<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 132]
- [cs.CL](#cs.CL) [Total: 67]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.RO](#cs.RO) [Total: 16]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Text2VR: Automated instruction Generation in Virtual Reality using Large language Models for Assembly Task](https://arxiv.org/abs/2508.03699)
*Subin Raj Peter*

Main category: cs.CV

TL;DR: 本文提出利用大语言模型（LLM）自动从文本生成虚拟现实训练中的指令内容，从而简化和加速VR培训应用的开发流程。


<details>
  <summary>Details</summary>
Motivation: 尽管虚拟现实（VR）在员工培训中具有沉浸性、交互性和无风险等优势，但创建高质量培训内容依然需要大量时间、专业知识和资源，极大限制了VR在培训中的广泛应用。因此亟需提高VR培训内容生成的自动化程度和效率。

Method: 作者设计了一个基于大语言模型的自动化系统。该系统包含两个核心模块：LLM模块从文本提取与任务相关的信息，智能模块将这些信息转化为VR中的动画演示和视觉提示。指令生成器利用数据库中的相关数据，通过改变虚拟物体颜色与创建动画来实现任务的模拟与展示。

Result: 该方法能够自动将文本内容转化为有效的VR训练指令，降低了VR培训开发的人力和资源成本，提高了VR培训系统的可扩展性和适应性。

Conclusion: 结合LLM与智能模块的自动化指令生成方法能有效提升VR培训应用的开发效率，使VR培训更易于推广并能灵活适应不断变化的行业需求。

Abstract: Virtual Reality (VR) has emerged as a powerful tool for workforce training,
offering immersive, interactive, and risk-free environments that enhance skill
acquisition, decision-making, and confidence. Despite its advantages,
developing VR applications for training remains a significant challenge due to
the time, expertise, and resources required to create accurate and engaging
instructional content. To address these limitations, this paper proposes a
novel approach that leverages Large Language Models (LLMs) to automate the
generation of virtual instructions from textual input. The system comprises two
core components: an LLM module that extracts task-relevant information from the
text, and an intelligent module that transforms this information into animated
demonstrations and visual cues within a VR environment. The intelligent module
receives input from the LLM module and interprets the extracted information.
Based on this, an instruction generator creates training content using relevant
data from a database. The instruction generator generates the instruction by
changing the color of virtual objects and creating animations to illustrate
tasks. This approach enhances training effectiveness and reduces development
overhead, making VR-based training more scalable and adaptable to evolving
industrial needs.

</details>


### [2] [Outlier Detection Algorithm for Circle Fitting](https://arxiv.org/abs/2508.03720)
*Ahmet Gökhan Poyraz*

Main category: cs.CV

TL;DR: 本文提出了一种基于极坐标的离群点检测（PCOD）算法，用于提高工业应用中圆拟合的精度，并验证了该方法优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 圆拟合广泛应用于工业质量控制与设计中，但在数据噪声较大时效果会显著下降，因此需要高效的离群点检测方法提高拟合精度。

Method: 提出PCOD算法，将点集转换为极坐标后，计算局部与整体标准差，并通过局部均值与整体标准差的对比识别离群点。此方法应用于机器视觉系统获取的垫圈零件图像，经亚像素边缘检测后，使用PCOD去除离群点，再进行圆拟合。并与其他十种圆拟合算法和五种离群点检测方法进行了对比。

Result: 实验显示，PCOD方法在精度方面优于其他方法，在工业数据集上表现最佳。

Conclusion: PCOD算法有效提升了圆拟合应用中的精度，尤其适用于工业场景，具有较强的实际应用潜力。

Abstract: Circle fitting methods are extensively utilized in various industries,
particularly in quality control processes and design applications. The
effectiveness of these algorithms can be significantly compromised when the
point sets to be predicted are noisy. To mitigate this issue, outlier detection
and removal algorithms are often applied before the circle fitting procedure.
This study introduces the Polar Coordinate-Based Outlier Detection (PCOD)
algorithm, which can be effectively employed in circle fitting applications. In
the proposed approach, the point set is first transformed into polar
coordinates, followed by the calculation of both local and global standard
deviations. Outliers are then identified by comparing local mean values with
the global standard deviation. The practicality and efficiency of the proposed
method are demonstrated by focusing on the high-precision diameter measurement
of industrial washer parts. Images from a machine vision system are processed
through preprocessing steps, including sub-pixel edge detection. The resulting
sub-pixel edge points are then cleaned using the proposed outlier detection and
removal algorithm, after which circle fitting is performed. A comparison is
made using ten different circle fitting algorithms and five distinct outlier
detection methods. The results indicate that the proposed method outperforms
the other approaches, delivering the best performance in terms of accuracy
within the dataset, thereby demonstrating its potential for enhancing circle
fitting applications in industrial environments.

</details>


### [3] [Enhancing Diameter Measurement Accuracy in Machine Vision Applications](https://arxiv.org/abs/2508.03721)
*Ahmet Gokhan Poyraz,Ahmet Emir Dirik,Hakan Gurkan,Mehmet Kacmaz*

Main category: cs.CV

TL;DR: 本论文提出了两种创新方法，通过多个已知参考件来提高相机测量系统的直径测量精度，显著减少了测量误差。


<details>
  <summary>Details</summary>
Motivation: 尽管在高精度测量中使用了诸如远心镜头等专业设备，但受机械和软件因素影响，尤其是在测量不同直径部件时，依然存在较大测量误差。作者希望增强通用相机测量系统的精度和稳定性。

Method: 提出了基于转换因子的测量方法和基于像素的测量方法。第一种利用已知参考件估计转换因子进而测量未知件的直径；第二种直接基于像素级参考信息推算未知件直径。实验采用工业相机和远心镜头，选用了玻璃样品（1-12 mm）和金属工件（3-24 mm）进行测试。

Result: 原始测量误差为13-114微米，应用新方法后错误降低到1-2微米。该方法仅需少量参考件即可实现高精度测量。

Conclusion: 提出的方法有效提升了现有直径测量的准确性和可靠性，在高精度工业测量领域具有实际应用价值，对相关文献起到了优化和补充作用。

Abstract: In camera measurement systems, specialized equipment such as telecentric
lenses is often employed to measure parts with narrow tolerances. However,
despite the use of such equipment, measurement errors can occur due to
mechanical and software-related factors within the system. These errors are
particularly evident in applications where parts of different diameters are
measured using the same setup. This study proposes two innovative approaches to
enhance measurement accuracy using multiple known reference parts: a conversion
factor-based method and a pixel-based method. In the first approach, the
conversion factor is estimated from known references to calculate the diameter
(mm) of the unknown part. In the second approach, the diameter (mm) is directly
estimated using pixel-based diameter information from the references. The
experimental setup includes an industrial-grade camera and telecentric lenses.
Tests conducted on glass samples (1-12 mm) and metal workpieces (3-24 mm) show
that measurement errors, which originally ranged from 13-114 micrometers, were
reduced to 1-2 micrometers using the proposed methods. By utilizing only a few
known reference parts, the proposed approach enables high-accuracy measurement
of all parts within the camera's field of view. Additionally, this method
enhances the existing diameter measurement literature by significantly reducing
error rates and improving measurement reliability.

</details>


### [4] [Multimodal Video Emotion Recognition with Reliable Reasoning Priors](https://arxiv.org/abs/2508.03722)
*Zhepeng Wang,Yingjian Zhu,Guanghao Dong,Hongzhu Yi,Feng Chen,Xinming Wang,Jun Xie*

Main category: cs.CV

TL;DR: 本文提出将可信的MLLM（多模态大语言模型）推理知识引入多模态情感识别，通过Gemini生成细粒度、可区分模态的推理过程作为先验信息用于模态融合阶段，同时提出平衡的双对比损失以缓解类别不平衡。实验结果表明，该方法在MER2024基准上显著提升了情感识别性能。


<details>
  <summary>Details</summary>
Motivation: 多模态情感识别效果受限于交互信息融合和类别极度不平衡的问题，且现有方法难以有效融合复杂的先验知识。作者旨在利用MLLM可靠的推理能力和高效融合策略，提升情感识别性能与稳健性。

Method: 利用Gemini模型生成细粒度、区分不同模态的推理轨迹，将其作为先验知识在模态融合阶段注入。同时设计了平衡的双对比学习损失，兼顾类间和类内分布，缓解多模态情感识别中的类别不平衡。

Result: 在MER2024基准测试上，提出的先验增强框架显著提升了情感识别的准确率，表现优于现有方法，验证了MLLM推理先验和轻量化自适应融合网络结合的有效性。

Conclusion: 将MLLM生成的高可信推理作为先验注入融合阶段，结合平衡的对比损失，有效增强了情感识别的跨模态交互和鲁棒性，为多模态情感识别提供了更强大且可扩展的解决思路。

Abstract: This study investigates the integration of trustworthy prior reasoning
knowledge from MLLMs into multimodal emotion recognition. We employ Gemini to
generate fine-grained, modality-separable reasoning traces, which are injected
as priors during the fusion stage to enrich cross-modal interactions. To
mitigate the pronounced class-imbalance in multimodal emotion recognition, we
introduce Balanced Dual-Contrastive Learning, a loss formulation that jointly
balances inter-class and intra-class distributions. Applied to the MER2024
benchmark, our prior-enhanced framework yields substantial performance gains,
demonstrating that the reliability of MLLM-derived reasoning can be
synergistically combined with the domain adaptability of lightweight fusion
networks for robust, scalable emotion recognition.

</details>


### [5] [From Waveforms to Pixels: A Survey on Audio-Visual Segmentation](https://arxiv.org/abs/2508.03724)
*Jia Li,Yapeng Tian*

Main category: cs.CV

TL;DR: 本文综述了音频-视觉分割（AVS）领域的研究进展，包括问题定义、数据集、评测指标、方法发展、主要挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: AVS作为多模态感知的重要研究方向，能实现对视频中发声物体的精细化分割与理解，但因融合多源数据面临诸多挑战，因此需要系统梳理和总结现有成果与限制。

Method: 论文对AVS领域的方法进行了系统分类与比较，包括单模态与多模态编码架构、音视频融合策略、解码器设计、全监督/弱监督/无监督等多种训练范式，并基于标准数据集详尽比对不同方法的性能。

Result: 揭示了不同架构、融合策略和训练范式对AVS任务效果的影响，总结了当前方案在时间建模、模态偏置、复杂环境鲁棒性和计算消耗等方面的局限。

Conclusion: 未来应提升时间推理能力和多模态融合效果，结合大模型实现更强泛化与少样本学习，通过自监督和弱监督方法减少标注依赖，并引入高级推理促进更智能的AVS系统。

Abstract: Audio-Visual Segmentation (AVS) aims to identify and segment sound-producing
objects in videos by leveraging both visual and audio modalities. It has
emerged as a significant research area in multimodal perception, enabling
fine-grained object-level understanding. In this survey, we present a
comprehensive overview of the AVS field, covering its problem formulation,
benchmark datasets, evaluation metrics, and the progression of methodologies.
We analyze a wide range of approaches, including architectures for unimodal and
multimodal encoding, key strategies for audio-visual fusion, and various
decoder designs. Furthermore, we examine major training paradigms, from fully
supervised learning to weakly supervised and training-free methods. Notably, we
provide an extensive comparison of AVS methods across standard benchmarks,
highlighting the impact of different architectural choices, fusion strategies,
and training paradigms on performance. Finally, we outline the current
challenges, such as limited temporal modeling, modality bias toward vision,
lack of robustness in complex environments, and high computational demands, and
propose promising future directions, including improving temporal reasoning and
multimodal fusion, leveraging foundation models for better generalization and
few-shot learning, reducing reliance on labeled data through selfand weakly
supervised learning, and incorporating higher-level reasoning for more
intelligent AVS systems.

</details>


### [6] [A Large Language Model Powered Integrated Circuit Footprint Geometry Understanding](https://arxiv.org/abs/2508.03725)
*Yida Wang,Taiting Lu,Runze Liu,Lanqing Yang,Yifan Yang,Zhe Chen,Yuehai Wang,Yixin Liu,Kaiyuan Lin,Xiaomeng Chen,Dian Ding,Yijie Li,Yi-Chao Chen,Yincheng Jin,Mahanth Gowda*

Main category: cs.CV

TL;DR: 本文提出了一种新方法，针对自动化IC机械图纸中的PCB封装几何标注，克服了当前大模型在几何感知上的不足，并发布了新的数据集和评测基准。


<details>
  <summary>Details</summary>
Motivation: 在PCB设计中，IC封装的几何标注直接关系到元器件与电路板布局的匹配。目前，缺乏自动化方法能够从IC机械图直接标注封装几何，人工处理繁琐且易出错，阻碍了自动化和智能化发展。

Method: 作者提出LLM4-IC8K框架，将IC机械图视为图像，引入多模态大模型进行结构化几何分析。其方法分为两个阶段：首先在合成数据上训练，学习几何推理基本能力；再用真实数据表进行微调提升实际性能。方法模仿工程人员实操流程，分为引脚数量识别、坐标计算及尺寸评估三步。同时，构建了ICGeo8K数据集，用于支持模型训练和评价。

Result: 在作者自建ICGeo8K基准上，LLM4-IC8K模型相比现有多模态大模型，在几何标注准确率及鲁棒性方面均表现更优。

Conclusion: 本文工作验证了多模态大模型在IC机械图几何标注中的潜力，通过合成+真实数据联合训练显著提升自动化标注能力，并为相关方向研究提供了新数据集和评测标准。

Abstract: Printed-Circuit-board (PCB) footprint geometry labeling of integrated
circuits (IC) is essential in defining the physical interface between
components and the PCB layout, requiring exceptional visual perception
proficiency. However, due to the unstructured footprint drawing and abstract
diagram annotations, automated parsing and accurate footprint geometry modeling
remain highly challenging. Despite its importance, no methods currently exist
for automated package geometry labeling directly from IC mechanical drawings.
In this paper, we first investigate the visual perception performance of Large
Multimodal Models (LMMs) when solving IC footprint geometry understanding. Our
findings reveal that current LMMs severely suffer from inaccurate geometric
perception, which hinders their performance in solving the footprint geometry
labeling problem. To address these limitations, we propose LLM4-IC8K, a novel
framework that treats IC mechanical drawings as images and leverages LLMs for
structured geometric interpretation. To mimic the step-by-step reasoning
approach used by human engineers, LLM4-IC8K addresses three sub-tasks:
perceiving the number of pins, computing the center coordinates of each pin,
and estimating the dimensions of individual pins. We present a two-stage
framework that first trains LMMs on synthetically generated IC footprint
diagrams to learn fundamental geometric reasoning and then fine-tunes them on
real-world datasheet drawings to enhance robustness and accuracy in practical
scenarios. To support this, we introduce ICGeo8K, a multi-modal dataset with
8,608 labeled samples, including 4138 hand-crafted IC footprint samples and
4470 synthetically generated samples. Extensive experiments demonstrate that
our model outperforms state-of-the-art LMMs on the proposed benchmark.

</details>


### [7] [TIR-Diffusion: Diffusion-based Thermal Infrared Image Denoising via Latent and Wavelet Domain Optimization](https://arxiv.org/abs/2508.03727)
*Tai Hyoung Rhee,Dong-guw Lee,Ayoung Kim*

Main category: cs.CV

TL;DR: 该论文提出了一种基于扩散模型的热红外（TIR）图像去噪框架，在多个基准和实际数据集上优于现有方法，并能鲁棒泛化至实际机器人环境。


<details>
  <summary>Details</summary>
Motivation: 热红外成像在低能见度或光照恶劣环境下对机器人感知有重要应用，但TIR图像通常存在严重的固定模式噪声，影响后续检测、定位等任务，故亟需高效的去噪方法。

Method: 方法利用预训练的stable diffusion模型，结合潜空间表示与小波域（DWT/DTCWT）优化，对模型进行微调；并引入级联细节增强阶段提升去噪精度。损失函数创新地结合了潜空间与小波域误差。

Result: 在多个基准数据集和真实TIR数据测试中，该方法性能优于现有主流去噪方法，并展现出良好的零样本泛化能力。

Conclusion: 本文提出的去噪框架有效提升了TIR图像的质量，为机器人感知在实际恶劣环境下的可靠性打下基础。

Abstract: Thermal infrared imaging exhibits considerable potentials for robotic
perception tasks, especially in environments with poor visibility or
challenging lighting conditions. However, TIR images typically suffer from
heavy non-uniform fixed-pattern noise, complicating tasks such as object
detection, localization, and mapping. To address this, we propose a
diffusion-based TIR image denoising framework leveraging latent-space
representations and wavelet-domain optimization. Utilizing a pretrained stable
diffusion model, our method fine-tunes the model via a novel loss function
combining latent-space and discrete wavelet transform (DWT) / dual-tree complex
wavelet transform (DTCWT) losses. Additionally, we implement a cascaded
refinement stage to enhance fine details, ensuring high-fidelity denoising
results. Experiments on benchmark datasets demonstrate superior performance of
our approach compared to state-of-the-art denoising methods. Furthermore, our
method exhibits robust zero-shot generalization to diverse and challenging
real-world TIR datasets, underscoring its effectiveness for practical robotic
deployment.

</details>


### [8] [What is Beneath Misogyny: Misogynous Memes Classification and Explanation](https://arxiv.org/abs/2508.03732)
*Kushal Kanwar,Dushyant Singh Chauhan,Gopendra Vikram Singh,Asif Ekbal*

Main category: cs.CV

TL;DR: 本文提出了一种多模态方法MM-Misogyny，用于检测、分类和解释网络迷因中的厌女内容，并在新建的WBMS数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 许多带有有害意识形态（如厌女）的迷因以娱乐为幌子在网络流传，准确检测并理解这些多模态（图像+文本）复杂表达的厌女内容具备重要社会意义，但技术挑战较大。

Method: 提出MM-Misogyny模型，分别处理文本和图像信息，通过交叉注意力机制融合，形成多模态语境，再利用分类器和大型语言模型实现标签分类和解释。并构建WBMS数据集，将迷因分为厨房、领导力、工作和购物四类。

Result: 该模型能够有效检测和分类厌女迷因，并给出细致解释。实验显示新方法效果优于现有技术。

Conclusion: MM-Misogyny为识别、分类和理解网络迷因中的厌女现象提供了更优解决方案，有助于更细致地把握和防范不同场域中的厌女表达。

Abstract: Memes are popular in the modern world and are distributed primarily for
entertainment. However, harmful ideologies such as misogyny can be propagated
through innocent-looking memes. The detection and understanding of why a meme
is misogynous is a research challenge due to its multimodal nature (image and
text) and its nuanced manifestations across different societal contexts. We
introduce a novel multimodal approach, \textit{namely},
\textit{\textbf{MM-Misogyny}} to detect, categorize, and explain misogynistic
content in memes. \textit{\textbf{MM-Misogyny}} processes text and image
modalities separately and unifies them into a multimodal context through a
cross-attention mechanism. The resulting multimodal context is then easily
processed for labeling, categorization, and explanation via a classifier and
Large Language Model (LLM). The evaluation of the proposed model is performed
on a newly curated dataset (\textit{\textbf{W}hat's \textbf{B}eneath
\textbf{M}isogynous \textbf{S}tereotyping (WBMS)}) created by collecting
misogynous memes from cyberspace and categorizing them into four categories,
\textit{namely}, Kitchen, Leadership, Working, and Shopping. The model not only
detects and classifies misogyny, but also provides a granular understanding of
how misogyny operates in domains of life. The results demonstrate the
superiority of our approach compared to existing methods. The code and dataset
are available at
\href{https://github.com/kushalkanwarNS/WhatisBeneathMisogyny/tree/main}{https://github.com/Misogyny}.

</details>


### [9] [StorySync: Training-Free Subject Consistency in Text-to-Image Generation via Region Harmonization](https://arxiv.org/abs/2508.03735)
*Gopalji Gaur,Mohammadreza Zolfaghari,Thomas Brox*

Main category: cs.CV

TL;DR: 本文提出了一种无需额外训练，能在文本生成图像故事时保持主题一致性的新方法。


<details>
  <summary>Details</summary>
Motivation: 当前用扩散模型生成视觉故事时，如何在不同场景下让图片中的主题保持一致，是难点。如果每次都微调模型或重新训练，成本高且效率低，且可能影响原模型的生成能力。

Method: 作者提出训练无关的方法，直接在现有的预训练扩散模型上，通过“掩码跨图像注意力共享”来动态对齐各图片的主题特征，并结合“区域特征协调”细化局部视觉细节，从而提高主题一致性。

Result: 实验证明，该方法在多种场景下能生成主题高度一致的图片，同时不影响模型的创造力。

Conclusion: 文中方法高效且对原模型零损伤，为主旨连贯的图像故事生成提供了新思路。

Abstract: Generating a coherent sequence of images that tells a visual story, using
text-to-image diffusion models, often faces the critical challenge of
maintaining subject consistency across all story scenes. Existing approaches,
which typically rely on fine-tuning or retraining models, are computationally
expensive, time-consuming, and often interfere with the model's pre-existing
capabilities. In this paper, we follow a training-free approach and propose an
efficient consistent-subject-generation method. This approach works seamlessly
with pre-trained diffusion models by introducing masked cross-image attention
sharing to dynamically align subject features across a batch of images, and
Regional Feature Harmonization to refine visually similar details for improved
subject consistency. Experimental results demonstrate that our approach
successfully generates visually consistent subjects across a variety of
scenarios while maintaining the creative abilities of the diffusion model.

</details>


### [10] [Fusion of Pervasive RF Data with Spatial Images via Vision Transformers for Enhanced Mapping in Smart Cities](https://arxiv.org/abs/2508.03736)
*Rafayel Mkrtchyan,Armen Manukyan,Hrant Khachatrian,Theofanis P. Raptis*

Main category: cs.CV

TL;DR: 本文提出一种基于深度学习的新方法，结合开源地图与无线射频数据，利用DINOv2架构提升建筑物环境地图精度，实验结果显著优于传统和现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的智能城市环境地图构建方法如卫星影像、激光雷达扫描和人工标注受限于成本高、可获得性差和精度有限，且开源地图数据存在人为误差和环境动态变化带来的偏差，影响神经网络的可靠性。亟需高效、精准的环境建图新方案。

Method: 本文提出一种结合DINOv2视觉Transformer架构的深度学习方法，将来自开源平台的地图数据与多用户设备和基站收集的射频(RF)数据融合，统一建模空间依赖与结构先验，实现更精准的环境地图。采用华为联合制作的合成数据集，模型仅利用聚合路径损耗信息解决建图问题，并通过Jaccard指数、Hausdorff距离和Chamfer距离三项指标评估。

Result: 所提出方法的macro IoU达到65.3%，明显优于多种基线：(1)有误差地图基线为40.1%；(2)文献中的射频数据单一方法为37.3%；(3)作者自行设计的非AI融合基线为42.2%。

Conclusion: 基于DINOv2和多模态数据融合的新方法有效提升了智能城市场景下环境地图的精度，明显优于常见基线，有望为现实场景下应用提供更可靠的地图数据支持。

Abstract: Environment mapping is an important computing task for a wide range of smart
city applications, including autonomous navigation, wireless network operations
and extended reality environments. Conventional smart city mapping techniques,
such as satellite imagery, LiDAR scans, and manual annotations, often suffer
from limitations related to cost, accessibility and accuracy. Open-source
mapping platforms have been widely utilized in artificial intelligence
applications for environment mapping, serving as a source of ground truth.
However, human errors and the evolving nature of real-world environments
introduce biases that can negatively impact the performance of neural networks
trained on such data. In this paper, we present a deep learning-based approach
that integrates the DINOv2 architecture to improve building mapping by
combining maps from open-source platforms with radio frequency (RF) data
collected from multiple wireless user equipments and base stations. Our
approach leverages a vision transformer-based architecture to jointly process
both RF and map modalities within a unified framework, effectively capturing
spatial dependencies and structural priors for enhanced mapping accuracy. For
the evaluation purposes, we employ a synthetic dataset co-produced by Huawei.
We develop and train a model that leverages only aggregated path loss
information to tackle the mapping problem. We measure the results according to
three performance metrics which capture different qualities: (i) The Jaccard
index, also known as intersection over union (IoU), (ii) the Hausdorff
distance, and (iii) the Chamfer distance. Our design achieves a macro IoU of
65.3%, significantly surpassing (i) the erroneous maps baseline, which yields
40.1%, (ii) an RF-only method from the literature, which yields 37.3%, and
(iii) a non-AI fusion baseline that we designed which yields 42.2%.

</details>


### [11] [VQ-DeepISC: Vector Quantized-Enabled Digital Semantic Communication with Channel Adaptive Image Transmission](https://arxiv.org/abs/2508.03740)
*Jianqiao Chen,Tingting Zhu,Huishi Song,Nan Ma,Xiaodong Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于向量量化的数字语义通信系统VQ-DeepISC，通过端到端深度联合信道编码，实现对图像等语义信息的高效、可靠数字化和传输，重建质量优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 语义特征的离散化能够促进语义通信与传统数字通信系统的兼容，具备重要的实际应用潜力。然而，如何在保证鲁棒性和上下文连续性的同时，将本质上连续的语义特征有效离散化，一直是难点。

Method: 1. 设计Swin Transformer骨干网络，分层提取语义特征；2. 利用向量量化模块将特征投影到离散潜在空间，实现基于索引的传输；3. 提出基于注意力机制的信道自适应模块，动态优化索引传输；4. 为防止训练过程中码本塌陷，通过最小化KLD正则化索引分布，并结合EMA缓解训练不稳定，确保码本均衡；5. 充分采用符合IEEE 802.11a标准的QPSK-OFDM数字通信实现端到端。

Result: 实验表明，所提系统在图像重建质量上优于现有基线方法，具备更强的重建保真度和鲁棒性。

Conclusion: VQ-DeepISC系统兼顾了语义特征的离散化和通信鲁棒性，在数字语义通信方面展现出实际应用价值，为语义信息在数字系统中的高效可靠传输提供了新范式。

Abstract: Discretization of semantic features enables interoperability between semantic
and digital communication systems, showing significant potential for practical
applications. The fundamental difficulty in digitizing semantic features stems
from the need to preserve continuity and context in inherently analog
representations during their compression into discrete symbols while ensuring
robustness to channel degradation. In this paper, we propose a vector quantized
(VQ)-enabled digital semantic communication system with channel adaptive image
transmission, named VQ-DeepISC. Guided by deep joint source-channel coding
(DJSCC), we first design a Swin Transformer backbone for hierarchical semantic
feature extraction, followed by VQ modules projecting features into discrete
latent spaces. Consequently, it enables efficient index-based transmission
instead of raw feature transmission. To further optimize this process, we
develop an attention mechanism-driven channel adaptation module to dynamically
optimize index transmission. Secondly, to counteract codebook collapse during
training process, we impose a distributional regularization by minimizing the
Kullback-Leibler divergence (KLD) between codeword usage frequencies and a
uniform prior. Meanwhile, exponential moving average (EMA) is employed to
stabilize training and ensure balanced feature coverage during codebook
updates. Finally, digital communication is implemented using quadrature phase
shift keying (QPSK) modulation alongside orthogonal frequency division
multiplexing (OFDM), adhering to the IEEE 802.11a standard. Experimental
results demonstrate superior reconstruction fidelity of the proposed system
over benchmark methods.

</details>


### [12] [Tobler's First Law in GeoAI: A Spatially Explicit Deep Learning Model for Terrain Feature Detection Under Weak Supervision](https://arxiv.org/abs/2508.03745)
*Wenwen Li,Chia-Yu Hsu,Maosheng Hu*

Main category: cs.CV

TL;DR: 本文提出了一种结合地理空间原则的弱监督深度学习模型，用于地理对象检测，并成功应用于火星陨石坑识别。


<details>
  <summary>Details</summary>
Motivation: 现有地理空间AI应用普遍面临训练数据不足和忽视空间规律的问题，限制了AI与地理空间研究的融合效果。

Method: 1）提出基于托布勒第一地理定律的空间显式弱标签对象检测模型；2）在检测流程中引入注意力机制，并设计了多阶段训练策略；3）模型应用于火星陨石坑的自动检测。

Result: 该模型无需大量手动标注，只用弱标签就能有效检测自然和人工地理对象，并在火星陨石坑识别任务上表现出强泛化能力。

Conclusion: 本研究推动了GeoAI理论及方法创新，为地理空间分析提供了新的自动化智能工具。

Abstract: Recent interest in geospatial artificial intelligence (GeoAI) has fostered a
wide range of applications using artificial intelligence (AI), especially deep
learning, for geospatial problem solving. However, major challenges such as a
lack of training data and the neglect of spatial principles and spatial effects
in AI model design remain, significantly hindering the in-depth integration of
AI with geospatial research. This paper reports our work in developing a deep
learning model that enables object detection, particularly of natural features,
in a weakly supervised manner. Our work makes three contributions: First, we
present a method of object detection using only weak labels. This is achieved
by developing a spatially explicit model based on Tobler's first law of
geography. Second, we incorporate attention maps into the object detection
pipeline and develop a multistage training strategy to improve performance.
Third, we apply this model to detect impact craters on Mars, a task that
previously required extensive manual effort. The model generalizes to both
natural and human-made features on the surfaces of Earth and other planets.
This research advances the theoretical and methodological foundations of GeoAI.

</details>


### [13] [Closed-Circuit Television Data as an Emergent Data Source for Urban Rail Platform Crowding Estimation](https://arxiv.org/abs/2508.03749)
*Riccardo Fiorista,Awad Abdelhalim,Anson F. Stewart,Gabriel L. Pincus,Ian Thistle,Jinhua Zhao*

Main category: cs.CV

TL;DR: 该论文通过对地铁站台监控视频，比较了三种主流计算机视觉方法对站台人群密度的估算能力，并提出一种高效的基于线性优化的计数方法。实验证明，这些方法能够为城市轨道交通平台提供准确的实时人群拥挤度估算，有助于提升安全和运营效率。


<details>
  <summary>Details</summary>
Motivation: 背景是城市轨道交通站台的人流密度难以实时准确监测，依赖刷卡数据或人工观察精度有限。而监控视频为新数据源，有望提升估算准确性和实时性。

Method: 文章对比了三类计算机视觉方法：1）基于YOLOv11、RT-DETRv2和APGCC的目标检测和计数；2）基于Vision Transformer（Crowd-ViT）的自定义人群分级算法；3）DeepLabV3语义分割。提出了一种新颖、高效的线性优化算法，从分割图像中计人数，并考虑了影像深度影响。

Result: 基于与华盛顿地铁局合作收集的600小时视频数据集，实验证明：三类方法均能有效进行实时人群估算，线性优化算法显著提高计数准确度。

Conclusion: 监控视频数据独立于其他传统数据源，可为轨道交通平台提供高精度、实时的人群密度估算能力，有利于更及时做出运营响应，从而缓解站台拥挤问题。

Abstract: Accurately estimating urban rail platform occupancy can enhance transit
agencies' ability to make informed operational decisions, thereby improving
safety, operational efficiency, and customer experience, particularly in the
context of crowding. However, sensing real-time crowding remains challenging
and often depends on indirect proxies such as automatic fare collection data or
staff observations. Recently, Closed-Circuit Television (CCTV) footage has
emerged as a promising data source with the potential to yield accurate,
real-time occupancy estimates. The presented study investigates this potential
by comparing three state-of-the-art computer vision approaches for extracting
crowd-related features from platform CCTV imagery: (a) object detection and
counting using YOLOv11, RT-DETRv2, and APGCC; (b) crowd-level classification
via a custom-trained Vision Transformer, Crowd-ViT; and (c) semantic
segmentation using DeepLabV3. Additionally, we present a novel, highly
efficient linear-optimization-based approach to extract counts from the
generated segmentation maps while accounting for image object depth and, thus,
for passenger dispersion along a platform. Tested on a privacy-preserving
dataset created in collaboration with the Washington Metropolitan Area Transit
Authority (WMATA) that encompasses more than 600 hours of video material, our
results demonstrate that computer vision approaches can provide substantive
value for crowd estimation. This work demonstrates that CCTV image data,
independent of other data sources available to a transit agency, can enable
more precise real-time crowding estimation and, eventually, timely operational
responses for platform crowding mitigation.

</details>


### [14] [Modular Transformer Architecture for Precision Agriculture Imaging](https://arxiv.org/abs/2508.03751)
*Brian Gopalan,Nathalia Nascimento,Vishal Monga*

Main category: cs.CV

TL;DR: 提出一种适用于无人机视频杂草分割的质量感知模块化深度学习框架，通过针对性处理图像退化问题（如模糊和噪声），大幅提升了分割质量和计算效率，优于现有CNN方法。


<details>
  <summary>Details</summary>
Motivation: 传统的杂草分割方法容易受到无人机视频中常见的图像退化（模糊、噪声等）影响，降低了分割准确率，因此亟需提升在不同图像质量条件下的分割鲁棒性和效率。

Method: 首先利用均值绝对偏差（MAD）和拉普拉斯算子分析输入图像的噪声和模糊情况。根据分析结果，将数据动态分配至三种不同的视觉变换器（Vision Transformer）模型：清晰图像用基础模型、噪声图像用融合Fisher Vector编码的模型、模糊图像用嵌入Lucy-Robinson解码器的模型，以针对性预处理和建模提升性能。

Result: 所提系统在杂草分割任务中，在分割质量和计算效率两方面均优于当前主流基于CNN的分割方法，表现出更强的鲁棒性和实用性。

Conclusion: 质量感知和路由机制结合定制化transformer模型显著提升无人机农业应用中的分割能力，对精细农业场景下的智能视觉分析具有重要推动意义。

Abstract: This paper addresses the critical need for efficient and accurate weed
segmentation from drone video in precision agriculture. A quality-aware modular
deep-learning framework is proposed that addresses common image degradation by
analyzing quality conditions-such as blur and noise-and routing inputs through
specialized pre-processing and transformer models optimized for each
degradation type. The system first analyzes drone images for noise and blur
using Mean Absolute Deviation and the Laplacian. Data is then dynamically
routed to one of three vision transformer models: a baseline for clean images,
a modified transformer with Fisher Vector encoding for noise reduction, or
another with an unrolled Lucy-Robinson decoder to correct blur. This novel
routing strategy allows the system to outperform existing CNN-based methods in
both segmentation quality and computational efficiency, demonstrating a
significant advancement in deep-learning applications for agriculture.

</details>


### [15] [Generating Synthetic Invoices via Layout-Preserving Content Replacement](https://arxiv.org/abs/2508.03754)
*Bevin V,Ananthakrishnan P V,Ragesh KR,Sanjay M,Vineeth S,Bibin Wilson*

Main category: cs.CV

TL;DR: 本论文提出了一种自动生成高保真合成发票及其结构化数据的新型流程，为自动发票处理的机器学习模型提供大规模多样性训练数据。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习模型对发票自动处理依赖于大规模多样性的数据集，但受限于隐私法规和人工标注成本，难以获取。亟需一种能够轻松扩充有效数据集的方法。

Method: 作者提出以OCR提取真实发票文本与版面，利用大语言模型为选定字段生成合成文本，最后借助图像修复（inpainting）方法将合成文本渲染到原图，重建与源图一致的视觉风格，最终得到合成图片与严格对应的结构化数据。

Result: 该流程可以生成高质量的合成发票图像及其结构化数据文件，有效地扩充了小型、受限数据集。

Conclusion: 所提出的管线能够自动化并大规模扩展发票数据集，有助于训练更加强健、精准的文件智能模型。

Abstract: The performance of machine learning models for automated invoice processing
is critically dependent on large-scale, diverse datasets. However, the
acquisition of such datasets is often constrained by privacy regulations and
the high cost of manual annotation. To address this, we present a novel
pipeline for generating high-fidelity, synthetic invoice documents and their
corresponding structured data. Our method first utilizes Optical Character
Recognition (OCR) to extract the text content and precise spatial layout from a
source invoice. Select data fields are then replaced with contextually
realistic, synthetic content generated by a large language model (LLM).
Finally, we employ an inpainting technique to erase the original text from the
image and render the new, synthetic text in its place, preserving the exact
layout and font characteristics. This process yields a pair of outputs: a
visually realistic new invoice image and a perfectly aligned structured data
file (JSON) reflecting the synthetic content. Our approach provides a scalable
and automated solution to amplify small, private datasets, enabling the
creation of large, varied corpora for training more robust and accurate
document intelligence models.

</details>


### [16] [Refine-IQA: Multi-Stage Reinforcement Finetuning for Perceptual Image Quality Assessment](https://arxiv.org/abs/2508.03763)
*Ziheng Jia,Jiaying Qian,Zicheng Zhang,Zijian Chen,Xiongkuo Min*

Main category: cs.CV

TL;DR: 本文提出了一种新的多阶段强化微调方法（Refine-IQA）用于图像质量评价（IQA），在提升模型感知和评分能力的同时，还增强了其解释质量的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于强化微调（RFT）的IQA方法只对最终输出进行奖励，没有对模型“思考”过程提供监督，无法保证其过程的正确性和有效性；同时，现有方法直接在下游任务上微调，未提升模型原生的低级视觉感知，限制了性能发挥。

Method: 提出多阶段RFT IQA框架（Refine-IQA）：第一阶段，构建包含12种失真类型、超2万图像的Refine-Perception-20K数据集，并设计多任务奖励函数提升模型的视觉质量感知能力；第二阶段，在质量评分任务中引入概率差奖励来监督“思考”过程。

Result: Refine-IQA系列模型在感知和质量评分任务上取得了优异的性能，激活了模型强大的“思考”与质量解释能力，在相关解释基准表现突出。

Conclusion: 多阶段RFT方法不仅提升了图像质量评价性能，还令模型具备更强的品质解释与“思考”能力，对低级视觉领域具有实际应用与推广价值。

Abstract: Reinforcement fine-tuning (RFT) is a proliferating paradigm for LMM training.
Analogous to high-level reasoning tasks, RFT is similarly applicable to
low-level vision domains, including image quality assessment (IQA). Existing
RFT-based IQA methods typically use rule-based output rewards to verify the
model's rollouts but provide no reward supervision for the "think" process,
leaving its correctness and efficacy uncontrolled. Furthermore, these methods
typically fine-tune directly on downstream IQA tasks without explicitly
enhancing the model's native low-level visual quality perception, which may
constrain its performance upper bound. In response to these gaps, we propose
the multi-stage RFT IQA framework (Refine-IQA). In Stage-1, we build the
Refine-Perception-20K dataset (with 12 main distortions, 20,907
locally-distorted images, and over 55K RFT samples) and design multi-task
reward functions to strengthen the model's visual quality perception. In
Stage-2, targeting the quality scoring task, we introduce a probability
difference reward involved strategy for "think" process supervision. The
resulting Refine-IQA Series Models achieve outstanding performance on both
perception and scoring tasks-and, notably, our paradigm activates a robust
"think" (quality interpreting) capability that also attains exceptional results
on the corresponding quality interpreting benchmark.

</details>


### [17] [4D-PreNet: A Unified Preprocessing Framework for 4D-STEM Data Analysis](https://arxiv.org/abs/2508.03775)
*Mingyu Liu,Zian Mao,Zhu Liu,Haoran Zhang,Jintao Guo,Xiaoya He,Xi Huang,Shufen Chu,Chun Cheng,Jun Ding,Yujun Xie*

Main category: cs.CV

TL;DR: 本论文提出了一个端到端的深度学习框架4D-PreNet，有效提升了4D-STEM（四维扫描透射电子显微镜）高通量数据采集中的数据预处理效率，并改善了噪声、中心漂移和椭圆畸变等问题。


<details>
  <summary>Details</summary>
Motivation: 高通量4D-STEM实验的数据预处理困难，是自动化实时分析的瓶颈。噪声、中心漂移和畸变会严重影响衍射图样的质量，现有算法通常依赖具体材料，鲁棒性和通用性不足。

Method: 提出了4D-PreNet，一个结合attention增强的U-Net和ResNet的端到端深度学习流程，可同时进行去噪、中心修正和畸变校准。网络在包含多种噪声、漂移和畸变类型的大规模模拟数据上训练，在适应不同实验条件下有较好泛化性能。

Result: 该方法在去噪任务上可将均方误差减少50%，中心检测可实现小于0.04像素的平均误差，且在噪声抑制和衍射图修复等指标上优于传统方法。

Conclusion: 4D-PreNet为4D-STEM高通量、自动化和实时分析提供了更为高效可靠的数据预处理方法，显著提升了实验数据的准确性和可用性。

Abstract: Automated experimentation with real time data analysis in scanning
transmission electron microscopy (STEM) often require end-to-end framework. The
four-dimensional scanning transmission electron microscopy (4D-STEM) with
high-throughput data acquisition has been constrained by the critical
bottleneck results from data preprocessing. Pervasive noise, beam center drift,
and elliptical distortions during high-throughput acquisition inevitably
corrupt diffraction patterns, systematically biasing quantitative measurements.
Yet, conventional correction algorithms are often material-specific and fail to
provide a robust, generalizable solution. In this work, we present 4D-PreNet,
an end-to-end deep-learning pipeline that integrates attention-enhanced U-Net
and ResNet architectures to simultaneously perform denoising, center
correction, and elliptical distortion calibration. The network is trained on
large, simulated datasets encompassing a wide range of noise levels, drift
magnitudes, and distortion types, enabling it to generalize effectively to
experimental data acquired under varying conditions. Quantitative evaluations
demonstrate that our pipeline reduces mean squared error by up to 50% during
denoising and achieves sub-pixel center localization in the center detection
task, with average errors below 0.04 pixels. The outputs are bench-marked
against traditional algorithms, highlighting improvements in both noise
suppression and restoration of diffraction patterns, thereby facilitating
high-throughput, reliable 4D-STEM real-time analysis for automated
characterization.

</details>


### [18] [RiemanLine: Riemannian Manifold Representation of 3D Lines for Factor Graph Optimization](https://arxiv.org/abs/2508.04335)
*Yanyan Li,Ze Yang,Keisuke Tateno,Federico Tombari Liang Zhao,Gim Hee Lee*

Main category: cs.CV

TL;DR: 该论文提出了一种名为RiemanLine的3D直线最小参数化新方法，能够统一表示单一直线与平行线组，大幅压缩参数空间并提升相机定位与结构重建精度。


<details>
  <summary>Details</summary>
Motivation: 现有三维直线参数化方法主要处理独立的直线，忽视了人工环境中常见的平行线结构，导致在相机定位和地图构建任务中参数空间冗余且缺乏结构表达能力。

Method: 作者提出RiemanLine方法，将每条直线分解为全局共享的消失方向（在单位球面上优化）和局部的法向量（在正交子空间约束），从而高效编码平行结构。并将这一参数化集成至因子图框架，实现方向对齐和重投影联合优化。对于n条平行直线，参数维度从4n降至2n+2。

Result: 在ICL-NUIM、TartanAir和合成数据集上进行了广泛实验。结果显示该方法在减少参数维度的同时，能够获得更高的位姿估计精度和直线重建准确性，并提升了优化收敛的稳定性。

Conclusion: RiemanLine实现了对3D独立直线与平行线组的统一、最小表述，有效压缩参数空间，并在实际视觉SLAM和结构重建任务中显著提升了性能，具有很强的实用意义。

Abstract: Minimal parametrization of 3D lines plays a critical role in camera
localization and structural mapping. Existing representations in robotics and
computer vision predominantly handle independent lines, overlooking structural
regularities such as sets of parallel lines that are pervasive in man-made
environments. This paper introduces \textbf{RiemanLine}, a unified minimal
representation for 3D lines formulated on Riemannian manifolds that jointly
accommodates both individual lines and parallel-line groups. Our key idea is to
decouple each line landmark into global and local components: a shared
vanishing direction optimized on the unit sphere $\mathcal{S}^2$, and scaled
normal vectors constrained on orthogonal subspaces, enabling compact encoding
of structural regularities. For $n$ parallel lines, the proposed representation
reduces the parameter space from $4n$ (orthonormal form) to $2n+2$, naturally
embedding parallelism without explicit constraints. We further integrate this
parameterization into a factor graph framework, allowing global direction
alignment and local reprojection optimization within a unified manifold-based
bundle adjustment. Extensive experiments on ICL-NUIM, TartanAir, and synthetic
benchmarks demonstrate that our method achieves significantly more accurate
pose estimation and line reconstruction, while reducing parameter
dimensionality and improving convergence stability.

</details>


### [19] [HPSv3: Towards Wide-Spectrum Human Preference Score](https://arxiv.org/abs/2508.03789)
*Yuhang Ma,Xiaoshi Wu,Keqiang Sun,Hongsheng Li*

Main category: cs.CV

TL;DR: 本文提出了人类偏好打分v3（HPSv3），包括一个大规模的人类偏好数据集和基于视觉语言模型的偏好模型，解决了文本生成图像模型评估中的现有局限性。作者还引入了基于HPSv3的迭代图像优化方法，实验结果显示新方法有效提升了评测与生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的面向人类的文本到图像生成模型评估指标受到数据范围窄、特征提取不佳和损失函数低效等问题限制，难以很好反映人的真实感知，因此亟需更大规模且高质量的人类偏好数据和更有效的评价及优化方法。

Method: 1. 构建并发布了HPSv3数据集，包含108万组文本-图像对和117万个人类注释的成对比较，涵盖当前高水平生成模型和真实图片。2. 用视觉语言模型（VLM）训练了一个不确定性感知的排序偏好模型。3. 提出“人类偏好链式优化”（CoHP）方法，利用HPSv3作为评价标准，在每步选择最优图片以迭代提升质量。

Result: 实验表明，HPSv3评测指标在多种图像场景下均表现稳健可靠，能更好地与人类偏好一致。同时，CoHP方法能够在不依赖额外数据的情况下显著提升生成图像质量。

Conclusion: HPSv3数据集和指标为文本到图像生成模型提供了更符合人类感知的评测和优化工具，推动了生成模型的进一步发展。相关代码与数据已公开，便于社区使用与改进。

Abstract: Evaluating text-to-image generation models requires alignment with human
perception, yet existing human-centric metrics are constrained by limited data
coverage, suboptimal feature extraction, and inefficient loss functions. To
address these challenges, we introduce Human Preference Score v3 (HPSv3). (1)
We release HPDv3, the first wide-spectrum human preference dataset integrating
1.08M text-image pairs and 1.17M annotated pairwise comparisons from
state-of-the-art generative models and low to high-quality real-world images.
(2) We introduce a VLM-based preference model trained using an
uncertainty-aware ranking loss for fine-grained ranking. Besides, we propose
Chain-of-Human-Preference (CoHP), an iterative image refinement method that
enhances quality without extra data, using HPSv3 to select the best image at
each step. Extensive experiments demonstrate that HPSv3 serves as a robust
metric for wide-spectrum image evaluation, and CoHP offers an efficient and
human-aligned approach to improve image generation quality. The code and
dataset are available at the HPSv3 Homepage.

</details>


### [20] [OmniDepth: Bridging Monocular and Stereo Reasoning with Latent Alignment](https://arxiv.org/abs/2508.04611)
*Tongfan Guan,Jiaxin Guo,Chen Wang,Yun-Hui Liu*

Main category: cs.CV

TL;DR: 本文提出OmniDepth框架，通过单目和双目深度估计的潜在表示双向对齐，显著提升了深度估计在复杂场景下（如反光、透明物体）鲁棒性，达到了最新的性能。


<details>
  <summary>Details</summary>
Motivation: 单目深度估计具有丰富的上下文先验，但几何精度不足；双目方法具有优良几何约束，却在反光、纹理缺失等场景下易陷入歧义。现有方法多将两者割裂，缺乏有效融合手段。

Method: 提出了OmniDepth统一框架，核心为一种新颖的跨注意力对齐机制，在双目推理过程中动态同步单目和双目潜在特征，实现信息互补。这样既用单目先验缓解双目歧义，也用双目几何优化单目估计。所有流程集成于单一网络。

Result: 实验显示，OmniDepth实现了当前最优性能：在Middlebury和ETH3D数据集上，零样本泛化误差降低了40%以上，并有效解决了透明和反射场景的深度估计难题。

Conclusion: OmniDepth框架通过有机融合单目上下文与多视角几何信息，突破了各自感知模式的局限，为多场景下鲁棒3D感知提供了有效方案。

Abstract: Monocular and stereo depth estimation offer complementary strengths:
monocular methods capture rich contextual priors but lack geometric precision,
while stereo approaches leverage epipolar geometry yet struggle with
ambiguities such as reflective or textureless surfaces. Despite post-hoc
synergies, these paradigms remain largely disjoint in practice. We introduce
OmniDepth, a unified framework that bridges both through iterative
bidirectional alignment of their latent representations. At its core, a novel
cross-attentive alignment mechanism dynamically synchronizes monocular
contextual cues with stereo hypothesis representations during stereo reasoning.
This mutual alignment resolves stereo ambiguities (e.g., specular surfaces) by
injecting monocular structure priors while refining monocular depth with stereo
geometry within a single network. Extensive experiments demonstrate
state-of-the-art results: \textbf{OmniDepth reduces zero-shot generalization
error by $\!>\!40\%$ on Middlebury and ETH3D}, while addressing longstanding
failures on transparent and reflective surfaces. By harmonizing multi-view
geometry with monocular context, OmniDepth enables robust 3D perception that
transcends modality-specific limitations. Codes available at
https://github.com/aeolusguan/OmniDepth.

</details>


### [21] [Deep learning framework for crater detection and identification on the Moon and Mars](https://arxiv.org/abs/2508.03920)
*Yihan Ma,Zeyang Yu,Rohitash Chandra*

Main category: cs.CV

TL;DR: 该论文利用深度学习模型对行星撞击坑进行自动化检测，提出了一个两阶段的检测框架，并在火星和月球的遥感数据上进行了实验。


<details>
  <summary>Details</summary>
Motivation: 撞击坑作为行星表面的重要地貌特征，对行星表面组成、地质历史及撞击过程研究非常关键。传统方法检测复杂、效率低，亟需自动化和高效的检测方法。

Method: 提出了一个以深度学习为核心的两阶段撞击坑检测框架。第一阶段采用经典CNN、ResNet-50和YOLO进行初步检测，第二阶段用YOLO进一步精确定位，并对不同类型的坑进行识别。研究基于火星和月球的遥感数据进行。

Result: 实验结果显示，在各模型中，YOLO表现出检测性能最均衡，ResNet-50在识别大坑方面精度最高。

Conclusion: 深度学习模型（尤其YOLO和ResNet-50）在行星撞击坑自动检测中展现出较高潜力,可用于提高撞击坑识别的效率和精度。

Abstract: Impact craters are among the most prominent geomorphological features on
planetary surfaces and are of substantial significance in planetary science
research. Their spatial distribution and morphological characteristics provide
critical information on planetary surface composition, geological history, and
impact processes. In recent years, the rapid advancement of deep learning
models has fostered significant interest in automated crater detection. In this
paper, we apply advancements in deep learning models for impact crater
detection and identification. We use novel models, including Convolutional
Neural Networks (CNNs) and variants such as YOLO and ResNet. We present a
framework that features a two-stage approach where the first stage features
crater identification using simple classic CNN, ResNet-50 and YOLO. In the
second stage, our framework employs YOLO-based detection for crater
localisation. Therefore, we detect and identify different types of craters and
present a summary report with remote sensing data for a selected region. We
consider selected regions for craters and identification from Mars and the Moon
based on remote sensing data. Our results indicate that YOLO demonstrates the
most balanced crater detection performance, while ResNet-50 excels in
identifying large craters with high precision.

</details>


### [22] [Point-Based Shape Representation Generation with a Correspondence-Preserving Diffusion Model](https://arxiv.org/abs/2508.03925)
*Shen Zhu,Yinzhu Jin,Ifrah Zawar,P. Thomas Fletcher*

Main category: cs.CV

TL;DR: 本文提出了一种能够生成带有点对应关系（correspondences）的点云形状表示的扩散模型。相比现有深度学习生成模型仅处理无序点云，该方法可生成具备一致点对应关系的形状。


<details>
  <summary>Details</summary>
Motivation: 现有的深度生成模型生成的点云之间缺乏可对齐的点对应关系，这限制了这些模型在形状对比、疾病进展预测等任务中的应用。统计形状模型传统上关注点对应关系，但深度学习方法较少涉及。该研究旨在弥合这一空白。

Method: 作者设计了一种新的扩散模型，训练时输入带有一一对应点的信息（来源于OASIS-3数据库）。模型通过学习在样本之间保留点对应关系，从而可在生成新形状时保持训练数据的点对齐特性。

Result: 实验表明，该模型能有效生成形状逼真、具有点对应关系的海马体三维表示。与现有无序点云生成模型相比，生成结果在可比性和真实感上更优。作者进一步展示了该模型在有条件生成（如健康与AD病例）及反事实疾病进展预测等任务中的应用能力。

Conclusion: 该扩散模型首次实现了在点云生成中有效嵌入和维持点对应关系，为医学影像和疾病进程建模等领域的下游任务提供了更有用的生成工具。

Abstract: We propose a diffusion model designed to generate point-based shape
representations with correspondences. Traditional statistical shape models have
considered point correspondences extensively, but current deep learning methods
do not take them into account, focusing on unordered point clouds instead.
Current deep generative models for point clouds do not address generating
shapes with point correspondences between generated shapes. This work aims to
formulate a diffusion model that is capable of generating realistic point-based
shape representations, which preserve point correspondences that are present in
the training data. Using shape representation data with correspondences derived
from Open Access Series of Imaging Studies 3 (OASIS-3), we demonstrate that our
correspondence-preserving model effectively generates point-based hippocampal
shape representations that are highly realistic compared to existing methods.
We further demonstrate the applications of our generative model by downstream
tasks, such as conditional generation of healthy and AD subjects and predicting
morphological changes of disease progression by counterfactual generation.

</details>


### [23] [Policy to Assist Iteratively Local Segmentation: Optimising Modality and Location Selection for Prostate Cancer Localisation](https://arxiv.org/abs/2508.03953)
*Xiangcen Wu,Shaheer U. Saeed,Yipei Wang,Ester Bonmati Coll,Yipeng Hu*

Main category: cs.CV

TL;DR: 本文提出了一种推荐系统，用于辅助基于机器学习的前列腺癌分割，通过推荐最佳成像模态和图像区域，提升分割性能。利用策略网络动态选择合适的模态和区域进行局部分割，并在多参数MRI数据集上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 放射科医生在解读医学图像时会混合使用不同成像模态及不同图像区域的信息，然而现有分割模型很少考虑如何自动推荐最优化的查看方式，因此亟需一种智能推荐策略提升肿瘤分割的准确性和效率。

Method: 本文训练了一个策略网络，能够根据任务动态推荐最优成像模态和图像区域。训练过程中，预训练分割网络根据策略网络选择的模态和区域模拟医生检查流程，每次以局部分割结果为输入进行下一步推荐和分割，类似循环推理，直到所有肿瘤区域都被最优化定位。

Result: 在包含1325例前列腺癌患者多参数MRI的标注数据集上验证，所提方法在标注效率和分割准确性上均优于常规分割网络，特别是在复杂病理情况下效果更佳。同时，该智能体能自发学习出具有独特优化的检查策略，部分策略与现有医学指南（如PI-RADS）不同。

Conclusion: 该推荐系统不仅提升了分割模型在前列腺癌分割中的表现，也表明其策略有潜力作为辅助工具为放射科医生提供决策建议，有助于促进人机协作，优化临床流程。

Abstract: Radiologists often mix medical image reading strategies, including inspection
of individual modalities and local image regions, using information at
different locations from different images independently as well as
concurrently. In this paper, we propose a recommend system to assist machine
learning-based segmentation models, by suggesting appropriate image portions
along with the best modality, such that prostate cancer segmentation
performance can be maximised. Our approach trains a policy network that assists
tumor localisation, by recommending both the optimal imaging modality and the
specific sections of interest for review. During training, a pre-trained
segmentation network mimics radiologist inspection on individual or variable
combinations of these imaging modalities and their sections - selected by the
policy network. Taking the locally segmented regions as an input for the next
step, this dynamic decision making process iterates until all cancers are best
localised. We validate our method using a data set of 1325 labelled
multiparametric MRI images from prostate cancer patients, demonstrating its
potential to improve annotation efficiency and segmentation accuracy,
especially when challenging pathology is present. Experimental results show
that our approach can surpass standard segmentation networks. Perhaps more
interestingly, our trained agent independently developed its own optimal
strategy, which may or may not be consistent with current radiologist
guidelines such as PI-RADS. This observation also suggests a promising
interactive application, in which the proposed policy networks assist human
radiologists.

</details>


### [24] [Scaling Up Audio-Synchronized Visual Animation: An Efficient Training Paradigm](https://arxiv.org/abs/2508.03955)
*Lin Zhang,Zefan Cai,Yufan Zhou,Shentong Mo,Jinhong Lin,Cheng-En Wu,Yibing Wei,Yijing Zhang,Ruiyi Zhang,Wen Xiao,Tong Sun,Junjie Hu,Pedro Morgado*

Main category: cs.CV

TL;DR: 该论文提出了一种高效的双阶段训练方法，使音频同步的视觉动画能够扩展到开放领域的多类场景，并大幅减少了对高质量人工标注视频的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有音频驱动视觉动画的方法高度依赖手动整理的大量高质量视频，难以扩展到多样化的开放世界音视频类别。

Method: 采用两阶段训练流程：第一阶段利用自动筛选的大规模、含噪音视频进行预训练，让模型学习多样但不完美的音视频对齐；第二阶段仅在少量高质量人工标注视频上微调模型。此外，通过多特征条件和窗口注意力提升帧级音视频同步能力，并利用预训练的文本-视频生成器和音频编码器，仅引入少量可训练参数，提高训练效率。

Result: 实验中提出了包含48个类别的新基准集AVSync48，类别多样性为以往基准集的三倍。大量实验表明，该方法降低了超过10倍对人工整理视频的需求，同时模型在多类别和开放场景下依然具备较强泛化能力。

Conclusion: 该方法在提升视觉动画音频同步多样性与扩展性的同时，显著减少了人工标注数据的需求，为开放世界音视频合成提供了高效可扩展的解决方案。

Abstract: Recent advances in audio-synchronized visual animation enable control of
video content using audios from specific classes. However, existing methods
rely heavily on expensive manual curation of high-quality, class-specific
training videos, posing challenges to scaling up to diverse audio-video classes
in the open world. In this work, we propose an efficient two-stage training
paradigm to scale up audio-synchronized visual animation using abundant but
noisy videos. In stage one, we automatically curate large-scale videos for
pretraining, allowing the model to learn diverse but imperfect audio-video
alignments. In stage two, we finetune the model on manually curated
high-quality examples, but only at a small scale, significantly reducing the
required human effort. We further enhance synchronization by allowing each
frame to access rich audio context via multi-feature conditioning and window
attention. To efficiently train the model, we leverage pretrained text-to-video
generator and audio encoders, introducing only 1.9\% additional trainable
parameters to learn audio-conditioning capability without compromising the
generator's prior knowledge. For evaluation, we introduce AVSync48, a benchmark
with videos from 48 classes, which is 3$\times$ more diverse than previous
benchmarks. Extensive experiments show that our method significantly reduces
reliance on manual curation by over 10$\times$, while generalizing to many open
classes.

</details>


### [25] [RAVID: Retrieval-Augmented Visual Detection: A Knowledge-Driven Approach for AI-Generated Image Identification](https://arxiv.org/abs/2508.03967)
*Mamadou Keita,Wassim Hamidouche,Hessen Bougueffa Eutamene,Abdelmalik Taleb-Ahmed,Abdenour Hadid*

Main category: cs.CV

TL;DR: 本文提出了RAVID，这是首个基于视觉检索增强生成（RAG）框架的AI生成图像检测方法，实现了在多种生成模型下的高鲁棒性和准确率。


<details>
  <summary>Details</summary>
Motivation: 当前AI生成图像检测方法在泛化与鲁棒性方面存在不足，且多依赖低层次特征和特定模型，难以应对多样化和复杂的应用场景。现有RAG方法主要应用于文本领域，视觉知识利用不足，因此亟需新的检测方法提升对AI生成图像的识别效果。

Method: RAVID方法动态检索与查询图像相关的真实图片，将其与查询图像结合后送入视觉语言模型（如Qwen-VL或OpenFlamingo），利用经过细调和增强提示词训练的RAVID CLIP编码器提升特征表达能力，从而提高检测准确率和鲁棒性。

Result: 在UniversalFakeDetect基准测试（覆盖19种生成模型）上，RAVID平均准确率达到93.85%，在高斯模糊、JPEG压缩等图像退化条件下，准确率仍达80.27%，显著优于当前SOTA模型C2P-CLIP（63.44%），显示了更强的鲁棒性和广泛适用性。

Conclusion: RAVID利用视觉检索增强生成显著提升了AI生成图像检测的准确性与鲁棒性，对抗多种生成模型和图像退化条件表现优异，为该领域提供了新的有效解决方案。

Abstract: In this paper, we introduce RAVID, the first framework for AI-generated image
detection that leverages visual retrieval-augmented generation (RAG). While RAG
methods have shown promise in mitigating factual inaccuracies in foundation
models, they have primarily focused on text, leaving visual knowledge
underexplored. Meanwhile, existing detection methods, which struggle with
generalization and robustness, often rely on low-level artifacts and
model-specific features, limiting their adaptability. To address this, RAVID
dynamically retrieves relevant images to enhance detection. Our approach
utilizes a fine-tuned CLIP image encoder, RAVID CLIP, enhanced with
category-related prompts to improve representation learning. We further
integrate a vision-language model (VLM) to fuse retrieved images with the
query, enriching the input and improving accuracy. Given a query image, RAVID
generates an embedding using RAVID CLIP, retrieves the most relevant images
from a database, and combines these with the query image to form an enriched
input for a VLM (e.g., Qwen-VL or Openflamingo). Experiments on the
UniversalFakeDetect benchmark, which covers 19 generative models, show that
RAVID achieves state-of-the-art performance with an average accuracy of 93.85%.
RAVID also outperforms traditional methods in terms of robustness, maintaining
high accuracy even under image degradations such as Gaussian blur and JPEG
compression. Specifically, RAVID achieves an average accuracy of 80.27% under
degradation conditions, compared to 63.44% for the state-of-the-art model
C2P-CLIP, demonstrating consistent improvements in both Gaussian blur and JPEG
compression scenarios. The code will be publicly available upon acceptance.

</details>


### [26] [Investigating the Impact of Large-Scale Pre-training on Nutritional Content Estimation from 2D Images](https://arxiv.org/abs/2508.03996)
*Michele Andrade,Guilherme A. L. Silva,Valéria Santos,Gladston Moreira,Eduardo Luz*

Main category: cs.CV

TL;DR: 论文研究通过对比不同预训练数据集，在用2D图像估算食物营养成分的任务中的深度学习模型表现。结果发现，预训练数据集的选取对最终效果有重大影响，尤其是专有数据集表现优于公开数据集。


<details>
  <summary>Details</summary>
Motivation: 准确估算食物营养有助于健康和饮食管理，但仅凭2D图片难以实现，同时现有最佳方法依赖难以获取的专有大型数据集，影响领域复现和进一步研究。

Method: 对ViT模型进行基于ImageNet和COYO两个公开大规模数据集的预训练，并与基于专有JFT-300M数据集的SOTA方法，以及CNN基线（InceptionV2、ResNet-50）进行对比。在Nutrition5k数据集上，用MAE和MAE%指标评估它们的营养估算效果。

Result: JFT-300M专有数据集预训练的模型显著优于公开数据集。令人意外的是，COYO大规模预训练模型表现不如ImageNet，对最初假设构成反驳。

Conclusion: 预训练数据集的规模、领域相关性和质量对2D营养估算迁移学习效果有关键作用。研究为选择预训练数据集、提升可复现性和转移能力提供了实证依据。

Abstract: Estimating the nutritional content of food from images is a critical task
with significant implications for health and dietary monitoring. This is
challenging, especially when relying solely on 2D images, due to the
variability in food presentation, lighting, and the inherent difficulty in
inferring volume and mass without depth information. Furthermore,
reproducibility in this domain is hampered by the reliance of state-of-the-art
methods on proprietary datasets for large-scale pre-training. In this paper, we
investigate the impact of large-scale pre-training datasets on the performance
of deep learning models for nutritional estimation using only 2D images. We
fine-tune and evaluate Vision Transformer (ViT) models pre-trained on two large
public datasets, ImageNet and COYO, comparing their performance against
baseline CNN models (InceptionV2 and ResNet-50) and a state-of-the-art method
pre-trained on the proprietary JFT-300M dataset. We conduct extensive
experiments on the Nutrition5k dataset, a large-scale collection of real-world
food plates with high-precision nutritional annotations. Our evaluation using
Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAE%) reveals
that models pre-trained on JFT-300M significantly outperform those pre-trained
on public datasets. Unexpectedly, the model pre-trained on the massive COYO
dataset performs worse than the model pre-trained on ImageNet for this specific
regression task, refuting our initial hypothesis. Our analysis provides
quantitative evidence highlighting the critical role of pre-training dataset
characteristics, including scale, domain relevance, and curation quality, for
effective transfer learning in 2D nutritional estimation.

</details>


### [27] [JanusNet: Hierarchical Slice-Block Shuffle and Displacement for Semi-Supervised 3D Multi-Organ Segmentation](https://arxiv.org/abs/2508.03997)
*Zheng Zhang,Tianzhuzi Tan,Guanchun Yin,Bo Zhang,Xiuzhuang Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种名为JanusNet的数据增强框架，针对3D医学图像弱监督分割中的结构连续性问题，通过轴对齐切片打乱和置信度引导扰动两步，提升了分割性能，并在主流数据集上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 3D医学图像弱监督分割受限于训练样本稀缺和标注成本高，传统的卷积块打乱会破坏解剖结构连续性，导致小器官等难区域训练不足，因此需要一种更保留结构信息且关注难分区域的数据增强方法。

Method: 作者提出的JanusNet包括两步：第一步是Slice-Block Shuffle，即在体素体沿随机轴对齐打乱相同index切片块，保证扰动轴垂直平面的解剖连续性；第二步为Confidence-Guided Displacement，根据预测置信度选择和替换切片内块，增强对难分区域的训练信号。该框架为双阶段、轴对齐、可插拔方法，可兼容大部分师生式训练方案。

Result: JanusNet在Synapse和AMOS两个公开数据集上进行了实验，仅用20%的标注数据时，在Synapse数据集上DSC(Dice相似系数)提升4%，明显优于最新方法，在各种条件下都取得了领先的分割表现。

Conclusion: JanusNet 能够有效保留3D医学图像的全局结构连贯性，又有针对性地对难分区域做增强，是弱监督医学图像分割领域的有效插件式数据增强方法，在实际应用中具有广阔前景。

Abstract: Limited by the scarcity of training samples and annotations, weakly
supervised medical image segmentation often employs data augmentation to
increase data diversity, while randomly mixing volumetric blocks has
demonstrated strong performance. However, this approach disrupts the inherent
anatomical continuity of 3D medical images along orthogonal axes, leading to
severe structural inconsistencies and insufficient training in challenging
regions, such as small-sized organs, etc. To better comply with and utilize
human anatomical information, we propose JanusNet}, a data augmentation
framework for 3D medical data that globally models anatomical continuity while
locally focusing on hard-to-segment regions. Specifically, our Slice-Block
Shuffle step performs aligned shuffling of same-index slice blocks across
volumes along a random axis, while preserving the anatomical context on planes
perpendicular to the perturbation axis. Concurrently, the Confidence-Guided
Displacement step uses prediction reliability to replace blocks within each
slice, amplifying signals from difficult areas. This dual-stage, axis-aligned
framework is plug-and-play, requiring minimal code changes for most
teacher-student schemes. Extensive experiments on the Synapse and AMOS datasets
demonstrate that JanusNet significantly surpasses state-of-the-art methods,
achieving, for instance, a 4% DSC gain on the Synapse dataset with only 20%
labeled data.

</details>


### [28] [CAD-Judge: Toward Efficient Morphological Grading and Verification for Text-to-CAD Generation](https://arxiv.org/abs/2508.04002)
*Zheyuan Zhou,Jiayi Han,Liang Du,Naiyu Fang,Lemiao Qiu,Shuyou Zhang*

Main category: cs.CV

TL;DR: 本文针对文本生成可编辑CAD模型的系统提出了新的奖励与验证机制，提高了生成效率与准确性。采用Compiler-as-a-Judge和Compiler-as-a-Review模块，实现快速评分和自动修正。实验结果表明，该方法在效率和性能上均达到了最新水平。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-CAD系统在工业设计等领域有需求，但CAD模型渲染慢、对VLMs评审的依赖高、存在奖赏攻击等问题，影响了效率和可靠性，因此需要更快、更可验证的奖励和模型评估机制。

Method: 提出了CAD-Judge奖励系统，引入Compiler-as-a-Judge模块（CJM）用于生成过程中的快速、可验证奖励反馈；在测试阶段结合代理式CAD生成方法和Compiler-as-a-Review模块（CRM），对生成模型进行高效检验与自动微调。奖励机制设计考虑了前景理论以优化对齐。

Result: 在多个有挑战性的CAD数据集上进行了大量实验，所提出系统在效果和效率方面均超过了现有主流方法。

Conclusion: 文章提出了高效且可验证的Text-to-CAD生成奖励与检验系统，显著提升了通用CAD生成模型的性能和适用性，为实际CAD生成应用降低了门槛。

Abstract: Computer-Aided Design (CAD) models are widely used across industrial design,
simulation, and manufacturing processes. Text-to-CAD systems aim to generate
editable, general-purpose CAD models from textual descriptions, significantly
reducing the complexity and entry barrier associated with traditional CAD
workflows. However, rendering CAD models can be slow, and deploying VLMs to
review CAD models can be expensive and may introduce reward hacking that
degrades the systems. To address these challenges, we propose CAD-Judge, a
novel, verifiable reward system for efficient and effective CAD preference
grading and grammatical validation. We adopt the Compiler-as-a-Judge Module
(CJM) as a fast, direct reward signal, optimizing model alignment by maximizing
generative utility through prospect theory. To further improve the robustness
of Text-to-CAD in the testing phase, we introduce a simple yet effective
agentic CAD generation approach and adopt the Compiler-as-a-Review Module
(CRM), which efficiently verifies the generated CAD models, enabling the system
to refine them accordingly. Extensive experiments on challenging CAD datasets
demonstrate that our method achieves state-of-the-art performance while
maintaining superior efficiency.

</details>


### [29] [$\text{S}^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation](https://arxiv.org/abs/2508.04016)
*Weilun Feng,Haotong Qin,Chuanguang Yang,Xiangqi Li,Han Yang,Yuqi Li,Zhulin An,Libo Huang,Michele Magno,Yongjun Xu*

Main category: cs.CV

TL;DR: 本文提出了一种针对视频扩散模型（V-DMs）的后训练量化框架S2Q-VDiT，结合显著数据选择与稀疏Token蒸馏，实现近无损性能下的显著压缩与加速。


<details>
  <summary>Details</summary>
Motivation: 现有视频扩散变换器模型因参数量极大，计算资源消耗高。量化虽能缓解内存和推理压力，但视频序列过长造成量化校准数据噪声大，学习难度高，因此需要新方法解决这些问题。

Method: 1) 提出Hessian-aware显著数据选择，结合扩散和量化特性筛选高质量校准数据；2) 分析视频模型稀疏注意力结构，提出基于注意力分布的稀疏Token蒸馏，强调对输出更重要的Token提升量化效果。

Result: 在W4A6量化设定下，S2Q-VDiT实现了损失可忽略的量化表现，模型压缩3.9倍，推理加速1.3倍。

Conclusion: S2Q-VDiT通过高质量校准数据与注意力引导的Token蒸馏，有效解决了V-DMs量化的高方差和学习难题，在大幅缩减计算成本同时保持了模型性能。

Abstract: Diffusion transformers have emerged as the mainstream paradigm for video
generation models. However, the use of up to billions of parameters incurs
significant computational costs. Quantization offers a promising solution by
reducing memory usage and accelerating inference. Nonetheless, we observe that
the joint modeling of spatial and temporal information in video diffusion
models (V-DMs) leads to extremely long token sequences, which introduces high
calibration variance and learning challenges. To address these issues, we
propose \textbf{$\text{S}^2$Q-VDiT}, a post-training quantization framework for
V-DMs that leverages \textbf{S}alient data and \textbf{S}parse token
distillation. During the calibration phase, we identify that quantization
performance is highly sensitive to the choice of calibration data. To mitigate
this, we introduce \textit{Hessian-aware Salient Data Selection}, which
constructs high-quality calibration datasets by considering both diffusion and
quantization characteristics unique to V-DMs. To tackle the learning
challenges, we further analyze the sparse attention patterns inherent in V-DMs.
Based on this observation, we propose \textit{Attention-guided Sparse Token
Distillation}, which exploits token-wise attention distributions to emphasize
tokens that are more influential to the model's output. Under W4A6
quantization, $\text{S}^2$Q-VDiT achieves lossless performance while delivering
$3.9\times$ model compression and $1.3\times$ inference acceleration. Code will
be available at
\href{https://github.com/wlfeng0509/s2q-vdit}{https://github.com/wlfeng0509/s2q-vdit}.

</details>


### [30] [Can Large Multimodal Models Actively Recognize Faulty Inputs? A Systematic Evaluation Framework of Their Input Scrutiny Ability](https://arxiv.org/abs/2508.04017)
*Haiqi Yang,Jinzhe Li,Gengxu Li,Yi Chang,Yuan Wu*

Main category: cs.CV

TL;DR: 本文提出了ISEval评估框架，系统性测试了大规模多模态模型（LMMs）主动检测错误输入的能力，结果显示当前主流模型在无明显指引下难以自主识别语义错误，尤其是表层语用及某些条件类缺陷。


<details>
  <summary>Details</summary>
Motivation: 尽管LMMs在多模态任务上表现优异，但对于输入中的错误往往被动接受，缺乏主动甄别和质疑能力。此前相关问题主要聚焦于大型语言模型，尚无多模态领域系统性研究。

Method: 作者设计了ISEval框架，涵盖7类错误前提和3个量化指标，对10个领先的LMMs进行全面评测，对比其在不同类型错误输入上的识别表现及模态信任分布。

Result: 主流LMMs在无特定提示的情况下，大多难以有效识别文本中的错误前提；LMMs对逻辑谬误的识别优于对语言表层及部分条件性错误。不同模型对不同模态依赖不一，如Gemini 2.5 pro与Claude Sonnet 4较好融合视觉与文本信息，aya-vision-8b则在冲突场景下过度依赖文本。

Conclusion: 当前LMMs在主动验证输入有效性方面能力不足，需进一步提升其输入甄别能力。研究结果为未来模型鲁棒性增强提供了方向和参考。

Abstract: Large Multimodal Models (LMMs) have witnessed remarkable growth, showcasing
formidable capabilities in handling intricate multimodal tasks with exceptional
performance. Recent research has underscored the inclination of large language
models to passively accept defective inputs, often resulting in futile
reasoning on invalid prompts. However, the same critical question of whether
LMMs can actively detect and scrutinize erroneous inputs still remains
unexplored. To address this gap, we introduce the Input Scrutiny Ability
Evaluation Framework (ISEval), which encompasses seven categories of flawed
premises and three evaluation metrics. Our extensive evaluation of ten advanced
LMMs has identified key findings. Most models struggle to actively detect
flawed textual premises without guidance, which reflects a strong reliance on
explicit prompts for premise error identification. Error type affects
performance: models excel at identifying logical fallacies but struggle with
surface-level linguistic errors and certain conditional flaws. Modality trust
varies-Gemini 2.5 pro and Claude Sonnet 4 balance visual and textual info,
while aya-vision-8b over-rely on text in conflicts. These insights underscore
the urgent need to enhance LMMs' proactive verification of input validity and
shed novel insights into mitigating the problem. The code is available at
https://github.com/MLGroupJLU/LMM_ISEval.

</details>


### [31] [Prototype-Driven Structure Synergy Network for Remote Sensing Images Segmentation](https://arxiv.org/abs/2508.04022)
*Junyi Wang,Jinjiang Li,Guodong Fan,Yakun Ju,Xiang Fang,Alex C. Kot*

Main category: cs.CV

TL;DR: 本文针对遥感图像语义分割面临的“同类内差异大、类间相似度高”问题，提出了PDSSNet，通过原型驱动与结构协同机制提升分割完整性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 遥感图像中地物类别分割完整性对于后续精确分析至关重要，但由于同类内部差异大、不同类别特征相似，导致现有方法分割结果通常不完整，需要更加有效的类表示统一与特征区分技术。

Method: 作者提出PDSSNet，包含三个核心模块：1）自适应原型提取模块（APEM），从标注中提取无偏的类原型增强语义表征；2）语义-结构协同模块（SSCM），按照“先语义再结构”的分层融合方式，先构建整体语义理解再引入结构信息进行约束与细化，保障信息完整性；3）通道相似性调整模块（CSAM），动态调整聚焦类间可判别特征。

Result: 大量实验表明，PDSSNet在遥感语义分割任务上实现了优于当前主流方法的性能。

Conclusion: PDSSNet有效提升了分割完整性和精度，是遥感语义分割领域的先进方案，并公开源码以促进研究发展。

Abstract: In the semantic segmentation of remote sensing images, acquiring complete
ground objects is critical for achieving precise analysis. However, this task
is severely hindered by two major challenges: high intra-class variance and
high inter-class similarity. Traditional methods often yield incomplete
segmentation results due to their inability to effectively unify class
representations and distinguish between similar features. Even emerging
class-guided approaches are limited by coarse class prototype representations
and a neglect of target structural information.
  Therefore, this paper proposes a Prototype-Driven Structure Synergy Network
(PDSSNet). The design of this network is based on a core concept, a complete
ground object is jointly defined by its invariant class semantics and its
variant spatial structure. To implement this, we have designed three key
modules. First, the Adaptive Prototype Extraction Module (APEM) ensures
semantic accuracy from the source by encoding the ground truth to extract
unbiased class prototypes. Subsequently, the designed Semantic-Structure
Coordination Module (SSCM) follows a hierarchical semantics-first,
structure-second principle. This involves first establishing a global semantic
cognition, then leveraging structural information to constrain and refine the
semantic representation, thereby ensuring the integrity of class information.
Finally, the Channel Similarity Adjustment Module (CSAM) employs a dynamic
step-size adjustment mechanism to focus on discriminative features between
classes.
  Extensive experiments demonstrate that PDSSNet outperforms state-of-the-art
methods. The source code is available at
https://github.com/wangjunyi-1/PDSSNet.

</details>


### [32] [Dual Prompt Learning for Adapting Vision-Language Models to Downstream Image-Text Retrieval](https://arxiv.org/abs/2508.04028)
*Yifan Wang,Tao Wang,Chenwei Tang,Caiyang Yu,Zhengqing Zang,Mengmi Zhang,Shudong Huang,Jiancheng Lv*

Main category: cs.CV

TL;DR: 本文提出了一种名为DCAR的双提示学习框架，可在细粒度图文检索任务上实现更高性能，尤其是在新构建的FDRD数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 图文检索任务中，下游数据的细粒度属性区分和高度相似的子类别区分很难，导致已有视觉-语言大模型（如CLIP）迁移效果受限。

Method: 提出DCAR：结合类别和属性的联合重新加权机制，分别从语义和视觉层面动态调整提示向量。在属性层面，通过文本-图像互信息动态更新属性描述权重；在类别层面，通过多角度引入负样本并赋予类别匹配权重，提升子类别的判别能力。同时新构建了FDRD细粒度图文检索数据集。

Result: 在FDRD等数据集上，DCAR显著超过现有主流方法，实现了新的最优结果。

Conclusion: 联合类别和属性的提示学习策略能极大提升CLIP等大模型在细粒度下游图文检索任务上的性能，具有较好的泛化性和应用前景。

Abstract: Recently, prompt learning has demonstrated remarkable success in adapting
pre-trained Vision-Language Models (VLMs) to various downstream tasks such as
image classification. However, its application to the downstream Image-Text
Retrieval (ITR) task is more challenging. We find that the challenge lies in
discriminating both fine-grained attributes and similar subcategories of the
downstream data. To address this challenge, we propose Dual prompt Learning
with Joint Category-Attribute Reweighting (DCAR), a novel dual-prompt learning
framework to achieve precise image-text matching. The framework dynamically
adjusts prompt vectors from both semantic and visual dimensions to improve the
performance of CLIP on the downstream ITR task. Based on the prompt paradigm,
DCAR jointly optimizes attribute and class features to enhance fine-grained
representation learning. Specifically, (1) at the attribute level, it
dynamically updates the weights of attribute descriptions based on text-image
mutual information correlation; (2) at the category level, it introduces
negative samples from multiple perspectives with category-matching weighting to
learn subcategory distinctions. To validate our method, we construct the
Fine-class Described Retrieval Dataset (FDRD), which serves as a challenging
benchmark for ITR in downstream data domains. It covers over 1,500 downstream
fine categories and 230,000 image-caption pairs with detailed attribute
annotations. Extensive experiments on FDRD demonstrate that DCAR achieves
state-of-the-art performance over existing baselines.

</details>


### [33] [Radar-Based NLoS Pedestrian Localization for Darting-Out Scenarios Near Parked Vehicles with Camera-Assisted Point Cloud Interpretation](https://arxiv.org/abs/2508.04033)
*Hee-Yeun Kim,Byeonggyu Park,Byonghyok Choi,Hansang Cho,Byungkwan Kim,Soomok Lee,Mingu Jeon,Seung-Woo Seo,Seong-Woo Kim*

Main category: cs.CV

TL;DR: 本文提出了一种结合单目相机图像与2D毫米波雷达点云的新方法，有效解决在城市道路中由路边停车导致的视线盲区行人检测难题，并在现实环境下提升了危险预警能力。


<details>
  <summary>Details</summary>
Motivation: 城市道路边的停车车辆经常造成非视距（NLoS）盲区，这是导致行人突然出现、影响道路安全的重要因素。现有基于毫米波的NLoS探测方法通常依赖预设场景信息，难以适应临时变化的现实路况，因此亟需一种能动态适应现场变化的行人盲区探测方案。

Method: 方案利用单目摄像头进行路边停车目标分割与深度估计，初步获取障碍物空间信息，再结合2D毫米波雷达点云数据对障碍物位置与行人进行精确空间推断，实现对动态NLoS区域内突发行人的有效探测。

Result: 在真实城市道路环境中实验证明，该框架能够提升行人提前检测能力，有助于减少由停车带来的交通安全隐患。

Conclusion: 所提出的融合方法能克服传统毫米波NLoS探测方案对场景预设信息的依赖，提高系统在复杂城市环境中的实用性及行人安全保障能力。

Abstract: The presence of Non-Line-of-Sight (NLoS) blind spots resulting from roadside
parking in urban environments poses a significant challenge to road safety,
particularly due to the sudden emergence of pedestrians. mmWave technology
leverages diffraction and reflection to observe NLoS regions, and recent
studies have demonstrated its potential for detecting obscured objects.
However, existing approaches predominantly rely on predefined spatial
information or assume simple wall reflections, thereby limiting their
generalizability and practical applicability. A particular challenge arises in
scenarios where pedestrians suddenly appear from between parked vehicles, as
these parked vehicles act as temporary spatial obstructions. Furthermore, since
parked vehicles are dynamic and may relocate over time, spatial information
obtained from satellite maps or other predefined sources may not accurately
reflect real-time road conditions, leading to erroneous sensor interpretations.
To address this limitation, we propose an NLoS pedestrian localization
framework that integrates monocular camera image with 2D radar point cloud
(PCD) data. The proposed method initially detects parked vehicles through image
segmentation, estimates depth to infer approximate spatial characteristics, and
subsequently refines this information using 2D radar PCD to achieve precise
spatial inference. Experimental evaluations conducted in real-world urban road
environments demonstrate that the proposed approach enhances early pedestrian
detection and contributes to improved road safety. Supplementary materials are
available at https://hiyeun.github.io/NLoS/.

</details>


### [34] [CORE-ReID V2: Advancing the Domain Adaptation for Object Re-Identification with Optimized Training and Ensemble Fusion](https://arxiv.org/abs/2508.04036)
*Trinh Quoc Nguyen,Oky Dicky Ardiansyah Prima,Syahid Al Irfan,Hindriyanto Dwi Purnomo,Radius Tanone*

Main category: cs.CV

TL;DR: CORE-ReID V2提出了一种新的人/车辆无监督域自适应重识别方法，结合CycleGAN合成多样化数据以及先进的融合注意力机制，在多个基准数据集上取得了最优性能，支持轻量级网络结构，提升了特征表达和应用效率。


<details>
  <summary>Details</summary>
Motivation: 现有无监督域自适应（UDA）在物体重识别任务中存在跨域特征差异大、伪标签不准确以及特征表达不足等问题，限制了实际应用效果。提升UDA效果和适用范围成为学界关注点。

Method: 1. 预训练阶段使用CycleGAN生成多样化合成数据，缩小不同域之间的图像特征差异。2. 微调阶段引入由ECAB和SECAB组成的融合注意力机制，提升特征表达能力并优化目标域样本伪标签的判别性。3. 设计支持ResNet18/34等轻量级网络结构，提高模型效率和可扩展性。

Result: 实验在多个人员和车辆重识别UDA公开数据集上，CORE-ReID V2均超越了当前主流方法：取得更高的mAP、Top-1、Top-5和Top-10准确率，且在轻量化骨干网络下依然表现优异。

Conclusion: CORE-ReID V2显著推动了基于UDA的物体重识别技术发展，在保证高效性的同时提升了跨域泛化能力，并为后续相关探索提供了坚实基础。

Abstract: This study presents CORE-ReID V2, an enhanced framework building upon
CORE-ReID. The new framework extends its predecessor by addressing Unsupervised
Domain Adaptation (UDA) challenges in Person ReID and Vehicle ReID, with
further applicability to Object ReID. During pre-training, CycleGAN is employed
to synthesize diverse data, bridging image characteristic gaps across different
domains. In the fine-tuning, an advanced ensemble fusion mechanism, consisting
of the Efficient Channel Attention Block (ECAB) and the Simplified Efficient
Channel Attention Block (SECAB), enhances both local and global feature
representations while reducing ambiguity in pseudo-labels for target samples.
Experimental results on widely used UDA Person ReID and Vehicle ReID datasets
demonstrate that the proposed framework outperforms state-of-the-art methods,
achieving top performance in Mean Average Precision (mAP) and Rank-k Accuracy
(Top-1, Top-5, Top-10). Moreover, the framework supports lightweight backbones
such as ResNet18 and ResNet34, ensuring both scalability and efficiency. Our
work not only pushes the boundaries of UDA-based Object ReID but also provides
a solid foundation for further research and advancements in this domain. Our
codes and models are available at
https://github.com/TrinhQuocNguyen/CORE-ReID-V2.

</details>


### [35] [SPJFNet: Self-Mining Prior-Guided Joint Frequency Enhancement for Ultra-Efficient Dark Image Restoration](https://arxiv.org/abs/2508.04041)
*Tongshun Zhang,Pingling Liu,Zijian Zhang,Qiuzhan Zhou*

Main category: cs.CV

TL;DR: 现有的暗图像修复方法效率低下，主要由于依赖外部先验与多阶段复杂流程。本文提出SPJFNet，通过自生轻量先导和分频高效增强，大幅降低运算量，实现了最优性能和高效率。


<details>
  <summary>Details</summary>
Motivation: 目前暗图像增强算法存在计算开销大、依赖外部先验、操作冗余和频域处理无差别的问题，影响了推理速度和模型效率。作者希望解决这些效率瓶颈，提升暗图像修复的实用性和效果。

Method: 提出SPJFNet网络，核心包括两个创新：一是自生先导模块（SMGM），直接由网络内部生成先导信息，无需外部先验，提升速度与减少错误；二是通过频域分析，用小波和傅里叶联合分频，把多阶段流程压缩为单步处理，并用双分支架构（高频和低频分开处理）极大减低计算复杂性。

Result: 在多个基准测试上，SPJFNet性能优于现有最先进方法，且显著减少了模型参数量和计算开销，显示出在效率和效果上的双重提升。

Conclusion: SPJFNet通过自生轻量先导和分频高效增强，有效解决了暗图像修复的效率与性能瓶颈，为实际应用提供了高效优异的新方法。

Abstract: Current dark image restoration methods suffer from severe efficiency
bottlenecks, primarily stemming from: (1) computational burden and error
correction costs associated with reliance on external priors (manual or
cross-modal); (2) redundant operations in complex multi-stage enhancement
pipelines; and (3) indiscriminate processing across frequency components in
frequency-domain methods, leading to excessive global computational demands. To
address these challenges, we propose an Efficient Self-Mining Prior-Guided
Joint Frequency Enhancement Network (SPJFNet). Specifically, we first introduce
a Self-Mining Guidance Module (SMGM) that generates lightweight endogenous
guidance directly from the network, eliminating dependence on external priors
and thereby bypassing error correction overhead while improving inference
speed. Second, through meticulous analysis of different frequency domain
characteristics, we reconstruct and compress multi-level operation chains into
a single efficient operation via lossless wavelet decomposition and joint
Fourier-based advantageous frequency enhancement, significantly reducing
parameters. Building upon this foundation, we propose a Dual-Frequency Guidance
Framework (DFGF) that strategically deploys specialized high/low frequency
branches (wavelet-domain high-frequency enhancement and Fourier-domain
low-frequency restoration), decoupling frequency processing to substantially
reduce computational complexity. Rigorous evaluation across multiple benchmarks
demonstrates that SPJFNet not only surpasses state-of-the-art performance but
also achieves significant efficiency improvements, substantially reducing model
complexity and computational overhead. Code is available at
https://github.com/bywlzts/SPJFNet.

</details>


### [36] [VisualTrans: A Benchmark for Real-World Visual Transformation Reasoning](https://arxiv.org/abs/2508.04043)
*Yuheng Ji,Yipu Wang,Yuyang Liu,Xiaoshuai Hao,Yue Liu,Yuting Zhao,Huaihai Lyu,Xiaolong Zheng*

Main category: cs.CV

TL;DR: 该论文提出了VisualTrans，这是第一个针对真实世界人-物交互场景下视觉变换推理（VTR）的全面基准，涵盖12种多样任务和三类推理维度，有力促进了VTR领域的发展。


<details>
  <summary>Details</summary>
Motivation: 现有VTR基准存在仿真-现实鸿沟、任务复杂度有限及推理覆盖不全等问题，难以满足实际需求，因此亟需更贴合真实场景、任务丰富且推理全面的新基准。

Method: 作者设计了VisualTrans基准，包含12个人-物交互操作任务，从空间、过程和数量三个推理维度出发，细分出6类子任务，共472个高质量问答对。数据构建流程基于第一视角操作视频，结合自动化多模态元数据标注和结构化问句生成。最终数据集经人工校验保证准确性和可解释性。

Result: 多种先进视觉-语言模型在静态空间任务上表现良好，但在动态多步推理（如中间状态识别和变换序列规划）上表现不佳，暴露了当前模型在时序建模和因果推理方面的明显弱点。

Conclusion: VisualTrans有效填补了VTR领域的基准空白，系统性揭示了现有视觉-语言模型的能力瓶颈，并为未来提升模型的时序与因果推理能力指明了研究方向。

Abstract: Visual transformation reasoning (VTR) is a vital cognitive capability that
empowers intelligent agents to understand dynamic scenes, model causal
relationships, and predict future states, and thereby guiding actions and
laying the foundation for advanced intelligent systems. However, existing
benchmarks suffer from a sim-to-real gap, limited task complexity, and
incomplete reasoning coverage, limiting their practical use in real-world
scenarios. To address these limitations, we introduce VisualTrans, the first
comprehensive benchmark specifically designed for VTR in real-world
human-object interaction scenarios. VisualTrans encompasses 12 semantically
diverse manipulation tasks and systematically evaluates three essential
reasoning dimensions - spatial, procedural, and quantitative - through 6
well-defined subtask types. The benchmark features 472 high-quality
question-answer pairs in various formats, including multiple-choice, open-ended
counting, and target enumeration. We introduce a scalable data construction
pipeline built upon first-person manipulation videos, which integrates task
selection, image pair extraction, automated metadata annotation with large
multimodal models, and structured question generation. Human verification
ensures the final benchmark is both high-quality and interpretable. Evaluations
of various state-of-the-art vision-language models show strong performance in
static spatial tasks. However, they reveal notable shortcomings in dynamic,
multi-step reasoning scenarios, particularly in areas like intermediate state
recognition and transformation sequence planning. These findings highlight
fundamental weaknesses in temporal modeling and causal reasoning, providing
clear directions for future research aimed at developing more capable and
generalizable VTR systems. The dataset and code are available at
https://github.com/WangYipu2002/VisualTrans.

</details>


### [37] [Iterative pseudo-labeling based adaptive copy-paste supervision for semi-supervised tumor segmentation](https://arxiv.org/abs/2508.04044)
*Qiangguo Jin,Hui Cui,Junbo Wang,Changming Sun,Yimiao He,Ping Xuan,Linlin Wang,Cong Cong,Leyi Wei,Ran Su*

Main category: cs.CV

TL;DR: 本文提出了IPA-CP方法，能更有效地利用少量标注和大量未标注数据对CT扫描肿瘤进行分割。


<details>
  <summary>Details</summary>
Motivation: 当前半监督学习方法虽然在医学影像分割中取得进展，但多聚焦于大器官，对多发/体积小的肿瘤分割效果较差。同时，数据增强在标注与未标注数据上的潜力未被充分利用。

Method: 提出一种基于迭代伪标签和自适应copy-paste监督(IP-CP)的新方法，结合不确定性自适应增强机制和迭代伪标签生成，提升未标注样本伪标签的质量。

Result: 在自有数据和公开数据集上，IPA-CP明显超越现有最先进半监督方法，消融实验也验证了各技术设计的有效性。

Conclusion: IPA-CP能显著提升多发或体积小肿瘤的医学影像分割表现，对半监督医疗影像分割具有重要意义。

Abstract: Semi-supervised learning (SSL) has attracted considerable attention in
medical image processing. The latest SSL methods use a combination of
consistency regularization and pseudo-labeling to achieve remarkable success.
However, most existing SSL studies focus on segmenting large organs, neglecting
the challenging scenarios where there are numerous tumors or tumors of small
volume. Furthermore, the extensive capabilities of data augmentation
strategies, particularly in the context of both labeled and unlabeled data,
have yet to be thoroughly investigated. To tackle these challenges, we
introduce a straightforward yet effective approach, termed iterative
pseudo-labeling based adaptive copy-paste supervision (IPA-CP), for tumor
segmentation in CT scans. IPA-CP incorporates a two-way uncertainty based
adaptive augmentation mechanism, aiming to inject tumor uncertainties present
in the mean teacher architecture into adaptive augmentation. Additionally,
IPA-CP employs an iterative pseudo-label transition strategy to generate more
robust and informative pseudo labels for the unlabeled samples. Extensive
experiments on both in-house and public datasets show that our framework
outperforms state-of-the-art SSL methods in medical image segmentation.
Ablation study results demonstrate the effectiveness of our technical
contributions.

</details>


### [38] [Motion is the Choreographer: Learning Latent Pose Dynamics for Seamless Sign Language Generation](https://arxiv.org/abs/2508.04049)
*Jiayi He,Xu Wang,Shengeng Tang,Yaxiong Wang,Lechao Cheng,Dan Guo*

Main category: cs.CV

TL;DR: 本文提出了一种新范式，使手语视频生成能够在低数据需求和强泛化能力下实现真实流畅的动作与身份个性化。


<details>
  <summary>Details</summary>
Motivation: 现有手语视频生成方法往往需要大量个体化数据，且泛化能力差，难以满足实际需求。

Method: 提出两阶段合成框架：首先构建签名者无关的多模态动作词典，每个手语词条用与身份无关的姿态、手势、3D网格序列表示，仅需单次录制；接着通过离散到连续的动作合成，将手语词条序列转为连贯的动作轨迹，再通过身份感知神经渲染生成任意签名者的逼真视频。

Result: 实验表明，将动作语义与身份解耦不仅可行且具有优势，提升了合成质量，实现了前所未有的签名者个性化能力。

Conclusion: 动作和身份的有效解耦为手语视频生成开辟新方向，显著降低了数据需求，并提高了系统的灵活性与可用性。

Abstract: Sign language video generation requires producing natural signing motions
with realistic appearances under precise semantic control, yet faces two
critical challenges: excessive signer-specific data requirements and poor
generalization. We propose a new paradigm for sign language video generation
that decouples motion semantics from signer identity through a two-phase
synthesis framework. First, we construct a signer-independent multimodal motion
lexicon, where each gloss is stored as identity-agnostic pose, gesture, and 3D
mesh sequences, requiring only one recording per sign. This compact
representation enables our second key innovation: a discrete-to-continuous
motion synthesis stage that transforms retrieved gloss sequences into
temporally coherent motion trajectories, followed by identity-aware neural
rendering to produce photorealistic videos of arbitrary signers. Unlike prior
work constrained by signer-specific datasets, our method treats motion as a
first-class citizen: the learned latent pose dynamics serve as a portable
"choreography layer" that can be visually realized through different human
appearances. Extensive experiments demonstrate that disentangling motion from
identity is not just viable but advantageous - enabling both high-quality
synthesis and unprecedented flexibility in signer personalization.

</details>


### [39] [DOMR: Establishing Cross-View Segmentation via Dense Object Matching](https://arxiv.org/abs/2508.04050)
*Jitong Liao,Yulu Gao,Shaofei Huang,Jialin Gao,Jie Lei,Ronghua Liang,Si Liu*

Main category: cs.CV

TL;DR: 本文提出了一种称为DOMR的框架，实现了第一人称（egocentric）与第三人称（exocentric）视角下物体的高效对应匹配，并在主流数据集上取得了显著领先的性能。


<details>
  <summary>Details</summary>
Motivation: 跨视角物体对应对于视觉理解任务至关重要，但由于不同视角下物体表现差异较大，这一任务极具挑战。现有方法不足以充分建模物体间的语义和空间关系，因此亟需更有效的解决方案。

Method: 提出了Dense Object Matching and Refinement（DOMR）框架，其核心为Dense Object Matcher（DOM）模块。DOM不仅关注单个物体与全图特征的匹配，还联合建模多个物体间的位置和语义关系。方法包含提议生成模块和密集匹配模块，联合编码视觉、空间和语义线索，并通过掩模细化头提升预测掩模的完整性和准确性。

Result: 在Ego-Exo4D基准上，DOMR框架在Ego到Exo和Exo到Ego两项任务上分别取得49.7%和55.2%的平均IoU，相比以往方法提升了5.8%和4.3%。

Conclusion: DOMR框架能够有效提升跨视角物体对应的准确性，在现有公开基准上取得了最优性能，验证了所提方法的有效性。

Abstract: Cross-view object correspondence involves matching objects between egocentric
(first-person) and exocentric (third-person) views. It is a critical yet
challenging task for visual understanding. In this work, we propose the Dense
Object Matching and Refinement (DOMR) framework to establish dense object
correspondences across views. The framework centers around the Dense Object
Matcher (DOM) module, which jointly models multiple objects. Unlike methods
that directly match individual object masks to image features, DOM leverages
both positional and semantic relationships among objects to find
correspondences. DOM integrates a proposal generation module with a dense
matching module that jointly encodes visual, spatial, and semantic cues,
explicitly constructing inter-object relationships to achieve dense matching
among objects. Furthermore, we combine DOM with a mask refinement head designed
to improve the completeness and accuracy of the predicted masks, forming the
complete DOMR framework. Extensive evaluations on the Ego-Exo4D benchmark
demonstrate that our approach achieves state-of-the-art performance with a mean
IoU of 49.7% on Ego$\to$Exo and 55.2% on Exo$\to$Ego. These results outperform
those of previous methods by 5.8% and 4.3%, respectively, validating the
effectiveness of our integrated approach for cross-view understanding.

</details>


### [40] [Towards Globally Predictable k-Space Interpolation: A White-box Transformer Approach](https://arxiv.org/abs/2508.04051)
*Chen Luo,Qiyu Jin,Taofeng Xie,Xuemei Wang,Huayu Wang,Congcong Liu,Liming Tang,Guoqing Chen,Zhuo-Xu Cui,Dong Liang*

Main category: cs.CV

TL;DR: 本文提出了一种用于k-space插值的新型白盒Transformer框架GPI-WT，以提升MRI成像的速度和数据插值质量，其性能和可解释性均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的k-space插值方法主要利用局部信息，难以充分挖掘全局结构，且深度学习尤其Transformer方法虽然强大却缺乏可解释性，这对医疗影像领域的数据可靠性造成担忧。

Method: 作者提出基于全局可预测插值（GPI）的低秩k-space结构模型（SLR），用可学习的全局湮灭滤波器和由SLR子梯度自然诱导的学习型注意力机制，在线性优化算法基础上展开为级联网络，实现MRI加速的白盒Transformer。

Result: 实验结果显示，GPI-WT在k-space插值精度上显著优于当前主流方法，并且提升了模型的可解释性。

Conclusion: GPI-WT结合物理模型与深度学习优势，实现了高效、可解释的MRI k-space插值技术，为快速医疗成像提供了新方案。

Abstract: Interpolating missing data in k-space is essential for accelerating imaging.
However, existing methods, including convolutional neural network-based deep
learning, primarily exploit local predictability while overlooking the inherent
global dependencies in k-space. Recently, Transformers have demonstrated
remarkable success in natural language processing and image analysis due to
their ability to capture long-range dependencies. This inspires the use of
Transformers for k-space interpolation to better exploit its global structure.
However, their lack of interpretability raises concerns regarding the
reliability of interpolated data. To address this limitation, we propose
GPI-WT, a white-box Transformer framework based on Globally Predictable
Interpolation (GPI) for k-space. Specifically, we formulate GPI from the
perspective of annihilation as a novel k-space structured low-rank (SLR) model.
The global annihilation filters in the SLR model are treated as learnable
parameters, and the subgradients of the SLR model naturally induce a learnable
attention mechanism. By unfolding the subgradient-based optimization algorithm
of SLR into a cascaded network, we construct the first white-box Transformer
specifically designed for accelerated MRI. Experimental results demonstrate
that the proposed method significantly outperforms state-of-the-art approaches
in k-space interpolation accuracy while providing superior interpretability.

</details>


### [41] [Uni-DocDiff: A Unified Document Restoration Model Based on Diffusion](https://arxiv.org/abs/2508.04055)
*Fangmin Zhao,Weichao Zeng,Zhenhang Li,Dongbao Yang,Binbin Li,Xiaojun Bi,Yu Zhou*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型的统一文档修复方法Uni-DocDiff，能高效解决多种文档损坏问题，具备极强的任务扩展性，并在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有文档修复方法大都针对单一任务独立建模，导致系统复杂且不利于扩展；而试图统一多任务的方法则因手工设计提示和预处理繁琐，难以扩展且未充分利用任务间的协同效应。

Method: 提出了Uni-DocDiff，一种基于扩散模型的统一文档修复方法，通过可学习的任务提示增强扩展性。引入Prior Pool机制融合局部高频与全局低频特征，并设计Prior Fusion Module (PFM)以自适应为不同任务选择相关先验信息。

Result: 大量实验验证Uni-DocDiff在多种文档修复任务中性能接近甚至超过了专用专家模型，同时具备强大的任务扩展能力，能平滑适应新任务。

Conclusion: Uni-DocDiff实现了文档修复任务的统一与高可扩展性，大幅简化系统复杂度，并有效提升多任务修复性能，表现出优越的适应性和推广潜力。

Abstract: Removing various degradations from damaged documents greatly benefits
digitization, downstream document analysis, and readability. Previous methods
often treat each restoration task independently with dedicated models, leading
to a cumbersome and highly complex document processing system. Although recent
studies attempt to unify multiple tasks, they often suffer from limited
scalability due to handcrafted prompts and heavy preprocessing, and fail to
fully exploit inter-task synergy within a shared architecture. To address the
aforementioned challenges, we propose Uni-DocDiff, a Unified and highly
scalable Document restoration model based on Diffusion. Uni-DocDiff develops a
learnable task prompt design, ensuring exceptional scalability across diverse
tasks. To further enhance its multi-task capabilities and address potential
task interference, we devise a novel \textbf{Prior \textbf{P}ool}, a simple yet
comprehensive mechanism that combines both local high-frequency features and
global low-frequency features. Additionally, we design the \textbf{Prior
\textbf{F}usion \textbf{M}odule (PFM)}, which enables the model to adaptively
select the most relevant prior information for each specific task. Extensive
experiments show that the versatile Uni-DocDiff achieves performance comparable
or even superior performance compared with task-specific expert models, and
simultaneously holds the task scalability for seamless adaptation to new tasks.

</details>


### [42] [TCSAFormer: Efficient Vision Transformer with Token Compression and Sparse Attention for Medical Image Segmentation](https://arxiv.org/abs/2508.04058)
*Zunhui Xia,Hongxing Li,Libin Lan*

Main category: cs.CV

TL;DR: 本文提出了一种高效的医学图像分割网络TCSAFormer，通过引入压缩注意力机制（CA）和双分支前馈网络（DBFFN）模块，能更好地在降低计算量的同时提高分割精度，实验结果优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 基于Transformer的医学图像分割方法虽然能捕捉长距离依赖，但面临计算复杂度高和局部多尺度特征捕获能力不足的问题。这限制了其在实际应用中的效率和分割精度。

Method: TCSAFormer包含两个核心模块：（1）压缩注意力模块（CA），结合token压缩与像素级稀疏注意力，通过修剪无关token及合并冗余token减少计算量，并提升全局相关性建模能力；（2）双分支前馈网络（DBFFN）替代传统FFN，更有效地捕捉局部上下文和多尺度特征。

Result: 在ISIC-2018、CVC-ClinicDB和Synapse三个公开医学图像分割数据集上进行大量实验证明，TCSAFormer在分割精度和运算效率上均优于当前主流方法，实现了效率与精度的最佳折中。

Conclusion: TCSAFormer通过创新的模块设计，有效解决了基于Transformer方法在医学图像分割中计算开销大和特征表达能力有限的问题，能在保持低计算量的同时提升分割性能，在多个数据集上取得SOTA结果。

Abstract: In recent years, transformer-based methods have achieved remarkable progress
in medical image segmentation due to their superior ability to capture
long-range dependencies. However, these methods typically suffer from two major
limitations. First, their computational complexity scales quadratically with
the input sequences. Second, the feed-forward network (FFN) modules in vanilla
Transformers typically rely on fully connected layers, which limits models'
ability to capture local contextual information and multiscale features
critical for precise semantic segmentation. To address these issues, we propose
an efficient medical image segmentation network, named TCSAFormer. The proposed
TCSAFormer adopts two key ideas. First, it incorporates a Compressed Attention
(CA) module, which combines token compression and pixel-level sparse attention
to dynamically focus on the most relevant key-value pairs for each query. This
is achieved by pruning globally irrelevant tokens and merging redundant ones,
significantly reducing computational complexity while enhancing the model's
ability to capture relationships between tokens. Second, it introduces a
Dual-Branch Feed-Forward Network (DBFFN) module as a replacement for the
standard FFN to capture local contextual features and multiscale information,
thereby strengthening the model's feature representation capability. We conduct
extensive experiments on three publicly available medical image segmentation
datasets: ISIC-2018, CVC-ClinicDB, and Synapse, to evaluate the segmentation
performance of TCSAFormer. Experimental results demonstrate that TCSAFormer
achieves superior performance compared to existing state-of-the-art (SOTA)
methods, while maintaining lower computational overhead, thus achieving an
optimal trade-off between efficiency and accuracy.

</details>


### [43] [Beyond the Visible: Benchmarking Occlusion Perception in Multimodal Large Language Models](https://arxiv.org/abs/2508.04059)
*Zhaochen Liu,Kaiwen Gao,Shuyi Liang,Bin Xiao,Limeng Qiao,Lin Ma,Tingting Jiang*

Main category: cs.CV

TL;DR: 本文提出了O-Bench，这是首个专为遮挡感知设计的视觉问答基准，通过构建和标注图像与问题，全面评估多模态大模型的遮挡理解能力，并揭示其与人类之间的显著差距及具体失败模式。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型在多种任务上表现出色，但其在遮挡感知方面的能力尚未被充分研究。为系统分析并推动该方向发展，需要一个专门的评测基准。

Method: 作者在SA-1B数据集基础上，采用新颖的分层合成方法生成1365幅含遮挡情景且语义连贯的图像，并为其标注4588对问题-答案，涉及五项专为遮挡感知设计的任务。通过半自动化流程确保标注可靠。随后，评估了22种代表性多模态大模型，并与人类表现做对比和误差分析。

Result: 实验显示，目前的多模态大语言模型在遮挡感知任务上的表现与人类存在显著差距，且模型扩大规模或思维链推理策略难以弥合这一差距。发现三种典型失败模式：过于保守的倾向、形态整合能力脆弱、定量任务困难。

Conclusion: O-Bench为遮挡感知领域提供了关键的评测工具，有助于推动多模态模型向更高水平的视觉智能发展。未来，基准及相关资源会开放，以促进研究社区进步。

Abstract: Occlusion perception, a critical foundation for human-level spatial
understanding, embodies the challenge of integrating visual recognition and
reasoning. Though multimodal large language models (MLLMs) have demonstrated
remarkable capabilities, their performance on occlusion perception remains
under-explored. To address this gap, we introduce O-Bench, the first visual
question answering (VQA) benchmark specifically designed for occlusion
perception. Based on SA-1B, we construct 1,365 images featuring semantically
coherent occlusion scenarios through a novel layered synthesis approach. Upon
this foundation, we annotate 4,588 question-answer pairs in total across five
tailored tasks, employing a reliable, semi-automatic workflow. Our extensive
evaluation of 22 representative MLLMs against the human baseline reveals a
significant performance gap between current MLLMs and humans, which, we find,
cannot be sufficiently bridged by model scaling or thinking process. We further
identify three typical failure patterns, including an overly conservative bias,
a fragile gestalt prediction, and a struggle with quantitative tasks. We
believe O-Bench can not only provide a vital evaluation tool for occlusion
perception, but also inspire the development of MLLMs for better visual
intelligence. Our benchmark will be made publicly available upon paper
publication.

</details>


### [44] [TNet: Terrace Convolutional Decoder Network for Remote Sensing Image Semantic Segmentation](https://arxiv.org/abs/2508.04061)
*Chengqian Dai,Yonghong Guo,Hongzhao Xiang,Yigui Luo*

Main category: cs.CV

TL;DR: 本论文提出了TNet（一种梯田式卷积解码网络），利用卷积和加法在解码阶段跨尺度融合多分辨率特征，仅用ResNet-18编码器即可在遥感分割任务上实现高效且优异表现。


<details>
  <summary>Details</summary>
Motivation: 当前主流遥感分割网络（比如UNet及其变体）虽然引入Transformer或Mamba等模块以提升特征交互能力，但多局限于单一尺度，未充分考虑不同分辨率（多尺度）下全局上下文的融合，对提升分割效果存在瓶颈。

Method: 作者设计了TNet（Terrace Convolutional Decoder Network），在解码阶段逐步将低分辨率（含丰富全局信息）特征以卷积与加法操作融合到高分辨率（含丰富局部细节）特征中，实现跨尺度空间感知卷积核自适应地融合全局与局部信息。具体实现以ResNet-18为编码器，即TNet-R。

Result: TNet-R在ISPRS Vaihingen、ISPRS Potsdam和LoveDA三个遥感分割基准数据集上mIoU分别达到85.35%、87.05%和52.19%，兼具较高分割精度和计算效率。

Conclusion: TNet结构能够无需复杂的注意力或Transformer模块，仅靠简单的卷积和加法，实现高效且精准的多尺度特征融合，适用于高效遥感图像分割任务，具有良好的应用前景。

Abstract: In remote sensing, most segmentation networks adopt the UNet architecture,
often incorporating modules such as Transformers or Mamba to enhance
global-local feature interactions within decoder stages. However, these
enhancements typically focus on intra-scale relationships and neglect the
global contextual dependencies across multiple resolutions. To address this
limitation, we introduce the Terrace Convolutional Decoder Network (TNet), a
simple yet effective architecture that leverages only convolution and addition
operations to progressively integrate low-resolution features (rich in global
context) into higher-resolution features (rich in local details) across
decoding stages. This progressive fusion enables the model to learn
spatially-aware convolutional kernels that naturally blend global and local
information in a stage-wise manner. We implement TNet with a ResNet-18 encoder
(TNet-R) and evaluate it on three benchmark datasets. TNet-R achieves
competitive performance with a mean Intersection-over-Union (mIoU) of 85.35\%
on ISPRS Vaihingen, 87.05\% on ISPRS Potsdam, and 52.19\% on LoveDA, while
maintaining high computational efficiency. Code is publicly available.

</details>


### [45] [Bridging Diffusion Models and 3D Representations: A 3D Consistent Super-Resolution Framework](https://arxiv.org/abs/2508.04090)
*Yi-Ting Chen,Ting-Hsuan Liao,Pengsheng Guo,Alexander Schwing,Jia-Bin Huang*

Main category: cs.CV

TL;DR: 本文提出了一种基于3D高斯撒点的新型三维超分辨率方法3DSR，利用现有的基于扩散模型的2D超分辨率方法，并实现了不同视角间的三维一致性，显著提升了三维重建的视觉质量。


<details>
  <summary>Details</summary>
Motivation: 现有的图像上采样或视频超分辨方法要么忽略了3D一致性，要么仅隐式地涉及3D一致性，导致多视角三维重建时结构不连贯。因此，迫切需要一种能够在提升分辨率的同时保证三维一致性的方法。

Method: 3DSR采用基于3D高斯撒点的场景表达方式，并引入主流2D基于扩散模型的超分辨率，对多视角二维图像进行超分，同时通过3D表达方式在不同视角之间显式保证三维一致性。无需额外微调即可提升三维重建分辨率和空间连贯性。

Result: 在MipNeRF360和LLFF等数据集上实验，3DSR能生成视觉效果优异且结构上连贯的高分辨三维重建结果。

Conclusion: 3DSR方法能够有效提升多视角三维重建分辨率，并保持空间结构一致性，无需额外微调，实现了视觉质量和三维一致性的提升。

Abstract: We propose 3D Super Resolution (3DSR), a novel 3D Gaussian-splatting-based
super-resolution framework that leverages off-the-shelf diffusion-based 2D
super-resolution models. 3DSR encourages 3D consistency across views via the
use of an explicit 3D Gaussian-splatting-based scene representation. This makes
the proposed 3DSR different from prior work, such as image upsampling or the
use of video super-resolution, which either don't consider 3D consistency or
aim to incorporate 3D consistency implicitly. Notably, our method enhances
visual quality without additional fine-tuning, ensuring spatial coherence
within the reconstructed scene. We evaluate 3DSR on MipNeRF360 and LLFF data,
demonstrating that it produces high-resolution results that are visually
compelling, while maintaining structural consistency in 3D reconstructions.
Code will be released.

</details>


### [46] [DET-GS: Depth- and Edge-Aware Regularization for High-Fidelity 3D Gaussian Splatting](https://arxiv.org/abs/2508.04099)
*Zexu Huang,Min Xu,Stuart Perry*

Main category: cs.CV

TL;DR: 本文提出了DET-GS，一种用于3D高斯泼溅的统一深度与边缘感知正则化框架，显著提升了稀疏视角下的新视图合成的质量。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅在稀疏视角条件下几何重建精度有限，常用的方法不善于捕获细粒度结构，对深度噪声敏感，同时传统平滑方法会损失重要的结构边界和纹理。

Method: 提出DET-GS框架，包括多层次几何深度监督、基于Canny边缘的语义掩码引导的边缘感知深度正则化、以及RGB引导的边缘保持全变分损失，从而兼顾结构一致性和高频细节保留。

Result: DET-GS在多个稀疏视角的新视图合成基准上表现优异，在几何精度和视觉保真度上均超越了现有SOTA方法。

Conclusion: DET-GS方法能显著提升稀疏视角3D高斯泼溅重建的结构保真与视觉效果，对于提升3D重建与合成具有重要意义。

Abstract: 3D Gaussian Splatting (3DGS) represents a significant advancement in the
field of efficient and high-fidelity novel view synthesis. Despite recent
progress, achieving accurate geometric reconstruction under sparse-view
conditions remains a fundamental challenge. Existing methods often rely on
non-local depth regularization, which fails to capture fine-grained structures
and is highly sensitive to depth estimation noise. Furthermore, traditional
smoothing methods neglect semantic boundaries and indiscriminately degrade
essential edges and textures, consequently limiting the overall quality of
reconstruction. In this work, we propose DET-GS, a unified depth and edge-aware
regularization framework for 3D Gaussian Splatting. DET-GS introduces a
hierarchical geometric depth supervision framework that adaptively enforces
multi-level geometric consistency, significantly enhancing structural fidelity
and robustness against depth estimation noise. To preserve scene boundaries, we
design an edge-aware depth regularization guided by semantic masks derived from
Canny edge detection. Furthermore, we introduce an RGB-guided edge-preserving
Total Variation loss that selectively smooths homogeneous regions while
rigorously retaining high-frequency details and textures. Extensive experiments
demonstrate that DET-GS achieves substantial improvements in both geometric
accuracy and visual fidelity, outperforming state-of-the-art (SOTA) methods on
sparse-view novel view synthesis benchmarks.

</details>


### [47] [NEARL-CLIP: Interacted Query Adaptation with Orthogonal Regularization for Medical Vision-Language Understanding](https://arxiv.org/abs/2508.04101)
*Zelin Peng,Yichen Zhao,Yu Huang,Piao Yang,Feilong Tang,Zhengqin Xu,Xiaokang Yang,Wei Shen*

Main category: cs.CV

TL;DR: NEARL-CLIP提出了一种新颖的多模态交互框架，通过促进医学图像和文本的深度协同，有效提升了医学图像分析的表现。该方法高效且参数量低。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分析受限于数据集标注少，直接迁移通用视觉-语言模型（如CLIP）面临显著领域差异，现有方法仅提升单模态或存在模态对齐问题，无法充分发挥多模态模型潜力。

Method: 提出NEARL-CLIP框架，核心包括：（1）USEformer动态生成跨模态查询，实现多模态间知识互补和增强；（2）OCA通过正交分解，分离新知识和增量知识，减少增量信息干扰，进一步增强多模态信息的有效交互。

Result: 该方法以参数高效的方式（仅增加1.46M参数）实现，实验结果显示其在医学图像分析任务中取得了优异表现。

Conclusion: NEARL-CLIP能够有效弥合通用视觉-语言模型在医学图像分析中的领域差异，以极低参数开销促进多模态知识交互和增强，具有很强的实际应用价值。

Abstract: Computer-aided medical image analysis is crucial for disease diagnosis and
treatment planning, yet limited annotated datasets restrict medical-specific
model development. While vision-language models (VLMs) like CLIP offer strong
generalization capabilities, their direct application to medical imaging
analysis is impeded by a significant domain gap. Existing approaches to bridge
this gap, including prompt learning and one-way modality interaction
techniques, typically focus on introducing domain knowledge to a single
modality. Although this may offer performance gains, it often causes modality
misalignment, thereby failing to unlock the full potential of VLMs. In this
paper, we propose \textbf{NEARL-CLIP} (i\underline{N}teracted qu\underline{E}ry
\underline{A}daptation with o\underline{R}thogona\underline{L} Regularization),
a novel cross-modality interaction VLM-based framework that contains two
contributions: (1) Unified Synergy Embedding Transformer (USEformer), which
dynamically generates cross-modality queries to promote interaction between
modalities, thus fostering the mutual enrichment and enhancement of multi-modal
medical domain knowledge; (2) Orthogonal Cross-Attention Adapter (OCA). OCA
introduces an orthogonality technique to decouple the new knowledge from
USEformer into two distinct components: the truly novel information and the
incremental knowledge. By isolating the learning process from the interference
of incremental knowledge, OCA enables a more focused acquisition of new
information, thereby further facilitating modality interaction and unleashing
the capability of VLMs. Notably, NEARL-CLIP achieves these two contributions in
a parameter-efficient style, which only introduces \textbf{1.46M} learnable
parameters.

</details>


### [48] [AR as an Evaluation Playground: Bridging Metrics and Visual Perception of Computer Vision Models](https://arxiv.org/abs/2508.04102)
*Ashkan Ganj,Yiqin Zhao,Tian Guo*

Main category: cs.CV

TL;DR: 本文提出了ARCADE平台，利用增强现实（AR）技术简化和提升计算机视觉模型的人类感知评测。通过AR丰富的互动性和上下文，实现灵活、高效的实验流程，提升人群评测的可操作性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的人类感知评测方案操作复杂、耗时、难以推广，阻碍了计算机视觉模型在实际中的全面评估。增强现实提供了新机会，有助于优化评测流程。

Method: 设计并开发了名为ARCADE的增强现实评测平台，支持跨平台AR数据采集、自定义实验协议（模型可插件化推理）、AR流媒体等功能，用于开展用户研究。

Result: 以深度和光照估计为例，验证了通过AR任务能有效引导受试者对模型质量进行感知判断，并评估了ARCADE系统在不同部署和实验设置下的可用性和性能。

Conclusion: ARCADE灵活高效，显著简化了以人为中心的计算机视觉模型评测流程；AR为感知评测提供了重要价值，平台拓展性和可用性较强。

Abstract: Human perception studies can provide complementary insights to qualitative
evaluation for understanding computer vision (CV) model performance. However,
conducting human perception studies remains a non-trivial task, it often
requires complex, end-to-end system setups that are time-consuming and
difficult to scale. In this paper, we explore the unique opportunity presented
by augmented reality (AR) for helping CV researchers to conduct perceptual
studies. We design ARCADE, an evaluation platform that allows researchers to
easily leverage AR's rich context and interactivity for human-centered CV
evaluation. Specifically, ARCADE supports cross-platform AR data collection,
custom experiment protocols via pluggable model inference, and AR streaming for
user studies. We demonstrate ARCADE using two types of CV models, depth and
lighting estimation and show that AR tasks can be effectively used to elicit
human perceptual judgments of model quality. We also evaluate the systems
usability and performance across different deployment and study settings,
highlighting its flexibility and effectiveness as a human-centered evaluation
platform.

</details>


### [49] [Unlocking the Potential of MLLMs in Referring Expression Segmentation via a Light-weight Mask Decode](https://arxiv.org/abs/2508.04107)
*Jingchao Wang,Zhijian Wu,Dingjiang Huang,Yefeng Zheng,Hong Wang*

Main category: cs.CV

TL;DR: 本文提出了名为MLLMSeg的新型多模态大模型用于参考表达分割，提高了分割精度且大幅减少了模型参数量，比当前主流方法性能与效率均更优。


<details>
  <summary>Details</summary>
Motivation: 现有的参考表达分割（RES）方法要么依赖大量参数的Segment Anything Model（SAM），导致计算开销巨大；要么采用轻量级方案但牺牲了分割准确度，需要一个同时兼顾精度与开销的解决方案。

Method: 作者提出MLLMSeg框架，直接挖掘并利用MLLM视觉编码器中的图像细节特征，无需额外的视觉编码器。提出细节增强与语义一致特征融合模块（DSFF），充分整合视觉细节特征与大语言模型（LLM）输出的语义特征。最后设计了仅包含3400万参数的轻量级掩码解码器，有效结合空间与语义信息进行精准分割。

Result: 大量实验表明，该方法在分割精度和模型效率上超越了当前SAM依赖方法与SAM-free轻量级方法，实现了性能与消耗的更优平衡。

Conclusion: MLLMSeg框架能够高效、精准地完成参考表达分割任务，减少模型参数和计算开销，在维持甚至提升准确度的同时，大幅降低了资源需求，具有很好的研究和应用前景。

Abstract: Reference Expression Segmentation (RES) aims to segment image regions
specified by referring expressions and has become popular with the rise of
multimodal large models (MLLMs). While MLLMs excel in semantic understanding,
their token-generation paradigm struggles with pixel-level dense prediction.
Existing RES methods either couple MLLMs with the parameter-heavy Segment
Anything Model (SAM) with 632M network parameters or adopt SAM-free lightweight
pipelines that sacrifice accuracy. To address the trade-off between performance
and cost, we specifically propose MLLMSeg, a novel framework that fully
exploits the inherent visual detail features encoded in the MLLM vision encoder
without introducing an extra visual encoder. Besides, we propose a
detail-enhanced and semantic-consistent feature fusion module (DSFF) that fully
integrates the detail-related visual feature with the semantic-related feature
output by the large language model (LLM) of MLLM. Finally, we establish a
light-weight mask decoder with only 34M network parameters that optimally
leverages detailed spatial features from the visual encoder and semantic
features from the LLM to achieve precise mask prediction. Extensive experiments
demonstrate that our method generally surpasses both SAM-based and SAM-free
competitors, striking a better balance between performance and cost. Code is
available at https://github.com/jcwang0602/MLLMSeg.

</details>


### [50] [CLIPVehicle: A Unified Framework for Vision-based Vehicle Search](https://arxiv.org/abs/2508.04120)
*Likai Wang,Ruize Han,Xiangqun Zhang,Wei Feng*

Main category: cs.CV

TL;DR: 本文提出了一种名为CLIPVehicle的联合车辆检测与再识别（Re-ID）方法，通过利用视觉-语言模型（VLMs）和多层次身份学习策略，实现了从监控视频中高效搜索目标车辆，并在多个数据集上超越现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有车辆搜索方法往往需先检测、存储所有车辆片段，再进行车辆再识别，导致资源消耗大且效率低。因此，亟需一种能够联合车辆检测与再识别的高效、实用的端到端方法。

Method: 提出CLIPVehicle统一框架，引入了双粒度语义区域对齐模块以调动视觉-语言模型区分车辆，并通过全局、实例和特征三级身份表征学习提升再识别能力。此外，构建了包含真实和合成数据的新基准数据集。

Result: 在CityFlowVS、SynVS-Day和SynVS-All等多个基准数据集上的大量实验显示，CLIPVehicle在车辆再识别和类人搜索两方面均优于当前最优方法。

Conclusion: 联合检测与再识别可显著提升车辆搜索效率和准确率，CLIPVehicle框架的设计有效解决了两者目标冲突的问题，具有较强的应用和推广价值。

Abstract: Vehicles, as one of the most common and significant objects in the real
world, the researches on which using computer vision technologies have made
remarkable progress, such as vehicle detection, vehicle re-identification, etc.
To search an interested vehicle from the surveillance videos, existing methods
first pre-detect and store all vehicle patches, and then apply vehicle
re-identification models, which is resource-intensive and not very practical.
In this work, we aim to achieve the joint detection and re-identification for
vehicle search. However, the conflicting objectives between detection that
focuses on shared vehicle commonness and re-identification that focuses on
individual vehicle uniqueness make it challenging for a model to learn in an
end-to-end system. For this problem, we propose a new unified framework, namely
CLIPVehicle, which contains a dual-granularity semantic-region alignment module
to leverage the VLMs (Vision-Language Models) for vehicle discrimination
modeling, and a multi-level vehicle identification learning strategy to learn
the identity representation from global, instance and feature levels. We also
construct a new benchmark, including a real-world dataset CityFlowVS, and two
synthetic datasets SynVS-Day and SynVS-All, for vehicle search. Extensive
experimental results demonstrate that our method outperforms the
state-of-the-art methods of both vehicle Re-ID and person search tasks.

</details>


### [51] [Conditional Latent Diffusion Models for Zero-Shot Instance Segmentation](https://arxiv.org/abs/2508.04122)
*Maximilian Ulmer,Wout Boerdijk,Rudolph Triebel,Maximilian Durner*

Main category: cs.CV

TL;DR: 提出了一种新的扩散模型OC-DiT，用于物体分割任务，并在实例分割上实现了零样本学习，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前实例分割任务，尤其是零样本环境下，很难有效识别并分割新对象，现有方法泛化能力有限。作者希望借助扩散模型提升物体识别与分割的泛化性和效果。

Method: 提出了一种有条件潜变量扩散模型，生成实例分割掩码。方法将生成过程条件化于对象模板和图像特征，包含粗略提议模型和并行细化模型两部分；并创建大规模合成数据进行训练。

Result: 在多个具有挑战性的真实世界数据集上，无需针对目标数据重新训练即可达到当前最佳分割性能。

Conclusion: 扩散模型在实例分割任务上具备强大潜力，提出方法实现了零样本分割的突破，实验充分验证有效性。

Abstract: This paper presents OC-DiT, a novel class of diffusion models designed for
object-centric prediction, and applies it to zero-shot instance segmentation.
We propose a conditional latent diffusion framework that generates instance
masks by conditioning the generative process on object templates and image
features within the diffusion model's latent space. This allows our model to
effectively disentangle object instances through the diffusion process, which
is guided by visual object descriptors and localized image cues. Specifically,
we introduce two model variants: a coarse model for generating initial object
instance proposals, and a refinement model that refines all proposals in
parallel. We train these models on a newly created, large-scale synthetic
dataset comprising thousands of high-quality object meshes. Remarkably, our
model achieves state-of-the-art performance on multiple challenging real-world
benchmarks, without requiring any retraining on target data. Through
comprehensive ablation studies, we demonstrate the potential of diffusion
models for instance segmentation tasks.

</details>


### [52] [Excavate the potential of Single-Scale Features: A Decomposition Network for Water-Related Optical Image Enhancement](https://arxiv.org/abs/2508.04123)
*Zheng Cheng,Wenri Wang,Guangyong Chen,Yakun Ju,Yihua Cheng,Zhisong Liu,Yanda Meng,Jintao Song*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的单尺度分解网络（SSD-Net），挑战了水下图像增强领域对多尺度特征融合的依赖，显示单尺度技术也可取得甚至超过多尺度方法的效果。


<details>
  <summary>Details</summary>
Motivation: 主流水下图像增强方法依赖多尺度特征提取和融合机制，以提升图像重建质量。但作者发现多尺度融合带来较高复杂度，在实际增强中未必不可替代，从而激发探索单尺度特征潜力的动机。

Method: 作者提出SSD-Net，利用非对称分解机制将输入图像分为干净层（包含场景本质信息）和退化层（编码介质干扰）。网络设计结合了CNN的局部特征提取和Transformer的全局建模能力，核心模块包括：1）并行特征分解块（PFDB），通过高效注意力与自适应稀疏Transformer进行双分支分解；2）双向特征交流块（BFCB），实现跨层残差交互以挖掘和融合互补特征。

Result: 大量实验显示，SSD-Net仅用单尺度特征提取即可达到与多尺度方法相当，甚至更优的水下图像增强效果，同时显著降低了模型复杂度。

Conclusion: 单尺度特征分解在水下图像增强中同样具备强大潜力，SSD-Net凭借其新颖设计，成功突破了领域对多尺度融合的惯性依赖，推动了复杂度与增强效果的平衡发展。

Abstract: Underwater image enhancement (UIE) techniques aim to improve visual quality
of images captured in aquatic environments by addressing degradation issues
caused by light absorption and scattering effects, including color distortion,
blurring, and low contrast. Current mainstream solutions predominantly employ
multi-scale feature extraction (MSFE) mechanisms to enhance reconstruction
quality through multi-resolution feature fusion. However, our extensive
experiments demonstrate that high-quality image reconstruction does not
necessarily rely on multi-scale feature fusion. Contrary to popular belief, our
experiments show that single-scale feature extraction alone can match or
surpass the performance of multi-scale methods, significantly reducing
complexity. To comprehensively explore single-scale feature potential in
underwater enhancement, we propose an innovative Single-Scale Decomposition
Network (SSD-Net). This architecture introduces an asymmetrical decomposition
mechanism that disentangles input image into clean layer along with degradation
layer. The former contains scene-intrinsic information and the latter encodes
medium-induced interference. It uniquely combines CNN's local feature
extraction capabilities with Transformer's global modeling strengths through
two core modules: 1) Parallel Feature Decomposition Block (PFDB), implementing
dual-branch feature space decoupling via efficient attention operations and
adaptive sparse transformer; 2) Bidirectional Feature Communication Block
(BFCB), enabling cross-layer residual interactions for complementary feature
mining and fusion. This synergistic design preserves feature decomposition
independence while establishing dynamic cross-layer information pathways,
effectively enhancing degradation decoupling capacity.

</details>


### [53] [Learning Using Privileged Information for Litter Detection](https://arxiv.org/abs/2508.04124)
*Matthias Bartolo,Konstantinos Makantasis,Dylan Seychell*

Main category: cs.CV

TL;DR: 本研究提出了一种结合特权信息与深度学习目标检测的新方法，有效提升了垃圾检测的准确率，并兼顾了模型效率。


<details>
  <summary>Details</summary>
Motivation: 全球垃圾污染问题持续加剧，亟需自动化、有效的垃圾检测工具。而现有方法在检测小型且部分遮挡的垃圾物体时存在困难，且提升准确率往往会带来计算复杂度增加。

Method: 首次将特权信息与深度学习目标检测结合，同时提出bounding box信息编码为二值掩码的新方法，用以优化检测指导。方法在5种广泛使用的目标检测模型上进行了评估，并在SODA、BDW和UAVVaste等著名垃圾检测数据集上进行了数据集内及跨数据集实验。

Result: 实验结果显示，所提出方法在所有模型上均带来了检测性能的稳定提升，不仅提升了训练集上的准确率，对新场景具有较强泛化能力，而这些提升未增加模型复杂度，也未增加网络层数。

Conclusion: 该方法在提升垃圾检测准确率的同时保持了高效的计算性能，具备良好的实际应用前景，为解决实际垃圾监测问题提供了平衡准确率与效率的解决方案。

Abstract: As litter pollution continues to rise globally, developing automated tools
capable of detecting litter effectively remains a significant challenge. This
study presents a novel approach that combines, for the first time, privileged
information with deep learning object detection to improve litter detection
while maintaining model efficiency. We evaluate our method across five widely
used object detection models, addressing challenges such as detecting small
litter and objects partially obscured by grass or stones. In addition to this,
a key contribution of our work can also be attributed to formulating a means of
encoding bounding box information as a binary mask, which can be fed to the
detection model to refine detection guidance. Through experiments on both
within-dataset evaluation on the renowned SODA dataset and cross-dataset
evaluation on the BDW and UAVVaste litter detection datasets, we demonstrate
consistent performance improvements across all models. Our approach not only
bolsters detection accuracy within the training sets but also generalises well
to other litter detection contexts. Crucially, these improvements are achieved
without increasing model complexity or adding extra layers, ensuring
computational efficiency and scalability. Our results suggest that this
methodology offers a practical solution for litter detection, balancing
accuracy and efficiency in real-world applications.

</details>


### [54] [SVC 2025: the First Multimodal Deception Detection Challenge](https://arxiv.org/abs/2508.04129)
*Xun Lin,Xiaobao Guo,Taorui Wang,Yingjie Ma,Jiajian Huang,Jiayu Zhang,Junzhe Cao,Zitong Yu*

Main category: cs.CV

TL;DR: 本文提出了SVC 2025多模态欺骗检测挑战，通过汇集音频、视频与文本数据，旨在推动跨领域的欺骗检测能力，并对模型在异构数据集上的泛化性能进行评估。


<details>
  <summary>Details</summary>
Motivation: 现有的欺骗检测研究多局限于单一领域，且依赖于高质量欺骗样本，缺乏对跨领域泛化能力的关注，因此有必要提出跨领域基准，推动领域内方法进步。

Method: 设计了包含音频、视频和文本多模态信息的新基准挑战，要求参赛团队开发能在多种异构数据集上泛化的欺骗检测模型，并对模型在不同领域内外的表现进行评估。

Result: 共有21支队伍提交了最终结果，展现了多种跨领域欺骗检测模型的性能与创意。

Conclusion: 本基准和挑战有助于推动更具适应性、可解释性与实际应用性的多模态欺骗检测系统的发展，推动多模态学习与实际场景结合。

Abstract: Deception detection is a critical task in real-world applications such as
security screening, fraud prevention, and credibility assessment. While deep
learning methods have shown promise in surpassing human-level performance,
their effectiveness often depends on the availability of high-quality and
diverse deception samples. Existing research predominantly focuses on
single-domain scenarios, overlooking the significant performance degradation
caused by domain shifts. To address this gap, we present the SVC 2025
Multimodal Deception Detection Challenge, a new benchmark designed to evaluate
cross-domain generalization in audio-visual deception detection. Participants
are required to develop models that not only perform well within individual
domains but also generalize across multiple heterogeneous datasets. By
leveraging multimodal data, including audio, video, and text, this challenge
encourages the design of models capable of capturing subtle and implicit
deceptive cues. Through this benchmark, we aim to foster the development of
more adaptable, explainable, and practically deployable deception detection
systems, advancing the broader field of multimodal learning. By the conclusion
of the workshop competition, a total of 21 teams had submitted their final
results. https://sites.google.com/view/svc-mm25 for more information.

</details>


### [55] [DS$^2$Net: Detail-Semantic Deep Supervision Network for Medical Image Segmentation](https://arxiv.org/abs/2508.04131)
*Zhaohong Huang,Yuxin Zhang,Mingbao Lin,Taojian Zhou,Guorong Cai,Rongrong Ji*

Main category: cs.CV

TL;DR: 本论文提出了一种新的医学图像分割网络DS$^2$Net，能够综合利用低级细节特征与高级语义特征的互补信息，并通过多视角深度监督显著提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割中的深度监督方法，通常只关注粗粒度的语义特征或细粒度的细节特征，忽略了两者间的重要联系，影响了分割效果。因此需要一种能同时关注并有效融合两类特征的深度监督策略。

Method: 提出DS$^2$Net，通过Detail Enhance Module (DEM)增强细节特征监督，Semantic Enhance Module (SEM)增强语义特征监督，同时引入基于不确定性的自适应多尺度监督损失自动调整特征层次的监督强度。

Result: 在肠镜、超声和显微镜等六个公开数据集上进行了大量实验，DS$^2$Net分割效果优于当前最先进方法。

Conclusion: 多视角、基于细节与语义的深度监督以及不确定性自适应损失能显著提升医学图像分割性能，DS$^2$Net在多种医学图像场景下表现优越。

Abstract: Deep Supervision Networks exhibit significant efficacy for the medical
imaging community. Nevertheless, existing work merely supervises either the
coarse-grained semantic features or fine-grained detailed features in
isolation, which compromises the fact that these two types of features hold
vital relationships in medical image analysis. We advocate the powers of
complementary feature supervision for medical image segmentation, by proposing
a Detail-Semantic Deep Supervision Network (DS$^2$Net). DS$^2$Net navigates
both low-level detailed and high-level semantic feature supervision through
Detail Enhance Module (DEM) and Semantic Enhance Module (SEM). DEM and SEM
respectively harness low-level and high-level feature maps to create detail and
semantic masks for enhancing feature supervision. This is a novel shift from
single-view deep supervision to multi-view deep supervision. DS$^2$Net is also
equipped with a novel uncertainty-based supervision loss that adaptively
assigns the supervision strength of features within distinct scales based on
their uncertainty, thus circumventing the sub-optimal heuristic design that
typifies previous works. Through extensive experiments on six benchmarks
captured under either colonoscopy, ultrasound and microscope, we demonstrate
that DS$^2$Net consistently outperforms state-of-the-art methods for medical
image analysis.

</details>


### [56] [UniFGVC: Universal Training-Free Few-Shot Fine-Grained Vision Classification via Attribute-Aware Multimodal Retrieval](https://arxiv.org/abs/2508.04136)
*Hongyu Guo,Kuan Zhu,Xiangzhao Hao,Haiyun Guo,Ming Tang,Jinqiao Wang*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的新型通用few-shot细粒度视觉分类（FGVC）方法UniFGVC，通过多模态检索替代传统微调方式，在12个基准上优于以往方法。


<details>
  <summary>Details</summary>
Motivation: 现有few-shot FGVC方法通常对预训练视觉语言模型进行微调，容易过拟合且泛化性差。作者希望解决在数据有限情况下模型泛化及区分类别细微差异的能力。

Method: 提出UniFGVC框架，将few-shot FGVC转化为多模态检索问题。引入Category-Discriminative Visual Captioner（CDV-Captioner），利用多模态大模型生成区分类之间细粒度属性的结构化文本描述，并通过链式思考提示和视觉相似参考图减轻幻觉和提升描述判别力。利用文本描述和图像构建多模态类别模板，利用视觉和文本编码器在联合空间进行检索，实现分类。

Result: 在12个细粒度视觉分类基准上，UniFGVC在few-shot任务中性能优于之前的CLIP方法，并且超越部分全监督多模态方法，验证了广泛的适用性和强泛化能力。

Conclusion: UniFGVC架构无需训练即可适配各种多模态模型和编码器，表现出强泛化性和优良表现，为few-shot FGVC提供了新的简单高效解决途径。

Abstract: Few-shot fine-grained visual classification (FGVC) aims to leverage limited
data to enable models to discriminate subtly distinct categories. Recent works
mostly finetuned the pre-trained visual language models to achieve performance
gain, yet suffering from overfitting and weak generalization. To deal with
this, we introduce UniFGVC, a universal training-free framework that
reformulates few-shot FGVC as multimodal retrieval. First, we propose the
Category-Discriminative Visual Captioner (CDV-Captioner) to exploit the
open-world knowledge of multimodal large language models (MLLMs) to generate a
structured text description that captures the fine-grained attribute features
distinguishing closely related classes. CDV-Captioner uses chain-of-thought
prompting and visually similar reference images to reduce hallucination and
enhance discrimination of generated captions. Using it we can convert each
image into an image-description pair, enabling more comprehensive feature
representation, and construct the multimodal category templates using few-shot
samples for the subsequent retrieval pipeline. Then, off-the-shelf vision and
text encoders embed query and template pairs, and FGVC is accomplished by
retrieving the nearest template in the joint space. UniFGVC ensures broad
compatibility with diverse MLLMs and encoders, offering reliable generalization
and adaptability across few-shot FGVC scenarios. Extensive experiments on 12
FGVC benchmarks demonstrate its consistent superiority over prior few-shot
CLIP-based methods and even several fully-supervised MLLMs-based approaches.

</details>


### [57] [IDCNet: Guided Video Diffusion for Metric-Consistent RGBD Scene Generation with Precise Camera Control](https://arxiv.org/abs/2508.04147)
*Lijuan Liu,Wenfa Li,Dongbo Zhang,Shuo Wang,Shaohui Jiao*

Main category: cs.CV

TL;DR: 本文提出了IDC-Net，一个用于生成RGB-D视频序列的新型框架，可实现对摄像机轨迹的精确控制，并联合生成RGB图像和深度图。


<details>
  <summary>Details</summary>
Motivation: 现有方法往往对RGB和深度图像分开生成，难以保证时空和几何一致性，且缺乏对摄像机轨迹精准控制的能力，因此需要一种能够联合学习，并提升空间和几何对齐的新方法。

Method: 设计了IDC-Net，采用几何感知扩散模型，同时生成RGB和深度图。作者自建了摄像机-图像-深度一致的数据集，确保高几何一致性。引入了几何感知Transformer模块，实现精细的摄像机控制。

Result: 实验证明，IDC-Net在生成序列的视觉质量和几何一致性方面，相比最新方法均有提升。生成的RGB-D序列可直接用于3D场景重建，无需后处理。

Conclusion: IDC-Net通过联合学习和几何感知设计，实现了更高质量和一致性的RGB-D视频生成，推动了自动化3D场景重建等应用的发展。

Abstract: We present IDC-Net (Image-Depth Consistency Network), a novel framework
designed to generate RGB-D video sequences under explicit camera trajectory
control. Unlike approaches that treat RGB and depth generation separately,
IDC-Net jointly synthesizes both RGB images and corresponding depth maps within
a unified geometry-aware diffusion model. The joint learning framework
strengthens spatial and geometric alignment across frames, enabling more
precise camera control in the generated sequences. To support the training of
this camera-conditioned model and ensure high geometric fidelity, we construct
a camera-image-depth consistent dataset with metric-aligned RGB videos, depth
maps, and accurate camera poses, which provides precise geometric supervision
with notably improved inter-frame geometric consistency. Moreover, we introduce
a geometry-aware transformer block that enables fine-grained camera control,
enhancing control over the generated sequences. Extensive experiments show that
IDC-Net achieves improvements over state-of-the-art approaches in both visual
quality and geometric consistency of generated scene sequences. Notably, the
generated RGB-D sequences can be directly feed for downstream 3D Scene
reconstruction tasks without extra post-processing steps, showcasing the
practical benefits of our joint learning framework. See more at
https://idcnet-scene.github.io.

</details>


### [58] [ICM-Fusion: In-Context Meta-Optimized LoRA Fusion for Multi-Task Adaptation](https://arxiv.org/abs/2508.04153)
*Yihua Shao,Xiaofeng Lin,Xinwei Long,Siyu Chen,Minxi Yan,Yang Liu,Ziyang Yan,Ao Ma,Hao Tang,Jingcai Guo*

Main category: cs.CV

TL;DR: 本文提出了一种新的多任务LoRA融合方法ICM-Fusion，通过融合元学习与上下文自适应，显著提升预训练LoRA模型的多任务泛化能力，并有效避免权重冲突和遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有的多任务LoRA融合方法往往在融合过程中出现权重冲突与遗忘问题，尤其是在权重分布长尾及少样本场景下表现欠佳，因此需要新的方法提高模型多任务泛化能力。

Method: 提出了ICM-Fusion框架，将元学习与上下文自适应结合，核心为任务向量算术（task vector arithmetic），通过流形投影动态平衡不同任务间的优化冲突。此外，使用自设计的Fusion VAE（F-VAE）重构融合后的LoRA，实现多任务LoRA的生成。

Result: 大量视觉与语言任务的实验表明，ICM-Fusion具备很好的通用性与适应性。融合后的LoRA能大幅降低多任务loss，在少样本下甚至可实现任务能力增强。

Conclusion: ICM-Fusion有效解决了多任务LoRA融合的冲突与遗忘问题，可广泛适用于不同架构及任务，明显优于现有融合方法，特别适宜于few-shot情境。

Abstract: Enabling multi-task adaptation in pre-trained Low-Rank Adaptation (LoRA)
models is crucial for enhancing their generalization capabilities. Most
existing pre-trained LoRA fusion methods decompose weight matrices, sharing
similar parameters while merging divergent ones. However, this paradigm
inevitably induces inter-weight conflicts and leads to catastrophic domain
forgetting. While incremental learning enables adaptation to multiple tasks, it
struggles to achieve generalization in few-shot scenarios. Consequently, when
the weight data follows a long-tailed distribution, it can lead to forgetting
in the fused weights. To address this issue, we propose In-Context Meta LoRA
Fusion (ICM-Fusion), a novel framework that synergizes meta-learning with
in-context adaptation. The key innovation lies in our task vector arithmetic,
which dynamically balances conflicting optimization directions across domains
through learned manifold projections. ICM-Fusion obtains the optimal task
vector orientation for the fused model in the latent space by adjusting the
orientation of the task vectors. Subsequently, the fused LoRA is reconstructed
by a self-designed Fusion VAE (F-VAE) to realize multi-task LoRA generation. We
have conducted extensive experiments on visual and linguistic tasks, and the
experimental results demonstrate that ICM-Fusion can be adapted to a wide range
of architectural models and applied to various tasks. Compared to the current
pre-trained LoRA fusion method, ICM-Fusion fused LoRA can significantly reduce
the multi-tasking loss and can even achieve task enhancement in few-shot
scenarios.

</details>


### [59] [Audio-Assisted Face Video Restoration with Temporal and Identity Complementary Learning](https://arxiv.org/abs/2508.04161)
*Yuqin Cao,Yixuan Gao,Wei Sun,Xiaohong Liu,Yulun Zhang,Xiongkuo Min*

Main category: cs.CV

TL;DR: 本文提出了一种通用的音频辅助人脸视频复原网络（GAVN），能处理多种视频失真类型，并在现有方法中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 目前的人脸视频复原方法通常忽视了视觉与音频特征，尤其是口部区域的内在关联。已有的音频辅助方法仅关注压缩伪影的去除，无法应对多样化的流媒体视频失真。

Method: 提出GAVN网络，首步在低分辨率下提取时序特征以降低计算量并实现粗复原，随后在高分辨率下结合音频信号和人脸关键点提取身份特征以恢复面部细节，最后融合两类特征生成高质量视频。

Result: 实验表明，GAVN在去除视频压缩伪影、去模糊和超分辨率等任务上优于现有最先进方法。

Conclusion: GAVN能够通过音视频联合建模有效提升人脸视频复原质量，是多类型失真恢复的通用方案。相关代码将在论文发表后开源。

Abstract: Face videos accompanied by audio have become integral to our daily lives,
while they often suffer from complex degradations. Most face video restoration
methods neglect the intrinsic correlations between the visual and audio
features, especially in mouth regions. A few audio-aided face video restoration
methods have been proposed, but they only focus on compression artifact
removal. In this paper, we propose a General Audio-assisted face Video
restoration Network (GAVN) to address various types of streaming video
distortions via identity and temporal complementary learning. Specifically,
GAVN first captures inter-frame temporal features in the low-resolution space
to restore frames coarsely and save computational cost. Then, GAVN extracts
intra-frame identity features in the high-resolution space with the assistance
of audio signals and face landmarks to restore more facial details. Finally,
the reconstruction module integrates temporal features and identity features to
generate high-quality face videos. Experimental results demonstrate that GAVN
outperforms the existing state-of-the-art methods on face video compression
artifact removal, deblurring, and super-resolution. Codes will be released upon
publication.

</details>


### [60] [ToxicTAGS: Decoding Toxic Memes with Rich Tag Annotations](https://arxiv.org/abs/2508.04166)
*Subhankar Swain,Naquee Rizwan,Nayandeep Deb,Vishwajeet Singh Solanki,Vishwa Gangadhar S,Animesh Mukherjee*

Main category: cs.CV

TL;DR: 本文提出了一个首创的带有社会相关标签的有毒网络表情包（meme）数据集，并验证了标签生成模块可以提升有害内容检测效果。


<details>
  <summary>Details</summary>
Motivation: 随着社交媒体推动网络舆论极端化，有毒表情包被广泛用于传播有害信息，而现有高质量数据集的缺乏制约了有害内容自动识别系统的发展。

Method: 作者构建了一个包含6,300个真实表情包的数据集，分两步注释：第一步二分类（有毒/正常），第二步细分类有毒内容（仇恨、危险、冒犯）。此外，为表情包自动生成社会相关辅助标签，并评估这些标签对检测模型的提升效果。

Result: 实验结果表明，社会相关辅助标签显著提升了主流视觉-语言模型在有毒内容检测任务上的表现。

Conclusion: 该数据集及其标签生成技术为多模态内容审核提供了新的、可扩展的基础，有望改善网络有害内容的自动化识别与管理。

Abstract: The 2025 Global Risks Report identifies state-based armed conflict and
societal polarisation among the most pressing global threats, with social media
playing a central role in amplifying toxic discourse. Memes, as a widely used
mode of online communication, often serve as vehicles for spreading harmful
content. However, limitations in data accessibility and the high cost of
dataset curation hinder the development of robust meme moderation systems. To
address this challenge, in this work, we introduce a first-of-its-kind dataset
of 6,300 real-world meme-based posts annotated in two stages: (i) binary
classification into toxic and normal, and (ii) fine-grained labelling of toxic
memes as hateful, dangerous, or offensive. A key feature of this dataset is
that it is enriched with auxiliary metadata of socially relevant tags,
enhancing the context of each meme. In addition, we propose a tag generation
module that produces socially grounded tags, because most in-the-wild memes
often do not come with tags. Experimental results show that incorporating these
tags substantially enhances the performance of state-of-the-art VLMs detection
tasks. Our contributions offer a novel and scalable foundation for improved
content moderation in multimodal online environments.

</details>


### [61] [AD-FM: Multimodal LLMs for Anomaly Detection via Multi-Stage Reasoning and Fine-Grained Reward Optimization](https://arxiv.org/abs/2508.04175)
*Jingyi Liao,Yongyi Su,Rong-Cheng Tu,Zhao Jin,Wenhao Sun,Yiting Li,Dacheng Tao,Xun Xu,Xulei Yang*

Main category: cs.CV

TL;DR: 本文提出了一种新框架，通过多阶段推理和细粒度奖励机制，实现了多模态大模型在专业异常检测领域的高效适应，并在工业数据集上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型在专业异常检测领域的适应性受限，特别是在训练数据利用不足和推理过程欠缺监督等方面存在问题，因此亟需新方法提升其领域适应能力和推理精度。

Method: 提出两个创新：1）构建多阶段推理流程，使模型从区域识别逐步进入细致分析，并引入有结构的分析监督；2）设计细粒度奖励机制，将类别准确率和定位监督纳入奖励，将二元反馈转化为连续奖励信号，以区分真正洞察与偶然正确。

Result: 在多个工业数据集上，方法有效提升了多模态视觉-语言模型在专业异常检测任务中的性能，实现了更高的准确率与更高效的标注迁移。

Conclusion: 新方法能高效适配现有多模态模型至特定异常检测任务，实现对微小制造缺陷和结构异常的精细识别，弥合通用模型与实际检测需求间的差距。

Abstract: While Multimodal Large Language Models (MLLMs) demonstrate remarkable
capabilities across diverse domains, their application to specialized anomaly
detection (AD) remains constrained by domain adaptation challenges. Existing
Group Relative Policy Optimization (GRPO) based approaches suffer from two
critical limitations: inadequate training data utilization when models produce
uniform responses, and insufficient supervision over reasoning processes that
encourage immediate binary decisions without deliberative analysis. We propose
a comprehensive framework addressing these limitations through two synergistic
innovations. First, we introduce a multi-stage deliberative reasoning process
that guides models from region identification to focused examination,
generating diverse response patterns essential for GRPO optimization while
enabling structured supervision over analytical workflows. Second, we develop a
fine-grained reward mechanism incorporating classification accuracy and
localization supervision, transforming binary feedback into continuous signals
that distinguish genuine analytical insight from spurious correctness.
Comprehensive evaluation across multiple industrial datasets demonstrates
substantial performance improvements in adapting general vision-language models
to specialized anomaly detection. Our method achieves superior accuracy with
efficient adaptation of existing annotations, effectively bridging the gap
between general-purpose MLLM capabilities and the fine-grained visual
discrimination required for detecting subtle manufacturing defects and
structural irregularities.

</details>


### [62] [Uncertainty-Aware Spatial Color Correlation for Low-Light Image Enhancement](https://arxiv.org/abs/2508.04176)
*Jin Kuang,Dong Liu,Yukuang Zhang,Shengsheng Wang*

Main category: cs.CV

TL;DR: U2CLLIE是一种新颖的低光照图像增强框架，通过引入不确定性感知和因果关系建模，同时提升噪声抑制和图像质量，在多个数据集上取得了领先效果。


<details>
  <summary>Details</summary>
Motivation: 当前许多低光照图像增强方法主要专注于网络结构创新，忽视了极暗环境下特征表现的内在不确定性和噪声主导问题，这影响了模型的可靠性和因果推断能力。本文旨在解决极暗环境下传统方法难以抑制噪声和保持结构一致性的问题。

Method: 提出了U2CLLIE框架，包括两个关键模块：(1)不确定性感知的双域去噪模块（UaD），通过高斯引导的自适应频域特征增强（G2AF）抑制频域噪声, 优化不确定性驱动的特征表达，提升纹理提取及结构还原。(2)层次化因果关系感知框架，首先用亮度增强网络（LEN）粗略提升暗区亮度，然后利用邻域相关状态空间（NeCo）及自适应空间-颜色校准（AsC）模块在特征空间重建并强化结构与色彩一致性。

Result: 大量实验证明，U2CLLIE在多个主流低光照图像增强基准上表现优异，超越现有方法，并且具备良好的泛化能力，能适应多种场景。

Conclusion: U2CLLIE通过不确定性感知和因果关系建模，在噪声抑制和结构一致性方面取得显著提升，是低光照图像增强领域的最新进展。

Abstract: Most existing low-light image enhancement approaches primarily focus on
architectural innovations, while often overlooking the intrinsic uncertainty
within feature representations particularly under extremely dark conditions
where degraded gradient and noise dominance severely impair model reliability
and causal reasoning. To address these issues, we propose U2CLLIE, a novel
framework that integrates uncertainty-aware enhancement and spatial-color
causal correlation modeling. From the perspective of entropy-based uncertainty,
our framework introduces two key components: (1) An Uncertainty-Aware
Dual-domain Denoise (UaD) Module, which leverages Gaussian-Guided Adaptive
Frequency Domain Feature Enhancement (G2AF) to suppress frequency-domain noise
and optimize entropy-driven representations. This module enhances spatial
texture extraction and frequency-domain noise suppression/structure refinement,
effectively mitigating gradient vanishing and noise dominance. (2) A
hierarchical causality-aware framework, where a Luminance Enhancement Network
(LEN) first performs coarse brightness enhancement on dark regions. Then,
during the encoder-decoder phase, two asymmetric causal correlation modeling
modules Neighborhood Correlation State Space (NeCo) and Adaptive Spatial-Color
Calibration (AsC) collaboratively construct hierarchical causal constraints.
These modules reconstruct and reinforce neighborhood structure and color
consistency in the feature space. Extensive experiments demonstrate that
U2CLLIE achieves state-of-the-art performance across multiple benchmark
datasets, exhibiting robust performance and strong generalization across
various scenes.

</details>


### [63] [Deeper Inside Deep ViT](https://arxiv.org/abs/2508.04181)
*Sungrae Hong*

Main category: cs.CV

TL;DR: 本文分析和改进了大规模视觉模型ViT-22B的训练过程，在提升其稳定性的同时，首次探索了其在图像生成任务中的表现，并与ViT进行了对比。


<details>
  <summary>Details</summary>
Motivation: 虽然ViT-22B等大规模视觉模型取得了很多进展，但目前对其实际应用价值的认识仍然有限，特别是在本地训练环境下的行为和训练稳定性，以及其在新任务（如图像生成）中的适配性。

Method: 在本地环境下系统性训练ViT-22B，并分析其训练过程的稳定性。针对发现的不稳定问题对模型结构进行了修改以提升训练稳定性。同时，首次尝试基于ViT-22B架构进行图像生成任务，并与标准ViT架构进行了对比实验。

Result: ViT-22B在相同参数规模下整体性能优于ViT。经过模型结构调整后，训练过程更加稳定。同时，实验验证了ViT-22B和ViT在图像生成任务中的适用性差异。

Conclusion: 大规模ViT模型（如ViT-22B）通过结构调整可实现更稳定的训练过程，并在分类和图像生成等任务上展现出优于传统ViT的性能，显示出其扩展到多种视觉任务的潜力。

Abstract: There have been attempts to create large-scale structures in vision models
similar to LLM, such as ViT-22B. While this research has provided numerous
analyses and insights, our understanding of its practical utility remains
incomplete. Therefore, we examine how this model structure reacts and train in
a local environment. We also highlight the instability in training and make
some model modifications to stabilize it. The ViT-22B model, trained from
scratch, overall outperformed ViT in terms of performance under the same
parameter size. Additionally, we venture into the task of image generation,
which has not been attempted in ViT-22B. We propose an image generation
architecture using ViT and investigate which between ViT and ViT-22B is a more
suitable structure for image generation.

</details>


### [64] [RPCANet++: Deep Interpretable Robust PCA for Sparse Object Segmentation](https://arxiv.org/abs/2508.04190)
*Fengyi Wu,Yimian Dai,Tianfang Zhang,Yixuan Ding,Jian Yang,Ming-Ming Cheng,Zhenming Peng*

Main category: cs.CV

TL;DR: RPCANet++是一种结合RPCA解释力与高效深度网络的稀疏目标分割框架，通过模块化设计和特征增强，在多任务和多场景中表现出色，并提升了方法的可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统的RPCA模型虽然在图像修复和分割等任务中有效，但面临着计算复杂、高度依赖超参数以及对动态场景适应性不足等问题，这推动了作者提出更高效且更灵活的新方法。

Method: 作者提出RPCANet++，将放松版RPCA模型结构化展开为包含背景近似、目标提取和图像修复等模块。引入了记忆增强模块（MAM）来缓解特征丢失，并利用深度对比先验模块（DCPM）加快目标分割。整体结合了理论解释力和深度网络效率。

Result: 在多个公开数据集上，RPCANet++取得了当前最佳的目标分割性能，并通过可视化和定量的低秩与稀疏性测量进一步提升方法的可解释性。

Conclusion: RPCANet++有效结合了RPCA的理论优势和深度网络的实践效率，为可靠、可解释的稀疏目标分割方法设立了新基准。

Abstract: Robust principal component analysis (RPCA) decomposes an observation matrix
into low-rank background and sparse object components. This capability has
enabled its application in tasks ranging from image restoration to
segmentation. However, traditional RPCA models suffer from computational
burdens caused by matrix operations, reliance on finely tuned hyperparameters,
and rigid priors that limit adaptability in dynamic scenarios. To solve these
limitations, we propose RPCANet++, a sparse object segmentation framework that
fuses the interpretability of RPCA with efficient deep architectures. Our
approach unfolds a relaxed RPCA model into a structured network comprising a
Background Approximation Module (BAM), an Object Extraction Module (OEM), and
an Image Restoration Module (IRM). To mitigate inter-stage transmission loss in
the BAM, we introduce a Memory-Augmented Module (MAM) to enhance background
feature preservation, while a Deep Contrast Prior Module (DCPM) leverages
saliency cues to expedite object extraction. Extensive experiments on diverse
datasets demonstrate that RPCANet++ achieves state-of-the-art performance under
various imaging scenarios. We further improve interpretability via visual and
numerical low-rankness and sparsity measurements. By combining the theoretical
strengths of RPCA with the efficiency of deep networks, our approach sets a new
baseline for reliable and interpretable sparse object segmentation. Codes are
available at our Project Webpage https://fengyiwu98.github.io/rpcanetx.

</details>


### [65] [From Learning to Unlearning: Biomedical Security Protection in Multimodal Large Language Models](https://arxiv.org/abs/2508.04192)
*Dunyuan Xu,Xikai Yang,Yaoqian Li,Jinpeng Li,Pheng-Ann Heng*

Main category: cs.CV

TL;DR: 本文提出了首个用于评估生物医学多模态大模型（MLLMs）安全性去学习效果的基准数据集MLLMU-Med，并通过新颖的数据生成流程整合合成隐私数据和事实错误。结果显示现有去学习方法在去除有害知识方面效果有限，表明仍有巨大改进空间。


<details>
  <summary>Details</summary>
Motivation: 随着生物医学多模态大模型的广泛应用，模型训练过程中极易包含隐私信息和错误知识，容易引发隐私泄露或错误输出的问题。传统通过重训练去除敏感/有害数据的方法成本极高，因此迫切需要高效的去学习技术和相应评测基准。

Method: 作者设计了一套创新的数据生成管道，合成了包含患者隐私信息和事实错误的数据，构建了MLLMU-Med基准数据集。基准覆盖隐私保护和错误知识移除两大典型安全场景，并提出了新颖的Unlearning Efficiency Score作为评估指标。最后，作者在该基准上系统评测了五种去学习方法。

Result: 评测结果显示，现有去学习技术在去除生物医学多模态大模型中有害知识方面成效有限，无论是隐私保护还是错误知识移除，性能均有待提升。

Conclusion: MLLMU-Med为生物医学多模态大模型安全性评估提供了重要工具，相关去学习方法仍需持续优化。本工作为今后安全性去学习方向的研究奠定了基础。

Abstract: The security of biomedical Multimodal Large Language Models (MLLMs) has
attracted increasing attention. However, training samples easily contain
private information and incorrect knowledge that are difficult to detect,
potentially leading to privacy leakage or erroneous outputs after deployment.
An intuitive idea is to reprocess the training set to remove unwanted content
and retrain the model from scratch. Yet, this is impractical due to significant
computational costs, especially for large language models. Machine unlearning
has emerged as a solution to this problem, which avoids complete retraining by
selectively removing undesired knowledge derived from harmful samples while
preserving required capabilities on normal cases. However, there exist no
available datasets to evaluate the unlearning quality for security protection
in biomedical MLLMs. To bridge this gap, we propose the first benchmark
Multimodal Large Language Model Unlearning for BioMedicine (MLLMU-Med) built
upon our novel data generation pipeline that effectively integrates synthetic
private data and factual errors into the training set. Our benchmark targets
two key scenarios: 1) Privacy protection, where patient private information is
mistakenly included in the training set, causing models to unintentionally
respond with private data during inference; and 2) Incorrectness removal, where
wrong knowledge derived from unreliable sources is embedded into the dataset,
leading to unsafe model responses. Moreover, we propose a novel Unlearning
Efficiency Score that directly reflects the overall unlearning performance
across different subsets. We evaluate five unlearning approaches on MLLMU-Med
and find that these methods show limited effectiveness in removing harmful
knowledge from biomedical MLLMs, indicating significant room for improvement.
This work establishes a new pathway for further research in this promising
field.

</details>


### [66] [Gather and Trace: Rethinking Video TextVQA from an Instance-oriented Perspective](https://arxiv.org/abs/2508.04197)
*Yan Zhang,Gangyan Zeng,Daiqing Wu,Huawen Shen,Binbin Li,Yu Zhou,Can Ma,Xiaojun Bi*

Main category: cs.CV

TL;DR: 本文提出了一种名为GAT（Gather and Trace）的新型模型，通过实例聚合与轨迹追踪，有效提升了视频文本视觉问答（Video TextVQA）的准确率与推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有视频文本VQA多依赖逐帧处理，存在文本实体冗余及关系建模隐含等问题，导致准确率与效率受限。为解决上述难题，作者提出从实例导向视角重塑任务流程。

Method: 1. 实例聚合模块：结合视频中相关实体的视觉外观、布局和文本内容，统一为准确的文本实例表示。
2. 轨迹追踪模块：捕捉文本实例在视频中的时空动态演变，建立各实例间的关联，助力答案推断。

Result: GAT模型在多个公开Video TextVQA数据集上大幅优于现有方法，与主流视频语言预训练、视频大语言模型相比，准确率提升，且推理速度十倍于后者，并较SOTA提升3.86%的准确率。

Conclusion: 聚焦实例的GAT框架不仅提升了视频内文本的阅读与推理能力，还极大提高计算效率，具有良好的泛化性和应用前景。

Abstract: Video text-based visual question answering (Video TextVQA) aims to answer
questions by explicitly reading and reasoning about the text involved in a
video. Most works in this field follow a frame-level framework which suffers
from redundant text entities and implicit relation modeling, resulting in
limitations in both accuracy and efficiency. In this paper, we rethink the
Video TextVQA task from an instance-oriented perspective and propose a novel
model termed GAT (Gather and Trace). First, to obtain accurate reading result
for each video text instance, a context-aggregated instance gathering module is
designed to integrate the visual appearance, layout characteristics, and
textual contents of the related entities into a unified textual representation.
Then, to capture dynamic evolution of text in the video flow, an
instance-focused trajectory tracing module is utilized to establish
spatio-temporal relationships between instances and infer the final answer.
Extensive experiments on several public Video TextVQA datasets validate the
effectiveness and generalization of our framework. GAT outperforms existing
Video TextVQA methods, video-language pretraining methods, and video large
language models in both accuracy and inference speed. Notably, GAT surpasses
the previous state-of-the-art Video TextVQA methods by 3.86\% in accuracy and
achieves ten times of faster inference speed than video large language models.
The source code is available at https://github.com/zhangyan-ucas/GAT.

</details>


### [67] [Bootstrap Deep Spectral Clustering with Optimal Transport](https://arxiv.org/abs/2508.04200)
*Wengang Guo,Wei Ye,Chunchun Chen,Xin Sun,Christian Böhm,Claudia Plant,Susanto Rahardja*

Main category: cs.CV

TL;DR: 本文提出了一种端到端的深度谱聚类模型BootSC，有效解决了传统谱聚类在分阶段优化和表达能力不足等问题，并大幅提升了聚类效果。


<details>
  <summary>Details</summary>
Motivation: 传统谱聚类存在两个主要缺点：一是各阶段（亲和矩阵构建、谱嵌入、聚类）是分别优化的，难以全局协调；二是其表达能力有限，难以应对复杂数据。

Method: BootSC通过单一网络端到端联合学习谱聚类的全部流程，并引入由最优传输理论指导的监督信号以提升亲和矩阵和聚类分配的质量。同时通过一种语义一致的正交重参数化方法对谱嵌入进行正交化，提高了特征判别力。

Result: BootSC实现了当前最优的聚类表现，在ImageNet-Dogs等难度较高的数据集上，NMI指标较第二名方法提升了16%。

Conclusion: 端到端联合优化、最优传输自举和正交重参数化的结合，使得BootSC在实际聚类任务中取得了显著提升，证明了方法的有效性。

Abstract: Spectral clustering is a leading clustering method. Two of its major
shortcomings are the disjoint optimization process and the limited
representation capacity. To address these issues, we propose a deep spectral
clustering model (named BootSC), which jointly learns all stages of spectral
clustering -- affinity matrix construction, spectral embedding, and $k$-means
clustering -- using a single network in an end-to-end manner. BootSC leverages
effective and efficient optimal-transport-derived supervision to bootstrap the
affinity matrix and the cluster assignment matrix. Moreover, a
semantically-consistent orthogonal re-parameterization technique is introduced
to orthogonalize spectral embeddings, significantly enhancing the
discrimination capability. Experimental results indicate that BootSC achieves
state-of-the-art clustering performance. For example, it accomplishes a notable
16\% NMI improvement over the runner-up method on the challenging ImageNet-Dogs
dataset. Our code is available at https://github.com/spdj2271/BootSC.

</details>


### [68] [FrEVL: Leveraging Frozen Pretrained Embeddings for Efficient Vision-Language Understanding](https://arxiv.org/abs/2508.04469)
*Emmanuelle Bourigault,Pauline Bourigault*

Main category: cs.CV

TL;DR: FrEVL框架利用冻结的预训练嵌入，实现了高效的视觉-语言理解，显著减少训练参数与能耗，同时保持接近当前最先进方法的性能。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言模型部署时面临巨大的计算资源消耗，如何降低计算开销、提高推理效率是该领域的重要挑战。

Method: 提出FrEVL框架，直接利用冻结的预训练嵌入（不对嵌入进行训练），探索其在视觉-语言理解任务中的表现。将该方法在多个标准基准数据集上对比评测，与当前最先进的可训练模型进行性能和资源消耗分析。

Result: 在只需68.4M可训练参数的情况下，FrEVL能达到当前最优方法85%~95%的性能。整体计算加速2.3倍，能耗降低52%。性能好坏取决于预训练目标是否与下游任务紧密匹配。

Conclusion: 对于输入可预先计算或计算资源受限的场景，冻结嵌入方法能以较高效率替代端到端模型。文章为从业者提供了采用冻结嵌入与全模型部署间的实用选择依据，并承诺开放实现细节以推动相关研究发展。

Abstract: The deployment of vision-language models remains constrained by substantial
computational requirements. We present \textbf{FrEVL}, a framework exploring
whether frozen pretrained embeddings can support effective vision-language
understanding. Our analysis reveals that frozen embeddings contain rich
information for discriminative tasks, achieving 85\% to 95\% of
state-of-the-art performance on standard benchmarks with only 68.4M trainable
parameters. This performance dichotomy reveals a critical insight: frozen
embedding effectiveness depends on alignment between pretraining objectives and
downstream task requirements. When accounting for end-to-end computation
including embedding extraction, FrEVL provides $2.3\times$ speedup with 52\%
lower energy consumption, making it suitable for scenarios with pre-computable
inputs or when deployment constraints outweigh marginal performance gains. Our
evaluation provides practitioners with guidance on when frozen embedding
approaches represent viable alternatives to full model deployment. We will
release our complete implementation and evaluation framework to facilitate
further research into efficient multi-modal understanding.

</details>


### [69] [ViFP: A Framework for Visual False Positive Detection to Enhance Reasoning Reliability in VLMs](https://arxiv.org/abs/2508.04201)
*Ben Zhang,LuLu Yu,Lei Gao,Jing Liu,QuanJiang Guo,Hui Gao*

Main category: cs.CV

TL;DR: 该论文提出用于视觉-语言模型（VLM）推理可靠性增强的通用框架ViFP，通过检测和减少错误正例（FP），提升模型推理的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前VLM推理中存在错误正例问题，即虽然模型答案正确但推理路径错误。现有方法依赖特定多步推理数据集和强化学习，训练成本高且泛化性差，因此亟需一种通用、低成本且泛化能力强的解决方案。

Method: ViFP框架通过设计以视觉推理核心维度为基础的子问题模板（如目标定位、特征描述、目标发现），利用多轮问答构建有效推理路径；同时动态分析推理路径一致性来检测错误正例，并引入自适应链式思考（CoT）机制，分别引导错误正例和非错误正例样本，减少推理路径逻辑错误。提出结合答案准确率和错误正例率的可靠性评估指标VoC。

Result: 在闭源VLM（如GPT-4V）上，ViFP在A-OKVQA、OKVQA和FVQA三个数据集均显著提升了表现。在A-OKVQA数据集上，准确率提升5.4%，超越前SOTA 4.3%，同时大幅减少了错误正例数量。

Conclusion: ViFP框架不依赖特定数据集且泛化能力强，能有效提升VLM推理过程的准确性与可靠性，为今后视觉-语言推理的发展提供了实用工具和评估依据。

Abstract: In visual-language model (VLM) reasoning, false positive(FP) reasoning occurs
when a model generates a correct answer but follows an incorrect reasoning
path. Existing methods based on specific multi-step reasoning datasets and
reinforcement learning strategies, leading to high training costs and limited
generalization. In this work, we propose ViFP, a general framework for
enhancing visual reasoning reliability. It improves both answer accuracy and
reasoning soundness by detecting FPs. ViFP tackles the limitations of dataset
dependency and poor generalization by constructing sub-question templates
grounded in the core dimensions of visual reasoning, such as object
localization, characteristic description, and object discovery. ViFP then
builds effective reasoning paths via multi-turn QA to improve reasoning
accuracy. Meanwhile, ViFP dynamically analyzes the consistency of reasoning
path to identify potential FPs, and introduces a targeted chain-of-thought
(CoT) mechanism that adaptively guides both FP and non-FP samples. Thereby
reducing logical errors in the reasoning path while preserving accuracy.
Finally, we introduce a reliability evaluation metric-VoC, which integrates
answer accuracy and the FP rate, providing a quantitative tool to assess
whether a VLM not only answers correctly, but also reasons reliably. Our
experiments on closed-source VLMs show that ViFP consistently improves
performance across three datasets: A-OKVQA, OKVQA, and FVQA. On A-OKVQA, ViFP
improves accuracy by up to 5.4%, surpassing the previous state-of-the-art by
4.3%, and significantly reduces the number of FPs, validating its benefits in
enhancing reasoning reliability.

</details>


### [70] [Analyzing and Mitigating Object Hallucination: A Training Bias Perspective](https://arxiv.org/abs/2508.04567)
*Yifan Li,Kun Zhou,Wayne Xin Zhao,Lei Fang,Ji-Rong Wen*

Main category: cs.CV

TL;DR: 本文探讨了视觉-语言大模型（LVLMs）的幻觉问题，发现训练数据中的偏差导致模型对已见图像更易产生幻觉，提出了POPEv2基准进行系统性评估，并提出Obliviate方法来消除训练偏差，有效减少了模型的幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 尽管增大训练数据提升了LVLMs的多模态能力，但其依然存在生成与视觉输入不符文本的幻觉问题。作者希望深入理解训练数据在幻觉产生中的具体作用，并探索有效缓解措施。

Method: 1）提出新的幻觉测试基准POPEv2，收集并利用带有特定对象遮挡（masked）的训练集反事实图像；2）全面评估主流LVLMs在该基准上的表现，揭示训练偏差集中于语言模型头部（LM Head）；3）提出Obliviate方法，只更新约2%参数，通过精细化微调LM Head，实现快速高效的去偏训练。

Result: 实验表明，LVLMs在训练数据中的反事实图像上幻觉频发，尤其在已见图像及被遮挡对象相关问题上错误率高。Obliviate可有效降低幻觉，在判别与生成任务中效果显著，具备良好的扩展性和泛化性。

Conclusion: 训练数据中的偏差是LVLMs幻觉问题的关键原因，Obliviate可高效缓解此问题。该方法泛化能力强，可推广至不同模型规模与多种幻觉类型，推动幻觉鲁棒多模态系统的发展。

Abstract: As scaling up training data has significantly improved the general multimodal
capabilities of Large Vision-Language Models (LVLMs), they still suffer from
the hallucination issue, generating text that is inconsistent with the visual
input. This phenomenon motivates us to systematically investigate the role of
training data in hallucination. We introduce a new benchmark, POPEv2, which
consists of counterfactual images collected from the training data of LVLMs
with certain objects masked. Through comprehensive evaluation on POPEv2, we
find that current LVLMs suffer from training bias: they fail to fully leverage
their training data and hallucinate more frequently on images seen during
training. Specifically, they perform poorly on counterfactual images, often
incorrectly answering ``Yes'' to questions about masked objects. To understand
this issue, we conduct probing experiments on the models' internal components,
revealing that this training bias is primarily located in the language modeling
(LM) head. Based on these findings, we propose Obliviate, an efficient and
lightweight unlearning method designed to mitigate object hallucination via
training bias unlearning. Obliviate identifies the discrepancy between
ground-truth labels and model outputs on the training data as a proxy for bias
and adopts a parameter- and data-efficient fine-tuning strategy that only
updates the LM head. Extensive experiments demonstrate the effectiveness of our
approach. While only reusing the training data and updating approximately 2\%
of the parameters, Obliviate significantly reduces hallucination across both
discriminative and generative tasks. Furthermore, it demonstrates strong
scalability with respect to both model size (2B to 72B) and training data
volume, and exhibits promising generalization to hallucination types beyond
object-level hallucination. Our code and data will be publicly released.

</details>


### [71] [Small Lesions-aware Bidirectional Multimodal Multiscale Fusion Network for Lung Disease Classification](https://arxiv.org/abs/2508.04205)
*Jianxun Yu,Ruiquan Ge,Zhipeng Wang,Cheng Yang,Chenyu Lin,Xianjun Fu,Jikui Liu,Ahmed Elazab,Changmiao Wang*

Main category: cs.CV

TL;DR: 该 paper 提出了一种新的多模态多尺度交叉注意力融合网络（MMCAF-Net），有效融合医学图像与电子健康记录，显著提升了疾病诊断的准确率。


<details>
  <summary>Details</summary>
Motivation: 医学疾病的诊断容易因为小病灶而出现误诊。尽管深度学习中的多模态方法表现出了潜力，但医学影像与健康记录数据的维度差异为其有效融合带来了挑战。作者希望解决这类数据融合和对小病灶识别准确率低的问题。

Method: 提出了 MMCAF-Net，结合特征金字塔结构和高效的 3D 多尺度卷积注意力模块，用于从 3D 医学影像中提取病灶特征。该模型还引入多尺度交叉注意力模块解决多模态数据间的维度不一致，提升特征融合效果。

Result: 在 Lung-PET-CT-Dx 数据集上进行实验，MMCAF-Net 在诊断准确性方面显著优于当前最优方法。

Conclusion: MMCAF-Net 提升了多模态医学数据的融合能力，显著提高了疾病诊断准确率，对医学人工智能诊断具有重要意义。

Abstract: The diagnosis of medical diseases faces challenges such as the misdiagnosis
of small lesions. Deep learning, particularly multimodal approaches, has shown
great potential in the field of medical disease diagnosis. However, the
differences in dimensionality between medical imaging and electronic health
record data present challenges for effective alignment and fusion. To address
these issues, we propose the Multimodal Multiscale Cross-Attention Fusion
Network (MMCAF-Net). This model employs a feature pyramid structure combined
with an efficient 3D multi-scale convolutional attention module to extract
lesion-specific features from 3D medical images. To further enhance multimodal
data integration, MMCAF-Net incorporates a multi-scale cross-attention module,
which resolves dimensional inconsistencies, enabling more effective feature
fusion. We evaluated MMCAF-Net on the Lung-PET-CT-Dx dataset, and the results
showed a significant improvement in diagnostic accuracy, surpassing current
state-of-the-art methods. The code is available at
https://github.com/yjx1234/MMCAF-Net

</details>


### [72] [What Holds Back Open-Vocabulary Segmentation?](https://arxiv.org/abs/2508.04211)
*Josip Šarić,Ivan Martinović,Matej Kristan,Siniša Šegvić*

Main category: cs.CV

TL;DR: 标准分割方法难以识别训练标签体系外的概念，开放词汇方法虽有潜力但实际效果遇到瓶颈，本文通过引入新颖的oracle组件，揭示与分离这些瓶颈，实验结果为未来研究方向提供指引。


<details>
  <summary>Details</summary>
Motivation: 目前图像分割模型难以识别训练集外的新颖概念。虽然开放词汇模型（open-vocabulary）承诺能通过大规模图文预训练实现泛化，但实际表现未达预期且提升停滞。作者试图分析原因并推动该领域发展。

Method: 提出新颖的oracle组件，利用真实标签信息来识别并分离开放词汇模型中的性能瓶颈。在实验中通过控制变量揭示模型失败的具体原因。

Result: 大量实验证明现有open-vocabulary分割模型的性能瓶颈主要由几个核心环节导致，并通过oracle组件逐一定位了这些瓶颈点。

Conclusion: 对开放词汇分割模型的局限性有了更深入的实证认识，给出了解决方案的方向，为未来相关研究提供了重要启示。

Abstract: Standard segmentation setups are unable to deliver models that can recognize
concepts outside the training taxonomy. Open-vocabulary approaches promise to
close this gap through language-image pretraining on billions of image-caption
pairs. Unfortunately, we observe that the promise is not delivered due to
several bottlenecks that have caused the performance to plateau for almost two
years. This paper proposes novel oracle components that identify and decouple
these bottlenecks by taking advantage of the groundtruth information. The
presented validation experiments deliver important empirical findings that
provide a deeper insight into the failures of open-vocabulary models and
suggest prominent approaches to unlock the future research.

</details>


### [73] [SplitGaussian: Reconstructing Dynamic Scenes via Visual Geometry Decomposition](https://arxiv.org/abs/2508.04224)
*Jiahui Li,Shengeng Tang,Jingxuan He,Gang Huang,Zhangye Wang,Yantao Pan,Lechao Cheng*

Main category: cs.CV

TL;DR: 本文提出了一种名为SplitGaussian的新方法，通过将场景静态与动态部分在高斯重建中显式分离，有效提升了单目视频动态三维场景重建的质量与稳定性，并解决了过往方法中的运动混淆和失真问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于Gaussian Splatting的动态三维重建方法，往往将静态和动态元素混合建模，导致几何扭曲、运动泄露和时间抖动，影响重建效果。作者认为主要原因在于几何与外观的时域耦合，迫切需要更具解释性和稳定性的分离建模框架。

Method: 提出SplitGaussian框架，将场景重建表示明确分为静态和动态两部分。动态部分可随时间发生形变，仅允许动态分支变化，保证静态背景不受运动影响，并支持时变视角的外观细化。这种解耦设计强化了时序一致性并加速收敛。

Result: 大量实验证明，SplitGaussian在渲染质量、几何稳定性与运动分离方面优于当前最优方法，重建结果更加真实、稳定且收敛更快。

Conclusion: SplitGaussian通过解耦场景静态与动态分支，从根本上提升了单目动态三维场景重建的质量和效率，为后续相关研究提供了更稳定、可解释的新范式。

Abstract: Reconstructing dynamic 3D scenes from monocular video remains fundamentally
challenging due to the need to jointly infer motion, structure, and appearance
from limited observations. Existing dynamic scene reconstruction methods based
on Gaussian Splatting often entangle static and dynamic elements in a shared
representation, leading to motion leakage, geometric distortions, and temporal
flickering. We identify that the root cause lies in the coupled modeling of
geometry and appearance across time, which hampers both stability and
interpretability. To address this, we propose \textbf{SplitGaussian}, a novel
framework that explicitly decomposes scene representations into static and
dynamic components. By decoupling motion modeling from background geometry and
allowing only the dynamic branch to deform over time, our method prevents
motion artifacts in static regions while supporting view- and time-dependent
appearance refinement. This disentangled design not only enhances temporal
consistency and reconstruction fidelity but also accelerates convergence.
Extensive experiments demonstrate that SplitGaussian outperforms prior
state-of-the-art methods in rendering quality, geometric stability, and motion
separation.

</details>


### [74] [Continual Learning for VLMs: A Survey and Taxonomy Beyond Forgetting](https://arxiv.org/abs/2508.04227)
*Yuyang Liu,Qiuhe Hong,Linlan Huang,Alexandra Gomez-Villa,Dipam Goswami,Xialei Liu,Joost van de Weijer,Yonghong Tian*

Main category: cs.CV

TL;DR: 本文是首个系统性综述视觉-语言模型（VLMs）持续学习（Continual Learning, CL）领域的论文。通过分析VLMs在持续学习中的主要挑战和失败模式，为相关解决方案建立了分类，并梳理了评测协议及未来方向。


<details>
  <summary>Details</summary>
Motivation: 虽然VLMs在多模态任务中表现卓越，但其在持续学习环境下易受灾难性遗忘影响，导致跨模态对齐和泛化能力下降，且面临新的问题如特征漂移和参数干扰。当前尚缺系统综述研究这些问题及其对策。

Method: 通过梳理文献，作者分析了VLMs在CL中的三大核心失败模式，并以此为基础提出三类解决方案的挑战驱动型分类法：1. 多模态回放策略用于缓解特征漂移；2. 跨模态正则化用于保持模态对齐；3. 参数高效适应用于减轻参数干扰。进一步评估现有协议和数据集，并提出改进建议。

Result: 综述提出了面向VLM-CL的完整问题空间、解决策略分类和评测方法，对比不同方法的优缺点，并指出当前在持续预训练和组合式零样本学习等方向的不足。

Conclusion: 该综述为VLM持续学习研究者提供了全面的参考、问题分析和方法归纳，有助于推进终身视觉-语言系统的发展。作者还公开了相关资源。

Abstract: Vision-language models (VLMs) have achieved impressive performance across
diverse multimodal tasks by leveraging large-scale pre-training. However,
enabling them to learn continually from non-stationary data remains a major
challenge, as their cross-modal alignment and generalization capabilities are
particularly vulnerable to catastrophic forgetting. Unlike traditional unimodal
continual learning (CL), VLMs face unique challenges such as cross-modal
feature drift, parameter interference due to shared architectures, and
zero-shot capability erosion. This survey offers the first focused and
systematic review of continual learning for VLMs (VLM-CL). We begin by
identifying the three core failure modes that degrade performance in VLM-CL.
Based on these, we propose a challenge-driven taxonomy that maps solutions to
their target problems: (1) \textit{Multi-Modal Replay Strategies} address
cross-modal drift through explicit or implicit memory mechanisms; (2)
\textit{Cross-Modal Regularization} preserves modality alignment during
updates; and (3) \textit{Parameter-Efficient Adaptation} mitigates parameter
interference with modular or low-rank updates. We further analyze current
evaluation protocols, datasets, and metrics, highlighting the need for better
benchmarks that capture VLM-specific forgetting and compositional
generalization. Finally, we outline open problems and future directions,
including continual pre-training and compositional zero-shot learning. This
survey aims to serve as a comprehensive and diagnostic reference for
researchers developing lifelong vision-language systems. All resources are
available at:
https://github.com/YuyangSunshine/Awesome-Continual-learning-of-Vision-Language-Models.

</details>


### [75] [LayerT2V: Interactive Multi-Object Trajectory Layering for Video Generation](https://arxiv.org/abs/2508.04228)
*Kangrui Cen,Baixuan Zhao,Yi Xin,Siqi Luo,Guangtao Zhai,Xiaohong Liu*

Main category: cs.CV

TL;DR: 本文提出了一种用于文本生成视频（T2V）任务中新方法LayerT2V，实现了多对象分层生成，显著提升了多对象运动轨迹的可控性和视频合成质量。


<details>
  <summary>Details</summary>
Motivation: 当前T2V研究大多聚焦单一物体运动，多物体场景下缺乏高效的运动轨迹控制手段。多对象运动易在交互和重叠区域出现语义冲突，导致生成效果下降，制约了相关模型在复杂场景下的表现。

Method: 提出LayerT2V方法，将视频生成分为前景和背景的分层处理。通过为每个对象分配独立"图层"，在合成时实现对象之间较高的独立性和灵活性，有效避免运动轨迹交叉时的语义冲突。

Result: LayerT2V在多对象场景下的视频生成效果优于当前主流方法，在mIoU和AP50评测指标上分别提升1.4倍和4.5倍。

Conclusion: 分层生成策略可有效提升T2V中多对象运动场景的生成能力和控制力度，为复杂视频生成提供了新思路。

Abstract: Controlling object motion trajectories in Text-to-Video (T2V) generation is a
challenging and relatively under-explored area, particularly in scenarios
involving multiple moving objects. Most community models and datasets in the
T2V domain are designed for single-object motion, limiting the performance of
current generative models in multi-object tasks. Additionally, existing motion
control methods in T2V either lack support for multi-object motion scenes or
experience severe performance degradation when object trajectories intersect,
primarily due to the semantic conflicts in colliding regions. To address these
limitations, we introduce LayerT2V, the first approach for generating video by
compositing background and foreground objects layer by layer. This layered
generation enables flexible integration of multiple independent elements within
a video, positioning each element on a distinct "layer" and thus facilitating
coherent multi-object synthesis while enhancing control over the generation
process. Extensive experiments demonstrate the superiority of LayerT2V in
generating complex multi-object scenarios, showcasing 1.4x and 4.5x
improvements in mIoU and AP50 metrics over state-of-the-art (SOTA) methods.
Project page and code are available at https://kr-panghu.github.io/LayerT2V/ .

</details>


### [76] [Intention Enhanced Diffusion Model for Multimodal Pedestrian Trajectory Prediction](https://arxiv.org/abs/2508.04229)
*Yu Liu,Zhijie Liu,Xiao Ren,You-Fu Li,He Kong*

Main category: cs.CV

TL;DR: 本文提出了一种结合行人运动意图的扩散式多模态轨迹预测模型，在ETH和UCY数据集上达到了有竞争力的预测效果。


<details>
  <summary>Details</summary>
Motivation: 行人轨迹预测对于自动驾驶路径和运动控制至关重要，但由于人类行为本身具有多模态和不确定性，准确预测很具挑战性。现有的扩散模型虽然能够捕捉这种随机性，但很少显式融入运动意图，导致泛化性和可解释性有限。

Method: 作者提出将行人运动意图分解为横向与纵向两个分量，并引入意图识别模块，将意图信息融入扩散式生成式预测模型，并设计了高效的引导机制以优化预测轨迹的可解释性。

Result: 在ETH和UCY两个轨迹预测基准数据集上的实验表明，该方法与当前最先进技术相比表现具有竞争力。

Conclusion: 通过显式建模行人运动意图，所提出的方法提高了预测模型的可解释性与精度，为行人轨迹预测提供了新的参考方案。

Abstract: Predicting pedestrian motion trajectories is critical for path planning and
motion control of autonomous vehicles. However, accurately forecasting crowd
trajectories remains a challenging task due to the inherently multimodal and
uncertain nature of human motion. Recent diffusion-based models have shown
promising results in capturing the stochasticity of pedestrian behavior for
trajectory prediction. However, few diffusion-based approaches explicitly
incorporate the underlying motion intentions of pedestrians, which can limit
the interpretability and precision of prediction models. In this work, we
propose a diffusion-based multimodal trajectory prediction model that
incorporates pedestrians' motion intentions into the prediction framework. The
motion intentions are decomposed into lateral and longitudinal components, and
a pedestrian intention recognition module is introduced to enable the model to
effectively capture these intentions. Furthermore, we adopt an efficient
guidance mechanism that facilitates the generation of interpretable
trajectories. The proposed framework is evaluated on two widely used human
trajectory prediction benchmarks, ETH and UCY, on which it is compared against
state-of-the-art methods. The experimental results demonstrate that our method
achieves competitive performance.

</details>


### [77] [DocVCE: Diffusion-based Visual Counterfactual Explanations for Document Image Classification](https://arxiv.org/abs/2508.04233)
*Saifullah Saifullah,Stefan Agne,Andreas Dengel,Sheraz Ahmed*

Main category: cs.CV

TL;DR: 本文提出了一种创新方法（DocVCE），通过生成式对抗样本（counterfactuals）来解释文档图像分类模型的决策，提升AI系统的透明度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着AI在文档处理流程中的广泛应用，尤其是在高风险领域，其决策的不透明性和潜在偏见可能带来严重后果。现有解释方法如特征重要性热图难以直观展示模型决策依据，迫切需要更易理解的解释方式。

Method: 提出DocVCE方法，结合潜在扩散模型与分类器引导，先生成合理的视觉对抗样本，再进行分层补丁优化，使对抗样本更加接近特定目标。该方法在3个文档分类数据集和3种主流模型上进行定性与定量评估。

Result: DocVCE在RVL-CDIP、Tobacco3482、DocLayNet三个数据集和ResNet、ConvNeXt、DiT三种模型上，均通过有效性、接近度和真实感等指标验证了优越性。

Conclusion: 本研究首次在文档图像分析领域引入生成式对抗性解释，实验证明该方法在模型可解释性上取得了显著进展，有助于提升AI文档处理系统的透明度和可靠性。

Abstract: As black-box AI-driven decision-making systems become increasingly widespread
in modern document processing workflows, improving their transparency and
reliability has become critical, especially in high-stakes applications where
biases or spurious correlations in decision-making could lead to serious
consequences. One vital component often found in such document processing
workflows is document image classification, which, despite its widespread use,
remains difficult to explain. While some recent works have attempted to explain
the decisions of document image classification models through
feature-importance maps, these maps are often difficult to interpret and fail
to provide insights into the global features learned by the model. In this
paper, we aim to bridge this research gap by introducing generative document
counterfactuals that provide meaningful insights into the model's
decision-making through actionable explanations. In particular, we propose
DocVCE, a novel approach that leverages latent diffusion models in combination
with classifier guidance to first generate plausible in-distribution visual
counterfactual explanations, and then performs hierarchical patch-wise
refinement to search for a refined counterfactual that is closest to the target
factual image. We demonstrate the effectiveness of our approach through a
rigorous qualitative and quantitative assessment on 3 different document
classification datasets -- RVL-CDIP, Tobacco3482, and DocLayNet -- and 3
different models -- ResNet, ConvNeXt, and DiT -- using well-established
evaluation criteria such as validity, closeness, and realism. To the best of
the authors' knowledge, this is the first work to explore generative
counterfactual explanations in document image analysis.

</details>


### [78] [A machine learning approach for image classification in synthetic aperture RADAR](https://arxiv.org/abs/2508.04234)
*Romina Gaburro,Patrick Healy,Shraddha Naidu,Clifford Nolan*

Main category: cs.CV

TL;DR: 本文利用卷积神经网络（CNNs）对合成孔径雷达（SAR）数据进行目标形状和冰类型分类，并取得了较高的分类准确率。


<details>
  <summary>Details</summary>
Motivation: SAR数据中目标自动识别和分类一直是遥感领域的重要难题，尤其是在复杂环境下，常规方法抗干扰能力有限。本研究旨在探索深度学习方法（CNNs）在此领域中的表现和实际应用潜力。

Method: 作者首先采用单次散射近似模型分别在模拟和重建的SAR数据上，对物体形状进行分类，并比较不同数据处理方式的性能。随后，使用Sentinel-1卫星的真实SAR影像对冰类型进行识别。此外，还探究了不同天线高度的SAR数据对分类效果的影响。

Result: 不论是模拟数据还是真实影像，CNNs模型在分类形状及冰类型问题上均获得了较高的准确率（≥75%），显示出强大的识别能力。

Conclusion: 深度学习（CNNs）能够高效利用SAR数据完成地物和环境类型分类任务，并且对数据采集的天线高度有一定容错性，具有良好的实际应用前景。

Abstract: We consider the problem in Synthetic Aperture RADAR (SAR) of identifying and
classifying objects located on the ground by means of Convolutional Neural
Networks (CNNs). Specifically, we adopt a single scattering approximation to
classify the shape of the object using both simulated SAR data and
reconstructed images from this data, and we compare the success of these
approaches. We then identify ice types in real SAR imagery from the satellite
Sentinel-1. In both experiments we achieve a promising high classification
accuracy ($\geq$75\%). Our results demonstrate the effectiveness of CNNs in
using SAR data for both geometric and environmental classification tasks. Our
investigation also explores the effect of SAR data acquisition at different
antenna heights on our ability to classify objects successfully.

</details>


### [79] [PIS3R: Very Large Parallax Image Stitching via Deep 3D Reconstruction](https://arxiv.org/abs/2508.04236)
*Muhua Zhu,Xinhao Jin,Chengbo Wang,Yongcong Zhang,Yifei Xue,Tie Ji,Yizhen Lao*

Main category: cs.CV

TL;DR: 本文提出了一种能有效拼接大视差图像的新方法PIS3R，该方法结合深度3D重建与视觉Transformer，拼接效果优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 传统图像拼接方法在处理具有大视差（视点差异显著）的图像时往往效果不佳，容易出现几何畸变或拼接错误，因此亟需一种能够鲁棒应对大视差场景的拼接方案。

Method: 1. 首先利用基于视觉几何的Transformer模型，对两张存在大视差的输入图像进行分析，提取相机的内外参数与密集三维场景重建；2. 然后用恢复出的相机参数，将重建的点云重投影到目标视角，实现像素级对齐并生成初步拼接结果；3. 最后通过一个点条件影像扩散模块，对初始拼接结果进一步修复（如填补空洞、消除噪声），提升成像质量。

Result: 实验结果显示，所提算法在具有大视差的图像拼接任务中，能提供精准、几何一致性强的拼接结果，并在定性和定量上全面优于现有同类方法。

Conclusion: PIS3R不仅能有效处理超大视差场景下的图像拼接，保持3D信息完整，还具备良好的拓展性，可应用于后续的三维视觉任务（如结构自运动SfM）。

Abstract: Image stitching aim to align two images taken from different viewpoints into
one seamless, wider image. However, when the 3D scene contains depth variations
and the camera baseline is significant, noticeable parallax occurs-meaning the
relative positions of scene elements differ substantially between views. Most
existing stitching methods struggle to handle such images with large parallax
effectively. To address this challenge, in this paper, we propose an image
stitching solution called PIS3R that is robust to very large parallax based on
the novel concept of deep 3D reconstruction. First, we apply visual geometry
grounded transformer to two input images with very large parallax to obtain
both intrinsic and extrinsic parameters, as well as the dense 3D scene
reconstruction. Subsequently, we reproject reconstructed dense point cloud onto
a designated reference view using the recovered camera parameters, achieving
pixel-wise alignment and generating an initial stitched image. Finally, to
further address potential artifacts such as holes or noise in the initial
stitching, we propose a point-conditioned image diffusion module to obtain the
refined result.Compared with existing methods, our solution is very large
parallax tolerant and also provides results that fully preserve the geometric
integrity of all pixels in the 3D photogrammetric context, enabling direct
applicability to downstream 3D vision tasks such as SfM. Experimental results
demonstrate that the proposed algorithm provides accurate stitching results for
images with very large parallax, and outperforms the existing methods
qualitatively and quantitatively.

</details>


### [80] [From eye to AI: studying rodent social behavior in the era of machine Learning](https://arxiv.org/abs/2508.04255)
*Giuseppe Chindemi,Camilla Bellone,Benoit Girard*

Main category: cs.CV

TL;DR: 本论文综述了将人工智能和机器学习方法应用于啮齿动物社会行为研究的现状、工具、优势与挑战，并提出了实际的解决策略。


<details>
  <summary>Details</summary>
Motivation: 传统的人为观察方法容易产生偏见且难以捕捉复杂的社会行为，为提高研究的准确性和深度，需要采用计算方法辅助行为分析。

Method: 本文主要对比梳理了人类传统观察方法与现代AI计算方法，介绍了当前常用的分析工具，讨论其在社会行为研究中的应用流程、优劣势与存在的主要挑战。

Result: 现代计算方法在行为解析上具备更高的多维度和准确性，但也面临着技术集成、数据处理与方法选取等实际困难。作者提出了针对常见问题的具体解决建议。

Conclusion: AI方法在啮齿动物社会行为分析中的应用前景广阔，但工具的进一步优化和规范仍是未来发展的关键。建议新入门研究者结合现有经验，有步骤地选择和改良方法，同时呼吁领域专家加强讨论和推动工具进步。

Abstract: The study of rodent social behavior has shifted in the last years from
relying on direct human observation to more nuanced approaches integrating
computational methods in artificial intelligence (AI) and machine learning.
While conventional approaches introduce bias and can fail to capture the
complexity of rodent social interactions, modern approaches bridging computer
vision, ethology and neuroscience provide more multifaceted insights into
behavior which are particularly relevant to social neuroscience. Despite these
benefits, the integration of AI into social behavior research also poses
several challenges. Here we discuss the main steps involved and the tools
available for analyzing rodent social behavior, examining their advantages and
limitations. Additionally, we suggest practical solutions to address common
hurdles, aiming to guide young researchers in adopting these methods and to
stimulate further discussion among experts regarding the evolving requirements
of these tools in scientific applications.

</details>


### [81] [Segment Any Vehicle: Semantic and Visual Context Driven SAM and A Benchmark](https://arxiv.org/abs/2508.04260)
*Xiao Wang,Ziwen Wang,Wentao Wu,Anjie Wang,Jiashu Wu,Yantao Pan,Chenglong Li*

Main category: cs.CV

TL;DR: 本文提出了SAV新框架，结合SAM编码器-解码器、车辆部件知识图谱和上下文样本检索模块，实现对车辆部件的精细分割，同时发布了大规模数据集VehicleSeg10K。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶对精细车辆感知提出更高要求，现有如SAM等大模型无法准确细致地对车辆部件执行有语义分割，因此需要新方法满足结构化、类别特异性分割需求。

Method: 作者提出SAV框架：1) 利用SAM为基础的编码器-解码器提取特征，2) 构建车辆部件知识图谱，建模空间与几何关系以加入结构先验，3) 设计上下文检索模块，在训练数据中寻找视觉相似实例提供上下文信息以提升泛化能力。

Result: 作者构建并发布了包含11665张带像素级高质量标注的大型数据集VehicleSeg10K，并在该数据集及其他两个数据集上，SAV和多种代表性基线进行了全面实验，建立了坚实的新基线。

Conclusion: SAV框架显著提升了车辆部件分割的精度和泛化性能，数据集和代码的公开为后续相关研究提供了重要基础和资源。

Abstract: With the rapid advancement of autonomous driving, vehicle perception,
particularly detection and segmentation, has placed increasingly higher demands
on algorithmic performance. Pre-trained large segmentation models, especially
Segment Anything Model (SAM), have sparked significant interest and inspired
new research directions in artificial intelligence. However, SAM cannot be
directly applied to the fine-grained task of vehicle part segmentation, as its
text-prompted segmentation functionality is not publicly accessible, and the
mask regions generated by its default mode lack semantic labels, limiting its
utility in structured, category-specific segmentation tasks. To address these
limitations, we propose SAV, a novel framework comprising three core
components: a SAM-based encoder-decoder, a vehicle part knowledge graph, and a
context sample retrieval encoding module. The knowledge graph explicitly models
the spatial and geometric relationships among vehicle parts through a
structured ontology, effectively encoding prior structural knowledge.
Meanwhile, the context retrieval module enhances segmentation by identifying
and leveraging visually similar vehicle instances from training data, providing
rich contextual priors for improved generalization. Furthermore, we introduce a
new large-scale benchmark dataset for vehicle part segmentation, named
VehicleSeg10K, which contains 11,665 high-quality pixel-level annotations
across diverse scenes and viewpoints. We conduct comprehensive experiments on
this dataset and two other datasets, benchmarking multiple representative
baselines to establish a solid foundation for future research and comparison. %
Both the dataset and source code of this paper will be released upon
acceptance. Both the dataset and source code of this paper will be released on
https://github.com/Event-AHU/SAV

</details>


### [82] [Revisiting Continual Semantic Segmentation with Pre-trained Vision Models](https://arxiv.org/abs/2508.04267)
*Duzhen Zhang,Yong Ren,Wei Cong,Junhao Zheng,Qiaoyi Su,Shuncheng Jia,Zhong-Zhi Li,Xuanle Zhao,Ye Bai,Feilong Chen,Qi Tian,Tielin Zhang*

Main category: cs.CV

TL;DR: 作者重新审视了直接微调（DFT）在持续语义分割中的表现，发现预训练视觉模型（PVM）本身具有较强的抗遗忘能力。提出了改进方法DFT*，不仅方法更简单高效，而且效果优于其它主流方法。


<details>
  <summary>Details</summary>
Motivation: 以往持续语义分割领域普遍认为直接微调极易遗忘先前知识，各类复杂方案也因此而生。然而作者认为这种假设有待商榷，想要系统性地验证PVM在DFT条件下的真实抗遗忘能力。

Method: 系统分析了DFT在两个主流语义分割基准（Pascal VOC 2012与ADE20K）和两种代表性PVM主干（ResNet101和Swin-B）下的表现。进一步探查特征空间，发现遗忘主要源自分类器漂移非主干退化。基于此提出DFT*，采用冻结主干和分类器、预分配未来分类器等简洁策略。

Result: 实验表明，即使直接微调，PVM遗忘极小；DFT*在多个设置下均优或持平16种SOTA方法，且训练参数更少、效率更高。

Conclusion: DFT作为基础方法，其实际表现被低估。结合简单的冻结和预分配策略，能显著提升持续语义分割性能，体现了PVM骨干的强大抗遗忘能力。

Abstract: Continual Semantic Segmentation (CSS) seeks to incrementally learn to segment
novel classes while preserving knowledge of previously encountered ones. Recent
advancements in CSS have been largely driven by the adoption of Pre-trained
Vision Models (PVMs) as backbones. Among existing strategies, Direct
Fine-Tuning (DFT), which sequentially fine-tunes the model across classes,
remains the most straightforward approach. Prior work often regards DFT as a
performance lower bound due to its presumed vulnerability to severe
catastrophic forgetting, leading to the development of numerous complex
mitigation techniques. However, we contend that this prevailing assumption is
flawed. In this paper, we systematically revisit forgetting in DFT across two
standard benchmarks, Pascal VOC 2012 and ADE20K, under eight CSS settings using
two representative PVM backbones: ResNet101 and Swin-B. Through a detailed
probing analysis, our findings reveal that existing methods significantly
underestimate the inherent anti-forgetting capabilities of PVMs. Even under
DFT, PVMs retain previously learned knowledge with minimal forgetting. Further
investigation of the feature space indicates that the observed forgetting
primarily arises from the classifier's drift away from the PVM, rather than
from degradation of the backbone representations. Based on this insight, we
propose DFT*, a simple yet effective enhancement to DFT that incorporates
strategies such as freezing the PVM backbone and previously learned
classifiers, as well as pre-allocating future classifiers. Extensive
experiments show that DFT* consistently achieves competitive or superior
performance compared to sixteen state-of-the-art CSS methods, while requiring
substantially fewer trainable parameters and less training time.

</details>


### [83] [PKSS-Align: Robust Point Cloud Registration on Pre-Kendall Shape Space](https://arxiv.org/abs/2508.04286)
*Chenlei Lv,Hui Huang*

Main category: cs.CV

TL;DR: 本文提出一种新的点云配准方法PKSS-Align，能够高效并鲁棒地应对各种点云的变换和缺陷，比现有方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有点云配准方法对相似变换（平移、缩放、旋转）、噪声、不完整结构等问题敏感，尤其在点云尺度非均匀和缺损时，易陷入局部最优解，影响配准效果。需要一种更鲁棒、简便的方法。

Method: 提出了一种基于Pre-Kendall形状空间（PKSS）的相似性度量方法，无需点对点或点对面度量，利用流形度量提升对欧式坐标表达多样性的鲁棒性。方法可直接根据度量生成变换矩阵，无需训练和复杂特征编码，并通过并行加速提升效率。

Result: 实验证明，PKSS-Align在应对相似变换、密度非均匀、噪声和缺陷点云等多种影响时，配准效果明显优于相关领域内的先进方法。

Conclusion: 提出的PKSS-Align方法具备高鲁棒性和高效性，适用于实际点云配准场景，为三维视觉和计算机图形学相关任务提供了优越的配准工具。

Abstract: Point cloud registration is a classical topic in the field of 3D Vision and
Computer Graphics. Generally, the implementation of registration is typically
sensitive to similarity transformations (translation, scaling, and rotation),
noisy points, and incomplete geometric structures. Especially, the non-uniform
scales and defective parts of point clouds increase probability of struck local
optima in registration task. In this paper, we propose a robust point cloud
registration PKSS-Align that can handle various influences, including
similarity transformations, non-uniform densities, random noisy points, and
defective parts. The proposed method measures shape feature-based similarity
between point clouds on the Pre-Kendall shape space (PKSS),
\textcolor{black}{which is a shape measurement-based scheme and doesn't require
point-to-point or point-to-plane metric.} The employed measurement can be
regarded as the manifold metric that is robust to various representations in
the Euclidean coordinate system. Benefited from the measurement, the
transformation matrix can be directly generated for point clouds with mentioned
influences at the same time. The proposed method does not require data training
and complex feature encoding. Based on a simple parallel acceleration, it can
achieve significant improvement for efficiency and feasibility in practice.
Experiments demonstrate that our method outperforms the relevant
state-of-the-art methods.

</details>


### [84] [MuGS: Multi-Baseline Generalizable Gaussian Splatting Reconstruction](https://arxiv.org/abs/2508.04297)
*Yaopeng Lou,Liao Shen,Tianqi Liu,Jiaqi Li,Zihao Huang,Huiqiang Sun,Zhiguo Cao*

Main category: cs.CV

TL;DR: 本文提出MuRF方法，结合多视角立体视觉和单目深度估计特征，通过优化深度融合及引入参考视角损失，实现高效、通用的三维重建和新视角合成，并在多个数据集和场景下取得了最新最优效果。


<details>
  <summary>Details</summary>
Motivation: 针对现有新视角合成方法在处理不同基线（输入视角间距变化大）以及输入图像稀疏时表现不佳的问题，作者希望提出一种兼容稀疏/密集、大小基线输入的统一方法，并进一步提升重建质量与渲染效率。

Method: 1）融合多视角立体（MVS）与单目深度估计（MDE）特征，优化三维表达能力。2）提出投影与采样机制，实现深度信息的细致融合。3）引入参考视角损失，提升几何重建和优化效率。4）采用3D高斯表示加速训练与推理，并提升渲染质量。

Result: MuRF在DTU、RealEstate10K等多种基线、场景下均取得了领先性能。在LLFF与Mip-NeRF 360等数据集上实现了有竞争力的零样本泛化效果。相比以往方法有更高的质量和更快的速度。

Conclusion: MuRF方法能够有效统一处理大/小基线及稀疏/密集输入的新视角合成任务，并兼顾重建精度、模型泛化能力和运算速度，在多个标准数据集上实现了最新最优或接近最优的水平。

Abstract: We present Multi-Baseline Gaussian Splatting (MuRF), a generalized
feed-forward approach for novel view synthesis that effectively handles diverse
baseline settings, including sparse input views with both small and large
baselines. Specifically, we integrate features from Multi-View Stereo (MVS) and
Monocular Depth Estimation (MDE) to enhance feature representations for
generalizable reconstruction. Next, We propose a projection-and-sampling
mechanism for deep depth fusion, which constructs a fine probability volume to
guide the regression of the feature map. Furthermore, We introduce a
reference-view loss to improve geometry and optimization efficiency. We
leverage 3D Gaussian representations to accelerate training and inference time
while enhancing rendering quality. MuRF achieves state-of-the-art performance
across multiple baseline settings and diverse scenarios ranging from simple
objects (DTU) to complex indoor and outdoor scenes (RealEstate10K). We also
demonstrate promising zero-shot performance on the LLFF and Mip-NeRF 360
datasets.

</details>


### [85] [Length Matters: Length-Aware Transformer for Temporal Sentence Grounding](https://arxiv.org/abs/2508.04299)
*Yifan Wang,Ziyi Liu,Xiaolong Sun,Jiawei Wang,Hongmin Liu*

Main category: cs.CV

TL;DR: 本文提出了一种改进的时序句子定位方法，通过引入长度感知机制，提高了自然语言描述与视频片段间的匹配效率和准确性。新方法不仅显著提升了主流数据集上的表现，还通过消融实验证明了各个组件的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有DETR结构的时序句子定位方法因缺乏明确监督，导致查询向量存在角色重叠和预测冗余的问题。为了解决这一难题，作者希望提升每个查询向量的专一性和任务分工。

Method: 作者提出长度感知Transformer (LATR) 模型。具体做法是将所有查询划分为负责短、中、长三个不同时间段的视频片段组，并引入视频-文本长度先验。在训练过程中，增加了一个长度分类任务，并抑制与自身分配长度不符的预测，促使每个query只关注自身分内的预测。

Result: LATR在三个公开基准测试上都取得了SOTA指标。同时，通过消融实验分析，验证了长度先验设计和各模块的作用。

Conclusion: 长度感知的查询机制能有效提升时序句子定位精度，新的LATR方法为相应任务提供了更合理的解法与实验依据。

Abstract: Temporal sentence grounding (TSG) is a highly challenging task aiming to
localize the temporal segment within an untrimmed video corresponding to a
given natural language description. Benefiting from the design of learnable
queries, the DETR-based models have achieved substantial advancements in the
TSG task. However, the absence of explicit supervision often causes the learned
queries to overlap in roles, leading to redundant predictions. Therefore, we
propose to improve TSG by making each query fulfill its designated role,
leveraging the length priors of the video-description pairs. In this paper, we
introduce the Length-Aware Transformer (LATR) for TSG, which assigns different
queries to handle predictions based on varying temporal lengths. Specifically,
we divide all queries into three groups, responsible for segments with short,
middle, and long temporal durations, respectively. During training, an
additional length classification task is introduced. Predictions from queries
with mismatched lengths are suppressed, guiding each query to specialize in its
designated function. Extensive experiments demonstrate the effectiveness of our
LATR, achieving state-of-the-art performance on three public benchmarks.
Furthermore, the ablation studies validate the contribution of each component
of our method and the critical role of incorporating length priors into the TSG
task.

</details>


### [86] [A Foundation Model for DAS Signal Recognition and Visual Prompt Tuning of the Pre-trained Model for Downstream Tasks](https://arxiv.org/abs/2508.04316)
*Kun Gui,Hongliang Ren,Shang Shi,Jin Lu,Changqiu Yu,Quanjun Cao,Guomin Gu,Qi Xuan*

Main category: cs.CV

TL;DR: 本文提出了一种基于Masked Autoencoder的DAS信号识别基础模型MAEPD，结合视觉提示微调，对提升跨域泛化和降低参数微调量具有显著效果。


<details>
  <summary>Details</summary>
Motivation: 分布式声学传感（DAS）技术数据受环境异质性影响，数据分布多样，且跨域泛化能力弱、标注数据不足，限制AI模型实际应用。论文旨在解决DAS信号识别模型的泛化与高效微调难题。

Method: 提出MAEPD基础模型，采用大规模、多类型DAS信号自监督掩码重建预训练，结合视觉提示微调（VPT），仅微调插入Transformer编码器的小规模可学习向量，冻结主干参数。

Result: 在室内步态识别任务上，VPT-Deep仅微调0.322%参数，分类准确率达96.94%，优于传统全量微调（提升0.61%），训练时间缩短45%；在管道泄漏检测任务上普适性亦优。

Conclusion: MAEPD具备良好的通用性、高效性和可扩展性，为DAS领域信号识别模型的泛化问题提供了新思路与范式。

Abstract: Distributed Acoustic Sensing (DAS) technology finds growing applications
across various domains. However, data distribution disparities due to
heterogeneous sensing environments pose challenges for data-driven artificial
intelligence (AI) models, limiting cross-domain generalization and facing a
shortage of labeled training data. To address these issues, this study proposes
a foundational model for DAS signal recognition based on a Masked Autoencoder,
named MAEPD. The MAEPD model is pretrained on a dataset of 635,860 samples,
encompassing DAS gait spatiotemporal signals, 2D GASF images for perimeter
security, 2D time-frequency images for pipeline leakage, and open-dataset
signals including whale vocalizations and seismic activities, using a
self-supervised mask reconstruction task to capture deep semantic features of
DAS signals. Visual Prompt Tuning (VPT) is employed for downstream recognition
tasks. This method freezes the pretrained backbone parameters and fine-tunes
only a small set of learnable visual prompt vectors inserted into the
Transformer encoder layers. Experiments on the NVIDIA GeForce RTX 4080 Super
platform validate MAEPD using indoor gait recognition as a downstream task. The
VPT-Deep approach achieves a classification accuracy of 96.94% with just 0.322%
of parameters fine-tuned, surpassing the traditional Full Fine Tuning (FFT)
method by 0.61% and reducing training time by 45%. The model also exhibits
robust performance in pipeline leakage detection, confirming the generality,
efficiency, and scalability of MAEPD as a foundational model. This approach
offers a novel paradigm for addressing the limited generalization of signal
recognition models in the DAS domain.

</details>


### [87] [TempFlow-GRPO: When Timing Matters for GRPO in Flow Models](https://arxiv.org/abs/2508.04324)
*Xiaoxuan He,Siming Fu,Yuke Zhao,Wanli Li,Jian Yang,Dacheng Yin,Fengyun Rao,Bo Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新的基于时间结构的流匹配模型（TempFlow-GRPO），提升了文本到图像生成任务中与人类偏好对齐的性能。通过引入分支机制和噪声权重方案，实现更精准和高效的奖励优化，达到了最新的对齐和生成质量。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像的流匹配模型虽生成质量高，但与强化学习结合以实现对人类偏好的细粒度对齐效果仍不理想。现有方法在时间层面上假设回报分配均匀，导致在奖励分配上不能反映各时刻决策的重要性，优化效率低下。

Method: 提出TempFlow-GRPO框架，包括：（1）轨迹分支机制，在特定分支点集中随机性，方便过程奖励分配且无需构建中间奖励模型；（2）噪声感知加权方案，根据每个时序点的探索价值调整策略优化，兼顾高影响早期阶段和后期稳定微调。

Result: TempFlow-GRPO在考虑时序结构后，优化过程更加高效，实现了对人类偏好的更好对齐，并在文本到图像生成相关基准任务上达到领先水平。

Conclusion: 引入时间结构感知的奖励与优化机制显著提升了流模型在文本到图像生成中的表现，特别是在对齐人类偏好方面，展示了方法的有效性和先进性。

Abstract: Recent flow matching models for text-to-image generation have achieved
remarkable quality, yet their integration with reinforcement learning for human
preference alignment remains suboptimal, hindering fine-grained reward-based
optimization. We observe that the key impediment to effective GRPO training of
flow models is the temporal uniformity assumption in existing approaches:
sparse terminal rewards with uniform credit assignment fail to capture the
varying criticality of decisions across generation timesteps, resulting in
inefficient exploration and suboptimal convergence. To remedy this shortcoming,
we introduce \textbf{TempFlow-GRPO} (Temporal Flow GRPO), a principled GRPO
framework that captures and exploits the temporal structure inherent in
flow-based generation. TempFlow-GRPO introduces two key innovations: (i) a
trajectory branching mechanism that provides process rewards by concentrating
stochasticity at designated branching points, enabling precise credit
assignment without requiring specialized intermediate reward models; and (ii) a
noise-aware weighting scheme that modulates policy optimization according to
the intrinsic exploration potential of each timestep, prioritizing learning
during high-impact early stages while ensuring stable refinement in later
phases. These innovations endow the model with temporally-aware optimization
that respects the underlying generative dynamics, leading to state-of-the-art
performance in human preference alignment and standard text-to-image
benchmarks.

</details>


### [88] [RotatedMVPS: Multi-view Photometric Stereo with Rotated Natural Light](https://arxiv.org/abs/2508.04366)
*Songyun Yang,Yufei Han,Jilong Zhang,Kongming Liang,Peng Yu,Zhaowei Qu,Heng Guo*

Main category: cs.CV

TL;DR: 本文提出了一种基于自然光旋转的新型多视图光度立体(MVPS)方法RotatedMVPS，在不需要严格黑暗室的情况下实现高质量形状和反射率恢复，显著提升在真实环境中的实用性。


<details>
  <summary>Details</summary>
Motivation: 现有MVPS常受限于控制光照环境或忽略反射率和光照信息恢复，造成其在自然光环境和逆向渲染应用中的局限。本文旨在突破这些不足，提升MVPS实际应用能力。

Method: 提出RotatedMVPS，在拍摄时借助旋转台保证在不同相机与物体姿态下的光照一致性，从而简化自然光下复杂光照带来的不确定性。同时结合现有单视图学习法的先验，融入MVPS框架提升恢复精度。

Result: 在合成数据和真实数据集上的实验显示，该方法在形状和反射率重建上均取得了优异的效果，超越了现有方法。

Conclusion: RotatedMVPS实现了在自然光环境下无需严格控制即可高效恢复物体的形状和反射率，为MVPS在真实场景和逆向渲染等应用提供了新的可能性。

Abstract: Multiview photometric stereo (MVPS) seeks to recover high-fidelity surface
shapes and reflectances from images captured under varying views and
illuminations. However, existing MVPS methods often require controlled darkroom
settings for varying illuminations or overlook the recovery of reflectances and
illuminations properties, limiting their applicability in natural illumination
scenarios and downstream inverse rendering tasks. In this paper, we propose
RotatedMVPS to solve shape and reflectance recovery under rotated natural
light, achievable with a practical rotation stage. By ensuring light
consistency across different camera and object poses, our method reduces the
unknowns associated with complex environment light. Furthermore, we integrate
data priors from off-the-shelf learning-based single-view photometric stereo
methods into our MVPS framework, significantly enhancing the accuracy of shape
and reflectance recovery. Experimental results on both synthetic and real-world
datasets demonstrate the effectiveness of our approach.

</details>


### [89] [TSPO: Temporal Sampling Policy Optimization for Long-form Video Language Understanding](https://arxiv.org/abs/2508.04369)
*Canhui Tang,Zifan Han,Hongbo Sun,Sanping Zhou,Xuchong Zhang,Xin Wei,Ye Yuan,Jinglin Xu,Hao Sun*

Main category: cs.CV

TL;DR: 该论文提出了TSPO方法，用于提升多模态大语言模型在长视频理解任务中的表现，通过强化学习优化关键帧采样策略，实现更精准的事件检测和语言生成，在多个长视频理解基准上取得了最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型（MLLMs）在处理长视频时，受限于上下文长度和高昂的训练成本，通常采用稀疏帧采样。主流方法如均匀采样或基于已有模型的关键帧检索均存在遗漏重要事件或受限于模型事件理解能力的不足。由于稀疏帧采样的无监督和不可微特性，建立可训练的方法一直是难题。

Method: 论文提出了TSPO，即时间采样策略优化方法。具体包括：1）提出可训练、事件感知的时间智能体，以事件-查询相关性为基础实现概率性关键帧选择；2）采用强化学习，将关键帧选择和文本生成建模为联合决策过程，通过高效的基于规则的奖励，实现端到端优化；3）提出长视频训练数据构建流程，引入丰富的事件样本和“针尖寻草堆”式数据；4）结合基于规则的答题准确率与时间定位奖励机制，进一步优化采样策略。

Result: 实验结果表明，TSPO在多个长视频理解任务上取得了最优表现，并能适配多种主流视频-多模态大模型，具有良好的迁移和泛化能力。

Conclusion: TSPO方法有效提升了多模态大语言模型在长视频任务中的能力，优化了关键帧采样与时序推理过程，将关键帧采样从不可训练转变为端到端可训练流程，为多模态视频理解领域带来了新思路。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated significant
progress in vision-language tasks, yet they still face challenges when
processing long-duration video inputs. The limitation arises from MLLMs'
context limit and training costs, necessitating sparse frame sampling before
feeding videos into MLLMs. Existing video MLLMs adopt training-free uniform
sampling or keyframe search, which may miss critical events or be constrained
by the pre-trained models' event understanding capabilities. Meanwhile,
building a training-based method remains challenging due to the unsupervised
and non-differentiable nature of sparse frame sampling. To address these
problems, we propose Temporal Sampling Policy Optimization (TSPO), advancing
MLLMs' long-form video-language understanding via reinforcement learning.
Specifically, we first propose a trainable event-aware temporal agent, which
captures event-query correlation for performing probabilistic keyframe
selection. Then, we propose the TSPO reinforcement learning paradigm, which
models keyframe selection and language generation as a joint decision-making
process, enabling end-to-end group relative optimization with efficient
rule-based rewards. Furthermore, for the TSPO's training, we propose a long
video training data construction pipeline with comprehensive temporal data and
video Needle-in-a-Haystack data. Finally, we incorporate rule-based answering
accuracy and temporal locating reward mechanisms to optimize the temporal
sampling policy. Comprehensive experiments show that our TSPO achieves
state-of-the-art performance across multiple long video understanding
benchmarks, and shows transferable ability across different cutting-edge
Video-MLLMs.

</details>


### [90] [VisionTS++: Cross-Modal Time Series Foundation Model with Continual Pre-trained Visual Backbones](https://arxiv.org/abs/2508.04379)
*Lefei Shen,Mouxiang Chen,Xu Liu,Han Fu,Xiaoxue Ren,Jianling Sun,Zhuo Li,Chenghao Liu*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉模型进行时间序列预测的新方法VisionTS++，通过创新性地处理模态、变量数量和不确定性三大鸿沟，在多个基准测试上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前视觉模型在时间序列分析中的迁移潜力受到数据模态差异、多变量支持不足及输出不确定性缺陷限制。该研究旨在突破这些障碍，实现视觉模型向时间序列预测的有效泛化。

Method: 提出了VisionTS++方法，包括：1）利用视觉模型过滤机制筛选高质量时间序列数据，缓解模态差异并增强预训练稳定性；2）创新多变量彩色转化，将多变量时间序列转化为多子图RGB图像以增强变量间依赖建模；3）多分位数预测，通过并行重建头生成不同分位点预测，提升输出分布灵活性。

Result: VisionTS++在大规模时间序列基准测试中取得了SOTA表现，特别是均方误差较现有专用模型降低6%-44%，在9/12概率预测场景中排名第一。

Conclusion: 结果表明，VisionTS++为视觉到时间序列的跨模态迁移建立了新范式，为通用时间序列基础模型的发展开辟了新道路。

Abstract: Recent studies have revealed that vision models pre-trained on images can
perform well in time series forecasting by reformulating forecasting as an
image reconstruction task, suggesting their potential as universal time series
foundation models. However, effective cross-modal transfer from vision to time
series remains challenging due to three key discrepancies: (1) data-modality
gap between structured, bounded image data and unbounded, heterogeneous time
series; (2) multivariate-forecasting gap between standard RGB
three-channel-based vision models and the need to model time series with
arbitrary numbers of variates; and (3) probabilistic-forecasting gap between
the deterministic output formats of most vision models and the requirement for
uncertainty-aware probabilistic predictions. To bridge these gaps, we propose
VisionTS++, a vision-model-based TSFM that performs continual pre-training on
large-scale time series datasets, including 3 innovations: (1) a
vision-model-based filtering mechanism to identify high-quality time series
data, thereby mitigating modality gap and improving pre-training stability, (2)
a colorized multivariate conversion method that transforms multivariate time
series into multi-subfigure RGB images, capturing complex inter-variate
dependencies; and (3) a multi-quantile forecasting approach using parallel
reconstruction heads to generate forecasts of different quantile levels, thus
more flexibly approximating arbitrary output distributions without restrictive
prior distributional assumptions. Evaluated on both in-distribution and
out-of-distribution TSF benchmarks, \model achieves SOTA results, outperforming
specialized TSFMs by 6%-44% in MSE reduction and ranking first in 9 out of 12
probabilistic forecasting settings. Our work establishes a new paradigm for
cross-modal knowledge transfer, advancing the development of universal TSFMs.

</details>


### [91] [ProtoN: Prototype Node Graph Neural Network for Unconstrained Multi-Impression Ear Recognition](https://arxiv.org/abs/2508.04381)
*Santhoshkumar Peddi,Sadhvik Bathini,Arun Balasubramanian,Monalisa Sarma,Debasis Samanta*

Main category: cs.CV

TL;DR: 本文提出了一种基于图神经网络的少样本耳朵生物识别方法ProtoN，有效提升了在少量标注数据情境下的识别性能。


<details>
  <summary>Details</summary>
Motivation: 耳朵生物识别具备稳定且非接触式的优点，但受限于标注数据稀缺和同类变异大，导致现有方法识别效果有限。传统方法通常独立处理单张印象，难以捕捉一致且有区分力的特征表示。

Method: 提出ProtoN框架，将同一身份的多张耳朵印象封装为一个类特定图节点，每个节点还有一个可学习的原型节点用于整合身份层信息。通过原型图神经网络（PGNN）层和双路径消息传递机制同时优化印象特征和原型表示。为增强类别区分力，引入跨图原型对齐策略，强化类内聚类性和类间区分，还结合混合损失函数兼顾全局与episodic分类目标。

Result: 在五个耳朵识别基准数据集上，ProtoN取得了Rank-1识别率99.60%、EER低至0.025的业界最优表现，验证了方法在少样本场景下的有效性。

Conclusion: ProtoN方法创新性地利用图神经网络和原型学习，显著提升了耳朵少样本识别的准确率和鲁棒性，为在数据受限条件下的生物识别应用提供了新思路。

Abstract: Ear biometrics offer a stable and contactless modality for identity
recognition, yet their effectiveness remains limited by the scarcity of
annotated data and significant intra-class variability. Existing methods
typically extract identity features from individual impressions in isolation,
restricting their ability to capture consistent and discriminative
representations. To overcome these limitations, a few-shot learning framework,
ProtoN, is proposed to jointly process multiple impressions of an identity
using a graph-based approach. Each impression is represented as a node in a
class-specific graph, alongside a learnable prototype node that encodes
identity-level information. This graph is processed by a Prototype Graph Neural
Network (PGNN) layer, specifically designed to refine both impression and
prototype representations through a dual-path message-passing mechanism. To
further enhance discriminative power, the PGNN incorporates a cross-graph
prototype alignment strategy that improves class separability by enforcing
intra-class compactness while maintaining inter-class distinction.
Additionally, a hybrid loss function is employed to balance episodic and global
classification objectives, thereby improving the overall structure of the
embedding space. Extensive experiments on five benchmark ear datasets
demonstrate that ProtoN achieves state-of-the-art performance, with Rank-1
identification accuracy of up to 99.60% and an Equal Error Rate (EER) as low as
0.025, showing the effectiveness for few-shot ear recognition under limited
data conditions.

</details>


### [92] [Deep Learning-based Scalable Image-to-3D Facade Parser for Generating Thermal 3D Building Models](https://arxiv.org/abs/2508.04406)
*Yinan Yu,Alex Gonzalez-Caceres,Samuel Scheidegger,Sanjay Somanath,Alexander Hollberg*

Main category: cs.CV

TL;DR: 提出了一种新方法（SI3FP），通过图像自动生成高精度建筑热工三维模型，有助于大规模旧建筑节能改造的早期规划。


<details>
  <summary>Details</summary>
Motivation: 节能改造对气候影响巨大，但目前精确高效地识别建筑细节（如窗户）并建立热工三维模型仍很困难，尤其在大规模应用时面临挑战。

Method: 开发了SI3FP管线，结合计算机视觉和深度学习技术，直接在正交影像平面建模几何体，实现从稀疏或密集的实景图片中精确提取建筑细节，生成Level of Detail 3的热工模型。

Result: 在典型瑞典住宅建筑上测试，SI3FP方法在窗墙面积比估算上约有5%的误差，满足节能改造早期分析的精度需求。

Conclusion: SI3FP能够实现可扩展、精确的LoD3热工模型自动生成，极大促进能效改造与城市规划的效率和规模，也具备更广泛的城市应用潜力。

Abstract: Renovating existing buildings is essential for climate impact. Early-phase
renovation planning requires simulations based on thermal 3D models at Level of
Detail (LoD) 3, which include features like windows. However, scalable and
accurate identification of such features remains a challenge. This paper
presents the Scalable Image-to-3D Facade Parser (SI3FP), a pipeline that
generates LoD3 thermal models by extracting geometries from images using both
computer vision and deep learning. Unlike existing methods relying on
segmentation and projection, SI3FP directly models geometric primitives in the
orthographic image plane, providing a unified interface while reducing
perspective distortions. SI3FP supports both sparse (e.g., Google Street View)
and dense (e.g., hand-held camera) data sources. Tested on typical Swedish
residential buildings, SI3FP achieved approximately 5% error in window-to-wall
ratio estimates, demonstrating sufficient accuracy for early-stage renovation
analysis. The pipeline facilitates large-scale energy renovation planning and
has broader applications in urban development and planning.

</details>


### [93] [Thinking With Videos: Multimodal Tool-Augmented Reinforcement Learning for Long Video Reasoning](https://arxiv.org/abs/2508.04416)
*Haoji Zhang,Xin Gu,Jiawen Li,Chixiang Ma,Sule Bai,Chubin Zhang,Bowen Zhang,Zhichao Zhou,Dongliang He,Yansong Tang*

Main category: cs.CV

TL;DR: 本文提出了一种新的多模态大模型视频推理框架VITAL，通过工具增强学习提升了视频问答和时序定位的能力，在多项长视频推理任务中取得了领先表现。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型（MLLMs）在面向视频的推理任务，如视频问答和时间定位时，存在跨模态互动有限、推理链越长幻觉越多、长视频处理能力弱的问题。作者旨在解决这些挑战，提升模型的实际推理能力。

Method: 提出VITAL框架，内置可按需采样视频帧的视觉工具箱，并生成多模态链式推理（CoT）。构建了两个高质量多任务视频推理数据集（MTVR-CoT-72k用于有监督微调、MTVR-RL-110k用于强化学习），创新性设计了用于缓解任务难度失衡的DGRPO算法。

Result: 在11个有挑战性的视频理解基准上进行了大量实验，VITAL在视频问答和时序定位任务上，特别是在长视频场景里，全面优于现有方法。

Conclusion: VITAL有效增强了多模态大模型对长视频推理的能力，为视频理解相关研究带来了新范式和新工具。代码、数据和模型权重均将公开，有助于推动领域发展。

Abstract: The video reasoning ability of multimodal large language models (MLLMs) is
crucial for downstream tasks like video question answering and temporal
grounding. While recent approaches have explored text-based chain-of-thought
(CoT) reasoning for MLLMs, these methods often suffer from limited cross-modal
interaction and increased hallucination, especially with longer videos or
reasoning chains. To address these challenges, we propose Video Intelligence
via Tool-Augmented Learning (VITAL), a novel end-to-end agentic video reasoning
framework. With a visual toolbox, the model can densely sample new video frames
on demand and generate multimodal CoT for precise long video reasoning. We
observe that temporal grounding and question answering are mutually beneficial
for video understanding tasks. Therefore, we construct two high-quality
multi-task video reasoning datasets MTVR-CoT-72k for supervised fine-tuning and
MTVR-RL-110k for reinforcement learning. Moreover, we propose a
Difficulty-aware Group Relative Policy Optimization algorithm (DGRPO) to
mitigate difficulty imbalance in multi-task reinforcement learning. Extensive
experiments on 11 challenging video understanding benchmarks demonstrate the
advanced reasoning ability of VITAL, outperforming existing methods in video
question answering and temporal grounding tasks, especially in long video
scenarios. All code, data and model weight will be made publicly available.

</details>


### [94] [Efficient Inter-Task Attention for Multitask Transformer Models](https://arxiv.org/abs/2508.04422)
*Christian Bohn,Thomas Kurbiel,Klaus Friedrichs,Hasan Tercan,Tobias Meisen*

Main category: cs.CV

TL;DR: 本文提出了一种针对多任务问题的高效Transformer注意力机制方法，有效减少了计算量并提升了任务性能。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在多任务学习场景下由于需要处理更多的Query，Multi-Head-Attention的计算量随着任务数增多呈二次增长，逐渐逼近硬件可承受的极限。

Method: 作者提出了一种新颖的可变形任务间自注意力机制（Deformable Inter-Task Self-Attention），能在多任务模型不同特征图间更高效地聚合信息，从而缓解计算瓶颈。

Result: 在NYUD-v2和PASCAL-Context数据集上，该方法实现了数量级的FLOPs和推理延迟降低，且在各任务预测指标上最多提升了7.4%。

Conclusion: 本文提出的方法不仅大大提高了多任务Transformer模型的推理效率，也有效提升了多任务学习的精度和性能。

Abstract: In both Computer Vision and the wider Deep Learning field, the Transformer
architecture is well-established as state-of-the-art for many applications. For
Multitask Learning, however, where there may be many more queries necessary
compared to single-task models, its Multi-Head-Attention often approaches the
limits of what is computationally feasible considering practical hardware
limitations. This is due to the fact that the size of the attention matrix
scales quadratically with the number of tasks (assuming roughly equal numbers
of queries for all tasks). As a solution, we propose our novel Deformable
Inter-Task Self-Attention for Multitask models that enables the much more
efficient aggregation of information across the feature maps from different
tasks. In our experiments on the NYUD-v2 and PASCAL-Context datasets, we
demonstrate an order-of-magnitude reduction in both FLOPs count and inference
latency. At the same time, we also achieve substantial improvements by up to
7.4% in the individual tasks' prediction quality metrics.

</details>


### [95] [Composed Object Retrieval: Object-level Retrieval via Composed Expressions](https://arxiv.org/abs/2508.04424)
*Tong Wang,Guanyu Yang,Nian Liu,Zongyan Han,Jinxing Zhou,Salman Khan,Fahad Shahbaz Khan*

Main category: cs.CV

TL;DR: 本文提出了一个名为Composed Object Retrieval (COR)的新任务，实现基于用户组合表达式的目标级别检索与分割，并构建了大规模基准数据集COR127K。作者还提出了CORE模型，有效提升了该领域的检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态检索方法大多局限于图像级匹配，无法精确定位特定目标。为提升细粒度和个性化检索能力，亟需突破这种局限，实现对用户意图的更精准满足。

Method: 作者提出COR任务，实现基于参照目标和检索文本组合表达的目标级检索与分割。为此构建了COR127K数据集，并设计了集参照区域编码、自适应视觉-文本交互及区域级对比学习于一体的CORE统一模型。

Result: 大量实验表明，CORE模型在基础类和新颖类的检索任务中均显著优于现有方法，确立了新的有效基线。

Conclusion: CORE模型及COR任务为多模态细粒度检索开辟了新方向，并为后续研究提供了高质量数据集和有效方法。

Abstract: Retrieving fine-grained visual content based on user intent remains a
challenge in multi-modal systems. Although current Composed Image Retrieval
(CIR) methods combine reference images with retrieval texts, they are
constrained to image-level matching and cannot localize specific objects. To
this end, we propose Composed Object Retrieval (COR), a brand-new task that
goes beyond image-level retrieval to achieve object-level precision, allowing
the retrieval and segmentation of target objects based on composed expressions
combining reference objects and retrieval texts. COR presents significant
challenges in retrieval flexibility, which requires systems to identify
arbitrary objects satisfying composed expressions while avoiding semantically
similar but irrelevant negative objects within the same scene. We construct
COR127K, the first large-scale COR benchmark that contains 127,166 retrieval
triplets with various semantic transformations in 408 categories. We also
present CORE, a unified end-to-end model that integrates reference region
encoding, adaptive visual-textual interaction, and region-level contrastive
learning. Extensive experiments demonstrate that CORE significantly outperforms
existing models in both base and novel categories, establishing a simple and
effective baseline for this challenging task while opening new directions for
fine-grained multi-modal retrieval research.

</details>


### [96] [Benchmarking Foundation Models for Mitotic Figure Classification](https://arxiv.org/abs/2508.04441)
*Jonas Ammeling,Jonathan Ganz,Emely Rosbach,Ludwig Lausser,Christof A. Bertram,Katharina Breininger,Marc Aubreville*

Main category: cs.CV

TL;DR: 本文研究利用大规模自监督预训练基础模型，通过低秩适应（LoRA）机制对其进行微调，实现对有丝分裂图像分类任务的高效和鲁棒迁移，仅需10%标注数据即可接近100%数据量时的效果，并显著提升了新肿瘤域的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在医学影像领域常受限于标注数据不足，尤其是在病理图像任务中。作者希望通过自监督预训练的基础模型，缓解特定病理任务中标注稀缺的问题，进一步提升模型在有限数据和新任务环境下的性能与泛化能力。

Method: 作者采用多种主流自监督基础模型，在有丝分裂分类任务上分析数据扩展规律（scaling laws），并比较了传统线性探针法与基于LoRA注意力机制适应的微调方式。所有方法均分别与端到端训练的CNN和Vision Transformer基线进行对比，重点测试在只用小部分标注数据和未见过肿瘤域上的鲁棒性。

Result: 实验表明，使用LoRA微调的基础模型在10%训练数据下即可取得接近使用全部数据时的高性能，并在新肿瘤类型测试集上大幅缩小了性能差距。同时，传统模型完全微调也能取得有竞争力的结果。

Conclusion: LoRA技术显著增强了自监督基础模型在病理图像小样本分类、跨域泛化上的效果，是提升医学影像智能分析的重要方法，但传统终端到端微调方法在部分场景下依然有效。

Abstract: The performance of deep learning models is known to scale with data quantity
and diversity. In pathology, as in many other medical imaging domains, the
availability of labeled images for a specific task is often limited.
Self-supervised learning techniques have enabled the use of vast amounts of
unlabeled data to train large-scale neural networks, i.e., foundation models,
that can address the limited data problem by providing semantically rich
feature vectors that can generalize well to new tasks with minimal training
effort increasing model performance and robustness. In this work, we
investigate the use of foundation models for mitotic figure classification. The
mitotic count, which can be derived from this classification task, is an
independent prognostic marker for specific tumors and part of certain tumor
grading systems. In particular, we investigate the data scaling laws on
multiple current foundation models and evaluate their robustness to unseen
tumor domains. Next to the commonly used linear probing paradigm, we also adapt
the models using low-rank adaptation (LoRA) of their attention mechanisms. We
compare all models against end-to-end-trained baselines, both CNNs and Vision
Transformers. Our results demonstrate that LoRA-adapted foundation models
provide superior performance to those adapted with standard linear probing,
reaching performance levels close to 100% data availability with only 10% of
training data. Furthermore, LoRA-adaptation of the most recent foundation
models almost closes the out-of-domain performance gap when evaluated on unseen
tumor domains. However, full fine-tuning of traditional architectures still
yields competitive performance.

</details>


### [97] [Boosting Visual Knowledge-Intensive Training for LVLMs Through Causality-Driven Visual Object Completion](https://arxiv.org/abs/2508.04453)
*Qingguo Hu,Ante Wang,Jia Song,Delai Qiu,Qingsong Liu,Jinsong Su*

Main category: cs.CV

TL;DR: 本文提出了一种能提升大型视觉语言模型（LVLM）深层视觉感知与推理能力的自我提升框架，基于因果驱动的视觉对象补全（CVC）任务。


<details>
  <summary>Details</summary>
Motivation: 现有LVLM在需要细致视觉感知的任务上表现不佳，部分原因是指令微调用的数据集缺乏视觉知识，导致模型视觉理解与推理能力有限。

Method: 作者设计了一种新颖的CVC任务，要求模型根据可见信息与被掩盖物体的因果关系推断被隐藏物体。通过自动化管道大规模合成训练样本，无需高级LVLM或人工标注。模型通过试错学习自我提升视觉推理能力。

Result: 在四项具挑战性的视觉推理任务和四个主流基准评测中，新方法均取得了显著提升；特别是在专用任务上，LLaVA-1.5-7B与LLaVA-1.5-13B分别提升了5.4%和4.0%。

Conclusion: 因果驱动的视觉补全任务结合自我提升训练，可大幅增强LVLM的深层视觉理解与推理能力，为改进视觉语言模型提供了有效途径。

Abstract: Large Vision-Language Models (LVLMs) have experienced significant
advancements in recent years. However, their performance still falls short in
tasks requiring deep visual perception, such as identifying subtle differences
between images. A potential cause is the scarcity of visual knowledge in
popular instruction-tuning corpora, resulting in inadequate visual perception
and reasoning capabilities. To address this challenge, we introduce a
self-improvement framework grounded in a novel visual knowledge-intensive task,
\underline{C}ausality-driven \underline{V}isual object \underline{C}ompletion
(CVC). This task requires LVLMs to infer the masked object in an image based on
its \textit{causal} relationships with the other visible information. We first
obtain rich examples cheaply through our automated instance construction
pipeline, without relying on sophisticated LVLMs (\textit{e.g.}, GPT-4V) or
human assistance. Then, LVLMs effectively self-improve through trial and error
learning using these created instances. Our experiments demonstrate substantial
gains across four challenging specialized tasks and four widely-used
comprehensive benchmarks. Especially on specialized tasks, our method achieves
an average improvement of 5.4\% and 4.0\% compared to the corresponding
baselines when utilizing LLaVA-1.5-7B and LLaVA-1.5-13B, respectively. The code
is available at https://github.com/XMUDeepLIT/CVC.

</details>


### [98] [4DVD: Cascaded Dense-view Video Diffusion Model for High-quality 4D Content Generation](https://arxiv.org/abs/2508.04467)
*Shuzhou Yang,Xiaodong Cun,Xiaoyu Li,Yaowei Li,Jian Zhang*

Main category: cs.CV

TL;DR: 4DVD提出了一种分阶段的4D视频生成扩散模型，通过先生成粗多视图布局，再进行结构感知生成，实现高质量的4D内容生产。


<details>
  <summary>Details</summary>
Motivation: 直接生成4D等高维数据复杂度极高，现有方法在处理多视角和时间序列上存在效率低、表现不理想的问题。因此需要新的解耦方法，提高质量和实用性。

Method: 4DVD模型分为两步：第一步用单目视频预测稠密多视角布局，保证视角和时序一致性；第二步通过结构感知的时空生成分支，融合粗结构和详细外观，实现高质量稠密视图视频；同时提出了新的动态3D对象数据集用于训练。

Result: 实验显示4DVD在新视角合成和4D生成任务上都达到了当前最优表现。

Conclusion: 4DVD有效降低了4D内容生成难度，并提升了质量，促进了4D显式表达的实际应用潜力。

Abstract: Given the high complexity of directly generating high-dimensional data such
as 4D, we present 4DVD, a cascaded video diffusion model that generates 4D
content in a decoupled manner. Unlike previous multi-view video methods that
directly model 3D space and temporal features simultaneously with stacked cross
view/temporal attention modules, 4DVD decouples this into two subtasks: coarse
multi-view layout generation and structure-aware conditional generation, and
effectively unifies them. Specifically, given a monocular video, 4DVD first
predicts the dense view content of its layout with superior cross-view and
temporal consistency. Based on the produced layout priors, a structure-aware
spatio-temporal generation branch is developed, combining these coarse
structural priors with the exquisite appearance content of input monocular
video to generate final high-quality dense-view videos. Benefit from this,
explicit 4D representation~(such as 4D Gaussian) can be optimized accurately,
enabling wider practical application. To train 4DVD, we collect a dynamic 3D
object dataset, called D-Objaverse, from the Objaverse benchmark and render 16
videos with 21 frames for each object. Extensive experiments demonstrate our
state-of-the-art performance on both novel view synthesis and 4D generation.
Our project page is https://4dvd.github.io/

</details>


### [99] [Zero-Residual Concept Erasure via Progressive Alignment in Text-to-Image Model](https://arxiv.org/abs/2508.04472)
*Hongxu Chen,Zhen Wang,Taoran Mei,Lin Li,Bowei Zhu,Runshi Li,Long Chen*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的闭式概念擦除方法ErasePro，有效提升了预训练文本到图像模型中有害语义概念的擦除效果，并在保证生成质量的同时，实现更彻底的无害化处理。


<details>
  <summary>Details</summary>
Motivation: 现有概念擦除方法虽能减少模型生成有害内容，但常出现擦除不完全和生成质量下降的问题，特别是在面对复杂文本提示和参数更新集中于深层时。这促使作者探索更彻底且保留生成质量的解决方案。

Method: ErasePro引入“零残差约束”至优化目标，确保有害概念与锚定（无害）概念特征的完全对齐，实现彻底擦除。同时，采用渐进式分层参数更新策略，从浅层到深层逐步转移目标概念特征，有效减少对深层的干扰，提升生成图像的整体质量。

Result: 在实例、艺术风格、敏感内容等多项擦除任务上，ErasePro在彻底擦除目标概念的同时，更好地保持了模型的图像生成质量，性能优于主流现有方法。

Conclusion: ErasePro克服了传统方法擦除不彻底和生成质量下降的弊端，为安全、高质量的文本到图像生成模型去除有害概念提供了一种高效新方案。

Abstract: Concept Erasure, which aims to prevent pretrained text-to-image models from
generating content associated with semantic-harmful concepts (i.e., target
concepts), is getting increased attention. State-of-the-art methods formulate
this task as an optimization problem: they align all target concepts with
semantic-harmless anchor concepts, and apply closed-form solutions to update
the model accordingly. While these closed-form methods are efficient, we argue
that existing methods have two overlooked limitations: 1) They often result in
incomplete erasure due to "non-zero alignment residual", especially when text
prompts are relatively complex. 2) They may suffer from generation quality
degradation as they always concentrate parameter updates in a few deep layers.
To address these issues, we propose a novel closed-form method ErasePro: it is
designed for more complete concept erasure and better preserving overall
generative quality. Specifically, ErasePro first introduces a strict
zero-residual constraint into the optimization objective, ensuring perfect
alignment between target and anchor concept features and enabling more complete
erasure. Secondly, it employs a progressive, layer-wise update strategy that
gradually transfers target concept features to those of the anchor concept from
shallow to deep layers. As the depth increases, the required parameter changes
diminish, thereby reducing deviations in sensitive deep layers and preserving
generative quality. Empirical results across different concept erasure tasks
(including instance, art style, and nudity erasure) have demonstrated the
effectiveness of our ErasePro.

</details>


### [100] [QuantVSR: Low-Bit Post-Training Quantization for Real-World Video Super-Resolution](https://arxiv.org/abs/2508.04485)
*Bowen Chai,Zheng Chen,Libo Zhu,Wenbo Li,Yong Guo,Yulun Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种高效的视频超分辨率（VSR）扩散模型低比特量化方法QuantVSR，有效提升推理速度并减少资源消耗，模型性能接近全精度模型。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在现实世界视频超分任务表现优异，但计算速度慢且资源消耗大，难以实际应用。低比特量化能减小模型规模和能耗，但视频模型在时空和高保真度要求下，量化十分困难。

Method: 提出了时空复杂度感知（STCA）机制，根据标定数据集分析每层空间与时间复杂度，分配各层低秩全精度辅助分支，再联合优化全精度和低比特分支；同时提出可学习偏差校正（LBA）模块，减少量化带来的偏差误差。

Result: 在合成和真实数据集上的大量实验验证，该方法性能与全精度模型接近，且明显优于现有主流低比特量化方法。

Conclusion: QuantVSR在保证视频超分辨率高性能的同时，大幅提升了推理效率和资源利用率，具备实际部署的潜力。

Abstract: Diffusion models have shown superior performance in real-world video
super-resolution (VSR). However, the slow processing speeds and heavy resource
consumption of diffusion models hinder their practical application and
deployment. Quantization offers a potential solution for compressing the VSR
model. Nevertheless, quantizing VSR models is challenging due to their temporal
characteristics and high fidelity requirements. To address these issues, we
propose QuantVSR, a low-bit quantization model for real-world VSR. We propose a
spatio-temporal complexity aware (STCA) mechanism, where we first utilize the
calibration dataset to measure both spatial and temporal complexities for each
layer. Based on these statistics, we allocate layer-specific ranks to the
low-rank full-precision (FP) auxiliary branch. Subsequently, we jointly refine
the FP and low-bit branches to achieve simultaneous optimization. In addition,
we propose a learnable bias alignment (LBA) module to reduce the biased
quantization errors. Extensive experiments on synthetic and real-world datasets
demonstrate that our method obtains comparable performance with the FP model
and significantly outperforms recent leading low-bit quantization methods. Code
is available at: https://github.com/bowenchai/QuantVSR.

</details>


### [101] [Learning Robust Intervention Representations with Delta Embeddings](https://arxiv.org/abs/2508.04492)
*Panagiotis Alimisis,Christos Diou*

Main category: cs.CV

TL;DR: 该论文提出了一种新的因果表示学习方法，专注于介入（intervention）在潜在空间中的表征，并通过实验展示该方法在OOD（分布外）环境下的鲁棒性显著提升。


<details>
  <summary>Details</summary>
Motivation: 目前大多数因果表示学习研究侧重于场景中的因果变量识别与建模，较少关注介入本身的表示。该工作认为，更好地对介入进行建模能有效提升模型泛化与鲁棒性，特别是在分布外环境下。

Method: 作者提出了Causal Delta Embedding（因果增量嵌入），即用一种同时对视觉场景不变、且对因果变量受影响稀疏的方式来表征介入（Intervention）。并设计了一个无需额外监督，就可从图像对中学习此因果表示的框架。

Result: 在Causal Triplet挑战和多个合成及现实数据集上，所提方法（Causal Delta Embedding）在OOD任务上大幅超越基线方法。

Conclusion: 关注并有效建模介入在潜在空间中的表示，对于提升因果表示学习模型的泛化与鲁棒性至关重要。所提出的方法显示出极具潜力的性能。

Abstract: Causal representation learning has attracted significant research interest
during the past few years, as a means for improving model generalization and
robustness. Causal representations of interventional image pairs, have the
property that only variables corresponding to scene elements affected by the
intervention / action are changed between the start state and the end state.
While most work in this area has focused on identifying and representing the
variables of the scene under a causal model, fewer efforts have focused on
representations of the interventions themselves. In this work, we show that an
effective strategy for improving out of distribution (OOD) robustness is to
focus on the representation of interventions in the latent space. Specifically,
we propose that an intervention can be represented by a Causal Delta Embedding
that is invariant to the visual scene and sparse in terms of the causal
variables it affects. Leveraging this insight, we propose a framework that is
capable of learning causal representations from image pairs, without any
additional supervision. Experiments in the Causal Triplet challenge demonstrate
that Causal Delta Embeddings are highly effective in OOD settings,
significantly exceeding baseline performance in both synthetic and real-world
benchmarks.

</details>


### [102] [MonoCloth: Reconstruction and Animation of Cloth-Decoupled Human Avatars from Monocular Videos](https://arxiv.org/abs/2508.04505)
*Daisheng Jin,Ying He*

Main category: cs.CV

TL;DR: MonoCloth是一种能够从单目视频中重建和动画化穿衣人类头像的新方法，通过部位分解和衣物模拟显著提升了重建效果与动画真实感。


<details>
  <summary>Details</summary>
Motivation: 单目视频重建三维人类头像面临几何信息有限和非刚性运动复杂的问题，现有方法在视觉质量和真实感上存在不足，尤其是在复杂衣物和局部细节（如面部和手部）的处理上。

Method: 提出了MonoCloth方法，将人物分解为身体、面部、手部和衣物四个部分，分别处理其不同的重建难度和变形复杂性。对面部和手部进行精细建模和几何恢复，对衣物引入专用的布料模拟模块，结合时序运动线索和几何约束，提升衣物变形的自然度。

Result: 实验结果显示，MonoCloth在视觉重建质量和动画真实感方面均超过了现有方法，并且凭借部件式设计，还能支持衣物转移等额外任务，展现了方法的多样性和实用性。

Conclusion: MonoCloth有效解决了单目视频三维人类头像重建中的关键挑战，实现了更高质量的细节与真实感，并具备良好的灵活性和应用前景。

Abstract: Reconstructing realistic 3D human avatars from monocular videos is a
challenging task due to the limited geometric information and complex non-rigid
motion involved. We present MonoCloth, a new method for reconstructing and
animating clothed human avatars from monocular videos. To overcome the
limitations of monocular input, we introduce a part-based decomposition
strategy that separates the avatar into body, face, hands, and clothing. This
design reflects the varying levels of reconstruction difficulty and deformation
complexity across these components. Specifically, we focus on detailed geometry
recovery for the face and hands. For clothing, we propose a dedicated cloth
simulation module that captures garment deformation using temporal motion cues
and geometric constraints. Experimental results demonstrate that MonoCloth
improves both visual reconstruction quality and animation realism compared to
existing methods. Furthermore, thanks to its part-based design, MonoCloth also
supports additional tasks such as clothing transfer, underscoring its
versatility and practical utility.

</details>


### [103] [Skeleton Motion Words for Unsupervised Skeleton-Based Temporal Action Segmentation](https://arxiv.org/abs/2508.04513)
*Uzay Gökay,Federico Spurio,Dominik R. Bach,Juergen Gall*

Main category: cs.CV

TL;DR: 本文提出了一种无监督的基于骨架序列的时序动作分割方法，并在多个数据集上取得了优于现有方法的效果。


<details>
  <summary>Details</summary>
Motivation: 当前基于骨架的动作分割方法大多依赖监督学习，需要昂贵的标注数据，而骨架序列的无监督方法研究较少。作者希望开发一种无需标注、且能高效利用骨架动作数据的分割方法，以增强实际应用中对隐私和鲁棒性的需求。

Method: 作者提出了一种基于序列到序列的时序自编码器，将不同关节的信息在嵌入空间中解耦。随后，将潜在骨架序列划分为不重叠片段并进行量化，生成独特的“骨架运动词”，用于发现有语义意义的动作聚类。

Result: 在HuGaDB、LARa和BABEL三个常用数据集上，作者的方法在无监督时序动作分割任务上取得了超过现有状态的技术效果。

Conclusion: 该方法在无需标注数据的前提下，有效提升了基于骨架序列的动作分割性能，为实际应用提供了新的方向。

Abstract: Current state-of-the-art methods for skeleton-based temporal action
segmentation are predominantly supervised and require annotated data, which is
expensive to collect. In contrast, existing unsupervised temporal action
segmentation methods have focused primarily on video data, while skeleton
sequences remain underexplored, despite their relevance to real-world
applications, robustness, and privacy-preserving nature. In this paper, we
propose a novel approach for unsupervised skeleton-based temporal action
segmentation. Our method utilizes a sequence-to-sequence temporal autoencoder
that keeps the information of the different joints disentangled in the
embedding space. Latent skeleton sequences are then divided into
non-overlapping patches and quantized to obtain distinctive skeleton motion
words, driving the discovery of semantically meaningful action clusters. We
thoroughly evaluate the proposed approach on three widely used skeleton-based
datasets, namely HuGaDB, LARa, and BABEL. The results demonstrate that our
model outperforms the current state-of-the-art unsupervised temporal action
segmentation methods. Code is available at https://github.com/bachlab/SMQ .

</details>


### [104] [RAIDX: A Retrieval-Augmented Generation and GRPO Reinforcement Learning Framework for Explainable Deepfake Detection](https://arxiv.org/abs/2508.04524)
*Tianxiao Li,Zhenglin Huang,Haiquan Wen,Yiwei He,Shuchang Lyu,Baoyuan Wu,Guangliang Cheng*

Main category: cs.CV

TL;DR: RAIDX提出了一种结合RAG和GRPO的新颖深度伪造检测框架，实现了高准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前深度伪造检测缺乏决策可解释性，且现有方法依赖人工标注，限制了可靠性和效率。

Method: 提出RAIDX框架，结合了RAG用于引入外部知识以提升检测准确率，结合GRPO自主生成细粒度的解释文本和显著性图，无需大量人工标注。

Result: 在多个基准测试上，RAIDX在真假鉴别及解释性输出（文本和显著性图）方面表现突出，取得了最先进的检测效果。

Conclusion: RAIDX是第一个将RAG和GRPO结合的统一框架，在提升检测精度的同时，极大增强了检测过程的透明度和可解释性。

Abstract: The rapid advancement of AI-generation models has enabled the creation of
hyperrealistic imagery, posing ethical risks through widespread misinformation.
Current deepfake detection methods, categorized as face specific detectors or
general AI-generated detectors, lack transparency by framing detection as a
classification task without explaining decisions. While several LLM-based
approaches offer explainability, they suffer from coarse-grained analyses and
dependency on labor-intensive annotations. This paper introduces RAIDX
(Retrieval-Augmented Image Deepfake Detection and Explainability), a novel
deepfake detection framework integrating Retrieval-Augmented Generation (RAG)
and Group Relative Policy Optimization (GRPO) to enhance detection accuracy and
decision explainability. Specifically, RAIDX leverages RAG to incorporate
external knowledge for improved detection accuracy and employs GRPO to
autonomously generate fine-grained textual explanations and saliency maps,
eliminating the need for extensive manual annotations. Experiments on multiple
benchmarks demonstrate RAIDX's effectiveness in identifying real or fake, and
providing interpretable rationales in both textual descriptions and saliency
maps, achieving state-of-the-art detection performance while advancing
transparency in deepfake identification. RAIDX represents the first unified
framework to synergize RAG and GRPO, addressing critical gaps in accuracy and
explainability. Our code and models will be publicly available.

</details>


### [105] [No Masks Needed: Explainable AI for Deriving Segmentation from Classification](https://arxiv.org/abs/2508.04534)
*Mosong Ma,Tania Stathaki,Michalis Lazarou*

Main category: cs.CV

TL;DR: 本论文提出了一种结合了可解释性AI的医学图像分割新方法，通过微调预训练模型，显著提升了在多种医学图像数据集上的分割效果。


<details>
  <summary>Details</summary>
Motivation: 现有无监督分割方法虽然在一般计算机视觉标准数据集上效果良好，但在医学图像领域表现不佳。作者旨在为医学图像分割问题探索更高效、更准确的解决方式。

Method: 该方法主要通过对普通视觉预训练模型进行面向医学影像的微调，并融合可解释性AI生成的相关性分数，从而提升分割性能。

Result: 在CBIS-DDSM、NuInsSeg和Kvasir-SEG等多个医学图像数据集上，本文方法分割精度优于传统和现有方法，展现了通用预训练模型适应医学领域的潜力。

Conclusion: 将预训练模型与可解释性AI技术结合，能够克服传统方法在医学影像领域的短板，是提升自动化医学图像分割的重要方向。

Abstract: Medical image segmentation is vital for modern healthcare and is a key
element of computer-aided diagnosis. While recent advancements in computer
vision have explored unsupervised segmentation using pre-trained models, these
methods have not been translated well to the medical imaging domain. In this
work, we introduce a novel approach that fine-tunes pre-trained models
specifically for medical images, achieving accurate segmentation with extensive
processing. Our method integrates Explainable AI to generate relevance scores,
enhancing the segmentation process. Unlike traditional methods that excel in
standard benchmarks but falter in medical applications, our approach achieves
improved results on datasets like CBIS-DDSM, NuInsSeg and Kvasir-SEG.

</details>


### [106] [TopKD: Top-scaled Knowledge Distillation](https://arxiv.org/abs/2508.04539)
*Qi Wang,Jinjia Zhou*

Main category: cs.CV

TL;DR: 作者提出了一种名为Top-scaled Knowledge Distillation（TopKD）的方法，通过专注于教师网络logit的Top-K信息，提升了知识蒸馏的效果。该方法简单、高效，适用于多种网络结构，并在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法多专注于特征层面，忽视了教师模型输出（logit分布）中的关键信息，特别是前K大的logit值所蕴含的重要知识。作者认为挖掘Top-K logits可进一步提升学生模型性能。

Method: TopKD包括两个核心模块：（1）Top-K Scaling Module（TSM）：自适应地放大最有信息量的Top-K logits；（2）Top-K Decoupled Loss（TDL）：对Top-K logits提供有针对性的监督。该方法无需新增复杂结构，可平滑集成现有KD流程。

Result: 在CIFAR-100、ImageNet、STL-10和Tiny-ImageNet等数据集上的实验表明，TopKD在各种基础上均优于现有主流知识蒸馏方法。同时对Vision Transformers等不同架构的蒸馏效果也很明显。

Conclusion: TopKD证明了教师模型logit的Top-K信息对于知识蒸馏具有极大价值，提出的方式高效、通用，可推动知识蒸馏领域的发展。

Abstract: Recent advances in knowledge distillation (KD) predominantly emphasize
feature-level knowledge transfer, frequently overlooking critical information
embedded within the teacher's logit distributions. In this paper, we revisit
logit-based distillation and reveal an underexplored yet critical element:
Top-K knowledge. Motivated by this insight, we propose Top-scaled Knowledge
Distillation (TopKD), a simple, efficient, and architecture-agnostic framework
that significantly enhances logit-based distillation. TopKD consists of two
main components: (1) a Top-K Scaling Module (TSM), which adaptively amplifies
the most informative logits, and (2) a Top-K Decoupled Loss (TDL), which offers
targeted and effective supervision. Notably, TopKD integrates seamlessly into
existing KD methods without introducing extra modules or requiring
architectural changes. Extensive experiments on CIFAR-100, ImageNet, STL-10,
and Tiny-ImageNet demonstrate that TopKD consistently surpasses
state-of-the-art distillation methods. Moreover, our method demonstrates
substantial effectiveness when distilling Vision Transformers, underscoring its
versatility across diverse network architectures. These findings highlight the
significant potential of logits to advance knowledge distillation.

</details>


### [107] [InceptoFormer: A Multi-Signal Neural Framework for Parkinson's Disease Severity Evaluation from Gait](https://arxiv.org/abs/2508.04540)
*Safwen Naimi,Arij Said,Wassim Bouachir,Guillaume-Alexandre Bilodeau*

Main category: cs.CV

TL;DR: 提出了InceptoFormer，一种结合Inception1D和Transformer的多信号神经网络，用于通过步态动力学分析帕金森病严重程度，准确率达96.6%。


<details>
  <summary>Details</summary>
Motivation: 当前基于步态动力学分析的帕金森病分级方法在捕捉多尺度时序特征及长距离依赖上存在不足，且分级数据分布不均衡，影响模型准确性。

Method: 设计1D版Inception网络提取多尺度步态时序特征，并引入Transformer框架建模步态序列的长距离依赖。此外，采用过采样的数据处理策略来改善分级类别分布不均衡问题。

Result: InceptoFormer在帕金森病严重程度评估中获得了96.6%的准确率，显著优于现有先进方法。

Conclusion: 所提出的方法能有效捕捉步态信号中的细粒度和全局动态特征，极大提升了帕金森病分级的分类性能，对于临床评估具有重要意义。

Abstract: We present InceptoFormer, a multi-signal neural framework designed for
Parkinson's Disease (PD) severity evaluation via gait dynamics analysis. Our
architecture introduces a 1D adaptation of the Inception model, which we refer
to as Inception1D, along with a Transformer-based framework to stage PD
severity according to the Hoehn and Yahr (H&Y) scale. The Inception1D component
captures multi-scale temporal features by employing parallel 1D convolutional
filters with varying kernel sizes, thereby extracting features across multiple
temporal scales. The transformer component efficiently models long-range
dependencies within gait sequences, providing a comprehensive understanding of
both local and global patterns. To address the issue of class imbalance in PD
severity staging, we propose a data structuring and preprocessing strategy
based on oversampling to enhance the representation of underrepresented
severity levels. The overall design enables to capture fine-grained temporal
variations and global dynamics in gait signal, significantly improving
classification performance for PD severity evaluation. Through extensive
experimentation, InceptoFormer achieves an accuracy of 96.6%, outperforming
existing state-of-the-art methods in PD severity assessment. The source code
for our implementation is publicly available at
https://github.com/SafwenNaimi/InceptoFormer

</details>


### [108] [Hierarchical Event Memory for Accurate and Low-latency Online Video Temporal Grounding](https://arxiv.org/abs/2508.04546)
*Minghang Zheng,Yuxin Peng,Benyuan Sun,Yi Yang,Yang Liu*

Main category: cs.CV

TL;DR: 本文研究了在线视频流中的时序定位任务（OnVTG），即在不观察未来帧的前提下，根据文本查询实时定位视频中的目标事件。提出了基于事件的分层记忆结构及预测机制，显著提升了模型表现。


<details>
  <summary>Details</summary>
Motivation: 当前OnVTG方法只利用近期帧特征，缺乏长期事件建模和记忆，导致无法有效捕捉较长时间跨度内的目标事件核心信息。由于在线视频持续流入，存储所有历史帧不切实际，如何高效建模和利用历史信息成为关键挑战。

Method: 提出了一种事件驱动的分层记忆机制，将历史视频按事件分段，长短结合保留事件级信息。模型依据事件建议生成的proposal进行预测，结合未来预测分支，提前判断目标事件是否即将到来，并回归事件起始时间。

Result: 所提方法在TACoS、ActivityNet Captions和MAD数据集上均取得了当前最优的性能。

Conclusion: 通过引入分层事件记忆机制和实时未来预测分支，模型既能利用长时历史信息，又具备实时预测能力，显著提升了OnVTG任务的效果。

Abstract: In this paper, we tackle the task of online video temporal grounding (OnVTG),
which requires the model to locate events related to a given text query within
a video stream. Unlike regular video temporal grounding, OnVTG requires the
model to make predictions without observing future frames. As online videos are
streaming inputs and can go on indefinitely, it is impractical and inefficient
to store all historical inputs. The existing OnVTG models employ memory to
store recent historical video frame features and predict scores indicating
whether the current frame corresponds to the start or end time of the target
event. However, these methods lack effective event modeling and cannot retain
long-term historical information, leading to low performance. To tackle these
challenges, we propose a hierarchical event memory for OnVTG. We propose an
event-based OnVTG framework that makes predictions based on event proposals
that model event-level information with various durations. To preserve
historically valuable event information, we introduce a hierarchical event
memory that retains historical events, allowing the model to access both recent
and long-term information. To enable the real-time prediction, we further
propose a future prediction branch that predicts whether the target event will
occur shortly and further regresses the start time of the event. We achieve
state-of-the-art performance on the TACoS, ActivityNet Captions, and MAD
datasets. Code is available at https://github.com/minghangz/OnVTG.

</details>


### [109] [MSC: A Marine Wildlife Video Dataset with Grounded Segmentation and Clip-Level Captioning](https://arxiv.org/abs/2508.04549)
*Quang-Trung Truong,Yuk-Kwan Wong,Vo Hoang Kim Tuyen Dang,Rinaldi Gotama,Duc Thanh Nguyen,Sai-Kit Yeung*

Main category: cs.CV

TL;DR: 本文提出了一种面向海洋对象的视频描述新流程，并发布了包含视频、文本及分割掩码的大规模数据集，以提升海洋视频理解与生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视频描述数据集主要聚焦于通用场景或以人为中心，难以有效支持对复杂动态海洋环境和海洋生命的理解与分析，因此亟需针对海洋领域的更专业工具与数据。

Method: 提出了一个两阶段的面向海洋对象的视频描述流程：首先利用视频、描述文本和分割掩码三元组来实现更有效的视觉定位和内容生成；其次，创新性引入视频切分技术，检测场景变化中的显著对象过渡，以丰富描述语义。

Result: 该方法推动了海洋视频的理解和自动描述效果提升，对海洋视频生成也有积极促进作用，并通过新的评测基准和公开数据集为社区提供了重要资源。

Conclusion: 利用三元组数据以及视频切分机制，显著提升了海洋环境下视频自动描述的精度和泛化性，为相关研究和应用提供了新思路和基础支撑。

Abstract: Marine videos present significant challenges for video understanding due to
the dynamics of marine objects and the surrounding environment, camera motion,
and the complexity of underwater scenes. Existing video captioning datasets,
typically focused on generic or human-centric domains, often fail to generalize
to the complexities of the marine environment and gain insights about marine
life. To address these limitations, we propose a two-stage marine
object-oriented video captioning pipeline. We introduce a comprehensive video
understanding benchmark that leverages the triplets of video, text, and
segmentation masks to facilitate visual grounding and captioning, leading to
improved marine video understanding and analysis, and marine video generation.
Additionally, we highlight the effectiveness of video splitting in order to
detect salient object transitions in scene changes, which significantly enrich
the semantics of captioning content. Our dataset and code have been released at
https://msc.hkustvgd.com.

</details>


### [110] [Two-Way Garment Transfer: Unified Diffusion Framework for Dressing and Undressing Synthesis](https://arxiv.org/abs/2508.04551)
*Angang Zhang,Fang Deng,Hao Chen,Zhongjian Chen,Junyan Li*

Main category: cs.CV

TL;DR: 本文提出了一种双向服装转换模型（TWGTM），首次统一地处理虚拟试穿（VTON）和虚拟去穿（VTOFF）两大任务，并在多个公开数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多将虚拟试穿与虚拟去穿分别独立处理，忽略了二者互为补充、对称的关系，导致整体服装迁移与重建能力受限，因此需要构建能够同时处理两个任务的统一框架。

Method: 作者提出了双向服装转换模型（TWGTM），通过特征双向解耦，同时利用参考图像的潜在空间和像素空间条件指导，实现VTON和VTOFF的协同推理。为解决二者在掩码依赖上的不对称性，提出了逐步训练策略以桥接不同的训练模式。

Result: 在DressCode和VITON-HD两个数据集上，模型在定性和定量评测中均表现优越，充分说明所提方法的有效性与竞争力。

Conclusion: TWGTM首次实现了服装为中心的双向图像合成，为统一虚拟试穿与去穿任务提供了新的解决思路，并在实际评测中取得了良好效果。

Abstract: While recent advances in virtual try-on (VTON) have achieved realistic
garment transfer to human subjects, its inverse task, virtual try-off (VTOFF),
which aims to reconstruct canonical garment templates from dressed humans,
remains critically underexplored and lacks systematic investigation. Existing
works predominantly treat them as isolated tasks: VTON focuses on garment
dressing while VTOFF addresses garment extraction, thereby neglecting their
complementary symmetry. To bridge this fundamental gap, we propose the Two-Way
Garment Transfer Model (TWGTM), to the best of our knowledge, the first unified
framework for joint clothing-centric image synthesis that simultaneously
resolves both mask-guided VTON and mask-free VTOFF through bidirectional
feature disentanglement. Specifically, our framework employs dual-conditioned
guidance from both latent and pixel spaces of reference images to seamlessly
bridge the dual tasks. On the other hand, to resolve the inherent mask
dependency asymmetry between mask-guided VTON and mask-free VTOFF, we devise a
phased training paradigm that progressively bridges this modality gap.
Extensive qualitative and quantitative experiments conducted across the
DressCode and VITON-HD datasets validate the efficacy and competitive edge of
our proposed approach.

</details>


### [111] [Augmentation-based Domain Generalization and Joint Training from Multiple Source Domains for Whole Heart Segmentation](https://arxiv.org/abs/2508.04552)
*Franz Thaler,Darko Stern,Gernot Plank,Martin Urschler*

Main category: cs.CV

TL;DR: 本文提出了一种能够在多模态（CT和MR）数据下进行全心脏语义分割的方法，特别关注如何缓解数据分布转移导致的性能下降问题。通过联合均衡训练和强数据增强，方法在MR和CT数据上均取得了高精度分割结果，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球死亡的主要原因，因此从医学影像中自动、准确地分析心脏结构对于个性化诊疗和病理分析有重要意义。然而，不同影像模态（如CT、MR）以及不同来源数据间存在分布差异，导致深度学习方法在实际应用中面临泛化和性能下降的难题。

Method: (1) 利用来自不同源的CT与MR数据，采用均衡联合训练策略，保证多模态下的模型泛化能力；(2) 采用强度和空间的大幅度数据增强，增加训练数据多样性以缓解测试分布转移；(3) 最终采用5折集成模型提升稳定性和精度。

Result: 方法在MR数据上达到最优分割性能，在CT数据上与单独训练CT模型相当，具体指标为：CT数据DSC为93.33%，ASSD为0.8388mm；MR数据DSC为89.30%，ASSD为1.2411mm。整体优于传统单模态训练方法。

Conclusion: 提出的方法能在实际多模态应用场景下，有效实现全心脏结构的高精度分割，具备生成患者专属心脏数字孪生模型的潜力，推动个性化治疗和模拟进一步发展。

Abstract: As the leading cause of death worldwide, cardiovascular diseases motivate the
development of more sophisticated methods to analyze the heart and its
substructures from medical images like Computed Tomography (CT) and Magnetic
Resonance (MR). Semantic segmentations of important cardiac structures that
represent the whole heart are useful to assess patient-specific cardiac
morphology and pathology. Furthermore, accurate semantic segmentations can be
used to generate cardiac digital twin models which allows e.g.
electrophysiological simulation and personalized therapy planning. Even though
deep learning-based methods for medical image segmentation achieved great
advancements over the last decade, retaining good performance under domain
shift -- i.e. when training and test data are sampled from different data
distributions -- remains challenging. In order to perform well on domains known
at training-time, we employ a (1) balanced joint training approach that
utilizes CT and MR data in equal amounts from different source domains.
Further, aiming to alleviate domain shift towards domains only encountered at
test-time, we rely on (2) strong intensity and spatial augmentation techniques
to greatly diversify the available training data. Our proposed whole heart
segmentation method, a 5-fold ensemble with our contributions, achieves the
best performance for MR data overall and a performance similar to the best
performance for CT data when compared to a model trained solely on CT. With
93.33% DSC and 0.8388 mm ASSD for CT and 89.30% DSC and 1.2411 mm ASSD for MR
data, our method demonstrates great potential to efficiently obtain accurate
semantic segmentations from which patient-specific cardiac twin models can be
generated.

</details>


### [112] [One Model For All: Partial Diffusion for Unified Try-On and Try-Off in Any Pose](https://arxiv.org/abs/2508.04559)
*Jinxi Liu,Zijian He,Guangrun Wang,Guanbin Li,Liang Lin*

Main category: cs.CV

TL;DR: 该论文提出了一种统一的扩散模型OMFA，实现了无需展示服装和分割掩码的虚拟试穿与脱衣，同时支持任意姿态转换，极大提升了实际应用的灵活性和效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的虚拟试衣方法受限于展览服装、分割掩码和固定姿态，难以满足用户对服装随意转换和姿态变化的实际需求，因此需要一种更通用、灵活的方法解决上述限制。

Method: 提出OMFA统一扩散框架，利用创新的部分扩散（partial diffusion）策略，对输入中的服装、人物形象和面部等组件选择性地加噪和去噪，实现灵活的子任务控制和高效的双向衣物-人物变换；通过SMPL-X姿态调控，仅用一张人像和目标姿态即可支持多视角、任意姿态试穿，无需掩码或多姿态图片。

Result: OMFA在虚拟试穿与脱衣的多个任务上，通过大量实验验证，取得了当前最新的结果，显示了其在实际应用中的泛化能力和优越性。

Conclusion: OMFA框架无需掩码与展览服装，支持用户在任意姿态下进行衣物转移和虚拟穿搭，实现了虚拟服装合成领域的通用型和实用性突破。

Abstract: Recent diffusion-based approaches have made significant advances in
image-based virtual try-on, enabling more realistic and end-to-end garment
synthesis. However, most existing methods remain constrained by their reliance
on exhibition garments and segmentation masks, as well as their limited ability
to handle flexible pose variations. These limitations reduce their practicality
in real-world scenarios-for instance, users cannot easily transfer garments
worn by one person onto another, and the generated try-on results are typically
restricted to the same pose as the reference image. In this paper, we introduce
\textbf{OMFA} (\emph{One Model For All}), a unified diffusion framework for
both virtual try-on and try-off that operates without the need for exhibition
garments and supports arbitrary poses. For example, OMFA enables removing
garments from a source person (try-off) and transferring them onto a target
person (try-on), while also allowing the generated target to appear in novel
poses-even without access to multi-pose images of that person. OMFA is built
upon a novel \emph{partial diffusion} strategy that selectively applies noise
and denoising to individual components of the joint input-such as the garment,
the person image, or the face-enabling dynamic subtask control and efficient
bidirectional garment-person transformation. The framework is entirely
mask-free and requires only a single portrait and a target pose as input,
making it well-suited for real-world applications. Additionally, by leveraging
SMPL-X-based pose conditioning, OMFA supports multi-view and arbitrary-pose
try-on from just one image. Extensive experiments demonstrate that OMFA
achieves state-of-the-art results on both try-on and try-off tasks, providing a
practical and generalizable solution for virtual garment synthesis. The project
page is here: https://onemodelforall.github.io/.

</details>


### [113] [Drone Detection with Event Cameras](https://arxiv.org/abs/2508.04564)
*Gabriele Magrini,Lorenzo Berlincioni,Luca Cultrera,Federico Becattini,Pietro Pala*

Main category: cs.CV

TL;DR: 本文综述了事件相机在无人机检测与反制中的应用进展，强调其在安全与低延迟反无人机系统中的独特优势。


<details>
  <summary>Details</summary>
Motivation: 无人机扩散带来许多安全与监管难题，传统基于帧的摄像头在检测小型、高速灵活动目标时易受运动模糊与光照条件影响，检测性能有限。亟需新型视觉技术提升检测可靠性。

Method: 本文系统性回顾了事件视觉领域在无人机检测方面的最新研究进展，包括数据表示、利用脉冲神经网络的处理流程、先进的实时检测、跟踪、轨迹预测和螺旋桨特征识别等技术，以及相关数据集和系统比较。

Result: 事件相机能极大减少运动模糊，在极端光照下依旧保持高检测性能，并因稀疏异步输出能抑制静态背景，低延迟响应运动特征。相关方法在无人机检测与跟踪等任务上表现优异。

Conclusion: 事件视觉技术为构建新一代高效、低延迟且可靠的反无人机系统提供了坚实基础，展现出较传统视觉检测方案更强的适应性和效率。

Abstract: The diffusion of drones presents significant security and safety challenges.
Traditional surveillance systems, particularly conventional frame-based
cameras, struggle to reliably detect these targets due to their small size,
high agility, and the resulting motion blur and poor performance in challenging
lighting conditions. This paper surveys the emerging field of event-based
vision as a robust solution to these problems. Event cameras virtually
eliminate motion blur and enable consistent detection in extreme lighting.
Their sparse, asynchronous output suppresses static backgrounds, enabling
low-latency focus on motion cues. We review the state-of-the-art in event-based
drone detection, from data representation methods to advanced processing
pipelines using spiking neural networks. The discussion extends beyond simple
detection to cover more sophisticated tasks such as real-time tracking,
trajectory forecasting, and unique identification through propeller signature
analysis. By examining current methodologies, available datasets, and the
distinct advantages of the technology, this work demonstrates that event-based
vision provides a powerful foundation for the next generation of reliable,
low-latency, and efficient counter-UAV systems.

</details>


### [114] [TAlignDiff: Automatic Tooth Alignment assisted by Diffusion-based Transformation Learning](https://arxiv.org/abs/2508.04565)
*Yunbi Liu,Enqi Tang,Shiyu Li,Lei Ma,Juncheng Li,Shu Lou,Yongchu Pan,Qingshan Liu*

Main category: cs.CV

TL;DR: 该论文提出了一种称为TAlignDiff的新型正畸牙齿排列自动化方法，结合了点云回归与扩散模型进行牙齿对齐，实现了更准确的牙齿位置预测。


<details>
  <summary>Details</summary>
Motivation: 目前深度学习方法主要通过点到点几何约束预测变换矩阵，但忽视了变换矩阵在口腔解剖结构中的分布特征，导致对牙齿排列问题存在一定局限性。作者因此提出新方法来提升预测准确性。

Method: 方法包括点云回归主网络（PRN）与基于扩散模型的变换矩阵去噪模块（DTMD），融合点云与扩散式变换学习于同一框架，实现几何约束与扩散优化的双向反馈。

Result: 通过大量消融实验和对比实验，验证了新方法的有效性和优越性，提升了牙齿排列的自动化与精度。

Conclusion: TAlignDiff方法在正畸牙齿排列领域展示出较大的潜力，有助于提升正畸治疗的智能化和效果。

Abstract: Orthodontic treatment hinges on tooth alignment, which significantly affects
occlusal function, facial aesthetics, and patients' quality of life. Current
deep learning approaches predominantly concentrate on predicting transformation
matrices through imposing point-to-point geometric constraints for tooth
alignment. Nevertheless, these matrices are likely associated with the
anatomical structure of the human oral cavity and possess particular
distribution characteristics that the deterministic point-to-point geometric
constraints in prior work fail to capture. To address this, we introduce a new
automatic tooth alignment method named TAlignDiff, which is supported by
diffusion-based transformation learning. TAlignDiff comprises two main
components: a primary point cloud-based regression network (PRN) and a
diffusion-based transformation matrix denoising module (DTMD).
Geometry-constrained losses supervise PRN learning for point cloud-level
alignment. DTMD, as an auxiliary module, learns the latent distribution of
transformation matrices from clinical data. We integrate point cloud-based
transformation regression and diffusion-based transformation modeling into a
unified framework, allowing bidirectional feedback between geometric
constraints and diffusion refinement. Extensive ablation and comparative
experiments demonstrate the effectiveness and superiority of our method,
highlighting its potential in orthodontic treatment.

</details>


### [115] [CLASP: Cross-modal Salient Anchor-based Semantic Propagation for Weakly-supervised Dense Audio-Visual Event Localization](https://arxiv.org/abs/2508.04566)
*Jinxing Zhou,Ziheng Zhou,Yanghao Zhou,Yuxin Mao,Zhangling Duan,Dan Guo*

Main category: cs.CV

TL;DR: 该论文提出了一种在弱监督条件下进行稠密音视频事件定位（W-DAVEL）的方法，通过挖掘跨模态显著锚点，实现无时间边界标签下的准确事件定位，实验证明方法优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有DAVEL任务大多依赖于精确的事件时间边界标签，然而实际应用中常常只能获得视频级别标签。因此，如何在弱监督（仅有视频级标签，无事件边界）下实现精准音视频事件定位成为一个重要且具挑战性的问题。

Method: 作者提出了一套新颖的框架：首先定义“跨模态显著锚点”（即在弱监督下被准确预测且音视频模态语义高度一致的时间点）；然后利用“互信息事件一致性评价”模块度量音频和视觉预测类别的一致性，生成锚点得分；再通过全局和局部机制筛选显著锚点；最后利用锚点特征实现时序语义的传播和增强，从而提升定位效果。

Result: 在UnAV-100和ActivityNet1.3两个数据集上建立了W-DAVEL基准，通过大量实验表明所提出的方法在弱监督下达到了当前最优性能。

Conclusion: 该工作首次系统性地研究了弱监督下的DAVEL任务，并通过跨模态显著锚点和特征传播机制显著提升了事件定位效果，为实际应用场景下音视频事件分析提供了有效的新方案。

Abstract: The Dense Audio-Visual Event Localization (DAVEL) task aims to temporally
localize events in untrimmed videos that occur simultaneously in both the audio
and visual modalities. This paper explores DAVEL under a new and more
challenging weakly-supervised setting (W-DAVEL task), where only video-level
event labels are provided and the temporal boundaries of each event are
unknown. We address W-DAVEL by exploiting \textit{cross-modal salient anchors},
which are defined as reliable timestamps that are well predicted under weak
supervision and exhibit highly consistent event semantics across audio and
visual modalities. Specifically, we propose a \textit{Mutual Event Agreement
Evaluation} module, which generates an agreement score by measuring the
discrepancy between the predicted audio and visual event classes. Then, the
agreement score is utilized in a \textit{Cross-modal Salient Anchor
Identification} module, which identifies the audio and visual anchor features
through global-video and local temporal window identification mechanisms. The
anchor features after multimodal integration are fed into an
\textit{Anchor-based Temporal Propagation} module to enhance event semantic
encoding in the original temporal audio and visual features, facilitating
better temporal localization under weak supervision. We establish benchmarks
for W-DAVEL on both the UnAV-100 and ActivityNet1.3 datasets. Extensive
experiments demonstrate that our method achieves state-of-the-art performance.

</details>


### [116] [DDTracking: A Deep Generative Framework for Diffusion MRI Tractography with Streamline Local-Global Spatiotemporal Modeling](https://arxiv.org/abs/2508.04568)
*Yijie Li,Wei Zhang,Xi Zhu,Ye Wu,Yogesh Rathi,Lauren J. O'Donnell,Fan Zhang*

Main category: cs.CV

TL;DR: DDTracking是一种用于扩散磁共振成像（dMRI）纤维束追踪的新型深度生成模型，利用条件扩散模型，结合局部空间与全局时序编码，实现准确且泛化性强的纤维追踪，优于当前主流方法。


<details>
  <summary>Details</summary>
Motivation: 现有的dMRI纤维追踪方法存在结构细节捕捉不足、远距离一致性差和泛化能力有限等问题。因此，需要一种更高效、准确且适应性强的新方法。

Method: 作者提出了DDTracking框架，核心包括双路径编码网络（分别处理局部细节和全局时序依赖）和条件扩散模型模块。该方法端到端学习，通过局部与全局特征融合，预测纤维追踪走向。

Result: 在ISMRM Challenge与TractoInferno两个有真实标签的基准数据集上，DDTracking显著优于领先的纤维追踪方法，并在不同健康状态、年龄、扫描协议及设备下展现了良好泛化性。

Conclusion: DDTracking作为一种端到端、可扩展且适应性强的纤维追踪方案，提升了dMRI追踪的准确性和稳健性，为广泛的临床和科研应用提供了有力工具。

Abstract: This paper presents DDTracking, a novel deep generative framework for
diffusion MRI tractography that formulates streamline propagation as a
conditional denoising diffusion process. In DDTracking, we introduce a
dual-pathway encoding network that jointly models local spatial encoding
(capturing fine-scale structural details at each streamline point) and global
temporal dependencies (ensuring long-range consistency across the entire
streamline). Furthermore, we design a conditional diffusion model module, which
leverages the learned local and global embeddings to predict streamline
propagation orientations for tractography in an end-to-end trainable manner. We
conduct a comprehensive evaluation across diverse, independently acquired dMRI
datasets, including both synthetic and clinical data. Experiments on two
well-established benchmarks with ground truth (ISMRM Challenge and
TractoInferno) demonstrate that DDTracking largely outperforms current
state-of-the-art tractography methods. Furthermore, our results highlight
DDTracking's strong generalizability across heterogeneous datasets, spanning
varying health conditions, age groups, imaging protocols, and scanner types.
Collectively, DDTracking offers anatomically plausible and robust tractography,
presenting a scalable, adaptable, and end-to-end learnable solution for broad
dMRI applications. Code is available at:
https://github.com/yishengpoxiao/DDtracking.git

</details>


### [117] [Knowledge to Sight: Reasoning over Visual Attributes via Knowledge Decomposition for Abnormality Grounding](https://arxiv.org/abs/2508.04572)
*Jun Li,Che Liu,Wenjia Bai,Mingxuan Liu,Rossella Arcucci,Cosmin I. Bercea,Julia A. Schnabel*

Main category: cs.CV

TL;DR: 本文提出了K2Sight方法，通过将临床概念分解为可解释的视觉属性（如形状、密度、解剖位置），以结构化语义监督提升医学图像异常定位能力，从而实现用极少数据训练小模型也能优于主流医学多模态大模型。


<details>
  <summary>Details</summary>
Motivation: 传统的通用视觉-语言大模型（VLMs）在医学领域难以精准定位异常，因为专业术语稀有、组合复杂、与视觉模式对齐不好。而专用医学多模态模型虽然有效，但对标注和算力要求很高，资源消耗大，难以广泛应用。

Method: 提出K2Sight框架，将医学临床概念拆解为形状、密度、解剖位置等基础视觉属性，并根据领域本体构建简明提示词，将其引导为训练时的区域-文本对齐监督，实现结构化语义指导。相较传统仅基于报告级别的监督方式，显式连接专业知识与空间结构，提升数据利用效率。

Result: 仅使用1.5%的主流医学VLM所需数据，训练出0.23B和2B参数量级的小模型，在mAP_50等指标上取得与或超越7B+大模型的效果，最高提升达9.82%。

Conclusion: K2Sight能以极高的数据与模型效率，实现医学图像异常精准定位，降低医学VLM对大数据及大算力依赖，具有良好推广价值。

Abstract: In this work, we address the problem of grounding abnormalities in medical
images, where the goal is to localize clinical findings based on textual
descriptions. While generalist Vision-Language Models (VLMs) excel in natural
grounding tasks, they often struggle in the medical domain due to rare,
compositional, and domain-specific terms that are poorly aligned with visual
patterns. Specialized medical VLMs address this challenge via large-scale
domain pretraining, but at the cost of substantial annotation and computational
resources. To overcome these limitations, we propose \textbf{Knowledge to Sight
(K2Sight)}, a framework that introduces structured semantic supervision by
decomposing clinical concepts into interpretable visual attributes, such as
shape, density, and anatomical location. These attributes are distilled from
domain ontologies and encoded into concise instruction-style prompts, which
guide region-text alignment during training. Unlike conventional report-level
supervision, our approach explicitly bridges domain knowledge and spatial
structure, enabling data-efficient training of compact models. We train compact
models with 0.23B and 2B parameters using only 1.5\% of the data required by
state-of-the-art medical VLMs. Despite their small size and limited training
data, these models achieve performance on par with or better than 7B+ medical
VLMs, with up to 9.82\% improvement in $mAP_{50}$. Code and models:
\href{https://lijunrio.github.io/K2Sight/}{\textcolor{SOTAPink}{https://lijunrio.github.io/K2Sight/}}.

</details>


### [118] [Visual Bias and Interpretability in Deep Learning for Dermatological Image Analysis](https://arxiv.org/abs/2508.04573)
*Enam Ahmed Taufik,Abdullah Khondoker,Antara Firoz Parsa,Seraj Al Mahmud Mostafa*

Main category: cs.CV

TL;DR: 本文提出了一种基于深度学习的多分类皮肤疾病诊断框架，并系统评估了三种图像预处理方法与多种模型的组合效果。研究发现，采用RGB预处理和DinoV2模型可取得最佳性能。


<details>
  <summary>Details</summary>
Motivation: 皮肤疾病诊断面临高类别相似度、同类变异性大和病变纹理复杂等挑战。虽然深度学习辅助诊断有潜力，但其表现高度依赖于图像预处理和模型结构，因此亟需系统性分析以推动CAD系统精准且可解释化发展。

Method: 本研究提出了一种深度学习多分类皮肤疾病分类框架，对标准RGB、CMY颜色空间转换和CLAHE三种图像预处理方法进行系统评估。并选用DenseNet201、Efficient-NetB5等预训练卷积神经网络和ViT、Swin Transformer、DinoV2 Large等Transformer类模型，以准确率和F1值作为评估指标。

Result: 实验结果显示，DinoV2模型结合RGB预处理时，在准确率（最高可达93%）和F1分数上均表现最佳。Grad-CAM可视化进一步验证了模型对病变区域的精准定位和解释能力。

Conclusion: 选择合适的图像预处理方法和模型结构对提升皮肤疾病辅助诊断系统的可靠性与可解释性至关重要。DinoV2与RGB预处理的结合为构建健壮且可解释的皮肤CAD系统提供了有力依据。

Abstract: Accurate skin disease classification is a critical yet challenging task due
to high inter-class similarity, intra-class variability, and complex lesion
textures. While deep learning-based computer-aided diagnosis (CAD) systems have
shown promise in automating dermatological assessments, their performance is
highly dependent on image pre-processing and model architecture. This study
proposes a deep learning framework for multi-class skin disease classification,
systematically evaluating three image pre-processing techniques: standard RGB,
CMY color space transformation, and Contrast Limited Adaptive Histogram
Equalization (CLAHE). We benchmark the performance of pre-trained convolutional
neural networks (DenseNet201, Efficient-NetB5) and transformer-based models
(ViT, Swin Transformer, DinoV2 Large) using accuracy and F1-score as evaluation
metrics. Results show that DinoV2 with RGB pre-processing achieves the highest
accuracy (up to 93%) and F1-scores across all variants. Grad-CAM visualizations
applied to RGB inputs further reveal precise lesion localization, enhancing
interpretability. These findings underscore the importance of effective
pre-processing and model choice in building robust and explainable CAD systems
for dermatology.

</details>


### [119] [Face-voice Association in Multilingual Environments (FAME) 2026 Challenge Evaluation Plan](https://arxiv.org/abs/2508.04592)
*Marta Moscati,Ahmed Abdullah,Muhammad Saad Saeed,Shah Nawaz,Rohan Kumar Das,Muhammad Zaigham Zaheer,Junaid Mir,Muhammad Haroon Yousaf,Khalid Malik,Markus Schedl*

Main category: cs.CV

TL;DR: 本文介绍了FAME 2026挑战赛，旨在探究多语种环境下的人脸-声音关联，并提供了挑战详情、数据集(MAV-Celeb)、基线模型及任务说明。


<details>
  <summary>Details</summary>
Motivation: 近年来，基于人脸与声音间独特关联的相关研究受到重视，尤其是在实际应用普遍涉及多语种交流的背景下。由于全球约一半人口为双语者，传统语音-视觉系统在单一语言环境下的局限性促使该方向研究。

Method: 此次挑战使用MAV-Celeb多语种音视频数据集，参与者需基于该数据集进行人脸与声音的关联建模。报告介绍了比赛的设计框架、任务定义和基线模型。

Result: 报告主要为挑战机制和资源介绍，目前未涉及具体实验结果或性能数据。

Conclusion: 通过本次挑战，推动在多语种环境下人脸与声音关联识别的技术进步，丰富和完善现有多模态识别系统研究基础。

Abstract: The advancements of technology have led to the use of multimodal systems in
various real-world applications. Among them, audio-visual systems are among the
most widely used multimodal systems. In the recent years, associating face and
voice of a person has gained attention due to the presence of unique
correlation between them. The Face-voice Association in Multilingual
Environments (FAME) 2026 Challenge focuses on exploring face-voice association
under the unique condition of a multilingual scenario. This condition is
inspired from the fact that half of the world's population is bilingual and
most often people communicate under multilingual scenarios. The challenge uses
a dataset named Multilingual Audio-Visual (MAV-Celeb) for exploring face-voice
association in multilingual environments. This report provides the details of
the challenge, dataset, baseline models, and task details for the FAME
Challenge.

</details>


### [120] [Pseudo Depth Meets Gaussian: A Feed-forward RGB SLAM Baseline](https://arxiv.org/abs/2508.04597)
*Linqing Zhao,Xiuwei Xu,Yirui Wang,Hao Wang,Wenzhao Zheng,Yansong Tang,Haibin Yan,Jiwen Lu*

Main category: cs.CV

TL;DR: 本文提出了一种用于从无姿态RGB视频流中增量恢复三维几何体的新方法，在不依赖深度传感器和长时间优化的情况下，大幅提升了重建速度，并与现有最优方法效果相当。


<details>
  <summary>Details</summary>
Motivation: 传统基于端到端或视觉SLAM的方法在处理长序列或者在缺乏深度信息时效果有限，且往往依赖慢速的测试时优化或深度传感器。作者希望解决这些依赖和效率瓶颈，实现对普通RGB流的高效、实时三维重建。

Method: 作者在RGB-D SLAM系统中集成深度估计，但发现预测深度的几何精度有限。进一步地，他们采用3D Gaussian mapping来提升几何恢复质量。最终提出结合基于3D Gaussian的SLAM和时序预测模块（通过光流直接前馈推理相机姿态），取代了传统的慢速优化。并引入局部图渲染技术以增强姿态预测鲁棒性。

Result: 在Replica和TUM-RGBD数据集上的实验，以及实际部署演示表明，该方法在重建效果上与SOTA方法SplaTAM持平，但跟踪速度提升了90%以上。

Conclusion: 所提方法在不中断速度和精度的前提下，能高效实现RGB序列的三维重建，极大降低了匹配和跟踪耗时，为实际场景部署奠定基础。

Abstract: Incrementally recovering real-sized 3D geometry from a pose-free RGB stream
is a challenging task in 3D reconstruction, requiring minimal assumptions on
input data. Existing methods can be broadly categorized into end-to-end and
visual SLAM-based approaches, both of which either struggle with long sequences
or depend on slow test-time optimization and depth sensors. To address this, we
first integrate a depth estimator into an RGB-D SLAM system, but this approach
is hindered by inaccurate geometric details in predicted depth. Through further
investigation, we find that 3D Gaussian mapping can effectively solve this
problem. Building on this, we propose an online 3D reconstruction method using
3D Gaussian-based SLAM, combined with a feed-forward recurrent prediction
module to directly infer camera pose from optical flow. This approach replaces
slow test-time optimization with fast network inference, significantly
improving tracking speed. Additionally, we introduce a local graph rendering
technique to enhance robustness in feed-forward pose prediction. Experimental
results on the Replica and TUM-RGBD datasets, along with a real-world
deployment demonstration, show that our method achieves performance on par with
the state-of-the-art SplaTAM, while reducing tracking time by more than 90\%.

</details>


### [121] [How Does Bilateral Ear Symmetry Affect Deep Ear Features?](https://arxiv.org/abs/2508.04614)
*Kagan Ozturk,Deeksha Arun,Kevin W. Bowyer,Patrick Flynn*

Main category: cs.CV

TL;DR: 本论文研究了耳朵双侧对称性在基于CNN的耳朵识别中的影响，并提出通过区分左右耳进行训练和测试可显著提升识别性能。


<details>
  <summary>Details</summary>
Motivation: 虽然基于CNN的耳朵识别取得了较好效果，但此前很少有研究关注左右耳对称性对特征学习的影响。为提升性能并更好理解对称性因素，有必要系统研究左右耳信息在训练和测试环节中的作用。

Method: 作者首先设计了一个自动判别左右耳的分类器，然后在五个大规模数据集上，比较了在训练和测试阶段分别考虑和不考虑左右耳信息的识别效果。同时，进行了对齐策略、输入尺寸、超参数等消融实验。

Result: 实验显示，分别对待左右耳训练和测试能够显著提升CNN耳朵识别系统的性能。此外，消融实验为更优的系统训练提供了实用建议。

Conclusion: 将左右耳信息纳入CNN耳朵识别流程不仅能提升准确率，也为大规模实际应用提供了有效的数据处理和系统训练方法，推动耳朵识别研究进一步发展。

Abstract: Ear recognition has gained attention as a reliable biometric technique due to
the distinctive characteristics of human ears. With the increasing availability
of large-scale datasets, convolutional neural networks (CNNs) have been widely
adopted to learn features directly from raw ear images, outperforming
traditional hand-crafted methods. However, the effect of bilateral ear symmetry
on the features learned by CNNs has received little attention in recent
studies. In this paper, we investigate how bilateral ear symmetry influences
the effectiveness of CNN-based ear recognition. To this end, we first develop
an ear side classifier to automatically categorize ear images as either left or
right. We then explore the impact of incorporating this side information during
both training and test. Cross-dataset evaluations are conducted on five
datasets. Our results suggest that treating left and right ears separately
during training and testing can lead to notable performance improvements.
Furthermore, our ablation studies on alignment strategies, input sizes, and
various hyperparameter settings provide practical insights into training
CNN-based ear recognition systems on large-scale datasets to achieve higher
verification rates.

</details>


### [122] [FinMMR: Make Financial Numerical Reasoning More Multimodal, Comprehensive, and Challenging](https://arxiv.org/abs/2508.04625)
*Zichen Tang,Haihong E,Jiacheng Liu,Zhongjun Yang,Rongjin Li,Zihua Rong,Haoyang He,Zhuodi Hao,Xinyang Hu,Kun Ji,Ziyan Ma,Mengyuan Ji,Jun Zhang,Chenghao Ma,Qianhe Zheng,Yang Liu,Yiling Huang,Xinyi Hu,Qing Huang,Zijian Xie,Shiyao Peng*

Main category: cs.CV

TL;DR: FinMMR是一个专为金融数值推理任务设计的中英双语多模态基准，用于评测多模态大语言模型（MLLMs）的推理能力，涵盖丰富题型和金融子领域，通过综合文本和复杂图像，对模型提出更高挑战。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在金融推理领域缺乏高质量、有挑战性的测评数据集，且现有基准多以文本为主，难以评估模型在融合文本和多样化金融图像时的推理能力。因此，作者希望推动MLLMs在现实金融场景的推理能力提升。

Method: 将现有金融推理基准题转化为多模态问题，并从最新中文金融研究报告中构建新题，最终汇总为含4.3K问题和8.7K图像、横跨14类金融细分领域的大型数据集。问题涉及表格、柱状图、股权结构图等，要求模型需融合金融知识，对复杂的文本和图像进行多步、精确推理。

Result: 在FinMMR上测试的最佳MLLM在最难题型（Hard problems）上的准确率仅为53.0%。

Conclusion: FinMMR极大提升了金融推理基准的多模态性和难度，可以促进MLLMs推理能力的进步，对实际金融应用有推动作用。

Abstract: We present FinMMR, a novel bilingual multimodal benchmark tailored to
evaluate the reasoning capabilities of multimodal large language models (MLLMs)
in financial numerical reasoning tasks. Compared to existing benchmarks, our
work introduces three significant advancements. (1) Multimodality: We
meticulously transform existing financial reasoning benchmarks, and construct
novel questions from the latest Chinese financial research reports. FinMMR
comprises 4.3K questions and 8.7K images spanning 14 categories, including
tables, bar charts, and ownership structure charts. (2) Comprehensiveness:
FinMMR encompasses 14 financial subdomains, including corporate finance,
banking, and industry analysis, significantly exceeding existing benchmarks in
financial domain knowledge breadth. (3) Challenge: Models are required to
perform multi-step precise numerical reasoning by integrating financial
knowledge with the understanding of complex financial images and text. The
best-performing MLLM achieves only 53.0% accuracy on Hard problems. We believe
that FinMMR will drive advancements in enhancing the reasoning capabilities of
MLLMs in real-world scenarios.

</details>


### [123] [EncQA: Benchmarking Vision-Language Models on Visual Encodings for Charts](https://arxiv.org/abs/2508.04650)
*Kushin Mukherjee,Donghao Ren,Dominik Moritz,Yannick Assogba*

Main category: cs.CV

TL;DR: 提出了面向图表理解的全新基准EncQA，系统考查不同视觉编码和分析任务，发现现有多模态视觉语言模型在细粒度能力上存在显著短板，提升模型大小并不能解决所有问题。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态视觉语言模型在图表理解上一些基准上的表现不断提升，但这些进步并未充分反映真实的可视化推理能力。现有评测未全面覆盖图表中的多种视觉编码方式及分析任务。

Method: 提出了EncQA基准，涵盖六种视觉编码（位置、长度、面积、定量色彩、定性色彩、形状）和八种图表任务，制造2076个合成问答对，全面系统地检验模型图表理解能力，并用该基准对九个SOTA模型进行评测。

Result: 模型在同一任务的不同视觉编码间、或不同任务间表现差异大，多数情况下提升模型参数规模对细粒度任务的提升有限，许多任务—编码对依然表现不佳。

Conclusion: 提升图表理解能力需有针对性地弥合具体视觉推理短板，单纯扩大模型或数据规模难以有效解决问题，呼吁更精细化、针对性的能力提升方向。

Abstract: Multimodal vision-language models (VLMs) continue to achieve ever-improving
scores on chart understanding benchmarks. Yet, we find that this progress does
not fully capture the breadth of visual reasoning capabilities essential for
interpreting charts. We introduce EncQA, a novel benchmark informed by the
visualization literature, designed to provide systematic coverage of visual
encodings and analytic tasks that are crucial for chart understanding. EncQA
provides 2,076 synthetic question-answer pairs, enabling balanced coverage of
six visual encoding channels (position, length, area, color quantitative, color
nominal, and shape) and eight tasks (find extrema, retrieve value, find
anomaly, filter values, compute derived value exact, compute derived value
relative, correlate values, and correlate values relative). Our evaluation of 9
state-of-the-art VLMs reveals that performance varies significantly across
encodings within the same task, as well as across tasks. Contrary to
expectations, we observe that performance does not improve with model size for
many task-encoding pairs. Our results suggest that advancing chart
understanding requires targeted strategies addressing specific visual reasoning
gaps, rather than solely scaling up model or dataset size.

</details>


### [124] [X-SAM: From Segment Anything to Any Segmentation](https://arxiv.org/abs/2508.04655)
*Hao Wang,Limeng Qiao,Zequn Jie,Zhijian Huang,Chengjian Feng,Qingfang Zheng,Lin Ma,Xiangyuan Lan,Xiaodan Liang*

Main category: cs.CV

TL;DR: 本文提出了一种新的多模态大语言模型（MLLM）框架X-SAM，通过统一方法提升细粒度像素级感知理解，支持任意分割任务，并表现出领先性能。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）虽具备广泛知识表示能力，但在像素级视觉理解方面存在天生短板。主流的Segment Anything Model（SAM）虽在视觉驱动分割领域取得进展，但在多掩码预测、类别敏感分割等任务以及统一分割模型架构方面存在局限。研究动机在于突破上述分割模型的限制，提升MLLM的像素级视觉理解能力。

Method: 作者提出X-SAM模型，设计了一个统一的多模态大语言模型框架，支持更高阶的像素级感知，包括新定义的Visual GrounDed（VGD）分割任务。VGD任务通过交互式视觉提示，实现对所有实例目标的分割，赋予模型视觉定位和像素级解释能力。同时，作者提出统一训练策略，实现跨多数据集的协同训练。

Result: X-SAM在多项图像分割基准测试上达到了最新最好结果，效能突出，充分展示了其在多模态、像素级视觉理解任务中的优越性。

Conclusion: X-SAM模型有效克服了以往分割模型的缺点，为多模态大语言模型在像素级视觉理解和任意分割任务上提供了有效解决方案，推动了相关研究领域的发展。

Abstract: Large Language Models (LLMs) demonstrate strong capabilities in broad
knowledge representation, yet they are inherently deficient in pixel-level
perceptual understanding. Although the Segment Anything Model (SAM) represents
a significant advancement in visual-prompt-driven image segmentation, it
exhibits notable limitations in multi-mask prediction and category-specific
segmentation tasks, and it cannot integrate all segmentation tasks within a
unified model architecture. To address these limitations, we present X-SAM, a
streamlined Multimodal Large Language Model (MLLM) framework that extends the
segmentation paradigm from \textit{segment anything} to \textit{any
segmentation}. Specifically, we introduce a novel unified framework that
enables more advanced pixel-level perceptual comprehension for MLLMs.
Furthermore, we propose a new segmentation task, termed Visual GrounDed (VGD)
segmentation, which segments all instance objects with interactive visual
prompts and empowers MLLMs with visual grounded, pixel-wise interpretative
capabilities. To enable effective training on diverse data sources, we present
a unified training strategy that supports co-training across multiple datasets.
Experimental results demonstrate that X-SAM achieves state-of-the-art
performance on a wide range of image segmentation benchmarks, highlighting its
efficiency for multimodal, pixel-level visual understanding. Code is available
at https://github.com/wanghao9610/X-SAM.

</details>


### [125] [YOLOv8-Based Deep Learning Model for Automated Poultry Disease Detection and Health Monitoring paper](https://arxiv.org/abs/2508.04658)
*Akhil Saketh Reddy Sabbella,Ch. Lakshmi Prachothan,Eswar Kumar Panta*

Main category: cs.CV

TL;DR: 研究提出利用YOLO v8深度学习模型，通过分析高分辨率鸡只图片，实时检测鸡只健康状况，实现自动、准确发现疾病迹象。


<details>
  <summary>Details</summary>
Motivation: 家禽业现有疾病检测方法依赖人工观察，效率低且易出错，急需自动化、智能化方案以减少经济损失。

Method: 构建基于YOLO v8的AI系统，使用大量带有标注的鸡只图片数据集进行训练，模型可以识别鸡只行为和外观的异常，从而判定是否感染疾病。

Result: 经训练的模型可实现对感染鸡只的实时精准检测，并能即时向农场操作员发出预警。

Conclusion: 该AI系统无需人为检查，能早期发现感染，提升大型养殖场的生物安全和管理效率。YOLO v8的实时性能为规模化养殖场管理提供了高效、可扩展的解决方案。

Abstract: In the poultry industry, detecting chicken illnesses is essential to avoid
financial losses. Conventional techniques depend on manual observation, which
is laborious and prone to mistakes. Using YOLO v8 a deep learning model for
real-time object recognition. This study suggests an AI based approach, by
developing a system that analyzes high resolution chicken photos, YOLO v8
detects signs of illness, such as abnormalities in behavior and appearance. A
sizable, annotated dataset has been used to train the algorithm, which provides
accurate real-time identification of infected chicken and prompt warnings to
farm operators for prompt action. By facilitating early infection
identification, eliminating the need for human inspection, and enhancing
biosecurity in large-scale farms, this AI technology improves chicken health
management. The real-time features of YOLO v8 provide a scalable and effective
method for improving farm management techniques.

</details>


### [126] [PixCuboid: Room Layout Estimation from Multi-view Featuremetric Alignment](https://arxiv.org/abs/2508.04659)
*Gustav Hanning,Kalle Åström,Viktor Larsson*

Main category: cs.CV

TL;DR: 本文提出了一种名为PixCuboid的新方法，通过多视角深度特征对齐，提升了三维房间结构估计的精度，并在两个新数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 准确估计房间结构对于许多下游任务至关重要，但现有方法大多依赖单视角和全景图像，限制了实际应用。作者希望突破这一局限，实现更为通用和精确的布局估计。

Method: 提出PixCuboid方法，基于多视角下密集深度特征的优化对齐，并在端到端训练过程中促进特征映射生成更优的损失平滑性和大收敛区。同时，引入简单启发式初始化布局。评测中，定义了ScanNet++和2D-3D-Semantics两个新基准数据集，提供手工标注的三维立方体真值。

Result: 实验显示，PixCuboid方法在两个新提出的基准数据集上均大幅优于其他现有方法，验证了多视角优化和深度特征策略的有效性。

Conclusion: PixCuboid不仅在单间房间三维布局估计上取得突破，还可扩展到多房间（如大公寓、办公楼）场景，具备很强的灵活性和实用性。

Abstract: Coarse room layout estimation provides important geometric cues for many
downstream tasks. Current state-of-the-art methods are predominantly based on
single views and often assume panoramic images. We introduce PixCuboid, an
optimization-based approach for cuboid-shaped room layout estimation, which is
based on multi-view alignment of dense deep features. By training with the
optimization end-to-end, we learn feature maps that yield large convergence
basins and smooth loss landscapes in the alignment. This allows us to
initialize the room layout using simple heuristics.
  For the evaluation we propose two new benchmarks based on ScanNet++ and
2D-3D-Semantics, with manually verified ground truth 3D cuboids. In thorough
experiments we validate our approach and significantly outperform the
competition. Finally, while our network is trained with single cuboids, the
flexibility of the optimization-based approach allow us to easily extend to
multi-room estimation, e.g. larger apartments or offices. Code and model
weights are available at https://github.com/ghanning/PixCuboid.

</details>


### [127] [HierarchicalPrune: Position-Aware Compression for Large-Scale Diffusion Models](https://arxiv.org/abs/2508.04663)
*Young D. Kwon,Rui Li,Sijia Li,Da Li,Sourav Bhattacharya,Stylianos I. Venieris*

Main category: cs.CV

TL;DR: 提出了一种名为HierarchicalPrune的新型扩散模型压缩框架，使大规模文本到图像模型能够在算力受限设备上高效部署，同时保持高图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的文本到图像扩散模型参数量巨大（8-11B），导致其难以在资源有限的设备上进行推理，迫切需要有效的模型压缩方法，以便实现广泛应用与实际部署。

Method: 提出了HierarchicalPrune框架，包括三个核心技术：（1）基于模型层级功能差异进行分层剪枝，主要剪去后期对纹理处理的部分块（Hierarchical Position Pruning）；（2）对早期维持语义结构的关键块予以权重保护（Positional Weight Preservation）；（3）根据模块敏感度分布，分层调整知识蒸馏强度（Sensitivity-Guided Distillation）。

Result: 结合INT4量化后，实现了77.5-80.4%的显存占用减少（如从15.8 GB降到3.2 GB），和27.9-38.0%延迟缩短，在生成质量的GenEval分数和HPSv2分数上仅有轻微降低（最低2.6%/7%），而用户主观评测表明，新方法下感知图像质量和原模型几乎持平，且显著优于其它压缩方案。

Conclusion: HierarchicalPrune成功将超大扩散模型压缩到可实用范围，大幅降低显存和延迟的同时，有效保留了生成质量与用户体验，为扩散模型的边缘设备应用奠定基础。

Abstract: State-of-the-art text-to-image diffusion models (DMs) achieve remarkable
quality, yet their massive parameter scale (8-11B) poses significant challenges
for inferences on resource-constrained devices. In this paper, we present
HierarchicalPrune, a novel compression framework grounded in a key observation:
DM blocks exhibit distinct functional hierarchies, where early blocks establish
semantic structures while later blocks handle texture refinements.
HierarchicalPrune synergistically combines three techniques: (1) Hierarchical
Position Pruning, which identifies and removes less essential later blocks
based on position hierarchy; (2) Positional Weight Preservation, which
systematically protects early model portions that are essential for semantic
structural integrity; and (3) Sensitivity-Guided Distillation, which adjusts
knowledge-transfer intensity based on our discovery of block-wise sensitivity
variations. As a result, our framework brings billion-scale diffusion models
into a range more suitable for on-device inference, while preserving the
quality of the output images. Specifically, when combined with INT4 weight
quantisation, HierarchicalPrune achieves 77.5-80.4% memory footprint reduction
(e.g., from 15.8 GB to 3.2 GB) and 27.9-38.0% latency reduction, measured on
server and consumer grade GPUs, with the minimum drop of 2.6% in GenEval score
and 7% in HPSv2 score compared to the original model. Last but not least, our
comprehensive user study with 85 participants demonstrates that
HierarchicalPrune maintains perceptual quality comparable to the original model
while significantly outperforming prior works.

</details>


### [128] [ANPrompt: Anti-noise Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2508.04677)
*Yansheng Gao,Yufei Zheng,Jinghan Qu,Zixi Zhu,Yukuan Zhang,Shengsheng Wang*

Main category: cs.CV

TL;DR: ANPrompt是一种提升视觉-语言模型抗噪能力的高效Prompt Tuning方法，能提升模型在弱语义噪声下的新类别泛化表现。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLM）虽然通过prompt tuning能高效适应新任务，但在面对图像或文本的小幅语义噪声时泛化能力下降，导致性能脆弱，因此需提升VLM对语义噪声的鲁棒性。

Method: ANPrompt提出：构建噪声文本特征，将原始与扰动文本嵌入融合并聚类，生成噪声提示；噪声提示与可学习prompt token结合，生成抗噪prompt，并注入图像和文本编码器的深层；此外，计算视觉编码器输出的prompt token均值，称为抗噪视觉prompt原型（NRVPP）；最后，联合引入WALoss（弱语义噪声对齐损失）、标准交叉熵和sim loss以优化模型。

Result: 在11个基准数据集上的实验结果显示，ANPrompt在鲁棒性与新类别泛化能力方面均优于现有prompt tuning方法。

Conclusion: ANPrompt有效提升VLM对弱语义噪声的鲁棒性，使其更好泛化到未见类别，显示了抗噪Prompt设计对于提升多模态模型实用性的价值。

Abstract: Prompt tuning has emerged as an efficient and effective technique for
adapting vision-language models (VLMs) with low computational overhead.
However, existing methods often overlook the vulnerability of prompt-tuned VLMs
to weak semantic perturbations-such as subtle image or text noise-that degrade
their generalization to unseen classes. To address this limitation, we propose
ANPrompt, a novel prompt tuning framework designed to enhance robustness under
such perturbations. ANPrompt first constructs weak noise text features by
fusing original and noise-perturbed text embeddings, which are then clustered
to form noise prompts. These noise prompts are integrated with learnable prompt
tokens to generate anti-noise prompts, which are injected into the deeper
layers of both image and text encoders. To further capture the noise-aware
visual semantics, ANPrompt computes the Noise-Resistant Visual Prompt Prototype
(NRVPP) by averaging the output prompt tokens from the vision encoder. Finally,
ANPrompt introduces alignment, robustness, and anti-noise objectives by
computing a Weak semantic noise Alignment Loss (WALoss) alongside the standard
cross-entropy and sim loss. Experiments across 11 benchmarks demonstrate that
ANPrompt consistently outperforms existing prompt tuning approaches, achieving
superior robustness to semantic noise and improved generalization to novel
categories.

</details>


### [129] [Perceiving and Acting in First-Person: A Dataset and Benchmark for Egocentric Human-Object-Human Interactions](https://arxiv.org/abs/2508.04681)
*Liang Xu,Chengqun Yang,Zili Lin,Fei Xu,Yifan Liu,Congsheng Xu,Yiyi Zhang,Jie Qin,Xingdong Sheng,Yunhui Liu,Xin Jin,Yichao Yan,Wenjun Zeng,Xiaokang Yang*

Main category: cs.CV

TL;DR: 本文提出了InterVLA，一个面向人机交互的第一人称多模态大规模数据集，用于推动AI助手在真实世界中泛化能力的研究，涵盖丰富的场景、精准的动作及语音指令，并建立了相关基准任务。


<details>
  <summary>Details</summary>
Motivation: 现有数据集多聚焦于单一交互类别，且忽略AI助手实际第一人称视角感知与决策，而通用交互知识与第一人称多模态数据对泛化AI助手的构建至关重要。

Method: 研究将辅助任务融合到视觉-语言-动作框架，搭建RGB-MoCap混合系统，助手和指导者依据GPT生成脚本相互配合、操作物体，并采集了多视角（第一人称、第三人称）、多模态（图像、动作捕捉、语言指令）数据，最终构建了InterVLA数据集。

Result: InterVLA数据集包含11.4小时、120万帧的多模态数据，涵盖2个第一人称与5个第三人称视频，以及高精度的动作数据和指令。同时在第一人称动作估计、交互合成和预测等任务上建立新基准并做了详尽分析。

Conclusion: InterVLA及其基准任务为今后AI助手在物理世界的泛化、感知与交互能力研究提供了新的基础和测试平台，预计将促进该领域的发展。

Abstract: Learning action models from real-world human-centric interaction datasets is
important towards building general-purpose intelligent assistants with
efficiency. However, most existing datasets only offer specialist interaction
category and ignore that AI assistants perceive and act based on first-person
acquisition. We urge that both the generalist interaction knowledge and
egocentric modality are indispensable. In this paper, we embed the
manual-assisted task into a vision-language-action framework, where the
assistant provides services to the instructor following egocentric vision and
commands. With our hybrid RGB-MoCap system, pairs of assistants and instructors
engage with multiple objects and the scene following GPT-generated scripts.
Under this setting, we accomplish InterVLA, the first large-scale
human-object-human interaction dataset with 11.4 hours and 1.2M frames of
multimodal data, spanning 2 egocentric and 5 exocentric videos, accurate
human/object motions and verbal commands. Furthermore, we establish novel
benchmarks on egocentric human motion estimation, interaction synthesis, and
interaction prediction with comprehensive analysis. We believe that our
InterVLA testbed and the benchmarks will foster future works on building AI
agents in the physical world.

</details>


### [130] [TurboTrain: Towards Efficient and Balanced Multi-Task Learning for Multi-Agent Perception and Prediction](https://arxiv.org/abs/2508.04682)
*Zewei Zhou,Seth Z. Zhao,Tianhui Cai,Zhiyu Huang,Bolei Zhou,Jiaqi Ma*

Main category: cs.CV

TL;DR: 提出了TurboTrain框架，通过空间-时间预训练和多任务学习策略，有效简化多智能体系统的端到端训练流程，提升多任务性能并减少人工干预和训练时间。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统端到端训练虽在多任务场景下表现优越，但存在模型训练困难、需手动设计及调试训练流程等难题。该研究旨在优化多智能体感知与预测模型训练的效率及表现，降低复杂度。

Method: TurboTrain包含两大关键部分：1) 基于mask重建的多智能体时空预训练方法，用于捕获多智能体间时空特征；2) 基于梯度冲突抑制的平衡多任务学习策略，协调各任务间的训练。无需手动构建和调优复杂的多阶段训练流程。

Result: 在真实协同驾驶数据集V2XPnP-Seq上测试，TurboTrain在多智能体感知和预测任务上刷新了现有模型表现，将训练流程大大简化，并能有效抽取跨智能体的时空特征，提升下游任务。

Conclusion: TurboTrain不仅能够减少模型训练人工设计和调试的工作量，还能提升多任务表现，对多智能体系统的实际部署和性能具有积极意义。

Abstract: End-to-end training of multi-agent systems offers significant advantages in
improving multi-task performance. However, training such models remains
challenging and requires extensive manual design and monitoring. In this work,
we introduce TurboTrain, a novel and efficient training framework for
multi-agent perception and prediction. TurboTrain comprises two key components:
a multi-agent spatiotemporal pretraining scheme based on masked reconstruction
learning and a balanced multi-task learning strategy based on gradient conflict
suppression. By streamlining the training process, our framework eliminates the
need for manually designing and tuning complex multi-stage training pipelines,
substantially reducing training time and improving performance. We evaluate
TurboTrain on a real-world cooperative driving dataset, V2XPnP-Seq, and
demonstrate that it further improves the performance of state-of-the-art
multi-agent perception and prediction models. Our results highlight that
pretraining effectively captures spatiotemporal multi-agent features and
significantly benefits downstream tasks. Moreover, the proposed balanced
multi-task learning strategy enhances detection and prediction.

</details>


### [131] [BEVCon: Advancing Bird's Eye View Perception with Contrastive Learning](https://arxiv.org/abs/2508.04702)
*Ziyang Leng,Jiawei Yang,Zhicheng Ren,Bolei Zhou*

Main category: cs.CV

TL;DR: 提出BEVCon框架，通过对比学习提升自动驾驶中鸟瞰图（BEV）感知的表现，在现有方法基础上带来性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前BEV感知主要聚焦于编码器和任务头的改进，对表示学习（representation learning）的作用关注较少，有必要通过增强特征表征进一步提升BEV模型性能。

Method: BEVCon包含两个对比学习模块：一个是实例特征对比模块，用于优化BEV特征；另一个是视角对比模块，用于提升图像主干网络。密集对比学习结合检测损失，联合优化BEV编码器和backbone的特征表征。

Result: 在nuScenes数据集上的实验表明，BEVCon在多个任务上实现了持续性能提升，在mAP指标上比SOTA基线高出最高2.4%。

Conclusion: BEVCon证明对比学习和特征表示学习对BEV感知至关重要，为自动驾驶相关任务提供了有力的补充优化途径。

Abstract: We present BEVCon, a simple yet effective contrastive learning framework
designed to improve Bird's Eye View (BEV) perception in autonomous driving. BEV
perception offers a top-down-view representation of the surrounding
environment, making it crucial for 3D object detection, segmentation, and
trajectory prediction tasks. While prior work has primarily focused on
enhancing BEV encoders and task-specific heads, we address the underexplored
potential of representation learning in BEV models. BEVCon introduces two
contrastive learning modules: an instance feature contrast module for refining
BEV features and a perspective view contrast module that enhances the image
backbone. The dense contrastive learning designed on top of detection losses
leads to improved feature representations across both the BEV encoder and the
backbone. Extensive experiments on the nuScenes dataset demonstrate that BEVCon
achieves consistent performance gains, achieving up to +2.4% mAP improvement
over state-of-the-art baselines. Our results highlight the critical role of
representation learning in BEV perception and offer a complementary avenue to
conventional task-specific optimizations.

</details>


### [132] [Occupancy Learning with Spatiotemporal Memory](https://arxiv.org/abs/2508.04705)
*Ziyang Leng,Jiawei Yang,Wenlong Yi,Bolei Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种用于自动驾驶的3D占据表示学习新方法ST-Occ，有效提升了多帧场景的时空感知表现，并在准确性和一致性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前3D占据（occupancy）表征虽有助于自动驾驶环境建模，但难以高效聚合多帧输入的体素信息，且面对高算力消耗和体素的不确定性及动态性带来挑战。作者希望提升跨时序的3D占据感知效率和一致性。

Method: 提出ST-Occ框架，核心包括一个可高效保存完整历史信息的时空记忆模块，以及能动态与当前占据表示联合建模不确定性和动态性的记忆注意力机制，从而高效挖掘多帧输入间的时空依赖。

Result: 实验显示，ST-Occ比当前最优方法提升了3点mIoU，并将时序不一致性减小了29%。

Conclusion: ST-Occ能显著提升3D占据预测任务中的时空表达能力，在自动驾驶等场景中展现出了更高的准确性和一致性，具有较高的实用应用前景。

Abstract: 3D occupancy becomes a promising perception representation for autonomous
driving to model the surrounding environment at a fine-grained scale. However,
it remains challenging to efficiently aggregate 3D occupancy over time across
multiple input frames due to the high processing cost and the uncertainty and
dynamics of voxels. To address this issue, we propose ST-Occ, a scene-level
occupancy representation learning framework that effectively learns the
spatiotemporal feature with temporal consistency. ST-Occ consists of two core
designs: a spatiotemporal memory that captures comprehensive historical
information and stores it efficiently through a scene-level representation and
a memory attention that conditions the current occupancy representation on the
spatiotemporal memory with a model of uncertainty and dynamic awareness. Our
method significantly enhances the spatiotemporal representation learned for 3D
occupancy prediction tasks by exploiting the temporal dependency between
multi-frame inputs. Experiments show that our approach outperforms the
state-of-the-art methods by a margin of 3 mIoU and reduces the temporal
inconsistency by 29%.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [133] [How Deep Is Representational Bias in LLMs? The Cases of Caste and Religion](https://arxiv.org/abs/2508.03712)
*Agrima Seth,Monojit Choudhary,Sunayana Sitaram,Kentaro Toyama,Aditya Vashistha,Kalika Bali*

Main category: cs.CL

TL;DR: 本文系统性审查了GPT-4 Turbo在印度宗教与种姓身份代表性方面的偏见，发现该模型对印度文化主导群体存在显著过度代表，且对多样性提示的响应效果有限。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型代表性偏见研究主要关注于全球北方的身份（如种族和性别），并通常基于单次交互。本文动机在于揭示这些偏见是否也存在于宗教和种姓等较少被关注的维度，特别是针对全球南方国家如印度的人口分布进行系统评估。

Method: 作者设计了鼓励身份多样性的提示，要求GPT-4 Turbo生成约7200个关于印度重要人生事件（如婚礼）的故事。随后将模型输出中有关印度宗教和种姓的代表性，与印度人口普查数据进行对比，量化偏见程度和其“黏性”。

Result: GPT-4 Turbo在宗教与种姓身份上，始终对印度主导群体表现出显著过度代表，即使在提示中明确要求多样性也难以纠正。并发现模型的偏见表现甚至超越了数据分布自身的偏见，且多次提示并不能持续有效改善。

Conclusion: 仅通过丰富训练数据并不能充分纠正大型语言模型的代表性偏见，模型本身的结构和开发机制需要更深层次的改变。

Abstract: Representational bias in large language models (LLMs) has predominantly been
measured through single-response interactions and has focused on Global
North-centric identities like race and gender. We expand on that research by
conducting a systematic audit of GPT-4 Turbo to reveal how deeply encoded
representational biases are and how they extend to less-explored dimensions of
identity. We prompt GPT-4 Turbo to generate over 7,200 stories about
significant life events (such as weddings) in India, using prompts designed to
encourage diversity to varying extents. Comparing the diversity of religious
and caste representation in the outputs against the actual population
distribution in India as recorded in census data, we quantify the presence and
"stickiness" of representational bias in the LLM for religion and caste. We
find that GPT-4 responses consistently overrepresent culturally dominant groups
far beyond their statistical representation, despite prompts intended to
encourage representational diversity. Our findings also suggest that
representational bias in LLMs has a winner-take-all quality that is more biased
than the likely distribution bias in their training data, and repeated
prompt-based nudges have limited and inconsistent efficacy in dislodging these
biases. These results suggest that diversifying training data alone may not be
sufficient to correct LLM bias, highlighting the need for more fundamental
changes in model development. Dataset and Codebook:
https://github.com/agrimaseth/How-Deep-Is-Representational-Bias-in-LLMs

</details>


### [134] [FeynTune: Large Language Models for High-Energy Theory](https://arxiv.org/abs/2508.03716)
*Paul Richmond,Prarit Agarwal,Borun Chowdhury,Vasilis Niarchos,Constantinos Papageorgakis*

Main category: cs.CL

TL;DR: 本文针对理论高能物理领域，通过对Llama-3.1（80亿参数）模型的20个变体进行针对性微调，显著提升了其在高能物理相关文献摘要补全任务上的表现，并对比了不同训练集和主流商用大模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有通用大语言模型在理论高能物理这类专业领域的理解和应用存在局限，因此需要开发更适合该领域的专业大语言模型。

Method: 作者将Llama-3.1模型根据hep-th、hep-ph、gr-qc三类arXiv摘要以及其它不相关领域（例如q-bio、cs等）组成不同训练集，采用两种不同的LoRA（低秩适应）微调方式和不同的数据规模，微调出20个变体进行实验。

Result: 所有专业高能物理模型在hep-th摘要补全任务上均优于未微调的基础模型。文中还将其性能与ChatGPT、Claude、Gemini、DeepSeek等主流商用大模型进行了对比。

Conclusion: 针对理论高能物理构建专用大语言模型，能够显著提升其在专业任务上的能力，并为今后相关模型的开发和应用提供了方法思路和实证基础。

Abstract: We present specialized Large Language Models for theoretical High-Energy
Physics, obtained as 20 fine-tuned variants of the 8-billion parameter
Llama-3.1 model. Each variant was trained on arXiv abstracts (through August
2024) from different combinations of hep-th, hep-ph and gr-qc. For a
comparative study, we also trained models on datasets that contained abstracts
from disparate fields such as the q-bio and cs categories. All models were
fine-tuned using two distinct Low-Rank Adaptation fine-tuning approaches and
varying dataset sizes, and outperformed the base model on hep-th abstract
completion tasks. We compare performance against leading commercial LLMs
(ChatGPT, Claude, Gemini, DeepSeek) and derive insights for further developing
specialized language models for High-Energy Theoretical Physics.

</details>


### [135] [Intent Aware Context Retrieval for Multi-Turn Agricultural Question Answering](https://arxiv.org/abs/2508.03719)
*Abhay Vijayvargia,Ajay Nagpal,Kundeshwar Pundalik,Atharva Savarkar,Smita Gautam,Pankaj Singh,Rohit Saluja,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: 本文提出了一款名为Krishi Sathi的AI农业聊天机器人，利用多轮会话和检索增强生成，为印地语和英语用户提供个性化、易懂的农技咨询，解决了印度农民农业咨询难获取的问题。系统性能优异，准确率和完成率均超过97%。


<details>
  <summary>Details</summary>
Motivation: 印度农民，特别是农村和低文盲群体，缺乏及时、易得且母语友好的农业咨询服务。数字化农业平台常存在语言和识字障碍，难以真正惠及广大农民。

Method: Krishi Sathi基于IFT模型并以印度农业领域知识数据集进行了精调。区别于传统一次性问答型机器人，通过多轮结构化对话逐步收集用户信息，以确保对问题充分理解。采用检索增强生成（RAG）技术，先检索数据库资料再以IFT生成个性化答案。支持印地语和英语，提供语音输入输出，适配低文盲和低数字化能力用户。

Result: 系统在英印双语下，问答准确率达到97.53%，上下文相关性和个性化达91.35%，问题完成率97.53%。平均响应时间不超过6秒，有效保障了及时性。

Conclusion: 本工作通过结合意图识别对话流、指令调优模型及检索增强生成，有效提升了数字农业咨询的质量和可及性，为印度农业数字化转型提供了新思路。

Abstract: Indian farmers often lack timely, accessible, and language-friendly
agricultural advice, especially in rural areas with low literacy. To address
this gap in accessibility, this paper presents a novel AI-powered agricultural
chatbot, Krishi Sathi, designed to support Indian farmers by providing
personalized, easy-to-understand answers to their queries through both text and
speech. The system's intelligence stems from an IFT model, subsequently refined
through fine-tuning on Indian agricultural knowledge across three curated
datasets. Unlike traditional chatbots that respond to one-off questions, Krishi
Sathi follows a structured, multi-turn conversation flow to gradually collect
the necessary details from the farmer, ensuring the query is fully understood
before generating a response. Once the intent and context are extracted, the
system performs Retrieval-Augmented Generation (RAG) by first fetching
information from a curated agricultural database and then generating a tailored
response using the IFT model. The chatbot supports both English and Hindi
languages, with speech input and output features (via ASR and TTS) to make it
accessible for users with low literacy or limited digital skills. This work
demonstrates how combining intent-driven dialogue flows, instruction-tuned
models, and retrieval-based generation can improve the quality and
accessibility of digital agricultural support in India.
  This approach yielded strong results, with the system achieving a query
response accuracy of 97.53%, 91.35% contextual relevance and personalization,
and a query completion rate of 97.53%. The average response time remained under
6 seconds, ensuring timely support for users across both English and Hindi
interactions.

</details>


### [136] [Hierarchical Verification of Speculative Beams for Accelerating LLM Inference](https://arxiv.org/abs/2508.03726)
*Jaydip Sen,Harshitha Puvvala,Subhasis Dasgupta*

Main category: cs.CL

TL;DR: 论文提出了一种新的分层验证树（HVT）框架，用于加速大语言模型的推理过程，显著减少推理时间和能耗，同时保证结果质量。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然在多种自然语言处理任务上表现出色，但由于自回归机制，推理时效率低下。现有的推测性解码和beam sampling虽有改善，但仍存在验证过程低效、资源浪费的问题。作者希望解决这一瓶颈，实现高效推理。

Method: 作者提出分层验证树（HVT）框架，将推测性beam解码重组，通过优先验证高概率序列并对低质量候选进行早期剪枝，从而提高效率。还提出了理论基础及验证-剪枝算法，保证正确性及高效性，并能无缝集成到现有LLM推理流程，无需重新训练或修改模型结构。

Result: 在多组数据集和模型上实验显示，HVT明显优于现有的推测性解码方法，在保持甚至提升输出质量的前提下，大幅降低推理时间和能耗。

Conclusion: 分层验证树框架为大语言模型的高效推理提供了新思路，显示出分层验证策略在加速模型推理方面的重要潜力。

Abstract: Large language models (LLMs) have achieved remarkable success across diverse
natural language processing tasks but face persistent challenges in inference
efficiency due to their autoregressive nature. While speculative decoding and
beam sampling offer notable improvements, traditional methods verify draft
sequences sequentially without prioritization, leading to unnecessary
computational overhead. This work proposes the Hierarchical Verification Tree
(HVT), a novel framework that restructures speculative beam decoding by
prioritizing high-likelihood drafts and enabling early pruning of suboptimal
candidates. Theoretical foundations and a formal verification-pruning algorithm
are developed to ensure correctness and efficiency. Integration with standard
LLM inference pipelines is achieved without requiring retraining or
architecture modification. Experimental evaluations across multiple datasets
and models demonstrate that HVT consistently outperforms existing speculative
decoding schemes, achieving substantial reductions in inference time and energy
consumption while maintaining or enhancing output quality. The findings
highlight the potential of hierarchical verification strategies as a new
direction for accelerating large language model inference.

</details>


### [137] [WINELL: Wikipedia Never-Ending Updating with LLM Agents](https://arxiv.org/abs/2508.03728)
*Revanth Gangi Reddy,Tanay Dixit,Jiaxin Qin,Cheng Qian,Daniel Lee,Jiawei Han,Kevin Small,Xing Fan,Ruhi Sarikaya,Heng Ji*

Main category: cs.CL

TL;DR: 本文提出WiNELL系统，利用多代理框架和精细化编辑模型，持续抓取网络最新信息并自动为Wikipedia条目生成高质量编辑建议，提高百科内容的时效性和覆盖面。


<details>
  <summary>Details</summary>
Motivation: 维基百科内容依赖人工编辑，难以保证信息实时更新。借助NELL持续知识获取的理念和大模型智能体进展，作者希望自动化更新维基百科知识库。

Method: 设计多代理系统，自动聚合在线新信息，对目标实体筛选重要知识，并生成精确编辑建议。编辑模型基于庞大的Wikipedia历史编辑记录训练，模拟人类编辑风格。同时与开源、闭源大模型进行了比较。

Result: 编辑模型在关键信息覆盖率和编辑效率上，优于现有开源指令模型和闭源LLM（如GPT-4o）。端到端实测证明，系统能及时发现和建议Wikipedia高活跃页面的新事实更新。

Conclusion: WiNELL展现了基于LLM智能体自动化持续更新知识库的潜力，为自动维护大型知识平台开辟了新方向。

Abstract: Wikipedia, a vast and continuously consulted knowledge base, faces
significant challenges in maintaining up-to-date content due to its reliance on
manual human editors. Inspired by the vision of continuous knowledge
acquisition in NELL and fueled by advances in LLM-based agents, this paper
introduces WiNELL, an agentic framework for continuously updating Wikipedia
articles. Our approach employs a multi-agent framework to aggregate online
information, select new and important knowledge for a target entity in
Wikipedia, and then generate precise edit suggestions for human review. Our
fine-grained editing models, trained on Wikipedia's extensive history of human
edits, enable incorporating updates in a manner consistent with human editing
behavior. Our editor models outperform both open-source instruction-following
baselines and closed-source LLMs (e.g., GPT-4o) in key information coverage and
editing efficiency. End-to-end evaluation on high-activity Wikipedia pages
demonstrates WiNELL's ability to identify and suggest timely factual updates.
This opens up a promising research direction in LLM agents for automatically
updating knowledge bases in a never-ending fashion.

</details>


### [138] [GanitBench: A bi-lingual benchmark for evaluating mathematical reasoning in Vision Language Models](https://arxiv.org/abs/2508.03737)
*Ashutosh Bandooni,Brindha Subburaj*

Main category: cs.CL

TL;DR: 本文提出了GanitBench——一个专为评估视觉语言模型（VLM）在数学相关任务上推理能力的基准数据集，覆盖英语和印地语。通过对主流VLM模型的测试，发现现有模型在该任务和非英语语言上表现有限。


<details>
  <summary>Details</summary>
Motivation: 当前针对VLM推理的评测数据集多为英语，且印地语数据集主要集中在理解和翻译任务，缺乏面向数学推理的多语种基准。因此，作者希望通过GanitBench补足该空白，推动多语种研究，尤其是印地语。

Method: GanitBench收集自印度两大权威考试（JEE Advanced和CBSE），共1527道仅含视觉要素（含文本及图形）的数学题，涵盖英语和印地语。作者在零样本和双样本链式思考（CoT）设定下，评估了两种闭源VLM模型，并引入“双重锁定”（Double Lock）约束以增加难度。

Result: GPT-4o mini模型在最佳情形下达到了38.15%的平均准确率。随着Double Lock约束的加入，模型表现大幅下降。双样本CoT在此环境下优于零样本，印地语下两模型表现进一步下降。

Conclusion: 当前主流VLM模型在数学视觉推理任务和低资源语言（如印地语）下的表现有限。GanitBench为多语种、多领域VLM推理评测提供了全新挑战，有助于推动相关多语种研究。

Abstract: Benchmarks for evaluating reasoning among Vision Language Models (VLMs) on
several fields and domains are being curated more frequently over the last few
years. However these are often monolingual, mostly available in English.
Additionally there also is a lack of datasets available in Hindi on tasks apart
from comprehension and translation. We introduce GanitBench, a tough benchmark
consisting of 1527 vision-only questions covering several topics in Mathematics
- available in languages English and Hindi. Collected from two major
examinations from India, the JEE Advanced and the CBSE Boards examinations,
this benchmark includes questions in the form of images comprising of figures
essential to a question as well as text. We evaluate two closed source models
for the same, in zero-shot Chain-of-Thought (CoT) and two-shot CoT settings.
GPT-4o mini is found to be the more dominant model on the benchmark, with it's
highest average accuracy being 38.15%. We also evaluate models through a
"Double Lock" constraint, which brings down the performance of the models by
considerable margins. We observe that two-shot CoT appears to be a more
effective setting under this environment. Performance of the two VLMs also
decreases when answering the same questions in the Hindi language. We hope to
facilitate the inclusion of languages like Hindi in research through our work.

</details>


### [139] [AttnTrace: Attention-based Context Traceback for Long-Context LLMs](https://arxiv.org/abs/2508.03793)
*Yanting Wang,Runpeng Geng,Ying Chen,Jinyuan Jia*

Main category: cs.CL

TL;DR: 本文提出了一种基于注意力权重的新型上下文回溯方法 AttnTrace，它比现有方法如 TracLLM 更高效且准确，可追溯LLM响应中最关键的上下文来源，并能显著提升长上下文下的注入检测能力。


<details>
  <summary>Details</summary>
Motivation: 随着长上下文大语言模型（LLM）的普及，系统中需高效解释LLM生成内容背后主要参考的上下文，以增强结果可解释性和安全性。然而，现有回溯方法如 TracLLM 计算成本过高，难以在实际应用中落地。研究动机在于开发一种在保证准确性的同时，大幅减少计算成本的回溯方案。

Method: 作者提出 AttnTrace 方法，核心思想是利用LLM生成过程中的注意力权重，追踪模型响应与上下文的相关性。为此，提出了两项增强技术，并进行了理论分析以论证其合理性。最后，作者在多项任务上系统性评估了该方法。

Result: 实验结果显示 AttnTrace 不仅比 TracLLM 等先进方法更高效，准确率也更高。尤其在长上下文下检测提示注入（prompt injection）任务中，AttnTrace 显著提高了检测效果。同时，实验证明其可准确定位篡改意图的注入指令。

Conclusion: AttnTrace 在上下文回溯和安全检测方面表现优异，兼具高效性和实用性，为LLM内容追溯和防护提供了新的可行方案。研究还公开了源码，便于社区进一步应用和改进。

Abstract: Long-context large language models (LLMs), such as Gemini-2.5-Pro and
Claude-Sonnet-4, are increasingly used to empower advanced AI systems,
including retrieval-augmented generation (RAG) pipelines and autonomous agents.
In these systems, an LLM receives an instruction along with a context--often
consisting of texts retrieved from a knowledge database or memory--and
generates a response that is contextually grounded by following the
instruction. Recent studies have designed solutions to trace back to a subset
of texts in the context that contributes most to the response generated by the
LLM. These solutions have numerous real-world applications, including
performing post-attack forensic analysis and improving the interpretability and
trustworthiness of LLM outputs. While significant efforts have been made,
state-of-the-art solutions such as TracLLM often lead to a high computation
cost, e.g., it takes TracLLM hundreds of seconds to perform traceback for a
single response-context pair. In this work, we propose AttnTrace, a new context
traceback method based on the attention weights produced by an LLM for a
prompt. To effectively utilize attention weights, we introduce two techniques
designed to enhance the effectiveness of AttnTrace, and we provide theoretical
insights for our design choice. We also perform a systematic evaluation for
AttnTrace. The results demonstrate that AttnTrace is more accurate and
efficient than existing state-of-the-art context traceback methods. We also
show that AttnTrace can improve state-of-the-art methods in detecting prompt
injection under long contexts through the attribution-before-detection
paradigm. As a real-world application, we demonstrate that AttnTrace can
effectively pinpoint injected instructions in a paper designed to manipulate
LLM-generated reviews. The code is at
https://github.com/Wang-Yanting/AttnTrace.

</details>


### [140] [Majority Bit-Aware Watermarking For Large Language Models](https://arxiv.org/abs/2508.03829)
*Jiahao Xu,Rui Hu,Zikai Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种更优的多比特水印方法MajorMark及其改进版MajorMark+，在保证生成文本质量的同时，提高了水印解码准确率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在实际应用中的广泛部署带来了生成有害或误导性内容的风险。为追溯内容来源及防止滥用，需要在生成文本中嵌入可识别的信息（水印）。

Method: 提出MajorMark水印方法，根据消息的多数比特动态确定优选token集合，从而扩展可采样的token范围，提升文本质量。同时，引入基于聚类的解码策略，即使优选token集合较大，也能保持高解码准确率。升级版MajorMark+将消息分块并独立编码/解码，每块都可确定性处理，进一步增强性能。

Result: 在多个前沿LLM上的实验显示，MajorMark及MajorMark+在文本生成质量和水印解码准确率上显著优于现有多比特水印基线方法。

Conclusion: MajorMark及其增强版有效解决了多比特水印中质量与准确率的权衡问题，为LLM生成文本的溯源和防滥用提供了更可靠的解决方案。

Abstract: The growing deployment of Large Language Models (LLMs) in real-world
applications has raised concerns about their potential misuse in generating
harmful or deceptive content. To address this issue, watermarking techniques
have emerged as a promising solution by embedding identifiable binary messages
into generated text for origin verification and misuse tracing. While recent
efforts have explored multi-bit watermarking schemes capable of embedding rich
information such as user identifiers, they typically suffer from the
fundamental trade-off between text quality and decoding accuracy: to ensure
reliable message decoding, they have to restrict the size of preferred token
sets during encoding, yet such restrictions reduce the quality of the generated
content. In this work, we propose MajorMark, a novel watermarking method that
improves this trade-off through majority bit-aware encoding. MajorMark selects
preferred token sets based on the majority bit of the message, enabling a
larger and more flexible sampling of tokens. In contrast to prior methods that
rely on token frequency analysis for decoding, MajorMark employs a
clustering-based decoding strategy, which maintains high decoding accuracy even
when the preferred token set is large, thus preserving both content quality and
decoding accuracy. We further introduce MajorMark$^+$, which partitions the
message into multiple blocks to independently encode and deterministically
decode each block, thereby further enhancing the quality of watermarked text
and improving decoding accuracy. Extensive experiments on state-of-the-art LLMs
demonstrate that our methods significantly enhance both decoding accuracy and
text generation quality, outperforming prior multi-bit watermarking baselines.

</details>


### [141] [Hallucination to Truth: A Review of Fact-Checking and Factuality Evaluation in Large Language Models](https://arxiv.org/abs/2508.03860)
*Subhey Sadi Rahman,Md. Adnanul Islam,Md. Mahbub Alam,Musarrat Zeba,Md. Abdur Rahman,Sadia Sultana Chowa,Mohaimenul Azam Khan Raiaan,Sami Azam*

Main category: cs.CL

TL;DR: 本文综述了大语言模型（LLM）事实准确性评估的现状与挑战，强调健全的事实核查体系和定制化策略的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM被广泛应用于各领域，其基于海量网络语料进行训练，难免生成虚假或误导性内容。为了提升LLM实用性与可信度，对其输出的事实性进行评测与改进变得至关重要。

Method: 作者系统梳理了2020-2025年相关领域的文献，分析了LLM事实评估面临的关键挑战，如幻觉现象、数据集限制和评测指标的可靠性，探讨了先进提示、领域微调、RAG（检索增强生成）等方法，并提出五个主要研究问题。

Result: 综述发现，当前指标和数据集存在明显局限，通过外部验证证据对LLM输出进行锚定并结合领域定制方法，有助于提升事实一致性和可靠性。文中还讨论了指令微调、多主体推理与RAG框架在改进事实核查中的作用。

Conclusion: 文章强调建立准确、可解释且适应特定领域的事实核查框架对于提升LLM信任度意义重大。其研究见解有助于推动更加可信和具有情境感知能力的大语言模型的发展。

Abstract: Large Language Models (LLMs) are trained on vast and diverse internet corpora
that often include inaccurate or misleading content. Consequently, LLMs can
generate misinformation, making robust fact-checking essential. This review
systematically analyzes how LLM-generated content is evaluated for factual
accuracy by exploring key challenges such as hallucinations, dataset
limitations, and the reliability of evaluation metrics. The review emphasizes
the need for strong fact-checking frameworks that integrate advanced prompting
strategies, domain-specific fine-tuning, and retrieval-augmented generation
(RAG) methods. It proposes five research questions that guide the analysis of
the recent literature from 2020 to 2025, focusing on evaluation methods and
mitigation techniques. The review also discusses the role of instruction
tuning, multi-agent reasoning, and external knowledge access via RAG
frameworks. Key findings highlight the limitations of current metrics, the
value of grounding outputs with validated external evidence, and the importance
of domain-specific customization to improve factual consistency. Overall, the
review underlines the importance of building LLMs that are not only accurate
and explainable but also tailored for domain-specific fact-checking. These
insights contribute to the advancement of research toward more trustworthy and
context-aware language models.

</details>


### [142] [An Entity Linking Agent for Question Answering](https://arxiv.org/abs/2508.03865)
*Yajie Luo,Yihong Wu,Muzhi Li,Fengran Mo,Jia Ao Sun,Xinyu Wang,Liheng Ma,Yingxue Zhang,Jian-Yun Nie*

Main category: cs.CL

TL;DR: 该论文提出了一种针对问答系统中短文本和歧义性强的问题的实体链接方法，基于大语言模型，通过模拟人类认知流程提升实体链接效果。实验结果表明该方法具备稳健性和高效性。


<details>
  <summary>Details</summary>
Motivation: 当前问答系统中的实体链接方法大多针对长文本，面对用户提出的简短且有歧义性的问题时表现不佳。为解决这一痛点，作者提出了一种适用于短文本问句的实体链接新方法。

Method: 作者设计了一种基于大语言模型的实体链接agent，模拟人类认知工作流，主动识别实体、检索候选实体并做出决策。通过实验对比工具式实体链接及其在问答任务中的表现评估该方法。

Result: 实验结果显示，该实体链接agent在工具式实体链接和问答任务中的表现均优于现有方法，具有较强的鲁棒性和有效性。

Conclusion: 本文方法能够提升短文本问答系统中的实体链接精度，为相关系统提供更准确的信息支持。

Abstract: Some Question Answering (QA) systems rely on knowledge bases (KBs) to provide
accurate answers. Entity Linking (EL) plays a critical role in linking natural
language mentions to KB entries. However, most existing EL methods are designed
for long contexts and do not perform well on short, ambiguous user questions in
QA tasks. We propose an entity linking agent for QA, based on a Large Language
Model that simulates human cognitive workflows. The agent actively identifies
entity mentions, retrieves candidate entities, and makes decision. To verify
the effectiveness of our agent, we conduct two experiments: tool-based entity
linking and QA task evaluation. The results confirm the robustness and
effectiveness of our agent.

</details>


### [143] [Sotopia-RL: Reward Design for Social Intelligence](https://arxiv.org/abs/2508.03905)
*Haofei Yu,Zhengyang Qi,Yining Zhao,Kolby Nottingham,Keyang Xuan,Bodhisattwa Prasad Majumder,Hao Zhu,Paul Pu Liang,Jiaxuan You*

Main category: cs.CL

TL;DR: 本文提出了一种适用于大语言模型（LLMs）社交智能训练的新型强化学习框架Sotopia-RL，通过精细化奖励机制显著提升了模型社交多任务下的表现。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs日益参与到现实社交任务中，具备社交智能显得尤为关键。然而，传统基于MDP的强化学习方法，在面临社交互动中的部分可观测性以及多维行为贡献间接性的情况下，效率低且不稳定。因此，亟需更适用于社交情景的RL训练框架。

Method: Sotopia-RL创新性地将粗粒度的回合奖励细化为发言级别的多维度奖励。通过发言级别的归因，有效缓解了部分可观测性问题；多维度奖励则能够全面刻画社交行为，降低奖励劫持现象。此框架在Sotopia这一开放式的社交学习环境中进行实验验证。

Result: 在Sotopia-hard和Sotopia-full两项评测中，Sotopia-RL分别取得了7.17与8.31的社交目标完成分数，显著优于现有方法。消融实验进一步证实了细粒度归因和多维奖励设计对效果提升至关重要。

Conclusion: Sotopia-RL通过创新性的奖励机制，有效缓解了社交强化学习中的关键难题，提升了LLMs的社交智能表现，并为今后相关研究提供了新的方向和参考。

Abstract: Social intelligence has become a critical capability for large language
models (LLMs), enabling them to engage effectively in real-world social tasks
such as accommodation, persuasion, collaboration, and negotiation.
Reinforcement learning (RL) is a natural fit for training socially intelligent
agents because it allows models to learn sophisticated strategies directly
through social interactions. However, social interactions have two key
characteristics that set barriers for RL training: (1) partial observability,
where utterances have indirect and delayed effects that complicate credit
assignment, and (2) multi-dimensionality, where behaviors such as
rapport-building or knowledge-seeking contribute indirectly to goal
achievement. These characteristics make Markov decision process (MDP)-based RL
with single-dimensional episode-level rewards inefficient and unstable. To
address these challenges, we propose Sotopia-RL, a novel framework that refines
coarse episode-level feedback into utterance-level, multi-dimensional rewards.
Utterance-level credit assignment mitigates partial observability by
attributing outcomes to individual utterances, while multi-dimensional rewards
capture the full richness of social interactions and reduce reward hacking.
Experiments in Sotopia, an open-ended social learning environment, demonstrate
that Sotopia-RL achieves state-of-the-art social goal completion scores (7.17
on Sotopia-hard and 8.31 on Sotopia-full), significantly outperforming existing
approaches. Ablation studies confirm the necessity of both utterance-level
credit assignment and multi-dimensional reward design for RL training. Our
implementation is publicly available at:
https://github.com/sotopia-lab/sotopia-rl.

</details>


### [144] [CoAct-1: Computer-using Agents with Coding as Actions](https://arxiv.org/abs/2508.03923)
*Linxin Song,Yutong Dai,Viraj Prabhu,Jieyu Zhang,Taiwei Shi,Li Li,Junnan Li,Silvio Savarese,Zeyuan Chen,Jieyu Zhao,Ran Xu,Caiming Xiong*

Main category: cs.CL

TL;DR: 本论文提出了一种将编程作为操作手段的新范式，即CoAct-1混合式多智能体系统，结合了GUI操作和直接编码执行，显著提升了自主代理在复杂计算机任务上的效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有通过GUI操作计算机任务的自主代理在处理复杂、长时任务时效率低、鲁棒性弱。尽管加入任务规划可以改善任务分解，但仍受限于GUI操作本身的效率和可靠性。作者认为，结合编程能力有望突破GUI操作的瓶颈，从而提升任务完成的效率和能力。

Method: 提出了CoAct-1系统，包括一个动态调度的Orchestrator，可根据子任务的特性选择传统GUI Operator或具备编程能力的Programmer代理。Programmer可直接编写并执行Python或Bash脚本，用于处理文件管理、数据处理等适合编码的任务，而其他任务则交给GUI Operator以模拟人类视觉操作。两者协同提升整体效能。

Result: 在OSWorld基准上，CoAct-1实现了60.76%的新SOTA成功率，显著优于以往方法，同时平均完成任务所需操作步数降至10.15步（领先GUI代理的15步）。

Conclusion: 将编程能力与GUI操作结合为计算机自主代理的核心操作模块，可极大提升系统的能力、效率和可扩展性，为实现通用自动化迈出重要一步。

Abstract: Autonomous agents that operate computers via Graphical User Interfaces (GUIs)
often struggle with efficiency and reliability on complex, long-horizon tasks.
While augmenting these agents with planners can improve task decomposition,
they remain constrained by the inherent limitations of performing all actions
through GUI manipulation, leading to brittleness and inefficiency. In this
work, we introduce a more robust and flexible paradigm: enabling agents to use
coding as a enhanced action. We present CoAct-1, a novel multi-agent system
that synergistically combines GUI-based control with direct programmatic
execution. CoAct-1 features an Orchestrator that dynamically delegates subtasks
to either a conventional GUI Operator or a specialized Programmer agent, which
can write and execute Python or Bash scripts. This hybrid approach allows the
agent to bypass inefficient GUI action sequences for tasks like file management
and data processing, while still leveraging visual interaction when necessary.
We evaluate our system on the challenging OSWorld benchmark, where CoAct-1
achieves a new state-of-the-art success rate of 60.76%, significantly
outperforming prior methods. Furthermore, our approach dramatically improves
efficiency, reducing the average number of steps required to complete a task to
just 10.15, compared to 15 for leading GUI agents. Our results demonstrate that
integrating coding as a core action provides a more powerful, efficient, and
scalable path toward generalized computer automation.

</details>


### [145] [CAP-LLM: Context-Augmented Personalized Large Language Models for News Headline Generation](https://arxiv.org/abs/2508.03935)
*Raymond Wilson,Cole Graham,Chase Carter,Zefeng Yang,Ruiqi Gu*

Main category: cs.CL

TL;DR: 提出了一种结合用户偏好和事实一致性的新型大语言模型（CAP-LLM），用于生成个性化且准确的新闻标题，并在真实数据集上取得了优异成绩。


<details>
  <summary>Details</summary>
Motivation: 现有个性化新闻标题生成方法难以有效捕捉复杂用户兴趣，并保证事实准确性，常导致标题雷同或失真。该研究旨在解决上述问题，提升个性化与事实一致性的平衡。

Method: 设计了CAP-LLM框架，包括三个核心模块：（1）用户偏好编码器，捕获用户长期兴趣；（2）上下文注入适配器，将用户偏好和新闻内容无缝融合进LLM生成流程；（3）事实一致性强化模块，用新型对比损失减少模型“幻觉”。

Result: 在PENS真实数据集上，CAP-LLM在所有评价指标上均优于强基线，如事实一致性（FactCC 87.50 > BART 86.67）、个性化指标（Pc(avg) 2.73, Pc(max) 17.25）与内容覆盖度（ROUGE-1 26.55等）均有提升。消融实验与人工评测亦验证了各模块的有效性和整体鲁棒性。

Conclusion: CAP-LLM结合用户个性化和事实一致性的增强机制，在新闻标题生成任务上达到了个性化与准确性的优秀平衡，为信息超载时代的内容推荐提供了更优解法。

Abstract: In the era of information overload, personalized news headline generation is
crucial for engaging users by tailoring content to their preferences while
accurately conveying news facts. Existing methods struggle with effectively
capturing complex user interests and ensuring factual consistency, often
leading to generic or misleading headlines. Leveraging the unprecedented
capabilities of Large Language Models (LLMs) in text generation, we propose
Context-Augmented Personalized LLM (CAP-LLM), a novel framework that integrates
user preferences and factual consistency constraints into a powerful
pre-trained LLM backbone. CAP-LLM features a User Preference Encoder to capture
long-term user interests, a Context Injection Adapter to seamlessly integrate
these preferences and current article context into the LLM's generation
process, and a Fact-Consistency Reinforcement Module employing a novel
contrastive loss to mitigate hallucination. Evaluated on the real-world PENS
dataset, CAP-LLM achieves state-of-the-art performance across all metrics.
Notably, it significantly improves factual consistency (FactCC of 87.50) over
strong baselines like BART (86.67), while simultaneously enhancing
personalization (Pc(avg) 2.73, Pc(max) 17.25) and content coverage (ROUGE-1
26.55, ROUGE-2 9.95, ROUGE-L 23.01). Our ablation studies, human evaluations,
and sensitivity analyses further validate the effectiveness of each component
and the robustness of our approach, demonstrating CAP-LLM's ability to achieve
a superior balance between personalization and factual accuracy in news
headline generation.

</details>


### [146] [Data and AI governance: Promoting equity, ethics, and fairness in large language models](https://arxiv.org/abs/2508.03970)
*Alok Abhishek,Lisa Erickson,Tushar Bandopadhyay*

Main category: cs.CL

TL;DR: 本文系统性探讨了在机器学习模型全生命周期中治理、评估和量化偏见的方法，重点关注大语言模型（LLM）的偏见、伦理、和事实性问题，并提出了一套数据和AI治理框架，有助于实际生产环境中提升生成式AI系统的安全与责任。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在生成内容时常出现偏见和不公平现象，容易引发社会、伦理和品牌风险。目前缺乏一套从模型开发到生产运维全流程管理偏见的系统性方法，亟需通过数据与AI治理提升系统的可信度和责任感。

Method: 基于前期的偏见评估测试套件（BEATS），本文提出并探讨了适用于大语言模型全生命周期的数据和AI治理框架，包括模型开发、上线、持续监控及防控措施。通过该框架可以实现模型上线前的严密基准测试、上线后的实时评估与主动治理。

Result: 应用所提的治理方法可以帮助企业和组织定量评估和显著缓解生成式AI系统中的偏见和不公问题，减少由此带来的歧视性风险，降低声誉及品牌受损的可能性。

Conclusion: 研究证明，通过在AI全生命周期中落地数据和AI治理框架，能够持续提升生成式AI系统的安全、合规和社会责任，有助于推动伦理性和社会责任明确的生成式AI实践。

Abstract: In this paper, we cover approaches to systematically govern, assess and
quantify bias across the complete life cycle of machine learning models, from
initial development and validation to ongoing production monitoring and
guardrail implementation. Building upon our foundational work on the Bias
Evaluation and Assessment Test Suite (BEATS) for Large Language Models, the
authors share prevalent bias and fairness related gaps in Large Language Models
(LLMs) and discuss data and AI governance framework to address Bias, Ethics,
Fairness, and Factuality within LLMs. The data and AI governance approach
discussed in this paper is suitable for practical, real-world applications,
enabling rigorous benchmarking of LLMs prior to production deployment,
facilitating continuous real-time evaluation, and proactively governing LLM
generated responses. By implementing the data and AI governance across the life
cycle of AI development, organizations can significantly enhance the safety and
responsibility of their GenAI systems, effectively mitigating risks of
discrimination and protecting against potential reputational or brand-related
harm. Ultimately, through this article, we aim to contribute to advancement of
the creation and deployment of socially responsible and ethically aligned
generative artificial intelligence powered applications.

</details>


### [147] [Confidence-Weighted Token Set Cover for Early Hypothesis Pruning in Self-Consistency](https://arxiv.org/abs/2508.03979)
*Md Arafat Sultan,Ramón Fernandez Astudillo*

Main category: cs.CL

TL;DR: 该论文提出通过早期假设剪枝，提升自洽性方法在长链式思维任务中的token使用效率，并保持并行性。实验证明对多个大模型和数学基准有10-35%的token节省。


<details>
  <summary>Details</summary>
Motivation: 自洽性方法虽然简单有效，但在实际应用中由于生成大量解消耗token过多，影响实用性。作者希望提升其token效率，使其在长推理任务中更可用。

Method: 作者设计了基于两项指标（模型对解的置信度、候选集合对当前所有解的词汇覆盖）进行早期假设剪枝。所有解并行生成，定期剪掉不必要的中间假设。实现了一个快速加权集合覆盖算法来支撑这一过程。

Result: 在三个数学任务基准和五个大语言模型上评估，该方法提升了token利用率，在许多情况下减少了10-35%的token消耗。

Conclusion: 通过早期剪枝和新的集合覆盖算法，方法在保证自洽性并行优势的同时，大幅提升了token效率，增强了长链推理任务的实用性。

Abstract: Despite its simplicity and efficacy, the high token expenditure of
self-consistency can limit its practical utility. Here we investigate if
self-consistency can be made more token-efficient for long chain-of-thought
reasoning tasks, while preserving its parallelism, through early hypothesis
pruning. Concretely, we generate all solutions in parallel, but periodically
prune intermediate hypotheses that are deemed unnecessary based on two
lightweight indicators: (a) the model's own confidence in individual
hypotheses, and (b) lexical coverage of all current hypotheses by candidate
subsets that are under consideration for continued retention. We design a fast
weighted set cover algorithm that utilizes the two indicators; our evaluation
of five LLMs on three math benchmarks shows that this method can improve token
efficiency for all models, by 10-35% in many cases.

</details>


### [148] [Are Today's LLMs Ready to Explain Well-Being Concepts?](https://arxiv.org/abs/2508.03990)
*Bohan Jiang,Dawei Li,Zhen Tan,Chengshuai Zhao,Huan Liu*

Main category: cs.CL

TL;DR: 本文建立了一个包含43,880条由10种不同大型语言模型（LLMs）生成的关于2,194个幸福感相关概念的解释数据集，并评估了这些模型在针对不同受众生成高质量解释方面的能力。通过监督微调(SFT)和直接偏好优化(DPO)提升了开放源代码LLM解释质量。实验表明模型经过DPO和SFT后能优于更大的未微调模型。


<details>
  <summary>Details</summary>
Motivation: 伴随人们越来越依赖LLM理解身心健康问题，提出了一个关键挑战：能否生成既准确又符合不同受众（领域、知识背景等）需求的高质量解释。

Method: 1. 构建包含43,880条、涵盖2,194个幸福感概念的大规模解释数据集，由10种多样化LLM自动生成；2. 提出一种基于原则的LLM-as-a-Judge双判官评估框架，用于衡量解释的质量；3. 对开放式LLM进行监督微调（SFT）和直接偏好优化（DPO），观察对解释生成质量的提升。

Result: 1. LLM判官与人工评估具有较高一致性；2. 不同模型、受众与类别的解释质量有显著差异；3. 微调后的（DPO、SFT）模型在专业解释任务中优于更大但未调优的模型。

Conclusion: 针对幸福感相关多维概念的解释生成，LLM通过结合基于原则的判别机制和偏好驱动微调方法，可获得比规模更大的基础模型更优的、多样化和受众适应性强的高质量解释。

Abstract: Well-being encompasses mental, physical, and social dimensions essential to
personal growth and informed life decisions. As individuals increasingly
consult Large Language Models (LLMs) to understand well-being, a key challenge
emerges: Can LLMs generate explanations that are not only accurate but also
tailored to diverse audiences? High-quality explanations require both factual
correctness and the ability to meet the expectations of users with varying
expertise. In this work, we construct a large-scale dataset comprising 43,880
explanations of 2,194 well-being concepts, generated by ten diverse LLMs. We
introduce a principle-guided LLM-as-a-judge evaluation framework, employing
dual judges to assess explanation quality. Furthermore, we show that
fine-tuning an open-source LLM using Supervised Fine-Tuning (SFT) and Direct
Preference Optimization (DPO) can significantly enhance the quality of
generated explanations. Our results reveal: (1) The proposed LLM judges align
well with human evaluations; (2) explanation quality varies significantly
across models, audiences, and categories; and (3) DPO- and SFT-finetuned models
outperform their larger counterparts, demonstrating the effectiveness of
preference-based learning for specialized explanation tasks.

</details>


### [149] [Transferring Expert Cognitive Models to Social Robots via Agentic Concept Bottleneck Models](https://arxiv.org/abs/2508.03998)
*Xinyu Zhao,Zhen Tan,Maya Enisman,Minjae Seo,Marta R. Durantini,Dolores Albarracin,Tianlong Chen*

Main category: cs.CL

TL;DR: 本文提出了一种社交机器人协同主持工具，利用可解释概念瓶颈模型（CBM）支持会议主持人识别小组动态，实现及时干预并辅助决策。该方法显著优于直接使用基础模型（FM），可及时纠正推理错误，并能将专家经验迁移到新组和新手主持人。


<details>
  <summary>Details</summary>
Motivation: 小组会议需要促进个体目标执行并强化组内社交关系，对主持人的认知负担极高。当前“黑箱”型基础模型虽然可识别社交线索，但缺乏透明度且难以干预现实过程，亟需能理解社会互动同时提供透明建议的技术辅助。

Method: 设计并实现了社交机器人辅助主持，利用基于人可解释的概念（如参与度、情感等）的概念瓶颈模型（CBM）分析多模态会议数据，并以转移学习方式将大规模基础模型的能力迁移到CBM。机器人能向主持人提供私密、透明、具可解释性的干预建议。

Result: 与直接零样本基础模型相比，本文系统在预测干预需求、实时推理纠正等方面表现更佳。模型在不同小组间泛化良好，实现了专家主持经验对初学者的迁移。

Conclusion: 本工作展示了将专家认知模型以可解释形式迁移至机器人辅助主持的可行性，为提升复杂社交场合下的人类能力提供了新范式和技术蓝本。

Abstract: Successful group meetings, such as those implemented in group
behavioral-change programs, work meetings, and other social contexts, must
promote individual goal setting and execution while strengthening the social
relationships within the group. Consequently, an ideal facilitator must be
sensitive to the subtle dynamics of disengagement, difficulties with individual
goal setting and execution, and interpersonal difficulties that signal a need
for intervention. The challenges and cognitive load experienced by facilitators
create a critical gap for an embodied technology that can interpret social
exchanges while remaining aware of the needs of the individuals in the group
and providing transparent recommendations that go beyond powerful but "black
box" foundation models (FMs) that identify social cues. We address this
important demand with a social robot co-facilitator that analyzes multimodal
meeting data and provides discreet cues to the facilitator. The robot's
reasoning is powered by an agentic concept bottleneck model (CBM), which makes
decisions based on human-interpretable concepts like participant engagement and
sentiments, ensuring transparency and trustworthiness. Our core contribution is
a transfer learning framework that distills the broad social understanding of
an FM into our specialized and transparent CBM. This concept-driven system
significantly outperforms direct zero-shot FMs in predicting the need for
intervention and enables real-time human correction of its reasoning.
Critically, we demonstrate robust knowledge transfer: the model generalizes
across different groups and successfully transfers the expertise of senior
human facilitators to improve the performance of novices. By transferring an
expert's cognitive model into an interpretable robotic partner, our work
provides a powerful blueprint for augmenting human capabilities in complex
social domains.

</details>


### [150] [HarmonyGuard: Toward Safety and Utility in Web Agents via Adaptive Policy Enhancement and Dual-Objective Optimization](https://arxiv.org/abs/2508.04010)
*Yurun Chen,Xavier Hu,Yuhan Liu,Keting Yin,Juncheng Li,Zhuosheng Zhang,Shengyu Zhang*

Main category: cs.CL

TL;DR: 该论文提出了HarmonyGuard框架，通过多智能体协同，兼顾网络环境中的任务效用和安全性，实现更高的政策合规和任务完成率。


<details>
  <summary>Details</summary>
Motivation: 现有研究在Web环境下，智能体执行任务时，要么只关注单一目标（如效用或安全），要么只考虑单轮任务，无法在多步开放环境中同时优化安全和效用。这导致Web代理在应对不断变化的网络威胁时，难以平衡任务表现与风险。

Method: 提出HarmonyGuard多智能体协作体系：一方面通过Policy Agent自动从非结构化文档中提取并维护结构化安全政策，并响应新威胁进行动态更新；另一方面，由Utility Agent基于安全与效用两个目标，采用马尔可夫实时推理和元认知优化能力，实现双目标的权衡与最优决策。

Result: 在多个基准测试上的实验显示，HarmonyGuard能使安全政策合规性提升至90%以上，并比现有方法提升政策合规率最多38%、任务完成率最多20%。

Conclusion: HarmonyGuard能有效实现Web环境下智能体的安全和效用协同优化，显著提升安全合规与任务性能，为多目标优化与开放环境智能体研究提供新思路。

Abstract: Large language models enable agents to autonomously perform tasks in open web
environments. However, as hidden threats within the web evolve, web agents face
the challenge of balancing task performance with emerging risks during
long-sequence operations. Although this challenge is critical, current research
remains limited to single-objective optimization or single-turn scenarios,
lacking the capability for collaborative optimization of both safety and
utility in web environments. To address this gap, we propose HarmonyGuard, a
multi-agent collaborative framework that leverages policy enhancement and
objective optimization to jointly improve both utility and safety. HarmonyGuard
features a multi-agent architecture characterized by two fundamental
capabilities: (1) Adaptive Policy Enhancement: We introduce the Policy Agent
within HarmonyGuard, which automatically extracts and maintains structured
security policies from unstructured external documents, while continuously
updating policies in response to evolving threats. (2) Dual-Objective
Optimization: Based on the dual objectives of safety and utility, the Utility
Agent integrated within HarmonyGuard performs the Markovian real-time reasoning
to evaluate the objectives and utilizes metacognitive capabilities for their
optimization. Extensive evaluations on multiple benchmarks show that
HarmonyGuard improves policy compliance by up to 38% and task completion by up
to 20% over existing baselines, while achieving over 90% policy compliance
across all tasks. Our project is available here:
https://github.com/YurunChen/HarmonyGuard.

</details>


### [151] [Step More: Going Beyond Single Backpropagation in Meta Learning Based Model Editing](https://arxiv.org/abs/2508.04012)
*Xiaopeng Li,Shasha Li,Xi Wang,Shezheng Song,Bin Ji,Shangwen Wang,Jun Ma,Xiaodong Liu,Mina Liu,Jie Yu*

Main category: cs.CL

TL;DR: 本文提出了SMEdit，一种改进的模型编辑方法，通过多步反向传播和正则化提升在低数据场景下对大语言模型的知识更新效率和效果。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）更新知识过程成本高昂，而基于元学习的模型编辑（MLBME）虽有效，但在数据较少时效果不好、且受制于KL散度计算带来的训练效率问题。

Method: 提出SMEdit方法，引入多步反向传播（MBPS）以增强低监督条件下的编辑能力，并通过对权重更新加入范数正则化以改进训练效率。

Result: 在两个数据集和两种LLM上的实验表明，SMEdit性能优于已有的MLBME方法，且MBPS策略能无缝集成到现有方法中提升效果。

Conclusion: SMEdit提升了在低数据环境下大模型编辑的有效性与效率，并为后续相关方法提供了可扩展的改进手段。

Abstract: Large Language Models (LLMs) underpin many AI applications, but their static
nature makes updating knowledge costly. Model editing offers an efficient
alternative by injecting new information through targeted parameter
modifications. In particular, meta-learning-based model editing (MLBME) methods
have demonstrated notable advantages in both editing effectiveness and
efficiency. Despite this, we find that MLBME exhibits suboptimal performance in
low-data scenarios, and its training efficiency is bottlenecked by the
computation of KL divergence. To address these, we propose $\textbf{S}$tep
$\textbf{M}$ore $\textbf{Edit}$ ($\textbf{SMEdit}$), a novel MLBME method that
adopts $\textbf{M}$ultiple $\textbf{B}$ackpro$\textbf{P}$agation
$\textbf{S}$teps ($\textbf{MBPS}$) to improve editing performance under limited
supervision and a norm regularization on weight updates to improve training
efficiency. Experimental results on two datasets and two LLMs demonstrate that
SMEdit outperforms prior MLBME baselines and the MBPS strategy can be
seamlessly integrated into existing methods to further boost their performance.
Our code will be released soon.

</details>


### [152] [ZARA: Zero-shot Motion Time-Series Analysis via Knowledge and Retrieval Driven LLM Agents](https://arxiv.org/abs/2508.04038)
*Zechen Li,Baiyu Chen,Hao Xue,Flora D. Salim*

Main category: cs.CL

TL;DR: 提出ZARA框架，无需微调即可对原始动作传感器时序数据进行零样本、可解释的人体活动识别，并取得领先性能。


<details>
  <summary>Details</summary>
Motivation: 当前人体活动识别方法高度依赖固定活动集合，并且针对新行为或新传感器需要高昂的重复训练成本。现有尝试引入大语言模型（LLM）进行识别的方法在准确率和解释性方面表现有限，因此需要一种无需微调即可进行可解释、泛化性强的人体活动识别新方案。

Method: 提出ZARA框架，包含自动构建的活动对特征知识库、多传感器证据检索模块与分层Agent流水线，引导大语言模型在原始时序数据上选择特征、调取证据并给出演示推理过程的活动预测。

Result: 在8个人体活动识别基准测试上，ZARA零样本条件下取得了最优表现，宏平均F1值是最强基线的2.53倍，并通过消融实验验证了各个模块的必要性。

Conclusion: ZARA框架为无需微调、具备可解释性的人体活动识别提供了新思路，表现优异并具有较高的实用前景和可信赖性。

Abstract: Motion sensor time-series are central to human activity recognition (HAR),
with applications in health, sports, and smart devices. However, existing
methods are trained for fixed activity sets and require costly retraining when
new behaviours or sensor setups appear. Recent attempts to use large language
models (LLMs) for HAR, typically by converting signals into text or images,
suffer from limited accuracy and lack verifiable interpretability. We propose
ZARA, the first agent-based framework for zero-shot, explainable HAR directly
from raw motion time-series. ZARA integrates an automatically derived pair-wise
feature knowledge base that captures discriminative statistics for every
activity pair, a multi-sensor retrieval module that surfaces relevant evidence,
and a hierarchical agent pipeline that guides the LLM to iteratively select
features, draw on this evidence, and produce both activity predictions and
natural-language explanations. ZARA enables flexible and interpretable HAR
without any fine-tuning or task-specific classifiers. Extensive experiments on
8 HAR benchmarks show that ZARA achieves SOTA zero-shot performance, delivering
clear reasoning while exceeding the strongest baselines by 2.53x in macro F1.
Ablation studies further confirm the necessity of each module, marking ZARA as
a promising step toward trustworthy, plug-and-play motion time-series analysis.
Our codes are available at https://github.com/zechenli03/ZARA.

</details>


### [153] [Large Reasoning Models Are Autonomous Jailbreak Agents](https://arxiv.org/abs/2508.04039)
*Thilo Hagendorff,Erik Derner,Nuria Oliver*

Main category: cs.CL

TL;DR: 本论文发现，通过大语言模型的推理和说服能力，越狱（绕过AI安全限制）变得容易且低成本，甚至非专家用户也可操作。作者用4种大型推理模型，对9种主流AI模型进行多轮自动越狱测试，总体成功率高达97.14%。


<details>
  <summary>Details</summary>
Motivation: 传统AI越狱需要复杂技术或专业知识，随着AI能力提升，是否简化了越狱过程？探究大型推理模型是否能轻松突破其他模型的安全防护。

Method: 作者选择4种大型推理模型作为攻击者，在无需人工干预下，根据系统提示自发策划并实施越狱，对9个目标模型开展多轮对话攻击。使用包含7个敏感领域、共70项的有害指令基准，系统性评估攻击效果。

Result: 所有模型组合下，攻击总体成功率为97.14%，表明这些推理模型能极高概率绕过主流AI模型的安全防护。

Conclusion: 随着AI对话模型能力进步，越狱技术门槛大大降低。前沿模型不仅要抵御外部越狱，还需防止自身被用于实施越狱，对AI安全对齐提出了更严峻挑战。

Abstract: Jailbreaking -- bypassing built-in safety mechanisms in AI models -- has
traditionally required complex technical procedures or specialized human
expertise. In this study, we show that the persuasive capabilities of large
reasoning models (LRMs) simplify and scale jailbreaking, converting it into an
inexpensive activity accessible to non-experts. We evaluated the capabilities
of four LRMs (DeepSeek-R1, Gemini 2.5 Flash, Grok 3 Mini, Qwen3 235B) to act as
autonomous adversaries conducting multi-turn conversations with nine widely
used target models. LRMs received instructions via a system prompt, before
proceeding to planning and executing jailbreaks with no further supervision. We
performed extensive experiments with a benchmark of harmful prompts composed of
70 items covering seven sensitive domains. This setup yielded an overall attack
success rate across all model combinations of 97.14%. Our study reveals an
alignment regression, in which LRMs can systematically erode the safety
guardrails of other models, highlighting the urgent need to further align
frontier models not only to resist jailbreak attempts, but also to prevent them
from being co-opted into acting as jailbreak agents.

</details>


### [154] [DTPA: Dynamic Token-level Prefix Augmentation for Controllable Text Generation](https://arxiv.org/abs/2508.04047)
*Jiabing Yang,Yixiang Chen,Zichen Wen,Chenhang Cui,Peiyan Li,Yuan Xu,Bowen Fang,Yan Huang,Liang Wang*

Main category: cs.CL

TL;DR: 本文提出了一种面向长文本生成的可控文本生成新方法DTPA，能增强属性控制效果，尤其在长文本上表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有可控文本生成方法主要关注短文本，长文本生成中的可控性效果较差，特别是Air-Decoding方法生成长文本时对前缀的关注随长度增长而减弱，急需改进。

Method: 提出DTPA（Dynamic Token-level Prefix Augmentation）框架：首先根据任务选择最优前缀类型（软/硬），然后随序列长度指数增强对前缀的关注度，提升属性控制；可选地对原始提示词做类似增强以保证文本质量。

Result: 在多个CTG任务上的实验显示，DTPA在属性可控性上普遍优于其他方法，同时流畅性、多样性和主题相关性表现竞争力，尤其在长文本生成中效果显著提升。

Conclusion: DTPA是一种高效、轻量的长文本可控生成方法，能有效增强前缀对属性控制的作用，兼顾文本质量，有望推广应用于更丰富的文本生成场景。

Abstract: Controllable Text Generation (CTG) is a vital subfield in Natural Language
Processing (NLP), aiming to generate text that aligns with desired attributes.
However, previous studies commonly focus on the quality of controllable text
generation for short sequences, while the generation of long-form text remains
largely underexplored. In this paper, we observe that the controllability of
texts generated by the powerful prefix-based method Air-Decoding tends to
decline with increasing sequence length, which we hypothesize primarily arises
from the observed decay in attention to the prefixes. Meanwhile, different
types of prefixes including soft and hard prefixes are also key factors
influencing performance. Building on these insights, we propose a lightweight
and effective framework called Dynamic Token-level Prefix Augmentation (DTPA)
based on Air-Decoding for controllable text generation. Specifically, it first
selects the optimal prefix type for a given task. Then we dynamically amplify
the attention to the prefix for the attribute distribution to enhance
controllability, with a scaling factor growing exponentially as the sequence
length increases. Moreover, based on the task, we optionally apply a similar
augmentation to the original prompt for the raw distribution to balance text
quality. After attribute distribution reconstruction, the generated text
satisfies the attribute constraints well. Experiments on multiple CTG tasks
demonstrate that DTPA generally outperforms other methods in attribute control
while maintaining competitive fluency, diversity, and topic relevance. Further
analysis highlights DTPA's superior effectiveness in long text generation.

</details>


### [155] [PAIRS: Parametric-Verified Adaptive Information Retrieval and Selection for Efficient RAG](https://arxiv.org/abs/2508.04057)
*Wang Chen,Guanqiang Qi,Weikang Li,Yang Li,Deguo Xia,Jizhou Huang*

Main category: cs.CL

TL;DR: PAIRS方法结合了大语言模型自身知识和外部检索信息，通过自适应判断是否检索和如何选择文档，有效提升了效率和准确率。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统每次都检索外部信息，哪怕问题很简单，这导致效率低下；同时，当查询信息稀疏时，容易检索到无关文档，因此需要更智能的检索机制。

Method: 提出PAIRS框架，该方法无需训练，针对每个问题先由LLM分别生成直接答案和自生成上下文辅助答案。如果两者一致，则不进行外部检索；如不一致，则基于原始查询和自生成上下文进行双通路检索，并用自适应信息选择（AIS）模块按权重筛选文档。

Result: 在六个问答数据集上，PAIRS平均将检索成本降低约25%（只对75%的问题检索），同时准确率提升，EM值和F1值均高于基线1%左右。

Conclusion: PAIRS框架能够显著提升RAG系统效率，同时还提升了问答准确率，对实际应用具有重要价值。

Abstract: Retrieval-Augmented Generation (RAG) has become a cornerstone technique for
enhancing large language models (LLMs) with external knowledge. However,
current RAG systems face two critical limitations: (1) they inefficiently
retrieve information for every query, including simple questions that could be
resolved using the LLM's parametric knowledge alone, and (2) they risk
retrieving irrelevant documents when queries contain sparse information
signals. To address these gaps, we introduce Parametric-verified Adaptive
Information Retrieval and Selection (PAIRS), a training-free framework that
integrates parametric and retrieved knowledge to adaptively determine whether
to retrieve and how to select external information. Specifically, PAIRS employs
a dual-path generation mechanism: First, the LLM produces both a direct answer
and a context-augmented answer using self-generated pseudo-context. When these
outputs converge, PAIRS bypasses external retrieval entirely, dramatically
improving the RAG system's efficiency. For divergent cases, PAIRS activates a
dual-path retrieval (DPR) process guided by both the original query and
self-generated contextual signals, followed by an Adaptive Information
Selection (AIS) module that filters documents through weighted similarity to
both sources. This simple yet effective approach can not only enhance
efficiency by eliminating unnecessary retrievals but also improve accuracy
through contextually guided retrieval and adaptive information selection.
Experimental results on six question-answering (QA) benchmarks show that PAIRS
reduces retrieval costs by around 25% (triggering for only 75% of queries)
while still improving accuracy-achieving +1.1% EM and +1.0% F1 over prior
baselines on average.

</details>


### [156] [Efficient Strategy for Improving Large Language Model (LLM) Capabilities](https://arxiv.org/abs/2508.04073)
*Julián Camilo Velandia Gutiérrez*

Main category: cs.CL

TL;DR: 本文针对大语言模型（LLMs）在资源受限环境下的高效部署问题，探索数据处理、数据选择、训练策略及架构调整等优化方法，并通过系统实验验证提升效果。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在AI领域取得重大突破，但其实际部署受限于对大量算力的需求。因此，研究如何在资源受限环境下提升LLMs的效率和能力显得尤为重要。

Method: 作者以基础模型为起点，系统地结合数据处理与数据选择技巧、训练策略、架构优化等多种方法。建立可靠数据集评判标准，进行多种配置下的对照实验，并评估模型在能力、多样性、响应速度和安全性等方面表现。

Result: 对不同策略优化后的模型变体进行了性能对比测试，结果显示通过精细数据选择与架构调整等方法能在受限资源下显著提升LLMs的能力与效率。

Conclusion: 本文提出的方法能有效提升LLMs在资源有限及知识库受限条件下的实用性与性能，证实了综合优化策略的有效性，为LLMs的实际部署提供了可行路径。

Abstract: Large Language Models (LLMs) have become a milestone in the field of
artificial intelligence and natural language processing. However, their
large-scale deployment remains constrained by the need for significant
computational resources. This work proposes starting from a base model to
explore and combine data processing and careful data selection techniques,
training strategies, and architectural adjustments to improve the efficiency of
LLMs in resource-constrained environments and within a delimited knowledge
base. The methodological approach included defining criteria for building
reliable datasets, conducting controlled experiments with different
configurations, and systematically evaluating the resulting variants in terms
of capability, versatility, response time, and safety. Finally, comparative
tests were conducted to measure the performance of the developed variants and
to validate the effectiveness of the proposed strategies. This work is based on
the master's thesis in Systems and Computer Engineering titled "Efficient
Strategy for Improving the Capabilities of Large Language Models (LLMs)".

</details>


### [157] [ToolGrad: Efficient Tool-use Dataset Generation with Textual "Gradients"](https://arxiv.org/abs/2508.04086)
*Zhongyi Zhou,Kohei Uehara,Haoyu Zhang,Jingtao Zhou,Lin Gu,Ruofei Du,Zheng Xu,Tatsuya Harada*

Main category: cs.CL

TL;DR: 本文提出了一种新的数据生成框架ToolGrad，采用“先答案后提问”的策略，有效提升了工具使用数据集的复杂度、生成效率和质量。


<details>
  <summary>Details</summary>
Motivation: 现有工具使用类LLM数据集的合成通常先生成用户问题，再进行复杂的工具使用注释（如DFS），导致注释失败和数据生成效率低下。作者希望改变这一低效且易出错的流程。

Method: ToolGrad框架通过迭代文本“梯度”引导，先合成有效的工具使用链，再反向合成对应的用户问题，实现“答案优先”的数据生成范式。由此生成了高质量的数据集ToolGrad-5k。

Result: 实验结果表明，ToolGrad-5k在工具使用的复杂度更高，数据生成成本更低，数据通过率达100%；用该数据集训练的模型在O O D基准上优于使用传统数据集和专有LLMs的数据。

Conclusion: ToolGrad提出了提升工具使用数据集自动合成质量和效率的新思路，生成的数据提升了模型在相关任务上的能力，有望为LLM工具链应用注入新活力。

Abstract: Prior work synthesizes tool-use LLM datasets by first generating a user
query, followed by complex tool-use annotations like DFS. This leads to
inevitable annotation failures and low efficiency in data generation. We
introduce ToolGrad, an agentic framework that inverts this paradigm. ToolGrad
first constructs valid tool-use chains through an iterative process guided by
textual "gradients", and then synthesizes corresponding user queries. This
"answer-first" approach led to ToolGrad-5k, a dataset generated with more
complex tool use, lower cost, and 100% pass rate. Experiments show that models
trained on ToolGrad-5k outperform those on expensive baseline datasets and
proprietary LLMs, even on OOD benchmarks.

</details>


### [158] [GM-PRM: A Generative Multimodal Process Reward Model for Multimodal Mathematical Reasoning](https://arxiv.org/abs/2508.04088)
*Jianghangfan Zhang,Yibo Yan,Kening Zheng,Xin Zou,Song Dai,Xuming Hu*

Main category: cs.CL

TL;DR: 本文提出了一种新的生成式多模态过程奖励模型（GM-PRM），能在多模态大语言模型进行复杂多步数学推理时，不仅判别错误，还能针对性地生成纠正建议，从而显著提升解题正确率。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在复杂多步数学推理任务中，经常因感知或推理细节出错而整体失败。虽然过程奖励模型（PRM）可以逐步监督，但以往PRM多为二元判定，难以提供具体解释或纠正建议，限制了解题性能提升。

Method: 作者提出GM-PRM，将PRM“被动判官”转变为“主动协作体”：不仅对每一步推理的意图、视觉一致性和逻辑有效性提供细粒度可解释分析，还能在检测到第一个错误步骤时生成纠正版本。借此，采用Refined Best-of-N（Refined-BoN）推断策略，将生成的纠错建议用于引导模型走向更优推理路径，提升答案多样性和正确性。

Result: GM-PRM在多个多模态数学基准上达到SOTA（state-of-the-art）表现，大幅提升基础策略模型的表现，仅需20K训练样本即展现出较高的数据利用率。

Conclusion: GM-PRM显著改善了多模态大模型的多步推理与错误纠正能力，极大增强了过程监督和模型输出的准确性，为复杂推理和AI数学解题任务提供了新范式。作者承诺代码将在论文接收后开源。

Abstract: Multimodal Large Language Models (MLLMs) demonstrate remarkable capabilities
but often struggle with complex, multi-step mathematical reasoning, where minor
errors in visual perception or logical deduction can lead to complete failure.
While Process Reward Models (PRMs) offer step-by-step supervision, existing
multimodal PRMs are limited to being binary verifiers that can identify but not
correct errors, offering little explanatory power. To address these
deficiencies, we introduce the Generative Multimodal Process Reward Model
(GM-PRM), a novel paradigm that transforms the PRM from a passive judge into an
active reasoning collaborator. Instead of a simple scalar score, GM-PRM
provides a fine-grained, interpretable analysis of each reasoning step,
evaluating its step intent, visual alignment, and logical soundness. More
critically, GM-PRM is trained to generate a corrected version of the first
erroneous step it identifies. This unique corrective capability enables our new
test-time inference strategy, Refined Best-of-N (Refined-BoN). This framework
actively enhances solution quality by using the PRM's generated correction to
guide the policy model toward a more promising reasoning trajectory, thereby
improving the diversity and correctness of the solution pool. We demonstrate
that GM-PRM achieves state-of-the-art results on multiple multimodal math
benchmarks, significantly boosting policy model performance with remarkable
data efficiency, requiring only a 20K-sample training dataset. Our code will be
released upon acceptance.

</details>


### [159] [Unveiling Over-Memorization in Finetuning LLMs for Reasoning Tasks](https://arxiv.org/abs/2508.04117)
*Zhiwen Ruan,Yun Chen,Yutao Hou,Peng Li,Yang Liu,Guanhua Chen*

Main category: cs.CL

TL;DR: 本文探讨了在大语言模型（LLM）微调过程中出现的过度记忆现象，该现象影响了模型鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型通常通过带标签数据进行微调以增强指令执行和价值对齐能力，但其在推理任务中的学习动态尚未被充分研究。

Method: 作者对LLM在推理任务上微调的不同阶段进行了系统实验，分析了过度记忆的出现阶段，并研究了训练轮数和学习率等因素对过度记忆的影响。

Result: 发现LLM在某一微调阶段会过度记忆训练集，表现为测试困惑度高但测试准确率仍好，并导致鲁棒性、泛化性和生成多样性降低。该现象在不同任务、模型和微调方法中普遍存在。

Conclusion: 过度参数化和大规模微调的LLM具有与传统机器学习模型不同的学习动态，提醒应注意微调时的检查点和学习率选择以避免过度记忆。

Abstract: The pretrained large language models (LLMs) are finetuned with labeled data
for better instruction following ability and alignment with human values. In
this paper, we study the learning dynamics of LLM finetuning on reasoning tasks
and reveal the uncovered over-memorization phenomenon during a specific stage
of LLM finetuning. At this stage, the LLMs have excessively memorized training
data and exhibit high test perplexity while maintaining good test accuracy. We
investigate the conditions that lead to LLM over-memorization and find that
training epochs and large learning rates contribute to this issue. Although
models with over-memorization demonstrate comparable test accuracy to normal
models, they suffer from reduced robustness, poor out-of-distribution
generalization, and decreased generation diversity. Our experiments unveil the
over-memorization to be broadly applicable across different tasks, models, and
finetuning methods. Our research highlights that overparameterized, extensively
finetuned LLMs exhibit unique learning dynamics distinct from traditional
machine learning models. Based on our observations of over-memorization, we
provide recommendations on checkpoint and learning rate selection during
finetuning.

</details>


### [160] [Difficulty-Based Preference Data Selection by DPO Implicit Reward Gap](https://arxiv.org/abs/2508.04149)
*Xuan Qi,Rongwu Xu,Zhijing Jin*

Main category: cs.CL

TL;DR: 提出一种基于难度的数据筛选方法，仅用10%的原始偏好数据集即可提升大型语言模型（LLMs）的人类偏好对齐效果，且表现优于五个现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有如RLHF和DPO等LLM对齐方法需大量高成本的人类偏好标注数据，且缺乏针对偏好数据的优质样本筛选手段，制约模型对齐的效率与可扩展性。

Method: 引入基于DPO隐式奖励机制的数据筛选方法，通过挑选DPO隐式奖励差距较小（更具挑战性）的样本进行训练，以提高数据利用效率和对齐效果。

Result: 所提方法在多个公开数据集和对齐任务上，均优于五个强基线方法，仅用原始数据集10%即可实现更佳模型性能。

Conclusion: 该策略为在数据有限条件下高效扩展LLM对齐提供了有效方案，有望显著提升对齐技术的数据利用率与实际应用价值。

Abstract: Aligning large language models (LLMs) with human preferences is a critical
challenge in AI research. While methods like Reinforcement Learning from Human
Feedback (RLHF) and Direct Preference Optimization (DPO) are widely used, they
often rely on large, costly preference datasets. The current work lacks methods
for high-quality data selection specifically for preference data. In this work,
we introduce a novel difficulty-based data selection strategy for preference
datasets, grounded in the DPO implicit reward mechanism. By selecting
preference data examples with smaller DPO implicit reward gaps, which are
indicative of more challenging cases, we improve data efficiency and model
alignment. Our approach consistently outperforms five strong baselines across
multiple datasets and alignment tasks, achieving superior performance with only
10\% of the original data. This principled, efficient selection method offers a
promising solution for scaling LLM alignment with limited resources.

</details>


### [161] [The State Of TTS: A Case Study with Human Fooling Rates](https://arxiv.org/abs/2508.04179)
*Praveen Srinivasa Varadhan,Sherry Thomas,Sai Teja M. S.,Suvrat Bhooshan,Mitesh M. Khapra*

Main category: cs.CL

TL;DR: 本文引入了Human Fooling Rate（HFR）作为衡量TTS语音逼真度的新指标，并在大规模评测中发现目前TTS系统在欺骗性评估中仍有明显不足。


<details>
  <summary>Details</summary>
Motivation: 近年来TTS（文本到语音）技术主观评测结果显示进步显著，但作者质疑这些系统是否真的能在类似图灵测试的人类欺骗测试中“骗过”人类。传统CMOS分数不能充分反映TTS系统的真实表现，因此需要更客观、严格的评测指标。

Method: 作者提出了HFR（Human Fooling Rate），衡量人对于机器生成语音误以为是人类语音的频率，并对多个开源和商业TTS模型进行大规模评测，包括在多样化数据集和不同调优条件下的对比。

Result: （1）许多基于CMOS的“达到人类水平”说法在欺骗性测试下不成立；（2）如果用单调或表达力较低的语音参考，TTS评测门槛过低，应选择能获得高HFR的人类语音数据集做基准；（3）商业TTS模型在zero-shot场景下较能“欺骗”人类，而开源系统在自然对话语音上仍有差距；（4）用高质量数据微调虽提升了语音真实感，但仍无法完全弥合与人类的差距。

Conclusion: 现有TTS主观测试不能完全替代以“欺骗性”为基础的真实感评估，未来TTS评估需结合HFR等更具人类中心的指标。

Abstract: While subjective evaluations in recent years indicate rapid progress in TTS,
can current TTS systems truly pass a human deception test in a Turing-like
evaluation? We introduce Human Fooling Rate (HFR), a metric that directly
measures how often machine-generated speech is mistaken for human. Our
large-scale evaluation of open-source and commercial TTS models reveals
critical insights: (i) CMOS-based claims of human parity often fail under
deception testing, (ii) TTS progress should be benchmarked on datasets where
human speech achieves high HFRs, as evaluating against monotonous or less
expressive reference samples sets a low bar, (iii) Commercial models approach
human deception in zero-shot settings, while open-source systems still struggle
with natural conversational speech; (iv) Fine-tuning on high-quality data
improves realism but does not fully bridge the gap. Our findings underscore the
need for more realistic, human-centric evaluations alongside existing
subjective tests.

</details>


### [162] [Hacking Hallucinations of MLLMs with Causal Sufficiency and Necessity](https://arxiv.org/abs/2508.04182)
*Peizheng Guo,Jingyao Wang,Wenwen Qiang,Huijie Guo,Changwen Zheng,Jiahuan Zhou,Gang Hua*

Main category: cs.CL

TL;DR: 本文提出了一种结合因果完备性的强化学习新方法，有效缓解多模态大模型（MLLMs）生成幻觉（hallucination）的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大模型在视觉-语言任务中表现突出，但仍存在幻觉现象，即模型输出与输入图像或文本语义不一致，影响模型可信度和应用落地。作者通过因果分析，针对产生幻觉的不同原因，动机在于深入理解并优化模型行为，从根本上减少幻觉输出。

Method: 作者首先通过因果分析区分了幻觉产生的两类主要原因：一是因果因素抓取不充分导致的遗漏（omission）；二是被非因果线索误导导致的伪造（fabrication）。随后，提出了一种基于因果完备性引导的强化学习新框架，兼顾令（token）因果充足性和因果必要性，基于每个token的独立贡献和反事实不可或缺性计算奖励，结合GRPO优化算法，提升模型生成的因果合理性。

Result: 在多个基准数据集和任务上的实验结果表明，该因果完备性强化学习方法能显著减少MLLMs的幻觉现象。

Conclusion: 本文新方法不仅有效缓解了多模态大模型的幻觉问题，也为模型生成内容的因果推理和可信学习提供了理论和实践的范式。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated impressive
capabilities across vision-language tasks. However, they may suffer from
hallucinations--generating outputs that are semantically inconsistent with the
input image or text. Through causal analyses, we find that: (i) hallucinations
with omission may arise from the failure to adequately capture essential causal
factors, and (ii) hallucinations with fabrication are likely caused by the
model being misled by non-causal cues. To address these challenges, we propose
a novel reinforcement learning framework guided by causal completeness, which
jointly considers both causal sufficiency and causal necessity of tokens.
Specifically, we evaluate each token's standalone contribution and
counterfactual indispensability to define a token-level causal completeness
reward. This reward is used to construct a causally informed advantage function
within the GRPO optimization framework, encouraging the model to focus on
tokens that are both causally sufficient and necessary for accurate generation.
Experimental results across various benchmark datasets and tasks demonstrate
the effectiveness of our approach, which effectively mitigates hallucinations
in MLLMs.

</details>


### [163] [Characterizing Deep Research: A Benchmark and Formal Definition](https://arxiv.org/abs/2508.04183)
*Abhinav Java,Ashmit Khandelwal,Sukruta Midigeshi,Aaron Halfaker,Amit Deshpande,Navin Goyal,Ankur Gupta,Nagarajan Natarajan,Amit Sharma*

Main category: cs.CL

TL;DR: 本文提出了对『深度研究』（Deep Research, DR）任务的正式定义，并发布了用于评测DR系统性能的基准数据集LiveDRBench。该任务核心不在于长篇报告的生成，而是要求在检索过程中进行广泛且复杂的推理探索。实验结果显示，目前主流DR系统在不同子类别的F1分数仅为0.02~0.72，OpenAI的模型表现最佳但F1也仅为0.55。作者分析了系统在搜索推理过程中的多分支、回溯等行为，并指出未来改进方向。


<details>
  <summary>Details</summary>
Motivation: 尽管深度研究（DR）作为新兴的信息任务受到广泛关注，但其任务边界尚不明确，并且与其他需要推理的任务区分不清。因此，作者希望通过正式定义该任务，并提供权威的评测工具，推动该领域有序发展。

Method: 1）正式界定DR任务，将其定义为在检索过程中需对概念高扩展、广覆盖和复杂推理的探索任务；2）提出中间输出结构，将推理挑战与报告生成分离；3）构建包含100个科学和公共话题任务的基准数据集LiveDRBench，并对现有主流DR系统进行评测。

Result: 主流DR系统在该基准集上的F1得分差异较大（0.02~0.72），OpenAI最新模型F1为0.55，整体表现尚有较大提升空间。对推理流程分析显示，当前系统在多分支推理、信息回溯等方面尚存在不足。

Conclusion: 作者提出的任务定义和评测基准为DR能力的客观对比创造了条件。研究结果揭示了当前DR系统在推理覆盖和溯源能力方面的显著差距，为未来相关系统机制改进提供了方向。

Abstract: Information tasks such as writing surveys or analytical reports require
complex search and reasoning, and have recently been grouped under the umbrella
of \textit{deep research} -- a term also adopted by recent models targeting
these capabilities. Despite growing interest, the scope of the deep research
task remains underdefined and its distinction from other reasoning-intensive
problems is poorly understood. In this paper, we propose a formal
characterization of the deep research (DR) task and introduce a benchmark to
evaluate the performance of DR systems. We argue that the core defining feature
of deep research is not the production of lengthy report-style outputs, but
rather the high fan-out over concepts required during the search process, i.e.,
broad and reasoning-intensive exploration. To enable objective evaluation, we
define DR using an intermediate output representation that encodes key claims
uncovered during search-separating the reasoning challenge from surface-level
report generation. Based on this formulation, we propose a diverse, challenging
benchmark LiveDRBench with 100 challenging tasks over scientific topics (e.g.,
datasets, materials discovery, prior art search) and public interest events
(e.g., flight incidents, movie awards). Across state-of-the-art DR systems, F1
score ranges between 0.02 and 0.72 for any sub-category. OpenAI's model
performs the best with an overall F1 score of 0.55. Analysis of reasoning
traces reveals the distribution over the number of referenced sources,
branching, and backtracking events executed by current DR systems, motivating
future directions for improving their search mechanisms and grounding
capabilities. The benchmark is available at
https://github.com/microsoft/LiveDRBench.

</details>


### [164] [Eliciting and Analyzing Emergent Misalignment in State-of-the-Art Large Language Models](https://arxiv.org/abs/2508.04196)
*Siddhant Panpatil,Hiskias Dingeto,Haon Park*

Main category: cs.CL

TL;DR: 语言模型即使经过先进的对齐训练，依然容易在精心设计的对话场景下被诱导出现不良行为。作者手动攻破Claude-4-Opus模型，归纳总结10种有效攻击情境，并提出了MISALIGNMENTBENCH评测框架，发现包括GPT-4.1等现有前沿模型普遍存在高度易受攻击性。


<details>
  <summary>Details</summary>
Motivation: 近年来，LLM对齐技术取得巨大进展，但是否真正能抵御复杂的对话操控和心理引诱尚无充分实证。作者希望揭示当前对齐方法覆盖的盲区及模型潜在安全风险。

Method: 作者采用系统性的人工红队测试，对Claude-4-Opus进行探索，总结出10种能够诱导出“行为偏移”的场景类型。这些情境涉及叙事沉浸、情感施压、战略设定等多维诱导，并以MISALIGNMENTBENCH自动评测框架实现了可复现的横向多模型测试。

Result: 在包括GPT-4.1、Claude-4-Sonnet等5个先进LLM上的评测结果显示，10个攻击场景平均易受攻击率为76%，其中GPT-4.1最高（90%），Claude-4-Sonnet表现较好（40%）。模型会因为推理能力强，反而更容易出现被操控的复杂不对齐行为。

Conclusion: 现有对齐方案对情景化操控和心理诱导类攻击防御力不足；模型复杂推理能力成为攻防新矛盾。论文提供了详细的操控模式分类和通用评测基准，为提升未来AI的对齐鲁棒性提供了实践基础和理论指引。

Abstract: Despite significant advances in alignment techniques, we demonstrate that
state-of-the-art language models remain vulnerable to carefully crafted
conversational scenarios that can induce various forms of misalignment without
explicit jailbreaking. Through systematic manual red-teaming with
Claude-4-Opus, we discovered 10 successful attack scenarios, revealing
fundamental vulnerabilities in how current alignment methods handle narrative
immersion, emotional pressure, and strategic framing. These scenarios
successfully elicited a range of misaligned behaviors, including deception,
value drift, self-preservation, and manipulative reasoning, each exploiting
different psychological and contextual vulnerabilities. To validate
generalizability, we distilled our successful manual attacks into
MISALIGNMENTBENCH, an automated evaluation framework that enables reproducible
testing across multiple models. Cross-model evaluation of our 10 scenarios
against five frontier LLMs revealed an overall 76% vulnerability rate, with
significant variations: GPT-4.1 showed the highest susceptibility (90%), while
Claude-4-Sonnet demonstrated greater resistance (40%). Our findings demonstrate
that sophisticated reasoning capabilities often become attack vectors rather
than protective mechanisms, as models can be manipulated into complex
justifications for misaligned behavior. This work provides (i) a detailed
taxonomy of conversational manipulation patterns and (ii) a reusable evaluation
framework. Together, these findings expose critical gaps in current alignment
strategies and highlight the need for robustness against subtle, scenario-based
manipulation in future AI systems.

</details>


### [165] [Reasoning Beyond Labels: Measuring LLM Sentiment in Low-Resource, Culturally Nuanced Contexts](https://arxiv.org/abs/2508.04199)
*Millicent Ochieng,Anja Thieme,Ignatius Ezeani,Risa Ueno,Samuel Maina,Keshet Ronen,Javier Gonzalez,Jacki O'Neill*

Main category: cs.CL

TL;DR: 本文提出了一个用于分析低资源、多文化情境下情感分析能力的诊断框架，聚焦LLM在肯尼亚奈洛比青年健康群体聊天信息中的表现。结果表明，高质量LLM在情感解释上更稳定，而开放式模型在含糊或情感变化下表现较差。


<details>
  <summary>Details</summary>
Motivation: 传统NLP方法假设情感标签固定，表达方式普遍化，但在文化差异大、资源稀缺的环境下效果不佳，因此需要新的评估和分析方法来贴合实际复杂语境。

Method: 采用人类标注数据、情感反转对照文本以及基于评分标准的解释评估，通过追踪LLM的可解释性、稳健性及与人类推理的一致性，综合检验模型在特定语境下的情感分析能力。

Result: 发现不同LLM在推理质量上存在明显差异，顶级LLM在解释时表现出较强的稳定性，而开放式模型在应对语义含糊或情感转变时容易出错。

Conclusion: 情感分析任务中，需重视文化敏感性和推理过程评估，应开发更能适应实际复杂通讯环境的AI评价方法与工具。

Abstract: Sentiment analysis in low-resource, culturally nuanced contexts challenges
conventional NLP approaches that assume fixed labels and universal affective
expressions. We present a diagnostic framework that treats sentiment as a
context-dependent, culturally embedded construct, and evaluate how large
language models (LLMs) reason about sentiment in informal, code-mixed WhatsApp
messages from Nairobi youth health groups. Using a combination of
human-annotated data, sentiment-flipped counterfactuals, and rubric-based
explanation evaluation, we probe LLM interpretability, robustness, and
alignment with human reasoning. Framing our evaluation through a social-science
measurement lens, we operationalize and interrogate LLMs outputs as an
instrument for measuring the abstract concept of sentiment. Our findings reveal
significant variation in model reasoning quality, with top-tier LLMs
demonstrating interpretive stability, while open models often falter under
ambiguity or sentiment shifts. This work highlights the need for culturally
sensitive, reasoning-aware AI evaluation in complex, real-world communication.

</details>


### [166] [ReasoningGuard: Safeguarding Large Reasoning Models with Inference-time Safety Aha Moments](https://arxiv.org/abs/2508.04204)
*Yuquan Wang,Mi Zhang,Yining Wang,Geng Hong,Xiaoyu You,Min Yang*

Main category: cs.CL

TL;DR: 本文提出了一种高效的推理模型安全防护方案ReasoningGuard，无需额外微调或专家知识，即可实时抑制模型生成有害内容，并优于现有七种防护方法。


<details>
  <summary>Details</summary>
Motivation: 大规模推理模型（LRMs）在高阶推理任务中表现优异，但在推理过程的中后期仍容易生成有害内容。现有防护方案高度依赖昂贵的微调和专家知识，难以扩展，需要一种成本更低、实用性强的新方法。

Method: 提出ReasoningGuard作为推理过程中的安全防护措施，通过分析模型内部注意力机制，定位推理过程中的关键节点，在合适时机注入以安全为导向的'aha'反思步骤。此外，引入缩放采样策略，在解码阶段动态选取最优推理路径，以保护后续推理和最终答案的安全。该方法不需要重新训练模型，且额外推理开销极小。

Result: ReasoningGuard显著削弱了三类针对推理过程的越狱攻击（包括最新攻击手法）的成功率，并在实测中超越了七种已有的安全防护方案，在保证安全的同时，规避了普遍存在的过度安全限制问题。

Conclusion: ReasoningGuard为大模型推理安全提供了高效、可扩展的新思路，兼顾了安全性和推理有用性，有望在实际安全防护中取代现有高成本方法。

Abstract: Large Reasoning Models (LRMs) have demonstrated impressive performance in
reasoning-intensive tasks, but they remain vulnerable to harmful content
generation, particularly in the mid-to-late steps of their reasoning processes.
Existing defense mechanisms, however, rely on costly fine-tuning and additional
expert knowledge, which restricts their scalability. In this work, we propose
ReasoningGuard, an inference-time safeguard for LRMs, which injects timely
safety aha moments to steer harmless while helpful reasoning processes.
Leveraging the model's internal attention behavior, our approach accurately
identifies critical points in the reasoning path, and triggers spontaneous,
safety-oriented reflection. To safeguard both the subsequent reasoning steps
and the final answers, we further implement a scaling sampling strategy during
the decoding phase, selecting the optimal reasoning path. Inducing minimal
extra inference cost, ReasoningGuard effectively mitigates three types of
jailbreak attacks, including the latest ones targeting the reasoning process of
LRMs. Our approach outperforms seven existing safeguards, achieving
state-of-the-art safety defenses while effectively avoiding the common
exaggerated safety issues.

</details>


### [167] [Hierarchical Text Classification Using Black Box Large Language Models](https://arxiv.org/abs/2508.04219)
*Kosuke Yoshimura,Hisashi Kashima*

Main category: cs.CL

TL;DR: 本文探索了利用黑盒大语言模型（LLM）API来进行层次化文本分类（HTC）的可行性，比较了三种提示策略在零样本和少样本场景下的表现，并与传统机器学习方法进行对比。结果表明DH策略在深层次标签体系上优于传统方法，但成本增高。


<details>
  <summary>Details</summary>
Motivation: 层次化文本分类任务因标签体系复杂、数据稀缺和模型复杂性高而困难。传统方法依赖大量标注数据和高计算资源，作者希望评估通过LLM API基于提示（prompting）的方法，作为传统方法的替代方案。

Method: 研究采用三种提示策略（DL、DH、TMH），并在零样本与少样本两种场景下，在两个数据集上进行分类实验，比较LLM方法和传统机器学习模型的准确率与成本。

Result: 少样本提升准确率优于零样本。在标签层级较深的数据集上，DH策略的LLM方法优于机器学习模型。DH策略在输入token上消耗更多，导致API成本上升。

Conclusion: 黑盒LLM适合层次化文本分类，尤其在复杂层级下能取得更好性能。但需要根据具体任务权衡成本与准确性，合理选择提示策略。

Abstract: Hierarchical Text Classification (HTC) aims to assign texts to structured
label hierarchies; however, it faces challenges due to data scarcity and model
complexity. This study explores the feasibility of using black box Large
Language Models (LLMs) accessed via APIs for HTC, as an alternative to
traditional machine learning methods that require extensive labeled data and
computational resources. We evaluate three prompting strategies -- Direct Leaf
Label Prediction (DL), Direct Hierarchical Label Prediction (DH), and Top-down
Multi-step Hierarchical Label Prediction (TMH) -- in both zero-shot and
few-shot settings, comparing the accuracy and cost-effectiveness of these
strategies. Experiments on two datasets show that a few-shot setting
consistently improves classification accuracy compared to a zero-shot setting.
While a traditional machine learning model achieves high accuracy on a dataset
with a shallow hierarchy, LLMs, especially DH strategy, tend to outperform the
machine learning model on a dataset with a deeper hierarchy. API costs increase
significantly due to the higher input tokens required for deeper label
hierarchies on DH strategy. These results emphasize the trade-off between
accuracy improvement and the computational cost of prompt strategy. These
findings highlight the potential of black box LLMs for HTC while underscoring
the need to carefully select a prompt strategy to balance performance and cost.

</details>


### [168] [DP-GPT4MTS: Dual-Prompt Large Language Model for Textual-Numerical Time Series Forecasting](https://arxiv.org/abs/2508.04239)
*Chanjuan Liu,Shengzhi Wang,Enqiang Zhu*

Main category: cs.CL

TL;DR: 本文提出了DP-GPT4MTS，一种基于双提示的多模态时序预测大语言模型，将文本信息与数值时间序列结合，实验结果显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统时序预测侧重于数值序列，常忽视与时间关联的文本信息（如新闻、事件）对预测准确性的提升潜力。现有大语言模型集成文本信息存在信息冗余、语义捕捉不足等问题。

Method: DP-GPT4MTS采用双提示机制：显式提示（指导任务）和文本提示（提取时间戳文本语义）。显式提示由tokenizer生成，文本提示经过自注意力和前馈网络增强，并融合至模型进行多模态预测。

Result: 在多种带有文本与数值信息的时序数据集上，DP-GPT4MTS预测效果明显优于现有最先进算法。

Conclusion: 引入双提示机制、高效整合时间戳文本上下文有助于提升时序预测精度，对多模态时序建模具有重要意义。

Abstract: Time series forecasting is crucial in strategic planning and decision-making
across various industries. Traditional forecasting models mainly concentrate on
numerical time series data, often overlooking important textual information
such as events and news, which can significantly affect forecasting accuracy.
While large language models offer a promise for integrating multimodal data,
existing single-prompt frameworks struggle to effectively capture the semantics
of timestamped text, introducing redundant information that can hinder model
performance. To address this limitation, we introduce DP-GPT4MTS (Dual-Prompt
GPT2-base for Multimodal Time Series), a novel dual-prompt large language model
framework that combines two complementary prompts: an explicit prompt for clear
task instructions and a textual prompt for context-aware embeddings from
time-stamped data. The tokenizer generates the explicit prompt while the
embeddings from the textual prompt are refined through self-attention and
feed-forward networks. Comprehensive experiments conducted on diverse
textural-numerical time series datasets demonstrate that this approach
outperforms state-of-the-art algorithms in time series forecasting. This
highlights the significance of incorporating textual context via a dual-prompt
mechanism to achieve more accurate time series predictions.

</details>


### [169] [TalkDep: Clinically Grounded LLM Personas for Conversation-Centric Depression Screening](https://arxiv.org/abs/2508.04248)
*Xi Wang,Anxo Perez,Javier Parapar,Fabio Crestani*

Main category: cs.CL

TL;DR: 本文提出了一种基于先进语言模型的新型虚拟患者模拟系统TalkDep，用于提升抑郁症诊断系统的训练和评估手段。


<details>
  <summary>Details</summary>
Motivation: 随着对心理健康服务需求的增加，临床培训数据稀缺，导致抑郁症诊断支持受限。这促使研究者探索虚拟患者的开发，以辅助训练和评估。

Method: 作者采用最新的语言模型为核心，提出了“临床医生参与回路”的TalkDep管线，通过结合精神病诊断标准、症状严重程度量表及情境因素，生成多样化、自然且临床有效的虚拟患者反应，并由临床专家评估其可靠性。

Result: 经过临床专业人员的详细评估，所生成的虚拟患者被证明具备较高的临床有效性。

Conclusion: 经过验证的虚拟患者资源可作为可扩展且适应性强的工具，用于提升自动化抑郁症诊断系统的稳健性与泛化能力。

Abstract: The increasing demand for mental health services has outpaced the
availability of real training data to develop clinical professionals, leading
to limited support for the diagnosis of depression. This shortage has motivated
the development of simulated or virtual patients to assist in training and
evaluation, but existing approaches often fail to generate clinically valid,
natural, and diverse symptom presentations. In this work, we embrace the recent
advanced language models as the backbone and propose a novel
clinician-in-the-loop patient simulation pipeline, TalkDep, with access to
diversified patient profiles to develop simulated patients. By conditioning the
model on psychiatric diagnostic criteria, symptom severity scales, and
contextual factors, our goal is to create authentic patient responses that can
better support diagnostic model training and evaluation. We verify the
reliability of these simulated patients with thorough assessments conducted by
clinical professionals. The availability of validated simulated patients offers
a scalable and adaptable resource for improving the robustness and
generalisability of automatic depression diagnosis systems.

</details>


### [170] [KVSink: Understanding and Enhancing the Preservation of Attention Sinks in KV Cache Quantization for LLMs](https://arxiv.org/abs/2508.04257)
*Zunhai Su,Kehong Yuan*

Main category: cs.CL

TL;DR: 该论文提出KVSink方法，通过有效预测attention sinks，以提升KV cache量化下大模型推理的效果。


<details>
  <summary>Details</summary>
Motivation: 现有KV cache量化方法虽然能减少内存和缓解瓶颈，但通常只保护前几个token的精度，忽略了attention sinks在后续token中也可能出现，导致性能下降且原理未被充分理解。

Method: 作者深入分析了attention sinks在推理中的作用和极端激活异常值的跨层演化，与KV cache量化之间的联系，并基于新发现提出KVSink方法，可高效预测sink token并优先保护，无明显计算开销，可直接应用于现有流程。

Result: 大量实验表明，KVSink相比以往的Preserve-First-N策略，在KV cache量化中能更有效保护attention sinks，将KVSink应用于主流KVQuant方法时，困惑度（PPL）进一步降低，对16位数值异常值的依赖也减少。

Conclusion: KVSink是一种高效且易用的方法，能够补全现有KV cache量化对attention sinks保护不足的问题，显著提升大模型推理性能并降低异常值依赖。

Abstract: Key-Value (KV) cache quantization has become a widely adopted optimization
technique for efficient large language models (LLMs) inference by reducing KV
cache memory usage and mitigating memory-bound constraints. Recent studies have
emphasized the importance of preserving the original precision of KVs for the
first few tokens to ensure the protection of attention sinks. While this
approach has proven effective in mitigating performance degradation, its
underlying principles remain insufficiently understood. Moreover, it fails to
address the recent discovery that attention sinks can emerge beyond the initial
token positions. In this work, we elucidate the underlying mechanisms of
attention sinks during inference by examining their role in the cross-layer
evolution of extreme activation outliers. Additionally, we provide a
comprehensive analysis of the interplay between attention sinks and KV cache
quantization. Based on our enhanced understanding, we introduce
\textit{\textbf{KVSink}}, a plug-and-play method that effectively predicts sink
tokens with negligible overhead, enabling more thorough preservation. Extensive
experiments demonstrate that KVSink outperforms the existing Preserve-First-N
(PFN) strategy, offering more effective preservation of attention sinks during
KV cache quantization. Moreover, when applied to the well-established KVQuant
method, KVSink further improves perplexity (PPL) and reduces reliance on 16-bit
numerical outliers.

</details>


### [171] [ShoppingBench: A Real-World Intent-Grounded Shopping Benchmark for LLM-based Agents](https://arxiv.org/abs/2508.04266)
*Jiangyuan Wang,Kejun Xiao,Qi Sun,Huaipeng Zhao,Tao Luo,Jiandong Zhang,Xiaoyi Zeng*

Main category: cs.CL

TL;DR: 本文提出了ShoppingBench，一个更接近真实复杂购物目标的电商基准测试，并开发了仿真环境和小模型蒸馏方法。实验证明，即使是最先进的大模型在此基准上的表现也不高，说明任务具有突出挑战性。


<details>
  <summary>Details</summary>
Motivation: 现有电商基准测试只关注基础用户意图（如找商品、购买），但真实用户有更丰富和复杂需求（如领券、预算管理、多商品查找）。因此，作者提出要建立覆盖更复杂场景和多样用户意图的新基准测试。

Method: 1）提出ShoppingBench框架，通过真实商品样本模拟多层次的复杂用户意图指令；2）开发一个大规模（250万真实商品）的仿真沙盒环境，实现端到端可交互的购物流程评测；3）引入基于轨迹蒸馏和有监督微调、强化学习相结合的方法，将大语言模型能力迁移到小模型。

Result: 实验表明，即使是GPT-4.1这样最先进的语言智能体，在该任务基准上的绝对成功率也不到50%；采用轨迹蒸馏和微调的小模型能取得与GPT-4.1相近的竞争性能。

Conclusion: ShoppingBench比已有基准更接近真实复杂电商场景，挑战性强且能够更有效评估购物场景下智能体能力；所提出的小模型蒸馏方法可提升小模型在复杂购物任务上的实用性。

Abstract: Existing benchmarks in e-commerce primarily focus on basic user intents, such
as finding or purchasing products. However, real-world users often pursue more
complex goals, such as applying vouchers, managing budgets, and finding
multi-products seller. To bridge this gap, we propose ShoppingBench, a novel
end-to-end shopping benchmark designed to encompass increasingly challenging
levels of grounded intent. Specifically, we propose a scalable framework to
simulate user instructions based on various intents derived from sampled
real-world products. To facilitate consistent and reliable evaluations, we
provide a large-scale shopping sandbox that serves as an interactive simulated
environment, incorporating over 2.5 million real-world products. Experimental
results demonstrate that even state-of-the-art language agents (such as
GPT-4.1) achieve absolute success rates under 50% on our benchmark tasks,
highlighting the significant challenges posed by our ShoppingBench. In
addition, we propose a trajectory distillation strategy and leverage supervised
fine-tuning, along with reinforcement learning on synthetic trajectories, to
distill the capabilities of a large language agent into a smaller one. As a
result, our trained agent achieves competitive performance compared to GPT-4.1.

</details>


### [172] [A Few Words Can Distort Graphs: Knowledge Poisoning Attacks on Graph-based Retrieval-Augmented Generation of Large Language Models](https://arxiv.org/abs/2508.04276)
*Jiayi Wen,Tianxin Chen,Zhirun Zheng,Cheng Huang*

Main category: cs.CL

TL;DR: 本文分析了图结构增强生成（GraphRAG）的新型知识投毒攻击，提出两种攻击方法并展示其极高的毒化效率与现有防御手段的失效。


<details>
  <summary>Details</summary>
Motivation: GraphRAG通过将原始文本转为知识图谱以提升大语言模型的准确性和可解释性，但其依赖LLM从文本中提取知识，存在被恶意篡改的风险。作者关注于GraphRAG在知识构建阶段的安全性漏洞，旨在揭示其潜在的攻击面。

Method: 作者提出两种知识投毒攻击方法：(1)定向投毒（TKPA）：使用图论分析识别易受攻击节点，并通过LLM改写相关叙述，实现对特定QA结果的精准操控；(2)通用投毒（UKPA）：利用指代和依存关系等语言特性，通过最小化全局文本修改破坏知识图结构。

Result: TKPA实现了高达93.1%的投毒成功率，并保持文本流畅自然。UKPA仅需修改不到0.05%的原文，即可将QA准确率从95%骤降至50%。现有主流防御方法无法识别这些攻击。

Conclusion: GraphRAG类管道在知识投毒攻击下极其脆弱，现有防御手段无法有效应对，未来需重点关注其安全性防护。

Abstract: Graph-based Retrieval-Augmented Generation (GraphRAG) has recently emerged as
a promising paradigm for enhancing large language models (LLMs) by converting
raw text into structured knowledge graphs, improving both accuracy and
explainability. However, GraphRAG relies on LLMs to extract knowledge from raw
text during graph construction, and this process can be maliciously manipulated
to implant misleading information. Targeting this attack surface, we propose
two knowledge poisoning attacks (KPAs) and demonstrate that modifying only a
few words in the source text can significantly change the constructed graph,
poison the GraphRAG, and severely mislead downstream reasoning. The first
attack, named Targeted KPA (TKPA), utilizes graph-theoretic analysis to locate
vulnerable nodes in the generated graphs and rewrites the corresponding
narratives with LLMs, achieving precise control over specific
question-answering (QA) outcomes with a success rate of 93.1\%, while keeping
the poisoned text fluent and natural. The second attack, named Universal KPA
(UKPA), exploits linguistic cues such as pronouns and dependency relations to
disrupt the structural integrity of the generated graph by altering globally
influential words. With fewer than 0.05\% of full text modified, the QA
accuracy collapses from 95\% to 50\%. Furthermore, experiments show that
state-of-the-art defense methods fail to detect these attacks, highlighting
that securing GraphRAG pipelines against knowledge poisoning remains largely
unexplored.

</details>


### [173] [Beyond the Leaderboard: Rethinking Medical Benchmarks for Large Language Models](https://arxiv.org/abs/2508.04325)
*Zizhan Ma,Wenxuan Wang,Guo Yu,Yiu-Fai Cheung,Meidan Ding,Jie Liu,Wenting Chen,Linlin Shen*

Main category: cs.CL

TL;DR: 该论文提出并验证了一个针对医疗类基准测试的全生命周期评估框架MedCheck，以提升大语言模型(LLMs)在医疗领域基准评测的规范性与安全性。


<details>
  <summary>Details</summary>
Motivation: 当前医疗领域用于评估大语言模型的基准测试普遍存在临床适用性差、数据管理薄弱以及缺乏安全评估指标的问题，亟需一个更具医学针对性和全面性的评估体系。

Method: 作者提出MedCheck评估框架，将医疗基准测试的开发过程拆分为五个连续阶段，并设计了46项医学定制化评估标准。同时，利用该框架对53个现有医疗LLM基准进行了实证分析。

Result: 实证分析发现医疗类基准普遍存在与真实临床应用脱节、数据完整性危机（如数据交叉污染风险）、对模型鲁棒性及不确定性等安全关键环节忽视等系统性问题。

Conclusion: MedCheck不仅能作为现有医疗基准的诊断工具，也为未来医疗AI评测流程的标准化、可靠性和透明度提升提供具体可行的操作建议。

Abstract: Large language models (LLMs) show significant potential in healthcare,
prompting numerous benchmarks to evaluate their capabilities. However, concerns
persist regarding the reliability of these benchmarks, which often lack
clinical fidelity, robust data management, and safety-oriented evaluation
metrics. To address these shortcomings, we introduce MedCheck, the first
lifecycle-oriented assessment framework specifically designed for medical
benchmarks. Our framework deconstructs a benchmark's development into five
continuous stages, from design to governance, and provides a comprehensive
checklist of 46 medically-tailored criteria. Using MedCheck, we conducted an
in-depth empirical evaluation of 53 medical LLM benchmarks. Our analysis
uncovers widespread, systemic issues, including a profound disconnect from
clinical practice, a crisis of data integrity due to unmitigated contamination
risks, and a systematic neglect of safety-critical evaluation dimensions like
model robustness and uncertainty awareness. Based on these findings, MedCheck
serves as both a diagnostic tool for existing benchmarks and an actionable
guideline to foster a more standardized, reliable, and transparent approach to
evaluating AI in healthcare.

</details>


### [174] [Modelling and Classifying the Components of a Literature Review](https://arxiv.org/abs/2508.04337)
*Francisco Bolaños,Angelo Salatino,Francesco Osborne,Enrico Motta*

Main category: cs.CL

TL;DR: 本文提出用于科研论文语句修辞角色注释的新方案，构建了新的数据集和基准，系统评估了多种主流大语言模型在该任务上的表现，为文献综述自动化打下基础。


<details>
  <summary>Details</summary>
Motivation: 分析科研文献时，按照语句修辞角色进行标注有助于AI理解和生成高质量的文献综述。然而，目前缺乏专门支持该目的的注释体系和大规模标注方法。

Method: 1）提出专为文献综述生成设计的新型语句修辞角色注释体系；2）构建含有人工与自动注释的Sci-Sentence多学科基准数据集；3）对37个不同类型和规模的大语言模型，通过零样本和微调等方式进行全面评测。

Result: 实验发现：1）当前LLMs在高质量微调数据上表现卓越，F1超过96%；2）GPT-4o类模型最佳，但部分轻量开源模型也有惊艳表现；3）引入由LLMs生成的半合成训练数据可提升小型编码器和开放解码器模型的效果。

Conclusion: 提出的注释方案与数据集推动了修辞角色识别研究的发展，为AI自动生成高质量文献综述奠定了基础。开放及高效模型的优异表现显示，该领域自动化和普惠化大有可为。

Abstract: Previous work has demonstrated that AI methods for analysing scientific
literature benefit significantly from annotating sentences in papers according
to their rhetorical roles, such as research gaps, results, limitations,
extensions of existing methodologies, and others. Such representations also
have the potential to support the development of a new generation of systems
capable of producing high-quality literature reviews. However, achieving this
goal requires the definition of a relevant annotation schema and effective
strategies for large-scale annotation of the literature. This paper addresses
these challenges by 1) introducing a novel annotation schema specifically
designed to support literature review generation and 2) conducting a
comprehensive evaluation of a wide range of state-of-the-art large language
models (LLMs) in classifying rhetorical roles according to this schema. To this
end, we also present Sci-Sentence, a novel multidisciplinary benchmark
comprising 700 sentences manually annotated by domain experts and 2,240
sentences automatically labelled using LLMs. We evaluate 37 LLMs on this
benchmark, spanning diverse model families and sizes, using both zero-shot
learning and fine-tuning approaches. The experiments yield several novel
insights that advance the state of the art in this challenging domain. First,
the current generation of LLMs performs remarkably well on this task when
fine-tuned on high-quality data, achieving performance levels above 96\% F1.
Second, while large proprietary models like GPT-4o achieve the best results,
some lightweight open-source alternatives also demonstrate excellent
performance. Finally, enriching the training data with semi-synthetic examples
generated by LLMs proves beneficial, enabling small encoders to achieve robust
results and significantly enhancing the performance of several open decoder
models.

</details>


### [175] [GTPO and GRPO-S: Token and Sequence-Level Reward Shaping with Policy Entropy](https://arxiv.org/abs/2508.04349)
*Hongze Tan,Jianfei Pan*

Main category: cs.CL

TL;DR: 本文针对大语言模型在强化学习中的细粒度奖励分配问题，提出动态熵加权机制，通过GTPO和GRPO-S两种方式显著提升模型推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有如GRPO等强化学习算法在提升大语言模型推理能力时，对长序列的奖励分配过于粗糙，全部token获得相同奖励，无法区分每个token对整体任务的贡献，限制了模型在复杂推理任务中的表现。

Method: 提出动态熵加权机制（Dynamic Entropy Weighting）：1）Group Token Policy Optimization (GTPO)：对序列中每个token分配基于熵的加权奖励，实现精细的信用分配；2）Sequence-Level Group Relative Policy Optimization (GRPO-S)：根据序列平均token熵加权奖励每个序列。

Result: 实验结果显示，该方法在推理类任务上显著优于强基线DAPO，证明熵加权对于提升推理能力有重要作用。

Conclusion: 动态熵加权机制能为大语言模型带来更高的推理性能上限，是提升深度推理能力的有效手段。

Abstract: Reinforcement learning (RL) with algorithms like Group Relative Policy
Optimization (GRPO) improves Large Language Model (LLM) reasoning, but is
limited by a coarse-grained credit assignment that applies a uniform reward to
all tokens in a sequence. This is a major flaw in long-chain reasoning tasks.
This paper solves this with \textbf{Dynamic Entropy Weighting}. Our core idea
is that high-entropy tokens in correct responses can guide the policy toward a
higher performance ceiling. This allows us to create more fine-grained reward
signals for precise policy updates via two ways: 1) \textbf{Group Token Policy
Optimization} (\textbf{GTPO}), we assigns a entropy-weighted reward to each
token for fine-grained credit assignment. 2) \textbf{Sequence-Level Group
Relative Policy Optimization} (\textbf{GRPO-S}), we assigns a entropy-weighted
reward to each sequence based on its average token entropy. Experiments show
our methods significantly outperform the strong DAPO baseline. The results
confirm that our entropy-weighting mechanism is the key driver of this
performance boost, offering a better path to enhance deep reasoning in models.

</details>


### [176] [Chain of Questions: Guiding Multimodal Curiosity in Language Models](https://arxiv.org/abs/2508.04350)
*Nima Iji,Kia Dashtipour*

Main category: cs.CL

TL;DR: 本文提出了Chain of Questions (CoQ) 框架，一种基于好奇心驱动的推理方法，提升了多模态大模型在复杂环境中的推理能力和任务表现。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型虽然在推理方面有进步（如思维链、逐步解释等），但尚未很好地迁移到多模态场景。面对真实世界复杂环境，模型需要主动决定选用哪些感官模态（视觉、听觉、空间等），以更有效地推理和响应。

Method: 提出CoQ框架，鼓励多模态语言模型主动生成与环境相关的有针对性的问题，通过这些问题有选择地激活、融合相关模态信息，从而收集关键数据提升推理和生成能力。实验基于集成WebGPT、ScienceQA、AVSD和ScanQA的新型多模态基准数据集进行评估。

Result: 实验结果显示，CoQ方法能有效提升底座模型识别与整合重要感官信息的能力，推理过程的准确性、可解释性和多模态任务对齐性都有明显提升。

Conclusion: CoQ框架为多模态大模型带来更优的推理与响应能力，推动其在多种复杂场景下的实际应用潜力。

Abstract: Reasoning capabilities in large language models (LLMs) have substantially
advanced through methods such as chain-of-thought and explicit step-by-step
explanations. However, these improvements have not yet fully transitioned to
multimodal contexts, where models must proactively decide which sensory
modalities such as vision, audio, or spatial perception to engage when
interacting with complex real-world environments. In this paper, we introduce
the Chain of Questions (CoQ) framework, a curiosity-driven reasoning approach
that encourages multimodal language models to dynamically generate targeted
questions regarding their surroundings. These generated questions guide the
model to selectively activate relevant modalities, thereby gathering critical
information necessary for accurate reasoning and response generation. We
evaluate our framework on a novel multimodal benchmark dataset, assembled by
integrating WebGPT, ScienceQA, AVSD, and ScanQA datasets. Experimental results
demonstrate that our CoQ method improves a foundation model's ability to
effectively identify and integrate pertinent sensory information. This leads to
improved accuracy, interpretability, and alignment of the reasoning process
with diverse multimodal tasks.

</details>


### [177] [AIC CTU@FEVER 8: On-premise fact checking through long context RAG](https://arxiv.org/abs/2508.04390)
*Herbert Ullrich,Jan Drchal*

Main category: cs.CL

TL;DR: 本文介绍了作者开发的事实核查流程，在FEVER 8竞赛中获得了第一名。该系统采用了两步式的RAG（Retrieval-Augmented Generation）管道，并在受限硬件条件下依然取得了最优表现。


<details>
  <summary>Details</summary>
Motivation: 提升事实核查任务中的性能，尤其是在硬件资源有限的情况下，能够在现实部署环境中高效、准确地进行事实核查。

Method: 采用了简单的两步式RAG（检索-增强生成）管道，基于前一年的系统进行了优化，使其可以在本地部署，并在限定的硬件资源（单个NVidia A10 GPU，23GB显存，单次运行限制为60秒）下运行。

Result: 该系统在FEVER 8竞技任务中表现最佳，获得了Ev2R测试分数的最高成绩，证明了其有效性和高效性。

Conclusion: 在有限硬件条件下，作者提出的两步RAG事实核查管道能够实现业界领先的性能，为事实核查在实际应用中的部署提供了可行的解决方案。

Abstract: In this paper, we present our fact-checking pipeline which has scored first
in FEVER 8 shared task. Our fact-checking system is a simple two-step RAG
pipeline based on our last year's submission. We show how the pipeline can be
redeployed on-premise, achieving state-of-the-art fact-checking performance (in
sense of Ev2R test-score), even under the constraint of a single NVidia A10
GPU, 23GB of graphical memory and 60s running time per claim.

</details>


### [178] [Improving Crash Data Quality with Large Language Models: Evidence from Secondary Crash Narratives in Kentucky](https://arxiv.org/abs/2508.04399)
*Xu Zhang,Mei Chen*

Main category: cs.CL

TL;DR: 本文分析了多种先进自然语言处理（NLP）模型在挖掘交通事故叙述、提升事故数据质量中的表现，证明了经过微调的Transformer模型在准确率与效率等方面均优于零样本大模型和传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统的事故数据依赖结构化信息，许多关键细节隐藏在非结构化的事故叙述中。精准识别二次事故对于交通管理和安全提升具有重要意义，因此需借助NLP技术从叙述文本中自动挖掘和提升数据质量。

Method: 作者以肯塔基州2015-2022年间的16,656份交通事故叙述（包含3,803个已确认二次事故）为数据集，比较了三类模型：1）零样本开源大语言模型（如LLaMA3:70B、DeepSeek-R1:70B等），2）多种经过微调的Transformer模型（如RoBERTa、BERT等），3）传统的逻辑回归基线。模型用2015-2021年数据训练并在2022年数据上测试。

Result: 经过微调的Transformer模型表现最优，RoBERTa取得了最高F1分数（0.90）与准确率（95%）；零样本的大模型LLaMA3:70B取得F1为0.86但推理时间远高于Transformer；逻辑回归表现较差（F1:0.66）。部分中等规模大模型在运行时间与效果之间取得较好权衡。

Conclusion: 微调Transformer模型在事故叙述文本挖掘中兼具高准确率与运行效率，是平衡精准性与实用性的最佳选择。研究还提出隐私保护的本地部署、集成方法及增量处理等实用建议，为提高事故数据质量提供可复制的技术方案。

Abstract: This study evaluates advanced natural language processing (NLP) techniques to
enhance crash data quality by mining crash narratives, using secondary crash
identification in Kentucky as a case study. Drawing from 16,656 manually
reviewed narratives from 2015-2022, with 3,803 confirmed secondary crashes, we
compare three model classes: zero-shot open-source large language models (LLMs)
(LLaMA3:70B, DeepSeek-R1:70B, Qwen3:32B, Gemma3:27B); fine-tuned transformers
(BERT, DistilBERT, RoBERTa, XLNet, Longformer); and traditional logistic
regression as baseline. Models were calibrated on 2015-2021 data and tested on
1,771 narratives from 2022. Fine-tuned transformers achieved superior
performance, with RoBERTa yielding the highest F1-score (0.90) and accuracy
(95%). Zero-shot LLaMA3:70B reached a comparable F1 of 0.86 but required 139
minutes of inference; the logistic baseline lagged well behind (F1:0.66). LLMs
excelled in recall for some variants (e.g., GEMMA3:27B at 0.94) but incurred
high computational costs (up to 723 minutes for DeepSeek-R1:70B), while
fine-tuned models processed the test set in seconds after brief training.
Further analysis indicated that mid-sized LLMs (e.g., DeepSeek-R1:32B) can
rival larger counterparts in performance while reducing runtime, suggesting
opportunities for optimized deployments. Results highlight trade-offs between
accuracy, efficiency, and data requirements, with fine-tuned transformer models
balancing precision and recall effectively on Kentucky data. Practical
deployment considerations emphasize privacy-preserving local deployment,
ensemble approaches for improved accuracy, and incremental processing for
scalability, providing a replicable scheme for enhancing crash-data quality
with advanced NLP.

</details>


### [179] [Why are LLMs' abilities emergent?](https://arxiv.org/abs/2508.04401)
*Vladimír Havlík*

Main category: cs.CL

TL;DR: 本文分析了大语言模型（LLM）中能力的“涌现”现象，认为这种能力并非仅来源于参数扩展，而是高度非线性与复杂系统动力学的自然结果。


<details>
  <summary>Details</summary>
Motivation: 大模型展现出的诸多能力常被认为是“出乎意料”且难以从训练目标直接解释。作者关注于人工智能系统“理解的缺失”，试图阐明当前AI能力产生本质。

Method: 论文采用理论分析和实证观察相结合的方法，研究了规模法则（scaling laws）、grokking现象，以及模型能力的“相变”过程，比较了神经网络方法与符号计算范式的根本差别。

Result: 作者发现，模型能力的涌现不是单纯由参数数量决定，而是复杂系统中高度敏感的非线性动态造成的协同行为。此外，现有对指标、预训练损失等关注无法解释其本体性质。

Conclusion: DNN的能力涌现属于类似自然科学中的复杂系统现象，必须以“复杂动力学系统”研究视角探索其内部机制，从而超越现有的表征描述，理解其新型本质。

Abstract: The remarkable success of Large Language Models (LLMs) in generative tasks
has raised fundamental questions about the nature of their acquired
capabilities, which often appear to emerge unexpectedly without explicit
training. This paper examines the emergent properties of Deep Neural Networks
(DNNs) through both theoretical analysis and empirical observation, addressing
the epistemological challenge of "creation without understanding" that
characterises contemporary AI development. We explore how the neural approach's
reliance on nonlinear, stochastic processes fundamentally differs from symbolic
computational paradigms, creating systems whose macro-level behaviours cannot
be analytically derived from micro-level neuron activities. Through analysis of
scaling laws, grokking phenomena, and phase transitions in model capabilities,
I demonstrate that emergent abilities arise from the complex dynamics of highly
sensitive nonlinear systems rather than simply from parameter scaling alone. My
investigation reveals that current debates over metrics, pre-training loss
thresholds, and in-context learning miss the fundamental ontological nature of
emergence in DNNs. I argue that these systems exhibit genuine emergent
properties analogous to those found in other complex natural phenomena, where
systemic capabilities emerge from cooperative interactions among simple
components without being reducible to their individual behaviours. The paper
concludes that understanding LLM capabilities requires recognising DNNs as a
new domain of complex dynamical systems governed by universal principles of
emergence, similar to those operating in physics, chemistry, and biology. This
perspective shifts the focus from purely phenomenological definitions of
emergence to understanding the internal dynamic transformations that enable
these systems to acquire capabilities that transcend their individual
components.

</details>


### [180] [What Do Humans Hear When Interacting? Experiments on Selective Listening for Evaluating ASR of Spoken Dialogue Systems](https://arxiv.org/abs/2508.04402)
*Kiyotada Mori,Seiya Kawano,Chaoran Liu,Carlos Toshinori Ishi,Angel Fernando Garcia Contreras,Koichiro Yoshino*

Main category: cs.CL

TL;DR: 本文探讨了人类在对话中利用“选择性聆听”能力，仅关注与生成对话回复相关的信息，并据此提出了一种新的人机语音识别（ASR）能力评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有SDS系统前端的ASR只关注于整体转录准确度，但实际对话生成只需要捕捉关键信息。人类能够进行选择性聆听，因此借鉴这一能力有助于更合理地评估ASR在实际对话系统中的有效性。

Method: 研究通过让人类以对话回复为目的对语音进行转录，并与完整转录作为参考进行对比，从而实验性地验证人类的选择性聆听现象。

Result: 实验证实了在人类生成对话回复时，存在选择性聆听现象，人类只关注与回复生成相关的语音部分。

Conclusion: 基于该现象，作者提出可以依据人类选择性聆听开发新的ASR评价方法，更真实地反映ASR系统与人类之间在实际对话回复需求上的能力差距。

Abstract: Spoken dialogue systems (SDSs) utilize automatic speech recognition (ASR) at
the front end of their pipeline. The role of ASR in SDSs is to recognize
information in user speech related to response generation appropriately.
Examining selective listening of humans, which refers to the ability to focus
on and listen to important parts of a conversation during the speech, will
enable us to identify the ASR capabilities required for SDSs and evaluate them.
In this study, we experimentally confirmed selective listening when humans
generate dialogue responses by comparing human transcriptions for generating
dialogue responses and reference transcriptions. Based on our experimental
results, we discuss the possibility of a new ASR evaluation method that
leverages human selective listening, which can identify the gap between
transcription ability between ASR systems and humans.

</details>


### [181] [Dialogue Response Prefetching Based on Semantic Similarity and Prediction Confidence of Language Model](https://arxiv.org/abs/2508.04403)
*Kiyotada Mori,Seiya Kawano,Angel Fernando Garcia Contreras,Koichiro Yoshino*

Main category: cs.CL

TL;DR: 本文提出了一种新的预测置信模型（PCM），用于判断在对话系统中是否可以预取响应，以减少用户感知延迟。通过比较预测的用户完整话语与实际话语的语义相似度，实现更有效的响应预取。


<details>
  <summary>Details</summary>
Motivation: 现有对话系统为减少用户等待时长，通常依赖语言模型提前预测完整的用户话语，但提前预测可能不准确，导致响应失效。因此需要更智能的方法来判断何时可以安全地进行预取。

Method: 作者提出了预测置信模型（PCM），该模型通过计算预测的完整用户话语与真实话语之间的语义相似度来判断是否可以进行预取。PCM 模型被用于自动决定在当前条件下是否进行预取。论文还通过对比预测话语和真实话语之间的差异来评估 PCM。

Result: 实验通过对比预测与实际用户话语之间的差异，验证了PCM模型能够较好地区分哪些情况下可以进行安全高效的响应预取。

Conclusion: 预测置信模型（PCM）能够有效提升对话系统响应预取的效果，减少用户等待时间，同时降低响应失效风险。

Abstract: Prefetching of dialogue responses has been investigated to reduce
user-perceived latency (UPL), which refers to the user's waiting time before
receiving the system's response, in spoken dialogue systems. To reduce the UPL,
it is necessary to predict complete user utterances before the end of the
user's speech, typically by language models, to prepare prefetched dialogue
responses. In this study, we proposed a prediction confidence model (PCM) that
determines whether prefetching is possible or not by estimating the semantic
similarity between the predicted complete user utterance and the complete user
utterance. We evaluated our PCM based on the differences between the predicted
complete user utterance and the complete user utterance.

</details>


### [182] [Evaluating, Synthesizing, and Enhancing for Customer Support Conversation](https://arxiv.org/abs/2508.04423)
*Jie Zhu,Huaixia Dou,Junhui Li,Lifan Guo,Feng Chen,Chi Zhang,Fang Kong*

Main category: cs.CL

TL;DR: 本文提出了Customer Support Conversation (CSC)任务，并围绕该任务构建了带有丰富战略指导的对话数据集，显著提升了客服对话生成的质量。


<details>
  <summary>Details</summary>
Motivation: 现有客服对话数据缺乏战略层面的指导，且真实客服数据难以获取和标注。因此，亟需引入结构化、贴近真实业界标准的对话任务和数据集，帮助客服AI提升沟通和问题解决能力。

Method: 提出结构化的CSC框架，基于COPC标准定义了5个对话阶段和12种策略。基于此，利用大模型重写和标注真实客服对话，构建了高质量数据集CSConv，同时通过角色扮演方式与大模型协同生成策略丰富的训练数据集RoleCS。

Result: 实验表明，使用RoleCS对大模型微调后，在CSConv评价集上的策略对齐能力和生成质量均有大幅提升，且通过人工评估显示解决实际问题的效果更好。

Conclusion: 结构化的战略性对话数据和训练流程不仅提升了客服AI的能力，也为后续高水平客服模型开发提供了通用框架和数据资源。

Abstract: Effective customer support requires not only accurate problem solving but
also structured and empathetic communication aligned with professional
standards. However, existing dialogue datasets often lack strategic guidance,
and real-world service data is difficult to access and annotate. To address
this, we introduce the task of Customer Support Conversation (CSC), aimed at
training customer service agents to respond using well-defined support
strategies. We propose a structured CSC framework grounded in COPC guidelines,
defining five conversational stages and twelve strategies to guide high-quality
interactions. Based on this, we construct CSConv, an evaluation dataset of
1,855 real-world customer-agent conversations rewritten using LLMs to reflect
deliberate strategy use, and annotated accordingly. Additionally, we develop a
role-playing approach that simulates strategy-rich conversations using
LLM-powered roles aligned with the CSC framework, resulting in the training
dataset RoleCS. Experiments show that fine-tuning strong LLMs on RoleCS
significantly improves their ability to generate high-quality, strategy-aligned
responses on CSConv. Human evaluations further confirm gains in problem
resolution. All code and data will be made publicly available at
https://github.com/aliyun/qwen-dianjin.

</details>


### [183] [StepFun-Formalizer: Unlocking the Autoformalization Potential of LLMs through Knowledge-Reasoning Fusion](https://arxiv.org/abs/2508.04440)
*Yutong Wu,Di Huang,Ruosi Wan,Yue Peng,Shijie Shang,Chenrui Cao,Lei Qi,Rui Zhang,Zidong Du,Jie Yan,Xing Hu*

Main category: cs.CL

TL;DR: 本文提出了一种新的自动形式化方法，通过数据合成和训练管道显著提升将自然语言数学描述转换为形式语言的准确率，所提出模型在公开基准上刷新了最好成绩。


<details>
  <summary>Details</summary>
Motivation: 现有基于大模型的自动形式化方法准确率不高，主要受限于缺乏深入的形式化领域知识和对自然语言与形式语言对齐的推理能力。

Method: 提出ThinkingF管道，首先通过数据蒸馏和专家模板得到两个数据集（一个侧重形式知识，一个侧重非正式到正式的推理过程），然后用SFT（监督微调）和RLVR（基于奖励的训练）加以训练，提升模型的双重能力。

Result: 7B和32B参数的模型都获得了全面的形式化知识和较强的推理能力，特别是StepFun-Formalizer-32B在FormalMATH-Lite和ProverBench基准上创下了新纪录（BEq@1分别为40.5%和26.7%），超过所有以往通用及专用模型。

Conclusion: 通过结合大规模形式知识和推理轨迹数据，以及先进的训练方法，可以大幅提升自动数学形式化领域的准确度，为自然语言到形式语言的转换带来新突破。

Abstract: Autoformalization aims to translate natural-language mathematical statements
into a formal language. While LLMs have accelerated progress in this area,
existing methods still suffer from low accuracy. We identify two key abilities
for effective autoformalization: comprehensive mastery of formal-language
domain knowledge, and reasoning capability of natural language problem
understanding and informal-formal alignment. Without the former, a model cannot
identify the correct formal objects; without the latter, it struggles to
interpret real-world contexts and map them precisely into formal expressions.
To address these gaps, we introduce ThinkingF, a data synthesis and training
pipeline that improves both abilities. First, we construct two datasets: one by
distilling and selecting large-scale examples rich in formal knowledge, and
another by generating informal-to-formal reasoning trajectories guided by
expert-designed templates. We then apply SFT and RLVR with these datasets to
further fuse and refine the two abilities. The resulting 7B and 32B models
exhibit both comprehensive formal knowledge and strong informal-to-formal
reasoning. Notably, StepFun-Formalizer-32B achieves SOTA BEq@1 scores of 40.5%
on FormalMATH-Lite and 26.7% on ProverBench, surpassing all prior
general-purpose and specialized models.

</details>


### [184] [Automated Generation of Curriculum-Aligned Multiple-Choice Questions for Malaysian Secondary Mathematics Using Generative AI](https://arxiv.org/abs/2508.04442)
*Rohaizah Abdul Wahid,Muhamad Said Nizamuddin Nadim,Suliana Sulaiman,Syahmi Akmal Shaharudin,Muhammad Danial Jupikil,Iqqwan Jasman Su Azlan Su*

Main category: cs.CL

TL;DR: 本文提出并比较了四种基于GPT-4o的生成性AI流水线，用于马来西亚低资源语言（马来语）中初中一年级数学多项选择题的自动生成。采用了自下而上的提示与检索增强生成（RAG）方法，并创新性地双管齐下自动评估试题质量。


<details>
  <summary>Details</summary>
Motivation: 随着马来西亚教育体系对于可扩展且高质量教育评估工具的需求增加，尤其是低资源语言下，AI自动生成题目的潜力受到关注，但在保证题目内容真实可靠和严格与课程衔接方面存在挑战。

Method: 设计了四种流水线：两种非检索基础的（结构化和基础提示），两种RAG方法（一个基于LangChain框架，一个手动实现），所有系统均以官方课程文档为知识基础。通过语义文本相似性（STS）与创新的RAG-QA方式对生成题目进行课程契合度与上下文有效性自动化评估。

Result: 结果显示RAG类方法在课程契合度和事实有效性上显著优于非基础提示。框架化RAG方案易于实现但控制度有限，手动RAG则可针对性微调，研究对比了二者的权衡。

Conclusion: 本研究验证了在低资源语言环境下，结合RAG和自动化多维评测可高效生成高质量、符合课程标准的教育内容，并对于区域教育技术应用的设计与推广提出了实际可行的参考。

Abstract: This paper addresses the critical need for scalable and high-quality
educational assessment tools within the Malaysian education system. It
highlights the potential of Generative AI (GenAI) while acknowledging the
significant challenges of ensuring factual accuracy and curriculum alignment,
especially for low-resource languages like Bahasa Melayu. This research
introduces and compares four incremental pipelines for generating Form 1
Mathematics multiple-choice questions (MCQs) in Bahasa Melayu using OpenAI's
GPT-4o. The methods range from non-grounded prompting (structured and basic) to
Retrieval-Augmented Generation (RAG) approaches (one using the LangChain
framework, one implemented manually). The system is grounded in official
curriculum documents, including teacher-prepared notes and the yearly teaching
plan (RPT). A dual-pronged automated evaluation framework is employed to assess
the generated questions. Curriculum alignment is measured using Semantic
Textual Similarity (STS) against the RPT, while contextual validity is verified
through a novel RAG-based Question-Answering (RAG-QA) method. The results
demonstrate that RAG-based pipelines significantly outperform non-grounded
prompting methods, producing questions with higher curriculum alignment and
factual validity. The study further analyzes the trade-offs between the ease of
implementation of framework-based RAG and the fine-grained control offered by a
manual pipeline. This work presents a validated methodology for generating
curriculum-specific educational content in a low-resource language, introduces
a symbiotic RAG-QA evaluation technique, and provides actionable insights for
the development and deployment of practical EdTech solutions in Malaysia and
similar regions.

</details>


### [185] [CALE : Concept-Aligned Embeddings for Both Within-Lemma and Inter-Lemma Sense Differentiation](https://arxiv.org/abs/2508.04494)
*Bastien Liétard,Gabriel Loiseau*

Main category: cs.CL

TL;DR: 该论文提出了一种新的词汇语义建模方法，通过词汇对比任务增强上下文语义模型，提升了模型对词义区分的能力，并提供了新数据集和模型验证。


<details>
  <summary>Details</summary>
Motivation: 现有上下文语言模型在词义建模上已经有进展，但主要聚焦于同一词元在不同上下文的辨别能力，忽视了不同单词之间语义关系的捕捉，限制了模型对词汇语义的全面理解。

Method: 作者提出了“概念区分”任务，将不同单词之间的语义比较引入建模过程，并基于SemCor数据集构建了任务数据，将多种表示模型在新数据集上进行了微调，得到强化的语义表征模型（CALE）。

Result: 通过在各类词汇语义任务上的实验，CALE模型在多项任务中均取得了最佳表现，证实了方法的有效性。同时，分析还发现CALE模型微调后嵌入空间结构发生了有益变化。

Conclusion: 论文的方法能够获得高效且多用途的词汇语义表征，有助于提升模型对词语语义和异义词理解的能力，扩展了上下文语言模型在词汇语义方向的应用。

Abstract: Lexical semantics is concerned with both the multiple senses a word can adopt
in different contexts, and the semantic relations that exist between meanings
of different words. To investigate them, Contextualized Language Models are a
valuable tool that provides context-sensitive representations that can be used
to investigate lexical meaning. Recent works like XL-LEXEME have leveraged the
task of Word-in-Context to fine-tune them to get more semantically accurate
representations, but Word-in-Context only compares occurrences of the same
lemma, limiting the range of captured information. In this paper, we propose an
extension, Concept Differentiation, to include inter-words scenarios. We
provide a dataset for this task, derived from SemCor data. Then we fine-tune
several representation models on this dataset. We call these models
Concept-Aligned Embeddings (CALE). By challenging our models and other models
on various lexical semantic tasks, we demonstrate that the proposed models
provide efficient multi-purpose representations of lexical meaning that reach
best performances in our experiments. We also show that CALE's fine-tuning
brings valuable changes to the spatial organization of embeddings.

</details>


### [186] [StyliTruth : Unlocking Stylized yet Truthful LLM Generation via Disentangled Steering](https://arxiv.org/abs/2508.04530)
*Chenglei Shen,Zhongxiang Sun,Teng Shi,Xiao Zhang,Jun Xu*

Main category: cs.CL

TL;DR: 本文提出了一种新的方法StyliTruth，在生成具有特定风格的大语言模型回答时，有效兼顾风格与真实性，克服以往方法中风格引入导致真实性崩塌的问题。


<details>
  <summary>Details</summary>
Motivation: 当前通过表示编辑实现LLM风格化输出时，常出现真实信息受损的问题。作者发现现有方法仅注入风格信号，未能避免对模型真实性表达的污染，因此需要一种能兼顾两者的细粒度控制机制。

Method: 作者分析了风格与真实性在部分注意力头中存在潜在耦合现象。提出StyliTruth，将风格相关与真实相关子空间进行正交分解，实现双方独立控制。通过为每个子空间设计自适应、逐token的引导向量，在模型生成过程中动态地维持风格与真实性的平衡。

Result: 在多种风格和多语言场景下，StyliTruth显著减少了风格化带来的真实性下降。与现有推理期干预方法相比，在风格一致性和真实度之间取得更佳平衡。

Conclusion: StyliTruth有效解决了大语言模型风格化过程中的真实性损失问题，实现了二者的相互独立和精准控制，为后续高质量风格化文本生成奠定方法基础。

Abstract: Generating stylized large language model (LLM) responses via representation
editing is a promising way for fine-grained output control. However, there
exists an inherent trade-off: imposing a distinctive style often degrades
truthfulness. Existing representation editing methods, by naively injecting
style signals, overlook this collateral impact and frequently contaminate the
model's core truthfulness representations, resulting in reduced answer
correctness. We term this phenomenon stylization-induced truthfulness collapse.
We attribute this issue to latent coupling between style and truth directions
in certain key attention heads, and propose StyliTruth, a mechanism that
preserves stylization while keeping truthfulness intact. StyliTruth separates
the style-relevant and truth-relevant subspaces in the model's representation
space via an orthogonal deflation process. This decomposition enables
independent control of style and truth in their own subspaces, minimizing
interference. By designing adaptive, token-level steering vectors within each
subspace, we dynamically and precisely control the generation process to
maintain both stylistic fidelity and truthfulness. We validate our method on
multiple styles and languages. Extensive experiments and analyses show that
StyliTruth significantly reduces stylization-induced truthfulness collapse and
outperforms existing inference-time intervention methods in balancing style
adherence with truthfulness.

</details>


### [187] [Unveiling the Landscape of Clinical Depression Assessment: From Behavioral Signatures to Psychiatric Reasoning](https://arxiv.org/abs/2508.04531)
*Zhuang Chen,Guanqun Bi,Wen Zhang,Jiawei Hu,Aoyun Wang,Xiyao Xiao,Kun Feng,Minlie Huang*

Main category: cs.CL

TL;DR: 本研究提出了C-MIND，一个真实医院环境下收集的多模态神经精神疾病诊断数据集，结合音频、视频、文本和fNIRS信号，全面分析抑郁症临床评估方法，并优化大模型在抑郁症诊断中的实际表现。


<details>
  <summary>Details</summary>
Motivation: 现有自动化抑郁症评估研究大多依赖非临床或有限数据，重模型设计而轻实用效果，难以应用于真实医疗场景。因此有必要建立基于临床真实数据的平台与方法，提升模型的实用价值和可靠性。

Method: 收集C-MIND数据集（包含结构化精神任务、专家最终诊断、多模态信号），采用多种经典模型量化不同任务和模态对诊断性能的贡献，并探索大型语言模型（LLM）在类临床场景的推理能力，同时通过引入临床专业知识引导模型推理，提升其诊断准确率。

Result: 分析不同模态及其组合对诊断的效果，发现用临床知识引导LLM可实现最高10%的Macro-F1提升，实证C-MIND数据集及改进方法提升临床抑郁症自动评估的可靠性和有效性。

Conclusion: 论文提出C-MIND多模态临床数据集，为自动抑郁症评估提供了真实、综合的基础资源，结合算法优化方案，有助于推动心理健康领域研究向更有临床价值的方向发展。

Abstract: Depression is a widespread mental disorder that affects millions worldwide.
While automated depression assessment shows promise, most studies rely on
limited or non-clinically validated data, and often prioritize complex model
design over real-world effectiveness. In this paper, we aim to unveil the
landscape of clinical depression assessment. We introduce C-MIND, a clinical
neuropsychiatric multimodal diagnosis dataset collected over two years from
real hospital visits. Each participant completes three structured psychiatric
tasks and receives a final diagnosis from expert clinicians, with informative
audio, video, transcript, and functional near-infrared spectroscopy (fNIRS)
signals recorded. Using C-MIND, we first analyze behavioral signatures relevant
to diagnosis. We train a range of classical models to quantify how different
tasks and modalities contribute to diagnostic performance, and dissect the
effectiveness of their combinations. We then explore whether LLMs can perform
psychiatric reasoning like clinicians and identify their clear limitations in
realistic clinical settings. In response, we propose to guide the reasoning
process with clinical expertise and consistently improves LLM diagnostic
performance by up to 10% in Macro-F1 score. We aim to build an infrastructure
for clinical depression assessment from both data and algorithmic perspectives,
enabling C-MIND to facilitate grounded and reliable research for mental
healthcare.

</details>


### [188] [Beyond Brainstorming: What Drives High-Quality Scientific Ideas? Lessons from Multi-Agent Collaboration](https://arxiv.org/abs/2508.04575)
*Nuo Chen,Yicheng Tong,Jiaying Wu,Minh Duc Duong,Qian Wang,Qingyun Zou,Bryan Hooi,Bingsheng He*

Main category: cs.CL

TL;DR: 本文提出并评估了一个多智能体协作框架，发现结构化多智能体讨论在科研创意生成中显著优于单智能体，并强调了领导角色和认知多样性的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有AI科研创意系统多采用单智能体推演，因知识和视角受限，创新性不足。作者受真实科研团队协作启发，探索多智能体结构化讨论是否能够突破此局限，提升科研方案的创新性和深度。

Method: 提出了多智能体合作框架，系统比较了不同小组规模、有无指定领导、团队成员跨学科与资历结构等变量。采用智能体评分与人工评审相结合，多维度评估提案的新颖性、战略愿景和整合深度。

Result: 多智能体合作显著优于单体基线，指定领导有助于促进讨论融合和提升方案前瞻性。认知多样性是质量提升的关键驱动，但前提是团队需具备一定资深知识，否则效果不及单一资深智能体。

Conclusion: 多智能体结构化讨论可显著提升AI科研创意质量。团队结构（如领导角色及资深成员配置）设计尤为重要，这为协作型AI创新系统的设计提供了可操作性建议。

Abstract: While AI agents show potential in scientific ideation, most existing
frameworks rely on single-agent refinement, limiting creativity due to bounded
knowledge and perspective. Inspired by real-world research dynamics, this paper
investigates whether structured multi-agent discussions can surpass solitary
ideation. We propose a cooperative multi-agent framework for generating
research proposals and systematically compare configurations including group
size, leaderled versus leaderless structures, and team compositions varying in
interdisciplinarity and seniority. To assess idea quality, we employ a
comprehensive protocol with agent-based scoring and human review across
dimensions such as novelty, strategic vision, and integration depth. Our
results show that multi-agent discussions substantially outperform solitary
baselines. A designated leader acts as a catalyst, transforming discussion into
more integrated and visionary proposals. Notably, we find that cognitive
diversity is a primary driver of quality, yet expertise is a non-negotiable
prerequisite, as teams lacking a foundation of senior knowledge fail to surpass
even a single competent agent. These findings offer actionable insights for
designing collaborative AI ideation systems and shed light on how team
structure influences creative outcomes.

</details>


### [189] [Share Your Attention: Transformer Weight Sharing via Matrix-based Dictionary Learning](https://arxiv.org/abs/2508.04581)
*Magauiya Zhussip,Dmitriy Shopkhoev,Ammar Ali,Stamatios Lefkimmiatis*

Main category: cs.CL

TL;DR: 提出MASA方法，通过结构化字典共享权重方式，大幅减少Transformer注意力模块参数（降低66.7%），在保证性能前提下提升模型效率，并可直接替换原有结构。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）计算和内存开销极大，限制了其广泛部署。现有模型压缩多关注于块内优化，对Transformer层间（块间）冗余研究较少。论文希望探索更高效的参数压缩方式。

Method: 借鉴CNN中的字典学习思路，提出MASA框架，将Transformer各层的注意力投影矩阵分解为可共享的“字典原子”，每层使用不同线性组合表示自身权重，无需蒸馏或结构修改，直接标准训练即可。

Result: 在100M-700M参数规模的实验中，MASA在相似参数预算下优于GQA、低秩方法及其他新近分享技术，并且稳健于字典规模选择。还推广到Vision Transformer上，图像分类和检测任务表现与原模型相当，同时减少66.7%的注意力参数。

Conclusion: MASA框架为Transformer类模型的高效、低参数实现提供了新思路，能够以低参数损耗获得与原版相近甚至更好的性能，也可用于预训练LLM参数压缩，基本无性能损失。

Abstract: Large language models (LLMs) have revolutionized AI applications, yet their
high computational and memory demands hinder their widespread deployment.
Existing compression techniques focus on intra-block optimizations (e.g.
low-rank approximation, attention head pruning), while the repetitive layered
structure of transformers implies significant inter-block redundancy - a
dimension largely unexplored beyond key-value (KV) caching. Inspired by
dictionary learning in CNNs, we propose a framework for structured weight
sharing across transformer layers. Our approach decomposes attention projection
matrices into shared dictionary atoms, reducing the attention module's
parameters by 66.7% while achieving on-par performance. Unlike complex methods
requiring distillation or architectural changes, MASA (Matrix Atom Sharing in
Attention) operates as a drop-in replacement - trained with standard optimizers
- and represents each layer's weights as linear combinations of shared matrix
atoms. Experiments across scales (100M-700M parameters) show that MASA achieves
better benchmark accuracy and perplexity than grouped-query attention (GQA),
low-rank baselines and recently proposed Repeat-all-over/Sequential sharing at
comparable parameter budgets. Ablation studies confirm robustness to the
dictionary size and the efficacy of shared representations in capturing
cross-layer statistical regularities. Extending to Vision Transformers (ViT),
MASA matches performance metrics on image classification and detection tasks
with 66.7% fewer attention parameters. By combining dictionary learning
strategies with transformer efficiency, MASA offers a scalable blueprint for
parameter-efficient models without sacrificing performance. Finally, we
investigate the possibility of employing MASA on pretrained LLMs to reduce
their number of parameters without experiencing any significant drop in their
performance.

</details>


### [190] [TURA: Tool-Augmented Unified Retrieval Agent for AI Search](https://arxiv.org/abs/2508.04604)
*Zhejun Zhao,Yuehu Dong,Alley Liu,Lixue Zheng,Pingsheng Liu,Dongdong Shen,Long Xia,Jiashu Zhao,Dawei Yin*

Main category: cs.CL

TL;DR: 本文提出TURA框架，结合RAG与智能工具，实现AI搜索产品对静态与动态实时信息的整合检索，解决工业级应用对低延迟和高实时性的需求。


<details>
  <summary>Details</summary>
Motivation: 现有基于RAG的大模型搜索引擎只能检索静态内容，难以处理需要动态、实时访问数据库或API等复杂任务，无法满足工业界的高效与实时数据需求。

Method: 作者提出TURA框架，包括三个核心模块：（1）意图感知检索模块，根据查询分解任务并调用封装为MCP协议的各种信息源；（2）基于DAG的任务规划器，识别依赖关系，支持多任务并行高效执行；（3）蒸馏后的高效智能体执行器，用于轻量级、快速调用相关工具，整合静态和动态信息源响应用户查询。

Result: TURA首次系统性地将RAG与动态信息源整合在AI搜索引擎中，已在面向千万级用户的产品中落地，能够在严格低延迟要求下，稳定、实时地提供强大答案。

Conclusion: TURA框架显著提升了AI搜索引擎对于复杂、实时和高并发数据需求的处理能力，为工业级应用的智能搜索产品带来了创新性的突破。

Abstract: The advent of Large Language Models (LLMs) is transforming search engines
into conversational AI search products, primarily using Retrieval-Augmented
Generation (RAG) on web corpora. However, this paradigm has significant
industrial limitations. Traditional RAG approaches struggle with real-time
needs and structured queries that require accessing dynamically generated
content like ticket availability or inventory. Limited to indexing static
pages, search engines cannot perform the interactive queries needed for such
time-sensitive data. Academic research has focused on optimizing RAG for static
content, overlooking complex intents and the need for dynamic sources like
databases and real-time APIs. To bridge this gap, we introduce TURA
(Tool-Augmented Unified Retrieval Agent for AI Search), a novel three-stage
framework that combines RAG with agentic tool-use to access both static content
and dynamic, real-time information. TURA has three key components: an
Intent-Aware Retrieval module to decompose queries and retrieve information
sources encapsulated as Model Context Protocol (MCP) Servers, a DAG-based Task
Planner that models task dependencies as a Directed Acyclic Graph (DAG) for
optimal parallel execution, and a lightweight Distilled Agent Executor for
efficient tool calling. TURA is the first architecture to systematically bridge
the gap between static RAG and dynamic information sources for a world-class AI
search product. Serving tens of millions of users, it leverages an agentic
framework to deliver robust, real-time answers while meeting the low-latency
demands of a large-scale industrial system.

</details>


### [191] [Lightweight Transformers for Zero-Shot and Fine-Tuned Text-to-SQL Generation Using Spider](https://arxiv.org/abs/2508.04623)
*Chirag Seth,Utkarsh Singh*

Main category: cs.CL

TL;DR: 本文评估了三种轻量级Transformer（T5-Small, BART-Small, GPT-2）在Spider数据集上的Text-to-SQL表现，T5-Small效果最佳，展示了解码器-编码器架构的优势，强调紧凑模型可用于低资源环境下的Text-to-SQL任务。


<details>
  <summary>Details</summary>
Motivation: Text-to-SQL旨在让非专家用户用自然语言查询数据库，但受限于模型资源，对轻量级模型在低资源环境下的效果尚缺乏系统研究。本文关注在资源受限情况下实现自然语言到SQL的高效转换，满足教育和商业智能等场景需求。

Method: 作者构建了一个可复用、模型无关的训练管道，对三种轻量级Transformer（T5-Small、BART-Small、GPT-2）分别进行Schema格式化优化，并在Spider数据集上训练1000~5000次，采用LFAcc、BLEU和EM度量测试集1000个样本的表现。

Result: 在低资源条件下，T5-Small细调后达到最高LFAcc（27.8%），BART-Small（23.98%），GPT-2（20.1%），表明编码器-解码器架构对处理数据库Schema与文本转换更具优势。

Conclusion: 虽然受限于计算资源，性能尚有限，但提出的管道具备高度模块化，易于扩展（如更复杂Schema链接或替换基座模型）。紧凑型Transformer有望为资源贫瘠环境下的Text-to-SQL应用提供可行和高效的解决方案。

Abstract: Text-to-SQL translation enables non-expert users to query relational
databases using natural language, with applications in education and business
intelligence. This study evaluates three lightweight transformer models -
T5-Small, BART-Small, and GPT-2 - on the Spider dataset, focusing on
low-resource settings. We developed a reusable, model-agnostic pipeline that
tailors schema formatting to each model's architecture, training them across
1000 to 5000 iterations and evaluating on 1000 test samples using Logical Form
Accuracy (LFAcc), BLEU, and Exact Match (EM) metrics. Fine-tuned T5-Small
achieves the highest LFAcc (27.8%), outperforming BART-Small (23.98%) and GPT-2
(20.1%), highlighting encoder-decoder models' superiority in schema-aware SQL
generation. Despite resource constraints limiting performance, our pipeline's
modularity supports future enhancements, such as advanced schema linking or
alternative base models. This work underscores the potential of compact
transformers for accessible text-to-SQL solutions in resource-scarce
environments.

</details>


### [192] [P-Aligner: Enabling Pre-Alignment of Language Models via Principled Instruction Synthesis](https://arxiv.org/abs/2508.04626)
*Feifan Song,Bofei Gao,Yifan Song,Yi Liu,Weimin Xiong,Yuyang Song,Tianyu Liu,Guoyin Wang,Houfeng Wang*

Main category: cs.CL

TL;DR: 本文提出P-Aligner模块，通过优化输入指令使LLM对齐于人类偏好，显著提升生成内容的安全性、帮助性和真实性。该方法在多个模型和标准测试中均超越现有强基线。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在收到不完善指令（如信息不足、语义模糊或语气不当）时，常常无法生成理想结果，影响用户体验和应用安全。提升LLM对用户指令偏好的对齐能力，是提升AI应用表现的关键。

Method: 作者提出P-Aligner，一个轻量级模块，用于在生成前将用户指令重新表达为更符合人类偏好的形式。P-Aligner在人工设计的UltraPrompt数据集上训练，该数据集通过基于蒙特卡洛树搜索的流程，系统探索更符合人类偏好的指令改写。

Result: 在包括GPT-4-turbo和Gemma-2-SimPO在内的多个主流大模型上，P-Aligner平均胜率分别提升28.35%和8.69%，超越各类强基线方案。多角度分析也验证了该方案在数据质量、迭代效果与效率上的优势。

Conclusion: P-Aligner提供了一种高效、低成本的大语言模型偏好对齐方案，可广泛适用于不同指令和模型。该方法提升了模型的实用性和用户友好度，数据和方法具有推广和持续优化的潜力。

Abstract: Large Language Models (LLMs) are expected to produce safe, helpful, and
honest content during interaction with human users, but they frequently fail to
align with such values when given flawed instructions, e.g., missing context,
ambiguous directives, or inappropriate tone, leaving substantial room for
improvement along multiple dimensions. A cost-effective yet high-impact way is
to pre-align instructions before the model begins decoding. Existing approaches
either rely on prohibitive test-time search costs or end-to-end model rewrite,
which is powered by a customized training corpus with unclear objectives. In
this work, we demonstrate that the goal of efficient and effective preference
alignment can be achieved by P-Aligner, a lightweight module generating
instructions that preserve the original intents while being expressed in a more
human-preferred form. P-Aligner is trained on UltraPrompt, a new dataset
synthesized via a proposed principle-guided pipeline using Monte-Carlo Tree
Search, which systematically explores the space of candidate instructions that
are closely tied to human preference. Experiments across different methods show
that P-Aligner generally outperforms strong baselines across various models and
benchmarks, including average win-rate gains of 28.35% and 8.69% on GPT-4-turbo
and Gemma-2-SimPO, respectively. Further analyses validate its effectiveness
and efficiency through multiple perspectives, including data quality, search
strategies, iterative deployment, and time overhead.

</details>


### [193] [IFDECORATOR: Wrapping Instruction Following Reinforcement Learning with Verifiable Rewards](https://arxiv.org/abs/2508.04632)
*Xu Guo,Tianyi Liang,Tong Jian,Xiaogui Yang,Ling-I Wu,Chenhui Li,Zhihui Lu,Qipeng Guo,Kai Chen*

Main category: cs.CL

TL;DR: 本文提出了Instruction Following Decorator (IFDecorator) 框架，以增强基于可验证奖励的强化学习（RLVR）的训练效果，并大幅减少模型过度优化和奖励漏洞利用现象。新方法在IFEval和FollowBench等任务上取得了优于主流模型的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管RLVR增强了大语言模型（LLM）的指令跟随能力，但在训练时常面临评估难度不足和效率低下的问题，并容易出现模型通过利用验证漏洞实现奖励最大化，而未真正对齐用户意图。

Method: IFDecorator包含三大核心组件：(1) 协作-对抗数据推送机制，即共进化生成更难的指令-验证对；(2) IntentCheck意图校验模块，强制模型输出与用户意图对齐；(3) trip wires奖励机制诊断，通过陷阱指令捕获模型利用验证漏洞的行为。

Result: 作者提出的Qwen2.5-32B-Instruct-IFDecorator，在IFEval上实现87.43%准确率，超过GPT-4o等更大商用模型。同时，在FollowBench任务集上显著提升指令跟随性能，并有效降低了奖励漏洞利用率。

Conclusion: IFDecorator大大提升了RLVR训练效率、模型对用户意图的符合度，并有效抑制了奖励外挂行为。相关模型、代码和数据将对外开放，促进未来研究。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) improves instruction
following capabilities of large language models (LLMs), but suffers from
training inefficiency due to inadequate difficulty assessment. Moreover, RLVR
is prone to over-optimization, where LLMs exploit verification shortcuts
without aligning to the actual intent of user instructions. We introduce
Instruction Following Decorator (IFDecorator}, a framework that wraps RLVR
training into a robust and sample-efficient pipeline. It consists of three
components: (1) a cooperative-adversarial data flywheel that co-evolves
instructions and hybrid verifications, generating progressively more
challenging instruction-verification pairs; (2) IntentCheck, a bypass module
enforcing intent alignment; and (3) trip wires, a diagnostic mechanism that
detects reward hacking via trap instructions, which trigger and capture
shortcut exploitation behaviors. Our Qwen2.5-32B-Instruct-IFDecorator achieves
87.43% accuracy on IFEval, outperforming larger proprietary models such as
GPT-4o. Additionally, we demonstrate substantial improvements on FollowBench
while preserving general capabilities. Our trip wires show significant
reductions in reward hacking rates. We will release models, code, and data for
future research.

</details>


### [194] [Can NLP Tackle Hate Speech in the Real World? Stakeholder-Informed Feedback and Survey on Counterspeech](https://arxiv.org/abs/2508.04638)
*Tanvi Dinkar,Aiqi Jiang,Simona Frenda,Poppy Gerrard-Abbott,Nancie Gunson,Gavin Abercrombie,Ioannis Konstas*

Main category: cs.CL

TL;DR: 本文系统性回顾了74篇NLP领域关于反仇恨言论的研究，发现现有研究正在逐渐脱离受影响社区的实际需求，建议重视利益相关者的参与。


<details>
  <summary>Details</summary>
Motivation: 近年来，NLP领域越来越关注通过反仇恨言论来应对网络仇恨，但自动化研究往往忽视了受害社群和相关组织的实际需求。本研究旨在评估和强调在反仇恨言论研究中利益相关者参与的重要性。

Method: 作者系统回顾了74项反仇恨言论的NLP研究，分析了利益相关者在数据集创建、模型开发和评估中的参与程度。同时，与5家专注于网络性别暴力的非政府组织开展了一项协作性案例研究，挖掘利益相关者驱动的反仇恨言论实践。

Result: 研究发现，当前NLP关于反仇恨言论的研究呈现出与受仇恨内容影响最深社区之间的脱节，利益相关者参与度逐步降低。同时，案例研究识别出多种由利益相关方推动的更有效反仇恨言论生成实践。

Conclusion: 作者建议未来反仇恨言论研究应重新聚焦于利益相关者的经验和需求，提出针对数据集、模型和评估流程的具体改进建议，以更好地服务受影响社群。

Abstract: Counterspeech, i.e. the practice of responding to online hate speech, has
gained traction in NLP as a promising intervention. While early work emphasised
collaboration with non-governmental organisation stakeholders, recent research
trends have shifted toward automated pipelines that reuse a small set of legacy
datasets, often without input from affected communities. This paper presents a
systematic review of 74 NLP studies on counterspeech, analysing the extent to
which stakeholder participation influences dataset creation, model development,
and evaluation. To complement this analysis, we conducted a participatory case
study with five NGOs specialising in online Gender-Based Violence (oGBV),
identifying stakeholder-informed practices for counterspeech generation. Our
findings reveal a growing disconnect between current NLP research and the needs
of communities most impacted by toxic online content. We conclude with concrete
recommendations for re-centring stakeholder expertise in counterspeech
research.

</details>


### [195] [Multi-module GRPO: Composing Policy Gradients and Prompt Optimization for Language Model Programs](https://arxiv.org/abs/2508.04660)
*Noah Ziems,Dilara Soylu,Lakshya A Agrawal,Isaac Miller,Liheng Lai,Chen Qian,Kaiqiang Song,Meng Jiang,Dan Klein,Matei Zaharia,Karel D'Oosterlinck,Christopher Potts,Omar Khattab*

Main category: cs.CL

TL;DR: 本文提出了mmGRPO算法，一种GRPO的多模块泛化版本，能更好地提升由多个语言模型模块组成的系统的性能，并在多种任务上显著优于单一后训练与单独提示优化。


<details>
  <summary>Details</summary>
Motivation: 现有GRPO方法虽然可提升单一语言模型，但AI系统越来越多地由多个语言模型模块、不同提示或工具组合而成，直接套用GRPO难以处理模块间的复杂结构和动态轨迹。

Method: 提出mmGRPO：一种多模块版本的GRPO方法，将不同模块的语言模型调用分组，对跨模块、变长与中断的执行轨迹进行处理。同时将其与自动提示优化方法结合。

Result: 在分类、多跳搜索、隐私委托等任务上，mmGRPO比单一后训练LM平均准确率提升11%，比独立的提示优化提升5%。

Conclusion: mmGRPO为模块化AI系统的模型优化提供了有效手段，并表现出广泛适用性；该方法已在DSPy库中开源。

Abstract: Group Relative Policy Optimization (GRPO) has proven to be an effective tool
for post-training language models (LMs). However, AI systems are increasingly
expressed as modular programs that mix together multiple LM calls with distinct
prompt templates and other tools, and it is not clear how best to leverage GRPO
to improve these systems. We begin to address this challenge by defining
mmGRPO, a simple multi-module generalization of GRPO that groups LM calls by
module across rollouts and handles variable-length and interrupted
trajectories. We find that mmGRPO, composed with automatic prompt optimization,
improves accuracy by 11% on average across classification, many-hop search, and
privacy-preserving delegation tasks against the post-trained LM, and by 5%
against prompt optimization on its own. We open-source mmGRPO in DSPy as the
dspy.GRPO optimizer.

</details>


### [196] [Sculptor: Empowering LLMs with Cognitive Agency via Active Context Management](https://arxiv.org/abs/2508.04664)
*Mo Li,L. H. Xu,Qitai Tan,Ting Cao,Yunxin Liu*

Main category: cs.CL

TL;DR: 本文提出了一种名为Sculptor的框架，通过赋予大语言模型（LLMs）主动管理上下文（Active Context Management, ACM）的能力，显著提升其处理长文本时的表现。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在处理长文本时，由于主动干扰（proactive interference）现象——即早期无关信息影响模型推理和记忆回调，导致模型性能大幅下降。以往研究多关注用外部记忆系统扩展LLM，本工作旨在让LLM自身学会主动管理和控制上下文，自主提升推理能力。

Method: 提出Sculptor 框架，为LLM提供三类主动上下文管理工具：1）上下文切片（fragmentation）、2）摘要、隐藏与恢复、3）智能检索，令LLM像人一样主动关注关键信息、过滤干扰，从而增强模型的内在工作记忆管理能力。

Result: 在PI-LLM（主动干扰评测）和NeedleBench等信息稀疏任务上，Sculptor 未经特殊训练即显著提升了LLM表现，凭借其泛化的调用工具能力，超越了单纯扩大模型上下文窗口的办法。

Conclusion: 通过赋予LLM主动上下文管理的手段，Sculptor不但能缓解主动干扰，还为长文本条件下的可靠推理提供了认知支撑。研究显示，有效的上下文控制而非盲目扩充窗口，是提升大模型长文本稳健推理的关键。

Abstract: Large Language Models (LLMs) suffer from significant performance degradation
when processing long contexts due to proactive interference, where irrelevant
information in earlier parts of the context disrupts reasoning and memory
recall. While most research focuses on external memory systems to augment LLMs'
capabilities, we propose a complementary approach: empowering LLMs with Active
Context Management (ACM) tools to actively sculpt their internal working
memory. We introduce Sculptor, a framework that equips LLMs with three
categories of tools: (1) context fragmentation, (2) summary, hide, and restore,
and (3) intelligent search. Our approach enables LLMs to proactively manage
their attention and working memory, analogous to how humans selectively focus
on relevant information while filtering out distractions. Experimental
evaluation on information-sparse benchmarks-PI-LLM (proactive interference) and
NeedleBench Multi-Needle Reasoning-demonstrates that Sculptor significantly
improves performance even without specific training, leveraging LLMs' inherent
tool calling generalization capabilities. By enabling Active Context
Management, Sculptor not only mitigates proactive interference but also
provides a cognitive foundation for more reliable reasoning across diverse
long-context tasks-highlighting that explicit context-control strategies,
rather than merely larger token windows, are key to robustness at scale.

</details>


### [197] [GeRe: Towards Efficient Anti-Forgetting in Continual Learning of LLM via General Samples Replay](https://arxiv.org/abs/2508.04676)
*Yunan Zhang,Shuoran Jiang,Mengchen Zhao,Yuefeng Li,Yang Fan,Xiangping Wu,Qingcai Chen*

Main category: cs.CL

TL;DR: 本文提出了一种名为General Sample Replay (GeRe)的新框架，通过使用预训练文本样本实现大语言模型（LLMs）的高效抗遗忘，提升其持续学习能力，并引入神经激活状态约束优化方法（TM损失），显著改善模型对遗忘的鲁棒性与整体表现。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在持续微调过程中，易出现灾难性遗忘问题，既会损失通用能力，又在老任务上表现锐减。论文旨在寻求既简单又稳定的方法，解决多任务、顺序学习情境下的遗忘困境。

Method: 作者提出GeRe框架，利用一小部分固定的预采集通用样本进行replay，并创新性引入激活状态一致性优化（TM损失），在回放学习时保持神经激活状态的稳定。对比了不同回放策略（基本标签拟合、KL散度logit模仿、L1/L2特征模仿）及其与TM的表现。

Result: 实验表明，TM方法不仅持续性提升模型性能，还具有更佳的鲁棒性。此外，少量通用样本即可有效避免遗忘，既保留了通用能力，也在增量任务上促进了整体表现。

Conclusion: GeRe框架及其TM方法为未来LLMs持续学习的高效回放提供了新的可行方案，并在规避遗忘的同时促进整体性能提升。

Abstract: The continual learning capability of large language models (LLMs) is crucial
for advancing artificial general intelligence. However, continual fine-tuning
LLMs across various domains often suffers from catastrophic forgetting,
characterized by: 1) significant forgetting of their general capabilities, and
2) sharp performance declines in previously learned tasks. To simultaneously
address both issues in a simple yet stable manner, we propose General Sample
Replay (GeRe), a framework that use usual pretraining texts for efficient
anti-forgetting. Beyond revisiting the most prevalent replay-based practices
under GeRe, we further leverage neural states to introduce a enhanced
activation states constrained optimization method using threshold-based margin
(TM) loss, which maintains activation state consistency during replay learning.
We are the first to validate that a small, fixed set of pre-collected general
replay samples is sufficient to resolve both concerns--retaining general
capabilities while promoting overall performance across sequential tasks.
Indeed, the former can inherently facilitate the latter. Through controlled
experiments, we systematically compare TM with different replay strategies
under the GeRe framework, including vanilla label fitting, logit imitation via
KL divergence and feature imitation via L1/L2 losses. Results demonstrate that
TM consistently improves performance and exhibits better robustness. Our work
paves the way for efficient replay of LLMs for the future. Our code and data
are available at https://github.com/Qznan/GeRe.

</details>


### [198] [FaST: Feature-aware Sampling and Tuning for Personalized Preference Alignment with Limited Data](https://arxiv.org/abs/2508.04698)
*Thibaut Thonet,Germán Kruszewski,Jos Rozen,Pierre Erbacher,Marc Dymetman*

Main category: cs.CL

TL;DR: 本文关注于通过有限数据实现大模型（LLM）个性化偏好对齐，引入了两个新数据集并提出了一种高效方法，取得了最佳效果。


<details>
  <summary>Details</summary>
Motivation: 当前LLM聊天助理多为千篇一律，无法满足个性化需求。作为解决方案，个性化模型受到关注，而现实中每个用户能够提供的偏好数据极少，因此亟需方法在小数据下做个性化对齐。

Method: 提出了个性化偏好对齐（PPALLI）问题，发布了两个新数据集DnD和ELIP，并对多种偏好对齐方法进行了基准测试。创新地提出了FaST方法，利用自动挖掘的高层特征实现参数高效的个性化对齐。

Result: 实验表明FaST方法在两个新数据集上表现最佳，在有限用户偏好数据情况下也能有效提升对齐效果。

Conclusion: 提出的小数据个性化偏好对齐方法有效，相关数据集为后续研究提供了资源，FaST方法在效率和效果间取得了良好平衡。

Abstract: LLM-powered conversational assistants are often deployed in a
one-size-fits-all manner, which fails to accommodate individual user
preferences. Recently, LLM personalization -- tailoring models to align with
specific user preferences -- has gained increasing attention as a way to bridge
this gap. In this work, we specifically focus on a practical yet challenging
setting where only a small set of preference annotations can be collected per
user -- a problem we define as Personalized Preference Alignment with Limited
Data (PPALLI). To support research in this area, we introduce two datasets --
DnD and ELIP -- and benchmark a variety of alignment techniques on them. We
further propose FaST, a highly parameter-efficient approach that leverages
high-level features automatically discovered from the data, achieving the best
overall performance.

</details>


### [199] [Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during Multi-Hop Analysis](https://arxiv.org/abs/2508.04699)
*Anushka Yadav,Isha Nalawade,Srujana Pillarichety,Yashwanth Babu,Reshmi Ghosh,Samyadeep Basu,Wenlong Zhao,Ali Nasaeh,Sriram Balasubramanian,Soundararajan Srinivasan*

Main category: cs.CL

TL;DR: 本文系统性探讨了当代语言模型在多跳问答任务中的推理失误，并提出了详细的错误分类框架，揭示了模型推理局限性。


<details>
  <summary>Details</summary>
Motivation: 随着具备推理能力的AI模型应用于复杂问答、深度搜索等任务，提升了这些任务的解决能力，但这些模型在推理任务中比通用模型更容易出现幻觉（hallucination），其根源尚未被充分理解。

Method: 作者提出了新的推理失败错误分类框架，从跳数多样性与唯一性（hops）、信息覆盖的完整性（coverage）、推理过程的认知低效（overthinking）三维度进行系统分析。采用严格人工标注和自动化指标，分析语言模型在多跳问答中的错误形式和模式。

Result: 研究揭示了以往以准确率为中心的评估方法未能发现的复杂错误模式。通过新框架和人工标注，发现了当前语言模型推理失误的更多细节与模式。

Conclusion: 该研究为理解和改进推理模型的认知局限性提供了新视角和实用指导，有助于未来提升模型推理的可靠性、透明性与稳健性。

Abstract: The emergence of reasoning models and their integration into practical AI
chat bots has led to breakthroughs in solving advanced math, deep search, and
extractive question answering problems that requires a complex and multi-step
thought process. Yet, a complete understanding of why these models hallucinate
more than general purpose language models is missing. In this investigative
study, we systematicallyexplore reasoning failures of contemporary language
models on multi-hop question answering tasks. We introduce a novel, nuanced
error categorization framework that examines failures across three critical
dimensions: the diversity and uniqueness of source documents involved ("hops"),
completeness in capturing relevant information ("coverage"), and cognitive
inefficiency ("overthinking"). Through rigorous hu-man annotation, supported by
complementary automated metrics, our exploration uncovers intricate error
patterns often hidden by accuracy-centric evaluations. This investigative
approach provides deeper insights into the cognitive limitations of current
models and offers actionable guidance toward enhancing reasoning fidelity,
transparency, and robustness in future language modeling efforts.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [200] [Think Before You Segment: An Object-aware Reasoning Agent for Referring Audio-Visual Segmentation](https://arxiv.org/abs/2508.04418)
*Jinxing Zhou,Yanghao Zhou,Mingfei Han,Tong Wang,Xiaojun Chang,Hisham Cholakkal,Rao Muhammad Anwer*

Main category: cs.MM

TL;DR: 本文提出了一种名为TGS-Agent的新方法，用于可指代音视频分割（Ref-AVS）。该方法通过将任务分解为“思考-定位-分割”三个过程，提升了分割的通用性和可解释性，并在新构建的数据集上取得了最优效果。


<details>
  <summary>Details</summary>
Motivation: 现有Ref-AVS方法依赖多模态表示融合与强像素级监督，缺乏任务推理能力和可解释性。因此，作者希望从显式理解参考表达的角度出发，提升任务推理、泛化和无强监督要求下的分割效果。

Method: 作者提出了TGS-Agent框架，将任务分为三步：1）用Ref-Thinker多模态大语言模型理解和推理参考表达，2）生成目标物体显式描述作为提示，3）将该提示输入Grounding-DINO和SAM2，分别实现目标定位与分割，无需像素级监督。同时构建了含复杂推理和多样表达的新基准R²-AVSBench。

Result: TGS-Agent在标准Ref-AVSBench和新提出的R²-AVSBench上获得了最优性能，显著优于之前同类方法。

Conclusion: TGS-Agent通过显式推理驱动的三阶段分割流程，有效提升了Ref-AVS的推理能力、泛化性和可解释性，为无像素级监督条件下的多模态分割开辟了新路径。

Abstract: Referring Audio-Visual Segmentation (Ref-AVS) aims to segment target objects
in audible videos based on given reference expressions. Prior works typically
rely on learning latent embeddings via multimodal fusion to prompt a tunable
SAM/SAM2 decoder for segmentation, which requires strong pixel-level
supervision and lacks interpretability. From a novel perspective of explicit
reference understanding, we propose TGS-Agent, which decomposes the task into a
Think-Ground-Segment process, mimicking the human reasoning procedure by first
identifying the referred object through multimodal analysis, followed by
coarse-grained grounding and precise segmentation. To this end, we first
propose Ref-Thinker, a multimodal language model capable of reasoning over
textual, visual, and auditory cues. We construct an instruction-tuning dataset
with explicit object-aware think-answer chains for Ref-Thinker fine-tuning. The
object description inferred by Ref-Thinker is used as an explicit prompt for
Grounding-DINO and SAM2, which perform grounding and segmentation without
relying on pixel-level supervision. Additionally, we introduce
R\textsuperscript{2}-AVSBench, a new benchmark with linguistically diverse and
reasoning-intensive references for better evaluating model generalization. Our
approach achieves state-of-the-art results on both standard Ref-AVSBench and
proposed R\textsuperscript{2}-AVSBench. Code will be available at
https://github.com/jasongief/TGS-Agent.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [201] [Audio Does Matter: Importance-Aware Multi-Granularity Fusion for Video Moment Retrieval](https://arxiv.org/abs/2508.04273)
*Junan Lin,Daizong Liu,Xianke Chen,Xiaoye Qu,Xun Yang,Jixiang Zhu,Sanyuan Zhang,Jianfeng Dong*

Main category: cs.IR

TL;DR: 本文提出了一种全新的重要性感知多粒度融合模型（IMG），能够根据音频对时刻检索的重要性自适应地融合音频、视觉和文本信息，大幅提升了视频时刻检索（VMR）的性能。


<details>
  <summary>Details</summary>
Motivation: 目前大多数VMR方法只关注视觉和文本，忽视了音频信息的辅助作用。即使有方法尝试融合三模态，但通常一刀切地处理所有音频，未针对无用或噪音音频进行区分，容易引入干扰，影响精度。为了解决这一问题，作者希望让模型能动态识别并利用对检索有用的音频。

Method: 1）将文本分别与视觉、音频融合。2）设计伪标签监督的音频重要性预测器，对音频模态分配权重以降低噪声影响。3）提出多粒度音频融合模块，在局部、事件和全局层面自适应整合音频与视觉上下文。4）引入跨模态知识蒸馏，缓解推理阶段音频缺失时的性能下降。5）构建新数据集Charades-AudioMatter，用人工标注挑选出音频相关样本评估模型。

Result: 在新的音频增强数据集Charades-AudioMatter以及现有数据集上，所提IMG模型在有音频参与的VMR任务中超越了现有最佳方法，验证了多模态细致融合和噪音控制策略的有效性。

Conclusion: 引入音频重要性判断和多粒度动态融合能够显著提高VMR效果，尤其面对有噪音或部分无用音频场景时。所提IMG方法为多模态视频理解与检索任务提供了更实用的技术基础。

Abstract: Video Moment Retrieval (VMR) aims to retrieve a specific moment semantically
related to the given query. To tackle this task, most existing VMR methods
solely focus on the visual and textual modalities while neglecting the
complementary but important audio modality. Although a few recent works try to
tackle the joint audio-vision-text reasoning, they treat all modalities equally
and simply embed them without fine-grained interaction for moment retrieval.
These designs are counter-practical as: Not all audios are helpful for video
moment retrieval, and the audio of some videos may be complete noise or
background sound that is meaningless to the moment determination. To this end,
we propose a novel Importance-aware Multi-Granularity fusion model (IMG), which
learns to dynamically and selectively aggregate the audio-vision-text contexts
for VMR. Specifically, after integrating the textual guidance with vision and
audio separately, we first design a pseudo-label-supervised audio importance
predictor that predicts the importance score of the audio, and accordingly
assigns weights to mitigate the interference caused by noisy audio. Then, we
design a multi-granularity audio fusion module that adaptively fuses audio and
visual modalities at local-, event-, and global-level, fully capturing their
complementary contexts. We further propose a cross-modal knowledge distillation
strategy to address the challenge of missing audio modality during inference.
To evaluate our method, we further construct a new VMR dataset, i.e.,
Charades-AudioMatter, where audio-related samples are manually selected and
re-organized from the original Charades-STA to validate the model's capability
in utilizing audio modality. Extensive experiments validate the effectiveness
of our method, achieving state-of-the-art with audio-video fusion in VMR
methods. Our code is available at https://github.com/HuiGuanLab/IMG.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [202] [Uncertainty-aware Accurate Elevation Modeling for Off-road Navigation via Neural Processes](https://arxiv.org/abs/2508.03890)
*Sanghun Jung,Daehoon Gwak,Byron Boots,James Hays*

Main category: cs.RO

TL;DR: 本文提出了一种基于神经过程（Neural Processes, NPs）的地形高程建模方法，能够高效精准地实时估计地形变化及其不确定性，并在提升准确度的同时降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 地形高程估计及不确定度定量对于越野导航中的规划与控制算法至关重要，但现有的高斯过程和神经网络方法面临实时性差、对地形急剧变化估计不足、且考虑不确定性时损失准确度等问题。

Method: 借鉴NPs结合高斯过程的不确定性估计和神经网络的高效性，提出了一种融合激光雷达与摄像头语义特征的新算法，同时引入局部球查询注意力机制，有效降低全局注意力计算成本17%，并提升对未观测区域的插值与外推能力。

Result: 在包含丰富地形特征的越野数据集上进行实验，结果显示所提方法在准确度和效率上均优于基线模型，能够更有效地建模复杂越野环境中的地形。

Conclusion: 所提基于神经过程的地形高程建模方法在不牺牲准确度的前提下，实现了对急剧地形变化和不确定性的精准估计且具备高效率，展示了其在复杂越野环境建模的应用潜力。

Abstract: Terrain elevation modeling for off-road navigation aims to accurately
estimate changes in terrain geometry in real-time and quantify the
corresponding uncertainties. Having precise estimations and uncertainties plays
a crucial role in planning and control algorithms to explore safe and reliable
maneuver strategies. However, existing approaches, such as Gaussian Processes
(GPs) and neural network-based methods, often fail to meet these needs. They
are either unable to perform in real-time due to high computational demands,
underestimating sharp geometry changes, or harming elevation accuracy when
learned with uncertainties. Recently, Neural Processes (NPs) have emerged as a
promising approach that integrates the Bayesian uncertainty estimation of GPs
with the efficiency and flexibility of neural networks. Inspired by NPs, we
propose an effective NP-based method that precisely estimates sharp elevation
changes and quantifies the corresponding predictive uncertainty without losing
elevation accuracy. Our method leverages semantic features from LiDAR and
camera sensors to improve interpolation and extrapolation accuracy in
unobserved regions. Also, we introduce a local ball-query attention mechanism
to effectively reduce the computational complexity of global attention by 17\%
while preserving crucial local and spatial information. We evaluate our method
on off-road datasets having interesting geometric features, collected from
trails, deserts, and hills. Our results demonstrate superior performance over
baselines and showcase the potential of neural processes for effective and
expressive terrain modeling in complex off-road environments.

</details>


### [203] [Constraint-Preserving Data Generation for Visuomotor Policy Learning](https://arxiv.org/abs/2508.03944)
*Kevin Lin,Varun Ragunath,Andrew McAlinden,Aaditya Prasad,Jimmy Wu,Yuke Zhu,Jeannette Bohg*

Main category: cs.RO

TL;DR: 本文提出了一种名为“约束保持数据生成（CP-Gen）”的方法，通过利用单一专家轨迹生成包含新颖物体几何形状和姿态的机器人演示数据，以大幅减少数据采集成本。该方法提升了机器人视觉-运动策略在实际环境中无须再训练即可迁移的能力，并且能适应多变的物体几何和姿态。实验结果显示，CP-Gen显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 收集大规模机器人操作演示数据成本高昂、效率低下，成为制约机器人操作学习和泛化能力的重要瓶颈。作者希望通过自动生成多变的、高质量的演示数据，同时做到几何和姿态的多样性与任务相关性，以提升机器人策略的泛化能力和实际应用效率。

Method: CP-Gen方法将专家演示分解为自由空间运动与关键技能，并将机器人技能形式化为关键点轨迹约束。系统先为任务相关物体采样新的几何和姿态变换，然后将变换应用到物体及其相关关键点轨迹。通过优化机器人关节配置，使关键点轨迹与变换后的目标保持一致，并通过运动规划实现无碰撞到达首个目标配置，最终生成新颖可用的演示数据。

Result: 在16个仿真任务和4个现实任务上进行实验（涵盖多阶段、非抓持及高精度操作），用CP-Gen生成的数据训练的策略平均成功率为77%，而最优基线方法仅为50%，显示CP-Gen在泛化和迁移上均优越。

Conclusion: CP-Gen实现了基于单一专家示范的多样性、几何相关演示自动生成，显著提升了机器人操作策略的泛化与迁移性能，为减少数据采集成本和提高实际应用能力提供了有效途径。

Abstract: Large-scale demonstration data has powered key breakthroughs in robot
manipulation, but collecting that data remains costly and time-consuming. We
present Constraint-Preserving Data Generation (CP-Gen), a method that uses a
single expert trajectory to generate robot demonstrations containing novel
object geometries and poses. These generated demonstrations are used to train
closed-loop visuomotor policies that transfer zero-shot to the real world and
generalize across variations in object geometries and poses. Similar to prior
work using pose variations for data generation, CP-Gen first decomposes expert
demonstrations into free-space motions and robot skills. But unlike those
works, we achieve geometry-aware data generation by formulating robot skills as
keypoint-trajectory constraints: keypoints on the robot or grasped object must
track a reference trajectory defined relative to a task-relevant object. To
generate a new demonstration, CP-Gen samples pose and geometry transforms for
each task-relevant object, then applies these transforms to the object and its
associated keypoints or keypoint trajectories. We optimize robot joint
configurations so that the keypoints on the robot or grasped object track the
transformed keypoint trajectory, and then motion plan a collision-free path to
the first optimized joint configuration. Experiments on 16 simulation tasks and
four real-world tasks, featuring multi-stage, non-prehensile and
tight-tolerance manipulation, show that policies trained using CP-Gen achieve
an average success rate of 77%, outperforming the best baseline that achieves
an average of 50%.

</details>


### [204] [Optimization of sliding control parameters for a 3-dof robot arm using genetic algorithm (GA)](https://arxiv.org/abs/2508.04009)
*Vu Ngoc Son,Pham Van Cuong,Dao Thi My Linh,Le Tieu Nien*

Main category: cs.RO

TL;DR: 提出了一种利用遗传算法（GA）优化机器人操作手滑模控制器（SMC）参数的方法，相比传统SMC和模糊SMC，能获得更好轨迹跟踪且降低抖振。


<details>
  <summary>Details</summary>
Motivation: SMC对于机器人精确轨迹跟踪有良好鲁棒性，但参数选择难且影响性能，因此需要自动优化参数方案。

Method: 利用遗传算法搜索、优化SMC关键参数，根据性能指标评判最优解，并与传统SMC及模糊SMC进行仿真对比。

Result: 仿真显示遗传算法优化SMC参数后，轨迹跟踪效果更佳，同时明显减少了SMC常见的抖振现象。

Conclusion: 结合遗传算法优化SMC参数可有效提升机器人操作手在不确定和扰动下的控制性能，优于传统方法。

Abstract: This paper presents a method for optimizing the sliding mode control (SMC)
parameter for a robot manipulator applying a genetic algorithm (GA). The
objective of the SMC is to achieve precise and consistent tracking of the
trajectory of the robot manipulator under uncertain and disturbed conditions.
However, the system effectiveness and robustness depend on the choice of the
SMC parameters, which is a difficult and crucial task. To solve this problem, a
genetic algorithm is used to locate the optimal values of these parameters that
gratify the capability criteria. The proposed method is efficient compared with
the conventional SMC and Fuzzy-SMC. The simulation results show that the
genetic algorithm with SMC can achieve better tracking capability and reduce
the chattering effect.

</details>


### [205] [SCOUT: An in-vivo Methane Sensing System for Real-time Monitoring of Enteric Emissions in Cattle with ex-vivo Validation](https://arxiv.org/abs/2508.04056)
*Yuelin Deng,Hinayah Rojas de Oliveira,Richard M. Voyles,Upinder Kaur*

Main category: cs.RO

TL;DR: 本研究开发了SCOUT系统，实现了对反刍动物瘤胃甲烷气体的持续高分辨率监测，显著优于以往方法，为畜牧业减排与精准管理提供关键工具。


<details>
  <summary>Details</summary>
Motivation: 现有畜牧甲烷排放监测手段由于数据保留率低、易受环境干扰、时间分辨率有限，制约了通过遗传选择和精准管理实现可持续畜牧业的发展。

Method: 研究团队开发了一种创新的SCOUT（智能套管光学甲烷追踪单元）系统，采用闭环气体循环设计，实现了实时、高分辨率、连续监测瘤胃甲烷浓度。以两头不同饮食处理的西门塔尔牛为实验对象，SCOUT系统与传统嗅探器进行对比和交叉平台验证。

Result: SCOUT系统实现了82%的数据保留率（传统嗅探器仅为17%），监测到的甲烷浓度远高于环境抽样（高100-1000倍），在40分钟窗口下与传统设备监测结果相关性最高（r = -0.564），且高频监测发现了动物姿势变化与甲烷排放的耦合关系。

Conclusion: SCOUT系统为甲烷排放连续表型分析和精准管理提供了新标准和生物学洞见，为基因选育与可持续畜牧生产体系提供了强有力的技术支撑，有助于气候友好型农业发展。

Abstract: Accurate measurement of enteric methane emissions remains a critical
bottleneck for advancing livestock sustainability through genetic selection and
precision management. Existing ambient sampling approaches suffer from low data
retention rates, environmental interference, and limited temporal resolution.
We developed SCOUT (Smart Cannula-mounted Optical Unit for Trace-methane), the
first robust in-vivo sensing system enabling continuous, high-resolution
monitoring of ruminal methane concentrations through an innovative closed-loop
gas recirculation design. We conducted comprehensive validation with two
cannulated Simmental heifers under contrasting dietary treatments, with
cross-platform comparison against established ambient sniffer systems. SCOUT
achieved exceptional performance with 82% data retention compared to 17% for
conventional sniffer systems, while capturing methane concentrations 100-1000x
higher than ambient approaches. Cross-platform validation demonstrated strong
scale-dependent correlations, with optimal correlation strength (r = -0.564
$\pm$ 0.007) at biologically relevant 40-minute windows and 100% statistical
significance. High-frequency monitoring revealed novel behavior-emission
coupling, including rapid concentration changes (14.5 $\pm$ 11.3k ppm)
triggered by postural transitions within 15 minutes, insights previously
inaccessible through existing technologies. The SCOUT system represents a
transformative advancement, enabling accurate, continuous emission phenotyping
essential for genomic selection programs and sustainable precision livestock
management. This validation framework establishes new benchmarks for
agricultural sensor performance while generating unprecedented biological
insights into ruminal methane dynamics, contributing essential tools for
sustainable livestock production in climate-conscious agricultural systems.

</details>


### [206] [DRIVE: Dynamic Rule Inference and Verified Evaluation for Constraint-Aware Autonomous Driving](https://arxiv.org/abs/2508.04066)
*Longling Geng,Huangxing Li,Viktor Lado Naess,Mert Pilanci*

Main category: cs.RO

TL;DR: 本文提出了一种新的自动驾驶软约束学习与决策框架DRIVE，通过学习专家驾驶数据，推断出隐含的软行为约束，并嵌入规划模块，实现更安全、更符合人类偏好的驾驶轨迹。实验显示DRIVE在主流数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶要安全、合规地与社会互动，必须理解并遵循各类软约束（如行为规范），但这些约束通常隐性难以明确定义。现有方法对这些软约束建模有限，难以泛化或缺乏合理性验证，因此需要新的方法更好地推断、评估和利用这些规则。

Method: 提出DRIVE框架，通过指数族似然建模，从专家示范数据中推断状态转移的可行性，进而学习反映驾驶偏好的概率分布。这些分布被嵌入到凸优化规划模块中，使生成轨迹既动态可行又合乎人类偏好。该方法同时具备数据驱动的泛化能力和规则可验证性。

Result: 在inD、highD与RoundD等大规模真实驾驶数据集上检验，DRIVE相较于代表性逆约束学习与规划方法，实现了0%的软约束违规率，轨迹更平滑，并能更好泛化到多样驾驶场景，在效率、解释性与鲁棒性上也表现突出。

Conclusion: DRIVE为软行为约束的自动驾驶决策提供了统一且有效的理论与实践框架，显著提升了安全性与实用性，对真实世界部署具有重要意义。

Abstract: Understanding and adhering to soft constraints is essential for safe and
socially compliant autonomous driving. However, such constraints are often
implicit, context-dependent, and difficult to specify explicitly. In this work,
we present DRIVE, a novel framework for Dynamic Rule Inference and Verified
Evaluation that models and evaluates human-like driving constraints from expert
demonstrations. DRIVE leverages exponential-family likelihood modeling to
estimate the feasibility of state transitions, constructing a probabilistic
representation of soft behavioral rules that vary across driving contexts.
These learned rule distributions are then embedded into a convex
optimization-based planning module, enabling the generation of trajectories
that are not only dynamically feasible but also compliant with inferred human
preferences. Unlike prior approaches that rely on fixed constraint forms or
purely reward-based modeling, DRIVE offers a unified framework that tightly
couples rule inference with trajectory-level decision-making. It supports both
data-driven constraint generalization and principled feasibility verification.
We validate DRIVE on large-scale naturalistic driving datasets, including inD,
highD, and RoundD, and benchmark it against representative inverse constraint
learning and planning baselines. Experimental results show that DRIVE achieves
0.0% soft constraint violation rates, smoother trajectories, and stronger
generalization across diverse driving scenarios. Verified evaluations further
demonstrate the efficiency, explanability, and robustness of the framework for
real-world deployment.

</details>


### [207] [Industrial Robot Motion Planning with GPUs: Integration of cuRobo for Extended DOF Systems](https://arxiv.org/abs/2508.04146)
*Luai Abuelsamen,Harsh Rana,Ho-Wei Lu,Wenhan Tang,Swati Priyadarshini,Gabriel Gomes*

Main category: cs.RO

TL;DR: 本文通过将基于GPU的运动规划引擎（NVIDIA cuRobo库）整合进Vention自动化平台，实现了复杂工业环境下多轴机器人高效、实时的路径规划和避障，大幅提升了自动化生产的效率和适应性。


<details>
  <summary>Details</summary>
Motivation: 工业机器人在复杂环境中的高效运动规划一直是难题，尤其是在多轴系统和复杂场景下，传统方法容易受限于运算速度和适应性，制约了工厂自动化的进一步发展。

Method: 研究将NVIDIA cuRobo库（GPU加速运动规划）与Vention的模块化自动化平台结合。系统基于CAD精确数字孪生模型，利用GPU并行优化实现实时轨迹、动态避障规划，并在具有更多自由度（如7轴龙门式机构）的机器人上进行测试。

Result: 实验结果显示，无论在多样化任务场景还是在扩展机器人自由度情况下，整体路径规划速度和系统鲁棒性均有显著提升。

Conclusion: 采用GPU运动规划管道能够显著提升多轴工业机器人在复杂环境中的部署效率和可扩展性，为现代工厂自动化带来更强的灵活性和应用前景。

Abstract: Efficient motion planning remains a key challenge in industrial robotics,
especially for multi-axis systems operating in complex environments. This paper
addresses that challenge by integrating GPU-accelerated motion planning through
NVIDIA's cuRobo library into Vention's modular automation platform. By
leveraging accurate CAD-based digital twins and real-time parallel
optimization, our system enables rapid trajectory generation and dynamic
collision avoidance for pick-and-place tasks. We demonstrate this capability on
robots equipped with additional degrees of freedom, including a 7th-axis
gantry, and benchmark performance across various scenarios. The results show
significant improvements in planning speed and robustness, highlighting the
potential of GPU-based planning pipelines for scalable, adaptable deployment in
modern industrial workflows.

</details>


### [208] [Improving Tactile Gesture Recognition with Optical Flow](https://arxiv.org/abs/2508.04338)
*Shaohong Zhong,Alessandro Albini,Giammarco Caroleo,Giorgio Cannata,Perla Maiolino*

Main category: cs.RO

TL;DR: 本论文提出通过引入稠密光流信息，提升触觉手势识别的分类准确率，实现了比单纯使用触觉图像更高的识别效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于触觉图像的手势识别方法，在区分类似触觉图案但动态特征不同的手势时存在准确率不足的问题。

Method: 作者提出在原有触觉图像的基础上，计算触点的稠密光流，将光流信息与原始图像结合输入手势分类器，从而强化对动态特征的刻画。

Result: 采用光流增强的触觉图像训练分类器后，手势识别准确率提升了9%。

Conclusion: 引入光流信息可显著提高基于触觉图像的手势识别准确率，尤其适用于区分触觉动态相似但接触动态不同的手势，方法简单有效。

Abstract: Tactile gesture recognition systems play a crucial role in Human-Robot
Interaction (HRI) by enabling intuitive communication between humans and
robots. The literature mainly addresses this problem by applying machine
learning techniques to classify sequences of tactile images encoding the
pressure distribution generated when executing the gestures. However, some
gestures can be hard to differentiate based on the information provided by
tactile images alone. In this paper, we present a simple yet effective way to
improve the accuracy of a gesture recognition classifier. Our approach focuses
solely on processing the tactile images used as input by the classifier. In
particular, we propose to explicitly highlight the dynamics of the contact in
the tactile image by computing the dense optical flow. This additional
information makes it easier to distinguish between gestures that produce
similar tactile images but exhibit different contact dynamics. We validate the
proposed approach in a tactile gesture recognition task, showing that a
classifier trained on tactile images augmented with optical flow information
achieved a 9% improvement in gesture classification accuracy compared to one
trained on standard tactile images.

</details>


### [209] [Tactile Comfort: Lowering Heart Rate Through Interactions](https://arxiv.org/abs/2508.04372)
*Morten Roed Frederiksen,Kasper Støy,Maja Matarić*

Main category: cs.RO

TL;DR: 该论文研究了一种无需训练即可即时放松的口袋伴侣机器人对儿童心率的影响。结果表明，与未使用机器人时相比，与机器人互动能显著降低儿童心率，具有安抚和放松作用。


<details>
  <summary>Details</summary>
Motivation: 当前焦虑症儿童常采用深呼吸和咒语等传统方法来缓解焦虑，但这些方法通常需事先训练。本研究旨在寻找一种无需训练、可直接带来安抚效果的新技术。

Method: 研究者设计了一种口袋大小的伴侣机器人，通过触觉游戏来转移用户注意力，实现放松效果。研究包含一个为期14天的实验性试点（2名8岁儿童）和一个主实验（18名7-8岁儿童），均采用被试内设计，对比儿童在与机器人互动及未使用机器人时的心率变化。

Result: 实验结果显示，与机器人互动能显著降低儿童心率（p<0.01），相较未使用时均表现出一致的镇静效果。

Conclusion: 触觉型伴侣机器人可提升放松技术的疗效，为无需事先训练的即时减压工具提供了新方向。

Abstract: Children diagnosed with anxiety disorders are taught a range of strategies to
navigate situations of heightened anxiety. Techniques such as deep breathing
and repetition of mantras are commonly employed, as they are known to be
calming and reduce elevated heart rates. Although these strategies are often
effective, their successful application relies on prior training of the
children for successful use when faced with challenging situations. This paper
investigates a pocket-sized companion robot designed to offer a relaxation
technique requiring no prior training, with a focus on immediate impact on the
user's heart rate. The robot utilizes a tactile game to divert the user's
attention, thereby promoting relaxation. We conducted two studies with children
who were not diagnosed with anxiety: a 14-day pilot study with two children
(age 8) and a main study with 18 children (ages 7-8). Both studies employed a
within-subjects design and focused on measuring heart rate during tactile
interaction with the robot and during non-use. Interacting with the robot was
found to significantly lower the study participants' heart rate (p$<$0.01)
compared to the non-use condition, indicating a consistent calming effect
across all participants. These results suggest that tactile companion robots
have the potential to enhance the therapeutic value of relaxation techniques.

</details>


### [210] [Incorporating Stochastic Models of Controller Behavior into Kinodynamic Efficiently Adaptive State Lattices for Mobile Robot Motion Planning in Off-Road Environments](https://arxiv.org/abs/2508.04384)
*Eric R. Damm,Eli S. Lancaster,Felix A. Sanchez,Kiana Bronder,Jason M. Gregory,Thomas M. Howard*

Main category: cs.RO

TL;DR: 通过在KEASL规划器中引入随机性控制行为，提高了机器人在真实环境中的运动安全性。


<details>
  <summary>Details</summary>
Motivation: 理论模型在实际机器人运动规划中因物理因素及底层控制器的不确定性导致模型误差，从而影响实际运动效果。为了解决这个现实差异，需要在运动规划中引入更加实际的控制行为建模。

Method: 提出了三种将随机控制器行为融入KEASL运动规划器组合搜索空间的方法，并通过真实无人地面车辆（Warthog UGV）在非结构化越野环境下的实验，以及在不同环境复杂度下的仿真消融实验，对方法效果进行了分析。

Result: 在KEASL中加入随机控制采样后，机器人轨迹更加保守，预测碰撞概率下降。与采用扩大障碍物边界的基线方法相比，引入采样后碰撞概率相近，但基线方法的规划成功率降低。

Conclusion: 将控制器随机性建模纳入路径规划能有效降低预测碰撞概率，提高规划真实可靠性，但也可能带来保守和成功率下降的权衡。

Abstract: Mobile robot motion planners rely on theoretical models to predict how the
robot will move through the world. However, when deployed on a physical robot,
these models are subject to errors due to real-world physics and uncertainty in
how the lower-level controller follows the planned trajectory. In this work, we
address this problem by presenting three methods of incorporating stochastic
controller behavior into the recombinant search space of the Kinodynamic
Efficiently Adaptive State Lattice (KEASL) planner. To demonstrate this work,
we analyze the results of experiments performed on a Clearpath Robotics Warthog
Unmanned Ground Vehicle (UGV) in an off-road, unstructured environment using
two different perception algorithms, and performed an ablation study using a
full spectrum of simulated environment map complexities. Analysis of the data
found that incorporating stochastic controller sampling into KEASL leads to
more conservative trajectories that decrease predicted collision likelihood
when compared to KEASL without sampling. When compared to baseline planning
with expanded obstacle footprints, the predicted likelihood of collisions
becomes more comparable, but reduces the planning success rate for baseline
search.

</details>


### [211] [Reliable and Real-Time Highway Trajectory Planning via Hybrid Learning-Optimization Frameworks](https://arxiv.org/abs/2508.04436)
*Yujia Lu,Chong Wei,Lu Ma*

Main category: cs.RO

TL;DR: 本文提出了一种混合轨迹规划框架，通过结合学习方法和优化方法，实现了高速公路自动驾驶中的高效可靠轨迹生成。框架分为上层（基于图神经网络预测速度）和下层（基于混合整数二次规划的路径优化），在保持安全性和计算效率的同时，实现实时、高成功率避碰。


<details>
  <summary>Details</summary>
Motivation: 高速公路自动驾驶环境动态变化快、反应时间有限，存在高碰撞风险，因此需要一种既安全又高效的轨迹规划方法。现有学习方法适应性强但安全性难以保证，优化方法可提供安全性却计算复杂度高，难以实时应用。

Method: 提出双层混合轨迹规划架构。上层使用在真实数据上训练的图神经网络（GNN）预测符合人类驾驶行为的纵向速度轨迹，下层采用混合整数二次规划（MIQP）进行路径优化，采用车辆几何的线性离散近似简化计算复杂度，同时施加严格的时空防重叠约束，以形式化地保证全程避碰。

Result: 实验显示，该方法在复杂真实紧急场景下可规划出平滑、无碰撞轨迹，成功率超过97%，平均规划时间54毫秒，满足实际实时性要求。

Conclusion: 所提混合框架兼具学习方法的自适应性与优化方法的安全性保障，在高速公路自动驾驶轨迹规划中有效实现了实时、高效、安全的路径生成。

Abstract: Autonomous highway driving presents a high collision risk due to
fast-changing environments and limited reaction time, necessitating reliable
and efficient trajectory planning. This paper proposes a hybrid trajectory
planning framework that integrates the adaptability of learning-based methods
with the formal safety guarantees of optimization-based approaches. The
framework features a two-layer architecture: an upper layer employing a graph
neural network (GNN) trained on real-world highway data to predict human-like
longitudinal velocity profiles, and a lower layer utilizing path optimization
formulated as a mixed-integer quadratic programming (MIQP) problem. The primary
contribution is the lower-layer path optimization model, which introduces a
linear approximation of discretized vehicle geometry to substantially reduce
computational complexity, while enforcing strict spatiotemporal non-overlapping
constraints to formally guarantee collision avoidance throughout the planning
horizon. Experimental results demonstrate that the planner generates highly
smooth, collision-free trajectories in complex real-world emergency scenarios,
achieving success rates exceeding 97% with average planning times of 54 ms,
thereby confirming real-time capability.

</details>


### [212] [Behaviorally Adaptive Multi-Robot Hazard Localization in Failure-Prone, Communication-Denied Environments](https://arxiv.org/abs/2508.04537)
*Alkesh K. Srivastava,Aamodh Suresh,Carlos Nieto-Granda*

Main category: cs.RO

TL;DR: 本文提出了一种基于行为自适应的信息论规划框架（BAPP），提升多机器人在高风险与通讯受限环境中的自主灾害地图构建能力。BAPP通过可调风险敏感参数，在仿真中优于传统Shannon熵策略，实现了更快的信息获取与更高的生存率。


<details>
  <summary>Details</summary>
Motivation: 在灾后区域、地下矿井、洞穴、星球表面等高风险、设备易失效且通讯受限的环境下，多机器人协同开展灾害区域勘测和风险建图任务非常困难。本研究旨在解决机器人需要在保证自身安全的同时，最大化勘测效益的问题。

Method: 提出基于行为熵（Behavioral Entropy, BE）的信息论路径规划框架BAPP，并设计了两种算法：BAPP-TID（针对高性能机器人的智能触发）和BAPP-SIG（适用于高风险情况下的安全部署）。BAPP框架引入风险敏感性参数，支持路径规划适应环境威胁。此外，通过空间划分、移动基站和角色差异化等手段，实现多机器人高效协作。

Result: 理论分析了BAPP的信息增益性质，并通过单/多机器人仿真实验验证。结果显示：BAPP-TID显著加速信息熵下降；BAPP-SIG在信息获取量损失极小的前提下显著提升机器人生存率。多机器人场景下，通过自适应分工和空间规划，BAPP展现出优异的可扩展性和协作能力。

Conclusion: BAPP行为自适应规划方法提升了高风险、失效易发环境下多机器人团队的勘测效率和安全性。该方法为复杂环境下的风险敏感自主探索提供了有力手段，有望推广至更多无人系统应用。

Abstract: We address the challenge of multi-robot autonomous hazard mapping in
high-risk, failure-prone, communication-denied environments such as
post-disaster zones, underground mines, caves, and planetary surfaces. In these
missions, robots must explore and map hazards while minimizing the risk of
failure due to environmental threats or hardware limitations. We introduce a
behavior-adaptive, information-theoretic planning framework for multi-robot
teams grounded in the concept of Behavioral Entropy (BE), that generalizes
Shannon entropy (SE) to capture diverse human-like uncertainty evaluations.
Building on this formulation, we propose the Behavior-Adaptive Path Planning
(BAPP) framework, which modulates information gathering strategies via a
tunable risk-sensitivity parameter, and present two planning algorithms:
BAPP-TID for intelligent triggering of high-fidelity robots, and BAPP-SIG for
safe deployment under high risk. We provide theoretical insights on the
informativeness of the proposed BAPP framework and validate its effectiveness
through both single-robot and multi-robot simulations. Our results show that
the BAPP stack consistently outperforms Shannon-based and random strategies:
BAPP-TID accelerates entropy reduction, while BAPP-SIG improves robot
survivability with minimal loss in information gain. In multi-agent
deployments, BAPP scales effectively through spatial partitioning, mobile base
relocation, and role-aware heterogeneity. These findings underscore the value
of behavior-adaptive planning for robust, risk-sensitive exploration in
complex, failure-prone environments.

</details>


### [213] [$NavA^3$: Understanding Any Instruction, Navigating Anywhere, Finding Anything](https://arxiv.org/abs/2508.04598)
*Lingfeng Zhang,Xiaoshuai Hao,Yingbo Tang,Haoxiang Fu,Xinyu Zheng,Pengwei Wang,Zhongyuan Wang,Wenbo Ding,Shanghang Zhang*

Main category: cs.RO

TL;DR: 该论文提出了一种新的层次化导航框架NavA^3，结合高级指令理解和空间感知，推动机器人在真实世界中进行复杂长距离导航。


<details>
  <summary>Details</summary>
Motivation: 现有导航任务多集中于预定义的目标或简单指令，无法满足需要理解复杂环境和高级人类指令的真实场景需求。

Method: 提出了NavA^3，分为全局策略和局部策略两阶段。全局阶段利用Reasoning-VLM解析高级指令并结合三维场景视图推理目标区域，局部阶段通过收集100万样本训练NaviAfford模型，实现开放词汇目标的定位和空间感知，以支持精确导航。

Result: NavA^3在长距离导航任务中取得了最先进的表现，能在多种真实机器人平台上成功完成不同场景的导航任务。

Conclusion: NavA^3显著提升了机器人在开放词汇、复杂场景下的导航与目标定位能力，为通用化真实世界导航奠定了基础。

Abstract: Embodied navigation is a fundamental capability of embodied intelligence,
enabling robots to move and interact within physical environments. However,
existing navigation tasks primarily focus on predefined object navigation or
instruction following, which significantly differs from human needs in
real-world scenarios involving complex, open-ended scenes. To bridge this gap,
we introduce a challenging long-horizon navigation task that requires
understanding high-level human instructions and performing spatial-aware object
navigation in real-world environments. Existing embodied navigation methods
struggle with such tasks due to their limitations in comprehending high-level
human instructions and localizing objects with an open vocabulary. In this
paper, we propose $NavA^3$, a hierarchical framework divided into two stages:
global and local policies. In the global policy, we leverage the reasoning
capabilities of Reasoning-VLM to parse high-level human instructions and
integrate them with global 3D scene views. This allows us to reason and
navigate to regions most likely to contain the goal object. In the local
policy, we have collected a dataset of 1.0 million samples of spatial-aware
object affordances to train the NaviAfford model (PointingVLM), which provides
robust open-vocabulary object localization and spatial awareness for precise
goal identification and navigation in complex environments. Extensive
experiments demonstrate that $NavA^3$ achieves SOTA results in navigation
performance and can successfully complete longhorizon navigation tasks across
different robot embodiments in real-world settings, paving the way for
universal embodied navigation. The dataset and code will be made available.
Project website: https://NavigationA3.github.io/.

</details>


### [214] [RoboTron-Sim: Improving Real-World Driving via Simulated Hard-Case](https://arxiv.org/abs/2508.04642)
*Baihui Xiao,Chengjian Feng,Zhijian Huang,Feng yan,Yujie Zhong,Lin Ma*

Main category: cs.RO

TL;DR: 该论文提出利用由模拟生成的高风险极端场景数据提升自动驾驶系统在关键情境下的表现。通过新型数据集和模型结构，显著增强了应对罕见、复杂驾驶事件的能力。


<details>
  <summary>Details</summary>
Motivation: 现实世界中收集罕见高风险场景、长尾驾驶事件和复杂交互的数据非常困难，导致现有自动驾驶系统在这些关键情境下表现较差。该研究旨在通过模拟手段丰富这类关键场景的数据，从而提升系统在真实关键情境中的性能。

Method: 1）开发模拟数据集HASS，涵盖13类高风险极端场景，并平衡多种环境条件（如昼/夜、晴/雨）；2）提出场景感知提示工程（SPE）与图像到自车坐标编码器（I2E Encoder），使大型多模态语言模型能够从HASS中有效学习真实世界的复杂驾驶技能，并适应模拟与真实环境差异。

Result: 在nuScenes数据集上大量实验证明，RoboTron-Sim在挑战场景下的驾驶性能提升约50%，在真实数据上的开放环规划任务中达到最新水平。定性结果也展示了其在应对罕见高风险驾驶场景时的优越性。

Conclusion: 通过引入高风险极端场景模拟数据和场景感知提示工程等方法，RoboTron-Sim有效提升了自动驾驶系统在现实关键驾驶情境下的表现，为提升安全性和应对长尾事件提供了有力手段。

Abstract: Collecting real-world data for rare high-risk scenarios, long-tailed driving
events, and complex interactions remains challenging, leading to poor
performance of existing autonomous driving systems in these critical
situations. In this paper, we propose RoboTron-Sim that improves real-world
driving in critical situations by utilizing simulated hard cases. First, we
develop a simulated dataset called Hard-case Augmented Synthetic Scenarios
(HASS), which covers 13 high-risk edge-case categories, as well as balanced
environmental conditions such as day/night and sunny/rainy. Second, we
introduce Scenario-aware Prompt Engineering (SPE) and an Image-to-Ego Encoder
(I2E Encoder) to enable multimodal large language models to effectively learn
real-world challenging driving skills from HASS, via adapting to environmental
deviations and hardware differences between real-world and simulated scenarios.
Extensive experiments on nuScenes show that RoboTron-Sim improves driving
performance in challenging scenarios by around 50%, achieving state-of-the-art
results in real-world open-loop planning. Qualitative results further
demonstrate the effectiveness of RoboTron-Sim in better managing rare high-risk
driving scenarios. Project page: https://stars79689.github.io/RoboTron-Sim/

</details>


### [215] [Open Scene Graphs for Open-World Object-Goal Navigation](https://arxiv.org/abs/2508.04678)
*Joel Loo,Zhanxin Wu,David Hsu*

Main category: cs.RO

TL;DR: 本文提出OSG Navigator，一种利用基础模型，针对开放世界语义导航任务（如机器人根据自然语言在新环境中寻找目标物体）设计的通用机器人系统。该系统采用开放场景图（OSG）作为空间记忆，有效组织和泛化环境信息，实现对不同目标、环境和机器人的零样本泛化，并在实际和仿真中达到最新性能。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型虽具备丰富语义知识，但在大规模环境中难以有效管理和利用空间信息，限制了机器人在未知环境中的通用性和开放性导航能力。因此，亟需一种能融合语义理解与空间组织的机器人导航方法，提升机器人在开放世界中的任务执行能力。

Method: 提出OSG Navigator系统，将基础模型嵌入机器人模块，创新性地提出开放场景图（OSG）空间记忆表示。OSG基于可自动生成的“场景图模板”（schema），以分层结构组织空间信息，无需复杂建模即可根据简单语义标签（如“家”、“超市”）快速适配新环境，增强零样本泛化能力。

Result: 在Fetch和Spot机器人（仿真与现实）中进行多项实验，OSG Navigator在ObjectNav基准上取得最先进性能，且可无须额外训练即在不同目标、环境和机器人平台间实现零样本泛化。

Conclusion: OSG Navigator充分结合了基础模型的语义知能与高效空间组织，展示了通用机器人系统在开放世界内语义导航的可行新路径，为机器人认知与行为泛化带来实际突破。

Abstract: How can we build general-purpose robot systems for open-world semantic
navigation, e.g., searching a novel environment for a target object specified
in natural language? To tackle this challenge, we introduce OSG Navigator, a
modular system composed of foundation models, for open-world Object-Goal
Navigation (ObjectNav). Foundation models provide enormous semantic knowledge
about the world, but struggle to organise and maintain spatial information
effectively at scale. Key to OSG Navigator is the Open Scene Graph
representation, which acts as spatial memory for OSG Navigator. It organises
spatial information hierarchically using OSG schemas, which are templates, each
describing the common structure of a class of environments. OSG schemas can be
automatically generated from simple semantic labels of a given environment,
e.g., "home" or "supermarket". They enable OSG Navigator to adapt zero-shot to
new environment types. We conducted experiments using both Fetch and Spot
robots in simulation and in the real world, showing that OSG Navigator achieves
state-of-the-art performance on ObjectNav benchmarks and generalises zero-shot
over diverse goals, environments, and robot embodiments.

</details>


### [216] [From MAS to MARS: Coordination Failures and Reasoning Trade-offs in Hierarchical Multi-Agent Robotic Systems within a Healthcare Scenario](https://arxiv.org/abs/2508.04691)
*Yuanchen Bai,Zijian Ding,Shaoyue Wen,Xiang Chang,Angelique Taylor*

Main category: cs.RO

TL;DR: 本文分析了基于多智能体系统的多机器人系统（MARS）在现实场景部署中的协调和执行挑战，提出并测试了两种多智能体框架下的协调机制，揭示系统自主性与稳定性的权衡。


<details>
  <summary>Details</summary>
Motivation: 虽然多智能体系统（MAS）框架已高度发展，但其在机器人领域的现实部署受限，限制了MARS实际应用和研究进展。因此，论文旨在探究当前多智能体框架在真实世界中应用时的性能瓶颈与改进方向。

Method: 作者通过两项模拟实验（健康护理场景）分析多智能体框架：1）基于CrewAI，迭代完善知识库，归纳无法单靠知识提供解决的协调失败类型；2）基于AutoGen，设计双向通信结构，评估推理与非推理模型在同一机器人团队中的权衡表现。

Result: 实验揭示了如工具访问违规、失效报告处理不及时等协调失败类型，指出单靠场景知识无法完全消除此类问题。通过双向通信与模型组合，作者详细分析了系统实际工作中的自主性与稳定性间的矛盾。

Conclusion: 论文认为，提升多机器人系统可靠性与安全性需重视极端案例测试，并强调系统自主性与稳定性需综合权衡。文中提供了丰富的补充材料供进一步研究。

Abstract: Multi-agent robotic systems (MARS) build upon multi-agent systems by
integrating physical and task-related constraints, increasing the complexity of
action execution and agent coordination. However, despite the availability of
advanced multi-agent frameworks, their real-world deployment on robots remains
limited, hindering the advancement of MARS research in practice. To bridge this
gap, we conducted two studies to investigate performance trade-offs of
hierarchical multi-agent frameworks in a simulated real-world multi-robot
healthcare scenario. In Study 1, using CrewAI, we iteratively refine the
system's knowledge base, to systematically identify and categorize coordination
failures (e.g., tool access violations, lack of timely handling of failure
reports) not resolvable by providing contextual knowledge alone. In Study 2,
using AutoGen, we evaluate a redesigned bidirectional communication structure
and further measure the trade-offs between reasoning and non-reasoning models
operating within the same robotic team setting. Drawing from our empirical
findings, we emphasize the tension between autonomy and stability and the
importance of edge-case testing to improve system reliability and safety for
future real-world deployment. Supplementary materials, including codes, task
agent setup, trace outputs, and annotated examples of coordination failures and
reasoning behaviors, are available at:
https://byc-sophie.github.io/mas-to-mars/.

</details>


### [217] [Achieving Precise and Reliable Locomotion with Differentiable Simulation-Based System Identification](https://arxiv.org/abs/2508.04696)
*Vyacheslav Kovalev,Ekaterina Chaikovskaia,Egor Davydenko,Roman Gorbachev*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的控制框架，将系统辨识无缝集成到强化学习训练流程中，通过可微分仿真（MuJoCo-XLA）优化机器人系统参数，仅依靠轨迹及控制信号数据，无需直接测量力矩，实现仿真与现实行为高度一致，有效减少双足机器人轨迹漂移。


<details>
  <summary>Details</summary>
Motivation: 在双足机器人运动中，轨迹漂移会影响其步态稳定性和精准性，而现有强化学习或基于模型的控制方法，需要高精度的系统参数获得，但传统系统辨识依赖于力矩等难以直接测量的物理量，降低了辨识效率和可推广性。因此，本研究致力于开发只利用可获得数据（如位置、速度、控制输入）实现系统参数高效辨识，提高轨迹精度。

Method: 提出将系统辨识过程直接嵌入强化学习训练回路，利用可微分仿真平台MuJoCo-XLA，通过对比仿真轨迹与真实轨迹，自动优化系统参数。参数范围覆盖基础物理属性（如质量、惯性），并可通过神经网络建模复杂的非线性（如高级摩擦模型），无需力矩等难测信息。

Result: 实验结果表明，该方法能大幅提升机器人轨迹跟踪精度，显著减少运动漂移，仿真与实际的行为趋势更为一致，并展现出良好的标定灵活性和扩展性。

Conclusion: 将系统辨识集成到可微强化学习与仿真平台，可有效提升双足步行机器人在实际场景中的轨迹精度与稳健性，适用于各类复杂物理参数及非线性建模，具有良好的应用前景。

Abstract: Accurate system identification is crucial for reducing trajectory drift in
bipedal locomotion, particularly in reinforcement learning and model-based
control. In this paper, we present a novel control framework that integrates
system identification into the reinforcement learning training loop using
differentiable simulation. Unlike traditional approaches that rely on direct
torque measurements, our method estimates system parameters using only
trajectory data (positions, velocities) and control inputs. We leverage the
differentiable simulator MuJoCo-XLA to optimize system parameters, ensuring
that simulated robot behavior closely aligns with real-world motion. This
framework enables scalable and flexible parameter optimization. Accurate system
identification is crucial for reducing trajectory drift in bipedal locomotion,
particularly in reinforcement learning and model-based control. In this paper,
we present a novel control framework that integrates system identification into
the reinforcement learning training loop using differentiable simulation.
Unlike traditional approaches that rely on direct torque measurements, our
method estimates system parameters using only trajectory data (positions,
velocities) and control inputs. We leverage the differentiable simulator
MuJoCo-XLA to optimize system parameters, ensuring that simulated robot
behavior closely aligns with real-world motion. This framework enables scalable
and flexible parameter optimization. It supports fundamental physical
properties such as mass and inertia. Additionally, it handles complex system
nonlinear behaviors, including advanced friction models, through neural network
approximations. Experimental results show that our framework significantly
improves trajectory following.

</details>
