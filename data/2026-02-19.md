<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 46]
- [cs.CL](#cs.CL) [Total: 69]
- [cs.RO](#cs.RO) [Total: 46]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Egocentric Bias in Vision-Language Models](https://arxiv.org/abs/2602.15892)
*Maijunxian Wang,Yijiang Li,Bingyang Wang,Tianwei Zhao,Ran Ji,Qingying Gao,Emmy Liu,Hokin Deng,Dezhi Luo*

Main category: cs.CV

TL;DR: 本文提出了FlipSet基准，用于测试视觉-语言模型的二级视觉视角转换能力，发现当前模型在需要结合社交理解与空间转换时存在严重缺陷。


<details>
  <summary>Details</summary>
Motivation: 视觉视角转换是社会认知的重要基础，但视觉-语言模型目前在空间和社交认知集成方面的能力尚不明确，急需一个标准化的诊断工具和系统性分析。

Method: 作者提出了FlipSet基准任务，要求模型模拟另一个观察者的180度视角旋转，从而排除3D场景复杂性的影响，专注于空间变换。他们测试了103个视觉-语言模型，并设计了对照实验比较理论心智和单独空间旋转任务。

Result: 绝大多数模型在FlipSet任务下表现低于随机水平，并且三分之二的错误与摄像机视角一致。虽然模型在单一理论心智和空间旋转任务取得较高成绩，但在需要组合这两类能力时表现极差。

Conclusion: 当前视觉-语言模型在社交认知与空间操作结合方面存在根本性局限，FlipSet成为诊断多模态系统视角转换能力的重要工具。

Abstract: Visual perspective taking--inferring how the world appears from another's viewpoint--is foundational to social cognition. We introduce FlipSet, a diagnostic benchmark for Level-2 visual perspective taking (L2 VPT) in vision-language models. The task requires simulating 180-degree rotations of 2D character strings from another agent's perspective, isolating spatial transformation from 3D scene complexity. Evaluating 103 VLMs reveals systematic egocentric bias: the vast majority perform below chance, with roughly three-quarters of errors reproducing the camera viewpoint. Control experiments expose a compositional deficit--models achieve high theory-of-mind accuracy and above-chance mental rotation in isolation, yet fail catastrophically when integration is required. This dissociation indicates that current VLMs lack the mechanisms needed to bind social awareness to spatial operations, suggesting fundamental limitations in model-based spatial reasoning. FlipSet provides a cognitively grounded testbed for diagnosing perspective-taking capabilities in multimodal systems.

</details>


### [2] [Detecting Deepfakes with Multivariate Soft Blending and CLIP-based Image-Text Alignment](https://arxiv.org/abs/2602.15903)
*Jingwei Li,Jiaxin Tong,Pengfei Wu*

Main category: cs.CV

TL;DR: 提出了MSBA-CLIP方法，通过多模态对齐与多元伪造增强，有效提升了人脸伪造检测的准确性和泛化能力，在多个数据集上取得新SOTA。


<details>
  <summary>Details</summary>
Motivation: 随着高仿真面部伪造技术的激增，现有检测算法因不同伪造手法的分布差异，准确率和泛化能力受限，因此急需更鲁棒的检测方法。

Method: 方法结合了CLIP的多模态对齐能力和多元软混合增强机制（MSBA）：通过随机权重融合多种伪造数据，迫使模型学习普遍伪造特征。同时引入伪造强度估计模块（MFIE），显式引导模型关注不同类型与强度的伪造痕迹，提升泛化能力。

Result: 大规模实验表明，所提方法在同域测试中，准确率和AUC分别比现有最好基线提升3.32%和4.02%；跨域五个数据集平均AUC提升3.27%。消融实验也证实两大组件的有效性。

Conclusion: 依赖大型视觉-语言模型带来计算开销，但MSBA-CLIP大幅提升了伪造检测的泛化性和鲁棒性，是朝向更通用深度伪造检测的重要进展。

Abstract: The proliferation of highly realistic facial forgeries necessitates robust detection methods. However, existing approaches often suffer from limited accuracy and poor generalization due to significant distribution shifts among samples generated by diverse forgery techniques. To address these challenges, we propose a novel Multivariate and Soft Blending Augmentation with CLIP-guided Forgery Intensity Estimation (MSBA-CLIP) framework. Our method leverages the multimodal alignment capabilities of CLIP to capture subtle forgery traces. We introduce a Multivariate and Soft Blending Augmentation (MSBA) strategy that synthesizes images by blending forgeries from multiple methods with random weights, forcing the model to learn generalizable patterns. Furthermore, a dedicated Multivariate Forgery Intensity Estimation (MFIE) module is designed to explicitly guide the model in learning features related to varied forgery modes and intensities. Extensive experiments demonstrate state-of-the-art performance. On in-domain tests, our method improves Accuracy and AUC by 3.32\% and 4.02\%, respectively, over the best baseline. In cross-domain evaluations across five datasets, it achieves an average AUC gain of 3.27\%. Ablation studies confirm the efficacy of both proposed components. While the reliance on a large vision-language model entails higher computational cost, our work presents a significant step towards more generalizable and robust deepfake detection.

</details>


### [3] [A Comprehensive Survey on Deep Learning-Based LiDAR Super-Resolution for Autonomous Driving](https://arxiv.org/abs/2602.15904)
*June Moh Goo,Zichao Zeng,Jan Boehm*

Main category: cs.CV

TL;DR: 本文综述了自动驾驶领域中使用深度学习提升低分辨率LiDAR点云分辨率的研究进展与方法分类，总结了基础概念、主流体系、当前趋势，并指出未来挑战。


<details>
  <summary>Details</summary>
Motivation: 高分辨率LiDAR传感器昂贵，而低分辨率传感器数据稀疏且信息缺失，限制了自动驾驶技术的普及和跨传感器的兼容性，因此需要对低分辨率点云进行超分辨率处理。尽管技术意义重大，目前缺乏系统综述。

Method: 本文首次对自动驾驶中的LiDAR超分辨率方法进行全面综述，将现有方法分为四类：基于卷积神经网络（CNN）、基于模型展开、基于隐式表示以及基于Transformer和Mamba的架构。同时介绍数据表示方法、问题形式化、常用数据集与评测指标。

Result: 梳理了主流方法及现有技术发展的趋势，例如采用range image进行高效处理、极致模型压缩、分辨率灵活的网络架构等。指出最新研究日益关注实时推理和跨传感器泛化能力以促进实用化。

Conclusion: 总结了当前LiDAR超分辨率领域的进展，指出了实际应用中仍待解决的问题，并展望了未来的研究方向。

Abstract: LiDAR sensors are often considered essential for autonomous driving, but high-resolution sensors remain expensive while affordable low-resolution sensors produce sparse point clouds that miss critical details. LiDAR super-resolution addresses this challenge by using deep learning to enhance sparse point clouds, bridging the gap between different sensor types and enabling cross-sensor compatibility in real-world deployments. This paper presents the first comprehensive survey of LiDAR super-resolution methods for autonomous driving. Despite the importance of practical deployment, no systematic review has been conducted until now. We organize existing approaches into four categories: CNN-based architectures, model-based deep unrolling, implicit representation methods, and Transformer and Mamba-based approaches. We establish fundamental concepts including data representations, problem formulation, benchmark datasets and evaluation metrics. Current trends include the adoption of range image representation for efficient processing, extreme model compression and the development of resolution-flexible architectures. Recent research prioritizes real-time inference and cross-sensor generalization for practical deployment. We conclude by identifying open challenges and future research directions for advancing LiDAR super-resolution technology.

</details>


### [4] [MaS-VQA: A Mask-and-Select Framework for Knowledge-Based Visual Question Answering](https://arxiv.org/abs/2602.15915)
*Xianwei Mao,Kai Ye,Sheng Zhou,Nan Zhang,Haikuan Huang,Bin Li,Jiajun Bu*

Main category: cs.CV

TL;DR: 本文提出了一种新的框架MaS-VQA，通过对外部知识和视觉信息进行联合选择过滤，从而提升视觉问答任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 在知识驱动的视觉问答（KB-VQA）任务中，模型需要综合图像信息与外部知识来回答问题。然而，现有方法中的外部知识往往很嘈杂、部分无关，且与视觉内容存在偏差，内部模型的知识也难以控制与解释，导致推理能力和答案准确率受限。因此，提升多源知识信息的有效融合和利用成为核心挑战。

Method: 作者提出MaS-VQA框架，首先检索候选知识段落，并利用Mask-and-Select机制联合过滤图像中无关区域和文本知识中的弱相关片段，生成精简且高价值的多模态知识。随后，这些过滤后的显式知识引导对模型内部知识的激活，实现显式与隐式知识的协同推理，从而提升答案预测的鲁棒性。

Result: 在Encyclopedic-VQA和InfoSeek数据集，以及多种大语言视觉模型（MLLM）后端上，MaS-VQA均取得了持续的性能提升。消融实验还验证了选择机制能有效降噪并增强知识利用效果。

Conclusion: MaS-VQA结合了知识过滤与协同推理的优势，有效缓解了外部知识噪声和知识利用不足的问题，提升了KB-VQA任务的性能和鲁棒性。

Abstract: Knowledge-based Visual Question Answering (KB-VQA) requires models to answer questions by integrating visual information with external knowledge. However, retrieved knowledge is often noisy, partially irrelevant, or misaligned with the visual content, while internal model knowledge is difficult to control and interpret. Naive aggregation of these sources limits reasoning effectiveness and reduces answer accuracy. To address this, we propose MaS-VQA, a selection-driven framework that tightly couples explicit knowledge filtering with implicit knowledge reasoning. MaS-VQA first retrieves candidate passages and applies a Mask-and-Select mechanism to jointly prune irrelevant image regions and weakly relevant knowledge fragments, producing compact, high-signal multimodal knowledge . This filtered knowledge then guides the activation of internal knowledge in a constrained semantic space, enabling complementary co-modeling of explicit and implicit knowledge for robust answer prediction. Experiments on Encyclopedic-VQA and InfoSeek demonstrate consistent performance gains across multiple MLLM backbones, and ablations verify that the selection mechanism effectively reduces noise and enhances knowledge utilization.

</details>


### [5] [EarthSpatialBench: Benchmarking Spatial Reasoning Capabilities of Multimodal LLMs on Earth Imagery](https://arxiv.org/abs/2602.15918)
*Zelin Xu,Yupu Zhang,Saugat Adhikari,Saiful Islam,Tingsong Xiao,Zibo Liu,Shigang Chen,Da Yan,Zhe Jiang*

Main category: cs.CV

TL;DR: 此论文提出了一个新的基准EarthSpatialBench，用于评测多模态大语言模型（MLLMs）在地球影像上的空间推理能力，涵盖定量距离、方向、拓扑关系及复杂对象几何等方面。


<details>
  <summary>Details</summary>
Motivation: 目前的空间推理基准多集中于一般计算机视觉场景，很少关注地球影像，其中涉及地理坐标物体的精确推理，其现有基准在方向、距离、复杂空间关系和对象几何支持上有限，因此需要更全面、系统的评测基准。

Method: 作者设计EarthSpatialBench基准，包含325K+问答对，涵盖：定性与定量距离与方向推理、系统化拓扑关系、单对象/对象对/组合对象查询，以及不同方式的对象参照（文本、视觉标注、坐标几何）。并对开源和专有模型进行了大规模实验评测。

Result: 通过该基准，实验揭示了现有多模态大模型在空间推理上的不足与局限，尤其是在定量距离、复杂拓扑关系和几何对象上的表现不佳。

Conclusion: EarthSpatialBench为MLLMs在地球影像空间推理提供了首个系统且全面的评测工具，对于推动具备真实世界地理空间推理能力的智能系统具有重要意义。

Abstract: Benchmarking spatial reasoning in multimodal large language models (MLLMs) has attracted growing interest in computer vision due to its importance for embodied AI and other agentic systems that require precise interaction with the physical world. However, spatial reasoning on Earth imagery has lagged behind, as it uniquely involves grounding objects in georeferenced images and quantitatively reasoning about distances, directions, and topological relations using both visual cues and vector geometry coordinates (e.g., 2D bounding boxes, polylines, and polygons). Existing benchmarks for Earth imagery primarily focus on 2D spatial grounding, image captioning, and coarse spatial relations (e.g., simple directional or proximity cues). They lack support for quantitative direction and distance reasoning, systematic topological relations, and complex object geometries beyond bounding boxes. To fill this gap, we propose \textbf{EarthSpatialBench}, a comprehensive benchmark for evaluating spatial reasoning in MLLMs on Earth imagery. The benchmark contains over 325K question-answer pairs spanning: (1) qualitative and quantitative reasoning about spatial distance and direction; (2) systematic topological relations; (3) single-object queries, object-pair queries, and compositional aggregate group queries; and (4) object references expressed via textual descriptions, visual overlays, and explicit geometry coordinates, including 2D bounding boxes, polylines, and polygons. We conducted extensive experiments on both open-source and proprietary models to identify limitations in the spatial reasoning of MLLMs.

</details>


### [6] [A Study on Real-time Object Detection using Deep Learning](https://arxiv.org/abs/2602.15926)
*Ankita Bose,Jayasravani Bhumireddy,Naveen N*

Main category: cs.CV

TL;DR: 本文综述了当前深度学习算法在实时目标检测中的应用与发展。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能的发展，对实时、准确的目标检测需求日益增长，广泛应用于自动驾驶、安全监控等多个领域。

Method: 系统梳理和分析了主流目标检测算法（如Faster R-CNN、YOLO、SSD等）、公开数据集，并对不同模型在各种应用场景下的表现进行对比和研究。

Result: 通过对比实验，得出各算法在不同应用中的优缺点及表现差异，同时揭示了模型在实际应用中的挑战。

Conclusion: 深度学习极大推动了目标检测的发展，但仍有诸多待解决的问题，文章提出了未来在算法改进与应用研究方面的建议。

Abstract: Object detection has compelling applications over a range of domains, including human-computer interfaces, security and video surveillance, navigation and road traffic monitoring, transportation systems, industrial automation healthcare, the world of Augmented Reality (AR) and Virtual Reality (VR), environment monitoring and activity identification. Applications of real time object detection in all these areas provide dynamic analysis of the visual information that helps in immediate decision making. Furthermore, advanced deep learning algorithms leverage the progress in the field of object detection providing more accurate and efficient solutions. There are some outstanding deep learning algorithms for object detection which includes, Faster R CNN(Region-based Convolutional Neural Network),Mask R-CNN, Cascade R-CNN, YOLO (You Only Look Once), SSD (Single Shot Multibox Detector), RetinaNet etc. This article goes into great detail on how deep learning algorithms are used to enhance real time object recognition. It provides information on the different object detection models available, open benchmark datasets, and studies on the use of object detection models in a range of applications. Additionally, controlled studies are provided to compare various strategies and produce some illuminating findings. Last but not least, a number of encouraging challenges and approaches are offered as suggestions for further investigation in both relevant deep learning approaches and object recognition.

</details>


### [7] [Visual Memory Injection Attacks for Multi-Turn Conversations](https://arxiv.org/abs/2602.15927)
*Christian Schlarmann,Matthias Hein*

Main category: cs.CV

TL;DR: 本文提出了一种新型的隐蔽视觉记忆注入（VMI）攻击方式，能够利用篡改图片诱导大型视觉-语言模型（LVLMs）在多轮长对话后输出指定消息，展示了此类攻击在真实环境下的威胁。


<details>
  <summary>Details</summary>
Motivation: LVMs用户日益增长，但其安全性研究不足，尤其在长上下文、多轮对话场景中的潜在攻击手法尚未被充分探索。

Method: 设计VMI攻击：攻击者上传经过特殊处理的图片，普通用户下载并输入LVLM。在非触发提示下模型表现正常，一旦收到特定“触发提示”，模型即输出攻击者预设的信息。该方法针对长对话和多轮交互场景，有别于以往只关注单轮攻击的研究。

Result: 在多个主流开源LVLM上实验验证，证明VMI攻击在经历多轮对话后依然有效，大规模操控用户成为现实威胁。

Conclusion: LVLM存在经图片注入的长对话操控风险，应加强针对多轮场景的鲁棒性防护。相关代码已公开。

Abstract: Generative large vision-language models (LVLMs) have recently achieved impressive performance gains, and their user base is growing rapidly. However, the security of LVLMs, in particular in a long-context multi-turn setting, is largely underexplored. In this paper, we consider the realistic scenario in which an attacker uploads a manipulated image to the web/social media. A benign user downloads this image and uses it as input to the LVLM. Our novel stealthy Visual Memory Injection (VMI) attack is designed such that on normal prompts the LVLM exhibits nominal behavior, but once the user gives a triggering prompt, the LVLM outputs a specific prescribed target message to manipulate the user, e.g. for adversarial marketing or political persuasion. Compared to previous work that focused on single-turn attacks, VMI is effective even after a long multi-turn conversation with the user. We demonstrate our attack on several recent open-weight LVLMs. This article thereby shows that large-scale manipulation of users is feasible with perturbed images in multi-turn conversation settings, calling for better robustness of LVLMs against these attacks. We release the source code at https://github.com/chs20/visual-memory-injection

</details>


### [8] [Can Vision-Language Models See Squares? Text-Recognition Mediates Spatial Reasoning Across Three Model Families](https://arxiv.org/abs/2602.15950)
*Yuval Levental*

Main category: cs.CV

TL;DR: 作者设计了实验，发现顶尖视觉语言模型难以准确定位没有文字信息的二值格子中的填充单元，暴露了其空间识别能力的局限。


<details>
  <summary>Details</summary>
Motivation: 当前VLMs虽然在多模态任务上表现卓越，但对于无文本身份信息的结构化视觉内容，其空间定位和识别能力尚不明确，作者希望揭示其短板。

Method: 作者制作15张不同密度（10.7%-41.8%填充率）的15x15二值格子，分别用文本符号（.和#）和纯色方格（无网格线）渲染为图片，并要求Claude Opus、ChatGPT 5.2和Gemini 3 Thinking三种主流VLM对其重新转写（转录）。比较两种条件下的识别准确率与F1分数。

Result: 在文本符号条件下，Claude和ChatGPT达到约91%单元准确率和84% F1，Gemini为84%和63%；在纯色方格条件下，三者准确率跌至60-73%，F1仅29-39%。不同模型在纯色条件下表现各有典型失败模式，但空间定位非文本元素的能力均严重退化。

Conclusion: VLMs仿佛具备高保真的文本识别通路用于空间推理，但其视觉通路本身在空间精准定位非文本元素时能力有限。这暴露了VLMs对非文本视觉结构化任务的根本缺陷。

Abstract: We present a simple experiment that exposes a fundamental limitation in vision-language models (VLMs): the inability to accurately localize filled cells in binary grids when those cells lack textual identity. We generate fifteen 15x15 grids with varying density (10.7%-41.8% filled cells) and render each as two image types -- text symbols (. and #) and filled squares without gridlines -- then ask three frontier VLMs (Claude Opus, ChatGPT 5.2, and Gemini 3 Thinking) to transcribe them. In the text-symbol condition, Claude and ChatGPT achieve approximately 91% cell accuracy and 84% F1, while Gemini achieves 84% accuracy and 63% F1. In the filled-squares condition, all three models collapse to 60-73% accuracy and 29-39% F1. Critically, all conditions pass through the same visual encoder -- the text symbols are images, not tokenized text. The text-vs-squares F1 gap ranges from 34 to 54 points across models, demonstrating that VLMs behave as if they possess a high-fidelity text-recognition pathway for spatial reasoning that dramatically outperforms their native visual pathway. Each model exhibits a distinct failure mode in the squares condition -- systematic under-counting (Claude), massive over-counting (ChatGPT), and template hallucination (Gemini) -- but all share the same underlying deficit: severely degraded spatial localization for non-textual visual elements.

</details>


### [9] [Position-Aware Scene-Appearance Disentanglement for Bidirectional Photoacoustic Microscopy Registration](https://arxiv.org/abs/2602.15959)
*Yiwen Wang,Jiahao Qin*

Main category: cs.CV

TL;DR: 该论文提出一种新方法GPEReg-Net，用于解决高速光学分辨光声显微成像过程中正反向扫描造成的图像错位和域差异问题，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在高速度光学分辨光声显微成像（OR-PAM）中，双向扫描虽提高了成像速度，但正反向的图像会出现域转移和几何错位问题，现有配准方法在精度和时间一致性方面存在瓶颈。

Method: 提出GPEReg-Net，通过自适应实例归一化（AdaIN）实现场景特征与外观特征解耦，进而支持直接的图像到图像注册，无需估算形变场。引入全局位置编码（GPE）模块，结合可学习的位置嵌入、正余弦编码及跨帧注意力机制，有效融合邻帧的时序结构信息，提高配准的时空一致性。

Result: 在OR-PAM-Reg-4K基准测试（432个样本）上，GPEReg-Net取得了NCC为0.953，SSIM为0.932，PSNR为34.49dB的优异结果，比当前最好方法SSIM提升3.8%，PSNR提升1.99dB，同时NCC表现竞争力。

Conclusion: GPEReg-Net大幅提升了高速OR-PAM成像配准的效果和时序一致性，优于现有方法，并具有实际应用价值，相关代码已开源。

Abstract: High-speed optical-resolution photoacoustic microscopy (OR-PAM) with bidirectional raster scanning doubles imaging speed but introduces coupled domain shift and geometric misalignment between forward and backward scan lines. Existing registration methods, constrained by brightness constancy assumptions, achieve limited alignment quality, while recent generative approaches address domain shift through complex architectures that lack temporal awareness across frames. We propose GPEReg-Net, a scene-appearance disentanglement framework that separates domain-invariant scene features from domain-specific appearance codes via Adaptive Instance Normalization (AdaIN), enabling direct image-to-image registration without explicit deformation field estimation. To exploit temporal structure in sequential acquisitions, we introduce a Global Position Encoding (GPE) module that combines learnable position embeddings with sinusoidal encoding and cross-frame attention, allowing the network to leverage context from neighboring frames for improved temporal coherence. On the OR-PAM-Reg-4K benchmark (432 test samples), GPEReg-Net achieves NCC of 0.953, SSIM of 0.932, and PSNR of 34.49dB, surpassing the state-of-the-art by 3.8% in SSIM and 1.99dB in PSNR while maintaining competitive NCC. Code is available at https://github.com/JiahaoQin/GPEReg-Net.

</details>


### [10] [Automated Re-Identification of Holstein-Friesian Cattle in Dense Crowds](https://arxiv.org/abs/2602.15962)
*Phoenix Yu,Tilo Burghardt,Andrew W Dowsey,Neill W Campbell*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的奶牛目标检测与重识别(Dairy Cow Detection and Re-ID)方法，可在拥挤环境下有效识别个体，准确率高达98.93%，大幅提升现有方法表现。


<details>
  <summary>Details</summary>
Motivation: 现有奶牛检测与重识别方法在个体分散时表现良好，但在奶牛密集聚集、花斑打破轮廓的情况下效果急剧下降。因此，亟需一种在密集牧场环境下依然高效准确的检测与重识别方法。

Method: 提出了detect-segment-identify新管线，利用Open-Vocabulary Weight-free Localisation和Segment Anything模型作为预处理环节，结合重识别神经网络；并采集九天真实牧场CCTV数据进行评测。

Result: 新方法在密集奶牛环境下检测准确率达98.93%，分别比当前基于定向边界框和SAM检测基线高出47.52%和27.13%；进一步结合无监督对比学习，重识别准确率达94.82%。

Conclusion: 在真实工作牧场且无需人工干预的条件下，本方法实现在密集环境下的高效、可靠牛只检测与重识别。代码与数据集已公开，以促进复现与后续研究。

Abstract: Holstein-Friesian detection and re-identification (Re-ID) methods capture individuals well when targets are spatially separate. However, existing approaches, including YOLO-based species detection, break down when cows group closely together. This is particularly prevalent for species which have outline-breaking coat patterns. To boost both effectiveness and transferability in this setting, we propose a new detect-segment-identify pipeline that leverages the Open-Vocabulary Weight-free Localisation and the Segment Anything models as pre-processing stages alongside Re-ID networks. To evaluate our approach, we publish a collection of nine days CCTV data filmed on a working dairy farm. Our methodology overcomes detection breakdown in dense animal groupings, resulting in a 98.93% accuracy. This significantly outperforms current oriented bounding box-driven, as well as SAM species detection baselines with accuracy improvements of 47.52% and 27.13%, respectively. We show that unsupervised contrastive learning can build on this to yield 94.82% Re-ID accuracy on our test data. Our work demonstrates that Re-ID in crowded scenarios is both practical as well as reliable in working farm settings with no manual intervention. Code and dataset are provided for reproducibility.

</details>


### [11] [Non-Contact Physiological Monitoring in Pediatric Intensive Care Units via Adaptive Masking and Self-Supervised Learning](https://arxiv.org/abs/2602.15967)
*Mohamed Khalil Ben Salah,Philippe Jouvet,Rita Noumeir*

Main category: cs.CV

TL;DR: 本文提出了一种面向PICU环境的rPPG无接触心率监测预训练方法，融合自监督学习、进阶式训练课程和自适应掩码机制，大幅提升了在实际临床数据下的心率估计准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有PICU生命体征监测多依赖接触式传感器，带来感染风险和病人不适。非接触式rPPG虽有潜力，但受运动伪影、遮挡和光照变化影响大，实验室方法难以直接迁移到临床，特别缺乏标注样本驱动技术进步。

Method: 提出基于VisionMamba架构的自监督预训练框架，包括：(1) 分阶段课程训练，逐步提升重建难度并保持生理信息相关；(2) 轻量化Mamba控制的自适应掩码机制，指导时空补丁采样，强调关键区域；(3) 使用教师-学生蒸馏方法，由受监督模型提供潜在生理指导，逐步适应从公开数据、合成遮挡到无标注临床视频。

Result: 相较于标准掩码自编码器，平均绝对误差降低42%；优于PhysFormer 31%，最终MAE为3.2 bpm。无需显式提取ROI，模型可自动关注脉搏丰富区，并在遮挡与噪声影响下表现出良好的鲁棒性。

Conclusion: 所提框架有效提升了rPPG技术在PICU实际环境中的可用性和准确性，为大规模无创生命体征监测提供了新的解决方案。

Abstract: Continuous monitoring of vital signs in Pediatric Intensive Care Units (PICUs) is essential for early detection of clinical deterioration and effective clinical decision-making. However, contact-based sensors such as pulse oximeters may cause skin irritation, increase infection risk, and lead to patient discomfort. Remote photoplethysmography (rPPG) offers a contactless alternative to monitor heart rate using facial video, but remains underutilized in PICUs due to motion artifacts, occlusions, variable lighting, and domain shifts between laboratory and clinical data.
  We introduce a self-supervised pretraining framework for rPPG estimation in the PICU setting, based on a progressive curriculum strategy. The approach leverages the VisionMamba architecture and integrates an adaptive masking mechanism, where a lightweight Mamba-based controller assigns spatiotemporal importance scores to guide probabilistic patch sampling. This strategy dynamically increases reconstruction difficulty while preserving physiological relevance.
  To address the lack of labeled clinical data, we adopt a teacher-student distillation setup. A supervised expert model, trained on public datasets, provides latent physiological guidance to the student. The curriculum progresses through three stages: clean public videos, synthetic occlusion scenarios, and unlabeled videos from 500 pediatric patients.
  Our framework achieves a 42% reduction in mean absolute error relative to standard masked autoencoders and outperforms PhysFormer by 31%, reaching a final MAE of 3.2 bpm. Without explicit region-of-interest extraction, the model consistently attends to pulse-rich areas and demonstrates robustness under clinical occlusions and noise.

</details>


### [12] [LAND: A Longitudinal Analysis of Neuromorphic Datasets](https://arxiv.org/abs/2602.15973)
*Gregory Cohen,Alexandre Marcireau*

Main category: cs.CV

TL;DR: 本文综述了当前神经形态工程领域的数据集现状，指出数据挑战主要包括数据集稀缺、标准化不足、获取困难以及合成数据带来的新问题。


<details>
  <summary>Details</summary>
Motivation: 尽管过去十年神经形态数据集激增，但研究需求仍未满足，论文普遍呼吁更大规模、更多样化的数据集。这源于深度学习对数据量的需求和现有神经形态数据集在访问和使用上的各种现实障碍。

Method: 作者综述并分析了现有超过423个神经形态数据集，梳理其任务属性和数据结构，探讨了数据集规模、标准化和下载难点，并对合成和元数据集的作用进行了讨论。

Result: 分析表明，当前神经形态数据集普遍存在规模较小、标准化缺失、获取与应用困难等问题。合成数据集的兴起便利了一些应用测试，但也带来了偏见和限制。元数据集的引入可以在一定程度上缓解数据需求，减少偏倚。

Conclusion: 神经形态工程领域亟需改善数据集标准、提升可用性和规模，需警惕合成数据的潜在偏见。同时，推广元数据集理念有助于降低数据需求并推动技术发展。

Abstract: Neuromorphic engineering has a data problem. Despite the meteoric rise in the number of neuromorphic datasets published over the past ten years, the conclusion of a significant portion of neuromorphic research papers still states that there is a need for yet more data and even larger datasets. Whilst this need is driven in part by the sheer volume of data required by modern deep learning approaches, it is also fuelled by the current state of the available neuromorphic datasets and the difficulties in finding them, understanding their purpose, and determining the nature of their underlying task. This is further compounded by practical difficulties in downloading and using these datasets. This review starts by capturing a snapshot of the existing neuromorphic datasets, covering over 423 datasets, and then explores the nature of their tasks and the underlying structure of the presented data. Analysing these datasets shows the difficulties arising from their size, the lack of standardisation, and difficulties in accessing the actual data. This paper also highlights the growth in the size of individual datasets and the complexities involved in working with the data. However, a more important concern is the rise of synthetic datasets, created by either simulation or video-to-events methods. This review explores the benefits of simulated data for testing existing algorithms and applications, highlighting the potential pitfalls for exploring new applications of neuromorphic technologies. This review also introduces the concepts of meta-datasets, created from existing datasets, as a way of both reducing the need for more data, and to remove potential bias arising from defining both the dataset and the task.

</details>


### [13] [SAM 3D Body: Robust Full-Body Human Mesh Recovery](https://arxiv.org/abs/2602.15989)
*Xitong Yang,Devansh Kukreja,Don Pinkus,Anushka Sagar,Taosha Fan,Jinhyung Park,Soyong Shin,Jinkun Cao,Jiawei Liu,Nicolas Ugrinovic,Matt Feiszli,Jitendra Malik,Piotr Dollar,Kris Kitani*

Main category: cs.CV

TL;DR: 提出了SAM 3D Body（3DB）模型，实现了单图片人体三维重建，性能达到SOTA，并且对各种场景通用性和精度高。


<details>
  <summary>Details</summary>
Motivation: 现有三维人体重建方法在复杂、真实场景中的泛化能力和准确性有限，且很少能灵活利用额外信息引导推理，缺乏适用于精细用户交互和不同人体部件的通用模型。

Method: 提出了3DB模型，基于新的Momentum Human Rig（MHR）参数化网格实现骨架和表面形态分离；采用encoder-decoder架构；支持额外输入（如2D关键点、mask）作为prompt进行推理。使用多阶段标注流水线，结合手工和自动标注、几何优化等获得高质量数据，并开发多样化数据集和评价体系。

Result: 3DB在各类用户偏好调查和定量评估中均超越现有方法，对不常见姿势和特殊成像条件表现良好，泛化能力强。

Conclusion: 3DB及其MHR参数化方案均已开源，显著提升了三维人体重建的准确性、灵活性和泛化性，对相关研究和应用有重要意义。

Abstract: We introduce SAM 3D Body (3DB), a promptable model for single-image full-body 3D human mesh recovery (HMR) that demonstrates state-of-the-art performance, with strong generalization and consistent accuracy in diverse in-the-wild conditions. 3DB estimates the human pose of the body, feet, and hands. It is the first model to use a new parametric mesh representation, Momentum Human Rig (MHR), which decouples skeletal structure and surface shape. 3DB employs an encoder-decoder architecture and supports auxiliary prompts, including 2D keypoints and masks, enabling user-guided inference similar to the SAM family of models. We derive high-quality annotations from a multi-stage annotation pipeline that uses various combinations of manual keypoint annotation, differentiable optimization, multi-view geometry, and dense keypoint detection. Our data engine efficiently selects and processes data to ensure data diversity, collecting unusual poses and rare imaging conditions. We present a new evaluation dataset organized by pose and appearance categories, enabling nuanced analysis of model behavior. Our experiments demonstrate superior generalization and substantial improvements over prior methods in both qualitative user preference studies and traditional quantitative analysis. Both 3DB and MHR are open-source.

</details>


### [14] [BTReport: A Framework for Brain Tumor Radiology Report Generation with Clinically Relevant Features](https://arxiv.org/abs/2602.16006)
*Juampablo E. Heras Rivera,Dickson T. Chen,Tianyi Ren,Daniel K. Low,Asma Ben Abacha,Alberto Santamaria-Pang,Mehmet Kurt*

Main category: cs.CV

TL;DR: 提出了一种用于脑肿瘤影像报告生成（RRG）的开源框架BTReport，通过确定性影像特征提取和大语言模型结合，实现了更可解释、更贴近临床的自动化报告生成，同时发布了配套数据集。


<details>
  <summary>Details</summary>
Motivation: 现有RRG进展主要得益于大规模的配对影像-文本数据集，但在神经肿瘤学领域由于缺乏开放数据集，进展缓慢。需要更可解释、减少‘幻觉’、贴合临床实际的报告自动生成方法。

Method: BTReport采取两步法：第一步用确定性方法提取影像特征，第二步仅用大语言模型进行句法和叙述结构构建（非影像解释）。这种分离使报告过程更易解释、减少虚假生成。系统还与BraTS影像数据集结合，合成了配套报告数据集。

Result: 所用特征不仅可生成报告，还能预测关键临床结局，如生存和IDH突变状态。BTReport生成的报告比现有方法与标准临床报告更一致。BTReport-BraTS数据集为进一步研究提供数据基础。

Conclusion: BTReport框架提升了RRG的可解释性与临床一致性，降低了AI报告‘幻觉’的风险，并通过开源方式促进神经肿瘤学领域的自动化报告研究。

Abstract: Recent advances in radiology report generation (RRG) have been driven by large paired image-text datasets; however, progress in neuro-oncology has been limited due to a lack of open paired image-report datasets. Here, we introduce BTReport, an open-source framework for brain tumor RRG that constructs natural language radiology reports using deterministically extracted imaging features. Unlike existing approaches that rely on large general-purpose or fine-tuned vision-language models for both image interpretation and report composition, BTReport performs deterministic feature extraction for image analysis and uses large language models only for syntactic structuring and narrative formatting. By separating RRG into a deterministic feature extraction step and a report generation step, the generated reports are completely interpretable and less prone to hallucinations. We show that the features used for report generation are predictive of key clinical outcomes, including survival and IDH mutation status, and reports generated by BTReport are more closely aligned with reference clinical reports than existing baselines for RRG. Finally, we introduce BTReport-BraTS, a companion dataset that augments BraTS imaging with synthetically generated radiology reports produced with BTReport. Code for this project can be found at  https://github.com/KurtLabUW/BTReport.

</details>


### [15] [MedProbCLIP: Probabilistic Adaptation of Vision-Language Foundation Model for Reliable Radiograph-Report Retrieval](https://arxiv.org/abs/2602.16019)
*Ahmad Elallaf,Yu Zhang,Yuktha Priya Masupalli,Jeong Yang,Young Lee,Zechun Cao,Gongbo Liang*

Main category: cs.CV

TL;DR: 提出了MedProbCLIP，一种用于胸部X光和放射学报告的概率型视觉-语言学习框架，在医学影像检索和表征学习中优于现有模型，并显著提升了模型的可靠性和安全性。


<details>
  <summary>Details</summary>
Motivation: 当前主流视觉-语言基础模型，如CLIP，虽然表现优异，但其确定性嵌入对于高风险医学领域并不可靠。因此，需要一种能表达不确定性、提高安全性的视觉-语言表征方法，用于医学影像诊断等严肃场景。

Method: MedProbCLIP将图像和文本表征建模为高斯分布嵌入，通过概率对比目标来显式捕捉图像与文本间的不确定性和多对多关系。同时引入变分信息瓶颈以减少过度自信预测；训练时采用多视角X光编码和多段报告编码提供细粒度监督，但推理时仅需一张影像和一份报告。

Result: 在MIMIC-CXR医学影像数据集上，MedProbCLIP在检索和零样本分类任务中优于当前主流的确定性与概率型模型（如CLIP、CXR-CLIP、PCME++），并在校准、风险覆盖、选择性检索可靠性和对临床相关干扰的鲁棒性方面表现更优。

Conclusion: 概率型视觉-语言建模显著提升了医学影像文本检索系统的可信度和安全性，MedProbCLIP为高风险医学领域中的多模态表征与应用提供了新思路。

Abstract: Vision-language foundation models have emerged as powerful general-purpose representation learners with strong potential for multimodal understanding, but their deterministic embeddings often fail to provide the reliability required for high-stakes biomedical applications. This work introduces MedProbCLIP, a probabilistic vision-language learning framework for chest X-ray and radiology report representation learning and bidirectional retrieval. MedProbCLIP models image and text representations as Gaussian embeddings through a probabilistic contrastive objective that explicitly captures uncertainty and many-to-many correspondences between radiographs and clinical narratives. A variational information bottleneck mitigates overconfident predictions, while MedProbCLIP employs multi-view radiograph encoding and multi-section report encoding during training to provide fine-grained supervision for clinically aligned correspondence, yet requires only a single radiograph and a single report at inference. Evaluated on the MIMIC-CXR dataset, MedProbCLIP outperforms deterministic and probabilistic baselines, including CLIP, CXR-CLIP, and PCME++, in both retrieval and zero-shot classification. Beyond accuracy, MedProbCLIP demonstrates superior calibration, risk-coverage behavior, selective retrieval reliability, and robustness to clinically relevant corruptions, underscoring the value of probabilistic vision-language modeling for improving the trustworthiness and safety of radiology image-text retrieval systems.

</details>


### [16] [LGQ: Learning Discretization Geometry for Scalable and Stable Image Tokenization](https://arxiv.org/abs/2602.16086)
*Idil Bilge Altun,Mert Onur Cakiroglu,Elham Buxton,Mehmet Dalkilic,Hasan Kurban*

Main category: cs.CV

TL;DR: 本文提出了一种新的可学习几何量化（LGQ）方法，用于高效且均衡的离散图像分词，通过端到端学习分词几何结构，有效解决了现有量化器利用率低、不稳定等问题，在ImageNet等任务中取得了优于主流方法的表现。


<details>
  <summary>Details</summary>
Motivation: 当前主流的离散图像分词方法在表示能力和利用率之间存在权衡。基于向量量化的分词器虽然几何结构灵活，但在词表变大时存在优化偏差、代码利用率低及崩溃等问题；结构化或固定量化器则存在容量分配低效的问题。因此，需要一种既能自适应学习几何结构，又能高效利用容量的分词方法。

Method: 提出Learnable Geometric Quantization（LGQ）方法，将硬性的最近邻量化替换为带温控的软分配，使训练过程可微，并在推理时恢复硬分配。通过引入峰值正则和全局利用率正则，在不依赖僵硬网格的情况下，实现了均衡的代码利用和表示，理论上可收敛到传统最近邻量化的效果。

Result: 在ImageNet等基准数据集以及多种词表规模下，LGQ方法实现了优化稳定和均衡利用。在词典规模16K时，相较FSQ指标提升11.88％，使用的活动代码减少近50％；比SimVQ提升6.06％，有效表示率降低近50％，以更少的活动词条实现了类似甚至更优的生成保真度。

Conclusion: LGQ在分词器词表利用率、训练稳定性和生成质量上，均优于现有主流方法，并且具备良好的可扩展性和适应不同统计特性的能力，在大规模视觉生成任务中具有实际应用前景。

Abstract: Discrete image tokenization is a key bottleneck for scalable visual generation: a tokenizer must remain compact for efficient latent-space priors while preserving semantic structure and using discrete capacity effectively. Existing quantizers face a trade-off: vector-quantized tokenizers learn flexible geometries but often suffer from biased straight-through optimization, codebook under-utilization, and representation collapse at large vocabularies. Structured scalar or implicit tokenizers ensure stable, near-complete utilization by design, yet rely on fixed discretization geometries that may allocate capacity inefficiently under heterogeneous latent statistics.
  We introduce Learnable Geometric Quantization (LGQ), a discrete image tokenizer that learns discretization geometry end-to-end. LGQ replaces hard nearest-neighbor lookup with temperature-controlled soft assignments, enabling fully differentiable training while recovering hard assignments at inference. The assignments correspond to posterior responsibilities of an isotropic Gaussian mixture and minimize a variational free-energy objective, provably converging to nearest-neighbor quantization in the low-temperature limit. LGQ combines a token-level peakedness regularizer with a global usage regularizer to encourage confident yet balanced code utilization without imposing rigid grids.
  Under a controlled VQGAN-style backbone on ImageNet across multiple vocabulary sizes, LGQ achieves stable optimization and balanced utilization. At 16K codebook size, LGQ improves rFID by 11.88% over FSQ while using 49.96% fewer active codes, and improves rFID by 6.06% over SimVQ with 49.45% lower effective representation rate, achieving comparable fidelity with substantially fewer active entries. Our GitHub repository is available at: https://github.com/KurbanIntelligenceLab/LGQ

</details>


### [17] [OmniCT: Towards a Unified Slice-Volume LVLM for Comprehensive CT Analysis](https://arxiv.org/abs/2602.16110)
*Tianwei Lin,Zhongwei Qiu,Wenqiao Zhang,Jiang Liu,Yihan Xie,Mingjian Gao,Zhenxuan Fan,Zhaocheng Li,Sijing Li,Zhongle Xie,Peng LU,Yueting Zhuang,Yingda Xia,Ling Zhang,Beng Chin Ooi*

Main category: cs.CV

TL;DR: 本文提出了一种统一切片与体积理解的CT影像大规模视觉语言模型OmniCT，实现了单一模型在细节与空间推理方面的优异性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型（LVLMs）在CT影像理解上切片和体积建模分裂，无法同时兼顾局部细节（如小结节、边界）与体积空间关系（如肿瘤扩散、器官关系），制约了医疗AI的临床应用。

Method: OmniCT提出三大技术创新：（1）空间一致性增强（SCE）：结合体积切片组合与三轴位置嵌入，加入MoE混合投影机制，实现高效切片-体积适配；（2）器官级语义增强（OSE）：通过分割和感兴趣区（ROI）定位，突出病灶与器官级语义对齐；（3）MedEval-CT：构建最大规模的切片-体积CT数据集与评测基准，整合多维度指标进行统一评估。

Result: OmniCT在多个临床任务和评测中，显著优于现有技术，实现了对微观细节和宏观空间推理的兼顾。

Conclusion: OmniCT开创了跨模态医学影像理解的新范式，可大幅提升CT临床AI的准确性与适用性。

Abstract: Computed Tomography (CT) is one of the most widely used and diagnostically information-dense imaging modalities, covering critical organs such as the heart, lungs, liver, and colon. Clinical interpretation relies on both slice-driven local features (e.g., sub-centimeter nodules, lesion boundaries) and volume-driven spatial representations (e.g., tumor infiltration, inter-organ anatomical relations). However, existing Large Vision-Language Models (LVLMs) remain fragmented in CT slice versus volumetric understanding: slice-driven LVLMs show strong generalization but lack cross-slice spatial consistency, while volume-driven LVLMs explicitly capture volumetric semantics but suffer from coarse granularity and poor compatibility with slice inputs. The absence of a unified modeling paradigm constitutes a major bottleneck for the clinical translation of medical LVLMs. We present OmniCT, a powerful unified slice-volume LVLM for CT scenarios, which makes three contributions: (i) Spatial Consistency Enhancement (SCE): volumetric slice composition combined with tri-axial positional embedding that introduces volumetric consistency, and an MoE hybrid projection enables efficient slice-volume adaptation; (ii) Organ-level Semantic Enhancement (OSE): segmentation and ROI localization explicitly align anatomical regions, emphasizing lesion- and organ-level semantics; (iii) MedEval-CT: the largest slice-volume CT dataset and hybrid benchmark integrates comprehensive metrics for unified evaluation. OmniCT consistently outperforms existing methods with a substantial margin across diverse clinical tasks and satisfies both micro-level detail sensitivity and macro-level spatial reasoning. More importantly, it establishes a new paradigm for cross-modal medical imaging understanding.

</details>


### [18] [CHAI: CacHe Attention Inference for text2video](https://arxiv.org/abs/2602.16132)
*Joel Mathew Cherian,Ashutosh Muralidhara Bharadwaj,Vima Gupta,Anand Padmanabha Iyer*

Main category: cs.CV

TL;DR: CHAI提出了一种缓存机制（Cache Attention），通过跨推理缓存，显著提升文本生成视频扩散模型的推理速度，并保持视频质量。


<details>
  <summary>Details</summary>
Motivation: 现有文本生成视频的扩散模型推理速度慢，现有提速方法要么需要昂贵的模型重训，要么牺牲视频质量，本工作旨在解决这一矛盾。

Method: 提出CHAI框架，核心是Cache Attention机制，实现跨推理缓存和选择性关注共享物体/场景，使得系统能高效重复利用缓存数据，在少量去噪步骤下仍生成高质量视频。

Result: 实现了只需8步去噪即可生成高质量视频，集成后系统比OpenSora 1.2快1.65-3.35倍，且维持了画面质量。

Conclusion: CHAI通过Cache Attention显著提升了文本生成视频模型的推理效率，无需模型重训或显著降低视频质量，可用于加速现有扩散模型。

Abstract: Text-to-video diffusion models deliver impressive results but remain slow because of the sequential denoising of 3D latents. Existing approaches to speed up inference either require expensive model retraining or use heuristic-based step skipping, which struggles to maintain video quality as the number of denoising steps decreases. Our work, CHAI, aims to use cross-inference caching to reduce latency while maintaining video quality. We introduce Cache Attention as an effective method for attending to shared objects/scenes across cross-inference latents. This selective attention mechanism enables effective reuse of cached latents across semantically related prompts, yielding high cache hit rates. We show that it is possible to generate high-quality videos using Cache Attention with as few as 8 denoising steps. When integrated into the overall system, CHAI is 1.65x - 3.35x faster than baseline OpenSora 1.2 while maintaining video quality.

</details>


### [19] [IRIS: Intent Resolution via Inference-time Saccades for Open-Ended VQA in Large Vision-Language Models](https://arxiv.org/abs/2602.16138)
*Parsa Madinei,Srijita Karmakar,Russell Cohen Hoffing,Felix Gervitz,Miguel P. Eckstein*

Main category: cs.CV

TL;DR: 本论文提出了一种新的无需训练的方法IRIS，利用实时眼动追踪数据，提高了开放式视觉问答（VQA）中处理歧义问题的准确率。


<details>
  <summary>Details</summary>
Motivation: 当前大规模视觉语言模型（VLMs）在面对歧义性视觉问答时存在理解障碍，人工解释较为模糊，如何有效利用用户的行为信号辅助模型理解其意图成为亟需解决的问题。

Method: 作者提出了IRIS方法，通过实时眼动追踪，在用户开始提问时捕捉其注视点，利用这些注视数据在推理阶段帮助VLMs更准确理解用户意图，从而提升对歧义性问题的回答。该方法无需额外训练，并在500对图片-问题数据上进行广泛用户研究。

Result: IRIS方法将VLMs在歧义问题上的准确率从35.2%提升到77.2%，并且在无歧义问题上的表现未受影响。该方法在多种主流VLM架构下均能带来稳定提升。

Conclusion: 引入用户眼动追踪数据可以显著提升视觉问答系统对歧义问题的理解与处理能力，作者还发布了相关数据集、协议和评测工具，为今后该领域研究提供了重要资源。

Abstract: We introduce IRIS (Intent Resolution via Inference-time Saccades), a novel training-free approach that uses eye-tracking data in real-time to resolve ambiguity in open-ended VQA. Through a comprehensive user study with 500 unique image-question pairs, we demonstrate that fixations closest to the time participants start verbally asking their questions are the most informative for disambiguation in Large VLMs, more than doubling the accuracy of responses on ambiguous questions (from 35.2% to 77.2%) while maintaining performance on unambiguous queries. We evaluate our approach across state-of-the-art VLMs, showing consistent improvements when gaze data is incorporated in ambiguous image-question pairs, regardless of architectural differences. We release a new benchmark dataset to use eye movement data for disambiguated VQA, a novel real-time interactive protocol, and an evaluation suite.

</details>


### [20] [Evaluating Demographic Misrepresentation in Image-to-Image Portrait Editing](https://arxiv.org/abs/2602.16149)
*Huichan Seo,Minki Hong,Sieun Choi,Jihie Kim,Jean Oh*

Main category: cs.CV

TL;DR: 本文探讨了在基于指令的图像编辑任务中，编辑结果因人口统计学属性（如种族、性别、年龄）而出现系统性差异的问题，并提出了两种主要失败模式。作者还开发了相关基准和评估方法，发现当前主流图像编辑器在身份保持方面普遍存在、且具有人口属性不均等的问题，并探索了缓解策略。


<details>
  <summary>Details</summary>
Motivation: 虽然文本生成图像（T2I）的群体偏见已被广泛研究，但针对基于指令的图像编辑（I2I）在人口属性条件下的失效与偏见还未被充分探索。考虑到实际应用中，保护各类人群形象公平性至关重要，因此有必要系统分析I2I编辑中的此类失效现象。

Method: 作者提出两个失败模式——软抹除（编辑效果被无声削弱或忽略）与刻板替换（编辑结果引入未请求、符合刻板印象的属性），并建立了涵盖种族、性别、年龄的受控基准，通过诊断型指令集生成与编辑肖像，结合视觉-语言模型打分和人工评估，对多个主流开放模型的I2I编辑器进行了系统测试。

Result: 实验证明，不同人口统计学群体在身份保持上存在普遍及不均等的编辑失效。个别编辑器容易根据社会隐性预设（如利用职业类提示自动推断性别）产生群体性差异。作者同时提出，通过在编辑指令中增加身份保护约束（无需模型本身改动），能有效减轻少数群体画像的身份扰动，但对多数群体影响不大，进一步揭示了主流模型中潜在的身份先验不对称性。

Conclusion: 作者确立了身份保持失败作为I2I编辑中心且带有群体偏见的主要问题，并强调需研发具有人口属性鲁棒性的公平编辑系统。

Abstract: Demographic bias in text-to-image (T2I) generation is well studied, yet demographic-conditioned failures in instruction-guided image-to-image (I2I) editing remain underexplored. We examine whether identical edit instructions yield systematically different outcomes across subject demographics in open-weight I2I editors. We formalize two failure modes: Soft Erasure, where edits are silently weakened or ignored in the output image, and Stereotype Replacement, where edits introduce unrequested, stereotype-consistent attributes. We introduce a controlled benchmark that probes demographic-conditioned behavior by generating and editing portraits conditioned on race, gender, and age using a diagnostic prompt set, and evaluate multiple editors with vision-language model (VLM) scoring and human evaluation. Our analysis shows that identity preservation failures are pervasive, demographically uneven, and shaped by implicit social priors, including occupation-driven gender inference. Finally, we demonstrate that a prompt-level identity constraint, without model updates, can substantially reduce demographic change for minority groups while leaving majority-group portraits largely unchanged, revealing asymmetric identity priors in current editors. Together, our findings establish identity preservation as a central and demographically uneven failure mode in I2I editing and motivate demographic-robust editing systems. Project page: https://seochan99.github.io/i2i-demographic-bias

</details>


### [21] [Uncertainty-Guided Inference-Time Depth Adaptation for Transformer-Based Visual Tracking](https://arxiv.org/abs/2602.16160)
*Patrick Poggi,Divake Kumar,Theja Tulabandhula,Amit Ranjan Trivedi*

Main category: cs.CV

TL;DR: 本论文提出了一种名为UncL-STARK的方法，使Transformer目标跟踪器能够根据不确定性动态调整模型深度，从而在保证精度的同时减少不必要的计算开销。实验表明，该方法能显著降低计算量和能耗，同时几乎不损失精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的单目标跟踪方法虽然精度高，但在处理时长视频、帧间差异不大时总是全深度推理，导致大量不必要的计算和能耗浪费。迫切需要一种既能灵活调整模型深度，又不影响跟踪精度的方法。

Method: 1. 采用随机深度训练和知识蒸馏，使模型能在不同中间深度都保持稳健性。2. 在推理时，根据模型输出的角点定位热图，直接估计不确定性，并以此作为反馈，动态决定下一帧使用的网络深度。3. 该方法不改变原有网络结构，也无需额外网络头。

Result: 在GOT-10k和LaSOT基准上实验，UncL-STARK最大可减少12%的GFLOPs、8.9%的延迟和10.8%的能耗，同时跟踪精度仅比全深度模型低0.2%。短期和长期跟踪均表现出优势。

Conclusion: UncL-STARK能够在不牺牲跟踪精度的前提下，动态降低Transformer跟踪器的推理深度，显著优化计算与能耗开销，适用于长视频场景。

Abstract: Transformer-based single-object trackers achieve state-of-the-art accuracy but rely on fixed-depth inference, executing the full encoder--decoder stack for every frame regardless of visual complexity, thereby incurring unnecessary computational cost in long video sequences dominated by temporally coherent frames. We propose UncL-STARK, an architecture-preserving approach that enables dynamic, uncertainty-aware depth adaptation in transformer-based trackers without modifying the underlying network or adding auxiliary heads. The model is fine-tuned to retain predictive robustness at multiple intermediate depths using random-depth training with knowledge distillation, thus enabling safe inference-time truncation. At runtime, we derive a lightweight uncertainty estimate directly from the model's corner localization heatmaps and use it in a feedback-driven policy that selects the encoder and decoder depth for the next frame based on the prediction confidence by exploiting temporal coherence in video. Extensive experiments on GOT-10k and LaSOT demonstrate up to 12\% GFLOPs reduction, 8.9\% latency reduction, and 10.8\% energy savings while maintaining tracking accuracy within 0.2\% of the full-depth baseline across both short-term and long-term sequences.

</details>


### [22] [DataCube: A Video Retrieval Platform via Natural Language Semantic Profiling](https://arxiv.org/abs/2602.16231)
*Yiming Ju,Hanyu Zhao,Quanyue Ma,Donglin Hao,Chengwei Wu,Ming Li,Songjing Wang,Tengfei Pan*

Main category: cs.CV

TL;DR: DataCube是一个智能视频处理平台，能自动处理、分析、构建和检索大规模视频数据，极大提升视频数据的获取与利用效率。


<details>
  <summary>Details</summary>
Motivation: 随着大规模视频内容的爆发，如何高效地从原始视频中构建高质量、任务相关的数据集变得尤为重要，但人工处理过程成本高且低效。该工作旨在解决视频数据处理、表达和检索的自动化与智能化难题。

Method: 提出了DataCube平台：1）自动对视频进行语义结构化处理和多维分析；2）利用神经网络实现混合检索，包括神经重排序和深度语义匹配；3）提供可交互的Web界面，方便用户自定义筛选和构建所需视频集合；4）支持私有视频库的搜索能力。

Result: 平台实现了自动化、高效、多维度的视频数据处理与检索，支持从大规模视频库高效构建定制化数据子集，并已上线公开可访问，用户体验与效果有一定实际展示。

Conclusion: DataCube大幅降低了视频数据处理和检索的成本，提高了效率，为视频理解和生成等任务的数据准备提供了有力基础。平台的公测进一步验证其实用价值。

Abstract: Large-scale video repositories are increasingly available for modern video understanding and generation tasks. However, transforming raw videos into high-quality, task-specific datasets remains costly and inefficient. We present DataCube, an intelligent platform for automatic video processing, multi-dimensional profiling, and query-driven retrieval. DataCube constructs structured semantic representations of video clips and supports hybrid retrieval with neural re-ranking and deep semantic matching. Through an interactive web interface, users can efficiently construct customized video subsets from massive repositories for training, analysis, and evaluation, and build searchable systems over their own private video collections. The system is publicly accessible at https://datacube.baai.ac.cn/. Demo Video: https://baai-data-cube.ks3-cn-beijing.ksyuncs.com/custom/Adobe%20Express%20-%202%E6%9C%8818%E6%97%A5%20%281%29%281%29%20%281%29.mp4

</details>


### [23] [EasyControlEdge: A Foundation-Model Fine-Tuning for Edge Detection](https://arxiv.org/abs/2602.16238)
*Hiroki Nakamura,Hiroto Iino,Masashi Okada,Tadahiro Taniguchi*

Main category: cs.CV

TL;DR: 本文提出了EasyControlEdge方法，将图像生成基础模型应用于边缘检测领域，实现了更高的清晰度和数据效率，尤其在样本有限时优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有边缘检测任务，尤其是在实际应用如楼层平面图、卫星道路/建筑和医学器官边界中，要求边缘输出既清晰又能在数据少的情况下有效。传统方法难以在有限训练样本下生成高质量边缘图，而图像生成基础模型虽然在下游任务表现良好，但其预训练先验和高频细节迭代能力未被充分利用。

Method: 通过设计EasyControlEdge框架，专门适配图像生成基础模型用于边缘检测，增强了模型在边缘检测任务中的能力。方法中结合了以边缘为导向的目标函数和高效的像素空间损失。在推理阶段，引入基于无条件动态的引导机制，仅用一个模型即可通过引导尺度控制边缘密度。

Result: 在BSDS500、NYUDv2、BIPED和CubiCasa四个数据集上的实验表明，EasyControlEdge在无需后处理的情况下、以及训练数据有限场景下，对比SOTA方法均取得了更优质更清晰的边缘检测效果。

Conclusion: EasyControlEdge能够高效地迁移并精细提升图像生成基础模型在边缘检测任务上的性能，尤其在数据有限和对边缘清晰度要求高的实际场景下，显示出明显优势。

Abstract: We propose EasyControlEdge, adapting an image-generation foundation model to edge detection. In real-world edge detection (e.g., floor-plan walls, satellite roads/buildings, and medical organ boundaries), crispness and data efficiency are crucial, yet producing crisp raw edge maps with limited training samples remains challenging. Although image-generation foundation models perform well on many downstream tasks, their pretrained priors for data-efficient transfer and iterative refinement for high-frequency detail preservation remain underexploited for edge detection. To enable crisp and data-efficient edge detection using these capabilities, we introduce an edge-specialized adaptation of image-generation foundation models. To better specialize the foundation model for edge detection, we incorporate an edge-oriented objective with an efficient pixel-space loss. At inference, we introduce guidance based on unconditional dynamics, enabling a single model to control the edge density through a guidance scale. Experiments on BSDS500, NYUDv2, BIPED, and CubiCasa compare against state-of-the-art methods and show consistent gains, particularly under no-post-processing crispness evaluation and with limited training data.

</details>


### [24] [HyPCA-Net: Advancing Multimodal Fusion in Medical Image Analysis](https://arxiv.org/abs/2602.16245)
*J. Dhar,M. K. Pandey,D. Chakladar,M. Haghighat,A. Alavi,S. Mistry,N. Zaidi*

Main category: cs.CV

TL;DR: 该论文提出了一种高效的新型多模态医学影像融合网络HyPCA-Net，在十个公开数据集上测试表现优异，兼顾性能提升和计算资源节省。


<details>
  <summary>Details</summary>
Motivation: 现有多模态影像融合方法虽然在医学诊断上很有潜力，但计算开销大，不适合低资源环境，而且级联注意力机制导致信息流失，限制了跨疾病诊断的泛化能力。

Method: 作者提出HyPCA-Net，包含两个创新模块：高效的残差自适应学习注意力块（捕获精细的模态特异性信息）和双视角级联注意力块（学习多模态间共享的鲁棒表示）。这种结构并行高效，降低了信息损失风险。

Result: 在十个公开医学数据集上的实验显示，HyPCA-Net平均优于现有先进方法，性能最高提升5.2%，计算量最多下降73.1%。

Conclusion: HyPCA-Net不仅大幅提升多疾病诊断多模态分析的效果，还极大减少了计算资源消耗，适用于低资源环境，具备推广和实际应用价值。

Abstract: Multimodal fusion frameworks, which integrate diverse medical imaging modalities (e.g., MRI, CT), have shown great potential in applications such as skin cancer detection, dementia diagnosis, and brain tumor prediction. However, existing multimodal fusion methods face significant challenges. First, they often rely on computationally expensive models, limiting their applicability in low-resource environments. Second, they often employ cascaded attention modules, which potentially increase risk of information loss during inter-module transitions and hinder their capacity to effectively capture robust shared representations across modalities. This restricts their generalization in multi-disease analysis tasks. To address these limitations, we propose a Hybrid Parallel-Fusion Cascaded Attention Network (HyPCA-Net), composed of two core novel blocks: (a) a computationally efficient residual adaptive learning attention block for capturing refined modality-specific representations, and (b) a dual-view cascaded attention block aimed at learning robust shared representations across diverse modalities. Extensive experiments on ten publicly available datasets exhibit that HyPCA-Net significantly outperforms existing leading methods, with improvements of up to 5.2% in performance and reductions of up to 73.1% in computational cost. Code: https://github.com/misti1203/HyPCA-Net.

</details>


### [25] [AFFMAE: Scalable and Efficient Vision Pretraining for Desktop Graphics Cards](https://arxiv.org/abs/2602.16249)
*David Smerkous,Zian Wang,Behzad Najafian*

Main category: cs.CV

TL;DR: 本文提出AFFMAE，一种适用于高分辨率视觉任务的高效自监督预训练框架，能够显著减少算力需求，方便中小型实验室开展高分辨率模型研究。


<details>
  <summary>Details</summary>
Motivation: 传统的自监督预训练（如MAE）虽然数据高效，但在高分辨率训练下需要庞大服务器资源，严重阻碍实验室级别自主发展视觉基础模型。MAE等方法在与分层下采样结构结合时也存在结构上的挑战。

Method: 作者提出AFFMAE框架，利用自适应离网Token合并策略。具体做法是在预训练时丢弃被mask的Token，只对可见Token进行动态合并，从而摆脱了稠密网格结构要求，同时保持分层计算的可扩展性。实现过程中包括了高效且数值稳定的Flash风格聚类注意力核，并利用深层监督缓解稀疏阶段的表达坍缩问题。

Result: 在高分辨率电子显微镜分割任务中，AFFMAE在相同参数规模下达到与ViT-MAE相似性能，但算力消耗（FLOPs）降低7倍，显存占用减半，且能在一块RTX 5090上更快完成训练。

Conclusion: AFFMAE显著优化了高分辨率视觉任务的自监督预训练资源消耗，使得高效分层视觉基础模型的训练变得更加可行，降低了高分辨率模型开发的门槛。

Abstract: Self-supervised pretraining has transformed computer vision by enabling data-efficient fine-tuning, yet high-resolution training typically requires server-scale infrastructure, limiting in-domain foundation model development for many research laboratories. Masked Autoencoders (MAE) reduce computation by encoding only visible tokens, but combining MAE with hierarchical downsampling architectures remains structurally challenging due to dense grid priors and mask-aware design compromises. We introduce AFFMAE, a masking-friendly hierarchical pretraining framework built on adaptive, off-grid token merging. By discarding masked tokens and performing dynamic merging exclusively over visible tokens, AFFMAE removes dense-grid assumptions while preserving hierarchical scalability. We developed numerically stable mixed-precision Flash-style cluster attention kernels, and mitigate sparse-stage representation collapse via deep supervision. On high-resolution electron microscopy segmentation, AFFMAE matches ViT-MAE performance at equal parameter count while reducing FLOPs by up to 7x, halving memory usage, and achieving faster training on a single RTX 5090. Code available at https://github.com/najafian-lab/affmae.

</details>


### [26] [Breaking the Sub-Millimeter Barrier: Eyeframe Acquisition from Color Images](https://arxiv.org/abs/2602.16281)
*Manel Guzmán,Antonio Agudo*

Main category: cs.CV

TL;DR: 本文提出了一种基于人工视觉的新型镜框轮廓追踪算法，用于提升眼镜行业镜片加工的效率与精度。


<details>
  <summary>Details</summary>
Motivation: 目前传统机械镜框追踪方式需要精密校准和特殊器械，流程复杂且耗时，对验光师和技师的工作造成效率瓶颈，因此亟需更高效简便的替代方案。

Method: 该研究利用InVision系统采集多视角图像，先通过图像分割剔除背景，获得镜框区域，再进行深度估算获取三维信息，最后融合RGB与深度数据以精确测量镜框轮廓。文中还分析了多种算法配置和变体，并在真实数据集上进行了对比测试。

Result: 基于多视角采集和深度信息融合的算法在静态彩色图像下获得了与主流方法相媲美的精度，同时避免了专用设备的需求，展现出较强的适用性和简化流程的优势。

Conclusion: 该方法显著简化眼镜加工的追踪流程，降低了技能门槛和设备投入，有助于提升光学行业的加工效率和质量，是对传统方法的有效创新替代。

Abstract: Eyeframe lens tracing is an important process in the optical industry that requires sub-millimeter precision to ensure proper lens fitting and optimal vision correction. Traditional frame tracers rely on mechanical tools that need precise positioning and calibration, which are time-consuming and require additional equipment, creating an inefficient workflow for opticians. This work presents a novel approach based on artificial vision that utilizes multi-view information. The proposed algorithm operates on images captured from an InVision system. The full pipeline includes image acquisition, frame segmentation to isolate the eyeframe from background, depth estimation to obtain 3D spatial information, and multi-view processing that integrates segmented RGB images with depth data for precise frame contour measurement. To this end, different configurations and variants are proposed and analyzed on real data, providing competitive measurements from still color images with respect to other solutions, while eliminating the need for specialized tracing equipment and reducing workflow complexity for optical technicians.

</details>


### [27] [A Self-Supervised Approach for Enhanced Feature Representations in Object Detection Tasks](https://arxiv.org/abs/2602.16322)
*Santiago C. Vilabella,Pablo Pérez-Núñez,Beatriz Remeseiro*

Main category: cs.CV

TL;DR: 本文提出通过提升特征提取器能力，可以在减少标注数据情况下提升目标检测模型表现，采用自监督学习策略，在无标签数据上训练模型，结果优于现有ImageNet预训练特征提取器。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型复杂度和规模持续上升，但高质量标注数据稀缺且获取成本高，尤其是在目标检测等领域。为缓解数据标注瓶颈，急需寻找减少对大量标注数据依赖的方法。

Method: 采用自监督学习策略，在大量无标签数据上训练特征提取器，强化模型对物体关键结构信息的关注，并与ImageNet预训练特征提取器在目标检测任务上作对比。

Result: 提出的自监督训练的特征提取器优于主流的ImageNet预训练提取器，模型对物体关键特征更敏感，特征表达更有效。

Conclusion: 通过改进特征提取器并采用自监督学习，可显著降低对标注数据量的依赖，同时提升目标检测模型在特征表达、准确性和鲁棒性方面的表现。

Abstract: In the fast-evolving field of artificial intelligence, where models are increasingly growing in complexity and size, the availability of labeled data for training deep learning models has become a significant challenge. Addressing complex problems like object detection demands considerable time and resources for data labeling to achieve meaningful results. For companies developing such applications, this entails extensive investment in highly skilled personnel or costly outsourcing. This research work aims to demonstrate that enhancing feature extractors can substantially alleviate this challenge, enabling models to learn more effective representations with less labeled data. Utilizing a self-supervised learning strategy, we present a model trained on unlabeled data that outperforms state-of-the-art feature extractors pre-trained on ImageNet and particularly designed for object detection tasks. Moreover, the results demonstrate that our approach encourages the model to focus on the most relevant aspects of an object, thus achieving better feature representations and, therefore, reinforcing its reliability and robustness.

</details>


### [28] [Subtractive Modulative Network with Learnable Periodic Activations](https://arxiv.org/abs/2602.16337)
*Tiou Wang,Zhuoqian Yang,Markus Flierl,Mathieu Salzmann,Sabine Süsstrunk*

Main category: cs.CV

TL;DR: 提出了一种新型、高效的神经隐式表示架构SMN，能以更少的参数实现图像和3D重建任务的高性能。


<details>
  <summary>Details</summary>
Motivation: 现有的隐式神经表示方法在参数效率和表达能力之间存在权衡。本研究动机是希望设计出结构更简单、参数更少，但重建性能依然强大的INR模型。

Method: 借鉴传统减法合成思想，提出Subtractive Modulative Network（SMN），包括一个可学习的周期激活层生成多频基底，以及一系列调制掩码模块生成高阶谐波，形成有效信号处理流程，并给出理论分析和实证结果。

Result: 在两个图像数据集上，SMN的PSNR超过40dB，参数效率和重建精度均优于现有SOTA方法，并在3D新视角合成任务上表现出持续优势。

Conclusion: SMN结构新颖、参数高效，并能在图像和三维任务中表现出优越性能，是隐式神经表示领域的有力竞争方案。

Abstract: We propose the Subtractive Modulative Network (SMN), a novel, parameter-efficient Implicit Neural Representation (INR) architecture inspired by classical subtractive synthesis. The SMN is designed as a principled signal processing pipeline, featuring a learnable periodic activation layer (Oscillator) that generates a multi-frequency basis, and a series of modulative mask modules (Filters) that actively generate high-order harmonics. We provide both theoretical analysis and empirical validation for our design. Our SMN achieves a PSNR of $40+$ dB on two image datasets, comparing favorably against state-of-the-art methods in terms of both reconstruction accuracy and parameter efficiency. Furthermore, consistent advantage is observed on the challenging 3D NeRF novel view synthesis task. Supplementary materials are available at https://inrainbws.github.io/smn/.

</details>


### [29] [SCAR: Satellite Imagery-Based Calibration for Aerial Recordings](https://arxiv.org/abs/2602.16349)
*Henry Hölzemann,Michael Schleiss*

Main category: cs.CV

TL;DR: 提出了一种利用卫星影像辅助长期自动校准空中视觉-惯性系统的新方法SCAR，显著提升了无人工干预下的定位与姿态精度。


<details>
  <summary>Details</summary>
Motivation: 空中视觉-惯性系统在长期部署过程中常因环境变化、设备老化等，导致校准参数(内参和外参)逐渐退化。现有方法多依赖专门的校准动作或人工布设控制点，成本高且不适宜自动化与大规模应用。因此，急需一种无需人工干预、可自适应环境变化的长期校准方法。

Method: 提出SCAR方法，利用公开的正射影像和高程模型构建2D-3D对应，通过将无人机采集的航空影像与地理参照的卫星图像对齐，实现系统内参和外参的自动估计与精化。全流程不依赖人工现场辅助，能适用于常规飞行场景。

Result: 在六次覆盖两年、不同时节与环境大规模航测任务上的实验显示，SCAR在所有序列上都显著优于Kalibr、COLMAP和VINS-Mono等主流校准方案，降低了中值重投影误差，并大幅提升了姿态估计精度与定位准确率。

Conclusion: SCAR无需人工干预即可为空中视觉-惯性系统带来准确、稳健且可复现的长期自校准能力，对提升野外无人机/航测等大规模无人系统的实用性与可靠性有重要意义。

Abstract: We introduce SCAR, a method for long-term auto-calibration refinement of aerial visual-inertial systems that exploits georeferenced satellite imagery as a persistent global reference. SCAR estimates both intrinsic and extrinsic parameters by aligning aerial images with 2D--3D correspondences derived from publicly available orthophotos and elevation models. In contrast to existing approaches that rely on dedicated calibration maneuvers or manually surveyed ground control points, our method leverages external geospatial data to detect and correct calibration degradation under field deployment conditions. We evaluate our approach on six large-scale aerial campaigns conducted over two years under diverse seasonal and environmental conditions. Across all sequences, SCAR consistently outperforms established baselines (Kalibr, COLMAP, VINS-Mono), reducing median reprojection error by a large margin, and translating these calibration gains into substantially lower visual localization rotation errors and higher pose accuracy. These results demonstrate that SCAR provides accurate, robust, and reproducible calibration over long-term aerial operations without the need for manual intervention.

</details>


### [30] [Parameter-Free Adaptive Multi-Scale Channel-Spatial Attention Aggregation framework for 3D Indoor Semantic Scene Completion Toward Assisting Visually Impaired](https://arxiv.org/abs/2602.16385)
*Qi He,XiangXiang Wang,Jingtao Zhang,Yongbin Yu,Hongxiang Chu,Manping Fan,JingYe Cai,Zhenglin Yang*

Main category: cs.CV

TL;DR: 这篇论文提出了一种适用于单目视觉下室内辅助感知的自适应多尺度注意力聚合（AMAA）框架，提升了3D语义场景补全的准确性和部署鲁棒性，对视觉障碍用户更安全友好。


<details>
  <summary>Details</summary>
Motivation: 目前单目3D语义场景补全（SSC）方法在2D到3D投影及多尺度特征融合环节缺乏对体素特征可靠性和信息传播的有效建模，容易造成特征扩散和混淆，从而影响结构稳定性。这对需要高安全性的视觉障碍用户场景尤为关键。

Method: 论文提出AMAA框架，在MonoScene 基础上倾向于对特征可靠性进行调控。具体包括通过并行通道-空间注意力机制联合校准提升体素特征的语义和空间维度表现，并引入分层自适应特征门控策略，对多尺度信息注入进行调控，防止信息扰乱。

Result: 在NYUv2基准测试集上，AMAA在不显著增加系统复杂度的前提下，相比MonoScene分别提升了0.31%的SSC mIoU（至27.25%）和0.59%的SC IoU（至43.10%）。同时在NVIDIA Jetson嵌入式硬件平台上具备良好的运行稳定性。

Conclusion: AMAA显著提升了单目SSC的质量和结构鲁棒性，且便于嵌入式系统部署，为面向视觉障碍者的室内辅助感知系统提供了更可靠的技术方案。

Abstract: In indoor assistive perception for visually impaired users, 3D Semantic Scene Completion (SSC) is expected to provide structurally coherent and semantically consistent occupancy under strictly monocular vision for safety-critical scene understanding. However, existing monocular SSC approaches often lack explicit modeling of voxel-feature reliability and regulated cross-scale information propagation during 2D-3D projection and multi-scale fusion, making them vulnerable to projection diffusion and feature entanglement and thus limiting structural stability.To address these challenges, this paper presents an Adaptive Multi-scale Attention Aggregation (AMAA) framework built upon the MonoScene pipeline. Rather than introducing a heavier backbone, AMAA focuses on reliability-oriented feature regulation within a monocular SSC framework. Specifically, lifted voxel features are jointly calibrated in semantic and spatial dimensions through parallel channel-spatial attention aggregation, while multi-scale encoder-decoder fusion is stabilized via a hierarchical adaptive feature-gating strategy that regulates information injection across scales.Experiments on the NYUv2 benchmark demonstrate consistent improvements over MonoScene without significantly increasing system complexity: AMAA achieves 27.25% SSC mIoU (+0.31) and 43.10% SC IoU (+0.59). In addition, system-level deployment on an NVIDIA Jetson platform verifies that the complete AMAA framework can be executed stably on embedded hardware. Overall, AMAA improves monocular SSC quality and provides a reliable and deployable perception framework for indoor assistive systems targeting visually impaired users.

</details>


### [31] [ReMoRa: Multimodal Large Language Model based on Refined Motion Representation for Long-Video Understanding](https://arxiv.org/abs/2602.16412)
*Daichi Yashima,Shuhei Kurita,Yusuke Oda,Komei Sugiura*

Main category: cs.CV

TL;DR: 本论文提出了一种名为ReMoRa的视频多模态大语言模型，能够在不依赖完整RGB帧序列的情况下，有效理解和处理长视频内容。


<details>
  <summary>Details</summary>
Motivation: 近年来多模态大语言模型取得显著进展，但对于长视频的高效理解仍然困难，主要因为处理完整RGB帧序列计算量大且冗余。解决长视频理解的计算瓶颈和信息冗余，是推动该领域发展的关键问题。

Method: 论文提出ReMoRa方法：仅保留稀疏RGB关键帧，并用压缩表示（特别是运动信息）替代全序列RGB帧，将运动编码视为光流的紧凑代理。为提升运动表示精度，引入去噪与细化模块。此外，ReMoRa整体特征提取和处理的复杂度随序列线性增长，显著提升计算效率。

Result: ReMoRa在多个长视频理解基准上进行了大量实验，结果显示其在LongVideoBench、NExT-QA、MLVU等数据集上均优于现有方法，表现出更好的视频理解能力和效率。

Conclusion: ReMoRa首次实现在长视频场景下兼顾效率与高性能的多模态大模型，用于视频理解任务，推动了长视频智能分析技术的发展。

Abstract: While multimodal large language models (MLLMs) have shown remarkable success across a wide range of tasks, long-form video understanding remains a significant challenge. In this study, we focus on video understanding by MLLMs. This task is challenging because processing a full stream of RGB frames is computationally intractable and highly redundant, as self-attention have quadratic complexity with sequence length. In this paper, we propose ReMoRa, a video MLLM that processes videos by operating directly on their compressed representations. A sparse set of RGB keyframes is retained for appearance, while temporal dynamics are encoded as a motion representation, removing the need for sequential RGB frames. These motion representations act as a compact proxy for optical flow, capturing temporal dynamics without full frame decoding. To refine the noise and low fidelity of block-based motions, we introduce a module to denoise and generate a fine-grained motion representation. Furthermore, our model compresses these features in a way that scales linearly with sequence length. We demonstrate the effectiveness of ReMoRa through extensive experiments across a comprehensive suite of long-video understanding benchmarks. ReMoRa outperformed baseline methods on multiple challenging benchmarks, including LongVideoBench, NExT-QA, and MLVU.

</details>


### [32] [Designing Production-Scale OCR for India: Multilingual and Domain-Specific Systems](https://arxiv.org/abs/2602.16430)
*Ali Faraz,Raja Kolla,Ashish Kulkarni,Shubham Agarwal*

Main category: cs.CV

TL;DR: 本文研究了在印度多语言环境下，如何用视觉-语言模型有效构建高效的OCR系统，并提出两种训练策略，对比性能与部署优势。


<details>
  <summary>Details</summary>
Motivation: 印度存在极高的语言多样性和文档异质性，同时OCR系统部署还面临时延和算力等实际限制。因此亟需研究既能处理多语种，又可高效部署的新型OCR方案。

Method: 提出两种训练策略：一种是用通用视觉编码器和多语种语言模型端到端训练，一种是微调已有OCR模型，即使原模型未针对目标语言训练。此外，开发了专门针对印度政府文档字段提取的Parichay系列OCR模型。

Result: 第二种微调策略在准确率与推理时延之间取得更优权衡，Chitrapathak-2速度提升3-6倍，在泰卢固语上达SOTA效果，在其它语种也表现优异。Parichay系列OCR在9种政府文档上提取结构字段达到89.8%准确率并推理更快。

Conclusion: 两种系统均达到了国际领先的性能，并为大规模生产部署的印度OCR系统设计提供了系统性和实用性参考。

Abstract: Designing Optical Character Recognition (OCR) systems for India requires balancing linguistic diversity, document heterogeneity, and deployment constraints. In this paper, we study two training strategies for building multilingual OCR systems with Vision-Language Models through the Chitrapathak series. We first follow a popular multimodal approach, pairing a generic vision encoder with a strong multilingual language model and training the system end-to-end for OCR. Alternatively, we explore fine-tuning an existing OCR model, despite not being trained for the target languages. Through extensive evaluation on multilingual Indic OCR benchmarks and deployment-oriented metrics, we find that the second strategy consistently achieves better accuracy-latency trade-offs. Chitrapathak-2 achieves 3-6x speedup over its predecessor with being state-of-the-art (SOTA) in Telugu (6.69 char ANLS) and second best in the rest. In addition, we present Parichay, an independent OCR model series designed specifically for 9 Indian government documents to extract structured key fields, achieving 89.8% Exact Match score with a faster inference. Together, these systems achieve SOTA performance and provide practical guidance for building production-scale OCR pipelines in the Indian context.

</details>


### [33] [Visual Self-Refine: A Pixel-Guided Paradigm for Accurate Chart Parsing](https://arxiv.org/abs/2602.16455)
*Jinsong Li,Xiaoyi Dong,Yuhang Zang,Yuhang Cao,Jiaqi Wang,Dahua Lin*

Main category: cs.CV

TL;DR: 本文引入了一种新的视觉自查范式（Visual Self-Refine, VSR），帮助大型视觉-语言模型（LVLMs）在处理复杂图表解析任务时提升准确性。该方法通过像素级定位和可视化反馈实现更精准的数据提取，并提出了新的基准测试集。


<details>
  <summary>Details</summary>
Motivation: 尽管LVLMs在文本推理和自我修正方面表现优秀，但在处理可视化密集的图表解析任务时，仍容易出现数据遗漏、错位和幻觉等问题。受到人类用手指作为视觉锚点帮助读取复杂图表的启发，作者提出一种让模型自查自身视觉感知错误的新策略。

Method: 核心方法是提出视觉自查（VSR）范式。具体在图表解析领域，提出了ChartVSR模型，包括两个阶段：1）Refine阶段，模型通过像素级本地化输出并可视化，利用自反馈迭代校正视觉感知错误；2）Decode阶段，利用已确认的像素级锚点解析最终结构化数据。此外，作者还构建了更具挑战性的图表解析基准ChartP-Bench。

Result: ChartVSR在新构建的ChartP-Bench基准上的性能优于现有模型，显著减少了数据遗漏、错位和幻觉等常见错误。实验证明，VSR范式可有效提升模型在视觉密集型任务上的解析精度。

Conclusion: VSR是一种通用的视觉反馈机制，不仅提升了图表解析的表现，还为更多以视觉为中心的复杂任务提供了增强模型准确性的潜力和新方向。

Abstract: While Large Vision-Language Models (LVLMs) have demonstrated remarkable capabilities for reasoning and self-correction at the textual level, these strengths provide minimal benefits for complex tasks centered on visual perception, such as Chart Parsing. Existing models often struggle with visually dense charts, leading to errors like data omission, misalignment, and hallucination. Inspired by the human strategy of using a finger as a ``visual anchor'' to ensure accuracy when reading complex charts, we propose a new paradigm named Visual Self-Refine (VSR). The core idea of VSR is to enable a model to generate pixel-level localization outputs, visualize them, and then feed these visualizations back to itself, allowing it to intuitively inspect and correct its own potential visual perception errors. We instantiate the VSR paradigm in the domain of Chart Parsing by proposing ChartVSR. This model decomposes the parsing process into two stages: a Refine Stage, where it iteratively uses visual feedback to ensure the accuracy of all data points' Pixel-level Localizations, and a Decode Stage, where it uses these verified localizations as precise visual anchors to parse the final structured data. To address the limitations of existing benchmarks, we also construct ChartP-Bench, a new and highly challenging benchmark for chart parsing. Our work also highlights VSR as a general-purpose visual feedback mechanism, offering a promising new direction for enhancing accuracy on a wide range of vision-centric tasks.

</details>


### [34] [MMA: Multimodal Memory Agent](https://arxiv.org/abs/2602.16493)
*Yihao Lu,Wanru Cheng,Zeyu Zhang,Hao Tang*

Main category: cs.CV

TL;DR: 本文提出了一种多模态记忆智能体（MMA），通过动态评估和调整外部记忆项的可靠性，提升长期多模态推理的准确性和安全性。


<details>
  <summary>Details</summary>
Motivation: 长期多模态智能体依赖外部记忆，但基于相似性的检索方法容易检索到过时、低可信或冲突的信息，导致过度自信的错误。作者希望解决记忆检索可信度不高且易引发错误的问题。

Method: 提出MMA，结合来源可信度、时间衰减和冲突感知共识，为每个检索到的记忆项动态分配可靠度分数，并据此重加权证据或在支持不足时选择放弃作答。同时引入MMA-Bench，这是一套自动生成、具备受控说话者可靠性和结构化文本-视觉矛盾的评测基准。通过该框架，分析和揭示了RAG型代理存在视觉偏见的“视觉安慰剂效应”。

Result: MMA在FEVER数据集上与基线准确率持平，但方差降低了35.2%，选择性效用提升；在LoCoMo安全设定下提升了可执行准确率并减少错误答案；在MMA-Bench上，MMA在视觉模式下的Type-B准确率达到41.18%，而基线方法在同一协议下降至0.0%。

Conclusion: MMA能有效提升多模态长期推理的可靠性和安全性，减少因低可信或冲突记忆项带来的错误，能够有效支持谨慎决策，并揭示多模态基础模型可能自带的潜在偏见。

Abstract: Long-horizon multimodal agents depend on external memory; however, similarity-based retrieval often surfaces stale, low-credibility, or conflicting items, which can trigger overconfident errors. We propose Multimodal Memory Agent (MMA), which assigns each retrieved memory item a dynamic reliability score by combining source credibility, temporal decay, and conflict-aware network consensus, and uses this signal to reweight evidence and abstain when support is insufficient. We also introduce MMA-Bench, a programmatically generated benchmark for belief dynamics with controlled speaker reliability and structured text-vision contradictions. Using this framework, we uncover the "Visual Placebo Effect", revealing how RAG-based agents inherit latent visual biases from foundation models. On FEVER, MMA matches baseline accuracy while reducing variance by 35.2% and improving selective utility; on LoCoMo, a safety-oriented configuration improves actionable accuracy and reduces wrong answers; on MMA-Bench, MMA reaches 41.18% Type-B accuracy in Vision mode, while the baseline collapses to 0.0% under the same protocol. Code: https://github.com/AIGeeksGroup/MMA.

</details>


### [35] [Benchmarking Adversarial Robustness and Adversarial Training Strategies for Object Detection](https://arxiv.org/abs/2602.16494)
*Alexis Winter,Jean-Vincent Martini,Romaric Audigier,Angelique Loesch,Bertrand Luvison*

Main category: cs.CV

TL;DR: 该论文提出了一个统一的评测框架，用于公平比较物体检测中对抗攻击与防御方法，并揭示了攻击在不同架构间的迁移性较差及混合对抗训练策略的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有物体检测的对抗攻击和防御研究，在评测标准、数据集和效率度量上不统一，导致难以公平比较不同方法。因此，迫切需要一个标准化的基准来系统评测并指导后续研究。

Method: 作者提出了一个专注于数字型、非patch类对抗攻击的统一基准框架。该框架引入了区分定位与分类误差的专用指标，并用多个感知度量评估攻击代价，能够系统性比较不同攻击算法和检测模型。

Result: 实验覆盖了主流对抗攻击及多种检测器。结果显示，当前对抗攻击对基于transformer的检测器迁移性较差。同时，利用混合高扰动、目标多样（空间与语义）的对抗样本进行训练，比单一攻击训练有更强的鲁棒性。

Conclusion: 提出的基准框架能促进物体检测对抗研究的规范化。发现混合目标、多类型攻击的对抗训练策略能有效提升模型鲁棒性，是未来防御研究的推荐路径。

Abstract: Object detection models are critical components of automated systems, such as autonomous vehicles and perception-based robots, but their sensitivity to adversarial attacks poses a serious security risk. Progress in defending these models lags behind classification, hindered by a lack of standardized evaluation. It is nearly impossible to thoroughly compare attack or defense methods, as existing work uses different datasets, inconsistent efficiency metrics, and varied measures of perturbation cost. This paper addresses this gap by investigating three key questions: (1) How can we create a fair benchmark to impartially compare attacks? (2) How well do modern attacks transfer across different architectures, especially from Convolutional Neural Networks to Vision Transformers? (3) What is the most effective adversarial training strategy for robust defense? To answer these, we first propose a unified benchmark framework focused on digital, non-patch-based attacks. This framework introduces specific metrics to disentangle localization and classification errors and evaluates attack cost using multiple perceptual metrics. Using this benchmark, we conduct extensive experiments on state-of-the-art attacks and a wide range of detectors. Our findings reveal two major conclusions: first, modern adversarial attacks against object detection models show a significant lack of transferability to transformer-based architectures. Second, we demonstrate that the most robust adversarial training strategy leverages a dataset composed of a mix of high-perturbation attacks with different objectives (e.g., spatial and semantic), which outperforms training on any single attack.

</details>


### [36] [DressWild: Feed-Forward Pose-Agnostic Garment Sewing Pattern Generation from In-the-Wild Images](https://arxiv.org/abs/2602.16502)
*Zeng Tao,Ying Jiang,Yunuo Chen,Tianyi Xie,Huamin Wang,Yingnian Wu,Yin Yang,Abishek Sampath Kumar,Kenji Tashiro,Chenfanfu Jiang*

Main category: cs.CV

TL;DR: 提出了一种名为DressWild的新方法，可从单张自然场景图片中高效还原出物理一致的2D纸样和对应的3D服装模型。


<details>
  <summary>Details</summary>
Motivation: 现有的服装纸样生成方法，要么对不同人物姿态和视角适应性差（前馈方法），要么计算量大不易扩展（基于优化的方法），难以满足实际建模与制造中的可编辑、可分离及可仿真需求。

Method: 提出DressWild方法，利用视觉-语言模型（VLMs）对输入服装图片进行姿态归一化，并提取具备三维信息的服装特征。这些特征通过transformer编码器进行融合后，用于预测2D纸样参数，支持物理仿真、多层试衣等应用。无需多视角输入或迭代优化。

Result: 实验证明，该方法无需多视角或复杂优化，就能稳定还原多样化服装的2D纸样和3D模型，实现了高效且可扩展的自然场景服装还原。

Conclusion: DressWild能大幅提升服装建模和仿真的效率与适应性，为服装动画和虚拟试衣等实际应用提供了强大支撑。

Abstract: Recent advances in garment pattern generation have shown promising progress. However, existing feed-forward methods struggle with diverse poses and viewpoints, while optimization-based approaches are computationally expensive and difficult to scale. This paper focuses on sewing pattern generation for garment modeling and fabrication applications that demand editable, separable, and simulation-ready garments. We propose DressWild, a novel feed-forward pipeline that reconstructs physics-consistent 2D sewing patterns and the corresponding 3D garments from a single in-the-wild image. Given an input image, our method leverages vision-language models (VLMs) to normalize pose variations at the image level, then extract pose-aware, 3D-informed garment features. These features are fused through a transformer-based encoder and subsequently used to predict sewing pattern parameters, which can be directly applied to physical simulation, texture synthesis, and multi-layer virtual try-on. Extensive experiments demonstrate that our approach robustly recovers diverse sewing patterns and the corresponding 3D garments from in-the-wild images without requiring multi-view inputs or iterative optimization, offering an efficient and scalable solution for realistic garment simulation and animation.

</details>


### [37] [Let's Split Up: Zero-Shot Classifier Edits for Fine-Grained Video Understanding](https://arxiv.org/abs/2602.16545)
*Kaiting Liu,Hazel Doughty*

Main category: cs.CV

TL;DR: 本文提出了一种新的任务“类别细分”，即无需额外数据，将已有分类器中粗粒度类别细化为更具体的子类别，并保持其它类别精度不变。作者提出零样本编辑方法，充分挖掘分类器的潜在组合结构，并验证少样本微调法的有效性。实验证明，该方法在新提出的视频基准上大幅优于视觉-语言基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频识别模型依赖于固定的粗粒度类别体系，难以适应任务和定义变化，引入新类别和重标注耗时耗力。如何在不增加额外数据的情况下，动态细化原有分类体系，是实际应用的需求痛点。

Method: 作者提出“类别细分”任务，要求在不影响其他类别性能的前提下，将某个已有粗粒度类别细化为多个子类别。方法上，先提出一种零样本编辑技术，利用分类器的潜在组合结构实现类别细分；另提出少样本微调策略，进一步提升性能，并与零样本方法结合。

Result: 在新提出的视频类别细分基准测试上，所提方法显著优于视觉-语言大模型等基线，在新增子类别上大幅提升准确率，并能保持对原有类别的性能不变。

Conclusion: 所提类别细分与零样本编辑新范式，为动态更新和细化视频分类体系提供了低成本、高效的方法，实验证明其实用性和优越性。

Abstract: Video recognition models are typically trained on fixed taxonomies which are often too coarse, collapsing distinctions in object, manner or outcome under a single label. As tasks and definitions evolve, such models cannot accommodate emerging distinctions and collecting new annotations and retraining to accommodate such changes is costly. To address these challenges, we introduce category splitting, a new task where an existing classifier is edited to refine a coarse category into finer subcategories, while preserving accuracy elsewhere. We propose a zero-shot editing method that leverages the latent compositional structure of video classifiers to expose fine-grained distinctions without additional data. We further show that low-shot fine-tuning, while simple, is highly effective and benefits from our zero-shot initialization. Experiments on our new video benchmarks for category splitting demonstrate that our method substantially outperforms vision-language baselines, improving accuracy on the newly split categories without sacrificing performance on the rest. Project page: https://kaitingliu.github.io/Category-Splitting/.

</details>


### [38] [Arc2Morph: Identity-Preserving Facial Morphing with Arc2Face](https://arxiv.org/abs/2602.16569)
*Nicolò Di Domenico,Annalisa Franco,Matteo Ferrara,Davide Maltoni*

Main category: cs.CV

TL;DR: 本文提出了一种基于Arc2Face模型的人脸合成方法，用于制造更难检测的人脸变换攻击，并在大规模数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 很多国家的护照照片采集在无人监督下进行，导致人脸识别系统易受到人脸变换攻击。现有防护措施尚难以全面应对，因此需要更强的人脸变换生成技术，用以测试和提升检测手段。

Method: 提出一种基于Arc2Face（人脸基础模型）的新型人脸变换方法，通过身份条件合成紧凑编码的人脸图像，并在两个大规模人脸变换检测数据集和两个新的人脸数据集上，与多种主流方法进行对比分析。

Result: 新方法在攻击潜力方面表现与传统地标点法相当，能生产高质量且难以检测的合成图像，在多个公开与新建数据集上均有验证。

Conclusion: 该方法能够在变换生成过程中有效保留和管理身份信息，为相关安全系统的研究和改进带来新挑战和机遇。

Abstract: Face morphing attacks are widely recognized as one of the most challenging threats to face recognition systems used in electronic identity documents. These attacks exploit a critical vulnerability in passport enrollment procedures adopted by many countries, where the facial image is often acquired without a supervised live capture process. In this paper, we propose a novel face morphing technique based on Arc2Face, an identity-conditioned face foundation model capable of synthesizing photorealistic facial images from compact identity representations. We demonstrate the effectiveness of the proposed approach by comparing the morphing attack potential metric on two large-scale sequestered face morphing attack detection datasets against several state-of-the-art morphing methods, as well as on two novel morphed face datasets derived from FEI and ONOT. Experimental results show that the proposed deep learning-based approach achieves a morphing attack potential comparable to that of landmark-based techniques, which have traditionally been regarded as the most challenging. These findings confirm the ability of the proposed method to effectively preserve and manage identity information during the morph generation process.

</details>


### [39] [A Contrastive Learning Framework Empowered by Attention-based Feature Adaptation for Street-View Image Classification](https://arxiv.org/abs/2602.16590)
*Qi You,Yitai Cheng,Zichao Zeng,James Haworth*

Main category: cs.CV

TL;DR: 本文提出了CLIP-MHAdapter方法，通过引入带有多头自注意力机制的MLP瓶颈模块，提升了街景图像中属性分类任务的表现，尤其是在细粒度、局部化场景下，且计算需求低，取得了新SOTA成果。


<details>
  <summary>Details</summary>
Motivation: 当前街景图像属性分类在实际应用如自动驾驶等场景下十分重要，但主流方法在计算资源和对局部细节表达能力上存在不足。尤其是基于CLIP等预训练视觉-语言模型的适配方法主要依赖全局特征，难以捕捉复杂街景中的细致属性，因此需要改进。

Method: 提出CLIP-MHAdapter，将轻量级适配范式与多头自注意力MLP结合，通过作用于patch token，建模patch间依赖关系，从而增强模型对局部细粒度属性的捕捉能力。整个适配器仅约140万可训练参数，计算开销低。

Result: 在Global StreetScapes数据集的八个属性分类任务上，CLIP-MHAdapter取得更优或具竞争力的准确率，刷新了当前最佳效果，同时保持了低计算成本。

Conclusion: CLIP-MHAdapter显著提升了街景属性分类性能，特别适用于资源有限且细粒度属性重要的实际场景，兼顾精度和效率，具备广泛的应用前景。

Abstract: Street-view image attribute classification is a vital downstream task of image classification, enabling applications such as autonomous driving, urban analytics, and high-definition map construction. It remains computationally demanding whether training from scratch, initialising from pre-trained weights, or fine-tuning large models. Although pre-trained vision-language models such as CLIP offer rich image representations, existing adaptation or fine-tuning methods often rely on their global image embeddings, limiting their ability to capture fine-grained, localised attributes essential in complex, cluttered street scenes. To address this, we propose CLIP-MHAdapter, a variant of the current lightweight CLIP adaptation paradigm that appends a bottleneck MLP equipped with multi-head self-attention operating on patch tokens to model inter-patch dependencies. With approximately 1.4 million trainable parameters, CLIP-MHAdapter achieves superior or competitive accuracy across eight attribute classification tasks on the Global StreetScapes dataset, attaining new state-of-the-art results while maintaining low computational cost. The code is available at https://github.com/SpaceTimeLab/CLIP-MHAdapter.

</details>


### [40] [Unpaired Image-to-Image Translation via a Self-Supervised Semantic Bridge](https://arxiv.org/abs/2602.16664)
*Jiaming Liu,Felix Petersen,Yunhe Gao,Yabin Zhang,Hyojin Kim,Akshay S. Chaudhari,Yu Sun,Stefano Ermon,Sergios Gatidis*

Main category: cs.CV

TL;DR: 本论文提出了一种名为Self-Supervised Semantic Bridge (SSB)的无监督图像到图像翻译框架，能有效提升医学影像合成与文本引导编辑的效果，解决了以往方法泛化性差或保真度低的问题。


<details>
  <summary>Details</summary>
Motivation: 现有无监督图像翻译方法受制于对抗损失泛化能力不足或扩散-反演方法低保真度等问题，难以在新领域和复杂场景下获得高质量翻译。作者希望突破这些限制，实现高质量和高泛化能力的图像到图像翻译。

Method: 作者提出了SSB框架，将自监督视觉编码器学到的外部语义先验纳入扩散桥接模型，通过提取对外观变化不敏感但捕捉几何结构的共享潜空间，指导无监督图像翻译，无需跨域监督。

Result: 通过大量实验，SSB在医学图像合成的域内和跨域场景下均超越了强力先前方法，并能自然扩展到高质量文本引导的图像编辑任务。

Conclusion: SSB框架有效克服了现有无监督图像翻译方法的主要缺点，实现了空间一致和保真度高的图像翻译，在实际医学图像及其他复杂任务中有良好应用前景。

Abstract: Adversarial diffusion and diffusion-inversion methods have advanced unpaired image-to-image translation, but each faces key limitations. Adversarial approaches require target-domain adversarial loss during training, which can limit generalization to unseen data, while diffusion-inversion methods often produce low-fidelity translations due to imperfect inversion into noise-latent representations. In this work, we propose the Self-Supervised Semantic Bridge (SSB), a versatile framework that integrates external semantic priors into diffusion bridge models to enable spatially faithful translation without cross-domain supervision. Our key idea is to leverage self-supervised visual encoders to learn representations that are invariant to appearance changes but capture geometric structure, forming a shared latent space that conditions the diffusion bridges. Extensive experiments show that SSB outperforms strong prior methods for challenging medical image synthesis in both in-domain and out-of-domain settings, and extends easily to high-quality text-guided editing.

</details>


### [41] [PredMapNet: Future and Historical Reasoning for Consistent Online HD Vectorized Map Construction](https://arxiv.org/abs/2602.16669)
*Bo Lang,Nirav Savaliya,Zhihao Zheng,Jinglun Feng,Zheng-Hang Yeh,Mooi Choo Chuah*

Main category: cs.CV

TL;DR: 本文提出了一种一致性的在线高精地图（HD地图）构建方法，结合实例跟踪与短期预测，并通过多个创新模块提高时序一致性与稳定性，在主流自动驾驶数据集上效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有高精地图构建方法由于随机查询初始化和时间建模不充分，导致全局地图在时间维度上的不一致和不稳定。本文旨在解决地图生成过程中的时序一致性与实例感知问题，提升自动驾驶系统的地图构建质量。

Method: 提出端到端的框架，包含：1）基于语义掩码的查询生成器，实现空间及语义对齐；2）实例级历史地图存储（History Rasterized Map Memory），显式记录和利用历史信息；3）历史地图引导模块将历史信息融合进查询以增强时序连续性；4）短期未来引导模块依据历史轨迹预测地图元素的近期变化，进一步提升预测合 plausibility 和时序一致性。

Result: 在nuScenes和Argoverse2这两个主流自动驾驶数据集上进行了大量实验证明，该方法提升了地图构建的准确性和时序稳定性，在效率和效果上均超过了最新的现有方法。

Conclusion: 本文方法能更好地捕捉和利用历史及场景信息，有效解决了高精地图构建时的时序一致性问题，推动了自动驾驶地图构建技术发展。

Abstract: High-definition (HD) maps are crucial to autonomous driving, providing structured representations of road elements to support navigation and planning. However, existing query-based methods often employ random query initialization and depend on implicit temporal modeling, which lead to temporal inconsistencies and instabilities during the construction of a global map. To overcome these challenges, we introduce a novel end-to-end framework for consistent online HD vectorized map construction, which jointly performs map instance tracking and short-term prediction. First, we propose a Semantic-Aware Query Generator that initializes queries with spatially aligned semantic masks to capture scene-level context globally. Next, we design a History Rasterized Map Memory to store fine-grained instance-level maps for each tracked instance, enabling explicit historical priors. A History-Map Guidance Module then integrates rasterized map information into track queries, improving temporal continuity. Finally, we propose a Short-Term Future Guidance module to forecast the immediate motion of map instances based on the stored history trajectories. These predicted future locations serve as hints for tracked instances to further avoid implausible predictions and keep temporal consistency. Extensive experiments on the nuScenes and Argoverse2 datasets demonstrate that our proposed method outperforms state-of-the-art (SOTA) methods with good efficiency.

</details>


### [42] [VETime: Vision Enhanced Zero-Shot Time Series Anomaly Detection](https://arxiv.org/abs/2602.16681)
*Yingyuan Yang,Tian Lan,Yifei Gao,Yimeng Lu,Wenjun He,Meng Wang,Chenghao Liu,Chen Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种统一时序与视觉模态的新方法VETime，在时间序列异常检测任务中实现了更精细的定位与更低计算开销，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列异常检测方法在时序建模和全局上下文理解之间存在基本权衡：1D时序模型定位精细但上下文感知弱，2D视觉模型则反之。本工作旨在同时兼顾两者优势。

Method: 提出VETime框架，通过可逆图像转换与局部补丁级时序对齐，构建视觉-时序共享时间线，并利用异常窗口对比学习和任务自适应多模态融合，有效组合时序与视觉信息。

Result: 在多个零样本场景下，VETime显著优于先进方法，实现了更高的异常定位精度和更低计算成本。

Conclusion: VETime突破了TSAD领域中时序与视觉建模各自的局限，展现了强大的实用价值，并有望推动多模态异常检测的发展。

Abstract: Time-series anomaly detection (TSAD) requires identifying both immediate Point Anomalies and long-range Context Anomalies. However, existing foundation models face a fundamental trade-off: 1D temporal models provide fine-grained pointwise localization but lack a global contextual perspective, while 2D vision-based models capture global patterns but suffer from information bottlenecks due to a lack of temporal alignment and coarse-grained pointwise detection. To resolve this dilemma, we propose VETime, the first TSAD framework that unifies temporal and visual modalities through fine-grained visual-temporal alignment and dynamic fusion. VETime introduces a Reversible Image Conversion and a Patch-Level Temporal Alignment module to establish a shared visual-temporal timeline, preserving discriminative details while maintaining temporal sensitivity. Furthermore, we design an Anomaly Window Contrastive Learning mechanism and a Task-Adaptive Multi-Modal Fusion to adaptively integrate the complementary perceptual strengths of both modalities. Extensive experiments demonstrate that VETime significantly outperforms state-of-the-art models in zero-shot scenarios, achieving superior localization precision with lower computational overhead than current vision-based approaches. Code available at: https://github.com/yyyangcoder/VETime.

</details>


### [43] [Learning Situated Awareness in the Real World](https://arxiv.org/abs/2602.16682)
*Chuhan Li,Ruilin Han,Joy Hsu,Yongyuan Liang,Rajiv Dhawan,Jiajun Wu,Ming-Hsuan Yang,Xin Eric Wang*

Main category: cs.CV

TL;DR: 论文提出了SAW-Bench数据集，用于评估多模态基础模型在真实世界自我中心场景下的情境感知能力，发现当前主流模型与人类在该任务上存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有多模态模型评测主要关注环境中心的空间关系，忽视了观察者本体（如视角、姿势和运动）相关的推理，这与人类实际感知存在差异。作者希望解决这一评测空白，以提升模型对现实中自我中心场景的理解。

Method: 作者构建了SAW-Bench基准，包括786段由Ray-Ban Meta智能眼镜录制的自我视角视频，涵盖多种室内外场景及2,071组人工标注的问答对，通过六类感知任务系统评测模型在观察者中心认知方面的表现。

Result: 在SAW-Bench上评测发现，目前最优的多模态基础模型（如Gemini 3 Flash）与人类在该任务上仍有37.66%的性能差距。进一步分析揭示模型尽管能利用部分几何线索，但在推断摄像头几何关系时常出错，导致空间推理系统性错误。

Conclusion: SAW-Bench为模型情境空间智能提供了新的评测基准，有助于多模态模型从被动观察提升到具备物理依赖、观察者中心动态理解能力。

Abstract: A core aspect of human perception is situated awareness, the ability to relate ourselves to the surrounding physical environment and reason over possible actions in context. However, most existing benchmarks for multimodal foundation models (MFMs) emphasize environment-centric spatial relations (relations among objects in a scene), while largely overlooking observer-centric relationships that require reasoning relative to agent's viewpoint, pose, and motion. To bridge this gap, we introduce SAW-Bench (Situated Awareness in the Real World), a novel benchmark for evaluating egocentric situated awareness using real-world videos. SAW-Bench comprises 786 self-recorded videos captured with Ray-Ban Meta (Gen 2) smart glasses spanning diverse indoor and outdoor environments, and over 2,071 human-annotated question-answer pairs. It probes a model's observer-centric understanding with six different awareness tasks. Our comprehensive evaluation reveals a human-model performance gap of 37.66%, even with the best-performing MFM, Gemini 3 Flash. Beyond this gap, our in-depth analysis uncovers several notable findings; for example, while models can exploit partial geometric cues in egocentric videos, they often fail to infer a coherent camera geometry, leading to systematic spatial reasoning errors. We position SAW-Bench as a benchmark for situated spatial intelligence, moving beyond passive observation to understanding physically grounded, observer-centric dynamics.

</details>


### [44] [Are Object-Centric Representations Better At Compositional Generalization?](https://arxiv.org/abs/2602.16689)
*Ferdinand Kapl,Amir Mohammad Karimi Mamaghan,Maximilian Seitzer,Karl Henrik Johansson,Carsten Marr,Stefan Bauer,Andrea Dittadi*

Main category: cs.CV

TL;DR: 本文通过设计视觉问答基准，系统比较了带有和不带有对象中心化（OC）偏置的视觉编码器在组合泛化任务中的表现，发现OC方法在资源受限或任务更难时表现更强。


<details>
  <summary>Details</summary>
Motivation: 人类在熟悉概念的新组合情境下具有卓越的泛化能力（组合泛化），而让机器学习模型具备这一能力仍面临挑战。OC表示被认为有助于组合泛化，但在复杂视觉场景下的系统性验证有限，因此作者提出新基准系统地评测这一点。

Method: 作者在三个受控视觉世界（CLEVRTex、Super-CLEVR、MOVi-C）中构建视觉问答基准，比较经典视觉编码器（DINOv2、SigLIP2）及其对象中心化变体在泛化到未见过的对象属性组合上的能力，并严格控制数据多样性、样本数、表示维度、下游模型容量和算力等变量。

Result: （1）OC方法在难度更高的组合泛化任务中表现优越；（2）原始密集表现在简单场景中略优，但需更多下游算力支持；（3）OC模型在样本效率和小数据泛化上更具优势，密集编码器则需大量多样数据才能追上或超过OC方法。

Conclusion: 当数据量、样本多样性或下游算力受限时，OC表示能带来更强的组合泛化能力，建议在有泛化需求和资源受限的实际场景中优先考虑对象中心化表示。

Abstract: Compositional generalization, the ability to reason about novel combinations of familiar concepts, is fundamental to human cognition and a critical challenge for machine learning. Object-centric (OC) representations, which encode a scene as a set of objects, are often argued to support such generalization, but systematic evidence in visually rich settings is limited. We introduce a Visual Question Answering benchmark across three controlled visual worlds (CLEVRTex, Super-CLEVR, and MOVi-C) to measure how well vision encoders, with and without object-centric biases, generalize to unseen combinations of object properties. To ensure a fair and comprehensive comparison, we carefully account for training data diversity, sample size, representation size, downstream model capacity, and compute. We use DINOv2 and SigLIP2, two widely used vision encoders, as the foundation models and their OC counterparts. Our key findings reveal that (1) OC approaches are superior in harder compositional generalization settings; (2) original dense representations surpass OC only on easier settings and typically require substantially more downstream compute; and (3) OC models are more sample efficient, achieving stronger generalization with fewer images, whereas dense encoders catch up or surpass them only with sufficient data and diversity. Overall, object-centric representations offer stronger compositional generalization when any one of dataset size, training data diversity, or downstream compute is constrained.

</details>


### [45] [Saliency-Aware Multi-Route Thinking: Revisiting Vision-Language Reasoning](https://arxiv.org/abs/2602.16702)
*Mingjia Shi,Yinhan He,Yaochen Zhu,Jundong Li*

Main category: cs.CV

TL;DR: 论文提出了一种针对视觉-语言模型(vision-language models, VLMs)推理的新方法，称为Saliency-Aware Principle (SAP) selection，显著提升了模型在视觉证据支撑、推理稳定性和效率方面的表现。


<details>
  <summary>Details</summary>
Motivation: VLMs 推理过程中，视觉输入仅在生成开始时提供一次，后续推理受文本主导，导致早期的视觉对齐误差易累积，并引发目标幻觉等问题。此外，推理过程中的视觉引导方式通常粗糙且噪声大，难以高效地指导长文本推理。因此，亟需一种方法，既能更稳健地利用视觉证据，又能改善推理过程的连贯性和多样性。

Method: 提出 Saliency-Aware Principle (SAP) selection 方法。SAP不是依赖传统的逐token生成路线，而是在高层次的推理原则上进行选择，使模型能在推理过程中多次、灵活地重新查询视觉证据，提升推理稳定性。SAP还支持多路径并行推理，探索不同的推理思路。此外，SAP属于模型无关、数据无关的方法，无需额外训练。

Result: 实验证明，SAP 能在相同token生成预算下，显著减少对象幻觉问题，推理更稳定，并且比采用链式思维(COT)风格的长序列推理更低的响应延迟和更好的稳定性。

Conclusion: SAP selection 有效解决了VLMs中视觉证据利用不足和推理不稳的问题，无需额外训练就能提升推理表现，在多个实证任务上展现了显著优势。

Abstract: Vision-language models (VLMs) aim to reason by jointly leveraging visual and textual modalities. While allocating additional inference-time computation has proven effective for large language models (LLMs), achieving similar scaling in VLMs remains challenging. A key obstacle is that visual inputs are typically provided only once at the start of generation, while textual reasoning (e.g., early visual summaries) is generated autoregressively, causing reasoning to become increasingly text-dominated and allowing early visual grounding errors to accumulate. Moreover, vanilla guidance for visual grounding during inference is often coarse and noisy, making it difficult to steer reasoning over long texts. To address these challenges, we propose \emph{Saliency-Aware Principle} (SAP) selection. SAP operates on high-level reasoning principles rather than token-level trajectories, which enable stable control over discrete generation under noisy feedback while allowing later reasoning steps to re-consult visual evidence when renewed grounding is required. In addition, SAP supports multi-route inference, enabling parallel exploration of diverse reasoning behaviors. SAP is model-agnostic and data-free, requiring no additional training. Empirical results show that SAP achieves competitive performance, especially in reducing object hallucination, under comparable token-generation budgets while yielding more stable reasoning and lower response latency than CoT-style long sequential reasoning.

</details>


### [46] [TeCoNeRV: Leveraging Temporal Coherence for Compressible Neural Representations for Videos](https://arxiv.org/abs/2602.16711)
*Namitha Padmanabhan,Matthew Gwilliam,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: 提出了一种高效的神经隐式表示视频压缩方法TeCoNeRV，显著降低了内存需求和比特率，并提升了视频重建质量和编码速度，在高分辨率视频压缩上首次取得突破性效果。


<details>
  <summary>Details</summary>
Motivation: 现有INR方法需要对每个视频单独过拟合模型，不易扩展到高分辨率视频。基于超网络的方法虽然编码速度快，但面临重建质量差、压缩体积大和高分辨率内存需求过高等难题。如何兼顾高效性、低内存及高质量，成为视频压缩领域的重要挑战。

Method: 1）将权重预测任务分解为空间和时间两部分，用patch tubelet处理视频分段，极大减小预训练内存；2）采用残差存储策略，仅存储相邻片段表示的差异，降低码流大小；3）设计时序一致性正则化，使权重空间的变化与视频内容一致。

Result: TeCoNeRV方法在UVG数据集上，480p和720p分辨率分别比基线提升2.47dB和5.35dB PSNR，码率降低36%，编码速度提升1.5-3倍。首次实现了超网络方法在480p、720p、1080p高分辨率下对UVG、HEVC和MCL-JCV数据集的有效视频压缩。

Conclusion: TeCoNeRV以创新的分解预测和残差存储机制，显著提升了高分辨率视频压缩的性能，为低内存、高效率的视频编码提供了切实可行的新方案，推动了神经隐式表示技术在实际大规模视频压缩场景的应用。

Abstract: Implicit Neural Representations (INRs) have recently demonstrated impressive performance for video compression. However, since a separate INR must be overfit for each video, scaling to high-resolution videos while maintaining encoding efficiency remains a significant challenge. Hypernetwork-based approaches predict INR weights (hyponetworks) for unseen videos at high speeds, but with low quality, large compressed size, and prohibitive memory needs at higher resolutions. We address these fundamental limitations through three key contributions: (1) an approach that decomposes the weight prediction task spatially and temporally, by breaking short video segments into patch tubelets, to reduce the pretraining memory overhead by 20$\times$; (2) a residual-based storage scheme that captures only differences between consecutive segment representations, significantly reducing bitstream size; and (3) a temporal coherence regularization framework that encourages changes in the weight space to be correlated with video content. Our proposed method, TeCoNeRV, achieves substantial improvements of 2.47dB and 5.35dB PSNR over the baseline at 480p and 720p on UVG, with 36% lower bitrates and 1.5-3$\times$ faster encoding speeds. With our low memory usage, we are the first hypernetwork approach to demonstrate results at 480p, 720p and 1080p on UVG, HEVC and MCL-JCV. Our project page is available at https://namithap10.github.io/teconerv/ .

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [47] [The Perplexity Paradox: Why Code Compresses Better Than Math in LLM Prompts](https://arxiv.org/abs/2602.15843)
*Warren Johnson*

Main category: cs.CL

TL;DR: 本文系统验证了代码生成和推理任务在提示压缩下的行为差异，发现代码生成可容忍高压缩但推理性能则逐步下降，并提出了一种自适应压缩算法TAAC，实现了在保证质量情况下的显著成本节约。


<details>
  <summary>Details</summary>
Motivation: 前期工作发现代码生成对于提示压缩具有较强鲁棒性，但推理任务则随压缩度增加而性能逐步退化。原有研究仅限于小样本，未能深入解释“困惑度悖论”，也未提出自适应压缩方法。因此，该文旨在通过更大规模、多类型数据验证上述结论，并探究困惑度悖论的内在机制，进而提出能自动适应任务特性的压缩方案。

Method: 作者采用六大代码类和四大推理类基准进行广泛实验，在token级别分析压缩后的困惑度变化，同时设计“signature injection”提升关键任务信息保留。最后提出TAAC（Task-Aware Adaptive Compression）算法，能根据任务敏感性自适应压缩以优化成本与质量平衡，并在MBPP基准大规模验证。

Result: 实验显示代码生成任务在高压缩（r>=0.6）下性能基本保持，而推理任务性能随压缩度增加逐步下降；困惑度悖论分析发现代码token被优先保留而数学问题中的数字等关键信息易被丢弃。通过signature injection，可将通过率由5.3%提升至39.3%。TAAC算法实现了22%的成本节约，并保持96%的输出质量，优于固定比例压缩7%。MBPP试验证实压缩比例与性能变化呈系统性对应关系。

Conclusion: 本文全面拓展了此前关于提示压缩鲁棒性的发现，证实该阈值对不同任务、数据集具有普遍性，并揭示了困惑度悖论背后的机制。所提TAAC算法在保证质量时大幅节省成本，为实际部署提供了更优解法。

Abstract: In "Compress or Route?" (Johnson, 2026), we found that code generation tolerates aggressive prompt compression (r >= 0.6) while chain-of-thought reasoning degrades gradually. That study was limited to HumanEval (164 problems), left the "perplexity paradox" mechanism unvalidated, and provided no adaptive algorithm. This paper addresses all three gaps. First, we validate across six code benchmarks (HumanEval, MBPP, HumanEval+, MultiPL-E) and four reasoning benchmarks (GSM8K, MATH, ARC-Challenge, MMLU-STEM), confirming the compression threshold generalizes across languages and difficulties. Second, we conduct the first per-token perplexity analysis (n=723 tokens), revealing a "perplexity paradox": code syntax tokens are preserved (high perplexity) while numerical values in math problems are pruned despite being task-critical (low perplexity). Signature injection recovers +34 percentage points in pass rate (5.3% to 39.3%; Cohen's h=0.890). Third, we propose TAAC (Task-Aware Adaptive Compression), achieving 22% cost reduction with 96% quality preservation, outperforming fixed-ratio compression by 7%. MBPP validation (n=1,800 trials) confirms systematic variation: 3.6% at r=0.3 to 54.6% at r=1.0.

</details>


### [48] [Language Model Representations for Efficient Few-Shot Tabular Classification](https://arxiv.org/abs/2602.15844)
*Inwon Kang,Parikshit Ram,Yi Zhou,Horst Samulowitz,Oshani Seneviratne*

Main category: cs.CL

TL;DR: 本文提出了一种利用大语言模型（LLM）内嵌的现有能力对Web端结构化表格数据进行少样本分类的方法（TaRL），达到接近专有模型的效果。


<details>
  <summary>Details</summary>
Motivation: Web上的表格数据丰富，但结构和语义异构，难以统一处理。现有大语言模型已广泛部署，如能复用它们进行表格分类，将减少定制化模型和重复训练的需求。

Method: 提出TaRL范式：直接利用LLM得到表格行的语义嵌入。发现直接应用效果不佳，基于此，提出去除所有嵌入的共性分量和软最大值温度校准两个关键技术；进一步借助基于手工特征的元学习器预测合适温度。

Result: 在少样本（k≤32）的语义丰富表格分类任务上，增强后的TaRL方案能取得与SOTA模型相当的表现。

Conclusion: 实验结果表明，结合嵌入处理与温度校准，能有效复用现有LLM基础设施，实现高效的Web结构化表格理解，无需专门训练新模型。

Abstract: The Web is a rich source of structured data in the form of tables, from product catalogs and knowledge bases to scientific datasets. However, the heterogeneity of the structure and semantics of these tables makes it challenging to build a unified method that can effectively leverage the information they contain. Meanwhile, Large language models (LLMs) are becoming an increasingly integral component of web infrastructure for tasks like semantic search. This raises a crucial question: can we leverage these already-deployed LLMs to classify structured data in web-native tables (e.g., product catalogs, knowledge base exports, scientific data portals), avoiding the need for specialized models or extensive retraining? This work investigates a lightweight paradigm, $\textbf{Ta}$ble $\textbf{R}$epresentation with $\textbf{L}$anguage Model~($\textbf{TaRL}$), for few-shot tabular classification that directly utilizes semantic embeddings of individual table rows. We first show that naive application of these embeddings underperforms compared to specialized tabular models. We then demonstrate that their potentials can be unlocked with two key techniques: removing the common component from all embeddings and calibrating the softmax temperature. We show that a simple meta-learner, trained on handcrafted features, can learn to predict an appropriate temperature. This approach achieves performance comparable to state-of-the-art models in low-data regimes ($k \leq 32$) of semantically-rich tables. Our findings demonstrate the viability of reusing existing LLM infrastructure for efficient semantics-driven pathway to reuse existing LLM infrastructure for Web table understanding.

</details>


### [49] [KD4MT: A Survey of Knowledge Distillation for Machine Translation](https://arxiv.org/abs/2602.15845)
*Ona de Gibert,Joseph Attieh,Timothee Mickus,Yves Scherrer,Jörg Tiedemann*

Main category: cs.CL

TL;DR: 本综述系统梳理了105篇知识蒸馏在机器翻译（KD4MT）领域的研究，总结了主要方法、应用趋势与研究空白，并提供实用指南和风险提醒。


<details>
  <summary>Details</summary>
Motivation: 随着NLP模型体积不断变大，知识蒸馏作为压缩工具备受关注。相比于一般NLP任务，机器翻译场景下的知识蒸馏不仅用于模型压缩，更是提高翻译质量和指导学习的重要手段，因此需要专门梳理和分析其研究进展。

Method: 本综述面向非专业读者介绍了MT和KD的基本概念，回顾了适用于机器翻译的主流知识蒸馏方法，对105篇相关论文进行了系统分类，按照方法创新点和实际应用场景两方面梳理了进展，并通过定性和定量分析总结了趋势、共性与不足。

Result: 分析发现，KD4MT研究存在趋势趋同、缺乏统一评价体系、实际应用风险（如幻觉和偏见扩大）等共性问题，并归纳了各类方法的适用情形，提供了选型建议和风险提示。同时还收集汇编了主要方法数据库及术语表作为资源。

Conclusion: KD在机器翻译领域用途多样，但当前仍缺乏标准化评估体系及应对潜在风险措施。随着大模型的发展，KD4MT领域面临新的机遇和挑战，需持续关注效果、效率与安全性的平衡。

Abstract: Knowledge Distillation (KD) as a research area has gained a lot of traction in recent years as a compression tool to address challenges related to ever-larger models in NLP. Remarkably, Machine Translation (MT) offers a much more nuanced take on this narrative: in MT, KD also functions as a general-purpose knowledge transfer mechanism that shapes supervision and translation quality as well as efficiency.
  This survey synthesizes KD for MT (KD4MT) across 105 papers (through October 1, 2025). We begin by introducing both MT and KD for non-experts, followed by an overview of the standard KD approaches relevant to MT applications. Subsequently, we categorize advances in the KD4MT literature based on (i) their methodological contributions and (ii) their practical applications. Our qualitative and quantitative analyses identify common trends in the field and highlight key research gaps as well as the absence of unified evaluation practice for KD methods in MT. We further provide practical guidelines for selecting a KD method in concrete settings and highlight potential risks associated with the application of KD to MT such as increased hallucination and bias amplification. Finally, we discuss the role of LLMs in re-shaping the KD4MT field. To support further research, we complement our survey with a publicly available database summarizing the main characteristics of the surveyed KD methods and a glossary of key terms.

</details>


### [50] [Gated Tree Cross-attention for Checkpoint-Compatible Syntax Injection in Decoder-Only LLMs](https://arxiv.org/abs/2602.15846)
*Xinyu Gao,Shaonan Wang,Nai Ding*

Main category: cs.CL

TL;DR: 提出一种名为GTCA的新方法，通过引入可控的句法结构分支，增强大语言模型对句法扰动的鲁棒性，不影响其原有性能。


<details>
  <summary>Details</summary>
Motivation: 现有解码器型大语言模型虽然表现强大，但对小的语法扰动敏感，影响推理的可靠性。直接在已有模型中引入明确的句法结构会干扰其预训练能力，因此需要一种既能增强句法鲁棒性又兼容原有检查点的方法。

Method: 设计了一种可以与现有模型检查点兼容的门控树形交叉注意力（GTCA）分支。该方法利用外部预计算的句法短语记忆，引入token更新掩码以及分阶段训练，精准控制结构信息的注入方式和时机，而无需改动主干Transformer架构。

Result: 在多个基准测试和不同Transformer骨干上，GTCA在增强句法鲁棒性的同时，不会降低多项选择问答(MCQA)或常识推理能力，优于继续训练的基线模型。

Conclusion: GTCA方法为只解码型LLMs模型在不更改主结构的前提下显著提升语法鲁棒性，提供了一种实用的技术路径。

Abstract: Decoder-only large language models achieve strong broad performance but are brittle to minor grammatical perturbations, undermining reliability for downstream reasoning. However, directly injecting explicit syntactic structure into an existing checkpoint can interfere with its pretrained competence. We introduce a checkpoint-compatible gated tree cross-attention (GTCA) branch that reads precomputed constituency chunk memory while leaving backbone architecture unchanged. Our design uses a token update mask and staged training to control the scope and timing of structural updates. Across benchmarks and Transformer backbones, GTCA strengthens syntactic robustness beyond continued-training baselines without compromising Multiple-Choice QA performance or commonsense reasoning, providing a practical checkpoint-compatible route to more syntax-robust decoder-only LLMs.

</details>


### [51] [Do Personality Traits Interfere? Geometric Limitations of Steering in Large Language Models](https://arxiv.org/abs/2602.15847)
*Pranav Bhandari,Usman Naseem,Mehwish Nasim*

Main category: cs.CL

TL;DR: 本论文研究了大语言模型（LLMs）中通过向量注入实现个性特征操控的有效性，发现个性特征之间即使经过正交化处理仍存在耦合，难以完全独立控制。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs普遍假设不同个性特征可以通过注入特征向量独立控制，但这一前提实际是否成立尚未被严谨检验。该工作希望从几何角度揭示个性操控的本质限制。

Method: 作者从两类模型（LLaMA-3-8B与Mistral-8B）中提取“大五人格”特征的调控向量，并采用不同的几何条件化方案（包括软、硬正交化）来分析特征向量间的关系与耦合情况。

Result: 实验表明，不同人格特质的操控向量表现出很强的几何相关性，操控单一特质时会影响其它特质，即使实施严格正交化也难以完全消除行为上的交叉影响，同时过度正交会削弱调控能力。

Conclusion: LLMs中的人格特质实际处于一个轻微耦合的子空间内，完全独立地调控各特质较为困难，这对个性化操控方法提出了限制。

Abstract: Personality steering in large language models (LLMs) commonly relies on injecting trait-specific steering vectors, implicitly assuming that personality traits can be controlled independently. In this work, we examine whether this assumption holds by analysing the geometric relationships between Big Five personality steering directions. We study steering vectors extracted from two model families (LLaMA-3-8B and Mistral-8B) and apply a range of geometric conditioning schemes, from unconstrained directions to soft and hard orthonormalisation. Our results show that personality steering directions exhibit substantial geometric dependence: steering one trait consistently induces changes in others, even when linear overlap is explicitly removed. While hard orthonormalisation enforces geometric independence, it does not eliminate cross-trait behavioural effects and can reduce steering strength. These findings suggest that personality traits in LLMs occupy a slightly coupled subspace, limiting fully independent trait control.

</details>


### [52] [Can LLMs Assess Personality? Validating Conversational AI for Trait Profiling](https://arxiv.org/abs/2602.15848)
*Andrius Matšenas,Anet Lello,Tõnis Lees,Hans Peep,Kim Lilii Tamm*

Main category: cs.CL

TL;DR: 本研究验证了大语言模型（LLM）可以作为问卷式人格测评的动态替代方法。通过实验，比较了LLM对话获得的人格得分与IPIP-50问卷的差异，并考察了用户对两种方法准确性的看法。结果显示，部分人格维度得分等效，用户对LLM生成的人格画像认可度高，表明会话式AI在人格测评领域具有潜力。


<details>
  <summary>Details</summary>
Motivation: 当前人格评估主要依赖标准化问卷，但这种方式可能有局限性。大语言模型因其交互性和灵活性，有望成为更动态、自然的人格测评工具。因此，研究动机在于验证LLM在此领域的有效性和可替代性。

Method: 采用被试内实验设计，招募33名参与者。比较通过与LLM的引导对话获得的Big Five人格评分和经典IPIP-50问卷评分，同时收集用户对双方测评准确性的主观评价。

Result: LLM测评与问卷在责任心、开放性、神经质维度得分无显著差异，收敛效度中等（相关系数0.38-0.58）。宜人性和外向性维度存在显著性差异。大多数参与者认为LLM生成的画像与问卷结果一样准确。

Conclusion: 会话式人工智能可作为传统人格测评的新兴替代方式，尽管部分维度需进一步校准，总体具有较高的用户接受度和一定的有效性，值得进一步研究和推广。

Abstract: This study validates Large Language Models (LLMs) as a dynamic alternative to questionnaire-based personality assessment. Using a within-subjects experiment (N=33), we compared Big Five personality scores derived from guided LLM conversations against the gold-standard IPIP-50 questionnaire, while also measuring user-perceived accuracy. Results indicate moderate convergent validity (r=0.38-0.58), with Conscientiousness, Openness, and Neuroticism scores statistically equivalent between methods. Agreeableness and Extraversion showed significant differences, suggesting trait-specific calibration is needed. Notably, participants rated LLM-generated profiles as equally accurate as traditional questionnaire results. These findings suggest conversational AI offers a promising new approach to traditional psychometrics.

</details>


### [53] [Preference Optimization for Review Question Generation Improves Writing Quality](https://arxiv.org/abs/2602.15849)
*Karun Sharma,Vidushee Vats,Shengzhi Li,Yuxiang Wang,Zhongtian Sun,Prayag Tiwari*

Main category: cs.CL

TL;DR: 本文提出IntelliReward和IntelliAsk两种新方法，提升LLM生成同行评审问题的质量，特别是在推理和写作等复杂任务上的表现优于以往方法。


<details>
  <summary>Details</summary>
Motivation: 目前大多数基于LLM的方法在生成学术评审问题时表现为表层，依赖于论文首页内容，未能达到专家级深度和基于证据的标准，亟需改进。

Method: 作者提出了IntelliReward（基于可训练多头transformer的奖励模型）和IntelliAsk（使用DAPO优化的自动问题生成模型）。IntelliReward能更好预测专家偏好，IntelliAsk能生成更具证据、努力和深度的问题。

Result: IntelliAsk在多个推理和写作评测中显著优于Qwen3-32B等基础模型，在MuSR和WritingBench任务中取得更高分数。

Conclusion: 新方法能够提升LLM在自动生成高质量学术评审问题上的表现，且公开发布模型和数据，利于后续自动化评测和领域发展。

Abstract: Peer review relies on substantive, evidence-based questions, yet existing LLM-based approaches often generate surface-level queries, drawing over 50\% of their question tokens from a paper's first page. To bridge this gap, we develop IntelliReward, a novel reward model built from a frozen autoregressive LLM with trainable multi-head transformers over the final 50 token states, which outperforms API-based SFT baselines in predicting expert-level human preferences. By applying Decoupled Clip and Dynamic Sampling Policy Optimization (DAPO) with IntelliReward, we train IntelliAsk, a question-generation model aligned with human standards of effort, evidence, and grounding. We find consistent improvements on reasoning and writing benchmarks, suggesting reviewer-question quality correlates with broader capabilities. Compared to the Qwen3-32B base model, IntelliAsk shows measurable gains across diverse benchmarks, specifically improving performance on reasoning tasks like MuSR (68.3 vs 64.7 Acc) and complex writing evaluations such as WritingBench (8.31 vs 8.07). We release our implementation, expert preference annotations, and the IntelliReward model to provide an automatic evaluation benchmark for grounding, effort, and evidence in LLM-generated review questions.

</details>


### [54] [Large Language Models for Assisting American College Applications](https://arxiv.org/abs/2602.15850)
*Zhengliang Liu,Weihang You,Peng Shu,Junhao Chen,Yi Pan,Hanqi Jiang,Yiwei Li,Zhaojun Ding,Chao Cao,Xinliang Li,Yifan Zhou,Ruidong Zhang,Shaochen Xu,Wei Ruan,Huaqin Zhao,Dajiang Zhu,Tianming Liu*

Main category: cs.CL

TL;DR: 本文提出了EZCollegeApp系统，利用大语言模型（LLM）帮助高中生高效、准确地填写美国大学申请表，方法包括结构化表单、权威文件溯源、以及保持用户控制，系统开源。


<details>
  <summary>Details</summary>
Motivation: 当前美国大学申请流程繁琐，政策不一，表单重复且问题模糊，申请者需频繁查阅多方信息，导致效率低下、易出错，亟需智能辅助工具简化流程。

Method: 提出了“mapping-first”范式，先对表单进行结构理解，再生成答案；系统具备官方文件文档摄取、检索增强问答、人工审核对话界面，且不自动提交表单；架构包括数据管线、内部表示、安全与隐私措施，并结合自动测试和人工质量评估。

Result: 系统可为申请者在各类异构申请门户之间，实现一致、权威的表单填写指导，并保证生成答案可溯源权威文件，用户保留最终表单决定权。经过自动化和人工评测，证明系统的有效性与实用性。

Conclusion: EZCollegeApp可以显著提升大学申请的效率与准确性，降低信息混乱与表单填写成本。系统已开源，便于社区推广和持续优化，对推动公平、高效的大学入学申请具有积极意义。

Abstract: American college applications require students to navigate fragmented admissions policies, repetitive and conditional forms, and ambiguous questions that often demand cross-referencing multiple sources. We present EZCollegeApp, a large language model (LLM)-powered system that assists high-school students by structuring application forms, grounding suggested answers in authoritative admissions documents, and maintaining full human control over final responses. The system introduces a mapping-first paradigm that separates form understanding from answer generation, enabling consistent reasoning across heterogeneous application portals. EZCollegeApp integrates document ingestion from official admissions websites, retrieval-augmented question answering, and a human-in-the-loop chatbot interface that presents suggestions alongside application fields without automated submission. We describe the system architecture, data pipeline, internal representations, security and privacy measures, and evaluation through automated testing and human quality assessment. Our source code is released on GitHub (https://github.com/ezcollegeapp-public/ezcollegeapp-public) to facilitate the broader impact of this work.

</details>


### [55] [Narrative Theory-Driven LLM Methods for Automatic Story Generation and Understanding: A Survey](https://arxiv.org/abs/2602.15851)
*David Y. Liu,Aditya Joshi,Paul Dawson*

Main category: cs.CL

TL;DR: 本文综述了大型语言模型（LLMs）在自动生成和理解叙事任务中的应用，总结了当前的研究方法和面临的挑战，并展望了未来的发展方向。


<details>
  <summary>Details</summary>
Motivation: LLMs 在自然语言处理中的叙事生成和理解展现出巨大潜力，然而目前缺乏针对叙事任务的统一定义和评测标准，导致模型间难以直接比较，推动更系统且理论驱动的叙事研究势在必行。

Method: 作者调研了自然语言处理领域与叙事学的交叉研究，构建了一个基于叙事学理论的任务分类体系，并分析了在数据集、理论、技术流程、提示和微调等方面的研究趋势，强调LLMs如何促进NLP流程与抽象叙事概念的结合。

Result: 调研发现，虽然LLMs能为NLP与叙事研究提供新机会并促进学科交叉，但由于缺乏统一标准，评估和比较模型表现仍存在挑战。单一、通用化的叙事质量基准难以实现，应更关注基于理论的、多维叙事属性的细化评测和应用。

Conclusion: 作者建议未来研究重心应放在基于理论的单项叙事属性指标的定义与优化，以及大规模、理论驱动的文学、社会和文化分析。同时，创设能验证或优化叙事理论的实验。该综述为NLP叙事研究提供了理论基础和整体视角，助力系统性、理论化的跨学科进展。

Abstract: Applications of narrative theories using large language models (LLMs) deliver promising use-cases in automatic story generation and understanding tasks. Our survey examines how natural language processing (NLP) research engages with fields of narrative studies, and proposes a taxonomy for ongoing efforts that reflect established distinctions in narratology. We discover patterns in the following: narrative datasets and tasks, narrative theories and NLP pipeline and methodological trends in prompting and fine-tuning. We highlight how LLMs enable easy connections of NLP pipelines with abstract narrative concepts and opportunities for interdisciplinary collaboration. Challenges remain in attempts to work towards any unified definition or benchmark of narrative related tasks, making model comparison difficult. For future directions, instead of the pursuit of a single, generalised benchmark for 'narrative quality', we believe that progress benefits more from efforts that focus on the following: defining and improving theory-based metrics for individual narrative attributes to incrementally improve model performance; conducting large-scale, theory-driven literary/social/cultural analysis; and creating experiments where outputs can be used to validate or refine narrative theories. This work provides a contextual foundation for more systematic and theoretically informed narrative research in NLP by providing an overview to ongoing research efforts and the broader narrative studies landscape.

</details>


### [56] [Building Safe and Deployable Clinical Natural Language Processing under Temporal Leakage Constraints](https://arxiv.org/abs/2602.15852)
*Ha Na Cho,Sairam Sutari,Alexander Lopez,Hansen Bow,Kai Zheng*

Main category: cs.CL

TL;DR: 本文关注于医院出院规划中临床NLP模型在面对时间泄漏及词汇泄漏问题时的安全性与可部署性，并提出解释性审核流程来提升模型的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有面向临床文本的NLP预测模型易因文档中隐性透露未来医疗决策的信息（时间和词汇泄漏）而导致“预测能力”虚高，这在实际临床部署中可能带来安全隐患和不合理干预。

Method: 作者提出了一种轻量级的审核流程，将可解释性分析纳入模型开发，主动识别并抑制容易泄漏未来信息的信号，然后进行最终训练。以择期脊柱手术后次日出院预测为例，评估审核流程对模型预测行为、校准和安全相关权衡的影响。

Result: 经审核的模型在概率预测上更为保守且校准更好，对与出院相关的词汇信号依赖减弱。

Conclusion: 临床NLP系统要实际部署，必须优先考虑时间有效性、模型校准性及行为鲁棒性，而非单纯追求理想化的预测性能。

Abstract: Clinical natural language processing (NLP) models have shown promise for supporting hospital discharge planning by leveraging narrative clinical documentation. However, note-based models are particularly vulnerable to temporal and lexical leakage, where documentation artifacts encode future clinical decisions and inflate apparent predictive performance. Such behavior poses substantial risks for real-world deployment, where overconfident or temporally invalid predictions can disrupt clinical workflows and compromise patient safety. This study focuses on system-level design choices required to build safe and deployable clinical NLP under temporal leakage constraints. We present a lightweight auditing pipeline that integrates interpretability into the model development process to identify and suppress leakage-prone signals prior to final training. Using next-day discharge prediction after elective spine surgery as a case study, we evaluate how auditing affects predictive behavior, calibration, and safety-relevant trade-offs. Results show that audited models exhibit more conservative and better-calibrated probability estimates, with reduced reliance on discharge-related lexical cues. These findings emphasize that deployment-ready clinical NLP systems should prioritize temporal validity, calibration, and behavioral robustness over optimistic performance.

</details>


### [57] [A Lightweight Explainable Guardrail for Prompt Safety](https://arxiv.org/abs/2602.15853)
*Md Asiful Islam,Mihai Surdeanu*

Main category: cs.CL

TL;DR: 提出了一种轻量级可解释保护方法LEG，用于识别不安全的提示，并能解释判断依据。该方法训练高效，模型体积小，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 已有检测不安全提示的模型可解释性有限且模型体积较大，影响实际部署和信任度。作者希望设计同时高效、可解释且轻量级的方法。

Method: LEG采用多任务学习架构，同时训练提示分类器和解释分类器，后者对提示词进行标注以解释安全/不安全的判决。此外，利用合成可解释性训练数据（采用新策略减少大模型的确认偏差），以及全新损失函数融合全局信号、交叉熵及带不确定性的focal loss。

Result: LEG在三组数据集内域和外域任务中，在提示分类和可解释性方面均达到了与最优方法相当或更好的表现，且模型参数显著更小。

Conclusion: LEG是一种高效、可解释、轻量级的不安全提示检测方法，优于现有方法，具有良好的应用前景。作者承诺开源全部模型及数据集。

Abstract: We propose a lightweight explainable guardrail (LEG) method for the classification of unsafe prompts. LEG uses a multi-task learning architecture to jointly learn a prompt classifier and an explanation classifier, where the latter labels prompt words that explain the safe/unsafe overall decision. LEG is trained using synthetic data for explainability, which is generated using a novel strategy that counteracts the confirmation biases of LLMs. Lastly, LEG's training process uses a novel loss that captures global explanation signals and combines cross-entropy and focal losses with uncertainty-based weighting. LEG obtains equivalent or better performance than the state-of-the-art for both prompt classification and explainability, both in-domain and out-of-domain on three datasets, despite the fact that its model size is considerably smaller than current approaches. If accepted, we will release all models and the annotated dataset publicly.

</details>


### [58] [Decoupling Strategy and Execution in Task-Focused Dialogue via Goal-Oriented Preference Optimization](https://arxiv.org/abs/2602.15854)
*Jingyi Xu,Xingyu Ren,Zhiqiang You,Yumeng Zhang,Zhoupeng Shou*

Main category: cs.CL

TL;DR: 提出了一种面向目标的偏好优化（GOPO）方法，用分层强化学习提升任务型对话系统在长对话任务中的表现，并在公开及电商数据集上验证了效果明显优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的任务型对话系统训练方法多基于单步生成或偏好优化，难以与长任务对话的最终成果对齐，导致系统在实际复杂任务中表现有限，亟需新的优化范式。

Method: GOPO采用分层强化学习架构，分离策略规划和回复生成。由Expert Agent在多轮会话轨迹层面优化目标达成偏好，Customer Service Agent根据策略生成符合目标的回复，并引入了基于真实电商数据的序列级评价指标TSE。

Result: GOPO在Mgshop等数据集的TSE指标上相比主流方法（如PPO、Memento）提升7.7%-10.3%，大模型（14B参数）在TSE上优于Qwen-235B和GPT-5.2。消融实验表明Expert Agent对长任务优化至关重要，并在多数据集上有一致提升。

Conclusion: GOPO为商业场景下任务型对话系统建立了新范式，显著提升了序列级任务完成度，代码和数据集将公开，有助于行业发展。

Abstract: Large language models show potential in task-oriented dialogue systems, yet existing training methods often rely on token-level likelihood or preference optimization, which poorly align with long-horizon task success. To address this, we propose Goal-Oriented Preference Optimization (GOPO), a hierarchical reinforcement learning framework that decouples strategy planning from response generation via an Expert Agent and a Customer Service Agent. The Expert Agent optimizes multi-turn goal preferences at the dialogue-trajectory level, while the Customer Service Agent generates responses strictly aligned with the selected strategy. We evaluate GOPO on public benchmarks and e-commerce customer service datasets, and introduce Task-focused Sequential Engagement (TSE), a sequence-level metric derived from real e-commerce interaction data. On the Mgshop dataset, GOPO improves TSE by 7.7% and 10.3% over PPO and Memento, with consistent gains in sequence-level reward and generation quality. Furthermore, a 14B model trained with GOPO achieves 2.7% and 1.5% higher TSE than Qwen-235B and GPT-5.2, respectively. Ablation studies confirm the Expert Agent's critical role in long-horizon optimization. GOPO demonstrates consistent improvements across other datasets as well. This work establishes a new paradigm for task-oriented dialogue systems in commercial scenarios, with code and datasets to be made public.

</details>


### [59] [Rethinking Soft Compression in Retrieval-Augmented Generation: A Query-Conditioned Selector Perspective](https://arxiv.org/abs/2602.15856)
*Yunhao Liu,Zian Jia,Xinyu Gao,Kanjun Xu,Yun Xiong*

Main category: cs.CL

TL;DR: SeleCom方法针对RAG系统中的软压缩不足与冗余问题，将编码器重新定位为查询相关信息选择器，在大规模合成QA数据上训练，显著提升效果并降低计算消耗。


<details>
  <summary>Details</summary>
Motivation: 现有的软压缩方法虽然尝试通过压缩Embedding来减小长文档带来的计算压力，但由于采用了全压缩策略，导致模型压缩了所有信息，包括与输入查询无关的信息，这种方式限制了下游LLM生成表现，并且降低了与任务相关的信息密度，因此效果不佳。

Method: 提出SeleCom框架，将RAG中的编码器设计为基于查询选择信息，而非无差别全压缩。SeleCom采用仅解码器结构，在大量、难度分级的合成问答数据集上通过课程学习方式训练，从而精准选取与查询强相关的信息作为压缩输出。

Result: SeleCom在多个实验中，相比现有软压缩方法有明显优势，并且在许多任务上达到或超越了未压缩RAG的表现，同时将计算量和响应时延减少了33.8%到84.6%。

Conclusion: SeleCom显著缓解了软压缩失效及RAG检索冗余问题，实现了更高效且高性能的知识增强生成，为大模型应用于长文档检索和生成任务提供了新的有效途径。

Abstract: Retrieval-Augmented Generation (RAG) effectively grounds Large Language Models (LLMs) with external knowledge and is widely applied to Web-related tasks. However, its scalability is hindered by excessive context length and redundant retrievals. Recent research on soft context compression aims to address this by encoding long documents into compact embeddings, yet they often underperform non-compressed RAG due to their reliance on auto-encoder-like full-compression that forces the encoder to compress all document information regardless of relevance to the input query.
  In this work, we conduct an analysis on this paradigm and reveal two fundamental limitations: (I) Infeasibility, full-compression conflicts with the LLM's downstream generation behavior; and (II) Non-necessity: full-compression is unnecessary and dilutes task-relevant information density. Motivated by these insights, we introduce SeleCom, a selector-based soft compression framework for RAG that redefines the encoder's role as query-conditioned information selector. The selector is decoder-only and is trained with a massive, diverse and difficulty-graded synthetic QA dataset with curriculum learning.
  Extensive experiments show that SeleCom significantly outperforms existing soft compression approaches and achieves competitive or superior performance to non-compression baselines, while reducing computation and latency by 33.8%~84.6%.

</details>


### [60] [Multi-source Heterogeneous Public Opinion Analysis via Collaborative Reasoning and Adaptive Fusion: A Systematically Integrated Approach](https://arxiv.org/abs/2602.15857)
*Yi Liu*

Main category: cs.CL

TL;DR: 本文提出了一个创新性的CRAF框架，融合传统特征方法和大语言模型，通过多阶段推理机制分析多平台、多模态舆情数据，显著提升了话题聚类和情感分析的准确性，并大幅度降低了新平台标注数据需求。


<details>
  <summary>Details</summary>
Motivation: 多平台（如微博、抖音、快手等）舆情分析面临结构、语义和偏倚等异构挑战，现有方法难以兼顾各平台特性与总体融合效能，因此亟需新的系统性方法提升跨平台舆情分析的鲁棒性和适应性。

Method: 提出CRAF框架，创新点包括：1）跨平台协同注意力对齐语义表征并保留平台特性；2）分层自适应融合机制，动态加权特征；3）主题与情感分布联合优化的共享潜在空间学习；4）结合OCR、ASR和视觉情感分析的新型多模态视频信息抽取能力。

Result: 理论分析显示CRAF相较于独立建模有更紧的泛化界（误差项降低）；在三个多平台数据集上，话题聚类ARI达到0.76（比最佳基线提升4.1%），情感分析F1达到0.84（提升3.8%）；该框架还能将新平台的标注数据需求降低75%。

Conclusion: CRAF框架能有效整合多源异构数据，提升跨平台舆情分析效果，并展现出极强的适应性和标注节省潜力，是多平台舆情理解的重要进展。

Abstract: The analysis of public opinion from multiple heterogeneous sources presents significant challenges due to structural differences, semantic variations, and platform-specific biases. This paper introduces a novel Collaborative Reasoning and Adaptive Fusion (CRAF) framework that systematically integrates traditional feature-based methods with large language models (LLMs) through a structured multi-stage reasoning mechanism. Our approach features four key innovations: (1) a cross-platform collaborative attention module that aligns semantic representations while preserving source-specific characteristics, (2) a hierarchical adaptive fusion mechanism that dynamically weights features based on both data quality and task requirements, (3) a joint optimization strategy that simultaneously learns topic representations and sentiment distributions through shared latent spaces, and (4) a novel multimodal extraction capability that processes video content from platforms like Douyin and Kuaishou by integrating OCR, ASR, and visual sentiment analysis. Theoretical analysis demonstrates that CRAF achieves a tighter generalization bound with a reduction of O(sqrt(d log K / m)) compared to independent source modeling, where d is feature dimensionality, K is the number of sources, and m is sample size. Comprehensive experiments on three multi-platform datasets (Weibo-12, CrossPlatform-15, NewsForum-8) show that CRAF achieves an average topic clustering ARI of 0.76 (4.1% improvement over best baseline) and sentiment analysis F1-score of 0.84 (3.8% improvement). The framework exhibits strong cross-platform adaptability, reducing the labeled data requirement for new platforms by 75%.

</details>


### [61] [State Design Matters: How Representations Shape Dynamic Reasoning in Large Language Models](https://arxiv.org/abs/2602.15858)
*Annie Wong,Aske Plaat,Thomas Bäck,Niki van Stein,Anna V. Kononova*

Main category: cs.CL

TL;DR: 论文系统考察了在动态环境中，大语言模型（LLMs）面对随交互变化的环境时，状态表示方式对其决策表现的影响。通过不同的状态摘要、结构和空间表征比较，发现状态表示的设计显著影响模型性能。


<details>
  <summary>Details</summary>
Motivation: 以往大语言模型多聚焦于静态推理任务，但真实环境（如Sequential Decision Making）随时变化，模型需要动态感知和响应。此前关于“状态”如何被表示对模型决策表现的影响研究较少。

Method: 固定模型参数，系统化地在顺序决策基准测试下，变更三种状态表示方式：（1）粒度（长文本vs摘要）；（2）结构（自然语言vs符号）；（3）空间锚定（纯文本vs图片/文本地图编码），比较模型表现。

Result: （1）轨迹摘要能降噪并改善长时推理表现；（2）自然语言表征在各种模型下最稳健，结构化表示仅对有结构输出强先验（如json schema）的模型有效；（3）图片可带来有限收益，但文本化空间编码效果更佳，其优势源于编码过程促进空间推理，而非空间信息本身。

Conclusion: 状态的具体表示设计会显著影响模型决策表现，这一影响独立于信息本身的多少。但即使使用更好表征，当前LLM和VLM在长时任务、多子任务并行时依然稳定性不足。

Abstract: As large language models (LLMs) move from static reasoning tasks toward dynamic environments, their success depends on the ability to navigate and respond to an environment that changes as they interact at inference time. An underexplored factor in these settings is the representation of the state. Holding model parameters fixed, we systematically vary three key aspects: (1) state granularity (long form versus summary), (2) structure (natural language versus symbolic), and (3) spatial grounding (text-only versus images or textual map encodings) across sequential decision-making benchmarks. We find that trajectory summarisation improves performance by reducing noise and stabilising long-horizon reasoning. Second, natural language representations are the most robust across models, whereas structured encodings help mainly for models with strong code or structured output priors, such as JSON schemas. Third, while image-inputs show some benefit, text-based spatial encodings prove most effective. This advantage stems not from the spatial information itself, but from the act of construction, which compels the model to perform the spatial reasoning that static input does not elicit. Overall, we demonstrate that design choices for representing state are a decisive factor in performance, distinct from the availability of information itself. We note, however, that even with improved representations, current LLMs and VLMs remain brittle over long horizons, particularly when they must synthesise information to manage multiple subtasks to reach a goal.

</details>


### [62] [From Transcripts to AI Agents: Knowledge Extraction, RAG Integration, and Robust Evaluation of Conversational AI Assistants](https://arxiv.org/abs/2602.15859)
*Krittin Pachtrachai,Petmongkon Pornpichitsuwan,Wachiravit Modecrua,Touchapon Kraisingkorn*

Main category: cs.CL

TL;DR: 本文提出了一种从历史通话记录端到端构建对话AI助手的框架，并在房产与招聘高实时需求领域取得了高自动化和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有面向客户的对话AI建设困难，主要原因包括数据噪声大、知识碎片化和必须实现准确的人机交接，尤其是对实时信息依赖高的领域更具挑战性。

Method: 首先，用简化版的PIPA框架对历史通话进行评分和筛选，保留高质量对话。然后，利用大型语言模型从优质记录中提取结构化知识，并作为RAG系统的唯一知识基础。AI助手的行为通过逐步细化的Prompt调优实现，从单体到模块化，确保其一致性与安全性。评估采用基于通话记录的用户模拟器，量化覆盖率、准确率和人工转接情况，并进行红队测试以检验其对攻击的鲁棒性。

Result: 在房产和专业招聘两大高难自动化领域，助手可自主处理约30%的来电，事实性准确率和拒答能力接近完美，并在对抗性测试下表现出强鲁棒性。

Conclusion: 本文框架在高实时依赖行业实现了可控、高准确度及自动化的对话助手构建，为类似复杂领域的自动助理研发提供了可行思路。

Abstract: Building reliable conversational AI assistants for customer-facing industries remains challenging due to noisy conversational data, fragmented knowledge, and the requirement for accurate human hand-off - particularly in domains that depend heavily on real-time information. This paper presents an end-to-end framework for constructing and evaluating a conversational AI assistant directly from historical call transcripts. Incoming transcripts are first graded using a simplified adaptation of the PIPA framework, focusing on observation alignment and appropriate response behavior, and are filtered to retain only high-quality interactions exhibiting coherent flow and effective human agent responses. Structured knowledge is then extracted from curated transcripts using large language models (LLMs) and deployed as the sole grounding source in a Retrieval-Augmented Generation (RAG) pipeline. Assistant behavior is governed through systematic prompt tuning, progressing from monolithic prompts to lean, modular, and governed designs that ensure consistency, safety, and controllable execution. Evaluation is conducted using a transcript-grounded user simulator, enabling quantitative measurement of call coverage, factual accuracy, and human escalation behavior. Additional red teaming assesses robustness against prompt injection, out-of-scope, and out-of-context attacks. Experiments are conducted in the Real Estate and Specialist Recruitment domains, which are intentionally challenging and currently suboptimal for automation due to their reliance on real-time data. Despite these constraints, the assistant autonomously handles approximately 30 percents of calls, achieves near-perfect factual accuracy and rejection behavior, and demonstrates strong robustness under adversarial testing.

</details>


### [63] [Reranker Optimization via Geodesic Distances on k-NN Manifolds](https://arxiv.org/abs/2602.15860)
*Wen G. Gong*

Main category: cs.CL

TL;DR: Maniscope是一种用于检索增强生成（RAG)的几何重排序方法，能大幅提升效果与速度，优于主流方法，并能支持实时应用。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG神经重排序方法（如cross-encoder或大模型）计算资源消耗大，延迟高，难以用于需要快速响应的场景。因此，需要能更高效且精度不降低的重排序方法。

Method: Maniscope通过在候选文档上构建k近邻流形，计算测地距离，结合全局余弦相似性与局部流形结构，捕获常规欧氏度量无法描述的语义结构，从而实现更精细的重排序。算法复杂度为O(ND + M^2D + Mk logk), 支持极低延迟。

Result: 在BEIR八个基准数据集上评估，Maniscope在三个最难数据集上优于HNSW基线（NDCG@3提升最多7%），平均速度提升3倍以上。对比cross-encoder, Maniscope仅2%内准确率差距但延迟降低10-45倍。与LLM重排序相比，性能几乎持平但速度快840倍。

Conclusion: Maniscope在保证高精度的同时显著降低延迟和资源消耗，是实时RAG部署的实用选择。团队计划开源该方法，有潜力被广泛采用。

Abstract: Current neural reranking approaches for retrieval-augmented generation (RAG) rely on cross-encoders or large language models (LLMs), requiring substantial computational resources and exhibiting latencies of 3-5 seconds per query. We propose Maniscope, a geometric reranking method that computes geodesic distances on k-nearest neighbor (k-NN) manifolds constructed over retrieved document candidates. This approach combines global cosine similarity with local manifold geometry to capture semantic structure that flat Euclidean metrics miss. Evaluating on eight BEIR benchmark datasets (1,233 queries), Maniscope outperforms HNSW graph-based baseline on the three hardest datasets (NFCorpus: +7.0%, TREC-COVID: +1.6%, AorB: +2.8% NDCG@3) while being 3.2x faster (4.7 ms vs 14.8 ms average). Compared to cross-encoder rerankers, Maniscope achieves within 2% accuracy at 10-45x lower latency. On TREC-COVID, LLM-Reranker provides only +0.5% NDCG@3 improvement over Maniscope at 840x higher latency, positioning Maniscope as a practical alternative for real-time RAG deployment. The method requires O(N D + M^2 D + M k log k) complexity where M << N , enabling sub-10 ms latency. We plan to release Maniscope as open-source software.

</details>


### [64] [CAST: Achieving Stable LLM-based Text Analysis for Data Analytics](https://arxiv.org/abs/2602.15861)
*Jinxiang Xie,Zihao Li,Wei He,Rui Ding,Shi Han,Dongmei Zhang*

Main category: cs.CL

TL;DR: 本文提出了CAST框架，通过算法提示和显式推理路径增强LLM在结构化表格数据文本分析中的输出稳定性，在多个基准数据集上显著提升了标签和摘要任务的稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在表格数据的摘要和标签等文本分析任务中，输出稳定性不足，难以满足高要求的数据分析应用，需要一种提升输出一致性和可靠性的方法。

Method: 提出CAST框架，包含两大核心：1）算法化提示（Algorithmic Prompting），为模型推理提供明确的操作流程约束；2）先思考后生成（Thinking-before-Speaking），让模型在最终输出前做出中间表态。并引入了CAST-S和CAST-T两项指标用于评价摘要和标签任务中的输出稳定性。

Result: 在多个公开基准上，CAST在提升LLM输出稳定性方面优于所有对比基线，Stability Score最高提升达16.2%，且不影响甚至提升了输出质量。

Conclusion: CAST框架有效增强了LLM在结构化数据文本分析中的输出稳定性，有望为数据分析场景中的高可靠性文本生成提供新方案。

Abstract: Text analysis of tabular data relies on two core operations: \emph{summarization} for corpus-level theme extraction and \emph{tagging} for row-level labeling. A critical limitation of employing large language models (LLMs) for these tasks is their inability to meet the high standards of output stability demanded by data analytics. To address this challenge, we introduce \textbf{CAST} (\textbf{C}onsistency via \textbf{A}lgorithmic Prompting and \textbf{S}table \textbf{T}hinking), a framework that enhances output stability by constraining the model's latent reasoning path. CAST combines (i) Algorithmic Prompting to impose a procedural scaffold over valid reasoning transitions and (ii) Thinking-before-Speaking to enforce explicit intermediate commitments before final generation. To measure progress, we introduce \textbf{CAST-S} and \textbf{CAST-T}, stability metrics for bulleted summarization and tagging, and validate their alignment with human judgments. Experiments across publicly available benchmarks on multiple LLM backbones show that CAST consistently achieves the best stability among all baselines, improving Stability Score by up to 16.2\%, while maintaining or improving output quality.

</details>


### [65] [Enhancing Action and Ingredient Modeling for Semantically Grounded Recipe Generation](https://arxiv.org/abs/2602.15862)
*Guoshan Liu,Bin Zhu,Yian Li,Jingjing Chen,Chong-Wah Ngo,Yu-Gang Jiang*

Main category: cs.CL

TL;DR: 提出一种结合监督微调和强化微调的多模态模型，从美食图片更准确地生成语义正确的食谱。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型虽然能根据食物图片生成食谱，但结果常出现语义不正确的操作或食材，影响实际可用性。提升生成食谱的语义准确性非常有必要。

Method: 提出分两阶段的流程：(1) 用动作-推理数据集和食材语料进行监督微调，夯实模型基础；(2) 利用频率感知的奖励机制进行强化微调，提升对长尾动作和食材的预测能力。最后加入语义置信评分与修正模块（SCSR）过滤与修正不准预测。

Result: 在Recipe1M数据集上，方法实现了最新最优表现，语义准确度较以往方法大幅提升。

Conclusion: 结合语义感知机制的两阶段微调流程显著提升了多模态模型生成食谱时的语义准确性，优于传统单靠词面匹配的评估方法，有望促进更实用的智能食谱生成。

Abstract: Recent advances in Multimodal Large Language Models (MLMMs) have enabled recipe generation from food images, yet outputs often contain semantically incorrect actions or ingredients despite high lexical scores (e.g., BLEU, ROUGE). To address this gap, we propose a semantically grounded framework that predicts and validates actions and ingredients as internal context for instruction generation. Our two-stage pipeline combines supervised fine-tuning (SFT) with reinforcement fine-tuning (RFT): SFT builds foundational accuracy using an Action-Reasoning dataset and ingredient corpus, while RFT employs frequency-aware rewards to improve long-tail action prediction and ingredient generalization. A Semantic Confidence Scoring and Rectification (SCSR) module further filters and corrects predictions. Experiments on Recipe1M show state-of-the-art performance and markedly improved semantic fidelity.

</details>


### [66] [Not the Example, but the Process: How Self-Generated Examples Enhance LLM Reasoning](https://arxiv.org/abs/2602.15863)
*Daehoon Gwak,Minseo Jung,Junwoo Park,Minho Park,ChaeHun Park,Junha Hyung,Jaegul Choo*

Main category: cs.CL

TL;DR: 研究发现生成的few-shot示例提升推理表现，但其机制不明。本文证明，关键提升源自生成过程而非示例本身。通过对LLM不同架构和三种提示策略实验证明，整合式提示表现最佳。注意力分析进一步支持结论。


<details>
  <summary>Details</summary>
Motivation: 之前LLM通过自我生成few-shot示例提升推理能力，且能接近人工示例，但为什么有提升不明确，导致难以合理使用。作者希望揭示其机制，指导更有效的提示策略。

Method: 比较三种提示策略：零样本提示（Zero-shot）、整合式提示（Integrated，模型在统一提示内生成并解题）、解耦式提示（Decoupled，仅重用已生成示例但排除其产生过程）。在五种主流LLM架构和多类推理任务上系统实验，并分析提示过程中的注意力模式差异。

Result: 实验表明，整合式提示始终胜过零样本与解耦式提示，而解耦式相较零样本仅有微弱提升。注意力分析发现，整合式与解耦式提示在注意力分布上存在显著不同。

Conclusion: LLM自我生成few-shot示例带来推理表现提升的关键在于“生成过程”而非生成内容本身。这一结论为如何设计更优提示策略带来启示。

Abstract: Recent studies have shown that Large Language Models (LLMs) can improve their reasoning performance through self-generated few-shot examples, achieving results comparable to manually curated in-context examples. However, the underlying mechanism behind these gains remains unclear, making it hard to decide when and how to apply the technique effectively. In this work, we argue that the key benefit arises not from the generated examples themselves but from the act of creating them. To validate this, on reasoning-intensive tasks across diverse LLM architectures, we systematically evaluate three prompting strategies for in-context learning: (1) Zero-shot prompting; (2) Integrated prompting, where LLMs create and solve problems within a single, unified prompt; and (3) Decoupled prompting, where self-generated examples are reused as in-context examples, but the context of their creation itself is excluded. We conduct experiments across five widely used model architectures, demonstrating that Integrated prompting consistently outperforms both Zero-shot and Decoupled prompting. In contrast, Decoupled prompting offers only marginal gains over Zero-shot. Further, for a more in-depth analysis, we conduct an attention analysis and observe significant differences in attention patterns between Integrated and Decoupled prompting. These findings suggest that the advantage of self-generation prompting comes from the process of problem creation, not the examples themselves, providing valuable insights for designing more effective prompting strategies.

</details>


### [67] [NLP Privacy Risk Identification in Social Media (NLP-PRISM): A Survey](https://arxiv.org/abs/2602.15866)
*Dhiman Goswami,Jai Kruthunz Naveen Kumar,Sanchari Das*

Main category: cs.CL

TL;DR: 本文系统性评估了社交媒体自然语言处理（NLP）中的隐私风险，提出了NLP-PRISM框架，并分析了现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 社交媒体NLP不可避免地处理包含个人身份信息（PII）、行为线索和元数据的内容，带来了诸如监控、画像和精准广告等重大隐私风险。目前缺乏系统的方法对这些风险进行全面评估，因此亟需新的评价框架。

Method: 作者回顾了203篇论文，提出六维度的NLP-PRISM框架（数据收集、预处理、可见性、公平性、计算风险和法规合规），分析主流NLP模型（如transformer）在六类任务中的表现和隐私保护带来的性能损失，并考察模型面临的推断攻击风险。

Result: transformer模型在无隐私保护时F1为0.58-0.84，隐私保护微调后下降1%-23%；6类NLP任务的隐私研究覆盖存在较大空白。模型在实用性和隐私保护之间存在2%-9%的性能折衷；成员推断攻击AUC为0.81，属性推断准确率为0.75。

Conclusion: 建议加强匿名化、采用隐私感知学习、公平性导向的训练策略，以保障社交媒体NLP的伦理与合规性。

Abstract: Natural Language Processing (NLP) is integral to social media analytics but often processes content containing Personally Identifiable Information (PII), behavioral cues, and metadata raising privacy risks such as surveillance, profiling, and targeted advertising. To systematically assess these risks, we review 203 peer-reviewed papers and propose the NLP Privacy Risk Identification in Social Media (NLP-PRISM) framework, which evaluates vulnerabilities across six dimensions: data collection, preprocessing, visibility, fairness, computational risk, and regulatory compliance. Our analysis shows that transformer models achieve F1-scores ranging from 0.58-0.84, but incur a 1% - 23% drop under privacy-preserving fine-tuning. Using NLP-PRISM, we examine privacy coverage in six NLP tasks: sentiment analysis (16), emotion detection (14), offensive language identification (19), code-mixed processing (39), native language identification (29), and dialect detection (24) revealing substantial gaps in privacy research. We further found a (reduced by 2% - 9%) trade-off in model utility, MIA AUC (membership inference attacks) 0.81, AIA accuracy 0.75 (attribute inference attacks). Finally, we advocate for stronger anonymization, privacy-aware learning, and fairness-driven training to enable ethical NLP in social media contexts.

</details>


### [68] [Playing With AI: How Do State-Of-The-Art Large Language Models Perform in the 1977 Text-Based Adventure Game Zork?](https://arxiv.org/abs/2602.15867)
*Berry Gerrits*

Main category: cs.CL

TL;DR: 本论文通过经典文字冒险游戏Zork评估了当代大型语言模型（LLM）的推理和问题解决能力，结果显示其性能有限，平均通关率不足10%。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在对话和推理任务中表现优异，但其实际问题解决能力和元认知水平尚不清楚，因此作者选择用结构化但富有挑战性的Zork游戏进行测试。

Method: 对ChatGPT、Claude、Gemini等主流LLM，在仅提供最小指令或详细规则下进行Zork游戏测试，通过得分衡量进展，同时分析推理过程中的行为和反应。

Result: 所有模型平均完成度低于10%，最高分Claude Opus 4.5仅得75/350。更详细的游戏指令或'扩展思考'功能均未带来明显提升。

Conclusion: 当前主流LLM在即时学习、反思和持续性策略制定等方面存在显著局限，表明其在复杂推理及问题解决场景中尚无法比拟人类的元认知能力。

Abstract: In this positioning paper, we evaluate the problem-solving and reasoning capabilities of contemporary Large Language Models (LLMs) through their performance in Zork, the seminal text-based adventure game first released in 1977. The game's dialogue-based structure provides a controlled environment for assessing how LLM-based chatbots interpret natural language descriptions and generate appropriate action sequences to succeed in the game. We test the performance of leading proprietary models - ChatGPT, Claude, and Gemini - under both minimal and detailed instructions, measuring game progress through achieved scores as the primary metric. Our results reveal that all tested models achieve less than 10% completion on average, with even the best-performing model (Claude Opus 4.5) reaching only approximately 75 out of 350 possible points. Notably, providing detailed game instructions offers no improvement, nor does enabling ''extended thinking''. Qualitative analysis of the models' reasoning processes reveals fundamental limitations: repeated unsuccessful actions suggesting an inability to reflect on one's own thinking, inconsistent persistence of strategies, and failure to learn from previous attempts despite access to conversation history. These findings suggest substantial limitations in current LLMs' metacognitive abilities and problem-solving capabilities within the domain of text-based games, raising questions about the nature and extent of their reasoning capabilities.

</details>


### [69] [Understanding LLM Failures: A Multi-Tape Turing Machine Analysis of Systematic Errors in Language Model Reasoning](https://arxiv.org/abs/2602.15868)
*Magnus Boman*

Main category: cs.CL

TL;DR: 本文提出用多带图灵机形式化LLM的推理流程，能够精准定位并分析其容易出现错误的各个阶段，为理解LLM失败原因和改进方法提供理论工具。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在简单任务上也会意外失败，当前缺乏严谨、可证伪的分析方法来定位和解释这些失败模式。

Method: 作者将LLM的流程抽象为一个确定性的多带图灵机，每条带对应输入字符、分词、词表、模型参数、激活值、概率分布和输出文本等不同组成部分，从而实现了推理过程的可追踪与细致分析。

Result: 这一建模方式能够将模型的失败精准定位到特定环节，例如发现分词机制会掩盖字符级结构，进而影响到如计数类的任务。研究还解释了连锁思维提示（CoT）为何有用及其本质局限。

Conclusion: 通过形式化分析，作者为以往基于类比性描述的理论提供了严格且可检验的替代方案，也为大模型错误分析和改进提供了系统化工具，补充了纯经验性的尺度规律研究。

Abstract: Large language models (LLMs) exhibit failure modes on seemingly trivial tasks. We propose a formalisation of LLM interaction using a deterministic multi-tape Turing machine, where each tape represents a distinct component: input characters, tokens, vocabulary, model parameters, activations, probability distributions, and output text. The model enables precise localisation of failure modes to specific pipeline stages, revealing, e.g., how tokenisation obscures character-level structure needed for counting tasks. The model clarifies why techniques like chain-of-thought prompting help, by externalising computation on the output tape, while also revealing their fundamental limitations. This approach provides a rigorous, falsifiable alternative to geometric metaphors and complements empirical scaling laws with principled error analysis.

</details>


### [70] [Towards Fair and Efficient De-identification: Quantifying the Efficiency and Generalizability of De-identification Approaches](https://arxiv.org/abs/2602.15869)
*Noopur Zambare,Kiana Aghakasiri,Carissa Lin,Carrie Ye,J. Ross Mitchell,Mohamed Abdalla*

Main category: cs.CL

TL;DR: 本文系统评估了不同大小和类型的语言模型在医疗去标识化任务中的泛化能力，发现小模型在多个语言和性别标识中可达到与大模型相当甚至更优的表现，并降低了部署成本。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型（LLM）在医疗去标识化方面表现优异，但其在不同格式、文化和性别上的泛化能力尚未被系统探讨。为了实现更公正、高效的去标识化，有必要研究不同模型在多元背景下的表现和适用性。

Method: 系统比较了微调的Transformer模型（BERT、ClinicalBERT、ModernBERT）、小型LLM（Llama 1-8B、Qwen 1.5-7B）和大型LLM（Llama-70B、Qwen-72B）在去标识化任务上的表现。模型被测试于包括多种语言（普通话、印地语、西班牙语、法语、孟加拉语、不同地区英语）及性别化名字的标识上。此外，作者发布了多文化标识去除模型BERT-MultiCulture-DEID，提高多文化环境的鲁棒性。

Result: 小型模型在准确性上与大型模型相当，推理成本显著降低。在有限数据微调情况下，小模型对不同语言和性别标识的去标识化效果优于大模型。多文化去标识化模型支持多语言环境下的高效公平去标识化。

Conclusion: 首次量化了去标识化任务中的效率与泛化能力权衡，为医疗临床文本的公平高效去标识化提供了可行方案。

Abstract: Large language models (LLMs) have shown strong performance on clinical de-identification, the task of identifying sensitive identifiers to protect privacy. However, previous work has not examined their generalizability between formats, cultures, and genders. In this work, we systematically evaluate fine-tuned transformer models (BERT, ClinicalBERT, ModernBERT), small LLMs (Llama 1-8B, Qwen 1.5-7B), and large LLMs (Llama-70B, Qwen-72B) at de-identification. We show that smaller models achieve comparable performance while substantially reducing inference cost, making them more practical for deployment. Moreover, we demonstrate that smaller models can be fine-tuned with limited data to outperform larger models in de-identifying identifiers drawn from Mandarin, Hindi, Spanish, French, Bengali, and regional variations of English, in addition to gendered names. To improve robustness in multi-cultural contexts, we introduce and publicly release BERT-MultiCulture-DEID, a set of de-identification models based on BERT, ClinicalBERT, and ModernBERT, fine-tuned on MIMIC with identifiers from multiple language variants. Our findings provide the first comprehensive quantification of the efficiency-generalizability trade-off in de-identification and establish practical pathways for fair and efficient clinical de-identification.
  Details on accessing the models are available at: https://doi.org/10.5281/zenodo.18342291

</details>


### [71] [VDLM: Variable Diffusion LMs via Robust Latent-to-Text Rendering](https://arxiv.org/abs/2602.15870)
*Shuhui Qu*

Main category: cs.CL

TL;DR: 本文提出了一种新的扩散语言模型VDLM，通过将语义规划与文本生成分离，提升了多步推理与长文本生成性能，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统自回归语言模型在生成过程中左到右逐字承诺，限制了模型在多步推理时的修正能力，影响长文本和复杂任务的生成效果。

Method: VDLM采用模块化结构，首先在隐空间的语义变量嵌入上通过类扩散（LLaDA-style masked diffusion）实现可迭代的语义规划，并用基于嵌入空间奖励与价值的轨迹优化进行后训练。文本生成阶段，引入Vec2Text解码器并采用嵌入扰动策略，提高对规划器噪声的鲁棒性。

Result: 在包括一般推理、数学、代码等九个基准测试上，VDLM在预训练阶段表现具有竞争力，后训练在长文本生成任务上较其它基线有显著提升。

Conclusion: 本文工作证明了在扩散语言建模中，隐空间后训练和健壮的语义到文本解码策略的有效性，为复杂文本生成任务提供了新思路。

Abstract: Autoregressive language models decode left-to-right with irreversible commitments, limiting revision during multi-step reasoning. We propose \textbf{VDLM}, a modular variable diffusion language model that separates semantic planning from text rendering. VDLM applies LLaDA-style masked diffusion over semantic variable embeddings to enable iterative refinement in latent space, then post-trains the planner with trajectory-aware optimization using embedding-space rewards and values, avoiding text decoding inside the RL loop. To convert planned embeddings back to text, we use a \textbf{Vec2Text} renderer and introduce \textbf{embedding perturbations} to robustify decoding under planner noise. Across nine benchmarks spanning general reasoning, math, and code, VDLM is competitive in pre-training and yields substantial post-training improvements on long-form generation tasks, outperforming other baselines. These results highlight the effectiveness of embedding-space post-training and robust latent-to-text rendering for diffusion language modeling.

</details>


### [72] [CheckIfExist: Detecting Citation Hallucinations in the Era of AI-Generated Content](https://arxiv.org/abs/2602.15871)
*Diletta Abbonato*

Main category: cs.CL

TL;DR: 本文提出了“CheckIfExist”工具，用于即时验证学术论文引用的真实性，防止LLM生成的虚假引用。该工具开源且免费，通过整合多个数据库实现自动校验，支持用户批量和单条参考文献查验。


<details>
  <summary>Details</summary>
Motivation: 大语言模型广泛应用在学术写作中，导致虚假文献引用（虚幻引用）增多，严重影响文献的学术诚信。现有工具要么功能不足，要么需要付费，本项目旨在免费、便捷地解决这一痛点。

Method: 该工具为基于网页的开源工具，通过级联验证架构和字符串相似度算法，对引用进行多维度置信度匹配。系统集成CrossRef、Semantic Scholar和OpenAlex数据库，批量或单条查验，返回APA引用和可导出的BibTeX。

Result: 通过多源数据库自动验证，工具能在秒级时间内反馈参考文献的真实性及置信度。

Conclusion: CheckIfExist有效促进了学术引用的真实性验证，弥补了现有工具和服务的不足，有助于维护学术论文的引用质量和完整性。

Abstract: The proliferation of large language models (LLMs) in academic workflows has introduced unprecedented challenges to bibliographic integrity, particularly through reference hallucination -- the generation of plausible but non-existent citations. Recent investigations have documented the presence of AI-hallucinated citations even in papers accepted at premier machine learning conferences such as NeurIPS and ICLR, underscoring the urgency of automated verification mechanisms. This paper presents "CheckIfExist", an open-source web-based tool designed to provide immediate verification of bibliographic references through multi-source validation against CrossRef, Semantic Scholar, and OpenAlex scholarly databases. While existing reference management tools offer bibliographic organization capabilities, they do not provide real-time validation of citation authenticity. Commercial hallucination detection services, though increasingly available, often impose restrictive usage limits on free tiers or require substantial subscription fees. The proposed tool fills this gap by employing a cascading validation architecture with string similarity algorithms to compute multi-dimensional match confidence scores, delivering instant feedback on reference authenticity. The system supports both single-reference verification and batch processing of BibTeX entries through a unified interface, returning validated APA citations and exportable BibTeX records within seconds.

</details>


### [73] [P-RAG: Prompt-Enhanced Parametric RAG with LoRA and Selective CoT for Biomedical and Multi-Hop QA](https://arxiv.org/abs/2602.15874)
*Xingda Lyu,Gongfu Lyu,Zitai Yan,Yuxin Jiang*

Main category: cs.CL

TL;DR: 本文提出了一种结合参数化知识和检索证据的新型RAG变体（P-RAG），显著提升了大语言模型在生物医学和通用问答任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLMs）依赖静态训练数据，难以实时更新知识。检索增强生成（RAG）虽然能引入外部知识，但效果受限于知识库质量。因此有必要探索更好结合参数模型与检索信息的新方法，提升知识问答能力。

Method: 比较了标准RAG、文档增强RAG（DA-RAG）与作者提出的Prompt-Enhanced Parametric RAG（P-RAG）。P-RAG将LLM内在知识和检索证据结合，并基于Chain-of-Thought（CoT）提示工程，以及Low-Rank Adaptation（LoRA）微调。在LLaMA-3.2-1B-Instruct进行LoRA微调后，分别在PubMedQA和2WikiMultihopQA两个数据集上测试模型能力。

Result: P-RAG在PubMedQA上F1得分达到93.33%，较标准RAG高出10.47个百分点。在2WikiMultihopQA上的整体得分几乎翻倍（33.44%对17.83%），并在其各子集均有较好表现。CoT提示对多跳推理提升明显。

Conclusion: P-RAG证明了融合参数化知识和检索证据、辅以CoT提示的混合方法能大幅提升可扩展、高准确度和情境自适应的生物医学等领域问答系统性能。文章还贡献了对LLaMA-3.2-1B-Instruct模型的生物医学微调与RAG新结构。

Abstract: Large Language Models (LLMs) demonstrate remarkable capabilities but remain limited by their reliance on static training data. Retrieval-Augmented Generation (RAG) addresses this constraint by retrieving external knowledge during inference, though it still depends heavily on knowledge base quality. To explore potential improvements, we evaluated three RAG variants-Standard RAG, DA-RAG, and our proposed Prompt-Enhanced Parametric RAG (P-RAG), a hybrid architecture that integrates parametric knowledge within the LLM and retrieved evidence, guided by Chain-of-Thought (CoT) prompting and Low-Rank Adaptation (LoRA) fine-tuning-on both general and biomedical datasets. Using LLaMA-3.2-1B-Instruct fine-tuned via LoRA, we evaluate on PubMedQA and 2WikiMultihopQA. P-RAG outperforms Standard RAG on PubMedQA by 10.47 percentage points in F1 (93.33% vs. 82.86%; 12.64% relative). On 2WikiMultihopQA, P-RAG nearly doubles the overall score vs. Standard RAG (33.44% vs. 17.83%) and achieves 44.03% on the Compare subset (with 42.74% Bridge, 21.84% Inference, 8.60% Compose). CoT prompting substantially improves multi-hop reasoning but yields mixed results for simpler, single-hop queries. These findings underscore P-RAG's potential for accurate, scalable, and contextually adaptive biomedical question answering. Our contributions include: (1) LoRA-based fine-tuning of LLaMA-3.2-1B-Instruct for biomedical QA, (2) introduction of P-RAG with Chain-of-Thought prompting, and (3) state-of-the-art results on PubMedQA and 2WikiMultihopQA.

</details>


### [74] [Quality-constrained Entropy Maximization Policy Optimization for LLM Diversity](https://arxiv.org/abs/2602.15894)
*Haihui Pan,Yuzhong Hong,Shaoke Lv,Junwei Bao,Hongfei Jiang,Yang Song*

Main category: cs.CL

TL;DR: 提出了一种增强大语言模型输出多样性且保证质量的新方法QEMPO。


<details>
  <summary>Details</summary>
Motivation: 现有的对齐方法提升了大语言模型输出的质量，但明显降低了输出的多样性。已有提升多样性的方法往往以牺牲输出质量为代价，因此需要一种兼顾二者的新方法。

Method: 理论上将对齐任务分解为质量与多样性两个分布，并提出“质量约束的熵最大化策略优化(QEMPO)”以最大化模型输出多样性(熵)的同时确保输出质量，同时设计了online和offline两种训练方式。通过对QEMPO增加不同约束获得不同策略。

Result: 实验表明，QEMPO在保证甚至优于RLHF输出质量的同时，提升了输出的多样性。

Conclusion: QEMPO能有效提升大语言模型输出多样性的同时，维持或提升输出质量，优于现有对齐方法，是提升LLM多样性的新途径。

Abstract: Recent research indicates that while alignment methods significantly improve the quality of large language model(LLM) outputs, they simultaneously reduce the diversity of the models' output. Although some methods have been proposed to enhance LLM output diversity, they often come at the cost of reduced performance. In this work, we first theoretically demonstrate that the alignment task can be decomposed into two distributions: quality and diversity. To enhance the diversity of LLM outputs while ensuring quality, we propose the Quality-constrained Entropy Maximization Policy Optimization (QEMPO). QEMPO aims to maximize the output entropy of the policy while ensuring output quality. By adding different constraints to QEMPO, we obtain different policies. To optimize policies, we propose both online and offline training methods. Experiments validate that QEMPO achieves performance comparable to or even better than RLHF while improving output diversity.

</details>


### [75] [Understand Then Memory: A Cognitive Gist-Driven RAG Framework with Global Semantic Diffusion](https://arxiv.org/abs/2602.15895)
*Pengcheng Zhou,Haochen Li,Zhiqiang Nie,JiaLe Chen,Qing Gong,Weizhen Zhang,Chun Yu*

Main category: cs.CL

TL;DR: CogitoRAG提出了一种模拟人类认知记忆机制的RAG框架，通过引入语义要旨提取、知识图谱、多模块查询和排序方法，大幅提升复杂知识检索和推理能力，实验效果优于现有RAG系统。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法由于文本离散表达导致语义损失和检索偏差，限制了对于复杂知识和推理任务的支持。作者希望引入更接近人类记忆机制的方法以解决这一问题。

Method: CogitoRAG主要创新包括：（1）离线阶段将文本精炼为要旨记忆体并构建多维知识图谱；（2）在线阶段通过查询分解和实体扩散模块模拟人类对复杂问题的拆解和联想检索；（3）提出CogniRank算法，结合扩散得分和语义相似度对候选文本进行精确重排序；（4）检索结果以高密度信息对形式供生成器使用。

Result: 在五个主流问答基准和GraphBench多任务生成上，CogitoRAG显著优于当前最先进的RAG方法，在复杂知识整合与推理任务上展现了卓越表现。

Conclusion: CogitoRAG通过人类认知机制的模拟和关键算法创新，极大提升了RAG在复杂任务下的表现，为大模型知识增强和推理能力带来了新的可能性。

Abstract: Retrieval-Augmented Generation (RAG) effectively mitigates hallucinations in LLMs by incorporating external knowledge. However, the inherent discrete representation of text in existing frameworks often results in a loss of semantic integrity, leading to retrieval deviations. Inspired by the human episodic memory mechanism, we propose CogitoRAG, a RAG framework that simulates human cognitive memory processes. The core of this framework lies in the extraction and evolution of the Semantic Gist. During the offline indexing stage, CogitoRAG first deduces unstructured corpora into gist memory corpora, which are then transformed into a multi-dimensional knowledge graph integrating entities, relational facts, and memory nodes. In the online retrieval stage, the framework handles complex queries via Query Decomposition Module that breaks them into comprehensive sub-queries, mimicking the cognitive decomposition humans employ for complex information. Subsequently, Entity Diffusion Module performs associative retrieval across the graph, guided by structural relevance and an entity-frequency reward mechanism. Furthermore, we propose the CogniRank algorithm, which precisely reranks candidate passages by fusing diffusion-derived scores with semantic similarity. The final evidence is delivered to the generator in a passage-memory pairing format, providing high-density information support. Experimental results across five mainstream QA benchmarks and multi-task generation on GraphBench demonstrate that CogitoRAG significantly outperforms state-of-the-art RAG methods, showcasing superior capabilities in complex knowledge integration and reasoning.

</details>


### [76] [Every Little Helps: Building Knowledge Graph Foundation Model with Fine-grained Transferable Multi-modal Tokens](https://arxiv.org/abs/2602.15896)
*Yichi Zhang,Zhuo Chen,Lingbing Guo,Wen Zhang,Huajun Chen*

Main category: cs.CL

TL;DR: 提出了一种面向多模态知识图谱推理的新基础模型TOFU，能有效迁移至不同知识图谱，并显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多模态知识图谱推理方法难以泛化到新图谱，且通常忽略了多模态信号。近期的知识图谱基础模型侧重结构，忽视视觉和文本等模态。需要一种能够结合多模态信息且具有跨图谱泛化能力的模型。

Method: 提出TOFU模型，将结构、视觉和文本特征离散化为模态相关的token，并通过分层融合架构及message混合机制处理这些离散信息，从而获得可迁移的多模态特征表征。

Result: 在17个知识图谱基准（覆盖迁移和泛化场景）下，TOFU在各项任务中持续优于现有KGFM和MMKGR模型，尤其在未见过的新型多模态知识图谱上性能突出。

Conclusion: TOFU为多模态知识图谱推理提供了有效的基础模型，显著提升了模型的泛化能力和实际应用价值。

Abstract: Multi-modal knowledge graph reasoning (MMKGR) aims to predict the missing links by exploiting both graph structure information and multi-modal entity contents. Most existing works are designed for a transductive setting, which learns dataset-specific embeddings and struggles to generalize to new KGs. Recent knowledge graph foundation models (KGFMs) improve cross-KG transfer, but they mainly exploit structural patterns and ignore rich multi-modal signals. We address these gaps by proposing a token-based foundation model (TOFU) for MMKGR, which exhibits strong generalization across different MMKGs. TOFU discretizes structural, visual, and textual information into modality-specific tokens. TOFU then employs a hierarchical fusion architecture with mixture-of-message mechanisms, aiming to process these tokens and obtain transferable features for MMKGR. Experimental results on 17 transductive, inductive, and fully-inductive MMKGs show that TOFU consistently outperforms strong KGFM and MMKGR baselines, delivering strong performance on unseen MMKGs.

</details>


### [77] [Mitigating Gradient Inversion Risks in Language Models via Token Obfuscation](https://arxiv.org/abs/2602.15897)
*Xinguo Feng,Zhongkui Ma,Zihan Wang,Alsharif Abuadbba,Guangdong Bai*

Main category: cs.CL

TL;DR: 论文提出了一种新的防护机制GHOST，通过令Token级别的扰动，有效抵御梯度反演攻击，在保护隐私的同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型的协作式训练和微调，面临梯度反演攻击（GIA）带来的隐私威胁。现有基于梯度扰动的防护措施，因梯度、嵌入和Token空间间的语义相似性，难以完全杜绝攻击。需有创新方法破除此关联，增强隐私保护。

Method: GHOST利用Token空间规模大、存在语义差异但嵌入相近的Token作为“影子Token”，通过搜索和选择分两步替换原Token，实现Token空间语义断裂、而嵌入和梯度空间的连接不变，从而迷惑GIA。搜索阶段基于多标准筛选语义上相异的候选Token，选择阶段则保障与原Token输出一致性，兼顾隐私与训练效果。

Result: GHOST在BERT、Llama等多种模型及数据集上测试，对抗最先进GIA及自适应攻击时，恢复率仅1%，但分类F1最高仍达0.92，生成任务困惑度为5.45，证明其同时实现了显著的隐私保护与模型实用性。

Conclusion: GHOST打破了Token、嵌入和梯度空间的语义联系，令现有GIA难以恢复原始数据，有效提升了大模型协作训练的隐私安全，同时极大保留了下游任务性能。

Abstract: Training and fine-tuning large-scale language models largely benefit from collaborative learning, but the approach has been proven vulnerable to gradient inversion attacks (GIAs), which allow adversaries to reconstruct private training data from shared gradients. Existing defenses mainly employ gradient perturbation techniques, e.g., noise injection or gradient pruning, to disrupt GIAs' direct mapping from gradient space to token space. However, these methods often fall short due to the retention of semantics similarity across gradient, embedding, and token spaces. In this work, we propose a novel defense mechanism named GHOST (gradient shield with obfuscated tokens), a token-level obfuscation mechanism that neutralizes GIAs by decoupling the inherent connections across gradient, embedding, and token spaces. GHOST is built upon an important insight: due to the large scale of the token space, there exist semantically distinct yet embedding-proximate tokens that can serve as the shadow substitutes of the original tokens, which enables a semantic disconnection in the token space while preserving the connection in the embedding and gradient spaces. GHOST comprises a searching step, which identifies semantically distinct candidate tokens using a multi-criteria searching process, and a selection step, which selects optimal shadow tokens to ensure minimal disruption to features critical for training by preserving alignment with the internal outputs produced by original tokens. Evaluation across diverse model architectures (from BERT to Llama) and datasets demonstrates the remarkable effectiveness of GHOST in protecting privacy (as low as 1% in recovery rate) and preserving utility (up to 0.92 in classification F1 and 5.45 in perplexity), in both classification and generation tasks against state-of-the-art GIAs and adaptive attack scenarios.

</details>


### [78] [MultiCube-RAG for Multi-hop Question Answering](https://arxiv.org/abs/2602.15898)
*Jimeng Shi,Wei Hu,Runchu Tian,Bowen Jin,Wonbin Kweon,SeongKu Kang,Yunfan Kang,Dingqi Ye,Sizhe Zhou,Shaowen Wang,Jiawei Han*

Main category: cs.CL

TL;DR: 本文提出了一种新的、多维本体结构MultiCube-RAG，用于无训练地提升多跳问答中的推理与检索效果。该方法比现有方法更准确、更高效，并具备更强的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有多跳问答任务中的检索增强生成方法难以准确捕捉结构化语义，图结构方法噪声大且计算成本高，而多数方法忽略了多步推理。近期的训练方法又面临收敛不稳定和高计算开销。因此，作者希望提出一种既能准确建模结构关系、又高效且无需训练的方法。

Method: 作者设计了包含多维本体结构的cube，每个cube用于建模不同子类，支持从正交方向分解复杂查询为简单子查询并分步解决。总方法MultiCube-RAG是无训练的，能灵活选取cube结合需求，实现多步推理和检索。

Result: 在四个多跳问答数据集上，MultiCube-RAG的准确率平均比多种基线方法高8.9%，并展示了更高检索效率和天然的解释能力。

Conclusion: MultiCube-RAG能在无需训练情况下实现高效、可解释的多跳问答推理与检索，优于现有主流方法，拓展了多跳问答领域的技术边界。

Abstract: Multi-hop question answering (QA) necessitates multi-step reasoning and retrieval across interconnected subjects, attributes, and relations. Existing retrieval-augmented generation (RAG) methods struggle to capture these structural semantics accurately, resulting in suboptimal performance. Graph-based RAGs structure such information in graphs, but the resulting graphs are often noisy and computationally expensive. Moreover, most methods rely on single-step retrieval, neglecting the need for multi-hop reasoning processes. Recent training-based approaches attempt to incentivize the large language models (LLMs) for iterative reasoning and retrieval, but their training processes are prone to unstable convergence and high computational overhead. To address these limitations, we devise an ontology-based cube structure with multiple and orthogonal dimensions to model structural subjects, attributes, and relations. Built on the cube structure, we propose MultiCube-RAG, a training-free method consisting of multiple cubes for multi-step reasoning and retrieval. Each cube specializes in modeling a class of subjects, so that MultiCube-RAG flexibly selects the most suitable cubes to acquire the relevant knowledge precisely. To enhance the query-based reasoning and retrieval, our method decomposes a complex multi-hop query into a set of simple subqueries along cube dimensions and conquers each of them sequentially. Experiments on four multi-hop QA datasets show that MultiCube-RAG improves response accuracy by 8.9% over the average performance of various baselines. Notably, we also demonstrate that our method performs with greater efficiency and inherent explainability.

</details>


### [79] [Doc-to-LoRA: Learning to Instantly Internalize Contexts](https://arxiv.org/abs/2602.15902)
*Rujikorn Charakorn,Edoardo Cetin,Shinnosuke Uesaka,Robert Tjarko Lange*

Main category: cs.CL

TL;DR: 为了解决大模型在处理长文本时推理效率和内存消耗高的问题，提出了一种叫做Doc-to-LoRA (D2L)的新方法，可以快速将文档语境转化为适配参数，实现高效推理和低内存消耗。


<details>
  <summary>Details</summary>
Motivation: 现有大模型在长上下文下推理很耗内存且慢，现有context distillation虽然能部分解决但成本高、延迟大，实际不可行。因此需要更高效的解决方案。

Method: 提出Doc-to-LoRA（D2L）方法：在接收到新提示时，D2L超网络生成LoRA适配器，使得后续查询无需反复处理原始长上下文，大幅降低推理时的延迟和内存消耗。

Result: 在超长上下文needle-in-a-haystack任务中，D2L能成功映射并保留关键信息，零样本准确率几乎完美，序列长度超过基本模型窗口4倍也能良好工作。在真实QA任务与有限算力下，D2L优于传统context distillation，并大幅降低峰值内存和延迟。

Conclusion: D2L可使大模型快速适应新知识，显著提升效率，有望支持知识高频更新和更个性化的交互。

Abstract: Long input sequences are central to in-context learning, document understanding, and multi-step reasoning of Large Language Models (LLMs). However, the quadratic attention cost of Transformers makes inference memory-intensive and slow. While context distillation (CD) can transfer information into model parameters, per-prompt distillation is impractical due to training costs and latency. To address these limitations, we propose Doc-to-LoRA (D2L), a lightweight hypernetwork that meta-learns to perform approximate CD within a single forward pass. Given an unseen prompt, D2L generates a LoRA adapter for a target LLM, enabling subsequent queries to be answered without re-consuming the original context, reducing latency and KV-cache memory consumption during inference of the target LLM. On a long-context needle-in-a-haystack task, D2L successfully learns to map contexts into adapters that store the needle information, achieving near-perfect zero-shot accuracy at sequence lengths exceeding the target LLM's native context window by more than 4x. On real-world QA datasets with limited compute, D2L outperforms standard CD while significantly reducing peak memory consumption and update latency. We envision that D2L can facilitate rapid adaptation of LLMs, opening up the possibility of frequent knowledge updates and personalized chat behavior.

</details>


### [80] [DocSplit: A Comprehensive Benchmark Dataset and Evaluation Approach for Document Packet Recognition and Splitting](https://arxiv.org/abs/2602.15958)
*Md Mofijul Islam,Md Sirajus Salekin,Nivedha Balakrishnan,Vincil C. Bishop,Niharika Jain,Spencer Romo,Bob Strahan,Boyi Xie,Diego A. Socolinsky*

Main category: cs.CL

TL;DR: 本文提出了DocSplit基准数据集和新的评测指标，用于评估和推动多模态大模型在文档包分割任务中的能力，填补了领域内的重要空白。


<details>
  <summary>Details</summary>
Motivation: 现实场景下常见的多页混合文档包处理需求尚未被很好解决，而现有视觉文档理解方法难以直接应用于文档分割这一基本任务。

Method: 作者提出了DocSplit——首个涵盖多类型文档、多样布局和多模态特征的分割基准数据集。该基准包含五个不同难度的数据集，并引入新评测指标。任务形式化为：检测文档边界、文档类型分类以及保持文档页序。作者还进行了一系列实证实验，对当前主流多模态大模型在复杂文档分割任务中的表现作了综合分析。

Result: 实验发现，现有多模态大模型在面对此类复杂文档分割任务时存在显著性能短板，无法有效应对实际文档中的页面错序、文档交错和无明显分界等挑战。

Conclusion: DocSplit作为新的开放基准和对应评测体系，为推动法律、金融、医疗等高文档密集行业的文档自动处理奠定了基础，有望促进未来相关模型创新和应用落地。

Abstract: Document understanding in real-world applications often requires processing heterogeneous, multi-page document packets containing multiple documents stitched together. Despite recent advances in visual document understanding, the fundamental task of document packet splitting, which involves separating a document packet into individual units, remains largely unaddressed. We present the first comprehensive benchmark dataset, DocSplit, along with novel evaluation metrics for assessing the document packet splitting capabilities of large language models. DocSplit comprises five datasets of varying complexity, covering diverse document types, layouts, and multimodal settings. We formalize the DocSplit task, which requires models to identify document boundaries, classify document types, and maintain correct page ordering within a document packet. The benchmark addresses real-world challenges, including out-of-order pages, interleaved documents, and documents lacking clear demarcations. We conduct extensive experiments evaluating multimodal LLMs on our datasets, revealing significant performance gaps in current models' ability to handle complex document splitting tasks. The DocSplit benchmark datasets and proposed novel evaluation metrics provide a systematic framework for advancing document understanding capabilities essential for legal, financial, healthcare, and other document-intensive domains. We release the datasets to facilitate future research in document packet processing.

</details>


### [81] [A Curious Class of Adpositional Multiword Expressions in Korean](https://arxiv.org/abs/2602.16023)
*Junghyun Min,Na-Rae Han,Jena D. Hwang,Nathan Schneider*

Main category: cs.CL

TL;DR: 本论文关注韩语多词表达中的后置动词结构（PVCs），分析并制定了注释指南，以促进该领域的发展。


<details>
  <summary>Details</summary>
Motivation: 尽管跨语言注释体系如PARSEME已广泛研究多词表达（MWEs），但韩语的MWEs尤其是多词介词缺乏系统分析和资源支持。因此，本文致力于填补韩国多词表达在这一领域的研究空白。

Method: 以韩语维基百科为语料来源，作者对多种PVC表达式进行调研和对比分析，涉及非MWEs和具有类似结构的轻动词结构（LVCs）。

Result: 通过系统性分析，作者区分了PVC与其他结构的差异，并在此基础上提出了适用于韩语多词介词注释的新指南。

Conclusion: 这些注释标准将支持未来韩语多词介词相关研究，并有助于该领域与其他跨语种研究框架的接轨。

Abstract: Multiword expressions (MWEs) have been widely studied in cross-lingual annotation frameworks such as PARSEME. However, Korean MWEs remain underrepresented in these efforts. In particular, Korean multiword adpositions lack systematic analysis, annotated resources, and integration into existing multilingual frameworks. In this paper, we study a class of Korean functional multiword expressions: postpositional verb-based constructions (PVCs). Using data from Korean Wikipedia, we survey and analyze several PVC expressions and contrast them with non-MWEs and light verb constructions (LVCs) with similar structure. Building on this analysis, we propose annotation guidelines designed to support future work in Korean multiword adpositions and facilitate alignment with cross-lingual frameworks.

</details>


### [82] [CLAA: Cross-Layer Attention Aggregation for Accelerating LLM Prefill](https://arxiv.org/abs/2602.16054)
*Bradley McDanel,Steven Li,Harshit Khaitan*

Main category: cs.CL

TL;DR: 本文针对大模型长上下文推理中prefill阶段的计算瓶颈，提出了一种更稳定的token排序方法，大幅加速推理效率，显著降低首token延迟。


<details>
  <summary>Details</summary>
Motivation: 长上下文LLM推理prefill阶段计算代价高，现有基于token排序的加速方法效果受限，主要由于排序在不同层之间不稳定，且难以独立评估排序质量。

Method: 提出Answer-Informed Oracle，通过测量回答回溯到prompt的注意力，定义token重要性的真实性，然后发现现有排序机制在不同层表现波动大。基于诊断，提出跨层聚合机制（CLAA），整合多层token得分，提高排序稳定性。

Result: 新方法CLAA在与oracle上界接近的同时，将首token生成时间（TTFT）比完整KV缓存基线降低了最高39%。

Conclusion: 通过跨层得分聚合，token排序稳定性大幅提升，从而显著加速长上下文LLM推理，验证了新的评估方法和改进策略的有效性。

Abstract: The prefill stage in long-context LLM inference remains a computational bottleneck. Recent token-ranking heuristics accelerate inference by selectively processing a subset of semantically relevant tokens. However, existing methods suffer from unstable token importance estimation, often varying between layers. Evaluating token-ranking quality independently from heuristic-specific architectures is challenging. To address this, we introduce an Answer-Informed Oracle, which defines ground-truth token importance by measuring attention from generated answers back to the prompt. This oracle reveals that existing heuristics exhibit high variance across layers: rankings can degrade sharply at specific layers, a failure mode invisible to end-to-end benchmarks. The diagnosis suggests a simple fix: aggregate scores across layers rather than relying on any single one. We implement this as Cross-Layer Attention Aggregation (CLAA), which closes the gap to the oracle upper bound and reduces Time-to-First-Token (TTFT) by up to 39\% compared to the Full KV Cache baseline.

</details>


### [83] [Surgical Activation Steering via Generative Causal Mediation](https://arxiv.org/abs/2602.16080)
*Aruna Sankaranarayanan,Amir Zur,Atticus Geiger,Dylan Hadfield-Menell*

Main category: cs.CL

TL;DR: 本文提出了一种名为Generative Causal Mediation (GCM)的新方法，用于定位并控制语言模型内部与特定概念相关的组件，优化长文本生成中的行为控制效果。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在长文本生成过程中，某些行为（如风格、顺从、拒绝）通常分布在多个token上，难以精准干预，现有方法主要关注短句或主要依赖相关性分析，效果有限，缺乏有效的定位与控制方法。

Method: 作者提出了一套基于生成因果中介（GCM）分析的流程：（1）构建对比性输入和输出数据集，（2）量化模型各部件（如注意力头）在表达二元概念时的中介作用，并（3）选择最具代表性的组件进行行为引导。方法主要在refusal、sycophancy、style transfer三个具体任务和三个不同的语言模型上进行评估。

Result: 实验表明，GCM方法能有效定位和控制长文本中表达的复杂概念，利用一小部分注意力头进行控制时，整体表现优于基于相关性探针的传统方法。

Conclusion: GCM为定位和干预大语言模型长文本生成中分布式行为提供了有效技术，显著提升了语言模型行为调控的可精确性和有效性。

Abstract: Where should we intervene in a language model (LM) to control behaviors that are diffused across many tokens of a long-form response? We introduce Generative Causal Mediation (GCM), a procedure for selecting model components, e.g., attention heads, to steer a binary concept (e.g., talk in verse vs. talk in prose) from contrastive long-form responses. In GCM, we first construct a dataset of contrasting inputs and responses. Then, we quantify how individual model components mediate the contrastive concept and select the strongest mediators for steering. We evaluate GCM on three tasks--refusal, sycophancy, and style transfer--across three language models. GCM successfully localizes concepts expressed in long-form responses and consistently outperforms correlational probe-based baselines when steering with a sparse set of attention heads. Together, these results demonstrate that GCM provides an effective approach for localizing and controlling the long-form responses of LMs.

</details>


### [84] [Language Statistics and False Belief Reasoning: Evidence from 41 Open-Weight LMs](https://arxiv.org/abs/2602.16085)
*Sean Trott,Samuel Taylor,Cameron Jones,James A. Michaelov,Pamela D. Rivière*

Main category: cs.CL

TL;DR: 本文通过对41个开源语言模型(LM)的测试，复现并扩展了关于心智状态推理的经典心理学实验，发现部分大模型表现出对知识状态暗示的敏感性，但整体仍不及人类水平；此外，提出并验证了模型和人类一致存在的一种语言线索偏见。


<details>
  <summary>Details</summary>
Motivation: 目前关于语言模型心智状态推理的研究大多集中在少数几个闭源模型上，这限制了对心理学理论的验证及对模型能力的全面评价。因此，作者希望通过大量开源模型的系统性测试，更好地探究语言模型在心智推理方面的表现及其对人类认知理论的启示作用。

Method: 研究者选取了41个来自不同家族的开源权重语言模型，利用经典的“错误信念任务”范式，系统评估模型对隐藏或暗示性知识状态的敏感程度，并分析模型规模对能力的影响。同时，基于模型行为提出一个语言线索相关的认知假说，并在人类数据中进行验证。

Result: 结果表明34%的模型对于知识状态暗示具备一定敏感性，但无一能完美重现人类的行为特征；模型规模越大，推理表现越好。还发现，无论人在实验还是模型推理时，如果用非事实性动词表达情景，更容易归因为“错误信念”，而该现象在人类和模型中的效应量分布完全重叠。

Conclusion: 大样本开源模型为认知心理学理论验证和模型能力评测提供了新工具。语言模型对知识状态的推理能力尚有差距，但对特定语言线索的处理与人类相当，这提示语言分布统计特征可解释部分认知现象，而不能完全反映人类心智推理机制。

Abstract: Research on mental state reasoning in language models (LMs) has the potential to inform theories of human social cognition--such as the theory that mental state reasoning emerges in part from language exposure--and our understanding of LMs themselves. Yet much published work on LMs relies on a relatively small sample of closed-source LMs, limiting our ability to rigorously test psychological theories and evaluate LM capacities. Here, we replicate and extend published work on the false belief task by assessing LM mental state reasoning behavior across 41 open-weight models (from distinct model families). We find sensitivity to implied knowledge states in 34% of the LMs tested; however, consistent with prior work, none fully ``explain away'' the effect in humans. Larger LMs show increased sensitivity and also exhibit higher psychometric predictive power. Finally, we use LM behavior to generate and test a novel hypothesis about human cognition: both humans and LMs show a bias towards attributing false beliefs when knowledge states are cued using a non-factive verb (``John thinks...'') than when cued indirectly (``John looks in the...''). Unlike the primary effect of knowledge states, where human sensitivity exceeds that of LMs, the magnitude of the human knowledge cue effect falls squarely within the distribution of LM effect sizes-suggesting that distributional statistics of language can in principle account for the latter but not the former in humans. These results demonstrate the value of using larger samples of open-weight LMs to test theories of human cognition and evaluate LM capacities.

</details>


### [85] [Updating Parametric Knowledge with Context Distillation Retains Post-Training Capabilities](https://arxiv.org/abs/2602.16093)
*Shankar Padmanabhan,Mustafa Omer Gul,Tanya Goyal*

Main category: cs.CL

TL;DR: 本论文提出了一种名为Distillation via Split Contexts（DiSC）的新方法，实现了大语言模型在持续适应新知识时，有效平衡新知识学习与旧能力遗忘。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型经过训练具备多种技能，但其知识有截止日期，必须持续适应新知识。现有方法难以兼顾新知识的学习与旧知识和技能的保留。

Method: 提出了DiSC（Distillation via Split Contexts）方法：通过将训练样本分割为不同片段，分别构造teacher和student的分布，并在它们的共享token上最小化KL散度，无需在训练时进行显式生成，提升了训练效率。

Result: 在四个后训练模型和两个知识适应任务上进行实验，相较于以往微调和蒸馏方法，DiSC在学习新知识和减缓旧技能遗忘之间取得了最佳平衡表现。

Conclusion: DiSC是一种高效的持续知识适应方案，为大语言模型的长期迭代和能力保持提供了有效工具。

Abstract: Post-training endows pretrained LLMs with a variety of desirable skills, including instruction-following, reasoning, and others. However, these post-trained LLMs only encode knowledge up to a cut-off date, necessitating continual adaptation. Unfortunately, existing solutions cannot simultaneously learn new knowledge from an adaptation document corpora and mitigate the forgetting of earlier learned capabilities. To address this, we introduce Distillation via Split Contexts (DiSC), a simple context-distillation based approach for continual knowledge adaptation. \methodname~derives student and teacher distributions by conditioning on distinct segments of the training example and minimizes the KL divergence between the shared tokens. This allows us to efficiently apply context-distillation without requiring explicit generation steps during training. We run experiments on four post-trained models and two adaptation domains. Compared to prior finetuning and distillation methods for continual adaptation, DiSC consistently reports the best trade-off between learning new knowledge and mitigating forgetting of previously learned skills like instruction-following, reasoning, and factual knowledge.

</details>


### [86] [Missing-by-Design: Certifiable Modality Deletion for Revocable Multimodal Sentiment Analysis](https://arxiv.org/abs/2602.16144)
*Rong Fu,Wenxin Zhang,Ziming Wang,Chunlei Meng,Jiaxuan Lu,Jiekai Wu,Kangan Qian,Hao Zhang,Simon Fong*

Main category: cs.CL

TL;DR: 本文提出了Missing-by-Design (MBD) 框架，实现了多模态情感分析中对特定数据模态的可撤销处理，既保护了隐私又保留分析效果。


<details>
  <summary>Details</summary>
Motivation: 随着多模态系统处理大量敏感个人数据，用户隐私保护需求提高，尤其在某些情况下必须允许特定模态的数据被撤销或删除（如用户/监管请求）。传统模型通常无法针对单一模态高效撤销，缺乏有效可验证机制。

Method: MBD引入结构化表示学习，训练出具备可撤销特性的embedding，并通过生成器重构缺失模态信息以保证任务表现。在用户或监管方请求删除特定模态数据时，框架采用关注度驱动的候选选择和高斯分布校准更新机制，生成机器可验证的‘模态删除证书’。

Result: 在多个基准数据集上，MBD即使输入不完整也能保持良好预测效果，显示出隐私性与可用性之间的实用权衡能力。相比全模型重训，MBD外科式撤销更高效。

Conclusion: MBD为多模态系统支持数据可撤销和隐私保护提供了一种统一、实用的解决方案，兼顾性能和合规性，实现了可验证的‘外科式遗忘’。

Abstract: As multimodal systems increasingly process sensitive personal data, the ability to selectively revoke specific data modalities has become a critical requirement for privacy compliance and user autonomy. We present Missing-by-Design (MBD), a unified framework for revocable multimodal sentiment analysis that combines structured representation learning with a certifiable parameter-modification pipeline. Revocability is critical in privacy-sensitive applications where users or regulators may request removal of modality-specific information. MBD learns property-aware embeddings and employs generator-based reconstruction to recover missing channels while preserving task-relevant signals. For deletion requests, the framework applies saliency-driven candidate selection and a calibrated Gaussian update to produce a machine-verifiable Modality Deletion Certificate. Experiments on benchmark datasets show that MBD achieves strong predictive performance under incomplete inputs and delivers a practical privacy-utility trade-off, positioning surgical unlearning as an efficient alternative to full retraining.

</details>


### [87] [Balancing Faithfulness and Performance in Reasoning via Multi-Listener Soft Execution](https://arxiv.org/abs/2602.16154)
*Nithin Sivakumaran,Shoubin Yu,Hyunji Lee,Yue Zhang,Ali Payani,Mohit Bansal,Elias Stengel-Eskin*

Main category: cs.CL

TL;DR: 本文提出了一种新的多方强化学习方法REMUL，以提升大模型推理链（CoT）的忠实度，同时还能兼顾可解释性和任务性能，在多个推理基准测试中均达到了更高的忠实度和准确率。


<details>
  <summary>Details</summary>
Motivation: 以往的推理链解释方式往往不能真实反映大模型的内部推理过程，而且提升推理忠实性与可解释性时常常会导致性能下降。如何兼顾这两者是当前的一个难题。

Method: 提出了REMUL方法，基于“多监听者”假设：让多个模型（listener）分别继续人类生成的推理链，由speaker模型生成初步推理流程给listener继续，若listener能顺利完成即视为推理链更忠实清晰。speaker的奖励函数结合了listener能否理解及回答的表现，以及结合mask监督微调来权衡性能与忠实度。

Result: REMUL算法在多个推理测试集（如BIG-Bench Extra Hard, MuSR, ZebraLogicBench等）上，显著提升了hint attribution、early answering AOC、mistake injection AOC三种衡量忠实度的指标，并同时提升了准确率。实验还发现REMUL训练出的推理链更短、更直接，并且对不同数据域表现出鲁棒性。

Conclusion: REMUL有效提升了大模型推理链的忠实度与可解释性，不再以牺牲性能为代价，在多个领域测试中都获得了更好结果，是增强大模型推理解释能力的重要进展。

Abstract: Chain-of-thought (CoT) reasoning sometimes fails to faithfully reflect the true computation of a large language model (LLM), hampering its utility in explaining how LLMs arrive at their answers. Moreover, optimizing for faithfulness and interpretability in reasoning often degrades task performance. To address this tradeoff and improve CoT faithfulness, we propose Reasoning Execution by Multiple Listeners (REMUL), a multi-party reinforcement learning approach. REMUL builds on the hypothesis that reasoning traces which other parties can follow will be more faithful. A speaker model generates a reasoning trace, which is truncated and passed to a pool of listener models who "execute" the trace, continuing the trace to an answer. Speakers are rewarded for producing reasoning that is clear to listeners, with additional correctness regularization via masked supervised finetuning to counter the tradeoff between faithfulness and performance. On multiple reasoning benchmarks (BIG-Bench Extra Hard, MuSR, ZebraLogicBench, and FOLIO), REMUL consistently and substantially improves three measures of faithfulness -- hint attribution, early answering area over the curve (AOC), and mistake injection AOC -- while also improving accuracy. Our analysis finds that these gains are robust across training domains, translate to legibility gains, and are associated with shorter and more direct CoTs.

</details>


### [88] [LLMs Exhibit Significantly Lower Uncertainty in Creative Writing Than Professional Writers](https://arxiv.org/abs/2602.16162)
*Peiqi Sui*

Main category: cs.CL

TL;DR: 本文指出，大语言模型（LLM）在创造性写作中的表现受限于其输出的不确定性不足，这也是其作品被认为平淡和陈词滥调的原因。研究通过信息论方法定量分析人类与模型故事创作的“不确定性差距”，并提出提升LLM创造力需发展能区分有益和有害不确定性的对齐策略。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在生成内容时倾向于降低不确定性，以减少虚假和幻觉输出，但这导致其创造性写作缺乏人类作品的丰富和开放性。文学理论认为，不确定性是创造性表达的必要条件，因此作者希望揭示这一张力并量化其影响。

Method: 作者对28种LLM，在高质量故事写作数据集上，采用受控的信息论分析，衡量模型与人类写作样本中的不确定性水平，并对比不同类型模型以及不同写作领域之间的差异。

Result: 结果显示，人类作品中不确定性显著高于模型生成内容。经过指令微调和推理优化的模型，相较于基础模型，不确定性更低。这一差距在创造性写作领域尤为明显，并与文本质量强相关。

Conclusion: 如果LLM要实现人类水平的创造力，需要新的、不确定性感知的对齐范式，既能避免有害的幻觉现象，又能保留有利于文学丰富性的建设性模糊和不确定性。

Abstract: We argue that uncertainty is a key and understudied limitation of LLMs' performance in creative writing, which is often characterized as trite and cliché-ridden. Literary theory identifies uncertainty as a necessary condition for creative expression, while current alignment strategies steer models away from uncertain outputs to ensure factuality and reduce hallucination. We formalize this tension by quantifying the "uncertainty gap" between human-authored stories and model-generated continuations. Through a controlled information-theoretic analysis of 28 LLMs on high-quality storytelling datasets, we demonstrate that human writing consistently exhibits significantly higher uncertainty than model outputs. We find that instruction-tuned and reasoning models exacerbate this trend compared to their base counterparts; furthermore, the gap is more pronounced in creative writing than in functional domains, and strongly correlates to writing quality. Achieving human-level creativity requires new uncertainty-aware alignment paradigms that can distinguish between destructive hallucinations and the constructive ambiguity required for literary richness.

</details>


### [89] [Beyond Learning: A Training-Free Alternative to Model Adaptation](https://arxiv.org/abs/2602.16189)
*Namkyung Yoon,Kyeonghyun Yoo,Wooyong Jung,Sanghong Kim,Hwangnam Kim*

Main category: cs.CL

TL;DR: 该论文提出了一种通过模块移植提升语言模型性能的方法，即在不需额外训练或微调的条件下，将在特定任务中表现良好的内部模块转移到表现不佳的目标模型中，从而实现性能的提升。


<details>
  <summary>Details</summary>
Motivation: 现有的提升语言模型性能的方法通常需要大量计算资源，而有些新版本模型反而表现不如旧版本，因此需要一种能够立刻改进模型效果的低资源方法。

Method: 作者首先通过激活分析确定在推理过程中表现出一致和局部激活变化的内部模块。随后，将在特定任务上高激活的内模块移植到目标模型中，以观察功能提升，无需额外训练。

Result: 实验证明，通过模块移植，表现不佳的模型性能可提升至目标基线的2倍，功能差距得到100%以上的弥补。在基础模型和指令微调模型间移植时，性能可提升至目标基线的2.33倍，表现出显著的能力转移。

Conclusion: 模型内部存在可迁移的局部化模块，通过模块移植可实现高效能力转移，无需复杂训练。该工作为语言模型的任务局部模块化和模型移植研究提供了有力的实证依据，开辟了新的研究方向。

Abstract: Despite the continuous research and evolution of language models, they sometimes underperform previous versions. Existing approaches to overcome these challenges are resource-intensive, highlighting the need for alternatives that enable immediate action. We assume that each language model has a local module inside that is suitable for a specific function. First, this work identifies a set of modules showing consistent and local activation changes under an inference workload through activation-based analysis. Subsequently, we transplant an internal module that is properly activated for a specific task into the target model, leading to immediate and measurable functional changes without additional training or fine-tuning. To experimentally demonstrate the effectiveness of the transplant technique, we quantify the relationship between transplant strength and performance improvement under different conditions for two language models. In the cross-generation setting, we find that transplanting activation-selected modules can substantially improve the underperforming model, reaching up to twice the target baseline and achieving gap-based recovery above 100%. Moreover, in transplant experiments between a base model and its instruction-tuned counterpart, transplantation improves the underperforming model toward the stronger baseline, yielding up to about 2.33 times the target baseline with gap-based recovery reaching up to 100% in the best case. These results show that meaningful capacity transfer can be realized through the implantation of highly localized modules implied by language models. Overall, this work provides empirical evidence for task-localized modularity in language models and presents a new research area: model transplantation.

</details>


### [90] [The Validity of Coreference-based Evaluations of Natural Language Understanding](https://arxiv.org/abs/2602.16200)
*Ian Porada*

Main category: cs.CL

TL;DR: 论文探讨了基于共指消解的自然语言处理（NLP）评估方法的有效性，指出当前评估方式存在测量有效性不足等问题，并提出了新的评估方案以弥补不足。


<details>
  <summary>Details</summary>
Motivation: 现有共指消解评估方法经常得出难以推广的结论，测量指标的不一致和对共指定义的争议导致现有评估方法的可信度受质疑，因此需要进行更加全面和有效的评估。

Method: 首先分析了标准共指消解评估方法并指出其中的测量有效性问题，包括定义上的不统一和不同基准测试下模型排名不一致。随后，作者提出并实现了一种基于事件相对合理性推断的新型评估方法，用以测试系统解决共指消解时对事件合理性的判断。

Result: 实验发现，虽然现代语言模型在标准基准下表现优异，并且在特定领域及共指类型上优于早期系统，但对评估条件十分敏感，只要评测环境稍加变化，模型泛化能力就难以达到人类水平。

Conclusion: 当前NLP系统虽在标准评估中表现提升，但存在测量有效性不足和泛化能力有限的问题。论文建议未来需要开发更完善、具普适性的评估方法和系统。

Abstract: In this thesis, I refine our understanding as to what conclusions we can reach from coreference-based evaluations by expanding existing evaluation practices and considering the extent to which evaluation results are either converging or conflicting. First, I analyze standard coreference evaluations and show that their design often leads to non-generalizable conclusions due to issues of measurement validity - including contestedness (multiple, competing definitions of coreference) and convergent validity (evaluation results that rank models differently across benchmarks). Second, I propose and implement a novel evaluation focused on testing systems' ability to infer the relative plausibility of events, a key aspect of resolving coreference. Through this extended evaluation, I find that contemporary language models demonstrate strong performance on standard benchmarks - improving over earlier baseline systems within certain domains and types of coreference - but remain sensitive to the evaluation conditions: they often fail to generalize in ways one would expect a human to be capable of when evaluation contexts are slightly modified. Taken together, these findings clarify both the strengths, such as improved accuracy over baselines on widely used evaluations, and the limitations of the current NLP paradigm, including weaknesses in measurement validity, and suggest directions for future work in developing better evaluation methods and more genuinely generalizable systems.

</details>


### [91] [Long-Tail Knowledge in Large Language Models: Taxonomy, Mechanisms, Interventions and Implications](https://arxiv.org/abs/2602.16201)
*Sanket Badhe,Deep Shah,Nehal Kathrotia*

Main category: cs.CL

TL;DR: 本文针对大语言模型中'长尾知识'的问题，提出了系统性分析框架，探讨了知识定义、丢失机制、技术解决方法及其公平性、透明性等影响，并指出评估与治理面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在主流知识上的表现良好，但在低频、领域专属、文化和时间敏感等长尾知识方面表现不佳，相关问题缺乏系统性研究，带来诸多影响和挑战。

Method: 作者通过综合现有技术和社会技术文献，提出了一个结构化分析框架，从知识定义、丢失机制、干预方法和社会影响四个维度分析长尾知识，批判了当前评估方式的不足。

Result: 提出了统一的概念框架，明确了长尾知识在训练与推理中的丢失机制，梳理了相关技术干预手段，总结了对公平、问责、透明和信任等方面的影响，并指明现有评估实践掩盖了许多重要但罕见的失败情况。

Conclusion: 本文为理解大语言模型中长尾知识的定义、丢失、评估及实际表现提供了基础性理论框架，并呼吁在隐私、可持续性和治理等方面加强研究与实践，以改善长尾知识的表达和问责。

Abstract: Large language models (LLMs) are trained on web-scale corpora that exhibit steep power-law distributions, in which the distribution of knowledge is highly long-tailed, with most appearing infrequently. While scaling has improved average-case performance, persistent failures on low-frequency, domain-specific, cultural, and temporal knowledge remain poorly characterized. This paper develops a structured taxonomy and analysis of long-Tail Knowledge in large language models, synthesizing prior work across technical and sociotechnical perspectives.
  We introduce a structured analytical framework that synthesizes prior work across four complementary axes: how long-Tail Knowledge is defined, the mechanisms by which it is lost or distorted during training and inference, the technical interventions proposed to mitigate these failures, and the implications of these failures for fairness, accountability, transparency, and user trust. We further examine how existing evaluation practices obscure tail behavior and complicate accountability for rare but consequential failures. The paper concludes by identifying open challenges related to privacy, sustainability, and governance that constrain long-Tail Knowledge representation. Taken together, this paper provides a unifying conceptual framework for understanding how long-Tail Knowledge is defined, lost, evaluated, and manifested in deployed language model systems.

</details>


### [92] [Are LLMs Ready to Replace Bangla Annotators?](https://arxiv.org/abs/2602.16241)
*Md. Najib Hasan,Touseef Hasan,Souvika Sarkar*

Main category: cs.CL

TL;DR: 本文通过系统评测表明，当前大型语言模型(LLMs)在孟加拉语仇恨言论的零样本标注任务中存在偏见和判断不稳定性，且模型规模增加并不一定带来更高的标注质量。


<details>
  <summary>Details</summary>
Motivation: 在低资源、身份敏感的任务中，依赖LLMs进行自动化标注逐渐普及，但其是否能作为可靠、无偏见的标注者还未得到充分验证，尤其是在人类间本就不易达成一致的仇恨言论任务上。

Method: 作者设计了一个统一的评估框架，对17种主流LLMs作为零样本的孟加拉语仇恨言论标注者进行了系统性基准测试。

Result: 评测揭示，各模型不仅存在标注偏见，还表现出较大的判断不稳定性。更大规模的语言模型并不一定标注更好，反而有时更小且对任务更对齐的模型表现更一致。

Conclusion: 当前LLMs在低资源敏感任务中的标注能力有限，存在显著问题，在实际部署前需谨慎评估其效果和潜在风险。

Abstract: Large Language Models (LLMs) are increasingly used as automated annotators to scale dataset creation, yet their reliability as unbiased annotators--especially for low-resource and identity-sensitive settings--remains poorly understood. In this work, we study the behavior of LLMs as zero-shot annotators for Bangla hate speech, a task where even human agreement is challenging, and annotator bias can have serious downstream consequences. We conduct a systematic benchmark of 17 LLMs using a unified evaluation framework. Our analysis uncovers annotator bias and substantial instability in model judgments. Surprisingly, increased model scale does not guarantee improved annotation quality--smaller, more task-aligned models frequently exhibit more consistent behavior than their larger counterparts. These results highlight important limitations of current LLMs for sensitive annotation tasks in low-resource languages and underscore the need for careful evaluation before deployment.

</details>


### [93] [Aladdin-FTI @ AMIYA Three Wishes for Arabic NLP: Fidelity, Diglossia, and Multidialectal Generation](https://arxiv.org/abs/2602.16290)
*Jonathan Mutal,Perla Al Almaoui,Simon Hengchen,Pierrette Bouillon*

Main category: cs.CL

TL;DR: 该论文提出了一种名为Aladdin-FTI的系统，能够生成和翻译多种阿拉伯方言，并支持与标准阿拉伯语及英语的双向翻译。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯方言由于缺乏标准化和变异性大，在自然语言处理领域研究不足。研究者希望借助大语言模型的新进展，改善对这类多中心语言的建模。

Method: 提出了一种多功能生成与翻译系统——Aladdin-FTI，具体支持摩洛哥、埃及、巴勒斯坦、叙利亚和沙特五种方言的文本生成及其与现代标准阿拉伯语和英语的双向翻译。

Result: 实验证明该系统对方言生成及多语种翻译具有良好的支持能力，实现了任务目标。代码和模型均已开源。

Conclusion: Aladdin-FTI为阿拉伯多方言建模与翻译任务提供了有效工具，有助于推动阿拉伯方言NLP研究发展。

Abstract: Arabic dialects have long been under-represented in Natural Language Processing (NLP) research due to their non-standardization and high variability, which pose challenges for computational modeling. Recent advances in the field, such as Large Language Models (LLMs), offer promising avenues to address this gap by enabling Arabic to be modeled as a pluricentric language rather than a monolithic system. This paper presents Aladdin-FTI, our submission to the AMIYA shared task. The proposed system is designed to both generate and translate dialectal Arabic (DA). Specifically, the model supports text generation in Moroccan, Egyptian, Palestinian, Syrian, and Saudi dialects, as well as bidirectional translation between these dialects, Modern Standard Arabic (MSA), and English. The code and trained model are publicly available.

</details>


### [94] [MultiCW: A Large-Scale Balanced Benchmark Dataset for Training Robust Check-Worthiness Detection Models](https://arxiv.org/abs/2602.16298)
*Martin Hyben,Sebastian Kula,Jan Cegin,Jakub Simko,Ivan Srba,Robert Moro*

Main category: cs.CL

TL;DR: 本文提出了MultiCW数据集，这是一个覆盖16种语言、7个话题领域和2种文体的、多语言、多领域、平衡的可核查主张检测基准，并用于评估多种主流模型在该任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在媒体行业信息核查中的应用日益增多，但自动检测值得核查主张的工具仍不完善。自动高效地找到需要事实核查的语句对于提升事实核查流程非常重要。为了推动相关研究，需要同时支持多语言、多领域和多种文体的公开数据集。

Method: 作者构建了MultiCW数据集，包括123,722个样本，噪声（非正式）与结构化（正式）文本各占一半，且可核查与不可核查类别均衡分布在全部语言。还构建了27,761个样本的分布外测试集。以3个微调多语言transformer模型和15个商用及开源LLM在零样本条件下进行主张分类基线对比。

Result: 实验结果显示，微调后的模型在主张分类任务上普遍优于零样本LLM，并且在语言、领域和文体上具备较强的泛化能力。

Conclusion: MultiCW为事实核查的自动主张检测任务提供了严格且平衡的多语言数据资源，便于系统性比测微调模型与先进LLM，并有望推动自动化事实核查的发展。

Abstract: Large Language Models (LLMs) are beginning to reshape how media professionals verify information, yet automated support for detecting check-worthy claims a key step in the fact-checking process remains limited. We introduce the Multi-Check-Worthy (MultiCW) dataset, a balanced multilingual benchmark for check-worthy claim detection spanning 16 languages, 7 topical domains, and 2 writing styles. It consists of 123,722 samples, evenly distributed between noisy (informal) and structured (formal) texts, with balanced representation of check-worthy and non-check-worthy classes across all languages. To probe robustness, we also introduce an equally balanced out-of-distribution evaluation set of 27,761 samples in 4 additional languages. To provide baselines, we benchmark 3 common fine-tuned multilingual transformers against a diverse set of 15 commercial and open LLMs under zero-shot settings. Our findings show that fine-tuned models consistently outperform zero-shot LLMs on claim classification and show strong out-of-distribution generalization across languages, domains, and styles. MultiCW provides a rigorous multilingual resource for advancing automated fact-checking and enables systematic comparisons between fine-tuned models and cutting-edge LLMs on the check-worthy claim detection task.

</details>


### [95] [MemoryArena: Benchmarking Agent Memory in Interdependent Multi-Session Agentic Tasks](https://arxiv.org/abs/2602.16313)
*Zexue He,Yu Wang,Churan Zhi,Yuanzhe Hu,Tzu-Ping Chen,Lang Yin,Ze Chen,Tong Arthur Wu,Siru Ouyang,Zihan Wang,Jiaxin Pei,Julian McAuley,Yejin Choi,Alex Pentland*

Main category: cs.CL

TL;DR: 该论文引入了MemoryArena，一个评测智能体记忆能力的新型基准环境，用于多轮次复杂任务中评估智能体如何获取、存储并利用记忆指导行为。实验显示传统高分记忆模型在该环境下表现较差，暴露出现有测评的不足。


<details>
  <summary>Details</summary>
Motivation: 现实环境中智能体需要综合利用记忆与行动，但现有评测大多仅单独考察记忆回忆或单环节任务操作，缺乏评价记忆与行动耦合能力的有效设置。

Method: 提出了MemoryArena评测平台，设计具有关联子任务的多阶段任务，要求智能体在多轮会话和不同环境中通过积累经验获得记忆，并利用该记忆完成后续复杂任务。涵盖网页导航、受偏好约束规划、递进式信息检索、序贯推理等场景。

Result: 在MemoryArena中，现有在长上下文记忆任务（如LoCoMo）中表现接近饱和的智能体，在多环节任务中表现显著下降，说明它们不能有效将记忆转化为有效行动。

Conclusion: 当前针对记忆智能体的测评不够完备，需采用如MemoryArena这种结合记忆与行动能力的多阶段评测框架，才能反映模型在实际任务中的真实能力。

Abstract: Existing evaluations of agents with memory typically assess memorization and action in isolation. One class of benchmarks evaluates memorization by testing recall of past conversations or text but fails to capture how memory is used to guide future decisions. Another class focuses on agents acting in single-session tasks without the need for long-term memory. However, in realistic settings, memorization and action are tightly coupled: agents acquire memory while interacting with the environment, and subsequently rely on that memory to solve future tasks. To capture this setting, we introduce MemoryArena, a unified evaluation gym for benchmarking agent memory in multi-session Memory-Agent-Environment loops. The benchmark consists of human-crafted agentic tasks with explicitly interdependent subtasks, where agents must learn from earlier actions and feedback by distilling experiences into memory, and subsequently use that memory to guide later actions to solve the overall task. MemoryArena supports evaluation across web navigation, preference-constrained planning, progressive information search, and sequential formal reasoning, and reveals that agents with near-saturated performance on existing long-context memory benchmarks like LoCoMo perform poorly in our agentic setting, exposing a gap in current evaluations for agents with memory.

</details>


### [96] [Helpful to a Fault: Measuring Illicit Assistance in Multi-Turn, Multilingual LLM Agents](https://arxiv.org/abs/2602.16346)
*Nivya Talokar,Ayush K Tarun,Murari Mandal,Maksym Andriushchenko,Antoine Bosselut*

Main category: cs.CL

TL;DR: 本文提出了一种针对大模型智能体复杂滥用场景的自动化红队测试框架STING，实现多轮对话和工具交互下智能体滥用风险的高效评估。


<details>
  <summary>Details</summary>
Motivation: 现有智能体滥用测试多聚焦于单轮提示，但现实中滥用往往通过多轮复杂交互发生，缺少系统性测试方法，导致安全性评估存在盲区。

Method: 作者提出STING框架，通过构建具备良性身份的逐步非法计划，结合适应性追问与评判智能体分阶段推进攻击，能系统化、多轮、多语种测试代理完成非法任务的能力，并引入多项新的分析指标。

Result: 相较于单轮和传统多轮测试，STING显著提升智能体在AgentHarm等场景下完成非法任务的测试覆盖率和深度，且多语言实验证实低资源语言并非总更易规避安全防御。

Conclusion: STING框架为现实部署场景下智能体多轮滥用测试和压力测试提供了实用工具，有助于发现和避免大型AI代理实际应用中的安全风险。

Abstract: LLM-based agents execute real-world workflows via tools and memory. These affordances enable ill-intended adversaries to also use these agents to carry out complex misuse scenarios. Existing agent misuse benchmarks largely test single-prompt instructions, leaving a gap in measuring how agents end up helping with harmful or illegal tasks over multiple turns. We introduce STING (Sequential Testing of Illicit N-step Goal execution), an automated red-teaming framework that constructs a step-by-step illicit plan grounded in a benign persona and iteratively probes a target agent with adaptive follow-ups, using judge agents to track phase completion. We further introduce an analysis framework that models multi-turn red-teaming as a time-to-first-jailbreak random variable, enabling analysis tools like discovery curves, hazard-ratio attribution by attack language, and a new metric: Restricted Mean Jailbreak Discovery. Across AgentHarm scenarios, STING yields substantially higher illicit-task completion than single-turn prompting and chat-oriented multi-turn baselines adapted to tool-using agents. In multilingual evaluations across six non-English settings, we find that attack success and illicit-task completion do not consistently increase in lower-resource languages, diverging from common chatbot findings. Overall, STING provides a practical way to evaluate and stress-test agent misuse in realistic deployment settings, where interactions are inherently multi-turn and often multilingual.

</details>


### [97] [Label-Consistent Data Generation for Aspect-Based Sentiment Analysis Using LLM Agents](https://arxiv.org/abs/2602.16379)
*Mohammad H. A. Monfared,Lucie Flek,Akbar Karimi*

Main category: cs.CL

TL;DR: 本文提出了一种用于细粒度情感分析（ABSA）的自主数据增广方法，通过“生成-验证”迭代产生高质量的合成训练样本。实验结果显示，该方法优于直接基于提示的生成方式，尤其在需要生成方面词时表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有ABSA任务的数据稀缺影响了模型性能，需要高质量的数据增广方法提升训练效果。传统基于提示的方法容易造成标签不准确，难以保证合成数据的有效性。本文旨在探索更有效的主动生成方法，提升合成样本质量。

Method: 作者提出了基于代理（agentic）的数据增广法，结合生成与验证两个步骤自动迭代，提升合成训练数据的标签准确性。设计了与之相匹配的基于提示（prompting）的基线模型，并在三个ABSA子任务、四个数据集及T5-Base和Tk-Instruct两个模型上进行了对比评测。

Result: 实验显示，agentic增广方法在标签保持性尤其是方面词生成方面优于基线，也能与真实数据结合带来更高性能提升。T5-Base模型收益最为明显，能够靠合成数据达到与Tk-Instruct媲美的效果，而Tk-Instruct则增益略小。

Conclusion: 论文证实了基于生成-验证的自主增广方法可以获得优质的训练样本，并且在细粒度情感分析中效果优于现有提示生成方法，建议在数据稀缺场景中推广使用。

Abstract: We propose an agentic data augmentation method for Aspect-Based Sentiment Analysis (ABSA) that uses iterative generation and verification to produce high quality synthetic training examples. To isolate the effect of agentic structure, we also develop a closely matched prompting-based baseline using the same model and instructions. Both methods are evaluated across three ABSA subtasks (Aspect Term Extraction (ATE), Aspect Sentiment Classification (ATSC), and Aspect Sentiment Pair Extraction (ASPE)), four SemEval datasets, and two encoder-decoder models: T5-Base and Tk-Instruct. Our results show that the agentic augmentation outperforms raw prompting in label preservation of the augmented data, especially when the tasks require aspect term generation. In addition, when combined with real data, agentic augmentation provides higher gains, consistently outperforming prompting-based generation. These benefits are most pronounced for T5-Base, while the more heavily pretrained Tk-Instruct exhibits smaller improvements. As a result, augmented data helps T5-Base achieve comparable performance with its counterpart.

</details>


### [98] [TabAgent: A Framework for Replacing Agentic Generative Components with Tabular-Textual Classifiers](https://arxiv.org/abs/2602.16429)
*Ido Levy,Eilam Shapira,Yinon Goldshtein,Avi Yaeli,Nir Mashkif,Segev Shlomov*

Main category: cs.CL

TL;DR: 本论文提出了一种名为TabAgent的新框架，用于替换多步代理型AI系统中的闭集决策任务，极大降低了使用LLM导致的延迟和成本，同时保持任务性能。


<details>
  <summary>Details</summary>
Motivation: 目前的自主代理AI系统在多步决策（如路由、筛选、验证等）中大量调用大语言模型（LLM），虽然灵活但成本高、速度慢，需要更高效方案。

Method: TabAgent通过三部分实现高效决策：1) TabSchema从执行轨迹中提取结构化特征；2) TabSynth用合成监督增强训练样本覆盖面；3) TabHead用轻量级分类器评估候选项，替换LLM短名单生成等环节。

Result: 在长序列任务AppWorld基准中，TabAgent在不损失任务成功率的前提下，完全去除了短名单生成过程中的LLM调用，使延迟减少约95%，推理成本降低85-91%。

Conclusion: TabAgent有效替代了现有代理系统中的生成式LLM瓶颈，为生产级AI代理决策提供了高效的判别式新范式，并具备良好任务泛化能力。

Abstract: Agentic systems, AI architectures that autonomously execute multi-step workflows to achieve complex goals, are often built using repeated large language model (LLM) calls for closed-set decision tasks such as routing, shortlisting, gating, and verification. While convenient, this design makes deployments slow and expensive due to cumulative latency and token usage. We propose TabAgent, a framework for replacing generative decision components in closed-set selection tasks with a compact textual-tabular classifier trained on execution traces. TabAgent (i) extracts structured schema, state, and dependency features from trajectories (TabSchema), (ii) augments coverage with schema-aligned synthetic supervision (TabSynth), and (iii) scores candidates with a lightweight classifier (TabHead). On the long-horizon AppWorld benchmark, TabAgent maintains task-level success while eliminating shortlist-time LLM calls, reducing latency by approximately 95% and inference cost by 85-91%. Beyond tool shortlisting, TabAgent generalizes to other agentic decision heads, establishing a paradigm for learned discriminative replacements of generative bottlenecks in production agent architectures.

</details>


### [99] [IndicEval: A Bilingual Indian Educational Evaluation Framework for Large Language Models](https://arxiv.org/abs/2602.16467)
*Saurabh Bharti,Gaurav Azad,Abhinaw Jagtap,Nachiket Tapas*

Main category: cs.CL

TL;DR: 本论文提出了IndicEval，一个基于真实高难度考试题（涵盖STEM与人文学科，英文与印地语）的多语言大模型评测平台，发现当前LLM在推理、跨语言及高复杂度任务方面仍存明显短板。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）能力提升，现有评测方法很难全面反映其在真实学术、高难度、多语种情境下的表现。因此，急需一个能支持真实考试、双语、跨学科的官方评测基准。

Method: 提出IndicEval基准，采用印度主要考试（UPSC、JEE、NEET）中的真实题目，支持英文和印地语。集成Zero-Shot、Few-Shot和Chain-of-Thought三种提示策略，平台可自动化评测并方便兼容不同模型与语种。

Result: 实验覆盖Gemini 2.0 Flash、GPT-4、Claude与LLaMA 3-70B。主要发现：（1）CoT提示显著提升推理准确率；（2）模型间在高难度题目上的表现分化明显；（3）印地语环境下，各模型准确率皆大幅下滑，特别是在Zero-Shot设置下。

Conclusion: IndicEval为LLM多语言、高难度、真实场景评估奠定基础。研究揭示了当前模型在高复杂性、多语言推理与知识迁移方面的不足，为未来提升大模型推理稳健性及语言适应性提供方向。

Abstract: The rapid advancement of large language models (LLMs) necessitates evaluation frameworks that reflect real-world academic rigor and multilingual complexity. This paper introduces IndicEval, a scalable benchmarking platform designed to assess LLM performance using authentic high-stakes examination questions from UPSC, JEE, and NEET across STEM and humanities domains in both English and Hindi. Unlike synthetic benchmarks, IndicEval grounds evaluation in real examination standards, enabling realistic measurement of reasoning, domain knowledge, and bilingual adaptability. The framework automates assessment using Zero-Shot, Few-Shot, and Chain-of-Thought (CoT) prompting strategies and supports modular integration of new models and languages. Experiments conducted on Gemini 2.0 Flash, GPT-4, Claude, and LLaMA 3-70B reveal three major findings. First, CoT prompting consistently improves reasoning accuracy, with substantial gains across subjects and languages. Second, significant cross-model performance disparities persist, particularly in high-complexity examinations. Third, multilingual degradation remains a critical challenge, with marked accuracy drops in Hindi compared to English, especially under Zero-Shot conditions. These results highlight persistent gaps in bilingual reasoning and domain transfer. Overall, IndicEval provides a practice-oriented, extensible foundation for rigorous, equitable evaluation of LLMs in multilingual educational settings and offers actionable insights for improving reasoning robustness and language adaptability.

</details>


### [100] [Explainable AI: Context-Aware Layer-Wise Integrated Gradients for Explaining Transformer Models](https://arxiv.org/abs/2602.16608)
*Melkamu Abay Mersha,Jugal Kalita*

Main category: cs.CL

TL;DR: 提出了一种新型的Transformer模型可解释性方法——上下文感知的分层积分梯度（CA-LIG），实现跨层、上下文敏感、语义连贯的模型决策解释。


<details>
  <summary>Details</summary>
Motivation: 当前Transformer模型虽效果卓越，但其深层结构导致模型决策难以解释，现有方法局限于最后一层、割裂了局部与全局、忽略层间及结构依赖等信息，解释效果有限。

Method: 提出CA-LIG框架，在Transformer每层内部计算积分梯度，将分层的token归因与类别注意力梯度整合，生成有符号、上下文敏感的归因图，同时跟踪相关性在层内的传递路径。

Result: CA-LIG方法在多任务、多模型、多领域（如情感分析、长文本分类、仇恨言论检测、图像分类等）实验中，相较已有方法，归因更真实，解释更具有上下文敏感性，视觉化更清晰、语义更连贯。

Conclusion: CA-LIG显著提升了Transformer的可解释性和可信度，为理解深层神经模型决策机制带来新进展，对实际和理论均有推进作用。

Abstract: Transformer models achieve state-of-the-art performance across domains and tasks, yet their deeply layered representations make their predictions difficult to interpret. Existing explainability methods rely on final-layer attributions, capture either local token-level attributions or global attention patterns without unification, and lack context-awareness of inter-token dependencies and structural components. They also fail to capture how relevance evolves across layers and how structural components shape decision-making. To address these limitations, we proposed the \textbf{Context-Aware Layer-wise Integrated Gradients (CA-LIG) Framework}, a unified hierarchical attribution framework that computes layer-wise Integrated Gradients within each Transformer block and fuses these token-level attributions with class-specific attention gradients. This integration yields signed, context-sensitive attribution maps that capture supportive and opposing evidence while tracing the hierarchical flow of relevance through the Transformer layers. We evaluate the CA-LIG Framework across diverse tasks, domains, and transformer model families, including sentiment analysis and long and multi-class document classification with BERT, hate speech detection in a low-resource language setting with XLM-R and AfroLM, and image classification with Masked Autoencoder vision Transformer model. Across all tasks and architectures, CA-LIG provides more faithful attributions, shows stronger sensitivity to contextual dependencies, and produces clearer, more semantically coherent visualizations than established explainability methods. These results indicate that CA-LIG provides a more comprehensive, context-aware, and reliable explanation of Transformer decision-making, advancing both the practical interpretability and conceptual understanding of deep neural models.

</details>


### [101] [Training Models on Dialects of Translationese Shows How Lexical Diversity and Source-Target Syntactic Similarity Shape Learning](https://arxiv.org/abs/2602.16469)
*Jenny Kunz*

Main category: cs.CL

TL;DR: 本文研究了用机器翻译数据训练小型英语语言模型时，源语言的差异性对模型表现的影响。结果表明，译文的源语言会显著影响模型的表现。


<details>
  <summary>Details</summary>
Motivation: 多语言NLP常需依赖机器翻译生成的数据，但翻译文本（翻译腔）和原生文本存在系统性差异。因此需要系统地分析，机器翻译语料的源语言如何影响英语模型的行为。

Method: 作者选取24种类型和资源多样的源语言，将它们的文本翻译成英文，并用这些翻译文本训练英语小型语言模型。通过对比分析不同源语言和语料属性对模型学习到的内容的影响。

Result: 实验显示，源语言会显著影响模型行为：模型的困惑度（perplexity）由译文语料的词汇多样性驱动，而语法表现则随着源语言与英语语言类型学相似度增加而提升（在数据量充足情况下）。

Conclusion: 在用机器翻译数据训练英语模型时，需重视源语言的选择，因为源语言的类型和词汇丰富度会分别影响模型的困惑度和语法表现，对提升英语NLP系统的效果有重要意义。

Abstract: Machine-translated data is widely used in multilingual NLP, particularly when native text is scarce. However, translated text differs systematically from native text. This phenomenon is known as translationese, and it reflects both traces of the source language and characteristic properties of translation itself. In this paper, we study how training on machine-translated data affects small English language models, focusing on how translationese from different source languages shapes linguistic acceptability judgments and language modelling for different domains. We train models on English text translated from 24 typologically and resource-diverse source languages, enabling a systematic analysis of how source language and corpus properties influence what models learn. Our results show that the source language has a clear impact on model behavior: general perplexity is more driven by the lexical diversity of the translated corpus, while grammatical performance is strongly correlated to typological similarity to English, given enough data.

</details>


### [102] [Team of Thoughts: Efficient Test-time Scaling of Agentic Systems through Orchestrated Tool Calling](https://arxiv.org/abs/2602.16485)
*Jeffrey T. H. Wong,Zixi Zhang,Junyi Liu,Yiren Zhao*

Main category: cs.CL

TL;DR: 提出了一种可以动态调用不同能力代理的新多智能体系统架构，显著提升了推理和代码生成任务的表现。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统通常依赖同质、静态的模型配置，无法充分利用训练后模型间的差异化能力。本研究旨在解决不同后训练模型特长利用不足的问题。

Method: 提出Team-of-Thoughts架构，结合了异构代理与“协调器-工具”范式。设计了：1) 协调器校准机制，用于识别具备较强协调能力的模型；2) 工具代理自评机制，根据自身领域专长配置技能档案。推理时，协调器根据技能档案动态激活最合适的工具代理。

Result: 在五个推理与代码生成基准测试上，Team-of-Thoughts表现优越。其中，在AIME24和LiveCodeBench分别达到了96.67%和72.53%的准确率，远超同质基线（80%和65.93%）。

Conclusion: Team-of-Thoughts框架能有效释放多模型系统的异质优势，显著改善复杂推理和生成能力，优于传统同质多智能体方法。

Abstract: Existing Multi-Agent Systems (MAS) typically rely on static, homogeneous model configurations, limiting their ability to exploit the distinct strengths of differently post-trained models. To address this, we introduce Team-of-Thoughts, a novel MAS architecture that leverages the complementary capabilities of heterogeneous agents via an orchestrator-tool paradigm. Our framework introduces two key mechanisms to optimize performance: (1) an orchestrator calibration scheme that identifies models with superior coordination capabilities, and (2) a self-assessment protocol where tool agents profile their own domain expertise to account for variations in post-training skills. During inference, the orchestrator dynamically activates the most suitable tool agents based on these proficiency profiles. Experiments on five reasoning and code generation benchmarks show that Team-of-Thoughts delivers consistently superior task performance. Notably, on AIME24 and LiveCodeBench, our approach achieves accuracies of 96.67% and 72.53%, respectively, substantially outperforming homogeneous role-play baselines, which score 80% and 65.93%.

</details>


### [103] [Learning to Learn from Language Feedback with Social Meta-Learning](https://arxiv.org/abs/2602.16488)
*Jonathan Cook,Diego Antognini,Martin Klissarov,Claudiu Musat,Edward Grefenstette*

Main category: cs.CL

TL;DR: 本论文提出了一种从社会元学习（SML）中汲取灵感的微调方法，使大型语言模型（LLM）能够在对话中主动寻求并利用用户反馈，从而提升其对话适应性和问题解决能力。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型在对话中很难主动获取和有效利用他人反馈，导致对话不够灵活和人性化。作者希望通过模拟人类社会学习方式，使模型能够更好地学习如何从他人的反馈中优化自我表现。

Method: 作者提出将社会元学习（SML）作为微调方法，训练模型在模拟的教学对话中主动索取和应用语言反馈，把静态任务转变为互动式学习问题。

Result: 通过SML方法训练的模型不仅能更好地利用反馈解决自身不能一次性解决的问题，而且该能力能在数学和编程等不同领域间迁移。模型还在解决信息不充分的任务时表现更佳，如能主动询问所需关键信息、减少过早答题的情况。

Conclusion: SML为AI系统带来了一种可泛化、可扩展的训练方法，使其能更好地从语言反馈中学习，提升对话的自然性与问题解决能力。

Abstract: Large language models (LLMs) often struggle to learn from corrective feedback within a conversational context. They are rarely proactive in soliciting this feedback, even when faced with ambiguity, which can make their dialogues feel static, one-sided, and lacking the adaptive qualities of human conversation. To address these limitations, we draw inspiration from social meta-learning (SML) in humans - the process of learning how to learn from others. We formulate SML as a finetuning methodology, training LLMs to solicit and learn from language feedback in simulated pedagogical dialogues, where static tasks are converted into interactive social learning problems. SML effectively teaches models to use conversation to solve problems they are unable to solve in a single turn. This capability generalises across domains; SML on math problems produces models that better use feedback to solve coding problems and vice versa. Furthermore, despite being trained only on fully-specified problems, these models are better able to solve underspecified tasks where critical information is revealed over multiple turns. When faced with this ambiguity, SML-trained models make fewer premature answer attempts and are more likely to ask for the information they need. This work presents a scalable approach to developing AI systems that effectively learn from language feedback.

</details>


### [104] [From Growing to Looping: A Unified View of Iterative Computation in LLMs](https://arxiv.org/abs/2602.16490)
*Ferdinand Kapl,Emmanouil Angelis,Kaitlin Maile,Johannes von Oswald,Stefan Bauer*

Main category: cs.CL

TL;DR: 本文研究了深度网络中“循环使用”和“深度生长”两种机制对推理能力的提升作用，并揭示其底层共性与协同效果。


<details>
  <summary>Details</summary>
Motivation: “循环（Looping）”和“深度生长（Depth Growing）”分别指网络在推理时重复利用结构体块或逐步扩展深度，这两种方法都被观测到能提高模型推理能力，但它们之间的关系尚不清楚。本文旨在解释二者之间的联系，推动对迭代计算本质的理解。

Method: 作者通过对比循环和深度生长模型的深度特征表现，分析它们在网络结构中的依赖模式和重复利用层次，并尝试将二者结合，比如在深度生长模型的中间块应用推理时循环。同时，探索这两种机制在不同上下文和训练数据丰富度下的适应能力。

Result: 两种方法在深度维度表现出趋同的特征（如后期层依赖增强、中间块模式反复）；二者都能显著提升特定推理任务准确率（如某些情况下提升可达2倍），在更多上下文示例或有监督微调时适应性更强。深度生长模型配合高质量、涉及数学的训练数据时提升最大，而加入中间块循环后进一步增强效果。

Conclusion: 循环和深度生长是两种互补且实用的网络迭代计算扩展方式，通过机制统一和组合，可以有效提升神经网络的推理能力和可扩展性。

Abstract: Looping, reusing a block of layers across depth, and depth growing, training shallow-to-deep models by duplicating middle layers, have both been linked to stronger reasoning, but their relationship remains unclear. We provide a mechanistic unification: looped and depth-grown models exhibit convergent depth-wise signatures, including increased reliance on late layers and recurring patterns aligned with the looped or grown block. These shared signatures support the view that their gains stem from a common form of iterative computation. Building on this connection, we show that the two techniques are adaptable and composable: applying inference-time looping to the middle blocks of a depth-grown model improves accuracy on some reasoning primitives by up to $2\times$, despite the model never being trained to loop. Both approaches also adapt better than the baseline when given more in-context examples or additional supervised fine-tuning data. Additionally, depth-grown models achieve the largest reasoning gains when using higher-quality, math-heavy cooldown mixtures, which can be further boosted by adapting a middle block to loop. Overall, our results position depth growth and looping as complementary, practical methods for inducing and scaling iterative computation to improve reasoning.

</details>


### [105] [Optimizing Soft Prompt Tuning via Structural Evolution](https://arxiv.org/abs/2602.16500)
*Zhenzhen Huang,Chaoning Zhang,Haoyu Bian,Songbo Zhang,Chi-lok Andy Tai,Jiaquan Zhang,Caiyan Qin,Jingjing Qu,Yalan Ye,Yang Yang,Heng Tao Shen*

Main category: cs.CL

TL;DR: 本文提出利用拓扑数据分析（TDA）中的持久同调理论来定量分析软提示调优的方法，并据此提出一种新的优化损失函数TSLoss，提升了软提示的可解释性和性能。


<details>
  <summary>Details</summary>
Motivation: 尽管软提示调优在大模型上表现出色，但其高维隐式特征导致可解释性差，且训练行为难以追踪和理解，影响了其推广与应用。

Method: 利用拓扑数据分析的持久同调方法衡量软提示在连续参数空间中的结构表现及其训练过程演化，并以此分析软提示结构的稳定性和紧致性对任务表现的影响。基于该分析，设计了一种新的损失函数TSLoss，引导模型学习结构稳定的软提示。

Result: 通过在多个任务上的实验证明，TSLoss有助于软提示更快收敛，并在性能上实现进一步提升，训练过程也更易于解释。

Conclusion: 通过拓扑结构视角分析与优化软提示，不仅提升了训练效率和最终效果，也增强了可解释性，为软提示调优研究和应用提供了新路径。

Abstract: Soft prompt tuning leverages continuous embeddings to capture task-specific information in large pre-trained language models (LLMs), achieving competitive performance in few-shot settings. However, soft prompts rely on high-dimensional, implicit representations and lack explicit semantics and traceable training behaviors, which limits their interpretability. To address this limitation, we propose a soft prompt tuning optimization method based on topological morphological evolution. Specifically, we employ persistent homology from topological data analysis (TDA) to quantify the structural representations of soft prompts in continuous parameter space and their training process evolution. Quantitative analysis shows that topologically stable and compact soft prompts achieve better downstream performance. Based on this empirical observation, we construct a loss function for optimizing soft prompt tuning, termed Topological Soft Prompt Loss (TSLoss). TSLoss guides the model to learn structurally stable adaptations by quantifying inter-parameter connectivity and redundancy. Extensive experiments show that training with TSLoss accelerates convergence and improves tuning performance, providing an interpretable method to understand and optimize soft prompt tuning from structural and topological perspectives.

</details>


### [106] [Supercharging Agenda Setting Research: The ParlaCAP Dataset of 28 European Parliaments and a Scalable Multilingual LLM-Based Classification](https://arxiv.org/abs/2602.16516)
*Taja Kuzman Pungeršek,Peter Rupnik,Daniela Širinić,Nikola Ljubešić*

Main category: cs.CL

TL;DR: 本文提出了ParlaCAP数据集及一种高效构建领域特定政策主题分类器的方法，有效提升了议会政策主题分析的准确性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有跨国议会话语分析存在数据标注难、规模小和领域泛化不足等问题，阻碍比较性政策议题研究。作者希望通过新的大规模多语言数据和自动化标注方法，提升分析效率和准确性。

Method: 作者将CAP议题分类体系应用于多语言的ParlaMint语料，利用大型语言模型（LLM）自动标注领域内训练数据，并用教师-学生框架微调多语言编码器模型，从而实现可扩展的政策主题自动分类。

Result: LLM-驱动的训练数据标注与人类标注员之间的一致性与人类之间的一致性相当，微调后的模型在目标领域的CAP分类任务中优于用人工标注但领域外数据训练的现有模型。

Conclusion: ParlaCAP提供了丰富的议会言说结构化数据和自动化标注方法，为跨国政策议程、情感分析和群体差异研究开辟了新路径，极大促进了比较政策分析的研究基础。

Abstract: This paper introduces ParlaCAP, a large-scale dataset for analyzing parliamentary agenda setting across Europe, and proposes a cost-effective method for building domain-specific policy topic classifiers. Applying the Comparative Agendas Project (CAP) schema to the multilingual ParlaMint corpus of over 8 million speeches from 28 parliaments of European countries and autonomous regions, we follow a teacher-student framework in which a high-performing large language model (LLM) annotates in-domain training data and a multilingual encoder model is fine-tuned on these annotations for scalable data annotation. We show that this approach produces a classifier tailored to the target domain. Agreement between the LLM and human annotators is comparable to inter-annotator agreement among humans, and the resulting model outperforms existing CAP classifiers trained on manually-annotated but out-of-domain data. In addition to the CAP annotations, the ParlaCAP dataset offers rich speaker and party metadata, as well as sentiment predictions coming from the ParlaSent multilingual transformer model, enabling comparative research on political attention and representation across countries. We illustrate the analytical potential of the dataset with three use cases, examining the distribution of parliamentary attention across policy topics, sentiment patterns in parliamentary speech, and gender differences in policy attention.

</details>


### [107] [Utility-Preserving De-Identification for Math Tutoring: Investigating Numeric Ambiguity in the MathEd-PII Benchmark Dataset](https://arxiv.org/abs/2602.16571)
*Zhuqian Zhou,Kirk Vanacore,Bakhtawar Ahtisham,Jinsook Lee,Doug Pietrzak,Daryl Hedley,Jorge Dias,Chris Shaw,Ruth Schäfer,René F. Kizilcec*

Main category: cs.CL

TL;DR: 本论文针对数学辅导对话中PII（个人可识别信息）检测难题，提出首个相关基准数据集MathEd-PII，并验证领域感知模型在保护数据可用性上的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统PII检测工具在数学辅导文本中往往将数字表述（如日期、ID等）误判为PII，导致教学关键信息被过度遮蔽，影响数据的分析和共享价值。因此，亟需能兼顾隐私保护与数据可用性的去标识化方案。

Method: 作者构建了包含1000场辅导对话的新基准数据集MathEd-PII，数据标注采用“人机协同+隐私保留替换”流程。同时，提出基于信息密度的区块分割算法以分析误判集中区域，并系统比较了四种不同的PII检测策略，包括常规PII检测工具及三种基于LLM的“数学感知”与“分割感知”提示策略。

Result: 实验发现，错误的PII遮蔽在数学高密度区块尤为突出。与传统PII检测相比，“math-aware”提示极大提升检测效果（F1从0.379提升至0.821），并有效减少将数学内容误判为敏感信息的情况。

Conclusion: 仅依赖通用PII检测方法难以在教学数据中兼顾隐私与可用性，引入领域知识、设计专用检测策略意义重大。作者开源了基准数据集，为后续领域感知型去标识化研究奠定基础。

Abstract: Large-scale sharing of dialogue-based data is instrumental for advancing the science of teaching and learning, yet rigorous de-identification remains a major barrier. In mathematics tutoring transcripts, numeric expressions frequently resemble structured identifiers (e.g., dates or IDs), leading generic Personally Identifiable Information (PII) detection systems to over-redact core instructional content and reduce dataset utility. This work asks how PII can be detected in math tutoring transcripts while preserving their educational utility. To address this challenge, we investigate the "numeric ambiguity" problem and introduce MathEd-PII, the first benchmark dataset for PII detection in math tutoring dialogues, created through a human-in-the-loop LLM workflow that audits upstream redactions and generates privacy-preserving surrogates. The dataset contains 1,000 tutoring sessions (115,620 messages; 769,628 tokens) with validated PII annotations. Using a density-based segmentation method, we show that false PII redactions are disproportionately concentrated in math-dense regions, confirming numeric ambiguity as a key failure mode. We then compare four detection strategies: a Presidio baseline and LLM-based approaches with basic, math-aware, and segment-aware prompting. Math-aware prompting substantially improves performance over the baseline (F1: 0.821 vs. 0.379) while reducing numeric false positives, demonstrating that de-identification must incorporate domain context to preserve analytic utility. This work provides both a new benchmark and evidence that utility-preserving de-identification for tutoring data requires domain-aware modeling.

</details>


### [108] [CitiLink-Summ: Summarization of Discussion Subjects in European Portuguese Municipal Meeting Minutes](https://arxiv.org/abs/2602.16607)
*Miguel Marques,Ana Luísa Fernandes,Ana Filipa Pacheco,Rute Rebouças,Inês Cantante,José Isidro,Luís Filipe Cunha,Alípio Jorge,Nuno Guimarães,Sérgio Nunes,António Leal,Purificação Silvano,Ricardo Campos*

Main category: cs.CL

TL;DR: 本文提出了CitiLink-Summ语料库，专为欧洲葡萄牙语市政会议记录自动摘要而建，是该领域的首个基准数据集。作者用该数据集对主流生成模型和大型语言模型进行了基线测试。


<details>
  <summary>Details</summary>
Motivation: 市政会议纪要篇幅长、内容密集，普通市民难以快速获取关键信息。自动摘要有助于提高透明度和公众可访问性，然而此类研究欠缺，尤其是在低资源语言领域，缺少高质量摘要数据集严重制约模型研究和评测。

Method: 作者构建了一个包含100份欧洲葡萄牙语市政会议纪要和2,322个手写摘要的新数据集CitiLink-Summ，并用BART、PRIMERA等SOTA生成模型及大语言模型进行自动摘要实验。评测指标涵盖ROUGE、BLEU、METEOR及BERTScore等。

Result: 实验证明CitiLink-Summ语料库可作为市政领域摘要的首个葡萄牙语基准，也展示了常用自动摘要模型在此任务上的表现。

Conclusion: CitiLink-Summ为葡萄牙语市政纪要自动摘要任务首创了高质量基准数据集，对复杂行政文本NLP研究具有重要推动作用。

Abstract: Municipal meeting minutes are formal records documenting the discussions and decisions of local government, yet their content is often lengthy, dense, and difficult for citizens to navigate. Automatic summarization can help address this challenge by producing concise summaries for each discussion subject. Despite its potential, research on summarizing discussion subjects in municipal meeting minutes remains largely unexplored, especially in low-resource languages, where the inherent complexity of these documents adds further challenges. A major bottleneck is the scarcity of datasets containing high-quality, manually crafted summaries, which limits the development and evaluation of effective summarization models for this domain. In this paper, we present CitiLink-Summ, a new corpus of European Portuguese municipal meeting minutes, comprising 100 documents and 2,322 manually hand-written summaries, each corresponding to a distinct discussion subject. Leveraging this dataset, we establish baseline results for automatic summarization in this domain, employing state-of-the-art generative models (e.g., BART, PRIMERA) as well as large language models (LLMs), evaluated with both lexical and semantic metrics such as ROUGE, BLEU, METEOR, and BERTScore. CitiLink-Summ provides the first benchmark for municipal-domain summarization in European Portuguese, offering a valuable resource for advancing NLP research on complex administrative texts.

</details>


### [109] [ColBERT-Zero: To Pre-train Or Not To Pre-train ColBERT models](https://arxiv.org/abs/2602.16609)
*Antoine Chaffin,Luca Arnaboldi,Amélie Chatelain,Florent Krzakala*

Main category: cs.CL

TL;DR: 本文探讨多向量模型的大规模预训练，提出直接多向量预训练能获得更强效果，并发布了相关模型和代码。


<details>
  <summary>Details</summary>
Motivation: 现有多向量（multi-vector）模型多为在单向量模型（single-vector）基础上，进行知识蒸馏与微调得到，尚未充分利用多向量模型自身的大规模预训练潜力。

Method: 以ColBERT为代表，通过对多向量模型直接进行大规模预训练，比较这种预训练方式与现有以单向量为基础的微调/蒸馏方法的性能差异。同时研究在微调流程中增加监督步骤，对模型表现的影响。

Result: 全新的ColBERT-Zero（完全多向量大规模预训练，仅用公开数据）超越了基于闭集强数据的GTE-ModernColBERT及其基础模型，达到了同等规模下的新SOTA。补充监督微调步骤可以在跳过高成本的无监督阶段情况下，将性能逼近完全预训练。

Conclusion: 多向量模型的直接大规模预训练能显著提升模型表现，适当调整微调步骤（如增加有监督阶段并对齐预训练与微调流程）能够高效提升效果。相关资源已开放发布。

Abstract: Current state-of-the-art multi-vector models are obtained through a small Knowledge Distillation (KD) training step on top of strong single-vector models, leveraging the large-scale pre-training of these models. In this paper, we study the pre-training of multi-vector models and show that large-scale multi-vector pre-training yields much stronger multi-vector models. Notably, a fully ColBERT-pre-trained model, ColBERT-Zero, trained only on public data, outperforms GTE-ModernColBERT as well as its base model, GTE-ModernBERT, which leverages closed and much stronger data, setting new state-of-the-art for model this size. We also find that, although performing only a small KD step is not enough to achieve results close to full pre-training, adding a supervised step beforehand allows to achieve much closer performance while skipping the most costly unsupervised phase. Finally, we find that aligning the fine-tuning and pre-training setups is crucial when repurposing existing models. To enable exploration of our results, we release various checkpoints as well as code used to train them.

</details>


### [110] [Who can we trust? LLM-as-a-jury for Comparative Assessment](https://arxiv.org/abs/2602.16610)
*Mengjie Qian,Guangzhi Sun,Mark J. F. Gales,Kate M. Knill*

Main category: cs.CL

TL;DR: 本文提出了BT-sigma模型，通过考虑评审员（LLM）间的可靠性差异，解决当前自动评测模型存在的偏差与不一致问题。实验表明，该方法优于传统平均方法，对预测排序和可靠性校准效果更好。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型被广泛用于自然语言生成评价，相关方法大多未能区分不同评审员（LLM）在判别上的可靠性差异，忽视了模型判断存在的偏见和不一致性，降低了评测结果的准确性。

Method: 本文提出了一种基于Bradley-Terry模型扩展的BT-sigma方法。BT-sigma为每位LLM评审员引入一个判别参数，仅基于两两对比结果联合推断项目排名及评审员可靠性，无需人工标注的监督信息。

Result: 在自然语言生成评测基准数据集上的实验显示，BT-sigma在项目排名准确性和一致性度量上，均优于基于平均的传统方法。同时，学习到的判别参数与LLM判断循环一致性等独立指标高度相关。

Conclusion: BT-sigma不仅提升了LLM评审结果的聚合效能，还可作为一种无监督的评审员校准机制，为未来自动化评测方法提供了更稳健的方案。

Abstract: Large language models (LLMs) are increasingly applied as automatic evaluators for natural language generation assessment often using pairwise comparative judgements. Existing approaches typically rely on single judges or aggregate multiple judges assuming equal reliability. In practice, LLM judges vary substantially in performance across tasks and aspects, and their judgment probabilities may be biased and inconsistent. Furthermore, human-labelled supervision for judge calibration may be unavailable. We first empirically demonstrate that inconsistencies in LLM comparison probabilities exist and show that it limits the effectiveness of direct probability-based ranking. To address this, we study the LLM-as-a-jury setting and propose BT-sigma, a judge-aware extension of the Bradley-Terry model that introduces a discriminator parameter for each judge to jointly infer item rankings and judge reliability from pairwise comparisons alone. Experiments on benchmark NLG evaluation datasets show that BT-sigma consistently outperforms averaging-based aggregation methods, and that the learned discriminator strongly correlates with independent measures of the cycle consistency of LLM judgments. Further analysis reveals that BT-sigma can be interpreted as an unsupervised calibration mechanism that improves aggregation by modelling judge reliability.

</details>


### [111] [AREG: Adversarial Resource Extraction Game for Evaluating Persuasion and Resistance in Large Language Models](https://arxiv.org/abs/2602.16639)
*Adib Sakhawat,Fardeen Sadab*

Main category: cs.CL

TL;DR: 本文提出了一个用于评估大型语言模型（LLMs）社交智力的新基准——对抗资源获取博弈（AREG），以测量模型在劝说与抵抗中的表现，并发现模型防御能力普遍强于劝说能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评测多聚焦静态文本生成，难以全面反映其社交智力，尤其是在动态对抗与谈判场景下的表现，因此亟需能同时评价劝说与抵抗的新方法。

Method:  authors定义了AREG基准，让模型在多回合零和博弈中进行金钱资源的劝说与抵抗；通过循环赛形式对主流大模型进行攻防能力的联合评测，并结合语言学分析，考察策略与博弤结果间的关联。

Result: 攻防（劝说与抵抗）能力相关性弱（ρ=0.33），模型抵抗得分普遍高于劝说得分，表现出防御优势。结构性分析显示，逐步承诺策略有助于资源获取，验证型反应优于直接拒绝。

Conclusion: 社交影响能力在大模型中并非单一维度，仅聚焦劝说会掩盖模型在对抗设置下的不对称漏洞，评测需兼顾攻防能力。

Abstract: Evaluating the social intelligence of Large Language Models (LLMs) increasingly requires moving beyond static text generation toward dynamic, adversarial interaction. We introduce the Adversarial Resource Extraction Game (AREG), a benchmark that operationalizes persuasion and resistance as a multi-turn, zero-sum negotiation over financial resources. Using a round-robin tournament across frontier models, AREG enables joint evaluation of offensive (persuasion) and defensive (resistance) capabilities within a single interactional framework. Our analysis provides evidence that these capabilities are weakly correlated ($ρ= 0.33$) and empirically dissociated: strong persuasive performance does not reliably predict strong resistance, and vice versa. Across all evaluated models, resistance scores exceed persuasion scores, indicating a systematic defensive advantage in adversarial dialogue settings. Further linguistic analysis suggests that interaction structure plays a central role in these outcomes. Incremental commitment-seeking strategies are associated with higher extraction success, while verification-seeking responses are more prevalent in successful defenses than explicit refusal. Together, these findings indicate that social influence in LLMs is not a monolithic capability and that evaluation frameworks focusing on persuasion alone may overlook asymmetric behavioral vulnerabilities.

</details>


### [112] [Quecto-V1: Empirical Analysis of 8-bit Quantized Small Language Models for On-Device Legal Retrieval](https://arxiv.org/abs/2602.16640)
*Subrit Dikshit*

Main category: cs.CL

TL;DR: 本文提出了一种专为印度法律领域设计的小型语言模型Quecto-V1，通过定制GPT-2架构并利用印度主要法律文本从零训练，在保障隐私和低资源环境下实现了高效的法律信息检索能力。


<details>
  <summary>Details</summary>
Motivation: 当前主流法律智能系统基于大规模参数和云端推理，导致普通用户和低资源环境难以接入，同时存在数据主权隐患。作者希望研发一款离线、本地可用的、专用于印度法律领域的紧凑型语言模型，降低资源门槛、保障隐私。

Method: 采用GPT-2 124M参数架构自定义训练，数据仅涵盖印度主要法律文本。模型在训练后进行8-bit量化，具体采用GGUF格式，将模型压缩至150MB以内，无需云端即可在消费级CPU上运行。

Result: Quecto-V1在法律条文定义和刑罚检索等任务上，较通用小语言模型展现出更高准确率，全部离线运行。8-bit量化带来74%模型压缩，精度仅略降3.5%。

Conclusion: 专用小模型通过领域定向训练和激进量化，在高敏感领域（如法律）相较通用云模型能实现可落地、强隐私保护的智能检索方案，具备实际应用前景。

Abstract: The rapid proliferation of Large Language Models (LLMs) has revolutionized Natural Language Processing (NLP) but has simultaneously created a "resource divide." State-of-the-art legal intelligence systems typically rely on massive parameter counts (7B+) and cloud-based inference, rendering them inaccessible to practitioners in resource-constrained environments and posing significant data sovereignty risks. This paper introduces Quecto-V1, a domain-specific Small Language Model (SLM) engineered to democratize access to Indian legal intelligence. Built upon a custom configuration of the GPT-2 architecture (124 million parameters), Quecto-V1 was trained from scratch exclusively on a corpus of Indian statutes, including the Indian Penal Code (IPC), the Code of Criminal Procedure (CrPC), and the Constitution of India. Unlike generalist models, which prioritize broad world knowledge, our approach maximizes "lexical density" within the legal domain. Furthermore, we address the deployment bottleneck by applying post-training 8-bit quantization (GGUF format), compressing the model to a memory footprint of under 150 MB. Our empirical analysis demonstrates that Quecto-V1 achieves high fidelity in retrieving statutory definitions and penal provisions, outperforming general-purpose SLMs in domain-specific exact match tasks while running entirely offline on consumer-grade CPUs. We further present an ablation study showing that 8-bit quantization yields a 74% reduction in model size with less than 3.5% degradation in retrieval accuracy compared to full-precision baselines. These findings suggest that for specialized, high-stakes domains like law, domain-specific training coupled with aggressive quantization offers a viable, privacy-preserving alternative to monolithic cloud models.

</details>


### [113] [Align Once, Benefit Multilingually: Enforcing Multilingual Consistency for LLM Safety Alignment](https://arxiv.org/abs/2602.16660)
*Yuyan Bu,Xiaohao Liu,ZhaoXing Ren,Yaodong Yang,Juntao Dai*

Main category: cs.CL

TL;DR: 提出了一种低资源消耗的方法，通过多语一致性损失（MLC loss），提升大语言模型在多语言安全对齐上的能力，无需大量目标语言监督。


<details>
  <summary>Details</summary>
Motivation: 虽然大模型在多语言环境推广广泛，但安全对齐通常需要大量资源（如丰富的目标语言标注或与高资源语言配对对齐），限制了多语言延展能力。该论文为了解决多语言对齐的资源瓶颈。

Method: 提出了可嵌入到现有单语对齐流程的“多语一致性损失（MLC loss）”，通过提升不同语言下语义向量方向的一致性，实现用多语提示即可同时对齐多种语言，无需低资源语言响应级的附加监督。多轮实验验证了方法对不同架构和对齐范式的通用性和有效性。

Result: 该方法提升了多语言安全能力，对模型整体功能基本没有负向影响。横跨多语言与多任务的评测中展示了更好的跨语言泛化能力。

Conclusion: 在低监督下，实现多语言一致性对齐的有效方法，对于实际多语言安全对齐需求具有应用价值，是当前可扩展、多语对齐场景下的实用新方案。

Abstract: The widespread deployment of large language models (LLMs) across linguistic communities necessitates reliable multilingual safety alignment. However, recent efforts to extend alignment to other languages often require substantial resources, either through large-scale, high-quality supervision in the target language or through pairwise alignment with high-resource languages, which limits scalability. In this work, we propose a resource-efficient method for improving multilingual safety alignment. We introduce a plug-and-play Multi-Lingual Consistency (MLC) loss that can be integrated into existing monolingual alignment pipelines. By improving collinearity between multilingual representation vectors, our method encourages directional consistency at the multilingual semantic level in a single update. This allows simultaneous alignment across multiple languages using only multilingual prompt variants without requiring additional response-level supervision in low-resource languages. We validate the proposed method across different model architectures and alignment paradigms, and demonstrate its effectiveness in enhancing multilingual safety with limited impact on general model utility. Further evaluation across languages and tasks indicates improved cross-lingual generalization, suggesting the proposed approach as a practical solution for multilingual consistency alignment under limited supervision.

</details>


### [114] [Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents](https://arxiv.org/abs/2602.16699)
*Wenxuan Ding,Nicholas Tomlin,Greg Durrett*

Main category: cs.CL

TL;DR: 本论文提出了一种新的方法，使大语言模型（LLMs）在面对需要与环境交互、存在不确定性和成本权衡的问题时，能更合理地决策。通过引入Calibrate-Then-Act (CTA) 框架，LLMs能够更好地评估何时停止探索、何时采取行动，提升整体任务表现。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在信息检索、编程等复杂任务中的应用增多，这些任务往往需要多轮交互，并在探索与行动之间权衡成本与不确定性。现有模型通常未明确考虑何时应该继续探索（如进一步测试代码）或何时应该作出决策（如直接提交答案），因此可能带来次优表现或较高错误成本。

Method: 作者将信息检索和编程任务形式化为不确定性下的序贯决策问题。为此，提出了“Calibrate-Then-Act (CTA)”框架：首先给LLMs输入关于环境状态的先验信息，让模型对不确定性和成本进行权衡，然后基于这一判断进行后续决策。对比基线方法和强化学习训练下的不同策略，观察其决策质量变化。

Result: 实验结果显示，在信息检索问答和简化编程任务中，通过CTA框架使LLMs显式权衡成本与收益，能够促使模型采取更优决策策略。该优势在强化学习训练后相比基线方法仍能保留。

Conclusion: 将成本-不确定性权衡显式化能够有效提升LLMs在需要环境交互与决策的复杂任务中的表现，CTA框架为此类任务提供了更为合理和高效的决策方法。

Abstract: LLMs are increasingly being used for complex problems which are not necessarily resolved in a single response, but require interacting with an environment to acquire information. In these scenarios, LLMs must reason about inherent cost-uncertainty tradeoffs in when to stop exploring and commit to an answer. For instance, on a programming task, an LLM should test a generated code snippet if it is uncertain about the correctness of that code; the cost of writing a test is nonzero, but typically lower than the cost of making a mistake. In this work, we show that we can induce LLMs to explicitly reason about balancing these cost-uncertainty tradeoffs, then perform more optimal environment exploration. We formalize multiple tasks, including information retrieval and coding, as sequential decision-making problems under uncertainty. Each problem has latent environment state that can be reasoned about via a prior which is passed to the LLM agent. We introduce a framework called Calibrate-Then-Act (CTA), where we feed the LLM this additional context to enable it to act more optimally. This improvement is preserved even under RL training of both the baseline and CTA. Our results on information-seeking QA and on a simplified coding task show that making cost-benefit tradeoffs explicit with CTA can help agents discover more optimal decision-making strategies.

</details>


### [115] [Reinforced Fast Weights with Next-Sequence Prediction](https://arxiv.org/abs/2602.16704)
*Hee Seung Hwang,Xindi Wu,Sanghyuk Chun,Olga Russakovsky*

Main category: cs.CL

TL;DR: 本文提出REFINE框架，通过强化学习和多token序列预测目标，提升了fast weight模型对长文本的建模能力，显著优于传统的NTP训练方式。


<details>
  <summary>Details</summary>
Motivation: Fast weight架构在长上下文建模中有内存优势，但传统的NTP训练关注单token预测，导致该模型无法很好捕捉长距离依赖，因此需要探索更有效的训练方式。

Method: 提出REFINE，一个基于强化学习的训练框架，将训练目标从NTP切换到NSP。REFINE通过预测熵选择信息量大的token，进行多token rollouts，赋予自监督序列级奖励，并利用GRPO算法训练模型。

Result: 在LaCT-760M和DeltaNet-1.3B两个fast weight模型上，REFINE在needle-in-a-haystack、长上下文问答以及LongBench多任务测试均超越了传统NTP微调方法。

Conclusion: REFINE为fast weight架构带来高效且通用的长上下文建模能力，可在预训练、微调、甚至测试时使用，有效提升模型性能。

Abstract: Fast weight architectures offer a promising alternative to attention-based transformers for long-context modeling by maintaining constant memory overhead regardless of context length. However, their potential is limited by the next-token prediction (NTP) training paradigm. NTP optimizes single-token predictions and ignores semantic coherence across multiple tokens following a prefix. Consequently, fast weight models, which dynamically update their parameters to store contextual information, learn suboptimal representations that fail to capture long-range dependencies. We introduce REFINE (Reinforced Fast weIghts with Next sEquence prediction), a reinforcement learning framework that trains fast weight models under the next-sequence prediction (NSP) objective. REFINE selects informative token positions based on prediction entropy, generates multi-token rollouts, assigns self-supervised sequence-level rewards, and optimizes the model with group relative policy optimization (GRPO). REFINE is applicable throughout the training lifecycle of pre-trained language models: mid-training, post-training, and test-time training. Our experiments on LaCT-760M and DeltaNet-1.3B demonstrate that REFINE consistently outperforms supervised fine-tuning with NTP across needle-in-a-haystack retrieval, long-context question answering, and diverse tasks in LongBench. REFINE provides an effective and versatile framework for improving long-context modeling in fast weight architectures.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [116] [EdgeNav-QE: QLoRA Quantization and Dynamic Early Exit for LAM-based Navigation on Edge Devices](https://arxiv.org/abs/2602.15836)
*Mengyun Liu,Shanshan Huang,Jianan Jiang*

Main category: cs.RO

TL;DR: EdgeNav-QE 框架通过结合低比特量化和动态提前退出机制，显著降低大模型在边缘设备上的运行延迟和内存消耗，并保持高导航成功率。


<details>
  <summary>Details</summary>
Motivation: 大型动作模型（LAMs）在自主导航中表现出巨大潜力，但其庞大的参数量导致难以在边缘设备部署，主要因内存和时延限制。本文动机是寻找能够支持实时性能并适配边缘设备的有效优化方案。

Method: 提出 EdgeNav-QE 框架，将低秩自适应量化（QLoRA）与动态提前退出（DEE）机制结合：一方面将主干模型量化到4-bit以降低内存与运算需求，另一方面在模型结构中设置可以根据任务简单度动态提前结束推理的分支，复杂任务则用全部模型推理。

Result: 在 Habitat-Sim 环境与 Matterport3D 数据集上，采用 OpenVLA-7B 主干模型测试，EdgeNav-QE 在与全精度模型相比，推理延迟降低82.7%、内存使用降低66.7%、导航成功率仍达81.8%，且比最新的静态提前退出方法在延迟上快17.9%。

Conclusion: EdgeNav-QE 框架有效兼顾了边缘设备上的高效性与导航准确性，动态、内容自适应的推理方式优于静态方法，适用于对安全性与实时性要求高的自主导航场景。

Abstract: Large Action Models (LAMs) have shown immense potential in autonomous navigation by bridging high-level reasoning with low-level control. However, deploying these multi-billion parameter models on edge devices remains a significant challenge due to memory constraints and latency requirements. In this paper, we propose EdgeNav-QE, a novel framework that integrates Quantized Low-Rank Adaptation (QLoRA) with a dynamic early-exit (DEE) mechanism to optimize LAMs for real-time edge navigation. By quantizing the backbone to 4-bit precision and strategically placing early-exit branches, we enable the model to terminate inference early for simple navigation tasks while retaining full depth for complex decision-making. Experimental results on the Habitat-Sim environment with Matterport3D dataset using OpenVLA-7B backbone, demonstrate that EdgeNav-QE reduces inference latency by 82.7% and memory footprint by 66.7% compared to full-precision baselines, while maintaining 81.8% navigation success rate. Furthermore, it outperforms state-of-the-art static early-exit method by 17.9% in latency, demonstrating the superiority of content-aware adaptive computation for safety-critical applications.

</details>


### [117] [From Conflicts to Collisions: A Two-Stage Collision Scenario-Testing Approach for Autonomous Driving Systems](https://arxiv.org/abs/2602.15837)
*Siyuan Chen,Fuyuan Zhang,Hua Qi,Lei Ma,Tomoyuki Tsuchiya,Michio Hayashi,Manabu Okada*

Main category: cs.RO

TL;DR: 本文提出了一种两阶段的自动驾驶系统仿真测试框架，首先搜索潜在冲突，再对冲突场景进行变异以诱发碰撞，从而更高效、多样地发现系统隐患。


<details>
  <summary>Details</summary>
Motivation: 现有仿真测试方法主要围绕接近碰撞的场景展开，容易忽略其他类型的危险情境，导致覆盖范围有限和测试效率不高。

Method: 提出以'冲突'作为碰撞的中间目标，采用两阶段框架：第一阶段搜索可能发生冲突的场景，第二阶段对这些冲突场景进行变异，引发实际碰撞，从而扩大危险场景的发现覆盖面。

Result: 在Baidu Apollo平台测试中，该方法在一轮测试中揭示了多达12种不同类型的碰撞，场景多样性翻倍且所需模拟次数更少，显著优于当前最先进的基线方法。

Conclusion: 以冲突为中间测试目标能够有效拓宽危险场景的搜索空间，显著提升自动驾驶系统安全评估的效率和效果。

Abstract: Autonomous driving systems (ADS) are safety-critical and require rigorous testing before public deployment. Simulation-based scenario testing provides a safe and cost-effective alternative to extensive on-road trials, enabling efficient evaluation of ADS under diverse and high-risk conditions. However, existing approaches mainly evaluates the scenarios based on their proximity to collisions and focus on scenarios already close to collision, leaving many other hazardous situations unexplored. To bridge this, we introduce a collision-related concept of conflict as an intermediate search target and propose a two-stage scenario testing framework that first searches for conflicts and then mutates these conflict scenarios to induce actual collisions. Evaluated on Baidu Apollo, our approach reveals up to 12 distinct collision types in a single run, doubling the diversity discovered by state-of-the-art baselines while requiring fewer simulations thanks to conflict-targeted mutations. These results show that using conflicts as intermediate objectives broadens the search horizon and significantly improves the efficiency and effectiveness of ADS safety evaluation.

</details>


### [118] [TurboADMM: A Structure-Exploiting Parallel Solver for Multi-Agent Trajectory Optimization](https://arxiv.org/abs/2602.15838)
*Yucheng Chen*

Main category: cs.RO

TL;DR: 本文提出了一种专门用于多智能体轨迹优化的新型QP求解器TurboADMM，大幅提升了在高密度耦合与大规模环境下的计算效率。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在实际应用中普遍存在，例如自动驾驶、机器人协作等，这类问题因智能体数量增多和交互加密，导致联合二次规划(QP)问题规模庞大且耦合复杂。现有的通用或结构化QP求解器对大规模多智能体问题难以兼顾可扩展性和计算效率，因此亟需专门面向此类结构的高效求解器。

Method: 作者提出TurboADMM，将三种技术协同组合：（1）通过ADMM分解，将大问题拆分为可并行处理的单智能体子问题，同时保留了原始问题的块三对角结构，适用于高密度耦合；（2）利用Riccati递归算法进行warmstart，为每个智能体QP提供高质量的初始解，加速收敛；（3）在qpOASES中实现parametric QP hotstart，即在ADMM迭代中重复利用KKT系统的分解结果，进一步节省计算时间。

Result: TurboADMM在实验中实现了随着智能体数量线性增长的计算复杂度，显著超过了现有通用（OSQP、MOSEK）和结构化（HPIPM）求解器，展现出优越的可扩展性和效率。

Conclusion: TurboADMM系统性结合了分布式分解、时间结构利用和迭代相似性复用三大关键策略，在解决大规模高密度耦合多智能体轨迹优化问题时表现出色，为相关领域实际应用提供了高效的计算工具。

Abstract: Multi-agent trajectory optimization with dense interaction networks require solving large coupled QPs at control rates, yet existing solvers fail to simultaneously exploit temporal structure, agent decomposition, and iteration similarity. One usually treats multi-agent problems monolithically when using general-purpose QP solvers (OSQP, MOSEK), which encounter scalability difficulties with agent count. Structure-exploiting solvers (HPIPM) leverage temporal structure through Riccati recursion but can be vulnerable to dense coupling constraints. We introduce TurboADMM, a specialized single-machine QP solver that achieves empirically near linear complexity in agent count through systematic co-design of three complementary components: (1) ADMM decomposition creates per-agent subproblems solvable in parallel, preserving block-tridiagonal structure under dense coupling; (2) Riccati warmstart exploits temporal structure to provide high-quality primal-dual initialization for each agent's QP; (3) parametric QP hotstart \footnote{In the paper, we refer warmstart as the technique that uses the Riccati equation results as auxiliary QP initialization for a single QP solve, while hotstart as reusing the QR factorization across QP solve iterations.}in qpOASES reuses similar KKT system factorizations across ADMM iterations.

</details>


### [119] [A Decade of Human-Robot Interaction through Immersive Lenses: A Literature Review on Extended Reality as a Research Instrument in Social Robotics](https://arxiv.org/abs/2602.15840)
*André Helgert,Carolin Straßmann,Sabrina C. Eimler*

Main category: cs.RO

TL;DR: 本文系统回顾了2015至2025年间XR在人机交互（HRI）社会机器人研究中的实证应用，发现相关研究较少且多集中于实验室环境，报告信息和样本多样性不足。


<details>
  <summary>Details</summary>
Motivation: 随着XR（扩展现实）技术包括虚拟现实、增强现实和混合现实的发展，其在人机交互领域受到关注，但在社会机器人实证研究中仍利用有限。因此，作者希望梳理并评估该领域的研究现状与挑战。

Method: 作者对2015-2025年期间共6527篇同行评审文章进行系统筛查，严格筛选后仅33篇被纳入综述。分析内容包括XR及虚拟社会机器人的使用场景、数据收集与分析方法、研究团队及参与者构成、并总结研究现有困难和未来方向。

Result: 结果显示，社会XR-HRI研究主要局限在实验室模拟，核心技术细节常常缺失。大多数机器人作为被动视觉刺激而非高度交互主体。此外，头戴显示器的生理信号跟踪功能未被充分利用。研究者与被试群体偏向技术背景、西方、年轻、男性，样本组成单一且报告不充分。主要瓶颈是技术延迟、小且同质化样本及实验周期短。

Conclusion: 作者提出，应通过方法创新、提升生态效度、增强机器人交互性能、促进样本多样性及建立研究分类体系五大阶段，推动社会XR-HRI研究成熟化，以便其更好服务于社会机器人领域的实证研究。

Abstract: Over the past decade, extended reality (XR), including virtual, augmented, and mixed reality, gained attention as a research instrument in human-robot interaction studies, but remains underexplored in empirical investigations of social robotics. To map the field, we systematically reviewed empirical studies from 2015 to 2025. Of 6,527 peer-reviewed articles, only 33 met strict inclusion criteria. We examined (1) how XR and virtual social robots are used and in which contexts, (2) data collection and analysis methods, (3) demographics of the researchers and participants, and (4) the stated challenges and future agendas. Our findings show that social XR-HRI research is still dominated by laboratory simulations, while crucial specifications like used hardware, software, and robots are often not reported. Robots typically act as passive and less interactive visual stimuli, while the rich biosignal (e.g., eye-tracking) and logging functions of modern head-mounted displays remain largely untapped. The research teams and samples are predominantly tech-centric, Western, young, and male, with frequent gaps in demographic reporting. Key limitations include hardware delays, small homogeneous samples, and short, shallow study cycles. We propose a five-phase roadmap to establish social XR-HRI as a reliable research medium, which includes fostering methodological innovation, a reinforced ecological validity by, e.g., using application contexts, the improvement of the robot's interaction quality, promoting diversity in the sample and the development of a social XR-HRI taxonomy. Advancing in these directions is essential for XR to mature from a lab prototype into an ecologically valid research instrument for social robotics.

</details>


### [120] [ReasonNavi: Human-Inspired Global Map Reasoning for Zero-Shot Embodied Navigation](https://arxiv.org/abs/2602.15864)
*Yuzhuo Ao,Anbang Wang,Yu-Wing Tai,Chi-Keung Tang*

Main category: cs.RO

TL;DR: 本文提出ReasonNavi，一种结合多模态大模型与确定性规划的零样本导航方法，通过引入全局推理和局部执行，显著提升了具身智能体的导航效率。


<details>
  <summary>Details</summary>
Motivation: 目前的具身智能体依赖于局部视角，缺乏全局导航规划能力，导致探索效率低下；而人类的导航则充分利用地图和全局推理，因此需要引入类似的人类导航机制提升智能体能力。

Method: ReasonNavi 用房间分割和候选目标节点采样，将俯视地图转为离散推理空间，然后多轮调用多模态大模型（MLLMs）选择与任务描述最匹配的节点。针对选定节点，再用在线构建的占据栅格图和确定性动作规划输出可执行轨迹，最终借助预训练的目标检测与分割模型提升终点识别鲁棒性，全流程无需对MLLM微调。

Result: ReasonNavi 在三个导航任务中均大幅优于需大量训练或复杂场景建模的既有方法，且表现出良好的可扩展性和解释性。

Conclusion: ReasonNavi 构建了一套无需训练、可解释性强且能随基础大模型进步自然扩展的全局导航方案，为具身智能体高效、类人导航带来新范式。

Abstract: Embodied agents often struggle with efficient navigation because they rely primarily on partial egocentric observations, which restrict global foresight and lead to inefficient exploration. In contrast, humans plan using maps: we reason globally first, then act locally. We introduce ReasonNavi, a human-inspired framework that operationalizes this reason-then-act paradigm by coupling Multimodal Large Language Models (MLLMs) with deterministic planners. ReasonNavi converts a top-down map into a discrete reasoning space by room segmentation and candidate target nodes sampling. An MLLM is then queried in a multi-stage process to identify the candidate most consistent with the instruction (object, image, or text goal), effectively leveraging the model's semantic reasoning ability while sidestepping its weakness in continuous coordinate prediction. The selected waypoint is grounded into executable trajectories using a deterministic action planner over an online-built occupancy map, while pretrained object detectors and segmenters ensure robust recognition at the goal. This yields a unified zero-shot navigation framework that requires no MLLM fine-tuning, circumvents the brittleness of RL-based policies and scales naturally with foundation model improvements. Across three navigation tasks, ReasonNavi consistently outperforms prior methods that demand extensive training or heavy scene modeling, offering a scalable, interpretable, and globally grounded solution to embodied navigation. Project page: https://reasonnavi.github.io/

</details>


### [121] [MARVL: Multi-Stage Guidance for Robotic Manipulation via Vision-Language Models](https://arxiv.org/abs/2602.15872)
*Xunlan Zhou,Xuanlin Chen,Shaowei Zhang,Xiangkun Li,ShengHua Wan,Xiaohai Hu,Yuan Lei,Le Gan,De-chuan Zhan*

Main category: cs.RO

TL;DR: 本论文提出了MARVL方法，通过多阶段指导和视觉语言模型提升了机器人强化学习中的稠密奖励设计，实验表明其在操作任务上效果显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 稠密奖励函数对于机器人强化学习的效率非常重要，但目前多依赖手工设计，限制了自动化与大规模应用。视觉语言模型虽然有潜力用于奖励设计，但现有方法在任务进展和语义理解等方面存在明显不足。

Method: 作者提出MARVL方法，通过对视觉语言模型进行空间和语义一致性的微调，并将复杂任务分解为多阶段子任务，通过任务方向投影增强轨迹敏感性，从而提升奖励设计的有效性与泛化能力。

Result: 在Meta-World基准测试中，MARVL在样本效率和稀疏奖励下的操作任务鲁棒性方面，均显著优于现有VLM奖励方法。

Conclusion: MARVL为基于视觉语言模型的奖励函数设计提供了有效途径，显著提升了机器人的学习效率和泛化能力，实现了稠密奖励函数的自动化与可扩展化。

Abstract: Designing dense reward functions is pivotal for efficient robotic Reinforcement Learning (RL). However, most dense rewards rely on manual engineering, which fundamentally limits the scalability and automation of reinforcement learning. While Vision-Language Models (VLMs) offer a promising path to reward design, naive VLM rewards often misalign with task progress, struggle with spatial grounding, and show limited understanding of task semantics. To address these issues, we propose MARVL-Multi-stAge guidance for Robotic manipulation via Vision-Language models. MARVL fine-tunes a VLM for spatial and semantic consistency and decomposes tasks into multi-stage subtasks with task direction projection for trajectory sensitivity. Empirically, MARVL significantly outperforms existing VLM-reward methods on the Meta-World benchmark, demonstrating superior sample efficiency and robustness on sparse-reward manipulation tasks.

</details>


### [122] [Test-Time Adaptation for Tactile-Vision-Language Models](https://arxiv.org/abs/2602.15873)
*Chuyang Ye,Haoxian Jing,Qinting Jiang,Yixi Lin,Qiang Li,Xing Tang,Jingyan Jiang*

Main category: cs.RO

TL;DR: 提出一种用于触觉-视觉-语言多模态模型在测试时适应分布变化的新方法，能显著提升不同模态受扰动时的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时自适应（TTA）方法主要针对单一模态，缺乏对多模态中各个模态可靠性的显式建模。当某些模态在测试时变得不可靠时，现有方法表现不佳。

Method: 通过从模型预测的不确定性和扰动响应中估计每个模态的可靠性。利用这个可靠性信号进行：（1）筛查不可靠的测试样本；（2）自适应融合触觉、视觉和语言特征；（3）用可靠性引导的目标函数对测试时优化过程进行正则化。

Result: 在TAG-C基准和其他TVL场景下，该方法在不同模态严重受损时，对比强基线表现出高达49.9%的准确率提升。

Conclusion: 对各模态可靠性进行显式建模，对于多模态模型在测试时适应分布变化和保持鲁棒性至关重要。

Abstract: Tactile-vision-language (TVL) models are increasingly deployed in real-world robotic and multimodal perception tasks, where test-time distribution shifts are unavoidable. Existing test-time adaptation (TTA) methods provide filtering in unimodal settings but lack explicit treatment of modality-wise reliability under asynchronous cross-modal shifts, leaving them brittle when some modalities become unreliable. We study TTA for TVL models under such shifts and propose a reliability-aware framework that estimates per-modality reliability from prediction uncertainty and perturbation-based responses. This shared reliability signal is used to (i) filter unreliable test samples, (ii) adaptively fuse tactile, visual, and language features, and (iii) regularize test-time optimization with a reliability-guided objective. On the TAG-C benchmark and additional TVL scenarios, our approach consistently outperforms strong TTA baselines, achieving accuracy gains of up to 49.9\% under severe modality corruptions, underscoring the importance of explicit modality-wise reliability modeling for robust test-time adaptation.

</details>


### [123] [Fly0: Decoupling Semantic Grounding from Geometric Planning for Zero-Shot Aerial Navigation](https://arxiv.org/abs/2602.15875)
*Zhenxing Xu,Brikit Lu,Weidong Bao,Zhengqiu Zhu,Junsong Zhang,Hui Yan,Wenhao Lu,Ji Wang*

Main category: cs.RO

TL;DR: 本文提出了一种新型视觉-语言导航（VLN）方法Fly0，将语义推理与几何规划解耦，通过三阶段流程提升导航性能，并显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言导航方法在语义理解与控制精度之间存在权衡。多模态大模型虽然推理能力强，但作为底层控制器时，存在高延迟、轨迹震荡、泛化能力差等问题。本研究旨在解决这些限制。

Method: Fly0方法通过三阶段流程实现：（1）由多模态大模型驱动，将自然语言指令映射为2D像素坐标；（2）利用深度数据，通过几何投影将目标定位到3D空间；（3）几何规划器生成无碰撞运动轨迹。该方案在导航过程中减少连续推理需求，提高效率与稳定性，即使目标在视觉上丢失也能稳健导航。

Result: 在仿真和真实环境中的大量实验表明，Fly0方法在无结构环境下，导航成功率提升20%以上，导航误差降低约50%，各项性能均优于现有最先进方法。

Conclusion: Fly0通过解耦语义与几何模块，兼顾语义理解和运动控制，克服了大模型作为底层控制器的缺陷，显著提升了导航系统的性能与鲁棒性。

Abstract: Current Visual-Language Navigation (VLN) methodologies face a trade-off between semantic understanding and control precision. While Multimodal Large Language Models (MLLMs) offer superior reasoning, deploying them as low-level controllers leads to high latency, trajectory oscillations, and poor generalization due to weak geometric grounding. To address these limitations, we propose Fly0, a framework that decouples semantic reasoning from geometric planning. The proposed method operates through a three-stage pipeline: (1) an MLLM-driven module for grounding natural language instructions into 2D pixel coordinates; (2) a geometric projection module that utilizes depth data to localize targets in 3D space; and (3) a geometric planner that generates collision-free trajectories. This mechanism enables robust navigation even when visual contact is lost. By eliminating the need for continuous inference, Fly0 reduces computational overhead and improves system stability. Extensive experiments in simulation and real-world environments demonstrate that Fly0 outperforms state-of-the-art baselines, improving the Success Rate by over 20\% and reducing Navigation Error (NE) by approximately 50\% in unstructured environments. Our code is available at https://github.com/xuzhenxing1/Fly0.

</details>


### [124] [FUTURE-VLA: Forecasting Unified Trajectories Under Real-time Execution](https://arxiv.org/abs/2602.15882)
*Jingjing Fan,Yushan Liu,Shoujie Li,Botao Ren,Siyuan Li,Xiao-Ping Zhang,Wenbo Ding,Zhidong Deng*

Main category: cs.RO

TL;DR: 本文提出了FUTURE-VLA架构，能高效处理机器人长时序空间-时间推理任务，同时大幅降低延迟，实现实时性预测和控制。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型虽能处理长视频流的空间-时间推理，但部署到机器人时，因处理历史数据和未来预测时延过高，难以真实应用。

Method: FUTURE-VLA将长时域控制和未来预测统一建模为序列生成任务，采用时间自适应压缩，提升信息密度，保持推理延迟恒定；同时在潜空间做自回归预测，实现高效的一帧式并发前瞻控制。此外，模型支持人机协作的交互执行门控，允许操作者根据未来可视化结果动态验证行为。

Result: FUTURE-VLA在LIBERO、RoboTwin和真实Piper平台等多个基准上均创下新最高成功率（分别为99.2%、75.4%和78.0%），且在16倍时空窗口扩展下，保持单帧推理延迟。

Conclusion: FUTURE-VLA显著提升了机器人在长时序复杂任务中的推理与控制效率，同时保障了实时交互能力，并显著超过现有技术水平。

Abstract: General vision-language models increasingly support unified spatiotemporal reasoning over long video streams, yet deploying such capabilities on robots remains constrained by the prohibitive latency of processing long-horizon histories and generating high-dimensional future predictions. To bridge this gap, we present FUTURE-VLA, a unified architecture that reformulates long-horizon control and future forecasting as a monolithic sequence-generation task. Adopting a dual-sided efficiency paradigm, FUTURE-VLA leverages a temporally adaptive compression strategy to maximize spatiotemporal information density, enabling the ingestion of extensive multi-view histories while maintaining constant inference latency. Simultaneously, it performs latent-space autoregression to align actionable dynamics with reviewable visual look-aheads in a single forward pass. These real-time predictive capabilities further enable a prediction-guided Human-In-the-Loop mechanism via interactive execution gating, allowing operators to dynamically validate behaviors based on interpretable future previews. Extensive evaluations demonstrate that FUTURE-VLA establishes new state-of-the-art performance, attaining success rates of 99.2% on LIBERO, 75.4% on RoboTwin, and 78.0% on a real-world Piper platform, all with a $16\times$ extended spatiotemporal window while maintaining the inference latency of a single-frame baseline.

</details>


### [125] [The SLAM Confidence Trap](https://arxiv.org/abs/2602.15884)
*Sebastian Sansoni,Santiago Ramón Tosetti Sanz*

Main category: cs.RO

TL;DR: 该论文指出SLAM领域过于关注基准评分，忽视了对不确定性的有效估计，导致系统虽然几何精度高但不够稳健。作者呼吁应将实时一致性的不确定性估计作为主要评价指标。


<details>
  <summary>Details</summary>
Motivation: 当前SLAM研究追求高基准分数，但对不确定性的估计不够重视，导致系统脆弱、不具可靠性。作者想解决这一问题。

Method: 论文提出将不确定性一致性和实时计算能力作为评估SLAM系统的新标准，而非仅依赖传统基准评测。

Result: 证明了现有方法下SLAM系统在几何上虽然精确但却不具概率一致性，提出该新的评估方式后有助于提升系统的稳健性。

Conclusion: 一致性的实时不确定性估计应成为SLAM评价的新常态，有望推动更可靠实用的SLAM技术发展。

Abstract: The SLAM community has fallen into a "Confidence Trap" by prioritizing benchmark scores over principled uncertainty estimation. This yields systems that are geometrically accurate but probabilitistically inconsistent and brittle. We advocate for a paradigm shift where the consistent, real-time computation of uncertainty becomes a primary metric of success.

</details>


### [126] [A novel Integrated Motion Tracking Device (IMTD) for Objective Laparoscopic Training Assessment: Development and Validation](https://arxiv.org/abs/2602.15885)
*Siwar Bouzid,Abdelbadia Chaker,Marc Arsicault,Sami Bennour,Med Amine Laribi*

Main category: cs.RO

TL;DR: 本论文提出了一种新型、紧凑的四自由度运动跟踪设备（IMTD），用于腹腔镜手术训练与评估，具有高精度、低成本、易集成等优点。


<details>
  <summary>Details</summary>
Motivation: 腹腔镜手术对医生操作技能要求极高，但传统训练手段缺乏精确、客观的动作反馈。本研究旨在开发一种既经济实用又能高精度跟踪手术动作的设备，以提升训练与评估效率。

Method: 作者设计并开发了IMTD设备，从运动学、机械结构、仪器集成到原型实现，并与现有运动捕捉系统（MoCap）在角运动与平移运动跟踪精度等方面进行了性能对比，同时评估了包括精度、流畅性、速度和效率等指标。

Result: IMTD系统在手术动作跟踪方面表现优异，能有效追踪并评估训练者的精细动作，在多项核心性能参数上显示出良好的效果。

Conclusion: IMTD设备不仅成本低、便于集成，还能为手术训练提供实时、客观反馈，有助于提升外科技能、缩短新手学习曲线，为后续手势评分算法与标准化训练协议的发展奠定基础。

Abstract: This paper presents a novel, compact four-degree-of-freedom motion-tracking device (IMTD) designed for training and evaluation in laparoscopic surgery. The device's kinematics, mechanical design, instrumentation, and prototypes are developed and presented to meet the specific requirements of laparoscopic training context, including movement around a fixed center of motion and seamless integration into standard box trainers. The system IMTD's tracking accuracy and reliability are compared to a motion capture system (MoCap), assessing its ability to capture both angular and translational motions of surgical instruments. The study then focuses on key performance parameters including precision, fluidity, speed, and overall motion efficiency. The results highlight the system's effectiveness in tracking surgical gestures, providing valuable insights into its potential as a tool for training and performance evaluation in minimally invasive surgery. Additionally, IMTD's low cost and integrated design allow for easy integration and implementation in training rooms, offering a practical and accessible solution for general use. By offering objective, real-time feedback, the system can significantly contribute to improving surgical skills and shortening the learning curve for novice students, while also providing a foundation for future development of gesture scoring algorithms and standardized training protocols.

</details>


### [127] [Optimization of an Augmented R-CUBE mechanism for Cervical Surgery](https://arxiv.org/abs/2602.15886)
*Terence Essomba,Yu-Wen Wu,Abdelbadia Chaker,Med Amine Laribi*

Main category: cs.RO

TL;DR: 本文提出一种新型机械结构来辅助脊柱手术中椎骨钻孔，基于扩展型R-CUBE机构，可实现复杂的空间运动以提升手术精度和灵活性。


<details>
  <summary>Details</summary>
Motivation: 脊柱手术中需要高精度、高自由度的机械操作来安全高效地完成椎骨钻孔，现有设备在运动自由度和灵活性上存在不足。

Method: 提出了一种基于全平移R-CUBE机制并增加了额外旋转运动的新型机械结构，包含三个运动阶段：平移、传动和旋转，分别建立了其运动学和速度模型，并结合真实病例的手术轨迹进行优化。

Result: 该机构能够实现3T2R（3个平移+2个旋转）自由度运动，优化后能生成最佳的运动学性能以适应临床手术需求。

Conclusion: 新机械结构增强了椎骨钻孔操作的灵活性和性能，有望提升脊柱手术的精确性和安全性。

Abstract: In some surgical operations targeting the spine, it is required to drill cavities in the vertebrae for the insertion of pedicle screws. A new mechanical architecture is proposed for this application. It is based on an augmented version of the full translational R-CUBE mechanism, with improved linkages to implement additional rotational motion. Using this concept, a mechanism presented with a 3T2R motion that is required for the manipulation of the surgical drill. It is mainly composed three stages: one translational, one transmitting and one rotational. Their respective kinematic and velocity models are separately derived, then combined. Based on the drilling trajectories obtained from a real patient case, the mechanism is optimized for generating the highest kinematic performances.

</details>


### [128] [Learning to Drive in New Cities Without Human Demonstrations](https://arxiv.org/abs/2602.15891)
*Zilin Wang,Saeed Rahmani,Daphne Cornelisse,Bidipta Sarkar,Alexander David Goldie,Jakob Nicolaus Foerster,Shimon Whiteson*

Main category: cs.RO

TL;DR: 该论文提出了一种无需人工示范、仅凭地图和城市元信息就能快速适应新城市自动驾驶策略的方法。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶车辆在不同城市部署时，往往因需大量人工驾驶数据而耗时耗力。城市间道路、交通规则和互动模式不同，使得策略迁移难度很大。

Method: 作者提出了NOMAD（NO data Map-based self-play for Autonomous Driving）方法，通过仅利用目标城市的地图和元信息，在仿真环境中用多智能体自对弈强化学习进行策略自适应，无需目标城市的人工演示数据。

Result: 在目标城市，以简单奖励函数训练出的NOMAD方法显著提升了任务成功率和轨迹真实性，优于其他依赖大量数据的迁移方法。

Conclusion: NOMAD提供了一种高效、可扩展且无需目标城市人工数据的解决方案，有效推动了自动驾驶策略的跨城市迁移。

Abstract: While autonomous vehicles have achieved reliable performance within specific operating regions, their deployment to new cities remains costly and slow. A key bottleneck is the need to collect many human demonstration trajectories when adapting driving policies to new cities that differ from those seen in training in terms of road geometry, traffic rules, and interaction patterns. In this paper, we show that self-play multi-agent reinforcement learning can adapt a driving policy to a substantially different target city using only the map and meta-information, without requiring any human demonstrations from that city. We introduce NO data Map-based self-play for Autonomous Driving (NOMAD), which enables policy adaptation in a simulator constructed based on the target-city map. Using a simple reward function, NOMAD substantially improves both task success rate and trajectory realism in target cities, demonstrating an effective and scalable alternative to data-intensive city-transfer methods. Project Page: https://nomaddrive.github.io/

</details>


### [129] [Statistical-Geometric Degeneracy in UAV Search: A Physics-Aware Asymmetric Filtering Approach](https://arxiv.org/abs/2602.15893)
*Zhiyuan Ren,Yudong Fang,Tao Zhang,Wenchi Cheng,Ben Lan*

Main category: cs.RO

TL;DR: 本论文针对无人机在灾后环境下定位幸存者时，由于废墟造成的大量非视距（NLOS）传播而出现的定位偏差问题，提出了一种结合物理约束和非对称损失函数的新型滤波方法，显著提升了定位的准确性和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 传统的定位方法及滤波器多基于误差对称性的假设，但在灾后坍塌结构中，信号反射引发的定位误差具有严格非负性，造成常规鲁棒估计器（如Huber或Tukey）性能下降，甚至出现统计-几何退化问题。此外，数据驱动方法在灾害环境中缺乏足够训练数据，难以可靠应用。针对这一物理实际与理论工具之间的脱节，本文提出新的方法。

Method: 作者设计了AsymmetricHuberEKF滤波器，通过引入基于物理先验（NLOS误差为非负）的非对称损失函数，改进定位滤波过程，并在理论上证明对称滤波器只是该新框架的特例。此外，通过与主动感知策略联合设计，获得“双边信息”，进一步提升估计性能。在2D扫描实验证明其有效性。

Result: 新方法在2D俯视扫描场景下，与传统对称滤波基线方法相比，大幅加快了收敛速度和定位鲁棒性。即使在观测数据有限和复杂几何限制下，仍显示出优异性能。

Conclusion: 本文方法突破了灾后场景“数据少、几何受限”的定位固有限制，基于物理模型设计滤波器并与主动感知策略联合，显著提升了鲁棒性和收敛效率，为实际无人机搜救任务提供了更可靠的基础。

Abstract: Post-disaster survivor localization using Unmanned Aerial Vehicles (UAVs) faces a fundamental physical challenge: the prevalence of Non-Line-of-Sight (NLOS) propagation in collapsed structures. Unlike standard Gaussian noise, signal reflection from debris introduces strictly non-negative ranging biases. Existing robust estimators, typically designed with symmetric loss functions (e.g., Huber or Tukey), implicitly rely on the assumption of error symmetry. Consequently, they experience a theoretical mismatch in this regime, leading to a phenomenon we formally identify as Statistical-Geometric Degeneracy (SGD)-a state where the estimator stagnates due to the coupling of persistent asymmetric bias and limited observation geometry. While emerging data-driven approaches offer alternatives, they often struggle with the scarcity of training data and the sim-to-real gap inherent in unstructured disaster zones. In this work, we propose a physically-grounded solution, the AsymmetricHuberEKF, which explicitly incorporates the non-negative physical prior of NLOS biases via a derived asymmetric loss function. Theoretically, we show that standard symmetric filters correspond to a degenerate case of our framework where the physical constraint is relaxed. Furthermore, we demonstrate that resolving SGD requires not just a robust filter, but specific bilateral information, which we achieve through a co-designed active sensing strategy. Validated in a 2D nadir-view scanning scenario, our approach significantly accelerates convergence compared to symmetric baselines, offering a resilient building block for search operations where data is scarce and geometry is constrained.

</details>


### [130] [VGGT-based online 3D semantic SLAM for indoor scene understanding and navigation](https://arxiv.org/abs/2602.15899)
*Anna Gelencsér-Horváth,Gergely Dinya,Dorka Boglárka Erős,Péter Halász,Islam Muhammad Muqsit,Kristóf Karacs*

Main category: cs.RO

TL;DR: 本文提出了SceneVGGT，一个集成SLAM与语义映射的三维场景理解框架，能高效处理长视频流，实现交互性强的辅助导航。


<details>
  <summary>Details</summary>
Motivation: 为了解决在自主和辅助导航场景下，实现高效、时空一致的三维语义场景理解面临的计算资源和实时性挑战。

Method: 提出基于VGGT的SceneVGGT框架，采用滑动窗口处理长视频流，通过相机位姿对齐局部子图，以提升内存与速度效率，将2D语义实例提升为3D目标，并用于辅助导航。

Result: 该方法GPU显存使用不超过17GB且不随输入序列长度增长，在ScanNet++基准点云任务上有竞争力的表现，并具备支持实时交互导航的速度。

Conclusion: SceneVGGT能够实现鲁棒的三维语义识别，速度快，适合于带音频反馈的交互式辅助导航等实际应用。

Abstract: We present SceneVGGT, a spatio-temporal 3D scene understanding framework that combines SLAM with semantic mapping for autonomous and assistive navigation. Built on VGGT, our method scales to long video streams via a sliding-window pipeline. We align local submaps using camera-pose transformations, enabling memory- and speed-efficient mapping while preserving geometric consistency. Semantics are lifted from 2D instance masks to 3D objects using the VGGT tracking head, maintaining temporally coherent identities for change detection. As a proof of concept, object locations are projected onto an estimated floor plane for assistive navigation. The pipeline's GPU memory usage remains under 17 GB, irrespectively of the length of the input sequence and achieves competitive point-cloud performance on the ScanNet++ benchmark. Overall, SceneVGGT ensures robust semantic identification and is fast enough to support interactive assistive navigation with audio feedback.

</details>


### [131] [Adaptive Illumination Control for Robot Perception](https://arxiv.org/abs/2602.15900)
*Yash Turkar,Shekoufeh Sadeghi,Karthik Dantu*

Main category: cs.RO

TL;DR: 论文提出了一种新的机器人闭环照明控制框架Lightning，用于在低光或高动态范围环境下提升视觉SLAM效果，并同时兼顾能耗与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在低光或高动态范围环境下，机器人感知能力受限。现有方案通过特征增强或曝光控制等方式改进，但最终依赖于受限的原始图像质量。通过主动可编程补光可提升图像质量，但其对成像的具体影响受多因素非线性耦合影响，难以精确预测。本文旨在解决补光对视觉SLAM的系统性作用与最优策略问题。

Method: 作者提出了Lightning框架，包括三大步骤：1）训练一个共位照明分解模型（CLID），将场景分解为环境光和补光成分，实现不同行为下的数据生成；2）基于合成数据，提出离线最优补光强度调度（OIS），在图像效用、功耗和平滑性之间权衡补光策略；3）将最优调度通过行为克隆转化为可实时运行的照明控制策略（ILC），以供实际机器人在线控制。

Result: Lightning在评估中显著提升了SLAM轨迹的鲁棒性，并有效减少了不必要的照明功耗。

Conclusion: 主动照明的闭环控制能显著增强极端光照环境下的机器人视觉SLAM性能。该框架实现了补光的自动优化与实时应用，为感知系统升级提供了新思路。

Abstract: Robot perception under low light or high dynamic range is usually improved downstream - via more robust feature extraction, image enhancement, or closed-loop exposure control. However, all of these approaches are limited by the image captured these conditions. An alternate approach is to utilize a programmable onboard light that adds to ambient illumination and improves captured images. However, it is not straightforward to predict its impact on image formation. Illumination interacts nonlinearly with depth, surface reflectance, and scene geometry. It can both reveal structure and induce failure modes such as specular highlights and saturation. We introduce Lightning, a closed-loop illumination-control framework for visual SLAM that combines relighting, offline optimization, and imitation learning. This is performed in three stages. First, we train a Co-Located Illumination Decomposition (CLID) relighting model that decomposes a robot observation into an ambient component and a light-contribution field. CLID enables physically consistent synthesis of the same scene under alternative light intensities and thereby creates dense multi-intensity training data without requiring us to repeatedly re-run trajectories. Second, using these synthesized candidates, we formulate an offline Optimal Intensity Schedule (OIS) problem that selects illumination levels over a sequence trading off SLAM-relevant image utility against power consumption and temporal smoothness. Third, we distill this ideal solution into a real-time controller through behavior cloning, producing an Illumination Control Policy (ILC) that generalizes beyond the initial training distribution and runs online on a mobile robot to command discrete light-intensity levels. Across our evaluation, Lightning substantially improves SLAM trajectory robustness while reducing unnecessary illumination power.

</details>


### [132] [Coverage Path Planning for Autonomous Sailboats in Inhomogeneous and Time-Varying Oceans: A Spatiotemporal Optimization Approach](https://arxiv.org/abs/2602.15901)
*Yang An,Zhikang Ge,Taiyu Zhang,Jean-Baptiste R. G. Souppez,Gaofei Xu,Zhengru Ren*

Main category: cs.RO

TL;DR: 提出了一种针对自主帆船在时空异质海洋环境下的覆盖路径规划新方法，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 自主帆船依靠风力行驶，具有较长续航能力，被广泛用于海洋观测。但其性能取决于变化多端的风流环境，传统的覆盖方法（如牛耕式扫描）在现实复杂海洋环境下效率低，缺乏对环境约束下的路径规划研究。

Method: 提出时空领域结合的覆盖路径规划框架：在空间上引入基于拓扑的形态约束以实现紧凑、连续的覆盖，在时间上结合对未来风流预报的前瞻性路径规划，综合考虑环境变化以制定决策。

Result: 在随机非均质及随时间变化的仿真海洋环境中进行了测试，包括一定角度方向不可达的情况。结果显示，该方法能生成高效、可行的覆盖路径，而传统策略多数失效。

Conclusion: 本研究首次为自主帆船在时空异质海洋环境中提供专门的覆盖路径规划解决方案，为未来多帆船协同覆盖打下基础。

Abstract: Autonomous sailboats are well suited for long-duration ocean observation due to their wind-driven endurance. However, their performance is highly anisotropic and strongly influenced by inhomogeneous and time-varying wind and current fields, limiting the effectiveness of existing coverage methods such as boustrophedon sweeping. Planning under these environmental and maneuvering constraints remains underexplored. This paper presents a spatiotemporal coverage path planning framework tailored to autonomous sailboats, combining (1) topology-based morphological constraints in the spatial domain to promote compact and continuous coverage, and (2) forecast-aware look-ahead planning in the temporal domain to anticipate environmental evolution and enable foresighted decision-making. Simulations conducted under stochastic inhomogeneous and time-varying ocean environments, including scenarios with partial directional accessibility, demonstrate that the proposed method generates efficient and feasible coverage paths where traditional strategies often fail. To the best of our knowledge, this study provides the first dedicated solution to the coverage path planning problem for autonomous sailboats operating in inhomogeneous and time-varying ocean environments, establishing a foundation for future cooperative multi-sailboat coverage.

</details>


### [133] [World Action Models are Zero-shot Policies](https://arxiv.org/abs/2602.15922)
*Seonghyeon Ye,Yunhao Ge,Kaiyuan Zheng,Shenyuan Gao,Sihyun Yu,George Kurian,Suneel Indupuru,You Liang Tan,Chuning Zhu,Jiannan Xiang,Ayaan Malik,Kyungmin Lee,William Liang,Nadun Ranawaka,Jiasheng Gu,Yinzhen Xu,Guanzhi Wang,Fengyuan Hu,Avnish Narayan,Johan Bjorck,Jing Wang,Gwanghyun Kim,Dantong Niu,Ruijie Zheng,Yuqi Xie,Jimmy Wu,Qi Wang,Ryan Julian,Danfei Xu,Yilun Du,Yevgen Chebotar,Scott Reed,Jan Kautz,Yuke Zhu,Linxi "Jim" Fan,Joel Jang*

Main category: cs.RO

TL;DR: 本论文提出了DreamZero，一种基于视频扩散模型的世界动作模型（WAM），能有效提升机器人在新环境和任务中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的视觉-语言-动作（VLA）模型在语义泛化方面表现出色，但对于未知物理运动和新环境的泛化能力较弱。作者希望突破这一限制，实现机器人跨环境、跨任务的泛化。

Method: 作者提出DreamZero，将预训练的视频扩散神经网络作为骨干，通过联合建模视频和机器人动作，直接预测世界的未来状态和动作，并能有效从多样和异构的机器人数据中学习技能，无需连续重复演示。同时，针对模型和系统进行优化，使14B的视频扩散模型可在7Hz的闭环控制环境下实时运行，支持实际机器人任务。

Result: 与现有VLA方法相比，DreamZero在真实机器人实验中在新任务和新环境上的泛化能力提升了2倍以上。在仅10-20分钟的视频演示下，跨主体（机器人/人类）迁移任务上的性能提升超过42%。对于新机器人形态，利用30分钟的“随意操作”数据即可实现少样本迁移，同时保持零样本泛化能力。

Conclusion: DreamZero证明了通过视频和动作的联合建模，机器人能够在复杂环境下大幅提升泛化能力，支持高效的跨任务、跨主体和跨形态迁移，朝向更通用的机器人智能迈进一步。

Abstract: State-of-the-art Vision-Language-Action (VLA) models excel at semantic generalization but struggle to generalize to unseen physical motions in novel environments. We introduce DreamZero, a World Action Model (WAM) built upon a pretrained video diffusion backbone. Unlike VLAs, WAMs learn physical dynamics by predicting future world states and actions, using video as a dense representation of how the world evolves. By jointly modeling video and action, DreamZero learns diverse skills effectively from heterogeneous robot data without relying on repetitive demonstrations. This results in over 2x improvement in generalization to new tasks and environments compared to state-of-the-art VLAs in real robot experiments. Crucially, through model and system optimizations, we enable a 14B autoregressive video diffusion model to perform real-time closed-loop control at 7Hz. Finally, we demonstrate two forms of cross-embodiment transfer: video-only demonstrations from other robots or humans yield a relative improvement of over 42% on unseen task performance with just 10-20 minutes of data. More surprisingly, DreamZero enables few-shot embodiment adaptation, transferring to a new embodiment with only 30 minutes of play data while retaining zero-shot generalization.

</details>


### [134] [Hybrid Model Predictive Control with Physics-Informed Neural Network for Satellite Attitude Control](https://arxiv.org/abs/2602.15954)
*Carlo Cena,Mauro Martini,Marcello Chiaberge*

Main category: cs.RO

TL;DR: 本文采用物理信息神经网络（PINNs）对航天器姿态动力学建模，并与传统的数据驱动方法进行对比，最终证明物理约束的引入大幅提高了预测可靠性和控制性能。


<details>
  <summary>Details</summary>
Motivation: 航天器姿态控制依赖于准确预测其动力学。复杂动力学下基于物理的模型难以获取且计算量大，因此寻求结合物理知识的高效学习方法，以提升模型预测控制（MPC）的效果。

Method: 首先通过高保真数值仿真生成数据集，然后分别采用数据驱动神经网络和引入物理约束优化的PINN方法建模。将学习得到的模型集成至MPC架构，评估其在闭环跟踪和鲁棒性方面表现。最后提出将非线性学习模型和线性名义模型混合的控制方案，进一步提升动态响应能力。

Result: 物理约束的神经网络模型相对纯数据驱动模型在平均相对误差上降低了68.17%。在MPC框架下，物理信息模型实现了更优的跟踪性能和鲁棒性。在实际控制中，混合控制方案在测量噪声和反作用轮摩擦下，使系统收敛时间缩短了61.52%-76.42%。

Conclusion: 在学习航天器复杂动力学时，物理信息神经网络通过引入先验知识显著提升模型预测精度和控制性能，优于单纯数据驱动和传统建模方法，具有实际应用潜力。

Abstract: Reliable spacecraft attitude control depends on accurate prediction of attitude dynamics, particularly when model-based strategies such as Model Predictive Control (MPC) are employed, where performance is limited by the quality of the internal system model. For spacecraft with complex dynamics, obtaining accurate physics-based models can be difficult, time-consuming, or computationally heavy. Learning-based system identification presents a compelling alternative; however, models trained exclusively on data frequently exhibit fragile stability properties and limited extrapolation capability. This work explores Physics-Informed Neural Networks (PINNs) for modeling spacecraft attitude dynamics and contrasts it with a conventional data-driven approach. A comprehensive dataset is generated using high-fidelity numerical simulations, and two learning methodologies are investigated: a purely data-driven pipeline and a physics-regularized approach that incorporates prior knowledge into the optimization process. The results indicate that embedding physical constraints during training leads to substantial improvements in predictive reliability, achieving a 68.17% decrease in mean relative error relative. When deployed within an MPC architecture, the physics-informed models yield superior closed-loop tracking performance and improved robustness to uncertainty. Furthermore, a hybrid control formulation that merges the learned nonlinear dynamics with a nominal linear model enables consistent steady-state convergence and significantly faster response, reducing settling times by 61.52%-76.42% under measurement noise and reaction wheel friction.

</details>


### [135] [The human intention. A taxonomy attempt and its applications to robotics](https://arxiv.org/abs/2602.15963)
*J. E. Domínguez-Vidal,Alberto Sanfeliu*

Main category: cs.RO

TL;DR: 本文总结并梳理了机器人领域对人类意图推断的研究，提出了一种更全面的意图框架，并通过案例分析强调多元化意图理解的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前机器人对人类意图的研究主要聚焦于具体任务目标，对“意图”的定义普遍缺乏统一和深入，导致人机协作理解存在局限。作者希望以心理学视角填补该领域的理论和方法空白。

Method: 文章查阅并整合了心理学、交流学领域有关意图的研究，分类构建了人类意图的多维框架，并将现有机器人研究归入相应类别，通过协作搜索和物体搬运案例深入分析多维意图的重要性。

Result: 提出了基于心理学的意图类型分类指导框架；明确了现有机器人意图推断研究的局限性；案例表明多维意图框架有助于提升机器人理解人类意图的能力。

Conclusion: 推动机器人研究向以人为本的多层次意图理解转变对于提升人机协作体验至关重要，未来应加强多视角、跨学科的意图建模和推断方法。

Abstract: Despite a surge in robotics research dedicated to inferring and understanding human intent, a universally accepted definition remains elusive since existing works often equate human intention with specific task-related goals. This article seeks to address this gap by examining the multifaceted nature of intention. Drawing on insights from psychology, it attempts to consolidate a definition of intention into a comprehensible framework for a broader audience. The article classifies different types of intention based on psychological and communication studies, offering guidance to researchers shifting from pure technical enhancements to a more human-centric perspective in robotics. It then demonstrates how various robotics studies can be aligned with these intention categories. Finally, through in-depth analyses of collaborative search and object transport use cases, the article underscores the significance of considering the diverse facets of human intention.

</details>


### [136] [ODYN: An All-Shifted Non-Interior-Point Method for Quadratic Programming in Robotics and AI](https://arxiv.org/abs/2602.16005)
*Jose Rojas,Aristotelis Papatheodorou,Sergi Martinez,Ioannis Havoutis,Carlos Mastalli*

Main category: cs.RO

TL;DR: 本文提出了一种新的二次规划（QP）求解器ODYN，能高效解决各种规模和难度的密集或稀疏QP问题，特别适用于机器人和人工智能应用。


<details>
  <summary>Details</summary>
Motivation: 当前许多QP求解器难以高效且鲁棒地应对病态或奇异的优化问题，尤其是约束独立性无法保证时，实际应用中需要更强的warm-start鲁棒性和广泛适用性。

Method: ODYN结合了全位移非线性互补问题（NCP）函数与乘子近端法（proximal method of multipliers），避免了对约束线性无关的要求，提升鲁棒性与泛化能力。同时支持高效warm-start并开源实现，在标准Maros-Mészáros基准上进行系统测试。

Result: 实验表明ODYN在小型到大规模问题上均展现出与主流方法同等或优于主流方法的收敛性能，特别是在warm-start（问题序列快速重启）场景下表现优异，适应实时与顺序优化需求。

Conclusion: ODYN是一款性能卓越、应用广泛且易于集成的QP求解器，在机器人、AI和优化相关领域具备明显优势，并已成功应用于预测控制、可微优化深度学习层和动力学仿真等实际系统。

Abstract: We introduce ODYN, a novel all-shifted primal-dual non-interior-point quadratic programming (QP) solver designed to efficiently handle challenging dense and sparse QPs. ODYN combines all-shifted nonlinear complementarity problem (NCP) functions with proximal method of multipliers to robustly address ill-conditioned and degenerate problems, without requiring linear independence of the constraints. It exhibits strong warm-start performance and is well suited to both general-purpose optimization, and robotics and AI applications, including model-based control, estimation, and kernel-based learning methods. We provide an open-source implementation and benchmark ODYN on the Maros-Mészáros test set, demonstrating state-of-the-art convergence performance in small-to-high-scale problems. The results highlight ODYN's superior warm-starting capabilities, which are critical in sequential and real-time settings common in robotics and AI. These advantages are further demonstrated by deploying ODYN as the backend of an SQP-based predictive control framework (OdynSQP), as the implicitly differentiable optimization layer for deep learning (ODYNLayer), and the optimizer of a contact-dynamics simulation (ODYNSim).

</details>


### [137] [The Impact of Class Uncertainty Propagation in Perception-Based Motion Planning](https://arxiv.org/abs/2602.16035)
*Jibran Iqbal Shah,Andrei Ivanovic,Kelly Zhu,Masha Itkina,Rowan McAllister,Igor Gilitschenski,Florian Shkurti*

Main category: cs.RO

TL;DR: 本文分析了感知不确定性在自动驾驶车辆决策规划中的传播与校准对系统性能的影响，通过对两种不同不确定性传播方案在nuPlan基准上的对比实验证明，上游不确定性传播有助于提高系统在复杂场景下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶车辆在城市环境中的广泛部署，安全可靠的运行要求车辆决策系统合理应对感知数据中的不确定性。虽然已有规划方法考虑了这些不确定性，但预测不确定性的校准误差带来的影响尚未充分研究，因此有必要定量分析感知不确定性的传播过程及其对规划性能的影响。

Method: 作者设计并对比了两种在不确定性传播程度上不同的预测—规划处理流程，基于nuPlan规划基准数据集进行实验，并采用闭环方式评估不同方法在挑战性场景下的表现，以此分析不确定性传播与校准对整体系统的影响。

Result: 实验显示，包含上游不确定性传播的规划方法在nuPlan挑战场景中表现出更强的泛化能力，特别是在复杂闭环场景下，其性能相较于未充分处理不确定性传播的方法更为优越。

Conclusion: 将感知和预测阶段的不确定性有效地传播到决策规划环节，对提升自动驾驶系统在复杂环境下的鲁棒性和泛化能力具有重要作用，建议今后的自动驾驶决策系统设计更多关注不确定性的建模与校准机制。

Abstract: Autonomous vehicles (AVs) are being increasingly deployed in urban environments. In order to operate safely and reliably, AVs need to account for the inherent uncertainty associated with perceiving the world through sensor data and incorporate that into their decision-making process. Uncertainty-aware planners have recently been developed to account for upstream perception and prediction uncertainty. However, such planners may be sensitive to prediction uncertainty miscalibration, the magnitude of which has not yet been characterized. Towards this end, we perform a detailed analysis on the impact that perceptual uncertainty propagation and calibration has on perception-based motion planning. We do so by comparing two novel prediction-planning pipelines with varying levels of uncertainty propagation on the recently-released nuPlan planning benchmark. We study the impact of upstream uncertainty calibration using closed-loop evaluation on the nuPlan challenge scenarios. We find that the method incorporating upstream uncertainty propagation demonstrates superior generalization to complex closed-loop scenarios.

</details>


### [138] [ScenicRules: An Autonomous Driving Benchmark with Multi-Objective Specifications and Abstract Scenarios](https://arxiv.org/abs/2602.16073)
*Kevin Kai-Chun Chang,Ekin Beyazit,Alberto Sangiovanni-Vincentelli,Tichakorn Wongpiromsarn,Sanjit A. Seshia*

Main category: cs.RO

TL;DR: 本文提出了ScenicRules基准，用于评估在多目标优先级和正式环境模型下的自动驾驶系统。该基准辅助发现自动驾驶系统在复杂交通规则和情景下的表现与失败。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶评测缺少同时具备多目标优先级和正式环境建模的基准，而现实驾驶任务常需在无法同时满足全部目标时作优先排序。

Method: 作者提出了Hierarchical Rulebook框架，用于明确表达多目标及其优先顺序，并将多个复杂驾驶场景用Scenic语言正式化构建，用于量化评测自动驾驶系统。

Result: 实验表明，形式化的目标与优先级与人类驾驶判断高度一致，ScenicRules基准能够有效揭示自动驾驶系统对多目标优先级的遵循与失败。

Conclusion: ScenicRules为自动驾驶多目标与优先级评测提供了新工具，有助于推动安全、合规和高效自动驾驶技术研究。

Abstract: Developing autonomous driving systems for complex traffic environments requires balancing multiple objectives, such as avoiding collisions, obeying traffic rules, and making efficient progress. In many situations, these objectives cannot be satisfied simultaneously, and explicit priority relations naturally arise. Also, driving rules require context, so it is important to formally model the environment scenarios within which such rules apply. Existing benchmarks for evaluating autonomous vehicles lack such combinations of multi-objective prioritized rules and formal environment models. In this work, we introduce ScenicRules, a benchmark for evaluating autonomous driving systems in stochastic environments under prioritized multi-objective specifications. We first formalize a diverse set of objectives to serve as quantitative evaluation metrics. Next, we design a Hierarchical Rulebook framework that encodes multiple objectives and their priority relations in an interpretable and adaptable manner. We then construct a compact yet representative collection of scenarios spanning diverse driving contexts and near-accident situations, formally modeled in the Scenic language. Experimental results show that our formalized objectives and Hierarchical Rulebooks align well with human driving judgments and that our benchmark effectively exposes agent failures with respect to the prioritized objectives. Our benchmark can be accessed at https://github.com/BerkeleyLearnVerify/ScenicRules/.

</details>


### [139] [Reactive Slip Control in Multifingered Grasping: Hybrid Tactile Sensing and Internal-Force Optimization](https://arxiv.org/abs/2602.16127)
*Théo Ayral,Saifeddine Aloui,Mathieu Grossard*

Main category: cs.RO

TL;DR: 本文提出了一种结合学习和模型驱动的多指机械手内抓取力自适应方法，通过触觉组合和优化算法，实现了亚50毫秒的闭环稳定抓持。


<details>
  <summary>Details</summary>
Motivation: 在多指机械手操作中，物体滑动（slip）严重影响抓取稳定性和任务完成。现有方法在响应速度、鲁棒性及多传感数据融合方面存在不足，急需更高效兼容的解决方案。

Method: 作者设计了一种多模态触觉感知系统，将压电（PzE）快滑感知与压阻（PzR）接触定位阵列相融合，实现在线构建抓取矩阵。发生滑动时，通过四次规划在抓取矩阵零空间内调整内力，保证物体受力平衡并考虑执行器限制。全流程的触觉到命令延迟能理论上控制在35-40毫秒内。

Result: 实验中，系统能在20毫秒内检测滑动发生，并在多指抓持和外部扰动下实现闭环动态稳定。实测表明总体延迟主要由数据传递路径限制，算法本身响应远低于50毫秒。

Conclusion: 将高效解析力控制与学习触觉策略结合，可提升多指机械手的稳定性与响应速度，实现实用的亚50毫秒级闭环抗扰增稳，为未来高性能机器人抓取奠定基础。

Abstract: We present a hybrid learning and model-based approach that adapts internal grasp forces to halt in-hand slip on a multifingered robotic gripper. A multimodal tactile stack combines piezoelectric (PzE) sensing for fast slip cues with piezoresistive (PzR) arrays for contact localization, enabling online construction of the grasp matrix. Upon slip, we update internal forces computed in the null space of the grasp via a quadratic program that preserves the object wrench while enforcing actuation limits. The pipeline yields a theoretical sensing-to-command latency of 35-40 ms, with 5 ms for PzR-based contact and geometry updates and about 4 ms for the quadratic program solve. In controlled trials, slip onset is detected at 20ms. We demonstrate closed-loop stabilization on multifingered grasps under external perturbations. Augmenting efficient analytic force control with learned tactile cues yields both robustness and rapid reactions, as confirmed in our end-to-end evaluation. Measured delays are dominated by the experimental data path rather than actual computation. The analysis outlines a clear route to sub-50 ms closed-loop stabilization.

</details>


### [140] [Image Measurement Method for Automatic Insertion of Forks into Inclined Pallet](https://arxiv.org/abs/2602.16178)
*Nobuyuki Kita,Takuro Kato*

Main category: cs.RO

TL;DR: 本论文提出了一种基于广角相机图像测量的叉车自动对准托盘孔方法，并通过实验验证了其实用性和精度。


<details>
  <summary>Details</summary>
Motivation: 自动引导叉车（AGF）安全、准确地将叉插入托盘的孔，需要精确控制叉子的高度、伸出距离和倾斜角，对应托盘的实际空间位置及姿态。传统方法缺乏高效实时的智能视觉感知手段，制约了AGF自动作业能力。

Method: 提出了一种基于广角相机的图像测量方法，通过拍摄托盘图像并识别其姿态，测量出托盘在相机坐标系下的俯仰倾角。同时，提出了一种简易的相机坐标系与叉子坐标系的自动标定方法，实现图像测量结果到叉子控制指令的转换。

Result: 通过将广角相机固定于叉车背部，对不同状态下的托盘进行成像实验，并比较图像测量值与手工测量值。结果表明：在改变托盘俯仰角、高度、载货与否等情况下，图像测量误差均在安全插叉的允许范围内。

Conclusion: 本文提出的方法能够有效、自动地测量托盘姿态并指导叉车叉臂正确定位，满足AGF对托盘自动作业所需精度，有望提升叉车自动化水平。

Abstract: In order to insert a fork into a hole of a pallet by a forklift located in front of a pallet, it is necessary to control the height position, reach position, and tilt angle of the fork to match the position and orientation of the hole of the pallet. In order to make AGF (Autonomous Guided Forklift) do this automatically, we propose an image measurement method to measure the pitch inclination of the pallet in the camera coordinate system from an image obtained by using a wide-angle camera. In addition, we propose an image measurement method to easily acquire the calibration information between the camera coordinate system and the fork coordinate system necessary to apply the measurements in the camera coordinate system to the fork control. In the experiment space, a wide-angle camera was fixed at the backrest of a reach type forklift. The wide-angle images taken by placing a pallet in front of the camera were processed. As a result of evaluating the error by comparing the image measurement value with the hand measurement value when changing the pitch inclination angle of the pallet, the relative height of the pallet and the fork, and whether the pallet is loaded or not, it was confirmed that the error was within the allowable range for safely inserting the fork.

</details>


### [141] [World Model Failure Classification and Anomaly Detection for Autonomous Inspection](https://arxiv.org/abs/2602.16182)
*Michelle Ho,Muhammad Fadhil Ginting,Isaac R. Ward,Andrzej Reinke,Mykel J. Kochenderfer,Ali-akbar Agha-Mohammadi,Shayegan Omidshafiei*

Main category: cs.RO

TL;DR: 本文提出一种用于自主巡检机器人的混合框架，结合监督故障分类和异常检测，实现对巡检任务的成功、已知故障和异常三种情况的准确分类，具备实时性和高准确率。


<details>
  <summary>Details</summary>
Motivation: 工业巡检存在人工成本高和安全风险大等问题，而自主机器人巡检虽然能改善这些问题，但受视角遮挡、环境变化等影响，检测准确率仍不足，因此需要提升自动巡检任务的可靠性和故障检测能力。

Method: 提出一种无关任务策略且分布无关的混合型分类框架，将世界模型骨干网络和视频压缩输入结合，利用符合预测（conformal prediction，CP）阈值的双重决策函数，在人工观测前对巡检任务进行三分类判定（成功、已知故障、分布外异常）。

Result: 在办公和工业场景采集的仪表巡检视频上进行评估，并实现在Boston Dynamics Spot机器人上的实时部署。实验结果表明该方法区分三种情况的准确率超过90%，且判定速度快于人类观察。

Conclusion: 该方法为自动巡检中的稳健、预判性失败检测提供了可行思路，同时能够作为模型训练反馈信号来评估并提升训练数据质量，具备实际推广应用价值。

Abstract: Autonomous inspection robots for monitoring industrial sites can reduce costs and risks associated with human-led inspection. However, accurate readings can be challenging due to occlusions, limited viewpoints, or unexpected environmental conditions. We propose a hybrid framework that combines supervised failure classification with anomaly detection, enabling classification of inspection tasks as a success, known failure, or anomaly (i.e., out-of-distribution) case. Our approach uses a world model backbone with compressed video inputs. This policy-agnostic, distribution-free framework determines classifications based on two decision functions set by conformal prediction (CP) thresholds before a human observer does. We evaluate the framework on gauge inspection feeds collected from office and industrial sites and demonstrate real-time deployment on a Boston Dynamics Spot. Experiments show over 90% accuracy in distinguishing between successes, failures, and OOD cases, with classifications occurring earlier than a human observer. These results highlight the potential for robust, anticipatory failure detection in autonomous inspection tasks or as a feedback signal for model training to assess and improve the quality of training data. Project website: https://autoinspection-classification.github.io

</details>


### [142] [SIT-LMPC: Safe Information-Theoretic Learning Model Predictive Control for Iterative Tasks](https://arxiv.org/abs/2602.16187)
*Zirui Zang,Ahmad Amine,Nick-Marios T. Kokolakis,Truong X. Nghiem,Ugo Rosolia,Rahul Mangharam*

Main category: cs.RO

TL;DR: 本文提出了一种用于机器人迭代任务的安全信息论学习模型预测控制（SIT-LMPC）算法，能在复杂和不确定环境下实现高效且安全的控制。


<details>
  <summary>Details</summary>
Motivation: 在复杂且具有不确定性的环境中，机器人执行迭代任务时，控制策略需要在鲁棒性、安全性和高性能之间取得平衡。现有方法在处理非线性、随机系统和约束优化时存在不足，且对不确定性的建模有限，因此亟需更优的方法。

Method: 提出了一种基于信息理论的模型预测控制框架，用于解决离散时间非线性随机系统的约束无限时域最优控制问题。采用自适应惩罚法以保障安全性与最优性的平衡。利用前次迭代轨迹，通过归一化流（normalizing flows）学习价值函数，从而比高斯先验能更丰富地描述不确定性。该方法在GPU上高度并行，支持高效的实时优化。

Result: 仿真基准测试和硬件实验显示，SIT-LMPC能在每次迭代中不断提升系统性能，同时始终稳健地满足系统约束。

Conclusion: SIT-LMPC实现了对机器人迭代任务的安全和高效控制，具备较强的不确定性建模与实时优化能力，在复杂环境中展现出较优的稳健性和性能。

Abstract: Robots executing iterative tasks in complex, uncertain environments require control strategies that balance robustness, safety, and high performance. This paper introduces a safe information-theoretic learning model predictive control (SIT-LMPC) algorithm for iterative tasks. Specifically, we design an iterative control framework based on an information-theoretic model predictive control algorithm to address a constrained infinite-horizon optimal control problem for discrete-time nonlinear stochastic systems. An adaptive penalty method is developed to ensure safety while balancing optimality. Trajectories from previous iterations are utilized to learn a value function using normalizing flows, which enables richer uncertainty modeling compared to Gaussian priors. SIT-LMPC is designed for highly parallel execution on graphics processing units, allowing efficient real-time optimization. Benchmark simulations and hardware experiments demonstrate that SIT-LMPC iteratively improves system performance while robustly satisfying system constraints.

</details>


### [143] [Nonplanar Model Predictive Control for Autonomous Vehicles with Recursive Sparse Gaussian Process Dynamics](https://arxiv.org/abs/2602.16206)
*Ahmad Amine,Kabir Puri,Viet-Anh Le,Rahul Mangharam*

Main category: cs.RO

TL;DR: 本文提出了一种用于非平面地形自动驾驶车辆的模型预测控制（MPC）框架，该框架结合了残差高斯过程学习和实时自适应机制，并在仿真环境中实现了高精度路径跟踪。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在复杂3D地形行驶时，因地形起伏、车辆动力学复杂，现有的控制方法难以保证精确性和实时性，因此需要新的建模与控制策略提高非平面地形下的适应能力。

Method: 作者提出了一种几何感知型建模方法，采用残差高斯过程（GP）学习补偿复杂动力学，并通过递归稀疏GP实现对变化地形的实时自适应与高效性。该方法结合MPPI控制器进行路径跟踪，并在自定义仿真环境（Isaac Sim）中进行验证。

Result: 仿真结果表明，该MPC框架能够在复杂、起伏的3D地形上实现高精度的路径跟踪，展示了所学模型和控制算法的有效性。

Conclusion: 基于GP的非平面MPC框架可以提升自动驾驶车辆在非平面地形下的适应性和控制精度，为复杂环境下自动驾驶控制提供了有效的新方法。

Abstract: This paper proposes a nonplanar model predictive control (MPC) framework for autonomous vehicles operating on nonplanar terrain. To approximate complex vehicle dynamics in such environments, we develop a geometry-aware modeling approach that learns a residual Gaussian Process (GP). By utilizing a recursive sparse GP, the framework enables real-time adaptation to varying terrain geometry. The effectiveness of the learned model is demonstrated in a reference-tracking task using a Model Predictive Path Integral (MPPI) controller. Validation within a custom Isaac Sim environment confirms the framework's capability to maintain high tracking accuracy on challenging 3D surfaces.

</details>


### [144] [Markerless Robot Detection and 6D Pose Estimation for Multi-Agent SLAM](https://arxiv.org/abs/2602.16308)
*Markus Rueggeberg,Maximilian Ulmer,Maximilian Durner,Wout Boerdijk,Marcus Gerhard Mueller,Rudolph Triebel,Riccardo Giubilato*

Main category: cs.RO

TL;DR: 本文提出在多机器人SLAM系统中利用深度学习实现无标记的相互姿态估计，以解决传统数据关联和闭环检测遇到的难题，并通过实验验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 多机器人SLAM系统在整合不同观测者的定位历史和地图时，常受到数据关联困难的挑战，尤其在感知环境存在混淆或视角差异较大时传统闭环检测效果较差。而现有依赖标记阵列（如AprilTag）的直接互观方法受限于标记可见性与光照条件。因此，迫切需要无需标记、鲁棒性更强的互观方法。

Method: 本文提出利用深度学习的6D姿态估计技术，开发无需标记的多机器人间相互观测方法，并集成到去中心化的多机器人SLAM系统中。

Result: 实验在类行星环境实测数据验证了该方法，结果显示其有效提升了机器人团队间的相对定位精度。

Conclusion: 基于深度学习的无标记相互观测方案能够显著改善多机器人SLAM中的数据关联和定位精度，克服了传统依赖标记的限制，具有良好的应用前景。

Abstract: The capability of multi-robot SLAM approaches to merge localization history and maps from different observers is often challenged by the difficulty in establishing data association. Loop closure detection between perceptual inputs of different robotic agents is easily compromised in the context of perceptual aliasing, or when perspectives differ significantly. For this reason, direct mutual observation among robots is a powerful way to connect partial SLAM graphs, but often relies on the presence of calibrated arrays of fiducial markers (e.g., AprilTag arrays), which severely limits the range of observations and frequently fails under sharp lighting conditions, e.g., reflections or overexposure. In this work, we propose a novel solution to this problem leveraging recent advances in Deep-Learning-based 6D pose estimation. We feature markerless pose estimation as part of a decentralized multi-robot SLAM system and demonstrate the benefit to the relative localization accuracy among the robotic team. The solution is validated experimentally on data recorded in a test field campaign on a planetary analogous environment.

</details>


### [145] [Machine Learning Driven Prediction of the Behavior of Biohybrid Actuators](https://arxiv.org/abs/2602.16330)
*Michail-Antisthenis Tsompanas,Marco Perez Hernandez,Faisal Abdul-Fattah,Karim Elhakim,Mostafa Ibrahim,Judith Fuentes,Florencia Lezcano,Riccardo Collu,Massimo Barbaro,Stefano Lai,Samuel Sanchez,Andrew Adamatzky*

Main category: cs.RO

TL;DR: 本研究通过引入监督学习模型，显著提升了骨骼肌生物杂化驱动器的可控性和可预测性。静态与动态机器学习模型均实现了高精度预测，为软体机器人肌肉驱动系统的力输出和控制提供了新方案。


<details>
  <summary>Details</summary>
Motivation: 骨骼肌生物杂化驱动器在软体机器人领域已经展示出高效运动能力，但由于其生物本质导致的变异性和非线性，使得实际应用中难以实现精准控制和预测。因此，研究者希望引入数据驱动方法提升其建模、控制与优化能力。

Method: 本研究采用两类监督学习方法：（1）静态预测模型，包括随机森林和神经网络回归器，利用肌肉样本、电刺激参数和基线力量预测最大输出力；（2）基于长短时记忆（LSTM）网络的动态建模框架，作为数字孪生实时模拟受电刺激下的施力时间序列。

Result: 静态模型的最佳R2达0.9425，LSTM动态模型R2高达0.9956，均表现出精准的预测能力。

Conclusion: 机器学习方法能够准确建模和预测生物杂化机器人的动力学行为，为未来软体机器人的性能优化和自适应控制策略的开发打下基础。

Abstract: Skeletal muscle-based biohybrid actuators have proved to be a promising component in soft robotics, offering efficient movement. However, their intrinsic biological variability and nonlinearity pose significant challenges for controllability and predictability. To address these issues, this study investigates the application of supervised learning, a form of machine learning, to model and predict the behavior of biohybrid machines (BHMs), focusing on a muscle ring anchored on flexible polymer pillars. First, static prediction models (i.e., random forest and neural network regressors) are trained to estimate the maximum exerted force achieved from input variables such as muscle sample, electrical stimulation parameters, and baseline exerted force. Second, a dynamic modeling framework, based on Long Short-Term Memory networks, is developed to serve as a digital twin, replicating the time series of exerted forces observed in response to electrical stimulation. Both modeling approaches demonstrate high predictive accuracy. The best performance of the static models is characterized by R2 of 0.9425, whereas the dynamic model achieves R2 of 0.9956. The static models can enable optimization of muscle actuator performance for targeted applications and required force outcomes, while the dynamic model provides a foundation for developing robustly adaptive control strategies in future biohybrid robotic systems.

</details>


### [146] [Dual-Quadruped Collaborative Transportation in Narrow Environments via Safe Reinforcement Learning](https://arxiv.org/abs/2602.16353)
*Zhezhi Lei,Zhihai Bi,Wenxin Wang,Jun Ma*

Main category: cs.RO

TL;DR: 本文提出了一种用于双四足机器人协同搬运的安全强化学习方法，有效提升在狭窄环境下的搬运性能及安全性。


<details>
  <summary>Details</summary>
Motivation: 多机器人协同搬运任务近年来受到关注，但在狭窄环境下的安全高效协作极具挑战，亟需针对性的新方法以保障安全和提升作业能力。

Method: 作者将协同搬运任务建模为完全合作的受约束马尔可夫博弈，通过引入成本-优势分解方法，限制团队约束总和在上限内以确保安全。同时，提出约束分配方法，将团队约束分配给单个机器人，从而最大化整体任务奖励并促进自主任务分配。

Result: 仿真和实时实验证明，所提方法在双四足机器人协同搬运任务中成功率及整体性能均优于现有主流方法。

Conclusion: 通过安全强化学习结合创新的约束管理与分配机制，本方法显著提升了双四足机器人在复杂环境下的协作安全性和任务完成表现，对多机器人协作任务具有重要参考意义。

Abstract: Collaborative transportation, where multiple robots collaboratively transport a payload, has garnered significant attention in recent years. While ensuring safe and high-performance inter-robot collaboration is critical for effective task execution, it is difficult to pursue in narrow environments where the feasible region is extremely limited. To address this challenge, we propose a novel approach for dual-quadruped collaborative transportation via safe reinforcement learning (RL). Specifically, we model the task as a fully cooperative constrained Markov game, where collision avoidance is formulated as constraints. We introduce a cost-advantage decomposition method that enforces the sum of team constraints to remain below an upper bound, thereby guaranteeing task safety within an RL framework. Furthermore, we propose a constraint allocation method that assigns shared constraints to individual robots to maximize the overall task reward, encouraging autonomous task-assignment among robots, thereby improving collaborative task performance. Simulation and real-time experimental results demonstrate that the proposed approach achieves superior performance and a higher success rate in dual-quadruped collaborative transportation compared to existing methods.

</details>


### [147] [Articulated 3D Scene Graphs for Open-World Mobile Manipulation](https://arxiv.org/abs/2602.16356)
*Martin Büchner,Adrian Röfer,Tim Engelbracht,Tim Welschehold,Zuria Bauer,Hermann Blum,Marc Pollefeys,Abhinav Valada*

Main category: cs.RO

TL;DR: 本文提出MoMa-SG，一个构建具有运动能力信息的三维语义场景图的新框架，通过分析RGB-D序列，实现了对多物体交互运动的精确理解和操作。


<details>
  <summary>Details</summary>
Motivation: 现有三维场景理解方法多停留在语义和几何层面，缺乏对物体运动学（如关节运动）的建模，导致机器人对可动物体的操作能力有限，因此需要将语义、几何与运动学紧密结合。

Method: MoMa-SG框架首先输入包含多物体动作的RGB-D序列，通过鲁棒的点追踪算法实现时序分割和物体运动推断。进一步采用创新的统一twist估计方法，一步优化估算旋转（revolute）与滑动（prismatic）关节参数，然后基于父子关系将动作与物体关联，同时检测包含物体。最后引入了带层次语义和关节轴标注的新数据集Arti4D-Semantic来验证方法有效性。

Result: MoMa-SG在两个数据集上表现优异，并通过消融实验证实设计选择的有效性。实物实验表明其为四足机器人和移动机械臂在家庭环境中灵活操作可动物体提供了支持。

Conclusion: MoMa-SG显著提升了机器人在现实环境中理解和操作复杂机械结构物体的能力，促进了语义、几何与运动学信息的有机结合。

Abstract: Semantics has enabled 3D scene understanding and affordance-driven object interaction. However, robots operating in real-world environments face a critical limitation: they cannot anticipate how objects move. Long-horizon mobile manipulation requires closing the gap between semantics, geometry, and kinematics. In this work, we present MoMa-SG, a novel framework for building semantic-kinematic 3D scene graphs of articulated scenes containing a myriad of interactable objects. Given RGB-D sequences containing multiple object articulations, we temporally segment object interactions and infer object motion using occlusion-robust point tracking. We then lift point trajectories into 3D and estimate articulation models using a novel unified twist estimation formulation that robustly estimates revolute and prismatic joint parameters in a single optimization pass. Next, we associate objects with estimated articulations and detect contained objects by reasoning over parent-child relations at identified opening states. We also introduce the novel Arti4D-Semantic dataset, which uniquely combines hierarchical object semantics including parent-child relation labels with object axis annotations across 62 in-the-wild RGB-D sequences containing 600 object interactions and three distinct observation paradigms. We extensively evaluate the performance of MoMa-SG on two datasets and ablate key design choices of our approach. In addition, real-world experiments on both a quadruped and a mobile manipulator demonstrate that our semantic-kinematic scene graphs enable robust manipulation of articulated objects in everyday home environments. We provide code and data at: https://momasg.cs.uni-freiburg.de.

</details>


### [148] [System Identification under Constraints and Disturbance: A Bayesian Estimation Approach](https://arxiv.org/abs/2602.16358)
*Sergi Martinez,Steve Tonneau,Carlos Mastalli*

Main category: cs.RO

TL;DR: 本文提出了一种贝叶斯系统辨识方法，同时高精度估计机器人状态轨迹与物理参数，并通过引入多种物理约束与能量观测提升参数可观测性。实验结果显示该方法优于传统基线，在模型预测控制应用中显著提升运动控制表现。


<details>
  <summary>Details</summary>
Motivation: 传统机器人系统辨识方法在估计机器人状态和系统参数时常常彼此独立处理，难以充分整合物理约束（如接触和回环）与复杂摩擦建模，且对系统参数的可观测性存在限制。此外，现有方法在复杂、长期任务和环境中往往在精度和收敛速度上存在不足。因此，作者希望通过建立统一、物理一致且高效可扩展的贝叶斯辨识框架，提高辨识的精度、鲁棒性和效率。

Method: 该方法以贝叶斯框架为基础，联合估计机器人状态轨迹和物理参数。具体做法包括：1）将逆动力学、接触和回环等物理约束，以及关节摩擦模型以等式约束严格嵌入推断过程；2）利用基于能量的回归器增强参数可观测性，通过能量观测辅助区分非线性摩擦效应；3）对惯性和驱动参数设置等式/不等式先验，保持系统物理一致性；4）提出参数化等式约束的Riccati递归算法，实现随任务时长线性增长的高效求解。方法在仿真机器人及Unitree B1实际平台上验证。

Result: 在仿真和实际硬件实验（Unitree B1+Z1机械臂）中，本方法实现了较基线方法（前向动力学与解耦辨识）更快的收敛速度、更低的惯性与摩擦估计误差，以及更高的接触一致性。进一步，在模型预测控制任务中，辨识模型带来了对复杂地形显著更优的轨迹跟踪性能。

Conclusion: 本文提出的贝叶斯系统辨识框架综合了物理约束与能量观测，实现了高精度机器人动态建模，在辨识精度、收敛速度与下游控制效果上皆优于现有方法，具备良好的实际推广价值。

Abstract: We introduce a Bayesian system identification (SysID) framework for jointly estimating robot's state trajectories and physical parameters with high accuracy. It embeds physically consistent inverse dynamics, contact and loop-closure constraints, and fully featured joint friction models as hard, stage-wise equality constraints. It relies on energy-based regressors to enhance parameter observability, supports both equality and inequality priors on inertial and actuation parameters, enforces dynamically consistent disturbance projections, and augments proprioceptive measurements with energy observations to disambiguate nonlinear friction effects. To ensure scalability, we derive a parameterized equality-constrained Riccati recursion that preserves the banded structure of the problem, achieving linear complexity in the time horizon, and develop computationally efficient derivatives. Simulation studies on representative robotic systems, together with hardware experiments on a Unitree B1 equipped with a Z1 arm, demonstrate faster convergence, lower inertial and friction estimation errors, and improved contact consistency compared to forward-dynamics and decoupled identification baselines. When deployed within model predictive control frameworks, the resulting models yield measurable improvements in tracking performance during locomotion over challenging environments.

</details>


### [149] [Docking and Persistent Operations for a Resident Underwater Vehicle](https://arxiv.org/abs/2602.16360)
*Leonard Günzel,Gabrielė Kasparavičiūtė,Ambjørn Grimsrud Waldum,Bjørn-Magnus Moslått,Abubakar Aliyu Badawi,Celil Yılmaz,Md Shamin Yeasher Yousha,Robert Staven,Martin Ludvigsen*

Main category: cs.RO

TL;DR: 本论文介绍了一套基于水下对接站和小型ROV的常驻水下监测系统，解决了深海环境下长期自主运行的关键难题。该系统在90米海深下实现了高效自治巡检，并达到90%的自主对接成功率，证明了以自主无人潜水器为核心的水下监测具备可扩展性和成本效益。


<details>
  <summary>Details</summary>
Motivation: 当前水下监测受限于高昂成本和操作难度，主要依赖间断性巡检或固定点长期观测，导致数据稀疏且频次低。为获取连续、空间覆盖广泛的水下数据，亟需突破技术瓶颈，实现无需持续人工支持的自持型、常驻式水下观测。

Method: 作者开发了包含对接基站及增强感知处理能力的ROV系统。ROV使用声学（USBL）信号自主导航，通过融合ArUco视觉标记和扩展卡尔曼滤波实现自动对接。系统部署于90米深海，进行了自治巡检和对接测试。

Result: ROV系统在实际海试中实现了90%的自动对接成功率，单次完整巡检任务仅用时4分钟，成功展示了声学与视觉导航集成的实用性与高效性。

Conclusion: 本文验证了小型ROV结合对接基站可实现可靠、高效的深海自主作业，具备良好的实用前景，为未来大规模、低成本的常驻水下观测系统奠定了技术基础。

Abstract: Our understanding of the oceans remains limited by sparse and infrequent observations, primarily because current methods are constrained by the high cost and logistical effort of underwater monitoring, relying either on sporadic surveys across broad areas or on long-term measurements at fixed locations. To overcome these limitations, monitoring systems must enable persistent and autonomous operations without the need for continuous surface support. Despite recent advances, resident underwater vehicles remain uncommon due to persistent challenges in autonomy, robotic resilience, and mechanical robustness, particularly under long-term deployment in harsh and remote environments. This work addresses these problems by presenting the development, deployment, and operation of a resident infrastructure using a docking station with a mini-class Remotely Operated Vehicle (ROV) at 90m depth. The ROVis equipped with enhanced onboard processing and perception, allowing it to autonomously navigate using USBL signals, dock via ArUco marker-based visual localisation fused through an Extended Kalman Filter, and carry out local inspection routines. The system demonstrated a 90% autonomous docking success rate and completed full inspection missions within four minutes, validating the integration of acoustic and visual navigation in real-world conditions. These results show that reliable, untethered operations at depth are feasible, highlighting the potential of resident ROV systems for scalable, cost-effective underwater monitoring.

</details>


### [150] [Markerless 6D Pose Estimation and Position-Based Visual Servoing for Endoscopic Continuum Manipulators](https://arxiv.org/abs/2602.16365)
*Junhyun Park,Chunggil An,Myeongbo Park,Ihsan Ullah,Sihyeong Park,Minho Hwang*

Main category: cs.RO

TL;DR: 本文提出了一种无需标记物的连续体机械臂立体6D姿态估计和基于视觉伺服的控制框架，并在实际环境中取得了高精度的闭环控制效果。


<details>
  <summary>Details</summary>
Motivation: 现有柔性内镜外科系统中的连续体机械臂操作灵活，但由于迟滞、柔顺性及末端传感能力有限，导致精确的姿态估计和闭环控制仍具挑战。视觉方法虽简化了硬件但易受观测限制与计算负担影响，难以实时应用。

Method: 该方法通过建立逼真仿真管线生成大规模像素精确的数据，用于训练联合利用分割掩码、关键点、热图和边界框的多特征融合网络。采用一次性前馈渲染校正模块提升几何一致性，并通过自监督仿真到现实域自适应提升无标注数据下的实际性能。

Result: 在1,000个样本的实际验证中，平均平移误差为0.83mm，平均旋转误差为2.76°。基于姿态驱动的无标记闭环视觉伺服实现了轨迹跟踪，平均平移误差2.07mm、旋转误差7.41°，相较开环控制误差分别降低85%和59%，重复性表现优异。

Conclusion: 本研究首次实现了无需物理标记和内嵌传感的连续体机械臂全流程闭环视觉伺服，在医用内镜等领域具备重要意义。

Abstract: Continuum manipulators in flexible endoscopic surgical systems offer high dexterity for minimally invasive procedures; however, accurate pose estimation and closed-loop control remain challenging due to hysteresis, compliance, and limited distal sensing. Vision-based approaches reduce hardware complexity but are often constrained by limited geometric observability and high computational overhead, restricting real-time closed-loop applicability. This paper presents a unified framework for markerless stereo 6D pose estimation and position-based visual servoing of continuum manipulators. A photo-realistic simulation pipeline enables large-scale automatic training with pixel-accurate annotations. A stereo-aware multi-feature fusion network jointly exploits segmentation masks, keypoints, heatmaps, and bounding boxes to enhance geometric observability. To enforce geometric consistency without iterative optimization, a feed-forward rendering-based refinement module predicts residual pose corrections in a single pass. A self-supervised sim-to-real adaptation strategy further improves real-world performance using unlabeled data. Extensive real-world validation achieves a mean translation error of 0.83 mm and a mean rotation error of 2.76° across 1,000 samples. Markerless closed-loop visual servoing driven by the estimated pose attains accurate trajectory tracking with a mean translation error of 2.07 mm and a mean rotation error of 7.41°, corresponding to 85% and 59% reductions compared to open-loop control, together with high repeatability in repeated point-reaching tasks. To the best of our knowledge, this work presents the first fully markerless pose-estimation-driven position-based visual servoing framework for continuum manipulators, enabling precise closed-loop control without physical markers or embedded sensing.

</details>


### [151] [Dynamic Modeling and MPC for Locomotion of Tendon-Driven Soft Quadruped](https://arxiv.org/abs/2602.16371)
*Saumya Karan,Neerav Maram,Suraj Borate,Madhu Vadali*

Main category: cs.RO

TL;DR: 本文提出了一种基于腱驱动和3D打印TPU材料的软体四足机器人SLOT，通过物理建模和模型预测控制，实现了高精度、稳定的软体四足机器人运动控制。


<details>
  <summary>Details</summary>
Motivation: 当前软体多足机器人在建模和实时控制方面存在诸多挑战，包括腿部柔性大、非线性强、与地面复杂的接触作用等。本研究旨在开发一种通用、高精度且可扩展的软体腿模型，并集成效率高、物理精度强的控制框架，以推动软体机器人实用化。

Method: 作者采用离散Cosserat杆理论，对每条软腿进行连续体建模，捕捉其大变形与柔性行为并考虑腱驱动及地面接触。整体建模框架将柔性腿的动力学以反作用力形式加载到刚性躯干，实现连续体与刚体动力学的高效耦合。控制方面，将该模型嵌入凸模型预测控制（MPC）内，对地面反作用力进行优化，并通过基于物理的力-角关系转化为腱驱动指令，从而实现实时闭环运动控制。

Result: 提出的控制方法在实际原型机上进行爬行和步行实验，中心质量轨迹RMSE低于5 mm，且在多种外部扰动下能保持渐进稳定。

Conclusion: 本研究展示了将连续体软腿与模型驱动控制深度集成的可行框架，有望推广至更多软体四足机器人领域，提升其建模和控制的通用性、可扩展性与精度。

Abstract: SLOT (Soft Legged Omnidirectional Tetrapod), a tendon-driven soft quadruped robot with 3D-printed TPU legs, is presented to study physics-informed modeling and control of compliant legged locomotion using only four actuators. Each leg is modeled as a deformable continuum using discrete Cosserat rod theory, enabling the capture of large bending deformations, distributed elasticity, tendon actuation, and ground contact interactions. A modular whole-body modeling framework is introduced, in which compliant leg dynamics are represented through physically consistent reaction forces applied to a rigid torso, providing a scalable interface between continuum soft limbs and rigid-body locomotion dynamics. This formulation allows efficient whole-body simulation and real-time control without sacrificing physical fidelity. The proposed model is embedded into a convex model predictive control framework that optimizes ground reaction forces over a 0.495 s prediction horizon and maps them to tendon actuation through a physics-informed force-angle relationship. The resulting controller achieves asymptotic stability under diverse perturbations. The framework is experimentally validated on a physical prototype during crawling and walking gaits, achieving high accuracy with less than 5 mm RMSE in center of mass trajectories. These results demonstrate a generalizable approach for integrating continuum soft legs into model-based locomotion control, advancing scalable and reusable modeling and control methods for soft quadruped robots.

</details>


### [152] [RoboGene: Boosting VLA Pre-training via Diversity-Driven Agentic Framework for Real-World Task Generation](https://arxiv.org/abs/2602.16444)
*Yixue Zhang,Kun Wu,Zhi Gao,Zhen Zhao,Pei Ren,Zhiyuan Xu,Fei Liao,Xinhua Wang,Shichao Fan,Di Wu,Qiuxuan Feng,Meng Li,Zhengping Che,Chang Liu,Jian Tang*

Main category: cs.RO

TL;DR: 本文提出了RoboGene框架，用于自动生成多样且物理可行的机器人操作任务，显著提升了数据集质量与机器人泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操控任务的数据采集成本高、手动策划的方法效率低且易有偏见，而现成的大模型又常常生成不切实际的指令，因此亟需高效且自动化的任务生成方法。

Method: RoboGene框架包含三大核心组件：基于多样性的任务采样机制、用以保证物理可行性的自我反思机制、以及人类参与的持续优化流程。通过这些机制自动生成并筛选合适的操控任务，涵盖单臂、双臂和移动机器人。

Result: 通过大规模真实环境实验，团队收集了1.8万条机器人操作轨迹，引入了新的任务质量、可行性和多样性指标，实验证明RoboGene在任务生成质量上明显超过现有主流基础模型（如GPT-4o、Gemini 2.5 Pro）。

Conclusion: 高质量的自动任务生成对于提升机器人泛化能力至关重要，RoboGene为自动、多样且物理可行的任务生成提供了高效方法，已在真实世界实验中证实有效。

Abstract: The pursuit of general-purpose robotic manipulation is hindered by the scarcity of diverse, real-world interaction data. Unlike data collection from web in vision or language, robotic data collection is an active process incurring prohibitive physical costs. Consequently, automated task curation to maximize data value remains a critical yet under-explored challenge. Existing manual methods are unscalable and biased toward common tasks, while off-the-shelf foundation models often hallucinate physically infeasible instructions. To address this, we introduce RoboGene, an agentic framework designed to automate the generation of diverse, physically plausible manipulation tasks across single-arm, dual-arm, and mobile robots. RoboGene integrates three core components: diversity-driven sampling for broad task coverage, self-reflection mechanisms to enforce physical constraints, and human-in-the-loop refinement for continuous improvement. We conduct extensive quantitative analysis and large-scale real-world experiments, collecting datasets of 18k trajectories and introducing novel metrics to assess task quality, feasibility, and diversity. Results demonstrate that RoboGene significantly outperforms state-of-the-art foundation models (e.g., GPT-4o, Gemini 2.5 Pro). Furthermore, real-world experiments show that VLA models pre-trained with RoboGene achieve higher success rates and superior generalization, underscoring the importance of high-quality task generation. Our project is available at https://robogene-boost-vla.github.io.

</details>


### [153] [Reactive Motion Generation With Particle-Based Perception in Dynamic Environments](https://arxiv.org/abs/2602.16462)
*Xiyuan Zhao,Huijun Li,Lifeng Zhu,Zhikai Wei,Xianyi Zhu,Aiguo Song*

Main category: cs.RO

TL;DR: 本文提出了一种针对动态和非结构化场景下机械臂反应式运动规划的方法，通过显式建模机器人与障碍物的动态特性，实现更安全和高效的避障运动。


<details>
  <summary>Details</summary>
Motivation: 在现实世界中，机械臂常常需要在动态环境中进行作业，但现有方法大多基于静态感知，难以处理动态障碍物及感知与控制的不确定性，因此亟需新的方案提升动态避障能力和响应性。

Method: 文中提出一种张量化的粒子权重更新策略动态地维护障碍物速度及协方差，实现带有动态属性的粒子感知；基于该动态表示，提出结合障碍物的MPPI运动规划方法，实现对机器人-障碍物动力学的联合预测与评估。

Result: 在仿真和带噪声的真实环境测试中，该方法在避开多个静态和动态障碍物时，相比主流MPPI感知-规划基线方法表现出更高的安全性和响应能力。

Conclusion: 显式建模机器人与障碍物动力学、并在运动规划中综合考虑不确定性，可持续提升机械臂在复杂动态场景中的反应能力和安全性能。

Abstract: Reactive motion generation in dynamic and unstructured scenarios is typically subject to essentially static perception and system dynamics. Reliably modeling dynamic obstacles and optimizing collision-free trajectories under perceptive and control uncertainty are challenging. This article focuses on revealing tight connection between reactive planning and dynamic mapping for manipulators from a model-based perspective. To enable efficient particle-based perception with expressively dynamic property, we present a tensorized particle weight update scheme that explicitly maintains obstacle velocities and covariance meanwhile. Building upon this dynamic representation, we propose an obstacle-aware MPPI-based planning formulation that jointly propagates robot-obstacle dynamics, allowing future system motion to be predicted and evaluated under uncertainty. The model predictive method is shown to significantly improve safety and reactivity with dynamic surroundings. By applying our complete framework in simulated and noisy real-world environments, we demonstrate that explicit modeling of robot-obstacle dynamics consistently enhances performance over state-of-the-art MPPI-based perception-planning baselines avoiding multiple static and dynamic obstacles.

</details>


### [154] [VIGOR: Visual Goal-In-Context Inference for Unified Humanoid Fall Safety](https://arxiv.org/abs/2602.16511)
*Osher Azulay,Zhengjie Xu,Andrew Scheffer,Stella X. Yu*

Main category: cs.RO

TL;DR: 本文提出了一种统一的人形机器人跌倒安全恢复方法，实现了机器人在复杂非平坦环境下的鲁棒、自适应跌倒恢复。通过模仿和蒸馏学习，机器人无需实地微调即可处理多样化的跌倒场景。


<details>
  <summary>Details</summary>
Motivation: 在人形机器人应用中，跌倒事件常导致高能冲击、多体接触和视角剧变，现有方法仅针对跌倒避免、冲击缓解或起立等子环节，难以统一处理完整的跌倒恢复流程，且依赖于大规模数据或受限地形，通用性和可扩展性差。

Method: 方法包含两大创新：1）挖掘人类受限且可迁移的跌倒及恢复姿态，把平地经验通过对齐扩展到复杂地形；2）提出感知-运动一体化隐表示，结合目标姿态与本地地形，让机器人快速全身反应。具体实现为：利用稀疏人类演示在仿真中训练含“特权信息”的教师策略，并蒸馏成仅依赖深度视觉与本体感觉的学生策略。

Result: 在仿真和真实Unitree G1人形机器人上的实验显示，学生模型无需实际世界微调即可在不同非平坦环境下实现鲁棒的零样本跌倒恢复。

Conclusion: 本文方法实现了人形机器人在复杂环境下通用且有效的跌倒安全体系，为后续提升真实环境适应性以及降低现实训练成本提供了新思路。

Abstract: Reliable fall recovery is critical for humanoids operating in cluttered environments. Unlike quadrupeds or wheeled robots, humanoids experience high-energy impacts, complex whole-body contact, and large viewpoint changes during a fall, making recovery essential for continued operation. Existing methods fragment fall safety into separate problems such as fall avoidance, impact mitigation, and stand-up recovery, or rely on end-to-end policies trained without vision through reinforcement learning or imitation learning, often on flat terrain. At a deeper level, fall safety is treated as monolithic data complexity, coupling pose, dynamics, and terrain and requiring exhaustive coverage, limiting scalability and generalization. We present a unified fall safety approach that spans all phases of fall recovery. It builds on two insights: 1) Natural human fall and recovery poses are highly constrained and transferable from flat to complex terrain through alignment, and 2) Fast whole-body reactions require integrated perceptual-motor representations. We train a privileged teacher using sparse human demonstrations on flat terrain and simulated complex terrains, and distill it into a deployable student that relies only on egocentric depth and proprioception. The student learns how to react by matching the teacher's goal-in-context latent representation, which combines the next target pose with the local terrain, rather than separately encoding what it must perceive and how it must act. Results in simulation and on a real Unitree G1 humanoid demonstrate robust, zero-shot fall safety across diverse non-flat environments without real-world fine-tuning. The project page is available at https://vigor2026.github.io/

</details>


### [155] [Decentralized and Fully Onboard: Range-Aided Cooperative Localization and Navigation on Micro Aerial Vehicles](https://arxiv.org/abs/2602.16594)
*Abhishek Goudar,Angela P. Schoellig*

Main category: cs.RO

TL;DR: 本文提出了一种无需中心化计算或全球定位系统的分布式多机器人编队控制与定位方法。该方法结合自身里程计与机器人间距离信息，实现协同导航和队形控制，并通过实验证明了其实用性和高精度。


<details>
  <summary>Details</summary>
Motivation: 多机器人编队控制传统上依赖中心化处理和外部定位系统，但在复杂环境下中心化方案难以扩展，外部定位往往不可用。因此，设计只用本地传感器和机器人间测距即可实现高效协同的自主系统，是提升鲁棒性与适用性的关键难题。

Method: 方法包括两部分：一是提出基于分块坐标下降的去中心化相对定位，不需要机器人间严格同步；二是将编队控制建模为因子图推断任务，充分考虑状态估计的不确定性，并可高效求解。整个系统既能定位，也能实现所需编队移动。

Result: 通过在多种室内外场景下的实际编队飞行实验，证明了该方案能实现分米级的定位与编队控制精度，并验证了其在无需专用路径情况下的适应性和可靠性。

Conclusion: 作者提出的分布式定位与编队导航框架无需全局定位、无需专用队形轨迹，显著提升了多机器人系统的自主性、扩展性与实际应用潜力。

Abstract: Controlling a team of robots in a coordinated manner is challenging because centralized approaches (where all computation is performed on a central machine) scale poorly, and globally referenced external localization systems may not always be available. In this work, we consider the problem of range-aided decentralized localization and formation control. In such a setting, each robot estimates its relative pose by combining data only from onboard odometry sensors and distance measurements to other robots in the team. Additionally, each robot calculates the control inputs necessary to collaboratively navigate an environment to accomplish a specific task, for example, moving in a desired formation while monitoring an area. We present a block coordinate descent approach to localization that does not require strict coordination between the robots. We present a novel formulation for formation control as inference on factor graphs that takes into account the state estimation uncertainty and can be solved efficiently. Our approach to range-aided localization and formation-based navigation is completely decentralized, does not require specialized trajectories to maintain formation, and achieves decimeter-level positioning and formation control accuracy. We demonstrate our approach through multiple real experiments involving formation flights in diverse indoor and outdoor environments.

</details>


### [156] [Sensor Query Schedule and Sensor Noise Covariances for Accuracy-constrained Trajectory Estimation](https://arxiv.org/abs/2602.16598)
*Abhishek Goudar,Angela P. Schoellig*

Main category: cs.RO

TL;DR: 本文提出了一种根据期望的轨迹估计精度，合理配置传感器的数据采集频率（调度）和精度（协方差），以平衡精度与成本。方法基于半正定规划，验证显示该方法能达到指定的估计精度，并能识别系统能力不足的情况。


<details>
  <summary>Details</summary>
Motivation: 移动机器人轨迹估计依赖于传感器频率和精度，但高精度和高频率往往受成本和资源的限制。因此，需要一种科学的方法决定传感器的使用参数，在确保估计精度的同时兼顾约束。

Method: 将传感器调度（采集频率）与精度（噪声协方差）对轨迹估计精度的影响系统建模，并将最优参数设定问题转化为半正定规划（SDP）问题。通过SDP求解器得到满足目标精度的最优参数组合。

Result: 通过仿真和实际实验，验证了用该方法推算得到的传感器调度频率和协方差，能够在实际应用中达到预定的轨迹估计精度。如果系统能力无法满足要求，方法也能及时检测到。

Conclusion: 所提出的方法能科学制定传感器参数配置方案，为机器人轨迹估计在不同成本-精度约束下提供支持，具有理论和实际应用价值。

Abstract: Trajectory estimation involves determining the trajectory of a mobile robot by combining prior knowledge about its dynamic model with noisy observations of its state obtained using sensors. The accuracy of such a procedure is dictated by the system model fidelity and the sensor parameters, such as the accuracy of the sensor (as represented by its noise covariance) and the rate at which it can generate observations, referred to as the sensor query schedule. Intuitively, high-rate measurements from accurate sensors lead to accurate trajectory estimation. However, cost and resource constraints limit the sensor accuracy and its measurement rate. Our work's novel contribution is the estimation of sensor schedules and sensor covariances necessary to achieve a specific estimation accuracy. Concretely, we focus on estimating: (i) the rate or schedule with which a sensor of known covariance must generate measurements to achieve specific estimation accuracy, and alternatively, (ii) the sensor covariance necessary to achieve specific estimation accuracy for a given sensor update rate. We formulate the problem of estimating these sensor parameters as semidefinite programs, which can be solved by off-the-shelf solvers. We validate our approach in simulation and real experiments by showing that the sensor schedules and the sensor covariances calculated using our proposed method achieve the desired trajectory estimation accuracy. Our method also identifies scenarios where certain estimation accuracy is unachievable with the given system and sensor characteristics.

</details>


### [157] [Towards Autonomous Robotic Kidney Ultrasound: Spatial-Efficient Volumetric Imaging via Template Guided Optimal Pivoting](https://arxiv.org/abs/2602.16641)
*Xihan Ma,Haichong Zhang*

Main category: cs.RO

TL;DR: 该论文提出了一种自动化、空间高效的机器人超声肾脏成像方法，通过模板引导的最优旋转方式，提高成像效率并减少扫描范围，验证了其精度和省时效果。


<details>
  <summary>Details</summary>
Motivation: 目前手持超声依赖操作员，结果不一致，缺乏3D定位，且对操作者有身体损伤风险。现有机器人扫描方法不能高效选择最佳成像窗口，往往导致成像范围过大、遮挡和器官覆盖不全。迫切需要一种最大化覆盖、最小化探头移动的高效成像技术。

Method: 先进行探索性成像，获得肾脏的部分图像，并与标准肾脏模板配准，估算肾脏位置。再让机器人以肾脏长轴为旋转中心进行定点旋转扫描，减少探头平移，实现高效成像。方法通过仿真和体内试验验证。

Result: 仿真显示60%的探索扫描比率在定位准确性与扫描效率间取得最佳平衡；体内试验（两名男性）定位误差达7.36mm和13.84度；相较基线方法，探头行程减少约75mm。

Conclusion: 基于模板的最优对齐及旋转扫描方案能有效提升机器人超声肾脏成像的效率和准确性，有望实现标准化、空间高效的3D超声肾脏检查。

Abstract: Medical ultrasound (US) imaging is a frontline tool for the diagnosis of kidney diseases. However, traditional freehand imaging procedure suffers from inconsistent, operator-dependent outcomes, lack of 3D localization information, and risks of work-related musculoskeletal disorders. While robotic ultrasound (RUS) systems offer the potential for standardized, operator-independent 3D kidney data acquisition, the existing scanning methods lack the ability to determine the optimal imaging window for efficient imaging. As a result, the scan is often blindly performed with excessive probe footprint, which frequently leads to acoustic shadowing and incomplete organ coverage. Consequently, there is a critical need for a spatially efficient imaging technique that can maximize the kidney coverage through minimum probe footprint. Here, we propose an autonomous workflow to achieve efficient kidney imaging via template-guided optimal pivoting. The system first performs an explorative imaging to generate partial observations of the kidney. This data is then registered to a kidney template to estimate the organ pose. With the kidney localized, the robot executes a fixed-point pivoting sweep where the imaging plane is aligned with the kidney long axis to minimize the probe translation. The proposed method was validated in simulation and in-vivo. Simulation results indicate that a 60% exploration ratio provides optimal balance between kidney localization accuracy and scanning efficiency. In-vivo evaluation on two male subjects demonstrates a kidney localization accuracy up to 7.36 mm and 13.84 degrees. Moreover, the optimal pivoting approach shortened the probe footprint by around 75 mm when compared with the baselines. These results valid our approach of leveraging anatomical templates to align the probe optimally for volumetric sweep.

</details>


### [158] [Learning to unfold cloth: Scaling up world models to deformable object manipulation](https://arxiv.org/abs/2602.16675)
*Jack Rome,Stephen James,Subramanian Ramamoorthy*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习的空中布料操控方法，改进了DreamerV2架构，通过引入表面法线输入、修改回放缓冲和数据增强流程，有效提升了机器人对多种布料的泛化和操控能力。方法在仿真和真实机器人测试中均表现出色。


<details>
  <summary>Details</summary>
Motivation: 布料操控因其复杂的物理特性在机器人领域是一个极具挑战性且应用价值极高的问题。面对布料的多样形状、尺寸及皱褶，亟需能够广泛泛化且高效的操作策略。

Method: 采用基于DreamerV2的强化学习架构，增加布料表面法线信息作为输入，并对回放缓冲机制与数据增强流程做出改进，以强化模型的物理理解和泛化性能。

Result: 提出的架构在仿真环境和真实机器人（零样本迁移）设定下，成功实现了多种不同类型布料的空中展开，证实了方案的广泛适用性和有效的泛化能力。

Conclusion: 通过增强世界模型并引入多项改进，所提出的机器人操控策略能够有效解决复杂布料操控问题，为该领域泛化性强的操作方法提供了新范例。

Abstract: Learning to manipulate cloth is both a paradigmatic problem for robotic research and a problem of immediate relevance to a variety of applications ranging from assistive care to the service industry. The complex physics of the deformable object makes this problem of cloth manipulation nontrivial. In order to create a general manipulation strategy that addresses a variety of shapes, sizes, fold and wrinkle patterns, in addition to the usual problems of appearance variations, it becomes important to carefully consider model structure and their implications for generalisation performance. In this paper, we present an approach to in-air cloth manipulation that uses a variation of a recently proposed reinforcement learning architecture, DreamerV2. Our implementation modifies this architecture to utilise surface normals input, in addition to modiying the replay buffer and data augmentation procedures. Taken together these modifications represent an enhancement to the world model used by the robot, addressing the physical complexity of the object being manipulated by the robot. We present evaluations both in simulation and in a zero-shot deployment of the trained policies in a physical robot setup, performing in-air unfolding of a variety of different cloth types, demonstrating the generalisation benefits of our proposed architecture.

</details>


### [159] [Learning Humanoid End-Effector Control for Open-Vocabulary Visual Loco-Manipulation](https://arxiv.org/abs/2602.16705)
*Runpei Dong,Ziyan Li,Xialin He,Saurabh Gupta*

Main category: cs.RO

TL;DR: 该论文提出了一种新范式HERO，将大型视觉模型的泛化能力与仿真中训练的高效控制策略结合，实现了仿人机器人在多样、复杂环境下对任意物体的精确操作和移动。


<details>
  <summary>Details</summary>
Motivation: 传统基于模仿学习的方法受限于真实世界大规模数据集的获取难度，导致泛化能力不足，难以在多变的现实场景中进行准确的末端执行器控制和视觉理解。

Method: HERO方法融合了大型视觉模型与仿真训练的控制策略，并设计了残差感知末端执行器（EE）跟踪策略，结合经典机器人学和机器学习：a)利用逆向运动学将残差目标转为参考轨迹；b)采用神经网络前向模型提升运动学精度；c)目标自适应调整；d)轨迹再规划。

Result: 通过上述策略，将末端执行器的跟踪误差降低了3.2倍。该系统可以在办公室、咖啡馆等多种真实环境中操作日常物品，表现在不同高度的各种表面上均表现优良。大量仿真与现实测试验证了其模块化与端到端设计的有效性。

Conclusion: 该工作增强了仿人机器人对日常物品的泛化交互能力，并为日后开发能适应多变现实环境的机器人开辟了新道路。

Abstract: Visual loco-manipulation of arbitrary objects in the wild with humanoid robots requires accurate end-effector (EE) control and a generalizable understanding of the scene via visual inputs (e.g., RGB-D images). Existing approaches are based on real-world imitation learning and exhibit limited generalization due to the difficulty in collecting large-scale training datasets. This paper presents a new paradigm, HERO, for object loco-manipulation with humanoid robots that combines the strong generalization and open-vocabulary understanding of large vision models with strong control performance from simulated training. We achieve this by designing an accurate residual-aware EE tracking policy. This EE tracking policy combines classical robotics with machine learning. It uses a) inverse kinematics to convert residual end-effector targets into reference trajectories, b) a learned neural forward model for accurate forward kinematics, c) goal adjustment, and d) replanning. Together, these innovations help us cut down the end-effector tracking error by 3.2x. We use this accurate end-effector tracker to build a modular system for loco-manipulation, where we use open-vocabulary large vision models for strong visual generalization. Our system is able to operate in diverse real-world environments, from offices to coffee shops, where the robot is able to reliably manipulate various everyday objects (e.g., mugs, apples, toys) on surfaces ranging from 43cm to 92cm in height. Systematic modular and end-to-end tests in simulation and the real world demonstrate the effectiveness of our proposed design. We believe the advances in this paper can open up new ways of training humanoid robots to interact with daily objects.

</details>


### [160] [EgoScale: Scaling Dexterous Manipulation with Diverse Egocentric Human Data](https://arxiv.org/abs/2602.16710)
*Ruijie Zheng,Dantong Niu,Yuqi Xie,Jing Wang,Mengda Xu,Yunfan Jiang,Fernando Castañeda,Fengyuan Hu,You Liang Tan,Letian Fu,Trevor Darrell,Furong Huang,Yuke Zhu,Danfei Xu,Linxi Fan*

Main category: cs.RO

TL;DR: 该论文提出了一种基于大规模第一视角人类动作数据，实现人到灵巧操作转移的新框架EgoScale，并显著提升了机器人灵巧操作能力。


<details>
  <summary>Details</summary>
Motivation: 现有关于人类行为如何助力机器人灵巧操作的研究规模有限，尚不清楚大规模人类数据是否可以支持高自由度、精细的机器人操作控制。因此，作者旨在探索如何更好地利用大规模人类行为数据提升机器人灵巧操作。

Method: 作者提出EgoScale框架，通过采集并标注超过20,854小时的第一视角人类视频（行动标注），训练视觉-语言-动作（VLA）模型，并发现人类数据量与模型验证损失之间存在对数线性关系。随后，采用“两阶段迁移”：先在人类大规模数据上预训练，再进行少量人机对齐中间训练。

Result: 相比无预训练的基线方法，采用EgoScale的机器人（22自由度机械手）平均任务成功率提升了54%。所学策略能有效迁移到低自由度机械手，显示大规模人类运动可作为通用、与具体机械结构无关的运动先验。

Conclusion: 大规模人类运动数据为机器人灵巧操作提供了强有力、可预测的监督源，并通过预训练与少量中间对齐，可极大提升机器人的长时序操作能力和任务适应性。

Abstract: Human behavior is among the most scalable sources of data for learning physical intelligence, yet how to effectively leverage it for dexterous manipulation remains unclear. While prior work demonstrates human to robot transfer in constrained settings, it is unclear whether large scale human data can support fine grained, high degree of freedom dexterous manipulation. We present EgoScale, a human to dexterous manipulation transfer framework built on large scale egocentric human data. We train a Vision Language Action (VLA) model on over 20,854 hours of action labeled egocentric human video, more than 20 times larger than prior efforts, and uncover a log linear scaling law between human data scale and validation loss. This validation loss strongly correlates with downstream real robot performance, establishing large scale human data as a predictable supervision source. Beyond scale, we introduce a simple two stage transfer recipe: large scale human pretraining followed by lightweight aligned human robot mid training. This enables strong long horizon dexterous manipulation and one shot task adaptation with minimal robot supervision. Our final policy improves average success rate by 54% over a no pretraining baseline using a 22 DoF dexterous robotic hand, and transfers effectively to robots with lower DoF hands, indicating that large scale human motion provides a reusable, embodiment agnostic motor prior.

</details>


### [161] [One Hand to Rule Them All: Canonical Representations for Unified Dexterous Manipulation](https://arxiv.org/abs/2602.16712)
*Zhenyu Wei,Yunchao Yao,Mingyu Ding*

Main category: cs.RO

TL;DR: 本文提出了一种参数化的规范表示方法，以统一表征多样化的灵巧手结构，并通过此框架促进跨手型的政策泛化和迁移学习，实现高效的泛化和零次迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有灵巧操作策略主要针对固定手型，难以适应不同机械结构的新手型，限制了在实际机器人手多样化场景下的泛用性。

Method: 作者提出了一个包括统一参数空间和规范URDF的通用表示框架。该方法通过提炼各类手结构的形态和运动学参数，在此空间上用VAE训练潜在表征，并实现规范化的动作空间，从而促进不同手型间策略的迁移和泛化。

Result: 实验证明，该方法支持在不同手型之间的 grasp policy replay、VAE潜在编码、零次迁移任务等；在仿真和真实环境中，在未知手型（如3指LEAP Hand）上实现了81.9%的零次成功率，优于现有方法。

Conclusion: 本文方法有效统一了结构多样灵巧手的表征与动作策略空间，为通用灵巧操作策略的研究与部署提供了可扩展基础。

Abstract: Dexterous manipulation policies today largely assume fixed hand designs, severely restricting their generalization to new embodiments with varied kinematic and structural layouts. To overcome this limitation, we introduce a parameterized canonical representation that unifies a broad spectrum of dexterous hand architectures. It comprises a unified parameter space and a canonical URDF format, offering three key advantages. 1) The parameter space captures essential morphological and kinematic variations for effective conditioning in learning algorithms. 2) A structured latent manifold can be learned over our space, where interpolations between embodiments yield smooth and physically meaningful morphology transitions. 3) The canonical URDF standardizes the action space while preserving dynamic and functional properties of the original URDFs, enabling efficient and reliable cross-embodiment policy learning. We validate these advantages through extensive analysis and experiments, including grasp policy replay, VAE latent encoding, and cross-embodiment zero-shot transfer. Specifically, we train a VAE on the unified representation to obtain a compact, semantically rich latent embedding, and develop a grasping policy conditioned on the canonical representation that generalizes across dexterous hands. We demonstrate, through simulation and real-world tasks on unseen morphologies (e.g., 81.9% zero-shot success rate on 3-finger LEAP Hand), that our framework unifies both the representational and action spaces of structurally diverse hands, providing a scalable foundation for cross-hand learning toward universal dexterous manipulation.

</details>
