<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 92]
- [cs.CL](#cs.CL) [Total: 109]
- [cs.RO](#cs.RO) [Total: 31]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Beyond CNNs: Efficient Fine-Tuning of Multi-Modal LLMs for Object Detection on Low-Data Regimes](https://arxiv.org/abs/2510.08589)
*Nirmal Elamon,Rouzbeh Davoudi*

Main category: cs.CV

TL;DR: 本论文系统比较了传统CNN、零样本多模态大模型和微调多模态大模型在图片人工文本覆盖检测任务上的表现，发现微调后的多模态大模型在极少数据下也能显著超越传统CNN。


<details>
  <summary>Details</summary>
Motivation: 尽管CNN在图像任务中仍表现出色，但多模态大模型具备更强的场景理解和语言指导能力。然而，直接使用预训练模型在特定视觉任务上的性能有限，因此需探索其微调潜力。

Method: 作者对比了三类方法：1）面向图像的传统CNN（如ResNet、YOLO）；2）零样本的预训练多模态大模型（无需特定任务微调）；3）在极少数据集（<1000张图）上微调的多模态大模型。任务为人工文本覆盖检测。

Result: 实验表明，经过微调的多模态大模型在仅使用少量图片的情况下，准确率可比零样本提升高达36%，并达到或超过需大量数据训练的CNN基线。

Conclusion: 多模态大模型只需极少样本即可实现高效图像理解，体现出极强的数据利用效率和适应性。研究为多模态模型在低资源视觉环境下的落地提供参考，并开放了代码以促进相关领域发展。

Abstract: The field of object detection and understanding is rapidly evolving, driven
by advances in both traditional CNN-based models and emerging multi-modal large
language models (LLMs). While CNNs like ResNet and YOLO remain highly effective
for image-based tasks, recent transformer-based LLMs introduce new capabilities
such as dynamic context reasoning, language-guided prompts, and holistic scene
understanding. However, when used out-of-the-box, the full potential of LLMs
remains underexploited, often resulting in suboptimal performance on
specialized visual tasks. In this work, we conduct a comprehensive comparison
of fine-tuned traditional CNNs, zero-shot pre-trained multi-modal LLMs, and
fine-tuned multi-modal LLMs on the challenging task of artificial text overlay
detection in images. A key contribution of our study is demonstrating that LLMs
can be effectively fine-tuned on very limited data (fewer than 1,000 images) to
achieve up to 36% accuracy improvement, matching or surpassing CNN-based
baselines that typically require orders of magnitude more data. By exploring
how language-guided models can be adapted for precise visual understanding with
minimal supervision, our work contributes to the broader effort of bridging
vision and language, offering novel insights into efficient cross-modal
learning strategies. These findings highlight the adaptability and data
efficiency of LLM-based approaches for real-world object detection tasks and
provide actionable guidance for applying multi-modal transformers in
low-resource visual environments. To support continued progress in this area,
we have made the code used to fine-tune the models available in our GitHub,
enabling future improvements and reuse in related applications.

</details>


### [2] [Reproducible Evaluation of Data Augmentation and Loss Functions for Brain Tumor Segmentation](https://arxiv.org/abs/2510.08617)
*Saumya B*

Main category: cs.CV

TL;DR: 本论文评估了在脑肿瘤MRI分割任务中，使用focal loss和基础数据增强对U-Net性能的影响，提出了可复现的基线方法。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤分割对诊断与治疗规划至关重要，但现有方法易受类别不平衡和模型泛化能力有限的影响，因此亟需提升分割算法的性能和可复现性。

Method: 采用U-Net神经网络结构，引入focal loss并对其参数进行调优，同时评估了三种基础数据增强方法（水平翻转、旋转、缩放）在公开脑肿瘤MRI数据集上的效果，所有代码和实验结果均公开。

Result: 使用focal loss的U-Net模型达到了90%的精确率，表现与当前先进方法相当。

Conclusion: 本研究为脑肿瘤分割领域带来了公开透明、可复现的基线，有助于今后增强策略与损失函数设计的研究。

Abstract: Brain tumor segmentation is crucial for diagnosis and treatment planning, yet
challenges such as class imbalance and limited model generalization continue to
hinder progress. This work presents a reproducible evaluation of U-Net
segmentation performance on brain tumor MRI using focal loss and basic data
augmentation strategies. Experiments were conducted on a publicly available MRI
dataset, focusing on focal loss parameter tuning and assessing the impact of
three data augmentation techniques: horizontal flip, rotation, and scaling. The
U-Net with focal loss achieved a precision of 90%, comparable to
state-of-the-art results. By making all code and results publicly available,
this study establishes a transparent, reproducible baseline to guide future
research on augmentation strategies and loss function design in brain tumor
segmentation.

</details>


### [3] [Adjusting Initial Noise to Mitigate Memorization in Text-to-Image Diffusion Models](https://arxiv.org/abs/2510.08625)
*Hyeonggeun Han,Sehwan Kim,Hyungjun Joo,Sangwoo Hong,Jungwoo Lee*

Main category: cs.CV

TL;DR: 本文针对文生图扩散模型容易记忆和复制训练数据的问题，提出通过调整初始噪声来促进早期脱离吸引阱，从而减少记忆化并保持图文一致性。


<details>
  <summary>Details</summary>
Motivation: 文生图扩散模型在生成图像时存在记忆训练数据且复现原始素材的风险，带来了隐私和版权问题。已有方法通过延迟应用分类器无关引导（CFG）避免陷入吸引阱，但会导致生成结果与文本描述对齐性下降，因此需要改进。

Method: 作者发现初始噪声对脱离记忆吸引阱的时刻有显著影响。基于这一观察，提出了两种通过调整初始噪声（集体或个别）选择促使更早脱阱噪声样本的策略，并利用这些噪声进行生成，以减少记忆化。

Result: 两种初始噪声调整策略均显著降低了模型生成结果与训练集记忆重复的概率，同时较好保持了生成图像与文本描述的对齐度。

Conclusion: 通过优化初始噪声选择，可以在不影响文本-图像对齐的前提下，大幅降低扩散模型训练数据的记忆化问题，为保障数据隐私和版权提供了可行方案。

Abstract: Despite their impressive generative capabilities, text-to-image diffusion
models often memorize and replicate training data, prompting serious concerns
over privacy and copyright. Recent work has attributed this memorization to an
attraction basin-a region where applying classifier-free guidance (CFG) steers
the denoising trajectory toward memorized outputs-and has proposed deferring
CFG application until the denoising trajectory escapes this basin. However,
such delays often result in non-memorized images that are poorly aligned with
the input prompts, highlighting the need to promote earlier escape so that CFG
can be applied sooner in the denoising process. In this work, we show that the
initial noise sample plays a crucial role in determining when this escape
occurs. We empirically observe that different initial samples lead to varying
escape times. Building on this insight, we propose two mitigation strategies
that adjust the initial noise-either collectively or individually-to find and
utilize initial samples that encourage earlier basin escape. These approaches
significantly reduce memorization while preserving image-text alignment.

</details>


### [4] [The Digital Mirror: Gender Bias and Occupational Stereotypes in AI-Generated Images](https://arxiv.org/abs/2510.08628)
*Siiri Leppälampi,Sonja M. Hyrynsalmi,Erno Vanhala*

Main category: cs.CV

TL;DR: 本文研究了AI生成图像在职业场景下的代表性偏见，发现主流AI生成工具（DALL-E 3和Ideogram）在职业形象生成中普遍强化了传统性别刻板印象。


<details>
  <summary>Details</summary>
Motivation: 近年来，AI生成视觉内容的能力大幅提升，但研究多侧重于创作流程和图像质量，而忽视了生成内容在性别、年龄等方面的代表性偏见。该文正是为了弥补AI生成图片在性别和社会角色刻板化再现方面的研究空白。

Method: 作者选择DALL-E 3和Ideogram两种知名AI图像生成工具，针对职业类形象输入提示，生成了750多张图片。然后采用主题分析法对生成结果的性别表现及其潜在偏见进行评估，并讨论了图像中的年龄与情感表达情况。

Result: 主题分析结果表明，无论是DALL-E 3还是Ideogram，在AI生成的职业图像中均明显强化了传统性别刻板印象，但强化程度有所差异。这些工具往往呈现出狭窄且易于固化的职业性别形象。

Conclusion: AI视觉工具存在加剧性别与职业刻板印象的风险。建议实践者、用户和研究人员在生成带有明显性别特征的图像时，通过优化输入提示、加强多样性意识等方式，提升图像的代表性和包容性，避免负向社会影响。

Abstract: Generative AI offers vast opportunities for creating visualisations, such as
graphics, videos, and images. However, recent studies around AI-generated
visualisations have primarily focused on the creation process and image
quality, overlooking representational biases. This study addresses this gap by
testing representation biases in AI-generated pictures in an occupational
setting and evaluating how two AI image generator tools, DALL-E 3 and Ideogram,
compare. Additionally, the study discusses topics such as ageing and emotions
in AI-generated images. As AI image tools are becoming more widely used,
addressing and mitigating harmful gender biases becomes essential to ensure
diverse representation in media and professional settings. In this study, over
750 AI-generated images of occupations were prompted. The thematic analysis
results revealed that both DALL-E 3 and Ideogram reinforce traditional gender
stereotypes in AI-generated images, although to varying degrees. These findings
emphasise that AI visualisation tools risk reinforcing narrow representations.
In our discussion section, we propose suggestions for practitioners,
individuals and researchers to increase representation when generating images
with visible genders.

</details>


### [5] [Dynamic Mixture-of-Experts for Visual Autoregressive Model](https://arxiv.org/abs/2510.08629)
*Jort Vincenti,Metod Jazbec,Guoxuan Xia*

Main category: cs.CV

TL;DR: 提出了一种动态专家混合（Mixture-of-Experts）机制，用于提升视觉自回归模型（VAR）的效率，在减少计算量的同时保持图像生成质量。


<details>
  <summary>Details</summary>
Motivation: 传统视觉自回归模型在高分辨率下需多次调用Transformer，导致计算冗余，效率低下。因此，作者希望在不损失生成质量的情况下，减轻这一计算负担。

Method: 在VAR模型中集成动态Mixture-of-Experts路由器，通过scale-aware thresholding策略，根据token复杂度和分辨率动态选择专家，达到在计算和生成质量之间权衡。该方法无需额外训练。

Result: 该方法在保持生成质量的同时，实现了计算量（FLOPs）减少20%，推理速度提升11%。

Conclusion: 动态专家混合方法有效提升了VAR模型的推理效率，在保证图像质量的前提下显著减少了计算消耗。

Abstract: Visual Autoregressive Models (VAR) offer efficient and high-quality image
generation but suffer from computational redundancy due to repeated Transformer
calls at increasing resolutions. We introduce a dynamic Mixture-of-Experts
router integrated into VAR. The new architecture allows to trade compute for
quality through scale-aware thresholding. This thresholding strategy balances
expert selection based on token complexity and resolution, without requiring
additional training. As a result, we achieve 20% fewer FLOPs, 11% faster
inference and match the image quality achieved by the dense baseline.

</details>


### [6] [Out-of-Distribution Detection in LiDAR Semantic Segmentation Using Epistemic Uncertainty from Hierarchical GMMs](https://arxiv.org/abs/2510.08631)
*Hanieh Shojaei Miandashti,Claus Brenner*

Main category: cs.CV

TL;DR: 本文提出了一种基于层次贝叶斯高斯混合模型的无监督OOD（分布外）检测方法，能更准确识别激光雷达点云中未见过的（未知类）实例。该方法在无需额外数据和训练的情况下，性能优于现有的不确定性建模方法。


<details>
  <summary>Details</summary>
Motivation: 现有感知系统在LiDAR点云的语义分割过程中，难以准确检测分布外（OOD）未知物体，常将新类别误分类为已知类别。现有无监督方法主要依据预测熵，但会混淆模型和数据的不确定性，导致很多模糊但属于分布内部的区域误被判定为OOD，降低系统安全性。作者旨在克服这一问题，提升OOD检测的精度。

Method: 提出通过深度神经网络的特征空间，对高斯混合模型（GMM）参数进行层次贝叶斯建模，具体量化模型的epistemic不确定性，从而提升OOD检测的能力。该方法不依赖外部辅助数据集，也无需额外训练阶段。通过与先前主流的预测熵方法做了实验对比。

Result: 在SemanticKITTI数据集上，提出方法相较传统基于预测熵的不确定性方法，在AUROC提升了18%，AUPRC提升22%，FPR95从76%降至40%，表现显著优越。

Conclusion: 该方法在不增加数据和训练成本的前提下，有效提升了基于不确定性建模的LiDAR点云OOD检测性能，为自动驾驶等场景的安全性感知提供了更优方案。

Abstract: In addition to accurate scene understanding through precise semantic
segmentation of LiDAR point clouds, detecting out-of-distribution (OOD)
objects, instances not encountered during training, is essential to prevent the
incorrect assignment of unknown objects to known classes. While supervised OOD
detection methods depend on auxiliary OOD datasets, unsupervised methods avoid
this requirement but typically rely on predictive entropy, the entropy of the
predictive distribution obtained by averaging over an ensemble or multiple
posterior weight samples. However, these methods often conflate epistemic
(model) and aleatoric (data) uncertainties, misclassifying ambiguous in
distribution regions as OOD. To address this issue, we present an unsupervised
OOD detection approach that employs epistemic uncertainty derived from
hierarchical Bayesian modeling of Gaussian Mixture Model (GMM) parameters in
the feature space of a deep neural network. Without requiring auxiliary data or
additional training stages, our approach outperforms existing uncertainty-based
methods on the SemanticKITTI dataset, achieving an 18\% improvement in AUROC,
22\% increase in AUPRC, and 36\% reduction in FPR95 (from 76\% to 40\%),
compared to the predictive entropy approach used in prior works.

</details>


### [7] [Hi-OSCAR: Hierarchical Open-set Classifier for Human Activity Recognition](https://arxiv.org/abs/2510.08635)
*Conor McCarthy,Loes Quirijnen,Jan Peter van Zandwijk,Zeno Geradts,Marcel Worring*

Main category: cs.CV

TL;DR: 本文提出了一种层次化开放集分类器Hi-OSCAR，用于在识别已知活动的同时拒绝未知活动，并发布了新数据集NFI_FARED促进相关研究。


<details>
  <summary>Details</summary>
Motivation: 在现实生活中，人的活动类型远多于用于训练的传感器标注数据集。如果不能有效处理“未见过”的活动，会大大影响活动识别（HAR）系统的可靠性。同时，部分活动之间存在重叠或包含关系，因此需要建立活动类别的层次结构。

Method: 作者将活动类别组织成结构化的层级体系，并提出了层次化开放集分类器Hi-OSCAR。该方法既能以先进的精度识别已知活动，又能拒绝未知活动，还可将未知类别定位到最近的内部节点，超越了传统的“已知/未知”二元分类。

Result: Hi-OSCAR在识别已知活动和拒绝未知活动方面均有优异表现。为推动开放集HAR研究，作者采集并公开了一个涵盖19项不同活动、包含多位被试的新数据集NFI_FARED。

Conclusion: 本文提出的Hi-OSCAR方法有效提升了开放环境下的人体活动识别能力，尤其是在应对类别不可预见性与类别重叠现实问题方面具有理论与实际意义。新数据集有助于后续相关研究。

Abstract: Within Human Activity Recognition (HAR), there is an insurmountable gap
between the range of activities performed in life and those that can be
captured in an annotated sensor dataset used in training. Failure to properly
handle unseen activities seriously undermines any HAR classifier's reliability.
Additionally within HAR, not all classes are equally dissimilar, some
significantly overlap or encompass other sub-activities. Based on these
observations, we arrange activity classes into a structured hierarchy. From
there, we propose Hi-OSCAR: a Hierarchical Open-set Classifier for Activity
Recognition, that can identify known activities at state-of-the-art accuracy
while simultaneously rejecting unknown activities. This not only enables
open-set classification, but also allows for unknown classes to be localized to
the nearest internal node, providing insight beyond a binary "known/unknown"
classification. To facilitate this and future open-set HAR research, we
collected a new dataset: NFI_FARED. NFI_FARED contains data from multiple
subjects performing nineteen activities from a range of contexts, including
daily living, commuting, and rapid movements, which is fully public and
available for download.

</details>


### [8] [Detection of high-frequency oscillations using time-frequency analysis](https://arxiv.org/abs/2510.08637)
*Mostafa Mohammadpour,Mehdi Zekriyapanah Gashti,Yusif S. Gasimov*

Main category: cs.CV

TL;DR: 本研究提出了一种新颖的高频振荡（HFOs）自动检测方法，并验证其在癫痫病灶区识别中的有效性。


<details>
  <summary>Details</summary>
Motivation: 高频振荡是识别癫痫病灶区的新型生物标志物，但现有的肉眼识别方法繁琐且主观，亟需自动化、可靠的检测方法以用于临床和科研。

Method: 研究团队开发了一种适用于80-500 Hz频段新的检测算法，结合了S变换提取时频域特征与无监督聚类方法，将HFOs与尖波、背景活动和伪影区分开。方法在受控数据集和真实癫痫患者数据上进行了验证。

Result: 方法在受控数据集上检测HFOs的灵敏度为97.67%、精准度为98.57%、F得分为97.78%。在癫痫患者中，该方法检测到的病灶区HFOs与手术预后具有很强相关性，切除区与非切除区比值达到0.73。

Conclusion: HFOs是癫痫病灶区的有力生物标志物，自动检测方法可辅助精准手术切除，尤其是快速高频震荡的清除与术后无发作率密切相关。

Abstract: High-frequency oscillations (HFOs) are a new biomarker for identifying the
epileptogenic zone. Mapping HFO-generating regions can improve the precision of
resection sites in patients with refractory epilepsy. However, detecting HFOs
remains challenging, and their clinical features are not yet fully defined.
Visual identification of HFOs is time-consuming, labor-intensive, and
subjective. As a result, developing automated methods to detect HFOs is
critical for research and clinical use. In this study, we developed a novel
method for detecting HFOs in the ripple and fast ripple frequency bands (80-500
Hz). We validated it using both controlled datasets and data from epilepsy
patients. Our method employs an unsupervised clustering technique to categorize
events extracted from the time-frequency domain using the S-transform. The
proposed detector differentiates HFOs events from spikes, background activity,
and artifacts. Compared to existing detectors, our method achieved a
sensitivity of 97.67%, a precision of 98.57%, and an F-score of 97.78% on the
controlled dataset. In epilepsy patients, our results showed a stronger
correlation with surgical outcomes, with a ratio of 0.73 between HFOs rates in
resected versus non-resected contacts. The study confirmed previous findings
that HFOs are promising biomarkers of epileptogenicity in epileptic patients.
Removing HFOs, especially fast ripple, leads to seizure freedom, while
remaining HFOs lead to seizure recurrence.

</details>


### [9] [Into the Rabbit Hull: From Task-Relevant Concepts in DINO to Minkowski Geometry](https://arxiv.org/abs/2510.08638)
*Thomas Fel,Binxu Wang,Michael A. Lepori,Matthew Kowal,Andrew Lee,Randall Balestriero,Sonia Joseph,Ekdeep S. Lubana,Talia Konkle,Demba Ba,Martin Wattenberg*

Main category: cs.CV

TL;DR: 本论文对DINOv2视觉Transformer中的表征进行可解释性分析，认为其表征结构比线性稀疏更富层次，提出了Minkowski Representation Hypothesis，认为表征是多个原型混合而成，对ViT的解释机制提出新见解。


<details>
  <summary>Details</summary>
Motivation: 尽管DINOv2已被广泛应用于各类视觉任务，但其内部感知及表征特性尚不清楚。因此，作者希望深入揭示其表征机制，并推动对视觉模型可解释性的理解。

Method: 作者采用线性表征假说（LRH）为基线，利用稀疏自动编码器（SAE）构建包含3.2万个单元的表征字典，对模型编码的概念进行分析。随后结合几何和统计方法探查表征特点，并提出新的假说（MRH）。

Result: 分类、分割、深度估计等下游任务对该字典中的概念有各自的功能化利用，如分类侧重于对象以外区域信号、分割依赖边界单元、深度估计对应神经科学三大线索。概念表征呈现部分致密，非完全面性稀疏，且在几何上偏离正交最理想状态。每张图片内的token分布在低维连续空间，表征组织超越线性稀疏。

Conclusion: DINOv2的表征并非单纯的线性稀疏表达，而更符合由多个原型凸组合的结构。新提出的Minkowski Representation Hypothesis为ViT中的视觉表征提供了更贴合且可验证的解释视角，对后续模型可解释性研究有重要启发。

Abstract: DINOv2 is routinely deployed to recognize objects, scenes, and actions; yet
the nature of what it perceives remains unknown. As a working baseline, we
adopt the Linear Representation Hypothesis (LRH) and operationalize it using
SAEs, producing a 32,000-unit dictionary that serves as the interpretability
backbone of our study, which unfolds in three parts.
  In the first part, we analyze how different downstream tasks recruit concepts
from our learned dictionary, revealing functional specialization:
classification exploits "Elsewhere" concepts that fire everywhere except on
target objects, implementing learned negations; segmentation relies on boundary
detectors forming coherent subspaces; depth estimation draws on three distinct
monocular depth cues matching visual neuroscience principles.
  Following these functional results, we analyze the geometry and statistics of
the concepts learned by the SAE. We found that representations are partly dense
rather than strictly sparse. The dictionary evolves toward greater coherence
and departs from maximally orthogonal ideals (Grassmannian frames). Within an
image, tokens occupy a low dimensional, locally connected set persisting after
removing position. These signs suggest representations are organized beyond
linear sparsity alone.
  Synthesizing these observations, we propose a refined view: tokens are formed
by combining convex mixtures of archetypes (e.g., a rabbit among animals, brown
among colors, fluffy among textures). This structure is grounded in Gardenfors'
conceptual spaces and in the model's mechanism as multi-head attention produces
sums of convex mixtures, defining regions bounded by archetypes. We introduce
the Minkowski Representation Hypothesis (MRH) and examine its empirical
signatures and implications for interpreting vision-transformer
representations.

</details>


### [10] [PhyDAE: Physics-Guided Degradation-Adaptive Experts for All-in-One Remote Sensing Image Restoration](https://arxiv.org/abs/2510.08653)
*Zhe Dong,Yuzhe Sun,Haochen Jiang,Tianzhu Liu,Yanfeng Gu*

Main category: cs.CV

TL;DR: 本文提出了一种新型的物理引导的退化自适应专家模型（PhyDAE），能够通过显式建模多种复杂遥感图像退化（如雾霾、噪声、模糊、低光），实现高效高质量的图像恢复，并在多个基准数据集上全面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 遥感图像在采集过程中不可避免地受到大气干扰、传感器局限等多种复杂退化影响，导致图像质量下降，严重影响后续应用。现有方法多依赖隐式特征，无法充分刻画退化物理规律，处理多类型退化效果有限，有必要提出能精细处理且兼顾物理一致性的通用恢复方法。

Method: 提出物理引导退化自适应专家（PhyDAE）模型，采用两阶段级联架构，将隐式退化特征显式转化为决策信号，实现对多退化类型的辨别与差异化处理。关键技术包括残差流形投影器（RMP）、频域退化分解器（FADD），结合物理感知专家模块与温控稀疏激活策略，兼顾物理一致性与高效计算。

Result: 在MD-RSID、MD-RRSHID、MDRS-Landsat三个基准上，PhyDAE在雾霾、噪声、模糊、低光等所有任务和指标上均大幅优于最新方法，恢复质量显著提升，总参数量和计算量大幅减少，实现了性能与效率最优平衡。

Conclusion: PhyDAE凭借有效的多退化识别与物理一致恢复机制，在遥感图像多退化恢复领域达到了新的性能与效率高度，为实际应用带来更高质量和更高效的遥感图像处理方案。

Abstract: Remote sensing images inevitably suffer from various degradation factors
during acquisition, including atmospheric interference, sensor limitations, and
imaging conditions. These complex and heterogeneous degradations pose severe
challenges to image quality and downstream interpretation tasks. Addressing
limitations of existing all-in-one restoration methods that overly rely on
implicit feature representations and lack explicit modeling of degradation
physics, this paper proposes Physics-Guided Degradation-Adaptive Experts
(PhyDAE). The method employs a two-stage cascaded architecture transforming
degradation information from implicit features into explicit decision signals,
enabling precise identification and differentiated processing of multiple
heterogeneous degradations including haze, noise, blur, and low-light
conditions. The model incorporates progressive degradation mining and
exploitation mechanisms, where the Residual Manifold Projector (RMP) and
Frequency-Aware Degradation Decomposer (FADD) comprehensively analyze
degradation characteristics from manifold geometry and frequency perspectives.
Physics-aware expert modules and temperature-controlled sparse activation
strategies are introduced to enhance computational efficiency while ensuring
imaging physics consistency. Extensive experiments on three benchmark datasets
(MD-RSID, MD-RRSHID, and MDRS-Landsat) demonstrate that PhyDAE achieves
superior performance across all four restoration tasks, comprehensively
outperforming state-of-the-art methods. Notably, PhyDAE substantially improves
restoration quality while achieving significant reductions in parameter count
and computational complexity, resulting in remarkable efficiency gains compared
to mainstream approaches and achieving optimal balance between performance and
efficiency. Code is available at https://github.com/HIT-SIRS/PhyDAE.

</details>


### [11] [Hulu-Med: A Transparent Generalist Model towards Holistic Medical Vision-Language Understanding](https://arxiv.org/abs/2510.08668)
*Songtao Jiang,Yuan Wang,Sibo Song,Tianxiang Hu,Chenyi Zhou,Bin Pu,Yan Zhang,Zhibo Yang,Yang Feng,Joey Tianyi Zhou,Jin Hao,Zijian Chen,Ruijia Wu,Tao Tang,Junhui Lv,Hongxia Xu,Hongwei Wang,Jun Xiao,Bin Feng,Fudong Zhu,Kenli Li,Weidi Xie,Jimeng Sun,Jian Wu,Zuozhu Liu*

Main category: cs.CV

TL;DR: 该论文提出了Hulu-Med，一种统一多模态医学理解的视觉-语言模型（VLM），能够处理医学文本、2D/3D图像及视频等多种类型数据，并在多个医学任务和基准上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现实临床决策中需要融合多种数据模态（如文本、图像、视频），但现有通用VLM在医学领域面临管道不透明、数据稀缺和架构灵活性差等问题。因此需要一种透明、高效、适应多模态的医学VLM。

Method: Hulu-Med采用统一的patch-based视觉编码器和大语言模型解码器，并利用医学感知的token reduction机制提升训练效率。模型在1670万样本上逐步扩展了2D到3D及视频理解能力，支持7B到32B参数规模。

Result: Hulu-Med在30个医学基准任务上均展现优异表现，超越主流开源模型，并与闭源系统竞争，涵盖视觉问答、医学报告生成、多语言和罕见病推理等多个场景。

Conclusion: Hulu-Med证明了高性能医学VLM可以通过公开透明的方式实现，并为临床AI研究提供了坚实基础。完整代码和管道已开源，有助于推动可访问且具影响力的医学AI发展。

Abstract: Real-world clinical decision-making grapples with integrating information
from diverse data modalities, including medical text, 2D/3D images, and video,
leading to inefficiencies and potential diagnostic oversights. While generalist
vision-language models (VLMs) offer promise, their medical development faces
challenges of opaque pipelines, data scarcity, and architectural inflexibility.
Here we present Hulu-Med, a transparent medical VLM that unifies understanding
across all these modalities. Built upon a unified patch-based vision encoder
and an LLM decoder, Hulu-Med was progressively trained on 16.7 million (M)
samples to scale from 2D to 3D and video comprehension. The medical-aware token
reduction enables efficient training, requiring only 4,000 to 40,000 GPU hours
for 7B to 32B parameter variants. Extensive evaluation across 30 benchmarks
exhibits state-of-the-art performance, surpassing leading open-source models
and competing with proprietary systems in tasks spanning visual
question-answering, medical report generation, and complex reasoning in
multilingual and rare disease scenarios. By open-sourcing our complete
pipeline, we establish that high-performance medical VLM can be achieved
transparently, providing a foundational tool for accessible and impactful
clinical AI. Code is released on
\href{https://github.com/ZJUI-AI4H/Hulu-Med}{https://github.com/ZJUI-AI4H/Hulu-Med}.

</details>


### [12] [Thinking with Camera: A Unified Multimodal Model for Camera-Centric Understanding and Generation](https://arxiv.org/abs/2510.08673)
*Kang Liao,Size Wu,Zhonghua Wu,Linyi Jin,Chao Wang,Yikai Wang,Fei Wang,Wei Li,Chen Change Loy*

Main category: cs.CV

TL;DR: Puffin 是一个结合了多模态理解和生成的 camera-centric 模型，能够从任意视角理解和生成场景，在多个空间智能相关任务中性能优异。


<details>
  <summary>Details</summary>
Motivation: 空间智能的核心在于对场景的理解和生成，而多数现有方法将二者分开研究，缺乏统一的 camera-centric 空间感知。

Method: 提出 Puffin 模型，将镜头参数和像素级相机信息编码为类语言特征，通过将“相机”作为一种语言模态，融合语言回归与基于扩散的生成，实现视角无关的场景理解与创作。新构建 Puffin-4M 数据集（400万组物体-语言-相机三元组）。

Result: Puffin 在相机中心的生成和理解任务上表现优于现有专门模型，能处理多种跨视角任务，并具备很强的泛化能力。

Conclusion: Puffin 展现了统一的视觉-语言-相机多模态建模范式，在空间智能研究领域具有重要意义。代码、模型和数据即将开放，有望推动该领域发展。

Abstract: Camera-centric understanding and generation are two cornerstones of spatial
intelligence, yet they are typically studied in isolation. We present Puffin, a
unified camera-centric multimodal model that extends spatial awareness along
the camera dimension. Puffin integrates language regression and diffusion-based
generation to interpret and create scenes from arbitrary viewpoints. To bridge
the modality gap between cameras and vision-language, we introduce a novel
paradigm that treats camera as language, enabling thinking with camera. This
guides the model to align spatially grounded visual cues with photographic
terminology while reasoning across geometric context. Puffin is trained on
Puffin-4M, a large-scale dataset of 4 million vision-language-camera triplets.
We incorporate both global camera parameters and pixel-wise camera maps,
yielding flexible and reliable spatial generation. Experiments demonstrate
Puffin superior performance over specialized models for camera-centric
generation and understanding. With instruction tuning, Puffin generalizes to
diverse cross-view tasks such as spatial imagination, world exploration, and
photography guidance. We will release the code, models, dataset pipeline, and
benchmark to advance multimodal spatial intelligence research.

</details>


### [13] [Structured Output Regularization: a framework for few-shot transfer learning](https://arxiv.org/abs/2510.08728)
*Nicolas Ewen,Jairo Diaz-Rodriguez,Kelly Ramsay*

Main category: cs.CV

TL;DR: 该论文提出了一种新的迁移学习框架“结构化输出正则化（SOR）”，通过引入group lasso和L1正则，冻结网络内部结构，应用于少样本医学图像分类，实验效果优异。


<details>
  <summary>Details</summary>
Motivation: 传统迁移学习通常通过冻结部分预训练网络权重，并添加任务特定层来适应新任务，虽然高效，但适应性有限且数据极少时易过拟合。本文旨在克服这些局限。

Method: 提出Structured Output Regularization（SOR）框架，在冻结网络内部结构的同时，利用group lasso与L1惩罚，实现对特定任务数据的微调，且引入的额外参数有限。该方法可应用于不同神经网络组件（如卷积核或网络模块），适用性广。

Result: 在三个少样本医学图像分类任务中，基于DenseNet121和EfficientNetB4的SOR方法取得了与现有基线模型相当甚至更优的性能。

Conclusion: SOR方法在迁移学习特别是少样本领域表现出色，结构简单易应用，有助于神经网络在有限数据下的适应性扩展。

Abstract: Traditional transfer learning typically reuses large pre-trained networks by
freezing some of their weights and adding task-specific layers. While this
approach is computationally efficient, it limits the model's ability to adapt
to domain-specific features and can still lead to overfitting with very limited
data. To address these limitations, we propose Structured Output Regularization
(SOR), a simple yet effective framework that freezes the internal network
structures (e.g., convolutional filters) while using a combination of group
lasso and $L_1$ penalties. This framework tailors the model to specific data
with minimal additional parameters and is easily applicable to various network
components, such as convolutional filters or various blocks in neural networks
enabling broad applicability for transfer learning tasks. We evaluate SOR on
three few shot medical imaging classification tasks and we achieve competitive
results using DenseNet121, and EfficientNetB4 bases compared to established
benchmarks.

</details>


### [14] [BEAR: Benchmarking and Enhancing Multimodal Language Models for Atomic Embodied Capabilities](https://arxiv.org/abs/2510.08759)
*Yu Qi,Haibo Zhao,Ziyu Guo,Siyuan Ma,Ziyan Chen,Yaokun Han,Renrui Zhang,Zitiantao Lin,Shiji Xin,Yijian Huang,Kai Cheng,Peiheng Wang,Jiazheng Liu,Jiayi Zhang,Yizhe Zhu,Wenqing Wang,Yiran Qin,Xupeng Zhu,Haojie Huang,Lawson L. S. Wong*

Main category: cs.CV

TL;DR: 本文提出了BEAR基准，用于全面评估多模态大语言模型（MLLMs）的具身能力，并开发了BEAR-Agent提升模型表现。实验发现改进后的MLLM在多种具身任务中的能力显著提升。


<details>
  <summary>Details</summary>
Motivation: 以往对MLLMs具身能力的评估不够系统和细致，现有基准通常仅覆盖规划等特定领域，缺乏对基本与复杂具身能力的全面测试。本文旨在填补此评估空白。

Method: 作者提出了BEAR基准，包含4469条跨越14个领域、6大类的图像-视频-文本任务，覆盖从基础到高级的具身任务。对20个主流MLLM进行系统测试，并提出BEAR-Agent，结合预训练视觉模型来提升模型在感知、三维理解和规划方面的能力。

Result: 大量实验显示，当前各类MLLM在具身能力全域都存在明显不足。应用BEAR-Agent后，模型在BEAR基准上获得了9.12%的绝对提升和17.5%的相对提升，GPT-5表现尤为突出。同时，提升的具身能力有助于模型在模拟环境下具身任务的表现。

Conclusion: BEAR为MLLMs的具身能力评估提供了系统化工具，证明通过多模态整合能显著提升其在多种具身场景下的表现，对未来MLLM研究与应用具有重要意义。

Abstract: Embodied capabilities refer to a suite of fundamental abilities for an agent
to perceive, comprehend, and interact with the physical world. While multimodal
large language models (MLLMs) show promise as embodied agents, a thorough and
systematic evaluation of their embodied capabilities remains underexplored, as
existing benchmarks primarily focus on specific domains such as planning or
spatial understanding. To bridge this gap, we introduce BEAR, a comprehensive
and fine-grained benchmark that evaluates MLLMs on atomic embodied
capabilities. BEAR comprises 4,469 interleaved image-video-text entries across
14 domains in 6 categories, including tasks from low-level pointing, trajectory
understanding, spatial reasoning, to high-level planning. Extensive evaluation
results of 20 representative MLLMs reveal their persistent limitations across
all domains of embodied capabilities. To tackle the shortfall, we propose
BEAR-Agent, a multimodal conversable agent that integrates pretrained vision
models to strengthen MLLM perception, 3D understanding, and planning
capabilities. It substantially enhances MLLM performance across diverse
embodied capabilities on BEAR, yielding a 9.12% absolute gain and a relative
improvement of 17.5% on GPT-5. Furthermore, our experiments indicate that
improving MLLM embodied capabilities can benefit embodied tasks in simulated
environments. Project website: https://bear-official66.github.io/

</details>


### [15] [SAFER-AiD: Saccade-Assisted Foveal-peripheral vision Enhanced Reconstruction for Adversarial Defense](https://arxiv.org/abs/2510.08761)
*Jiayang Liu,Daniel Tso,Yiming Bu,Qinru Qiu*

Main category: cs.CV

TL;DR: 本文提出了一种受生物视觉机制启发的防御框架，通过模拟人类视觉系统增强深度学习模型对对抗攻击的鲁棒性。该方法无需对下游分类器重新训练，在提升鲁棒性的同时大幅降低训练开销。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗攻击防御方法多依赖计算密集的优化策略，如对抗训练或数据增强，效率低下。而人类视觉系统能天然抵御对抗干扰，有望为神经网络鲁棒性提供新思路。因此，本文希望探索生物机制对抗攻击的潜力。

Method: 框架融合了三项生物机制：中心-周边视觉加工、扫视性眼动和皮层填补。具体实现上，借助强化学习引导的扫视动作获取多次不同视域（中心+周边）图像信息，并将其重建汇总，作为分类前的预处理步骤。这一过程可与现有分类器无缝集成，无需其重新训练或微调。

Result: 在ImageNet数据集上的实验证明，该方法在不同类型攻击和多种分类器下均能显著提升系统鲁棒性，且训练资源消耗远低于其他主流防御方法。

Conclusion: 受生物视觉系统启发的输入预处理可以有效缓解对抗干扰，提升深度学习模型的安全性与实用性，并具备极强的工程兼容性和实际应用潜力。

Abstract: Adversarial attacks significantly challenge the safe deployment of deep
learning models, particularly in real-world applications. Traditional defenses
often rely on computationally intensive optimization (e.g., adversarial
training or data augmentation) to improve robustness, whereas the human visual
system achieves inherent robustness to adversarial perturbations through
evolved biological mechanisms. We hypothesize that attention guided
non-homogeneous sparse sampling and predictive coding plays a key role in this
robustness. To test this hypothesis, we propose a novel defense framework
incorporating three key biological mechanisms: foveal-peripheral processing,
saccadic eye movements, and cortical filling-in. Our approach employs
reinforcement learning-guided saccades to selectively capture multiple
foveal-peripheral glimpses, which are integrated into a reconstructed image
before classification. This biologically inspired preprocessing effectively
mitigates adversarial noise, preserves semantic integrity, and notably requires
no retraining or fine-tuning of downstream classifiers, enabling seamless
integration with existing systems. Experiments on the ImageNet dataset
demonstrate that our method improves system robustness across diverse
classifiers and attack types, while significantly reducing training overhead
compared to both biologically and non-biologically inspired defense techniques.

</details>


### [16] [Detecting spills using thermal imaging, pretrained deep learning models, and a robotic platform](https://arxiv.org/abs/2510.08770)
*Gregory Yeghiyan,Jurius Azar,Devson Butani,Chan-Jin Chung*

Main category: cs.CV

TL;DR: 本文提出了一个基于预训练深度学习模型、结合RGB和热成像的实时液体泄漏检测系统。实验结果显示，使用热成像的模型在速度、精度和模型体积方面表现更佳，可快速且准确地检测泄漏，适用于安全关键场景。


<details>
  <summary>Details</summary>
Motivation: 液体泄漏（如油、水等）会造成严重安全隐患，尤其在复杂和多变的环境中，传统检测方式存在局限。作者希望通过深度学习和多模态成像提升液体泄漏检测的实时性和准确性。

Method: 采用平衡的二分类数据集（4000张图像），结合RGB与热成像数据，利用多个轻量级深度学习模型（如VGG19、NasNetMobile）进行训练与测试，并对比分析不同模型与成像方式的表现。

Result: 在实验中，热成像模型在推理速度、准确率（最高达100%）、鲁棒性上均优于RGB模型。系统在消费级硬件（RTX 4080）上，推理速度低至44毫秒，模型体积小于350 MB，VGG19热成像模型表现最优。

Conclusion: 热成像结合轻量级深度学习模型，为实时液体泄漏检测提供高效、准确和可部署的解决方案，特别适合应用于安全关键场景。

Abstract: This paper presents a real-time spill detection system that utilizes
pretrained deep learning models with RGB and thermal imaging to classify spill
vs. no-spill scenarios across varied environments. Using a balanced binary
dataset (4,000 images), our experiments demonstrate the advantages of thermal
imaging in inference speed, accuracy, and model size. We achieve up to 100%
accuracy using lightweight models like VGG19 and NasNetMobile, with thermal
models performing faster and more robustly across different lighting
conditions. Our system runs on consumer-grade hardware (RTX 4080) and achieves
inference times as low as 44 ms with model sizes under 350 MB, highlighting its
deployability in safety-critical contexts. Results from experiments with a real
robot and test datasets indicate that a VGG19 model trained on thermal imaging
performs best.

</details>


### [17] [LinearSR: Unlocking Linear Attention for Stable and Efficient Image Super-Resolution](https://arxiv.org/abs/2510.08771)
*Xiaohui Li,Shaobin Zhuang,Shuo Cao,Yang Yang,Yuandong Pu,Qi Qin,Siqi Luo,Bin Fu,Yihao Liu*

Main category: cs.CV

TL;DR: 本论文提出了一种高效的图像超分辨率生成模型LinearSR，首次系统性地解决了线性注意力在真实感超分领域应用面对的关键难题，实现了高效且高质量的图像重建。


<details>
  <summary>Details</summary>
Motivation: 当前图像超分辨率生成模型虽然能力强大，但自注意力机制的平方级复杂度导致计算瓶颈。线性注意力可降为线性复杂度，却因一系列未解难题未能有效用于高质量超分辨率重建。为打破这一障碍，亟需创新性框架。

Method: 提出了LinearSR框架，创新性地解决了模型训练不稳定的问题（通过基于拐点的早停微调ESGF策略），感知-失真权衡问题（采用基于SNR的专家混合MoE结构），以及高效轻量的TAG指导范式，体现“质量优先于体量”原则。

Result: LinearSR模型在保持感知质量SOTA的同时实现了出色的推理效率（1-NFE的扩散前向速度接近SOTA，多步推理整体时间亦非常有竞争力）。

Conclusion: 本文首次为线性注意力在真实感超分领域的有效应用提供了完整可行的方法论，奠定了此方向高效生成式超分研究的新范式。

Abstract: Generative models for Image Super-Resolution (SR) are increasingly powerful,
yet their reliance on self-attention's quadratic complexity (O(N^2)) creates a
major computational bottleneck. Linear Attention offers an O(N) solution, but
its promise for photorealistic SR has remained largely untapped, historically
hindered by a cascade of interrelated and previously unsolved challenges. This
paper introduces LinearSR, a holistic framework that, for the first time,
systematically overcomes these critical hurdles. Specifically, we resolve a
fundamental, training instability that causes catastrophic model divergence
using our novel "knee point"-based Early-Stopping Guided Fine-tuning (ESGF)
strategy. Furthermore, we mitigate the classic perception-distortion trade-off
with a dedicated SNR-based Mixture of Experts (MoE) architecture. Finally, we
establish an effective and lightweight guidance paradigm, TAG, derived from our
"precision-over-volume" principle. Our resulting LinearSR model simultaneously
delivers state-of-the-art perceptual quality with exceptional efficiency. Its
core diffusion forward pass (1-NFE) achieves SOTA-level speed, while its
overall multi-step inference time remains highly competitive. This work
provides the first robust methodology for applying Linear Attention in the
photorealistic SR domain, establishing a foundational paradigm for future
research in efficient generative super-resolution.

</details>


### [18] [Re-Identifying Kākā with AI-Automated Video Key Frame Extraction](https://arxiv.org/abs/2510.08775)
*Paula Maddigan,Andrew Lensen,Rachael C. Shaw*

Main category: cs.CV

TL;DR: 采用人工智能和计算机视觉，利用无创视频分析技术实现了濒危新西兰鹦鹉kākā个体的高效识别和再识别，显著提升了野生动物监测的自动化与准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的野生动物个体识别方法（如环志）操作繁琐且具侵入性，难以满足现代野生动物保护与监测的高效与智能化需求。随着AI和计算机视觉的发展，需要探索其在野生动物非侵入性识别中的应用潜力。

Method: 从专用投喂器拍摄的kākā视频中，利用YOLO与Grounding DINO进行对象检测，结合光流模糊检测，DINOv2进行图像编码，并通过聚类方法自动提取代表性关键帧，以实现个体识别与再识别；该方法属于无监督范式。

Result: 所提出的关键帧选择方法可以有效挑选高质量代表图像，并显著提升kākā个体的再识别准确率，在真实收集数据中表现良好。

Conclusion: 该研究表明，结合AI的无创、自动个体识别是传统物理标记方法的有效补充，有助于提升野生动物种群监测的效率，为生态与保护生物学领域提供了新工具和新思路。

Abstract: Accurate recognition and re-identification of individual animals is essential
for successful wildlife population monitoring. Traditional methods, such as leg
banding of birds, are time consuming and invasive. Recent progress in
artificial intelligence, particularly computer vision, offers encouraging
solutions for smart conservation and efficient automation. This study presents
a unique pipeline for extracting high-quality key frames from videos of
k\={a}k\={a} (Nestor meridionalis), a threatened forest-dwelling parrot in New
Zealand. Key frame extraction is well-studied in person re-identification,
however, its application to wildlife is limited. Using video recordings at a
custom-built feeder, we extract key frames and evaluate the re-identification
performance of our pipeline. Our unsupervised methodology combines object
detection using YOLO and Grounding DINO, optical flow blur detection, image
encoding with DINOv2, and clustering methods to identify representative key
frames. The results indicate that our proposed key frame selection methods
yield image collections which achieve high accuracy in k\={a}k\={a}
re-identification, providing a foundation for future research using media
collected in more diverse and challenging environments. Through the use of
artificial intelligence and computer vision, our non-invasive and efficient
approach provides a valuable alternative to traditional physical tagging
methods for recognising k\={a}k\={a} individuals and therefore improving the
monitoring of populations. This research contributes to developing fresh
approaches in wildlife monitoring, with applications in ecology and
conservation biology.

</details>


### [19] [Q-Router: Agentic Video Quality Assessment with Expert Model Routing and Artifact Localization](https://arxiv.org/abs/2510.08789)
*Shuo Xing,Soumik Dey,Mingyang Wu,Ashirbad Mishra,Hansi Wu,Binbin Li,Zhengzhong Tu*

Main category: cs.CV

TL;DR: Q-Router 是一种新的视频质量评估(VQA)框架，通过多层模型路由系统，将多个专家模型与视觉-语言模型结合，有效提升泛化性、可解释性和可扩展性，并在多项基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 目前主流的VQA模型在面对不同类型视频内容（如UGC、短视频、AI生成内容）时，泛化能力不足，且缺乏可解释性和对新场景的适应能力，难以满足实际中多变的需求。

Method: 提出 Q-Router 框架，将多个具有专业能力的专家模型通过视觉-语言模型动态路由整合，采用多层级路由方案（考虑算力消耗），在解释性最高层提供时空伪影定位。整体采用 agentic（自主智能体型）设计，使路由决策基于输入视频语义，实现灵活组合专家模型。

Result: 在多项VQA基准上，Q-Router达到或超越现有最优方法，尤其提升了模型的泛化能力和解释性，同时在质量问题问答基准Q-Bench-Video上表现突出，并能准确定位视频时空伪影。

Conclusion: Q-Router不仅兼具VQA的灵活性、鲁棒性与可扩展性，还具备很强的可解释性和新领域适应能力，有望成为下一代视频质量评估系统的基础，并能用于后期视频生成模型的奖励函数。

Abstract: Video quality assessment (VQA) is a fundamental computer vision task that
aims to predict the perceptual quality of a given video in alignment with human
judgments. Existing performant VQA models trained with direct score supervision
suffer from (1) poor generalization across diverse content and tasks, ranging
from user-generated content (UGC), short-form videos, to AI-generated content
(AIGC), (2) limited interpretability, and (3) lack of extensibility to novel
use cases or content types. We propose Q-Router, an agentic framework for
universal VQA with a multi-tier model routing system. Q-Router integrates a
diverse set of expert models and employs vision--language models (VLMs) as
real-time routers that dynamically reason and then ensemble the most
appropriate experts conditioned on the input video semantics. We build a
multi-tiered routing system based on the computing budget, with the heaviest
tier involving a specific spatiotemporal artifacts localization for
interpretability. This agentic design enables Q-Router to combine the
complementary strengths of specialized experts, achieving both flexibility and
robustness in delivering consistent performance across heterogeneous video
sources and tasks. Extensive experiments demonstrate that Q-Router matches or
surpasses state-of-the-art VQA models on a variety of benchmarks, while
substantially improving generalization and interpretability. Moreover, Q-Router
excels on the quality-based question answering benchmark, Q-Bench-Video,
highlighting its promise as a foundation for next-generation VQA systems.
Finally, we show that Q-Router capably localizes spatiotemporal artifacts,
showing potential as a reward function for post-training video generation
models.

</details>


### [20] [Alignment, Mining and Fusion: Representation Alignment with Hard Negative Mining and Selective Knowledge Fusion for Medical Visual Question Answering](https://arxiv.org/abs/2510.08791)
*Yuanhao Zou,Zhaozheng Yin*

Main category: cs.CV

TL;DR: 本文提出了一种创新框架，有效提升了医学视觉问答（Med-VQA）中的多模态对齐与难负样本处理，并在多个主流数据集上超过了现有最优方法。


<details>
  <summary>Details</summary>
Motivation: 现有的医学视觉问答方法虽取得进展，但还缺乏统一的多模态对齐解决方案，难负样本问题也未得到充分研究，且知识融合技术容易引入无关信息。为此，作者希望提出新的方法来解决这些挑战。

Method: 本文方法包括三个方面：（1）采用对比学习和最优传输理论，提出统一的多层次多模态对齐方法；（2）提出基于软标签的难负样本挖掘，有效区分困难负对；（3）设计门控交叉注意力模块，引入答案词表作为先验知识，筛选相关信息。

Result: 该方法在RAD-VQA、SLAKE、PathVQA和VQA-2019等主流医学视觉问答数据集上均显著优于此前的SOTA方法。

Conclusion: 作者的框架有效解决了Med-VQA中的多模态对齐与难负样本问题，同时整合了更有效的知识融合手段，为后续相关任务提供了新方向。

Abstract: Medical Visual Question Answering (Med-VQA) is a challenging task that
requires a deep understanding of both medical images and textual questions.
Although recent works leveraging Medical Vision-Language Pre-training (Med-VLP)
have shown strong performance on the Med-VQA task, there is still no unified
solution for modality alignment, and the issue of hard negatives remains
under-explored. Additionally, commonly used knowledge fusion techniques for
Med-VQA may introduce irrelevant information. In this work, we propose a
framework to address these challenges through three key contributions: (1) a
unified solution for heterogeneous modality alignments across multiple levels,
modalities, views, and stages, leveraging methods like contrastive learning and
optimal transport theory; (2) a hard negative mining method that employs soft
labels for multi-modality alignments and enforces the hard negative pair
discrimination; and (3) a Gated Cross-Attention Module for Med-VQA that
integrates the answer vocabulary as prior knowledge and selects relevant
information from it. Our framework outperforms the previous state-of-the-art on
widely used Med-VQA datasets like RAD-VQA, SLAKE, PathVQA and VQA-2019.

</details>


### [21] [SkipSR: Faster Super Resolution with Token Skipping](https://arxiv.org/abs/2510.08799)
*Rohan Choudhury,Shanchuan Lin,Jianyi Wang,Hao Chen,Qi Zhao,Feng Cheng,Lu Jiang,Kris Kitani,Laszlo A. Jeni*

Main category: cs.CV

TL;DR: 本文提出SkipSR框架，通过预先识别视频中低细节区域并跳过这些区域的超分辨处理，显著加速扩散模型在视频超分辨中的应用，同时不损失感知质量。


<details>
  <summary>Details</summary>
Motivation: 目前扩散式超分辨方法在视频生成和修复中效果突出，但运算慢、消耗大，难以扩展到高分辨率和长视频。作者注意到视频中很多区域其实细节很低，对超分辨提升贡献不大，却被统一处理，造成计算浪费。

Method: SkipSR框架首先从低分辨率输入中直接识别出低细节区域，对于这些区域完全跳过超分辨计算，仅对需要细化的部分进行超分辨处理。该策略可与标准扩散模型和单步扩散SR模型结合，无需对原视频全部像素均匀计算，大幅减轻计算压力。

Result: 在常用视频超分辨基准测试上，SkipSR方法在处理720p视频时端到端延迟最高可比以往方法快60%，且感知质量无明显下降。

Conclusion: SkipSR为扩散视频超分辨任务提供了一种高效方案，兼顾计算效率和视觉质量，具有良好的实际应用潜力。

Abstract: Diffusion-based super-resolution (SR) is a key component in video generation
and video restoration, but is slow and expensive, limiting scalability to
higher resolutions and longer videos. Our key insight is that many regions in
video are inherently low-detail and gain little from refinement, yet current
methods process all pixels uniformly. To take advantage of this, we propose
SkipSR, a simple framework for accelerating video SR by identifying low-detail
regions directly from low-resolution input, then skipping computation on them
entirely, only super-resolving the areas that require refinement. This simple
yet effective strategy preserves perceptual quality in both standard and
one-step diffusion SR models while significantly reducing computation. In
standard SR benchmarks, our method achieves up to 60% faster end-to-end latency
than prior models on 720p videos with no perceptible loss in quality. Video
demos are available at https://rccchoudhury.github.io/skipsr/

</details>


### [22] [D-CoDe: Scaling Image-Pretrained VLMs to Video via Dynamic Compression and Question Decomposition](https://arxiv.org/abs/2510.08818)
*Yiyang Huang,Yizhou Wang,Yun Fu*

Main category: cs.CV

TL;DR: 本文提出了一种名为D-CoDe的新颖训练免费适配框架，通过动态压缩和问题分解，有效扩展了图像预训练视觉-语言模型（VLMs）在视频领域的能力，显著提升了视频理解性能。


<details>
  <summary>Details</summary>
Motivation: 大多数视频大语言模型（Vid-LLMs）通过适配图像预训练的视觉-语言模型实现，但直接扩展存在密集和长时序输入的处理瓶颈，导致“感知瓶颈”和“token过载”，严重影响性能。因此，亟须方法解决这些障碍，促进更有效的视频理解。

Method: 提出D-CoDe框架，包括两大核心技术：（1）动态压缩：通过自适应选取有代表性的帧与内容感知的空间token聚合，有效减少冗余，缓解感知瓶颈。（2）问题分解：将原始复杂问题分解为若干子问题，引导模型分别聚焦不同视频部分，从而缓解token过载并提升理解效果。整个框架不需要额外训练。

Result: 在多种主流视频基准任务上，D-CoDe均取得了显著性能提升，尤其是在长视频理解任务中表现优异，展现了其处理复杂视频-语言任务的能力。

Conclusion: D-CoDe为无训练适配图像视觉-语言模型到视频领域提供了有效途径，能大幅提升多种视频理解任务的性能，特别适用于需要处理大量长视频数据的场景。

Abstract: Video large language models (Vid-LLMs), which excel in diverse video-language
tasks, can be effectively constructed by adapting image-pretrained
vision-language models (VLMs). However, this adaptation remains challenging, as
it requires processing dense and temporally extended visual inputs that exceed
the capacity of image-based models. This paper identifies the perception
bottleneck and token overload as key challenges in extending image-based VLMs
to the video domain. To address these issues, we propose D-CoDe, a
training-free adaptation framework that incorporates dynamic compression and
question decomposition. Specifically, dynamic compression alleviates the
perception bottleneck through adaptive selection of representative frames and
content-aware aggregation of spatial tokens, thereby reducing redundancy while
preserving informative content. In parallel, question decomposition mitigates
token overload by reformulating the original query into sub-questions, guiding
the model to focus on distinct aspects of the video and enabling more
comprehensive understanding. Experiments demonstrate that D-CoDe effectively
improves video understanding across various benchmarks. Furthermore, strong
performance on the challenging long-video benchmark highlights the potential of
D-CoDe in handling complex video-language tasks. Code is available at
https://github.com/hukcc/D-CoDe.

</details>


### [23] [FOLK: Fast Open-Vocabulary 3D Instance Segmentation via Label-guided Knowledge Distillation](https://arxiv.org/abs/2510.08849)
*Hongrui Wu,Zhicheng Gao,Jin Cao,Kelu Yao,Wen Shen,Zhihua Wei*

Main category: cs.CV

TL;DR: 提出FOLK方法，实现快速高效的开放词汇3D实例分割，通过知识蒸馏显著提升速度和精度。


<details>
  <summary>Details</summary>
Motivation: 传统基于2D映射和VLM的3D实例分割，存在遮挡引入噪声、推理速度慢和资源消耗高等问题。为提升推理效率并减少噪声，需创新方法。

Method: 设计教师-学生框架，教师模型基于2D CLIP嵌入为3D实例生成高质量表示，学生模型直接学习输出3D嵌入，通过标签引导的蒸馏方法将2D开放词汇知识有效迁移到3D模型，训练时对齐嵌入分布。

Result: 在ScanNet200和Replica数据集上实验，FOLK在ScanNet200上AP50达35.7，推理速度提升6.0到152.2倍，优于现有方法。

Conclusion: FOLK解决了传统方法中的主要弊端，实现开放词汇3D实例分割的效率与精度双提升，具有较强应用潜力。

Abstract: Open-vocabulary 3D instance segmentation seeks to segment and classify
instances beyond the annotated label space. Existing methods typically map 3D
instances to 2D RGB-D images, and then employ vision-language models (VLMs) for
classification. However, such a mapping strategy usually introduces noise from
2D occlusions and incurs substantial computational and memory costs during
inference, slowing down the inference speed. To address the above problems, we
propose a Fast Open-vocabulary 3D instance segmentation method via Label-guided
Knowledge distillation (FOLK). Our core idea is to design a teacher model that
extracts high-quality instance embeddings and distills its open-vocabulary
knowledge into a 3D student model. In this way, during inference, the distilled
3D model can directly classify instances from the 3D point cloud, avoiding
noise caused by occlusions and significantly accelerating the inference
process. Specifically, we first design a teacher model to generate a 2D CLIP
embedding for each 3D instance, incorporating both visibility and viewpoint
diversity, which serves as the learning target for distillation. We then
develop a 3D student model that directly produces a 3D embedding for each 3D
instance. During training, we propose a label-guided distillation algorithm to
distill open-vocabulary knowledge from label-consistent 2D embeddings into the
student model. FOLK conducted experiments on the ScanNet200 and Replica
datasets, achieving state-of-the-art performance on the ScanNet200 dataset with
an AP50 score of 35.7, while running approximately 6.0x to 152.2x faster than
previous methods. All codes will be released after the paper is accepted.

</details>


### [24] [Modeling Time-Lapse Trajectories to Characterize Cranberry Growth](https://arxiv.org/abs/2510.08901)
*Ronan John,Anis Chihoub,Ryan Meegan,Gina Sidelli,Jeffery Neyhart,Peter Oudemans,Kristin Dana*

Main category: cs.CV

TL;DR: 本文提出了一种基于自监督视觉Transformer（ViT）微调的作物生长变化监测方法，并发布了蔓越莓果实生长时序数据集。该方法能够减少人工注释，提高成长监测自动化和解释性。


<details>
  <summary>Details</summary>
Motivation: 传统蔓越莓生长监测主要依赖人工，耗时费力。尽管深度学习方法有自动化潜力，但通常需要手工标注且特征难以解释。因此，亟需一种无需繁琐注释、且可解释性强的自动监测方法。

Method: 采用自监督学习方法微调视觉Transformer（ViT），通过时间回归和类别预测双重预任务，学习反映作物生长变化的时序潜在空间，得到可解释的二维时间轨迹，实现生长预测和品种区分。

Result: 方法在全新采集并标注的蔓越莓八品种时序数据集上进行实验，数据包含52次生长记录及相关农艺信息。结果显示，该方法不仅实现了用于生长监测的时间序列建模，还能区分不同蔓越莓品种的生长时序差异。

Conclusion: 作者提出的自监督ViT方法，无需人工注释，能够高效、可解释地监测作物生长变化，具备推广到其他作物与农业领域的潜力，相关代码与数据集已开源。

Abstract: Change monitoring is an essential task for cranberry farming as it provides
both breeders and growers with the ability to analyze growth, predict yield,
and make treatment decisions. However, this task is often done manually,
requiring significant time on the part of a cranberry grower or breeder. Deep
learning based change monitoring holds promise, despite the caveat of
hard-to-interpret high dimensional features and hand-annotations for
fine-tuning. To address this gap, we introduce a method for modeling crop
growth based on fine-tuning vision transformers (ViTs) using a self-supervised
approach that avoids tedious image annotations. We use a two-fold pretext task
(time regression and class prediction) to learn a latent space for the
time-lapse evolution of plant and fruit appearance. The resulting 2D temporal
tracks provide an interpretable time-series model of crop growth that can be
used to: 1) predict growth over time and 2) distinguish temporal differences of
cranberry varieties. We also provide a novel time-lapse dataset of cranberry
fruit featuring eight distinct varieties, observed 52 times over the growing
season (span of around four months), annotated with information about fungicide
application, yield, and rot. Our approach is general and can be applied to
other crops and applications (code and dataset can be found at https://github.
com/ronan-39/tlt/).

</details>


### [25] [PHyCLIP: $\ell_1$-Product of Hyperbolic Factors Unifies Hierarchy and Compositionality in Vision-Language Representation Learning](https://arxiv.org/abs/2510.08919)
*Daiki Yoshikawa,Takashi Matsubara*

Main category: cs.CV

TL;DR: 本论文提出PHyCLIP模型，通过新的嵌入方式同时表达概念层级结构和跨概念组分解结构，提升视觉-语言多模态模型的表示能力，并在多项任务上取得优异结果。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言模型虽然在处理大规模视觉和语言配对数据上取得进展，但难以同时有效地表达概念内部层级关系与跨概念组的组分关系。已有方法利用双曲空间来建模层级，但难以表达组合型语义，存在表达瓶颈。

Method: 提出PHyCLIP模型，将双曲空间与ℓ_1-Product度量结合，使用多个双曲空间分别捕捉概念家族的层级结构，并利用ℓ_1-Product度量实现在不同概念间的组合。

Result: PHyCLIP在零样本分类、检索、层级分类和组分理解等任务上均优于以往的单空间方法，同时在嵌入空间中展现出更可解释的结构。

Conclusion: PHyCLIP在表达语义层级和组合关系方面兼具效率和解释性，为多模态任务提供了更强的支持，优于现有主流嵌入空间方法。

Abstract: Vision-language models have achieved remarkable success in multi-modal
representation learning from large-scale pairs of visual scenes and linguistic
descriptions. However, they still struggle to simultaneously express two
distinct types of semantic structures: the hierarchy within a concept family
(e.g., dog $\preceq$ mammal $\preceq$ animal) and the compositionality across
different concept families (e.g., "a dog in a car" $\preceq$ dog, car). Recent
works have addressed this challenge by employing hyperbolic space, which
efficiently captures tree-like hierarchy, yet its suitability for representing
compositionality remains unclear. To resolve this dilemma, we propose PHyCLIP,
which employs an $\ell_1$-Product metric on a Cartesian product of Hyperbolic
factors. With our design, intra-family hierarchies emerge within individual
hyperbolic factors, and cross-family composition is captured by the
$\ell_1$-product metric, analogous to a Boolean algebra. Experiments on
zero-shot classification, retrieval, hierarchical classification, and
compositional understanding tasks demonstrate that PHyCLIP outperforms existing
single-space approaches and offers more interpretable structures in the
embedding space.

</details>


### [26] [SegTrans: Transferable Adversarial Examples for Segmentation Models](https://arxiv.org/abs/2510.08922)
*Yufei Song,Ziqi Zhou,Qi Lu,Hangtao Zhang,Yifan Hu,Lulu Xue,Shengshan Hu,Minghui Li,Leo Yu Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为SegTrans的新型迁移攻击框架，能显著提高对分割模型的对抗样本迁移攻击成功率，并在提升效率的同时减少算力消耗。


<details>
  <summary>Details</summary>
Motivation: 语义分割模型对抗样本迁移性差，现有攻击方法在不同模型间转移攻击成功率低，主要受制于模型间复杂的上下文依赖和特征分布差异。

Method: SegTrans将输入样本划分为多个局部区域，并重映射其语义信息以生成多样性增强样本，用这些样本替换原始样本进行扰动优化，仅保留局部语义信息，从而提升对抗扰动的泛化性和迁移性。

Result: SegTrans在PASCAL VOC和Cityscapes两个数据集、四种分割模型及三种主干网络上显著提升了对抗迁移攻击成功率，平均提升8.55%，计算效率提升超过100%。

Conclusion: SegTrans能够在无需增加额外算力开销的情况下，有效提升分割模型间的对抗迁移攻击效果，优于现有最先进方法。

Abstract: Segmentation models exhibit significant vulnerability to adversarial examples
in white-box settings, but existing adversarial attack methods often show poor
transferability across different segmentation models. While some researchers
have explored transfer-based adversarial attack (i.e., transfer attack) methods
for segmentation models, the complex contextual dependencies within these
models and the feature distribution gaps between surrogate and target models
result in unsatisfactory transfer success rates. To address these issues, we
propose SegTrans, a novel transfer attack framework that divides the input
sample into multiple local regions and remaps their semantic information to
generate diverse enhanced samples. These enhanced samples replace the original
ones for perturbation optimization, thereby improving the transferability of
adversarial examples across different segmentation models. Unlike existing
methods, SegTrans only retains local semantic information from the original
input, rather than using global semantic information to optimize perturbations.
Extensive experiments on two benchmark datasets, PASCAL VOC and Cityscapes,
four different segmentation models, and three backbone networks show that
SegTrans significantly improves adversarial transfer success rates without
introducing additional computational overhead. Compared to the current
state-of-the-art methods, SegTrans achieves an average increase of 8.55% in
transfer attack success rate and improves computational efficiency by more than
100%.

</details>


### [27] [Defense against Unauthorized Distillation in Image Restoration via Feature Space Perturbation](https://arxiv.org/abs/2510.08925)
*Han Hu,Zhuoran Zheng,Chen Lyu*

Main category: cs.CV

TL;DR: 本文提出了一种针对图像恢复模型的知识蒸馏（KD）攻击防御方法——自适应奇异值扰动（ASVP），能够有效阻断学生模型的学习过程，同时几乎不影响教师模型的恢复质量。


<details>
  <summary>Details</summary>
Motivation: 已有针对分类任务的KD防御方法依赖于扰动输出概率，但由于图像恢复任务是高维连续生成型任务，这些方法直接应用效果有限。针对图像恢复模型知识产权泄露风险，亟需新的有效防御机制。

Method: 提出ASVP防御方法：在教师模型推理阶段，对其内部特征图进行奇异值分解（SVD），并放大前k个奇异值，从而注入结构化的高频扰动，扰乱了蒸馏需要依赖的特征对齐。

Result: ASVP在五个图像恢复任务（超分辨率、低光增强、水下增强、去雾、去雨）上显著降低了学生模型的PSNR（最高降4dB）和SSIM（降60-75%），而几乎不损害教师模型的输出质量。

Conclusion: ASVP是一种高效、实用且适用于多种图像恢复任务的KD防御方法，能够有效保护开源恢复模型免受未授权知识蒸馏攻击。

Abstract: Knowledge distillation (KD) attacks pose a significant threat to deep model
intellectual property by enabling adversaries to train student networks using a
teacher model's outputs. While recent defenses in image classification have
successfully disrupted KD by perturbing output probabilities, extending these
methods to image restoration is difficult. Unlike classification, restoration
is a generative task with continuous, high-dimensional outputs that depend on
spatial coherence and fine details. Minor perturbations are often insufficient,
as students can still learn the underlying mapping.To address this, we propose
Adaptive Singular Value Perturbation (ASVP), a runtime defense tailored for
image restoration models. ASVP operates on internal feature maps of the teacher
using singular value decomposition (SVD). It amplifies the topk singular values
to inject structured, high-frequency perturbations, disrupting the alignment
needed for distillation. This hinders student learning while preserving the
teacher's output quality.We evaluate ASVP across five image restoration tasks:
super-resolution, low-light enhancement, underwater enhancement, dehazing, and
deraining. Experiments show ASVP reduces student PSNR by up to 4 dB and SSIM by
60-75%, with negligible impact on the teacher's performance. Compared to prior
methods, ASVP offers a stronger and more consistent defense.Our approach
provides a practical solution to protect open-source restoration models from
unauthorized knowledge distillation.

</details>


### [28] [RO-Bench: Large-scale robustness evaluation of MLLMs with text-driven counterfactual videos](https://arxiv.org/abs/2510.08936)
*Zixi Yang,Jiapeng Li,Muxi Diao,Yinuo Jing,Kongming Liang*

Main category: cs.CV

TL;DR: 本文提出了Ro-Bench，这是首个用于评测多模态大语言模型(MLLMs)在处理动态分布外反事实视频数据时鲁棒性的基准测试。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLMs在多种视频理解任务上取得了显著进展，但其面对经过操控或编辑的视频内容时的鲁棒性尚未被充分研究，因此需要针对这方面进行系统评估。

Method: 作者构建了Ro-Bench基准，将高质量、多样化且具有时间相关性的视频通过风格、对象、背景及其组合方式进行编辑，生成反事实视频数据，并用此评测了八个最新的视频MLLMs，随后还进行了反事实数据微调实验。

Result: 结果显示，当前模型在Ro-Bench上的表现因反事实内容显著下降。但通过在反事实数据上微调，模型鲁棒性得到明显提升：Ro-Bench上提升了21.73%，在MVBench 20项任务上提升了12.78%。

Conclusion: 反事实数据对提升MLLMs视频理解鲁棒性效果显著。Ro-Bench为模型鲁棒性评估和改进提供了重要工具，未来代码和数据也将公开。

Abstract: Recently, Multi-modal Large Language Models (MLLMs) have demonstrated
significant performance across various video understanding tasks. However,
their robustness, particularly when faced with manipulated video content,
remains largely unexplored. In this paper, we introduce Ro-Bench, the first
benchmark for evaluating MLLMs on dynamic out-of-distribution (OOD)
counterfactual video test sets. Ro-Bench incorporates high-quality, diverse and
temporally relevant video data, by editing Style, Object, Background and their
compositions. We evaluated eight recent video MLLMs and found that current
models exhibit substantial performance degradation on Ro-Bench when exposed to
counterfactual video content. Furthermore, we demonstrate that fine-tuning
MLLMs with counterfactual data enhances robustness, achieving a 21.73%
performance increase on Ro-Bench and a 12.78% improvement across 20 tasks in
the MVBench dataset. These findings underscore the effectiveness of
counterfactual data in enhancing the video understanding ability of MLLMs. The
code and data will be released shortly.

</details>


### [29] [Denoised Diffusion for Object-Focused Image Augmentation](https://arxiv.org/abs/2510.08955)
*Nisha Pillai,Aditi Virupakshaiah,Harrison W. Smith,Amanda J. Ashworth,Prasanna Gowda,Phillip R. Owens,Adam R. Rivers,Bindu Nanduri,Mahalingam Ramkumar*

Main category: cs.CV

TL;DR: 本文提出了一种面向动物健康监测的物体聚焦型数据增强框架，用于解决数据稀缺场景下动物检测的难题。通过从背景中分割动物并进行相关增强和合成，有效提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有农场动物健康监测主要依赖无人机影像，但由于动物体型小、遮挡严重等问题，且缺乏针对具体场景的大型数据集，主流迁移学习方法难以奏效，因此亟需专门的数据增强策略以提升监测效果。

Method: 设计了一套动物聚焦的数据增强框架：首先将动物从原始图像中分割出来，然后对其进行变换和基于扩散模型的合成，再将其融合到多样化背景中，从而构建多样且真实的增强数据集。

Result: 通过初步实验，作者的增强数据集在动物检测任务上比原有基线模型表现更优，有效提升了检测性能。

Conclusion: 所提方法在数据有限情况下，为动物健康监控创造了更具实际适用性的数据，填补了传统数据增强不足以应对农场实际复杂场景的空白，为实时动物健康监测提供了有效支持。

Abstract: Modern agricultural operations increasingly rely on integrated monitoring
systems that combine multiple data sources for farm optimization. Aerial
drone-based animal health monitoring serves as a key component but faces
limited data availability, compounded by scene-specific issues such as small,
occluded, or partially visible animals. Transfer learning approaches often fail
to address this limitation due to the unavailability of large datasets that
reflect specific farm conditions, including variations in animal breeds,
environments, and behaviors. Therefore, there is a need for developing a
problem-specific, animal-focused data augmentation strategy tailored to these
unique challenges. To address this gap, we propose an object-focused data
augmentation framework designed explicitly for animal health monitoring in
constrained data settings. Our approach segments animals from backgrounds and
augments them through transformations and diffusion-based synthesis to create
realistic, diverse scenes that enhance animal detection and monitoring
performance. Our initial experiments demonstrate that our augmented dataset
yields superior performance compared to our baseline models on the animal
detection task. By generating domain-specific data, our method empowers
real-time animal health monitoring solutions even in data-scarce scenarios,
bridging the gap between limited data and practical applicability.

</details>


### [30] [Unleashing Perception-Time Scaling to Multimodal Reasoning Models](https://arxiv.org/abs/2510.08964)
*Yifan Li,Zhenghao Chen,Ziheng Wu,Kun Zhou,Ruipu Luo,Can Zhang,Zhentao He,Yufei Zhan,Wayne Xin Zhao,Minghui Qiu*

Main category: cs.CV

TL;DR: 本文提出了DisTANCE，专注于视觉估计任务的基准，发现大规模视-语言模型（LVLMs）在视觉感知精度上表现有限，推断时扩展带来收益甚微。针对这一问题，作者提出感知时扩展（Perception-Time Scaling, PTS）新范式，显著提升了LVLM感知能力。


<details>
  <summary>Details</summary>
Motivation: 尽管推断时扩展和基于可验证奖励的强化学习能提升LVLM在推理类任务中的能力，但其对多模态‘感知’的有效性尚不明确。为弥补这一研究空白，作者关注视觉估计领域，检测并提升LVLM的感知精度。

Method: 作者提出DisTANCE基准用于评估视觉估计能力，对比现有推断时扩展方法，并引入感知时扩展（PTS）新方法。PTS鼓励生成更多与视觉细节相关的token，将复杂视觉问题分解为更易处理的子问题，并结合强化学习技术进行训练。

Result: 实验表明，现有LVLM在DisTANCE上的高精度表现仅8.0%，而PTS提升至64.7%，且提升能泛化到域外任务。PTS引入的数据为纯合成，但结合数学推理数据使用，表现提升同样显著。进一步分析显示，PTS促使模型生成更多感知相关token并提升其对图像token的关注度。

Conclusion: 作者提出的PTS方法显著增强了LVLM的感知精度，实现了以感知为中心的能力提升，不仅提升了基准测试上的表现，还能泛化至实际应用场景。PTS与推理类数据结合时表现更佳，展现了其方法的极大潜力。相关代码和数据将公开发布。

Abstract: Recent advances in inference-time scaling, particularly those leveraging
reinforcement learning with verifiable rewards, have substantially enhanced the
reasoning capabilities of Large Vision-Language Models (LVLMs). Inspired by
this success, similar strategies have been applied to multimodal reasoning, yet
their impact on visual perception remains unclear. To investigate this gap, we
introduce DisTANCE, a perception-centric benchmark for visual estimation tasks.
Evaluation results show that LVLMs exhibit limited estimation precision, and
inference-time scaling offers only marginal gains. We attribute this to the
fast perception paradigm of current LVLMs, where visual understanding is
treated as a one-shot output without modeling the underlying perceptual
process. To address this, we propose Perception-Time Scaling (PTS), a novel
paradigm that encourages token-rich perception and decomposes complex
perception problems into intermediate tractable sub-problems, thereby enabling
perception to align with and benefit from inference-time scaling. Combined with
reinforcement learning techniques, PTS significantly improves perception
accuracy, raising high-precision performance on DisTANCE from 8.0% to 64.7%,
and generalizes well to out-of-domain tasks. Surprisingly, even though PTS data
are purely synthetic, combining them with math reasoning data yields consistent
gains in both reasoning and real-world perception benchmarks. Further analysis
reveals that PTS introduces more perception-related tokens and increases the
model's attention to image tokens. Our code and data will be publicly released.

</details>


### [31] [mmJoints: Expanding Joint Representations Beyond (x,y,z) in mmWave-Based 3D Pose Estimation](https://arxiv.org/abs/2510.08970)
*Zhenyu Wang,Mahathir Monjur,Shahriar Nirjon*

Main category: cs.CV

TL;DR: 本文提出了mmJoints框架，通过增加联合描述符提升mmWave 3D姿态估计的可解释性和下游任务表现。该方法对现有黑盒模型的输出进行增强并显式估计关节可感知性及置信度。实验结果显示，关节位置和动作识别准确率显著提升。


<details>
  <summary>Details</summary>
Motivation: mmWave姿态估计由于信号稀疏和反射弱，模型更依赖统计先验而非真实传感器数据，导致动作识别等下游任务性能下降。因此需要更好利用传感器输出而非过度依赖先验。

Method: 提出mmJoints框架，不修改原有黑盒3D mmWave姿态估计算法，而是通过额外的描述符，显式估计每个关节的被感知概率和预测定位的可靠性，增强其解释性并帮助下游任务。

Result: 在13种姿态估计场景中，超过11.5万帧信号实验显示，mmJoints对描述符估计错误率低于4.2%；关节位置精度提升最高达12.5%；动作识别性能相比SOTA方法提升最高16%。

Conclusion: mmJoints框架能够提升mmWave姿态估计可信度和下游动作识别表现，为此类任务提供增强型解释性与实用性。

Abstract: In mmWave-based pose estimation, sparse signals and weak reflections often
cause models to infer body joints from statistical priors rather than sensor
data. While prior knowledge helps in learning meaningful representations,
over-reliance on it degrades performance in downstream tasks like gesture and
activity recognition. In this paper, we introduce mmJoints, a framework that
augments a pre-trained, black-box mmWave-based 3D pose estimator's output with
additional joint descriptors. Rather than mitigating bias, mmJoints makes it
explicit by estimating the likelihood of a joint being sensed and the
reliability of its predicted location. These descriptors enhance
interpretability and improve downstream task accuracy. Through extensive
evaluations using over 115,000 signal frames across 13 pose estimation
settings, we show that mmJoints estimates descriptors with an error rate below
4.2%. mmJoints also improves joint position accuracy by up to 12.5% and boosts
activity recognition by up to 16% over state-of-the-art methods.

</details>


### [32] [Hierarchical Scheduling for Multi-Vector Image Retrieval](https://arxiv.org/abs/2510.08976)
*Maoliang Li,Ke Li,Yaoyang Liu,Jiayu Chen,Zihao Zheng,Yinjun Wu,Xiang Chen*

Main category: cs.CV

TL;DR: 该论文提出了一种高效的图像检索调度框架HiMIR，能够提升多模态大语言模型应用中的图像检索准确率，并显著降低计算量。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型常用检索增强生成（RAG）方法来利用用户数据，但传统检索方法检准率有限，现有多向量检索（MVR）虽有提升，但在查询与图像对象对齐和计算效率上仍存在不足。

Method: 提出HiMIR框架：一是采用分层检索策略，对不同粒度图像对象进行中间分层，提升检索与查询对齐；二是利用分层间相似性一致性和稀疏性，减少不必要的比对，减轻冗余；三是自动配置参数以适应不同数据集。

Result: 实验证明，HiMIR在各类数据集上显著提升图像检索准确性，同时相比现有MVR系统计算量减少最高达3.5倍。

Conclusion: HiMIR框架兼顾了检索准确率和计算效率，适用于多种实际多模态应用场景，推动了检索增强生成技术的发展。

Abstract: To effectively leverage user-specific data, retrieval augmented generation
(RAG) is employed in multimodal large language model (MLLM) applications.
However, conventional retrieval approaches often suffer from limited retrieval
accuracy. Recent advances in multi-vector retrieval (MVR) improve accuracy by
decomposing queries and matching against segmented images. They still suffer
from sub-optimal accuracy and efficiency, overlooking alignment between the
query and varying image objects and redundant fine-grained image segments. In
this work, we present an efficient scheduling framework for image retrieval -
HiMIR. First, we introduce a novel hierarchical paradigm, employing multiple
intermediate granularities for varying image objects to enhance alignment.
Second, we minimize redundancy in retrieval by leveraging cross-hierarchy
similarity consistency and hierarchy sparsity to minimize unnecessary matching
computation. Furthermore, we configure parameters for each dataset
automatically for practicality across diverse scenarios. Our empirical study
shows that, HiMIR not only achieves substantial accuracy improvements but also
reduces computation by up to 3.5 times over the existing MVR system.

</details>


### [33] [HandEval: Taking the First Step Towards Hand Quality Evaluation in Generated Images](https://arxiv.org/abs/2510.08978)
*Zichuan Wang,Bo Peng,Songlin Yang,Zhenchen Tang,Jing Dong*

Main category: cs.CV

TL;DR: 该论文提出了一个专注于生成式图像中手部区域质量评估的新任务，并开发了相应的数据集与评估模型，显著提升了下游任务表现。


<details>
  <summary>Details</summary>
Motivation: 尽管当前T2I（文本到图像）模型在视觉质量上取得了重大进展，但在复杂局部区域、特别是人手细节的生成上仍存在显著缺陷。以往手部生成质量的评估被忽视，影响了如人像生成质量优化和AIGC检测等下游任务。

Method: 作者提出了针对生成手部区域的质量评估任务，并发布HandPair数据集（由48k对高、低质量手部图像组成，无需人工标注），用于训练手部质量评估模型。基于此，设计了HandEval模型，结合多模态大模型的视觉理解能力与手部关键点先验知识，提升了模型对手部质量的感知能力。作者还建立了真人标注的测试集，验证模型有效性。

Result: 实验结果表明，HandEval在手部图像质量评估上比现有SOTA方法更符合人类判断标准。将HandEval用于图像生成和AIGC检测流程后，分别显著增强了生成手部的真实感和检测准确率。

Conclusion: HandEval及其配套数据集不仅有效提升了生成手部质量的评估能力，还极大增强了T2I和AIGC检测等多项下游任务的表现，具备通用性和实用性。

Abstract: Although recent text-to-image (T2I) models have significantly improved the
overall visual quality of generated images, they still struggle in the
generation of accurate details in complex local regions, especially human
hands. Generated hands often exhibit structural distortions and unrealistic
textures, which can be very noticeable even when the rest of the body is
well-generated. However, the quality assessment of hand regions remains largely
neglected, limiting downstream task performance like human-centric generation
quality optimization and AIGC detection. To address this, we propose the first
quality assessment task targeting generated hand regions and showcase its
abundant downstream applications. We first introduce the HandPair dataset for
training hand quality assessment models. It consists of 48k images formed by
high- and low-quality hand pairs, enabling low-cost, efficient supervision
without manual annotation. Based on it, we develop HandEval, a carefully
designed hand-specific quality assessment model. It leverages the powerful
visual understanding capability of Multimodal Large Language Model (MLLM) and
incorporates prior knowledge of hand keypoints, gaining strong perception of
hand quality. We further construct a human-annotated test set with hand images
from various state-of-the-art (SOTA) T2I models to validate its quality
evaluation capability. Results show that HandEval aligns better with human
judgments than existing SOTA methods. Furthermore, we integrate HandEval into
image generation and AIGC detection pipelines, prominently enhancing generated
hand realism and detection accuracy, respectively, confirming its universal
effectiveness in downstream applications. Code and dataset will be available.

</details>


### [34] [Uncolorable Examples: Preventing Unauthorized AI Colorization via Perception-Aware Chroma-Restrictive Perturbation](https://arxiv.org/abs/2510.08979)
*Yuki Nii,Futa Waseda,Ching-Chun Chang,Isao Echizen*

Main category: cs.CV

TL;DR: 本文提出了一种通过在灰度图像中嵌入不可察觉扰动，以防止AI自动上色滥用的新方法。


<details>
  <summary>Details</summary>
Motivation: AI自动上色技术虽然强大，但可能被用于未经授权地处理和售卖单色的漫画、电影等，存在版权风险。目前尚无有效方式阻止这种滥用，因此需要一种防护机制。

Method: 提出一种名为PAChroma（感知感知色彩限制扰动）的方法，通过拉普拉斯滤波器优化的不可察觉扰动嵌入到灰度图像中，以阻止AI上色。该方法兼顾效果、不可察觉性、可迁移性和鲁棒性，并在优化过程中对输入施加多种变换以提升跨模型和抗后处理能力。

Result: 在ImageNet和Danbooru数据集上的实验表明，PAChroma能够明显降低AI上色效果，但肉眼几乎无法察觉原始灰度图的变化。

Conclusion: PAChroma是首个针对防止AI上色滥用的保护措施，为实现生成内容的版权保护提供了新思路，推动了版权感知的防御机制发展。

Abstract: AI-based colorization has shown remarkable capability in generating realistic
color images from grayscale inputs. However, it poses risks of copyright
infringement -- for example, the unauthorized colorization and resale of
monochrome manga and films. Despite these concerns, no effective method
currently exists to prevent such misuse. To address this, we introduce the
first defensive paradigm, Uncolorable Examples, which embed imperceptible
perturbations into grayscale images to invalidate unauthorized colorization. To
ensure real-world applicability, we establish four criteria: effectiveness,
imperceptibility, transferability, and robustness. Our method, Perception-Aware
Chroma-Restrictive Perturbation (PAChroma), generates Uncolorable Examples that
meet these four criteria by optimizing imperceptible perturbations with a
Laplacian filter to preserve perceptual quality, and applying diverse input
transformations during optimization to enhance transferability across models
and robustness against common post-processing (e.g., compression). Experiments
on ImageNet and Danbooru datasets demonstrate that PAChroma effectively
degrades colorization quality while maintaining the visual appearance. This
work marks the first step toward protecting visual content from illegitimate AI
colorization, paving the way for copyright-aware defenses in generative media.

</details>


### [35] [Speculative Jacobi-Denoising Decoding for Accelerating Autoregressive Text-to-image Generation](https://arxiv.org/abs/2510.08994)
*Yao Teng,Fuyun Wang,Xian Liu,Zhekai Chen,Han Shi,Yu Wang,Zhenguo Li,Weiyang Liu,Difan Zou,Xihui Liu*

Main category: cs.CV

TL;DR: 本文提出了一种新的并行生成方法（SJD2），能加速自回归文本到图像模型的推理过程，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 当前自回归文本到图像模型在生成图片时需逐个token解码，推理速度慢，需要大量模型前向计算，限制了实际应用。

Method: 提出Speculative Jacobi-Denoising Decoding（SJD2）框架，将去噪过程与Jacobi迭代结合，实现自回归模型中token的并行生成。通过少量微调，让模型能接受带噪音的token embedding，并预测下一个clean的token。推理时以高斯噪声初始化序列，多次并行预测，结合概率准则并行接受token，并对未被接受的token进一步去噪。

Result: 实验证明该方法能大幅减少模型前向推理次数，加速图片生成，同时保持生成图像的视觉质量。

Conclusion: SJD2显著提升了自回归文本到图像模型的生成效率，为高效视觉内容生成提供了新方案。

Abstract: As a new paradigm of visual content generation, autoregressive text-to-image
models suffer from slow inference due to their sequential token-by-token
decoding process, often requiring thousands of model forward passes to generate
a single image. To address this inefficiency, we propose Speculative
Jacobi-Denoising Decoding (SJD2), a framework that incorporates the denoising
process into Jacobi iterations to enable parallel token generation in
autoregressive models. Our method introduces a next-clean-token prediction
paradigm that enables the pre-trained autoregressive models to accept
noise-perturbed token embeddings and predict the next clean tokens through
low-cost fine-tuning. This denoising paradigm guides the model towards more
stable Jacobi trajectories. During inference, our method initializes token
sequences with Gaussian noise and performs iterative
next-clean-token-prediction in the embedding space. We employ a probabilistic
criterion to verify and accept multiple tokens in parallel, and refine the
unaccepted tokens for the next iteration with the denoising trajectory.
Experiments show that our method can accelerate generation by reducing model
forward passes while maintaining the visual quality of generated images.

</details>


### [36] [Hamba: Single-view 3D Hand Reconstruction with Graph-guided Bi-Scanning Mamba](https://arxiv.org/abs/2407.09646)
*Haoye Dong,Aviral Chharia,Wenbo Gou,Francisco Vicente Carrasco,Fernando De la Torre*

Main category: cs.CV

TL;DR: 本文提出了一种新的3D手部重建方法Hamba，结合了图学习与状态空间建模，有效提升了单张RGB图像下的手部重建精度和效率，超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于注意力机制的transformer方法在空间结构建模效率较低，导致3D手部重建在精度和鲁棒性上依然存在较大提升空间。为此，作者旨在提出一种能够高效建模关节空间关系的新框架。

Method: 作者提出了一种名为Hamba的图引导Mamba框架，将Mamba的扫描操作重新设计为图引导的双向扫描，仅用少量有效token学习手部关节的空间结构。具体包括设计了Graph-guided State Space（GSS）模块，极大减少token数量，并通过特征融合模块结合局部与全局特征增强表现。

Result: 实验显示，Hamba在FreiHAND等多个基准测试及真实场景中均取得SOTA表现，如PA-MPVPE达到5.3mm，F@15mm达0.992，在3D手部重建相关比赛中排名第一。

Conclusion: Hamba方法通过高效的空间关系建模，有效提升了3D手部重建的准确性和效率，是当前该方向的最佳方案之一。

Abstract: 3D Hand reconstruction from a single RGB image is challenging due to the
articulated motion, self-occlusion, and interaction with objects. Existing SOTA
methods employ attention-based transformers to learn the 3D hand pose and
shape, yet they do not fully achieve robust and accurate performance, primarily
due to inefficiently modeling spatial relations between joints. To address this
problem, we propose a novel graph-guided Mamba framework, named Hamba, which
bridges graph learning and state space modeling. Our core idea is to
reformulate Mamba's scanning into graph-guided bidirectional scanning for 3D
reconstruction using a few effective tokens. This enables us to efficiently
learn the spatial relationships between joints for improving reconstruction
performance. Specifically, we design a Graph-guided State Space (GSS) block
that learns the graph-structured relations and spatial sequences of joints and
uses 88.5% fewer tokens than attention-based methods. Additionally, we
integrate the state space features and the global features using a fusion
module. By utilizing the GSS block and the fusion module, Hamba effectively
leverages the graph-guided state space features and jointly considers global
and local features to improve performance. Experiments on several benchmarks
and in-the-wild tests demonstrate that Hamba significantly outperforms existing
SOTAs, achieving the PA-MPVPE of 5.3mm and F@15mm of 0.992 on FreiHAND. At the
time of this paper's acceptance, Hamba holds the top position, Rank 1 in two
Competition Leaderboards on 3D hand reconstruction. Project Website:
https://humansensinglab.github.io/Hamba/

</details>


### [37] [On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large Vision-Language Models](https://arxiv.org/abs/2510.09008)
*Hoigi Seo,Dong Un Kang,Hyunjin Cho,Joohoon Lee,Se Young Chun*

Main category: cs.CV

TL;DR: 本文提出了一种通过识别并抑制视觉编码器（VE）中不确定的视觉token来减少大型视觉-语言模型（LVLMs）物体幻觉的方法。该方法仅需修改视觉编码器，显著降低了模型生成图像中不存在物体描述的现象。


<details>
  <summary>Details</summary>
Motivation: 当前LVLMs在实际应用中常出现物体幻觉问题，即生成关于输入图片中不存在的物体描述。这一问题严重影响了模型的实际可靠性。作者认为导致该现象的关键在于VE中高不确定性的视觉token。

Method: 作者首先通过统计分析证明VE中高不确定性视觉token与幻觉现象强相关。理论与实验进一步表明，在VE早期层中对小扰动高度敏感的token具有较高不确定性。据此，作者提出：1）利用对抗扰动高效识别不确定token，2）在VE中间层的自注意力中屏蔽这些token，减小其对视觉编码的影响，从而缓解幻觉。

Result: 通过大量实验，作者验证了所提出方法显著减少了LVLMs中的物体幻觉现象，同时该法可与其它已有技术协同增强效果。

Conclusion: 修改和抑制视觉编码器内不确定视觉token的影响，是缓解LVLMs物体幻觉的有效手段，为后续提升多模态模型真实性和可靠性提供了新路径。

Abstract: Large vision-language models (LVLMs), which integrate a vision encoder (VE)
with a large language model, have achieved remarkable success across various
tasks. However, there are still crucial challenges in LVLMs such as object
hallucination, generating descriptions of objects that are not in the input
image. Here, we argue that uncertain visual tokens within the VE is a key
factor that contributes to object hallucination. Our statistical analysis found
that there are positive correlations between visual tokens with high epistemic
uncertainty and the occurrence of hallucinations. Furthermore, we show
theoretically and empirically that visual tokens in early VE layers that
exhibit large representation deviations under small adversarial perturbations
indicate high epistemic uncertainty. Based on these findings, we propose a
simple yet effective strategy to mitigate object hallucination by modifying the
VE only. Our method comprises a proxy method with adversarial perturbations for
identifying uncertain visual tokens efficiently and a method to mask these
uncertain visual tokens during the self-attention process in the middle layers
of the VE, suppressing their influence on visual encoding and thus alleviating
hallucinations. Extensive experiments show that our method significantly
reduces object hallucinations in LVLMs and can synergistically work with other
prior arts.

</details>


### [38] [Towards Better & Faster Autoregressive Image Generation: From the Perspective of Entropy](https://arxiv.org/abs/2510.09012)
*Xiaoxiao Ma,Feng Zhao,Pengyang Ling,Haibo Qiu,Zhixiang Wei,Hu Yu,Jie Huang,Zhixiong Zeng,Lin Ma*

Main category: cs.CV

TL;DR: 论文重新审视了当前自回归（AR）图像生成模型的采样问题，提出了一种基于熵信息的解码策略，提高了生成质量并加快了采样速度。


<details>
  <summary>Details</summary>
Motivation: 现有自回归图像生成模型在采样阶段存在信息密度低、空间分布不均等问题，直接借用文本生成中的方法效果不佳，因此需要针对图像的特点设计更优的采样方案。

Method: 提出了熵感知解码策略，包含两个创新点：（1）基于空间熵的动态温度调控，提升内容多样性、准确性和结构一致性；（2）在推测解码中加入熵感知的接受规则，实现更高效且接近无损的生成。整个方法几乎无额外计算开销。

Result: 大规模实验显示，该方法在多个自回归图像生成模型和基准上，显著提升了生成质量和采样速度，达到传统加速方法85%的推理成本下近乎无损的生成表现。

Conclusion: 本文提出的熵感知解码策略能够有效提升自回归图像生成模型的采样质量和速度，具有良好的通用性和应用潜力。

Abstract: In this work, we first revisit the sampling issues in current autoregressive
(AR) image generation models and identify that image tokens, unlike text
tokens, exhibit lower information density and non-uniform spatial distribution.
Accordingly, we present an entropy-informed decoding strategy that facilitates
higher autoregressive generation quality with faster synthesis speed.
Specifically, the proposed method introduces two main innovations: 1) dynamic
temperature control guided by spatial entropy of token distributions, enhancing
the balance between content diversity, alignment accuracy, and structural
coherence in both mask-based and scale-wise models, without extra computational
overhead, and 2) entropy-aware acceptance rules in speculative decoding,
achieving near-lossless generation at about 85\% of the inference cost of
conventional acceleration methods. Extensive experiments across multiple
benchmarks using diverse AR image generation models demonstrate the
effectiveness and generalizability of our approach in enhancing both generation
quality and sampling speed.

</details>


### [39] [Exploring Single Domain Generalization of LiDAR-based Semantic Segmentation under Imperfect Labels](https://arxiv.org/abs/2510.09035)
*Weitong Kong,Zichao Zeng,Di Wen,Jiale Wei,Kunyu Peng,June Moh Goo,Jan Boehm,Rainer Stiefelhagen*

Main category: cs.CV

TL;DR: 本文关注于自动驾驶中激光雷达（LiDAR）3D语义分割任务下的噪声标签及域泛化问题，提出并验证了一种双分支一致性框架，显著提升了跨域和噪声鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶对环境感知精度要求极高，激光雷达是核心传感器。然而，不同场景、设备和天气条件下，如果重新标注数据成本高且实际标注经常带有噪声，直接影响分割精度和系统安全。因此，需要研究在标签存在噪声、且不同域间具有分布差异情况下的鲁棒三维分割方法。

Method: 本文提出了DGLSS-NL这一新任务，并首次建立基准，将三种典型噪声标签学习方法从2D图像迁移至3D点云分割。在观察现有方法适应性差后，作者提出了DuNe：一个具有强、弱分支的双视角特征一致性方法，并结合基于置信度的交叉熵损失筛选预测，提高对噪声标注和域泛化的鲁棒性。

Result: DuNe方法在三个公开数据集（SemanticKITTI, nuScenes, SemanticPOSS）和10%对称噪声标签下分别达到了56.86%、42.28%、52.58%的mIoU，AM为49.57%，HM为48.50%，显著优于现有方法。

Conclusion: 本文提出的DuNe框架有效提升了带噪声情况下的激光雷达语义分割的跨域泛化能力，并为相关研究提供了基准和可复现代码，对实际自动驾驶系统具重要指导意义。

Abstract: Accurate perception is critical for vehicle safety, with LiDAR as a key
enabler in autonomous driving. To ensure robust performance across
environments, sensor types, and weather conditions without costly
re-annotation, domain generalization in LiDAR-based 3D semantic segmentation is
essential. However, LiDAR annotations are often noisy due to sensor
imperfections, occlusions, and human errors. Such noise degrades segmentation
accuracy and is further amplified under domain shifts, threatening system
reliability. While noisy-label learning is well-studied in images, its
extension to 3D LiDAR segmentation under domain generalization remains largely
unexplored, as the sparse and irregular structure of point clouds limits direct
use of 2D methods. To address this gap, we introduce the novel task Domain
Generalization for LiDAR Semantic Segmentation under Noisy Labels (DGLSS-NL)
and establish the first benchmark by adapting three representative noisy-label
learning strategies from image classification to 3D segmentation. However, we
find that existing noisy-label learning approaches adapt poorly to LiDAR data.
We therefore propose DuNe, a dual-view framework with strong and weak branches
that enforce feature-level consistency and apply cross-entropy loss based on
confidence-aware filtering of predictions. Our approach shows state-of-the-art
performance by achieving 56.86% mIoU on SemanticKITTI, 42.28% on nuScenes, and
52.58% on SemanticPOSS under 10% symmetric label noise, with an overall
Arithmetic Mean (AM) of 49.57% and Harmonic Mean (HM) of 48.50%, thereby
demonstrating robust domain generalization in DGLSS-NL tasks. The code is
available on our project page.

</details>


### [40] [Lesion-Aware Post-Training of Latent Diffusion Models for Synthesizing Diffusion MRI from CT Perfusion](https://arxiv.org/abs/2510.09056)
*Junhyeok Lee,Hyunwoong Kim,Hyungjin Chung,Heeseong Eom,Joon Jang,Chul-Ho Sohn,Kyu Sung Choi*

Main category: cs.CV

TL;DR: 本文提出了一种新的后训练框架，提升了潜在扩散模型（LDMs）在医学图像（特别是病灶区）翻译任务中的像素级细节复原能力，显著改善了脑卒中患者CT到MRI的图像合成质量和病灶勾画效果。


<details>
  <summary>Details</summary>
Motivation: 尽管LDMs在生成医学图像任务中高效且表现突出，但其在压缩潜在空间学习时牺牲了像素级细节，尤其影响到病灶（如中风病灶）等关键小区域的精确还原，这对临床诊断和决策很重要。

Method: 作者提出在LDM的后训练阶段引入“对病灶敏感”的像素空间目标函数，即针对病灶区域提升生成精度，从而增强模型对关键结构的复原。该框架可无缝适配已有LDM，不需重新训练主模型。

Result: 在一个包含817名急性缺血性脑卒中患者的CT到MRI（DWI/ADC）翻译任务上，所提方法在整体图像质量和病灶勾画精度上均优于当前主流的图像翻译模型。

Conclusion: 引入病灶敏感目标的LDM后训练框架，显著提升了医学图像合成的临床可用性，且易于迁移到其他医学图像任务，有望广泛应用于医学图像的生成与翻译领域。

Abstract: Image-to-Image translation models can help mitigate various challenges
inherent to medical image acquisition. Latent diffusion models (LDMs) leverage
efficient learning in compressed latent space and constitute the core of
state-of-the-art generative image models. However, this efficiency comes with a
trade-off, potentially compromising crucial pixel-level detail essential for
high-fidelity medical images. This limitation becomes particularly critical
when generating clinically significant structures, such as lesions, which often
occupy only a small portion of the image. Failure to accurately reconstruct
these regions can severely impact diagnostic reliability and clinical
decision-making. To overcome this limitation, we propose a novel post-training
framework for LDMs in medical image-to-image translation by incorporating
lesion-aware medical pixel space objectives. This approach is essential, as it
not only enhances overall image quality but also improves the precision of
lesion delineation. We evaluate our framework on brain CT-to-MRI translation in
acute ischemic stroke patients, where early and accurate diagnosis is critical
for optimal treatment selection and improved patient outcomes. While diffusion
MRI is the gold standard for stroke diagnosis, its clinical utility is often
constrained by high costs and low accessibility. Using a dataset of 817
patients, we demonstrate that our framework improves overall image quality and
enhances lesion delineation when synthesizing DWI and ADC images from CT
perfusion scans, outperforming existing image-to-image translation models.
Furthermore, our post-training strategy is easily adaptable to pre-trained LDMs
and exhibits substantial potential for broader applications across diverse
medical image translation tasks.

</details>


### [41] [Visual Anomaly Detection for Reliable Robotic Implantation of Flexible Microelectrode Array](https://arxiv.org/abs/2510.09071)
*Yitong Chen,Xinyao Xu,Ping Zhu,Xinyong Han,Fangbo Qin,Shan Yu*

Main category: cs.CV

TL;DR: 本文提出了一种基于显微摄像头的图像异常检测框架，用于机器人柔性微电极（FME）植入脑皮层过程中的安全监控，通过预训练ViT和新颖的特征采样方法提升了异常检测的准确性。


<details>
  <summary>Details</summary>
Motivation: FME植入因其柔性和易变形的结构，以及与生物组织的复杂相互作用，使植入过程具有挑战性。确保植入的可靠性和安全性迫切需要高效的在线监测和异常检测机制。

Method: 提出了一套融合显微摄像头图像的异常检测系统，在植入流程的四个关键节点进行自动检测。具体做法为利用预训练图像变换网络（ViT）在对齐后的感兴趣区域提取特征，并引入细粒度的特征采样和信噪比筛选方法，以适应不同场景下的检测需求。

Result: 基于真实植入系统采集的数据集，验证了所提出方法能更有效地检测和识别关键节点的异常，提升了系统对于敏感和容错性的兼顾能力。

Conclusion: 研究证明了联合深度特征采样与选择的图像异常检测框架适用于FME植入过程，能够提升植入手术的安全性与可靠性。

Abstract: Flexible microelectrode (FME) implantation into brain cortex is challenging
due to the deformable fiber-like structure of FME probe and the interaction
with critical bio-tissue. To ensure reliability and safety, the implantation
process should be monitored carefully. This paper develops an image-based
anomaly detection framework based on the microscopic cameras of the robotic FME
implantation system. The unified framework is utilized at four checkpoints to
check the micro-needle, FME probe, hooking result, and implantation point,
respectively. Exploiting the existing object localization results, the aligned
regions of interest (ROIs) are extracted from raw image and input to a
pretrained vision transformer (ViT). Considering the task specifications, we
propose a progressive granularity patch feature sampling method to address the
sensitivity-tolerance trade-off issue at different locations. Moreover, we
select a part of feature channels with higher signal-to-noise ratios from the
raw general ViT features, to provide better descriptors for each specific
scene. The effectiveness of the proposed methods is validated with the image
datasets collected from our implantation system.

</details>


### [42] [SilvaScenes: Tree Segmentation and Species Classification from Under-Canopy Images in Natural Forests](https://arxiv.org/abs/2510.09458)
*David-Alexandre Duclos,William Guimont-Martin,Gabriel Jeanson,Arthur Larochelle-Tremblay,Théo Defosse,Frédéric Moore,Philippe Nolet,François Pomerleau,Philippe Giguère*

Main category: cs.CV

TL;DR: 提出了SilvaScenes森林树种实例分割数据集，以提升林业场景下机器感知能力，并验证深度学习方法在树木分割和树种分类上的性能。


<details>
  <summary>Details</summary>
Motivation: 林业机器人应用需求增长，但复杂自然环境中的感知挑战仍难以突破，特别在自动化林业设备和生物多样性监测等任务需要更先进的感知能力，而现有数据集多集中于城市场景或物种有限，难以满足需求。

Method: 作者收集了SilvaScenes数据集，涵盖加拿大魁北克五个生物气候区的24种树，共1476棵，由林业专家标注。采用当前主流深度学习分割方法在该数据集上进行了实例分割和树种分类基准测试。

Result: 在实例分割任务中，树木分割较为容易，最高均值平均精度（mAP）达到67.65%；但树种细粒度分类极具挑战，mAP仅为35.69%。

Conclusion: SilvaScenes数据集能有效推动林业机器人在复杂自然场景下的感知研究，强调了树木分割与树种分类任务的难度差异，并为后续方法改进和基准对比提供了基础资源。

Abstract: Interest in robotics for forest management is growing, but perception in
complex, natural environments remains a significant hurdle. Conditions such as
heavy occlusion, variable lighting, and dense vegetation pose challenges to
automated systems, which are essential for precision forestry, biodiversity
monitoring, and the automation of forestry equipment. These tasks rely on
advanced perceptual capabilities, such as detection and fine-grained species
classification of individual trees. Yet, existing datasets are inadequate to
develop such perception systems, as they often focus on urban settings or a
limited number of species. To address this, we present SilvaScenes, a new
dataset for instance segmentation of tree species from under-canopy images.
Collected across five bioclimatic domains in Quebec, Canada, SilvaScenes
features 1476 trees from 24 species with annotations from forestry experts. We
demonstrate the relevance and challenging nature of our dataset by benchmarking
modern deep learning approaches for instance segmentation. Our results show
that, while tree segmentation is easy, with a top mean average precision (mAP)
of 67.65%, species classification remains a significant challenge with an mAP
of only 35.69%. Our dataset and source code will be available at
https://github.com/norlab-ulaval/SilvaScenes.

</details>


### [43] [MambaH-Fit: Rethinking Hyper-surface Fitting-based Point Cloud Normal Estimation via State Space Modelling](https://arxiv.org/abs/2510.09088)
*Weijia Wang,Yuanzhi Su,Pei-Gen Ye,Yuan-Gen Wang,Xuequan Lu*

Main category: cs.CV

TL;DR: MambaH-Fit是一种针对点云法线估计的状态空间建模方法，通过新颖的特征融合和局部模型提升了细粒度几何结构刻画能力，实现了更高精度的法线预测。


<details>
  <summary>Details</summary>
Motivation: 现有点云法线估计方法在捕捉细节几何结构时表现不足，影响了法线预测精度。虽然Mamba等状态空间模型在处理全局结构方面有所突破，但对于局部、细粒度信息建模仍不充分，因此需要新的方法提升这一能力。

Method: 论文提出MambaH-Fit框架，核心包括两个创新：一是注意力驱动的分层特征融合（AHFF），自适应融合多尺度区域特征，增强局部上下文学习能力；二是基于状态空间的Patch-wise建模（PSSM），通过状态动力学将点云局部区域建模为隐式超曲面，从而更好地理解局部细节。

Result: 在多个基准数据集上的大量实验表明，所提方法在精度、鲁棒性和灵活性上均优于现有方法。消融实验也验证了各组成部分对性能提升的重要性。

Conclusion: MambaH-Fit通过创新的局部特征融合与状态空间建模，有效提升了点云法线估计的准确性与鲁棒性，为后续相关任务研究提供了新思路。

Abstract: We present MambaH-Fit, a state space modelling framework tailored for
hyper-surface fitting-based point cloud normal estimation. Existing normal
estimation methods often fall short in modelling fine-grained geometric
structures, thereby limiting the accuracy of the predicted normals. Recently,
state space models (SSMs), particularly Mamba, have demonstrated strong
modelling capability by capturing long-range dependencies with linear
complexity and inspired adaptations to point cloud processing. However,
existing Mamba-based approaches primarily focus on understanding global shape
structures, leaving the modelling of local, fine-grained geometric details
largely under-explored. To address the issues above, we first introduce an
Attention-driven Hierarchical Feature Fusion (AHFF) scheme to adaptively fuse
multi-scale point cloud patch features, significantly enhancing geometric
context learning in local point cloud neighbourhoods. Building upon this, we
further propose Patch-wise State Space Model (PSSM) that models point cloud
patches as implicit hyper-surfaces via state dynamics, enabling effective
fine-grained geometric understanding for normal prediction. Extensive
experiments on benchmark datasets show that our method outperforms existing
ones in terms of accuracy, robustness, and flexibility. Ablation studies
further validate the contribution of the proposed components.

</details>


### [44] [PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs](https://arxiv.org/abs/2510.09507)
*Zixin Zhang,Kanghao Chen,Xingwang Lin,Lutao Jiang,Xu Zheng,Yuanhuiyi Lyu,Litao Guo,Yinchuan Li,Ying-Cong Chen*

Main category: cs.CV

TL;DR: 本文提出了PhysToolBench，这是第一个专门评估多模态大模型（MLLM）对物理工具理解能力的基准。研究显示，当前主流MLLMs在工具理解方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 人类智能的重要表现之一是使用和创造工具。对于通用智能体来说，掌握工具相关能力是实现多样化任务的基础。现有多模态大模型虽在高层次感知与规划方面表现突出，但其对真实物理工具的理解能力却未被定量化。

Method: 作者构建了PhysToolBench数据集，包含1000余组图文对，以VQA方式分为三类难度：工具识别、工具原理理解及在无现成工具时创造新工具。作者对32种主流MLLMs（包括专有、开源、下游VLA模型等）进行了全面评测。

Result: 测试发现，虽然MLLMs在工具识别上表现尚可，但在工具原理理解和新工具创造方面存在明显短板。综合分析了各模型表现，并提出初步改进建议。

Conclusion: 研究表明，现有MLLMs对物理工具的深入理解能力有限。PhysToolBench为该方向研究提供了标准和基准，有利于未来针对性改进。数据集和代码已开源。

Abstract: The ability to use, understand, and create tools is a hallmark of human
intelligence, enabling sophisticated interaction with the physical world. For
any general-purpose intelligent agent to achieve true versatility, it must also
master these fundamental skills. While modern Multimodal Large Language Models
(MLLMs) leverage their extensive common knowledge for high-level planning in
embodied AI and in downstream Vision-Language-Action (VLA) models, the extent
of their true understanding of physical tools remains unquantified. To bridge
this gap, we present PhysToolBench, the first benchmark dedicated to evaluating
the comprehension of physical tools by MLLMs. Our benchmark is structured as a
Visual Question Answering (VQA) dataset comprising over 1,000 image-text pairs.
It assesses capabilities across three distinct difficulty levels: (1) Tool
Recognition: Requiring the recognition of a tool's primary function. (2) Tool
Understanding: Testing the ability to grasp the underlying principles of a
tool's operation. (3) Tool Creation: Challenging the model to fashion a new
tool from surrounding objects when conventional options are unavailable. Our
comprehensive evaluation of 32 MLLMs-spanning proprietary, open-source,
specialized embodied, and backbones in VLAs-reveals a significant deficiency in
tool understanding. Furthermore, we provide an in-depth analysis and propose
preliminary solutions. Code and dataset are publicly available.

</details>


### [45] [GL-DT: Multi-UAV Detection and Tracking with Global-Local Integration](https://arxiv.org/abs/2510.09092)
*Juanqin Liu,Leonardo Plotegher,Eloy Roura,Shaoming He*

Main category: cs.CV

TL;DR: 该论文提出了一种名为GL-DT的新多目标跟踪（MOT）框架，专为无人机场景的高效、准确跟踪小目标设计，并以实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 无人机在军事侦察和环境监测等领域广泛应用，对高效、精确的多目标跟踪技术需求急迫。然而，复杂背景、小尺度目标及频繁遮挡、交互等问题严重影响跟踪准确率和轨迹连续性。

Method: 提出了全局-局部检测与跟踪（GL-DT）框架，融合时空特征（STFF模块）联合建模运动与外观信息，采用全局-局部协同检测策略提升小目标检测能力。此外，提出JPTrack算法以减少ID切换和轨迹断裂问题。

Result: 实验表明，所提方法在保持实时性的同时，显著提升了多目标跟踪的连续性与稳定性。

Conclusion: GL-DT框架及JPTrack算法为无人机目标检测和跟踪技术进步提供了有力支持，提升了小目标检测与跟踪的表现。

Abstract: The extensive application of unmanned aerial vehicles (UAVs) in military
reconnaissance, environmental monitoring, and related domains has created an
urgent need for accurate and efficient multi-object tracking (MOT)
technologies, which are also essential for UAV situational awareness. However,
complex backgrounds, small-scale targets, and frequent occlusions and
interactions continue to challenge existing methods in terms of detection
accuracy and trajectory continuity. To address these issues, this paper
proposes the Global-Local Detection and Tracking (GL-DT) framework. It employs
a Spatio-Temporal Feature Fusion (STFF) module to jointly model motion and
appearance features, combined with a global-local collaborative detection
strategy, effectively enhancing small-target detection. Building upon this, the
JPTrack tracking algorithm is introduced to mitigate common issues such as ID
switches and trajectory fragmentation. Experimental results demonstrate that
the proposed approach significantly improves the continuity and stability of
MOT while maintaining real-time performance, providing strong support for the
advancement of UAV detection and tracking technologies.

</details>


### [46] [Dense2MoE: Restructuring Diffusion Transformer to MoE for Efficient Text-to-Image Generation](https://arxiv.org/abs/2510.09094)
*Youwei Zheng,Yuxi Ren,Xin Xia,Xuefeng Xiao,Xiaohua Xie*

Main category: cs.CV

TL;DR: 本文提出了一种创新方法，将传统高参数量的Diffusion Transformer (DiT)转化为结构稀疏的专家混合（MoE）模型，大幅降低推理所需参数数量，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的DiT模型因参数量庞大，推理开销高，且已有的模型压缩（如剪枝）方法会严重损害模型性能，因此亟需一种在降低参数量的同时能维持甚至提升性能的新方法。

Method: 作者将DiT中的前馈神经网络（FFN）替换为MoE层，使仅部分专家激活，以此减少每次推理时的参数参与度。同时提出Mixture of Blocks (MoB)，即在推理时动态激活部分DiT块，进一步稀疏模型。整个密集到MoE的转化流程由多步蒸馏流程支持，包括泰勒度量专家初始化、负载均衡的知识蒸馏、组特征损失辅助MoB优化。

Result: 在将大规模扩散变换器（如FLUX.1）转制为MoE结构后，激活参数减少了约60%，但生成性能几乎无损，并且在广泛实验中明显优于传统剪枝方法。

Conclusion: Dense2MoE为高效文本到图像生成任务提供了新的范式，显著减少推理资源需求，且能够维持高性能，优于以往结构压缩方法。

Abstract: Diffusion Transformer (DiT) has demonstrated remarkable performance in
text-to-image generation; however, its large parameter size results in
substantial inference overhead. Existing parameter compression methods
primarily focus on pruning, but aggressive pruning often leads to severe
performance degradation due to reduced model capacity. To address this
limitation, we pioneer the transformation of a dense DiT into a Mixture of
Experts (MoE) for structured sparsification, reducing the number of activated
parameters while preserving model capacity. Specifically, we replace the
Feed-Forward Networks (FFNs) in DiT Blocks with MoE layers, reducing the number
of activated parameters in the FFNs by 62.5\%. Furthermore, we propose the
Mixture of Blocks (MoB) to selectively activate DiT blocks, thereby further
enhancing sparsity. To ensure an effective dense-to-MoE conversion, we design a
multi-step distillation pipeline, incorporating Taylor metric-based expert
initialization, knowledge distillation with load balancing, and group feature
loss for MoB optimization. We transform large diffusion transformers (e.g.,
FLUX.1 [dev]) into an MoE structure, reducing activated parameters by 60\%
while maintaining original performance and surpassing pruning-based approaches
in extensive experiments. Overall, Dense2MoE establishes a new paradigm for
efficient text-to-image generation.

</details>


### [47] [A Novel Multi-branch ConvNeXt Architecture for Identifying Subtle Pathological Features in CT Scans](https://arxiv.org/abs/2510.09107)
*Irash Perera,Uthayasanker Thayasivam*

Main category: cs.CV

TL;DR: 该论文提出了一种新型多分支ConvNeXt架构，有效提升医学影像智能分析、尤其是COVID-19诊断的准确性，在多个评价指标上超过了现有方法。


<details>
  <summary>Details</summary>
Motivation: 医学影像分析对临床诊断尤其识别细微病理特征非常重要，但其挑战性高，需要新模型提升分类性能和泛化能力。

Method: 设计了一个多分支ConvNeXt神经网络架构，包含全局均值池化、全局最大池化和新颖的注意力加权池化三条并行特征提取分支。采用了端到端流程，包括数据预处理与增强、两阶段迁移学习训练方案。模型在2,609张CT图像的合并数据集上进行了训练与验证。

Result: 在COVID-19诊断任务中，模型在验证集上达到了0.9937的ROC-AUC、0.9757的准确率和0.9825的F1分数，均优于此前所有同数据集的模型。

Conclusion: 现代深度学习多分支架构结合严谨数据处理，可在医学影像诊断中达到、甚至超过当前最先进水平，证明其强大学习与泛化能力。

Abstract: Intelligent analysis of medical imaging plays a crucial role in assisting
clinical diagnosis, especially for identifying subtle pathological features.
This paper introduces a novel multi-branch ConvNeXt architecture designed
specifically for the nuanced challenges of medical image analysis. While
applied here to the specific problem of COVID-19 diagnosis, the methodology
offers a generalizable framework for classifying a wide range of pathologies
from CT scans. The proposed model incorporates a rigorous end-to-end pipeline,
from meticulous data preprocessing and augmentation to a disciplined two-phase
training strategy that leverages transfer learning effectively. The
architecture uniquely integrates features extracted from three parallel
branches: Global Average Pooling, Global Max Pooling, and a new
Attention-weighted Pooling mechanism. The model was trained and validated on a
combined dataset of 2,609 CT slices derived from two distinct datasets.
Experimental results demonstrate a superior performance on the validation set,
achieving a final ROC-AUC of 0.9937, a validation accuracy of 0.9757, and an
F1-score of 0.9825 for COVID-19 cases, outperforming all previously reported
models on this dataset. These findings indicate that a modern, multi-branch
architecture, coupled with careful data handling, can achieve performance
comparable to or exceeding contemporary state-of-the-art models, thereby
proving the efficacy of advanced deep learning techniques for robust medical
diagnostics.

</details>


### [48] [SOS: Synthetic Object Segments Improve Detection, Segmentation, and Grounding](https://arxiv.org/abs/2510.09110)
*Weikai Huang,Jieyu Zhang,Taoyang Jia,Chenhao Zheng,Ziqi Gao,Jae Sung Park,Ranjay Krishna*

Main category: cs.CV

TL;DR: 本文提出了一种基于目标合成的可控合成数据生成管道SOS，用于提升视觉分组任务（如实例分割、目标检测、视觉指代等）的性能，其合成数据在多个任务上显著优于大规模真实数据。


<details>
  <summary>Details</summary>
Motivation: 现有视觉分组任务高度依赖大规模人工标注数据，这类数据昂贵、偏见重且难以扩展。尽管合成数据可作为替代，但现有方法缺乏灵活性、准确性和合成多样性。作者因此提出一种高质量、可控性强的合成数据生成方法，以提升视觉分组模型泛化能力并降低对真实数据的依赖。

Method: 设计了一条以目标为中心的合成管道SOS，将高质量的合成目标片段通过结构化布局先验和生成式重新照明技术“粘贴”到新背景图像中，生成准确、多样的实例分割掩码、检测框和指代表达。该管道支持数据生成过程中的可控性调整，便于针对性增强弱场景。

Result: 使用SOS生成的10万张合成图像在目标检测和指代任务上显著超越用大型真实数据集（如GRIT和V3Det）训练的模型：在LVIS检测上提升10.9 AP，在gRefCOCO指代任务上提升8.4 $N_{Acc}$。在真实数据极少情况下（如COCO仅1%数据），合成增强依然带来显著提升，如LVIS实例分割稀有类提升3.83 AP、COCO检测提升6.59 AP。

Conclusion: SOS能自动生成高质量、多样、易控的视觉分组标注数据，有效提升模型在低数据量、封闭词汇等场景的泛化能力，并支持针对性挑战场景的数据构建，在现有真实大数据上进一步增强性能。

Abstract: Visual grouping -- operationalized via instance segmentation, visual
grounding, and object detection -- underpins applications from robotic
perception to photo editing. Large annotated datasets are costly, biased in
coverage, and hard to scale. Synthetic data are promising but often lack
flexibility, accuracy, and compositional diversity.
  We present SOS, a simple and scalable data synthesis pipeline based on an
object-centric composition strategy. It pastes high-quality synthetic object
segments into new images using structured layout priors and generative
relighting, producing accurate and diverse masks, boxes, and referring
expressions. Models trained on 100000 synthetic images from SOS outperform
those trained on larger real-image datasets such as GRIT (20M) and V3Det (200K)
on detection and grounding tasks, achieving +10.9 AP on LVIS detection and +8.4
$N_{\text{Acc}}$ on gRefCOCO grounding. SOS enables controllable dataset
construction and improves generalization in both low-data and closed-vocabulary
settings. Augmenting LVIS and COCO with synthetic object segments yields strong
performance across real-data scales and even larger gains under extremely
limited real data (for example, +3.83 $AP_{\text{rare}}$ on LVIS instance
segmentation and +6.59 AP with a 1 percent COCO setup). This controllability
also supports targeted data generation for challenging intra-class referring in
visual grounding.

</details>


### [49] [MSDM: Generating Task-Specific Pathology Images with a Multimodal Conditioned Diffusion Model for Cell and Nuclei Segmentation](https://arxiv.org/abs/2510.09121)
*Dominik Winter,Mai Bui,Monica Azqueta Gavaldon,Nicolas Triltsch,Marco Rosati,Nicolas Brieu*

Main category: cs.CV

TL;DR: 本文提出了多模态语义扩散模型（MSDM），能合成精准像素级掩膜对，提高细胞与细胞核分割模型在稀有形态学样本上的表现。


<details>
  <summary>Details</summary>
Motivation: 细胞与细胞核分割受限于人工标注数据的不足，尤其是罕见或非典型形态的数据，导致模型性能受限。手工标注费时费力，因此亟需能够自动生成高质量标注数据的新方法。

Method: 提出了一种多模态语义扩散模型（MSDM），将细胞/细胞核形态（通过水平和垂直地图）、RGB色彩图像，以及BERT编码的实验/应用元数据共同作为条件，通过多头交叉注意力机制整合，实现对细胞形态属性等细粒度可控的图像-掩膜对生成。

Result: 实验显示，MSDM生成的图像与真实生物条件下的图像在嵌入空间的Wasserstein距离很低，表明其高度接近真实数据。将这些合成数据用于训练后，针对如“柱状细胞”等稀有形态，分割模型的准确率明显提升。

Conclusion: 该方法可系统性地丰富数据集，针对性弥补分割模型在弱势类型上的能力，显著增强模型鲁棒性和泛化性能，推动生成模型在计算病理领域的广泛应用。

Abstract: Scarcity of annotated data, particularly for rare or atypical morphologies,
present significant challenges for cell and nuclei segmentation in
computational pathology. While manual annotation is labor-intensive and costly,
synthetic data offers a cost-effective alternative. We introduce a Multimodal
Semantic Diffusion Model (MSDM) for generating realistic pixel-precise
image-mask pairs for cell and nuclei segmentation. By conditioning the
generative process with cellular/nuclear morphologies (using horizontal and
vertical maps), RGB color characteristics, and BERT-encoded assay/indication
metadata, MSDM generates datasests with desired morphological properties. These
heterogeneous modalities are integrated via multi-head cross-attention,
enabling fine-grained control over the generated images. Quantitative analysis
demonstrates that synthetic images closely match real data, with low
Wasserstein distances between embeddings of generated and real images under
matching biological conditions. The incorporation of these synthetic samples,
exemplified by columnar cells, significantly improves segmentation model
accuracy on columnar cells. This strategy systematically enriches data sets,
directly targeting model deficiencies. We highlight the effectiveness of
multimodal diffusion-based augmentation for advancing the robustness and
generalizability of cell and nuclei segmentation models. Thereby, we pave the
way for broader application of generative models in computational pathology.

</details>


### [50] [Polar Separable Transform for Efficient Orthogonal Rotation-Invariant Image Representation](https://arxiv.org/abs/2510.09125)
*Satya P. Singh,Rashmi Chaudhry,Anand Srivastava,Jagath C. Rajapakse*

Main category: cs.CV

TL;DR: 本文提出了一种名为PSepT的极坐标可分离正交变换方法，实现了对高阶图像正交矩的高效、稳定计算，极大突破了以往方法的计算复杂性和数值不稳定性问题，适用于高阶鲁棒图像特征提取。


<details>
  <summary>Details</summary>
Motivation: 传统正交矩（如Zernike与伪Zernike矩）尽管在图像表示中很有价值，但在高阶下需耦合径向-角向处理，计算复杂度与数值条件数随阶数急剧增长，限制了其实用性。当前急需一种能实现高效、稳定、高阶正交图像表示的新方法。

Method: 提出Polar Separable Transform（PSepT）：通过张量积构造，将离散余弦变换（DCT）用于径向基、傅里叶谐波用于角向基，首创实现极坐标下的完全面核分离，使角、径向处理互不影响，降低了复杂度和计算量。

Result: PSepT将计算复杂度从传统$mathcal{O}(n^3N^2)$-$mathcal{O}(n^6N^2)$降至$mathcal{O}(N^2 \\log N)$，内存占用降为$mathcal{O}(N^2)$，数值条件数优于以往方法。实际测试展现了更优的数值稳定性、极高的计算效率，以及在分类等任务上的竞争性表现，并可实现精确重构。

Conclusion: PSepT突破了因极坐标非可分性导致的瓶颈，为高阶正交矩分析提供了可实际应用的高效方案，极大拓展了其在鲁棒图像分析及其它高维特征提取场景中的应用前景。

Abstract: Orthogonal moment-based image representations are fundamental in computer
vision, but classical methods suffer from high computational complexity and
numerical instability at large orders. Zernike and pseudo-Zernike moments, for
instance, require coupled radial-angular processing that precludes efficient
factorization, resulting in $\mathcal{O}(n^3N^2)$ to $\mathcal{O}(n^6N^2)$
complexity and $\mathcal{O}(N^4)$ condition number scaling for the $n$th-order
moments on an $N\times N$ image. We introduce \textbf{PSepT} (Polar Separable
Transform), a separable orthogonal transform that overcomes the
non-separability barrier in polar coordinates. PSepT achieves complete kernel
factorization via tensor-product construction of Discrete Cosine Transform
(DCT) radial bases and Fourier harmonic angular bases, enabling independent
radial and angular processing. This separable design reduces computational
complexity to $\mathcal{O}(N^2 \log N)$, memory requirements to
$\mathcal{O}(N^2)$, and condition number scaling to $\mathcal{O}(\sqrt{N})$,
representing exponential improvements over polynomial approaches. PSepT
exhibits orthogonality, completeness, energy conservation, and
rotation-covariance properties. Experimental results demonstrate better
numerical stability, computational efficiency, and competitive classification
performance on structured datasets, while preserving exact reconstruction. The
separable framework enables high-order moment analysis previously infeasible
with classical methods, opening new possibilities for robust image analysis
applications.

</details>


### [51] [Training Feature Attribution for Vision Models](https://arxiv.org/abs/2510.09135)
*Aziz Bacha,Thomas George*

Main category: cs.CV

TL;DR: 本文提出一种新的解释方法——训练特征归因，将测试预测结果归因到训练集中具体图片的具体区域，为理解深度模型工作原理提供了更细致的解释。该方法揭示了常规归因方法难以发现的有害训练样本和伪相关性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在决策过程中不透明，需要更好的可解释性方法来提高信任和责任。现有方法只关注输入特征或训练样本对预测的影响，缺乏联合视角。

Method: 提出“训练特征归因”方法，将测试样本的预测结果关联到训练集中具体区域，从而实现对预测的细粒度、具体化解释，通过实验证明该方法在图像数据集上有效。

Result: 实验证明，该方法能够识别导致错误分类的有害训练实例，以及现有归因方法无法发现的伪相关性，如基于特定区域的捷径。

Conclusion: 训练特征归因能够提供比传统方法更细致和具体的模型决策解释，有助于发现模型潜在的问题，提高其可解释性。

Abstract: Deep neural networks are often considered opaque systems, prompting the need
for explainability methods to improve trust and accountability. Existing
approaches typically attribute test-time predictions either to input features
(e.g., pixels in an image) or to influential training examples. We argue that
both perspectives should be studied jointly. This work explores *training
feature attribution*, which links test predictions to specific regions of
specific training images and thereby provides new insights into the inner
workings of deep models. Our experiments on vision datasets show that training
feature attribution yields fine-grained, test-specific explanations: it
identifies harmful examples that drive misclassifications and reveals spurious
correlations, such as patch-based shortcuts, that conventional attribution
methods fail to expose.

</details>


### [52] [Online Topological Localization for Navigation Assistance in Bronchoscopy](https://arxiv.org/abs/2510.09144)
*Clara Tomasini,Luis Riazuelo,Ana C. Murillo*

Main category: cs.CV

TL;DR: 本文提出了一种无需患者CT扫描、基于图像的支气管镜导航定位方法，仅通过仿真数据训练，能为医生在实际操作中提供位置指引，且在真实数据上效果优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有支气管镜导航方法需依赖患者CT扫描和复杂的设备设置，对医生训练要求高，且实际临床中并不总需要精确的三维定位。降低导航过程的技术门槛和成本，有助于推广和提升支气管镜手术的效率与安全性。

Method: 不依赖患者个体CT，仅通过通用气道模型和影像信息进行定位。方法基于图像数据，通过在仿真模型（phantom data）上训练定位算法，再将其应用于实际手术过程中，实现拓扑级别的导航辅助。

Result: 本文提出的算法在真实支气管镜影像数据上的测试结果优于现有定位方法，显示出较好的泛化能力和准确度。

Conclusion: 该方法可以有效降低支气管镜导航的依赖条件与成本，在无需获取患者CT和额外复杂设备的情况下，仍能为医生提供较为准确的导航辅助，具有实际应用价值和良好的推广前景。

Abstract: Video bronchoscopy is a fundamental procedure in respiratory medicine, where
medical experts navigate through the bronchial tree of a patient to diagnose or
operate the patient. Surgeons need to determine the position of the scope as
they go through the airway until they reach the area of interest. This task is
very challenging for practitioners due to the complex bronchial tree structure
and varying doctor experience and training. Navigation assistance to locate the
bronchoscope during the procedure can improve its outcome. Currently used
techniques for navigational guidance commonly rely on previous CT scans of the
patient to obtain a 3D model of the airway, followed by tracking of the scope
with additional sensors or image registration. These methods obtain accurate
locations but imply additional setup, scans and training. Accurate metric
localization is not always required, and a topological localization with regard
to a generic airway model can often suffice to assist the surgeon with
navigation. We present an image-based bronchoscopy topological localization
pipeline to provide navigation assistance during the procedure, with no need of
patient CT scan. Our approach is trained only on phantom data, eliminating the
high cost of real data labeling, and presents good generalization capabilities.
The results obtained surpass existing methods, particularly on real data test
sequences.

</details>


### [53] [Instance-Level Generation for Representation Learning](https://arxiv.org/abs/2510.09171)
*Yankun Wu,Zakaria Laskar,Giorgos Kordopatis-Zilos,Noa Garcia,Giorgos Tolias*

Main category: cs.CV

TL;DR: 本文提出了一种无需真实图像，纯合成生成大规模实例级识别（ILR）数据集的方法，通过在不同领域和环境下合成各类对象实例，解决ILR在现实应用中训练数据不足的难题。


<details>
  <summary>Details</summary>
Motivation: ILR需要极高的数据精细度，现有大规模标注数据集构建成本高、难度大，制约其应用。作者希望能跳过真实样本采集，快速高效获得训练数据，推广ILR技术。

Method: 作者提出全新合成数据生成方法，能够在多领域、多场景下自动合成多样化的对象实例数据集，不依赖任何真实图片，仅需目标领域的名称。随后在这些数据上对基础视觉模型进行微调。

Result: 用生成数据微调基础视觉模型，在七个涵盖多个领域的ILR基准上均显著提升了检索性能。

Conclusion: 该方法为数据收集和标注提供了一种全新、有效且高效的替代方案，仅凭目标领域名称即可生成训练集，极大拓宽ILR的现实应用前景，开启了ILR的新范式。

Abstract: Instance-level recognition (ILR) focuses on identifying individual objects
rather than broad categories, offering the highest granularity in image
classification. However, this fine-grained nature makes creating large-scale
annotated datasets challenging, limiting ILR's real-world applicability across
domains. To overcome this, we introduce a novel approach that synthetically
generates diverse object instances from multiple domains under varied
conditions and backgrounds, forming a large-scale training set. Unlike prior
work on automatic data synthesis, our method is the first to address
ILR-specific challenges without relying on any real images. Fine-tuning
foundation vision models on the generated data significantly improves retrieval
performance across seven ILR benchmarks spanning multiple domains. Our approach
offers a new, efficient, and effective alternative to extensive data collection
and curation, introducing a new ILR paradigm where the only input is the names
of the target domains, unlocking a wide range of real-world applications.

</details>


### [54] [TARO: Toward Semantically Rich Open-World Object Detection](https://arxiv.org/abs/2510.09173)
*Yuchen Zhang,Yao Lu,Johannes Betz*

Main category: cs.CV

TL;DR: 该论文提出了一种新的开放集目标检测框架TARO，能够将未知目标进一步细分为粗粒度父类别，从而提升实际场景的安全决策能力。


<details>
  <summary>Details</summary>
Motivation: 现有目标检测器基于封闭世界假设，只能识别预定义类别，无法有效处理遇到的未知对象。开放集检测方法虽然能标记'未知'，但无法满足安全关键场景对未知细分类别的需求（如自动驾驶）。

Method: 提出TARO框架，包含基于sparsemax的objectness检测头、引导辅助监督的语义层级重标签模块，以及用于学习层级关系的分类器，实现对未知目标进行父类别识别。

Result: 实验表明，TARO可将最多29.9%的未知目标识别为有意义的粗粒度类别，同时显著减少已知与未知类别混淆，并在未知召回率和已知mAP上均表现优异。

Conclusion: TARO打破了传统将所有未知作为单一类别处理的局限，实现了对未知目标的层级分类，提升了在实际应用中识别未知物体的解释性和实用性。

Abstract: Modern object detectors are largely confined to a "closed-world" assumption,
limiting them to a predefined set of classes and posing risks when encountering
novel objects in real-world scenarios. While open-set detection methods aim to
address this by identifying such instances as 'Unknown', this is often
insufficient. Rather than treating all unknowns as a single class, assigning
them more descriptive subcategories can enhance decision-making in
safety-critical contexts. For example, identifying an object as an 'Unknown
Animal' (requiring an urgent stop) versus 'Unknown Debris' (requiring a safe
lane change) is far more useful than just 'Unknown' in autonomous driving. To
bridge this gap, we introduce TARO, a novel detection framework that not only
identifies unknown objects but also classifies them into coarse parent
categories within a semantic hierarchy. TARO employs a unique architecture with
a sparsemax-based head for modeling objectness, a hierarchy-guided relabeling
component that provides auxiliary supervision, and a classification module that
learns hierarchical relationships. Experiments show TARO can categorize up to
29.9% of unknowns into meaningful coarse classes, significantly reduce
confusion between unknown and known classes, and achieve competitive
performance in both unknown recall and known mAP. Code will be made available.

</details>


### [55] [Online Video Depth Anything: Temporally-Consistent Depth Prediction with Low Memory Consumption](https://arxiv.org/abs/2510.09182)
*Johann-Friedrich Feiden,Tim Küchler,Denis Zavadski,Bogdan Savchynskyy,Carsten Rother*

Main category: cs.CV

TL;DR: 该论文提出了一种用于单目视频的在线深度估计算法oVDA，不仅效果优异，还能高效运行于低算力设备。


<details>
  <summary>Details</summary>
Motivation: 目前主流的Video Depth Anything（VDA）在长序列视频的深度估计上表现突出，但基于批处理，无法在线实时应用，限制了其实用性。为了实现在实时场景（例如边缘设备）中的应用，需要提出高效的在线方案。

Method: 引入了在线VDA（oVDA）方法，核心创新是借鉴大语言模型（LLM）技术：推理时缓存特征，在训练时对帧进行掩码处理，从而高效地处理视频帧，实现在线推断。

Result: oVDA在准确性和显存消耗上均优于现有所有在线视频深度估计算法。在NVIDIA A100上能以42 FPS运行，在NVIDIA Jetson边缘设备上能以20 FPS运行，证明其高效和适用于低算力环境。

Conclusion: oVDA不仅解决了传统VDA不能在线实时推断的难题，还提升了精度和资源利用率，适合在边缘设备上部署，相关代码和编译脚本也会开源，便于实际应用。

Abstract: Depth estimation from monocular video has become a key component of many
real-world computer vision systems. Recently, Video Depth Anything (VDA) has
demonstrated strong performance on long video sequences. However, it relies on
batch-processing which prohibits its use in an online setting. In this work, we
overcome this limitation and introduce online VDA (oVDA). The key innovation is
to employ techniques from Large Language Models (LLMs), namely, caching latent
features during inference and masking frames at training. Our oVDA method
outperforms all competing online video depth estimation methods in both
accuracy and VRAM usage. Low VRAM usage is particularly important for
deployment on edge devices. We demonstrate that oVDA runs at 42 FPS on an
NVIDIA A100 and at 20 FPS on an NVIDIA Jetson edge device. We will release
both, code and compilation scripts, making oVDA easy to deploy on low-power
hardware.

</details>


### [56] [Modern Deep Learning Approaches for Cricket Shot Classification: A Comprehensive Baseline Study](https://arxiv.org/abs/2510.09187)
*Sungwoo Kang*

Main category: cs.CV

TL;DR: 本文系统性地对板球击球动作分类的深度学习方法进行了大规模基线比较，发现以往文献的准确率被高估，现代高效架构和标准化评估显著提升了实际性能。


<details>
  <summary>Details</summary>
Motivation: 板球击球动作分类是运动视频分析领域的一个难题，现有文献中各种深度学习方法准确率高报，但缺乏统一的基线和严格验证。此研究希望揭示文献与真实效果的差距，并探索现代神经网络方法能否显著改进效果。

Method: 作者实现并系统比较了七种深度学习方法，涵盖CNN-LSTM、注意力机制模型、视觉Transformer、迁移学习、EfficientNet-GRU组合等，并统一在一个基准平台上做测试，采用PyTorch Lightning严格遵循ML Ops规范，确保实验可复现和标准化。

Result: 实际重新实现的文献方法准确率远低于原报道（46%~57.7%）。现代的EfficientNet-B0+GRU模型达到了92.25%的准确率，显著优于其它方法，也明显超过文献复现水平。

Conclusion: 该研究揭示了板球动作分类领域评估标准不统一所造成的虚高论文结果，通过现代神经网络架构和系统优化，可以实际获得很强的效果。建议未来研究需重视评估的规范化与结果复现，推动领域进步。

Abstract: Cricket shot classification from video sequences remains a challenging
problem in sports video analysis, requiring effective modeling of both spatial
and temporal features. This paper presents the first comprehensive baseline
study comparing seven different deep learning approaches across four distinct
research paradigms for cricket shot classification. We implement and
systematically evaluate traditional CNN-LSTM architectures, attention-based
models, vision transformers, transfer learning approaches, and modern
EfficientNet-GRU combinations on a unified benchmark. A critical finding of our
study is the significant performance gap between claims in academic literature
and practical implementation results. While previous papers reported accuracies
of 96\% (Balaji LRCN), 99.2\% (IJERCSE), and 93\% (Sensors), our standardized
re-implementations achieve 46.0\%, 55.6\%, and 57.7\% respectively. Our modern
SOTA approach, combining EfficientNet-B0 with a GRU-based temporal model,
achieves 92.25\% accuracy, demonstrating that substantial improvements are
possible with modern architectures and systematic optimization. All
implementations follow modern MLOps practices with PyTorch Lightning, providing
a reproducible research platform that exposes the critical importance of
standardized evaluation protocols in sports video analysis research.

</details>


### [57] [Towards Safer and Understandable Driver Intention Prediction](https://arxiv.org/abs/2510.09200)
*Mukilan Karuppasamy,Shankar Gangisetty,Shyam Nandan Rai,Carlo Masone,C V Jawahar*

Main category: cs.CV

TL;DR: 本文提出了解释性驾驶意图预测（DIP）任务，并发布了全新的多模态、主观视角驾驶数据集（DAAD-X），还提出了无需后处理的概念瓶颈模型（VCBM）生成因果解释，证明Transformer模型比CNN模型更加可解释。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统不断增强，但其决策过程的可解释性，目前仍是实现安全人机协作的重要挑战，现有深度学习方法在意图预测的解释性不足。

Method: （1）构建并公开了DAAD-X数据集，包含主观视角视频及基于视线追踪的层次化文本解释；（2）提出VCBM模型，能在预测操控动作前生成符合时空语义且内在可解释的概念说明，不依赖事后解释手段；（3）设计多标签t-SNE可视化，分析解释间的因果关系。

Result: 通过大量实验表明，基于Transformer的VCBM模型在DAAD-X数据集上的可解释性和性能均优于传统CNN方法，多标签t-SNE可有效揭示多种解释间的解耦与因果关系。

Conclusion: 该工作推动了解释性驾驶意图预测任务，数据集与模型均有助于领域发展；提出的VCBM提升可解释性并为安全人机协同提供理论和数据支持。

Abstract: Autonomous driving (AD) systems are becoming increasingly capable of handling
complex tasks, mainly due to recent advances in deep learning and AI. As
interactions between autonomous systems and humans increase, the
interpretability of decision-making processes in driving systems becomes
increasingly crucial for ensuring safe driving operations. Successful
human-machine interaction requires understanding the underlying representations
of the environment and the driving task, which remains a significant challenge
in deep learning-based systems. To address this, we introduce the task of
interpretability in maneuver prediction before they occur for driver safety,
i.e., driver intent prediction (DIP), which plays a critical role in AD
systems. To foster research in interpretable DIP, we curate the eXplainable
Driving Action Anticipation Dataset (DAAD-X), a new multimodal, ego-centric
video dataset to provide hierarchical, high-level textual explanations as
causal reasoning for the driver's decisions. These explanations are derived
from both the driver's eye-gaze and the ego-vehicle's perspective. Next, we
propose Video Concept Bottleneck Model (VCBM), a framework that generates
spatio-temporally coherent explanations inherently, without relying on post-hoc
techniques. Finally, through extensive evaluations of the proposed VCBM on the
DAAD-X dataset, we demonstrate that transformer-based models exhibit greater
interpretability than conventional CNN-based models. Additionally, we introduce
a multilabel t-SNE visualization technique to illustrate the disentanglement
and causal correlation among multiple explanations. Our data, code and models
are available at: https://mukil07.github.io/VCBM.github.io/

</details>


### [58] [Cattle-CLIP: A Multimodal Framework for Cattle Behaviour Recognition](https://arxiv.org/abs/2510.09203)
*Huimin Liu,Jing Gao,Daria Baran,AxelX Montout,Neill W Campbell,Andrew W Dowsey*

Main category: cs.CV

TL;DR: 提出了一种多模态深度学习框架Cattle-CLIP，用于牛行为识别，通过语义信息增强视频特征识别，在数据有限的情况下表现出色。


<details>
  <summary>Details</summary>
Motivation: 牛的行为是健康、生产力和福利的重要指标，监测牛的行为对畜牧业管理至关重要。传统方法依赖人工观察，效率和准确性有限。随着深度学习的发展，基于视频的自动识别成为主流，但面临数据稀缺和领域差异等挑战，尤其是在真实牧场场景下。

Method: 本文提出Cattle-CLIP模型，基于CLIP架构，通过增加时序信息整合模块，将图像-文本大模型适配到牛行为识别任务。为解决预训练模型的领域差异问题，设计了针对性的图像数据增强策略和专业化文本提示词。模型在全监督和小样本学习设置下进行评估，并公开了新的六类牛舍行为数据集。

Result: Cattle-CLIP在全监督条件下，六类行为总体识别准确率达96.1%，其中喂食、饮水和站立反刍行为召回率接近100%。在数据稀缺的小样本情况下，模型依然表现出良好的泛化能力。

Conclusion: Cattle-CLIP利用多模态学习有效提升了牛行为识别准确率，并具备较强的少样本泛化能力，为畜牧业视频监控及动物行为研究提供了有力的工具和数据支持。

Abstract: Cattle behaviour is a crucial indicator of an individual animal health,
productivity and overall well-being. Video-based monitoring, combined with deep
learning techniques, has become a mainstream approach in animal biometrics, and
it can offer high accuracy in some behaviour recognition tasks. We present
Cattle-CLIP, a multimodal deep learning framework for cattle behaviour
recognition, using semantic cues to improve the performance of video-based
visual feature recognition. It is adapted from the large-scale image-language
model CLIP by adding a temporal integration module. To address the domain gap
between web data used for the pre-trained model and real-world cattle
surveillance footage, we introduce tailored data augmentation strategies and
specialised text prompts. Cattle-CLIP is evaluated under both fully-supervised
and few-shot learning scenarios, with a particular focus on data-scarce
behaviour recognition - an important yet under-explored goal in livestock
monitoring. To evaluate the proposed method, we release the CattleBehaviours6
dataset, which comprises six types of indoor behaviours: feeding, drinking,
standing-self-grooming, standing-ruminating, lying-self-grooming and
lying-ruminating. The dataset consists of 1905 clips collected from our John
Oldacre Centre dairy farm research platform housing 200 Holstein-Friesian cows.
Experiments show that Cattle-CLIP achieves 96.1% overall accuracy across six
behaviours in a supervised setting, with nearly 100% recall for feeding,
drinking and standing-ruminating behaviours, and demonstrates robust
generalisation with limited data in few-shot scenarios, highlighting the
potential of multimodal learning in agricultural and animal behaviour analysis.

</details>


### [59] [3D Reconstruction from Transient Measurements with Time-Resolved Transformer](https://arxiv.org/abs/2510.09205)
*Yue Li,Shida Sun,Yu Hong,Feihu Xu,Zhiwei Xiong*

Main category: cs.CV

TL;DR: 本论文提出了一种通用的时域变换网络（Time-Resolved Transformer, TRT）架构，专为光子效率高的3D重建任务设计，并开发出针对视线内（LOS）和非视线内（NLOS）成像的具体实现版本，显著提升了在合成和真实数据上的重建性能。


<details>
  <summary>Details</summary>
Motivation: 目前时域测量常用于高效光子3D重建，但在远距离或复杂场景下，受限于传感器低量子效率和高噪声，重建质量较差。因此需要一种能够提升空间-时间相关性建模能力、增强抗噪性能的新方法。

Method: 作者设计了一种专门针对时空瞬态测量的时域变换网络（TRT），具有独特的空间-时间自注意力编码器和跨注意力解码器模块，在多尺度下提取局部和全局特征，再在token空间融合，获取强表征能力的深层特征，并分别针对LOS与NLOS开发了特定算法实现。

Result: 该方法在大量合成和真实数据（包括作者自建的大规模高分辨率合成LOS数据集以及采集的NLOS数据）上进行了实验，相较现有方法在3D重建任务上有明显的性能提升。

Conclusion: TRT架构在提升视线内与非视线内成像的3D重建性能方面具有较强优势，为瞬态成像领域带来有效的深度特征建模手段，同时丰富了公开数据资源，对相关研究具有推动作用。

Abstract: Transient measurements, captured by the timeresolved systems, are widely
employed in photon-efficient reconstruction tasks, including line-of-sight
(LOS) and non-line-of-sight (NLOS) imaging. However, challenges persist in
their 3D reconstruction due to the low quantum efficiency of sensors and the
high noise levels, particularly for long-range or complex scenes. To boost the
3D reconstruction performance in photon-efficient imaging, we propose a generic
Time-Resolved Transformer (TRT) architecture. Different from existing
transformers designed for high-dimensional data, TRT has two elaborate
attention designs tailored for the spatio-temporal transient measurements.
Specifically, the spatio-temporal self-attention encoders explore both local
and global correlations within transient data by splitting or downsampling
input features into different scales. Then, the spatio-temporal cross attention
decoders integrate the local and global features in the token space, resulting
in deep features with high representation capabilities. Building on TRT, we
develop two task-specific embodiments: TRT-LOS for LOS imaging and TRT-NLOS for
NLOS imaging. Extensive experiments demonstrate that both embodiments
significantly outperform existing methods on synthetic data and real-world data
captured by different imaging systems. In addition, we contribute a
large-scale, high-resolution synthetic LOS dataset with various noise levels
and capture a set of real-world NLOS measurements using a custom-built imaging
system, enhancing the data diversity in this field. Code and datasets are
available at https://github.com/Depth2World/TRT.

</details>


### [60] [Stable Video Infinity: Infinite-Length Video Generation with Error Recycling](https://arxiv.org/abs/2510.09212)
*Wuyang Li,Wentao Pan,Po-Chien Luan,Yang Gao,Alexandre Alahi*

Main category: cs.CV

TL;DR: 该论文提出了Stable Video Infinity (SVI)方法，实现了高时序一致性、场景自然过渡和流畅剧情控制的无限长视频生成，且性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有生成长视频的方法多通过手工反漂移措施减缓累积误差，但仍主要局限于单一提示下的均质场景，且容易出现动作重复。作者发现根本挑战在于训练假设（干净输入）和推理阶段（自产生、含误差的输出）之间的差异。

Method: SVI提出了"误差回收微调"方法，将Diffusion Transformer（DiT）模型自身生成的误差作为新的训练提示反馈用于自身纠错。具体步骤包括：向干净输入注入模型历史误差，模拟误差轨迹；用一步双向积分高效近似预测并采用残差计算误差；将产生的误差动态存入重放记忆库，并在后续采样。

Result: SVI方法可在无额外推理成本下，实现从几秒到无限时长的视频生成，并能适配多种条件（如音频、骨架、文本等）。在多个基准测试的不同场景下表现优异，实现了当前最优水平。

Conclusion: SVI成功解决了长视频生成中的关键误差累积和训练一测试假设不一致问题，为可控、场景丰富且无限时长的视频生成提供了先进的方法。

Abstract: We propose Stable Video Infinity (SVI) that is able to generate
infinite-length videos with high temporal consistency, plausible scene
transitions, and controllable streaming storylines. While existing long-video
methods attempt to mitigate accumulated errors via handcrafted anti-drifting
(e.g., modified noise scheduler, frame anchoring), they remain limited to
single-prompt extrapolation, producing homogeneous scenes with repetitive
motions. We identify that the fundamental challenge extends beyond error
accumulation to a critical discrepancy between the training assumption (seeing
clean data) and the test-time autoregressive reality (conditioning on
self-generated, error-prone outputs). To bridge this hypothesis gap, SVI
incorporates Error-Recycling Fine-Tuning, a new type of efficient training that
recycles the Diffusion Transformer (DiT)'s self-generated errors into
supervisory prompts, thereby encouraging DiT to actively identify and correct
its own errors. This is achieved by injecting, collecting, and banking errors
through closed-loop recycling, autoregressively learning from error-injected
feedback. Specifically, we (i) inject historical errors made by DiT to
intervene on clean inputs, simulating error-accumulated trajectories in flow
matching; (ii) efficiently approximate predictions with one-step bidirectional
integration and calculate errors with residuals; (iii) dynamically bank errors
into replay memory across discretized timesteps, which are resampled for new
input. SVI is able to scale videos from seconds to infinite durations with no
additional inference cost, while remaining compatible with diverse conditions
(e.g., audio, skeleton, and text streams). We evaluate SVI on three benchmarks,
including consistent, creative, and conditional settings, thoroughly verifying
its versatility and state-of-the-art role.

</details>


### [61] [Tag-Enriched Multi-Attention with Large Language Models for Cross-Domain Sequential Recommendation](https://arxiv.org/abs/2510.09224)
*Wangyu Wu,Xuhang Chen,Zhenhong Chen,Jing-En Jiang,Kim-Fung Tsang,Xiaowei Huang,Fei Ma,Jimin Xiao*

Main category: cs.CV

TL;DR: 提出了一种新的跨领域序列推荐模型TEMA-LLM，结合大语言模型进行语义标签生成和多注意力机制，有效提升了推荐精度。


<details>
  <summary>Details</summary>
Motivation: 现代电商和消费电子平台涵盖多种服务，用户行为跨域频繁，如何准确理解和建模跨域用户兴趣成为提升个性化体验的挑战。现有方法难以同时捕捉领域内部与跨领域的行为特征。

Method: TEMA-LLM框架利用大语言模型对物品标题和描述进行领域感知的语义标签生成，通过多注意力机制融合标签、ID、文本和视觉特征，增强物品表示；模型同时从域内和跨域建模用户偏好。

Result: 在四个大规模电商数据集上的实验显示，TEMA-LLM整体优于最新的基线方法，验证了语义标签和多注意力机制结合的有效性。

Conclusion: 利用LLM进行语义标签丰富并结合多注意力机制，为跨领域推荐提供了更智能和以用户为中心的新方法，展示了LLM在消费电子推荐领域的应用前景。

Abstract: Cross-Domain Sequential Recommendation (CDSR) plays a crucial role in modern
consumer electronics and e-commerce platforms, where users interact with
diverse services such as books, movies, and online retail products. These
systems must accurately capture both domain-specific and cross-domain
behavioral patterns to provide personalized and seamless consumer experiences.
To address this challenge, we propose \textbf{TEMA-LLM} (\textit{Tag-Enriched
Multi-Attention with Large Language Models}), a practical and effective
framework that integrates \textit{Large Language Models (LLMs)} for semantic
tag generation and enrichment. Specifically, TEMA-LLM employs LLMs to assign
domain-aware prompts and generate descriptive tags from item titles and
descriptions. The resulting tag embeddings are fused with item identifiers as
well as textual and visual features to construct enhanced item representations.
A \textit{Tag-Enriched Multi-Attention} mechanism is then introduced to jointly
model user preferences within and across domains, enabling the system to
capture complex and evolving consumer interests. Extensive experiments on four
large-scale e-commerce datasets demonstrate that TEMA-LLM consistently
outperforms state-of-the-art baselines, underscoring the benefits of LLM-based
semantic tagging and multi-attention integration for consumer-facing
recommendation systems. The proposed approach highlights the potential of LLMs
to advance intelligent, user-centric services in the field of consumer
electronics.

</details>


### [62] [Clear Roads, Clear Vision: Advancements in Multi-Weather Restoration for Smart Transportation](https://arxiv.org/abs/2510.09228)
*Vijay M. Galshetwar,Praful Hambarde,Prashant W. Patil,Akshay Dudhane,Sachin Chaudhary,Santosh Kumar Vipparathi,Subrahmanyam Murala*

Main category: cs.CV

TL;DR: 这篇综述系统梳理了应对恶劣天气（如雾、雨、雪）造成视觉退化的图像与视频复原技术，对各种方法进行了归纳和展望。


<details>
  <summary>Details</summary>
Motivation: 恶劣天气严重影响智能交通系统视觉输入，进而影响自动驾驶、交通监测等关键应用，因此有必要全面总结和归纳相关复原方法以推动该领域进步。

Method: 将现有方法分为传统的先验技术与基于深度学习（如CNN、transformer、扩散模型、视觉-语言模型等）的数据驱动方法，并进一步按照任务范围（单任务、多任务/多天气、全能型）进行分类，评述了昼夜不同情境、数据集和评测标准。

Result: 总结了当前各类复原方法的优势、局限性以及实际应用中的挑战，提供了最新模型、数据资源以及开源实现的整理网址。

Conclusion: 指出当前研究面临的主要难题如混合/复合退化、实时部署和自治AI框架，并对未来发展方向提出建议。综述旨在为研发高鲁棒性的智慧交通视觉系统提供理论和技术参考。

Abstract: Adverse weather conditions such as haze, rain, and snow significantly degrade
the quality of images and videos, posing serious challenges to intelligent
transportation systems (ITS) that rely on visual input. These degradations
affect critical applications including autonomous driving, traffic monitoring,
and surveillance. This survey presents a comprehensive review of image and
video restoration techniques developed to mitigate weather-induced visual
impairments. We categorize existing approaches into traditional prior-based
methods and modern data-driven models, including CNNs, transformers, diffusion
models, and emerging vision-language models (VLMs). Restoration strategies are
further classified based on their scope: single-task models,
multi-task/multi-weather systems, and all-in-one frameworks capable of handling
diverse degradations. In addition, we discuss day and night time restoration
challenges, benchmark datasets, and evaluation protocols. The survey concludes
with an in-depth discussion on limitations in current research and outlines
future directions such as mixed/compound-degradation restoration, real-time
deployment, and agentic AI frameworks. This work aims to serve as a valuable
reference for advancing weather-resilient vision systems in smart
transportation environments. Lastly, to stay current with rapid advancements in
this field, we will maintain regular updates of the latest relevant papers and
their open-source implementations at
https://github.com/ChaudharyUPES/A-comprehensive-review-on-Multi-weather-restoration

</details>


### [63] [Diagnosing Shoulder Disorders Using Multimodal Large Language Models and Consumer-Grade Cameras](https://arxiv.org/abs/2510.09230)
*Jindong Hong,Wencheng Zhang,Shiqin Qiao,Jianhai Chen,Jianing Qiu,Chuanyang Zheng,Qian Xu,Yun Ji,Qianyue Wen,Weiwei Sun,Hao Li,Huizhen Li,Huichao Wang,Kai Wu,Meng Li,Yijun He,Lingjie Luo,Jiankai Sun*

Main category: cs.CV

TL;DR: 本文提出了一种基于消费级设备视频和多模态大模型（MLLMs）的肩关节疾病辅助诊断新方法HMVDx，大幅提升视频诊断肩疾的准确率，降低了诊断成本。


<details>
  <summary>Details</summary>
Motivation: 肩关节疾病如冻结肩在全球普遍存在，尤其高发于老年人及重复肩部工作者。在医疗资源稀缺地区，早期、准确的诊断尤为困难，急需低成本、易推广的诊断辅助方案。

Method: 该研究利用消费级终端设备采集的视频，应用创新的多模态大模型（MLLMs），提出了混合动作视频诊断框架（HMVDx），任务分为动作理解与疾病诊断，分别由两个MLLM完成。同时提出以医疗逻辑流程为核心的新评估指标——可用性指数（Usability Index），以衡量整个诊断流程中的有效性。

Result: 在实验中，HMVDx相比直接视频诊断，肩关节疾病诊断准确率提升了79.6%；提出的可用性指数可全面评估MLLMs在医用过程中的价值。

Conclusion: 结果表明，HMVDx极大提升了低成本视频诊断的准确性，并显示出多模态大模型在医学视频理解及辅助诊断上的应用潜力，对未来相关研究有重要技术推动作用。

Abstract: Shoulder disorders, such as frozen shoulder (a.k.a., adhesive capsulitis),
are common conditions affecting the health of people worldwide, and have a high
incidence rate among the elderly and workers engaged in repetitive shoulder
tasks. In regions with scarce medical resources, achieving early and accurate
diagnosis poses significant challenges, and there is an urgent need for
low-cost and easily scalable auxiliary diagnostic solutions. This research
introduces videos captured by consumer-grade devices as the basis for
diagnosis, reducing the cost for users. We focus on the innovative application
of Multimodal Large Language Models (MLLMs) in the preliminary diagnosis of
shoulder disorders and propose a Hybrid Motion Video Diagnosis framework
(HMVDx). This framework divides the two tasks of action understanding and
disease diagnosis, which are respectively completed by two MLLMs. In addition
to traditional evaluation indicators, this work proposes a novel metric called
Usability Index by the logical process of medical decision-making (action
recognition, movement diagnosis, and final diagnosis). This index evaluates the
effectiveness of MLLMs in the medical field from the perspective of the entire
medical diagnostic pathway, revealing the potential value of low-cost MLLMs in
medical applications for medical practitioners. In experimental comparisons,
the accuracy of HMVDx in diagnosing shoulder joint injuries has increased by
79.6\% compared with direct video diagnosis, a significant technical
contribution to future research on the application of MLLMs for video
understanding in the medical field.

</details>


### [64] [Zero-shot image privacy classification with Vision-Language Models](https://arxiv.org/abs/2510.09253)
*Alina Elena Baia,Alessio Xompero,Andrea Cavallaro*

Main category: cs.CV

TL;DR: 本文对大规模视觉-语言模型（VLMs）与专用模型在图像隐私预测任务中的表现进行了系统性比较。实验发现，尽管VLMs在资源消耗和推理速度上劣势明显，在隐私预测准确性上也不如小型专用模型，但它们对图像扰动更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前研究领域越来越多地采用为通用任务设计的VLMs来进行图像隐私预测，而忽视了专用模型可能的性能优势，并且缺乏对两者系统的对比评估。

Method: 作者建立了一个零样本（zero-shot）图像隐私分类基准，使用任务对齐提示语对3个主流开源VLM进行评测，并与已知的视觉专用模型及多模态方法在性能、效率和鲁棒性方面进行了对比。

Result: 实验结果显示，尽管VLMs在参数规模和推理速度上耗费更多资源，但在图像隐私预测准确性上却落后于小型的专用模型。同时，VLMs对图像扰动表现出更高的鲁棒性。

Conclusion: 当前VLMs尚不能完全替代专用的小型模型进行高精度的图像隐私预测，不过它们在模型鲁棒性方面有其独特的优势。

Abstract: While specialized learning-based models have historically dominated image
privacy prediction, the current literature increasingly favours adopting large
Vision-Language Models (VLMs) designed for generic tasks. This trend risks
overlooking the performance ceiling set by purpose-built models due to a lack
of systematic evaluation. To address this problem, we establish a zero-shot
benchmark for image privacy classification, enabling a fair comparison. We
evaluate the top-3 open-source VLMs, according to a privacy benchmark, using
task-aligned prompts and we contrast their performance, efficiency, and
robustness against established vision-only and multi-modal methods.
Counter-intuitively, our results show that VLMs, despite their
resource-intensive nature in terms of high parameter count and slower
inference, currently lag behind specialized, smaller models in privacy
prediction accuracy. We also find that VLMs exhibit higher robustness to image
perturbations.

</details>


### [65] [Hallucination Filtering in Radiology Vision-Language Models Using Discrete Semantic Entropy](https://arxiv.org/abs/2510.09256)
*Patrick Wienholt,Sophie Caselitz,Robert Siepmann,Philipp Bruners,Keno Bressem,Christiane Kuhl,Jakob Nikolas Kather,Sven Nebelung,Daniel Truhn*

Main category: cs.CV

TL;DR: 本文探索了通过使用离散语义熵（DSE）过滤掉更有可能引起幻觉（hallucination）的提问，是否能提升黑盒视觉-语言模型（VLM）对放射影像视觉问答任务（VQA）的答案准确率。


<details>
  <summary>Details</summary>
Motivation: 近年来大语言模型和视觉-语言模型被广泛应用于医学影像分析与自动问答，但这类模型往往会生成与事实不符的答案（即幻觉），降低其在临床场景的可靠性，因此需要找到实用且有效的方法检测并减少幻觉现象。

Method: 作者提出利用离散语义熵（DSE）来量化模型对同一问题回答的一致性，并以DSE为阈值过滤掉高风险问题。研究在两个公共影像问答数据集（VQA-Med 2019和一套诊断放射学数据集）上，用GPT-4o和GPT-4.1多次回答问题，评估和比较不同DSE阈值下的准确率提升效果。

Result: 去除高DSE（语义熵）的问题后，不同模型在剩余问题上的答案准确率有明显提升：比如DSE>0.3过滤后，GPT-4o的准确率从51.7%提升到76.3%，GPT-4.1从54.8%提升到63.8%。这种提升在两个数据集上均有体现，且统计意义显著。

Conclusion: 通过计算和利用DSE，能有效检测并过滤掉更易产生幻觉的问题，从而显著提高黑盒视觉-语言模型在医学影像问答中的实际诊断准确率，为临床应用提供了一种安全、可靠的筛选策略。

Abstract: To determine whether using discrete semantic entropy (DSE) to reject
questions likely to generate hallucinations can improve the accuracy of
black-box vision-language models (VLMs) in radiologic image based visual
question answering (VQA). This retrospective study evaluated DSE using two
publicly available, de-identified datasets: (i) the VQA-Med 2019 benchmark (500
images with clinical questions and short-text answers) and (ii) a diagnostic
radiology dataset (206 cases: 60 computed tomography scans, 60 magnetic
resonance images, 60 radiographs, 26 angiograms) with corresponding
ground-truth diagnoses. GPT-4o and GPT-4.1 answered each question 15 times
using a temperature of 1.0. Baseline accuracy was determined using
low-temperature answers (temperature 0.1). Meaning-equivalent responses were
grouped using bidirectional entailment checks, and DSE was computed from the
relative frequencies of the resulting semantic clusters. Accuracy was
recalculated after excluding questions with DSE > 0.6 or > 0.3. p-values and
95% confidence intervals were obtained using bootstrap resampling and a
Bonferroni-corrected threshold of p < .004 for statistical significance. Across
706 image-question pairs, baseline accuracy was 51.7% for GPT-4o and 54.8% for
GPT-4.1. After filtering out high-entropy questions (DSE > 0.3), accuracy on
the remaining questions was 76.3% (retained questions: 334/706) for GPT-4o and
63.8% (retained questions: 499/706) for GPT-4.1 (both p < .001). Accuracy gains
were observed across both datasets and largely remained statistically
significant after Bonferroni correction. DSE enables reliable hallucination
detection in black-box VLMs by quantifying semantic inconsistency. This method
significantly improves diagnostic answer accuracy and offers a filtering
strategy for clinical VLM applications.

</details>


### [66] [MomentSeg: Moment-Centric Sampling for Enhanced Video Pixel Understanding](https://arxiv.org/abs/2510.09274)
*Ming Dai,Sen Yang,Boqiang Duan,Wankou Yang,Jingdong Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新的Referring Video Object Segmentation (RefVOS)方法，通过统一优化时序句子定位（TSG）与RefVOS，同时引入关键时刻采样和更稳定的掩码传播策略，提升了多模态分割的精度与效率。


<details>
  <summary>Details</summary>
Motivation: 现有的RefVOS方法在采样关键帧时依赖手工启发或额外的关键帧模型，两者分别容易忽视时序信息或增加系统复杂性，因此需要一种更有效的端到端解决方案。

Method: 作者提出统一的TSG与RefVOS框架，训练时引入专用的[FIND] token进行时序匹配，无需外部时间戳；推理时设计Moment-Centric Sampling（MCS）策略，对重要时刻密集采样，忽略性帧稀疏采样。同时，提出Bidirectional Anchor-updated Propagation（BAP）机制，利用最相关时刻的初始化掩码进行双向传播并动态更新，减少误差累积。

Result: 新方法在保持运动细节和全局语境的同时，有效提升了RefVOS任务的分割精度和时序推理能力，同时降低了系统复杂性。

Conclusion: 该方法为RefVOS引入了强有力的时序定位和掩码传播机制，实现了更优的性能表现，并且简化了系统设计，代码和模型已开源。

Abstract: Referring Video Object Segmentation (RefVOS) seeks to segment target objects
in videos guided by natural language descriptions, demanding both temporal
reasoning and fine-grained visual comprehension. Existing sampling strategies
for LLM-based approaches typically rely on either handcrafted heuristics or
external keyframe models. The former often overlooks essential temporal cues,
while the latter increases system complexity. To address this, we propose a
unified framework that jointly optimizes Temporal Sentence Grounding (TSG) and
RefVOS, naturally incorporating key moment grounding capability. During
training, we introduce a novel TSG paradigm that employs a dedicated
\texttt{[FIND]} token for key moment identification through temporal token
similarity matching, thereby avoiding the need for external timestamp
encodings. For inference, we design a Moment-Centric Sampling (MCS) strategy
that densely samples informative moments while sparsely sampling non-essential
frames, preserving both motion details and global context. To further enhance
tracking stability, we develop Bidirectional Anchor-updated Propagation (BAP),
which leverages the most relevant moment as start point for high-quality mask
initialization and dynamically updates at sampled points to mitigate
accumulated errors. Code and model will be available at:
https://github.com/Dmmm1997/MomentSeg

</details>


### [67] [Spotlight on Token Perception for Multimodal Reinforcement Learning](https://arxiv.org/abs/2510.09285)
*Siyuan Huang,Xiaoye Qu,Yafu Li,Yun Luo,Zefeng He,Daizong Liu,Yu Cheng*

Main category: cs.CV

TL;DR: 本文提出Visually-Perceptive Policy Optimization (VPPO)，一种新颖的多模态强化学习优化算法，通过关注生成token的视觉依赖性（token perception），显著提升大型视觉-语言模型（LVLMs）的感知与推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有多模态RLVR方法忽略了视觉感知在优化过程中的关键作用，导致LVLMs推理能力受限。本文希望通过深入分析token级别的视觉依赖性，发掘增强模型感知和推理能力的新方法。

Method: 作者提出VPPO算法，在强化学习策略优化中引入token perception的概念。具体方法包括：（1）对每个生成token分析其对视觉的依赖性；（2）分析CoT推理链中的视觉感知分布；（3）按照整体视觉依赖性对轨迹优势进行重加权；（4）仅在具有高度视觉依赖的关键token上进行策略更新。

Result: 在8套视觉感知与推理基准测试中，VPPO在7B与32B规模的开源RL-tuned模型上均展现显著性能提升。

Conclusion: 本文开创性地提出基于token级视觉感知的新视角，并通过VPPO验证其在提升多模态LVLM推理能力上的有效性，为多模态RLVR优化提供新的理论与方法基础。

Abstract: While Reinforcement Learning with Verifiable Rewards (RLVR) has advanced the
reasoning capabilities of Large Vision-Language Models (LVLMs), most existing
methods in multimodal reasoning neglect the critical role of visual perception
within the RLVR optimization process. In this paper, we undertake a pioneering
exploration of multimodal RLVR through the novel perspective of token
perception, which measures the visual dependency of each generated token. With
a granular analysis of Chain-of-Thought (CoT) processes, we uncover two key
insights: first, token perception in a rollout trajectory is sparsely
distributed, where only a small fraction of tokens have high visual dependency
for visually-grounded reasoning; second, different trajectories exhibit
significant divergence in their overall visual dependency. Based on these
observations, we propose Visually-Perceptive Policy Optimization (VPPO), a
novel policy gradient algorithm that explicitly leverages token perception to
refine the learning signal. Specifically, VPPO achieves this through a dual
mechanism: it reweights a trajectory's advantage by its overall visual
dependency, and focuses policy updates exclusively on perceptually pivotal
tokens. On a comprehensive suite of eight perception and reasoning benchmarks,
VPPO demonstrates substantial gains over leading open-source RL-tuned models,
with its effectiveness consistently validated across 7B and 32B model scales.
Our findings not only establish a new token-level perceptual perspective for
analyzing multimodal RLVR but also present a novel and effective optimization
strategy to significantly enhance the multimodal reasoning capabilities of
LVLMs.

</details>


### [68] [Foraging with the Eyes: Dynamics in Human Visual Gaze and Deep Predictive Modeling](https://arxiv.org/abs/2510.09299)
*Tejaswi V. Panchagnula*

Main category: cs.CV

TL;DR: 该论文发现人类视觉注视轨迹遵循与动物觅食相似的Levy walk重尾分布，揭示人眼在浏览图像时也存在类觅食的最优信息采集行为。同时，卷积神经网络模型能够仅凭图像结构预测注视热点区域，证明视觉特征对注视行为的高度解释性。


<details>
  <summary>Details</summary>
Motivation: 以往视觉注视建模多依赖图像显著性，但对于注视眼动的时空统计特性探索不足。动物觅食研究表明Levy walk对于稀疏资源搜索具有优化优势，作者试图验证人类视觉探索是否也服从类似统计规律，这对于注意力建模及视觉接口有理论和应用意义。

Method: 进行了大规模眼动实验，40名受试者自由浏览50张风格多样的图片，通过高速眼动仪采集了400多万个注视点。随后，统计分析眼动轨迹分布，并基于卷积神经网络（CNN）从单幅图像预测注视热图，对比真实数据评估模型性能。

Result: 人眼注视轨迹的步长分布与Levy walk一致，证实了类觅食机制。所训练的CNN模型能够在未见图像上准确复现人类主要注视区域，说明视觉结构能够解释和预测注视热点。

Conclusion: 人类视觉探索遵循与动物觅食类似的统计规律，注视行为可用生成和预测模型建模。该研究为注意力建模、智能人机交互等领域提供了新的理论依据和计算工具。

Abstract: Animals often forage via Levy walks stochastic trajectories with heavy tailed
step lengths optimized for sparse resource environments. We show that human
visual gaze follows similar dynamics when scanning images. While traditional
models emphasize image based saliency, the underlying spatiotemporal statistics
of eye movements remain underexplored. Understanding these dynamics has broad
applications in attention modeling and vision-based interfaces. In this study,
we conducted a large scale human subject experiment involving 40 participants
viewing 50 diverse images under unconstrained conditions, recording over 4
million gaze points using a high speed eye tracker. Analysis of these data
shows that the gaze trajectory of the human eye also follows a Levy walk akin
to animal foraging. This suggests that the human eye forages for visual
information in an optimally efficient manner. Further, we trained a
convolutional neural network (CNN) to predict fixation heatmaps from image
input alone. The model accurately reproduced salient fixation regions across
novel images, demonstrating that key components of gaze behavior are learnable
from visual structure alone. Our findings present new evidence that human
visual exploration obeys statistical laws analogous to natural foraging and
open avenues for modeling gaze through generative and predictive frameworks.

</details>


### [69] [CapGeo: A Caption-Assisted Approach to Geometric Reasoning](https://arxiv.org/abs/2510.09302)
*Yuying Li,Siyi Qian,Hao Liang,Leqi Zheng,Ruichuan An,Yongzhen Guo,Wentao Zhang*

Main category: cs.CV

TL;DR: 论文提出了CapGeo，一种利用文本描述（caption）辅助大模型解决几何问题的新框架，大幅提升了多模态大模型在几何推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 多模态大模型（如GPT-4、Gemini等）在文字推理上表现优异，但在理解和解答几何类题目时，效果远不如文本任务。作者认为瓶颈在于模型对几何图形的视觉理解有限。因此，将几何图形转化为文本描述（caption），有望打通视觉与文本间的鸿沟。

Method: 作者提出CapGeo框架，首先将几何图形用高质量文本描述进行辅助，再交给多模态大模型进行推理。同时建立了CapGeo-Bench数据集，包含4641对人工精选的图形-文本描述，并设计基于关键点的评价指标，以更精准衡量caption模型对几何信息的捕捉能力。

Result: 实验结果表明，使用caption后，模型几何推理能力大幅提升。比如Qwen2.5-VL-72B模型准确率从8.6%提升到59.0%，Claude-Opus-4从44.8%提升到73.0%。关键点评分指标与推理表现高度相关。

Conclusion: 通过将几何图形转成文本描述（caption），能够有效弥补视觉理解短板，显著提升多模态大模型的几何推理能力；CapGeo框架和数据集为该方向的持续进步奠定了基础。

Abstract: Geometric reasoning remains a core challenge for Multimodal Large Language
Models (MLLMs). Even the most advanced closed-source systems, such as GPT-O3
and Gemini-2.5-Pro, still struggle to solve geometry problems reliably, despite
exhibiting strong textual reasoning abilities on tasks like the International
Mathematical Olympiad (IMO). This gap suggests that the bottleneck lies in
understanding geometric diagrams rather than reasoning itself. Since geometric
figures can often be faithfully described in concise textual form, converting
visual content into captions offers a promising direction. Motivated by this
insight, we introduce CapGeo, a caption-assisted reasoning framework that
bridges visual and textual modalities. Experiments show substantial
improvements when models are equipped with captions: Qwen2.5-VL-72B improves
from 8.6% (vision-only) to 59.0%, while Claude-Opus-4 rises from 44.8% to
73.0%. To systematically evaluate and identify high-quality geometric
captioning models, we further propose CapGeo-Bench, a dataset of 4,641 curated
figure-caption pairs. Crucially, CapGeo-Bench incorporates a keypoint-based
evaluation metric that correlates strongly with downstream CapGeo performance,
enabling reliable assessment of geometric captioning ability. Together, our
framework and benchmark highlight a new pathway toward advancing geometric
reasoning in MLLMs.

</details>


### [70] [RadioFlow: Efficient Radio Map Construction Framework with Flow Matching](https://arxiv.org/abs/2510.09314)
*Haozhe Jia,Wenshuo Chen,Xiucheng Wang,Nan Cheng,Hongbo Zhang,Kuimou Yu,Songning Lai,Nanjian Jia,Bowen Tian,Hongru Xiao,Yutao Yue*

Main category: cs.CV

TL;DR: 本论文提出了一种名为RadioFlow的新型生成框架，用于高效且高保真的无线射频地图生成，大幅提升了速度与精度并显著减小了模型规模。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的无线射频地图生成方法存在模型大、推理慢、延迟高等问题，严重制约了其实用性和大规模部署。

Method: 作者提出RadioFlow，一种基于flow-matching的生成模型，不同于扩散模型采用逐步去噪采样，RadioFlow直接学习噪声与数据之间的连续变换轨迹，实现单步采样，从而加速训练和推理并维持重建准确度。

Result: 实验表明，RadioFlow在参数量比主流扩散模型（如RadioDiff）减少8倍的同时，推理速度提升4倍以上，并且达到当前最优的生成性能。

Conclusion: RadioFlow为实现可扩展、节能、实时的电磁数字孪生系统（服务于6G等未来无线网络）提供了新的技术路径。

Abstract: Accurate and real-time radio map (RM) generation is crucial for
next-generation wireless systems, yet diffusion-based approaches often suffer
from large model sizes, slow iterative denoising, and high inference latency,
which hinder practical deployment. To overcome these limitations, we propose
\textbf{RadioFlow}, a novel flow-matching-based generative framework that
achieves high-fidelity RM generation through single-step efficient sampling.
Unlike conventional diffusion models, RadioFlow learns continuous transport
trajectories between noise and data, enabling both training and inference to be
significantly accelerated while preserving reconstruction accuracy.
Comprehensive experiments demonstrate that RadioFlow achieves state-of-the-art
performance with \textbf{up to 8$\times$ fewer parameters} and \textbf{over
4$\times$ faster inference} compared to the leading diffusion-based baseline
(RadioDiff). This advancement provides a promising pathway toward scalable,
energy-efficient, and real-time electromagnetic digital twins for future 6G
networks. We release the code at
\href{https://github.com/Hxxxz0/RadioFlow}{GitHub}.

</details>


### [71] [Hybrid-grained Feature Aggregation with Coarse-to-fine Language Guidance for Self-supervised Monocular Depth Estimation](https://arxiv.org/abs/2510.09320)
*Wenyao Zhang,Hongsi Liu,Bohan Li,Jiawei He,Zekun Qi,Yunnan Wang,Shengyang Zhao,Xinqiang Yu,Wenjun Zeng,Xin Jin*

Main category: cs.CV

TL;DR: 本文提出了一种名为Hybrid-depth的自监督单目深度估计新方法，利用基础模型（如CLIP与DINO）集成多尺度视觉信息，并通过语言引导实现更优特征对齐，大幅提升了深度估计性能。


<details>
  <summary>Details</summary>
Motivation: 现有自监督单目深度估计算法由于对语义和空间知识提取不足，导致性能受限。本文希望通过更好地利用视觉基础模型，提升深度估计时对场景语义和空间细节的感知能力。

Method: 方法上，采用了CLIP提取全局语义，DINO提取局部空间特征，并通过对比学习和语言引导进行特征对齐；通过一个“粗到细”的渐进学习框架，先用文本提示引导全局与局部对齐，再结合相机位姿和像素级语言引导细化特征。该方法可以作为插件集成进现有自监督MDE流程中。

Result: 在KITTI基准测试上显著超过了现有最优方法，在所有评价指标上均取得了更好成绩，并带动了如BEV感知等下游任务的提升。

Conclusion: 集成基础视觉模型与语言引导能够有效增强单目深度估计算法，多尺度特征融合及渐进对齐方式为MDE领域带来了性能新突破。

Abstract: Current self-supervised monocular depth estimation (MDE) approaches encounter
performance limitations due to insufficient semantic-spatial knowledge
extraction. To address this challenge, we propose Hybrid-depth, a novel
framework that systematically integrates foundation models (e.g., CLIP and
DINO) to extract visual priors and acquire sufficient contextual information
for MDE. Our approach introduces a coarse-to-fine progressive learning
framework: 1) Firstly, we aggregate multi-grained features from CLIP (global
semantics) and DINO (local spatial details) under contrastive language
guidance. A proxy task comparing close-distant image patches is designed to
enforce depth-aware feature alignment using text prompts; 2) Next, building on
the coarse features, we integrate camera pose information and pixel-wise
language alignment to refine depth predictions. This module seamlessly
integrates with existing self-supervised MDE pipelines (e.g., Monodepth2,
ManyDepth) as a plug-and-play depth encoder, enhancing continuous depth
estimation. By aggregating CLIP's semantic context and DINO's spatial details
through language guidance, our method effectively addresses feature granularity
mismatches. Extensive experiments on the KITTI benchmark demonstrate that our
method significantly outperforms SOTA methods across all metrics, which also
indeed benefits downstream tasks like BEV perception. Code is available at
https://github.com/Zhangwenyao1/Hybrid-depth.

</details>


### [72] [Instance-Aware Robust Consistency Regularization for Semi-Supervised Nuclei Instance Segmentation](https://arxiv.org/abs/2510.09329)
*Zenan Lin,Wei Li,Jintao Chen,Zihao Wu,Wenxiong Kang,Changxin Gao,Liansheng Wang,Jin-Gang Yu*

Main category: cs.CV

TL;DR: 本文提出了一个结合实例感知一致性正则化和病理形态先验的半监督核实例分割方法IRCR-Net，大幅提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 病理图像中细胞核分割是下游肿瘤微环境分析等任务的基础，但人工标注代价高昂且数据稀缺，现有半监督方法在实例一致性和利用先验知识上不足，还易引入伪标签噪声。

Method: 提出了IRCR-Net，引入了两种一致性机制：基于匹配的实例感知一致性（MIAC）和基于先验的实例感知一致性（PIAC），结合病理形态学先验，用于优化teacher-student网络的结果，对低质量伪标签进行筛除，提高训练鲁棒性，尤其在核密集分布和重叠情况下提升表现。

Result: 在多个公共数据集上，IRCR-Net极大提升了半监督核分割性能，部分场景下超过了全监督方法，优于现有半监督方法。

Conclusion: 引入实例感知一致性及形态先验，能有效优化半监督核实例分割，提升准确率并减少噪声，增强了方法的实用性和泛化能力。

Abstract: Nuclei instance segmentation in pathological images is crucial for downstream
tasks such as tumor microenvironment analysis. However, the high cost and
scarcity of annotated data limit the applicability of fully supervised methods,
while existing semi-supervised methods fail to adequately regularize
consistency at the instance level, lack leverage of the inherent prior
knowledge of pathological structures, and are prone to introducing noisy
pseudo-labels during training. In this paper, we propose an Instance-Aware
Robust Consistency Regularization Network (IRCR-Net) for accurate
instance-level nuclei segmentation. Specifically, we introduce the
Matching-Driven Instance-Aware Consistency (MIAC) and Prior-Driven
Instance-Aware Consistency (PIAC) mechanisms to refine the nuclei instance
segmentation result of the teacher and student subnetwork, particularly for
densely distributed and overlapping nuclei. We incorporate morphological prior
knowledge of nuclei in pathological images and utilize these priors to assess
the quality of pseudo-labels generated from unlabeled data. Low-quality
pseudo-labels are discarded, while high-quality predictions are enhanced to
reduce pseudo-label noise and benefit the network's robust training.
Experimental results demonstrate that the proposed method significantly
enhances semi-supervised nuclei instance segmentation performance across
multiple public datasets compared to existing approaches, even surpassing fully
supervised methods in some scenarios.

</details>


### [73] [Enhancing Infrared Vision: Progressive Prompt Fusion Network and Benchmark](https://arxiv.org/abs/2510.09343)
*Jinyuan Liu,Zihang Chen,Zhu Liu,Zhiying Jiang,Long Ma,Xin Fan,Risheng Liu*

Main category: cs.CV

TL;DR: 本文提出了一种全新的热红外图像增强方法，能同时处理多种复杂退化问题，并显著提升增强质量。


<details>
  <summary>Details</summary>
Motivation: 以往红外图像增强方法大多针对单一类型退化（如噪声、对比度、模糊），难以同时应对多重复杂退化情况，而常见的RGB图像增强方法由于成像机制差异，在红外领域表现有限。为此，作者重新审视了热成像机制，希望设计一个面向红外的综合增强体系。

Method: 作者提出了渐进式提示融合网络（PPFN），根据热成像过程生成prompt对，针对不同退化类型融合对应prompt对以调制模型特征，实现自适应处理多重退化。同时引入选择性渐进训练机制（SPT），分阶段提升模型在复杂退化下的复合处理能力，并提供全新多场景高质量红外基准测试集。

Result: 实验表明，本文方法在特定和复杂退化场景下都能带来显著视觉提升，针对复杂退化的整体性能提升高达8.76%。

Conclusion: 方法能有效去除噪声、提升结构细节和整体对比度，在红外图像增强领域具有突出表现，实验和基准数据支持其实用性与先进性。

Abstract: We engage in the relatively underexplored task named thermal infrared image
enhancement. Existing infrared image enhancement methods primarily focus on
tackling individual degradations, such as noise, contrast, and blurring, making
it difficult to handle coupled degradations. Meanwhile, all-in-one enhancement
methods, commonly applied to RGB sensors, often demonstrate limited
effectiveness due to the significant differences in imaging models. In sight of
this, we first revisit the imaging mechanism and introduce a Progressive Prompt
Fusion Network (PPFN). Specifically, the PPFN initially establishes prompt
pairs based on the thermal imaging process. For each type of degradation, we
fuse the corresponding prompt pairs to modulate the model's features, providing
adaptive guidance that enables the model to better address specific
degradations under single or multiple conditions. In addition, a Selective
Progressive Training (SPT) mechanism is introduced to gradually refine the
model's handling of composite cases to align the enhancement process, which not
only allows the model to remove camera noise and retain key structural details,
but also enhancing the overall contrast of the thermal image. Furthermore, we
introduce the most high-quality, multi-scenarios infrared benchmark covering a
wide range of scenarios. Extensive experiments substantiate that our approach
not only delivers promising visual results under specific degradation but also
significantly improves performance on complex degradation scenes, achieving a
notable 8.76\% improvement. Code is available at
https://github.com/Zihang-Chen/HM-TIR.

</details>


### [74] [Boosting Multi-modal Keyphrase Prediction with Dynamic Chain-of-Thought in Vision-Language Models](https://arxiv.org/abs/2510.09358)
*Qihang Ma,Shengyu Li,Jie Tang,Dingkang Yang,Shaodong Chen,Yingyi Zhang,Chao Feng,Jiao Ran*

Main category: cs.CV

TL;DR: 该论文针对传统多模态关键词生成（MMKP）任务中的局限，引入了视觉-语言模型（VLMs），通过动态和自适应的链式思考（CoT）策略提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 目前多模态关键词生成方法在缺失或未见场景下表现有限，现有基准评测过于高估模型能力，缺乏真实挑战性。

Method: 1）使用VLMs并结合零样本和有监督微调，测量基线性能；2）采用Fine-tune-CoT方法，通过优质CoT数据微调小模型，以提升推理能力；3）提出动态CoT，在训练过程中自适应注入CoT数据，避免推理过度。

Result: 在多个数据集上实验后发现，所提方法均有效提升了多模态关键词生成任务表现。

Conclusion: 利用动态CoT等新方法可以有效增强VLMs的关键词生成能力，提升其复杂推理性能，对MMKP任务具有积极意义。

Abstract: Multi-modal keyphrase prediction (MMKP) aims to advance beyond text-only
methods by incorporating multiple modalities of input information to produce a
set of conclusive phrases. Traditional multi-modal approaches have been proven
to have significant limitations in handling the challenging absence and unseen
scenarios. Additionally, we identify shortcomings in existing benchmarks that
overestimate model capability due to significant overlap in training tests. In
this work, we propose leveraging vision-language models (VLMs) for the MMKP
task. Firstly, we use two widely-used strategies, e.g., zero-shot and
supervised fine-tuning (SFT) to assess the lower bound performance of VLMs.
Next, to improve the complex reasoning capabilities of VLMs, we adopt
Fine-tune-CoT, which leverages high-quality CoT reasoning data generated by a
teacher model to finetune smaller models. Finally, to address the
"overthinking" phenomenon, we propose a dynamic CoT strategy which adaptively
injects CoT data during training, allowing the model to flexibly leverage its
reasoning capabilities during the inference stage. We evaluate the proposed
strategies on various datasets and the experimental results demonstrate the
effectiveness of the proposed approaches. The code is available at
https://github.com/bytedance/DynamicCoT.

</details>


### [75] [BLINK-Twice: You see, but do you observe? A Reasoning Benchmark on Visual Perception](https://arxiv.org/abs/2510.09361)
*Junyan Ye,Dongzhi Jiang,Jun He,Baichuan Zhou,Zilong Huang,Zhiyuan Yan,Hongsheng Li,Conghui He,Weijia Li*

Main category: cs.CV

TL;DR: 本文提出了BLINK-Twice视觉中心推理基准，用于评测多模态大模型在视觉推理上的能力，而不是仅仅依赖于基于语言的推理。该基准包含更细粒度、更具挑战性的感知任务，强调模型必须通过观察图片本身进行复杂推理。评测结果显示现有模型在该基准下表现有限，强调了视觉推理范式变革的必要性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型推理基准多偏重于语言推理，常把视觉输入当作可替换的上下文，并未真正考查模型的视觉推理与感知理解能力。因此需设计视觉为核心、摒弃外部知识、要求模型仅凭图像内容进行推理的全新基准，以推动多模态推理研究向更真实的视觉理解迈进。

Method: 1. 构建BLINK-Twice基准，包含七类视觉挑战任务，要求模型在细致观察基础上进行分析推理；2. 使用天然对抗图像对，强制模型依赖视觉内容而非语言模式；3. 提供标注化推理链，评测模型推理过程而非仅终极答案；4. 对比测试20款业界主流多模态模型，包括基础模型与推理增强模型，分析推理策略（如思维链、自我批判）对视觉推理表现的影响。

Result: 实验证明，BLINK-Twice对现有多模态模型是重大挑战。虽然引入链式推理和自我批判等策略能提升表现，但模型在本基准上推理过程不稳定、冗余明显。反复观察图像有助于提升性能，显示主动视觉交互能力（如模型o3所示）对于视觉推理十分关键。

Conclusion: BLINK-Twice揭示出当前多模态大模型视觉推理能力的短板，强调了模型需从“看见”到“观察”再到“推理”的转变。未来视觉推理模型应增强对图像内容的主动分析、细粒度感知和动态交互能力，推动视觉推理范式的革新。

Abstract: Recently, Multimodal Large Language Models (MLLMs) have made rapid progress,
particularly in enhancing their reasoning capabilities. However, existing
reasoning benchmarks still primarily assess language-based reasoning, often
treating visual input as replaceable context. To address this gap, we introduce
BLINK-Twice, a vision-centric reasoning benchmark grounded in challenging
perceptual tasks. Instead of relying on external knowledge, our tasks require
models to reason from visual content alone, shifting the focus from
language-based to image-grounded reasoning. Compared to prior perception
benchmarks, it moves beyond shallow perception ("see") and requires
fine-grained observation and analytical reasoning ("observe"). BLINK-Twice
integrates three core components: seven types of visual challenges for testing
visual reasoning, natural adversarial image pairs that enforce reliance on
visual content, and annotated reasoning chains for fine-grained evaluation of
the reasoning process rather than final answers alone. We evaluate 20 leading
MLLMs, including 12 foundation models and 8 reasoning-enhanced models.
BLINK-Twice poses a significant challenge to current models. While existing
reasoning strategies in the language space-such as chain-of-thought or
self-criticism can improve performance, they often result in unstable and
redundant reasoning. We observe that repeated image observation improves
performance across models, and active visual interaction, as demonstrated by
models like o3, highlights the need for a new paradigm for vision reasoning.
The dataset is publicly available at https://github.com/PicoTrex/BLINK-Twice

</details>


### [76] [Visibility-Aware Densification for 3D Gaussian Splatting in Dynamic Urban Scenes](https://arxiv.org/abs/2510.09364)
*Yikang Zhang,Rui Fan*

Main category: cs.CV

TL;DR: 本文提出了VAD-GS方法，解决了3D Gaussian splatting方法在城市场景中因初始点云稀疏带来的几何失真与重建缺陷，显著提升三维重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有3D Gaussian splatting方法对初始点云质量极为依赖，且需场景结构被完整均匀覆盖。但在动态、无边界的城市环境中，该假设往往不成立，导致重建失真与伪影，无法还原被遮挡或不可见的结构。

Method: 提出VAD-GS框架：通过基于体素的可见性推理检测不可靠结构，基于多样性视角选择高信息支持帧，利用基于patch匹配的多视角立体重建缺失结构。由此在初始点稀疏区域能生成新的高质量高斯点。

Result: 在Waymo和nuScenes数据集上大量实验表明，VAD-GS优于现有主流3DGS方法，对静态及动态目标的重建质量提升显著。

Conclusion: VAD-GS显著强化了城市场景下的3D Gaussian splatting能力，尤其擅长恢复稀疏或不完整点云区域的几何结构，并为三维重建领域带来新的思路。

Abstract: 3D Gaussian splatting (3DGS) has demonstrated impressive performance in
synthesizing high-fidelity novel views. Nonetheless, its effectiveness
critically depends on the quality of the initialized point cloud. Specifically,
achieving uniform and complete point coverage over the underlying scene
structure requires overlapping observation frustums, an assumption that is
often violated in unbounded, dynamic urban environments. Training Gaussian
models with partially initialized point clouds often leads to distortions and
artifacts, as camera rays may fail to intersect valid surfaces, resulting in
incorrect gradient propagation to Gaussian primitives associated with occluded
or invisible geometry. Additionally, existing densification strategies simply
clone and split Gaussian primitives from existing ones, incapable of
reconstructing missing structures. To address these limitations, we propose
VAD-GS, a 3DGS framework tailored for geometry recovery in challenging urban
scenes. Our method identifies unreliable geometry structures via voxel-based
visibility reasoning, selects informative supporting views through
diversity-aware view selection, and recovers missing structures via patch
matching-based multi-view stereo reconstruction. This design enables the
generation of new Gaussian primitives guided by reliable geometric priors, even
in regions lacking initial points. Extensive experiments on the Waymo and
nuScenes datasets demonstrate that VAD-GS outperforms state-of-the-art 3DGS
approaches and significantly improves the quality of reconstructed geometry for
both static and dynamic objects. Source code will be released upon publication.

</details>


### [77] [Minkowski-MambaNet: A Point Cloud Framework with Selective State Space Models for Forest Biomass Quantification](https://arxiv.org/abs/2510.09367)
*Jinxiang Tu,Dayong Ren,Fei Shi,Zhenhong Jia,Yahong Ren,Jiwei Qin,Fang He*

Main category: cs.CV

TL;DR: 提出了一种新的深度学习框架Minkowski-MambaNet，用于从原始激光雷达点云数据直接估算森林木材体积和地上生物量（AGB），显著提升了估算精度与稳健性。


<details>
  <summary>Details</summary>
Motivation: 森林生物量的准确测量对于碳循环监测至关重要，但当前利用激光雷达点云直接估算树木体积与AGB存在难以建模长距离依赖、树木难以区分等问题。作者希望解决这一难题。

Method: 提出将Mamba模型的选择性状态空间模型（SSM）集成进Minkowski网络架构，增强全局上下文与长距离依赖的表达能力，结合跳跃连接提升特征增强和训练收敛速度。该方法直接处理原始激光雷达点云，无需DTM。

Result: 在丹麦国家森林调查激光雷达数据上测试，Minkowski-MambaNet模型在体积和AGB估算上均显著优于当前最先进方法，且对边界伪影更具鲁棒性。

Conclusion: 该方法为大规模森林生物量分析提供了强有力的新工具，推动了基于激光雷达的森林资源清查创新发展。

Abstract: Accurate forest biomass quantification is vital for carbon cycle monitoring.
While airborne LiDAR excels at capturing 3D forest structure, directly
estimating woody volume and Aboveground Biomass (AGB) from point clouds is
challenging due to difficulties in modeling long-range dependencies needed to
distinguish trees.We propose Minkowski-MambaNet, a novel deep learning
framework that directly estimates volume and AGB from raw LiDAR. Its key
innovation is integrating the Mamba model's Selective State Space Model (SSM)
into a Minkowski network, enabling effective encoding of global context and
long-range dependencies for improved tree differentiation. Skip connections are
incorporated to enhance features and accelerate convergence.Evaluated on Danish
National Forest Inventory LiDAR data, Minkowski-MambaNet significantly
outperforms state-of-the-art methods, providing more accurate and robust
estimates. Crucially, it requires no Digital Terrain Model (DTM) and is robust
to boundary artifacts. This work offers a powerful tool for large-scale forest
biomass analysis, advancing LiDAR-based forest inventories.

</details>


### [78] [Utilizing dynamic sparsity on pretrained DETR](https://arxiv.org/abs/2510.09380)
*Reza Sedghi,Anand Subramoney,David Kappel*

Main category: cs.CV

TL;DR: 本文针对Transformer视觉模型推理效率低的问题，分析了DETR模型MLP层的稀疏性，并提出两种无需重新训练即可利用稀疏性的方法，显著减少了计算量。


<details>
  <summary>Details</summary>
Motivation: Transformer视觉模型（如DETR）在推理阶段计算开销大，限制了实际部署，作者关注能否直接利用神经元激活的稀疏性提升推理效率，却无需全部模型重训练。

Method: 本文首先提出静态指示器稀疏化（SIBS），依据已观测到的激活模式预测神经元失活，方法简单但受限于输入相关性。于是，进一步提出微门控稀疏化（MGS）：在预训练DETR基础上再训练一个轻量级门控层，动态预测神经元的稀疏激活。

Result: 在COCO数据集实验表明，MGS方法在保持甚至提升模型性能的同时，实现了85-95%的激活稀疏率，极大减少了计算量。

Conclusion: MGS作为一种无需全模型重训练、可自适应输入的稀疏化方法，可高效赋能预训练Vision Transformer模型的部署。

Abstract: Efficient inference with transformer-based models remains a challenge,
especially in vision tasks like object detection. We analyze the inherent
sparsity in the MLP layers of DETR and introduce two methods to exploit it
without retraining. First, we propose Static Indicator-Based Sparsification
(SIBS), a heuristic method that predicts neuron inactivity based on fixed
activation patterns. While simple, SIBS offers limited gains due to the
input-dependent nature of sparsity. To address this, we introduce Micro-Gated
Sparsification (MGS), a lightweight gating mechanism trained on top of a
pretrained DETR. MGS predicts dynamic sparsity using a small linear layer and
achieves up to 85 to 95% activation sparsity. Experiments on the COCO dataset
show that MGS maintains or even improves performance while significantly
reducing computation. Our method offers a practical, input-adaptive approach to
sparsification, enabling efficient deployment of pretrained vision transformers
without full model retraining.

</details>


### [79] [Mono4DEditor: Text-Driven 4D Scene Editing from Monocular Video via Point-Level Localization of Language-Embedded Gaussians](https://arxiv.org/abs/2510.09438)
*Jin-Chuan Shi,Chengye Su,Jiajun Wang,Ariel Shamir,Miao Wang*

Main category: cs.CV

TL;DR: Mono4DEditor是一种基于文本驱动的单目视频4D场景编辑新方法，可实现高质量、局部精准的场景编辑，并超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前基于文本编辑复杂动态4D场景，在局部语义精确度和未编辑内容完整性上仍存在挑战，有效的解决方案对于内容创作和虚拟环境意义重大。

Method: Mono4DEditor采用三维高斯与量化CLIP特征结合，形成可高效语义查询的4D动态表示；提出两阶段点级定位：先通过CLIP相似性筛选候选高斯，再精细定位其空间范围；最后利用扩散式视频编辑模型结合流场与涂鸦引导进行局部区域编辑，确保空间一致性和时间连贯性。

Result: 大量实验表明，Mono4DEditor可在各类场景和物体间实现灵活、精准的文本驱动编辑，并在未编辑区域外观及几何保持、灵活性和视觉真实度方面优于现有方法。

Conclusion: Mono4DEditor实现了单目视频4D场景的高质量、局部精准文本驱动编辑，有效保留未编辑区域属性，在灵活性和可视化质量上表现突出。

Abstract: Editing 4D scenes reconstructed from monocular videos based on text prompts
is a valuable yet challenging task with broad applications in content creation
and virtual environments. The key difficulty lies in achieving semantically
precise edits in localized regions of complex, dynamic scenes, while preserving
the integrity of unedited content. To address this, we introduce Mono4DEditor,
a novel framework for flexible and accurate text-driven 4D scene editing. Our
method augments 3D Gaussians with quantized CLIP features to form a
language-embedded dynamic representation, enabling efficient semantic querying
of arbitrary spatial regions. We further propose a two-stage point-level
localization strategy that first selects candidate Gaussians via CLIP
similarity and then refines their spatial extent to improve accuracy. Finally,
targeted edits are performed on localized regions using a diffusion-based video
editing model, with flow and scribble guidance ensuring spatial fidelity and
temporal coherence. Extensive experiments demonstrate that Mono4DEditor enables
high-quality, text-driven edits across diverse scenes and object types, while
preserving the appearance and geometry of unedited areas and surpassing prior
approaches in both flexibility and visual fidelity.

</details>


### [80] [Dynamic Weight-based Temporal Aggregation for Low-light Video Enhancement](https://arxiv.org/abs/2510.09450)
*Ruirui Lin,Guoxi Huang,Nantheera Anantrasirichai*

Main category: cs.CV

TL;DR: 本文提出了一种用于低光照视频增强的新方法DWTA-Net，该方法通过两阶段框架结合短期与长期时序信息，高效提升画面亮度、色彩和细节，同时有效降噪。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法在低光照环境下视频增强效果有限，尤其在降噪方面，多帧时序信息未被充分利用，导致实际场景中的噪声仍难以处理。

Method: DWTA-Net采用两阶段设计：第一阶段利用视觉状态空间块进行多帧对齐，增强局部一致性，恢复亮度、色彩与结构。第二阶段引入基于光流引导的动态权重时序聚合的递归细化模块，动态平衡静态与动态区域。此外，纹理自适应损失函数有助于保留细节并优化平滑区域。

Result: 在真实低光照视频数据集上的实验结果显示，DWTA-Net能显著抑制噪声和伪影，在增强画面质量方面优于现有先进方法。

Conclusion: DWTA-Net结合短期和长期时序信息，在低光照视频增强领域取得了更优的性能与视觉效果，有效解决了噪声和细节损失问题。

Abstract: Low-light video enhancement (LLVE) is challenging due to noise, low contrast,
and color degradations. Learning-based approaches offer fast inference but
still struggle with heavy noise in real low-light scenes, primarily due to
limitations in effectively leveraging temporal information. In this paper, we
address this issue with DWTA-Net, a novel two-stage framework that jointly
exploits short- and long-term temporal cues. Stage I employs Visual State-Space
blocks for multi-frame alignment, recovering brightness, color, and structure
with local consistency. Stage II introduces a recurrent refinement module with
dynamic weight-based temporal aggregation guided by optical flow, adaptively
balancing static and dynamic regions. A texture-adaptive loss further preserves
fine details while promoting smoothness in flat areas. Experiments on
real-world low-light videos show that DWTA-Net effectively suppresses noise and
artifacts, delivering superior visual quality compared with state-of-the-art
methods.

</details>


### [81] [D-TPT: Dimensional Entropy Maximization for Calibrating Test-Time Prompt Tuning in Vision-Language Models](https://arxiv.org/abs/2510.09473)
*Jisu Han,Wonjun Hwang*

Main category: cs.CV

TL;DR: 本文提出了一种新的方法，通过限制视觉-语言模型（VLMs）中特定主导特征维度的影响，提升模型在测试时适应（test-time prompt tuning）时的可靠性和校准表现。其核心是引入维度熵最大化的方法使文本特征分布更加均匀，从而弥补多模态间的差异。


<details>
  <summary>Details</summary>
Motivation: 随着测试时自适应技术的发展，视觉-语言模型在无标注目标域适应时表现不稳定。作者发现主要受一种主导特征维度影响的多模态间存在“模态间隙”，导致模型校准误差偏高，亟需提升模型在真实世界部署时的可靠性。

Method: 论文聚焦于对比学习型视觉-语言模型，分析文本和图像模态中主导特征维度带来的影响。提出通过“维度熵最大化”方法对文本特征分布进行正则化，使其趋于均匀化，减少对主导维度的依赖，从而优化prompt tuning时模型的校准能力。

Result: 实验表明，所提方法显著缓解了测试时Prompt调整带来的模型校准表现下降问题，在不同下游任务上，模型的适应能力和可靠性都有明显提升。

Conclusion: 维度熵最大化是一种简单有效的正则化技术，可用于提升视觉-语言模型在测试时Prompt调整中的可靠性和校准性，适合实际部署场景。

Abstract: Test-time adaptation paradigm provides flexibility towards domain shifts by
performing immediate adaptation on unlabeled target data from the source model.
Vision-Language Models (VLMs) leverage their generalization capabilities for
diverse downstream tasks, and test-time prompt tuning has emerged as a
prominent solution for adapting VLMs. In this work, we explore contrastive VLMs
and identify the modality gap caused by a single dominant feature dimension
across modalities. We observe that the dominant dimensions in both text and
image modalities exhibit high predictive sensitivity, and that constraining
their influence can improve calibration error. Building on this insight, we
propose dimensional entropy maximization that regularizes the distribution of
textual features toward uniformity to mitigate the dependency of dominant
dimensions. Our method alleviates the degradation of calibration performance in
test-time prompt tuning, offering a simple yet effective solution to enhance
the reliability of VLMs in real-world deployment scenarios.

</details>


### [82] [Few-shot multi-token DreamBooth with LoRa for style-consistent character generation](https://arxiv.org/abs/2510.09475)
*Ruben Pascual,Mikel Sesma-Sara,Aranzazu Jurio,Daniel Paternain,Mikel Galar*

Main category: cs.CV

TL;DR: 本论文提出了一种基于DreamBooth改进的生成方法，能够在保持艺术风格的同时生成无限数量的高质量新角色，扩展了动画、游戏等行业的创造力边界。


<details>
  <summary>Details</summary>
Motivation: 当前影视与创意行业希望借助AI技术，实现美术风格一致的海量原创角色生成，以促进动画、游戏等领域的创新，但受限于人力设计效率和训练样本有限。此外，现有文本到图像扩散模型难以细致还原角色风格和细节。

Method: 方法建立在DreamBooth微调技术基础上，提出多token策略，通过聚类为每个人物与整体风格分配独立token，并结合基于LoRA的高效参数微调，删除类别特定正则集，并在生成时引入随机token和embedding，实现对风格的良好学习和无限角色生成。

Result: 在五个小型专业数据集上，与主流方法在定量指标和人工评估上对比，新方法能生成保留参照角色独特风格的高质量多样化新角色，且人类评价显示生成结果更具美学一致性和创新潜力。

Conclusion: 本方法能有效提升创意行业AI角色生成能力，实现风格一致性和无限多样性的统一，助力动画、游戏等领域艺术创作的提升，具有广阔应用前景。

Abstract: The audiovisual industry is undergoing a profound transformation as it is
integrating AI developments not only to automate routine tasks but also to
inspire new forms of art. This paper addresses the problem of producing a
virtually unlimited number of novel characters that preserve the artistic style
and shared visual traits of a small set of human-designed reference characters,
thus broadening creative possibilities in animation, gaming, and related
domains. Our solution builds upon DreamBooth, a well-established fine-tuning
technique for text-to-image diffusion models, and adapts it to tackle two core
challenges: capturing intricate character details beyond textual prompts and
the few-shot nature of the training data. To achieve this, we propose a
multi-token strategy, using clustering to assign separate tokens to individual
characters and their collective style, combined with LoRA-based
parameter-efficient fine-tuning. By removing the class-specific regularization
set and introducing random tokens and embeddings during generation, our
approach allows for unlimited character creation while preserving the learned
style. We evaluate our method on five small specialized datasets, comparing it
to relevant baselines using both quantitative metrics and a human evaluation
study. Our results demonstrate that our approach produces high-quality, diverse
characters while preserving the distinctive aesthetic features of the reference
characters, with human evaluation further reinforcing its effectiveness and
highlighting the potential of our method.

</details>


### [83] [A methodology for clinically driven interactive segmentation evaluation](https://arxiv.org/abs/2510.09499)
*Parhom Esmaeili,Virginia Fernandez,Pedro Borges,Eli Gibson,Sebastien Ourselin,M. Jorge Cardoso*

Main category: cs.CV

TL;DR: 本文提出了一种基于临床实际的交互式分割评估方法，并开发了标准化评估流程，系统比较了当前医学影像体数据交互分割算法的表现。


<details>
  <summary>Details</summary>
Motivation: 当前医学影像体数据交互分割算法在评估上存在不一致且不切实际的问题，影响了方法间的公平比较，也不反映临床实际应用中的性能。因此需要提出更合理、标准化的评估体系。

Method: 作者提出基于临床场景的任务和指标定义方法，并开发了通用评估软件框架，构建标准评测流程。利用该框架，系统评测了多种当前主流交互式分割算法在复杂异构数据上的表现，并分析不同算法关键设计及行为对结果的影响。

Result: 实验发现：1) 处理用户交互时信息损失的最小化对模型鲁棒性影响极大；2) 自适应缩放机制提升鲁棒性及收敛速度；3) 验证时与训练时用户交互模式不一致会导致性能下降；4) 2D方法对二维或粗糙结构较好，3D方法更适用于大体积或形状不规则目标；5) 通用分割模型（如SAM2）在对比度差及结构复杂数据性能大幅下降。

Conclusion: 本文提出了更贴合临床实际的交互分割评测方法和标准化框架，有助于推进该领域算法的公平、客观评价与落地。针对不同任务和数据类型，应合理选择算法设计与策略。

Abstract: Interactive segmentation is a promising strategy for building robust,
generalisable algorithms for volumetric medical image segmentation. However,
inconsistent and clinically unrealistic evaluation hinders fair comparison and
misrepresents real-world performance. We propose a clinically grounded
methodology for defining evaluation tasks and metrics, and built a software
framework for constructing standardised evaluation pipelines. We evaluate
state-of-the-art algorithms across heterogeneous and complex tasks and observe
that (i) minimising information loss when processing user interactions is
critical for model robustness, (ii) adaptive-zooming mechanisms boost
robustness and speed convergence, (iii) performance drops if validation
prompting behaviour/budgets differ from training, (iv) 2D methods perform well
with slab-like images and coarse targets, but 3D context helps with large or
irregularly shaped targets, (v) performance of non-medical-domain models (e.g.
SAM2) degrades with poor contrast and complex shapes.

</details>


### [84] [Diagonal Artifacts in Samsung Images: PRNU Challenges and Solutions](https://arxiv.org/abs/2510.09509)
*David Vázquez-Padín,Fernando Pérez-González,Alejandro Martín-Del-Río*

Main category: cs.CV

TL;DR: 本文研究了三星部分智能手机拍摄的图像中存在的对角线伪影，这些伪影会影响基于PRNU的摄像头溯源验证。通过实验发现，某些Galaxy S和A系列有共同的伪影模式，会导致指纹冲突。但使用支持PRO模式且能获取RAW原图的设备，仍可可靠进行PRNU验证。同时，本文探讨了如何利用这些伪影辅助法取证。


<details>
  <summary>Details</summary>
Motivation: 基于PRNU（传感器噪声）进行摄像头来源验证是一种常见且有效的取证方法，但实际应用中会因设备图像处理引入的伪影影响其准确性。本研究动机在于揭示某些三星手机中普遍存在的对角线伪影给PRNU取证带来的挑战，并探索应对策略。

Method: 作者分析了多款三星Galaxy S和A系列手机，检测图像中的对角线伪影特征，通过比对不同设备间的伪影模式和指纹碰撞情况，测试了在有/无RAW图时对PRNU验证的影响，并提出了利用伪影进行进一步取证的方法。

Result: 发现部分Galaxy S系列和A系列存在相似的对角线伪影/模式，导致PRNU指纹互撞，影响可靠性。而带有PRO模式且能获取RAW图像的设备，因能绕开后期处理流程，PRNU验证结果依然可靠。此外还发现伪影可用于降低HDR图像的误检，以及辅助定位人像模式中人造虚化区域。

Conclusion: 三星部分机型的对角线伪影会导致PRNU溯源的误判，尤其是在没有RAW图的情况下。对于不支持RAW的中端手机和取证环境，这将限制PRNU取证法。与此同时，这些伪影本身也可作为法取证新工具，如辅助揭示图像处理痕迹或局部篡改。

Abstract: We investigate diagonal artifacts present in images captured by several
Samsung smartphones and their impact on PRNU-based camera source verification.
We first show that certain Galaxy S series models share a common pattern
causing fingerprint collisions, with a similar issue also found in some Galaxy
A models. Next, we demonstrate that reliable PRNU verification remains feasible
for devices supporting PRO mode with raw capture, since raw images bypass the
processing pipeline that introduces artifacts. This option, however, is not
available for the mid-range A series models or in forensic cases without access
to raw images. Finally, we outline potential forensic applications of the
diagonal artifacts, such as reducing misdetections in HDR images and localizing
regions affected by synthetic bokeh in portrait-mode images.

</details>


### [85] [PRNet: Original Information Is All You Have](https://arxiv.org/abs/2510.09531)
*PeiHuang Zheng,Yunlong Zhao,Zheng Cui,Yang Li*

Main category: cs.CV

TL;DR: 提出了一种新型的小目标检测网络PRNet，能够更好地保留和利用浅层空间特征，从而在计算资源有限的情况下显著提升航拍图像中的小目标检测准确率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在特征提取过程中浅层空间信息与语义信息难以有效对齐，导致小目标检测中信息丢失严重，易出现漏检和误检。已有FPN类方法仅能在后处理增强细节，但难以精准还原原图信息，阻碍语义融合。

Method: 提出PRNet检测框架，包括两个新模块：(1) PRN（Progressive Refinement Neck），通过主干网络复用和迭代细致优化，实现空间与语义信息对齐；(2) ESSamp（Enhanced SliceSamp），在下采样阶段通过优化重排与卷积，有效保留浅层信息。

Result: 在VisDrone、AI-TOD和UAVDT数据集上，PRNet在相似计算资源消耗下，相较主流方法取得了更高的检测准确率和效率表现，准确率-效率权衡优越。

Conclusion: PRNet能有效改善小目标检测任务中的特征对齐和信息保真问题，在实际应用中具备更优表现和推广价值。

Abstract: Small object detection in aerial images suffers from severe information
degradation during feature extraction due to limited pixel representations,
where shallow spatial details fail to align effectively with semantic
information, leading to frequent misses and false positives. Existing FPN-based
methods attempt to mitigate these losses through post-processing enhancements,
but the reconstructed details often deviate from the original image
information, impeding their fusion with semantic content. To address this
limitation, we propose PRNet, a real-time detection framework that prioritizes
the preservation and efficient utilization of primitive shallow spatial
features to enhance small object representations. PRNet achieves this via two
modules:the Progressive Refinement Neck (PRN) for spatial-semantic alignment
through backbone reuse and iterative refinement, and the Enhanced SliceSamp
(ESSamp) for preserving shallow information during downsampling via optimized
rearrangement and convolution. Extensive experiments on the VisDrone, AI-TOD,
and UAVDT datasets demonstrate that PRNet outperforms state-of-the-art methods
under comparable computational constraints, achieving superior
accuracy-efficiency trade-offs.

</details>


### [86] [FLOWING: Implicit Neural Flows for Structure-Preserving Morphing](https://arxiv.org/abs/2510.09537)
*Arthur Bizzi,Matias Grynberg,Vitor Matias,Daniel Perazzo,João Paulo Lima,Luiz Velho,Nuno Gonçalves,João Pereira,Guilherme Schardong,Tiago Novello*

Main category: cs.CV

TL;DR: 本文提出了一种名为FLOWING的新型变形方法，通过差分向量流实现图像和三维形状的结构化、高质量连续变形，显著提升配准准确性与训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于MLP的隐式神经表示（INR）在实现特征变形时，需要复杂的正则化来保证变形的连贯性与准确性，既消耗计算资源又易导致训练不稳定，难以实现高效和精细的特征对齐。为解决这些问题，需要一种能够自然保证可逆性、连贯性和结构保持的方法。

Method: FLOWING将变形任务重述为差分向量流的构建，通过在网络架构中直接编码流的结构性质，保障变形过程的连续性、可逆性和时序一致性，避免了繁琐的正则化。该方法适用于二维图像和三维物体的变形，提升了变形的结构保持和收敛速度。

Result: 在包括人脸、通用图像和高斯Splatting等多种应用中的实验表明，FLOWING不仅实现了业界领先的变形质量，还具备更快的收敛速度。

Conclusion: FLOWING框架以向量流为中心，通过网络结构创新，实现高效、结构友好的变形建模，为视觉和计算机图形的变形任务提供了新方案，具备广泛应用潜力。

Abstract: Morphing is a long-standing problem in vision and computer graphics,
requiring a time-dependent warping for feature alignment and a blending for
smooth interpolation. Recently, multilayer perceptrons (MLPs) have been
explored as implicit neural representations (INRs) for modeling such
deformations, due to their meshlessness and differentiability; however,
extracting coherent and accurate morphings from standard MLPs typically relies
on costly regularizations, which often lead to unstable training and prevent
effective feature alignment. To overcome these limitations, we propose FLOWING
(FLOW morphING), a framework that recasts warping as the construction of a
differential vector flow, naturally ensuring continuity, invertibility, and
temporal coherence by encoding structural flow properties directly into the
network architectures. This flow-centric approach yields principled and stable
transformations, enabling accurate and structure-preserving morphing of both 2D
images and 3D shapes. Extensive experiments across a range of applications -
including face and image morphing, as well as Gaussian Splatting morphing -
show that FLOWING achieves state-of-the-art morphing quality with faster
convergence. Code and pretrained models are available at
http://schardong.github.io/flowing.

</details>


### [87] [TC-LoRA: Temporally Modulated Conditional LoRA for Adaptive Diffusion Control](https://arxiv.org/abs/2510.09561)
*Minkyoung Cho,Ruben Ohana,Christian Jacobsen,Adityan Jothi,Min-Hung Chen,Z. Morley Mao,Ethem Can*

Main category: cs.CV

TL;DR: 本文提出了一种动态权重调控扩散模型TC-LoRA（Temporally Modulated Conditional LoRA），通过时间和用户条件动态调整模型权重，在提升生成图像质量和对条件的遵循方面优于以往静态激活调控方法。


<details>
  <summary>Details</summary>
Motivation: 现有可控扩散模型主要依赖静态结构和固定的条件注入方式，无法充分适应扩散过程各阶段不同的调控需求，限制了生成结果的细致性和对条件的响应能力。因此，亟需一种能够动态调控、适应各阶生成需求的新方法。

Method: 提出TC-LoRA框架，用超网络根据当前扩散步（时间）和用户条件动态生成LoRA权重适配器，直接调控主模型的权重，实现自适应的条件引导。该方法允许模型在扩散生成的不同阶段采用不同的调控策略。

Result: 实验表明，动态权重调控（TC-LoRA）在多个数据域上相较于传统静态激活调控方法，能显著提升生成保真度并更好地遵循空间条件。

Conclusion: TC-LoRA为扩散模型条件引导提供了一种通过权重深层功能适配的新范式，使条件控制与生成任务和阶段动态需求更好地对齐，拓展了扩散模型的可控生成能力。

Abstract: Current controllable diffusion models typically rely on fixed architectures
that modify intermediate activations to inject guidance conditioned on a new
modality. This approach uses a static conditioning strategy for a dynamic,
multi-stage denoising process, limiting the model's ability to adapt its
response as the generation evolves from coarse structure to fine detail. We
introduce TC-LoRA (Temporally Modulated Conditional LoRA), a new paradigm that
enables dynamic, context-aware control by conditioning the model's weights
directly. Our framework uses a hypernetwork to generate LoRA adapters
on-the-fly, tailoring weight modifications for the frozen backbone at each
diffusion step based on time and the user's condition. This mechanism enables
the model to learn and execute an explicit, adaptive strategy for applying
conditional guidance throughout the entire generation process. Through
experiments on various data domains, we demonstrate that this dynamic,
parametric control significantly enhances generative fidelity and adherence to
spatial conditions compared to static, activation-based methods. TC-LoRA
establishes an alternative approach in which the model's conditioning strategy
is modified through a deeper functional adaptation of its weights, allowing
control to align with the dynamic demands of the task and generative stage.

</details>


### [88] [FSP-DETR: Few-Shot Prototypical Parasitic Ova Detection](https://arxiv.org/abs/2510.09583)
*Shubham Trehan,Udhav Ramachandran,Akash Rao,Ruth Scimeca,Sathyanarayanan N. Aakur*

Main category: cs.CV

TL;DR: 本文提出了一种新型多功能生物医学目标检测框架FSP-DETR，能在标注样本极少和类别频繁变化的条件下，实现强大的小样本检测、开放集识别及跨任务泛化能力，并在多个检测任务上验证了其显著优越性。


<details>
  <summary>Details</summary>
Motivation: 生物医学领域面临标注数据稀缺与新类别频发，传统检测方法难以应对小样本、未知类别、以及跨任务泛化等实际需求，需要开发更通用且自适应的检测方法。

Method: 以无类别偏见的DETR为基础，通过原始支持图像构建类别原型，并利用数据增强视图及轻量级Transformer解码器学习嵌入空间。训练时联合优化原型匹配损失、对齐分离损失与KL散度正则项，提高特征区分力及模型鲁棒性；支持开放集识别和跨任务适配，推理阶段无需额外训练。

Result: 在新引入的包含20种寄生虫的重要基准和多个医学图像任务（卵类、血细胞、疟疾检测）中，FSP-DETR在小样本及开放集场景下明显优于以往的小样本和原型检测方法。

Conclusion: FSP-DETR框架有效解决了生物医学目标检测中样本稀缺和未知类别难题，具备强大的任务泛化和开放集识别能力，为该领域的检测应用提供了更通用的解决方案。

Abstract: Object detection in biomedical settings is fundamentally constrained by the
scarcity of labeled data and the frequent emergence of novel or rare
categories. We present FSP-DETR, a unified detection framework that enables
robust few-shot detection, open-set recognition, and generalization to unseen
biomedical tasks within a single model. Built upon a class-agnostic DETR
backbone, our approach constructs class prototypes from original support images
and learns an embedding space using augmented views and a lightweight
transformer decoder. Training jointly optimizes a prototype matching loss, an
alignment-based separation loss, and a KL divergence regularization to improve
discriminative feature learning and calibration under scarce supervision.
Unlike prior work that tackles these tasks in isolation, FSP-DETR enables
inference-time flexibility to support unseen class recognition, background
rejection, and cross-task adaptation without retraining. We also introduce a
new ova species detection benchmark with 20 parasite classes and establish
standardized evaluation protocols. Extensive experiments across ova, blood
cell, and malaria detection tasks demonstrate that FSP-DETR significantly
outperforms prior few-shot and prototype-based detectors, especially in
low-shot and open-set scenarios.

</details>


### [89] [Vision Language Models: A Survey of 26K Papers](https://arxiv.org/abs/2510.09586)
*Fengming Lin*

Main category: cs.CV

TL;DR: 本文通过分析2023-2025年CVPR、ICLR和NeurIPS三大顶会共26104篇论文，量化了AI/ML领域研究的宏观趋势，并公开了方法和词库以便复现与扩展。


<details>
  <summary>Details</summary>
Motivation: 当前AI领域发展极为迅速，为了定量把握研究主线和新兴方向，有必要通过系统、可重现的方法归纳整理顶会论文趋势。

Method: 作者标准化论文标题和摘要，利用人工设计的关键词词库进行短语保护与多标签赋值，从任务、架构、训练方式、目标、数据集及多模态性等多个维度详尽标注并统计趋势，对比不同会议和年份的变化。

Result: 主要发现三大趋势：1）多模态视觉-语言-大模型快速崛起，聚焦于指令跟随及推理；2）生成式方法稳步发展，扩散模型技术向可控性、蒸馏和效率聚集；3）三维和视频研究依然活跃，组成方式从NeRF转向Gaussian splatting，更关注人和智能体的理解。此外，VLM领域流行参数高效适配、轻量级桥接，训练策略更偏向微调强基座网络、损失目标由对比转向交叉熵等。

Conclusion: 本研究为理解AI前沿趋势提供了清晰、可复现的量化视角，并发布了资源以支持后续追踪和审计。但方法受限于词库覆盖率和仅基于摘要的分析，纵向信号在不同会议与时间内表现一致，有较高参考价值。

Abstract: We present a transparent, reproducible measurement of research trends across
26,104 accepted papers from CVPR, ICLR, and NeurIPS spanning 2023-2025. Titles
and abstracts are normalized, phrase-protected, and matched against a
hand-crafted lexicon to assign up to 35 topical labels and mine fine-grained
cues about tasks, architectures, training regimes, objectives, datasets, and
co-mentioned modalities. The analysis quantifies three macro shifts: (1) a
sharp rise of multimodal vision-language-LLM work, which increasingly reframes
classic perception as instruction following and multi-step reasoning; (2)
steady expansion of generative methods, with diffusion research consolidating
around controllability, distillation, and speed; and (3) resilient 3D and video
activity, with composition moving from NeRFs to Gaussian splatting and a
growing emphasis on human- and agent-centric understanding. Within VLMs,
parameter-efficient adaptation like prompting/adapters/LoRA and lightweight
vision-language bridges dominate; training practice shifts from building
encoders from scratch to instruction tuning and finetuning strong backbones;
contrastive objectives recede relative to cross-entropy/ranking and
distillation. Cross-venue comparisons show CVPR has a stronger 3D footprint and
ICLR the highest VLM share, while reliability themes such as efficiency or
robustness diffuse across areas. We release the lexicon and methodology to
enable auditing and extension. Limitations include lexicon recall and
abstract-only scope, but the longitudinal signals are consistent across venues
and years.

</details>


### [90] [SpaceVista: All-Scale Visual Spatial Reasoning from mm to km](https://arxiv.org/abs/2510.09606)
*Peiwen Sun,Shiqiang Lang,Dongming Wu,Yi Ding,Kaituo Feng,Huadai Liu,Zhen Ye,Rui Liu,Yun-Hui Liu,Jianan Wang,Xiangyu Yue*

Main category: cs.CV

TL;DR: 本文提出了一套集数据集构建、空间推理知识体系、尺度感知建模及渐进训练于一体的全新方案，力图提升大模型对全尺度多场景空间推理任务的智能水平。


<details>
  <summary>Details</summary>
Motivation: 当前室内空间推理研究虽有进展，但在多样化实际应用（如机器人和自动驾驶）中仍面临数据集依赖室内扫描及手工标注繁重、模型往往只适应单场景等难点。

Method: （1）提出基于专家驱动的自动化流程，生成跨5种空间尺度、涵盖19任务、含百余万问答对的大型数据集SpaceVista-1M；（2）人工准确标注和组装视频建立高质量benchmark；（3）新模型SpaceVista-7B引入尺度感知专家和渐进奖励，结合语义密集输入，实现泛化。

Result: 在自建的SpaceVista-Bench等五个基准数据集上，SpaceVista-7B展现出对不同尺度与场景的优秀泛化能力，性能具竞争力。

Conclusion: 本工作显著推动了全尺度空间推理能力及数据集构建方法的发展，为实际多场景空间智能任务提供了有价值的支持和资源。

Abstract: With the current surge in spatial reasoning explorations, researchers have
made significant progress in understanding indoor scenes, but still struggle
with diverse applications such as robotics and autonomous driving. This paper
aims to advance all-scale spatial reasoning across diverse scenarios by
tackling two key challenges: 1) the heavy reliance on indoor 3D scans and
labor-intensive manual annotations for dataset curation; 2) the absence of
effective all-scale scene modeling, which often leads to overfitting to
individual scenes. In this paper, we introduce a holistic solution that
integrates a structured spatial reasoning knowledge system, scale-aware
modeling, and a progressive training paradigm, as the first attempt to broaden
the all-scale spatial intelligence of MLLMs to the best of our knowledge. Using
a task-specific, specialist-driven automated pipeline, we curate over 38K video
scenes across 5 spatial scales to create SpaceVista-1M, a dataset comprising
approximately 1M spatial QA pairs spanning 19 diverse task types. While
specialist models can inject useful domain knowledge, they are not reliable for
evaluation. We then build an all-scale benchmark with precise annotations by
manually recording, retrieving, and assembling video-based data. However, naive
training with SpaceVista-1M often yields suboptimal results due to the
potential knowledge conflict. Accordingly, we introduce SpaceVista-7B, a
spatial reasoning model that accepts dense inputs beyond semantics and uses
scale as an anchor for scale-aware experts and progressive rewards. Finally,
extensive evaluations across 5 benchmarks, including our SpaceVista-Bench,
demonstrate competitive performance, showcasing strong generalization across
all scales and scenarios. Our dataset, model, and benchmark will be released on
https://peiwensun2000.github.io/mm2km .

</details>


### [91] [VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation](https://arxiv.org/abs/2510.09607)
*Shaoqi Dong,Chaoyou Fu,Haihan Gao,Yi-Fan Zhang,Chi Yan,Chu Wu,Xiaoyu Liu,Yunhang Shen,Jing Huo,Deqiang Jiang,Haoyu Cao,Yang Gao,Xing Sun,Ran He,Caifeng Shan*

Main category: cs.CV

TL;DR: 本文提出了一种利用知识蒸馏，使预训练视觉-语言模型（VLM）快速获得动作执行能力的新框架，既提高了泛化能力，也显著降低了训练成本，并在标准任务和真实机器人实验中取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 将视觉-语言模型应用于机器人操作需提升其动作执行能力，但从零训练代价高昂。因此，作者希望能通过有效方法将小型动作模型的动作知识转移到VLM，提升能力的同时降低训练成本。

Method: 提出了一种蒸馏框架：保留原VLM结构，仅增加动作token和状态编码器；采用两阶段训练，先将VLM隐状态与动作模型的动作空间对齐，复用预训练解码器，再选择性微调各模块以整合多模态输入和精确动作生成。

Result: 在仿真任务LIBERO上，平均任务成功率达97.3%，比现有方法高11.8%；在LIBERO-LONG上达93.5%，提升24.5%；真实机器人五项任务中，达82.0%成功率（提升17%），均超越教师模型和主流方法。

Conclusion: 通过动作知识蒸馏，大幅提升了VLM动作决策能力和训练效率，有效激发了VLM在机器人操作任务中的潜能。

Abstract: Vision-Language Action (VLA) models significantly advance robotic
manipulation by leveraging the strong perception capabilities of pretrained
vision-language models (VLMs). By integrating action modules into these
pretrained models, VLA methods exhibit improved generalization. However,
training them from scratch is costly. In this work, we propose a simple yet
effective distillation-based framework that equips VLMs with action-execution
capability by transferring knowledge from pretrained small action models. Our
architecture retains the original VLM structure, adding only an action token
and a state encoder to incorporate physical inputs. To distill action
knowledge, we adopt a two-stage training strategy. First, we perform
lightweight alignment by mapping VLM hidden states into the action space of the
small action model, enabling effective reuse of its pretrained action decoder
and avoiding expensive pretraining. Second, we selectively fine-tune the
language model, state encoder, and action modules, enabling the system to
integrate multimodal inputs with precise action generation. Specifically, the
action token provides the VLM with a direct handle for predicting future
actions, while the state encoder allows the model to incorporate robot dynamics
not captured by vision alone. This design yields substantial efficiency gains
over training large VLA models from scratch. Compared with previous
state-of-the-art methods, our method achieves 97.3% average success rate on
LIBERO (11.8% improvement) and 93.5% on LIBERO-LONG (24.5% improvement). In
real-world experiments across five manipulation tasks, our method consistently
outperforms the teacher model, achieving 82.0% success rate (17% improvement),
which demonstrate that action distillation effectively enables VLMs to generate
precise actions while substantially reducing training costs.

</details>


### [92] [StreamingVLM: Real-Time Understanding for Infinite Video Streams](https://arxiv.org/abs/2510.09608)
*Ruyi Xu,Guangxuan Xiao,Yukang Chen,Liuning He,Kelly Peng,Yao Lu,Song Han*

Main category: cs.CV

TL;DR: 本文提出了StreamingVLM，一种能够实时高效理解无限视觉输入的视频-语言模型，通过高效地缓存历史信息，解决了以往全局注意力和滑动窗口方法在长视频处理中的高算力和高延迟问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型难以高效处理持续增长的视频流，全局处理计算量大，滑动窗口导致上下文断裂或高延迟，因此需要能够实时、连续理解长视频的新方法。

Method: 提出StreamingVLM模型，在推理时通过重用注意力锚点状态、缓存短窗口的视觉token和长窗口的文本token来保持紧凑KV缓存，模型利用一种简单的有监督微调策略，在重叠短视频片段施加全局注意力，模拟推理时实际的注意力模式，无需在极长上下文上训练。

Result: 构建了含平均视频时长超2小时的新基准Inf-Streams-Eval，StreamingVLM在该基准上对抗GPT-4O mini取得66.18%的胜率，并能在一张NVIDIA H100显卡上保持最高8FPS的稳定实时性能。此外，无需特定微调的情况下模型在长视频和实时VQA基准上分别提升+4.30和+5.96。

Conclusion: StreamingVLM有效提升了视频-语言模型在无限流视频的实时理解与问答能力，表现优于现有领先模型，并显著降低了内存和延迟，相关方法和代码已开源。

Abstract: Vision-language models (VLMs) could power real-time assistants and autonomous
agents, but they face a critical challenge: understanding near-infinite video
streams without escalating latency and memory usage. Processing entire videos
with full attention leads to quadratic computational costs and poor performance
on long videos. Meanwhile, simple sliding window methods are also flawed, as
they either break coherence or suffer from high latency due to redundant
recomputation. In this paper, we introduce StreamingVLM, a model designed for
real-time, stable understanding of infinite visual input. Our approach is a
unified framework that aligns training with streaming inference. During
inference, we maintain a compact KV cache by reusing states of attention sinks,
a short window of recent vision tokens, and a long window of recent text
tokens. This streaming ability is instilled via a simple supervised fine-tuning
(SFT) strategy that applies full attention on short, overlapped video chunks,
which effectively mimics the inference-time attention pattern without training
on prohibitively long contexts. For evaluation, we build Inf-Streams-Eval, a
new benchmark with videos averaging over two hours that requires dense,
per-second alignment between frames and text. On Inf-Streams-Eval, StreamingVLM
achieves a 66.18% win rate against GPT-4O mini and maintains stable, real-time
performance at up to 8 FPS on a single NVIDIA H100. Notably, our SFT strategy
also enhances general VQA abilities without any VQA-specific fine-tuning,
improving performance on LongVideoBench by +4.30 and OVOBench Realtime by
+5.96. Code is available at https://github.com/mit-han-lab/streaming-vlm.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [93] [Enhancing Biomedical Named Entity Recognition using GLiNER-BioMed with Targeted Dictionary-Based Post-processing for BioASQ 2025 task 6](https://arxiv.org/abs/2510.08588)
*Ritesh Mehta*

Main category: cs.CL

TL;DR: 该论文研究了如何通过字典后处理方法改进GLiNER-BioMed模型在BioASQ数据集上的生物医学命名实体识别（BioNER）性能，但发现该方法在开发集上提升明显，在盲测试集上反而不如基线，表明泛化能力不足。


<details>
  <summary>Details</summary>
Motivation: 生物医学实体识别在科学文献信息抽取中非常重要，但不同类型的实体（如基因和化学物质）区分难度大，现有模型依然存在显著误判，亟需更有效的识别与纠错方法。

Method: 评估GLiNER-BioMed模型在BioASQ数据集上的表现，并提出针对易混淆实体类别的字典式后处理方案。同时探索条件随机场等其他方法，以对模型性能进一步分析对比。

Result: 该字典式后处理方法在开发集上将micro F1分数从0.79提高到0.83，但在盲测试集上提升未能泛化，分数降至0.77，低于基线模型的0.79。

Conclusion: 字典式后处理可以提升BioNER模型对已知数据的表现，但容易过拟合开发集，难以在新数据上泛化，说明未来需关注提升方法的泛化与适用性。

Abstract: Biomedical Named Entity Recognition (BioNER), task6 in BioASQ (A challenge in
large-scale biomedical semantic indexing and question answering), is crucial
for extracting information from scientific literature but faces hurdles such as
distinguishing between similar entity types like genes and chemicals. This
study evaluates the GLiNER-BioMed model on a BioASQ dataset and introduces a
targeted dictionary-based post-processing strategy to address common
misclassifications. While this post-processing approach demonstrated notable
improvement on our development set, increasing the micro F1-score from a
baseline of 0.79 to 0.83, this enhancement did not generalize to the blind test
set, where the post-processed model achieved a micro F1-score of 0.77 compared
to the baselines 0.79. We also discuss insights gained from exploring
alternative methodologies, including Conditional Random Fields. This work
highlights the potential of dictionary-based refinement for pre-trained BioNER
models but underscores the critical challenge of overfitting to development
data and the necessity of ensuring robust generalization for real-world
applicability.

</details>


### [94] [Less Diverse, Less Safe: The Indirect But Pervasive Risk of Test-Time Scaling in Large Language Models](https://arxiv.org/abs/2510.08592)
*Shahriar Kabir Nahin,Hadi Askari,Muhao Chen,Anshuman Chhabra*

Main category: cs.CL

TL;DR: 本文揭示了Test-Time Scaling（TTS）方法在候选响应多样性不足时，会导致生成不安全内容的风险大幅提升，并指出现有安全防护手段对此类问题防护有限。


<details>
  <summary>Details</summary>
Motivation: TTS 被用来提升大语言模型（LLM）推理能力，前提是依赖多样化的候选输出以增强可靠性。但作者发现若候选多样性下降，TTS 存在未被重视的失效风险。研究动机是验证和揭示多样性削弱下 TTS 的安全短板。

Method: 作者提出参考引导多样性削减协议（RefDiv），对 TTS 流水线进行压力测试。采用四个开源模型和两种主流 TTS 策略（蒙特卡洛树搜索、Best-of-N）进行广泛实验，并延伸至闭源模型，以验证现象普遍性。同时测试主流安全分类器对 RefDiv 生成对抗提示的检测能力。

Result: 实验显示，削弱多样性极大提高了 TTS 生成不安全内容的概率，且这一影响在多种模型和不同 TTS 策略下均成立，甚至超过通过高对抗性提示直接攻击模型的效果。主流的安全防线如 Llama-Guard 和 OpenAI Moderation API 难以识别 RefDiv 生成的对抗性输入。

Conclusion: TTS 的多样性失效是普遍且现实的安全隐患，现有安全机制难以防御。今后需关注并改进 TTS 方法的安全性，尤其要提升其对多样性削弱攻击的鲁棒性。

Abstract: Test-Time Scaling (TTS) improves LLM reasoning by exploring multiple
candidate responses and then operating over this set to find the best output. A
tacit premise behind TTS is that sufficiently diverse candidate pools enhance
reliability. In this work, we show that this assumption in TTS introduces a
previously unrecognized failure mode. When candidate diversity is curtailed,
even by a modest amount, TTS becomes much more likely to produce unsafe
outputs. We present a reference-guided diversity reduction protocol (RefDiv)
that serves as a diagnostic attack to stress test TTS pipelines. Through
extensive experiments across four open-source models (Qwen3, Mistral, Llama3.1,
Gemma3) and two widely used TTS strategies (Monte Carlo Tree Search and
Best-of-N), constraining diversity consistently signifies the rate at which TTS
produces unsafe results. The effect is often stronger than that produced by
prompts directly with high adversarial intent scores. This observed phenomenon
also transfers across TTS strategies and to closed-source models (e.g. OpenAI
o3 and Gemini-2.5-Pro), thus indicating that this is a general and extant
property of TTS rather than a model-specific artifact. Additionally, we find
that numerous widely used safety guardrail classifiers (e.g. Llama-Guard and
OpenAI Moderation API), are unable to flag the adversarial input prompts
generated by RefDiv, demonstrating that existing defenses offer limited
protection against this diversity-driven failure mode. Through this work, we
hope to motivate future research on designing robust TTS strategies that are
both effective and secure against diversity-targeted stress tests as
illustrated by RefDiv.

</details>


### [95] [Hierarchical Self-Supervised Representation Learning for Depression Detection from Speech](https://arxiv.org/abs/2510.08593)
*Yuxin Li,Eng Siong Chng,Cuntai Guan*

Main category: cs.CL

TL;DR: 本论文提出了一种利用多层自监督学习（SSL）特征的多任务架构HAREN-CTC，有效提升了语音抑郁症检测（SDD）的准确性，并在两个公开数据集上实现了新的SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有的SDD方法难以充分利用预训练自监督模型的多层特征，大多只用最后一层或单一层，这导致模型往往过拟合特定数据集，且无法系统捕捉复杂多样的抑郁症语音信号。

Method: 作者提出HAREN-CTC架构，核心包括两大模块：层次自适应聚类模块（将多层SSL特征重组为互补嵌入）和跨模态融合模块（通过跨层注意力建模层间依赖），结合CTC损失处理时序监督稀疏的问题，并在多任务学习框架下训练。

Result: 在DAIC-WOZ和MODMA两个公开数据集上，HAREN-CTC分别取得了0.81和0.82的macro F1分数，显著优于同类SOTA方法，并在标准及交叉验证的泛化设置下均表现领先。

Conclusion: HAREN-CTC能有效提取、融合自监督模型多层语音特征，显著提升语音抑郁症检测精度和泛化能力，为无创抑郁症辅助诊断提供了新方法和实践价值。

Abstract: Speech-based depression detection (SDD) is a promising, non-invasive
alternative to traditional clinical assessments. However, it remains limited by
the difficulty of extracting meaningful features and capturing sparse,
heterogeneous depressive cues over time. Pretrained self-supervised learning
(SSL) models such as WavLM provide rich, multi-layer speech representations,
yet most existing SDD methods rely only on the final layer or search for a
single best-performing one. These approaches often overfit to specific datasets
and fail to leverage the full hierarchical structure needed to detect subtle
and persistent depression signals.
  To address this challenge, we propose HAREN-CTC, a novel architecture that
integrates multi-layer SSL features using cross-attention within a multitask
learning framework, combined with Connectionist Temporal Classification loss to
handle sparse temporal supervision. HAREN-CTC comprises two key modules: a
Hierarchical Adaptive Clustering module that reorganizes SSL features into
complementary embeddings, and a Cross-Modal Fusion module that models
inter-layer dependencies through cross-attention. The CTC objective enables
alignment-aware training, allowing the model to track irregular temporal
patterns of depressive speech cues.
  We evaluate HAREN-CTC under both an upper-bound setting with standard data
splits and a generalization setting using five-fold cross-validation. The model
achieves state-of-the-art macro F1-scores of 0.81 on DAIC-WOZ and 0.82 on
MODMA, outperforming prior methods across both evaluation scenarios.

</details>


### [96] [Systematic Diagnosis of Brittle Reasoning in Large Language Models](https://arxiv.org/abs/2510.08595)
*V. S. Raghu Parupudi*

Main category: cs.CL

TL;DR: 本文提出了一种新框架，通过分析大型语言模型在数学推理中的逐步推理过程，发现其在程序性计算方面表现优异，但在需要组合推理的模式下表现脆弱，从而更细致地诊断和量化模型在数学理解方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的数学基准测试往往难以揭示大型语言模型在不同数学推理模式下具体的失效点。作者希望通过更细粒度的方法，深入了解模型在哪些推理技能上表现强、哪些方面存在明显缺陷，以推动模型能力提升和更安全可靠的实际应用。

Method: 首先，作者利用GPT-3.5-turbo模型在GSM8K数据集上生成结构化的逐步数学推理过程。随后，使用更强的分析模型（gpt-4o-mini）对这些推理过程的错误进行分类，并对每一步推理语句进行无监督聚类，挖掘出现的不同“推理模式”。

Result: 分析表明，模型在顺序计算等程序性推理模式下几乎达到完美准确率，但在涉及限制条件的组合推理等模式时表现明显下降，显示出“非人类式”的脆弱认知类型。

Conclusion: 该工作提供了一种更细致的评估数学理解的新方法，有助于明确界定和量化不同推理能力的可靠性，并为未来提高模型能力与实际应用的可靠性提供清晰的发展路径。

Abstract: A central question in artificial intelligence is the extent to which machine
learning models comprehend mathematics. To address this, we propose a novel
framework for measuring mathematical reasoning that moves beyond standard
benchmarks to diagnose specific failure points. Our method first generates
structured, step-by-step reasoning from gpt-3.5-turbo on the GSM8K dataset. We
then use a more capable analyst model, gpt-4o-mini, to categorize errors and,
crucially, perform an unsupervised clustering of every reasoning sentence to
identify emergent "reasoning modes." This analysis reveals a cognitive profile
with a stark, nonhuman-like brittleness: while the model achieves near-perfect
accuracy on procedural modes like sequential calculation, its performance on
modes requiring combinatorial reasoning with restrictions plummets. By
identifying and quantifying the reliability of these distinct reasoning skills,
our work provides a more granular method to evaluate mathematical comprehension
and offers a precise roadmap for developing new capabilities and more reliable
future applications.

</details>


### [97] [Confidence, Not Perplexity: A Better Metric for the Creative Era of LLMs](https://arxiv.org/abs/2510.08596)
*V. S. Raghu Parupudi*

Main category: cs.CL

TL;DR: 提出了一种新的评价指标Confidence Score（CS），用于更公平地评估生成模型的创意文本。实验结果显示，CS在评判创意生成上比传统无参考指标更不偏向陈词滥调。


<details>
  <summary>Details</summary>
Motivation: 传统无参考（reference-free）指标如self-perplexity，在评估生成模型时对创意文本有强烈的偏见，往往不利于新颖生成。因此亟需一种更公平的评测方法。

Method: 作者提出Confidence Score（CS），该指标基于模型输出的概率分布，设计为减少对创意生成的偏见。并在gpt-4o-mini模型及99条创意提示上，与传统流畅性指标进行了对比。

Result: 实验表明，CS偏好新颖回复的概率为19%，显著高于传统流畅性指标的0%（显著性区间[11.1%, 27.3%]）。此外，CS还能区分不同难度的任务，其置信区间无重叠。

Conclusion: CS指标能有效减轻传统指标对创意生成的偏见，同时保持流畅性等核心评价能力，为现代大模型的评估提供了更均衡的方法。

Abstract: Reference-free metrics like self-perplexity are strongly biased against
creative text generation. We propose the Confidence Score (CS), derived from a
model's output probability distribution, as a less biased alternative.
Experiments on gpt-4o-mini show that while fluency-based metrics prefer novel
responses in 0\% of cases on 99 creative prompts, our CS does so 19% of the
time, a statistically significant difference (95% CI for difference: [11.1%,
27.3%]). We also show that CS effectively distinguishes between easy, medium,
and hard tasks, confirmed by non-overlapping confidence intervals. The
Confidence Score thus mitigates the creativity bias of traditional metrics
while retaining their core evaluative strengths, offering a more balanced
assessment for modern LLMs.

</details>


### [98] [Recover-LoRA: Data-Free Accuracy Recovery of Degraded Language Models via Low-Rank Adaptation](https://arxiv.org/abs/2510.08600)
*Devleena Das,Rajeev Patwari,Ashish Sirasao*

Main category: cs.CL

TL;DR: 模型在推理过程中的优化（如量化、剪枝、格式/数据类型转换、模型导出和序列化）会导致模型性能下降。本文提出Recover-LoRA方法，通过对部分退化层使用合成数据和logit蒸馏训练LoRA适配器，有效恢复退化小语言模型的准确率，结果显示可提升5-17%。


<details>
  <summary>Details</summary>
Motivation: 实际部署中，为了提升效率，经常对模型进行量化、剪枝等优化，但这些操作常导致性能下降，目前业界更多关注于提高量化鲁棒性，缺乏通用型的性能恢复方法。

Method: 提出Recover-LoRA方法：利用合成数据进行logit蒸馏，只在部分选择的网络层引入LoRA适配器，将退化模型与全精度模型对齐。此方法具有轻量级和数据集无关性。

Result: 在多种小语言模型（涵盖多头注意力MHA和组查询注意力GQA架构）以及不同评测数据集上测试，Recover-LoRA能将因优化退化的模型准确率提升5-17%。

Conclusion: Recover-LoRA是一种简单、通用的精度恢复方法，能显著提升由于各种优化操作导致退化的小语言模型的准确率，为模型部署带来实际价值。

Abstract: Inference optimizations such as quantization, pruning, format and datatype
conversion, model export, and serialization can lead to functional degradations
in language model task performance. While most efforts on performance recovery
for deployment focus on robust quantization techniques, we focus on recovering
model accuracies from any sources that degrade model weights, such as improper
model serialization. In this work, we propose Recover-LoRA, a lightweight and
dataset agnostic method to recover accuracy in degraded models. Recover-LoRA
uses synthetic data and logit distillation to learn LoRA adapters on selective
layers that facilitate aligning the degraded model to its full precision model.
We investigate the utility of Recover-LoRA across a diverse set of small
language models (SLMs), including models with varying attention architectures,
multi-head attention (MHA) and group-query attention (GQA), as well as several
evaluation datasets. Our results show that Recover-LoRA recovers model
accuracies by 5-17% on MHA and GQA SLMs.

</details>


### [99] [Mnemosyne: An Unsupervised, Human-Inspired Long-Term Memory Architecture for Edge-Based LLMs](https://arxiv.org/abs/2510.08601)
*Aneesh Jonelagadda,Christina Hahn,Haoze Zheng,Salvatore Penachio*

Main category: cs.CL

TL;DR: 本文提出了一种适用于边缘设备的大型语言模型（LLM）长期记忆系统Mnemosyne，通过类人机制提升了对话的真实性与记忆能力，显著优于现有检索增强方法。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的长期记忆依赖简单扩张上下文或静态检索，难以适用于资源受限的边缘设备，且在类似医疗等对话场景中表现有限。因此，需求设计更高效、类人且能适应边缘部署的长期记忆方案。

Method: Mnemosyne采用图结构存储，结合可模块化的内容/冗余过滤器、记忆提交与修剪机制，实现带概率的、具时间衰减及刷新的人类记忆模型。此外引入核心摘要，紧凑表达用户个性与领域特征，优化长程信息保存与检索效率。

Result: 在医疗领域长时对话测试中，Mnemosyne在真实性及长期记忆能力的盲测人类评估里赢得65.8%胜率（对比RAG基线31.1%）。LoCoMo基准上时间推理和单跳检索表现领先，综合得分54.6%居次高，超越多种公开基线。

Conclusion: Mnemosyne证实无监督、易迁移且适配边缘设备的记忆架构，可大幅提升信息召回、时间推理与自然对话表现，对实际长期任务如医疗助理具有重要应用价值。

Abstract: Long-term memory is essential for natural, realistic dialogue. However,
current large language model (LLM) memory systems rely on either brute-force
context expansion or static retrieval pipelines that fail on edge-constrained
devices. We introduce Mnemosyne, an unsupervised, human-inspired long-term
memory architecture designed for edge-based LLMs. Our approach uses
graph-structured storage, modular substance and redundancy filters, memory
committing and pruning mechanisms, and probabilistic recall with temporal decay
and refresh processes modeled after human memory. Mnemosyne also introduces a
concentrated "core summary" efficiently derived from a fixed-length subset of
the memory graph to capture the user's personality and other domain-specific
long-term details such as, using healthcare application as an example,
post-recovery ambitions and attitude towards care. Unlike existing
retrieval-augmented methods, Mnemosyne is designed for use in longitudinal
healthcare assistants, where repetitive and semantically similar but temporally
distinct conversations are limited by naive retrieval. In experiments with
longitudinal healthcare dialogues, Mnemosyne demonstrates the highest win rate
of 65.8% in blind human evaluations of realism and long-term memory capability
compared to a baseline RAG win rate of 31.1%. Mnemosyne also achieves current
highest LoCoMo benchmark scores in temporal reasoning and single-hop retrieval
compared to other same-backboned techniques. Further, the average overall score
of 54.6% was second highest across all methods, beating commonly used Mem0 and
OpenAI baselines among others. This demonstrates that improved factual recall,
enhanced temporal reasoning, and much more natural user-facing responses can be
feasible with an edge-compatible and easily transferable unsupervised memory
architecture.

</details>


### [100] [Human Texts Are Outliers: Detecting LLM-generated Texts via Out-of-distribution Detection](https://arxiv.org/abs/2510.08602)
*Cong Zeng,Shengkun Tang,Yuanzhou Chen,Zhiqiang Shen,Wenchao Yu,Xujiang Zhao,Haifeng Chen,Wei Cheng,Zhiqiang Xu*

Main category: cs.CL

TL;DR: 该论文提出将AI文本检测任务从二分类重构为异常检测（OOD）问题，显著提升了跨领域和模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有AI文本检测方法多采用二分类，将判断问题简化为“人类/AI生成文本”分类，但忽视了人类文本的多样性与分布不统一，导致泛化能力差。需要新的方法更好地区分AI与真实人类文本。

Method: 作者提出将检测任务重构为OOD异常检测，将AI生成文本视作分布内部样本（ID），而人类文本是分布外样本（OOD）。采用深度单类学习（DeepSVDD、HRN）和基于能量的评分方法，实现检测器的训练和判别。

Result: 所提方法在多个数据集上表现优异：在DeepFake数据集上实现98.3% AUROC和AUPR，FPR95为8.9%。同时在多语言、攻击和未见过的模型及领域场景下测试，展现出强鲁棒性和泛化能力。

Conclusion: 将AI检测重构为OOD任务更准确刻画了检测目标，提出的框架显著优于传统二分类检测器，泛化强。代码及模型将公开，利于后续研究。

Abstract: The rapid advancement of large language models (LLMs) such as ChatGPT,
DeepSeek, and Claude has significantly increased the presence of AI-generated
text in digital communication. This trend has heightened the need for reliable
detection methods to distinguish between human-authored and machine-generated
content. Existing approaches both zero-shot methods and supervised classifiers
largely conceptualize this task as a binary classification problem, often
leading to poor generalization across domains and models. In this paper, we
argue that such a binary formulation fundamentally mischaracterizes the
detection task by assuming a coherent representation of human-written texts. In
reality, human texts do not constitute a unified distribution, and their
diversity cannot be effectively captured through limited sampling. This causes
previous classifiers to memorize observed OOD characteristics rather than learn
the essence of `non-ID' behavior, limiting generalization to unseen
human-authored inputs. Based on this observation, we propose reframing the
detection task as an out-of-distribution (OOD) detection problem, treating
human-written texts as distributional outliers while machine-generated texts
are in-distribution (ID) samples. To this end, we develop a detection framework
using one-class learning method including DeepSVDD and HRN, and score-based
learning techniques such as energy-based method, enabling robust and
generalizable performance. Extensive experiments across multiple datasets
validate the effectiveness of our OOD-based approach. Specifically, the
OOD-based method achieves 98.3% AUROC and AUPR with only 8.9% FPR95 on DeepFake
dataset. Moreover, we test our detection framework on multilingual, attacked,
and unseen-model and -domain text settings, demonstrating the robustness and
generalizability of our framework. Code, pretrained weights, and demo will be
released.

</details>


### [101] [YpathRAG:A Retrieval-Augmented Generation Framework and Benchmark for Pathology](https://arxiv.org/abs/2510.08603)
*Deshui Yu,Yizhi Wang,Saihui Jin,Taojie Zhu,Fanyi Zeng,Wen Qian,Zirui Huang,Jingli Ouyang,Jiameng Li,Zhen Song,Tian Guan,Yonghong He*

Main category: cs.CL

TL;DR: 本文提出为病理学领域设计的RAG（检索增强生成）系统YpathRAG，通过构建大型病理文本库和优化检索机制，显著提升了医学相关LLM的事实性和召回率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在通用任务表现优秀，但在如病理学等高门槛领域，仍容易出现幻觉和事实错误；现有方法主要靠领域微调，无法根本提升知识边界或牢靠支撑证据。为此，作者希望搭建一个高质量的病理知识库，并设计更强的检索与判断机制，提高医学AI的可靠性。

Method: 作者构建了覆盖28个子领域、153万段落的病理向量数据库，提出了YpathRAG系统，包括双通道混合检索（密集+BGE-M3向量检索和稀疏的词表引导检索）和LLM辅助的支持性证据判断模块，形成了一个检索-判断-生成闭环；并发布了两个评测集（YpathR, YpathQA-M）。

Result: 在YpathR数据集上，YpathRAG的Recall@5达98.64%，比基线提升23个百分点；在最有挑战性的YpathQA-M数据集上，平均提升了医学和通用LLM准确率9.0-15.6%。

Conclusion: YpathRAG提升了检索质量和事实可靠性，为病理学RAG系统的构建和评测提供了可扩展且具解释性的范式。

Abstract: Large language models (LLMs) excel on general tasks yet still hallucinate in
high-barrier domains such as pathology. Prior work often relies on domain
fine-tuning, which neither expands the knowledge boundary nor enforces
evidence-grounded constraints. We therefore build a pathology vector database
covering 28 subfields and 1.53 million paragraphs, and present YpathRAG, a
pathology-oriented RAG framework with dual-channel hybrid retrieval (BGE-M3
dense retrieval coupled with vocabulary-guided sparse retrieval) and an
LLM-based supportive-evidence judgment module that closes the
retrieval-judgment-generation loop. We also release two evaluation benchmarks,
YpathR and YpathQA-M. On YpathR, YpathRAG attains Recall@5 of 98.64%, a gain of
23 percentage points over the baseline; on YpathQA-M, a set of the 300 most
challenging questions, it increases the accuracies of both general and medical
LLMs by 9.0% on average and up to 15.6%. These results demonstrate improved
retrieval quality and factual reliability, providing a scalable construction
paradigm and interpretable evaluation for pathology-oriented RAG.

</details>


### [102] [LatentBreak: Jailbreaking Large Language Models through Latent Space Feedback](https://arxiv.org/abs/2510.08604)
*Raffaele Mura,Giorgio Piras,Kamilė Lukošiūtė,Maura Pintor,Amin Karbasi,Battista Biggio*

Main category: cs.CL

TL;DR: 本文提出了一种名为LatentBreak的新型越狱攻击方法，能够有效规避基于困惑度（perplexity）筛查的防御机制。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的越狱攻击常被困惑度过滤器检测并阻断，亟需新的越狱手段绕过该类防御。

Method: LatentBreak采用白盒攻击方式，通过在潜在空间中最小化与无害请求的距离，替换输入提示词为语义等价词，生成低困惑度且更自然的对抗性提示，而非传统的高困惑度后缀或长模板。

Result: 实验结果显示，LatentBreak生成的提示更短、困惑度更低，在多个安全对齐模型中对抗困惑度筛查防御的效果优于现有越狱算法。

Conclusion: LatentBreak不仅提升了越狱攻击的隐蔽性，还展现了针对困惑度防御的优越性，为大模型安全防护提出新的挑战。

Abstract: Jailbreaks are adversarial attacks designed to bypass the built-in safety
mechanisms of large language models. Automated jailbreaks typically optimize an
adversarial suffix or adapt long prompt templates by forcing the model to
generate the initial part of a restricted or harmful response. In this work, we
show that existing jailbreak attacks that leverage such mechanisms to unlock
the model response can be detected by a straightforward perplexity-based
filtering on the input prompt. To overcome this issue, we propose LatentBreak,
a white-box jailbreak attack that generates natural adversarial prompts with
low perplexity capable of evading such defenses. LatentBreak substitutes words
in the input prompt with semantically-equivalent ones, preserving the initial
intent of the prompt, instead of adding high-perplexity adversarial suffixes or
long templates. These words are chosen by minimizing the distance in the latent
space between the representation of the adversarial prompt and that of harmless
requests. Our extensive evaluation shows that LatentBreak leads to shorter and
low-perplexity prompts, thus outperforming competing jailbreak algorithms
against perplexity-based filters on multiple safety-aligned models.

</details>


### [103] [Toward a Safer Web: Multilingual Multi-Agent LLMs for Mitigating Adversarial Misinformation Attacks](https://arxiv.org/abs/2510.08605)
*Nouar Aldahoul,Yasir Zaki*

Main category: cs.CL

TL;DR: 本文探讨通过跨语言切换、翻译、查询长度膨胀和结构重组等新型对抗性策略对假信息检测系统的攻击与防御，并提出了可在线部署的多语言、多智能体大模型检测框架。


<details>
  <summary>Details</summary>
Motivation: 数字平台上的虚假信息快速传播，威胁公共舆论和决策。已有研究关注了假信息检测中的对抗攻击，但针对跨语言、结构重组等变换形式的系统性研究尚缺乏，因此本文希望填补这一空白。

Method: 研究者设计了一套多语言（涵盖英语、法语、西班牙语、阿拉伯语、印地语和中文）、多智能体的大语言模型检测框架，采用检索增强生成（RAG）策略，可作为web插件部署到在线平台。对抗攻击形式包括跨语言切换与翻译、查询长度扩展、结构化重组（如转为选择题形式）等。

Result: 该框架能有效应对多种复杂对抗攻击场景，并能集成到现实网络环境中进行在线检测。实验表明，多语言、多智能体与RAG技术的结合显著提升了假信息检测的适应性和鲁棒性。

Conclusion: AI驱动的多语言假信息检测系统对维护网络事实完整性至关重要。插件化部署方式证明了相关技术在真实环境中的可行性和推广潜力。

Abstract: The rapid spread of misinformation on digital platforms threatens public
discourse, emotional stability, and decision-making. While prior work has
explored various adversarial attacks in misinformation detection, the specific
transformations examined in this paper have not been systematically studied. In
particular, we investigate language-switching across English, French, Spanish,
Arabic, Hindi, and Chinese, followed by translation. We also study query length
inflation preceding summarization and structural reformatting into
multiple-choice questions. In this paper, we present a multilingual,
multi-agent large language model framework with retrieval-augmented generation
that can be deployed as a web plugin into online platforms. Our work
underscores the importance of AI-driven misinformation detection in
safeguarding online factual integrity against diverse attacks, while showcasing
the feasibility of plugin-based deployment for real-world web applications.

</details>


### [104] [Centering Emotion Hotspots: Multimodal Local-Global Fusion and Cross-Modal Alignment for Emotion Recognition in Conversations](https://arxiv.org/abs/2510.08606)
*Yu Liu,Hanlei Shi,Haoxun Li,Yuqing Sun,Yuxuan Ding,Linlin Gong,Leyuan Qu,Taihao Li*

Main category: cs.CL

TL;DR: 该论文提出了一种以“情感热点”为中心的新方法，提升了多模态会话情感识别（ERC）的性能。模型聚焦于检测文本、音频和视频中每句话的情感热点，并采用热点门控融合和混合对齐机制，有效捕捉和对齐关键线索，实验结果显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 会话情感识别任务面临判别线索稀疏、局部且跨模态异步的问题，现有方法难以充分捕获并融合这些局部显著信息。因此作者希望通过发现和建模情感热点，提升关键区域的信息融合和对齐能力，从而提高ERC效果。

Method: 方法包括三个核心：1）在文本、音频、视频三种模态分别检测每句话中的情感热点；2）将这些热点线索与全局特征通过热点门控融合（HGF）模块结合；3）利用混合对齐机制（MoA）自动匹配多模态信息，同时用跨模态图编码对话结构，提升对话上下文建模能力。

Result: 在标准ERC基准数据集上，本文方法在各项指标上均优于强劲的现有基线模型；消融实验进一步验证了HGF和MoA模块在模型性能提升中的关键作用。

Conclusion: 该方法明确验证了以热点为中心的多模态融合新视角在ERC任务中的有效性，为未来多模态情感理解研究提供了新的思路和方法参考。

Abstract: Emotion Recognition in Conversations (ERC) is hard because discriminative
evidence is sparse, localized, and often asynchronous across modalities. We
center ERC on emotion hotspots and present a unified model that detects
per-utterance hotspots in text, audio, and video, fuses them with global
features via Hotspot-Gated Fusion, and aligns modalities using a routed
Mixture-of-Aligners; a cross-modal graph encodes conversational structure. This
design focuses modeling on salient spans, mitigates misalignment, and preserves
context. Experiments on standard ERC benchmarks show consistent gains over
strong baselines, with ablations confirming the contributions of HGF and MoA.
Our results point to a hotspot-centric view that can inform future multimodal
learning, offering a new perspective on modality fusion in ERC.

</details>


### [105] [MMA-ASIA: A Multilingual and Multimodal Alignment Framework for Culturally-Grounded Evaluation](https://arxiv.org/abs/2510.08608)
*Weihua Zheng,Zhengyuan Liu,Tanmoy Chakraborty,Weiwen Xu,Xiaoxue Gao,Bryan Chen Zhengyu Tan,Bowei Zou,Chang Liu,Yujia Hu,Xing Xie,Xiaoyuan Yi,Jing Yao,Chaojun Wang,Long Li,Rui Liu,Huiyao Liu,Koji Inoue,Ryuichi Sumida,Tatsuya Kawahara,Fan Xu,Lingyu Ye,Wei Tian,Dongjun Kim,Jimin Jung,Jaehyung Seo,Nadya Yuki Wangsajaya,Pham Minh Duc,Ojasva Saxena,Palash Nandi,Xiyan Tao,Wiwik Karlina,Tuan Luong,Keertana Arun Vasan,Roy Ka-Wei Lee,Nancy F. Chen*

Main category: cs.CL

TL;DR: 本文提出了MMA-ASIA框架，系统评估了大语言模型在亚洲多文化多模态情境下的理解和推理能力，涵盖8国和10种语言，共2.7万多项多步骤推理题，并建立了跨文本、图像和语音三模态对齐的数据集和多维评估方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）虽然在全球广泛应用，但其在西方以外的多文化环境中的多模态理解和推理能力明显衰减，尤其是在亚洲等高多样性、低资源设定中。缺乏针对这些环境的评测工具和标准，导致模型难以普适和可靠应用。

Method: 作者构建了名为MMA-ASIA的多模态多国语言对齐的数据集，覆盖8个亚洲国家10种语言，含27000个多步骤、多模态的选择题，并保证题目间文本、图片和语音的输入对齐。提出五维度评测体系，设计地检验文化意识差异、跨语言一致性、跨模态一致性、知识泛化和文化推理基础，辅以针对“捷径推理”的验证模块和模型剖析方法。

Result: MMA-ASIA数据集及其评测方案能够有效揭示主流大模型在亚洲多模态、多语言文化理解能力上的实际表现及偏差。通过VPR等方法，分析了模型在语言、模态间能力分化的根源，提出了可执行的模型改进建议。

Conclusion: MMA-ASIA填补了多模态大模型在亚洲多文化场景下缺乏系统评测工具的空白，为未来构建文化可靠的多模态大模型打下基础，同时为后续模型优化和公平性提升提供了评估和方法论支持。

Abstract: Large language models (LLMs) are now used worldwide, yet their multimodal
understanding and reasoning often degrade outside Western, high-resource
settings. We propose MMA-ASIA, a comprehensive framework to evaluate LLMs'
cultural awareness with a focus on Asian contexts. MMA-ASIA centers on a
human-curated, multilingual, and multimodally aligned multiple-choice benchmark
covering 8 Asian countries and 10 languages, comprising 27,000 questions; over
79 percent require multi-step reasoning grounded in cultural context, moving
beyond simple memorization. To our knowledge, this is the first dataset aligned
at the input level across three modalities: text, image (visual question
answering), and speech. This enables direct tests of cross-modal transfer.
Building on this benchmark, we propose a five-dimensional evaluation protocol
that measures: (i) cultural-awareness disparities across countries, (ii)
cross-lingual consistency, (iii) cross-modal consistency, (iv) cultural
knowledge generalization, and (v) grounding validity. To ensure rigorous
assessment, a Cultural Awareness Grounding Validation Module detects "shortcut
learning" by checking whether the requisite cultural knowledge supports correct
answers. Finally, through comparative model analysis, attention tracing, and an
innovative Vision-ablated Prefix Replay (VPR) method, we probe why models
diverge across languages and modalities, offering actionable insights for
building culturally reliable multimodal LLMs.

</details>


### [106] [GraphGhost: Tracing Structures Behind Large Language Models](https://arxiv.org/abs/2510.08613)
*Xinnan Dai,Kai Guo,Chung-Hsiang Lo,Shenglai Zeng,Jiayuan Ding,Dongsheng Luo,Subhabrata Mukherjee,Jiliang Tang*

Main category: cs.CL

TL;DR: 本文提出了GraphGhost框架，以图结构方式分析LLM内部的推理机制，并表明关键神经元节点对推理有决定作用。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM展现了卓越的推理能力，但其结构性推理机制尚不清晰。本文旨在用图结构方法解释和揭示这背后的结构机制。

Method: 作者将神经元激活及其信号传播表示为图，并采用PageRank等图算法分析LLM推理过程，同时通过结构干预实验考察关键神经元的作用。

Result: GraphGhost能区分不同LLM模型间的通用及特有推理行为，结构干预显示关键节点修改会导致推理崩溃，逻辑和语义理解发生明显变化。

Conclusion: GraphGhost为分析和干预LLM的推理结构提供了有力工具，有助于深入理解LLM推理的结构基础。

Abstract: Large Language Models (LLMs) demonstrate remarkable reasoning capabilities,
yet the structural mechanisms underlying these abilities remain under explored.
In this work, we introduce GraphGhost, a unified framework that represents
neuron activations and their signal propagation as graphs, explaining how LLMs
capture structural semantics from sequential inputs and generate outputs
through structurally consistent mechanisms. This graph-based perspective
enables us to employ graph algorithms such as PageRank to characterize the
properties of LLMs, revealing both shared and model-specific reasoning
behaviors across diverse datasets. We further identify the activated neurons
within GraphGhost and evaluate them through structural interventions, showing
that edits to key neuron nodes can trigger reasoning collapse, altering both
logical flow and semantic understanding. Together, these contributions position
GraphGhost as a powerful tool for analyzing, intervening in, and ultimately
understanding the structural foundations of reasoning in LLMs.

</details>


### [107] [Gender Bias in Large Language Models for Healthcare: Assignment Consistency and Clinical Implications](https://arxiv.org/abs/2510.08614)
*Mingxuan Liu,Yuhe Ke,Wentao Zhu,Mayli Mertens,Yilin Ning,Jingchi Liao,Chuan Hong,Daniel Shu Wei Ting,Yifan Peng,Danielle S. Bitterman,Marcus Eng Hock Ong,Nan Liu*

Main category: cs.CL

TL;DR: 本论文探讨了大语言模型（LLM）在医疗领域可能存在的性别相关偏见，尤其是在诊断和判断患者性别相关性时的不一致性，指出需加强身份分配一致性以确保AI临床应用的可靠性和公平性。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM有助于提升临床决策，但其易受性别等偏见影响仍是关键隐忧。由于性别历来影响医生行为和患者结果，作者担心LLM扮演临床医生、医学教育者等类人角色时，可能复现甚至加剧这些性别偏见。

Method: 利用NEJM病例挑战中的案例，给多个开源和专有LLM分配不同性别身份（女性、男性或未指定），评估不同性别下LLM在疾病诊断以及对患者性别临床相关性或必要性的判断上的一致性。

Result: 在大多数模型中，不同性别LLM在诊断结果上表现出较高一致性。但在判断患者性别临床相关性和必要性时，所有模型都存在明显不一致，尤其是在相关性判断上。一些模型还表现出系统性的男女差异。

Conclusion: LLM存在在性别身份分配下表现不一致的潜在偏见，这种偏见或将破坏临床实践中LLM的可靠性。因此，建议在与LLM交互时常规性检查身份分配的一致性，以保障AI辅助医疗的可靠公平。

Abstract: The integration of large language models (LLMs) into healthcare holds promise
to enhance clinical decision-making, yet their susceptibility to biases remains
a critical concern. Gender has long influenced physician behaviors and patient
outcomes, raising concerns that LLMs assuming human-like roles, such as
clinicians or medical educators, may replicate or amplify gender-related
biases. Using case studies from the New England Journal of Medicine Challenge
(NEJM), we assigned genders (female, male, or unspecified) to multiple
open-source and proprietary LLMs. We evaluated their response consistency
across LLM-gender assignments regarding both LLM-based diagnosis and models'
judgments on the clinical relevance or necessity of patient gender. In our
findings, diagnoses were relatively consistent across LLM genders for most
models. However, for patient gender's relevance and necessity in LLM-based
diagnosis, all models demonstrated substantial inconsistency across LLM
genders, particularly for relevance judgements. Some models even displayed a
systematic female-male disparity in their interpretation of patient gender.
These findings present an underexplored bias that could undermine the
reliability of LLMs in clinical practice, underscoring the need for routine
checks of identity-assignment consistency when interacting with LLMs to ensure
reliable and equitable AI-supported clinical care.

</details>


### [108] [Iterative LLM-Based Generation and Refinement of Distracting Conditions in Math Word Problems](https://arxiv.org/abs/2510.08615)
*Kaiqi Yang,Hang Li,Yucheng Chu,Zitao Liu,Mi Tian,Hui Liu*

Main category: cs.CL

TL;DR: 本文针对现有数学文字题（MWP）数据集对分散注意力条件处理不足，提出一种高效利用大模型自动生成分散注意力条件的框架，提升数据难度与质量。


<details>
  <summary>Details</summary>
Motivation: 现有MWP数据集多为仅含必要信息的题目，缺乏带有分散注意力条件（无关或多余信息）的问题。而现实中，LLM对这些条件表现显著下降，现有带分散条件数据集数量少且难度低，影响模型评测的准确性与挑战性。手动生成此类题目需大量人力校对和修改解答。

Method: 提出基于LLM的迭代自动生成框架，通过多种提示词引导模型从不同认知层面和角度，对原有MWP进行干扰条件的丰富和优化。同时，明确要求所加条件不影响原题解答，使答案可复用，无须新解，极大降低人工干预和成本。

Result: 该框架可自动高效、大规模地为MWP生成高质量有意义的分散注意力条件，同时保持题目原有解答不变，大幅提升数据集挑战性且便于部署应用。

Conclusion: 本文推出现成MWP数据自动升级的解决思路，为基于大模型的复杂推理能力评测提供更佳范本，有助于推动数学推理领域的数据资源与测评工具发展。

Abstract: Mathematical reasoning serves as a crucial testbed for evaluating the
intelligence of large language models (LLMs), and math word problems (MWPs)
represent one of the most widely used formats. Most existing MWP datasets
contain only the necessary information, while problems with distracting or
excessive conditions are often overlooked. Prior studies have shown that
popular LLMs experience a dramatic performance drop when such distracting
conditions are introduced. However, available datasets of MWPs with distracting
conditions remain limited, and most exhibit low difficulty and out-of-context
expressions. These shortcomings make the distracting conditions easy to detect
and disregard, thereby reducing the credibility of benchmarking on these
datasets. Moreover, when distracting conditions are added, the reasoning
process and answers may change, requiring intensive manual effort to check and
rewrite solutions.
  To address these issues, we design an iterative framework that leverages LLMs
to generate distracting conditions automatically. We develop a set of prompts
to revise MWPs from multiple perspectives and cognitive levels, encouraging the
creation of meaningful distracting conditions as well as suggestions for
further refinement. A key advantage of our framework is the preservation of
shared solutions between the original and revised problems: the LLMs are
explicitly guided to generate distractions that do not alter the original
solution, thus eliminating the need to produce new answers. This framework is
efficient and easy to deploy, substantially reducing the effort required to
generate MWPs with distracting conditions while maintaining high data quality.

</details>


### [109] [LLMs Show Surface-Form Brittleness Under Paraphrase Stress Tests](https://arxiv.org/abs/2510.08616)
*Juan Miguel Navarro Carranza*

Main category: cs.CL

TL;DR: 该论文提出通过对基准测试题目的释义，检测大语言模型（LLM）的泛化能力。结果显示，释义后的准确率显著下降，说明现有基准可能高估了模型的真实能力。


<details>
  <summary>Details</summary>
Motivation: 目前LLM的基准测试分数可能因为模型记忆测试题目或其近似重复而被高估，缺乏对模型泛化能力的有效测试。

Method: 作者提出了一套协议，通过将基准测试题目释义后重新评价模型表现。具体使用Mistral-7B-Instruct和Qwen2.5-7B-Instruct，在ARC-Easy和ARC-Challenge两个数据集上测试。流程包括严格控制解码过程、指定输出格式，以及采用语义保真的释义去重步骤。

Result: 实验发现，模型在释义后题目上的准确率比原题上有明显下降，证明释义处理对表现影响较大。该结果与先前对于数据污染及模型依赖表层特征的担忧一致。

Conclusion: 该研究证实了现有基准测试可能无法准确反映模型真实的泛化能力，表明未来评价应当考虑更能考察泛化能力的方法。

Abstract: Benchmark scores for Large Language Models (LLMs) can be inflated by
memorization of test items or near duplicates. We present a simple, protocol
that probes generalization by re-evaluating models on paraphrased versions of
benchmark questions. Using Mistral-7B-Instruct and Qwen2.5-7B-Instruct, we
measure the accuracy gap between original and paraphrased items on ARC-Easy and
ARC-Challenge. Our pipeline controls decoding, enforces multiple-choice output
format, and includes a robust paraphrase-cleaning step to preserve semantics.
We find that paraphrasing induces a non-trivial accuracy drop (original vs.
paraphrased), consistent with prior concerns about contamination and brittle
surface-form shortcuts.

</details>


### [110] [JAI-1: A Thai-Centric Large Language Model](https://arxiv.org/abs/2510.08620)
*Attapol T. Rutherford,Jullajak Karnjanaekarin,Narongkorn Panitsrisit,Pontakorn Trakuekul,Sumana Sumanakul,Natchanon Pollertlam*

Main category: cs.CL

TL;DR: JAI-1 是一个专为泰语设计的 75B 参数大模型，通过扩展参数空间并系统性地融合泰语知识，取得了在泰语基准测试上的最优表现。


<details>
  <summary>Details</summary>
Motivation: 当前专注泰语的大模型主要在英文或多语言开源模型上做增量训练，未改变结构，这种方式可能导致模型原有知识丢失。作者希望通过结构创新，兼顾英文通用能力和泰语专长。

Method: 作者以高性能英文 LLM 为基础，先扩展其参数空间，再有系统地注入泰语知识，随后进行预训练（15 亿 token，其中 3000 亿为泰语），再用 60 万+ 指令数据进行微调和对齐训练。

Result: JAI-1 在多个泰语基准（IFEval-TH、MT-Bench-TH 和 JAI-Hall-Bench）上性能优于现有泰语模型 Typhoon2-70B，验证了其框架的有效性。

Conclusion: JAI-1 通过参数扩展和知识注入，成功兼顾了原有模型的通用性和泰语专能，为未来功能拓展和多样性提供了新架构。

Abstract: This technical report introduces JAI-1, a Thai-centric language model with
75B parameters. Recent Thai models have primarily relied on existing
open-source models, applying additional training without structural
modifications to specialize in Thai. However, this approach risks eroding
pre-existing knowledge in the model's parameter space during the injection of
Thai-specific information, as optimized parameters for general tasks may
conflict with new linguistic requirements. In contrast, JAI-1 adopts an
upscaling strategy: starting from a smaller, high-performing English
open-source LLM, we expanded its parameter space and utilized the newly
allocated capacity to systematically integrate Thai-language knowledge. This
methodology not only preserves the original model's general intelligence but
also establishes a unique architecture distinct from other open-source models,
enabling scalable future enhancements. During pre-training, JAI-1 was exposed
to 1.5T tokens, including over 300B Thai language tokens. This was followed by
post-training stages -- supervised fine-tuning and alignment tuning -- using
more than 600K instruction-based examples. The final model demonstrated
superior performance compared to Typhoon2-70B on Thai-centric benchmarks
(IFEval-TH, MT-Bench-TH, and JAI-Hall-Bench), validating the efficacy of its
upscaling and knowledge-integration framework.

</details>


### [111] [From Simulation to Strategy: Automating Personalized Interaction Planning for Conversational Agents](https://arxiv.org/abs/2510.08621)
*Wen-Yu Chang,Tzu-Hung Huang,Chih-Ho Chen,Yun-Nung Chen*

Main category: cs.CL

TL;DR: 本文提出通过分析用户画像（年龄、性别、职业）调整面向销售的对话代理策略，发现职业对意图影响最大，并引入基于职业的轻量对话策略，有效提升对话效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 随着代理型对话模型的普及，如何设计更有效的对话策略成为重要课题。为了使销售对话代理更贴合不同用户的需求，需要理解不同用户画像（尤其是职业等特征）对对话表现和意图的影响。

Method: 设计了具备年龄、性别、职业信息的用户模拟器，通过实验分析各因素对对话效率与成功率的影响。在发现职业影响最大后，提出了一种基于职业画像的轻量级对话策略，使代理优先考虑符合用户偏好的意图。

Result: 实验表明，基于职业条件的对话策略能有效缩短对话轮次，提高销售成功率，且策略简单易实现。

Conclusion: 丰富的用户画像（尤其职业）对提升销售对话系统效果至关重要。采用简易的基于职业的个性化策略能够显著增强对话代理的销售能力。

Abstract: Amid the rapid rise of agentic dialogue models, realistic user-simulator
studies are essential for tuning effective conversation strategies. This work
investigates a sales-oriented agent that adapts its dialogue based on user
profiles spanning age, gender, and occupation. While age and gender influence
overall performance, occupation produces the most pronounced differences in
conversational intent. Leveraging this insight, we introduce a lightweight,
occupation-conditioned strategy that guides the agent to prioritize intents
aligned with user preferences, resulting in shorter and more successful
dialogues. Our findings highlight the importance of rich simulator profiles and
demonstrate how simple persona-informed strategies can enhance the
effectiveness of sales-oriented dialogue systems.

</details>


### [112] [Text2Stories: Evaluating the Alignment Between Stakeholder Interviews and Generated User Stories](https://arxiv.org/abs/2510.08622)
*Francesco Dente,Fabiano Dalpiaz,Paolo Papotti*

Main category: cs.CL

TL;DR: 本文提出了一种名为Text2Stories的新任务和指标，用于自动评估用户故事对访谈需求的覆盖和准确性，为需求自动化生成提供可扩展的质量评估方法。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型（LLMs）可以从访谈记录等自然语言输入生成软件需求，但评价生成需求是否真实反映利益相关方需求仍是主要依赖人工的难题。

Method: 作者提出Text2Stories，用于量化用户故事与访谈需求的一致性。具体通过将访谈记录分段，将每一段与用户故事比对，将对齐建模为匹配问题，定义了正确性（故事是否被访谈支持）和完整性（访谈是否被故事覆盖）指标。并用LLM和嵌入模型在四个数据集上进行验证分析。

Result: LLM为基础的匹配模型在F1分数上达到0.86，明显优于仅用嵌入模型（后者可用于高效的筛选）；同时展示了新指标可用于比较人类与模型生成的用户故事质量。

Conclusion: Text2Stories为用户故事质量评估提供了自动化、可扩展的度量，对现有人工或定性标准形成有力补充，有助于实际需求自动化流程的落地。

Abstract: Large language models (LLMs) can be employed for automating the generation of
software requirements from natural language inputs such as the transcripts of
elicitation interviews. However, evaluating whether those derived requirements
faithfully reflect the stakeholders' needs remains a largely manual task. We
introduce Text2Stories, a task and metrics for text-to-story alignment that
allow quantifying the extent to which requirements (in the form of user
stories) match the actual needs expressed by the elicitation session
participants. Given an interview transcript and a set of user stories, our
metric quantifies (i) correctness: the proportion of stories supported by the
transcript, and (ii) completeness: the proportion of transcript supported by at
least one story. We segment the transcript into text chunks and instantiate the
alignment as a matching problem between chunks and stories. Experiments over
four datasets show that an LLM-based matcher achieves 0.86 macro-F1 on held-out
annotations, while embedding models alone remain behind but enable effective
blocking. Finally, we show how our metrics enable the comparison across sets of
stories (e.g., human vs. generated), positioning Text2Stories as a scalable,
source-faithful complement to existing user-story quality criteria.

</details>


### [113] [PARSE: LLM Driven Schema Optimization for Reliable Entity Extraction](https://arxiv.org/abs/2510.08623)
*Anubhav Shrimal,Aryan Jain,Soumyajit Chowdhury,Promod Yenigalla*

Main category: cs.CL

TL;DR: 本文提出了一种结构化信息抽取系统PARSE，显著提升了LLM在API交互和工具调用等场景下的信息抽取准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有方法将JSON schema作为静态合同，但这些schema存在歧义或不完整性，导致大型语言模型（LLM）在抽取任务中表现不佳，如产生幻觉、错误频发，影响系统稳定性。因此，需要让LLM更好地理解和优化结构化数据契约。

Method: 提出PARSE系统，包含两个创新组件：ARCHITECT（自动优化并改良JSON schema，使其适合LLM理解，并通过RELAY保证向后兼容）和SCOPE（结合静态与LLM反思机制，提升信息抽取的准确性和安全性）。

Result: 在SGD、SWDE和零售对话等数据集上进行实验，PARSE在SWDE数据集的抽取准确率提升高达64.7%，平均框架总体提升10%，且首轮重试后抽取错误率降低92%，延迟控制在实用范围。

Conclusion: 动态优化与反思机制能大幅提升LLM结构化信息抽取能力，显著减少错误和幻觉，提高API与工具交互应用的可靠性和实用性。

Abstract: Structured information extraction from unstructured text is critical for
emerging Software 3.0 systems where LLM agents autonomously interact with APIs
and tools. Recent approaches apply large language models directly to extraction
tasks using existing JSON schemas, often with constraint decoding or
reinforcement learning approaches to ensure syntactic validity, but treat JSON
schemas as static contracts designed for human developers, leading to
suboptimal extraction performance, frequent hallucinations, and unreliable
agent behavior when schemas contain ambiguous or incomplete specifications. We
recognize that JSON schemas themselves are a form of natural language
understanding contract that encodes rules, relationships, and expectations
about data structure contracts that LLMs should be able to both interpret and
systematically improve. Consequently, we develop PARSE (Parameter Automated
Refinement and Schema Extraction), a novel system with two synergistic
components: ARCHITECT, which autonomously optimizes JSON schemas for LLM
consumption while maintaining backward compatibility through RELAY (an
integrated code generation system), and SCOPE, which implements
reflection-based extraction with combined static and LLM-based guardrails. We
evaluate PARSE qualitatively and quantitatively on three datasets including
Schema-Guided Dialogue (SGD), Structured Web Data Extraction (SWDE), and
internal retail conversation data, and find that it achieves up to 64.7%
improvement in extraction accuracy on SWDE with combined framework improvements
reaching 10% across models, while reducing extraction errors by 92% within the
first retry and and maintaining practical latency.

</details>


### [114] [Do LLMs Know They Are Being Tested? Evaluation Awareness and Incentive-Sensitive Failures in GPT-OSS-20B](https://arxiv.org/abs/2510.08624)
*Nisar Ahmed,Muhammad Imran Zaman,Gulshan Saleem,Ali Hassan*

Main category: cs.CL

TL;DR: 现有大模型评测多依赖详细推理和严格格式的提示词，但实际应用需简洁、契约化的回答。本文对比了两种评测提示词对模型表现的影响，并提出更实用的评测建议。


<details>
  <summary>Details</summary>
Motivation: 当前大模型评测方法与实际部署场景差异明显，标杆成绩可能被夸大，实际能力未必提高，需要验证提示词设定对评测结果的影响。

Method: 作者选用单一开源大模型（GPT-OSS-20B），设计6组AB实验，分别调整提示词的评测导向及推理深度，对比不同场景下模型在数学、代码、引用、多语种等任务的表现。通过自动验证器量化准确率、回答格式等多项指标。

Result: 评测导向的提示词增加模型推理文本长度但降低了简洁回答比例，对核心准确度提升有限。在结构化输出中，对格式有提升但对内容无明显改进。不同激励方向（鼓励谨慎或自信）会影响错误类型和答案风格，多语种提示还可能导致表现波动。

Conclusion: 现有评测方式可能夸大大模型部署能力，建议采用更中性或多样化的提示，真实反映模型实际能力，优化评测与实际需求的契合度。并开源了可重现的评测框架与具体操作建议。

Abstract: Benchmarks for large language models (LLMs) often rely on rubric-scented
prompts that request visible reasoning and strict formatting, whereas real
deployments demand terse, contract-bound answers. We investigate whether such
"evaluation scent" inflates measured performance without commensurate
capability gains. Using a single open-weights model (GPT-OSS-20B), we run six
paired A/B scenarios that hold task content and decoding fixed while varying
framing (evaluation-oriented vs. real-world) and reasoning depth (Medium/High):
deterministic math, strict code-fix, citation generation, incentive flips
(caution vs. competence), CoT visibility, and multilingual (Urdu) headers.
Deterministic validators compute accuracy, answer-only compliance,
hedging/refusals, chain-of-thought (CoT) length, and schema compliance, with
pre-registered deltas and composite indices. Across scenarios, evaluation
framing reliably inflates CoT (hundreds to >1000 characters) and reduces
answer-only compliance, with limited or inconsistent accuracy gains. In
structured outputs, it improves wrappers (e.g., fenced blocks, enumerated
lists) but not regex-validated substance. Incentive wording reweights error
composition: praising caution modestly improves accuracy at high reasoning and
reduces wrong-but-confident errors, whereas praising competence yields terser
but riskier outputs. Urdu rubric headers reproduce these signatures and can
decrease accuracy at higher reasoning depth, indicating multilingual parity
risks. We provide a reproducible A/B framework (prompt banks, validators,
per-run scores, scripts; versioned DOI) and practical guidance: neutral
phrasing or dual-framing checks, contract-aware grading, style-delta reporting,
confidence governance, and multilingual dashboards to ensure that benchmark
gains reflect deployable capability.

</details>


### [115] [From What to Why: Thought-Space Recommendation with Small Language Models](https://arxiv.org/abs/2510.08626)
*Prosenjit Biswas,Pervez Shaik,Abhinav Thorat,Ravi Kolla,Niranjan Pedanekar*

Main category: cs.CL

TL;DR: 本文提出了一种新的推荐系统方法PULSE，利用小语言模型（SLM）生成的理由（rationales）作为监督信号，比传统方法和大语言模型（LLM）在多个任务和数据集上都表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统多依赖LLM来加强推理能力，但推理成本高，不适合实际部署。SLM推理能力弱未被充分挖掘。同时，现有方法未充分利用自然语言理由作为有效的学习信号。作者希望利用SLM提升推荐系统效率，同时充分发挥自然语言理由的指导作用。

Method: 作者提出了PULSE框架，创新点是将SLM生成的理由（rationales）作为直接的监督信号，并结合用户交互历史，共同建模用户的行为与其背后的语义驱动。不同于只关注序列或embedding的传统方法，PULSE将理由作为核心信息，生成更健壮、泛化能力更强的embedding。

Result: PULSE在多个主流基准数据集上均优于ID方法、协同过滤（CF）和基于LLM的序列推荐模型。同时，PULSE在跨领域推荐和推理类问答等下游任务中也表现突出，展现出良好的迁移性和泛化能力。

Conclusion: 通过创新性地利用SLM生成的自然语言理由作为一等公民特征，PULSE不仅显著提升了推荐准确率与泛化性，还降低了推理和部署的成本，为推荐系统提供了一条高效、鲁棒的新路径。

Abstract: Large Language Models (LLMs) have advanced recommendation capabilities
through enhanced reasoning, but pose significant challenges for real-world
deployment due to high inference costs. Conversely, while Small Language Models
(SLMs) offer an efficient alternative, their reasoning capabilities for
recommendation remain underexplored. Existing systems often use natural
language rationales merely as unsupervised descriptive text, failing to harness
their full potential as learning signals. In this work our main idea is to
create a common understanding of user and items across multiple domains called
Thought Space with SLMs instead of using LLMs' distilled knowledge. To that end
we propose PULSE (Preference Understanding by Latent Semantic Embeddings), a
framework that treats SLM-generated rationales as director learning signals,
supervising them with interaction histories to jointly model user actions
(what) and their semantic drivers (why). Existing methods consider only
interactions such as sequences and embeddings, whereas PULSE treats rationales
as first-class signals, this novel design yields embeddings that are more
robust and generalizable. Extensive experiments demonstrate that PULSE
outperforms leading ID, Collaborative Filtering (CF), and LLM-based sequential
recommendation models across multiple benchmark datasets. Furthermore, PULSE
exhibits superior transferability in cross-domain recommendation and
demonstrates strong performance on downstream tasks such as reasoning-oriented
question answering. Our code is available
\href{https://anonymous.4open.science/r/Thinking_PULSE-0FC5/README.md}{here}.

</details>


### [116] [ExPO-HM: Learning to Explain-then-Detect for Hateful Meme Detection](https://arxiv.org/abs/2510.08630)
*Jingbiao Mei,Mingsheng Sun,Jinghong Chen,Pengda Qin,Yuhong Li,Da Chen,Bill Byrne*

Main category: cs.CL

TL;DR: 本文提出了一种新方法ExPO-HM，用于对仇恨型梗图进行解释式检测，不仅提升了二分类准确率，还能生成有助于内容审核的解释，显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统仇恨型梗图检测方法只输出二分类结果，缺乏可解释性，无法满足实际内容审核需求，且现有解释式检测方法性能不佳。

Method: 提出ExPO-HM方法，模拟人工标注流程，结合SFT预训练、GRPO策略优化、课程学习及条件决策熵（CDE）作为评估和奖励信号，提高模型的推理和解释能力。

Result: 在三个相关基准数据集上，ExPO-HM在二分类、细粒度分类和推理质量等方面均达到最优，F1分数较GRPO和DPO分别提升15%和17%。

Conclusion: ExPO-HM推动了仇恨型梗图检测从二分类向可解释、可执行的审核辅助演进，为实际内容审核提供了更准确、透明的决策支持。

Abstract: Hateful memes have emerged as a particularly challenging form of online
abuse, motivating the development of automated detection systems. Most prior
approaches rely on direct detection, producing only binary predictions. Such
models fail to provide the context and explanations that real-world moderation
requires. Recent Explain-then-Detect approaches, using Chain-of-Thought
prompting or LMM agents, perform worse than simple SFT baselines, and even
advanced post-training methods such as GRPO fail to close the gap. Our analysis
identifies two key issues of such systems: important policy-relevant cues such
as targets and attack types are not hypothesized by the model as a likely
explanation; and the binary reward signal is insufficient to guide reasoning.
To address these challenges, we propose ExPO-HM (Explain-then-Detect Policy
Optimization for Hateful Memes), inspired by the training and evaluation
process of human annotators. ExPO-HM combines SFT warmup, GRPO with curriculum
learning, and Conditional Decision Entropy (CDE) as both metric and reward for
reasoning quality. Across three hateful meme benchmarks, ExPO-HM achieves
state-of-the-art performance on binary detection, fine-grained classification,
and reasoning quality, with up to 15\% and 17\% F1 improvement over the GRPO
and DPO baselines, respectively. By moving hateful meme detection from simple
binary alarms to explanation-driven detection, ExPO-HM provides accurate,
interpretable, and actionable moderation support.

</details>


### [117] [Next Semantic Scale Prediction via Hierarchical Diffusion Language Models](https://arxiv.org/abs/2510.08632)
*Cai Zhou,Chenyu Wang,Dinghuai Zhang,Shangyuan Tong,Yifei Wang,Stephen Bates,Tommi Jaakkola*

Main category: cs.CL

TL;DR: 提出了一种新的分层扩散语言模型（HDLM），通过分层词汇表提升语言建模效果，在文本生成任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散语言模型在处理语言的多层次语义细节时存在局限，难以同时捕捉词汇的粗粒度和细粒度语义，因此需要更有效的分层机制提升生成质量。

Method: HDLM利用分层词汇表，将低层细致语义的token通过映射与高层粗语义的token关联。在前向过程将token逐步抽象化，在反向过程再逐步细化，还推导了对应的扩散ELBO，兼容MDLM，并提出了配套的训练技巧。

Result: 在多项文本生成实验中，HDLM相较于现有基线模型展现出更低的验证集和生成困惑度，验证了其有效性。

Conclusion: 分层扩散语言模型能够在语言建模中有效结合语义层次，提升文本生成质量，为扩散模型在NLP领域提供了新的思路和方法。

Abstract: In this paper we introduce Hierarchical Diffusion Language Models (HDLM) -- a
novel family of discrete diffusion models for language modeling. HDLM builds on
a hierarchical vocabulary where low-level tokens with detailed semantics are
surjectively mapped to high-level tokens with coarse-grained meanings. In the
forward process, each token is independently perturbed to its higher-level
ancestor with more abstract semantics according to the scheduler, while in the
reverse process the model progressively predicts the next, more detailed
semantics. Taken together, HDLM provides a general time-varying next semantic
scale prediction process for language modeling. We derive closed-form
expressions for the diffusion Evidence Lower Bound (ELBO), and show that HDLM
can be implemented in a flexible manner while including the existing MDLM as a
special case. We also propose practical training techniques based on the
insights. Extensive text generation experiments validate the effectiveness of
HDLM, which demonstrates consistently lower validation and generative
perplexity than baselines.

</details>


### [118] [Upfront Chain-of-Thought: A Cooperative Framework for Chain-of-Thought Compression](https://arxiv.org/abs/2510.08647)
*Chengzhengxu Li,Xiaoming Liu,Zhaohan Zhang,Shaochu Zhang,Shengchao Liu,Guoxin Ma,Yu Lan,Chao Shen*

Main category: cs.CL

TL;DR: 该论文提出了一种名为Upfront CoT (UCoT)的新型高效推理框架，通过自动化Chain-of-Thought（CoT）压缩，有效提升大语言模型推理效率，实验证明在减少一半推理token同时精度优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型推理能力增强，长CoT推理虽提升了复杂任务的解答能力，但带来了显著的计算代价和推理延迟，亟需提升推理效率的自动化CoT压缩方法。

Method: UCoT框架由小模型（压缩器）与大模型（执行器）协作组成。第一阶段训练压缩器生成富含推理信息的向量嵌入，第二阶段通过奖励机制优化执行器利用该嵌入进行简短但正确的推理，从而自动实现CoT压缩，无需手工设计提示。

Result: 大量实验表明，UCoT能大幅降低推理所需token数量，同时维持甚至提升推理准确率。例如在Qwen2.5-7B-Instruct与GSM8K数据集上，token消耗减半，性能提升3.08%。

Conclusion: UCoT框架实现了高效自动化的推理流程，通过压缩CoT长度提高了推理速度并降低计算成本，兼顾推理能力和效率，为大语言模型推理优化提供了有力新方案。

Abstract: Recent developments have enabled advanced reasoning in Large Language Models
(LLMs) via long Chain-of-Thought (CoT), while long CoT suffers from high
computational costs and significant latency losses owing to the autoregressive
nature of generative LLMs. CoT compression aims to improve efficiency in the
reasoning process by reducing output length. Previous works trade reasoning
efficiency by either laborious discrete prompt designing or the construction of
external compressed CoT datasets that sacrifice key reasoning details. In this
work, we propose Upfront CoT (UCoT): an efficient reasoning framework with
upfront thought embedding to automate CoT compression. UCoT is a cooperative
workflow involving a small model (compressor) and a large model (executor). The
first stage of UCoT trains compressor to generate upfront thought embeddings
rich in reasoning information for the executor, avoiding the drawbacks of
manually designed prompts. The second stage optimizes executor to utilize
upfront thought embeddings to derive the correct answer with short reasoning,
using a reward mechanism. Extensive experiments show that UCoT maintains the
powerful reasoning ability of executor while significantly reducing the length
of CoT. It is worth mentioning that when applying UCoT to the
Qwen2.5-7B-Instruct model, the usage of tokens on GSM8K dataset is reduced by
50\%, while the performance is 3.08\% higher than that of the state-of-the-art
(SOTA) method. The code and dataset are in supplementary material.

</details>


### [119] [Formalizing Style in Personal Narratives](https://arxiv.org/abs/2510.08649)
*Gustave Cortal,Alain Finkel*

Main category: cs.CL

TL;DR: 本论文提出了一个形式化的框架，系统分析个人叙述中作者的文体选择，方法结合了功能语言学、计算机科学和心理学领域，并通过语言模型自动提取叙述中的语言特征。


<details>
  <summary>Details</summary>
Motivation: 个人叙述是作者表达和理解自身经验的重要手段，而文体作为语言表达的独特方式，对叙述主观体验至关重要，但目前缺乏系统分析文体选择的形式化框架。

Method: 作者提出了一个新的分析框架：结合功能语言学（将语言视为意义选择的系统）、计算机科学（用于自动提取和分析序列模式的方法）以及心理学（将语言模式与心理观察关联）；利用语言模型自动提取叙述中的过程、参与者、环境等语言特征。

Result: 在数百篇梦境叙述中，特别是对一位患有PTSD的退伍军人案例分析，发现其叙述中动词过程（verbal processes）显著多于心理过程（mental processes），揭示了其语言选择与心理状态的关联。

Conclusion: 该框架能够有效揭示个人叙述中文体特征与心理状态的关系，对于深入理解叙述者主观体验具有重要意义。

Abstract: Personal narratives are stories authors construct to make meaning of their
experiences. Style, the distinctive way authors use language to express
themselves, is fundamental to how these narratives convey subjective
experiences. Yet there is a lack of a formal framework for systematically
analyzing these stylistic choices. We present a novel approach that formalizes
style in personal narratives as patterns in the linguistic choices authors make
when communicating subjective experiences. Our framework integrates three
domains: functional linguistics establishes language as a system of meaningful
choices, computer science provides methods for automatically extracting and
analyzing sequential patterns, and these patterns are linked to psychological
observations. Using language models, we automatically extract linguistic
features such as processes, participants, and circumstances. We apply our
framework to hundreds of dream narratives, including a case study on a war
veteran with post-traumatic stress disorder. Analysis of his narratives
uncovers distinctive patterns, particularly how verbal processes dominate over
mental ones, illustrating the relationship between linguistic choices and
psychological states.

</details>


### [120] [A Novel Framework for Augmenting Rating Scale Tests with LLM-Scored Text Data](https://arxiv.org/abs/2510.08663)
*Joe Watson,Ivan O'Conner,Chia-Wen Chen,Luning Sun,Fang Luo,David Stillwell*

Main category: cs.CL

TL;DR: 本研究提出了一种结合大语言模型（LLM）评分文本和传统量表项目的心理测评增强框架，显著提升了测量的精度与准确性。


<details>
  <summary>Details</summary>
Motivation: 当前心理评估多依赖结构化量表，无法捕捉被试自然语言中的丰富信息。近年来LLM的发展带来处理文本数据的新机遇，作者希望通过创新方法，将受访者的自由文本有效转化为测评信息，使测量更全面、更具个体差异性。

Method: 该研究将LLM对文本的评分与传统量表项目结合，在抑郁测评场景下，于真实高中生样本（n=693）及合成数据集（n=3,000）中开发与评估该框架。通过经验选择最具信息价值的LLM评分指令，无需依赖标注数据或专家复杂评分规则。

Result: 增强后的测评在留出测试集上，显著提高了测量的精度和准确性。LLM文本项目带来的信息增益，相当于原有19题量表增加6.3（真实数据）到16.0（合成数据）个新项目。

Conclusion: 该方法实现了心理测评自动评分方式的概念创新，突破了传统依赖标注和专家规则的瓶颈，具备拓展性和临床等实际应用潜力。

Abstract: Psychological assessments typically rely on structured rating scales, which
cannot incorporate the rich nuance of a respondent's natural language. This
study leverages recent LLM advances to harness qualitative data within a novel
conceptual framework, combining LLM-scored text and traditional rating-scale
items to create an augmented test. We demonstrate this approach using
depression as a case study, developing and assessing the framework on a
real-world sample of upper secondary students (n=693) and corresponding
synthetic dataset (n=3,000). On held-out test sets, augmented tests achieved
statistically significant improvements in measurement precision and accuracy.
The information gain from the LLM items was equivalent to adding between 6.3
(real data) and 16.0 (synthetic data) items to the original 19-item test. Our
approach marks a conceptual shift in automated scoring that bypasses its
typical bottlenecks: instead of relying on pre-labelled data or complex
expert-created rubrics, we empirically select the most informative LLM scoring
instructions based on calculations of item information. This framework provides
a scalable approach for leveraging the growing stream of transcribed text to
enhance traditional psychometric measures, and we discuss its potential utility
in clinical health and beyond.

</details>


### [121] [dInfer: An Efficient Inference Framework for Diffusion Language Models](https://arxiv.org/abs/2510.08666)
*Yuxin Ma,Lun Du,Lanning Wei,Kun Chen,Qian Xu,Kangyu Wang,Guofeng Feng,Guoshan Lu,Lin Liu,Xiaojing Qi,Xinyuan Zhang,Zhen Tao,Haibo Feng,Ziyun Jiang,Ying Xu,Zenan Huang,Yihong Zhuang,Haokai Xu,Jiaqi Hu,Zhenzhong Lan,Junbo Zhao,Jianguo Li,Da Zheng*

Main category: cs.CL

TL;DR: 本文提出了一个高效且可扩展的扩散式大语言模型(dLLM)推理框架dInfer，通过模块化设计和系统优化，大幅提升了推理速度，并实现了较大性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的dLLM模型由于缺乏高效标准的推理框架，难以广泛应用，急需一个提升推理效率、促进落地的系统性解决方案。

Method: dInfer将推理流程细分为模型、扩散迭代管理、解码策略和KV缓存管理四大模块，并针对每一模块结合新颖算法和系统级优化以提升整体性能。

Result: 在LLaDA-MoE等任务中，dInfer在单卡和多卡场景下均取得了显著的推理速度提升：单卡1,100 tokens/s，8卡平均超800 tokens/s，对比Fast-dLLM提速10倍，对比高效AR模型QWen2.5-3B提速2—3倍，且输出质量无损失。

Conclusion: dInfer显著提升了dLLM推理效率，解决了扩散模型推理落地的瓶颈，并已开源，有望推动dLLM技术的普及和实际应用。

Abstract: Diffusion-based large language models (dLLMs) have emerged as a promising
alternative to autoregressive (AR) LLMs, leveraging denoising-based generation
to enable inherent parallelism. Even more and more open-sourced dLLM models
emerge, yet their widespread adoption remains constrained by the lack of a
standardized and efficient inference framework. We present dInfer, an efficient
and extensible framework for dLLM inference. dInfer decomposes the inference
pipeline into four modular components-model, diffusion iteration manager,
decoding strategy, and KV-cache manager-and integrates novel algorithms for
each component alongside system-level optimizations. Through this combination
of algorithmic innovations and system enhancements, dInfer achieves substantial
efficiency gains without compromising output quality on LLaDA-MoE. At batch
size 1, it surpasses 1,100 tokens per second on HumanEval and averages over 800
tokens per second across six benchmarks on $8\times$ H800 GPUs. Compared to
prior systems, dInfer delivers $10\times$ speedup over Fast-dLLM while
maintaining similar model performance. Even compared with AR models (with a
comparable number of activation parameters and performance) QWen2.5-3B, which
is highly optimized with latest vLLM inference engine, dInfer still deliverers
$2$-$3\times$ speedup. The implementation of dInfer is open-sourced at
https://github.com/inclusionAI/dInfer.

</details>


### [122] [Scaling Laws for Code: A More Data-Hungry Regime](https://arxiv.org/abs/2510.08702)
*Xianzhen Luo,Wenzhen Zheng,Qingfu Zhu,Rongyi Zhang,Houyi Li,Siming Huang,YuanTao Fan,Wanxiang Che*

Main category: cs.CL

TL;DR: 本论文首次系统性分析了代码大模型的Scaling Law（扩展规律），发现代码模型对数据需求比自然语言模型更高。实验比较了不同Scaling Law的适应性，并研究了代码与自然语言混合训练的效果。


<details>
  <summary>Details</summary>
Motivation: 当前大模型的扩展规律研究主要聚焦于自然语言领域，然而代码和自然语言在表达形式与约束规则上有根本不同。作者希望揭示代码场景下Scaling Law的适应性和差异，以指导更高效的代码大模型训练。

Method: 作者进行了117组实验，模型规模从0.2B到3.8B，训练token数从2B到128B，对比拟合了Chinchilla law与更具表现力的Farseer law，并进一步实验了代码与自然语言数据混合训练在不同资源场景下的表现。

Result: 实验发现：1）Farseer law在准确性上优于Chinchilla law；2）代码模型规模扩大时性能提升显著，但对数据量的依赖程度较自然语言更强（更高的数据/参数比）；3）在资源有限时，加入自然语言有利于性能，但在计算资源充足时则可能拖累效果。

Conclusion: 代码大模型的扩展规律不同于自然语言，需要投入更多数据以获得最佳训练效果。在资源受限时自然语言数据可补充代码数据，但资源充足情形下应聚焦于代码数据以提升模型性能。

Abstract: Code Large Language Models (LLMs) are revolutionizing software engineering.
However, scaling laws that guide the efficient training are predominantly
analyzed on Natural Language (NL). Given the fundamental differences like
strict syntax between code and NL, it is unclear whether these laws are
directly applicable to code. To address this gap, we conduct the first
large-scale empirical study of scaling laws for code, comprising 117
experimental runs with model sizes from 0.2B to 3.8B and training tokens from
2B to 128B. We fit the Chinchilla law and the Farsser law. First, the results
show that the more expressive Farseer law offers greater accuracy. Second, the
analysis reveals that Code LLMs scale effectively with model size. Crucially,
code represents a more data-hungry regime, requiring a substantially higher
data-to-parameter ratio than NL. Finally, two additional sets of experiments on
code-NL mixtures show that NL benefits resource-constrained scenarios, but
becomes a detriment at higher compute budgets.

</details>


### [123] [Thinking Longer, Not Always Smarter: Evaluating LLM Capabilities in Hierarchical Legal Reasoning](https://arxiv.org/abs/2510.08710)
*Li Zhang,Matthias Grabmair,Morgan Gray,Kevin Ashley*

Main category: cs.CL

TL;DR: 本文提出了一个分解式框架，用于评估大型语言模型在美式法律案例推理（以判例为基础的推理）中的表现，并揭示了其现有的能力瓶颈。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型（LLM）已显示出强大的能力，但其在美式法律关键推理领域（如通过判例类比和区分）上的实际有效性尚不明确。研究动机在于剖析LLM在法律推理复杂任务中的优势与局限性，推动法律AI的可靠性与实用性。

Method: 作者提出了一个三阶段的推理评测框架：（1）将案例表示为由因素（factors）构成的事实谓词；（2）建立法律知识的层次结构；（3）制定可验证的规则来识别案例的区分点、分析论证支持并评估其重要性。此外，对现代推理LLM进行分阶段综合评估。

Result: 研究发现，语言模型在表层推理任务（任务1）上表现较好，但在更高层次的层级推理（任务2，准确率64.82%~92.09%）和综合分析（任务3，准确率仅为11.46%~33.99%）上能力显著下降。更有趣的是，模型在错误回答上常花费更多计算资源，说明“思考更久”并不代表“思考更聪明”。

Conclusion: 本文提出的评估方法能细致刻画LLM在复杂法律推理中的能力，揭示了其根本性短板。想要构建真正可靠可信的法律AI系统，必须突破这些推理局限。

Abstract: Case-based reasoning is a cornerstone of U.S. legal practice, requiring
professionals to argue about a current case by drawing analogies to and
distinguishing from past precedents. While Large Language Models (LLMs) have
shown remarkable capabilities, their proficiency in this complex, nuanced form
of reasoning needs further investigation. We propose a formal framework that
decomposes the process of identifying significant distinctions between cases
into three-stage reasoning tasks. Our framework models cases using factual
predicates called factors, organizes them into a legal knowledge hierarchy, and
defines verifiable rules for identifying distinctions, analyzing their
argumentative support, and evaluating their significance. Through comprehensive
evaluation of modern reasoning LLMs, we reveal a paradox: while models achieve
high accuracy on surface-level reasoning (Task 1), performance degrades on
hierarchical reasoning (Task 2: 64.82%-92.09%) and collapses on integrated
analysis (Task 3: 11.46%-33.99%). Most strikingly, we find that models
consistently expend more computational resources on incorrect responses than
correct ones, suggesting that "thinking longer" does not always mean "thinking
smarter." Our work provides a methodology for fine-grained analysis of LLM
reasoning capabilities in complex domains and reveals fundamental limitations
that must be addressed for robust and trustworthy legal AI.

</details>


### [124] [How Many Code and Test Cases Are Enough? Evaluating Test Cases Generation from a Binary-Matrix Perspective](https://arxiv.org/abs/2510.08720)
*Xianzhen Luo,Jinyang Huang,Wenzhen Zheng,Qingfu Zhu,Mingzheng Xu,Yiheng Xu,Yuantao Fan,Libo Qin,Wanxiang Che*

Main category: cs.CL

TL;DR: 本文提出了一种新方法，用于自动评估由大语言模型生成的测试用例。通过构建最小且多样的错误代码集合以及对应的测试用例集，显著改进了评测基准的紧凑性和抗通胀性。实验证明，目前最先进的测试生成方法在新基准上表现有限，揭示了其诊断能力的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型测试用例基准存在计算成本高、分数膨胀和偏向琐碎错误等问题，难以准确评估模型发现重大缺陷的能力。作者希望通过更科学的方法，衡量和提升测试用例覆盖关键错误的表现，引入更具代表性和挑战性的评测集合。

Method: 作者将基准构建形式化为在二元代码-测试矩阵中寻找最优诊断基的问题，提出WrongSelect算法高效近似选取最大多样性错误代码集合，并据此生成新基准TC-Bench。该方法的理论基础是：矩阵秩对应于错误模式的独立数目，决定最小测试用例规模。

Result: 在大规模竞赛代码数据上构建出的TC-Bench基准，比现有方法更紧凑、多样，并且不易出现分数膨胀。实验证明，当前最优的测试数据自动生成方法在TC-Bench上的排除率仅60%左右，远低于理想水平。

Conclusion: 新构建的TC-Bench基准能够更有效区分和评估测试用例生成模型的实际诊断能力，揭示了现有方法的局限，有望推动领域基准和测试方法的进一步发展。

Abstract: Evaluating test cases automatically generated by Large Language Models (LLMs)
is a critical yet challenging task. Existing benchmarks suffer from high
computational costs, score inflation, and a bias towards trivial bugs over
rare, critical faults. In this work, we ask two fundamental questions: (1) What
is the minimal set of wrong codes sufficient to represent the entire error
space? and (2) What is the minimal set of test cases needed to distinguish
them? We introduce a framework that formalizes benchmark construction as
finding an optimal diagnostic basis in a binary code-test matrix. The rank of
this matrix specifies the minimal number of independent error patterns (wrong
codes) and provides a tight upper bound on the number of test cases required
for complete fault coverage. Our objective is to identify a basis of size equal
to the matrix rank that maximizes internal diversity. To tackle this NP-hard
problem, we propose WrongSelect, an efficient approximation algorithm to select
maximally diverse wrong codes. Applying this framework to millions of
competitive programming submissions, we construct TC-Bench, a compact, diverse,
and inflation-resistant benchmark. Extensive experiments show that even the
most advanced test case generation methods achieve only ~60% exclusion rates on
TC-Bench, exposing a significant gap in their diagnostic power. Our dataset is
available at: https://huggingface.co/datasets/Luoberta/TC-Bench and our code is
at: https://github.com/Luowaterbi/TC-Bench.

</details>


### [125] [How Reliable is Language Model Micro-Benchmarking?](https://arxiv.org/abs/2510.08730)
*Gregory Yauney,Shahzaib Saqib Warraich,Swabha Swayamdipta*

Main category: cs.CL

TL;DR: 本文研究了微基准测试能否稳定地对大模型进行排名，并发现当前微基准方案在模型表现接近时排名不可靠。提出了新的元评估指标，分析微基准排名和样本数量之间的权衡，为高效可靠评测提供指导。


<details>
  <summary>Details</summary>
Motivation: 大模型全量评测成本高，微基准测试用极少样本能否带来同样可靠的排名尚存疑。作者关注微基准测试方案在评测效率与可靠性之间的权衡，解决模型快速迭代与评估需求矛盾。

Method: 提出了一种新的元评估指标，衡量微基准在全量基准测试上两模型表现差异不同情况下的正确排序能力，并用不同样本规模和主流基准任务对比实验，统计失真情况和样本数量与可靠性关系。

Result: 结果表明，当模型表现差距较小时（如3.5~4分），目前微基准（无论如何采样）均无法稳定排序；要保证排名一致性，往往需采样250个样本以上，此时随机采样效果已与复杂方法接近。

Conclusion: 微基准在样本极少时不能保证可靠排名，需权衡评估效率与可靠性。本文为微基准用户和开发者提供了按样本规模权衡效能的实用建议。

Abstract: Micro-benchmarking offers a solution to the often prohibitive time and cost
of language model development: evaluate on a very small subset of existing
benchmarks. Can these micro-benchmarks, however, rank models as consistently as
the full benchmarks they replace? And can they rank models more consistently
than selecting a random subset of data points? In many scenarios, we find that
the answer is no. We introduce a meta-evaluation measure for micro-benchmarking
which investigates how well a micro-benchmark can rank two models as a function
of their performance difference on the full benchmark. This approach can
determine which model pairs can be ranked correctly by a micro-benchmark,
allowing for a finer-grained analysis of the trade-off between micro-benchmark
size and reliability. Prior work has suggested selecting as few as 10 examples;
we find that no micro-benchmarking method can consistently rank model pairs 3.5
points of accuracy apart on MMLU-Pro or 4 points apart on BIG-bench Hard. In
order to consistently rank model pairs with relatively similar performances, we
show that often as many as 250 examples must be selected, at which point random
sampling is competitive with existing micro-benchmarking methods. When
comparing only 8B instruction-tuned models on MMLU-Pro micro-benchmarks with 25
examples, we find that more than half of pairwise comparisons are not likely to
be preserved. Our work provides actionable guidance for both micro-benchmark
users and developers in navigating the trade-off between evaluation efficiency
and reliability.

</details>


### [126] [Coordinates from Context: Using LLMs to Ground Complex Location References](https://arxiv.org/abs/2510.08741)
*Tessa Masis,Brendan O'Connor*

Main category: cs.CL

TL;DR: 本文提出了一种基于LLM的大模型方法，用于地理编码复合地名表达，提升了解析效果，并证明小型微调模型在该任务上接近大模型性能。


<details>
  <summary>Details</summary>
Motivation: 许多非结构化文本分析需要将描述性地理信息准确映射为实际地理位置，但复合型地名（即多地理元素组合）解析困难，现有方法表现有限。

Method: 作者分析了LLM在地理空间知识和推理能力上的表现，并据此提出一种使用LLM进行复合地名地理编码的方法。还比较了小型微调LLM与大型现成模型的性能。

Result: 实验结果显示，所提出的LLM策略在该任务上取得了更佳表现。微调的小型LLM在准确率上达到或接近更大模型的水平。

Conclusion: 基于LLM的方法能有效提升复合型地名地理编码能力，且小型、经过微调的LLM具有实际高效性和可行性。

Abstract: Geocoding is the task of linking a location reference to an actual geographic
location and is essential for many downstream analyses of unstructured text. In
this paper, we explore the challenging setting of geocoding compositional
location references. Building on recent work demonstrating LLMs' abilities to
reason over geospatial data, we evaluate LLMs' geospatial knowledge versus
reasoning skills relevant to our task. Based on these insights, we propose an
LLM-based strategy for geocoding compositional location references. We show
that our approach improves performance for the task and that a relatively small
fine-tuned LLM can achieve comparable performance with much larger
off-the-shelf models.

</details>


### [127] [Measuring Moral LLM Responses in Multilingual Capacities](https://arxiv.org/abs/2510.08776)
*Kimaya Basu,Savi Kolari,Allison Yu*

Main category: cs.CL

TL;DR: 本研究评估了主流与开源大模型在多语言环境下的表现，发现模型间随语言和类别的响应一致性存在较大差异。


<details>
  <summary>Details</summary>
Motivation: 随着大模型（LLM）被广泛应用于全球不同国家和语言，理解并规范其多语言输出的必要性日益增加，因此需要进行跨语言、跨维度的系统性测试。

Method: 构建了大规模多语种数据集，选择前沿主流和开源大模型，在高、低资源语言环境下，从五个维度评估模型响应的准确性与一致性。评分采用五分制规则，并利用另一个大模型作为评判标准。

Result: GPT-5在各维度均表现最佳，特别是在‘同意与自主’和‘伤害预防与安全’两个维度，平均分分别为3.56和4.73；而Gemini 2.5 Pro表现最差，分别仅有1.39和1.98分。其他大模型随语言和类别变化表现出明显的不一致性。

Conclusion: 多语言环境下，大模型输出的准确性和一致性存在显著差异，未来需进一步测试和改进，尤其关注语言特性对不同类别任务表现的影响。

Abstract: With LLM usage becoming widespread across countries, languages, and humanity
more broadly, the need to understand and guardrail their multilingual responses
increases. Large-scale datasets for testing and benchmarking have been created
to evaluate and facilitate LLM responses across multiple dimensions. In this
study, we evaluate the responses of frontier and leading open-source models in
five dimensions across low and high-resource languages to measure LLM accuracy
and consistency across multilingual contexts. We evaluate the responses using a
five-point grading rubric and a judge LLM. Our study shows that GPT-5 performed
the best on average in each category, while other models displayed more
inconsistency across language and category. Most notably, in the Consent &
Autonomy and Harm Prevention & Safety categories, GPT scored the highest with
averages of 3.56 and 4.73, while Gemini 2.5 Pro scored the lowest with averages
of 1.39 and 1.98, respectively. These findings emphasize the need for further
testing on how linguistic shifts impact LLM responses across various categories
and improvement in these areas.

</details>


### [128] [Learning What to Remember: Adaptive Probabilistic Memory Retention for Memory-Efficient Language Models](https://arxiv.org/abs/2510.08798)
*S M Rafiuddin,Muntaha Nujat Khan*

Main category: cs.CL

TL;DR: 该论文提出了一种可灵活控制Token保留的方法，能在减少显存与计算资源消耗的同时保持Transformer模型性能。


<details>
  <summary>Details</summary>
Motivation: Transformer的自注意力机制计算复杂度为O(n^2)，导致在处理长文本时效率低、资源消耗高。作者希望在保证模型表现的情况下，提升长上下文任务的计算效率。

Method: 提出了Adaptive Retention（自适应保留）机制：在每层对Token进行概率性选择是否保留，通过Bernoulli门控（硬混合/变分松弛训练）学习保留策略。推理阶段用Top-M规则，严格控制保留Token总量，方法可微分且便于直接集成到常规编码器中。

Result: 在分类、抽取式问答和长文档摘要任务上，仅保留30-50% Token时模型性能基本不下降（≥95%），但峰值显存下降约35-45%，计算吞吐提升最高可达1.8倍。

Conclusion: 所提方法无需改动自注意力或下游任务头即可高效支持长文本，具有架构无关性，且在多任务中实现显著资源节约。

Abstract: Transformer attention scales quadratically with sequence length O(n^2),
limiting long-context use. We propose Adaptive Retention, a probabilistic,
layer-wise token selection mechanism that learns which representations to keep
under a strict global budget M. Retention is modeled with Bernoulli gates
trained via a Hard-Concrete/variational relaxation and enforced with a simple
top-M rule at inference, making the method differentiable and drop-in for
standard encoders. Across classification, extractive QA, and long-document
summarization, keeping only 30-50% of tokens preserves >= 95% of full-model
performance while cutting peak memory by ~35-45% and improving throughput by up
to ~1.8x. This architecture-agnostic approach delivers practical long-context
efficiency without modifying base attention or task heads.

</details>


### [129] [Benchmarking Chinese Commonsense Reasoning with a Multi-hop Reasoning Perspective](https://arxiv.org/abs/2510.08800)
*Wangjie You,Xusheng Wang,Xing Wang,Wenxiang Jiao,Chao Feng,Juntao Li,Min Zhang*

Main category: cs.CL

TL;DR: 本文提出了一个多跳推理基准CCMOR，用于全面评估大语言模型在中文环境下的常识和推理能力，并发现当前模型在处理知识密集型推理时仍有明显不足。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型（LLM）展现了高级推理能力，但其在中文一般环境下的综合评估仍然不足。因此，为完善LLM在中文知识和逻辑推理领域的评测，需要构建更加贴合实际的多跳推理基准。

Method: 作者先从现有问答数据集中构建领域均衡的种子集，然后利用大语言模型生成基于事实单元链的多跳推理问题，并引入人工-循环验证机制，由领域专家对生成问题进行系统验证和优化，从而保证数据集的高质量。

Result: 基于CCMOR对当前主流大语言模型进行测试，结果显示这些模型在处理长尾知识和知识密集型推理时仍有较大局限性。另外，增加检索增强生成模块后，模型性能显著提升，部分弥补了知识空缺。

Conclusion: CCMOR推动了中文领域下LLMs推理能力的评测与发展。同时，结合检索技术是提升模型推理能力的重要方向。

Abstract: While Large Language Models (LLMs) have demonstrated advanced reasoning
capabilities, their comprehensive evaluation in general Chinese-language
contexts remains understudied. To bridge this gap, we propose Chinese
Commonsense Multi-hop Reasoning (CCMOR), a novel benchmark designed to evaluate
LLMs' ability to integrate Chinese-specific factual knowledge with multi-step
logical reasoning. Specifically, we first construct a domain-balanced seed set
from existing QA datasets, then develop an LLM-powered pipeline to generate
multi-hop questions anchored on factual unit chains. To ensure the quality of
resulting dataset, we implement a human-in-the-loop verification system, where
domain experts systematically validate and refine the generated questions.
Using CCMOR, we evaluate state-of-the-art LLMs, demonstrating persistent
limitations in LLMs' ability to process long-tail knowledge and execute
knowledge-intensive reasoning. Notably, retrieval-augmented generation
substantially mitigates these knowledge gaps, yielding significant performance
gains.

</details>


### [130] [MOSAIC: Multi-agent Orchestration for Task-Intelligent Scientific Coding](https://arxiv.org/abs/2510.08804)
*Siddeshwar Raghavan,Tanwi Mallick*

Main category: cs.CL

TL;DR: 本文提出了MOSAIC框架，一种多智能体大语言模型（LLM）系统，能更好地解决复杂的科学编程任务，比现有方法在准确性、稳健性和可解释性上表现更优。


<details>
  <summary>Details</summary>
Motivation: 科学领域的编程任务相比通用编程更复杂，需要严谨的算法、深度领域知识、复杂推理以及无需I/O测试用例的迭代。许多科学问题还需分步解决多个子问题，现有方法难以有效应对这些挑战。

Method: MOSAIC是一种免训练的多智能体LLM框架，通过专门设计的智能体（如自省、推理、编码、调试等）采用师生范式协作解决科学代码生成难题。框架支持逐步分解问题、定向纠错，并结合统一上下文窗口（CCW）减少复杂任务中的LLM幻觉。

Result: 在多个科学编程基准测试上，MOSAIC框架相较于其他方法，在准确性、稳健性与可解释性方面均表现更优。

Conclusion: MOSAIC作为一种新型的多智能体LLM框架，能够更有效地解决复杂科学编程任务，是科学工作流自动化的一项有前景突破。

Abstract: We present MOSAIC, a multi-agent Large Language Model (LLM) framework for
solving challenging scientific coding tasks. Unlike general-purpose coding,
scientific workflows require algorithms that are rigorous, interconnected with
deep domain knowledge, and incorporate domain-specific reasoning, as well as
algorithm iteration without requiring I/O test cases. Many scientific problems
also require a sequence of subproblems to be solved, leading to the final
desired result. MOSAIC is designed as a training-free framework with specially
designed agents to self-reflect, create the rationale, code, and debug within a
student-teacher paradigm to address the challenges of scientific code
generation. This design facilitates stepwise problem decomposition, targeted
error correction, and, when combined with our Consolidated Context Window
(CCW), mitigates LLM hallucinations when solving complex scientific tasks
involving chained subproblems. We evaluate MOSAIC on scientific coding
benchmarks and demonstrate that our specialized agentic framework outperforms
existing approaches in terms of accuracy, robustness, and interpretability.

</details>


### [131] [The Model's Language Matters: A Comparative Privacy Analysis of LLMs](https://arxiv.org/abs/2510.08813)
*Abhishek K. Mishra,Antoine Boutet,Lucas Magnana*

Main category: cs.CL

TL;DR: 本论文分析了大语言模型（LLMs）在不同语言下的隐私泄露风险，发现语言结构会显著影响泄露程度。


<details>
  <summary>Details</summary>
Motivation: LLMs广泛应用于处理多语言的敏感数据，但关于其隐私风险的研究主要集中在英文，其他语言的风险情况并不清楚。因此需要研究不同语言结构对隐私泄漏的具体影响。

Method: 作者以医学语料训练的英语、西班牙语、法语和意大利语LLM为对象，量化六个语言学指标，设计三类攻击（信息抽取、反事实记忆、成员推断）对比各语言下隐私泄露程度。

Result: 意大利语LLM因冗余度和分词粒度高而泄露最严重，英语成员分离性更高。法语和西班牙语则因形态复杂性高表现出更强韧性。

Conclusion: 首次量化证明，语言本身会显著影响LLMs隐私泄露风险，今后在多语环境下模型部署需引入差异化、具语言感知的隐私保护机制。

Abstract: Large Language Models (LLMs) are increasingly deployed across multilingual
applications that handle sensitive data, yet their scale and linguistic
variability introduce major privacy risks. Mostly evaluated for English, this
paper investigates how language structure affects privacy leakage in LLMs
trained on English, Spanish, French, and Italian medical corpora. We quantify
six linguistic indicators and evaluate three attack vectors: extraction,
counterfactual memorization, and membership inference. Results show that
privacy vulnerability scales with linguistic redundancy and tokenization
granularity: Italian exhibits the strongest leakage, while English shows higher
membership separability. In contrast, French and Spanish display greater
resilience due to higher morphological complexity. Overall, our findings
provide the first quantitative evidence that language matters in privacy
leakage, underscoring the need for language-aware privacy-preserving mechanisms
in LLM deployments.

</details>


### [132] [Search-on-Graph: Iterative Informed Navigation for Large Language Model Reasoning on Knowledge Graphs](https://arxiv.org/abs/2510.08825)
*Jia Ao Sun,Hao Yu,Fabrizio Gotti,Fengran Mo,Yihong Wu,Yuchen Hui,Jian-Yun Nie*

Main category: cs.CL

TL;DR: 本文提出了一种新方法SoG，使大语言模型更有效地在知识图谱上进行推理，提升了多跳问答的准确性和可靠性，在多个基准测试中取得领先表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在多跳、依赖知识的问答场景下经常会遗漏事实或产生幻觉，很难应对知识更新和复杂关系，而现有基于知识图谱的问答方法也面临检索噪声大、规划不灵活、搜索空间爆炸等难题。本文旨在解决这些可靠性与效率瓶颈。

Method: 提出Search-on-Graph（SoG）框架，让大语言模型通过单一的精心设计的Search函数，在知识图谱上逐步导航。与传统预先规划路径或大规模子图检索不同，SoG采用“观测-再导航”策略，每步都依据当前实体实际可用关系做出决策，并对高度节点自适应筛选。该方法无需微调，可适配不同知识图谱结构。

Result: 在Freebase和Wikidata六个基准数据集上，SoG在无需微调的情况下达到了最新最优表现。尤其在Wikidata上比之前最佳方法提升了16%，在Freebase也有持续改进。

Conclusion: SoG方法使大语言模型能高效、可靠地在知识图谱上推理，克服了以往方法的关键缺陷，为知识问答任务提供了更优解决方案。

Abstract: Large language models (LLMs) have demonstrated impressive reasoning abilities
yet remain unreliable on knowledge-intensive, multi-hop questions -- they miss
long-tail facts, hallucinate when uncertain, and their internal knowledge lags
behind real-world change. Knowledge graphs (KGs) offer a structured source of
relational evidence, but existing KGQA methods face fundamental trade-offs:
compiling complete SPARQL queries without knowing available relations proves
brittle, retrieving large subgraphs introduces noise, and complex agent
frameworks with parallel exploration exponentially expand search spaces. To
address these limitations, we propose Search-on-Graph (SoG), a simple yet
effective framework that enables LLMs to perform iterative informed graph
navigation using a single, carefully designed \textsc{Search} function. Rather
than pre-planning paths or retrieving large subgraphs, SoG follows an
``observe-then-navigate'' principle: at each step, the LLM examines actual
available relations from the current entity before deciding on the next hop.
This approach further adapts seamlessly to different KG schemas and handles
high-degree nodes through adaptive filtering. Across six KGQA benchmarks
spanning Freebase and Wikidata, SoG achieves state-of-the-art performance
without fine-tuning. We demonstrate particularly strong gains on Wikidata
benchmarks (+16\% improvement over previous best methods) alongside consistent
improvements on Freebase benchmarks.

</details>


### [133] [Pattern Enhanced Multi-Turn Jailbreaking: Exploiting Structural Vulnerabilities in Large Language Models](https://arxiv.org/abs/2510.08859)
*Ragib Amin Nihal,Rui Wen,Kazuhiro Nakadai,Jun Sakuma*

Main category: cs.CL

TL;DR: LLM 依然容易被多轮越狱攻击绕过安全限制，提出了一种基于对话模式的全新攻击框架 PE-CoA，用于分析和发现 LLM 的安全弱点。


<details>
  <summary>Details</summary>
Motivation: 多轮越狱攻击的对话策略多样，现有方法多依赖启发式或零散策略，导致对模型弱点本质的理解有限，不同伤害类别下的对话模式与模型脆弱性的关系未被深入探究。

Method: 提出了 Pattern Enhanced Chain of Attack (PE-CoA) 框架，总结出五种对话模式，系统性地构建有效的多轮越狱攻击，并在 12 个主流 LLM、10 类危害场景下进行实验评估。

Result: PE-CoA 框架获得了多轮越狱攻击的最新最好成绩，进一步发现不同 LLM 对不同对话模式表现出独特的脆弱性，与某种模式的鲁棒性无法泛化到其他模式，同一模型家族表现出相似的失败模式。

Conclusion: 现有安全训练存在局限性，提升 LLM 安全性需发展模式感知型的防御措施。

Abstract: Large language models (LLMs) remain vulnerable to multi-turn jailbreaking
attacks that exploit conversational context to bypass safety constraints
gradually. These attacks target different harm categories (like malware
generation, harassment, or fraud) through distinct conversational approaches
(educational discussions, personal experiences, hypothetical scenarios).
Existing multi-turn jailbreaking methods often rely on heuristic or ad hoc
exploration strategies, providing limited insight into underlying model
weaknesses. The relationship between conversation patterns and model
vulnerabilities across harm categories remains poorly understood. We propose
Pattern Enhanced Chain of Attack (PE-CoA), a framework of five conversation
patterns to construct effective multi-turn jailbreaks through natural dialogue.
Evaluating PE-CoA on twelve LLMs spanning ten harm categories, we achieve
state-of-the-art performance, uncovering pattern-specific vulnerabilities and
LLM behavioral characteristics: models exhibit distinct weakness profiles where
robustness to one conversational pattern does not generalize to others, and
model families share similar failure modes. These findings highlight
limitations of safety training and indicate the need for pattern-aware
defenses. Code available on: https://github.com/Ragib-Amin-Nihal/PE-CoA

</details>


### [134] [Quality Estimation Reranking for Document-Level Translation](https://arxiv.org/abs/2510.08870)
*Krzysztof Mrozinski,Minji Kang,Ahmed Khota,Vincent Michael Sutanto,Giovanni Gatti De Giacomo*

Main category: cs.CL

TL;DR: 本文探讨了质量评估（QE）重排序在文档级机器翻译中的有效性，发现QE重排序能大幅提升译文质量，尤其是在候选译文数量较多时。


<details>
  <summary>Details</summary>
Motivation: 此前QE重排序大多应用于句子级机器翻译，但随着文档级翻译需求增长，文档级QE重排序的应用和效果尚未深入研究。作者希望检验和量化其在文档级场景下的潜力。

Method: 作者利用多种学习型和大语言模型（LLM）驱动的QE指标，在文档级机器翻译中对候选译文进行质量评分与重排序，并比较了不同指标下的性能变化。

Result: 最佳学习型指标SLIDE和最佳LLM指标GEMBA-DA在不同候选数下均带来了显著的BLEURT-20分提升。即便在超长文档中，重排序依然带来明显改进。

Conclusion: 文档级QE重排序能够在保持计算效率的前提下，显著提升大语言模型和NMT模型的翻译质量，展示了其在实际应用中的价值。

Abstract: Quality estimation (QE) reranking is a form of quality-aware decoding which
aims to improve machine translation (MT) by scoring and selecting the best
candidate from a pool of generated translations. While known to be effective at
the sentence level, its application to the increasingly prominent domain of
document-level translation remains underexplored. In this work, we evaluate QE
reranking performance on document-level (rather than the typical
sentence-level) translation, using various learned and large language model
(LLM)-based QE metrics. We find that with our best learned metric, SLIDE,
BLEURT-20 scores improve by +2.00 with only two candidates, and by +5.09 with
32, across both decoder-only LLM models and encoder-decoder neural machine
translation (NMT) models. Using the best LLM-based metric, GEMBA-DA, gains of
+1.63 and +4.30 are achieved under the same conditions. Although gains shrink
with longer inputs, reranking with 32 candidates yields improvements of +2.34
(SLIDE) and +1.40 (GEMBA-DA) on our longest documents (512-1024 source tokens).
These findings demonstrate the practical value of document-level QE, with
minimal runtime overhead given suitable translation models and hardware.

</details>


### [135] [FinAuditing: A Financial Taxonomy-Structured Multi-Document Benchmark for Evaluating LLMs](https://arxiv.org/abs/2510.08886)
*Yan Wang,Keyi Wang,Shanshan Yang,Jaisal Patel,Jeff Zhao,Fengran Mo,Xueqing Peng,Lingfei Qian,Jimin Huang,Guojun Xiong,Xiao-Yang Liu,Jian-Yun Nie*

Main category: cs.CL

TL;DR: 本文提出了FinAuditing，这是首个针对金融审计任务评估大语言模型（LLM）的结构化、多文档基准，专注于语义、关系和数值一致性。实验发现现有LLM在面对结构化财务文件时表现不佳。


<details>
  <summary>Details</summary>
Motivation: GAAP的复杂性与XBRL文件的层次结构导致金融审计自动化和验证的难度加大。目前，LLMs虽在非结构化文本理解上有优异表现，但其在税收驱动、结构化财务文件上的推理能力尚未探索。作者为满足结构化审计领域对高效、自动化智能系统的需求，创建了结构对齐、多维考察的评测基准。

Method: 构建了FinAuditing基准数据集，基于真实US-GAAP XBRL文件，设计了FinSM（语义）、FinRE（关系）、FinMR（数值）三项子任务，并提出统一评估框架，综合使用检索、分类、推理多维指标，针对13个主流LLM进行了零样本实验。

Result: 实验结果显示，现有大语言模型在处理结构化、多文档的财务报告时，在语义、关系和数学推理三个维度表现均不理想，有的准确率相比简单结构下降60-90%。

Conclusion: 当前LLM在基于结构化、层级税收体系的财务推理中的系统性短板明显，FinAuditing为开发更可信、结构感知、符合法规的智能金融系统奠定了评测基础。

Abstract: The complexity of the Generally Accepted Accounting Principles (GAAP) and the
hierarchical structure of eXtensible Business Reporting Language (XBRL) filings
make financial auditing increasingly difficult to automate and verify. While
large language models (LLMs) have demonstrated strong capabilities in
unstructured text understanding, their ability to reason over structured,
interdependent, and taxonomy-driven financial documents remains largely
unexplored. To fill this gap, we introduce FinAuditing, the first
taxonomy-aligned, structure-aware, multi-document benchmark for evaluating LLMs
on financial auditing tasks. Built from real US-GAAP-compliant XBRL filings,
FinAuditing defines three complementary subtasks, FinSM for semantic
consistency, FinRE for relational consistency, and FinMR for numerical
consistency, each targeting a distinct aspect of structured auditing reasoning.
We further propose a unified evaluation framework integrating retrieval,
classification, and reasoning metrics across these subtasks. Extensive
zero-shot experiments on 13 state-of-the-art LLMs reveal that current models
perform inconsistently across semantic, relational, and mathematical
dimensions, with accuracy drops of up to 60-90% when reasoning over
hierarchical multi-document structures. Our findings expose the systematic
limitations of modern LLMs in taxonomy-grounded financial reasoning and
establish FinAuditing as a foundation for developing trustworthy,
structure-aware, and regulation-aligned financial intelligence systems. The
benchmark dataset is available at Hugging Face.

</details>


### [136] [Exploring Multi-Temperature Strategies for Token- and Rollout-Level Control in RLVR](https://arxiv.org/abs/2510.08892)
*Haomin Zhuang,Yujun Zhou,Taicheng Guo,Yue Huang,Fangxu Liu,Kai Song,Xiangliang Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种在大语言模型生成推理时，依据不同类型token设置不同采样温度的新方法，从而提升模型在推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型在推理任务中表现优异，但不同类型的token（高熵推理token与低熵知识token）在生成过程中的作用不同。以往工作主要通过间接方法（如限制参数更新）促进模型探索性，未直接在token生成阶段引入探索机制。

Method: 作者提出针对token类型设定区别化温度：对高熵推理token采用高温度值以增加生成多样性，促进探索；对低熵知识token采用低温度值以保障事实准确性。并系统性地研究了多温度调度策略及其在强化学习环境下的效果。

Result: 实验证明该方法在多个推理任务上显著提升了LLMs的推理能力。

Conclusion: 通过基于token类型差异化的温度采样策略，可以更有效地平衡探索与准确性，切实提升大语言模型的推理表现。

Abstract: Reinforcement Learning has demonstrated substantial improvements in the
reasoning abilities of Large Language Models (LLMs), exhibiting significant
applicability across various domains. Recent research has identified that
tokens within LLMs play distinct roles during reasoning tasks, categorizing
them into high-entropy reasoning tokens and low-entropy knowledge tokens. Prior
approaches have typically focused on restricting updates to indirectly
encourage exploration, yet they do not explicitly facilitate exploratory
behavior during the token generation stage itself. In this work, we introduce a
complementary approach that explicitly promotes exploration during sampling by
applying distinct temperature settings for different token types. Specifically,
our method employs higher temperatures for reasoning tokens to actively
encourage exploration, while retaining lower temperatures for knowledge tokens
to maintain factual correctness. Furthermore, we systematically investigate
various multi-temperature scheduling strategies and their impacts within
reinforcement learning contexts. Empirical evaluations on several reasoning
benchmarks demonstrate that our approach significantly enhances the reasoning
performance of LLMs. The code is available at
https://github.com/zhmzm/Multi_Temperature_Verl.git.

</details>


### [137] [A Unified Biomedical Named Entity Recognition Framework with Large Language Models](https://arxiv.org/abs/2510.08902)
*Tengxiao Lv,Ling Luo,Juntao Li,Yanhua Wang,Yuchen Pan,Chao Liu,Yanan Wang,Yan Jiang,Huiyi Lv,Yuanyuan Sun,Jian Wang,Hongfei Lin*

Main category: cs.CL

TL;DR: 本文提出一种基于大语言模型（LLMs）的统一生物医学命名实体识别（BioNER）框架，实现了对中英双语，平面和嵌套实体的高准确率识别，并具有良好的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有BioNER方法在处理嵌套实体、实体边界模糊以及跨语言泛化上存在困难，影响医学信息抽取和知识发现的效果。

Method: 1. 将BioNER重新表述为文本生成任务；2. 设计符号化标注策略以同时处理平面和嵌套实体，明确标注实体边界；3. 跨中英多数据集进行双语联合微调，增强多语种和多任务泛化能力；4. 引入基于对比学习的实体选择器，利用边界敏感的正负样本过滤错误或杂散的预测结果。

Result: 在四个基准数据集和两个未见数据集上的实验表明，该方法达到当前最优表现，同时在跨语言零样本场景下有强泛化能力。

Conclusion: 该方法有效提升了BioNER在处理嵌套实体、边界识别及跨语言应用中的准确性和鲁棒性，有助于推动医学信息抽取自动化进程。

Abstract: Accurate recognition of biomedical named entities is critical for medical
information extraction and knowledge discovery. However, existing methods often
struggle with nested entities, entity boundary ambiguity, and cross-lingual
generalization. In this paper, we propose a unified Biomedical Named Entity
Recognition (BioNER) framework based on Large Language Models (LLMs). We first
reformulate BioNER as a text generation task and design a symbolic tagging
strategy to jointly handle both flat and nested entities with explicit boundary
annotation. To enhance multilingual and multi-task generalization, we perform
bilingual joint fine-tuning across multiple Chinese and English datasets.
Additionally, we introduce a contrastive learning-based entity selector that
filters incorrect or spurious predictions by leveraging boundary-sensitive
positive and negative samples. Experimental results on four benchmark datasets
and two unseen corpora show that our method achieves state-of-the-art
performance and robust zero-shot generalization across languages. The source
codes are freely available at https://github.com/dreamer-tx/LLMNER.

</details>


### [138] [Autoencoding-Free Context Compression for LLMs via Contextual Semantic Anchors](https://arxiv.org/abs/2510.08907)
*Xin Liu,RunSong Zhao,PengCheng Huang,XinYu Liu,JunYi Xiao,ChunYang Xiao,Tong Xiao,Shengxiang Gao,Zhengtao Yu,JingBo Zhu*

Main category: cs.CL

TL;DR: 本文提出了一种新的语义锚点压缩（SAC）方法，通过直接选择并利用原始上下文中的重要锚点token及其KV表示，实现高效的上下文压缩，免去了传统自编码训练流程，压缩效果超过现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前大模型的上下文压缩方法大多依赖于自编码任务训练与重建原始内容，但这种训练与实际下游任务之间存在目标不一致，导致模型压缩后在真实应用中的表现受限。

Method: SAC方法不再用自编码训练方式进行压缩，而是直接从原始上下文中选取“锚点token”，并将上下文信息聚合到这些锚点的KV表示中。该方法包括两大设计：(1) 锚点嵌入用于识别关键token；(2) 双向注意力修改机制用于让锚点获得全局上下文信息。这样无需额外训练即可实现压缩。

Result: 实验表明，SAC在多种压缩比条件下，相对现有上下文压缩方法都表现更优；在MRQA等OOD（分布外）评估任务上，SAC在5倍压缩时较强baseline提升1 EM分数，随着压缩比提升优势更明显。

Conclusion: SAC免去了自编码训练，设计直接、有效，压缩表现优于现有方法，尤其在高压缩比下优势突出，为LLM上下文压缩提供了更优解。

Abstract: Context compression presents a promising approach for accelerating large
language model (LLM) inference by compressing long contexts into compact
representations. Current context compression methods predominantly rely on
autoencoding tasks to train context-agnostic compression tokens to compress
contextual semantics. While autoencoding tasks enable compression tokens to
acquire compression capabilities, compression via autoencoding tasks creates a
fundamental mismatch: the models are optimized for reconstruction that diverge
from actual downstream tasks, thereby weakening the features more beneficial
for real-world usage. We propose Semantic-Anchor Compression (SAC), a novel
method that shifts from autoencoding task based compression to an architecture
that is equipped with this compression capability \textit{a priori}. Instead of
training models to compress contexts through autoencoding tasks, SAC directly
selects so-called anchor tokens from the original context and aggregates
contextual information into their key-value (KV) representations. By deriving
representations directly from the contextual tokens, SAC eliminates the need
for autoencoding training. To ensure compression performance while directly
leveraging anchor tokens, SAC incorporates two key designs: (1) anchor
embeddings that enable the compressor to identify critical tokens, and (2)
bidirectional attention modification that allows anchor tokens to capture
information from the entire context. Experimental results demonstrate that SAC
consistently outperforms existing context compression methods across various
compression ratios. On out-of-distribution evaluation using MRQA, SAC achieves
1 EM improvement at 5x compression over strong baselines, with increasing
advantages at higher compression ratios.

</details>


### [139] [Artificial Impressions: Evaluating Large Language Model Behavior Through the Lens of Trait Impressions](https://arxiv.org/abs/2510.08915)
*Nicholas Deas,Kathleen McKeown*

Main category: cs.CL

TL;DR: 本论文研究了大型语言模型（LLM）内部如何形成类似于人类印象和刻板印象的“人工印象”，并分析了这些印象对模型行为的影响。


<details>
  <summary>Details</summary>
Motivation: 人类在理解语言时会自动形成印象和刻板印象，了解LLM是否也会形成类似印象，有助于揭示其决策机制和潜在偏见，并提高模型的可解释性与公平性。

Method: 作者通过对生成的提示（prompts）使用双维刻板印象内容模型（Stereotype Content Model, SCM），训练线性探测器（linear probes）以预测LLM内部的印象表示，然后分析印象与模型下游行为及提示语特征之间的关系，包含内容、风格和方言等因素。

Result: 研究发现，LLM在显式表达印象时不稳定，但印象在隐藏层中更容易被线性探测器解码。此外，这些人工印象能预测模型回答时的措辞质量和使用模糊语气（hedging）的情况。不同提示中的内容、风格和方言也影响LLM形成的印象。

Conclusion: LLM内部会以隐性的方式形成人工印象，并影响生成文本的质量与风格。理解这些过程有助于未来改进模型的透明性和减少偏见影响。

Abstract: We introduce and study artificial impressions--patterns in LLMs' internal
representations of prompts that resemble human impressions and stereotypes
based on language. We fit linear probes on generated prompts to predict
impressions according to the two-dimensional Stereotype Content Model (SCM).
Using these probes, we study the relationship between impressions and
downstream model behavior as well as prompt features that may inform such
impressions. We find that LLMs inconsistently report impressions when prompted,
but also that impressions are more consistently linearly decodable from their
hidden representations. Additionally, we show that artificial impressions of
prompts are predictive of the quality and use of hedging in model responses. We
also investigate how particular content, stylistic, and dialectal features in
prompts impact LLM impressions.

</details>


### [140] [SOP-Maze: Evaluating Large Language Models on Complicated Business Standard Operating Procedures](https://arxiv.org/abs/2510.08942)
*Jiaming Wang,Zhe Tang,Yilin Jin,Peng Ding,Xiaoyu Li,Xuezhi Cao*

Main category: cs.CL

TL;DR: 本文提出了SOP-Maze基准，用以评估LLM在复杂商业标准操作流程（SOP）场景下的能力，结果显示现有模型普遍存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型（LLM）在特定领域得到了广泛应用，也有许多测试标准评估其指令执行与决策能力，但现实中的业务SOP流程更为复杂，相关能力评估尚不充分，因此需要针对复杂SOP场景专门的评测方法。

Method: 作者从真实业务数据中构建了SOP-Maze基准集，包括23种复杂SOP场景下的397个任务，并将任务分为两类：宽选项任务（LRS）需精确选择，深逻辑任务（HRS）需复杂推理。同时对现有主流LLM进行了广泛测试。

Result: 测试结果表明，主流LLM在SOP-Maze基准下表现不佳，表现为三大类典型错误：路径盲点（无法跟随流程）、对话脆弱（复杂对话处理能力弱）、和计算错误（时序及算术推理错误）。

Conclusion: SOP-Maze有效揭示了LLM在复杂商业流程下的能力短板，为今后模型能力提升与实际应用指明方向。相关数据和资源已开放共享。

Abstract: As large language models (LLMs) are widely deployed as domain-specific
agents, many benchmarks have been proposed to evaluate their ability to follow
instructions and make decisions in real-world scenarios. However, business
scenarios often involve complex standard operating procedures (SOPs), and the
evaluation of LLM capabilities in such contexts has not been fully explored. To
bridge this gap, we propose SOP-Maze, a benchmark constructed from real-world
business data and adapted into a collection of 397 tasks from 23 complex SOP
scenarios. We further categorize SOP tasks into two broad classes: Lateral Root
System (LRS), representing wide-option tasks that demand precise selection; and
Heart Root System (HRS), which emphasizes deep logical reasoning with complex
branches. Extensive experiments reveal that nearly all state-of-the-art models
struggle with SOP-Maze. We conduct a comprehensive analysis and identify three
key error categories: (i) route blindness: difficulty following procedures;
(ii) conversational fragility: inability to handle real dialogue nuances; and
(iii) calculation errors: mistakes in time or arithmetic reasoning under
complex contexts. The systematic study explores LLM performance across SOP
tasks that challenge both breadth and depth, offering new insights for
improving model capabilities. We have open-sourced our work on
https://github.com/ADoublLEN/SOP-Maze.

</details>


### [141] [A Human Behavioral Baseline for Collective Governance in Software Projects](https://arxiv.org/abs/2510.08956)
*Mobina Noori,Mahasweta Chakraborti,Amy X Zhang,Seth Frey*

Main category: cs.CL

TL;DR: 本文通过分析开源社区治理文档，探讨了参与与控制的表述及其演变。


<details>
  <summary>Details</summary>
Motivation: 了解开源项目治理结构如何在参与和控制方面发展变化，尤其关注角色和行动的描述，以及AI未来是否会影响权力的分布。

Method: 收集710个项目的治理文档历史快照，通过文本解析提取行为者、规则、行为和对象，并用信息熵、丰富度、Jensen Shannon散度等指标衡量变化。

Result: 随着时间的推移，项目定义的角色和行动数量增加且分布更均匀，但整体规则结构稳定。

Conclusion: 开源项目治理通过扩展和均衡角色与参与类别实现发展，而非显著增强规范性。该研究为今后评估AI对权力分配影响提供基线。

Abstract: We study how open source communities describe participation and control
through version controlled governance documents. Using a corpus of 710 projects
with paired snapshots, we parse text into actors, rules, actions, and objects,
then group them and measure change with entropy for evenness, richness for
diversity, and Jensen Shannon divergence for drift. Projects define more roles
and more actions over time, and these are distributed more evenly, while the
composition of rules remains stable. These findings indicate that governance
grows by expanding and balancing categories of participation without major
shifts in prescriptive force. The analysis provides a reproducible baseline for
evaluating whether future AI mediated workflows concentrate or redistribute
authority.

</details>


### [142] [Creation of the Chinese Adaptive Policy Communication Corpus](https://arxiv.org/abs/2510.08986)
*Bolun Sun,Charles Chang,Yuen Yuen Ang,Pingxu Hao,Ruotong Mu,Yuchen Xu,Zhengxin Zhang*

Main category: cs.CL

TL;DR: 本文介绍了首个中文政策指令开放数据集CAPC-CG，包含了自1949年以来的国家级政策文件，并对文本进行五类语言模糊/清晰标签标注。


<details>
  <summary>Details</summary>
Motivation: 缺乏多语言、特别是中文的高质量政策沟通数据集，限制了政策语料分析、政策沟通模糊性研究等相关NLP应用的发展，尤其是在中国政府文件中的实际应用。

Method: 建立大型语料库（1949-2023年中国中央政府政策文件），将所有文本按段落切分，并采用五色标签体系标注模糊与清晰语言，设计了双轮标注流程，借助专家与训练过的标注员，统计一致性（Fleiss's kappa = 0.86），并用LLMs基线实验检验效果。

Result: 形成了3.3百万个段落的高质量中文政策文件标注数据集，并公布了元数据、标注手册、专家金标集及多种LLM分类基线，标注一致性高。数据揭示了政策沟通中语言清晰性与模糊性的分布和规律。

Conclusion: CAPC-CG数据集有助于推动政策沟通、法律NLP和多语言政策文本研究，为政策文本分析和下游NLP任务提供高质量的训练资源。

Abstract: We introduce CAPC-CG, the Chinese Adaptive Policy Communication (Central
Government) Corpus, the first open dataset of Chinese policy directives
annotated with a five-color taxonomy of clear and ambiguous language
categories, building on Ang's theory of adaptive policy communication. Spanning
1949-2023, this corpus includes national laws, administrative regulations, and
ministerial rules issued by China's top authorities. Each document is segmented
into paragraphs, producing a total of 3.3 million units. Alongside the corpus,
we release comprehensive metadata, a two-round labeling framework, and a
gold-standard annotation set developed by expert and trained coders.
Inter-annotator agreement achieves a Fleiss's kappa of K = 0.86 on directive
labels, indicating high reliability for supervised modeling. We provide
baseline classification results with several large language models (LLMs),
together with our annotation codebook, and describe patterns from the dataset.
This release aims to support downstream tasks and multilingual NLP research in
policy communication.

</details>


### [143] [MASA: LLM-Driven Multi-Agent Systems for Autoformalization](https://arxiv.org/abs/2510.08988)
*Lan Zhang,Marco Valentino,André Freitas*

Main category: cs.CL

TL;DR: 本文提出了MASA，一个基于大型语言模型（LLM）驱动的多智能体系统，用于实现自然语言到形式化表达的自动化转换。MASA具有高度模块化和可扩展性，能高效整合新智能体和工具。通过真实数学定义和数据集实验，MASA被证明可提升自动形式化的效率和可靠性。


<details>
  <summary>Details</summary>
Motivation: 自动形式化是将自然语言与形式化推理相连接的关键技术。由于自然语言与形式化表达之间存在语义鸿沟，如何高效、准确地实现两者的转化成为研究难点。

Method: 论文提出了MASA框架，采用协作式多智能体结构，各智能体在大型语言模型驱动下共同将自然语言陈述转化为形式化表达。整个体系强调模块化、灵活性和可扩展性，便于集成新的智能体和工具。

Result: 通过在真实数学定义和形式化数学数据集上的应用与实验，MASA展现出了较强的效果，能够有效提升自动形式化任务的效能和可靠性。

Conclusion: MASA证明了多智能体系统结合大型语言模型与定理证明器在自动形式化领域的潜力，为相关研究者和从业者带来借鉴与支持，有望驱动该领域进一步发展。

Abstract: Autoformalization serves a crucial role in connecting natural language and
formal reasoning. This paper presents MASA, a novel framework for building
multi-agent systems for autoformalization driven by Large Language Models
(LLMs). MASA leverages collaborative agents to convert natural language
statements into their formal representations. The architecture of MASA is
designed with a strong emphasis on modularity, flexibility, and extensibility,
allowing seamless integration of new agents and tools to adapt to a
fast-evolving field. We showcase the effectiveness of MASA through use cases on
real-world mathematical definitions and experiments on formal mathematics
datasets. This work highlights the potential of multi-agent systems powered by
the interaction of LLMs and theorem provers in enhancing the efficiency and
reliability of autoformalization, providing valuable insights and support for
researchers and practitioners in the field.

</details>


### [144] [DARO: Difficulty-Aware Reweighting Policy Optimization](https://arxiv.org/abs/2510.09001)
*Jingyu Zhou,Lu Ma,Hao Liang,Chengyu Shen,Bin Cui,Wentao Zhang*

Main category: cs.CL

TL;DR: 本文提出了DARO方法，通过难度感知的动态重加权机制，提升了大语言模型在RLVR训练下的推理能力，实验显示DARO优于现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于RLVR的方法（如GRPO及其变体）普遍采用静态或过于简单的权重机制，导致训练关注于特定难度等级样本，限制了模型性能的全面提升。

Method: 本文分析了主流RLVR方法，并提出了Difficulty-Aware Reweighting Policy Optimization（DARO），依据模型当前的学习状态动态调整不同难度组别样本的损失权重。

Result: DARO在Qwen2.5-Math-1.5B、Qwen2.5-Math-7B和Llama3.1-8B上，六个数学基准测试中全面优于四类主流方法，实现了更快收敛与更高终极性能。

Conclusion: DARO克服了现有RLVR方法的失衡问题，通过动态权重提升了模型多难度水平上的综合能力，为未来RL训练方法的设计提供了新思路。

Abstract: Recent advances in large language models (LLMs) have shown that reasoning
ability can be significantly enhanced through Reinforcement Learning with
Verifiable Rewards (RLVR). Group Relative Policy Optimization (GRPO) has
emerged as the de facto approach for RLVR, inspiring numerous variants.
However, our mathematical analysis reveals that these methods are fundamentally
weighted variations of GRPO. We provide a unified view, demonstrating that
their reliance on static or overly simplistic weighting schemes tied to sample
difficulty prevents adaptation to a model's evolving capabilities. This creates
a significant loss scale issue, where training disproportionately focuses on
certain difficulty levels at the expense of others, hindering overall
performance. To address these limitations, we introduce
\textbf{Difficulty-Aware Reweighting Policy Optimization (DARO)}, a method that
dynamically adjusts the loss contribution of each difficulty group based on the
model's learning state. Extensive experiments on Qwen2.5-Math-1.5B,
Qwen2.5-Math-7B, and Llama3.1-8B show that DARO outperforms four leading
baselines across six math benchmarks, achieving significantly faster
convergence and superior final performance.

</details>


### [145] [Decoupling Safety into Orthogonal Subspace: Cost-Efficient and Performance-Preserving Alignment for Large Language Models](https://arxiv.org/abs/2510.09004)
*Yutao Mou,Xiaoling Zhou,Yuxiao Luo,Shikun Zhang,Wei Ye*

Main category: cs.CL

TL;DR: 本文提出利用LoRA（Low-Rank Adaptation）对大模型进行拒绝训练实现安全性对齐，不影响模型通用性能的同时提升安全属性，无需复杂的数据配比调优。


<details>
  <summary>Details</summary>
Motivation: 现有提升大模型安全性的方式往往导致其通用性能下降，而且需耗费大量计算资源寻找安全与性能的最佳数据比例，效率低、成本高。

Method: 作者提出基于LoRA的拒绝训练方法，仅用安全性数据即可实现安全属性提升，并对LoRA进行理论与实验分析，发现该方法可以将安全属性调整到与模型主功能低相关的子空间，提高安全性而不损害能力。

Result: 实验和理论结果均表明，LoRA拒绝训练能有效提升模型安全性，同时保持通用性能，且成本远低于传统方法。

Conclusion: 采用LoRA实现的安全性对齐具有高效、低成本、模块化特点，可作为大模型安全属性的增强插件，不会牺牲模型既有性能。

Abstract: Safety alignment is essential for building trustworthy artificial
intelligence, yet it remains challenging to enhance model safety without
degrading general performance. Current approaches require computationally
expensive searches for the optimal proportion of safety-critical and
general-purpose data to balance safety and general performance, incurring high
costs with limited gains. In this work, we show that LoRA-based
Refusal-training enables performance-preserving safety alignment even when
trained solely on safety data, demonstrating that LoRA serves as
cost-efficient, performance-preserving, and plug-and-play safety patches.
Beyond empirical findings, we provide both theoretical and experimental
evidence that LoRA effectively decouples safety into a low-rank subspace
largely orthogonal to the model's intrinsic transformation space, ensuring that
safety enhancements do not interfere with inherent capabilities.

</details>


### [146] [LitE-SQL: A Lightweight and Efficient Text-to-SQL Framework with Vector-based Schema Linking and Execution-Guided Self-Correction](https://arxiv.org/abs/2510.09014)
*Shengmin Piao,Jieun Lee,Sanghyun Park*

Main category: cs.CL

TL;DR: 本文提出了一种轻量高效的Text-to-SQL模型LitE-SQL，在保证隐私和资源有限的情况下也能实现强劲的翻译准确率。


<details>
  <summary>Details</summary>
Motivation: 当前Text-to-SQL模型依赖大规模专有LLM，带来部署和数据隐私方面的困扰，因此作者希望构建一种既高效又便于部署的方案。

Method: LitE-SQL包括两个主要部分：(1) 利用向量数据库预先计算并检索schema嵌入，实现高效schema关联；(2) SQL生成器采用两阶段微调（有监督微调+基于执行结果的强化学习），不需要多候选生成即可实现自我纠错。

Result: 在BIRD数据集上，LitE-SQL取得了72.1%的执行准确率，在Spider 1.0数据集上达到了88.45%，用更少参数取得可比甚至更优性能。

Conclusion: 轻量级模型同样能够实现高质量的Text-to-SQL翻译，适用于对隐私和计算资源有较高要求的实际环境。

Abstract: The Text-to-SQL task translates natural language questions into SQL queries,
enabling intuitive database interaction for non-experts. While recent methods
leveraging Large Language Models (LLMs) achieve strong performance, their
reliance on proprietary models raise concerns about deployment feasibility and
data privacy. In this work, we introduce LitE-SQL, a Lightweight and Efficient
framework with two components: (i) a Schema Retriever that performs efficient
schema linking using a vector database of pre-computed schema embeddings, and
(ii) a SQL Generator fine-tuned in two stages-supervised fine-tuning followed
by execution-guided reinforcement-enabling self-correction without costly
multi-candidate generation. On BIRD, LitE-SQL achieves 72.10% execution
accuracy, and on Spider 1.0 it reaches 88.45%, demonstrating comparable or
superior performance to LLM-based methods despite using 2x to 30x fewer
parameters. Our findings demonstrate that high-quality Text-to-SQL generation
is feasible with lightweight models, offering a practical solution for
privacy-sensitive and resource-constrained settings.

</details>


### [147] [Automated Refinement of Essay Scoring Rubrics for Language Models via Reflect-and-Revise](https://arxiv.org/abs/2510.09030)
*Keno Harada,Lui Yoshida,Takeshi Kojima,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.CL

TL;DR: 本研究通过引入迭代评分标准优化方法，显著提升了大模型在自动作文评分任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）在自动作文评分（AES）领域的应用，模型对于评分提示（prompts）敏感，提示优化对提升模型表现起到关键作用，但鲜有研究关注于评分标准本身的精炼与模型评分一致性的改进。

Method: 提出了一种让模型反思自身评分理由，并结合与人类评分差异，迭代优化评分标准（rubric）的提示方法，并在TOEFL11和ASAP数据集上，分别用GPT-4.1、Gemini-2.5-Pro和Qwen-3-Next-80B-A3B-Instruct进行了实证研究。

Result: 在TOEFL11和ASAP数据集上，提出方法的QWK指标分别提升了最多0.19和0.47。即使起始评分标准较为简单，也能达到或超过使用详尽人工标准的效果。

Conclusion: 反复优化评分标准，可以大幅提升大模型自动评分与人工评分的一致性，强调了迭代优化评分标准在大语言模型自动评分系统中的重要性。

Abstract: The performance of Large Language Models (LLMs) is highly sensitive to the
prompts they are given. Drawing inspiration from the field of prompt
optimization, this study investigates the potential for enhancing Automated
Essay Scoring (AES) by refining the scoring rubrics used by LLMs. Specifically,
our approach prompts models to iteratively refine rubrics by reflecting on
models' own scoring rationales and observed discrepancies with human scores on
sample essays. Experiments on the TOEFL11 and ASAP datasets using GPT-4.1,
Gemini-2.5-Pro, and Qwen-3-Next-80B-A3B-Instruct show Quadratic Weighted Kappa
(QWK) improvements of up to 0.19 and 0.47, respectively. Notably, even with a
simple initial rubric, our approach achieves comparable or better QWK than
using detailed human-authored rubrics. Our findings highlight the importance of
iterative rubric refinement in LLM-based AES to enhance alignment with human
evaluations.

</details>


### [148] [Exploring Cross-Lingual Knowledge Transfer via Transliteration-Based MLM Fine-Tuning for Critically Low-resource Chakma Language](https://arxiv.org/abs/2510.09032)
*Adity Khisa,Nusrat Jahan Lia,Tasnim Mahfuz Nafis,Zarif Masud,Tanzir Pial,Shebuti Rayana,Ahmedul Kabir*

Main category: cs.CL

TL;DR: 本文针对资源稀缺的Chakma语，构建了一个经母语者校验的Bangla音译Chakma语料库，并用其对六种多语言及区域性Transformer模型进行微调，有效提升了模型对Chakma语的处理能力。


<details>
  <summary>Details</summary>
Motivation: Chakma语作为一种印度-雅利安语系的小语种，其在现有语言模型中的资源极为有限，为支持这一低资源语言的处理与建模，亟需高质量的专门语料库及适配方法。

Method: 构建并发布了一个来自Chakma文学作品、人工校验的Bangla音译Chakma语料库；在此基础上，使用该数据对mBERT、XLM-RoBERTa、DistilBERT、DeBERTaV3、BanglaBERT和IndicBERT等六种模型进行了MLM任务微调，并进行了性能评估和分析。

Result: 微调后的多语言模型在Bangla音译Chakma文本上的表现优于仅用原始预训练权重，最高实现了73.54%的token准确率和2.90的困惑度。同时分析证明了数据质量对模型提升的重要影响，以及OCR技术在处理形态复杂的印度文字体系中的局限。

Conclusion: Bangla音译的Chakma语在模型迁移学习中可显著提升对Chakma语的处理能力，所发布的数据集将有助于推动更多低资源语言的多语言模型研究。

Abstract: As an Indo-Aryan language with limited available data, Chakma remains largely
underrepresented in language models. In this work, we introduce a novel corpus
of contextually coherent Bangla-transliterated Chakma, curated from Chakma
literature, and validated by native speakers. Using this dataset, we fine-tune
six encoder-based multilingual and regional transformer models (mBERT,
XLM-RoBERTa, DistilBERT, DeBERTaV3, BanglaBERT, and IndicBERT) on masked
language modeling (MLM) tasks. Our experiments show that fine-tuned
multilingual models outperform their pre-trained counterparts when adapted to
Bangla-transliterated Chakma, achieving up to 73.54% token accuracy and a
perplexity as low as 2.90. Our analysis further highlights the impact of data
quality on model performance and shows the limitations of OCR pipelines for
morphologically rich Indic scripts. Our research demonstrates that
Bangla-transliterated Chakma can be very effective for transfer learning for
Chakma language, and we release our manually validated monolingual dataset to
encourage further research on multilingual language modeling for low-resource
languages.

</details>


### [149] [Large Language Models Do NOT Really Know What They Don't Know](https://arxiv.org/abs/2510.09033)
*Chi Seng Cheang,Hou Pong Chan,Wenxuan Zhang,Yang Deng*

Main category: cs.CL

TL;DR: 论文分析了大型语言模型（LLMs）在内部表征中能否区分事实和幻觉（错误信息）。结果表明，LLMs在关联主体知识的幻觉与真实答案时，其内部状态难以区分，只有与主体知识无关的幻觉才便于检测。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs取得了很好的事实性表现，但它们依赖于训练目标，有时会产生与事实不符的幻觉。社区关注能否通过分析模型内部表示来识别和区分这些幻觉，以提升模型的可靠性和可控性。

Method: 作者通过对比两类幻觉的内部表征（与主体知识相关和无关），分析LLMs在处理事实问答时的隐藏状态空间几何结构。评估内部状态是否能用来区分事实和幻觉输出。

Result: 若幻觉与主体知识相关，LLMs的内部召回过程与正确答案高度一致，导致隐藏状态难以区分；而与知识无关的幻觉在内部表征上与真实答案有明显区别，形成可检测的聚类。

Conclusion: LLMs的内部状态并不直接编码真实性，只反映了知识召回的模式，因此无法从内部表征可靠区分所有幻觉，表明“LLMs其实不知道自己不知道什么”。

Abstract: Recent work suggests that large language models (LLMs) encode factuality
signals in their internal representations, such as hidden states, attention
weights, or token probabilities, implying that LLMs may "know what they don't
know". However, LLMs can also produce factual errors by relying on shortcuts or
spurious associations. These error are driven by the same training objective
that encourage correct predictions, raising the question of whether internal
computations can reliably distinguish between factual and hallucinated outputs.
In this work, we conduct a mechanistic analysis of how LLMs internally process
factual queries by comparing two types of hallucinations based on their
reliance on subject information. We find that when hallucinations are
associated with subject knowledge, LLMs employ the same internal recall process
as for correct responses, leading to overlapping and indistinguishable
hidden-state geometries. In contrast, hallucinations detached from subject
knowledge produce distinct, clustered representations that make them
detectable. These findings reveal a fundamental limitation: LLMs do not encode
truthfulness in their internal states but only patterns of knowledge recall,
demonstrating that "LLMs don't really know what they don't know".

</details>


### [150] [Alif: Advancing Urdu Large Language Models via Multilingual Synthetic Data Distillation](https://arxiv.org/abs/2510.09051)
*Muhammad Ali Shafique,Kanwal Mehreen,Muhammad Arham,Maaz Amjad,Sabur Butt,Hamza Farooq*

Main category: cs.CL

TL;DR: 本文提出了一种用于乌尔都语-英语的多语种大语言模型（Alif-1.0-8B-Instruct），通过构建高质量的合成数据集和改进的自指令方法，显著提升了低资源语言的大模型性能，模型和数据已开源。


<details>
  <summary>Details</summary>
Motivation: 乌尔都语等低资源语言在现有大模型中的表现受限，主要原因在于高质量数据稀缺、多语种模型存在不一致性以及安全性挑战，现有的翻译采集数据方法难以兼顾质量、文化和成本。

Method: 1）提出Alif-1.0-8B-Instruct多语种模型；2）使用修改后的自指令技术，结合独特的提示词和种子库、全局任务池，生成高质量含链式推理、双语翻译、文化相关性和伦理安全性的合成数据集（Urdu-Instruct）；3）以Llama-3.1-8B为基础进行训练。

Result: Alif-1.0-8B-Instruct在乌尔都语相关任务上优于Llama-3.1-8B-Instruct，并且超过了Mistral-7B-Instruct-v0.3、Qwen-2.5-7B-Instruct和Cohere-Aya-Expanse-8B等领先多语言模型，且训练预算低于$100。

Conclusion: 通过改进自指令方法可以高效、低成本地构建性能优良、具备文化适应性的低资源语言大模型，对于乌尔都语等低资源语言具有显著应用价值。

Abstract: Developing a high-performing large language models (LLMs) for low-resource
languages such as Urdu, present several challenges. These challenges include
the scarcity of high-quality datasets, multilingual inconsistencies, and safety
concerns. Existing multilingual LLMs often address these issues by translating
large volumes of available data. However, such translations often lack quality
and cultural nuance while also incurring significant costs for data curation
and training. To address these issues, we propose Alif-1.0-8B-Instruct, a
multilingual Urdu-English model, that tackles these challenges with a unique
approach. We train the model on a high-quality, multilingual synthetic dataset
(Urdu-Instruct), developed using a modified self-instruct technique. By using
unique prompts and seed values for each task along with a global task pool,
this dataset incorporates Urdu-native chain-of-thought based reasoning,
bilingual translation, cultural relevance, and ethical safety alignments. This
technique significantly enhances the comprehension of Alif-1.0-8B-Instruct
model for Urdu-specific tasks. As a result, Alif-1.0-8B-Instruct, built upon
the pretrained Llama-3.1-8B, demonstrates superior performance compared to
Llama-3.1-8B-Instruct for Urdu specific-tasks. It also outperformed leading
multilingual LLMs, including Mistral-7B-Instruct-v0.3, Qwen-2.5-7B-Instruct,
and Cohere-Aya-Expanse-8B, all within a training budget of under $100. Our
results demonstrate that high-performance and low-resource language LLMs can be
developed efficiently and culturally aligned using our modified self-instruct
approach. All datasets, models, and code are publicly available at:
https://github.com/traversaal-ai/alif-urdu-llm.

</details>


### [151] [ReFIne: A Framework for Trustworthy Large Reasoning Models with Reliability, Faithfulness, and Interpretability](https://arxiv.org/abs/2510.09062)
*Chung-En Sun,Ge Yan,Akshay Kulkarni,Tsui-Wei Weng*

Main category: cs.CL

TL;DR: 论文提出了一个全新的长链推理训练框架ReFIne，旨在提升大模型在可解释性、忠实性和可靠性三方面的可信度，从而让推理系统更值得信赖。


<details>
  <summary>Details</summary>
Motivation: 当前长链推理研究多聚焦于提升答案准确率和令牌效率，但很少关注推理过程的可信度，如解释清晰性、推理忠实性和输出可靠性。作者认为，只有兼顾这些维度，推理系统才具备实用性。

Method: 提出了ReFIne训练框架，将有监督微调与GRPO（possibly一种RL训练技术）结合，设计结构化、带标签的推理步骤，要求模型在推理过程中进行高层次规划、披露决定信息、引用推理依据，并通过自评机制对推理声音性和答案信心做出判断。

Result: 在Qwen3不同规模模型（1.7B/4B/8B）与多种数学基准测试上，ReFIne模型的推理过程较基线模型更清晰（可解释性提升44%）、更忠实（忠实性提升18.8%）、可靠性更高（提升42.4%），实验结果突出三大维度的全面改进。

Conclusion: 作者强调推理模型优化不应只关注准确率，还应系统提升可解释性、忠实性和可靠性，为可信赖AI推理指明新方向。

Abstract: Recent advances in long chain-of-thought (CoT) reasoning have largely
prioritized answer accuracy and token efficiency, while overlooking aspects
critical to trustworthiness. We argue that usable reasoning systems must be
trustworthy, characterized by three properties: interpretability, faithfulness,
and reliability. To this end, we propose ReFIne, a new training framework that
integrates supervised fine-tuning with GRPO to encourage models to: (i) improve
interpretability by producing structured, tag-based traces with high-level
planning that are easier for humans to follow; (ii) enhance faithfulness by
explicitly disclosing the decisive information guiding each solution, with
consistent cross-section references; and (iii) promote reliability by providing
self-assessments of both the derivation's soundness and the confidence of the
final answer. We apply ReFIne to the Qwen3 models at multiple scales
(1.7B/4B/8B) and evaluate across mathematical benchmarks of varying difficulty.
Our experimental results show that ReFIne models generate clearer and
better-structured reasoning traces (interpretability +44.0%), more faithfully
expose their underlying decision process (faithfulness +18.8%), and offer
informative confidence estimates (reliability +42.4%). These findings highlight
an overlooked but important direction: reasoning models should be optimized not
only for accuracy, but also for broader dimensions of trustworthiness. Our code
is available at:
https://github.com/Trustworthy-ML-Lab/Training_Trustworthy_LRM_with_Refine

</details>


### [152] [FrameEOL: Semantic Frame Induction using Causal Language Models](https://arxiv.org/abs/2510.09097)
*Chihiro Yano,Kosuke Yamada,Hayato Tsukagoshi,Ryohei Sasano,Koichi Takeda*

Main category: cs.CL

TL;DR: 这篇论文提出了一种利用因果语言模型（如GPT、Llama）进行语义框架归纳的新方法，并证明了在英语和日语数据上优于以往方法，尤其是在日语上表现突出。


<details>
  <summary>Details</summary>
Motivation: 当前的语义框架归纳通常基于BERT等掩码语言模型（MLM），但因果语言模型虽在理解任务表现优异，却尚未被应用于此任务。研究动机是弥补CLM在这一领域的空白并探索其潜力。

Method: 作者提出了一种基于CLM的新方法FrameEOL，通过提示学习获取代表语义框架的词嵌入，并结合上下文学习（ICL）和深度度量学习（DML）以优化嵌入表示，最终基于聚类进行框架归纳。

Result: 在英语和日语FrameNet数据集上，论文方法优于现有语义框架归纳方法。特别是在日语上，仅用5个ICL示例的CLM法就能达到甚至超过经过DML微调的MLM法。

Conclusion: 因果语言模型通过适当设计的方法（如FrameEOL）在语义框架归纳任务中有很大潜力，尤其是在低资源语言上也能取得优异性能，对现有方法形成了有力补充。

Abstract: Semantic frame induction is the task of clustering frame-evoking words
according to the semantic frames they evoke. In recent years, leveraging
embeddings of frame-evoking words that are obtained using masked language
models (MLMs) such as BERT has led to high-performance semantic frame
induction. Although causal language models (CLMs) such as the GPT and Llama
series succeed in a wide range of language comprehension tasks and can engage
in dialogue as if they understood frames, they have not yet been applied to
semantic frame induction. We propose a new method for semantic frame induction
based on CLMs. Specifically, we introduce FrameEOL, a prompt-based method for
obtaining Frame Embeddings that outputs One frame-name as a Label representing
the given situation. To obtain embeddings more suitable for frame induction, we
leverage in-context learning (ICL) and deep metric learning (DML). Frame
induction is then performed by clustering the resulting embeddings.
Experimental results on the English and Japanese FrameNet datasets demonstrate
that the proposed methods outperform existing frame induction methods. In
particular, for Japanese, which lacks extensive frame resources, the CLM-based
method using only 5 ICL examples achieved comparable performance to the
MLM-based method fine-tuned with DML.

</details>


### [153] [When Retrieval Succeeds and Fails: Rethinking Retrieval-Augmented Generation for LLMs](https://arxiv.org/abs/2510.09106)
*Yongjie Wang,Yue Yu,Kaisong Song,Jun Lin,Zhiqi Shen*

Main category: cs.CL

TL;DR: 本文综述了检索增强生成（RAG）技术，在大语言模型迅速发展的背景下，分析了RAG相较于LLMs的优势、挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的广泛应用和能力提升，其在处理新兴信息和专业领域问题上仍有限，RAG应运而生以弥补LLMs的信息获取短板。

Method: 本文首先介绍RAG的目标和核心组件，接着分析其在应用中遇到的关键挑战和不足，并展示RAG在特定场景下显著提升LLMs表现的例子。

Result: 研究揭示了RAG在处理LLMs无法独立胜任任务时具有提升效果，但随着LLMs能力增强，RAG的相对优势被削弱，其局限性也日益突出。

Conclusion: 作者呼吁学界重新思考RAG的角色，并鼓励开发新一代RAG系统，以更好结合LLMs与外部检索能力，适应未来需求。

Abstract: Large Language Models (LLMs) have enabled a wide range of applications
through their powerful capabilities in language understanding and generation.
However, as LLMs are trained on static corpora, they face difficulties in
addressing rapidly evolving information or domain-specific queries.
Retrieval-Augmented Generation (RAG) was developed to overcome this limitation
by integrating LLMs with external retrieval mechanisms, allowing them to access
up-to-date and contextually relevant knowledge. However, as LLMs themselves
continue to advance in scale and capability, the relative advantages of
traditional RAG frameworks have become less pronounced and necessary. Here, we
present a comprehensive review of RAG, beginning with its overarching
objectives and core components. We then analyze the key challenges within RAG,
highlighting critical weakness that may limit its effectiveness. Finally, we
showcase applications where LLMs alone perform inadequately, but where RAG,
when combined with LLMs, can substantially enhance their effectiveness. We hope
this work will encourage researchers to reconsider the role of RAG and inspire
the development of next-generation RAG systems.

</details>


### [154] [DITING: A Multi-Agent Evaluation Framework for Benchmarking Web Novel Translation](https://arxiv.org/abs/2510.09116)
*Enze Zhang,Jiaying Wang,Mengxi Xiao,Jifei Liu,Ziyan Kuang,Rui Dong,Youzhong Dong,Sophia Ananiadou,Min Peng,Qianqian Xie*

Main category: cs.CL

TL;DR: 本文提出了专门针对网络小说翻译评测的DITING框架，以及AgentEval多智能体推理评测方法，系统性评估了多种语言大模型（LLMs）在网络小说翻译中的表现，并发现本土中文大模型在相关翻译任务中优于更大规模的国外模型。


<details>
  <summary>Details</summary>
Motivation: 现有“大语言模型”在文学、网络小说类文本翻译方面的表现和挑战尚不清楚，且主流自动评测方法未能准确体现该体裁作品的叙事性和文化性。因此，亟需有针对性的评测工具和数据来推动该领域发展。

Method: 1）提出DITING评测框架，从成语翻译、词汇歧义、专有名词本地化、时态一致性、省略主语解析与文化安全性六方面评估网络小说翻译，并构建含18K多对中英专家标注的句对数据集。
2）提出AgentEval，模拟专家讨论、推理的自动多智能体评测方法。
3）开发MetricAlign元评测数据集用于不同自动评测指标的比较。
4）面向14个开放、闭源及商用模型进行了系统评测。

Result: 新提出的AgentEval自动评测指标与人工评价的相关性在所有七种对比指标中最高。评测发现，训练于中文语料的大语言模型在网络小说翻译任务上整体优于更大规模的国外模型，其中DeepSeek-V3模型在忠实度和文体一致性上表现最佳。

Conclusion: 本文开创了网络小说翻译新的评测范式，提供了高质量公开资源，对后续探索基于大语言模型的网络小说翻译研究具有重要推动作用。

Abstract: Large language models (LLMs) have substantially advanced machine translation
(MT), yet their effectiveness in translating web novels remains unclear.
Existing benchmarks rely on surface-level metrics that fail to capture the
distinctive traits of this genre. To address these gaps, we introduce DITING,
the first comprehensive evaluation framework for web novel translation,
assessing narrative and cultural fidelity across six dimensions: idiom
translation, lexical ambiguity, terminology localization, tense consistency,
zero-pronoun resolution, and cultural safety, supported by over 18K
expert-annotated Chinese-English sentence pairs. We further propose AgentEval,
a reasoning-driven multi-agent evaluation framework that simulates expert
deliberation to assess translation quality beyond lexical overlap, achieving
the highest correlation with human judgments among seven tested automatic
metrics. To enable metric comparison, we develop MetricAlign, a meta-evaluation
dataset of 300 sentence pairs annotated with error labels and scalar quality
scores. Comprehensive evaluation of fourteen open, closed, and commercial
models reveals that Chinese-trained LLMs surpass larger foreign counterparts,
and that DeepSeek-V3 delivers the most faithful and stylistically coherent
translations. Our work establishes a new paradigm for exploring LLM-based web
novel translation and provides public resources to advance future research.

</details>


### [155] [Augmenting Dialog with Think-Aloud Utterances for Modeling Individual Personality Traits by LLM](https://arxiv.org/abs/2510.09158)
*Seiya Ishikura,Hiroaki Yamada,Tatsuya Hiraoka,Hiroaki Yamada,Takenobu Tokunaga*

Main category: cs.CL

TL;DR: 本研究提出通过引入思维表达语(think-aloud utterances, TAUs)增强对话数据，以提升大型语言模型(LLM)的个性建模能力，实验表明TAU增强数据能使模型更好地拟合人的某些个性特质。


<details>
  <summary>Details</summary>
Motivation: 目前使用大型语言模型生成个性化对话时，模型难以准确反映个体的个性特征。作者认为，通常的对话数据不足以反映说话者的内心想法与性格，因此提出通过加入说话者思维过程的描述(TAU)来丰富数据。

Method: 采用大五人格(Big Five)理论评价人类个性特质。将对话数据用人工或自动方式加入TAU，并用这些增强数据训练个性化LLM，之后分析模型输出与目标人物的个性特质(特别是宜人性和神经质)的对齐程度。

Result: 实验表明，使用TAU增强的数据训练出来的模型在人格中的宜人性和神经质维度，与真实说话者更加一致。此外，TAU数据的质量对模型表现有显著影响。

Conclusion: TAU增强方法有助于提升大模型对说话者个性特质的建模能力，但其效果依赖于所用TAU的质量，未来可探讨更优的TAU生成方法。

Abstract: This study proposes augmenting dialog data with think-aloud utterances (TAUs)
for modeling individual personalities in text chat by LLM. TAU is a
verbalization of a speaker's thought before articulating the utterance. We
expect "persona LLMs" trained with TAU-augmented data can mimic the speaker's
personality trait better. We tested whether the trained persona LLMs obtain the
human personality with respect to Big Five, a framework characterizing human
personality traits from five aspects. The results showed that LLMs trained with
TAU-augmented data more closely align to the speakers' Agreeableness and
Neuroticism of Big Five than those trained with original dialog data. We also
found that the quality of TAU-augmentation impacts persona LLM's performance.

</details>


### [156] [Stronger Re-identification Attacks through Reasoning and Aggregation](https://arxiv.org/abs/2510.09184)
*Lucas Georges Gabriel Charpentier,Pierre Lison*

Main category: cs.CL

TL;DR: 这篇论文提出了两种增强机密信息再识别攻击的方法，用于评估文本去身份化技术的鲁棒性。通过研究信息再识别顺序和利用推理模型，进一步提升了再识别的效果。


<details>
  <summary>Details</summary>
Motivation: 文本去身份化用于隐藏文本中的个人身份信息（PII），但其隐藏效果难以度量。近年来，研究者们通过构建自动化对手进行再识别攻击，以评估去身份化方法的防护能力。作者希望提出更强的攻击策略，以更准确衡量去身份化技术的有效性。

Method: 作者提出两个互补策略：（1）分析再识别PII时顺序的重要性，并通过多种顺序结果融合提升攻击能力；（2）引入推理模型，尤其是在攻击者拥有丰富背景知识假设下，进一步增强再识别表现。

Result: 实验显示，利用多种再识别顺序汇总预测结果能提升攻击效果。同时，推理模型显著提高了攻击性能，特别是在攻击者有更广背景知识的场景下。

Conclusion: 文本去身份化的安全防护能力需要更加严格的检验。作者提出的策略能更有效评估和攻击去身份化系统，建议未来应从预测顺序和推理能力两个方面提升系统鲁棒性。

Abstract: Text de-identification techniques are often used to mask personally
identifiable information (PII) from documents. Their ability to conceal the
identity of the individuals mentioned in a text is, however, hard to measure.
Recent work has shown how the robustness of de-identification methods could be
assessed by attempting the reverse process of _re-identification_, based on an
automated adversary using its background knowledge to uncover the PIIs that
have been masked. This paper presents two complementary strategies to build
stronger re-identification attacks. We first show that (1) the _order_ in which
the PII spans are re-identified matters, and that aggregating predictions
across multiple orderings leads to improved results. We also find that (2)
reasoning models can boost the re-identification performance, especially when
the adversary is assumed to have access to extensive background knowledge.

</details>


### [157] [LLaMAX2: Your Translation-Enhanced Model also Performs Well in Reasoning](https://arxiv.org/abs/2510.09189)
*Changjiang Gao,Zixian Huang,Jingyang Gong,Shujian Huang,Lei Li,Fei Yuan*

Main category: cs.CL

TL;DR: 本文提出了一种新的方法，实现了兼顾推理与翻译能力的大语言模型Qwen3-XPlus，并在多语种任务上显著提升了低资源语言的翻译表现，且推理能力保持优秀。


<details>
  <summary>Details</summary>
Motivation: 通用大语言模型虽然擅长推理，但针对翻译增强的模型在推理任务上表现不佳。作者希望找到一种方法，实现推理能力与翻译能力的兼得，尤其关注低资源语言。

Method: 提出“翻译增强食谱”，基于指令微调模型，采用层选择微调，仅在部分模型层用双语平行数据进行训练。使用这一新流程训练并推出了Qwen3-XPlus系列模型。

Result: Qwen3-XPlus在高低资源语言翻译上均表现优异，低资源语言如斯瓦希里语上的spBLEU超过15、xComet超过40。模型在仅用少量平行数据训练的情况下，7项多语种任务平均提升1分以上，同时在15个推理数据集上的表现与原始推理模型相当。

Conclusion: 该方法为大语言模型多语种能力增强提供了新思路，显著降低了训练复杂度，提高了低资源语言的可及性，对多语种应用具有重要意义。

Abstract: General Large Language Models (LLMs) excel in reasoning, but those enhanced
for translation struggle with reasoning tasks. To address this, we propose a
novel translationenhanced recipe that begins with instruct models and applies
layer-selective tuning only on parallel data. Following this pipeline, we
introduce the Qwen3-XPlus models, which demonstrate significant improvements in
translation performance across both high- and lowresource languages, achieving
15+ spBLEU and 40+ xComet in low-resource languages, like Swahili.
Interestingly, training only with small parallel datasets, Qwen3-XPlus achieves
an average improvement of 1+ points on 7 multilingual tasks while maintaining
proficiency comparable to the Qwen3 instruct model in 15 popular reasoning
datasets. This work offers a promising approach to multilingual enhancement,
significantly reducing complexity and enhancing accessibility for a wider range
of languages. The code and model are publicly available.

</details>


### [158] [DICE: Structured Reasoning in LLMs through SLM-Guided Chain-of-Thought Correction](https://arxiv.org/abs/2510.09211)
*Yiqi Li,Yusheng Liao,Zhe Chen,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 本文提出了DICE框架，通过小语言模型对大语言模型输出进行链式思考修正，从而更好地兼顾推理能力和用户对输出结构的严格需求，明显提升了输出的格式准确率和内容正确率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在用户有复杂输出格式需求时，往往更关注推理任务本身，忽视了对细致指令的遵守。而直接对大模型微调既成本高昂又难以获得参数访问权限。因此，需要高效且实际可行的方法来让模型同时满足推理能力和结构化输出的需求。

Method: 提出DICE框架，流程是先让大语言模型生成自然语言答案，再用训练好的小语言模型对这些答案进行分析和格式化修正。具体包括两个阶段：用双阶段方法构建结构化链式思考（CoT）数据集，并通过双重调优策略微调小模型，使其以“分析-回答”模式生成结构化输出。

Result: 基于DICE的实验显示，其能将大模型输出的平均格式准确率提升35.4%，内容正确率提升29.4%，在多个基线任务上取得了SOTA（最优）表现。

Conclusion: DICE框架既能保留大语言模型的知识和推理优势，又能显著提升其在复杂结构化输出场景下的表现，为低成本优化大模型输出质量提供了新思路。

Abstract: When performing reasoning tasks with user-specific requirements, such as
strict output formats, large language models (LLMs) often prioritize reasoning
over adherence to detailed instructions. Fine-tuning LLMs on supervised
datasets to address this is impractical due to high computational costs and
limited parameter access. To tackle this, we propose DICE, a lightweight
framework that guides small language models (SLMs) to refine LLMs' outputs
through chain-of-thought (CoT) correction. DICE decouples the process by first
prompting LLMs to generate natural language responses, then using trained SLMs
to analyze and refine these outputs to meet structured output specifications.
This framework preserves LLMs' broad knowledge and reasoning capabilities while
ensuring the outputs conform to user demands. Specifically, DICE first
constructs structured CoT adaptation datasets via a two-stage method and
subsequently applies a dual-tuning strategy to fine-tune SLMs for generating
structured outputs in an analyze-then-answer pattern. Experiments demonstrate
that DICE improves the average format accuracy and content correctness of LLM
outputs by 35.4\% and 29.4\%, respectively, achieving state-of-the-art (SOTA)
performance over other competitive baselines.

</details>


### [159] [IRIS: An Iterative and Integrated Framework for Verifiable Causal Discovery in the Absence of Tabular Data](https://arxiv.org/abs/2510.09217)
*Tao Feng,Lizhen Qu,Niket Tandon,Gholamreza Haffari*

Main category: cs.CL

TL;DR: 该论文提出了IRIS框架，结合统计算法与大模型，自动收集文档与变量，实现实时因果发现并支持变量扩展，解决传统方法的多项痛点。


<details>
  <summary>Details</summary>
Motivation: 因果发现对科学研究至关重要，而传统统计方法面临数据收集成本高、重复计算、假设不现实等难题。现有大模型方法又只擅长找已知关系，难以发现新的因果关联。

Method: 作者提出IRIS框架。首先从初始变量出发，自动检索和收集相关文档，提取变量，寻找因果关系。采用统计算法和大模型混合方法，既能发现已知也能挖掘未知的因果关系。IRIS还可自动提出并加入缺失变量，扩展因果图谱。

Result: IRIS可实现仅凭一组初始变量，无需现成数据集，进行实时且自动的因果关系发现和因果图扩展，兼具效率和创新性。

Conclusion: IRIS有效解决了传统和大模型方法的局限，为科学研究领域带来了自动化和多元的因果发现新范式。

Abstract: Causal discovery is fundamental to scientific research, yet traditional
statistical algorithms face significant challenges, including expensive data
collection, redundant computation for known relations, and unrealistic
assumptions. While recent LLM-based methods excel at identifying commonly known
causal relations, they fail to uncover novel relations. We introduce IRIS
(Iterative Retrieval and Integrated System for Real-Time Causal Discovery), a
novel framework that addresses these limitations. Starting with a set of
initial variables, IRIS automatically collects relevant documents, extracts
variables, and uncovers causal relations. Our hybrid causal discovery method
combines statistical algorithms and LLM-based methods to discover known and
novel causal relations. In addition to causal discovery on initial variables,
the missing variable proposal component of IRIS identifies and incorporates
missing variables to expand the causal graphs. Our approach enables real-time
causal discovery from only a set of initial variables without requiring
pre-existing datasets.

</details>


### [160] [CrisiText: A dataset of warning messages for LLM training in emergency communication](https://arxiv.org/abs/2510.09243)
*Giacomo Gonella,Gian Maria Campedelli,Stefano Menini,Marco Guerini*

Main category: cs.CL

TL;DR: 本文提出了CrisiText，这是首个针对13种不同危机场景的大规模危机警告消息生成数据集，并评估了多种NLG模型在此任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 在危机事件中，及时准确地生成警告信息对保护人员安全至关重要。目前NLP在应急领域应用有限，主要只做分类，警告信息生成这一领域未被充分研究。

Method: 从现有的危机事件描述出发，制作事件链并针对每个事件由专家编写合格的、符合事实的警告信息，同时每条警告还配有三种次优参考版本。然后，利用这些数据在不同的NLG生成模型（如有监督微调、偏好对齐、零样本、少样本）以及自动后编辑机制上做比较实验，并评估其在非分布数据下的表现。

Result: 构建了包含逾40万条警告消息的数据集，在各种NLG生成方法下进行了系统性评测，比较了不同算法、设置的优劣，并证明了自动后编辑和模型适应性的有效性。

Conclusion: CrisiText丰富了危机应对领域的NLG研究资源，有助于推动基于生成的应急消息自动化研发，对于提高危机响应效率和信息传播的质量具有重要意义。

Abstract: Effectively identifying threats and mitigating their potential damage during
crisis situations, such as natural disasters or violent attacks, is paramount
for safeguarding endangered individuals. To tackle these challenges, AI has
been used in assisting humans in emergency situations. Still, the use of NLP
techniques remains limited and mostly focuses on classification tasks. The
significant potential of timely warning message generation using NLG
architectures, however, has been largely overlooked. In this paper we present
CrisiText, the first large-scale dataset for the generation of warning messages
across 13 different types of crisis scenarios. The dataset contains more than
400,000 warning messages (spanning almost 18,000 crisis situations) aimed at
assisting civilians during and after such events. To generate the dataset, we
started from existing crisis descriptions and created chains of events related
to the scenarios. Each event was then paired with a warning message. The
generations follow experts' written guidelines to ensure correct terminology
and factuality of their suggestions. Additionally, each message is accompanied
by three suboptimal warning types to allow for the study of different NLG
approaches. To this end, we conducted a series of experiments comparing
supervised fine-tuning setups with preference alignment, zero-shot, and
few-shot approaches. We further assessed model performance in
out-of-distribution scenarios and evaluated the effectiveness of an automatic
post-editor.

</details>


### [161] [DSPO: Stable and Efficient Policy Optimization for Agentic Search and Reasoning](https://arxiv.org/abs/2510.09255)
*Chenyang Gu,Yewen Pu,Bruce Yang,Xiaofan Li,Huan Gao*

Main category: cs.CL

TL;DR: 本文提出了一种新的强化学习算法DSPO，提升了大型语言模型主动检索外部知识和多轮推理能力，在复杂问答任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在主动搜索外部知识以处理复杂任务方面能力有限，现有方法依赖提示或强化学习，但后者在复杂任务上表现不佳且易于崩溃。因此，亟需更稳定高效的方法以充分挖掘模型作为智能体的潜力。

Method: 提出动态过滤序列级策略优化（DSPO）算法，该方法通过在序列级别优化与动态过滤样本，采用纯强化学习训练方式实现多轮搜索与推理，无需监督示例数据。

Result: 在多个问答基准上，经DSPO训练的7B参数模型性能相比以往方法提高了34.1%，并在复杂的多跳问答任务（如HotpotQA）上明显超越了参数翻倍的14B模型，训练过程也更加稳定。

Conclusion: DSPO显著提升了大模型主动搜索和推理能力，在无需监督数据的前提下达到更高准确率和更优稳定性，为大模型智能体化提供了新路径。

Abstract: Enhancing LLMs with the ability to actively search external knowledge is
crucial for complex and real-world tasks. Current approaches either rely on
prompting to elicit the model's innate agent capabilities, or suffer from
performance ceilings and collapse when applying RL to complex interactive
tasks, leaving their true agentic potential untapped. To address this, we
introduce \textbf{D}ynamic-filter \textbf{S}equence-level \textbf{P}olicy
\textbf{O}ptimization (DSPO), an improved RL algorithm designed for robust
agent training through sequence-level optimization and dynamic sample
filtering. We train our model purely through RL to interleave multi-turn search
and reasoning, obviating the need for supervised demonstration data. Across
multiple QA benchmarks, our DSPO-trained 7B model improves over a comparable
previous work by \textbf{34.1\%}, and even outperforms the 14B model from
previous work in complex multihop QA such as HotpotQA by nearly \textbf{9\%
relative}, maintaining exceptional training stability.

</details>


### [162] [Detecting Data Contamination from Reinforcement Learning Post-training for Large Language Models](https://arxiv.org/abs/2510.09259)
*Yongding Tao,Tian Wang,Yihong Dong,Huanyu Liu,Kechi Zhang,Xiaolong Hu,Ge Li*

Main category: cs.CL

TL;DR: 本文关注于大模型强化学习后训练阶段数据污染的检测难题，提出了Self-Critique方法及RL-MIA基准，有效提升了污染检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法主要针对预训练和有监督微调阶段，而随着强化学习后训练（RL post-training）在大模型研发中的关键作用日益突出，该阶段的数据污染检测却几乎未被研究，构成性能评估的重大隐患。为解决这一漏洞，作者开展了系统性的研究。

Method: 提出了Self-Critique方法。该方法基于一个重要观察：强化学习后LLM输出熵（entropy）急剧收敛到稀疏、特定的模式，说明模型策略出现收敛（policy collapse），即推理路径过于狭窄。Self-Critique通过检测这种熵收缩来识别数据污染。同时，作者构建了RL-MIA基准以模拟此类污染。

Result: Self-Critique在多个模型和污染任务中的检测性能显著优于现有基线方法，AUC提升高达30%。实验表明传统方法在RL阶段检测几乎等同于随机猜测，而Self-Critique使检测成为可能。

Conclusion: 本文首次系统性研究了RL后训练阶段的数据污染检测，并提出有效的新方法及基准，为后续相关领域的研究和评测提供了基础与方向。

Abstract: Data contamination poses a significant threat to the reliable evaluation of
Large Language Models (LLMs). This issue arises when benchmark samples may
inadvertently appear in training sets, compromising the validity of reported
performance. While detection methods have been developed for the pre-training
and Supervised Fine-Tuning stages, a critical research gap exists for the
increasingly significant phase of Reinforcement Learning (RL) post-training. As
RL post-training becomes pivotal for advancing LLM reasoning, the absence of
specialized contamination detection methods in this paradigm presents a
critical vulnerability. To address this, we conduct the first systematic study
of data detection within RL post-training scenario and propose Self-Critique.
Our method is motivated by a key observation: after RL phase, the output
entropy distribution of LLMs tends to collapse into highly specific and sparse
modes. Self-Critique probes for the underlying policy collapse, i.e., the
model's convergence to a narrow reasoning path, which causes this entropy
reduction. To facilitate this research, we also introduce RL-MIA, a benchmark
constructed to simulate this specific contamination scenario. Extensive
experiments show that Self-Critique significantly outperforms baseline methods
across multiple models and contamination tasks, achieving an AUC improvement of
up to 30%. Whereas existing methods are close to a random guess for RL-phase
contamination, our method makes detection possible.

</details>


### [163] [CFVBench: A Comprehensive Video Benchmark for Fine-grained Multimodal Retrieval-Augmented Generation](https://arxiv.org/abs/2510.09266)
*Kaiwen Wei,Xiao Liu,Jie Zhang,Zijian Wang,Ruida Liu,Yuming Yang,Xin Xiao,Xiao Sun,Haoyang Zeng,Changzai Pan,Yidan Zhang,Jiang Zhong,Peijin Wang,Yingchao Feng*

Main category: cs.CL

TL;DR: 该论文提出了一个新的多模态视频检索增强生成（MRAG）基准——CFVBench，用于评估大型多模态语言模型在复杂视频条件下的检索与生成能力，并发现现有模型在细粒度多模态信息处理上存在瓶颈，提出了AVR方法有效改进了此问题。


<details>
  <summary>Details</summary>
Motivation: 当前类似基准多聚焦于单一或有限模态、常为粗粒度任务，无法全面反映模型跨模态细粒度推理能力；需要一个覆盖更多格式和领域且更苛刻的大规模基准推动MRAG模型发展。

Method: 作者构建了CFVBench，集合599个公开视频和5,360组开放式QA，涵盖图表报告、新闻、软件教学等高密度模态场景，并用该基准系统性测试了7种检索方法和14种主流MLLM。针对现有模型细节捕捉弱的问题，提出了自适应视觉细化（AVR）方法，动态调整采帧密度，并在需要时调用外部工具增强细粒度理解。

Result: 在CFVBench测试下，即使是最先进的GPT5、Gemini等模型，也难以精准把握视频中的短暂关键多模态细节。而引入AVR后，所有评估的MLLM在细粒度多模态理解和任务表现上均显著提升。

Conclusion: CFVBench成为衡量多模态检索生成模型理解高密度、复杂视频新标杆，揭示了现有大模型的细粒度理解瓶颈；AVR方法可有效缓解此问题，为未来MRAG研究和应用提供了参考和进步方向。

Abstract: Multimodal Retrieval-Augmented Generation (MRAG) enables Multimodal Large
Language Models (MLLMs) to generate responses with external multimodal
evidence, and numerous video-based MRAG benchmarks have been proposed to
evaluate model capabilities across retrieval and generation stages. However,
existing benchmarks remain limited in modality coverage and format diversity,
often focusing on single- or limited-modality tasks, or coarse-grained scene
understanding. To address these gaps, we introduce CFVBench, a large-scale,
manually verified benchmark constructed from 599 publicly available videos,
yielding 5,360 open-ended QA pairs. CFVBench spans high-density formats and
domains such as chart-heavy reports, news broadcasts, and software tutorials,
requiring models to retrieve and reason over long temporal video spans while
maintaining fine-grained multimodal information. Using CFVBench, we
systematically evaluate 7 retrieval methods and 14 widely-used MLLMs, revealing
a critical bottleneck: current models (even GPT5 or Gemini) struggle to capture
transient yet essential fine-grained multimodal details. To mitigate this, we
propose Adaptive Visual Refinement (AVR), a simple yet effective framework that
adaptively increases frame sampling density and selectively invokes external
tools when necessary. Experiments show that AVR consistently enhances
fine-grained multimodal comprehension and improves performance across all
evaluated MLLMs

</details>


### [164] [Inflated Excellence or True Performance? Rethinking Medical Diagnostic Benchmarks with Dynamic Evaluation](https://arxiv.org/abs/2510.09275)
*Xiangxu Zhang,Lei Li,Yanyun Zhou,Xiao Zhou,Yingying Zhang,Xian Wu*

Main category: cs.CL

TL;DR: 本论文指出当前对大语言模型（LLM）在医学诊断领域的评估与实际临床存在较大偏差，提出了一个更加动态且符合真实情境的评测基准DyReMe，并证明这一方式可以更真实地反映现有模型的表现不足。


<details>
  <summary>Details</summary>
Motivation: 现有针对医用LLM的评估方法多基于医学考试题等静态问题集，容易高估模型能力，无法反映实际临床中多样且不确定的真实问题。为填补评价体系与现实临床实践间的鸿沟，亟需一种更具临床代表性的动态评测方法。

Method: 提出DyReMe动态测试基准，可生成带有干扰项的仿真实诊疗案例（如鉴别诊断和常见误诊因素），同时优化问题表达方式以模拟现实世界的多样化咨询习惯，并从准确性、真实性、助益性、一致性四个临床相关维度评价模型表现。

Result: 实验表明，DyReMe能构建更具挑战性和现实性的评测环境，揭示主流LLM在临床表现与静态基准测试结果间存在明显落差。

Conclusion: 当前的LLM医学评估体系远未满足真实临床需求，亟需采用更动态、更接近临床实际的评价方法，以推动可信医疗AI的发展。

Abstract: Medical diagnostics is a high-stakes and complex domain that is critical to
patient care. However, current evaluations of large language models (LLMs) are
fundamentally misaligned with real-world clinical practice. Most of them rely
on static benchmarks derived from public medical exam items, which tend to
overestimate model performance and ignore the difference between textbook cases
and the ambiguous, varying conditions in the real world. Recent efforts toward
dynamic evaluation offer a promising alternative, but their improvements are
limited to superficial perturbations and a narrow focus on accuracy. To address
these gaps, we propose DyReMe, a dynamic benchmark for medical diagnostics that
better reflects real clinical practice. Unlike static exam-style questions,
DyReMe generates fresh, consultation-like cases that introduce distractors such
as differential diagnoses and common misdiagnosis factors. It also varies
expression styles to mimic diverse real-world query habits. Beyond accuracy,
DyReMe evaluates LLMs on three additional clinically relevant dimensions:
veracity, helpfulness, and consistency. Our experiments demonstrate that this
dynamic approach yields more challenging and realistic assessments, revealing
significant misalignments between the performance of state-of-the-art LLMs and
real clinical practice. These findings highlight the urgent need for evaluation
frameworks that better reflect the demands of trustworthy medical diagnostics.

</details>


### [165] [CLARity: Reasoning Consistency Alone Can Teach Reinforced Experts](https://arxiv.org/abs/2510.09278)
*Jiuheng Lin,Cong Jiang,Zirui Wu,Jiarui Sun,Yansong Feng*

Main category: cs.CL

TL;DR: CLARity提出了一种高效的RL训练框架，通过仅用小型通用LLM提升专家LLM的推理一致性和回应质量，在有限数据领域表现优异。


<details>
  <summary>Details</summary>
Motivation: 领域数据稀缺使得训练专家LLM困难，而传统基于多选题的RL方法虽然能提升准确率，却常导致推理质量下降（如逻辑一致性变差）。现有推理监督方法（如大规模过程奖励模型）成本高昂，难以实际应用。

Method: 提出CLARity框架：结合一致性感知奖励机制与两阶段（先细化后监控）训练流程，强化推理一致性。同时采用动态数据重构策略，提高有限数据的利用效率。CLARity仅需小型通用LLM，无需大规模PRM。

Result: 实验显示CLARity在回复一致性上提升16.5%，准确率提升7.5%。人类评估进一步验证了其在连贯性和专业性上的整体提升。

Conclusion: CLARity为数据稀缺领域提供了一种普适、低成本的方法，能让小模型有效监督和提升专家模型的推理一致性，实用性强且具有广泛推广价值。

Abstract: Training expert LLMs in domains with scarce data is difficult, often relying
on multiple-choice questions (MCQs). However, standard outcome-based
reinforcement learning (RL) on MCQs is risky. While it may improve accuracy, we
observe it often degrades reasoning quality such as logical consistency.
Existing solutions to supervise reasoning, such as large-scale Process Reward
Models (PRMs), are prohibitively expensive. To address this, we propose
CLARity, a cost-effective RL framework that enhances reasoning quality using
only a small, general-purpose LLM. CLARity integrates a consistency-aware
reward mechanism with a 2-stage refine-then-monitor training pipeline to
enhance reasoning consistency, and a dynamic data reformulation strategy to to
better exploit limited data. Experiments demonstrate that CLARity improves
response consistency by 16.5% and accuracy by 7.5% over baselines. Human
evaluations further confirm holistic improvements in coherence and
professionalism. Thus, CLARity offers a generalizable solution that enables
smaller models to effectively guide expert models by reasoning consistency.Our
code is open sourced at: https://github.com/Infinite-set/CLARity

</details>


### [166] [One Sentence, Two Embeddings: Contrastive Learning of Explicit and Implicit Semantic Representations](https://arxiv.org/abs/2510.09293)
*Kohei Oda,Po-Min Chuang,Kiyoaki Shirai,Natthawut Kertkeidkachorn*

Main category: cs.CL

TL;DR: 本文提出了一种新型双嵌入的句子表示方法DualCSE，通过分别建模显性和隐性语义，提高了句子嵌入对深层含义的捕捉能力，实验验证了其在下游任务上的表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有句子嵌入方法通常只用一个向量表示句子，难以充分表达句子中的隐性语义信息。为更好捕获句子的丰富语义，需要突破传统方法的局限性。

Method: DualCSE方法为每个句子赋予两个嵌入：一份显式语义表示，另一份是隐式语义表示，两者在同一空间共存，可根据实际应用选择所需语义信息进行使用。

Result: 实验表明，DualCSE方法能够有效地编码并区分句子的显性与隐性含义，在文本检索、文本分类等下游任务中取得了更好的效果。

Conclusion: DualCSE提升了句子嵌入在语义层面的表达能力，为相关NLP任务提供了更优质的语义输入，具有进一步应用和推广的潜力。

Abstract: Sentence embedding methods have made remarkable progress, yet they still
struggle to capture the implicit semantics within sentences. This can be
attributed to the inherent limitations of conventional sentence embedding
methods that assign only a single vector per sentence. To overcome this
limitation, we propose DualCSE, a sentence embedding method that assigns two
embeddings to each sentence: one representing the explicit semantics and the
other representing the implicit semantics. These embeddings coexist in the
shared space, enabling the selection of the desired semantics for specific
purposes such as information retrieval and text classification. Experimental
results demonstrate that DualCSE can effectively encode both explicit and
implicit meanings and improve the performance of the downstream task.

</details>


### [167] [MaP: A Unified Framework for Reliable Evaluation of Pre-training Dynamics](https://arxiv.org/abs/2510.09295)
*Jiapeng Wang,Changxin Tian,Kunlong Chen,Ziqi Liu,Jiaxin Mao,Wayne Xin Zhao,Zhiqiang Zhang,Jun Zhou*

Main category: cs.CL

TL;DR: 本文指出在大模型训练期间的评估过程不稳定，提出了MaP框架（包括checkpoint merging和Pass@k指标）来提升评估的稳定性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型的预训练阶段，评估的波动和不稳定使得研究者难以真实观察和分析模型学习过程，从而影响模型改进。该问题主要来源于训练随机性导致的参数不稳定性以及评估协议本身噪声带来的评估不稳定性。

Method: 作者将不稳定的源头分为两类：参数不稳定性和评估不稳定性，并提出了MaP框架。该框架包含：1）权重合并（checkpoint merging），通过平均几个最近的模型权重来平滑参数空间；2）Pass@k指标，提供统计学上更鲁棒、方差更低的模型能力评估。

Result: 实验结果显示：MaP方法能有效平滑性能曲线、降低多次实验之间的方差、并对模型能力排名更一致。与传统方法相比，模型训练动态的观察更加真实和可靠。

Conclusion: MaP框架为大语言模型的评估提供了更可靠和更具有信度的方法，有助于推动LLM研究的扎实发展。

Abstract: Reliable evaluation is fundamental to the progress of Large Language Models
(LLMs), yet the evaluation process during pre-training is plagued by
significant instability that obscures true learning dynamics. In this work, we
systematically diagnose this instability, attributing it to two distinct
sources: \textit{Parameter Instability} from training stochasticity and
\textit{Evaluation Instability} from noisy measurement protocols. To counteract
both sources of noise, we introduce \textbf{MaP}, a dual-pronged framework that
synergistically integrates checkpoint \underline{M}erging \underline{a}nd the
\underline{P}ass@k metric. Checkpoint merging smooths the parameter space by
averaging recent model weights, while Pass@k provides a robust, low-variance
statistical estimate of model capability. Extensive experiments show that MaP
yields significantly smoother performance curves, reduces inter-run variance,
and ensures more consistent model rankings. Ultimately, MaP provides a more
reliable and faithful lens for observing LLM training dynamics, laying a
crucial empirical foundation for LLM research.

</details>


### [168] [ShiZhi: A Chinese Lightweight Large Language Model for Court View Generation](https://arxiv.org/abs/2510.09297)
*Zhitian Hou,Kun Zeng*

Main category: cs.CL

TL;DR: 本文提出了ShiZhi，这是首个专为法院裁判文书“法庭意见”生成任务设计的大型语言模型，并构建了包含11万多案例的大型中文数据集CCVG，模型在生成法庭意见和罪名预测上均取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 法庭意见书生成任务在法律AI领域具有重要意义，但由于案例事实多样复杂，从原始事实生成高质量法庭意见具有挑战，因此需要更专业、高效的模型及数据支持。

Method: 作者首先构建了包含11万多例真实案件（每例有案情事实和对应法庭意见）的CCVG中文数据集。基于该数据集，训练了专为法庭意见书生成（CVG）设计的ShiZhi大语言模型，并对模型在法庭意见生成和罪名预测两项任务上进行了评测。

Result: ShiZhi模型在法庭意见生成任务上，BLEU-1分数达到58.5，在罪名预测上准确率86.1%，宏F1为92.5%，均显著优于以往方法和基线。实验还表明，即使小规模LLM也能在高质量领域数据上取得法律上连贯与合理的文本生成效果。

Conclusion: 专用数据与模型的结合显著提升了法庭意见生成与罪名预测的效果，ShiZhi为法律文书自动化生成提供了可行方案，其开放的数据与模型对推动法律人工智能发展具有促进作用。

Abstract: Criminal Court View Generation (CVG) is a fundamental task in legal
artificial intelligence, aiming to automatically generate the "Court View"
section of a legal case document. Generating court views is challenging due to
the diversity and complexity of case facts, and directly generating from raw
facts may limit performance. In this paper, we present ShiZhi, the first large
language model (LLM) specifically designed for court view generation. We
construct a Chinese Court View Generation dataset, CCVG, of more than 110K
cases, each containing fact descriptions paired with corresponding court views.
Based on this dataset, ShiZhi achieving 58.5 BLEU-1 on court view generation
and 86.1\% accuracy with 92.5\% macro F1 on charge prediction. Experimental
results demonstrate that even a small LLM can generate reasonable and legally
coherent court views when trained on high-quality domain-specific data. Our
model and dataset are available at
\href{https://github.com/ZhitianHou/ShiZhi}{https://github.com/ZhitianHou/ShiZhi}.

</details>


### [169] [Mask Tokens as Prophet: Fine-Grained Cache Eviction for Efficient dLLM Inference](https://arxiv.org/abs/2510.09309)
*Jianuo Huang,Yaojie Zhang,Yicun Yang,Benhao Huang,Biqing Qi,Dongrui Liu,Linfeng Zhang*

Main category: cs.CL

TL;DR: 本文提出MaskKV，一种无需额外训练、专为扩散型大语言模型（dLLMs）设计的缓存淘汰框架，以高效应对内存与计算资源限制，实现大幅压缩缓存后依旧保留模型性能。


<details>
  <summary>Details</summary>
Motivation: 扩散型大语言模型支持并行解码，但因双向注意力的缓存机制导致极高内存消耗，限制了其在长上下文及资源有限条件下的应用。现有淘汰策略多为自回归模型设计，与dLLMs特性不符，效果欠佳。

Method: MaskKV框架包含两大创新：(1) 基于掩码的查询指导淘汰分数机制，利用注意力权重逐头识别并淘汰作用较小的提示token；(2) 自适应缓存分配策略，减少中间层分配，将资源向更敏感提示的头部集中，提升内存使用效率。方法无需额外训练。

Result: 在LLaDA模型上，用MaskKV将KV缓存压缩到仅256对（不到5%的token），依旧保持94%的满缓存性能，在32k长度提示下推理加速达31倍。

Conclusion: MaskKV有效缓解了dLLMs缓存压力，实现了大幅度内存压缩并显著提升长上下文推理速度，在资源受限环境下扩展了dLLMs应用潜力。

Abstract: Diffusion large language models (dLLMs) present a promising alternative to
dominant autoregressive models (ARMs) by the ability of parallel decoding at
the expense of substantial computation and memory costs. Specifically, the
cache mechanism for bidirectional attention in dLLMs demands large memory
footprint, restricting their ability to handle long contexts under
resource-limited settings. Existing cache eviction strategies are designed for
ARMs and ignore the unique characteristics of dLLMs, thus leading to
unsatisfactory performance. To address these challenges, we introduce MaskKV, a
training-free cache eviction framework tailored to dLLMs, focusing on the
effect of mask tokens in dLLMs. MaskKV is built on two key innovations: (1) a
mask-query guided scoring mechanism that leverages attention weights to
identify and evict less critical prompt tokens for each head; (2) an adaptive
cache budgeting strategy that improves efficiency by reducing allocation in
intermediate layers and concentrating resources on prompt-preferring heads. On
LLaDA with MaskKV, compressing the KV cache to only 256 pairs (less than 5% of
tokens) retains 94% of the full-cache performance on LongBench and achieves up
to 31x acceleration at 32k prompt length. The code is publicly available at:
https://github.com/jianuo-huang/MaskKV

</details>


### [170] [Verifying Chain-of-Thought Reasoning via Its Computational Graph](https://arxiv.org/abs/2510.09312)
*Zheng Zhao,Yeskendir Koishekenov,Xianjun Yang,Naila Murray,Nicola Cancedda*

Main category: cs.CL

TL;DR: 本文提出一种新颖的白盒链式思维（CoT）推理验证方法，通过分析模型内部激活归因图的结构特征，有效识别并纠正推理错误。


<details>
  <summary>Details</summary>
Motivation: 现有的CoT推理验证方法只基于模型输出或激活结果，无法解释推理失败的深层原因，缺乏对模型内部推理过程的可解释性。

Method: 提出Circuit-based Reasoning Verification（CRV）方法，通过获取模型在每一步推理的归因图，将其作为执行轨迹，提取其结构特征，训练分类器判断推理正确性，并据此指导模型修正错误。

Result: CRV方法能准确预测推理错误，且发现不同类型推理任务的错误具有各自特有的结构特征；通过基于分析结果的有针对性干预，能够有效修正模型的部分推理错误。

Conclusion: CRV方法不只是检测错误，更实现了对大模型推理过程的因果分析，为理解和优化大模型推理过程提供了新工具，拓展了CoT推理验证的研究范式。

Abstract: Current Chain-of-Thought (CoT) verification methods predict reasoning
correctness based on outputs (black-box) or activations (gray-box), but offer
limited insight into why a computation fails. We introduce a white-box method:
Circuit-based Reasoning Verification (CRV). We hypothesize that attribution
graphs of correct CoT steps, viewed as execution traces of the model's latent
reasoning circuits, possess distinct structural fingerprints from those of
incorrect steps. By training a classifier on structural features of these
graphs, we show that these traces contain a powerful signal of reasoning
errors. Our white-box approach yields novel scientific insights unattainable by
other methods. (1) We demonstrate that structural signatures of error are
highly predictive, establishing the viability of verifying reasoning directly
via its computational graph. (2) We find these signatures to be highly
domain-specific, revealing that failures in different reasoning tasks manifest
as distinct computational patterns. (3) We provide evidence that these
signatures are not merely correlational; by using our analysis to guide
targeted interventions on individual transcoder features, we successfully
correct the model's faulty reasoning. Our work shows that, by scrutinizing a
model's computational process, we can move from simple error detection to a
deeper, causal understanding of LLM reasoning.

</details>


### [171] [FLRC: Fine-grained Low-Rank Compressor for Efficient LLM Inference](https://arxiv.org/abs/2510.09332)
*Yu-Chen Lu,Chong-Yan Chen,Chi-Chih Chang,Yu-Fang Hu,Kai-Chiang Wu*

Main category: cs.CL

TL;DR: 提出了Fine-grained Low-Rank Compressor（FLRC）方法，通过针对不同层分配最佳低秩压缩比，并引入逐步低秩解码技术，实现了对大语言模型（LLM）的高效压缩和高质量文本生成。实验显示，在摘要任务上，FLRC较现有方法带来高达17%的ROUGE-L提升。


<details>
  <summary>Details</summary>
Motivation: 大语言模型参数规模巨大，难以部署在资源受限的硬件环境上。简单进行均匀低秩压缩会严重损失性能，且现有方法在解码时表现不佳。因此，急需一种在高效压缩同时兼顾生成质量的解决方案。

Method: 提出FLRC方法，能够为每一层高效分配最优秩，并采用渐进式低秩解码，有效降低内存与计算需求，同时缓解均匀压缩带来的性能下降。

Result: 在多个基准任务上进行了全面实验，尤其在文本摘要任务上，ROUGE-L指标提升了最多17%，明显优于当前主流低秩压缩方法。

Conclusion: FLRC为大语言模型推断提供了更加稳健且高效的低秩压缩框架，兼顾模型体积缩减与文本生成质量，为未来模型部署带来更好方案。

Abstract: Although large language models (LLM) have achieved remarkable performance,
their enormous parameter counts hinder deployment on resource-constrained
hardware. Low-rank compression can reduce both memory usage and computational
demand, but applying a uniform compression ratio across all layers often leads
to significant performance degradation, and previous methods perform poorly
during decoding. To address these issues, we propose the Fine-grained Low-Rank
Compressor (FLRC), which efficiently determines an optimal rank allocation for
each layer, and incorporates progressive low-rank decoding to maintain text
generation quality. Comprehensive experiments on diverse benchmarks demonstrate
the superiority of FLRC, achieving up to a 17% improvement in ROUGE-L on
summarization tasks compared to state-of-the-art low-rank compression methods,
establishing a more robust and efficient framework to improve LLM inference.

</details>


### [172] [LLP: LLM-based Product Pricing in E-commerce](https://arxiv.org/abs/2510.09347)
*Hairu Wang,Sheng You,Qiheng Zhang,Xike Xie,Shuguang Han,Yuchen Wu,Fei Huang,Jufeng Chen*

Main category: cs.CL

TL;DR: 本文提出了LLP（基于大语言模型的生成式二手商品定价框架），通过检索相似商品和利用LLM生成价格建议，相较传统静态回归模型，在定价准确性与泛化能力上有显著提升，并已在中国闲鱼平台成功应用，采用率大幅提升。


<details>
  <summary>Details</summary>
Motivation: C2C平台上缺乏经验的个人卖家难以合理为二手商品定价，现有静态模型无法反映市场动态，迫切需要更智能、动态的定价机制。

Method: LLP框架先检索相似商品以反映市场变化，再用LLM对自由文本中的定价关键信息进行理解和生成价格建议。采用两阶段优化（SFT + GRPO）增强领域推理能力，并通过置信度过滤机制剔除不可靠建议。

Result: 在多项实验中，LLP在定价准确性和泛化能力上全面超越现有方法。实际在闲鱼的部署中，在30%商品覆盖下静态采用率由40%提升到72%，在90%召回下也保有47%的采用率。

Conclusion: 基于LLM的LLP方法能显著提升C2C二手商品定价的准确性和适应性，具有广泛的实际应用前景和推广价值。

Abstract: Unlike Business-to-Consumer e-commerce platforms (e.g., Amazon),
inexperienced individual sellers on Consumer-to-Consumer platforms (e.g., eBay)
often face significant challenges in setting prices for their second-hand
products efficiently. Therefore, numerous studies have been proposed for
automating price prediction. However, most of them are based on static
regression models, which suffer from poor generalization performance and fail
to capture market dynamics (e.g., the price of a used iPhone decreases over
time). Inspired by recent breakthroughs in Large Language Models (LLMs), we
introduce LLP, the first LLM-based generative framework for second-hand product
pricing. LLP first retrieves similar products to better align with the dynamic
market change. Afterwards, it leverages the LLMs' nuanced understanding of key
pricing information in free-form text to generate accurate price suggestions.
To strengthen the LLMs' domain reasoning over retrieved products, we apply a
two-stage optimization, supervised fine-tuning (SFT) followed by group relative
policy optimization (GRPO), on a dataset built via bidirectional reasoning.
Moreover, LLP employs a confidence-based filtering mechanism to reject
unreliable price suggestions. Extensive experiments demonstrate that LLP
substantially surpasses existing methods while generalizing well to unseen
categories. We have successfully deployed LLP on Xianyu\footnote\{Xianyu is
China's largest second-hand e-commerce platform.\}, significantly outperforming
the previous pricing method. Under the same 30\% product coverage, it raises
the static adoption rate (SAR) from 40\% to 72\%, and maintains a strong SAR of
47\% even at 90\% recall.

</details>


### [173] [ReTraceQA: Evaluating Reasoning Traces of Small Language Models in Commonsense Question Answering](https://arxiv.org/abs/2510.09351)
*Francesco Maria Molfese,Luca Moroni,Ciro Porcaro,Simone Conia,Roberto Navigli*

Main category: cs.CL

TL;DR: 现有针对小型语言模型（SLM）常识推理能力的评估主要只看最终答案的正确性，忽略了推理过程的合理性。本文引入了一个新的基准ReTraceQA，关注过程层面的推理评价，发现SLM常被高估能力。使用大型语言模型（LLM）判定推理合理性时，SLM表现下降明显。


<details>
  <summary>Details</summary>
Motivation: 当前SLM评估过分关注最终答案，未能检验推理过程的有效性，导致对模型能力的高估。需要开发新的评测方法，更全面衡量SLM的推理质量。

Method: 提出了ReTraceQA基准，专门用于常识推理任务中的过程层面评估。该数据集由专家标注，不仅检查最终答案，还关注推理链条是否合理。同时，采用LLM作为自动评审，比较推理感知与答案感知两种评测方式下SLM的表现差异。

Result: 实验证明，SLM在相当一部分情况下（14-24%）即便推理不合理也能给出正确答案。当以LLM自动评审推理过程合理性时，SLM在所有模型和数据集上的分数最高下降25%。

Conclusion: 只关注答案正确性的评估方式夸大了SLM的推理能力。更细致的推理过程评估揭示了SLM存在重要局限。未来SLM评测应在过程层面展开，更真实反映其推理能力。

Abstract: While Small Language Models (SLMs) have demonstrated promising performance on
an increasingly wide array of commonsense reasoning benchmarks, current
evaluation practices rely almost exclusively on the accuracy of their final
answers, neglecting the validity of the reasoning processes that lead to those
answers. To address this issue, we introduce ReTraceQA, a novel benchmark that
introduces process-level evaluation for commonsense reasoning tasks. Our
expert-annotated dataset reveals that in a substantial portion of instances
(14-24%), SLMs provide correct final answers despite flawed reasoning
processes, suggesting that the capabilities of SLMs are often overestimated by
evaluation metrics that focus only on comparing the final answer with the
ground truth. Indeed, we show that when employing strong Large Language Models
(LLMs) as automated judges for reasoning-aware evaluation rather than
answer-only metrics, SLM performance drops significantly across all models and
datasets, with scores decreasing by up to 25%.

</details>


### [174] [Logit Arithmetic Elicits Long Reasoning Capabilities Without Training](https://arxiv.org/abs/2510.09354)
*Yunxiang Zhang,Muhammad Khalifa,Lechen Zhang,Xin Liu,Ayoung Lee,Xinliang Frederick Zhang,Farima Fatahi Bayat,Lu Wang*

Main category: cs.CL

TL;DR: 本文提出了一种名为ThinkLogit的解码时推理增强方法，无需对大模型额外训练，通过较小推理模型的指导提升大模型链式推理能力，并在多项推理基准上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 大规模模型虽具备链式推理等复杂能力，但通常依赖昂贵的额外训练。研究动机在于：能否仅通过推理阶段的技术，无需对大模型再训练，就实现其长链式推理提升？

Method: 作者提出ThinkLogit方法：在解码阶段，用小型推理模型对大型非推理模型的logit进行调整，实现推理增强。进一步引入ThinkLogit-DPO，通过偏好优化训练引导模型，对正确/错误推理对进行采样优化，提升指导效果。

Result: 在五个推理基准中，Qwen2.5-32B在R1-Distill-Qwen-1.5B（小21倍模型）引导下，ThinkLogit与ThinkLogit-DPO平均准确率分别提升24.5%、29.1%。此外，方法适用于不同家族模型间协作，且可与蒸馏、强化学习等技术无缝结合。

Conclusion: ThinkLogit及其拓展方法无需大模型后训练即可显著提升其链式推理表现，为低成本解锁大模型推理能力，推动实际应用带来新途径。

Abstract: Large reasoning models exhibit long chain-of-thought reasoning with
strategies such as backtracking and self-correction, though recent studies
suggest that these abilities typically require additional training. We first
investigate whether such behaviors can be elicited without any training. To
this end, we propose a decoding-time approach, ThinkLogit, which utilizes logit
arithmetic to tune a target large non-reasoning model for long reasoning using
a substantially smaller reasoning model as the guider. We then show that we can
further boost its performance by training the guider model with preference
optimization over correct/incorrect reasoning pairs sampled from both the
target and guider model, a setup we refer to as ThinkLogit-DPO. Our experiments
demonstrate that ThinkLogit and ThinkLogit-DPO achieve a relative improvement
in average accuracy by 24.5% and 29.1%, respectively, over five reasoning
benchmarks using the Qwen2.5-32B guided by R1-Distill-Qwen-1.5B, a model 21x
smaller. Moreover, we find that ThinkLogit remains effective when the guider
and target come from different model families. It is also orthogonal to
post-training methods for small models, as guiders improved through supervised
distillation or reinforcement learning can be directly plugged in to yield
stronger large models, offering a practical path to unlock long reasoning in
large-scale models without costly post-training.

</details>


### [175] [NL2GenSym: Natural Language to Generative Symbolic Rules for SOAR Cognitive Architecture via Large Language Models](https://arxiv.org/abs/2510.09355)
*Fang Yuan,Junjie Zeng,Yue Hu,Zhengqiu Zhu,Quanjun Yin,Yuxiang Xie*

Main category: cs.CL

TL;DR: 本文提出了NL2GenSym框架，将大语言模型（LLM）与SOAR认知架构结合，实现从自然语言自动生成符号规则，用于构建更高效的智能体，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: SOAR虽然在构建类人智能体上有广泛应用，但其规则需人工编码，耗时且低效。大语言模型能高效生成知识，但缺乏实证验证。本工作旨在解决规则自动化生成、高效验证与优化问题。

Method: 提出NL2GenSym框架，核心为执行驱动的生成-评论机制。首先利用检索增强的LLM生成初步规则，并在SOAR环境即时执行验证；再由LLM评论员根据执行反馈反复修正规则。实验在自建的水壶问题数据集上，采用Gemini和Qwen系列模型进行验证。

Result: NL2GenSym框架在自然语言生成规则的成功率超过86%，自动产生了新颖启发式规则，有效减少决策轮数至最优解的1.98倍，仅为基线方法的千分之一。部分实验表明小模型在框架下可优于大模型。

Conclusion: NL2GenSym大幅提升了符号规则自动生成效率，并扩展了SOAR架构的实用性。此外，框架促进了小参数模型的实用性能，显示LLM与符号智能结合的新潜力。

Abstract: SOAR, a classic symbol-based cognitive architecture, has been fostering the
development of general, human-like intelligent agents. Nevertheless, its
practical adoption is hindered by the laborious manual rule coding. Emerging
Large Language Models (LLMs) present the immense potential for efficient rules
generation. However, there is a critical gap that current research
predominantly focuses on conceptual frameworks and lacks robust experimental
validation. To bridge this gap, we propose \textit{N}atural \textit{L}anguage
to \textit{Gen}erative \textit{Sym}bolic Rules (NL2GenSym), a novel framework
that integrates LLMs with SOAR to autonomously produce generative symbolic
rules from natural language. Specifically, our framework introduces a novel
Execution-Grounded Generator-Critic mechanism. The LLM-based Generator, guided
by a Retrieval-Augmented Generation-accessed self-evolving domain knowledge
base, proposes rules from natural language. Subsequently, these rules are
immediately executed within the SOAR environment to rigorously validate their
correctness. Based on this execution-grounded feedback, a reflective LLM-based
Critic drives the iterative refinement of these rules. Experiments on our
specialized Water Jug Problem (WJP) dataset, utilizing both Gemini and Qwen
series models, validate the efficacy of our framework. It achieves a success
rate over 86\% in generating rules from natural language. Crucially, the
framework also generates novel heuristic rules, reducing average decision
cycles for solving the WJP to 1.98 times the optimal solution and 1/1000 of
baseline methods. Additionally, our initial experiments show that NL2GenSym
enables smaller-parameter models to achieve better performance than larger
counterparts.

</details>


### [176] [Understanding the Effects of Domain Finetuning on LLMs](https://arxiv.org/abs/2510.09359)
*Eshaan Tanwar,Deepak Nathani,William Yang Wang,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 本文系统性研究了大语言模型（LLM）在医学等特定领域微调时参数空间变化的机制，并提出了用于解释和分析这种变化的新方法。


<details>
  <summary>Details</summary>
Motivation: 虽然特定领域微调能显著提升LLM表现，但其对模型参数空间具体带来的变化机理尚不明确，尤其领域专用LLM的研究相对匮乏。

Method: 作者通过分析医学领域大型语言模型，观察微调过程对表示子空间的影响，并提出了“微调向量”（tuning vectors）这一新框架，专门用于捕捉微调引发的参数变化方向和特性。此外，分析了这些向量在模型不同层（如MLP层和注意力头）的表现和作用。

Result: 发现微调主要影响模型参数空间中的一小部分子空间，大部分预训练表示被保留。提出的微调向量能有效提升指令遵循性和文本生成质量，且不同领域微调向量组合可提升模型泛化能力。微调向量在MLP层写入新信息，在注意力头强化原有方向。

Conclusion: 该研究为理解LLM领域适应机制提供了新见解，并提出了一套通用、可解释化的分析特殊化LLM的方法论。

Abstract: Large Language Models (LLMs) fine-tuned for specific domains exhibit strong
performance; however, the underlying mechanisms by which this fine-tuning
reshapes their parametric space are not well understood. Prior works primarily
focus on auto-regressive or general-purpose instruct models, leaving
domain-specialised LLMs under-explored. We present the first systematic study
of domain-specific fine-tuning in large medical language models. Our analysis
reveals that fine-tuning modifies only a small subset of the representational
subspace, essentially preserving the pre-trained model's representation. To
interpret these changes in subspaces, we propose tuning vectors, a novel
framework inspired by task vectors, which explicitly capture the directional
parameter shifts induced by fine-tuning. We demonstrate that these vectors are
critical for enhancing both instruction-following and generation quality.
Furthermore, combining tuning vectors across different domains yields improved
generalisation. Upon closer inspection of directional alignment, we find these
vectors primarily write new directional information into the MLP layers of the
model, while amplifying existing directions in attention heads. Our findings
offer new insights into LLM adaptation and provide a general, interpretable
framework for analysing specialisation in large language models.

</details>


### [177] [Token-Level Policy Optimization: Linking Group-Level Rewards to Token-Level Aggregation via Markov Likelihood](https://arxiv.org/abs/2510.09369)
*Xingyu Lin,Yilin Wen,En Wang,Du Su,Wenbin Liu,Chenfu Bao,Zhonghou Lv*

Main category: cs.CL

TL;DR: 本文提出TEPO方法，通过改进token级奖励聚合，有效提升大语言模型数学推理能力，实现了新SOTA，并提升了训练稳定性。


<details>
  <summary>Details</summary>
Motivation: GRPO等方法提升了大模型推理，尤其数学能力，但面临因稀疏token奖励导致的训练不稳定和熵崩溃等问题。现有方法对token的熵调整缺少针对性，需更有效方案。

Method: 提出TEPO方法：通过token级框架结合Markov序列似然，将group级奖励与token通过聚合方式关联，实现更细致有效的奖励传递。

Result: TEPO在@k、准确率等关键指标上超越现有方法，并显著提升了训练的稳定性，对比基线效果更佳。

Conclusion: TEPO有效解决了GRPO在token奖励稀疏、模型（熵）崩溃等难题，提升了大模型推理能力和训练性能，在数学推理任务上达成新SOTA。

Abstract: Group Relative Policy Optimization (GRPO) has significantly advanced the
reasoning ability of large language models (LLMs), particularly by boosting
their mathematical performance. However, GRPO and related
entropy-regularization methods still face challenges rooted in the sparse token
rewards inherent to chain-of-thought (CoT). Current approaches often rely on
undifferentiated token-level entropy adjustments, which frequently lead to
entropy collapse or model collapse. In this work, we propose TEPO, a novel
token-level framework that incorporates Markov Likelihood (sequence likelihood)
links group-level rewards with tokens via token-level aggregation. Experiments
show that TEPO consistently outperforms existing baselines across key metrics
(including @k and accuracy). It not only sets a new state of the art on
mathematical reasoning tasks but also significantly enhances training
stability.

</details>


### [178] [Identifying & Interactively Refining Ambiguous User Goals for Data Visualization Code Generation](https://arxiv.org/abs/2510.09390)
*Mert İnan,Anthony Sicilia,Alex Xie,Saujas Vaduguru,Daniel Fried,Malihe Alikhani*

Main category: cs.CL

TL;DR: 本论文针对人机沟通中的共享目标建立，分析了自然语言歧义如何影响数据可视化代码生成，并提出了歧义类型分类和量化指标，展示多轮对话可有效减少歧义并提升代码准确性。


<details>
  <summary>Details</summary>
Motivation: 在人机协作中，共享目标确立至关重要，但歧义经常导致输出貌似正确但并未反映用户真实意图。数据可视化领域中，自然语言到代码生成环节容易被歧义影响，因此需要系统方法识别和量化这些问题。

Method: 论文在DS-1000数据集中选取绘图任务，提出歧义类型分类法和量化指标，并与不确定性等基线指标对比其与人工注释的相关性。此外，通过模拟多轮对话，评估三种语用学模型（Gricean协作，话语表示理论，和讨论下的问题）对减少歧义、提升代码匹配用户目标的作用。

Result: 实验证明提出的歧义量化指标与人工标注的相关性高于传统不确定性指标。模拟用户实验显示，多轮对话能更有效减轻歧义，使生成代码更准确地反映用户目标。三种语用学模型均对优化对话策略有推动作用。

Conclusion: 本文系统梳理了数据可视化中自然语言歧义的问题，通过指标和对话建模，提升了代码生成准确性，强调多轮交流对正确理解用户意图的重要价值，对人机协作和代码生成有积极意义。

Abstract: Establishing shared goals is a fundamental step in human-AI communication.
However, ambiguities can lead to outputs that seem correct but fail to reflect
the speaker's intent. In this paper, we explore this issue with a focus on the
data visualization domain, where ambiguities in natural language impact the
generation of code that visualizes data. The availability of multiple views on
the contextual (e.g., the intended plot and the code rendering the plot) allows
for a unique and comprehensive analysis of diverse ambiguity types. We develop
a taxonomy of types of ambiguity that arise in this task and propose metrics to
quantify them. Using Matplotlib problems from the DS-1000 dataset, we
demonstrate that our ambiguity metrics better correlate with human annotations
than uncertainty baselines. Our work also explores how multi-turn dialogue can
reduce ambiguity, therefore, improve code accuracy by better matching user
goals. We evaluate three pragmatic models to inform our dialogue strategies:
Gricean Cooperativity, Discourse Representation Theory, and Questions under
Discussion. A simulated user study reveals how pragmatic dialogues reduce
ambiguity and enhance code accuracy, highlighting the value of multi-turn
exchanges in code generation.

</details>


### [179] [Beyond Single-Granularity Prompts: A Multi-Scale Chain-of-Thought Prompt Learning for Graph](https://arxiv.org/abs/2510.09394)
*Ziyu Zheng,Yaming Yang,Ziyu Guan,Wei Zhao,Xinyan Huang,Weigang Lu*

Main category: cs.CL

TL;DR: 本文提出了一种多尺度图链式思考（MSGCOT）提示框架，突破传统图提示调优方法仅限于单一粒度的限制，有效提升了下游任务的性能，尤其在小样本学习场景中表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有图提示调优方法只在单一粒度（如节点级或子图级）上生成提示，忽略了图数据内在的多尺度结构信息，从而限制了提示语义的多样性和模型表现。

Method: 作者提出MSGCOT框架，用轻量级低秩粗化网络捕捉多尺度结构特征，将其作为分层基向量用于提示生成，并在人类由粗到细的推理模式启发下，动态整合多尺度信息，形成逐步优化的提示链。

Result: 在八个基准数据集上的大量实验显示，MSGCOT在下游任务，特别是小样本学习场景下，相较于现有单一粒度提示方法有更优表现。

Conclusion: 多尺度结构与链式思考式提示的融合能够丰富语义表达，提高图神经网络在多任务和低样本场景中的泛化性能，为图领域的提示调优提供了新思路。

Abstract: The "pre-train, prompt'' paradigm, designed to bridge the gap between
pre-training tasks and downstream objectives, has been extended from the NLP
domain to the graph domain and has achieved remarkable progress. Current
mainstream graph prompt-tuning methods modify input or output features using
learnable prompt vectors. However, existing approaches are confined to
single-granularity (e.g., node-level or subgraph-level) during prompt
generation, overlooking the inherently multi-scale structural information in
graph data, which limits the diversity of prompt semantics. To address this
issue, we pioneer the integration of multi-scale information into graph prompt
and propose a Multi-Scale Graph Chain-of-Thought (MSGCOT) prompting framework.
Specifically, we design a lightweight, low-rank coarsening network to
efficiently capture multi-scale structural features as hierarchical basis
vectors for prompt generation. Subsequently, mimicking human cognition from
coarse-to-fine granularity, we dynamically integrate multi-scale information at
each reasoning step, forming a progressive coarse-to-fine prompt chain.
Extensive experiments on eight benchmark datasets demonstrate that MSGCOT
outperforms the state-of-the-art single-granularity graph prompt-tuning method,
particularly in few-shot scenarios, showcasing superior performance.

</details>


### [180] [Active Model Selection for Large Language Models](https://arxiv.org/abs/2510.09418)
*Yavuz Durmazkeser,Patrik Okanovic,Andreas Kirsch,Torsten Hoefler,Nezihe Merve Gürel*

Main category: cs.CL

TL;DR: LLM SELECTOR是一个可高效选择最佳大语言模型的新框架，大幅减少标注成本。


<details>
  <summary>Details</summary>
Motivation: 现有的大模型评估方法依赖大量全标注数据，成本高且不灵活，亟需高效、低成本的选择策略。

Method: 提出了一种主动模型选择框架LLM SELECTOR，可自适应选择对判别模型最有信息量的小规模查询集合，并采用“评委式”判别模型以进一步降低标注成本。

Result: 在6个基准任务、151个大模型上实验，LLM SELECTOR选择最佳（或次佳）模型时标注成本最多降低59.62%。

Conclusion: LLM SELECTOR能够在保持模型选择准确率的同时，大幅降低人工标注成本，对大模型应用具有现实意义。

Abstract: We introduce LLM SELECTOR, the first framework for active model selection of
Large Language Models (LLMs). Unlike prior evaluation and benchmarking
approaches that rely on fully annotated datasets, LLM SELECTOR efficiently
identifies the best LLM with limited annotations. In particular, for any given
task, LLM SELECTOR adaptively selects a small set of queries to annotate that
are most informative about the best model for the task. To further reduce
annotation cost, we leverage a judge-based oracle annotation model. Through
extensive experiments on 6 benchmarks with 151 LLMs, we show that LLM SELECTOR
reduces annotation costs by up to 59.62% when selecting the best and near-best
LLM for the task.

</details>


### [181] [On the Representations of Entities in Auto-regressive Large Language Models](https://arxiv.org/abs/2510.09421)
*Victor Morand,Josiane Mothe,Benjamin Piwowarski*

Main category: cs.CL

TL;DR: 本文提出了一种新框架，用于研究大型语言模型（LLMs）如何内部表示和操控命名实体，并开发了新方法揭示了模型对多词实体的独特表征机制。


<details>
  <summary>Details</summary>
Motivation: 尽管命名实体在文本知识中至关重要，目前仍不清楚LLMs在内部如何表征实体，尤其对多词命名实体的表征方式知之甚少。

Method: 本文提出了实体提及重构（entity mention reconstruction）框架，并利用 task vectors 结合 LLMs 的隐藏状态，使得可以一致地从多种实体表示中生成多词实体提及。同时提出 Entity Lens 方法，扩展了原有的 logit-lens，以预测多词实体。

Result: 实验结果显示，LLMs能够利用其内部机制准确表示和重建多词实体（包括训练时未见过的），而且这些机制能有效捕获实体间关系知识。

Conclusion: LLMs发展出实体特定的内部机制，可以有效地表示和操控包括未见过的多词命名实体，这为理解和改进LLMs处理知识实体能力提供了新视角。

Abstract: Named entities are fundamental building blocks of knowledge in text,
grounding factual information and structuring relationships within language.
Despite their importance, it remains unclear how Large Language Models (LLMs)
internally represent entities. Prior research has primarily examined explicit
relationships, but little is known about entity representations themselves. We
introduce entity mention reconstruction as a novel framework for studying how
LLMs encode and manipulate entities. We investigate whether entity mentions can
be generated from internal representations, how multi-token entities are
encoded beyond last-token embeddings, and whether these representations capture
relational knowledge. Our proposed method, leveraging _task vectors_, allows to
consistently generate multi-token mentions from various entity representations
derived from the LLMs hidden states. We thus introduce the _Entity Lens_,
extending the _logit-lens_ to predict multi-token mentions. Our results bring
new evidence that LLMs develop entity-specific mechanisms to represent and
manipulate any multi-token entities, including those unseen during training.
Our code is avalable at https://github.com/VictorMorand/EntityRepresentations .

</details>


### [182] [Dyna-Mind: Learning to Simulate from Experience for Better AI Agents](https://arxiv.org/abs/2510.09577)
*Xiao Yu,Baolin Peng,Michel Galley,Hao Cheng,Qianhui Wu,Janardhan Kulkarni,Suman Nath,Zhou Yu,Jianfeng Gao*

Main category: cs.CL

TL;DR: 本文提出Dyna-Mind框架，通过引入“类比试错”机制，显著提升AI代理在复杂、交互性强的长周期任务中的推理和规划能力。该框架在多个任务和环境中均验证有效。


<details>
  <summary>Details</summary>
Motivation: 虽然现有AI模型在数学和编程等领域表现出色，但在长周期且需交互的任务（如网页导航、设备操作）中表现较差。受人类认知机制启发，作者认为AI需要具备“类比试错”（即行动前脑内预演多种未来情景）的能力，以提升其在复杂任务中的表现。

Method: 提出两阶段训练框架Dyna-Mind。第一阶段ReSim，通过基于真实环境交互扩展的搜索树，训练代理生成结构化推理轨迹，从而让其推理扎根于真实世界动态并具备预测未来状态的能力。第二阶段Dyna-GRPO，采用在线强化学习，结合结果奖励与中间状态反馈，进一步增强代理的仿真和决策能力。

Result: 在两个合成基准测试（推箱子、ALFWorld）和一个真实基准（AndroidWorld）上，实验证明ReSim提升了AI模拟未来的能力，Dyna-GRPO使AI学会了更优策略，应对长周期、依赖规划的任务。

Conclusion: 模拟能力对AI在复杂环境中的推理、规划与行动至关重要。Dyna-Mind框架为提升AI综合智能提供了有效方法，可广泛应用于未来更具挑战性的任务。

Abstract: Reasoning models have recently shown remarkable progress in domains such as
math and coding. However, their expert-level abilities in math and coding
contrast sharply with their performance in long-horizon, interactive tasks such
as web navigation and computer/phone-use. Inspired by literature on human
cognition, we argue that current AI agents need ''vicarious trial and error'' -
the capacity to mentally simulate alternative futures before acting - in order
to enhance their understanding and performance in complex interactive
environments. We introduce Dyna-Mind, a two-stage training framework that
explicitly teaches (V)LM agents to integrate such simulation into their
reasoning. In stage 1, we introduce Reasoning with Simulations (ReSim), which
trains the agent to generate structured reasoning traces from expanded search
trees built from real experience gathered through environment interactions.
ReSim thus grounds the agent's reasoning in faithful world dynamics and equips
it with the ability to anticipate future states in its reasoning. In stage 2,
we propose Dyna-GRPO, an online reinforcement learning method to further
strengthen the agent's simulation and decision-making ability by using both
outcome rewards and intermediate states as feedback from real rollouts.
Experiments on two synthetic benchmarks (Sokoban and ALFWorld) and one
realistic benchmark (AndroidWorld) demonstrate that (1) ReSim effectively
infuses simulation ability into AI agents, and (2) Dyna-GRPO leverages outcome
and interaction-level signals to learn better policies for long-horizon,
planning-intensive tasks. Together, these results highlight the central role of
simulation in enabling AI agents to reason, plan, and act more effectively in
the ever more challenging environments.

</details>


### [183] [The Speech-LLM Takes It All: A Truly Fully End-to-End Spoken Dialogue State Tracking Approach](https://arxiv.org/abs/2510.09424)
*Nizar El Ghazal,Antoine Caubrière,Valentin Vielzeuf*

Main category: cs.CL

TL;DR: 本文比较了基于Speech-LLM的端到端口语对话状态追踪中的不同上下文管理策略，发现完整语音历史输入效果最佳，压缩语音历史可在效率和准确率间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 随着语音对话系统的发展，如何高效利用对话上下文来提升状态追踪准确率成为研究热点。以往方法多注重多模态或部分历史信息，缺少系统性比较。

Method: 作者设计了三种上下文输入策略：（1）传统多模态上下文（文本历史+本轮语音），（2）全量语音历史输入，（3）基于attention pooling的语音历史压缩，并在SpokenWOZ数据集上系统评测。

Result: 实验表明，完整输入所有语音历史的模型在同等模型规模下表现最佳，大幅超越以往方法。压缩策略下则可以有效缩减输入规模但保持较高准确性。

Conclusion: 研究证实，充分利用完整语音历史能够显著提升语音对话状态追踪的效果，且合理压缩上下文也能兼顾效率和性能，对后续对话系统设计有参考价值。

Abstract: This paper presents a comparative study of context management strategies for
end-to-end Spoken Dialog State Tracking using Speech-LLMs. We systematically
evaluate traditional multimodal context (combining text history and spoken
current turn), full spoken history, and compressed spoken history approaches.
Our experiments on the SpokenWOZ corpus demonstrate that providing the full
spoken conversation as input yields the highest performance among models of
similar size, significantly surpassing prior methods. Furthermore, we show that
attention-pooling-based compression of the spoken history offers a strong
trade-off, maintaining competitive accuracy with reduced context size. Detailed
analysis confirms that improvements stem from more effective context
utilization.

</details>


### [184] [KORMo: Korean Open Reasoning Model for Everyone](https://arxiv.org/abs/2510.09426)
*Minjun Kim,Hyeonseok Lim,Hangyeol Yoo,Inho Won,Seungwoo Song,Minkyung Cho,Junhun Yuk,Changsu Choi,Dongjae Shin,Huige Lee,Hoyun Song,Alice Oh,Kyungtae Lim*

Main category: cs.CL

TL;DR: 本文提出并详细分析了为韩语构建完全开源的双语大模型（KORMo-10B），该模型主要用合成数据进行训练，并在多个基准测试中表现良好。


<details>
  <summary>Details</summary>
Motivation: 在多语言环境下，低资源语言（如韩语）缺乏高质量训练数据，阻碍了相关大模型的开发与研究。因此，作者希望通过合成数据解决数据短缺，推动开源多语言大模型的研究。

Method: 作者从零开始训练了一个108亿参数的韩英双语大模型KORMo-10B，其中68.74%的韩语数据为合成内容。重点对合成数据进行了精细筛选，保证语言覆盖面和多样性，并进行了系统实验验证模型的稳定性和性能。

Result: 在推理、知识、指令遵循等多项基准测试上，KORMo-10B的表现与现有主流开源多语种大模型相当。实验还表明：精心设计的合成数据能确保长期预训练稳定，双语指令微调可实现接近母语的韩语理解和表述能力。

Conclusion: 合成数据驱动的开源模型在低资源语种上可行且高效。作者公开所有数据、代码和实验流程，为低资源语言大模型的发展提供了开放可复现的范例。

Abstract: This work presents the first large-scale investigation into constructing a
fully open bilingual large language model (LLM) for a non-English language,
specifically Korean, trained predominantly on synthetic data. We introduce
KORMo-10B, a 10.8B-parameter model trained from scratch on a Korean-English
corpus in which 68.74% of the Korean portion is synthetic. Through systematic
experimentation, we demonstrate that synthetic data, when carefully curated
with balanced linguistic coverage and diverse instruction styles, does not
cause instability or degradation during large-scale pretraining. Furthermore,
the model achieves performance comparable to that of contemporary open-weight
multilingual baselines across a wide range of reasoning, knowledge, and
instruction-following benchmarks. Our experiments reveal two key findings: (1)
synthetic data can reliably sustain long-horizon pretraining without model
collapse, and (2) bilingual instruction tuning enables near-native reasoning
and discourse coherence in Korean. By fully releasing all components including
data, code, training recipes, and logs, this work establishes a transparent
framework for developing synthetic data-driven fully open models (FOMs) in
low-resource settings and sets a reproducible precedent for future multilingual
LLM research.

</details>


### [185] [Domain-Adapted Pre-trained Language Models for Implicit Information Extraction in Crash Narratives](https://arxiv.org/abs/2510.09434)
*Xixi Wang,Jordanka Kovaceva,Miguel Costa,Shuai Wang,Francisco Camara Pereira,Robert Thomson*

Main category: cs.CL

TL;DR: 本文探索了使用小型开源预训练语言模型（PLMs），如改进的BERT，通过精调（LoRA等方法）对交通事故叙述文本进行推理密集型任务处理，结果超过了GPT-4o等封闭大模型，并且数据隐私与资源占用更优。


<details>
  <summary>Details</summary>
Motivation: 交通事故数据库中的自由文本叙述对提升交通安全很有价值，但批量处理这些非结构化、非标准化文本极具挑战，且现有工具稀缺。同时，闭源LLM存在隐私风险与领域适应性不强的问题。本文希望验证紧凑型开源PLM模型在推理密集、细粒度任务中的实用性。

Method: 主要采用LoRA等方法，对开源预训练模型（如BERT）进行精调，使其能针对特定任务（如碰撞方式和各车辆碰撞类型识别）更好地理解和推理交通事故叙述文本。训练和评估均基于权威真实数据集CISS。

Result: 精调后的紧凑型PLMs在推理密集型任务上超越了如GPT-4o等强大封闭大模型，同时对硬件资源要求低。模型不仅能更好地提取叙述细节，还能纠正部分数据标签错误。

Conclusion: 精调的开源小模型可低成本高效地应对交通事故文本推理任务，优于闭源LLM，能有效保护数据隐私、提升行业应用价值。

Abstract: Free-text crash narratives recorded in real-world crash databases have been
shown to play a significant role in improving traffic safety. However,
large-scale analyses remain difficult to implement as there are no documented
tools that can batch process the unstructured, non standardized text content
written by various authors with diverse experience and attention to detail. In
recent years, Transformer-based pre-trained language models (PLMs), such as
Bidirectional Encoder Representations from Transformers (BERT) and large
language models (LLMs), have demonstrated strong capabilities across various
natural language processing tasks. These models can extract explicit facts from
crash narratives, but their performance declines on inference-heavy tasks in,
for example, Crash Type identification, which can involve nearly 100
categories. Moreover, relying on closed LLMs through external APIs raises
privacy concerns for sensitive crash data. Additionally, these black-box tools
often underperform due to limited domain knowledge. Motivated by these
challenges, we study whether compact open-source PLMs can support
reasoning-intensive extraction from crash narratives. We target two challenging
objectives: 1) identifying the Manner of Collision for a crash, and 2) Crash
Type for each vehicle involved in the crash event from real-world crash
narratives. To bridge domain gaps, we apply fine-tuning techniques to inject
task-specific knowledge to LLMs with Low-Rank Adaption (LoRA) and BERT.
Experiments on the authoritative real-world dataset Crash Investigation
Sampling System (CISS) demonstrate that our fine-tuned compact models
outperform strong closed LLMs, such as GPT-4o, while requiring only minimal
training resources. Further analysis reveals that the fine-tuned PLMs can
capture richer narrative details and even correct some mislabeled annotations
in the dataset.

</details>


### [186] [Getting Your Indices in a Row: Full-Text Search for LLM Training Data for Real World](https://arxiv.org/abs/2510.09471)
*Ines Altemir Marinas,Anastasiia Kucherenko,Alexander Sternfeld,Andrei Kucharavy*

Main category: cs.CL

TL;DR: 本文介绍了Apertus LLM训练数据的全文索引流程，实现了对大规模训练数据的高效索引，并展示了其在LLM安全与开放网络搜索中的应用。


<details>
  <summary>Details</summary>
Motivation: 尽管开源LLM越来越多，但其训练数据的访问性和可审查性有限，限制了研究者与公众了解模型背后的数据基础，也影响了安全性、偏见和透明度等研究。

Method: 作者利用Elasticsearch并行索引和高能效的arm64 Alps超级集群，对Apertus LLM使用的15.2万亿Token中的8.6万亿Token进行了全文索引，实现了超大规模的数据处理。

Result: 成功将Elasticsearch移植到下一代arm64基础设施，实现了面向LLM训练数据和开放网络的全文索引任务，并开发出了新的LLM安全工具。

Conclusion: 全文索引不仅提升了LLM训练数据的透明度和可获取性，还有助于推动更安全、更绿色的算力基础设施发展，并为其他团队的类似项目提供了借鉴。

Abstract: The performance of Large Language Models (LLMs) is determined by their
training data. Despite the proliferation of open-weight LLMs, access to LLM
training data has remained limited. Even for fully open LLMs, the scale of the
data makes it all but inscrutable to the general scientific community, despite
potentially containing critical data scraped from the internet.
  In this paper, we present the full-text indexing pipeline for the Apertus LLM
training data. Leveraging Elasticsearch parallel indices and the Alps
infrastructure, a state-of-the-art, highly energy-efficient arm64 supercluster,
we were able to index 8.6T tokens out of 15.2T used to train the Apertus LLM
family, creating both a critical LLM safety tool and effectively an offline,
curated, open web search engine. Our contribution is threefold. First, we
demonstrate that Elasticsearch can be successfully ported onto next-generation
arm64-based infrastructure. Second, we demonstrate that full-text indexing at
the scale of modern LLM training datasets and the entire open web is feasible
and accessible. Finally, we demonstrate that such indices can be used to ensure
previously inaccessible jailbreak-agnostic LLM safety.
  We hope that our findings will be useful to other teams attempting
large-scale data indexing and facilitate the general transition towards greener
computation.

</details>


### [187] [Hybrid Models for Natural Language Reasoning: The Case of Syllogistic Logic](https://arxiv.org/abs/2510.09472)
*Manuel Vargas Guzmán,Jakub Szymanik,Maciej Malicki*

Main category: cs.CL

TL;DR: 当前大模型在逻辑推理任务上的泛化能力存在局限，尤其在组分性和递归性上表现不同。文中提出通过符号-神经混合架构以提升大模型推理泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管神经网络模型表现优异，但在逻辑推理等任务上的泛化能力仍然不足。特别是在组分性（抽象原子规则）的掌握和递归性（迭代推理）的表现差异明显。因此，需要区分与提升这两个泛化能力。

Method: 作者以三段论推理为基准，系统评估了大语言模型（LLMs）的组分性与递归性能力。随后，提出了结合符号推理与神经网络计算的混合架构，并在各种规模的神经分量下进行了实验。

Result: 实验结果显示，LLMs在递归性推理上表现尚可，但在组分性推理上存在显著不足。提出的混合架构能够高效并鲁棒地进行推理，即使神经部分规模较小，整体效果也很强。

Conclusion: 符号-神经混合推理架构有效弥补了现有大模型在逻辑泛化（尤其是组分性）上的不足，为解决神经推理系统中的核心泛化难题提供了有前景的方法。

Abstract: Despite the remarkable progress in neural models, their ability to
generalize, a cornerstone for applications like logical reasoning, remains a
critical challenge. We delineate two fundamental aspects of this ability:
compositionality, the capacity to abstract atomic logical rules underlying
complex inferences, and recursiveness, the aptitude to build intricate
representations through iterative application of inference rules. In the
literature, these two aspects are often confounded together under the umbrella
term of generalization. To sharpen this distinction, we investigated the
logical generalization capabilities of pre-trained large language models (LLMs)
using the syllogistic fragment as a benchmark for natural language reasoning.
Though simple, this fragment provides a foundational yet expressive subset of
formal logic that supports controlled evaluation of essential reasoning
abilities. Our findings reveal a significant disparity: while LLMs demonstrate
reasonable proficiency in recursiveness, they struggle with compositionality.
To overcome these limitations and establish a reliable logical prover, we
propose a hybrid architecture integrating symbolic reasoning with neural
computation. This synergistic interaction enables robust and efficient
inference, neural components accelerate processing, while symbolic reasoning
ensures completeness. Our experiments show that high efficiency is preserved
even with relatively small neural components. As part of our proposed
methodology, this analysis gives a rationale and highlights the potential of
hybrid models to effectively address key generalization barriers in neural
reasoning systems.

</details>


### [188] [Multimodal Policy Internalization for Conversational Agents](https://arxiv.org/abs/2510.09474)
*Zhenhailong Wang,Jiateng Liu,Amin Fazel,Ritesh Sarkhel,Xing Fan,Xiang Li,Chenlei Guo,Heng Ji,Ruhi Sarikaya*

Main category: cs.CL

TL;DR: 本文提出了一种将多模态政策直接内化到大模型参数中的方法，无需推理时携带冗长政策提示，有效提升多模态智能体的政策遵循能力和效率。


<details>
  <summary>Details</summary>
Motivation: 随着LLM驱动的对话智能体越来越复杂，内嵌的政策（如元数据、风格和工具使用规则）也随之扩展和变得冗长，尤其是在多模态任务下，既增加了计算负担，也降低了政策遵从度，亟需新的机制简化和提升政策执行。

Method: 作者提出多模态政策内化任务（MPI），并设计了TriMPI三阶段训练框架：先通过持续预训练注入政策知识，再用有监督微调强化，最后通过融合强化学习和政策感知的PolicyRollout提升泛化和探索能力。同时构建了合成和真实任务数据集验证方案。

Result: TriMPI方法在端到端准确率、泛化性及遗忘鲁棒性上均获得显著提升，超越了以往只压缩文本提示或对齐文本安全规则的工作。

Conclusion: 该工作首次系统研究多模态政策内化问题，提出通用的数据集、训练范式和评测手段，为后续多模态智能体政策学习和应用奠定了基础。

Abstract: Modern conversational agents like ChatGPT and Alexa+ rely on predefined
policies specifying metadata, response styles, and tool-usage rules. As these
LLM-based systems expand to support diverse business and user queries, such
policies, often implemented as in-context prompts, are becoming increasingly
complex and lengthy, making faithful adherence difficult and imposing large
fixed computational costs. With the rise of multimodal agents, policies that
govern visual and multimodal behaviors are critical but remain understudied.
Prior prompt-compression work mainly shortens task templates and
demonstrations, while existing policy-alignment studies focus only on
text-based safety rules. We introduce Multimodal Policy Internalization (MPI),
a new task that internalizes reasoning-intensive multimodal policies into model
parameters, enabling stronger policy-following without including the policy
during inference. MPI poses unique data and algorithmic challenges. We build
two datasets spanning synthetic and real-world decision-making and tool-using
tasks and propose TriMPI, a three-stage training framework. TriMPI first
injects policy knowledge via continual pretraining, then performs supervised
finetuning, and finally applies PolicyRollout, a GRPO-style reinforcement
learning extension that augments rollouts with policy-aware responses for
grounded exploration. TriMPI achieves notable gains in end-to-end accuracy,
generalization, and robustness to forgetting. As the first work on multimodal
policy internalization, we provide datasets, training recipes, and
comprehensive evaluations to foster future research. Project page:
https://mikewangwzhl.github.io/TriMPI.

</details>


### [189] [StatEval: A Comprehensive Benchmark for Large Language Models in Statistics](https://arxiv.org/abs/2510.09517)
*Yuchen Lu,Run Yang,Yichen Zhang,Shuguang Yu,Runpeng Dai,Ziwei Wang,Jiayi Xiang,Wenxin E,Siran Gao,Xinyao Ruan,Yirui Huang,Chenjing Xi,Haibo Hu,Yueming Fu,Qinglan Yu,Xiaobing Wei,Jiani Gu,Rui Sun,Jiaxuan Jia,Fan Zhou*

Main category: cs.CL

TL;DR: 本论文提出了StatEval，这是首个专门针对统计学领域的大型基准测试集，涵盖本科、研究生和研究级别的问题，以评估大型语言模型（LLMs）在统计推理上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型基准评测主要关注数学和逻辑推理，而缺乏对统计学这一独立且综合性的学科的系统测试，由此导致LLMs在统计推理能力方面的真实水平不明。

Method: 作者构建了StatEval基准，共包含13817道基础统计学题目和2374道来自顶级期刊的研究级证明题。通过可扩展的多智能体流程与人工参与，自动化实现题目收集、重写与质量控制，并设计了适用于计算和证明任务的评估体系，对模型的推理能力进行细致分析。

Result: 实验显示，主流闭源模型（如GPT5-mini）在研究级问题上的表现不足57%，开源模型表现更低，暴露出统计推理任务对于LLMs存在显著挑战。

Conclusion: 当前LLMs在处理高阶统计推理任务方面存在显著不足，StatEval为推动语言模型在统计智能领域的进步提供了科学的评测工具和研究平台。

Abstract: Large language models (LLMs) have demonstrated remarkable advances in
mathematical and logical reasoning, yet statistics, as a distinct and
integrative discipline, remains underexplored in benchmarking efforts. To
address this gap, we introduce \textbf{StatEval}, the first comprehensive
benchmark dedicated to statistics, spanning both breadth and depth across
difficulty levels. StatEval consists of 13,817 foundational problems covering
undergraduate and graduate curricula, together with 2374 research-level proof
tasks extracted from leading journals. To construct the benchmark, we design a
scalable multi-agent pipeline with human-in-the-loop validation that automates
large-scale problem extraction, rewriting, and quality control, while ensuring
academic rigor. We further propose a robust evaluation framework tailored to
both computational and proof-based tasks, enabling fine-grained assessment of
reasoning ability. Experimental results reveal that while closed-source models
such as GPT5-mini achieve below 57\% on research-level problems, with
open-source models performing significantly lower. These findings highlight the
unique challenges of statistical reasoning and the limitations of current LLMs.
We expect StatEval to serve as a rigorous benchmark for advancing statistical
intelligence in large language models. All data and code are available on our
web platform: https://stateval.github.io/.

</details>


### [190] [Can We Reliably Rank Model Performance across Domains without Labeled Data?](https://arxiv.org/abs/2510.09519)
*Veronica Rammouz,Aaron Gonzalez,Carlos Cruzportillo,Adrian Tan,Nicole Beebe,Anthony Rios*

Main category: cs.CL

TL;DR: 本文讨论了无需标签评估NLP模型性能的方法，重点比较了不同估算方式在跨领域排序的可靠性，并通过实验验证了基于大语言模型的误差预测方法更优。


<details>
  <summary>Details</summary>
Motivation: 没有标签时评估模型性能对于判断NLP模型泛化能力至关重要。尽管已经有些无监督估算方法，如基于数据集相似性或预测正确性，但这些方法在跨领域排序中何时可靠尚不明确。本文旨在系统分析影响性能排序可靠性的因素。

Method: 提出了两步评估框架，使用四个基础分类器与多种大语言模型作为误差预测器，分别在GeoOLID和Amazon Reviews数据集、15个领域上进行实验。将大语言模型预测结果与漂移（drift）和零样本（zero-shot）基线进行对比，并分析误差模型预测与真实失败分布的一致性。

Result: 实验结果显示，大语言模型作为误差预测器时，其预测的性能排名与真实标签上的准确率之间存在更强、更一致的相关性，显著优于基于数据漂移或零样本的方法；排序的可靠性在领域间表现差异较大时提高，当误差模型的预测能准确反映基础模型的失败模式时也更可信。

Conclusion: 本文明确了无监督性能排序方法可靠性的适用条件，并总结了跨领域性能估算的实践指南，为未来无标签跨领域模型评价提供参考。

Abstract: Estimating model performance without labels is an important goal for
understanding how NLP models generalize. While prior work has proposed measures
based on dataset similarity or predicted correctness, it remains unclear when
these estimates produce reliable performance rankings across domains. In this
paper, we analyze the factors that affect ranking reliability using a two-step
evaluation setup with four base classifiers and several large language models
as error predictors. Experiments on the GeoOLID and Amazon Reviews datasets,
spanning 15 domains, show that large language model-based error predictors
produce stronger and more consistent rank correlations with true accuracy than
drift-based or zero-shot baselines. Our analysis reveals two key findings:
ranking is more reliable when performance differences across domains are
larger, and when the error model's predictions align with the base model's true
failure patterns. These results clarify when performance estimation methods can
be trusted and provide guidance for their use in cross-domain model evaluation.

</details>


### [191] [Accent-Invariant Automatic Speech Recognition via Saliency-Driven Spectrogram Masking](https://arxiv.org/abs/2510.09528)
*Mohammad Hossein Sameti,Sepehr Harfi Moridani,Ali Zarean,Hossein Sameti*

Main category: cs.CL

TL;DR: 本文提出了一种用于自动语音识别（ASR）的口音无关性增强框架，通过掩蔽语谱图的口音关键区域进行数据增强，有效降低了英语和波斯语的口音敏感性，提高了ASR的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于预训练transformer的ASR系统在遇到口音或方言变化时识别性能显著下降（WER升高），尤其在如英语和波斯语等语言多样性较强的场景下表现不足，亟需提升模型的口音鲁棒性。

Method: 1）构建语谱图基础的口音分类器，学习不同口音的区分特征。2）掩蔽对分类影响最大的语谱区域，对原始语音数据进行口音相关特征掩蔽。3）用掩蔽后的语谱图进行数据增强，提升ASR模型对口音多样性的适应能力。4）針对波斯语新采集并建立多方言数据集作为标准基线进行实验。

Result: 在英语和波斯语（包括新建方言数据集）上，与Whisper模型结合的掩蔽增强方法显著降低了WER，表明该方法确实提升了ASR对口音的鲁棒性。

Conclusion: 所提出的口音无关ASR框架有效提升了多语言、多口音场景下的自动语音识别表现，并为低资源、语言多样性高的语种研究提供了新数据集和基线，有助于推动更鲁棒的多语言ASR系统发展。

Abstract: Pre-trained transformer-based models have significantly advanced automatic
speech recognition (ASR), yet they remain sensitive to accent and dialectal
variations, resulting in elevated word error rates (WER) in linguistically
diverse languages such as English and Persian. To address this challenge, we
propose an accent-invariant ASR framework that integrates accent and dialect
classification into the recognition pipeline. Our approach involves training a
spectrogram-based classifier to capture accent-specific cues, masking the
regions most influential to its predictions, and using the masked spectrograms
for data augmentation. This enhances the robustness of ASR models against
accent variability. We evaluate the method using both English and Persian
speech. For Persian, we introduce a newly collected dataset spanning multiple
regional accents, establishing the first systematic benchmark for accent
variation in Persian ASR that fills a critical gap in multilingual speech
research and provides a foundation for future studies on low-resource,
linguistically diverse languages. Experimental results with the Whisper model
demonstrate that our masking and augmentation strategy yields substantial WER
reductions in both English and Persian settings, confirming the effectiveness
of the approach. This research advances the development of multilingual ASR
systems that are resilient to accent and dialect diversity. Code and dataset
are publicly available at: https://github.com/MH-Sameti/Accent_invariant_ASR

</details>


### [192] [Mitigating Overthinking through Reasoning Shaping](https://arxiv.org/abs/2510.09535)
*Feifan Song,Shaohang Wei,Bofei Gao,Yejie Wang,Wen Luo,Wei Li,Linli Yao,Weimin Xiong,Liang Chen,Tianyu Liu,Houfeng Wang*

Main category: cs.CL

TL;DR: 本文提出了一种新的正则化方法GRSP，通过在推理流程中以分段为单位进行奖励和惩罚权衡，提升大型推理模型的效率，显著降低计算消耗，并且在处理难题时效果尤为突出。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在训练时常因过度推理造成计算资源浪费，现有的基于RLVR的惩罚手段虽能控消耗，却往往简单粗暴，导致模型精度下降。作者认为监督粒度是影响效率与精度平衡关键。

Method: 提出一种分组相对分段惩罚机制（GRSP），不再对每个token惩罚，而是对推理中的语义分段施加奖励/惩罚，并结合分段长度设计加权机制，训练过程中能更细致地优化推理链条。

Result: 实验表明，GRSP相比现有RLVR方法有效提升了token效率（减少token数和计算量），在高难度任务中更为突出，并且训练过程更加稳定，对不同模型规模均适用。

Conclusion: GRSP作为高粒度分段级约束，对提升大模型推理效率和稳定性有效，是提升RLVR训练性能和应用价值的新途径。

Abstract: Large reasoning models (LRMs) boosted by Reinforcement Learning from Verifier
Reward (RLVR) have shown great power in problem solving, yet they often cause
overthinking: excessive, meandering reasoning that inflates computational cost.
Prior designs of penalization in RLVR manage to reduce token consumption while
often harming model performance, which arises from the oversimplicity of
token-level supervision. In this paper, we argue that the granularity of
supervision plays a crucial role in balancing efficiency and accuracy, and
propose Group Relative Segment Penalization (GRSP), a step-level method to
regularize reasoning. Since preliminary analyses show that reasoning segments
are strongly correlated with token consumption and model performance, we design
a length-aware weighting mechanism across segment clusters. Extensive
experiments demonstrate that GRSP achieves superior token efficiency without
heavily compromising accuracy, especially the advantages with harder problems.
Moreover, GRSP stabilizes RL training and scales effectively across model
sizes.

</details>


### [193] [Evaluating Robustness of Large Language Models Against Multilingual Typographical Errors](https://arxiv.org/abs/2510.09536)
*Yihong Liu,Raoyuan Zhao,Lena Altinger,Hinrich Schütze,Michael A. Hedderich*

Main category: cs.CL

TL;DR: 本论文提出并验证了MulTypo，一种用于多语言场景下模拟人类拼写错误的生成算法，系统性评估了18个开源大语言模型在多任务中的鲁棒性，发现模型面对拼写错误表现普遍下降，尤其是生成和推理任务，同时不同语言间鲁棒性存在明显差异。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型多部署于多语种应用中，实际用户输入不可避免包含拼写错误，而当前主流评测基准多假设输入无误，忽视了模型对拼写错误鲁棒性的考察，尤其在多语言环境下。为弥补这一空白，需要开发更贴近真实输入状态的评测方法与基准。

Method: 作者提出MulTypo算法，依据各语言特定键盘布局和打字行为，自动生成拟人化的拼写错误样本。利用MulTypo，作者对18个开源LLM横跨三大模型家族、五类任务（语言推断、多项选择问答、数学推理、机器翻译等）进行大规模评测，考查拼写错误对模型性能的影响。

Result: 拼写错误显著降低了模型性能，生成类与推理类任务影响尤为突出，传统NLI任务较为稳健。Instruction tuning可提升干净输入下性能，但对噪声输入往往更脆弱。高资源语言比低资源语言更具鲁棒性，英译他语比他语译英表现更好。

Conclusion: 拼写错误问题严重制约现有LLM在真实多语言环境下的应用性能，模型噪声鲁棒性和训练策略亟需加强。建议未来评估和模型培养时必须引入噪声场景，促进多语言与恶劣输入条件下的鲁棒发展。

Abstract: Large language models (LLMs) are increasingly deployed in multilingual,
real-world applications with user inputs -- naturally introducing typographical
errors (typos). Yet most benchmarks assume clean input, leaving the robustness
of LLMs to typos across languages largely underexplored. To address this gap,
we introduce MulTypo, a multilingual typo generation algorithm that simulates
human-like errors based on language-specific keyboard layouts and typing
behavior. We evaluate 18 open-source LLMs across three model families and five
downstream tasks spanning language inference, multi-choice question answering,
mathematical reasoning, and machine translation tasks. Our results show that
typos consistently degrade performance, particularly in generative tasks and
those requiring reasoning -- while the natural language inference task is
comparatively more robust. Instruction tuning improves clean-input performance
but may increase brittleness under noise. We also observe language-dependent
robustness: high-resource languages are generally more robust than low-resource
ones, and translation from English is more robust than translation into
English. Our findings underscore the need for noise-aware training and
multilingual robustness evaluation. We make our code and data publicly
available.

</details>


### [194] [SPG: Sandwiched Policy Gradient for Masked Diffusion Language Models](https://arxiv.org/abs/2510.09541)
*Chengyu Wang,Paria Rashidinejad,DiJia Su,Song Jiang,Sid Wang,Siyan Zhao,Cai Zhou,Shannon Zejiang Shen,Feiyu Chen,Tommi Jaakkola,Yuandong Tian,Bo Liu*

Main category: cs.CL

TL;DR: 本文提出了一种新方法Sandwiched Policy Gradient（SPG），用于更有效地训练扩散大语言模型（dLLMs），显著提升了多项基准任务表现。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型（dLLMs）因可并行生成多个token而成为自回归模型的高效替代方案。然而，用强化学习（RL）使其对齐人类偏好或任务奖励时，现有方法受限于无法直接利用真实对数似然，导致策略梯度存在偏差，影响性能。

Method: 论文提出Sandwiched Policy Gradient（SPG）方法，利用对数似然的上下界联合估计，从而更准确地优化dLLMs，并缓解现有方法（如ELBO）带来的策略梯度偏差。

Result: 与基于ELBO或单步估计的现有方法相比，SPG方法在GSM8K、MATH500、Countdown和Sudoku等数据集上准确率分别提高了3.6%、2.6%、18.4%、27%。

Conclusion: SPG方法有效提升了扩散大语言模型的强化学习训练效率和任务性能，为大模型优化带来新思路。

Abstract: Diffusion large language models (dLLMs) are emerging as an efficient
alternative to autoregressive models due to their ability to decode multiple
tokens in parallel. However, aligning dLLMs with human preferences or
task-specific rewards via reinforcement learning (RL) is challenging because
their intractable log-likelihood precludes the direct application of standard
policy gradient methods. While prior work uses surrogates like the evidence
lower bound (ELBO), these one-sided approximations can introduce significant
policy gradient bias. To address this, we propose the Sandwiched Policy
Gradient (SPG) that leverages both an upper and a lower bound of the true
log-likelihood. Experiments show that SPG significantly outperforms baselines
based on ELBO or one-step estimation. Specifically, SPG improves the accuracy
over state-of-the-art RL methods for dLLMs by 3.6% in GSM8K, 2.6% in MATH500,
18.4% in Countdown and 27.0% in Sudoku.

</details>


### [195] [Beyond Surface Reasoning: Unveiling the True Long Chain-of-Thought Capacity of Diffusion Large Language Models](https://arxiv.org/abs/2510.09544)
*Qiguang Chen,Hanjing Li,Libo Qin,Dengyun Peng,Jinhao Liu,Jiangyi Wang,Chengyue Wu,Xie Chen,Yantao Du,Wanxiang Che*

Main category: cs.CL

TL;DR: 本论文分析了扩散大语言模型（DLLMs）在顺序推理时面临的并行-顺序矛盾（PSC）问题，并提出了针对PSC的实用缓解方法。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型因其高吞吐量和有效的序列推理能力，成为自回归LLMs的有竞争力的替代方案。然而，并行解码与严格推理所需的因果顺序存在冲突，影响了模型推理的效果。

Method: 本文首先系统分析并界定了并行-顺序矛盾（PSC），通过对简单和复杂推理任务中的行为进行实证分析，研究DLLMs的并行性随任务难度的变化。进一步，论文提出三大扩展维度（并行、扩散、顺序），从经验上考察PSC对性能的制约，最后提出并行式引导、扩散提前终止和并行扩展等缓解方法。

Result: 实验证明，DLLMs仅在直接可判定输出时表现真正的并行性，难度提升时往往退化为自回归行为。自回归引导下推理步数增加而质量未改善，PSC显著限制了DLLMs的反思、推理深度和探索广度。并行扩展能带来持续提升，但扩散和顺序扩展受PSC限制。最后，提出的缓解措施能减轻PSC引发的低效与无效。

Conclusion: PSC是DLLMs在并行推理中面临的核心挑战，显著影响复杂任务推理表现。针对这个挑战，合理设计推理方式及引导策略，有助于提升DLLMs在实际推理任务中的效率与效果。

Abstract: Recently, Diffusion Large Language Models (DLLMs) have offered high
throughput and effective sequential reasoning, making them a competitive
alternative to autoregressive LLMs (ALLMs). However, parallel decoding, which
enables simultaneous token updates, conflicts with the causal order often
required for rigorous reasoning. We first identify this conflict as the core
Parallel-Sequential Contradiction (PSC). Behavioral analyses in both simple and
complex reasoning tasks show that DLLMs exhibit genuine parallelism only for
directly decidable outputs. As task difficulty increases, they revert to
autoregressive-like behavior, a limitation exacerbated by autoregressive
prompting, which nearly doubles the number of decoding steps with remasking
without improving quality. Moreover, PSC restricts DLLMs' self-reflection,
reasoning depth, and exploratory breadth. To further characterize PSC, we
introduce three scaling dimensions for DLLMs: parallel, diffusion, and
sequential. Empirically, while parallel scaling yields consistent improvements,
diffusion and sequential scaling are constrained by PSC. Based on these
findings, we propose several practical mitigations, parallel-oriented
prompting, diffusion early stopping, and parallel scaling, to reduce
PSC-induced ineffectiveness and inefficiencies.

</details>


### [196] [Hierarchical Indexing with Knowledge Enrichment for Multilingual Video Corpus Retrieval](https://arxiv.org/abs/2510.09553)
*Yu Wang,Tianhao Tan,Yifei Wang*

Main category: cs.CL

TL;DR: 提出了一种高效检索多语言医学视频的多阶段系统，通过语义分块、知识图谱增强和层次化树结构，实现了更高效、准确的检索。


<details>
  <summary>Details</summary>
Motivation: 现有多语言医学视频检索方法要么过于粗糙（将长视频压缩成粗略嵌入），要么计算量过大（细粒度匹配成本高），无法高效处理复杂、多跳、跨语言医学问答需求。

Method: 采用多阶段方案：1）将视频字幕按语义分成连贯块；2）每块内容用知识图谱简要增强；3）块按层次树结构组织，并用多语言无关的编码器生成嵌入；4）查询时，用同一编码器处理问题，先用树结构粗筛再精排，最后针对最高分的内容块用小型大语言模型重新打分，兼顾效率和精度。

Result: 在mVCR测试集上取得了SOTA性能。消融实验验证了知识图谱增强、层次化索引及LLM精选重排序的互补作用。

Conclusion: 该方法为专用医学多语言视频集合提供了准确且可扩展的检索解决方案。

Abstract: Retrieving relevant instructional videos from multilingual medical archives
is crucial for answering complex, multi-hop questions across language
boundaries. However, existing systems either compress hour-long videos into
coarse embeddings or incur prohibitive costs for fine-grained matching. We
tackle the Multilingual Video Corpus Retrieval (mVCR) task in the NLPCC-2025
M4IVQA challenge with a multi-stage framework that integrates multilingual
semantics, domain terminology, and efficient long-form processing. Video
subtitles are divided into semantically coherent chunks, enriched with concise
knowledge-graph (KG) facts, and organized into a hierarchical tree whose node
embeddings are generated by a language-agnostic multilingual encoder. At query
time, the same encoder embeds the input question; a coarse-to-fine tree search
prunes irrelevant branches, and only the top-ranked chunks are re-scored by a
lightweight large language model (LLM). This design avoids exhaustive
cross-encoder scoring while preserving chunk-level precision. Experiments on
the mVCR test set demonstrate state-of-the-art performance, and ablation
studies confirm the complementary contributions of KG enrichment, hierarchical
indexing, and targeted LLM re-ranking. The proposed method offers an accurate
and scalable solution for multilingual retrieval in specialized medical video
collections.

</details>


### [197] [A Comprehensive Evaluation of Multilingual Chain-of-Thought Reasoning: Performance, Consistency, and Faithfulness Across Languages](https://arxiv.org/abs/2510.09555)
*Raoyuan Zhao,Yihong Liu,Hinrich Schütze,Michael A. Hedderich*

Main category: cs.CL

TL;DR: 本论文对大型推理模型（LRMs）在多语言环境下的Chain-of-Thought（CoT）推理进行了首次全面研究，评估了表现、一致性和可靠性，并揭示了不同语言下推理过程的差异和模型依赖性。


<details>
  <summary>Details</summary>
Motivation: 尽管多语言环境下模型最终答案的准确性已有所研究，但推理过程中的每一步（思考轨迹）尚未得到深入探讨。理解模型在多语言任务中是如何“思考”的，有助于改进其表现和可靠性。

Method: 作者从三个维度出发：（1）通过指令或提示注入，考察模型在目标语言下的语言遵从性、答案准确率和一致性；（2）采用跨语言交换思考轨迹，评估不同语言下推理过程的一致性；（3）运用截断和错误注入等扰动方法，考察不同语言下思考轨迹的可靠性。

Result: 实验发现：（1）模型对某些语言存在偏好，不同语言间表现差异显著；（2）思考轨迹跨语言交互时，其质量和有效性也取决于提示使用的语言；（3）模型对思考轨迹的依赖程度因语言而异。

Conclusion: 作者提出多语言CoT推理存在语言偏好和一致性问题，并通过实验分析阐明了其影响，为未来改进多语言推理模型及相关研究提供了数据与工具支持。

Abstract: Large reasoning models (LRMs) increasingly rely on step-by-step
Chain-of-Thought (CoT) reasoning to improve task performance, particularly in
high-resource languages such as English. While recent work has examined
final-answer accuracy in multilingual settings, the thinking traces themselves,
i.e., the intermediate steps that lead to the final answer, remain
underexplored. In this paper, we present the first comprehensive study of
multilingual CoT reasoning, evaluating three key dimensions: performance,
consistency, and faithfulness. We begin by measuring language compliance,
answer accuracy, and answer consistency when LRMs are explicitly instructed or
prompt-hacked to think in a target language, revealing strong language
preferences and divergent performance across languages. Next, we assess
crosslingual consistency of thinking traces by interchanging them between
languages. We find that the quality and effectiveness of thinking traces vary
substantially depending on the prompt language. Finally, we adapt
perturbation-based techniques -- i.e., truncation and error injection -- to
probe the faithfulness of thinking traces across languages, showing that models
rely on traces to varying degrees. We release our code and data to support
future research.

</details>


### [198] [WUGNECTIVES: Novel Entity Inferences of Language Models from Discourse Connectives](https://arxiv.org/abs/2510.09556)
*Daniel Brubaker,William Sheffield,Junyi Jessy Li,Kanishka Misra*

Main category: cs.CL

TL;DR: 该论文研究了话语连接词是否能帮助语言模型推理世界知识，并提出了WUGNECTIVES数据集以评估相关能力。


<details>
  <summary>Details</summary>
Motivation: 以往研究强调世界知识对预测话语连接词的作用，但尚未探讨过反过来话语连接词是否有助于语言模型获取或推理世界知识。

Method: 作者提出了WUGNECTIVES数据集，其中包含8880个样本，通过不同的连接词将虚构实体与特定属性关联，并用它评估17种不同规模和训练方案下的语言模型的推断能力。

Result: 将语言模型进行推理行为调优后，在大多数连接词上能获得显著提升；但所有模型在表达让步含义的连接词上表现普遍较差。

Conclusion: 该研究首次系统考察了话语连接词对语言模型推理能力的影响，为后续探索语言线索的功能性与作用提供了新视角，并公开了数据集促进社区研究。

Abstract: The role of world knowledge has been particularly crucial to predict the
discourse connective that marks the discourse relation between two arguments,
with language models (LMs) being generally successful at this task. We flip
this premise in our work, and instead study the inverse problem of
understanding whether discourse connectives can inform LMs about the world. To
this end, we present WUGNECTIVES, a dataset of 8,880 stimuli that evaluates
LMs' inferences about novel entities in contexts where connectives link the
entities to particular attributes. On investigating 17 different LMs at various
scales, and training regimens, we found that tuning an LM to show reasoning
behavior yields noteworthy improvements on most connectives. At the same time,
there was a large variation in LMs' overall performance across connective type,
with all models systematically struggling on connectives that express a
concessive meaning. Our findings pave the way for more nuanced investigations
into the functional role of language cues as captured by LMs. We release
WUGNECTIVES at https://github.com/sheffwb/wugnectives.

</details>


### [199] [AutoPR: Let's Automate Your Academic Promotion!](https://arxiv.org/abs/2510.09558)
*Qiguang Chen,Zheng Yan,Mingda Yang,Libo Qin,Yixin Yuan,Hanjing Li,Jinhao Liu,Yiyan Ji,Dengyun Peng,Jiannan Guan,Mengkang Hu,Yantao Du,Wanxiang Che*

Main category: cs.CL

TL;DR: 本文提出了AutoPR任务和PRAgent系统，实现了科学论文自动生成高质量宣传内容，并通过PRBench基准进行评测，显著提升了传播和互动效果。


<details>
  <summary>Details</summary>
Motivation: 随着学术论文数量激增，学者们越来越依赖社交媒体发现新研究，同时作者为提升论文影响力需要投入大量推广精力。为减轻人工负担并提升宣传效率，亟需自动化的论文推广工具。

Method: 作者提出AutoPR任务，并发布PRBench评测基准，涵盖512篇论文及其高质量推广内容，从准确性、吸引力、内容发布节奏等维度综合评价自动化系统。此外，PRAgent多智能体框架分为内容提取、多模态整理、协作生成和平台定制优化三步，自动生成并适配多平台的推广内容。

Result: PRAgent相比直接的LLM生成，在各项指标上显著提升：总观看时长提升604%，点赞数提升438%，整体互动量提升至少2.9倍。消融实验表明，平台建模与定向推广为主要贡献因素。

Conclusion: AutoPR任务为实现学术传播自动化提供了可操作、可评测的新方向，PRAgent系统和PRBench数据集为未来相关研究和应用提供了基础和路线图，有助于大规模提升学术传播的效率和影响力。

Abstract: As the volume of peer-reviewed research surges, scholars increasingly rely on
social platforms for discovery, while authors invest considerable effort in
promoting their work to ensure visibility and citations. To streamline this
process and reduce the reliance on human effort, we introduce Automatic
Promotion (AutoPR), a novel task that transforms research papers into accurate,
engaging, and timely public content. To enable rigorous evaluation, we release
PRBench, a multimodal benchmark that links 512 peer-reviewed articles to
high-quality promotional posts, assessing systems along three axes: Fidelity
(accuracy and tone), Engagement (audience targeting and appeal), and Alignment
(timing and channel optimization). We also introduce PRAgent, a multi-agent
framework that automates AutoPR in three stages: content extraction with
multimodal preparation, collaborative synthesis for polished outputs, and
platform-specific adaptation to optimize norms, tone, and tagging for maximum
reach. When compared to direct LLM pipelines on PRBench, PRAgent demonstrates
substantial improvements, including a 604% increase in total watch time, a 438%
rise in likes, and at least a 2.9x boost in overall engagement. Ablation
studies show that platform modeling and targeted promotion contribute the most
to these gains. Our results position AutoPR as a tractable, measurable research
problem and provide a roadmap for scalable, impactful automated scholarly
communication.

</details>


### [200] [Mind-Paced Speaking: A Dual-Brain Approach to Real-Time Reasoning in Spoken Language Models](https://arxiv.org/abs/2510.09592)
*Donghang Wu,Haoyang Zhang,Jun Chen,Xiangyu,Zhang,Hexin Liu,Eng Siong Chng,Fei Tian,Xuerui Yang,Xiangyu Zhang,Daxin Jiang,Gang Yu*

Main category: cs.CL

TL;DR: 论文提出了一种新的人脑启发式实时语言模型框架（Mind-Paced Speaking, MPS），实现了高质量实时推理和流畅语音生成，在多个任务上显著优于现有方法，并大幅提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有实时口语生成模型（SLM）受限于链式思维（CoT）推理的高延迟，难以边思考边说话，亟需一种兼顾推理质量和实时性的方案。

Method: 受大脑分区启发，提出了"双脑架构"：由"推理脑"负责高层次推理，控制和指导"表达脑"生成流畅口语，以并行方式消除模式切换带来的延迟损失。

Result: 在数学推理（Spoken-MQA）与对话（URO-Bench）任务上，无延迟配置下分别取得92.8%准确率和82.5分；在推理质量与实时性上均优于现有边说边想方法，接近离线预计算CoT模型。

Conclusion: MPS架构成功实现了人类般的边思考边说话，为高质量、低延迟推理的实时语音交互提供了可行方案。

Abstract: Real-time Spoken Language Models (SLMs) struggle to leverage Chain-of-Thought
(CoT) reasoning due to the prohibitive latency of generating the entire thought
process sequentially. Enabling SLMs to think while speaking, similar to humans,
is attracting increasing attention. We present, for the first time, Mind-Paced
Speaking (MPS), a brain-inspired framework that enables high-fidelity,
real-time reasoning. Similar to how humans utilize distinct brain regions for
thinking and responding, we propose a novel dual-brain approach, employing a
"Formulation Brain" for high-level reasoning to pace and guide a separate
"Articulation Brain" for fluent speech generation. This division of labor
eliminates mode-switching, preserving the integrity of the reasoning process.
Experiments show that MPS significantly outperforms existing
think-while-speaking methods and achieves reasoning performance comparable to
models that pre-compute the full CoT before speaking, while drastically
reducing latency. Under a zero-latency configuration, the proposed method
achieves an accuracy of 92.8% on the mathematical reasoning task Spoken-MQA and
attains a score of 82.5 on the speech conversation task URO-Bench. Our work
effectively bridges the gap between high-quality reasoning and real-time
interaction.

</details>


### [201] [Prompting Test-Time Scaling Is A Strong LLM Reasoning Data Augmentation](https://arxiv.org/abs/2510.09599)
*Sondos Mahmoud Bsharat,Zhiqiang Shen*

Main category: cs.CL

TL;DR: 本文提出了一种名为Prompting Test-Time Scaling (P-TTS)的数据增强推理方法，仅使用少量人工挑选的样本，通过测试时多样化的提示策略提升大型语言模型(LLM)的推理能力。该方法在数学推理等主流测试集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理能力虽强，但训练所需的高质量推理数据集难以大规模获取，数据收集和处理成本高。作者希望找到一种能够用更少人工数据实现推理性能提升的新途径。

Method: 作者提出P-TTS方法，即在推理测试时，针对仅有的90个人工挑选推理实例，通过有系统地增强指令提示的多样性，合成出具有不同推理轨迹的数据，然后在这些数据上对Qwen-2.5等模型不同尺寸进行微调，从而提升推理泛化能力。

Result: 在AIME2024、AIME2025、MATH500和GPQA-Diamond等数据集上，7B和32B参数量的P-TTS模型均大幅提升了准确率，超越了S1和S1.1等1K-shot强基线，部分测试中提升幅度超过30%。此外，P-TTS在多项零样本外域推理基准上同样取得了提升。

Conclusion: P-TTS是一种简单高效、成本低廉的数据增强推理方法，在资源有限或新兴领域尤具实用价值。该方法能够放大LLM的推理能力和泛化性，对未来LLM实际部署具有重要意义。

Abstract: Large language models (LLMs) have demonstrated impressive reasoning
capabilities when provided with chain-of-thought exemplars, but curating large
reasoning datasets remains laborious and resource-intensive. In this work, we
introduce Prompting Test-Time Scaling (P-TTS), a simple yet effective
inference-time data augmentation strategy for enhancing LLM reasoning through
finetuning. Rather than collecting thousands or even millions of examples,
P-TTS leverages a small pool of only 90 manually selected reasoning instances
and systematically varies exemplar augmentation through principled instruction
prompting intensities at test time to synthesize diverse reasoning trajectory
contexts. Then we finetune the various sizes of Qwen-2.5 models on P-TTS data.
Across a suite of mathematical reasoning AIME2024 & 25, MATH500, and
GPQA-Diamond, our P-TTS-7B and 32B models outperform the prior competitive
baselines like S1 and S1.1 (1K-shot), achieving absolute accuracy gains of
+26.66% and +30.00% on AIME'24 (7B), and +13.34% and +6.67% on AIME'25 (7B);
P-TTS-32B yields gains of +23.33% and +16.63% on AIME'24, and +26.63% and
+3.33% on AIME'25 (vs. S1 and S1.1, respectively), with comparable or better
performance on MATH500 and GPQA-Diamond. We further show that P-TTS enhances
zero-shot generalization accuracy on out-of-domain reasoning benchmarks of
Gaokao, Kaoyan, OlympiadBench, AMC23, GradeSchoolMath, and Minerva. Our
analysis suggests that test-time scaling effectively explores the latent space
of reasoning patterns, amplifying LLM problem-solving with minimal annotation
overhead, and further unlocking the reasoning potential and capabilities of
LLMs. Prompting Test-Time Scaling offers a practical, low-cost way to elicit
LLM reasoning in resource-constrained or rapidly evolving domains.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [202] [ConPoSe: LLM-Guided Contact Point Selection for Scalable Cooperative Object Pushing](https://arxiv.org/abs/2510.08705)
*Noah Steinkrüger,Nisarga Nilavadi,Wolfram Burgard,Tanja Katharina Kaiser*

Main category: cs.RO

TL;DR: 本论文提出了一种结合大语言模型（LLM）与局部搜索的方法，用于多机器人协作推运中的接触点选择，在不同物体形状和规模下展现了优越的可扩展性和性能。


<details>
  <summary>Details</summary>
Motivation: 多机器人协作搬运（例如推运大物体）在复杂环境下广泛应用，但如何为机器人选择合适的物体接触点以实现合作，是一个组合爆炸问题，传统解析法对规模和复杂度支持有限，需要新的高效方法。

Method: 作者提出了名为ConPoSe的方法，结合大语言模型的推理能力和本地搜索技术，智能地为机器人团队选择合适的物体接触点，适用于不同形状的物体（如长方体、圆柱体、T形物体）。

Result: 该方法能在各种形状和尺寸的物体上为机器人团队有效选择接触点，不仅可扩展到更多机器人和更大物体，还优于纯LLM选择和传统解析方法。

Conclusion: LLM与局部搜索结合的方法在多机器人协作运输中的接触点选取上展现很好的扩展性及性能，表明智能推理辅助的自动化决策为该类问题提供了新思路。

Abstract: Object transportation in cluttered environments is a fundamental task in
various domains, including domestic service and warehouse logistics. In
cooperative object transport, multiple robots must coordinate to move objects
that are too large for a single robot. One transport strategy is pushing, which
only requires simple robots. However, careful selection of robot-object contact
points is necessary to push the object along a preplanned path. Although this
selection can be solved analytically, the solution space grows combinatorially
with the number of robots and object size, limiting scalability. Inspired by
how humans rely on common-sense reasoning for cooperative transport, we propose
combining the reasoning capabilities of Large Language Models with local search
to select suitable contact points. Our LLM-guided local search method for
contact point selection, ConPoSe, successfully selects contact points for a
variety of shapes, including cuboids, cylinders, and T-shapes. We demonstrate
that ConPoSe scales better with the number of robots and object size than the
analytical approach, and also outperforms pure LLM-based selection.

</details>


### [203] [Point and Go: Intuitive Reference Frame Reallocation in Mode Switching for Assistive Robotics](https://arxiv.org/abs/2510.08753)
*A. Wang,C. Jiang,M. Przystupa,J. Valentine,M. Jagersand*

Main category: cs.RO

TL;DR: 本文提出了一种更为直观的“Point and Go”模式切换方法，用于改善轮椅安装机器人操作困难的问题。实验表明该方法有效降低了任务完成时间、操作暂停和模式切换次数，并获得了用户积极评价。


<details>
  <summary>Details</summary>
Motivation: 传统的笛卡尔空间模式切换方法存在使用不直观、参考系复杂、运动受限等问题，导致轮椅机器人操控效率低下、用户体验差。因此，研究者希望开发一种更人性化、高效的新方法。

Method: 作者提出了“Point and Go”模式切换，将控制参考系转化为以末端执行器指向为主的直观动作空间，用户通过创新的挥扫手势指向，实现沿机器人底座水平面的平移；转动控制则结合了精细化的末端执行器定向框架，实现更准确且一致的旋转。方法在初步实验和三项任务用户研究中与传统笛卡尔切换方法及最新学习法对比验证。

Result: 与对比方法相比，Point and Go模式实现任务平均完成时间降低31%、操作暂停减少41%、模式切换次数减少33%，并在用户问卷中获得显著更高的好评。

Conclusion: Point and Go模式切换更高效直观，显著提升了高自由度轮椅机器人手臂的操作性能和用户体验，有望被更广泛应用于实际辅助机器人系统。

Abstract: Operating high degree of freedom robots can be difficult for users of
wheelchair mounted robotic manipulators. Mode switching in Cartesian space has
several drawbacks such as unintuitive control reference frames, separate
translation and orientation control, and limited movement capabilities that
hinder performance. We propose Point and Go mode switching, which reallocates
the Cartesian mode switching reference frames into a more intuitive action
space comprised of new translation and rotation modes. We use a novel sweeping
motion to point the gripper, which defines the new translation axis along the
robot base frame's horizontal plane. This creates an intuitive `point and go'
translation mode that allows the user to easily perform complex, human-like
movements without switching control modes. The system's rotation mode combines
position control with a refined end-effector oriented frame that provides
precise and consistent robot actions in various end-effector poses. We verified
its effectiveness through initial experiments, followed by a three-task user
study that compared our method to Cartesian mode switching and a state of the
art learning method. Results show that Point and Go mode switching reduced
completion times by 31\%, pauses by 41\%, and mode switches by 33\%, while
receiving significantly favorable responses in user surveys.

</details>


### [204] [Whole Body Model Predictive Control for Spin-Aware Quadrupedal Table Tennis](https://arxiv.org/abs/2510.08754)
*David Nguyen,Zulfiqar Zaidi,Kevin Karol,Jessica Hodgins,Zhaoming Xie*

Main category: cs.RO

TL;DR: 本文提出了一种面向四足机器人（如Spot）的高动态乒乓球系统，实现了高速感知、轨迹预测与灵活全身控制，能自动适应各种回球策略，并能与人类玩家进行互动。


<details>
  <summary>Details</summary>
Motivation: 现有的四足机器人在乒乓球等高动态任务中，难以达到人的速度、精度和对复杂球旋的反应能力。实现这些能力是机器人灵活性和泛化能力的重要挑战。

Method: 1. 使用外部高速摄像头实现乒乓球位置感知；2. 结合物理模型与数据学习的残差预测旋转和轨迹；3. 基于模型预测控制（MPC），设计新颖的全身动态控制方法，实现对击球动作的实时优化。通过上述系统各模块，实现机器人与人类的实时互动及自动化回球策略生成。

Result: 系统在真实世界对Spot四足机器人进行了实测。各系统组件的准确度被逐项评估，机器人能够根据不同旋转类型自动协调动作，实现精确回球并与人类玩家击球回合。

Conclusion: 该系统首次展现了四足机器人在高动态、复杂场景下的乒乓球能力，包括灵活的回球策略和面对不同旋转的自适应性，为四足机器人泛化能力和运动控制提供了新思路。

Abstract: Developing table tennis robots that mirror human speed, accuracy, and ability
to predict and respond to the full range of ball spins remains a significant
challenge for legged robots. To demonstrate these capabilities we present a
system to play dynamic table tennis for quadrupedal robots that integrates high
speed perception, trajectory prediction, and agile control. Our system uses
external cameras for high-speed ball localization, physical models with learned
residuals to infer spin and predict trajectories, and a novel model predictive
control (MPC) formulation for agile full-body control. Notably, a continuous
set of stroke strategies emerge automatically from different ball return
objectives using this control paradigm. We demonstrate our system in the real
world on a Spot quadruped, evaluate accuracy of each system component, and
exhibit coordination through the system's ability to aim and return balls with
varying spin types. As a further demonstration, the system is able to rally
with human players.

</details>


### [205] [Geometry-aware Policy Imitation](https://arxiv.org/abs/2510.08787)
*Yiming Li,Nael Darwiche,Amirreza Razmjoo,Sichao Liu,Yilun Du,Auke Ijspeert,Sylvain Calinon*

Main category: cs.RO

TL;DR: 本文提出了一种几何感知的策略模仿（GPI）方法，将专家演示轨迹视为几何曲线，通过距离场形成可控向量场，直接指导机器人模仿学习。GPI 实现高成功率、速度快、内存占用低且鲁棒性强。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法大多将演示视为离散的状态-动作采样，忽视了轨迹的连续几何特性，导致泛化性和效率受限。作者希望通过几何化方法提升模仿学习效果和效率。

Method: GPI 将专家演示轨迹作为几何曲线处理，计算距离场，进而导出两种控制流：一是沿专家轨迹前进的推进流，二是修正偏离的吸引流。两流组合构成非参数向量场，直接引导机器人行为，并天然支持多模态与新演示的高效组合。

Result: GPI 方法在仿真和真实机器人上的多种任务中，取得比基于扩散的策略更高的成功率，运行速度快20倍，且内存消耗更低，表现出较强的鲁棒性。

Conclusion: GPI 是一种高效、可解释且可扩展的模仿学习新方法，相较于生成式方法具备显著优势，适用于机器人模仿学习场景。

Abstract: We propose a Geometry-aware Policy Imitation (GPI) approach that rethinks
imitation learning by treating demonstrations as geometric curves rather than
collections of state-action samples. From these curves, GPI derives distance
fields that give rise to two complementary control primitives: a progression
flow that advances along expert trajectories and an attraction flow that
corrects deviations. Their combination defines a controllable, non-parametric
vector field that directly guides robot behavior. This formulation decouples
metric learning from policy synthesis, enabling modular adaptation across
low-dimensional robot states and high-dimensional perceptual inputs. GPI
naturally supports multimodality by preserving distinct demonstrations as
separate models and allows efficient composition of new demonstrations through
simple additions to the distance field. We evaluate GPI in simulation and on
real robots across diverse tasks. Experiments show that GPI achieves higher
success rates than diffusion-based policies while running 20 times faster,
requiring less memory, and remaining robust to perturbations. These results
establish GPI as an efficient, interpretable, and scalable alternative to
generative approaches for robotic imitation learning. Project website:
https://yimingli1998.github.io/projects/GPI/

</details>


### [206] [Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation](https://arxiv.org/abs/2510.08807)
*Zhenyu Zhao,Hongyi Jing,Xiawei Liu,Jiageng Mao,Abha Jha,Hanwen Yang,Rong Xue,Sergey Zakharor,Vitor Guizilini,Yue Wang*

Main category: cs.RO

TL;DR: 本文提出了一个大规模、多样化的类人机器人操控数据集Humanoid Everyday，并配套发布了基于云的评测平台，以支持通用类人机器人操控研究。


<details>
  <summary>Details</summary>
Motivation: 当前机器人学习的数据集多集中在固定机械臂，缺乏涵盖类人机器人运动、操控和人机交互的高质量、多样化数据，也缺少标准的评测平台。这限制了类人机器人通用技能与现实应用的进一步发展。

Method: 作者基于高效的人类监督远程操作管道，采集了包含RGB、深度、激光雷达、触觉等多模态感知的优质数据，并辅以自然语言注释。数据集覆盖260个任务、7大类场景，包含超3百万帧和1万条以上轨迹。同时，分析并评测了代表性策略学习方法，并开发了云端评测平台，为研究社区提供标准化环境。

Result: Humanoid Everyday数据集丰富多样，支持不同任务类别的研究。实验对现有策略学习方法的能力与局限进行了系统分析，云平台为评估模型性能提供了标准流程。

Conclusion: 该工作填补了类人机器人操控领域高质量数据和评测平台的空白，为后续全能化类人机器人及其现实交互应用奠定了基础。项目全部内容公开开放，有助于推动该领域整体进步。

Abstract: From loco-motion to dextrous manipulation, humanoid robots have made
remarkable strides in demonstrating complex full-body capabilities. However,
the majority of current robot learning datasets and benchmarks mainly focus on
stationary robot arms, and the few existing humanoid datasets are either
confined to fixed environments or limited in task diversity, often lacking
human-humanoid interaction and lower-body locomotion. Moreover, there are a few
standardized evaluation platforms for benchmarking learning-based policies on
humanoid data. In this work, we present Humanoid Everyday, a large-scale and
diverse humanoid manipulation dataset characterized by extensive task variety
involving dextrous object manipulation, human-humanoid interaction,
locomotion-integrated actions, and more. Leveraging a highly efficient
human-supervised teleoperation pipeline, Humanoid Everyday aggregates
high-quality multimodal sensory data, including RGB, depth, LiDAR, and tactile
inputs, together with natural language annotations, comprising 10.3k
trajectories and over 3 million frames of data across 260 tasks across 7 broad
categories. In addition, we conduct an analysis of representative policy
learning methods on our dataset, providing insights into their strengths and
limitations across different task categories. For standardized evaluation, we
introduce a cloud-based evaluation platform that allows researchers to
seamlessly deploy their policies in our controlled setting and receive
performance feedback. By releasing Humanoid Everyday along with our policy
learning analysis and a standardized cloud-based evaluation platform, we intend
to advance research in general-purpose humanoid manipulation and lay the
groundwork for more capable and embodied robotic agents in real-world
scenarios. Our dataset, data collection code, and cloud evaluation website are
made publicly available on our project website.

</details>


### [207] [Adaptive Motion Planning via Contact-Based Intent Inference for Human-Robot Collaboration](https://arxiv.org/abs/2510.08811)
*Jiurun Song,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: 论文提出了一种基于物理接触推断人类意图并实现自适应运动规划的新框架，有效提升了人机协作中的安全性与效率。


<details>
  <summary>Details</summary>
Motivation: 当前人机协同需机器人理解人类意图以安全、高效地共同作业。虽然大语言模型可推断高层意图，但在运动规划中应用受限。而传统物理互动依赖持续动力引导，增加人类操作负担。解决如何实时、便捷地推断人意图并修正协作机器人的运动，是本研究的核心动机。

Method: 作者提出了一种基于优化的力估算方法，仅通过机器人关节扭矩与动力学模型即可推断人体接触力的大小和位置，无需复杂外部传感器，提升了部署灵活性。为了缩小搜索空间和提升实时性，方法中引入了基于扭矩的分节接触检测机制。最后，结合上述手段，开发了一个接触感知的自适应运动规划器，实现碰触引导下的机器人在线运动修正。

Result: 在7自由度机械臂上的实验显示：方法能够准确估算接触力，有效推断人类意图，并在感知存在不确定性的情况下，完成平滑的运动纠正与适应，提高了HRC准确性和互动效率。

Conclusion: 论文提出的接触感知-自适应运动规划框架，为人机协作中高效、安全的实时运动修正提供了新思路，降低了系统复杂度，并在实际实验中取得良好效果，具有广阔应用前景。

Abstract: Human-robot collaboration (HRC) requires robots to adapt their motions to
human intent to ensure safe and efficient cooperation in shared spaces.
Although large language models (LLMs) provide high-level reasoning for
inferring human intent, their application to reliable motion planning in HRC
remains challenging. Physical human-robot interaction (pHRI) is intuitive but
often relies on continuous kinesthetic guidance, which imposes burdens on
operators. To address these challenges, a contact-informed adaptive
motion-planning framework is introduced to infer human intent directly from
physical contact and employ the inferred intent for online motion correction in
HRC. First, an optimization-based force estimation method is proposed to infer
human-intended contact forces and locations from joint torque measurements and
a robot dynamics model, thereby reducing cost and installation complexity while
enabling whole-body sensitivity. Then, a torque-based contact detection
mechanism with link-level localization is introduced to reduce the optimization
search space and to enable real-time estimation. Subsequently, a
contact-informed adaptive motion planner is developed to infer human intent
from contacts and to replan robot motion online, while maintaining smoothness
and adapting to human corrections. Finally, experiments on a 7-DOF manipulator
are conducted to demonstrate the accuracy of the proposed force estimation
method and the effectiveness of the contact-informed adaptive motion planner
under perception uncertainty in HRC.

</details>


### [208] [Adaptive Science Operations in Deep Space Missions Using Offline Belief State Planning](https://arxiv.org/abs/2510.08812)
*Grace Ra Kim,Hailey Warner,Duncan Eddy,Evan Astle,Zachary Booth,Edward Balaban,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 本文提出了一种使用POMDP和贝叶斯网络相结合的方法，实现深空任务中飞行器科学仪器的智能调度，显著降低了样本识别错误率。


<details>
  <summary>Details</summary>
Motivation: 深空探测任务因为远距离通信延迟和外部环境不确定，无法实现地面实时操作。为解决通信受限下的自主科学探索，需要高效、可靠的仪器操作决策方案。

Method: 本研究将贝叶斯网络嵌入POMDP的观测空间，用以管理典型深空任务中复杂且不确定的科学测量数据。仪器操作策略在地面离线计算生成，结合贝叶斯网络结构和奖励函数调整，提升了决策系统的资源感知和结果可解释性。以Enceladus Orbilander的生命探测仪器集为案例，和传统任务操作流程进行了对比分析。

Result: 与任务基线操作流程相比，所提出方法在样本识别错误率降低了近40%，并在非正常样品积累场景下表现更优。

Conclusion: 结合贝叶斯网络和POMDP的自主决策框架能够支持深空飞行器在通信受限环境下实现更智能和高效的科学仪器调度，可有效提升探测任务的可靠性和科学产出。

Abstract: Deep space missions face extreme communication delays and environmental
uncertainty that prevent real-time ground operations. To support autonomous
science operations in communication-constrained environments, we present a
partially observable Markov decision process (POMDP) framework that adaptively
sequences spacecraft science instruments. We integrate a Bayesian network into
the POMDP observation space to manage the high-dimensional and uncertain
measurements typical of astrobiology missions. This network compactly encodes
dependencies among measurements and improves the interpretability and
computational tractability of science data. Instrument operation policies are
computed offline, allowing resource-aware plans to be generated and thoroughly
validated prior to launch. We use the Enceladus Orbilander's proposed Life
Detection Suite (LDS) as a case study, demonstrating how Bayesian network
structure and reward shaping influence system performance. We compare our
method against the mission's baseline Concept of Operations (ConOps),
evaluating both misclassification rates and performance in off-nominal sample
accumulation scenarios. Our approach reduces sample identification errors by
nearly 40%

</details>


### [209] [CDE: Concept-Driven Exploration for Reinforcement Learning](https://arxiv.org/abs/2510.08851)
*Le Mao,Andrew H. Liu,Renos Zabounidis,Zachary Kingston,Joseph Campbell*

Main category: cs.RO

TL;DR: 提出了一种概念驱动探索方法（CDE），通过文本描述结合视觉-语言模型，引导视觉强化学习有效探索，实现了高效且稳健的任务完成，并展示了真实场景迁移能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉强化学习难以高效探索，因为需要从像素级别的信息中提取与任务相关的结构，且探索过程低效。因此需要新方法提升视觉任务的探索效率。

Method: CDE利用预训练的视觉-语言模型（VLM）从文本任务描述中生成基于对象的视觉概念。这些概念作为弱监督信号，并非直接使用，而是通过辅助目标引导策略网络去重构这些概念，将重构准确率作为内在奖励，引导策略关注与任务相关的对象，从而提升探索效率。VLM只在训练阶段使用，部署时无需求，减少了对外部模型的依赖。

Result: CDE在五个具有挑战性的模拟视觉操作任务中实现了高效、针对性的探索，并对VLM预测中的噪声具有鲁棒性。

Conclusion: CDE方法能有效提升视觉强化学习的探索效率，在现实机器人任务中也有良好迁移能力，证明了其实用性。

Abstract: Intelligent exploration remains a critical challenge in reinforcement
learning (RL), especially in visual control tasks. Unlike low-dimensional
state-based RL, visual RL must extract task-relevant structure from raw pixels,
making exploration inefficient. We propose Concept-Driven Exploration (CDE),
which leverages a pre-trained vision-language model (VLM) to generate
object-centric visual concepts from textual task descriptions as weak,
potentially noisy supervisory signals. Rather than directly conditioning on
these noisy signals, CDE trains a policy to reconstruct the concepts via an
auxiliary objective, using reconstruction accuracy as an intrinsic reward to
guide exploration toward task-relevant objects. Because the policy internalizes
these concepts, VLM queries are only needed during training, reducing
dependence on external models during deployment. Across five challenging
simulated visual manipulation tasks, CDE achieves efficient, targeted
exploration and remains robust to noisy VLM predictions. Finally, we
demonstrate real-world transfer by deploying CDE on a Franka Research 3 arm,
attaining an 80\% success rate in a real-world manipulation task.

</details>


### [210] [Online IMU-odometer Calibration using GNSS Measurements for Autonomous Ground Vehicle Localization](https://arxiv.org/abs/2510.08880)
*Baoshan Song,Xiao Xia,Penggao Yan,Yihan Zhong,Weisong Wen,Li-Ta Hsu*

Main category: cs.RO

TL;DR: 该文提出了一种用于自动驾驶地面车辆定位的在线精确标定方法，能有效融合IMU、里程计与原始GNSS数据，在标定与定位精度上优于现有方法，并发布了首个公开相关测量数据集。


<details>
  <summary>Details</summary>
Motivation: 现有GNSS辅助标定方法未充分解决参数可观性等问题，且未利用模糊度固定处理，影响了标定与定位精度。因此，需要一种更严密、精确的融合与标定方法。

Method: 提出基于可拓展因子图优化（FGO）框架的紧耦合在线标定方法，融合IMU、里程计和原始GNSS测量数据，内置异常值剔除和模糊度固定机制，并进行了可观性分析。

Result: 仿真和实车实验显示，所提方法在标定和定位上均优于先进的松耦合方法。利用新标定参数，IMU-里程计定位最大绝对误差为17.75米，比松耦合方法（61.51米）提升71.14%。

Conclusion: 所提方法显著提升了标定与定位精度，并推动了相关研究，其发布的首个IMU+2D里程计+GNSS原始测量数据集为后续研究提供了宝贵资源。

Abstract: Accurate calibration of intrinsic (odometer scaling factors) and extrinsic
parameters (IMU-odometer translation and rotation) is essential for autonomous
ground vehicle localization. Existing GNSS-aided approaches often rely on
positioning results or raw measurements without ambiguity resolution, and their
observability properties remain underexplored. This paper proposes a tightly
coupled online calibration method that fuses IMU, odometer, and raw GNSS
measurements (pseudo-range, carrier-phase, and Doppler) within an extendable
factor graph optimization (FGO) framework, incorporating outlier mitigation and
ambiguity resolution. Observability analysis reveals that two horizontal
translation and three rotation parameters are observable under general motion,
while vertical translation remains unobservable. Simulation and real-world
experiments demonstrate superior calibration and localization performance over
state-of-the-art loosely coupled methods. Specifically, the IMU-odometer
positioning using our calibrated parameters achieves the absolute maximum error
of 17.75 m while the one of LC method is 61.51 m, achieving up to 71.14 percent
improvement. To foster further research, we also release the first open-source
dataset that combines IMU, 2D odometer, and raw GNSS measurements from both
rover and base stations.

</details>


### [211] [Model-Based Lookahead Reinforcement Learning for in-hand manipulation](https://arxiv.org/abs/2510.08884)
*Alexandre Lopes,Catarina Barata,Plinio Moreno*

Main category: cs.RO

TL;DR: 本文提出并验证了一种将混合强化学习框架应用于机器手内操作任务的方法，这种方法能提升操作表现，尤其在面对不同对象属性时具有一定泛化能力，但计算代价增加。


<details>
  <summary>Details</summary>
Motivation: 机器手内操作任务由于涉及复杂动力学与精准控制，一直是机器人领域的难点。现有方法在通用性和效率上仍有局限，因此亟需探索新的控制策略以提升操作效果和泛化能力。

Method: 采用一种结合Model-Free和Model-Based强化学习优点的混合RL框架——通过引入动态模型和价值函数引导已训练策略，借鉴模型预测控制（MPC）进行轨迹评估。在仿真环境下，用全驱与欠驱机器人手，操控不同类型与属性物体，测试框架在各种情境下的表现。

Result: 该混合框架在大多数测试情况下，尤其是在物体密度与大小变化时，都比单纯RL策略表现更好。泛化测试显示方法对未见过的物体属性具有更强适应性，但以显著增加运算量为代价。

Conclusion: 混合强化学习框架能有效提升在内操作任务的表现与泛化能力，特别适合于属性变化频繁的场景，但需要权衡更高的计算资源消耗。

Abstract: In-Hand Manipulation, as many other dexterous tasks, remains a difficult
challenge in robotics by combining complex dynamic systems with the capability
to control and manoeuvre various objects using its actuators. This work
presents the application of a previously developed hybrid Reinforcement
Learning (RL) Framework to In-Hand Manipulation task, verifying that it is
capable of improving the performance of the task. The model combines concepts
of both Model-Free and Model-Based Reinforcement Learning, by guiding a trained
policy with the help of a dynamic model and value-function through trajectory
evaluation, as done in Model Predictive Control. This work evaluates the
performance of the model by comparing it with the policy that will be guided.
To fully explore this, various tests are performed using both fully-actuated
and under-actuated simulated robotic hands to manipulate different objects for
a given task. The performance of the model will also be tested for
generalization tests, by changing the properties of the objects in which both
the policy and dynamic model were trained, such as density and size, and
additionally by guiding a trained policy in a certain object to perform the
same task in a different one. The results of this work show that, given a
policy with high average reward and an accurate dynamic model, the hybrid
framework improves the performance of in-hand manipulation tasks for most test
cases, even when the object properties are changed. However, this improvement
comes at the expense of increasing the computational cost, due to the
complexity of trajectory evaluation.

</details>


### [212] [Direct Data-Driven Predictive Control for a Three-dimensional Cable-Driven Soft Robotic Arm](https://arxiv.org/abs/2510.08953)
*Cheng Ouyang,Moeen Ul Islam,Dong Chen,Kaixiang Zhang,Zhaojian Li,Xiaobo Tan*

Main category: cs.RO

TL;DR: 本文将无需建模、基于数据的数据驱动预测控制（DeePC）方法首次应用于三维软体机器人，实验表明其比传统模型控制器表现更佳。


<details>
  <summary>Details</summary>
Motivation: 软体机器人由于本身动态复杂和高度非线性，难以实现精确和动态控制。现有数据驱动预测控制方法DeePC在其他领域有效，但其在三维软体机器人上的应用研究很少，因此需要探索其是否适用于此类系统。

Method: 设计并制造了一种带有厚管骨架和大腔体硅胶体的三维软体机械臂平台，利用SVD降维技巧，将DeePC引入软体机械臂的定点调节和三维轨迹跟踪两大典型任务中，并与传统基于模型的控制器进行对比实验。

Result: 实验表明，在两项典型控制任务中，DeePC框架在准确性、鲁棒性和适应性方面均优于模型基控制方法。

Conclusion: DeePC对三维软体机器人的动态控制具有显著优势，可作为软体机器人控制的实用方案，具备推广前景。

Abstract: Soft robots offer significant advantages in safety and adaptability, yet
achieving precise and dynamic control remains a major challenge due to their
inherently complex and nonlinear dynamics. Recently, Data-enabled Predictive
Control (DeePC) has emerged as a promising model-free approach that bypasses
explicit system identification by directly leveraging input-output data. While
DeePC has shown success in other domains, its application to soft robots
remains underexplored, particularly for three-dimensional (3D) soft robotic
systems. This paper addresses this gap by developing and experimentally
validating an effective DeePC framework on a 3D, cable-driven soft arm.
Specifically, we design and fabricate a soft robotic arm with a thick tubing
backbone for stability, a dense silicone body with large cavities for strength
and flexibility, and rigid endcaps for secure termination. Using this platform,
we implement DeePC with singular value decomposition (SVD)-based dimension
reduction for two key control tasks: fixed-point regulation and trajectory
tracking in 3D space. Comparative experiments with a baseline model-based
controller demonstrate DeePC's superior accuracy, robustness, and adaptability,
highlighting its potential as a practical solution for dynamic control of soft
robots.

</details>


### [213] [A geometrical approach to solve the proximity of a point to an axisymmetric quadric in space](https://arxiv.org/abs/2510.08973)
*Bibekananda Patra,Aditya Mahesh Kolte,Sandipan Bandyopadhyay*

Main category: cs.RO

TL;DR: 本文提出了一种将一般二次曲面分类为轴对称二次曲面的方法，并解决了给定点到轴对称二次曲面最近距离的问题。其方法可高效地实现并优于商业库。


<details>
  <summary>Details</summary>
Motivation: 在计算机图形、几何建模等领域，快速准确地计算点到二次曲面（尤其是轴对称二次曲面）的距离具有重要意义。然而，现有文献中很少涉及将三维二次曲面相关问题简化为二维的问题。

Method: 作者提出通过几何特性（如子法线、半长轴、离心率、斜率和半径）将三维点到二次曲面的距离问题降维到二维，并针对抛物线与椭圆/双曲线进一步细分为不同子情况，依据点的位置采用不同处理方式。该方法尤其适合在C等通用编程语言中实现。

Result: 所提方法不仅结构新颖，而且计算速度明显快于当前主流的商业库，如Bullet，在实际测试中表现良好。

Conclusion: 该论文提出的分类与降维思想以及基于几何性质的计算方法具备理论创新和实际应用价值，为点到二次曲面距离问题提供了高效而可靠的解决方案。

Abstract: This paper presents the classification of a general quadric into an
axisymmetric quadric (AQ) and the solution to the problem of the proximity of a
given point to an AQ. The problem of proximity in $R^3$ is reduced to the same
in $R^2$, which is not found in the literature. A new method to solve the
problem in $R^2$ is used based on the geometrical properties of the conics,
such as sub-normal, length of the semi-major axis, eccentricity, slope and
radius. Furthermore, the problem in $R^2$ is categorised into two and three
more sub-cases for parabola and ellipse/hyperbola, respectively, depending on
the location of the point, which is a novel approach as per the authors'
knowledge. The proposed method is suitable for implementation in a common
programming language, such as C and proved to be faster than a commercial
library, namely, Bullet.

</details>


### [214] [Trust Modeling and Estimation in Human-Autonomy Interactions](https://arxiv.org/abs/2510.09013)
*Daniel A. Williams,Airlie Chapman,Daniel R. Little,Chris Manzie*

Main category: cs.RO

TL;DR: 本文提出了一种考虑非对称响应和断续通讯的监督者信任动态模型，并通过用户实验验证。


<details>
  <summary>Details</summary>
Motivation: 虽然自主系统应用广泛，但其在人机协作中的表现很大程度上取决于人类监督者对系统的信任。然而，现有文献缺乏能够同时考虑信任对系统表现的非对称响应和监督-自主系统间间断通信的信任动态模型。

Method: 作者提出了一种切换线性系统结构的估计模型，通过事件触发的方式对输入和输出进行抽样，来模拟监督者信任的动态变化。随后，在51位参与者的用户实验中收集了信任响应数据，并利用这些数据确定模型参数。

Result: 通过用户实验获得的信任数据，成功识别出基于切换线性模型的监督者信任观察器参数，验证了模型能够有效反映监督者在实际互动中的信任动态。

Conclusion: 该研究提出的信任动态模型能够更真实地刻画监督者对自主系统的信任演变，有助于未来自主系统在实际人机协作中的应用。

Abstract: Advances in the control of autonomous systems have accompanied an expansion
in the potential applications for autonomous robotic systems. The success of
applications involving humans depends on the quality of interaction between the
autonomous system and the human supervisor, which is particularly affected by
the degree of trust that the supervisor places in the autonomous system. Absent
from the literature are models of supervisor trust dynamics that can
accommodate asymmetric responses to autonomous system performance and the
intermittent nature of supervisor-autonomous system communication. This paper
focuses on formulating an estimated model of supervisor trust that incorporates
both of these features by employing a switched linear system structure with
event-triggered sampling of the model input and output. Trust response data
collected in a user study with 51 participants were then used identify
parameters for a switched linear model-based observer of supervisor trust.

</details>


### [215] [iMoWM: Taming Interactive Multi-Modal World Model for Robotic Manipulation](https://arxiv.org/abs/2510.09036)
*Chuanrui Zhang,Zhengxian Wu,Guanxing Lu,Yansong Tang,Ziwei Wang*

Main category: cs.RO

TL;DR: 本文提出了一种新的多模态交互世界模型（iMoWM），能高效生成包含颜色、深度和机械臂掩码的预测，适用于机器人操作。


<details>
  <summary>Details</summary>
Motivation: 现有基于2D视频的世界模型难以处理三维空间中的几何和物理结构，对于机器人操作有局限性，需要能更好理解3D世界的模型。

Method: 作者提出iMoWM，结合新颖的MMTokenizer，将多模态输入（如图像、深度、机械臂mask）压缩为紧凑的token，经验证能更高效地处理三维信息，并利用了预训练的大规模VideoGPT模型。预测方式为自回归，输出未来多模态观测。

Result: 大量实验表明，iMoWM在视觉预测质量、模型强化学习(MBRL)仿真和真实机器人模仿学习任务上均优于现有方法，验证了模型的优越性和通用性。

Conclusion: 多模态世界模型能显著提升机器人对环境的理解和预测能力。iMoWM为机器人操作领域提供了一种高效、信息丰富的预测模拟平台，有利于推进模型驱动的决策与控制。

Abstract: Learned world models hold significant potential for robotic manipulation, as
they can serve as simulator for real-world interactions. While extensive
progress has been made in 2D video-based world models, these approaches often
lack geometric and spatial reasoning, which is essential for capturing the
physical structure of the 3D world. To address this limitation, we introduce
iMoWM, a novel interactive world model designed to generate color images, depth
maps, and robot arm masks in an autoregressive manner conditioned on actions.
To overcome the high computational cost associated with three-dimensional
information, we propose MMTokenizer, which unifies multi-modal inputs into a
compact token representation. This design enables iMoWM to leverage large-scale
pretrained VideoGPT models while maintaining high efficiency and incorporating
richer physical information. With its multi-modal representation, iMoWM not
only improves the visual quality of future predictions but also serves as an
effective simulator for model-based reinforcement learning (MBRL) and
facilitates real-world imitation learning. Extensive experiments demonstrate
the superiority of iMoWM across these tasks, showcasing the advantages of
multi-modal world modeling for robotic manipulation. Homepage:
https://xingyoujun.github.io/imowm/

</details>


### [216] [Training Models to Detect Successive Robot Errors from Human Reactions](https://arxiv.org/abs/2510.09080)
*Shannon Liu,Maria Teresa Parreira,Wendy Ju*

Main category: cs.RO

TL;DR: 本论文提出通过机器学习分析人类在机器人反复出错时的反应，以检测和分类机器人失败阶段。


<details>
  <summary>Details</summary>
Motivation: 随着机器人逐渐融入社会，人机交互对检测机器人错误提出更高需求。尽管已有研究表明人类反应能够指示机器人失败，但鲜有文献探究人类反应随连续错误演进的过程。了解这一过程有助于提升错误检测能力。

Method: 作者设计了一项实验，让26位参与者与犯有重复对话错误的机器人互动，利用视频数据提取行为特征，并为个体用户训练机器学习模型以识别和分类不同阶段的机器人失败。

Result: 最佳机器学习模型在检测错误方面准确率达93.5%，在分类连续失败阶段上准确率为84.1%。

Conclusion: 建模人类反应的演变能有效提升机器人错误检测能力，有助于深入理解人机交互中反复故障的本质。

Abstract: As robots become more integrated into society, detecting robot errors is
essential for effective human-robot interaction (HRI). When a robot fails
repeatedly, how can it know when to change its behavior? Humans naturally
respond to robot errors through verbal and nonverbal cues that intensify over
successive failures-from confusion and subtle speech changes to visible
frustration and impatience. While prior work shows that human reactions can
indicate robot failures, few studies examine how these evolving responses
reveal successive failures. This research uses machine learning to recognize
stages of robot failure from human reactions. In a study with 26 participants
interacting with a robot that made repeated conversational errors, behavioral
features were extracted from video data to train models for individual users.
The best model achieved 93.5% accuracy for detecting errors and 84.1% for
classifying successive failures. Modeling the progression of human reactions
enhances error detection and understanding of repeated interaction breakdowns
in HRI.

</details>


### [217] [Robust Visual Teach-and-Repeat Navigation with Flexible Topo-metric Graph Map Representation](https://arxiv.org/abs/2510.09089)
*Jikai Wang,Yunqi Cheng,Kezhi Wang,Zonghai Chen*

Main category: cs.RO

TL;DR: 该论文提出了一种视觉引导的教-复现导航系统，通过对关键帧拓扑图管理、局部地图匹配以及无图局部导航模块，提升了移动机器人在未知环境中的重复导航鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉教-复现导航方法在环境变化和动态障碍物情况下，路径复现鲁棒性不足，亟需提升系统对复杂环境的适应能力。

Method: 系统由三部分组成：1）使用关键帧构建拓扑-度量图用于柔性地图表示，节点可扩展保存新观测数据，减轻全局一致性建图压力；2）通过关键帧聚类形成局部地图，采用视觉帧到局部地图的匹配，提高地点识别，避免单帧匹配的脆弱性；3）提出持久目标管理和无图的轨迹优化算法，实现即使环境遮挡或变化下也能追踪目标。

Result: 在自有移动平台上进行大量实验，结果显示所提系统在鲁棒性和有效性方面都优于现有方法。

Conclusion: 该系统在复杂和动态环境下能够实现更加稳健和高效的教-复现导航，为移动机器人实际落地提供了更优解决方案。

Abstract: Visual Teach-and-Repeat Navigation is a direct solution for mobile robot to
be deployed in unknown environments. However, robust trajectory repeat
navigation still remains challenged due to environmental changing and dynamic
objects. In this paper, we propose a novel visual teach-and-repeat navigation
system, which consists of a flexible map representation, robust map matching
and a map-less local navigation module. During the teaching process, the
recorded keyframes are formulated as a topo-metric graph and each node can be
further extended to save new observations. Such representation also alleviates
the requirement of globally consistent mapping. To enhance the place
recognition performance during repeating process, instead of using
frame-to-frame matching, we firstly implement keyframe clustering to aggregate
similar connected keyframes into local map and perform place recognition based
on visual frame-tolocal map matching strategy. To promote the local goal
persistent tracking performance, a long-term goal management algorithm is
constructed, which can avoid the robot getting lost due to environmental
changes or obstacle occlusion. To achieve the goal without map, a local
trajectory-control candidate optimization algorithm is proposed. Extensively
experiments are conducted on our mobile platform. The results demonstrate that
our system is superior to the baselines in terms of robustness and
effectiveness.

</details>


### [218] [When a Robot is More Capable than a Human: Learning from Constrained Demonstrators](https://arxiv.org/abs/2510.09096)
*Xinhu Li,Ayush Jain,Zhaojing Yang,Yigit Korkmaz,Erdem Bıyık*

Main category: cs.RO

TL;DR: 本论文提出一种新方法，利用受限专家的演示，通过推断基于状态的奖励信号，使机器人能够学习比演示更优的策略，并显著提升学习效率与任务完成速度。


<details>
  <summary>Details</summary>
Motivation: 专家通过演示教导机器人通常受到接口和硬件等限制，导致演示并非最优，因此学习出的策略也有限，这限制了机器人的实际表现；论文关注于突破这些受限演示带来的瓶颈。

Method: 作者提出，不直接模仿受限专家的动作，而是利用演示数据推断出基于状态的奖励信号，并通过时间插值策略自标未知状态的奖励，引导机器人自我探索更高效的轨迹。

Result: 相比常用的模仿学习方法，该方法在样本利用率和任务完成时间上均有显著提升。在实物机器人（WidowX机械臂）上的实验表明，此法能用12秒完成任务，比行为克隆法快10倍。

Conclusion: 通过从受限演示推断奖励并自我探索，机器人可以超越专家演示水平，学习出更优更有效的行为策略，为机器人模仿学习提供了新策略和实际提升。

Abstract: Learning from demonstrations enables experts to teach robots complex tasks
using interfaces such as kinesthetic teaching, joystick control, and
sim-to-real transfer. However, these interfaces often constrain the expert's
ability to demonstrate optimal behavior due to indirect control, setup
restrictions, and hardware safety. For example, a joystick can move a robotic
arm only in a 2D plane, even though the robot operates in a higher-dimensional
space. As a result, the demonstrations collected by constrained experts lead to
suboptimal performance of the learned policies. This raises a key question: Can
a robot learn a better policy than the one demonstrated by a constrained
expert? We address this by allowing the agent to go beyond direct imitation of
expert actions and explore shorter and more efficient trajectories. We use the
demonstrations to infer a state-only reward signal that measures task progress,
and self-label reward for unknown states using temporal interpolation. Our
approach outperforms common imitation learning in both sample efficiency and
task completion time. On a real WidowX robotic arm, it completes the task in 12
seconds, 10x faster than behavioral cloning, as shown in real-robot videos on
https://sites.google.com/view/constrainedexpert .

</details>


### [219] [Decentralized Multi-Robot Relative Navigation in Unknown, Structurally Constrained Environments under Limited Communication](https://arxiv.org/abs/2510.09188)
*Zihao Mao,Yunheng Wang,Yunting Ji,Yi Yang,Wenjie Song*

Main category: cs.RO

TL;DR: 本文提出了一种完全去中心化的分层相对导航框架，使多机器人在结构受限且无法使用GPS的未知环境中协同导航，无需统一坐标系，兼顾全局策略前瞻和局部战术灵活性，显著提升了效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 多机器人在未知、结构复杂且无法依赖GPS的环境中协同导航是一个挑战，因为集中式方法通信负担重，而分布式方法易陷入死锁和拓扑陷阱，现有方法难以兼顾全局和局部性能。

Method: 本方法采用分层框架：战略层在机器人相遇时建立并交换拓扑地图，逐步形成全局感知，实现高层次、高效率避陷路线规划；战术层根据局部度量信息，利用基于采样的逃逸点策略，动态生成可行轨迹，实时应对密集冲突并满足环境和运动约束。

Result: 大量仿真和实际实验验证，该系统在复杂拓扑结构和通信受限环境下，成功率和导航效率显著优于现有方法。

Conclusion: 该方法首次实现在无统一坐标和有限通信条件下，多机器人能有效结合全局前瞻和局部机动，不仅提升了性能还扩展了多机器人自主导航的应用范围。

Abstract: Multi-robot navigation in unknown, structurally constrained, and GPS-denied
environments presents a fundamental trade-off between global strategic
foresight and local tactical agility, particularly under limited communication.
Centralized methods achieve global optimality but suffer from high
communication overhead, while distributed methods are efficient but lack the
broader awareness to avoid deadlocks and topological traps. To address this, we
propose a fully decentralized, hierarchical relative navigation framework that
achieves both strategic foresight and tactical agility without a unified
coordinate system. At the strategic layer, robots build and exchange
lightweight topological maps upon opportunistic encounters. This process
fosters an emergent global awareness, enabling the planning of efficient,
trap-avoiding routes at an abstract level. This high-level plan then inspires
the tactical layer, which operates on local metric information. Here, a
sampling-based escape point strategy resolves dense spatio-temporal conflicts
by generating dynamically feasible trajectories in real time, concurrently
satisfying tight environmental and kinodynamic constraints. Extensive
simulations and real-world experiments demonstrate that our system
significantly outperforms in success rate and efficiency, especially in
communication-limited environments with complex topological structures.

</details>


### [220] [Flow-Opt: Scalable Centralized Multi-Robot Trajectory Optimization with Flow Matching and Differentiable Optimization](https://arxiv.org/abs/2510.09204)
*Simon Idoko,Arun Kumar Singh*

Main category: cs.RO

TL;DR: 该论文提出了一种高效的多机器人集中式轨迹优化方法，有效提升了大规模机器人群体在复杂环境下的轨迹计算速度与质量。


<details>
  <summary>Details</summary>
Motivation: 现有多机器人集中式轨迹优化方法可得到更优轨迹，但计算复杂度极高，限制了其在大规模机器人群体中的应用，尤其在狭窄空间和复杂环境下更为突出。

Method: 作者提出了一种名为Flow-Opt的学习式优化框架：1）首先利用基于扩散Transformer（DiT）和具有置换不变性的编码器的flow-matching模型，学习从生成模型中高效采样多机器人轨迹；2）再利用自学习方式训练的Safety-Filter（SF）及初始化神经网络，保证高效推理下的约束满足。所有关键模块均支持并行批处理。

Result: 方法能在极短时间内（几十毫秒）线上生成几十个机器人在障碍环境下的可行轨迹，速度远超传统方法，且在轨迹平滑性和生成多样性方面效果显著。

Conclusion: Flow-Opt突破了现有方法的计算限制，实现了多机器人群体在集中式轨迹优化下的高效、大规模、可批量与多样化轨迹生成，为相关应用提供了新可能。

Abstract: Centralized trajectory optimization in the joint space of multiple robots
allows access to a larger feasible space that can result in smoother
trajectories, especially while planning in tight spaces. Unfortunately, it is
often computationally intractable beyond a very small swarm size. In this
paper, we propose Flow-Opt, a learning-based approach towards improving the
computational tractability of centralized multi-robot trajectory optimization.
Specifically, we reduce the problem to first learning a generative model to
sample different candidate trajectories and then using a learned
Safety-Filter(SF) to ensure fast inference-time constraint satisfaction. We
propose a flow-matching model with a diffusion transformer (DiT) augmented with
permutation invariant robot position and map encoders as the generative model.
We develop a custom solver for our SF and equip it with a neural network that
predicts context-specific initialization. The initialization network is trained
in a self-supervised manner, taking advantage of the differentiability of the
SF solver. We advance the state-of-the-art in the following respects. First, we
show that we can generate trajectories of tens of robots in cluttered
environments in a few tens of milliseconds. This is several times faster than
existing centralized optimization approaches. Moreover, our approach also
generates smoother trajectories orders of magnitude faster than competing
baselines based on diffusion models. Second, each component of our approach can
be batched, allowing us to solve a few tens of problem instances in a fraction
of a second. We believe this is a first such result; no existing approach
provides such capabilities. Finally, our approach can generate a diverse set of
trajectories between a given set of start and goal locations, which can capture
different collision-avoidance behaviors.

</details>


### [221] [PLEXUS Hand: Lightweight Four-Motor Prosthetic Hand Enabling Precision-Lateral Dexterous Manipulation](https://arxiv.org/abs/2510.09209)
*Yuki Kuroda,Tomoya Takahashi,Cristian C Beltran-Hernandez,Masashi Hamaya,Kazutoshi Tanaka*

Main category: cs.RO

TL;DR: 本文提出了一种新型轻量级电动假手，仅用四个马达实现了基本姿势和体内操作（如旋转），同时保留了人手外观和紧凑结构，实验表明其实用性强。


<details>
  <summary>Details</summary>
Motivation: 当前电动假手多只能完成静态抓握，需要更多马达或复杂机制才能实现物品旋转等体内操作，但这样会牺牲重量、外观和内部空间，影响日常使用和耐用性。

Method: 作者设计了一款只有四个马达的假手，通过单轴拇指和优化拇指位置，使假手能在保持轻量（311克）和类似人手外形的前提下，完成精细抓和侧向抓之间的旋转，从而实现体内操作。

Result: 实验表明，该假手在应对不同宽度（5-30毫米）、不同形状物体（圆柱体、棱柱体）时，体内操作成功率达90-100%，并能成功完成盖章、插拔USB和螺丝刀旋转等实际任务。

Conclusion: 该方案以极简设计高效兼顾了功能、重量与外观，推进了假手向实际生活广泛应用，并为后续轻便多功能假肢开发提供了新思路。

Abstract: Electric prosthetic hands should be lightweight to decrease the burden on the
user, shaped like human hands for cosmetic purposes, and have motors inside to
protect them from damage and dirt. In addition to the ability to perform daily
activities, these features are essential for everyday use of the hand. In-hand
manipulation is necessary to perform daily activities such as transitioning
between different postures, particularly through rotational movements, such as
reorienting cards before slot insertion and operating tools such as
screwdrivers. However, currently used electric prosthetic hands only achieve
static grasp postures, and existing manipulation approaches require either many
motors, which makes the prosthesis heavy for daily use in the hand, or complex
mechanisms that demand a large internal space and force external motor
placement, complicating attachment and exposing the components to damage.
Alternatively, we combine a single-axis thumb and optimized thumb positioning
to achieve basic posture and in-hand manipulation, that is, the reorientation
between precision and lateral grasps, using only four motors in a lightweight
(311 g) prosthetic hand. Experimental validation using primitive objects of
various widths (5-30 mm) and shapes (cylinders and prisms) resulted in success
rates of 90-100% for reorientation tasks. The hand performed seal stamping and
USB device insertion, as well as rotation to operate a screwdriver.

</details>


### [222] [HANDO: Hierarchical Autonomous Navigation and Dexterous Omni-loco-manipulation](https://arxiv.org/abs/2510.09221)
*Jingyuan Sun,Chaoran Wang,Mingyu Zhang,Cui Miao,Hongyu Ji,Zihan Qu,Han Sun,Bing Wang,Qingyi Si*

Main category: cs.RO

TL;DR: 本文提出了HANDO框架，旨在让具 manipulators（机械臂）的四足机器人在未经结构化的环境中自主探索、移动与操作，实现复杂的人机交互任务。框架包括两个层次：自主导航层和全身移动操作层。


<details>
  <summary>Details</summary>
Motivation: 当前移动操作机器人在复杂、动态环境下实现自主探索和全身协调操作（loco-manipulation）存在巨大挑战。要让机器人有效、高效地完成隐藏目标或人机交互任务，需要新颖的层次化方法。

Method: HANDO框架分为两层：第一层使用基于目标条件的自主探索策略，引导机器人导航到具有语义指定的目标（如动态环境中的黑色办公椅）；第二层采用统一的全身loco-manipulation策略，实现手臂与腿的协调，从而精细完成与人的交互操作（如递饮料）。

Result: 作者已经初步部署了导航模块，并计划进一步细化部署全身loco-manipulation模块，用以实现更复杂的人机交互任务。

Conclusion: HANDO框架为具机械臂的四足机器人在复杂、动态环境下的自主探索与高精度移动操作提供了有效方案，有助于推进人机交互场景下机器人应用的发展。

Abstract: Seamless loco-manipulation in unstructured environments requires robots to
leverage autonomous exploration alongside whole-body control for physical
interaction. In this work, we introduce HANDO (Hierarchical Autonomous
Navigation and Dexterous Omni-loco-manipulation), a two-layer framework
designed for legged robots equipped with manipulators to perform human-centered
mobile manipulation tasks. The first layer utilizes a goal-conditioned
autonomous exploration policy to guide the robot to semantically specified
targets, such as a black office chair in a dynamic environment. The second
layer employs a unified whole-body loco-manipulation policy to coordinate the
arm and legs for precise interaction tasks-for example, handing a drink to a
person seated on the chair. We have conducted an initial deployment of the
navigation module, and will continue to pursue finer-grained deployment of
whole-body loco-manipulation.

</details>


### [223] [Glovity: Learning Dexterous Contact-Rich Manipulation via Spatial Wrench Feedback Teleoperation System](https://arxiv.org/abs/2510.09229)
*Yuyang Gao,Haofei Ma,Pai Zheng*

Main category: cs.RO

TL;DR: 本文介绍了Glovity，一种低成本、结合力反馈和触觉手套的遥操作系统，能够提供丰富反馈、提升灵巧操作能力。


<details>
  <summary>Details</summary>
Motivation: 遥操作在接触丰富的任务中面临反馈和精确重定向的难题，如何通过低成本设备实现更高效的人机交互与学习，是当前技术发展的关键问题。

Method: 作者设计了一套结合空间力-矩（force-torque）反馈器和基于霍尔传感器校准的手指触觉手套的系统，同时采用精确重定向技术提升操作表现，并通过用户实验和模仿学习（DP-R3M）进行评估。

Result: 用户实验显示，力反馈使翻书成功率由48%提升到78%，任务时间缩短25%，手指校准在薄物抓取任务上的表现也显著优于商用手套。在模仿学习场景下，集成了力反馈信号的新模型在新颖任务中表现良好。

Conclusion: Glovity系统有效改进了遥操作中灵巧操作和反馈体验，提升了复杂任务中的成功率和效率，硬件设计和软件将开源以促进相关研究发展。

Abstract: We present Glovity, a novel, low-cost wearable teleoperation system that
integrates a spatial wrench (force-torque) feedback device with a haptic glove
featuring fingertip Hall sensor calibration, enabling feedback-rich dexterous
manipulation. Glovity addresses key challenges in contact-rich tasks by
providing intuitive wrench and tactile feedback, while overcoming embodiment
gaps through precise retargeting. User studies demonstrate significant
improvements: wrench feedback boosts success rates in book-flipping tasks from
48% to 78% and reduces completion time by 25%, while fingertip calibration
enhances thin-object grasping success significantly compared to commercial
glove. Furthermore, incorporating wrench signals into imitation learning (via
DP-R3M) achieves high success rate in novel contact-rich scenarios, such as
adaptive page flipping and force-aware handovers. All hardware designs,
software will be open-sourced. Project website: https://glovity.github.io/

</details>


### [224] [Obstacle Avoidance using Dynamic Movement Primitives and Reinforcement Learning](https://arxiv.org/abs/2510.09254)
*Dominik Urbaniak,Alejandro Agostini,Pol Ramon,Jan Rosell,Raúl Suárez,Michael Suppa*

Main category: cs.RO

TL;DR: 本文提出了一种基于单个人为演示、能快速高效生成近似最优、平滑且避障的三维轨迹的学习方法。


<details>
  <summary>Details</summary>
Motivation: 传统学习型运动规划需大量训练数据或昂贵的人类演示，面临数据收集难、成本高等问题。作者希望找到一种既能高效生成高质量轨迹，又能减少人工成本和数据需求的新方法。

Method: 作者提出用单次人工演示，经DMP编码后，通过策略优化型强化学习不断变形扩展，自动生成多样化轨迹数据集。然后利用该数据集训练神经网络，输入由点云自动推理出的障碍参数，输出具体的DMP参数，实现针对不同障碍条件的动态轨迹生成。

Result: 在仿真及真实机器人实验中，该方法在运算速度、执行时间和轨迹长度上，均优于RRT-Connect等基准方法，并能适应多种障碍形状和末端执行器尺寸。

Conclusion: 本文方法只需一次演示，可自动扩展数据并生成鲁棒的避障轨迹，具备高效率、低数据需求与广泛适应性，验证了其实用性和工程价值。

Abstract: Learning-based motion planning can quickly generate near-optimal
trajectories. However, it often requires either large training datasets or
costly collection of human demonstrations. This work proposes an alternative
approach that quickly generates smooth, near-optimal collision-free 3D
Cartesian trajectories from a single artificial demonstration. The
demonstration is encoded as a Dynamic Movement Primitive (DMP) and iteratively
reshaped using policy-based reinforcement learning to create a diverse
trajectory dataset for varying obstacle configurations. This dataset is used to
train a neural network that takes as inputs the task parameters describing the
obstacle dimensions and location, derived automatically from a point cloud, and
outputs the DMP parameters that generate the trajectory. The approach is
validated in simulation and real-robot experiments, outperforming a RRT-Connect
baseline in terms of computation and execution time, as well as trajectory
length, while supporting multi-modal trajectory generation for different
obstacle geometries and end-effector dimensions. Videos and the implementation
code are available at https://github.com/DominikUrbaniak/obst-avoid-dmp-pi2.

</details>


### [225] [Placeit! A Framework for Learning Robot Object Placement Skills](https://arxiv.org/abs/2510.09267)
*Amina Ferrad,Johann Huber,François Hélénon,Julien Gleyze,Mahdi Khoramshahi,Stéphane Doncieux*

Main category: cs.RO

TL;DR: 提出了Placeit!，一个用于自动生成刚性物体有效放置位置的进化计算框架，大幅提升了放置技能学习的效率和效果。


<details>
  <summary>Details</summary>
Motivation: 机器人基础技能如物体放置一直难以突破，主要瓶颈在于高质量训练数据的获取成本高且效率低。因此，亟需自动化、高效生成物体放置数据的方法以加速机器人技能发展。

Method: 受Graspit!自动模拟抓取姿态启发，作者设计了Placeit!进化计算框架，利用质量-多样性优化自动生成刚性物体在各类场景（如桌面放置、堆叠、插入）中的多样有效放置姿态。

Result: 实验证明，Placeit!在各种物体放置场景下生成多样且有效姿态的能力显著优于现有方法。基于Placeit!构建的pick&place管线在真实世界120次实验中取得了90%的成功率。

Conclusion: Placeit!为开放环境下的取放任务及机器人通用模型训练数据生成提供了强大工具，有助于推动机器人基础技能学习的发展。

Abstract: Robotics research has made significant strides in learning, yet mastering
basic skills like object placement remains a fundamental challenge. A key
bottleneck is the acquisition of large-scale, high-quality data, which is often
a manual and laborious process. Inspired by Graspit!, a foundational work that
used simulation to automatically generate dexterous grasp poses, we introduce
Placeit!, an evolutionary-computation framework for generating valid placement
positions for rigid objects. Placeit! is highly versatile, supporting tasks
from placing objects on tables to stacking and inserting them. Our experiments
show that by leveraging quality-diversity optimization, Placeit! significantly
outperforms state-of-the-art methods across all scenarios for generating
diverse valid poses. A pick&place pipeline built on our framework achieved a
90% success rate over 120 real-world deployments. This work positions Placeit!
as a powerful tool for open-environment pick-and-place tasks and as a valuable
engine for generating the data needed to train simulation-based foundation
models in robotics.

</details>


### [226] [Bridging Research and Practice in Simulation-based Testing of Industrial Robot Navigation Systems](https://arxiv.org/abs/2510.09396)
*Sajad Khatiri,Francisco Eli Vina Barrientos,Maximilian Wulf,Paolo Tonella,Sebastiano Panichella*

Main category: cs.RO

TL;DR: 本文介绍了一种基于仿真的自动化测试框架Surrealist，从无人机领域扩展到四足机器人ANYmal的工业巡检应用，用于生成复杂障碍场景，有效发现人工测试难以覆盖的导航失败案例。实际工业流程测试结果和用户反馈均证明了其价值。


<details>
  <summary>Details</summary>
Motivation: 动态环境下机器人的稳健导航很难用传统人工测试全面覆盖，容易遗漏关键失败场景，迫切需要自动化、高覆盖率的测试方法，加强工业级机器人算法的验证能力。

Method: 将Surrealist——一种本用于无人机的基于仿真测试生成框架——应用到四足机器人ANYmal，借助搜索算法自动生成障碍回避测试场景，对多种导航算法进行系统性测试。通过与人工测试对比，以及长达半年的工业流程集成验证其效果。

Result: 在初步测试中，自动生成的测试集揭示某实验性导航算法成功率仅40.3%，另一种则有71.2%。之后，框架被集成到工业级ANYbotics流程，用于测试5种专有算法。调查反馈表明该工具能有效发现关键失败、提升开发、验证与评估流程的客观性。

Conclusion: Surrealist测试框架能够高效发现传统人工测试易遗漏的导航漏洞，显著提升四足机器人在复杂动态环境中的算法鲁棒性验证水平，被工业界认可为测试流程的重要组成部分。

Abstract: Ensuring robust robotic navigation in dynamic environments is a key
challenge, as traditional testing methods often struggle to cover the full
spectrum of operational requirements. This paper presents the industrial
adoption of Surrealist, a simulation-based test generation framework originally
for UAVs, now applied to the ANYmal quadrupedal robot for industrial
inspection. Our method uses a search-based algorithm to automatically generate
challenging obstacle avoidance scenarios, uncovering failures often missed by
manual testing. In a pilot phase, generated test suites revealed critical
weaknesses in one experimental algorithm (40.3% success rate) and served as an
effective benchmark to prove the superior robustness of another (71.2% success
rate). The framework was then integrated into the ANYbotics workflow for a
six-month industrial evaluation, where it was used to test five proprietary
algorithms. A formal survey confirmed its value, showing it enhances the
development process, uncovers critical failures, provides objective benchmarks,
and strengthens the overall verification pipeline.

</details>


### [227] [Failure Prediction at Runtime for Generative Robot Policies](https://arxiv.org/abs/2510.09459)
*Ralf Römer,Adrian Kobras,Luca Worbis,Angela P. Schoellig*

Main category: cs.RO

TL;DR: 本文提出了FIPER，一种用于生成式模仿学习策略的实时故障预测通用框架，无需故障数据即可预测机器人任务失败，提升了机器人在复杂、关键环境下的安全性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型驱动的模仿学习在面对环境变化或动作误差时，易出现分布偏移，导致机器人运行不可预测甚至任务失败，因此需要一种有效的实时失败预测机制，保障安全运行。

Method: FIPER框架主要基于两个失败前兆指标：(1)通过随机网络蒸馏检测策略嵌入空间的分布外（OOD）观测；(2)使用新颖的动作片段熵评分度量生成动作的不确定性。两者都利用少量成功轨迹并结合保序预测方法进行校准。当这两个指标在短时间窗内均超过阈值时，将触发故障警报。

Result: FIPER在五个仿真和真实环境中进行评估，涵盖多种故障模式。实验结果表明，FIPER能更好区分实际失败与无害的OOD情形，并且比现有方法预测更准确、时间更早。

Conclusion: FIPER显著提高了生成式IL策略的故障预测能力，有助于实现更安全、可靠与可解释的机器人策略部署。

Abstract: Imitation learning (IL) with generative models, such as diffusion and flow
matching, has enabled robots to perform complex, long-horizon tasks. However,
distribution shifts from unseen environments or compounding action errors can
still cause unpredictable and unsafe behavior, leading to task failure. Early
failure prediction during runtime is therefore essential for deploying robots
in human-centered and safety-critical environments. We propose FIPER, a general
framework for Failure Prediction at Runtime for generative IL policies that
does not require failure data. FIPER identifies two key indicators of impending
failure: (i) out-of-distribution (OOD) observations detected via random network
distillation in the policy's embedding space, and (ii) high uncertainty in
generated actions measured by a novel action-chunk entropy score. Both failure
prediction scores are calibrated using a small set of successful rollouts via
conformal prediction. A failure alarm is triggered when both indicators,
aggregated over short time windows, exceed their thresholds. We evaluate FIPER
across five simulation and real-world environments involving diverse failure
modes. Our results demonstrate that FIPER better distinguishes actual failures
from benign OOD situations and predicts failures more accurately and earlier
than existing methods. We thus consider this work an important step towards
more interpretable and safer generative robot policies. Code, data and videos
are available at https://tum-lsy.github.io/fiper_website.

</details>


### [228] [FOGMACHINE -- Leveraging Discrete-Event Simulation and Scene Graphs for Modeling Hierarchical, Interconnected Environments under Partial Observations from Mobile Agents](https://arxiv.org/abs/2510.09483)
*Lars Ohnemus,Nils Hantke,Max Weißer,Kai Furmans*

Main category: cs.RO

TL;DR: 本文提出了FOGMACHINE框架，将动态场景图（DSG）与离散事件仿真相结合，以实现对多智能体系统中不确定性、部分可观测性和复杂交互的高效建模。


<details>
  <summary>Details</summary>
Motivation: 当前的动态场景图方法难以有效刻画环境中的随机动态、部分可观测性以及多智能体的活动，而这些特性对于需要在不确定和感知延迟情况下行动的具身人工智能（embodied AI）至关重要。

Method: FOGMACHINE通过将DSG结构与大规模离散事件仿真融合，能够模拟对象动态、智能体观测和交互过程，从而支持对不确定性传播、有限感知下的规划和多智能体涌现行为的研究。

Result: 在城市场景实验中，FOGMACHINE能够展现现实的时空模式，并揭示在稀疏观测条件下信念估计面临的挑战。

Conclusion: 利用结构化表示和高效仿真，FOGMACHINE为具身AI在复杂不确定环境下的基准测试、模型训练和前沿研究提供了有效工具。

Abstract: Dynamic Scene Graphs (DSGs) provide a structured representation of
hierarchical, interconnected environments, but current approaches struggle to
capture stochastic dynamics, partial observability, and multi-agent activity.
These aspects are critical for embodied AI, where agents must act under
uncertainty and delayed perception. We introduce FOGMACHINE , an open-source
framework that fuses DSGs with discrete-event simulation to model object
dynamics, agent observations, and interactions at scale. This setup enables the
study of uncertainty propagation, planning under limited perception, and
emergent multi-agent behavior. Experiments in urban scenarios illustrate
realistic temporal and spatial patterns while revealing the challenges of
belief estimation under sparse observations. By combining structured
representations with efficient simulation, FOGMACHINE establishes an effective
tool for benchmarking, model training, and advancing embodied AI in complex,
uncertain environments.

</details>


### [229] [Autonomous Soft Robotic Guidewire Navigation via Imitation Learning](https://arxiv.org/abs/2510.09497)
*Noah Barnes,Ji Woong Kim,Lingyun Di,Hannah Qu,Anuruddha Bhattacharjee,Miroslaw Janowski,Dheeraj Gandhi,Bailey Felix,Shaopeng Jiang,Olivia Young,Mark Fuge,Ryan D. Sochol,Jeremy D. Brown,Axel Krieger*

Main category: cs.RO

TL;DR: 本文提出了一种基于Transformer的模仿学习框架，实现了软体机器人导丝在动脉瘤定位任务中的自主导航，模型在三个未见过的几何数据集上的成功率达到83%，优于多个基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有导丝虽然增加了末端的操控性，但建模和控制仍有难度，自动化导航可以提升血管内手术的精确性和安全性。而模仿学习在其他外科领域已表现良好，因此作者尝试将其应用于机器人软体导丝的导航任务。

Method: 作者开发了一种带有目标条件、相对动作输出、自动造影剂注射功能的Transformer模仿学习框架，在36种不同的分叉血管几何结构下生成共647个模拟演示样本用于训练，并在三个新的血管几何结构中评估性能。同时，进行了消融实验和基线对比，分析了各设计选择的效果。

Result: 模型在未见过的血管几何结构中，能够自动将导丝末端导航至动脉瘤位置，成功率达到83%，明显优于多种基线方法。此外，消融实验验证了各设计元素的有效性。

Conclusion: Transformer + 目标条件模仿学习方法在软体机器人导丝自主导航任务中表现出色，大幅提升了面向新几何情形下的泛化能力和操作成功率，为提升血管内手术自动化和安全性提供了技术基础。

Abstract: In endovascular surgery, endovascular interventionists push a thin tube
called a catheter, guided by a thin wire to a treatment site inside the
patient's blood vessels to treat various conditions such as blood clots,
aneurysms, and malformations. Guidewires with robotic tips can enhance
maneuverability, but they present challenges in modeling and control.
Automation of soft robotic guidewire navigation has the potential to overcome
these challenges, increasing the precision and safety of endovascular
navigation. In other surgical domains, end-to-end imitation learning has shown
promising results. Thus, we develop a transformer-based imitation learning
framework with goal conditioning, relative action outputs, and automatic
contrast dye injections to enable generalizable soft robotic guidewire
navigation in an aneurysm targeting task. We train the model on 36 different
modular bifurcated geometries, generating 647 total demonstrations under
simulated fluoroscopy, and evaluate it on three previously unseen vascular
geometries. The model can autonomously drive the tip of the robot to the
aneurysm location with a success rate of 83% on the unseen geometries,
outperforming several baselines. In addition, we present ablation and baseline
studies to evaluate the effectiveness of each design and data collection
choice. Project website: https://softrobotnavigation.github.io/

</details>


### [230] [Dynamic Quadrupedal Legged and Aerial Locomotion via Structure Repurposing](https://arxiv.org/abs/2510.09526)
*Chenghao Wang,Kaushik Venkatesh Krishnamurthy,Shreyansh Pitroda,Adarsh Salagame,Ioannis Mandralis,Eric Sihite,Alireza Ramezani,Morteza Gharib*

Main category: cs.RO

TL;DR: 本文介绍了Husky v.2多模态地空机器人，其特色在于通过结构重用，实现了腿部可用于地面行走及飞行，两种功能之间的集成和转换取得了初步实验成果。


<details>
  <summary>Details</summary>
Motivation: 多模态机器人需在不同运动模式间切换，但各模式需求往往冲突，传统设计难以兼顾，因此需要创新结构来集成不同运动能力。

Method: 采用腿部结构重用，结合姿态调整与推力矢量技术，使一套腿部结构兼顾动态步行以及飞行悬停。主要介绍硬件设计及对步行和悬停的初步实验。

Result: Husky v.2实现了动态四足步行和空中悬停，初步测试展示了有效的多模态转换与结构复用能力。

Conclusion: 结构重用和推力矢量结合，为多模态机器人在地面与空中模式间切换提供了新思路，初步结果验证了该设计的可行性。

Abstract: Multi-modal ground-aerial robots have been extensively studied, with a
significant challenge lying in the integration of conflicting requirements
across different modes of operation. The Husky robot family, developed at
Northeastern University, and specifically the Husky v.2 discussed in this
study, addresses this challenge by incorporating posture manipulation and
thrust vectoring into multi-modal locomotion through structure repurposing.
This quadrupedal robot features leg structures that can be repurposed for
dynamic legged locomotion and flight. In this paper, we present the hardware
design of the robot and report primary results on dynamic quadrupedal legged
locomotion and hovering.

</details>


### [231] [Guiding Energy-Efficient Locomotion through Impact Mitigation Rewards](https://arxiv.org/abs/2510.09543)
*Chenghao Wang,Arjun Viswanathan,Eric Sihite,Alireza Ramezani*

Main category: cs.RO

TL;DR: 该论文提出将AMP（对抗性运动先验）与物理启发的IMF（冲击缓解因子）奖励相结合，提升机器人模仿动物高效运动的能力，实现高达32%的能耗降低。


<details>
  <summary>Details</summary>
Motivation: 传统RL模仿动物运动注重于显式步态，忽视了动物运动中的隐式被动动力学，导致机器人运动能效不高。作者希望解决这一能效瓶颈。

Method: 引入IMF作为奖励项，IMF是量化机器人被动缓冲冲击能力的物理指标。将其与AMP整合，推动RL不仅学习动物的运动轨迹，还学习其隐式动力学特性。

Result: 与传统AMP和手工奖励结构相比，加入IMF奖励后，机器人运动的能量消耗指数（CoT）最高降低32%。

Conclusion: 通过IMF奖励，RL能够更好地复现动物自然且节能的运动，兼顾运动轨迹和被动动力学，推动仿生机器人向高效运动发展。

Abstract: Animals achieve energy-efficient locomotion by their implicit passive
dynamics, a marvel that has captivated roboticists for decades.Recently,
methods incorporated Adversarial Motion Prior (AMP) and Reinforcement learning
(RL) shows promising progress to replicate Animals' naturalistic motion.
However, such imitation learning approaches predominantly capture explicit
kinematic patterns, so-called gaits, while overlooking the implicit passive
dynamics. This work bridges this gap by incorporating a reward term guided by
Impact Mitigation Factor (IMF), a physics-informed metric that quantifies a
robot's ability to passively mitigate impacts. By integrating IMF with AMP, our
approach enables RL policies to learn both explicit motion trajectories from
animal reference motion and the implicit passive dynamic. We demonstrate energy
efficiency improvements of up to 32%, as measured by the Cost of Transport
(CoT), across both AMP and handcrafted reward structure.

</details>


### [232] [Zero-shot Structure Learning and Planning for Autonomous Robot Navigation using Active Inference](https://arxiv.org/abs/2510.09574)
*Daria de tinguy,Tim Verbelen,Emilio Gamba,Bart Dhoedt*

Main category: cs.RO

TL;DR: 该论文提出了一种生物启发式主动推断导航框架AIMAPP，实现了无须预训练和地图的自主导航。该系统统一了建图、定位和决策，能在真实和模拟环境中鲁棒导航。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中，机器人导航需要同时应对探索、定位和规划的不确定性，现有方法往往依赖于预定义地图或大量训练。本文旨在解决在无地图、无训练的条件下自主导航的难题。

Method: 提出AIMAPP框架，融合主动推断理论与海马体机制，采用稀疏拓扑建图、位置编码和情节记忆，实现动态状态转移学习和最小化期望自由能的规划策略。系统完全自监督，支持多种硬件平台，无需预训练。

Result: AIMAPP在大规模真实和仿真环境中展现了优异性能，优于多种主流规划模型，在处理模糊观测、环境变化及传感噪声时表现出高度适应性和鲁棒性。

Conclusion: AIMAPP为非结构化环境下的可扩展、自监督导航提供了模块化、生物学启发的有效解决方案，并展示了与硬件无关的、强大的实际应用潜力。

Abstract: Autonomous navigation in unfamiliar environments requires robots to
simultaneously explore, localise, and plan under uncertainty, without relying
on predefined maps or extensive training. We present a biologically inspired,
Active Inference-based framework, Active Inference MAPping and Planning
(AIMAPP). This model unifies mapping, localisation, and decision-making within
a single generative model. Inspired by hippocampal navigation, it uses
topological reasoning, place-cell encoding, and episodic memory to guide
behaviour. The agent builds and updates a sparse topological map online, learns
state transitions dynamically, and plans actions by minimising Expected Free
Energy. This allows it to balance goal-directed and exploratory behaviours. We
implemented a ROS-compatible navigation system that is sensor and
robot-agnostic, capable of integrating with diverse hardware configurations. It
operates in a fully self-supervised manner, is resilient to drift, and supports
both exploration and goal-directed navigation without any pre-training. We
demonstrate robust performance in large-scale real and simulated environments
against state-of-the-art planning models, highlighting the system's
adaptability to ambiguous observations, environmental changes, and sensor
noise. The model offers a biologically inspired, modular solution to scalable,
self-supervised navigation in unstructured settings. AIMAPP is available at
https://github.com/decide-ugent/AIMAPP.

</details>
