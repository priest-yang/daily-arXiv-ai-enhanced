<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 113]
- [cs.CL](#cs.CL) [Total: 31]
- [cs.RO](#cs.RO) [Total: 23]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Complex Mathematical Expression Recognition: Benchmark, Large-Scale Dataset and Strong Baseline](https://arxiv.org/abs/2512.13731)
*Weikang Bai,Yongkun Du,Yuchen Su,Yazhen Xie,Zhineng Chen*

Main category: cs.CV

TL;DR: 本文主要解决复杂数学表达式识别（MER）难题，通过构建高质量数据集和新的模型显著提升了复杂表达式的识别能力。


<details>
  <summary>Details</summary>
Motivation: 尽管现有算法能较好识别简单数学表达式，但应对大量符号、多行和结构复杂的表达式时准确率下降明显，缺乏支持复杂表达式的训练数据。

Method: 1. 构建CMER-Bench基准，按难易分级表达式，系统评测现有MER模型和通用多模态大模型的表现。2. 发布两个大规模复杂表达式数据集MER-17M与CMER-3M。3. 提出面向空间层次结构的表达式tokenizer和Structured Mathematical Language新表达。4. 基于encoder-decoder结构，利用CMER-3M训练新模型CMERNet。

Result: 1. 实验表明主流方法在处理复杂表达式时性能大幅下降。2. 新提出的CMERNet（1.25亿参数）在CMER-Bench上显著优于现有MER模型和多模态大模型。

Conclusion: 大规模、复杂表达式数据集和结构化表示方法能有效提升复杂MER性能，CMERNet方法在精准识别复杂数学表达式方面具备优越性。

Abstract: Mathematical Expression Recognition (MER) has made significant progress in recognizing simple expressions, but the robust recognition of complex mathematical expressions with many tokens and multiple lines remains a formidable challenge. In this paper, we first introduce CMER-Bench, a carefully constructed benchmark that categorizes expressions into three difficulty levels: easy, moderate, and complex. Leveraging CMER-Bench, we conduct a comprehensive evaluation of existing MER models and general-purpose multimodal large language models (MLLMs). The results reveal that while current methods perform well on easy and moderate expressions, their performance degrades significantly when handling complex mathematical expressions, mainly because existing public training datasets are primarily composed of simple samples. In response, we propose MER-17M and CMER-3M that are large-scale datasets emphasizing the recognition of complex mathematical expressions. The datasets provide rich and diverse samples to support the development of accurate and robust complex MER models. Furthermore, to address the challenges posed by the complicated spatial layout of complex expressions, we introduce a novel expression tokenizer, and a new representation called Structured Mathematical Language, which explicitly models the hierarchical and spatial structure of expressions beyond LaTeX format. Based on these, we propose a specialized model named CMERNet, built upon an encoder-decoder architecture and trained on CMER-3M. Experimental results show that CMERNet, with only 125 million parameters, significantly outperforms existing MER models and MLLMs on CMER-Bench.

</details>


### [2] [Human-AI Collaboration Mechanism Study on AIGC Assisted Image Production for Special Coverage](https://arxiv.org/abs/2512.13739)
*Yajie Yang,Yuqing Zhao,Xiaochao Xi,Yinan Zhu*

Main category: cs.CV

TL;DR: 本文分析AIGC（人工智能生成内容）技术在新闻图片制作中的争议与挑战，并通过实验提出了一套可控的、可追溯的人机协同生成机制以及专门的评估指标。


<details>
  <summary>Details</summary>
Motivation: 随着AIGC在媒体行业的广泛应用，其在新闻图片制作中的虚假信息、真实性、语义一致性和可解释性问题日益突出。为提高内容准确性和语义对齐，需要可控的技术和机制，解决“黑箱”带来的信任困境。

Method: 本文通过两项实验展开研究：实验一采用标准化提示词分别在不同平台和场景测试AIGC工具的适应性，比较语义对齐、文化特异性和视觉真实度。实验二设计了“人类参与环节”的模块化生成流程，结合了高精度分割（SAM、GroundingDINO）、语义对齐（BrushNet）和风格调节（Style-LoRA、Prompt-to-Prompt），通过CLIP评分及多重内容过滤确保发布图片的编辑一致性和可溯源性。

Result: 实验结果揭示了不同AIGC平台的训练语料以及过滤机制导致的语义与文化落差；提出的人机协作生成流程可提升新闻图片的语义表现、可控性及真实性，并能追溯生成过程。

Conclusion: 论文认为新闻领域AIGC图片生产需采纳人机协同机制，并建议采用“角色身份稳定性”(CIS)、“文化表达准确性”(CEA)和“用户-公众适宜性”(U-PA)等新评估维度，以促进内容的真实、合规与社会信任。

Abstract: Artificial Intelligence Generated Content (AIGC) assisting image production triggers controversy in journalism while attracting attention from media agencies. Key issues involve misinformation, authenticity, semantic fidelity, and interpretability. Most AIGC tools are opaque "black boxes," hindering the dual demands of content accuracy and semantic alignment and creating ethical, sociotechnical, and trust dilemmas. This paper explores pathways for controllable image production in journalism's special coverage and conducts two experiments with projects from China's media agency: (1) Experiment 1 tests cross-platform adaptability via standardized prompts across three scenes, revealing disparities in semantic alignment, cultural specificity, and visual realism driven by training-corpus bias and platform-level filtering. (2) Experiment 2 builds a human-in-the-loop modular pipeline combining high-precision segmentation (SAM, GroundingDINO), semantic alignment (BrushNet), and style regulating (Style-LoRA, Prompt-to-Prompt), ensuring editorial fidelity through CLIP-based semantic scoring, NSFW/OCR/YOLO filtering, and verifiable content credentials. Traceable deployment preserves semantic representation. Consequently, we propose a human-AI collaboration mechanism for AIGC assisted image production in special coverage and recommend evaluating Character Identity Stability (CIS), Cultural Expression Accuracy (CEA), and User-Public Appropriateness (U-PA).

</details>


### [3] [DL$^3$M: A Vision-to-Language Framework for Expert-Level Medical Reasoning through Deep Learning and Large Language Models](https://arxiv.org/abs/2512.13742)
*Md. Najib Hasan,Imran Ahmad,Sourav Basak Shuvo,Md. Mahadi Hasan Ankon,Sunanda Das,Nazmul Siddique,Hui Wang*

Main category: cs.CV

TL;DR: 本文提出了一种将医学影像分类与结构化临床推理相结合的框架，并基于新模型MobileCoAtNet在胃病内镜图像上取得高分类准确率。该框架利用分类结果驱动多个大语言模型（LLMs）生成临床推理文本，并通过专家验证的基准评估其解释质量。结果显示LLMs生成的解释与输入提示变化有关，尚难达到人类的稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有医学影像分类器虽能有效检测疾病，却无法解释决策过程；而LLMs虽可生成临床文本，但缺乏视觉推理能力且结果不稳定。临床医生期待的是透明、有理有据的推理。亟需一种桥接模型视觉能力和临床推理之间差距的方法。

Method: 1. 设计面向内镜图像的MobileCoAtNet图像分类模型，针对8类胃部疾病进行分类。
2. 利用分类结果驱动32个LLMs进行结构化临床推理（涵盖病因、症状、治疗等）。
3. 构建两个经专家验证的基准，评测各模型临床推理的质量和稳定性。

Result: MobileCoAtNet分类准确率高，LLMs基于其输出能够生成更有质量的解释文本，但所有LLMs在推理稳定性、连贯性等方面均低于人类水平，提示敏感性较高。

Conclusion: 深度学习与LLM结合可产出有用的临床解释，但目前LLMs不适合高风险医疗决策。提出的框架有助于明确LLMs的局限，并为构建更安全的临床推理系统提供方向。

Abstract: Medical image classifiers detect gastrointestinal diseases well, but they do not explain their decisions. Large language models can generate clinical text, yet they struggle with visual reasoning and often produce unstable or incorrect explanations. This leaves a gap between what a model sees and the type of reasoning a clinician expects. We introduce a framework that links image classification with structured clinical reasoning. A new hybrid model, MobileCoAtNet, is designed for endoscopic images and achieves high accuracy across eight stomach-related classes. Its outputs are then used to drive reasoning by several LLMs. To judge this reasoning, we build two expert-verified benchmarks covering causes, symptoms, treatment, lifestyle, and follow-up care. Thirty-two LLMs are evaluated against these gold standards. Strong classification improves the quality of their explanations, but none of the models reach human-level stability. Even the best LLMs change their reasoning when prompts vary. Our study shows that combining DL with LLMs can produce useful clinical narratives, but current LLMs remain unreliable for high-stakes medical decisions. The framework provides a clearer view of their limits and a path for building safer reasoning systems. The complete source code and datasets used in this study are available at https://github.com/souravbasakshuvo/DL3M.

</details>


### [4] [Why Text Prevails: Vision May Undermine Multimodal Medical Decision Making](https://arxiv.org/abs/2512.13747)
*Siyuan Dai,Lunxiao Li,Kun Zhao,Eardi Lila,Paul K. Crane,Heng Huang,Dongkuan Xu,Haoteng Tang,Liang Zhan*

Main category: cs.CV

TL;DR: 当前先进的多模态大模型在医疗决策任务上表现有限，仅依靠文本推理往往优于多模态输入。本文评估原因，并提出多种改进策略以增强医学场景下的多模态决策能力。


<details>
  <summary>Details</summary>
Motivation: 虽然多模态大模型（MLLM）在一般视觉和语言任务上表现卓越，但在医学决策等高难度任务中效果不佳，限制其在医疗健康领域的实际应用。本文旨在找出成因并探索提升方法。

Method: 作者基于两个人工智能难题——阿尔兹海默症三阶段分类与MIMIC-CXR胸片多标签分类，对比文本、视觉、以及多模态输入在MLLM下的表现，并尝试三种改进方法：（1）利用带推理注释范例的上下文学习，（2）视觉内容先自动描述后文本推理，（3）对视觉模块进行少样本分类微调。

Result: 实验显示，纯文本模式在医疗决策任务中明显优于视觉或多模态输入。三种改进方法均一定程度提升了多模态模型的性能，但总体显示目前MLLM在医学视觉理解上存在明显短板。

Conclusion: 当前MLLM在医学视觉理解和决策中的能力有限。文本推理为主的策略表现更优，未来提升多模态视觉基础理解力是医学AI的重要方向。

Abstract: With the rapid progress of large language models (LLMs), advanced multimodal large language models (MLLMs) have demonstrated impressive zero-shot capabilities on vision-language tasks. In the biomedical domain, however, even state-of-the-art MLLMs struggle with basic Medical Decision Making (MDM) tasks. We investigate this limitation using two challenging datasets: (1) three-stage Alzheimer's disease (AD) classification (normal, mild cognitive impairment, dementia), where category differences are visually subtle, and (2) MIMIC-CXR chest radiograph classification with 14 non-mutually exclusive conditions. Our empirical study shows that text-only reasoning consistently outperforms vision-only or vision-text settings, with multimodal inputs often performing worse than text alone. To mitigate this, we explore three strategies: (1) in-context learning with reason-annotated exemplars, (2) vision captioning followed by text-only inference, and (3) few-shot fine-tuning of the vision tower with classification supervision. These findings reveal that current MLLMs lack grounded visual understanding and point to promising directions for improving multimodal decision making in healthcare.

</details>


### [5] [STAR: STacked AutoRegressive Scheme for Unified Multimodal Learning](https://arxiv.org/abs/2512.13752)
*Jie Qin,Jiancheng Huang,Limeng Qiao,Lin Ma*

Main category: cs.CV

TL;DR: 本文提出了一种名为STAR的分阶段自回归多模态大模型架构，解决了多模态理解与生成统一学习中的性能冲突，实现了在理解、生成和编辑等多任务下的高效扩展。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大模型推动了通用人工智能的发展，但同时提升多模态理解与生成性能面临任务冲突和优化难题，因此需要新的方法能够兼顾理解和生成能力。

Method: 提出STAR(stack autoregressive)方案，将多模态学习分解为理解、生成、编辑多个阶段，通过冻结基础自回归模型参数，并逐层堆叠同构自回归模块，实现能力扩展且减少任务干扰。同时引入高容量向量量化(VQ)加强图像表征的细粒度，并用隐式推理机制提升复杂场景下的生成质量。

Result: STAR模型在GenEval、DPG-Bench与ImgEdit评测中取得了SOTA表现，性能显著优于以往方法。

Conclusion: STAR方案有效解决多模态理解与生成统一中的冲突，实现了分阶段的高效多模态学习，并在多个基准任务上验证了其实用性与先进性。

Abstract: Multimodal large language models (MLLMs) play a pivotal role in advancing the quest for general artificial intelligence. However, achieving unified target for multimodal understanding and generation remains challenging due to optimization conflicts and performance trade-offs. To effectively enhance generative performance while preserving existing comprehension capabilities, we introduce STAR: a STacked AutoRegressive scheme for task-progressive unified multimodal learning. This approach decomposes multimodal learning into multiple stages: understanding, generation, and editing. By freezing the parameters of the fundamental autoregressive (AR) model and progressively stacking isomorphic AR modules, it avoids cross-task interference while expanding the model's capabilities. Concurrently, we introduce a high-capacity VQ to enhance the granularity of image representations and employ an implicit reasoning mechanism to improve generation quality under complex conditions. Experiments demonstrate that STAR achieves state-of-the-art performance on GenEval (0.91), DPG-Bench (87.44), and ImgEdit (4.34), validating its efficacy for unified multimodal learning.

</details>


### [6] [Time-aware UNet and super-resolution deep residual networks for spatial downscaling](https://arxiv.org/abs/2512.13753)
*Mika Sipilä,Sabrina Maggio,Sandra De Iaco,Klaus Nordhausen,Monica Palma,Sara Taskinen*

Main category: cs.CV

TL;DR: 本研究提出了基于深度学习的时空下采样方法，显著提升了卫星臭氧数据的空间分辨率，并验证了时间特征对下采样性能的积极作用。


<details>
  <summary>Details</summary>
Motivation: 卫星污染物数据空间分辨率较低，限制了其在本地环境分析与决策中的应用，需要有效的空间下采样（超分辨率）方法提升数据精度。

Method: 选用两种主流深度学习架构：超分辨率深度残差网络（SRDRN）和编码器-解码器UNet，并添加轻量化的时序模块（使用正弦或径向基函数对时间进行编码），将时间特征与空间特征融合。

Result: 在意大利的臭氧下采样案例中，增加时间编码的扩展方法，在计算复杂度仅略有增加的前提下，明显改善了下采样性能和模型收敛速度。

Conclusion: 将时间特征显式引入深度学习空间下采样框架，可以有效提升卫星大气污染物数据的高分辨率重建效果，具有实际应用潜力。

Abstract: Satellite data of atmospheric pollutants are often available only at coarse spatial resolution, limiting their applicability in local-scale environmental analysis and decision-making. Spatial downscaling methods aim to transform the coarse satellite data into high-resolution fields. In this work, two widely used deep learning architectures, the super-resolution deep residual network (SRDRN) and the encoder-decoder-based UNet, are considered for spatial downscaling of tropospheric ozone. Both methods are extended with a lightweight temporal module, which encodes observation time using either sinusoidal or radial basis function (RBF) encoding, and fuses the temporal features with the spatial representations in the networks. The proposed time-aware extensions are evaluated against their baseline counterparts in a case study on ozone downscaling over Italy. The results suggest that, while only slightly increasing computational complexity, the temporal modules significantly improve downscaling performance and convergence speed.

</details>


### [7] [Nexels: Neurally-Textured Surfels for Real-Time Novel View Synthesis with Sparse Geometries](https://arxiv.org/abs/2512.13796)
*Victor Rong,Jan Held,Victor Chu,Daniel Rebain,Marc Van Droogenbroeck,Kiriakos N. Kutulakos,Andrea Tagliasacchi,David B. Lindell*

Main category: cs.CV

TL;DR: 本文提出了一种新的新颖视角合成方法，通过解耦几何和外观，显著减少了建模所需的原语数量及内存消耗，同时提升渲染速度及视觉质量。


<details>
  <summary>Details</summary>
Motivation: 高斯点云（Gaussian splatting）虽在新视角合成方面表现出色，但在简单几何、复杂纹理的场景下，需要大量点云原语，导致冗余和计算、内存的浪费。该工作旨在减少这种冗余，实现更紧凑高效的表示。

Method: 作者提出采用surface elements（surfels）描述几何，并将外观信息分为两部分：一部分为全局神经场用于纹理生成，另一部分为每个原语的颜色。渲染时，神经场仅作用于每像素固定数量的原语，有效控制计算开销。该方法突破了点云渲染的限制，达成了几何与外观的解耦。

Result: 该方法在户外场景下比3D Gaussian splatting减少约9.7倍的原语和5.5倍的存储，室内场景减少31倍原语和3.7倍存储。同时渲染速度提高2倍，并在视觉质量上优于现有点云和纹理原语方法。

Conclusion: 本文代表了一种高效紧凑的新颖视角合成表示方式，兼顾视觉质量、运行速度和内存开销，为高质量3D场景渲染提供了新的解决方案。

Abstract: Though Gaussian splatting has achieved impressive results in novel view synthesis, it requires millions of primitives to model highly textured scenes, even when the geometry of the scene is simple. We propose a representation that goes beyond point-based rendering and decouples geometry and appearance in order to achieve a compact representation. We use surfels for geometry and a combination of a global neural field and per-primitive colours for appearance. The neural field textures a fixed number of primitives for each pixel, ensuring that the added compute is low. Our representation matches the perceptual quality of 3D Gaussian splatting while using $9.7\times$ fewer primitives and $5.5\times$ less memory on outdoor scenes and using $31\times$ fewer primitives and $3.7\times$ less memory on indoor scenes. Our representation also renders twice as fast as existing textured primitives while improving upon their visual quality.

</details>


### [8] [VajraV1 -- The most accurate Real Time Object Detector of the YOLO family](https://arxiv.org/abs/2512.13834)
*Naman Balbir Singh Makkar*

Main category: cs.CV

TL;DR: 本文提出了VajraV1模型，它在现有YOLO系列的基础上进行了结构性增强，不仅提升了检测准确率，还保持了优异的推理速度。


<details>
  <summary>Details</summary>
Motivation: 随着YOLO系列（YOLOv10-13）不断发展，实时目标检测的准确率不断提升，但模型在速度与精度之间仍需进一步平衡。因此提出VajraV1以进一步提升性能。

Method: VajraV1结合了以往YOLO模型中的有效设计，改进了模型架构，实现了在保证推理速度的前提下更高的精度。

Result: 在COCO验证集上，各种规模的VajraV1模型（Nano、Small、Medium、Large、Xlarge）均超越了YOLOv12、YOLOv13等最新模型，在44.3%至56.2%的mAP区间内取得了全面领先，并保持了与YOLO同类模型相当的推理速度。

Conclusion: VajraV1架构在不牺牲推理速度的前提下实现了更高的准确率，为实时目标检测领域提供了新的领先方案。

Abstract: Recent years have seen significant advances in real-time object detection, with the release of YOLOv10, YOLO11, YOLOv12, and YOLOv13 between 2024 and 2025. This technical report presents the VajraV1 model architecture, which introduces architectural enhancements over existing YOLO-based detectors. VajraV1 combines effective design choices from prior YOLO models to achieve state-of-the-art accuracy among real-time object detectors while maintaining competitive inference speed.
  On the COCO validation set, VajraV1-Nano achieves 44.3% mAP, outperforming YOLOv12-N by 3.7% and YOLOv13-N by 2.7% at latency competitive with YOLOv12-N and YOLOv11-N. VajraV1-Small achieves 50.4% mAP, exceeding YOLOv12-S and YOLOv13-S by 2.4%. VajraV1-Medium achieves 52.7% mAP, outperforming YOLOv12-M by 0.2%. VajraV1-Large achieves 53.7% mAP, surpassing YOLOv13-L by 0.3%. VajraV1-Xlarge achieves 56.2% mAP, outperforming all existing real-time object detectors.

</details>


### [9] [MoLingo: Motion-Language Alignment for Text-to-Motion Generation](https://arxiv.org/abs/2512.13840)
*Yannan He,Garvita Tiwari,Xiaohan Zhang,Pankaj Bora,Tolga Birdal,Jan Eric Lenssen,Gerard Pons-Moll*

Main category: cs.CV

TL;DR: MoLingo是一种新的文本到运动生成模型，通过在连续潜空间中去噪生成逼真的人体动作，并在对齐语义潜空间与多Token交叉注意力条件下，实现了业界领先的动作生成效果。


<details>
  <summary>Details</summary>
Motivation: 目前的文本到动作生成方法在潜空间扩散中准确性与语义对齐仍有限，尤其在如何构建适合扩散的运动潜空间及文本条件注入策略方面存在不足。该研究致力于解决潜空间的语义对齐与文本条件高效融合的问题。

Method: 提出以帧级文本标签训练的语义对齐运动编码器，使语义相关的潜变量在空间上接近，增强潜空间对扩散的友好性。同时，比较了单Token与多Token交叉注意力的文本注入方式，最终采用交叉注意力以提升动作与文本的一致性和现实感。此外，结合自回归生成策略。

Result: 模型在标准评测指标和用户实验中都达到了新的业界最佳表现，在动作逼真度和文本一致性上优于现有方法。

Conclusion: 通过语义对齐的潜空间编码、自回归生成和多Token交叉注意力机制，MoLingo实现了更优的文本到运动生成性能，并计划开源代码促进后续研究和应用。

Abstract: We introduce MoLingo, a text-to-motion (T2M) model that generates realistic, lifelike human motion by denoising in a continuous latent space. Recent works perform latent space diffusion, either on the whole latent at once or auto-regressively over multiple latents. In this paper, we study how to make diffusion on continuous motion latents work best. We focus on two questions: (1) how to build a semantically aligned latent space so diffusion becomes more effective, and (2) how to best inject text conditioning so the motion follows the description closely. We propose a semantic-aligned motion encoder trained with frame-level text labels so that latents with similar text meaning stay close, which makes the latent space more diffusion-friendly. We also compare single-token conditioning with a multi-token cross-attention scheme and find that cross-attention gives better motion realism and text-motion alignment. With semantically aligned latents, auto-regressive generation, and cross-attention text conditioning, our model sets a new state of the art in human motion generation on standard metrics and in a user study. We will release our code and models for further research and downstream usage.

</details>


### [10] [Improvise, Adapt, Overcome -- Telescopic Adapters for Efficient Fine-tuning of Vision Language Models in Medical Imaging](https://arxiv.org/abs/2512.13855)
*Ujjwal Mishra,Vinita Shukla,Praful Hambarde,Amit Shukla*

Main category: cs.CV

TL;DR: 本文提出了一种新的参数高效微调框架——Telescopic Adapters，在医疗影像分割任务中大幅减少所需训练参数的同时，提升了模型适应性和准确率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言分割模型（VLSMs）在医疗影像领域微调时需大量算力，且现有高效微调法对各层适配器参数分配不合理，影响了模型优化效率。

Method: 提出Telescopic Adapters，通过层深自适应扩展适配器容量，在CLIPSeg编码器内以瓶颈模块注入，依据层深和语义相关性动态调整参数配置。

Result: 仅用61.3万可训练参数（比全量微调少244倍），在息肉分割、皮肤病变检测和乳腺超声等五个医疗数据集上均优于现有方法。消融研究证明深层比浅层更需适应能力，验证了提出的层深扩展假设。

Conclusion: Telescopic Adapters为医疗VLSM高效微调树立了新范式，在计算资源有限的临床环境下也能保证优异分割表现。

Abstract: Adapting Vision Language Segmentation Models (VLSMs) to medical imaging domains requires significant computational overhead when using conventional fine-tuning approaches. Existing Parameter-Efficient Fine-Tuning (PEFT) methods apply uniform adapter dimensions across all transformer layers, leading to suboptimal parameter allocation and reduced adaptation efficiency. We introduce Telescopic Adapters, a novel PEFT framework that employs depth-aware scaling to progressively increase adapter capacity from shallow to deep transformer layers. Our method integrates lightweight bottleneck modules within CLIPSeg's vision and text encoders, with adapter dimensions dynamically scaled based on layer depth and semantic relevance. Using only 613k trainable parameters--244x fewer than end-to-end fine-tuning, Telescopic Adapters achieve superior performance across five diverse medical datasets spanning polyp segmentation, skin lesion detection, and breast ultrasound imaging. Comprehensive ablation studies demonstrate that deeper layers require substantially more adaptation capacity than shallow layers, validating our telescopic scaling hypothesis. Our approach establishes a new paradigm for efficient medical VLSM fine-tuning, enabling deployment in resource-constrained clinical environments while maintaining competitive segmentation accuracy.

</details>


### [11] [Coarse-to-Fine Hierarchical Alignment for UAV-based Human Detection using Diffusion Models](https://arxiv.org/abs/2512.13869)
*Wenda Li,Meng Wu,Sungmin Eum,Heesung Kwon,Qing Qu*

Main category: cs.CV

TL;DR: 本文解决了无人机人类检测中合成数据与真实数据之间域差距大的问题，提出了一种三阶段的扩散模型CFHA，实现合成数据向真实数据的域对齐，并有效提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 无人机（UAV）进行人类检测时，数据标注代价高且真实带标注的数据稀缺。为降低标注成本，通常采用仿真器生成合成数据，但由于合成与真实图像之间存在较大域差，导致模型在真实场景下表现不佳。因此需要缩小合成与真实数据间的差距。

Method: 提出CFHA（三阶段扩散模型框架）：（1）全局风格迁移模块，通过扩散模型将合成图像的颜色、光照、纹理对齐为真实风格；（2）局部细化模块，利用超分辨扩散模型提升小目标（如人）细节和边界表现；（3）幻觉移除模块，筛除与真实数据属性不符的人体实例，从而使合成数据分布更贴近真实数据。

Result: 在公开的UAV Sim2Real检测基准上进行实验，CFHA显著提升了检测准确率。具体在Semantic-Drone基准上比未变换基线方法mAP50提升最多达14.1个百分点。消融实验进一步验证了全局与局部对齐模块的互补性及分层对齐的重要性。

Conclusion: CFHA能有效解决合成与真实域差距的问题，大幅提升无人机人类检测的准确率。分层、粗到细的对齐策略是实现高性能Sim2Real检测模型的关键。

Abstract: Training object detectors demands extensive, task-specific annotations, yet this requirement becomes impractical in UAV-based human detection due to constantly shifting target distributions and the scarcity of labeled images. As a remedy, synthetic simulators are adopted to generate annotated data, with a low annotation cost. However, the domain gap between synthetic and real images hinders the model from being effectively applied to the target domain. Accordingly, we introduce Coarse-to-Fine Hierarchical Alignment (CFHA), a three-stage diffusion-based framework designed to transform synthetic data for UAV-based human detection, narrowing the domain gap while preserving the original synthetic labels. CFHA explicitly decouples global style and local content domain discrepancies and bridges those gaps using three modules: (1) Global Style Transfer -- a diffusion model aligns color, illumination, and texture statistics of synthetic images to the realistic style, using only a small real reference set; (2) Local Refinement -- a super-resolution diffusion model is used to facilitate fine-grained and photorealistic details for the small objects, such as human instances, preserving shape and boundary integrity; (3) Hallucination Removal -- a module that filters out human instances whose visual attributes do not align with real-world data to make the human appearance closer to the target distribution. Extensive experiments on public UAV Sim2Real detection benchmarks demonstrate that our methods significantly improve the detection accuracy compared to the non-transformed baselines. Specifically, our method achieves up to $+14.1$ improvement of mAP50 on Semantic-Drone benchmark. Ablation studies confirm the complementary roles of the global and local stages and highlight the importance of hierarchical alignment. The code is released at \href{https://github.com/liwd190019/CFHA}{this url}.

</details>


### [12] [SAGE: Training Smart Any-Horizon Agents for Long Video Reasoning with Reinforcement Learning](https://arxiv.org/abs/2512.13874)
*Jitesh Jain,Jialuo Li,Zixian Ma,Jieyu Zhang,Chris Dongjoo Kim,Sangho Lee,Rohun Tripathi,Tanmay Gupta,Christopher Clark,Humphrey Shi*

Main category: cs.CV

TL;DR: 本文提出了SAGE系统，实现了基于人类灵感的可变时长视频推理，能灵活处理短视频与长视频，并通过多项创新方法和数据集推动了视频推理任务的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有视频推理模型通常采用单步推理并处理大量帧，类似“看完所有长视频”，资源消耗大且不灵活。人类可以根据任务需要灵活选择“快速略读”或“完整观看”，作者希望模型也能具备这种能力。

Method: 1）提出SAGE智能体系统，既能多步推理长视频，也能一步解决简单问题；2）设计数据生成流程，通过Gemini-2.5-Flash 合成数据训练 SAGE-MM 协调器；3）引入强化学习后训练方法，赋予模型可变时长推理能力；4）构建SAGE-Bench长时视频推理基准测试集。

Result: 在实际任务和基准测试中，使用所提系统、数据和RL训练后，视频推理任务表现提升明显，其中整体提升达6.1%，长于10分钟视频任务提升达8.2%。

Conclusion: 本工作首次实现了类似人类的任意时长（any-horizon）视频推理，并通过结合合成数据、RL训练和新基准测试，显著提升了长视频推理性能，为未来视频理解系统的灵活推理提供了新方向。

Abstract: As humans, we are natural any-horizon reasoners, i.e., we can decide whether to iteratively skim long videos or watch short ones in full when necessary for a given task. With this in mind, one would expect video reasoning models to reason flexibly across different durations. However, SOTA models are still trained to predict answers in a single turn while processing a large number of frames, akin to watching an entire long video, requiring significant resources. This raises the question: Is it possible to develop performant any-horizon video reasoning systems? Inspired by human behavior, we first propose SAGE, an agent system that performs multi-turn reasoning on long videos while handling simpler problems in a single turn. Secondly, we introduce an easy synthetic data generation pipeline using Gemini-2.5-Flash to train the orchestrator, SAGE-MM, which lies at the core of SAGE. We further propose an effective RL post-training recipe essential for instilling any-horizon reasoning ability in SAGE-MM. Thirdly, we curate SAGE-Bench with an average duration of greater than 700 seconds for evaluating video reasoning ability in real-world entertainment use cases. Lastly, we empirically validate the effectiveness of our system, data, and RL recipe, observing notable improvements of up to 6.1% on open-ended video reasoning tasks, as well as an impressive 8.2% improvement on videos longer than 10 minutes.

</details>


### [13] [Route-DETR: Pairwise Query Routing in Transformers for Object Detection](https://arxiv.org/abs/2512.13876)
*Ye Zhang,Qi Chen,Wenyou Huang,Rui Liu,Zhengjian Kang*

Main category: cs.CV

TL;DR: 本论文提出Route-DETR，通过自适应路由机制改进DETR目标检测器，有效减少冗余计算并提升检测性能，在多个基线和数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: DETR虽然简化了目标检测流程，但存在查询竞争问题，导致多个查询聚集在同一目标位置，浪费计算资源且降低检测效率。

Method: 作者设计了基于解码器自注意力层的自适应对偶路由机制，利用查询间的相似度、置信度和几何信息区分竞争查询与互补查询。抑制（suppressor）路由用于减少竞争查询的重复关注，分派（delegator）路由鼓励探索更多区域。实现方法是在自注意力中添加可学习的低秩偏置，并采用双分支训练策略，仅在训练时启用路由机制，推理阶段无额外计算开销。

Result: 在COCO和Cityscapes等数据集以及多个DETR变体上均有提升，如在ResNet-50+DINO基线上提升1.7%的mAP，在Swin-L基线上达到57.6%的mAP，超越了以往最佳水平。

Conclusion: Route-DETR可显著缓解DETR中的查询竞争问题，提高了目标检测准确性，且不增加推理计算量，展现了良好的扩展和应用前景。

Abstract: Detection Transformer (DETR) offers an end-to-end solution for object detection by eliminating hand-crafted components like non-maximum suppression. However, DETR suffers from inefficient query competition where multiple queries converge to similar positions, leading to redundant computations. We present Route-DETR, which addresses these issues through adaptive pairwise routing in decoder self-attention layers. Our key insight is distinguishing between competing queries (targeting the same object) versus complementary queries (targeting different objects) using inter-query similarity, confidence scores, and geometry. We introduce dual routing mechanisms: suppressor routes that modulate attention between competing queries to reduce duplication, and delegator routes that encourage exploration of different regions. These are implemented via learnable low-rank attention biases enabling asymmetric query interactions. A dual-branch training strategy incorporates routing biases only during training while preserving standard attention for inference, ensuring no additional computational cost. Experiments on COCO and Cityscapes demonstrate consistent improvements across multiple DETR baselines, achieving +1.7% mAP gain over DINO on ResNet-50 and reaching 57.6% mAP on Swin-L, surpassing prior state-of-the-art models.

</details>


### [14] [KLO-Net: A Dynamic K-NN Attention U-Net with CSP Encoder for Efficient Prostate Gland Segmentation from MRI](https://arxiv.org/abs/2512.13902)
*Anning Tian,Byunghyun Ko,Kaichen Qu,Mengyuan Liu,Jeongkyu Lee*

Main category: cs.CV

TL;DR: 本文提出了一种高效的前列腺MRI分割模型KLO-Net，该方法在保证分割精度的同时，显著降低了计算和内存负担，适合于临床实时部署。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习前列腺分割方法面对解剖结构变异性时，准确性和效率难以兼顾，且高性能模型的计算负载与内存占用难以满足临床工作站实时部署需求。

Method: 作者提出了KLO-Net模型，结合了动态K近邻注意力机制和跨阶段部分（CSP）编码结构。动态K-NN注意力机制能自适应调整每个空间位置的注意力连接数，提升分割适应性；CSP模块降低了整体计算和内存消耗。

Result: 在PROMISE12和PROSTATEx两个公共数据集上进行了充分的实验和消融研究，结果显示KLO-Net相较现有方法在分割精度与效率方面具备显著优势。

Conclusion: KLO-Net在保证分割质量的基础上，大幅提升了计算效率和内存利用率，为前列腺MRI分割临床实时应用提供了可行方案。

Abstract: Real-time deployment of prostate MRI segmentation on clinical workstations is often bottlenecked by computational load and memory footprint. Deep learning-based prostate gland segmentation approaches remain challenging due to anatomical variability. To bridge this efficiency gap while still maintaining reliable segmentation accuracy, we propose KLO-Net, a dynamic K-Nearest Neighbor attention U-Net with Cross Stage Partial, i.e., CSP, encoder for efficient prostate gland segmentation from MRI scan. Unlike the regular K-NN attention mechanism, the proposed dynamic K-NN attention mechanism allows the model to adaptively determine the number of attention connections for each spatial location within a slice. In addition, CSP blocks address the computational load to reduce memory consumption. To evaluate the model's performance, comprehensive experiments and ablation studies are conducted on two public datasets, i.e., PROMISE12 and PROSTATEx, to validate the proposed architecture. The detailed comparative analysis demonstrates the model's advantage in computational efficiency and segmentation quality.

</details>


### [15] [An evaluation of SVBRDF Prediction from Generative Image Models for Appearance Modeling of 3D Scenes](https://arxiv.org/abs/2512.13950)
*Alban Gauthier,Valentin Deschaintre,Alexandre Lanvin,Fredo Durand,Adrien Bousseau,George Drettakis*

Main category: cs.CV

TL;DR: 本文探讨如何结合深度生成模型和SVBRDF预测网络，高效生成3D场景的高质量材质贴图，并分析多视角一致性和网络设计的关键。


<details>
  <summary>Details</summary>
Motivation: 当前3D场景纹理和材质建模虽有提升，但多视角的一致性和快速高质量贴图创建仍具挑战。作者旨在分析并提升SVBRDF预测流程的效率与精度。

Method: 结合条件生成的RGB图像与SVBRDF预测网络，从不同视角生成SVBRDF贴图，研究不同神经网络架构、条件输入对精度与一致性的影响，并进行系统性比较。

Result: 发现单视角预测易带来多视角不一致，但条件生成图像的多模态特征有助提升结果。实验显示标准UNet性能可与更复杂设计媲美，并在准确性与一致性方面表现良好。

Conclusion: SVBRDF预测在深度生成辅助的管线中表现出更多潜力，合理选择条件和网络结构可实现高效高质量的材质建模。

Abstract: Digital content creation is experiencing a profound change with the advent of deep generative models. For texturing, conditional image generators now allow the synthesis of realistic RGB images of a 3D scene that align with the geometry of that scene. For appearance modeling, SVBRDF prediction networks recover material parameters from RGB images. Combining these technologies allows us to quickly generate SVBRDF maps for multiple views of a 3D scene, which can be merged to form a SVBRDF texture atlas of that scene. In this paper, we analyze the challenges and opportunities for SVBRDF prediction in the context of such a fast appearance modeling pipeline. On the one hand, single-view SVBRDF predictions might suffer from multiview incoherence and yield inconsistent texture atlases. On the other hand, generated RGB images, and the different modalities on which they are conditioned, can provide additional information for SVBRDF estimation compared to photographs. We compare neural architectures and conditions to identify designs that achieve high accuracy and coherence. We find that, surprisingly, a standard UNet is competitive with more complex designs. Project page: http://repo-sam.inria.fr/nerphys/svbrdf-evaluation

</details>


### [16] [From Unlearning to UNBRANDING: A Benchmark for Trademark-Safe Text-to-Image Generation](https://arxiv.org/abs/2512.13953)
*Dawid Malarz,Artur Kasymov,Filip Manjak,Maciej Zięba,Przemysław Spurek*

Main category: cs.CV

TL;DR: 本文提出了“unbranding”任务，旨在从文本到图像的扩散模型中细致移除品牌相关标识（包括商标和结构性特征），以防止未经授权地再现商标内容，并为研究此问题构建了基准数据集和新的评测指标。


<details>
  <summary>Details</summary>
Motivation: 随着文本到图像扩散模型的发展，出现了模型能够无意间生成带有品牌标识及特征的图片，带来商标侵权风险。而现有方法主要针对风格、名人等一般概念，未能解决品牌识别中的具体元素，尤其是抽象或结构性的品牌特征。

Method: 1) 提出unbranding任务，目标是细粒度地从图像中移除显性和隐性的品牌特征（如标志、结构特征等），同时保持图像的语义一致性。2) 构建包含多种品牌元素的基准数据集。3) 设计了一种基于视觉-语言模型（VLM）的新评测指标，通过问答方式同时检测图像中的明确品牌标志和隐含的整体品牌特征。

Result: 建立的新基准和VLM评分标准可以有效检测模型生成中的品牌元素，并量化unbranding任务的效果。实验发现，新一代扩散模型（如SDXL、FLUX）更容易合成品牌特征，说明unbranding任务越来越重要。VLM指标的结果也验证了该任务的独特性和实际需求。

Conclusion: unbranding是一个与实际紧密相关、独立于传统去标志问题的新任务，对防止生成模型侵犯商标权具有重要意义。相比单纯去除logo，该任务需要专门技术和新的评价方法。

Abstract: The rapid progress of text-to-image diffusion models raises significant concerns regarding the unauthorized reproduction of trademarked content. While prior work targets general concepts (e.g., styles, celebrities), it fails to address specific brand identifiers. Crucially, we note that brand recognition is multi-dimensional, extending beyond explicit logos to encompass distinctive structural features (e.g., a car's front grille). To tackle this, we introduce unbranding, a novel task for the fine-grained removal of both trademarks and subtle structural brand features, while preserving semantic coherence. To facilitate research, we construct a comprehensive benchmark dataset. Recognizing that existing brand detectors are limited to logos and fail to capture abstract trade dress (e.g., the shape of a Coca-Cola bottle), we introduce a novel evaluation metric based on Vision Language Models (VLMs). This VLM-based metric uses a question-answering framework to probe images for both explicit logos and implicit, holistic brand characteristics. Furthermore, we observe that as model fidelity increases, with newer systems (SDXL, FLUX) synthesizing brand identifiers more readily than older models (Stable Diffusion), the urgency of the unbranding challenge is starkly highlighted. Our results, validated by our VLM metric, confirm unbranding is a distinct, practically relevant problem requiring specialized techniques. Project Page: https://gmum.github.io/UNBRANDING/.

</details>


### [17] [Quality-Driven and Diversity-Aware Sample Expansion for Robust Marine Obstacle Segmentation](https://arxiv.org/abs/2512.13970)
*Miaohua Zhang,Mohammad Ali Armin,Xuesong Li,Sisi Liang,Lars Petersson,Changming Sun,David Ahmedt-Aristizabal,Zeeshan Hayder*

Main category: cs.CV

TL;DR: 本文提出了一种用于海洋障碍物检测的新型数据扩增方法，通过高质量、具多样性的合成样本提升分割鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在海洋环境下，阳光反射、雾、复杂的波浪等因素会严重影响图像质量，导致障碍物检测变得困难。与此同时，真实海洋数据稀缺且结构重复，限制了模型训练数据的多样性和泛化能力。

Method: 提出了一种完全在推理阶段生成的样本扩增流程，无需重新训练扩散模型。主要包括两部分：(1) 类感知风格库，用于构建高熵、语义丰富的提示词提升样本多样性；(2) 自适应退火采样器，在早期扰动条件下，通过COD引导的比例控制器调节扰动，兼顾多样性和布局保真。

Result: 在多个海洋障碍物分割基准上，用所合成的高质量样本进行训练，有效提升了多种分割主干网络的性能，尤其在稀有和对纹理敏感的类别上增强了视觉多样性和鲁棒性。

Conclusion: 该方法无需扩散模型重训练，能通过高质量、高多样性的合成数据提升实际海洋障碍物检测效果，对改善在恶劣环境下的分割表现非常有效。

Abstract: Marine obstacle detection demands robust segmentation under challenging conditions, such as sun glitter, fog, and rapidly changing wave patterns. These factors degrade image quality, while the scarcity and structural repetition of marine datasets limit the diversity of available training data. Although mask-conditioned diffusion models can synthesize layout-aligned samples, they often produce low-diversity outputs when conditioned on low-entropy masks and prompts, limiting their utility for improving robustness. In this paper, we propose a quality-driven and diversity-aware sample expansion pipeline that generates training data entirely at inference time, without retraining the diffusion model. The framework combines two key components:(i) a class-aware style bank that constructs high-entropy, semantically grounded prompts, and (ii) an adaptive annealing sampler that perturbs early conditioning, while a COD-guided proportional controller regulates this perturbation to boost diversity without compromising layout fidelity. Across marine obstacle benchmarks, augmenting training data with these controlled synthetic samples consistently improves segmentation performance across multiple backbones and increases visual variation in rare and texture-sensitive classes.

</details>


### [18] [XAI-Driven Diagnosis of Generalization Failure in State-Space Cerebrovascular Segmentation Models: A Case Study on Domain Shift Between RSNA and TopCoW Datasets](https://arxiv.org/abs/2512.13977)
*Youssef Abuzeid,Shimaa El-Bana,Ahmad Al-Kabbany*

Main category: cs.CV

TL;DR: 该论文提出了一种两阶段的方法来诊断深度学习模型（尤其是UMamaba状态空间模型）在脑血管分割任务中的泛化失败，利用可解释性方法（Seg-XRes-CAM）证明模型在存在领域差异的数据集上未能关注真实解剖特征，揭示可解释AI可用于识别和理解医疗影像AI模型的偏差。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在医学影像领域的应用受到领域差异（domain shift）严重限制，高性能模型在外部数据集上容易失效，阻碍了AI在临床的可信部署。论文旨在明确诊断这一失败背后的具体原因，而不仅关心最终指标。

Method: 提出两阶段方法。第一阶段，建立来源（RSNA CTA动脉瘤）与目标（TopCoW Willis环CT）数据集的可量化领域差异（如Z轴分辨率、背景噪声）。第二阶段，利用Seg-XRes-CAM可解释性技术分析模型注意力区域与真值分割和预测分割的重叠程度，定量诊断泛化失败的原因。

Result: 领域差异显著，模型Dice分数从来源集的0.8604骤降到目标集的0.2902。注意力分析表明，模型在目标域放弃了对真实脑血管解剖结构的关注，仅关注自己错误预测的区域，IoU指标明显降低。

Conclusion: 可解释AI可作为有效诊断工具，揭示新兴架构模型在域转移下存在偏见和错误聚焦，为改进医学影像AI模型的泛化和可信性提供了方法论参考。

Abstract: The clinical deployment of deep learning models in medical imaging is severely hindered by domain shift. This challenge, where a high-performing model fails catastrophically on external datasets, is a critical barrier to trustworthy AI. Addressing this requires moving beyond simple performance metrics toward deeper understanding, making Explainable AI (XAI) an essential diagnostic tool in medical image analysis. We present a rigorous, two-phase approach to diagnose the generalization failure of state-of-the-art State-Space Models (SSMs), specifically UMamaba, applied to cerebrovascular segmentation. We first established a quantifiable domain gap between our Source (RSNA CTA Aneurysm) and Target (TopCoW Circle of Willis CT) datasets, noting significant differences in Z-resolution and background noise. The model's Dice score subsequently plummeted from 0.8604 (Source) to 0.2902 (Target). In the second phase, which is our core contribution, we utilized Seg-XRes-CAM to diagnose the cause of this failure. We quantified the model's focus by measuring the overlap between its attention maps and the Ground Truth segmentations, and between its attention maps and its own Prediction Mask. Our analysis proves the model failed to generalize because its attention mechanism abandoned true anatomical features in the Target domain. Quantitative metrics confirm the model's focus shifted away from the Ground Truth vessels (IoU~0.101 at 0.3 threshold) while still aligning with its own wrong predictions (IoU~0.282 at 0.3 threshold). This demonstrates the model learned spurious correlations, confirming XAI is a powerful diagnostic tool for identifying dataset bias in emerging architectures.

</details>


### [19] [FocalComm: Hard Instance-Aware Multi-Agent Perception](https://arxiv.org/abs/2512.13982)
*Dereje Shenkut,Vijayakumar Bhagavatula*

Main category: cs.CV

TL;DR: 本文提出了一种名为FocalComm的多智能体协同感知框架，通过挖掘难检测实例的特征并进行有针对性的特征交流，显著提升了自动驾驶场景中对行人等易漏检目标的感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体协同感知方法在提升车辆检测表现的同时，对于体积较小但安全性要求更高的目标（如行人）表现不佳，且普遍采取全特征共享，效率低且难以降低检测漏报，易对安全造成影响。

Method: FocalComm包含两个核心新设计：一是自适应的渐进式难例挖掘模块（HIM），为每个智能体挑选出与难检测目标相关的特征；二是基于查询机制的特征级中间融合方法，在信息交换过程中动态赋予这些特征不同权重，使得协同更关注有助于减少漏检的特征。

Result: FocalComm在V2X-Real和DAIR-V2X两个真实多源数据集上，实现了优于现有协同感知方法的检测效果，特别是在面向行人的检测任务中取得了显著提升。

Conclusion: 通过专注于难检测实例的特征挖掘和有针对性的特征交流，FocalComm能够有效提升多智能体协同感知系统在高安全需求场景下的实际表现，尤其有助于行人检测这类安全关键目标。

Abstract: Multi-agent collaborative perception (CP) is a promising paradigm for improving autonomous driving safety, particularly for vulnerable road users like pedestrians, via robust 3D perception. However, existing CP approaches often optimize for vehicle detection performance metrics, underperforming on smaller, safety-critical objects such as pedestrians, where detection failures can be catastrophic. Furthermore, previous CP methods rely on full feature exchange rather than communicating only salient features that help reduce false negatives. To this end, we present FocalComm, a novel collaborative perception framework that focuses on exchanging hard-instance-oriented features among connected collaborative agents. FocalComm consists of two key novel designs: (1) a learnable progressive hard instance mining (HIM) module to extract hard instance-oriented features per agent, and (2) a query-based feature-level (intermediate) fusion technique that dynamically weights these identified features during collaboration. We show that FocalComm outperforms state-of-the-art collaborative perception methods on two challenging real-world datasets (V2X-Real and DAIR-V2X) across both vehicle-centric and infrastructure-centric collaborative setups. FocalComm also shows a strong performance gain in pedestrian detection in V2X-Real.

</details>


### [20] [Repurposing 2D Diffusion Models for 3D Shape Completion](https://arxiv.org/abs/2512.13991)
*Yao He,Youngjoong Kwon,Tiange Xiang,Wenxiao Cai,Ehsan Adeli*

Main category: cs.CV

TL;DR: 本文提出了一种将2D扩散模型适配到3D形状补全的新框架，通过创新性地引入Shape Atlas（形状图谱），将3D点云转换为精炼的2D表示，从而充分利用2D预训练扩散模型的生成能力，实现高质量的3D形状补全。


<details>
  <summary>Details</summary>
Motivation: 2D文本-图像扩散模型由于丰富的2D数据而取得巨大成功，但3D扩散模型因高质量3D数据稀缺及3D输入与2D潜空间间存在模态差距而发展缓慢。现有3D补全方法难以充分利用2D生成模型，因此需要新方法弥合2D和3D模型间的差距。

Method: 方法核心为Shape Atlas，一种能将3D几何点云压缩为2D紧凑表示的技术，以此桥接3D输入和2D扩散模型间的模态不匹配。利用Shape Atlas，论文在条件输入和输出空间实现了高效对齐，可最大化利用已有2D预训练模型，实现高效、数据利用率高的3D形状补全。

Result: 在PCN和ShapeNet-55等常用3D数据集上，方法取得了高质量、细节丰富的形状补全过程。同时，作者展示了该方法生成的点云可支持艺术级Mesh建模，体现其实用价值。

Conclusion: Shape Atlas框架可有效利用2D扩散模型进行3D形状补全，缓解了3D数据稀缺和模态不匹配问题，在提升补全质量及细节表现力的同时，具有良好的实际应用潜力。

Abstract: We present a framework that adapts 2D diffusion models for 3D shape completion from incomplete point clouds. While text-to-image diffusion models have achieved remarkable success with abundant 2D data, 3D diffusion models lag due to the scarcity of high-quality 3D datasets and a persistent modality gap between 3D inputs and 2D latent spaces. To overcome these limitations, we introduce the Shape Atlas, a compact 2D representation of 3D geometry that (1) enables full utilization of the generative power of pretrained 2D diffusion models, and (2) aligns the modalities between the conditional input and output spaces, allowing more effective conditioning. This unified 2D formulation facilitates learning from limited 3D data and produces high-quality, detail-preserving shape completions. We validate the effectiveness of our results on the PCN and ShapeNet-55 datasets. Additionally, we show the downstream application of creating artist-created meshes from our completed point clouds, further demonstrating the practicality of our method.

</details>


### [21] [Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models](https://arxiv.org/abs/2512.14008)
*Shufan Li,Jiuxiang Gu,Kangning Liu,Zhe Lin,Zijun Wei,Aditya Grover,Jason Kuen*

Main category: cs.CV

TL;DR: 本文提出Sparse-LaViDa框架，通过动态剪除无用的mask tokens并引入register tokens，显著加快了MDM采样速度，且不损失生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有Masked Discrete Diffusion Models在多模态任务表现优异，但推理速度较慢，因为每一步都需处理大量冗余的mask tokens。本工作旨在解决推理阶段速度瓶颈。

Method: 提出Sparse-LaViDa，通过在每次推理时动态裁剪不必要的mask tokens，加速采样。为避免生成质量下降，引入register tokens来紧凑表示被裁剪的信息；通过特殊attention mask设计，确保训练和推理过程的一致性。

Result: Sparse-LaViDa在文本生成图像、图像编辑、数学推理等多任务上，实现了高达2倍的推理加速，并保持了生成质量。

Conclusion: Sparse-LaViDa能够有效提升MDM模型的推理效率，为相关多模态任务带来更高效的应用前景，同时保证生成结果的质量不下降。

Abstract: Masked Discrete Diffusion Models (MDMs) have achieved strong performance across a wide range of multimodal tasks, including image understanding, generation, and editing. However, their inference speed remains suboptimal due to the need to repeatedly process redundant masked tokens at every sampling step. In this work, we propose Sparse-LaViDa, a novel modeling framework that dynamically truncates unnecessary masked tokens at each inference step to accelerate MDM sampling. To preserve generation quality, we introduce specialized register tokens that serve as compact representations for the truncated tokens. Furthermore, to ensure consistency between training and inference, we design a specialized attention mask that faithfully matches the truncated sampling procedure during training. Built upon the state-of-the-art unified MDM LaViDa-O, Sparse-LaViDa achieves up to a 2x speedup across diverse tasks including text-to-image generation, image editing, and mathematical reasoning, while maintaining generation quality.

</details>


### [22] [KFS-Bench: Comprehensive Evaluation of Key Frame Sampling in Long Video Understanding](https://arxiv.org/abs/2512.14017)
*Zongyao Li,Kengo Ishida,Satoshi Yamazaki,Xiaotong Ji,Jianquan Liu*

Main category: cs.CV

TL;DR: 本文提出了KFS-Bench，这是第一个专注于长视频问答（QA）中关键帧采样的基准数据集，通过多场景标注来直接评价采样策略，有效推动长视频理解和多模态大模型的发展。


<details>
  <summary>Details</summary>
Motivation: 在长视频QA任务中，挑选信息丰富的关键帧可以提升大模型的准确性和效率，但此前缺乏能直接评估帧采样质量的公开基准数据集。

Method: 1. 构建了KFS-Bench基准，提供了针对每个问题需要的多不相交场景的人工标注。2. 综合评测现有关键帧采样方法，分析关键因素如采样精度、场景覆盖率与采样均衡性。3. 设计了与QA准确率相关的新采样质量指标。4. 提出了基于问题与视频相关性的自适应采样新方法，实现采样多样性与相似性的平衡。

Result: 发现采样精度、场景覆盖率与均衡性均会显著影响QA性能。提出的新评估指标与QA准确率高度相关，创新的自适应采样方法在采样与问答表现上均超过以往方法。

Conclusion: KFS-Bench实现了关键帧采样策略的直接、公平、系统性评估，同时提出的新方法和指标推动了相关研究的发展，为长视频理解提供了强有力的工具。

Abstract: We propose KFS-Bench, the first benchmark for key frame sampling in long video question answering (QA), featuring multi-scene annotations to enable direct and robust evaluation of sampling strategies. Key frame sampling is crucial for efficient long-form video understanding. In long video QA, selecting informative frames enables multimodal large language models (MLLMs) to improve both accuracy and efficiency. KFS-Bench addresses the limitation of prior works that only indirectly assess frame selection quality via QA accuracy. By providing ground-truth annotations of multiple disjoint scenes required per question, KFS-Bench allows us to directly analyze how different sampling approaches capture essential content across an entire long video. Using KFS-Bench, we conduct a comprehensive study of key frame sampling methods and identify that not only sampling precision but also scene coverage and sampling balance are the key factors influencing QA performance. Regarding all the factors, we design a novel sampling quality metric that correlates with QA accuracy. Furthermore, we develop a novel key frame sampling method that leverages question-video relevance to balance sampling diversity against question-frame similarity, thereby improving coverage of relevant scenes. Our adaptively balanced sampling approach achieves superior performance in both key frame sampling and QA performance. The benchmark is available at https://github.com/NEC-VID/KFS-Bench.

</details>


### [23] [DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos](https://arxiv.org/abs/2512.14217)
*Yang Bai,Liudi Yang,George Eskandar,Fengyi Shen,Mohammad Altillawi,Ziyuan Liu,Gitta Kutyniok*

Main category: cs.CV

TL;DR: 本文提出了DRAW2ACT，一种结合多模态（深度信息等）轨迹条件的视频扩散生成框架，可提高机器人操作任务中的视频生成可控性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有视频扩散模型支持具身智能的仿真，但在控制性方面有限；近期工作虽引入了轨迹条件，但多依赖二维轨迹或单模态，难以生成高质量、可控且一致的机器人操作示范。

Method: 1. 提出深度感知的轨迹条件视频生成框架DRAW2ACT，从轨迹中提取深度、语义、形状和运动等多正交特征，注入扩散模型。
2. 设计跨模态注意力机制与深度监督，同时生成空间对齐的RGB与深度视频，提高空间和时间一致性。
3. 引入多模态策略模型，基于生成的视频序列回归机器人关节角度。

Result: 在Bridge V2、Berkeley Autolab及仿真基准上，DRAW2ACT展现出更优的视觉保真度和一致性，并在操作任务中成功率超越现有方法。

Conclusion: DRAW2ACT显著提升了轨迹条件视频生成在机器人操作领域的可控性、一致性和实用性，为未来多模态可控视频生成及具身智能应用打开新方向。

Abstract: Video diffusion models provide powerful real-world simulators for embodied AI but remain limited in controllability for robotic manipulation. Recent works on trajectory-conditioned video generation address this gap but often rely on 2D trajectories or single modality conditioning, which restricts their ability to produce controllable and consistent robotic demonstrations. We present DRAW2ACT, a depth-aware trajectory-conditioned video generation framework that extracts multiple orthogonal representations from the input trajectory, capturing depth, semantics, shape and motion, and injects them into the diffusion model. Moreover, we propose to jointly generate spatially aligned RGB and depth videos, leveraging cross-modality attention mechanisms and depth supervision to enhance the spatio-temporal consistency. Finally, we introduce a multimodal policy model conditioned on the generated RGB and depth sequences to regress the robot's joint angles. Experiments on Bridge V2, Berkeley Autolab, and simulation benchmarks show that DRAW2ACT achieves superior visual fidelity and consistency while yielding higher manipulation success rates compared to existing baselines.

</details>


### [24] [Deep Learning Perspective of Scene Understanding in Autonomous Robots](https://arxiv.org/abs/2512.14020)
*Afia Maham,Dur E Nayab Tashfa*

Main category: cs.CV

TL;DR: 本文综述了深度学习在自主机器人场景理解中的应用，如目标检测、语义与实例分割、深度估计、三维重建和视觉SLAM，并指出其相较于传统方法的优势和未来方向。


<details>
  <summary>Details</summary>
Motivation: 传统几何模型在自主机器人场景理解中存在感知能力局限，如难以实时准确处理遮挡、无纹理表面等场景。因此，迫切需要借助深度学习方法提升自主机器人的环境理解能力。

Method: 系统梳理了深度学习方法在目标检测、语义与实例分割、深度估计、三维重建、视觉SLAM等场景理解任务中的创新及应用，特别关注这些方法对实时感知和语义推理的改进。

Result: 集成后的深度学习感知模块在动态无结构环境下，显著提升了机器人的决策、导航与交互能力，能更好地理解和响应真实世界。

Conclusion: 深度学习方法有效突破了传统视觉感知局限，但仍面临诸如泛化性、鲁棒性等挑战。未来研究应聚焦提升自主机器人场景理解精度与稳定性等问题。

Abstract: This paper provides a review of deep learning applications in scene understanding in autonomous robots, including innovations in object detection, semantic and instance segmentation, depth estimation, 3D reconstruction, and visual SLAM. It emphasizes how these techniques address limitations of traditional geometric models, improve depth perception in real time despite occlusions and textureless surfaces, and enhance semantic reasoning to understand the environment better. When these perception modules are integrated into dynamic and unstructured environments, they become more effective in decisionmaking, navigation and interaction. Lastly, the review outlines the existing problems and research directions to advance learning-based scene understanding of autonomous robots.

</details>


### [25] [History-Enhanced Two-Stage Transformer for Aerial Vision-and-Language Navigation](https://arxiv.org/abs/2512.14222)
*Xichen Ding,Jianzhe Gao,Cong Pan,Wenguan Wang,Jie Qin*

Main category: cs.CV

TL;DR: 提出了一种新颖的两阶段Transformer框架用于无人机城市导航任务，通过粗到细的导航流程提升全球推理和局部理解能力，并在改进后的数据集上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有无人机导航方法难以兼顾环境全局推理与局部场景理解，单一粒度的框架无法平衡这两者，亟需改进方法提升导航准确性和实用性。

Method: 提出了历史增强型两阶段Transformer（HETT）框架，分为两步：第一步融合空间地标和历史上下文进行粗粒度目标预测，第二步通过细粒度视觉分析精细调整动作。此外，引入历史网格图动态聚合视觉特征，实现结构化空间记忆，并手动精修CityNav数据集标注提升数据质量。

Result: 在精修版CityNav数据集上的实验表明，HETT框架相较于以往方法有显著性能提升，丰富的消融实验也验证了各组件的有效性。

Conclusion: HETT框架能够更好地整合全局与局部信息，有效提升无人机在城市环境下基于语言指令的导航表现。

Abstract: Aerial Vision-and-Language Navigation (AVLN) requires Unmanned Aerial Vehicle (UAV) agents to localize targets in large-scale urban environments based on linguistic instructions. While successful navigation demands both global environmental reasoning and local scene comprehension, existing UAV agents typically adopt mono-granularity frameworks that struggle to balance these two aspects. To address this limitation, this work proposes a History-Enhanced Two-Stage Transformer (HETT) framework, which integrates the two aspects through a coarse-to-fine navigation pipeline. Specifically, HETT first predicts coarse-grained target positions by fusing spatial landmarks and historical context, then refines actions via fine-grained visual analysis. In addition, a historical grid map is designed to dynamically aggregate visual features into a structured spatial memory, enhancing comprehensive scene awareness. Additionally, the CityNav dataset annotations are manually refined to enhance data quality. Experiments on the refined CityNav dataset show that HETT delivers significant performance gains, while extensive ablation studies further verify the effectiveness of each component.

</details>


### [26] [Unleashing the Power of Image-Tabular Self-Supervised Learning via Breaking Cross-Tabular Barriers](https://arxiv.org/abs/2512.14026)
*Yibing Fu,Yunpeng Zhao,Zhitao Zeng,Cheng Chen,Yueming Jin*

Main category: cs.CV

TL;DR: 本文提出了一种新的自监督学习（SSL）框架CITab，实现了医学图像与异构表格数据的跨数据集多模态表示学习，并在阿尔茨海默病诊断任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的医学图像与表格数据多模态SSL方法在模型表格数据时机制较为刚性，难以处理不同数据集的异构表格，导致知识难以跨队列迁移，限制了方法的泛化与大规模应用。

Method: 提出CITab框架，从语义感知角度将表格的列标题作为语义线索，促进可迁移知识的学习和多数据源的可扩展预训练。同时，设计了原型驱动的混合线性层（P-MoLin）模块，用于提升模型对异构表格数据的适应性和探索潜在医学概念的能力。

Result: 在包含4,461名受试者、跨三个公开数据集的阿尔茨海默病诊断任务上，CITab均取得了优于当前主流方法的性能表现。

Conclusion: CITab为异构医疗表格跨队列的自监督多模态学习提供了有效可扩展的解决途径，有望推动医学多模态学习与知识迁移的实际应用。

Abstract: Multi-modal learning integrating medical images and tabular data has significantly advanced clinical decision-making in recent years. Self-Supervised Learning (SSL) has emerged as a powerful paradigm for pretraining these models on large-scale unlabeled image-tabular data, aiming to learn discriminative representations. However, existing SSL methods for image-tabular representation learning are often confined to specific data cohorts, mainly due to their rigid tabular modeling mechanisms when modeling heterogeneous tabular data. This inter-tabular barrier hinders the multi-modal SSL methods from effectively learning transferrable medical knowledge shared across diverse cohorts. In this paper, we propose a novel SSL framework, namely CITab, designed to learn powerful multi-modal feature representations in a cross-tabular manner. We design the tabular modeling mechanism from a semantic-awareness perspective by integrating column headers as semantic cues, which facilitates transferrable knowledge learning and the scalability in utilizing multiple data sources for pretraining. Additionally, we propose a prototype-guided mixture-of-linear layer (P-MoLin) module for tabular feature specialization, empowering the model to effectively handle the heterogeneity of tabular data and explore the underlying medical concepts. We conduct comprehensive evaluations on Alzheimer's disease diagnosis task across three publicly available data cohorts containing 4,461 subjects. Experimental results demonstrate that CITab outperforms state-of-the-art approaches, paving the way for effective and scalable cross-tabular multi-modal learning.

</details>


### [27] [A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning](https://arxiv.org/abs/2512.14442)
*Zixin Zhang,Kanghao Chen,Hanqing Wang,Hongfei Zhang,Harold Haodong Chen,Chenfei Liao,Litao Guo,Ying-Cong Chen*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的、无需训练的A4-Agent框架，实现了基于语言指令的物体可供性预测，并在多个基准上显著优于现有有监督方法。


<details>
  <summary>Details</summary>
Motivation: 现有的可供性预测端到端模型在新物体和未见环境中泛化能力较差，因为它们将高层次推理和低层次定位耦合在一起，并依赖于有标签数据集训练。

Method: A4-Agent将可供性预测过程分为三个阶段，分别由专门的基础模型协同完成：Dreamer负责用生成模型可视化交互场景，Thinker利用大视觉-语言模型决定与哪个对象部分交互，Spotter使用视觉基础模型准确定位交互区域。整个流程在测试时运行，无需针对特定任务微调。

Result: A4-Agent无需任何特定任务的微调，在多个基准测试上显著优于最新的有监督方法，并展示了对真实环境的强泛化能力。

Conclusion: 该方法通过解耦流程并依赖于预训练大模型的能力，显著提升了可供性预测的泛化性，为具身智能领域提供了一种有效的新范式。

Abstract: Affordance prediction, which identifies interaction regions on objects based on language instructions, is critical for embodied AI. Prevailing end-to-end models couple high-level reasoning and low-level grounding into a single monolithic pipeline and rely on training over annotated datasets, which leads to poor generalization on novel objects and unseen environments. In this paper, we move beyond this paradigm by proposing A4-Agent, a training-free agentic framework that decouples affordance prediction into a three-stage pipeline. Our framework coordinates specialized foundation models at test time: (1) a $\textbf{Dreamer}$ that employs generative models to visualize $\textit{how}$ an interaction would look; (2) a $\textbf{Thinker}$ that utilizes large vision-language models to decide $\textit{what}$ object part to interact with; and (3) a $\textbf{Spotter}$ that orchestrates vision foundation models to precisely locate $\textit{where}$ the interaction area is. By leveraging the complementary strengths of pre-trained models without any task-specific fine-tuning, our zero-shot framework significantly outperforms state-of-the-art supervised methods across multiple benchmarks and demonstrates robust generalization to real-world settings.

</details>


### [28] [Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding](https://arxiv.org/abs/2512.14028)
*Jiaheng Li,Qiyu Dai,Lihan Li,Praneeth Chakravarthula,He Sun,Baoquan Chen,Wenzheng Chen*

Main category: cs.CV

TL;DR: 本文提出了一种基于学习的方法来提升单拍结构光系统的3D深度成像，在挑战性场景下显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统结构光3D成像在复杂情形下（如遮挡、细微结构及非理想反射面）鲁棒性有限，亟需新的解码方式提升深度恢复质量。

Method: 作者提出在特征空间（而非像素空间）进行模式与红外图像的对应关系匹配，显式利用几何先验构建代价体，并引入基于大规模单目深度估计的深度精细化模块。同时，设计物理基础的结构光合成渲染管线，生成大规模合成数据用于网络训练。

Result: 方法在多种结构光模式和真实室内数据上均获得了优异的泛化性，无需重新训练即可处理不同模式，整体性能超越了商业结构光系统及无源立体RGB深度估计算法。

Conclusion: 基于特征空间匹配与合成数据训练的结构光解码框架能够有效提升3D成像鲁棒性和质量，具备良好的实用性和推广能力。

Abstract: We consider the problem of active 3D imaging using single-shot structured light systems, which are widely employed in commercial 3D sensing devices such as Apple Face ID and Intel RealSense. Traditional structured light methods typically decode depth correspondences through pixel-domain matching algorithms, resulting in limited robustness under challenging scenarios like occlusions, fine-structured details, and non-Lambertian surfaces. Inspired by recent advances in neural feature matching, we propose a learning-based structured light decoding framework that performs robust correspondence matching within feature space rather than the fragile pixel domain. Our method extracts neural features from the projected patterns and captured infrared (IR) images, explicitly incorporating their geometric priors by building cost volumes in feature space, achieving substantial performance improvements over pixel-domain decoding approaches. To further enhance depth quality, we introduce a depth refinement module that leverages strong priors from large-scale monocular depth estimation models, improving fine detail recovery and global structural coherence. To facilitate effective learning, we develop a physically-based structured light rendering pipeline, generating nearly one million synthetic pattern-image pairs with diverse objects and materials for indoor settings. Experiments demonstrate that our method, trained exclusively on synthetic data with multiple structured light patterns, generalizes well to real-world indoor environments, effectively processes various pattern types without retraining, and consistently outperforms both commercial structured light systems and passive stereo RGB-based depth estimation methods. Project page: https://namisntimpot.github.io/NSLweb/.

</details>


### [29] [CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives](https://arxiv.org/abs/2512.14696)
*Zihan Wang,Jiashun Wang,Jeff Tan,Yiwen Zhao,Jessica Hodgins,Shubham Tulsiani,Deva Ramanan*

Main category: cs.CV

TL;DR: CRISP方法能从单目视频中恢复可用于仿真的人体动作和场景几何，实现高质量、物理合理的还原，显著提升了动作跟踪和仿真效率。


<details>
  <summary>Details</summary>
Motivation: 现有的人-场景联合重建方法在物理一致性和几何质量上存在明显不足，易导致动作追踪失败及交互失效，限制了其在机器人和AR/VR等实际场景中的应用。

Method: 提出通过点云重建场景后，用基于深度、法向和流的聚类流程拟合平面基元，恢复干净且可仿真的凸几何体。结合人体姿态推断遮挡区域（如椅子的座位），进一步用强化学习驱动人形体仿真，确保人和场景的物理合理性。

Result: CRISP方法将动作跟踪失败率从55.2%降至6.9%，RL仿真吞吐提升了43%；在真实、网络和生成视频上验证了方法的泛化能力和实用性。

Conclusion: CRISP极大提升了人体-场景重建的物理真实感和仿真效率，为机器人和AR/VR的“真实到仿真”应用提供了更可靠的基础。

Abstract: We introduce CRISP, a method that recovers simulatable human motion and scene geometry from monocular video. Prior work on joint human-scene reconstruction relies on data-driven priors and joint optimization with no physics in the loop, or recovers noisy geometry with artifacts that cause motion tracking policies with scene interactions to fail. In contrast, our key insight is to recover convex, clean, and simulation-ready geometry by fitting planar primitives to a point cloud reconstruction of the scene, via a simple clustering pipeline over depth, normals, and flow. To reconstruct scene geometry that might be occluded during interactions, we make use of human-scene contact modeling (e.g., we use human posture to reconstruct the occluded seat of a chair). Finally, we ensure that human and scene reconstructions are physically-plausible by using them to drive a humanoid controller via reinforcement learning. Our approach reduces motion tracking failure rates from 55.2\% to 6.9\% on human-centric video benchmarks (EMDB, PROX), while delivering a 43\% faster RL simulation throughput. We further validate it on in-the-wild videos including casually-captured videos, Internet videos, and even Sora-generated videos. This demonstrates CRISP's ability to generate physically-valid human motion and interaction environments at scale, greatly advancing real-to-sim applications for robotics and AR/VR.

</details>


### [30] [ACE-SLAM: Scene Coordinate Regression for Neural Implicit Real-Time SLAM](https://arxiv.org/abs/2512.14032)
*Ignacio Alzugaray,Marwan Taher,Andrew J. Davison*

Main category: cs.CV

TL;DR: 本文提出了一种基于神经网络的RGB-D SLAM系统，采用场景坐标回归（SCR）作为核心隐式地图表示，实现了实时、高效和低内存的三维建图与定位。


<details>
  <summary>Details</summary>
Motivation: 现有的神经隐式SLAM技术在实时性、效率以及隐私保护等方面存在限制。作者希望探索更简洁、高效、能保护隐私且适用于实时RGB-D场景的SLAM隐式地图表示。

Method: 作者首次将场景坐标回归网络（SCR）作为神经SLAM的核心地图表示，训练轻量网络将2D图像特征直接映射到3D全局坐标。并提出专门为该任务设计的新型SCR网络结构，详细说明其与实时SLAM系统集成的关键设计。该方法支持稀疏和稠密特征，且能适应动态环境，无需专门的适应措施。

Result: 在合成和真实数据集上评估，该方法在定位和建图方面与当前最先进方法具有竞争力，并首次在神经隐式RGB-D SLAM中实现了严格的实时性能。

Conclusion: 基于SCR的神经隐式SLAM为实时、高效、灵活且注重隐私的三维场景建图与定位提供了一种可行方向，具有良好的应用前景和推广价值。

Abstract: We present a novel neural RGB-D Simultaneous Localization And Mapping (SLAM) system that learns an implicit map of the scene in real time. For the first time, we explore the use of Scene Coordinate Regression (SCR) as the core implicit map representation in a neural SLAM pipeline, a paradigm that trains a lightweight network to directly map 2D image features to 3D global coordinates. SCR networks provide efficient, low-memory 3D map representations, enable extremely fast relocalization, and inherently preserve privacy, making them particularly suitable for neural implicit SLAM.
  Our system is the first one to achieve strict real-time in neural implicit RGB-D SLAM by relying on a SCR-based representation. We introduce a novel SCR architecture specifically tailored for this purpose and detail the critical design choices required to integrate SCR into a live SLAM pipeline. The resulting framework is simple yet flexible, seamlessly supporting both sparse and dense features, and operates reliably in dynamic environments without special adaptation. We evaluate our approach on established synthetic and real-world benchmarks, demonstrating competitive performance against the state of the art. Project Page: https://github.com/ialzugaray/ace-slam

</details>


### [31] [ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization](https://arxiv.org/abs/2512.14039)
*Meng Wei,Cheng Zhang,Jianmin Zheng,Hamid Rezatofighi,Jianfei Cai*

Main category: cs.CV

TL;DR: 本文改进了3D Gaussian Splatting 的纹理参数化方法，提出ASAP Textured Gaussians，实现了更高效的高质量渲染。


<details>
  <summary>Details</summary>
Motivation: 当前3D高斯着色方法依赖纹理参数提升外观建模和后续任务表现，但由此带来的内存效率问题仍未解决。该工作发现主流方法存在纹理采样效率低和参数分配过度两个核心瓶颈。

Method: 本文提出两项策略：1）基于高斯密度分布的自适应采样，只在视觉贡献高的区域精细采样；2）基于渲染误差的各向异性参数分配，对视觉复杂、高误差的区域分配更多纹理资源。该方法统称为ASAP Textured Gaussians。

Result: 所提方法能用更少的纹理参数实现高质量渲染，在质量与效率之间取得更优权衡。实验证明了方法在纹理参数数量大幅减少下，渲染效果依然优秀。

Conclusion: ASAP Textured Gaussians显著提升了3D Gaussian Splatting的内存效率，实现高保真度渲染，适合实际场景应用。

Abstract: Recent advances have equipped 3D Gaussian Splatting with texture parameterizations to capture spatially varying attributes, improving the performance of both appearance modeling and downstream tasks. However, the added texture parameters introduce significant memory efficiency challenges. Rather than proposing new texture formulations, we take a step back to examine the characteristics of existing textured Gaussian methods and identify two key limitations in common: (1) Textures are typically defined in canonical space, leading to inefficient sampling that wastes textures' capacity on low-contribution regions; and (2) texture parameterization is uniformly assigned across all Gaussians, regardless of their visual complexity, resulting in over-parameterization. In this work, we address these issues through two simple yet effective strategies: adaptive sampling based on the Gaussian density distribution and error-driven anisotropic parameterization that allocates texture resources according to rendering error. Our proposed ASAP Textured Gaussians, short for Adaptive Sampling and Anisotropic Parameterization, significantly improve the quality efficiency tradeoff, achieving high-fidelity rendering with far fewer texture parameters.

</details>


### [32] [ChartAgent: A Chart Understanding Framework with Tool Integrated Reasoning](https://arxiv.org/abs/2512.14040)
*Boran Wang,Xinming Wang,Yi Chen,Xiang Li,Jian Xu,Jing Yuan,Chenglin Liu*

Main category: cs.CV

TL;DR: ChartAgent是一种用于图表理解的新框架，采用工具集成推理，能够分阶段解析图表并追溯推理过程，在标注稀疏条件下依然表现优异。


<details>
  <summary>Details</summary>
Motivation: 近年来多模态大模型在自动图表理解方面取得进展，但过度依赖文本注释，在关键数字缺失时性能大幅下降。为解决现有方法在注释稀缺场景下的局限性，提出了ChartAgent。

Method: 提出ChartAgent框架，利用工具集成推理思想，将复杂图表分析分解为可复现、可追溯的多步推理过程，并配备可扩展的模块化工具库（如关键元素检测、实例分割、OCR等）；每一步推理产出标准化的证据包（Evidence Package），提升系统透明度和可验证性。

Result: 实验结果显示，ChartAgent在标注稀疏环境下明显优于以往方法，提升了健壮性。

Conclusion: ChartAgent通过工具化、多步、可追溯推理，为图表理解系统提供了更可信和更易扩展的解决方案，有望推动该领域的发展。

Abstract: With their high information density and intuitive readability, charts have become the de facto medium for data analysis and communication across disciplines. Recent multimodal large language models (MLLMs) have made notable progress in automated chart understanding, yet they remain heavily dependent on explicit textual annotations and the performance degrades markedly when key numerals are absent. To address this limitation, we introduce ChartAgent, a chart understanding framework grounded in Tool-Integrated Reasoning (TIR). Inspired by human cognition, ChartAgent decomposes complex chart analysis into a sequence of observable, replayable steps. Supporting this architecture is an extensible, modular tool library comprising more than a dozen core tools, such as keyelement detection, instance segmentation, and optical character recognition (OCR), which the agent dynamically orchestrates to achieve systematic visual parsing across diverse chart types. Leveraging TIRs transparency and verifiability, ChartAgent moves beyond the black box paradigm by standardizing and consolidating intermediate outputs into a structured Evidence Package, providing traceable and reproducible support for final conclusions. Experiments show that ChartAgent substantially improves robustness under sparse annotation settings, offering a practical path toward trustworthy and extensible systems for chart understanding.

</details>


### [33] [HyperVL: An Efficient and Dynamic Multimodal Large Language Model for Edge Devices](https://arxiv.org/abs/2512.14052)
*HyperAI Team,Yuchen Liu,Kaiyang Han,Zhiqiang Xia,Yuhang Dong,Chen Song,Kangyu Tang,Jiaming Xu,Xiushi Feng,WenXuan Yu,Li Peng,Mingyang Wang,Kai Wang,Changpeng Yang,Yang Li,Haoyu Lu,Hao Wang,Bingna Xu,Guangyao Liu,Long Huang,Kaibin Guo,Jinyang Wu,Dan Wu,Hongzhen Wang,Peng Zhou,Shuai Nie,Shande Wang,Runyu Shi,Ying Huang*

Main category: cs.CV

TL;DR: 提出了一种高效、适合端侧推理的多模态大语言模型HyperVL，显著降低了资源消耗同时性能优异。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型虽然能力强，但对计算和内存需求高，不适合在移动终端等受限环境部署，尤其是标准的视觉Transformer在处理高分辨率输入时开销很大。

Method: HyperVL采用图像切块（image-tiling）策略限制内存消耗，并引入了两项新技术：1）视觉分辨率压缩器（VRC），自适应预测最佳编码分辨率以消除冗余计算；2）双重一致性学习（DCL），对多尺度ViT编码器进行对齐，实现视觉分支的动态切换，整体共享LLM框架。

Result: 在多个基准测试中，HyperVL在同体量模型中实现了最优性能，且在真实移动设备上显著降低了推理延迟和功耗。

Conclusion: HyperVL兼顾了资源消耗和推理能力，适合移动端等环境下的多模态大模型落地应用，具备较高实用性和推广价值。

Abstract: Current multimodal large lanauge models possess strong perceptual and reasoning capabilities, however high computational and memory requirements make them difficult to deploy directly on on-device environments. While small-parameter models are progressively endowed with strong general capabilities, standard Vision Transformer (ViT) encoders remain a critical bottleneck, suffering from excessive latency and memory consumption when processing high-resolution inputs.To address these challenges, we introduce HyperVL, an efficient multimodal large language model tailored for on-device inference. HyperVL adopts an image-tiling strategy to cap peak memory usage and incorporates two novel techniques: (1) a Visual Resolution Compressor (VRC) that adaptively predicts optimal encoding resolutions to eliminate redundant computation, and (2) Dual Consistency Learning (DCL), which aligns multi-scale ViT encoders within a unified framework, enabling dynamic switching between visual branches under a shared LLM. Extensive experiments demonstrate that HyperVL achieves state-of-the-art performance among models of comparable size across multiple benchmarks. Furthermore, it significantly significantly reduces latency and power consumption on real mobile devices, demonstrating its practicality for on-device multimodal inference.

</details>


### [34] [OmniDrive-R1: Reinforcement-driven Interleaved Multi-modal Chain-of-Thought for Trustworthy Vision-Language Autonomous Driving](https://arxiv.org/abs/2512.14044)
*Zhenguo Zhang,Haohan Zhen,Yishen Wang,Le Xu,Tianchen Deng,Xuefeng Chen,Qu Chen,Bo Zhang,Wuxiong Huang*

Main category: cs.CV

TL;DR: 本文提出OmniDrive-R1模型，针对自动驾驶领域的VLM对象幻觉问题，通过端到端联合感知和推理以及全新的强化视觉定位与奖励机制，大幅提升模型的推理与决策准确率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型在自动驾驶等安全关键领域中常因对象幻觉等失效问题，影响其可靠性，主要由于其基于文本的链式推理缺乏真实视觉基础。此外，已有方法存在感知与推理解耦、依赖高成本定位标注等关键缺陷。

Method: 提出OmniDrive-R1框架，在“交错式多模态链式推理”(iMCoT)机制下，将感知与推理端到端统一。同时创新性地引入基于强化学习的视觉定位能力，通过纯两阶段强化学习流程及Clip-GRPO算法，实现无标注、过程驱动的定位奖励，强化视觉聚焦与文本推理间的一致性。

Result: 在DriveLMM-o1数据集上，OmniDrive-R1相比主流基线Qwen2.5VL-7B，整体推理得分由51.77%提升至80.35%，最终答案准确率由37.81%提升至73.62%。

Conclusion: OmniDrive-R1通过创新的端到端设计和强化视觉地基机制，有效提升了自动驾驶场景下VLM的推理可靠性和准确性，且无需依赖昂贵的密集标注，展现出优越的实际应用潜力。

Abstract: The deployment of Vision-Language Models (VLMs) in safety-critical domains like autonomous driving (AD) is critically hindered by reliability failures, most notably object hallucination. This failure stems from their reliance on ungrounded, text-based Chain-of-Thought (CoT) reasoning.While existing multi-modal CoT approaches attempt mitigation, they suffer from two fundamental flaws: (1) decoupled perception and reasoning stages that prevent end-to-end joint optimization, and (2) reliance on expensive, dense localization labels.Thus we introduce OmniDrive-R1, an end-to-end VLM framework designed for autonomous driving, which unifies perception and reasoning through an interleaved Multi-modal Chain-of-Thought (iMCoT) mechanism. Our core innovation is an Reinforcement-driven visual grounding capability, enabling the model to autonomously direct its attention and "zoom in" on critical regions for fine-grained analysis. This capability is enabled by our pure two-stage reinforcement learning training pipeline and Clip-GRPO algorithm. Crucially, Clip-GRPO introduces an annotation-free, process-based grounding reward. This reward not only eliminates the need for dense labels but also circumvents the instability of external tool calls by enforcing real-time cross-modal consistency between the visual focus and the textual reasoning. Extensive experiments on DriveLMM-o1 demonstrate our model's significant improvements. Compared to the baseline Qwen2.5VL-7B, OmniDrive-R1 improves the overall reasoning score from 51.77% to 80.35%, and the final answer accuracy from 37.81% to 73.62%.

</details>


### [35] [TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs](https://arxiv.org/abs/2512.14698)
*Jun Zhang,Teng Wang,Yuying Ge,Yixiao Ge,Xinhao Li,Ying Shan,Limin Wang*

Main category: cs.CV

TL;DR: 该论文提出了TimeLens，一种系统化的大模型视频时序定位（VTG）基线和范式，着重于数据和算法质量，提出了新数据集和高效方法，使开源模型在该任务上刷新纪录。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型在视频理解任务中表现突出，但针对视频时序定位（VTG）领域的训练优化策略研究尚不充分，当前基准和数据存在明显质量问题。作者希望通过系统调查和改进推动该领域发展。

Method: 1. 重构数据：对现有VTG基准进行了严格的质量重标注，形成TimeLens-Bench；2. 构建高质量大规模训练集TimeLens-100K，通过自动重注释去除标注噪声；3. 算法设计：提出交错文本编码时序表示，引入“无推理”可验证奖励强化学习（RLVR）训练范式，并提供高效实用的训练配方。

Result: （1）TimeLens-Bench数据标准的提升导致模型排名发生巨大变化，否定了旧有评估方式的可靠性；（2）TimeLens-100K有效提升了模型训练表现；（3）改进的算法方案获得了有效提升，所提出的TimeLens模型在开源模型中取得SOTA，并超越了商用闭源模型如GPT-5与Gemini-2.5-Flash。

Conclusion: 系统性数据重注释与创新性算法设计极大提升了VTG任务的基线表现，为该领域后续研究提供了强有力资源和范式，相关代码与数据已开源以促进社区发展。

Abstract: This paper does not introduce a novel method but instead establishes a straightforward, incremental, yet essential baseline for video temporal grounding (VTG), a core capability in video understanding. While multimodal large language models (MLLMs) excel at various video understanding tasks, the recipes for optimizing them for VTG remain under-explored. In this paper, we present TimeLens, a systematic investigation into building MLLMs with strong VTG ability, along two primary dimensions: data quality and algorithmic design. We first expose critical quality issues in existing VTG benchmarks and introduce TimeLens-Bench, comprising meticulously re-annotated versions of three popular benchmarks with strict quality criteria. Our analysis reveals dramatic model re-rankings compared to legacy benchmarks, confirming the unreliability of prior evaluation standards. We also address noisy training data through an automated re-annotation pipeline, yielding TimeLens-100K, a large-scale, high-quality training dataset. Building on our data foundation, we conduct in-depth explorations of algorithmic design principles, yielding a series of meaningful insights and effective yet efficient practices. These include interleaved textual encoding for time representation, a thinking-free reinforcement learning with verifiable rewards (RLVR) approach as the training paradigm, and carefully designed recipes for RLVR training. These efforts culminate in TimeLens models, a family of MLLMs with state-of-the-art VTG performance among open-source models and even surpass proprietary models such as GPT-5 and Gemini-2.5-Flash. All codes, data, and models will be released to facilitate future research.

</details>


### [36] [SELECT: Detecting Label Errors in Real-world Scene Text Data](https://arxiv.org/abs/2512.14050)
*Wenjun Liu,Qian Wu,Yifeng Hu,Yuke Li*

Main category: cs.CV

TL;DR: 本文提出了一个名为SELECT的新方法，利用多模态训练准确检测真实场景文本数据集中的标签错误，并引入SSLC机制提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 场景文本识别数据集常因标签错误、序列长度变化及字符级错配影响模型性能，现有方法难以有效检测这些复杂的标签错误。需要一种能处理变长标签且有实际应用价值的高效检测方法。

Method: 提出了基于图像-文本编码器和字符级分词器的SELECT方法，从多个模态提取信息，结合SSLC（基于相似度的序列标签扰动）机制，在训练中模拟真实世界错误情境，通过引入字符的视觉相似性进行数据增强和标签错误检测。

Result: SELECT方法在实际场景文本数据集中展现出高准确率和实用性，在检测标签错误和提升场景文本识别（STR）准确率方面优于现有方法。

Conclusion: SELECT首次实现了对真实场景文本数据集变长标签的高效错误检测，证明了其实用价值，并提升了STR模型的性能。

Abstract: We introduce SELECT (Scene tExt Label Errors deteCTion), a novel approach that leverages multi-modal training to detect label errors in real-world scene text datasets. Utilizing an image-text encoder and a character-level tokenizer, SELECT addresses the issues of variable-length sequence labels, label sequence misalignment, and character-level errors, outperforming existing methods in accuracy and practical utility. In addition, we introduce Similarity-based Sequence Label Corruption (SSLC), a process that intentionally introduces errors into the training labels to mimic real-world error scenarios during training. SSLC not only can cause a change in the sequence length but also takes into account the visual similarity between characters during corruption. Our method is the first to detect label errors in real-world scene text datasets successfully accounting for variable-length labels. Experimental results demonstrate the effectiveness of SELECT in detecting label errors and improving STR accuracy on real-world text datasets, showcasing its practical utility.

</details>


### [37] [FacEDiT: Unified Talking Face Editing and Generation via Facial Motion Infilling](https://arxiv.org/abs/2512.14056)
*Kim Sung-Bin,Joohyun Chang,David Harwath,Tae-Hyun Oh*

Main category: cs.CV

TL;DR: 本文提出了一种将说话人面部编辑和面部生成统一建模为“语音条件下的面部运动补全”任务的新方法，并提出了FacEDiT模型及其对应基准数据集。该方法能精准、平滑地生成和编辑说话人面部表情。


<details>
  <summary>Details</summary>
Motivation: 过去说话人面部编辑与生成一直被当作两个独立的问题，而实际上二者高度相关。作者希望用统一视角和方法，简化流程，提高模型效果，并填补该领域缺乏标准化数据集的空白。

Method: 1）提出了FacEDiT，一种结合扩散模型与Transformer架构、用flow matching训练的语音条件生成方法；2）借鉴masked autoencoder思想，让模型在已知周围运动和语音条件下合成被遮盖面部运动；3）引入偏置注意力与时序平滑约束，提升边界连续性和唇形同步性。4）提出标准化编辑评测集FacEDiTBench。

Result: 实验证明，使用FacEDiT能在面部生成与编辑任务上生成准确、与语音高度对齐、身份保持强且视觉连续性好的结果，并能在面部生成任务上展现良好的泛化能力。

Conclusion: 作者将说话人面部编辑与生成统一为语音条件下面部运动补全，提出FacEDiT模型，显著提升了编辑和生成质量，并建立了新领域标准基准数据集，为后续研究打下基础。

Abstract: Talking face editing and face generation have often been studied as distinct problems. In this work, we propose viewing both not as separate tasks but as subtasks of a unifying formulation, speech-conditional facial motion infilling. We explore facial motion infilling as a self-supervised pretext task that also serves as a unifying formulation of dynamic talking face synthesis. To instantiate this idea, we propose FacEDiT, a speech-conditional Diffusion Transformer trained with flow matching. Inspired by masked autoencoders, FacEDiT learns to synthesize masked facial motions conditioned on surrounding motions and speech. This formulation enables both localized generation and edits, such as substitution, insertion, and deletion, while ensuring seamless transitions with unedited regions. In addition, biased attention and temporal smoothness constraints enhance boundary continuity and lip synchronization. To address the lack of a standard editing benchmark, we introduce FacEDiTBench, the first dataset for talking face editing, featuring diverse edit types and lengths, along with new evaluation metrics. Extensive experiments validate that talking face editing and generation emerge as subtasks of speech-conditional motion infilling; FacEDiT produces accurate, speech-aligned facial edits with strong identity preservation and smooth visual continuity while generalizing effectively to talking face generation.

</details>


### [38] [Real-time prediction of workplane illuminance distribution for daylight-linked controls using non-intrusive multimodal deep learning](https://arxiv.org/abs/2512.14058)
*Zulin Zhuang,Yu Bian*

Main category: cs.CV

TL;DR: 本研究提出了一种多模态深度学习框架，可以利用侧窗区域的非侵入式图像，实时预测室内工作面照度分布，且验证结果显示该方法精度高且具有良好的时序泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于室内日光预测的研究多针对静态场景，无法满足动态人员活动和实时照明控制的需求。为了更好地实现节能的日光联动控制，并适应动态室内空间的复杂情况，有必要开发能在实际动态场景中高效工作的实时照度预测方法。

Method: 作者提出了一种多模态深度学习框架。主要创新是只提取靠近侧窗区域的图像特征，避免对室内隐私和活动的侵扰。通过采集大量（17,344组）照度及图像样本，并采用深度学习方法，对工作面照度分布进行实时预测。

Result: 在广州测试间实地实验中，模型在同分布测试集上R²>0.98、RMSE<0.14；在未见过的新一天数据上R²>0.82、RMSE<0.17，显示出较高精度和良好的时间泛化能力。

Conclusion: 所提框架在动态占用环境下依然能准确预测照度分布，适用于日光联动控制，具有实际应用和推广价值。

Abstract: Daylight-linked controls (DLCs) have significant potential for energy savings in buildings, especially when abundant daylight is available and indoor workplane illuminance can be accurately predicted in real time. Most existing studies on indoor daylight predictions were developed and tested for static scenes. This study proposes a multimodal deep learning framework that predicts indoor workplane illuminance distributions in real time from non-intrusive images with temporal-spatial features. By extracting image features only from the side-lit window areas rather than interior pixels, the approach remains applicable in dynamically occupied indoor spaces. A field experiment was conducted in a test room in Guangzhou (China), where 17,344 samples were collected for model training and validation. The model achieved R2 > 0.98 with RMSE < 0.14 on the same-distribution test set and R2 > 0.82 with RMSE < 0.17 on an unseen-day test set, indicating high accuracy and acceptable temporal generalization.

</details>


### [39] [Bridging Fidelity-Reality with Controllable One-Step Diffusion for Image Super-Resolution](https://arxiv.org/abs/2512.14061)
*Hao Chen,Junyang Chen,Jinshan Pan,Jiangxin Dong*

Main category: cs.CV

TL;DR: CODSR是一种用于图像超分辨率的可控一步扩散网络，解决了现有方法在输入信息损失、区域判别激活不足和文本与语义区域错位等问题，并在实验中达到了更优的感知质量和竞争性的保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的一步扩散方法虽然在图像超分领域有进展，但由于低质量输入的压缩编码会造成信息损失，加之区域判别激活不足以及文本提示与语义区域不匹配，导致生成图像的保真度和感知质量受限。论文旨在解决这些关键瓶颈。

Method: 提出CODSR网络，包括三大创新：(1) LQ引导的特征调制模块，利用原始未压缩信息为扩散过程提供高保真条件；(2) 区域自适应生成先验激活方法，提高感知丰富性并保持结构保真；(3) 文本匹配引导策略，增强文本提示与对应区域的匹配。

Result: 通过大量实验，CODSR在感知质量上优于现有方法，并在高效一步推理下提供了有竞争力的保真度。

Conclusion: CODSR有效克服了一步扩散超分方法的三大关键限制，实现了更高感知质量和较强保真性能，有望促进超分辨率实际应用发展。

Abstract: Recent diffusion-based one-step methods have shown remarkable progress in the field of image super-resolution, yet they remain constrained by three critical limitations: (1) inferior fidelity performance caused by the information loss from compression encoding of low-quality (LQ) inputs; (2) insufficient region-discriminative activation of generative priors; (3) misalignment between text prompts and their corresponding semantic regions. To address these limitations, we propose CODSR, a controllable one-step diffusion network for image super-resolution. First, we propose an LQ-guided feature modulation module that leverages original uncompressed information from LQ inputs to provide high-fidelity conditioning for the diffusion process. We then develop a region-adaptive generative prior activation method to effectively enhance perceptual richness without sacrificing local structural fidelity. Finally, we employ a text-matching guidance strategy to fully harness the conditioning potential of text prompts. Extensive experiments demonstrate that CODSR achieves superior perceptual quality and competitive fidelity compared with state-of-the-art methods with efficient one-step inference.

</details>


### [40] [SDAR-VL: Stable and Efficient Block-wise Diffusion for Vision-Language Understanding](https://arxiv.org/abs/2512.14068)
*Shuang Cheng,Yuhua Jiang,Zineng Zhou,Dawei Liu,Wang Tao,Linfeng Zhang,Biqing Qi,Bowen Zhou*

Main category: cs.CV

TL;DR: 提出了一种高效、稳定的分块离散扩散方法（SDAR-VL），首次系统性扩展到大规模视觉-语言理解上，并在多个基准上表现出优异的训练效率、稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 分块离散扩散兼顾了并行生成和因果建模，有望作为视觉-语言建模主干，但实际应用受限于高训练成本、收敛慢和不稳定，落后于主流自回归方法。

Method: 提出SDAR-VL框架，整合了三大训练优化组件：1) 异步分块噪声调度，实现更丰富的监督信号；2) 有效的掩码比例缩放，确保掩码随机下的无偏损失归一化；3) 递进式Beta噪声课程，提高掩码范围，保持扰动多样性。

Result: 在单图像、多图像、视频等21项基准上，SDAR-VL训练效率、稳定性、任务表现均显著优于传统分块扩散；在扩散类视觉-语言模型中达成新SOTA，与当前最强的自回归和全局扩散基线在同等设置下持平甚至超越。

Conclusion: SDAR-VL使分块离散扩散成为视觉-语言理解的实用主干，实现了性能、效率和稳定性的均衡提升。

Abstract: Block-wise discrete diffusion offers an attractive balance between parallel generation and causal dependency modeling, making it a promising backbone for vision-language modeling. However, its practical adoption has been limited by high training cost, slow convergence, and instability, which have so far kept it behind strong autoregressive (AR) baselines. We present \textbf{SDAR-VL}, the first systematic application of block-wise discrete diffusion to large-scale vision-language understanding (VLU), together with an \emph{integrated framework for efficient and stable training}. This framework unifies three components: (1) \textbf{Asynchronous Block-wise Noise Scheduling} to diversify supervision within each batch; (2) \textbf{Effective Mask Ratio Scaling} for unbiased loss normalization under stochastic masking; and (3) a \textbf{Progressive Beta Noise Curriculum} that increases effective mask coverage while preserving corruption diversity. Experiments on 21 single-image, multi-image, and video benchmarks show that SDAR-VL consistently improves \emph{training efficiency}, \emph{convergence stability}, and \emph{task performance} over conventional block diffusion. On this evaluation suite, SDAR-VL sets a new state of the art among diffusion-based vision-language models and, under matched settings, matches or surpasses strong AR baselines such as LLaVA-OneVision as well as the global diffusion baseline LLaDA-V, establishing block-wise diffusion as a practical backbone for VLU.

</details>


### [41] [GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants](https://arxiv.org/abs/2512.14087)
*Yang Yang,Risa Shinoda,Hiroaki Santo,Fumio Okura*

Main category: cs.CV

TL;DR: 本文提出了一种基于多视角图像联合恢复植物外观和内部结构的方法GaussianPlant，结合3D Gaussian Splatting实现对植物形态和结构的高保真重建。


<details>
  <summary>Details</summary>
Motivation: 传统3DGS虽能很好地重建场景外观用于新视角合成，但缺乏对底层结构（如植物分枝结构）的建模，不适于结构分析等应用。植物表型分析等任务对结构和外观的精确建模有较高要求。

Method: 提出层次化的3DGS表达——GaussianPlant，将结构与外观解耦。用结构基元（StPs）显式建模枝、叶的几何结构，用外观基元（ApPs）用3D高斯描述外观。StPs使用圆柱体和圆盘简化枝和叶，通过自组织优化区分各自属性。ApPs与StPs绑定，共同优化，使外观和结构通过多视角重渲染损失和梯度流进行联合优化。

Result: 实验结果表明，该方法在外观精度和结构精度上均优于传统3DGS，不仅可以高质量重建植物外观，还能准确提取分枝和叶片实例，满足实际需求。

Conclusion: GaussianPlant实现了对植物外观和结构的高保真重建，为植物表型分析等需求提供了有效工具，拓展了3DGS的应用场景。

Abstract: We present a method for jointly recovering the appearance and internal structure of botanical plants from multi-view images based on 3D Gaussian Splatting (3DGS). While 3DGS exhibits robust reconstruction of scene appearance for novel-view synthesis, it lacks structural representations underlying those appearances (e.g., branching patterns of plants), which limits its applicability to tasks such as plant phenotyping. To achieve both high-fidelity appearance and structural reconstruction, we introduce GaussianPlant, a hierarchical 3DGS representation, which disentangles structure and appearance. Specifically, we employ structure primitives (StPs) to explicitly represent branch and leaf geometry, and appearance primitives (ApPs) to the plants' appearance using 3D Gaussians. StPs represent a simplified structure of the plant, i.e., modeling branches as cylinders and leaves as disks. To accurately distinguish the branches and leaves, StP's attributes (i.e., branches or leaves) are optimized in a self-organized manner. ApPs are bound to each StP to represent the appearance of branches or leaves as in conventional 3DGS. StPs and ApPs are jointly optimized using a re-rendering loss on the input multi-view images, as well as the gradient flow from ApP to StP using the binding correspondence information. We conduct experiments to qualitatively evaluate the reconstruction accuracy of both appearance and structure, as well as real-world experiments to qualitatively validate the practical performance. Experiments show that the GaussianPlant achieves both high-fidelity appearance reconstruction via ApPs and accurate structural reconstruction via StPs, enabling the extraction of branch structure and leaf instances.

</details>


### [42] [ProtoFlow: Interpretable and Robust Surgical Workflow Modeling with Learned Dynamic Scene Graph Prototypes](https://arxiv.org/abs/2512.14092)
*Felix Holm,Ghazal Ghazaei,Nassir Navab*

Main category: cs.CV

TL;DR: 本文提出了一种名为ProtoFlow的新模型，通过学习动态场景图原型（scene graph prototypes），有效、可解释地分析复杂手术流程，提升在有限数据条件下的表现和模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: AI辅助手术的发展需要对手术过程进行详细识别，但高昂的标注成本、数据稀缺和缺乏可解释性模型限制了进展。场景图能结构化表述手术事件，但潜力尚未被充分利用。

Method: ProtoFlow基于图神经网络（GNN）编码-解码结构，采用自监督预训练以获得丰富表示，再通过原型方法微调，提炼归纳出能反映临床有意义的交互模式的核心原型，实现对手术流程的解释与分析。

Result: 在细粒度CAT-SG数据集上，ProtoFlow整体优于标准GNN基线方法，特别在极少数据（如仅1条手术视频）时仍能保持优秀表现。质性分析显示，其所学原型能辨识不同的手术子技巧，并给出关于流程偏差及罕见并发症的直观解释。

Conclusion: ProtoFlow结合了强大表征能力与模型自身可解释性，为构建更透明、可靠和高数据效率的AI系统迈出关键一步，促进其在手术培训、实时决策支持和流程优化等领域的临床应用。

Abstract: Purpose: Detailed surgical recognition is critical for advancing AI-assisted surgery, yet progress is hampered by high annotation costs, data scarcity, and a lack of interpretable models. While scene graphs offer a structured abstraction of surgical events, their full potential remains untapped. In this work, we introduce ProtoFlow, a novel framework that learns dynamic scene graph prototypes to model complex surgical workflows in an interpretable and robust manner.
  Methods: ProtoFlow leverages a graph neural network (GNN) encoder-decoder architecture that combines self-supervised pretraining for rich representation learning with a prototype-based fine-tuning stage. This process discovers and refines core prototypes that encapsulate recurring, clinically meaningful patterns of surgical interaction, forming an explainable foundation for workflow analysis.
  Results: We evaluate our approach on the fine-grained CAT-SG dataset. ProtoFlow not only outperforms standard GNN baselines in overall accuracy but also demonstrates exceptional robustness in limited-data, few-shot scenarios, maintaining strong performance when trained on as few as one surgical video. Our qualitative analyses further show that the learned prototypes successfully identify distinct surgical sub-techniques and provide clear, interpretable insights into workflow deviations and rare complications.
  Conclusion: By uniting robust representation learning with inherent explainability, ProtoFlow represents a significant step toward developing more transparent, reliable, and data-efficient AI systems, accelerating their potential for clinical adoption in surgical training, real-time decision support, and workflow optimization.

</details>


### [43] [Quality-Aware Framework for Video-Derived Respiratory Signals](https://arxiv.org/abs/2512.14093)
*Nhi Nguyen,Constantino Álvarez Casado,Le Nguyen,Manuel Lage Cañellas,Miguel Bordallo López*

Main category: cs.CV

TL;DR: 提出一种能自适应融合多种信号源并引入动态信号可靠性评估的视频呼吸率估计算法框架，在多个公开数据集上展现出优于单一方法的精度。


<details>
  <summary>Details</summary>
Motivation: 视频方式估算呼吸率时信号质量不一，导致现有方法常常不可靠。团队希望通过引入多信号源和质量感知机制来提升估算的可靠性和泛化能力。

Method: 从面部rPPG、上半身运动以及深度学习管道共提取10种信号，通过Welch、MUSIC、FFT和峰值检测等4种频谱分析方法得出呼吸率估计。然后利用分段信号质量指数训练机器学习模型，实现准确性预测或选择最可靠信号，支持自适应信号融合和基于质量的分段过滤。

Result: 在OMuSense-23、COHFACE、MAHNOB-HCI三大公开数据集上，整体呼吸率估计误差低于各单一提取方法，且不同数据集上的提升幅度有所不同。

Conclusion: 质量驱动的预测建模框架有助于提高视频呼吸率监测的准确性与泛化性，为可扩展的远程健康监测提供了新思路。

Abstract: Video-based respiratory rate (RR) estimation is often unreliable due to inconsistent signal quality across extraction methods. We present a predictive, quality-aware framework that integrates heterogeneous signal sources with dynamic assessment of reliability. Ten signals are extracted from facial remote photoplethysmography (rPPG), upper-body motion, and deep learning pipelines, and analyzed using four spectral estimators: Welch's method, Multiple Signal Classification (MUSIC), Fast Fourier Transform (FFT), and peak detection. Segment-level quality indices are then used to train machine learning models that predict accuracy or select the most reliable signal. This enables adaptive signal fusion and quality-based segment filtering. Experiments on three public datasets (OMuSense-23, COHFACE, MAHNOB-HCI) show that the proposed framework achieves lower RR estimation errors than individual methods in most cases, with performance gains depending on dataset characteristics. These findings highlight the potential of quality-driven predictive modeling to deliver scalable and generalizable video-based respiratory monitoring solutions.

</details>


### [44] [AnchorHOI: Zero-shot Generation of 4D Human-Object Interaction via Anchor-based Prior Distillation](https://arxiv.org/abs/2512.14095)
*Sisi Dai,Kai Xu*

Main category: cs.CV

TL;DR: 本文提出了一种新框架AnchorHOI，通过结合视频扩散模型和图像扩散模型，提升了零样本4D人-物交互生成的效果。


<details>
  <summary>Details</summary>
Motivation: 当前基于监督学习的4D人-物交互生成受限于数据集规模，小样本问题导致模型可扩展性弱。近期使用预训练的图像扩散模型实现零样本生成，但互动信息利用不足，限制了广泛应用。

Method: 提出AnchorHOI框架，融合视频与图像扩散模型，并引入锚点先验蒸馏策略。核心包括根据交互内容设计的锚点NeRF用于表达性交互组合，以及锚点关键点用于真实动作生成，以两步引导方式分阶段优化高维4D交互生成。

Result: 大量实验表明，所提方法在多样性和泛化能力方面显著优于现有方法。

Conclusion: AnchorHOI框架有效解决了零样本4D人-物交互生成中互动表达和动作真实性的难题，推进了该领域的发展。

Abstract: Despite significant progress in text-driven 4D human-object interaction (HOI) generation with supervised methods, the scalability remains limited by the scarcity of large-scale 4D HOI datasets. To overcome this, recent approaches attempt zero-shot 4D HOI generation with pre-trained image diffusion models. However, interaction cues are minimally distilled during the generation process, restricting their applicability across diverse scenarios. In this paper, we propose AnchorHOI, a novel framework that thoroughly exploits hybrid priors by incorporating video diffusion models beyond image diffusion models, advancing 4D HOI generation. Nevertheless, directly optimizing high-dimensional 4D HOI with such priors remains challenging, particularly for human pose and compositional motion. To address this challenge, AnchorHOI introduces an anchor-based prior distillation strategy, which constructs interaction-aware anchors and then leverages them to guide generation in a tractable two-step process. Specifically, two tailored anchors are designed for 4D HOI generation: anchor Neural Radiance Fields (NeRFs) for expressive interaction composition, and anchor keypoints for realistic motion synthesis. Extensive experiments demonstrate that AnchorHOI outperforms previous methods with superior diversity and generalization.

</details>


### [45] [OUSAC: Optimized Guidance Scheduling with Adaptive Caching for DiT Acceleration](https://arxiv.org/abs/2512.14096)
*Ruitong Sun,Tianze Yang,Wei Niu,Jin Sun*

Main category: cs.CV

TL;DR: 本文提出了一种名为OUSAC的新框架，通过优化采样步骤和自适应缓存机制，在不降低图像生成质量的情况下，大幅加速扩散 Transformer（DiT）；相较于现有方法，计算量降低显著且生成效果提升。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在高质量图像生成领域表现突出，但由于采样过程需要多次迭代反向过程，导致推理计算量极大。无分类器引导（CFG）虽然提升质量和可控性，却使计算量翻倍。本研究旨在显著减少该过程的计算负担，同时保证甚至提升生成效果。

Method: OUSAC包含两大技术：第一，借助进化算法联合优化哪些步长可以跳过CFG，以及在不同步长下应用何种引导强度，从而跳过高达82%的无条件分支而不损失质量；第二，为应对动态引导模式带来的缓存失效，提出按transformer block自适应分配校准算力，使在变化引导下缓存依然有效。

Result: 在DiT-XL/2（ImageNet 512x512）数据集上，OUSAC在保证/提升（15%↑）生成质量的前提下节省了53%的计算；在PixArt-alpha（MSCOCO）上，节省60%计算并提升16.1%质量；在FLUX模型上获得5倍加速，同时提高CLIP分数。

Conclusion: OUSAC以系统优化方法，兼顾节省算力与生成质量显著提升，超越了现有扩散采样加速方法，为高效可控图像生成提供了新思路。

Abstract: Diffusion models have emerged as the dominant paradigm for high-quality image generation, yet their computational expense remains substantial due to iterative denoising. Classifier-Free Guidance (CFG) significantly enhances generation quality and controllability but doubles the computation by requiring both conditional and unconditional forward passes at every timestep. We present OUSAC (Optimized gUidance Scheduling with Adaptive Caching), a framework that accelerates diffusion transformers (DiT) through systematic optimization. Our key insight is that variable guidance scales enable sparse computation: adjusting scales at certain timesteps can compensate for skipping CFG at others, enabling both fewer total sampling steps and fewer CFG steps while maintaining quality. However, variable guidance patterns introduce denoising deviations that undermine standard caching methods, which assume constant CFG scales across steps. Moreover, different transformer blocks are affected at different levels under dynamic conditions. This paper develops a two-stage approach leveraging these insights. Stage-1 employs evolutionary algorithms to jointly optimize which timesteps to skip and what guidance scale to use, eliminating up to 82% of unconditional passes. Stage-2 introduces adaptive rank allocation that tailors calibration efforts per transformer block, maintaining caching effectiveness under variable guidance. Experiments demonstrate that OUSAC significantly outperforms state-of-the-art acceleration methods, achieving 53% computational savings with 15% quality improvement on DiT-XL/2 (ImageNet 512x512), 60% savings with 16.1% improvement on PixArt-alpha (MSCOCO), and 5x speedup on FLUX while improving CLIP Score over the 50-step baseline.

</details>


### [46] [ViewMask-1-to-3: Multi-View Consistent Image Generation via Multimodal Diffusion Models](https://arxiv.org/abs/2512.14099)
*Ruishu Zhu,Zhihao Huang,Jiacheng Sun,Ping Luo,Hongyuan Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 本文提出了一种新的单图-文本驱动多视角图像生成方法ViewMask-1-to-3，通过离散扩散模型以及视觉Token化，实现无需复杂3D约束的多视图生成，并在多个数据集上取得领先表现。


<details>
  <summary>Details</summary>
Motivation: 现有多视角图像生成方法高度依赖3D建模或复杂的扩散模型，需要大量多视角训练数据和几何先验，对实际应用造成限制。作者希望探索更简单、更通用的生成方法，以克服上述障碍。

Method: 提出ViewMask-1-to-3方法，将多视角图像生成表示为离散序列建模任务，借助MAGVIT-v2对图片进行Token化，通过语言与视觉统一的掩码Token预测机制进行迭代解码，实现多视角的逐步生成。核心采用随机掩码与自注意力机制，简化了架构设计，无需额外的3D几何约束。

Result: 在GSO和3D-FUTURE两个主流多视角数据集上，ViewMask-1-to-3在PSNR、SSIM和LPIPS等评估指标均取得了平均第一的成绩，验证了该方法的有效性和优越性。

Conclusion: 离散扩散模型配合简单的Token生成机制，能够有效实现高一致性、简洁架构的多视角图像生成，是对现有复杂多视角生成方法的重要补充与突破。

Abstract: Multi-view image generation from a single image and text description remains challenging due to the difficulty of maintaining geometric consistency across different viewpoints. Existing approaches typically rely on 3D-aware architectures or specialized diffusion models that require extensive multi-view training data and complex geometric priors. In this work, we introduce ViewMask-1-to-3, a pioneering approach to apply discrete diffusion models to multi-view image generation. Unlike continuous diffusion methods that operate in latent spaces, ViewMask-1-to-3 formulates multi-view synthesis as a discrete sequence modeling problem, where each viewpoint is represented as visual tokens obtained through MAGVIT-v2 tokenization. By unifying language and vision through masked token prediction, our approach enables progressive generation of multiple viewpoints through iterative token unmasking with text input. ViewMask-1-to-3 achieves cross-view consistency through simple random masking combined with self-attention, eliminating the requirement for complex 3D geometric constraints or specialized attention architectures. Our approach demonstrates that discrete diffusion provides a viable and simple alternative to existing multi-view generation methods, ranking first on average across GSO and 3D-FUTURE datasets in terms of PSNR, SSIM, and LPIPS, while maintaining architectural simplicity.

</details>


### [47] [Neurosymbolic Inference On Foundation Models For Remote Sensing Text-to-image Retrieval With Complex Queries](https://arxiv.org/abs/2512.14102)
*Emanuele Mezzi,Gertjan Burghouts,Maarten Kruithof*

Main category: cs.CV

TL;DR: 本文提出了一种结合大语言模型（LLMs）与神经符号AI的新方法RUNE，用于提升遥感图像的文本检索性能，并解决解释性和复杂空间关系理解不足的问题。


<details>
  <summary>Details</summary>
Motivation: 虽然现有大规模视觉-语言模型（RS-LVLMs）在遥感文本到图像检索方面取得进展，但由于其隐式表征方式，模型在解释能力及应对复杂空间关系时表现不佳，影响实际应用。

Method: RUNE方法利用大语言模型把文本查询转化为一阶逻辑表达式（FOL），结合神经符号推理对检测到的实体执行显性逻辑推断，并通过逻辑拆分策略提升推理效率。基础模型仅用于生成逻辑表达式，真正推理交由神经符号模块完成。实验中对DOTA数据集重新标注并设计更复杂的查询任务，以进行评估对比。

Result: 实验证明，RUNE在复杂查询下显著优于主流的RS-LVLM联合嵌入方法。文中还引入RRQC和RRIU两个新指标，系统评估模型在查询复杂度和图像不确定性下的鲁棒性。RUNE不仅性能和鲁棒性更佳，且检索理由清晰可解释。

Conclusion: RUNE实现了遥感图像复杂文本检索的性能、健壮性与可解释性的同步提升，并展示了在实际场景（如灾后卫星图像检索）中的应用潜力。

Abstract: Text-to-image retrieval in remote sensing (RS) has advanced rapidly with the rise of large vision-language models (LVLMs) tailored for aerial and satellite imagery, culminating in remote sensing large vision-language models (RS-LVLMS). However, limited explainability and poor handling of complex spatial relations remain key challenges for real-world use. To address these issues, we introduce RUNE (Reasoning Using Neurosymbolic Entities), an approach that combines Large Language Models (LLMs) with neurosymbolic AI to retrieve images by reasoning over the compatibility between detected entities and First-Order Logic (FOL) expressions derived from text queries. Unlike RS-LVLMs that rely on implicit joint embeddings, RUNE performs explicit reasoning, enhancing performance and interpretability. For scalability, we propose a logic decomposition strategy that operates on conditioned subsets of detected entities, guaranteeing shorter execution time compared to neural approaches. Rather than using foundation models for end-to-end retrieval, we leverage them only to generate FOL expressions, delegating reasoning to a neurosymbolic inference module. For evaluation we repurpose the DOTA dataset, originally designed for object detection, by augmenting it with more complex queries than in existing benchmarks. We show the LLM's effectiveness in text-to-logic translation and compare RUNE with state-of-the-art RS-LVLMs, demonstrating superior performance. We introduce two metrics, Retrieval Robustness to Query Complexity (RRQC) and Retrieval Robustness to Image Uncertainty (RRIU), which evaluate performance relative to query complexity and image uncertainty. RUNE outperforms joint-embedding models in complex RS retrieval tasks, offering gains in performance, robustness, and explainability. We show RUNE's potential for real-world RS applications through a use case on post-flood satellite image retrieval.

</details>


### [48] [Selective, Controlled and Domain-Agnostic Unlearning in Pretrained CLIP: A Training- and Data-Free Approach](https://arxiv.org/abs/2512.14113)
*Ashish Mishra,Gyanaranjan Nayak,Tarun Kumar,Arpit Shah,Suparna Bhattacharya,Martin Foltin*

Main category: cs.CV

TL;DR: 本文提出了一种无需再训练和额外数据即可实现模型“遗忘”特定类别的框架，提升了预训练模型如CLIP的可控性和实用性。


<details>
  <summary>Details</summary>
Motivation: 实际应用中，有时需要让预训练模型忘记某些类别（如受限对象），但又不能损失与其他任务/类别相关的知识。现有方法多数涉及模型的重新训练，耗时且代价高。

Method: 提出了一种基于多模态零空间的遗忘方法，结合文本提示和由CLIP嵌入空间生成的视觉原型，实现了：（1）全局遗忘指定对象，（2）特定领域内的类别遗忘，比如仅在素描域中遗忘，（3）仅在部分领域完全遗忘。这一方法无需再训练或新数据。

Result: 新方法能有效地移除不需要的类别信息，同时保持对未移除类别的识别能力。多模态零空间机制实现了在多个视觉领域的精细遗忘控制。

Conclusion: 该方法为现实中需要模型“选择性遗忘”场景，提供了高效、灵活且无需额外训练或数据的技术方案，优于传统再训练型遗忘方法。

Abstract: Pretrained models like CLIP have demonstrated impressive zero-shot classification capabilities across diverse visual domains, spanning natural images, artistic renderings, and abstract representations. However, real-world applications often demand the removal (or "unlearning") of specific object classes without requiring additional data or retraining, or affecting the model's performance on unrelated tasks. In this paper, we propose a novel training- and data-free unlearning framework that enables three distinct forgetting paradigms: (1) global unlearning of selected objects across all domains, (2) domain-specific knowledge removal (e.g., eliminating sketch representations while preserving photo recognition), and (3) complete unlearning in selective domains. By leveraging a multimodal nullspace through synergistic integration of text prompts and synthesized visual prototypes derived from CLIP's joint embedding space, our method efficiently removes undesired class information while preserving the remaining knowledge. This approach overcomes the limitations of existing retraining-based methods and offers a flexible and computationally efficient solution for controlled model forgetting.

</details>


### [49] [MFE-GAN: Efficient GAN-based Framework for Document Image Enhancement and Binarization with Multi-scale Feature Extraction](https://arxiv.org/abs/2512.14114)
*Rui-Yang Ju,KokSheik Wong,Yanlin Jin,Jen-Shiun Chiang*

Main category: cs.CV

TL;DR: 本论文提出了一种高效的文档图像增强与二值化方法MFE-GAN，能够显著降低训练和推断时间，同时保持与最新方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有文档图像增强与二值化方法，常需要对不同颜色通道分别训练多个GAN，导致训练和推断时间过长，降低了实际应用效率。

Method: 提出MFE-GAN框架，利用多尺度特征提取(MFE)、Haar小波变换和归一化预处理，并设计了新的生成器、判别器和损失函数，统一高效地处理文档图像，无需对颜色通道分开训练多个GAN。

Result: 在Benchmark、Nabuco和CMATERdb三个数据集上，实验结果表明MFE-GAN在大幅减少总训练和推断时间的情况下，性能仍能与SOTA方法相媲美。

Conclusion: MFE-GAN提供了一个更高效的文档增强和二值化方案，为实际OCR等下游文档分析任务提供了技术支持，兼顾效率与效果。

Abstract: Document image enhancement and binarization are commonly performed prior to document analysis and recognition tasks for improving the efficiency and accuracy of optical character recognition (OCR) systems. This is because directly recognizing text in degraded documents, particularly in color images, often results in unsatisfactory recognition performance. To address these issues, existing methods train independent generative adversarial networks (GANs) for different color channels to remove shadows and noise, which, in turn, facilitates efficient text information extraction. However, deploying multiple GANs results in long training and inference times. To reduce both training and inference times of document image enhancement and binarization models, we propose MFE-GAN, an efficient GAN-based framework with multi-scale feature extraction (MFE), which incorporates Haar wavelet transformation (HWT) and normalization to process document images before feeding them into GANs for training. In addition, we present novel generators, discriminators, and loss functions to improve the model's performance, and we conduct ablation studies to demonstrate their effectiveness. Experimental results on the Benchmark, Nabuco, and CMATERdb datasets demonstrate that the proposed MFE-GAN significantly reduces the total training and inference times while maintaining comparable performance with respect to state-of-the-art (SOTA) methods. The implementation of this work is available at https://ruiyangju.github.io/MFE-GAN.

</details>


### [50] [SportsGPT: An LLM-driven Framework for Interpretable Sports Motion Assessment and Training Guidance](https://arxiv.org/abs/2512.14121)
*Wenbo Tian,Ruting Lin,Hongxian Zheng,Yaodong Yang,Geng Wu,Zihao Zhang,Zhang Zhang*

Main category: cs.CV

TL;DR: 本文提出了SportsGPT，一个基于大语言模型（LLM）驱动的端到端体育动作评估与训练指导系统，实现了从运动数据到专业训练建议的闭环。其核心包括运用新的动作对齐与关键帧提取算法，以及知识驱动的动作评测模型和基于RAG的训练指导模块，实验表明其在准确性和专业性上明显优于传统和通用LLM方法。


<details>
  <summary>Details</summary>
Motivation: 现有智能体育分析系统大多只关注记分和可视化，缺乏自动化表现诊断和可解释的训练指导，难以满足运动员专业训练和提升的实际需求。大语言模型与运动分析技术的进步，为更精准和智能的体育训练干预提供了新途径。

Method: 提出SportsGPT框架：（1）首先设计MotionDTW，创新的两阶段时序对齐算法，用于骨架运动序列的关键帧提取；（2）接着，提出知识驱动且可解释的体育动作评估模型KISMAM，通过关键帧与高质量目标模型对比生成多项可解释指标；（3）最后，设计SportsRAG，依托包含6B token领域知识库，通过知识增强检索与问答驱动LLM生成专业训练建议。

Result: 运动对齐算法MotionDTW相比传统方法在时间误差和IoU评分上显著提升。KISMAM与SportsRAG的消融实验进一步验证了各模块的有效性。此外SportsGPT整体在诊断准确性和专业性上优于通用大语言模型。

Conclusion: SportsGPT实现了从动作数据到智能可解释评测，再到个性化训练指导的完整闭环，相较现有系统在科学诊断和专业指导方面取得了重大突破，为智能体育训练带来了新可能。

Abstract: Existing intelligent sports analysis systems mainly focus on "scoring and visualization," often lacking automatic performance diagnosis and interpretable training guidance. Recent advances of Large Language Models (LMMs) and motion analysis techniques provide new opportunities to address the above limitations. In this paper, we propose SportsGPT, an LLM-driven framework for interpretable sports motion assessment and training guidance, which establishes a closed loop from motion time-series input to professional training guidance. First, given a set of high-quality target models, we introduce MotionDTW, a two-stage time series alignment algorithm designed for accurate keyframe extraction from skeleton-based motion sequences. Subsequently, we design a Knowledge-based Interpretable Sports Motion Assessment Model (KISMAM) to obtain a set of interpretable assessment metrics (e.g., insufficient extension) by constrasting the keyframes with the targe models. Finally, we propose SportsRAG, a RAG-based training guidance model based on Qwen3. Leveraging a 6B-token knowledge base, it prompts the LLM to generate professional training guidance by retrieving domain-specific QA pairs. Experimental results demonstrate that MotionDTW significantly outperforms traditional methods with lower temporal error and higher IoU scores. Furthermore, ablation studies validate the KISMAM and SportsRAG, confirming that SportsGPT surpasses general LLMs in diagnostic accuracy and professionalism.

</details>


### [51] [Consistent Instance Field for Dynamic Scene Understanding](https://arxiv.org/abs/2512.14126)
*Junyi Wu,Van Nguyen Nguyen,Benjamin Planche,Jiachen Tao,Changchang Sun,Zhongpai Gao,Zhenghao Zhao,Anwesa Choudhuri,Gengyu Zhang,Meng Zheng,Feiran Wang,Terrence Chen,Yan Yan,Ziyan Wu*

Main category: cs.CV

TL;DR: 论文提出了Consistent Instance Field，一种用于动态场景理解的连续、概率化时空表示法，通过基于可变形3D高斯的新型实例嵌入方式，能有效分离可见性与持久物体身份，并在多项任务上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有动态场景理解的方法通常依赖离散的目标追踪或者依赖视图的特征，难以保持时空上一致与泛化性。作者希望克服视图依赖和实例跟踪中一致性不强的问题，提升动态场景理解中实例分割的准确性与一致性。

Method: 作者提出了Consistent Instance Field，通过概率化方式为时空中每一点建模其可见性概率和条件实例分布。创新地采用基于可变形3D高斯的实例嵌入，联合编码辐射度和语义信息，并通过可微光栅化直接从RGB图像和实例mask中学习。此外，引入了高斯身份校准与重新采样机制，使实例在时空中表现更为一致。

Result: 在HyperNeRF和Neu3D数据集上的实验表明，该方法在新视角全景分割及开放词汇4D查询任务上，相较于最先进方法取得了显著性能提升。

Conclusion: Consistent Instance Field方法能更好地实现动态场景中实例的一致建模与分割，并具备较强的泛化能力，推动了动态场景理解领域的进步。

Abstract: We introduce Consistent Instance Field, a continuous and probabilistic spatio-temporal representation for dynamic scene understanding. Unlike prior methods that rely on discrete tracking or view-dependent features, our approach disentangles visibility from persistent object identity by modeling each space-time point with an occupancy probability and a conditional instance distribution. To realize this, we introduce a novel instance-embedded representation based on deformable 3D Gaussians, which jointly encode radiance and semantic information and are learned directly from input RGB images and instance masks through differentiable rasterization. Furthermore, we introduce new mechanisms to calibrate per-Gaussian identities and resample Gaussians toward semantically active regions, ensuring consistent instance representations across space and time. Experiments on HyperNeRF and Neu3D datasets demonstrate that our method significantly outperforms state-of-the-art methods on novel-view panoptic segmentation and open-vocabulary 4D querying tasks.

</details>


### [52] [Erasing CLIP Memories: Non-Destructive, Data-Free Zero-Shot class Unlearning in CLIP Models](https://arxiv.org/abs/2512.14137)
*Ashish Mishra,Tarun Kumar,Gyanaranjan Nayak,Arpit Shah,Suparna Bhattacharya,Martin Foltin*

Main category: cs.CV

TL;DR: 该论文提出了一种新颖的选择性遗忘方法，仅需一次闭式操作即可让多模态模型（如CLIP）忘记特定类别，无需任何再训练或使用要遗忘图片，且对模型整体性能影响较小。


<details>
  <summary>Details</summary>
Motivation: 当前主流的模型遗忘技术需要大量重复训练和数据筛选，成本高且难以精确控制。实际应用中常常需要让模型遗忘某些敏感或不合规类别信息，同时保证模型其它知识不受影响，因此更高效、精准的遗忘方法是迫切需求。

Method: 作者提出通过对目标类别的文本嵌入计算张成子空间，并构造其标准正交基，再将模型最终投影层对这些方向进行投影，使得图像特征与目标类别的对齐度显著降低，全程无需再训练或遗忘集图片。

Result: 实验表明，该方法能显著降低模型在目标类别上的零样本性能，而对其它类别知识影响极小，且当仅做部分投影时，能灵活权衡遗忘彻底性与信息保留。

Conclusion: 新方法能高效、精确地实现多模态模型的选择性遗忘，有效解决了模型净化和隐私保护中的多个关键难题，显示出很强的实际应用潜力。

Abstract: We introduce a novel, closed-form approach for selective unlearning in multimodal models, specifically targeting pretrained models such as CLIP. Our method leverages nullspace projection to erase the target class information embedded in the final projection layer, without requiring any retraining or the use of images from the forget set. By computing an orthonormal basis for the subspace spanned by target text embeddings and projecting these directions, we dramatically reduce the alignment between image features and undesired classes. Unlike traditional unlearning techniques that rely on iterative fine-tuning and extensive data curation, our approach is both computationally efficient and surgically precise. This leads to a pronounced drop in zero-shot performance for the target classes while preserving the overall multimodal knowledge of the model. Our experiments demonstrate that even a partial projection can balance between complete unlearning and retaining useful information, addressing key challenges in model decontamination and privacy preservation.

</details>


### [53] [SketchAssist: A Practical Assistant for Semantic Edits and Precise Local Redrawing](https://arxiv.org/abs/2512.14140)
*Han Zou,Yan Zhang,Ruiqi Yu,Cong Xie,Jie Huang,Zhenpeng Zhan*

Main category: cs.CV

TL;DR: 本文提出了SketchAssist，一种用于素描编辑的交互式助手系统，能在保持素描风格和结构的同时，实现语义级全局编辑与局部精细重绘。


<details>
  <summary>Details</summary>
Motivation: 现有图像编辑系统难以在素描等稀疏、风格敏感的线稿中，同时支持高层次语义修改和精确局部重绘，且难以保证非相关区域和整体布局不受影响。

Method: 作者搭建了一个可控的数据生成流程，通过对无属性素描添加属性，形成多步编辑链，并利用风格保留的属性移除模型扩展风格多样性。在此基础上，他们提出统一框架，重用RGB通道在输入层编码指令或线稿信息，并在LoRA层集成任务引导的专家混合结构，以文本和视觉线索引导模型专精不同任务。

Result: 大量实验表明，SketchAssist在指令遵循性、风格与结构保持方面，均优于近期同类方法，达到最新性能水平。

Conclusion: 本文所提数据集与SketchAssist，为素描创作与修改提供了实用、可控、同时保持风格与结构的智能助手。

Abstract: Sketch editing is central to digital illustration, yet existing image editing systems struggle to preserve the sparse, style-sensitive structure of line art while supporting both high-level semantic changes and precise local redrawing. We present SketchAssist, an interactive sketch drawing assistant that accelerates creation by unifying instruction-guided global edits with line-guided region redrawing, while keeping unrelated regions and overall composition intact. To enable this assistant at scale, we introduce a controllable data generation pipeline that (i) constructs attribute-addition sequences from attribute-free base sketches, (ii) forms multi-step edit chains via cross-sequence sampling, and (iii) expands stylistic coverage with a style-preserving attribute-removal model applied to diverse sketches. Building on this data, SketchAssist employs a unified sketch editing framework with minimal changes to DiT-based editors. We repurpose the RGB channels to encode the inputs, enabling seamless switching between instruction-guided edits and line-guided redrawing within a single input interface. To further specialize behavior across modes, we integrate a task-guided mixture-of-experts into LoRA layers, routing by text and visual cues to improve semantic controllability, structural fidelity, and style preservation. Extensive experiments show state-of-the-art results on both tasks, with superior instruction adherence and style/structure preservation compared to recent baselines. Together, our dataset and SketchAssist provide a practical, controllable assistant for sketch creation and revision.

</details>


### [54] [TorchTraceAP: A New Benchmark Dataset for Detecting Performance Anti-Patterns in Computer Vision Models](https://arxiv.org/abs/2512.14141)
*Hanning Chen,Keyu Man,Kevin Zhu,Chenguang Zhu,Haonan Li,Tongbo Luo,Xizhou Feng,Wei Sun,Sreen Tallam,Mohsen Imani,Partha Kanuparthy*

Main category: cs.CV

TL;DR: 本文提出了首个用于检测机器学习训练与推理过程中性能反模式的基准数据集，并提出了结合轻量级模型与大模型（LLM）的新方法，显著提升了反模式检测效果。


<details>
  <summary>Details</summary>
Motivation: 当前，分析和解决机器学习模型中的性能反模式需要深厚且跨领域的技术背景，且主要依赖于大公司专职的基础设施工程师，对于普通的计算机视觉研究人员来说获取门槛较高。尤其是在长时间执行trace中定位问题段落极为耗时，难以被现有方法（包括LLM）自动化处理。因此，亟需一种高效、通用的反模式检测机制。

Method: 作者收集了涵盖多种计算机视觉任务和硬件平台的600余条PyTorch执行trace，建立了首个相关基准数据集。提出了一种两步法：先由轻量级ML模型粗筛出疑似反模式段，再用大语言模型（LLM）做精细分类及反馈。

Result: 实验证明，该方法在识别反模式区域上显著优于无监督聚类和基于规则的统计技术。同时，该策略有效缓解了LLM上下文长度和推理效率有限的问题。

Conclusion: 该工作首次建立了针对执行trace反模式检测的公开基准，并提出了一种简单高效的新方法，为提升性能分析自动化水平、降低技术门槛提供了切实可行的解决方案。

Abstract: Identifying and addressing performance anti-patterns in machine learning (ML) models is critical for efficient training and inference, but it typically demands deep expertise spanning system infrastructure, ML models and kernel development. While large tech companies rely on dedicated ML infrastructure engineers to analyze torch traces and benchmarks, such resource-intensive workflows are largely inaccessible to computer vision researchers in general. Among the challenges, pinpointing problematic trace segments within lengthy execution traces remains the most time-consuming task, and is difficult to automate with current ML models, including LLMs. In this work, we present the first benchmark dataset specifically designed to evaluate and improve ML models' ability to detect anti patterns in traces. Our dataset contains over 600 PyTorch traces from diverse computer vision models classification, detection, segmentation, and generation collected across multiple hardware platforms. We also propose a novel iterative approach: a lightweight ML model first detects trace segments with anti patterns, followed by a large language model (LLM) for fine grained classification and targeted feedback. Experimental results demonstrate that our method significantly outperforms unsupervised clustering and rule based statistical techniques for detecting anti pattern regions. Our method also effectively compensates LLM's limited context length and reasoning inefficiencies.

</details>


### [55] [CIS-BA: Continuous Interaction Space Based Backdoor Attack for Object Detection in the Real-World](https://arxiv.org/abs/2512.14158)
*Shuxin Zhao,Bo Lang,Nan Xiao,Yilang Zhang*

Main category: cs.CV

TL;DR: 提出了一种新的后门攻击方法CIS-BA，可对目标检测模型进行更复杂、鲁棒性更强的攻击，尤其适用于物体间存在复杂交互的实际场景。


<details>
  <summary>Details</summary>
Motivation: 现有目标检测后门攻击方式依赖单一触发器和像素级特征，容易被检测和防御，且在多目标、多触发器复杂场景下能力受限。研究更自然且难以防御的攻击模式具有实际意义。

Method: 作者提出CIS-BA范式，用于捕捉物体共现和交互形成的连续空间触发器。设计了CIS-Frame框架，从交互模式中提取空间触发约束，用于训练时投毒，实现单目标及多目标同步后门攻击。该方法通过嵌入不变的几何关系，增强攻击鲁棒性。

Result: 实验表明，CIS-BA在MS-COCO和真实视频中复杂环境下攻击成功率超97%，多触发条件下仍有效性超95%，并能规避三种主流防御方法。

Conclusion: CIS-BA突破了传统后门攻击的局限，为高交互场景下目标检测模型安全研究提供了新思路和更具威胁性的攻击方式。

Abstract: Object detection models deployed in real-world applications such as autonomous driving face serious threats from backdoor attacks. Despite their practical effectiveness,existing methods are inherently limited in both capability and robustness due to their dependence on single-trigger-single-object mappings and fragile pixel-level cues. We propose CIS-BA, a novel backdoor attack paradigm that redefines trigger design by shifting from static object features to continuous inter-object interaction patterns that describe how objects co-occur and interact in a scene. By modeling these patterns as a continuous interaction space, CIS-BA introduces space triggers that, for the first time, enable a multi-trigger-multi-object attack mechanism while achieving robustness through invariant geometric relations. To implement this paradigm, we design CIS-Frame, which constructs space triggers via interaction analysis, formalizes them as class-geometry constraints for sample poisoning, and embeds the backdoor during detector training. CIS-Frame supports both single-object attacks (object misclassification and disappearance) and multi-object simultaneous attacks, enabling complex and coordinated effects across diverse interaction states. Experiments on MS-COCO and real-world videos show that CIS-BA achieves over 97% attack success under complex environments and maintains over 95% effectiveness under dynamic multi-trigger conditions, while evading three state-of-the-art defenses. In summary, CIS-BA extends the landscape of backdoor attacks in interaction-intensive scenarios and provides new insights into the security of object detection systems.

</details>


### [56] [FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation](https://arxiv.org/abs/2512.14162)
*Qingyuan Cai,Linxin Zhang,Xuecai Hu,Saihui Hou,Yongzhen Huang*

Main category: cs.CV

TL;DR: 本文提出了Fast3DHPE，一个整合现有单目3D人体姿态估计方法的模块化统一框架，并在该框架下推出了基于扩散模型的FastDDHPose方法，显著提升了训练效率和公平性，并在主要数据集上获得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有单目3D人体姿态估计方法普遍缺乏统一的训练和评估框架，导致不同方法之间难以进行公平比较，也限制了新方法的快速开发与复现。

Method: 1）提出Fast3DHPE，标准化训练和评估流程，提供模块化开发环境。2）提出FastDDHPose，基于扩散模型分离建模骨长与骨方向分布，避免误差积累。3）设计高效的运动学-层级空间时间去噪器，引导模型关注关节点运动学结构，减少不必要的复杂结构建模。

Result: 在Human3.6M和MPI-INF-3DHP等主流数据集上，Fast3DHPE显著提升训练效率，实现了所有方法的公平对比。FastDDHPose在统一框架下取得了最新最优性能，展现出强泛化能力和实际场景鲁棒性。

Conclusion: Fast3DHPE为单目3D人体姿态估计提供了公平、高效、可扩展的平台，并促成新方法的快速开发。FastDDHPose方法兼具准确性与泛化能力，有望推动3D HPE领域进一步发展。

Abstract: Recent approaches for monocular 3D human pose estimation (3D HPE) have achieved leading performance by directly regressing 3D poses from 2D keypoint sequences. Despite the rapid progress in 3D HPE, existing methods are typically trained and evaluated under disparate frameworks, lacking a unified framework for fair comparison. To address these limitations, we propose Fast3DHPE, a modular framework that facilitates rapid reproduction and flexible development of new methods. By standardizing training and evaluation protocols, Fast3DHPE enables fair comparison across 3D human pose estimation methods while significantly improving training efficiency. Within this framework, we introduce FastDDHPose, a Disentangled Diffusion-based 3D Human Pose Estimation method which leverages the strong latent distribution modeling capability of diffusion models to explicitly model the distributions of bone length and bone direction while avoiding further amplification of hierarchical error accumulation. Moreover, we design an efficient Kinematic-Hierarchical Spatial and Temporal Denoiser that encourages the model to focus on kinematic joint hierarchies while avoiding unnecessary modeling of overly complex joint topologies. Extensive experiments on Human3.6M and MPI-INF-3DHP show that the Fast3DHPE framework enables fair comparison of all methods while significantly improving training efficiency. Within this unified framework, FastDDHPose achieves state-of-the-art performance with strong generalization and robustness in in-the-wild scenarios. The framework and models will be released at: https://github.com/Andyen512/Fast3DHPE

</details>


### [57] [Improving Semantic Uncertainty Quantification in LVLMs with Semantic Gaussian Processes](https://arxiv.org/abs/2512.14177)
*Joseph Hoche,Andrei Bursuc,David Brellmann,Gilles Louppe,Pavel Izmailov,Angela Yao,Gianni Franchi*

Main category: cs.CV

TL;DR: 本文提出了SGPU，一种新的贝叶斯框架，用于量化大规模视觉-语言模型（LVLMs）输出的语义不确定性，能更可靠地衡量模型回答的信心水平，且在多个任务和模型上取得了出色表现。


<details>
  <summary>Details</summary>
Motivation: 现有的语义不确定性估计方法主要依赖带有聚类的外部模型，这些聚类方法容易受到表述微小变化的影响，会错误分组语义相近的答案，导致不准确的结果。因此需要更鲁棒的方法来度量LVLMs的输出不确定性。

Method: SGPU首先把模型生成的答案映射到稠密的语义空间中，再计算这些嵌入向量的Gram矩阵，并用其谱（特征值分布）来表征答案集的语义结构。通过将谱表示输入高斯过程分类器，学习将语义一致性的模式映射到预测不确定性，无需敏感的语义聚类。

Result: SGPU在六个LLM和LVLM模型、八个涵盖VQA、图像分类和文本问答的数据集上，显著提升了模型校准（ECE）与区分度（AUROC、AUARC）等关键指标，达到SOTA水平。

Conclusion: SGPU不仅改进了LVLMs的语义不确定性估计，还能跨模型、跨模态迁移，表明其谱表示可捕捉普遍的语义不确定性模式，可广泛应用于提升多模态大模型的安全与可靠性。

Abstract: Large Vision-Language Models (LVLMs) often produce plausible but unreliable outputs, making robust uncertainty estimation essential. Recent work on semantic uncertainty estimates relies on external models to cluster multiple sampled responses and measure their semantic consistency. However, these clustering methods are often fragile, highly sensitive to minor phrasing variations, and can incorrectly group or separate semantically similar answers, leading to unreliable uncertainty estimates. We propose Semantic Gaussian Process Uncertainty (SGPU), a Bayesian framework that quantifies semantic uncertainty by analyzing the geometric structure of answer embeddings, avoiding brittle clustering. SGPU maps generated answers into a dense semantic space, computes the Gram matrix of their embeddings, and summarizes their semantic configuration via the eigenspectrum. This spectral representation is then fed into a Gaussian Process Classifier that learns to map patterns of semantic consistency to predictive uncertainty, and that can be applied in both black-box and white-box settings. Across six LLMs and LVLMs on eight datasets spanning VQA, image classification, and textual QA, SGPU consistently achieves state-of-the-art calibration (ECE) and discriminative (AUROC, AUARC) performance. We further show that SGPU transfers across models and modalities, indicating that its spectral representation captures general patterns of semantic uncertainty.

</details>


### [58] [Spherical Voronoi: Directional Appearance as a Differentiable Partition of the Sphere](https://arxiv.org/abs/2512.14180)
*Francesco Di Sario,Daniel Rebain,Dor Verbin,Marco Grangetto,Andrea Tagliasacchi*

Main category: cs.CV

TL;DR: 本文提出用Spherical Voronoi (SV) 方法替代常用的Spherical Harmonics（SH），改进3D高斯Splatting外观建模，能有效解决SH处理高频信号和镜面反射的局限，同时优化过程更简单；在合成和真实数据集上达到了最新最优效果。


<details>
  <summary>Details</summary>
Motivation: 当前3D高斯Splatting等辐射场方法常用的SH在高频信号和镜面反射建模上表现不佳，且存在Gibbs振铃、反射失效等问题。其它替代方法（如球面高斯）优化复杂，亟需更有效且易优化的外观表示方案。

Method: 提出Spherical Voronoi (SV) 框架，将方向域分割为可学习的光滑区域，参数化视角相关效果。漫反射用SV表现可与现有方法竞争，镜面反射则将SV作为可学习的反射探针，输入反射方向实现高质量建模。

Result: SV在漫反射建模上简化了优化过程，并在需要镜面反射建模时远超过SH，实现了对合成及真实数据集上的最新最优性能。

Conclusion: Spherical Voronoi为3D高斯Splatting中的外观建模提供了原理清晰、高效且通用的新方案，能够稳健处理高频和镜面反射问题，具有广泛的应用前景。

Abstract: Radiance field methods (e.g. 3D Gaussian Splatting) have emerged as a powerful paradigm for novel view synthesis, yet their appearance modeling often relies on Spherical Harmonics (SH), which impose fundamental limitations. SH struggle with high-frequency signals, exhibit Gibbs ringing artifacts, and fail to capture specular reflections - a key component of realistic rendering. Although alternatives like spherical Gaussians offer improvements, they add significant optimization complexity. We propose Spherical Voronoi (SV) as a unified framework for appearance representation in 3D Gaussian Splatting. SV partitions the directional domain into learnable regions with smooth boundaries, providing an intuitive and stable parameterization for view-dependent effects. For diffuse appearance, SV achieves competitive results while keeping optimization simpler than existing alternatives. For reflections - where SH fail - we leverage SV as learnable reflection probes, taking reflected directions as input following principles from classical graphics. This formulation attains state-of-the-art results on synthetic and real-world datasets, demonstrating that SV offers a principled, efficient, and general solution for appearance modeling in explicit 3D representations.

</details>


### [59] [Fracture Morphology Classification: Local Multiclass Modeling for Multilabel Complexity](https://arxiv.org/abs/2512.14196)
*Cassandra Krause,Mattias P. Heinrich,Ron Keuth*

Main category: cs.CV

TL;DR: 提出了一种能够自动为儿童骨折框分配全球AO编码的方法，以提升骨折形态学诊断表现，平均F1提升7.89%。


<details>
  <summary>Details</summary>
Motivation: 儿童骨折发生率高且诊断需精确，骨折形态学是诊断要素之一，因此亟需自动化的骨折特征提取方法以辅助诊断。

Method: 通过将骨折检测框自动分配全球AO编码，将原本的全局多标签任务转化为局部多类别任务，从而提升特征识别性能，并利用公开数据集进行训练和评估。

Result: 该方法在骨折形态学提取任务中平均F1分数提升了7.89%，但在骨折检测器存在缺陷时性能下降。

Conclusion: 提出的方法显著改善了骨折形态学诊断性能，为自动化骨折分析提供了新思路，但实际部署时仍需解决检测器不理想带来的挑战。

Abstract: Between $15\,\%$ and $45\,\%$ of children experience a fracture during their growth years, making accurate diagnosis essential. Fracture morphology, alongside location and fragment angle, is a key diagnostic feature. In this work, we propose a method to extract fracture morphology by assigning automatically global AO codes to corresponding fracture bounding boxes. This approach enables the use of public datasets and reformulates the global multilabel task into a local multiclass one, improving the average F1 score by $7.89\,\%$. However, performance declines when using imperfect fracture detectors, highlighting challenges for real-world deployment. Our code is available on GitHub.

</details>


### [60] [Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination](https://arxiv.org/abs/2512.14200)
*Zhuoxiao Li,Wenzong Ma,Taoyu Wu,Jinjing Zhu,Zhenchao Q,Shuai Zhang,Jing Ou,Yinrui Ren,Weiqing Qi,Guobin Shen,Hui Xiong,Wufan Zhao*

Main category: cs.CV

TL;DR: 本文提出了SkyLume数据集，这是一个面向城市场景、具有多时段采集的无人机影像大规模真实世界数据集。该数据集可用于研究光照变化下的鲁棒三维重建，并引入了评估反演渲染的全新指标TCC。


<details>
  <summary>Details</summary>
Motivation: 尽管神经辐射场和三维高斯喷溅方法在无人机三维重建中表现出色，但现实中的无人机大规模三维采集常因不同时间的光照不一致而导致颜色伪影和几何失真。由于缺乏系统记录光照变化的无人机数据集，这一问题尚未充分探索。

Method: 作者收集了10个城市区域、超过10万张高分辨率无人机图像（包括四个侧视和垂直视角），每个区域在一天的三个时间段采集，以系统性地隔离光照变化。同时，提供每个场景的激光雷达数据和精确的三维真值，用于评估不同光照下的深度、表面法线与重建质量。最后提出了TCC指标，用于衡量多时段间反演渲染的反照率稳定性。

Result: 构建了涵盖多时段、多视角和高精度三维基准（激光雷达、表面法线、深度、真值模型）的SkyLume数据集，并提出TCC指标，具备良好评估复杂光照变化下三维重建/反演效果的能力。

Conclusion: SkyLume弥补了无人机城市场景大规模、多时段、高精度三维数据集的空白，为城市级三维重建、逆向渲染、视图合成等研究的现实评测与进步提供了坚实基础。

Abstract: Recent advances in Neural Radiance Fields and 3D Gaussian Splatting have demonstrated strong potential for large-scale UAV-based 3D reconstruction tasks by fitting the appearance of images. However, real-world large-scale captures are often based on multi-temporal data capture, where illumination inconsistencies across different times of day can significantly lead to color artifacts, geometric inaccuracies, and inconsistent appearance. Due to the lack of UAV datasets that systematically capture the same areas under varying illumination conditions, this challenge remains largely underexplored. To fill this gap, we introduceSkyLume, a large-scale, real-world UAV dataset specifically designed for studying illumination robust 3D reconstruction in urban scene modeling: (1) We collect data from 10 urban regions data comprising more than 100k high resolution UAV images (four oblique views and nadir), where each region is captured at three periods of the day to systematically isolate illumination changes. (2) To support precise evaluation of geometry and appearance, we provide per-scene LiDAR scans and accurate 3D ground-truth for assessing depth, surface normals, and reconstruction quality under varying illumination. (3) For the inverse rendering task, we introduce the Temporal Consistency Coefficient (TCC), a metric that measuress cross-time albedo stability and directly evaluates the robustness of the disentanglement of light and material. We aim for this resource to serve as a foundation that advances research and real-world evaluation in large-scale inverse rendering, geometry reconstruction, and novel view synthesis.

</details>


### [61] [OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving](https://arxiv.org/abs/2512.14225)
*Tao Tang,Enhui Ma,xia zhou,Letian Wang,Tianyi Yan,Xueyang Zhang,Kun Zhan,Peng Jia,XianPeng Lang,Jia-Wang Bian,Kaicheng Yu,Xiaodan Liang*

Main category: cs.CV

TL;DR: 本文提出OminiGen框架，利用统一的鸟瞰视角空间和创新的多模态重建方法，实现了高一致性的多模态传感器数据生成，可同时灵活重建激光雷达和多视角摄像头信息。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶领域依赖大量真实场景数据，但采集多样性和极端情况的数据成本高、效率低。现有生成模型多聚焦于单一模态，难以满足多模态一致和高效数据需求。

Method: 提出OminiGen统一框架，利用共享的鸟瞰视角(BEV)特征融合多模态信息，并设计通用可推广的多模态重建方法UAE，基于体素渲染解码重构激光雷达和多视角摄像头数据。此外，结合扩散Transformer和ControlNet实现可控的数据生成。

Result: 实验结果显示，OminiGen在多模态传感器数据统一生成上表现优异，能够保证多模态数据之间的一致性，并支持灵活的传感器参数调整。

Conclusion: OminiGen显著提升了自动驾驶仿真和算法测试中多模态数据的生成效率与一致性，为相关领域数据生成与利用提供了有效工具。

Abstract: Autonomous driving has seen remarkable advancements, largely driven by extensive real-world data collection. However, acquiring diverse and corner-case data remains costly and inefficient. Generative models have emerged as a promising solution by synthesizing realistic sensor data. However, existing approaches primarily focus on single-modality generation, leading to inefficiencies and misalignment in multimodal sensor data. To address these challenges, we propose OminiGen, which generates aligned multimodal sensor data in a unified framework. Our approach leverages a shared Bird\u2019s Eye View (BEV) space to unify multimodal features and designs a novel generalizable multimodal reconstruction method, UAE, to jointly decode LiDAR and multi-view camera data. UAE achieves multimodal sensor decoding through volume rendering, enabling accurate and flexible reconstruction. Furthermore, we incorporate a Diffusion Transformer (DiT) with a ControlNet branch to enable controllable multimodal sensor generation. Our comprehensive experiments demonstrate that OminiGen achieves desired performances in unified multimodal sensor data generation with multimodal consistency and flexible sensor adjustments.

</details>


### [62] [Multi-View MRI Approach for Classification of MGMT Methylation in Glioblastoma Patients](https://arxiv.org/abs/2512.14232)
*Rawan Alyahya,Asrar Alruwayqi,Atheer Alqarni,Asma Alkhaldi,Metab Alkubeyyer,Xin Gao,Mona Alshahrani*

Main category: cs.CV

TL;DR: 本研究提出了一种基于MRI影像和深度学习的多视角方法，用于无创检测GBM患者MGMT启动子甲基化状态，并验证其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 检测MGMT启动子甲基化状态对GBM化疗响应具有重要意义，当前却依赖侵入性活检。研究目标是开发一种无创、精度高的新型判别方法。

Method: 利用MRI影像和深度学习，提出多视角方法，结合不同视角间空间关系，无需复杂的3D模型；还创新提出肿瘤切片提取算法，并与主流方法系统比较。

Result: 所提出方法在多个评价指标上优于现有方法，并展示模型在准确区分MGMT甲基化状态上的有效性。此外，公开了复现性高的模型管线。

Conclusion: 该研究显著推动了GBM精准医疗，证明了基于影像的无创MGMT检测方法的潜力，并为构建更加透明、鲁棒的诊断工具奠定基础。

Abstract: The presence of MGMT promoter methylation significantly affects how well chemotherapy works for patients with Glioblastoma Multiforme (GBM). Currently, confirmation of MGMT promoter methylation relies on invasive brain tumor tissue biopsies. In this study, we explore radiogenomics techniques, a promising approach in precision medicine, to identify genetic markers from medical images. Using MRI scans and deep learning models, we propose a new multi-view approach that considers spatial relationships between MRI views to detect MGMT methylation status. Importantly, our method extracts information from all three views without using a complicated 3D deep learning model, avoiding issues associated with high parameter count, slow convergence, and substantial memory demands. We also introduce a new technique for tumor slice extraction and show its superiority over existing methods based on multiple evaluation metrics. By comparing our approach to state-of-the-art models, we demonstrate the efficacy of our method. Furthermore, we share a reproducible pipeline of published models, encouraging transparency and the development of robust diagnostic tools. Our study highlights the potential of non-invasive methods for identifying MGMT promoter methylation and contributes to advancing precision medicine in GBM treatment.

</details>


### [63] [ViBES: A Conversational Agent with Behaviorally-Intelligent 3D Virtual Body](https://arxiv.org/abs/2512.14234)
*Juze Zhang,Changan Chen,Xin Chen,Heng Yu,Tiange Xiang,Ali Sartaz Khan,Shrinidhi K. Lakshmikanth,Ehsan Adeli*

Main category: cs.CV

TL;DR: ViBES提出了一种能够在多轮对话中联合生成语言和动作的3D虚拟智能体模型，有效提升了对话与行为的协调和社交能力。


<details>
  <summary>Details</summary>
Motivation: 现有的虚拟人主要将对话文本直接映射成动作，缺乏对于何时、如何行动的灵活决策，导致行为机械、社交适应性弱，各模态割裂。需要一种模型能够自然、主动地协调语言与肢体多模态表达。

Method: ViBES利用混合模态专家（MoME）结构，将Transformer专家按模态（语音、面部表情、身体动作）专责建模，参数分离但利用跨专家注意力共享信息。模型可同时处理各模态token流，支持用户在对话中灵活发起文字、语音或动作指令，并可流式地进行可控行为生成。

Result: ViBES在多轮对话中的对话-动作同步性和行为质量自动评测指标上，相较于主流co-speech和text-to-motion基线模型均实现了稳定提升。

Conclusion: ViBES实现了超越传统“语音驱动动作生成”的多模态虚拟体，为自然、可控、社交能力强的3D虚拟交互体验提供了有力支持。相关代码和数据将公开。

Abstract: Human communication is inherently multimodal and social: words, prosody, and body language jointly carry intent. Yet most prior systems model human behavior as a translation task co-speech gesture or text-to-motion that maps a fixed utterance to motion clips-without requiring agentic decision-making about when to move, what to do, or how to adapt across multi-turn dialogue. This leads to brittle timing, weak social grounding, and fragmented stacks where speech, text, and motion are trained or inferred in isolation. We introduce ViBES (Voice in Behavioral Expression and Synchrony), a conversational 3D agent that jointly plans language and movement and executes dialogue-conditioned body actions. Concretely, ViBES is a speech-language-behavior (SLB) model with a mixture-of-modality-experts (MoME) backbone: modality-partitioned transformer experts for speech, facial expression, and body motion. The model processes interleaved multimodal token streams with hard routing by modality (parameters are split per expert), while sharing information through cross-expert attention. By leveraging strong pretrained speech-language models, the agent supports mixed-initiative interaction: users can speak, type, or issue body-action directives mid-conversation, and the system exposes controllable behavior hooks for streaming responses. We further benchmark on multi-turn conversation with automatic metrics of dialogue-motion alignment and behavior quality, and observe consistent gains over strong co-speech and text-to-motion baselines. ViBES goes beyond "speech-conditioned motion generation" toward agentic virtual bodies where language, prosody, and movement are jointly generated, enabling controllable, socially competent 3D interaction. Code and data will be made available at: ai.stanford.edu/~juze/ViBES/

</details>


### [64] [4D-RaDiff: Latent Diffusion for 4D Radar Point Cloud Generation](https://arxiv.org/abs/2512.14235)
*Jimmie Kwok,Holger Caesar,Andras Palffy*

Main category: cs.CV

TL;DR: 本文提出了一种生成高质量4D雷达点云的框架（4D-RaDiff），可用于目标检测模型训练和评估，缓解雷达数据标注稀缺的问题，并显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 雷达因价格低、耐恶劣天气而在环境感知中应用广泛，但缺乏标注数据限制了感知系统的发展，需要生成并利用高质量的合成雷达点云数据支持检测任务。

Method: 作者提出4D-RaDiff方法，通过在潜在点云表征空间上基于扩散模型进行点云生成，并可根据物体或场景层级进行有条件生成。同时，该方法支持将未标注的包围盒自动转化为雷达标注，也能将激光雷达数据转换为真实感雷达场景点云，用于训练和评估。

Result: 实验显示，使用4D-RaDiff生成的合成雷达点云作数据增强，能持续提升目标检测性能。预训练时采用该方法生成的数据，还能将所需真实雷达标注量减少90%，且检测效果与全真实数据训练可比。

Conclusion: 4D-RaDiff能有效缓解 annotated 雷达点云稀缺问题，用合成数据提升检测性能，并大幅降低人工标注需求，为自动驾驶等领域雷达感知系统的发展提供重要支持。

Abstract: Automotive radar has shown promising developments in environment perception due to its cost-effectiveness and robustness in adverse weather conditions. However, the limited availability of annotated radar data poses a significant challenge for advancing radar-based perception systems. To address this limitation, we propose a novel framework to generate 4D radar point clouds for training and evaluating object detectors. Unlike image-based diffusion, our method is designed to consider the sparsity and unique characteristics of radar point clouds by applying diffusion to a latent point cloud representation. Within this latent space, generation is controlled via conditioning at either the object or scene level. The proposed 4D-RaDiff converts unlabeled bounding boxes into high-quality radar annotations and transforms existing LiDAR point cloud data into realistic radar scenes. Experiments demonstrate that incorporating synthetic radar data of 4D-RaDiff as data augmentation method during training consistently improves object detection performance compared to training on real data only. In addition, pre-training on our synthetic data reduces the amount of required annotated radar data by up to 90% while achieving comparable object detection performance.

</details>


### [65] [Elastic3D: Controllable Stereo Video Conversion with Guided Latent Decoding](https://arxiv.org/abs/2512.14236)
*Nando Metzger,Prune Truong,Goutam Bhat,Konrad Schindler,Federico Tombari*

Main category: cs.CV

TL;DR: Elastic3D提出了一种端到端、可控的单目视频到立体视频自动转换方法，在多个数据集上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着对沉浸式3D内容需求的增加，单目视频自动转化为立体视频成为亟需解决的技术难题，现有方法普遍依赖深度估计和图像扭曲，易带来伪影与不一致问题。

Method: 该方法基于有条件的潜变量扩散模型（latent diffusion），结合创新性的受引导VAE解码器，跳过直接深度估计和扭曲过程，从而规避传统方法的伪影问题。同时，用户在推理阶段可通过调节单一参数对立体效应强弱进行控制。

Result: 在三个真实世界的立体视频数据集上，Elastic3D相比基于图像扭曲的经典方法和最新无扭曲基线在输出质量和可控性方面有显著提升。

Conclusion: Elastic3D为单目视频升级为立体视频提供了高质量、可控且鲁棒的新途径，在自动3D视频内容生产领域设定了新标准。

Abstract: The growing demand for immersive 3D content calls for automated monocular-to-stereo video conversion. We present Elastic3D, a controllable, direct end-to-end method for upgrading a conventional video to a binocular one. Our approach, based on (conditional) latent diffusion, avoids artifacts due to explicit depth estimation and warping. The key to its high-quality stereo video output is a novel, guided VAE decoder that ensures sharp and epipolar-consistent stereo video output. Moreover, our method gives the user control over the strength of the stereo effect (more precisely, the disparity range) at inference time, via an intuitive, scalar tuning knob. Experiments on three different datasets of real-world stereo videos show that our method outperforms both traditional warping-based and recent warping-free baselines and sets a new standard for reliable, controllable stereo video conversion. Please check the project page for the video samples https://elastic3d.github.io.

</details>


### [66] [Enhancing Visual Programming for Visual Reasoning via Probabilistic Graphs](https://arxiv.org/abs/2512.14257)
*Wentao Wan,Kaiyu Wu,Qingyang Ma,Nan Kang,Yunjie Chen,Liang Lin,Keze Wang*

Main category: cs.CV

TL;DR: 本文提出了一种创新方法（EVPG），将视觉编程（VP）过程转化为可微分的概率图推断过程，从而实现了大规模语言模型驱动的视觉推理任务的端到端高效优化，显著提升了传统VP系统在经典视觉推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有VP研究仅关注提升由大语言模型生成的视觉程序质量，忽视了优化由VP调用的预训练子模型。而这些子模型对于分解的视觉子任务至关重要，且VP流程本身不可微分，无法端到端训练，极大限制了性能提升。

Method: 作者提出EVPG方法，将VP过程中的变量依赖关系构建为有向概率图。通过重构VP为可微分的概率推理过程，使整个VP框架能够利用最终标签进行高效的梯度优化，实现端到端的监督学习。

Result: 在GQA、NLVRv2和Open Images三大复杂视觉推理任务上，EVPG方法显著提升了VP推理的性能，实验结果充分证明了其有效性和优越性。

Conclusion: EVPG创新性地解决了VP不可微、难以端到端优化的问题，为大语言模型驱动的视觉推理开辟了新途径，并对后续相关研究具有重要参考价值。

Abstract: Recently, Visual Programming (VP) based on large language models (LLMs) has rapidly developed and demonstrated significant potential in complex Visual Reasoning (VR) tasks. Previous works to enhance VP have primarily focused on improving the quality of LLM-generated visual programs. However, they have neglected to optimize the VP-invoked pre-trained models, which serve as modules for the visual sub-tasks decomposed from the targeted tasks by VP. The difficulty is that there are only final labels of targeted VR tasks rather than labels of sub-tasks. Besides, the non-differentiable nature of VP impedes the direct use of efficient gradient-based optimization methods to leverage final labels for end-to-end learning of the entire VP framework. To overcome these issues, we propose EVPG, a method to Enhance Visual Programming for visual reasoning via Probabilistic Graphs. Specifically, we creatively build a directed probabilistic graph according to the variable dependency relationships during the VP executing process, which reconstructs the non-differentiable VP executing process into a differentiable exact probability inference process on this directed probabilistic graph. As a result, this enables the VP framework to utilize the final labels for efficient, gradient-based optimization in end-to-end supervised learning on targeted VR tasks. Extensive and comprehensive experiments demonstrate the effectiveness and advantages of our EVPG, showing significant performance improvements for VP on three classical complex VR tasks: GQA, NLVRv2, and Open Images.

</details>


### [67] [DriverGaze360: OmniDirectional Driver Attention with Object-Level Guidance](https://arxiv.org/abs/2512.14266)
*Shreedhar Govil,Didier Stricker,Jason Rambach*

Main category: cs.CV

TL;DR: 本文提出了DriverGaze360数据集和DriverGaze360-Net模型，用以提升对全方位驾驶员注意力的预测能力，并在多项指标上达到最新水平。


<details>
  <summary>Details</summary>
Motivation: 现有驾驶员注意力预测工作受限于前方窄视场和驾驶场景多样性不足，难以捕捉车道变换、转弯及与周边物体互动时的完整空间环境信息。

Method: 作者提出了DriverGaze360数据集，覆盖360度视野，包含约100万带注视标注的帧，同时提出基于全景输入的DriverGaze360-Net模型，其通过辅助语义分割头协同学习注意力热图和被关注对象，从而提升空间感知和注意力预测能力。

Result: DriverGaze360-Net方法在全景驾驶图片上的多个指标上取得了最新最优注意力预测表现，相关数据集和方法已开源。

Conclusion: 结合全景标注数据和新型全景网络结构能够更准确地预测驾驶员注意力，有助于发展可解释性更强的自动驾驶系统及理解人类驾驶行为。

Abstract: Predicting driver attention is a critical problem for developing explainable autonomous driving systems and understanding driver behavior in mixed human-autonomous vehicle traffic scenarios. Although significant progress has been made through large-scale driver attention datasets and deep learning architectures, existing works are constrained by narrow frontal field-of-view and limited driving diversity. Consequently, they fail to capture the full spatial context of driving environments, especially during lane changes, turns, and interactions involving peripheral objects such as pedestrians or cyclists. In this paper, we introduce DriverGaze360, a large-scale 360$^\circ$ field of view driver attention dataset, containing $\sim$1 million gaze-labeled frames collected from 19 human drivers, enabling comprehensive omnidirectional modeling of driver gaze behavior. Moreover, our panoramic attention prediction approach, DriverGaze360-Net, jointly learns attention maps and attended objects by employing an auxiliary semantic segmentation head. This improves spatial awareness and attention prediction across wide panoramic inputs. Extensive experiments demonstrate that DriverGaze360-Net achieves state-of-the-art attention prediction performance on multiple metrics on panoramic driving images. Dataset and method available at https://av.dfki.de/drivergaze360.

</details>


### [68] [Zoom-Zero: Reinforced Coarse-to-Fine Video Understanding via Temporal Zoom-in](https://arxiv.org/abs/2512.14273)
*Xiaoqian Shen,Min-Hung Chen,Yu-Chiang Frank Wang,Mohamed Elhoseiny,Ryo Hachiuma*

Main category: cs.CV

TL;DR: 本文提出Zoom-Zero框架，通过粗到细的方式提升视频问答任务中的时间定位和答案准确性，在多个数据集上实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有大型视频—语言模型（LVLMs）在处理视频问答任务时，时间定位能力有限，容易出现答案未能基于正确信息的情况。现有GRPO方法虽有提升，但仍存在定位不精准和幻觉问题。

Method: 提出Zoom-Zero框架，分两步进行：首先粗定位与问题相关的视频片段，然后对关键帧进行细致验证。引入两项创新：一是zoom-in accuracy reward，用于验证和提升定位精度；二是token-selective credit assignment，分别对时序定位和答案生成的token分配奖励，解决GRPO奖励多元信号处理不佳的问题。

Result: 在NExT-GQA和ReXTime数据集上，时间定位性能分别提升5.2%和4.6%，答案准确率提升2.4%。在长视频理解任务上的平均提升为6.4%。

Conclusion: Zoom-Zero框架能有效提升带有时间定位的视频问答任务的表现，尤其在长视频场景下既保留全局信息又精细捕捉关键细节，使答案更加可靠。

Abstract: Grounded video question answering (GVQA) aims to localize relevant temporal segments in videos and generate accurate answers to a given question; however, large video-language models (LVLMs) exhibit limited temporal awareness. Although existing approaches based on Group Relative Policy Optimization (GRPO) attempt to improve temporal grounding, they still struggle to faithfully ground their answers in the relevant video evidence, leading to temporal mislocalization and hallucinations. In this work, we present Zoom-Zero, a coarse-to-fine framework that first localizes query-relevant segments and then temporally zooms into the most salient frames for finer-grained visual verification. Our method addresses the limits of GRPO for the GVQA task with two key innovations: (i) a zoom-in accuracy reward that validates the fidelity of temporal grounding prediction and facilitates fine-grained visual verification on grounded frames; (ii) token-selective credit assignment, which attributes rewards to the tokens responsible for temporal localization or answer generation, mitigating GRPO's issue in handling multi-faceted reward signals. Our proposed method advances grounded video question answering, improving temporal grounding by 5.2\% on NExT-GQA and 4.6\% on ReXTime, while also enhancing average answer accuracy by 2.4\%. Additionally, the coarse-to-fine zoom-in during inference further benefits long-form video understanding by preserving critical visual details without compromising global context, yielding an average improvement of 6.4\% on long-video benchmarks.

</details>


### [69] [TUN: Detecting Significant Points in Persistence Diagrams with Deep Learning](https://arxiv.org/abs/2512.14274)
*Yu Chen,Hongwei Lin*

Main category: cs.CV

TL;DR: 本论文提出了一种新的多模态神经网络TUN，实现了对一维持久性图中重要点的自动识别，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，难以自动且可靠地判别持久性图中的哪些点是真实信号，导致拓扑数据分析的实际应用受阻。

Method: 提出Topology Understanding Net（TUN），结合增强的持久性图描述符、自注意力机制、PointNet式点云编码器、融合学习和逐点分类等多种手段，并采用稳定的预处理和考虑数据不均衡的训练方式。

Result: TUN在自动检测持久性图中显著点任务上，性能优于传统方法，实验验证其效果突出。

Conclusion: TUN为持久性图显著点识别提供了自动化、有效的解决方案，有助于拓扑数据分析在实际领域的推广和应用。

Abstract: Persistence diagrams (PDs) provide a powerful tool for understanding the topology of the underlying shape of a point cloud. However, identifying which points in PDs encode genuine signals remains challenging. This challenge directly hinders the practical adoption of topological data analysis in many applications, where automated and reliable interpretation of persistence diagrams is essential for downstream decision-making. In this paper, we study automatic significance detection for one-dimensional persistence diagrams. Specifically, we propose Topology Understanding Net (TUN), a multi-modal network that combines enhanced PD descriptors with self-attention, a PointNet-style point cloud encoder, learned fusion, and per-point classification, alongside stable preprocessing and imbalance-aware training. It provides an automated and effective solution for identifying significant points in PDs, which are critical for downstream applications. Experiments show that TUN outperforms classic methods in detecting significant points in PDs, illustrating its effectiveness in real-world applications.

</details>


### [70] [SS4D: Native 4D Generative Model via Structured Spacetime Latents](https://arxiv.org/abs/2512.14284)
*Zhibing Li,Mengchen Zhang,Tong Wu,Jing Tan,Jiaqi Wang,Dahua Lin*

Main category: cs.CV

TL;DR: 本文提出了SS4D，一种能够直接从单目视频合成动态三维对象的原生4D生成模型，能够实现高质量、时序连贯和结构一致的4D动态对象生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常通过优化已有的3D或视频生成模型间接获得4D表示，难以直接保证高保真度和时序一致，而4D训练数据又稀缺。因此，迫切需要一种能直接在4D数据上训练、生成一致性更强动态三维内容的新方法。

Method: 1) 利用预训练的单图像到三维模型，确保空间一致性；2) 引入专门的时序层以增强跨帧时序连贯性；3) 通过因式分解的4D卷积和时序下采样对时空隐变量进行压缩，提升长序列训练与推理效率。同时，采用特殊的训练策略提升在遮挡情况下的鲁棒性。

Result: 实验结果表明，SS4D能生成高保真、时序连贯且结构一致的动态3D对象，并在有限的4D数据训练资源条件下保持优异表现。

Conclusion: SS4D首次实现了基于原生4D生成器的动态三维对象生成，显著提升了生成质量与一致性，并兼顾了训练及推理效率，为4D对象生成提供了新范式。

Abstract: We present SS4D, a native 4D generative model that synthesizes dynamic 3D objects directly from monocular video. Unlike prior approaches that construct 4D representations by optimizing over 3D or video generative models, we train a generator directly on 4D data, achieving high fidelity, temporal coherence, and structural consistency. At the core of our method is a compressed set of structured spacetime latents. Specifically, (1) To address the scarcity of 4D training data, we build on a pre-trained single-image-to-3D model, preserving strong spatial consistency. (2) Temporal consistency is enforced by introducing dedicated temporal layers that reason across frames. (3) To support efficient training and inference over long video sequences, we compress the latent sequence along the temporal axis using factorized 4D convolutions and temporal downsampling blocks. In addition, we employ a carefully designed training strategy to enhance robustness against occlusion

</details>


### [71] [PSMamba: Progressive Self-supervised Vision Mamba for Plant Disease Recognition](https://arxiv.org/abs/2512.14309)
*Abdullah Al Mamun,Miaohua Zhang,David Ahmedt-Aristizabal,Zeeshan Hayder,Mohammad Awrangjeb*

Main category: cs.CV

TL;DR: 本文提出了一种名为PSMamba的进阶自监督学习框架，能够更好地捕捉植物病害图像中的多尺度、层次化病灶特征。在多个基准数据集上的实验显示，该方法优于现有主流自监督学习方法。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习框架主要关注全局特征对齐，难以有效捕获植物病害图像的层次化、多尺度病灶特点，导致对复杂图像细节理解不足。

Method: 提出PSMamba框架，将高效的Vision Mamba序列建模与双学生分层蒸馏策略结合。其结构包括一个共享的全局教师模型和两个专用学生模块，分别处理中尺度（如病斑分布及叶脉结构）和局部尺度（如纹理异常与早期病斑）信息，通过多粒度监督和一致性损失促进上下文与细节特征的共同学习和跨尺度对齐。

Result: 在三个基准数据集上，PSMamba在精度和鲁棒性上都显著优于当前先进自监督方法，尤其在领域迁移和细粒度识别任务中表现突出。

Conclusion: PSMamba能够有效捕获植物病害图像的多规模、层次化特征，在无监督表示学习任务中实现更高表现，对类似视觉任务有广泛潜力。

Abstract: Self-supervised Learning (SSL) has become a powerful paradigm for representation learning without manual annotations. However, most existing frameworks focus on global alignment and struggle to capture the hierarchical, multi-scale lesion patterns characteristic of plant disease imagery. To address this gap, we propose PSMamba, a progressive self-supervised framework that integrates the efficient sequence modelling of Vision Mamba (VM) with a dual-student hierarchical distillation strategy. Unlike conventional single teacher-student designs, PSMamba employs a shared global teacher and two specialised students: one processes mid-scale views to capture lesion distributions and vein structures, while the other focuses on local views to capture fine-grained cues such as texture irregularities and early-stage lesions. This multi-granular supervision facilitates the joint learning of contextual and detailed representations, with consistency losses ensuring coherent cross-scale alignment. Experiments on three benchmark datasets show that PSMamba consistently outperforms state-of-the-art SSL methods, delivering superior accuracy and robustness in both domain-shifted and fine-grained scenarios.

</details>


### [72] [From YOLO to VLMs: Advancing Zero-Shot and Few-Shot Detection of Wastewater Treatment Plants Using Satellite Imagery in MENA Region](https://arxiv.org/abs/2512.14312)
*Akila Premarathna,Kanishka Hewageegana,Garcia Andarcia Mariangel*

Main category: cs.CV

TL;DR: 本研究比较了基于视觉-语言模型（VLMs）与传统YOLOv8分割方法，在中东北非地区卫星图像中识别污水处理厂（WWTPs）的表现。结果显示部分VLMs在零样本（zero-shot）条件下优于YOLOv8，尤其是Gemma-3模型。


<details>
  <summary>Details</summary>
Motivation: 中东北非地区对污水处理厂的识别和监测需求高，而传统方法依赖繁重的手动标注。现有研究显示VLMs能在无需大量人工标注下有效完成相关任务，因此需要系统比较VLMs与YOLOv8等方法在此场景中的性能。

Method: 使用埃及、沙特、阿联酋共83,566张高分辨率卫星图像训练YOLOv8模型。选取包括LLaMA 3.2 Vision、Qwen 2.5 VL、DeepSeek-VL2、Gemma 3、Gemini和Pixtral 12B等VLM，利用零样本与少样本方法，通过专家提示识别WWTP关键结构并输出结果。测试集含1,207个经过验证的WWTP与同数量的非WWTP样本。

Result: 在WWTP图像的零样本评估中，多数VLM表现优于YOLOv8，Gemma-3模型表现最佳。VLM在无需额外标注的情况下实现更高真阳性识别率。

Conclusion: 视觉-语言模型（VLMs），尤其是在零样本场景下，已可取代YOLOv8等传统模型，有效实现高效、免注释的WWTP遥感分类，为大规模环境监测带来新方案。

Abstract: In regions of the Middle East and North Africa (MENA), there is a high demand for wastewater treatment plants (WWTPs), crucial for sustainable water management. Precise identification of WWTPs from satellite images enables environmental monitoring. Traditional methods like YOLOv8 segmentation require extensive manual labeling. But studies indicate that vision-language models (VLMs) are an efficient alternative to achieving equivalent or superior results through inherent reasoning and annotation. This study presents a structured methodology for VLM comparison, divided into zero-shot and few-shot streams specifically to identify WWTPs. The YOLOv8 was trained on a governmental dataset of 83,566 high-resolution satellite images from Egypt, Saudi Arabia, and UAE: ~85% WWTPs (positives), 15% non-WWTPs (negatives). Evaluated VLMs include LLaMA 3.2 Vision, Qwen 2.5 VL, DeepSeek-VL2, Gemma 3, Gemini, and Pixtral 12B (Mistral), used to identify WWTP components such as circular/rectangular tanks, aeration basins and distinguish confounders via expert prompts producing JSON outputs with confidence and descriptions. The dataset comprises 1,207 validated WWTP locations (198 UAE, 354 KSA, 655 Egypt) and equal non-WWTP sites from field/AI data, as 600mx600m Geo-TIFF images (Zoom 18, EPSG:4326). Zero-shot evaluations on WWTP images showed several VLMs out-performing YOLOv8's true positive rate, with Gemma-3 highest. Results confirm that VLMs, particularly with zero-shot, can replace YOLOv8 for efficient, annotation-free WWTP classification, enabling scalable remote sensing.

</details>


### [73] [Semantic Mismatch and Perceptual Degradation: A New Perspective on Image Editing Immunity](https://arxiv.org/abs/2512.14320)
*Shuai Dong,Jie Zhang,Guoying Zhao,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: 本论文提出了一种新的方法，通过在扩散模型中对中间特征进行扰动，实现对图像免疫编辑保护，并引入了更合理的衡量免疫成功的新指标ISR，实验显示该方法效果领先。


<details>
  <summary>Details</summary>
Motivation: 文本引导的图像编辑因其强大能力而易被滥用，因此需要对图像进行不可见扰动保护，以防止被不当编辑。但现有评估方法忽视了免疫的语义防护核心，仅关注视觉结果的差异，不能全面评估免疫效果。

Method: 提出了Synergistic Intermediate Feature Manipulation（SIFM）方法，通过两个目标协同作用，在扩散模型的中间特征层进行扰动：一是最大化与原始编辑轨迹的特征偏离，破坏语义对齐；二是最小化特征范数，诱导感知退化。同时引入Immunization Success Rate（ISR）指标，利用多模态大模型判断输出是否失去了与攻击者意图对齐或出现明显退化。

Result: 实验表明，SIFM方法在防护基于扩散模型的恶意图像编辑方面取得了业界最优表现，ISR评估下的免疫成功率显著高于其他方法。

Conclusion: 论文通过SIFM方法实现了对扩散模型编辑免疫的新突破，提出了更符合实际防护需求的衡量标准，为保护视觉内容安全提供了有效手段。

Abstract: Text-guided image editing via diffusion models, while powerful, raises significant concerns about misuse, motivating efforts to immunize images against unauthorized edits using imperceptible perturbations. Prevailing metrics for evaluating immunization success typically rely on measuring the visual dissimilarity between the output generated from a protected image and a reference output generated from the unprotected original. This approach fundamentally overlooks the core requirement of image immunization, which is to disrupt semantic alignment with attacker intent, regardless of deviation from any specific output. We argue that immunization success should instead be defined by the edited output either semantically mismatching the prompt or suffering substantial perceptual degradations, both of which thwart malicious intent. To operationalize this principle, we propose Synergistic Intermediate Feature Manipulation (SIFM), a method that strategically perturbs intermediate diffusion features through dual synergistic objectives: (1) maximizing feature divergence from the original edit trajectory to disrupt semantic alignment with the expected edit, and (2) minimizing feature norms to induce perceptual degradations. Furthermore, we introduce the Immunization Success Rate (ISR), a novel metric designed to rigorously quantify true immunization efficacy for the first time. ISR quantifies the proportion of edits where immunization induces either semantic failure relative to the prompt or significant perceptual degradations, assessed via Multimodal Large Language Models (MLLMs). Extensive experiments show our SIFM achieves the state-of-the-art performance for safeguarding visual content against malicious diffusion-based manipulation.

</details>


### [74] [Dual Attention Guided Defense Against Malicious Edits](https://arxiv.org/abs/2512.14333)
*Jie Zhang,Shuai Dong,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: 本文提出了一种新的“二重注意力引导噪声扰动”（DANP）方法，有效防御文本到图像扩散模型在被恶意编辑时的滥用。


<details>
  <summary>Details</summary>
Motivation: 扩散模型带来的文字生成图像技术为图像编辑打开了新局面，但恶意编辑或伪造内容的风险也随之增加，现有的微扰防御方法难以抵抗针对性强的攻击，因此需要更有效的防护手段。

Method: DANP方法在多个时间步引入不可察觉的扰动，并利用动态阈值生成掩膜，识别文本相关与无关区域。在生成过程中，有意识地减少重要区域的注意力、增加无关区域注意力，误导模型编辑到错误位置。同时，最大化噪声注入与模型预测噪声的差异，双重干扰模型的语义理解及生成能力。

Result: DANP方法在干扰恶意编辑上展现出显著的防护效果，实验结果表明该方法在对抗性防御任务中优于现有主流对比方法，达到了当前最先进水平。

Conclusion: 通过在注意力和噪声预测机制上联合干预，DANP极大提升了对恶意文本引导图像编辑行为的免疫能力，为安全防护扩散模型提供了更强有力的解决方案。

Abstract: Recent progress in text-to-image diffusion models has transformed image editing via text prompts, yet this also introduces significant ethical challenges from potential misuse in creating deceptive or harmful content. While current defenses seek to mitigate this risk by embedding imperceptible perturbations, their effectiveness is limited against malicious tampering. To address this issue, we propose a Dual Attention-Guided Noise Perturbation (DANP) immunization method that adds imperceptible perturbations to disrupt the model's semantic understanding and generation process. DANP functions over multiple timesteps to manipulate both cross-attention maps and the noise prediction process, using a dynamic threshold to generate masks that identify text-relevant and irrelevant regions. It then reduces attention in relevant areas while increasing it in irrelevant ones, thereby misguides the edit towards incorrect regions and preserves the intended targets. Additionally, our method maximizes the discrepancy between the injected noise and the model's predicted noise to further interfere with the generation. By targeting both attention and noise prediction mechanisms, DANP exhibits impressive immunity against malicious edits, and extensive experiments confirm that our method achieves state-of-the-art performance.

</details>


### [75] [Vector Prism: Animating Vector Graphics by Stratifying Semantic Structure](https://arxiv.org/abs/2512.14336)
*Jooyeol Yun,Jaegul Choo*

Main category: cs.CV

TL;DR: 本文提出了一种通过语义结构恢复提升矢量图自动动画生成准确性的框架，显著改进了现有基于视觉-语言模型（VLM）的SVG动画方法。


<details>
  <summary>Details</summary>
Motivation: 随着Web设计对SVG动画需求的增加，自动化生成SVG动画仍然困难。现有VLM虽然在代码生成和运动规划上取得进步，但在处理SVG时，常将视觉上相关的部分分割为低层图形单元，缺乏动画时需协调移动的整体语义指引。为实现更高质量、连贯的SVG动画，亟需解决这一语义层次缺失问题。

Method: 提出利用多种弱部件预测结果进行统计聚合的方法，从嘈杂预测中稳定推断出SVG的语义结构，并将SVG按语义进行重组，从而为生成动画时提供合理分组。通过这一框架，提升了VLM生成连贯SVG动画的能力。

Result: 实验表明，该方法相比当前主流方法有显著性能提升，所生成动画在语义连贯性与视觉效果上表现更佳。

Conclusion: 语义结构恢复是实现可靠SVG动画生成的关键步骤，有助于VLM与矢量图之间更可解释、高效的交互。该框架为未来自动化、智能化SVG动画提供了新方向。

Abstract: Scalable Vector Graphics (SVG) are central to modern web design, and the demand to animate them continues to grow as web environments become increasingly dynamic. Yet automating the animation of vector graphics remains challenging for vision-language models (VLMs) despite recent progress in code generation and motion planning. VLMs routinely mis-handle SVGs, since visually coherent parts are often fragmented into low-level shapes that offer little guidance of which elements should move together. In this paper, we introduce a framework that recovers the semantic structure required for reliable SVG animation and reveals the missing layer that current VLM systems overlook. This is achieved through a statistical aggregation of multiple weak part predictions, allowing the system to stably infer semantics from noisy predictions. By reorganizing SVGs into semantic groups, our approach enables VLMs to produce animations with far greater coherence. Our experiments demonstrate substantial gains over existing approaches, suggesting that semantic recovery is the key step that unlocks robust SVG animation and supports more interpretable interactions between VLMs and vector graphics.

</details>


### [76] [Towards Transferable Defense Against Malicious Image Edits](https://arxiv.org/abs/2512.14341)
*Jie Zhang,Shuai Dong,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: 本文提出了一种新型的图文双模防御框架（TDAE），通过视觉和文本两方面的协同优化，有效提升了对扩散模型恶意图像编辑的免疫能力，实现了优于以往方法的跨模型防御和迁移性。


<details>
  <summary>Details</summary>
Motivation: 当前通过对输入图像添加微小扰动以防范扩散式图像编辑系统中恶意篡改的方法，存在防御效果无法很好迁移到未见过的编辑模型的问题，因此需要新的防御机制来提升免疫功效及其迁移性。

Method: 提出了TDAE框架，在视觉防御层引入了梯度正则化（FDM），使扰动导向平坦极小值，从而增强对未知编辑模型的鲁棒性；在文本增强保护层，设计了一种动态图文对抗优化（DPD），动态调整文本嵌入，使免疫图像的编辑结果始终与源图像一致，并以此持续优化图像，实现更强的特征泛化。

Result: 在多项实验和跨不同编辑模型的评估下，TDAE在防御恶意图像编辑方面达到了当前最优（SOTA）表现，显著优于此前方法。

Conclusion: TDAE能高效提升对扩散模型恶意编辑的鲁棒性，并在跨模型场景下展现出强迁移能力，为实际防御复杂图像编辑威胁提供了有效解决方案。

Abstract: Recent approaches employing imperceptible perturbations in input images have demonstrated promising potential to counter malicious manipulations in diffusion-based image editing systems. However, existing methods suffer from limited transferability in cross-model evaluations. To address this, we propose Transferable Defense Against Malicious Image Edits (TDAE), a novel bimodal framework that enhances image immunity against malicious edits through coordinated image-text optimization. Specifically, at the visual defense level, we introduce FlatGrad Defense Mechanism (FDM), which incorporates gradient regularization into the adversarial objective. By explicitly steering the perturbations toward flat minima, FDM amplifies immune robustness against unseen editing models. For textual enhancement protection, we propose an adversarial optimization paradigm named Dynamic Prompt Defense (DPD), which periodically refines text embeddings to align the editing outcomes of immunized images with those of the original images, then updates the images under optimized embeddings. Through iterative adversarial updates to diverse embeddings, DPD enforces the generation of immunized images that seek a broader set of immunity-enhancing features, thereby achieving cross-model transferability. Extensive experimental results demonstrate that our TDAE achieves state-of-the-art performance in mitigating malicious edits under both intra- and cross-model evaluations.

</details>


### [77] [HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis](https://arxiv.org/abs/2512.14352)
*Kaizhe Zhang,Yijie Zhou,Weizhan Zhang,Caixia Yan,Haipeng Du,yugui xie,Yu-Hui Wen,Yong-Jin Liu*

Main category: cs.CV

TL;DR: 提出了一种高效、体积小、适用于动态场景新视角合成的混合高斯溅射（HGS）方法，通过静态-动态分解（SDD）和RBF建模，极大降低了参数量并提升了渲染速度。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯溅射的动态新视角合成方法效率低，模型臃肿，难以满足实时和低资源设备需求；亟需结构更紧凑且渲染速度快的方法。

Method: 提出了HGS框架，核心为静态-动态分解（SDD）：对动态区域用时变RBF建模捕捉变化，对静态区域参数共享减少冗余。并引入两个阶段的训练策略提升边界区域的时序一致性。

Result: 在不同GPU上大幅提升渲染速度（3090上4K实时125FPS，3050上160FPS），模型体积减少高达98%；集成进虚拟现实系统，保持与最先进方法相当甚至更佳的画质。

Conclusion: HGS能高效区分并处理动态与静态区域，实现了极高压缩率和实时渲染，为资源受限设备和实际应用中的动态新视角渲染提供了解决方案。

Abstract: Dynamic novel view synthesis (NVS) is essential for creating immersive experiences. Existing approaches have advanced dynamic NVS by introducing 3D Gaussian Splatting (3DGS) with implicit deformation fields or indiscriminately assigned time-varying parameters, surpassing NeRF-based methods. However, due to excessive model complexity and parameter redundancy, they incur large model sizes and slow rendering speeds, making them inefficient for real-time applications, particularly on resource-constrained devices. To obtain a more efficient model with fewer redundant parameters, in this paper, we propose Hybrid Gaussian Splatting (HGS), a compact and efficient framework explicitly designed to disentangle static and dynamic regions of a scene within a unified representation. The core innovation of HGS lies in our Static-Dynamic Decomposition (SDD) strategy, which leverages Radial Basis Function (RBF) modeling for Gaussian primitives. Specifically, for dynamic regions, we employ time-dependent RBFs to effectively capture temporal variations and handle abrupt scene changes, while for static regions, we reduce redundancy by sharing temporally invariant parameters. Additionally, we introduce a two-stage training strategy tailored for explicit models to enhance temporal coherence at static-dynamic boundaries. Experimental results demonstrate that our method reduces model size by up to 98% and achieves real-time rendering at up to 125 FPS at 4K resolution on a single RTX 3090 GPU. It further sustains 160 FPS at 1352 * 1014 on an RTX 3050 and has been integrated into the VR system. Moreover, HGS achieves comparable rendering quality to state-of-the-art methods while providing significantly improved visual fidelity for high-frequency details and abrupt scene changes.

</details>


### [78] [Enhancing Interpretability for Vision Models via Shapley Value Optimization](https://arxiv.org/abs/2512.14354)
*Kanglong Fan,Yunqiao Yang,Chen Ma*

Main category: cs.CV

TL;DR: 该论文提出了一种结合Shapley值估计的新型自解释神经网络框架，实现了在保持性能和兼容性的前提下提升对DNN决策过程的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有DNN可解释方法存在局限性：后验解释方法难以忠实反映模型行为，自解释网络由于结构特殊往往牺牲性能和兼容性。作者希望提出新方法，兼顾可解释性与模型性能。

Method: 方法是在训练过程中引入Shapley值估计作为辅助任务，将模型预测分数合理分配给图像不同区域，在模型结构上只做少量改动。

Result: 在多个基准上，实验结果表明该方法在可解释性方面达到了当前最优，并基本不影响模型性能。

Conclusion: 结合Shapley值估计的自解释框架能够在提升模型可解释性的同时，保持模型性能和兼容性，具备实际应用前景。

Abstract: Deep neural networks have demonstrated remarkable performance across various domains, yet their decision-making processes remain opaque. Although many explanation methods are dedicated to bringing the obscurity of DNNs to light, they exhibit significant limitations: post-hoc explanation methods often struggle to faithfully reflect model behaviors, while self-explaining neural networks sacrifice performance and compatibility due to their specialized architectural designs. To address these challenges, we propose a novel self-explaining framework that integrates Shapley value estimation as an auxiliary task during training, which achieves two key advancements: 1) a fair allocation of the model prediction scores to image patches, ensuring explanations inherently align with the model's decision logic, and 2) enhanced interpretability with minor structural modifications, preserving model performance and compatibility. Extensive experiments on multiple benchmarks demonstrate that our method achieves state-of-the-art interpretability.

</details>


### [79] [Mimicking Human Visual Development for Learning Robust Image Representations](https://arxiv.org/abs/2512.14360)
*Ankita Raj,Kaashika Prajaapat,Tapan Kumar Gandhi,Chetan Arora*

Main category: cs.CV

TL;DR: 本文提出一种灵感来源于人类视觉发育过程的逐步模糊训练策略，以提升CNN的泛化能力和鲁棒性。通过先用模糊图像训练，再逐步减少模糊度，增强模型对全局结构的关注，从而在多个数据集上取得了优于常规训练的表现。


<details>
  <summary>Details</summary>
Motivation: 现代卷积神经网络在应对分布变化和输入噪声时表现不如人类视觉系统。作者受婴儿视觉发育过程的启发，旨在通过模拟人类视觉清晰度的逐步提升，提升神经网络的泛化和鲁棒性。

Method: 提出“逐步模糊课程”（progressive blurring curriculum）：训练初期用高度模糊的图像输入，随着训练推进逐步减少图像模糊度，使网络先聚焦全局结构后逐步学习细节。该方法与静态模糊增强(随机使用模糊图像)区别，通过结构化的模糊递减获得更稳定的优化效果。

Result: 在CIFAR-10-C和ImageNet-100-C等数据集上，该方法的平均腐蚀误差（mCE）分别降低8.30%和4.43%。此外，该策略与其他增强方法（如CutMix和MixUp）兼容，并提升了模型对自然噪声和对抗攻击的鲁棒性。

Conclusion: 逐步模糊课程提升了CNN的泛化与鲁棒能力，对常规任务性能影响极小，并能与多种数据增强方法协同提升表现。该方法为模拟视觉发育过程提供了一个有效的工程实现。

Abstract: The human visual system is remarkably adept at adapting to changes in the input distribution; a capability modern convolutional neural networks (CNNs) still struggle to match. Drawing inspiration from the developmental trajectory of human vision, we propose a progressive blurring curriculum to improve the generalization and robustness of CNNs. Human infants are born with poor visual acuity, gradually refining their ability to perceive fine details. Mimicking this process, we begin training CNNs on highly blurred images during the initial epochs and progressively reduce the blur as training advances. This approach encourages the network to prioritize global structures over high-frequency artifacts, improving robustness against distribution shifts and noisy inputs. Challenging prior claims that blurring in the initial training epochs imposes a stimulus deficit and irreversibly harms model performance, we reveal that early-stage blurring enhances generalization with minimal impact on in-domain accuracy. Our experiments demonstrate that the proposed curriculum reduces mean corruption error (mCE) by up to 8.30% on CIFAR-10-C and 4.43% on ImageNet-100-C datasets, compared to standard training without blurring. Unlike static blur-based augmentation, which applies blurred images randomly throughout training, our method follows a structured progression, yielding consistent gains across various datasets. Furthermore, our approach complements other augmentation techniques, such as CutMix and MixUp, and enhances both natural and adversarial robustness against common attack methods. Code is available at https://github.com/rajankita/Visual_Acuity_Curriculum.

</details>


### [80] [Unified Semantic Transformer for 3D Scene Understanding](https://arxiv.org/abs/2512.14364)
*Sebastian Koch,Johanna Wald,Hide Matsuki,Pedro Hermosilla,Timo Ropinski,Federico Tombari*

Main category: cs.CV

TL;DR: 本文提出了一个统一的3D场景理解模型UNITE，能够同时完成多种3D语义任务，且性能优于众多专用模型。


<details>
  <summary>Details</summary>
Motivation: 传统3D场景理解方法高度依赖任务专用模型，无法高效统一处理多种任务，且通常需要结构化输入或先验。本研究试图开发一个能统一处理多类3D语义任务的模型，简化流程、提升效率和通用性。

Method: 开发了一种全新前馈神经网络UNITE，纯基于RGB图像输入，能端到端预测3D场景分割、实例嵌入、开放词汇特征、可供性与可运动性等多语义属性。训练过程中，采用2D蒸馏、自监督学习和多视图损失保证3D一致性。

Result: UNITE在多项3D语义任务上取得了业界最优结果，部分情况下甚至超过了基于真实3D几何信息的专用方法。还显示出良好的泛化能力，可在未见过的场景中几秒完成推断。

Conclusion: UNITE证明了统一语义Transformer可高效融合多3D任务，在保持高性能的同时，简化了3D场景理解的整体框架，为未来多任务3D理解研究和应用提供了新方向。

Abstract: Holistic 3D scene understanding involves capturing and parsing unstructured 3D environments. Due to the inherent complexity of the real world, existing models have predominantly been developed and limited to be task-specific. We introduce UNITE, a Unified Semantic Transformer for 3D scene understanding, a novel feed-forward neural network that unifies a diverse set of 3D semantic tasks within a single model. Our model operates on unseen scenes in a fully end-to-end manner and only takes a few seconds to infer the full 3D semantic geometry. Our approach is capable of directly predicting multiple semantic attributes, including 3D scene segmentation, instance embeddings, open-vocabulary features, as well as affordance and articulations, solely from RGB images. The method is trained using a combination of 2D distillation, heavily relying on self-supervision and leverages novel multi-view losses designed to ensure 3D view consistency. We demonstrate that UNITE achieves state-of-the-art performance on several different semantic tasks and even outperforms task-specific models, in many cases, surpassing methods that operate on ground truth 3D geometry. See the project website at unite-page.github.io

</details>


### [81] [Optimizing Rank for High-Fidelity Implicit Neural Representations](https://arxiv.org/abs/2512.14366)
*Julian McGinnis,Florian A. Hölzl,Suprosanna Shit,Florentin Bieder,Paul Friedrich,Mark Mühlau,Björn Menze,Daniel Rueckert,Benedikt Wiestler*

Main category: cs.CV

TL;DR: 本文质疑了传统观点，即普通MLP在隐式神经表示（INR）中无法表达高频信息。作者发现问题不在架构本身，而是训练过程中网络秩的退化。通过调节网络秩并采用特定优化器，显著提升了INR能力，甚至超越现有方法。


<details>
  <summary>Details</summary>
Motivation: INR常用于表达信号，但普遍认为普通MLP结构存在低频偏置，难以捕捉高频信息，促使研究者不断设计复杂结构。作者希望探索普通MLP的真正局限，并尝试突破现有限制。

Method: 作者分析了MLP在训练过程中的稳定秩退化现象，提出通过训练时调控网络秩，结合如Muon等优化器进行高秩、近正交的参数更新，从而提升表达能力。

Result: 采用设计的优化和调节后，简单MLP模型在多种应用（自然图像、医学图像、新视角合成）上，均获得明显提升，PSNR最高提升9 dB，超过当前最佳方法。

Conclusion: MLP的低频偏置更多是训练时网络秩退化而非结构本身限制。通过适当方法调节秩，简单结构的INR也可高效表达高频内容，相关优化范式在多个领域展现出强大性能。

Abstract: Implicit Neural Representations (INRs) based on vanilla Multi-Layer Perceptrons (MLPs) are widely believed to be incapable of representing high-frequency content. This has directed research efforts towards architectural interventions, such as coordinate embeddings or specialized activation functions, to represent high-frequency signals. In this paper, we challenge the notion that the low-frequency bias of vanilla MLPs is an intrinsic, architectural limitation to learn high-frequency content, but instead a symptom of stable rank degradation during training. We empirically demonstrate that regulating the network's rank during training substantially improves the fidelity of the learned signal, rendering even simple MLP architectures expressive. Extensive experiments show that using optimizers like Muon, with high-rank, near-orthogonal updates, consistently enhances INR architectures even beyond simple ReLU MLPs. These substantial improvements hold across a diverse range of domains, including natural and medical images, and novel view synthesis, with up to 9 dB PSNR improvements over the previous state-of-the-art. Our project page, which includes code and experimental results, is available at: (https://muon-inrs.github.io).

</details>


### [82] [EcoScapes: LLM-Powered Advice for Crafting Sustainable Cities](https://arxiv.org/abs/2512.14373)
*Martin Röhn,Nora Gourmelon,Vincent Christlein*

Main category: cs.CV

TL;DR: 本文提出了一种多层次系统，将专业化大模型（LLMs）、卫星影像分析和知识库相结合，帮助小城市制定气候适应策略。


<details>
  <summary>Details</summary>
Motivation: 小城市由于人力资源有限，数据整合和分析能力不足，难以制定有效的气候适应方案，因此需要新的技术来辅助分析和决策。

Method: 设计并实现了一个多层级系统，整合专业LLMs处理文本和决策支持、卫星影像自动分析和集成知识库，提供全面的数据分析和建议支持。

Result: 系统能够有效整合来自多种来源的数据，提升小城市应对气候变化的能力。相关代码已开源，便于实际部署。

Conclusion: 该系统为资源有限的小城市在气候适应方面提供了实用、可扩展的技术方案，能够提高分析效率和决策质量，促进城市可持续发展。

Abstract: Climate adaptation is vital for the sustainability and sometimes the mere survival of our urban areas. However, small cities often struggle with limited personnel resources and integrating vast amounts of data from multiple sources for a comprehensive analysis. To overcome these challenges, this paper proposes a multi-layered system combining specialized LLMs, satellite imagery analysis and a knowledge base to aid in developing effective climate adaptation strategies. The corresponding code can be found at https://github.com/Photon-GitHub/EcoScapes.

</details>


### [83] [Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos](https://arxiv.org/abs/2512.14406)
*Le Jiang,Shaotong Zhu,Yedi Luo,Shayda Moezzi,Sarah Ostadabbas*

Main category: cs.CV

TL;DR: ExpanDyNeRF提出了一种改进的动态NeRF框架，通过引入高斯分布先验和伪真实标签提升了在大角度视角下的渲染质量，并发布了新的多视角动态数据集SynDM。实验结果显示，在极端视角下其渲染效果显著超过现有动态NeRF方法。


<details>
  <summary>Details</summary>
Motivation: 现有动态NeRF系统在视角大幅偏移时，合成的新视图常常出现不稳定或不真实的结果，限制了其实际应用。因此，作者希望提升动态NeRF系统在大角度视角变换下的鲁棒性和渲染质量。

Method: 提出ExpanDyNeRF框架，通过利用高斯样条先验与伪真实标签生成方案，联合优化密度和颜色特征，增强动态场景从极端视角下的重建表现。同时，构建了基于GTA V渲染的首个多视角动态场景数据集SynDM，包含明确的侧视监督。

Result: 在SynDM和真实世界数据集上的定量和定性实验表明，ExpanDyNeRF在渲染保真度和极端视角下的鲁棒性方面，明显优于现有动态NeRF方法。

Conclusion: ExpanDyNeRF通过创新先验、伪标签和数据集设计，显著推动了动态NeRF系统在极端视角条件下的渲染能力，为后续研究提供了坚实基础。

Abstract: In dynamic Neural Radiance Fields (NeRF) systems, state-of-the-art novel view synthesis methods often fail under significant viewpoint deviations, producing unstable and unrealistic renderings. To address this, we introduce Expanded Dynamic NeRF (ExpanDyNeRF), a monocular NeRF framework that leverages Gaussian splatting priors and a pseudo-ground-truth generation strategy to enable realistic synthesis under large-angle rotations. ExpanDyNeRF optimizes density and color features to improve scene reconstruction from challenging perspectives. We also present the Synthetic Dynamic Multiview (SynDM) dataset, the first synthetic multiview dataset for dynamic scenes with explicit side-view supervision-created using a custom GTA V-based rendering pipeline. Quantitative and qualitative results on SynDM and real-world datasets demonstrate that ExpanDyNeRF significantly outperforms existing dynamic NeRF methods in rendering fidelity under extreme viewpoint shifts. Further details are provided in the supplementary materials.

</details>


### [84] [DISCODE: Distribution-Aware Score Decoder for Robust Automatic Evaluation of Image Captioning](https://arxiv.org/abs/2512.14420)
*Nakamasa Inoue,Kanoko Goto,Masanari Oi,Martyna Gruszka,Mahiro Ukai,Takumi Hirose,Yusuke Sekikawa*

Main category: cs.CV

TL;DR: 本文提出了一种新方法DISCODE，提高大型视觉-语言模型在图像描述评价中的稳健性，无需微调即可更好地对齐人类评价，尤其在跨域情况下表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有的图像描述评价方法在面对领域变化（domain-shift）时，鲁棒性不足，难以与人类主观评价保持一致，亟需一种无监督、无需微调、且稳健的评价方法。

Method: 提出DISCODE方法，在测试时通过引入自适应损失（ATT loss），利用高斯先验分布对评价分数进行调整，提高鲁棒性。这一损失可通过作者推导的解析解高效地在测试阶段最小化，无需再训练。此外，构建了多领域评价基准MCEval，覆盖六大领域，用以综合评价算法鲁棒性。

Result: DISCODE在MCEval及四个主流现有基准上作为无参考评价指标取得了最优性能，且更好地与人类评价对齐。

Conclusion: DISCODE为图像描述质量评价提供了无需微调且跨域鲁棒性强的解决方案，有助于在多样化真实场景下提升自动评价与人类判断的一致性。

Abstract: Large vision-language models (LVLMs) have shown impressive performance across a broad range of multimodal tasks. However, robust image caption evaluation using LVLMs remains challenging, particularly under domain-shift scenarios. To address this issue, we introduce the Distribution-Aware Score Decoder (DISCODE), a novel finetuning-free method that generates robust evaluation scores better aligned with human judgments across diverse domains. The core idea behind DISCODE lies in its test-time adaptive evaluation approach, which introduces the Adaptive Test-Time (ATT) loss, leveraging a Gaussian prior distribution to improve robustness in evaluation score estimation. This loss is efficiently minimized at test time using an analytical solution that we derive. Furthermore, we introduce the Multi-domain Caption Evaluation (MCEval) benchmark, a new image captioning evaluation benchmark covering six distinct domains, designed to assess the robustness of evaluation metrics. In our experiments, we demonstrate that DISCODE achieves state-of-the-art performance as a reference-free evaluation metric across MCEval and four representative existing benchmarks.

</details>


### [85] [LCMem: A Universal Model for Robust Image Memorization Detection](https://arxiv.org/abs/2512.14421)
*Mischa Dombrowski,Felix Nützel,Bernhard Kainz*

Main category: cs.CV

TL;DR: 本论文提出了一种新的跨领域记忆检测方法LCMem，用于提升生成模型中的隐私检测能力，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 生成图像模型已经可以生成足以欺骗人类的图片，但关于其在保护隐私数据方面的效果和检测模型记忆私人信息的机制尚不明确。主要障碍是缺乏有效的检测机制，并且现有隐私审查方法在不同领域泛化能力弱。

Method: 将记忆检测统一视为身份重识别（re-identification）与复制检测（copy detection）融合的问题，提出Latent Contrastive Memorization Network (LCMem)。该模型采用两阶段训练：第一阶段学习身份一致性，第二阶段训练对增强的数据实现鲁棒的复制检测。

Result: 在六个基准数据集上，LCMem在身份重识别和复制检测两个任务上分别提升了高达16和30个百分点。

Conclusion: LCMem为跨领域隐私审查定了新标准，比现有隐私过滤器更可靠、更具扩展性。当前方法保护能力有限，需要更强机制。LCMem的代码和模型已经公开。

Abstract: Recent advances in generative image modeling have achieved visual realism sufficient to deceive human experts, yet their potential for privacy preserving data sharing remains insufficiently understood. A central obstacle is the absence of reliable memorization detection mechanisms, limited quantitative evaluation, and poor generalization of existing privacy auditing methods across domains. To address this, we propose to view memorization detection as a unified problem at the intersection of re-identification and copy detection, whose complementary goals cover both identity consistency and augmentation-robust duplication, and introduce Latent Contrastive Memorization Network (LCMem), a cross-domain model evaluated jointly on both tasks. LCMem achieves this through a two-stage training strategy that first learns identity consistency before incorporating augmentation-robust copy detection. Across six benchmark datasets, LCMem achieves improvements of up to 16 percentage points on re-identification and 30 percentage points on copy detection, enabling substantially more reliable memorization detection at scale. Our results show that existing privacy filters provide limited performance and robustness, highlighting the need for stronger protection mechanisms. We show that LCMem sets a new standard for cross-domain privacy auditing, offering reliable and scalable memorization detection. Code and model is publicly available at https://github.com/MischaD/LCMem.

</details>


### [86] [The Devil is in Attention Sharing: Improving Complex Non-rigid Image Editing Faithfulness via Attention Synergy](https://arxiv.org/abs/2512.14423)
*Zhuo Chen,Fanyue Wei,Runze Xu,Jingjing Li,Lixin Duan,Angela Yao,Wen Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为SynPS的新方法，实现了无需训练下对复杂非刚性图像编辑（如姿态、形状变化）的高保真操作，通过动态融合位置和语义信息，有效避免过度编辑或不足编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的大型扩散模型在无训练情况下难以完成复杂的非刚性编辑，主要原因在于注意力机制的‘塌缩’：位置嵌入或语义特征容易主导内容检索，导致编辑效果不理想。

Method: 提出SynPS方法，首先通过量化每个去噪步骤的编辑幅度，设计了注意力协同方案，动态调整位置嵌入对编辑过程的影响，从而兼顾语义调整与图像真实性。模型能够自适应地融合位置与语义线索。

Result: 通过在公开和新构建的基准数据集上大量实验，SynPS表现出更高的编辑准确性和保真度，优于现有方法。

Conclusion: SynPS能更好地实现复杂非刚性编辑，兼顾保真与编辑幅度，为扩散模型的无需训练编辑带来更高的实用性。

Abstract: Training-free image editing with large diffusion models has become practical, yet faithfully performing complex non-rigid edits (e.g., pose or shape changes) remains highly challenging. We identify a key underlying cause: attention collapse in existing attention sharing mechanisms, where either positional embeddings or semantic features dominate visual content retrieval, leading to over-editing or under-editing.To address this issue, we introduce SynPS, a method that Synergistically leverages Positional embeddings and Semantic information for faithful non-rigid image editing. We first propose an editing measurement that quantifies the required editing magnitude at each denoising step. Based on this measurement, we design an attention synergy pipeline that dynamically modulates the influence of positional embeddings, enabling SynPS to balance semantic modifications and fidelity preservation.By adaptively integrating positional and semantic cues, SynPS effectively avoids both over- and under-editing. Extensive experiments on public and newly curated benchmarks demonstrate the superior performance and faithfulness of our approach.

</details>


### [87] [Score-Based Turbo Message Passing for Plug-and-Play Compressive Imaging](https://arxiv.org/abs/2512.14435)
*Chang Cai,Hao Jiang,Xiaojun Yuan,Ying-Jun Angela Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种结合score-based生成模型和消息传递算法的新型压缩成像恢复方法（STMP），在重建质量和计算效率之间取得了优越的平衡，且在高量化（如1-bit）下依然性能稳健。


<details>
  <summary>Details</summary>
Motivation: 传统消息传递与PnP方法依赖通用或手工设计的图像先验，无法充分刻画复杂自然图像统计特性，导致在高度欠定条件下重建质量不足。score-based生成模型虽可刻画复杂分布，但直接用于后验采样计算复杂度极高。

Method: 将score-based生成建模与经验贝叶斯去噪结合，提出基于score-based MMSE去噪器的消息传递算法（STMP）；针对量化观测数据，提出带有分量级MMSE去量化模块的Q-STMP。利用state-evolution方程理论分析算法性能。

Result: 在FFHQ数据集上的实验表明，STMP在重建质量和计算速度上均优于现有方法，Q-STMP即使在1bit量化条件下也表现稳健。两者普遍在十次迭代内收敛。

Conclusion: 结合score-based生成模型和消息传递的STMP及其量化扩展Q-STMP能有效提升压缩感知图像重建任务的质量与效率，且理论可准确预估其性能。

Abstract: Message-passing algorithms have been adapted for compressive imaging by incorporating various off-the-shelf image denoisers. However, these denoisers rely largely on generic or hand-crafted priors and often fall short in accurately capturing the complex statistical structure of natural images. As a result, traditional plug-and-play (PnP) methods often lead to suboptimal reconstruction, especially in highly underdetermined regimes. Recently, score-based generative models have emerged as a powerful framework for accurately characterizing sophisticated image distribution. Yet, their direct use for posterior sampling typically incurs prohibitive computational complexity. In this paper, by exploiting the close connection between score-based generative modeling and empirical Bayes denoising, we devise a message-passing framework that integrates a score-based minimum mean-squared error (MMSE) denoiser for compressive image recovery. The resulting algorithm, named score-based turbo message passing (STMP), combines the fast convergence of message passing with the expressive power of score-based generative priors. For practical systems with quantized measurements, we further propose quantized STMP (Q-STMP), which augments STMP with a component-wise MMSE dequantization module. We demonstrate that the asymptotic performance of STMP and Q-STMP can be accurately predicted by a set of state-evolution (SE) equations. Experiments on the FFHQ dataset demonstrate that STMP strikes a significantly better performance-complexity tradeoff compared with competing baselines, and that Q-STMP remains robust even under 1-bit quantization. Remarkably, both STMP and Q-STMP typically converge within 10 iterations.

</details>


### [88] [S2D: Sparse-To-Dense Keymask Distillation for Unsupervised Video Instance Segmentation](https://arxiv.org/abs/2512.14440)
*Leon Sick,Lukas Hoyer,Dominik Engel,Pedro Hermosilla,Timo Ropinski*

Main category: cs.CV

TL;DR: 本文提出了一种全新的无监督视频实例分割方法，完全依赖真实视频数据训练，并通过稀疏关键帧伪标注与时序一致性策略，使分割效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前无监督视频实例分割主要依赖合成视频数据，但传统合成方式无法真实模拟视频中的视角、部分运动或相机移动，导致模型泛化能力不足。为提升分割效果，需要依靠真实视频数据，并解决真实视频帧分割时的时序噪声和质量不一的问题。

Method: 方法从真实视频中获取单帧无监督实例分割掩码，通过深度运动先验筛选高质量关键帧mask。利用这些稀疏关键帧伪标注，提出稀疏到密集蒸馏（Sparse-To-Dense Distillation）并结合时序DropLoss，对分割模型进行训练，实现mask的隐式传播。最终使用得到的密集标签集优化模型。

Result: 经大规模基准测试，所提出方法超越了当前最先进的无监督视频实例分割技术，在多个数据集上取得更好表现。

Conclusion: 利用真实视频数据和创新的伪标注+时序一致性机制，可以在无监督视频实例分割任务上获得最佳性能，为该方向研究提供了新思路。

Abstract: In recent years, the state-of-the-art in unsupervised video instance segmentation has heavily relied on synthetic video data, generated from object-centric image datasets such as ImageNet. However, video synthesis by artificially shifting and scaling image instance masks fails to accurately model realistic motion in videos, such as perspective changes, movement by parts of one or multiple instances, or camera motion. To tackle this issue, we propose an unsupervised video instance segmentation model trained exclusively on real video data. We start from unsupervised instance segmentation masks on individual video frames. However, these single-frame segmentations exhibit temporal noise and their quality varies through the video. Therefore, we establish temporal coherence by identifying high-quality keymasks in the video by leveraging deep motion priors. The sparse keymask pseudo-annotations are then used to train a segmentation model for implicit mask propagation, for which we propose a Sparse-To-Dense Distillation approach aided by a Temporal DropLoss. After training the final model on the resulting dense labelset, our approach outperforms the current state-of-the-art across various benchmarks.

</details>


### [89] [TACK Tunnel Data (TTD): A Benchmark Dataset for Deep Learning-Based Defect Detection in Tunnels](https://arxiv.org/abs/2512.14477)
*Andreas Sjölander,Valeria Belloni,Robel Fekadu,Andrea Nascetti*

Main category: cs.CV

TL;DR: 本文介绍了一个包含三类隧道衬砌缺陷（裂缝、渗漏、渗水）标注图像的新公开数据集，以促进自动化隧道检测技术的发展。


<details>
  <summary>Details</summary>
Motivation: 隧道作为交通基础设施的重要组成部分，受老化和结构劣化等问题影响日益严重，传统人工巡检成本高、主观性强、效率低。深度学习等自动化检测依赖高质量数据集，但隧道领域公开数据稀缺，成为技术发展的瓶颈。

Method: 作者收集并标注了三种不同类型隧道衬砌的缺陷图像，包括裂缝、渗漏和水渗等典型病害，制作符合监督、半监督和无监督深度学习方法需求的数据集，具备结构多样性，支持模型泛化和迁移性研究。

Result: 该数据集已公开发布，包含丰富多样的实际隧道缺陷实例，能够用于缺陷检测和分割任务，并支持模型在隧道类型间的泛化能力测试。

Conclusion: 本工作通过缓解隧道领域数据匮乏问题，为基于深度学习的自动化隧道检测技术和更安全高效的运维决策提供了重要数据基础和支持。

Abstract: Tunnels are essential elements of transportation infrastructure, but are increasingly affected by ageing and deterioration mechanisms such as cracking. Regular inspections are required to ensure their safety, yet traditional manual procedures are time-consuming, subjective, and costly. Recent advances in mobile mapping systems and Deep Learning (DL) enable automated visual inspections. However, their effectiveness is limited by the scarcity of tunnel datasets. This paper introduces a new publicly available dataset containing annotated images of three different tunnel linings, capturing typical defects: cracks, leaching, and water infiltration. The dataset is designed to support supervised, semi-supervised, and unsupervised DL methods for defect detection and segmentation. Its diversity in texture and construction techniques also enables investigation of model generalization and transferability across tunnel types. By addressing the critical lack of domain-specific data, this dataset contributes to advancing automated tunnel inspection and promoting safer, more efficient infrastructure maintenance strategies.

</details>


### [90] [SuperCLIP: CLIP with Simple Classification Supervision](https://arxiv.org/abs/2512.14480)
*Weiheng Zhao,Zilong Huang,Jiashi Feng,Xinggang Wang*

Main category: cs.CV

TL;DR: CLIP模型未能充分利用文本中的细粒度语义，特别是在处理长且细致描述时，SuperCLIP通过增加分类监督层，显著提升了视觉-文本对齐能力，且对计算资源基本无额外消耗。


<details>
  <summary>Details</summary>
Motivation: 尽管CLIP具备较强的视觉-语言泛化能力，但其仅优化全局的图文相似性，导致在细粒度对齐方面表现不足，尤其在文本描述较长、细致时这一劣势更加突出。为实现更精细的视觉-文本对齐，需要改进其训练目标。

Method: 提出SuperCLIP框架，在原有CLIP的视觉编码器上直接加一层线性分类层，利用分类监督增强token级别的视觉-文本对齐，仅带来极小的推理开销（FLOPs增加0.077%），且无需新增标注数据。

Result: SuperCLIP在零样本分类、图文检索以及纯视觉任务上均取得了显著提升，无论是基于原始网页数据还是经过重新标注的数据训练，均能恢复关键的文本监督效果，同时通过分类监督缓解了CLIP在小批量数据下性能大幅下降的问题。

Conclusion: SuperCLIP能高效且简洁地改进CLIP在细粒度视觉-文本对齐方面的性能，几乎不增加计算成本，也无需额外标注数据，并对不同训练数据来源一致有效，未来将开源代码与模型。

Abstract: Contrastive Language-Image Pretraining (CLIP) achieves strong generalization in vision-language tasks by aligning images and texts in a shared embedding space. However, recent findings show that CLIP-like models still underutilize fine-grained semantic signals in text, and this issue becomes even more pronounced when dealing with long and detailed captions. This stems from CLIP's training objective, which optimizes only global image-text similarity and overlooks token-level supervision - limiting its ability to achieve fine-grained visual-text alignment. To address this, we propose SuperCLIP, a simple yet effective framework that augments contrastive learning with classification-based supervision. By adding only a lightweight linear layer to the vision encoder, SuperCLIP leverages token-level cues to enhance visual-textual alignment - with just a 0.077% increase in total FLOPs, and no need for additional annotated data. Experiments show that SuperCLIP consistently improves zero-shot classification, image-text retrieval, and purely visual tasks. These gains hold regardless of whether the model is trained on original web data or rich re-captioned data, demonstrating SuperCLIP's ability to recover textual supervision in both cases. Furthermore, SuperCLIP alleviates CLIP's small-batch performance drop through classification-based supervision that avoids reliance on large batch sizes. Code and models will be made open source.

</details>


### [91] [SignIT: A Comprehensive Dataset and Multimodal Analysis for Italian Sign Language Recognition](https://arxiv.org/abs/2512.14489)
*Alessia Micieli,Giovanni Maria Farinella,Francesco Ragusa*

Main category: cs.CV

TL;DR: 本文介绍了SignIT，这是一个用于意大利手语（LIS）识别的新数据集，包含644段视频，并对其进行了细致注释和姿态关键点提取，同时建立了基准任务和模型评测。


<details>
  <summary>Details</summary>
Motivation: 目前用于意大利手语识别的数据集十分有限，阻碍了机器学习和计算机视觉领域在LIS自动识别方面的发展。作者希望通过构建公开、高质量注释的数据集，推动相关研究进展。

Method: 作者采集了共3.33小时、涵盖5大类（动物、食物、颜色、情感、家庭），共94种手语的视频，对其进行了人工标注，并提取了双手、面部和身体的二维关键点。基于这些数据，搭建了识别任务基准，评估了多种主流时序模型、关键点与RGB输入对性能的影响。

Result: 实验结果表明，现有的多种主流模型在SignIT数据集上表现存在明显局限性，尤其是在充分利用时序信息和多模态特征方面表现不佳。

Conclusion: SignIT数据集为意大利手语识别提供了一个新标准，并揭示了当前方法在该领域的不足，为后续算法优化和新方法提供了基础。数据及标注已公开发布，方便学术界进一步研究。

Abstract: In this work we present SignIT, a new dataset to study the task of Italian Sign Language (LIS) recognition. The dataset is composed of 644 videos covering 3.33 hours. We manually annotated videos considering a taxonomy of 94 distinct sign classes belonging to 5 macro-categories: Animals, Food, Colors, Emotions and Family. We also extracted 2D keypoints related to the hands, face and body of the users. With the dataset, we propose a benchmark for the sign recognition task, adopting several state-of-the-art models showing how temporal information, 2D keypoints and RGB frames can be influence the performance of these models. Results show the limitations of these models on this challenging LIS dataset. We release data and annotations at the following link: https://fpv-iplab.github.io/SignIT/.

</details>


### [92] [Native Intelligence Emerges from Large-Scale Clinical Practice: A Retinal Foundation Model with Deployment Efficiency](https://arxiv.org/abs/2512.14499)
*Jia Guo,Jiawei Du,Shengzhu Yang,Shuai Lu,Wenquan Cheng,Kaiwen Zhang,Yihua Sun,Chuhong Yang,Weihang Zhang,Fang Chen,Yilan Wu,Lie Ju,Guochen Ning,Longfei Ma,Huiping Yao,Jinyuan Wang,Peilun Shi,Yukun Zhou,Jie Xu,Pearse A. Keane,Hanruo Liu,Hongen Liao,Ningli Wang,Huiqi Li*

Main category: cs.CV

TL;DR: 该论文提出了一种名为ReVision的视网膜基础模型，能够利用真实临床实践中自然生成的大规模眼底照相及其诊断报告，无需额外注释和繁琐优化，在低资源环境中实现高效部署。


<details>
  <summary>Details</summary>
Motivation: 现有视网膜基础模型主要依赖经过精选的研究数据集，缺乏真实的临床背景，并且每个新任务都需大量专门调优，为低资源地区应用带来瓶颈。作者希望解决这一难题，实现无需复杂适配的医学AI系统。

Method: 作者利用中国162家医疗机构、十年间通过远程医疗积累的485,980份眼底彩照及其配套诊断报告，构建大规模影像-文本配对数据，通过自然对齐关系训练ReVision模型，实现了无需手工注释提取的“临床原生智能”。

Result: ReVision在27个眼科基准测试中表现优异，在12个公开基准实现平均AUROC 0.946，在3个临床数据集中达到0.952。无需任务特定训练即可实现zero-shot疾病检测；微调需求极低时，匹配了大规模精调模型，同时需求的参数和样本更少。表征具有良好迁移性，适用于新场所和多任务。33名眼科医师的读片实验也显示，ReVision零样本辅助提升诊断准确率14.8%。

Conclusion: 真实临床档案自带的影像-报告配对能够直接提取医疗AI系统所需的“原生智能”，可跳过人工注释和复杂优化，便于在低资源场景大规模推广。

Abstract: Current retinal foundation models remain constrained by curated research datasets that lack authentic clinical context, and require extensive task-specific optimization for each application, limiting their deployment efficiency in low-resource settings. Here, we show that these barriers can be overcome by building clinical native intelligence directly from real-world medical practice. Our key insight is that large-scale telemedicine programs, where expert centers provide remote consultations across distributed facilities, represent a natural reservoir for learning clinical image interpretation. We present ReVision, a retinal foundation model that learns from the natural alignment between 485,980 color fundus photographs and their corresponding diagnostic reports, accumulated through a decade-long telemedicine program spanning 162 medical institutions across China. Through extensive evaluation across 27 ophthalmic benchmarks, we demonstrate that ReVison enables deployment efficiency with minimal local resources. Without any task-specific training, ReVision achieves zero-shot disease detection with an average AUROC of 0.946 across 12 public benchmarks and 0.952 on 3 independent clinical cohorts. When minimal adaptation is feasible, ReVision matches extensively fine-tuned alternatives while requiring orders of magnitude fewer trainable parameters and labeled examples. The learned representations also transfer effectively to new clinical sites, imaging domains, imaging modalities, and systemic health prediction tasks. In a prospective reader study with 33 ophthalmologists, ReVision's zero-shot assistance improved diagnostic accuracy by 14.8% across all experience levels. These results demonstrate that clinical native intelligence can be directly extracted from clinical archives without any further annotation to build medical AI systems suited to various low-resource settings.

</details>


### [93] [DASP: Self-supervised Nighttime Monocular Depth Estimation with Domain Adaptation of Spatiotemporal Priors](https://arxiv.org/abs/2512.14536)
*Yiheng Huang,Junhong Chen,Anqi Ning,Zhanhong Liang,Nick Michiels,Luc Claesen,Wenyin Liu*

Main category: cs.CV

TL;DR: 本文提出了一种新的自监督夜间单目深度估计算法DASP，有效提升了低照度和运动模糊条件下的深度估计精度，在Oxford RobotCar和nuScenes数据集上取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 目前自监督单目深度估计在白天条件下表现良好，但在夜间因照度不足、纹理信息缺失和动态模糊带来极大挑战。因此，亟需发展能够适应夜间复杂光照和动态场景的深度估计方法。

Method: DASP包含两个分支：一是利用对抗分支结合设计的时空先验学习块（SPLB），从白天先验中提取细粒度的时空特征；二是自监督分支提出3D一致性投影损失，通过在共享3D空间下双向投影目标帧和源帧，优化深度抽取的一致性。SPLB具体由正交差分提取运动信息的STLM和结合非对称卷积与轴向注意力的ASLM组成，增强模型对纹理缺失和动态模糊区域的感知能力。

Result: 在Oxford RobotCar和nuScenes数据集上进行了大量实验，DASP在夜间深度估计任务上显著优于现有方法。消融实验进一步验证了每个模块的有效性。

Conclusion: DASP通过结合时空先验和3D一致性损失，显著提升了夜间复杂环境下的单目深度估计效果，并为自监督深度学习在低照度场景中的应用奠定了基础。

Abstract: Self-supervised monocular depth estimation has achieved notable success under daytime conditions. However, its performance deteriorates markedly at night due to low visibility and varying illumination, e.g., insufficient light causes textureless areas, and moving objects bring blurry regions. To this end, we propose a self-supervised framework named DASP that leverages spatiotemporal priors for nighttime depth estimation. Specifically, DASP consists of an adversarial branch for extracting spatiotemporal priors and a self-supervised branch for learning. In the adversarial branch, we first design an adversarial network where the discriminator is composed of four devised spatiotemporal priors learning blocks (SPLB) to exploit the daytime priors. In particular, the SPLB contains a spatial-based temporal learning module (STLM) that uses orthogonal differencing to extract motion-related variations along the time axis and an axial spatial learning module (ASLM) that adopts local asymmetric convolutions with global axial attention to capture the multiscale structural information. By combining STLM and ASLM, our model can acquire sufficient spatiotemporal features to restore textureless areas and estimate the blurry regions caused by dynamic objects. In the self-supervised branch, we propose a 3D consistency projection loss to bilaterally project the target frame and source frame into a shared 3D space, and calculate the 3D discrepancy between the two projected frames as a loss to optimize the 3D structural consistency and daytime priors. Extensive experiments on the Oxford RobotCar and nuScenes datasets demonstrate that our approach achieves state-of-the-art performance for nighttime depth estimation. Ablation studies further validate the effectiveness of each component.

</details>


### [94] [CAPRMIL: Context-Aware Patch Representations for Multiple Instance Learning](https://arxiv.org/abs/2512.14540)
*Andreas Lolos,Theofilos Christodoulou,Aris L. Moustakas,Stergios Christodoulidis,Maria Vakalopoulou*

Main category: cs.CV

TL;DR: 本文提出了一种新的MIL（多实例学习）框架CAPRMIL，用于计算病理学的全切片图像分析，利用上下文感知的特征嵌入，在降低计算和参数量的同时，达到或超越了最新方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有病理学中的深度学习方法多依赖MIL框架，因为切片图像超大且缺乏精确标注。但复杂的注意力机制聚合器增加了模型复杂度和计算量。因此，作者希望提出更高效低复杂度的方法。

Method: 作者提出CAPRMIL框架，先用冻结的patch编码器提取特征，再将这些特征通过全局token和多头自注意力机制进行上下文建模，生成丰富的patch表征，最后用简单的Mean MIL聚合完成分类，实现端到端训练。

Result: 与现有SOTA方法相比，CAPRMIL在多个公开病理学数据集上达到同等或更好的性能，同时可将训练参数减少48%-92.8%，推理计算量降低52%-99%，显著提升显存和训练效率。

Conclusion: 利用全局上下文感知的特征嵌入替代复杂聚合操作，是一种高效、可扩展的全切片分析方案。CAPRMIL在性能、计算资源消耗、效率上均具优势。

Abstract: In computational pathology, weak supervision has become the standard for deep learning due to the gigapixel scale of WSIs and the scarcity of pixel-level annotations, with Multiple Instance Learning (MIL) established as the principal framework for slide-level model training. In this paper, we introduce a novel setting for MIL methods, inspired by proceedings in Neural Partial Differential Equation (PDE) Solvers. Instead of relying on complex attention-based aggregation, we propose an efficient, aggregator-agnostic framework that removes the complexity of correlation learning from the MIL aggregator. CAPRMIL produces rich context-aware patch embeddings that promote effective correlation learning on downstream tasks. By projecting patch features -- extracted using a frozen patch encoder -- into a small set of global context/morphology-aware tokens and utilizing multi-head self-attention, CAPRMIL injects global context with linear computational complexity with respect to the bag size. Paired with a simple Mean MIL aggregator, CAPRMIL matches state-of-the-art slide-level performance across multiple public pathology benchmarks, while reducing the total number of trainable parameters by 48%-92.8% versus SOTA MILs, lowering FLOPs during inference by 52%-99%, and ranking among the best models on GPU memory efficiency and training time. Our results indicate that learning rich, context-aware instance representations before aggregation is an effective and scalable alternative to complex pooling for whole-slide analysis. Our code is available at https://github.com/mandlos/CAPRMIL

</details>


### [95] [HiFi-Portrait: Zero-shot Identity-preserved Portrait Generation with High-fidelity Multi-face Fusion](https://arxiv.org/abs/2512.14542)
*Yifang Xu,Benxiang Zhai,Yunzhuo Sun,Ming Li,Yang Li,Sidan Du*

Main category: cs.CV

TL;DR: 本文提出HiFi-Portrait方法，通过高保真度零样本肖像生成，能够更好地保持身份并精准控制人脸属性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于多张同一ID参考图像的肖像生成方法在人脸保真度和属性定制上表现较差。解决该问题对于提高肖像生成的质量和应用价值至关重要。

Method: 作者提出HiFi-Portrait方法，包括人脸细化器、地标生成器，融合精细化多脸特征和3D人脸地标，并设计HiFi-Net网络对两者进行融合与对齐。此外，还构建了基于身份的自动化训练数据集。

Result: 实验表明，该方法在身份相似度和人脸可控性上均优于当前最先进方法，并且兼容现有SDXL框架。

Conclusion: HiFi-Portrait提升了零样本肖像生成的人脸一致性和属性控制能力，具有高推广价值。

Abstract: Recent advancements in diffusion-based technologies have made significant strides, particularly in identity-preserved portrait generation (IPG). However, when using multiple reference images from the same ID, existing methods typically produce lower-fidelity portraits and struggle to customize face attributes precisely. To address these issues, this paper presents HiFi-Portrait, a high-fidelity method for zero-shot portrait generation. Specifically, we first introduce the face refiner and landmark generator to obtain fine-grained multi-face features and 3D-aware face landmarks. The landmarks include the reference ID and the target attributes. Then, we design HiFi-Net to fuse multi-face features and align them with landmarks, which improves ID fidelity and face control. In addition, we devise an automated pipeline to construct an ID-based dataset for training HiFi-Portrait. Extensive experimental results demonstrate that our method surpasses the SOTA approaches in face similarity and controllability. Furthermore, our method is also compatible with previous SDXL-based works.

</details>


### [96] [TAT: Task-Adaptive Transformer for All-in-One Medical Image Restoration](https://arxiv.org/abs/2512.14550)
*Zhiwen Yang,Jiaju Zhang,Yang Yi,Jian Liang,Bingzheng Wei,Yan Xu*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的任务自适应Transformer（TAT）架构，能有效应对多种医学图像恢复任务中任务干扰与任务不均衡的问题，实现了更优的多任务图像恢复效果。


<details>
  <summary>Details</summary>
Motivation: 现有All-in-One医学图像恢复模型在同时处理多任务时，由于任务间模态与降质类型差异较大，容易出现参数冲突（任务干扰）和学习难度不均（任务不均衡），导致模型表现受限。作者旨在通过新方法减少这种性能下降，实现多任务医学图像高质量恢复。

Method: 提出了任务自适应Transformer（TAT）框架。其中两项关键创新：（1）任务自适应权重生成机制，为每个任务动态生成专属参数，避免共享参数时梯度冲突；（2）任务自适应损失平衡机制，依据各任务学习难度动态调整损失权重，防止某任务主导训练或训练不足。

Result: TAT框架在PET合成、CT降噪和MRI超分辨率三类医学图像恢复任务上（无论是单任务还是全任务一体化）均取得了领先于现有方法的性能。

Conclusion: TAT能有效缓解All-in-One医学图像恢复中的任务干扰与不均衡问题，提升了多任务模型的泛化与恢复质量，为实际医学图像处理提供了更强有力的技术支撑。

Abstract: Medical image restoration (MedIR) aims to recover high-quality medical images from their low-quality counterparts. Recent advancements in MedIR have focused on All-in-One models capable of simultaneously addressing multiple different MedIR tasks. However, due to significant differences in both modality and degradation types, using a shared model for these diverse tasks requires careful consideration of two critical inter-task relationships: task interference, which occurs when conflicting gradient update directions arise across tasks on the same parameter, and task imbalance, which refers to uneven optimization caused by varying learning difficulties inherent to each task. To address these challenges, we propose a task-adaptive Transformer (TAT), a novel framework that dynamically adapts to different tasks through two key innovations. First, a task-adaptive weight generation strategy is introduced to mitigate task interference by generating task-specific weight parameters for each task, thereby eliminating potential gradient conflicts on shared weight parameters. Second, a task-adaptive loss balancing strategy is introduced to dynamically adjust loss weights based on task-specific learning difficulties, preventing task domination or undertraining. Extensive experiments demonstrate that our proposed TAT achieves state-of-the-art performance in three MedIR tasks--PET synthesis, CT denoising, and MRI super-resolution--both in task-specific and All-in-One settings. Code is available at https://github.com/Yaziwel/TAT.

</details>


### [97] [CLNet: Cross-View Correspondence Makes a Stronger Geo-Localizationer](https://arxiv.org/abs/2512.14560)
*Xianwei Cao,Dou Quan,Shuang Wang,Ning Huyan,Wei Wang,Yunan Li,Licheng Jiao*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的特征细化框架CLNet，用于显式建模跨视角图像（如卫星与街景）之间的空间对应性，实现更准确的地理定位，并在多个公开基准上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图像检索的跨视角地理定位方法大多依赖于全局表示或隐式的特征对齐，难以有效建模卫星与街景之间显式的空间对应关系，限制了定位精度。因此，亟需方法能显式桥接不同视角间的语义和几何鸿沟。

Method: 作者提出了CLNet框架，将视角对齐分解为三个可学习且互补的模块：1）神经对应关系图（NCM）用于通过潜在对应场进行空间特征对齐；2）非线性嵌入转换器（NEC）使用MLP对不同视角特征进行转换；3）全局特征重标定（GFR）模块结合空间线索调整特征通道权重，从而实现高层语义与细粒度对齐的联合建模。

Result: 在CVUSA、CVACT、VIGOR和University-1652四个公开基准上，CLNet均取得了最先进的性能，并展现出了更好的可解释性和泛化能力。

Conclusion: CLNet能显式建模跨视角语义和空间对应关系，显著提升了地理定位准确率，验证了其有效性与优越性。

Abstract: Image retrieval-based cross-view geo-localization (IRCVGL) aims to match images captured from significantly different viewpoints, such as satellite and street-level images. Existing methods predominantly rely on learning robust global representations or implicit feature alignment, which often fail to model explicit spatial correspondences crucial for accurate localization. In this work, we propose a novel correspondence-aware feature refinement framework, termed CLNet, that explicitly bridges the semantic and geometric gaps between different views. CLNet decomposes the view alignment process into three learnable and complementary modules: a Neural Correspondence Map (NCM) that spatially aligns cross-view features via latent correspondence fields; a Nonlinear Embedding Converter (NEC) that remaps features across perspectives using an MLP-based transformation; and a Global Feature Recalibration (GFR) module that reweights informative feature channels guided by learned spatial cues. The proposed CLNet can jointly capture both high-level semantics and fine-grained alignments. Extensive experiments on four public benchmarks, CVUSA, CVACT, VIGOR, and University-1652, demonstrate that our proposed CLNet achieves state-of-the-art performance while offering better interpretability and generalizability.

</details>


### [98] [FoodLogAthl-218: Constructing a Real-World Food Image Dataset Using Dietary Management Applications](https://arxiv.org/abs/2512.14574)
*Mitsuki Watanabe,Sosuke Amano,Kiyoharu Aizawa,Yoko Yamakata*

Main category: cs.CV

TL;DR: 本论文提出了FoodLogAthl-218，一个基于真实用户饮食日志构建的食品图像数据集，用于改进饮食管理领域的食品识别任务。


<details>
  <summary>Details</summary>
Motivation: 现有食品图像分类数据集大多依赖网络爬取的图片，与普通用户上传的真实用餐照片存在差异，影响模型在实际饮食管理应用中的表现。本研究旨在构建更加贴近实际应用场景的食品图像数据集，提升相关模型的实用价值。

Method: 数据集基于FoodLog Athl应用中的用户实际用餐记录，每张图片附带就餐时间、匿名用户ID、就餐情境等丰富元数据。从用户提交的原始照片出发，后续进行标注，保证数据的多样性和真实性。设计了三个任务：标准分类、增量微调（按用户日志顺序）、多菜品场景下的情境感知分类，并使用大规模多模态模型进行评测。

Result: 数据集包含218类食物，共6,925张图片和14,349个标注框。通过不同任务和大模型的实验，验证了数据集的多样性和在实际饮食管理中的适用性。数据集现已公开。

Conclusion: FoodLogAthl-218更贴合真实饮食场景，有助于推动食品图像分类研究在实际中更好地应用，并支持新的场景感知和持续学习任务，对提升自动饮食管理系统的人机互动体验具有重要意义。

Abstract: Food image classification models are crucial for dietary management applications because they reduce the burden of manual meal logging. However, most publicly available datasets for training such models rely on web-crawled images, which often differ from users' real-world meal photos. In this work, we present FoodLogAthl-218, a food image dataset constructed from real-world meal records collected through the dietary management application FoodLog Athl. The dataset contains 6,925 images across 218 food categories, with a total of 14,349 bounding boxes. Rich metadata, including meal date and time, anonymized user IDs, and meal-level context, accompany each image. Unlike conventional datasets-where a predefined class set guides web-based image collection-our data begins with user-submitted photos, and labels are applied afterward. This yields greater intra-class diversity, a natural frequency distribution of meal types, and casual, unfiltered images intended for personal use rather than public sharing. In addition to (1) a standard classification benchmark, we introduce two FoodLog-specific tasks: (2) an incremental fine-tuning protocol that follows the temporal stream of users' logs, and (3) a context-aware classification task where each image contains multiple dishes, and the model must classify each dish by leveraging the overall meal context. We evaluate these tasks using large multimodal models (LMMs). The dataset is publicly available at https://huggingface.co/datasets/FoodLog/FoodLogAthl-218.

</details>


### [99] [LLM-driven Knowledge Enhancement for Multimodal Cancer Survival Prediction](https://arxiv.org/abs/2512.14594)
*Chenyu Zhao,Yingxue Xu,Fengtao Zhou,Yihui Wang,Hao Chen*

Main category: cs.CV

TL;DR: 本文提出了一种融合专家报告和知识背景的多模态癌症生存预测方法，通过大模型生成的知识有效提升了预测性能，并在多个数据集上取得了SOTA表现。


<details>
  <summary>Details</summary>
Motivation: 现有多模态生存预测方法依赖于高维、冗余的病理图像和基因组数据，难以提取判别特征且模态对齐困难；同时，单一的生存标签难以指导复杂的预测任务。

Method: 提出KEMM（Knowledge-Enhanced Multimodal Model），融合两类LLM生成的知识：1）经过大模型精炼的专家报告，2）大模型生成的不同癌症类型的预后背景知识。并提出了知识增强的跨模态注意力模块（KECM），帮助模型聚焦于有区分力和与生存相关的特征。

Result: KEMM在五个数据集上进行了大量实验，表现优越，达到了SOTA水平。

Conclusion: 融合大模型生成的临床知识和背景信息显著提升了多模态生存预测的准确性和泛化能力。

Abstract: Current multimodal survival prediction methods typically rely on pathology images (WSIs) and genomic data, both of which are high-dimensional and redundant, making it difficult to extract discriminative features from them and align different modalities. Moreover, using a simple survival follow-up label is insufficient to supervise such a complex task. To address these challenges, we propose KEMM, an LLM-driven Knowledge-Enhanced Multimodal Model for cancer survival prediction, which integrates expert reports and prognostic background knowledge. 1) Expert reports, provided by pathologists on a case-by-case basis and refined by large language model (LLM), offer succinct and clinically focused diagnostic statements. This information may typically suggest different survival outcomes. 2) Prognostic background knowledge (PBK), generated concisely by LLM, provides valuable prognostic background knowledge on different cancer types, which also enhances survival prediction. To leverage these knowledge, we introduce the knowledge-enhanced cross-modal (KECM) attention module. KECM can effectively guide the network to focus on discriminative and survival-relevant features from highly redundant modalities. Extensive experiments on five datasets demonstrate that KEMM achieves state-of-the-art performance. The code will be released upon acceptance.

</details>


### [100] [TUMTraf EMOT: Event-Based Multi-Object Tracking Dataset and Baseline for Traffic Scenarios](https://arxiv.org/abs/2512.14595)
*Mengyu Li,Xingcheng Zhou,Guang Chen,Alois Knoll,Hu Cao*

Main category: cs.CV

TL;DR: 本文提出了一个用于事件摄像头智能交通系统（ITS）的初步数据集，并基于此建立了车辆与行人检测和跟踪的基准，实现了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 传统帧式摄像头在弱光和高速运动环境下表现有限，而事件摄像头具备低延迟、高动态范围和高时间分辨率，能更好适应实际场景。现有关于事件视觉的研究较少，特别是在ITS领域，亟需填补相关研究空白。

Method: 作者构建了首个针对ITS场景的事件视觉数据集，涵盖车辆与行人检测与跟踪。同时，基于该数据集提出了跟踪-检测一体化的基准任务，并设计了专用特征提取器，用于事件数据的处理和分析。

Result: 基于该事件摄像头数据集，提出的检测与跟踪算法在实验中取得了极佳的性能，验证了事件视觉在智能交通场景下的有效性。

Conclusion: 该工作为事件视觉在智能交通系统领域的应用开创了新的方向，为后续相关研究和实际应用提供了数据基础和基准方法。

Abstract: In Intelligent Transportation Systems (ITS), multi-object tracking is primarily based on frame-based cameras. However, these cameras tend to perform poorly under dim lighting and high-speed motion conditions. Event cameras, characterized by low latency, high dynamic range and high temporal resolution, have considerable potential to mitigate these issues. Compared to frame-based vision, there are far fewer studies on event-based vision. To address this research gap, we introduce an initial pilot dataset tailored for event-based ITS, covering vehicle and pedestrian detection and tracking. We establish a tracking-by-detection benchmark with a specialized feature extractor based on this dataset, achieving excellent performance.

</details>


### [101] [FakeRadar: Probing Forgery Outliers to Detect Unknown Deepfake Videos](https://arxiv.org/abs/2512.14601)
*Zhaolun Li,Jichang Li,Yinqi Cai,Junye Chen,Xiaonan Luo,Guanbin Li,Rushi Lan*

Main category: cs.CV

TL;DR: 该论文提出了FakeRadar框架，通过大规模预训练模型和伪造异常样本生成方法显著提升了深度伪造视频检测的跨领域泛化能力，在多个基准数据集上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法对新型伪造手法的泛化能力较差，检测准确率大幅下降，因此急需提升深度伪造检测的跨域适应能力，以应对不断涌现的新型伪造技术。

Method: 提出FakeRadar检测框架，利用CLIP等大规模预训练模型增强特征表达能力；引入伪造异常探测（Forgery Outlier Probing），通过动态子聚类建模和子聚类条件异常生成方法，合成临近子聚类边界的异常样本，以模拟未知伪造类型；同时设计包含异常引导对比学习和异常条件交叉熵损失的三路训练机制，以提升模型区分真实、已知伪造及异常样本的能力。

Result: 在多个深度伪造视频检测基准数据集上的实验显示，FakeRadar在跨域任务下优于当前主流方法，特别是在对抗未见过的新型伪造手法时表现更为稳定和出色。

Conclusion: FakeRadar显著提升了深度伪造检测方法对未知伪造样本的泛化能力，为实际应用中的深度伪造检测提供了更强的可靠性与适应性。

Abstract: In this paper, we propose FakeRadar, a novel deepfake video detection framework designed to address the challenges of cross-domain generalization in real-world scenarios. Existing detection methods typically rely on manipulation-specific cues, performing well on known forgery types but exhibiting severe limitations against emerging manipulation techniques. This poor generalization stems from their inability to adapt effectively to unseen forgery patterns. To overcome this, we leverage large-scale pretrained models (e.g. CLIP) to proactively probe the feature space, explicitly highlighting distributional gaps between real videos, known forgeries, and unseen manipulations. Specifically, FakeRadar introduces Forgery Outlier Probing, which employs dynamic subcluster modeling and cluster-conditional outlier generation to synthesize outlier samples near boundaries of estimated subclusters, simulating novel forgery artifacts beyond known manipulation types. Additionally, we design Outlier-Guided Tri-Training, which optimizes the detector to distinguish real, fake, and outlier samples using proposed outlier-driven contrastive learning and outlier-conditioned cross-entropy losses. Experiments show that FakeRadar outperforms existing methods across various benchmark datasets for deepfake video detection, particularly in cross-domain evaluations, by handling the variety of emerging manipulation techniques.

</details>


### [102] [WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling](https://arxiv.org/abs/2512.14614)
*Wenqiang Sun,Haiyu Zhang,Haoyuan Wang,Junta Wu,Zehan Wang,Zhenwei Wang,Yunhong Wang,Jun Zhang,Tengfei Wang,Chunchao Guo*

Main category: cs.CV

TL;DR: 该论文提出了WorldPlay，一种能够实现实时、具有长期几何一致性的视频流扩散模型，有效解决了速度与内存之间的权衡问题，相比现有技术有明显优势。


<details>
  <summary>Details</summary>
Motivation: 现有的视频生成方法难以兼顾实时性和长期几何一致性，特别是在高分辨率和长时间序列的场景下易出现错误累积和内存消耗过大。因此亟需一种既能高效生成视频，又能保持长期空间一致性的方法。

Method: WorldPlay主要有三项创新：（1）采用Dual Action Representation，实现对用户输入的键盘和鼠标操作的稳健动作控制；（2）通过Reconstituted Context Memory，动态重建历史帧的上下文，并利用时间重构机制，使关键的历史帧依然可用，缓解了内存衰减问题；（3）提出Context Forcing蒸馏方法，通过对齐教师和学生模型的内存上下文，提升模型利用长时程信息的能力，实现实时推理并抑制误差漂移。

Result: WorldPlay能以24 FPS的速度生成720p分辨率、长期一致的视频，在一致性和泛化能力上优于现有方法，能够适用于多种复杂场景。

Conclusion: WorldPlay实现了实时、高一致性的视频流生成，为视频扩散模型提供了新范式，展示了显著的性能提升和广泛的应用潜力。

Abstract: This paper presents WorldPlay, a streaming video diffusion model that enables real-time, interactive world modeling with long-term geometric consistency, resolving the trade-off between speed and memory that limits current methods. WorldPlay draws power from three key innovations. 1) We use a Dual Action Representation to enable robust action control in response to the user's keyboard and mouse inputs. 2) To enforce long-term consistency, our Reconstituted Context Memory dynamically rebuilds context from past frames and uses temporal reframing to keep geometrically important but long-past frames accessible, effectively alleviating memory attenuation. 3) We also propose Context Forcing, a novel distillation method designed for memory-aware model. Aligning memory context between the teacher and student preserves the student's capacity to use long-range information, enabling real-time speeds while preventing error drift. Taken together, WorldPlay generates long-horizon streaming 720p video at 24 FPS with superior consistency, comparing favorably with existing techniques and showing strong generalization across diverse scenes. Project page and online demo can be found: https://3d-models.hunyuan.tencent.com/world/ and https://3d.hunyuan.tencent.com/sceneTo3D.

</details>


### [103] [Distill Video Datasets into Images](https://arxiv.org/abs/2512.14621)
*Zhenghao Zhao,Haoxuan Wang,Kai Wang,Yuzhang Shang,Yuan Hong,Yan Yan*

Main category: cs.CV

TL;DR: 该论文提出了一种名为SFVD的视频数据集蒸馏方法，仅通过对每个类别选取高信息量的单帧图片进行蒸馏，使模型在精简数据集上实现接近全量数据训练的效果。


<details>
  <summary>Details</summary>
Motivation: 现有数据集蒸馏方法在图像上表现优秀，但扩展到视频时因时序维度引入大量参数，导致优化困难、性能下降。如何高效地对视频数据进行蒸馏，压缩数据体积同时保留判别信息，是一个重要且未解决的问题。

Method: SFVD首先观察到单帧即可表达视频主要语义，因此为每个类别选择关键帧，通过可微分插值将单帧还原为伪视频，与原始数据集做匹配。优化时参数仅更新关键帧，提升了训练效率。此外，为补充时序信息，在匹配过程中引入真实视频样本，并通过通道重构层融合。

Result: 在多个公开基准（如MiniUCF）上，SFVD显著优于以往方法，性能提升最高达5.3%。

Conclusion: SFVD为视频数据集蒸馏提供了一种高效、有效的解决方案，在压缩数据集的同时，保证了模型训练性能，为视频理解等领域相关任务带来新思路。

Abstract: Dataset distillation aims to synthesize compact yet informative datasets that allow models trained on them to achieve performance comparable to training on the full dataset. While this approach has shown promising results for image data, extending dataset distillation methods to video data has proven challenging and often leads to suboptimal performance. In this work, we first identify the core challenge in video set distillation as the substantial increase in learnable parameters introduced by the temporal dimension of video, which complicates optimization and hinders convergence. To address this issue, we observe that a single frame is often sufficient to capture the discriminative semantics of a video. Leveraging this insight, we propose Single-Frame Video set Distillation (SFVD), a framework that distills videos into highly informative frames for each class. Using differentiable interpolation, these frames are transformed into video sequences and matched with the original dataset, while updates are restricted to the frames themselves for improved optimization efficiency. To further incorporate temporal information, the distilled frames are combined with sampled real videos from real videos during the matching process through a channel reshaping layer. Extensive experiments on multiple benchmarks demonstrate that SFVD substantially outperforms prior methods, achieving improvements of up to 5.3% on MiniUCF, thereby offering a more effective solution.

</details>


### [104] [AMD-HookNet++: Evolution of AMD-HookNet with Hybrid CNN-Transformer Feature Enhancement for Glacier Calving Front Segmentation](https://arxiv.org/abs/2512.14639)
*Fei Wu,Marcel Dreier,Nora Gourmelon,Sebastian Wind,Jianlin Zhang,Thorsten Seehaus,Matthias Braun,Andreas Maier,Vincent Christlein*

Main category: cs.CV

TL;DR: 本文提出了一种结合CNN与Transformer的新型混合模型AMD-HookNet++，用于在合成孔径雷达图像中高效、精细地分割冰川和识别断裂前缘，其在主流数据集上表现优异，达到最新技术水平。


<details>
  <summary>Details</summary>
Motivation: 冰川与冰架前缘的位置变化直接影响冰盖质量及海平面变化，现有方法难以同时兼顾长距离依赖与局部细节，高精度自动分割冰川及前缘位置极为关键。

Method: 提出了AMD-HookNet++混合架构：包含Transformer分支捕捉长距离依赖提供全局上下文，CNN分支保留局部细节，并引入空间-通道注意力模块增强两分支信息交互，辅以像素对比深度监督提升判别能力。

Result: 在冰川分割基准数据集CaFFe上，模型取得IoU 78.2、HD95 1,318米、MDE 367米的表现，优于现有方法，并能获得更平滑的断裂前缘轮廓，解决了Transformer分割易产生锯齿边缘的问题。

Conclusion: AMD-HookNet++兼容了CNN与Transformer的优势，通过创新模块改进特征交互和判别能力，在冰川分割任务上达到了最新最好表现，对后续冰川监测与海平面研究具有重要意义。

Abstract: The dynamics of glaciers and ice shelf fronts significantly impact the mass balance of ice sheets and coastal sea levels. To effectively monitor glacier conditions, it is crucial to consistently estimate positional shifts of glacier calving fronts. AMD-HookNet firstly introduces a pure two-branch convolutional neural network (CNN) for glacier segmentation. Yet, the local nature and translational invariance of convolution operations, while beneficial for capturing low-level details, restricts the model ability to maintain long-range dependencies. In this study, we propose AMD-HookNet++, a novel advanced hybrid CNN-Transformer feature enhancement method for segmenting glaciers and delineating calving fronts in synthetic aperture radar images. Our hybrid structure consists of two branches: a Transformer-based context branch to capture long-range dependencies, which provides global contextual information in a larger view, and a CNN-based target branch to preserve local details. To strengthen the representation of the connected hybrid features, we devise an enhanced spatial-channel attention module to foster interactions between the hybrid CNN-Transformer branches through dynamically adjusting the token relationships from both spatial and channel perspectives. Additionally, we develop a pixel-to-pixel contrastive deep supervision to optimize our hybrid model by integrating pixelwise metric learning into glacier segmentation. Through extensive experiments and comprehensive quantitative and qualitative analyses on the challenging glacier segmentation benchmark dataset CaFFe, we show that AMD-HookNet++ sets a new state of the art with an IoU of 78.2 and a HD95 of 1,318 m, while maintaining a competitive MDE of 367 m. More importantly, our hybrid model produces smoother delineations of calving fronts, resolving the issue of jagged edges typically seen in pure Transformer-based approaches.

</details>


### [105] [A Multicenter Benchmark of Multiple Instance Learning Models for Lymphoma Subtyping from HE-stained Whole Slide Images](https://arxiv.org/abs/2512.14640)
*Rao Muhammad Umer,Daniel Sens,Jonathan Noll,Christian Matek,Lukas Wolfseher,Rainer Spang,Ralf Huss,Johannes Raffler,Sarah Reinke,Wolfram Klapper,Katja Steiger,Kristina Schwamborn,Carsten Marr*

Main category: cs.CV

TL;DR: 本文建立了首个多中心淋巴瘤基准数据集，并系统评估了5个主流病理基础模型与多实例学习聚合方法在不同放大倍数下的诊断效果。结果显示模型在同分布下准确率较高，但遇到外部分布数据时泛化能力不足。


<details>
  <summary>Details</summary>
Motivation: 当前淋巴瘤诊断依赖多种高成本检测手段，流程复杂且耗时，深度学习可用HE染色切片辅助诊断，但缺乏多中心、系统化的基准评测。

Method: 作者建立了覆盖四种常见淋巴瘤亚型及健康对照组织的多中心基准数据集，系统评估了5个公开病理模型与两种多实例学习方法，在三种不同放大倍数下进行分类实验，并在同分布和外部分布数据上评测模型表现。

Result: 在同分布测试集上，所有模型多类别平衡准确率均超80%，聚合方法表现类似。40x放大率已足够，进一步增大分辨率没有提升。外部分布测试集上准确率仅约60%，显示出泛化性问题。

Conclusion: 多中心深度学习模型有望辅助淋巴瘤亚型诊断，但当前还需扩展至更多稀有亚型，提高模型泛化能力。本文提供了自动化基准评测流程，为后续研究奠定基础。

Abstract: Timely and accurate lymphoma diagnosis is essential for guiding cancer treatment. Standard diagnostic practice combines hematoxylin and eosin (HE)-stained whole slide images with immunohistochemistry, flow cytometry, and molecular genetic tests to determine lymphoma subtypes, a process requiring costly equipment, skilled personnel, and causing treatment delays. Deep learning methods could assist pathologists by extracting diagnostic information from routinely available HE-stained slides, yet comprehensive benchmarks for lymphoma subtyping on multicenter data are lacking. In this work, we present the first multicenter lymphoma benchmarking dataset covering four common lymphoma subtypes and healthy control tissue. We systematically evaluate five publicly available pathology foundation models (H-optimus-1, H0-mini, Virchow2, UNI2, Titan) combined with attention-based (AB-MIL) and transformer-based (TransMIL) multiple instance learning aggregators across three magnifications (10x, 20x, 40x). On in-distribution test sets, models achieve multiclass balanced accuracies exceeding 80% across all magnifications, with all foundation models performing similarly and both aggregation methods showing comparable results. The magnification study reveals that 40x resolution is sufficient, with no performance gains from higher resolutions or cross-magnification aggregation. However, on out-of-distribution test sets, performance drops substantially to around 60%, highlighting significant generalization challenges. To advance the field, larger multicenter studies covering additional rare lymphoma subtypes are needed. We provide an automated benchmarking pipeline to facilitate such future research.

</details>


### [106] [Adaptable Segmentation Pipeline for Diverse Brain Tumors with Radiomic-guided Subtyping and Lesion-Wise Model Ensemble](https://arxiv.org/abs/2512.14648)
*Daniel Capellán-Martín,Abhijeet Parida,Zhifan Jiang,Nishad Kulkarni,Krithika Iyer,Austin Tapp,Syed Muhammad Anwar,María J. Ledesma-Carbayo,Marius George Linguraru*

Main category: cs.CV

TL;DR: 本文提出了一种灵活、模块化并可适应不同类型脑肿瘤的分割流程，通过结合多种先进模型与针对不同肿瘤和病灶的处理方法，在多参数MRI图像上取得了高水平的分割效果，并在BraTS 2025基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有脑肿瘤分割方法在多参数MRI上难以达到稳健和泛化，因为肿瘤类型差异大、数据复杂性高，限制了其在实际临床中的应用。

Method: 该文提出一种端到端分割流程，整合多种最先进的分割模型，并引入基于肿瘤和病灶特定的训练前后处理。利用MRI的影像组学特征进行肿瘤亚型检测，平衡训练。通过自定义病灶级别的性能评估，优化模型集成与后处理，每一步均针对具体病例调整。

Result: 在BraTS多项测试集中，该流程分割准确性达到当前顶尖算法水平，且在成人与儿童不同类型肿瘤数据集皆表现优良。

Conclusion: 结合定制的病灶感知处理与灵活模型选择，能获得稳健、泛化良好的肿瘤分割，而且无需限制具体网络架构，具备未来在临床定量肿瘤测量的潜力，可辅助诊疗和预后。

Abstract: Robust and generalizable segmentation of brain tumors on multi-parametric magnetic resonance imaging (MRI) remains difficult because tumor types differ widely. The BraTS 2025 Lighthouse Challenge benchmarks segmentation methods on diverse high-quality datasets of adult and pediatric tumors: multi-consortium international pediatric brain tumor segmentation (PED), preoperative meningioma tumor segmentation (MEN), meningioma radiotherapy segmentation (MEN-RT), and segmentation of pre- and post-treatment brain metastases (MET). We present a flexible, modular, and adaptable pipeline that improves segmentation performance by selecting and combining state-of-the-art models and applying tumor- and lesion-specific processing before and after training. Radiomic features extracted from MRI help detect tumor subtype, ensuring a more balanced training. Custom lesion-level performance metrics determine the influence of each model in the ensemble and optimize post-processing that further refines the predictions, enabling the workflow to tailor every step to each case. On the BraTS testing sets, our pipeline achieved performance comparable to top-ranked algorithms across multiple challenges. These findings confirm that custom lesion-aware processing and model selection yield robust segmentations yet without locking the method to a specific network architecture. Our method has the potential for quantitative tumor measurement in clinical practice, supporting diagnosis and prognosis.

</details>


### [107] [ViRC: Enhancing Visual Interleaved Mathematical CoT with Reason Chunking](https://arxiv.org/abs/2512.14654)
*Lihong Wang,Liangqi Li,Weiwei Feng,Jiamin Wu,Changtao Miao,Tieru Wu,Rui Ma,Bo Zhang,Zhe Li*

Main category: cs.CV

TL;DR: 本文提出了一种面向多模态数学任务的新型推理框架ViRC，通过Reason Chunking机制把推理分解为多个关键推理单元（CRU），实现更像人类专家的逐步、多次视觉获取式推理，有效提升了模型的数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 虽然链式思维（CoT）极大提升了LLM的推理能力，但在涉及多模态、特别是数学任务时存在局限，当前多模态LLM主要只基于单一静态数学图片进行文本推理，忽视了动态视觉信息的持续利用。与此不同，人类解决数学问题时会不断检视图片并逐步推理。因此，作者尝试模仿人类的推理策略，提升多模态LLM在数学推理中的表现。

Method: 作者提出了ViRC框架，引入Reason Chunking机制，将推理过程结构化为一系列关键推理单元（CRU）。每个CRU内部保证文本连贯性和中间命题验证，同时整合跨单元的视觉信息推动后续推理，并制备配套的CRUX数据集，涵盖多工具、多推理模式下的显式CRU注释。此外，采用逐步训练策略（包括教学指令微调、实践微调和策略强化学习）强化模型的推理分块能力。

Result: 基于上述技术，训练得到的ViRC-7B模型在多个数学基准测试中相较于基线模型平均提升了18.8%的推理表现。

Conclusion: ViRC以类人专家的分步推理模式，有效促进了多模态LLM在复杂数学推理任务中的表现，证明了Reason Chunking机制的有效性。

Abstract: CoT has significantly enhanced the reasoning ability of LLMs while it faces challenges when extended to multimodal domains, particularly in mathematical tasks. Existing MLLMs typically perform textual reasoning solely from a single static mathematical image, overlooking dynamic visual acquisition during reasoning. In contrast, humans repeatedly examine visual image and employ step-by-step reasoning to prove intermediate propositions. This strategy of decomposing the problem-solving process into key logical nodes adheres to Miller's Law in cognitive science. Inspired by this insight, we propose a ViRC framework for multimodal mathematical tasks, introducing a Reason Chunking mechanism that structures multimodal mathematical CoT into consecutive Critical Reasoning Units (CRUs) to simulate human expert problem-solving patterns. CRUs ensure intra-unit textual coherence for intermediate proposition verification while integrating visual information across units to generate subsequent propositions and support structured reasoning. To this end, we present CRUX dataset by using three visual tools and four reasoning patterns to provide explicitly annotated CRUs across multiple reasoning paths for each mathematical problem. Leveraging the CRUX dataset, we propose a progressive training strategy inspired by human cognitive learning, which includes Instructional SFT, Practice SFT, and Strategic RL, aimed at further strengthening the Reason Chunking ability of the model.The resulting ViRC-7B model achieves a 18.8\% average improvement over baselines across multiple mathematical benchmarks. Code is available at https://github.com/Leon-LihongWang/ViRC.

</details>


### [108] [Enhancing Visual Sentiment Analysis via Semiotic Isotopy-Guided Dataset Construction](https://arxiv.org/abs/2512.14665)
*Marco Blanchini,Giovanna Maria Dimitri,Benedetta Tondi,Tarcisio Lancioni,Mauro Barni*

Main category: cs.CV

TL;DR: 本文提出了一种基于符号同义理论（semiotic isotopy）的视觉情感分析（VSA）数据集构建方法，通过整合现有数据集生成更大且多样性更高的数据集，从而显著提升VSA模型的泛化能力及情感元素识别效果。


<details>
  <summary>Details</summary>
Motivation: 当前视觉情感分析面临两大挑战：1）缺乏足够大且多样化的数据集，难以全面覆盖多样的情感图像；2）缺乏有效方法，导致模型难以准确识别图像中的情感相关元素，进而导致模型在不同数据集间的泛化能力有限。

Method: 作者利用符号同义理论（semiotic isotopy），在整合现有数据集基础上，构建了一个覆盖图像多样性更广、情感标签更丰富的新型大规模VSA数据集。该理论帮助挖掘和组织图像中情感相关元素，从而增强数据集对情感内涵的表达能力。通过在此新数据集上训练，能促使模型更关注情感相关的图像组合。

Result: 实验表明，使用本文方法生成的数据集训练的VSA模型，在主要VSA基准测试数据集上的泛化能力和表现均明显优于在原始数据集上训练的模型。

Conclusion: 基于符号同义理论构建的大规模多样化VSA数据集，能够有效提升视觉情感分析模型识别情感元素和跨数据集泛化的能力。

Abstract: Visual Sentiment Analysis (VSA) is a challenging task due to the vast diversity of emotionally salient images and the inherent difficulty of acquiring sufficient data to capture this variability comprehensively. Key obstacles include building large-scale VSA datasets and developing effective methodologies that enable algorithms to identify emotionally significant elements within an image. These challenges are reflected in the limited generalization performance of VSA algorithms and models when trained and tested across different datasets. Starting from a pool of existing data collections, our approach enables the creation of a new larger dataset that not only contains a wider variety of images than the original ones, but also permits training new models with improved capability to focus on emotionally relevant combinations of image elements. This is achieved through the integration of the semiotic isotopy concept within the dataset creation process, providing deeper insights into the emotional content of images. Empirical evaluations show that models trained on a dataset generated with our method consistently outperform those trained on the original data collections, achieving superior generalization across major VSA benchmarks

</details>


### [109] [ART: Articulated Reconstruction Transformer](https://arxiv.org/abs/2512.14671)
*Zizhang Li,Cheng Zhang,Zhengqin Li,Henry Howard-Jenkins,Zhaoyang Lv,Chen Geng,Jiajun Wu,Richard Newcombe,Jakob Engel,Zhao Dong*

Main category: cs.CV

TL;DR: 本文提出了ART（Articulated Reconstruction Transformer），一种能够从稀疏多状态RGB图像重建完整三维关节物体的、类别无关的前馈模型。通过部分为基础的方法，ART显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的关节物体三维重建方法存在以下问题：一是依赖于繁琐且脆弱的跨状态对应关系的优化，效率低下；二是现有的前馈模型限制于特定的物体类别，泛化能力弱。因而需要一种高效且类别无关的三维重建方法。

Method: ART将关节物体视为刚性部件的组合，将重建任务公式化为基于部件的预测。创新性的transformer架构映射稀疏图像输入到一组可学习的部件slot，并统一解码得到各部件的三维几何体、纹理以及显式结构参数。其输出结果可物理解释，且可直接用于仿真。训练基于大规模、带部件标注的数据集。

Result: ART在多种基准测试中都取得了比现有方法更优的表现，在类别无关的关节物体重建领域树立了新的性能标杆。

Conclusion: ART为关节物体的三维重建提供了一种高效、物理可解释且推广性强的新方法，对图像输入场景下的复杂结构建模有重要意义。

Abstract: We introduce ART, Articulated Reconstruction Transformer -- a category-agnostic, feed-forward model that reconstructs complete 3D articulated objects from only sparse, multi-state RGB images. Previous methods for articulated object reconstruction either rely on slow optimization with fragile cross-state correspondences or use feed-forward models limited to specific object categories. In contrast, ART treats articulated objects as assemblies of rigid parts, formulating reconstruction as part-based prediction. Our newly designed transformer architecture maps sparse image inputs to a set of learnable part slots, from which ART jointly decodes unified representations for individual parts, including their 3D geometry, texture, and explicit articulation parameters. The resulting reconstructions are physically interpretable and readily exportable for simulation. Trained on a large-scale, diverse dataset with per-part supervision, and evaluated across diverse benchmarks, ART achieves significant improvements over existing baselines and establishes a new state of the art for articulated object reconstruction from image inputs.

</details>


### [110] [VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image](https://arxiv.org/abs/2512.14677)
*Sicheng Xu,Guojun Chen,Jiaolong Yang,Yizhong Zhang,Yu Deng,Steve Lin,Baining Guo*

Main category: cs.CV

TL;DR: VASA-3D是一种音频驱动的单张图像3D头像生成方法，实现了高保真、真实感强的3D说话头像生成。


<details>
  <summary>Details</summary>
Motivation: 现实中利用单张人脸图片自动生成能随音频驱动作出细腻表情变化的3D头像具有很大挑战性，主要难点是细微表情捕捉与精细3D头像重建。

Method: 方法上，VASA-3D基于VASA-1模型的运动潜变量（motion latent），将2D里高度真实的表情转化为3D模型。通过一个以运动潜变量为条件的3D头部模型，以及结合自输入图片合成的多帧参考头部视频，采取优化框架，适应各种训练损失以增强模型对生成数据伪影和姿态覆盖有限的鲁棒性，实现对个体图像的自定义。

Result: 实验显示VASA-3D生成的3D说话头像比现有方法更加真实，并能在线实时生成512x512分辨率、最大75FPS的自由视角视频。

Conclusion: VASA-3D能够显著提升3D说话头像的真实感和交互性，为沉浸式3D虚拟人技术带来进步。

Abstract: We propose VASA-3D, an audio-driven, single-shot 3D head avatar generator. This research tackles two major challenges: capturing the subtle expression details present in real human faces, and reconstructing an intricate 3D head avatar from a single portrait image. To accurately model expression details, VASA-3D leverages the motion latent of VASA-1, a method that yields exceptional realism and vividness in 2D talking heads. A critical element of our work is translating this motion latent to 3D, which is accomplished by devising a 3D head model that is conditioned on the motion latent. Customization of this model to a single image is achieved through an optimization framework that employs numerous video frames of the reference head synthesized from the input image. The optimization takes various training losses robust to artifacts and limited pose coverage in the generated training data. Our experiment shows that VASA-3D produces realistic 3D talking heads that cannot be achieved by prior art, and it supports the online generation of 512x512 free-viewpoint videos at up to 75 FPS, facilitating more immersive engagements with lifelike 3D avatars.

</details>


### [111] [Native and Compact Structured Latents for 3D Generation](https://arxiv.org/abs/2512.14692)
*Jianfeng Xiang,Xiaoxue Chen,Sicheng Xu,Ruicheng Wang,Zelong Lv,Yu Deng,Hongyuan Zhu,Yue Dong,Hao Zhao,Nicholas Jing Yuan,Jiaolong Yang*

Main category: cs.CV

TL;DR: 提出了一种基于O-Voxel稀疏体素结构的新型3D生成模型方法，大幅提升了复杂拓扑和细致外观的建模能力。


<details>
  <summary>Details</summary>
Motivation: 当前3D生成建模虽已取得进展，但对于复杂拓扑、详细外观的资产表现仍受限于传统的3D表示方式。

Method: 引入O-Voxel（omni-voxel）稀疏体素表示法，将几何和外观属性（含PBR参数）统一编码。基于此结构，设计了Sparse Compression VAE，实现高空间压缩和紧凑潜空间；并利用4B参数的流匹配模型，在大规模3D数据集上训练。

Result: 新方法在推理效率极高的同时，生成资产的几何和材质质量显著优于现有模型。

Conclusion: O-Voxel及相关方法为三维生成建模领域带来重大进步。

Abstract: Recent advancements in 3D generative modeling have significantly improved the generation realism, yet the field is still hampered by existing representations, which struggle to capture assets with complex topologies and detailed appearance. This paper present an approach for learning a structured latent representation from native 3D data to address this challenge. At its core is a new sparse voxel structure called O-Voxel, an omni-voxel representation that encodes both geometry and appearance. O-Voxel can robustly model arbitrary topology, including open, non-manifold, and fully-enclosed surfaces, while capturing comprehensive surface attributes beyond texture color, such as physically-based rendering parameters. Based on O-Voxel, we design a Sparse Compression VAE which provides a high spatial compression rate and a compact latent space. We train large-scale flow-matching models comprising 4B parameters for 3D generation using diverse public 3D asset datasets. Despite their scale, inference remains highly efficient. Meanwhile, the geometry and material quality of our generated assets far exceed those of existing models. We believe our approach offers a significant advancement in 3D generative modeling.

</details>


### [112] [Spherical Leech Quantization for Visual Tokenization and Generation](https://arxiv.org/abs/2512.14697)
*Yue Zhao,Hanwen Jiang,Zhenlin Xu,Chutong Yang,Ehsan Adeli,Philipp Krähenbühl*

Main category: cs.CV

TL;DR: 本文提出了一种基于Leech格的量化方法（Spherical Leech Quantization, $\Lambda_{24}$-SQ），在图像分词与压缩任务中，在保留较低比特数的同时，相较于现有最佳方法（如BSQ）取得了更好的重构质量。


<details>
  <summary>Details</summary>
Motivation: 非参数量化方法因其参数高效与扩展性强而受关注，但现有方法如BSQ在训练自编码器时需辅助损失，且不同格编码方法的结构尚未系统统一。作者希望通过格编码视角统一这些方法，并发现更优的量化结构。

Method: 作者从格编码（lattice coding）的角度统一了不同的非参数量化方法，对比了随机格、广义斐波那契格、最密球堆积格等备选方案，并提出了基于高对称性Leech格的球面量化方法（$\Lambda_{24}$-SQ），以实现高效且均匀分布的量化编码。

Result: Leech格量化方法带来了简化的训练流程和更优的重构-压缩折中。在图像分词和压缩任务中，该方法在所有评测指标上优于BSQ，且所需比特略少。同时，该方法在最先进自回归图像生成框架中同样表现优异。

Conclusion: 本文提出的球面Leech格量化方法在提升重构质量、降低比特和简化训练方面取得突破，为非参数量化方法的发展提供了理论与实践的支持。

Abstract: Non-parametric quantization has received much attention due to its efficiency on parameters and scalability to a large codebook. In this paper, we present a unified formulation of different non-parametric quantization methods through the lens of lattice coding. The geometry of lattice codes explains the necessity of auxiliary loss terms when training auto-encoders with certain existing lookup-free quantization variants such as BSQ. As a step forward, we explore a few possible candidates, including random lattices, generalized Fibonacci lattices, and densest sphere packing lattices. Among all, we find the Leech lattice-based quantization method, which is dubbed as Spherical Leech Quantization ($Λ_{24}$-SQ), leads to both a simplified training recipe and an improved reconstruction-compression tradeoff thanks to its high symmetry and even distribution on the hypersphere. In image tokenization and compression tasks, this quantization approach achieves better reconstruction quality across all metrics than BSQ, the best prior art, while consuming slightly fewer bits. The improvement also extends to state-of-the-art auto-regressive image generation frameworks.

</details>


### [113] [MemFlow: Flowing Adaptive Memory for Consistent and Efficient Long Video Narratives](https://arxiv.org/abs/2512.14699)
*Sihui Ji,Xi Chen,Shuai Yang,Xin Tao,Pengfei Wan,Hengshuang Zhao*

Main category: cs.CV

TL;DR: MemFlow是一种用于流式视频生成的新方法，其通过动态检索与当前生成片段相关的历史帧来更新记忆库，从而提升长时内容一致性，同时保持高效生成。


<details>
  <summary>Details</summary>
Motivation: 流式视频生成面临着保持长上下文内容一致性的挑战，对记忆机制提出了很高的要求。现有方法通常通过固定策略压缩历史帧，但不同生成片段所需的历史信息可能不同，固定策略难以很好满足需要。

Method: 提出MemFlow方法：在生成新的视频片段前，根据该片段的文本提示从历史帧中检索出最相关的帧并动态更新记忆库。在生成过程中，每个查询仅激活记忆库中最相关的token进行注意力计算，提高效率。

Result: MemFlow在保证与无记忆方法近似的运算速度（仅慢7.9%）下，实现了优异的长时一致性表现，并可与任何支持KV cache的流式视频生成模型兼容。

Conclusion: MemFlow通过按需动态检索相关历史帧并高效管理内存，在提升流式视频生成一致性的同时保持了良好的效率和通用性。

Abstract: The core challenge for streaming video generation is maintaining the content consistency in long context, which poses high requirement for the memory design. Most existing solutions maintain the memory by compressing historical frames with predefined strategies. However, different to-generate video chunks should refer to different historical cues, which is hard to satisfy with fixed strategies. In this work, we propose MemFlow to address this problem. Specifically, before generating the coming chunk, we dynamically update the memory bank by retrieving the most relevant historical frames with the text prompt of this chunk. This design enables narrative coherence even if new event happens or scenario switches in future frames. In addition, during generation, we only activate the most relevant tokens in the memory bank for each query in the attention layers, which effectively guarantees the generation efficiency. In this way, MemFlow achieves outstanding long-context consistency with negligible computation burden (7.9% speed reduction compared with the memory-free baseline) and keeps the compatibility with any streaming video generation model with KV cache.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [114] [FiNERweb: Datasets and Artifacts for Scalable Multilingual Named Entity Recognition](https://arxiv.org/abs/2512.13884)
*Jonas Golde,Patrick Haller,Alan Akbik*

Main category: cs.CL

TL;DR: 该论文提出了FiNERweb，一个可扩展至91种语言和25种文字系统的多语言命名实体识别数据集构建管道，通过大模型生成标注，旨在为多语言NER任务提供高质量、可重用的数据资源。


<details>
  <summary>Details</summary>
Motivation: 当前多语言NER数据集多为实验副产品，缺乏系统性与重用性。为了高效推动教师-学生范式下的多语言NER研究，迫切需要一种能大规模生成高质量多语标注数据的方法。

Method: 利用FineWeb-Edu基础，先用回归模型筛选与NER相关的文本段落，再通过多语言LLM生成标注，最终生成约22.5万段标注数据和23.5万种不同类别标签。实验还用LLM评测了标注质量，并提供英文标签及对应目标语言标签集。

Result: 回归模型筛选段落的F1超过84。在英、泰、斯瓦希里等语种无监督迁移设置下，基于FiNERweb训练的模型即便只用1/19量级的数据，也有可比甚至更优的表现。同时，LLM评判的标注忠实度与完整度分别达3.99/5和4.05/5。标签用目标语时当前SOTA模型平均F1下降0.02至0.09。

Conclusion: FiNERweb能高效生成多语言、高质量NER数据，并能在节省数据量的前提下获得优异性能，对多语言NER系统的开发与研究具有重要价值。已公开全部数据及工具，促进领域发展。

Abstract: Recent multilingual named entity recognition (NER) work has shown that large language models (LLMs) can provide effective synthetic supervision, yet such datasets have mostly appeared as by-products of broader experiments rather than as systematic, reusable resources. We introduce FiNERweb, a dataset-creation pipeline that scales the teacher-student paradigm to 91 languages and 25 scripts. Building on FineWeb-Edu, our approach trains regression models to identify NER-relevant passages and annotates them with multilingual LLMs, resulting in about 225k passages with 235k distinct entity labels. Our experiments show that the regression model achieves more than 84 F1, and that models trained on FiNERweb obtain comparable or improved performance in zero shot transfer settings on English, Thai, and Swahili, despite being trained on 19x less data than strong baselines. In addition, we assess annotation quality using LLM-as-a-judge and observe consistently high scores for both faithfulness (3.99 out of 5) and completeness (4.05 out of 5), indicating reliable and informative annotations. Further, we release the dataset with both English labels and translated label sets in the respective target languages because we observe that the performance of current state-of-the-art models drops by 0.02 to 0.09 F1 when evaluated using target language labels instead of English ones. We release FiNERweb together with all accompanying artifacts to the research community in order to facilitate more effective student-teacher training for multilingual named entity recognition.

</details>


### [115] [Olmo 3](https://arxiv.org/abs/2512.13961)
*Team Olmo,:,Allyson Ettinger,Amanda Bertsch,Bailey Kuehl,David Graham,David Heineman,Dirk Groeneveld,Faeze Brahman,Finbarr Timbers,Hamish Ivison,Jacob Morrison,Jake Poznanski,Kyle Lo,Luca Soldaini,Matt Jordan,Mayee Chen,Michael Noukhovitch,Nathan Lambert,Pete Walsh,Pradeep Dasigi,Robert Berry,Saumya Malik,Saurabh Shah,Scott Geng,Shane Arora,Shashank Gupta,Taira Anderson,Teng Xiao,Tyler Murray,Tyler Romero,Victoria Graf,Akari Asai,Akshita Bhagia,Alexander Wettig,Alisa Liu,Aman Rangapur,Chloe Anastasiades,Costa Huang,Dustin Schwenk,Harsh Trivedi,Ian Magnusson,Jaron Lochner,Jiacheng Liu,Lester James V. Miranda,Maarten Sap,Malia Morgan,Michael Schmitz,Michal Guerquin,Michael Wilson,Regan Huff,Ronan Le Bras,Rui Xin,Rulin Shao,Sam Skjonsberg,Shannon Zejiang Shen,Shuyue Stella Li,Tucker Wilde,Valentina Pyatkin,Will Merrill,Yapei Chang,Yuling Gu,Zhiyuan Zeng,Ashish Sabharwal,Luke Zettlemoyer,Pang Wei Koh,Ali Farhadi,Noah A. Smith,Hannaneh Hajishirzi*

Main category: cs.CL

TL;DR: 本文介绍了Olmo 3系列开放语言模型，覆盖7B和32B参数规模，专注于长上下文推理、函数调用、代码、指令跟随等任务，数据与流程全部公开。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型的发展对高质量、完全公开的模型需求不断增长，尤其关注模型的透明度、复现性和广泛应用性。Olmo 3旨在填补全开源强大全面模型的空白。

Method: 作者构建了两个参数规模的Olmo 3模型，并在长上下文、多功能任务（如函数调用、代码、知识召回等）上进行专项优化，同时公布了从数据、训练到最终模型的全流程信息。

Result: Olmo 3模型在目标任务上达到最先进性能，旗舰版Think 32B表现尤为突出，被认为是迄今最强的完全开放的推理型语言模型。

Conclusion: Olmo 3模型不仅在性能上处于领先地位，还首次实现了全方面开放，推动了语言模型社区的透明、协作及创新。

Abstract: We introduce Olmo 3, a family of state-of-the-art, fully-open language models at the 7B and 32B parameter scales. Olmo 3 model construction targets long-context reasoning, function calling, coding, instruction following, general chat, and knowledge recall. This release includes the entire model flow, i.e., the full lifecycle of the family of models, including every stage, checkpoint, data point, and dependency used to build it. Our flagship model, Olmo 3 Think 32B, is the strongest fully-open thinking model released to-date.

</details>


### [116] [Structure-Aware Decoding Mechanisms for Complex Entity Extraction with Large-Scale Language Models](https://arxiv.org/abs/2512.13980)
*Zhimin Qiu,Di Wu,Feng Liu,Chenrui Hu,Yuxiao Wang*

Main category: cs.CL

TL;DR: 提出了一种结构感知解码方法，提升了大模型在嵌套和重叠实体抽取任务中的表现，显著提高了复杂场景下的识别准确率。


<details>
  <summary>Details</summary>
Motivation: 传统实体抽取方法很难同时保持语义完整性和结构一致性，尤其在嵌套和重叠实体抽取上表现不佳，因此需要更强的结构建模能力。

Method: 方法包括候选跨度生成机制、结构化注意力建模，结合预训练语言模型，提高多粒度实体边界、层级关系和跨依赖信息的捕获能力，并引入结构约束和联合优化损失，提升复杂条件下的稳定性。

Result: 在ACE 2005数据集上，方法在准确率、查准率、召回率和F1分数等指标上都有显著提升，尤其在嵌套和重叠实体识别中，展现出更强的边界定位和结构建模能力。

Conclusion: 结构感知解码在复杂语义信息抽取任务中效果显著，为具有层级理解能力的语言模型设计提供了新思路，为高精度信息抽取奠定了方法基础。

Abstract: This paper proposes a structure-aware decoding method based on large language models to address the difficulty of traditional approaches in maintaining both semantic integrity and structural consistency in nested and overlapping entity extraction tasks. The method introduces a candidate span generation mechanism and structured attention modeling to achieve unified modeling of entity boundaries, hierarchical relationships, and cross-dependencies. The model first uses a pretrained language model to obtain context-aware semantic representations, then captures multi-granular entity span features through candidate representation combinations, and introduces hierarchical structural constraints during decoding to ensure consistency between semantics and structure. To enhance stability in complex scenarios, the model jointly optimizes classification loss and structural consistency loss, maintaining high recognition accuracy under multi-entity co-occurrence and long-sentence dependency conditions. Experiments conducted on the ACE 2005 dataset demonstrate significant improvements in Accuracy, Precision, Recall, and F1-Score, particularly in nested and overlapping entity recognition, where the model shows stronger boundary localization and structural modeling capability. This study verifies the effectiveness of structure-aware decoding in complex semantic extraction tasks, provides a new perspective for developing language models with hierarchical understanding, and establishes a methodological foundation for high-precision information extraction.

</details>


### [117] [What Affects the Effective Depth of Large Language Models?](https://arxiv.org/abs/2512.14064)
*Yi Hu,Cai Zhou,Muhan Zhang*

Main category: cs.CL

TL;DR: 论文分析了大型语言模型（LLM）在扩展深度时层利用率的问题，发现深度增加带来的性能提升有限。系统性地研究了有效深度与模型规模、训练类型和任务难度的关系。结果显示当前LLM未能充分利用其所有层，提示有提升层利用率的研究空间。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的规模不断扩大，业界普遍通过增加层数来提升性能。但已有研究表明，模型很难充分利用所有新增的层，导致有效深度远小于实际深度。所以需要深入理解有效深度随不同因素变化的规律。

Method: 作者以Qwen-2.5系列模型（1.5B-32B）为对象，评估不同规模、训练范式（基础模型与长链思维扩展模型）及任务难度下的有效层数量和占比。系统性对比有效深度随这些因素的变化。

Result: 结果表明：随着模型规模增大，有效层数虽然增加，但占比基本不变；长链思维模型有效深度无增长，推理能力提升源自上下文扩展而非每token计算变深；在难度提升的任务中，模型并不会动态动用更多层。

Conclusion: 当前LLM未能充分利用其深度，无论是在规模扩展、训练方法还是难度变化的任务中都如此。这为提升层利用率、模型剪枝与提前退出等方向提供了新的研究机会。

Abstract: The scaling of large language models (LLMs) emphasizes increasing depth, yet performance gains diminish with added layers. Prior work introduces the concept of "effective depth", arguing that deeper models fail to fully utilize their layers for meaningful computation. Building on this, we systematically study how effective depth varies with model scale, training type, and task difficulty. First, we analyze the model behavior of Qwen-2.5 family (1.5B-32B) and find that while the number of effective layers grows with model size, the effective depth ratio remains stable. Besides, comparisons between base and corresponding long-CoT models show no increase in effective depth, suggesting that improved reasoning stems from longer context rather than deeper per-token computation. Furthermore, evaluations across tasks of varying difficulty indicate that models do not dynamically use more layers for harder problems. Our results suggest that current LLMs underuse available depth across scales, training paradigms and tasks of varying difficulties, pointing out research opportunities on increasing the layer utilization rate of LLMs, model pruning, and early exiting. Our code is released at https://github.com/AheadOFpotato/what_affects_effective_depth.

</details>


### [118] [Efficient-DLM: From Autoregressive to Diffusion Language Models, and Beyond in Speed](https://arxiv.org/abs/2512.14067)
*Yonggan Fu,Lexington Whalen,Zhifan Ye,Xin Dong,Shizhe Diao,Jingyu Liu,Chengyue Wu,Hao Zhang,Enze Xie,Song Han,Maksim Khadkevich,Jan Kautz,Yingyan Celine Lin,Pavlo Molchanov*

Main category: cs.CL

TL;DR: 本文提出了一种将预训练自回归（AR）语言模型高效转换为扩散语言模型（dLMs）的方法，实现了生成速度与准确性的双提升。


<details>
  <summary>Details</summary>
Motivation: 虽然扩散语言模型（dLMs）具有并行非自回归生成的优势，但从头训练效率不及自回归（AR）模型。因此，本文研究如何将高效预训练的AR模型转化为dLMs，以兼顾速度和任务准确性。

Method: 作者系统比较了不同注意力模式，发现保持预训练AR权重分布至关重要，并提出了块状注意力（block-wise）和连续预训练方案，在每个块内支持双向建模，块间保持因果结构。同时，提出基于位置的token掩码策略，加大训练后期token的掩码概率，更贴合测试实际。

Result: 高效转换方法（Efficient-DLM）能够更好保留AR模型特性，在准确性和效率上优于以往的AR与dLMs，例如Efficient-DLM 8B准确率分别比Dream 7B和Qwen3 4B高5.4%和2.7%，吞吐提升4.5倍和2.7倍。

Conclusion: 提出的AR到dLM高效转换方法能确保预训练权重有效迁移，提升扩散语言模型并行生成速度的同时，准确性也不逊于甚至超越主流AR和dLMs，为大规模高效语言模型转换提供了新思路和实践方案。

Abstract: Diffusion language models (dLMs) have emerged as a promising paradigm that enables parallel, non-autoregressive generation, but their learning efficiency lags behind that of autoregressive (AR) language models when trained from scratch. To this end, we study AR-to-dLM conversion to transform pretrained AR models into efficient dLMs that excel in speed while preserving AR models' task accuracy. We achieve this by identifying limitations in the attention patterns and objectives of existing AR-to-dLM methods and then proposing principles and methodologies for more effective AR-to-dLM conversion. Specifically, we first systematically compare different attention patterns and find that maintaining pretrained AR weight distributions is critical for effective AR-to-dLM conversion. As such, we introduce a continuous pretraining scheme with a block-wise attention pattern, which remains causal across blocks while enabling bidirectional modeling within each block. We find that this approach can better preserve pretrained AR models' weight distributions than fully bidirectional modeling, in addition to its known benefit of enabling KV caching, and leads to a win-win in accuracy and efficiency. Second, to mitigate the training-test gap in mask token distributions (uniform vs. highly left-to-right), we propose a position-dependent token masking strategy that assigns higher masking probabilities to later tokens during training to better mimic test-time behavior. Leveraging this framework, we conduct extensive studies of dLMs' attention patterns, training dynamics, and other design choices, providing actionable insights into scalable AR-to-dLM conversion. These studies lead to the Efficient-DLM family, which outperforms state-of-the-art AR models and dLMs, e.g., our Efficient-DLM 8B achieves +5.4%/+2.7% higher accuracy with 4.5x/2.7x higher throughput compared to Dream 7B and Qwen3 4B, respectively.

</details>


### [119] [A Unified Sparse Attention via Multi-Granularity Compression](https://arxiv.org/abs/2512.14082)
*Siran Liu,Zane Cao,Yongchao He*

Main category: cs.CL

TL;DR: 本文提出了UniSparse方法，通过引入复合token和多粒度压缩，实现了长文本中高效、统一的稀疏注意力机制，在准确率和推理速度上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏注意力方法存在训练成本高、难以插件化应用或推理效率低等问题，而长文本处理需求日益重要，需要一种兼具高效性、通用性和易部署的新方案。

Method: 作者提出UniSparse机制，核心是用复合token聚合多粒度上下文信息，并结合多粒度压缩与块级选择，在GPU上动态构建稀疏注意力，兼顾效率和多模态通用性。

Result: UniSparse在多种模态和任务上，相比最新稀疏注意力方法（如MInference、XAttention、FlexPrefill），在准确率上几乎与全量注意力持平（≥99%），在执行速度上最高比FlashAttention快2.61倍。

Conclusion: UniSparse提供了一种高效、硬件友好且易部署的长文本稀疏注意力方案，有望在多模态和复杂应用场景中推广应用。

Abstract: Efficient long-context understanding and reasoning are increasingly vital for large language model (LLM) applications such as multi-turn dialogue and program analysis. However, the core self-attention mechanism scales quadratically with sequence length, creating a fundamental computational bottleneck. Existing sparse attention methods alleviate this issue but face trade-offs: training-based methods are costly and cannot be directly applied as acceleration plugins for other models, while inference-time methods often compromise efficiency or cross-modal generality. To address these limitations, we present UniSparse, a unified mechanism that introduces the notion of composite tokens--compact representations that aggregate multi-granularity contextual information. Building on this abstraction, UniSparse dynamically constructs sparse attention through multi-granularity compression and block-level selection, enabling efficient and hardware-friendly execution on GPU. Across multiple modalities and tasks ranging from synthetic benchmarks to real-world applications, UniSparse consistently surpasses state-of-the-art sparse attention methods (e.g., MInference, XAttention, FlexPrefill) in both accuracy and efficiency, achieving $\ge$ 99% of full-attention accuracy and up to 2.61$\times$ faster attention computation than FlashAttention.

</details>


### [120] [Multilingual and Continuous Backchannel Prediction: A Cross-lingual Study](https://arxiv.org/abs/2512.14085)
*Koji Inoue,Mikey Elmers,Yahui Fu,Zi Haur Pang,Taiga Mori,Divesh Lala,Keiko Ochi,Tatsuya Kawahara*

Main category: cs.CL

TL;DR: 本文提出了一个基于Transformer的多语种持续性Backchannel（听话反应）预测模型，覆盖日语、英语和中文，并分析了不同语言下Backchannel时机的差异。模型性能优于单语基线，并揭示了语言间和语言内的显著区别。论文还实现了CPU实时推理，相关成果可为自然对话系统设计提供参考。


<details>
  <summary>Details</summary>
Motivation: 跨语言对话系统需理解和生成符合文化和语言习惯的Backchannel。现有研究多关注单语，缺少统一模型比较多语言间的差异，因此本研究旨在提出统一框架，揭示多语言在对话中Backchannel时机的共性与个性。

Method: 作者提出了基于Transformer的多语种持续性Backchannel预测模型，模型以帧为单位，融合辅助任务共同训练，训练数据涵盖三种语言共约300小时的双人对话。通过消融实验、扰动分析和上下文长度实验，进一步剖析模型在语言间的表现及其依赖的语音线索。

Result: 多语种模型总体表现优于或持平于单语模型，展现出能够同时学习语言共性和个性特征。不同语言依赖不同的提示线索，如日语倾向于短时语言线索，英语和中文更依赖静默时长和韵律变化；多语种训练有助于泛化和减少对单一特征（如音高）的过度依赖。中文对更长上下文尤为敏感，日语表现较为稳健。

Conclusion: 本文展示了一个可以同时适应多语言的Backchannel时机预测模型，并系统揭示了日语、英语、中文间的行为差异。相关分析为跨文化自然对话系统的设计提供了重要实证支持。

Abstract: We present a multilingual, continuous backchannel prediction model for Japanese, English, and Chinese, and use it to investigate cross-linguistic timing behavior. The model is Transformer-based and operates at the frame level, jointly trained with auxiliary tasks on approximately 300 hours of dyadic conversations. Across all three languages, the multilingual model matches or surpasses monolingual baselines, indicating that it learns both language-universal cues and language-specific timing patterns. Zero-shot transfer with two-language training remains limited, underscoring substantive cross-lingual differences. Perturbation analyses reveal distinct cue usage: Japanese relies more on short-term linguistic information, whereas English and Chinese are more sensitive to silence duration and prosodic variation; multilingual training encourages shared yet adaptable representations and reduces overreliance on pitch in Chinese. A context-length study further shows that Japanese is relatively robust to shorter contexts, while Chinese benefits markedly from longer contexts. Finally, we integrate the trained model into a real-time processing software, demonstrating CPU-only inference. Together, these findings provide a unified model and empirical evidence for how backchannel timing differs across languages, informing the design of more natural, culturally-aware spoken dialogue systems.

</details>


### [121] [CogMem: A Cognitive Memory Architecture for Sustained Multi-Turn Reasoning in Large Language Models](https://arxiv.org/abs/2512.14118)
*Yiran Zhang,Jincheng Hu,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: LLMs在多轮对话中表现不稳定，CogMem提出用类人认知记忆结构提升持续性推理表现。


<details>
  <summary>Details</summary>
Motivation: 目前LLMs多轮交互时易出现推理失误、记忆衰减等问题，且历史拼接导致上下文膨胀和效率下降。作者希望通过结构性记忆改进LLMs的多轮推理能力。

Method: 提出CogMem架构，融合三层记忆：长期记忆（LTM）整合跨会话推理策略，直接访问记忆（DA）存储会话级笔记并检索相关长期记忆，注意焦点（FoA）机制动态重建每轮简明上下文。

Result: 在TurnBench基准测试上，CogMem能够缓解推理失败，控制上下文增长，提升推理一致性。

Conclusion: CogMem有助于提升LLMs在复杂多轮推理中的可靠性，实现更接近人类的持续推理能力。

Abstract: Large language models (LLMs) excel at single-turn reasoning but often lose accuracy and coherence over extended, multi-turn interactions. Recent evaluations such as TurnBench highlight recurring failure modes-reasoning bias, task drift, hallucination, overconfidence, and memory decay. Current approaches typically append full conversational histories, causing unbounded context growth, higher computational costs, and degraded reasoning efficiency. We introduce CogMem, a cognitively inspired, memory-augmented LLM architecture that supports sustained iterative reasoning through structured, persistent memory. CogMem incorporates three layers: a Long-Term Memory (LTM) that consolidates cross-session reasoning strategies; a Direct Access (DA) memory that maintains session-level notes and retrieves relevant long-term memories; and a Focus of Attention (FoA) mechanism that dynamically reconstructs concise, task-relevant context at each turn. Experiments on TurnBench show that this layered design mitigates reasoning failures, controls context growth, and improves consistency across extended reasoning chains, moving toward more reliable, human-like reasoning in LLMs.

</details>


### [122] [Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents](https://arxiv.org/abs/2512.14142)
*Hongqiu Ni,Jiabao Zhang,Guopeng Li,Zilong Wang,Ruiqi Wu,Chi Zhang,Haisheng Tan*

Main category: cs.CL

TL;DR: Astraea系统通过全局生命周期调度优化，显著减少了大模型代理执行端到端时延。


<details>
  <summary>Details</summary>
Motivation: 现有推理系统只针对局部推理阶段优化，无法有效降低大语言模型（LLM）多阶段、涉及外部服务调用的代理工作流的整体时延（JCT）。

Method: 提出Astraea服务引擎，将优化重心转向全局请求管理，采用状态感知的分层调度算法，结合历史状态和未来预测，并动态区分I/O和计算密集型请求，利用增强型HRRN策略实现高效与公平。此外，引入自适应KV缓存管理器，调整I/O等待期间的状态处理以适应系统内存压力。

Result: 实验表明，Astraea在各种模型规模和高负载下具备良好稳定性和鲁棒性，平均作业完成时间（JCT）可比基线系统降低最多25.5%。

Conclusion: Astraea有效提升了大语言模型代理系统在复杂多阶段任务场景下的整体效率和鲁棒性，并为后续相关系统优化提供了新思路。

Abstract: Large Language Models (LLMs) are increasingly being deployed as intelligent agents. Their multi-stage workflows, which alternate between local computation and calls to external network services like Web APIs, introduce a mismatch in their execution pattern and the scheduling granularity of existing inference systems such as vLLM. Existing systems typically focus on per-segment optimization which prevents them from minimizing the end-to-end latency of the complete agentic workflow, i.e., the global Job Completion Time (JCT) over the entire request lifecycle. To address this limitation, we propose Astraea, a service engine designed to shift the optimization from local segments to the global request lifecycle. Astraea employs a state-aware, hierarchical scheduling algorithm that integrates a request's historical state with future predictions. It dynamically classifies requests by their I/O and compute intensive nature and uses an enhanced HRRN policy to balance efficiency and fairness. Astraea also implements an adaptive KV cache manager that intelligently handles the agent state during I/O waits based on the system memory pressure. Extensive experiments show that Astraea reduces average JCT by up to 25.5\% compared to baseline methods. Moreover, our approach demonstrates strong robustness and stability under high load across various model scales.

</details>


### [123] [A Comparative Analysis of Retrieval-Augmented Generation Techniques for Bengali Standard-to-Dialect Machine Translation Using LLMs](https://arxiv.org/abs/2512.14179)
*K. M. Jubair Sami,Dipto Sumit,Ariyan Hossain,Farig Sadeque*

Main category: cs.CL

TL;DR: 本文提出并对比了两种新型RAG管道，用于标准孟加拉语到方言的翻译，发现基于句对的管道效果更好，有效降低了关键指标的误差率，并使小模型优于大模型。


<details>
  <summary>Details</summary>
Motivation: 标准语到方言的翻译因数据稀缺和语言变化大而困难，尤其在孟加拉语中更为突出。当前缺乏成熟的、低资源下有效的方言翻译方法，对语言多样性的保护也亟待解决。

Method: 论文提出两种RAG（Retrieval-Augmented Generation）管道：一种以音频转录本的大量方言句子为上下文（转录本管道），另一种采用结构化的“方言-标准语”句对（句对管道）。分别在六种孟加拉语方言和多种大语言模型（LLMs）上进行评测。

Result: 句对管道在所有评测中均优于转录本管道。例如，对Chittagong方言，词错误率(WER)从76%降到55%。此外，使用该管道的小型模型（如Llama-3.1-8B）能超过更大型模型（如GPT-OSS-120B）。

Conclusion: 基于检索增强生成的句对管道为低资源方言翻译提供了无需微调、效果优异的解决方案，为语言多样性保护和实际应用提供了有效蓝本。

Abstract: Translating from a standard language to its regional dialects is a significant NLP challenge due to scarce data and linguistic variation, a problem prominent in the Bengali language. This paper proposes and compares two novel RAG pipelines for standard-to-dialectal Bengali translation. The first, a Transcript-Based Pipeline, uses large dialect sentence contexts from audio transcripts. The second, a more effective Standardized Sentence-Pairs Pipeline, utilizes structured local\_dialect:standard\_bengali sentence pairs. We evaluated both pipelines across six Bengali dialects and multiple LLMs using BLEU, ChrF, WER, and BERTScore. Our findings show that the sentence-pair pipeline consistently outperforms the transcript-based one, reducing Word Error Rate (WER) from 76\% to 55\% for the Chittagong dialect. Critically, this RAG approach enables smaller models (e.g., Llama-3.1-8B) to outperform much larger models (e.g., GPT-OSS-120B), demonstrating that a well-designed retrieval strategy can be more crucial than model size. This work contributes an effective, fine-tuning-free solution for low-resource dialect translation, offering a practical blueprint for preserving linguistic diversity.

</details>


### [124] [Ladder Up, Memory Down: Low-Cost Fine-Tuning With Side Nets](https://arxiv.org/abs/2512.14237)
*Estelle Zheng,Nathan Cerisara,Sébastien Warichet,Emmanuel Helbert,Christophe Cerisara*

Main category: cs.CL

TL;DR: 本文提出Ladder Side Tuning（LST）作为参数高效微调大模型的新方法，可大幅降低显存消耗，并兼具较高准确率和良好扩展性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的微调受限于GPU显存，主流的PEFT方法如QLoRA虽能减少可训练参数但显存消耗仍高。研究希望找到既省显存又高性能的PEFT新方案。

Method: 重审罕见使用的Ladder Side Tuning（LST），在主网络旁加轻量侧网络，实现高效微调。并进一步提出xLadder，通过跨层连接提升模型深度和推理能力，且不增加参数总量。

Result: 实验表明：与QLoRA相比，LST于多类任务（理解、数学、模型评价）中平均表现接近但显存消耗降低约50%。且在单块12GB消费级GPU上即可微调70亿参数大模型，无需梯度检查点。还发现LST与QLoRA同样具备良好可扩展性。xLadder则进一步提升了深度推理能力。

Conclusion: Ladder Side Tuning在显存受限时尤具优势，允许在常规GPU设备上处理大语境微调任务，并通过xLadder实现更深层推理，这为资源受限下的大模型应用打开新路。

Abstract: Fine-tuning large language models (LLMs) is often limited by the memory available on commodity GPUs. Parameter-efficient fine-tuning (PEFT) methods such as QLoRA reduce the number of trainable parameters, yet still incur high memory usage induced by the backward pass in the full model. We revisit Ladder Side Tuning (LST), a rarely explored PEFT technique that adds a lightweight side network, and show that it matches QLoRA's compute scaling slope while cutting peak memory by 50\%. Across different downstream benchmarks spanning natural language understanding, mathematical and LLM-critic tasks, LST has competitive performance with QLoRA's accuracy on average while being much more memory-efficient. This efficiency enables fine-tuning of 7B-parameter models on a single 12 GB consumer GPU with 2k-token contexts, requiring no gradient checkpointing\textemdash conditions under which QLoRA exhausts memory. Beyond memory efficiency, we also establish scaling laws showing that LST scales similarly to QLoRA. We exploit Ladder's architectural flexibility by introducing xLadder, a depth-extended variant that increases effective depth via cross-connections and shortens chain-of-thought (CoT) at fixed parameter count. Ladder is strong when memory is the bottleneck; xLadder builds on this by enabling deeper reasoning without additional memory overhead.

</details>


### [125] [Two CFG Nahuatl for automatic corpora expansion](https://arxiv.org/abs/2512.14239)
*Juan-José Guzmán-Landa,Juan-Manuel Torres-Moreno,Miguel Figueroa-Saavedra,Ligia Quintana-Torres,Graham Ranger Martha-Lorena Avendaño-Garrido*

Main category: cs.CL

TL;DR: 本文提出了两种用于Nawatl语料扩展的无上下文文法(CFG)，以解决Nawatl语言数字资源极其匮乏的问题，并通过生成合成句子提高对句子语义相似任务的表现。


<details>
  <summary>Details</summary>
Motivation: Nawatl作为墨西哥的国家语言之一，面临数字化资源极少、缺乏训练大型语言模型（LLM）所需语料的难题，需要通过技术手段扩展其可用语料。

Method: 作者提出了两种新颖的Nawatl语言无上下文文法（CFG），用于自动生成大量语法正确的Nawatl句子，实现语料扩充，并利用扩充后的语料学习词嵌入，最后在句子语义相似性任务中进行评估。

Result: 经过语料扩展和词嵌入训练后，Nawatl在句子语义相似性任务上的表现有明显提升，且简单的词嵌入方法有时甚至优于某些LLM。

Conclusion: 采用CFG自动生成合成Nawatl句子能显著扩展小语种语料，提高嵌入学习与下游任务效果，为资源匮乏语言的自然语言处理提供了有效路径。

Abstract: The aim of this article is to introduce two Context-Free Grammars (CFG) for Nawatl Corpora expansion. Nawatl is an Amerindian language (it is a National Language of Mexico) of the $π$-language type, i.e. a language with few digital resources. For this reason the corpora available for the learning of Large Language Models (LLMs) are virtually non-existent, posing a significant challenge. The goal is to produce a substantial number of syntactically valid artificial Nawatl sentences and thereby to expand the corpora for the purpose of learning non contextual embeddings. For this objective, we introduce two new Nawatl CFGs and use them in generative mode. Using these grammars, it is possible to expand Nawatl corpus significantly and subsequently to use it to learn embeddings and to evaluate their relevance in a sentences semantic similarity task. The results show an improvement compared to the results obtained using only the original corpus without artificial expansion, and also demonstrate that economic embeddings often perform better than some LLMs.

</details>


### [126] [From Context to EDUs: Faithful and Structured Context Compression via Elementary Discourse Unit Decomposition](https://arxiv.org/abs/2512.14244)
*Yiqing Zhou,Yu Lei,Shuzheng Si,Qingyan Sun,Wei Wang,Yifei Wu,Hao Wen,Gang Chen,Fanchao Qi,Maosong Sun*

Main category: cs.CL

TL;DR: 本文提出了一种新的基于EDU（Elementary Discourse Units）的上下文压缩方法，能够提升大型语言模型处理长文本的效率与效果。


<details>
  <summary>Details</summary>
Motivation: 现有的上文压缩方法要么通过直接删除token破坏了文本的连贯性，要么依赖隐式的潜在编码方式，导致位置偏置和与私有API不兼容，因此需要一种兼顾结构理解和细节保留的新方案。

Method: 作者设计了EDU-based Context Compressor，核心流程为“结构分析-再筛选（structure-then-select）”：先用LingoEDU将文本转换为结构化的关系树，再用高效排序模块挑选与查询相关的子结构进行线性化，且所有EDU都和原文索引严格对应，避免了生成幻觉。此外，还发布了结构化理解评测数据集StructBench。

Result: 实验表明，所提方法在结构预测准确率上达到SOTA水平，优于先进LLM，在成本降低的同时，压缩后内容对下游各类长文本任务和复杂深度搜索均有较大提升。

Conclusion: EDU-based上下文压缩方法兼顾了全局结构与细粒度信息，既提升了长文本任务的效果，也提升了执行效率，为结构感知的文本压缩提供了新思路。

Abstract: Managing extensive context remains a critical bottleneck for Large Language Models (LLMs), particularly in applications like long-document question answering and autonomous agents where lengthy inputs incur high computational costs and introduce noise. Existing compression techniques often disrupt local coherence through discrete token removal or rely on implicit latent encoding that suffers from positional bias and incompatibility with closed-source APIs. To address these limitations, we introduce the EDU-based Context Compressor, a novel explicit compression framework designed to preserve both global structure and fine-grained details. Our approach reformulates context compression as a structure-then-select process. First, our LingoEDU transforms linear text into a structural relation tree of Elementary Discourse Units (EDUs) which are anchored strictly to source indices to eliminate hallucination. Second, a lightweight ranking module selects query-relevant sub-trees for linearization. To rigorously evaluate structural understanding, we release StructBench, a manually annotated dataset of 248 diverse documents. Empirical results demonstrate that our method achieves state-of-the-art structural prediction accuracy and significantly outperforms frontier LLMs while reducing costs. Furthermore, our structure-aware compression substantially enhances performance across downstream tasks ranging from long-context tasks to complex Deep Search scenarios.

</details>


### [127] [Inflation Attitudes of Large Language Models](https://arxiv.org/abs/2512.14306)
*Nikoleta Anesti,Edward Hill,Andreas Joseph*

Main category: cs.CL

TL;DR: 本文研究大语言模型（LLM），特别是GPT-3.5-turbo，在基于宏观经济价格信号形成通胀感知和预期方面的能力，并将其输出与家庭调查数据和官方统计进行比较。


<details>
  <summary>Details</summary>
Motivation: 通胀感知和预期对宏观经济政策和公众行为有重大影响，而LLM是否能有效模拟人类在经济调查中的反应仍不清楚。本研究旨在评估LLM在社会科学中模拟人类反应的适用性与局限。

Method: 采用准实验设计，利用GPT-3.5-turbo的训练截止时间为2021年9月，避开了之后的通胀冲击。同时模拟英格兰银行通胀态度调查的受访者特征及信息集，通过Shapley值分解分析LLM输出，探索其对提示内容的敏感性与决策驱动。

Result: GPT在短期内能够较好地追踪总体调查预测和官方统计数据。在分群体层面上，GPT能复现家庭通胀感知的主要经验规律，特别在收入、住房和社会阶层方面表现突出。此外，GPT对食品通胀信息的敏感性与人类类似，但缺乏一致的消费者价格通胀内部模型。

Conclusion: 尽管GPT在某些方面模拟了人类的通胀预期反应，但整体上缺乏一致和深入的价格形成理解。该方法有助于评估LLM在社会科学中的表现，并推广至模型比较和调查设计等领域。

Abstract: This paper investigates the ability of Large Language Models (LLMs), specifically GPT-3.5-turbo (GPT), to form inflation perceptions and expectations based on macroeconomic price signals. We compare the LLM's output to household survey data and official statistics, mimicking the information set and demographic characteristics of the Bank of England's Inflation Attitudes Survey (IAS). Our quasi-experimental design exploits the timing of GPT's training cut-off in September 2021 which means it has no knowledge of the subsequent UK inflation surge. We find that GPT tracks aggregate survey projections and official statistics at short horizons. At a disaggregated level, GPT replicates key empirical regularities of households' inflation perceptions, particularly for income, housing tenure, and social class. A novel Shapley value decomposition of LLM outputs suited for the synthetic survey setting provides well-defined insights into the drivers of model outputs linked to prompt content. We find that GPT demonstrates a heightened sensitivity to food inflation information similar to that of human respondents. However, we also find that it lacks a consistent model of consumer price inflation. More generally, our approach could be used to evaluate the behaviour of LLMs for use in the social sciences, to compare different models, or to assist in survey design.

</details>


### [128] [Step-Tagging: Toward controlling the generation of Language Reasoning Models through step monitoring](https://arxiv.org/abs/2512.14332)
*Yannis Belkhiter,Seshu Tirupathi,Giulio Zizzo,John D. Kelleher*

Main category: cs.CL

TL;DR: 作者提出了一种名为Step-Tagging的轻量级框架，可以实时标注大型语言推理模型在生成推理步骤时的类型。通过在线监测推理步骤数，可以早停模型不必要的生成，减少计算资源消耗，同时保持准确率。该方法在多个常用数据集和任务中验证有效，节省了20%-50%的生成token。


<details>
  <summary>Details</summary>
Motivation: 尽管语言推理模型（LRMs）在推理能力上有很大提升，但在推理过程中仍存在效率低下、过度生成冗余验证和反思步骤的问题。因此，需要一种方法更好地控制模型推理过程，提升推理效率。

Method: 提出Step-Tagging框架，用于实时地对语言模型生成的每一句话或推理步骤进行分类打标签。定义了ReasonType推理步骤分类体系，用于追踪分析推理行为。通过对一定类型推理步骤数量进行在线监测，作为提前终止推理的依据。

Result: 在MATH500、GSM8K、AIME等数学推理数据集及GPQA、MMLU-Pro等非数学任务上进行了实验。结果显示，在保持准确率的前提下，平均减少了20%-50%的token数量，尤其在计算量较大的任务中效果最明显。

Conclusion: Step-Tagging提供了一种提升语言推理模型生成过程控制力的新方法，同时也是研究推理模型行为的新工具。该框架能有效提升推理效率，并为理解和改进大型语言模型推理过程提供了参考。

Abstract: The field of Language Reasoning Models (LRMs) has been very active over the past few years with advances in training and inference techniques enabling LRMs to reason longer, and more accurately. However, a growing body of studies show that LRMs are still inefficient, over-generating verification and reflection steps. To address this challenge, we introduce the Step-Tagging framework, a lightweight sentence-classifier enabling real-time annotation of the type of reasoning steps that an LRM is generating. To monitor reasoning behaviors, we introduced ReasonType: a novel taxonomy of reasoning steps. Building on this framework, we demonstrated that online monitoring of the count of specific steps can produce effective interpretable early stopping criteria of LRM inferences. We evaluate the Step-tagging framework on three open-source reasoning models across standard benchmark datasets: MATH500, GSM8K, AIME and non-mathematical tasks (GPQA and MMLU-Pro). We achieve 20 to 50\% token reduction while maintaining comparable accuracy to standard generation, with largest gains observed on more computation-heavy tasks. This work offers a novel way to increase control over the generation of LRMs, and a new tool to study behaviors of LRMs.

</details>


### [129] [Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models](https://arxiv.org/abs/2512.14427)
*Gabriele Prato,Shagun Sodhani,Alessandro Sordoni,Sarath Chandar*

Main category: cs.CL

TL;DR: 研究探讨了训练大语言模型时文档打包方式对模型能力的影响，发现合理打包有助于提升推理能力。


<details>
  <summary>Details</summary>
Motivation: 目前在训练大语言模型时通常会将多个文档打包以提高计算效率，但这种做法对模型能力的具体影响还不清楚。

Method: 通过对比不同文档打包策略对模型潜在多跳推理能力的影响，并且进行消融实验分析打包带来的优势的关键要素。

Result: 文档打包训练能够提升模型的表现，尤其是在推理能力方面，但同时会增加计算资源消耗。

Conclusion: 合理运用文档打包策略有助于优化大语言模型的训练效果，并为实际训练提供了优化建议。

Abstract: The standard practice for training large language models involves packing multiple documents together to optimize computational efficiency. However, the impact of this process on the models' capabilities remains largely unexplored. To address this gap, we investigate how different document-packing strategies influence the latent multi-hop reasoning abilities of LLMs. Our findings indicate that packing can improve model performance compared to training on individual documents, at the expense of more compute. To further understand the underlying mechanisms, we conduct an ablation study, identifying key factors that explain the advantages of packing. Ultimately, our research deepens the understanding of LLM training dynamics and provides practical insights for optimizing model development.

</details>


### [130] [SASQ: Static Activation Scaling for Quantization-Aware Training in Large Language Models](https://arxiv.org/abs/2512.14481)
*Shizhuo Mao,Song Chen,Yi Kang*

Main category: cs.CL

TL;DR: 本论文提出了SASQ，一种专注于激活值量化因子的轻量级量化感知训练（QAT）框架，有效在不改变预训练权重的情况下提升模型推理精度，并显著优于现有主流量化方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）因模型参数庞大，难以直接部署在GPU或边缘设备上。现有的量化方法在准确率和部署效率之间存在权衡，且QAT方法成本较高，因此需要设计一种能保持高精度、提高部署效率、训练成本更低的新型量化方法。

Method: 提出SASQ框架，仅优化激活值的量化因子，不更新权重，使训练成本低、部署高效。SASQ还通过自适应剪裁部分激活异常值，降低量化难度并保持激活分布特性，从而提升量化性能。

Result: 在LLaMA2-7B模型和WikiText2数据集上，SASQ比QuaRot低5.2%的perplexity，比FP16低4.7%的perplexity，精度和部署效率均优于主流方法。

Conclusion: SASQ有效克服了传统量化带来的损失和部署难题，在无需权重训练的前提下实现了高效且高精度的模型部署，适合用于大语言模型的实际部署场景。

Abstract: Large language models (LLMs) excel at natural language tasks but face deployment challenges due to their growing size outpacing GPU memory advancements. Model quantization mitigates this issue by lowering weight and activation precision, but existing solutions face fundamental trade-offs: dynamic quantization incurs high computational overhead and poses deployment challenges on edge devices, while static quantization sacrifices accuracy. Existing approaches of quantization-aware training (QAT) further suffer from weight training costs. We propose SASQ: a lightweight QAT framework specifically tailored for activation quantization factors. SASQ exclusively optimizes only the quantization factors (without changing pre-trained weights), enabling static inference with high accuracy while maintaining deployment efficiency. SASQ adaptively truncates some outliers, thereby reducing the difficulty of quantization while preserving the distributional characteristics of the activations. SASQ not only surpasses existing SOTA quantization schemes but also outperforms the corresponding FP16 models. On LLaMA2-7B, it achieves 5.2% lower perplexity than QuaRot and 4.7% lower perplexity than the FP16 model on WikiText2.

</details>


### [131] [C-ing Clearly: Enhanced Binary Code Explanations using C code](https://arxiv.org/abs/2512.14500)
*Teodor Poncu,Ioana Pintilie,Marius Dragoi,Dragos Tantaru,Florin Brad*

Main category: cs.CL

TL;DR: 本文提出一种名为C-ing Clearly的合成数据生成方法，通过利用对应的C代码增强大语言模型对汇编语言的理解，并通过微调提升其在二进制代码摘要和漏洞检测任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）在处理高级编程语言时表现优异，但在处理低级编程语言（如汇编）时能力较弱。因此，研究人员希望提升LLMs在汇编相关任务（如代码摘要与漏洞检测）上的表现。

Method: 作者提出了C-ing Clearly方法，通过利用现有的C代码与其对应的汇编代码自动生成训练数据，并以此对LLM进行微调。该方法使模型能够更好地联结高级与低级代码语义，从而增强对汇编的理解能力。

Result: 在对不同家族和不同规模的LLM进行实验后，基于C-ing Clearly方法生成的数据微调后的模型在二进制代码摘要和漏洞检测任务中均获得了稳定提升。

Conclusion: 通过引入C代码辅助的汇编理解强化训练，可以显著提升LLMs在汇编相关代码理解任务上的效果，且方法对不同模型及规模均有效。

Abstract: Large Language Models (LLMs) typically excel at coding tasks involving high-level programming languages, as opposed to lower-level programming languages, such as assembly. We propose a synthetic data generation method named C-ing Clearly, which leverages the corresponding C code to enhance an LLM's understanding of assembly. By fine-tuning on data generated through our method, we demonstrate improved LLM performance for binary code summarization and vulnerability detection. Our approach demonstrates consistent gains across different LLM families and model sizes.

</details>


### [132] [Linguists should learn to love speech-based deep learning models](https://arxiv.org/abs/2512.14506)
*Marianne de Heer Kloots,Paul Boersma,Willem Zuidema*

Main category: cs.CL

TL;DR: 该文认为单纯基于文本的LLM限制了与语言学的结合，建议引入音频模型以拓展研究。


<details>
  <summary>Details</summary>
Motivation: 许多关于人类语言的重要问题无法仅通过书面文本解决，因此需要新的模型来弥补这些不足。

Method: 提出将音频为基础的深度学习模型纳入语言学与AI结合研究的视野，用以补充并扩展文本LLM的应用范围。

Result: 指出当前文本LLM无法涵盖全部语言现象，拓展音频模型能够涵盖更多语言属性。

Conclusion: 未来深度学习语言模型的研究应将音频模型纳入，以获得对人类语言更全面的理解。

Abstract: Futrell and Mahowald present a useful framework bridging technology-oriented deep learning systems and explanation-oriented linguistic theories. Unfortunately, the target article's focus on generative text-based LLMs fundamentally limits fruitful interactions with linguistics, as many interesting questions on human language fall outside what is captured by written text. We argue that audio-based deep learning models can and should play a crucial role.

</details>


### [133] [VersatileFFN: Achieving Parameter Efficiency in LLMs via Adaptive Wide-and-Deep Reuse](https://arxiv.org/abs/2512.14531)
*Ying Nie,Kai Han,Hongguang Li,Hang Zhou,Tianyu Guo,Enhua Wu,Xinghao Chen,Yunhe Wang*

Main category: cs.CL

TL;DR: 本文提出了一种名为VersatileFFN的新型前馈网络架构，在固定参数预算下实现参数在宽度和深度维度的高效复用，从而在不增加内存消耗的前提下提升大模型性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）虽然性能卓越，扩展时却导致巨大的内存消耗，现有的压缩技术如剪枝、量化仅在原有模型架构内压缩参数，无法突破模型表达能力的上限。

Method: 受双过程认知理论启发，VersatileFFN 设计了两个自适应通路：1）宽度自适应通路通过共享FFN生成多个子专家，实现类似稀疏专家路由；2）深度自适应通路通过递归使用同一个FFN模拟更深层次计算；难度感知门控机制根据输入token难易程度动态分配两条路径。同时，两路径完全共享参数，新增容量来源于计算而非内存。

Result: 在多项基准测试和不同规模模型上实验证明，VersatileFFN方法能够在不增加参数数量的情况下显著提升模型性能。

Conclusion: VersatileFFN为参数高效利用提供了新思路，突破了LLM在固定参数预算下的表达能力瓶颈，对大模型高效扩展具有实际意义。代码已开源。

Abstract: The rapid scaling of Large Language Models (LLMs) has achieved remarkable performance, but it also leads to prohibitive memory costs. Existing parameter-efficient approaches such as pruning and quantization mainly compress pretrained models without enhancing architectural capacity, thereby hitting the representational ceiling of the base model. In this work, we propose VersatileFFN, a novel feed-forward network (FFN) that enables flexible reuse of parameters in both width and depth dimensions within a fixed parameter budget. Inspired by the dual-process theory of cognition, VersatileFFN comprises two adaptive pathways: a width-versatile path that generates a mixture of sub-experts from a single shared FFN, mimicking sparse expert routing without increasing parameters, and a depth-versatile path that recursively applies the same FFN to emulate deeper processing for complex tokens. A difficulty-aware gating dynamically balances the two pathways, steering "easy" tokens through the efficient width-wise route and allocating deeper iterative refinement to "hard" tokens. Crucially, both pathways reuse the same parameters, so all additional capacity comes from computation rather than memory. Experiments across diverse benchmarks and model scales demonstrate the effectiveness of the method. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/VersatileFFN.

</details>


### [134] [Dual Language Models: Balancing Training Efficiency and Overfitting Resilience](https://arxiv.org/abs/2512.14549)
*David Samuel,Lucas Georges Gabriel Charpentier*

Main category: cs.CL

TL;DR: 本文提出了一种同时结合自回归和掩码扩散训练目标、无需网络结构修改即可提升语言模型性能的方法，并通过实验证明该方法优于单一训练目标的模型。


<details>
  <summary>Details</summary>
Motivation: 自回归模型训练高效但易过拟合，掩码扩散模型抗过拟合但训练效率低。如何权衡两者的优缺点、提升整体性能是动机所在。

Method: 在无需网络结构更改的前提下，设定不同比率同时结合自回归与掩码扩散两个训练目标，训练并评估50个语言模型，测试不同数据重复度下的表现，进一步探索最优目标比例。

Result: 实验证明：无论在不同数据重复度下，联合训练始终优于单一目标，且针对自回归或掩码扩散任务时，最佳目标比率均相近。

Conclusion: 双目标联合训练可取得自回归与掩码扩散的优势（高效性及抗过拟合），为语言模型训练提供了一条新的高效性能途径。

Abstract: This paper combines autoregressive and masked-diffusion training objectives without any architectural modifications, resulting in flexible language models that outperform single-objective models. Autoregressive modeling has been a popular approach, partly because of its training efficiency; however, that comes at the cost of sensitivity to overfitting. On the other hand, masked-diffusion models are less efficient to train while being more resilient to overfitting. In this work, we demonstrate that dual-objective training achieves the best of both worlds. To derive the optimal ratio between both objectives, we train and evaluate 50 language models under varying levels of data repetition. We show that it is optimal to combine both objectives under all evaluated settings and that the optimal ratio is similar whether targeting autoregressive or masked-diffusion downstream performance.

</details>


### [135] [VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models](https://arxiv.org/abs/2512.14554)
*Nguyen Tien Dong,Minh-Anh Nguyen,Thanh Dat Hoang,Nguyen Tuan Ngoc,Dao Xuan Quang Minh,Phan Phi Hai,Nguyen Thi Ngoc Anh,Dang Van Tu,Binh Vu*

Main category: cs.CL

TL;DR: 本文提出了VLegal-Bench，这是一个系统评估大语言模型（LLM）在越南法律领域任务表现的基准数据集。该基准涵盖多层次法学理解任务，数据由法律专家标注，严格校验，为LLM在越南法律场景下的应用和发展提供评测基础。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在多个领域已经表现突出，但越南法律体系的复杂性、层级性和频繁变化对LLM的法律知识理解提出独特挑战。目前缺乏用于评估LLM在应对越南法律任务时综合表现的基准，因此需要一个系统性、实用性强的评价标准。

Method: 作者基于Bloom认知分类法，设计了多层次法律任务，包括法律问答、基于检索的信息生成、多步推理和情景分析。数据集共包含10,450个样本，均由法律专家标注及交叉验证，确保每个实例对应权威法律文件，并反映实际法律助理的工作流程。

Result: 作者构建了VLegal-Bench，并将其作为标准化、透明的LLM评测工具，实现了基础设施的搭建。数据涵盖丰富任务类型和实际法律应用场景，为后续模型开发和评估提供了可靠依据。

Conclusion: VLegal-Bench填补了越南法律AI评测的空白，为LLM在该领域的系统评估提供了基础；有助于推动更为可靠、可解释和伦理合规的AI法律系统发展。

Abstract: The rapid advancement of large language models (LLMs) has enabled new possibilities for applying artificial intelligence within the legal domain. Nonetheless, the complexity, hierarchical organization, and frequent revisions of Vietnamese legislation pose considerable challenges for evaluating how well these models interpret and utilize legal knowledge. To address this gap, Vietnamese Legal Benchmark (VLegal-Bench) is introduced, the first comprehensive benchmark designed to systematically assess LLMs on Vietnamese legal tasks. Informed by Bloom's cognitive taxonomy, VLegal-Bench encompasses multiple levels of legal understanding through tasks designed to reflect practical usage scenarios. The benchmark comprises 10,450 samples generated through a rigorous annotation pipeline, where legal experts label and cross-validate each instance using our annotation system to ensure every sample is grounded in authoritative legal documents and mirrors real-world legal assistant workflows, including general legal questions and answers, retrieval-augmented generation, multi-step reasoning, and scenario-based problem solving tailored to Vietnamese law. By providing a standardized, transparent, and cognitively informed evaluation framework, VLegal-Bench establishes a solid foundation for assessing LLM performance in Vietnamese legal contexts and supports the development of more reliable, interpretable, and ethically aligned AI-assisted legal systems.

</details>


### [136] [Agreement Between Large Language Models and Human Raters in Essay Scoring: A Research Synthesis](https://arxiv.org/abs/2512.14561)
*Hongli Li,Che Han Chen,Kevin Fan,Chiho Young-Johnson,Soyoung Lim,Yali Feng*

Main category: cs.CL

TL;DR: 本研究系统性综述了2022年1月至2025年8月关于大型语言模型（LLMs）与人类评分员在自动作文评分（AES）中评分一致性的65项研究，指出整体一致性中等到良好，但存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在自动作文评分中的应用前景广阔，但其评分与人类评分员的可靠性尚无定论，存在研究结论不一致的问题，因此有必要系统梳理和综合已有实证研究。

Method: 遵循PRISMA 2020系统评价指南，收集并综合2022年1月至2025年8月期间已发表及未发表的相关文献，共纳入65项研究，分析LLMs与人类评分员之间的一致性，采用一致性指标（如QWK、皮尔逊相关、斯皮尔曼相关）。

Result: LLMs与人类评分员在自动作文评分中报告的一致性普遍为中等到良好（相关系数范围0.30至0.80），但不同研究间存在较大变异，主要受具体研究设计及报告标准不统一影响。

Conclusion: LLMs在AES任务中与人类评分员总体一致性较好，但仍存在方法和报告规范上的差异，需要进一步研究以提升一致性与标准化，明确未来研究方向和改进空间。

Abstract: Despite the growing promise of large language models (LLMs) in automatic essay scoring (AES), empirical findings regarding their reliability compared to human raters remain mixed. Following the PRISMA 2020 guidelines, we synthesized 65 published and unpublished studies from January 2022 to August 2025 that examined agreement between LLMs and human raters in AES. Across studies, reported LLM-human agreement was generally moderate to good, with agreement indices (e.g., Quadratic Weighted Kappa, Pearson correlation, and Spearman's rho) mostly ranging between 0.30 and 0.80. Substantial variability in agreement levels was observed across studies, reflecting differences in study-specific factors as well as the lack of standardized reporting practices. Implications and directions for future research are discussed.

</details>


### [137] [Polypersona: Persona-Grounded LLM for Synthetic Survey Responses](https://arxiv.org/abs/2512.14562)
*Tejaswani Dash,Dinesh Karri,Anudeep Vurity,Gautam Datla,Tazeem Ahmad,Saima Rafi,Rohith Tangudu*

Main category: cs.CL

TL;DR: PolyPersona是一个用于生成多领域、多角色问卷作答的生成式框架，通过高效调优小型对话模型，能生成一致且可靠的人设化合成数据。


<details>
  <summary>Details</summary>
Motivation: 现有问卷数据稀缺且高质量数据获取成本高，尤其是在多领域和丰富角色背景下，限制了模型个性化和泛化能力的评估和提升，因此需要自动生成高质量、多样化的人设化数据。

Method: 本框架对小型对话模型（如TinyLlama 1.1B、Phi-2）进行指令微调，利用LoRA适配器和四位量化技术，实现资源自适应训练。同时，通过对话式数据流程显式保持人物特征和行为一致性，构建了含有10个领域、433个人设、3568个合成问卷答复的数据集。评估采用多指标体系，结合传统文本生成指标（BLEU、ROUGE、BERTScore）和调查问卷专用指标，全面评判生成质量。

Result: 实验显示，紧凑模型的生成质量可媲美7B-8B量级大模型，如BLEU分数达0.090，ROUGE-1 达0.429。小模型经过人设调优后，能稳定产生一致、结构化和风格统一的问卷回应。

Conclusion: PolyPersona框架提高了小型语言模型合成问卷能力，方法高效、易复现，有助于大规模生成和评估，同时能通过公开协议进行偏差分析，为后续相关研究和应用提供了可扩展工具。

Abstract: This paper introduces PolyPersona, a generative framework for synthesizing persona-conditioned survey responses across multiple domains. The framework instruction-tunes compact chat models using parameter-efficient LoRA adapters with 4-bit quantization under a resource-adaptive training setup. A dialogue-based data pipeline explicitly preserves persona cues, ensuring consistent behavioral alignment across generated responses. Using this pipeline, we construct a dataset of 3,568 synthetic survey responses spanning ten domains and 433 distinct personas, enabling controlled instruction tuning and systematic multi-domain evaluation. We evaluate the generated responses using a multi-metric evaluation suite that combines standard text generation metrics, including BLEU, ROUGE, and BERTScore, with survey-specific metrics designed to assess structural coherence, stylistic consistency, and sentiment alignment.Experimental results show that compact models such as TinyLlama 1.1B and Phi-2 achieve performance comparable to larger 7B to 8B baselines, with a highest BLEU score of 0.090 and ROUGE-1 of 0.429. These findings demonstrate that persona-conditioned fine-tuning enables small language models to generate reliable and coherent synthetic survey data. The proposed framework provides an efficient and reproducible approach for survey data generation, supporting scalable evaluation while facilitating bias analysis through transparent and open protocols.

</details>


### [138] [Low-Resource, High-Impact: Building Corpora for Inclusive Language Technologies](https://arxiv.org/abs/2512.14576)
*Ekaterina Artemova,Laurie Burchell,Daryna Dementieva,Shu Okabe,Mariya Shmatova,Pedro Ortiz Suarez*

Main category: cs.CL

TL;DR: 这是一篇面向低资源语言和多语言自然语言处理（NLP）领域的实用教程，涵盖从数据获取到下游应用的全流程。


<details>
  <summary>Details</summary>
Motivation: 当前大多数NLP技术和工具主要适用于资源丰富语言，许多低资源语言在数据和工具上都存在巨大缺口，难以享受数字化技术带来的红利。本文旨在解决数据稀缺和文化多样性带来的挑战，推动语言技术公平可及。

Method: 教程内容涵盖：数据收集与网络爬取、平行语句挖掘、机器翻译、文本分类与多模态推理等完整流程，并提供面向低资源语言的实际操作方法和建模框架。突出强调公平、可复现、社区参与的开发方式，并通过多种真实语言场景案例展示具体应用。

Result: 教程展示了10多种不同语言，包括资源丰富和贫乏的多语言真实用例，提升了低资源语言NLP端到端管道的实操性和可复制性。

Conclusion: 通过本教程，参与者能获得系统工具和方法，推动多语言、低资源语言技术的公正发展，并促进社会公平和数字包容。

Abstract: This tutorial (https://tum-nlp.github.io/low-resource-tutorial) is designed for NLP practitioners, researchers, and developers working with multilingual and low-resource languages who seek to create more equitable and socially impactful language technologies. Participants will walk away with a practical toolkit for building end-to-end NLP pipelines for underrepresented languages -- from data collection and web crawling to parallel sentence mining, machine translation, and downstream applications such as text classification and multimodal reasoning. The tutorial presents strategies for tackling the challenges of data scarcity and cultural variance, offering hands-on methods and modeling frameworks. We will focus on fair, reproducible, and community-informed development approaches, grounded in real-world scenarios. We will showcase a diverse set of use cases covering over 10 languages from different language families and geopolitical contexts, including both digitally resource-rich and severely underrepresented languages.

</details>


### [139] [Towards Nepali-language LLMs: Efficient GPT training with a Nepali BPE tokenizer](https://arxiv.org/abs/2512.14585)
*Adarsha Shrestha,Basanta Pokharel,Binit Shrestha,Smriti Adhikari,Dinesh Gothe*

Main category: cs.CL

TL;DR: 本文提出了一个基于GPT-2的尼泊尔语大语言模型，采用GPT-3启发的训练策略，以提升尼泊尔语文本生成能力。


<details>
  <summary>Details</summary>
Motivation: 尼泊尔语是资源稀缺语言，复杂语法和词形变化以及高质量语料匮乏使自然语言处理（NLP）面临极大挑战。现有方法多为基础编码器结构，对尼泊尔语文本生成效果有限。

Method: 基于GPT-2架构，采用GPT-3的训练策略（如优化学习率计划、批量大小扩展、结构改进）；为尼泊尔语专门训练了16k BPE分词器；采用10.75GB的清洗尼泊尔语语料及新闻抓取数据进行预训练；集成FlashAttention减少内存占用、提高训练稳定性。

Result: 模型经过两轮训练后，训练损失为3.168177，验证损失为3.081982，最终困惑度达到21.80，可生成连贯的尼泊尔语新闻风格文本。

Conclusion: 所提出方法有效提升了尼泊尔语文本生成质量，证明面向资源稀缺语言定制的训练策略和分词器设计十分关键。

Abstract: Nepali, a low-resource language spoken by over 32 million people, continues to face challenges in natural language processing (NLP) due to its complex grammar, agglutinative morphology, and limited availability of high-quality corpora. Most efforts to date have centered on basic encoder architectures; they remain insufficient for Nepali-specific text generation. This study presents a GPT-2-based Nepali language model trained using several training strategies inspired by GPT-3, including optimized learning rate schedules, batch scaling, and architectural refinements. A custom 16k Byte-Pair Encoding (BPE) tokenizer was trained exclusively on Nepali text to ensure more consistent segmentation and improved input representation. The model was pretrained on a combined dataset comprising a 10.75GB cleaned NepBERTa corpus and additional web-scraped Nepali news articles. FlashAttention was integrated to reduce memory usage and stabilize training. After two epochs, the model achieved a training loss of 3.168177, a validation loss of 3.081982, and a final perplexity of 21.80, demonstrating its capability to generate coherent Nepali news-style text.

</details>


### [140] [JMMMU-Pro: Image-based Japanese Multi-discipline Multimodal Understanding Benchmark via Vibe Benchmark Construction](https://arxiv.org/abs/2512.14620)
*Atsuyuki Miyai,Shota Onohara,Jeonghun Baek,Kiyoharu Aizawa*

Main category: cs.CL

TL;DR: 本文提出了JMMMU-Pro基准和Vibe Benchmark Construction方法，为日语多学科多模态理解提供了新的高质量评测工具，并表明当前开源多模态大模型在该基准上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有多模态基准无法充分考察日语场景下视觉文本一体化理解能力，且高质量基准的构建成本较高，缺乏高效且可扩展的方法。

Method: 作者将多模态问题的图片和文本整合为单一图片，利用Nano Banana Pro等高质量图像生成模型生成候选问题图片，经人工审核与优化，构建包含丰富场景与布局的高质量日语多模态理解基准。

Result: 实验表明，目前所有开源多模态大模型（LMMs）在JMMMU-Pro基准上均表现不佳，显示其评测难度和区分力。

Conclusion: JMMMU-Pro对评估LMM在日语多模态任务中的能力更为严苛，同时提出的Vibe Benchmark Construction为构建高质低成本多模态问答基准提供了有效范式，对未来基准开发具有借鉴意义。

Abstract: This paper introduces JMMMU-Pro, an image-based Japanese Multi-discipline Multimodal Understanding Benchmark, and Vibe Benchmark Construction, a scalable construction method. Following the evolution from MMMU to MMMU-Pro, JMMMU-Pro extends JMMMU by composing the question image and question text into a single image, thereby creating a benchmark that requires integrated visual-textual understanding through visual perception. To build JMMMU-Pro, we propose Vibe Benchmark Construction, a methodology in which an image generative model (e.g., Nano Banana Pro) produces candidate visual questions, and humans verify the outputs and, when necessary, regenerate with adjusted prompts to ensure quality. By leveraging Nano Banana Pro's highly realistic image generation capabilities and its ability to embed clean Japanese text, we construct a high-quality benchmark at low cost, covering a wide range of background and layout designs. Experimental results show that all open-source LMMs struggle substantially with JMMMU-Pro, underscoring JMMMU-Pro as an important benchmark for guiding future efforts in the open-source community. We believe that JMMMU-Pro provides a more rigorous evaluation tool for assessing the Japanese capabilities of LMMs and that our Vibe Benchmark Construction also offers an efficient guideline for future development of image-based VQA benchmarks.

</details>


### [141] [TiME: Tiny Monolingual Encoders for Efficient NLP Pipelines](https://arxiv.org/abs/2512.14645)
*David Schulmeister,Valentin Hartmann,Lars Klein,Robert West*

Main category: cs.CL

TL;DR: 本文提出了一种高效的小型NLP模型TiME，针对只需有限能力的场景，通过现代训练技术（蒸馏等）显著提升能效和性能权衡。


<details>
  <summary>Details</summary>
Motivation: 当前NLP领域的主流研究集中于大型通用模型，但实际许多场景只需有限能力。大模型虽然覆盖这些任务，但速度慢、耗能高，不适合实时或资源受限应用，影响部署和可持续性。为此，作者希望开发高效、资源友好型的小模型。

Method: 采用知识蒸馏等现代训练方法，从多语种大模型向单语种小模型迁移知识，并支持低资源语言。探讨了从有相对位置编码到绝对位置编码的教师-学生模型蒸馏方法。

Result: 提出的TiME模型在多种主流NLP任务中进行了全面评测。结果表明，TiME在性能、吞吐量、延迟和能耗之间取得了更优的权衡。同时验证了蒸馏不同语言和不同位置编码方式模型的可行性。

Conclusion: TiME模型充分满足对高效率、小体量及低能耗的实际应用需求，为资源受限和注重可持续性的NLP任务提供了有效解决方案。

Abstract: Today, a lot of research on language models is focused on large, general-purpose models. However, many NLP pipelines only require models with a well-defined, small set of capabilities. While large models are capable of performing the tasks of those smaller models, they are simply not fast enough to process large amounts of data or offer real-time responses. Furthermore, they often use unnecessarily large amounts of energy, leading to sustainability concerns and problems when deploying them on battery-powered devices. In our work, we show how to train small models for such efficiency-critical applications. As opposed to many off-the-shelf NLP pipelines, our models use modern training techniques such as distillation, and offer support for low-resource languages. We call our models TiME (Tiny Monolingual Encoders) and comprehensively evaluate them on a range of common NLP tasks, observing an improved trade-off between benchmark performance on one hand, and throughput, latency and energy consumption on the other. Along the way, we show that distilling monolingual models from multilingual teachers is possible, and likewise distilling models with absolute positional embeddings from teachers with relative positional embeddings.

</details>


### [142] [Fast and Accurate Causal Parallel Decoding using Jacobi Forcing](https://arxiv.org/abs/2512.14681)
*Lanxiang Hu,Siqi Kou,Yichao Fu,Samyam Rajbhandari,Tajana Rosing,Yuxiong He,Zhijie Deng,Hao Zhang*

Main category: cs.CL

TL;DR: 本文提出一种新范式Jacobi Forcing，通过渐进式蒸馏方法，将自回归(AR)大模型平滑迁移为高效的并行解码器模型，实现多token高效生成，极大加速推理速度，并兼顾性能损失。


<details>
  <summary>Details</summary>
Motivation: 当前通过扩散型大模型(dLLMs)实现多token并行生成，尽管在理论上能提升推理速度，但因后训练(posttrain)和预训练分布不匹配，以及双向注意力和因果推理冲突等问题，导致实际加速有限，且键值缓存复用困难。需要新的方法兼容高性能和高并行度。

Method: 作者提出Jacobi Forcing，一种渐进蒸馏训练范式。在训练时，模型基于自身并行生成轨迹进行进化，逐步由AR转化为并行解码结构，还保留了原先自回归的因果推理能力。在此基础上，提出多块拒绝回收解码策略，进一步提升每次生成token的有效率。

Result: 所提方法在代码和数学任务上推理速度提升3.8倍，最大token接受率提升4.5倍，整体推理延迟接近4.0倍加速，且性能损失极小。

Conclusion: Jacobi Forcing能有效解决AR到并行解码转化过程中的瓶颈，实现并行推理速度显著提升，为大模型推理带来高效新方案。

Abstract: Multi-token generation has emerged as a promising paradigm for accelerating transformer-based large model inference. Recent efforts primarily explore diffusion Large Language Models (dLLMs) for parallel decoding to reduce inference latency. To achieve AR-level generation quality, many techniques adapt AR models into dLLMs to enable parallel decoding. However, they suffer from limited speedup compared to AR models due to a pretrain-to-posttrain mismatch. Specifically, the masked data distribution in post-training deviates significantly from the real-world data distribution seen during pretraining, and dLLMs rely on bidirectional attention, which conflicts with the causal prior learned during pretraining and hinders the integration of exact KV cache reuse. To address this, we introduce Jacobi Forcing, a progressive distillation paradigm where models are trained on their own generated parallel decoding trajectories, smoothly shifting AR models into efficient parallel decoders while preserving their pretrained causal inference property. The models trained under this paradigm, Jacobi Forcing Model, achieves 3.8x wall-clock speedup on coding and math benchmarks with minimal loss in performance. Based on Jacobi Forcing Models' trajectory characteristics, we introduce multi-block decoding with rejection recycling, which enables up to 4.5x higher token acceptance count per iteration and nearly 4.0x wall-clock speedup, effectively trading additional compute for lower inference latency. Our code is available at https://github.com/hao-ai-lab/JacobiForcing.

</details>


### [143] [Spoken DialogSum: An Emotion-Rich Conversational Dataset for Spoken Dialogue Summarization](https://arxiv.org/abs/2512.14687)
*Yen-Ju Lu,Kunxiao Gao,Mingrui Liang,Helin Wang,Thomas Thebaud,Laureano Moro-Velazquez,Najim Dehak,Jesus Villalba*

Main category: cs.CL

TL;DR: 本文提出了Spoken DialogSum数据集，这是首个将原始对话语音与事实摘要、情感摘要及说话人年龄、性别、情感等标签对齐的数据集，为情感感知对话摘要等任务提供了基础。


<details>
  <summary>Details</summary>
Motivation: 以往的情感感知或口语对话摘要研究受限于缺乏同时包含语音、摘要和副语言（情感、说话人信息等）线索的数据，因此亟需构建这类高质量对齐语料。

Method: 数据集构建分两步：第一，利用大语言模型重写DialogSum剧本，赋予Switchboard风格，给每句标注情感、音高及语速。第二，使用富表达力的TTS合成对应标签的语音，生成13,460条情感多样化的对话，每条配有事实和情感摘要。

Result: 提出的数据集规模大、情感丰富，并对话语事实与情感摘要均有配对。基线实验显示，端到端的Audio-LLM在情感摘要ROUGE-L指标上比传统级联ASR-LLM方案提升了28%。

Conclusion: Spoken DialogSum为情感感知音频对话摘要等研究提供了新的数据资源和基准，对提升端到端语音建模效果非常重要。

Abstract: Recent audio language models can follow long conversations. However, research on emotion-aware or spoken dialogue summarization is constrained by the lack of data that links speech, summaries, and paralinguistic cues. We introduce Spoken DialogSum, the first corpus aligning raw conversational audio with factual summaries, emotion-rich summaries, and utterance-level labels for speaker age, gender, and emotion. The dataset is built in two stages: first, an LLM rewrites DialogSum scripts with Switchboard-style fillers and back-channels, then tags each utterance with emotion, pitch, and speaking rate. Second, an expressive TTS engine synthesizes speech from the tagged scripts, aligned with paralinguistic labels. Spoken DialogSum comprises 13,460 emotion-diverse dialogues, each paired with both a factual and an emotion-focused summary. The dataset is available online at https://fatfat-emosum.github.io/EmoDialog-Sum-Audio-Samples/. Baselines show that an Audio-LLM raises emotional-summary ROUGE-L by 28% relative to a cascaded ASR-LLM system, confirming the value of end-to-end speech modeling.

</details>


### [144] [MMGR: Multi-Modal Generative Reasoning](https://arxiv.org/abs/2512.14691)
*Zefan Cai,Haoyi Qiu,Tianyi Ma,Haozhe Zhao,Gengze Zhou,Kung-Hsiang Huang,Parisa Kordjamshidi,Minjia Zhang,Xiao Wen,Jiuxiang Gu,Nanyun Peng,Junjie Hu*

Main category: cs.CL

TL;DR: 本文提出了MMGR（多模态生成推理评估与基准），用于综合评估生成式视频/图像模型在物理、逻辑和空间等推理能力上的表现，弥补现有评测忽视因果、物理规律等推理缺陷的不足，并对业界主流模型进行系统性测试。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成大模型虽能生成视觉真实、时间连贯的内容，但主要强调感知质量，对因果、物理、全局一致性等推理能力的评测较弱。现有度量如FVD忽视了推理失败（如物理、逻辑、因果性破坏），因此需要新的评测框架来系统检验和比较模型的推理能力与世界模拟可靠性。

Method: 作者提出MMGR评测框架，从物理、逻辑、三维空间、二维空间和时间五个维度，结合抽象推理、具身导航、物理常识三大领域，设计细粒度基准任务。通过这些任务和新评价指标，全方位评估主流视频及图像生成模型的推理与生成能力。

Result: 主流视频（Veo-3、Sora-2、Wan-2.2）和图像模型（Nano-banana等）在物理常识领域表现尚可，在抽象推理和长时范围空间规划方面表现很差，例如在ARC-AGI任务准确率低于10%。暴露出依赖感知信息、缺乏全局状态一致性等关键不足。

Conclusion: 当前生成模型难以形成理解世界内在规律和复杂推理的通用能力。MMGR为诊断和引导生成式世界模型走向推理感知一体化提供了新的基准和途径，是该领域的重要进展。

Abstract: Video foundation models generate visually realistic and temporally coherent content, but their reliability as world simulators depends on whether they capture physical, logical, and spatial constraints. Existing metrics such as Frechet Video Distance (FVD) emphasize perceptual quality and overlook reasoning failures, including violations of causality, physics, and global consistency. We introduce MMGR (Multi-Modal Generative Reasoning Evaluation and Benchmark), a principled evaluation framework based on five reasoning abilities: Physical, Logical, 3D Spatial, 2D Spatial, and Temporal. MMGR evaluates generative reasoning across three domains: Abstract Reasoning (ARC-AGI, Sudoku), Embodied Navigation (real-world 3D navigation and localization), and Physical Commonsense (sports and compositional interactions). MMGR applies fine-grained metrics that require holistic correctness across both video and image generation. We benchmark leading video models (Veo-3, Sora-2, Wan-2.2) and image models (Nano-banana, Nano-banana Pro, GPT-4o-image, Qwen-image), revealing strong performance gaps across domains. Models show moderate success on Physical Commonsense tasks but perform poorly on Abstract Reasoning (below 10 percent accuracy on ARC-AGI) and struggle with long-horizon spatial planning in embodied settings. Our analysis highlights key limitations in current models, including overreliance on perceptual data, weak global state consistency, and objectives that reward visual plausibility over causal correctness. MMGR offers a unified diagnostic benchmark and a path toward reasoning-aware generative world models.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [145] [PrediFlow: A Flow-Based Prediction-Refinement Framework for Real-Time Human Motion Prediction in Human-Robot Collaboration](https://arxiv.org/abs/2512.13903)
*Sibo Tian,Minghui Zheng,Xiao Liang*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的人-机器人协作环境下的随机人类动作预测方法，通过引入预测-细化框架，并融合人类与机器人动作信息，实现了高效、真实且考虑交互的人类动作预测。


<details>
  <summary>Details</summary>
Motivation: 传统的人类动作预测方法难以有效捕捉人类动作的不确定性和多模态性，且常常忽略机器人动作对人类行为的影响。此外，如何在保证实时性的前提下进一步提升预测质量是亟需解决的问题。

Method: 作者提出了一个包含预测和细化两个阶段的框架。首先利用预训练的先进预测器获得初步人类动作预测，然后通过引入机器人与人类观测动作信息、结合流匹配结构的细化模块对初步预测进行修正，以更好地考虑不确定性和两者的交互影响。

Result: 在HRC桌面拆解数据集上的实验表明，该方法能在保证多模态性和动作不确定性的同时，显著提升预测准确性，总推理时间也满足实时性要求。

Conclusion: 该方法在预测质量和实时性能方面均取得优异表现，为实际工业协作中的人类动作预测提供了更实用和有效的方案。

Abstract: Stochastic human motion prediction is critical for safe and effective human-robot collaboration (HRC) in industrial remanufacturing, as it captures human motion uncertainties and multi-modal behaviors that deterministic methods cannot handle. While earlier works emphasize highly diverse predictions, they often generate unrealistic human motions. More recent methods focus on accuracy and real-time performance, yet there remains potential to improve prediction quality further without exceeding time budgets. Additionally, current research on stochastic human motion prediction in HRC typically considers human motion in isolation, neglecting the influence of robot motion on human behavior. To address these research gaps and enable real-time, realistic, and interaction-aware human motion prediction, we propose a novel prediction-refinement framework that integrates both human and robot observed motion to refine the initial predictions produced by a pretrained state-of-the-art predictor. The refinement module employs a Flow Matching structure to account for uncertainty. Experimental studies on the HRC desktop disassembly dataset demonstrate that our method significantly improves prediction accuracy while preserving the uncertainties and multi-modalities of human motion. Moreover, the total inference time of the proposed framework remains within the time budget, highlighting the effectiveness and practicality of our approach.

</details>


### [146] [Autonomous Construction-Site Safety Inspection Using Mobile Robots: A Multilayer VLM-LLM Pipeline](https://arxiv.org/abs/2512.13974)
*Hossein Naderi,Alireza Shojaei,Philip Agee,Kereshmeh Afsari,Abiola Akanmu*

Main category: cs.RO

TL;DR: 该论文提出一个集成机器人和AI的多层框架，自动连接机器人感知与施工安全规则，实现自动化安全检查报告生成，在实验场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统施工安全检查多为人工，自动化方法依赖特定数据集且维护成本高，机器人现场检查仍需人工操作和报告，效率低下。因此，亟需更智能、通用且可自动化生成报告的安全检查方法。

Method: 提出多层框架，包括机器人模块（利用SLAM和自主导航覆盖和重访关键点）和AI模块（利用视觉语言模型生成场景描述，结合检索组件将描述对接至安全规则，再利用VLM评估风险，最后由大语言模型生成报告）。框架经过实验室仿真典型危险场景验证。

Result: 在三种典型施工场景中，所提系统回召率高，精确率与先进商业闭源模型竞争，且能够提供中间结果，便于人类监督和扩展。

Conclusion: 本文提出的透明、通用管道实现了安全透明可控的自动化安全检查，并建立了未来应用扩展的基础，具备推动自动化安全检测与报告领域发展的潜力。

Abstract: Construction safety inspection remains mostly manual, and automated approaches still rely on task-specific datasets that are hard to maintain in fast-changing construction environments due to frequent retraining. Meanwhile, field inspection with robots still depends on human teleoperation and manual reporting, which are labor-intensive. This paper aims to connect what a robot sees during autonomous navigation to the safety rules that are common in construction sites, automatically generating a safety inspection report. To this end, we proposed a multi-layer framework with two main modules: robotics and AI. On the robotics side, SLAM and autonomous navigation provide repeatable coverage and targeted revisits via waypoints. On AI side, a Vision Language Model (VLM)-based layer produces scene descriptions; a retrieval component powered grounds those descriptions in OSHA and site policies; Another VLM-based layer assesses the safety situation based on rules; and finally Large Language Model (LLM) layer generates safety reports based on previous outputs. The framework is validated with a proof-of-concept implementation and evaluated in a lab environment that simulates common hazards across three scenarios. Results show high recall with competitive precision compared to state-of-the-art closed-source models. This paper contributes a transparent, generalizable pipeline that moves beyond black-box models by exposing intermediate artifacts from each layer and keeping the human in the loop. This work provides a foundation for future extensions to additional tasks and settings within and beyond construction context.

</details>


### [147] [Impact of Robot Facial-Audio Expressions on Human Robot Trust Dynamics and Trust Repair](https://arxiv.org/abs/2512.13981)
*Hossein Naderi,Alireza Shojaei,Philip Agee,Kereshmeh Afsari,Abiola Akanmu*

Main category: cs.RO

TL;DR: 本文探讨了机器人任务表现及其表达型反馈如何动态影响协作过程中的人类信任变化，实验证明道歉和表达可部分恢复信任。


<details>
  <summary>Details</summary>
Motivation: 尽管机器人与人机协作领域已取得进展，但关于信任如何随协作事件动态变化的研究匮乏，现有工作多将信任视为静态问题。了解信任动态对成功部署机器人于建筑业具有现实意义。

Method: 设计了受控的被试内实验，设置了两类建筑相关任务（物资配送和信息收集），分别多次测量参与者对机器人的信任度，并操控机器人成功/失败后的多模态表达（高兴或道歉请求重试）。共有30名参与者在实验室环境下与四足机器人平台互动。

Result: 机器人成功任务后人类信任显著提升，失败时信任急剧下降，道歉表达可部分恢复信任（最高恢复44%）。信任恢复主要体现在交互与沟通维度，能力维度部分恢复，自治性变化最小。不同年龄与态度的参与者信任变化特征不同。

Conclusion: 机器人通过表达与修复策略可动态影响人类信任，后续研究可针对不同任务与用户特征优化信任修复机制，促进建筑业中机器人安全高效应用。

Abstract: Despite recent advances in robotics and human-robot collaboration in the AEC industry, trust has mostly been treated as a static factor, with little guidance on how it changes across events during collaboration. This paper investigates how a robot's task performance and its expressive responses after outcomes shape the dynamics of human trust over time. To this end, we designed a controlled within-subjects study with two construction-inspired tasks, Material Delivery (physical assistance) and Information Gathering (perceptual assistance), and measured trust repeatedly (four times per task) using the 14-item Trust Perception Scale for HRI plus a redelegation choice. The robot produced two multimodal expressions, a "glad" display with a brief confirmation after success, and a "sad" display with an apology and a request for a second chance after failure. The study was conducted in a lab environment with 30 participants and a quadruped platform, and we evaluated trust dynamics and repair across both tasks. Results show that robot success reliably increases trust, failure causes sharp drops, and apology-based expressions partially restores trust (44% recovery in Material Delivery; 38% in Information Gathering). Item-level analysis indicates that recovered trust was driven mostly by interaction and communication factors, with competence recovering partially and autonomy aspects changing least. Additionally, age group and prior attitudes moderated trust dynamics with younger participants showed larger but shorter-lived changes, mid-20s participants exhibited the most durable repair, and older participants showed most conservative dynamics. This work provides a foundation for future efforts that adapt repair strategies to task demands and user profiles to support safe, productive adoption of robots on construction sites.

</details>


### [148] [CLAIM: Camera-LiDAR Alignment with Intensity and Monodepth](https://arxiv.org/abs/2512.14001)
*Zhuo Zhang,Yonghui Liu,Meijie Zhang,Feiyang Tan,Yikang Ding*

Main category: cs.RO

TL;DR: 本文提出了一种基于单目深度（monodepth）模型的新方法CLAIM，实现了相机与激光雷达的高效标定，依靠结构和纹理损失联合优化，无需复杂特征处理，实验优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前相机与激光雷达的标定方法往往需要复杂的数据处理和特征提取，流程繁琐且适应性差。因此，提出一种无需繁琐特征处理、简单且适应场景广泛的新方法成为需求。

Method: CLAIM方法利用monodepth模型为基础，结合图像与激光雷达点云数据，通过粗到细的搜索策略优化变换参数。其核心创新是采用基于分块Pearson相关性的结构损失和基于互信息的纹理损失，直接衡量对齐效果，无需繁琐特征提取或匹配步骤。

Result: CLAIM在KITTI、Waymo和MIAS-LCEC公开数据集上做了验证，实验表明其标定精度优于当前主流方法，即使初始值不准也能稳健优化，实验证明了其有效性和优越性。

Conclusion: CLAIM是一种简单高效、无需复杂预处理或特征提取的通用相机-激光雷达标定方法，在多个基准数据集上都取得了优异效果，有广泛实际应用前景，相关代码已开源。

Abstract: In this paper, we unleash the potential of the powerful monodepth model in camera-LiDAR calibration and propose CLAIM, a novel method of aligning data from the camera and LiDAR. Given the initial guess and pairs of images and LiDAR point clouds, CLAIM utilizes a coarse-to-fine searching method to find the optimal transformation minimizing a patched Pearson correlation-based structure loss and a mutual information-based texture loss. These two losses serve as good metrics for camera-LiDAR alignment results and require no complicated steps of data processing, feature extraction, or feature matching like most methods, rendering our method simple and adaptive to most scenes. We validate CLAIM on public KITTI, Waymo, and MIAS-LCEC datasets, and the experimental results demonstrate its superior performance compared with the state-of-the-art methods. The code is available at https://github.com/Tompson11/claim.

</details>


### [149] [Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model](https://arxiv.org/abs/2512.14031)
*Zhaofeng Hu,Hongrui Yu,Vaidhyanathan Chandramouli,Ci-Jyun Liang*

Main category: cs.RO

TL;DR: 本文比较了VLA模型与RL方法在建筑机器人技能学习中的应用效果，发现VLA在任务切换和数据需求上更有优势。


<details>
  <summary>Details</summary>
Motivation: 随着建筑自动化需求增长，机器人需要快速学习和适应新任务。当前主流方法（VLA、RL）在实际部署中的优劣尚不清楚，亟需系统性对比。

Method: 作者开发了两种遥操作接口收集数据，通过三阶段实验：1. 比较MLP与DQN的性能，作为RL基线；2. 训练三种VLA模型并相互比较；3. 用样本效率和机器人实物实验将精选RL基线与VLA模型进行对比，任务为多阶段板材安装。

Result: VLA模型在泛化和少样本能力上表现优越，抓取阶段成功率达60%-100%；DQN虽可调优至稳定，但需加入噪声，调试工作量大。总体上，VLA实现相似或更高性能，且对数据和调试依赖更低。

Conclusion: VLA适合多变任务和数据有限情境，大幅降低编程与部署难度，而DQN在充分调试下也可作为可靠基线方案。

Abstract: This study evaluates two leading approaches for teaching construction robots new skills to understand their applicability for construction automation: a Vision-Language-Action (VLA) model and Reinforcement Learning (RL) methods. The goal is to understand both task performance and the practical effort needed to deploy each approach on real jobs. The authors developed two teleoperation interfaces to control the robots and collect the demonstrations needed, both of which proved effective for training robots for long-horizon and dexterous tasks. In addition, the authors conduct a three-stage evaluation. First, the authors compare a Multi-Layer Perceptron (MLP) policy with a Deep Q-network (DQN) imitation model to identify the stronger RL baseline, focusing on model performance, generalization, and a pick-up experiment. Second, three different VLA models are trained in two different scenarios and compared with each other. Third, the authors benchmark the selected RL baseline against the VLA model using computational and sample-efficiency measures and then a robot experiment on a multi-stage panel installation task that includes transport and installation. The VLA model demonstrates strong generalization and few-shot capability, achieving 60% and 100% success in the pickup phase. In comparison, DQN can be made robust but needs additional noise during tuning, which increases the workload. Overall, the findings indicate that VLA offers practical advantages for changing tasks by reducing programming effort and enabling useful performance with minimal data, while DQN provides a viable baseline when sufficient tuning effort is acceptable.

</details>


### [150] [E-Navi: Environmental Adaptive Navigation for UAVs on Resource Constrained Platforms](https://arxiv.org/abs/2512.14046)
*Boyang Li,Zhongpeng Jin,Shuai Zhao,Jiahui Liao,Tian Liu,Han Liu,Yuanhai Zhang,Kai Huang*

Main category: cs.RO

TL;DR: 本文提出了一种名为E-Navi的无人机环境自适应导航系统，可根据环境复杂度和计算资源动态调整任务执行策略，从而有效提升无人机自主导航性能，并在多种硬件平台上的实验中取得显著优化效果。


<details>
  <summary>Details</summary>
Motivation: 现有无人机导航系统采用固定的执行配置，未考虑环境变化和计算资源的动态分配，导致过度计算和飞行策略僵化，降低了飞行性能甚至引发失效。因此，开发能够灵活适应环境变化和硬件能力的导航系统成为必要。

Method: 提出E-Navi系统，通过定量评估环境复杂度，动态调整导航系统中感知-规划流程的地图分辨率和执行频率，实现基于环境和计算资源的任务调整。同时，该系统支持在不同计算能力的硬件平台灵活部署。

Result: 通过大量硬件闭环和实际飞行实验，E-Navi在不同硬件平台下相较于基线方法，导航任务负载降低高达53.9%，飞行时间节省高达63.8%，同时实现了更加稳定的速度控制。

Conclusion: E-Navi实现了无人机导航系统对动态环境的自适应，显著优化了任务负载、飞行时间以及飞行稳定性，证明了其在多硬件平台上的有效性和实用价值。

Abstract: The ability to adapt to changing environments is crucial for the autonomous navigation systems of Unmanned Aerial Vehicles (UAVs). However, existing navigation systems adopt fixed execution configurations without considering environmental dynamics based on available computing resources, e.g., with a high execution frequency and task workload. This static approach causes rigid flight strategies and excessive computations, ultimately degrading flight performance or even leading to failures in UAVs. Despite the necessity for an adaptive system, dynamically adjusting workloads remains challenging, due to difficulties in quantifying environmental complexity and modeling the relationship between environment and system configuration. Aiming at adapting to dynamic environments, this paper proposes E-Navi, an environmental-adaptive navigation system for UAVs that dynamically adjusts task executions on the CPUs in response to environmental changes based on available computational resources. Specifically, the perception-planning pipeline of UAVs navigation system is redesigned through dynamic adaptation of mapping resolution and execution frequency, driven by the quantitative environmental complexity evaluations. In addition, E-Navi supports flexible deployment across hardware platforms with varying levels of computing capability. Extensive Hardware-In-the-Loop and real-world experiments demonstrate that the proposed system significantly outperforms the baseline method across various hardware platforms, achieving up to 53.9% navigation task workload reduction, up to 63.8% flight time savings, and delivering more stable velocity control.

</details>


### [151] [Expert Switching for Robust AAV Landing: A Dual-Detector Framework in Simulation](https://arxiv.org/abs/2512.14054)
*Humaira Tasnim,Ashik E Rasul,Bruce Jo,Hyung-Jin Yoon*

Main category: cs.RO

TL;DR: 本文提出了一种适应尺度变化的双专家检测框架，用于提升自主飞行器在不同高度阶段的停机坪检测与着陆表现，优于单一检测器方案。


<details>
  <summary>Details</summary>
Motivation: 当前自主飞行器着陆任务中，停机坪检测在高空（目标小）和近地（目标大）时对检测器提出了极高的鲁棒性与适应性要求。单模型检测器在尺度适应性方面存在性能瓶颈，特别是在着陆过程中多尺度极端切换时易出现检测退化。

Method: 作者提出将检测任务根据距离分为远距离和近距离两个尺度区间，对YOLOv8进行双专家训练，每个专家分别针对小尺度（高空小目标）和大尺度（近地大目标）优化，并在推理阶段并行运行，通过几何门控策略自适应分配检测结果，提升全流程的检测鲁棒性。

Result: 在CARLA仿真与NASA飞行动力学引擎环境下，所提双专家检测框架在停机坪对准稳定性、着陆精度与鲁棒性方面均显著优于传统单检测器基线。

Conclusion: 该文提出的基于尺度自适应专家路由的新策略，有效提升了自主飞行器的着陆感知系统鲁棒性，为多专家感知框架在AAV场景中的拓展和应用奠定了基础。

Abstract: Reliable helipad detection is essential for Autonomous Aerial Vehicle (AAV) landing, especially under GPS-denied or visually degraded conditions. While modern detectors such as YOLOv8 offer strong baseline performance, single-model pipelines struggle to remain robust across the extreme scale transitions that occur during descent, where helipads appear small at high altitude and large near touchdown. To address this limitation, we propose a scale-adaptive dual-expert perception framework that decomposes the detection task into far-range and close-range regimes. Two YOLOv8 experts are trained on scale-specialized versions of the HelipadCat dataset, enabling one model to excel at detecting small, low-resolution helipads and the other to provide high-precision localization when the target dominates the field of view. During inference, both experts operate in parallel, and a geometric gating mechanism selects the expert whose prediction is most consistent with the AAV's viewpoint. This adaptive routing prevents the degradation commonly observed in single-detector systems when operating across wide altitude ranges. The dual-expert perception module is evaluated in a closed-loop landing environment that integrates CARLA's photorealistic rendering with NASA's GUAM flight-dynamics engine. Results show substantial improvements in alignment stability, landing accuracy, and overall robustness compared to single-detector baselines. By introducing a scale-aware expert routing strategy tailored to the landing problem, this work advances resilient vision-based perception for autonomous descent and provides a foundation for future multi-expert AAV frameworks.

</details>


### [152] [Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning](https://arxiv.org/abs/2512.14057)
*Amir M. Soufi Enayati,Homayoun Honari,Homayoun Najjaran*

Main category: cs.RO

TL;DR: 本文提出了一种无需动作信息的变换器模型CRAFT，可更好地泛化和适应机器人强化学习新任务。


<details>
  <summary>Details</summary>
Motivation: 标准的元强化学习方法在任务泛化能力上有限，且习惯上高度依赖动作信息，使任务推断紧密绑定于特定策略，导致适应能力与灵活性不足。

Method: 提出CRAFT（Context Representation via Action Free Transformer），基于变换器的编码解码结构，仅利用状态和奖励序列进行任务推断，完全移除了对动作的依赖。模型采用了旋转位置嵌入以及现成变分推断方法来实现高效的信念更新和长期依赖建模。

Result: 在MetaWorld ML-10机器人操作基准测试中，CRAFT相较于现有的元强化学习基线表现出更快的适应速度、更强的泛化能力以及更有效的探索能力。

Conclusion: CRAFT验证了“去动作化”的任务推断思路在机器人强化学习中的可行性与优越性，为实现大规模、可扩展的自主机器人控制奠定了基础。

Abstract: Reinforcement learning (RL) enables robots to operate in uncertain environments, but standard approaches often struggle with poor generalization to unseen tasks. Context-adaptive meta reinforcement learning addresses these limitations by conditioning on the task representation, yet they mostly rely on complete action information in the experience making task inference tightly coupled to a specific policy. This paper introduces Context Representation via Action Free Transformer encoder decoder (CRAFT), a belief model that infers task representations solely from sequences of states and rewards. By removing the dependence on actions, CRAFT decouples task inference from policy optimization, supports modular training, and leverages amortized variational inference for scalable belief updates. Built on a transformer encoder decoder with rotary positional embeddings, the model captures long range temporal dependencies and robustly encodes both parametric and non-parametric task variations. Experiments on the MetaWorld ML-10 robotic manipulation benchmark show that CRAFT achieves faster adaptation, improved generalization, and more effective exploration compared to context adaptive meta--RL baselines. These findings highlight the potential of action-free inference as a foundation for scalable RL in robotic control.

</details>


### [153] [Interactive Motion Planning for Human-Robot Collaboration Based on Human-Centric Configuration Space Ergonomic Field](https://arxiv.org/abs/2512.14111)
*Chenzui Li,Yiming Chen,Xi Wu,Tao Teng,Sylvain Calinon,Darwin Caldwell,Fei Chen*

Main category: cs.RO

TL;DR: 提出了一种基于构型空间的人机工效场（CSEF），提升人机协作中的运动规划效率和人体工效安全。


<details>
  <summary>Details</summary>
Motivation: 工业中的人-机器人协作需要保证运动过程无碰撞、响应迅速且人体工程学安全，以降低作业疲劳和肌肉骨骼风险。现有的人体工效规划方法通常依赖任务空间，难以兼顾实时性与工效优化。

Method: 提出CSEF方法，通过在人体关节空间建立持续可微的工效评分场，并利用高效算法结合关节加权和任务条件，生成实时梯度信息，集成于梯度型运动规划器，实现与阻抗控制机器人兼容的工效优化运动规划。

Result: 在2自由度基准测试中，CSEF方法较任务空间方法提高了规划成功率，降低工效代价，并加快了计算速度。硬件实验（单手引导、协作钻孔、双手搬运）中，CSEF显著降低工效代价、肌肉激活程度，更贴合优化目标，并相较基线法提高人体工效表现。

Conclusion: CSEF规划方法实际降低了协作任务中的人体工效分数和肌肉激活水平，展现出良好的现实部署前景。

Abstract: Industrial human-robot collaboration requires motion planning that is collision-free, responsive, and ergonomically safe to reduce fatigue and musculoskeletal risk. We propose the Configuration Space Ergonomic Field (CSEF), a continuous and differentiable field over the human joint space that quantifies ergonomic quality and provides gradients for real-time ergonomics-aware planning. An efficient algorithm constructs CSEF from established metrics with joint-wise weighting and task conditioning, and we integrate it into a gradient-based planner compatible with impedance-controlled robots. In a 2-DoF benchmark, CSEF-based planning achieves higher success rates, lower ergonomic cost, and faster computation than a task-space ergonomic planner. Hardware experiments with a dual-arm robot in unimanual guidance, collaborative drilling, and bimanual cocarrying show faster ergonomic cost reduction, closer tracking to optimized joint targets, and lower muscle activation than a point-to-point baseline. CSEF-based planning method reduces average ergonomic scores by up to 10.31% for collaborative drilling tasks and 5.60% for bimanual co-carrying tasks while decreasing activation in key muscle groups, indicating practical benefits for real-world deployment.

</details>


### [154] [SUPER -- A Framework for Sensitivity-based Uncertainty-aware Performance and Risk Assessment in Visual Inertial Odometry](https://arxiv.org/abs/2512.14189)
*Johannes A. Gaus,Daniel Häufle,Woo-Jeong Baek*

Main category: cs.RO

TL;DR: 本文提出了SUPER框架，一种基于敏感性传播不确定性的实时风险评估方法，能在视觉惯性里程计（VIO）系统中无需真实轨迹提前预测轨迹退化和触发恢复。


<details>
  <summary>Details</summary>
Motivation: 现有VO/VIO/SLAM系统虽然精度高，但普遍缺乏在运行时对风险的评估与解释能力，难以及时发现和预防轨迹退化问题。

Method: 提出了SUPER框架，利用高斯-牛顿法正态矩阵的Schur补方法传播不确定性，并通过残差大小、几何条件与短时间趋势等特征，实时估计轨迹风险，无需依赖真实轨迹，且适用于各种后端。

Result: SUPER能比基线准确率提升20%地提前50帧预测轨迹退化，触发停止/重定位的召回率达到89.1%。同时，实现开销极低（CPU增加<0.2%），实验表现不确定性估计稳定，并有效用于长时间SLAM。

Conclusion: SUPER框架可实时、泛后端地为VIO/SLAM系统提供准确、可解释的风险预警与管理，显著提升系统鲁棒性和应用范围。

Abstract: While many visual odometry (VO), visual-inertial odometry (VIO), and SLAM systems achieve high accuracy, the majority of existing methods miss to assess risks at runtime. This paper presents SUPER (Sensitivity-based Uncertainty-aware PErformance and Risk assessment) that is a generic and explainable framework that propagates uncertainties via sensitivities for real-time risk assessment in VIO. The scientific novelty lies in the derivation of a real-time risk indicator that is backend-agnostic and exploits the Schur complement blocks of the Gauss-Newton normal matrix to propagate uncertainties. Practically, the Schur complement captures the sensitivity that reflects the influence of the uncertainty on the risk occurrence. Our framework estimates risks on the basis of the residual magnitudes, geometric conditioning, and short horizon temporal trends without requiring ground truth knowledge. Our framework enables to reliably predict trajectory degradation 50 frames ahead with an improvement of 20% to the baseline. In addition, SUPER initiates a stop or relocalization policy with 89.1% recall. The framework is backend agnostic and operates in real time with less than 0.2% additional CPU cost. Experiments show that SUPER provides consistent uncertainty estimates. A SLAM evaluation highlights the applicability to long horizon mapping.

</details>


### [155] [Trajectory Tracking for Multi-Manipulator Systems in Constrained Environments](https://arxiv.org/abs/2512.14206)
*Mayank Sewlia,Christos K. Verginis,Dimos V. Dimarogonas*

Main category: cs.RO

TL;DR: 本文提出了一种针对多移动机械臂在障碍密集环境下协作搬运物体任务的多层次规划与控制框架。


<details>
  <summary>Details</summary>
Motivation: 在复杂受限的环境中，多机械臂系统协作搬运物体需要同时应对连续动力学和离散环境约束，现有方法难以同时高效兼顾任务规定、障碍避让及运动协调。

Method: 方法上，采用“离线-在线”相结合的多速率规划与控制架构：先离线生成满足时空任务逻辑（STL）约束的物体轨迹和无碰撞基座路径，再在线进行有约束逆运动学求解与连续反馈控制，确保整体系统协同动作。

Result: 通过高保真物理仿真验证了方法有效性，实验证明三台Franka Emika Panda移动机械臂能牢固抓持物体并实现高效协作搬运。

Conclusion: 提出的多层次混合规划控制框架能在高度受限环境下提升多移动机械臂系统的协作搬运能力，为实际机器人协作等应用提供了新的解决思路。

Abstract: We consider the problem of cooperative manipulation by a mobile multi-manipulator system operating in obstacle-cluttered and highly constrained environments under spatio-temporal task specifications. The task requires transporting a grasped object while respecting both continuous robot dynamics and discrete geometric constraints arising from obstacles and narrow passages. To address this hybrid structure, we propose a multi-rate planning and control framework that combines offline generation of an STL-satisfying object trajectory and collision-free base footprints with online constrained inverse kinematics and continuous-time feedback control. The resulting closed-loop system enables coordinated reconfiguration of multiple manipulators while tracking the desired object motion. The approach is evaluated in high-fidelity physics simulations using three Franka Emika Panda mobile manipulators rigidly grasping an object.

</details>


### [156] [CaFe-TeleVision: A Coarse-to-Fine Teleoperation System with Immersive Situated Visualization for Enhanced Ergonomics](https://arxiv.org/abs/2512.14270)
*Zixin Tang,Yiming Chen,Quentin Rouxel,Dianxi Li,Shuang Wu,Fei Chen*

Main category: cs.RO

TL;DR: 该论文提出了一种名为CaFe-TeleVision的新型远程操作系统，通过分层控制和沉浸式可视化提升了人机工程体验和操作效率，并在挑战性的双手机器人任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前远程操作系统在高效性和人机工程方面仍存在不足，特别是在处理复杂任务时。作者希望通过改进控制与反馈方式，以提升操作体验和效率。

Method: 系统在控制模块中采用粗到细的运动映射机制，解决人机工作空间差异，兼顾效率和人机工程。同时结合按需沉浸式多视角可视化，减轻操作员的认知负担，提高视觉反馈质量。系统在仿人双臂协作机器人上实现了六项复杂任务，并进行了用户研究。

Result: 用户研究表明，该系统在人机工程和用户接受度方面显著优于现有方案，六项任务的成功率提升最多达28.89%，任务完成时间加速26.81%。

Conclusion: CaFe-TeleVision系统通过创新的分层控制与沉浸式可视化，显著提升了远程操作的效率和用户体验，为高难度机器人操作提供了有效工具。

Abstract: Teleoperation presents a promising paradigm for remote control and robot proprioceptive data collection. Despite recent progress, current teleoperation systems still suffer from limitations in efficiency and ergonomics, particularly in challenging scenarios. In this paper, we propose CaFe-TeleVision, a coarse-to-fine teleoperation system with immersive situated visualization for enhanced ergonomics. At its core, a coarse-to-fine control mechanism is proposed in the retargeting module to bridge workspace disparities, jointly optimizing efficiency and physical ergonomics. To stream immersive feedback with adequate visual cues for human vision systems, an on-demand situated visualization technique is integrated in the perception module, which reduces the cognitive load for multi-view processing. The system is built on a humanoid collaborative robot and validated with six challenging bimanual manipulation tasks. User study among 24 participants confirms that CaFe-TeleVision enhances ergonomics with statistical significance, indicating a lower task load and a higher user acceptance during teleoperation. Quantitative results also validate the superior performance of our system across six tasks, surpassing comparative methods by up to 28.89% in success rate and accelerating by 26.81% in completion time. Project webpage: https://clover-cuhk.github.io/cafe_television/

</details>


### [157] [ARCADE: Adaptive Robot Control with Online Changepoint-Aware Bayesian Dynamics Learning](https://arxiv.org/abs/2512.14331)
*Rishabh Dev Yadav,Avirup Das,Hongyu Song,Samuel Kaski,Wei Pan*

Main category: cs.RO

TL;DR: 本文提出了一种能够实时适应动态变化的机器人动力学建模框架，并通过变化点检测提升了模型对长期与突发变化的鲁棒性和响应能力。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的机器人经常遇到操作条件变化、外部扰动和未建模效应，这些因素会导致机器人动力学随时间不断演化，需要鲁棒且灵敏的实时自适应能力。现有方法通常在面对波动或突变时表现有限，难以同时兼顾模型的不确定性校准和对变化的快速响应。

Method: 该方法将表示学习和在线自适应解耦，先线下学习动力学潜在表征，再用该表征支持流数据条件下的在线贝叶斯闭式更新；引入了变化点感知机制，通过一个潜变量根据数据似然推断系统是否处于连续态或已发生变化；在连续状态下，证据累积分步改进预测；发生变化时，弱化旧信息以实现快速再学习；全过程维持不确定性校准，支持对不同变化类型的概率推理。

Result: 从理论上，框架的自适应遗憾只随时间对数增长、随变化次数线性增长，达到与提前知变化时机的“神谕”算法相当的竞争水平；实验证明在cartpole和真实四旋翼负载变动场景下，该方法有更高预测精度、更快恢复速度、闭环跟踪表现也超过了相关基线方法。

Conclusion: 本文方法有效提升了机器人动力学模型对非平稳环境的适应与预测能力，在实际和仿真任务中的性能优势显著，为复杂动态环境下的机器人自主决策提供了有力技术支撑。

Abstract: Real-world robots must operate under evolving dynamics caused by changing operating conditions, external disturbances, and unmodeled effects. These may appear as gradual drifts, transient fluctuations, or abrupt shifts, demanding real-time adaptation that is robust to short-term variation yet responsive to lasting change. We propose a framework for modeling the nonlinear dynamics of robotic systems that can be updated in real time from streaming data. The method decouples representation learning from online adaptation, using latent representations learned offline to support online closed-form Bayesian updates. To handle evolving conditions, we introduce a changepoint-aware mechanism with a latent variable inferred from data likelihoods that indicates continuity or shift. When continuity is likely, evidence accumulates to refine predictions; when a shift is detected, past information is tempered to enable rapid re-learning. This maintains calibrated uncertainty and supports probabilistic reasoning about transient, gradual, or structural change. We prove that the adaptive regret of the framework grows only logarithmically in time and linearly with the number of shifts, competitive with an oracle that knows timings of shift. We validate on cartpole simulations and real quadrotor flights with swinging payloads and mid-flight drops, showing improved predictive accuracy, faster recovery, and more accurate closed-loop tracking than relevant baselines.

</details>


### [158] [Field evaluation and optimization of a lightweight lidar-based UAV navigation system for dense boreal forest environments](https://arxiv.org/abs/2512.14340)
*Aleksi Karhunen,Teemu Hakala,Väinö Karjalainen,Eija Honkavaara*

Main category: cs.RO

TL;DR: 本文利用轻量级激光雷达与开源算法，开发并优化了森林林下无人机自主飞行系统，通过93次实地飞行，显著提升了系统在不同密度森林中的任务完成率，并提出了标准化测试和评估体系。


<details>
  <summary>Details</summary>
Motivation: 当前林下无人机自主飞行缺乏系统性测评和详实、可重复的试验，影响算法和系统的进步，因此有必要建立标准化测试体系并提升林下飞行自主性。

Method: 搭建基于轻量级激光雷达、IPC路径规划和LTA-OM SLAM算法的四旋翼原型机，先进行33次初步测试并分析优化，后进行60次优化系统的实飞实验，并采用统一的测试环境和成绩统计标准。

Result: 优化后的系统在1 m/s目标速度下，中等密度森林成功率为12/15，密林为15/15；2 m/s速度下分别为12/15和5/15。同时建立了标准测试环境与评价标准。

Conclusion: 优化后的林下无人机系统有效提升了航行稳定性和任务完成效率，提出的标准化测试与评价方法有助于推动林下无人机和森林机器人领域的研发进步。

Abstract: The interest in the usage of uncrewed aerial vehicles (UAVs) for forest applications has increased in recent years. While above-canopy flight has reached a high level of autonomy, navigating under-canopy remains a significant challenge. The use of autonomous UAVs could reduce the burden of data collection, which has motivated the development of numerous solutions for under-canopy autonomous flight. However, the experiments conducted in the literature and their reporting lack rigor. Very rarely, the density and the difficulty of the test forests are reported, or multiple flights are flown, and the success rate of those flights is reported. The aim of this study was to implement an autonomously flying quadrotor based on a lightweight lidar using openly available algorithms and test its behavior in real forest environments. A set of rigorous experiments was conducted with a quadrotor prototype utilizing the IPC path planner and LTA-OM SLAM algorithm. Based on the results of the first 33 flights, the original system was further enhanced. With the optimized system, 60 flights were performed, resulting in a total of 93 test flights. The optimized system performed significantly better in terms of reliability and flight mission completion times, achieving success rates of 12/15 in a medium-density forest and 15/15 in a dense forest, at a target flight velocity of 1 m/s. At a target flight velocity of 2 m/s, it had a success rate of 12/15 and 5/15, respectively. Furthermore, a standardized testing setup and evaluation criteria were proposed, enabling consistent performance comparisons of autonomous under-canopy UAV systems, enhancing reproducibility, guiding system improvements, and accelerating progress in forest robotics.

</details>


### [159] [Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization](https://arxiv.org/abs/2512.14350)
*Henrik Hose,Paul Brunzema,Alexander von Rohr,Alexander Gräfe,Angela P. Schoellig,Sebastian Trimpe*

Main category: cs.RO

TL;DR: 本论文提出用贝叶斯优化自动微调AMPC参数，无需手工操作或重复训练，有效改善实际部署效率。


<details>
  <summary>Details</summary>
Motivation: AMPC虽可避免实时求解优化问题，但每次调整MPC超参数时仍需重生成数据集并重训练网络，导致应用不便。现有无须重训练的参数微调方法又需人工操作，且对高维系统难以实现。

Method: 作者提出基于实验数据，用贝叶斯优化自动调整AMPC参数。结合模型控制和局部直接学习，无需手动调参或大规模实验即可优化性能。

Result: 在倒立小车和自平衡独轮车硬件实验中，所提方法无需额外实验，显著优于普通AMPC的实绩。

Conclusion: 本方法能高效、自动地适应AMPC到新系统实例，同时微调难以明确建模的代价函数，在实际极具应用价值。

Abstract: Approximate model-predictive control (AMPC) aims to imitate an MPC's behavior with a neural network, removing the need to solve an expensive optimization problem at runtime. However, during deployment, the parameters of the underlying MPC must usually be fine-tuned. This often renders AMPC impractical as it requires repeatedly generating a new dataset and retraining the neural network. Recent work addresses this problem by adapting AMPC without retraining using approximated sensitivities of the MPC's optimization problem. Currently, this adaption must be done by hand, which is labor-intensive and can be unintuitive for high-dimensional systems. To solve this issue, we propose using Bayesian optimization to tune the parameters of AMPC policies based on experimental data. By combining model-based control with direct and local learning, our approach achieves superior performance to nominal AMPC on hardware, with minimal experimentation. This allows automatic and data-efficient adaptation of AMPC to new system instances and fine-tuning to cost functions that are difficult to directly implement in MPC. We demonstrate the proposed method in hardware experiments for the swing-up maneuver on an inverted cartpole and yaw control of an under-actuated balancing unicycle robot, a challenging control problem.

</details>


### [160] [CoLD Fusion: A Real-time Capable Spline-based Fusion Algorithm for Collective Lane Detection](https://arxiv.org/abs/2512.14355)
*Jörg Gamerdinger,Sven Teufel,Georg Volk,Oliver Bringmann*

Main category: cs.RO

TL;DR: 本文提出了一种基于车与车之间通信，实现车道集体感知的方法，通过样条估计对未检测到的道路段进行补全，并证明该方法能够实时运行并将感知范围扩展至原本的2倍。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车的安全运行依赖于全面的环境感知，然而在真实场景中由于传感器感知范围有限、道路曲线或被遮挡等原因，对周围环境的全面感知难以实现，尤其在没有高精度地图或定位不准确时，车辆只能依赖自身感知。因此，提升感知范围和准确性成为亟需解决的问题。

Method: 提出一种基于车对车通信的集体感知算法，不同车辆通过共享感知信息，并结合样条曲线方法，对部分感知盲区的道路（如车道线）进行估计和补全，实现整体感知范围的提升。该算法具备实时运算能力。

Result: 在多种道路场景下对该融合算法进行了评估，取得了实时性能，并且集体感知方案可将车辆的道路感知范围提升最高达200%。

Conclusion: 基于车对车通信的集体车道感知方法有效提升了路面信息的覆盖率和精确性，为缺失高精地图或定位不佳的自动驾驶场景提供了切实可行的补充感知方案。

Abstract: Comprehensive environment perception is essential for autonomous vehicles to operate safely. It is crucial to detect both dynamic road users and static objects like traffic signs or lanes as these are required for safe motion planning. However, in many circumstances a complete perception of other objects or lanes is not achievable due to limited sensor ranges, occlusions, and curves. In scenarios where an accurate localization is not possible or for roads where no HD maps are available, an autonomous vehicle must rely solely on its perceived road information. Thus, extending local sensing capabilities through collective perception using vehicle-to-vehicle communication is a promising strategy that has not yet been explored for lane detection. Therefore, we propose a real-time capable approach for collective perception of lanes using a spline-based estimation of undetected road sections. We evaluate our proposed fusion algorithm in various situations and road types. We were able to achieve real-time capability and extend the perception range by up to 200%.

</details>


### [161] [A Comprehensive Safety Metric to Evaluate Perception in Autonomous Systems](https://arxiv.org/abs/2512.14367)
*Georg Volk,Jörg Gamerdinger,Alexander von Bernuth,Oliver Bringmann*

Main category: cs.RO

TL;DR: 本文提出了一种新的安全评估指标，用于对自动驾驶车辆的目标感知能力进行更全面的安全性考量。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶环境感知的准确性对车辆安全至关重要。现有目标感知评估方法未充分考虑目标的重要性差异（如速度、距离、体积、朝向、碰撞潜在伤害等），为交通安全带来潜在风险。

Method: 作者提出了一种新型安全度量，将目标的速度、距离、体积、朝向以及碰撞潜在伤害等多维参数融合，生成单一、易于解释的安全性评估分数。该指标在虚拟与真实世界数据集上进行了实验，并与现有主流评估方法进行了对比。

Result: 新度量指标能综合反映与目标相关的多种风险因素，在各类数据集上的表现优于传统度量方法，评估结果更加贴合实际交通安全需求。

Conclusion: 新安全指标能够为自动驾驶车辆的目标感知能力提供更全面、直观的安全评价，有助于推动自动驾驶系统安全性提升。

Abstract: Complete perception of the environment and its correct interpretation is crucial for autonomous vehicles. Object perception is the main component of automotive surround sensing. Various metrics already exist for the evaluation of object perception. However, objects can be of different importance depending on their velocity, orientation, distance, size, or the potential damage that could be caused by a collision due to a missed detection. Thus, these additional parameters have to be considered for safety evaluation. We propose a new safety metric that incorporates all these parameters and returns a single easily interpretable safety assessment score for object perception. This new metric is evaluated with both real world and virtual data sets and compared to state of the art metrics.

</details>


### [162] [Synthetic Data Pipelines for Adaptive, Mission-Ready Militarized Humanoids](https://arxiv.org/abs/2512.14411)
*Mohammed Ayman Habib,Aldo Petruzzelli*

Main category: cs.RO

TL;DR: Omnia提出了一套基于合成数据的流程，加速军事化仿生机器人训练和部署，通过从多种第一视角数据生成高保真仿真场景，实现更高效的感知、导航和决策能力开发。


<details>
  <summary>Details</summary>
Motivation: 仿生机器人在实际部署中面临高昂、耗时且有风险的实地测试需求，难以及时适应不同作战环境与威胁。该工作旨在利用合成数据，解决真实性数据获取不足、开发周期长的问题。

Method: 通过收集来自第一视角录制、智能眼镜、增强现实头显和空间浏览等的空间观测数据，自动生成大量合成场景，并实现自动标注和模型训练，支持快速迭代与场景条件调整。

Result: 该流程能够快速生成可针对不同任务、环境和威胁条件调优的大规模数据集，提高仿生机器人在感知、导航、决策和专用任务（如多模态感知、敌我生存、侦查等）方面的表现。

Conclusion: Omnia流程能缩短军事化仿生机器人的开发周期，提升其在复杂环境下的鲁棒性和任务适应性，加速高级自主系统的实用化进程。

Abstract: Omnia presents a synthetic data driven pipeline to accelerate the training, validation, and deployment readiness of militarized humanoids. The approach converts first-person spatial observations captured from point-of-view recordings, smart glasses, augmented reality headsets, and spatial browsing workflows into scalable, mission-specific synthetic datasets for humanoid autonomy. By generating large volumes of high-fidelity simulated scenarios and pairing them with automated labeling and model training, the pipeline enables rapid iteration on perception, navigation, and decision-making capabilities without the cost, risk, or time constraints of extensive field trials. The resulting datasets can be tuned quickly for new operational environments and threat conditions, supporting both baseline humanoid performance and advanced subsystems such as multimodal sensing, counter-detection survivability, and CBRNE-relevant reconnaissance behaviors. This work targets faster development cycles and improved robustness in complex, contested settings by exposing humanoid systems to broad scenario diversity early in the development process.

</details>


### [163] [Odyssey: An Automotive Lidar-Inertial Odometry Dataset for GNSS-denied situations](https://arxiv.org/abs/2512.14428)
*Aaron Kurda,Simon Steuernagel,Lukas Jung,Marcus Baum*

Main category: cs.RO

TL;DR: Odyssey 数据集专注于GNSS失效环境（如隧道、地下停车场等），通过RLG-INS精确获取地面真实数据，为LIO和SLAM等算法研究提供支持。


<details>
  <summary>Details</summary>
Motivation: 现有用于Lidar-Inertial Odometry (LIO) 和SLAM系统开发的数据集，对GNSS信号缺失的持续环境支持不足，且常用IMU精度有限，难以持久准确地评估算法性能。

Method: 构建了包含多种GNSS失效场景（如隧道、停车场、颠簸路段等）的数据集，并用高精度环形激光陀螺仪（RLG）导航级惯导系统（INS）作为地面真实数据获取来源。同时对每条轨迹重复三次，便于研究场所识别等任务。

Result: Odyssey成为第一个公开可用、基于RLG-INS的LIO数据集，并覆盖许多现有数据集未涉及但实际常见的复杂环境。数据集还附带精确的地理坐标，便于融合外部地图用于多种研究。

Conclusion: Odyssey数据集极大扩展了LIO和SLAM系统在实际复杂GNSS失效场景下的研究基础，为后续多项基于精确导航地面真实数据的研究任务（如定位、场所识别和多传感器地图融合）提供重要资源和支撑。

Abstract: The development and evaluation of Lidar-Inertial Odometry (LIO) and Simultaneous Localization and Mapping (SLAM) systems requires a precise ground truth. The Global Navigation Satellite System (GNSS) is often used as a foundation for this, but its signals can be unreliable in obstructed environments due to multi-path effects or loss-of-signal. While existing datasets compensate for the sporadic loss of GNSS signals by incorporating Inertial Measurement Unit (IMU) measurements, the commonly used Micro-Electro-Mechanical Systems (MEMS) or Fiber Optic Gyroscope (FOG)-based systems do not permit the prolonged study of GNSS-denied environments. To close this gap, we present Odyssey, a LIO dataset with a focus on GNSS-denied environments such as tunnels and parking garages as well as other underrepresented, yet ubiquitous situations such as stop-and-go-traffic, bumpy roads and wide open fields. Our ground truth is derived from a navigation-grade Inertial Navigation System (INS) equipped with a Ring Laser Gyroscope (RLG), offering exceptional bias stability characteristics compared to IMUs used in existing datasets and enabling the prolonged and accurate study of GNSS-denied environments. This makes Odyssey the first publicly available dataset featuring a RLG-based INS. Besides providing data for LIO, we also support other tasks, such as place recognition, through the threefold repetition of all trajectories as well as the integration of external mapping data by providing precise geodetic coordinates. All data, dataloader and other material is available online at https://odyssey.uni-goettingen.de/ .

</details>


### [164] [Geometric Parameter Optimization of a Novel 3-(PP(2-(UPS))) Redundant Parallel Mechanism based on Workspace Determination](https://arxiv.org/abs/2512.14434)
*Quan Yuan,Daqian Cao,Weibang Bai*

Main category: cs.RO

TL;DR: 本文提出了一种新型冗余并联机器人3-(PP(2-(UPS)))机构，并深入分析其关键几何参数对工作空间和方向能力的影响，提出了定量评估指标，并进行仿真验证。


<details>
  <summary>Details</summary>
Motivation: 冗余并联机器人常用于对精度、载重、工作空间有较高要求的场合，但其基本构型和参数优化具有挑战性。因此，有必要开发通用性好、性能优异的新型冗余并联机构，并探索其参数优化方法。

Method: 提出一种新型3-(PP(2-(UPS)))冗余并联机构，分析其关键几何参数对工作空间体积、形状、边界完整性和方向能力的影响。定义了扭转能力指标TI_1和倾斜能力指标TI_2来评估机构的姿态性能，并通过数值仿真验证分析结果。

Result: 通过仿真研究，揭示了关键几何参数对机构工作空间及方向能力的具体影响，为参数优化提供理论依据。所定义的性能指标能够有效评估机构的方向能力。

Conclusion: 该方法为3-(PP(2-(UPS)))机构及类似冗余并联机构的参数优化提供了合理和必要的参考，对相关机构的设计和应用具有指导意义。

Abstract: Redundant parallel robots are normally employed in scenarios requiring good precision, high load capability, and large workspace compared to traditional parallel mechanisms. However, the elementary robotic configuration and geometric parameter optimization are still quite challenging. This paper proposes a novel 3-(PP(2-(UPS))) redundant parallel mechanism, with good generalizability first, and further investigates the kinematic optimization issue by analyzing and investigating how its key geometric parameters influence the volume, shape, boundary completeness, and orientation capabilities of its workspace. The torsional capability index TI_1 and tilting capability index TI_2 are defined to evaluate the orientation performance of the mechanism. Numerical simulation studies are completed to indicate the analysis, providing reasonable but essential references for the parameter optimization of 3-(PP(2-(UPS))) and other similar redundant parallel mechanisms.

</details>


### [165] [EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models](https://arxiv.org/abs/2512.14666)
*Zechen Bai,Chen Gao,Mike Zheng Shou*

Main category: cs.RO

TL;DR: 本文提出EVOLVE-VLA框架，使视觉-语言-动作（VLA）模型能在极少甚至无任务演示的条件下，通过与环境交互持续自适应学习，克服了传统监督微调（SFT）模型在泛化、适应性上的局限。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在机器人操作上尽管有进展，但受限于需要大量演示、轨迹僵化和缺乏部署自适应能力，难以像人一样通过实践自我完善。作者希望让模型能像人练习技能一样，通过持续与环境交互自我进步。

Method: 提出EVOLVE-VLA测试时训练框架，引入自主进度估计器替代不可获得的奖励信号，并通过累计进度估计和平滑机制，以及逐步拓展决策视野（progressive horizon extension）的方法，减弱进度信号的噪声，使模型能在无任务特定监督奖励下自主学习。

Result: EVOLVE-VLA在长任务上提升8.6%，在单例学习上提升22%，并且在从未见过的任务上无需演示即可获得20.8%的成功率（传统SFT模型为0%）。质性分析显示该方法还带来了演示数据中未出现的能力，比如错误恢复和策略创新。

Conclusion: EVOLVE-VLA使VLA模型摆脱了被动模仿与静态监督的局限，能够通过环境交互实现持续自我改进，朝向具备真实自适应智能的机器人迈出关键一步。

Abstract: Achieving truly adaptive embodied intelligence requires agents that learn not just by imitating static demonstrations, but by continuously improving through environmental interaction, which is akin to how humans master skills through practice. Vision-Language-Action (VLA) models have advanced robotic manipulation by leveraging large language models, yet remain fundamentally limited by Supervised Finetuning (SFT): requiring hundreds of demonstrations per task, rigidly memorizing trajectories, and failing to adapt when deployment conditions deviate from training. We introduce EVOLVE-VLA, a test-time training framework enabling VLAs to continuously adapt through environment interaction with minimal or zero task-specific demonstrations. The key technical challenge is replacing oracle reward signals (unavailable at test time) with autonomous feedback. We address this through a learned progress estimator providing dense feedback, and critically, we design our framework to ``tame'' this inherently noisy signal via two mechanisms: (1) an accumulative progress estimation mechanism smoothing noisy point-wise estimates, and (2) a progressive horizon extension strategy enabling gradual policy evolution. EVOLVE-VLA achieves substantial gains: +8.6\% on long-horizon tasks, +22.0\% in 1-shot learning, and enables cross-task generalization -- achieving 20.8\% success on unseen tasks without task-specific demonstrations training (vs. 0\% for pure SFT). Qualitative analysis reveals emergent capabilities absent in demonstrations, including error recovery and novel strategies. This work represents a critical step toward VLAs that truly learn and adapt, moving beyond static imitation toward continuous self-improvements.

</details>


### [166] [CHIP: Adaptive Compliance for Humanoid Control through Hindsight Perturbation](https://arxiv.org/abs/2512.14689)
*Sirui Chen,Zi-ang Cao,Zhengyi Luo,Fernando Castañeda,Chenran Li,Tingwu Wang,Ye Yuan,Linxi "Jim" Fan,C. Karen Liu,Yuke Zhu*

Main category: cs.RO

TL;DR: 本文提出了一种名为CHIP的控制模块，使人形机器人能够在保持运动灵活性的同时，实现多种高强度操作任务。


<details>
  <summary>Details</summary>
Motivation: 尽管人形机器人已具备复杂灵活的运动技能，但在执行如推拉、擦拭等需要力量操作的任务时，仍面临执行端刚度与运动灵活性难以兼顾的挑战。

Method: 作者提出了一种名为CHIP的控制模块，通过perturbation技术调节末端执行器的刚性，实现对其柔顺性的自适应调控。该方法无需数据增强或额外的奖励调参，易于集成到现有系统中。

Result: 实验表明，集成CHIP的通用运动跟踪控制器能够成功胜任协作、擦拭、递送和开门等多种需要不同柔顺性的高强度操作任务。

Conclusion: CHIP方法为人形机器人的复杂物理交互任务提供了一种高效、通用且易用的解决方案，显著拓展了其应用范围。

Abstract: Recent progress in humanoid robots has unlocked agile locomotion skills, including backflipping, running, and crawling. Yet it remains challenging for a humanoid robot to perform forceful manipulation tasks such as moving objects, wiping, and pushing a cart. We propose adaptive Compliance Humanoid control through hIsight Perturbation (CHIP), a plug-and-play module that enables controllable end-effector stiffness while preserving agile tracking of dynamic reference motions. CHIP is easy to implement and requires neither data augmentation nor additional reward tuning. We show that a generalist motion-tracking controller trained with CHIP can perform a diverse set of forceful manipulation tasks that require different end-effector compliance, such as multi-robot collaboration, wiping, box delivery, and door opening.

</details>


### [167] [WAM-Flow: Parallel Coarse-to-Fine Motion Planning via Discrete Flow Matching for Autonomous Driving](https://arxiv.org/abs/2512.06112)
*Yifang Xu,Jiahao Cui,Feipeng Cai,Zhihao Zhu,Hanlin Shang,Shan Luan,Mingwang Xu,Neng Zhang,Yaoyi Li,Jia Cai,Siyu Zhu*

Main category: cs.RO

TL;DR: 提出了WAM-Flow，一种新颖的视觉-语言-动作（VLA）模型，通过离散流匹配实现端到端自动驾驶的轨迹规划，并在重要基准上优于传统模型。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归解码器在自动驾驶轨迹规划中效率不高，无法满足灵活性和并行性需求。作者希望通过新的流匹配方法提升推理效率与性能。

Method: WAM-Flow将自车轨迹规划建模为结构化token空间上的离散流匹配。其关键技术包括：数值tokenizer通过triplet-margin学习对标量几何信息进行保持，几何感知的流目标，融合多重奖励（安全、进度、乘坐舒适）且维持并行生成的GRPO对齐；并且将预训练自回归模型（Janus-1.5B）转换为非因果流模型并持续多模态预训练。

Result: 在NAVSIM v1基准上，1步推理取得89.1 PDMS，5步推理达到90.3 PDMS，显著优于自回归和扩散式VLA基线模型。

Conclusion: 离散流匹配被证实是一种极具前景的端到端自动驾驶轨迹规划新范式，WAM-Flow在闭环评测中取得优越表现，未来代码将公开。

Abstract: We introduce WAM-Flow, a vision-language-action (VLA) model that casts ego-trajectory planning as discrete flow matching over a structured token space. In contrast to autoregressive decoders, WAM-Flow performs fully parallel, bidirectional denoising, enabling coarse-to-fine refinement with a tunable compute-accuracy trade-off. Specifically, the approach combines a metric-aligned numerical tokenizer that preserves scalar geometry via triplet-margin learning, a geometry-aware flow objective and a simulator-guided GRPO alignment that integrates safety, ego progress, and comfort rewards while retaining parallel generation. A multi-stage adaptation converts a pre-trained auto-regressive backbone (Janus-1.5B) from causal decoding to non-causal flow model and strengthens road-scene competence through continued multimodal pretraining. Thanks to the inherent nature of consistency model training and parallel decoding inference, WAM-Flow achieves superior closed-loop performance against autoregressive and diffusion-based VLA baselines, with 1-step inference attaining 89.1 PDMS and 5-step inference reaching 90.3 PDMS on NAVSIM v1 benchmark. These results establish discrete flow matching as a new promising paradigm for end-to-end autonomous driving. The code will be publicly available soon.

</details>
