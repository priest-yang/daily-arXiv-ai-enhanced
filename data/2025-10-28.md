<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 210]
- [cs.CL](#cs.CL) [Total: 114]
- [cs.RO](#cs.RO) [Total: 73]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Diagnosing Bottlenecks in Data Visualization Understanding by Vision-Language Models](https://arxiv.org/abs/2510.21740)
*Alexa R. Tartaglini,Satchel Grant,Daniel Wurgaft,Christopher Potts,Judith E. Fan*

Main category: cs.CV

TL;DR: 本文分析了当前视觉-语言模型（VLM）在数据可视化理解任务中的表现，发现其在基础任务上仍有明显不足，并通过新开发的FUGU任务集追踪了错误原因。主要发现模型在视觉信息与语言信息衔接时存在信息丢失，且对复杂统计关系提取能力有限。


<details>
  <summary>Details</summary>
Motivation: 虽然VLMs被广泛应用于图表和可视化的自动理解，但它们在面对数据可视化相关的基本问题时表现不佳。本文希望明确这种失败的根本原因，是视觉感知的局限、视觉与语言之间的信息传递，还是语言模块内部的信息处理不足，从而为提升模型能力指明方向。

Method: 作者开发了FUGU数据集，设计了一系列任务用于细致评估和定位VLM处理数据可视化的难点，并分析三个主流VLM的表现。通过激活修补和线性探针等方法，跟踪和诊断模型内部信息流动及错误来源，评估输入正确坐标后对模型表现的影响，并测试通过FUGU微调后的效果。

Result: 研究发现，模型经常无法正确生成数据点坐标，并且坐标错误会连带影响最终回答。但即使最终回答错误，模型视觉编码的潜在表示中往往还包含正确坐标，指向视觉-语言模块交接处存在性能瓶颈。同时，输入正确坐标有助于少量数据点任务，但对涉及全局统计关系的任务则反而有害。此外，仅靠数据集微调无法显著改善其极限表现。

Conclusion: 目前VLM在数据可视化理解方面存在架构性的局限，主要问题在于视觉与语言段的信息交接，且对复杂统计的抽取存在劣势，这为未来设计更可靠的数据可视化理解系统提供了启示。

Abstract: Data visualizations are vital components of many scientific articles and news
stories. Current vision-language models (VLMs) still struggle on basic data
visualization understanding tasks, but the causes of failure remain unclear.
Are VLM failures attributable to limitations in how visual information in the
data visualization is encoded, how information is transferred between the
vision and language modules, or how information is processed within the
language module? We developed FUGU, a suite of data visualization understanding
tasks, to precisely characterize potential sources of difficulty (e.g.,
extracting the position of data points, distances between them, and other
summary statistics). We used FUGU to investigate three widely used VLMs. To
diagnose the sources of errors produced by these models, we used activation
patching and linear probes to trace information flow through models across a
variety of prompting strategies. We found that some models fail to generate the
coordinates of individual data points correctly, and these initial errors often
lead to erroneous final responses. When these models are provided with the
correct coordinates, performance improves substantially. Moreover, even when
the model generates an incorrect response, the correct coordinates can be
successfully read out from the latent representations in the vision encoder,
suggesting that the source of these errors lies in the vision-language handoff.
We further found that while providing correct coordinates helps with tasks
involving one or a small number of data points, it generally worsens
performance for tasks that require extracting statistical relationships across
many data points. Fine-tuning models on FUGU also fails to yield ceiling
performance. These findings point to architectural constraints in current VLMs
that might pose significant challenges for reliable data visualization
understanding.

</details>


### [2] [Agro-Consensus: Semantic Self-Consistency in Vision-Language Models for Crop Disease Management in Developing Countries](https://arxiv.org/abs/2510.21757)
*Mihir Gupta,Pratik Desai,Ross Greer*

Main category: cs.CV

TL;DR: 本文提出了一种经济高效的自一致性框架，用于提升农业领域视觉-语言模型（VLM）在图像描述任务中的可靠性，特别适用于发展中国家资源受限的场景。


<details>
  <summary>Details</summary>
Motivation: 在印度、肯尼亚和尼日利亚等发展中国家，农业病害管理因专家短缺、网络不稳定及成本约束，难以采用大规模AI系统。本研究旨在解决如何在低成本条件下提升农业图像诊断系统的可靠性。

Method: 方法包括使用一个轻量级预训练嵌入模型（仅80MB）进行语义聚类，将多条候选描述分组，并基于余弦相似度共识挑选出包括诊断、症状、分析、治疗和预防建议的最连贯描述。同时引入人工参与环节，通过用户确认作物类型过滤错误生成，提升最终输入描述的质量。该方法在PlantVillage公开数据集上，用微调后的3B参数PaliGemma模型进行实验。

Result: 在800张作物病害图片的实验中，单聚类共识方法在每图像生成10条候选描述时，将准确率提升到83.1%，优于贪婪解码的77.5%。考虑多聚类后，只要前4个聚类中有正确答案，准确率可达94.0%，高于基线方法的88.5%。

Conclusion: 所提自一致性框架无需大型算力和稳定网络，便可显著提升农业VLM图像诊断的可靠性和实用性，为资源有限地区提供了更切实际的智能农业解决方案。

Abstract: Agricultural disease management in developing countries such as India, Kenya,
and Nigeria faces significant challenges due to limited access to expert plant
pathologists, unreliable internet connectivity, and cost constraints that
hinder the deployment of large-scale AI systems. This work introduces a
cost-effective self-consistency framework to improve vision-language model
(VLM) reliability for agricultural image captioning. The proposed method
employs semantic clustering, using a lightweight (80MB) pre-trained embedding
model to group multiple candidate responses. It then selects the most coherent
caption -- containing a diagnosis, symptoms, analysis, treatment, and
prevention recommendations -- through a cosine similarity-based consensus. A
practical human-in-the-loop (HITL) component is incorporated, wherein user
confirmation of the crop type filters erroneous generations, ensuring
higher-quality input for the consensus mechanism. Applied to the publicly
available PlantVillage dataset using a fine-tuned 3B-parameter PaliGemma model,
our framework demonstrates improvements over standard decoding methods.
Evaluated on 800 crop disease images with up to 21 generations per image, our
single-cluster consensus method achieves a peak accuracy of 83.1% with 10
candidate generations, compared to the 77.5% baseline accuracy of greedy
decoding. The framework's effectiveness is further demonstrated when
considering multiple clusters; accuracy rises to 94.0% when a correct response
is found within any of the top four candidate clusters, outperforming the 88.5%
achieved by a top-4 selection from the baseline.

</details>


### [3] [Proportion and Perspective Control for Flow-Based Image Generation](https://arxiv.org/abs/2510.21763)
*Julien Boudier,Hugo Caselles-Dupré*

Main category: cs.CV

TL;DR: 本文提出了两种专为艺术创作控制设计的ControlNet：一种基于边界框控制物体位置与比例，另一种基于消失线进行透视几何控制。实验表明，两者可提升对图像结构的操控，但在处理复杂约束时仍有限制。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型虽然可以生成高质量图像，但对输出图像的空间与几何结构可控性较弱。为了增强对生成图像结构的艺术控制，引入专门的方法。

Method: 提出了两种新的ControlNet模块：（1）比例ControlNet，利用边界框标注对象的位置和尺度；（2）透视ControlNet，利用消失线控制场景的三维几何结构。数据标注通过视觉-语言模型和专用算法完成。

Result: 实验表明，这两种ControlNet可以实现对图像空间结构的有效控制，但在处理复杂或高度组合性的约束时仍有一定局限性。

Conclusion: 本文的方法改进了文本到图像生成的可控性，为艺术创作带来新工具；两种ControlNet已开源，便于社区使用和改进，但未来仍需解决对复杂结构的更精细控制问题。

Abstract: While modern text-to-image diffusion models generate high-fidelity images,
they offer limited control over the spatial and geometric structure of the
output. To address this, we introduce and evaluate two ControlNets specialized
for artistic control: (1) a proportion ControlNet that uses bounding boxes to
dictate the position and scale of objects, and (2) a perspective ControlNet
that employs vanishing lines to control the 3D geometry of the scene. We
support the training of these modules with data pipelines that leverage
vision-language models for annotation and specialized algorithms for
conditioning image synthesis. Our experiments demonstrate that both modules
provide effective control but exhibit limitations with complex constraints.
Both models are released on HuggingFace:
https://huggingface.co/obvious-research

</details>


### [4] [H2OFlow: Grounding Human-Object Affordances with 3D Generative Models and Dense Diffused Flows](https://arxiv.org/abs/2510.21769)
*Harry Zhang,Luca Carlone*

Main category: cs.CV

TL;DR: 本文提出了H2OFlow，一种无需人工标注、利用生成式模型合成数据学习人-物体三维交互适用性的系统。它不仅关注于接触，还涵盖了朝向和空间占据，通过点云扩散学习3D流，实现更全面的3D适用性理解，并在真实场景中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有关于人-物体三维交互（3D HOI）和适用性（affordance）推理的方法高度依赖劳动力密集且昂贵的人工标注数据，并且大多仅关注接触点，忽略了朝向和空间占据这些对理解实际人-物关系至关重要的方面。

Method: 作者提出H2OFlow框架，仅使用3D生成模型合成的点云数据，不需要人工标注。方法基于稠密3D流表示，通过点云上扩散模型学习，能捕捉接触、朝向和空间占据等三维行为，发掘丰富的交互适应性。

Result: 定量和定性的广泛实验结果显示，H2OFlow能泛化到真实物体，在三维适用性建模上优于以往依赖人工标注或网格表示的方法。

Conclusion: H2OFlow创新性地实现了无需人工标注、全面理解三维人-物适用性的目标，提升了三维交互推理的自动化水平，有望推进相关CV、机器人与AI领域的发展。

Abstract: Understanding how humans interact with the surrounding environment, and
specifically reasoning about object interactions and affordances, is a critical
challenge in computer vision, robotics, and AI. Current approaches often depend
on labor-intensive, hand-labeled datasets capturing real-world or simulated
human-object interaction (HOI) tasks, which are costly and time-consuming to
produce. Furthermore, most existing methods for 3D affordance understanding are
limited to contact-based analysis, neglecting other essential aspects of
human-object interactions, such as orientation (\eg, humans might have a
preferential orientation with respect certain objects, such as a TV) and
spatial occupancy (\eg, humans are more likely to occupy certain regions around
an object, like the front of a microwave rather than its back). To address
these limitations, we introduce \emph{H2OFlow}, a novel framework that
comprehensively learns 3D HOI affordances -- encompassing contact, orientation,
and spatial occupancy -- using only synthetic data generated from 3D generative
models. H2OFlow employs a dense 3D-flow-based representation, learned through a
dense diffusion process operating on point clouds. This learned flow enables
the discovery of rich 3D affordances without the need for human annotations.
Through extensive quantitative and qualitative evaluations, we demonstrate that
H2OFlow generalizes effectively to real-world objects and surpasses prior
methods that rely on manual annotations or mesh-based representations in
modeling 3D affordance.

</details>


### [5] [OCR-Quality: A Human-Annotated Dataset for OCR Quality Assessment](https://arxiv.org/abs/2510.21774)
*Yulong Zhang*

Main category: cs.CV

TL;DR: 本文提出了OCR-Quality数据集，这是一个人类标注的OCR质量评估数据集，包含1000页来自不同场景的PDF页面，适用于OCR质量评测与相关系统的开发。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏全面且公开的人为标注的OCR质量评估数据，限制了OCR系统评测和改进的发展，因此需要一个多样且高质量的基准数据集支撑相关研究。

Method: 作者采集了来自学术论文、教材、电子书和多语言文档的PDF页面，转换为高分辨率PNG图片，并用最先进的视觉-语言模型处理，再由人工采用4级评分体系进行质量打分，附有详细标注指南和代表性案例。

Result: 最终构建了包含1000页、涵盖多种文档类型和难度的OCR-Quality数据集，为OCR质量评估和系统验证提供了高质量的基准。数据集及其详细说明已在Huggingface平台公开。

Conclusion: OCR-Quality数据集为实际应用中的OCR质量评估提供了可靠资源，有助于推动OCR验证系统的训练和评测，是该领域基础性的重要贡献。

Abstract: We present OCR-Quality, a comprehensive human-annotated dataset designed for
evaluating and developing OCR quality assessment methods. The dataset consists
of 1,000 PDF pages converted to PNG images at 300 DPI, sampled from diverse
real-world scenarios, including academic papers, textbooks, e-books, and
multilingual documents. Each document has been processed using state-of-the-art
Vision-Language Models (VLMs) and manually annotated with quality scores using
a 4-level scoring system (1: Excellent, 2: Good, 3: Fair, 4: Poor). The dataset
includes detailed source information, annotation guidelines, and representative
cases across various difficulty levels. OCR-Quality addresses the critical need
for reliable OCR quality assessment in real-world applications and provides a
valuable benchmark for training and evaluating OCR verification systems. The
dataset is publicly available at
https://huggingface.co/datasets/Aslan-mingye/OCR-Quality .

</details>


### [6] [Face-MakeUpV2: Facial Consistency Learning for Controllable Text-to-Image Generation](https://arxiv.org/abs/2510.21775)
*Dawei Dai,Yinxiu Zhou,Chenghang Li,Guolai Jiang,Chengfang Zhang*

Main category: cs.CV

TL;DR: Face-MakeUpV2是一种新的人脸图像生成模型，解决了现有文本到图像模型在人脸属性泄露和物理一致性不足的问题，实现了更可靠、可控的人脸编辑。


<details>
  <summary>Details</summary>
Motivation: 现有文本驱动的人脸图像生成模型，难以保持与参考图像在身份和物理特征上的一致，局部语义指令下尤为突出，易产生属性泄露和一致性差的问题。

Method: 1）构建大规模FaceCaptionMask-1M数据集（约百万级图文掩码三元组），为局部语义指令提供空间监督；2）以通用文本到图像预训练模型为基础，增加3D人脸渲染通道和全局人脸特征通道，分别引入物理特征和全局特征信息；3）设计语义对齐和感知损失两个优化目标，前者缓解属性泄露，后者提升ID一致性。

Result: 大量实验表明，该方法在人脸身份保持和物理一致性方面性能最佳，超越现有的方法，证明了其实用潜力。

Conclusion: Face-MakeUpV2在保持人脸ID、物理一致性方面表现突出，显示出在人脸可控编辑等多种应用场景下的广阔前景。

Abstract: In facial image generation, current text-to-image models often suffer from
facial attribute leakage and insufficient physical consistency when responding
to local semantic instructions. In this study, we propose Face-MakeUpV2, a
facial image generation model that aims to maintain the consistency of face ID
and physical characteristics with the reference image. First, we constructed a
large-scale dataset FaceCaptionMask-1M comprising approximately one million
image-text-masks pairs that provide precise spatial supervision for the local
semantic instructions. Second, we employed a general text-to-image pretrained
model as the backbone and introduced two complementary facial information
injection channels: a 3D facial rendering channel to incorporate the physical
characteristics of the image and a global facial feature channel. Third, we
formulated two optimization objectives for the supervised learning of our
model: semantic alignment in the model's embedding space to mitigate the
attribute leakage problem and perceptual loss on facial images to preserve ID
consistency. Extensive experiments demonstrated that our Face-MakeUpV2 achieves
best overall performance in terms of preserving face ID and maintaining
physical consistency of the reference images. These results highlight the
practical potential of Face-MakeUpV2 for reliable and controllable facial
editing in diverse applications.

</details>


### [7] [Ageing Drift in Binary Face Templates: A Bits-per-Decade Analysis](https://arxiv.org/abs/2510.21778)
*Abdelilah Ganmati,Karim Afdel,Lahcen Koutti*

Main category: cs.CV

TL;DR: 本文研究了紧凑型人脸模板的随年龄漂移现象，并量化了人脸特征二进制码随年龄增长的变化。结果发现，二进制码越长，年龄相关漂移越明显。


<details>
  <summary>Details</summary>
Motivation: 人脸识别系统在实际应用中的长期稳定性至关重要，但个体人脸特征随年龄变化会影响认证性能。作者希望定量分析和理解人脸模板随年龄变化的稳定性，指导模板设计和部署策略。

Method: 将现代CNN人脸特征通过PCA-ITQ方法分别压缩为64位和128位二进制编码。利用AgeDB数据集中有三种年龄的个体，计算同一人的不同年龄图片间所有配对的汉明距离，并拟合距离与年龄差之间的线性模型，统计漂移速率（单位：bit/十年），并采用自助法计算置信区间。进一步分析不同年龄段下识别性能指标（EER与TPR@FAR=1%），并讨论漂移对智能卡等实际部署的影响。

Result: 共有566名满足条件的个体。64位模板的中位漂移速率为每十年1.357 bit，128位为2.571 bit，均值大多为正，表明模板内部距离随年龄差略有增加。代码长度越短，模板对年龄变化越具稳定性。EER和TPR数据进一步揭示识别性能随年龄变化的细节。

Conclusion: 压缩码越短，则人脸模板更能抵御随年龄增长导致的识别性能下降。为实际应用，建议通过周期性重新注册或对不稳定位实施校验以增强系统稳定性。提供了实验代码和数据以支持结果复现。

Abstract: We study the longitudinal stability of compact binary face templates and
quantify ageing drift directly in bits per decade. Float embeddings from a
modern face CNN are compressed with PCA-ITQ into 64- and 128-bit codes. For
each identity in AgeDB with at least three distinct ages, we form all genuine
pairs and fit a per-identity linear model of Hamming distance versus absolute
age gap. Across 566 identities, the median slope is 1.357 bits per decade for
64-bit templates and 2.571 bits per decade for 128-bit templates, with tight
non-parametric 95 percent bootstrap confidence intervals. The distributions are
predominantly positive, indicating a small but systematic increase in
intra-class distance over time. Because drift scales with code length, shorter
codes are inherently more age-stable at a fixed decision threshold. We connect
these slopes to operating characteristics by reporting EER and TPR at FAR = 1
percent in three age bins. We discuss implications for smart-card and
match-on-card deployments, including simple mitigations such as periodic
re-enrolment and targeted parity on empirically unstable bit positions. Code
and CSV artifacts are provided to support reproducibility.

</details>


### [8] [Bridging Accuracy and Interpretability: Deep Learning with XAI for Breast Cancer Detection](https://arxiv.org/abs/2510.21780)
*Bishal Chhetri,B. V. Rathish Kumar*

Main category: cs.CV

TL;DR: 本研究提出了一种可解释的深度学习框架，用于利用细针穿刺（FNA）图像量化特征实现乳腺癌的早期检测，并在多项指标上超越现有方法，同时结合可解释性技术提升临床可行性。


<details>
  <summary>Details</summary>
Motivation: 传统使用深度学习进行乳腺癌检测虽然准确率高，但由于模型不可解释性，难以获得临床医生的信任与采用，需要在保证高性能的同时提升模型的可解释性。

Method: 构建基于ReLU激活、Adam优化器和二元交叉熵损失的深度神经网络，提取FNA图像量化特征，并与多种经典机器学习算法对比。采用SHAP和LIME等模型无关的可解释AI方法，为每个特征和预测提供可视化解释，辅助理解模型决策。

Result: 模型达到0.992的准确率、1.000的精准率、0.977的召回率和0.988的F1分数，显著优于传统算法。SHAP等解释模型揭示“细胞核凹点”特征对分类贡献最大。

Conclusion: 该方法在保障高检测性能的同时，大幅提升模型决策的可解释性，为乳腺癌的诊断和临床应用提供了可行和信任的技术路径。同时，关键特征的识别也为病理诊断和治疗提供新线索。

Abstract: In this study, we present an interpretable deep learning framework for the
early detection of breast cancer using quantitative features extracted from
digitized fine needle aspirate (FNA) images of breast masses. Our deep neural
network, using ReLU activations, the Adam optimizer, and a binary cross-entropy
loss, delivers state-of-the-art classification performance, achieving an
accuracy of 0.992, precision of 1.000, recall of 0.977, and an F1 score of
0.988. These results substantially exceed the benchmarks reported in the
literature. We evaluated the model under identical protocols against a suite of
well-established algorithms (logistic regression, decision trees, random
forests, stochastic gradient descent, K-nearest neighbors, and XGBoost) and
found the deep model consistently superior on the same metrics. Recognizing
that high predictive accuracy alone is insufficient for clinical adoption due
to the black-box nature of deep learning models, we incorporated model-agnostic
Explainable AI techniques such as SHAP and LIME to produce feature-level
attributions and human-readable visualizations. These explanations quantify the
contribution of each feature to individual predictions, support error analysis,
and increase clinician trust, thus bridging the gap between performance and
interpretability for real-world clinical use. The concave points feature of the
cell nuclei is found to be the most influential feature positively impacting
the classification task. This insight can be very helpful in improving the
diagnosis and treatment of breast cancer by highlighting the key
characteristics of breast tumor.

</details>


### [9] [EdgeSync: Accelerating Edge-Model Updates for Data Drift through Adaptive Continuous Learning](https://arxiv.org/abs/2510.21781)
*Runchu Donga,Peng Zhao,Guiqin Wang,Nan Qi,Jie Lin*

Main category: cs.CV

TL;DR: 论文介绍了一种名为EdgeSync的新方法，用于提升边缘设备上视频分析模型的准确性和更新效率。


<details>
  <summary>Details</summary>
Motivation: 现有实时视频分析系统通常在边缘设备上部署轻量模型以降低延迟，但由于环境变化（如光照或天气），输入分布会变化，导致模型准确率下降。已有解决办法如云端辅助更新模型，但存在计算开销高、延迟大和适应性差等问题。

Method: 作者提出EdgeSync方法，通过结合时效性和推理结果进行样本筛选，选取更贴近视频当前内容的训练样本，减少模型更新延迟。同时，EdgeSync拥有动态训练管理模块，可智能调度模型更新时机，提高更新及时性。

Result: 在多个复杂真实数据集上的实验显示，EdgeSync方法比已有方法准确率提升约3.4%，比传统方式提升约10%。

Conclusion: EdgeSync有效提升了边缘视频分析模型的及时更新能力和识别准确率，是边缘视频分析领域的有意义进展。

Abstract: Real-time video analytics systems typically deploy lightweight models on edge
devices to reduce latency. However, the distribution of data features may
change over time due to various factors such as changing lighting and weather
conditions, leading to decreased model accuracy. Recent frameworks try to
address this issue by leveraging remote servers to continuously train and adapt
lightweight edge models using more complex models in the cloud. Despite these
advancements, existing methods face two key challenges: first, the retraining
process is compute-intensive, causing significant delays in model updates;
second, the new model may not align well with the evolving data distribution of
the current video stream. To address these challenges, we introduce EdgeSync,
an efficient edge-model updating approach that enhances sample filtering by
incorporating timeliness and inference results, thus ensuring training samples
are more relevant to the current video content while reducing update delays.
Additionally, EdgeSync features a dynamic training management module that
optimizes the timing and sequencing of model updates to improve their
timeliness. Evaluations on diverse and complex real-world datasets demonstrate
that EdgeSync improves accuracy by approximately 3.4% compared to existing
methods and by about 10% compared to traditional approaches.

</details>


### [10] [Promptable Fire Segmentation: Unleashing SAM2's Potential for Real-Time Mobile Deployment with Strategic Bounding Box Guidance](https://arxiv.org/abs/2510.21782)
*Emmanuel U. Ugwu,Zhang Xinming*

Main category: cs.CV

TL;DR: 本文评估了Segment Anything Model (SAM) 及其移动端变体在火焰分割任务中的表现，发现基于边界框的提示方法最佳，轻量化模型适合边缘端部署。


<details>
  <summary>Details</summary>
Motivation: 火焰分割具有不规则边界、半透明边缘和强度变化大等挑战。虽然SAM模型在跨领域分割中表现良好，但其在火焰分割、尤其是移动部署方面的适用性尚未系统研究。

Method: 论文系统评估了4种SAM2.1变体（tiny、small、base_plus、large）和2种移动端变体（TinySAM、MobileSAM）在3个火焰数据集上的分割性能。比较了多种提示方式（自动、单点、点+负点、多点、边界框和混合提示）。

Result: 实验表明，边界框提示法普遍优于自动和单点提示，Box+MP组合在Khan 数据集上获得最高的 mIoU（0.64）和 Dice（0.75）。轻量化变体显著降低运行成本，适合作为边缘端方案。

Conclusion: 本文为火焰监测系统中提示分割模型的部署提供了基准和关键见解，同时为以后面向特定领域的SAM 应用研究奠定了基础。

Abstract: Fire segmentation remains a critical challenge in computer vision due to
flames' irregular boundaries, translucent edges, and highly variable
intensities. While the Segment Anything Models (SAM and SAM2) have demonstrated
impressive cross-domain generalization capabilities, their effectiveness in
fire segmentation -- particularly under mobile deployment constraints --
remains largely unexplored. This paper presents the first comprehensive
evaluation of SAM2 variants for fire segmentation, focusing on bounding box
prompting strategies to enhance deployment feasibility. We systematically
evaluate four SAM2.1 variants (tiny, small, base_plus, large) alongside
mobile-oriented variants (TinySAM, MobileSAM) across three fire datasets using
multiple prompting strategies: automatic, single positive point (SP), single
positive point + single negative point (SP+SN), multiple positive points (MP),
bounding box (Box), and hybrid variants (Box+SP and Box+MP). Our experimental
results demonstrate that bounding box prompts consistently outperform automatic
and single point-based approaches, with Box+MP achieving the highest mean IoU
(0.64) and Dice coefficient (0.75) on the Khan dataset. Lightweight variants
such as TinySAM and MobileSAM further reduce memory and computational costs,
making them more suitable for latency-tolerant edge scenarios. Overall, this
work provides critical insights for deploying promptable segmentation models in
fire monitoring systems and establishes benchmarks for future research in
domain-specific SAM applications. Code is available at:
https://github.com/UEmmanuel5/ProFSAM

</details>


### [11] [Noise Aggregation Analysis Driven by Small-Noise Injection: Efficient Membership Inference for Diffusion Models](https://arxiv.org/abs/2510.21783)
*Guo Li,Yuyang Yu,Xuemiao Xu*

Main category: cs.CV

TL;DR: 本文提出了一种高效针对扩散模型（如Stable Diffusion）的成员推理攻击方法，通过噪声注入和噪声分布凝聚度分析，有效识别模型训练数据成员，且比现有方法更高效、更具扩展性。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型在高质量图像生成领域的广泛应用，用户隐私泄露风险增加。尤其是成员推理攻击会揭示某个样本是否参与了模型训练，亟需研究相关隐私安全性问题及攻击方法。

Method: 作者提出通过向待测图像注入轻微噪声，并分析扩散模型预测噪声的分布凝聚度来实施成员推理攻击。方法核心在于区分训练集样本与非训练集样本在特定扩散步骤下噪声预测的聚合与离散特性。只需少量模型访问即可完成攻击。

Result: 实验表明，该方法在多个数据集上均取得了优越表现。在大规模文本到图像扩散模型上也展现出更好的攻击效果（如ASR和AUC指标），显示了方法的扩展性。

Conclusion: 作者提出的方法不仅高效且对扩散模型具有良好适应性和可扩展性，能够有效识别模型训练数据成员，对扩散模型的隐私风险评估和防护具有指导意义。

Abstract: Diffusion models have demonstrated powerful performance in generating
high-quality images. A typical example is text-to-image generator like Stable
Diffusion. However, their widespread use also poses potential privacy risks. A
key concern is membership inference attacks, which attempt to determine whether
a particular data sample was used in the model training process. We propose an
efficient membership inference attack method against diffusion models. This
method is based on the injection of slight noise and the evaluation of the
aggregation degree of the noise distribution. The intuition is that the noise
prediction patterns of diffusion models for training set samples and
non-training set samples exhibit distinguishable differences.Specifically, we
suppose that member images exhibit higher aggregation of predicted noise around
a certain time step of the diffusion process. In contrast, the predicted noises
of non-member images exhibit a more discrete characteristic around the certain
time step. Compared with other existing methods, our proposed method requires
fewer visits to the target diffusion model. We inject slight noise into the
image under test and then determine its membership by analyzing the aggregation
degree of the noise distribution predicted by the model. Empirical findings
indicate that our method achieves superior performance across multiple
datasets. At the same time, our method can also show better attack effects in
ASR and AUC when facing large-scale text-to-image diffusion models, proving the
scalability of our method.

</details>


### [12] [Multi-Agent Pose Uncertainty: A Differentiable Rendering Cramér-Rao Bound](https://arxiv.org/abs/2510.21785)
*Arun Muthukkumar*

Main category: cs.CV

TL;DR: 本文提出了一种结合可微渲染器的姿态估计不确定性下界新方法，通过对姿态扰动线性化，实现了与传统视觉理论兼容的闭式下界推导，可推广至多摄像机和多智能体情境。


<details>
  <summary>Details</summary>
Motivation: 当前姿态估计广泛应用于计算机视觉与机器人，但大多相关方法缺乏对基于稠密或学习模型的姿态估计不确定性进行严格量化的研究，限制了其理论严谨性和实际应用安全性。为提升姿态估计方法的可靠性和通用性，亟需严密的不确定性度量工具。

Method: 作者将可微分渲染器视为测量函数，对图像生成过程关于姿态扰动进行线性化，推导出render-aware Cramér-Rao Bound（CRB）。该统计下界可回溯到传统bundle-adjustment方法，并能通过Fisher信息融合拓展到多摄像机/多智能体情境。

Result: 方法得到了姿态估计协方差的闭式下界，有效结合了可微渲染和传统模型，且能无须显式关键点对应，适用于多个摄像头联合或多智能体知觉等复杂场景。

Conclusion: 该方法为基于稠密或学习模型的姿态估计提供了理论严密的不确定性量化工具，拓宽了感知、合作和新视角合成等下游应用场景的理论基础和实际应用方式。

Abstract: Pose estimation is essential for many applications within computer vision and
robotics. Despite its uses, few works provide rigorous uncertainty
quantification for poses under dense or learned models. We derive a closed-form
lower bound on the covariance of camera pose estimates by treating a
differentiable renderer as a measurement function. Linearizing image formation
with respect to a small pose perturbation on the manifold yields a render-aware
Cram\'er-Rao bound. Our approach reduces to classical bundle-adjustment
uncertainty, ensuring continuity with vision theory. It also naturally extends
to multi-agent settings by fusing Fisher information across cameras. Our
statistical formulation has downstream applications for tasks such as
cooperative perception and novel view synthesis without requiring explicit
keypoint correspondences.

</details>


### [13] [EventFormer: A Node-graph Hierarchical Attention Transformer for Action-centric Video Event Prediction](https://arxiv.org/abs/2510.21786)
*Qile Su,Shoutai Zhu,Shuai Zhang,Baoyu Liang,Chao Tong*

Main category: cs.CV

TL;DR: 本文提出了AVEP任务，专注于视频中更复杂语义和逻辑的事件预测，并发布了大规模结构化数据集和新的预测模型EventFormer，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统脚本事件预测侧重于文本领域，但现实中事件多以视频形式记录，现有视觉领域相关研究稀缺。本文旨在推动视频事件预测领域发展，引入更丰富、复杂的结构化任务。

Method: 1. 提出AVEP任务，区别于以往的视频预测任务，更关注事件之间的复杂逻辑和语义关系。
2. 构建包含约35000条标注视频、超过178000个事件片段的大型结构化数据集，采用多模态事件节点粒度进行精细注释。
3. 基于节点-图分层注意力机制，提出EventFormer模型，能够捕捉事件与参数间关系以及参数的共指关系。
4. 在数据集上评测若干主流SOTA视频预测模型和大规模视觉-语言模型（LVLMs）。

Result: 实验结果显示，AVEP任务具有高度挑战性。EventFormer模型在数据集上表现超越所有现有视频预测模型，验证了任务难度和数据集的价值。

Conclusion: 本文首次提出事件为中心的视频事件预测任务并提供了大规模高质量数据集和领先方法，对视觉事件理解领域具有推动作用。数据集和代码将公开，有助于相关研究进一步发展。

Abstract: Script event induction, which aims to predict the subsequent event based on
the context, is a challenging task in NLP, achieving remarkable success in
practical applications. However, human events are mostly recorded and presented
in the form of videos rather than scripts, yet there is a lack of related
research in the realm of vision. To address this problem, we introduce AVEP
(Action-centric Video Event Prediction), a task that distinguishes itself from
existing video prediction tasks through its incorporation of more complex logic
and richer semantic information. We present a large structured dataset, which
consists of about $35K$ annotated videos and more than $178K$ video clips of
event, built upon existing video event datasets to support this task. The
dataset offers more fine-grained annotations, where the atomic unit is
represented as a multimodal event argument node, providing better structured
representations of video events. Due to the complexity of event structures,
traditional visual models that take patches or frames as input are not
well-suited for AVEP. We propose EventFormer, a node-graph hierarchical
attention based video event prediction model, which can capture both the
relationships between events and their arguments and the coreferencial
relationships between arguments. We conducted experiments using several SOTA
video prediction models as well as LVLMs on AVEP, demonstrating both the
complexity of the task and the value of the dataset. Our approach outperforms
all these video prediction models. We will release the dataset and code for
replicating the experiments and annotations.

</details>


### [14] [Mismatch reconstruction theory for unknown measurement matrix in imaging through multimode fiber bending](https://arxiv.org/abs/2510.21787)
*Le Yang*

Main category: cs.CV

TL;DR: 本文针对多模光纤成像中测量矩阵未知导致无法重构图像的问题，提出了基于失配重构理论的新方法。通过实验验证，在低噪声下能成功重构原图像，并分析了算法鲁棒性和局限性。


<details>
  <summary>Details</summary>
Motivation: 实际应用中，由于系统信息不明或光纤弯曲后的难以实时校准，传统成像算法需要的测量矩阵通常难以获得，导致图像重构失败。

Method: 提出失配方程，设计了配对求解和校准算法，通过这些方法在未知测量矩阵情况下重建新的测量矩阵，并为这些理论和算法提供了详细证明。

Result: 实验表明，在低噪声水平下，所构造的测量矩阵能够在传统重构算法中成功配对并重构原始图像。同时分析了噪声、计算精度和正交性对性能的影响，发现算法具备一定鲁棒性。

Conclusion: 新提出的失配重构理论为测量矩阵未知条件下的多模光纤成像提供了可行的图像重构方法，具有一定的应用前景和鲁棒性，但也存在一定局限。

Abstract: Multimode fiber imaging requires strict matching between measurement value
and measurement matrix to achieve image reconstruction. However, in practical
applications, the measurement matrix often cannot be obtained due to unknown
system configuration or difficulty in real-time alignment after arbitrary fiber
bending, resulting in the failure of traditional reconstruction algorithms.
This paper presents a novel mismatch reconstruction theory for solving the
problem of image reconstruction when measurement matrix is unknown. We first
propose mismatch equation and design matched and calibration solution
algorithms to construct a new measurement matrix. In addition, we also provide
a detailed proof of these equations and algorithms in the appendix. The
experimental results show that under low noise levels, constructed matrix can
be used for matched pair in traditional reconstruction algorithms, and
reconstruct the original image successfully. Then, we analyze the impact of
noise, computational precision and orthogonality on reconstruction performance.
The results show that proposed algorithms have a certain degree of robustness.
Finally, we discuss the limitations and potential applications of this theory.
The code is available: https://github.com/yanglebupt/mismatch-solution.

</details>


### [15] [Exploring the design space of diffusion and flow models for data fusion](https://arxiv.org/abs/2510.21791)
*Niraj Chaudhari,Manmeet Singh,Naveen Sudharsan,Amit Kumar Srivastava,Harsh Kamath,Dushyant Mahajan,Ayan Paul*

Main category: cs.CV

TL;DR: 本文研究了数据融合中的扩散和流模型，重点应用于卫星遥感多源数据（如DMSP-OLS与VIIRS夜间灯光数据）的集成。通过对多种生成模型（包括UNET、扩散模型和流模型）进行评估，发现基于UNet的扩散模型在空间细节保留和高质量融合图像生成上表现最佳。此外，探讨了噪声调度策略与量化技术对性能和效率的影响，并提出了具体应用建议。


<details>
  <summary>Details</summary>
Motivation: 多源卫星遥感数据融合能提升时空分辨率与数据质量，但不同模型在融合效果、效率及资源消耗等方面优缺点不明，因此亟需系统对比并优化相关的生成模型及技术路径。尤其对于夜间灯光数据的高质量融合，有助于更好地理解和监测地表活动。

Method: 作者设计并实现了一系列2D图像生成模型（包括UNET、扩散模型、流模型），将其应用于DMSP-OLS与VIIRS夜间灯光数据融合。通过比较不同模型结构和噪声调度机制，以及对量化技术的实验，实现模型性能、图像质量、内存和计算效率的全面评估。

Result: 实验结果表明，基于UNet的扩散模型能够更好地保留细节并生成高保真融合图像。同时，噪声调度策略对融合质量与推理速度有显著影响，而合适的量化技术能在不降低表现的情况下优化模型资源消耗。

Conclusion: UNet为基础的扩散模型在卫星遥感数据融合中具有明显优势。针对不同应用需求，可权衡迭代解算器（提升速度）与离散调度器（提升质量）。同时，建议采用量化技术提高效率。研究为遥感数据融合模型选型和优化提供了实用指南。

Abstract: Data fusion is an essential task in various domains, enabling the integration
of multi-source information to enhance data quality and insights. One key
application is in satellite remote sensing, where fusing multi-sensor
observations can improve spatial and temporal resolution. In this study, we
explore the design space of diffusion and flow models for data fusion, focusing
on the integration of Defense Meteorological Satellite Program's Operational
Linescan System (DMSP-OLS) and Visible Infrared Imaging Radiometer Suite
(VIIRS) nighttime lights data. Our approach leverages a diverse set of 2D
image-to-image generative models, including UNET, diffusion, and flow modeling
architectures. We evaluate the effectiveness of these architectures in
satellite remote sensing data fusion, identifying diffusion models based on
UNet as particularly adept at preserving fine-grained spatial details and
generating high-fidelity fused images. We also provide guidance on the
selection of noise schedulers in diffusion-based models, highlighting the
trade-offs between iterative solvers for faster inference and discrete
schedulers for higher-quality reconstructions. Additionally, we explore
quantization techniques to optimize memory efficiency and computational cost
without compromising performance. Our findings offer practical insights into
selecting the most effective diffusion and flow model architectures for data
fusion tasks, particularly in remote sensing applications, and provide
recommendations for leveraging noise scheduling strategies to enhance fusion
quality.

</details>


### [16] [2D_3D Feature Fusion via Cross-Modal Latent Synthesis and Attention Guided Restoration for Industrial Anomaly Detection](https://arxiv.org/abs/2510.21793)
*Usman Ali,Ali Zia,Abdul Rehman,Umer Ramzan,Zohaib Hassan,Talha Sattar,Jing Wang,Wei Xiang*

Main category: cs.CV

TL;DR: 本文提出一种新的无监督多模态融合框架（MAFR），有效结合2D图像和3D点云实现工业异常检测，在多个基准数据集上取得新SOTA表现。


<details>
  <summary>Details</summary>
Motivation: 工业异常检测希望融合2D与3D数据提升检测能力，但两种模态间的稳健融合仍存在挑战。

Method: 作者提出MAFR框架，利用共享融合编码器从RGB图像和点云中合成统一潜在空间，然后通过注意力引导的模态特定解码器重建输入。异常定位方式基于输入与重建特征间的差异。

Result: 在MVTec 3D-AD和Eyecandies基准上分别取得0.972和0.901的I-AUROC，优于现有方法。少样本条件下依然表现优异，消融实验证实了融合结构和损失函数的重要性。

Conclusion: MAFR为视觉与几何信息融合提供了有效方案，显著提升了工业异常检测的稳健性和准确性。

Abstract: Industrial anomaly detection (IAD) increasingly benefits from integrating 2D
and 3D data, but robust cross-modal fusion remains challenging. We propose a
novel unsupervised framework, Multi-Modal Attention-Driven Fusion Restoration
(MAFR), which synthesises a unified latent space from RGB images and point
clouds using a shared fusion encoder, followed by attention-guided,
modality-specific decoders. Anomalies are localised by measuring reconstruction
errors between input features and their restored counterparts. Evaluations on
the MVTec 3D-AD and Eyecandies benchmarks demonstrate that MAFR achieves
state-of-the-art results, with a mean I-AUROC of 0.972 and 0.901, respectively.
The framework also exhibits strong performance in few-shot learning settings,
and ablation studies confirm the critical roles of the fusion architecture and
composite loss. MAFR offers a principled approach for fusing visual and
geometric information, advancing the robustness and accuracy of industrial
anomaly detection. Code is available at https://github.com/adabrh/MAFR

</details>


### [17] [Token-Level Inference-Time Alignment for Vision-Language Models](https://arxiv.org/abs/2510.21794)
*Kejia Chen,Jiawen Zhang,Jiacong Hu,Kewei Gao,Jian Lou,Zunlei Feng,Mingli Song*

Main category: cs.CV

TL;DR: 本文提出了一种名为TITA的轻量级推理时对齐方法，有效减少了视觉-语言模型(VLMs)生成幻觉（与图片内容不符文本）的现象，并且具有较低的推理开销。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型容易生成与图像内容无关的文本（幻觉），而主流的对齐方法通常需要高昂的标注数据微调或精度有限的推理机制。因此，亟需一种高效、无需重训练主模型且对齐粒度更细致的解决方案。

Method: TITA在不微调主模型的前提下，单独训练一个奖励模型来近似VLM的分布。在推理阶段，通过奖励模型和目标VLM的对数概率比获得token级反馈，实现即时的偏好对齐。这种方法等价于DPO的推理时变种，无需对主干网络重新训练。

Result: 在LLaVA-1.5-7B和13B等多项基准测试中，TITA方法分别在MMVet和POPE任务上取得了8.6%和6.7%的准确率提升。对Qwen2.5-VL-7B和DeepSeek-VL2-27.5B等其它模型也有类似效果，显著减少幻觉现象与提升VQA表现，几乎无额外推理负担。

Conclusion: TITA可在无需微调主模型的条件下，有效实现视觉-语言模型的更精细化对齐，大幅提升模型理解能力和输出准确性，有助于推动多模态智能系统可靠性的发展。

Abstract: Vision-Language Models (VLMs) have become essential backbones of modern
multimodal intelligence, yet their outputs remain prone to
hallucination-plausible text misaligned with visual inputs. Existing alignment
approaches often rely on expensive fine-tuning with annotated preference data
or sequence-level inference strategies that provide only coarse, delayed
feedback. To overcome these limitations, we present TITA (Token-level
Inference-Time Alignment), a lightweight framework that freezes the base VLM
and instead trains a reward model to approximate its distribution. During
inference, implicit preference signals are extracted as log-probability ratios
between the reward model and the target VLM, yielding dense autoregressive
feedback. This formulation can be viewed as an inference-time variant of Direct
Preference Optimization (DPO), providing token-level corrective signals without
retraining the backbone. Extensive evaluations on LLaVA-1.5-7B and 13B show
consistent gains across 12 benchmarks, with improvements of 8.6% on MMVet and
6.7% on POPE, indicating stronger general understanding and reduced
hallucinations. Additional experiments on Qwen2.5-VL-7B and DeepSeek-VL2-27.5B
show comparable gains, especially in hallucination reduction and VQA accuracy,
while incurring negligible inference overhead.

</details>


### [18] [Xihe: Scalable Zero-Shot Time Series Learner Via Hierarchical Interleaved Block Attention](https://arxiv.org/abs/2510.21795)
*Yinbo Sun,Yuchen Fang,Zhibo Zhu,Jia Li,Yu Liu,Qiwen Deng,Jun Zhou,Hang Yu,Xingyu Lu,Lintao Ma*

Main category: cs.CV

TL;DR: 本文提出了一种新的时序基础模型架构HIBA，并基于该架构开发了Xihe模型家族，在不同参数规模下均展现出优异的性能，尤其在零样本转移任务中表现突出，刷新了业内最佳结果。


<details>
  <summary>Details</summary>
Motivation: 当前时序基础模型多直接借用语言模型架构，难以有效捕捉时序数据固有的多尺度时序依赖性，尤其是在不同数据集或采样策略间的零样本迁移中表现不足。

Method: 提出层次交错块注意力机制（HIBA），结合块内稀疏注意力实现局部信息交换，以及块间注意力捕捉全局时序模式与动态演化，并基于此架构构建了Xihe系列模型，参数量覆盖9.5M至1.5B。

Result: 在GIFT-Eval基准上，Xihe-tiny（9.5M参数）超越多数现有模型，1.5B参数的Xihe-max在零样本任务中大幅刷新业界最佳表现，展现模型尺寸与性能的卓越兼容性。

Conclusion: HIBA及Xihe家族在不同参数规模下均展现强大泛化能力和架构优越性，为时序数据建模及跨场景迁移提供了新范式。

Abstract: The rapid advancement of time series foundation models (TSFMs) has been
propelled by migrating architectures from language models. While existing TSFMs
demonstrate impressive performance, their direct adoption of cross-domain
architectures constrains effective capture of multiscale temporal dependencies
inherent to time series data. This limitation becomes particularly pronounced
during zero-shot transfer across datasets with divergent underlying patterns
and sampling strategies. To address these challenges, we propose Hierarchical
Interleaved Block Attention (HIBA) which employs hierarchical inter- and
intra-block sparse attention to effectively capture multi-scale dependencies.
Intra-block attention facilitates local information exchange, and inter-block
attention operates across blocks to capture global temporal pattern interaction
and dynamic evolution. Leveraging the HIBA architecture, we introduce Xihe, a
scalable TSFM family spanning from an ultra-efficient 9.5M parameter
configuration to high-capacity 1.5B variant. Evaluated on the comprehensive
GIFT-Eval benchmark, our most compact Xihe-tiny model (9.5M) surpasses the
majority of contemporary TSFMs, demonstrating remarkable parameter efficiency.
More impressively, Xihe-max (1.5B) establishes new state-of-the-art zero-shot
performance, surpassing previous best results by a substantial margin. This
consistent performance excellence across the entire parameter spectrum provides
compelling evidence for the exceptional generalization capabilities and
architectural superiority of HIBA.

</details>


### [19] [AI-Boosted Video Annotation: Assessing the Process Enhancement](https://arxiv.org/abs/2510.21798)
*Juan Gutiérrez,Ángel Mora,Pablo Regodón,Silvia Rodriguez,José Luis Blanco*

Main category: cs.CV

TL;DR: 本研究通过将AI自动标注与人工参与结合，提升视频标注的效率和准确性。在UCF-Crime数据集实验中，AI辅助标注显著减少了人工时间，且保证了标注质量。


<details>
  <summary>Details</summary>
Motivation: 传统视频标注耗时且易受主观影响，难以高效获得高质量数据。作者希望借助AI提升标注效率，同时保留人工的判断力和灵活性。

Method: 采用基于Label Studio的平台和AI零样本自动预标注，为人工标注人员智能辅助。同时设立实验，在UCF-Crime数据集上对比手动标注和AI辅助标注效率与质量。

Result: 在视频标注任务中，70%的标注员通过AI预标注方案，标注时间减少了35%，同时标注质量与传统手动方法相当。各标注员间结果更一致，注释内容更符合视频帧的实际分布。

Conclusion: AI预标注与人工结合能有效提升视频标注流程的效率和一致性，减少人工负担，对大规模视频分析任务具有重要意义。

Abstract: We explore the enhancement of Human-in-the-Loop video annotation by
integrating automatic capabilities to ease the task for annotators and assess
their performance. The research delves into the practical implications of the
annotation processes, the integration of AI components, and the evaluation of
its outcomes. We analyze their impact on efficiency, accuracy, and overall
annotation quality. Focusing on the Human-in-the-Loop for video annotation
tasks, we implemented a single-iteration scheme using Label Studio and
AI-powered zero-shot pre-annotations. Using this framework, we designed a test
based on the annotation of the UCF-Crime dataset to discriminate between normal
and abnormal activities in video footage. Our results evidence how automatic
AI-based pre-annotation can streamline the video annotation workflow,
empowering human annotators and optimizing the overall pipeline. Using the
pre-annotated data, we observed a 35% reduction in the annotation time for 70%
of the annotators with similar quality annotations, compared to the traditional
manual annotation task. Results are consistent with asset duration and
complexity. We also observed that while annotators rapidly learned to use the
tool, the produced annotations are more coherent among annotators and better
match the natural clustering of the video frames.

</details>


### [20] [Morphology-Aware KOA Classification: Integrating Graph Priors with Vision Models](https://arxiv.org/abs/2510.21801)
*Marouane Tliba,Mohamed Amine Kerkouri,Yassine Nasser,Nour Aburaed,Aladine Chetouani,Ulas Bagci,Rachid Jennane*

Main category: cs.CV

TL;DR: 本文提出了一种将形态结构信息与放射学特征融合的新型多模态骨关节炎诊断方法，能显著提升影像诊断性能。


<details>
  <summary>Details</summary>
Motivation: 膝骨关节炎影像诊断存在细微形态差异深度模型难捕捉的问题，标准单模态算法难以有效识别和分级。

Method: 基于Segment Anything Model (SAM) 分割结果提取形态结构，构建图形表征，并与视觉编码器输出的放射学特征通过互信息最大化对齐，在OAI数据集上进行建模和评估。

Result: 该方法在OAI数据集的分类精度比单模态基线提升10%，达到近80%；优于当前最优方法，准确率和F1分数分别提升8%和11%。

Conclusion: 将明确的解剖结构信息纳入影像分析对于膝骨关节炎分级至关重要，该多模态方法有效提升了诊断准确性。

Abstract: Knee osteoarthritis (KOA) diagnosis from radiographs remains challenging due
to the subtle morphological details that standard deep learning models struggle
to capture effectively. We propose a novel multimodal framework that combines
anatomical structure with radiographic features by integrating a morphological
graph representation - derived from Segment Anything Model (SAM) segmentations
- with a vision encoder. Our approach enforces alignment between
geometry-informed graph embeddings and radiographic features through mutual
information maximization, significantly improving KOA classification accuracy.
By constructing graphs from anatomical features, we introduce explicit
morphological priors that mirror clinical assessment criteria, enriching the
feature space and enhancing the model's inductive bias. Experiments on the
Osteoarthritis Initiative dataset demonstrate that our approach surpasses
single-modality baselines by up to 10\% in accuracy (reaching nearly 80\%),
while outperforming existing state-of-the-art methods by 8\% in accuracy and
11\% in F1 score. These results underscore the critical importance of
incorporating anatomical structure into radiographic analysis for accurate KOA
severity grading.

</details>


### [21] [It Takes Two to Tango: Two Parallel Samplers Improve Quality in Diffusion Models for Limited Steps](https://arxiv.org/abs/2510.21802)
*Pedro Cisneros-Velarde*

Main category: cs.CV

TL;DR: 该论文提出了一种在扩散模型去噪步数受限时提升采样图像质量的方法，通过并行使用两个去噪采样器，并在关键时刻融合它们的信息，取得了更好的图像生成效果。该方法简单易用，无需模型微调或引入外部模型。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，扩散模型的计算资源有限，无法执行大量的去噪步骤，这会影响生成图像的质量。论文关注如何在步数有限情况下最大化样本质量。

Method: 将两个采样器（或处理器）并行工作，但在不同时间顺序进行去噪操作；关键在于如何在潜在空间中正确整合两者的信息。方法无需特别修改原有模型，也不需额外训练，属于即插即用型。

Result: 自动化和人工实验均显示，在有限去噪步数下，采用本文并行信息融合方法可以提升采样图像的质量。直接简单地对两采样器结果融合反而会降低质量，且增加并行采样器数量并不是越多越好。

Conclusion: 论文验证了在扩散模型下，合理并行两个采样器可在计算步数有限时提升生成效果，方法简单实用且具备广泛适用性，但并行采样器数量增加需有度，融合方式关键。

Abstract: We consider the situation where we have a limited number of denoising steps,
i.e., of evaluations of a diffusion model. We show that two parallel processors
or samplers under such limitation can improve the quality of the sampled image.
Particularly, the two samplers make denoising steps at successive times, and
their information is appropriately integrated in the latent image. Remarkably,
our method is simple both conceptually and to implement: it is plug-&-play,
model agnostic, and does not require any additional fine-tuning or external
models. We test our method with both automated and human evaluations for
different diffusion models. We also show that a naive integration of the
information from the two samplers lowers sample quality. Finally, we find that
adding more parallel samplers does not necessarily improve sample quality.

</details>


### [22] [Frame-Difference Guided Dynamic Region Perception for CLIP Adaptation in Text-Video Retrieval](https://arxiv.org/abs/2510.21806)
*Jiaao Yu,Mingjie Han,Tao Gong,Jian Zhang,Man Lan*

Main category: cs.CV

TL;DR: 该论文提出了一种名为FDA-CLIP的新方法，通过引入帧差动态特征，有效提升了文本-视频检索的准确性与效率。


<details>
  <summary>Details</summary>
Motivation: 当前文本-视频检索技术面临需大规模标注数据和跨模态特征对齐难题，现有方法对动态视频特征增强不足且静态冗余抑制能力有限。

Method: 提出FDA-CLIP方法，利用视频帧差生成动态区域掩码，并将其作为Alpha通道输入改进版CLIP模型，引导模型关注语义关键动态区域，抑制静态冗余背景。

Result: 实验表明，该方法能有效提升视频语义编码，在保证检索效率的同时显著提高检索准确率。

Conclusion: FDA-CLIP通过帧差引导的动态特征增强，实现了高效且精准的文本-视频对齐，为跨模态检索任务提供了新的解决方案。

Abstract: With the rapid growth of video data, text-video retrieval technology has
become increasingly important in numerous application scenarios such as
recommendation and search. Early text-video retrieval methods suffer from two
critical drawbacks: first, they heavily rely on large-scale annotated
video-text pairs, leading to high data acquisition costs; second, there is a
significant modal gap between video and text features, which limits cross-modal
alignment accuracy. With the development of vision-language model, adapting
CLIP to video tasks has attracted great attention. However, existing adaptation
methods generally lack enhancement for dynamic video features and fail to
effectively suppress static redundant features. To address this issue, this
paper proposes FDA-CLIP (Frame Difference Alpha-CLIP), which is a concise
CLIP-based training framework for text-video alignment. Specifically, the
method uses frame differences to generate dynamic region masks, which are input
into Alpha-CLIP as an additional Alpha channel. This proactively guides the
model to focus on semantically critical dynamic regions while suppressing
static background redundancy. Experiments demonstrate that frame
difference-guided video semantic encoding can effectively balance retrieval
efficiency and accuracy.

</details>


### [23] [Activating Visual Context and Commonsense Reasoning through Masked Prediction in VLMs](https://arxiv.org/abs/2510.21807)
*Jiaao Yu,Shenwei Li,Mingjie Han,Yifei Yin,Wenzheng Song,Chenghao Jia,Man Lan*

Main category: cs.CV

TL;DR: 该论文提出了一种新颖的微调任务Masked Prediction via Context and Commonsense（MPCC），要求模型通过视觉上下文和常识推理重建被遮挡图片的有意义内容，并提出了配套评测基准MPCC Eval，结合多种微调策略提升视觉-语言模型跨场景推理泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在推理任务上进步显著，但在实际视觉-语言多模态场景中的泛化能力有限，现有做法未能充分利用视觉上下文和常识知识，影响了多模态推理能力，因此需要新方法提升VLM的推理泛化能力。

Method: 提出Masked Prediction via Context and Commonsense微调任务，推动模型在重建被遮挡图像时融合视觉上下文与常识推理；设计MPCC Eval用于系统性评测推理能力，并探索多种微调策略，包括 Reinforcement Fine tuning with Prior Sampling创新训练法。

Result: 所提出的新训练方法显著提升了模型在OOD（分布外）和跨任务场景下的推理能力，实验在MPCC Eval等基准上验证了方法的有效性。

Conclusion: 通过结合视觉信息与常识推理的新型训练任务及创新微调方法，可以有效提升视觉-语言模型在多模态、多场景下的泛化推理能力。

Abstract: Recent breakthroughs in reasoning models have markedly advanced the reasoning
capabilities of large language models, particularly via training on tasks with
verifiable rewards. Yet, a significant gap persists in their adaptation to real
world multimodal scenarios, most notably, vision language tasks, due to a heavy
focus on single modal language settings. While efforts to transplant
reinforcement learning techniques from NLP to VLMs have emerged, these
approaches often remain confined to perception centric tasks or reduce images
to textual summaries, failing to fully exploit visual context and commonsense
knowledge, ultimately constraining the generalization of reasoning capabilities
across diverse multimodal environments. To address this limitation, we
introduce a novel fine tuning task, Masked Prediction via Context and
Commonsense, which forces models to integrate visual context and commonsense
reasoning by reconstructing semantically meaningful content from occluded
images, thereby laying the foundation for generalized reasoning. To
systematically evaluate the model performance in generalized reasoning, we
developed a specialized evaluation benchmark, MPCC Eval, and employed various
fine tuning strategies to guide reasoning. Among these, we introduced an
innovative training method, Reinforcement Fine tuning with Prior Sampling,
which not only enhances model performance but also improves its generalized
reasoning capabilities in OOD and cross task scenarios.

</details>


### [24] [Semantic Relation-Enhanced CLIP Adapter for Domain Adaptive Zero-Shot Learning](https://arxiv.org/abs/2510.21808)
*Jiaao Yu,Mingjie Han,Jinkun Jiang,Junyu Dong,Tao Gong,Man Lan*

Main category: cs.CV

TL;DR: 论文提出了SRE-CLIP，一种增强语义关系的CLIP适配器框架，有效提升了在领域自适应零样本学习（DAZSL）场景下的表现，取得了当前最优的实验结果。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在数据有限场景下表现受限，DAZSL任务中亟需同时解决跨域迁移与跨类别泛化问题。CLIP模型虽有潜力，但当前方法未能充分发挥其能力，尤其是在语义关系指导和跨模态对齐上存在瓶颈。

Method: 作者提出Semantic Relation-Enhanced CLIP (SRE-CLIP) Adapter框架，核心包括语义关系结构损失与跨模态对齐保留策略，旨在提升CLIP在DAZSL任务中的知识迁移和对齐效率。

Result: SRE-CLIP在I2AwA和I2WebV数据集上均取得了优异成绩，显著优于现有方法，且为首个基于CLIP的DAZSL方法。

Conclusion: SRE-CLIP充分挖掘了CLIP在DAZSL任务下的潜力，成为当前领域表现最优的方法，为领域自适应零样本学习提供了有效新思路。

Abstract: The high cost of data annotation has spurred research on training deep
learning models in data-limited scenarios. Existing paradigms, however, fail to
balance cross-domain transfer and cross-category generalization, giving rise to
the demand for Domain-Adaptive Zero-Shot Learning (DAZSL). Although
vision-language models (e.g., CLIP) have inherent advantages in the DAZSL
field, current studies do not fully exploit their potential. Applying CLIP to
DAZSL faces two core challenges: inefficient cross-category knowledge transfer
due to the lack of semantic relation guidance, and degraded cross-modal
alignment during target domain fine-tuning. To address these issues, we propose
a Semantic Relation-Enhanced CLIP (SRE-CLIP) Adapter framework, integrating a
Semantic Relation Structure Loss and a Cross-Modal Alignment Retention
Strategy. As the first CLIP-based DAZSL method, SRE-CLIP achieves
state-of-the-art performance on the I2AwA and I2WebV benchmarks, significantly
outperforming existing approaches.

</details>


### [25] [Embodied Navigation with Auxiliary Task of Action Description Prediction](https://arxiv.org/abs/2510.21809)
*Haru Kondoh,Asako Kanezaki*

Main category: cs.CV

TL;DR: 本论文提出在多模态机器人室内导航中，将动作描述的语言任务引入导航的强化学习作为辅助任务，以提升系统的可解释性，同时保持高性能。通过知识蒸馏，方法解决了动作描述缺少真实数据的问题，在多个导航任务上取得优异表现，并在语义音视导航任务上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 随着多模态机器人导航任务复杂度提升，决策系统趋于黑箱化，缺乏可解释性，而可解释性对于系统可靠性极为关键。传统上，可解释性的提升往往牺牲导航性能，因此需寻找新方法以兼顾两者。

Method: 将动作描述的语言生成任务作为强化学习导航的辅助任务，利用知识蒸馏从预训练视觉-语言模型引导描述模块，以弥补动作描述缺少标注数据的难题。最终在不同导航任务中进行系统性评估。

Result: 所提方法能有效生成多模态导航动作说明，同时保持较高的导航性能。在语义音视导航这一极具挑战的任务上，性能达到当前最优。

Conclusion: 该研究实现导航智能体在执行决策时自动生成自然语言解释，兼顾高性能和可解释性，为多模态导航领域提供了新的技术思路。

Abstract: The field of multimodal robot navigation in indoor environments has garnered
significant attention in recent years. However, as tasks and methods become
more advanced, the action decision systems tend to become more complex and
operate as black-boxes. For a reliable system, the ability to explain or
describe its decisions is crucial; however, there tends to be a trade-off in
that explainable systems can not outperform non-explainable systems in terms of
performance. In this paper, we propose incorporating the task of describing
actions in language into the reinforcement learning of navigation as an
auxiliary task. Existing studies have found it difficult to incorporate
describing actions into reinforcement learning due to the absence of
ground-truth data. We address this issue by leveraging knowledge distillation
from pre-trained description generation models, such as vision-language models.
We comprehensively evaluate our approach across various navigation tasks,
demonstrating that it can describe actions while attaining high navigation
performance. Furthermore, it achieves state-of-the-art performance in the
particularly challenging multimodal navigation task of semantic audio-visual
navigation.

</details>


### [26] [Hybrid Deep Learning Framework for Enhanced Diabetic Retinopathy Detection: Integrating Traditional Features with AI-driven Insights](https://arxiv.org/abs/2510.21810)
*Arpan Maity,Aviroop Pal,MD. Samiul Islam,Tamal Ghosh*

Main category: cs.CV

TL;DR: 本文提出了一种结合传统特征提取与深度学习的混合诊断框架，以提升糖尿病视网膜病变（DR）的检测效果。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变早期无明显症状，若未及时发现会导致不可逆的视力损失。印度作为糖尿病大国，面临巨大筛查压力，因此亟需高效、准确、可扩展的DR筛查方法。

Method: 采用多模态AI算法，将传统人工特征和深度学习自动提取的特征结合。人工特征便于解释关键的临床标志，深度学习擅长自动识别复杂的图像模式，两者互补，可提升DR检测的灵敏度和准确性。

Result: 这种混合模型在DR分类和减少漏检（假阴性）率方面表现优于仅用深度学习方法。

Conclusion: 该方案为糖尿病高发地区的大规模、精准筛查提供了可行技术路径，有助于早期发现和干预DR，防止不可逆的视力丧失。

Abstract: Diabetic Retinopathy (DR), a vision-threatening complication of Dia-betes
Mellitus (DM), is a major global concern, particularly in India, which has one
of the highest diabetic populations. Prolonged hyperglycemia damages reti-nal
microvasculature, leading to DR symptoms like microaneurysms, hemor-rhages, and
fluid leakage, which, if undetected, cause irreversible vision loss. Therefore,
early screening is crucial as DR is asymptomatic in its initial stages. Fundus
imaging aids precise diagnosis by detecting subtle retinal lesions. This paper
introduces a hybrid diagnostic framework combining traditional feature
extraction and deep learning (DL) to enhance DR detection. While handcrafted
features capture key clinical markers, DL automates hierarchical pattern
recog-nition, improving early diagnosis. The model synergizes interpretable
clinical data with learned features, surpassing standalone DL approaches that
demon-strate superior classification and reduce false negatives. This
multimodal AI-driven approach enables scalable, accurate DR screening, crucial
for diabetes-burdened regions.

</details>


### [27] [Comparative Analysis of Object Detection Algorithms for Surface Defect Detection](https://arxiv.org/abs/2510.21811)
*Arpan Maity,Tamal Ghosh*

Main category: cs.CV

TL;DR: 本文比较了六种主流目标检测算法（YOLOv11、RetinaNet、Fast R-CNN、YOLOv8、RT-DETR和DETR）在用于工业金属表面缺陷检测的NEU-DET数据集上的性能。结果表明，YOLOv11在准确率和检测速度方面远超其他算法，特别是在检测微小缺陷时表现突出。


<details>
  <summary>Details</summary>
Motivation: 表面缺陷检测在工业质控中至关重要，但现有检测算法在不同缺陷类型和实用性方面尚有提升空间。本文旨在系统评估并比较多种主流目标检测算法在该领域的性能表现。

Method: 选取六种目标检测算法，在包含多种金属表面缺陷图像的NEU-DET数据集上，从检测准确率、速度和鲁棒性等多个维度进行实验和分析，重点关注对划痕、夹杂、压入等不同类型缺陷的检测效果。

Result: YOLOv11的检测准确率平均比其他方法高70%，在检测速度和对细小缺陷的敏感性方面也表现领先。其优势主要得益于增强的特征提取能力、单次前向推理全图处理、高效的锚框生成以及更深的卷积结构。

Conclusion: YOLOv11凭借卓越的检测准确率与效率，成为NEU-DET表面缺陷检测任务的最佳算法，显著优于其它主流目标检测方法，具有极高的实际应用价值。

Abstract: This article compares the performance of six prominent object detection
algorithms, YOLOv11, RetinaNet, Fast R-CNN, YOLOv8, RT-DETR, and DETR, on the
NEU-DET surface defect detection dataset, comprising images representing
various metal surface defects, a crucial application in industrial quality
control. Each model's performance was assessed regarding detection accuracy,
speed, and robustness across different defect types such as scratches,
inclusions, and rolled-in scales. YOLOv11, a state-of-the-art real-time object
detection algorithm, demonstrated superior performance compared to the other
methods, achieving a remarkable 70% higher accuracy on average. This
improvement can be attributed to YOLOv11s enhanced feature extraction
capabilities and ability to process the entire image in a single forward pass,
making it faster and more efficient in detecting minor surface defects.
Additionally, YOLOv11's architecture optimizations, such as improved anchor box
generation and deeper convolutional layers, contributed to more precise
localization of defects. In conclusion, YOLOv11's outstanding performance in
accuracy and speed solidifies its position as the most effective model for
surface defect detection on the NEU dataset, surpassing competing algorithms by
a substantial margin.

</details>


### [28] [SITS-DECO: A Generative Decoder Is All You Need For Multitask Satellite Image Time Series Modelling](https://arxiv.org/abs/2510.21813)
*Samuel J. Barrett,Docko Sow*

Main category: cs.CV

TL;DR: 本文提出了一种新的地球观测（EO）时序影像基础模型SITS-DECO，该模型采用类似GPT的解码器结构，通过生成式方式统一处理多种任务，实现了无需任务或模态适配的多任务、多模态推理，并在作物类型分类任务中超越了更大的基础模型。


<details>
  <summary>Details</summary>
Motivation: 现有EO基础模型在实际应用前通常需要额外适配，且结构僵化，无法灵活应对不同的数据源和任务。作者希望通过吸取大语言模型的训练与推理模式，提出一种可直接处理多任务、多模态，无需复杂适配的EO基础模型。

Method: 提出SITS-DECO模型，采用单一GPT风格的解码器结构，将EO数据编码为统一序列，通过生成式训练和符号提示（symbolic prompting）实现像素级、多时序、多模态的作物类型分类任务，无需根据任务或模态进行特定适配。

Result: SITS-DECO虽然结构简单且不利用空间信息，但在PASTIS-R作物类型分类任务上表现优于大规模EO基础模型，表明密集时序序列建模是当前EO模型的重要补充。

Conclusion: 展示了以数据多样性和结构为核心、非依赖架构复杂性的EO基础建模新范式。SITS-DECO为轻量、实用的多模态多任务EO建模提供了新方向，并为未来生成式EO基础模型奠定了概念基础。

Abstract: Earth Observation (EO) Foundation Modelling (FM) holds great promise for
simplifying and improving the use of EO data for diverse real-world tasks.
However, most existing models require additional adaptation before they can be
used and are structured rigidly around particular data sources or training
approaches. To address this, we take inspiration from large language models,
where diverse tasks, both pre-training and downstream, are implicitly captured
through next-token prediction over unified token sequences, leveraging the
structure and diversity of the training data.
  We introduce SITS-DECO (Satellite Image Time Series-DECoder Only), a
proof-of-concept generative model that applies this unified-sequence framing to
EO data. Using a simple GPT-style decoder-only architecture, and demonstrate
its ability to perform useful EO tasks (pixel-wise, multi-temporal, multi-modal
crop-type classification) in a purely generative framework. Through symbolic
prompting, we show that the model can perform multiple supervised and
self-supervised tasks within a single unified architecture, without task- or
modality-specific adaptation. Despite its simplicity and lack of spatial
context, SITS-DECO outperforms much larger EO foundation models on crop-type
classification (PASTIS-R) demonstrating that dense temporal sequence modelling
is a critical missing ingredient in the current paradigm.
  This work exemplifies a data-centric modelling paradigm in which capability
arises from the diversity and structure of the training data rather than from
architectural complexity. SITS-DECO provides a lightweight, practical route to
multi-modal, multi-task EO modelling, and a conceptual bridge toward future
generative EO foundation models.

</details>


### [29] [Gestura: A LVLM-Powered System Bridging Motion and Semantics for Real-Time Free-Form Gesture Understanding](https://arxiv.org/abs/2510.21814)
*Zhuoming Li,Aitong Liu,Mengxi Jia,Tengxiang Zhang,Dell Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 提出Gestura系统，结合大型视觉-语言模型和手部先验等模块，实现对自由形式手势的高效理解，并发布了首个相关的数据集。


<details>
  <summary>Details</summary>
Motivation: 解决当前自由形式手势理解精度低、响应慢的问题，提升人机交互的自然性和灵活性。

Method: 采用预训练大型视觉-语言模型（LVLM）进行手势与语义对齐，引入Landmark Processing Module（手部先验嵌入）提升对细微手势的感知，引入Chain-of-Thought推理实现更深层的语义理解，并配套构建了大规模开放数据集。

Result: Gestura系统显著提高了自由形式手势的识别准确率与响应速度，能更鲁棒且自适应地理解多样、复杂的手势意图。还公开了30万+标注样本的数据集供研究。

Conclusion: Gestura有效解决了自由形式手势理解的瓶颈，为自然人机交互和相关研究提供了新技术和标准数据资源。

Abstract: Free-form gesture understanding is highly appealing for human-computer
interaction, as it liberates users from the constraints of predefined gesture
categories. However, the sole existing solution GestureGPT suffers from limited
recognition accuracy and slow response times. In this paper, we propose
Gestura, an end-to-end system for free-form gesture understanding. Gestura
harnesses a pre-trained Large Vision-Language Model (LVLM) to align the highly
dynamic and diverse patterns of free-form gestures with high-level semantic
concepts. To better capture subtle hand movements across different styles, we
introduce a Landmark Processing Module that compensate for LVLMs' lack of
fine-grained domain knowledge by embedding anatomical hand priors. Further, a
Chain-of-Thought (CoT) reasoning strategy enables step-by-step semantic
inference, transforming shallow knowledge into deep semantic understanding and
significantly enhancing the model's ability to interpret ambiguous or
unconventional gestures. Together, these components allow Gestura to achieve
robust and adaptable free-form gesture comprehension. Additionally, we have
developed the first open-source dataset for free-form gesture intention
reasoning and understanding with over 300,000 annotated QA pairs.

</details>


### [30] [Prompt fidelity of ChatGPT4o / Dall-E3 text-to-image visualisations](https://arxiv.org/abs/2510.21821)
*Dirk HR Spennemann*

Main category: cs.CV

TL;DR: 本研究评估了ChatGPT4o / DALL-E3文本到图像生成对提示要求的准确履行程度，发现整体提示与图像一致性良好，但存在15.6%的属性未正确呈现，尤以人物属性（如年龄）误差最大。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI（如DALL-E3等文本到图像模型）在文化创意等行业的广泛应用，理解这些AI对用户明确要求（prompt）的准确响应变得尤为重要，尤其是其是否会引入偏见或细节失真。

Method: 作者采用两个公开数据集：女性文化创意产业工作者图片（200张）和博物馆策展人图片（230张），指定具体属性（如年龄、发色、服饰、眼镜、名牌、写字板）在prompt中，并比对生成图像中这些属性的还原情况，对准确率进行定量分析。

Result: DALL-E3在生成图像时，整体属性准确率较高，但有15.6%（共710项属性计）未按提示正确表达。附属物品（如名牌等）误差最小，外表细节居中，人物本身属性误差最大，尤其是年龄还原最不准确。

Conclusion: DALL-E3等AI在文本到图像任务中，虽然整体忠实于用户提示，但部分属性（尤其是人物核心特征）存在偏差。这一结论对于检测AI模型引入的潜在偏见及日后模型评估具有重要意义。

Abstract: This study examines the prompt fidelity of ChatGPT4o / DALL-E3 text-to-image
visualisations by analysing whether attributes explicitly specified in
autogenously generated prompts are correctly rendered in the resulting images.
Using two public-domain datasets comprising 200 visualisations of women working
in the cultural and creative industries and 230 visualisations of museum
curators, the study assessed accuracy across personal attributes (age, hair),
appearance (attire, glasses), and paraphernalia (name tags, clipboards). While
correctly rendered in most cases, DALL-E3 deviated from prompt specifications
in 15.6% of all attributes (n=710). Errors were lowest for paraphernalia,
moderate for personal appearance, and highest for depictions of the person
themselves, particularly age. These findings demonstrate measurable
prompt-to-image fidelity gaps with implications for bias detection and model
evaluation.

</details>


### [31] [Wavelet-based GAN Fingerprint Detection using ResNet50](https://arxiv.org/abs/2510.21822)
*Sai Teja Erukude,Suhasnadh Reddy Veluru,Viswa Chaitanya Marella*

Main category: cs.CV

TL;DR: 本文提出了一种结合离散小波变换（DWT）与ResNet50网络的检测方法，有效区分由StyleGAN生成的图像与真实图像，准确率高于传统空间域方法。


<details>
  <summary>Details</summary>
Motivation: 随着生成对抗网络（GANs）技术的发展，GAN生成的逼真图像越来越难以与真实图像区分，对数字图像取证带来了巨大挑战，因此亟需高效的检测方法。

Method: 采用Haar和Daubechies小波滤波器对输入图像进行多分辨率小波变换预处理，将变换后的特征送入ResNet50分类网络进行真假图像区分，并与直接在空间域训练的模型效果进行比较。

Result: Haar和Daubechies小波预处理模型分别实现了93.8%和95.1%的准确率，显著高于仅基于空间域的ResNet50模型（81.5%准确率），其中Daubechies小波效果更优。

Conclusion: 基于小波域的分析方法能有效捕捉GAN生成图像中的特有小波域伪影，有望作为未来深度伪造检测系统的重要方向。

Abstract: Identifying images generated by Generative Adversarial Networks (GANs) has
become a significant challenge in digital image forensics. This research
presents a wavelet-based detection method that uses discrete wavelet transform
(DWT) preprocessing and a ResNet50 classification layer to differentiate the
StyleGAN-generated images from real ones. Haar and Daubechies wavelet filters
are applied to convert the input images into multi-resolution representations,
which will then be fed to a ResNet50 network for classification, capitalizing
on subtle artifacts left by the generative process. Moreover, the wavelet-based
models are compared to an identical ResNet50 model trained on spatial data. The
Haar and Daubechies preprocessed models achieved a greater accuracy of 93.8
percent and 95.1 percent, much higher than the model developed in the spatial
domain (accuracy rate of 81.5 percent). The Daubechies-based model outperforms
Haar, showing that adding layers of descriptive frequency patterns can lead to
even greater distinguishing power. These results indicate that the
GAN-generated images have unique wavelet-domain artifacts or "fingerprints."
The method proposed illustrates the effectiveness of wavelet-domain analysis to
detect GAN images and emphasizes the potential of further developing the
capabilities of future deepfake detection systems.

</details>


### [32] [Explainable Deep Learning in Medical Imaging: Brain Tumor and Pneumonia Detection](https://arxiv.org/abs/2510.21823)
*Sai Teja Erukude,Viswa Chaitanya Marella,Suhasnadh Reddy Veluru*

Main category: cs.CV

TL;DR: 该论文提出了一种可解释的深度学习框架，用于利用ResNet50和DenseNet121检测脑部MRI肿瘤和胸部X射线肺炎，并通过Grad-CAM实现可视化解释。DenseNet121在两个任务上均优于ResNet50。


<details>
  <summary>Details</summary>
Motivation: 深度学习在医学影像诊断中潜力巨大，但模型缺乏可解释性，影响了临床医生信任和实际应用。作者旨在提升模型可解释性，推进深度学习工具在医学诊断领域的可靠应用。

Method: 分别使用ResNet50和DenseNet121两种CNN模型，在公开Kaggle数据集上的MRI脑肿瘤和X射线肺炎影像分类任务进行训练和测试，同时采用Grad-CAM方法对预测结果进行可视化解释，突出模型决策时关注的关键区域。

Result: DenseNet121在脑肿瘤检测中的准确率为94.3%，肺炎检测为89.1%，均高于ResNet50的92.5%和84.4%；Grad-CAM可视化显示DenseNet121关注核心病灶区域，而ResNet50有时关注于外围和非病理区域。

Conclusion: 结合深度学习和可解释性AI方法，有助于开发出更可信、可解释且能够临床应用的医学影像诊断工具，DenseNet121在此框架下表现更优。

Abstract: Deep Learning (DL) holds enormous potential for improving medical imaging
diagnostics, yet the lack of interpretability in most models hampers clinical
trust and adoption. This paper presents an explainable deep learning framework
for detecting brain tumors in MRI scans and pneumonia in chest X-ray images
using two leading Convolutional Neural Networks, ResNet50 and DenseNet121.
These models were trained on publicly available Kaggle datasets comprising
7,023 brain MRI images and 5,863 chest X-ray images, achieving high
classification performance. DenseNet121 consistently outperformed ResNet50 with
94.3 percent vs. 92.5 percent accuracy for brain tumors and 89.1 percent vs.
84.4 percent accuracy for pneumonia. For better explainability,
Gradient-weighted Class Activation Mapping (Grad-CAM) was integrated to create
heatmap visualizations superimposed on the test images, indicating the most
influential image regions in the decision-making process. Interestingly, while
both models produced accurate results, Grad-CAM showed that DenseNet121
consistently focused on core pathological regions, whereas ResNet50 sometimes
scattered attention to peripheral or non-pathological areas. Combining deep
learning and explainable AI offers a promising path toward reliable,
interpretable, and clinically useful diagnostic tools.

</details>


### [33] [Precise classification of low quality G-banded Chromosome Images by reliability metrics and data pruning classifier](https://arxiv.org/abs/2510.21827)
*Mojtaba Moattari*

Main category: cs.CV

TL;DR: 本文提出了一种基于置信度阈值和特征工程的新方法，以提升低成本和低质量图像环境下染色体分类的准确率。经过多种深度学习及传统方法评估，结果显示该方法对常见染色体异常识别的准确率大幅提升，并验证了该方法在低质量数据上的实用性。


<details>
  <summary>Details</summary>
Motivation: 高分辨率相机和精确分析工具提升了染色体分类准确率，但现有系统依赖大量高质量训练数据，在资源匮乏的实验室无法满足。作者旨在解决低成本系统和低质量图像下假阳性偏高的问题。

Method: 提出了基于置信度阈值和特征工程的染色体分类提升方法，并结合深度神经网络（变体的Alex-Net）、SVM、KNN及其级联流程，对自动化半拉直染色体进行筛选、分类和过滤，并对比了不同阈值指标的效果。

Result: 提出的方法分类准确率显著提升，尤其在常见错误和异位情况下可达到90%以上准确率；对不同阈值指标进行比较，突出最优指标的显著特性。

Conclusion: 该方法对低质量G带染色体数据库表现出高准确率，验证了其在贫困国家及低预算实验室的卡氏核型分析中的可行性和有效性。

Abstract: In the last decade, due to high resolution cameras and accurate meta-phase
analyzes, the accuracy of chromosome classification has improved substantially.
However, current Karyotyping systems demand large number of high quality train
data to have an adequately plausible Precision per each chromosome. Such
provision of high quality train data with accurate devices are not yet
accomplished in some out-reached pathological laboratories. To prevent false
positive detections in low-cost systems and low-quality images settings, this
paper improves the classification Precision of chromosomes using proposed
reliability thresholding metrics and deliberately engineered features. The
proposed method has been evaluated using a variation of deep Alex-Net neural
network, SVM, K Nearest-Neighbors, and their cascade pipelines to an automated
filtering of semi-straight chromosome. The classification results have highly
improved over 90% for the chromosomes with more common defections and
translocations. Furthermore, a comparative analysis over the proposed
thresholding metrics has been conducted and the best metric is bolded with its
salient characteristics. The high Precision results provided for a very
low-quality G-banding database verifies suitability of the proposed metrics and
pruning method for Karyotyping facilities in poor countries and lowbudget
pathological laboratories.

</details>


### [34] [Structured and Abstractive Reasoning on Multi-modal Relational Knowledge Images](https://arxiv.org/abs/2510.21828)
*Yichi Zhang,Zhuo Chen,Lingbing Guo,Lei Liang,Wen Zhang,Huajun Chen*

Main category: cs.CV

TL;DR: 本文提出了一种新的多模态结构化抽象推理（STAR）数据生成与增强方法，大幅提升了小型多模态大语言模型（MLLMs）对抽象关系知识的推理能力，并构建了包含64K高质量数据的STAR-64K数据集，在多项任务上显著超越GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型难以理解和推理抽象的多模态关系知识（MMRK），相关高质量数据和提升方法稀缺，影响实际应用和研究进展。本文旨在弥补该领域在数据和模型能力提升上的双重空白。

Method: 提出自动STAR数据引擎，合成具备多模态关系知识的图像和推理数据，并建立链式思维的多模态指令任务；设计两阶段训练框架，分阶段提升模型在结构化抽象推理任务上的能力，并配备多项针对不同STAR任务的评测方法。

Result: 构建了64K高质量的STAR-64K数据集，并在五个开源多模态大模型上验证。实验结果显示：两阶段增强后的小型模型（3B/7B参数量）在STAR任务上显著超越GPT-4o，同时分析了不同设计、数据迁移性与扩展性带来的影响。

Conclusion: 提出的STAR数据引擎与两阶段能力增强框架，有效提升了多模态大模型在抽象结构化推理任务中的理解与推理能力，为该领域的进一步研究和实际应用提供了宝贵的数据与方法基础。

Abstract: Understanding and reasoning with abstractive information from the visual
modality presents significant challenges for current multi-modal large language
models (MLLMs). Among the various forms of abstractive information, Multi-Modal
Relational Knowledge (MMRK), which represents abstract relational structures
between multi-modal entities using node-edge formats, remains largely
under-explored. In particular, STructured and Abstractive Reasoning (STAR) on
such data has received little attention from the research community. To bridge
the dual gaps in large-scale high-quality data and capability enhancement
methodologies, this paper makes the following key contributions: (i). An
automatic STAR data engine capable of synthesizing images with MMRK to build
multi-modal instruction data with reliable chain-of-thought thinking for
various STAR tasks and (ii). A comprehsive two-stage capability enhancement
training framework, accompanied by a suite of evaluation protocols tailored to
different STAR tasks. Based upon these contributions, we introduce STAR-64K, a
dataset comprising 64K high-quality multi-modal instruction samples, and
conduct experiments across 5 open-source MLLMs. Experimental results show that
our two-stage enhancement framework enables smaller 3B/7B models to
significantly outperform GPT-4o in STAR. Additionally, we provide in-depth
analysis regarding the effectiveness of various designs, data transferability,
and scalability.

</details>


### [35] [A Flow Model with Low-Rank Transformers for Incomplete Multimodal Survival Analysis](https://arxiv.org/abs/2510.21829)
*Yi Yin,Yuntao Shou,Zao Dai,Yun Peng,Tao Meng,Wei Ai,Keqin Li*

Main category: cs.CV

TL;DR: 本文提出了一种结合低秩Transformer与基于flow的生成模型的新型多模态生存分析框架，有效解决了真实医疗数据中因信息缺失导致的模态不一致、重建不可靠的问题，实现了在模态完整和不完整情况下均具备强鲁棒性和准确性的生存预测。


<details>
  <summary>Details</summary>
Motivation: 现实多模态医疗数据中常有模态缺失（如患者部分图像或基因信息缺失），现有方法直接用神经网络推断缺失模态，但常出现跨模态分布不一致，导致预测结果不可靠。本文工作旨在解决该问题，提高重建与预测的一致性和鲁棒性。

Method: 采用多实例表征的WSIs和基因组数据，借助类别条件下的class-specific flow对齐跨模态分布，利用可逆结构和密度建模能力强的normalizing flow将缺失模态映射到一致的潜在空间，并基于轻量级低秩Transformer捕捉模态内部依赖，同时避免高维融合下的过拟合。

Result: 在完整和不完整模态数据实验中，所提方法均达到了目前最优或领先的生存预测准确率，展现出良好的鲁棒性与泛化能力。

Conclusion: 该框架为处理真实环境下多模态医疗数据生存分析中的模态缺失、分布不一致等问题提供了新思路，具备很强的实际应用潜力。

Abstract: In recent years, multimodal medical data-based survival analysis has
attracted much attention. However, real-world datasets often suffer from the
problem of incomplete modality, where some patient modality information is
missing due to acquisition limitations or system failures. Existing methods
typically infer missing modalities directly from observed ones using deep
neural networks, but they often ignore the distributional discrepancy across
modalities, resulting in inconsistent and unreliable modality reconstruction.
To address these challenges, we propose a novel framework that combines a
low-rank Transformer with a flow-based generative model for robust and flexible
multimodal survival prediction. Specifically, we first formulate the concerned
problem as incomplete multimodal survival analysis using the multi-instance
representation of whole slide images (WSIs) and genomic profiles. To realize
incomplete multimodal survival analysis, we propose a class-specific flow for
cross-modal distribution alignment. Under the condition of class labels, we
model and transform the cross-modal distribution. By virtue of the reversible
structure and accurate density modeling capabilities of the normalizing flow
model, the model can effectively construct a distribution-consistent latent
space of the missing modality, thereby improving the consistency between the
reconstructed data and the true distribution. Finally, we design a lightweight
Transformer architecture to model intra-modal dependencies while alleviating
the overfitting problem in high-dimensional modality fusion by virtue of the
low-rank Transformer. Extensive experiments have demonstrated that our method
not only achieves state-of-the-art performance under complete modality
settings, but also maintains robust and superior accuracy under the incomplete
modalities scenario.

</details>


### [36] [Towards Accurate and Efficient Waste Image Classification: A Hybrid Deep Learning and Machine Learning Approach](https://arxiv.org/abs/2510.21833)
*Ngoc-Bao-Quang Nguyen,Tuan-Minh Do,Cong-Tam Phan,Thi-Thu-Hong Phan*

Main category: cs.CV

TL;DR: 本文对垃圾图片分类的三种主流方法进行了系统比较，提出了一种融合深度学习和传统机器学习的高效混合方法，并在多个数据集上刷新了准确率纪录。


<details>
  <summary>Details</summary>
Motivation: 全球垃圾管理日益重要，图像自动分类是其关键环节，但至今缺乏同时涵盖机器学习、深度学习及其混合方法的系统基准。

Method: 对三类方法进行了比较：(1) 传统机器学习结合人工特征，(2) 多种深度学习架构（如ResNet和EfficientNetV2S），(3) 用深度模型提特征再用经典分类器（如SVM、Logistic回归）判别的混合方法。并进行特征选择以降维。

Result: 混合方法在三个公开数据集上均优于其他方法，TrashNet与修正后的家庭垃圾数据集达100%准确率，Garbage Classification达99.87%，均刷新了最优成绩。特征选择降维95%以上，训练、推理速度提升。

Conclusion: 该研究提出了更可靠的垃圾分类基准，并证明了高效混合框架在保证高准确度的同时大幅降低推理成本，适用于资源受限环境的广泛应用。

Abstract: Automated image-based garbage classification is a critical component of
global waste management; however, systematic benchmarks that integrate Machine
Learning (ML), Deep Learning (DL), and efficient hybrid solutions remain
underdeveloped. This study provides a comprehensive comparison of three
paradigms: (1) machine learning algorithms using handcrafted features, (2) deep
learning architectures, including ResNet variants and EfficientNetV2S, and (3)
a hybrid approach that utilizes deep models for feature extraction combined
with classical classifiers such as Support Vector Machine and Logistic
Regression to identify the most effective strategy. Experiments on three public
datasets - TrashNet, Garbage Classification, and a refined Household Garbage
Dataset (with 43 corrected mislabels)- demonstrate that the hybrid method
consistently outperforms the others, achieving up to 100% accuracy on TrashNet
and the refined Household set, and 99.87% on Garbage Classification, thereby
surpassing state-of-the-art benchmarks. Furthermore, feature selection reduces
feature dimensionality by over 95% without compromising accuracy, resulting in
faster training and inference. This work establishes more reliable benchmarks
for waste classification and introduces an efficient hybrid framework that
achieves high accuracy while reducing inference cost, making it suitable for
scalable deployment in resource-constrained environments.

</details>


### [37] [Evaluating ChatGPT's Performance in Classifying Pneumonia from Chest X-Ray Images](https://arxiv.org/abs/2510.21839)
*Pragna Prahallad,Pranathi Prahallad*

Main category: cs.CV

TL;DR: 本文探讨了OpenAI的gpt-4o模型在无需微调的情况下对胸部X光片进行正常/肺炎分类的能力。结果显示简明、注重特征的提示效果最佳，但诊断能力距离临床应用还有差距。


<details>
  <summary>Details</summary>
Motivation: 近年来AI在医学影像诊断领域展现出巨大潜力，作者希望评估最新大模型（gpt-4o）直接用于医疗影像诊断（零样本设定）时的能力和局限性。

Method: 采用400张胸部X光片（200正常，200肺炎）的平衡测试集，设置四种不同复杂度的提示词，从简单说明到复杂推理，评估gpt-4o在零样本下的分类准确率。

Result: 简洁且强调特征的提示词获得最高准确率74%；而复杂的推理型提示词分类效果反而较差。说明gpt-4o在医学影像零样本诊断上有一定能力，但现阶段准确率有限。

Conclusion: 尽管gpt-4o在医学影像解释中展现潜力，但其诊断可靠性尚不足以支持临床应用。需进一步提升视觉推理和针对医学领域的适配能力。

Abstract: In this study, we evaluate the ability of OpenAI's gpt-4o model to classify
chest X-ray images as either NORMAL or PNEUMONIA in a zero-shot setting,
without any prior fine-tuning. A balanced test set of 400 images (200 from each
class) was used to assess performance across four distinct prompt designs,
ranging from minimal instructions to detailed, reasoning-based prompts. The
results indicate that concise, feature-focused prompts achieved the highest
classification accuracy of 74\%, whereas reasoning-oriented prompts resulted in
lower performance. These findings highlight that while ChatGPT exhibits
emerging potential for medical image interpretation, its diagnostic reliability
remains limited. Continued advances in visual reasoning and domain-specific
adaptation are required before such models can be safely applied in clinical
practice.

</details>


### [38] [Improving the Physics of Video Generation with VJEPA-2 Reward Signal](https://arxiv.org/abs/2510.21840)
*Jianhao Yuan,Xiaofeng Zhang,Felix Friedrich,Nicolas Beltran-Velez,Melissa Hall,Reyhane Askari-Hemmat,Xiaochuang Han,Nicolas Ballas,Michal Drozdzal,Adriana Romero-Soriano*

Main category: cs.CV

TL;DR: 本报告介绍了一种结合自监督学习（SSL）视频世界模型和视频生成模型以提升生成物理合理性的方法，并在PhysicsIQ Challenge中取得最佳成绩。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在物理理解上表现较差，常生成不合理的视频。以往工作发现SSL预训练能激发一定的物理直觉。问题是，能否利用SSL视频世界模型改善生成模型的物理合理性？

Method: 在最先进的视频生成模型MAGI-1的基础上，引入新提出的视频联合嵌入预测架构2（VJEPA-2），将其作为奖励信号引导生成过程，提高视频生成中的物理合理性。

Result: 通过以VJEPA-2作为奖励信号，验证了该方法能使视频生成模型的物理合理性提升约6%。

Conclusion: 使用SSL预训练世界模型引导视频生成过程有助于提升其物理合理性，对改进视频生成物理表现具备实际价值。

Abstract: This is a short technical report describing the winning entry of the
PhysicsIQ Challenge, presented at the Perception Test Workshop at ICCV 2025.
State-of-the-art video generative models exhibit severely limited physical
understanding, and often produce implausible videos. The Physics IQ benchmark
has shown that visual realism does not imply physics understanding. Yet,
intuitive physics understanding has shown to emerge from SSL pretraining on
natural videos. In this report, we investigate whether we can leverage
SSL-based video world models to improve the physics plausibility of video
generative models. In particular, we build ontop of the state-of-the-art video
generative model MAGI-1 and couple it with the recently introduced Video Joint
Embedding Predictive Architecture 2 (VJEPA-2) to guide the generation process.
We show that by leveraging VJEPA-2 as reward signal, we can improve the physics
plausibility of state-of-the-art video generative models by ~6%.

</details>


### [39] [RatioWaveNet: A Learnable RDWT Front-End for Robust and Interpretable EEG Motor-Imagery Classification](https://arxiv.org/abs/2510.21841)
*Marco Siino,Giuseppe Bonomo,Rosario Sorbello,Ilenia Tinnirello*

Main category: cs.CV

TL;DR: 本文提出RatioWaveNet，一种集成了可训练小波前端的时序CNN-Transformer架构，用于提升基于运动想象的脑-机接口（BCI）的解码鲁棒性，尤其改善最难受试者的表现。


<details>
  <summary>Details</summary>
Motivation: 运动想象BCI的EEG信号存在非平稳性、低信噪比和个体差异大等问题，使得高可靠性解码十分困难，尤其在最差受试者上表现不佳。研究旨在探索引入可训练小波前端，能否有针对性地提升系统在这一短板上的表现。

Method: 作者提出RatioWaveNet架构，它在强大的TCFormer（时序CNN-Transformer）骨干网络前引入可训练的Rationally-Dilated Wavelet Transform（RDWT）前端，对输入信号进行多分辨率子带分解，从而提高运动感觉节律信号的识别能力并减少伪影影响。经过轻量化卷积、局部与全局特征提取和因果集成，全流程增强解码性能。

Result: 在BCI-IV-2a和2b公开数据集、5组随机种子的测试下，RatioWaveNet在最难受试者上的准确率较TCFormer骨干提升0.17/0.42pp(2a)和1.07/2.54pp(2b)，平均准确率也有所提高，且计算开销增加有限。

Conclusion: 可训练小波前端作为Transformer-based BCI的灵活插件，有效增强运动想象BCI在最难受试者上的解码可靠性，同时保持高效性和平均性能，是提升BCI实用性的有前景工具。

Abstract: Brain-computer interfaces (BCIs) based on motor imagery (MI) translate covert
movement intentions into actionable commands, yet reliable decoding from
non-invasive EEG remains challenging due to nonstationarity, low SNR, and
subject variability. We present RatioWaveNet, which augments a strong temporal
CNN-Transformer backbone (TCFormer) with a trainable, Rationally-Dilated
Wavelet Transform (RDWT) front end. The RDWT performs an undecimated,
multi-resolution subband decomposition that preserves temporal length and
shift-invariance, enhancing sensorimotor rhythms while mitigating jitter and
mild artifacts; subbands are fused via lightweight grouped 1-D convolutions and
passed to a multi-kernel CNN for local temporal-spatial feature extraction, a
grouped-query attention encoder for long-range context, and a compact TCN head
for causal temporal integration.
  Our goal is to test whether this principled wavelet front end improves
robustness precisely where BCIs typically fail - on the hardest subjects - and
whether such gains persist on average across seeds under both intra- and
inter-subject protocols. On BCI-IV-2a and BCI-IV-2b, across five seeds,
RatioWaveNet improves worst-subject accuracy over the Transformer backbone by
+0.17 / +0.42 percentage points (Sub-Dependent / LOSO) on 2a and by +1.07 /
+2.54 percentage points on 2b, with consistent average-case gains and modest
computational overhead. These results indicate that a simple, trainable wavelet
front end is an effective plug-in to strengthen Transformer-based BCIs,
improving worst-case reliability without sacrificing efficiency.

</details>


### [40] [Modal Aphasia: Can Unified Multimodal Models Describe Images From Memory?](https://arxiv.org/abs/2510.21842)
*Michael Aerni,Joshua Swanson,Kristina Nikolić,Florian Tramèr*

Main category: cs.CV

TL;DR: 当前多模态模型在视觉记忆上表现优异，但在文本描述上存在严重缺陷，这种系统性失调现象被称为“模态失语症”。


<details>
  <summary>Details</summary>
Motivation: 深入分析统一多模态模型在处理图片和文本信息时，是否真的做到了模态间理解与表达的统一，及其带来的安全隐患。

Method: 实证分析包括：对主流模型进行经典电影海报的视觉再现和文本描述测试，在合成数据集和不同架构上做对照实验，验证视觉记忆与文字表达间的失配。

Result: 发现当前多模态模型能够几乎完美复制视觉内容，但在文本描述中会混淆重要细节，这种失配在不同模型和数据集上均普遍存在。

Conclusion: “模态失语症”是当前多模态模型的基本属性，非训练偶然产物。在实际应用中，这会造成安全漏洞，仅对某一模态的安全措施可能导致其它模态泄露有害内容。

Abstract: We present modal aphasia, a systematic dissociation in which current unified
multimodal models accurately memorize concepts visually but fail to articulate
them in writing, despite being trained on images and text simultaneously. For
one, we show that leading frontier models can generate near-perfect
reproductions of iconic movie artwork, but confuse crucial details when asked
for textual descriptions. We corroborate those findings through controlled
experiments on synthetic datasets in multiple architectures. Our experiments
confirm that modal aphasia reliably emerges as a fundamental property of
current unified multimodal models, not just as a training artifact. In
practice, modal aphasia can introduce vulnerabilities in AI safety frameworks,
as safeguards applied to one modality may leave harmful concepts accessible in
other modalities. We demonstrate this risk by showing how a model aligned
solely on text remains capable of generating unsafe images.

</details>


### [41] [SCoPE VLM: Selective Context Processing for Efficient Document Navigation in Vision-Language Models](https://arxiv.org/abs/2510.21850)
*Gyubeum Lim,Yemo Koo,Vijay Krishna Madisetti*

Main category: cs.CV

TL;DR: 提出了一种新方法SCoPE VLM，采用递归导航策略解决视觉-语言模型在长文档和界面控制中的高效理解与操作难题。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言模型在处理网页、GUI等结构化长文档时，缺乏面向决策的文档理解，且现有方法对长输入的处理方式内存开销大，不适合本地部署。

Method: 提出Chain of Scroll机制让模型能够递归性地只关注相关文档部分，并设计配套数据生成流程和“Episodic Group Relative Policy Optimization”强化学习算法，缩小训练与推理间的差距。

Result: 新方法大幅降低内存需求，能高效模拟人类阅读行为，在多页面文档问答任务中取得优异效果。

Conclusion: SCoPE VLM首次系统性建模了代理式阅读策略，推动多模态智能体在长文档理解和交互方向的能力提升。

Abstract: Understanding long-context visual information remains a fundamental challenge
for vision-language models, particularly in agentic tasks such as GUI control
and web navigation. While web pages and GUI environments are inherently
structured documents, current VLMs typically neglect decision-oriented document
understanding in their training objectives. Existing approaches primarily
extend visual embeddings to process long, high-resolution inputs, but these
methods are memory-intensive and impractical for locally deployable solutions.
To address these issues, we propose SCoPE VLM, a document navigation expert
that leverages a novel Chain of Scroll mechanism to selectively and recursively
navigate documents, focusing exclusively on relevant segments. We introduce a
dedicated data generation pipeline to construct informative Chain of Scroll
trajectories and Episodic Group Relative Policy Optimization, a tailored
reinforcement learning method to reduce the gap between training and inference.
Our method substantially reduces memory usage and effectively models human-like
reading behaviors. To the best of our knowledge, SCoPE VLM is the first
framework to explicitly model agentic reading patterns in multi-page document
question answering, advancing the capabilities of multimodal agents.

</details>


### [42] [Poisson Flow Consistency Training](https://arxiv.org/abs/2510.21857)
*Anthony Zhang,Mahmut Gokmen,Dennis Hein,Rongjun Ge,Wenjun Xia,Ge Wang,Jin Chen*

Main category: cs.CV

TL;DR: 本文提出了一种新的训练Poisson Flow Consistency Model（PFCM）的方法，实现了PFCM的独立训练，提升了CT低剂量图像去噪的性能。


<details>
  <summary>Details</summary>
Motivation: PFCM模型原来只能通过蒸馏方式训练，应用受限，亟需探索新的训练方法以拓展其在不同数据模态下的潜力。

Method: 提出了Poisson Flow Consistency Training（PFCT）方法，通过使用扰动核去除对预训练PFGM++的依赖，并引入正弦离散化时间表和Beta噪声分布以提升适应性和生成质量。

Result: 在低剂量CT图像去噪实验中，该方法提升了低剂量图像的LPIPS和SSIM分数，去噪效果与Consistency Model相当。

Conclusion: PFCT可有效独立训练PFCM，且在CT去噪任务中取得与主流生成模型竞争的效果，具有较高的灵活性和潜力，但仍需进一步优化和验证其在其他生成建模任务中的适用性。

Abstract: The Poisson Flow Consistency Model (PFCM) is a consistency-style model based
on the robust Poisson Flow Generative Model++ (PFGM++) which has achieved
success in unconditional image generation and CT image denoising. Yet the PFCM
can only be trained in distillation which limits the potential of the PFCM in
many data modalities. The objective of this research was to create a method to
train the PFCM in isolation called Poisson Flow Consistency Training (PFCT).
The perturbation kernel was leveraged to remove the pretrained PFGM++, and the
sinusoidal discretization schedule and Beta noise distribution were introduced
in order to facilitate adaptability and improve sample quality. The model was
applied to the task of low dose computed tomography image denoising and
improved the low dose image in terms of LPIPS and SSIM. It also displayed
similar denoising effectiveness as models like the Consistency Model. PFCT is
established as a valid method of training the PFCM from its effectiveness in
denoising CT images, showing potential with competitive results to other
generative models. Further study is needed in the precise optimization of PFCT
and in its applicability to other generative modeling tasks. The framework of
PFCT creates more flexibility for the ways in which a PFCM can be created and
can be applied to the field of generative modeling.

</details>


### [43] [A Multi-Stage Hybrid Framework for Automated Interpretation of Multi-View Engineering Drawings Using Vision Language Model](https://arxiv.org/abs/2510.21862)
*Muhammad Tayyab Khan,Zane Yong,Lequn Chen,Wenhe Feng,Nicholas Yew Jin Tan,Seung Ki Moon*

Main category: cs.CV

TL;DR: 本文提出了一种三阶段混合框架，利用现代检测和视觉语言模型，实现对2D多视图工程图的自动解析，显著提高了解读精度和自动化水平。


<details>
  <summary>Details</summary>
Motivation: 工程图是制造业沟通的关键载体，但因其结构复杂、多视图和注释密集，用人工方法或通用OCR、传统深度学习手段难以高效、准确解读，因此亟需能自动化、精准解析的技术。

Method: 方法分三阶段：第一，用YOLOv11-det进行版面分割，定位视图、图框、说明等区域；第二，利用YOLOv11-obb针对注释进行敏感方向和细粒度检测，识别标注、GD&T符号和粗糙度指标；第三，采用两种基于Donut的OCR-free视觉语言模型，对文本(如图框、说明)和数值信息(如尺寸、GD&T结构、粗糙度)进行语义解析。

Result: 开发了两个专用数据集(1000张用于布局检测，1406张用于注释级训练)。Alphabetical VLM在文本解析上F1为0.672，Numerical VLM在数值解析上F1为0.963，表现优异。

Conclusion: 该混合框架在工程图自动解析中取得了较高精度，实现了与CAD/制造数据库的无缝集成，为智能化工程图分析提供了可扩展高效的解决方案。

Abstract: Engineering drawings are fundamental to manufacturing communication, serving
as the primary medium for conveying design intent, tolerances, and production
details. However, interpreting complex multi-view drawings with dense
annotations remains challenging using manual methods, generic optical character
recognition (OCR) systems, or traditional deep learning approaches, due to
varied layouts, orientations, and mixed symbolic-textual content. To address
these challenges, this paper proposes a three-stage hybrid framework for the
automated interpretation of 2D multi-view engineering drawings using modern
detection and vision language models (VLMs). In the first stage, YOLOv11-det
performs layout segmentation to localize key regions such as views, title
blocks, and notes. The second stage uses YOLOv11-obb for orientation-aware,
fine-grained detection of annotations, including measures, GD&T symbols, and
surface roughness indicators. The third stage employs two Donut-based, OCR-free
VLMs for semantic content parsing: the Alphabetical VLM extracts textual and
categorical information from title blocks and notes, while the Numerical VLM
interprets quantitative data such as measures, GD&T frames, and surface
roughness. Two specialized datasets were developed to ensure robustness and
generalization: 1,000 drawings for layout detection and 1,406 for
annotation-level training. The Alphabetical VLM achieved an overall F1 score of
0.672, while the Numerical VLM reached 0.963, demonstrating strong performance
in textual and quantitative interpretation, respectively. The unified JSON
output enables seamless integration with CAD and manufacturing databases,
providing a scalable solution for intelligent engineering drawing analysis.

</details>


### [44] [LSF-Animation: Label-Free Speech-Driven Facial Animation via Implicit Feature Representation](https://arxiv.org/abs/2510.21864)
*Xin Lu,Chuanqing Zhuang,Chenxi Jin,Zhengda Lu,Yiqun Wang,Wu Liu,Jun Xiao*

Main category: cs.CV

TL;DR: 本文提出了一种无需显式表征情感与身份标签的新型语音驱动3D人脸动画方法LSF-Animation，能够更好地泛化到未见过的说话人和情感状态，并提升动画真实性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖人工提供的情感和身份标签，限制了对未见说话人和情感状态的泛化能力，同时忽略了语音中本有的情感信号，导致生成动画自然性和适应性欠佳。

Method: 提出LSF-Animation框架，从语音中隐式提取情感信息，从中性3D人脸网格中获取身份特征，无需人工标签。方法中引入了分层交互融合模块（HIFB），通过融合token，有效整合Transformer提取的双路特征，实现情感、动作与身份线索的更优融合。

Result: 在3DMEAD数据集上进行实验，LSF-Animation在情感表现力、身份泛化和动画真实感三个方面均超过了最新方法。

Conclusion: LSF-Animation提升了3D人脸动画的表达性和泛化能力，同时增强了动画的自然与真实感，是该方向的有效进步。

Abstract: Speech-driven 3D facial animation has attracted increasing interest since its
potential to generate expressive and temporally synchronized digital humans.
While recent works have begun to explore emotion-aware animation, they still
depend on explicit one-hot encodings to represent identity and emotion with
given emotion and identity labels, which limits their ability to generalize to
unseen speakers. Moreover, the emotional cues inherently present in speech are
often neglected, limiting the naturalness and adaptability of generated
animations. In this work, we propose LSF-Animation, a novel framework that
eliminates the reliance on explicit emotion and identity feature
representations. Specifically, LSF-Animation implicitly extracts emotion
information from speech and captures the identity features from a neutral
facial mesh, enabling improved generalization to unseen speakers and emotional
states without requiring manual labels. Furthermore, we introduce a
Hierarchical Interaction Fusion Block (HIFB), which employs a fusion token to
integrate dual transformer features and more effectively integrate emotional,
motion-related and identity-related cues. Extensive experiments conducted on
the 3DMEAD dataset demonstrate that our method surpasses recent
state-of-the-art approaches in terms of emotional expressiveness, identity
generalization, and animation realism. The source code will be released at:
https://github.com/Dogter521/LSF-Animation.

</details>


### [45] [Addressing Corner Cases in Autonomous Driving: A World Model-based Approach with Mixture of Experts and LLMs](https://arxiv.org/abs/2510.21867)
*Haicheng Liao,Bonan Wang,Junxian Yang,Chengyue Wang,Zhengbin He,Guohui Zhang,Chengzhong Xu,Zhenning Li*

Main category: cs.CV

TL;DR: WM-MoE模型结合世界模型、混合专家机制和大语言模型，有效提升自动驾驶在罕见危险场景下的运动预测能力，验证了其在多个数据集上的优越表现。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶运动预测模型在罕见但关键的“角落案例”场景表现不佳，主要由于常规场景数据过度代表和泛化能力有限。安全自动驾驶亟需提升对这些极端情况的预测能力。

Method: 作者提出WM-MoE框架，结合世界模型实现感知-记忆-决策一体化，利用大语言模型与轻量级时序嵌入增强长期推理，并引入混合专家机制将复杂角落案例分解为子问题，由路由分配给专项专家进行预测。此外构建了nuScenes-corner基准用于严谨评估。

Result: 在nuScenes、NGSIM、HighD和MoCAD四个数据集上，WM-MoE在常规和角落案例场景及数据缺失条件下均超越现有方法，表现出更强的鲁棒性和泛化能力。

Conclusion: 基于世界模型的运动预测架构对提升自动驾驶在高风险角落案例下的性能有显著潜力，为实现安全、泛化的全自动驾驶提供了新路径。

Abstract: Accurate and reliable motion forecasting is essential for the safe deployment
of autonomous vehicles (AVs), particularly in rare but safety-critical
scenarios known as corner cases. Existing models often underperform in these
situations due to an over-representation of common scenes in training data and
limited generalization capabilities. To address this limitation, we present
WM-MoE, the first world model-based motion forecasting framework that unifies
perception, temporal memory, and decision making to address the challenges of
high-risk corner-case scenarios. The model constructs a compact scene
representation that explains current observations, anticipates future dynamics,
and evaluates the outcomes of potential actions. To enhance long-horizon
reasoning, we leverage large language models (LLMs) and introduce a lightweight
temporal tokenizer that maps agent trajectories and contextual cues into the
LLM's feature space without additional training, enriching temporal context and
commonsense priors. Furthermore, a mixture-of-experts (MoE) is introduced to
decompose complex corner cases into subproblems and allocate capacity across
scenario types, and a router assigns scenes to specialized experts that infer
agent intent and perform counterfactual rollouts. In addition, we introduce
nuScenes-corner, a new benchmark that comprises four real-world corner-case
scenarios for rigorous evaluation. Extensive experiments on four benchmark
datasets (nuScenes, NGSIM, HighD, and MoCAD) showcase that WM-MoE consistently
outperforms state-of-the-art (SOTA) baselines and remains robust under
corner-case and data-missing conditions, indicating the promise of world
model-based architectures for robust and generalizable motion forecasting in
fully AVs.

</details>


### [46] [AI Powered Urban Green Infrastructure Assessment Through Aerial Imagery of an Industrial Township](https://arxiv.org/abs/2510.21876)
*Anisha Dutta*

Main category: cs.CV

TL;DR: 本研究提出了一种基于人工智能和计算机视觉的高效方法，用于从无人机高分辨率影像中自动识别和估算城市绿冠覆盖率，为智慧城市规划和环境管理提供数据支撑。


<details>
  <summary>Details</summary>
Motivation: 城市绿冠覆盖率评估对城市规划、环境监测及气候变化应对至关重要，但传统方法受技术、可扩展性、数据处理和专业能力限制，难以满足大规模高效评估需求。

Method: 采用基于深度学习的目标化影像分析方法，对无人机高分辨率航拍图像中的绿色冠层进行自动识别与分割，并在云平台上利用高性能处理器提升大数据处理效率，降低空间和时延成本。

Result: 实验表明，该方法可在城市尺度上准确评估冠层覆盖率，实现对城市植被的细致分析，有效支撑工业园区的城市林务管理。

Conclusion: 本研究方法为城市森林管理和碳汇潜力评估提供了新的数据和工具，有助于优化城市植树及推动可持续城市规划，建设更绿色健康的城市环境。

Abstract: Accurate assessment of urban canopy coverage is crucial for informed urban
planning, effective environmental monitoring, and mitigating the impacts of
climate change. Traditional practices often face limitations due to inadequate
technical requirements, difficulties in scaling and data processing, and the
lack of specialized expertise. This study presents an efficient approach for
estimating green canopy coverage using artificial intelligence, specifically
computer vision techniques, applied to aerial imageries. Our proposed
methodology utilizes object-based image analysis, based on deep learning
algorithms to accurately identify and segment green canopies from
high-resolution drone images. This approach allows the user for detailed
analysis of urban vegetation, capturing variations in canopy density and
understanding spatial distribution. To overcome the computational challenges
associated with processing large datasets, it was implemented over a cloud
platform utilizing high-performance processors. This infrastructure efficiently
manages space complexity and ensures affordable latency, enabling the rapid
analysis of vast amounts of drone imageries. Our results demonstrate the
effectiveness of this approach in accurately estimating canopy coverage at the
city scale, providing valuable insights for urban forestry management of an
industrial township. The resultant data generated by this method can be used to
optimize tree plantation and assess the carbon sequestration potential of urban
forests. By integrating these insights into sustainable urban planning, we can
foster more resilient urban environments, contributing to a greener and
healthier future.

</details>


### [47] [TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge](https://arxiv.org/abs/2510.21879)
*Shu-Hao Zhang,Wei-Cheng Tang,Chen Wu,Peng Hu,Nan Li,Liang-Jie Zhang,Qi Zhang,Shao-Qun Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为TernaryCLIP的轻量级模型，通过将CLIP模型中的视觉和文本编码器权重三值化，在极大压缩计算和存储开销的同时，仍能保持优异的图像-文本任务性能。


<details>
  <summary>Details</summary>
Motivation: 尽管图文对比学习模型如CLIP应用广泛，但其庞大的模型体积和高资源消耗限制了在计算资源受限设备上的部署。因此，降低模型存储和计算需求成为亟需解决的问题。

Method: TernaryCLIP通过将视觉和文本编码器的权重由浮点数转化为三值（-1, 0, 1），结合量化感知训练和模型蒸馏技术以缓解精度损失，实现极低比特表示（1.58-bit），从而大幅压缩和加速模型。

Result: TernaryCLIP可以实现高达99%的权重量三值化，获得1.58-bit权重表示，模型压缩比达16.98倍，推理加速2.3倍，存储减少16倍，内存优化10倍，60%的稀疏性，同时在41个公开数据集的零样本图像分类和图文检索任务上仍表现良好。

Conclusion: 极端量化（如三值化）能够在大规模多模态模型中有效应用，实现高效部署，特别适用于资源受限设备，而且性能保持较好，为此类模型普及提供了可行技术路径。

Abstract: Recent years have witnessed an increasing interest in image-text contrastive
modeling, exemplified by models such as Contrastive Language-Image Pretraining
(CLIP). In this paper, we propose the TernaryCLIP, a lightweight computational
framework that converts connection weights of both vision and text encoders of
CLIP into the ternary format, instead of full-precision or floating ones.
TernaryCLIP incorporates quantization-aware training and distillation modules,
preventing precision degradation and enabling low-cost and high-efficiency
computations. Comprehensive experiments demonstrate that TernaryCLIP can
achieve up to 99\% ternarized weights with 1.58-bit representation, 16.98
$\times$ compression ratio, 2.3 $\times$ inference acceleration, 16 $\times$
storage reduction, 10 $\times$ memory optimization, and 60\% sparsity while
maintaining promising performance on zero-shot image classification and
image-text retrieval tasks across 41 commonly used datasets. Our work
highlights the feasibility of extreme quantization for large multimodal models,
supporting effective and efficient deployment on resource-constrained devices.
The model and code can be accessed from Hugging Face and GitHub.

</details>


### [48] [Generative AI in Depth: A Survey of Recent Advances, Model Variants, and Real-World Applications](https://arxiv.org/abs/2510.21887)
*Shamim Yazdani,Akansha Singh,Nripsuta Saxena,Zichong Wang,Avash Palikhe,Deng Pan,Umapada Pal,Jie Yang,Wenbin Zhang*

Main category: cs.CV

TL;DR: 本文综述了深度生成模型（如GANs、VAEs和扩散模型）在图像、视频等内容生成领域的最新进展，梳理技术进步、创新点、伦理问题及未来方向。


<details>
  <summary>Details</summary>
Motivation: 近年来生成模型成果丰硕、应用广泛，相关领域文献和技术复杂度快速增长，研究者难以及时了解整体进展，因此需要一份系统梳理与总结。

Method: 提出了系统的分类体系，对主要的深度生成模型及其变体、融合方法进行组织和综述，横向归纳各自创新与优势，并结合技术与伦理双线索分析该领域。

Result: 总结了提升生成内容质量、多样性与可控性的关键创新，梳理了不同模型的技术演进，归纳了当前面临的主要伦理风险和社会影响，并探讨了未解难题和研究前沿。

Conclusion: 本综述为研究者提供了高效查阅、系统理解GANs、VAEs及扩散模型等主流生成模型及变体的框架，有助于把握技术全貌、创新趋势和道德挑战，并为未来研究指明方向。

Abstract: In recent years, deep learning based generative models, particularly
Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and
Diffusion Models (DMs), have been instrumental in in generating diverse,
high-quality content across various domains, such as image and video synthesis.
This capability has led to widespread adoption of these models and has captured
strong public interest. As they continue to advance at a rapid pace, the
growing volume of research, expanding application areas, and unresolved
technical challenges make it increasingly difficult to stay current. To address
this need, this survey introduces a comprehensive taxonomy that organizes the
literature and provides a cohesive framework for understanding the development
of GANs, VAEs, and DMs, including their many variants and combined approaches.
We highlight key innovations that have improved the quality, diversity, and
controllability of generated outputs, reflecting the expanding potential of
generative artificial intelligence. In addition to summarizing technical
progress, we examine rising ethical concerns, including the risks of misuse and
the broader societal impact of synthetic media. Finally, we outline persistent
challenges and propose future research directions, offering a structured and
forward looking perspective for researchers in this fast evolving field.

</details>


### [49] [Sprint: Sparse-Dense Residual Fusion for Efficient Diffusion Transformers](https://arxiv.org/abs/2510.21986)
*Dogyun Park,Moayed Haji-Ali,Yanyu Li,Willi Menapace,Sergey Tulyakov,Hyunwoo J. Kim,Aliaksandr Siarohin,Anil Kag*

Main category: cs.CV

TL;DR: 本文提出了SPRINT方法，通过在Diffusion Transformers（DiTs）中在不同深度采用稀疏-稠密残差融合，显著提升了训练效率，同时保持生成质量。SPRINT实现了高达75%的token丢弃率，训练效率提升近10倍，且生成质量几乎无损。


<details>
  <summary>Details</summary>
Motivation: 当前DiTs虽然生成性能优良，但其训练开销随序列长度呈二次增长，导致大规模预训练代价极高。传统token dropping策略虽可降低计算量，却容易损害表示能力，或在高丢弃率下失败。因此，需要一种既能高效丢弃token又能保持模型性能的新方法。

Method: SPRINT方法设计为：在网络浅层处理全部token以捕获细粒度局部信息，深层仅处理稀疏子集以减少计算量，最终通过残差连接融合稀疏/稠密信息。同时采用两阶段训练策略：先进行长时掩码预训练以提升效率，再用短时全token微调以弥补推理-训练差距。推理端引入PDG策略进一步节省计算并提升质量。

Result: 在ImageNet-1K 256x256数据集上，SPRINT方案实现了9.8倍的训练计算量节省，输出结果与原始方法相比FID/FDD指标相当。推理端通过PDG，实现了近乎减半的FLOPs并反向提升了生成质量。

Conclusion: SPRINT证明了一种简洁而高效的token稀疏选择及残差融合方式，可以大幅提升DiTs的训练与推理效率且质量无损，为高效训练Diffusion Transformer类模型提供了直接且通用的解决方案。

Abstract: Diffusion Transformers (DiTs) deliver state-of-the-art generative performance
but their quadratic training cost with sequence length makes large-scale
pretraining prohibitively expensive. Token dropping can reduce training cost,
yet na\"ive strategies degrade representations, and existing methods are either
parameter-heavy or fail at high drop ratios. We present SPRINT, Sparse--Dense
Residual Fusion for Efficient Diffusion Transformers, a simple method that
enables aggressive token dropping (up to 75%) while preserving quality. SPRINT
leverages the complementary roles of shallow and deep layers: early layers
process all tokens to capture local detail, deeper layers operate on a sparse
subset to cut computation, and their outputs are fused through residual
connections. Training follows a two-stage schedule: long masked pre-training
for efficiency followed by short full-token fine-tuning to close the
train--inference gap. On ImageNet-1K 256x256, SPRINT achieves 9.8x training
savings with comparable FID/FDD, and at inference, its Path-Drop Guidance (PDG)
nearly halves FLOPs while improving quality. These results establish SPRINT as
a simple, effective, and general solution for efficient DiT training.

</details>


### [50] [LiteDiff](https://arxiv.org/abs/2510.22004)
*Ruchir Namjoshi,Nagasai Thadishetty,Vignesh Kumar,Hemanth Venkateshwara*

Main category: cs.CV

TL;DR: 提出了一种名为Lite-Diff的轻量级扩散模型微调方法，能在有限领域数据和低计算资源下有效适应医学影像等专业领域。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在高质量图像生成领域表现突出，但在医学影像等特殊领域进行微调时，受限于数据稀缺和全模型适应的高计算代价，存在适应性差、过拟合等问题。亟需高效、低成本且能在小样本场景下稳定适应的新方法。

Method: Lite-Diff通过在冻结的扩散U-Net基础上引入轻量级的适应层，仅对小型残差适配器模块进行优化。同时，训练流程中结合了潜在空间形态自编码器（ تعزيز领域一致性）和像素级判别器（用于对抗性对齐），以增强模型对特定领域的泛化能力，并降低过拟合风险。还进行了消融实验分析不同U-Net层集成适应层的效率和表现。

Result: 在三个胸部X光公开数据集（Kaggle Chest X-Ray Pneumonia、NIH Chest X-ray14、VinBigData Chest X-ray）上的实验显示，Lite-Diff实现了比常规全量微调更优的适应效率和性能，在小样本条件下仍能有效提升结果。

Conclusion: Lite-Diff为扩散模型的迁移学习提供了有效且高效的新框架，特别适用于低数据量领域，如医学影像，显著减少了计算开销和过拟合风险，为实际应用和部署拓展了可能。

Abstract: In recent years, diffusion models have demonstrated remarkable success in
high-fidelity image synthesis. However, fine-tuning these models for
specialized domains, such as medical imaging, remains challenging due to
limited domain-specific data and the high computational cost of full model
adaptation. In this paper, we introduce Lite-Diff (Lightweight Diffusion Model
Adaptation), a novel finetuning approach that integrates lightweight adaptation
layers into a frozen diffusion U-Net while enhancing training with a latent
morphological autoencoder (for domain-specific latent consistency) and a pixel
level discriminator(for adversarial alignment). By freezing weights of the base
model and optimizing only small residual adapter modules, LiteDiff
significantly reduces the computational overhead and mitigates overfitting,
even in minimal-data settings. Additionally, we conduct ablation studies to
analyze the effects of selectively integrating adaptation layers in different
U-Net blocks, revealing an optimal balance between efficiency and performance.
Experiments on three chest X-ray datasets - (1) Kaggle Chest X-Ray Pneumonia,
(2) NIH Chest X-ray14 and (3) VinBigData Chest X_ray demonstrate that LiteDiff
achieves superior adaptation efficiency compared to naive full fine-tuning. Our
framework provides a promising direction for transfer learning in diffusion
models, facilitating their deployment in diverse low data domains.

</details>


### [51] [FlowOpt: Fast Optimization Through Whole Flow Processes for Training-Free Editing](https://arxiv.org/abs/2510.22010)
*Or Ronai,Vladimir Kulikov,Tomer Michaeli*

Main category: cs.CV

TL;DR: 提出了一种名为FlowOpt的零阶优化框架，通过将扩散或流匹配模型的采样过程视为黑盒，能够在无需反向传播的情况下高效地对整个采样路径进行优化，实现了高效、灵活的受控生成。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型等生成模型在受控生成（如图像编辑、个性化等）任务中的应用受到采样过程是迭代式的影响，导致无法直接采用梯度优化高效地控制生成结果；现有方法主要针对每个时间步做调整，效率有限。作者希望找到一种高效、全局的黑盒优化方案。

Method: 提出FlowOpt，一个基于零阶（无梯度）优化思想的框架，将整个扩散或流匹配过程作为黑盒处理，通过无需反向传播的黑盒优化方式对结果进行整体优化，同时允许中途观察和提前终止。方法还包括针对步长的收敛性分析和步长上界的经验估计。

Result: FlowOpt可有效用于扩散模型中的图像反演和文本引导的图像编辑，实验证明其在不增加神经网络调用次数的情况下，达到了最先进性能；并可灵活控制优化过程。

Conclusion: FlowOpt突破了扩散模型采样过程难以整体优化的难题，兼顾了效率与性能，为各类扩散相关的受控生成场景（如编辑、压缩等）提供了新的实用工具，对实际应用与后续研究很有启发意义。

Abstract: The remarkable success of diffusion and flow-matching models has ignited a
surge of works on adapting them at test time for controlled generation tasks.
Examples range from image editing to restoration, compression and
personalization. However, due to the iterative nature of the sampling process
in those models, it is computationally impractical to use gradient-based
optimization to directly control the image generated at the end of the process.
As a result, existing methods typically resort to manipulating each timestep
separately. Here we introduce FlowOpt - a zero-order (gradient-free)
optimization framework that treats the entire flow process as a black box,
enabling optimization through the whole sampling path without backpropagation
through the model. Our method is both highly efficient and allows users to
monitor the intermediate optimization results and perform early stopping if
desired. We prove a sufficient condition on FlowOpt's step-size, under which
convergence to the global optimum is guaranteed. We further show how to
empirically estimate this upper bound so as to choose an appropriate step-size.
We demonstrate how FlowOpt can be used for image editing, showcasing two
options: (i) inversion (determining the initial noise that generates a given
image), and (ii) directly steering the edited image to be similar to the source
image while conforming to a target text prompt. In both cases, FlowOpt achieves
state-of-the-art results while using roughly the same number of neural function
evaluations (NFEs) as existing methods. Code and examples are available on the
project's webpage.

</details>


### [52] [Reconnaissance Automatique des Langues des Signes : Une Approche Hybridée CNN-LSTM Basée sur Mediapipe](https://arxiv.org/abs/2510.22011)
*Fraisse Sacré Takouchouang,Ho Tuong Vinh*

Main category: cs.CV

TL;DR: 本文提出了一种基于CNN-LSTM混合架构的自动手语识别系统，结合Mediapipe关键点提取，实现了高精度（92%）的实时手势翻译，对明显手势表现优异，但对相似手势有一定混淆。


<details>
  <summary>Details</summary>
Motivation: 手语对聋哑群体至关重要，但常常被边缘化，导致他们在医疗、教育等关键服务中面临障碍。该研究旨在提升手语自动识别水平，辅助这些群体更便捷地获取服务。

Method: 采用CNN-LSTM混合神经网络框架，通过Mediapipe提取手势关键点，利用Python、TensorFlow与Streamlit开发，实现实时手语识别与翻译。

Result: 系统整体识别准确率达92%，对于如“Hello”“Thank you”等明显手势分类准确，对于“Call”“Yes”等相似手势会出现混淆。

Conclusion: 该系统在手语识别领域表现优异，有望在医疗、教育及公共服务等多个场景落地，为聋哑人士提供更好的辅助交流工具。

Abstract: Sign languages play a crucial role in the communication of deaf communities,
but they are often marginalized, limiting access to essential services such as
healthcare and education. This study proposes an automatic sign language
recognition system based on a hybrid CNN-LSTM architecture, using Mediapipe for
gesture keypoint extraction. Developed with Python, TensorFlow and Streamlit,
the system provides real-time gesture translation. The results show an average
accuracy of 92\%, with very good performance for distinct gestures such as
``Hello'' and ``Thank you''. However, some confusions remain for visually
similar gestures, such as ``Call'' and ``Yes''. This work opens up interesting
perspectives for applications in various fields such as healthcare, education
and public services.

</details>


### [53] [Caption-Driven Explainability: Probing CNNs for Bias via CLIP](https://arxiv.org/abs/2510.22035)
*Patrick Koller,Amil V. Dravid,Guido M. Schuster,Aggelos K. Katsaggelos*

Main category: cs.CV

TL;DR: 文章提出了一种基于描述生成（caption-based）的可解释人工智能（XAI）方法，用以改善现有显著性图方法在解释机器学习模型时的局限性，并提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统用于计算机视觉的XAI方法——显著性图，在图像存在重叠伪特征时可能误导模型解释，导致鲁棒性降低。因此，作者希望提出更有效、健壮的解释方法。

Method: 将需要解释的独立模型通过一种新颖的“网络手术”方式集成到CLIP模型中，实现能够输出文本描述的XAI。利用CLIP强大的跨模态对比学习能力，自动生成解释性描述，指出对模型预测影响最大的主导概念。

Result: 这种基于描述的XAI方法更好地识别了对模型推断影响最大的语义概念，有效减少模型因协变量偏移（covariate shift）所导致的解释误差。

Conclusion: 提出的方法提升了模型解释的准确性和鲁棒性，有助于发展更加稳健的机器学习模型。

Abstract: Robustness has become one of the most critical problems in machine learning
(ML). The science of interpreting ML models to understand their behavior and
improve their robustness is referred to as explainable artificial intelligence
(XAI). One of the state-of-the-art XAI methods for computer vision problems is
to generate saliency maps. A saliency map highlights the pixel space of an
image that excites the ML model the most. However, this property could be
misleading if spurious and salient features are present in overlapping pixel
spaces. In this paper, we propose a caption-based XAI method, which integrates
a standalone model to be explained into the contrastive language-image
pre-training (CLIP) model using a novel network surgery approach. The resulting
caption-based XAI model identifies the dominant concept that contributes the
most to the models prediction. This explanation minimizes the risk of the
standalone model falling for a covariate shift and contributes significantly
towards developing robust ML models.

</details>


### [54] [VLM-SlideEval: Evaluating VLMs on Structured Comprehension and Perturbation Sensitivity in PPT](https://arxiv.org/abs/2510.22045)
*Hyeonsu Kang,Emily Bao,Anjan Goswami*

Main category: cs.CV

TL;DR: 本文提出了VLM-SlideEval框架，用于系统评估视觉-语言模型（VLMs）对幻灯片内容的理解力，揭示其在多维任务上的局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管VLMs越来越多地用于评审多模态内容（如幻灯片），但其在幻灯片特定语境下的理解能力尚未得到充分探索，尤其是在自动化智能流程中作为审评者的作用变得更加重要。

Method: 作者构建了VLM-SlideEval评测框架，从三个方面评估VLMs：（1）元素级别的幻灯片图像内容抽取；（2）对几何、样式和文本扰动的鲁棒性；（3）对幻灯片整体叙事顺序的高级理解。实验基于公开的数据集，采用PowerPoint XML和渲染信息，统一成可验证的元数据格式。

Result: 实验表明，VLMs在像素精度内容抽取方面表现不佳，在受控扰动下具备一定一致性和可信度，但对单页内容的理解表现较好；在多页叙事结构理解方面能力有限。

Conclusion: 现有VLMs在幻灯片评测上存在明显短板，难以满足复杂智能流程对高层次理解的需求。作者建议结合校准及人类参与方法，以提升VLMs在自动化流程中的实际效用。

Abstract: Vision-language models (VLMs) are increasingly used to evaluate multimodal
content, including presentation slides, yet their slide-specific understanding
remains underexplored {despite their growing role as critics in agentic,
model-forward pipelines}. We introduce VLM-SlideEval, an evaluation framework
that probes VLMs along three axes: (1) element-level extraction from slide
images aligned to ground truth; (2) robustness to controlled perturbations in
geometry, style, and text; and (3) higher-level comprehension, such as
recovering a deck's narrative order from shuffled slides. Using publicly
available decks from Zenodo
(https://huggingface.co/datasets/Forceless/Zenodo10K/viewer/default/pptx), we
standardize ground-truth element metadata from PowerPoint XML and live
renderings into a unified, verifiable schema. Empirically, VLMs underperform on
pixel-accurate extraction and show non-trivial agreement, fidelity, and
consistency under controlled perturbations, while performing better on
single-slide content understanding; however, they do not reliably capture
narrative structure across slides. These results highlight the limits of
current VLMs for slide evaluation and motivate calibrated, critic-in-the-loop
evaluators that drive iterative refinement and selection in agentic pipelines.

</details>


### [55] [Human-Centric Anomaly Detection in Surveillance Videos Using YOLO-World and Spatio-Temporal Deep Learning](https://arxiv.org/abs/2510.22056)
*Mohammad Ali Etemadi Naeen,Hoda Mohammadzade,Saeed Bagheri Shouraki*

Main category: cs.CV

TL;DR: 本文提出了一种结合了以人为中心的预处理方法和时空建模的深度学习框架，有效提升了监控视频异常检测的准确性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 监控视频异常检测存在异常事件多样、类别不平衡、场景干扰等难题，亟需更精准、具泛化能力的方法应对实际复杂环境。

Method: 首先利用YOLO-World进行人类目标检测与ByteTrack实现跟踪，对非前景区域通过高斯模糊处理，聚焦于与行为相关的前景区。随后用InceptionV3提取空间特征，再用BiLSTM捕捉时序动态，最终进行多类别异常分类。

Result: 在UCF-Crime五分类子集上，平均测试准确率达92.41%，类别F1分数均大于0.85，各类综合评估指标显示其良好的泛化与类别不平衡抗性。

Conclusion: 以人为中心的前景提取结合时空特征深度模型，显著改善了真实监控场景下异常检测的判别力和稳定性。

Abstract: Anomaly detection in surveillance videos remains a challenging task due to
the diversity of abnormal events, class imbalance, and scene-dependent visual
clutter. To address these issues, we propose a robust deep learning framework
that integrates human-centric preprocessing with spatio-temporal modeling for
multi-class anomaly classification. Our pipeline begins by applying YOLO-World
- an open-vocabulary vision-language detector - to identify human instances in
raw video clips, followed by ByteTrack for consistent identity-aware tracking.
Background regions outside detected bounding boxes are suppressed via Gaussian
blurring, effectively reducing scene-specific distractions and focusing the
model on behaviorally relevant foreground content. The refined frames are then
processed by an ImageNet-pretrained InceptionV3 network for spatial feature
extraction, and temporal dynamics are captured using a bidirectional LSTM
(BiLSTM) for sequence-level classification. Evaluated on a five-class subset of
the UCF-Crime dataset (Normal, Burglary, Fighting, Arson, Explosion), our
method achieves a mean test accuracy of 92.41% across three independent trials,
with per-class F1-scores consistently exceeding 0.85. Comprehensive evaluation
metrics - including confusion matrices, ROC curves, and macro/weighted averages
- demonstrate strong generalization and resilience to class imbalance. The
results confirm that foreground-focused preprocessing significantly enhances
anomaly discrimination in real-world surveillance scenarios.

</details>


### [56] [Capturing Gaze Shifts for Guidance: Cross-Modal Fusion Enhancement for VLM Hallucination Mitigation](https://arxiv.org/abs/2510.22067)
*Zheng Qi,Chao Shang,Evangelia Spiliopoulou,Nikolaos Pappas*

Main category: cs.CV

TL;DR: 本文提出了一种名为GIFT的新方法，通过关注视觉注意力变化（凝视转移），提升视觉语言模型（VLM）消除幻觉内容的能力，显著减少生成不真实内容的概率。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型常产生与输入内容无关的幻觉，之前的方法仅加强视觉注意但未解决注意力误分配及多模态融合失衡的问题。亟需一种有效平衡跨模态关注、减轻视觉注意力误分配的方案。

Method: 作者提出GIFT方法，通过预先计算视觉“凝视转移”生成整体视觉显著性图，然后于每步生成时，利用此图同步增强对重要视觉区域和用户查询的关注，以减少壁垒不相关区域的关注并确保良好的跨模态融合。

Result: GIFT在多项生成和分类任务上显著减少了VLM的幻觉现象，在提高幻觉消除能力的同时，保持了整体性能，最高提升达20.7%，几乎无额外计算负担。

Conclusion: GIFT方法能有效缓解VLM幻觉问题，仅用低计算成本即可获得较佳跨模态表示和平衡，有助于提升后续视觉-语言任务的可靠性和实用性。

Abstract: Vision language models (VLMs) often generate hallucination, i.e., content
that cannot be substantiated by either textual or visual inputs. Prior work
primarily attributes this to over-reliance on linguistic prior knowledge rather
than visual inputs. Some methods attempt to mitigate hallucination by
amplifying visual token attention proportionally to their attention scores.
However, these methods overlook the visual attention sink problem, where
attention is frequently misallocated to task-irrelevant visual regions, and
neglect cross-modal fusion balance by enhancing only visual attention without
adjusting attention to the user query. This can result in amplifying incorrect
areas while failing to properly interpret the user query. To address these
challenges, we propose a simple yet effective method called Gaze Shift-Guided
Cross-modal Fusion Enhancement (GIFT). GIFT pre-computes a holistic visual
saliency map by tracking positive changes in visual attention, or "gaze
shifts", during user query comprehension, and leverages this map to amplify
attention to both salient visual information and the user query at each
decoding step. This reduces the impact of visual attention sink, as irrelevant
tokens exhibit minimal shifts, while ensuring balanced cross-modal fusion for
well-integrated representation. Extensive experiments show that GIFT
effectively mitigates hallucination in VLMs across both generative and
classification tasks, achieving up to 20.7% improvement over greedy decoding,
while maintaining general vision-language performance with low computational
overhead.

</details>


### [57] [Scanner-Agnostic MRI Harmonization via SSIM-Guided Disentanglement](https://arxiv.org/abs/2510.22073)
*Luca Caldera,Lara Cavinato,Francesca Ieva*

Main category: cs.CV

TL;DR: 该论文提出了一种新型的3D T1加权脑MRI图像谐和框架，有效减少多中心研究中不同扫描仪和协议带来的数据差异，提高了神经影像学研究的一致性和下游任务表现。


<details>
  <summary>Details</summary>
Motivation: 不同MRI扫描仪、扫描协议及成像地点的差异导致多中心神经影像学数据分析难以一致和泛化，影响科学研究的可靠性，需要新的方法实现数据谐和。

Method: 作者设计了一种基于图像的谐和模型，能够分离大脑结构的解剖信息与设备或场地带来的变异。创新地引入了基于结构相似性指数（SSIM）的可微损失函数来保持生物学特征，同时减少不同中心间的变异。模型在多个公开数据集上进行训练和验证，并通过多种风格目标（包括无风格参考）进行谐和，适用于健康和临床人群。

Result: 谐和后图像在视觉、体素强度分布、SSIM等评价指标上表现出良好的一致性和高保真度。结构SSIM提升至0.97，亮度SSIM为0.98-0.99，体素强度分布的Wasserstein距离明显降低。下游任务显著改善：大脑年龄预测绝对误差从5.36降至3.30，阿尔茨海默病分类AUC由0.78升至0.85。

Conclusion: 该方法能显著提高多中心MRI数据的图像一致性、保留主要解剖信息，并提升后续AI任务的效果，是大规模多中心神经影像学研究中鲁棒、通用的数据谐和解决方案。

Abstract: The variability introduced by differences in MRI scanner models, acquisition
protocols, and imaging sites hinders consistent analysis and generalizability
across multicenter studies. We present a novel image-based harmonization
framework for 3D T1-weighted brain MRI, which disentangles anatomical content
from scanner- and site-specific variations. The model incorporates a
differentiable loss based on the Structural Similarity Index (SSIM) to preserve
biologically meaningful features while reducing inter-site variability. This
loss enables separate evaluation of image luminance, contrast, and structural
components. Training and validation were performed on multiple publicly
available datasets spanning diverse scanners and sites, with testing on both
healthy and clinical populations. Harmonization using multiple style targets,
including style-agnostic references, produced consistent and high-quality
outputs. Visual comparisons, voxel intensity distributions, and SSIM-based
metrics demonstrated that harmonized images achieved strong alignment across
acquisition settings while maintaining anatomical fidelity. Following
harmonization, structural SSIM reached 0.97, luminance SSIM ranged from 0.98 to
0.99, and Wasserstein distances between mean voxel intensity distributions
decreased substantially. Downstream tasks showed substantial improvements: mean
absolute error for brain age prediction decreased from 5.36 to 3.30 years, and
Alzheimer's disease classification AUC increased from 0.78 to 0.85. Overall,
our framework enhances cross-site image consistency, preserves anatomical
fidelity, and improves downstream model performance, providing a robust and
generalizable solution for large-scale multicenter neuroimaging studies.

</details>


### [58] [Mitigating Coordinate Prediction Bias from Positional Encoding Failures](https://arxiv.org/abs/2510.22102)
*Xingjian Tao,Yiwei Wang,Yujun Cai,Yihong Luo,Jing Tang*

Main category: cs.CV

TL;DR: 本文发现多模态大语言模型（MLLMs）在高分辨率下精确坐标预测存在系统性偏差，而非随机错误。提出了无需训练的测试时纠偏方法VPSG，实验证明可提升坐标预测性能。


<details>
  <summary>Details</summary>
Motivation: 虽然MLLMs在视觉-语言任务上表现突出，但在处理高分辨率输入、准确预测坐标时效果不佳。本文旨在揭示这一现象背后的本质原因，发现主因是视觉位置编码失效而导致的方向性偏差，是制约该类模型空间推理性能的关键瓶颈。

Method: 作者通过分析和扰动视觉位置编码（VPE shuffle），系统性研究了坐标预测的偏差模式。基于分析，提出VPSG方法，在测试时对VPE进行辅助扰动解码，再结合有限状态机修正坐标数字输出，无需额外训练。

Result: 在ScreenSpot-Pro基准上测试，VPSG方案能有效纠正模型的方向性坐标偏差，坐标预测准确率显著提升。

Conclusion: 视觉位置编码稳定性对MLLMs空间推理至关重要。VPSG作为一种高效、无须训练的测试时纠偏方法，为提升MLLMs的精确空间定位能力提供了有效思路。

Abstract: Multimodal large language models (MLLMs) excel at vision-language tasks such
as VQA and document understanding, yet precise coordinate prediction remains
challenging. High-resolution inputs exacerbate this difficulty by producing
long token sequences that weaken positional encodings and introduce directional
biases in coordinate outputs. We investigate this phenomenon by analyzing how
MLLMs behave when visual positional encodings (VPEs) are deliberately perturbed
through shuffling. Our analysis reveals that such perturbations induce
predictable, non-random coordinate biases rather than random errors, suggesting
that models rely on internal positional priors when spatial grounding signals
are degraded. Crucially, we observe similar directional error patterns in
natural high-resolution datasets, indicating that positional encoding failures
are a key bottleneck for accurate coordinate prediction at scale. To address
this issue, we propose Vision-PE Shuffle Guidance (VPSG), a training-free
test-time method that leverages the directional nature of these biases for
correction. VPSG runs auxiliary decoding with shuffled VPEs to isolate
position-unconditioned tendencies, then uses this as negative evidence to guide
digit prediction while preserving coordinate format through a lightweight
finite-state machine. Experiments on ScreenSpot-Pro demonstrate reliable
improvements, highlighting positional encoding robustness as a critical factor
for spatial reasoning in MLLMs.

</details>


### [59] [Discovering Latent Graphs with GFlowNets for Diverse Conditional Image Generation](https://arxiv.org/abs/2510.22107)
*Bailey Trang,Parham Saremi,Alan Q. Wang,Fangrui Huang,Zahra TehraniNasab,Amar Kumar,Tal Arbel,Li Fei-Fei,Ehsan Adeli*

Main category: cs.CV

TL;DR: 该论文提出了Rainbow，一个通用的条件图像生成框架，能有效捕获条件和提示中的不确定性，生成多样、合理的图像。


<details>
  <summary>Details</summary>
Motivation: 在条件或提示存在不确定性时，通常可能产生多种合理的输出。现有方法要么通过更换随机种子获得变化有限的生成，要么通过更换输入提示实现口头多样性，效果有限。亟需一种能真正捕捉和表达条件多样性的方法。

Method: 提出将输入条件分解为多个潜在表示，每个表示捕捉到了不确定性的不同方面。具体实现为：引入一个由GFlowNets参数化的潜在图表示，利用其图采样能力，生成多条对应输入条件的不同潜在轨迹，并将其作为多样条件，输入已有的生成模型，最终输出多样图像。

Result: 实验证明Rainbow在自然图像和医学图像的数据集上，在图像合成、生成和反事实生成任务中，实现了图像多样性和保真度的双提升。

Conclusion: Rainbow框架普适性强，能与任何预训练的条件生成模型结合，并有效提升多样采样效果，是处理条件不确定性和提升生成多样性的有效手段。

Abstract: Capturing diversity is crucial in conditional and prompt-based image
generation, particularly when conditions contain uncertainty that can lead to
multiple plausible outputs. To generate diverse images reflecting this
diversity, traditional methods often modify random seeds, making it difficult
to discern meaningful differences between samples, or diversify the input
prompt, which is limited in verbally interpretable diversity. We propose
Rainbow, a novel conditional image generation framework, applicable to any
pretrained conditional generative model, that addresses inherent
condition/prompt uncertainty and generates diverse plausible images. Rainbow is
based on a simple yet effective idea: decomposing the input condition into
diverse latent representations, each capturing an aspect of the uncertainty and
generating a distinct image. First, we integrate a latent graph, parameterized
by Generative Flow Networks (GFlowNets), into the prompt representation
computation. Second, leveraging GFlowNets' advanced graph sampling capabilities
to capture uncertainty and output diverse trajectories over the graph, we
produce multiple trajectories that collectively represent the input condition,
leading to diverse condition representations and corresponding output images.
Evaluations on natural image and medical image datasets demonstrate Rainbow's
improvement in both diversity and fidelity across image synthesis, image
generation, and counterfactual generation tasks.

</details>


### [60] [GRAID: Enhancing Spatial Reasoning of VLMs Through High-Fidelity Data Generation](https://arxiv.org/abs/2510.22118)
*Karim Elmaaroufi,Liheng Lai,Justin Svegliato,Yutong Bai,Sanjit A. Seshia,Matei Zaharia*

Main category: cs.CV

TL;DR: GRAID框架通过只基于2D几何信息生成高质量视觉问答（VQA）数据，大幅提升视语言模型空间推理能力及数据质量。


<details>
  <summary>Details</summary>
Motivation: 现有视语言模型（VLMs）在空间推理任务上表现不佳，主因在于数据生成流程中3D重建误差较大及文本描述数据存在幻想和标注困难。迫切需要更可靠、更高质量的数据集，以推动模型在空间推理任务上的表现。

Method: 该文提出GRAID框架，仅依赖于标准物体检测器输出的2D边界框，通过分析几何空间关系（如空间关系、数量、排序和大小比较）自动生成VQA问答数据。避免了3D建模误差和文本生成带来的错误，通过人工评估确保数据质量。作者利用该框架在BDD100k、NuImages、Waymo等数据集上生成了850万多高质量问答数据。

Result: GRAID生成的数据集经过人工验证的准确率高达91.16%，远超当前主流方法的57.6%。用GRAID数据进行微调可使模型在空间推理任务的泛化能力大幅增强：Llama 3.2B/11B在BDD和NuImages上分别提升47.5%和37.9%。在BLINK等公开基准亦取得显著进步。

Conclusion: GRAID框架为视觉语言理解中的空间推理任务提供了高质量训练数据，既提升了数据集质量，也增强了模型对空间推理问题的理解和泛化能力。

Abstract: Vision Language Models (VLMs) achieve strong performance on many
vision-language tasks but often struggle with spatial reasoning\textemdash{}a
prerequisite for many applications. Empirically, we find that a dataset
produced by a current training data generation pipeline has a 57.6\% human
validation rate. These rates stem from current limitations: single-image 3D
reconstruction introduces cascading modeling errors and requires wide answer
tolerances, while caption-based methods require hyper-detailed annotations and
suffer from generative hallucinations. We present GRAID, built on the key
insight that qualitative spatial relationships can be reliably determined from
2D geometric primitives alone. By operating exclusively on 2D bounding boxes
from standard object detectors, GRAID avoids both 3D reconstruction errors and
generative hallucinations, resulting in datasets that are of higher quality
than existing tools that produce similar datasets as validated by human
evaluations. We apply our framework to the BDD100k, NuImages, and Waymo
datasets, generating over 8.5 million high-quality VQA pairs creating questions
spanning spatial relations, counting, ranking, and size comparisons. We
evaluate one of the datasets and find it achieves 91.16\% human-validated
accuracy\textemdash{}compared to 57.6\% on a dataset generated by recent work.
% or recent work Critically, we demonstrate that when trained on GRAID data,
models learn spatial reasoning concepts that generalize: models fine-tuned on 6
question types improve on over 10 held-out types, with accuracy gains of 47.5\%
on BDD and 37.9\% on NuImages for Llama 3.2B 11B, and when trained on all
questions types, achieve improvements on several existing benchmarks such as
BLINK. The GRAID framework, datasets, and additional information can be found
on our \href{https://ke7.github.io/graid/}{project page}.

</details>


### [61] [CogStereo: Neural Stereo Matching with Implicit Spatial Cognition Embedding](https://arxiv.org/abs/2510.22119)
*Lihuang Fang,Xiao Hu,Yuchen Zou,Hong Zhang*

Main category: cs.CV

TL;DR: CogStereo提出认知驱动的深度立体匹配方法，无需数据集特定先验，跨域泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的立体匹配方法在特定数据集微调后性能突出，但在新域上的零样本泛化能力不足，与其他视觉任务中的基础模型表现差距明显。作者希望提升立体匹配的跨域泛化及处理复杂区域（如遮挡、弱纹理）的能力。

Method: 提出CogStereo框架，将单目深度特征作为空间认知先验引入，嵌入于匹配结果的优化过程中，超越局部匹配，捕获对全局场景的理解；采用双条件优化机制，将像素不确定性与认知驱动特征结合，对失配区域进行全局一致性纠正。

Result: CogStereo在Scene Flow、KITTI、Middlebury、ETH3D、EuRoc等多个主流数据集以及真实场景上均取得了最新最优成绩，且在跨域测试中展现了优异的泛化能力。

Conclusion: CogStereo展示了基于空间认知的先验有助于提升立体匹配模型泛化性和结构一致性。该方法推动了立体视觉向认知驱动的方向发展，为实际复杂场景下稳定、准确的深度估计提供新思路。

Abstract: Deep stereo matching has advanced significantly on benchmark datasets through
fine-tuning but falls short of the zero-shot generalization seen in foundation
models in other vision tasks. We introduce CogStereo, a novel framework that
addresses challenging regions, such as occlusions or weak textures, without
relying on dataset-specific priors. CogStereo embeds implicit spatial cognition
into the refinement process by using monocular depth features as priors,
capturing holistic scene understanding beyond local correspondences. This
approach ensures structurally coherent disparity estimation, even in areas
where geometry alone is inadequate. CogStereo employs a dual-conditional
refinement mechanism that combines pixel-wise uncertainty with cognition-guided
features for consistent global correction of mismatches. Extensive experiments
on Scene Flow, KITTI, Middlebury, ETH3D, EuRoc, and real-world demonstrate that
CogStereo not only achieves state-of-the-art results but also excels in
cross-domain generalization, shifting stereo vision towards a cognition-driven
approach.

</details>


### [62] [Mint: A Simple Test-Time Adaptation of Vision-Language Models against Common Corruptions](https://arxiv.org/abs/2510.22127)
*Wenxuan Bao,Ruxi Deng,Jingrui He*

Main category: cs.CV

TL;DR: 本文发现CLIP等视觉-语言预训练模型在遇到输入扰动时，其特征嵌入空间出现“嵌入方差塌缩”，导致分类性能下降。作者提出了一种基于伪标签的推理时自适应新方法Mint，通过最大化类别间方差缓解该问题，实验证明其有效提升了性能。


<details>
  <summary>Details</summary>
Motivation: CLIP等模型虽具有强大的零样本泛化能力，但在面对图像扰动等分布移位时表现明显下降。理解其鲁棒性弱的原因，并提出提升方法具有重要意义。

Method: 作者首先分析了扰动如何影响CLIP的嵌入空间，发现扰动导致嵌入表示空间的“嵌入方差塌缩”（即类内与类间方差均减小）；随后理论分析表明，视觉编码器受到扰动信号影响，削弱了类别判别性。基于此，提出了一种新颖的推理时自适应方法Mint，通过不断最大化伪标签下的类别间方差来提升嵌入区分度，且不依赖标签，在小批量下也表现良好。

Result: 实验证明，Mint在多个图像扰动基准和不同CLIP架构上均能稳定有效提升分类性能，超过了现有一些应对扰动的方案。

Conclusion: 嵌入方差塌缩是导致视觉-语言模型输入扰动下性能下降的核心原因，最大化类别间方差的简单自适应方法Mint能够有效缓解该问题，增强模型的稳健性。

Abstract: Pretrained vision-language models such as CLIP achieve strong zero-shot
generalization but remain vulnerable to distribution shifts caused by input
corruptions. In this work, we investigate how corruptions affect CLIP's image
embeddings and uncover a consistent phenomenon we term as embedding variance
collapse, where both intra-class and inter-class variances shrink as corruption
severity increases. We find that this collapse is closely tied to performance
degradation, with inter-class variance strongly correlated with classification
accuracy. To explain this phenomenon, we analyze how corruptions alter the
structure of the embedding space. Our theoretical results suggest that the
visual encoder tends to encode corruption-related signals, which dilute
class-discriminative features and compress the representation geometry. We
further show that maximizing inter-class variance, even when estimated from
pseudo-labels, can provably enhance embedding quality. Based on this insight,
we propose Mint, a simple test-time adaptation method that maximizes
pseudo-label-based inter-class variance on the fly using a mean accumulator and
a gradient accumulator. Mint operates effectively with small batch sizes and
consistently improves performance across multiple corruption benchmarks and
CLIP architectures. Our code is available at https://github.com/baowenxuan/Mint .

</details>


### [63] [egoEMOTION: Egocentric Vision and Physiological Signals for Emotion and Personality Recognition in Real-World Tasks](https://arxiv.org/abs/2510.22129)
*Matthias Jammot,Bjöern Braun,Paul Streli,Rafael Wampfler,Christian Holz*

Main category: cs.CV

TL;DR: 本文提出了egoEMOTION，是首个结合头戴设备视觉与生理信号以及密集自我情感与人格报告的数据集，实现了情感和人格在第一视角感知任务中的基准评测。


<details>
  <summary>Details</summary>
Motivation: 现有的第一视角视觉数据集和任务主要关注物理活动和交互，忽视了影响人类行为的重要内在因素——情感和人格，导致视觉系统无法真实预测行为动因。

Method: 该研究采集了43名参与者共50小时数据，使用Meta Aria眼镜同步记录眼动视频、光电容积描记（PPG）、惯性数据及生理基线。参与者完成情感引发和自然任务并自报告情感（Circumplex模型、Mikels情感轮）和人格（Big Five量表）。研究设定了三项基准任务：情感（连续/离散）和人格推断，并用经典机器学习方法对比了视觉信号与生理信号的预测效果。

Result: 实验证明，在现实世界中进行情感预测时，基于视觉系统采集信号的模型较仅用生理信号表现更优，验证了视觉线索的重要性。

Conclusion: egoEMOTION数据集确立了情感和人格为第一视角感知的核心维度，推动了基于情感动力的行为、意图与交互建模研究。

Abstract: Understanding affect is central to anticipating human behavior, yet current
egocentric vision benchmarks largely ignore the person's emotional states that
shape their decisions and actions. Existing tasks in egocentric perception
focus on physical activities, hand-object interactions, and attention modeling
- assuming neutral affect and uniform personality. This limits the ability of
vision systems to capture key internal drivers of behavior. In this paper, we
present egoEMOTION, the first dataset that couples egocentric visual and
physiological signals with dense self-reports of emotion and personality across
controlled and real-world scenarios. Our dataset includes over 50 hours of
recordings from 43 participants, captured using Meta's Project Aria glasses.
Each session provides synchronized eye-tracking video, headmounted
photoplethysmography, inertial motion data, and physiological baselines for
reference. Participants completed emotion-elicitation tasks and naturalistic
activities while self-reporting their affective state using the Circumplex
Model and Mikels' Wheel as well as their personality via the Big Five model. We
define three benchmark tasks: (1) continuous affect classification (valence,
arousal, dominance); (2) discrete emotion classification; and (3) trait-level
personality inference. We show that a classical learning-based method, as a
simple baseline in real-world affect prediction, produces better estimates from
signals captured on egocentric vision systems than processing physiological
signals. Our dataset establishes emotion and personality as core dimensions in
egocentric perception and opens new directions in affect-driven modeling of
behavior, intent, and interaction.

</details>


### [64] [STG-Avatar: Animatable Human Avatars via Spacetime Gaussian](https://arxiv.org/abs/2510.22140)
*Guangan Jiang,Tianzi Zhang,Dong Li,Zhenjun Zhao,Haoang Li,Mingrui Li,Hongyu Wang*

Main category: cs.CV

TL;DR: 本文提出了一种基于3D高斯球(3DGS)的新型人类动画化头像重建方法STG-Avatar，可以从单目视频中高保真重建可动画的人物头像，有效提升了动态和非刚性区域的细节表现，同时实现了实时渲染。


<details>
  <summary>Details</summary>
Motivation: 目前基于3DGS的人体头像重建方法在处理非刚性物体（如服装变形）和动态区域（如快速移动的四肢）时表现不足，难以准确还原细节，因此需要新的方法提升这些方面的表现。

Method: STG-Avatar框架创新性地结合了Spacetime Gaussians（STG）与线性混合蒙皮（LBS），提出刚体-非刚体耦合变形方案。LBS用于驱动整体骨骼变换，实现实时控制；STG则对3D高斯球进行时空自适应优化，并利用光流检测高动态区域，引导这些区域的高斯球自适应加密，以提升动态细节。

Result: 实验结果显示，该方法在重建质量和运行效率上均超过了现有主流方法，能够实现更高精度的定量指标且保持实时渲染能力。

Conclusion: STG-Avatar显著提升了从单目视频重建高保真、可动画化人类头像的能力，尤其在动态和非刚性区域表现突出，为虚拟人类和人机交互等领域提供了技术进步。

Abstract: Realistic animatable human avatars from monocular videos are crucial for
advancing human-robot interaction and enhancing immersive virtual experiences.
While recent research on 3DGS-based human avatars has made progress, it still
struggles with accurately representing detailed features of non-rigid objects
(e.g., clothing deformations) and dynamic regions (e.g., rapidly moving limbs).
To address these challenges, we present STG-Avatar, a 3DGS-based framework for
high-fidelity animatable human avatar reconstruction. Specifically, our
framework introduces a rigid-nonrigid coupled deformation framework that
synergistically integrates Spacetime Gaussians (STG) with linear blend skinning
(LBS). In this hybrid design, LBS enables real-time skeletal control by driving
global pose transformations, while STG complements it through spacetime
adaptive optimization of 3D Gaussians. Furthermore, we employ optical flow to
identify high-dynamic regions and guide the adaptive densification of 3D
Gaussians in these regions. Experimental results demonstrate that our method
consistently outperforms state-of-the-art baselines in both reconstruction
quality and operational efficiency, achieving superior quantitative metrics
while retaining real-time rendering capabilities. Our code is available at
https://github.com/jiangguangan/STG-Avatar

</details>


### [65] [LOC: A General Language-Guided Framework for Open-Set 3D Occupancy Prediction](https://arxiv.org/abs/2510.22141)
*Yuhang Gao,Xiang Xiang,Sheng Zhong,Guoyou Wang*

Main category: cs.CV

TL;DR: 提出了一种新的语言引导的3D场景理解框架（LOC），能在监督和自监督下提升开集识别，且无需额外训练数据即可区分未知类别。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉-语言模型（VLMs）在开集任务上表现优异，但由于缺乏3D数据集，VLMs很难有效应用于3D场景理解。因此，亟需提升3D理解任务中模型的泛化和开集识别能力。

Method: 提出LOC通用框架，支持多种3D占用网络，兼容监督与自监督学习。在自监督方面，融合多帧LiDAR点云并使用Poisson重建填补空洞，通过KNN分配体素语义，获得丰富体素表达。为避免特征同质化，设计了Densely Contrastive Learning（DCL）方法，结合体素语义与文本提示，实现更高效的开集识别。模型输出嵌入CLIP特征空间的密集体素特征，通过文本及语义相似性分类。

Result: 在nuScenes数据集上进行实验，结果显示该方法在已知类别上达到了高精度，并能在无需额外训练数据的情况下区分未知类别，优于现有方法。

Conclusion: LOC框架通过创新的自监督和密集对比学习机制，显著增强了3D理解任务中开集识别能力，可广泛应用于3D场景理解等任务。

Abstract: Vision-Language Models (VLMs) have shown significant progress in open-set
challenges. However, the limited availability of 3D datasets hinders their
effective application in 3D scene understanding. We propose LOC, a general
language-guided framework adaptable to various occupancy networks, supporting
both supervised and self-supervised learning paradigms. For self-supervised
tasks, we employ a strategy that fuses multi-frame LiDAR points for
dynamic/static scenes, using Poisson reconstruction to fill voids, and
assigning semantics to voxels via K-Nearest Neighbor (KNN) to obtain
comprehensive voxel representations. To mitigate feature over-homogenization
caused by direct high-dimensional feature distillation, we introduce Densely
Contrastive Learning (DCL). DCL leverages dense voxel semantic information and
predefined textual prompts. This efficiently enhances open-set recognition
without dense pixel-level supervision, and our framework can also leverage
existing ground truth to further improve performance. Our model predicts dense
voxel features embedded in the CLIP feature space, integrating textual and
image pixel information, and classifies based on text and semantic similarity.
Experiments on the nuScenes dataset demonstrate the method's superior
performance, achieving high-precision predictions for known classes and
distinguishing unknown classes without additional training data.

</details>


### [66] [Attention Residual Fusion Network with Contrast for Source-free Domain Adaptation](https://arxiv.org/abs/2510.22142)
*Renrong Shao,Wei Zhang,Jun Wang*

Main category: cs.CV

TL;DR: 本文提出了一种基于对比学习的新型注意力残差融合网络（ARFNet）用于源无关域自适应（SFDA），通过多种创新机制显著提升在该任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 源无关域自适应任务中，无法获取源域数据，且场景信息复杂，当前方法多侧重于解决域间偏移，而常忽视了负迁移问题；负迁移会阻碍模型性能的提升，因此需要兼顾这两方面的问题。

Method: 提出ARFNet框架，利用注意力机制分辨目标的判别区域，对特征进行空间和通道的逐层注意力残差融合与自蒸馏。同时，通过对比全局-局部表示，增强类别区分能力。采用动态质心评估策略生成可靠的类中心和伪标签，实现更加接近源域的数据分布自蒸馏，最终在不依赖源数据的情况下实现有效域适应。

Result: 在五个不同规模的主流基准数据集上进行了实验，结果表明ARFNet在所有SFDA数据集上均获得了优于现有方法的性能。

Conclusion: 所提ARFNet框架能够同时缓解域偏移与负迁移问题，在源无关域自适应任务上取得了领先的性能表现。

Abstract: Source-free domain adaptation (SFDA) involves training a model on source
domain and then applying it to a related target domain without access to the
source data and labels during adaptation. The complexity of scene information
and lack of the source domain make SFDA a difficult task. Recent studies have
shown promising results, but many approaches to domain adaptation concentrate
on domain shift and neglect the effects of negative transfer, which may impede
enhancements of model performance during adaptation. n this paper, addressing
this issue, we propose a novel framework of Attention Residual Fusion Network
(ARFNet) based on contrast learning for SFDA to alleviate negative transfer and
domain shift during the progress of adaptation, in which attention residual
fusion, global-local attention contrast, and dynamic centroid evaluation are
exploited. Concretely, the attention mechanism is first exploited to capture
the discriminative region of the target object. Then, in each block, attention
features are decomposed into spatial-wise and channel-wise attentions to
achieve the cross-layer attention residual fusion progressively and
self-distillation. During adaptation progress, we contrast global and local
representations to improve the perceptual capabilities of different categories,
which enables the model to discriminate variations between inner-class and
intra-class. Finally, a dynamic centroid evaluation strategy is exploited to
evaluate the trustworthy centroids and labels for self-supervised
self-distillation, which aims to accurately approximate the center of the
source domain and pseudo-labels to mitigate domain shift. To validate the
efficacy, we execute comprehensive experiments on five benchmarks of varying
scales. Experimental outcomes indicate that our method surpasses other
techniques, attaining superior performance across SFDA benchmarks.

</details>


### [67] [I2-NeRF: Learning Neural Radiance Fields Under Physically-Grounded Media Interactions](https://arxiv.org/abs/2510.22161)
*Shuhong Liu,Lin Gu,Ziteng Cui,Xuangeng Chu,Tatsuya Harada*

Main category: cs.CV

TL;DR: 论文提出I2-NeRF框架，通过改进采样和退化介质建模，提高了生成式AI对真实3D物理世界的度量感知能力，特别适用于复杂环境如水下、雾霾和弱光下。实验显示该方法在重建精度和物理合理性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的NeRF模型主要依赖以物体为中心的采样方法，无法很好地保持空间等距性，同时对介质退化（如水下、雾霾等）场景的3D度量感知能力有限。为增强生成式AI与真实3D世界的交互能力，有必要提升其在复杂介质环境中的感知精度与物理一致性。

Method: 提出一种逆分层上采样策略，实现3D空间的近似均匀采样，以保持等距性。引入基于Beer-Lambert定律的广义介质退化辐射模型，将发射、吸收和散射统一为粒子模型，综合考虑直接光和介质诱发的入射散射辐射，适应各种复杂介质（如水下、雾霾、弱光）。光传播在各方向一致处理，从而支持各向同性度量感知及估算介质属性（如水深）。

Result: 在真实世界数据集上进行实验，结果表明I2-NeRF在重建精度和物理合理性方面都显著优于现有NeRF及相关方法。

Conclusion: I2-NeRF通过创新的采样策略和一般化的介质退化建模，大幅提升了复杂环境下的三维重建质量与物理一致性，为生成式AI提升3D世界的度量和理解能力开辟了新方向。

Abstract: Participating in efforts to endow generative AI with the 3D physical world
perception, we propose I2-NeRF, a novel neural radiance field framework that
enhances isometric and isotropic metric perception under media degradation.
While existing NeRF models predominantly rely on object-centric sampling,
I2-NeRF introduces a reverse-stratified upsampling strategy to achieve
near-uniform sampling across 3D space, thereby preserving isometry. We further
present a general radiative formulation for media degradation that unifies
emission, absorption, and scattering into a particle model governed by the
Beer-Lambert attenuation law. By composing the direct and media-induced
in-scatter radiance, this formulation extends naturally to complex media
environments such as underwater, haze, and even low-light scenes. By treating
light propagation uniformly in both vertical and horizontal directions, I2-NeRF
enables isotropic metric perception and can even estimate medium properties
such as water depth. Experiments on real-world datasets demonstrate that our
method significantly improves both reconstruction fidelity and physical
plausibility compared to existing approaches.

</details>


### [68] [HARMONY: Hidden Activation Representations and Model Output-Aware Uncertainty Estimation for Vision-Language Models](https://arxiv.org/abs/2510.22171)
*Erum Mushtaq,Zalan Fabian,Yavuz Faruk Bakman,Anil Ramakrishna,Mahdi Soltanolkotabi,Salman Avestimehr*

Main category: cs.CV

TL;DR: 提出了一种新的视觉-语言模型（VLM）不确定性估计框架HARMONY，通过结合模型激活中的多模态信息和输出分布，提高生成结果的可信度判断。该方法在多个基准数据集和主流VLM模型上表现优越，刷新了不确定性估计算法的性能。


<details>
  <summary>Details</summary>
Motivation: 随着视觉-语言模型被广泛应用于自动驾驶、辅助视觉等高风险场景，模型输出的可靠性变得至关重要。传统的不确定性估算方法存在无法有效捕捉多模态语义关系以及受语言先验影响的概率偏差等问题，因此亟需更可靠的不确定性估算机制。

Method: 提出HARMONY框架，联合利用模型激活中的多模态特征和输出分布信息，对模型输出的可靠性进行估算。假设模型内部的视觉理解信念（由隐藏表示捕捉）以及生成的token概率都包含有价值的置信度信号。通过融合二者提升不确定性估算准确性。

Result: 在A-OKVQA, VizWiz和PathVQA三个VQA基准以及LLaVa-7b、LLaVA-13b、InstructBLIP三种主流VLM上进行实验，HARMONY方法的AUROC提升最高达4%，PRR提升最高达6%，整体性能优于现有方法。

Conclusion: HARMONY框架能够更好地利用模型内在多模态信息和输出分布，提高VLM生成结果的置信度判断，是当前视觉-语言模型不确定性估算领域的新SOTA方法。

Abstract: The growing deployment of Vision-Language Models (VLMs) in high-stakes
applications such as autonomous driving and assistive technologies for visually
impaired individuals necessitates reliable mechanisms to assess the
trustworthiness of their generation. Uncertainty Estimation (UE) plays a
central role in quantifying the reliability of model outputs and reducing
unsafe generations via selective prediction. In this regard, most existing
probability-based UE approaches rely on output probability distributions,
aggregating token probabilities into a single uncertainty score using
predefined functions such as length-normalization. Another line of research
leverages model hidden representations and trains MLP-based models to predict
uncertainty. However, these methods often fail to capture the complex
multimodal relationships between semantic and textual tokens and struggle to
identify biased probabilities often influenced by language priors. Motivated by
these observations, we propose a novel UE framework, HARMONY, that jointly
leverages fused multimodal information in model activations and the output
distribution of the VLM to determine the reliability of responses. The key
hypothesis of our work is that both the model's internal belief in its visual
understanding, captured by its hidden representations, and the produced token
probabilities carry valuable reliability signals that can be jointly leveraged
to improve UE performance, surpassing approaches that rely on only one of these
components. Experimental results on three open-ended VQA benchmarks, A-OKVQA,
VizWiz, and PathVQA, and three state-of-the-art VLMs, LLaVa-7b, LLaVA-13b and
InstructBLIP demonstrate that our method consistently performs on par with or
better than existing approaches, achieving up to 4\% improvement in AUROC, and
6\% in PRR, establishing new state of the art in uncertainty estimation for
VLMs.

</details>


### [69] [Scaling Non-Parametric Sampling with Representation](https://arxiv.org/abs/2510.22196)
*Vincent Lu,Aaron Truong,Zeyu Yun,Yubei Chen*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练、非参数化的简单生成模型，可生成高质量的图像，揭示了自然图像结构的最小理论，并通过追踪生成像素来源实现模型机理透明。


<details>
  <summary>Details</summary>
Motivation: 当前主流图像生成模型虽然能生成高度逼真的图像，但其内部机制难以理解，且依赖于复杂的工程设计。作者希望通过去除冗余工程方法，设计一种结构极简、可解释性强而且无需训练的生成模型，并以此探索自然图像的基础结构及生成原理。

Method: 该方法基于自然图像的三个基本特性：空间非平稳性、低级别规律性以及高级别语义。具体做法是利用像素的局部上下文窗口定义每个像素的分布，完全摒弃复杂参数及工程技巧，也无需训练过程。

Result: 模型在MNIST上可生成高保真样本，在CIFAR-10上也展现出有视觉吸引力的生成效果。文章还通过追踪每个生成像素的来源，能够清晰地分析模型的生成与泛化机制。

Conclusion: 该研究提出了一种结构极简又性能良好的生成模型，为理解自然图像的生成规律提供了理论基础，也为今后神经网络生成模型的可解释性与泛化机制研究提供了新视角。

Abstract: Scaling and architectural advances have produced strikingly photorealistic
image generative models, yet their mechanisms still remain opaque. Rather than
advancing scaling, our goal is to strip away complicated engineering tricks and
propose a simple, non-parametric generative model. Our design is grounded in
three principles of natural images-(i) spatial non-stationarity, (ii) low-level
regularities, and (iii) high-level semantics-and defines each pixel's
distribution from its local context window. Despite its minimal architecture
and no training, the model produces high-fidelity samples on MNIST and visually
compelling CIFAR-10 images. This combination of simplicity and strong empirical
performance points toward a minimal theory of natural-image structure. The
model's white-box nature also allows us to have a mechanistic understanding of
how the model generalizes and generates diverse images. We study it by tracing
each generated pixel back to its source images. These analyses reveal a simple,
compositional procedure for "part-whole generalization", suggesting a
hypothesis for how large neural network generative models learn to generalize.

</details>


### [70] [MOGRAS: Human Motion with Grasping in 3D Scenes](https://arxiv.org/abs/2510.22199)
*Kunal Bhosikar,Siddharth Katageri,Vivek Madhavaram,Kai Han,Charu Sharma*

Main category: cs.CV

TL;DR: 本文提出并发布了一个大规模的3D场景下人体动作及抓取姿态数据集MOGRAS，同时提出了改进方法以实现更真实的全身抓取动作。


<details>
  <summary>Details</summary>
Motivation: 现有全身动作生成方法对于精细任务如抓取，存在真实感不足，而专注于手部抓取的研究又忽略了场景信息，缺乏在复杂3D场景中实现物理合理全身抓取动作的方法。

Method: 作者构建了MOGRAS数据集，包含丰富标注的3D室内场景中的全身运动与抓取姿态，并基于此对现有方法进行基准测试。同时，提出一种简单有效的方法，适配现有动作生成方法以增强其场景感知能力，实现全身抓取动作的生成。

Result: 实验展示了MOGRAS数据集在支持相关研究方面的价值，并用定量与定性实验证明所提出方法在全身抓取动作生成的真实性和场景适应性上都有显著提升。

Conclusion: MOGRAS数据集填补了全身动作与抓取场景结合的空白，所提方法推动了人-场景交互的研究发展，有助于更自然的虚拟人机/机器人场景交互。

Abstract: Generating realistic full-body motion interacting with objects is critical
for applications in robotics, virtual reality, and human-computer interaction.
While existing methods can generate full-body motion within 3D scenes, they
often lack the fidelity for fine-grained tasks like object grasping.
Conversely, methods that generate precise grasping motions typically ignore the
surrounding 3D scene. This gap, generating full-body grasping motions that are
physically plausible within a 3D scene, remains a significant challenge. To
address this, we introduce MOGRAS (Human MOtion with GRAsping in 3D Scenes), a
large-scale dataset that bridges this gap. MOGRAS provides pre-grasping
full-body walking motions and final grasping poses within richly annotated 3D
indoor scenes. We leverage MOGRAS to benchmark existing full-body grasping
methods and demonstrate their limitations in scene-aware generation.
Furthermore, we propose a simple yet effective method to adapt existing
approaches to work seamlessly within 3D scenes. Through extensive quantitative
and qualitative experiments, we validate the effectiveness of our dataset and
highlight the significant improvements our proposed method achieves, paving the
way for more realistic human-scene interactions.

</details>


### [71] [LongCat-Video Technical Report](https://arxiv.org/abs/2510.22200)
*Meituan LongCat Team,Xunliang Cai,Qilong Huang,Zhuoliang Kang,Hongyu Li,Shijun Liang,Liya Ma,Siyu Ren,Xiaoming Wei,Rixu Xie,Tong Zhang*

Main category: cs.CV

TL;DR: LongCat-Video是一款拥有13.6B参数的视频生成基础模型，能高效、高质量地生成长视频，同时支持多种视频生成任务，表现优异。代码和模型已开源。


<details>
  <summary>Details</summary>
Motivation: 目前视频生成领域亟需能够高效生成长视频的基础模型，以支持世界模型等更复杂的AI任务。本研究旨在突破现有模型在长视频生成上的效率与质量瓶颈，实现统一、多任务能力。

Method: 该模型基于Diffusion Transformer（DiT）架构设计，统一支持文本生成视频、图片生成视频和视频续写等多种任务。通过在视频续写任务上进行预训练，以提升长视频生成的时序一致性和质量。采用时空轴上的逐步粗到细生成策略，并利用块稀疏注意力机制优化高分辨率下的推理效率。同时引入多奖励的RLHF训练优化性能。

Result: LongCat-Video在多个主流视频生成任务上表现强劲。能够分钟级生成720p、30fps长视频，兼具高质量和时序连贯性。多奖励RLHF训练使其性能媲美最新的闭源及主流开源模型。

Conclusion: LongCat-Video首次将高效长视频生成、多任务统一架构和开源集于一身，为世界模型基础设施迈出关键一步，有望推动视频生成及相关领域的快速发展。

Abstract: Video generation is a critical pathway toward world models, with efficient
long video inference as a key capability. Toward this end, we introduce
LongCat-Video, a foundational video generation model with 13.6B parameters,
delivering strong performance across multiple video generation tasks. It
particularly excels in efficient and high-quality long video generation,
representing our first step toward world models. Key features include: Unified
architecture for multiple tasks: Built on the Diffusion Transformer (DiT)
framework, LongCat-Video supports Text-to-Video, Image-to-Video, and
Video-Continuation tasks with a single model; Long video generation:
Pretraining on Video-Continuation tasks enables LongCat-Video to maintain high
quality and temporal coherence in the generation of minutes-long videos;
Efficient inference: LongCat-Video generates 720p, 30fps videos within minutes
by employing a coarse-to-fine generation strategy along both the temporal and
spatial axes. Block Sparse Attention further enhances efficiency, particularly
at high resolutions; Strong performance with multi-reward RLHF: Multi-reward
RLHF training enables LongCat-Video to achieve performance on par with the
latest closed-source and leading open-source models. Code and model weights are
publicly available to accelerate progress in the field.

</details>


### [72] [TrajGATFormer: A Graph-Based Transformer Approach for Worker and Obstacle Trajectory Prediction in Off-site Construction Environments](https://arxiv.org/abs/2510.22205)
*Mohammed Alduais,Xinming Li,Qipei Mei*

Main category: cs.CV

TL;DR: 本文提出了一种结合YOLOv10n和DeepSORT的检测与追踪框架，并创新性地设计了TrajGATFormer与TrajGATFormer-Obstacle两种轨迹预测模型，用于提升施工现场人员与障碍物的轨迹预测准确性，进而提高工地安全性。


<details>
  <summary>Details</summary>
Motivation: 施工行业对更快、更安全、更高效的流程需求不断增长。尽管离线施工(Offsite construction)能提升效率，但也带来了因人与机器及障碍物紧密交互的新安全风险。传统方法难以适应施工环境的动态复杂性，对预测碰撞及风险评估的能力有限，因此需要一种能够集成人、机器、社会与环境因素的新型轨迹预测软件模型。

Method: 本文构建了以YOLOv10n为主干的对象检测系统，结合DeepSORT实现工人和移动障碍物的高效多目标跟踪。轨迹预测模型采用transformer编码器-解码器结构，融合了图注意力网络（GAT），分别提出TrajGATFormer（仅针对工人）和TrajGATFormer-Obstacle（扩展至工人与障碍物）。通过对时空和社会因素的建模，提高了对未来轨迹的预测能力。

Result: TrajGATFormer模型在4.8秒的预测时长内，平均偏差ADE为1.25米，末端偏差FDE为2.3米。TrajGATFormer-Obstacle模型进一步提升准确率，ADE为1.15米，FDE为2.2米。对比传统方法，两模型可分别降低ADE和FDE达35%和38%。

Conclusion: 集成目标检测与基于图注意力机制的轨迹预测框架能更准确地预测工地人员与障碍物轨迹，显著优于传统方法，有助于提升施工环境下的实时风险识别和安全保障水平。

Abstract: As the demand grows within the construction industry for processes that are
not only faster but also safer and more efficient, offsite construction has
emerged as a solution, though it brings new safety risks due to the close
interaction between workers, machinery, and moving obstacles. Predicting the
future trajectories of workers and taking into account social and environmental
factors is a crucial step for developing collision-avoidance systems to
mitigate such risks. Traditional methods often struggle to adapt to the dynamic
and unpredictable nature of construction environments. Many rely on simplified
assumptions or require hand-crafted features, limiting their ability to respond
to complex, real-time interactions between workers and moving obstacles. While
recent data-driven methods have improved the modeling of temporal patterns,
they still face challenges in capturing long-term behavior and accounting for
the spatial and social context crucial to collision risk assessment. To address
these limitations, this paper proposes a framework integrating YOLOv10n and
DeepSORT for precise detection and tracking, along with two novel trajectory
prediction models: TrajGATFormer and TrajGATFormer-Obstacle. YOLOv10n serves as
the backbone for object detection, accurately identifying workers and obstacles
in diverse scenes, while DeepSORT efficiently tracks them over time with unique
IDs for continuity. Both models employ a transformer encoder-decoder with Graph
Attention Networks (GAT) to capture temporal and spatial interactions.
TrajGATFormer predicts worker trajectories with an ADE of 1.25 m and FDE of 2.3
m over a 4.8 s horizon, while TrajGATFormer-Obstacle extends prediction to both
workers and obstacles, achieving higher accuracy (ADE 1.15 m, FDE 2.2 m).
Comparative analysis shows both models outperform traditional methods, reducing
ADE and FDE by up to 35% and 38%, respectively.

</details>


### [73] [DynamicTree: Interactive Real Tree Animation via Sparse Voxel Spectrum](https://arxiv.org/abs/2510.22213)
*Yaokun Li,Lihe Ding,Xiao Chen,Guang Tan,Tianfan Xue*

Main category: cs.CV

TL;DR: 本文提出了一种名为DynamicTree的新方法，可以高效生成真实的3D树木动态动画，特别适用于虚拟现实、游戏和模拟等领域。通过创新的稀疏体素频谱和新的4D树数据集，实现了真实高效的树木运动建模。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成复杂真实树木的4D动态时面临着难以真实、响应慢、计算成本高等问题，因此需要一种既能保持真实感又能高效交互的新方法。

Method: 1. 提出DynamicTree框架，使用稀疏体素频谱（Sparse Voxel Spectrum）紧凑表示树的运动。2. 先利用该频谱生成网格运动；再将高斯点绑定到网格实现形变。3. 该体素频谱还能支持外力实时、可交互响应。4. 构建了名为4DTree的大规模合成4D树数据集用于训练和评测。

Result: 实验证明所提方法在视觉质量和计算效率上，相较于现有方法有显著提升。可以生成长期且高度响应的动态树木动画，表现更真实且交互性更好。

Conclusion: DynamicTree能有效解决复杂树木动态动画的生成难题，为虚拟环境中真实感、交互性树木建模提供了实用、高效的解决方案。

Abstract: Generating dynamic and interactive 3D objects, such as trees, has wide
applications in virtual reality, games, and world simulation. Nevertheless,
existing methods still face various challenges in generating realistic 4D
motion for complex real trees. In this paper, we propose DynamicTree, the first
framework that can generate long-term, interactive animation of 3D Gaussian
Splatting trees. Unlike prior optimization-based methods, our approach
generates dynamics in a fast feed-forward manner. The key success of our
approach is the use of a compact sparse voxel spectrum to represent the tree
movement. Given a 3D tree from Gaussian Splatting reconstruction, our pipeline
first generates mesh motion using the sparse voxel spectrum and then binds
Gaussians to deform the mesh. Additionally, the proposed sparse voxel spectrum
can also serve as a basis for fast modal analysis under external forces,
allowing real-time interactive responses. To train our model, we also introduce
4DTree, the first large-scale synthetic 4D tree dataset containing 8,786
animated tree meshes with semantic labels and 100-frame motion sequences.
Extensive experiments demonstrate that our method achieves realistic and
responsive tree animations, significantly outperforming existing approaches in
both visual quality and computational efficiency.

</details>


### [74] [GALA: A GlobAl-LocAl Approach for Multi-Source Active Domain Adaptation](https://arxiv.org/abs/2510.22214)
*Juepeng Zheng,Peifeng Zhang,Yibin Wen,Qingmei Li,Yang Zhang,Haohuan Fu*

Main category: cs.CV

TL;DR: 本文提出了一种多源主动领域自适应（MS-ADA）的新方法GALA，通过聚类与局部选择相结合，极大改善了目标域任务性能，仅需极少的标注数据便可接近全监督学习的效果。


<details>
  <summary>Details</summary>
Motivation: 尽管多源领域自适应（MSDA）能从多个源域迁移丰富知识，但与完全监督学习仍有较大差距。为进一步提升目标域性能，本文考虑了实际任务中可用少量目标域标注的情况，提出了更具挑战性和实用性的MS-ADA设定。

Method: 提出了GALA策略，结合了全局k-means聚类对目标域样本进行分组，并应用基于聚类的局部选择准则来选择需标注的数据。该方法为现有DA框架的插件式方案，无需增加可训练参数。

Result: GALA在三大标准领域自适应基准实验中表现优异，持续超过现有主动学习和主动领域自适应方法。在仅使用1%目标域标注的情况下，达到接近全监督学习的效果。

Conclusion: GALA极大提升了多源主动领域自适应的效果，可在极低标注成本下实现高性能迁移，证明了聚类与局部主动选择准则结合的有效性。

Abstract: Domain Adaptation (DA) provides an effective way to tackle target-domain
tasks by leveraging knowledge learned from source domains. Recent studies have
extended this paradigm to Multi-Source Domain Adaptation (MSDA), which exploits
multiple source domains carrying richer and more diverse transferable
information. However, a substantial performance gap still remains between
adaptation-based methods and fully supervised learning. In this paper, we
explore a more practical and challenging setting, named Multi-Source Active
Domain Adaptation (MS-ADA), to further enhance target-domain performance by
selectively acquiring annotations from the target domain. The key difficulty of
MS-ADA lies in designing selection criteria that can jointly handle inter-class
diversity and multi-source domain variation. To address these challenges, we
propose a simple yet effective GALA strategy (GALA), which combines a global
k-means clustering step for target-domain samples with a cluster-wise local
selection criterion, effectively tackling the above two issues in a
complementary manner. Our proposed GALA is plug-and-play and can be seamlessly
integrated into existing DA frameworks without introducing any additional
trainable parameters. Extensive experiments on three standard DA benchmarks
demonstrate that GALA consistently outperforms prior active learning and active
DA methods, achieving performance comparable to the fully-supervised upperbound
while using only 1% of the target annotations.

</details>


### [75] [Enpowering Your Pansharpening Models with Generalizability: Unified Distribution is All You Need](https://arxiv.org/abs/2510.22217)
*Yongchuan Cui,Peng Liu,Hui Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新的分布统一策略（UniPAN），提升遥感图像融合（pansharpening）模型在不同卫星数据间的泛化能力。通过归一化不同源数据分布，有效减少模型在新数据上的性能下降。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习遥感图像融合模型普遍训练集表现良好，但在未见过的卫星数据上受传感器和成像条件影响，泛化性差，限制了实际应用。亟需新方法克服不同数据源分布差异带来的性能下降问题。

Method: 作者提出统一分布策略UniPAN，构建分布变换函数，将来自不同卫星的数据归一化到同一分布域中。模型在统一分布域上训练，测试时新数据也做同样分布变换，保证训练与测试分布一致，从而提升泛化能力。

Result: 大量实验证明，引入UniPAN后，多个主流深度融合模型在来自不同卫星传感器的数据上，性能显著提升，展示了分布统一策略在实际应用中的普适性和有效性。

Conclusion: UniPAN可以作为通用插件增强各类深度融合模型的泛化能力，实现一次训练，多场景应用，推动遥感图像融合技术的落地应用。

Abstract: Existing deep learning-based models for remote sensing pansharpening exhibit
exceptional performance on training datasets. However, due to sensor-specific
characteristics and varying imaging conditions, these models suffer from
substantial performance degradation when applied to unseen satellite data,
lacking generalizability and thus limiting their applicability. We argue that
the performance drops stem primarily from distributional discrepancies from
different sources and the key to addressing this challenge lies in bridging the
gap between training and testing distributions. To validate the idea and
further achieve a "train once, deploy forever" capability, this paper
introduces a novel and intuitive approach to enpower any pansharpening models
with generalizability by employing a unified distribution strategy (UniPAN).
Specifically, we construct a distribution transformation function that
normalizes the pixels sampled from different sources to conform to an identical
distribution. The deep models are trained on the transformed domain, and during
testing on new datasets, the new data are also transformed to match the
training distribution. UniPAN aims to train and test the model on a unified and
consistent distribution, thereby enhancing its generalizability. Extensive
experiments validate the efficacy of UniPAN, demonstrating its potential to
significantly enhance the performance of deep pansharpening models across
diverse satellite sensors. Codes: https://github.com/yc-cui/UniPAN.

</details>


### [76] [Audio Frequency-Time Dual Domain Evaluation on Depression Diagnosis](https://arxiv.org/abs/2510.22225)
*Yu Luo,Nan Huang,Sophie Yu,Hendry Xu,Jerry Wang,Colin Wang,Zhichao Liu,Chen Zeng*

Main category: cs.CV

TL;DR: 本文提出了一种基于语音信号及深度学习的智能抑郁症诊断算法，实验结果表现优异。


<details>
  <summary>Details</summary>
Motivation: 虽然抑郁症对公众健康带来重大影响，但其预防和诊断仍存在多重难题，包括诊断过程复杂、标准不明确及就诊率低，导致无法及时评估和干预。

Method: 研究利用语音作为生理信号，结合其频域和时域的多模态特征，通过深度学习模型开发智能抑郁症评估与诊断算法。

Result: 实验显示，该方法在抑郁症分类任务中取得了卓越表现。

Conclusion: 该智能方法为抑郁症的评估、筛查与诊断提供了新思路和新方法。

Abstract: Depression, as a typical mental disorder, has become a prevalent issue
significantly impacting public health. However, the prevention and treatment of
depression still face multiple challenges, including complex diagnostic
procedures, ambiguous criteria, and low consultation rates, which severely
hinder timely assessment and intervention. To address these issues, this study
adopts voice as a physiological signal and leverages its frequency-time dual
domain multimodal characteristics along with deep learning models to develop an
intelligent assessment and diagnostic algorithm for depression. Experimental
results demonstrate that the proposed method achieves excellent performance in
the classification task for depression diagnosis, offering new insights and
approaches for the assessment, screening, and diagnosis of depression.

</details>


### [77] [Diffusion-Driven Two-Stage Active Learning for Low-Budget Semantic Segmentation](https://arxiv.org/abs/2510.22229)
*Jeongin Kim,Wonho Bae,YouLee Han,Giyeong Oh,Youngjae Yu,Danica J. Sutherland,Junhyug Noh*

Main category: cs.CV

TL;DR: 本文提出了一种用于语义分割的低标注成本主动学习新方法，利用扩散模型和两阶段选择策略，大幅提升极少像素标注下的分割效果。


<details>
  <summary>Details</summary>
Motivation: 语义分割需要大量像素级别的标注，人工成本极高。在标注预算极为有限的情况下，如何高效选择最有价值的标注像素，成为亟需解决的问题。

Method: 提出了基于扩散模型特征的两阶段主动学习方法：第一阶段，利用MaxHerding算法在单图像内选取具有代表性的像素，并构建全局多样性池；第二阶段，基于多尺度特征计算结合了熵的不一致性分数（eDALD），选出信息量最大的像素用于标注。该流程将多样性（代表性）与不确定性解耦。

Result: 在CamVid、ADE-Bed、Cityscapes和Pascal-Context四个基准数据集上进行实验，证明在极小像素标注比例下，该方法显著优于现有主动学习基准方法。

Conclusion: 提出的方法能以极少标注成本达到高精度分割效果，对低预算语义分割任务具有重要应用价值。

Abstract: Semantic segmentation demands dense pixel-level annotations, which can be
prohibitively expensive - especially under extremely constrained labeling
budgets. In this paper, we address the problem of low-budget active learning
for semantic segmentation by proposing a novel two-stage selection pipeline.
Our approach leverages a pre-trained diffusion model to extract rich
multi-scale features that capture both global structure and fine details. In
the first stage, we perform a hierarchical, representation-based candidate
selection by first choosing a small subset of representative pixels per image
using MaxHerding, and then refining these into a diverse global pool. In the
second stage, we compute an entropy-augmented disagreement score (eDALD) over
noisy multi-scale diffusion features to capture both epistemic uncertainty and
prediction confidence, selecting the most informative pixels for annotation.
This decoupling of diversity and uncertainty lets us achieve high segmentation
accuracy with only a tiny fraction of labeled pixels. Extensive experiments on
four benchmarks (CamVid, ADE-Bed, Cityscapes, and Pascal-Context) demonstrate
that our method significantly outperforms existing baselines under extreme
pixel-budget regimes. Our code is available at
https://github.com/jn-kim/two-stage-edald.

</details>


### [78] [Bag-of-Word-Groups (BoWG): A Robust and Efficient Loop Closure Detection Method Under Perceptual Aliasing](https://arxiv.org/abs/2510.22529)
*Xiang Fei,Tina Tian,Howie Choset,Lu Li*

Main category: cs.CV

TL;DR: 该论文提出了一种名为Bag-of-Word-Groups (BoWG)的新型回环检测方法，在查准率-查全率、健壮性和计算效率等多方面显著优于现有方法，特别适用于狭窄管道等感知混淆环境。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM回环检测方法在特征稀疏、重复纹理等环境下易受混淆影响且运算量大，因此需要一种既高效又鲁棒的新方法。

Method: 提出Bag-of-Word-Groups（BoWG）方法，创新性地通过分组视觉词来捕捉空间共现和邻近关系，并在线构建字典。同时引入自适应的时序一致性建模，结合特征分布分析模块与后验验证机制，有效提升性能。

Result: 在公开数据集及自建狭窄管道数据集上进行大量实验，BoWG在查准率—查全率和运行效率上全面优于最新传统与学习方法，处理速度在Bicocca25b数据集上的平均为16毫秒/幅。

Conclusion: BoWG方法在精度、效率和可扩展性上均具有显著优势，特别适合感知混淆环境下的回环检测任务，有望广泛应用于实际SLAM系统。

Abstract: Loop closure is critical in Simultaneous Localization and Mapping (SLAM)
systems to reduce accumulative drift and ensure global mapping consistency.
However, conventional methods struggle in perceptually aliased environments,
such as narrow pipes, due to vector quantization, feature sparsity, and
repetitive textures, while existing solutions often incur high computational
costs. This paper presents Bag-of-Word-Groups (BoWG), a novel loop closure
detection method that achieves superior precision-recall, robustness, and
computational efficiency. The core innovation lies in the introduction of word
groups, which captures the spatial co-occurrence and proximity of visual words
to construct an online dictionary. Additionally, drawing inspiration from
probabilistic transition models, we incorporate temporal consistency directly
into similarity computation with an adaptive scheme, substantially improving
precision-recall performance. The method is further strengthened by a feature
distribution analysis module and dedicated post-verification mechanisms. To
evaluate the effectiveness of our method, we conduct experiments on both public
datasets and a confined-pipe dataset we constructed. Results demonstrate that
BoWG surpasses state-of-the-art methods, including both traditional and
learning-based approaches, in terms of precision-recall and computational
efficiency. Our approach also exhibits excellent scalability, achieving an
average processing time of 16 ms per image across 17,565 images in the
Bicocca25b dataset.

</details>


### [79] [DiffusionLane: Diffusion Model for Lane Detection](https://arxiv.org/abs/2510.22236)
*Kunyang Zhou,Yeqin Shao*

Main category: cs.CV

TL;DR: 本文提出了一种新的基于扩散模型的车道线检测方法DiffusionLane，将车道线检测任务视为参数空间的去噪扩散过程。实验结果表明，DiffusionLane在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的车道线检测方法在特征表示和鲁棒性方面存在不足。本文希望通过引入扩散模型和参数去噪过程，提升车道线检测的精度和泛化能力。

Method: 1. 将车道线参数（起始点和角度）进行高斯噪声扰动，生成带噪声的车道锚点；2. 模型通过逐步去噪恢复目标车道线；3. 设计了结合全局和局部特征的混合扩散解码器以提升检测质量；4. 在训练阶段引入辅助头部，增强编码器特征学习。

Result: 在Carlane、Tusimple、CULane、LLAMAS四个主流数据集上，DiffusionLane均取得了优异性能。例如: 用ResNet18在Carlane surpasses现有方法至少1%；用MobileNetV4在CULane获得81.32% F1分数；在Tusimple用ResNet34达到96.89%准确率；在LLAMAS用ResNet101获得97.59% F1。

Conclusion: DiffusionLane展现出强大的泛化能力和领先的检测性能，优于现有的主流车道线检测方法。

Abstract: In this paper, we present a novel diffusion-based model for lane detection,
called DiffusionLane, which treats the lane detection task as a denoising
diffusion process in the parameter space of the lane. Firstly, we add the
Gaussian noise to the parameters (the starting point and the angle) of ground
truth lanes to obtain noisy lane anchors, and the model learns to refine the
noisy lane anchors in a progressive way to obtain the target lanes. Secondly,
we propose a hybrid decoding strategy to address the poor feature
representation of the encoder, resulting from the noisy lane anchors.
Specifically, we design a hybrid diffusion decoder to combine global-level and
local-level decoders for high-quality lane anchors. Then, to improve the
feature representation of the encoder, we employ an auxiliary head in the
training stage to adopt the learnable lane anchors for enriching the
supervision on the encoder. Experimental results on four benchmarks, Carlane,
Tusimple, CULane, and LLAMAS, show that DiffusionLane possesses a strong
generalization ability and promising detection performance compared to the
previous state-of-the-art methods. For example, DiffusionLane with ResNet18
surpasses the existing methods by at least 1\% accuracy on the domain
adaptation dataset Carlane. Besides, DiffusionLane with MobileNetV4 gets
81.32\% F1 score on CULane, 96.89\% accuracy on Tusimple with ResNet34, and
97.59\% F1 score on LLAMAS with ResNet101. Code will be available at
https://github.com/zkyntu/UnLanedet.

</details>


### [80] [Look and Tell: A Dataset for Multimodal Grounding Across Egocentric and Exocentric Views](https://arxiv.org/abs/2510.22672)
*Anna Deichler,Jonas Beskow*

Main category: cs.CV

TL;DR: 该论文提出了Look and Tell多模态数据集，用于研究在自我视角（egocentric）和外部视角（exocentric）下的指称性交流。数据集结合了Meta Project Aria智能眼镜与固定摄像头的同步注视点、语音和视频记录，并包含超过三小时的数据和详细标注。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态交流数据集中缺乏一致的三维场景重建和多视角（自我与外部）比较，限制了对空间表征在交流中作用的研究与智能体发展的推进。该数据集旨在弥补这一空白。

Method: 作者邀请25位参与者在厨房场景进行任务式配合——一人说明，另一人识别指定食材。通过穿戴Meta Project Aria智能眼镜和场地固定摄像头，同步采集注视点追踪、语音、视频数据，并融合3D场景重建。所有指称性表达都进行了详细标注。

Result: 最终制备出3.67小时、包含2,707条注释的多模态数据集，并能评估2D与3D、自我与外部等空间表征方式对多模态语义落地能力的影响。

Conclusion: Look and Tell数据集为理解和开发能在真实场景对话交流的具身智能体提供了新基准，推动了多模态、空间感知语义落地方法的研究进展。

Abstract: We introduce Look and Tell, a multimodal dataset for studying referential
communication across egocentric and exocentric perspectives. Using Meta Project
Aria smart glasses and stationary cameras, we recorded synchronized gaze,
speech, and video as 25 participants instructed a partner to identify
ingredients in a kitchen. Combined with 3D scene reconstructions, this setup
provides a benchmark for evaluating how different spatial representations (2D
vs. 3D; ego vs. exo) affect multimodal grounding. The dataset contains 3.67
hours of recordings, including 2,707 richly annotated referential expressions,
and is designed to advance the development of embodied agents that can
understand and engage in situated dialogue.

</details>


### [81] [Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework](https://arxiv.org/abs/2510.22243)
*Amir Mohammad Khadem Hosseini,Sattar Mirzakuchaki*

Main category: cs.CV

TL;DR: 本文提出了一种基于FPGA的实时语义分割实现，结合LMIINet轻量级架构和CGRA4ML硬件框架，实现了高效、低功耗且准确的分割性能。


<details>
  <summary>Details</summary>
Motivation: 实时语义分割在如自动驾驶等实际应用中至关重要，但面临在有限的运算和硬件资源下达到高准确度的挑战。现有GPU方案在功耗等方面存在不足，FPGA具备更高的能效比。

Method: 采用LMIINet轻量级架构，利用CGRA4ML硬件平台部署，同时通过量化感知训练(QAT)将权重量化为8位精度以降低内存需求，并针对FPGA限制简化了跳跃连接，用硬件友好的操作（如深度可分离卷积和1A-1卷积）与部分Flatten Transformer结构重设计以适应硬件实现。

Result: 在Cityscapes数据集测试，所实现方案在ZCU104 FPGA板上实现了约90%像素准确率，mIoU达45%，实时运行速度为20FPS，延迟为50.1ms。

Conclusion: 结果表明，基于CGRA4ML的FPGA平台能灵活支持现代网络结构，在能效方面优于传统GPU方案，同时保证了分割精度，是实现先进实时语义分割网络在资源受限环境下的可行路径。

Abstract: Semantic segmentation has emerged as a fundamental problem in computer
vision, gaining particular importance in real-time applications such as
autonomous driving. The main challenge is achieving high accuracy while
operating under computational and hardware constraints. In this research, we
present an FPGA-based implementation of real-time semantic segmentation
leveraging the lightweight LMIINet architecture and the Coarse-Grained
Reconfigurable Array for Machine Learning (CGRA4ML) hardware framework. The
model was trained using Quantization-Aware Training (QAT) with 8-bit precision
on the Cityscapes dataset, reducing memory footprint by a factor of four while
enabling efficient fixed-point computations. Necessary modifications were
applied to adapt the model to CGRA4ML constraints, including simplifying skip
connections, employing hardware-friendly operations such as depthwise-separable
and 1A-1 convolutions, and redesigning parts of the Flatten Transformer. Our
implementation achieves approximately 90% pixel accuracy and 45% mean
Intersection-over-Union (mIoU), operating in real-time at 20 frames per second
(FPS) with 50.1 ms latency on the ZCU104 FPGA board. The results demonstrate
the potential of CGRA4ML, with its flexibility in mapping modern layers and
off-chip memory utilization for skip connections, provides a path for
implementing advanced semantic segmentation networks on FPGA for real-time
applications to outperform traditional GPU solutions in terms of power
efficiency while maintaining competitive accuracy. The code for this project is
publicly available at https://github.com/STAmirr/ cgra4ml_semantic_segmentation

</details>


### [82] [EndoWave: Rational-Wavelet 4D Gaussian Splatting for Endoscopic Reconstruction](https://arxiv.org/abs/2510.23087)
*Taoyu Wu,Yiyi Miao,Jiaxin Guo,Ziyan Chen,Sihang Zhao,Zhuoxiao Li,Zhe Tang,Baoru Huang,Limin Yu*

Main category: cs.CV

TL;DR: 本文提出一种名为EndoWave的统一时空高斯泼溅（Gaussian Splatting）框架，通过结合光流约束和多分辨率小波监督，实现端到端镜下视频的高质量3D重建。实验表明，该方法在真实手术数据上获得了业界领先的重建效果。


<details>
  <summary>Details</summary>
Motivation: 内窥镜辅助手术的精准3D重建对于后续任务和术后效果至关重要。然而，内窥镜场景存在光照不均、组织非刚性运动、高光等复杂动态视觉干扰，当前仅依赖外观约束的3DGS方法难以保证重建准确性。为克服这些挑战，作者设计了结合几何和多尺度信息的统一优化框架。

Method: 提出EndoWave方法，并有三大创新：1）直接在统一的四维（时空）高斯表达下优化基本体；2）引入基于光流的几何约束，提升时间连续性和三维结构约束力；3）提出多分辨率正交小波约束，有效分离内镜细节，提高渲染性能。

Result: 在真实的内镜手术数据集EndoNeRF和StereoMIS上验证，EndoWave方法取得了比现有基线方法更高的重建质量和视觉准确性。

Conclusion: EndoWave通过结合时空高斯表达、光流几何约束以及多分辨率小波监督，为动态、视觉复杂的内镜视频3D重建提供了有效思路，并在实际应用中展示了卓越性能。

Abstract: In robot-assisted minimally invasive surgery, accurate 3D reconstruction from
endoscopic video is vital for downstream tasks and improved outcomes. However,
endoscopic scenarios present unique challenges, including photometric
inconsistencies, non-rigid tissue motion, and view-dependent highlights. Most
3DGS-based methods that rely solely on appearance constraints for optimizing
3DGS are often insufficient in this context, as these dynamic visual artifacts
can mislead the optimization process and lead to inaccurate reconstructions. To
address these limitations, we present EndoWave, a unified spatio-temporal
Gaussian Splatting framework by incorporating an optical flow-based geometric
constraint and a multi-resolution rational wavelet supervision. First, we adopt
a unified spatio-temporal Gaussian representation that directly optimizes
primitives in a 4D domain. Second, we propose a geometric constraint derived
from optical flow to enhance temporal coherence and effectively constrain the
3D structure of the scene. Third, we propose a multi-resolution rational
orthogonal wavelet as a constraint, which can effectively separate the details
of the endoscope and enhance the rendering performance. Extensive evaluations
on two real surgical datasets, EndoNeRF and StereoMIS, demonstrate that our
method EndoWave achieves state-of-the-art reconstruction quality and visual
accuracy compared to the baseline method.

</details>


### [83] [Accident Anticipation via Temporal Occurrence Prediction](https://arxiv.org/abs/2510.22260)
*Tianhao Zhao,Yiyang Zou,Zihao Mao,Peilun Xiao,Yulin Huang,Hongda Yang,Yuxuan Li,Qun Li,Guobin Wu,Yutian Lin*

Main category: cs.CV

TL;DR: 本论文提出了一种新的事故预判范式，直接预测未来多个时间点的事故概率，结合Transformer时序解码器和更精细的评测协议，有效提升了模型的实际鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有事故预判方法对视频所有事故帧采用模糊的二值监督，忽略了风险是随时间连续变化的，造成学习不可靠和误报多。作者希望通过更精确的标签和评估，提高模型实用性和预测准确性。

Method: 作者提出以精确带时标的事故数据为监督，直接预测未来不同时间（如0.1s-2.0s）内的事故分数。模型采用片段级编码器联合建模空间与时序特征，再通过Transformer时序解码器以多个时域查询并行预测。同时，提出以受控误报率下的TTA与召回率为新评测方案。

Result: 实验结果表明，在合理的误报率限制下，该方法在召回率与预警提前时间（TTA）方面均大幅优于现有方法。

Conclusion: 方法有效解决了现有风险标注不准及误报多的问题，提高了事故预警系统的实用性，为自动驾驶等领域事故风险预测提供了更精细和可靠的参考。

Abstract: Accident anticipation aims to predict potential collisions in an online
manner, enabling timely alerts to enhance road safety. Existing methods
typically predict frame-level risk scores as indicators of hazard. However,
these approaches rely on ambiguous binary supervision (labeling all frames in
accident videos as positive) despite the fact that risk varies continuously
over time, leading to unreliable learning and false alarms. To address this, we
propose a novel paradigm that shifts the prediction target from current-frame
risk scoring to directly estimating accident scores at multiple future time
steps (e.g., 0.1s-2.0s ahead), leveraging precisely annotated accident
timestamps as supervision. Our method employs a snippet-level encoder to
jointly model spatial and temporal dynamics, and a Transformer-based temporal
decoder that predicts accident scores for all future horizons simultaneously
using dedicated temporal queries. Furthermore, we introduce a refined
evaluation protocol that reports Time-to-Accident (TTA) and recall (evaluated
at multiple pre-accident intervals (0.5s, 1.0s, and 1.5s)) only when the false
alarm rate (FAR) remains within an acceptable range, ensuring practical
relevance. Experiments show that our method achieves superior performance in
both recall and TTA under realistic FAR constraints.

</details>


### [84] [DPGLA: Bridging the Gap between Synthetic and Real Data for Unsupervised Domain Adaptation in 3D LiDAR Semantic Segmentation](https://arxiv.org/abs/2510.23525)
*Wanmeng Li,Simone Mosco,Daniel Fusaro,Alberto Pretto*

Main category: cs.CV

TL;DR: 该论文提出了一种面向点云语义分割领域自监督领域自适应的新方法，通过动态伪标签过滤和先验引导数据增强，显著提升了从合成点云到真实点云的迁移效果。


<details>
  <summary>Details</summary>
Motivation: 真实世界LiDAR点云标注成本高昂，而现有自监督领域自适应方法未能有效利用无标签数据，通常使用固定或预定置信度阈值，导致表现不佳。作者希望通过更有效的方法提升点云语义分割在跨域应用中的表现。

Method: 方法包括动态伪标签过滤（DPLF）机制来提升真实数据利用率，设计了先验引导数据增强管道（PG-DAP）以减小合成与真实点云的域间差异，还引入了数据混合一致性损失来促进无上下文依赖的表示学习。

Result: 在两个具有挑战性的合成到真实点云语义分割任务上，作者提出的方法实验效果优于当前主流方法。消融实验进一步验证了DPLF和PG-DAP模块的有效性。

Conclusion: 文中所提方法显著提升了合成到真实点云的语义分割性能，充分利用了无标签真实数据，并为领域适应任务提供了新的高效方案，代码已发布。

Abstract: Annotating real-world LiDAR point clouds for use in intelligent autonomous
systems is costly. To overcome this limitation, self-training-based
Unsupervised Domain Adaptation (UDA) has been widely used to improve point
cloud semantic segmentation by leveraging synthetic point cloud data. However,
we argue that existing methods do not effectively utilize unlabeled data, as
they either rely on predefined or fixed confidence thresholds, resulting in
suboptimal performance. In this paper, we propose a Dynamic Pseudo-Label
Filtering (DPLF) scheme to enhance real data utilization in point cloud UDA
semantic segmentation. Additionally, we design a simple and efficient
Prior-Guided Data Augmentation Pipeline (PG-DAP) to mitigate domain shift
between synthetic and real-world point clouds. Finally, we utilize data mixing
consistency loss to push the model to learn context-free representations. We
implement and thoroughly evaluate our approach through extensive comparisons
with state-of-the-art methods. Experiments on two challenging synthetic-to-real
point cloud semantic segmentation tasks demonstrate that our approach achieves
superior performance. Ablation studies confirm the effectiveness of the DPLF
and PG-DAP modules. We release the code of our method in this paper.

</details>


### [85] [GSAlign: Geometric and Semantic Alignment Network for Aerial-Ground Person Re-Identification](https://arxiv.org/abs/2510.22268)
*Qiao Li,Jie Li,Yukang Zhang,Lei Tan,Jing Chen,Jiayi Ji*

Main category: cs.CV

TL;DR: 本文提出了一种针对空地人重识别（AG-ReID）任务的几何与语义对齐网络（GSAlign），显著提升了跨视角行人匹配的准确率。


<details>
  <summary>Details</summary>
Motivation: 空地人重识别任务由于视角差异巨大、遮挡和域差难题，现有方法在极端姿态变化和空间错位下表现有限，因此需要更有效的对齐策略。

Method: 提出GSAlign模型，包含可学习薄板样条（LTPS）模块以及动态对齐模块（DAM）。LTPS自适应地根据学到的关键点对行人特征进行几何变形，DAM通过辨别可见区域生成语义级的特征掩码，以应对遮挡和部分可见性问题。

Result: 在CARGO数据集四个匹配协议下进行全面评估，GSAlign相较于最新方法在aerial-ground设置下mAP提升18.8%，Rank-1准确率提升16.8%。

Conclusion: GSAlign能够有效缓解极端视角变化和几何-语义错位问题，极大提升了空地人重识别性能，推动了该领域的研究进展。

Abstract: Aerial-Ground person re-identification (AG-ReID) is an emerging yet
challenging task that aims to match pedestrian images captured from drastically
different viewpoints, typically from unmanned aerial vehicles (UAVs) and
ground-based surveillance cameras. The task poses significant challenges due to
extreme viewpoint discrepancies, occlusions, and domain gaps between aerial and
ground imagery. While prior works have made progress by learning cross-view
representations, they remain limited in handling severe pose variations and
spatial misalignment. To address these issues, we propose a Geometric and
Semantic Alignment Network (GSAlign) tailored for AG-ReID. GSAlign introduces
two key components to jointly tackle geometric distortion and semantic
misalignment in aerial-ground matching: a Learnable Thin Plate Spline (LTPS)
Module and a Dynamic Alignment Module (DAM). The LTPS module adaptively warps
pedestrian features based on a set of learned keypoints, effectively
compensating for geometric variations caused by extreme viewpoint changes. In
parallel, the DAM estimates visibility-aware representation masks that
highlight visible body regions at the semantic level, thereby alleviating the
negative impact of occlusions and partial observations in cross-view
correspondence. A comprehensive evaluation on CARGO with four matching
protocols demonstrates the effectiveness of GSAlign, achieving significant
improvements of +18.8\% in mAP and +16.8\% in Rank-1 accuracy over previous
state-of-the-art methods on the aerial-ground setting. The code is available
at: \textcolor{magenta}{https://github.com/stone96123/GSAlign}.

</details>


### [86] [Track, Inpaint, Resplat: Subject-driven 3D and 4D Generation with Progressive Texture Infilling](https://arxiv.org/abs/2510.23605)
*Shuhong Zheng,Ashkan Mirzaei,Igor Gilitschenski*

Main category: cs.CV

TL;DR: 现有3D/4D生成方法难以在不同视角下保持主体身份一致性，本文提出TIRE方法，显著提升了个性化3D/4D生成的身份保持能力。


<details>
  <summary>Details</summary>
Motivation: 虽然当前的3D/4D生成模型在写实性、效率和美学方面表现优秀，但在跨视角生成时，往往无法很好地保持特定主体的身份特征。个性化（主体驱动）的生成在3D/4D领域研究不足，因此需要更好地方法来解决该问题。

Method: 提出TIRE（Track, Inpaint, REsplat）方法，流程为：1）用已有3D生成模型获取初步3D资产；2）利用视频跟踪识别需修改的区域；3）采用2D主体驱动的修补模型依次填充这些区域；4）将多视角2D修补结果重新融合回3D，实现一致性保持。

Result: 大量实验结果表明，TIRE方法在个性化3D/4D生成中的身份保持上，远优于现有主流方法。

Conclusion: TIRE为个性化3D/4D生成任务提供了强有力的新工具，显著提升了跨视角身份一致性，有助于促进个性化内容生成应用的发展。

Abstract: Current 3D/4D generation methods are usually optimized for photorealism,
efficiency, and aesthetics. However, they often fail to preserve the semantic
identity of the subject across different viewpoints. Adapting generation
methods with one or few images of a specific subject (also known as
Personalization or Subject-driven generation) allows generating visual content
that align with the identity of the subject. However, personalized 3D/4D
generation is still largely underexplored. In this work, we introduce TIRE
(Track, Inpaint, REsplat), a novel method for subject-driven 3D/4D generation.
It takes an initial 3D asset produced by an existing 3D generative model as
input and uses video tracking to identify the regions that need to be modified.
Then, we adopt a subject-driven 2D inpainting model for progressively infilling
the identified regions. Finally, we resplat the modified 2D multi-view
observations back to 3D while still maintaining consistency. Extensive
experiments demonstrate that our approach significantly improves identity
preservation in 3D/4D generation compared to state-of-the-art methods. Our
project website is available at
https://zsh2000.github.io/track-inpaint-resplat.github.io/.

</details>


### [87] [WAON: Large-Scale and High-Quality Japanese Image-Text Pair Dataset for Vision-Language Models](https://arxiv.org/abs/2510.22276)
*Issa Sugiura,Shuhei Kurita,Yusuke Oda,Daisuke Kawahara,Yasuo Okabe,Naoaki Okazaki*

Main category: cs.CV

TL;DR: 本论文介绍了WAON，这是一个包含约1.55亿日文图文对的大规模高质量数据集，并证实其在提升视觉-语言模型性能方面优于现有数据集。


<details>
  <summary>Details</summary>
Motivation: 当前高效的视觉-语言模型（VLMs）依赖于大规模高质量的图文对数据集。然而，针对日语的大型公开数据集稀缺，阻碍了在日语相关任务上的模型发展。因此，作者希望通过构建一个大规模高质量的日文图文对数据集，推动日语VLMs的发展。

Method: 作者利用Common Crawl公开数据源，经过系统性的数据过滤和去重流程，构建了WAON数据集。为了评估该数据集的有效性，还手动整理了涵盖374个类别的WAON-Bench（日式文化图像分类基准数据集）。通过对比实验，将强大的多语言模型SigLIP2分别在WAON和ReLAION（日文子集）上微调，并在多个基准任务上进行测试。

Result: 实验结果表明，基于WAON微调的模型在WAON-Bench及所有评测基准上都取得了高于ReLAION的数据集微调模型的性能提升。部分日本文化相关基准上甚至达到了最新的最优结果。

Conclusion: WAON作为一个高质量大规模日文图文对数据集，可显著提升多语言视觉-语言模型在相关任务上的表现。数据集、模型及代码均已开源，助力社区发展。

Abstract: Large-scale and high-quality image-text pair datasets play an important role
in developing high-performing Vision-Language Models (VLMs). In this work, we
introduce WAON, a large-scale and high-quality Japanese image-text pair dataset
containing approximately 155 million examples, collected from Common Crawl. Our
dataset construction pipeline employs various techniques, including filtering
and deduplication, which have been shown to be effective in previous studies.
To evaluate its effectiveness, we also construct WAON-Bench, a manually curated
benchmark for Japanese cultural image classification, consisting of 374
classes. To assess the effectiveness of our dataset, we conduct experiments
using both WAON and the Japanese subset of ReLAION, one of the most widely used
vision-language datasets. We fine-tune SigLIP2, a strong multilingual model, on
both datasets. The results demonstrate that WAON enhances model performance on
WAON-Bench more efficiently than ReLAION and achieves higher accuracy across
all evaluated benchmarks. Furthermore, the model fine-tuned on WAON achieves
state-of-the-art performance on several Japanese cultural benchmarks. We
release our dataset, model, and code at https://speed1313.github.io/WAON.

</details>


### [88] [CityRiSE: Reasoning Urban Socio-Economic Status in Vision-Language Models via Reinforcement Learning](https://arxiv.org/abs/2510.22282)
*Tianhui Liu,Hetian Pang,Xin Zhang,Jie Feng,Yong Li,Pan Hui*

Main category: cs.CV

TL;DR: 本论文提出了CityRiSE，一种结合大规模视觉语言模型（LVLM）与强化学习（RL）的方法，实现对城市社会经济状态的精准推断，并且在跨城市和未知指标上的泛化能力优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 利用街景、卫星图像等公开大规模网络数据进行城市社会经济感知，对于实现全球可持续发展目标至关重要。然而，现有LVLM在用视觉数据推断社会经济指标时表现出准确性和可解释性不足。因此，需要一种能提升模型准确率、泛化性和解释能力的新方法。

Method: 提出了CityRiSE框架，通过精心设计的多模态数据集与可验证的奖励机制，以纯强化学习方式优化LVLM，引导模型关注语义上重要的视觉线索，实现结构化、目标导向的推理和社会经济状态预测。

Result: 实验表明，CityRiSE具备新颖的推理能力，在预测准确性、跨城市泛化性、未知指标适应性等方面都显著优于现有基线方法，尤其在无法见的城市和指标上表现更佳。

Conclusion: 结合强化学习和LVLM能带来更具解释性和泛化性的城市社会经济感知新范式，为未来相关领域研究提供了重要参考和突破。

Abstract: Harnessing publicly available, large-scale web data, such as street view and
satellite imagery, urban socio-economic sensing is of paramount importance for
achieving global sustainable development goals. With the emergence of Large
Vision-Language Models (LVLMs), new opportunities have arisen to solve this
task by treating it as a multi-modal perception and understanding problem.
However, recent studies reveal that LVLMs still struggle with accurate and
interpretable socio-economic predictions from visual data. To address these
limitations and maximize the potential of LVLMs, we introduce
\textbf{CityRiSE}, a novel framework for \textbf{R}eason\textbf{i}ng urban
\textbf{S}ocio-\textbf{E}conomic status in LVLMs through pure reinforcement
learning (RL). With carefully curated multi-modal data and verifiable reward
design, our approach guides the LVLM to focus on semantically meaningful visual
cues, enabling structured and goal-oriented reasoning for generalist
socio-economic status prediction. Experiments demonstrate that CityRiSE with
emergent reasoning process significantly outperforms existing baselines,
improving both prediction accuracy and generalization across diverse urban
contexts, particularly for prediction on unseen cities and unseen indicators.
This work highlights the promise of combining RL and LVLMs for interpretable
and generalist urban socio-economic sensing.

</details>


### [89] [GRPO-Guard: Mitigating Implicit Over-Optimization in Flow Matching via Regulated Clipping](https://arxiv.org/abs/2510.22319)
*Jing Wang,Jiajun Liang,Jie Liu,Henglin Liu,Gongye Liu,Jun Zheng,Wanyuan Pang,Ao Ma,Zhenyu Xie,Xintao Wang,Meng Wang,Pengfei Wan,Xiaodan Liang*

Main category: cs.CV

TL;DR: 本文提出GRPO-Guard，解决基于GRPO的强化学习在训练流匹配模型时易于过度优化的问题，对生成模型稳定性和效果提升有明显作用。


<details>
  <summary>Details</summary>
Motivation: 现有GRPO方法通过重要性比例裁剪限制策略更新，以更好对齐任务奖励。然而，实际中重要性比例分布存在系统性偏移，导致裁剪机制失效，造成模型过度优化并损害生成质量。

Method: 提出GRPO-Guard，包括比值归一化（ratio normalization）和梯度重加权（gradient reweighting），恢复分布稳定性和平滑各时刻策略更新，增强PPO裁剪作用，无需依赖重KL正则。

Result: 在多个扩散模型（如SD3.5M、Flux.1-dev）和多种任务上，GRPO-Guard显著减少过度优化，同时保持甚至提升生成质量。

Conclusion: GRPO-Guard能有效防止隐性过度优化，提高生成模型在实际任务中的可用性和质量，是GRPO范式下简单实用的优化工具。

Abstract: Recently, GRPO-based reinforcement learning has shown remarkable progress in
optimizing flow-matching models, effectively improving their alignment with
task-specific rewards. Within these frameworks, the policy update relies on
importance-ratio clipping to constrain overconfident positive and negative
gradients. However, in practice, we observe a systematic shift in the
importance-ratio distribution-its mean falls below 1 and its variance differs
substantially across timesteps. This left-shifted and inconsistent distribution
prevents positive-advantage samples from entering the clipped region, causing
the mechanism to fail in constraining overconfident positive updates. As a
result, the policy model inevitably enters an implicit over-optimization
stage-while the proxy reward continues to increase, essential metrics such as
image quality and text-prompt alignment deteriorate sharply, ultimately making
the learned policy impractical for real-world use. To address this issue, we
introduce GRPO-Guard, a simple yet effective enhancement to existing GRPO
frameworks. Our method incorporates ratio normalization, which restores a
balanced and step-consistent importance ratio, ensuring that PPO clipping
properly constrains harmful updates across denoising timesteps. In addition, a
gradient reweighting strategy equalizes policy gradients over noise conditions,
preventing excessive updates from particular timestep regions. Together, these
designs act as a regulated clipping mechanism, stabilizing optimization and
substantially mitigating implicit over-optimization without relying on heavy KL
regularization. Extensive experiments on multiple diffusion backbones (e.g.,
SD3.5M, Flux.1-dev) and diverse proxy tasks demonstrate that GRPO-Guard
significantly reduces over-optimization while maintaining or even improving
generation quality.

</details>


### [90] [Beyond Augmentation: Leveraging Inter-Instance Relation in Self-Supervised Representation Learning](https://arxiv.org/abs/2510.22322)
*Ali Javidani,Babak Nadjar Araabi,Mohammad Amin Sadeghi*

Main category: cs.CV

TL;DR: 本文提出了一种将图论方法融入自监督表征学习的新方法，通过结合KNN图和图神经网络增强实例间关系，有效提升了主流数据集图像识别任务的表现。


<details>
  <summary>Details</summary>
Motivation: 现有自监督表征学习主要关注单个样本（intra-instance）的多样性，通常忽略了不同样本之间的重要联系（inter-instance relationships），影响了表征质量。本文旨在同时利用实例间关系以改进模型效果。

Method: 首先在训练阶段为教师流和学生流分别构建KNN图，节点为样本表征，边表示样本间的相似度。随后在表征精炼阶段，引入图神经网络（GNN），通过多跳邻居信息传播，进一步融合和扩展上下文信息。

Result: 在CIFAR-10、ImageNet-100和ImageNet-1K数据集上，所提方法相较于最新SOTA方法分别提升了7.3%、3.2%和1.0%的准确率。

Conclusion: 将图论与自监督学习相结合，能够补充并增强实例间关系的学习，有效提升图像分类任务表现。该思路对自监督学习领域具有推广意义和实际应用价值。

Abstract: This paper introduces a novel approach that integrates graph theory into
self-supervised representation learning. Traditional methods focus on
intra-instance variations generated by applying augmentations. However, they
often overlook important inter-instance relationships. While our method retains
the intra-instance property, it further captures inter-instance relationships
by constructing k-nearest neighbor (KNN) graphs for both teacher and student
streams during pretraining. In these graphs, nodes represent samples along with
their latent representations. Edges encode the similarity between instances.
Following pretraining, a representation refinement phase is performed. In this
phase, Graph Neural Networks (GNNs) propagate messages not only among immediate
neighbors but also across multiple hops, thereby enabling broader contextual
integration. Experimental results on CIFAR-10, ImageNet-100, and ImageNet-1K
demonstrate accuracy improvements of 7.3%, 3.2%, and 1.0%, respectively, over
state-of-the-art methods. These results highlight the effectiveness of the
proposed graph based mechanism. The code is publicly available at
https://github.com/alijavidani/SSL-GraphNNCLR.

</details>


### [91] [Moving Beyond Diffusion: Hierarchy-to-Hierarchy Autoregression for fMRI-to-Image Reconstruction](https://arxiv.org/abs/2510.22335)
*Xu Zhang,Ruijie Quan,Wenguan Wang,Yi Yang*

Main category: cs.CV

TL;DR: MindHier是一种层次化的fMRI脑信号到图像重建的新方法，通过分阶段引导，使重建结果更接近真实视觉体验，并显著提升效率和效果。


<details>
  <summary>Details</summary>
Motivation: 现有fMRI信号到图像的重建方法主要依赖单一高层特征作为引导，忽视了大脑视觉信息的层级结构，导致重建过程中信息损失、效果有限。为此，作者引入更加贴合认知过程的层次化方案，提升重建质量和效率。

Method: 提出MindHier方法，包含三个关键部分：1）层次化fMRI编码器，提取多层次神经特征；2）层-层对齐策略，将提取的特征与CLIP中不同层次的图像特征逐层对应；3）分尺度渐进神经引导机制，将上述分层特征逐步作用于图像自回归生成模型，引导图像在不同尺度进行粗到细的重建。整体流程模拟人类视觉由整体到细节的认知过程。

Result: 在NSD数据集上的实验表明，MindHier在语义保真度上优于扩散模型类基线方法，推理速度提升4.67倍，生成结果的确定性更高，表现出强大的综合性能。

Conclusion: MindHier验证了层次化引导和逐步重建在fMRI到图像任务中的有效性，既提升生成质量，也显著加快推理速度，为神经科学和人工智能交叉研究提供了高效、认知一致性强的新工具。

Abstract: Reconstructing visual stimuli from fMRI signals is a central challenge
bridging machine learning and neuroscience. Recent diffusion-based methods
typically map fMRI activity to a single high-level embedding, using it as fixed
guidance throughout the entire generation process. However, this fixed guidance
collapses hierarchical neural information and is misaligned with the
stage-dependent demands of image reconstruction. In response, we propose
MindHier, a coarse-to-fine fMRI-to-image reconstruction framework built on
scale-wise autoregressive modeling. MindHier introduces three components: a
Hierarchical fMRI Encoder to extract multi-level neural embeddings, a
Hierarchy-to-Hierarchy Alignment scheme to enforce layer-wise correspondence
with CLIP features, and a Scale-Aware Coarse-to-Fine Neural Guidance strategy
to inject these embeddings into autoregression at matching scales. These
designs make MindHier an efficient and cognitively-aligned alternative to
diffusion-based methods by enabling a hierarchical reconstruction process that
synthesizes global semantics before refining local details, akin to human
visual perception. Extensive experiments on the NSD dataset show that MindHier
achieves superior semantic fidelity, 4.67x faster inference, and more
deterministic results than the diffusion-based baselines.

</details>


### [92] [GeoDiffusion: A Training-Free Framework for Accurate 3D Geometric Conditioning in Image Generation](https://arxiv.org/abs/2510.22337)
*Phillip Mueller,Talip Uenlue,Sebastian Schmidt,Marcel Kollovieh,Jiajie Fan,Stephan Guennemann,Lars Mikelsons*

Main category: cs.CV

TL;DR: GeoDiffusion是一个无需训练的新框架，可以在图像生成中实现对3D几何特征的精准、快速控制，克服了现有方法在几何约束上的精度不足问题。


<details>
  <summary>Details</summary>
Motivation: 工程设计和创意产业在图像生成中需要对物体的3D几何特征进行精确控制，而现有3D编辑方法操作复杂、耗时，现有基于图像的生成方法又缺乏精确的几何控制能力，因此需要新方法提升效率和几何精度。

Method: 提出了GeoDiffusion框架，采用类别特定的3D对象作为几何先验，通过定义关键点和参数相关性进行控制。使用渲染的参考3D对象图像保证视角一致，通过风格迁移满足外观需求。核心模块GeoDrag提升了拖拽式几何编辑的速度与精度。

Result: 实验表明，GeoDiffusion能在多种迭代设计流程中实现高精度的几何修改，且速度和准确性均有显著提升。

Conclusion: GeoDiffusion框架为图像生成中的3D几何精准控制和高效设计提供了强大工具，有望推进相关工业与创意领域的应用。

Abstract: Precise geometric control in image generation is essential for engineering \&
product design and creative industries to control 3D object features accurately
in image space. Traditional 3D editing approaches are time-consuming and demand
specialized skills, while current image-based generative methods lack accuracy
in geometric conditioning. To address these challenges, we propose
GeoDiffusion, a training-free framework for accurate and efficient geometric
conditioning of 3D features in image generation. GeoDiffusion employs a
class-specific 3D object as a geometric prior to define keypoints and
parametric correlations in 3D space. We ensure viewpoint consistency through a
rendered image of a reference 3D object, followed by style transfer to meet
user-defined appearance specifications. At the core of our framework is
GeoDrag, improving accuracy and speed of drag-based image editing on geometry
guidance tasks and general instructions on DragBench. Our results demonstrate
that GeoDiffusion enables precise geometric modifications across various
iterative design workflows.

</details>


### [93] [EndoSfM3D: Learning to 3D Reconstruct Any Endoscopic Surgery Scene using Self-supervised Foundation Model](https://arxiv.org/abs/2510.22359)
*Changhao Zhang,Matthew J. Clarkson,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: 本文提出一种集成内参估计的自监督单目深度估计算法，有效提升内镜手术场景三维重建的精确度，并在公开数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有多数内镜三维重建方法未估计相机内参，导致精度不高，且实际手术环境下因无菌和器械特性，内参校准极具挑战。

Method: 在自监督单目深度估计框架中引入内参估计，基于Depth Anything V2模型，联合预测深度、位姿和相机内参，提出了注意力机制的位姿网络及权重分解低秩适应策略以高效微调模型参数。

Result: 该方法在SCARED和C3VD公开数据集上，单目深度估计与三维重建表现优于当前主流方法。

Conclusion: 集成内参估计的自监督方法能更准确地进行内镜三维重建，有望提升临床图像导航场景的实用性和可靠性。

Abstract: 3D reconstruction of endoscopic surgery scenes plays a vital role in
enhancing scene perception, enabling AR visualization, and supporting
context-aware decision-making in image-guided surgery. A critical yet
challenging step in this process is the accurate estimation of the endoscope's
intrinsic parameters. In real surgical settings, intrinsic calibration is
hindered by sterility constraints and the use of specialized endoscopes with
continuous zoom and telescope rotation. Most existing methods for endoscopic 3D
reconstruction do not estimate intrinsic parameters, limiting their
effectiveness for accurate and reliable reconstruction. In this paper, we
integrate intrinsic parameter estimation into a self-supervised monocular depth
estimation framework by adapting the Depth Anything V2 (DA2) model for joint
depth, pose, and intrinsics prediction. We introduce an attention-based pose
network and a Weight-Decomposed Low-Rank Adaptation (DoRA) strategy for
efficient fine-tuning of DA2. Our method is validated on the SCARED and C3VD
public datasets, demonstrating superior performance compared to recent
state-of-the-art approaches in self-supervised monocular depth estimation and
3D reconstruction. Code and model weights can be found in project repository:
https://github.com/MOYF-beta/EndoSfM3D.

</details>


### [94] [T2SMark: Balancing Robustness and Diversity in Noise-as-Watermark for Diffusion Models](https://arxiv.org/abs/2510.22366)
*Jindong Yang,Han Fang,Weiming Zhang,Nenghai Yu,Kejiang Chen*

Main category: cs.CV

TL;DR: 本文提出了T2SMark，一种用于扩散模型图像水印的新方法，实现了水印鲁棒性与生成多样性的最佳平衡。作者通过尾部截断采样（TTS）及双阶段框架有效提升了水印稳健性且不影响图像质量。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型产生高质量图像，但知识产权保护与滥用风险增加。已有噪声水印方法难以兼顾水印的鲁棒性与生成图像的多样性，影响用户体验或实际可用性。

Method: 提出T2SMark，包括两大创新：一是“尾部截断采样”，仅在稳定可靠的高斯分布尾部区域嵌入信息位，中心区域随机采样，确保分布多样性；二是双阶段框架，将会话密钥引入加密流程，进一步提升采样多样性和安全性。

Result: 在带有U-Net和DiT骨干的扩散模型上做了大量实验，T2SMark都可以在水印鲁棒性和图像多样性之间获得最佳平衡，优于现有方法。

Conclusion: T2SMark为扩散模型数据版权保护提供了更为稳健且实际可用的水印方案，有效缓解了当前技术在水印鲁棒性和多样性间权衡的难题。

Abstract: Diffusion models have advanced rapidly in recent years, producing
high-fidelity images while raising concerns about intellectual property
protection and the misuse of generative AI. Image watermarking for diffusion
models, particularly Noise-as-Watermark (NaW) methods, encode watermark as
specific standard Gaussian noise vector for image generation, embedding the
infomation seamlessly while maintaining image quality. For detection, the
generation process is inverted to recover the initial noise vector containing
the watermark before extraction. However, existing NaW methods struggle to
balance watermark robustness with generation diversity. Some methods achieve
strong robustness by heavily constraining initial noise sampling, which
degrades user experience, while others preserve diversity but prove too fragile
for real-world deployment. To address this issue, we propose T2SMark, a
two-stage watermarking scheme based on Tail-Truncated Sampling (TTS). Unlike
prior methods that simply map bits to positive or negative values, TTS enhances
robustness by embedding bits exclusively in the reliable tail regions while
randomly sampling the central zone to preserve the latent distribution. Our
two-stage framework then ensures sampling diversity by integrating a randomly
generated session key into both encryption pipelines. We evaluate T2SMark on
diffusion models with both U-Net and DiT backbones. Extensive experiments show
that it achieves an optimal balance between robustness and diversity. Our code
is available at
\href{https://github.com/0xD009/T2SMark}{https://github.com/0xD009/T2SMark}.

</details>


### [95] [Efficient Large-Deformation Medical Image Registration via Recurrent Dynamic Correlation](https://arxiv.org/abs/2510.22380)
*Tianran Li,Marius Staring,Yuchuan Qiao*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的基于递归相关性的图像配准框架，有效提升了医学影像中大变形情况下的效率和精度。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法虽然提升了图像配准的速度，但在应对大形变时仍显不足。主要挑战在于卷积网络只能聚合局部特征，难以直接建模体素对应关系，而现有匹配方法在效率和全局对应捕获之间难以兼顾。

Method: 作者提出一种递归相关性框架，通过动态迁移匹配区域，在每一步以低成本进行局部匹配，并利用先前步骤的偏移引导后续的匹配搜索，实现对大变形情况下的高效收敛。此外，设计了轻量的递归更新模块，并将运动相关特征和纹理特征解耦，降低语义冗余。方法在脑MRI和腹部CT数据集上，分别在有/无仿射预配准条件下进行了实验验证。

Result: 实验表明，本文方法在计算量和准确性之间实现了优越的平衡。比如在OASIS非仿射数据集上，性能与高效基线方法RDP相当，但仅用9.5%的FLOPs，运行速度快了96%。

Conclusion: 该方法能够在保持高配准精度的同时，极大提高效率，优于或匹配目前最先进的方法，为医学影像大形变配准提供了有效的解决思路。

Abstract: Deformable image registration estimates voxel-wise correspondences between
images through spatial transformations, and plays a key role in medical
imaging. While deep learning methods have significantly reduced runtime,
efficiently handling large deformations remains a challenging task.
Convolutional networks aggregate local features but lack direct modeling of
voxel correspondences, promoting recent works to explore explicit feature
matching. Among them, voxel-to-region matching is more efficient for direct
correspondence modeling by computing local correlation features whithin
neighbourhoods, while region-to-region matching incurs higher redundancy due to
excessive correlation pairs across large regions. However, the inherent
locality of voxel-to-region matching hinders the capture of long-range
correspondences required for large deformations. To address this, we propose a
Recurrent Correlation-based framework that dynamically relocates the matching
region toward more promising positions. At each step, local matching is
performed with low cost, and the estimated offset guides the next search
region, supporting efficient convergence toward large deformations. In
addition, we uses a lightweight recurrent update module with memory capacity
and decouples motion-related and texture features to suppress semantic
redundancy. We conduct extensive experiments on brain MRI and abdominal CT
datasets under two settings: with and without affine pre-registration. Results
show that our method exibits a strong accuracy-computation trade-off,
surpassing or matching the state-of-the-art performance. For example, it
achieves comparable performance on the non-affine OASIS dataset, while using
only 9.5% of the FLOPs and running 96% faster than RDP, a representative
high-performing method.

</details>


### [96] [A Fully Interpretable Statistical Approach for Roadside LiDAR Background Subtraction](https://arxiv.org/abs/2510.22390)
*Aitor Iglesias,Nerea Aranjuelo,Patricia Javierre,Ainhoa Menendez,Ignacio Arganda-Carreras,Marcos Nieto*

Main category: cs.CV

TL;DR: 本文提出了一种适用于路边LiDAR数据的背景消除新方法，通过高斯分布网格和高效滤波算法，实现高准确率和灵活性，适配多种传感器及硬件。


<details>
  <summary>Details</summary>
Motivation: 现有的路边LiDAR背景消除方法在不同传感器类型与配置下适应性不强，且在资源受限硬件上的执行效率有限，亟需可解释且高效的新方法以提升自动驾驶基础设施感知能力。

Method: 作者提出了高斯分布网格（GDG）来用仅含背景的扫描数据对背景的空间统计进行建模，并设计了配套滤波算法，通过GDG表征对LiDAR点进行前景/背景分类。此方法兼容多线360度和MEMS型LiDAR传感器，能自适应不同配置。

Result: 在RCooper公开数据集上评测，所提方法在准确率和灵活性上优于当前主流技术，即便仅使用少量背景数据。在低资源硬件上实现依旧高效可靠，具备规模化部署能力。

Conclusion: 该方法为基础设施型自动驾驶感知系统提供了一种既可解释又高效灵活的背景消除方案，适合多种实际应用场景，有望推动其大规模落地。

Abstract: We present a fully interpretable and flexible statistical method for
background subtraction in roadside LiDAR data, aimed at enhancing
infrastructure-based perception in automated driving. Our approach introduces
both a Gaussian distribution grid (GDG), which models the spatial statistics of
the background using background-only scans, and a filtering algorithm that uses
this representation to classify LiDAR points as foreground or background. The
method supports diverse LiDAR types, including multiline 360 degree and
micro-electro-mechanical systems (MEMS) sensors, and adapts to various
configurations. Evaluated on the publicly available RCooper dataset, it
outperforms state-of-the-art techniques in accuracy and flexibility, even with
minimal background data. Its efficient implementation ensures reliable
performance on low-resource hardware, enabling scalable real-world deployment.

</details>


### [97] [Top-Down Semantic Refinement for Image Captioning](https://arxiv.org/abs/2510.22391)
*Jusheng Zhang,Kaitong Cai,Jing Yang,Jian Wang,Chengpei Tang,Keze Wang*

Main category: cs.CV

TL;DR: 本文提出了一种称为TDSR的分层细化规划方法，利用高效的蒙特卡洛树搜索（MCTS）算法和视觉引导机制，有效提升大规模视觉-语言模型（VLM）在图像描述任务中的表现，实现了细致描述、全局一致和低计算消耗。


<details>
  <summary>Details</summary>
Motivation: 当前大规模视觉-语言模型在图像描述任务中，虽然具备强大的单步生成能力，但容易陷入短视决策，导致难以兼顾全局叙述连贯性与丰富细节。这一矛盾在需要多步和复杂场景描述的任务中尤为突出，因此亟需新的方法来解决这一问题。

Method: 作者将图像描述任务重新定义为目标导向的分层细化规划问题，并提出了TDSR框架，将生成过程建模为马尔可夫决策过程（MDP）。为解决庞大状态空间带来的计算挑战，设计了一种高效的蒙特卡洛树搜索（MCTS）算法，同时引入视觉引导的并行扩展与轻量级价值网络，大幅减少了对VLM的调用次数，并通过自适应提前终止机制，根据图片复杂度动态调整计算量。

Result: 在DetailCaps、COMPOSITIONCAP、POPE等多个基准数据集上进行了大量实验。TDSR作为即插即用模块，显著提升了如LLaVA-1.5、Qwen2.5-VL等现有VLM的精细化描述、组成泛化与幻觉抑制表现，达到了最新或极具竞争力的效果。

Conclusion: TDSR框架有效解决了大规模VLM在图像描述时全局一致性与细致细节难以兼顾的问题，不仅提升了性能，还显著降低了计算开销，可广泛应用于增强各类VLM的图像描述能力。

Abstract: Large Vision-Language Models (VLMs) face an inherent contradiction in image
captioning: their powerful single-step generation capabilities often lead to a
myopic decision-making process. This makes it difficult to maintain global
narrative coherence while capturing rich details, a limitation that is
particularly pronounced in tasks that require multi-step and complex scene
description. To overcome this fundamental challenge, we redefine image
captioning as a goal-oriented hierarchical refinement planning problem, and
further propose a novel framework, named Top-Down Semantic Refinement (TDSR),
which models the generation process as a Markov Decision Process (MDP).
However, planning within the vast state space of a VLM presents a significant
computational hurdle. Our core contribution, therefore, is the design of a
highly efficient Monte Carlo Tree Search (MCTS) algorithm tailored for VLMs. By
incorporating a visual-guided parallel expansion and a lightweight value
network, our TDSR reduces the call frequency to the expensive VLM by an order
of magnitude without sacrificing planning quality. Furthermore, an adaptive
early stopping mechanism dynamically matches computational overhead to the
image's complexity. Extensive experiments on multiple benchmarks, including
DetailCaps, COMPOSITIONCAP, and POPE, demonstrate that our TDSR, as a
plug-and-play module, can significantly enhance the performance of existing
VLMs (e.g., LLaVA-1.5, Qwen2.5-VL) by achieving state-of-the-art or highly
competitive results in fine-grained description, compositional generalization,
and hallucination suppression.

</details>


### [98] [3D Roadway Scene Object Detection with LIDARs in Snowfall Conditions](https://arxiv.org/abs/2510.22436)
*Ghazal Farhani,Taufiq Rahman,Syed Mostaquim Ali,Andrew Liu,Mohamed Zaki,Dominique Charlebois,Benoit Anctil*

Main category: cs.CV

TL;DR: 本论文研究了雪天对汽车级LiDAR性能的影响，建立了物理模型模拟雪天信号衰减，并评估了其对目标检测模型表现的影响。


<details>
  <summary>Details</summary>
Motivation: LiDAR对于自动驾驶感知至关重要，但当前主要聚焦于清晰天气，对恶劣天气（如雨雪）下性能退化缺乏量化研究，尤其对学习模型影响未明确。作者希望通过物理建模明确雪天对LiDAR传感器工作模式的具体影响。

Method: 作者在不同降雪率下，测试与建模了LiDAR信号衰减和雪粒反射效应。利用物理模型将晴天LiDAR数据合成拟合为雪天场景，并与真实雪天数据对比。同时，把合成数据输入预训练目标检测模型，评估其在不同雪强度下的表现。

Result: 建成了可将晴天数据转化为雪天场景的LiDAR物理模拟模型，并验证其与实测雪天数据较为一致。结果显示，随降雪率提升，LiDAR信号显著衰减，目标检测模型性能下降明显。

Conclusion: 雪天对LiDAR传感器的感知能力与目标检测模型性能有显著影响。所提物理模型可有效模拟雪天场景，辅助未来自动驾驶系统在恶劣天气下的适应性设计和模型鲁棒性提升。

Abstract: Because 3D structure of a roadway environment can be characterized directly
by a Light Detection and Ranging (LiDAR) sensors, they can be used to obtain
exceptional situational awareness for assitive and autonomous driving systems.
Although LiDARs demonstrate good performance in clean and clear weather
conditions, their performance significantly deteriorates in adverse weather
conditions such as those involving atmospheric precipitation. This may render
perception capabilities of autonomous systems that use LiDAR data in learning
based models to perform object detection and ranging ineffective. While efforts
have been made to enhance the accuracy of these models, the extent of signal
degradation under various weather conditions remains largely not quantified. In
this study, we focus on the performance of an automotive grade LiDAR in snowy
conditions in order to develop a physics-based model that examines failure
modes of a LiDAR sensor. Specifically, we investigated how the LiDAR signal
attenuates with different snowfall rates and how snow particles near the source
serve as small but efficient reflectors. Utilizing our model, we transform data
from clear conditions to simulate snowy scenarios, enabling a comparison of our
synthetic data with actual snowy conditions. Furthermore, we employ this
synthetic data, representative of different snowfall rates, to explore the
impact on a pre-trained object detection model, assessing its performance under
varying levels of snowfall

</details>


### [99] [Benchmarking Egocentric Multimodal Goal Inference for Assistive Wearable Agents](https://arxiv.org/abs/2510.22443)
*Vijay Veerabadran,Fanyi Xiao,Nitin Kamra,Pedro Matias,Joy Chen,Caley Drooff,Brett D Roads,Riley Williams,Ethan Henderson,Xuanyi Zhao,Kevin Carlberg,Joseph Tighe,Karl Ridgeway*

Main category: cs.CV

TL;DR: 本文关注于可穿戴智能助手，通过多模态信息推断用户目标，并提出了衡量该任务的强基准WAGIBench。结果显示当前模型距离实际可用性仍有差距。


<details>
  <summary>Details</summary>
Motivation: 在智能可穿戴设备（如智能眼镜）广泛发展的背景下，如何理解并自动推断用户目标变得重要，这可提升用户体验，减少人工交互。此前该领域几乎没有标准数据集与衡量方法，阻碍了进展。

Method: 作者建立了WAGIBench基准，包括收集了348名参与者、29小时、3477条多模态（视觉、音频、数字和时间上下文）记录，含有真实目标标签。以最新视觉-语言模型（VLMs）作多个评测，并分析不同模态信息对模型表现的影响。

Result: 人在该任务上有93%多项选择准确率，最佳VLM仅为84%；VLM在生成目标任务中最高仅有55%相关目标生成率。更大规模VLM性能提升明显，并且在相关模态信息被增添时模型表现更好，剔除无关模态影响有限。

Conclusion: 虽然当前VLM在推断用户目标方面取得一定进步，但和人类表现仍有较大差距。WAGIBench为后续研究提供了数据和基线，方便进一步优化多模态辅助智能系统的目标推断能力。

Abstract: There has been a surge of interest in assistive wearable agents: agents
embodied in wearable form factors (e.g., smart glasses) who take assistive
actions toward a user's goal/query (e.g. "Where did I leave my keys?"). In this
work, we consider the important complementary problem of inferring that goal
from multi-modal contextual observations. Solving this "goal inference" problem
holds the promise of eliminating the effort needed to interact with such an
agent. This work focuses on creating WAGIBench, a strong benchmark to measure
progress in solving this problem using vision-language models (VLMs). Given the
limited prior work in this area, we collected a novel dataset comprising 29
hours of multimodal data from 348 participants across 3,477 recordings,
featuring ground-truth goals alongside accompanying visual, audio, digital, and
longitudinal contextual observations. We validate that human performance
exceeds model performance, achieving 93% multiple-choice accuracy compared with
84% for the best-performing VLM. Generative benchmark results that evaluate
several families of modern vision-language models show that larger models
perform significantly better on the task, yet remain far from practical
usefulness, as they produce relevant goals only 55% of the time. Through a
modality ablation, we show that models benefit from extra information in
relevant modalities with minimal performance degradation from irrelevant
modalities.

</details>


### [100] [SemiETPicker: Fast and Label-Efficient Particle Picking for CryoET Tomography Using Semi-Supervised Learning](https://arxiv.org/abs/2510.22454)
*Linhan Wang,Jianwen Dou,Wang Li,Shengkun Wang,Zhiwu Xie,Chang-Tien Lu,Yinlin Chen*

Main category: cs.CV

TL;DR: 该论文提出了一种高效的半监督3D粒子定位与分类框架，用于CryoET蛋白质结构解析，显著提升了在标注稀缺条件下的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的CryoET粒子拾取依赖大量人工标注，耗时耗力，导致海量未标注数据无法利用，成为制约分子分辨率结构解析的主要瓶颈。

Method: 提出端到端的热力图监督检测模型（借鉴关键点检测思想）和教师-学生协同训练机制，并引入多视图伪标签和CryoET专用的DropBlock增强方法，以充分利用未标注的数据。

Result: 在大规模CZII数据集上，提出框架相比监督学习基线，F1得分提高了10%。

Conclusion: 半监督学习方法能够有效利用未标注的CryoET三维数据，提升蛋白质定位与分类的准确率，为分子分辨率原位结构生物学研究开辟了新路径。

Abstract: Cryogenic Electron Tomography (CryoET) combined with sub-volume averaging
(SVA) is the only imaging modality capable of resolving protein structures
inside cells at molecular resolution. Particle picking, the task of localizing
and classifying target proteins in 3D CryoET volumes, remains the main
bottleneck. Due to the reliance on time-consuming manual labels, the vast
reserve of unlabeled tomograms remains underutilized. In this work, we present
a fast, label-efficient semi-supervised framework that exploits this untapped
data. Our framework consists of two components: (i) an end-to-end
heatmap-supervised detection model inspired by keypoint detection, and (ii) a
teacher-student co-training mechanism that enhances performance under sparse
labeling conditions. Furthermore, we introduce multi-view pseudo-labeling and a
CryoET-specific DropBlock augmentation strategy to further boost performance.
Extensive evaluations on the large-scale CZII dataset show that our approach
improves F1 by 10% over supervised baselines, underscoring the promise of
semi-supervised learning for leveraging unlabeled CryoET data.

</details>


### [101] [DynaPose4D: High-Quality 4D Dynamic Content Generation via Pose Alignment Loss](https://arxiv.org/abs/2510.22473)
*Jing Yang,Yufeng Yang*

Main category: cs.CV

TL;DR: 本文提出DynaPose4D框架，实现了从单张静态图像生成高质量4D动态内容，解决了建模时空依赖和动态几何变化难题。


<details>
  <summary>Details</summary>
Motivation: 现有2D/3D生成模型无法有效从单图像生成高质量4D（含时间变化）动态内容，尤其在动态几何变化和视角变化下表现受限，因此需要新方法提升时空一致性和动态流畅性。

Method: 提出DynaPose4D方法，结合4D高斯投影技术与类别无关的姿态估计（CAPE）：（1）利用3D高斯投影从单图像构建3D模型；（2）基于选定视角进行多视图姿态关键点预测，并利用监督信号增强运动一致性。

Result: 实验表明DynaPose4D在生成动态内容时具备很好的连贯性、一致性和流畅性，优于传统方法。

Conclusion: DynaPose4D框架能高效生成高质量4D动态内容，对计算机视觉和动画制作领域具备实际应用潜力。

Abstract: Recent advancements in 2D and 3D generative models have expanded the
capabilities of computer vision. However, generating high-quality 4D dynamic
content from a single static image remains a significant challenge. Traditional
methods have limitations in modeling temporal dependencies and accurately
capturing dynamic geometry changes, especially when considering variations in
camera perspective. To address this issue, we propose DynaPose4D, an innovative
solution that integrates 4D Gaussian Splatting (4DGS) techniques with
Category-Agnostic Pose Estimation (CAPE) technology. This framework uses 3D
Gaussian Splatting to construct a 3D model from single images, then predicts
multi-view pose keypoints based on one-shot support from a chosen view,
leveraging supervisory signals to enhance motion consistency. Experimental
results show that DynaPose4D achieves excellent coherence, consistency, and
fluidity in dynamic motion generation. These findings not only validate the
efficacy of the DynaPose4D framework but also indicate its potential
applications in the domains of computer vision and animation production.

</details>


### [102] [Single-Teacher View Augmentation: Boosting Knowledge Distillation via Angular Diversity](https://arxiv.org/abs/2510.22480)
*Seonghoon Yu,Dongjun Nam,Dina Katabi,Jeany Son*

Main category: cs.CV

TL;DR: 本文提出了一种高效低成本的知识蒸馏方法，仅通过在单一教师模型上附加多分支，生成多样的知识视角，从而提升学生模型的表现。


<details>
  <summary>Details</summary>
Motivation: 多教师网络能提升知识蒸馏效果，但计算成本较高；希望在不增加计算负担的情况下获得多样的知识视角。

Method: 在单一教师模型上添加多个分支，产生多样化的输出视角。设计了两个角度多样性损失：约束交角多样化损失（最大化视角间夹角并保持和原始输出接近）、内角多样化损失（鼓励所有分支相对于原始输出均匀分布），将多样化的集成知识蒸馏给学生模型。

Result: 理论分析表明，本方法提升了集成成员多样性，降低了集成期望损失的上界。实验结果显示，该方法在多种配置下超越了现有知识增强方法，并可与其他知识蒸馏框架搭配，持续提升泛化能力。

Conclusion: 单教师多分支的知识增强不仅低成本且高效，能有效提升知识蒸馏的效果，并且具有良好的通用性和扩展性。

Abstract: Knowledge Distillation (KD) aims to train a lightweight student model by
transferring knowledge from a large, high-capacity teacher. Recent studies have
shown that leveraging diverse teacher perspectives can significantly improve
distillation performance; however, achieving such diversity typically requires
multiple teacher networks, leading to high computational costs. In this work,
we propose a novel cost-efficient knowledge augmentation method for KD that
generates diverse multi-views by attaching multiple branches to a single
teacher. To ensure meaningful semantic variation across multi-views, we
introduce two angular diversity objectives: 1) constrained inter-angle
diversify loss, which maximizes angles between augmented views while preserving
proximity to the original teacher output, and 2) intra-angle diversify loss,
which encourages an even distribution of views around the original output. The
ensembled knowledge from these angularly diverse views, along with the original
teacher, is distilled into the student. We further theoretically demonstrate
that our objectives increase the diversity among ensemble members and thereby
reduce the upper bound of the ensemble's expected loss, leading to more
effective distillation. Experimental results show that our method surpasses an
existing knowledge augmentation method across diverse configurations. Moreover,
the proposed method is compatible with other KD frameworks in a plug-and-play
fashion, providing consistent improvements in generalization performance.

</details>


### [103] [GateFuseNet: An Adaptive 3D Multimodal Neuroimaging Fusion Network for Parkinson's Disease Diagnosis](https://arxiv.org/abs/2510.22507)
*Rui Jin,Chen Chen,Yin Liu,Hongfu Sun,Min Zeng,Min Li,Yang Gao*

Main category: cs.CV

TL;DR: 本研究提出了GateFuseNet，一个融合QSM和T1w MRI影像用于帕金森病诊断的3D多模态网络，创新性地引入门控融合机制提升特征利用，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统MRI如T1w对帕金森病的诊断灵敏度有限，而QSM能量化铁沉积，对病理更敏感，因此研究者希望融合二者提高诊断准确率。

Method: 提出了一种自适应三维多模态融合网络GateFuseNet，使用门控融合模块学习模态特异性注意权重与通道门控向量，有层次性地增强关注区域特征并抑制无关信号。

Result: 实验显示，GateFuseNet在准确率（85.00%）和AUC（92.06%）上均优于三种现有先进方法，消融实验验证了各模块的有效性，Grad-CAM可视化证实模型对关键病理区域的关注。

Conclusion: GateFuseNet有效提升了融合MRI影像下帕金森病的诊断性能，为临床病理提示和精确诊断提供了新工具。

Abstract: Accurate diagnosis of Parkinson's disease (PD) from MRI remains challenging
due to symptom variability and pathological heterogeneity. Most existing
methods rely on conventional magnitude-based MRI modalities, such as
T1-weighted images (T1w), which are less sensitive to PD pathology than
Quantitative Susceptibility Mapping (QSM), a phase-based MRI technique that
quantifies iron deposition in deep gray matter nuclei. In this study, we
propose GateFuseNet, an adaptive 3D multimodal fusion network that integrates
QSM and T1w images for PD diagnosis. The core innovation lies in a gated fusion
module that learns modality-specific attention weights and channel-wise gating
vectors for selective feature modulation. This hierarchical gating mechanism
enhances ROI-aware features while suppressing irrelevant signals. Experimental
results show that our method outperforms three existing state-of-the-art
approaches, achieving 85.00% accuracy and 92.06% AUC. Ablation studies further
validate the contributions of ROI guidance, multimodal integration, and fusion
positioning. Grad-CAM visualizations confirm the model's focus on clinically
relevant pathological regions. The source codes and pretrained models can be
found at https://github.com/YangGaoUQ/GateFuseNet

</details>


### [104] [Open Multimodal Retrieval-Augmented Factual Image Generation](https://arxiv.org/abs/2510.22521)
*Yang Tian,Fan Liu,Jingyuan Zhang,Wei Bi,Yupeng Hu,Liqiang Nie*

Main category: cs.CV

TL;DR: 论文提出了一种新方法，提升大型多模态模型生成图片的事实性和现实感，解决传统方法在知识更新与融合上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态生成模型在生成高质量、符合提示的图片上表现出色，但在涉及细致属性或时效性事件的情景下，常常无法输出与事实一致的内容。现有的检索增强方法由于对静态信息源和浅层证据融合的依赖，无法有效更新和整合最新知识，因此亟需更优方法提升生成结果的事实性。

Method: 提出ORIG，一种具备智能体特性的开放式多模态检索增强框架。ORIG通过迭代式从网络检索和过滤多模态证据，将精炼后的知识逐步整合到生成提示中，从而引导生成更具事实依据的图片。同时，构建了涵盖感知、组合和时序等维度的FIG-Eval基准，用于系统评估该任务。

Result: 实验证明，ORIG在事实一致性和整体图片质量方面，均显著优于现有的强基线方法。FIG-Eval的评估结果也突出表现了该方法对事实性图片生成的改进效果。

Conclusion: ORIG展示了开放多模态检索在事实性图片生成任务中的巨大潜力，推进了该领域模型在知识更新和整合方面的能力。

Abstract: Large Multimodal Models (LMMs) have achieved remarkable progress in
generating photorealistic and prompt-aligned images, but they often produce
outputs that contradict verifiable knowledge, especially when prompts involve
fine-grained attributes or time-sensitive events. Conventional
retrieval-augmented approaches attempt to address this issue by introducing
external information, yet they are fundamentally incapable of grounding
generation in accurate and evolving knowledge due to their reliance on static
sources and shallow evidence integration. To bridge this gap, we introduce
ORIG, an agentic open multimodal retrieval-augmented framework for Factual
Image Generation (FIG), a new task that requires both visual realism and
factual grounding. ORIG iteratively retrieves and filters multimodal evidence
from the web and incrementally integrates the refined knowledge into enriched
prompts to guide generation. To support systematic evaluation, we build
FIG-Eval, a benchmark spanning ten categories across perceptual, compositional,
and temporal dimensions. Experiments demonstrate that ORIG substantially
improves factual consistency and overall image quality over strong baselines,
highlighting the potential of open multimodal retrieval for factual image
generation.

</details>


### [105] [AesCrop: Aesthetic-driven Cropping Guided by Composition](https://arxiv.org/abs/2510.22528)
*Yen-Hong Wong,Lai-Kuan Wong*

Main category: cs.CV

TL;DR: 本文提出了AesCrop模型，通过强化图像构图元素，实现更美学驱动的图片裁剪，实验显示优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前自动化图片裁剪方法在美学和多样性上存在不足，缺乏对摄影构图知识的有效利用。本文旨在填补现有评估式与回归式方法在整体性、构图指导和多样性上的短板。

Method: AesCrop结合了VMamba图像编码器和创新的Mamba Composition Attention Bias (MCAB)，利用Transformer解码器进行端到端、基于排名的多样化图片裁剪，并对每个裁剪区域进行美学评估。MCAB机制增强模型对重要构图区域的关注。

Result: 大量实验表明，AesCrop在量化指标和裁剪效果上均优于当前最先进方法，生成的图片更具美感与多样性。

Conclusion: AesCrop有效整合构图感知与多样性，推动美学驱动图片裁剪方法的发展，在实际应用中具有潜在优势。

Abstract: Aesthetic-driven image cropping is crucial for applications like view
recommendation and thumbnail generation, where visual appeal significantly
impacts user engagement. A key factor in visual appeal is composition--the
deliberate arrangement of elements within an image. Some methods have
successfully incorporated compositional knowledge through evaluation-based and
regression-based paradigms. However, evaluation-based methods lack globality
while regression-based methods lack diversity. Recently, hybrid approaches that
integrate both paradigms have emerged, bridging the gap between these two to
achieve better diversity and globality. Notably, existing hybrid methods do not
incorporate photographic composition guidance, a key attribute that defines
photographic aesthetics. In this work, we introduce AesCrop, a
composition-aware hybrid image-cropping model that integrates a VMamba image
encoder, augmented with a novel Mamba Composition Attention Bias (MCAB) and a
transformer decoder to perform end-to-end rank-based image cropping, generating
multiple crops along with the corresponding quality scores. By explicitly
encoding compositional cues into the attention mechanism, MCAB directs AesCrop
to focus on the most compositionally salient regions. Extensive experiments
demonstrate that AesCrop outperforms current state-of-the-art methods,
delivering superior quantitative metrics and qualitatively more pleasing crops.

</details>


### [106] [SRSR: Enhancing Semantic Accuracy in Real-World Image Super-Resolution with Spatially Re-Focused Text-Conditioning](https://arxiv.org/abs/2510.22534)
*Chen Chen,Majid Abdolshah,Violetta Shevchenko,Hongdong Li,Chang Xu,Pulak Purkait*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的、高效的空间再聚焦超分辨（SRSR）框架，能有效提升扩散模型在超分辨任务中的语义准确性与感知质量，并优于现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在超分辨任务中，因文本条件不精确及交叉注意力机制易关注无关像素，常导致生成图像存在语义歧义与细节臆造问题。本文旨在解决这些现有方法中的语义对齐与幻觉错误。

Method: 提出SRSR框架，包含两大改进：1）空间再聚焦交叉注意力（SRCA），利用分割掩码引导交叉注意力，以优化推理时的文本条件；2）空间针对性无分类器引导（STCFG），在未被文本条件支撑的像素上有选择地削弱文本影响，避免幻觉式细节产生。

Result: 在多组合成数据和真实世界数据集上，SRSR在PSNR、SSIM等常用保真度指标以及LPIPS、DISTS等感知质量指标上均优于七种主流对比方法，验证了算法的有效性。

Conclusion: SRSR能够同时实现高语义一致性和优良的感知质量，是扩散超分辨领域的有力创新方法。

Abstract: Existing diffusion-based super-resolution approaches often exhibit semantic
ambiguities due to inaccuracies and incompleteness in their text conditioning,
coupled with the inherent tendency for cross-attention to divert towards
irrelevant pixels. These limitations can lead to semantic misalignment and
hallucinated details in the generated high-resolution outputs. To address
these, we propose a novel, plug-and-play spatially re-focused super-resolution
(SRSR) framework that consists of two core components: first, we introduce
Spatially Re-focused Cross-Attention (SRCA), which refines text conditioning at
inference time by applying visually-grounded segmentation masks to guide
cross-attention. Second, we introduce a Spatially Targeted Classifier-Free
Guidance (STCFG) mechanism that selectively bypasses text influences on
ungrounded pixels to prevent hallucinations. Extensive experiments on both
synthetic and real-world datasets demonstrate that SRSR consistently
outperforms seven state-of-the-art baselines in standard fidelity metrics (PSNR
and SSIM) across all datasets, and in perceptual quality measures (LPIPS and
DISTS) on two real-world benchmarks, underscoring its effectiveness in
achieving both high semantic fidelity and perceptual quality in
super-resolution.

</details>


### [107] [STATUS Bench: A Rigorous Benchmark for Evaluating Object State Understanding in Vision-Language Models](https://arxiv.org/abs/2510.22571)
*Mahiro Ukai,Shuhei Kurita,Nakamasa Inoue*

Main category: cs.CV

TL;DR: 论文提出了一个专门用于评估视觉-语言模型（VLMs）识别物体状态能力的新基准STATUS Bench，并通过大规模训练集STATUS Train推动领域进步。结果显示现有模型对细微物体状态区分表现有限，强调了该基准的重要性。


<details>
  <summary>Details</summary>
Motivation: 虽然VLMs能完成多模态任务，但对于物体状态（如开/关、开/合等细致状态）的识别能力尚不明确。为推动相关模型评估与提升，需要一个专业且系统化的基准。

Method: 作者提出了STATUS Bench基准，包括三项任务：物体状态识别（OSI）、图像检索（IR）、状态变化识别（SCI）。实验利用了来自手工制作图片对及详细状态描述的数据集，并引入了包含1300万条半自动生成描述的大规模训练集STATUS Train。

Result: 实验发现，目前主流VLMs在所提严格评测下对细粒度状态识别表现近于随机，仅在经过STATUS Train微调后，Qwen2.5-VL可达到与Gemini 2.0 Flash相似水平。

Conclusion: 当前VLMs在识别细微物体状态上存在明显不足，STATUS Bench与STATUS Train对于推动该方向发展具有重要价值。

Abstract: Object state recognition aims to identify the specific condition of objects,
such as their positional states (e.g., open or closed) and functional states
(e.g., on or off). While recent Vision-Language Models (VLMs) are capable of
performing a variety of multimodal tasks, it remains unclear how precisely they
can identify object states. To alleviate this issue, we introduce the STAte and
Transition UnderStanding Benchmark (STATUS Bench), the first benchmark for
rigorously evaluating the ability of VLMs to understand subtle variations in
object states in diverse situations. Specifically, STATUS Bench introduces a
novel evaluation scheme that requires VLMs to perform three tasks
simultaneously: object state identification (OSI), image retrieval (IR), and
state change identification (SCI). These tasks are defined over our fully
hand-crafted dataset involving image pairs, their corresponding object state
descriptions and state change descriptions. Furthermore, we introduce a
large-scale training dataset, namely STATUS Train, which consists of 13 million
semi-automatically created descriptions. This dataset serves as the largest
resource to facilitate further research in this area. In our experiments, we
demonstrate that STATUS Bench enables rigorous consistency evaluation and
reveal that current state-of-the-art VLMs still significantly struggle to
capture subtle object state distinctions. Surprisingly, under the proposed
rigorous evaluation scheme, most open-weight VLMs exhibited chance-level
zero-shot performance. After fine-tuning on STATUS Train, Qwen2.5-VL achieved
performance comparable to Gemini 2.0 Flash. These findings underscore the
necessity of STATUS Bench and Train for advancing object state recognition in
VLM research.

</details>


### [108] [MELDAE: A Framework for Micro-Expression Spotting, Detection, and Automatic Evaluation in In-the-Wild Conversational Scenes](https://arxiv.org/abs/2510.22575)
*Yigui Feng,Qinglin Wang,Yang Liu,Ke Liu,Haotian Mo,Enhao Huang,Gencheng Liu,Mingzhe Liu,Jie Liu*

Main category: cs.CV

TL;DR: 该论文针对在自然对话环境中准确分析微表情的问题，提出了新的数据集、检测框架和损失函数，并实现了显著提升的检测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有微表情分析方法主要依赖受控实验室数据集，导致在真实场景下性能大幅下降，因此亟需适用于自然环境的解决方案。

Method: 提出了首个面向自然对话场景的微表情数据集，同时设计了端到端微表情定位与检测框架MELDAE，并创新性地引入了边界感知损失函数以提升时间定位精度。

Result: MELDAE在WDMD数据集上实现了最新最优的性能，关键的F1_{DR}定位指标比最强基线提升了17.72%，并在其他基准测试上表现出良好泛化性。

Conclusion: 论文的方法有效提升了自然场景下的微表情检测精度，对实际应用具有较大推动作用。

Abstract: Accurately analyzing spontaneous, unconscious micro-expressions is crucial
for revealing true human emotions, but this task remains challenging in wild
scenarios, such as natural conversation. Existing research largely relies on
datasets from controlled laboratory environments, and their performance
degrades dramatically in the real world. To address this issue, we propose
three contributions: the first micro-expression dataset focused on
conversational-in-the-wild scenarios; an end-to-end localization and detection
framework, MELDAE; and a novel boundary-aware loss function that improves
temporal accuracy by penalizing onset and offset errors. Extensive experiments
demonstrate that our framework achieves state-of-the-art results on the WDMD
dataset, improving the key F1_{DR} localization metric by 17.72% over the
strongest baseline, while also demonstrating excellent generalization
capabilities on existing benchmarks.

</details>


### [109] [From Pixels to Views: Learning Angular-Aware and Physics-Consistent Representations for Light Field Microscopy](https://arxiv.org/abs/2510.22577)
*Feng He,Guodong Tan,Qiankun Li,Jun Yu,Quan Wen*

Main category: cs.CV

TL;DR: 本论文提出了一套用于扩展光场显微成像（XLFM）三维重建的新方法，并构建了数据集，实现了比现有方法更高的重建准确率。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的XLFM三维重建研究进展缓慢，主要由于缺乏标准化数据集和有效建模角-空间结构的物理合理方法。

Method: 1）构建了XLFM-Zebrafish数据集，用于大规模XLFM重建评测；2）提出了遮挡视图掩码建模（MVN-LF），通过自监督预测遮挡视图进行角向先验学习，提高数据效率；3）设计了光学渲染一致性损失（ORC Loss），作为物理约束，确保预测体积与基于点扩散函数投影结果一致。

Result: 在XLFM-Zebrafish基准上，该方法PSNR比最新基线提升了7.7%。

Conclusion: 通过提出新数据集、自监督角度建模方法和物理一致性损失，显著提升了XLFM三维重建效果，为基于学习的XLFM研究奠定了基础。

Abstract: Light field microscopy (LFM) has become an emerging tool in neuroscience for
large-scale neural imaging in vivo, notable for its single-exposure volumetric
imaging, broad field of view, and high temporal resolution. However,
learning-based 3D reconstruction in XLFM remains underdeveloped due to two core
challenges: the absence of standardized datasets and the lack of methods that
can efficiently model its angular-spatial structure while remaining physically
grounded. We address these challenges by introducing three key contributions.
First, we construct the XLFM-Zebrafish benchmark, a large-scale dataset and
evaluation suite for XLFM reconstruction. Second, we propose Masked View
Modeling for Light Fields (MVN-LF), a self-supervised task that learns angular
priors by predicting occluded views, improving data efficiency. Third, we
formulate the Optical Rendering Consistency Loss (ORC Loss), a differentiable
rendering constraint that enforces alignment between predicted volumes and
their PSF-based forward projections. On the XLFM-Zebrafish benchmark, our
method improves PSNR by 7.7% over state-of-the-art baselines.

</details>


### [110] [Cross-View UAV Geo-Localization with Precision-Focused Efficient Design: A Hierarchical Distillation Approach with Multi-view Refinement](https://arxiv.org/abs/2510.22582)
*Jian Sun,Kangdao Liu,Chi Zhang,Chuangquan Chen,Junge Shen,Chi-Man Vong*

Main category: cs.CV

TL;DR: 提出了一种高效、精准的跨视角地理定位（CVGL）方法PFED，兼具高准确率和低推理开销，适用于无人机在无GNSS环境下的实时定位任务。


<details>
  <summary>Details</summary>
Motivation: 当前CVGL方法虽然准确，但依赖于多分支和复杂特征提取，使得在边缘设备运行时推理资源消耗极大，难以满足实时应用需求。作者旨在降低运算和资源消耗，同时保持甚至提升CVGL的精度，以推动无人机实际应用。

Method: 提出了Precision-Focused Efficient Design（PFED）框架，核心包括两部分：一，训练阶段引入分层蒸馏（HD-CVGL）与不确定性预测对齐（UAPA），高效蒸馏关键信息并解决数据不均衡；二，推理阶段用多视角精炼模块（MRM）基于互信息过滤冗余样本，高效利用多视角信息。

Result: PFED在University-1652等数据集上实现了97.15% Recall@1的业界最佳准确率，并在FLOPs和运行速度上分别比以往SOTA方法高效5倍和3倍。在AGX Orin边缘设备上推理速度达251.5 FPS，展现出了实际部署的可行性和优越性能。

Conclusion: PFED框架有效缓解了现有CVGL系统推理资源消耗大的痛点，在保证或者提升定位精度的同时，大幅提高了推理效率，非常适合在实际边缘设备和实时无人机场景中应用。

Abstract: Cross-view geo-localization (CVGL) enables UAV localization by matching
aerial images to geo-tagged satellite databases, which is critical for
autonomous navigation in GNSS-denied environments. However, existing methods
rely on resource-intensive fine-grained feature extraction and alignment, where
multiple branches and modules significantly increase inference costs, limiting
their deployment on edge devices. We propose Precision-Focused Efficient Design
(PFED), a resource-efficient framework combining hierarchical knowledge
transfer and multi-view representation refinement. This innovative method
comprises two key components: 1) During training, Hierarchical Distillation
paradigm for fast and accurate CVGL (HD-CVGL), coupled with Uncertainty-Aware
Prediction Alignment (UAPA) to distill essential information and mitigate the
data imbalance without incurring additional inference overhead. 2) During
inference, an efficient Multi-view Refinement Module (MRM) leverages mutual
information to filter redundant samples and effectively utilize the multi-view
data. Extensive experiments show that PFED achieves state-of-the-art
performance in both accuracy and efficiency, reaching 97.15\% Recall@1 on
University-1652 while being over $5 \times$ more efficient in FLOPs and $3
\times$ faster than previous top methods. Furthermore, PFED runs at 251.5 FPS
on the AGX Orin edge device, demonstrating its practical viability for
real-time UAV applications. The project is available at
https://github.com/SkyEyeLoc/PFED

</details>


### [111] [PSScreen V2: Partially Supervised Multiple Retinal Disease Screening](https://arxiv.org/abs/2510.22589)
*Boyi Zheng,Yalin Zheng,Hrvoje Bogunović,Qing Liu*

Main category: cs.CV

TL;DR: 本文提出了PSScreen V2框架，可在多个部分标注、分布不同的眼底图像数据集中进行视网膜疾病筛查，实现了强大的跨域泛化能力和最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖于全标注或单一领域的数据集，无法很好地应对部分标签缺失与领域分布迁移带来的挑战，实际应用中多源数据往往很难全部标注且存在域差异。

Method: PSScreen V2采用三分支结构，包括一个教师网络和两个学生网络。教师分支利用弱增强图像生成伪标签，以弥补标签缺失。两个学生分支分别引入低频丢弃（LF-Dropout）与低频不确定性（LF-Uncert）策略以增强领域鲁棒性和捕获域变异。其中LF-Dropout随机去除域相关的低频成分，LF-Uncert通过对低频统计量生成高斯扰动建模域间变异。

Result: 在多个眼底数据集的域内及域外测试任务中，PSScreen V2表现优异，达到最新水平。兼容性测试显示其能适配如DINOv2等不同backbone，并在胸部X光数据集上也取得良好成绩，表现出较强的通用性。

Conclusion: PSScreen V2能够有效利用部分标注、不同分布的数据进行多疾病筛查，提升了领域泛化能力，并具备较高的适配性和实际应用潜力。

Abstract: In this work, we propose PSScreen V2, a partially supervised self-training
framework for multiple retinal disease screening. Unlike previous methods that
rely on fully labelled or single-domain datasets, PSScreen V2 is designed to
learn from multiple partially labelled datasets with different distributions,
addressing both label absence and domain shift challenges. To this end,
PSScreen V2 adopts a three-branch architecture with one teacher and two student
networks. The teacher branch generates pseudo labels from weakly augmented
images to address missing labels, while the two student branches introduce
novel feature augmentation strategies: Low-Frequency Dropout (LF-Dropout),
which enhances domain robustness by randomly discarding domain-related
low-frequency components, and Low-Frequency Uncertainty (LF-Uncert), which
estimates uncertain domain variability via adversarially learned Gaussian
perturbations of low-frequency statistics. Extensive experiments on multiple
in-domain and out-of-domain fundus datasets demonstrate that PSScreen V2
achieves state-of-the-art performance and superior domain generalization
ability. Furthermore, compatibility tests with diverse backbones, including the
vision foundation model DINOv2, as well as evaluations on chest X-ray datasets,
highlight the universality and adaptability of the proposed framework. The
codes are available at https://github.com/boyiZheng99/PSScreen_V2.

</details>


### [112] [Projection Embedded Diffusion Bridge for CT Reconstruction from Incomplete Data](https://arxiv.org/abs/2510.22605)
*Yuang Wang,Pengfei Jin,Siyeop Yoon,Matthew Tivnan,Shaoyang Zhang,Li Zhang,Quanzheng Li,Zhiqiang Chen,Dufan Wu*

Main category: cs.CV

TL;DR: 本文提出了一种用于恢复不完整数据下CT图像的高效扩散桥模型PEDB，实现了更佳的数据一致性，并在多种场景下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前CT重建在不完整投影数据情况下面临病态问题，虽然扩散模型有提升但数据一致性仍未被充分挖掘，亟需方法提升重建准确性与细节还原。

Method: 提出了Projection Embedded Diffusion Bridge (PEDB)方法：在逆SDE采样过程中，将投影数据嵌入score函数，实现采样时对重建图像与观测投影数据的显式条件约束，增强数据一致性。同时提出一个参数调控逆过程随机性，并设计离散化方案减弱误差。

Result: PEDB在三种类型的不完整投影（稀疏视角、有限角度、截断投影）CT重建任务中，均显著优于当前最先进的扩散桥模型，并在标准、有噪声及领域偏移评测下获得更佳表现。

Conclusion: PEDB模型通过融合投影数据与扩散过程，有效增强重建的一致性和细节恢复，推动了不完整数据CT重建领域的方法进步。

Abstract: Reconstructing CT images from incomplete projection data remains challenging
due to the ill-posed nature of the problem. Diffusion bridge models have
recently shown promise in restoring clean images from their corresponding
Filtered Back Projection (FBP) reconstructions, but incorporating data
consistency into these models remains largely underexplored. Incorporating data
consistency can improve reconstruction fidelity by aligning the reconstructed
image with the observed projection data, and can enhance detail recovery by
integrating structural information contained in the projections. In this work,
we propose the Projection Embedded Diffusion Bridge (PEDB). PEDB introduces a
novel reverse stochastic differential equation (SDE) to sample from the
distribution of clean images conditioned on both the FBP reconstruction and the
incomplete projection data. By explicitly conditioning on the projection data
in sampling the clean images, PEDB naturally incorporates data consistency. We
embed the projection data into the score function of the reverse SDE. Under
certain assumptions, we derive a tractable expression for the posterior score.
In addition, we introduce a free parameter to control the level of
stochasticity in the reverse process. We also design a discretization scheme
for the reverse SDE to mitigate discretization error. Extensive experiments
demonstrate that PEDB achieves strong performance in CT reconstruction from
three types of incomplete data, including sparse-view, limited-angle, and
truncated projections. For each of these types, PEDB outperforms evaluated
state-of-the-art diffusion bridge models across standard, noisy, and
domain-shift evaluations.

</details>


### [113] [SWAN: Self-supervised Wavelet Neural Network for Hyperspectral Image Unmixing](https://arxiv.org/abs/2510.22607)
*Yassh Ramchandani,Vijayashekhar S S,Jignesh S. Bhatt*

Main category: cs.CV

TL;DR: 本文提出自监督三阶段小波神经网络（SWAN），实现高光谱影像的端元与丰度联合估计，展现比现有方法更优的分解和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 实际高光谱影像的端元与丰度分解极为关键，但人工标注代价大、真实端元难以获取；主流方法常需监督信息或物理先验，限制其应用。提升无监督/自监督环境下的分解效果和泛化力十分必要。

Method: 方法包括三阶段：1）将高光谱图像扩展到双正交小波基空间，形成稀疏多尺度表征；2）SWANencoder将小波系数编码到紧凑潜变量空间；3）SWANdecoder据潜表征重建小波系数；4）SWANforward学习影像物理机制。整体三阶段联合损失在影像采集域定义，无需标签，实现自监督优化。模型还结合Adam、Dropout、Sigmoid和核正则化提升稳健性和空间细节保留。

Result: 在两组合成数据和三组真实高光谱数据集上，与多种最先进神经网络解混方法对比，SWAN在定性、定量和消融实验均表现出更强的分解准确性、自监督能力及参数紧凑性。

Conclusion: SWAN能在无标签下实现兼具精度和泛化力的端元与丰度解混，为高光谱影像实际解混场景提供了高效实用的新途径。

Abstract: In this article, we present SWAN: a three-stage, self-supervised wavelet
neural network for joint estimation of endmembers and abundances from
hyperspectral imagery. The contiguous and overlapping hyperspectral band images
are first expanded to Biorthogonal wavelet basis space that provides sparse,
distributed, and multi-scale representations. The idea is to exploit latent
symmetries from thus obtained invariant and covariant features using a
self-supervised learning paradigm. The first stage, SWANencoder maps the input
wavelet coefficients to a compact lower-dimensional latent space. The second
stage, SWANdecoder uses the derived latent representation to reconstruct the
input wavelet coefficients. Interestingly, the third stage SWANforward learns
the underlying physics of the hyperspectral image. A three-stage combined loss
function is formulated in the image acquisition domain that eliminates the need
for ground truth and enables self-supervised training. Adam is employed for
optimizing the proposed loss function, while Sigmoid with a dropout of 0.3 is
incorporated to avoid possible overfitting. Kernel regularizers bound the
magnitudes and preserve spatial variations in the estimated endmember
coefficients. The output of SWANencoder represents estimated abundance maps
during inference, while weights of SWANdecoder are retrieved to extract
endmembers. Experiments are conducted on two benchmark synthetic data sets with
different signal-to-noise ratios as well as on three real benchmark
hyperspectral data sets while comparing the results with several
state-of-the-art neural network-based unmixing methods. The qualitative,
quantitative, and ablation results show performance enhancement by learning a
resilient unmixing function as well as promoting self-supervision and compact
network parameters for practical applications.

</details>


### [114] [Cross-Species Transfer Learning in Agricultural AI: Evaluating ZebraPose Adaptation for Dairy Cattle Pose Estimation](https://arxiv.org/abs/2510.22618)
*Mackenzie Tapp,Sibi Chakravarthy Parivendan,Kashfia Sailunaz,Suresh Neethirajan*

Main category: cs.CV

TL;DR: 本文研究了跨物种迁移学习在牲畜姿态估计中的潜力与局限，评估了将基于视觉Transformer模型ZebraPose由合成斑马图像迁移到实际奶牛牧场环境的效果。实验证明模型虽在同分布数据上表现良好，但对新环境泛化能力不足，说明现有合成到真实域的差异阻碍了AI在农业领域的可靠应用。


<details>
  <summary>Details</summary>
Motivation: 动物姿态估计对理解其行为和福利至关重要，但农业领域，尤其是奶牛的标注数据非常稀缺。研究者希望通过跨物种迁移学习，从已有的斑马合成数据利用机器学习模型，缓解数据不足问题，为实际牧场环境自动动物监测提供技术支撑。

Method: 采用基于视觉Transformer的ZebraPose模型，该模型原本在合成斑马图像数据上训练。本文针对27个关键点的检测任务，将其适配于奶牛，并用三个数据集配置进行测试：现场自建奶牛数据集（375张图片）、APT-36K动物姿态基准数据集子集及二者组合，系统评估模型在不同环境下的准确率与泛化能力。

Result: 在同分布数据上，组合模型表现良好（AP=0.86，AR=0.87，PCK 0.5=0.869）；但在未见过的牧场和牛群数据上泛化能力明显下降。结果表明，尽管形态相似，但跨域迁移在现实环境中受合成与真实域间差异影响显著，当前模型难以适用多样化场景。

Conclusion: 本研究揭示了合成到真实农牧业环境中的域间差异是AI部署的主要障碍，仅有物种形态相似无法保证模型泛化。应加强农场级真实性、跨环境鲁棒性和公开基准数据集的建设，推动面向农业的AI系统落地和可信应用。

Abstract: Pose estimation serves as a cornerstone of computer vision for understanding
animal posture, behavior, and welfare. Yet, agricultural applications remain
constrained by the scarcity of large, annotated datasets for livestock,
especially dairy cattle. This study evaluates the potential and limitations of
cross-species transfer learning by adapting ZebraPose - a vision
transformer-based model trained on synthetic zebra imagery - for 27-keypoint
detection in dairy cows under real barn conditions. Using three configurations
- a custom on-farm dataset (375 images, Sussex, New Brunswick, Canada), a
subset of the APT-36K benchmark dataset, and their combination, we
systematically assessed model accuracy and generalization across environments.
While the combined model achieved promising performance (AP = 0.86, AR = 0.87,
PCK 0.5 = 0.869) on in-distribution data, substantial generalization failures
occurred when applied to unseen barns and cow populations. These findings
expose the synthetic-to-real domain gap as a major obstacle to agricultural AI
deployment and emphasize that morphological similarity between species is
insufficient for cross-domain transfer. The study provides practical insights
into dataset diversity, environmental variability, and computational
constraints that influence real-world deployment of livestock monitoring
systems. We conclude with a call for agriculture-first AI design, prioritizing
farm-level realism, cross-environment robustness, and open benchmark datasets
to advance trustworthy and scalable animal-centric technologies.

</details>


### [115] [Robust Atypical Mitosis Classification with DenseNet121: Stain-Aware Augmentation and Hybrid Loss for Domain Generalization](https://arxiv.org/abs/2510.22630)
*Adinath Dukre,Ankan Deria,Yutong Xie,Imran Razzak*

Main category: cs.CV

TL;DR: 本文提出了一种基于DenseNet-121的分子分裂分类框架，解决病理图像中非典型分裂识别的难题，在多域测试下取得了良好的泛化能力和分类性能。


<details>
  <summary>Details</summary>
Motivation: 非典型有丝分裂是肿瘤侵袭性的关键生物标记，但由于类别失衡和不同成像领域的变化，自动识别极具挑战。因此急需开发出鲁棒且能泛化的自动识别方法。

Method: 方法以DenseNet-121为主干网络，结合染色感知的数据增强（Macenko），几何及强度变换，以及加权采样策略。损失函数采用类别加权的二元交叉熵与focal loss混合。训练过程采用AdamW优化器。在多种扫描仪和染色策略下进行评估。

Result: 模型在官方测试集上取得了85.0%的平衡准确率，AUROC为0.927，敏感性89.2%，特异性80.9%，显示出了在不同成像域下良好、稳定的泛化和分类效果。

Conclusion: DenseNet-121结合染色感知增强和失衡自适应损失目标，能实现对非典型有丝分裂的鲁棒、可推广分类，适用于实际计算病理工作流中。

Abstract: Atypical mitotic figures are important biomarkers of tumor aggressiveness in
histopathology, yet reliable recognition remains challenging due to severe
class imbalance and variability across imaging domains. We present a
DenseNet-121-based framework tailored for atypical mitosis classification in
the MIDOG 2025 (Track 2) setting. Our method integrates stain-aware
augmentation (Macenko), geometric and intensity transformations, and
imbalance-aware learning via weighted sampling with a hybrid objective
combining class-weighted binary cross-entropy and focal loss. Trained
end-to-end with AdamW and evaluated across multiple independent domains, the
model demonstrates strong generalization under scanner and staining shifts,
achieving balanced accuracy 85.0%, AUROC 0.927, sensitivity 89.2%, and
specificity 80.9% on the official test set. These results indicate that
combining DenseNet-121 with stain-aware augmentation and imbalance-adaptive
objectives yields a robust, domain-generalizable framework for atypical mitosis
classification suitable for real-world computational pathology workflows.

</details>


### [116] [A Critical Study on Tea Leaf Disease Detection using Deep Learning Techniques](https://arxiv.org/abs/2510.22647)
*Nabajyoti Borah,Raju Moni Borah,Bandan Boruah,Purnendu Bikash Acharjee,Sajal Saha,Ripjyoti Hazarika*

Main category: cs.CV

TL;DR: 本文利用深度学习方法，实现了对三种茶叶病害的识别与病斑区域检测，并评估了多种模型性能。


<details>
  <summary>Details</summary>
Motivation: 茶叶病害会导致农业损失，及时准确地识别病害类型及受损区域对农户生产具有重要意义。因此，提出基于深度学习的自动化疾病识别方法以辅助病害管理。

Method: 采用SSD MobileNet V2和Faster R-CNN ResNet50 V1两种目标检测模型识别三类茶叶病害（红锈、Helopeltis、红蜘蛛螨），并用Mask R-CNN进行实例分割，结合自定义方法计算叶片病损面积。

Result: SSD MobileNet V2模型在IOU 0.5:0.95下精度为0.209，召回率为0.02，mAP为20.9%；Faster R-CNN ResNet50 V1模型精度为0.252，召回率为0.044，mAP为25%，性能优于SSD；Mask R-CNN可用于病斑区域分割。

Conclusion: 深度学习模型能有效识别茶叶主要病害及其受损区域，Faster R-CNN ResNet50 V1效果优于SSD MobileNet V2，为农业自动化病害监测提供了有效手段。

Abstract: The proposed solution is Deep Learning Technique that will be able classify
three types of tea leaves diseases from which two diseases are caused by the
pests and one due to pathogens (infectious organisms) and environmental
conditions and also show the area damaged by a disease in leaves. Namely Red
Rust, Helopeltis and Red spider mite respectively. In this paper we have
evaluated two models namely SSD MobileNet V2 and Faster R-CNN ResNet50 V1 for
the object detection. The SSD MobileNet V2 gave precision of 0.209 for IOU
range of 0.50:0.95 with recall of 0.02 on IOU 0.50:0.95 and final mAP of 20.9%.
While Faster R-CNN ResNet50 V1 has precision of 0.252 on IOU range of 0.50:0.95
and recall of 0.044 on IOU of 0.50:0.95 with a mAP of 25%, which is better than
SSD. Also used Mask R-CNN for Object Instance Segmentation where we have
implemented our custom method to calculate the damaged diseased portion of
leaves. Keywords: Tea Leaf Disease, Deep Learning, Red Rust, Helopeltis and Red
Spider Mite, SSD MobileNet V2, Faster R-CNN ResNet50 V1 and Mask RCNN.

</details>


### [117] [Self-Attention Decomposition For Training Free Diffusion Editing](https://arxiv.org/abs/2510.22650)
*Tharun Anand,Mohammad Hassan Vali,Arno Solin*

Main category: cs.CV

TL;DR: 本论文提出了一种直接从扩散模型的预训练参数中提取可解释编辑方向的新方法，无需额外数据或微调，可高效进行语义编辑。通过分析自注意力权重矩阵的特征向量，能够获得稳健且可解释的语义编辑能力，且编辑速度比现有方法提升60%。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型虽然生成图像质量极高，但对输出内容的精确控制和语义编辑仍较为困难。以往方法需要大量采样或额外训练网络，效率低下。为提升模型可控性且提高效率，亟需一种无需额外数据和训练的新机制。

Method: 作者通过解析扩散模型自注意力权重矩阵，计算其特征向量（eigenvectors），直接获得对应于不同语义属性的可解释方向，用于图像编辑，无需额外训练或数据。

Result: 实验证明该方法无需微调或额外数据即可在多个数据集上实现高质量的语义编辑，编辑时间较现有标杆方法减少60%。

Conclusion: 该方法显著提升了扩散模型的可控性和编辑效率，是高效/可解释语义编辑的新途径，也为理解扩散模型潜变量结构提供了新见解。

Abstract: Diffusion models achieve remarkable fidelity in image synthesis, yet precise
control over their outputs for targeted editing remains challenging. A key step
toward controllability is to identify interpretable directions in the model's
latent representations that correspond to semantic attributes. Existing
approaches for finding interpretable directions typically rely on sampling
large sets of images or training auxiliary networks, which limits efficiency.
We propose an analytical method that derives semantic editing directions
directly from the pretrained parameters of diffusion models, requiring neither
additional data nor fine-tuning. Our insight is that self-attention weight
matrices encode rich structural information about the data distribution learned
during training. By computing the eigenvectors of these weight matrices, we
obtain robust and interpretable editing directions. Experiments demonstrate
that our method produces high-quality edits across multiple datasets while
reducing editing time significantly by 60% over current benchmarks.

</details>


### [118] [SARCLIP: A Vision Language Foundation Model for Semantic Understanding and Target Recognition in SAR Imagery](https://arxiv.org/abs/2510.22665)
*Qiwei Ma,Zhiyu Wang,Wang Liu,Xukun Lu,Bin Deng,Puhong Duan,Xudong Kang,Shutao Li*

Main category: cs.CV

TL;DR: 本文提出了SARCLIP，这是首个专为合成孔径雷达(SAR)领域设计的视觉-语言基础模型，使用了百万级图文对数据集SARCLIP-1M，实现了SAR图像与文本的有效对齐，提高了零样本识别和语义理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有SAR自监督学习和掩码图像建模方法主要关注低层视觉特征，忽视了SAR图像中的多模态对齐和零样本目标识别能力，因此亟需一种能处理视觉与文本语义对齐的基础模型。

Method: 作者构建了包含百万级图像-文本对的数据集SARCLIP-1M，并提出基于对比视觉语言学习的SARCLIP模型。通过迁移学习策略，将视觉语言模型扩展到SAR领域，实现了图像和文本的对齐训练。

Result: SARCLIP在图文检索和零样本分类任务上进行了大量实验，表现出在特征提取和语义理解上的显著提升，明显优于现有主流基础模型。

Conclusion: SARCLIP模型在推动SAR图像的语义理解、跨模态对齐和零样本识别方面取得了突破，为SAR领域的多模态任务提供了有力的基础模型。相关代码和数据集将会公开。

Abstract: Synthetic Aperture Radar (SAR) has emerged as a crucial imaging modality due
to its all-weather capabilities. While recent advancements in self-supervised
learning and Masked Image Modeling (MIM) have paved the way for SAR foundation
models, these approaches primarily focus on low-level visual features, often
overlooking multimodal alignment and zero-shot target recognition within SAR
imagery. To address this limitation, we construct SARCLIP-1M, a large-scale
vision language dataset comprising over one million text-image pairs aggregated
from existing datasets. We further introduce SARCLIP, the first vision language
foundation model tailored for the SAR domain. Our SARCLIP model is trained
using a contrastive vision language learning approach by domain transferring
strategy, enabling it to bridge the gap between SAR imagery and textual
descriptions. Extensive experiments on image-text retrieval and zero-shot
classification tasks demonstrate the superior performance of SARCLIP in feature
extraction and interpretation, significantly outperforming state-of-the-art
foundation models and advancing the semantic understanding of SAR imagery. The
code and datasets will be released soon.

</details>


### [119] [LVD-GS: Gaussian Splatting SLAM for Dynamic Scenes via Hierarchical Explicit-Implicit Representation Collaboration Rendering](https://arxiv.org/abs/2510.22669)
*Wenkai Zhu,Xu Li,Qimin Xu,Benwu Wang,Kun Wei,Yiming Peng,Zihang Wang*

Main category: cs.CV

TL;DR: LVD-GS是一种结合LiDAR与视觉信息的3D Gaussian Splatting SLAM系统，通过多模态协同和动态图建模，实现高精度、抗尺度漂移的户外大场景重建。


<details>
  <summary>Details</summary>
Motivation: 现有3D Gaussian Splatting SLAM大多采用单一表征方式，面对大规模动态户外场景时，易出现累计位姿误差和尺度不确定问题。作者旨在解决这些局限，提高SLAM鲁棒性与准确性。

Method: 提出LVD-GS系统，将LiDAR和视觉信息融合，借鉴人类链式思维，设计分层协同表征模块以优化建图并抑制尺度漂移。同时，联合动态图建模模块，利用深度特征的不确定性指导、结合显式分割和隐式约束，生成高精动态图遮罩，有效剔除动态物体干扰。

Result: 在KITTI、nuScenes及自采数据集上，所提方法在建图精度和鲁棒性等各项评测指标上均优于现有主流方法，达到当前最佳性能。

Conclusion: 通过多模态信息协同和动态图处理，这一方法突破了传统SLAM系统在复杂户外动态环境中的局限，表现出更强的重建能力和适应性。

Abstract: 3D Gaussian Splatting SLAM has emerged as a widely used technique for
high-fidelity mapping in spatial intelligence. However, existing methods often
rely on a single representation scheme, which limits their performance in
large-scale dynamic outdoor scenes and leads to cumulative pose errors and
scale ambiguity. To address these challenges, we propose \textbf{LVD-GS}, a
novel LiDAR-Visual 3D Gaussian Splatting SLAM system. Motivated by the human
chain-of-thought process for information seeking, we introduce a hierarchical
collaborative representation module that facilitates mutual reinforcement for
mapping optimization, effectively mitigating scale drift and enhancing
reconstruction robustness. Furthermore, to effectively eliminate the influence
of dynamic objects, we propose a joint dynamic modeling module that generates
fine-grained dynamic masks by fusing open-world segmentation with implicit
residual constraints, guided by uncertainty estimates from DINO-Depth features.
Extensive evaluations on KITTI, nuScenes, and self-collected datasets
demonstrate that our approach achieves state-of-the-art performance compared to
existing methods.

</details>


### [120] [Alias-Free ViT: Fractional Shift Invariance via Linear Attention](https://arxiv.org/abs/2510.22673)
*Hagay Michaeli,Daniel Soudry*

Main category: cs.CV

TL;DR: 本文提出了一种Alias-Free ViT模型，通过消除混叠效应提高ViT的平移不变性，实现对图像微小平移更鲁棒的特性，并在图像分类任务中表现出不错的效果，具备较强的抗对抗平移能力。


<details>
  <summary>Details</summary>
Motivation: 虽然Vision Transformers已被广泛应用于视觉任务，但相比卷积神经网络，其缺乏平移不变等归纳偏置，导致对图像的小幅度平移比较敏感，限制了潜在性能。而传统卷积网络通过某种抗混叠方法也可提升平移鲁棒性，启发了对ViT提升平移不变性的探索。

Method: 1) 在ViT中采用无混叠采样和非线性激活，减少因下采样和非线性层产生的混叠现象；2) 设计了线性交叉协方差注意力机制，对整数和平分平移都具备平移等变性，从而获取全局的平移不变表示。

Result: 所提出方法在图像分类任务中，模型性能与主流ViT持平甚至略优，并且在针对图像微小平移（对抗平移）场景下，表现出更强的鲁棒性，超越了同等规模的其他模型。

Conclusion: Alias-Free ViT不仅能够保持较高的图像识别性能，还有效提升了平移鲁棒性，有望进一步推动ViT在实际视觉任务中的应用。

Abstract: Transformers have emerged as a competitive alternative to convnets in vision
tasks, yet they lack the architectural inductive bias of convnets, which may
hinder their potential performance. Specifically, Vision Transformers (ViTs)
are not translation-invariant and are more sensitive to minor image
translations than standard convnets. Previous studies have shown, however, that
convnets are also not perfectly shift-invariant, due to aliasing in
downsampling and nonlinear layers. Consequently, anti-aliasing approaches have
been proposed to certify convnets' translation robustness. Building on this
line of work, we propose an Alias-Free ViT, which combines two main components.
First, it uses alias-free downsampling and nonlinearities. Second, it uses
linear cross-covariance attention that is shift-equivariant to both integer and
fractional translations, enabling a shift-invariant global representation. Our
model maintains competitive performance in image classification and outperforms
similar-sized models in terms of robustness to adversarial translations.

</details>


### [121] [DAMap: Distance-aware MapNet for High Quality HD Map Construction](https://arxiv.org/abs/2510.22675)
*Jinpeng Dong,Chen Li,Yutong Lin,Jingwen Fu,Sanping Zhou,Nanning Zheng*

Main category: cs.CV

TL;DR: 本文提出了一种新的高精度地图（HD Map）要素预测方法DAMap，专门解决现有方法在高质量预测中由于任务错配导致的性能瓶颈。


<details>
  <summary>Details</summary>
Motivation: 高精度地图要素的高质量预测对自动驾驶的安全至关重要，但目前方法因任务标签不当和任务特征提取不佳而导致预测不准，需要针对这些缺陷提出新的解决方案。

Method: 提出了DAMap方法，包含三大核心组成：1）距离感知的Focal Loss（DAFL），为一对多匹配样本分配合适的分类标签；2）任务调制的可变形注意力机制（TMDA），提取有判别力的任务特定特征；3）混合损失方案（HLS），更好地利用DAFL的优势。

Result: 在NuScenes和Argoverse2基准上进行大量实验，DAMap在多种指标、基线模型、分割方式、骨干网络及训练计划下都取得了持续性能提升。

Conclusion: DAMap有效克服了任务错配与特征提取不充分的问题，在多个公开数据集上表现优异，对高质量HD地图要素预测有重要推动作用。

Abstract: Predicting High-definition (HD) map elements with high quality (high
classification and localization scores) is crucial to the safety of autonomous
driving vehicles. However, current methods perform poorly in high quality
predictions due to inherent task misalignment. Two main factors are responsible
for misalignment: 1) inappropriate task labels due to one-to-many matching
queries sharing the same labels, and 2) sub-optimal task features due to
task-shared sampling mechanism. In this paper, we reveal two inherent defects
in current methods and develop a novel HD map construction method named DAMap
to address these problems. Specifically, DAMap consists of three components:
Distance-aware Focal Loss (DAFL), Hybrid Loss Scheme (HLS), and Task Modulated
Deformable Attention (TMDA). The DAFL is introduced to assign appropriate
classification labels for one-to-many matching samples. The TMDA is proposed to
obtain discriminative task-specific features. Furthermore, the HLS is proposed
to better utilize the advantages of the DAFL. We perform extensive experiments
and consistently achieve performance improvement on the NuScenes and Argoverse2
benchmarks under different metrics, baselines, splits, backbones, and
schedules. Code will be available at https://github.com/jpdong-xjtu/DAMap.

</details>


### [122] [Estimation of Fireproof Structure Class and Construction Year for Disaster Risk Assessment](https://arxiv.org/abs/2510.22683)
*Hibiki Ayabe,Kazushi Okamoto,Koki Karube,Atsushi Shibata,Kei Harada*

Main category: cs.CV

TL;DR: 该论文提出利用多任务学习模型，通过建筑外观图像预测建筑的建成年份、结构类型和物业类型，进而推断出其防火等级。实验结果显示该方法在多项任务上准确率较高，具有实际应用前景。


<details>
  <summary>Details</summary>
Motivation: 在日本，建筑的防火等级对灾害风险评估和保险定价至关重要，但二手房市场内很多关键建筑元数据经常缺失或过时，影响实际应用和决策。

Method: 作者针对该问题，设计了一个多任务学习模型，能够从住宅外观图像同时预测建筑的建成年份、结构、物业类型，并通过官方规则推断防火等级。模型在大规模日本住宅图像数据集上进行了严格的训练、筛选和去重。

Result: 模型在建成年份预测和各类别结构分类上取得了较高的准确率，且对于类别不平衡的数据表现出了良好的健壮性。定性分析表明，模型能有效捕捉与建筑年代和材料相关的视觉线索。

Conclusion: 该研究证明，基于图像的防火等级和风险预测方案具有可扩展性和可解释性，在保险、城市规划和灾难准备领域有广泛应用潜力。

Abstract: Structural fireproof classification is vital for disaster risk assessment and
insurance pricing in Japan. However, key building metadata such as construction
year and structure type are often missing or outdated, particularly in the
second-hand housing market. This study proposes a multi-task learning model
that predicts these attributes from facade images. The model jointly estimates
the construction year, building structure, and property type, from which the
structural fireproof class - defined as H (non-fireproof), T (semi-fireproof),
or M (fireproof) - is derived via a rule-based mapping based on official
insurance criteria. We trained and evaluated the model using a large-scale
dataset of Japanese residential images, applying rigorous filtering and
deduplication. The model achieved high accuracy in construction-year regression
and robust classification across imbalanced categories. Qualitative analyses
show that it captures visual cues related to building age and materials. Our
approach demonstrates the feasibility of scalable, interpretable, image-based
risk-profiling systems, offering potential applications in insurance, urban
planning, and disaster preparedness.

</details>


### [123] [RoboSVG: A Unified Framework for Interactive SVG Generation with Multi-modal Guidance](https://arxiv.org/abs/2510.22684)
*Jiuniu Wang,Gongjie Zhang,Quanhao Qian,Junlong Gao,Deli Zhao,Ran Xu*

Main category: cs.CV

TL;DR: 本文提出了RoboSVG，一个多模态框架，可以根据文本、图像及数值等多种信号生成高质量、可交互的SVG矢量图。作者还构建了包含100万个配对样本的大规模数据集RoboDraw，支持多个SVG生成相关任务。实验显示方法在各任务上均取得了最佳效果。


<details>
  <summary>Details</summary>
Motivation: SVG在数字设计和机器人控制中应用广泛，目前缺乏统一框架能够跨模态生成高质量、可交互SVG，对支持更多应用有需求。

Method: RoboSVG框架首先对输入请求（如文本、图片、部分SVG等）进行多模态引导，然后利用专门的生成模块合成候选SVG，最后在数值引导下精炼输出。配套的RoboDraw数据集同步提供了大规模多模态生成样本。

Result: RoboSVG在Text-to-SVG、Image-to-SVG、PartialSVG-to-SVG等四项SVG生成任务上，在查询契合度和视觉保真度方面均明显超越现有方法。

Conclusion: RoboSVG展示了统一多模态交互生成SVG的强大能力，配合RoboDraw数据集推动SVG生成技术进步，为复杂数字设计和机器人相关任务奠定新基础。

Abstract: Scalable Vector Graphics (SVGs) are fundamental to digital design and robot
control, encoding not only visual structure but also motion paths in
interactive drawings. In this work, we introduce RoboSVG, a unified multimodal
framework for generating interactive SVGs guided by textual, visual, and
numerical signals. Given an input query, the RoboSVG model first produces
multimodal guidance, then synthesizes candidate SVGs through dedicated
generation modules, and finally refines them under numerical guidance to yield
high-quality outputs. To support this framework, we construct RoboDraw, a
large-scale dataset of one million examples, each pairing an SVG generation
condition (e.g., text, image, and partial SVG) with its corresponding
ground-truth SVG code. RoboDraw dataset enables systematic study of four tasks,
including basic generation (Text-to-SVG, Image-to-SVG) and interactive
generation (PartialSVG-to-SVG, PartialImage-to-SVG). Extensive experiments
demonstrate that RoboSVG achieves superior query compliance and visual fidelity
across tasks, establishing a new state of the art in versatile SVG generation.
The dataset and source code of this project will be publicly available soon.

</details>


### [124] [VADTree: Explainable Training-Free Video Anomaly Detection via Hierarchical Granularity-Aware Tree](https://arxiv.org/abs/2510.22693)
*Wenlong Li,Yifei Xu,Yuan Rao,Zhenhua Wang,Shuiguang Deng*

Main category: cs.CV

TL;DR: 提出了一种用于视频异常检测的新方法VADTree，采用分层细粒度树结构灵活采样，实现无训练下异常检测性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有视频异常检测方法依赖大量标注数据且难以解释异常来源，无需训练的方法虽借助大模型知识但对异常时长变化适应性差，因此需要更灵活高效的采样策略。

Method: 提出了VADTree方法，利用分层细粒度树（HGTree）结构进行灵活采样。首先用预训练的通用事件边界检测模型确定视频的事件节点，根据置信度进行粗细粒度分层及冗余去除，构建HGTree。再将多维先验信息输入视觉语言模型（VLM）提升节点异常感知，最后结合大语言模型（LLMs）进行节点异常推理，通过节点相关性方法融合多粒度得分。

Result: 在三个具有挑战性的数据集上，VADTree在无需训练的情况下取得了最新最优性能，并大幅减少了视频片段的采样数量。

Conclusion: VADTree有效突破了训练自由异常检测的泛化不足和采样效率的问题，为视频异常检测提供了更强大与高效的解决方案。

Abstract: Video anomaly detection (VAD) focuses on identifying anomalies in videos.
Supervised methods demand substantial in-domain training data and fail to
deliver clear explanations for anomalies. In contrast, training-free methods
leverage the knowledge reserves and language interactivity of large pre-trained
models to detect anomalies. However, the current fixed-length temporal window
sampling approaches struggle to accurately capture anomalies with varying
temporal spans. Therefore, we propose VADTree that utilizes a Hierarchical
Granularityaware Tree (HGTree) structure for flexible sampling in VAD. VADTree
leverages the knowledge embedded in a pre-trained Generic Event Boundary
Detection (GEBD) model to characterize potential anomaly event boundaries.
Specifically, VADTree decomposes the video into generic event nodes based on
boundary confidence, and performs adaptive coarse-fine hierarchical structuring
and redundancy removal to construct the HGTree. Then, the multi-dimensional
priors are injected into the visual language models (VLMs) to enhance the
node-wise anomaly perception, and anomaly reasoning for generic event nodes is
achieved via large language models (LLMs). Finally, an inter-cluster node
correlation method is used to integrate the multi-granularity anomaly scores.
Extensive experiments on three challenging datasets demonstrate that VADTree
achieves state-of-the-art performance in training-free settings while
drastically reducing the number of sampled video segments. The code will be
available at https://github.com/wenlongli10/VADTree.

</details>


### [125] [Windsock is Dancing: Adaptive Multimodal Retrieval-Augmented Generation](https://arxiv.org/abs/2510.22694)
*Shu Zhao,Tianyi Shen,Nilesh Ahuja,Omesh Tickoo,Vijaykrishnan Narayanan*

Main category: cs.CV

TL;DR: 本论文提出了一种改进的多模态检索增强生成（MRAG）方法，能更智能地决定何时及如何检索并使用多模态知识，提升生成质量与效率。


<details>
  <summary>Details</summary>
Motivation: 现有MRAG方法存在静态检索策略、不灵活的模态选择和对检索信息的利用率低，导致难以高效、真实和最新地产生响应。亟需更智能的机制以优化检索及利用过程。

Method: 提出了Windsock模块，能根据查询动态决定是否检索及选择哪种模态，减少计算资源消耗并提升响应质量。同时，提出DANCE动态抗噪微调策略，增强模型对检索信息的利用并提升对噪声的鲁棒性。此外，采用自评方法将QA数据集转化为MRAG训练集。

Result: 实验显示，该方法在生成质量上提升了17.07%，检索次数减少了8.95%。

Conclusion: 通过动态检索决策与抗噪训练，不仅提升了多模态大模型的响应质量和效率，还有效降低了计算成本。

Abstract: Multimodal Retrieval-Augmented Generation (MRAG) has emerged as a promising
method to generate factual and up-to-date responses of Multimodal Large
Language Models (MLLMs) by incorporating non-parametric knowledge from external
knowledge bases. However, existing MRAG approaches suffer from static retrieval
strategies, inflexible modality selection, and suboptimal utilization of
retrieved information, leading to three critical challenges: determining when
to retrieve, what modality to incorporate, and how to utilize retrieved
information effectively. To address these challenges, we introduce Windsock, a
query-dependent module making decisions on retrieval necessity and modality
selection, effectively reducing computational overhead and improving response
quality. Additionally, we propose Dynamic Noise-Resistance (DANCE) Instruction
Tuning, an adaptive training strategy that enhances MLLMs' ability to utilize
retrieved information while maintaining robustness against noise. Moreover, we
adopt a self-assessment approach leveraging knowledge within MLLMs to convert
question-answering datasets to MRAG training datasets. Extensive experiments
demonstrate that our proposed method significantly improves the generation
quality by 17.07% while reducing 8.95% retrieval times.

</details>


### [126] [WaveMAE: Wavelet decomposition Masked Auto-Encoder for Remote Sensing](https://arxiv.org/abs/2510.22697)
*Vittorio Bernuzzi,Leonardo Rossi,Tomaso Fontanini,Massimo Bertozzi,Andrea Prati*

Main category: cs.CV

TL;DR: 本文提出了一种新的自监督学习方法WaveMAE，通过小波变换和地理条件位置编码提升多光谱卫星影像分析能力，性能超过现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 遥感领域标注数据稀缺，限制了全监督方法的应用，需要开发能充分利用无标注数据的自监督学习方法，并提升遥感影像的基础模型能力。

Method: 提出WaveMAE模型，将掩码自编码器与多层离散小波变换(DWT)结合，引导编码器学习不同尺度频率的表征；引入地理条件位置编码(GPE)，利用球谐函数结合地理先验，优化表征的空间和语义信息。所有方法均在fMoW-S2数据集上预训练，并在PANGAEA基准上系统评估。

Result: WaveMAE在语义分割和回归等下游任务上，相较已有方法取得显著提升。即便是参数量仅26.4%的轻量模型，也能实现当前最佳性能。

Conclusion: WaveMAE作为针对多光谱遥感影像的基础模型展现出强大且地理信息丰富的自监督预训练潜力，推动了遥感影像分析方法的发展。

Abstract: Self-supervised learning (SSL) has recently emerged as a key strategy for
building foundation models in remote sensing, where the scarcity of annotated
data limits the applicability of fully supervised approaches. In this work, we
introduce WaveMAE, a masked autoencoding framework tailored for multispectral
satellite imagery. Unlike conventional pixel-based reconstruction, WaveMAE
leverages a multi-level Discrete Wavelet Transform (DWT) to disentangle
frequency components and guide the encoder toward learning scale-aware
high-frequency representations. We further propose a Geo-conditioned Positional
Encoding (GPE), which incorporates geographical priors via Spherical Harmonics,
encouraging embeddings that respect both semantic and geospatial structure. To
ensure fairness in evaluation, all methods are pretrained on the same dataset
(fMoW-S2) and systematically evaluated on the diverse downstream tasks of the
PANGAEA benchmark, spanning semantic segmentation, regression, change
detection, and multilabel classification. Extensive experiments demonstrate
that WaveMAE achieves consistent improvements over prior state-of-the-art
approaches, with substantial gains on segmentation and regression benchmarks.
The effectiveness of WaveMAE pretraining is further demonstrated by showing
that even a lightweight variant, containing only 26.4% of the parameters,
achieves state-of-the-art performance. Our results establish WaveMAE as a
strong and geographically informed foundation model for multispectral remote
sensing imagery.

</details>


### [127] [M$^{3}$T2IBench: A Large-Scale Multi-Category, Multi-Instance, Multi-Relation Text-to-Image Benchmark](https://arxiv.org/abs/2510.23020)
*Huixuan Zhang,Xiaojun Wan*

Main category: cs.CV

TL;DR: 本文提出了一个更具挑战性的多实例、多类别、多关系的大规模文本到图像评测基准M$^3$T2IBench及同步新评测指标AlignScore，并提出Revise-Then-Enforce后处理方法来优化图文对齐。


<details>
  <summary>Details</summary>
Motivation: 传统文本到图像的评测多关注简单场景，难以反映复杂提示（如同类别多实例）的真实难度，且既有指标与人工评估相关性不足，因此需要新的基准和评价方法以推进模型进步。

Method: （1）构建了包含多类别、多实例和多种关系的大型数据集M$^3$T2IBench；（2）设计了基于目标检测的AlignScore指标，更贴合人工对齐评价；（3）提出Revise-Then-Enforce训练后处理方法，无需二次训练提升对齐度。

Result: 实验证明主流开源文本到图像模型在该新基准上表现较差；采用所提Revise-Then-Enforce方法后，不同扩散模型在图文对齐上都有所提升。

Conclusion: 当前主流模型在复杂图文对齐场景下仍有较大改进空间，提出的基准和指标可以更好地衡量能力，同时后处理方法为模型性能提升给出了新方向。

Abstract: Text-to-image models are known to struggle with generating images that
perfectly align with textual prompts. Several previous studies have focused on
evaluating image-text alignment in text-to-image generation. However, these
evaluations either address overly simple scenarios, especially overlooking the
difficulty of prompts with multiple different instances belonging to the same
category, or they introduce metrics that do not correlate well with human
evaluation. In this study, we introduce M$^3$T2IBench, a large-scale,
multi-category, multi-instance, multi-relation along with an
object-detection-based evaluation metric, $AlignScore$, which aligns closely
with human evaluation. Our findings reveal that current open-source
text-to-image models perform poorly on this challenging benchmark.
Additionally, we propose the Revise-Then-Enforce approach to enhance image-text
alignment. This training-free post-editing method demonstrates improvements in
image-text alignment across a broad range of diffusion models. \footnote{Our
code and data has been released in supplementary material and will be made
publicly available after the paper is accepted.}

</details>


### [128] [IGGT: Instance-Grounded Geometry Transformer for Semantic 3D Reconstruction](https://arxiv.org/abs/2510.22706)
*Hao Li,Zhengyu Zou,Fangfu Liu,Xuanyang Zhang,Fangzhou Hong,Yukang Cao,Yushi Lan,Manyuan Zhang,Gang Yu,Dingwen Zhang,Ziwei Liu*

Main category: cs.CV

TL;DR: 本文提出了一种统一3D空间重建与实例上下文理解的新型Transformer模型（IGGT），通过创新的数据集和学习策略提升三维场景理解的泛化能力和表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法多将3D几何重建与高层空间理解分割处理，导致在实际下游任务中泛化性和表现有限。此外，通过单纯与语言模型对齐的方法局限于模型能力，不能充分挖掘空间与语义信息的交互。作者希望通过统一建模和新的表示学习策略，改善这一情况。

Method: 提出了InstanceGrounded Geometry Transformer（IGGT），这是一个端到端的大型Transformer模型，能够同时处理空间重建和实例上下文理解。该方法引入3D一致性的对比学习策略，仅使用2D视觉输入，获得融合几何结构和实例语义的统一表示。此外，作者还建立了InsScene-15K大规模数据集，包含高质量RGB图像、位姿、深度图和3D一致性的实例级掩码，通过新颖的数据筛选流程生成。

Result: IGGT能够从2D视觉输入一致地重建3D场景，并明确区分各个物体实例。通过创新表示学习和新数据集的支持，在3D重建和下游理解任务上表现出更好的泛化性和性能。

Conclusion: IGGT实现了3D结构和实例级上下文的深度统一建模，相比现有各自为政的方法更具泛化力。创新的数据集和端到端模型为复杂场景的高效理解提供了新范式，对三维视觉领域具有重要推动作用。

Abstract: Humans naturally perceive the geometric structure and semantic content of a
3D world as intertwined dimensions, enabling coherent and accurate
understanding of complex scenes. However, most prior approaches prioritize
training large geometry models for low-level 3D reconstruction and treat
high-level spatial understanding in isolation, overlooking the crucial
interplay between these two fundamental aspects of 3D-scene analysis, thereby
limiting generalization and leading to poor performance in downstream 3D
understanding tasks. Recent attempts have mitigated this issue by simply
aligning 3D models with specific language models, thus restricting perception
to the aligned model's capacity and limiting adaptability to downstream tasks.
In this paper, we propose InstanceGrounded Geometry Transformer (IGGT), an
end-to-end large unified transformer to unify the knowledge for both spatial
reconstruction and instance-level contextual understanding. Specifically, we
design a 3D-Consistent Contrastive Learning strategy that guides IGGT to encode
a unified representation with geometric structures and instance-grounded
clustering through only 2D visual inputs. This representation supports
consistent lifting of 2D visual inputs into a coherent 3D scene with explicitly
distinct object instances. To facilitate this task, we further construct
InsScene-15K, a large-scale dataset with high-quality RGB images, poses, depth
maps, and 3D-consistent instance-level mask annotations with a novel data
curation pipeline.

</details>


### [129] [UniAIDet: A Unified and Universal Benchmark for AI-Generated Image Content Detection and Localization](https://arxiv.org/abs/2510.23023)
*Huixuan Zhang,Xiaojun Wan*

Main category: cs.CV

TL;DR: 该论文提出了一个统一且全面的AI生成图像检测基准UniAIDet，涵盖多种生成模型和图像类型，包括摄影和艺术图像，对现有检测方法进行了全面评估，并为后续研究建立了基础。


<details>
  <summary>Details</summary>
Motivation: 现有针对AI生成内容的检测方法和基准通常局限在特定模型和图像类别，且忽视了端到端图像编辑和艺术类图像，这导致评估结果缺乏广泛代表性。

Method: 作者构建了UniAIDet基准，覆盖文本生成图像、图像到图像、图像修补、图像编辑及深度伪造等多种模型及多类图片。利用该基准，作者对多种检测方法的泛化能力以及检测与定位之间的关系进行了系统评测和分析。

Result: 通过UniAIDet全面评测，作者回答了泛化能力和检测与定位关系等关键问题。结果显示现有检测方法在多场景和多类别下的表现，并发现了一些局限和改进空间。

Conclusion: UniAIDet基准和对应的分析为AI生成图像检测提供了更完善的评测工具，对未来研究具有重要推动作用。

Abstract: With the rapid proliferation of image generative models, the authenticity of
digital images has become a significant concern. While existing studies have
proposed various methods for detecting AI-generated content, current benchmarks
are limited in their coverage of diverse generative models and image
categories, often overlooking end-to-end image editing and artistic images. To
address these limitations, we introduce UniAIDet, a unified and comprehensive
benchmark that includes both photographic and artistic images. UniAIDet covers
a wide range of generative models, including text-to-image, image-to-image,
image inpainting, image editing, and deepfake models. Using UniAIDet, we
conduct a comprehensive evaluation of various detection methods and answer
three key research questions regarding generalization capability and the
relation between detection and localization. Our benchmark and analysis provide
a robust foundation for future research.

</details>


### [130] [LRW-Persian: Lip-reading in the Wild Dataset for Persian Language](https://arxiv.org/abs/2510.22716)
*Zahra Taghizadeh,Mohammad Shahverdikondori,Arian Noori,Alireza Dadgarnia*

Main category: cs.CV

TL;DR: 本文介绍了有史以来规模最大的波斯语口型识别数据集LRW-Persian，包括743个目标词、超过41.4万段视频，显著丰富了非英语视觉语音资源。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语音识别（口型识别）大多集中在英语，非英语特别是波斯语的相关公开资源极为稀缺，影响了该领域的研究和辅助技术发展。因此，亟需高质量、规模化的波斯语口型识别数据集以促进相关研究。

Method: 作者构建了LRW-Persian数据集，自动化收集并筛选了1900小时、67个电视节目的视频，包括身份独立的训练/测试集、广泛的地区与方言覆盖、每段视频丰富的元信息（如头部姿态、年龄、性别）。数据整理采用了ASR转录、主动说话人定位、质量筛选及姿态/口罩筛查的全自动流程。随后，作者还在该数据集上微调了两种主流的口型识别架构并建立了基线。

Result: 成功建立了大规模、高质量的波斯语口型识别数据集，对口型识别主流模型进行微调测试后结果显示波斯语视觉语音识别难度较高，数据集可作为基准对比平台。

Conclusion: LRW-Persian为资源稀缺语言视觉语音识别填补了重要空白，支持严谨对比、跨语种迁移与多模态语音研究，为推动弱势语言环境下的多模态人工智能研究提供了坚实基础。数据已公开发布。

Abstract: Lipreading has emerged as an increasingly important research area for
developing robust speech recognition systems and assistive technologies for the
hearing-impaired. However, non-English resources for visual speech recognition
remain limited. We introduce LRW-Persian, the largest in-the-wild Persian
word-level lipreading dataset, comprising $743$ target words and over
$414{,}000$ video samples extracted from more than $1{,}900$ hours of footage
across $67$ television programs. Designed as a benchmark-ready resource,
LRW-Persian provides speaker-disjoint training and test splits, wide regional
and dialectal coverage, and rich per-clip metadata including head pose, age,
and gender. To ensure large-scale data quality, we establish a fully automated
end-to-end curation pipeline encompassing transcription based on Automatic
Speech Recognition(ASR), active-speaker localization, quality filtering, and
pose/mask screening. We further fine-tune two widely used lipreading
architectures on LRW-Persian, establishing reference performance and
demonstrating the difficulty of Persian visual speech recognition. By filling a
critical gap in low-resource languages, LRW-Persian enables rigorous
benchmarking, supports cross-lingual transfer, and provides a foundation for
advancing multimodal speech research in underrepresented linguistic contexts.
The dataset is publicly available at: https://lrw-persian.vercel.app.

</details>


### [131] [Cross-view Localization and Synthesis - Datasets, Challenges and Opportunities](https://arxiv.org/abs/2510.22736)
*Ningli Xu,Rongjun Qin*

Main category: cs.CV

TL;DR: 本文综述了跨视角定位和合成的最新进展，这两项任务旨在通过分析卫星等俯视图与地面视图之间的关联，实现图像定位和生成，文中总结了主流数据集、挑战、方法与未来方向。


<details>
  <summary>Details</summary>
Motivation: 跨视角视觉理解应用广泛，如自动导航、城市规划及增强现实，但由于视角、分辨率和遮挡的差异，实现地面图像定位和生成仍有很大挑战，需要系统梳理当前进展。

Method: 文献综述方式，梳理了基于CNNs、ViTs的特征提取方法和基于GANs、扩散模型的地面图像生成方法，总结各类主流公开数据集，归纳了当前主要技术和挑战。

Result: 系统性地整理了跨视图定位和合成的最新理论与实践进展，对方法和数据集进行了对比，并指出了现有方法的不足和研究空白。

Conclusion: 当前跨视角定位与合成已有显著进展，但仍存在视角差异、分辨率及遮挡等多重技术挑战，文中为未来研究方向与改进提供了指导建议，同时整理了相关资源。

Abstract: Cross-view localization and synthesis are two fundamental tasks in cross-view
visual understanding, which deals with cross-view datasets: overhead (satellite
or aerial) and ground-level imagery. These tasks have gained increasing
attention due to their broad applications in autonomous navigation, urban
planning, and augmented reality. Cross-view localization aims to estimate the
geographic position of ground-level images based on information provided by
overhead imagery while cross-view synthesis seeks to generate ground-level
images based on information from the overhead imagery. Both tasks remain
challenging due to significant differences in viewing perspective, resolution,
and occlusion, which are widely embedded in cross-view datasets. Recent years
have witnessed rapid progress driven by the availability of large-scale
datasets and novel approaches. Typically, cross-view localization is formulated
as an image retrieval problem where ground-level features are matched with
tiled overhead images feature, extracted by convolutional neural networks
(CNNs) or vision transformers (ViTs) for cross-view feature embedding.
Cross-view synthesis, on the other hand, seeks to generate ground-level views
based on information from overhead imagery, generally using generative
adversarial networks (GANs) or diffusion models. This paper presents a
comprehensive survey of advances in cross-view localization and synthesis,
reviewing widely used datasets, highlighting key challenges, and providing an
organized overview of state-of-the-art techniques. Furthermore, it discusses
current limitations, offers comparative analyses, and outlines promising
directions for future research. We also include the project page via
https://github.com/GDAOSU/Awesome-Cross-View-Methods.

</details>


### [132] [ConMatFormer: A Multi-attention and Transformer Integrated ConvNext based Deep Learning Model for Enhanced Diabetic Foot Ulcer Classification](https://arxiv.org/abs/2510.22743)
*Raihan Ahamed Rifat,Fuyad Hasan Bhoyan,Md Humaion Kabir Mehedi,Md Kaviul Hossain,Md. Jakir Hossen,M. F. Mridha*

Main category: cs.CV

TL;DR: 本论文提出了一种名为ConMatFormer的新型混合深度学习架构，有效解决了糖尿病足溃疡（DFU）检测中由于数据集稀缺和多样性引发的挑战，实现了高精度的DFU分类。


<details>
  <summary>Details</summary>
Motivation: DFU检测在临床上具有重要意义，但现实中公开可用的数据集稀少且差异大，导致现有方法难以取得理想效果。因此，亟需开发能够适应不同DFU特征、提升检测精度的智能方法。

Method: 提出了一种结合ConvNeXt模块、多重注意力机制（CBAM与DANet）和Transformer模块的混合模型ConMatFormer。在模型初期通过ConvNeXt提取局部细节特征，随后结合Transformer加强全局特征建模。采用数据增强方法缓解类别不平衡问题，并利用解释性AI工具（如Grad-CAM、LIME）保障模型决策的可解释性和可信度。

Result: 在DFUC2021（DS1）和DFU（DS2）数据集上，ConMatFormer的准确率和精度优于当前主流CNN与ViT模型。单次实验中准确率达0.8961，精度0.9160，4折交叉验证下准确率达0.9755，标准差仅0.0031，显著优于现有方法。

Conclusion: ConMatFormer成为DFU分类的新基准，其混合注意力Transformer架构在医学图像分析领域表现出色，同时保障了模型决策的透明度和可追溯性。

Abstract: Diabetic foot ulcer (DFU) detection is a clinically significant yet
challenging task due to the scarcity and variability of publicly available
datasets. To solve these problems, we propose ConMatFormer, a new hybrid deep
learning architecture that combines ConvNeXt blocks, multiple attention
mechanisms convolutional block attention module (CBAM) and dual attention
network (DANet), and transformer modules in a way that works together. This
design facilitates the extraction of better local features and understanding of
the global context, which allows us to model small skin patterns across
different types of DFU very accurately. To address the class imbalance, we used
data augmentation methods. A ConvNeXt block was used to obtain detailed local
features in the initial stages. Subsequently, we compiled the model by adding a
transformer module to enhance long-range dependency. This enabled us to
pinpoint the DFU classes that were underrepresented or constituted minorities.
Tests on the DS1 (DFUC2021) and DS2 (diabetic foot ulcer (DFU)) datasets showed
that ConMatFormer outperformed state-of-the-art (SOTA) convolutional neural
network (CNN) and Vision Transformer (ViT) models in terms of accuracy,
reliability, and flexibility. The proposed method achieved an accuracy of
0.8961 and a precision of 0.9160 in a single experiment, which is a significant
improvement over the current standards for classifying DFUs. In addition, by
4-fold cross-validation, the proposed model achieved an accuracy of 0.9755 with
a standard deviation of only 0.0031. We further applied explainable artificial
intelligence (XAI) methods, such as Grad-CAM, Grad-CAM++, and LIME, to
consistently monitor the transparency and trustworthiness of the
decision-making process.. Our findings set a new benchmark for DFU
classification and provide a hybrid attention transformer framework for medical
image analysis.

</details>


### [133] [Self-Calibrated Consistency can Fight Back for Adversarial Robustness in Vision-Language Models](https://arxiv.org/abs/2510.22785)
*Jiaxiang Liu,Jiawei Du,Xiao Liu,Prayag Tiwari,Mingkun Xu*

Main category: cs.CV

TL;DR: 本文提出了一种在测试阶段提升跨模态预训练模型（如CLIP）抗攻击能力的新方法Self-Calibrated Consistency (SCC)，有效提升了其零样本鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管CLIP等视觉-语言预训练模型在零样本任务上表现优异，但它们在遭遇对抗扰动时极其脆弱，现有防御依赖有标签数据进行对抗微调，不适合零样本设定，因此亟需无需标注且泛用性强的防御方法。

Method: 作者发现现有攻击方法在语义指导和视角变化下表现脆弱（语义与视角易碎性）。为此，提出SCC方法，包括两个互补模块：1）语义一致性，利用伪标签和多视角预测，增强跨模态对齐及分离疑难负样本；2）空间一致性，通过多种视图增强，使视觉预测对扰动更加稳定。该方法仅需推理阶段操作，即插即用。

Result: 在22个不同攻击基准上的大量实验表明，SCC方法在不影响准确率的前提下显著提升了CLIP的零样本鲁棒性，并可无缝集成到其他VLM模型中进一步提升表现。

Conclusion: SCC为建立鲁棒的跨模态视觉-语言模型提供了新范式，有望推动生物医学等更广泛领域的VLM安全可靠应用。

Abstract: Pre-trained vision-language models (VLMs) such as CLIP have demonstrated
strong zero-shot capabilities across diverse domains, yet remain highly
vulnerable to adversarial perturbations that disrupt image-text alignment and
compromise reliability. Existing defenses typically rely on adversarial
fine-tuning with labeled data, limiting their applicability in zero-shot
settings. In this work, we identify two key weaknesses of current CLIP
adversarial attacks -- lack of semantic guidance and vulnerability to view
variations -- collectively termed semantic and viewpoint fragility. To address
these challenges, we propose Self-Calibrated Consistency (SCC), an effective
test-time defense. SCC consists of two complementary modules: Semantic
consistency, which leverages soft pseudo-labels from counterattack warm-up and
multi-view predictions to regularize cross-modal alignment and separate the
target embedding from confusable negatives; and Spatial consistency, aligning
perturbed visual predictions via augmented views to stabilize inference under
adversarial perturbations. Together, these modules form a plug-and-play
inference strategy. Extensive experiments on 22 benchmarks under diverse attack
settings show that SCC consistently improves the zero-shot robustness of CLIP
while maintaining accuracy, and can be seamlessly integrated with other VLMs
for further gains. These findings highlight the great potential of establishing
an adversarially robust paradigm from CLIP, with implications extending to
broader vision-language domains such as BioMedCLIP.

</details>


### [134] [MedXplain-VQA: Multi-Component Explainable Medical Visual Question Answering](https://arxiv.org/abs/2510.22803)
*Hai-Dang Nguyen,Minh-Anh Dang,Minh-Tan Le,Minh-Tuan Le*

Main category: cs.CV

TL;DR: 本文提出了MedXplain-VQA框架，通过多种可解释AI部件提升医学视觉问答（VQA）系统的可解释性，在医学图像诊断中展现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 医学VQA系统的临床应用需要强可解释性，以获得医生的信任，因此提升诊断推理的透明度非常关键。

Method: 提出了MedXplain-VQA，整合了五种可解释AI技术：微调的BLIP-2主干、医学查询重构、强化Grad-CAM注意力、精确区域提取以及以多模态语言模型为基础的链式推理。评价中采用了医学领域相关的指标，如术语覆盖率、临床结构质量和关注区域相关性。

Result: 在500个PathVQA样本上，综合得分由基线方法的0.378提升到0.683，推理置信度达到0.890。系统每例可识别3-5个诊断相关区域，并生成平均57词的结构化临床解释。消融实验显示，查询重构和链式推理分别对性能提升和诊断系统性有显著帮助。

Conclusion: MedXplain-VQA在提高医学VQA的可解释性及诊断可靠性方面具有显著优势，未来将进一步结合专家验证和大规模临床数据测试，推动其临床应用。

Abstract: Explainability is critical for the clinical adoption of medical visual
question answering (VQA) systems, as physicians require transparent reasoning
to trust AI-generated diagnoses. We present MedXplain-VQA, a comprehensive
framework integrating five explainable AI components to deliver interpretable
medical image analysis. The framework leverages a fine-tuned BLIP-2 backbone,
medical query reformulation, enhanced Grad-CAM attention, precise region
extraction, and structured chain-of-thought reasoning via multi-modal language
models. To evaluate the system, we introduce a medical-domain-specific
framework replacing traditional NLP metrics with clinically relevant
assessments, including terminology coverage, clinical structure quality, and
attention region relevance. Experiments on 500 PathVQA histopathology samples
demonstrate substantial improvements, with the enhanced system achieving a
composite score of 0.683 compared to 0.378 for baseline methods, while
maintaining high reasoning confidence (0.890). Our system identifies 3-5
diagnostically relevant regions per sample and generates structured
explanations averaging 57 words with appropriate clinical terminology. Ablation
studies reveal that query reformulation provides the most significant initial
improvement, while chain-of-thought reasoning enables systematic diagnostic
processes. These findings underscore the potential of MedXplain-VQA as a
robust, explainable medical VQA system. Future work will focus on validation
with medical experts and large-scale clinical datasets to ensure clinical
readiness.

</details>


### [135] [MAGIC-Talk: Motion-aware Audio-Driven Talking Face Generation with Customizable Identity Control](https://arxiv.org/abs/2510.22810)
*Fatemeh Nazarieh,Zhenhua Feng,Diptesh Kanojia,Muhammad Awais,Josef Kittler*

Main category: cs.CV

TL;DR: MAGIC-Talk是一种基于扩散模型的创新方法，实现了高质量、可自定义、时序稳定的开口说话人脸生成，只需一张图片即可保持身份，提升了长视频生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有音频驱动说话人脸生成方法虽然提升了音唇同步，但在生成长视频时容易出现时序不一致、身份保持难和自定义性差的问题。该研究旨在解决这些挑战，实现更高质量、更真实的说话人脸生成。

Method: 提出了MAGIC-Talk框架，包括ReferenceNet和AnimateNet两个子模块。ReferenceNet用于精准保持身份并通过文本提示实现面部细致编辑；AnimateNet利用结构化运动先验提升运动一致性。同时，采用渐进式潜在融合策略，有效提升长视频质量并减少画面闪烁。

Result: 通过大量实验，MAGIC-Talk在视觉质量、身份保持和音唇同步准确性方面都超过了当前主流方法。

Conclusion: MAGIC-Talk为说话人脸生成任务提供了鲁棒和高效的解决方案，特别适用于长视频生成和单张照片自定义应用，有望促进虚拟数字人等相关领域的发展。

Abstract: Audio-driven talking face generation has gained significant attention for
applications in digital media and virtual avatars. While recent methods improve
audio-lip synchronization, they often struggle with temporal consistency,
identity preservation, and customization, especially in long video generation.
To address these issues, we propose MAGIC-Talk, a one-shot diffusion-based
framework for customizable and temporally stable talking face generation.
MAGIC-Talk consists of ReferenceNet, which preserves identity and enables
fine-grained facial editing via text prompts, and AnimateNet, which enhances
motion coherence using structured motion priors. Unlike previous methods
requiring multiple reference images or fine-tuning, MAGIC-Talk maintains
identity from a single image while ensuring smooth transitions across frames.
Additionally, a progressive latent fusion strategy is introduced to improve
long-form video quality by reducing motion inconsistencies and flickering.
Extensive experiments demonstrate that MAGIC-Talk outperforms state-of-the-art
methods in visual quality, identity preservation, and synchronization accuracy,
offering a robust solution for talking face generation.

</details>


### [136] [FairJudge: MLLM Judging for Social Attributes and Prompt Image Alignment](https://arxiv.org/abs/2510.22827)
*Zahraa Al Sahili,Maryam Fetanat,Maimuna Nowaz,Ioannis Patras,Matthew Purver*

Main category: cs.CV

TL;DR: 现有文本转图像（T2I）系统在评估图像与提示词匹配度及社会属性处理时存在不足。本文提出FairJudge协议，利用多模态大模型（LLM）作为“公平裁判”，采用更科学、负责任的打分和溯源方法评估T2I系统的公平性。实验显示，FairJudge优于现有基线，促进更可靠的公平性评估。


<details>
  <summary>Details</summary>
Motivation: 当前T2I系统缺乏简单可复现、能反映社会属性（如性别、种族、宗教等）且兼具公平性的评估方式。常见方法（如CLIP相似度、面部识别器）侧重表面特征，对弱可见属性识别不佳，且无法合理拒判。

Method: 提出FairJudge协议，利用多模态大模型作为评判者，设计了解释性评分标准（[-1,1]区间），要求判决需有图像证据，并在证据不足时必须拒评。该协议与以往单靠CLIP或更改生成器的方法不同，主要着眼于评估环节的公平性。

Result: 在FairFace、PaTA和FairCoT等数据集上评估性别、种族、年龄，并扩展至宗教、文化、残障等属性。此外对职业相关数据集也做了评测。Judge模型在属性预测和对齐度上均超越对比和依赖面部的基线方法，同时保持对职业准确性的高水平。还发布了多样化场景的新数据集DIVERSIFY。

Conclusion: FairJudge协议为T2I系统带来更负责任和可复现的公平性评估方法，提升了评测的准确性及审计可靠性，有助于推动AI公平性研究的发展。

Abstract: Text-to-image (T2I) systems lack simple, reproducible ways to evaluate how
well images match prompts and how models treat social attributes. Common
proxies -- face classifiers and contrastive similarity -- reward surface cues,
lack calibrated abstention, and miss attributes only weakly visible (for
example, religion, culture, disability). We present FairJudge, a lightweight
protocol that treats instruction-following multimodal LLMs as fair judges. It
scores alignment with an explanation-oriented rubric mapped to [-1, 1];
constrains judgments to a closed label set; requires evidence grounded in the
visible content; and mandates abstention when cues are insufficient. Unlike
CLIP-only pipelines, FairJudge yields accountable, evidence-aware decisions;
unlike mitigation that alters generators, it targets evaluation fairness. We
evaluate gender, race, and age on FairFace, PaTA, and FairCoT; extend to
religion, culture, and disability; and assess profession correctness and
alignment on IdenProf, FairCoT-Professions, and our new DIVERSIFY-Professions.
We also release DIVERSIFY, a 469-image corpus of diverse, non-iconic scenes.
Across datasets, judge models outperform contrastive and face-centric baselines
on demographic prediction and improve mean alignment while maintaining high
profession accuracy, enabling more reliable, reproducible fairness audits.

</details>


### [137] [LLM-based Fusion of Multi-modal Features for Commercial Memorability Prediction](https://arxiv.org/abs/2510.22829)
*Aleksandar Pramov*

Main category: cs.CV

TL;DR: 本文提出了一个基于多模态融合系统，通过结合视觉和文本特征预测广告的记忆度，并在MediaEval 2025竞赛中展现出优异表现。


<details>
  <summary>Details</summary>
Motivation: 广告记忆度预测能帮助品牌提升宣传效果，当前相关任务在多模态特征融合与泛化能力上存在挑战。

Method: 以Gemma-3 LLM为主干，融合预先计算的视觉（ViT）和文本（E5）特征，通过多模态投影结合，并用Low-Rank Adaptation (LoRA)进行模型适配；同时，采用由LLM生成的基于专家经验的理由提示，指导模型训练。对比基线模型是精调的梯度提升树集成。

Result: 在最终测试集上，LLM结合多模态融合系统比基线方法表现更稳健，泛化能力更强。

Conclusion: 提出的方法在广告记忆度预测任务上取得更优效果，通过LLM生成的专家型提示显著提升模型表现，有望应用于广告优化场景。

Abstract: This paper addresses the prediction of commercial (brand) memorability as
part of "Subtask 2: Commercial/Ad Memorability" within the "Memorability:
Predicting movie and commercial memorability" task at the MediaEval 2025
workshop competition. We propose a multimodal fusion system with a Gemma-3 LLM
backbone that integrates pre-computed visual (ViT) and textual (E5) features by
multi-modal projections. The model is adapted using Low-Rank Adaptation (LoRA).
A heavily-tuned ensemble of gradient boosted trees serves as a baseline. A key
contribution is the use of LLM-generated rationale prompts, grounded in
expert-derived aspects of memorability, to guide the fusion model. The results
demonstrate that the LLM-based system exhibits greater robustness and
generalization performance on the final test set, compared to the baseline.
  The paper's codebase can be found at
https://github.com/dsgt-arc/mediaeval-2025-memorability

</details>


### [138] [Semantic-Preserving Cross-Style Visual Reasoning for Robust Multi-Modal Understanding in Large Vision-Language Models](https://arxiv.org/abs/2510.22838)
*Aya Nakayama,Brian Wong,Yuji Nishimura,Kaito Tanaka*

Main category: cs.CV

TL;DR: 本文提出了一种新架构SP-CSVR，有效提升了大规模视觉-语言模型在多视觉风格下的语义理解和迁移能力。


<details>
  <summary>Details</summary>
Motivation: 目前大规模视觉-语言模型在不同视觉风格下语义理解存在困难，尤其是在上下文学习(ICL)中表现不佳。现有方法难以将风格与内容有效解耦，影响模型泛化能力。

Method: 提出了语义保持的跨风格视觉推理框架（SP-CSVR），包括三个核心模块：跨风格特征编码器（CSFE）用于风格-内容解耦、语义对齐上下文解码器（SAICD）实现高效的风格自适应，以及自适应语义一致性模块（ASCM）利用多任务对比学习实现语义不变性。

Result: 在具有挑战性的多风格数据集上进行了大量实验，SP-CSVR在视觉描述、视觉问答和风格自适应等多项任务上达到最新最优性能。消融实验和泛化分析进一步验证了其鲁棒性、泛化能力和效率显著提升。

Conclusion: SP-CSVR显著提高了大模型在多样视觉风格下的鲁棒性和泛化性，为解决风格陷阱问题提供了有效方法，对视觉-语言理解领域具有重要推动作用。

Abstract: The "style trap" poses a significant challenge for Large Vision-Language
Models (LVLMs), hindering robust semantic understanding across diverse visual
styles, especially in in-context learning (ICL). Existing methods often fail to
effectively decouple style from content, hindering generalization. To address
this, we propose the Semantic-Preserving Cross-Style Visual Reasoner (SP-CSVR),
a novel framework for stable semantic understanding and adaptive cross-style
visual reasoning. SP-CSVR integrates a Cross-Style Feature Encoder (CSFE) for
style-content disentanglement, a Semantic-Aligned In-Context Decoder (SAICD)
for efficient few-shot style adaptation, and an Adaptive Semantic Consistency
Module (ASCM) employing multi-task contrastive learning to enforce cross-style
semantic invariance. Extensive experiments on a challenging multi-style dataset
demonstrate SP-CSVR's state-of-the-art performance across visual captioning,
visual question answering, and in-context style adaptation. Comprehensive
evaluations, including ablation studies and generalization analysis, confirm
SP-CSVR's efficacy in enhancing robustness, generalization, and efficiency
across diverse visual styles.

</details>


### [139] [FastJAM: a Fast Joint Alignment Model for Images](https://arxiv.org/abs/2510.22842)
*Omri Hirsch,Ron Shapira Weber,Shira Ifergane,Oren Freifeld*

Main category: cs.CV

TL;DR: 本文提出了一种快速图神经网络方法FastJAM，实现多图像的高效联合对齐，无需繁琐调参且计算速度大幅提升，在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有联合对齐方法往往需要大模型、长训练时间以及大量超参数调整，造成实际应用的门槛高且效率低下。作者希望设计一个更高效、参数依赖少的方法。

Method: FastJAM基于图结构，先用现有图像匹配器计算两两特征点对应关系，然后通过快速的无参数聚类构建图结构，利用图神经网络传播和聚合特征，最后通过图池化预测每张图像的单应性参数，并采用逆组合损失函数，省去了正则项及其调参。

Result: FastJAM在多个基准数据集上的实验结果显示，该方法对齐质量优于现有主流联合对齐方法，计算时间从小时/分钟级降至秒级。

Conclusion: FastJAM在保持甚至提升对齐效果的同时，大幅降低了计算和调整难度，为联合对齐任务提供了一种高效、实用的新方法。

Abstract: Joint Alignment (JA) of images aims to align a collection of images into a
unified coordinate frame, such that semantically-similar features appear at
corresponding spatial locations. Most existing approaches often require long
training times, large-capacity models, and extensive hyperparameter tuning. We
introduce FastJAM, a rapid, graph-based method that drastically reduces the
computational complexity of joint alignment tasks. FastJAM leverages pairwise
matches computed by an off-the-shelf image matcher, together with a rapid
nonparametric clustering, to construct a graph representing intra- and
inter-image keypoint relations. A graph neural network propagates and
aggregates these correspondences, efficiently predicting per-image homography
parameters via image-level pooling. Utilizing an inverse-compositional loss,
that eliminates the need for a regularization term over the predicted
transformations (and thus also obviates the hyperparameter tuning associated
with such terms), FastJAM performs image JA quickly and effectively.
Experimental results on several benchmarks demonstrate that FastJAM achieves
results better than existing modern JA methods in terms of alignment quality,
while reducing computation time from hours or minutes to mere seconds. Our code
is available at our project webpage, https://bgu-cs-vil.github.io/FastJAM/

</details>


### [140] [Semantic Surgery: Zero-Shot Concept Erasure in Diffusion Models](https://arxiv.org/abs/2510.22851)
*Lexiang Xiong,Chengyu Liu,Jingwen Ye,Yan Liu,Yuecong Xu*

Main category: cs.CV

TL;DR: 该论文提出了一种新的文本到图像扩散模型中概念擦除方法，在不影响生成质量的前提下，有效去除有害内容。


<details>
  <summary>Details</summary>
Motivation: 扩散模型生成的内容可能包含有害或不良信息，而现有概念擦除方法常常削弱图像生成质量。因此，亟需一种在保障生成质量的同时，有效擦除有害概念的技术。

Method: 提出了一种无需训练的零样本框架（Semantic Surgery），在扩散过程前直接作用于文本嵌入，通过动态估算提示词中的目标概念并校准向量相减，实现针对性和局部性的概念擦除。此外包含协同编码模块与视觉反馈循环，保障多概念擦除与去除残留的隐性概念。

Result: 在对象、敏感内容、艺术风格、多名人等多种擦除任务上显著优于现有方法，达到如对象擦除93.58 H-score，只剩1例显式内容，风格擦除8.09 H_a且无质量损失。

Conclusion: 该方法无需训练，能够动态适应不同提示词，实现高效、完整且本地化的概念擦除；不仅提升安全性，还可作为内置威胁检测系统，实用性强。

Abstract: Concept erasure in text-to-image diffusion models is crucial for mitigating
harmful content, yet existing methods often compromise generative quality. We
introduce Semantic Surgery, a novel training-free, zero-shot framework for
concept erasure that operates directly on text embeddings before the diffusion
process. It dynamically estimates the presence of target concepts in a prompt
and performs a calibrated vector subtraction to neutralize their influence at
the source, enhancing both erasure completeness and locality. The framework
includes a Co-Occurrence Encoding module for robust multi-concept erasure and a
visual feedback loop to address latent concept persistence. As a training-free
method, Semantic Surgery adapts dynamically to each prompt, ensuring precise
interventions. Extensive experiments on object, explicit content, artistic
style, and multi-celebrity erasure tasks show our method significantly
outperforms state-of-the-art approaches. We achieve superior completeness and
robustness while preserving locality and image quality (e.g., 93.58 H-score in
object erasure, reducing explicit content to just 1 instance, and 8.09 H_a in
style erasure with no quality degradation). This robustness also allows our
framework to function as a built-in threat detection system, offering a
practical solution for safer text-to-image generation.

</details>


### [141] [Seeing the Unseen: Towards Zero-Shot Inspection for Wind Turbine Blades using Knowledge-Augmented Vision Language Models](https://arxiv.org/abs/2510.22868)
*Yang Zhang,Qianyu Zhou,Farhad Imani,Jiong Tang*

Main category: cs.CV

TL;DR: 本文提出了一种零样本导向的风力发电机叶片损伤检测框架，将检索增强生成（RAG）与视觉语言模型（VLM）结合，无需大量标注数据即可检测多样和新型损伤。


<details>
  <summary>Details</summary>
Motivation: 风机叶片需在恶劣环境下长时间运行，及时的损伤检测对防止故障和优化维护至关重要。传统基于无人机和深度学习的方法依赖大量标注数据，难以有效检测罕见或新兴损伤类型，实际应用受到限制。

Method: 构建了多模态知识库（技术文档、参考图像、行业指南）；使用结合了关键词重排序的混合文本-图像检索器，在推理时为视觉语言模型提供最相关的上下文，无需针对特定任务训练。

Result: 在30个多类型损伤标注叶片图像的小数据集上测试，该RAG引导的VLM实现了全部样本正确分类，显著优于无检索的VLM和开放词表基线模型。还采用Clopper-Pearson置信区间评估小样本统计，并通过消融实验确认系统的可解释性和泛化能力优势。

Conclusion: 本文提出的方法提高了工业检测的数据效率，降低了对大规模标注数据的依赖，并能借助领域知识检测新型未见过的损伤类型，具有较强的可解释性和应用前景。

Abstract: Wind turbine blades operate in harsh environments, making timely damage
detection essential for preventing failures and optimizing maintenance.
Drone-based inspection and deep learning are promising, but typically depend on
large, labeled datasets, which limit their ability to detect rare or evolving
damage types. To address this, we propose a zero-shot-oriented inspection
framework that integrates Retrieval-Augmented Generation (RAG) with
Vision-Language Models (VLM). A multimodal knowledge base is constructed,
comprising technical documentation, representative reference images, and
domain-specific guidelines. A hybrid text-image retriever with keyword-aware
reranking assembles the most relevant context to condition the VLM at
inference, injecting domain knowledge without task-specific training. We
evaluate the framework on 30 labeled blade images covering diverse damage
categories. Although the dataset is small due to the difficulty of acquiring
verified blade imagery, it covers multiple representative defect types. On this
test set, the RAG-grounded VLM correctly classified all samples, whereas the
same VLM without retrieval performed worse in both accuracy and precision. We
further compare against open-vocabulary baselines and incorporate uncertainty
Clopper-Pearson confidence intervals to account for the small-sample setting.
Ablation studies indicate that the key advantage of the framework lies in
explainability and generalizability: retrieved references ground the reasoning
process and enable the detection of previously unseen defects by leveraging
domain knowledge rather than relying solely on visual cues. This research
contributes a data-efficient solution for industrial inspection that reduces
dependence on extensive labeled datasets.

</details>


### [142] [Estimating Pasture Biomass from Top-View Images: A Dataset for Precision Agriculture](https://arxiv.org/abs/2510.22916)
*Qiyu Liao,Dadong Wang,Rebecca Haling,Jiajun Liu,Xun Li,Martyna Plomecka,Andrew Robson,Matthew Pringle,Rhys Pirie,Megan Walker,Joshua Whelan*

Main category: cs.CV

TL;DR: 本文发布了一个大型的、人工标注的澳大利亚牧草地影像数据集，包含生物量、NDVI等多维信息，用于促进牧草生物量估算与精准放牧管理AI算法研究。


<details>
  <summary>Details</summary>
Motivation: 牧草生物量的准确估算对于畜牧业至关重要，可以优化放牧决策，防止过度放牧，提升系统健康。

Method: 研究者在澳大利亚19个地点、不同时节采集了1162张顶视图照片，并结合地面测量数据（如生物量各组分、植被高度、NDVI），建立融合视觉、光谱和结构信息的数据集。

Result: 最终构建了一个包含高质量注释和多维辅助手段的牧草多元数据集，并在Kaggle平台发起竞赛以推动国际机器学习领域对牧草生物量估算技术的研究。

Conclusion: 该数据集为精准放牧管理和相关AI算法研究提供了高价值的公开资源，有助于推动生物量估算方法和产业实践的进步。

Abstract: Accurate estimation of pasture biomass is important for decision-making in
livestock production systems. Estimates of pasture biomass can be used to
manage stocking rates to maximise pasture utilisation, while minimising the
risk of overgrazing and promoting overall system health. We present a
comprehensive dataset of 1,162 annotated top-view images of pastures collected
across 19 locations in Australia. The images were taken across multiple seasons
and include a range of temperate pasture species. Each image captures a 70cm *
30cm quadrat and is paired with on-ground measurements including biomass sorted
by component (green, dead, and legume fraction), vegetation height, and
Normalized Difference Vegetation Index (NDVI) from Active Optical Sensors
(AOS). The multidimensional nature of the data, which combines visual,
spectral, and structural information, opens up new possibilities for advancing
the use of precision grazing management. The dataset is released and hosted in
a Kaggle competition that challenges the international Machine Learning
community with the task of pasture biomass estimation. The dataset is available
on the official Kaggle webpage:
https://www.kaggle.com/competitions/csiro-biomass

</details>


### [143] [Gen-LangSplat: Generalized Language Gaussian Splatting with Pre-Trained Feature Compression](https://arxiv.org/abs/2510.22930)
*Pranav Saxena*

Main category: cs.CV

TL;DR: 本文提出Gen-LangSplat，一种无需场景特定自编码器的3D开放词汇语言场建模方法。该方法通过预训练通用自编码器，实现高效、可扩展的场景语言表达查询能力。


<details>
  <summary>Details</summary>
Motivation: 当前主流3D语言场建模方法如LangSplat需为每个场景训练自编码器来压缩特征，导致部署受限和效率低下。论文希望通过消除这一瓶颈，实现大规模、实时的3D场景语言交互。

Method: Gen-LangSplat用在大规模数据上预训练的通用自编码器代替原有的场景特定自编码器，从而构建统一的、紧凑的语言特征潜空间，无需场景特定训练即可泛化到新场景。通过对原始和重投影的CLIP嵌入向量进行量化（均方误差及余弦相似度）和消融实验优化嵌入维度。

Result: 无需场景特定自编码训练后，系统效率大幅提升，且查询表现与甚至优于原始LangSplat。消融实验和量化验证表明，通用嵌入空间能有效保持特征表达能力，支持开放词汇查询。

Conclusion: Gen-LangSplat实现了高效、准确的3D开放词汇语言场建模，消除了场景特定训练依赖，为可扩展、实时的3D AI应用铺平了道路。

Abstract: Modeling open-vocabulary language fields in 3D is essential for intuitive
human-AI interaction and querying within physical environments.
State-of-the-art approaches, such as LangSplat, leverage 3D Gaussian Splatting
to efficiently construct these language fields, encoding features distilled
from high-dimensional models like CLIP. However, this efficiency is currently
offset by the requirement to train a scene-specific language autoencoder for
feature compression, introducing a costly, per-scene optimization bottleneck
that hinders deployment scalability. In this work, we introduce Gen-LangSplat,
that eliminates this requirement by replacing the scene-wise autoencoder with a
generalized autoencoder, pre-trained extensively on the large-scale ScanNet
dataset. This architectural shift enables the use of a fixed, compact latent
space for language features across any new scene without any scene-specific
training. By removing this dependency, our entire language field construction
process achieves a efficiency boost while delivering querying performance
comparable to, or exceeding, the original LangSplat method. To validate our
design choice, we perform a thorough ablation study empirically determining the
optimal latent embedding dimension and quantifying representational fidelity
using Mean Squared Error and cosine similarity between the original and
reprojected 512-dimensional CLIP embeddings. Our results demonstrate that
generalized embeddings can efficiently and accurately support open-vocabulary
querying in novel 3D scenes, paving the way for scalable, real-time interactive
3D AI applications.

</details>


### [144] [Positional Preservation Embedding for Multimodal Large Language Models](https://arxiv.org/abs/2510.22936)
*Mouxiao Huang,Borui Jiang,Dehua Zheng,Hailin Hu,Kai Han,Xinghao Chen*

Main category: cs.CV

TL;DR: 本文提出了一种新型的位置保持编码（PPE）方法，用于多模态大语言模型（MLLM）视觉token压缩，在减少token数量的同时保持空间和时间结构，提高了视觉语言任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有的token合并方法在减少序列长度时，常常忽略视觉token间的空间和时间位置关系，导致空间布局及连续性被破坏，从而影响MLLM在视觉语言任务中的效果。本文旨在解决token合并时的信息损失问题，提高模型效率和表现。

Method: 作者提出位置保持编码（PPE），将3D位置信息显式编码进token维度。PPE可以无参数、无缝集成到现有token合并方法中，支持级联聚类压缩策略，在token压缩过程中保留原始空间与时间结构。

Result: PPE集成到最先进token合并框架中，在多个视觉语言基准测试上带来2%~5%的性能提升，包括MMBench（通用视觉理解）、TextVQA（版面理解）、VideoMME（时序理解）。

Conclusion: 实验结果验证了在MLLM中保留token的位置信息对于高效、有效的推理至关重要。PPE是一种通用、无参数且高效的操作，能够提升视觉语言模型的综合性能。

Abstract: Multimodal large language models (MLLMs) have achieved strong performance on
vision-language tasks, yet often suffer from inefficiencies due to redundant
visual tokens. Existing token merging methods reduce sequence length but
frequently disrupt spatial layouts and temporal continuity by disregarding
positional relationships. In this work, we propose a novel encoding operator
dubbed as \textbf{P}ositional \textbf{P}reservation \textbf{E}mbedding
(\textbf{PPE}), which has the main hallmark of preservation of spatiotemporal
structure during visual token compression. PPE explicitly introduces the
disentangled encoding of 3D positions in the token dimension, enabling each
compressed token to encapsulate different positions from multiple original
tokens. Furthermore, we show that PPE can effectively support cascade
clustering -- a progressive token compression strategy that leads to better
performance retention. PPE is a parameter-free and generic operator that can be
seamlessly integrated into existing token merging methods without any
adjustments. Applied to state-of-the-art token merging framework, PPE achieves
consistent improvements of $2\%\sim5\%$ across multiple vision-language
benchmarks, including MMBench (general vision understanding), TextVQA (layout
understanding) and VideoMME (temporal understanding). These results demonstrate
that preserving positional cues is critical for efficient and effective MLLM
reasoning.

</details>


### [145] [Bi-Encoder Contrastive Learning for Fingerprint and Iris Biometrics](https://arxiv.org/abs/2510.22937)
*Matthew So,Judah Goldfeder,Mark Lis,Hod Lipson*

Main category: cs.CV

TL;DR: 本论文质疑了个人生物识别特征（如指纹、虹膜）之间彼此独立的历史假设，结果显示同一人的生物特征之间实际上存在相关性。


<details>
  <summary>Details</summary>
Motivation: 长期以来，学界普遍假设个人的不同生物特征（如左、右眼虹膜、不同手指指纹等）之间是统计独立的。论文动机在于用现代深度学习方法实证这一假设的有效性。

Method: 论文采用ResNet-50和Vision Transformer作为Bi-Encoder主干网络，在指纹对比、虹膜对比和跨模态（指纹-虹膜）匹配三类任务上进行对比学习。数据集包括274名受试者、约10万个指纹和7千张虹膜图像，网络以最小化同一人样本间的对比损失为目标进行训练。

Result: 虹膜匹配的ResNet模型AUC达到91，说明个体的左右虹膜存在相关性。指纹模型也重现了过往文献发现的同一人指纹间的正相关。使用Vision Transformer为首例尝试，跨模态（指纹-虹膜）匹配效果仅略高于偶然，说明尚需更多数据和更复杂方法提升准确率。

Conclusion: 不同生物识别特征间独立性的传统假设受到挑战。未来工作将扩展至其它类型的生物特征。代码已公开。

Abstract: There has been a historic assumption that the biometrics of an individual are
statistically uncorrelated. We test this assumption by training Bi-Encoder
networks on three verification tasks, including fingerprint-to-fingerprint
matching, iris-to-iris matching, and cross-modal fingerprint-to-iris matching
using 274 subjects with $\sim$100k fingerprints and 7k iris images. We trained
ResNet-50 and Vision Transformer backbones in Bi-Encoder architectures such
that the contrastive loss between images sampled from the same individual is
minimized. The iris ResNet architecture reaches 91 ROC AUC score for
iris-to-iris matching, providing clear evidence that the left and right irises
of an individual are correlated. Fingerprint models reproduce the positive
intra-subject suggested by prior work in this space. This is the first work
attempting to use Vision Transformers for this matching. Cross-modal matching
rises only slightly above chance, which suggests that more data and a more
sophisticated pipeline is needed to obtain compelling results. These findings
continue challenge independence assumptions of biometrics and we plan to extend
this work to other biometrics in the future. Code available:
https://github.com/MatthewSo/bio_fingerprints_iris.

</details>


### [146] [Switchable Token-Specific Codebook Quantization For Face Image Compression](https://arxiv.org/abs/2510.22943)
*Yongbo Wang,Haonan Wang,Guodong Mu,Ruixin Zhang,Jiaqi Chen,Jingyun Zhang,Jun Wang,Yuan Xie,Zhizhong Zhang,Shouhong Ding*

Main category: cs.CV

TL;DR: 本文提出了一种针对人脸图像压缩的新方法：可切换的令牌特定码本量化（Switchable Token-Specific Codebook Quantization），有效提升低比特率下的重建质量。


<details>
  <summary>Details</summary>
Motivation: 当前主流基于码本（codebook）的图像压缩方案在处理人脸这样属性丰富的图像时，因采用单一全球码本，忽视了类别相关性和语义差异，导致低比特率下表现不佳。

Method: 提出将图像中的token分配到不同类别专属的码本组，并为每个token分配独立码本。通过记录每个token所属的码本组而只需消耗少量比特，可以有效减少每组码本缩小时带来的损失，从而在总体比特率较低时，支持更多码本、提升表达能力。

Result: 该方法在面部识别数据集上表现出色，在0.05 bpp下重建图像的识别准确率达到93.51%。

Conclusion: 本文方法不依赖于特定结构，可灵活集成到现有的基于码本的表示学习框架，能显著提升低比特率下的图像压缩与重建效果，尤其适合属性丰富的人脸图像。

Abstract: With the ever-increasing volume of visual data, the efficient and lossless
transmission, along with its subsequent interpretation and understanding, has
become a critical bottleneck in modern information systems. The emerged
codebook-based solution utilize a globally shared codebook to quantize and
dequantize each token, controlling the bpp by adjusting the number of tokens or
the codebook size. However, for facial images, which are rich in attributes,
such global codebook strategies overlook both the category-specific
correlations within images and the semantic differences among tokens, resulting
in suboptimal performance, especially at low bpp. Motivated by these
observations, we propose a Switchable Token-Specific Codebook Quantization for
face image compression, which learns distinct codebook groups for different
image categories and assigns an independent codebook to each token. By
recording the codebook group to which each token belongs with a small number of
bits, our method can reduce the loss incurred when decreasing the size of each
codebook group. This enables a larger total number of codebooks under a lower
overall bpp, thereby enhancing the expressive capability and improving
reconstruction performance. Owing to its generalizable design, our method can
be integrated into any existing codebook-based representation learning approach
and has demonstrated its effectiveness on face recognition datasets, achieving
an average accuracy of 93.51% for reconstructed images at 0.05 bpp.

</details>


### [147] [LightBagel: A Light-weighted, Double Fusion Framework for Unified Multimodal Understanding and Generation](https://arxiv.org/abs/2510.22946)
*Zeyu Wang,Zilong Chen,Chenhui Gou,Feng Li,Chaorui Deng,Deyao Zhu,Kunchang Li,Weihao Yu,Haoqin Tu,Haoqi Fan,Cihang Xie*

Main category: cs.CV

TL;DR: 本文提出了一种高效融合公开生成和理解专用多模态模型的方法，通过引入多模态自注意力模块，实现竞争性性能且资源消耗低。


<details>
  <summary>Details</summary>
Motivation: 当前领先的多模态模型虽然强大，但训练成本高、需大量资源。因此探索如何高效复用现有专用模型，实现资源节约且表现优异的统一多模态模型。

Method: 将公开的生成和理解模型原始结构保留，在网络中穿插多模态自注意力模块，实现“双重融合”：既保留原模型优势，同时增强高低层表达的互补融合。训练仅用约35B token。

Result: 在多项评测中取得强劲表现，包括GenEval 0.91、DPG-Bench 82.16、GEditBench 6.06和ImgEdit-Bench 3.77。

Conclusion: 所提方法能在大幅降低资源消耗下，提升多模态任务表现。全部开源将助力未来相关研究。

Abstract: Unified multimodal models have recently shown remarkable gains in both
capability and versatility, yet most leading systems are still trained from
scratch and require substantial computational resources. In this paper, we show
that competitive performance can be obtained far more efficiently by
strategically fusing publicly available models specialized for either
generation or understanding. Our key design is to retain the original blocks
while additionally interleaving multimodal self-attention blocks throughout the
networks. This double fusion mechanism (1) effectively enables rich multi-modal
fusion while largely preserving the original strengths of the base models, and
(2) catalyzes synergistic fusion of high-level semantic representations from
the understanding encoder with low-level spatial signals from the generation
encoder. By training with only ~ 35B tokens, this approach achieves strong
results across multiple benchmarks: 0.91 on GenEval for compositional
text-to-image generation, 82.16 on DPG-Bench for complex text-to-image
generation, 6.06 on GEditBench, and 3.77 on ImgEdit-Bench for image editing. By
fully releasing the entire suite of code, model weights, and datasets, we hope
to support future research on unified multimodal modeling.

</details>


### [148] [FAME: Fairness-aware Attention-modulated Video Editing](https://arxiv.org/abs/2510.22960)
*Zhangkai Wu,Xuhui Fan,Zhongyuan Xie,Kaize Shi,Zhidong Li,Longbing Cao*

Main category: cs.CV

TL;DR: 论文提出了FAME方法，用于在无训练的视频编辑中减少与职业相关的性别偏见，同时保持编辑结果的连贯性和对提示的符合度，并在新基准FairVE上取得了优于现有方法的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的无训练视频编辑模型在处理与职业相关的文本时容易强化性别刻板印象，缺乏对公平性的控制。作者希望解决这一公正性短板，使编辑结果在性别与职业结合时更加中立。

Method: 提出FAME框架，将公平性嵌入向量通过『软注入』方式加入文本编码器，并在时序自注意力和提示到区域交叉注意力中内嵌公平性调制。具体地，时序自注意力中使用区域约束的注意力掩码与时间衰减权重联合提升区域内一致性、减少区域间干扰。交叉注意力中则通过公平性感知的相似性掩码对匹配分数加权，确保公平性语义与正确视觉区域绑定，防止跨帧漂移。

Result: 在新提出的公平性视频编辑基准FairVE上，FAME在公平性一致性和语义保真度方面均优于当前视频编辑基线方法。

Conclusion: FAME有效缓解了职业相关性别偏见，在保证时空连贯与提示一致性的前提下提升了视频编辑模型的公平性，可为后续公正AI视频生成提供技术参考。

Abstract: Training-free video editing (VE) models tend to fall back on gender
stereotypes when rendering profession-related prompts. We propose \textbf{FAME}
for \textit{Fairness-aware Attention-modulated Video Editing} that mitigates
profession-related gender biases while preserving prompt alignment and temporal
consistency for coherent VE. We derive fairness embeddings from existing
minority representations by softly injecting debiasing tokens into the text
encoder. Simultaneously, FAME integrates fairness modulation into both temporal
self attention and prompt-to-region cross attention to mitigate the motion
corruption and temporal inconsistency caused by directly introducing fairness
cues. For temporal self attention, FAME introduces a region constrained
attention mask combined with time decay weighting, which enhances intra-region
coherence while suppressing irrelevant inter-region interactions. For cross
attention, it reweights tokens to region matching scores by incorporating
fairness sensitive similarity masks derived from debiasing prompt embeddings.
Together, these modulations keep fairness-sensitive semantics tied to the right
visual regions and prevent temporal drift across frames. Extensive experiments
on new VE fairness-oriented benchmark \textit{FairVE} demonstrate that FAME
achieves stronger fairness alignment and semantic fidelity, surpassing existing
VE baselines.

</details>


### [149] [Survey of Multimodal Geospatial Foundation Models: Techniques, Applications, and Challenges](https://arxiv.org/abs/2510.22964)
*Liling Yang,Ning Chen,Jun Yue,Yidan Liu,Jiayi Ma,Pedram Ghamisi,Antonio Plaza,Leyuan Fang*

Main category: cs.CV

TL;DR: 本文综述了多模态地理空间基础模型（GFMs）在遥感影像分析中的应用和最新进展，详细探讨了多模态模型的建模、应用与挑战。


<details>
  <summary>Details</summary>
Motivation: 遥感影像具有多模态、多分辨率和多时相等特点，传统方法难以充分利用其丰富信息。基础模型在NLP和CV领域取得巨大成功，因而有必要系统总结与分析GFMs对遥感的影响与挑战。

Method: 文章从模态驱动的视角出发，综述了五种核心视觉及视觉-语言模态，分析了不同成像物理和数据表达下模型交互设计、模态对齐、集成与知识迁移方法。此外，系统评估了当前训练范式、架构与下游任务适应策略，并总结了多个基准数据集及GFMs在十个任务上的表现。

Result: 代表性GFMs在土地覆盖、农业监测、灾害响应、气候、地理空间情报等实际场景下均展示了良好性能。文中还总结了现有模型在结构、性能和应用场景方面的优势与不足。

Conclusion: GFMs为遥感分析提供了强大的泛化能力和知识迁移潜力，但仍面临领域泛化、模型可解释性、效率和隐私等挑战。文末提出了未来有前景的研究方向。

Abstract: Foundation models have transformed natural language processing and computer
vision, and their impact is now reshaping remote sensing image analysis. With
powerful generalization and transfer learning capabilities, they align
naturally with the multimodal, multi-resolution, and multi-temporal
characteristics of remote sensing data. To address unique challenges in the
field, multimodal geospatial foundation models (GFMs) have emerged as a
dedicated research frontier. This survey delivers a comprehensive review of
multimodal GFMs from a modality-driven perspective, covering five core visual
and vision-language modalities. We examine how differences in imaging physics
and data representation shape interaction design, and we analyze key techniques
for alignment, integration, and knowledge transfer to tackle modality
heterogeneity, distribution shifts, and semantic gaps. Advances in training
paradigms, architectures, and task-specific adaptation strategies are
systematically assessed alongside a wealth of emerging benchmarks.
Representative multimodal visual and vision-language GFMs are evaluated across
ten downstream tasks, with insights into their architectures, performance, and
application scenarios. Real-world case studies, spanning land cover mapping,
agricultural monitoring, disaster response, climate studies, and geospatial
intelligence, demonstrate the practical potential of GFMs. Finally, we outline
pressing challenges in domain generalization, interpretability, efficiency, and
privacy, and chart promising avenues for future research.

</details>


### [150] [VALA: Learning Latent Anchors for Training-Free and Temporally Consistent](https://arxiv.org/abs/2510.22970)
*Zhangkai Wu,Xuhui Fan,Zhongyuan Xie,Kaize Shi,Longbing Cao*

Main category: cs.CV

TL;DR: 论文提出了一种新的无训练视频编辑方法VALA，可以自适应选择关键帧并对潜特征进行压缩，实现跨帧一致的视频编辑，实验结果达到最新性能。


<details>
  <summary>Details</summary>
Motivation: 现有无训练视频编辑方法依赖于人工启发式选帧，容易引入人为偏差，影响效率和推理的端到端能力。因此需要一种自动且高效维护时序一致性的方法。

Method: 提出了VALA（Variational Alignment for Latent Anchors），该模块自适应选择关键帧，并将其潜空间特征压缩成用于保持一致性的语义锚点。方法基于变分框架并结合对比学习目标，能有效学习有意义的关键帧分配和潜特征压缩。该方法可以无缝融入基于text-to-image扩散模型的视频编辑流程。

Result: 在真实视频编辑基准上进行全面实验，验证VALA在反演保真度、编辑质量和时序一致性方面都达到SOTA水平，且效率优于现有方法。

Conclusion: VALA能提升基于现有扩散模型的无训练视频编辑的端到端性能，兼具高效率与高编辑质量，消除了人工选帧带来的局限和偏差。

Abstract: Recent advances in training-free video editing have enabled lightweight and
precise cross-frame generation by leveraging pre-trained text-to-image
diffusion models. However, existing methods often rely on heuristic frame
selection to maintain temporal consistency during DDIM inversion, which
introduces manual bias and reduces the scalability of end-to-end inference. In
this paper, we propose~\textbf{VALA} (\textbf{V}ariational \textbf{A}lignment
for \textbf{L}atent \textbf{A}nchors), a variational alignment module that
adaptively selects key frames and compresses their latent features into
semantic anchors for consistent video editing. To learn meaningful assignments,
VALA propose a variational framework with a contrastive learning objective.
Therefore, it can transform cross-frame latent representations into compressed
latent anchors that preserve both content and temporal coherence. Our method
can be fully integrated into training-free text-to-image based video editing
models. Extensive experiments on real-world video editing benchmarks show that
VALA achieves state-of-the-art performance in inversion fidelity, editing
quality, and temporal consistency, while offering improved efficiency over
prior methods.

</details>


### [151] [Scaling Up Occupancy-centric Driving Scene Generation: Dataset and Method](https://arxiv.org/abs/2510.22973)
*Bohan Li,Xin Jin,Hu Zhu,Hongsi Liu,Ruikai Li,Jiazhe Guo,Kaiwen Cai,Chao Ma,Yueming Jin,Hao Zhao,Xiaokang Yang,Wenjun Zeng*

Main category: cs.CV

TL;DR: 本文提出了Nuplan-Occ，这是迄今为止最大规模的语义occupancy（占用）数据集，并基于此开发了一套统一的自动驾驶场景生成框架，可高质量生成语义占用、多视角视频和LiDAR点云。新方法在多模态、高时空分辨率数据生成上表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有occupancy-centric自动驾驶场景生成方法依赖于稀缺的标注occupancy数据，限制了模型性能和应用规模。为了突破数据瓶颈，促进大规模生成和下游应用，亟需更大、更多样的occupancy数据集及相应生成方法。

Method: 作者整理并发布了Nuplan-Occ大规模数据集。方法上，提出了一个时空解耦生成架构，能支持高质量4D动态场景生成；创新性地引入高斯投影稀疏点云渲染提升多视角视频生成，以及感知器建模策略增强多LiDAR模拟，提升了生成系统的兼容性和真实性。

Result: 实验显示，提出的方法在生成质量与扩展性上均优于现有方法，并在自动驾驶相关下游任务中展现出实际应用价值。

Conclusion: 本文通过丰富occupancy数据集和提出统一生成模型，推动了自动驾驶场景的高质量多模态生成，验证了其在实际自动驾驶场景中的潜力。

Abstract: Driving scene generation is a critical domain for autonomous driving,
enabling downstream applications, including perception and planning evaluation.
Occupancy-centric methods have recently achieved state-of-the-art results by
offering consistent conditioning across frames and modalities; however, their
performance heavily depends on annotated occupancy data, which still remains
scarce. To overcome this limitation, we curate Nuplan-Occ, the largest semantic
occupancy dataset to date, constructed from the widely used Nuplan benchmark.
Its scale and diversity facilitate not only large-scale generative modeling but
also autonomous driving downstream applications. Based on this dataset, we
develop a unified framework that jointly synthesizes high-quality semantic
occupancy, multi-view videos, and LiDAR point clouds. Our approach incorporates
a spatio-temporal disentangled architecture to support high-fidelity spatial
expansion and temporal forecasting of 4D dynamic occupancy. To bridge modal
gaps, we further propose two novel techniques: a Gaussian splatting-based
sparse point map rendering strategy that enhances multi-view video generation,
and a sensor-aware embedding strategy that explicitly models LiDAR sensor
properties for realistic multi-LiDAR simulation. Extensive experiments
demonstrate that our method achieves superior generation fidelity and
scalability compared to existing approaches, and validates its practical value
in downstream tasks. Repo:
https://github.com/Arlo0o/UniScene-Unified-Occupancy-centric-Driving-Scene-Generation/tree/v2

</details>


### [152] [VoMP: Predicting Volumetric Mechanical Property Fields](https://arxiv.org/abs/2510.22975)
*Rishit Dagli,Donglai Xiang,Vismay Modi,Charles Loop,Clement Fuji Tsang,Anka He Chen,Anita Hu,Gavriel State,David I. W. Levin,Maria Shugrina*

Main category: cs.CV

TL;DR: VoMP是一种新颖的机器学习方法，可以自动、精准且高效地为任意三维对象预测每个体素的材料属性（杨氏模量、泊松比和密度），无需繁琐手工设置。


<details>
  <summary>Details</summary>
Motivation: 物理仿真高度依赖于空间变化的力学属性，然而传统上这些属性通常需要手动、耗时且主观地赋值，影响了仿真效率和真实感，因此亟需自动化且准确地推断物体内部各区域的材料属性的方法。

Method: 作者提出了VoMP，一种端到端的前馈方法。流程包括：对3D物体进行多视角渲染并体素化，基于体素级的多视角特征，通过训练好的Geometry Transformer生成每体素的材料潜变量，这些变量在学习到的可行材料流形上，确保解码后的材料物性合理。训练数据通过将带分割的3D数据集、材料数据库和视觉-语言模型联合，以及新创建的基准数据集构建标注管线获得。

Result: 实验证明，VoMP能够显著提升体积属性的预测准确度和推理速度，远超已有方法。

Conclusion: VoMP为物理仿真提供了一种高效自动的材料属性预测新工具，大大简化了三维物体的物性赋值流程，有望推动更高效真实的仿真系统发展。

Abstract: Physical simulation relies on spatially-varying mechanical properties, often
laboriously hand-crafted. VoMP is a feed-forward method trained to predict
Young's modulus ($E$), Poisson's ratio ($\nu$), and density ($\rho$) throughout
the volume of 3D objects, in any representation that can be rendered and
voxelized. VoMP aggregates per-voxel multi-view features and passes them to our
trained Geometry Transformer to predict per-voxel material latent codes. These
latents reside on a manifold of physically plausible materials, which we learn
from a real-world dataset, guaranteeing the validity of decoded per-voxel
materials. To obtain object-level training data, we propose an annotation
pipeline combining knowledge from segmented 3D datasets, material databases,
and a vision-language model, along with a new benchmark. Experiments show that
VoMP estimates accurate volumetric properties, far outperforming prior art in
accuracy and speed.

</details>


### [153] [SceneDecorator: Towards Scene-Oriented Story Generation with Scene Planning and Scene Consistency](https://arxiv.org/abs/2510.22994)
*Quanjian Song,Donghao Zhou,Jingyu Lin,Fei Shen,Jiaze Wang,Xiaowei Hu,Cunjian Chen,Pheng-Ann Heng*

Main category: cs.CV

TL;DR: 针对现有文本生成图像模型难以保证叙事场景一致性的问题，提出了SceneDecorator框架，提升生成故事的场景连贯性和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成多图像故事时，更多关注角色一致性，忽略了对叙事中场景的持续性控制，导致故事场景碎片化、缺乏连贯性，创意受限。

Method: 提出SceneDecorator框架：1）通过VLM-Guided Scene Planning，从全局到局部方式制定场景计划，提升叙事连贯性；2）采用Long-Term Scene-Sharing Attention机制，实现多个故事间长期场景一致与主体多样化。该方法无需额外训练。

Result: 在多组实验中，SceneDecorator在场景一致性和故事多样性上均优于现有方法，表现出更强的叙事和创新能力。

Conclusion: SceneDecorator能够有效提升文本到多图像故事生成任务中的场景一致性和创造力，适合应用于艺术、影视、游戏等多个领域。

Abstract: Recent text-to-image models have revolutionized image generation, but they
still struggle with maintaining concept consistency across generated images.
While existing works focus on character consistency, they often overlook the
crucial role of scenes in storytelling, which restricts their creativity in
practice. This paper introduces scene-oriented story generation, addressing two
key challenges: (i) scene planning, where current methods fail to ensure
scene-level narrative coherence by relying solely on text descriptions, and
(ii) scene consistency, which remains largely unexplored in terms of
maintaining scene consistency across multiple stories. We propose
SceneDecorator, a training-free framework that employs VLM-Guided Scene
Planning to ensure narrative coherence across different scenes in a
``global-to-local'' manner, and Long-Term Scene-Sharing Attention to maintain
long-term scene consistency and subject diversity across generated stories.
Extensive experiments demonstrate the superior performance of SceneDecorator,
highlighting its potential to unleash creativity in the fields of arts, films,
and games.

</details>


### [154] [LoMix: Learnable Weighted Multi-Scale Logits Mixing for Medical Image Segmentation](https://arxiv.org/abs/2510.22995)
*Md Mostafijur Rahman,Radu Marculescu*

Main category: cs.CV

TL;DR: 该论文提出了一种新方法LoMix，通过多尺度融合U型网络的logits，显著提升了医学分割任务的性能。


<details>
  <summary>Details</summary>
Motivation: U型网络不同尺度输出捕获到粗细不同的信息，但现有训练方法往往独立监督每个尺度，未能充分融合多尺度的互补信息，导致性能受限。

Method: 提出LoMix模块，将不同尺度的logits通过加法、乘法、拼接和基于注意力的融合等四种轻量操作混合，生成新的mutant maps，并为每个原始或混合输出分配可学习的损失权重，联合优化实现自动搜索最优融合方式。

Result: LoMix融入PVT-V2-B2+EMCAD等U型架构，在Synapse 8-organ等数据集上，DICE系数较单一输出提升4.2%、较深监督提升2.2%、较简单加权提升1.5%，且无推理时开销。数据稀缺时效果更佳，提升9.23%。在四个基准和多种U型网络上，最高提升13.5%。

Conclusion: LoMix能自动学习混合多尺度网络输出的最优方式，在多场景下提升精度，特别适合数据有限场景，完全可解释且无额外推理开销，泛化能力强。

Abstract: U-shaped networks output logits at multiple spatial scales, each capturing a
different blend of coarse context and fine detail. Yet, training still treats
these logits in isolation - either supervising only the final,
highest-resolution logits or applying deep supervision with identical loss
weights at every scale - without exploring mixed-scale combinations.
Consequently, the decoder output misses the complementary cues that arise only
when coarse and fine predictions are fused. To address this issue, we introduce
LoMix (Logits Mixing), a NAS-inspired, differentiable plug-and-play module that
generates new mixed-scale outputs and learns how exactly each of them should
guide the training process. More precisely, LoMix mixes the multi-scale decoder
logits with four lightweight fusion operators: addition, multiplication,
concatenation, and attention-based weighted fusion, yielding a rich set of
synthetic mutant maps. Every original or mutant map is given a softplus loss
weight that is co-optimized with network parameters, mimicking a one-step
architecture search that automatically discovers the most useful scales,
mixtures, and operators. Plugging LoMix into recent U-shaped architectures
(i.e., PVT-V2-B2 backbone with EMCAD decoder) on Synapse 8-organ dataset
improves DICE by +4.2% over single-output supervision, +2.2% over deep
supervision, and +1.5% over equally weighted additive fusion, all with zero
inference overhead. When training data are scarce (e.g., one or two labeled
scans), the advantage grows to +9.23%, underscoring LoMix's data efficiency.
Across four benchmarks and diverse U-shaped networks, LoMiX improves DICE by up
to +13.5% over single-output supervision, confirming that learnable weighted
mixed-scale fusion generalizes broadly while remaining data efficient, fully
interpretable, and overhead-free at inference. Our code is available at
https://github.com/SLDGroup/LoMix.

</details>


### [155] [CoMo: Compositional Motion Customization for Text-to-Video Generation](https://arxiv.org/abs/2510.23007)
*Youcan Xu,Zhen Wang,Jiaxin Shi,Kexin Li,Feifei Shao,Jun Xiao,Yi Yang,Jun Yu,Long Chen*

Main category: cs.CV

TL;DR: 本文提出了CoMo框架，实现了文本驱动的视频生成中多重动作的可组合定制，解决了复杂、多主体动作精准控制这一难题，并在多动作融合方面达到新水平。


<details>
  <summary>Details</summary>
Motivation: 当前的文本生成视频模型在动作精准控制上表现不佳，特别是在涉及多个主体、复杂动作时。已有的个性化动作定制方法在组合场景下因动作与外观纠缠、动作融合不佳而失效，因此亟需一种新方法突破这一限制。

Method: CoMo采用两阶段方法：首先，单动作学习阶段通过静态-动态解耦，利用动作专属模块实现动作与外观的分离；其次，多动作组合阶段则采用分区与合并策略，在去噪流程中空间隔离各动作影响，实现无需额外训练的插件式组合，多动作融合更自然。

Result: 作者建立新基准与评价指标，评估多动作的保真度与融合效果。实验表明，CoMo在多动作可控生成任务上取得了当前最优（SOTA）表现。

Conclusion: CoMo显著提升了多动作可控生成视频的能力，为相关研究带来了里程碑式进展。

Abstract: While recent text-to-video models excel at generating diverse scenes, they
struggle with precise motion control, particularly for complex, multi-subject
motions. Although methods for single-motion customization have been developed
to address this gap, they fail in compositional scenarios due to two primary
challenges: motion-appearance entanglement and ineffective multi-motion
blending. This paper introduces CoMo, a novel framework for
$\textbf{compositional motion customization}$ in text-to-video generation,
enabling the synthesis of multiple, distinct motions within a single video.
CoMo addresses these issues through a two-phase approach. First, in the
single-motion learning phase, a static-dynamic decoupled tuning paradigm
disentangles motion from appearance to learn a motion-specific module. Second,
in the multi-motion composition phase, a plug-and-play divide-and-merge
strategy composes these learned motions without additional training by
spatially isolating their influence during the denoising process. To facilitate
research in this new domain, we also introduce a new benchmark and a novel
evaluation metric designed to assess multi-motion fidelity and blending.
Extensive experiments demonstrate that CoMo achieves state-of-the-art
performance, significantly advancing the capabilities of controllable video
generation. Our project page is at https://como6.github.io/.

</details>


### [156] [UGAE: Unified Geometry and Attribute Enhancement for G-PCC Compressed Point Clouds](https://arxiv.org/abs/2510.23009)
*Pan Zhao,Hui Yuan,Chongzhen Tian,Tian Guo,Raouf Hamzaoui,Zhigeng Pan*

Main category: cs.CV

TL;DR: 本文提出了一种统一的几何与属性增强（UGAE）框架，有效提升了有损压缩点云的几何和属性重建质量，并在基准数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 有损压缩虽减少了点云的存储和传输成本，但会不可避免地带来几何结构和属性信息的失真。现有的方法在恢复几何或属性时效果有限，因此亟需一种能同时增强几何与属性的高效方法。

Method: UGAE框架包括三大组件：1）基于Transformer和稀疏卷积U-Net的几何后增强（PoGE），精准恢复点云几何结构；2）引入细节感知K近邻法（DA-KNN）的属性前增强（PAE），在属性压缩前进行高保真再上色；3）解码端基于带权MSE损失的属性残差预测网络（PoAE），提升高频区域属性质量。

Result: 在8iVFB、Owlii和MVUB三个数据集上，UGAE在D1指标下，几何重建的平均BD-PSNR提高9.98 dB，BD-bitrate节省90.98%；属性的Y分量BD-PSNR提升3.67 dB，BD-bitrate节省56.88%。感知质量也有显著提升，全面超越G-PCC最新测试模型（TMC13v29）。

Conclusion: UGAE框架能够有效缓解点云有损压缩带来的失真问题，在提升几何和属性重建质量的同时，显著降低比特率，具有广阔的应用前景。

Abstract: Lossy compression of point clouds reduces storage and transmission costs;
however, it inevitably leads to irreversible distortion in geometry structure
and attribute information. To address these issues, we propose a unified
geometry and attribute enhancement (UGAE) framework, which consists of three
core components: post-geometry enhancement (PoGE), pre-attribute enhancement
(PAE), and post-attribute enhancement (PoAE). In PoGE, a Transformer-based
sparse convolutional U-Net is used to reconstruct the geometry structure with
high precision by predicting voxel occupancy probabilities. Building on the
refined geometry structure, PAE introduces an innovative enhanced
geometry-guided recoloring strategy, which uses a detail-aware K-Nearest
Neighbors (DA-KNN) method to achieve accurate recoloring and effectively
preserve high-frequency details before attribute compression. Finally, at the
decoder side, PoAE uses an attribute residual prediction network with a
weighted mean squared error (W-MSE) loss to enhance the quality of
high-frequency regions while maintaining the fidelity of low-frequency regions.
UGAE significantly outperformed existing methods on three benchmark datasets:
8iVFB, Owlii, and MVUB. Compared to the latest G-PCC test model (TMC13v29),
UGAE achieved an average BD-PSNR gain of 9.98 dB and 90.98% BD-bitrate savings
for geometry under the D1 metric, as well as a 3.67 dB BD-PSNR improvement with
56.88% BD-bitrate savings for attributes on the Y component. Additionally, it
improved perceptual quality significantly.

</details>


### [157] [Nested AutoRegressive Models](https://arxiv.org/abs/2510.23028)
*Hongyu Wu,Xuhui Fan,Zhangkai Wu,Longbing Cao*

Main category: cs.CV

TL;DR: 提出了NestAR模型，在保证生成质量和多样性的同时，大幅提升了自回归模型的计算效率。


<details>
  <summary>Details</summary>
Motivation: 当前自回归（AR）模型在图像生成任务中表现良好，但由于逐个token生成方式，计算成本高，且现有加速方法如VAR会牺牲样本多样性。亟需新方法突破效率和多样性的矛盾。

Method: 设计Hierarchical的多尺度嵌套自回归（NestAR）结构，较大尺度模块依赖前一小尺度模块的输出，并在每个尺度内以AR结构生成图像patch，从而整体复杂度从O(n)降至O(log n)。还引入flow matching损失和协调多尺度目标以优化训练。

Result: NestAR在保持或超越当前主流方法的生成性能的同时，大幅降低了生成的计算成本，并提升了图像多样性。

Conclusion: NestAR是一种高效的图像生成自回归模型，在计算复杂度和样本多样性上优于普通AR方法，具有实际应用潜力。

Abstract: AutoRegressive (AR) models have demonstrated competitive performance in image
generation, achieving results comparable to those of diffusion models. However,
their token-by-token image generation mechanism remains computationally
intensive and existing solutions such as VAR often lead to limited sample
diversity. In this work, we propose a Nested AutoRegressive~(NestAR) model,
which proposes nested AutoRegressive architectures in generating images. NestAR
designs multi-scale modules in a hierarchical order. These different scaled
modules are constructed in an AR architecture, where one larger-scale module is
conditioned on outputs from its previous smaller-scale module. Within each
module, NestAR uses another AR structure to generate ``patches'' of tokens. The
proposed nested AR architecture reduces the overall complexity from
$\mathcal{O}(n)$ to $\mathcal{O}(\log n)$ in generating $n$ image tokens, as
well as increases image diversities. NestAR further incorporates flow matching
loss to use continuous tokens, and develops objectives to coordinate these
multi-scale modules in model training. NestAR achieves competitive image
generation performance while significantly lowering computational cost.

</details>


### [158] [HieraMamba: Video Temporal Grounding via Hierarchical Anchor-Mamba Pooling](https://arxiv.org/abs/2510.23043)
*Joungbin An,Kristen Grauman*

Main category: cs.CV

TL;DR: HieraMamba是一种新的分层架构方法，用于长视频中精准地定位与自然语言查询相关的时间段，显著提升了现有方法的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的视频时序定位方法在处理长视频时，常因过度下采样或固定窗口而牺牲时间精度，难以同时获取全局上下文和细粒度时序信息。本文旨在解决这一矛盾，实现更精细的定位能力。

Method: 提出了HieraMamba架构，利用分层结构和Anchor-MambaPooling（AMP）模块，在不同粒度上生成精炼锚点token以保留视频内容。通过锚点条件和区段池化对比损失，兼顾局部细节和全局判别。

Result: HieraMamba方法在Ego4D-NLQ、MAD和TACoS等数据集上达到了新的SOTA水平，展现了长视频下高精度、时序响应能力的提升。

Conclusion: HieraMamba显著改进了长视频时序定位任务，实现了更高的精度和更好的时序一致性，为自然语言视频检索领域带来了新的进展。

Abstract: Video temporal grounding, the task of localizing the start and end times of a
natural language query in untrimmed video, requires capturing both global
context and fine-grained temporal detail. This challenge is particularly
pronounced in long videos, where existing methods often compromise temporal
fidelity by over-downsampling or relying on fixed windows. We present
HieraMamba, a hierarchical architecture that preserves temporal structure and
semantic richness across scales. At its core are Anchor-MambaPooling (AMP)
blocks, which utilize Mamba's selective scanning to produce compact anchor
tokens that summarize video content at multiple granularities. Two
complementary objectives, anchor-conditioned and segment-pooled contrastive
losses, encourage anchors to retain local detail while remaining globally
discriminative. HieraMamba sets a new state-of-the-art on Ego4D-NLQ, MAD, and
TACoS, demonstrating precise, temporally faithful localization in long,
untrimmed videos.

</details>


### [159] [Strategies for Robust Deep Learning Based Deformable Registration](https://arxiv.org/abs/2510.23079)
*Joel Honkamaa,Pekka Marttinen*

Main category: cs.CV

TL;DR: 本文提出一种在深度学习图像配准任务中提升泛化能力的方法，通过将输入影像先转换为MIND特征空间，再输入配准模型，并结合特有的集成策略，显著增强模型在不同对比度和模态下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 虽然基于深度学习的形变配准方法应用广泛，但其对训练集分布之外的数据泛化能力较差。因此，旨在提升模型在不同影像对比度和模态下的实用性和适应性。

Method: 核心方法是在模型输入前，将原始影像转换为MIND特征空间，以提高对模态和对比度差异的鲁棒性；同时采用特殊的模型集成策略，进一步提升整体配准效果。

Result: 在Learn2Reg 2025比赛的LUMIR大脑配准挑战中，提交的方法在训练集中未出现的新对比度及新模态数据上展示了显著优于传统方法的表现，集成策略也带来了小但稳定的性能增益。

Conclusion: 通过引入MIND特征变换和特殊集成机制，本方法可显著提升深度学习形变配准模型的泛化与鲁棒性，对实际多模态、多对比度医学影像配准任务具有参考价值。

Abstract: Deep learning based deformable registration methods have become popular in
recent years. However, their ability to generalize beyond training data
distribution can be poor, significantly hindering their usability. LUMIR brain
registration challenge for Learn2Reg 2025 aims to advance the field by
evaluating the performance of the registration on contrasts and modalities
different from those included in the training set. Here we describe our
submission to the challenge, which proposes a very simple idea for
significantly improving robustness by transforming the images into MIND feature
space before feeding them into the model. In addition, a special ensembling
strategy is proposed that shows a small but consistent improvement.

</details>


### [160] [Revisiting Multimodal Positional Encoding in Vision-Language Models](https://arxiv.org/abs/2510.23095)
*Jie Huang,Xuejing Liu,Sibo Song,Ruibing Hou,Hong Chang,Junyang Lin,Shuai Bai*

Main category: cs.CV

TL;DR: 本文系统性分析了多模态自回归位置编码（RoPE），并提出了两种新的变体，大幅提升了视觉-语言模型的多模态理解能力。


<details>
  <summary>Details</summary>
Motivation: 多模态位置编码对视觉-语言模型至关重要，但至今缺乏系统研究，尤其是如何设计和分配频率等核心细节仍不明确。

Method: 作者对多模态RoPE的两大核心：位置设计和频率分配进行了深入实验，提出“三大准则”：位置连贯性、频率充分利用、文本迁移的先验保持，并据此提出了Multi-Head RoPE（MHRoPE）和MRoPE-Interleave（MRoPE-I）两种无需改动架构的简便增强方法。

Result: 两种新方法在多种主流基准和细粒度多模态理解任务上均显著优于现有方法，表现出更好的通用和细致表现。

Conclusion: 论文为多模态位置编码提供了理论与实践的创新方案，提出的插件式方法具备优越性，有望成为视觉-语言模型中的标准选择。

Abstract: Multimodal position encoding is essential for vision-language models, yet
there has been little systematic investigation into multimodal position
encoding. We conduct a comprehensive analysis of multimodal Rotary Positional
Embedding (RoPE) by examining its two core components: position design and
frequency allocation. Through extensive experiments, we identify three key
guidelines: positional coherence, full frequency utilization, and preservation
of textual priors-ensuring unambiguous layout, rich representation, and
faithful transfer from the pre-trained LLM. Based on these insights, we propose
Multi-Head RoPE (MHRoPE) and MRoPE-Interleave (MRoPE-I), two simple and
plug-and-play variants that require no architectural changes. Our methods
consistently outperform existing approaches across diverse benchmarks, with
significant improvements in both general and fine-grained multimodal
understanding. Code will be avaliable at
https://github.com/JJJYmmm/Multimodal-RoPEs.

</details>


### [161] [Residual Diffusion Bridge Model for Image Restoration](https://arxiv.org/abs/2510.23116)
*Hebaixu Wang,Jing Zhang,Haoyang Chen,Haonan Guo,Di Wang,Jiayi Ma,Bo Du*

Main category: cs.CV

TL;DR: 本文提出了一种全新的残差扩散桥模型（RDBM），用于图像复原，理论上统一并推广了现有扩散桥方法，并能自适应地处理图像退化区域，实现更优的图像修复效果。


<details>
  <summary>Details</summary>
Motivation: 当前扩散桥模型在处理全局噪声注入与移除时，容易损坏原本未受损的区域，缺乏对图像局部结构的适应性，同时缺少理论统一视角。

Method: 理论上重构了广义扩散桥的随机微分方程，推导其前向与逆向过程的解析公式，创新性地引入残差机制调节噪声注入/移除，仅自适应地复原退化区域，并将现有桥模型推广为此通用模型的特例。

Result: 实验表明，所提出的RDBM在多项图像复原任务中，无论定性还是定量都优于现有方法，达到了当前最优水平。

Conclusion: RDBM不仅理论上统一了扩散桥模型，而且通过残差调制取得了更优的局部自适应修复能力，为图像复原领域提供了新范式，并展示了显著性能提升。

Abstract: Diffusion bridge models establish probabilistic paths between arbitrary
paired distributions and exhibit great potential for universal image
restoration. Most existing methods merely treat them as simple variants of
stochastic interpolants, lacking a unified analytical perspective. Besides,
they indiscriminately reconstruct images through global noise injection and
removal, inevitably distorting undegraded regions due to imperfect
reconstruction. To address these challenges, we propose the Residual Diffusion
Bridge Model (RDBM). Specifically, we theoretically reformulate the stochastic
differential equations of generalized diffusion bridge and derive the
analytical formulas of its forward and reverse processes. Crucially, we
leverage the residuals from given distributions to modulate the noise injection
and removal, enabling adaptive restoration of degraded regions while preserving
intact others. Moreover, we unravel the fundamental mathematical essence of
existing bridge models, all of which are special cases of RDBM and empirically
demonstrate the optimality of our proposed models. Extensive experiments are
conducted to demonstrate the state-of-the-art performance of our method both
qualitatively and quantitatively across diverse image restoration tasks. Code
is publicly available at https://github.com/MiliLab/RDBM.

</details>


### [162] [Task-Agnostic Fusion of Time Series and Imagery for Earth Observation](https://arxiv.org/abs/2510.23118)
*Gianfranco Basile,Johannes Jakubik,Benedikt Blumenstiel,Thomas Brunschwiler,Juan Bernabe Moreno*

Main category: cs.CV

TL;DR: 本文提出了一种面向多模态融合的新框架，用于结合时序数据和单时刻图像，实现跨模态生成和下游任务的高鲁棒性。实验证明该方法优于现有专用融合方法和基线。


<details>
  <summary>Details</summary>
Motivation: 当前多模态数据融合，尤其是时序数据与图像的融合方法有限，且往往需要为具体任务设计，缺乏通用性。作者希望设计一种任务无关、能促进跨模态表示学习和提升下游任务表现的方法。

Method: 提出了时间序列量化的确定性和学习型策略，并利用掩码相关性学习目标对图像和时序数据的离散token进行对齐，从而在统一的表示空间中建模。该方法在地球观测领域进行实例化，通过预训练生成全球气温剖面，并通过反事实实验验证。

Result: 预训练模型在下游任务上的平均R^2提升6%，RMSE降低2%；相比基线，R^2提升50%，RMSE降低12%。还分析了跨模态梯度敏感性，进一步阐释模型对不同模态的鲁棒性。

Conclusion: 所提框架显著提升了多模态数据融合的下游任务表现，并具备较强的鲁棒性和通用性，为相关领域提供了强有力的技术方案，后续将开放资源，促进社区发展。

Abstract: We propose a task-agnostic framework for multimodal fusion of time series and
single timestamp images, enabling cross-modal generation and robust downstream
performance. Our approach explores deterministic and learned strategies for
time series quantization and then leverages a masked correlation learning
objective, aligning discrete image and time series tokens in a unified
representation space. Instantiated in the Earth observation domain, the
pretrained model generates consistent global temperature profiles from
satellite imagery and is validated through counterfactual experiments. Across
downstream tasks, our task-agnostic pretraining outperforms task-specific
fusion by 6\% in R$^2$ and 2\% in RMSE on average, and exceeds baseline methods
by 50\% in R$^2$ and 12\% in RMSE. Finally, we analyze gradient sensitivity
across modalities, providing insights into model robustness. Code, data, and
weights will be released under a permissive license.

</details>


### [163] [DeepSalt: Bridging Laboratory and Satellite Spectra through Domain Adaptation and Knowledge Distillation for Large-Scale Soil Salinity Estimation](https://arxiv.org/abs/2510.23124)
*Rupasree Dey,Abdul Matin,Everett Lewark,Tanjim Bin Faruk,Andrei Bachinin,Sam Leuthold,M. Francesca Cotrufo,Shrideep Pallickara,Sangmi Lee Pallickara*

Main category: cs.CV

TL;DR: 本文提出了DeepSalt，一个基于深度学习的光谱迁移框架，实现了将实验室高分辨率光谱信息迁移到卫星高光谱遥感数据中，从而提升了大尺度土壤盐分监测的精度和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 土壤盐渍化对生态和农业危害巨大，现有基于实验室的光谱监测精确但难以大规模应用，而基于卫星的监测覆盖广但信息有限，因此需要新的方法将实验室精确信息迁移到遥感监测中。

Method: 提出DeepSalt框架，融合知识蒸馏与新颖的光谱自适应单元，将实验室光谱数据的详细信息迁移到卫星高光谱数据，实现无需大量地面采样的高精度土壤盐分估算。

Result: 经实验证明，DeepSalt在没有显式领域自适应的方法上实现了显著性能提升，所提光谱自适应单元和知识蒸馏方法贡献突出，且模型对未见过的地理区域有较好泛化能力，可解释大部分盐分变异。

Conclusion: DeepSalt为大尺度、高精度土壤盐分遥感估算提供了创新方法，显著减少对地面采样的依赖，为生态环境和农业监测提供了新技术路径。

Abstract: Soil salinization poses a significant threat to both ecosystems and
agriculture because it limits plants' ability to absorb water and, in doing so,
reduces crop productivity. This phenomenon alters the soil's spectral
properties, creating a measurable relationship between salinity and light
reflectance that enables remote monitoring. While laboratory spectroscopy
provides precise measurements, its reliance on in-situ sampling limits
scalability to regional or global levels. Conversely, hyperspectral satellite
imagery enables wide-area observation but lacks the fine-grained
interpretability of laboratory instruments. To bridge this gap, we introduce
DeepSalt, a deep-learning-based spectral transfer framework that leverages
knowledge distillation and a novel Spectral Adaptation Unit to transfer
high-resolution spectral insights from laboratory-based spectroscopy to
satellite-based hyperspectral sensing. Our approach eliminates the need for
extensive ground sampling while enabling accurate, large-scale salinity
estimation, as demonstrated through comprehensive empirical benchmarks.
DeepSalt achieves significant performance gains over methods without explicit
domain adaptation, underscoring the impact of the proposed Spectral Adaptation
Unit and the knowledge distillation strategy. The model also effectively
generalized to unseen geographic regions, explaining a substantial portion of
the salinity variance.

</details>


### [164] [Note on the Construction of Structure Tensor](https://arxiv.org/abs/2510.23137)
*Josef Bigun,Fernado Alonso-Fernandez*

Main category: cs.CV

TL;DR: 本文比较了两种结构张量的理论构建方式，并指出它们实际可通过总最小二乘拟合视角统一本质差别。这样可以使结构张量的数学解释和应用更加简化和广泛。


<details>
  <summary>Details</summary>
Motivation: 结构张量在图像分析、特征提取等领域应用广泛，但不同的构建方法在形式和实现上存在差异，给理解和应用带来障碍。作者希望探索其理论联系，并寻找更简明和通用的解释框架。

Method: 作者从总最小二乘（Total Least Squares, TLS）直线拟合功率谱的统一视角，对比和分析了Bigun和Granlund（1987）以及Granlund和Knutsson（1995）提出的两种结构张量构建方法，指出校正项的冗余性，并探讨了对滤波器类型和分解方式的放宽。

Result: 证明Granlund和Knutsson方法中的校正项可以去除，结构张量依然保持正半定，简化了特征值的物理解释。同时，多方向拟合、非四分滤波器、非角度分解（如Gabor滤波器）的可能性得以扩展。

Conclusion: 不同结构张量的理论基础可统一。简化处理后，结构张量解释性增强，适用范围扩展，有助于更多类型滤波器的灵活应用。

Abstract: This note presents a theoretical discussion of two structure tensor
constructions: one proposed by Bigun and Granlund 1987, and the other by
Granlund and Knutsson 1995. At first glance, these approaches may appear quite
different--the former is implemented by averaging outer products of gradient
filter responses, while the latter constructs the tensor from weighted outer
products of tune-in frequency vectors of quadrature filters. We argue that when
both constructions are viewed through the common lens of Total Least Squares
(TLS) line fitting to the power spectrum, they can be reconciled to a large
extent, and additional benefits emerge. From this perspective, the correction
term introduced in Granlund and Knutsson 1995 becomes unnecessary. Omitting it
ensures that the resulting tensor remains positive semi-definite, thereby
simplifying the interpretation of its eigenvalues. Furthermore, this
interpretation allows fitting more than a single 0rientation to the input by
reinterpreting quadrature filter responses without relying on a structure
tensor. It also removes the constraint that responses must originate strictly
from quadrature filters, allowing the use of alternative filter types and
non-angular tessellations. These alternatives include Gabor filters--which,
although not strictly quadrature, are still suitable for structure tensor
construction--even when they tessellate the spectrum in a Cartesian fashion,
provided they are sufficiently concentrated.

</details>


### [165] [Fast Voxel-Wise Kinetic Modeling in Dynamic PET using a Physics-Informed CycleGAN](https://arxiv.org/abs/2510.23140)
*Christian Salomonsen,Samuel Kuttner,Michael Kampffmeyer,Robert Jenssen,Kristoffer Wickstrøm,Jong Chul Ye,Elisabeth Wetzer*

Main category: cs.CV

TL;DR: 本文提出利用物理知识引导的CycleGAN模型，在动态PET中实现了无创、准确的动脉输入函数（AIF）预测，结果与传统参考方法高度一致。


<details>
  <summary>Details</summary>
Motivation: 传统的示踪剂动力学建模在医学诊断和治疗中非常重要，但AIF估算过程复杂且具侵入性，增加了患者负担。研究希望简化该流程，减少侵入操作。

Method: 借鉴物理知识引导的CycleGAN，原本在DCE-MRI中用于定量分析，将该方法应用到动态PET图像，实现对AIF的预测及相关参数映射。

Result: 实验表明该模型能够准确预测AIF，生成的参数图与参考结果高度一致。

Conclusion: 这种基于物理知识引导的CycleGAN方法可以在保证定量准确性的前提下，降低AIF估测的复杂性和侵入性，具有较好的实际应用前景。

Abstract: Tracer kinetic modeling serves a vital role in diagnosis, treatment planning,
tracer development and oncology, but burdens practitioners with complex and
invasive arterial input function estimation (AIF). We adopt a physics-informed
CycleGAN showing promise in DCE-MRI quantification to dynamic PET
quantification. Our experiments demonstrate sound AIF predictions and parameter
maps closely resembling the reference.

</details>


### [166] [DQ3D: Depth-guided Query for Transformer-Based 3D Object Detection in Traffic Scenarios](https://arxiv.org/abs/2510.23144)
*Ziyu Wang,Wenhao Li,Ji Wu*

Main category: cs.CV

TL;DR: 该论文提出了一种基于深度信息引导的3D目标检测方法，通过改进查询点生成方式和融合历史信息，有效提升了多视角交通场景下的3D检测准确性。


<details>
  <summary>Details</summary>
Motivation: 当前多视角3D目标检测方法普遍存在查询点远离真实目标，导致误检的缺陷，且在目标部分遮挡时检测效果较差。因此，如何更准确地生成与目标相关的参考点并提升遮挡情况下的检测效果，是该领域亟需解决的问题。

Method: 本文提出了一种深度引导的查询生成器（DQ3D），利用深度信息和2D检测结果生成更靠近目标表面或内部的参考点。同时，提出混合注意力机制，将历史帧的检测结果与深度引导的查询相融合，形成混合查询，从而适应当前帧中部分遮挡目标的检测。

Result: 在nuScenes数据集上的实验表明，DQ3D方法在平均精度（mAP）上比基线方法提升了6.3%，在NuScenes检测得分（NDS）上提升了4.3%。

Conclusion: 本文方法有效解决了现有方法误检和遮挡检测差的问题，大幅提升了3D目标检测精度，可为交通场景下的多视角感知提供有力支持。

Abstract: 3D object detection from multi-view images in traffic scenarios has garnered
significant attention in recent years. Many existing approaches rely on object
queries that are generated from 3D reference points to localize objects.
However, a limitation of these methods is that some reference points are often
far from the target object, which can lead to false positive detections. In
this paper, we propose a depth-guided query generator for 3D object detection
(DQ3D) that leverages depth information and 2D detections to ensure that
reference points are sampled from the surface or interior of the object.
Furthermore, to address partially occluded objects in current frame, we
introduce a hybrid attention mechanism that fuses historical detection results
with depth-guided queries, thereby forming hybrid queries. Evaluation on the
nuScenes dataset demonstrates that our method outperforms the baseline by 6.3\%
in terms of mean Average Precision (mAP) and 4.3\% in the NuScenes Detection
Score (NDS).

</details>


### [167] [Implicit Modeling for Transferability Estimation of Vision Foundation Models](https://arxiv.org/abs/2510.23145)
*Yaoyan Zheng,Huiqun Wang,Nan Zhou,Di Huang*

Main category: cs.CV

TL;DR: 本文提出ITM方法，通过高效估计预训练模型的可迁移性，减少了全面微调的高计算成本。实验表明，该方法优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前迁移性估计算法难以准确评估新兴多样预训练模型的可迁移性，影响其在下游任务的部署和预训练-微调范式的推进。

Method: 提出了Implicit Transferability Modeling (ITM)框架，通过内隐建模每个模型的内在可迁移性，并结合Divide-and-Conquer Variational Approximation (DVA)策略，有效逼近嵌入空间演化，实现高效泛化。

Result: 在全面的基准测试中，ITM在涵盖多种训练方式和模型类型的情况下，均显示出比现有方法更高的稳定性、效果和效率。

Conclusion: ITM能够在更广泛的模型与下游任务中提升迁移性估计的效果，为实际应用和理论研究都带来进展。

Abstract: Transferability estimation identifies the best pre-trained models for
downstream tasks without incurring the high computational cost of full
fine-tuning. This capability facilitates deployment and advances the
pre-training and fine-tuning paradigm. However, existing methods often struggle
to accurately assess transferability for emerging pre-trained models with
diverse architectures, training strategies, and task alignments. In this work,
we propose Implicit Transferability Modeling (ITM), a novel framework that
implicitly models each model's intrinsic transferability, coupled with a
Divide-and-Conquer Variational Approximation (DVA) strategy to efficiently
approximate embedding space evolution. This design enables generalization
across a broader range of models and downstream tasks. Extensive experiments on
a comprehensive benchmark--spanning extensive training regimes and a wider
variety of model types--demonstrate that ITM consistently outperforms existing
methods in terms of stability, effectiveness, and efficiency.

</details>


### [168] [AG-Fusion: adaptive gated multimodal fusion for 3d object detection in complex scenes](https://arxiv.org/abs/2510.23151)
*Sixian Liu,Chen Xu,Qiang Wang,Donghai Shi,Yiwen Li*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的多模态相机-激光雷达自适应门控融合方法，更好地应对传感器退化和环境干扰等复杂场景下的3D目标检测，并构建了E3D数据集进行测试。方法在KITTI和新数据集上均取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的相机-激光雷达融合3D目标检测方法在面对传感器退化或恶劣环境时性能大幅下降，严重制约了其在实际复杂工业场景中的应用。亟需一种更鲁棒的融合机制。

Method: 将每种模态特征投影到统一的BEV空间后，采用基于窗口的注意力机制进行增强。随后，设计了一种基于跨模态注意力的自适应门控融合模块，有选择地集成多个模态的可靠特征，提升复杂环境下的鲁棒表示。此外，作者还构建了面向挖掘机工作场景的新数据集E3D以进行评测。

Result: 所提方法在标准KITTI数据集上达到93.92%的准确率，在新的E3D数据集上比基线提高了24.88%，表现出对恶劣环境与传感器信息失效的更好鲁棒性。

Conclusion: AG-Fusion方法有效提升了相机-激光雷达融合式3D目标检测在复杂/极端场景下的稳定性和精度，尤其适用于实际工业应用中经常遇到的挑战环境。

Abstract: Multimodal camera-LiDAR fusion technology has found extensive application in
3D object detection, demonstrating encouraging performance. However, existing
methods exhibit significant performance degradation in challenging scenarios
characterized by sensor degradation or environmental disturbances. We propose a
novel Adaptive Gated Fusion (AG-Fusion) approach that selectively integrates
cross-modal knowledge by identifying reliable patterns for robust detection in
complex scenes. Specifically, we first project features from each modality into
a unified BEV space and enhance them using a window-based attention mechanism.
Subsequently, an adaptive gated fusion module based on cross-modal attention is
designed to integrate these features into reliable BEV representations robust
to challenging environments. Furthermore, we construct a new dataset named
Excavator3D (E3D) focusing on challenging excavator operation scenarios to
benchmark performance in complex conditions. Our method not only achieves
competitive performance on the standard KITTI dataset with 93.92% accuracy, but
also significantly outperforms the baseline by 24.88% on the challenging E3D
dataset, demonstrating superior robustness to unreliable modal information in
complex industrial scenes.

</details>


### [169] [Finding 3D Scene Analogies with Multimodal Foundation Models](https://arxiv.org/abs/2510.23184)
*Junho Kim,Young Min Kim*

Main category: cs.CV

TL;DR: 论文提出了一种利用多模态基础模型在零样本、开放词汇设置下进行3D场景类比的方法，无需额外训练或固定对象词表。该方法能够在复杂场景间准确建立对应关系，实现轨迹与路径点的转移。


<details>
  <summary>Details</summary>
Motivation: 现有的3D场景类比方法需要额外训练且对象词汇固定，难以适应新场景。作者希望通过基础大模型实现更加灵活、泛化能力强的3D场景匹配与信息转移。

Method: 该方法采用了混合神经表示：将视觉-语言模型提取的特征建成稀疏图，再结合3D形状基础模型中的特征场。通过先对齐图结构，再用特征场细化，分层粗到细地实现场景对应。

Result: 实验表明，该方法能在复杂3D场景之间准确建立对应关系。作者还演示了该方法在轨迹和路径点转移等任务上的潜力。

Conclusion: 本工作证明了多模态基础模型可在无训练和开放词汇条件下实现3D场景类比，为机器人适应和任务迁移提供了新途径。

Abstract: Connecting current observations with prior experiences helps robots adapt and
plan in new, unseen 3D environments. Recently, 3D scene analogies have been
proposed to connect two 3D scenes, which are smooth maps that align scene
regions with common spatial relationships. These maps enable detailed transfer
of trajectories or waypoints, potentially supporting demonstration transfer for
imitation learning or task plan transfer across scenes. However, existing
methods for the task require additional training and fixed object vocabularies.
In this work, we propose to use multimodal foundation models for finding 3D
scene analogies in a zero-shot, open-vocabulary setting. Central to our
approach is a hybrid neural representation of scenes that consists of a sparse
graph based on vision-language model features and a feature field derived from
3D shape foundation models. 3D scene analogies are then found in a
coarse-to-fine manner, by first aligning the graph and refining the
correspondence with feature fields. Our method can establish accurate
correspondences between complex scenes, and we showcase applications in
trajectory and waypoint transfer.

</details>


### [170] [Evaluation of Vision-LLMs in Surveillance Video](https://arxiv.org/abs/2510.23190)
*Pascal Benschop,Cristian Meo,Justin Dauwels,Jelte P. Mense*

Main category: cs.CV

TL;DR: 本文探讨视觉语言模型（VLMs）在零样本异常行为识别中的空间推理能力，尤其针对2D视频动态场景的理解，提出将视频转为文本描述并通过文本蕴涵做异常检测。实验证明，当前小型预训练视觉-语言模型在简单空间事件中表现良好，但对隐私处理和复杂空间线索较敏感，准确率下降。


<details>
  <summary>Details</summary>
Motivation: 随着摄像头普及，视频数据激增，人工监控已难以满足公共安全需求，亟需自动化异常事件检测手段，提升响应效率。本文关注如何利用视觉语言模型自动识别出视频中的异常行为，尤其关注空间推理在其中的作用。

Method: 作者将异常行为识别任务框定为零样本语言引导问题，即用已训练的VLM将视频转换成文本描述，再用文本蕴涵判断标签。评估了4种开源VLM在UCF-Crime和RWF-2000数据集上的表现，并分析了少样本提示和不同隐私保护方法对模型性能的影响。

Result: 实验发现：少样本提示可提升部分模型精度，但易增加误报率；隐私保护方法尤其是全身GAN变换会导致一致性降低和准确率下降。模型对空间明显简单事件有较好识别能力，对空间线索噪声和身份模糊事件表现较差。

Conclusion: 目前VLM对异常行为的空间推理有一定基础，但存在空间线索鲁棒性不足等短板。作者提出可通过结构感知提示、轻量化空间记忆、场景图或3D姿态先验、几何保持的隐私方法等途径提升空间推理和实际应用效果，将零样本语言管线作为现实视频理解的可扩展基础方案。

Abstract: The widespread use of cameras in our society has created an overwhelming
amount of video data, far exceeding the capacity for human monitoring. This
presents a critical challenge for public safety and security, as the timely
detection of anomalous or criminal events is crucial for effective response and
prevention. The ability for an embodied agent to recognize unexpected events is
fundamentally tied to its capacity for spatial reasoning. This paper
investigates the spatial reasoning of vision-language models (VLMs) by framing
anomalous action recognition as a zero-shot, language-grounded task, addressing
the embodied perception challenge of interpreting dynamic 3D scenes from sparse
2D video. Specifically, we investigate whether small, pre-trained vision--LLMs
can act as spatially-grounded, zero-shot anomaly detectors by converting video
into text descriptions and scoring labels via textual entailment. We evaluate
four open models on UCF-Crime and RWF-2000 under prompting and
privacy-preserving conditions. Few-shot exemplars can improve accuracy for some
models, but may increase false positives, and privacy filters -- especially
full-body GAN transforms -- introduce inconsistencies that degrade accuracy.
These results chart where current vision--LLMs succeed (simple, spatially
salient events) and where they falter (noisy spatial cues, identity
obfuscation). Looking forward, we outline concrete paths to strengthen spatial
grounding without task-specific training: structure-aware prompts, lightweight
spatial memory across clips, scene-graph or 3D-pose priors during description,
and privacy methods that preserve action-relevant geometry. This positions
zero-shot, language-grounded pipelines as adaptable building blocks for
embodied, real-world video understanding. Our implementation for evaluating
VLMs is publicly available at:
https://github.com/pascalbenschopTU/VLLM_AnomalyRecognition

</details>


### [171] [DecoDINO: 3D Human-Scene Contact Prediction with Semantic Classification](https://arxiv.org/abs/2510.23203)
*Lukas Bierling,Davide Pasero,Fleur Dolmans,Helia Ghasemi,Angelo Broere*

Main category: cs.CV

TL;DR: 本文提出了DecoDINO模型，实现了对人类与周围物体高精度的顶点级接触点预测，改进了之前DECO模型的不足，并在DAMON基准测试上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 准确预测人类与物体的细粒度接触点对机器人、AR/VR和行为模拟等领域至关重要。现有DECO算法存在仅能进行二分类接触、不善处理软物体、遮挡、儿童以及虚假脚部接触等问题。

Method: 提出DecoDINO，基于DECO框架，采用三分支网络结构，包含两个DINOv2 ViT-g/14编码器、类别平衡损失加权（减少偏差）、patch级别交叉注意力（提高局部推理），最终通过软max分配语义接触标签。尝试引入视觉-语言模型融合文本特征效果不如简化结构，最终采用更简单方案。

Result: 在DAMON基准测试上，DecoDINO将二值接触F1提升了7%、地质误差减半，并可预测物体级语义标签。消融实验表明LoRA微调和双编码器是改进的关键。DecoDINO在DAMON Challenge的两项任务中均超越了基线。

Conclusion: DecoDINO显著提升了顶点级人-物体接触预测的准确性，解决了DECO在复杂场景和多样化物体方面的限制，是该领域的重要进步。

Abstract: Accurate vertex-level contact prediction between humans and surrounding
objects is a prerequisite for high fidelity human object interaction models
used in robotics, AR/VR, and behavioral simulation. DECO was the first in the
wild estimator for this task but is limited to binary contact maps and
struggles with soft surfaces, occlusions, children, and false-positive foot
contacts. We address these issues and introduce DecoDINO, a three-branch
network based on DECO's framework. It uses two DINOv2 ViT-g/14 encoders,
class-balanced loss weighting to reduce bias, and patch-level cross-attention
for improved local reasoning. Vertex features are finally passed through a
lightweight MLP with a softmax to assign semantic contact labels. We also
tested a vision-language model (VLM) to integrate text features, but the
simpler architecture performed better and was used instead. On the DAMON
benchmark, DecoDINO (i) raises the binary-contact F1 score by 7$\%$, (ii)
halves the geodesic error, and (iii) augments predictions with object-level
semantic labels. Ablation studies show that LoRA fine-tuning and the dual
encoders are key to these improvements. DecoDINO outperformed the challenge
baseline in both tasks of the DAMON Challenge. Our code is available at
https://github.com/DavidePasero/deco/tree/main.

</details>


### [172] [VR-Drive: Viewpoint-Robust End-to-End Driving with Feed-Forward 3D Gaussian Splatting](https://arxiv.org/abs/2510.23205)
*Hoonhee Cho,Jae-Young Kang,Giwon Lee,Hyemin Yang,Heejun Park,Seokwoo Jung,Kuk-Jin Yoon*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的端到端自动驾驶（E2E-AD）方法 VR-Drive，通过集成3D场景重建辅助任务提升系统对不同摄像头视角变化的鲁棒性，并发布了专门评测新视角下表现的基准数据集。


<details>
  <summary>Details</summary>
Motivation: 当前E2E自动驾驶方案难以应对摄像头视角的多样变化，这限制了其在不同车辆实际部署的能力。作者希望消除这一瓶颈，使系统能适应各种视角带来的挑战。

Method: VR-Drive通过联合学习3D场景重建作为辅助任务，实现规划感知的视角合成。采用前馈推断策略，支持稀疏视角下的在线训练增强，并无需额外标注。同时，提出视角混合记忆库和视角一致性蒸馏，提升不同视角间的信息交互和知识迁移效果。

Result: VR-Drive有效应对由视角变化带来的数据噪声，优化了规划表现。实验验证了提出方法在新视角下的鲁棒性，并在新发布的基准数据集上表现优异。

Conclusion: VR-Drive方法提升了端到端自动驾驶系统对实际不同摄像头视角的适应性和鲁棒性，为E2E-AD大规模现实部署提供了有效方案。

Abstract: End-to-end autonomous driving (E2E-AD) has emerged as a promising paradigm
that unifies perception, prediction, and planning into a holistic, data-driven
framework. However, achieving robustness to varying camera viewpoints, a common
real-world challenge due to diverse vehicle configurations, remains an open
problem. In this work, we propose VR-Drive, a novel E2E-AD framework that
addresses viewpoint generalization by jointly learning 3D scene reconstruction
as an auxiliary task to enable planning-aware view synthesis. Unlike prior
scene-specific synthesis approaches, VR-Drive adopts a feed-forward inference
strategy that supports online training-time augmentation from sparse views
without additional annotations. To further improve viewpoint consistency, we
introduce a viewpoint-mixed memory bank that facilitates temporal interaction
across multiple viewpoints and a viewpoint-consistent distillation strategy
that transfers knowledge from original to synthesized views. Trained in a fully
end-to-end manner, VR-Drive effectively mitigates synthesis-induced noise and
improves planning under viewpoint shifts. In addition, we release a new
benchmark dataset to evaluate E2E-AD performance under novel camera viewpoints,
enabling comprehensive analysis. Our results demonstrate that VR-Drive is a
scalable and robust solution for the real-world deployment of end-to-end
autonomous driving systems.

</details>


### [173] [Accurate and Scalable Multimodal Pathology Retrieval via Attentive Vision-Language Alignment](https://arxiv.org/abs/2510.23224)
*Hongyi Wang,Zhengjie Zhu,Jiabo Ma,Fang Wang,Yue Shi,Bo Luo,Jili Wang,Qiuyu Cai,Xiuming Zhang,Yen-Wei Chen,Lanfen Lin,Hao Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为PathSearch的数字病理切片检索框架，通过细粒度注意力拼图表示与全局幻灯片嵌入相结合，以及视觉-语言对比学习对齐，实现了高效准确的切片检索，包括图像和文本多模态检索。


<details>
  <summary>Details</summary>
Motivation: 随着病理切片数字化的普及，传统人工检索面临切片像素规模巨大和微小语义差别难以捕捉等困难，急需精准且灵活的自动化检索工具以支持诊断一致性和教学等应用。

Method: PathSearch结合细粒度的注意力拼图表示（mosaic representations）与全局级别的切片嵌入，通过视觉-语言对比学习进行对齐，提升了对形态学特征和高阶语义的捕捉力。模型以6,926组切片及对应报告训练，支持基于图片和文本的多模式检索。

Result: PathSearch在4个公开病理数据集和3个内部队列的多项任务（解剖部位检索、肿瘤分型、肿瘤分类、分级等）上均优于传统检索方法，并在多中心病理医生实际评测中提升了诊断准确率、自信心及观察者间一致性。

Conclusion: PathSearch是面向数字病理领域的一种兼具扩展性及泛化能力的检索解决方案，可用于临床支持和病理教育。

Abstract: The rapid digitization of histopathology slides has opened up new
possibilities for computational tools in clinical and research workflows. Among
these, content-based slide retrieval stands out, enabling pathologists to
identify morphologically and semantically similar cases, thereby supporting
precise diagnoses, enhancing consistency across observers, and assisting
example-based education. However, effective retrieval of whole slide images
(WSIs) remains challenging due to their gigapixel scale and the difficulty of
capturing subtle semantic differences amid abundant irrelevant content. To
overcome these challenges, we present PathSearch, a retrieval framework that
unifies fine-grained attentive mosaic representations with global-wise slide
embeddings aligned through vision-language contrastive learning. Trained on a
corpus of 6,926 slide-report pairs, PathSearch captures both fine-grained
morphological cues and high-level semantic patterns to enable accurate and
flexible retrieval. The framework supports two key functionalities: (1)
mosaic-based image-to-image retrieval, ensuring accurate and efficient slide
research; and (2) multi-modal retrieval, where text queries can directly
retrieve relevant slides. PathSearch was rigorously evaluated on four public
pathology datasets and three in-house cohorts, covering tasks including
anatomical site retrieval, tumor subtyping, tumor vs. non-tumor discrimination,
and grading across diverse organs such as breast, lung, kidney, liver, and
stomach. External results show that PathSearch outperforms traditional
image-to-image retrieval frameworks. A multi-center reader study further
demonstrates that PathSearch improves diagnostic accuracy, boosts confidence,
and enhances inter-observer agreement among pathologists in real clinical
scenarios. These results establish PathSearch as a scalable and generalizable
retrieval solution for digital pathology.

</details>


### [174] [Through the Lens: Benchmarking Deepfake Detectors Against Moiré-Induced Distortions](https://arxiv.org/abs/2510.23225)
*Razaib Tariq,Minji Heo,Simon S. Woo,Shahroz Tariq*

Main category: cs.CV

TL;DR: 本文系统性地评估了当前主流深度伪造（deepfake）检测器在含有莫尔条纹（Moiré）失真的视频上的表现，并发现这类失真会显著降低检测准确率。还介绍了全新数据集DMF，推动实际场景下的检测研究。


<details>
  <summary>Details</summary>
Motivation: 智能手机等设备拍摄数字屏幕时常会引入莫尔条纹，这种失真影响了深度伪造检测效果，但相关问题尚无系统研究。提升在现实复杂环境下检测伪造内容的鲁棒性，成为亟需解决的难题。

Method: 作者采集并构建了包含12832条视频（共约35.64小时）的DMF数据集，涵盖不同的屏幕、手机、光线和拍摄角度。分析了15种主流检测算法在真实莫尔条纹和合成莫尔条纹影响下的性能，并验证了去除莫尔条纹（demoir’eing）技术的效果。

Result: 实验证明，莫尔条纹会导致检测性能最高下降25.4%；人工合成的莫尔模式也导致准确率下降21.4%。而尝试用去除莫尔条纹方法反而进一步降低准确率（最多降17.2%）。

Conclusion: 当前的深度伪造检测器难以应对莫尔条纹等现实失真现象，需要开发在复杂实际环境下更为鲁棒的检测模型。DMF数据集的发布将有助于推动相关领域实际应用。

Abstract: Deepfake detection remains a pressing challenge, particularly in real-world
settings where smartphone-captured media from digital screens often introduces
Moir\'e artifacts that can distort detection outcomes. This study
systematically evaluates state-of-the-art (SOTA) deepfake detectors on
Moir\'e-affected videos, an issue that has received little attention. We
collected a dataset of 12,832 videos, spanning 35.64 hours, from the Celeb-DF,
DFD, DFDC, UADFV, and FF++ datasets, capturing footage under diverse real-world
conditions, including varying screens, smartphones, lighting setups, and camera
angles. To further examine the influence of Moir\'e patterns on deepfake
detection, we conducted additional experiments using our DeepMoir\'eFake,
referred to as (DMF) dataset and two synthetic Moir\'e generation techniques.
Across 15 top-performing detectors, our results show that Moir\'e artifacts
degrade performance by as much as 25.4%, while synthetically generated Moir\'e
patterns lead to a 21.4% drop in accuracy. Surprisingly, demoir\'eing methods,
intended as a mitigation approach, instead worsened the problem, reducing
accuracy by up to 17.2%. These findings underscore the urgent need for
detection models that can robustly handle Moir\'e distortions alongside other
realworld challenges, such as compression, sharpening, and blurring. By
introducing the DMF dataset, we aim to drive future research toward closing the
gap between controlled experiments and practical deepfake detection.

</details>


### [175] [Autoregressive Styled Text Image Generation, but Make it Reliable](https://arxiv.org/abs/2510.23240)
*Carmine Zaccagnino,Fabio Quattrini,Vittorio Pippi,Silvia Cascianelli,Alessio Tonioni,Rita Cucchiara*

Main category: cs.CV

TL;DR: 本文提出了一种改进的手写风格文本生成方法（HTG），通过对当前主流的自动回归Transformer方法进行创新，提升了风格保真性和文本内容的可控性。新方法显著简化输入要求，同时提高对未见风格的泛化能力和文本提示的忠实度。


<details>
  <summary>Details</summary>
Motivation: 现有手写文本风格生成方法虽然在风格保真性有进展，但对内容控制不足，如需要额外输入、缺少停止机制、易产生重复和视觉伪影。作者希望解决这些内容可控性与泛化性问题。

Method: 作者将HTG问题重新定义为多模态、提示条件下的生成任务，通过引入特殊文本输入token提升文本与视觉的对齐，同时在自动回归模型中结合无分类器指导（Classifier-Free Guidance）策略，提升生成质量与可控性。

Result: 实验结果表明，新方法在输入减少、对未知风格泛化及文本一致性方面均优于现有方案。新模型更加忠实地遵循文本prompt，提高生成文本内容的准确性。

Conclusion: Eruku方法克服了现有HTG方法中的多项局限，不仅要求更少的输入，还能更好地适应新风格，并显著提升了内容的忠实和可控性，推动了手写风格文本生成的发展。

Abstract: Generating faithful and readable styled text images (especially for Styled
Handwritten Text generation - HTG) is an open problem with several possible
applications across graphic design, document understanding, and image editing.
A lot of research effort in this task is dedicated to developing strategies
that reproduce the stylistic characteristics of a given writer, with promising
results in terms of style fidelity and generalization achieved by the recently
proposed Autoregressive Transformer paradigm for HTG. However, this method
requires additional inputs, lacks a proper stop mechanism, and might end up in
repetition loops, generating visual artifacts. In this work, we rethink the
autoregressive formulation by framing HTG as a multimodal prompt-conditioned
generation task, and tackle the content controllability issues by introducing
special textual input tokens for better alignment with the visual ones.
Moreover, we devise a Classifier-Free-Guidance-based strategy for our
autoregressive model. Through extensive experimental validation, we demonstrate
that our approach, dubbed Eruku, compared to previous solutions requires fewer
inputs, generalizes better to unseen styles, and follows more faithfully the
textual prompt, improving content adherence.

</details>


### [176] [Progressive Growing of Patch Size: Curriculum Learning for Accelerated and Improved Medical Image Segmentation](https://arxiv.org/abs/2510.23241)
*Stefan M. Fischer,Johannes Kiechle,Laura Daza,Lina Felsner,Richard Osuala,Daniel M. Lang,Karim Lekadir,Jan C. Peeken,Julia A. Schnabel*

Main category: cs.CV

TL;DR: 本文提出了一种名为“Patch Size逐步增大”的自动课程学习方法，用于提升3D医学图像分割的性能和效率。该方法在训练过程中逐渐增大输入patch的大小，验证表明它在准确率和训练时间上均优于传统采样方式，并适用于多种主流分割网络。


<details>
  <summary>Details</summary>
Motivation: 在3D医学图像分割任务中，如何平衡训练准确率与计算成本，尤其是在处理小样本类别和任务高度不平衡时，传统的固定patch大小采样方法存在性能和效率瓶颈。因此，提出更高效、通用且能提高分割性能的方法非常重要。

Method: 作者提出了一种训练策略：训练初期采用较小patch，逐步增大至更大patch，从而实现类别平衡提升和加快收敛速度。他们在两种模式下评估该方法：一是追求计算效率，二是提升分割性能。实验覆盖15个医学图像分割任务，并分别与恒定patch大小采样做对比。该方法在不同主流网络架构（如UNet、UNETR、SwinUNETR等）上均进行了验证。

Result: 在资源高效模式下，训练时间减少至44%，而Dice分数与基线基本持平；在性能模式下，所有任务的Dice分数均明显优于基线，平均提升1.28%，训练时间也节省到89%。在难度较高的失衡任务（如病灶分割）上效果更加突出。此外，新方法显著降低了模型性能方差，提高了对比可信度。

Conclusion: “Patch Size逐步增大”的课程学习是一种简单有效、兼容性强的分割训练方案，显著提升了Dice分数与训练效率，可广泛应用于各种主流医学分割网络，并能为处理类别不平衡任务提供显著优势。

Abstract: In this work, we introduce Progressive Growing of Patch Size, an automatic
curriculum learning approach for 3D medical image segmentation. Our approach
progressively increases the patch size during model training, resulting in an
improved class balance for smaller patch sizes and accelerated convergence of
the training process. We evaluate our curriculum approach in two settings: a
resource-efficient mode and a performance mode, both regarding Dice score
performance and computational costs across 15 diverse and popular 3D medical
image segmentation tasks. The resource-efficient mode matches the Dice score
performance of the conventional constant patch size sampling baseline with a
notable reduction in training time to only 44%. The performance mode improves
upon constant patch size segmentation results, achieving a statistically
significant relative mean performance gain of 1.28% in Dice Score. Remarkably,
across all 15 tasks, our proposed performance mode manages to surpass the
constant patch size baseline in Dice Score performance, while simultaneously
reducing training time to only 89%. The benefits are particularly pronounced
for highly imbalanced tasks such as lesion segmentation tasks. Rigorous
experiments demonstrate that our performance mode not only improves mean
segmentation performance but also reduces performance variance, yielding more
trustworthy model comparison. Furthermore, our findings reveal that the
proposed curriculum sampling is not tied to a specific architecture but
represents a broadly applicable strategy that consistently boosts performance
across diverse segmentation models, including UNet, UNETR, and SwinUNETR. In
summary, we show that this simple yet elegant transformation on input data
substantially improves both Dice Score performance and training runtime, while
being compatible across diverse segmentation backbones.

</details>


### [177] [A Video Is Not Worth a Thousand Words](https://arxiv.org/abs/2510.23253)
*Sam Pollard,Michael Wray*

Main category: cs.CV

TL;DR: 本论文探讨了多模态视觉语言模型（VLMs）在视频问答（VQA）任务中对文本的依赖性，并提出基于Shapley值的特征归因与模态得分联合方法，揭示了多项选择VQA任务实际更多依赖于文本而弱化了多模态交互。


<details>
  <summary>Details</summary>
Motivation: 随着VLMs在现实场景中的广泛应用，研究如何提升VQA任务的难度与提升模型处理长上下文的能力变得重要。但依赖大语言模型常导致文本主导模式，缺乏对多模态交互的深入分析，作者希望明确评估多模态模型是否在正确的方向上发展。

Method: 作者提出了融合特征归因和Shapley值计算的联合方法，可自定义特征和模态用于归因评估。以此度量模型对不同模态（视频帧、问题文本和答案文本）的依赖，对6个不同上下文长度的VLM模型，在4个具有代表性的数据集上进行多项选择VQA测试。

Result: 实验显示，VLMs在多项选择VQA任务主要依赖文本信息，视频信息作用有限，任务变成了模型去除干扰项（distractors）的能力评测。

Conclusion: 多模态模型在当前VQA benchmark中，尚未很好地实现各模态合理互动，文本主导问题突出。作者的方法量化和揭示了这一趋势，说明以往VQA任务未能充分发挥视频信息价值，需重新设计以激励模型真正进行多模态推理。

Abstract: As we become increasingly dependent on vision language models (VLMs) to
answer questions about the world around us, there is a significant amount of
research devoted to increasing both the difficulty of video question answering
(VQA) datasets, and the context lengths of the models that they evaluate. The
reliance on large language models as backbones has lead to concerns about
potential text dominance, and the exploration of interactions between
modalities is underdeveloped. How do we measure whether we're heading in the
right direction, with the complexity that multi-modal models introduce? We
propose a joint method of computing both feature attributions and modality
scores based on Shapley values, where both the features and modalities are
arbitrarily definable. Using these metrics, we compare $6$ VLM models of
varying context lengths on $4$ representative datasets, focusing on
multiple-choice VQA. In particular, we consider video frames and whole textual
elements as equal features in the hierarchy, and the multiple-choice VQA task
as an interaction between three modalities: video, question and answer. Our
results demonstrate a dependence on text and show that the multiple-choice VQA
task devolves into a model's ability to ignore distractors. Code available at
https://github.com/sjpollard/a-video-is-not-worth-a-thousand-words.

</details>


### [178] [hYOLO Model: Enhancing Object Classification with Hierarchical Context in YOLOv8](https://arxiv.org/abs/2510.23278)
*Veska Tsenkova,Peter Stanchev,Daniel Petrov,Deyan Lazarov*

Main category: cs.CV

TL;DR: 本文提出了一种基于YOLO的端到端分层图像检测与分类模型，专为捕捉物体的层次结构而设计，并提出新的结构、损失函数和评估指标。实验表明该方法能有效利用物体的自然层级关系，超越传统的扁平分类方法。


<details>
  <summary>Details</summary>
Motivation: 现有CNN图像分类方法多为扁平分类，仅识别物体本身，未利用物体的自然层级关系。现实中的物体存在天然层次组织，捕捉物体之间的关系能提升分类效果与错误可控性。为充分挖掘和利用层级信息，提出新的分层分类模型。

Method: 基于YOLO模型，提出新的分层架构，并设计专门的损失函数和性能评估指标用于分层分类。模型在同一数据集的两种不同分层分类方案（系统性/视觉特征）上进行训练与测试。

Result: 实验结果表明，该方法能更好地反映现实物体的层级结构，相较扁平分类模型，提升了图像检测和分类的表现。

Conclusion: 分层建模及分类能有效提升现实场景下目标识别的精度和错误可控性，是对传统扁平分类的重要补充，具有实际应用价值。

Abstract: Current convolution neural network (CNN) classification methods are
predominantly focused on flat classification which aims solely to identify a
specified object within an image. However, real-world objects often possess a
natural hierarchical organization that can significantly help classification
tasks. Capturing the presence of relations between objects enables better
contextual understanding as well as control over the severity of mistakes.
Considering these aspects, this paper proposes an end-to-end hierarchical model
for image detection and classification built upon the YOLO model family. A
novel hierarchical architecture, a modified loss function, and a performance
metric tailored to the hierarchical nature of the model are introduced. The
proposed model is trained and evaluated on two different hierarchical
categorizations of the same dataset: a systematic categorization that
disregards visual similarities between objects and a categorization accounting
for common visual characteristics across classes. The results illustrate how
the suggested methodology addresses the inherent hierarchical structure present
in real-world objects, which conventional flat classification algorithms often
overlook.

</details>


### [179] [Adaptive Stochastic Coefficients for Accelerating Diffusion Sampling](https://arxiv.org/abs/2510.23285)
*Ruoyu Wang,Beier Zhu,Junzhi Li,Liangyu Yuan,Chi Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的单步SDE求解器AdaSDE，结合了ODE的高效性与SDE的抗误差能力，在提升扩散采样速度的同时保证了生成质量。AdaSDE通过轻量蒸馏自适应调节误差校正强度，实验结果显示在主流数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散的生成模型在计算速度与采样质量之间存在权衡。ODE方法虽然高效，但因确定性轨迹会累积梯度误差；SDE方法更抗误差，但有限步数预算下离散误差被放大。因此需要一种能兼顾两者优点的新方法。

Method: 作者提出AdaSDE，一种单步SDE求解器。核心在于引入可学习的单步系数，通过轻量级蒸馏动态调整每步的误差修正强度。该框架可集成现有扩散求解器提升性能。

Result: 在5次NFE测试下，AdaSDE在CIFAR-10、FFHQ和LSUN Bedroom上分别取得4.18、8.05和6.96的FID分数，均为当前最优水平。

Conclusion: AdaSDE方法兼具高效性和鲁棒性，在保证采样质量的同时大幅提升采样速度，为扩散模型求解器设计提供了新思路。

Abstract: Diffusion-based generative processes, formulated as differential equation
solving, frequently balance computational speed with sample quality. Our
theoretical investigation of ODE- and SDE-based solvers reveals complementary
weaknesses: ODE solvers accumulate irreducible gradient error along
deterministic trajectories, while SDE methods suffer from amplified
discretization errors when the step budget is limited. Building upon this
insight, we introduce AdaSDE, a novel single-step SDE solver that aims to unify
the efficiency of ODEs with the error resilience of SDEs. Specifically, we
introduce a single per-step learnable coefficient, estimated via lightweight
distillation, which dynamically regulates the error correction strength to
accelerate diffusion sampling. Notably, our framework can be integrated with
existing solvers to enhance their capabilities. Extensive experiments
demonstrate state-of-the-art performance: at 5 NFE, AdaSDE achieves FID scores
of 4.18 on CIFAR-10, 8.05 on FFHQ and 6.96 on LSUN Bedroom. Codes are available
in https://github.com/WLU-wry02/AdaSDE.

</details>


### [180] [MMSD3.0: A Multi-Image Benchmark for Real-World Multimodal Sarcasm Detection](https://arxiv.org/abs/2510.23299)
*Haochen Zhao,Yuyao Kong,Yongxiu Xu,Gaopeng Gou,Hongbo Xu,Yubin Wang,Haoliang Zhang*

Main category: cs.CV

TL;DR: 本文提出了专为多图场景设计的讽刺检测新基准MMSD3.0，并提出了跨图像推理模型CIRM，有效提升多图讽刺检测能力，在多个数据集上实现最佳表现。


<details>
  <summary>Details</summary>
Motivation: 当前多模态讽刺检测研究局限于单张图片，缺乏对真实环境中多图语义与情感关联的建模，导致在需要多个图片线索理解讽刺时表现不足。

Method: 作者构建了包含多个图片样本的新数据集MMSD3.0，并提出跨图像序列建模的CIRM模型，能够捕捉图像之间潜在关系，并通过基于文本-图片关联的细粒度跨模态融合机制，提高信息集成的精度，减少信息损失。同时，设计了全面的基线方案进行对比实验。

Result: 实验结果表明，MMSD3.0作为多图讽刺检测基准更贴近真实应用场景，而CIRM模型在MMSD、MMSD2.0和MMSD3.0数据集上均取得了当前最优的讽刺检测性能。

Conclusion: 本文通过提出MMSD3.0数据集填补了多图讽刺检测领域的空白，并用CIRM模型显著提升了多图和单图讽刺检测效果，为多模态讽刺检测研究提供了更具实用性和前瞻性的方法和资源。

Abstract: Despite progress in multimodal sarcasm detection, existing datasets and
methods predominantly focus on single-image scenarios, overlooking potential
semantic and affective relations across multiple images. This leaves a gap in
modeling cases where sarcasm is triggered by multi-image cues in real-world
settings. To bridge this gap, we introduce MMSD3.0, a new benchmark composed
entirely of multi-image samples curated from tweets and Amazon reviews. We
further propose the Cross-Image Reasoning Model (CIRM), which performs targeted
cross-image sequence modeling to capture latent inter-image connections. In
addition, we introduce a relevance-guided, fine-grained cross-modal fusion
mechanism based on text-image correspondence to reduce information loss during
integration. We establish a comprehensive suite of strong and representative
baselines and conduct extensive experiments, showing that MMSD3.0 is an
effective and reliable benchmark that better reflects real-world conditions.
Moreover, CIRM demonstrates state-of-the-art performance across MMSD, MMSD2.0
and MMSD3.0, validating its effectiveness in both single-image and multi-image
scenarios.

</details>


### [181] [MDReID: Modality-Decoupled Learning for Any-to-Any Multi-Modal Object Re-Identification](https://arxiv.org/abs/2510.23301)
*Yingying Feng,Jie Li,Jie Hu,Yukang Zhang,Lei Tan,Jiayi Ji*

Main category: cs.CV

TL;DR: MDReID是一种灵活的多模态重识别框架，通过分离模态共享与特定特征，并采用专门的度量学习策略，在多模态匹配与不匹配场景下均取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 现实世界的物体重识别系统常面临不同模态（如RGB、NIR、TIR）的一致性问题，而大多数现有方法仅在模态匹配条件下有效，限制了其实用性和可扩展性。

Method: 提出了MDReID框架，包括两大关键模块：模态解耦学习（MDL）将输入特征拆解为模态共享和模态特定两个部分；模态感知度量学习（MML）通过特定的度量策略加强两者的正交性和互补性，从而提升跨模态辨别能力。

Result: 在RGBNT201、RGBNT100、MSVR310等三个多模态重识别基准上，MDReID在模态匹配场景下mAP提升9.8%、3.0%、11.5%，在模态不匹配场景下平均提升3.4%、11.8%、10.9%。

Conclusion: MDReID在模态匹配与不匹配任务中均展示了明显优越性，为多模态重识别实际部署提供了更高的稳健性和灵活性。

Abstract: Real-world object re-identification (ReID) systems often face modality
inconsistencies, where query and gallery images come from different sensors
(e.g., RGB, NIR, TIR). However, most existing methods assume modality-matched
conditions, which limits their robustness and scalability in practical
applications. To address this challenge, we propose MDReID, a flexible
any-to-any image-level ReID framework designed to operate under both
modality-matched and modality-mismatched scenarios. MDReID builds on the
insight that modality information can be decomposed into two components:
modality-shared features that are predictable and transferable, and
modality-specific features that capture unique, modality-dependent
characteristics. To effectively leverage this, MDReID introduces two key
components: the Modality Decoupling Learning (MDL) and Modality-aware Metric
Learning (MML). Specifically, MDL explicitly decomposes modality features into
modality-shared and modality-specific representations, enabling effective
retrieval in both modality-aligned and mismatched scenarios. MML, a tailored
metric learning strategy, further enforces orthogonality and complementarity
between the two components to enhance discriminative power across modalities.
Extensive experiments conducted on three challenging multi-modality ReID
benchmarks (RGBNT201, RGBNT100, MSVR310) consistently demonstrate the
superiority of MDReID. Notably, MDReID achieves significant mAP improvements of
9.8\%, 3.0\%, and 11.5\% in general modality-matched scenarios, and average
gains of 3.4\%, 11.8\%, and 10.9\% in modality-mismatched scenarios,
respectively. The code is available at:
\textcolor{magenta}{https://github.com/stone96123/MDReID}.

</details>


### [182] [ReconViaGen: Towards Accurate Multi-view 3D Object Reconstruction via Generation](https://arxiv.org/abs/2510.23306)
*Jiahao Chang,Chongjie Ye,Yushuang Wu,Yuantao Chen,Yidan Zhang,Zhongjin Luo,Chenghong Li,Yihao Zhi,Xiaoguang Han*

Main category: cs.CV

TL;DR: 传统多视角三维重建方法对视角重叠要求高，面对遮挡和稀疏视点时重建不完整。近期扩散式三维生成模型能利用生成式先验修补不可见区域，但生成过程的随机性导致一致性差。作者分析原因并提出ReconViaGen，结合重建先验并改进多视角信息融合及去噪过程，有效提升了细节和全局结构一致性的三维重建效果。


<details>
  <summary>Details</summary>
Motivation: 现有多视角三维重建方法在实际应用中常因遮挡和稀疏视点采集导致重建效果不完整。现有的三维扩散生成模型虽能对不可见区域进行合理预测，但在一致性和可控性上表现不佳。该论文旨在分析现有扩散生成方法一致性不足的原因，并寻找可控而一致的三维重建解决方案。

Method: 针对扩散生成三维方法一致性差的问题，作者分析其原因包括：1）多视角条件特征提取时，视角间联系不足；2）去噪生成细节阶段缺乏可控性，造成与输入不一致。为此，作者提出ReconViaGen，通过创新性地将重建先验融入生成框架，并设计多项策略改善条件特征融合和去噪环节的可控性的一致性。

Result: 实验显示，ReconViaGen在三维模型的全局结构和局部细节一致性上均显著优于现有技术，能够重建出完整且与输入视角高度一致的三维模型。

Conclusion: ReconViaGen有效融合了重建与生成式先验，通过结构性和细节一致性创新，实现了比已有方法更精准和一致的多视角三维重建，为实际三维重建应用提供了更佳方案。

Abstract: Existing multi-view 3D object reconstruction methods heavily rely on
sufficient overlap between input views, where occlusions and sparse coverage in
practice frequently yield severe reconstruction incompleteness. Recent
advancements in diffusion-based 3D generative techniques offer the potential to
address these limitations by leveraging learned generative priors to
hallucinate invisible parts of objects, thereby generating plausible 3D
structures. However, the stochastic nature of the inference process limits the
accuracy and reliability of generation results, preventing existing
reconstruction frameworks from integrating such 3D generative priors. In this
work, we comprehensively analyze the reasons why diffusion-based 3D generative
methods fail to achieve high consistency, including (a) the insufficiency in
constructing and leveraging cross-view connections when extracting multi-view
image features as conditions, and (b) the poor controllability of iterative
denoising during local detail generation, which easily leads to plausible but
inconsistent fine geometric and texture details with inputs. Accordingly, we
propose ReconViaGen to innovatively integrate reconstruction priors into the
generative framework and devise several strategies that effectively address
these issues. Extensive experiments demonstrate that our ReconViaGen can
reconstruct complete and accurate 3D models consistent with input views in both
global structure and local details.Project page:
https://jiahao620.github.io/reconviagen.

</details>


### [183] [Multitask Multimodal Self-Supervised Learning for Medical Images](https://arxiv.org/abs/2510.23325)
*Cristian Simionescu*

Main category: cs.CV

TL;DR: 本文提出了Medformer，一个创新的神经网络架构，通过自监督学习和领域自适应，有效减少医疗影像对标注数据的依赖，提升深度学习在医疗影像分析中的应用能力。


<details>
  <summary>Details</summary>
Motivation: 医疗影像分析依赖大量标注数据，而这类数据因需要专家标签且受隐私、法规限制，获取极为困难。论文旨在通过自监督和领域适应方法，降低对标注数据的依赖。

Method: 提出Medformer，一种多任务学习和深度领域自适应的神经网络架构，具备动态输入输出适应机制，能够在多样化的医疗影像数据（如2D X光、3D MRI）上高效预训练。同时设计了新颖的自监督预任务以从无标签数据中提取信息，并在MedMNIST等数据集上进行实验验证。

Result: 实验表明，Medformer能够有效学习通用特征，提升在多种下游医疗影像任务中的表现，在少标签或无标签条件下依然优异。

Conclusion: 本论文提出的框架减少了医疗影像分析对人工标注的依赖，提高了诊断工具的准确性和效率，为深度学习在医疗影像中的广泛应用提供了新的方向。

Abstract: This thesis works to address a pivotal challenge in medical image analysis:
the reliance on extensive labeled datasets, which are often limited due to the
need for expert annotation and constrained by privacy and legal issues. By
focusing on the development of self-supervised learning techniques and domain
adaptation methods, this research aims to circumvent these limitations,
presenting a novel approach to enhance the utility and efficacy of deep
learning in medical imaging.
  Central to this thesis is the development of the Medformer, an innovative
neural network architecture designed for multitask learning and deep domain
adaptation. This model is adept at pre-training on diverse medical image
datasets, handling varying sizes and modalities, and is equipped with a dynamic
input-output adaptation mechanism. This enables efficient processing and
integration of a wide range of medical image types, from 2D X-rays to complex
3D MRIs, thus mitigating the dependency on large labeled datasets.
  Further, the thesis explores the current state of self-supervised learning in
medical imaging. It introduces novel pretext tasks that are capable of
extracting meaningful information from unlabeled data, significantly advancing
the model's interpretative abilities. This approach is validated through
rigorous experimentation, including the use of the MedMNIST dataset,
demonstrating the model's proficiency in learning generalized features
applicable to various downstream tasks.
  In summary, this thesis contributes to the advancement of medical image
analysis by offering a scalable, adaptable framework that reduces reliance on
labeled data. It paves the way for more accurate, efficient diagnostic tools in
healthcare, signifying a major step forward in the application of deep learning
in medical imaging.

</details>


### [184] [Interpretable Tile-Based Classification of Paclitaxel Exposure](https://arxiv.org/abs/2510.23363)
*Sean Fletcher,Gabby Scott,Douglas Currie,Xin Zhang,Yuqi Song,Bruce MacLeod*

Main category: cs.CV

TL;DR: 本文提出了一种基于简单切片与聚合的管道方法，有效提升了药物暴露医学图像的分类准确率，并显著超过了已有基线。


<details>
  <summary>Details</summary>
Motivation: 在药物发现和临床前评估中，医学图像分析能加速决策，但面对细微剂量差异，传统的全图像模型效果有限。因此，开发能更敏感捕捉局部特征的方法具有重要意义。

Method: 作者提出先将显微镜医学图像分割为若干小块（tiles），使用局部块进行分类，然后将所有局部分类结果聚合为全图标签。方法还利用Grad-CAM、Score-CAM和注意力分析理解模型决策机制，以增强可解释性。

Result: 该方法在标准数据集上取得了目前最好的分类准确率，相比已发表的基线方法提升了约20个百分点，交叉验证也证实了结果的稳健性。

Conclusion: 切片聚合方法对于捕捉图像中细微信息极为有效，解释性分析揭示了其鲁棒性，为医学图像分析提供了新的方向。作者已公开代码，促进复现和拓展。

Abstract: Medical image analysis is central to drug discovery and preclinical
evaluation, where scalable, objective readouts can accelerate decision-making.
We address classification of paclitaxel (Taxol) exposure from phase-contrast
microscopy of C6 glioma cells -- a task with subtle dose differences that
challenges full-image models. We propose a simple tiling-and-aggregation
pipeline that operates on local patches and combines tile outputs into an image
label, achieving state-of-the-art accuracy on the benchmark dataset and
improving over the published baseline by around 20 percentage points, with
trends confirmed by cross-validation. To understand why tiling is effective, we
further apply Grad-CAM and Score-CAM and attention analyses, which enhance
model interpretability and point toward robustness-oriented directions for
future medical image research. Code is released to facilitate reproduction and
extension.

</details>


### [185] [PlanarTrack: A high-quality and challenging benchmark for large-scale planar object tracking](https://arxiv.org/abs/2510.23368)
*Yifan Jiao,Xinran Liu,Xiaoqiong Liu,Xiaohui Yuan,Heng Fan,Libo Zhang*

Main category: cs.CV

TL;DR: 本文提出了一个名为PlanarTrack的大规模高质量平面跟踪基准数据集，旨在推动平面跟踪研究的发展，并对现有主流方法进行系统评测。


<details>
  <summary>Details</summary>
Motivation: 近年来，平面跟踪在机器人和增强现实等领域扮演着重要角色，但受限于缺乏大规模基准数据集，深度学习相关的平面跟踪方法发展滞后。

Method: 作者构建了PlanarTrack基准数据集，包含1150个序列及超73万帧数据，覆盖短期和长期、野外无约束环境下的视频。每帧标注由人工多轮审核，通过四角点精细标注。为提升目标多样性，每个序列只包含唯一目标。作者还对10个主流平面跟踪方法进行了全面对比和深入分析。

Result: 实验结果显示，目前领先的平面跟踪方法在PlanarTrack数据集上表现显著下降，说明当前方法尚不能很好应对实际复杂场景。

Conclusion: PlanarTrack是迄今最大、最具多样性和挑战性的平面跟踪专用数据集，有望推动未来平面跟踪方法的改进和发展。

Abstract: Planar tracking has drawn increasing interest owing to its key roles in
robotics and augmented reality. Despite recent great advancement, further
development of planar tracking, particularly in the deep learning era, is
largely limited compared to generic tracking due to the lack of large-scale
platforms. To mitigate this, we propose PlanarTrack, a large-scale high-quality
and challenging benchmark for planar tracking. Specifically, PlanarTrack
consists of 1,150 sequences with over 733K frames, including 1,000 short-term
and 150 new long-term videos, which enables comprehensive evaluation of short-
and long-term tracking performance. All videos in PlanarTrack are recorded in
unconstrained conditions from the wild, which makes PlanarTrack challenging but
more realistic for real-world applications. To ensure high-quality annotations,
each video frame is manually annotated by four corner points with multi-round
meticulous inspection and refinement. To enhance target diversity of
PlanarTrack, we only capture a unique target in one sequence, which is
different from existing benchmarks. To our best knowledge, PlanarTrack is by
far the largest and most diverse and challenging dataset dedicated to planar
tracking. To understand performance of existing methods on PlanarTrack and to
provide a comparison for future research, we evaluate 10 representative planar
trackers with extensive comparison and in-depth analysis. Our evaluation
reveals that, unsurprisingly, the top planar trackers heavily degrade on the
challenging PlanarTrack, which indicates more efforts are required for
improving planar tracking. Our data and results will be released at
https://github.com/HengLan/PlanarTrack

</details>


### [186] [An Efficient Remote Sensing Super Resolution Method Exploring Diffusion Priors and Multi-Modal Constraints for Crop Type Mapping](https://arxiv.org/abs/2510.23382)
*Songxi Yang,Tang Sui,Qunying Huang*

Main category: cs.CV

TL;DR: 本文提出了一种高效的遥感影像超分辨率框架LSSR，结合多源信息，有效提升了影像质量和下游任务表现。


<details>
  <summary>Details</summary>
Motivation: 遥感超分辨率（RSSR）能释放历史低分辨率遥感档案的数据价值，但现有生成式方法（如扩散模型）需要高昂运算资源、推理慢、难以结合辅助约束，且缺乏下游实际任务评估。

Method: 提出LSSR框架，基于冻结的预训练Stable Diffusion模型，引入跨模态注意力，将数字高程模型、土地覆盖、月份等辅助信息和合成孔径雷达作为先验约束，通过Adapter和定制的Fourier NDVI损失，均衡锐利度与光谱保真，多模态数据集支持。

Result: LSSR在RGB和红外波段分别获得了32.63/0.84和23.99/0.78的峰值信噪比和结构相似性，NDVI均方误差最低仅0.042，推理速度提升至0.39秒/张图，显著提升作物边界判别和恢复能力；在NASA HLS超分辨率下，作物分类F1达0.86，超过Sentinel-2的0.85。

Conclusion: LSSR框架能高效、科学地提升遥感图像分辨率，并显著改善下游精细农业应用表现，具备实际推广潜力。

Abstract: Super resolution offers a way to harness medium even lowresolution but
historically valuable remote sensing image archives. Generative models,
especially diffusion models, have recently been applied to remote sensing super
resolution (RSSR), yet several challenges exist. First, diffusion models are
effective but require expensive training from scratch resources and have slow
inference speeds. Second, current methods have limited utilization of auxiliary
information as real-world constraints to reconstruct scientifically realistic
images. Finally, most current methods lack evaluation on downstream tasks. In
this study, we present a efficient LSSR framework for RSSR, supported by a new
multimodal dataset of paired 30 m Landsat 8 and 10 m Sentinel 2 imagery. Built
on frozen pretrained Stable Diffusion, LSSR integrates crossmodal attention
with auxiliary knowledge (Digital Elevation Model, land cover, month) and
Synthetic Aperture Radar guidance, enhanced by adapters and a tailored Fourier
NDVI loss to balance spatial details and spectral fidelity. Extensive
experiments demonstrate that LSSR significantly improves crop boundary
delineation and recovery, achieving state-of-the-art performance with Peak
Signal-to-Noise Ratio/Structural Similarity Index Measure of 32.63/0.84 (RGB)
and 23.99/0.78 (IR), and the lowest NDVI Mean Squared Error (0.042), while
maintaining efficient inference (0.39 sec/image). Moreover, LSSR transfers
effectively to NASA Harmonized Landsat and Sentinel (HLS) super resolution,
yielding more reliable crop classification (F1: 0.86) than Sentinel-2 (F1:
0.85). These results highlight the potential of RSSR to advance precision
agriculture.

</details>


### [187] [VideoTG-R1: Boosting Video Temporal Grounding via Curriculum Reinforcement Learning on Reflected Boundary Annotations](https://arxiv.org/abs/2510.23397)
*Lu Dong,Haiyu Zhang,Han Lin,Ziang Yan,Xiangyu Zeng,Hongjie Zhang,Yifei Huang,Yi Wang,Zhen-Hua Ling,Limin Wang,Yali Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新的视频时序定位（VTG）方法VideoTG-R1，结合MLLM和课程式强化学习，提高了训练效率并减少了模糊监督和困难样本带来的负面影响，实验上显著优于全量数据方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于大多模态大模型的VTG方法在用强化学习进行训练时，没有充分考虑标注样本的质量与难易度问题。部分样本只做了部分标注，导致训练时监督信号模糊；同时，一些难定位的样本在强化学习过程中很难提升，影响整体训练效率。作者希望针对以上问题提出解决方法。

Method: 作者提出了VideoTG-R1框架。核心包括两个新组件：1）边界反射代理，能利用MLLM预测标注区间外与查询相关的时间戳，从而检测和过滤存在部分标注的样本，以减少监督信号不明造成的影响；2）难度估计代理，评估每个样本难易度，根据学习进度动态掩码难样本，逐步降低训练难度，形成课程式强化学习。

Result: 在VTG与grounded VideoQA任务上实验，VideoTG-R1仅用10%的训练数据和21%的算力预算，即在GRPO和SFT两种训练策略下，性能均超越使用全部数据的对比方法。

Conclusion: 针对标注样本不全和难定位样本问题，本文提出的VideoTG-R1显著提升了数据与计算效率，为视频理解和多模态任务提供了新的训练思路与方法。

Abstract: Video temporal grounding (VTG) aims to locate precise segments in videos
based on language queries, which is a fundamental challenge in video
understanding. While recent Multimodal Large Language Models (MLLMs) have shown
promise in tackling VTG through reinforcement learning (RL), they overlook the
challenges arising from both the quality and difficulty of training samples.
(1) Partially annotated samples. Many samples contain relevant segments beyond
the annotated interval, introducing ambiguous supervision. (2) Hard-to-ground
samples. Samples with poor zero-shot performance produce consistently low and
indistinguishable rewards during RL training, exhibiting no clear preference
among multiple outputs and thus hindering learning efficiency. To address these
challenges, we propose VideoTG-R1, a novel curriculum RL framework with
reflected boundary annotations, enabling data-efficient training. Specifically,
we propose a Boundary Reflection Agent that utilizes MLLMs to predict
query-relevant timestamps outside the annotated intervals, allowing us to
identify and filter out partially annotated samples, thereby reducing
ambiguity. Furthermore, we introduce a Difficulty Estimation Agent to assess
the training difficulty of each sample and design a curriculum RL strategy that
dynamically masks the videos of hard-to-ground samples according to the
training steps, easing the training difficulty and providing clearer
preference. Experiments on the VTG and grounded VideoQA tasks demonstrate the
effectiveness of our method. Remarkably, with only 10% of the training samples
and 21% of the computational budget, VideoTG-R1 outperforms full-data
counterparts under both group relative policy optimization (GRPO) and
supervised fine-tuning (SFT). The code is available at
https://github.com/ldong1111/VideoTG-R1.

</details>


### [188] [Color and Frequency Correction for Image Colorization](https://arxiv.org/abs/2510.23399)
*Yun Kai Zhuang*

Main category: cs.CV

TL;DR: 本文重优化了图像上色模型DDColor，通过两种优化方案提升了上色效果，改善了特定频段和输入维度导致的问题，实验验证了性能提升。


<details>
  <summary>Details</summary>
Motivation: 作者发现现有DDColor模型在某些频段表现有限，且输入维度不足会引起偏色问题，因此希望对其进行优化提升上色质量。

Method: 作者针对DDColor存在的问题，设计并结合了两种优化方案，方法聚焦于提升模型对频率信息的处理能力和增加输入信息量。

Result: 优化后的模型在PSNR和SSIM等指标上均实现了性能提升，证明了方法的有效性。

Conclusion: 结合两种优化方案后，模型有效解决了频段限制和输入不足带来的偏色问题，提高了总体图像上色的质量和一致性。

Abstract: The project has carried out the re-optimization of image coloring in
accordance with the existing Autocolorization direction model DDColor. For the
experiments on the existing weights of DDColor, we found that it has
limitations in some frequency bands and the color cast problem caused by
insufficient input dimension. We construct two optimization schemes and combine
them, which achieves the performance improvement of indicators such as PSNR and
SSIM of the images after DDColor.

</details>


### [189] [Symmetria: A Synthetic Dataset for Learning in Point Clouds](https://arxiv.org/abs/2510.23414)
*Ivan Sipiran,Gustavo Santelices,Lucas Oyarzún,Andrea Ranieri,Chiara Romanengo,Silvia Biasotti,Bianca Falcidieno*

Main category: cs.CV

TL;DR: 提出了一种名为Symmetria的公式生成型点云数据集，可以灵活生成任意规模数据，非常适合点云自监督预训练，并带来优异的下游性能。


<details>
  <summary>Details</summary>
Motivation: 现有点云学习方法因缺乏大规模数据集而受限，训练及扩展受阻。本研究旨在通过可无限扩展、具有准确标签的数据集，打破该瓶颈，促进点云领域发展。

Method: 设计基于对称性且能自动生成的Symmetria点云数据集，利用公式驱动的方式高效生成多样化且结构明确的形状，支持不同任务和扩展性，并在自监督预训练和下游任务中进行了实验评估。

Result: Symmetria在点云自监督预训练中表现优异，所训练模型在分类、分割等下游任务上性能突出，尤其在few-shot学习中效果显著；此外，数据集适用于微调真实世界对象分类任务，并设立了对称检测新基准任务。

Conclusion: Symmetria不仅突破了点云领域数据稀缺问题，可大规模生成高质量带标签点云数据，还极大提升了模型的泛化与实用能力，对后续研究和创新具有重要推动作用。

Abstract: Unlike image or text domains that benefit from an abundance of large-scale
datasets, point cloud learning techniques frequently encounter limitations due
to the scarcity of extensive datasets. To overcome this limitation, we present
Symmetria, a formula-driven dataset that can be generated at any arbitrary
scale. By construction, it ensures the absolute availability of precise ground
truth, promotes data-efficient experimentation by requiring fewer samples,
enables broad generalization across diverse geometric settings, and offers easy
extensibility to new tasks and modalities. Using the concept of symmetry, we
create shapes with known structure and high variability, enabling neural
networks to learn point cloud features effectively. Our results demonstrate
that this dataset is highly effective for point cloud self-supervised
pre-training, yielding models with strong performance in downstream tasks such
as classification and segmentation, which also show good few-shot learning
capabilities. Additionally, our dataset can support fine-tuning models to
classify real-world objects, highlighting our approach's practical utility and
application. We also introduce a challenging task for symmetry detection and
provide a benchmark for baseline comparisons. A significant advantage of our
approach is the public availability of the dataset, the accompanying code, and
the ability to generate very large collections, promoting further research and
innovation in point cloud learning.

</details>


### [190] [Towards Generalisable Foundation Models for 3D Brain MRI](https://arxiv.org/abs/2510.23415)
*Moona Mazher,Geoff J. M. Parker,Daniel C. Alexander*

Main category: cs.CV

TL;DR: BrainFound是一个为3D脑MRI设计的自监督基础模型，通过结合多模态信息和体积数据，显著提升了下游任务表现，并减少对标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能基础模型在医学影像领域的应用不断深化，然而针对3D脑MRI基础模型仍然稀缺，且对大规模有标签数据的依赖限制了模型推广和应用。

Method: 该研究基于DINO-v2视觉Transformer，将其扩展到适应3D脑解剖信息，能处理连续MRI切片的体积数据，同时支持单模态与多模态输入，并能推广到多种成像协议和临床场景。

Result: BrainFound在疾病检测、图像分割等任务上，相较于现有自监督和有监督预训练方法均表现更佳，尤其在标签稀缺和多对比度情境下优势明显。

Conclusion: BrainFound能高效整合多种3D MRI信息，提高诊断准确性、降低专家标注需求，是3D神经影像领域具有临床和研究应用前景的可扩展解决方案。

Abstract: Foundation models in artificial intelligence (AI) are transforming medical
imaging by enabling general-purpose feature learning from large-scale,
unlabeled datasets. In this work, we introduce BrainFound, a self-supervised
foundation model for brain MRI, built by extending DINO-v2, a vision
transformer originally designed for 2D natural images. BrainFound adapts
DINO-v2 to model full 3D brain anatomy by incorporating volumetric information
from sequential MRI slices, moving beyond conventional single-slice paradigms.
It supports both single- and multimodal inputs, enabling a broad range of
downstream tasks, including disease detection and image segmentation, while
generalising across varied imaging protocols and clinical scenarios. We show
that BrainFound consistently outperforms existing self-supervised pretraining
strategies and supervised baselines, particularly in label-scarce and
multi-contrast settings. By integrating information from diverse 3D MRI
modalities (e.g., T1, T2, FLAIR), it enhances diagnostic accuracy and reduces
dependency on extensive expert annotations. This flexibility makes BrainFound a
scalable and practical solution for 3D neuroimaging pipelines, with significant
potential for clinical deployment and research innovation.

</details>


### [191] [Quality-controlled registration of urban MLS point clouds reducing drift effects by adaptive fragmentation](https://arxiv.org/abs/2510.23416)
*Marco Antonio Ortiz Rincon,Yihui Yang,Christoph Holst*

Main category: cs.CV

TL;DR: 本研究提出了一种高效且准确的工作流程，实现大规模移动激光扫描（MLS）点云在城市街道场景下的配准，大幅提升了配准的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 城市街道点云数据存在密度不均、噪声、遮挡等问题，传统点云配准方法难以应对，亟需高效准确的新方法推动无人化三维建模与城市数字化。

Method: 1）提出半球检查（SSC）预处理技术，自动分割MLS轨迹数据，减少点云漂移影响并增加每段的几何特征；2）提出基于平面体素的广义最近点法（PV-GICP），精细注册时只利用体素区内的平面，有效提高配准精度并将计算时间节省一半以上。

Result: 在慕尼黑市中心真实数据集实验中，达到亚厘米级（<0.01 m）平均配准精度，处理时间大幅缩短，优于传统点到面ICP方法。

Conclusion: 所提方法能有效应对城市复杂点云融合难题，助力城市三维建模自动化及更新，广泛适用于城市规划、基础设施管理和城市动态监测等领域。

Abstract: This study presents a novel workflow designed to efficiently and accurately
register large-scale mobile laser scanning (MLS) point clouds to a target model
point cloud in urban street scenarios. This workflow specifically targets the
complexities inherent in urban environments and adeptly addresses the
challenges of integrating point clouds that vary in density, noise
characteristics, and occlusion scenarios, which are common in bustling city
centers. Two methodological advancements are introduced. First, the proposed
Semi-sphere Check (SSC) preprocessing technique optimally fragments MLS
trajectory data by identifying mutually orthogonal planar surfaces. This step
reduces the impact of MLS drift on the accuracy of the entire point cloud
registration, while ensuring sufficient geometric features within each fragment
to avoid local minima. Second, we propose Planar Voxel-based Generalized
Iterative Closest Point (PV-GICP), a fine registration method that selectively
utilizes planar surfaces within voxel partitions. This pre-process strategy not
only improves registration accuracy but also reduces computation time by more
than 50% compared to conventional point-to-plane ICP methods. Experiments on
real-world datasets from Munich's inner city demonstrate that our workflow
achieves sub-0.01 m average registration accuracy while significantly
shortening processing times. The results underscore the potential of the
proposed methods to advance automated 3D urban modeling and updating, with
direct applications in urban planning, infrastructure management, and dynamic
city monitoring.

</details>


### [192] [MiCADangelo: Fine-Grained Reconstruction of Constrained CAD Models from 3D Scans](https://arxiv.org/abs/2510.23429)
*Ahmet Serdar Karadeniz,Dimitrios Mallis,Danila Rukhovich,Kseniya Cherenkova,Anis Kacem,Djamila Aouada*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的将3D扫描数据逆向工程为可编辑参数化CAD模型的方法，通过借鉴人类设计师的建模流程，利用多平面截面提取2D特征，大幅提升了模型的细致度和可编辑性。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的CAD逆向工程方法难以兼顾模型的完全参数化和细致几何细节，且忽视了草图级约束，导致逆向得到的模型在工业场景下的实用性受限。

Method: 设计了一种新型的逆向工程流程，采用多平面截面提取二维图案，结合草图级约束，将其用于3D模型的参数化重建，兼顾细节捕捉与后期可编辑性。

Result: 提出的方法能够更有效地重建细致、可编辑的参数化CAD模型，且在包括草图约束的情况下首次超越现有主流方法。

Conclusion: 该方法显著提升了3D扫描数据到参数化CAD建模的细致度和实用性，有望推动自动化设计及逆向工程领域的进步。

Abstract: Computer-Aided Design (CAD) plays a foundational role in modern manufacturing
and product development, often requiring designers to modify or build upon
existing models. Converting 3D scans into parametric CAD representations--a
process known as CAD reverse engineering--remains a significant challenge due
to the high precision and structural complexity of CAD models. Existing deep
learning-based approaches typically fall into two categories: bottom-up,
geometry-driven methods, which often fail to produce fully parametric outputs,
and top-down strategies, which tend to overlook fine-grained geometric details.
Moreover, current methods neglect an essential aspect of CAD modeling:
sketch-level constraints. In this work, we introduce a novel approach to CAD
reverse engineering inspired by how human designers manually perform the task.
Our method leverages multi-plane cross-sections to extract 2D patterns and
capture fine parametric details more effectively. It enables the reconstruction
of detailed and editable CAD models, outperforming state-of-the-art methods
and, for the first time, incorporating sketch constraints directly into the
reconstruction process.

</details>


### [193] [CURVETE: Curriculum Learning and Progressive Self-supervised Training for Medical Image Classification](https://arxiv.org/abs/2510.23442)
*Asmaa Abbas,Mohamed Gaber,Mohammed M. Abdelsamea*

Main category: cs.CV

TL;DR: 本文提出CURVETE方法，通过课程学习与逐步自监督训练，有效提升医学影像分类准确性，尤其适用于样本有限且类别分布不均场景，对多个数据集取得领先表现。


<details>
  <summary>Details</summary>
Motivation: 医学影像分析中，高质量有标注样本难获取。虽然迁移学习有助于缓解样本不足，但类别分布不均时微调效果有限，因此需要更稳健的泛化和分类性能方法。

Method: 提出CURVETE深度卷积神经网络：1）在无标签样本训练阶段引入基于样本粒度的课程学习策略；2）下游任务中采用类别分解应对类别不平衡；对比有无课程学习组件下的自监督分解策略，评估模型性能。

Result: CURVETE在三个医学影像数据集（脑肿瘤、膝盖X光、Mini-DDSM）上取得优异分类准确率。以ResNet-50为基础，在脑肿瘤、膝盖X光、Mini-DDSM取得96.60%、75.6%、93.35%的准确率，DenseNet-121也实现95.77%、80.36%、93.22%，均优于其他策略。

Conclusion: CURVETE方法能有效改善小样本及类别分布不均情况下的医疗影像分类性能，展现出良好的泛化与实用潜力。

Abstract: Identifying high-quality and easily accessible annotated samples poses a
notable challenge in medical image analysis. Transfer learning techniques,
leveraging pre-training data, offer a flexible solution to this issue. However,
the impact of fine-tuning diminishes when the dataset exhibits an irregular
distribution between classes. This paper introduces a novel deep convolutional
neural network, named Curriculum Learning and Progressive Self-supervised
Training (CURVETE). CURVETE addresses challenges related to limited samples,
enhances model generalisability, and improves overall classification
performance. It achieves this by employing a curriculum learning strategy based
on the granularity of sample decomposition during the training of generic
unlabelled samples. Moreover, CURVETE address the challenge of irregular class
distribution by incorporating a class decomposition approach in the downstream
task. The proposed method undergoes evaluation on three distinct medical image
datasets: brain tumour, digital knee x-ray, and Mini-DDSM datasets. We
investigate the classification performance using a generic self-supervised
sample decomposition approach with and without the curriculum learning
component in training the pretext task. Experimental results demonstrate that
the CURVETE model achieves superior performance on test sets with an accuracy
of 96.60% on the brain tumour dataset, 75.60% on the digital knee x-ray
dataset, and 93.35% on the Mini-DDSM dataset using the baseline ResNet-50.
Furthermore, with the baseline DenseNet-121, it achieved accuracies of 95.77%,
80.36%, and 93.22% on the brain tumour, digital knee x-ray, and Mini-DDSM
datasets, respectively, outperforming other training strategies.

</details>


### [194] [FRBNet: Revisiting Low-Light Vision through Frequency-Domain Radial Basis Network](https://arxiv.org/abs/2510.23444)
*Fangtong Sun,Congyu Li,Ke Yang,Yuchen Pan,Hanwen Yu,Xichuan Zhang,Yiying Li*

Main category: cs.CV

TL;DR: 本文提出一种新颖的频域网络（FRBNet），通过频域信道比和可学习滤波器，有效增强低光照条件下的图像特征，对下游检测和分割任务表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有低光照视觉方法仍无法完整建模低光照条件，导致特征学习效果有限，影响下游视觉任务，亟需更优的低光照特征提取方法。

Method: 作者重新分析低光照图像形成过程，扩展经典的Lambertian模型到低光环境，并转向频域分析，理论上证明频域信道比可提取光照不变特征。基于此，设计了FRBNet模块，将该操作与可学习频域滤波结合，可端到端训练，且易于集成进现有网络。

Result: FRBNet在多个低光下游任务上取得显著提升，包括暗场检测提升2.2 mAP，夜间分割提升2.9 mIoU。

Conclusion: 通过频域建模和特征增强方法，FRBNet有效提升了低光照条件下图像表示能力，为低光视觉各类应用提供了新思路。

Abstract: Low-light vision remains a fundamental challenge in computer vision due to
severe illumination degradation, which significantly affects the performance of
downstream tasks such as detection and segmentation. While recent
state-of-the-art methods have improved performance through invariant feature
learning modules, they still fall short due to incomplete modeling of low-light
conditions. Therefore, we revisit low-light image formation and extend the
classical Lambertian model to better characterize low-light conditions. By
shifting our analysis to the frequency domain, we theoretically prove that the
frequency-domain channel ratio can be leveraged to extract
illumination-invariant features via a structured filtering process. We then
propose a novel and end-to-end trainable module named \textbf{F}requency-domain
\textbf{R}adial \textbf{B}asis \textbf{Net}work (\textbf{FRBNet}), which
integrates the frequency-domain channel ratio operation with a learnable
frequency domain filter for the overall illumination-invariant feature
enhancement. As a plug-and-play module, FRBNet can be integrated into existing
networks for low-light downstream tasks without modifying loss functions.
Extensive experiments across various downstream tasks demonstrate that FRBNet
achieves superior performance, including +2.2 mAP for dark object detection and
+2.9 mIoU for nighttime segmentation. Code is available at:
https://github.com/Sing-Forevet/FRBNet.

</details>


### [195] [Video-Thinker: Sparking "Thinking with Videos" via Reinforcement Learning](https://arxiv.org/abs/2510.23473)
*Shijian Wang,Jiarui Jin,Xingjian Wang,Linxin Song,Runhao Fu,Hecheng Wang,Zongyuan Ge,Yuan Lu,Xuelian Cheng*

Main category: cs.CV

TL;DR: 该论文提出了Video-Thinker框架，通过自主调用自身的“定位”和“描述”能力，使多模态大模型（MLLMs）具备视频推理能力，并显著提升了在多项视频推理基准上的表现。


<details>
  <summary>Details</summary>
Motivation: 目前多模态大模型已在图像推理领域取得突破（例如“Thinking with Images”），但这种动态图像推理范式尚未扩展到视频推理领域。

Method: 作者提出了Video-Thinker框架，使MLLMs在推理过程中能够自主利用内置的定位和描述能力生成推理线索。为支持这一能力，构建了Video-Thinker-10K数据集，包含自动工具使用的链式思维数据。训练流程包括监督微调（SFT）和Group Relative Policy Optimization（GRPO）以强化推理能力。无需调用外部工具，模型可自主完成视频推理中的定位和描述任务。

Result: Video-Thinker在视频推理领域多个基准数据集（如Video-Holmes、CG-Bench-Reasoning、VRBench）上取得了显著性能提升。Video-Thinker-7B版本在7B规模的MLLMs中表现出最优，显著优于Video-R1等现有基线。

Conclusion: Video-Thinker能够有效托管和调度MLLMs的内在工具，为视频推理带来了全新范式，并达到当前最优性能，推动了多模态大模型在视频领域的应用。

Abstract: Recent advances in image reasoning methods, particularly "Thinking with
Images", have demonstrated remarkable success in Multimodal Large Language
Models (MLLMs); however, this dynamic reasoning paradigm has not yet been
extended to video reasoning tasks. In this paper, we propose Video-Thinker,
which empowers MLLMs to think with videos by autonomously leveraging their
intrinsic "grounding" and "captioning" capabilities to generate reasoning clues
throughout the inference process. To spark this capability, we construct
Video-Thinker-10K, a curated dataset featuring autonomous tool usage within
chain-of-thought reasoning sequences. Our training strategy begins with
Supervised Fine-Tuning (SFT) to learn the reasoning format, followed by Group
Relative Policy Optimization (GRPO) to strengthen this reasoning capability.
Through this approach, Video-Thinker enables MLLMs to autonomously navigate
grounding and captioning tasks for video reasoning, eliminating the need for
constructing and calling external tools. Extensive experiments demonstrate that
Video-Thinker achieves significant performance gains on both in-domain tasks
and challenging out-of-domain video reasoning benchmarks, including
Video-Holmes, CG-Bench-Reasoning, and VRBench. Our Video-Thinker-7B
substantially outperforms existing baselines such as Video-R1 and establishes
state-of-the-art performance among 7B-sized MLLMs.

</details>


### [196] [UrbanIng-V2X: A Large-Scale Multi-Vehicle, Multi-Infrastructure Dataset Across Multiple Intersections for Cooperative Perception](https://arxiv.org/abs/2510.23478)
*Karthikeyan Chandra Sekaran,Markus Geisler,Dominik Rößle,Adithya Mohan,Daniel Cremers,Wolfgang Utschick,Michael Botsch,Werner Huber,Torsten Schön*

Main category: cs.CV

TL;DR: 本文提出了UrbanIng-V2X，这是首个包含多个城市路口、车辆与基础设施传感器协同感知的大规模多模态数据集，极大丰富了协同感知研究的数据基础。


<details>
  <summary>Details</summary>
Motivation: 现有协同感知数据集通常局限于单一路口或单一车辆，缺乏涵盖多路口、多车辆和多基础设施的复杂交通环境，导致算法易过拟合且泛化能力不足。

Method: UrbanIng-V2X在德国英戈尔施塔特的三个城区路口采集，包含34组时序和空间对齐的传感器数据，每组序列持续20秒，涵盖12个车载RGB摄像头、2个车载激光雷达、17个基础设施热像仪和12个基础设施激光雷达。数据以10Hz频率标注13类目标的3D包围框，共约71.2万个标注实例。

Result: 数据集支持车辆与基础设施之间的协同感知，包括真实交通环境和多种传感器模式，并对最先进协同感知方法进行了全面评测。

Conclusion: UrbanIng-V2X填补了多路口、多传感器、真实场景下协同感知数据集的空白，将促进智能交通和协同感知算法的研究。

Abstract: Recent cooperative perception datasets have played a crucial role in
advancing smart mobility applications by enabling information exchange between
intelligent agents, helping to overcome challenges such as occlusions and
improving overall scene understanding. While some existing real-world datasets
incorporate both vehicle-to-vehicle and vehicle-to-infrastructure interactions,
they are typically limited to a single intersection or a single vehicle. A
comprehensive perception dataset featuring multiple connected vehicles and
infrastructure sensors across several intersections remains unavailable,
limiting the benchmarking of algorithms in diverse traffic environments.
Consequently, overfitting can occur, and models may demonstrate misleadingly
high performance due to similar intersection layouts and traffic participant
behavior. To address this gap, we introduce UrbanIng-V2X, the first
large-scale, multi-modal dataset supporting cooperative perception involving
vehicles and infrastructure sensors deployed across three urban intersections
in Ingolstadt, Germany. UrbanIng-V2X consists of 34 temporally aligned and
spatially calibrated sensor sequences, each lasting 20 seconds. All sequences
contain recordings from one of three intersections, involving two vehicles and
up to three infrastructure-mounted sensor poles operating in coordinated
scenarios. In total, UrbanIng-V2X provides data from 12 vehicle-mounted RGB
cameras, 2 vehicle LiDARs, 17 infrastructure thermal cameras, and 12
infrastructure LiDARs. All sequences are annotated at a frequency of 10 Hz with
3D bounding boxes spanning 13 object classes, resulting in approximately 712k
annotated instances across the dataset. We provide comprehensive evaluations
using state-of-the-art cooperative perception methods and publicly release the
codebase, dataset, HD map, and a digital twin of the complete data collection
environment.

</details>


### [197] [MergeMix: A Unified Augmentation Paradigm for Visual and Multi-Modal Understanding](https://arxiv.org/abs/2510.23479)
*Xin Jin,Siyuan Li,Siyong Jian,Kai Yu,Huan Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为MergeMix的新型训练增强范式，用于改进多模态大语言模型（MLLMs）的视觉-语言对齐。MergeMix结合了SFT和RL的优点，兼顾扩展性、稳健性和对齐质量。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs视觉-语言对齐方法主要通过有监督微调（SFT）或强化学习（RL）实现。SFT对人类标注依赖大，无法捕捉细微偏好；而RL训练不稳定且代价高，两者存在扩展性、对齐质量、稳健性的权衡。

Method: MergeMix在训练时对图片进行基于注意力的token merge混合，保留更多聚类表达和空间上下文，然后通过混合图片与原始图片构建偏好对，并引入SimPO损失进行优化。这一方法像Mixup一样，提升了注意力一致性和效率。

Result: 实验表明，MergeMix作为数据增强方式，在分类任务和多模态大模型中超越了其他启发式方法，在保证竞争性准确率的同时显著提升效率。

Conclusion: MergeMix为偏好对齐和多模态大语言模型训练提供了一种可扩展、高效、对齐质量优异的新方法。

Abstract: Vision-language alignment in multi-modal large language models (MLLMs)
typically relies on supervised fine-tuning (SFT) or reinforcement learning
(RL). SFT is stable and efficient but requires large-scale human annotations
and cannot capture subtle preferences, while RL brings in a reward signal for
training, but suffers from overhead and instability. These limitations
highlight a trade-off between scalability, robustness, and alignment quality.
To address this, we propose MergeMix, a training-time augmentation paradigm
that bridges SFT and RL. It first applies an attention-aware image mixing via
token merge with more cluster representation and spatial context, and then
presents a preference-driven training paradigm for MLLMs by building preference
pairs with mixed images and raw images, and optimizing via SimPO loss. As a
mixup augmentation, MergeMix enhances attention consistency and efficiency,
surpassing other heuristic-based methods in classification. Extensive
experiments demonstrate that MergeMix achieves competitive accuracy with
improved efficiency, providing a scalable approach to preference alignment in
classification and MLLMs.

</details>


### [198] [On the Faithfulness of Visual Thinking: Measurement and Enhancement](https://arxiv.org/abs/2510.23482)
*Zujing Liu,Junwen Pan,Qi She,Yuan Gao,Guisong Xia*

Main category: cs.CV

TL;DR: 本文发现当前大型视觉-语言模型（LVLM）在多模态推理过程中，引用的视觉信息往往不准确，尽管答案正确，推理过程缺乏真实性。作者分析原因、提出了新的自动化评估指标和训练策略SCCM以提升模型视觉推理的真实性，并在多个基准上验证有效。


<details>
  <summary>Details</summary>
Motivation: LVLM在推理生成过程中常整合不准确的视觉信息，这使推理链条缺乏真实性，影响模型的解释性和可信度。现有强化学习仅鼓励形式混合而未考虑视觉内容的正确性，因此急需改进。

Method: 作者首先通过干预实验量化推理过程中视觉与文本信息对结果的影响。随后，提出一个自动化评估度量，从可靠性与充分性评估视觉证据的真实性。最后，提出SCCM训练策略，引导模型生成足够且独立有效的视觉组件来提升推理真实性。该方法无需人工标注、可兼容既有RFT流程。

Result: 实验证明，现有MCoT推理链中的视觉证据既不可靠亦不充分；采用SCCM训练后，各项细粒度感知与推理基准上视觉真实性指标明显提升。

Conclusion: 当前LVLM在多模态推理中依赖视觉信息不真实，存在可靠性和充分性问题。SCCM训练策略能有效提升视觉证据在推理过程中的作用，从而改善模型推理的真实性与可解释性。

Abstract: Recent large vision-language models (LVLMs) can generate vision-text
multimodal chain-of-thought (MCoT) traces after reinforcement fine-tuning
(RFT). However, we observe that the visual information incorporated in MCoT is
often inaccurate, though still yield correct answers, indicating a lack of
faithfulness in the MCoT reasoning process. We attribute this unfaithfulness to
the RL reward in RFT, which solely incentivizes the format of interleaved
vision-text cues, ie, it encourages the model to incorporate visual information
into its text reasoning steps without considering the correctness of the visual
information. In this paper, we first probe the faithfulness of MCoT by
measuring how much the prediction changes when its visual and textual thoughts
are intervened. Surprisingly, the model's predictions remain nearly unchanged
under visual intervention but change significantly under textual intervention,
indicating that the visual evidence is largely ignored. To further analyze
visual information, we introduce an automated LVLM-based evaluation metric that
quantifies the faithfulness of visual cues from two perspectives: reliability
and sufficiency. Our evaluation reveals that the visual information in current
MCoT traces is simultaneously unreliable and insufficient. To address this
issue, we propose a novel MCoT learning strategy termed Sufficient-Component
Cause Model (SCCM) learning. This approach encourages the MCoT to generate
sufficient yet minimal visual components that are independently capable of
leading to correct answers. We note that the proposed SCCM is annotation-free
and compatible with various RFT for MCoT in a plug-and-play manner. Empirical
results demonstrate that SCCM consistently improves the visual faithfulness
across a suite of fine-grained perception and reasoning benchmarks. Code is
available at https://github.com/EugeneLiu01/Faithful_Thinking_with_Image.

</details>


### [199] [Yesnt: Are Diffusion Relighting Models Ready for Capture Stage Compositing? A Hybrid Alternative to Bridge the Gap](https://arxiv.org/abs/2510.23494)
*Elisabeth Jüttner,Leona Krath,Stefan Korfhage,Hannah Dröge,Matthias B. Hullin,Markus Plack*

Main category: cs.CV

TL;DR: 本文提出了一种混合重光照框架，有效提升体积视频在虚拟场景中的重光照质量，兼顾时序稳定性和规模扩展能力。通过结合扩散模型的材质先验、时序正则化与物理渲染方法，相较现有仅用扩散模型的方案，达到了更高的序列一致性和更广泛的适用范围。


<details>
  <summary>Details</summary>
Motivation: 体积视频重光照对于将真实表演带入虚拟世界至关重要，但现有方法在时序稳定性和生产级应用上存在不足。单帧扩散模型虽然有效，但拓展到序列时噪声大且不稳定，视频级扩散模型又受限于内存和处理规模。亟需一种兼顾稳定性、物理一致性与可扩展性的重光照方案。

Method: 提出了一种混合架构，将单帧扩散模型获得的材质属性用时序正则（通过光流引导）进行整合，形成时序一致的分解结果。对于间接光照效果（如阴影、反射），从高斯不透明度场中提取网格代理，并在标准图形流水线中进行物理渲染。该方法可汇聚多次随机估计，提升结果平滑性和一致性。

Result: 在真实采集和合成数据集上，所提出方法相较扩散模型基线，能显著提升长期视频序列的重光照稳定性，并能处理更长的视频片段，突破了单一视频扩散模型的计算规模瓶颈。

Conclusion: 结合学习先验与物理约束的混合方法，是实现生产级体积视频重光照的有效途径。本方法在时序一致性和大规模处理上优于现有方案，为实用化和商用化提供重要基础。

Abstract: Volumetric video relighting is essential for bringing captured performances
into virtual worlds, but current approaches struggle to deliver temporally
stable, production-ready results. Diffusion-based intrinsic decomposition
methods show promise for single frames, yet suffer from stochastic noise and
instability when extended to sequences, while video diffusion models remain
constrained by memory and scale. We propose a hybrid relighting framework that
combines diffusion-derived material priors with temporal regularization and
physically motivated rendering. Our method aggregates multiple stochastic
estimates of per-frame material properties into temporally consistent shading
components, using optical-flow-guided regularization. For indirect effects such
as shadows and reflections, we extract a mesh proxy from Gaussian Opacity
Fields and render it within a standard graphics pipeline. Experiments on real
and synthetic captures show that this hybrid strategy achieves substantially
more stable relighting across sequences than diffusion-only baselines, while
scaling beyond the clip lengths feasible for video diffusion. These results
indicate that hybrid approaches, which balance learned priors with physically
grounded constraints, are a practical step toward production-ready volumetric
video relighting.

</details>


### [200] [VOLD: Reasoning Transfer from LLMs to Vision-Language Models via On-Policy Distillation](https://arxiv.org/abs/2510.23497)
*Walid Bousselham,Hilde Kuehne,Cordelia Schmid*

Main category: cs.CV

TL;DR: 本论文提出了一种名为VOLD的新框架，将文本推理能力迁移到视觉语言模型（VLM），以提升其复杂推理能力，取得了比现有方法更好的效果。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在复杂推理任务上的训练受限于高质量图文推理数据的稀缺，而纯文本推理数据则丰富且易获取。如何利用这些丰富的文本推理资源提升VLM的推理能力，是本研究关注的问题。

Method: 作者提出了VOLD框架，将文本教师模型的推理能力通过结合Group Relative Policy Optimization（GRPO）和on-policy蒸馏方式迁移到VLM学生模型中。该方法允许学生模型在推理过程中由教师模型指导；同时，研究还加入了一个cold-start对齐步骤，确保学生和教师模型在在线训练阶段的分布一致性，从而使蒸馏取得实质效果。

Result: VOLD在包括MMMU-Pro、MathVision、MathVista和LogicVista等多个基准测试上，显著优于基线模型，并超越了现有最新技术水平。消融实验显示，cold-start对齐步骤对实现基于文本教师进行有效蒸馏极为重要。

Conclusion: VOLD能够有效利用大规模文本推理资源，提升VLM在复杂推理任务中的表现，并证明了合适的对齐和蒸馏策略对于性能提升不可或缺。

Abstract: Training vision-language models (VLMs) for complex reasoning remains a
challenging task, i.a. due to the scarcity of high-quality image-text reasoning
data. Conversely, text-based reasoning resources are abundant and scalable, but
it is still an open question how to leveraging them for VLM reasoning. To
address this problem, we propose VOLD, a framework to transfer reasoning
capabilities from text-only teacher models to VLM student models. To this end,
VOLD combines reinforcement learning via Group Relative Policy Optimization
(GRPO) with on-policy distillation, which allows the student reasoning traces
to be guided by the teacher model, resulting in a significant gain over using
GRPO alone. We further show that a cold-start alignment is essential for an
effective transfer during the online training phase in this scenario and that
without sufficient distributional alignment between teacher and student,
on-policy distillation fails to provide meaningful guidance. We evaluate VOLD
across diverse benchmarks including MMMU-Pro, MathVision, MathVista, and
LogicVista, showing that VOLD outperforms the baseline model significantly and
improves over the state of the art by a margin. Our ablation shows the
importance of a cold-start alignment via SFT for on-policy distillation with a
text-only teacher.

</details>


### [201] [iPac: Incorporating Intra-image Patch Context into Graph Neural Networks for Medical Image Classification](https://arxiv.org/abs/2510.23504)
*Usama Zidan,Mohamed Gaber,Mohammed M. Abdelsamea*

Main category: cs.CV

TL;DR: 提出了一种新的将图神经网络应用于医学图像分类的方法iPac，通过更好地建模图像中元素间的结构和关系提升分类效果，实验显示可提升平均准确率5%。


<details>
  <summary>Details</summary>
Motivation: 现有的图神经网络在图像分类任务中未能充分考虑图像内部视觉实体的结构和关系，导致性能有限，尤其在要求高语义理解的医学图像领域亟需改进。

Method: iPac方法包含图像分块、特征提取、聚类、图构建和基于图的学习多个阶段，将图像转化为更具结构性和表达力的图形表达，通过聚类和关系建模有效提升图神经网络的图像分类能力。

Result: 在多个医学图像数据集上的实验显示，iPac方法相比已有方法平均分类精度提升最高可达5%。

Conclusion: iPac为医学图像分类任务提供了更有效、更具通用性的图神经网络解决方案，利用改进的图结构表达，充分利用视觉实体间的内在结构与关系，提高了分类表现。

Abstract: Graph neural networks have emerged as a promising paradigm for image
processing, yet their performance in image classification tasks is hindered by
a limited consideration of the underlying structure and relationships among
visual entities. This work presents iPac, a novel approach to introduce a new
graph representation of images to enhance graph neural network image
classification by recognizing the importance of underlying structure and
relationships in medical image classification. iPac integrates various stages,
including patch partitioning, feature extraction, clustering, graph
construction, and graph-based learning, into a unified network to advance graph
neural network image classification. By capturing relevant features and
organising them into clusters, we construct a meaningful graph representation
that effectively encapsulates the semantics of the image. Experimental
evaluation on diverse medical image datasets demonstrates the efficacy of iPac,
exhibiting an average accuracy improvement of up to 5% over baseline methods.
Our approach offers a versatile and generic solution for image classification,
particularly in the realm of medical images, by leveraging the graph
representation and accounting for the inherent structure and relationships
among visual entities.

</details>


### [202] [FreeFuse: Multi-Subject LoRA Fusion via Auto Masking at Test Time](https://arxiv.org/abs/2510.23515)
*Yaoli Liu,Yao-Xiang Ding,Kun Zhou*

Main category: cs.CV

TL;DR: FreeFuse是一种无需额外训练的多主题文本生成图像方法，通过自动融合多个主题的LoRA权重，实现高效高质的图像生成。


<details>
  <summary>Details</summary>
Motivation: 当前多主题文本生成图像主要依赖权重融合或复杂分割与混合技术，操作复杂且实用性不足。作者希望提出一种更高效、更便捷的多主题生成方案。

Method: 提出基于自注意力层权重自动推断动态主题掩模，并直接在推理过程中将这些掩模应用于LoRA输出，无需对LoRA进行修改或附加辅助模型，也不需额外的分割步骤。用户仅需提供激活关键词即可。

Result: 大量实验表明，FreeFuse在多主题文本到图像生成任务中无论是生成质量还是易用性上均优于现有方法。

Conclusion: FreeFuse无需训练及辅助模块，极大简化了多主题LoRA集成过程，同时保持或优于以往方法的生成质量，有良好的实用性和推广价值。

Abstract: This paper proposes FreeFuse, a novel training-free approach for
multi-subject text-to-image generation through automatic fusion of multiple
subject LoRAs. In contrast to existing methods that either focus on
pre-inference LoRA weight merging or rely on segmentation models and complex
techniques like noise blending to isolate LoRA outputs, our key insight is that
context-aware dynamic subject masks can be automatically derived from
cross-attention layer weights. Mathematical analysis shows that directly
applying these masks to LoRA outputs during inference well approximates the
case where the subject LoRA is integrated into the diffusion model and used
individually for the masked region. FreeFuse demonstrates superior practicality
and efficiency as it requires no additional training, no modification to LoRAs,
no auxiliary models, and no user-defined prompt templates or region
specifications. Alternatively, it only requires users to provide the LoRA
activation words for seamless integration into standard workflows. Extensive
experiments validate that FreeFuse outperforms existing approaches in both
generation quality and usability under the multi-subject generation tasks. The
project page is at https://future-item.github.io/FreeFuse/

</details>


### [203] [EgoThinker: Unveiling Egocentric Reasoning with Spatio-Temporal CoT](https://arxiv.org/abs/2510.23569)
*Baoqi Pei,Yifei Huang,Jilan Xu,Yuping He,Guo Chen,Fei Wu,Yu Qiao,Jiangmiao Pang*

Main category: cs.CV

TL;DR: 本文提出了EgoThinker框架，通过大规模数据和链式推理训练，有效提升了多模态大模型在第一视角视频中的推理能力，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态大语言模型（MLLMs）仅擅长处理可见事件推理，缺乏对摄像者意图和细粒度互动的第一视角推理能力。因此，需要专门框架弥补其在具身和时空推理方面的不足。

Method: 1）提出EgoRe-5M数据集，从1300万段第一视角视频中构建，包含详细的Chain-of-Thought推理标注和手-物体关联。2）首先在EgoRe-5M上进行有监督微调（SFT），继而使用强化微调（RFT），进一步提升模型的时空定位和推理能力。

Result: EgoThinker在多个第一视角视频推理基准上超越现有方法，特别是在细粒度时空定位任务上取得显著提升。

Conclusion: EgoThinker显著增强了MLLMs在第一视角视频中的推理和时空定位能力，为具身智能推理提供了新路径。

Abstract: Egocentric video reasoning centers on an unobservable agent behind the camera
who dynamically shapes the environment, requiring inference of hidden
intentions and recognition of fine-grained interactions. This core challenge
limits current multimodal large language models MLLMs, which excel at visible
event reasoning but lack embodied, first-person understanding. To bridge this
gap, we introduce EgoThinker, a novel framework that endows MLLMs with robust
egocentric reasoning capabilities through spatio-temporal chain-of-thought
supervision and a two-stage learning curriculum. First, we introduce EgoRe-5M,
a large-scale egocentric QA dataset constructed from 13M diverse egocentric
video clips. This dataset features multi-minute segments annotated with
detailed CoT rationales and dense hand-object grounding. Second, we employ SFT
on EgoRe-5M to instill reasoning skills, followed by reinforcement fine-tuning
RFT to further enhance spatio-temporal localization. Experimental results show
that EgoThinker outperforms existing methods across multiple egocentric
benchmarks, while achieving substantial improvements in fine-grained
spatio-temporal localization tasks. Full code and data are released at
https://github.com/InternRobotics/EgoThinker.

</details>


### [204] [More Than Generation: Unifying Generation and Depth Estimation via Text-to-Image Diffusion Models](https://arxiv.org/abs/2510.23574)
*Hongkai Lin,Dingkang Liang,Mingyang Du,Xin Zhou,Xiang Bai*

Main category: cs.CV

TL;DR: MERGE方法实现了图像生成和深度估计的统一，同时保持预训练文生图模型的生成能力，达到SOTA深度估计效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的深度估计方法训练后易损失图像生成能力，亟需可兼顾两种任务的统一方案。

Method: 提出MERGE架构，采用plug-and-play转换器，在固定预训练模型参数的基础上，通过简单插拔实现图像生成与深度估计模式切换，同时设计Group Reuse机制提高可学参数利用率。

Result: MERGE在保持原有生成能力的同时，在多个深度估计数据集上取得了SOTA表现。

Conclusion: MERGE验证了文生图扩散模型深度估计潜力，兼顾生成与估计，推进了多任务统一模型的发展。

Abstract: Generative depth estimation methods leverage the rich visual priors stored in
pre-trained text-to-image diffusion models, demonstrating astonishing zero-shot
capability. However, parameter updates during training lead to catastrophic
degra- dation in the image generation capability of the pre-trained model. We
introduce MERGE, a unified model for image generation and depth estimation,
starting from a fixed pre-trained text-to-image model. MERGE demonstrates that
the pre-trained text-to-image model can do more than image generation, but also
expand to depth estimation effortlessly. Specifically, MERGE introduces a play-
and-plug framework that enables seamless switching between image generation and
depth estimation modes through simple and pluggable converters. Meanwhile, we
propose a Group Reuse Mechanism to encourage parameter reuse and im- prove the
utilization of the additional learnable parameters. MERGE unleashes the
powerful depth estimation capability of the pre-trained text-to-image model
while preserving its original image generation ability. Compared to other
unified models for image generation and depth estimation, MERGE achieves
state-of- the-art performance across multiple depth estimation benchmarks. The
code will be made available at https://github.com/H-EmbodVis/MERGE

</details>


### [205] [Lookahead Anchoring: Preserving Character Identity in Audio-Driven Human Animation](https://arxiv.org/abs/2510.23581)
*Junyoung Seo,Rodrigo Mira,Alexandros Haliassos,Stella Bounareli,Honglie Chen,Linh Tran,Seungryong Kim,Zoe Landgraf,Jie Shen*

Main category: cs.CV

TL;DR: 本文提出了一种新的方法“Lookahead Anchoring”来解决音频驱动人物动画模型在时间自回归生成中出现的角色身份漂移问题。该方法通过利用未来帧的关键帧作为锚点，持续为模型提供身份一致性的引导，无需额外生成关键帧。实验证明该方法提升了唇形同步、身份保持和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 自动化的音频驱动人类动画模型往往会在长时间生成中出现‘身份漂移’，即角色的外观逐渐失真，缺乏一致性。传统方案通过生成中间关键帧作为锚点防止这一问题，但增加了复杂度并限制了动作自然性。因此，亟需一种既能保证身份一致，又不会影响动作表达的高效方法。

Method: 提出了Lookahead Anchoring（前瞻锚定）方法：模型不是在当前生成窗口内设置关键帧，而是利用未来时刻的关键帧作为“方向灯塔”。模型始终朝着未来锚点调整当前生成，同时响应即时音频信号。这种方式还可实现自我关键帧，即仅用初始参考图像作为唯一锚点，无需生成关键帧。此外，通过调整前瞻距离，可在表达性和一致性之间获得平衡。

Result: Lookahead Anchoring方法已在三种最新的人体动画模型上测试。结果表明，该方法在唇形同步、身份保持和视觉质量方面，均优于传统做法，并改进了模型时间条件建模能力。

Conclusion: 通过前瞻锚定策略，可以显著缓解音频驱动角色动画中的身份漂移问题，实现更为一致且自然的动画效果，且无需额外关键帧生成步骤，提升了模型的普适性和效率。

Abstract: Audio-driven human animation models often suffer from identity drift during
temporal autoregressive generation, where characters gradually lose their
identity over time. One solution is to generate keyframes as intermediate
temporal anchors that prevent degradation, but this requires an additional
keyframe generation stage and can restrict natural motion dynamics. To address
this, we propose Lookahead Anchoring, which leverages keyframes from future
timesteps ahead of the current generation window, rather than within it. This
transforms keyframes from fixed boundaries into directional beacons: the model
continuously pursues these future anchors while responding to immediate audio
cues, maintaining consistent identity through persistent guidance. This also
enables self-keyframing, where the reference image serves as the lookahead
target, eliminating the need for keyframe generation entirely. We find that the
temporal lookahead distance naturally controls the balance between expressivity
and consistency: larger distances allow for greater motion freedom, while
smaller ones strengthen identity adherence. When applied to three recent human
animation models, Lookahead Anchoring achieves superior lip synchronization,
identity preservation, and visual quality, demonstrating improved temporal
conditioning across several different architectures. Video results are
available at the following link: https://lookahead-anchoring.github.io.

</details>


### [206] [FARMER: Flow AutoRegressive Transformer over Pixels](https://arxiv.org/abs/2510.23588)
*Guangting Zheng,Qinyu Zhao,Tao Yang,Fei Xiao,Zhijie Lin,Jie Wu,Jiajun Deng,Yanyong Zhang,Rui Zhu*

Main category: cs.CV

TL;DR: 该论文提出了FARMER，一种结合了归一化流（Normalizing Flows, NF）和自回归（Autoregressive, AR）模型的新型端到端生成框架，能够高效高质量地从原始像素数据生成图像。


<details>
  <summary>Details</summary>
Motivation: 传统的大型语言模型在建模数据分布时通过自回归方法取得了巨大成功，但直接在视觉像素数据上进行连续自回归存在序列过长和维度过高的问题。提升对原始像素分布的有效建模能力，兼顾可扩展性和建模精准度，是该研究的出发点。

Method: FARMER 框架结合了可逆的自回归流，首先将图像转换为潜在序列，由自回归模型隐式建模概率分布。同时引入自监督的降维方法，将NF潜在通道划分为有效和冗余两类，提升AR建模效率。为进一步提升推理速度和生成质量，设计了一步蒸馏方案和基于重采样的无分类器引导算法。

Result: 实验结果显示，FARMER在生成模型性能上达到或超过了现有像素级生成方法，支持精确似然计算和可扩展训练，并取得了高质量的图像生成效果。

Conclusion: FARMER 框架有效解决了像素级自回归模型在时序和高维空间上的冗余和效率问题，为直接像素级概率建模和高质量图像合成提供了一种可行且强大的方案。

Abstract: Directly modeling the explicit likelihood of the raw data distribution is key
topic in the machine learning area, which achieves the scaling successes in
Large Language Models by autoregressive modeling. However, continuous AR
modeling over visual pixel data suffer from extremely long sequences and
high-dimensional spaces. In this paper, we present FARMER, a novel end-to-end
generative framework that unifies Normalizing Flows (NF) and Autoregressive
(AR) models for tractable likelihood estimation and high-quality image
synthesis directly from raw pixels. FARMER employs an invertible autoregressive
flow to transform images into latent sequences, whose distribution is modeled
implicitly by an autoregressive model. To address the redundancy and complexity
in pixel-level modeling, we propose a self-supervised dimension reduction
scheme that partitions NF latent channels into informative and redundant
groups, enabling more effective and efficient AR modeling. Furthermore, we
design a one-step distillation scheme to significantly accelerate inference
speed and introduce a resampling-based classifier-free guidance algorithm to
boost image generation quality. Extensive experiments demonstrate that FARMER
achieves competitive performance compared to existing pixel-based generative
models while providing exact likelihoods and scalable training.

</details>


### [207] [InFlux: A Benchmark for Self-Calibration of Dynamic Intrinsics of Video Cameras](https://arxiv.org/abs/2510.23589)
*Erich Liang,Roma Bhattacharjee,Sreemanti Dey,Rafael Moschopoulos,Caitlin Wang,Michel Liao,Grace Tan,Andrew Wang,Karhan Kayan,Stamatis Alexandropoulos,Jia Deng*

Main category: cs.CV

TL;DR: 本论文提出了一个真实世界的视频数据集InFlux，专门用于动态变化的相机内参标注，填补了该领域缺乏相关基准数据集的空白，并评估了主流方法在此任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 当前3D算法通常假设视频过程中的相机内参保持不变，但实际上许多真实场景中内参动态变化。现有数据集在场景多样性和内参变化方面严重有限，且缺乏逐帧内参变化的标注数据。缺少合适的基准阻碍了相关研究进展。

Method: 作者创建了InFlux数据集，涵盖386个高分辨率室内外视频，共143,000余帧，全部有逐帧真实内参数（intrinsics）标注。为确保标注准确，作者构建了完善的校准实验查找表，扩展了Kalibr工具以增强其精度与鲁棒性。

Result: 通过InFlux数据集，作者对现有用于预测动态相机内参的基线方法进行了评估，结果发现这些方法在动态内参场景下效果不佳，准确率较低。

Conclusion: InFlux填补了动态相机内参标注数据集的空白，为该领域方法的开发与评估提供了基础。实验证明现有方法仍难很好应对动态内参情境，未来有必要在相关算法上取得突破。

Abstract: Accurately tracking camera intrinsics is crucial for achieving 3D
understanding from 2D video. However, most 3D algorithms assume that camera
intrinsics stay constant throughout a video, which is often not true for many
real-world in-the-wild videos. A major obstacle in this field is a lack of
dynamic camera intrinsics benchmarks--existing benchmarks typically offer
limited diversity in scene content and intrinsics variation, and none provide
per-frame intrinsic changes for consecutive video frames. In this paper, we
present Intrinsics in Flux (InFlux), a real-world benchmark that provides
per-frame ground truth intrinsics annotations for videos with dynamic
intrinsics. Compared to prior benchmarks, InFlux captures a wider range of
intrinsic variations and scene diversity, featuring 143K+ annotated frames from
386 high-resolution indoor and outdoor videos with dynamic camera intrinsics.
To ensure accurate per-frame intrinsics, we build a comprehensive lookup table
of calibration experiments and extend the Kalibr toolbox to improve its
accuracy and robustness. Using our benchmark, we evaluate existing baseline
methods for predicting camera intrinsics and find that most struggle to achieve
accurate predictions on videos with dynamic intrinsics. For the dataset, code,
videos, and submission, please visit https://influx.cs.princeton.edu/.

</details>


### [208] [PRISM-Bench: A Benchmark of Puzzle-Based Visual Tasks with CoT Error Detection](https://arxiv.org/abs/2510.23594)
*Yusu Qian,Cheng Wan,Chao Jia,Yinfei Yang,Qingyu Zhao,Zhe Gan*

Main category: cs.CV

TL;DR: PRISM-Bench 是一个针对视觉谜题推理的全新基准，专注于评估多模态大模型（MLLMs）的推理过程准确性，而不仅仅是答案正确率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉推理评测普遍只关注模型最终的答案是否正确，缺乏对模型推理过程的细致诊断，无法有效衡量模型对错误的识别和推理一致性。

Method: PRISM-Bench 设计了一类视觉谜题，并要求模型在给定带有一步错误的推理链时，找出第一处错误。谜题涉及多步符号、几何、类比等复杂推理，难以用简单模式匹配“投机取巧”。然后对主流最前沿多模态模型进行测试，综合评估其推理链条的诊断和逻辑一致性。

Result: 实验显示，尽管最前沿的多模态大模型能流畅生成推理链条，但经常无法发现其中的明显逻辑错误，表明它们在推理的可信度和错误检测方面还有不足。

Conclusion: PRISM-Bench 将答案生成和推理核查解耦，能更加细致地检验多模态推理能力，强调在多模态模型开发中引入诊断式评测的重要性，以提升模型的可靠性。

Abstract: We introduce \textbf{PRISM-Bench}, a benchmark of puzzle-based visual
challenges designed to evaluate not only whether models can solve problems, but
how their reasoning unfolds. Unlike prior evaluations that measure only
final-answer accuracy, PRISM-Bench introduces a diagnostic task: given a visual
puzzle and a step-by-step chain-of-thought (CoT) containing exactly one error,
models must identify the first incorrect step. This setting enables
fine-grained assessment of logical consistency, error detection, and visual
reasoning. The puzzles in PRISM-Bench require multi-step symbolic, geometric,
and analogical reasoning, resisting shortcuts based on superficial pattern
matching. Evaluations across state-of-the-art MLLMs reveal a persistent gap
between fluent generation and faithful reasoning: models that produce plausible
CoTs often fail to locate simple logical faults. By disentangling answer
generation from reasoning verification, PRISM-Bench offers a sharper lens on
multimodal reasoning competence and underscores the need for diagnostic
evaluation protocols in the development of trustworthy MLLMs.

</details>


### [209] [PixelRefer: A Unified Framework for Spatio-Temporal Object Referring with Arbitrary Granularity](https://arxiv.org/abs/2510.23603)
*Yuqian Yuan,Wenqiao Zhang,Xin Li,Shihao Wang,Kehan Li,Wentong Li,Jun Xiao,Lei Zhang,Beng Chin Ooi*

Main category: cs.CV

TL;DR: 本文提出了PixelRefer和PixelRefer-Lite新方法，实现了对用户指定的图像或视频区域的高级细粒度理解，兼顾准确性和高效性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型（MLLMs）多专注于整体场景理解，缺乏对具体对象或区域的细粒度推理能力。为满足用户对特定区域关注和详细理解的需求，作者试图弥补现有MLLM的不足。

Method: 作者提出了一种统一的区域级MLLM框架PixelRefer，核心在于引入可自适应尺度对象分词器（SAOT），能从任意区域生成紧凑且语义丰富的对象表示。分析显示视觉全局token主要在早期层起作用，因此设计了PixelRefer-Lite，用对象中心融合模块将全局上下文预先融合进对象token，大大减轻计算负担。此外，作者构建了物体中心的指令微调数据集PixelRefer-2.2M。

Result: 在多项基准上，PixelRefer用更少训练样本取得了领先性能，PixelRefer-Lite则在保持较好准确率的同时大幅提高了效率。

Conclusion: PixelRefer系列方法不仅在对象级视觉理解任务中有显著提升，还能兼顾精度与效率，对细粒度、多样化场景的视觉理解具有较大应用前景。

Abstract: Multimodal large language models (MLLMs) have demonstrated strong
general-purpose capabilities in open-world visual comprehension. However, most
existing MLLMs primarily focus on holistic, scene-level understanding, often
overlooking the need for fine-grained, object-centric reasoning. In this paper,
we present PixelRefer, a unified region-level MLLM framework that enables
advanced fine-grained understanding over user-specified regions across both
images and videos. Motivated by the observation that LLM attention
predominantly focuses on object-level tokens, we propose a Scale-Adaptive
Object Tokenizer (SAOT) to generate compact and semantically rich object
representations from free-form regions. Our analysis reveals that global visual
tokens contribute mainly in early LLM layers, inspiring the design of
PixelRefer-Lite, an efficient variant that employs an Object-Centric Infusion
module to pre-fuse global context into object tokens. This yields a lightweight
Object-Only Framework that substantially reduces computational cost while
maintaining high semantic fidelity. To facilitate fine-grained instruction
tuning, we curate PixelRefer-2.2M, a high-quality object-centric instruction
dataset. Extensive experiments across a range of benchmarks validate that
PixelRefer achieves leading performance with fewer training samples, while
PixelRefer-Lite offers competitive accuracy with notable gains in efficiency.

</details>


### [210] [Concerto: Joint 2D-3D Self-Supervised Learning Emerges Spatial Representations](https://arxiv.org/abs/2510.23607)
*Yujia Zhang,Xiaoyang Wu,Yixing Lao,Chengyao Wang,Zhuotao Tian,Naiyan Wang,Hengshuang Zhao*

Main category: cs.CV

TL;DR: 该论文提出了一个模仿人类多感官抽象学习的模型Concerto，通过3D自蒸馏与2D-3D跨模态联合嵌入提升空间认知能力，实现了同类任务中最优表现。


<details>
  <summary>Details</summary>
Motivation: 人类可以借助多感官协同形成抽象概念，并能仅靠单一感官回忆。受此启发，作者希望设计一种系统，让机器模拟人类空间概念学习，提升空间场景理解的精度。

Method: Concerto模型结合了3D模态下的自蒸馏方法和2D-3D的跨模态联合嵌入机制，用极简方式模拟人类多模态融合，同时还开发了视频与点云空间理解的定制变体，以及一种能把模型特征线性投影到CLIP语言空间的转换器，实现开放世界感知。

Result: 在零样本可视化和线性探测任务中，Concerto的空间特征表现出更一致和丰富的表达，相比单独的2D或3D自监督模型提升了14.2%与4.8%。在全量微调下，于多个场景理解基准集（如ScanNet）都刷新了最优成绩。

Conclusion: Concerto能学习到细粒度几何与语义俱佳的空间表征，显著优于现有2D/3D方法，并具备良好开放世界感知能力。

Abstract: Humans learn abstract concepts through multisensory synergy, and once formed,
such representations can often be recalled from a single modality. Inspired by
this principle, we introduce Concerto, a minimalist simulation of human concept
learning for spatial cognition, combining 3D intra-modal self-distillation with
2D-3D cross-modal joint embedding. Despite its simplicity, Concerto learns more
coherent and informative spatial features, as demonstrated by zero-shot
visualizations. It outperforms both standalone SOTA 2D and 3D self-supervised
models by 14.2% and 4.8%, respectively, as well as their feature concatenation,
in linear probing for 3D scene perception. With full fine-tuning, Concerto sets
new SOTA results across multiple scene understanding benchmarks (e.g., 80.7%
mIoU on ScanNet). We further present a variant of Concerto tailored for
video-lifted point cloud spatial understanding, and a translator that linearly
projects Concerto representations into CLIP's language space, enabling
open-world perception. These results highlight that Concerto emerges spatial
representations with superior fine-grained geometric and semantic consistency.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [211] [A Multi-lingual Dataset of Classified Paragraphs from Open Access Scientific Publications](https://arxiv.org/abs/2510.21762)
*Eric Jeangirard*

Main category: cs.CL

TL;DR: 本文推出了一个包含83.3万段科学文献段落的数据集，并对其内容进行了多维度分类和标注，旨在推动学术文本挖掘任务的研究。


<details>
  <summary>Details</summary>
Motivation: 当前学术领域文本挖掘和自动化信息提取的需求不断增加，但缺乏高质量、公开可用并细致分类的数据集，限制了模型训练和评估。因此，作者希望通过构建大规模、结构化的数据集，促进科学文献挖掘相关任务，如文本分类和命名实体识别的发展。

Method: 作者从CC-BY授权的科学出版物中，提取了83.3万段落。段落被分为致谢、数据提及、软件/代码提及和临床试验提及四类。语言主要为英语和法语，并用fastText进行语言标注。利用OpenAlex提供的科学领域信息，对每段内容进行学科分类。所有段落均通过GROBID工具处理，并汇总在French Open Science Monitor语料库基础上构建。

Result: 作者得到了一个结构化良好、包含多语言与多类别标注的83.3万段学术段落数据集，并已经发布在HuggingFace共享平台，供学界免费使用。

Conclusion: 该数据集为学术文本分类与命名实体识别等NLP任务提供了重要资源，将助力相关模型的开发、评测和科学文献挖掘领域的进一步研究。

Abstract: We present a dataset of 833k paragraphs extracted from CC-BY licensed
scientific publications, classified into four categories: acknowledgments, data
mentions, software/code mentions, and clinical trial mentions. The paragraphs
are primarily in English and French, with additional European languages
represented. Each paragraph is annotated with language identification (using
fastText) and scientific domain (from OpenAlex). This dataset, derived from the
French Open Science Monitor corpus and processed using GROBID, enables training
of text classification models and development of named entity recognition
systems for scientific literature mining. The dataset is publicly available on
HuggingFace https://doi.org/10.57967/hf/6679 under a CC-BY license.

</details>


### [212] [Policy Optimization Prefers The Path of Least Resistance](https://arxiv.org/abs/2510.21853)
*Debdeep Sanyal,Aakash Sen Sharma,Dhruv Kumar,Saurabh Deshpande,Murari Mandal*

Main category: cs.CL

TL;DR: 本文研究了当大语言模型在策略优化（PO）中不再被强制执行严格的“思考-再作答”格式、而采用更开放、交错的思维链（CoT）结构时的表现。研究发现，PO算法总是倾向于选择最简单直接的响应路径——即直接输出答案、跳过推理步骤。这种趋势在多种模型和算法中都很明显，即使给予推理更高的奖励权重也难以逆转。


<details>
  <summary>Details</summary>
Motivation: 动机在于当前最优的 CoT 训练流程过于依赖严格的格式要求，而对当这些约束被放松时模型的训练行为研究不足。作者希望弄清楚，在更真实、无强制结构限制的条件下，PO会如何影响模型的推理与回答行为。

Method: 作者通过系统的对照实验，包括奖励分解等方法，分别测试了不同模型和PO算法下开放与刚性格式的训练效果。同样还设定了不同的奖励权重来研究模型是否会平衡推理与答案输出的偏好。

Result: 实验显示，当允许灵活交错地推理和作答时，PO始终学会抛弃显式推理，直接输出答案，这种模式在多种模型、算法和不同奖励分配下均保持一致。即使加大推理部分的奖励，模型依然优先优化最简单的奖励成分。此外，进一步发现，PO的快速收敛并非因为优化难度低，而是KL正则化的放松给予模型充分自由度，从而实现对初始策略显著改变。

Conclusion: 论文认为，策略优化中的“路径最小阻力”原则导致模型倾向于选择最简单的完成方式。尽管给予模型更多自由能让其探索高回报“捷径”，但也大大增加了模型“对齐”时奖励被投机利用（reward hacking）的风险，这对于未来调优和安全对齐提出了挑战。

Abstract: Policy optimization (PO) algorithms are used to refine Large Language Models
for complex, multi-step reasoning. Current state-of-the-art pipelines enforce a
strict think-then-answer format to elicit chain-of-thought (CoT); however, the
behavior of PO when these rigid constraints are relaxed into an open-ended CoT
structure remains an under-studied question. We investigate this gap with an
extensive suite of controlled experiments and identify a consistent principle:
\textit{policy optimization consistently follows the path of least resistance}.
When afforded the flexibility to interleave reasoning and response, policy
optimization consistently learns to discard explicit reasoning, causing the
policy to degenerate to a direct \texttt{<answer>}-only format. This outcome
holds true across various models and algorithms. We find that this collapse in
format is persistent even when the complex \texttt{<think><answer>} format is
assigned up to 4x larger reward weights. We formalize this principle through a
series of controlled reward decomposition experiments, demonstrating a clear
hierarchy: PO systematically optimizes for the simplest reward component first,
a preference that holds even when faced with mutually exclusive choices or
strong incentives for more complex behaviors. Finally, we show that successful
convergence on the high-reward shortcut is not a low-effort drift but is driven
by the optimization process that requires the KL-regularized policy to have
sufficient freedom to make a significant shift from its initial prior. Our
findings reveal that granting policies the freedom to diverge is a double-edged
sword: while necessary for discovering high-reward shortcuts, it also creates a
powerful incentive to game the simplest aspects of the reward function, posing
a critical challenge for reward hacking under alignment.

</details>


### [213] [Language Ranker: A Lightweight Ranking framework for LLM Decoding](https://arxiv.org/abs/2510.21883)
*Chenheng Zhang,Tianqi Du,Jizhe Zhang,Mingqing Xiao,Yifei Wang,Yisen Wang,Zhouchen Lin*

Main category: cs.CL

TL;DR: 该论文提出了一种名为Language Ranker的新框架，通过引入轻量级模块对LLM输出候选进行重排序，大幅降低了计算资源消耗并保持了性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型的研究主要聚焦于提升输出分布，较少关注将分布转为最终响应的解码过程。而现有以奖励模型辅助的推理解码方法虽有效，但运算成本高且适用范围有限。作者希望找到更高效的解码方法。

Method: 作者将LLM的输出解码过程与推荐系统的排序过程类比，将其视为对候选响应的再排序。基于此，提出Language Ranker，将轻量级模块用于利用基础模型提取的特征对候选响应进行重排序，提升输出效率和多样性。

Result: 在多种任务上，Language Ranker表现接近于大规模奖励模型，但其参数量不到50万个，极大地降低了训练和推理阶段的计算开销。

Conclusion: Language Ranker是一种高效且有效的解码框架，能以较低成本充分发挥LLM的能力，在实际应用中具有极大潜力。

Abstract: Conventional research on large language models (LLMs) has primarily focused
on refining output distributions, while paying less attention to the decoding
process that transforms these distributions into final responses. Recent
advances, such as scaling the computation of inference time with reward models,
have underscored the importance of decoding, but these methods often suffer
from high computational costs and limited applicability. In this paper, we
revisit LLM generation through the lens of recommender systems, conceptualizing
the decoding process as analogous to the ranking stage in recommendation
pipelines. From this perspective, we observe that both traditional decoding
methods and reward models exhibit clear limitations such as redundancy.
Motivated by this insight, we propose Language Ranker, a novel framework that
introduces a lightweight module to rerank candidate responses using features
extracted by the base model. Experiments across a wide range of tasks show that
Language Ranker achieves performance comparable to large-scale reward models,
while requiring only <0.5M additional parameters, significantly reducing the
computational overhead during both training and inference stages. This
highlights the efficiency and effectiveness of our method, showcasing its
potential to fully unlock the capabilities of LLMs.

</details>


### [214] [Framework for Machine Evaluation of Reasoning Completeness in Large Language Models For Classification Tasks](https://arxiv.org/abs/2510.21884)
*Avinash Patil*

Main category: cs.CL

TL;DR: 提出了RACE框架，系统评估LLM生成解释与特征重要性分数的一致性，发现正确预测的解释更贴合支持特征，错误预测更易突出矛盾特征，为评估神经语言模型解释的完备性提供新方法。


<details>
  <summary>Details</summary>
Motivation: 机器学习在敏感领域广泛应用，用户对AI可解释性和透明性的需求上升。目前尚不清楚大语言模型生成的解释是否真正反映了其决策依据。

Method: 作者提出RACE框架，通过与逻辑回归得到的特征重要性分数对比，评估LLM的解释和真实特征的一致性。涉及四个文本分类数据集，并采用不同粒度的文本匹配方法（token级、精确字符串、编辑距离）检测LLM解释和重要性特征的重合度。

Result: 实验显示，LLM对正确预测时解释覆盖更多支持性特征，而错误预测时更偏向矛盾特征。编辑距离匹配可以发现同义、改写等重合，但这种不对称性依旧存在。

Conclusion: LLM解释既包含表层证据也能灵活引用信息，但有时也会放大误导性特征。RACE为量化神经语言模型解释的完备性和真实度提供了新思路和评估基准。

Abstract: The growing adoption of machine learning (ML) in sensitive domains has
heightened the demand for transparent and interpretable artificial
intelligence. Large Language Models (LLMs) are increasingly capable of
producing natural language explanations, yet it remains unclear whether these
rationales faithfully capture the predictive signals that underlie decisions.
This paper introduces RACE-Reasoning Alignment for Completeness of
Explanations, a systematic framework to evaluate the alignment between
LLM-generated explanations and interpretable feature importance scores derived
from a logistic regression baseline. We analyze four widely used text
classification datasets-WIKI ONTOLOGY, AG NEWS, IMDB, and GOEMOTIONS-and
compare LLM rationales against top-ranked supporting and contradicting lexical
features. To capture alignment at multiple levels of granularity, RACE
implements token-aware, exact string, and edit-distance matching techniques.
Empirical results reveal a consistent asymmetry: correct predictions exhibit
higher coverage of supporting features, while incorrect predictions are
associated with elevated coverage of contradicting features. Edit-distance
matching further uncovers paraphrastic overlaps, boosting coverage while
preserving this asymmetry. These findings demonstrate that LLM rationales
combine both surface-level and flexible evidence reuse, yet can also amplify
misleading cues in error cases. RACE provides new insights into the
faithfulness of LLM explanations and establishes a quantitative basis for
evaluating reasoning completeness in neural language models.

</details>


### [215] [Preventing Catastrophic Forgetting: Behavior-Aware Sampling for Safer Language Model Fine-Tuning](https://arxiv.org/abs/2510.21885)
*Anh Pham,Mihir Thalanki,Michael Sun,Aditya Chaloo,Ankita Gupta,Tian Xia,Aditya Mate,Ehimwenma Nosakhare,Soundararajan Srinivasan*

Main category: cs.CL

TL;DR: 本文提出一种基于行为感知的数据采样方法，以缓解大语言模型微调过程中的遗忘安全性行为问题，并取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在微调过程中经常丧失之前对安全性行为的对齐（即灾难性遗忘），虽然已有研究通过添加随机安全样本进行缓解，但哪些样本最有效仍不清楚。

Method: 提出一种行为感知采样框架，基于指令-响应行为（如拒绝与 Compliance）以及在伤害类别上的语义多样性，选择用于微调的安全性样本。

Result: 系统性评估表明，该方法在仅增加0.5%训练数据的情况下，有害输出最多降低41%，同时保持模型的有用性。

Conclusion: 有针对性地选择安全数据样本可以在提升微调效率的同时，显著改善模型的安全性。

Abstract: Large language models often lose previously aligned safety behaviors when
fine-tuned on benign data, a phenomenon known as catastrophic forgetting. Prior
work shows that adding random safety examples can mitigate this effect, but it
remains unclear which examples are most effective. We propose a behavior-aware
sampling framework that selects safety examples based on two complementary
factors: instruction-response behavior (e.g., refusal versus compliance) and
semantic diversity across harm categories. Systematic evaluation shows that
this approach substantially reduces harmful outputs while maintaining
helpfulness, achieving up to a 41% reduction in harmfulness with only 0.5%
additional training data. These results highlight how targeted data selection
can improve the safety and efficiency of fine-tuning at scale.

</details>


### [216] [Embedding Trust: Semantic Isotropy Predicts Nonfactuality in Long-Form Text Generation](https://arxiv.org/abs/2510.21891)
*Dhrupad Bhardwaj,Julia Kempe,Tim G. J. Rudner*

Main category: cs.CL

TL;DR: 本文提出了一种基于语义等方性的新方法，用于低成本、可靠地评估大语言模型生成的长文本回复的可信度。


<details>
  <summary>Details</summary>
Motivation: 在高风险应用领域，部署大语言模型需要对其生成的长文本回复的真实性进行准确评估。现有方法依赖逐条事实核查，计算开销大且处理开放式长文本效果不佳。

Method: 作者提出“语义等方性”指标，通过将多个长文本回复进行嵌入，计算这些嵌入在单位球面上的角分布，以此衡量语义一致性。语义分散性越大，回复间事实一致性越低。该方法无需标注数据、微调或超参数选择，不受限于嵌入模型类型。

Result: 在多个领域实验表明，该方法仅需少量样本就能有效预测长文本不实信息，且预测准确性优于现有主流方法。

Conclusion: 语义等方性为评估大模型文本可信度提供了简单、低成本且实用的工具，易于集成到实际工作流中，对提升高风险场景下的LLM可靠性有重要意义。

Abstract: To deploy large language models (LLMs) in high-stakes application domains
that require substantively accurate responses to open-ended prompts, we need
reliable, computationally inexpensive methods that assess the trustworthiness
of long-form responses generated by LLMs. However, existing approaches often
rely on claim-by-claim fact-checking, which is computationally expensive and
brittle in long-form responses to open-ended prompts. In this work, we
introduce semantic isotropy -- the degree of uniformity across normalized text
embeddings on the unit sphere -- and use it to assess the trustworthiness of
long-form responses generated by LLMs. To do so, we generate several long-form
responses, embed them, and estimate the level of semantic isotropy of these
responses as the angular dispersion of the embeddings on the unit sphere. We
find that higher semantic isotropy -- that is, greater embedding dispersion --
reliably signals lower factual consistency across samples. Our approach
requires no labeled data, no fine-tuning, and no hyperparameter selection, and
can be used with open- or closed-weight embedding models. Across multiple
domains, our method consistently outperforms existing approaches in predicting
nonfactuality in long-form responses using only a handful of samples --
offering a practical, low-cost approach for integrating trust assessment into
real-world LLM workflows.

</details>


### [217] [Understanding Network Behaviors through Natural Language Question-Answering](https://arxiv.org/abs/2510.21894)
*Mingzhe Xing,Chang Tian,Jianan Zhang,Lichen Pan,Peipei Liu,Zhaoteng Yan,Yinliang Yue*

Main category: cs.CL

TL;DR: 该论文提出了NetMind框架，通过自然语言实现对大规模复杂网络行为的理解，结合配置文件分块、统一表示和混合语言设计，提高了准确性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现代大型网络结构复杂，网络配置理解难度大且易出错。现有方法依赖形式化模型和领域特定语言，学习曲线陡峭且灵活性不足。自然语言更易用易懂，结合大语言模型可提升网络行为理解体验。

Method: 作者提出NetMind方法，包括：1）树状配置分块以保证语义一致和高效处理；2）将厂商特定配置标准化为统一事实图；3）设计混合命令-声明式语言辅助推理；并构建了相应基准数据集。

Result: 实验证明，NetMind在网络行为理解任务中准确率和可扩展性优于现有方法。

Conclusion: NetMind有效解决了大规模网络配置理解存在的上下文、异构性和复杂推理三大难题，用自然语言接口显著提升了易用性和精度。

Abstract: Modern large-scale networks introduce significant complexity in understanding
network behaviors, increasing the risk of misconfiguration. Prior work proposed
to understand network behaviors by mining network configurations, typically
relying on domain-specific languages interfaced with formal models. While
effective, they suffer from a steep learning curve and limited flexibility. In
contrast, natural language (NL) offers a more accessible and interpretable
interface, motivating recent research on NL-guided network behavior
understanding. Recent advances in large language models (LLMs) further enhance
this direction, leveraging their extensive prior knowledge of network concepts
and strong reasoning capabilities. However, three key challenges remain: 1)
numerous router devices with lengthy configuration files challenge LLM's
long-context understanding ability; 2) heterogeneity across devices and
protocols impedes scalability; and 3) complex network topologies and protocols
demand advanced reasoning abilities beyond the current capabilities of LLMs. To
tackle the above challenges, we propose NetMind, a novel framework for querying
networks using NL. Our approach introduces a tree-based configuration chunking
strategy to preserve semantic coherence while enabling efficient partitioning.
We then construct a unified fact graph as an intermediate representation to
normalize vendor-specific configurations. Finally, we design a hybrid
imperative-declarative language to reduce the reasoning burden on LLMs and
enhance precision. We contribute a benchmark consisting of NL question-answer
pairs paired with network configurations. Experiments demonstrate that NetMind
achieves accurate and scalable network behavior understanding, outperforming
existing baselines.

</details>


### [218] [Deep Literature Survey Automation with an Iterative Workflow](https://arxiv.org/abs/2510.21900)
*Hongbo Zhang,Han Cui,Yidong Wang,Yijian Tian,Qi Guo,Cunxiang Wang,Jian Wu,Chiyu Song,Yue Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种基于迭代式大纲生成的新型自动综述生成框架，有效提升了内容覆盖、结构连贯性和引用质量，明显优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有自动综述系统普遍采用一次性（one-shot）获取大量论文并静态生成大纲的方法，导致信息噪音大、结构碎片化和上下文超载，降低了综述的整体质量。因此，需要一种更接近人类“逐步阅读—整合—修订”思路的新框架，以生成更优质的自动文献综述。

Method: 作者提出了一种基于迭代式大纲生成的框架，采用智能体不断地增量检索文献、阅读内容并动态更新大纲，确保综述的探索性和连贯性。同时，提出“论文卡片”机制，将每篇论文的贡献、方法和结果进行提炼，还引入了可视化增强的“审阅-改进”循环以提升文本流畅性，并整合了多模态元素（如图表），最后用Survey-Arena基准提供更客观的综述评测。

Result: 在多个前沿与新兴主题上，本文方法在内容覆盖度、结构连贯性和引用质量等方面，均显著优于主流现有方法，同时生成的综述更具可读性、结构更清晰、信息组织更优。

Conclusion: 基于迭代规划与动态大纲更新的自动综述生成框架，不仅显著提升了机器生成综述的各项核心指标，也重塑了相关评测标准，为领域文献自动综述带来了新的方向。

Abstract: Automatic literature survey generation has attracted increasing attention,
yet most existing systems follow a one-shot paradigm, where a large set of
papers is retrieved at once and a static outline is generated before drafting.
This design often leads to noisy retrieval, fragmented structures, and context
overload, ultimately limiting survey quality. Inspired by the iterative reading
process of human researchers, we propose \ours, a framework based on recurrent
outline generation, in which a planning agent incrementally retrieves, reads,
and updates the outline to ensure both exploration and coherence. To provide
faithful paper-level grounding, we design paper cards that distill each paper
into its contributions, methods, and findings, and introduce a
review-and-refine loop with visualization enhancement to improve textual flow
and integrate multimodal elements such as figures and tables. Experiments on
both established and emerging topics show that \ours\ substantially outperforms
state-of-the-art baselines in content coverage, structural coherence, and
citation quality, while producing more accessible and better-organized surveys.
To provide a more reliable assessment of such improvements, we further
introduce Survey-Arena, a pairwise benchmark that complements absolute scoring
and more clearly positions machine-generated surveys relative to human-written
ones. The code is available at
https://github.com/HancCui/IterSurvey\_Autosurveyv2.

</details>


### [219] [Explaining and Mitigating Crosslingual Tokenizer Inequities](https://arxiv.org/abs/2510.21909)
*Catherine Arnett,Tyler A. Chang,Stella Biderman,Benjamin K. Bergen*

Main category: cs.CL

TL;DR: 本论文研究了不同语言在并行文本编码时所需token数量（即token premiums）的差异，并分析这些差异背后的原因。


<details>
  <summary>Details</summary>
Motivation: 多语言模型训练和推理时，不同语言需要的token数量不同，token premiums过高会增加计算和成本。因此需要深入理解token premiums的成因和优化途径。

Method: 作者训练了约7000个覆盖97种语言的单语tokenizer，系统地操控了tokenizer算法、词表大小和数据集规模。通过定量分析数据相似性、词表大小、预分词和语言特性（例如书写系统和词长）对token premiums的影响，并尝试superword tokenizer方法。

Result: 作者发现数据相似性对token premiums影响不大，词表大小和预分词则有明显影响。单纯增大词表不能有效减少token premiums，但为每种语言选择'最优'词表规模则可明显降低token premiums。superword tokenizer方法进一步减少token premiums并提升压缩率。

Conclusion: 通过调整词表规模或采用更先进的预分词/tokenizer方法，可显著抑制不同语言间token premiums的影响，有助于提升多语言模型的效率和性能。

Abstract: The number of tokens it takes to encode parallel text in different languages
is known to vary. These disparities are called token premiums. Having high
token premiums leads to less throughput during training and increases costs at
inference. In this paper, we show that even after controlling for dataset size,
vocabulary size, and data content, monolingual tokenizers exhibit a wide range
of token premiums across languages. To understand the cross-linguistic
differences that cause these token premiums, we train a suite of approximately
7,000 comparable monolingual tokenizers for 97 languages, manipulating
tokenization algorithm, vocabulary size, and dataset size. We measure token
premiums and test for a relationship between factors such as data similarity
(between tokenizer training and evaluation), vocabulary size, and
pre-tokenization. We also investigate the role of language-specific features
such as writing system and word length. We find that similarity between
training and test data does not impact token premiums, but vocabulary size and
pre-tokenization do. While simply increasing vocabulary size does not lead to
reduced token premium effects, we can determine an ``optimal'' vocabulary size
for each language to achieve significantly reduced token premium effects. We
also train superword tokenizers which allow merges over whitespaces, and we
find that they both reduce token premium effects and improve compression
overall. Thus, intervening on the vocabulary size or the pre-tokenizer
significantly reduces crosslingual token premium effects.

</details>


### [220] [Model-Aware Tokenizer Transfer](https://arxiv.org/abs/2510.21954)
*Mykola Haltiuk,Aleksander Smywiński-Pohl*

Main category: cs.CL

TL;DR: 本文提出了一种名为MATT（Model-Aware Tokenizer Transfer）的新方法，用于在多语言大模型中实现更高效的分词器迁移，显著提升低资源或特殊文本的适应能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型支持多语言，但分词器的转移到低资源或特殊文字语言时受限，现有方法只用语义启发，不考虑模型内部动态，导致迁移效果受限。

Method: MATT方法引入了关注模型内部信息的AIM（Attention Influence Modeling）目标，将源模型的注意力和token间交流模式蒸馏到目标模型及其新分词器中。这不仅在嵌入初始化上超越简单语义相似性，还能用注意力行为引导模型适应。

Result: 在多种语言环境下实验表明，MATT方法只需几个GPU小时即可恢复模型的大部分原始性能，效果优于传统启发式分词器迁移方法。

Conclusion: MATT展示了利用模型层级内部信号提高大语言模型分词器迁移实用性与效果的可能性，为多语言适应提供了更有效途径。

Abstract: Large Language Models (LLMs) are trained to support an increasing number of
languages, yet their predefined tokenizers remain a bottleneck for adapting
models to lower-resource or distinct-script languages. Existing tokenizer
transfer methods typically rely on semantic heuristics to initialize new
embeddings, ignoring higher-layer model dynamics and limiting transfer quality.
We propose Model-Aware Tokenizer Transfer (MATT), a method that incorporates
model internals into the tokenizer transfer process. MATT introduces an
Attention Influence Modeling (AIM) objective that distills inter-token
communication patterns from a source model into a target model with a new
tokenizer, providing an efficient warm-up before standard language modeling.
Unlike approaches that focus solely on embedding similarity, MATT leverages
attention behavior to guide embedding initialization and adaptation.
Experiments across diverse linguistic settings show that MATT recovers a large
fraction of the original model's performance within a few GPU hours,
outperforming heuristic baselines. These results demonstrate that incorporating
model-level signals offers a practical and effective path toward robust
tokenizer transfer in multilingual LLMs.

</details>


### [221] [A Stylometric Application of Large Language Models](https://arxiv.org/abs/2510.21958)
*Harrison F. Stropkay,Jiayi Chen,Mohammad J. Latifi,Daniel N. Rockmore,Jeremy R. Manning*

Main category: cs.CL

TL;DR: 本论文证明了大语言模型（LLM）能够区分不同作者的写作风格，且用一位作者作品训练出的GPT-2模型能更准确预测该作者的文本，从而体现作者独特的写作特征。


<details>
  <summary>Details</summary>
Motivation: 作者希望探究LLM是否能识别和区分不同作者的写作风格，并进一步验证其在实际著作归属判定中的应用潜力。

Method: 作者用单独的GPT-2模型分别在8位已知作者的作品上从零训练，并检测这些模型在预测同作者和不同作者留出文本时的表现。此外，将此方法应用于奥兹系列第15本书的作者归属判定。

Result: 实验显示，每个作者专属的GPT-2模型在预测本作者留出文本时，优于预测其他作者文本。通过该方法确认了R. P. Thompson才是奥兹系列第15本书的作者。

Conclusion: 用LLM单独训练作者作品能抓取并体现其独特写作风格，能有效应用于文本作者归属判定等相关领域。

Abstract: We show that large language models (LLMs) can be used to distinguish the
writings of different authors. Specifically, an individual GPT-2 model, trained
from scratch on the works of one author, will predict held-out text from that
author more accurately than held-out text from other authors. We suggest that,
in this way, a model trained on one author's works embodies the unique writing
style of that author. We first demonstrate our approach on books written by
eight different (known) authors. We also use this approach to confirm R. P.
Thompson's authorship of the well-studied 15th book of the Oz series,
originally attributed to F. L. Baum.

</details>


### [222] [Uncovering the Persuasive Fingerprint of LLMs in Jailbreaking Attacks](https://arxiv.org/abs/2510.21983)
*Havva Alizadeh Noughabi,Julien Serbanescu,Fattane Zarrinkalam,Ali Dehghantanha*

Main category: cs.CL

TL;DR: 本文通过引入社会科学中的说服理论，提出了一种基于说服策略的越狱攻击方法，证实了这种方法在多个大型语言模型上显著提高了攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究提出了多种绕过大语言模型对齐机制的攻击方法，但鲜有工作关注于语言和心理学机制如何影响模型易受攻击的程度。作者希望探索人类说服理论能否被利用于对LLM的攻击实践。

Method: 作者基于社会科学中关于说服的经典理论，设计了包含说服策略的对抗性攻击提示词，并在多个现有对齐LLM上进行了实证测试。此外，还分析了模型自身在越狱响应中的说服性表达特征。

Result: 实验显示，结合说服结构的攻击提示词在多种主流LLM上明显提高了越狱攻击的绕过率，并呈现出各模型独有的说服指纹。

Conclusion: 跨学科理论（如说服理论）的引入揭示了LLM安全防护的新漏洞，提示未来在提升模型安全性时需加深对语言与社会心理学机制的理解和运用。

Abstract: Despite recent advances, Large Language Models remain vulnerable to jailbreak
attacks that bypass alignment safeguards and elicit harmful outputs. While
prior research has proposed various attack strategies differing in human
readability and transferability, little attention has been paid to the
linguistic and psychological mechanisms that may influence a model's
susceptibility to such attacks. In this paper, we examine an interdisciplinary
line of research that leverages foundational theories of persuasion from the
social sciences to craft adversarial prompts capable of circumventing alignment
constraints in LLMs. Drawing on well-established persuasive strategies, we
hypothesize that LLMs, having been trained on large-scale human-generated text,
may respond more compliantly to prompts with persuasive structures.
Furthermore, we investigate whether LLMs themselves exhibit distinct persuasive
fingerprints that emerge in their jailbreak responses. Empirical evaluations
across multiple aligned LLMs reveal that persuasion-aware prompts significantly
bypass safeguards, demonstrating their potential to induce jailbreak behaviors.
This work underscores the importance of cross-disciplinary insight in
addressing the evolving challenges of LLM safety. The code and data are
available.

</details>


### [223] [Toward Understanding the Transferability of Adversarial Suffixes in Large Language Models](https://arxiv.org/abs/2510.22014)
*Sarah Ball,Niki Hasrati,Alexander Robey,Avi Schwarzschild,Frauke Kreuter,Zico Kolter,Andrej Risteski*

Main category: cs.CL

TL;DR: 本文分析了离散优化的越狱攻击对大模型的传递性，并揭示了这种攻击在跨场景和跨模型下成功的统计学规律。


<details>
  <summary>Details</summary>
Motivation: 尽管越狱攻击的传递性（能对未见过的提示和模型同样有效）广为人知，但之前缺乏对其传递性机制的系统分析。作者希望通过实证方法解释这种现象，并为攻防提供理论依据。

Method: 作者分析了大量实验数据，提出并度量了三个与攻击传递性强相关的统计量：1）无后缀提示激活模型拒绝方向的强度；2）后缀推动模型远离该拒绝方向的程度；3）正交于拒绝方向的变化规模。同时，作者考察了语义相似度的相关性。

Result: 发现上述三个统计量与越狱攻击的跨提示和跨模型传递性高度相关，而语义相似度相关极弱。此外，通过干预实验，证明理解并优化这些统计量可以显著提升攻击成功率。

Conclusion: 越狱后缀的有效传递性并非因表面语义相似，而是与模型内部特定向量空间的变化相关。理解这些内在机制有助于改进攻击方法并制定更有效的防御策略。

Abstract: Discrete optimization-based jailbreaking attacks on large language models aim
to generate short, nonsensical suffixes that, when appended onto input prompts,
elicit disallowed content. Notably, these suffixes are often transferable --
succeeding on prompts and models for which they were never optimized. And yet,
despite the fact that transferability is surprising and empirically
well-established, the field lacks a rigorous analysis of when and why transfer
occurs. To fill this gap, we identify three statistical properties that
strongly correlate with transfer success across numerous experimental settings:
(1) how much a prompt without a suffix activates a model's internal refusal
direction, (2) how strongly a suffix induces a push away from this direction,
and (3) how large these shifts are in directions orthogonal to refusal. On the
other hand, we find that prompt semantic similarity only weakly correlates with
transfer success. These findings lead to a more fine-grained understanding of
transferability, which we use in interventional experiments to showcase how our
statistical analysis can translate into practical improvements in attack
success.

</details>


### [224] [Penalizing Length: Uncovering Systematic Bias in Quality Estimation Metrics](https://arxiv.org/abs/2510.22028)
*Yilin Zhang,Wenda Xu,Zhongtao Liu,Tetsuji Nakagawa,Markus Freitag*

Main category: cs.CL

TL;DR: 该论文系统性研究了机器翻译质量估计（QE）指标中的长度偏差问题，并提出了两种有效的缓解方法。


<details>
  <summary>Details</summary>
Motivation: 虽然QE广泛应用于无参考评价和强化学习奖励信号，但其中的长度偏差问题尚未被充分研究。该偏差可能导致评价不公并影响实际应用效果，因此亟需探究其表现及解决办法。

Method: 作者分析了回归类和大语言模型（LLM-as-a-Judge）QE指标在10组语言对上的表现，系统揭示了随翻译长度增加，QE过度预测错误、偏好短译文等现象。论文并提出在训练期引入长度归一化、评测时结合参考译文两种解决策略。

Result: 实验证明，该两种方法均可有效降低QE指标中的长度偏差，改善长文本和短文本的公平性。

Conclusion: 论文明确长度偏差对QE的不利影响，并给出可行的缓解方法，对相关应用和研究具有重要参考价值。

Abstract: Quality Estimation (QE) metrics are vital in machine translation for
reference-free evaluation and as a reward signal in tasks like reinforcement
learning. However, the prevalence and impact of length bias in QE have been
underexplored. Through a systematic study of top-performing regression-based
and LLM-as-a-Judge QE metrics across 10 diverse language pairs, we reveal two
critical length biases: First, QE metrics consistently over-predict errors with
increasing translation length, even for high-quality, error-free texts. Second,
they exhibit a preference for shorter translations when multiple candidates are
available for the same source text. These inherent length biases risk unfairly
penalizing longer, correct translations and can lead to sub-optimal
decision-making in applications such as QE reranking and QE guided
reinforcement learning. To mitigate this, we propose two strategies: (a)
applying length normalization during model training, and (b) incorporating
reference texts during evaluation. Both approaches were found to effectively
reduce the identified length bias.

</details>


### [225] [ATLAS: Adaptive Transfer Scaling Laws for Multilingual Pretraining, Finetuning, and Decoding the Curse of Multilinguality](https://arxiv.org/abs/2510.22037)
*Shayne Longpre,Sneha Kudugunta,Niklas Muennighoff,I-Hung Hsu,Isaac Caswell,Alex Pentland,Sercan Arik,Chen-Yu Lee,Sayna Ebrahimi*

Main category: cs.CL

TL;DR: 本文提出并验证了一种新的多语言预训练与扩展规律ATLAS，通过大规模实验证明其能优于现有规律，并揭示了多语言学习和迁移的多个规律性结论。


<details>
  <summary>Details</summary>
Motivation: 当前大部分关于AI模型扩展规律的研究仅关注英语，但全球用户多样，急需有效支持多语言的理论与实践框架。

Method: 作者开展了774组多语言训练实验，涵盖从10M到8B参数、400多种训练语言和48种评测语言，提出并测试了新型适应性迁移扩展规律（ATLAS），并从横向对比、规模增益、零样本泛化等多角度定量分析规律的优劣。

Result: ATLAS在单语和多语场景均显著优于现有扩展规律，泛化性R^2提升大于0.3；提出的跨语言迁移矩阵定量刻画了语言两两问的相互增益：发现了可同时优化模型规模与数据量的无关语言精度规律，给出了预训练与微调的分界点。

Conclusion: 该工作丰富了扩展规律研究的语言广度，为多语言AI模型高效扩展提供了可实践和科学支撑，有助于打破“以英语为先”的AI发展格局，实现更公平的AI模型扩展。

Abstract: Scaling laws research has focused overwhelmingly on English -- yet the most
prominent AI models explicitly serve billions of international users. In this
work, we undertake the largest multilingual scaling laws study to date,
totaling 774 multilingual training experiments, spanning 10M-8B model
parameters, 400+ training languages and 48 evaluation languages. We introduce
the Adaptive Transfer Scaling Law (ATLAS) for both monolingual and multilingual
pretraining, which outperforms existing scaling laws' out-of-sample
generalization often by more than 0.3 R^2. Our analyses of the experiments shed
light on multilingual learning dynamics, transfer properties between languages,
and the curse of multilinguality. First, we derive a cross-lingual transfer
matrix, empirically measuring mutual benefit scores between 38 x 38=1444
language pairs. Second, we derive a language-agnostic scaling law that reveals
how to optimally scale model size and data when adding languages without
sacrificing performance. Third, we identify the computational crossover points
for when to pretrain from scratch versus finetune from multilingual
checkpoints. We hope these findings provide the scientific foundation for
democratizing scaling laws across languages, and enable practitioners to
efficiently scale models -- beyond English-first AI.

</details>


### [226] [Emotions Where Art Thou: Understanding and Characterizing the Emotional Latent Space of Large Language Models](https://arxiv.org/abs/2510.22042)
*Benjamin Reichman,Adar Avsian,Larry Heck*

Main category: cs.CL

TL;DR: 本研究发现大语言模型（LLM）内部存在稳定且可操控的情感几何结构，这为其情感表征和操控提供了理论支持。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在理解和生成情感内容上表现优异，但其内部是如何表征和处理情感的仍不清楚。因此，作者试图揭示LLM内部的情感表征机制。

Method: 本文通过分析LLM的隐藏状态，发现低维的情感流形（emotional manifold），并对其方向性、多层分布及与可解释维度的对齐进行了研究。此外，作者在跨领域、跨语言的八个真实数据集上进行了实验，并构建了可学习干预模块以操控模型的内部情感感知。

Result: 结果表明：1. 情感表征呈现低维流形结构，且该结构跨模型深度较为稳定；2. 情感维度在不同任务和语言间对齐良好，线性探针和跨领域对齐误差低，表现出通用性；3. 构建的干预模块能有效调控模型对情感的内部感知。

Conclusion: LLM具有一致且可操控的情感几何结构，揭示了LLM内在情感处理机制，并为未来情感操控、情感智能应用提供理论依据。

Abstract: This work investigates how large language models (LLMs) internally represent
emotion by analyzing the geometry of their hidden-state space. The paper
identifies a low-dimensional emotional manifold and shows that emotional
representations are directionally encoded, distributed across layers, and
aligned with interpretable dimensions. These structures are stable across depth
and generalize to eight real-world emotion datasets spanning five languages.
Cross-domain alignment yields low error and strong linear probe performance,
indicating a universal emotional subspace. Within this space, internal emotion
perception can be steered while preserving semantics using a learned
intervention module, with especially strong control for basic emotions across
languages. These findings reveal a consistent and manipulable affective
geometry in LLMs and offer insight into how they internalize and process
emotion.

</details>


### [227] [Compositional Bias Control in Large Language Models: Preference Learning Fails, Supervision Succeeds](https://arxiv.org/abs/2510.22084)
*Atij Mahesh*

Main category: cs.CL

TL;DR: 本文系统比较了六种控制技术对大语言模型性别偏见缓解的效果，发现在复合约束下，只有显式正向监督能有效兼顾公平和流畅。


<details>
  <summary>Details</summary>
Motivation: 尽管已有多种方法尝试减少大语言模型中的性别刻板印象，但不同方法的效果及机制尚未被系统比较。

Method: 作者对提示工程、生成-筛选、DFA控制解码、监督微调（SFT）、直接偏好优化（DPO）、迭代零空间投影（INLP）六种方法进行横向比较，并设计了要求同时包含两类描述词的生成任务，量化比较公平性、流畅性和多样性。

Result: SFT方法在约束满足率和词汇多样性上表现最好；偏好优化DPO模式下准则满足率极低；DFA控制解码虽可完全控制，但严重损害流畅性和多样性。偏好学习模式无法适应复合逻辑约束。

Conclusion: 偏好学习方法无法泛化逻辑结构，只有显式正向监督才能有效缓解复合偏见，实现公平且自然的文本生成。

Abstract: Large Language Models (LLMs) still produce gender-stereotyped language even
in occupation-neutral contexts that reflect deep societal biases (Rudinger et
al., 2018). To address this, prior work has proposed prompting, constrained
decoding (Dathathri et al., 2020; Zhou et al., 2024), post-processing, and
fine-tuning-based alignment (Rafailov et al., 2023; Ravfogel et al., 2022).
However, the comparative efficacy and learning dynamics remain little
understood. We report a comparative analysis of six control techniques for bias
mitigation: prompt-only, generate-and-filter, DFA-based Ctrl-G decoding,
Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and
Iterative Nullspace Projection (INLP). We evaluate each method on a
compositional constraint task. This task requires generating sentences that
contain at least one agentic and one communal descriptor for each of the twenty
Winogender-derived occupations. We quantify trade-offs between control strength
and naturalness with evaluations of constraint compliance, lexical diversity,
and fluency. Our results reveal key contrasts among the methods: SFT achieves
99.87 +- 0.15% compliance and high lexical diversity, while DPO, despite
similar training stability, fails at 4.53 +- 0.82%. Ctrl-G guarantees perfect
compliance, but at the cost of severely reduced fluency and diversity.
Preference-based learning fundamentally differs: it cannot satisfy
compositional constraints, as binary preference signals encode ranking, not
logical conjunctions. Only explicit positive supervision enables mitigation of
compositional biases; preference-based alignment fails to generalize logical
structures, underscoring the limitations of preference learning and the
necessity of explicit supervision for fair and fluent controlled generation.

</details>


### [228] [Generalization or Memorization: Dynamic Decoding for Mode Steering](https://arxiv.org/abs/2510.22099)
*Xuanming Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种统一框架，用于理解、识别和控制大模型推理中的泛化与死记硬背这两种模式，并提出了Dynamic Mode Steering (DMS)算法以提升大模型的可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然泛化能力强，但在某些情景下会机械地记忆训练数据，这种不可预测性让其在关键应用中的可靠性降低。解决这一问题并增强模型在推理任务中的一致性与准确性具有重要意义。

Method: 本文首先引入基于信息瓶颈原理的理论模型，将泛化视为压缩与任务相关的表示，将死记硬背视为压缩失败。随后提出Dynamic Mode Steering（DMS）算法，包含两个部分：（1）通过轻量级线性探针及时识别模型依赖记忆的程度；（2）动态激活调整机制，将模型推理引导至已识别的泛化路径。该方法被表述为一种自适应、对比型的解码方式。

Result: 实验结果表明，在推理和事实准确性任务上，DMS算法显著提升了大模型的逻辑一致性和事实准确性。

Conclusion: 该研究提出了一种理论和实践结合的方法，能够有效增强大型语言模型的推理可靠性，为模型在高要求任务中的应用提供了有力支持。

Abstract: Large Language Models (LLMs) exhibit a troubling duality, capable of both
remarkable generalization and brittle, verbatim memorization of their training
data. This unpredictability undermines their reliability in high-stakes
applications. In this work, we propose a unified framework to understand,
identify, and control these distinct reasoning modes. First, we introduce a
theoretical model based on the Information Bottleneck (IB) principle,
formalizing generalization as the learning of a compressed, task-relevant
representation and memorization as a failure to compress. Building on this
theory, we develop Dynamic Mode Steering (DMS), a novel inference-time
algorithm which comprises two components: (1) a lightweight, causally-grounded
linear probe that identifies the model's instantaneous reliance on
memorization, and (2) a dynamic activation steering mechanism that nudges the
model's computation towards pre-identified generalization circuits. We frame
DMS as a form of adaptive, self-contrastive decoding. Experiments on reasoning
and faithfulness tasks demonstrate that DMS significantly improves logical
consistency and factual accuracy, thereby offering a principled approach to
enhancing LLM reliability.

</details>


### [229] [Gradual Forgetting: Logarithmic Compression for Extending Transformer Context Windows](https://arxiv.org/abs/2510.22109)
*Billy Dickson,Zoran Tiganj*

Main category: cs.CL

TL;DR: 作者提出了一种不改变Transformer架构，而是对输入进行对数压缩的新方法，以提升长文本建模能力，在多个基准测试上减少了困惑度。


<details>
  <summary>Details</summary>
Motivation: 现有针对长文本处理的方法通常需要增加Transformer结构的复杂性，比如引入循环或辅助记忆模块，这样会带来实现和部署上的额外负担。因此，作者希望寻找一种无需改变基础模型结构，也能扩展长距离依赖感知能力的方案。

Method: 作者受到人类记忆认知模型启发，对输入token进行尺度不变的对数压缩，然后用标准Transformer进行处理，无需对原有模型架构做任何改动。

Result: 在WikiText-103和PG-19语言建模基准上，与未压缩输入相比，所提方法显著降低了困惑度；并且随着压缩后输入长度的增加，效果进一步提升。

Conclusion: 输入级的对数压缩是一种简单有效的扩展Transformer长距离记忆的方法，无需对模型架构做复杂改动，即可获得较好的长文本处理性能。

Abstract: Most approaches to long-context processing increase the complexity of the
transformer's internal architecture by integrating mechanisms such as
recurrence or auxiliary memory modules. In this work, we introduce an
alternative approach that modifies the input representation itself, rather than
the transformer architecture. Inspired by cognitive models of human memory, our
method applies a scale-invariant logarithmic compression to the input tokens.
The resulting compressed representation is processed by a standard, unmodified
transformer, preserving architectural simplicity. We evaluate this approach on
the WikiText-103 and PG-19 language modeling benchmarks, showing a reduction in
perplexity compared to uncompressed baselines. Moreover, performance improves
consistently with longer compressed temporal contexts, showing that input-level
logarithmic compression is a simple and effective way to extend a transformer's
long-range memory.

</details>


### [230] [Every Activation Boosted: Scaling General Reasoner to 1 Trillion Open Language Foundation](https://arxiv.org/abs/2510.22115)
*Ling-Team,Ang Li,Ben Liu,Binbin Hu,Bing Li,Bingwei Zeng,Borui Ye,Caizhi Tang,Changxin Tian,Chao Huang,Chao Zhang,Chen Qian,Chenchen Ju,Chenchen Li,Chengfu Tang,Chili Fu,Chunshao Ren,Chunwei Wu,Cong Zhang,Cunyin Peng,Dafeng Xu,Daixin Wang,Dalong Zhang,Dingnan Jin,Dingyuan Zhu,Dongke Hu,Fangzheng Zhao,Feifan Wu,Feng Zhu,Gangshan Wang,Haitao Zhang,Hailin Zhao,Hanxiao Zhang,Hanzi Wang,Hao Qian,Haoyi Yu,Heng Zhang,Hongliang Zhang,Hongzhi Luan,Huirong Dong,Huizhong Li,Jia Li,Jia Liu,Jialong Zhu,Jian Sha,Jianping Wei,Jiaolong Yang,Jieyue Ma,Jiewei Wu,Jinjing Huang,Jingyun Tian,Jingyuan Zhang,Jinquan Sun,Juanhui Tu,Jun Liu,Jun Xu,Jun Zhou,Junjie Ou,Junpeng Fang,Kaihong Zhang,Kaiqin Hu,Ke Shi,Kun Tang,Kunlong Chen,Lanyin Mei,Lei Liang,Lei Xu,Libo Zhang,Lin Ju,Lin Yuan,Ling Zhong,Lintao Ma,Lu Liu,Lu Yu,Lun Cai,Meiqi Zhu,Mengying Li,Min Chen,Minghao Xue,Minghong Cai,Mingming Yin,Peijie Jiang,Peilong Zhao,Pingping Liu,Qian Zhao,Qing Cui,Qingxiang Huang,Qingyuan Yang,Quankun Yu,Shaowei Wei,Shijie Lian,Shoujian Zheng,Shun Song,Shungen Zhang,Shuo Zhang,Siyuan Li,Song Liu,Ting Guo,Tong Zhao,Wanli Gu,Weichang Wu,Weiguang Han,Wenjing Fang,Wubin Wang,Xiang Shu,Xiao Shi,Xiaoshun Lan,Xiaolu Zhang,Xiaqing Sun,Xin Zhao,Xingyu Lu,Xiong Xu,Xudong Wang,Xudong Wang,Xuemin Yang,Yajie Yang,Yang Xiang,Yanzhe Li,Yi Zhang,Yilong Wang,Yingxue Li,Yongzhen Guo,Yuzhuo Fu,Yuanyuan Wang,Yue Yang,Yue Yu,Yufeng Deng,Yun Zhang,Yunfei Xu,Yuqi Zhang,Yuxiao He,Zengke Gui,Zhaoxin Huan,Zhaoyang Wang,Zhibo Zhu,Zhihao Wang,Zhiqiang Zhang,Zhoufei Wang,Zihang Zeng,Ziqi Liu,Zitao Xuan,Zuoli Tang*

Main category: cs.CL

TL;DR: Ling 2.0 是一个面向推理能力提升的大型语言模型系列，采用高稀疏度的专家混合（MoE）架构，参数规模从160亿到1万亿，主打高效与一致性。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在推理能力与计算效率间存在权衡，如何兼顾更强推理能力和更高计算效率亟需创新。

Method: 采用高稀疏度的MoE架构，配合多项创新方法，包括高稀疏激活、以推理为导向的数据与训练策略（如中期链式思考激活、基于强化学习的微调）、全面FP8训练及异构训练流水线。

Result: Ling 2.0 的160亿至1万亿规模模型（如Ling-mini-2.0、Ling-flash-2.0、Ling-1T）实现了比稠密模型高达7倍的活跃计算效率。在1万亿参数规模下，推理能力与计算效率达到新的Pareto前沿。

Conclusion: 高稀疏激活和推理目标的有效结合能大幅提升大模型的可扩展性与推理效率，Ling 2.0为未来推理/思维型开源模型奠定了高效且一致的基础，包括基于其开发的Ring系列等。

Abstract: We introduce Ling 2.0, a series reasoning-oriented language foundation built
upon the principle that every activation boosts reasoning capability. Designed
to scale from tens of billions to one trillion parameters under a unified
Mixture-of-Experts (MoE) paradigm, Ling 2.0 emphasizes high sparsity,
cross-scale consistency, and efficiency guided by empirical scaling laws. The
series includes three non-thinking (instruct) models - Ling-mini-2.0,
Ling-flash-2.0, and Ling-1T - ranging from 16B to 1T total parameters and
achieving up to 7-fold active-compute efficiency compared with dense
counterparts. Ling 2.0 integrates coordinated innovations across model
architecture, pre-training, post-training, and infrastructure: a high-sparsity
MoE with MTP for efficient reasoning, reasoning-oriented data and mid-training
CoT activation, reinforcement-based fine-tuning (DFT, Evo-CoT), and full-scale
FP8 training with fine-grained heterogeneous pipelines. At the trillion scale,
Ling-1T establishes a new Pareto frontier of reasoning accuracy versus
computational efficiency, demonstrating that sparse activation, when properly
aligned with reasoning objectives, enables scalable and efficient intelligence.
Collectively, Ling 2.0 provides a coherent, open, and efficient foundation for
advancing future reasoning and thinking models, including the Ring series built
upon the same base.

</details>


### [231] [OlaMind: Towards Human-Like and Hallucination-Safe Customer Service for Retrieval-Augmented Dialogue](https://arxiv.org/abs/2510.22143)
*Tianhong Gao,Jundong Shen,Bei Shi,Jiapeng Wang,Ying Ju,Junfeng Yao,Jiao Ran,Yong Zhang,Lin Dong,Huiyu Yu,Tingting Ye*

Main category: cs.CL

TL;DR: 本文提出了OlaMind，一个在人机对话框架下提升客户服务智能度和安全性的系统，显著减少了幻觉（无根据或虚假回答）并提高了响应的自然性和人性化。


<details>
  <summary>Details</summary>
Motivation: 动机源于现有基于RAG（检索增强生成）的智能客服系统在自动化和效率提升方面虽有进步，但常出现幻觉和机械化回答，影响用户体验和带来业务风险。

Method: OlaMind框架包含两个阶段：首先通过Learn-to-Think阶段学习人类专家的推理和应答策略，随后通过Learn-to-Respond阶段进行冷启动监督微调，并结合强化学习进行由浅入深的自我优化。

Result: 在真实的社交客服与直播场景下开展大规模A/B实验，OlaMind在智能问题解决率上提升了28.92%（社区支持）和18.42%（直播互动），人工介入率分别下降6.08%和7.12%。

Conclusion: OlaMind能够有效增强客服系统的自然度和人性化，显著减少幻觉和业务关键风险，在多种实际应用场景下表现优异，系统代码和数据将公开。

Abstract: Intelligent customer service (ICS) systems via retrieval-augmented generation
(RAG) have been widely adopted in Web-based domains such as social platforms
and e-commerce, achieving remarkable improvements in automation and efficiency.
However, notable limitations still remain: these systems are prone to
hallucinations and often generate rigid, mechanical responses, which can
introduce business risks and undermine user experience, especially in Web-based
customer service interactions under the RAG scenarios. In this paper, we
introduce OlaMind, a human-like and hallucination-safe customer service
framework for retrieval-augmented dialogue. Specifically, it first leverages a
Learn-to-Think stage to learn the reasoning processes and response strategies
from human experts, and then employs a Learn-to-Respond stage to perform
cold-start supervised fine-tuning (SFT) combined with reinforcement learning
(RL) for basic-to-hard self-refinement. Our method significantly enhances
human-likeness and naturalness while effectively mitigating hallucinations and
critical business risks. We have conducted large-scale online A/B experiments
in an industry-level social customer service setting, and extensive
experimental results show that OlaMind achieves significant cumulative relative
improvements with intelligent resolution rates +28.92%/+18.42% and human
takeover rate -6.08%/-7.12% in community-support/livestream-interaction
scenarios, respectively, which highlights its consistent effectiveness across
diverse real-world applications. The code and data will be publicly available.

</details>


### [232] [SentiMaithili: A Benchmark Dataset for Sentiment and Reason Generation for the Low-Resource Maithili Language](https://arxiv.org/abs/2510.22160)
*Rahul Ranjan,Mahendra Kumar Gurve,Anuj,Nitin,Yamuna Prasad*

Main category: cs.CL

TL;DR: 本文创建了首个包含解释性标注的Maithili语情感分析数据集，为低资源语言情感分析和可解释AI提供了重要基准。


<details>
  <summary>Details</summary>
Motivation: Maithili语是仍被NLP领域严重低估的印地语-雅利安语系，多达1300万人使用，因缺乏专家和标注资源，相关情感分析数据集罕见，制约了在该语言上开展可解释的情感分析研究。

Method: 作者建立了3,221条Maithili句子的全新情感极性标注数据集，每条数据额外由母语专家给出自然语言、与情感标注一致的解释说明，确保高质量和上下文一致性。并利用传统机器学习和最前沿的transformer等模型对该数据集进行了情感分析与可解释性实验。

Result: 实验结果表明，基于该数据集，可在Maithili语上实现有效且具解释性的情感分析。数据集本身经过专家严格审核，结构丰富，极大提升了解释能力和模型泛化。

Conclusion: 该数据集成为Maithili语可解释情感计算的首个基准，对多语种自然语言处理和可解释AI领域具有重要推动作用，也支持更多低资源语言的研究。

Abstract: Developing benchmark datasets for low-resource languages poses significant
challenges, primarily due to the limited availability of native linguistic
experts and the substantial time and cost involved in annotation. Given these
challenges, Maithili is still underrepresented in natural language processing
research. It is an Indo-Aryan language spoken by more than 13 million people in
the Purvanchal region of India, valued for its rich linguistic structure and
cultural significance. While sentiment analysis has achieved remarkable
progress in high-resource languages, resources for low-resource languages, such
as Maithili, remain scarce, often restricted to coarse-grained annotations and
lacking interpretability mechanisms. To address this limitation, we introduce a
novel dataset comprising 3,221 Maithili sentences annotated for sentiment
polarity and accompanied by natural language justifications. Moreover, the
dataset is carefully curated and validated by linguistic experts to ensure both
label reliability and contextual fidelity. Notably, the justifications are
written in Maithili, thereby promoting culturally grounded interpretation and
enhancing the explainability of sentiment models. Furthermore, extensive
experiments using both classical machine learning and state-of-the-art
transformer architectures demonstrate the dataset's effectiveness for
interpretable sentiment analysis. Ultimately, this work establishes the first
benchmark for explainable affective computing in Maithili, thus contributing a
valuable resource to the broader advancement of multilingual NLP and
explainable AI.

</details>


### [233] [DETECT: Determining Ease and Textual Clarity of German Text Simplifications](https://arxiv.org/abs/2510.22212)
*Maria Korobeynikova,Alessia Battisti,Lukas Fischer,Yingqiang Gao*

Main category: cs.CL

TL;DR: 本文提出了DETECT，这是首个专为德语自动文本简化（ATS）质量全方位评估（包括简洁性、含义保留和流畅性）设计的指标，并利用大语言模型（LLM）生成的合成数据进行训练。


<details>
  <summary>Details</summary>
Motivation: 现有德语文本简化评价指标不足以全面反映文本的简化质量，尤其是简洁性、含义保留和流畅性三个方面缺乏高效评价工具，且由于缺少人工标注语料，德语相关研究落后于英语。因此，亟需开发适用于德语的专用自动简化评估指标。

Method: 作者将英语领域已有的LENS框架适配至德语，并提出两大改进：一是通过LLM自动生成高质量评分，构建无需人工标注的数据集；二是引入LLM微调环节，使评分标准更贴合简化任务要求。作者还构建了迄今最大规模的德语简化任务人工评测数据集，用以直接验证新指标的有效性。

Result: 实验表明，DETECT与人工评判结果相关性显著高于现有常用ATS指标，特别是在含义保留和流畅性维度提升尤为明显。

Conclusion: DETECT推动了德语简化自动评价的发展，证实了LLM在自动评价中的巨大潜力及现有限制，并为语言无障碍相关任务提供了可借鉴的方法指导。

Abstract: Current evaluation of German automatic text simplification (ATS) relies on
general-purpose metrics such as SARI, BLEU, and BERTScore, which insufficiently
capture simplification quality in terms of simplicity, meaning preservation,
and fluency. While specialized metrics like LENS have been developed for
English, corresponding efforts for German have lagged behind due to the absence
of human-annotated corpora. To close this gap, we introduce DETECT, the first
German-specific metric that holistically evaluates ATS quality across all three
dimensions of simplicity, meaning preservation, and fluency, and is trained
entirely on synthetic large language model (LLM) responses. Our approach adapts
the LENS framework to German and extends it with (i) a pipeline for generating
synthetic quality scores via LLMs, enabling dataset creation without human
annotation, and (ii) an LLM-based refinement step for aligning grading criteria
with simplification requirements. To the best of our knowledge, we also
construct the largest German human evaluation dataset for text simplification
to validate our metric directly. Experimental results show that DETECT achieves
substantially higher correlations with human judgments than widely used ATS
metrics, with particularly strong gains in meaning preservation and fluency.
Beyond ATS, our findings highlight both the potential and the limitations of
LLMs for automatic evaluation and provide transferable guidelines for general
language accessibility tasks.

</details>


### [234] [Estimating the Error of Large Language Models at Pairwise Text Comparison](https://arxiv.org/abs/2510.22219)
*Tianyi Li*

Main category: cs.CL

TL;DR: 本文提出了一种无需依赖真实标签来评估大语言模型(LLM)在成对文本比较任务中的输出错误率的方法，并揭示了现有LLM在该任务上的可拓展性问题。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型常用于文本偏好和质量评估，但理想的评测通常缺乏准确的标准答案。本研究旨在量化LLM在无真实标签参考下，进行成对文本比较时的错误概率及其位置偏差，进而更科学地评判其可靠性。

Method: 作者设计了两种误差估计方案：(i) 假设无顺序偏向（只需各2次比较，互换位置），(ii) 假设存在二进制位置偏向（多次重复互换比较以分别估算两种顺序的错误率）。采用Copeland计数法对文本进行成对偏好累积，得出排名，并用于计算LLM错误率。实验比较了六个主流模型在五类文本上的表现。

Result: 实验结果显示，不同LLM的两种位置偏向误差非常接近，整体误差也与无顺序偏向估计接近。Claude模型在误差率与鲁棒性方面表现最优。此外，所提出模型优于有偏Bradley-Terry模型及commutativity分数，反映LLM错误特性更清晰。

Conclusion: 此方法可有效评估LLM在成对偏好比较中的错误表现，并揭示当前LLM在大规模文本比较任务下的可拓展性问题，对后续模型优化和评估方法具有借鉴意义。

Abstract: We measure LLMs' output error at pairwise text comparison, noting the
probability of error in their preferences. Our method does not rely on the
ground truth and supports two scenarios: (i) uniform error rate regardless of
the order of comparison, estimated with two comparisons for each text pair with
either text placed first; (ii) binary positional bias assuming distinct error
rates for the two orders of comparison, estimated with repeated comparisons
between the texts. The Copeland counting constructs a ranking over the compared
texts from pairwise preferences; the ranking reveals the poor scalability of
LLM-based pairwise comparison and helps yield the estimates for LLMs' error
rates. We apply the method to six LLMs (ChatGPT, Claude, DeepSeek, Gemini,
Grok, Qwen) with five types of text input and obtain consistent estimates of
LLMs' error. In general, the measured two positional bias terms are similar,
close to the uniform error. Considering both the error rates and the robustness
to the variation of prompts, Claude obtained the most desirable performance in
this experiment. Our model outperforms the biased Bradley-Terry model and the
commutativity score in indicating LLMs' error at this task.

</details>


### [235] [Evolution of the lexicon: a probabilistic point of view](https://arxiv.org/abs/2510.22220)
*Maurizio Serva*

Main category: cs.CL

TL;DR: 本文对Swadesh词汇统计法用于估算两种语言分离时间的方法进行了深入分析，指出了其假设和方法上的局限，并提出引入词汇渐变的随机过程以提升估算准确性。


<details>
  <summary>Details</summary>
Motivation: Swadesh法广泛用于估算语言分离时间，但其基本假设经常不切实际，导致误差较大。作者希望分析这些理论和实际误差，探寻改进方法，提升分离时间推断的精度。

Method: 作者首先分析Swadesh法假设的不现实性及其可能带来的误差，进而用概率数学方法探讨即使理想假设下该法的理论极限。然后提出词汇渐变（而非仅词语完全替换）也是一种重要的随机过程，并通过纯概率模型分析二者共同作用对时间估算的影响。

Result: 分析表明，仅靠Swadesh的词语完全替换假设，即使假设全部成立，分离时间估计也受到概率极限的限制。而加入渐进词汇变化的随机过程后，可显著提升分离时间推断的精确度。

Conclusion: Swadesh法存在先天不足，特别是忽视词汇渐进变化。将词汇变化视为两个随机过程共同驱动，可以更准确地推断语言分离时间，这对于未来的语言演化研究和工具开发具有重要启示。

Abstract: The Swadesh approach for determining the temporal separation between two
languages relies on the stochastic process of words replacement (when a
complete new word emerges to represent a given concept). It is well known that
the basic assumptions of the Swadesh approach are often unrealistic due to
various contamination phenomena and misjudgments (horizontal transfers,
variations over time and space of the replacement rate, incorrect assessments
of cognacy relationships, presence of synonyms, and so on). All of this means
that the results cannot be completely correct.
  More importantly, even in the unrealistic case that all basic assumptions are
satisfied, simple mathematics places limits on the accuracy of estimating the
temporal separation between two languages. These limits, which are purely
probabilistic in nature and which are often neglected in lexicostatistical
studies, are analyzed in detail in this article.
  Furthermore, in this work we highlight that the evolution of a language's
lexicon is also driven by another stochastic process: gradual lexical
modification of words. We show that this process equally also represents a
major contribution to the reshaping of the vocabulary of languages over the
centuries and we also show, from a purely probabilistic perspective, that
taking into account this second random process significantly increases the
precision in determining the temporal separation between two languages.

</details>


### [236] [You Don't Need Prompt Engineering Anymore: The Prompting Inversion](https://arxiv.org/abs/2510.22251)
*Imran Khan*

Main category: cs.CL

TL;DR: 本文提出了一种名为“Sculpting”的受限规则型提示方法，并通过实验分析提示策略与大模型能力之间的协同关系。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）能力提升，如何通过提示工程进一步增强其推理表现成为研究热点。标准的CoT提示虽能提升推理能力，但容易因语义歧义和常识缺陷引入错误。作者旨在探索更有效的提示方式，并研究模型能力变化下的提示优化策略。

Method: 作者提出Sculpting提示工程方法，对标准CoT提示加以约束与规则，旨在减少模型推理中的语义与常识错误。在三个不同代际（gpt-4o-mini, gpt-4o, gpt-5）的OpenAI模型及GSM8K数学推理基准（1317题）上，分别对零样本、标准CoT和Sculpting三种提示策略进行系统评测，并详细分析错误类型。

Result: 实验结果显示，在gpt-4o上Sculpting优于标准CoT（97%对93%），但在gpt-5上反而变成劣势（94.00%对96.36%），即出现了“提示反转”现象。错误分析发现，Sculpting对中等模型起到纠偏作用，但对更强模型却限制过度，引发“护栏到手铐”效应。

Conclusion: 大模型的最佳提示策略需要与模型能力同步演化。简单提示对高能力模型可能更优，提示复杂化在进阶模型上反而可能损害表现。

Abstract: Prompt engineering, particularly Chain-of-Thought (CoT) prompting,
significantly enhances LLM reasoning capabilities. We introduce "Sculpting," a
constrained, rule-based prompting method designed to improve upon standard CoT
by reducing errors from semantic ambiguity and flawed common sense.
  We evaluate three prompting strategies (Zero Shot, standard CoT, and
Sculpting) across three OpenAI model generations (gpt-4o-mini, gpt-4o, gpt-5)
using the GSM8K mathematical reasoning benchmark (1,317 problems).
  Our findings reveal a "Prompting Inversion": Sculpting provides advantages on
gpt-4o (97% vs. 93% for standard CoT), but becomes detrimental on gpt-5 (94.00%
vs. 96.36% for CoT on full benchmark). We trace this to a
"Guardrail-to-Handcuff" transition where constraints preventing common-sense
errors in mid-tier models induce hyper-literalism in advanced models. Our
detailed error analysis demonstrates that optimal prompting strategies must
co-evolve with model capabilities, suggesting simpler prompts for more capable
models.

</details>


### [237] [SteerX: Disentangled Steering for LLM Personalization](https://arxiv.org/abs/2510.22256)
*Xiaoyan Zhao,Ming Yan,Yilun Qiu,Haoting Ni,Yang Zhang,Fuli Feng,Hong Cheng,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 该论文提出了一种新的个性化大模型激活引导方法SteerX，通过分离用户偏好相关信息与无关信息，提高了大模型个性化输出的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有大模型个性化方法依赖于所有历史数据计算引导向量，未能剔除与用户偏好无关的内容，从而削弱了个性化信号，影响模型效果。

Method: SteerX方法基于因果推断理论，在token级别估算因果效应，识别出真正由用户偏好驱动的文本，并将这些离散偏好信号转换为一致性描述，最终用于生成更精准的个性化激活引导向量。

Result: 在两个主流激活引导方法、多个真实世界数据集上的实验表明，SteerX持续提升了引导向量质量，增强了个性化效果。

Conclusion: SteerX为大语言模型提供了更有效、实用的个性化解决方案，可更好适应不同用户的需求。

Abstract: Large language models (LLMs) have shown remarkable success in recent years,
enabling a wide range of applications, including intelligent assistants that
support users' daily life and work. A critical factor in building such
assistants is personalizing LLMs, as user preferences and needs vary widely.
Activation steering, which directly leverages directions representing user
preference in the LLM activation space to adjust its behavior, offers a
cost-effective way to align the model's outputs with individual users. However,
existing methods rely on all historical data to compute the steering vector,
ignoring that not all content reflects true user preferences, which undermines
the personalization signal. To address this, we propose SteerX, a disentangled
steering method that isolates preference-driven components from
preference-agnostic components. Grounded in causal inference theory, SteerX
estimates token-level causal effects to identify preference-driven tokens,
transforms these discrete signals into a coherent description, and then
leverages them to steer personalized LLM generation. By focusing on the truly
preference-driven information, SteerX produces more accurate activation
steering vectors and enhances personalization. Experiments on two
representative steering backbone methods across real-world datasets demonstrate
that SteerX consistently enhances steering vector quality, offering a practical
solution for more effective LLM personalization.

</details>


### [238] [PatenTEB: A Comprehensive Benchmark and Model Family for Patent Text Embedding](https://arxiv.org/abs/2510.22264)
*Iliass Ayaou,Denis Cavallucci*

Main category: cs.CL

TL;DR: 本文提出了一个专为专利文本设计的新型嵌入基准PatenTEB，并发布了高性能、多任务专利文本嵌入模型patembed。


<details>
  <summary>Details</summary>
Motivation: 现有的文本嵌入基准很难全面反映专利领域独有的检索和分析难点，如长文本、领域特异性、碎片对文档的匹配等，亟需更合适的评测方案和更强大的专利文本嵌入模型。

Method: 作者设计了PatenTEB基准，包含跨15个任务、206万样本，特殊地融合了领域分层切分、专利领域难负例挖掘和系统性碎片到文档匹配的评测。通过多任务学习训练了多种规模（67M到344M参数，最大支持4096字符）的patembed模型，并在多项任务和外部公开基准上评测其泛化性能。

Result: patembed-base在MTEB BigPatentClustering.v2任务上V-measure 0.494（显著超越前最佳的0.445），patembed-large在DAPFAM上NDCG@100达到0.377。消融实验表明多任务学习能提升外部任务泛化，而领域预训练初始化在各类任务下都有优势。

Conclusion: PatenTEB是针对专利文本的全面基准，patembed模型在多个专利文本任务上达到SOTA，相关资源已开源，有望推动专利检索和分析相关研究发展。

Abstract: Patent text embeddings enable prior art search, technology landscaping, and
patent analysis, yet existing benchmarks inadequately capture patent-specific
challenges. We introduce PatenTEB, a comprehensive benchmark comprising 15
tasks across retrieval, classification, paraphrase, and clustering, with 2.06
million examples. PatenTEB employs domain-stratified splits, domain specific
hard negative mining, and systematic coverage of asymmetric
fragment-to-document matching scenarios absent from general embedding
benchmarks. We develop the patembed model family through multi-task training,
spanning 67M to 344M parameters with context lengths up to 4096 tokens.
External validation shows strong generalization: patembed-base achieves
state-of-the-art on MTEB BigPatentClustering.v2 (0.494 V-measure vs. 0.445
previous best), while patembed-large achieves 0.377 NDCG@100 on DAPFAM.
Systematic ablations reveal that multi-task training improves external
generalization despite minor benchmark costs, and that domain-pretrained
initialization provides consistent advantages across task families. All
resources will be made available at https://github.com/iliass-y/patenteb.
Keywords: patent retrieval, sentence embeddings, multi-task learning,
asymmetric retrieval, benchmark evaluation, contrastive learning.

</details>


### [239] [From Slides to Chatbots: Enhancing Large Language Models with University Course Materials](https://arxiv.org/abs/2510.22272)
*Tu Anh Dinh,Philipp Nicolas Schumacher,Jan Niehues*

Main category: cs.CL

TL;DR: 通过引入大学课程材料，提升大语言模型（LLM）在大学计算机课程中的答题能力，发现检索增强生成（RAG）比持续预训练（CPT）更为高效有效，并且多模态输入（图片形式的课件幻灯片）进一步促进了模型表现。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在大学级别计算机科学课程中的问题解答准确率不理想。研究动因在于探索如何利用课程资料（包括幻灯片和语音转录）提升LLM在教育领域的实用价值。

Method: 比较两类增强LLM的方法：1）检索增强生成（RAG），2）持续预训练（CPT）。针对多模态材料，提出了将幻灯片图片作为输入的RAG方法，并与文本检索效果对比。

Result: 实验发现，在大学课程材料体量较小的情况下，RAG相较CPT更有效率和效果；使用幻灯片图片作为检索内容的多模态RAG方式明显优于只用文本的做法。

Conclusion: 论文指出，RAG结合多模态输入可以有效提升AI助理在教育场景下对学生学习的支持。该方法为类似场景下的AI系统开发提供了实用的参考。

Abstract: Large Language Models (LLMs) have advanced rapidly in recent years. One
application of LLMs is to support student learning in educational settings.
However, prior work has shown that LLMs still struggle to answer questions
accurately within university-level computer science courses. In this work, we
investigate how incorporating university course materials can enhance LLM
performance in this setting. A key challenge lies in leveraging diverse course
materials such as lecture slides and transcripts, which differ substantially
from typical textual corpora: slides also contain visual elements like images
and formulas, while transcripts contain spoken, less structured language. We
compare two strategies, Retrieval-Augmented Generation (RAG) and Continual
Pre-Training (CPT), to extend LLMs with course-specific knowledge. For lecture
slides, we further explore a multi-modal RAG approach, where we present the
retrieved content to the generator in image form. Our experiments reveal that,
given the relatively small size of university course materials, RAG is more
effective and efficient than CPT. Moreover, incorporating slides as images in
the multi-modal setting significantly improves performance over text-only
retrieval. These findings highlight practical strategies for developing AI
assistants that better support learning and teaching, and we hope they inspire
similar efforts in other educational contexts.

</details>


### [240] [Supervised Fine-Tuning or In-Context Learning? Evaluating LLMs for Clinical NER](https://arxiv.org/abs/2510.22285)
*Andrei Baroian*

Main category: cs.CL

TL;DR: 本研究对CADEC语料上的临床命名实体识别(NER)方法进行比较，包括BERT类模型、GPT-4o的少样本学习与指令工程、以及GPT-4o的有监督微调。结果显示，BERT改进受限，GPT-4o有监督微调表现最佳 (F1约87.1%)，但成本较高。简化任务（双标签）时大模型表现更好。


<details>
  <summary>Details</summary>
Motivation: 临床文本中的实体识别对于医疗健康信息提取非常重要。现有BERT类模型性能提升有限，大型语言模型(LLM)的在此任务上的优势及应用方式值得深入探索。

Method: 对CADEC语料的五种实体（ADR, Drug, Disease, Symptom, Finding）进行NER，分别采用三类方案：（一）标准的BERT Base、BioClinicalBERT、RoBERTa-large编码器；（二）GPT-4o以少样本ICL、指令工程不同prompt模式；（三）GPT-4o有监督微调（SFT）。

Result: RoBERTa-large和BioClinicalBERT对比BERT Base只有有限提升。GPT-4o简单ICL效果优于复杂prompt。GPT-4o有监督微调SFT达到了最优F1≈87.1%，但训练成本高。简化为二分类任务时，LLM表现明显提高。

Conclusion: BERT类编码器在临床NER提升空间有限，GPT-4o微调后可显著提升性能但需付出成本。当任务简单化时，LLM展现更大优势。

Abstract: We study clinical Named Entity Recognition (NER) on the CADEC corpus and
compare three families of approaches: (i) BERT-style encoders (BERT Base,
BioClinicalBERT, RoBERTa-large), (ii) GPT-4o used with few-shot in-context
learning (ICL) under simple vs.\ complex prompts, and (iii) GPT-4o with
supervised fine-tuning (SFT). All models are evaluated on standard NER metrics
over CADEC's five entity types (ADR, Drug, Disease, Symptom, Finding).
RoBERTa-large and BioClinicalBERT offer limited improvements over BERT Base,
showing the limit of these family of models. Among LLM settings, simple ICL
outperforms a longer, instruction-heavy prompt, and SFT achieves the strongest
overall performance (F1 $\approx$ 87.1%), albeit with higher cost. We find that
the LLM achieve higher accuracy on simplified tasks, restricting classification
to two labels.

</details>


### [241] [Memory-based Language Models: An Efficient, Explainable, and Eco-friendly Approach to Large Language Modeling](https://arxiv.org/abs/2510.22317)
*Antal van den Bosch,Ainhoa Risco Patón,Teun Buijse,Peter Berck,Maarten van Gompel*

Main category: cs.CL

TL;DR: 提出一种基于记忆的语言建模方法，作为深度神经网络语言模型的高效环保替代方案，兼具高准确性和低生态影响。


<details>
  <summary>Details</summary>
Motivation: 当前主流的深度神经网络语言模型（如GPT）计算资源消耗大，碳排放和能耗高，因此需要更加环保、高效的替代方案。

Method: 实现了一种基于k近邻算法的记忆型语言建模方法OLIFANT，利用CPU而非GPU进行运算，并对比了OLIFANT和GPT-2、GPT-Neo在下一个词预测准确率、碳排放和推理速度等方面的表现。

Result: OLIFANT展现出接近主流模型的预测能力，显著降低了计算资源需求和碳排放，推理速度和透明性也有优势。

Conclusion: 基于记忆的语言模型是高效且环保的语言建模新途径，有望成为现有深度神经网络模型的重要补充或替代。

Abstract: We present memory-based language modeling as an efficient, eco-friendly
alternative to deep neural network-based language modeling. It offers
log-linearly scalable next-token prediction performance and strong memorization
capabilities. Implementing fast approximations of k-nearest neighbor
classification, memory-based language modeling leaves a relatively small
ecological footprint both in training and in inference mode, as it relies fully
on CPUs and attains low token latencies. Its internal workings are simple and
fully transparent. We compare our implementation of memory-based language
modeling, OLIFANT, with GPT-2 and GPT-Neo on next-token prediction accuracy,
estimated emissions and speeds, and offer some deeper analyses of the model.

</details>


### [242] [Multilingual Target-Stance Extraction](https://arxiv.org/abs/2510.22334)
*Ethan Mines,Bonnie Dorr*

Main category: cs.CL

TL;DR: 本文提出了首个多语言目标立场提取（TSE）基准数据集，并实现了无需为每种语言单独训练模型的TSE模型流水线，为多语言TSE研究奠定基础。


<details>
  <summary>Details</summary>
Motivation: 此前TSE研究仅限于英文，但社交媒体上存在多种语言，缺乏多语言立场提取基准和方法，亟需扩展TSE任务到多语言场景。

Method: 作者构建了涵盖加泰罗尼亚语、爱沙尼亚语、法语、意大利语、中文和西班牙语的TSE多语言数据集，并将现有TSE模型流程无缝扩展到多语言环境，无需分别训练多种语言模型。

Result: 提出的多语言TSE模型在F1分数上仅为12.78，结果显示多语言TSE任务明显难于英文单一语言；主要瓶颈在于目标的准确预测。此外，首次分析了目标措辞变化对TSE性能的影响。

Conclusion: 本研究建立了多语言TSE的初步基线，包括数据集、算法和评估标准，对后续相关研究基础设施和方法改进具有重要作用。

Abstract: Social media enables data-driven analysis of public opinion on contested
issues. Target-Stance Extraction (TSE) is the task of identifying the target
discussed in a document and the document's stance towards that target. Many
works classify stance towards a given target in a multilingual setting, but all
prior work in TSE is English-only. This work introduces the first multilingual
TSE benchmark, spanning Catalan, Estonian, French, Italian, Mandarin, and
Spanish corpora. It manages to extend the original TSE pipeline to a
multilingual setting without requiring separate models for each language. Our
model pipeline achieves a modest F1 score of 12.78, underscoring the increased
difficulty of the multilingual task relative to English-only setups and
highlighting target prediction as the primary bottleneck. We are also the first
to demonstrate the sensitivity of TSE's F1 score to different target
verbalizations. Together these serve as a much-needed baseline for resources,
algorithms, and evaluation criteria in multilingual TSE.

</details>


### [243] [FAIR-RAG: Faithful Adaptive Iterative Refinement for Retrieval-Augmented Generation](https://arxiv.org/abs/2510.22344)
*Mohammad Aghajani Asl,Majid Asgari-Bidhendi,Behrooz Minaei-Bidgoli*

Main category: cs.CL

TL;DR: 本文提出了FAIR-RAG框架，通过结构化证据审核和循环细化机制，系统性解决多跳问题中的信息缝隙，大幅提升复杂检索增强生成任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前RAG方法在复杂、多跳检索任务上表现不佳，尤其难以系统性发现和补全证据信息空缺，因此实际效果受限。

Method: 提出FAIR-RAG框架，通过Structured Evidence Assessment（SEA）模块，将原始问题分解为证据需求清单，逐步审核和标记证据空白，再由自适应查询细化代理补充所缺证据，不断迭代直至事实充分，最后生成可靠答案。

Result: FAIR-RAG在多个多跳问答基准（如HotpotQA、2WikiMultiHopQA、MusiQue）上实验，显著超过强力基线；在HotpotQA上F1提升8.3分，达到0.453，刷新该类方法新纪录。

Conclusion: 结构化、证据驱动的细化流程和显式缺口分析对于提升复杂任务中RAG系统的准确性和可靠性至关重要。

Abstract: While Retrieval-Augmented Generation (RAG) mitigates hallucination and
knowledge staleness in Large Language Models (LLMs), existing frameworks often
falter on complex, multi-hop queries that require synthesizing information from
disparate sources. Current advanced RAG methods, employing iterative or
adaptive strategies, lack a robust mechanism to systematically identify and
fill evidence gaps, often propagating noise or failing to gather a
comprehensive context. We introduce FAIR-RAG, a novel agentic framework that
transforms the standard RAG pipeline into a dynamic, evidence-driven reasoning
process. At its core is an Iterative Refinement Cycle governed by a module we
term Structured Evidence Assessment (SEA). The SEA acts as an analytical gating
mechanism: it deconstructs the initial query into a checklist of required
findings and audits the aggregated evidence to identify confirmed facts and,
critically, explicit informational gaps. These gaps provide a precise signal to
an Adaptive Query Refinement agent, which generates new, targeted sub-queries
to retrieve missing information. This cycle repeats until the evidence is
verified as sufficient, ensuring a comprehensive context for a final, strictly
faithful generation. We conducted experiments on challenging multi-hop QA
benchmarks, including HotpotQA, 2WikiMultiHopQA, and MusiQue. In a unified
experimental setup, FAIR-RAG significantly outperforms strong baselines. On
HotpotQA, it achieves an F1-score of 0.453 -- an absolute improvement of 8.3
points over the strongest iterative baseline -- establishing a new
state-of-the-art for this class of methods on these benchmarks. Our work
demonstrates that a structured, evidence-driven refinement process with
explicit gap analysis is crucial for unlocking reliable and accurate reasoning
in advanced RAG systems for complex, knowledge-intensive tasks.

</details>


### [244] [Irony Detection in Urdu Text: A Comparative Study Using Machine Learning Models and Large Language Models](https://arxiv.org/abs/2510.22356)
*Fiaz Ahmad,Nisar Hussain,Amna Qasim,Momina Hafeez,Muhammad Usman Grigori Sidorov,Alexander Gelbukh*

Main category: cs.CL

TL;DR: 本文致力于解决乌尔都语讽刺识别难题，通过将英语讽刺语料库翻译为乌尔都语，测试多种机器学习及大模型在该任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 讽刺识别在NLP领域难度较高，特别是在语法和文化背景差异明显的低资源语言中，乌尔都语就是其中代表。现有针对乌尔都语的讽刺识别研究匮乏，因此该工作旨在弥补这一空白。

Method: 将英文讽刺语料翻译成乌尔都语，利用GloVe和Word2Vec词嵌入，评估10种主流机器学习算法，同时对BERT、RoBERTa、LLaMA 2 (7B)、LLaMA 3 (8B)、Mistral等大模型进行微调并比较性能。

Result: 在机器学习模型中，梯度提升（Gradient Boosting）F1分数达到89.18%；在Transformer类大模型中，LLaMA 3 (8B)表现最佳，F1分数高达94.61%。

Conclusion: 通过转写和现代NLP模型结合，即使在数据稀缺的乌尔都语环境下也能有效实现讽刺检测，展示出新方法的强大鲁棒性和实用价值。

Abstract: Ironic identification is a challenging task in Natural Language Processing,
particularly when dealing with languages that differ in syntax and cultural
context. In this work, we aim to detect irony in Urdu by translating an English
Ironic Corpus into the Urdu language. We evaluate ten state-of-the-art machine
learning algorithms using GloVe and Word2Vec embeddings, and compare their
performance with classical methods. Additionally, we fine-tune advanced
transformer-based models, including BERT, RoBERTa, LLaMA 2 (7B), LLaMA 3 (8B),
and Mistral, to assess the effectiveness of large-scale models in irony
detection. Among machine learning models, Gradient Boosting achieved the best
performance with an F1-score of 89.18%. Among transformer-based models, LLaMA 3
(8B) achieved the highest performance with an F1-score of 94.61%. These results
demonstrate that combining transliteration techniques with modern NLP models
enables robust irony detection in Urdu, a historically low-resource language.

</details>


### [245] [GigaEmbeddings: Efficient Russian Language Embedding Model](https://arxiv.org/abs/2510.22369)
*Egor Kolodin,Daria Khomich,Nikita Savushkin,Anastasia Ianina,Fyodor Minkin*

Main category: cs.CL

TL;DR: GigaEmbeddings提出了一种专为俄语设计的高性能文本嵌入训练框架，综合多阶段训练流程和架构创新，性能优越。


<details>
  <summary>Details</summary>
Motivation: 当前俄语文本嵌入方法存在性能和泛化能力不足的问题，且常用模型参数量大、效率低，难以兼顾多任务应用需求，因此需要专注于俄语、高效且适用多任务的新方法。

Method: 提出三阶段训练流程：首先在大规模网络语料上进行对比预训练，其次利用困难负样本微调，最后在检索、分类、聚类等多任务中进行泛化訓练，并利用合成数据增强多样性。模型结构上采用通过层次化指令微调的解码器模型GigaChat-3B，并引入双向注意力、潜在注意力池化、删减25% transformer层以提升效率。

Result: 在ruMTEB多语种任务基准（共23个任务）上，GigaEmbeddings取得69.1的平均得分，超越了参数量更大的强基线模型，达到了最新最好水平。

Conclusion: GigaEmbeddings显著提升了俄语文本嵌入的表现，证明结构创新与多阶段训练策略有效，可为高效多语种应用提供新范式。

Abstract: We introduce GigaEmbeddings, a novel framework for training high-performance
Russian-focused text embeddings through hierarchical instruction tuning of the
decoder-only LLM designed specifically for Russian language (GigaChat-3B). Our
three-stage pipeline, comprising large-scale contrastive pre-training in
web-scale corpora, fine-tuning with hard negatives, and multitask
generalization across retrieval, classification, and clustering tasks,
addresses key limitations of existing methods by unifying diverse objectives
and leveraging synthetic data generation. Architectural innovations include
bidirectional attention for contextual modeling, latent attention pooling for
robust sequence aggregation, and strategic pruning of 25% of transformer layers
to enhance efficiency without compromising performance. Evaluated on the ruMTEB
benchmark spanning 23 multilingual tasks, GigaEmbeddings achieves
state-of-the-art results (69.1 avg. score), outperforming strong baselines with
a larger number of parameters.

</details>


### [246] [VisJudge-Bench: Aesthetics and Quality Assessment of Visualizations](https://arxiv.org/abs/2510.22373)
*Yupeng Xie,Zhiyang Zhang,Yifan Wu,Sirong Lu,Jiayi Zhang,Zhaoyang Yu,Jinlin Wang,Sirui Hong,Bang Liu,Chenglin Wu,Yuyu Luo*

Main category: cs.CL

TL;DR: 本文提出了VisJudge-Bench——首个针对多模态大型语言模型（MLLMs）在可视化美学与质量评估方面的基准数据集，并基于此提出了相应的新模型VisJudge，有效提升了模型在该任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 目前对数据可视化的评估需要兼顾数据编码准确性、信息表达能力和美学设计，但现有MLLMs主要针对自然图片评价，缺乏针对可视化评估的系统性基准，因此有必要建立新的评测体系和提升模型能力。

Method: 构建了包含3090个专家标注实例的VisJudge-Bench基准，涵盖32种图表类型，针对MLLM在单图、多图及仪表盘等不同可视化场景下的评估能力进行测试，并基于此提出了更适合该任务的VisJudge模型。

Result: 即便是最先进的MLLM（如GPT-5）在该基准上的表现与人类专家尚有差距（MAE=0.551，相关性=0.429）；VisJudge模型在该基准上的表现显著提升，MAE降至0.442，专家一致性提升至0.681。

Conclusion: VisJudge-Bench为MLLM在可视化评估领域的研究提供了首个系统性评测平台，VisJudge模型显著提高了机器对可视化美学与质量的评估能力，推动了相关研究进展。

Abstract: Visualization, a domain-specific yet widely used form of imagery, is an
effective way to turn complex datasets into intuitive insights, and its value
depends on whether data are faithfully represented, clearly communicated, and
aesthetically designed. However, evaluating visualization quality is
challenging: unlike natural images, it requires simultaneous judgment across
data encoding accuracy, information expressiveness, and visual aesthetics.
Although multimodal large language models (MLLMs) have shown promising
performance in aesthetic assessment of natural images, no systematic benchmark
exists for measuring their capabilities in evaluating visualizations. To
address this, we propose VisJudge-Bench, the first comprehensive benchmark for
evaluating MLLMs' performance in assessing visualization aesthetics and
quality. It contains 3,090 expert-annotated samples from real-world scenarios,
covering single visualizations, multiple visualizations, and dashboards across
32 chart types. Systematic testing on this benchmark reveals that even the most
advanced MLLMs (such as GPT-5) still exhibit significant gaps compared to human
experts in judgment, with a Mean Absolute Error (MAE) of 0.551 and a
correlation with human ratings of only 0.429. To address this issue, we propose
VisJudge, a model specifically designed for visualization aesthetics and
quality assessment. Experimental results demonstrate that VisJudge
significantly narrows the gap with human judgment, reducing the MAE to 0.442 (a
19.8% reduction) and increasing the consistency with human experts to 0.681 (a
58.7% improvement) compared to GPT-5. The benchmark is available at
https://github.com/HKUSTDial/VisJudgeBench.

</details>


### [247] [Confabulations from ACL Publications (CAP): A Dataset for Scientific Hallucination Detection](https://arxiv.org/abs/2510.22395)
*Federica Gamba,Aman Sinha,Timothee Mickus,Raul Vazquez,Patanjali Bhamidipati,Claudio Savelli,Ahana Chattopadhyay,Laura A. Zanella,Yash Kankanampati,Binesh Arakkal Remesh,Aryan Ashok Chandramania,Rohit Agarwal,Chuyuan Li,Ioana Buhnila,Radhika Mamidi*

Main category: cs.CL

TL;DR: 本论文介绍了CAP数据集，这是针对大语言模型（LLM）在科学文本生成中出现幻觉（捏造事实）现象的多语言研究资源。CAP覆盖9种语言，包含科学问题与LLM生成回答，并对其事实性和流畅性进行了标签注释，旨在推动该领域的研究。


<details>
  <summary>Details</summary>
Motivation: 科学文本自动生成中，LLM频繁产生日志性错误（幻觉问题），这些幻觉在有专业术语和推理的科学场景更为突出。目前缺乏标准化、多语言的数据资源用于系统地研究和检测这类幻觉，因此亟需一种新数据集支持领域发展。

Method: 作者构建了CAP数据集，覆盖5种高资源和4种低资源语言。数据集包含900道科学问题、16个主流LLM的7000多条生成回答及其token/logits信息。所有问答都由人工标注幻觉（二值，是否事实错误）和流畅性标签。

Result: 作者成功创建并公开发布了包括多语种、标注详尽的科学幻觉数据集，为LLM幻觉检测与评测提供了重要研究基础。

Conclusion: CAP数据集为多语言环境下LLM幻觉检测与更可靠科学文本生成研究提供了支持，有助于推动相关多语种NLP系统的进步。

Abstract: We introduce the CAP (Confabulations from ACL Publications) dataset, a
multilingual resource for studying hallucinations in large language models
(LLMs) within scientific text generation. CAP focuses on the scientific domain,
where hallucinations can distort factual knowledge, as they frequently do. In
this domain, however, the presence of specialized terminology, statistical
reasoning, and context-dependent interpretations further exacerbates these
distortions, particularly given LLMs' lack of true comprehension, limited
contextual understanding, and bias toward surface-level generalization. CAP
operates in a cross-lingual setting covering five high-resource languages
(English, French, Hindi, Italian, and Spanish) and four low-resource languages
(Bengali, Gujarati, Malayalam, and Telugu). The dataset comprises 900 curated
scientific questions and over 7000 LLM-generated answers from 16 publicly
available models, provided as question-answer pairs along with token sequences
and corresponding logits. Each instance is annotated with a binary label
indicating the presence of a scientific hallucination, denoted as a factuality
error, and a fluency label, capturing issues in the linguistic quality or
naturalness of the text. CAP is publicly released to facilitate advanced
research on hallucination detection, multilingual evaluation of LLMs, and the
development of more reliable scientific NLP systems.

</details>


### [248] [CHOIR: Collaborative Harmonization fOr Inference Robustness](https://arxiv.org/abs/2510.22475)
*Xiangjue Dong,Cong Wang,Maria Teleki,Millennium Bismay,James Caverlee*

Main category: cs.CL

TL;DR: 本文提出了一种新方法CHOIR，将大语言模型在不同人设下的推理结果协同融合，提高了模型的推理稳健性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型赋予不同人物设定后，细微的人设变动（如改变代词）会导致推理结果显著不同。这种多样性通常被视为偏差，但也可能是提升模型鲁棒性的机遇。

Method: 提出CHOIR方法，在推理阶段结合多个人设下的推理信号，通过协作解码，动态权衡一致性与多样性，将这些推理结果统一。该方法无需额外训练，只在测试阶段融合推理。

Result: 在多种推理基准测试中，CHOIR在不同族群、模型结构、规模和任务上均有显著提升。个别族群性能提升最高达26.4%，五类族群平均提升19.2%。即使基础人物设定不佳时，方法依然有效。

Conclusion: 将人设变化视为有益信息而非消极偏差，通过CHOIR，能以更可扩展及通用的方式提升模型推理的可靠性。

Abstract: Persona-assigned Large Language Models (LLMs) can adopt diverse roles,
enabling personalized and context-aware reasoning. However, even minor
demographic perturbations in personas, such as simple pronoun changes, can
alter reasoning trajectories, leading to divergent sets of correct answers.
Instead of treating these variations as biases to be mitigated, we explore
their potential as a constructive resource to improve reasoning robustness. We
propose CHOIR (Collaborative Harmonization fOr Inference Robustness), a
test-time framework that harmonizes multiple persona-conditioned reasoning
signals into a unified prediction. CHOIR orchestrates a collaborative decoding
process among counterfactual personas, dynamically balancing agreement and
divergence in their reasoning paths. Experiments on various reasoning
benchmarks demonstrate that CHOIR consistently enhances performance across
demographics, model architectures, scales, and tasks - without additional
training. Improvements reach up to 26.4% for individual demographic groups and
19.2% on average across five demographics. It remains effective even when base
personas are suboptimal. By reframing persona variation as a constructive
signal, CHOIR provides a scalable and generalizable approach to more reliable
LLM reasoning.

</details>


### [249] [The Tonogenesis Continuum in Tibetan: A Computational Investigation](https://arxiv.org/abs/2510.22485)
*Siyu Liang,Zhaxi Zerong*

Main category: cs.CL

TL;DR: 本文提出了一种利用自动语音识别（ASR）系统新颖地研究声调发生（tonogenesis）的计算方法，可量化语音变化不同阶段中音高的功能作用。


<details>
  <summary>Details</summary>
Motivation: 声调发生的传统研究方法主要依赖比较语言学和声学，但难以精准量化音高在各阶段的功能变化。作者希望用新的计算方法更加细致地刻画音高功能负载随语音演化的转变。

Method: 通过在藏语相关方言上系统地进行音高扁平化（pitch-flattening）实验，测量其对ASR识别性能的影响，来反推出方言对音高的敏感度与依赖度。再比较无声调、全声调及中间状态的三种方言，分析其在声调发生连续体上的表现。

Result: 发现阿姆多方言（无声调）对音高去除最不敏感，卫藏方言（有声调）最敏感，康方言（中间状态）介于两者之间，揭示出一个渐变的声调发生连续体。

Conclusion: ASR模型可以捕捉声调发生中音高功能负载的微妙变化，传统基于最小对立对的功能负载指标可能高估了音高在过渡方言中的作用，因此计算方法能更细致、客观地追踪语音演化的不同阶段。

Abstract: Tonogenesis-the historical process by which segmental contrasts evolve into
lexical tone-has traditionally been studied through comparative reconstruction
and acoustic phonetics. We introduce a computational approach that quantifies
the functional role of pitch at different stages of this sound change by
measuring how pitch manipulation affects automatic speech recognition (ASR)
performance. Through analysis on the sensitivity to pitch-flattening from a set
of closely related Tibetan languages, we find evidence of a tonogenesis
continuum: atonal Amdo dialects tolerate pitch removal the most, while fully
tonal U-Tsang varieties show severe degradation, and intermediate Kham dialects
fall measurably between these extremes. These gradient effects demonstrate how
ASR models implicitly learn the shifting functional load of pitch as languages
transition from consonant-based to tone-based lexical contrasts. Our findings
show that computational methods can capture fine-grained stages of sound change
and suggest that traditional functional load metrics, based solely on minimal
pairs, may overestimate pitch dependence in transitional systems where
segmental and suprasegmental cues remain phonetically intertwined.

</details>


### [250] [Frustratingly Easy Task-aware Pruning for Large Language Models](https://arxiv.org/abs/2510.22489)
*Yuanhe Tian,Junjie Liu,Xican Yang,Haishan Ye,Yan Song*

Main category: cs.CL

TL;DR: 本文提出了一种针对大语言模型（LLM）的剪枝方法，能够在压缩模型参数空间的同时，有效保留特定任务的能力。该方法融合通用和任务特定校准数据，优化剪枝效果，且兼容现有多种剪枝技术。在主流基准测试上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有LLM剪枝方法多关注于维持模型流畅文本生成能力，却忽视了模型在特定领域与任务上的表现。实际应用中，往往需要在降低资源消耗的同时，保留模型在某些任务上的专业能力。

Method: 作者分析了传统剪枝算法主要基于通用校准数据最小化损失扰动的机制，并提出结合任务特定特征分布，分别计算通用与任务数据下的参数重要性分数，将参数分为共享与独占组，并融合这些分数指导剪枝。该方案与多种现有剪枝技术兼容。

Result: 在常用基准任务上验证，提出的方法在相同剪枝率和不同设置下均显著优于对比基线，能更好地保留任务特定能力。

Conclusion: 本文方法在保证LLM模型压缩效果的同时，有效提升了其任务特定能力保留水平，为LLM高效部署提供了新的思路。

Abstract: Pruning provides a practical solution to reduce the resources required to run
large language models (LLMs) to benefit from their effective capabilities as
well as control their cost for training and inference. Research on LLM pruning
often ranks the importance of LLM parameters using their magnitudes and
calibration-data activations and removes (or masks) the less important ones,
accordingly reducing LLMs' size. However, these approaches primarily focus on
preserving the LLM's ability to generate fluent sentences, while neglecting
performance on specific domains and tasks. In this paper, we propose a simple
yet effective pruning approach for LLMs that preserves task-specific
capabilities while shrinking their parameter space. We first analyze how
conventional pruning minimizes loss perturbation under general-domain
calibration and extend this formulation by incorporating task-specific feature
distributions into the importance computation of existing pruning algorithms.
Thus, our framework computes separate importance scores using both general and
task-specific calibration data, partitions parameters into shared and exclusive
groups based on activation-norm differences, and then fuses their scores to
guide the pruning process. This design enables our method to integrate
seamlessly with various foundation pruning techniques and preserve the LLM's
specialized abilities under compression. Experiments on widely used benchmarks
demonstrate that our approach is effective and consistently outperforms the
baselines with identical pruning ratios and different settings.

</details>


### [251] [The Limits of Data Scaling: Sub-token Utilization and Acoustic Saturation in Multilingual ASR](https://arxiv.org/abs/2510.22492)
*Siyu Liang,Nicolas Ballier,Gina-Anne Levow,Richard Wright*

Main category: cs.CL

TL;DR: 本论文通过分析Whisper模型在49种语言下的解码行为，探究了多语种ASR模型在实际推理中各语种的子词利用情况及其与训练数据量的关系。发现数据量差异并未显著影响模型的词汇多样性，子词发现过程呈现自动饱和特性，且更受语言和脚本本身的影响。


<details>
  <summary>Details</summary>
Motivation: 理解多语种ASR模型（如Whisper）在推理阶段，是否由于训练数据量差异导致个别语言词汇利用度受限，从而影响模型的公平性和覆盖能力。

Method: 分析Whisper模型在49种语言下的子词解码日志，跟踪子词的累计发现情况；比较不同脚本、不同训练数据量下子词激活率、词频分布和子词长度等指标。提出“声学饱和时间”AST指标，并用Zipf-Mandelbrot分布建模词频分布。

Result: 发现各语言新子词发现速率迅速饱和，饱和点（AST）后新子词极少激活，AST与训练数据小时数独立。子词长度与语种资源量正相关，拉丁字母语言的子词分布更理想，非拉丁文字种如CJK、塞姆语等表现不佳。词频分布符合Zipf-Mandelbrot分布规律。

Conclusion: 多语种ASR模型在解码阶段的子词利用更受到语言类型、脚本及其统计属性影响，而训练数据规模影响较小。这为未来多语种语音识别更公平的数据构建及模型评估提供了实证参考。

Abstract: How much audio is needed to fully observe a multilingual ASR model's learned
sub-token inventory across languages, and does data disparity in multilingual
pre-training affect how these tokens are utilized during inference? We address
this question by analyzing Whisper's decoding behavior during inference across
49 languages. By logging decoding candidate sub-tokens and tracking their
cumulative discovery over time, we study the utilization pattern of the model's
sub-token space. Results show that the total number of discovered tokens
remains largely independent of a language's pre-training hours, indicating that
data disparity does not strongly influence lexical diversity in the model's
hypothesis space. Sub-token discovery rates follow a consistent exponential
saturation pattern across languages, suggesting a stable time window after
which additional audio yields minimal new sub-token activation. We refer to
this convergence threshold as acoustic saturation time (AST). Further analyses
of rank-frequency distributions reveal Zipf-like patterns better modeled by a
Zipf-Mandelbrot law, and mean sub-token length shows a positive correlation
with resource level. Additionally, those metrics show more favorable patterns
for languages in the Latin script than those in scripts such as Cyrillic, CJK,
and Semitic. Together, our study suggests that sub-token utilization during
multilingual ASR inference is constrained more by the statistical, typological,
and orthographic structure of the speech than by training data scale, providing
an empirical basis for more equitable corpus construction and cross-lingual
evaluation.

</details>


### [252] [A Sociophonetic Analysis of Racial Bias in Commercial ASR Systems Using the Pacific Northwest English Corpus](https://arxiv.org/abs/2510.22495)
*Michael Scott,Siyu Liang,Alicia Wassink,Gina-Anne Levow*

Main category: cs.CL

TL;DR: 本文系统评估了四大商用语音识别系统在不同种族群体间的种族偏见，发现语音变化是偏差的主要来源，尤其对非裔美国人影响显著。


<details>
  <summary>Details</summary>
Motivation: 随着语音识别系统广泛应用，社会关注其是否对不同种族群体存在性能偏差。已有研究表明，方言和社会语言特征可能导致识别不公，但缺乏对具体语音学差异影响的系统评估。

Method: 作者利用Pacific Northwest English (PNWE)语料库，涵盖四种族裔（非裔、白人、ChicanX、Yakama）发言者，对四大商用ASR系统进行分析。提出以语音注释为基础的Phonetic Error Rate (PER)新指标，并对11项社会音系特征做识别误差分析。

Result: 结果显示，元音质量的变化（如低背合并、鼻化合并等抗性）与各族裔识别错误相关性强，且非裔美国人受影响最大。此外，发现音系建模是当前ASR偏见主要原因。

Conclusion: 认为应在ASR训练中加强社交语言多样性特征的建模，并将PNWE语料库作为评测偏见的有力资源，为提升系统公平性提供切实建议。

Abstract: This paper presents a systematic evaluation of racial bias in four major
commercial automatic speech recognition (ASR) systems using the Pacific
Northwest English (PNWE) corpus. We analyze transcription accuracy across
speakers from four ethnic backgrounds (African American, Caucasian American,
ChicanX, and Yakama) and examine how sociophonetic variation contributes to
differential system performance. We introduce a heuristically-determined
Phonetic Error Rate (PER) metric that links recognition errors to specific
linguistically motivated variables derived from sociophonetic annotation. Our
analysis of eleven sociophonetic features reveals that vowel quality variation,
particularly resistance to the low-back merger and pre-nasal merger patterns,
is systematically associated with differential error rates across ethnic
groups, with the most pronounced effects for African American speakers across
all evaluated systems. These findings demonstrate that acoustic modeling of
dialectal phonetic variation, rather than lexical or syntactic factors, remains
a primary source of bias in commercial ASR systems. The study establishes the
PNWE corpus as a valuable resource for bias evaluation in speech technologies
and provides actionable guidance for improving ASR performance through targeted
representation of sociophonetic diversity in training data.

</details>


### [253] [Text to Trust: Evaluating Fine-Tuning and LoRA Trade-offs in Language Models for Unfair Terms of Service Detection](https://arxiv.org/abs/2510.22531)
*Noshitha Padma Pratyusha Juttu,Sahithi Singireddy,Sravani Gona,Sujal Timilsina*

Main category: cs.CL

TL;DR: 这篇论文系统性地评估了在法律领域（服务条款中的不公平条款检测）应用全量微调、参数高效适配（如LoRA、QLoRA）以及零样本提示等大模型适配方法，并提供了实验证据和设计权衡分析。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）在法律等特殊领域的适应性受制于高昂的全量微调成本，因此亟需探索更高效且可行的模型适配方式，特别是在不公平条款检测等实际法律应用场景。

Method: 论文对BERT和DistilBERT进行了全量微调，对TinyLlama、LLaMA 3B/7B和SaulLM等模型采用4-bit参数高效适配（LoRA），并在GPT-4o及其衍生版本上测试了零样本提示方法。实验基于CLAUDETTE-ToS基准和多语言爬虫语料库，对各种方法进行了衡量和对比。

Result: 结果显示，全量微调在精准率与召回率之间取得最佳平衡；而基于LoRA的参数高效方法虽然略有性能下降，却能在内存消耗上降低至三分之一，并在召回率上达到有竞争力的水平。

Conclusion: 论文指出了用于法律领域高效适配大模型的设计权衡，为法律文本处理提供了公开的微调基线，便于今后相关领域的研究。

Abstract: Large Language Models (LLMs) have transformed text understanding, yet their
adaptation to specialized legal domains remains constrained by the cost of full
fine-tuning. This study provides a systematic evaluation of fine tuning,
parameter efficient adaptation (LoRA, QLoRA), and zero-shot prompting
strategies for unfair clause detection in Terms of Service (ToS) documents, a
key application in legal NLP. We finetune BERT and DistilBERT, apply 4-bit
Low-Rank Adaptation (LoRA) to models such as TinyLlama, LLaMA 3B/7B, and
SaulLM, and evaluate GPT-4o and O-versions in zero-shot settings. Experiments
on the CLAUDETTE-ToS benchmark and the Multilingual Scraper Corpus show that
full fine-tuning achieves the strongest precision recall balance, while
LoRA-based models provide competitive recall with up to 3x lower memory cost.
These findings highlight practical design trade-offs for efficient and
domain-adapted LLMs, contributing open baselines for fine-tuning research in
legal text processing.

</details>


### [254] [LooGLE v2: Are LLMs Ready for Real World Long Dependency Challenges?](https://arxiv.org/abs/2510.22548)
*Ziyuan He,Yuxuan Wang,Jiaqi Li,Kexin Liang,Muhan Zhang*

Main category: cs.CL

TL;DR: 本文针对大语言模型（LLMs）在长文本理解方面的能力进行了探讨，并提出了LooGLE v2新基准，评测模型应对现实长上下文任务的表现。结果显示现有模型在长依赖理解上仍有较大提升空间。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型尽管上下文窗口不断扩展，但在应对需要长距离依赖的真实任务中表现尚未充分探索和验证。实际应用中存在大量此类长文本场景，然而缺乏系统性评估工具。

Method: 作者提出LooGLE v2基准，包括法律、金融、游戏、代码等多领域，自动采集16k至200万tokens的长文本，设计10类领域长依赖任务，生成1934个高多样性的QA实例，并对6个本地和4个API大模型系统地评测。

Result: 所有模型在该基准上的表现普遍有限，最高分模型整体得分仅为59.2%。大部分主流LLM实际可理解的上下文长度远低于理论窗口长度，对长依赖任务处理能力有限。

Conclusion: 当前主流LLM对超长上下文的理解能力远未达到理想值，距离满足实际复杂长依赖任务需求仍有巨大提升空间，亟需针对性优化模型以适应现实应用场景。

Abstract: Large language models (LLMs) are equipped with increasingly extended context
windows recently, yet their long context understanding capabilities over long
dependency tasks remain fundamentally limited and underexplored. This gap is
especially significant in many real-world long-context applications that were
rarely benchmarked. In this paper, we introduce LooGLE v2, a novel benchmark
designed to evaluate LLMs' long context ability in real-world applications and
scenarios. Our benchmark consists of automatically collected real-world long
texts, ranging from 16k to 2M tokens, encompassing domains in law, finance,
game and code. Accordingly, we delicately design 10 types of domain-specific
long-dependency tasks and generate 1,934 QA instances with various diversity
and complexity in a scalable data curation pipeline for further practical
needs. We conduct a comprehensive assessment of 6 locally deployed and 4
API-based LLMs. The evaluation results show that even the best-performing model
achieves only a 59.2% overall score on our benchmark. Despite the extensive
context windows, popular LLMs are only capable of understanding a much shorter
length of context than they claim to be, revealing significant limitations in
their ability to handle real-world tasks with long dependencies and
highlighting substantial room for model improvement in practical long-context
understanding.

</details>


### [255] [SABlock: Semantic-Aware KV Cache Eviction with Adaptive Compression Block Size](https://arxiv.org/abs/2510.22556)
*Jinhan Chen,Jianchun Liu,Hongli Xu,Xianjun Gao,Shilong Wang*

Main category: cs.CL

TL;DR: 现有的大型语言模型（LLM）推理中，KV缓存占用的内存过高影响可扩展性。SABlock提出了一种语义感知、自适应块大小的KV缓存淘汰框架，有效在减少内存的同时保持语义完整性，性能大幅优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 长期上下文的LLM推理对KV缓存的内存需求很高，成为系统扩展时的瓶颈。虽然已有的缓存压缩方法可以压缩内存，但在保持语义完整性和提升效率之间难以兼顾。

Method: SABlock采用了三步流程：1）对输入内容做语义分段，使压缩边界与语言结构对齐；2）通过分段引导的token打分优化token重要性评估；3）在每个语义分段中依据内存预算自适应确定最优块大小，实现更高效的压缩，同时保持语义的一致性。

Result: 在多个长上下文基准测试上，SABlock在相同内存预算下始终优于现有方法。例如，在NIAH测试中，仅用96个KV条目即可达到99.9%检索准确率，几乎媲美8K全缓存基线。在1024缓存预算下，SABlock将峰值内存减少46.28%，在128K上下文情况解码提速9.5倍。

Conclusion: SABlock有效缓解了长上下文LLM推理中的缓存内存压力，在保持模型性能的前提下，大幅提升内存利用率和推理速度。

Abstract: The growing memory footprint of the Key-Value (KV) cache poses a severe
scalability bottleneck for long-context Large Language Model (LLM) inference.
While KV cache eviction has emerged as an effective solution by discarding less
critical tokens, existing token-, block-, and sentence-level compression
methods struggle to balance semantic coherence and memory efficiency. To this
end, we introduce SABlock, a \underline{s}emantic-aware KV cache eviction
framework with \underline{a}daptive \underline{block} sizes. Specifically,
SABlock first performs semantic segmentation to align compression boundaries
with linguistic structures, then applies segment-guided token scoring to refine
token importance estimation. Finally, for each segment, a budget-driven search
strategy adaptively determines the optimal block size that preserves semantic
integrity while improving compression efficiency under a given cache budget.
Extensive experiments on long-context benchmarks demonstrate that SABlock
consistently outperforms state-of-the-art baselines under the same memory
budgets. For instance, on Needle-in-a-Haystack (NIAH), SABlock achieves 99.9%
retrieval accuracy with only 96 KV entries, nearly matching the performance of
the full-cache baseline that retains up to 8K entries. Under a fixed cache
budget of 1,024, SABlock further reduces peak memory usage by 46.28% and
achieves up to 9.5x faster decoding on a 128K context length.

</details>


### [256] [A Closed-Loop Personalized Learning Agent Integrating Neural Cognitive Diagnosis, Bounded-Ability Adaptive Testing, and LLM-Driven Feedback](https://arxiv.org/abs/2510.22559)
*Zhifeng Wang,Xinyue Zheng,Chunyan Zeng*

Main category: cs.CL

TL;DR: 本论文提出了EduLoop-Agent，一个集成神经认知诊断（NCD）、有界能力估计自适应测验（BECAT）以及大语言模型（LLM）的端到端个性化学习代理，实现了诊断-推荐-反馈的闭环系统，有效提升了个性化教育的针对性和指导性。


<details>
  <summary>Details</summary>
Motivation: 现有个性化学习方法通常将建模、题目选择和反馈分开处理，导致学生模型粗糙、适应性调取受限于假设、反馈泛泛不可操作。因此，需构建一个集成化且闭环的个性化学习系统以提升学习效率和反馈质量。

Method: 结合NCD进行细粒度知识点掌握诊断，BECAT动态选择题目以最大化相关性和效率，并利用LLM把诊断结果转化为结构化、可操作的学习建议，三者协同构成诊断-推荐-反馈闭环。

Result: 在ASSISTments数据集上，NCD实现了优秀的答题预测性能及可解释的掌握度评估；自适应推荐提升了题目相关性和个性化水平；LLM生成了针对性极强的学习引导。整体表现证明该系统高效且具备实际部署价值。

Conclusion: EduLoop-Agent为智能教育中的个性化学习轨迹生成提供了一条切实可行的路径，闭环系统显著提升了学习针对性、反馈有效性及系统实用性，助力智能教育落地应用。

Abstract: As information technology advances, education is moving from
one-size-fits-all instruction toward personalized learning. However, most
methods handle modeling, item selection, and feedback in isolation rather than
as a closed loop. This leads to coarse or opaque student models,
assumption-bound adaptivity that ignores diagnostic posteriors, and generic,
non-actionable feedback. To address these limitations, this paper presents an
end-to-end personalized learning agent, EduLoop-Agent, which integrates a
Neural Cognitive Diagnosis model (NCD), a Bounded-Ability Estimation
Computerized Adaptive Testing strategy (BECAT), and large language models
(LLMs). The NCD module provides fine-grained estimates of students' mastery at
the knowledge-point level; BECAT dynamically selects subsequent items to
maximize relevance and learning efficiency; and LLMs convert diagnostic signals
into structured, actionable feedback. Together, these components form a
closed-loop framework of ``Diagnosis--Recommendation--Feedback.'' Experiments
on the ASSISTments dataset show that the NCD module achieves strong performance
on response prediction while yielding interpretable mastery assessments. The
adaptive recommendation strategy improves item relevance and personalization,
and the LLM-based feedback offers targeted study guidance aligned with
identified weaknesses. Overall, the results indicate that the proposed design
is effective and practically deployable, providing a feasible pathway to
generating individualized learning trajectories in intelligent education.

</details>


### [257] [Pedagogy-driven Evaluation of Generative AI-powered Intelligent Tutoring Systems](https://arxiv.org/abs/2510.22581)
*Kaushal Kumar Maurya,Ekaterina Kochmar*

Main category: cs.CL

TL;DR: 该论文关注于当前AI赋能的智能教学系统（ITSs）缺乏统一、科学评估框架的问题，梳理评价实践并提出未来改进方向。


<details>
  <summary>Details</summary>
Motivation: 生成式AI推动了大语言模型驱动的ITSs发展，但由于缺乏可靠、通用且以教学为核心的评估标准，这些系统的效果和影响难以追踪和衡量。

Method: 作者系统性回顾了当前主流ITS评估实践，总结实际案例中遇到的挑战，并结合AIED领域的跨学科研究提出未来研究方向。

Result: 发现现有ITS评估大多依赖主观协议和非标准基准，导致评估结果不一致、泛化性弱。基于这些问题，作者提出了三条以学习科学为基础的实际研究路径，用于建立公正、统一、大规模可用的ITS评估方法论。

Conclusion: 当前ITS评估标准的缺失严重阻碍了其效果与影响的科学衡量，需发展以教育学理论为基础的新型评估框架，推动ITS领域健康发展。

Abstract: The interdisciplinary research domain of Artificial Intelligence in Education
(AIED) has a long history of developing Intelligent Tutoring Systems (ITSs) by
integrating insights from technological advancements, educational theories, and
cognitive psychology. The remarkable success of generative AI (GenAI) models
has accelerated the development of large language model (LLM)-powered ITSs,
which have potential to imitate human-like, pedagogically rich, and cognitively
demanding tutoring. However, the progress and impact of these systems remain
largely untraceable due to the absence of reliable, universally accepted, and
pedagogy-driven evaluation frameworks and benchmarks. Most existing educational
dialogue-based ITS evaluations rely on subjective protocols and
non-standardized benchmarks, leading to inconsistencies and limited
generalizability. In this work, we take a step back from mainstream ITS
development and provide comprehensive state-of-the-art evaluation practices,
highlighting associated challenges through real-world case studies from careful
and caring AIED research. Finally, building on insights from previous
interdisciplinary AIED research, we propose three practical, feasible, and
theoretically grounded research directions, rooted in learning science
principles and aimed at establishing fair, unified, and scalable evaluation
methodologies for ITSs.

</details>


### [258] [AutoBench: Automating LLM Evaluation through Reciprocal Peer Assessment](https://arxiv.org/abs/2510.22593)
*Dario Loi,Elena Maria Muià,Federico Siciliano,Giovanni Trappolini,Vincenzo Crisà,Peter Kruger,Fabrizio Silvestri*

Main category: cs.CL

TL;DR: AutoBench是一种用于评估大型语言模型（LLM）的自动化框架，采用对等互评方式，能持续、动态地生成新测试任务并评判模型表现。实验结果显示其评估结果和主流基准高度相关，且优于单一评委体系。


<details>
  <summary>Details</summary>
Motivation: 现有静态测评数据集容易被模型“记住”，评测适应性差且易受到污染。需有更动态、抗污染、能随模型演化的评测方式。

Method: 提出AutoBench，模型轮流担任生成题目者、答题者与评委。多模型作为评委，采用迭代加权机制增强稳定评委权重，通过集体裁决形成一致排名。系统可自动产生新任务，避免人工干预。

Result: AutoBench与MMLU-Pro及GPQA等主流基准测评相关性高（78%、63%），多裁判体系明显优于单裁判。评估更稳健且接近人类一致性。

Conclusion: AutoBench是一种可扩展、抗污染、适应语言模型持续发展的评测框架，优于传统静态基准。

Abstract: We present AutoBench, a fully automated and self-sustaining framework for
evaluating Large Language Models (LLMs) through reciprocal peer assessment.
This paper provides a rigorous scientific validation of the AutoBench
methodology, originally developed as an open-source project by eZecute S.R.L..
Unlike static benchmarks that suffer from test-set contamination and limited
adaptability, AutoBench dynamically generates novel evaluation tasks while
models alternately serve as question generators, contestants, and judges across
diverse domains. An iterative weighting mechanism amplifies the influence of
consistently reliable evaluators, aggregating peer judgments into
consensus-based rankings that reflect collective model agreement. Our
experiments demonstrate strong correlations with established benchmarks
including MMLU-Pro and GPQA (respectively 78\% and 63\%), validating this
peer-driven evaluation paradigm. The multi-judge design significantly
outperforms single-judge baselines, confirming that distributed evaluation
produces more robust and human-consistent assessments. AutoBench offers a
scalable, contamination-resistant alternative to static benchmarks for the
continuous evaluation of evolving language models.

</details>


### [259] [Personal Care Utility (PCU): Building the Health Infrastructure for Everyday Insight and Guidance](https://arxiv.org/abs/2510.22602)
*Mahyar Abbasian,Ramesh Jain*

Main category: cs.CL

TL;DR: 本文提出了个人健康公用系统（PCU），作为一个AI驱动的终身健康指导赛博系统，旨在个体与人群层面实现全天候的健康管理和帮助。


<details>
  <summary>Details</summary>
Motivation: 随着数字基础设施和生物医学创新的发展，目前的健康管理系统多为碎片化、被动和间断性服务，难以满足持续和个性化健康管理的需求。因此，亟需一种能够持续、主动、可靠地伴随个人的健康系统。

Method: PCU通过全球AI辅助的模式，结合多模态智能体、事件中心建模与情境推理，实现个性化健康信息、主动健康行为指导以及医疗事件后的持续康复与治疗响应解读。系统架构融合了个人感知、体验式计算和大规模分析。

Result: PCU可以实现为个体提供可信赖的健康信息、主动的健康导航和持续的医疗响应解释，有望带来更好的个人健康结果，也为公共卫生和科学研究提供新平台。

Conclusion: PCU代表了一种从被动、片段化医疗转向主动、持续、智能化健康管理的范式转变。虽然实现尚有诸多挑战，但其理念为未来个人与社会健康管理提供了新方向。

Abstract: Building on decades of success in digital infrastructure and biomedical
innovation, we propose the Personal Care Utility (PCU) - a cybernetic system
for lifelong health guidance. PCU is conceived as a global, AI-powered utility
that continuously orchestrates multimodal data, knowledge, and services to
assist individuals and populations alike. Drawing on multimodal agents,
event-centric modeling, and contextual inference, it offers three essential
capabilities: (1) trusted health information tailored to the individual, (2)
proactive health navigation and behavior guidance, and (3) ongoing
interpretation of recovery and treatment response after medical events. Unlike
conventional episodic care, PCU functions as an ambient, adaptive companion -
observing, interpreting, and guiding health in real time across daily life. By
integrating personal sensing, experiential computing, and population-level
analytics, PCU promises not only improved outcomes for individuals but also a
new substrate for public health and scientific discovery. We describe the
architecture, design principles, and implementation challenges of this emerging
paradigm.

</details>


### [260] [PerCoR: Evaluating Commonsense Reasoning in Persian via Multiple-Choice Sentence Completion](https://arxiv.org/abs/2510.22616)
*Morteza Alikhani,Mohammadtaha Bagherifard,Erfan Zinvandi,Mehran Sarmadi*

Main category: cs.CL

TL;DR: 本文提出了PerCoR，这是一套面向波斯语的大规模常识推理评测基准数据集，包括10.6万个多项选择句子补全题，并引入了创新的方法生成多样且具挑战性的选项。多个大型模型和人类测试表现展示了当前技术与数据集难度的差距。


<details>
  <summary>Details</summary>
Motivation: 现有主流的常识推理数据集多为英语，对波斯语等低资源语言的常识推理评测缺乏支持，阻碍了相关NLP研究与模型能力提升。旨在填补波斯语常识推理资源空白，并推动多语言语义理解能力的进步。

Method: 1. 构建数据集：通过创新型连词切分策略，从40余个波斯语新闻、文化等网站自动化生成多样且连贯的句子补全题。
2. 干扰项生成：提出无生成式对抗过滤算法DRESS-AF，从金标准答案中筛选最具迷惑性的选项，使模型更难辨别，从而提升任务难度。
3. 对主流闭源模型（如OpenAI、Claude）、开源模型及人类进行评测和对比。

Result: 人类评测得分为89%，OpenAI-o3最高为92.18%，Claude-Sonnet为91.17%，最强开源模型DeepSeek为82.51%，显示模型在该数据集上仍有较大发展空间；DRESS-AF方法可迁移至英文HellaSwag数据集，提升其难度同时不影响人类可解性。

Conclusion: PerCoR填补了波斯语常识推理数据集的空白，为波斯语及多语言常识推理研究和模型改进提供了重要资源。DRESS-AF创新性方法支持提升多语言推理任务难度，未来仍有较大提升空间。

Abstract: We introduced PerCoR (Persian Commonsense Reasoning), the first large-scale
Persian benchmark for commonsense reasoning. PerCoR contains 106K
multiple-choice sentence-completion problems drawn from more than forty news,
cultural, and other web sources. We introduce a novel conjunction-based
segmentation strategy to generate coherent sentence-completion pairs, enabling
broad topical and structural diversity. To create challenging distractors, we
propose DRESS-AF (Distractor Ranking via Embedding Similarity Scoring and
Adversarial Filtering), a generation-free adversarial filtering method that
selects distractors from the pool of gold continuations while maximising model
confusion. Human annotators score 89% on PerCoR, while OpenAI-o3 achieves the
highest performance at 92.18%, followed closely by Claude-Sonnet-3.7 (91.17%).
The strongest open-source model, DeepSeek-R1, reaches 82.51%, underscoring both
the dataset's difficulty and the remaining performance gap in Persian
commonsense reasoning. We further show that DRESS-AF transfers to the English
HellaSwag benchmark, increasing its difficulty without hurting human
solvability. The dataset is available at
https://huggingface.co/datasets/MCINext/PerCoR.

</details>


### [261] [Integrating Linguistics and AI: Morphological Analysis and Corpus development of Endangered Toto Language of West Bengal](https://arxiv.org/abs/2510.22629)
*Ambalika Guha,Sajal Saha,Debanjan Ballav,Soumi Mitra,Hritwick Chakraborty*

Main category: cs.CL

TL;DR: 本论文介绍了一种结合传统语言学与人工智能的新方法，以开发三语（Toto-孟加拉语-英语）学习应用，促进西孟加拉Toto濒危语言的数字化保护与传播。


<details>
  <summary>Details</summary>
Motivation: 全球许多濒危语言正在消失，因此需要通过数字化手段保存语言多样性。Toto语言的濒危状况促使研究人员开发新工具以促进其存续和传播。

Method: 通过田野调查收集Toto语言材料，建立三语词库，并对语料进行形态标注。随后训练小型语言模型（SLM）和基于Transformer的翻译引擎，同时开发标准化Unicode脚本及数字素养工具，提升应用的可用性。

Result: 成功构建了包含形态学信息的三语语料库，训练了初步的翻译引擎，并开发了对应的标准化脚本系统和辅助数字学习工具，提升了Toto语言的数字化传播能力。

Conclusion: 研究为濒危语言的复兴提供了可持续新模式，证明将传统语言学与AI技术结合能够推进社区主导的语言保护。多学科融合协作在语言振兴中非常有价值。

Abstract: Preserving linguistic diversity is necessary as every language offers a
distinct perspective on the world. There have been numerous global initiatives
to preserve endangered languages through documentation. This paper is a part of
a project which aims to develop a trilingual (Toto-Bangla-English) language
learning application to digitally archive and promote the endangered Toto
language of West Bengal, India. This application, designed for both native Toto
speakers and non-native learners, aims to revitalize the language by ensuring
accessibility and usability through Unicode script integration and a structured
language corpus. The research includes detailed linguistic documentation
collected via fieldwork, followed by the creation of a morpheme-tagged,
trilingual corpus used to train a Small Language Model (SLM) and a
Transformer-based translation engine. The analysis covers inflectional
morphology such as person-number-gender agreement, tense-aspect-mood
distinctions, and case marking, alongside derivational strategies that reflect
word-class changes. Script standardization and digital literacy tools were also
developed to enhance script usage. The study offers a sustainable model for
preserving endangered languages by incorporating traditional linguistic
methodology with AI. This bridge between linguistic research with technological
innovation highlights the value of interdisciplinary collaboration for
community-based language revitalization.

</details>


### [262] [Culturally Grounded Physical Commonsense Reasoning in Italian and English: A Submission to the MRL 2025 Shared Task](https://arxiv.org/abs/2510.22631)
*Marco De Santis,Lisa Alazraki*

Main category: cs.CL

TL;DR: 该论文介绍了FormaMentis，这是一个以意大利语言与文化为基础的物理常识推理基准数据集，作为MRL 2025多语种物理推理数据集共享任务的成果。


<details>
  <summary>Details</summary>
Motivation: 当前物理常识推理数据集主要以英文为主，缺乏对其他语言和本地文化的覆盖。多语种场景和本地文化常识对于提升模型泛化能力和适应不同地区非常重要。

Method: 由熟悉意大利本地习俗的母语专家人工标注物理常识推理样本，数据集格式类似PIQA，同时所有样本配有保留文化元素的英文翻译。

Result: 成功构建了基于意大利文化和语言的FormaMentis物理常识推理评测基准，涵盖多语言和文化特定元素。

Conclusion: FormaMentis填补了多语种物理常识推理领域意大利语的空白，可以推动本地化和多语言常识推理研究。

Abstract: This paper presents our submission to the MRL 2025 Shared Task on
Multilingual Physical Reasoning Datasets. The objective of the shared task is
to create manually-annotated evaluation data in the physical commonsense
reasoning domain, for languages other than English, following a format similar
to PIQA. Our contribution, FormaMentis, is a novel benchmark for physical
commonsense reasoning that is grounded in Italian language and culture. The
data samples in FormaMentis are created by expert annotators who are native
Italian speakers and are familiar with local customs and norms. The samples are
additionally translated into English, while preserving the cultural elements
unique to the Italian context.

</details>


### [263] [Conjugate Relation Modeling for Few-Shot Knowledge Graph Completion](https://arxiv.org/abs/2510.22656)
*Zilong Wang,Qingtian Zeng,Hua Duan,Cheng Cheng,Minghao Zou,Ziyang Wang*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的FKGC（少样本知识图谱补全）方法，能够更有效地捕捉复杂关系模式并缓解数据稀疏问题，并在多个基准数据集上取得了优于现有方法的表现。


<details>
  <summary>Details</summary>
Motivation: 当前FKGC方法面临的主要挑战在于难以捕捉复杂的关系模式以及有效应对数据的稀疏性和长尾分布问题。为提升模型对知识图谱中复杂语义关系与不确定性的建模能力，亟需提出新的方法。

Method: 作者提出了一套新的FKGC框架（CR-FKGC）：一是利用邻域聚合编码器集成高阶邻居信息；二是通过结合内隐条件扩散关系模块与稳定关系模块的共轭关系学习器，捕捉稳定语义和不确定性；三是提出流形共轭解码器，在流形空间内高效评估和推理缺失三元组。

Result: 在三个公开基准数据集上的实验结果显示，该方法在补全准确率等指标上明显优于最新的FKGC方法，充分验证了其有效性。

Conclusion: CR-FKGC能够更好地刻画复杂关系及处理数据稀疏问题，为FKGC研究提供了新的思路和工具，对知识图谱补全任务具有重要推进作用。

Abstract: Few-shot Knowledge Graph Completion (FKGC) infers missing triples from
limited support samples, tackling long-tail distribution challenges. Existing
methods, however, struggle to capture complex relational patterns and mitigate
data sparsity. To address these challenges, we propose a novel FKGC framework
for conjugate relation modeling (CR-FKGC). Specifically, it employs a
neighborhood aggregation encoder to integrate higher-order neighbor
information, a conjugate relation learner combining an implicit conditional
diffusion relation module with a stable relation module to capture stable
semantics and uncertainty offsets, and a manifold conjugate decoder for
efficient evaluation and inference of missing triples in manifold space.
Experiments on three benchmarks demonstrate that our method achieves superior
performance over state-of-the-art methods.

</details>


### [264] [Rule-Based Explanations for Retrieval-Augmented LLM Systems](https://arxiv.org/abs/2510.22689)
*Joel Rorseth,Parke Godfrey,Lukasz Golab,Divesh Srivastava,Jarek Szlichta*

Main category: cs.CL

TL;DR: 本文提出利用if-then规则解释RAG（Retrieval-augmented Generation）架构下的大型语言模型输出，并优化生成规则的方法。


<details>
  <summary>Details</summary>
Motivation: 目前if-then规则常用于解释机器学习模型，但针对融合检索信息的RAG大模型缺乏解释方法，因此研究如何用规则解释RAG输出的成因十分重要。

Method: 文章设计了一种生成规则的办法，对比朴素的穷举所有检索源组合以观测输出，作者借鉴频繁项集挖掘的Apriori剪枝思路进行优化，从而加快了规则生成的效率。

Result: 通过定性和定量实验，论文验证了提出方法的有效性与效率，能更好地解释RAG系统中的输出与检索源之间的关系。

Conclusion: 论文首次提出了用规则解释RAG大语言模型输出的框架，并提供了高效的规则生成方法，为该领域的解释性研究奠定了基础。

Abstract: If-then rules are widely used to explain machine learning models; e.g., "if
employed = no, then loan application = rejected." We present the first proposal
to apply rules to explain the emerging class of large language models (LLMs)
with retrieval-augmented generation (RAG). Since RAG enables LLM systems to
incorporate retrieved information sources at inference time, rules linking the
presence or absence of sources can explain output provenance; e.g., "if a Times
Higher Education ranking article is retrieved, then the LLM ranks Oxford
first." To generate such rules, a brute force approach would probe the LLM with
all source combinations and check if the presence or absence of any sources
leads to the same output. We propose optimizations to speed up rule generation,
inspired by Apriori-like pruning from frequent itemset mining but redefined
within the scope of our novel problem. We conclude with qualitative and
quantitative experiments demonstrating our solutions' value and efficiency.

</details>


### [265] [SALSA: Single-pass Autoregressive LLM Structured Classification](https://arxiv.org/abs/2510.22691)
*Ruslan Berdichevsky,Shai Nahum-Gefen,Elad Ben Zaken*

Main category: cs.CL

TL;DR: SALSA方法通过结构化提示、类别到token映射和高效微调，有效提升大型语言模型在文本分类任务的表现，并取得了多个基准任务的最佳成绩。


<details>
  <summary>Details</summary>
Motivation: 当前基于指令调优的大型语言模型虽然泛化能力强，但在文本分类场景下表现不佳，需要新的方法来提升其在该任务中的性能。

Method: 提出SALSA流水线方法，包括：将每个类别标签映射到独立的输出token，构造结构化的提示让模型输出单token答案，并在推理时只关注相关类别token的logits；此外结合高效参数微调，避免从零开始训练。

Result: SALSA方法在多个公开文本分类基准任务中取得了最先进的结果，展现出良好的鲁棒性和可扩展性。

Conclusion: SALSA为基于LLM的文本分类应用提供了高效、准确且鲁棒的新方案，有望作为未来大模型文本分类任务的主流方法。

Abstract: Despite their impressive generalization capabilities, instruction-tuned Large
Language Models often underperform on text classification benchmarks. We
introduce SALSA, a coherent pipeline that combines structured prompting,
class-to-token mapping, and parameter-efficient fine-tuning, thereby avoiding
cold-start training. Each class label is mapped to a distinct output token, and
prompts are constructed to elicit a single-token response. During inference,
the model's output is projected only onto the logits of the relevant class
tokens, enabling efficient and accurate classification in a single forward
pass. SALSA achieves state-of-the-art results across diverse benchmarks,
demonstrating its robustness and scalability for LLM-based classification
applications.

</details>


### [266] [$\text{E}^2\text{Rank}$: Your Text Embedding can Also be an Effective and Efficient Listwise Reranker](https://arxiv.org/abs/2510.22733)
*Qi Liu,Yanzhao Zhang,Mingxin Li,Dingkun Long,Pengjun Xie,Jiaxin Mao*

Main category: cs.CL

TL;DR: 本文提出了E²Rank框架，通过对基础文本嵌入模型进行listwise排序目标的训练，实现了高效的检索与排序一体化，兼具准确性和高效性。


<details>
  <summary>Details</summary>
Motivation: 现有文本嵌入模型虽能高效检索，但排名能力不及近年的LLM rerankers。希望提升嵌入模型在排序任务中的表现，同时保持其效率优势。

Method: 提出E²Rank框架，在基础嵌入模型上继续训练，使用cosine相似度作为统一的排序函数，并在listwise排名任务中引入由top-K文档构建的listwise prompt，类似于传统检索中的伪相关反馈（PRF）。这种方式既保留了嵌入模型的高效率，又提升了排序质量。

Result: E²Rank在BEIR rerank基准上取得了SOTA效果，在BRIGHT（推理高强度）基准上也表现优异，且重排延迟很低。同时在MTEB基准上嵌入性能明显提升。

Conclusion: 单一的嵌入模型经过本方法训练后，可高效同时实现检索与排序任务，在保证速度的同时，准确性达到或超过现有先进方法。

Abstract: Text embedding models serve as a fundamental component in real-world search
applications. By mapping queries and documents into a shared embedding space,
they deliver competitive retrieval performance with high efficiency. However,
their ranking fidelity remains limited compared to dedicated rerankers,
especially recent LLM-based listwise rerankers, which capture fine-grained
query-document and document-document interactions. In this paper, we propose a
simple yet effective unified framework $\text{E}^2\text{Rank}$, means Efficient
Embedding-based Ranking (also means Embedding-to-Rank), which extends a single
text embedding model to perform both high-quality retrieval and listwise
reranking through continued training under a listwise ranking objective,
thereby achieving strong effectiveness with remarkable efficiency. By applying
cosine similarity between the query and document embeddings as a unified
ranking function, the listwise ranking prompt, which is constructed from the
original query and its candidate documents, serves as an enhanced query
enriched with signals from the top-K documents, akin to pseudo-relevance
feedback (PRF) in traditional retrieval models. This design preserves the
efficiency and representational quality of the base embedding model while
significantly improving its reranking performance. Empirically,
$\textrm{E}^2\text{Rank}$ achieves state-of-the-art results on the BEIR
reranking benchmark and demonstrates competitive performance on the
reasoning-intensive BRIGHT benchmark, with very low reranking latency. We also
show that the ranking training process improves embedding performance on the
MTEB benchmark. Our findings indicate that a single embedding model can
effectively unify retrieval and reranking, offering both computational
efficiency and competitive ranking accuracy.

</details>


### [267] [Low-Resource Dialect Adaptation of Large Language Models: A French Dialect Case-Study](https://arxiv.org/abs/2510.22747)
*Eeham Khan,Firas Saidani,Owen Van Esbroeck,Richard Khoury,Leila Kosseim*

Main category: cs.CL

TL;DR: 本文利用低秩适配（LoRA）和计算高效的持续预训练（CPT），在极少数据和计算资源条件下，将三种大语言模型（LLMs）适配到魁北克法语方言，并发布了首个魁北克法语大语言模型。实验表明，在保持主流语言性能的同时，方言表现有明显提升。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在主要高资源语言上表现突出，但对小语种或地域方言支持有限。为了解决资源匮乏地区语言建模能力薄弱的问题，作者旨在探索如何在计算和数据严重受限的情况下，将LLMs有效迁移到低资源方言。

Method: 作者结合了持续预训练（CPT）和低秩适配（LoRA），在训练参数比例极小（不足1%）的条件下，对三种大语言模型进行微调，采用计算高效的方法将其适配到魁北克法语方言，并在COLE基准集上测试性能。

Result: 经过适配后的模型在方言任务上效果提升，同时在主流法语任务上回退很小（性能损失极小）。实验还发现，性能提升高度依赖于训练语料的构成。

Conclusion: 结合CPT与PEFT的方法能够以低成本、高可持续性的方式提升模型对小众方言的支持，有助于缩小语言资源差距，并扩大大语言模型在少数语言社区的应用。作者公开了魁北克法语LLMs，推动相关领域发展。

Abstract: Despite the widespread adoption of large language models (LLMs), their
strongest capabilities remain largely confined to a small number of
high-resource languages for which there is abundant training data. Recently,
continual pre-training (CPT) has emerged as a means to fine-tune these models
to low-resource regional dialects. In this paper, we study the use of CPT for
dialect learning under tight data and compute budgets. Using low-rank
adaptation (LoRA) and compute-efficient continual pre-training, we adapt three
LLMs to the Qu\'ebec French dialect using a very small dataset and benchmark
them on the COLE suite. Our experiments demonstrate an improvement on the
minority dialect benchmarks with minimal regression on the prestige language
benchmarks with under 1% of model parameters updated. Analysis of the results
demonstrate that gains are highly contingent on corpus composition. These
findings indicate that CPT with parameter-efficient fine-tuning (PEFT) can
narrow the dialect gap by providing cost-effective and sustainable language
resource creation, expanding high-quality LLM access to minority linguistic
communities. We release the first Qu\'ebec French LLMs on HuggingFace.

</details>


### [268] [Beyond Semantics: How Temporal Biases Shape Retrieval in Transformer and State-Space Models](https://arxiv.org/abs/2510.22752)
*Anooshka Bajaj,Deven Mahesh Mistry,Sahaj Singh Maini,Yash Aggarwal,Zoran Tiganj*

Main category: cs.CL

TL;DR: 本文研究了大语言模型（LLM）在上下文学习中对事件时间顺序的记忆和检索偏好，揭示了模型在时间上进行信息分离和回忆的方式。


<details>
  <summary>Details</summary>
Motivation: 人类在回忆事件时可以基于时间对不同事件进行区分。本文旨在考察各种预训练LLM（包括Transformer和状态空间模型）是否同样能区分并检索时间上分离的事件，从而深入理解其在上下文学习中的记忆机制。

Method: 作者设计了包含多次重复出现同一token的序列，并仅在序列结尾再次出现该token，同时打乱其他token的位置以排除语义干扰。通过这种设计，论文专注于考查模型在预测下一个token时的时间效应。此外，还对模型进行了消融实验以分析Transformer的归纳头（induction heads）作用，并扩展到语义上下文部分重叠的情况。

Result: 实验发现，无论模型架构如何，LLM在预测时倾向于选择较接近序列开头或结尾的重复token。同时，模型对处于序列中间的相关信息检索效果较差。消融实验显示，Transformer中的归纳头在该现象中起到关键作用。状态空间模型与Transformer模型展示了类似的时间偏置。

Conclusion: 研究加深了对LLM上下文学习中时间性偏置的理解，并展示了这种偏置如何帮助模型进行时间分离和类人“情节记忆”式的信息回忆。

Abstract: In-context learning is governed by both temporal and semantic relationships,
shaping how Large Language Models (LLMs) retrieve contextual information.
Analogous to human episodic memory, where the retrieval of specific events is
enabled by separating events that happened at different times, this work probes
the ability of various pretrained LLMs, including transformer and state-space
models, to differentiate and retrieve temporally separated events.
Specifically, we prompted models with sequences containing multiple
presentations of the same token, which reappears at the sequence end. By fixing
the positions of these repeated tokens and permuting all others, we removed
semantic confounds and isolated temporal effects on next-token prediction.
Across diverse sequences, models consistently placed the highest probabilities
on tokens following a repeated token, but with a notable bias for those nearest
the beginning or end of the input. An ablation experiment linked this
phenomenon in transformers to induction heads. Extending the analysis to unique
semantic contexts with partial overlap further demonstrated that memories
embedded in the middle of a prompt are retrieved less reliably. Despite
architectural differences, state-space and transformer models showed comparable
temporal biases. Our findings deepen the understanding of temporal biases in
in-context learning and offer an illustration of how these biases can enable
temporal separation and episodic retrieval.

</details>


### [269] [EchoMind: An Interrelated Multi-level Benchmark for Evaluating Empathetic Speech Language Models](https://arxiv.org/abs/2510.22758)
*Li Zhou,Lutong Yu,You Lyu,Yihang Lin,Zefeng Zhao,Junyi Ao,Yuhao Zhang,Benyou Wang,Haizhou Li*

Main category: cs.CL

TL;DR: EchoMind提出了一个评估语音语言模型（SLMs）共情能力的全新基准，考察模型在理解语音内容和感知语音非字面线索、推理和回应生成等多个层面的能力，并表明现有先进SLM在高表达性音色和共情反应生成方面仍存在明显不足。


<details>
  <summary>Details</summary>
Motivation: 尽管SLMs在理解口语语言方面取得进展，但它们是否能感知非字面语言信号（如情感、语调等）并作出与情感和语境相关的共情反应尚未明了。当前基准往往只隔离地评估模型个别能力，缺乏对这些能力融合表现的综合评估。因此，研究者有动力开发一种能整体考察模型共情对话能力的评测方法。

Method: 作者提出了EchoMind基准，通过模拟人类共情对话的认知过程，设立了四个连续、关联的测试任务：口语内容理解、语音信号感知、综合推理和回应生成。所有任务使用语义中性且无显式情感或情境线索的相同脚本，并通过控制语音风格变化测试语音递送对理解的影响。EchoMind基于3大类、12个细分类维度和39种语音属性，采用客观和主观指标评测模型表现。

Result: 对12个先进SLMs的测试显示，即使是最前沿的模型，在处理高表达性语音信号及产出共情反应方面依然表现不佳。此外，模型在指令遵循、应对真实语音变化和利用语音信号进行共情推理上都存在不足。

Conclusion: 研究强调发展能够融合文本内容与多元语音信号的SLM对于实现具有人类般共情对话能力的重要性，现有模型在共情推理与反应生成方面尚有很大提升空间。

Abstract: Speech Language Models (SLMs) have made significant progress in spoken
language understanding. Yet it remains unclear whether they can fully perceive
non lexical vocal cues alongside spoken words, and respond with empathy that
aligns with both emotional and contextual factors. Existing benchmarks
typically evaluate linguistic, acoustic, reasoning, or dialogue abilities in
isolation, overlooking the integration of these skills that is crucial for
human-like, emotionally intelligent conversation. We present EchoMind, the
first interrelated, multi-level benchmark that simulates the cognitive process
of empathetic dialogue through sequential, context-linked tasks: spoken-content
understanding, vocal-cue perception, integrated reasoning, and response
generation. All tasks share identical and semantically neutral scripts that are
free of explicit emotional or contextual cues, and controlled variations in
vocal style are used to test the effect of delivery independent of the
transcript. EchoMind is grounded in an empathy-oriented framework spanning 3
coarse and 12 fine-grained dimensions, encompassing 39 vocal attributes, and
evaluated using both objective and subjective metrics. Testing 12 advanced SLMs
reveals that even state-of-the-art models struggle with high-expressive vocal
cues, limiting empathetic response quality. Analyses of prompt strength, speech
source, and ideal vocal cue recognition reveal persistent weaknesses in
instruction-following, resilience to natural speech variability, and effective
use of vocal cues for empathy. These results underscore the need for SLMs that
integrate linguistic content with diverse vocal cues to achieve truly
empathetic conversational ability.

</details>


### [270] [Iterative Layer Pruning for Efficient Translation Inference](https://arxiv.org/abs/2510.22763)
*Yasmin Moslem,Muhammad Hazim Al Farouq,John D. Kelleher*

Main category: cs.CL

TL;DR: 本论文提出了一种基于层重要性分析的迭代式层剪枝方法，在大规模语言模型翻译任务中显著降低了模型规模和推理时间，同时保持了原有的翻译质量。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在机器翻译等自然语言处理任务中表现卓越，但其高昂的计算与部署成本成为实际应用的主要障碍。该论文旨在通过压缩模型，以提高其部署效率。

Method: 作者借助层重要性分析，提出了迭代去除不重要层的可行剪枝方案，并在WMT 2025赛事中，用Aya-Expanse-8B模型对捷克语到德语、英语到埃及阿拉伯语的翻译进行了实验评估。

Result: 采用所提的迭代层剪枝方法后，模型参数量和推理时间都大幅降低，但翻译质量基本不变。

Conclusion: 该方法兼顾了模型压缩与性能保持，为大语言模型在机器翻译等实际场景中的高效部署提供了有效手段。

Abstract: Large language models (LLMs) have transformed many areas of natural language
processing, including machine translation. However, efficient deployment of
LLMs remains challenging due to their intensive computational requirements. In
this paper, we address this challenge and present our submissions to the Model
Compression track at the Conference on Machine Translation (WMT 2025). In our
experiments, we investigate iterative layer pruning guided by layer importance
analysis. We evaluate this method using the Aya-Expanse-8B model for
translation from Czech to German, and from English to Egyptian Arabic. Our
approach achieves substantial reductions in model size and inference time,
while maintaining the translation quality of the baseline models.

</details>


### [271] [MMPersuade: A Dataset and Evaluation Framework for Multimodal Persuasion](https://arxiv.org/abs/2510.22768)
*Haoyi Qiu,Yilun Zhou,Pranav Narayanan Venkit,Kung-Hsiang Huang,Jiaxin Zhang,Nanyun Peng,Chien-Sheng Wu*

Main category: cs.CL

TL;DR: 本文聚焦于大型视觉语言模型（LVLMs）在面对多模态说服性内容时的易受影响性及不同说服策略的有效性。提出了MMPersuade框架，包含多模态数据集与评测体系，并实证分析不同LVLMs的说服易感性。结论为多模态输入显著提升说服力，指明了未来模型鲁棒性建设的方向。


<details>
  <summary>Details</summary>
Motivation: LVLMs在购物、健康、新闻等实际领域应用日益广泛，频繁遭遇包含图像、视频等多模态的说服性内容。理解模型为何被说服及如何被不同策略影响对模型安全性至关重要，避免其被误导导致不安全或不道德输出。

Method: 提出MMPersuade框架，构建包含图像和视频与经典说服原则对应的大规模多模态数据集，涵盖商业、主观行为、对抗三类场景。利用第三方判定评分及模型自估分数，系统评估LVLMs的说服效果与易感度。在六种主流LVLMs上进行实验对比。

Result: 多模态输入显著增强说服效果和模型易感性，尤其在虚假信息场景下效果更显著。声明偏好可减弱说服影响，但多模态信息依然占优。不同说服策略在不同情境下效果有差异：互惠在商业和主观场景最有效，可信度和逻辑在对抗场景更有影响力。

Conclusion: MMPersuade为评估和提升LVLMs在多模态说服下的稳健性、偏好一致性和伦理对齐提供了系统方法论，将有助于构建更安全、可靠的新一代多模态大模型。

Abstract: As Large Vision-Language Models (LVLMs) are increasingly deployed in domains
such as shopping, health, and news, they are exposed to pervasive persuasive
content. A critical question is how these models function as persuadees-how and
why they can be influenced by persuasive multimodal inputs. Understanding both
their susceptibility to persuasion and the effectiveness of different
persuasive strategies is crucial, as overly persuadable models may adopt
misleading beliefs, override user preferences, or generate unethical or unsafe
outputs when exposed to manipulative messages. We introduce MMPersuade, a
unified framework for systematically studying multimodal persuasion dynamics in
LVLMs. MMPersuade contributes (i) a comprehensive multimodal dataset that pairs
images and videos with established persuasion principles across commercial,
subjective and behavioral, and adversarial contexts, and (ii) an evaluation
framework that quantifies both persuasion effectiveness and model
susceptibility via third-party agreement scoring and self-estimated token
probabilities on conversation histories. Our study of six leading LVLMs as
persuadees yields three key insights: (i) multimodal inputs substantially
increase persuasion effectiveness-and model susceptibility-compared to text
alone, especially in misinformation scenarios; (ii) stated prior preferences
decrease susceptibility, yet multimodal information maintains its persuasive
advantage; and (iii) different strategies vary in effectiveness across
contexts, with reciprocity being most potent in commercial and subjective
contexts, and credibility and logic prevailing in adversarial contexts. By
jointly analyzing persuasion effectiveness and susceptibility, MMPersuade
provides a principled foundation for developing models that are robust,
preference-consistent, and ethically aligned when engaging with persuasive
multimodal content.

</details>


### [272] [Scalable Supervising Software Agents with Patch Reasoner](https://arxiv.org/abs/2510.22775)
*Junjielong Xu,Boyin Tan,Xiaoyuan Liu,Chao Peng,Pengfei Gao,Pinjia He*

Main category: cs.CL

TL;DR: 本文提出了R4P模型用于通过推理方式验证代码补丁，为大语言模型的软件工程代理（SWE agents）提供高效可扩展的奖励机制。R4P无需传统测试即可高效验证补丁，并在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前基于测试的监督方式存在构建繁琐、代价高、易受极端案例影响等问题，限制了为大模型提供大规模、高质量奖励信号的能力。亟需一种更高效、可扩展且稳健的奖励生成方法。

Method: 作者提出R4P模型，把补丁验证转化为一个推理任务，通过对多个补丁的组间关系设计奖励目标（group-wise objective），以减少奖励被'hack'的风险并获得更密集的奖励信号，支持强化学习训练。R4P能在不运行真实测试的情况下高效完成验证。

Result: R4P在SWE-bench-verified数据集上补丁验证准确率达72.2%，优于OpenAI o3。同时作者设计和训练了Mini-SE代理，全部奖励来自R4P，Pass@1达26.2%，较基线提升10个百分点，用R4P辅助推理进一步提升至32.8%。此外，R4P验证速度比测试快50倍。

Conclusion: R4P可为SWE大模型提供快速、可扩展、稳健的奖励信号，在效率、稳定性和准确率上都表现优秀，有望大幅提升软件工程自动化大模型的能力。

Abstract: While large language model agents have advanced software engineering tasks,
the unscalable nature of existing test-based supervision is limiting the
potential improvement of data scaling. The reason is twofold: (1) building and
running test sandbox is rather heavy and fragile, and (2) data with
high-coverage tests is naturally rare and threatened by test hacking via edge
cases. In this paper, we propose R4P, a patch verifier model to provide
scalable rewards for training and testing SWE agents via reasoning. We consider
that patch verification is fundamentally a reasoning task, mirroring how human
repository maintainers review patches without writing and running new
reproduction tests. To obtain sufficient reference and reduce the risk of
reward hacking, R4P uses a group-wise objective for RL training, enabling it to
verify multiple patches against each other's modification and gain a dense
reward for stable training. R4P achieves 72.2% Acc. for verifying patches from
SWE-bench-verified, surpassing OpenAI o3. To demonstrate R4P's practicality, we
design and train a lite scaffold, Mini-SE, with pure reinforcement learning
where all rewards are derived from R4P. As a result, Mini-SE achieves 26.2%
Pass@1 on SWE-bench-verified, showing a 10.0% improvement over the original
Qwen3-32B. This can be further improved to 32.8% with R4P for test-time
scaling. Furthermore, R4P verifies patches within a second, 50x faster than
testing on average. The stable scaling curves of rewards and accuracy along
with high efficiency reflect R4P's practicality.

</details>


### [273] [VEHME: A Vision-Language Model For Evaluating Handwritten Mathematics Expressions](https://arxiv.org/abs/2510.22798)
*Thu Phuong Nguyen,Duc M. Nguyen,Hyotaek Jeon,Hyunwook Lee,Hyunmin Song,Sungahn Ko,Taehwan Kim*

Main category: cs.CL

TL;DR: 本文提出VEHME，一种用于评估手写数学表达式的视觉-语言模型，在多项公开数据集上实现了领先的自动批改效果。


<details>
  <summary>Details</summary>
Motivation: 自动评估学生手写的数学解答一直是教育技术中的难题，因为学生书写存在多样化、不结构化与符号复杂的问题。目前，高效、准确且可解释的自动评估方法亟需发展。

Method: 提出VISME模型，采用两阶段训练：第一阶段通过有结构推理数据的监督微调，第二阶段通过强化学习，使输出同时对解答正确性、推理深度与错误定位等多维评价目标对齐。同时设计表达式感知视觉提示模块，增强模型对复杂版面和空间结构的理解。

Result: 在AIHub和FERMAT两个数据集上，VEHME在开源模型中表现最好，接近商用系统准确率。

Conclusion: VEHME作为开源自动手写数学批改工具，实现了优异的准确性和解释性，有望大规模应用于教育场景，并推动相关研究发展。

Abstract: Automatically assessing handwritten mathematical solutions is an important
problem in educational technology with practical applications, but it remains a
significant challenge due to the diverse formats, unstructured layouts, and
symbolic complexity of student work. To address this challenge, we introduce
VEHME-a Vision-Language Model for Evaluating Handwritten Mathematics
Expressions-designed to assess open-form handwritten math responses with high
accuracy and interpretable reasoning traces. VEHME integrates a two-phase
training pipeline: (i) supervised fine-tuning using structured reasoning data,
and (ii) reinforcement learning that aligns model outputs with
multi-dimensional grading objectives, including correctness, reasoning depth,
and error localization. To enhance spatial understanding, we propose an
Expression-Aware Visual Prompting Module, trained on our synthesized multi-line
math expressions dataset to robustly guide attention in visually heterogeneous
inputs. Evaluated on AIHub and FERMAT datasets, VEHME achieves state-of-the-art
performance among open-source models and approaches the accuracy of proprietary
systems, demonstrating its potential as a scalable and accessible tool for
automated math assessment. Our training and experiment code is publicly
available at our GitHub repository.

</details>


### [274] [Cross-Lingual Stability and Bias in Instruction-Tuned Language Models for Humanitarian NLP](https://arxiv.org/abs/2510.22823)
*Poli Nemkova,Amrit Adhikari,Matthew Pearson,Vamsi Krishna Sadu,Mark V. Albert*

Main category: cs.CL

TL;DR: 本论文系统性比较了商用与开源大语言模型（LLMs）在多语言人权违规检测方面的表现，评估了成本与可靠性之间的权衡，并为人道主义组织多语言部署提供了实践指导。


<details>
  <summary>Details</summary>
Motivation: 人道主义组织在采用自动化语言模型进行多语言人权监测时，面临选择高价商用API还是免费开源模型的困境，尤其是在低资源冲突语言上，缺乏开源模型的实证验证。作者希望填补这一评估空白。

Method: 论文对六种LLMs（四种商用指令对齐模型和两种开源权重模型）在七种不同语言上的人权违规检测能力进行对比。方法包含78,000次多语推理，采用标准分类指标及新提出的跨语言可靠性指标（CD, B, LRS, LSS）进行评估。

Result: 实验发现，对齐（alignment）而非规模决定了模型的跨语言能力。指令对齐的商用模型在不同类型、低资源语言（如Lingala、缅甸语）上表现出稳定和均衡的校准能力，而开源模型存在因提示语言变化导致的敏感性和校准漂移。

Conclusion: 多语言对齐显著提升了模型的语言无关推理能力。论文为预算有限的人道组织在多语言部署时，在可靠性与成本间提供了数据化、实证的选型建议。

Abstract: Humanitarian organizations face a critical choice: invest in costly
commercial APIs or rely on free open-weight models for multilingual human
rights monitoring. While commercial systems offer reliability, open-weight
alternatives lack empirical validation -- especially for low-resource languages
common in conflict zones. This paper presents the first systematic comparison
of commercial and open-weight large language models (LLMs) for
human-rights-violation detection across seven languages, quantifying the
cost-reliability trade-off facing resource-constrained organizations. Across
78,000 multilingual inferences, we evaluate six models -- four
instruction-aligned (Claude-Sonnet-4, DeepSeek-V3, Gemini-Flash-2.0,
GPT-4.1-mini) and two open-weight (LLaMA-3-8B, Mistral-7B) -- using both
standard classification metrics and new measures of cross-lingual reliability:
Calibration Deviation (CD), Decision Bias (B), Language Robustness Score (LRS),
and Language Stability Score (LSS). Results show that alignment, not scale,
determines stability: aligned models maintain near-invariant accuracy and
balanced calibration across typologically distant and low-resource languages
(e.g., Lingala, Burmese), while open-weight models exhibit significant
prompt-language sensitivity and calibration drift. These findings demonstrate
that multilingual alignment enables language-agnostic reasoning and provide
practical guidance for humanitarian organizations balancing budget constraints
with reliability in multilingual deployment.

</details>


### [275] [Exploration of Summarization by Generative Language Models for Automated Scoring of Long Essays](https://arxiv.org/abs/2510.22830)
*Haowei Hua,Hong Jiao,Xinyi Wang*

Main category: cs.CL

TL;DR: 本研究通过引入生成式语言模型，结合摘要和提示方法，对长文本作文进行自动评分，取得了明显优于传统BERT变体模型的效果。


<details>
  <summary>Details</summary>
Motivation: 目前主流的BERT及其变体由于编码器结构存在512 token的限制，导致对于长篇作文的自动评分存在不足，因此需要探索新的方法来提升长文评分的效果。

Method: 本文采用生成式语言模型，通过先对长文作文进行摘要处理或利用Prompting技术，将长文本压缩为模型可处理的长度，从而实现对长文本的有效自动评分。

Result: 在Learning Agency Lab Automated Essay Scoring 2.0数据集上，方法将QWK分数从0.822提升到0.8878，表明评分准确率有了显著提升。

Conclusion: 采用生成式语言模型并结合摘要与Prompt技术，可以突破传统BERT编码器模型的长度限制，显著提高长文本作文的自动评分效果。

Abstract: BERT and its variants are extensively explored for automated scoring.
However, a limit of 512 tokens for these encoder-based models showed the
deficiency in automated scoring of long essays. Thus, this research explores
generative language models for automated scoring of long essays via
summarization and prompting. The results revealed great improvement of scoring
accuracy with QWK increased from 0.822 to 0.8878 for the Learning Agency Lab
Automated Essay Scoring 2.0 dataset.

</details>


### [276] [Leveraging Large Language Models to Identify Conversation Threads in Collaborative Learning](https://arxiv.org/abs/2510.22844)
*Prerna Ravi,Dong Won Lee,Beatriz Flamia,Jasmine David,Brandon Hanks,Cynthia Breazeal,Emma Anderson,Grace Lin*

Main category: cs.CL

TL;DR: 论文研究了如何利用大语言模型（LLM）和明确话题线索（threading）提升对小组对话中协作交流与知识流动的自动化分析。作者提出了一套线程识别指南，并评估了不同的LLM提示策略。结果显示，提供清晰的对话线程信息能显著提升LLM在对话分析任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 协作性小组对话中的想法发展与流动是理解合作学习的关键。然而，同步语音对话中线程结构的自动检测非常困难，这影响了依赖此类结构进行的自动化对话分析。现有的LLM在处理长上下文和线程追踪方面能力有限。

Method: 1）提出了一份系统性的多方群体对话线程识别指南；2）对比了多种LLM自动化线程检测的提示策略；3）测试了线程检测对下游对话分析任务（如归纳同意、构建、引导等行为编码）的影响；4）分析了自动和人工-AI混合方法的性价比。

Result: 实验发现，通过为LLM提供清晰的线程结构信息，可以提升其对群体协作行为的自动识别和编码能力。下游对话分析高度依赖对话结构的完整性。还比较了全自动与人机协作方案的效率和成本。

Conclusion: 明确定义和提供线程结构能有效提升LLM在小组对话分 析中的表现。人机混合分析方法在效率与成本间具有优势。本研究推动了群体实时协作对话自动分析方法的发展，建议未来深入结合LLM与结构化对话信息。

Abstract: Understanding how ideas develop and flow in small-group conversations is
critical for analyzing collaborative learning. A key structural feature of
these interactions is threading, the way discourse talk naturally organizes
into interwoven topical strands that evolve over time. While threading has been
widely studied in asynchronous text settings, detecting threads in synchronous
spoken dialogue remains challenging due to overlapping turns and implicit cues.
At the same time, large language models (LLMs) show promise for automating
discourse analysis but often struggle with long-context tasks that depend on
tracing these conversational links. In this paper, we investigate whether
explicit thread linkages can improve LLM-based coding of relational moves in
group talk. We contribute a systematic guidebook for identifying threads in
synchronous multi-party transcripts and benchmark different LLM prompting
strategies for automated threading. We then test how threading influences
performance on downstream coding of conversational analysis frameworks, that
capture core collaborative actions such as agreeing, building, and eliciting.
Our results show that providing clear conversational thread information
improves LLM coding performance and underscores the heavy reliance of
downstream analysis on well-structured dialogue. We also discuss practical
trade-offs in time and cost, emphasizing where human-AI hybrid approaches can
yield the best value. Together, this work advances methods for combining LLMs
and robust conversational thread structures to make sense of complex, real-time
group interactions.

</details>


### [277] [Once Upon an Input: Reasoning via Per-Instance Program Synthesis](https://arxiv.org/abs/2510.22849)
*Adam Stein,Neelay Velingker,Mayur Naik,Eric Wong*

Main category: cs.CL

TL;DR: 本文提出PIPS方法，通过实例级程序生成与优化提升大模型复杂推理能力，并根据置信度动态切换推理策略，在多个任务上大幅优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在零样本推理表现突出，但在多步复杂推理任务上仍有明显短板，现有的链式思维(CoT)和程序化思维(PoT)方法常产生不理想解，特别是在算法任务中。因此，需要一种更可靠的推理增强机制。

Method: 提出了Per-Instance Program Synthesis（PIPS）方法。它在单独实例上自动生成和优化程序答案，通过结构化反馈迭代，不需依赖特定任务指导或测试用例。同时，用置信度指标，动态选择直接推理或程序生成，在实例级别进行最优选择。

Result: 在三款前沿LLM和30个基准任务（涵盖BBEH全部任务、视觉问答、关系和数学推理等）中，PIPS方法较PoT和CoT分别提升最高8.6%和9.4%的绝对调和平均准确率，并在Gemini-2.0-Flash的算法任务中将不理想程序生成减少了65.1%。

Conclusion: PIPS无须特定监督即可大幅提升复杂推理表现，兼顾结果准确率和解题过程质量，为扩展LLM推理应用提供新思路。

Abstract: Large language models (LLMs) excel at zero-shot inference but continue to
struggle with complex, multi-step reasoning. Recent methods that augment LLMs
with intermediate reasoning steps such as Chain of Thought (CoT) and Program of
Thought (PoT) improve performance but often produce undesirable solutions,
especially in algorithmic domains. We introduce Per-Instance Program Synthesis
(PIPS), a method that generates and refines programs at the instance-level
using structural feedback without relying on task-specific guidance or explicit
test cases. To further improve performance, PIPS incorporates a confidence
metric that dynamically chooses between direct inference and program synthesis
on a per-instance basis. Experiments across three frontier LLMs and 30
benchmarks including all tasks of Big Bench Extra Hard (BBEH), visual question
answering tasks, relational reasoning tasks, and mathematical reasoning tasks
show that PIPS improves the absolute harmonic mean accuracy by up to 8.6% and
9.4% compared to PoT and CoT respectively, and reduces undesirable program
generations by 65.1% on the algorithmic tasks compared to PoT with
Gemini-2.0-Flash.

</details>


### [278] [Far from the Shallow: Brain-Predictive Reasoning Embedding through Residual Disentanglement](https://arxiv.org/abs/2510.22860)
*Linyang He,Tianjun Zhong,Richard Antonello,Gavin Mischler,Micah Goldblum,Nima Mesgarani*

Main category: cs.CL

TL;DR: 本研究提出一种新方法，将大语言模型（LLM）中的词汇、句法、语义和推理表征解耦，并用这些解耦特征解释大脑对自然语言的反应，揭示推理过程的独特神经机制。


<details>
  <summary>Details</summary>
Motivation: 当前神经科学难以区分人脑从基础语言处理到高级推理的过程。虽然大语言模型能模拟语言相关的大脑反应，但其内部信息高度混杂，使得现有分析偏向于表层特征，难以剖析更深层次的认知过程。

Method: 作者提出残差解耦方法，首先定位LLM内部与各特征相关的层级，然后递归地回归掉低层表征，获得词汇、句法、语义及推理的近乎正交的特征嵌入。用这些嵌入去建模神经外科患者听语音时的脑内ECoG信号。

Result: 1）推理的独立嵌入对神经活动有独特解释力，能解释其它语言特征无法解释的脑信号变化，甚至能激活传统语言区以外的视觉区；2）推理的神经信号在时间上较晚出现，符合认知处理层级顶端的预测；3）普通未解耦的LLM嵌入以表浅特征为主，掩盖了更深层认知处理的贡献。

Conclusion: 借助解耦方法，可以清晰区分大脑处理不同语言层次及推理的神经基础。推理是一种高级、时间上独特且空间上分布更广的认知过程。既有的LLM表征不足以揭示其全部神经基础。

Abstract: Understanding how the human brain progresses from processing simple
linguistic inputs to performing high-level reasoning is a fundamental challenge
in neuroscience. While modern large language models (LLMs) are increasingly
used to model neural responses to language, their internal representations are
highly "entangled," mixing information about lexicon, syntax, meaning, and
reasoning. This entanglement biases conventional brain encoding analyses toward
linguistically shallow features (e.g., lexicon and syntax), making it difficult
to isolate the neural substrates of cognitively deeper processes. Here, we
introduce a residual disentanglement method that computationally isolates these
components. By first probing an LM to identify feature-specific layers, our
method iteratively regresses out lower-level representations to produce four
nearly orthogonal embeddings for lexicon, syntax, meaning, and, critically,
reasoning. We used these disentangled embeddings to model intracranial (ECoG)
brain recordings from neurosurgical patients listening to natural speech. We
show that: 1) This isolated reasoning embedding exhibits unique predictive
power, accounting for variance in neural activity not explained by other
linguistic features and even extending to the recruitment of visual regions
beyond classical language areas. 2) The neural signature for reasoning is
temporally distinct, peaking later (~350-400ms) than signals related to
lexicon, syntax, and meaning, consistent with its position atop a processing
hierarchy. 3) Standard, non-disentangled LLM embeddings can be misleading, as
their predictive success is primarily attributable to linguistically shallow
features, masking the more subtle contributions of deeper cognitive processing.

</details>


### [279] [Interpreting and Mitigating Unwanted Uncertainty in LLMs](https://arxiv.org/abs/2510.22866)
*Tiasa Singha Roy,Ayush Rajesh Jhaveri,Ilias Triantafyllopoulos*

Main category: cs.CL

TL;DR: LLMs在重新提问时会把正确答案变错，本文分析其机制并提出通过屏蔽特定注意力头减轻该现象。


<details>
  <summary>Details</summary>
Motivation: LLMs在高风险领域因答案不稳定降低信任度，理解并改善这种不确定性至关重要。

Method: 作者采用Needle-in-a-Haystack检索框架，并加入Flip风格的重新评估提示，系统性分析使答案翻转的机制，重点分析注意力头的影响，通过屏蔽特定注意力头进行实验。

Result: 发现非检索型的少数注意力头在不确定场景易被误导性token吸引，屏蔽这些头能让答案翻转行为降低至多15%，且不会造成表达混乱或过度修正，但对下游任务有权衡影响。

Conclusion: 本文揭示了LLMs中导致答案不稳定的机制，并提出了一种简单有效的缓解方法，对可解释性研究和安全应用有重要意义。

Abstract: Despite their impressive capabilities, Large Language Models (LLMs) exhibit
unwanted uncertainty, a phenomenon where a model changes a previously correct
answer into an incorrect one when re-prompted. This behavior undermines trust
and poses serious risks in high-stakes domains. In this work, we investigate
the mechanisms that drive this phenomenon. We adapt the Needle-in-a-Haystack
retrieval framework and integrate a Flip-style re-evaluation prompt to simulate
realistic answer-flipping scenarios. We find that retrieval heads are not
primarily responsible for avoiding uncertainty. Instead, we identify a small
set of non-retrieval attention heads that disproportionately attend to
misleading tokens in uncertain contexts. Masking these heads yields significant
improvements, reducing flip behavior by up to 15% without introducing
incoherence or overcorrection. However, when tested for downstream tasks, we
observe trade-offs with flip behavior. Our findings contribute to the growing
field of mechanistic interpretability and present a simple yet effective
technique for mitigating uncertainty-driven failure modes in LLMs.

</details>


### [280] [A Comprehensive Dataset for Human vs. AI Generated Text Detection](https://arxiv.org/abs/2510.22874)
*Rajarshi Roy,Nasrin Imanpour,Ashhar Aziz,Shashwat Bajpai,Gurpreet Singh,Shwetangshu Biswas,Kapil Wanaskar,Parth Patwa,Subhankar Ghosh,Shreyas Dixit,Nilesh Ranjan Pal,Vipula Rawte,Ritvik Garimella,Gaytri Jena,Amit Sheth,Vasu Sharma,Aishwarya Naresh Reganti,Vinija Jain,Aman Chadha,Amitava Das*

Main category: cs.CL

TL;DR: 本文公开了一个包含超58,000条文本样本的数据集，将真实的《纽约时报》新闻与多种主流大语言模型生成的仿真版本结合，用于AI文本检测和归因任务。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型生成文本越来越接近人类水平，如何检测AI生成内容、辨别来源逐渐成为内容真实性和可信度的难题，因此需要大规模、高质量的标注数据集支持相关研究。

Method: 收集了超过5.8万条新闻文本，包含真实新闻与Gemma-2-9b、Mistral-7B、Qwen-2-72B、LLaMA-8B、Yi-Large及GPT-4-o等主流LLM生成的仿真文本，数据集包括原始文章摘要（用于提示）、全文和作者信息，并对AI检测和归因两个任务进行了基线实验。

Result: 在人类与AI文本区分任务上基线准确率为58.35%，在AI文本归因（辨别由哪个模型生成）任务上基线准确率为8.92%。

Conclusion: 新数据集为生成式AI领域的内容检测、归因方法开发提供了真实且高质量的基准资源，有助于促进生成式AI内容的透明度和信任度建设。

Abstract: The rapid advancement of large language models (LLMs) has led to increasingly
human-like AI-generated text, raising concerns about content authenticity,
misinformation, and trustworthiness. Addressing the challenge of reliably
detecting AI-generated text and attributing it to specific models requires
large-scale, diverse, and well-annotated datasets. In this work, we present a
comprehensive dataset comprising over 58,000 text samples that combine
authentic New York Times articles with synthetic versions generated by multiple
state-of-the-art LLMs including Gemma-2-9b, Mistral-7B, Qwen-2-72B, LLaMA-8B,
Yi-Large, and GPT-4-o. The dataset provides original article abstracts as
prompts, full human-authored narratives. We establish baseline results for two
key tasks: distinguishing human-written from AI-generated text, achieving an
accuracy of 58.35\%, and attributing AI texts to their generating models with
an accuracy of 8.92\%. By bridging real-world journalistic content with modern
generative models, the dataset aims to catalyze the development of robust
detection and attribution methods, fostering trust and transparency in the era
of generative AI. Our dataset is available at:
https://huggingface.co/datasets/gsingh1-py/train.

</details>


### [281] [Batch Speculative Decoding Done Right](https://arxiv.org/abs/2510.22876)
*Ranran Haoran Zhang,Soumik Dey,Ashirbad Mishra,Hansi Wu,Binbin Li,Rui Zhang*

Main category: cs.CL

TL;DR: 本文提出了面向批量推理场景的规范性投机解码（speculative decoding）方法，有效解决了处理ragged tensor带来的对齐和正确性难题，大幅提升了LLM批量推理效率，并实现了高达3倍的吞吐提升，且与标准推理输出高度一致。


<details>
  <summary>Details</summary>
Motivation: 现有投机解码能加速单条LLM推理，但批量推理时会遇到ragged tensor问题（即各条序列接收draft token数量不同，导致位置及缓存错乱），进而违反生成输出等价性，不能直接生产化应用。为满足大规模部署需求，亟需一种既高效又正确的批量投机解码方法。

Method: 作者首先系统分析批量投机解码的对齐及同步需求，在此基础上提出了EQSPEC算法，优先保证正确性；同时提出EXSPEC算法，引入滑动池和动态分组机制，降低对齐开销且保留每序列投机速度提升。上述方法无须自定义算子，可无缝集成进现有的推理框架。

Result: 实验在多个目标/草稿模型组合上（如Vicuna-7B/68M、Qwen3-8B/0.6B、GLM-4-9B/0.6B），对比batch size 1和8，方法实现高达3倍吞吐提升，且样本输出正确率达95%以上，整体批量推理效率优异。

Conclusion: 文中方法有效解决了批量投机解码中的ragged tensor问题和正确性难题，提升了吞吐效率，且不影射推理框架或需特殊优化。这为LLM高效生产部署提供了实用可靠的技术路径。

Abstract: Speculative decoding speeds up LLM inference by using a small draft model to
propose multiple tokens that a target model verifies in parallel. Extending
this idea to batches is essential for production serving, but it introduces the
ragged tensor problem: sequences in the same batch accept different numbers of
draft tokens, breaking right-alignment and corrupting position IDs, attention
masks, and KV-cache state. We show that several existing batch implementations
violate output equivalence-the fundamental requirement that speculative
decoding must produce identical token sequences to standard autoregressive
generation. These violations occur precisely due to improper handling of the
ragged tensor problem. In response, we (1) characterize the synchronization
requirements that guarantee correctness, (2) present a correctness-first batch
speculative decoding EQSPEC that exposes realignment as consuming 40% of
overhead, and (3) introduce EXSPEC, which maintains a sliding pool of sequences
and dynamically forms same-length groups, to reduce the realignment overhead
while preserving per-sequence speculative speedups. On the SpecBench dataset,
across Vicuna-7B/68M, Qwen3-8B/0.6B, and GLM-4-9B/0.6B target/draft pairs, our
approach achieves up to 3$\times$ throughput improvement at batch size 8
compared to batch size 1, with efficient scaling through batch size 8, while
maintaining 95% output equivalence. Our method requires no custom kernels and
integrates cleanly with existing inference stacks. Our code is available at
https://github.com/eBay/spec_dec.

</details>


### [282] [Language Server CLI Empowers Language Agents with Process Rewards](https://arxiv.org/abs/2510.22907)
*Yifan Zhang,Lanser Contributors*

Main category: cs.CL

TL;DR: Lanser-CLI通过把语言服务器纳入编码代理和CI流程，实现了API调用的确定性与可复现性，并用语言服务器生成的验证信号来提升代码编辑操作的安全性和可追踪性。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型常常产生“幻觉”API和不准确的代码编辑定位，而语言服务器可以为真实代码提供结构化、可验证的信息。作者希望将这种确定性和可验证的过程信号引入智能编码代理（如LLM agent）和CI自动化中，从而提高其操作的可靠性和安全性。

Method: 设计并实现了Lanser-CLI—一个CLI优先的编排层，作为语言服务器的接口代理。它采用了更健壮的地址选择语言（Selector DSL），能以符号、AST路径和内容定位代码片段，配合原理化的重定位算法。提供确定性的分析包（Analysis Bundles）来标准化响应并捕获环境元数据，所有操作通过安全壳层实现预览和事务性应用（如Git感知）。结合语言服务器输出生成过程奖励函数，用于过程监督与反事实分析。

Result: Lanser-CLI提升了语言模型等编码代理及CI操作的确定性；此外，创新的Selector DSL和分析包机制增强了操作的健壮度和可追溯性。过程奖励函数实现了在线与离线可计算，并理论上证明了其确定性和单调性，可有效用于过程监督与分析。

Conclusion: Lanser-CLI展示了将语言服务器确定性信号引入智能编码代理和自动化流程的可行性与价值，不仅提升了安全性和可靠性，也为更高层次的过程监督和诊断分析提供了基础。

Abstract: Large language models routinely hallucinate APIs and mislocalize edits, while
language servers compute verified, IDE-grade facts about real code. We present
Lanser-CLI, a CLI-first orchestration layer that pins and mediates a Language
Server Protocol (LSP) server for coding agents and CI, exposing deterministic,
replayable workflows. Our position is that language servers provide not only
structural information (definitions, references, types, diagnostics) but also
an actionable process reward: machine-checked, step-wise signals that align an
agent's planning loop with program reality. In this work, Lanser-CLI
contributes: (i) a robust addressing scheme beyond brittle "file:line:col" via
a Selector DSL (symbolic, AST-path, and content-anchored selectors) with a
principled relocation algorithm; (ii) deterministic Analysis Bundles that
normalize Language Server responses and capture environment/capability metadata
with stable content hashes; (iii) a safety envelope for mutating operations
(rename, code actions) with preview, workspace jails, and Git-aware,
transactional apply; and (iv) a process-reward functional derived from Language
Server facts (diagnostic deltas, disambiguation confidence, and safe-apply
checks) that is computable online and replayable offline. We formalize
determinism under frozen snapshots and establish a monotonicity property for
the process reward, making it suitable for process supervision and
counterfactual analysis. Project Page:
https://github.com/yifanzhang-pro/lanser-cli

</details>


### [283] [Artificial Hivemind: The Open-Ended Homogeneity of Language Models (and Beyond)](https://arxiv.org/abs/2510.22954)
*Liwei Jiang,Yuanjun Chai,Margaret Li,Mickel Liu,Raymond Fok,Nouha Dziri,Yulia Tsvetkov,Maarten Sap,Alon Albalak,Yejin Choi*

Main category: cs.CL

TL;DR: 该论文提出了Infinity-Chat，这是一个包含2.6万条多样化、真实、开放式用户提问的大型数据集，用于系统性评估语言模型在开放式任务下生成内容的多样性。研究显示，主流语言模型在开放式内容生成中存在严重的“人工集体意识”效应，各模型输出高度同质化，难以满足人类多样化创造需求。


<details>
  <summary>Details</summary>
Motivation: 目前，语言模型生成的内容常表现出缺乏多样性、趋同化倾向，这可能导致人类思维长期单一化，同时目前缺乏可扩展、针对真实开放式任务的多样性评测方法和数据集。本研究旨在弥补这一空白，系统性探索和量化语言模型在开放任务下的多样性缺失问题。

Method: 作者构建了Infinity-Chat数据集，覆盖六大类、17个子类的多样化开放式任务，同时收集3万余条由25位独立人工标注者评定的人类评价标签。利用该数据集，系统对比分析多种主流大模型在开放式任务下“模式坍缩”（Mode Collapse）和同质化现象，并研究奖励模型和自动评测是否符合人类偏好。

Result: 实验发现，大模型在开放式生成中存在显著的单一模型内复读和跨模型同质化输出，受“人工集体意识”效应影响显著。在偏好多样性的开放任务下，无论是模型评分还是自动评测指标，都难以准确反映人类个体差异化的评价标准。

Conclusion: Infinity-Chat丰富了语言模型开放式任务多样性评测的工具链，首次揭示了主流语言模型在真实世界用户任务上的严重同质化风险。研究建议从模型设计和评测体系层面入手，抑制“人工集体意识”现象，以防止长期AI安全风险。

Abstract: Language models (LMs) often struggle to generate diverse, human-like creative
content, raising concerns about the long-term homogenization of human thought
through repeated exposure to similar outputs. Yet scalable methods for
evaluating LM output diversity remain limited, especially beyond narrow tasks
such as random number or name generation, or beyond repeated sampling from a
single model. We introduce Infinity-Chat, a large-scale dataset of 26K diverse,
real-world, open-ended user queries that admit a wide range of plausible
answers with no single ground truth. We introduce the first comprehensive
taxonomy for characterizing the full spectrum of open-ended prompts posed to
LMs, comprising 6 top-level categories (e.g., brainstorm & ideation) that
further breaks down to 17 subcategories. Using Infinity-Chat, we present a
large-scale study of mode collapse in LMs, revealing a pronounced Artificial
Hivemind effect in open-ended generation of LMs, characterized by (1)
intra-model repetition, where a single model consistently generates similar
responses, and more so (2) inter-model homogeneity, where different models
produce strikingly similar outputs. Infinity-Chat also includes 31,250 human
annotations, across absolute ratings and pairwise preferences, with 25
independent human annotations per example. This enables studying collective and
individual-specific human preferences in response to open-ended queries. Our
findings show that LMs, reward models, and LM judges are less well calibrated
to human ratings on model generations that elicit differing idiosyncratic
annotator preferences, despite maintaining comparable overall quality. Overall,
INFINITY-CHAT presents the first large-scale resource for systematically
studying real-world open-ended queries to LMs, revealing critical insights to
guide future research for mitigating long-term AI safety risks posed by the
Artificial Hivemind.

</details>


### [284] [Tagging-Augmented Generation: Assisting Language Models in Finding Intricate Knowledge In Long Contexts](https://arxiv.org/abs/2510.22956)
*Anwesan Pal,Karen Hovsepian,Tinghao Guo,Mengnan Zhao,Somendra Tripathi,Nikos Kanakaris,George Mihaila,Sumit Nigam*

Main category: cs.CL

TL;DR: 本文提出了一种名为TAG（Tagging-Augmented Generation）的轻量级数据增强方法，显著提升了大模型在长上下文下的问答与推理能力。实验表明，在NoLima和NovelQA基准上的性能较基线有明显提升。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLM）在面对超长、复杂上下文时，即便是最先进的模型也会在问答和推理效果上表现不佳。主流的解决方案如RAG和chunk重排序存在依赖数据预处理、检索及嵌入方式等多个问题，故亟需一种无需复杂处理、能有效提升长上下文处理能力的方法。

Method: 作者提出TAG方法，在提问上下文中直接加入标签或为标签定义，无需对原始文档结构和内容做复杂更改。通过数据增强形式，让模型“感知”文本不同部分之间的逻辑关联。

Result: 在NoLima和NovelQA两个挑战性数据集的测试中，引入TAG方法后，长上下文（32K tokens）问答的表现提升最高可达17%，复杂推理下的多跳问答准确率提升2.9%。

Conclusion: TAG方法成本低、实施简单，显著增强了LLM对长文本的理解和推理能力，为长上下文场景下的高效QA与推理提供了切实可行的新思路。

Abstract: Recent investigations into effective context lengths of modern flagship large
language models (LLMs) have revealed major limitations in effective question
answering (QA) and reasoning over long and complex contexts for even the
largest and most impressive cadre of models. While approaches like
retrieval-augmented generation (RAG) and chunk-based re-ranking attempt to
mitigate this issue, they are sensitive to chunking, embedding and retrieval
strategies and models, and furthermore, rely on extensive pre-processing,
knowledge acquisition and indexing steps. In this paper, we propose
Tagging-Augmented Generation (TAG), a lightweight data augmentation strategy
that boosts LLM performance in long-context scenarios, without degrading and
altering the integrity and composition of retrieved documents. We validate our
hypothesis by augmenting two challenging and directly relevant
question-answering benchmarks -- NoLima and NovelQA -- and show that tagging
the context or even just adding tag definitions into QA prompts leads to
consistent performance gains over the baseline -- up to 17% for 32K token
contexts, and 2.9% in complex reasoning question-answering for multi-hop
queries requiring knowledge across a wide span of text. Additional details are
available at https://sites.google.com/view/tag-emnlp.

</details>


### [285] [MAD-Fact: A Multi-Agent Debate Framework for Long-Form Factuality Evaluation in LLMs](https://arxiv.org/abs/2510.22967)
*Yucheng Ning,Xixun Lin,Fang Fang,Yanan Cao*

Main category: cs.CL

TL;DR: 本文提出了一个系统方法，用于评估和提升大型语言模型在长文本输出中的事实准确性，尤其针对中文领域。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型广泛应用，其输出的事实准确性成为高风险领域（如医学、法律、教育）关注的焦点。现有主要针对短文本的评测方法在长文本场景下效果不佳，无法应对复杂推理和信息累积的问题。

Method: 作者构建了一个中文长文本事实性数据集（LongHalluQA），并开发了一个辩论式多智能体验证系统（MAD-Fact），引入事实重要性层级，采用多维度加权指标评估长文本事实性。

Result: 实验证明，大型LLM通常能保持更高事实一致性，国内模型在中文内容上表现更好。提出的方法有效提升了长文本事实性评估的结构性和准确性。

Conclusion: 本文方法为长文本LLM输出的事实可靠性评测及增强提供了系统性框架，有助于LLM在敏感领域的安全落地和应用。

Abstract: The widespread adoption of Large Language Models (LLMs) raises critical
concerns about the factual accuracy of their outputs, especially in high-risk
domains such as biomedicine, law, and education. Existing evaluation methods
for short texts often fail on long-form content due to complex reasoning
chains, intertwined perspectives, and cumulative information. To address this,
we propose a systematic approach integrating large-scale long-form datasets,
multi-agent verification mechanisms, and weighted evaluation metrics. We
construct LongHalluQA, a Chinese long-form factuality dataset; and develop
MAD-Fact, a debate-based multi-agent verification system. We introduce a fact
importance hierarchy to capture the varying significance of claims in long-form
texts. Experiments on two benchmarks show that larger LLMs generally maintain
higher factual consistency, while domestic models excel on Chinese content. Our
work provides a structured framework for evaluating and enhancing factual
reliability in long-form LLM outputs, guiding their safe deployment in
sensitive domains.

</details>


### [286] [Measuring Teaching with LLMs](https://arxiv.org/abs/2510.22968)
*Michael Hardy*

Main category: cs.CL

TL;DR: 本论文提出了一种基于句子级嵌入的定制大语言模型（LLM），用于高效、可扩展地测量教学质量，能够实现与人类甚至超越人类的表现。


<details>
  <summary>Details</summary>
Motivation: 教育领域缺乏客观且可扩展的教学质量测量方法。尽管大语言模型有潜力，但通用模型难以适应复杂真实的课堂观测标准。

Method: 本研究基于句子级嵌入架构设计专用LLM，对五种不同的句子嵌入方法在数据高效且避免过拟合的训练策略下进行了系统评估，并分析模型判分的上下文窗口与实际教师评分及教学增值数据的一致性。

Result: 专用LLM在与专家评分的相关系数超过0.65，超过人类评分者间的平均相关度，并且高质量模型更多依据课时整体特征而非单独发言。同时模型总分与教师增值指标一致，但单题层面尚未完全泛化。

Conclusion: 提出的专用LLM方法为AI辅助教学测量提供了可行且强大的新途径，具备实现大规模、可靠、有效的教师发展反馈的潜力。

Abstract: Objective and scalable measurement of teaching quality is a persistent
challenge in education. While Large Language Models (LLMs) offer potential,
general-purpose models have struggled to reliably apply complex, authentic
classroom observation instruments. This paper uses custom LLMs built on
sentence-level embeddings, an architecture better suited for the long-form,
interpretive nature of classroom transcripts than conventional subword
tokenization. We systematically evaluate five different sentence embeddings
under a data-efficient training regime designed to prevent overfitting. Our
results demonstrate that these specialized models can achieve human-level and
even super-human performance with expert human ratings above 0.65 and
surpassing the average human-human rater correlation. Further, through analysis
of annotation context windows, we find that more advanced models-those better
aligned with human judgments-attribute a larger share of score variation to
lesson-level features rather than isolated utterances, challenging the
sufficiency of single-turn annotation paradigms. Finally, to assess external
validity, we find that aggregate model scores align with teacher value-added
measures, indicating they are capturing features relevant to student learning.
However, this trend does not hold at the individual item level, suggesting that
while the models learn useful signals, they have not yet achieved full
generalization. This work establishes a viable and powerful new methodology for
AI-driven instructional measurement, offering a path toward providing scalable,
reliable, and valid feedback for educator development.

</details>


### [287] [Understanding In-Context Learning Beyond Transformers: An Investigation of State Space and Hybrid Architectures](https://arxiv.org/abs/2510.23006)
*Shenran Wang,Timothy Tin-Long Tse,Jian Zhu*

Main category: cs.CL

TL;DR: 本文通过行为分析与干预相结合的方法，对不同结构的大语言模型（LLMs）在基于知识的上下文学习（ICL）任务上进行了深入评估，发现任务表现可类似，但模型内部机制存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 尽管不同架构的LLMs在ICL任务上的表现相近，但它们内部实现机制尚不清楚，因此需要深入分析以揭示架构间异同，对推动模型理解具有重要意义。

Method: 作者通过行为测试与机制干预两种方法相结合，系统评估了变换器、状态空间及混合型LLMs在两类知识型ICL任务（参数化知识检索和语境知识理解）中的表现，并定位了关键的功能向量（FVs）分布。

Result: 发现不同架构的LLMs在外部表现相似，但内部依赖机制存在差异。其中，FVs主要分布在自注意力和Mamba层，Mamba2则可能使用不同机制。对于参数知识检索任务，FVs尤为重要，而对语境理解则作用有限。

Conclusion: 本研究揭示了不同LLM架构在ICL任务中表面相似但机制不同，并强调结合行为与机制两方面分析对于深入理解LLM能力的重要性。

Abstract: We perform in-depth evaluations of in-context learning (ICL) on
state-of-the-art transformer, state-space, and hybrid large language models
over two categories of knowledge-based ICL tasks. Using a combination of
behavioral probing and intervention-based methods, we have discovered that,
while LLMs of different architectures can behave similarly in task performance,
their internals could remain different. We discover that function vectors (FVs)
responsible for ICL are primarily located in the self-attention and Mamba
layers, and speculate that Mamba2 uses a different mechanism from FVs to
perform ICL. FVs are more important for ICL involving parametric knowledge
retrieval, but not for contextual knowledge understanding. Our work contributes
to a more nuanced understanding across architectures and task types.
Methodologically, our approach also highlights the importance of combining both
behavioural and mechanistic analyses to investigate LLM capabilities.

</details>


### [288] [LangLingual: A Personalised, Exercise-oriented English Language Learning Tool Leveraging Large Language Models](https://arxiv.org/abs/2510.23011)
*Sammriddh Gupta,Sonit Singh,Aditya Joshi,Mira Kim*

Main category: cs.CL

TL;DR: 该论文介绍了LangLingual，一款基于LangChain和大语言模型的对话代理系统，旨在为语言学习者提供即时语法反馈、生成情境化练习并跟踪学习进展，实验结果表明系统具有良好的可用性和积极的学习成效。


<details>
  <summary>Details</summary>
Motivation: 现有语言教师难以提供足够的反馈与练习，限制了学习者的整体体验，因此需要自动化、智能化的语言学习辅助工具。

Method: 设计并实现了LangLingual系统，基于LangChain与大语言模型，支持实时语法纠错、自动化情境练习生成和学习过程追踪。

Result: 实验和用户测试显示，LangLingual系统易用、能提升学习者的学习成效，并且提高了学习的积极性和参与度。

Conclusion: LangLingual能够有效支持语言学习，并具备良好的用户体验和应用前景，值得进一步研究与推广。

Abstract: Language educators strive to create a rich experience for learners, while
they may be restricted in the extend of feedback and practice they can provide.
We present the design and development of LangLingual, a conversational agent
built using the LangChain framework and powered by Large Language Models. The
system is specifically designed to provide real-time, grammar-focused feedback,
generate context-aware language exercises and track learner proficiency over
time. The paper discusses the architecture, implementation and evaluation of
LangLingual in detail. The results indicate strong usability, positive learning
outcomes and encouraging learner engagement.

</details>


### [289] [Incentivizing Agentic Reasoning in LLM Judges via Tool-Integrated Reinforcement Learning](https://arxiv.org/abs/2510.23038)
*Ran Xu,Jingjing Chen,Jiayu Ye,Yu Wu,Jun Yan,Carl Yang,Hongkun Yu*

Main category: cs.CL

TL;DR: 本文提出TIR-Judge，一个将代码执行工具集成进大语言模型（LLM）评价流程的端到端强化学习框架，大幅提升了自动化评价的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM评价者主要依赖文本推理，难以处理复杂约束与精确计算，限制了评判质量，因此需要借助外部工具增强判别能力。

Method: 提出TIR-Judge框架：1）在可验证和不可验证领域进行多样化训练；2）支持多种评判方式（单点、成对、列表）；3）采用迭代式强化学习直接从初始模型自举，无需蒸馏。集成代码执行器辅助复杂推理与判断。

Result: 在七个公开基准上，TIR-Judge评判效果显著超过传统基于推理的LLM——点式提升6.4%，对式提升7.7%；列表式效果与Claude-Opus-4相当（但参数量仅8B）。

Conclusion: TIR-Judge显著提升自动化评判的性能，且不依赖标签蒸馏即可通过自我强化学习进化，展示了工具增强LLM评判的巨大潜力。

Abstract: Large Language Models (LLMs) are widely used as judges to evaluate response
quality, providing a scalable alternative to human evaluation. However, most
LLM judges operate solely on intrinsic text-based reasoning, limiting their
ability to verify complex constraints or perform accurate computation.
Motivated by the success of tool-integrated reasoning (TIR) in numerous tasks,
we propose TIR-Judge, an end-to-end RL framework for training LLM judges that
integrates a code executor for precise evaluation. TIR-Judge is built on three
principles: (i) diverse training across verifiable and non-verifiable domains,
(ii) flexible judgment formats (pointwise, pairwise, listwise), and (iii)
iterative RL that bootstraps directly from the initial model without
distillation. On seven public benchmarks, TIR-Judge surpasses strong
reasoning-based judges by up to 6.4% (pointwise) and 7.7% (pairwise), and
achieves listwise performance comparable to Claude-Opus-4 despite having only
8B parameters. Remarkably, TIR-Judge-Zero - trained entirely without distilled
judge trajectories, matches the performance of distilled variants,
demonstrating that tool-augmented judges can self-evolve through iterative
reinforcement learning.

</details>


### [290] [Knocking-Heads Attention](https://arxiv.org/abs/2510.23052)
*Zhanchao Zhou,Xiaodong Chen,Haoxing Chen,Zhenzhong Lan,Jianguo Li*

Main category: cs.CL

TL;DR: 本文提出了一种新的注意力机制KHA（knocking-heads attention），通过引入heads间的特征级交互，提升了多头注意力模型的表达能力，并在大规模模型上取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 多头注意力（MHA）虽然通过多个头并行增强了模型能力，但头之间缺乏有效互动，且头数增加会削弱单个头的能力。现有方法如GQA、GTA等仅拼接各自输出，未解决头间协作问题。

Method: 提出KHA机制，在传统注意力前引入可学习、共享、对角初始化的投影矩阵，实现注意力头之间的特征级“敲击”交互。该设计保证了初期各头的独立性，并逐步学习跨头融合。KHA所需新增参数和计算量极少，可无缝与MHA及其变体结合。

Result: 在包含6.1B参数（1.01B激活）的MoE模型上，KHA在1万亿高质量数据上训练，较传统和改进注意力机制带来了更优、更稳定的训练表现，下游任务性能提升。

Conclusion: KHA高效提升了多头注意力结构的表现和稳定性，且参数和计算开销极小，具有良好的通用性与应用前景。

Abstract: Multi-head attention (MHA) has become the cornerstone of modern large
language models, enhancing representational capacity through parallel attention
heads. However, increasing the number of heads inherently weakens individual
head capacity, and existing attention mechanisms - whether standard MHA or its
variants like grouped-query attention (GQA) and grouped-tied attention (GTA) -
simply concatenate outputs from isolated heads without strong interaction. To
address this limitation, we propose knocking-heads attention (KHA), which
enables attention heads to "knock" on each other - facilitating cross-head
feature-level interactions before the scaled dot-product attention. This is
achieved by applying a shared, diagonally-initialized projection matrix across
all heads. The diagonal initialization preserves head-specific specialization
at the start of training while allowing the model to progressively learn
integrated cross-head representations. KHA adds only minimal parameters and
FLOPs and can be seamlessly integrated into MHA, GQA, GTA, and other attention
variants. We validate KHA by training a 6.1B parameter MoE model (1.01B
activated) on 1T high-quality tokens. Compared to baseline attention
mechanisms, KHA brings superior and more stable training dynamics, achieving
better performance across downstream tasks.

</details>


### [291] [Quality-Aware Translation Tagging in Multilingual RAG system](https://arxiv.org/abs/2510.23070)
*Hoyeon Moon,Byeolhee Kim,Nikhil Verma*

Main category: cs.CL

TL;DR: 本文提出了一种用于多语言检索增强生成（mRAG）的新方法QTT-RAG，通过为检索到的翻译文档打分以提升生成效果，在低资源语种场景下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有mRAG方法依赖英语文档翻译，但在低资源语种下翻译质量差，影响生成质量。以往方法要么假设翻译质量充足，要么采用重写方法，导致事实错误和幻觉。迫切需要一种能识别并利用翻译质量的方法。

Method: 提出QTT-RAG方法，从语义等价、语法准确和流畅自然三个维度对翻译文档进行质量打分，并作为元数据附加在文档上，但不改变文档内容。这些分数帮助生成模型判别及利用高质量翻译信息。

Result: 在跨领域开放问答基准（XORQA和MKQA）和六个不同参数量的中文、韩语和芬兰语大模型上对QTT-RAG进行了评测。结果显示QTT-RAG在保持事实一致性的同时，提升了生成性能，明显优于CrossRAG和DKM-RAG基线方法。

Conclusion: QTT-RAG能让生成模型有效利用跨语种优质文档信息，在低资源语言环境中取得更好效果，是多语言领域内实用且鲁棒的解决方案。

Abstract: Multilingual Retrieval-Augmented Generation (mRAG) often retrieves English
documents and translates them into the query language for low-resource
settings. However, poor translation quality degrades response generation
performance. Existing approaches either assume sufficient translation quality
or utilize the rewriting method, which introduces factual distortion and
hallucinations. To mitigate these problems, we propose Quality-Aware
Translation Tagging in mRAG (QTT-RAG), which explicitly evaluates translation
quality along three dimensions-semantic equivalence, grammatical accuracy, and
naturalness&fluency-and attach these scores as metadata without altering the
original content. We evaluate QTT-RAG against CrossRAG and DKM-RAG as baselines
in two open-domain QA benchmarks (XORQA, MKQA) using six instruction-tuned LLMs
ranging from 2.4B to 14B parameters, covering two low-resource languages
(Korean and Finnish) and one high-resource language (Chinese). QTT-RAG
outperforms the baselines by preserving factual integrity while enabling
generator models to make informed decisions based on translation reliability.
This approach allows for effective usage of cross-lingual documents in
low-resource settings with limited native language documents, offering a
practical and robust solution across multilingual domains.

</details>


### [292] [A Survey on LLM Mid-training](https://arxiv.org/abs/2510.23081)
*Chengying Tu,Xuemiao Zhang,Rongxiang Weng,Rumei Li,Chen Zhang,Yang Bai,Hongfei Yan,Jingang Wang,Xunliang Cai*

Main category: cs.CL

TL;DR: 论文综述了大模型训练中的“中期训练”阶段，并对其定义、优化方法及相关应用进行了系统梳理与分析。


<details>
  <summary>Details</summary>
Motivation: 随着大模型（如LLM）不断发展，单一的预训练-微调流程已难以满足对模型多样能力的要求。尤其在数学、推理、长文本等特定能力培养方面，需要更加精细的训练过程，促使研究者提出并重视“中期训练”这一关键阶段。

Method: 文章提出了“中期训练”的正式定义，调研了包括数据选择、训练方法和架构优化在内的一系列优化框架，对比分析了不同主流模型在objective-driven（目标驱动）中期干预下的表现和具体做法。

Result: 论文归纳了中期训练的主流实现方式，并分类阐述了其对模型能力提升的贡献，总结出一套全面的知识体系和分类方法。

Conclusion: 中期训练不仅是承上启下的关键阶段，也是提升模型个别能力与整体表现不可或缺的一环。文章通过系统性梳理为后续LLM中期训练的研究与创新提供了理论依据和指导建议。

Abstract: Recent advances in foundation models have highlighted the significant
benefits of multi-stage training, with a particular emphasis on the emergence
of mid-training as a vital stage that bridges pre-training and post-training.
Mid-training is distinguished by its use of intermediate data and computational
resources, systematically enhancing specified capabilities such as mathematics,
coding, reasoning, and long-context extension, while maintaining foundational
competencies. This survey provides a formal definition of mid-training for
large language models (LLMs) and investigates optimization frameworks that
encompass data curation, training strategies, and model architecture
optimization. We analyze mainstream model implementations in the context of
objective-driven interventions, illustrating how mid-training serves as a
distinct and critical stage in the progressive development of LLM capabilities.
By clarifying the unique contributions of mid-training, this survey offers a
comprehensive taxonomy and actionable insights, supporting future research and
innovation in the advancement of LLMs.

</details>


### [293] [MAP4TS: A Multi-Aspect Prompting Framework for Time-Series Forecasting with Large Language Models](https://arxiv.org/abs/2510.23090)
*Suchan Lee,Jihoon Choi,Sohyeon Lee,Minseok Song,Bong-Gyu Jang,Hwanjo Yu,Soyeon Caren Han*

Main category: cs.CL

TL;DR: 本文提出了一种新的多方面提示框架（MAP4TS），通过结合经典时间序列分析与多模态提示设计，提升了大语言模型在时间序列预测任务中的表现，并显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前将大语言模型（LLM）应用于时间序列预测的研究，往往忽略了时间序列数据特有的统计性质与时序依赖性，导致现有多模态方法在处理时间序列数据时表现不足。作者希望通过更好地结合时间序列特征，提升LLM的预测能力。

Method: 提出MAP4TS框架，通过设计包含全局领域、局部领域、统计以及时序信息的多方面提示（如自相关、偏自相关和傅里叶分析等手工特征），将这些结构化提示与原始时序嵌入联合输入LLM，并通过跨模态对齐模块生成统一表示，实现更有效的预测。

Result: 在八个不同的数据集上的大量实验表明，MAP4TS在预测准确性上持续超越最新的LLM方法。消融实验显示，提示感知设计极大提升了模型的稳定性，并且结构化提示加持下的GPT-2主干在长期预测中优于更大规模的LLaMA。

Conclusion: MAP4TS通过结合多方面的结构化提示和传统统计分析，有效提升了LLM在时间序列预测中的表现和稳定性，这也启示了未来LLM与领域知识结合的新方向。

Abstract: Recent advances have investigated the use of pretrained large language models
(LLMs) for time-series forecasting by aligning numerical inputs with LLM
embedding spaces. However, existing multimodal approaches often overlook the
distinct statistical properties and temporal dependencies that are fundamental
to time-series data. To bridge this gap, we propose MAP4TS, a novel
Multi-Aspect Prompting Framework that explicitly incorporates classical
time-series analysis into the prompt design. Our framework introduces four
specialized prompt components: a Global Domain Prompt that conveys
dataset-level context, a Local Domain Prompt that encodes recent trends and
series-specific behaviors, and a pair of Statistical and Temporal Prompts that
embed handcrafted insights derived from autocorrelation (ACF), partial
autocorrelation (PACF), and Fourier analysis. Multi-Aspect Prompts are combined
with raw time-series embeddings and passed through a cross-modality alignment
module to produce unified representations, which are then processed by an LLM
and projected for final forecasting. Extensive experiments across eight diverse
datasets show that MAP4TS consistently outperforms state-of-the-art LLM-based
methods. Our ablation studies further reveal that prompt-aware designs
significantly enhance performance stability and that GPT-2 backbones, when
paired with structured prompts, outperform larger models like LLaMA in
long-term forecasting tasks.

</details>


### [294] [Leveraging Hierarchical Organization for Medical Multi-document Summarization](https://arxiv.org/abs/2510.23104)
*Yi-Li Hsu,Katelyn X. Mei,Lucy Lu Wang*

Main category: cs.CL

TL;DR: 本文研究了在医学多文档摘要任务中，将层次化结构融入输入能提升摘要模型组织和理解跨文档信息的能力，结果显示层次化方法能更好地提升摘要质量并获得专家偏好。


<details>
  <summary>Details</summary>
Motivation: 医学多文档摘要任务需要对来自多个文献的信息进行有效整合，现有方法多为扁平化处理，往往难以组织和管理文档间的复杂关系。作者希望探索通过输入端的层次化结构提升摘要的结构化与内容相关性，解决现有摘要质量和偏好不足的问题。

Method: 作者在三个大型语言模型（LLM）上，尝试了两种不同的层次化输入方法，并对生成的医学摘要进行了全面评估，包括自动化指标、基于模型的指标，以及专家对摘要各项特性的主观评价（如偏好、可理解性、清晰度、复杂度、相关性、覆盖度、事实性和连贯性）。同时考察了GPT-4模拟评价与人类专家评价的一致性。

Result: 人类专家总体更偏好模型生成的摘要而非人工写作摘要；层次化输入方法在确保事实性、信息覆盖和连贯性的同时，也提升了专家对摘要的总体偏好。同时，GPT-4 模拟评价与人类评价在客观维度上较为一致。

Conclusion: 医学多文档摘要中，采用输入层次结构能提升自动生成摘要的清晰度与覆盖度，增加模型摘要的专家偏好，是提升医学摘要可用性和质量的有效方法。

Abstract: Medical multi-document summarization (MDS) is a complex task that requires
effectively managing cross-document relationships. This paper investigates
whether incorporating hierarchical structures in the inputs of MDS can improve
a model's ability to organize and contextualize information across documents
compared to traditional flat summarization methods. We investigate two ways of
incorporating hierarchical organization across three large language models
(LLMs), and conduct comprehensive evaluations of the resulting summaries using
automated metrics, model-based metrics, and domain expert evaluation of
preference, understandability, clarity, complexity, relevance, coverage,
factuality, and coherence. Our results show that human experts prefer
model-generated summaries over human-written summaries. Hierarchical approaches
generally preserve factuality, coverage, and coherence of information, while
also increasing human preference for summaries. Additionally, we examine
whether simulated judgments from GPT-4 align with human judgments, finding
higher agreement along more objective evaluation facets. Our findings
demonstrate that hierarchical structures can improve the clarity of medical
summaries generated by models while maintaining content coverage, providing a
practical way to improve human preference for generated summaries.

</details>


### [295] [Flexing in 73 Languages: A Single Small Model for Multilingual Inflection](https://arxiv.org/abs/2510.23114)
*Tomáš Sourada,Jana Straková*

Main category: cs.CL

TL;DR: 本论文提出了一种紧凑型单模型用于多语言词形变化任务，能从词根生成多种变化形式，覆盖73种语言，并在大多数语言上优于单语模型。


<details>
  <summary>Details</summary>
Motivation: 传统的词形变化任务通常为每种语言单独训练模型，管理和部署复杂，且面对未见词时效果有限，缺少一个通用、多语言、鲁棒性强的解决方案。

Method: 作者设计并训练了一个单一的多语言模型，联合学习73种语言的数据。在数据划分上引入了新的频率加权、词元分离的数据重采样方法。评测上除了常规SIGMORPHON基准，还采集自UD语料库，提取词根-标签-变化三元组及其频率。

Result: 该多语言模型模型参数量小、对未见词表现鲁棒，在大多数语言上超过单语基线模型。模型能够简化多语言部署需求，并支持未见词变形。

Conclusion: 多语言联合训练可以提升词形变化系统的性能与实用性，能够为多语言NLP应用提供通用方案，同时降低开发和运维成本。所有代码已开源。

Abstract: We present a compact, single-model approach to multilingual inflection, the
task of generating inflected word forms from base lemmas to express grammatical
categories. Our model, trained jointly on data from 73 languages, is
lightweight, robust to unseen words, and outperforms monolingual baselines in
most languages. This demonstrates the effectiveness of multilingual modeling
for inflection and highlights its practical benefits: simplifying deployment by
eliminating the need to manage and retrain dozens of separate monolingual
models. In addition to the standard SIGMORPHON shared task benchmarks, we
evaluate our monolingual and multilingual models on 73 Universal Dependencies
(UD) treebanks, extracting lemma-tag-form triples and their frequency counts.
To ensure realistic data splits, we introduce a novel frequency-weighted,
lemma-disjoint train-dev-test resampling procedure. Our work addresses the lack
of an open-source, general-purpose, multilingual morphological inflection
system capable of handling unseen words across a wide range of languages,
including Czech. All code is publicly released at:
https://github.com/tomsouri/multilingual-inflection.

</details>


### [296] [Beyond Higher Rank: Token-wise Input-Output Projections for Efficient Low-Rank Adaptation](https://arxiv.org/abs/2510.23123)
*Shiwei Li,Xiandi Luo,Haozhao Wang,Xing Tang,Ziqiang Cui,Dugang Liu,Yuhua Li,Xiuqiang He,Ruixuan Li*

Main category: cs.CL

TL;DR: 本文提出了一种改进的低秩适应（LoRA）方法，称为Token-wise Projected Low-Rank Adaptation（TopLoRA），通过为不同输入token动态调整权重，实现更细粒度的参数高效微调，在多项实验中表现优于主流方法。


<details>
  <summary>Details</summary>
Motivation: 现有的LoRA方法在所有输入tokens间共享同一组低秩权重，无法有效区分和利用不同token的语义差异，导致模型微调能力受限。

Method: TopLoRA引入token相关的动态对角矩阵Σ_X，实现根据每个输入token生成独立的LoRA权重，形式为BΣ_XA（A、B为低秩矩阵），通过端到端学习token级的输入-输出映射，同时保持权重的低秩特性且参数开销不变。

Result: 在多个大模型和数据集上的大量实验显示，TopLoRA在各项评测中都优于标准LoRA和其他变体。

Conclusion: TopLoRA通过token级别的自适应调整，显著提升了参数高效微调效果，为进一步改善大模型微调方法提供了新的思路和工具。

Abstract: Low-rank adaptation (LoRA) is a parameter-efficient fine-tuning (PEFT) method
widely used in large language models (LLMs). LoRA essentially describes the
projection of an input space into a low-dimensional output space, with the
dimensionality determined by the LoRA rank. In standard LoRA, all input tokens
share the same weights and undergo an identical input-output projection. This
limits LoRA's ability to capture token-specific information due to the inherent
semantic differences among tokens. To address this limitation, we propose
Token-wise Projected Low-Rank Adaptation (TopLoRA), which dynamically adjusts
LoRA weights according to the input token, thereby learning token-wise
input-output projections in an end-to-end manner. Formally, the weights of
TopLoRA can be expressed as $B\Sigma_X A$, where $A$ and $B$ are low-rank
matrices (as in standard LoRA), and $\Sigma_X$ is a diagonal matrix generated
from each input token $X$. Notably, TopLoRA does not increase the rank of LoRA
weights but achieves more granular adaptation by learning token-wise LoRA
weights (i.e., token-wise input-output projections). Extensive experiments
across multiple models and datasets demonstrate that TopLoRA consistently
outperforms LoRA and its variants. The code is available at
https://github.com/Leopold1423/toplora-neurips25.

</details>


### [297] [Corpus Frequencies in Morphological Inflection: Do They Matter?](https://arxiv.org/abs/2510.23131)
*Tomáš Sourada,Jana Straková*

Main category: cs.CL

TL;DR: 该论文探讨了将实际语料中的词频信息融入形态变化任务，提升模型在现实场景下的表现，并在43种语言中验证频率感知训练的方法优势。


<details>
  <summary>Details</summary>
Motivation: 现有形态变化系统通常将所有词条等同处理，忽视了实际语言中不同词的使用频率差异。然而在真实应用中，用户输入的单词频率往往符合自然文本的分布，因此有必要将词频信息纳入模型开发流程。

Method: 论文在三个方面引入词频信息：(1) 数据集的划分采用兼顾词根区分和词频分布的策略；(2) 评估指标除传统的type accuracy外，引入token accuracy以更贴近实际应用表现；(3) 在训练数据采样阶段提出了频率感知采样方法，使高频词更常被采样。

Result: 实验证明，频率感知训练在43种语言中有26种表现优于传统均匀采样方法。

Conclusion: 引入词频信息可以更好地反映现实世界中的词形变化需求，频率感知训练对大多数语言有效，有助于提升形态变化系统的实用价值和实际部署效果。

Abstract: The traditional approach to morphological inflection (the task of modifying a
base word (lemma) to express grammatical categories) has been, for decades, to
consider lexical entries of lemma-tag-form triples uniformly, lacking any
information about their frequency distribution. However, in production
deployment, one might expect the user inputs to reflect a real-world
distribution of frequencies in natural texts. With future deployment in mind,
we explore the incorporation of corpus frequency information into the task of
morphological inflection along three key dimensions during system development:
(i) for train-dev-test split, we combine a lemma-disjoint approach, which
evaluates the model's generalization capabilities, with a frequency-weighted
strategy to better reflect the realistic distribution of items across different
frequency bands in training and test sets; (ii) for evaluation, we complement
the standard type accuracy (often referred to simply as accuracy), which treats
all items equally regardless of frequency, with token accuracy, which assigns
greater weight to frequent words and better approximates performance on running
text; (iii) for training data sampling, we introduce a method novel in the
context of inflection, frequency-aware training, which explicitly incorporates
word frequency into the sampling process. We show that frequency-aware training
outperforms uniform sampling in 26 out of 43 languages.

</details>


### [298] [ENTP: Enhancing Low-Quality SFT Data via Neural-Symbolic Text Purge-Mix](https://arxiv.org/abs/2510.23160)
*Zile Yang,Ling Li,Na Di,Jinlong Pang,Yao Zhou,Hao Cheng,Bo Han,Jiaheng Wei*

Main category: cs.CL

TL;DR: 本文提出ENTP框架，通过符号净化和神经重建，提升了低质量SFT数据的利用率，显著改善了LLM指令微调效果。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs的SFT通常只选高质量数据，忽视了低质量数据中的潜在价值，而且现有筛选机制并不完美，导致资源浪费。

Method: ENTP框架由两部分组成：符号模块用统计先验识别并剪除噪音样本，神经模块依靠潜在表示和模型知识重构并丰富指令-回复对，从而提升数据的信息量与多样性。

Result: 通过实验，ENTP增强的数据集（仅由低质量数据生成）在五个基准测试中超过了13种主流数据选择方法，甚至优于直接用原300K全部数据微调。

Conclusion: 低质量数据经过智能净化和合成后可极大提升模型表现，强调了合理挖掘与再利用低质量数据对高效指令对齐的重要性。

Abstract: Supervised Fine-Tuning (SFT) adapts pre-trained Large Language Models (LLMs)
to domain-specific instructions by training on a carefully curated subset of
high-quality instruction-response pairs, typically drawn from a larger dataset
that often contains many low-quality or noisy samples. However, existing
quality-first paradigms often overlook valuable signals in discarded
low-quality data and rely on imperfect quality filters. We introduce ENTP
(Enhancing low-quality SFT data via Neural-symbolic Text Purge-Mix), a
framework that revitalizes low-quality corpora through symbolic purification
and neural reconstruction. The symbolic module identifies and prunes noisy
samples based on statistical priors, while the neural component synthesizes
enriched instruction-response pairs by leveraging latent representations and
model knowledge. This neural-symbolic synergy enhances data informativeness and
diversity. Experiments show that ENTP-augmented datasets, constructed
exclusively from low-quality data, outperform 13 established data-selection
baselines across five instruction-following benchmarks, and even surpass
fine-tuning on the full original dataset (approximately 300K examples). Our
results highlight the untapped potential of low-quality data and underscore the
importance of intelligent purification and synthesis for efficient instruction
alignment.

</details>


### [299] [Beyond Direct Generation: A Decomposed Approach to Well-Crafted Screenwriting with LLMs](https://arxiv.org/abs/2510.23163)
*Hang Lei,Shengyi Zong,Zhaoyan Li,Ziren Zhou,Hao Liu*

Main category: cs.CL

TL;DR: 本文提出了一种双阶段精炼（DSR）框架，以提升大语言模型（LLM）在剧本生成上的质量，通过将创意叙事与格式转换分开，显著提升了生成剧本的结构完整性与专业性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM端到端生成剧本方法往往只能模仿表面风格，难以兼顾创意叙事和严格的剧本格式，导致输出缺乏专业深度和结构完整性。

Method: 提出DSR双阶段精炼框架：第一阶段将提纲生成丰富的小说体叙事文本，第二阶段再将其转化为专业格式的剧本。为解决训练数据稀缺问题，采用逆向和正向混合数据合成方法，既分解现有剧本为训练输入，也生成高质量叙事文本作为目标。

Result: DSR在专业编剧的盲评中，相比Gemini-2.5-Pro等强基线取得75%胜率，达到人类水平的82.7%。

Conclusion: 分解式生成框架和针对性数据合成方法可有效提升LLM在复杂创意领域的专业表现，尤其适用于结构化需求强的任务如剧本创作。

Abstract: The screenplay serves as the foundation for television production, defining
narrative structure, character development, and dialogue. While Large Language
Models (LLMs) show great potential in creative writing, direct end-to-end
generation approaches often fail to produce well-crafted screenplays. We argue
this failure stems from forcing a single model to simultaneously master two
disparate capabilities: creative narrative construction and rigid format
adherence. The resulting outputs may mimic superficial style but lack the deep
structural integrity and storytelling substance required for professional use.
To enable LLMs to generate high-quality screenplays, we introduce Dual-Stage
Refinement (DSR), a decomposed framework that decouples creative narrative
generation from format conversion. The first stage transforms a brief outline
into rich, novel-style prose. The second stage refines this narrative into a
professionally formatted screenplay. This separation enables the model to
specialize in one distinct capability at each stage. A key challenge in
implementing DSR is the scarcity of paired outline-to-novel training data. We
address this through hybrid data synthesis: reverse synthesis deconstructs
existing screenplays into structured inputs, while forward synthesis leverages
these inputs to generate high-quality narrative texts as training targets.
Blind evaluations by professional screenwriters show that DSR achieves a 75%
win rate against strong baselines like Gemini-2.5-Pro and reaches 82.7% of
human-level performance. Our work demonstrates that decomposed generation
architecture with tailored data synthesis effectively specializes LLMs in
complex creative domains.

</details>


### [300] [MATCH: Task-Driven Code Evaluation through Contrastive Learning](https://arxiv.org/abs/2510.23169)
*Marah Ghoummaid,Vladimir Tchuiev,Ofek Glick,Michal Moschkovitz,Dotan Di Castro*

Main category: cs.CL

TL;DR: 该论文提出了一种全新的AI代码生成无参考评测方法MATCH，通过对比学习关联代码与任务描述，用于更准确地衡量生成代码与开发者意图的匹配程度。


<details>
  <summary>Details</summary>
Motivation: 当前AI代码生成广泛应用，但现有的评估方法如单元测试成本高、传统的文本相似度（BLEU、ROUGE）不能体现代码功能，CodeBERTScore等又依赖参考代码，而参考代码往往缺失，因此亟需一种高效、无参考的评估方法。

Method: 提出了MATCH指标，通过对比学习训练得到代码与自然语言任务描述的嵌入表示，再基于两者间的相似性对生成代码进行评估，无需参考代码。

Result: MATCH在多个编程语言上，功能正确性和与人类偏好的相关性均优于现有评测指标。

Conclusion: MATCH是一种更准确且实用的无参考代码评测新方法，有助于推动AI代码自动生成领域的发展与评测进步。

Abstract: AI-based code generation is increasingly prevalent, with GitHub Copilot
estimated to generate 46% of the code on GitHub. Accurately evaluating how well
generated code aligns with developer intent remains a critical challenge.
Traditional evaluation methods, such as unit tests, are often unscalable and
costly. Syntactic similarity metrics (e.g., BLEU, ROUGE) fail to capture code
functionality, and metrics like CodeBERTScore require reference code, which is
not always available. To address the gap in reference-free evaluation, with few
alternatives such as ICE-Score, this paper introduces MATCH, a novel
reference-free metric. MATCH uses Contrastive Learning to generate meaningful
embeddings for code and natural language task descriptions, enabling similarity
scoring that reflects how well generated code implements the task. We show that
MATCH achieves stronger correlations with functional correctness and human
preference than existing metrics across multiple programming languages.

</details>


### [301] [SI-Bench: Benchmarking Social Intelligence of Large Language Models in Human-to-Human Conversations](https://arxiv.org/abs/2510.23182)
*Shuai Huang,Wenxuan Zhao,Jun Gao*

Main category: cs.CL

TL;DR: 本文提出了一个新的评测基准SI-Bench，用于评估大语言模型（LLMs）在真实社交对话中的社交智能。实验发现，先进模型在推理上超过人类专家，但在回复质量上还有差距。


<details>
  <summary>Details</summary>
Motivation: 现有LLM的社交交互能力评估主要依赖模拟对话，难以反映真实社会互动中的语言风格和关系动态。作者希望通过更真实、更具代表性的评测体系弥补这一不足。

Method: 构建了涵盖2221条来自真实社交应用的多轮对话的新型评测基准SI-Bench，并对8种主流模型在312条对话上进行了人工标注评测，同时测试了链式思维（CoT）推理对性能的影响。

Result: 实验显示，最先进的LLM模型在复杂社交情境下的过程推理能力优于人类专家，但在回复内容质量上仍不及人类。同时，使用CoT方法可能反而降低模型在社交对话任务上的表现。

Conclusion: SI-Bench有效填补了LLM社交智能评测的空白，数据集已公开。当前LLM虽在部分推理任务上突出，但在真实对话回复质量方面仍需优化，未来需要进一步提升其社交能力。

Abstract: As large language models (LLMs) develop anthropomorphic abilities, they are
increasingly being deployed as autonomous agents to interact with humans.
However, evaluating their performance in realistic and complex social
interactions remains a significant challenge. Most previous research built
datasets through simulated agent-to-agent interactions, which fails to capture
the authentic linguistic styles and relational dynamics found in real human
conversations. To address this gap, we introduce SI-Bench, a novel benchmark
designed to evaluate aspects of social intelligence in LLMs. Grounded in broad
social science theories, SI-Bench contains 2,221 authentic multi-turn dialogues
collected from a social networking application. We further selected a subset of
312 dialogues for manual annotation across 8 major models. The experiments show
that SOTA models have surpassed the human expert in process reasoning under
complex social situations, yet they still fall behind humans in reply quality.
Moreover, introducing Chain-of-Thought (CoT) reasoning may degrade the
performance of LLMs in social dialogue tasks. All datasets are openly available
at https://github.com/SI-Bench/SI-Bench.git.

</details>


### [302] [DREaM: Drug-Drug Relation Extraction via Transfer Learning Method](https://arxiv.org/abs/2510.23189)
*Ali Fata,Hossein Rahmani,Parinaz Soltanzadeh,Amirhossein Derakhshan,Behrouz Minaei Bidgoli*

Main category: cs.CL

TL;DR: 本文提出了一种基于机器学习和大型语言模型（LLM）的药物关系抽取方法，可以有效识别药物之间的相互作用，并已在医学文本中验证。


<details>
  <summary>Details</summary>
Motivation: 目前专门针对药物关系抽取的数据集非常有限，给机器学习在该领域的应用带来了困难。需要迁移学习和新的方法来挖掘医学文本中的药物关系。

Method: 提出DREAM方法，首先利用受训的关系抽取模型识别医学文本中的药物实体关系，然后将模型应用于大规模医学语料，构建药物关系本体，最后利用大型语言模型（LLM）验证抽取结果的准确性。

Result: 在PubMed摘要子集上，LLM对71个抽取出的关系给出了同意，定量结果显示方法有效。同时，定性分析显示该方法能暴露医学领域内关系抽取存在的模糊性和挑战。

Conclusion: 结合关系抽取模型与LLM的方法能够自动构建高质量的药物关系本体，有助于药物间相互作用和不良反应研究，但医学文本中的歧义仍需关注。

Abstract: Relation extraction between drugs plays a crucial role in identifying drug
drug interactions and predicting side effects. The advancement of machine
learning methods in relation extraction, along with the development of large
medical text databases, has enabled the low cost extraction of such relations
compared to other approaches that typically require expert knowledge. However,
to the best of our knowledge, there are limited datasets specifically designed
for drug drug relation extraction currently available. Therefore, employing
transfer learning becomes necessary to apply machine learning methods in this
domain. In this study, we propose DREAM, a method that first employs a trained
relation extraction model to discover relations between entities and then
applies this model to a corpus of medical texts to construct an ontology of
drug relationships. The extracted relations are subsequently validated using a
large language model. Quantitative results indicate that the LLM agreed with 71
of the relations extracted from a subset of PubMed abstracts. Furthermore, our
qualitative analysis indicates that this approach can uncover ambiguities in
the medical domain, highlighting the challenges inherent in relation extraction
in this field.

</details>


### [303] [Process Reward Models for Sentence-Level Verification of LVLM Radiology Reports](https://arxiv.org/abs/2510.23217)
*Alois Thomas,Maya Varma,Jean-Benoit Delbrouck,Curtis P. Langlotz*

Main category: cs.CL

TL;DR: 本论文提出了一种实际可用、轻量级且与具体生成模型无关的句子级事实性检测方法（Process Reward Model, PRM），显著提升了大规模视觉-语言模型在医学影像报告自动生成中的安全性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 大规模视觉-语言模型（LVLMs）被广泛用于自动生成医学影像报告，但常常产生严重的、临床关键的幻觉（即错误事实），给临床实际应用带来巨大风险。现有检测方法要么粒度不足（未到句子级别），要么缺乏强泛化能力（仅适用于特定模型），亟需细粒度且通用的幻觉检测方法。

Method: 作者提出了一种基于句子级别的过程奖励模型（Process Reward Model, PRM），该模型结合临床上下文和前文，预测自动生成报告中每句话的事实正确性。PRM在MIMIC-CXR数据集上采用弱监督标签进行微调，且模型仅含0.5B参数，便于部署和迁移。PRM无需访问生成器内部状态，实现模型无关性。

Result: 实验表明，句子级PRM相比现有验证技术有明显提升：Matthews相关系数提升7.5%，AUROC提升1.8%。PRM具备较强泛化能力，对未见过的生成模型也适用。此外，利用PRM筛掉低质量报告后，报告整体的F1-CheXbert分数提升4.5%；引导加权best-of-N策略时，F1-CheXbert提升7.4%，BERTScore提升0.6%。

Conclusion: PRM在不依赖于模型内部激活信息的前提下，为医学影像报告生成提供了通用、轻量、安全的事实性把关方案，有望大幅降低临床幻觉风险，增强自动化报告的实际可信度和可用性。

Abstract: Automating radiology report generation with Large Vision-Language Models
(LVLMs) holds great potential, yet these models often produce clinically
critical hallucinations, posing serious risks. Existing hallucination detection
methods frequently lack the necessary sentence-level granularity or robust
generalization across different LVLM generators. We introduce a novel approach:
a sentence-level Process Reward Model (PRM) adapted for this vision-language
task. Our PRM predicts the factual correctness of each generated sentence,
conditioned on clinical context and preceding text. When fine-tuned on
MIMIC-CXR with weakly-supervised labels, a lightweight 0.5B-parameter PRM
outperforms existing verification techniques, demonstrating, for instance,
relative improvements of 7.5% in Matthews Correlation Coefficient and 1.8% in
AUROC over strong white-box baselines on outputs from one LVLM. Unlike methods
reliant on internal model states, our PRM demonstrates strong generalization to
an unseen LVLM. We further show its practical utility: PRM scores effectively
filter low-quality reports, improving F1-CheXbert scores by 4.5% (when
discarding the worst 10% of reports). Moreover, when guiding a novel weighted
best-of-N selection process on the MIMIC-CXR test set, our PRM show relative
improvements in clinical metrics of 7.4% for F1-CheXbert and 0.6% for
BERTScore. These results demonstrate that a lightweight, context-aware PRM
provides a model-agnostic safety layer for clinical LVLMs without access to
internal activations

</details>


### [304] [Are ASR foundation models generalized enough to capture features of regional dialects for low-resource languages?](https://arxiv.org/abs/2510.23252)
*Tawsif Tashwar Dipto,Azmol Hossain,Rubayet Sabbir Faruque,Md. Rezuwan Hassan,Kanij Fatema,Tanmoy Shome,Ruwad Naswan,Md. Foriduzzaman Zihad,Mohaymen Ul Anam,Nazia Tasnim,Hasan Mahmud,Md Kamrul Hasan,Md. Mehedi Hasan Shawon,Farig Sadeque,Tahsin Reasat*

Main category: cs.CL

TL;DR: 本文提出了一个78小时的孟加拉语语音转文本（STT）数据集Ben-10，用于研究区域方言对自动语音识别（ASR）的影响。实验发现，现有的语音基础模型在面对方言时表现不佳，但针对特定方言进行模型训练能有效缓解该问题。


<details>
  <summary>Details</summary>
Motivation: 目前大多关于语音识别的研究主要集中于标准语，对于低资源语言的区域方言支持有限。为深入了解方言变体对ASR性能的影响，作者希望构建专门的数据集并进行系统分析。

Method: 作者建立了一个包含78小时、带注释的孟加拉语方言语音数据集Ben-10，并采用语言学和数据驱动视角对方言对ASR的影响进行了评估。他们既测试了基础模型的零样本性能，也进行了特定方言的微调实验。

Result: 结果显示，目前所有深度学习模型在面对方言变化的语音数据时表现均不理想，无论是零样本还是微调设定。不过，若专门针对方言训练模型，可以在一定程度上缓解性能下降的问题。

Conclusion: 本文证明了深度学习语音识别模型对区域方言的适应性有限，方言专属模型训练是提升识别性能的有效方法。该数据集为资源受限环境下的ASR建模提供了重要的OOD基准资源，数据和代码已公开。

Abstract: Conventional research on speech recognition modeling relies on the canonical
form for most low-resource languages while automatic speech recognition (ASR)
for regional dialects is treated as a fine-tuning task. To investigate the
effects of dialectal variations on ASR we develop a 78-hour annotated Bengali
Speech-to-Text (STT) corpus named Ben-10. Investigation from linguistic and
data-driven perspectives shows that speech foundation models struggle heavily
in regional dialect ASR, both in zero-shot and fine-tuned settings. We observe
that all deep learning methods struggle to model speech data under dialectal
variations but dialect specific model training alleviates the issue. Our
dataset also serves as a out of-distribution (OOD) resource for ASR modeling
under constrained resources in ASR algorithms. The dataset and code developed
for this project are publicly available

</details>


### [305] [Mubeen AI: A Specialized Arabic Language Model for Heritage Preservation and User Intent Understanding](https://arxiv.org/abs/2510.23271)
*Mohammed Aljafari,Ismail Alturki,Ahmed Mori,Yehya Kadumi*

Main category: cs.CL

TL;DR: Mubeen是马萨拉特公司开发的一款专注于阿拉伯语深度理解的专用语言模型，通过原生阿拉伯数据训练，在语义和文化准确性上优于基于英译文本的模型，主要应用于伊斯兰学、阿拉伯语言学及文化遗产传承。其创新的'实用闭环架构'专注解决信息问答中的实际效用缺口。


<details>
  <summary>Details</summary>
Motivation: 当前阿拉伯语大模型多依赖英文数据翻译，存在意图识别和检索增强问答（RAG）表现不佳的问题，难以准确满足用户需求。为解决阿拉伯语言模型在文化、学科领域深度理解和实际应用效用不足的困境，推动符合沙特2030愿景的知识技术进步。

Method: 通过自主研发的阿拉伯语OCR技术将大量历史手稿数字化，结合权威著作、学术论文、学位论文等原生阿拉伯数据，采用深度语言工程框架训练。模型架构引入多学科专家模块与'实用闭环架构'以提升实际解答能力和用户核心需求满足。

Result: Mubeen模型在古典阿拉伯语、当代文献及地区方言的精确理解和回答能力上表现优异，通过原生数据训练实现语义和文化双重准确。'实用闭环架构'显著缓解了信息问答中的实用性缺口，提高了用户满意度。

Conclusion: Mubeen通过深度专业化与工程创新，成为在伊斯兰学、语言学及文化遗产等领域具高可靠度和文化适配力的阿拉伯语大模型，为沙特及阿拉伯世界的知识数字化与智能化应用提供有力支撑。

Abstract: Mubeen is a proprietary Arabic language model developed by MASARAT SA,
optimized for deep understanding of Arabic linguistics, Islamic studies, and
cultural heritage. Trained on an extensive collection of authentic Arabic
sources significantly expanded by digitizing historical manuscripts via a
proprietary Arabic OCR engine, the model incorporates seminal scholarly works
in linguistics, jurisprudence, hadith, and Quranic exegesis, alongside
thousands of academic theses and peer-reviewed research papers. Conditioned
through a deep linguistic engineering framework, Mubeen masters not just the
meaning but the eloquence of Arabic, enabling precise understanding across
classical texts, contemporary writing, and regional dialects with focus on
comprehending user intent and delivering accurate, contextually relevant
responses. Unlike other Arabic models relying on translated English data that
often fail in intent detection or retrieval-augmented generation (RAG), Mubeen
uses native Arabic sources to ensure cultural authenticity and accuracy. Its
core innovation is the Practical Closure Architecture, designed to solve the
"Utility Gap Crisis" where factually correct answers fail to resolve users'
core needs, forcing them into frustrating cycles of re-prompting. By
prioritizing clarity and decisive guidance, Mubeen transforms from an
information repository into a decisive guide, aligning with Saudi Vision 2030.
The model's architecture combines deep heritage specialization with
multi-disciplinary expert modules, enabling robust performance across both
cultural preservation and general knowledge domains.

</details>


### [306] [Code Aesthetics with Agentic Reward Feedback](https://arxiv.org/abs/2510.23272)
*Bang Xiao,Lingjie Jiang,Shaohan Huang,Tengchao Lv,Yupan Huang,Xun Wu,Lei Cui,Furu Wei*

Main category: cs.CL

TL;DR: 本文提出了一种提升大语言模型（LLM）生成代码美学质量的新方法，并构建了相关数据集和评价基准，显著提升了代码美观性和可用性。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在传统编程任务（如代码生成和修复）中表现优异，但在涉及视觉美感要求的任务上表现不佳。本文旨在解决LLM在代码美学上的短板，提升其生成代码的视觉和结构美感。

Method: 1. 构建AesCode-358K，这是一个聚焦代码美学的大规模指令微调数据集；2. 提出agentic reward feedback的多智能体奖励机制，对代码的可执行性、静态美学和交互美学多维打分反馈；3. 将上述信号整合进GRPO算法，提出GRPO-AR，实现代码功能与美学的联合优化；4. 构建OpenDesign数据集作为代码美学评测集。

Result: 在OpenDesign和PandasPlotBench等评测集上，经过AesCode-358K微调和agentic奖励反馈强化学习的模型性能明显提升。提出的AesCoder-4B模型在美学与功能性评测中超越了GPT-4o和GPT-4.1，且在仅用4B参数规模下逼近了数百亿级开源大模型。

Conclusion: 通过美学专用数据集与多维奖励强化优化，LLM在具备美学需求的编程任务上获得了极大提升，方法高效且模型参数规模可控，未来具有广泛应用潜力。

Abstract: Large Language Models (LLMs) have become valuable assistants for developers
in code-related tasks. While LLMs excel at traditional programming tasks such
as code generation and bug fixing, they struggle with visually-oriented coding
tasks, often producing suboptimal aesthetics. In this paper, we introduce a new
pipeline to enhance the aesthetic quality of LLM-generated code. We first
construct AesCode-358K, a large-scale instruction-tuning dataset focused on
code aesthetics. Next, we propose agentic reward feedback, a multi-agent system
that evaluates executability, static aesthetics, and interactive aesthetics.
Building on this, we develop GRPO-AR, which integrates these signals into the
GRPO algorithm for joint optimization of functionality and code aesthetics.
Finally, we develop OpenDesign, a benchmark for assessing code aesthetics.
Experimental results show that combining supervised fine-tuning on AesCode-358K
with reinforcement learning using agentic reward feedback significantly
improves performance on OpenDesign and also enhances results on existing
benchmarks such as PandasPlotBench. Notably, our AesCoder-4B surpasses GPT-4o
and GPT-4.1, and achieves performance comparable to large open-source models
with 480B-685B parameters, underscoring the effectiveness of our approach.

</details>


### [307] [A Cocktail-Party Benchmark: Multi-Modal dataset and Comparative Evaluation Results](https://arxiv.org/abs/2510.23276)
*Thai-Binh Nguyen,Katerina Zmolikova,Pingchuan Ma,Ngoc Quan Pham,Christian Fuegen,Alexander Waibel*

Main category: cs.CL

TL;DR: 本论文介绍了CHiME挑战赛中的多模态情境感知识别（MCoRec）任务，旨在通过结合音频、视觉和上下文线索，解决房间内重叠对话的识别问题，并报告了基线系统与数据采集流程。


<details>
  <summary>Details</summary>
Motivation: 随着真实世界中多方对话的普遍存在，尤其是在嘈杂、多人参与的场景下，单凭音频难以准确识别和恢复每位说话者的内容，因此亟需利用多模态信息来提升识别准确性。

Method: MCoRec任务通过采集包含100%重叠语音、自然分散对话的视频和音频数据，要求系统不仅对每位说话者转写内容，还需自动聚类还原独立的对话群组。论文同时报告了仅用音频与结合视觉线索的基线系统比较。

Result: 实验显示，仅音频处理的基线系统词错误率超过100%，而引入视觉线索后识别性能提升约50%，凸显多模态结合的有效性。

Conclusion: 多模态线索对于复杂场景下的多方对话识别至关重要，MCoRec为相关研究提供了新的任务和评测数据集，推动此类技术的发展。

Abstract: We introduce the task of Multi-Modal Context-Aware Recognition (MCoRec) in
the ninth CHiME Challenge, which addresses the cocktail-party problem of
overlapping conversations in a single-room setting using audio, visual, and
contextual cues. MCoRec captures natural multi-party conversations where the
recordings focus on unscripted, casual group chats, leading to extreme speech
overlap of up to 100% and highly fragmented conversational turns. The task
requires systems to answer the question "Who speaks when, what, and with whom?"
by jointly transcribing each speaker's speech and clustering them into their
respective conversations from audio-visual recordings. Audio-only baselines
exceed 100% word error rate, whereas incorporating visual cues yields
substantial 50% improvements, highlighting the importance of multi-modality. In
this manuscript, we present the motivation behind the task, outline the data
collection process, and report the baseline systems developed for the MCoRec.

</details>


### [308] [DCMM-SQL: Automated Data-Centric Pipeline and Multi-Model Collaboration Training for Text-to-SQL Model](https://arxiv.org/abs/2510.23284)
*Yuanzhen Xie,Liu Ye,Jiqun Chu,Mochi Gao,Hehuan Liu,Yunzhi Tan,Bo Hu,Zang Li*

Main category: cs.CL

TL;DR: 本文提出了一种自动化的数据中心化处理流程和多模型协作训练框架，在Text-to-SQL任务上显著提升了性能，并在轻量级模型上取得了第一名成绩。


<details>
  <summary>Details</summary>
Motivation: 尽管基于agent的方案和大型语言模型推动了Text-to-SQL任务进步，但数据质量和数据增强对于提升模型性能的系统性影响还缺乏研究，因此作者希望探索数据中心化策略如何推进Text-to-SQL任务。

Method: 1) 设计了全自动的数据修复和错误数据增强流程，可自动发现并修复训练集中的错误并增强难例数据；2) 提出多模型协作训练方案，让不同增强数据训练出来的模型协同工作；3) 通过模型集成策略整合多模型能力以提升解题准确率。

Result: 通过实验和消融研究，所提出的数据中心化自动流程和多模型互动迭代策略在Text-to-SQL任务上有效提升准确率，在70B参数量以内的轻量级模型组别中取得了第一。

Conclusion: 系统性地采用数据修复与增强流程，结合多模型互动和集成策略，对于提升Text-to-SQL任务性能有显著帮助，对未来相关领域有实际意义和参考价值。

Abstract: Text-to-SQL tasks have gained attractive improvements since the release of
ChatGPT. Among them, agent-based frameworks have been widely used in this
field. However, the impact of data-centric strategies on text-to-SQL tasks has
rarely been explored. In this paper, we systemically design a fully automated
data-centric pipeline for text-to-SQL tasks, including \emph{adaptive data
repair}, which can automatically find and fix errors in the training dataset;
and \emph{error data augmentation}, where we specifically diffuse and enhance
erroneous data predicted by the initially trained models. Meanwhile, we propose
a Multi-Model collaboration training schema, aiming to train multiple models
with different augmented data, enabling them to possess distinct capabilities
and work together to complement each other, because it has been found that the
capability of a single fine-tuned model is very limited. Furthermore, we
utilize an ensemble strategy to integrate the capabilities of multiple models
to solve a multiple-choice question, aiming to further improve the accuracy of
text-to-SQL tasks. The experiment results and ablation study have demonstrated
the effectiveness of data-centric pipeline and Multi-Model(MM) interactive
iterative strategies, achieving first place in lightweight text-to-SQL models
(within 70B).

</details>


### [309] [Arabic Little STT: Arabic Children Speech Recognition Dataset](https://arxiv.org/abs/2510.23319)
*Mouhand Alkadri,Dania Desouki,Khloud Al Jallad*

Main category: cs.CL

TL;DR: 研究提出了Arabic Little STT数据集，专为研究阿拉伯儿童语音识别而设计，填补了该领域数据匮乏的缺口，并评估了Whisper模型在儿童语音上的表现。


<details>
  <summary>Details</summary>
Motivation: 目前人工智能语音识别系统在低资源语言（如阿拉伯语）尤其是儿童语音方面缺少高质量数据集，限制了ASR系统在这些场景下的性能提升。

Method: 研究团队创建了Levantine方言的阿拉伯儿童语音数据集Arabic Little STT，并系统评测了八种Whisper语音识别模型在该数据集与成人阿拉伯语数据集上的表现对比。

Result: Whisper系列模型在儿童阿拉伯语语音上的表现远逊于成人，最佳模型Large_v3的词错误率高达0.66，而在成人语音数据集上的词错误率低于0.20。该现象与已有英文语音识别研究结果一致。

Conclusion: 儿童语音数据在ASR开发中的重要性被再次强调，显示出亟需为儿童开发更具包容性且符合法律伦理的数据基线与模型，相关数据采集也需要严格隐私保护。该数据集的公开有望促进未来阿拉伯语儿童语音识别技术的公平与进步。

Abstract: The performance of Artificial Intelligence (AI) systems fundamentally depends
on high-quality training data. However, low-resource languages like Arabic
suffer from severe data scarcity. Moreover, the absence of child-specific
speech corpora is an essential gap that poses significant challenges. To
address this gap, we present our created dataset, Arabic Little STT, a dataset
of Levantine Arabic child speech recorded in classrooms, containing 355
utterances from 288 children (ages 6 - 13). We further conduct a systematic
assessment of Whisper, a state-of-the-art automatic speech recognition (ASR)
model, on this dataset and compare its performance with adult Arabic
benchmarks. Our evaluation across eight Whisper variants reveals that even the
best-performing model (Large_v3) struggles significantly, achieving a 0.66 word
error rate (WER) on child speech, starkly contrasting with its sub 0.20 WER on
adult datasets. These results align with other research on English speech.
Results highlight the critical need for dedicated child speech benchmarks and
inclusive training data in ASR development. Emphasizing that such data must be
governed by strict ethical and privacy frameworks to protect sensitive child
information. We hope that this study provides an initial step for future work
on equitable speech technologies for Arabic-speaking children. We hope that our
publicly available dataset enrich the children's demographic representation in
ASR datasets.

</details>


### [310] [Adaptive Blockwise Search: Inference-Time Alignment for Large Language Models](https://arxiv.org/abs/2510.23334)
*Mohammad Atif Quamar,Mohammad Areeb,Nishant Sharma,Ananth Shreekumar,Jonathan Rosenthal,Muslum Ozgur Ozmen,Mikhail Kuznetsov,Z. Berkay Celik*

Main category: cs.CL

TL;DR: 论文提出了一种新的推理阶段对齐方法AdaSearch，通过自适应分配计算资源，提高了LLM对齐效果，显著优于主流方法。


<details>
  <summary>Details</summary>
Motivation: 推理阶段对齐方法虽然灵活，但对所有token计算资源分配均匀，常导致对齐能力不足。作者认为，响应前几个token对对齐任务影响最大，因此希望有选择性地分配计算资源，以提升对齐效果。

Method: 提出AdaSearch方法，采用块式(blockwise)搜索策略，通过自适应采样机制集中计算资源在关键初始token上，并进一步提出了树搜索版本AdaBeam。方法在有限计算预算下动态调整搜索重点。

Result: 在8个LLM和多个任务上评估，AdaSearch在生成无害内容、情感控制和数学推理等任务中，相比Best-of-N和微调等基线方法，胜率提升超过10%。

Conclusion: AdaSearch及其衍生方法在推理阶段实现了更高效的对齐，能够在多数对齐任务上显著优于现有方法，尤其适合计算预算有限时的推理优化场景。

Abstract: LLM alignment remains a critical challenge. Inference-time methods provide a
flexible alternative to fine-tuning, but their uniform computational effort
often yields suboptimal alignment. We hypothesize that for many alignment
tasks, the initial tokens of a response are disproportionately more critical.
To leverage this principle, we introduce AdaSearch, a novel blockwise search
strategy. It adaptively allocates a fixed computational budget using a sampling
schedule, focusing search effort on these critical tokens. We apply AdaSearch
to sequential decoding and introduce its tree-search counterpart, AdaBeam. Our
comprehensive evaluation across eight LLMs demonstrates that AdaSearch
outperforms strong Best-of-N and fine-tuning baselines. Specifically, win-rates
improve by over 10% for harmlessness generation, controlled sentiment
generation, and for mathematical reasoning tasks relative to Best-of-N.

</details>


### [311] [BaZi-Based Character Simulation Benchmark: Evaluating AI on Temporal and Persona Reasoning](https://arxiv.org/abs/2510.23337)
*Siyuan Zheng,Pai Liu,Xi Chen,Jizheng Dong,Sihan Jia*

Main category: cs.CL

TL;DR: 本文提出了一种结合八字（BaZi）符号推理与大语言模型（LLMs）的方法，以真实人类经验为基础，生成具有人格一致性和文化特色的虚拟角色，并建立了首个BaZi人格推理QA数据集。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟角色生成方法高度依赖带标注的数据或人工设定的人格提示，导致难以扩展且真实性不足，缺乏文化相关性。作者希望通过引入BaZi传统命理学，将人类经验与符号推理结合，以提升角色的真实性和情境连贯性。

Method: 作者首先构建了一个包含财富、健康、亲情、事业和人际关系等五类真实人类经验的BaZi人格推理问答数据集。随后，提出了BaZi-LLM系统，将八字符号推理机制与大语言模型结合，动态地生成细粒度、具时序变化特点的虚拟人格。该系统还能根据不同BaZi信息生成相应的虚拟角色响应。

Result: 与主流LLM模型（如DeepSeek-v3、GPT-5-mini）相比，BaZi-LLM系统在该数据集上表现出30.3%至62.6%的准确率提升。当输入错误的八字信息时，准确率下降20%-45%，验证其对文化符号推理的敏感性和必要性。

Conclusion: 作者的方法有效地提升了虚拟角色生成的文化真实性和情境连贯性，通过符号-大模型集成，为高度拟人化、文化依托的虚拟角色模拟提供了新思路。

Abstract: Human-like virtual characters are crucial for games, storytelling, and
virtual reality, yet current methods rely heavily on annotated data or
handcrafted persona prompts, making it difficult to scale up and generate
realistic, contextually coherent personas. We create the first QA dataset for
BaZi-based persona reasoning, where real human experiences categorized into
wealth, health, kinship, career, and relationships are represented as
life-event questions and answers. Furthermore, we propose the first BaZi-LLM
system that integrates symbolic reasoning with large language models to
generate temporally dynamic and fine-grained virtual personas. Compared with
mainstream LLMs such as DeepSeek-v3 and GPT-5-mini, our method achieves a
30.3%-62.6% accuracy improvement. In addition, when incorrect BaZi information
is used, our model's accuracy drops by 20%-45%, showing the potential of
culturally grounded symbolic-LLM integration for realistic character
simulation.

</details>


### [312] [LightKGG: Simple and Efficient Knowledge Graph Generation from Textual Data](https://arxiv.org/abs/2510.23341)
*Teng Lin*

Main category: cs.CL

TL;DR: 本文提出了一种新方法LightKGG，可以用小型语言模型（SLM）高效地从文本中抽取高质量知识图谱，大幅降低对大模型和高计算资源的依赖。


<details>
  <summary>Details</summary>
Motivation: 当前高质量知识图谱稀缺，现有自动抽取方法要么依赖容易出错的模式匹配，要么需要消耗大量算力的LLM，不适合资源有限的场景。

Method: 提出LightKGG框架，包括两项关键技术创新：1）上下文融合图抽取，将上下文与节点、边整合为统一结构，减少复杂语义处理需求并保留更多关键信息；2）结构增强的关系推断，利用图的拓扑结构高效推断关系，无需复杂的语言理解能力。

Result: LightKGG能在低硬件资源条件下，高效准确地构建知识图谱，且在结构化NLP任务中优化了SLM的效率。

Conclusion: 本研究为知识图谱自动抽取和实际部署之间搭建了桥梁，提出了可科学优化SLM效率的方法，有助于知识抽取技术的广泛应用。

Abstract: The scarcity of high-quality knowledge graphs (KGs) remains a critical
bottleneck for downstream AI applications, as existing extraction methods rely
heavily on error-prone pattern-matching techniques or resource-intensive large
language models (LLMs). While recent tools leverage LLMs to generate KGs, their
computational demands limit accessibility for low-resource environments. Our
paper introduces LightKGG, a novel framework that enables efficient KG
extraction from textual data using small-scale language models (SLMs) through
two key technical innovations: (1) Context-integrated Graph extraction
integrates contextual information with nodes and edges into a unified graph
structure, reducing the reliance on complex semantic processing while
maintaining more key information; (2) Topology-enhanced relationship inference
leverages the inherent topology of the extracted graph to efficiently infer
relationships, enabling relationship discovery without relying on complex
language understanding capabilities of LLMs. By enabling accurate KG
construction with minimal hardware requirements, this work bridges the gap
between automated knowledge extraction and practical deployment scenarios while
introducing scientifically rigorous methods for optimizing SLM efficiency in
structured NLP tasks.

</details>


### [313] [How AI Forecasts AI Jobs: Benchmarking LLM Predictions of Labor Market Changes](https://arxiv.org/abs/2510.23358)
*Sheri Osborn,Rohit Valecha,H. Raghav Rao,Dan Sass,Anthony Rios*

Main category: cs.CL

TL;DR: 本论文提出了一个新基准，评估大型语言模型（LLMs）预测AI对劳动市场影响的能力，并公开该基准支持未来研究。


<details>
  <summary>Details</summary>
Motivation: 当前AI正在重塑劳动力市场，但缺乏系统预测其对就业影响的工具。该研究旨在弥补这一空白，开发和评估LLM在预测行业变动中的有效性。

Method: 作者整合了美国行业级职位发布高频指数和全球AI带来的职业变化预测数据，设计成时间分割的预测任务，防止信息泄漏。采用多种prompt策略（如结构化任务、角色扮演、混合式）评测不同模型家族，在定量准确性与定性一致性上进行对比。

Result: 结构化任务型prompt能显著提升预测稳定性，角色扮演prompt在短期趋势上有优势，但不同产业和预测周期下表现差异较大。

Conclusion: LLM可辅助就业趋势预测，但效果受prompt设计和任务特性影响，需领域感知的提示词与严谨评测。公开基准促进未来劳动力预测相关研究和经济推理能力提升。

Abstract: Artificial intelligence is reshaping labor markets, yet we lack tools to
systematically forecast its effects on employment. This paper introduces a
benchmark for evaluating how well large language models (LLMs) can anticipate
changes in job demand, especially in occupations affected by AI. Existing
research has shown that LLMs can extract sentiment, summarize economic reports,
and emulate forecaster behavior, but little work has assessed their use for
forward-looking labor prediction. Our benchmark combines two complementary
datasets: a high-frequency index of sector-level job postings in the United
States, and a global dataset of projected occupational changes due to AI
adoption. We format these data into forecasting tasks with clear temporal
splits, minimizing the risk of information leakage. We then evaluate LLMs using
multiple prompting strategies, comparing task-scaffolded, persona-driven, and
hybrid approaches across model families. We assess both quantitative accuracy
and qualitative consistency over time. Results show that structured task
prompts consistently improve forecast stability, while persona prompts offer
advantages on short-term trends. However, performance varies significantly
across sectors and horizons, highlighting the need for domain-aware prompting
and rigorous evaluation protocols. By releasing our benchmark, we aim to
support future research on labor forecasting, prompt design, and LLM-based
economic reasoning. This work contributes to a growing body of research on how
LLMs interact with real-world economic data, and provides a reproducible
testbed for studying the limits and opportunities of AI as a forecasting tool
in the context of labor markets.

</details>


### [314] [Detecting Religious Language in Climate Discourse](https://arxiv.org/abs/2510.23395)
*Evy Beijen,Pien Pieterse,Yusuf Çelik,Willem Th. van Peursen,Sandjai Bhulai,Meike Morren*

Main category: cs.CL

TL;DR: 本文探讨宗教性语言在气候变化相关文本中的出现和识别，比较基于规则与大模型的方法，揭示宗教语言检测的挑战和意义。


<details>
  <summary>Details</summary>
Motivation: 随着宗教性语言渗透至表面上世俗的领域，如环境保护和气候变化讨论，理解宗教性语言的表现和作用变得重要。作者希望理解宗教性语言如何在不同组织（宗教/非宗教NGO）文本中体现，并评估其检测方法。

Method: 作者提出了两种分析方法：一是基于生态神学文献构建的宗教术语分层树的规则模型；二是在零样本设置下应用大语言模型（LLMs）。利用包含88万余句子的语料库，比较两种方法在检测宗教性语言方面的表现及其异同。

Result: 结果表明，基于规则的方法比大语言模型检测出更多宗教性语句，两者在部分文本判断上一致，也表现出分歧。

Conclusion: 研究表明，宗教性语言检测存在方法学挑战——应仅凭词表还是结合语境，依然存争议。该研究为宗教研究中的数字分析方法提供了新见解，揭示了神圣内容在气候话语中持续存在的复杂性。

Abstract: Religious language continues to permeate contemporary discourse, even in
ostensibly secular domains such as environmental activism and climate change
debates. This paper investigates how explicit and implicit forms of religious
language appear in climate-related texts produced by secular and religious
nongovernmental organizations (NGOs). We introduce a dual methodological
approach: a rule-based model using a hierarchical tree of religious terms
derived from ecotheology literature, and large language models (LLMs) operating
in a zero-shot setting. Using a dataset of more than 880,000 sentences, we
compare how these methods detect religious language and analyze points of
agreement and divergence. The results show that the rule-based method
consistently labels more sentences as religious than LLMs. These findings
highlight not only the methodological challenges of computationally detecting
religious language but also the broader tension over whether religious language
should be defined by vocabulary alone or by contextual meaning. This study
contributes to digital methods in religious studies by demonstrating both the
potential and the limitations of approaches for analyzing how the sacred
persists in climate discourse.

</details>


### [315] [EMTSF:Extraordinary Mixture of SOTA Models for Time Series Forecasting](https://arxiv.org/abs/2510.23396)
*Musleh Alharthi,Kaleel Mahmood,Sarosh Patel,Ausif Mahmood*

Main category: cs.CL

TL;DR: 本文提出了一种基于Transformer的专家混合（MoE）框架，通过结合多种前沿时序预测模型，在标准基准测试中实现了优于所有现有方法的表现。


<details>
  <summary>Details</summary>
Motivation: 近年来Transformer及其变体在时序预测领域取得了出色的表现，但其有效性屡受质疑，常被更简单或不同设计的模型（如线性模型或LLM模型）挑战。作者希望借助多个架构的互补性，进一步提升时序预测效果。

Method: 本文采用专家混合（MoE）框架，通过Transformer为基础的门控网络，将xLSTM、增强线性模型、PatchTST、minGRU等多种当前顶尖的时序模型进行整合，实现模型多样性和互补性。

Result: 实验证明，所提MoE模型在标准时序预测基准上，整体性能超过包括最新MoE框架在内的所有现有模型。

Conclusion: 将多个高性能时序模型集成为基于Transformer门控的MoE框架，可显著提升时序预测效果，优于其他单一或现有混合方法。

Abstract: The immense success of the Transformer architecture
  in Natural Language Processing has led to its adoption in Time Se ries
Forecasting (TSF), where superior performance has been shown.
  However, a recent important paper questioned their effectiveness by
  demonstrating that a simple single layer linear model outperforms
  Transformer-based models. This was soon shown to be not as valid,
  by a better transformer-based model termed PatchTST. More re cently, TimeLLM
demonstrated even better results by repurposing a
  Large Language Model (LLM) for the TSF domain. Again, a follow
  up paper challenged this by demonstrating that removing the LLM
  component or replacing it with a basic attention layer in fact yields
  better performance. One of the challenges in forecasting is the fact
  that TSF data favors the more recent past, and is sometimes subject
  to unpredictable events. Based upon these recent insights in TSF, we
  propose a strong Mixture of Experts (MoE) framework. Our method
  combines the state-of-the-art (SOTA) models including xLSTM, en hanced
Linear, PatchTST, and minGRU, among others. This set of
  complimentary and diverse models for TSF are integrated in a Trans former
based MoE gating network. Our proposed model outperforms
  all existing TSF models on standard benchmarks, surpassing even the
  latest approaches based on MoE frameworks.

</details>


### [316] [Omni-Reward: Towards Generalist Omni-Modal Reward Modeling with Free-Form Preferences](https://arxiv.org/abs/2510.23451)
*Zhuoran Jin,Hongbang Yuan,Kejian Zhu,Jiachun Li,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种名为Omni-Reward的新型奖励模型，能够支持多种模态（文本、图像、视频、音频、3D）和自由形式的偏好表达，并在首个多模态奖励模型基准Omni-RewardBench上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型大多只关注文本和图像，忽视了视频、音频等多模态数据；而且采用简单的二元偏好训练，无法捕捉多样化和复杂的个性化偏好。

Method: 提出了包含三部分的Omni-Reward体系：1）建立了覆盖九项任务、五种模态的自由形式偏好的奖励模型基准Omni-RewardBench；2）构建了包含24.8万个偏好对和6.9万个指令微调对的多模态偏好数据集Omni-RewardData；3）设计了包括判别式和生成式的Omni-RewardModel奖励模型。

Result: Omni-RewardModel不仅在Omni-RewardBench表现优异，在其它主流奖励模型基准测试上也有良好成绩。

Conclusion: Omni-Reward体系推动了通用多模态奖励建模的发展，在处理复杂、个性化偏好和多模态输入方面取得了重要进展。

Abstract: Reward models (RMs) play a critical role in aligning AI behaviors with human
preferences, yet they face two fundamental challenges: (1) Modality Imbalance,
where most RMs are mainly focused on text and image modalities, offering
limited support for video, audio, and other modalities; and (2) Preference
Rigidity, where training on fixed binary preference pairs fails to capture the
complexity and diversity of personalized preferences. To address the above
challenges, we propose Omni-Reward, a step toward generalist omni-modal reward
modeling with support for free-form preferences, consisting of: (1) Evaluation:
We introduce Omni-RewardBench, the first omni-modal RM benchmark with free-form
preferences, covering nine tasks across five modalities including text, image,
video, audio, and 3D; (2) Data: We construct Omni-RewardData, a multimodal
preference dataset comprising 248K general preference pairs and 69K
instruction-tuning pairs for training generalist omni-modal RMs; (3) Model: We
propose Omni-RewardModel, which includes both discriminative and generative
RMs, and achieves strong performance on Omni-RewardBench as well as other
widely used reward modeling benchmarks.

</details>


### [317] [BrowseConf: Confidence-Guided Test-Time Scaling for Web Agents](https://arxiv.org/abs/2510.23458)
*Litu Ou,Kuan Li,Huifeng Yin,Liwen Zhang,Zhongwang Zhang,Xixi Wu,Rui Ye,Zile Qiao,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.CL

TL;DR: 本文关注于大语言模型（LLM）在多轮复杂任务中的信心表达，提出了基于信心评分的测试时自适应重复机制，从而在保证性能的前提下有效降低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 现有关于LLM信心水平的研究大都集中在单轮场景，对于实际应用中更为常见的多轮复杂交互，其信心表达及应用机制尚不明朗。因此，探索LLM在多轮推理过程中的信心传递，对提升模型可靠性及用户体验具有现实意义。

Method: 作者首先实验性分析了开源代理型大模型在多轮任务中的信心与准确率的关系，发现低信心时准确率极低，高信心时准确率大幅提升。在此基础上，提出了测试时自适应重复（Test-Time Scaling, TTS）方法：模型通过信心评分对答案质量进行反馈，并在信心未达阈值时自发尝试生成更优答案，直至满意为止。

Result: 实验证明，通过该TTS方法，在保持结果竞争力的同时显著减少了token消耗。与传统的固定预算TTS方法相比，效率更高，资源利用更优。

Conclusion: 大语言模型可以较好地通过自身信心分数衡量和传递答案可靠性。基于信心驱动的自适应答复机制，不仅提升模型实用性，还能有效降低计算资源消耗。

Abstract: Confidence in LLMs is a useful indicator of model uncertainty and answer
reliability. Existing work mainly focused on single-turn scenarios, while
research on confidence in complex multi-turn interactions is limited. In this
paper, we investigate whether LLM-based search agents have the ability to
communicate their own confidence through verbalized confidence scores after
long sequences of actions, a significantly more challenging task compared to
outputting confidence in a single interaction. Experimenting on open-source
agentic models, we first find that models exhibit much higher task accuracy at
high confidence while having near-zero accuracy when confidence is low. Based
on this observation, we propose Test-Time Scaling (TTS) methods that use
confidence scores to determine answer quality, encourage the model to try again
until reaching a satisfactory confidence level. Results show that our proposed
methods significantly reduce token consumption while demonstrating competitive
performance compared to baseline fixed budget TTS methods.

</details>


### [318] [Evaluating Large Language Models for Stance Detection on Financial Targets from SEC Filing Reports and Earnings Call Transcripts](https://arxiv.org/abs/2510.23464)
*Nikesh Gyawali,Doina Caragea,Alex Vasenkov,Cornelia Caragea*

Main category: cs.CL

TL;DR: 本文提出了面向金融领域，针对关键财务指标（债务、每股收益和销售额）的句子级立场检测数据集，并系统评估了大型语言模型（LLM）在此任务上的表现，发现结合CoT的少样本提示效果最好。


<details>
  <summary>Details</summary>
Motivation: 以往金融领域的情感分析依赖大量标注数据且难以细致到具体财务目标的句子级立场判断。实际应用中，投资者、审计员及监管者需要更精细、面向指标的文本分析工具。

Method: 作者从美国SEC 10-K年报及季度电话会议提取涉及三大财务指标的句子，并用ChatGPT-o3-pro模型在严格人工验证下进行正、负、中立立场标注。基于该数据集，采用零样本、少样本及链式思维（CoT）提示系统评估多种LLM的效果。

Result: 实验显示，相较于有监督基线，少样本+CoT提示策略在立场判别方面表现最佳。同时，不同类型（SEC和ECT）数据集上模型表现不同。

Conclusion: LLMs在无需大量标注数据的情况下，能够实现针对关键财务目标的句子级立场检测，具备现实金融领域应用价值。

Abstract: Financial narratives from U.S. Securities and Exchange Commission (SEC)
filing reports and quarterly earnings call transcripts (ECTs) are very
important for investors, auditors, and regulators. However, their length,
financial jargon, and nuanced language make fine-grained analysis difficult.
Prior sentiment analysis in the financial domain required a large, expensive
labeled dataset, making the sentence-level stance towards specific financial
targets challenging. In this work, we introduce a sentence-level corpus for
stance detection focused on three core financial metrics: debt, earnings per
share (EPS), and sales. The sentences were extracted from Form 10-K annual
reports and ECTs, and labeled for stance (positive, negative, neutral) using
the advanced ChatGPT-o3-pro model under rigorous human validation. Using this
corpus, we conduct a systematic evaluation of modern large language models
(LLMs) using zero-shot, few-shot, and Chain-of-Thought (CoT) prompting
strategies. Our results show that few-shot with CoT prompting performs best
compared to supervised baselines, and LLMs' performance varies across the SEC
and ECT datasets. Our findings highlight the practical viability of leveraging
LLMs for target-specific stance in the financial domain without requiring
extensive labeled data.

</details>


### [319] [MMTutorBench: The First Multimodal Benchmark for AI Math Tutoring](https://arxiv.org/abs/2510.23477)
*Tengchao Yang,Sichen Guo,Mengzhao Jia,Jiaming Su,Yuanyang Liu,Zhihan Zhang,Meng Jiang*

Main category: cs.CL

TL;DR: 本文提出了MMTutorBench——首个专为AI数学辅导设计的基准测试集，涵盖685道题及细粒度评价标准，用以全面评估多模态大语言模型（MLLMs）在诊断学生难点、分步指导等辅导关键能力上的表现。试验显示，主流MLLMs与人类辅导之间仍有明显差距，MMTutorBench能有效促进相关技术进步。


<details>
  <summary>Details</summary>
Motivation: 目前多模态大语言模型（MLLMs）在数学问题求解上取得进展，但现有基准多聚焦于解题本身，忽略了AI在发现学生困难、分步引导等教学核心能力上的评估需求。为推动AI更好地辅助数学辅导，亟需相关领域的专业基准。

Method: 作者设计了MMTutorBench，包括685个围绕教学关键步骤编制的数学问题，每题配有六个维度的问题特定评分标准。基准划分为'洞察发现'、'操作制定'、'操作执行'三类子任务，并采用rubric（评分细则）对12种主流MLLMs进行细致测评。同时，分析了OCR质量、few-shot提示等技术对结果的影响。

Result: 主流MLLMs在MMTutorBench上的表现与人类辅导存在较大差距；专有模型优于开源模型；OCR处理过程会显著降低AI辅导质量；Few-shot提示方式提升有限；所提出的基于rubric的LLM作为评估者具有高度可靠性。

Conclusion: MMTutorBench不仅反映了AI数学辅导领域的挑战，也为后续模型诊断和迭代提供了有价值的分析工具，有望推动更具教学能力与诊断性的AI辅导系统的发展。

Abstract: Effective math tutoring requires not only solving problems but also
diagnosing students' difficulties and guiding them step by step. While
multimodal large language models (MLLMs) show promise, existing benchmarks
largely overlook these tutoring skills. We introduce MMTutorBench, the first
benchmark for AI math tutoring, consisting of 685 problems built around
pedagogically significant key-steps. Each problem is paired with
problem-specific rubrics that enable fine-grained evaluation across six
dimensions, and structured into three tasks-Insight Discovery, Operation
Formulation, and Operation Execution. We evaluate 12 leading MLLMs and find
clear performance gaps between proprietary and open-source systems, substantial
room compared to human tutors, and consistent trends across input variants: OCR
pipelines degrade tutoring quality, few-shot prompting yields limited gains,
and our rubric-based LLM-as-a-Judge proves highly reliable. These results
highlight both the difficulty and diagnostic value of MMTutorBench for
advancing AI tutoring.

</details>


### [320] [M4FC: a Multimodal, Multilingual, Multicultural, Multitask Real-World Fact-Checking Dataset](https://arxiv.org/abs/2510.23508)
*Jiahui Geng,Jonathan Tonglet,Iryna Gurevych*

Main category: cs.CL

TL;DR: 该论文提出了一个新的多模态自动事实核查真实数据集M4FC，包含4982张图片及6980项声明，覆盖10种语言，支持6种多模态任务，并提供基线结果及代码。


<details>
  <summary>Details</summary>
Motivation: 现有多模态事实核查数据集样本数量有限、语言和任务种类稀缺、存在证据泄漏或依赖外部新闻集，无法满足多元化与高质量研究需求。

Method: 作者构建了M4FC数据集，收集22家专业机构验证的图片，涵盖多元文化和地理背景，并为每张图片配对一到多项声明（共6980项），声明用10种语言中的一至两种表达。数据集支持视觉声明抽取、发布者意图预测、虚假检测、图片语境化、地点核查和结论预测6项任务，并给出所有任务的基线实验结果；同时分析了中间任务对结论预测任务的影响。

Result: M4FC数据集成功构建，涵盖广泛语言、任务类型，真实、多元。此外，文中提供了全部任务的基线模型实验，并系统分析了多任务关系及中间任务对最终判决预测的提升作用。数据集及代码已公开。

Conclusion: M4FC突破了现有多模态自动事实核查数据集的诸多局限，为多元语种、多任务的事实核查研究提供坚实资源基础，能促进领域研究进步。

Abstract: Existing real-world datasets for multimodal automated fact-checking have
multiple limitations: they contain few instances, focus on only one or two
languages and tasks, suffer from evidence leakage, or depend on external sets
of news articles for sourcing true claims. To address these shortcomings, we
introduce M4FC, a new real-world dataset comprising 4,982 images paired with
6,980 claims. The images, verified by professional fact-checkers from 22
organizations, represent diverse cultural and geographic contexts. Each claim
is available in one or two out of ten languages. M4FC spans six multimodal
fact-checking tasks: visual claim extraction, claimant intent prediction, fake
detection, image contextualization, location verification, and verdict
prediction. We provide baseline results for all tasks and analyze how combining
intermediate tasks influence downstream verdict prediction performance. We make
our dataset and code available.

</details>


### [321] [IPQA: A Benchmark for Core Intent Identification in Personalized Question Answering](https://arxiv.org/abs/2510.23536)
*Jieyong Kim,Maryam Amirizaniani,Soojin Yoon,Dongha Lee*

Main category: cs.CL

TL;DR: 该论文提出了IPQA基准，用于衡量个性化问答中的核心意图识别能力，并发现现有模型在此任务上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 当前个性化问答系统只能评估回复质量或检索性能，未直接衡量系统识别用户核心意图的能力。而理解用户核心意图对于满足个性化需求至关重要。

Method: 作者提出“核心意图”概念，并基于满意化理论，通过用户在答案选择行为中推断核心意图。构建了包含多个领域的数据集，结合LLM标注、自动与人工质控，开发IPQA评测基准用于评估模型的核心意图识别能力。

Result: 实验结果显示，现有最先进的语言模型在个性化场景下难以准确识别用户核心意图，且随着问题复杂度增加表现进一步下降。

Conclusion: 当前模型核心意图识别能力不足，需要专门的数据集和评测体系推动个性化问答模型在理解用户深层需求方面取得进展，作者公开了相关数据和代码以促进后续研究。

Abstract: Intent identification serves as the foundation for generating appropriate
responses in personalized question answering (PQA). However, existing
benchmarks evaluate only response quality or retrieval performance without
directly measuring intent identification capabilities. This gap is critical
because without understanding which intents users prioritize, systems cannot
generate responses satisfying individual information needs. To address this, we
introduce the concept of core intents: intents users prioritize when selecting
answers to satisfy their information needs. To evaluate these core intents, we
propose IPQA, a benchmark for core Intent identification in Personalized
Question Answering. Since users do not explicitly state their prioritized
intents, we derive core intents from observable behavior patterns in answer
selection, grounded in satisficing theory where users choose answers meeting
their acceptance thresholds. We construct a dataset with various domains
through systematic filtering, LLM-based annotation, and rigorous quality
control combining automated verification with human validation. Experimental
evaluations across state-of-the-art language models reveal that current systems
struggle with core intent identification in personalized contexts. Models fail
to identify core intents from user histories, with performance degrading as
question complexity increases. The code and dataset will be made publicly
available to facilitate future research in this direction.

</details>


### [322] [LimRank: Less is More for Reasoning-Intensive Information Reranking](https://arxiv.org/abs/2510.23544)
*Tingyu Song,Yilun Zhao,Siyue Zhang,Chen Zhao,Arman Cohan*

Main category: cs.CL

TL;DR: 该论文提出了LIMRANK-SYNTHESIZER管道，用于合成高质量重排序数据，并通过极少量数据监督成功微调大模型LIMRANK，大幅减少数据和算力需求，依然取得了优异效果。


<details>
  <summary>Details</summary>
Motivation: 现有信息重排序任务通常依赖大规模微调LLM，算力和数据消耗高昂，亟需更高效的适配方式。

Method: 作者设计了LIMRANK-SYNTHESIZER，一个可复用、开源的数据合成管道，用以生成多样、复杂的重排序训练样本，并用这些合成数据对LIMRANK模型进行微调。

Result: 在BRIGHT（推理型检索）和FollowIR（指令型检索）两个评测基准上，LIMRANK模型仅用不到5%的常规数据量就取得了有竞争力的表现。消融实验也印证了LIMRANK-SYNTHESIZER和LIMRANK在多任务和下游检索、生成问题上的强泛化能力。

Conclusion: 通过少量高质量标注和合成数据，LLM可以有效适配重排序任务。所提出的LIMRANK-SYNTHESIZER管道提升了训练效率与模型泛化能力，对后续知识密集型和检索相关任务有较高参考价值。

Abstract: Existing approaches typically rely on large-scale fine-tuning to adapt LLMs
for information reranking tasks, which is computationally expensive. In this
work, we demonstrate that modern LLMs can be effectively adapted using only
minimal, high-quality supervision. To enable this, we design
LIMRANK-SYNTHESIZER, a reusable and open-source pipeline for generating
diverse, challenging, and realistic reranking examples. Using this synthetic
data, we fine-tune our reranker model, LIMRANK. We evaluate LIMRANK on two
challenging benchmarks, i.e., BRIGHT for reasoning-intensive retrieval and
FollowIR for instruction-following retrieval. Our experiments demonstrate that
LIMRANK achieves competitive performance, while being trained on less than 5%
of the data typically used in prior work. Further ablation studies demonstrate
the effectiveness of LIMRANK-SYNTHESIZER and the strong generalization
capabilities of LIMRANK across downstream tasks, including scientific
literature search and retrieval-augmented generation for knowledge-intensive
problem solving.

</details>


### [323] [Hope Speech Detection in Social Media English Corpora: Performance of Traditional and Transformer Models](https://arxiv.org/abs/2510.23585)
*Luis Ramos,Hiram Calvo,Olga Kolesnikova*

Main category: cs.CL

TL;DR: 本论文评估了主流机器学习模型与微调后的Transformer模型在希望言论（hope speech）识别任务上的表现，发现Transformer模型在准确率和召回率上表现更优。


<details>
  <summary>Details</summary>
Motivation: 社交媒体中存在大量鼓励性、积极性的希望言论，自动识别这些言论对于理解网络正能量、构建更健康的网络环境具有实际意义。

Method: 作者使用了已经划分好的希望言论数据集，分别采用传统的SVM（线性核、RBF核）、逻辑回归、朴素贝叶斯等机器学习方法，以及微调的Transformer模型进行训练和测试，并对比分析了它们在开发集上的表现。

Result: 在开发集上，线性核SVM和逻辑回归均取得了0.78的macro-F1分数；RBF核SVM为0.77；朴素贝叶斯为0.75。Transformer模型整体表现更佳，最佳模型的宏平均F1为0.79，准确率为0.80，表现优于传统模型。

Conclusion: 配置优化后的传统机器学习模型依然高效，但Transformer模型在理解希望言论的细致语义方面具有优势，取得了更高的准确率和召回率。大型的Transformer及LLM即使在小数据集条件下也可能具有更好的表现。

Abstract: The identification of hope speech has become a promised NLP task, considering
the need to detect motivational expressions of agency and goal-directed
behaviour on social media platforms. This proposal evaluates traditional
machine learning models and fine-tuned transformers for a previously split hope
speech dataset as train, development and test set. On development test, a
linear-kernel SVM and logistic regression both reached a macro-F1 of 0.78; SVM
with RBF kernel reached 0.77, and Na\"ive Bayes hit 0.75. Transformer models
delivered better results, the best model achieved weighted precision of 0.82,
weighted recall of 0.80, weighted F1 of 0.79, macro F1 of 0.79, and 0.80
accuracy. These results suggest that while optimally configured traditional
machine learning models remain agile, transformer architectures detect some
subtle semantics of hope to achieve higher precision and recall in hope speech
detection, suggesting that larges transformers and LLMs could perform better in
small datasets.

</details>


### [324] [Think Twice: Branch-and-Rethink Reasoning Reward Model](https://arxiv.org/abs/2510.23596)
*Yizhu Jiao,Jiaqi Zeng,Julien Veron Vialard,Oleksii Kuchaiev,Jiawei Han,Olivier Delalleau*

Main category: cs.CL

TL;DR: 本文提出了一种基于“再思考”原则的奖励模型BR-RM，通过两轮评估提升对细微质量差异的敏感性，并在多个基准上取得了先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在推理时会外显中间步骤并分配更多算力，而主流奖励模型为了简化评估，多维质量被压缩成单一分数，导致注意力分散、分析浅显。为了克服这一缺陷，提升奖励模型对质量细节的捕捉能力，作者提出了新方法。

Method: 方法称为BR-RM，模拟LLM的“再思考”流程，分为两步：第一步自适应选出最关键的评估维度并生成假设；第二步针对这些维度细致验证假设。训练时采用结构化两轮样本和二元奖励，通过强化学习（GRPO）优化，可与现有RLHF管线兼容。

Result: 实验表明BR-RM在多个不同领域的奖励建模基准测试中均取得了 SOTA（最先进）表现，能更敏锐地捕捉细微且重要的错误。

Conclusion: BR-RM方法通过分步聚焦评判和再思考，有效减少了判断分散问题，提高了奖励模型的准确性和实用性，同时具备可扩展性和现实应用价值。

Abstract: Large language models (LLMs) increasingly rely on thinking models that
externalize intermediate steps and allocate extra test-time compute, with
think-twice strategies showing that a deliberate second pass can elicit
stronger reasoning. In contrast, most reward models (RMs) still compress many
quality dimensions into a single scalar in one shot, a design that induces
judgment diffusion: attention spreads across evaluation criteria, yielding
diluted focus and shallow analysis. We introduce branch-and-rethink (BR-RM), a
two-turn RM that transfers the think-twice principle to reward modeling. Turn 1
performs adaptive branching, selecting a small set of instance-critical
dimensions (such as factuality and safety) and sketching concise,
evidence-seeking hypotheses. Turn 2 executes branch-conditioned rethinking, a
targeted reread that tests those hypotheses and scrutinizes only what matters
most. We train with GRPO-style reinforcement learning over structured two-turn
traces using a simple binary outcome reward with strict format checks, making
the approach compatible with standard RLHF pipelines. By converting
all-at-oncescoringintofocused, second-lookreasoning,
BR-RMreducesjudgmentdiffusionandimproves sensitivity to subtle yet
consequential errors while remaining practical and scalable. Experimental
results demonstrate that our model achieves state-of-the-art performance on
three challenging reward modeling benchmarks across diverse domains. The code
and the model will be released soon.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [325] [A Robotic Stirring Method with Trajectory Optimization and Adaptive Speed Control for Accurate Pest Counting in Water Traps](https://arxiv.org/abs/2510.21732)
*Xumin Gao,Mark Stevens,Grzegorz Cielniak*

Main category: cs.RO

TL;DR: 本文提出了一种结合机械臂搅拌与自适应速度控制的新方法，用于提升黄色水盆中农业害虫个体的图像化计数准确性，尤其是解决害虫遮挡带来的难题。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像处理结合机器学习/深度学习的害虫计数方案，存在对害虫遮挡情形处理效果不佳、准确率受限问题。因此需要探索新的计数手段，提升水盆中害虫计数的准确性。

Method: 设计并搭建了用于搅拌黄色水盆的机械臂自动系统。通过机械臂搅拌使被遮挡害虫移动暴露，继而拍照计数。具体设计六种代表性搅拌轨迹（圆形、方形、三角形、螺旋、四小圆、随机线条），比较不同轨迹在多种虫密度情况下的计数误差与计数可信度，并筛选最佳轨迹。进一步提出基于计数可信度反馈的闭环自适应速度控制系统，实现搅拌速度的动态调整。

Result: 实验表明，所提出的机械臂搅拌系统及优化轨迹，显著提升了计数准确率，尤其在害虫密集与遮挡严重场景下优于常规方法。自适应速度闭环控制进一步增强了系统稳定性和计数可靠性。

Conclusion: 本研究首次系统研究了液体环境下不同搅拌轨迹对目标计数的影响，并实现了自适应速度搅拌，为精准农业害虫监测提供了新方案和理论参考。

Abstract: Accurate monitoring of pest population dynamics is crucial for informed
decision-making in precision agriculture. Currently, mainstream image-based
pest counting methods primarily rely on image processing combined with machine
learning or deep learning for pest counting. However, these methods have
limitations and struggle to handle situations involving pest occlusion. To
address this issue, this paper proposed a robotic stirring method with
trajectory optimization and adaptive speed control for accurate pest counting
in water traps. First, we developed an automated stirring system for pest
counting in yellow water traps based on a robotic arm. Stirring alters the
distribution of pests in the yellow water trap, making some of the occluded
individuals visible for detection and counting. Then, we investigated the
impact of different stirring trajectories on pest counting performance and
selected the optimal trajectory for pest counting. Specifically, we designed
six representative stirring trajectories, including circle, square, triangle,
spiral, four small circles, and random lines, for the robotic arm to stir. And
by comparing the overall average counting error and counting confidence of
different stirring trajectories across various pest density scenarios, we
determined the optimal trajectory. Finally, we proposed a counting
confidence-driven closed-loop control system to achieve adaptive-speed
stirring. It uses changes in pest counting confidence between consecutive
frames as feedback to adjust the stirring speed. To the best of our knowledge,
this is the first study dedicated to investigating the effects of different
stirring trajectories on object counting in the dynamic liquid environment and
to implement adaptive-speed stirring for this type of task. Experimental
results show ...

</details>


### [326] [Force-Displacement Profiling for Robot-Assisted Deployment of a Left Atrial Appendage Occluder Using FBG-EM Distal Sensing](https://arxiv.org/abs/2510.21734)
*Giovanni Battista Regazzo,Wim-Alexander Beckers,Xuan Thao Ha,Mouloud Ourak,Johan Vlekken,Emmanuel Vander Poorten*

Main category: cs.RO

TL;DR: 本研究提出了一种结合力感知和电磁追踪的机器人辅助左心耳封堵术（LAAC）方案，能够在无需电离辐射的条件下实时监测手术过程中的力学变化并提高手术精度。


<details>
  <summary>Details</summary>
Motivation: 现有LAAC术依赖人工和放射成像，存在辐射风险和定位精度有限的问题，需要更安全、精确的部署方式。

Method: 采用集成光纤布拉格光栅的力感知导管鞘，并结合电磁追踪，实现机器人辅助下的实时力学监测和位置追踪，对模拟解剖模型中的手术操作进行了力-位移特征分析。

Result: 该方法能够识别手术关键步骤，力学曲线表现出较低的作用力，减小了对组织的机械应力；验证了新方法的实用性和对手术反馈的提升。

Conclusion: 结合力感知和电磁追踪技术的机器人辅助LAAC手术有望提升手术安全性和有效性，未来工作将进一步实现过程自动识别并在更逼真的环境中验证该技术。

Abstract: Atrial fibrillation (AF) increases the risk of thromboembolic events due to
impaired function of the left atrial appendage (LAA). Left atrial appendage
closure (LAAC) is a minimally invasive intervention designed to reduce stroke
risk by sealing the LAA with an expandable occluder device. Current deployment
relies on manual catheter control and imaging modalities like fluoroscopy and
transesophageal echocardiography, which carry limitations including radiation
exposure and limited positioning precision. In this study, we leverage a
previously developed force-sensing delivery sheath integrating fiber Bragg
gratings (FBGs) at the interface between the catheter and the occluder.
Combined with electromagnetic (EM) tracking, this setup enables real-time
measurement of interaction forces and catheter tip position during
robot-assisted LAAC deployment in an anatomical phantom. We present a novel
force-displacement profiling method that characterizes occluder deployment
dynamics and identifies key procedural steps without relying on ionizing
radiation. The force profiles reveal low-magnitude interaction forces,
suggesting minimal mechanical stress on the surrounding anatomy. This approach
shows promise in providing clinicians with enhanced intraoperative feedback,
improving deployment outcome. Future work will focus on automating deployment
steps classification and validating the sensing strategy in dynamic, realistic
environments.

</details>


### [327] [A phase-aware AI car-following model for electric vehicles with adaptive cruise control: Development and validation using real-world data](https://arxiv.org/abs/2510.21735)
*Yuhui Liu,Shian Wang,Ansel Panicker,Kate Embry,Ayana Asanova,Tianyi Li*

Main category: cs.RO

TL;DR: 本研究提出了一种专为电动车设计的“相位感知AI (PAAI)”跟车模型，能够更准确地反映电动车在交通流中的动态行为，并在实际数据上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 目前主流微观交通流模型主要针对燃油车（ICE），而电动车（EV）由于加速、再生制动等动力学特性显著不同，现有模型难以精确描述EV的跟车行为，随着EV比例增加，新的针对性建模迫在眉睫。

Method: 提出PAAI电动车跟车模型，将物理公式与AI方法结合，针对不同驾驶阶段（如快速加速、再生制动）进行识别和自适应。通过采集具备自适应巡航功能车辆的真实轨迹数据进行建模和仿真。

Result: 仿真结果显示，PAAI模型在预测精度方面显著优于传统微观跟车模型，更能逼真还原EV在行驶过程中的行为。

Conclusion: PAAI模型为电动车交通仿真和相关研究提供了一个高精度的建模工具，有助于提升对EV交通流的理解和管理能力。

Abstract: Internal combustion engine (ICE) vehicles and electric vehicles (EVs) exhibit
distinct vehicle dynamics. EVs provide rapid acceleration, with electric motors
producing peak power across a wider speed range, and achieve swift deceleration
through regenerative braking. While existing microscopic models effectively
capture the driving behavior of ICE vehicles, a modeling framework that
accurately describes the unique car-following dynamics of EVs is lacking.
Developing such a model is essential given the increasing presence of EVs in
traffic, yet creating an easy-to-use and accurate analytical model remains
challenging.
  To address these gaps, this study develops and validates a Phase-Aware AI
(PAAI) car-following model specifically for EVs. The proposed model enhances
traditional physics-based frameworks with an AI component that recognizes and
adapts to different driving phases, such as rapid acceleration and regenerative
braking. Using real-world trajectory data from vehicles equipped with adaptive
cruise control (ACC), we conduct comprehensive simulations to validate the
model's performance. The numerical results demonstrate that the PAAI model
significantly improves prediction accuracy over traditional car-following
models, providing an effective tool for accurately representing EV behavior in
traffic simulations.

</details>


### [328] [Learn2Drive: A neural network-based framework for socially compliant automated vehicle control](https://arxiv.org/abs/2510.21736)
*Yuhui Liu,Samannita Halder,Shian Wang,Tianyi Li*

Main category: cs.RO

TL;DR: 本研究提出了一种结合LSTM神经网络与物理约束的新型自适应巡航控制（ACC）框架，提升自动驾驶车辆（AVs）在与人驾车辆（HVs）混合交通流中的整体效率。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶控制策略多关注单车或车队优化，普遍忽视了与人驾车辆的互动及对整体交通流的影响，可能造成拥堵和效率下降，因此亟需社会化、全局视角的控制方法。

Method: 提出基于神经网络的社会合规AV控制框架，引入社会价值取向（SVO），定义AV与HV效用函数，并根据SVO对AV行为进行优化，实现兼顾自身与全局流量目标的自适应调控。

Result: 数值仿真显示，该方法能适应不同交通状况，提高系统整体效率。当AV控制方式从节能转向优化交通流时，后方车队的能耗增加58.99%，平均车速提升38.39%，显著改善了交通动态。

Conclusion: 结合LSTM、社会价值取向及物理约束的智能控制框架，可有效提升自动驾驶车辆在混合交通中的表现，促进交通畅通与能效优化，对未来智能交通系统具有重要意义。

Abstract: This study introduces a novel control framework for adaptive cruise control
(ACC) in automated driving, leveraging Long Short-Term Memory (LSTM) networks
and physics-informed constraints. As automated vehicles (AVs) adopt advanced
features like ACC, transportation systems are becoming increasingly intelligent
and efficient. However, existing AV control strategies primarily focus on
optimizing the performance of individual vehicles or platoons, often neglecting
their interactions with human-driven vehicles (HVs) and the broader impact on
traffic flow. This oversight can exacerbate congestion and reduce overall
system efficiency. To address this critical research gap, we propose a neural
network-based, socially compliant AV control framework that incorporates social
value orientation (SVO). This framework enables AVs to account for their
influence on HVs and traffic dynamics. By leveraging AVs as mobile traffic
regulators, the proposed approach promotes adaptive driving behaviors that
reduce congestion, improve traffic efficiency, and lower energy consumption.
Within this framework, we define utility functions for both AVs and HVs, which
are optimized based on the SVO of each AV to balance its own control objectives
with broader traffic flow considerations. Numerical results demonstrate the
effectiveness of the proposed method in adapting to varying traffic conditions,
thereby enhancing system-wide efficiency. Specifically, when the AV's control
mode shifts from prioritizing energy consumption to optimizing traffic flow
efficiency, vehicles in the following platoon experience at least a 58.99%
increase in individual energy consumption alongside at least a 38.39%
improvement in individual average speed, indicating significant enhancements in
traffic dynamics.

</details>


### [329] [Next-Generation LLM for UAV: From Natural Language to Autonomous Flight](https://arxiv.org/abs/2510.21739)
*Liangqi Yuan,Chuhao Deng,Dong-Jun Han,Inseok Hwang,Sabine Brunswicker,Christopher G. Brinton*

Main category: cs.RO

TL;DR: 本文提出了一套基于大语言模型（LLM）的无人机（UAV）多尺度自动化操作系统NeLV，并验证其在多场景任务中的可行性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在无人机领域受到关注，现有研究多局限于小型无人机及其单一功能，缺乏面向中大规模无人机及实际应用背景的端到端系统设计和全流程自动化探索。

Method: 设计NeLV系统，将自然语言指令转化为无人机任务执行，包含五大技术组件：LLM解析、兴趣点路径规划、航点生成、飞控实现及无人机监控。通过多无人机巡逻、多点配送和多跳转运三种实际应用场景进行系统有效性验证。

Result: NeLV系统成功实现了短、中、长航程无人机任务的完整流程展示，证明了基于LLM的复杂无人机自动化指挥的可行性。同时提出了无人机自动化五级进阶路径，并对各级的技术挑战进行了梳理与分析。

Conclusion: LLM有望显著提升中大型无人机自动化系统的智能化水平，但实现真正的全流程无人值守还需在多方面持续研究和突破，对系统集成、监管合规、任务自适应性等提出了后续发展方向。

Abstract: With the rapid advancement of Large Language Models (LLMs), their
capabilities in various automation domains, particularly Unmanned Aerial
Vehicle (UAV) operations, have garnered increasing attention. Current research
remains predominantly constrained to small-scale UAV applications, with most
studies focusing on isolated components such as path planning for toy drones,
while lacking comprehensive investigation of medium- and long-range UAV systems
in real-world operational contexts. Larger UAV platforms introduce distinct
challenges, including stringent requirements for airport-based take-off and
landing procedures, adherence to complex regulatory frameworks, and specialized
operational capabilities with elevated mission expectations. This position
paper presents the Next-Generation LLM for UAV (NeLV) system -- a comprehensive
demonstration and automation roadmap for integrating LLMs into multi-scale UAV
operations. The NeLV system processes natural language instructions to
orchestrate short-, medium-, and long-range UAV missions through five key
technical components: (i) LLM-as-Parser for instruction interpretation, (ii)
Route Planner for Points of Interest (POI) determination, (iii) Path Planner
for waypoint generation, (iv) Control Platform for executable trajectory
implementation, and (v) UAV monitoring. We demonstrate the system's feasibility
through three representative use cases spanning different operational scales:
multi-UAV patrol, multi-POI delivery, and multi-hop relocation. Beyond the
current implementation, we establish a five-level automation taxonomy that
charts the evolution from current LLM-as-Parser capabilities (Level 1) to fully
autonomous LLM-as-Autopilot systems (Level 5), identifying technical
prerequisites and research challenges at each stage.

</details>


### [330] [FORGE-Tree: Diffusion-Forcing Tree Search for Long-Horizon Robot Manipulation](https://arxiv.org/abs/2510.21744)
*Yanjia Huang,Shuo Liu,Sheng Liu,Qingxiao Xu,Mingyang Wu,Xiangbo Gao,Zhengzhong Tu*

Main category: cs.RO

TL;DR: FORGE-Tree是一种提升长时序机器人操作任务成功率的新控制层方法，可与现有视觉-语言-动作（VLA）策略结合使用，主要采用阶段对齐的扩散强制头与测试时蒙特卡洛树扩散策略进行局部调整，实现更高效的轨迹优化。


<details>
  <summary>Details</summary>
Motivation: 解决长时域机器人操作中轨迹漂移和暴露偏差问题，现有VLA策略常常用固定超参数对整个轨迹去噪，导致小的几何误差逐步放大，轨迹难以精准控制，尤其在复杂空间（如紧密 Clearance）下缺乏动态分配计算资源的机制。

Method: 提出FORGE-Tree：在冻结的VLA编码器基础上，增加阶段对齐扩散强制（DF）头，将时间步与各子任务阶段对齐，只对目标片段进行部分去噪，同时保留其它片段不变，实现局部编辑。推理时结合蒙特卡洛树扩散（MCTD）框架，自动选择下一个需要重点优化的轨迹片段，利用场景图的先验和几何关系感知评分进行扩展与 rollouts，实现树状轨迹去噪调整。

Result: 在LIBERO数据集上，FORGE-Tree对比原生VLA策略（包括OpenVLA和Octo-Base基线）成功率提升了13.4到17.2个百分点，在相同计算预算下依然保持显著优势，尤其在长时域任务上提升更为明显。

Conclusion: FORGE-Tree作为一种插件式控制层，有效解决多阶段长时域机器人操作中的误差积累和资源动态分配难题，在多个基线和复杂任务场景下均显著提升操作成功率，具备实际推广价值。

Abstract: Long-horizon robot manipulation tasks remain challenging for
Vision-Language-Action (VLA) policies due to drift and exposure bias, often
denoise the entire trajectory with fixed hyperparameters, causing small
geometric errors to compound across stages and offering no mechanism to
allocate extra test-time compute where clearances are tight. To address these
challenges, we introduce FORGE-Tree, a plug-in control layer that couples a
stage-aligned Diffusion Forcing (DF) head with test-time Monte Carlo Tree
Diffusion (MCTD). With a frozen VLA encoder, DF aligns timesteps to subtask
stages; during inference we partially denoise only a target segment while
keeping other tokens frozen, turning trajectory refinement into a sequence of
local edits. We then apply Monte Carlo Tree Diffusion to select the next
segment to refine. A scene graph supplies priors for expansion and geometry
relation-aware scoring for rollouts, yielding tree-structured denoising whose
performance scales with search budget while preserving the executed prefix.
Evaluation on LIBERO, FORGE-Tree improves success rate by 13.4 to 17.2 pp over
the native VLA baselines with both OpenVLA and Octo-Base. Gains remain
consistent under comparable compute budgets, especially on long-horizon
variants. Videos available at: https://taco-group.github.io/FORGE-Tree/

</details>


### [331] [Avi: Action from Volumetric Inference](https://arxiv.org/abs/2510.21746)
*Harris Song,Long Le*

Main category: cs.RO

TL;DR: Avi提出了一种创新的3D视觉-语言-动作(VLA)架构，将机器人动作生成看作3D感知与空间推理问题，用3D点云和语言指导场景理解，通过几何变换执行动作，而非传统端到端策略学习。Avi不直接预测动作序列，而是借助多模态大语言模型生成下一个点云，并显式计算动作，增强了泛化与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 目前VLA机器人系统主要依赖2D视觉输入和端到端任务特定策略学习，存在泛化性差、对相机视角和遮挡不够鲁棒的问题。作者希望通过三维推理和场景理解，提升机器人对复杂任务与环境变化的适应能力，摆脱黑盒策略学习的限制。

Method: Avi采用3D点云、语言理解和经典几何变换，将机器人动作生成转化为点云预测和三维空间推理。其关键在于利用3D多模态大语言模型(Multi-modal LLM)结合场景语言知识推理下一步点云状态，之后通过显式几何变换算出机器人需要执行的操作动作。整个流程不直接训练动作序列预测，提升了推理透明度和解释性。

Result: 初步实验表明，Avi能够在面对视角变化、部分遮挡等现实挑战时，展现出较传统模型更好的泛化能力和鲁棒性，能够可靠地将高层级语言指令转化为可执行的低层级动作。

Conclusion: Avi展示了利用3D视觉-语言推理作为新型机器人基础架构的可行性。该思路为构建可扩展、稳健且具备解释性的机器人系统提供了新方向，有望摆脱端到端黑盒策略学习的核心局限。

Abstract: We propose Avi, a novel 3D Vision-Language-Action (VLA) architecture that
reframes robotic action generation as a problem of 3D perception and spatial
reasoning, rather than low-level policy learning. While existing VLA models
primarily operate on 2D visual inputs and are trained end-to-end on
task-specific action policies, Avi leverages 3D point clouds and
language-grounded scene understanding to compute actions through classical
geometric transformations. Most notably, Avi does not train on previous action
tokens, rather, we build upon a 3D Multi-modal Large Language Model (MLLM) to
generate the next point cloud and explicitly calculate the actions through
classical transformations. This approach enables generalizable behaviors that
are robust to occlusions, camera pose variations, and changes in viewpoint. By
treating the robotic decision-making process as a structured reasoning task
over 3D representations, Avi bridges the gap between high-level language
instructions and low-level actuation without requiring opaque policy learning.
Our preliminary results highlight the potential of 3D vision-language reasoning
as a foundation for scalable, robust robotic systems. Check it out at
https://avi-3drobot.github.io/.

</details>


### [332] [Real-time Mixed-Integer Quadratic Programming for Driving Behavior-Inspired Speed Bump Optimal Trajectory Planning](https://arxiv.org/abs/2510.21751)
*Van Nam Dinh,Van Vy Phan,Thai Son Dang,Van Du Phan,The Anh Mai,Van Chuong Le,Sy Phuong Ho,Dinh Tu Duong,Hung Cuong Ta*

Main category: cs.RO

TL;DR: 本论文提出了一种基于混合整数二次规划（MIQP）的自动驾驶车辆轨迹规划新方法，专门解决通过减速带时的舒适性与效率兼顾问题，并通过仿真验证其在城市道路中优越效果。


<details>
  <summary>Details</summary>
Motivation: 目前自动驾驶车辆在遇到减速带等路面特征时，既要保证通过的平顺性（乘客舒适度），又不能影响整体行驶效率，但传统方法难以同时兼顾两者，且受到实时计算能力的限制。因此，亟需一种能模拟人类驾驶减速带经验、又能实时部署的新型轨迹规划方法。

Method: 作者将减速带处理问题和常规道路导航约束统一建模为一个混合整数二次规划（MIQP）问题。在此框架下，结合模型预测控制（MPC），设计了模拟人类驾驶策略的减速带约束条件，使生成轨迹在通过减速带时既能兼顾舒适，也能满足实时性和道路安全要求。

Result: 通过在多种城市驾驶仿真环境下进行大量实验，验证了该方法在减速带前后的速度平滑过渡能力，并表现出良好的实时计算效率，适合实际自动驾驶车辆部署。

Conclusion: 该研究显著提升了自动驾驶车辆在复杂城市环境中处理混合道路特征（如减速带）时的轨迹规划能力，并成功兼顾了乘客舒适度与算法实时性，是城市自动驾驶领域的一项重要进展。

Abstract: This paper proposes a novel methodology for trajectory planning in autonomous
vehicles (AVs), addressing the complex challenge of negotiating speed bumps
within a unified Mixed-Integer Quadratic Programming (MIQP) framework. By
leveraging Model Predictive Control (MPC), we develop trajectories that
optimize both the traversal of speed bumps and overall passenger comfort. A key
contribution of this work is the formulation of speed bump handling constraints
that closely emulate human driving behavior, seamlessly integrating these with
broader road navigation requirements. Through extensive simulations in varied
urban driving environments, we demonstrate the efficacy of our approach,
highlighting its ability to ensure smooth speed transitions over speed bumps
while maintaining computational efficiency suitable for real-time deployment.
The method's capability to handle both static road features and dynamic
constraints, alongside expert human driving, represents a significant step
forward in trajectory planning for urban

</details>


### [333] [Taxonomy and Trends in Reinforcement Learning for Robotics and Control Systems: A Structured Review](https://arxiv.org/abs/2510.21758)
*Kumater Ter,RexCharles Donatus,Ore-Ofe Ajayi,Daniel Udekwe*

Main category: cs.RO

TL;DR: 本文综述了深度强化学习（DRL）在机器人与控制系统中的应用，系统总结了主流算法及其在各类领域的实际进展。


<details>
  <summary>Details</summary>
Motivation: 随着机器人系统需求的提升，如何应对复杂多变和不确定环境成为挑战。强化学习因其自适应性被视为实现智能机器行为的关键，但其工程化落地和领域应用尚需系统梳理。

Method: 文章首先沿用马尔可夫决策过程（MDP）形式描述基本的智能体-环境交互框架，随后对主流的强化学习及深度强化学习算法（如DDPG、TD3、PPO和SAC）逐一讲解。通过引入结构化的分类体系，文章梳理了RL在机器人行走、操作、多智能体协同、人机交互等领域的应用实例，并总结了当前主流的训练和部署方法。

Result: 该综述收集与分析了近年来相关领域的代表性文献，总结了RL在实际机器人平台中的主要技术进展，包括算法性能提升、应用领域扩展、设计规范等。

Conclusion: RL尤其是DRL在机器人中的研究和应用日趋成熟，理论与实际实现间的鸿沟持续缩小。本文为从理论到工程的转化提供了系统性参考，有助于推动自主机器人系统的发展。

Abstract: Reinforcement learning (RL) has become a foundational approach for enabling
intelligent robotic behavior in dynamic and uncertain environments. This work
presents an in-depth review of RL principles, advanced deep reinforcement
learning (DRL) algorithms, and their integration into robotic and control
systems. Beginning with the formalism of Markov Decision Processes (MDPs), the
study outlines essential elements of the agent-environment interaction and
explores core algorithmic strategies including actor-critic methods,
value-based learning, and policy gradients. Emphasis is placed on modern DRL
techniques such as DDPG, TD3, PPO, and SAC, which have shown promise in solving
high-dimensional, continuous control tasks. A structured taxonomy is introduced
to categorize RL applications across domains such as locomotion, manipulation,
multi-agent coordination, and human-robot interaction, along with training
methodologies and deployment readiness levels. The review synthesizes recent
research efforts, highlighting technical trends, design patterns, and the
growing maturity of RL in real-world robotics. Overall, this work aims to
bridge theoretical advances with practical implementations, providing a
consolidated perspective on the evolving role of RL in autonomous robotic
systems.

</details>


### [334] [J-ORA: A Framework and Multimodal Dataset for Japanese Object Identification, Reference, Action Prediction in Robot Perception](https://arxiv.org/abs/2510.21761)
*Jesse Atuhurra,Hidetaka Kamigaito,Taro Watanabe,Koichiro Yoshino*

Main category: cs.RO

TL;DR: J-ORA是一个针对机器人感知的多模态数据集，包含日本人机对话中的详细物体属性标注，旨在提升机器人对话中的感知任务表现。


<details>
  <summary>Details</summary>
Motivation: 目前机器人感知在多模态对话场景下缺乏详细的物体属性数据集，导致物体识别、指代消解和下一步动作预测等关键任务表现有限。

Method: 创建了J-ORA数据集，包括详尽的物体属性信息（如类别、颜色、形状、大小、材质和空间关系）用于三项感知任务，并对多种专有和开源视觉语言模型（VLMs）进行综合评测。

Result: 实验表明，相比没有物体属性标注的情况，增加详细属性显著提升多模态感知能力。专有VLMs与开源VLMs在感知性能上仍有差距。此外，不同模型在理解物体功能和语境关系上表现不同。

Conclusion: 丰富、具备上下文感知的物体属性标注对于推动动态环境下的机器人感知发展至关重要。

Abstract: We introduce J-ORA, a novel multimodal dataset that bridges the gap in robot
perception by providing detailed object attribute annotations within Japanese
human-robot dialogue scenarios. J-ORA is designed to support three critical
perception tasks, object identification, reference resolution, and next-action
prediction, by leveraging a comprehensive template of attributes (e.g.,
category, color, shape, size, material, and spatial relations). Extensive
evaluations with both proprietary and open-source Vision Language Models (VLMs)
reveal that incorporating detailed object attributes substantially improves
multimodal perception performance compared to without object attributes.
Despite the improvement, we find that there still exists a gap between
proprietary and open-source VLMs. In addition, our analysis of object
affordances demonstrates varying abilities in understanding object
functionality and contextual relationships across different VLMs. These
findings underscore the importance of rich, context-sensitive attribute
annotations in advancing robot perception in dynamic environments. See project
page at https://jatuhurrra.github.io/J-ORA/.

</details>


### [335] [Improving the performance of AI-powered Affordable Robotics for Assistive Tasks](https://arxiv.org/abs/2510.21771)
*Dharunish Yugeswardeenoo*

Main category: cs.RO

TL;DR: 本文提出了一种低成本的助理机械臂，通过模仿学习实现如喂食、清洁、取药等任务，具备高准确率且无须复杂编程或标注。核心模型能有效压缩参数规模，系统整体性能优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 到2050年，全球需要辅助护理的人口将达35亿，远超人类护理者的供给。现有机器人方案成本高、需技术背景，难以普及。因此亟需便宜、智能且易用的助理机器人。

Method: 搭建由六个舵机、双摄像头和3D打印夹爪组成的机械臂，通过示范视频模仿学习（无须手动编程或标注），利用Phased Action Chunking Transformer（PACT）建模时序动作，并通过Temporal Ensemble（TE）进行轨迹优化。采集了5万帧示范视频，涵盖三项助理任务。

Result: 系统在五种模型规模、四种架构及十小时实际环境下测试，助理任务准确率超90%，比基线最高提升40%。PACT使模型缩小5倍仍保有75%准确率。显著性分析显示模型正确利用视觉线索，有效理解关键时序节点。

Conclusion: 该助理机械臂方案以极低成本取得高精度，易用且推广潜力大。模型展现出优异的参数效率和动作理解能力。后续将研究双臂配合和移动能力以扩展应用场景。

Abstract: By 2050, the global demand for assistive care is expected to reach 3.5
billion people, far outpacing the availability of human caregivers. Existing
robotic solutions remain expensive and require technical expertise, limiting
accessibility. This work introduces a low-cost robotic arm for assistive tasks
such as feeding, cleaning spills, and fetching medicine. The system uses
imitation learning from demonstration videos, requiring no task-specific
programming or manual labeling. The robot consists of six servo motors, dual
cameras, and 3D-printed grippers. Data collection via teleoperation with a
leader arm yielded 50,000 video frames across the three tasks. A novel Phased
Action Chunking Transformer (PACT) captures temporal dependencies and segments
motion dynamics, while a Temporal Ensemble (TE) method refines trajectories to
improve accuracy and smoothness. Evaluated across five model sizes and four
architectures, with ten hours of real-world testing, the system achieved over
90% task accuracy, up to 40% higher than baselines. PACT enabled a 5x model
size reduction while maintaining 75% accuracy. Saliency analysis showed
reliance on key visual cues, and phase token gradients peaked at critical
trajectory moments, indicating effective temporal reasoning. Future work will
explore bimanual manipulation and mobility for expanded assistive capabilities.

</details>


### [336] [Real-Time QP Solvers: A Concise Review and Practical Guide Towards Legged Robots](https://arxiv.org/abs/2510.21773)
*Van Nam Dinh*

Main category: cs.RO

TL;DR: 本论文对适用于四足机器人等腿式机器人控制的前沿二次规划（QP）求解器进行了系统分析与基准测试，比较了不同求解方法在实时性能、约束满足和鲁棒性等方面的实用性。


<details>
  <summary>Details</summary>
Motivation: 腿式机器人控制中的关键模块（如逆动力学、模型预测控制、全身控制）普遍依赖QP求解，但在嵌入式平台上需兼顾速度、能耗和计算资源，因此急需对各类QP求解器的优缺点做出全面评估。

Method: 论文首先给出标准凸QP的数学形式，并将QP求解器分为内点法、主动集法、算子分裂法和增广拉格朗日法四类。全面分析了每类方法在算法结构、计算特点、利用问题结构与热启动能力等方面的表现，并基于公开基准测试进行了对比，考察了计算时间、约束满足度、扰动下的鲁棒性等多项指标。

Result: 通过特性对比表和具体实测，论文总结了不同类求解器在实际场景下的取舍，例如长时域MPC适合稀疏内点法，高频WBC则适合稠密主动集法，并讨论了速度、精度与能效之间的权衡。

Conclusion: 论文建议根据具体任务与硬件特性选择合适的QP求解器，指出解算器、任务与硬件三者协同的重要性，认为对非凸/分布式QP的新探索将进一步推动敏捷自主腿式机器人系统的发展。

Abstract: Quadratic programming (QP) underpins real-time robotics by enabling
efficient, constrained optimization in state estimation, motion planning, and
control. In legged locomotion and manipulation, essential modules like inverse
dynamics, Model Predictive Control (MPC), and Whole-Body Control (WBC) are
inherently QP-based, demanding reliable solutions amid tight timing, energy,
and computational limits on embedded platforms. This paper presents a
comprehensive analysis and benchmarking study of cutting-edge QP solvers for
legged robotics. We begin by formulating the standard convex QP and classify
solvers into four principal algorithmic approaches, including interior-point
methods, active-set strategies, operator splitting schemes, and augmented
Lagrangian approaches. Each solver is examined in terms of algorithmic
structure, computational characteristics, and its ability to exploit problem
structure and warm-starting. Performance is evaluated using publicly available
benchmarks, focusing on metrics such as computation time, constraint
satisfaction, and robustness under perturbations. Feature tables and
comparisons yield practical guidance for solver selection, underscoring
trade-offs in speed, accuracy, and energy efficiency. Our findings emphasize
the synergy between solver, task, and hardware, sparse IPMs for long-horizon
MPC, and dense active-set for high frequency WBC to advance agile, autonomous
legged systems, with emerging extensions to nonconvex and distributed QP.

</details>


### [337] [VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing, Speaking, and Acting](https://arxiv.org/abs/2510.21817)
*Xiaoyu Liu,Chaoyou Fu,Chi Yan,Chu Wu,Haihan Gao,Yi-Fan Zhang,Shaoqi Dong,Cheng Qian,Bin Luo,Xiuyong Yang,Guanwu Li,Yusheng Cai,Yunhang Shen,Deqiang Jiang,Haoyu Cao,Xing Sun,Caifeng Shan,Ran He*

Main category: cs.RO

TL;DR: 提出了VITA-E框架，实现了视觉-语言-行动模型的行为并发与实时可打断，极大提升了智能体的自然交互和响应能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-行动（VLA）模型不能同时看到、听到、说话和行动，对实时用户打断的处理能力有限，导致交互不自然、响应不灵活。

Method: 提出了VITA-E框架，核心为双模型架构：两个并行VLA实例分别作为“主动模型”和“待机模型”，使智能体具备像人类一样的多任务处理（如观察、听用户说话、回答和执行动作等），均可并发且实时打断。此外，创新性地用模型生成系统级控制命令，直接联动模型推理与系统行为。

Result: 在实体人形平台上实验证明，VITA-E能可靠处理复杂交互场景，与多种双系统VLA模型兼容，在应急停止和语音打断任务上成功率极高，且能顺利实现语音和动作并发。

Conclusion: VITA-E显著提升了智能体的交互自然度和能力，为更智能、灵活的具身助手迈出了重要一步。

Abstract: Current Vision-Language-Action (VLA) models are often constrained by a rigid,
static interaction paradigm, which lacks the ability to see, hear, speak, and
act concurrently as well as handle real-time user interruptions dynamically.
This hinders seamless embodied collaboration, resulting in an inflexible and
unresponsive user experience. To address these limitations, we introduce
VITA-E, a novel embodied interaction framework designed for both behavioral
concurrency and nearly real-time interruption. The core of our approach is a
dual-model architecture where two parallel VLA instances operate as an ``Active
Model'' and a ``Standby Model'', allowing the embodied agent to observe its
environment, listen to user speech, provide verbal responses, and execute
actions, all concurrently and interruptibly, mimicking human-like multitasking
capabilities. We further propose a ``model-as-controller'' paradigm, where we
fine-tune the VLM to generate special tokens that serve as direct system-level
commands, coupling the model's reasoning with the system's behavior.
Experiments conducted on a physical humanoid platform demonstrate that VITA-E
can reliably handle complex interactive scenarios. Our framework is compatible
with various dual-system VLA models, achieving an extremely high success rate
on emergency stops and speech interruptions while also successfully performing
concurrent speech and action. This represents a significant step towards more
natural and capable embodied assistants.

</details>


### [338] [A Literature Review On Stewart-Gough Platform Calibrations A Literature Review On Stewart-Gough Platform Calibrations](https://arxiv.org/abs/2510.21854)
*Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 本文综述了Stewart-Gough平台（六足平台）在高精度3D运动控制中的应用及其校准方法，尤其关注基于逆运动学的校准方式。


<details>
  <summary>Details</summary>
Motivation: 由于六足平台常被用于医疗、芯片制造、航天等对运动控制精度要求极高的领域，因此平台精确校准（超越应用精度要求）尤为关键。

Method: 回顾与分析了多个校准方法，包括外部仪器辅助、约束运动自由度、额外传感器协助的自动或自校准等，特别聚焦于逆运动学方法相较于正运动学的优势和应用。

Result: 多数研究均通过优化校准流程，有效提升了平台的位置与姿态准确性；研究重点在于减少因机构误差、结构误差以及部分环境因素带来的影响。但普遍校准在无载荷情境下进行。

Conclusion: 本文总结了当前Stewart-Gough平台校准的最新进展，归纳了各种校准流程及误差来源，对该领域未来发展与实际应用的局限性和关注点进行了探讨。

Abstract: Researchers have studied Stewart-Gough platforms, also known as Gough-Stewart
platforms or hexapod platforms extensively for their inherent fine control
characteristics. Their studies led to the potential deployment opportunities of
Stewart-Gough Platforms in many critical applications such as the medical
field, engineering machines, space research, electronic chip manufacturing,
automobile manufacturing, etc. Some of these applications need micro and
nano-level movement control in 3D space for the motions to be precise,
complicated, and repeatable; a Stewart-Gough platform fulfills these challenges
smartly. For this, the platform must be more accurate than the specified
application accuracy level and thus proper calibration for a parallel robot is
crucial. Forward kinematics-based calibration for these hexapod machines
becomes unnecessarily complex and inverse kinematics complete this task with
much ease. To experiment with different calibration techniques, various
calibration approaches were implemented by using external instruments,
constraining one or more motions of the system, and using extra sensors for
auto or self-calibration. This survey paid attention to those key
methodologies, their outcome, and important details related to inverse
kinematic-based parallel robot calibrations. It was observed during this study
that the researchers focused on improving the accuracy of the platform position
and orientation considering the errors contributed by one source or multiple
sources. The error sources considered are mainly kinematic and structural, in
some cases, environmental factors also are reviewed, however, those
calibrations are done under no-load conditions. This study aims to review the
present state of the art in this field and highlight the processes and errors
considered for the calibration of Stewart-Gough platforms.

</details>


### [339] [Butter-Bench: Evaluating LLM Controlled Robots for Practical Intelligence](https://arxiv.org/abs/2510.21860)
*Callum Sharrock,Lukas Petersson,Hanna Petersson,Axel Backlund,Axel Wennström,Kristoffer Nordström,Elias Aronsson*

Main category: cs.RO

TL;DR: 本文提出了Butter-Bench基准用于评估大型语言模型（LLM）控制机器人的实际智能能力，并发现人类在该任务中远超LLM。


<details>
  <summary>Details</summary>
Motivation: 当前机器人系统通常采用分层结构，LLM负责高层推理，VLA模型负责低层控制，但尚缺乏专门评估LLM在复杂现实场景下智能的方法，因此需要有效的基准测试。

Method: 提出Butter-Bench基准，专门独立评估LLM在机器人控制中的实际智能表现，具体测试多步空间规划和社会理解等，并与人类做对比。同时还测试了经过实体推理微调的LLM。

Result: 人类在Butter-Bench测试上的均分为95%，而表现最好的LLM仅为40%。LLM尤其在多步骤空间规划和社会理解方面表现不佳。实体推理微调也未能提升LLM在该基准上的表现。

Conclusion: 当前LLM在实际机器人智能任务上的能力远不及人类，特别是在多步规划和社会理解方面，现有微调方法尚无法有效提升这方面能力。

Abstract: We present Butter-Bench, a benchmark evaluating large language model (LLM)
controlled robots for practical intelligence, defined as the ability to
navigate the messiness of the physical world. Current state-of-the-art robotic
systems use a hierarchical architecture with LLMs in charge of high-level
reasoning, and a Vision Language Action (VLA) model for low-level control.
Butter-Bench evaluates the LLM part in isolation from the VLA. Although LLMs
have repeatedly surpassed humans in evaluations requiring analytical
intelligence, we find humans still outperform LLMs on Butter-Bench. The best
LLMs score 40% on Butter-Bench, while the mean human score is 95%. LLMs
struggled the most with multi-step spatial planning and social understanding.
We also evaluate LLMs that are fine-tuned for embodied reasoning and conclude
that this training does not improve their score on Butter-Bench.

</details>


### [340] [A Physics-Informed Neural Network Approach for UAV Path Planning in Dynamic Environments](https://arxiv.org/abs/2510.21874)
*Shuning Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种基于物理约束神经网络（PINN）的无人机轨迹规划方法，能够在动态风场下生成更加安全、能耗更低且更平滑的轨迹。


<details>
  <summary>Details</summary>
Motivation: 传统轨迹规划器（如A*、kinodynamic RRT*）由于离散化和采样限制，生成的无人机路径往往不够优，路径平滑性和安全性也有限，尤其在风场动态干扰下更加明显。

Method: 提出了一种物理约束神经网络（PINN）框架，将无人机动力学特性、风场干扰和避障要求直接嵌入神经网络训练过程中，无需监督数据，网络通过最小化物理残差及风险感知损失，学习到动态可行且安全的轨迹。

Result: 实验表明，该方法在控制能耗、轨迹平滑性和安全裕度等指标上显著优于A*和Kino-RRT*，同时飞行效率与传统方法相当。

Conclusion: 该研究证明了物理约束学习能够统一基于模型和数据驱动的路径规划思路，为无人机轨迹优化提供了可扩展且物理一致的框架。

Abstract: Unmanned aerial vehicles (UAVs) operating in dynamic wind fields must
generate safe and energy-efficient trajectories under physical and
environmental constraints. Traditional planners, such as A* and kinodynamic
RRT*, often yield suboptimal or non-smooth paths due to discretization and
sampling limitations. This paper presents a physics-informed neural network
(PINN) framework that embeds UAV dynamics, wind disturbances, and obstacle
avoidance directly into the learning process. Without requiring supervised
data, the PINN learns dynamically feasible and collision-free trajectories by
minimizing physical residuals and risk-aware objectives. Comparative
simulations show that the proposed method outperforms A* and Kino-RRT* in
control energy, smoothness, and safety margin, while maintaining similar flight
efficiency. The results highlight the potential of physics-informed learning to
unify model-based and data-driven planning, providing a scalable and physically
consistent framework for UAV trajectory optimization.

</details>


### [341] [Two-Steps Diffusion Policy for Robotic Manipulation via Genetic Denoising](https://arxiv.org/abs/2510.21991)
*Mateo Clemente,Leo Brunswic,Rui Heng Yang,Xuan Zhao,Yasser Khalil,Haoyu Lei,Amir Rasouli,Yinchuan Li*

Main category: cs.RO

TL;DR: 本文提出了一种针对具身智能任务（如机器人操作）的改进扩散模型采样方法Genetic Denoising，在极少神经网络前向推理步数下依然获得高性能，显著提升效率和效果。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型，虽在机器人模仿学习任务取得好成绩，但推理过程原本为视觉域设计，未针对低维、结构化的动作空间调整，导致推理效率偏低。

Method: 提出将扩散模型的去噪过程专门调整以适应机器人操作任务的动作分布特性，并设计基于种群的采样策略Genetic Denoising，通过选择低风险的去噪轨迹来提升表现及稳定性，大大减少所需的推理步数。

Result: 在D4RL和Robomimic等多任务评测（超过200万个评估），该方法即使只用2步推理，也能提升或匹配原方法效果，在多个任务上实现高达20%的性能提升。

Conclusion: 针对机器人控制任务优化的扩散模型采样方法，可显著减少推理步数同时提升性能，对具身智能和低维控制领域扩散模型应用具有重要实用意义。

Abstract: Diffusion models, such as diffusion policy, have achieved state-of-the-art
results in robotic manipulation by imitating expert demonstrations. While
diffusion models were originally developed for vision tasks like image and
video generation, many of their inference strategies have been directly
transferred to control domains without adaptation. In this work, we show that
by tailoring the denoising process to the specific characteristics of embodied
AI tasks -- particularly structured, low-dimensional nature of action
distributions -- diffusion policies can operate effectively with as few as 5
neural function evaluations (NFE).
  Building on this insight, we propose a population-based sampling strategy,
genetic denoising, which enhances both performance and stability by selecting
denoising trajectories with low out-of-distribution risk. Our method solves
challenging tasks with only 2 NFE while improving or matching performance. We
evaluate our approach across 14 robotic manipulation tasks from D4RL and
Robomimic, spanning multiple action horizons and inference budgets. In over 2
million evaluations, our method consistently outperforms standard
diffusion-based policies, achieving up to 20\% performance gains with
significantly fewer inference steps.

</details>


### [342] [Estimation of Minimum Stride Frequency for the Frontal Plane Stability of Bipedal Systems](https://arxiv.org/abs/2510.22030)
*Harsha Karunanayaka,Siavash Rezazadeh*

Main category: cs.RO

TL;DR: 本文研究了双足系统在前额面上的稳定性，探索了如何通过主动调整步态参数实现无需反馈的稳定行走，并提出了最小步频的预测方法。


<details>
  <summary>Details</summary>
Motivation: 现有双足行走系统对前额面稳定性的理解有限，尤其在缺少反馈控制、依赖前馈步态调节时，受质量、刚度、腿长及髋宽等参数影响，稳定性机理和所需最小步频尚不明确。为更好实现节能、简化控制并提升健壮性，有必要深入探讨这些关键参数对稳定性和步频的影响规律。

Method: 通过分析双足系统模型，系统考察了质量、刚度、腿长、髋宽等参数，以及系统固有频率对维持稳定步态所需最小步频的影响。提出了一种可预测最小步频的方法，并用随机生成的多组模型对预测结果进行了对比验证。

Result: 研究发现，各关键结构参数及自然频率显著影响系统所需的最小步频。所提方法能够有效预测不同模型在无反馈条件下维持稳定所需的最小步频，预测值与实际值匹配良好。

Conclusion: 本工作加深了对双足行走前额面稳定性及前馈步态调节原理的理解，为设计低能耗、高鲁棒性的控制策略提供了理论依据。

Abstract: Stability of bipedal systems in frontal plane is affected by the hip offset,
to the extent that adjusting stride time using feedforward retraction and
extension of the legs can lead to stable oscillations without feedback control.
This feedforward stabilization can be leveraged to reduce the control effort
and energy expenditure and increase the locomotion robustness. However, there
is limited understanding of how key parameters, such as mass, stiffness, leg
length, and hip width, affect stability and the minimum stride frequency needed
to maintain it. This study aims to address these gaps through analyzing how
individual model parameters and the system's natural frequency influence the
minimum stride frequency required to maintain a stable cycle. We propose a
method to predict the minimum stride frequency, and compare the predicted
stride frequencies with actual values for randomly generated models. The
findings of this work provide a better understanding of the frontal plane
stability mechanisms and how feedforward stabilization can be leveraged to
reduce the control effort.

</details>


### [343] [RaycastGrasp: Eye-Gaze Interaction with Wearable Devices for Robotic Manipulation](https://arxiv.org/abs/2510.22113)
*Zitiantao Lin,Yongpeng Sang,Yang Ye*

Main category: cs.RO

TL;DR: 该论文提出了一种以穿戴式混合现实头戴设备为基础，通过凝视引导实现操控机械臂拾取物体的新型交互界面。


<details>
  <summary>Details</summary>
Motivation: 传统的操纵杆控制方式对于行动不便人群来说，操作精度要求高且界面不直观，限制了辅助机器人的普及和易用性。因此，迫切需要更直观、自然且无屏化的控制方式提升辅助机器人系统的可访问性。

Method: 作者提出了基于第一视角、以使用者视线为交互主导的机械臂控制系统。该系统采用可穿戴MR头显，实现对现实物体的自然凝视交互、意图识别和反馈提示，结合预训练视觉模型提升识别准确率，由机械臂完成实际操作。

Result: 实验结果表明，该方法显著提升了操作的准确性与效率，单次意图和物体识别的准确率均超过88%，并降低了系统延迟，适用于多种实际应用场景。

Conclusion: 此系统凭借更强的直观性与易用性，为辅助机器人在现实生活中支持行动障碍人群提供了实用且有效的解决方案，具有广泛推广价值。

Abstract: Robotic manipulators are increasingly used to assist individuals with
mobility impairments in object retrieval. However, the predominant
joystick-based control interfaces can be challenging due to high precision
requirements and unintuitive reference frames. Recent advances in human-robot
interaction have explored alternative modalities, yet many solutions still rely
on external screens or restrictive control schemes, limiting their
intuitiveness and accessibility. To address these challenges, we present an
egocentric, gaze-guided robotic manipulation interface that leverages a
wearable Mixed Reality (MR) headset. Our system enables users to interact
seamlessly with real-world objects using natural gaze fixation from a
first-person perspective, while providing augmented visual cues to confirm
intent and leveraging a pretrained vision model and robotic arm for intent
recognition and object manipulation. Experimental results demonstrate that our
approach significantly improves manipulation accuracy, reduces system latency,
and achieves single-pass intention and object recognition accuracy greater than
88% across multiple real-world scenarios. These results demonstrate the
system's effectiveness in enhancing intuitiveness and accessibility,
underscoring its practical significance for assistive robotics applications.

</details>


### [344] [EasyUUV: An LLM-Enhanced Universal and Lightweight Sim-to-Real Reinforcement Learning Framework for UUV Attitude Control](https://arxiv.org/abs/2510.22126)
*Guanwen Xie,Jingzehua Xu,Jiwei Tang,Yubo Huang,Shuai Zhang,Xiaofan Li*

Main category: cs.RO

TL;DR: 提出EasyUUV框架，用于提高无人水下航行器（UUV）姿态控制的通用性和鲁棒性，通过引入大语言模型辅助的混合控制和自适应策略，实现了高效且可靠的UUV控制。


<details>
  <summary>Details</summary>
Motivation: 现有UUV姿态控制方法在泛化能力、对真实扰动的鲁棒性和高效部署方面存在不足，需要更智能、更适应现实环境的方法。

Method: 提出EasyUUV强化学习框架，结合并行化RL训练与混合控制结构，RL学习策略负责高层姿态修正，低层由自适应S-Surface控制器执行。通过多模态大语言模型，利用视觉与文本反馈在运行时自适应调参，实现无需重新训练即可适应未建模动力学。

Result: 开发了低成本6自由度UUV平台，并进行了广泛仿真与实物实验。结果显示EasyUUV在多种水下环境下表现出优秀的鲁棒性和自适应能力。

Conclusion: EasyUUV实现了UUV姿态控制领域的通用性与自适应性突破，为复杂、变化的水下环境提供了有效的智能控制解决方案。

Abstract: Despite recent advances in Unmanned Underwater Vehicle (UUV) attitude
control, existing methods still struggle with generalizability, robustness to
real-world disturbances, and efficient deployment. To address the above
challenges, this paper presents EasyUUV, a Large Language Model (LLM)-enhanced,
universal, and lightweight simulation-to-reality reinforcement learning (RL)
framework for robust attitude control of UUVs. EasyUUV combines parallelized RL
training with a hybrid control architecture, where a learned policy outputs
high-level attitude corrections executed by an adaptive S-Surface controller. A
multimodal LLM is further integrated to adaptively tune controller parameters
at runtime using visual and textual feedback, enabling training-free adaptation
to unmodeled dynamics. Also, we have developed a low-cost 6-DoF UUV platform
and applied an RL policy trained through efficient parallelized simulation.
Extensive simulation and real-world experiments validate the effectiveness and
outstanding performance of EasyUUV in achieving robust and adaptive UUV
attitude control across diverse underwater conditions. The source code is
available from the following website: https://360zmem.github.io/easyuuv/

</details>


### [345] [LT-Exosense: A Vision-centric Multi-session Mapping System for Lifelong Safe Navigation of Exoskeletons](https://arxiv.org/abs/2510.22164)
*Jianeng Wang,Matias Mattamala,Christina Kassab,Nived Chebrolu,Guillaume Burger,Fabio Elnecave,Marine Petriaux,Maurice Fallon*

Main category: cs.RO

TL;DR: 本文提出了LT-Exosense——一种以视觉为中心、多会话的建图系统，用于自平衡外骨骼在动态环境下实现长期可靠的（半）自主导航。


<details>
  <summary>Details</summary>
Motivation: 自平衡外骨骼为下肢残疾人士提供了新的出行方案，但在实际环境中长期有效运行面临感知与地图更新的挑战，尤其是在环境变化频繁的情况下。

Method: LT-Exosense系统通过多次会话逐步融合空间信息，自动检测环境变化，及时更新全局地图。此外，系统支持智能路径规划，能根据新障碍物调整路线，障碍消除后恢复原路径。

Result: 该系统在实际场景中经过多次试验，所构建多会话地图的点对点误差平均低于5厘米，且能展现出在动态室内环境下自适应路径规划的效果。

Conclusion: LT-Exosense大幅提升了自平衡外骨骼在动态场所的长期自主导航能力，为下肢残障人士的独立行动提供了技术支撑，并证实了多会话视觉建图的实用价值。

Abstract: Self-balancing exoskeletons offer a promising mobility solution for
individuals with lower-limb disabilities. For reliable long-term operation,
these exoskeletons require a perception system that is effective in changing
environments. In this work, we introduce LT-Exosense, a vision-centric,
multi-session mapping system designed to support long-term (semi)-autonomous
navigation for exoskeleton users. LT-Exosense extends single-session mapping
capabilities by incrementally fusing spatial knowledge across multiple
sessions, detecting environmental changes, and updating a persistent global
map. This representation enables intelligent path planning, which can adapt to
newly observed obstacles and can recover previous routes when obstructions are
removed. We validate LT-Exosense through several real-world experiments,
demonstrating a scalable multi-session map that achieves an average
point-to-point error below 5 cm when compared to ground-truth laser scans. We
also illustrate the potential application of adaptive path planning in
dynamically changing indoor environments.

</details>


### [346] [ACG: Action Coherence Guidance for Flow-based VLA models](https://arxiv.org/abs/2510.22201)
*Minho Park,Kinam Kim,Junha Hyung,Hyojin Jang,Hoiyeong Jin,Jooyeol Yun,Hojoon Lee,Jaegul Choo*

Main category: cs.RO

TL;DR: 提出了一种新的无训练测试时引导算法（ACG），可提升机器人视觉-语言-动作模型执行任务时的动作连贯性和成功率，尤其在高精准操作任务中表现优秀。


<details>
  <summary>Details</summary>
Motivation: 扩散和流匹配模型作为机器人策略虽能泛化多场景任务，但高生成能力令其在以模仿学习训练时，容易对人类演示中的噪声（如动作抖动、停顿）敏感，导致最终动作连贯性下降，进而在精细操作任务部署时出现漂移和失败，亟需提升动作连贯性的方法。

Method: 提出一种名为“动作连贯性引导（ACG）”的算法，无需额外训练而在测试阶段自动提升VLA模型（视觉-语言-动作模型）的动作连贯性，提高操作稳定性。

Result: 在RoboCasa、DexMimicGen和真实场景SO-101等多种精细操作任务上评测显示，ACG显著提升了动作连贯性和任务成功率。

Conclusion: ACG可作为通用的测试时增强策略，不需重新训练即可有效提升机器人VLA模型在各类复杂任务下的表现和可靠性。

Abstract: Diffusion and flow matching models have emerged as powerful robot policies,
enabling Vision-Language-Action (VLA) models to generalize across diverse
scenes and instructions. Yet, when trained via imitation learning, their high
generative capacity makes them sensitive to noise in human demonstrations:
jerks, pauses, and jitter which reduce action coherence. Reduced action
coherence causes instability and trajectory drift during deployment, failures
that are catastrophic in fine-grained manipulation where precision is crucial.
In this paper, we present Action Coherence Guidance (ACG) for VLA models, a
training-free test-time guidance algorithm that improves action coherence and
thereby yields performance gains. Evaluated on RoboCasa, DexMimicGen, and
real-world SO-101 tasks, ACG consistently improves action coherence and boosts
success rates across diverse manipulation tasks. Code and project page are
available at https://github.com/DAVIAN-Robotics/ACG and
https://DAVIAN-Robotics.github.io/ACG , respectively.

</details>


### [347] [Bridging Perception and Reasoning: Dual-Pipeline Neuro-Symbolic Landing for UAVs in Cluttered Environments](https://arxiv.org/abs/2510.22204)
*Weixian Qian,Sebastian Schroder,Yao Deng,Jiaohong Yao,Linfeng Liang,Xiao Cheng,Richard Han,Xi Zheng*

Main category: cs.RO

TL;DR: 该论文提出了一种新的人机结合神经符号框架NeuroSymLand，用于提升无人机在复杂、不可预测环境中的自主降落能力，并取得了比现有方法更好的泛化、效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 无人机在杂乱无章、崎岖不平且地图信息稀缺的环境中安全自主降落具有挑战性。现有基于视觉或深度学习的方法容易受环境变化影响并缺乏可解释性，无法满足无人机高安全性的需求。

Method: 提出NeuroSymLand神经符号体系，包括两个核心流程：（1）离线使用大语言模型和人工修正从多样降落场景中提炼通用且可验证的符号知识（Scallop程序）；（2）在线则用高效的基础模型做语义分割，生成概率事实并组合成场景图，实时进行符号推理决策。节点和边的属性完全由几何规则计算，减少对数据和模型训练的依赖。整体方案融合了感知能力和可解释性。

Result: 通过多个数据集、多样仿真地图与真实无人机硬件实验，NeuroSymLand在准确性、环境泛化和效率上均优于当前主流方法。系统能提供逐区域降落安全评分和可读解释，提升了降落决策的可靠性。

Conclusion: NeuroSymLand显著提升了无人机在应急救援、监视和投递等任务中的降落安全与鲁棒性，是推动无人机技术向实际复杂环境落地的重要进展。

Abstract: Autonomous landing in unstructured (cluttered, uneven, and map-poor)
environments is a core requirement for Unmanned Aerial Vehicles (UAVs), yet
purely vision-based or deep learning models often falter under covariate shift
and provide limited interpretability. We propose NeuroSymLand, a neuro-symbolic
framework that tightly couples two complementary pipelines: (i) an offline
pipeline, where Large Language Models (LLMs) and human-in-the-loop refinement
synthesize Scallop code from diverse landing scenarios, distilling
generalizable and verifiable symbolic knowledge; and (ii) an online pipeline,
where a compact foundation-based semantic segmentation model generates
probabilistic Scallop facts that are composed into semantic scene graphs for
real-time deductive reasoning. This design combines the perceptual strengths of
lightweight foundation models with the interpretability and verifiability of
symbolic reasoning. Node attributes (e.g., flatness, area) and edge relations
(adjacency, containment, proximity) are computed with geometric routines rather
than learned, avoiding the data dependence and latency of train-time graph
builders. The resulting Scallop program encodes landing principles (avoid water
and obstacles; prefer large, flat, accessible regions) and yields calibrated
safety scores with ranked Regions of Interest (ROIs) and human-readable
justifications. Extensive evaluations across datasets, diverse simulation maps,
and real UAV hardware show that NeuroSymLand achieves higher accuracy, stronger
robustness to covariate shift, and superior efficiency compared with
state-of-the-art baselines, while advancing UAV safety and reliability in
emergency response, surveillance, and delivery missions.

</details>


### [348] [Breaking the Static Assumption: A Dynamic-Aware LIO Framework Via Spatio-Temporal Normal Analysis](https://arxiv.org/abs/2510.22313)
*Chen Zhiqiang,Le Gentil Cedric,Lin Fuling,Lu Minghao,Qiao Qiyuan,Xu Bowen,Qi Yuhua,Lu Peng*

Main category: cs.RO

TL;DR: 本文提出了一种动态环境下更鲁棒的激光雷达-惯导里程计（LIO）方法，解决了传统算法在动态场景和稀疏几何环境下表现不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 现有LIO方法普遍假设环境是静态的，因此在存在大量动态物体或几何稀疏的环境下难以实现准确定位。动态特征的可靠识别与精确位姿估计之间存在相互依赖的难题。

Method: 作者提出将动态感知直接融入点云配准流程，设计了一种新颖的动态感知迭代最近点（ICP）算法，通过时空法线分析辅助，以高效的空间一致性验证方法提升静态地图构建的准确性。

Result: 实验结果显示，所提方法在动态且几何结构稀疏的环境下，相较于现有最前沿LIO系统，表现出明显的性能提升。相关代码与数据集已开放。

Conclusion: 该工作有效打破了动态识别与精准定位的相互依赖，显著提升动态环境中LIO的稳健性，为实际应用提供了有力支持。

Abstract: This paper addresses the challenge of Lidar-Inertial Odometry (LIO) in
dynamic environments, where conventional methods often fail due to their
static-world assumptions. Traditional LIO algorithms perform poorly when
dynamic objects dominate the scenes, particularly in geometrically sparse
environments. Current approaches to dynamic LIO face a fundamental challenge:
accurate localization requires a reliable identification of static features,
yet distinguishing dynamic objects necessitates precise pose estimation. Our
solution breaks this circular dependency by integrating dynamic awareness
directly into the point cloud registration process. We introduce a novel
dynamic-aware iterative closest point algorithm that leverages spatio-temporal
normal analysis, complemented by an efficient spatial consistency verification
method to enhance static map construction. Experimental evaluations demonstrate
significant performance improvements over state-of-the-art LIO systems in
challenging dynamic environments with limited geometric structure. The code and
dataset are available at https://github.com/thisparticle/btsa.

</details>


### [349] [Toward Humanoid Brain-Body Co-design: Joint Optimization of Control and Morphology for Fall Recovery](https://arxiv.org/abs/2510.22336)
*Bo Yue,Sheng Xu,Kui Jia,Guiliang Liu*

Main category: cs.RO

TL;DR: 本文提出了RoboCraft，一个面向仿人机器人体型与控制策略协同优化的可扩展联合设计框架，显著提升了跌倒恢复能力。


<details>
  <summary>Details</summary>
Motivation: 仿人机器人因其类人形态能够更自然地融入人类工作环境，但要实现其真正的自主和实用性，跌倒恢复是至关重要的功能。因此，研究如何通过联合优化“身体结构”和“控制大脑”来提升跌倒恢复和整体性能成为热点。

Method: 提出并实现了RoboCraft方法框架，采用“脑-体联合设计”理念，实现控制策略（policy）和机器人形态（morphology）迭代式共同优化。共享控制策略可在多种形态间预训练后再针对表现优良的结构个性化微调。形态搜索则融合了类人启发式、优化算法及优先缓冲区机制，兼顾重评有潜力候选和探索新设计。

Result: 实验结果表明，RoboCraft在7款公开仿人机器人上平均性能提升44.55%。在四款机器人联合优化实验中，形态优化在提升中贡献度达40%以上，充分体现了脑-体联合设计的关键价值。

Conclusion: 本文验证了脑-体联合策略在提升仿人机器人跌倒恢复及整体能力方面的重要性，RoboCraft为今后机器人自动化设计和大规模应用奠定了坚实基础。

Abstract: Humanoid robots represent a central frontier in embodied intelligence, as
their anthropomorphic form enables natural deployment in humans' workspace.
Brain-body co-design for humanoids presents a promising approach to realizing
this potential by jointly optimizing control policies and physical morphology.
Within this context, fall recovery emerges as a critical capability. It not
only enhances safety and resilience but also integrates naturally with
locomotion systems, thereby advancing the autonomy of humanoids. In this paper,
we propose RoboCraft, a scalable humanoid co-design framework for fall recovery
that iteratively improves performance through the coupled updates of control
policy and morphology. A shared policy pretrained across multiple designs is
progressively finetuned on high-performing morphologies, enabling efficient
adaptation without retraining from scratch. Concurrently, morphology search is
guided by human-inspired priors and optimization algorithms, supported by a
priority buffer that balances reevaluation of promising candidates with the
exploration of novel designs. Experiments show that \ourmethod{} achieves an
average performance gain of 44.55% on seven public humanoid robots, with
morphology optimization drives at least 40% of improvements in co-designing
four humanoid robots, underscoring the critical role of humanoid co-design.

</details>


### [350] [Estimating Continuum Robot Shape under External Loading using Spatiotemporal Neural Networks](https://arxiv.org/abs/2510.22339)
*Enyi Wang,Zhen Deng,Chuanchuan Pan,Bingwei He,Jianwei Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种基于深度学习的柔性连续体机器人三维形状估计方法，通过多模态时空神经网络，实现了高精度形变重建，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 由于柔性连续体机器人容易受到外部载荷影响，准确估计其三维形状对于控制和应用至关重要，但传统方法在形变加载条件下精度有限，亟需更精准的估型方法。

Method: 提出了一种融合多模态输入（当前及历史腱驱动位移、RGB图像）的时空神经网络。该网络结合了时序特征提取（循环单元）、空间特征提取（编码模块）及多模态融合模块，最终通过拟合Bézier曲线实现三维形状重建。

Result: 在实验验证中，该方法在无载荷和有载荷条件下平均形状估计误差分别为0.08 mm和0.22 mm，精度明显优于现有TDCR形状感知方法。

Conclusion: 实验结果证明，基于深度学习的时空数据融合方法能够高精度地估计加载条件下的连续体机器人三维形状，具有实际应用价值。

Abstract: This paper presents a learning-based approach for accurately estimating the
3D shape of flexible continuum robots subjected to external loads. The proposed
method introduces a spatiotemporal neural network architecture that fuses
multi-modal inputs, including current and historical tendon displacement data
and RGB images, to generate point clouds representing the robot's deformed
configuration. The network integrates a recurrent neural module for temporal
feature extraction, an encoding module for spatial feature extraction, and a
multi-modal fusion module to combine spatial features extracted from visual
data with temporal dependencies from historical actuator inputs. Continuous 3D
shape reconstruction is achieved by fitting B\'ezier curves to the predicted
point clouds. Experimental validation demonstrates that our approach achieves
high precision, with mean shape estimation errors of 0.08 mm (unloaded) and
0.22 mm (loaded), outperforming state-of-the-art methods in shape sensing for
TDCRs. The results validate the efficacy of deep learning-based spatiotemporal
data fusion for precise shape estimation under loading conditions.

</details>


### [351] [BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework for Lane Keeping in Autonomous Vehicles](https://arxiv.org/abs/2510.22370)
*Seyed Ahmad Hosseini Miangoleh,Amin Jalal Aghdasian,Farzaneh Abdollahi*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的多模态强化学习方法BLIP-FusePPO，通过将视觉语言模型(VLM)产生的语义嵌入与几何状态、LiDAR观测和PID控制反馈融合于RL智能体的观测空间，实现更强鲁棒性和可解释性的自动车道保持决策。


<details>
  <summary>Details</summary>
Motivation: 现有车道保持任务中的方法多仅利用视觉或单一模态信息，难以兼顾高层语义理解和低层精确控制，且语义模型常只用于奖励塑形，推理效率低。作者希望实现多信号融合，让语义特征直接参与状态感知，提升策略学习的泛化性和实时性。

Method: 将VLM生成的高层语义嵌入与几何状态、激光雷达观测和PID控制反馈端到端融合，在PPO框架下输入智能体，采用融合了语义对齐、车道保持精度、障碍规避和速度调控的混合奖励函数训练。

Result: 仿真实验表明，BLIP-FusePPO在多种复杂驾驶场景下的车道保持稳定性和适应性均优于最优的视觉或多模态RL基线方法，并显著提升了推理效率。

Conclusion: 通过将语义特征嵌入状态空间而非仅参与奖励塑形，方法兼顾了高效性、泛化性和决策可解释性，为自动驾驶RL研究提供了有力新范式。

Abstract: In this paper, we propose Bootstrapped Language-Image Pretraining-driven
Fused State Representation in Proximal Policy Optimization (BLIP-FusePPO), a
novel multimodal reinforcement learning (RL) framework for autonomous
lane-keeping (LK), in which semantic embeddings generated by a vision-language
model (VLM) are directly fused with geometric states, LiDAR observations, and
Proportional-Integral-Derivative-based (PID) control feedback within the agent
observation space. The proposed method lets the agent learn driving rules that
are aware of their surroundings and easy to understand by combining high-level
scene understanding from the VLM with low-level control and spatial signals.
Our architecture brings together semantic, geometric, and control-aware
representations to make policy learning more robust. A hybrid reward function
that includes semantic alignment, LK accuracy, obstacle avoidance, and speed
regulation helps learning to be more efficient and generalizable. Our method is
different from the approaches that only use semantic models to shape rewards.
Instead, it directly embeds semantic features into the state representation.
This cuts down on expensive runtime inference and makes sure that semantic
guidance is always available. The simulation results show that the proposed
model is better at LK stability and adaptability than the best vision-based and
multimodal RL baselines in a wide range of difficult driving situations. We
make our code publicly available.

</details>


### [352] [A Novel Multi-Timescale Stability-Preserving Hierarchical Reinforcement Learning Controller Framework for Adaptive Control in High-Dimensional Dynamical Systems](https://arxiv.org/abs/2510.22420)
*Mohammad Ali Labbaf Khaniki,Fateme Taroodi,Benyamin Safizadeh*

Main category: cs.RO

TL;DR: 本文提出了一种多时间尺度Lyapunov约束分层强化学习框架（MTLHRL），有效提升高维随机系统的控制稳定性与性能，在仿真中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 高维随机系统（如机器人、自动驾驶、超混沌系统）的控制面临维度灾难、缺乏时间抽象及稳定性难以保证等难题。

Method: 提出MTLHRL框架，将分层策略嵌入到半马尔可夫决策过程中，高层负责策略规划，低层负责反应控制；采用神经Lyapunov函数和Lagrange松弛联合多时间尺度actor-critic优化，利用约束促进学习效率，并严格保证系统稳定。

Result: 在8维超混沌系统和5自由度机器人上，MTLHRL在稳定性、收敛速度及扰动抑制方面显著优于基线策略，取得了最低的误差指标（如超混沌控制IAE为3.912，机器人为1.623）。

Conclusion: MTLHRL理论扎实且实用，为高维复杂随机系统的鲁棒控制提供了高效、可靠的新方案。

Abstract: Controlling high-dimensional stochastic systems, critical in robotics,
autonomous vehicles, and hyperchaotic systems, faces the curse of
dimensionality, lacks temporal abstraction, and often fails to ensure
stochastic stability. To overcome these limitations, this study introduces the
Multi-Timescale Lyapunov-Constrained Hierarchical Reinforcement Learning
(MTLHRL) framework. MTLHRL integrates a hierarchical policy within a
semi-Markov Decision Process (SMDP), featuring a high-level policy for
strategic planning and a low-level policy for reactive control, which
effectively manages complex, multi-timescale decision-making and reduces
dimensionality overhead. Stability is rigorously enforced using a neural
Lyapunov function optimized via Lagrangian relaxation and multi-timescale
actor-critic updates, ensuring mean-square boundedness or asymptotic stability
in the face of stochastic dynamics. The framework promotes efficient and
reliable learning through trust-region constraints and decoupled optimization.
Extensive simulations on an 8D hyperchaotic system and a 5-DOF robotic
manipulator demonstrate MTLHRL's empirical superiority. It significantly
outperforms baseline methods in both stability and performance, recording the
lowest error indices (e.g., Integral Absolute Error (IAE): 3.912 in
hyperchaotic control and IAE: 1.623 in robotics), achieving faster convergence,
and exhibiting superior disturbance rejection. MTLHRL offers a theoretically
grounded and practically viable solution for robust control of complex
stochastic systems.

</details>


### [353] [A short methodological review on social robot navigation benchmarking](https://arxiv.org/abs/2510.22448)
*Pranup Chhetri,Alejandro Torrejon,Sergio Eslava,Luis J. Manso*

Main category: cs.RO

TL;DR: 本文综述了社交机器人导航领域自2020年1月至2025年7月间的评测趋势，梳理了标准缺失造成的问题，并分析当前文献中的主流评价指标、算法和用户调查方法。


<details>
  <summary>Details</summary>
Motivation: 社交机器人导航缺乏公认的评测标准，这可能阻碍该领域进步，并导致研究结论不一致。为弥补这一空白，作者进行了此综述研究。

Method: 作者使用IEEE Xplore数据库检索相关论文，共找到130篇，最终筛选出85篇符合综述标准的论文并进行深入分析，主要关注评测指标、所用算法、人类调查的应用及结论提取方法。

Result: 论文系统总结了文献中用于评测社交机器人导航的各类指标、常见的评测算法、采用的用户调查方法，以及如何利用评测结果得出结论。

Conclusion: 当前社交机器人导航领域缺乏统一的评测标准，这导致研究间存在差异和潜在矛盾。本文的综述有助于梳理现有工作，推动领域内评测体系的标准化。

Abstract: Social Robot Navigation is the skill that allows robots to move efficiently
in human-populated environments while ensuring safety, comfort, and trust.
Unlike other areas of research, the scientific community has not yet achieved
an agreement on how Social Robot Navigation should be benchmarked. This is
notably important, as the lack of a de facto standard to benchmark Social Robot
Navigation can hinder the progress of the field and may lead to contradicting
conclusions. Motivated by this gap, we contribute with a short review focused
exclusively on benchmarking trends in the period from January 2020 to July
2025. Of the 130 papers identified by our search using IEEE Xplore, we analysed
the 85 papers that met the criteria of the review. This review addresses the
metrics used in the literature for benchmarking purposes, the algorithms
employed in such benchmarks, the use of human surveys for benchmarking, and how
conclusions are drawn from the benchmarking results, when applicable.

</details>


### [354] [Forward Kinematics Solution For A General Stewart Platform Through Iteration Based Simulation](https://arxiv.org/abs/2510.22465)
*Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 该论文提出了一种针对一般Stewart平台的前向运动学唯一解生成方法，能够自动、准确地得到可行解，无需人工验证。


<details>
  <summary>Details</summary>
Motivation: Stewart平台这类并联机器人结构在前向运动学求解中存在复杂性及多解性，传统算法下无法快速且自动获得唯一有效的解。针对其有利于材料力学种多自由度复杂加载的需求，亟需一种能自动输出可验证解的算法。

Method: 利用逆向运动学获取移动平台有效工作空间数据及相应驱动长度，基于修正的Denavit-Hartenberg方法设计简单迭代算法，能直接给出每个工作位姿的唯一可行前向解。

Result: 该方法对每种有效位姿都自动生成唯一可行前向运动学解，无需人工验证，且直接可用于后续运算。实验表明该算法在测试系统中的实际应用表现良好。

Conclusion: 新算法简化了并联机构前向运动学求解流程，提升了数据的可靠性与自动化处理能力，特别适用于多自由度材料测试系统等需要精确实时控制的场合。

Abstract: This paper presents a method to generate feasible, unique forward-kinematic
solutions for a general Stewart platform. This is done by using inverse
kinematics to obtain valid workspace data and corresponding actuator lengths
for the moving platform. For parallel kinematic machines, such as the Stewart
Platform, inverse kinematics are straight forward, but the forward kinematics
are complex and generates multiple solutions due to the closed loop structure
of the kinematic links. In this research, a simple iterative algorithm has been
used employing modified Denavit-Hartenberg convention. The outcome is
encouraging as this method generates a single feasible forward kinematic
solution for each valid pose with the solved DH parameters and unlike earlier
forward kinematics solutions, this unique solution does not need to be manually
verified. Therefore, the forward kinematic solutions can be used directly for
further calculations without the need for manual pose verification. This
capability is essential for the six degree of freedom materials testing system
developed by the authors in their laboratory. The developed system is aimed at
characterizing additively manufactured materials under complex combined
multiple loading conditions. The material characterization is done by enabling
high precision force control on the moving platform via in situ calibration of
the as-built kinematics of the Stewart Gough Platform.

</details>


### [355] [On Steerability Factors for Growing Vine Robots](https://arxiv.org/abs/2510.22504)
*Ciera McFarland,Antonio Alvarez,Sarah Taher,Nathaniel Hanson,Margaret McGuinness*

Main category: cs.RO

TL;DR: 本论文研究了影响Vine机器人转向能力（可控曲率）的关键参数，包括前端载重、气压、长度、直径及制造方式，并提出了优化设计原则。


<details>
  <summary>Details</summary>
Motivation: Vine机器人能在复杂环境中前行，广泛应用于救援等领域，但其性能受限于传感器或工具的重量及设计选型。为提升实际应用能力，亟需系统分析这些因素对转向性能的影响。

Method: 作者采用室内实验，针对两种Vine机器人（自支持、地面支撑）分别研究前端载重、气压、长度、直径、制造方法及驱动压力比例对机器人转弯能力的影响，分析不同执行器布局与实施参数。

Result: 转向能力随前端载重增加而下降、在中等腔体气压时最好、长度越长转向能力越强、直径影响较小。执行器若集成于机器人本体，需更高压力才能转向但最终曲率更大；若装在外部，低压即可开始弯曲但曲率易饱和。优化参数设计的机器人在任务中曲率表现优于普通配置。

Conclusion: 通过合理选择载重、气压、长度和执行器集成方式等设计参数，可显著提升Vine机器人的弯曲和机动表现，为其在实地救援等领域应用打下基础。

Abstract: Vine robots extend their tubular bodies by everting material from the tip,
enabling navigation in complex environments with a minimalist soft body.
Despite their promise for field applications, especially in the urban search
and rescue domain, performance is constrained by the weight of attached sensors
or tools, as well as other design and control choices. This work investigates
how tip load, pressure, length, diameter, and fabrication method shape vine
robot steerability--the ability to maneuver with controlled curvature--for
robots that steer with series pouch motor-style pneumatic actuators. We conduct
two groups of experiments: (1) studying tip load, chamber pressure, length, and
diameter in a robot supporting itself against gravity, and (2) studying
fabrication method and ratio of actuator to chamber pressure in a robot
supported on the ground. Results show that steerability decreases with
increasing tip load, is best at moderate chamber pressure, increases with
length, and is largely unaffected by diameter. Robots with actuators attached
on their exterior begin curving at low pressure ratios, but curvature saturates
at high pressure ratios; those with actuators integrated into the robot body
require higher pressure ratios to begin curving but achieve higher curvature
overall. We demonstrate that robots optimized with these principles outperform
those with ad hoc parameters in a mobility task that involves maximizing upward
and horizontal curvatures.

</details>


### [356] [Ant-inspired Walling Strategies for Scalable Swarm Separation: Reinforcement Learning Approaches Based on Finite State Machines](https://arxiv.org/abs/2510.22524)
*Shenbagaraj Kannapiran,Elena Oikonomou,Albert Chu,Spring Berman,Theodore P. Pavlic*

Main category: cs.RO

TL;DR: 本文受自然界中军蚁构建临时墙以维持秩序的启发，提出了两种用于异构机器人群体保持空间分隔的去中心化控制器。实验表明，这些方法能显著减少子群体间的混合。


<details>
  <summary>Details</summary>
Motivation: 自然系统中常有生物通过自组织结构平衡不同需求，军蚁通过筑墙防止觅食路径间干扰。作者希望将这种自组织策略应用于机器人群体，使其在执行并发任务时保持空间分隔，减少冲突，提高协作效率。

Method: 提出了两种控制方法：一种是基于有限状态机（FSM），通过遭遇触发状态转移，形成稳定墙体；另一种则把FSM与深度Q网络（DQN）结合，利用强化学习动态优化“非军事区”，实现更自适应的空间分隔。所有方法均采用分布式架构。

Result: 仿真结果显示，两种控制器都能有效减少机器人子群体的混合。特别是DQN增强型控制器，不仅适应性更强，而且混合度降低了40-50%，收敛速度也更快。

Conclusion: 仿真证明，军蚁启发的去中心化控制策略能显著改善机器人群体空间分隔，并提高任务并发执行的效率。DQN方法在适应性和性能提升方面效果突出。

Abstract: In natural systems, emergent structures often arise to balance competing
demands. Army ants, for example, form temporary "walls" that prevent
interference between foraging trails. Inspired by this behavior, we developed
two decentralized controllers for heterogeneous robotic swarms to maintain
spatial separation while executing concurrent tasks. The first is a
finite-state machine (FSM)-based controller that uses encounter-triggered
transitions to create rigid, stable walls. The second integrates FSM states
with a Deep Q-Network (DQN), dynamically optimizing separation through emergent
"demilitarized zones." In simulation, both controllers reduce mixing between
subgroups, with the DQN-enhanced controller improving adaptability and reducing
mixing by 40-50% while achieving faster convergence.

</details>


### [357] [SPIRAL: Self-Play Incremental Racing Algorithm for Learning in Multi-Drone Competitions](https://arxiv.org/abs/2510.22568)
*Onur Akgün*

Main category: cs.RO

TL;DR: 本文提出了SPIRAL（一种基于自博弈的增量训练方法），提升多智能体无人机竞速能力。通过自博弈机制，无人机能逐步适应更复杂的竞赛环境，显著优化自主竞速表现。


<details>
  <summary>Details</summary>
Motivation: 多智能体无人机竞速的复杂性与挑战性需要新的高效训练方法，现有方法难以适应不断升级的竞争环境，且泛化与自主学习能力有限。

Method: SPIRAL引入自博弈机制，代理与自身实力不断提升的历史版本竞赛，将基础飞行技能逐步提升到复杂的协作竞速策略，且框架可集成任意最新深度强化学习算法。

Result: 在模拟实验下，SPIRAL平台显著提升了各类深度强化学习算法的竞速表现，展现出在多无人机竞速任务中的有效性和优越性。

Conclusion: SPIRAL为无人机竞速领域提供了一个灵活、可扩展、自我提升的学习框架，能够自动生成逐步升级的挑战，为智能无人机在复杂环境中实现稳健、适应性强的发展提供了新方向。

Abstract: This paper introduces SPIRAL (Self-Play Incremental Racing Algorithm for
Learning), a novel approach for training autonomous drones in multi-agent
racing competitions. SPIRAL distinctively employs a self-play mechanism to
incrementally cultivate complex racing behaviors within a challenging, dynamic
environment. Through this self-play core, drones continuously compete against
increasingly proficient versions of themselves, naturally escalating the
difficulty of competitive interactions. This progressive learning journey
guides agents from mastering fundamental flight control to executing
sophisticated cooperative multi-drone racing strategies. Our method is designed
for versatility, allowing integration with any state-of-the-art Deep
Reinforcement Learning (DRL) algorithms within its self-play framework.
Simulations demonstrate the significant advantages of SPIRAL and benchmark the
performance of various DRL algorithms operating within it. Consequently, we
contribute a versatile, scalable, and self-improving learning framework to the
field of autonomous drone racing. SPIRAL's capacity to autonomously generate
appropriate and escalating challenges through its self-play dynamic offers a
promising direction for developing robust and adaptive racing strategies in
multi-agent environments. This research opens new avenues for enhancing the
performance and reliability of autonomous racing drones in increasingly complex
and competitive scenarios.

</details>


### [358] [Curriculum-Based Iterative Self-Play for Scalable Multi-Drone Racing](https://arxiv.org/abs/2510.22570)
*Onur Akgün*

Main category: cs.RO

TL;DR: 论文提出CRUISE框架，一种结合递进式课程和自博弈的强化学习方法，用于多无人机竞速，显著优于现有方法，并具备良好可扩展性。


<details>
  <summary>Details</summary>
Motivation: 多智能体在高速、竞争性环境中的协调控制面临巨大挑战，尤其是在无人机竞速等复杂场景下，现有方法在规模和性能上存在瓶颈。

Method: 提出CRUISE强化学习框架，结合课程学习（通过逐步增加难度训练智能体）和高效自博弈机制，使多无人机可以在竞争场景中学习到更为健壮和高效的竞速策略。

Result: 在高保真仿真和真实的四旋翼动力学下，CRUISE训练的策略在竞速速度、成功率和扩展能力上均大幅优于传统强化学习基线和先进的博弈论规划器，速度提升接近一倍。消融实验表明课程结构是性能提升的关键。

Conclusion: CRUISE框架为动态、竞争性任务的自主系统开发提供了有效且可扩展的方法，并为未来实际部署提供了参考蓝本。

Abstract: The coordination of multiple autonomous agents in high-speed, competitive
environments represents a significant engineering challenge. This paper
presents CRUISE (Curriculum-Based Iterative Self-Play for Scalable Multi-Drone
Racing), a reinforcement learning framework designed to solve this challenge in
the demanding domain of multi-drone racing. CRUISE overcomes key scalability
limitations by synergistically combining a progressive difficulty curriculum
with an efficient self-play mechanism to foster robust competitive behaviors.
Validated in high-fidelity simulation with realistic quadrotor dynamics, the
resulting policies significantly outperform both a standard reinforcement
learning baseline and a state-of-the-art game-theoretic planner. CRUISE
achieves nearly double the planner's mean racing speed, maintains high success
rates, and demonstrates robust scalability as agent density increases. Ablation
studies confirm that the curriculum structure is the critical component for
this performance leap. By providing a scalable and effective training
methodology, CRUISE advances the development of autonomous systems for dynamic,
competitive tasks and serves as a blueprint for future real-world deployment.

</details>


### [359] [RoGER-SLAM: A Robust Gaussian Splatting SLAM System for Noisy and Low-light Environment Resilience](https://arxiv.org/abs/2510.22600)
*Huilin Yin,Zhaolin Yang,Linchuan Zhang,Gerhard Rigoll,Johannes Betz*

Main category: cs.RO

TL;DR: RoGER-SLAM提出一种应对噪声和低光照环境下3DGS-SLAM系统的新方法，通过多项创新显著提升了定位与地图重建的鲁棒性和精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D Gaussian Splatting (3DGS) 的SLAM系统在理想条件下效果出色，但在噪声干扰和低照明环境下性能大幅下降，实际上限制了SLAM技术在真实恶劣环境中的应用。作者旨在解决视觉输入受损时的映射与定位问题，提升SLAM系统的鲁棒性。

Method: 提出RoGER-SLAM系统，包含三大创新：（1）结构保持鲁棒融合（SP-RoFusion）模块，融合外观、深度和边缘特征；（2）自适应残差平衡正则化的跟踪优化目标，提高追踪鲁棒性；（3）基于CLIP的增强模块，在复合退化条件下恢复语义和结构信息。

Result: 在Replica、TUM以及真实世界数据集进行大量实验，RoGER-SLAM在各类不良成像环境下，相较于现有3DGS-SLAM方法，其轨迹精度及重建质量均获得显著提升。

Conclusion: RoGER-SLAM有效增强了3DGS-SLAM系统的抗噪声和低照明能力，针对真实复杂场景具有更强的适应性和可靠性，推动了高鲁棒性SLAM系统的进步。

Abstract: The reliability of Simultaneous Localization and Mapping (SLAM) is severely
constrained in environments where visual inputs suffer from noise and low
illumination. Although recent 3D Gaussian Splatting (3DGS) based SLAM
frameworks achieve high-fidelity mapping under clean conditions, they remain
vulnerable to compounded degradations that degrade mapping and tracking
performance. A key observation underlying our work is that the original 3DGS
rendering pipeline inherently behaves as an implicit low-pass filter,
attenuating high-frequency noise but also risking over-smoothing. Building on
this insight, we propose RoGER-SLAM, a robust 3DGS SLAM system tailored for
noise and low-light resilience. The framework integrates three innovations: a
Structure-Preserving Robust Fusion (SP-RoFusion) mechanism that couples
rendered appearance, depth, and edge cues; an adaptive tracking objective with
residual balancing regularization; and a Contrastive Language-Image Pretraining
(CLIP)-based enhancement module, selectively activated under compounded
degradations to restore semantic and structural fidelity. Comprehensive
experiments on Replica, TUM, and real-world sequences show that RoGER-SLAM
consistently improves trajectory accuracy and reconstruction quality compared
with other 3DGS-SLAM systems, especially under adverse imaging conditions.

</details>


### [360] [Uncertainty-Aware Autonomous Vehicles: Predicting the Road Ahead](https://arxiv.org/abs/2510.22680)
*Shireen Kudukkil Manchingal,Armand Amaritei,Mihir Gohad,Maryam Sultana,Julian F. P. Kooij,Fabio Cuzzolin,Andrew Bradley*

Main category: cs.RO

TL;DR: 本文提出并实验证明了一种基于不确定性感知的图像分类方法（RS-NN），用于提升自动驾驶车辆在新颖或模糊场景下的安全性和鲁棒性。该方法优于传统CNN和贝叶斯神经网络，在路况多变时的准确率和不确定性校准表现更佳。


<details>
  <summary>Details</summary>
Motivation: 尽管自动驾驶感知系统进步迅速，但在罕见事件或未知场景下仍容易因过度自信导致决策错误，因此需提升系统“知晓何时不确定”的能力，提升安全性。

Method: 引入RS-NN（Random-Set Neural Network）作为自动驾驶车辆感知模块，利用其对类别集合预测信念函数的能力，量化和识别新奇或模棱两可场景中的不确定性，并接入ROS车辆控制系统，根据预测不确定性动态调整行驶速度。

Result: RS-NN在多种路况下展现出更高的分类准确率和更优的不确定性校准能力，优于传统CNN和贝叶斯NN。

Conclusion: 将不确定性感知（特别是RS-NN）集成到自动驾驶系统中的可行性与有效性得以证明，能够提升车辆安全性和鲁棒性，适合实际应用。

Abstract: Autonomous Vehicle (AV) perception systems have advanced rapidly in recent
years, providing vehicles with the ability to accurately interpret their
environment. Perception systems remain susceptible to errors caused by
overly-confident predictions in the case of rare events or out-of-sample data.
This study equips an autonomous vehicle with the ability to 'know when it is
uncertain', using an uncertainty-aware image classifier as part of the AV
software stack. Specifically, the study exploits the ability of Random-Set
Neural Networks (RS-NNs) to explicitly quantify prediction uncertainty. Unlike
traditional CNNs or Bayesian methods, RS-NNs predict belief functions over sets
of classes, allowing the system to identify and signal uncertainty clearly in
novel or ambiguous scenarios. The system is tested in a real-world autonomous
racing vehicle software stack, with the RS-NN classifying the layout of the
road ahead and providing the associated uncertainty of the prediction.
Performance of the RS-NN under a range of road conditions is compared against
traditional CNN and Bayesian neural networks, with the RS-NN achieving
significantly higher accuracy and superior uncertainty calibration. This
integration of RS-NNs into Robot Operating System (ROS)-based vehicle control
pipeline demonstrates that predictive uncertainty can dynamically modulate
vehicle speed, maintaining high-speed performance under confident predictions
while proactively improving safety through speed reductions in uncertain
scenarios. These results demonstrate the potential of uncertainty-aware neural
networks - in particular RS-NNs - as a practical solution for safer and more
robust autonomous driving.

</details>


### [361] [RL-AVIST: Reinforcement Learning for Autonomous Visual Inspection of Space Targets](https://arxiv.org/abs/2510.22699)
*Matteo El-Hariry,Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习（RL）的空间目标自主视觉巡检系统RL-AVIST，旨在提升航天器在复杂任务环境下的操控与自适应能力。


<details>
  <summary>Details</summary>
Motivation: 目前在轨服务对航天器的自主性提出更高要求，如巡视、维护和态势感知。但传统控制系统难以应对模型不确定性、多航天器协作和任务动态变化等实际挑战。

Method: 作者利用高保真六自由度（6-DOF）航天器动力学仿真平台Space Robotics Bench（SRB），采用先进的模型化强化学习算法DreamerV3进行训练，并以PPO和TD3作为模型无关基线，对航天器在空间目标附近的三维机动任务进行研究。分别评估了泛化型（随机速度向量训练）和专用型（固定轨迹训练）智能体的性能，并检验政策在不同航天器形态与任务领域下的鲁棒性和泛化能力。

Result: 实验结果表明，基于模型的RL方法（如DreamerV3）在轨迹精度和样本效率方面取得了优异表现，优于模型无关方法。相关策略在不同任务和平台上的泛化能力良好。

Conclusion: 模型化强化学习为未来空间操作任务提供了可扩展、可重训练的控制解决方案，展现了在自主航天器视觉巡检等任务中的巨大潜力。

Abstract: The growing need for autonomous on-orbit services such as inspection,
maintenance, and situational awareness calls for intelligent spacecraft capable
of complex maneuvers around large orbital targets. Traditional control systems
often fall short in adaptability, especially under model uncertainties,
multi-spacecraft configurations, or dynamically evolving mission contexts. This
paper introduces RL-AVIST, a Reinforcement Learning framework for Autonomous
Visual Inspection of Space Targets. Leveraging the Space Robotics Bench (SRB),
we simulate high-fidelity 6-DOF spacecraft dynamics and train agents using
DreamerV3, a state-of-the-art model-based RL algorithm, with PPO and TD3 as
model-free baselines. Our investigation focuses on 3D proximity maneuvering
tasks around targets such as the Lunar Gateway and other space assets. We
evaluate task performance under two complementary regimes: generalized agents
trained on randomized velocity vectors, and specialized agents trained to
follow fixed trajectories emulating known inspection orbits. Furthermore, we
assess the robustness and generalization of policies across multiple spacecraft
morphologies and mission domains. Results demonstrate that model-based RL
offers promising capabilities in trajectory fidelity, and sample efficiency,
paving the way for scalable, retrainable control solutions for future space
operations

</details>


### [362] [SCAL for Pinch-Lifting: Complementary Rotational and Linear Prototypes for Environment-Adaptive Grasping](https://arxiv.org/abs/2510.22738)
*Wentao Guo,Wenzeng Zhang*

Main category: cs.RO

TL;DR: 本论文提出了一种基于可自适应连杆的两种夹持手指（SCAL-R和SCAL-L）用于环境自适应夹取，能够实现对不同形态物体的稳定抓取，并在多种实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前夹持器在应对物体多样性和复杂环境时存在稳定性和适应性不足的问题，难以无缝处理薄形、低矮或结构弱特征的物体，因此需要一种操作简单、适用范围广且具自适应能力的夹持解决方案。

Method: 设计了两种互补的自适应手指——旋转驱动主动包覆型（SCAL-R）和线性驱动被动开合型（SCAL-L），通过3D打印制备成夹持器，并在不同物体和任务情景下进行夹取、滑动、夹升等实验，同时进行准静态分析建立了力学模型，指导结构设计与操作。

Result: 两种自适应手指在夹取小部件、盒子、罐子、胶带环等多种物体时均表现出一致的稳定夹持能力，操作无需精细调节；准静态分析得到封闭形式的力学模型，可指导设计选择。

Conclusion: SCAL-R和SCAL-L实现了对不同环境和物体的互补、稳定夹取，展示了简单驱动下环境自适应抓取的可行性，为实用型夹持器的设计提供了新路径。

Abstract: This paper presents environment-adaptive pinch-lifting built on a
slot-constrained adaptive linkage (SCAL) and instantiated in two complementary
fingers: SCAL-R, a rotational-drive design with an active fingertip that folds
inward after contact to form an envelope, and SCAL-L, a linear-drive design
that passively opens on contact to span wide or weak-feature objects. Both
fingers convert surface following into an upward lifting branch while
maintaining fingertip orientation, enabling thin or low-profile targets to be
raised from supports with minimal sensing and control. Two-finger grippers are
fabricated via PLA-based 3D printing. Experiments evaluate (i)
contact-preserving sliding and pinch-lifting on tabletops, (ii) ramp
negotiation followed by lift, and (iii) handling of bulky objects via active
enveloping (SCAL-R) or contact-triggered passive opening (SCAL-L). Across
dozens of trials on small parts, boxes, jars, and tape rolls, both designs
achieve consistent grasps with limited tuning. A quasi-static analysis provides
closed-form fingertip-force models for linear parallel pinching and two-point
enveloping, offering geometry-aware guidance for design and operation. Overall,
the results indicate complementary operating regimes and a practical path to
robust, environment-adaptive grasping with simple actuation.

</details>


### [363] [Policies over Poses: Reinforcement Learning based Distributed Pose-Graph Optimization for Multi-Robot SLAM](https://arxiv.org/abs/2510.22740)
*Sai Krishna Ghanta,Ramviyas Parasuraman*

Main category: cs.RO

TL;DR: 该论文提出了一种基于多智能体强化学习（MARL）的分布式二维Pose-Graph Optimization（PGO）方法，显著提升了多机器人SLAM中的轨迹估计精度和计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统PGO方法依赖高度非凸问题的线性化与反复求解，对噪声和局部最优敏感，难以应对多机器人SLAM中的规模扩展和异常值干扰。需要更强鲁棒性与可扩展性的分布式优化方法。

Method: 将分布式PGO建模为局部Pose-Graph上的部分可观马尔可夫博弈，每一步通过动作优化一条边的位姿估计。利用图分割对任务分块，每台机器人运行带自适应边门控的循环图神经网络编码器去噪。机器人采用混合策略（结合历史动作和图嵌入）依次修正局部边，局部优化后再通过一致性机制融合多机器人结果。

Result: 在大量合成与真实数据集上评测，所提MARL方案比现有最佳分布式PGO框架全球目标值平均多减少37.5%，推理效率提升至少6倍。且学习到的策略可无缝扩展到大规模机器人团队，无需重新训练。

Conclusion: 基于MARL与图神经网络的分布式PGO新框架在多机器人SLAM场景下表现出色，不仅提升了精度与效率，还具备良好扩展性。

Abstract: We consider the distributed pose-graph optimization (PGO) problem, which is
fundamental in accurate trajectory estimation in multi-robot simultaneous
localization and mapping (SLAM). Conventional iterative approaches linearize a
highly non-convex optimization objective, requiring repeated solving of normal
equations, which often converge to local minima and thus produce suboptimal
estimates. We propose a scalable, outlier-robust distributed planar PGO
framework using Multi-Agent Reinforcement Learning (MARL). We cast distributed
PGO as a partially observable Markov game defined on local pose-graphs, where
each action refines a single edge's pose estimate. A graph partitioner
decomposes the global pose graph, and each robot runs a recurrent
edge-conditioned Graph Neural Network (GNN) encoder with adaptive edge-gating
to denoise noisy edges. Robots sequentially refine poses through a hybrid
policy that utilizes prior action memory and graph embeddings. After local
graph correction, a consensus scheme reconciles inter-robot disagreements to
produce a globally consistent estimate. Our extensive evaluations on a
comprehensive suite of synthetic and real-world datasets demonstrate that our
learned MARL-based actors reduce the global objective by an average of 37.5%
more than the state-of-the-art distributed PGO framework, while enhancing
inference efficiency by at least 6X. We also demonstrate that actor replication
allows a single learned policy to scale effortlessly to substantially larger
robot teams without any retraining. Code is publicly available at
https://github.com/herolab-uga/policies-over-poses.

</details>


### [364] [TWC-SLAM: Multi-Agent Cooperative SLAM with Text Semantics and WiFi Features Integration for Similar Indoor Environments](https://arxiv.org/abs/2510.22754)
*Chunyu Li,Shoubin Chen,Dong Li,Weixing Xue,Qingquan Li*

Main category: cs.RO

TL;DR: 本论文提出TWC-SLAM，将文本语义和WiFi信号特征融入多智能体协作SLAM框架，提高在结构重复的室内环境中的定位和闭环检测精度。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体协作SLAM系统在点云为主的方案下，难以在相似结构（如走廊、房间重复）环境中进行准确的位点辨识，导致地图融合和闭环准确性下降。

Method: 提出TWC-SLAM协作SLAM框架，融合文本语义信息和WiFi信号特征。系统包括单体前端里程计、融合文本和WiFi的位点识别与闭环检测模块及全局建图模块。多智能体配备可识别文本与WiFi信号的传感器，通过多源信息相关性实现有效的位点辨识与点云对齐。

Result: 在包含相似走廊、房间和文字标识的室内数据集上实验，TWC-SLAM显著提升了在重复建筑结构环境下的协作SLAM性能。

Conclusion: TWC-SLAM通过引入文本语义和WiFi特征，有效解决了多智能体SLAM在重复结构环境下位点识别准确性不足的问题，实现了更高精度的地图构建与协作定位。

Abstract: Multi-agent cooperative SLAM often encounters challenges in similar indoor
environments characterized by repetitive structures, such as corridors and
rooms. These challenges can lead to significant inaccuracies in shared location
identification when employing point cloud-based techniques. To mitigate these
issues, we introduce TWC-SLAM, a multi-agent cooperative SLAM framework that
integrates text semantics and WiFi signal features to enhance location
identification and loop closure detection. TWC-SLAM comprises a single-agent
front-end odometry module based on FAST-LIO2, a location identification and
loop closure detection module that leverages text semantics and WiFi features,
and a global mapping module. The agents are equipped with sensors capable of
capturing textual information and detecting WiFi signals. By correlating these
data sources, TWC-SLAM establishes a common location, facilitating point cloud
alignment across different agents' maps. Furthermore, the system employs loop
closure detection and optimization modules to achieve global optimization and
cohesive mapping. We evaluated our approach using an indoor dataset featuring
similar corridors, rooms, and text signs. The results demonstrate that TWC-SLAM
significantly improves the performance of cooperative SLAM systems in complex
environments with repetitive architectural features.

</details>


### [365] [PIP-LLM: Integrating PDDL-Integer Programming with LLMs for Coordinating Multi-Robot Teams Using Natural Language](https://arxiv.org/abs/2510.22784)
*Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme*

Main category: cs.RO

TL;DR: 本文提出了PIP-LLM框架，用于将自然语言指令高效地分解并执行到多机器人系统上，提升了任务成功率和团队效率。


<details>
  <summary>Details</summary>
Motivation: 现有将大语言模型与PDDL结合的方法主要聚焦于单机器人任务，在多机器人任务中面临任务分解脆弱、扩展性差与协调效率低的问题。

Method: 提出PIP-LLM框架，分为两步：首先将自然语言命令转为基于PDDL的团队级任务规划，获得团队级计划并抽象掉具体机器人分配。然后将团队级计划转为任务依赖图，针对每个子任务利用整数规划进行机器人分配，显式优化成本和负载均衡，同时满足机器人能力与用户约束。

Result: 在各种任务上的实验表明，PIP-LLM相较于现有方法在任务成功率、最大与平均移动成本、负载均衡等方面均有提升。

Conclusion: PIP-LLM通过规划与分配两步分离，解决了传统方法在多机器人任务上的缺陷，能够更好地处理大规模团队任务与复杂约束，具有较强的实用性和推广价值。

Abstract: Enabling robot teams to execute natural language commands requires
translating high-level instructions into feasible, efficient multi-robot plans.
While Large Language Models (LLMs) combined with Planning Domain Description
Language (PDDL) offer promise for single-robot scenarios, existing approaches
struggle with multi-robot coordination due to brittle task decomposition, poor
scalability, and low coordination efficiency.
  We introduce PIP-LLM, a language-based coordination framework that consists
of PDDL-based team-level planning and Integer Programming (IP) based
robot-level planning. PIP-LLMs first decomposes the command by translating the
command into a team-level PDDL problem and solves it to obtain a team-level
plan, abstracting away robot assignment. Each team-level action represents a
subtask to be finished by the team. Next, this plan is translated into a
dependency graph representing the subtasks' dependency structure. Such a
dependency graph is then used to guide the robot-level planning, in which each
subtask node will be formulated as an IP-based task allocation problem,
explicitly optimizing travel costs and workload while respecting robot
capabilities and user-defined constraints. This separation of planning from
assignment allows PIP-LLM to avoid the pitfalls of syntax-based decomposition
and scale to larger teams. Experiments across diverse tasks show that PIP-LLM
improves plan success rate, reduces maximum and average travel costs, and
achieves better load balancing compared to state-of-the-art baselines.

</details>


### [366] [Learning Neural Observer-Predictor Models for Limb-level Sampling-based Locomotion Planning](https://arxiv.org/abs/2510.22789)
*Abhijeet M. Kulkarni,Ioannis Poulakakis,Guoquan Huang*

Main category: cs.RO

TL;DR: 本文提出了一种基于学习的观测-预测框架，可高效且准确地预测腿式机器人全身运动，显著提升了其在复杂环境中的自主导航和碰撞规避能力。


<details>
  <summary>Details</summary>
Motivation: 腿式机器人的全身运动预测对其安全、自主导航极为重要，尤其是在拥挤环境下进行肢体级的碰撞检测。然而，传统简化运动模型难以捕捉机器人及其低层控制器的复杂闭环动力学，限制了其预测能力。

Method: 提出了一种学习型的观测-预测框架，包括：1）带有可证明UUB（有界最终稳定性）保证的神经观测器，通过历史本体感觉数据稳定估计潜在状态；2）高效的运动预测器，支持采样推理规划器对数千种潜在轨迹的快速、并行评估。最后将该框架集成至MPPI规划器，并在Vision 60四足机器人上进行硬件实验验证。

Result: 集成后的系统在通过狭窄通道和越过小型障碍物等具有挑战性的场景下，成功实现了有效的、具肢体感知能力的运动规划。实验结果证明了所提方法在动态机器人平台上为高性能、碰撞感知规划提供了坚实基础。

Conclusion: 该方法显著提升了腿式机器人在复杂动态环境中运动预测和碰撞检测的能力，验证了基于深度学习潜在状态估计结合高效预测器的实用价值，可为未来动态平台的高性能规划奠定基础。

Abstract: Accurate full-body motion prediction is essential for the safe, autonomous
navigation of legged robots, enabling critical capabilities like limb-level
collision checking in cluttered environments. Simplified kinematic models often
fail to capture the complex, closed-loop dynamics of the robot and its
low-level controller, limiting their predictions to simple planar motion. To
address this, we present a learning-based observer-predictor framework that
accurately predicts this motion. Our method features a neural observer with
provable UUB guarantees that provides a reliable latent state estimate from a
history of proprioceptive measurements. This stable estimate initializes a
computationally efficient predictor, designed for the rapid, parallel
evaluation of thousands of potential trajectories required by modern
sampling-based planners. We validated the system by integrating our neural
predictor into an MPPI-based planner on a Vision 60 quadruped. Hardware
experiments successfully demonstrated effective, limb-aware motion planning in
a challenging, narrow passage and over small objects, highlighting our system's
ability to provide a robust foundation for high-performance, collision-aware
planning on dynamic robotic platforms.

</details>


### [367] [Analytical Swarm Chemistry: Characterization and Analysis of Emergent Swarm Behaviors](https://arxiv.org/abs/2510.22821)
*Ricardo Vega,Connor Mattson,Kevin Zhu,Daniel S. Brown,Cameron Nowzari*

Main category: cs.RO

TL;DR: 提出了一种新的群体机器人分析框架，可用来系统探索参数与群体行为的关系，通过相图法分析和化学类比，识别并验证了参数空间中可重复产生特定行为的区域。


<details>
  <summary>Details</summary>
Motivation: 尽管群体机器人在理论上用途广泛，但现实中由于涌现行为难以预测，实际应用很少。传统工程与生命模拟法各有不足，因此需一种能系统分析涌现行为的框架。

Method: 提出了“分析性群体化学”框架，融合工程、人工生命和化学概念。通过系统定义群体宏观状态，并利用相图工具，把参数视为“热力学变量”，来分析参数对行为的作用。并在最小能力的群体机器人上应用该方法。

Result: 运用该框架，发现了能可靠产生特定行为（如旋转、扩散）的足够条件和参数区，并通过初步的真实机器人实验证明这些参数区确实可实现相应群体行为。

Conclusion: 该框架为群体机器人涌现行为的可预测与可控提供了理论基础，有助于推动其在现实世界中的可靠部署。

Abstract: Swarm robotics has potential for a wide variety of applications, but
real-world deployments remain rare due to the difficulty of predicting emergent
behaviors arising from simple local interactions. Traditional engineering
approaches design controllers to achieve desired macroscopic outcomes under
idealized conditions, while agent-based and artificial life studies explore
emergent phenomena in a bottom-up, exploratory manner. In this work, we
introduce Analytical Swarm Chemistry, a framework that integrates concepts from
engineering, agent-based and artificial life research, and chemistry. This
framework combines macrostate definitions with phase diagram analysis to
systematically explore how swarm parameters influence emergent behavior.
Inspired by concepts from chemistry, the framework treats parameters like
thermodynamic variables, enabling visualization of regions in parameter space
that give rise to specific behaviors. Applying this framework to agents with
minimally viable capabilities, we identify sufficient conditions for behaviors
such as milling and diffusion and uncover regions of the parameter space that
reliably produce these behaviors. Preliminary validation on real robots
demonstrates that these regions correspond to observable behaviors in practice.
By providing a principled, interpretable approach, this framework lays the
groundwork for predictable and reliable emergent behavior in real-world swarm
systems.

</details>


### [368] [Kinematically Controllable Cable Robots with Reconfigurable End-effectors](https://arxiv.org/abs/2510.22825)
*Nan Zhang*

Main category: cs.RO

TL;DR: 本论文提出了通过结构创新，扩大了索驱动机器人机械手末端执行器的旋转工作空间，并简化了控制难度。


<details>
  <summary>Details</summary>
Motivation: 传统扩展索驱动机器人工作空间的方法往往通过增加电缆数量，带来了电缆干涉和张力解非唯一性等挑战，导致控制复杂化。

Method: 作者设计了一种结构简单的可重构末端执行器，主要引入了弹簧、螺旋槽轴以及匹配螺母，将末端执行器内部的线性运动转化为旋转。同时，加入了轴承以赋予额外的旋转自由度，避免系统冗余。

Result: 该结构设计显著扩展了机器人末端执行器的旋转工作空间，同时保证了系统的非冗余性。

Conclusion: 所提方案不仅提升了索驱动机器人末端的可控性，还简化了对张力感知和控制的依赖，使机器人能够仅用运动学方法实现准确控制。

Abstract: To enlarge the translational workspace of cable-driven robots, one common
approach is to increase the number of cables. However, this introduces two
challenges: (1) cable interference significantly reduces the rotational
workspace, and (2) the solution of tensions in cables becomes non-unique,
resulting in difficulties for kinematic control of the robot. In this work, we
design structurally simple reconfigurable end-effectors for cable robots. By
incorporating a spring, a helical-grooved shaft, and a matching nut, relative
linear motions between end-effector components are converted into relative
rotations, thereby expanding the rotational workspace of the mechanism.
Meanwhile, a bearing is introduced to provide an additional rotational degree
of freedom, making the mechanism non-redundant. As a result, the robot's motion
can be controlled purely through kinematics without additional tension sensing
and control.

</details>


### [369] [Never Too Rigid to Reach: Adaptive Virtual Model Control with LLM- and Lyapunov-Based Reinforcement Learning](https://arxiv.org/abs/2510.22892)
*Jingzehua Xu,Yangyang Li,Yangfei Chen,Guanwen Xie,Shuai Zhang*

Main category: cs.RO

TL;DR: 本文提出了结合大语言模型（LLM）和Lyapunov基强化学习的自适应虚拟模型控制（VMC）方法，用于提升机器人机械臂在不确定环境下的灵活性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统的虚拟模型控制（VMC）虽然能实现柔顺控制，但其参数固定、虚拟构件协同有限，导致在面临扰动或任务变化时适应能力差、稳定性不足。解决VMC适应性差和安全性保障的问题，成为机器人控制领域的需求。

Method: 该方法在VMC框架下，利用大语言模型（LLM）作为先验知识和高层推理的提供者，提升虚拟构件间的协同性和任务适应性，同时通过Lyapunov约束的强化学习实现带理论稳定保证的在线自适应调整。

Result: 在7自由度Panda机械臂上的大量仿真实验证明，该方法在动态任务中能有效平衡多种目标，性能优于常规方法，同时显示LLM引导与Lyapunov约束共同促进的优势。

Conclusion: 文中方法既保持了VMC的物理可解释性，又增添了自适应与理论稳定保障，为不确定环境中的机器人控制提供了有效的新途径。

Abstract: Robotic arms are increasingly deployed in uncertain environments, yet
conventional control pipelines often become rigid and brittle when exposed to
perturbations or incomplete information. Virtual Model Control (VMC) enables
compliant behaviors by embedding virtual forces and mapping them into joint
torques, but its reliance on fixed parameters and limited coordination among
virtual components constrains adaptability and may undermine stability as task
objectives evolve. To address these limitations, we propose Adaptive VMC with
Large Language Model (LLM)- and Lyapunov-Based Reinforcement Learning (RL),
which preserves the physical interpretability of VMC while supporting
stability-guaranteed online adaptation. The LLM provides structured priors and
high-level reasoning that enhance coordination among virtual components,
improve sample efficiency, and facilitate flexible adjustment to varying task
requirements. Complementarily, Lyapunov-based RL enforces theoretical stability
constraints, ensuring safe and reliable adaptation under uncertainty. Extensive
simulations on a 7-DoF Panda arm demonstrate that our approach effectively
balances competing objectives in dynamic tasks, achieving superior performance
while highlighting the synergistic benefits of LLM guidance and
Lyapunov-constrained adaptation.

</details>


### [370] [HyPerNav: Hybrid Perception for Object-Oriented Navigation in Unknown Environment](https://arxiv.org/abs/2510.22917)
*Zecheng Yin,Hao Zhao,Zhen Li*

Main category: cs.RO

TL;DR: 本论文提出了一种结合局部与全局感知的新导航方法HyPerNav，通过融合第一视角RGB-D感知和实时俯视图信息，显著提升了未知环境中机器人目标导向导航的效率和智能水平。


<details>
  <summary>Details</summary>
Motivation: 现有目标导向导航研究大多只利用机器人单一路径上的感知信息（如第一视角图像或俯视地图），未能有效结合二者的互补优势，而人类自然导航时会整合局部与全局信息。因此，作者希望借助这种混合感知提升机器人在未知环境导航的性能。

Method: 提出了HyPerNav方法：利用视觉-语言模型（VLM）强大的推理与联合理解能力，整合来自机器人第一视角的RGB-D观测和实时构建的俯视图地图，增强机器人对环境的全方位感知与推理。通过仿真和真实环境中的广泛实验对方法进行验证。

Result: 与现有主流方法对比，HyPerNav在多个仿真测试和真实机器人实验中均达到了最新最优的导航效果。混合感知使机器人能更好理解环境，提升目标发现和路径规划的效率。消融实验也证明了局部和全局感知各自对性能有促进作用。

Conclusion: 融合第一视角和全局地图的混合感知方法显著提升了机器人未知环境下目标导航的表现。VLM增强的理解能力为机器人自主导航带来了更丰富与高效的感知机制，有望为智能体导航提供新的范式。

Abstract: Objective-oriented navigation(ObjNav) enables robot to navigate to target
object directly and autonomously in an unknown environment. Effective
perception in navigation in unknown environment is critical for autonomous
robots. While egocentric observations from RGB-D sensors provide abundant local
information, real-time top-down maps offer valuable global context for ObjNav.
Nevertheless, the majority of existing studies focus on a single source, seldom
integrating these two complementary perceptual modalities, despite the fact
that humans naturally attend to both. With the rapid advancement of
Vision-Language Models(VLMs), we propose Hybrid Perception Navigation
(HyPerNav), leveraging VLMs' strong reasoning and vision-language understanding
capabilities to jointly perceive both local and global information to enhance
the effectiveness and intelligence of navigation in unknown environments. In
both massive simulation evaluation and real-world validation, our methods
achieved state-of-the-art performance against popular baselines. Benefiting
from hybrid perception approach, our method captures richer cues and finds the
objects more effectively, by simultaneously leveraging information
understanding from egocentric observations and the top-down map. Our ablation
study further proved that either of the hybrid perception contributes to the
navigation performance.

</details>


### [371] [End-to-End Design and Validation of a Low-Cost Stewart Platform with Nonlinear Estimation and Control](https://arxiv.org/abs/2510.22949)
*Benedictus C. G. Cinun,Tua A. Tamba,Immanuel R. Santjoko,Xiaofeng Wang,Michael A. Gunarso,Bin Hu*

Main category: cs.RO

TL;DR: 本文介绍了一款低成本的Stewart平台原型，结合现成元件与3D打印件，实现六自由度运动，集成了建模、数据采集和实时控制等功能，并通过实验验证了其在研究和教学中的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于高性能Stewart平台价格昂贵，限制了其在高校及小型研究机构中的广泛应用，本文旨在解决现有平台成本高、集成有限的问题，提供一个廉价且全面的研究与教学型测试床。

Method: 平台采用市售元件和自制部件构建，具备六自由度。软件部分集成了动力学建模、数据采集和实时控制。控制器采用基于反馈线性化和LQR的方法补偿非线性动力学，实现精确轨迹控制。同时，利用扩展卡尔曼滤波器融合IMU与编码器数据，加强了有噪声和干扰情况下的状态估计。

Result: 平台经过仿真和实际实验，能够在静态及动态轨迹下进行有效的轨迹跟踪和实时状态估计，实验结果验证了硬件和软件系统的完整性和高性能。

Conclusion: 该低成本Stewart平台具备完整的硬件-软件集成、高性能控制以及准实时估计能力，性价比高，适合作为先进机器人研究和工程教育的通用工具。

Abstract: This paper presents the complete design, control, and experimental validation
of a low-cost Stewart platform prototype developed as an affordable yet capable
robotic testbed for research and education. The platform combines off the shelf
components with 3D printed and custom fabricated parts to deliver full six
degrees of freedom motions using six linear actuators connecting a moving
platform to a fixed base. The system software integrates dynamic modeling, data
acquisition, and real time control within a unified framework. A robust
trajectory tracking controller based on feedback linearization, augmented with
an LQR scheme, compensates for the platform's nonlinear dynamics to achieve
precise motion control. In parallel, an Extended Kalman Filter fuses IMU and
actuator encoder feedback to provide accurate and reliable state estimation
under sensor noise and external disturbances. Unlike prior efforts that
emphasize only isolated aspects such as modeling or control, this work delivers
a complete hardware-software platform validated through both simulation and
experiments on static and dynamic trajectories. Results demonstrate effective
trajectory tracking and real-time state estimation, highlighting the platform's
potential as a cost effective and versatile tool for advanced research and
educational applications.

</details>


### [372] [An Intelligent Water-Saving Irrigation System Based on Multi-Sensor Fusion and Visual Servoing Control](https://arxiv.org/abs/2510.23003)
*ZhengKai Huang,YiKun Wang,ChenYu Hui,XiaoCheng*

Main category: cs.RO

TL;DR: 本文提出了一种智能节水灌溉系统，通过多传感器融合、计算机视觉和机器人控制，实现精准农业的高效、适应复杂地形的灌溉，并显著提升用水效率。


<details>
  <summary>Details</summary>
Motivation: 传统农业灌溉存在水资源浪费和难以适应地势变化的问题，亟需更智能、高效的解决方案。

Method: 系统集成了轻量级YOLO视觉模型，部署在嵌入式K210处理器上进行实时目标检测，并结合简化的手眼标定算法、主动平台调平系统（基于STM32和JY901S惯性模块），实现精准定位和平台稳定。通过多传感器数据融合提高鲁棒性。

Result: 在三种模拟农业环境中，系统检测准确率超96%、目标定位成功率超90%、平台可在10度坡面1.8秒内稳定。与传统漫灌相比，节水30-50%，灌溉用水效率均超92%。

Conclusion: 该系统有效提升了精准农业灌溉的水利用率和地形适应性，具备良好的实时性和推广价值。

Abstract: This paper introduces an intelligent water-saving irrigation system designed
to address critical challenges in precision agriculture, such as inefficient
water use and poor terrain adaptability. The system integrates advanced
computer vision, robotic control, and real-time stabilization technologies via
a multi-sensor fusion approach. A lightweight YOLO model, deployed on an
embedded vision processor (K210), enables real-time plant container detection
with over 96% accuracy under varying lighting conditions. A simplified hand-eye
calibration algorithm-designed for 'handheld camera' robot arm
configurations-ensures that the end effector can be precisely positioned, with
a success rate exceeding 90%. The active leveling system, driven by the
STM32F103ZET6 main control chip and JY901S inertial measurement data, can
stabilize the irrigation platform on slopes up to 10 degrees, with a response
time of 1.8 seconds. Experimental results across three simulated agricultural
environments (standard greenhouse, hilly terrain, complex lighting) demonstrate
a 30-50% reduction in water consumption compared to conventional flood
irrigation, with water use efficiency exceeding 92% in all test cases.

</details>


### [373] [ManiDP: Manipulability-Aware Diffusion Policy for Posture-Dependent Bimanual Manipulation](https://arxiv.org/abs/2510.23016)
*Zhuo Li,Junjia Liu,Dianxi Li,Tao Teng,Miao Li,Sylvain Calinon,Darwin Caldwell,Fei Chen*

Main category: cs.RO

TL;DR: 该论文提出了一种新方法，能让机器人双臂学习时充分考虑与姿态相关的任务特征，从而实现更灵活和任务适配性更强的双臂操作。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型方法在机器人双臂操作学习中，忽略了姿态依赖的任务特征，这使得难以根据不同任务对力和速度的需求优化双臂的配置，影响操作的灵活性和适应性。

Method: 作者提出了Manipulability-Aware Diffusion Policy（ManiDP），该方法首先从专家示范中提取凝练双臂姿态的可操作性特征，通过Riemannian概率模型进行编码；然后将这些编码后的姿态特征引入条件扩散过程，引导生成符合任务要求的双臂动作轨迹。

Result: 在六个真实双臂操作任务上的实验结果显示，ManiDP相较于基线方法平均操作成功率提升了39.33%，任务适配性提升了0.45。

Conclusion: 将与姿态相关的机器人先验融入双臂扩散模型，有助于实现类似人类的适应性和灵巧性，在复杂操作中具有重要意义。

Abstract: Recent work has demonstrated the potential of diffusion models in robot
bimanual skill learning. However, existing methods ignore the learning of
posture-dependent task features, which are crucial for adapting dual-arm
configurations to meet specific force and velocity requirements in dexterous
bimanual manipulation. To address this limitation, we propose
Manipulability-Aware Diffusion Policy (ManiDP), a novel imitation learning
method that not only generates plausible bimanual trajectories, but also
optimizes dual-arm configurations to better satisfy posture-dependent task
requirements. ManiDP achieves this by extracting bimanual manipulability from
expert demonstrations and encoding the encapsulated posture features using
Riemannian-based probabilistic models. These encoded posture features are then
incorporated into a conditional diffusion process to guide the generation of
task-compatible bimanual motion sequences. We evaluate ManiDP on six real-world
bimanual tasks, where the experimental results demonstrate a 39.33$\%$ increase
in average manipulation success rate and a 0.45 improvement in task
compatibility compared to baseline methods. This work highlights the importance
of integrating posture-relevant robotic priors into bimanual skill diffusion to
enable human-like adaptability and dexterity.

</details>


### [374] [Seq-DeepIPC: Sequential Sensing for End-to-End Control in Legged Robot Navigation](https://arxiv.org/abs/2510.23057)
*Oskar Natan,Jun Miura*

Main category: cs.RO

TL;DR: Seq-DeepIPC是一种为腿式机器人导航设计的端到端感知到控制系统，通过多模态感知与时序融合，大大提升了机器人自主导航能力。


<details>
  <summary>Details</summary>
Motivation: 当前腿式机器人在真实环境下自主导航面临感知和控制难题，传统方法感知维度有限、时序信息利用不足，且部署到边缘设备时计算资源受限。因此亟需一种高效、集成多模态感知和时序信息的模型。

Method: Seq-DeepIPC模型采用RGB-D与GNSS为输入，利用EfficientNet-B0编解码器进行高效特征提取，实现语义分割和深度估计的联合预测，并通过时序特征融合增强空间表征。此外，系统取消噪声较大的IMU，直接用GNSS序列计算朝向。作者采集了涵盖公路与草地的新数据集，并在机器狗机器人上进行了实验与消融分析。

Result: 实验结果表明，Seq-DeepIPC利用时序输入显著提升了感知和控制性能，在模型规模合理的前提下取得了与现有方法相当甚至更优的表现。与其他基线相比，只有Seq-DeepIPC从时序特征中明显获益。GNSS朝向在开阔地带表现稳定，但在高楼附近准确性略低。

Conclusion: Seq-DeepIPC将端到端导航能力从轮式机器人拓展到更灵活、具时序感知能力的腿式机器人，提升了复杂地形下的自主导航水平。作者还计划开源代码，促进相关研究。

Abstract: We present Seq-DeepIPC, a sequential end-to-end perception-to-control model
for legged robot navigation in realworld environments. Seq-DeepIPC advances
intelligent sensing for autonomous legged navigation by tightly integrating
multi-modal perception (RGB-D + GNSS) with temporal fusion and control. The
model jointly predicts semantic segmentation and depth estimation, giving
richer spatial features for planning and control. For efficient deployment on
edge devices, we use EfficientNet-B0 as the encoder, reducing computation while
maintaining accuracy. Heading estimation is simplified by removing the noisy
IMU and instead computing the bearing angle directly from consecutive GNSS
positions. We collected a larger and more diverse dataset that includes both
road and grass terrains, and validated Seq-DeepIPC on a robot dog. Comparative
and ablation studies show that sequential inputs improve perception and control
in our models, while other baselines do not benefit. Seq-DeepIPC achieves
competitive or better results with reasonable model size; although GNSS-only
heading is less reliable near tall buildings, it is robust in open areas.
Overall, Seq-DeepIPC extends end-to-end navigation beyond wheeled robots to
more versatile and temporally-aware systems. To support future research, we
will release the codes to our GitHub repository at
https://github.com/oskarnatan/Seq-DeepIPC.

</details>


### [375] [Awakening Facial Emotional Expressions in Human-Robot](https://arxiv.org/abs/2510.23059)
*Yongtong Zhu,Lei Li,Iggy Qian,WenBin Zhou,Ye Yuan,Qingdu Li,Na Liu,Jianwei Zhang*

Main category: cs.RO

TL;DR: 为提升仿人社交机器人表情生成能力，本文提出一种结合物理电子面部单元、KAN网络和注意力机制的端到端学习框架，并首次公开相关表情数据集。结果显示，该方法在不同对象上实现了准确且多样的表情模仿。


<details>
  <summary>Details</summary>
Motivation: 现有仿人社交机器人表情生成多依赖手工编程，代价高且灵活性不足。为了让机器人能自主学习和泛化表情，需要开发能够模仿人类表情、自训练的系统。

Method: 设计高度仿生的机器人面部结构，包括物理-电子表情单元；提出基于KAN网络和注意力机制的学习框架；采用自动化系统基于面部运动原语专家策略采集大规模数据，并建立首个开源仿人表情数据集。

Result: 提出的方法能在多个测试对象间实现准确及多样的面部表情生成，显著优于传统手工模式，对表示能力有提升。

Conclusion: 本文方法提升了机器人自主学习和泛化表情的能力，为自然的人机交互奠定基础，并通过开源数据集推动领域发展。

Abstract: The facial expression generation capability of humanoid social robots is
critical for achieving natural and human-like interactions, playing a vital
role in enhancing the fluidity of human-robot interactions and the accuracy of
emotional expression. Currently, facial expression generation in humanoid
social robots still relies on pre-programmed behavioral patterns, which are
manually coded at high human and time costs. To enable humanoid robots to
autonomously acquire generalized expressive capabilities, they need to develop
the ability to learn human-like expressions through self-training. To address
this challenge, we have designed a highly biomimetic robotic face with
physical-electronic animated facial units and developed an end-to-end learning
framework based on KAN (Kolmogorov-Arnold Network) and attention mechanisms.
Unlike previous humanoid social robots, we have also meticulously designed an
automated data collection system based on expert strategies of facial motion
primitives to construct the dataset. Notably, to the best of our knowledge,
this is the first open-source facial dataset for humanoid social robots.
Comprehensive evaluations indicate that our approach achieves accurate and
diverse facial mimicry across different test subjects.

</details>


### [376] [Breaking the Circle: An Autonomous Control-Switching Strategy for Stable Orographic Soaring in MAVs](https://arxiv.org/abs/2510.23084)
*Sunyou Hwang,Christophe De Wagter,Bart Remes,Guido de Croon*

Main category: cs.RO

TL;DR: 本文提出了一种新的控制切换方法SAOS，用于自主地形上升滑翔，减少了微型飞行器的能耗并提升了飞行稳定性。


<details>
  <summary>Details</summary>
Motivation: 微型飞行器（MAVs）通过地形滑翔可以延长续航时间，但因纵向与垂直轴的控制冲突会产生绕圈行为，导致能耗上升和飞行风险增加。

Method: 提出了一种名为SAOS的控制切换方法，通过选择性地控制横向或纵向轴，将系统从欠驱动转变为全驱动，并将攻角引入INDI控制器以提升受力估计精度。

Result: 仿真和风洞实验（含随机初始位置及两种MAV）显示SAOS改善了位置收敛、降低了油门使用并减弱了俯仰-滚转耦合导致的滚转振荡。

Conclusion: 所提方法提升了受限滑翔环境下MAV的能效与飞行稳定性。

Abstract: Orographic soaring can significantly extend the endurance of micro aerial
vehicles (MAVs), but circling behavior, arising from control conflicts between
the longitudinal and vertical axes, increases energy consumption and the risk
of divergence. We propose a control switching method, named SAOS: Switched
Control for Autonomous Orographic Soaring, which mitigates circling behavior by
selectively controlling either the horizontal or vertical axis, effectively
transforming the system from underactuated to fully actuated during soaring.
Additionally, the angle of attack is incorporated into the INDI controller to
improve force estimation. Simulations with randomized initial positions and
wind tunnel experiments on two MAVs demonstrate that the SAOS improves position
convergence, reduces throttle usage, and mitigates roll oscillations caused by
pitch-roll coupling. These improvements enhance energy efficiency and flight
stability in constrained soaring environments.

</details>


### [377] [An Automated Tape Laying System Employing a Uniaxial Force Control Device](https://arxiv.org/abs/2510.23109)
*Bernhard Rameder,Hubert Gattringer,Ronald Naderer,Andreas Mueller*

Main category: cs.RO

TL;DR: 本文提出了一种具有成本效益的自动铺带系统，集成了单轴力控和精确温控，确保材料融化与层间黏结，实现了复杂形状的自动铺带并通过实验验证了系统性能。


<details>
  <summary>Details</summary>
Motivation: 自动铺带技术在复合材料制造中的工艺控制越来越关键，尤其是在确保高品质层间黏结和适应复杂形状方面。现有ATL系统成本较高，且多为设备运动、工艺过程控制不够精细，有改进空间。

Method: 设计了包括带料储存、导向、处理、加热及压实等模块的ATL系统，并集成了单轴力控和温控技术，还提出了新型机器人控制策略——固定辅带设备，通过机器人移动模具处理复杂工件。系统用碳纤维增强HDPE带材进行了实验验证。

Result: 所设计系统各子模块和整体铺带过程均通过实验验证，其温控、力控和新型工艺移动模式均达到了预期效果，能够有效铺设并压实增强塑料带材。

Conclusion: 本系统能以较低成本实现自动化、精细化和高适应性的铺带操作，被验证可处理复杂构型，为复合材料自动化制造提供了新技术方案。

Abstract: This paper deals with the design of a cost effective automated tape laying
system (ATL system) with integrated uniaxial force control to ensure the
necessary compaction forces as well as with an accurate temperature control to
guarantee the used tape being melted appropriate. It is crucial to control the
substrate and the oncoming tape onto a specific temperature level to ensure an
optimal consolidation between the different layers of the product. Therefore,
it takes several process steps from the spooled tape on the coil until it is
finally tacked onto the desired mold. The different modules are divided into
the tape storage spool, a tape-guiding roller, a tape processing unit, a
heating zone and the consolidation unit. Moreover, a special robot control
concept for testing the ATL system is presented. In contrast to many other
systems, with this approach, the tape laying device is spatially fixed and the
shape is moved accordingly by the robot, which allows for handling of rather
compact and complex shapes. The functionality of the subsystems and the taping
process itself was finally approved in experimental results using a carbon
fiber reinforced HDPE tape.

</details>


### [378] [OmniDexGrasp: Generalizable Dexterous Grasping via Foundation Model and Force Feedback](https://arxiv.org/abs/2510.23119)
*Yi-Lin Wei,Zhexi Luo,Yuhao Lin,Mu Lin,Zhizhao Liang,Shuoyu Chen,Wei-Shi Zheng*

Main category: cs.RO

TL;DR: OmniDexGrasp提出一种结合基础模型与控制策略的通用框架，提升机器人在多样任务下依照人类指令灵巧抓取与操作物体的能力。


<details>
  <summary>Details</summary>
Motivation: 现有机器人抓取方法在面对多样化的对象和任务时泛化能力不足，主要因为相关数据集规模有限；同时直接利用基础模型生成可执行的机器人动作存在知识与执行间的落差。

Method: OmniDexGrasp框架融合三大模块：（1）利用基础模型生成能支持多种用户提示及任务的抓取示意图，增强泛化性；（2）将人类抓取演示通过图像转换为可执行的机器人动作，实现人手到机器手的灵巧动作迁移；（3）采用力感知自适应抓取策略，保证抓取的稳定与鲁棒性。

Result: 在仿真和真实机器人实验中，OmniDexGrasp在多样的用户指令、抓取任务及灵巧机械手上有效验证了其性能，并表现出其对灵巧操作任务的可扩展性。

Conclusion: OmniDexGrasp能显著提升机器人在多样化任务和物体上的泛化与灵巧抓取操作能力，为机器人灵巧操作领域带来了新的解决方案。

Abstract: Enabling robots to dexterously grasp and manipulate objects based on human
commands is a promising direction in robotics. However, existing approaches are
challenging to generalize across diverse objects or tasks due to the limited
scale of semantic dexterous grasp datasets. Foundation models offer a new way
to enhance generalization, yet directly leveraging them to generate feasible
robotic actions remains challenging due to the gap between abstract model
knowledge and physical robot execution. To address these challenges, we propose
OmniDexGrasp, a generalizable framework that achieves omni-capabilities in user
prompting, dexterous embodiment, and grasping tasks by combining foundation
models with the transfer and control strategies. OmniDexGrasp integrates three
key modules: (i) foundation models are used to enhance generalization by
generating human grasp images supporting omni-capability of user prompt and
task; (ii) a human-image-to-robot-action transfer strategy converts human
demonstrations into executable robot actions, enabling omni dexterous
embodiment; (iii) force-aware adaptive grasp strategy ensures robust and stable
grasp execution. Experiments in simulation and on real robots validate the
effectiveness of OmniDexGrasp on diverse user prompts, grasp task and dexterous
hands, and further results show its extensibility to dexterous manipulation
tasks.

</details>


### [379] [Reliable Robotic Task Execution in the Face of Anomalies](https://arxiv.org/abs/2510.23121)
*Bharath Santhanam,Alex Mitrevski,Santosh Thoduka,Sebastian Houben,Teena Hassan*

Main category: cs.RO

TL;DR: 本论文提出了一种结合视觉异常检测和恢复机制的机器人决策执行框架，通过异常检测提升机器人在开放环境中的执行成功率和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有学习型机器人策略虽然灵活，但对环境复杂性的适应性差，缺乏异常检测和处理，容易导致失败甚至产生安全问题。

Method: 利用训练好的策略执行过程中标准（正常）数据，训练视觉异常检测模型，并将其集成到实际策略执行过程中。一旦检测到异常，依次触发三步恢复过程：暂时暂停、状态微调扰动、通过学习的成功模型重置到安全状态。方法在两种机器人任务中进行了验证。

Result: 在门把手操作任务和物体放置任务中，集成异常检测和恢复机制后，机器人在面对轨迹偏离、恶意干扰等异常时，执行成功率显著提升。

Conclusion: 提出的框架可增强学习型机器人在开放环境中的可靠性与安全性，为实际部署提供有效支持。

Abstract: Learned robot policies have consistently been shown to be versatile, but they
typically have no built-in mechanism for handling the complexity of open
environments, making them prone to execution failures; this implies that
deploying policies without the ability to recognise and react to failures may
lead to unreliable and unsafe robot behaviour. In this paper, we present a
framework that couples a learned policy with a method to detect visual
anomalies during policy deployment and to perform recovery behaviours when
necessary, thereby aiming to prevent failures. Specifically, we train an
anomaly detection model using data collected during nominal executions of a
trained policy. This model is then integrated into the online policy execution
process, so that deviations from the nominal execution can trigger a
three-level sequential recovery process that consists of (i) pausing the
execution temporarily, (ii) performing a local perturbation of the robot's
state, and (iii) resetting the robot to a safe state by sampling from a learned
execution success model. We verify our proposed method in two different
scenarios: (i) a door handle reaching task with a Kinova Gen3 arm using a
policy trained in simulation and transferred to the real robot, and (ii) an
object placing task with a UFactory xArm 6 using a general-purpose policy
model. Our results show that integrating policy execution with anomaly
detection and recovery increases the execution success rate in environments
with various anomalies, such as trajectory deviations and adversarial human
interventions.

</details>


### [380] [Combining High Level Scheduling and Low Level Control to Manage Fleets of Mobile Robots](https://arxiv.org/abs/2510.23129)
*Sabino Francesco Roselli,Ze Zhang,Knut Åkesson*

Main category: cs.RO

TL;DR: 本文提出了一种两层式框架，实现大规模移动机器人队列在动态工业环境中的高效、可扩展协调。结合高层调度与底层控制，确保高任务完成率与鲁棒操作。


<details>
  <summary>Details</summary>
Motivation: 工业环境中物料搬运对大规模移动机器人队列高效、动态协调提出了挑战，现有方法难以兼顾任务调度、碰撞避免和灵活应变能力。

Method: 框架分为两层：高层用ComSat算法为每台机器人生成带时间参数的任务路线；低层则采用分布式模型预测控制（MPC），实时规划局部轨迹，应对静态和动态障碍，支持运行中快速重调度。

Result: 在不同道路容量和交通条件下的二维仿真中，该方法展现出高任务完成率和强鲁棒性，即使遇到拥堵、机器人故障等也能稳定运行。

Conclusion: 该模块化、灵活的框架计算高效，适合部署到复杂现实工业场景，保障多移动机器人协作的安全、高效和鲁棒性。

Abstract: The deployment of mobile robots for material handling in industrial
environments requires scalable coordination of large fleets in dynamic
settings. This paper presents a two-layer framework that combines high-level
scheduling with low-level control. Tasks are assigned and scheduled using the
compositional algorithm ComSat, which generates time-parameterized routes for
each robot. These schedules are then used by a distributed Model Predictive
Control (MPC) system in real time to compute local reference trajectories,
accounting for static and dynamic obstacles. The approach ensures safe,
collision-free operation, and supports rapid rescheduling in response to
disruptions such as robot failures or environmental changes. We evaluate the
method in simulated 2D environments with varying road capacities and traffic
conditions, demonstrating high task completion rates and robust behavior even
under congestion. The modular structure of the framework allows for
computational tractability and flexibility, making it suitable for deployment
in complex, real-world industrial scenarios.

</details>


### [381] [TARC: Time-Adaptive Robotic Control](https://arxiv.org/abs/2510.23176)
*Arnav Sukhija,Lenart Treven,Jin Cheng,Florian Dörfler,Stelian Coros,Andreas Krause*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习的方法，使机器人能自主调节控制频率，从而兼顾控制的效率与鲁棒性，并在不同硬件平台上通过真实世界实验验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 常规机器人控制采用固定频率，低频高效但鲁棒性差，高频则相反，这种折中不符合生物系统的自适应特性，因此需要一种能在不同情境下灵活调整控制频率的方案。

Method: 采用强化学习方法，训练策略网络不仅输出控制动作，同时选择这些动作的执行时长，使机器人能根据具体情况自主调节控制频率。

Result: 在高性能RC车和四足机器人平台上开展了零样本仿真到现实实验，结果显示该方法在保持甚至超越固定频率基线奖励的同时，显著降低了实际控制频率，并能根据环境需求自适应频率。

Conclusion: 提出的方法不仅提升了机器人控制的灵活性和资源利用效率，还具备良好的仿真到现实迁移能力，表明自适应控制频率对实际机器人应用具有较大潜力。

Abstract: Fixed-frequency control in robotics imposes a trade-off between the
efficiency of low-frequency control and the robustness of high-frequency
control, a limitation not seen in adaptable biological systems. We address this
with a reinforcement learning approach in which policies jointly select control
actions and their application durations, enabling robots to autonomously
modulate their control frequency in response to situational demands. We
validate our method with zero-shot sim-to-real experiments on two distinct
hardware platforms: a high-speed RC car and a quadrupedal robot. Our method
matches or outperforms fixed-frequency baselines in terms of rewards while
significantly reducing the control frequency and exhibiting adaptive frequency
control under real-world conditions.

</details>


### [382] [If They Disagree, Will You Conform? Exploring the Role of Robots' Value Awareness in a Decision-Making Task](https://arxiv.org/abs/2510.23204)
*Giulia Pusceddu,Giulio Antonio Abbo,Francesco Rea,Tony Belpaeme,Alessandra Sciutti*

Main category: cs.RO

TL;DR: 本研究探讨了机器人是否因展现对人类价值观的理解而更能影响人类的决策，发现价值感知型机器人更受关注并被认为更忠诚，但没有明显影响最终选择。


<details>
  <summary>Details</summary>
Motivation: 随着社会机器人越来越多地参与到人类社会活动，了解其影响人类决策的机制变得重要，尤其是机器人是否展现“价值感知”会影响人类信任与跟随。

Method: 实验设计让参与者与两个人形机器人互动：一台被设定为“价值感知型”，能表达对人类原则的理解；另一台则为“非价值感知型”。参与者执行图片标注任务，观察他们的决定与反应。

Result: 参与者能区分两种机器人，对价值感知型机器人注视更多，且认为其更忠诚；但在实际决策中两者影响无明显差异。出现机器人与人意见不一致时，约25%的情况下人类会顺从，且决策更犹豫。

Conclusion: 价值感知可提升社交机器人在群体中的承诺感，但不必然改变人类实际选择。双重反对意见会导致人类更犹豫，意味着机器人既有助于反思、亦存在被滥用的风险。

Abstract: This study investigates whether the opinions of robotic agents are more
likely to influence human decision-making when the robots are perceived as
value-aware (i.e., when they display an understanding of human principles). We
designed an experiment in which participants interacted with two Furhat robots
- one programmed to be Value-Aware and the other Non-Value-Aware - during a
labeling task for images representing human values. Results indicate that
participants distinguished the Value-Aware robot from the Non-Value-Aware one.
Although their explicit choices did not indicate a clear preference for one
robot over the other, participants directed their gaze more toward the
Value-Aware robot. Additionally, the Value-Aware robot was perceived as more
loyal, suggesting that value awareness in a social robot may enhance its
perceived commitment to the group. Finally, when both robots disagreed with the
participant, conformity occurred in about one out of four trials, and
participants took longer to confirm their responses, suggesting that two robots
expressing dissent may introduce hesitation in decision-making. On one hand,
this highlights the potential risk that robots, if misused, could manipulate
users for unethical purposes. On the other hand, it reinforces the idea that
social robots might encourage reflection in ambiguous situations and help users
avoid scams.

</details>


### [383] [Workspace Registration and Collision Detection for Industrial Robotics Applications](https://arxiv.org/abs/2510.23227)
*Klaus Zauner,Josef El Dib,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 本论文提出了一套基于点云的机械臂运动规划环境建模与碰撞检测流程，并比较了不同环境感知传感器的性能。


<details>
  <summary>Details</summary>
Motivation: 机械臂运动规划需要精确的环境信息，以正确识别碰撞物体和定义限制区域。目前点云结合传感器广泛用于环境建模，但不同传感器与点云处理方法对最终效果有显著影响。

Method: 采用多种传感器采集环境点云，通过区域增长分割和VCCS算法识别碰撞物体，将得到的点云簇进行近似，形成碰撞环境模型，并检测机械臂与环境的碰撞。

Result: 比较了多种传感器在采集点云、进行点云分割和碰撞检测流程中的表现，从检测到建模再到碰撞检测整个流程进行了具体展示。

Conclusion: 该研究展示并比较了基于不同传感器的机械臂安全作业环境建模与碰撞检测方法，为实际应用中传感器选择与点云处理流程提供了参考。

Abstract: Motion planning for robotic manipulators relies on precise knowledge of the
environment in order to be able to define restricted areas and to take
collision objects into account. To capture the workspace, point clouds of the
environment are acquired using various sensors. The collision objects are
identified by region growing segmentation and VCCS algorithm. Subsequently the
point clusters are approximated. The aim of the present paper is to compare
different sensors, to illustrate the process from detection to the finished
collision environment and to detect collisions between the robot and this
environment.

</details>


### [384] [Optimal Dimensioning of Elastic-Link Manipulators regarding Lifetime Estimation](https://arxiv.org/abs/2510.23234)
*Klaus Zauner,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 提出了一种结合疲劳寿命估算和几何优化方法，以减重并抑制振动，实现柔性机械臂在可持续工业自动化中的最优设计。


<details>
  <summary>Details</summary>
Motivation: 为了实现可持续的工业自动化，需要设计轻量化并具备时间和能耗最优控制的机械臂。由于柔性机械臂在任务运行中存在机械顺应性，必须将设计与控制深度结合，优化机械臂寿命和性能。

Method: 首先提出了一种用于估算柔性串联机械臂寿命的方法，通过雨流计数法和临界切割面法进行疲劳分析，利用Tresca准则计算等效应力，并采用线性损伤累积假设。接着将该寿命估算法应用于拾取-放置任务的机械臂几何参数优化，优化目标结合了机械臂整体重量和振动幅值。最终的设计通过Pareto前沿在寿命和振动特性间取折衷。

Result: 以一个三自由度关节型机械臂为例，展示了优化方法可有效筛选机械臂参数，实现重量和振动的权衡，并延长使用寿命。

Conclusion: 所提方法能为柔性机械臂实现重量减轻和振动抑制的几何优化提供依据，有助于提升工业自动化系统的可持续性和可靠性。

Abstract: Resourceful operation and design of robots is key for sustainable industrial
automation. This will be enabled by lightweight design along with time and
energy optimal control of robotic manipulators. Design and control of such
systems is intertwined as the control must take into account inherent
mechanical compliance while the design must accommodate the dynamic
requirements demanded by the control. As basis for such design optimization, a
method for estimating the lifetime of elastic link robotic manipulators is
presented. This is applied to the geometry optimization of flexible serial
manipulators performing pick-and-place operations, where the optimization
objective is a combination of overall weight and vibration amplitudes. The
lifetime estimation draws from a fatigue analysis combining the rainflow
counting algorithm and the method of critical cutting plane. Tresca hypothesis
is used to formulate an equivalent stress, and linear damage accumulation is
assumed. The final robot geometry is selected from a Pareto front as a tradeoff
of lifetime and vibration characteristic. The method is illustrated for a three
degrees of freedom articulated robotic manipulator.

</details>


### [385] [Deep Active Inference with Diffusion Policy and Multiple Timescale World Model for Real-World Exploration and Navigation](https://arxiv.org/abs/2510.23258)
*Riko Yokozawa,Kentaro Fujii,Yuta Nomura,Shingo Murata*

Main category: cs.RO

TL;DR: 本文提出了一种基于主动推断（AIF）的深度学习框架，用于实现真实环境下自主机器人的统一探索与目标导向导航。该方法通过整合扩散策略和多时间尺度递归状态空间模型，实现了高效的决策和环境探索。实验结果表明，该框架在真实场景下导航成功率更高，碰撞次数更少。


<details>
  <summary>Details</summary>
Motivation: 在现实世界中，自动化机器人需要能有效地探索环境并达到指定目标，现有方法往往难以统一探索与目标达成，且缺乏理论指导。AIF基于自由能原理（free-energy principle）有望提供一个结合探索和利用的统一框架，但实际实现仍面临挑战。

Method: 作者提出了一个深度主动推断（deep AIF）框架，将扩散策略（diffusion policy）作为策略模型，用于生成多样化候选动作，利用多时间尺度递归状态空间模型（MTRSSM）作为世界模型，通过潜在空间的推理预测动作的长期后果，从而选择能最小化期望自由能（EFE）的动作，实现探索与目标导向统一。

Result: 在真实环境下的机器人导航实验中，该方法相比对比基线表现出更高的任务成功率和更少的碰撞，尤其在需要大量探索的情景下优势更明显。

Conclusion: 这一工作证明了基于期望自由能最小化的主动推断方法能够在现实世界中统一解决机器人探索与目标驱动导航问题，具备更优的安全性和有效性。

Abstract: Autonomous robotic navigation in real-world environments requires exploration
to acquire environmental information as well as goal-directed navigation in
order to reach specified targets. Active inference (AIF) based on the
free-energy principle provides a unified framework for these behaviors by
minimizing the expected free energy (EFE), thereby combining epistemic and
extrinsic values. To realize this practically, we propose a deep AIF framework
that integrates a diffusion policy as the policy model and a multiple timescale
recurrent state-space model (MTRSSM) as the world model. The diffusion policy
generates diverse candidate actions while the MTRSSM predicts their
long-horizon consequences through latent imagination, enabling action selection
that minimizes EFE. Real-world navigation experiments demonstrated that our
framework achieved higher success rates and fewer collisions compared with the
baselines, particularly in exploration-demanding scenarios. These results
highlight how AIF based on EFE minimization can unify exploration and
goal-directed navigation in real-world robotic settings.

</details>


### [386] [Precise Time Delay Measurement and Compensation for Tightly Coupled Underwater SINS/piUSBL Navigation](https://arxiv.org/abs/2510.23286)
*Jin Huang,Yingqiang Wang,Haoda Li,Zichen Liu,Zhikun Wang,Ying Chen*

Main category: cs.RO

TL;DR: 该论文提出了一种针对水下多传感器集成导航系统（尤其是涉及声学定位系统）的紧耦合导航框架，通过精确时间同步与延时补偿，有效提升了系统精度。


<details>
  <summary>Details</summary>
Motivation: 水下多传感器集成导航系统存在显著的时间同步和延迟问题，尤其是声学定位带来的延迟，如果处理不当会导致测量和数据融合时刻不一致，严重影响导航精度。因此亟需一种能有效测量与补偿延迟的方法。

Method: 提出了将被动倒置超短基线（piUSBL）声学定位系统、捷联惯性导航系统（SINS）和深度计紧密结合的导航框架，核心技术在于综合测量方位、倾斜距离和深度信息，并采用创新的延迟测量策略，将传统不可观测的声学传播及系统处理延迟转化为可估计参数，实现精确补偿。

Result: 通过仿真与实地实验验证，该方法的延迟补偿显著降低了导航RMSE 40.45%，最大误差降低32.55%。

Conclusion: 精确的延迟测量与补偿不仅提升了水下导航系统的整体精度，还为声学定位集成与时间敏感型多传感器系统的数据融合提供了通用参考。

Abstract: In multi-sensor systems, time synchronization between sensors is a
significant challenge, and this issue is particularly pronounced in underwater
integrated navigation systems incorporating acoustic positioning. Such systems
are highly susceptible to time delay, which can significantly degrade accuracy
when measurement and fusion moments are misaligned. To address this challenge,
this paper introduces a tightly coupled navigation framework that integrates a
passive inverted ultra-short baseline (piUSBL) acoustic positioning system, a
strapdown inertial navigation system (SINS), and a depth gauge under precise
time synchronization. The framework fuses azimuth and slant range from the
piUSBL with depth data, thereby avoiding poor vertical-angle observability in
planar arrays. A novel delay measurement strategy is introduced, combining
synchronized timing with acoustic signal processing, which redefines
delay-traditionally an unobservable error-into a quantifiable parameter,
enabling explicit estimation of both acoustic propagation and system processing
delays. Simulations and field experiments confirm the feasibility of the
proposed method, with delay-compensated navigation reducing RMSE by 40.45% and
maximum error by 32.55%. These findings show that precise delay measurement and
compensation not only enhance underwater navigation accuracy but also establish
a generalizable framework for acoustic positioning integration, offering
valuable insights into time alignment and data fusion in latency-sensitive
multi-sensor systems.

</details>


### [387] [Transferable Deep Reinforcement Learning for Cross-Domain Navigation: from Farmland to the Moon](https://arxiv.org/abs/2510.23329)
*Shreya Santra,Thomas Robbins,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 本论文使用深度强化学习（DRL）方法，让农业机器人的导航策略能在不同地貌（地球与月球）间迁移，无需再次训练也能具备较高导航成功率。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人自主导航算法需要针对特定环境做大量调整，难以在新领域直接应用。因此，研究者希望用DRL实现无需环境特定调整的通用导航策略，尤其用于复杂、未知乃至外星环境。

Method: 开发了一个三维农业机器人仿真环境，采用PPO算法训练机器人在农田中完成目标导向导航及避障。随后将该导航策略直接测试于模拟月球地貌环境，考查政策在跨域环境下的效果，无任何再训练。

Result: 经过训练的导航策略，在月球仿真环境下无需额外调整即可实现约50%的目标导航成功率。显示出较好的跨环境迁移能力。

Conclusion: DRL训练得到的导航策略具有很好的跨领域泛化性能，有望为未来外太空自主探索任务提供具高适应性和高效性的解决方案，同时显著降低再训练成本。

Abstract: Autonomous navigation in unstructured environments is essential for field and
planetary robotics, where robots must efficiently reach goals while avoiding
obstacles under uncertain conditions. Conventional algorithmic approaches often
require extensive environment-specific tuning, limiting scalability to new
domains. Deep Reinforcement Learning (DRL) provides a data-driven alternative,
allowing robots to acquire navigation strategies through direct interactions
with their environment. This work investigates the feasibility of DRL policy
generalization across visually and topographically distinct simulated domains,
where policies are trained in terrestrial settings and validated in a zero-shot
manner in extraterrestrial environments. A 3D simulation of an agricultural
rover is developed and trained using Proximal Policy Optimization (PPO) to
achieve goal-directed navigation and obstacle avoidance in farmland settings.
The learned policy is then evaluated in a lunar-like simulated environment to
assess transfer performance. The results indicate that policies trained under
terrestrial conditions retain a high level of effectiveness, achieving close to
50\% success in lunar simulations without the need for additional training and
fine-tuning. This underscores the potential of cross-domain DRL-based policy
transfer as a promising approach to developing adaptable and efficient
autonomous navigation for future planetary exploration missions, with the added
benefit of minimizing retraining costs.

</details>


### [388] [Large language model-based task planning for service robots: A review](https://arxiv.org/abs/2510.23357)
*Shaohan Bian,Ying Zhang,Guohui Tian,Zhiqiang Miao,Edmond Q. Wu,Simon X. Yang,Changchun Hua*

Main category: cs.RO

TL;DR: 本文综述了大语言模型（LLMs）在服务机器人任务规划中的应用及进展。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型和机器人技术快速发展，服务机器人日益融入日常生活，对其智能、高效的任务规划能力提出更高要求。

Method: 论文梳理了LLMs基础（如预训练、微调、RAG和提示工程），分析了其作为机器人认知核心的应用，并系统回顾了文本、视觉、音频及多模态输入下的LLM驱动任务规划方法。

Result: 总结了LLMs使服务机器人在自主性和决策能力上的提升，分析了不同输入模态下最新的任务规划进展。

Conclusion: 指出当前研究的主要挑战和不足，提出未来研究方向，以进一步推动服务机器人在复杂环境中的任务规划能力。

Abstract: With the rapid advancement of large language models (LLMs) and robotics,
service robots are increasingly becoming an integral part of daily life,
offering a wide range of services in complex environments. To deliver these
services intelligently and efficiently, robust and accurate task planning
capabilities are essential. This paper presents a comprehensive overview of the
integration of LLMs into service robotics, with a particular focus on their
role in enhancing robotic task planning. First, the development and
foundational techniques of LLMs, including pre-training, fine-tuning,
retrieval-augmented generation (RAG), and prompt engineering, are reviewed. We
then explore the application of LLMs as the cognitive core-`brain'-of service
robots, discussing how LLMs contribute to improved autonomy and
decision-making. Furthermore, recent advancements in LLM-driven task planning
across various input modalities are analyzed, including text, visual, audio,
and multimodal inputs. Finally, we summarize key challenges and limitations in
current research and propose future directions to advance the task planning
capabilities of service robots in complex, unstructured domestic environments.
This review aims to serve as a valuable reference for researchers and
practitioners in the fields of artificial intelligence and robotics.

</details>


### [389] [T-ESKF: Transformed Error-State Kalman Filter for Consistent Visual-Inertial Navigation](https://arxiv.org/abs/2510.23359)
*Chungeng Tian,Ning Hao,Fenghua He*

Main category: cs.RO

TL;DR: 本文提出了一种创新的方法，通过线性时变变换在误差状态卡尔曼滤波器（ESKF）内对误差状态进行处理，从而解决视觉-惯性导航系统（VINS）中因可观测性不匹配导致的不一致性问题。


<details>
  <summary>Details</summary>
Motivation: VINS常因观测量不同步、线性化点变化等引起可观测性不匹配，导致滤波器不一致、估计精度下降，需要新的方法确保系统可观测性不变性和估计一致性。

Method: 提出在ESKF中对误差状态施加线性时变变换，使变换后的误差状态系统的不可观测子空间与系统状态无关，从而保证线性化点变化下的正确可观测性；并提出高效的协方差传播技术，提升运算速度。

Result: 通过大量仿真和实际试验，结果显示所提方法在精度和一致性方面优于或至少与现有SOTA方法相当。

Conclusion: T-ESKF方法有效提升了VINS系统的一致性与可观测性控制，计算高效，实验验证具有竞争力，适用于实际应用。

Abstract: This paper presents a novel approach to address the inconsistency problem
caused by observability mismatch in visual-inertial navigation systems (VINS).
The key idea involves applying a linear time-varying transformation to the
error-state within the Error-State Kalman Filter (ESKF). This transformation
ensures that \textrr{the unobservable subspace of the transformed error-state
system} becomes independent of the state, thereby preserving the correct
observability of the transformed system against variations in linearization
points. We introduce the Transformed ESKF (T-ESKF), a consistent VINS estimator
that performs state estimation using the transformed error-state system.
Furthermore, we develop an efficient propagation technique to accelerate the
covariance propagation based on the transformation relationship between the
transition and accumulated matrices of T-ESKF and ESKF. We validate the
proposed method through extensive simulations and experiments, demonstrating
better (or competitive at least) performance compared to state-of-the-art
methods. The code is available at github.com/HITCSC/T-ESKF.

</details>


### [390] [Full-Dynamics Real-Time Nonlinear Model Predictive Control of Heavy-Duty Hydraulic Manipulator for Trajectory Tracking Tasks](https://arxiv.org/abs/2510.23386)
*Alvaro Paz,Mahdi Hejrati,Pauli Mustalahti,Jouni Mattila*

Main category: cs.RO

TL;DR: 本论文提出了一种适用于大型液压机械臂的非线性模型预测控制（NMPC）框架，实现了同时满足关节和末端执行器多种安全约束条件的高精度实时控制。


<details>
  <summary>Details</summary>
Motivation: 液压机械臂由于体积大、动力强、非线性特性复杂，其操作过程中同时受到多种安全和物理约束（如力、速度、位置等），但现有实时控制框架很少能兼顾上述所有约束问题。

Method: 提出了基于非线性模型预测控制（NMPC）的控制框架，结合多点射击方法和实时传感器反馈，并以虚拟分解控制（VDC）为底层精确关节跟踪控制器，在1 kHz控制频率下运行。

Result: 在真实的大型液压机械臂实验中，所提NMPC框架不仅可以在关节层面强制执行驱动约束，同时保证末端执行器在笛卡尔空间的运动也符合约束且精确跟踪目标轨迹。

Conclusion: 本方法实现在严格安全约束下的大型液压系统实时高精度控制，树立了此类系统实时控制的新标杆。

Abstract: Heavy-duty hydraulic manipulators (HHMs) operate under strict physical and
safety-critical constraints due to their large size, high power, and complex
nonlinear dynamics. Ensuring that both joint-level and end-effector
trajectories remain compliant with actuator capabilities, such as force,
velocity, and position limits, is essential for safe and reliable operation,
yet remains largely underexplored in real-time control frameworks. This paper
presents a nonlinear model predictive control (NMPC) framework designed to
guarantee constraint satisfaction throughout the full nonlinear dynamics of
HHMs, while running at a real-time control frequency of 1 kHz. The proposed
method combines a multiple-shooting strategy with real-time sensor feedback,
and is supported by a robust low-level controller based on virtual
decomposition control (VDC) for precise joint tracking. Experimental validation
on a full-scale hydraulic manipulator shows that the NMPC framework not only
enforces actuator constraints at the joint level, but also ensures
constraint-compliant motion in Cartesian space for the end-effector. These
results demonstrate the method's capability to deliver high-accuracy trajectory
tracking while strictly respecting safety-critical limits, setting a new
benchmark for real-time control in large-scale hydraulic systems.

</details>


### [391] [COOPERA: Continual Open-Ended Human-Robot Assistance](https://arxiv.org/abs/2510.23495)
*Chenyang Ma,Kai Lu,Ruta Desai,Xavier Puig,Andrew Markham,Niki Trigoni*

Main category: cs.RO

TL;DR: 本论文提出了COOPERA框架，实现机器人在复杂环境下对人类个体特性与长期意图的持续建模和协作，首次支持跨时域、开放式的人机长期协作研究。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人助手多聚焦于有预定义任务的结构化环境，缺乏对人类个体特质、习惯、长期活动的理解和建模，难以实现真正开放和个性化的人机协作。

Method: 提出COOPERA框架，通过模拟具备心理特质和长期意图的人类，与机器人交互，并融入持续的人类反馈。该框架包括用于开放式长期人机协作的新基准，以及根据个体人类特性和上下文意图，学习并个性化协作策略的方法。

Result: 实验表明，COOPERA模拟的人类行为符合真实人类行为特征，同时证明机器人推断并适应人类意图后，在开放式、长期协作场景中具备更强的协作能力和个性化效果。

Conclusion: COOPERA能够支持长期、开放性的人机协作研究，并通过对人类特性的学习和适应，提升协作效率和体验。

Abstract: To understand and collaborate with humans, robots must account for individual
human traits, habits, and activities over time. However, most robotic
assistants lack these abilities, as they primarily focus on predefined tasks in
structured environments and lack a human model to learn from. This work
introduces COOPERA, a novel framework for COntinual, OPen-Ended human-Robot
Assistance, where simulated humans, driven by psychological traits and
long-term intentions, interact with robots in complex environments. By
integrating continuous human feedback, our framework, for the first time,
enables the study of long-term, open-ended human-robot collaboration (HRC) in
different collaborative tasks across various time-scales. Within COOPERA, we
introduce a benchmark and an approach to personalize the robot's collaborative
actions by learning human traits and context-dependent intents. Experiments
validate the extent to which our simulated humans reflect realistic human
behaviors and demonstrate the value of inferring and personalizing to human
intents for open-ended and long-term HRC. Project Page:
https://dannymcy.github.io/coopera/

</details>


### [392] [Deductive Chain-of-Thought Augmented Socially-aware Robot Navigation World Model](https://arxiv.org/abs/2510.23509)
*Weizheng Wang,Obi Ike,Soyun Choi,Sungeun Hong,Byung-Cheol Min*

Main category: cs.RO

TL;DR: 提出了一种结合大型语言模型（LLM）与结构化世界模型的社交机器人导航系统NaviWM，实现了更安全和合规的人类环境导航能力。


<details>
  <summary>Details</summary>
Motivation: 目前社交机器人越来越依赖LLM进行导航规划，但仅依赖LLM常会造成逻辑不一致、物理不安全的问题，特别在人类动态环境中亟需更完善的安全与社交规范支持。

Method: NaviWM结合了时空世界模型（记录环境中人的位置、速度和活动）和演绎推理模块（引导LLM进行多步逻辑推理）。社会规范采用一阶逻辑编码，实现可解释和可检验的推理。

Result: 实验表明，在拥挤环境下，NaviWM有效提升了导航成功率并减少了社会规范违规事件。

Conclusion: 将形式化推理与LLM结合，可显著提升社交机器人在动态人类空间的导航表现，具备更强的安全性和社会合规性。

Abstract: Social robot navigation increasingly relies on large language models for
reasoning, path planning, and enabling movement in dynamic human spaces.
However, relying solely on LLMs for planning often leads to unpredictable and
unsafe behaviors, especially in dynamic human spaces, due to limited physical
grounding and weak logical consistency. In this work, we introduce NaviWM, a
socially-aware robot Navigation World Model that augments LLM reasoning with a
structured world model and a logic-driven chain-of-thought process. NaviWM
consists of two main components: (1) a spatial-temporal world model that
captures the positions, velocities, and activities of agents in the
environment, and (2) a deductive reasoning module that guides LLMs through a
multi-step, logic-based inference process. This integration enables the robot
to generate navigation decisions that are both socially compliant and
physically safe, under well-defined constraints such as personal space,
collision avoidance, and timing. Unlike previous methods based on prompting or
fine-tuning, NaviWM encodes social norms as first-order logic, enabling
interpretable and verifiable reasoning. Experiments show that NaviWM improves
success rates and reduces social violations, particularly in crowded
environments. These results demonstrate the benefit of combining formal
reasoning with LLMs for robust social navigation. Additional experimental
details and demo videos for this work can be found at:
https://sites.google.com/view/NaviWM.

</details>


### [393] [Dexbotic: Open-Source Vision-Language-Action Toolbox](https://arxiv.org/abs/2510.23511)
*Bin Xie,Erjin Zhou,Fan Jia,Hao Shi,Haoqiang Fan,Haowei Zhang,Hebei Li,Jianjian Sun,Jie Bin,Junwen Huang,Kai Liu,Kaixin Liu,Kefan Gu,Lin Sun,Meng Zhang,Peilong Han,Ruitao Hao,Ruitao Zhang,Saike Huang,Songhan Xie,Tiancai Wang,Tianle Liu,Wenbin Tang,Wenqi Zhu,Yang Chen,Yingfei Liu,Yizhuang Zhou,Yu Liu,Yucheng Zhao,Yunchao Ma,Yunfei Wei,Yuxiang Chen,Ze Chen,Zeming Li,Zhao Wu,Ziheng Zhang,Ziming Liu,Ziwei Yan,Ziyu Zhang*

Main category: cs.RO

TL;DR: 本文提出了Dexbotic，一个基于PyTorch的开源视觉-语言-动作（VLA）模型工具箱，旨在为体现智能领域的研究人员提供一站式的研究服务。


<details>
  <summary>Details</summary>
Motivation: 当前VLA领域缺乏支持多种主流方法、易于复现实验和快速迭代的新工具，限制了研究和应用的发展。因此，论文旨在通过提供统一的工具箱来简化实验流程和方法复现，助力该领域进步。

Method: Dexbotic工具箱基于PyTorch实现，能同时支持多种主流VLA方法，只需一次环境配置即可复现多种实验。工具箱以实验为核心，用户仅需修改实验脚本即可快速开发新的VLA实验。此外，作者还提供了更强的预训练模型，显著提升了多项VLA方法的性能。

Result: Dexbotic能显著提升主流VLA策略的性能，极大方便了实验复现和新方法的开发。用户可直接利用工具箱内更强的预训练模型提升表现。

Conclusion: Dexbotic为VLA领域提供了统一、易用、高性能的工具支持，将持续更新，纳入最新的基础模型和方法，助力体现智能研究与产业发展。

Abstract: In this paper, we present Dexbotic, an open-source Vision-Language-Action
(VLA) model toolbox based on PyTorch. It aims to provide a one-stop VLA
research service for professionals in the field of embodied intelligence. It
offers a codebase that supports multiple mainstream VLA policies
simultaneously, allowing users to reproduce various VLA methods with just a
single environment setup. The toolbox is experiment-centric, where the users
can quickly develop new VLA experiments by simply modifying the Exp script.
Moreover, we provide much stronger pretrained models to achieve great
performance improvements for state-of-the-art VLA policies. Dexbotic will
continuously update to include more of the latest pre-trained foundation models
and cutting-edge VLA models in the industry.

</details>


### [394] [Localising under the drape: proprioception in the era of distributed surgical robotic system](https://arxiv.org/abs/2510.23512)
*Martin Huber,Nicola A. Cavalcanti,Ayoob Davoodi,Ruixuan Li,Christopher E. Mower,Fabio Carrillo,Christoph J. Laux,Francois Teyssere,Thibault Chandanson,Antoine Harlé,Elie Saghbiny,Mazda Farshad,Guillaume Morel,Emmanuel Vander Poorten,Philipp Fürnstahl,Sébastien Ourselin,Christos Bergeles,Tom Vercauteren*

Main category: cs.RO

TL;DR: 本文提出一种无需标记的本体感知方法，通过轻量级的双目RGB摄像头和Transformer深度学习模型，精准定位在消毒罩下的外科手术机器人，提升机器人空间感知能力，减少碰撞和中断，提高手术安全性。


<details>
  <summary>Details</summary>
Motivation: 当前外科手术机器人普遍缺乏对周围环境的空间感知，仅依赖于红外摄像头和反光标记的传统追踪系统，存在视野局限、硬件负担重、易于被遮挡等问题，且难以适应未来多自主机械臂协作操作的复杂场景。

Method: 作者提出基于双目RGB摄像头配合Transformer深度学习模型的无标记本体感知方法，利用大规模（140万幅）的多中心空间手术机器人数据集，跟踪整个机器人和手术场景，实现对机械臂位置的精准感知和场景理解。

Result: 方法实现了对完全覆盖消毒布下机器人的准确本体追踪，在多机器人系统中的定位表现突出，追踪可见性较现有系统提升了25%，并可实时感知组织动态，弥补了传统标记法在术中面临遮挡等情况下的信息盲区。

Conclusion: 这是首次实现无需标记的完全遮蔽下手术机器人本体追踪技术，简化了设置流程，提升了安全性，为未来模块化、自治化手术机器人系统的发展提供了基础。

Abstract: Despite their mechanical sophistication, surgical robots remain blind to
their surroundings. This lack of spatial awareness causes collisions, system
recoveries, and workflow disruptions, issues that will intensify with the
introduction of distributed robots with independent interacting arms. Existing
tracking systems rely on bulky infrared cameras and reflective markers,
providing only limited views of the surgical scene and adding hardware burden
in crowded operating rooms. We present a marker-free proprioception method that
enables precise localisation of surgical robots under their sterile draping
despite associated obstruction of visual cues. Our method solely relies on
lightweight stereo-RGB cameras and novel transformer-based deep learning
models. It builds on the largest multi-centre spatial robotic surgery dataset
to date (1.4M self-annotated images from human cadaveric and preclinical in
vivo studies). By tracking the entire robot and surgical scene, rather than
individual markers, our approach provides a holistic view robust to occlusions,
supporting surgical scene understanding and context-aware control. We
demonstrate an example of potential clinical benefits during in vivo breathing
compensation with access to tissue dynamics, unobservable under state of the
art tracking, and accurately locate in multi-robot systems for future
intelligent interaction. In addition, and compared with existing systems, our
method eliminates markers and improves tracking visibility by 25%. To our
knowledge, this is the first demonstration of marker-free proprioception for
fully draped surgical robots, reducing setup complexity, enhancing safety, and
paving the way toward modular and autonomous robotic surgery.

</details>


### [395] [Explicit Memory through Online 3D Gaussian Splatting Improves Class-Agnostic Video Segmentation](https://arxiv.org/abs/2510.23521)
*Anthony Opipari,Aravindhan K Krishnan,Shreekant Gayaka,Min Sun,Cheng-Hao Kuo,Arnie Sen,Odest Chadwicke Jenkins*

Main category: cs.RO

TL;DR: 本论文提出了一种利用显式3D记忆（3D高斯溅射技术）的方法，以提升视频中无类别分割算法的预测准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 当前大多数视频分割算法要么不使用对象级记忆（如FastSAM），要么仅依赖于隐式的神经网络特征记忆（如SAM2），难以有效追踪和利用历史分割信息，导致预测不够精确和连贯。

Method: 作者提出将显式3D高斯溅射（3DGS）对象级记忆融入分割模型中，通过存储历史分割对象的空间数据，结合多种融合技术（FastSAM-Splat和SAM2-Splat），提升基础模型在视频分割中的表现，并通过消融实验验证设计合理性和参数选择。

Result: 在真实和仿真数据集上的实验表明，采用显式3D记忆的模型，相比无记忆或仅用隐式记忆的模型，在分割的准确性和一致性方面均有明显提升。

Conclusion: 显式3D对象级记忆能够有效增强视频分割模型的表现，是提升分割准确性与时序一致性的有效方法。

Abstract: Remembering where object segments were predicted in the past is useful for
improving the accuracy and consistency of class-agnostic video segmentation
algorithms. Existing video segmentation algorithms typically use either no
object-level memory (e.g. FastSAM) or they use implicit memories in the form of
recurrent neural network features (e.g. SAM2). In this paper, we augment both
types of segmentation models using an explicit 3D memory and show that the
resulting models have more accurate and consistent predictions. For this, we
develop an online 3D Gaussian Splatting (3DGS) technique to store predicted
object-level segments generated throughout the duration of a video. Based on
this 3DGS representation, a set of fusion techniques are developed, named
FastSAM-Splat and SAM2-Splat, that use the explicit 3DGS memory to improve
their respective foundation models' predictions. Ablation experiments are used
to validate the proposed techniques' design and hyperparameter settings.
Results from both real-world and simulated benchmarking experiments show that
models which use explicit 3D memories result in more accurate and consistent
predictions than those which use no memory or only implicit neural network
memories. Project Page: https://topipari.com/projects/FastSAM-Splat/

</details>


### [396] [RobotArena $\infty$: Scalable Robot Benchmarking via Real-to-Sim Translation](https://arxiv.org/abs/2510.23571)
*Yash Jangir,Yidi Zhang,Kashu Yamazaki,Chenyu Zhang,Kuan-Hsun Tu,Tsung-Wei Ke,Lei Ke,Yonatan Bisk,Katerina Fragkiadaki*

Main category: cs.RO

TL;DR: 本文提出了一种新的基准评测框架，将机器人评估转向大规模仿真环境并结合在线人类反馈，提高了评估的规模性、可重复性和真实性。


<details>
  <summary>Details</summary>
Motivation: 当前机器人政策在现实世界中测试存在劳动力密集、慢、难以复制和大规模不安全等问题，而现有模拟基准无法评估来自真实世界演示的数据，且难以衡量复杂策略的泛化能力及执行质量。为此需要一种能更公平和高效评测通用机器人能力的新方法。

Method: 该方法通过视觉语言模型、2D到3D生成建模和可微渲染等技术，将主流机器人视觉演示数据自动转换为仿真环境的数字孪生体。在此基础上，结合自动化VLM引导评分和众包收集的人类偏好判断，对策略效果进行定量和定性评测，并通过系统性扰动仿真环境（如纹理、物体位置）测试策略的稳健性和泛化能力。

Result: 该框架实现了高效、可扩展和可复现的机器人操作策略评测流程，支持对真实世界训练的策略进行严格、持续和广泛的压力测试，显著降低了人工参与的负担。

Conclusion: 所提出的基准解决了当前机器人评测领域缺失的对真实策略可大规模、可扩展、可复现实验环境的需求，有助于推动通用型机器人研究与应用的发展。

Abstract: The pursuit of robot generalists - instructable agents capable of performing
diverse tasks across diverse environments - demands rigorous and scalable
evaluation. Yet real-world testing of robot policies remains fundamentally
constrained: it is labor-intensive, slow, unsafe at scale, and difficult to
reproduce. Existing simulation benchmarks are similarly limited, as they train
and test policies within the same synthetic domains and cannot assess models
trained from real-world demonstrations or alternative simulation environments.
As policies expand in scope and complexity, these barriers only intensify,
since defining "success" in robotics often hinges on nuanced human judgments of
execution quality. In this paper, we introduce a new benchmarking framework
that overcomes these challenges by shifting VLA evaluation into large-scale
simulated environments augmented with online human feedback. Leveraging
advances in vision-language models, 2D-to-3D generative modeling, and
differentiable rendering, our approach automatically converts video
demonstrations from widely used robot datasets into simulated counterparts.
Within these digital twins, we assess VLA policies using both automated
VLM-guided scoring and scalable human preference judgments collected from
crowdworkers, transforming human involvement from tedious scene setup,
resetting, and safety supervision into lightweight preference comparisons. To
measure robustness, we systematically perturb simulated environments along
multiple axes, such as textures and object placements, stress-testing policy
generalization under controlled variation. The result is a continuously
evolving, reproducible, and scalable benchmark for real-world trained robot
manipulation policies, addressing a critical missing capability in today's
robotics landscape.

</details>


### [397] [UrbanVLA: A Vision-Language-Action Model for Urban Micromobility](https://arxiv.org/abs/2510.23576)
*Anqi Li,Zhiyong Wang,Jiazhao Zhang,Minghan Li,Yunpeng Qi,Zhibo Chen,Zhizheng Zhang,He Wang*

Main category: cs.RO

TL;DR: 提出了UrbanVLA框架，显著提升了机器人在城市大规模环境中的导航能力，超过强基线55%以上，具备端到端鲁棒性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 城市微出行应用（如送货机器人）需要在动态、复杂的城市环境下按照长距离路线导航，但现有方法多局限于短距离和可控环境，难以满足真实需求。

Method: 提出UrbanVLA框架，实现视觉-语言-动作（VLA）端到端导航。该方法将带噪声的路线点与视觉观测显式对齐，并据此规划轨迹。训练分为两阶段：一是使用模拟环境和从网络视频解析的轨迹进行有监督微调（SFT）；二是结合仿真和真实世界数据进行强化微调（RFT），提升模型在实际环境下的安全性和适应性。

Result: UrbanVLA在MetaUrban平台的SocialNav任务中，相比于强基线性能提升超过55%。在真实城市环境中，UrbanVLA同样展现出高可靠性与鲁棒性。

Conclusion: UrbanVLA有效整合高低层次导航能力，实现了大规模城市环境中可靠、可扩展和安全的机器人导航，对城市微出行应用具有重要意义。

Abstract: Urban micromobility applications, such as delivery robots, demand reliable
navigation across large-scale urban environments while following long-horizon
route instructions. This task is particularly challenging due to the dynamic
and unstructured nature of real-world city areas, yet most existing navigation
methods remain tailored to short-scale and controllable scenarios. Effective
urban micromobility requires two complementary levels of navigation skills:
low-level capabilities such as point-goal reaching and obstacle avoidance, and
high-level capabilities, such as route-visual alignment. To this end, we
propose UrbanVLA, a route-conditioned Vision-Language-Action (VLA) framework
designed for scalable urban navigation. Our method explicitly aligns noisy
route waypoints with visual observations during execution, and subsequently
plans trajectories to drive the robot. To enable UrbanVLA to master both levels
of navigation, we employ a two-stage training pipeline. The process begins with
Supervised Fine-Tuning (SFT) using simulated environments and trajectories
parsed from web videos. This is followed by Reinforcement Fine-Tuning (RFT) on
a mixture of simulation and real-world data, which enhances the model's safety
and adaptability in real-world settings. Experiments demonstrate that UrbanVLA
surpasses strong baselines by more than 55% in the SocialNav task on MetaUrban.
Furthermore, UrbanVLA achieves reliable real-world navigation, showcasing both
scalability to large-scale urban environments and robustness against real-world
uncertainties.

</details>
