<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 92]
- [cs.CL](#cs.CL) [Total: 74]
- [cs.RO](#cs.RO) [Total: 36]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [MA-LipNet: Multi-Dimensional Attention Networks for Robust Lipreading](https://arxiv.org/abs/2601.20881)
*Matteo Rossi*

Main category: cs.CV

TL;DR: 论文提出了一种名为MA-LipNet的多注意力唇读网络，通过多维度特征优化显著提升了唇读准确率。


<details>
  <summary>Details</summary>
Motivation: 现有唇读方法对说话者口型等精细动作区分能力弱，泛化能力不足，难以应对实际复杂场景。提升特征辨别力和泛化性是该领域核心难题。

Method: 提出了MA-LipNet模型，采用依次串联的三种专用注意力模块：通道注意力模块（CA）自适应调整通道特征；联合时空注意力（JSTA）对时空维统一粗筛；分离时空注意力（SSTA）精细分别优化时间和空间特征，从多维度净化视觉特征。

Result: 在CMLR和GRID主流唇读数据集上，MA-LipNet大幅降低了字符错误率（CER）和单词错误率（WER），优于其他主流方法。

Conclusion: 多维度特征净化（通道、时空）对于提升视觉语音识别鲁棒性至关重要，MA-LipNet展现了卓越的效果和广泛应用潜力。

Abstract: Lipreading, the technology of decoding spoken content from silent videos of lip movements, holds significant application value in fields such as public security. However, due to the subtle nature of articulatory gestures, existing lipreading methods often suffer from limited feature discriminability and poor generalization capabilities. To address these challenges, this paper delves into the purification of visual features from temporal, spatial, and channel dimensions. We propose a novel method named Multi-Attention Lipreading Network(MA-LipNet). The core of MA-LipNet lies in its sequential application of three dedicated attention modules. Firstly, a \textit{Channel Attention (CA)} module is employed to adaptively recalibrate channel-wise features, thereby mitigating interference from less informative channels. Subsequently, two spatio-temporal attention modules with distinct granularities-\textit{Joint Spatial-Temporal Attention (JSTA)} and \textit{Separate Spatial-Temporal Attention (SSTA)}-are leveraged to suppress the influence of irrelevant pixels and video frames. The JSTA module performs a coarse-grained filtering by computing a unified weight map across the spatio-temporal dimensions, while the SSTA module conducts a more fine-grained refinement by separately modeling temporal and spatial attentions. Extensive experiments conducted on the CMLR and GRID datasets demonstrate that MA-LipNet significantly reduces the Character Error Rate (CER) and Word Error Rate (WER), validating its effectiveness and superiority over several state-of-the-art methods. Our work highlights the importance of multi-dimensional feature refinement for robust visual speech recognition.

</details>


### [2] [Non-Markov Multi-Round Conversational Image Generation with History-Conditioned MLLMs](https://arxiv.org/abs/2601.20911)
*Haochen Zhang,Animesh Sinha,Felix Juefei-Xu,Haoyu Ma,Kunpeng Li,Zhipeng Fan,Meng Dong,Xiaoliang Dai,Tingbo Hou,Peizhao Zhang,Zecheng He*

Main category: cs.CV

TL;DR: 本文提出了一种针对非马尔可夫对话图像生成的新方法，并通过一系列技术手段显著提升了多轮对话中的一致性和指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型虽然能进行生成和编辑图像，但在多轮对话任务中多采用马尔可夫设定（只关注最近一轮历史），这导致模型无法有效利用和理解长程历史信息。实际应用场景中，用户可能会回溯、撤销或引用多轮前信息，因此需要更强历史建模能力。

Method: 1）构造非马尔可夫多轮基准数据，包括回滚式编辑和基于名字的多轮个性化任务；2）提出基于历史条件的训练与推理框架，通过token级缓存防止多轮中的身份漂移；3）改进高保真图像重建与可编辑个性化方法，引入基于重建的DiT解码器和多阶段微调策略。

Result: 通过在新方法上训练，实验表明多轮对话中的一致性和对指令的遵循性有了显著提升，同时保持了单轮编辑和个性化能力。

Conclusion: 专门针对非马尔可夫多轮对话进行训练，能大幅提升多模态对话生成模型在复杂历史语境下的表现，为实际应用中的多轮图像交互带来更优体验。

Abstract: Conversational image generation requires a model to follow user instructions across multiple rounds of interaction, grounded in interleaved text and images that accumulate as chat history. While recent multimodal large language models (MLLMs) can generate and edit images, most existing multi-turn benchmarks and training recipes are effectively Markov: the next output depends primarily on the most recent image, enabling shortcut solutions that ignore long-range history. In this work we formalize and target the more challenging non-Markov setting, where a user may refer back to earlier states, undo changes, or reference entities introduced several rounds ago. We present (i) non-Markov multi-round data construction strategies, including rollback-style editing that forces retrieval of earlier visual states and name-based multi-round personalization that binds names to appearances across rounds; (ii) a history-conditioned training and inference framework with token-level caching to prevent multi-round identity drift; and (iii) enabling improvements for high-fidelity image reconstruction and editable personalization, including a reconstruction-based DiT detokenizer and a multi-stage fine-tuning curriculum. We demonstrate that explicitly training for non-Markov interactions yields substantial improvements in multi-round consistency and instruction compliance, while maintaining strong single-round editing and personalization.

</details>


### [3] [Text controllable PET denoising](https://arxiv.org/abs/2601.20990)
*Xuehua Ye,Hongxu Yang,Adam J. Schwarz*

Main category: cs.CV

TL;DR: 本文提出了一种结合CLIP特征与U-Net结构的文本引导型去噪方法，可提升不同计数水平下的PET图像质量，实验显示在定性和定量评估方面均有明显提升。


<details>
  <summary>Details</summary>
Motivation: PET图像在医学诊断中很重要，但常受复杂噪声影响，影响诊断效果。现有去噪方法受制于数据特性，难以在不同计数水平下适用。作者希望开发一个通用且高效的去噪模型。

Method: 提出基于CLIP预训练模型提取的文本特征作为引导，结合U-Net网络结构，实现对不同剂量/计数水平下PET图像的一体化去噪训练和推理。模型能根据输入的描述自适应调整去噪策略。

Result: 该模型在多个评价指标上超越以往方法，无论是主观视觉效果还是客观量化标准，均取得了显著提升。展示了在多种计数水平下均具有良好适应性和稳定性。

Conclusion: 该文提出的文本引导型去噪方法能广泛提升PET图像质量，具备较高的灵活性，有潜力应用于更复杂的去噪场景或用于减少扫描采集时间。

Abstract: Positron Emission Tomography (PET) imaging is a vital tool in medical diagnostics, offering detailed insights into molecular processes within the human body. However, PET images often suffer from complicated noise, which can obscure critical diagnostic information. The quality of the PET image is impacted by various factors including scanner hardware, image reconstruction, tracer properties, dose/count level, and acquisition time. In this study, we propose a novel text-guided denoising method capable of enhancing PET images across a wide range of count levels within a single model. The model utilized the features from a pretrained CLIP model with a U-Net based denoising model. Experimental results demonstrate that the proposed model leads significant improvements in both qualitative and quantitative assessments. The flexibility of the model shows the potential for helping more complicated denoising demands or reducing the acquisition time.

</details>


### [4] [Low performing pixel correction in computed tomography with unrolled network and synthetic data training](https://arxiv.org/abs/2601.20995)
*Hongxu Yang,Levente Lippenszky,Edina Timko,Lehel Ferenczi,Gopal Avinash*

Main category: cs.CV

TL;DR: 本文提出了一种无需真实临床数据，仅用合成数据训练的双域展开网络，有效校正CT探测器低性能像素导致的伪影问题，实际性能大幅优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前CT低性能像素引起的伪影校正方法多依赖监督学习和昂贵的数据采集，而且仅关注于图像域或投影域，未合理利用二者间的内在关联。急需一种无需真实数据采集、可充分利用图像和投影数据相关性的校正方法。

Method: 作者提出一种基于合成数据的卷积神经网络展开方法，联合利用图像域和正弦域的相关性进行伪影校正。具体通过从自然图像合成CT投影，提高模型泛化能力，无需真实临床数据即可完成模型训练，实现双域伪影矫正。

Result: 在1-2%探测器失效模拟实验中，该方法在伪影校正能力上远超当前最佳方法，能有效降低低性能像素带来的环形和条带伪影。

Conclusion: 该方法无需昂贵的数据采集，成功实现了软件层面对不同CT设备低性能像素伪影的通用自动化校正，具有广泛适应性和实际推广价值。

Abstract: Low performance pixels (LPP) in Computed Tomography (CT) detectors would lead to ring and streak artifacts in the reconstructed images, making them clinically unusable. In recent years, several solutions have been proposed to correct LPP artifacts, either in the image domain or in the sinogram domain using supervised deep learning methods. However, these methods require dedicated datasets for training, which are expensive to collect. Moreover, existing approaches focus solely either on image-space or sinogram-space correction, ignoring the intrinsic correlations from the forward operation of the CT geometry. In this work, we propose an unrolled dual-domain method based on synthetic data to correct LPP artifacts. Specifically, the intrinsic correlations of LPP between the sinogram and image domains are leveraged through synthetic data generated from natural images, enabling the trained model to correct artifacts without requiring any real-world clinical data. In experiments simulating 1-2% detectors defect near the isocenter, the proposed method outperformed the state-of-the-art approaches by a large margin. The results indicate that our solution can correct LPP artifacts without the cost of data collection for model training, and it is adaptable to different scanner settings for software-based applications.

</details>


### [5] [AI-based Prediction of Biochemical Recurrence from Biopsy and Prostatectomy Samples](https://arxiv.org/abs/2601.21022)
*Andrea Camilloni,Chiara Micoli,Nita Mulliqi,Erik Everett Palm,Thorgerdur Palsdottir,Kelvin Szolnoky,Xiaoyi Ji,Sol Erika Boman,Andrea Discacciati,Henrik Grönberg,Lars Egevad,Tobias Nordström,Kimmo Kartasalo,Martin Eklund*

Main category: cs.CV

TL;DR: 本研究开发并验证了一种基于AI的组织病理图像分析模型，可用于预测前列腺癌根治性切除术后生化复发（BCR）的风险，并显示有助于提升术前和术后决策制定。


<details>
  <summary>Details</summary>
Motivation: 现有的前列腺癌术后生化复发风险预测工具准确性有限，难以精确识别高风险患者，因此需要更精确、个性化的预测手段。

Method: 研究者使用STHLM3队列（n=676）的前列腺活检切片，应用基础模型（foundation models）与基于注意力的多实例学习训练AI模型预测BCR风险，并在LEOPARD、CHIMERA和TCGA-PRAD三个独立的根治切除术队列进行外部验证。模型性能通过5年时变AUC评估，并结合临床变量分析模型的增量价值。

Result: AI模型在三个外部队列中的5年AUC分别为0.64、0.70、0.70。临床变量的整合进一步提升了风险分层的准确性。与现有指南（CAPRA-S）相比，AI模型在术后预后判定方面表现有增量改善。

Conclusion: AI驱动的组织病理预测方法具备良好的泛化能力，可服务于前列腺癌术前及术后风险评估，但其在多模态预测模型中的实际增益需更严格的后续验证。

Abstract: Biochemical recurrence (BCR) after radical prostatectomy (RP) is a surrogate marker for aggressive prostate cancer with adverse outcomes, yet current prognostic tools remain imprecise. We trained an AI-based model on diagnostic prostate biopsy slides from the STHLM3 cohort (n = 676) to predict patient-specific risk of BCR, using foundation models and attention-based multiple instance learning. Generalizability was assessed across three external RP cohorts: LEOPARD (n = 508), CHIMERA (n = 95), and TCGA-PRAD (n = 379). The image-based approach achieved 5-year time-dependent AUCs of 0.64, 0.70, and 0.70, respectively. Integrating clinical variables added complementary prognostic value and enabled statistically significant risk stratification. Compared with guideline-based CAPRA-S, AI incrementally improved postoperative prognostication. These findings suggest biopsy-trained histopathology AI can generalize across specimen types to support preoperative and postoperative decision making, but the added value of AI-based multimodal approaches over simpler predictive models should be critically scrutinized in further studies.

</details>


### [6] [BadDet+: Robust Backdoor Attacks for Object Detection](https://arxiv.org/abs/2601.21066)
*Kealan Dunnett,Reza Arablouei,Dimity Miller,Volkan Dedeoglu,Raja Jurdak*

Main category: cs.CV

TL;DR: 本文提出了BadDet+，一种增强型的目标检测后门攻击方法，兼顾了位置与尺度不变性，并提升了物理世界下的攻击效果。相比以往方法，BadDet+实现了更好的攻击转移能力，同时保持了模型正常性能。


<details>
  <summary>Details</summary>
Motivation: 目前深度学习中的后门攻击主要集中于图像分类任务，对目标检测任务的攻击方法还不成熟，且存在过度依赖不现实假设以及缺乏物理验证等问题。该研究旨在填补这一空白，提出更具实际应用价值的目标检测后门攻击方法。

Method: 作者提出了BadDet+，基于惩罚机制的后门攻击框架。该方法通过对触发输入进行log-barrier惩罚来压制真实类别的预测，统一实现了区域误分类攻击（RMA）和物体消失攻击（ODA），具备位置与尺度不变性，并提升了物理鲁棒性。

Result: 在真实数据集上的实验显示，BadDet+在合成-物理迁移效果上显著优于现有的RMA和ODA基线方法，同时不会影响模型在干净样本上的性能。理论分析还表明，该惩罚机制可在特定特征子空间中稳定诱发后门攻击。

Conclusion: BadDet+揭示了目标检测系统在后门攻击下存在的严重安全隐患，并说明针对该类攻击需制定专门的防御策略。

Abstract: Backdoor attacks pose a severe threat to deep learning, yet their impact on object detection remains poorly understood compared to image classification. While attacks have been proposed, we identify critical weaknesses in existing detection-based methods, specifically their reliance on unrealistic assumptions and a lack of physical validation. To bridge this gap, we introduce BadDet+, a penalty-based framework that unifies Region Misclassification Attacks (RMA) and Object Disappearance Attacks (ODA). The core mechanism utilizes a log-barrier penalty to suppress true-class predictions for triggered inputs, resulting in (i) position and scale invariance, and (ii) enhanced physical robustness. On real-world benchmarks, BadDet+ achieves superior synthetic-to-physical transfer compared to existing RMA and ODA baselines while preserving clean performance. Theoretical analysis confirms the proposed penalty acts within a trigger-specific feature subspace, reliably inducing attacks without degrading standard inference. These results highlight significant vulnerabilities in object detection and the necessity for specialized defenses.

</details>


### [7] [Towards Mitigating Modality Bias in Vision-Language Models for Temporal Action Localization](https://arxiv.org/abs/2601.21078)
*Jiaqi Li,Guangming Wang,Shuntian Zheng,Minzhe Ni,Xiaoman Lu,Guanghui Ye,Yu Guan*

Main category: cs.CV

TL;DR: 本文提出了ActionVLM框架，通过动态调整视觉与语言信息在时序动作定位中的贡献，有效减轻了模态偏倚；实验表明该方法领先现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有利用视觉-语言模型(VLM)的方法在时序动作定位任务中过度依赖语言先验，导致视觉表现受损，产生显著的模态偏倚，影响整体识别效果。

Method: 提出ActionVLM框架，核心为两个创新模块：一是去偏重加权模块，动态根据语言对视觉提升的实际增益调整语言分量权重；二是残差聚合策略，将语言作为视觉的辅助手段，而非主导模态，从而系统性减轻模态偏倚。

Result: 在THUMOS14等数据集上实验，ActionVLM较最新方法在mAP指标上提升最高达3.2%。

Conclusion: ActionVLM实现了视觉主导下的视觉-语言融合，有效弱化模态偏倚，显著提升了时序动作定位性能。

Abstract: Temporal Action Localization (TAL) requires identifying both the boundaries and categories of actions in untrimmed videos. While vision-language models (VLMs) offer rich semantics to complement visual evidence, existing approaches tend to overemphasize linguistic priors at the expense of visual performance, leading to a pronounced modality bias. We propose ActionVLM, a vision-language aggregation framework that systematically mitigates modality bias in TAL. Our key insight is to preserve vision as the dominant signal while adaptively exploiting language only when beneficial. To this end, we introduce (i) a debiasing reweighting module that estimates the language advantage-the incremental benefit of language over vision-only predictions-and dynamically reweights language modality accordingly, and (ii) a residual aggregation strategy that treats language as a complementary refinement rather than the primary driver. This combination alleviates modality bias, reduces overconfidence from linguistic priors, and strengthens temporal reasoning. Experiments on THUMOS14 show that our model outperforms state-of-the-art by up to 3.2% mAP.

</details>


### [8] [Shape of Thought: Progressive Object Assembly via Visual Chain-of-Thought](https://arxiv.org/abs/2601.21081)
*Yu Huo,Siyu Zhang,Kun Zeng,Haoyue Liu,Owen Lee,Junlin Chen,Yuquan Lu,Yifu Guo,Yaodong Liang,Xiaoying Tang*

Main category: cs.CV

TL;DR: 提出了Shape-of-Thought (SoT) 框架，使生成式多模态模型在文本到图像生成任务中，能更好地处理结构化的组合问题，如数目、属性绑定和部件关系。通过构建新数据集和基准任务，SoT显著提升了生成结果的结构完整性和属性一致性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像的生成模型难以处理组合结构约束，尤其在数目、属性绑定、部件关系等方面表现不佳。本研究致力于解决这些限制，使生成模型在结构和属性控制上更加可靠。

Method: 提出Shape-of-Thought (SoT) 框架，让多模态自回归模型交错生成文本计划和2D中间可视化结果，通过这个过程模型学习形状组装逻辑。构建了SoT-26K大规模带装配路径的数据集及T2S-CompBench基准，用于训练和评测。

Result: 在SoT-26K上微调后的模型在组件数量和结构拓扑两项任务上，分别达到88.4%和84.8%，比纯文本基线高出约20%。

Conclusion: SoT为组合型生成任务引入了可解释、过程可监督的新范式，在多模态生成领域显著提升了结构控制和透明度。

Abstract: Multimodal models for text-to-image generation have achieved strong visual fidelity, yet they remain brittle under compositional structural constraints-notably generative numeracy, attribute binding, and part-level relations. To address these challenges, we propose Shape-of-Thought (SoT), a visual CoT framework that enables progressive shape assembly via coherent 2D projections without external engines at inference time. SoT trains a unified multimodal autoregressive model to generate interleaved textual plans and rendered intermediate states, helping the model capture shape-assembly logic without producing explicit geometric representations. To support this paradigm, we introduce SoT-26K, a large-scale dataset of grounded assembly traces derived from part-based CAD hierarchies, and T2S-CompBench, a benchmark for evaluating structural integrity and trace faithfulness. Fine-tuning on SoT-26K achieves 88.4% on component numeracy and 84.8% on structural topology, outperforming text-only baselines by around 20%. SoT establishes a new paradigm for transparent, process-supervised compositional generation. The code is available at https://anonymous.4open.science/r/16FE/. The SoT-26K dataset will be released upon acceptance.

</details>


### [9] [An AI Framework for Microanastomosis Motion Assessment](https://arxiv.org/abs/2601.21120)
*Yan Meng,Eduardo J. Torres-Rodríguez,Marcelle Altshuler,Nishanth Gowda,Arhum Naeem,Recai Yilmaz,Omar Arnaout,Daniel A. Donoho*

Main category: cs.CV

TL;DR: 本论文提出了一个基于AI的微血管吻合技术自动评估系统，能够高效且客观评估手术器械操作能力。


<details>
  <summary>Details</summary>
Motivation: 传统显微外科技能评估方法存在主观性强、评判标准不统一、易受认知偏见影响及人工评审耗时等问题，亟需一种客观、自动化且可扩展的评估系统来提升评估的可靠性和效率。

Method: 该系统包含四个核心模块：(1) 基于YOLO架构的器械检测模块；(2) 基于DeepSORT的器械追踪模块；(3) 使用形状描述符的器械尖端定位模块；(4) 基于专家标记数据训练的监督分类模块，用于评估器械操作能力。

Result: 实验结果显示，该框架仪器检测精度达97%，mAP为96%(IoU阈值50-95%)，体现出该系统的高效性和准确性。

Conclusion: 本文提出的AI评估框架能够自动、客观地评估微血管吻合手术中的器械操作能力，有望替代传统人工评判，显著提升评估效率与一致性。

Abstract: Proficiency in microanastomosis is a fundamental competency across multiple microsurgical disciplines. These procedures demand exceptional precision and refined technical skills, making effective, standardized assessment methods essential. Traditionally, the evaluation of microsurgical techniques has relied heavily on the subjective judgment of expert raters. They are inherently constrained by limitations such as inter-rater variability, lack of standardized evaluation criteria, susceptibility to cognitive bias, and the time-intensive nature of manual review. These shortcomings underscore the urgent need for an objective, reliable, and automated system capable of assessing microsurgical performance with consistency and scalability. To bridge this gap, we propose a novel AI framework for the automated assessment of microanastomosis instrument handling skills. The system integrates four core components: (1) an instrument detection module based on the You Only Look Once (YOLO) architecture; (2) an instrument tracking module developed from Deep Simple Online and Realtime Tracking (DeepSORT); (3) an instrument tip localization module employing shape descriptors; and (4) a supervised classification module trained on expert-labeled data to evaluate instrument handling proficiency. Experimental results demonstrate the effectiveness of the framework, achieving an instrument detection precision of 97%, with a mean Average Precision (mAP) of 96%, measured by Intersection over Union (IoU) thresholds ranging from 50% to 95% (mAP50-95).

</details>


### [10] [Bidirectional Cross-Perception for Open-Vocabulary Semantic Segmentation in Remote Sensing Imagery](https://arxiv.org/abs/2601.21159)
*Jianzheng Wang,Huan Ni*

Main category: cs.CV

TL;DR: 本论文提出了一种新的无需训练的开放词汇语义分割框架（SDCI），能有效提升高分辨率遥感图像中复杂目标和边界的分割精度，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有无训练开放词汇遥感语义分割方法通过单向的信息融合与浅层处理，难以有效结合精准定位与语义预测，在高分辨率、目标密集且边界复杂的场景下表现受限。

Method: 提出SDCI框架，包括三大技术创新：1）跨模型注意力融合模块（CAF），实现多模型之间的特征协同推理；2）双向跨图扩散细化模块（BCDR），通过随机游走迭代，增强分割分数的可靠性；3）基于超像素结构和凸优化机制的超像素协同预测（CSCP），进一步精细化边界。

Result: 在多个遥感语义分割公开数据集上，SDCI方法在分割精度等指标上超越现有无训练开放词汇语义分割方法。消融实验还证明传统超像素结构在深度学习框架下仍具有效性。

Conclusion: SDCI实现了高分辨率遥感图像中无训练、开放词汇条件下的高效精细分割，并为传统遥感图像分析方法在深度框架中的应用提供了新的思路。

Abstract: High-resolution remote sensing imagery is characterized by densely distributed land-cover objects and complex boundaries, which places higher demands on both geometric localization and semantic prediction. Existing training-free open-vocabulary semantic segmentation (OVSS) methods typically fuse CLIP and vision foundation models (VFMs) using "one-way injection" and "shallow post-processing" strategies, making it difficult to satisfy these requirements. To address this issue, we propose a spatial-regularization-aware dual-branch collaborative inference framework for training-free OVSS, termed SDCI. First, during feature encoding, SDCI introduces a cross-model attention fusion (CAF) module, which guides collaborative inference by injecting self-attention maps into each other. Second, we propose a bidirectional cross-graph diffusion refinement (BCDR) module that enhances the reliability of dual-branch segmentation scores through iterative random-walk diffusion. Finally, we incorporate low-level superpixel structures and develop a convex-optimization-based superpixel collaborative prediction (CSCP) mechanism to further refine object boundaries. Experiments on multiple remote sensing semantic segmentation benchmarks demonstrate that our method achieves better performance than existing approaches. Moreover, ablation studies further confirm that traditional object-based remote sensing image analysis methods leveraging superpixel structures remain effective within deep learning frameworks. Code: https://github.com/yu-ni1989/SDCI.

</details>


### [11] [Enhancing Underwater Light Field Images via Global Geometry-aware Diffusion Process](https://arxiv.org/abs/2601.21179)
*Yuji Lin,Qian Zhao,Zongsheng Yue,Junhui Hou,Deyu Meng*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型的新方法GeoDiff-LF，用于提升4维光场（LF）水下成像质量，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 水下图像存在颜色失真和视觉质量下降等问题，尤其是在多视角4D光场成像下更为复杂。现有方法难以同时提升多角度视觉效果和整体结构一致性。

Method: 方法基于扩散模型（diffusion model）和SD-Turbo架构，包含三大创新：1）改进的U-Net架构，融合卷积和注意力机制以捕捉几何线索；2）基于张量分解与分阶段加权的几何引导损失函数，提升全局一致性；3）带噪声预测的优化采样策略，提高采样效率。通过结合扩散先验和光场几何特性，有效提升水下4D成像的表现。

Result: 大量实验表明，GeoDiff-LF在视觉保真度和定量指标上都优于现有方法，显著改善水下场景的颜色失真，并提升整体图像质量。

Conclusion: GeoDiff-LF为水下4D光场图像增强提供了新的手段，推动了该领域的最新发展。代码已开源方便进一步研究和应用。

Abstract: This work studies the challenging problem of acquiring high-quality underwater images via 4-D light field (LF) imaging. To this end, we propose GeoDiff-LF, a novel diffusion-based framework built upon SD-Turbo to enhance underwater 4-D LF imaging by leveraging its spatial-angular structure. GeoDiff-LF consists of three key adaptations: (1) a modified U-Net architecture with convolutional and attention adapters to model geometric cues, (2) a geometry-guided loss function using tensor decomposition and progressive weighting to regularize global structure, and (3) an optimized sampling strategy with noise prediction to improve efficiency. By integrating diffusion priors and LF geometry, GeoDiff-LF effectively mitigates color distortion in underwater scenes. Extensive experiments demonstrate that our framework outperforms existing methods across both visual fidelity and quantitative performance, advancing the state-of-the-art in enhancing underwater imaging. The code will be publicly available at https://github.com/linlos1234/GeoDiff-LF.

</details>


### [12] [FRISM: Fine-Grained Reasoning Injection via Subspace-Level Model Merging for Vision-Language Models](https://arxiv.org/abs/2601.21187)
*Chenyu Huang,Peng Ye,Xudong Tan,Jinhan Mu,Shenghe Zheng,Li Shen,Tao Chen*

Main category: cs.CV

TL;DR: 该论文提出了FRISM，一种通过更细粒度的子空间级模型融合来提升视觉-语言模型（VLM）推理能力的方法。相较以往粗粒度的方法，FRISM能在不损失视觉能力的同时，有效注入推理能力。


<details>
  <summary>Details</summary>
Motivation: 目前VLM与大型推理模型（LRM）的融合多在层级进行，常常导致推理增强和视觉能力保持之间存在权衡，难以兼顾。作者因此寻求一种更细粒度的融合方式，兼顾两者性能。

Method: FRISM框架将推理能力视作存在于模型权重的不同子空间中。先用奇异值分解（SVD）分解LRM的任务向量，再通过学习自适应调整每个子空间的缩放系数，实现更精细的推理能力注入。同时引入了无标签自蒸馏的双目标优化策略，提高泛用性。

Result: 在多个主流视觉推理数据集上进行实验，FRISM相比现有方法在推理能力提升的同时，并未牺牲视觉任务性能，取得了最新最优的结果。

Conclusion: FRISM通过子空间级的精细融合，有效增强了VLM的推理能力且保持了视觉能力，为模型融合提供了新的思路。

Abstract: Efficiently enhancing the reasoning capabilities of Vision-Language Models (VLMs) by merging them with Large Reasoning Models (LRMs) has emerged as a promising direction. However, existing methods typically operate at a coarse-grained layer level, which often leads to a trade-off between injecting reasoning capabilities and preserving visual capabilities. To address this limitation, we propose {FRISM} (Fine-grained Reasoning Injection via Subspace-level model Merging), a fine-grained reasoning injection framework based on subspace-level model merging. Observing that reasoning capabilities are encoded in distinct subspaces, FRISM decomposes LRM task vectors via Singular Value Decomposition (SVD) and adaptively tunes the scaling coefficients of each subspace through learning to realize fine-grained reasoning injection. Furthermore, we introduce a label-free self-distillation learning strategy with a dual-objective optimization using common vision-language perception datasets. Extensive experiments demonstrate that FRISM effectively improves reasoning capabilities without compromising the model's original visual capabilities by consistently achieving state-of-the-art performance across diverse visual reasoning benchmarks.

</details>


### [13] [Generative Recall, Dense Reranking: Learning Multi-View Semantic IDs for Efficient Text-to-Video Retrieval](https://arxiv.org/abs/2601.21193)
*Zecheng Zhao,Zhi Chen,Zi Huang,Shazia Sadiq,Tong Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为GRDR的两阶段文本到视频检索方法，兼具高准确性和极低存储、推理成本。新方法能在显著减少存储和加速检索的同时，达到甚至匹配先进的稠密检索模型准确率。


<details>
  <summary>Details</summary>
Motivation: 传统的稠密检索（dense retrieval）在文本到视频检索中准确性高，但随数据集扩大计算和存储压力激增，不适合实时大规模场景。因此主流采用两阶段流程，首阶段用高效但粗糙的召回模型，次阶段用高精度（含稠密检索器）精细重排。但首阶段模型成为性能瓶颈。生成式检索（generative retrieval）以语义ID表征视频，推理与存储几乎与库规模无关，但现有方案语义歧义大、跨模态对齐差，限制了实际召回质量。作者为提升召回模型能力，解决以上缺陷，提出新方法。

Method: 提出GRDR方法，利用“查询引导多视图分词器”，赋予每个视频多个语义ID，各ID代表不同语义路径；分词器与生成式召回器联合训练，共享码本，让生成式检索的ID成为视频和文本间的语义桥梁。推理时用“字典树约束解码”快速生成精简候选集，再用稠密模型精细重排。

Result: 在多个文本到视频检索基准数据集上，GRDR在检索准确率与领先的稠密方案持平，但索引存储降低了一个数量级，且全库检索速度提升最高达300倍。

Conclusion: GRDR有效突破了两阶段文本到视频检索中召回端性能瓶颈。兼顾效率与准确率，提升实践落地价值。

Abstract: Text-to-Video Retrieval (TVR) is essential in video platforms. Dense retrieval with dual-modality encoders leads in accuracy, but its computation and storage scale poorly with corpus size. Thus, real-time large-scale applications adopt two-stage retrieval, where a fast recall model gathers a small candidate pool, which is reranked by an advanced dense retriever. Due to hugely reduced candidates, the reranking model can use any off-the-shelf dense retriever without hurting efficiency, meaning the recall model bounds two-stage TVR performance. Recently, generative retrieval (GR) replaces dense video embeddings with discrete semantic IDs and retrieves by decoding text queries into ID tokens. GR offers near-constant inference and storage complexity, and its semantic IDs capture high-level video features via quantization, making it ideal for quickly eliminating irrelevant candidates during recall. However, as a recall model in two-stage TVR, GR suffers from (i) semantic ambiguity, where each video satisfies diverse queries but is forced into one semantic ID; and (ii) cross-modal misalignment, as semantic IDs are solely derived from visual features without text supervision. We propose Generative Recall and Dense Reranking (GRDR), designing a novel GR method to uplift recalled candidate quality. GRDR assigns multiple semantic IDs to each video using a query-guided multi-view tokenizer exposing diverse semantic access paths, and jointly trains the tokenizer and generative retriever via a shared codebook to cast semantic IDs as the semantic bridge between texts and videos. At inference, trie-constrained decoding generates a compact candidate set reranked by a dense model for fine-grained matching. Experiments on TVR benchmarks show GRDR matches strong dense retrievers in accuracy while reducing index storage by an order of magnitude and accelerating up to 300$\times$ in full-corpus retrieval.

</details>


### [14] [Thinker: A vision-language foundation model for embodied intelligence](https://arxiv.org/abs/2601.21199)
*Baiyu Pan,Daqin Luo,Junpeng Yang,Jiyuan Wang,Yixuan Zhang,Hailin Shi,Jichao Jiao*

Main category: cs.CV

TL;DR: 本文提出Thinker模型，通过专为机器人设计的大规模数据集和新的输入方法，有效解决视觉-语言模型在机器人应用中的视角混淆和视频理解不足问题，取得了SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 大模型应用在机器人领域常见易被人类轻松解决但对模型容易出错的问题（如视角混淆、视频结尾信息遗漏），因此需要提升模型在机器人场景中的感知和推理能力。

Method: 1）构建大规模机器人感知与推理相关数据集，包括第一视角视频、视觉定位、空间理解以及链式思维数据。2）提出联合输入关键帧与整段视频序列的新方法，提升模型视频理解能力。

Result: 模型在任务规划领域两大主流基准数据集上取得了当前最优（SOTA）性能。

Conclusion: 通过专门数据集和输入改进能显著提升视觉-语言大模型在机器人领域的推理与任务规划能力。

Abstract: When large vision-language models are applied to the field of robotics, they encounter problems that are simple for humans yet error-prone for models. Such issues include confusion between third-person and first-person perspectives and a tendency to overlook information in video endings during temporal reasoning. To address these challenges, we propose Thinker, a large vision-language foundation model designed for embodied intelligence. We tackle the aforementioned issues from two perspectives. Firstly, we construct a large-scale dataset tailored for robotic perception and reasoning, encompassing ego-view videos, visual grounding, spatial understanding, and chain-of-thought data. Secondly, we introduce a simple yet effective approach that substantially enhances the model's capacity for video comprehension by jointly incorporating key frames and full video sequences as inputs. Our model achieves state-of-the-art results on two of the most commonly used benchmark datasets in the field of task planning.

</details>


### [15] [LAMP: Learning Universal Adversarial Perturbations for Multi-Image Tasks via Pre-trained Models](https://arxiv.org/abs/2601.21220)
*Alvi Md Ishmam,Najibul Haque Sarker,Zaber Ibn Abdul Hakim,Chris Thomas*

Main category: cs.CV

TL;DR: 本文提出了一种名为LAMP的黑盒攻击方法，能在多图像视觉-语言大模型(MLLMs)中实现高效的对抗攻击，突破了单图像、白盒假设的限制。


<details>
  <summary>Details</summary>
Motivation: 随着视觉-语言大模型的发展，越来越多系统支持多张图片输入，但此类多图输入模型的安全性还未被充分探索。现有研究大多仅关注单图像，并假设攻击者拥有模型内部信息（白盒），这在现实中往往不切实际。

Method: 作者提出了LAMP方法，在黑盒设定下，通过学习通用对抗扰动（UAP）攻击多图像MLLMs。该方法引入了基于注意力的约束，阻止模型有效聚合跨图片的信息；同时设计了新颖的跨图像“传染性”约束，使得对抗扰动可影响未被修改的图片，以及让对抗性攻击在不同图片和位置都能稳定生效的位置不变损失。

Result: 实验结果表明，LAMP在多个视觉-语言任务和模型上均显著优于现有攻击方法，达到了最高的攻击成功率。

Conclusion: LAMP突破了以往单图像、白盒攻击的局限，为多图像MLLMs的安全性测试提供了有效工具，也揭示了多模态模型在实际应用中的潜在风险。

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable performance across vision-language tasks. Recent advancements allow these models to process multiple images as inputs. However, the vulnerabilities of multi-image MLLMs remain unexplored. Existing adversarial attacks focus on single-image settings and often assume a white-box threat model, which is impractical in many real-world scenarios. This paper introduces LAMP, a black-box method for learning Universal Adversarial Perturbations (UAPs) targeting multi-image MLLMs. LAMP applies an attention-based constraint that prevents the model from effectively aggregating information across images. LAMP also introduces a novel cross-image contagious constraint that forces perturbed tokens to influence clean tokens, spreading adversarial effects without requiring all inputs to be modified. Additionally, an index-attention suppression loss enables a robust position-invariant attack. Experimental results show that LAMP outperforms SOTA baselines and achieves the highest attack success rates across multiple vision-language tasks and models.

</details>


### [16] [PTQ4ARVG: Post-Training Quantization for AutoRegressive Visual Generation Models](https://arxiv.org/abs/2601.21238)
*Xuewen Liu,Zhikai Li,Jing Zhang,Mengjuan Chen,Qingyi Gu*

Main category: cs.CV

TL;DR: 本文提出了PTQ4ARVG框架，实现了对自回归视觉生成模型（ARVG）的高效量化，无需重新训练，且性能损失极小。


<details>
  <summary>Details</summary>
Motivation: 虽然自回归视觉生成模型(ARVG)在性能和架构上表现优异，但其量化技术尚未成熟，现有量化方法难以有效适用于ARVG，严重制约其在资源受限场景下的应用。作者旨在探索ARVG模型量化的关键难题并提出解决方案。

Method: 提出了PTQ4ARVG训练后量化框架，包括：(1)信道级Gain-Projected Scaling (GPS)，通过泰勒展开量化损失并微分求解最优缩放因子，用以抑制信道出极值；(2)静态Token级量化(STWQ)，利用ARVG模型特有的token结构特性，减少Token间动态变化影响，且无需复杂校准；(3)分布引导校准(DGC)，挑选能最大化分布熵的样本，消除由样本不一致引入的分布偏差。

Result: PTQ4ARVG在将ARVG系列模型量化为8-bit和6-bit时，能较好地保留模型原有性能，并拥有广泛验证的实验结果。

Conclusion: PTQ4ARVG为ARVG模型提供了一种低损耗、高效、无须重新训练的量化方法，能够促进此类模型在实际低资源场景落地。

Abstract: AutoRegressive Visual Generation (ARVG) models retain an architecture compatible with language models, while achieving performance comparable to diffusion-based models. Quantization is commonly employed in neural networks to reduce model size and computational latency. However, applying quantization to ARVG remains largely underexplored, and existing quantization methods fail to generalize effectively to ARVG models. In this paper, we explore this issue and identify three key challenges: (1) severe outliers at channel-wise level, (2) highly dynamic activations at token-wise level, and (3) mismatched distribution information at sample-wise level. To these ends, we propose PTQ4ARVG, a training-free post-training quantization (PTQ) framework consisting of: (1) Gain-Projected Scaling (GPS) mitigates the channel-wise outliers, which expands the quantization loss via a Taylor series to quantify the gain of scaling for activation-weight quantization, and derives the optimal scaling factor through differentiation.(2) Static Token-Wise Quantization (STWQ) leverages the inherent properties of ARVG, fixed token length and position-invariant distribution across samples, to address token-wise variance without incurring dynamic calibration overhead.(3) Distribution-Guided Calibration (DGC) selects samples that contribute most to distributional entropy, eliminating the sample-wise distribution mismatch. Extensive experiments show that PTQ4ARVG can effectively quantize the ARVG family models to 8-bit and 6-bit while maintaining competitive performance. Code is available at http://github.com/BienLuky/PTQ4ARVG .

</details>


### [17] [NFCDS: A Plug-and-Play Noise Frequency-Controlled Diffusion Sampling Strategy for Image Restoration](https://arxiv.org/abs/2601.21248)
*Zhen Wang,Hongyi Liu,Jianing Li,Zhihui Wei*

Main category: cs.CV

TL;DR: 该论文提出了一种噪声频率调控扩散采样（NFCDS）方法，通过在扩散采样过程中对噪声频率进行控制，改善扩散采样式Plug-and-Play方法在感知质量与数据一致性之间的矛盾。


<details>
  <summary>Details</summary>
Motivation: 扩散采样类PnP方法虽然能生成高感知质量图像，但由于逆扩散过程引入的噪声，导致图像真实度下降，尤其是低频噪声导致模糊。解决感知-保真性（fidelity-perception）矛盾，是提升扩散采样方法实用性的关键。

Method: 提出了一种基于傅里叶域的频谱调控机制（过滤器），在逆扩散采样过程中动态抑制噪声的低频成分、保留高频成分，从而有效控制噪声结构，将数据一致性先验直接注入生成过程，无需额外训练。此模块可直接Plug-and-Play集成到现有扩散重建框架中。

Result: NFCDS提升了多类任务中的保真-感知平衡，实现了更快收敛，并产生同时具有高保真度和高感知质量的结果，无需对模型进行额外训练。

Conclusion: 通过频率域针对性调控扩散采样过程中的噪声结构，可以实现在高感知质量和高保真度之间的优良权衡，为扩散型图像恢复和重建任务提供了新的高效PnP模块。

Abstract: Diffusion sampling-based Plug-and-Play (PnP) methods produce images with high perceptual quality but often suffer from reduced data fidelity, primarily due to the noise introduced during reverse diffusion. To address this trade-off, we propose Noise Frequency-Controlled Diffusion Sampling (NFCDS), a spectral modulation mechanism for reverse diffusion noise. We show that the fidelity-perception conflict can be fundamentally understood through noise frequency: low-frequency components induce blur and degrade fidelity, while high-frequency components drive detail generation. Based on this insight, we design a Fourier-domain filter that progressively suppresses low-frequency noise and preserves high-frequency content. This controlled refinement injects a data-consistency prior directly into sampling, enabling fast convergence to results that are both high-fidelity and perceptually convincing--without additional training. As a PnP module, NFCDS seamlessly integrates into existing diffusion-based restoration frameworks and improves the fidelity-perception balance across diverse zero-shot tasks.

</details>


### [18] [Hypersolid: Emergent Vision Representations via Short-Range Repulsion](https://arxiv.org/abs/2601.21255)
*Esteban Rodríguez-Betancourt,Edgar Casasola-Murillo*

Main category: cs.CV

TL;DR: 本文提出Hypersolid方法，通过局部硬球排斥防止自监督学习中表征坍塌，在精细及低分辨率分类任务取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 自监督学习常出现表征坍塌问题。现有方法多采用全局正则，但效果有限。作者希望找到更有效的方式避免信息损失。

Method: 作者将表征学习视为离散填充问题，将保持信息转化为维持单射性。具体提出Hypersolid方法，通过短距离的硬球排斥实现局部不碰撞，避免表征坍塌。

Result: 采用Hypersolid后的模型在精细分类和低分辨率分类任务中，能更好地保留增强多样性，表现优于现有方法。

Conclusion: 通过局部约束代替全局正则，Hypersolid在防止表征坍塌的同时提升了自监督学习效果，尤其适用于难分辨任务。

Abstract: A recurring challenge in self-supervised learning is preventing representation collapse. Existing solutions typically rely on global regularization, such as maximizing distances, decorrelating dimensions or enforcing certain distributions. We instead reinterpret representation learning as a discrete packing problem, where preserving information simplifies to maintaining injectivity. We operationalize this in Hypersolid, a method using short-range hard-ball repulsion to prevent local collisions. This constraint results in a high-separation geometric regime that preserves augmentation diversity, excelling on fine-grained and low-resolution classification tasks.

</details>


### [19] [Lightweight High-Fidelity Low-Bitrate Talking Face Compression for 3D Video Conference](https://arxiv.org/abs/2601.21269)
*Jianglong Li,Jun Xu,Bingcong Lu,Zhengxue Cheng,Hongwei Hu,Ronghua Wu,Li Song*

Main category: cs.CV

TL;DR: 提出了一种基于参数化人脸建模与3D高斯神经渲染结合的三维说话人脸压缩框架，能以极低码率实现高保真、实时的视频会议。


<details>
  <summary>Details</summary>
Motivation: 现有3D视频会议中，高还原度的人脸表现常常受限于低码率压缩能力。传统2D压缩难以保留三维几何与细节，NeRF等隐式神经渲染又计算开销巨大，需要更高效的新方法。

Method: 提出结合FLAME参数人脸模型和3D Gaussian Splatting神经渲染，只实时传输必要人脸元数据，并利用高斯头模进行高效重建。同时提出高斯属性压缩和MLP网络优化方法，极大提升了编码压缩和传输效率。

Result: 实验显示该方法在同样低码率下，达到更优的码率-失真平衡，生成的人脸渲染高质量、低带宽消耗。

Conclusion: 方法能在极低带宽下实现高保真3D人脸压缩和重建，非常适合实时3D视频会议等应用场景。

Abstract: The demand for immersive and interactive communication has driven advancements in 3D video conferencing, yet achieving high-fidelity 3D talking face representation at low bitrates remains a challenge. Traditional 2D video compression techniques fail to preserve fine-grained geometric and appearance details, while implicit neural rendering methods like NeRF suffer from prohibitive computational costs. To address these challenges, we propose a lightweight, high-fidelity, low-bitrate 3D talking face compression framework that integrates FLAME-based parametric modeling with 3DGS neural rendering. Our approach transmits only essential facial metadata in real time, enabling efficient reconstruction with a Gaussian-based head model. Additionally, we introduce a compact representation and compression scheme, including Gaussian attribute compression and MLP optimization, to enhance transmission efficiency. Experimental results demonstrate that our method achieves superior rate-distortion performance, delivering high-quality facial rendering at extremely low bitrates, making it well-suited for real-time 3D video conferencing applications.

</details>


### [20] [GeoRC: A Benchmark for Geolocation Reasoning Chains](https://arxiv.org/abs/2601.21278)
*Mohit Talreja,Joshua Diao,Jim Thannikary James,Radu Casapu,Tejas Santanam,Ethan Mendes,Alan Ritter,Wei Xu,James Hays*

Main category: cs.CV

TL;DR: 本论文提出了首个视觉语言模型(VLM)在地理位置推理链方面的基准，发现当前VLM虽然定位精度高，但推理解释性差，常产生幻觉错误。


<details>
  <summary>Details</summary>
Motivation: 尽管理论上VLM在地理位置预测上表现优异，但它们很难依据视觉证据给出可靠、可审计的推断过程。本研究动机在于评估和提升VLM在地理推理链解释能力。

Method: 作者与GeoGuessr世界冠军等专家合作，人工标注500个场景、800个地理推理链，构建丰富的推理链数据集，涵盖多种视觉判别属性。利用LLM或VLM作为评审，定量评估VLM自动生成的推理链与专家链的一致性和质量。

Result: Qwen 3的LLM评审方法与人工评分相关性最佳。闭源大模型（如Gemini、GPT-5）在定位上接近专家，但推理链仍弱于人类。开源VLM（如Llama和Qwen）在推理链任务上表现极差，基本等于只基于答案生成幻觉推理的基线。

Conclusion: 现有VLM在高精细视觉属性提取及推理链解释方面仍存在明显短板，与人类专家有不小差距。完善此类能力对提升VLM可信度和实际应用意义重大。

Abstract: Vision Language Models (VLMs) are good at recognizing the global location of a photograph -- their geolocation prediction accuracy rivals the best human experts. But many VLMs are startlingly bad at explaining which image evidence led to their prediction, even when their location prediction is correct. The reasoning chains produced by VLMs frequently hallucinate scene attributes to support their location prediction (e.g. phantom writing, imagined infrastructure, misidentified flora). In this paper, we introduce the first benchmark for geolocation reasoning chains. We focus on the global location prediction task in the popular GeoGuessr game which draws from Google Street View spanning more than 100 countries. We collaborate with expert GeoGuessr players, including the reigning world champion, to produce 800 ground truth reasoning chains for 500 query scenes. These expert reasoning chains address hundreds of different discriminative visual attributes such as license plate shape, architecture, and soil properties to name just a few. We evaluate LLM-as-a-judge and VLM-as-a-judge strategies for scoring VLM-generated reasoning chains against our expert reasoning chains and find that Qwen 3 LLM-as-a-judge correlates best with human scoring. Our benchmark reveals that while large, closed-source VLMs such as Gemini and GPT 5 rival human experts at prediction locations, they still lag behind human experts when it comes to producing auditable reasoning chains. Open weights VLMs such as Llama and Qwen catastrophically fail on our benchmark -- they perform only slightly better than a baseline in which an LLM hallucinates a reasoning chain with oracle knowledge of the photo location but no visual information at all. We believe the gap between human experts and VLMs on this task points to VLM limitations at extracting fine-grained visual attributes from high resolution images.

</details>


### [21] [Token Entropy Regularization for Multi-modal Antenna Affiliation Identification](https://arxiv.org/abs/2601.21280)
*Dong Chen,Ruoyu Li,Xinyan Zhang,Jialei Xu,Ruoseng Zhao,Zhikang Zhang,Lingyun Li,Zizhuang Wei*

Main category: cs.CV

TL;DR: 本文提出一种利用多模态数据（视频影像、天线几何特征和物理小区识别码（PCI）信号）进行天线归属判定的新范式，并引入了Token Entropy Regularization（TER）机制，有效提升了模型在该任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 传统天线归属识别依赖人工巡检，效率低且易出错，随着通信网络复杂化，急需更高效、自动化的识别方法。

Method: 将天线归属判定任务转化为多模态分类与匹配任务，融合了基站视频、天线几何特征及PCI信号，同时针对现有预训练模型在通信领域的不足，提出了专门的训练框架和Token Entropy Regularization（TER）模块，用于在预训练阶段改善模态对齐。

Result: 实验表明，引入TER模块可以加速模型收敛并显著提升性能，同时分析发现首个token的熵值具有模态依赖性。

Conclusion: 多模态结合及TER机制有效提升了天线归属自动识别的准确性与训练效率，为通信网络的运维提供了智能化新方法。

Abstract: Accurate antenna affiliation identification is crucial for optimizing and maintaining communication networks. Current practice, however, relies on the cumbersome and error-prone process of manual tower inspections. We propose a novel paradigm shift that fuses video footage of base stations, antenna geometric features, and Physical Cell Identity (PCI) signals, transforming antenna affiliation identification into multi-modal classification and matching tasks. Publicly available pretrained transformers struggle with this unique task due to a lack of analogous data in the communications domain, which hampers cross-modal alignment. To address this, we introduce a dedicated training framework that aligns antenna images with corresponding PCI signals. To tackle the representation alignment challenge, we propose a novel Token Entropy Regularization module in the pretraining stage. Our experiments demonstrate that TER accelerates convergence and yields significant performance gains. Further analysis reveals that the entropy of the first token is modality-dependent. Code will be made available upon publication.

</details>


### [22] [WorldBench: Disambiguating Physics for Diagnostic Evaluation of World Models](https://arxiv.org/abs/2601.21282)
*Rishi Upadhyay,Howard Zhang,Jim Solomon,Ayush Agrawal,Pranay Boreddy,Shruti Satya Narayana,Yunhao Ba,Alex Wong,Celso M de Melo,Achuta Kadambi*

Main category: cs.CV

TL;DR: 本文提出了WorldBench——一个针对生成式基础模型（如视频世界模型）物理推理能力的全新基准。WorldBench通过分离不同物理概念，有效诊断模型对单一物理规律的理解，发现现有模型均存在物理一致性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有物理视频基准由于多种物理规律纠缠在同一测试中，无法精确评估模型对单一物理概念的理解，使得模型物理推理能力诊断受限。因此需要一个能分门别类评估不同物理概念的基准。

Method: 提出WorldBench基准，针对视频世界模型的物理推理能力进行分概念、分层次的评测。分为两类测试：1）直观物理理解（如物体永久性、尺度/视角等），2）低层次物理常数（如摩擦系数、流体粘度等）。通过每次只考察单一物理规律，实现诊断性评估。

Result: 使用WorldBench对当前最先进的视频世界模型进行测试，发现它们在特定物理概念上均存在明显失败模式，而且所有模型都未达到生成可靠物理交互的物理一致性要求。

Conclusion: WorldBench提供了一个细致且可扩展的物理推理评估框架，有助于推动基于世界模型的学习方法向更强健与通用化方向发展。

Abstract: Recent advances in generative foundational models, often termed "world models," have propelled interest in applying them to critical tasks like robotic planning and autonomous system training. For reliable deployment, these models must exhibit high physical fidelity, accurately simulating real-world dynamics. Existing physics-based video benchmarks, however, suffer from entanglement, where a single test simultaneously evaluates multiple physical laws and concepts, fundamentally limiting their diagnostic capability. We introduce WorldBench, a novel video-based benchmark specifically designed for concept-specific, disentangled evaluation, allowing us to rigorously isolate and assess understanding of a single physical concept or law at a time. To make WorldBench comprehensive, we design benchmarks at two different levels: 1) an evaluation of intuitive physical understanding with concepts such as object permanence or scale/perspective, and 2) an evaluation of low-level physical constants and material properties such as friction coefficients or fluid viscosity. When SOTA video-based world models are evaluated on WorldBench, we find specific patterns of failure in particular physics concepts, with all tested models lacking the physical consistency required to generate reliable real-world interactions. Through its concept-specific evaluation, WorldBench offers a more nuanced and scalable framework for rigorously evaluating the physical reasoning capabilities of video generation and world models, paving the way for more robust and generalizable world-model-driven learning.

</details>


### [23] [Gaussian Belief Propagation Network for Depth Completion](https://arxiv.org/abs/2601.21291)
*Jie Tang,Pingping Xie,Jian Li,Ping Tan*

Main category: cs.CV

TL;DR: 本文提出了一种新的深度补全方法——高斯置信传播网络（GBPN），通过结合深度学习与概率图模型，有效提升了从稀疏深度数据预测高质量稠密深度图的能力，在高稀疏情况下表现尤为突出，并在NYUv2和KITTI等基准上取得了SOTA水平。


<details>
  <summary>Details</summary>
Motivation: 当前深度补全领域的主要挑战在于如何利用深度网络有效处理输入深度数据的稀疏性和不规则性。现有方法在高稀疏度的场景下性能受限，难以充分捕获全局空间依赖。

Method: 作者提出高斯置信传播网络（GBPN），其核心是将深度学习与概率图模型结合。具体流程包括由图模型构建网络（GMCN）动态构建场景特定的马尔可夫随机场（MRF），并利用高斯置信传播（GBP）进行推理来输出稠密深度分布。GMCN不仅学习MRF的数据相关势函数，还自适应地预测非局部边，捕捉复杂的长距离空间依赖。同时，GBP配合串并行信息传递机制，有效传播稀疏深度观测的信息。

Result: 在NYUv2和KITTI数据集上，GBPN显著优于现有方法，达到了SOTA水平。此外，在不同稀疏度、稀疏模式及不同数据集条件下，GBPN展现了更强的鲁棒性及泛化能力。

Conclusion: GBPN通过创新性地结合深度网络与概率图模型，在深度补全任务中有效克服了稀疏和空间依赖性挑战，取得了优异性能，并具备良好的泛化和鲁棒性，可为相关视觉任务提供有效参考。

Abstract: Depth completion aims to predict a dense depth map from a color image with sparse depth measurements. Although deep learning methods have achieved state-of-the-art (SOTA), effectively handling the sparse and irregular nature of input depth data in deep networks remains a significant challenge, often limiting performance, especially under high sparsity. To overcome this limitation, we introduce the Gaussian Belief Propagation Network (GBPN), a novel hybrid framework synergistically integrating deep learning with probabilistic graphical models for end-to-end depth completion. Specifically, a scene-specific Markov Random Field (MRF) is dynamically constructed by the Graphical Model Construction Network (GMCN), and then inferred via Gaussian Belief Propagation (GBP) to yield the dense depth distribution. Crucially, the GMCN learns to construct not only the data-dependent potentials of MRF but also its structure by predicting adaptive non-local edges, enabling the capture of complex, long-range spatial dependencies. Furthermore, we enhance GBP with a serial \& parallel message passing scheme, designed for effective information propagation, particularly from sparse measurements. Extensive experiments demonstrate that GBPN achieves SOTA performance on the NYUv2 and KITTI benchmarks. Evaluations across varying sparsity levels, sparsity patterns, and datasets highlight GBPN's superior performance, notable robustness, and generalizable capability.

</details>


### [24] [Mam-App: A Novel Parameter-Efficient Mamba Model for Apple Leaf Disease Classification](https://arxiv.org/abs/2601.21307)
*Md Nadim Mahamood,Md Imran Hasan,Md Rasheduzzaman,Ausrukona Ray,Md Shafi Ud Doula,Kamrul Hasan*

Main category: cs.CV

TL;DR: 提出了一种基于Mamba的参数高效模型Mam-App，用于果叶病害识别，在多个数据集上以极低参数量取得了高准确率和泛化性能，适用于资源受限平台。


<details>
  <summary>Details</summary>
Motivation: 全球人口增长与技术进步加剧了对粮食的需求，水果病害尤其是苹果叶病造成大量产量损失。现有深度学习模型虽性能优异但参数量大，不利于部署在低资源设备上，轻量化模型又易性能下降。因此需要兼具效率与性能的果叶病害识别方法。

Method: 设计了一种基于Mamba机制的轻量级模型Mam-App，用于特征提取和叶病分类。在PlantVillage苹果、玉米和马铃薯叶病数据集上进行了实验，比较了与主流方法的性能与参数量。

Result: Mam-App模型在苹果叶病测试集上达到了99.58%的准确率（accuracy）、99.30%精度（precision）、99.14%召回率（recall）和99.22%的F1分数，参数量仅为0.051M。在玉米与马铃薯数据集上也获得了接近或超过98%的各项指标，展现强泛化能力。

Conclusion: Mam-App实现了高精度低参数的病害识别，适合在移动端、无人机等资源受限环境部署，并具备良好的跨作物泛化能力。

Abstract: The rapid growth of the global population, alongside exponential technological advancement, has intensified the demand for food production. Meeting this demand depends not only on increasing agricultural yield but also on minimizing food loss caused by crop diseases. Diseases account for a substantial portion of apple production losses, despite apples being among the most widely produced and nutritionally valuable fruits worldwide. Previous studies have employed machine learning techniques for feature extraction and early diagnosis of apple leaf diseases, and more recently, deep learning-based models have shown remarkable performance in disease recognition. However, most state-of-the-art deep learning models are highly parameter-intensive, resulting in increased training and inference time. Although lightweight models are more suitable for user-friendly and resource-constrained applications, they often suffer from performance degradation. To address the trade-off between efficiency and performance, we propose Mam-App, a parameter-efficient Mamba-based model for feature extraction and leaf disease classification. The proposed approach achieves competitive state-of-the-art performance on the PlantVillage Apple Leaf Disease dataset, attaining 99.58% accuracy, 99.30% precision, 99.14% recall, and a 99.22% F1-score, while using only 0.051M parameters. This extremely low parameter count makes the model suitable for deployment on drones, mobile devices, and other low-resource platforms. To demonstrate the robustness and generalizability of the proposed model, we further evaluate it on the PlantVillage Corn Leaf Disease and Potato Leaf Disease datasets. The model achieves 99.48%, 99.20%, 99.34%, and 99.27% accuracy, precision, recall, and F1-score on the corn dataset and 98.46%, 98.91%, 95.39%, and 97.01% on the potato dataset, respectively.

</details>


### [25] [HiFi-Mesh: High-Fidelity Efficient 3D Mesh Generation via Compact Autoregressive Dependence](https://arxiv.org/abs/2601.21314)
*Yanfeng Li,Tao Tan,Qingquan Gao,Zhiwen Cao,Xiaohong liu,Yue Sun*

Main category: cs.CV

TL;DR: 本文提出了一种新的高效3D网格生成方法——LANE，能生成更长序列并提升速度与细节，还引入了AdaGraph策略进一步加速推理。


<details>
  <summary>Details</summary>
Motivation: 现有3D网格序列自回归建模方法受限于资源，生成速度慢且细节受限，无法处理大规模序列，急需突破以提升表现力和效率。

Method: 提出Latent Autoregressive Network (LANE)新架构，通过紧凑的自回归依赖关系来扩展可生成最大序列长度约6倍；采用Adaptive Computation Graph Reconfiguration (AdaGraph)策略，通过时空解耦加快生成过程，突破传统串行推理效率瓶颈。

Result: 实验表明LANE在生成速度、结构细节和几何一致性方面均优于现有方法，且大幅拓展了最大可生成网格序列长度。

Conclusion: LANE为高质量3D网格生成提供了高效且细节丰富的新方案，克服了传统方法在速度及序列规模上的限制。

Abstract: High-fidelity 3D meshes can be tokenized into one-dimension (1D) sequences and directly modeled using autoregressive approaches for faces and vertices. However, existing methods suffer from insufficient resource utilization, resulting in slow inference and the ability to handle only small-scale sequences, which severely constrains the expressible structural details. We introduce the Latent Autoregressive Network (LANE), which incorporates compact autoregressive dependencies in the generation process, achieving a $6\times$ improvement in maximum generatable sequence length compared to existing methods. To further accelerate inference, we propose the Adaptive Computation Graph Reconfiguration (AdaGraph) strategy, which effectively overcomes the efficiency bottleneck of traditional serial inference through spatiotemporal decoupling in the generation process. Experimental validation demonstrates that LANE achieves superior performance across generation speed, structural detail, and geometric consistency, providing an effective solution for high-quality 3D mesh generation.

</details>


### [26] [Optimal Transport-Induced Samples against Out-of-Distribution Overconfidence](https://arxiv.org/abs/2601.21320)
*Keke Tang,Ziyong Du,Xiaofei Wang,Weilong Peng,Peican Zhu,Zhihong Tian*

Main category: cs.CV

TL;DR: 本文提出了一种基于最优传输（OT）几何结构的新方法，通过在OT诱导的奇异边界附近采样构造OOD样本，并在训练中压制模型在这些区域的置信度，从而有效减轻深度神经网络对分布外（OOD）输入过度自信的问题，结果优于多种先进方法。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在遇到分布外输入时容易做出过度自信的错误预测，这在实际开放世界环境中损害了模型可靠性。现有方法难以精准刻画模型面临语义模糊区域时的行为，作者观察到OT中的奇异性标志着语义歧义的位置，因此希望利用这些几何特征提升模型对OOD数据的识别和置信度校准能力。

Method: 作者将最优传输问题设定在训练集的潜在表示与一个连续基分布之间，推导出OT诱导的奇异边界并在其邻域采样得到具有几何和语义歧义性的OOD样本（OTIS）。在训练阶段引入置信度抑制损失，对模型在这些区域的预测进行校准，促使其在结构性不确定区域输出合理置信度。

Result: 大量实验表明，该方法能显著减轻分布外过度自信的问题，在多项OOD识别任务中均超过当前主流领先方法。

Conclusion: 利用OT几何结构刻画的语义模糊区域构造OOD样本并校准模型置信度，有效提升了神经网络的开放世界可靠性和鲁棒性。

Abstract: Deep neural networks (DNNs) often produce overconfident predictions on out-of-distribution (OOD) inputs, undermining their reliability in open-world environments. Singularities in semi-discrete optimal transport (OT) mark regions of semantic ambiguity, where classifiers are particularly prone to unwarranted high-confidence predictions. Motivated by this observation, we propose a principled framework to mitigate OOD overconfidence by leveraging the geometry of OT-induced singular boundaries. Specifically, we formulate an OT problem between a continuous base distribution and the latent embeddings of training data, and identify the resulting singular boundaries. By sampling near these boundaries, we construct a class of OOD inputs, termed optimal transport-induced OOD samples (OTIS), which are geometrically grounded and inherently semantically ambiguous. During training, a confidence suppression loss is applied to OTIS to guide the model toward more calibrated predictions in structurally uncertain regions. Extensive experiments show that our method significantly alleviates OOD overconfidence and outperforms state-of-the-art methods.

</details>


### [27] [Do Pathology Foundation Models Encode Disease Progression? A Pseudotime Analysis of Visual Representations](https://arxiv.org/abs/2601.21334)
*Pritika Vig,Ren-Chin Wu,William Lotter*

Main category: cs.CV

TL;DR: 本文研究了计算病理学中视觉基础模型是否能在其表征空间中隐式捕捉连续的疾病进展过程。通过扩散拟时算法验证，不同模型对癌症进展的顺序推断均显著优于无序基线，且推断结果与少样本分类性能高度相关，并与已知的生物学规律相符。


<details>
  <summary>Details</summary>
Motivation: 虽然视觉基础模型在分类任务上表现突出，但其隐式表征是否反映了底层数据的连续动态过程尚未明确。计算病理学领域的疾病发展是连续演变的，如果模型能反映这种连续性，将更具生物学解释力与泛化能力。

Method: 借用单细胞转录组领域的扩散拟时（diffusion pseudotime）分析方法，评估基础视觉模型在表征空间中是否能将疾病状态沿着合理的进展轨迹有序排列。对4种癌症发展过程和6种模型进行比较，分析模型推断轨迹顺序与已知顺序的一致性，并探索细胞类型变化与轨迹的关系。

Result: 所有面向病理的模型均能显著还原疾病进展轨迹顺序，效果优于随机基线。其中，纯视觉模型在部分任务上准确率最高（如CRC-Serrated任务τ>0.78）。模型轨迹保真度高的同时，其在少样本分类任务上的表现也更优（Spearman相关ρ=0.92），细胞类型沿推断轨迹也有合理生物学分布。

Conclusion: 视觉基础模型可以通过静态样本隐式学习连续性过程，轨迹保真度是下游任务之外重要的表征质量考量。该方法框架可推广到其他用静态观测反映连续过程的领域。

Abstract: Vision foundation models trained on discretely sampled images achieve strong performance on classification benchmarks, yet whether their representations encode the continuous processes underlying their training data remains unclear. This question is especially pertinent in computational pathology, where we posit that models whose latent representations implicitly capture continuous disease progression may better reflect underlying biology, support more robust generalization, and enable quantitative analyses of features associated with disease transitions. Using diffusion pseudotime, a method developed to infer developmental trajectories from single-cell transcriptomics, we probe whether foundation models organize disease states along coherent progression directions in representation space. Across four cancer progressions and six models, we find that all pathology-specific models recover trajectory orderings significantly exceeding null baselines, with vision-only models achieving the highest fidelities $(τ> 0.78$ on CRC-Serrated). Model rankings by trajectory fidelity on reference diseases strongly predict few-shot classification performance on held-out diseases ($ρ= 0.92$), and exploratory analysis shows cell-type composition varies smoothly along inferred trajectories in patterns consistent with known stromal remodeling. Together, these results demonstrate that vision foundation models can implicitly learn to represent continuous processes from independent static observations, and that trajectory fidelity provides a complementary measure of representation quality beyond downstream performance. While demonstrated in pathology, this framework could be applied to other domains where continuous processes are observed through static snapshots.

</details>


### [28] [SR$^{2}$-Net: A General Plug-and-Play Model for Spectral Refinement in Hyperspectral Image Super-Resolution](https://arxiv.org/abs/2601.21338)
*Ji-Xuan He,Guohang Zhuang,Junge Bo,Tingyi Li,Chen Ling,Yanan Qiao*

Main category: cs.CV

TL;DR: 该论文提出了一种可插拔式的光谱整流超分辨网络（SR2-Net），提升高光谱图像的空间分辨率，并兼顾光谱一致性。该方法能与现有多种超分辨模型结合，提升重建质量，且计算量增加极小。


<details>
  <summary>Details</summary>
Motivation: 现有高光谱图像超分辨方法重空间信息，却常忽略不同波段间的光谱一致性，导致伪影和物理不合理。直接通过网络结构设计虽可改善，但会牺牲模型泛化性与灵活性。

Method: 作者设计了一种轻量级、即插即用的物理先验光谱整流超分辨网络（SR2-Net），无需修改底层架构即可嵌入主流HSI-SR模型。网络包含两步：（1）分层光谱-空间协同注意力模块（H-S3A）强化波段间关联；（2）流形一致性整流（MCR）模块确保重建光谱落在物理合理的流形上。此外，提出退化一致性损失，保证算法对低分辨输入具有数据一致性。

Result: 在多个数据集和多种主流HSI-SR网络上做了消融实验，新方法在空间与光谱重建质量上都有明显提升，且计算负担极小。

Conclusion: SR2-Net能够显著提升高光谱图像超分辨重建结果的物理合理性和光谱一致性，兼容性好，可为各类现有模型带来性能提升。

Abstract: HSI-SR aims to enhance spatial resolution while preserving spectrally faithful and physically plausible characteristics. Recent methods have achieved great progress by leveraging spatial correlations to enhance spatial resolution. However, these methods often neglect spectral consistency across bands, leading to spurious oscillations and physically implausible artifacts. While spectral consistency can be addressed by designing the network architecture, it results in a loss of generality and flexibility. To address this issue, we propose a lightweight plug-and-play rectifier, physically priors Spectral Rectification Super-Resolution Network (SR$^{2}$-Net), which can be attached to a wide range of HSI-SR models without modifying their architectures. SR$^{2}$-Net follows an enhance-then-rectify pipeline consisting of (i) Hierarchical Spectral-Spatial Synergy Attention (H-S$^{3}$A) to reinforce cross-band interactions and (ii) Manifold Consistency Rectification (MCR) to constrain the reconstructed spectra to a compact, physically plausible spectral manifold. In addition, we introduce a degradation-consistency loss to enforce data fidelity by encouraging the degraded SR output to match the observed low resolution input. Extensive experiments on multiple benchmarks and diverse backbones demonstrate consistent improvements in spectral fidelity and overall reconstruction quality with negligible computational overhead. Our code will be released upon publication.

</details>


### [29] [Dynamical Adapter Fusion: Constructing A Global Adapter for Pre-Trained Model-based Class-Incremental Learning](https://arxiv.org/abs/2601.21341)
*Ruiqi Liu,Boyu Diao,Zijia An,Zhulin An,Fei Wang,Yongjun Xu*

Main category: cs.CV

TL;DR: 提出了一种新的动态适配器融合（DAF）方法，有效解决了类增量学习中知识转移和灾难性遗忘问题，并在多个基准测试中取得SOTA表现。


<details>
  <summary>Details</summary>
Motivation: 传统类增量学习方法需维护大量任务专用参数，导致知识难以共享且检索成本高；而直接参数融合又容易引发知识干扰和灾难性遗忘。当前缺乏兼顾稳定性和可塑性的高效融合策略。

Method: 作者提出Dynamical Adapter Fusion (DAF)，利用PAC-Bayes理论，融合任务适配器、全局适配器和初始化参数三部分。通过对损失函数泰勒展开，动态推导最优融合系数，实现自适应平衡模型的稳定与可塑性。此外，设计了Robust Initialization策略，强化全球知识捕获。

Result: 在多个类增量学习基准（CIL benchmark）上，DAF方法展示了优越表现，超越现有主流方法，取得了最新最优（SOTA）的实验结果。

Conclusion: 动态融合方法能有效提升类别增量学习中的知识保留和新知识引入能力，对比现有方法具有更高性能和更好泛化能力，适用于实际增量学习场景。

Abstract: Class-Incremental Learning (CIL) requires models to continuously acquire new classes without forgetting previously learned ones. A dominant paradigm involves freezing a pre-trained model and training lightweight, task-specific adapters. However, maintaining task-specific parameters hinders knowledge transfer and incurs high retrieval costs, while naive parameter fusion often leads to destructive interference and catastrophic forgetting. To address these challenges, we propose Dynamical Adapter Fusion (DAF) to construct a single robust global adapter. Grounded in the PAC-Bayes theorem, we derive a fusion mechanism that explicitly integrates three components: the optimized task-specific adapter parameters, the previous global adapter parameters, and the initialization parameters. We utilize the Taylor expansion of the loss function to derive the optimal fusion coefficients, dynamically achieving the best balance between stability and plasticity. Furthermore, we propose a Robust Initialization strategy to effectively capture global knowledge patterns. Experiments on multiple CIL benchmarks demonstrate that DAF achieves state-of-the-art (SOTA) performance.

</details>


### [30] [Semantic-Guided Dynamic Sparsification for Pre-Trained Model-based Class-Incremental Learning](https://arxiv.org/abs/2601.21345)
*Ruiqi Liu,Boyu Diao,Zijia An,Runjie Shao,Zhulin An,Fei Wang,Yongjun Xu*

Main category: cs.CV

TL;DR: 该论文提出了一种用于类增量学习的新方法，即语义引导的动态稀疏化（SGDS），能够在不牺牲模型可塑性的前提下，有效减少新旧类别间的干扰，并取得了最先进的实验效果。


<details>
  <summary>Details</summary>
Motivation: 现有的类增量学习方法常通过冻结预训练模型和使用参数正交的轻量级适配器来防止不同任务的相互影响，但这种对参数空间的硬性约束会损害模型对新知识的学习能力（可塑性），因此作者希望在提升模型可塑性的同时保证抗干扰性。

Method: 提出SGDS方法，通过稀疏化激活空间并引入语义引导，将相似类别的激活投射到紧凑、共享的子空间，而不相似类别则分配到互不重叠的子空间。该方法通过激活空间的灵活建模来代替参数空间的刚性约束，从而改善知识迁移和任务间的区分性。

Result: 在多个基准数据集上进行实验，SGDS方法实现了当前最优的类增量学习性能，比现有方法在有效降低知识遗忘和任务干扰的同时，具有更好的灵活性和扩展性。

Conclusion: SGDS通过在激活空间动态稀疏分配子空间，成功平衡了知识迁移与抗干扰性，为类增量学习提供了更有效和灵活的解决方案，优于传统的参数正交约束方法。

Abstract: Class-Incremental Learning (CIL) requires a model to continually learn new classes without forgetting old ones. A common and efficient solution freezes a pre-trained model and employs lightweight adapters, whose parameters are often forced to be orthogonal to prevent inter-task interference. However, we argue that this parameter-constraining method is detrimental to plasticity. To this end, we propose Semantic-Guided Dynamic Sparsification (SGDS), a novel method that proactively guides the activation space by governing the orientation and rank of its subspaces through targeted sparsification. Specifically, SGDS promotes knowledge transfer by encouraging similar classes to share a compact activation subspace, while simultaneously preventing interference by assigning non-overlapping activation subspaces to dissimilar classes. By sculpting class-specific sparse subspaces in the activation space, SGDS effectively mitigates interference without imposing rigid constraints on the parameter space. Extensive experiments on various benchmark datasets demonstrate the state-of-the-art performance of SGDS.

</details>


### [31] [Towards Geometry-Aware and Motion-Guided Video Human Mesh Recovery](https://arxiv.org/abs/2601.21376)
*Hongjun Chen,Huan Zheng,Wencheng Han,Jianbing Shen*

Main category: cs.CV

TL;DR: 论文提出了HMRMamba，一种利用结构化状态空间模型（SSM）的视频三维人体网格恢复新方法，显著提升了恢复效果和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的视频三维人体网格恢复方法依赖不完美的中间3D姿态锚点，且难以建模复杂的时空动态，导致恢复结果不真实。本文旨在解决这些架构性难题。

Method: 方法包括两大核心创新：1）几何感知提升模块，引入双扫描Mamba架构，将图像特征中的几何线索直接用于2D到3D姿态估计，获得更可靠的3D姿态锚点；2）运动引导重建网络，基于该锚点显式建模时序运动模式，提升网格重建在遮挡和运动模糊场景下的连续性和鲁棒性。

Result: 在3DPW、MPI-INF-3DHP和Human3.6M等主流基准测试集上，HMRMamba在精度、时序一致性和计算效率方面均超过现有最优方法，取得新的SOTA表现。

Conclusion: HMRMamba有效解决了传统视频三维人体网格恢复中的架构性瓶颈，显著增强了人体恢复的物理合理性和稳定性，为领域带来了新的进展。

Abstract: Existing video-based 3D Human Mesh Recovery (HMR) methods often produce physically implausible results, stemming from their reliance on flawed intermediate 3D pose anchors and their inability to effectively model complex spatiotemporal dynamics. To overcome these deep-rooted architectural problems, we introduce HMRMamba, a new paradigm for HMR that pioneers the use of Structured State Space Models (SSMs) for their efficiency and long-range modeling prowess. Our framework is distinguished by two core contributions. First, the Geometry-Aware Lifting Module, featuring a novel dual-scan Mamba architecture, creates a robust foundation for reconstruction. It directly grounds the 2D-to-3D pose lifting process with geometric cues from image features, producing a highly reliable 3D pose sequence that serves as a stable anchor. Second, the Motion-guided Reconstruction Network leverages this anchor to explicitly process kinematic patterns over time. By injecting this crucial temporal awareness, it significantly enhances the final mesh's coherence and robustness, particularly under occlusion and motion blur. Comprehensive evaluations on 3DPW, MPI-INF-3DHP, and Human3.6M benchmarks confirm that HMRMamba sets a new state-of-the-art, outperforming existing methods in both reconstruction accuracy and temporal consistency while offering superior computational efficiency.

</details>


### [32] [Rectifying Geometry-Induced Similarity Distortions for Real-World Aerial-Ground Person Re-Identification](https://arxiv.org/abs/2601.21405)
*Kailash A. Hambarde,Hugo Proença*

Main category: cs.CV

TL;DR: 本文提出了一种新方法来解决无人机与地面摄像头之间极端视角与距离差异导致的人体再识别（AG-ReID）难题，通过直接纠正注意力机制中的关联空间，提升了跨视角识别的准确性。


<details>
  <summary>Details</summary>
Motivation: AG-ReID面临极端视角与距离差异，导致几何畸变严重，从而使传统的基于特征相似度的注意力机制无法可靠地工作。这一挑战尚未被现有方法充分解决。

Method: 作者提出了几何感知的Query-Key变换（GIQT）模块，它直接调整注意力机制中的query-key相似性计算，使其能够适应相机几何带来的非均匀畸变。此外，作者还引入了基于几何条件的全局prompt生成机制，用于提供视角自适应的全局表征先验。

Result: 在四个主流的空地跨视角人体再识别数据集上，所提方法相比现有方法在极端及新颖视角条件下表现出更强的鲁棒性，并且计算开销极小。

Conclusion: 该方法有效提升了极端视角与距离条件下AG-ReID的识别鲁棒性，在几乎不增加计算负担的前提下，显著优于当前主流方法。

Abstract: Aerial-ground person re-identification (AG-ReID) is fundamentally challenged by extreme viewpoint and distance discrepancies between aerial and ground cameras, which induce severe geometric distortions and invalidate the assumption of a shared similarity space across views. Existing methods primarily rely on geometry-aware feature learning or appearance-conditioned prompting, while implicitly assuming that the geometry-invariant dot-product similarity used in attention mechanisms remains reliable under large viewpoint and scale variations. We argue that this assumption does not hold. Extreme camera geometry systematically distorts the query-key similarity space and degrades attention-based matching, even when feature representations are partially aligned.
  To address this issue, we introduce Geometry-Induced Query-Key Transformation (GIQT), a lightweight low-rank module that explicitly rectifies the similarity space by conditioning query-key interactions on camera geometry. Rather than modifying feature representations or the attention formulation itself, GIQT adapts the similarity computation to compensate for dominant geometry-induced anisotropic distortions. Building on this local similarity rectification, we further incorporate a geometry-conditioned prompt generation mechanism that provides global, view-adaptive representation priors derived directly from camera geometry.
  Experiments on four aerial-ground person re-identification benchmarks demonstrate that the proposed framework consistently improves robustness under extreme and previously unseen geometric conditions, while introducing minimal computational overhead compared to state-of-the-art methods.

</details>


### [33] [Generation Enhances Understanding in Unified Multimodal Models via Multi-Representation Generation](https://arxiv.org/abs/2601.21406)
*Zihan Su,Hongyang Wei,Kangrui Cen,Yong Wang,Guanhua Chen,Chun Yuan,Xiangxiang Chu*

Main category: cs.CV

TL;DR: 论文提出了一种统一多模态模型（UMMs）的后训练方法UniMRG，通过引入多种生成辅助任务，显著提升模型的理解与生成能力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型更多关注利用理解提升生成，但“反向”即通过生成提升理解的方法较少。本研究希望填补该空白，让生成与理解形成良性循环。

Method: 提出架构无关的UniMRG后训练方法，让模型不仅完成常规视觉理解任务，还需生成输入图像的像素重建、深度图和分割图等多种内在表示，从而加强模型对外观、空间和结构的综合把握。

Result: 在多种主流UMMs架构上的大量实验证明，UniMRG能显著提升模型的细粒度感知能力，减少幻觉现象，加强空间理解，并同步提升生成质量。

Conclusion: 通过集成多种辅助生成任务，UniMRG打通了视觉理解与生成间的正向反馈通路，推动了多模态模型理解和生成能力的协同进步。

Abstract: Unified Multimodal Models (UMMs) integrate both visual understanding and generation within a single framework. Their ultimate aspiration is to create a cycle where understanding and generation mutually reinforce each other. While recent post-training methods have successfully leveraged understanding to enhance generation, the reverse direction of utilizing generation to improve understanding remains largely unexplored. In this work, we propose UniMRG (Unified Multi-Representation Generation), a simple yet effective architecture-agnostic post-training method. UniMRG enhances the understanding capabilities of UMMs by incorporating auxiliary generation tasks. Specifically, we train UMMs to generate multiple intrinsic representations of input images, namely pixel (reconstruction), depth (geometry), and segmentation (structure), alongside standard visual understanding objectives. By synthesizing these diverse representations, UMMs capture complementary information regarding appearance, spatial relations, and structural layout. Consequently, UMMs develop a deeper and more comprehensive understanding of visual inputs. Extensive experiments across diverse UMM architectures demonstrate that our method notably enhances fine-grained perception, reduces hallucinations, and improves spatial understanding, while simultaneously boosting generation capabilities.

</details>


### [34] [Causal World Modeling for Robot Control](https://arxiv.org/abs/2601.21998)
*Lin Li,Qihang Zhang,Yiming Luo,Shuai Yang,Ruilin Wang,Fei Han,Mingrui Yu,Zelin Gao,Nan Xue,Xing Zhu,Yujun Shen,Yinghao Xu*

Main category: cs.CV

TL;DR: 该论文提出LingBot-VA框架，将视频世界建模与视觉-语言预训练结合，为机器人学习提供了新基础。模型同时学习视频帧预测和策略执行，通过创新架构在多个基准和现实场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 视频世界建模可以通过因果关系理解和想象未来，有助于机器人更好地感知并预测环境变化；但该能力尚未与现有视觉-语言预训练有机结合，需要开发新方法增强机器人学习能力。

Method: 提出LingBot-VA自动回归扩散框架，具三个核心设计：(1) 共享视觉与动作的潜在空间，由Mixture-of-Transformers架构驱动；(2) 闭环回滚机制，实时获取环境反馈和真实观测；(3) 异步推理流程，实现高效的动作预测和执行。

Result: 在仿真基准和现实场景中，LingBot-VA在长时序操控、后训练数据效率及新环境泛化性方面均展现出显著优势。

Conclusion: 视频世界建模与视觉-语言预训练的结合极大提升了机器人学习能力，所提方法具有效率高、泛化强等优点，有望推动机器人自主智能的发展。

Abstract: This work highlights that video world modeling, alongside vision-language pre-training, establishes a fresh and independent foundation for robot learning. Intuitively, video world models provide the ability to imagine the near future by understanding the causality between actions and visual dynamics. Inspired by this, we introduce LingBot-VA, an autoregressive diffusion framework that learns frame prediction and policy execution simultaneously. Our model features three carefully crafted designs: (1) a shared latent space, integrating vision and action tokens, driven by a Mixture-of-Transformers (MoT) architecture, (2) a closed-loop rollout mechanism, allowing for ongoing acquisition of environmental feedback with ground-truth observations, (3) an asynchronous inference pipeline, parallelizing action prediction and motor execution to support efficient control. We evaluate our model on both simulation benchmarks and real-world scenarios, where it shows significant promise in long-horizon manipulation, data efficiency in post-training, and strong generalizability to novel configurations. The code and model are made publicly available to facilitate the community.

</details>


### [35] [MPF-Net: Exposing High-Fidelity AI-Generated Video Forgeries via Hierarchical Manifold Deviation and Micro-Temporal Fluctuations](https://arxiv.org/abs/2601.21408)
*Xinan He,Kaiqing Lin,Yue Zhou,Jiaming Zhong,Wei Ye,Wenhui Yi,Bing Fan,Feng Ding,Haodong Li,Bo Cao,Bin Li*

Main category: cs.CV

TL;DR: 提出了一种利用流形投影波动（MPF）现象侦测高保真AI生成视频真伪的分层双路径框架。


<details>
  <summary>Details</summary>
Motivation: 尽管AI生成视频在视觉质量上已达到极高水平，但其与真实视频之间仍存在不可忽视、可追踪的特征差异，尤其在像素层面与物理拍摄间存在本质区别。本研究旨在寻找并利用这些特征高效检测AI生成的视频内容。

Method: 框架分为两步：1）静态流形偏差分支——依靠大规模视觉基础模型（VFMs）捕捉空间上的离流形异常或物理冲突；2）微时域波动分支——针对已通过空间检测、表面上极为真实的视频，进一步细致挖掘相邻帧间的结构化像素波动（即MPF），作为揭示造假视频的补充证据。

Result: 框架能够有效分辨真实高质量视频和领先的AI合成视频，无论造假迹象是宏观的空间偏差还是微观的像素级指纹，均能予以曝光。

Conclusion: 通过揭示与利用AI合成视频在时空域的深层统计结构差异，提出的方法为检测高保真视频造假提供了有力技术手段，在应对日益精细的深度合成内容检测挑战上具有前瞻意义。

Abstract: With the rapid advancement of video generation models such as Veo and Wan, the visual quality of synthetic content has reached a level where macro-level semantic errors and temporal inconsistencies are no longer prominent. However, this does not imply that the distinction between real and cutting-edge high-fidelity fake is untraceable. We argue that AI-generated videos are essentially products of a manifold-fitting process rather than a physical recording. Consequently, the pixel composition logic of consecutive adjacent frames residual in AI videos exhibits a structured and homogenous characteristic. We term this phenomenon `Manifold Projection Fluctuations' (MPF). Driven by this insight, we propose a hierarchical dual-path framework that operates as a sequential filtering process. The first, the Static Manifold Deviation Branch, leverages the refined perceptual boundaries of Large-Scale Vision Foundation Models (VFMs) to capture residual spatial anomalies or physical violations that deviate from the natural real-world manifold (off-manifold). For the remaining high-fidelity videos that successfully reside on-manifold and evade spatial detection, we introduce the Micro-Temporal Fluctuation Branch as a secondary, fine-grained filter. By analyzing the structured MPF that persists even in visually perfect sequences, our framework ensures that forgeries are exposed regardless of whether they manifest as global real-world manifold deviations or subtle computational fingerprints.

</details>


### [36] [From Implicit Ambiguity to Explicit Solidity: Diagnosing Interior Geometric Degradation in Neural Radiance Fields for Dense 3D Scene Understanding](https://arxiv.org/abs/2601.21421)
*Jiangsan Zhao,Jakob Geipel,Kryzysztof Kusnierek*

Main category: cs.CV

TL;DR: 本文分析了NeRF在密集自遮挡场景下的缺陷，提出了一种结合SfM特征和稀疏体素光栅化的新方法，有效提升了3D重建的准确性。


<details>
  <summary>Details</summary>
Motivation: 随着NeRF在多视图3D重建中的广泛应用，其在密集、强自遮挡场景中定量分析的可靠性却未被充分验证。研究动机在于揭示NeRF隐式密度表征在复杂场景下的核心不足，寻找更稳健的3D重建解决方案。

Method: 本文首先在合成数据上展示NeRF在可见性受限环境下容易出现“内部几何退化”问题。随后，作者提出显式几何+稀疏体素光栅化（SVRaster）方法：利用SfM提取几何信息，将2D实例掩码投影到3D体素网格上，并通过递归分割实现几何隔离，保证物体的实体连贯性。

Result: 实验证明，主流基于掩码监督的NeRF在密集场景中的实例恢复率约为89%，而提出的SVRaster方法则提升至95.8%；在监督信号退化时，显式几何方法依然比隐式方法多恢复43%的实例。

Conclusion: 显式几何先验是高自遮挡密集3D场景定量分析的前提。单纯依赖NeRF等隐式表征在结构复杂环境下易出错，需引入结构化空间先验与显式重建流水线以提升分析可靠性。

Abstract: Neural Radiance Fields (NeRFs) have emerged as a powerful paradigm for multi-view reconstruction, complementing classical photogrammetric pipelines based on Structure-from-Motion (SfM) and Multi-View Stereo (MVS). However, their reliability for quantitative 3D analysis in dense, self-occluding scenes remains poorly understood. In this study, we identify a fundamental failure mode of implicit density fields under heavy occlusion, which we term Interior Geometric Degradation (IGD). We show that transmittance-based volumetric optimization satisfies photometric supervision by reconstructing hollow or fragmented structures rather than solid interiors, leading to systematic instance undercounting. Through controlled experiments on synthetic datasets with increasing occlusion, we demonstrate that state-of-the-art mask-supervised NeRFs saturate at approximately 89% instance recovery in dense scenes, despite improved surface coherence and mask quality. To overcome this limitation, we introduce an explicit geometric pipeline based on Sparse Voxel Rasterization (SVRaster), initialized from SfM feature geometry. By projecting 2D instance masks onto an explicit voxel grid and enforcing geometric separation via recursive splitting, our approach preserves physical solidity and achieves a 95.8% recovery rate in dense clusters. A sensitivity analysis using degraded segmentation masks further shows that explicit SfM-based geometry is substantially more robust to supervision failure, recovering 43% more instances than implicit baselines. These results demonstrate that explicit geometric priors are a prerequisite for reliable quantitative analysis in highly self-occluding 3D scenes.

</details>


### [37] [MultiModal Fine-tuning with Synthetic Captions](https://arxiv.org/abs/2601.21426)
*Shohei Enomoto,Shin'ya Yamaguchi*

Main category: cs.CV

TL;DR: 本文解决了深度神经网络中预训练与微调阶段模态不一致的问题，提出用多模态大语言模型（MLLM）为单模态数据合成图片描述，实现多模态微调，并通过对比损失和新的推理方式提升图像分类效果。


<details>
  <summary>Details</summary>
Motivation: 现有预训练注重多模态（如图像+文本）已显著增强视觉理解能力，但下游任务常用的微调仍以单模态为主，无法充分利用预训练获得的多模态表征，阻碍了模型性能最大化。

Method: 作者利用多模态大语言模型为原本只有图像标签的数据生成与类别、领域上下文相关的高质量文本描述，将单模态数据转变为多模态。同时，提出带有类别聚类约束的对比损失函数，以及通过多条描述平均文本嵌入的推理方法，提高分类精度。

Result: 在13个图像分类基准测试上，本文方法均优于常规基线，特别在小样本学习场景下表现突出，显著提升了模型利用预训练知识的能力。

Conclusion: 本研究提出了一种创新的数据集增强与多模态微调范式，有效弥合了多模态预训练与单模态微调之间的落差，为图像分类等任务带来更优表现。

Abstract: In this paper, we address a fundamental gap between pre-training and fine-tuning of deep neural networks: while pre-training has shifted from unimodal to multimodal learning with enhanced visual understanding, fine-tuning predominantly remains unimodal, limiting the benefits of rich pre-trained representations. To bridge this gap, we propose a novel approach that transforms unimodal datasets into multimodal ones using Multimodal Large Language Models (MLLMs) to generate synthetic image captions for fine-tuning models with a multimodal objective. Our method employs carefully designed prompts incorporating class labels and domain context to produce high-quality captions tailored for classification tasks. Furthermore, we introduce a supervised contrastive loss function that explicitly encourages clustering of same-class representations during fine-tuning, along with a new inference technique that leverages class-averaged text embeddings from multiple synthetic captions per image. Extensive experiments across 13 image classification benchmarks demonstrate that our approach outperforms baseline methods, with particularly significant improvements in few-shot learning scenarios. Our work establishes a new paradigm for dataset enhancement that effectively bridges the gap between multimodal pre-training and fine-tuning. Our code is available at https://github.com/s-enmt/MMFT.

</details>


### [38] [Spava: Accelerating Long-Video Understanding via Sequence-Parallelism-aware Approximate Attention](https://arxiv.org/abs/2601.21444)
*Yuxiang Huang,Mingye Li,Xu Han,Chaojun Xiao,Weilin Zhao,Ao Sun,Ziqi Yuan,Hao Zhou,Fandong Meng,Zhiyuan Liu*

Main category: cs.CV

TL;DR: 本文提出Spava序列并行框架，通过跨多GPU的近似注意力优化，显著加速长视频推理，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型在处理长视频时，由于前置阶段高密度计算导致推理效率低下，而传统的加速方法（压缩视觉特征或单卡稀疏注意力）要么加速有限，要么影响性能，难以扩展到更长更复杂的视频任务。

Method: 提出Spava框架，将近似注意力计算分布到多个GPU，减少计算量，提高并行效率，无需特征压缩，同时通过系统级优化如负载均衡和融合前向传播进一步提升效率。

Result: Spava在推理速度上相较于FlashAttn、ZigZagRing和APB分别提升12.72倍、1.70倍和1.18倍，且任务性能无明显下降。

Conclusion: Spava有效突破了长视频推理效率瓶颈，实现多GPU高效并行推理，为多模态大模型处理更长更复杂视频任务提供了新途径。

Abstract: The efficiency of long-video inference remains a critical bottleneck, mainly due to the dense computation in the prefill stage of Large Multimodal Models (LMMs). Existing methods either compress visual embeddings or apply sparse attention on a single GPU, yielding limited acceleration or degraded performance and restricting LMMs from handling longer, more complex videos. To overcome these issues, we propose Spava, a sequence-parallel framework with optimized attention that accelerates long-video inference across multiple GPUs. By distributing approximate attention, Spava reduces computation and increases parallelism, enabling efficient processing of more visual embeddings without compression and thereby improving task performance. System-level optimizations, such as load balancing and fused forward passes, further unleash the potential of Spava, delivering speedups of 12.72x, 1.70x, and 1.18x over FlashAttn, ZigZagRing, and APB, without notable performance loss. Code available at https://github.com/thunlp/APB

</details>


### [39] [Variance & Greediness: A comparative study of metric-learning losses](https://arxiv.org/abs/2601.21450)
*Donghuo Zeng,Hao Niu,Zhi Li,Masato Taya*

Main category: cs.CV

TL;DR: 本文提出了针对度量学习损失函数（如Contrastive、Triplet、InfoNCE等）效果的诊断框架，并分析了各主流损失在图像检索任务中的几何表现与优化动态。


<details>
  <summary>Details</summary>
Motivation: 度量学习是检索任务的核心，但不同损失对嵌入空间结构和训练过程的具体影响仍不清楚，故需要系统分析和指导。

Method: 提出VARIANCE（类内/类间方差）和GREEDINESS（激活比例和梯度范数）两个分析指标，对7种典型损失函数在5个图像检索数据集上进行比较。

Result: Triplet和SCL损失能保持更高的类内方差和更明显的类间间隔，适用于区分细粒度类别；Contrastive和InfoNCE能加速收敛但可能过分简化类结构；N-pair虽然平均分开类别距离大，但类间间隔不均匀。

Conclusion: 在关注多样性和难样本时优选Triplet/SCL，在追求快速聚类时用Contrastive/InfoNCE。并揭示了效率-粒度的权衡，为损失函数的实际选用提供了参考。

Abstract: Metric learning is central to retrieval, yet its effects on embedding geometry and optimization dynamics are not well understood. We introduce a diagnostic framework, VARIANCE (intra-/inter-class variance) and GREEDINESS (active ratio and gradient norms), to compare seven representative losses, i.e., Contrastive, Triplet, N-pair, InfoNCE, ArcFace, SCL, and CCL, across five image-retrieval datasets. Our analysis reveals that Triplet and SCL preserve higher within-class variance and clearer inter-class margins, leading to stronger top-1 retrieval in fine-grained settings. In contrast, Contrastive and InfoNCE compact embeddings are achieved quickly through many small updates, accelerating convergence but potentially oversimplifying class structures. N-pair achieves a large mean separation but with uneven spacing. These insights reveal a form of efficiency-granularity trade-off and provide practical guidance: prefer Triplet/SCL when diversity preservation and hard-sample discrimination are critical, and Contrastive/InfoNCE when faster embedding compaction is desired.

</details>


### [40] [Mining Forgery Traces from Reconstruction Error: A Weakly Supervised Framework for Multimodal Deepfake Temporal Localization](https://arxiv.org/abs/2601.21458)
*Midou Guo,Qilin Yin,Wei Lu,Xiangyang Luo,Rui Yang*

Main category: cs.CV

TL;DR: 提出了一种弱监督的时序伪造定位方法RT-DeepLoc，通过重建误差检测Deepfake视频中被篡改的局部帧，实现高效且细粒度的伪造识别。


<details>
  <summary>Details</summary>
Motivation: 随着Deepfake技术发展，伪造已从整体性伪造演变为更加隐蔽和间歇性的局部篡改。手动逐帧标注代价极高，因此亟需仅依赖视频级标签进行弱监督识别的方法。

Method: 方法采用仅在真实数据上训练的Mask Autoencoder（MAE），通过重建误差发现伪造片段。同时，提出不对称的帧内对比损失（AICL），利用重建提示增强真实特征的区分性，提升模型对局部伪造的定位能力和对新型伪造的泛化。

Result: 在包含LAV-DF在内的大规模数据集上进行实验，RT-DeepLoc在弱监督时序伪造定位任务上实现了当前最优表现。

Conclusion: 基于重建误差与创新损失设计的弱监督深度伪造定位方法能够有效弥补帧级标注缺失，实现高效、泛化性强的局部时序伪造检测。

Abstract: Modern deepfakes have evolved into localized and intermittent manipulations that require fine-grained temporal localization. The prohibitive cost of frame-level annotation makes weakly supervised methods a practical necessity, which rely only on video-level labels. To this end, we propose Reconstruction-based Temporal Deepfake Localization (RT-DeepLoc), a weakly supervised temporal forgery localization framework that identifies forgeries via reconstruction errors. Our framework uses a Masked Autoencoder (MAE) trained exclusively on authentic data to learn its intrinsic spatiotemporal patterns; this allows the model to produce significant reconstruction discrepancies for forged segments, effectively providing the missing fine-grained cues for localization. To robustly leverage these indicators, we introduce a novel Asymmetric Intra-video Contrastive Loss (AICL). By focusing on the compactness of authentic features guided by these reconstruction cues, AICL establishes a stable decision boundary that enhances local discrimination while preserving generalization to unseen forgeries. Extensive experiments on large-scale datasets, including LAV-DF, demonstrate that RT-DeepLoc achieves state-of-the-art performance in weakly-supervised temporal forgery localization.

</details>


### [41] [Hypernetwork-Based Adaptive Aggregation for Multimodal Multiple-Instance Learning in Predicting Coronary Calcium Debulking](https://arxiv.org/abs/2601.21479)
*Kaito Shiku,Ichika Seo,Tetsuya Matoba,Rissei Hino,Yasuhiro Nakano,Ryoma Bise*

Main category: cs.CV

TL;DR: 本文首次尝试利用CT影像估算冠状动脉钙化去块（去除）操作的必要性，并提出了一个基于超网络、适应性聚合Transformer的新方法，在临床数据集上的实验结果有效。


<details>
  <summary>Details</summary>
Motivation: 冠状动脉钙化会影响介入治疗的效果，医生需根据患者情况决定是否需要去块操作。现有方法缺乏针对CT图片自动辅助判定去块必要性的工具。本文旨在解决这一实际临床需求，提高决策效率及准确性。

Method: 作者将去块需求判定任务建模为多实例学习（MIL）问题，并提出了一种基于超网络的适应性聚合Transformer方法（HyperAdAgFormer）。该方法利用患者的表格数据（如基础病情指标），通过超网络自适应调整影像特征的聚合方式，从而更精准地反映个体化决策依据。

Result: 在真实临床数据集上，HyperAdAgFormer模型实现了有效的去块需求判定，实验结果优于传统方法，证明了方法的有效性和优势。

Conclusion: HyperAdAgFormer方法为基于CT影像及患者表格数据自动判断去块必要性提供了一种有效工具，有望辅助医生做出更精准、个性化的临床决策。

Abstract: In this paper, we present the first attempt to estimate the necessity of debulking coronary artery calcifications from computed tomography (CT) images. We formulate this task as a Multiple-instance Learning (MIL) problem. The difficulty of this task lies in that physicians adjust their focus and decision criteria for device usage according to tabular data representing each patient's condition. To address this issue, we propose a hypernetwork-based adaptive aggregation transformer (HyperAdAgFormer), which adaptively modifies the feature aggregation strategy for each patient based on tabular data through a hypernetwork. The experiments using the clinical dataset demonstrated the effectiveness of HyperAdAgFormer. The code is publicly available at https://github.com/Shiku-Kaito/HyperAdAgFormer.

</details>


### [42] [SimGraph: A Unified Framework for Scene Graph-Based Image Generation and Editing](https://arxiv.org/abs/2601.21498)
*Thanh-Nhan Vo,Trong-Thuan Nguyen,Tam V. Nguyen,Minh-Triet Tran*

Main category: cs.CV

TL;DR: 本文提出了SimGraph, 一个将场景图应用于图像生成与编辑的统一框架，实现了对图像中对象关系与空间布局的精准控制，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有生成式AI在图像生成和编辑方面通常分开处理，导致空间一致性和语义连贯性难以保证，且缺乏对对象关系及空间结构的有序控制。场景图能以结构化方式表述对象及其关系，有望解决上述问题。

Method: 提出SimGraph框架，将基于Token的生成和基于扩散的编辑二者结合，通过场景图驱动，使模型能够在生成和编辑时一致地控制对象交互、布局和空间信息。

Result: 大量实验显示，该方法在图像生成与编辑的一致性和质量上均优于当前最先进的相关方法。

Conclusion: SimGraph为图像生成和编辑提供了精细且统一的控制方式，提升了空间和语义的一致性，为生成式AI领域带来了新的进展。

Abstract: Recent advancements in Generative Artificial Intelligence (GenAI) have significantly enhanced the capabilities of both image generation and editing. However, current approaches often treat these tasks separately, leading to inefficiencies and challenges in maintaining spatial consistency and semantic coherence between generated content and edits. Moreover, a major obstacle is the lack of structured control over object relationships and spatial arrangements. Scene graph-based methods, which represent objects and their interrelationships in a structured format, offer a solution by providing greater control over composition and interactions in both image generation and editing. To address this, we introduce SimGraph, a unified framework that integrates scene graph-based image generation and editing, enabling precise control over object interactions, layouts, and spatial coherence. In particular, our framework integrates token-based generation and diffusion-based editing within a single scene graph-driven model, ensuring high-quality and consistent results. Through extensive experiments, we empirically demonstrate that our approach outperforms existing state-of-the-art methods.

</details>


### [43] [HERS: Hidden-Pattern Expert Learning for Risk-Specific Vehicle Damage Adaptation in Diffusion Models](https://arxiv.org/abs/2601.21517)
*Teerapong Panboonyuen*

Main category: cs.CV

TL;DR: 本文提出了一种名为HERS的新框架，通过对扩散模型的专家化微调，实现对车辆损伤图像生成的高保真、可控和领域对齐，有效提升了合成图像在文本一致性和用户偏好上的表现。


<details>
  <summary>Details</summary>
Motivation: 随着文本生成图像（T2I）扩散模型的发展，越来越真实的车辆损伤合成图像可被生成，这对车险自动化处理造成了潜在的欺诈和数据真伪难辨的风险，因此迫切需要提升合成数据的可靠性和可区分性。

Method: 作者提出HERS框架，通过专家学习对基础扩散模型进行领域特化微调，无需人工标注，利用大语言模型和T2I管道自动生成的自监督图文对来训练针对不同损伤类型的专家模型，最后集成为多损伤统一模型。

Result: 在四种扩散模型上评估，HERS均实现了较基线模型5.5%的文本一致性提升和2.3%的人类偏好提升。

Conclusion: HERS在提升合成图像性能的同时，也揭示了相关技术在防欺诈、审计及安全部署等方面的重要意义，强调在高风险领域应用生成模型必须确保生成结果的可信度和可追溯性。

Abstract: Recent advances in text-to-image (T2I) diffusion models have enabled increasingly realistic synthesis of vehicle damage, raising concerns about their reliability in automated insurance workflows. The ability to generate crash-like imagery challenges the boundary between authentic and synthetic data, introducing new risks of misuse in fraud or claim manipulation. To address these issues, we propose HERS (Hidden-Pattern Expert Learning for Risk-Specific Damage Adaptation), a framework designed to improve fidelity, controllability, and domain alignment of diffusion-generated damage images. HERS fine-tunes a base diffusion model via domain-specific expert adaptation without requiring manual annotation. Using self-supervised image-text pairs automatically generated by a large language model and T2I pipeline, HERS models each damage category, such as dents, scratches, broken lights, or cracked paint, as a separate expert. These experts are later integrated into a unified multi-damage model that balances specialization with generalization. We evaluate HERS across four diffusion backbones and observe consistent improvements: plus 5.5 percent in text faithfulness and plus 2.3 percent in human preference ratings compared to baselines. Beyond image fidelity, we discuss implications for fraud detection, auditability, and safe deployment of generative models in high-stakes domains. Our findings highlight both the opportunities and risks of domain-specific diffusion, underscoring the importance of trustworthy generation in safety-critical applications such as auto insurance.

</details>


### [44] [Vision KAN: Towards an Attention-Free Backbone for Vision with Kolmogorov-Arnold Networks](https://arxiv.org/abs/2601.21541)
*Zhuoqin Yang,Jiansong Zhang,Xiaoling Luo,Xu Wu,Zheng Lu,Linlin Shen*

Main category: cs.CV

TL;DR: 本文提出了一种无需注意力机制的新型视觉骨干网络ViK，核心基于Kolmogorov-Arnold Networks，通过独特的token混合策略，兼顾局部非线性建模和全局信息传播。方法在ImageNet测试上表现优良且计算复杂度为线性。


<details>
  <summary>Details</summary>
Motivation: 传统注意力机制虽能有效建模长依赖关系，但其二次复杂度和可解释性差，严重影响扩展和应用。因此需要探索无需注意力的新方案，寻求兼具效率与表现力的替代模型。

Method: ViK基于Kolmogorov-Arnold Networks设计，以MultiPatch-RBFKAN为核心。方法包括：1）使用RBF-KAN对patch进行非线性变换；2）轴向可分离混合提升局部信息传播效率；3）低秩全局映射捕捉全局依赖。同时采用patch分组和轻量操作，降低高分辨率特征下的计算压力，恢复跨patch关系。

Result: 在ImageNet-1K数据集实验显示，ViK模型取得了有竞争力的准确率，并兼具线性复杂度，表现优异。

Conclusion: 基于KAN的token混合是一种高效且理论扎实的注意力替代方案，ViK为视觉主干网络提供了新的设计方向。

Abstract: Attention mechanisms have become a key module in modern vision backbones due to their ability to model long-range dependencies. However, their quadratic complexity in sequence length and the difficulty of interpreting attention weights limit both scalability and clarity. Recent attention-free architectures demonstrate that strong performance can be achieved without pairwise attention, motivating the search for alternatives. In this work, we introduce Vision KAN (ViK), an attention-free backbone inspired by the Kolmogorov-Arnold Networks. At its core lies MultiPatch-RBFKAN, a unified token mixer that combines (a) patch-wise nonlinear transform with Radial Basis Function-based KANs, (b) axis-wise separable mixing for efficient local propagation, and (c) low-rank global mapping for long-range interaction. Employing as a drop-in replacement for attention modules, this formulation tackles the prohibitive cost of full KANs on high-resolution features by adopting a patch-wise grouping strategy with lightweight operators to restore cross-patch dependencies. Experiments on ImageNet-1K show that ViK achieves competitive accuracy with linear complexity, demonstrating the potential of KAN-based token mixing as an efficient and theoretically grounded alternative to attention.

</details>


### [45] [Bi-Anchor Interpolation Solver for Accelerating Generative Modeling](https://arxiv.org/abs/2601.21542)
*Hongxu Chen,Hongxiang Li,Zhen Wang,Long Chen*

Main category: cs.CV

TL;DR: 本论文提出了一种名为Bi-Anchor Interpolation Solver（BA-solver）的新方法，用于加速Flow Matching（FM）模型生成，同时保持高保真度并降低训练和计算成本。


<details>
  <summary>Details</summary>
Motivation: FM模型虽生成质量高，但高度依赖ODE的迭代求解，导致生成过程缓慢。现有训练自由/不自由的方法不是生成效果下降就是训练成本过高且不通用，因此亟需一个兼具高效、低成本和通用性的生成方法。

Method: BA-solver方法由两个部分组成：（1）引入轻量级SideNet（背骨网络的1-2%规模），学习同时近似历史和未来的速度信息（双向时序感知），无需对主网络再训练；（2）双锚点速度积分，利用SideNet和主网络提供的‘锚点’高效近似中间速度，实现大步长积分加速推理。整个方案与主干网络兼容，便于无缝集成。

Result: 在ImageNet-256^2数据集上，BA-solver只需10步推理（NFEs）即可达到传统Euler方法100步的图像生成质量，5步时依然保持很高保真度，训练成本极低。实验证明该方法具备很强的高效性和生成质量。

Conclusion: BA-solver不仅显著加速了FM模型的生成过程，还兼具高保真度、低额外训练成本与良好通用性，可无缝融入现有生成式模型管线，支持下游任务如图像编辑。

Abstract: Flow Matching (FM) models have emerged as a leading paradigm for high-fidelity synthesis. However, their reliance on iterative Ordinary Differential Equation (ODE) solving creates a significant latency bottleneck. Existing solutions face a dichotomy: training-free solvers suffer from significant performance degradation at low Neural Function Evaluations (NFEs), while training-based one- or few-steps generation methods incur prohibitive training costs and lack plug-and-play versatility. To bridge this gap, we propose the Bi-Anchor Interpolation Solver (BA-solver). BA-solver retains the versatility of standard training-free solvers while achieving significant acceleration by introducing a lightweight SideNet (1-2% backbone size) alongside the frozen backbone. Specifically, our method is founded on two synergistic components: \textbf{1) Bidirectional Temporal Perception}, where the SideNet learns to approximate both future and historical velocities without retraining the heavy backbone; and 2) Bi-Anchor Velocity Integration, which utilizes the SideNet with two anchor velocities to efficiently approximate intermediate velocities for batched high-order integration. By utilizing the backbone to establish high-precision ``anchors'' and the SideNet to densify the trajectory, BA-solver enables large interval sizes with minimized error. Empirical results on ImageNet-256^2 demonstrate that BA-solver achieves generation quality comparable to 100+ NFEs Euler solver in just 10 NFEs and maintains high fidelity in as few as 5 NFEs, incurring negligible training costs. Furthermore, BA-solver ensures seamless integration with existing generative pipelines, facilitating downstream tasks such as image editing.

</details>


### [46] [Unifying Heterogeneous Degradations: Uncertainty-Aware Diffusion Bridge Model for All-in-One Image Restoration](https://arxiv.org/abs/2601.21592)
*Luwei Tu,Jiawei Wu,Xing Luo,Zhi Jin*

Main category: cs.CV

TL;DR: 本文提出了一种基于不确定性感知扩散桥（UDBM）的全能图像恢复方法，有效解决了不同退化类型间优化目标冲突的问题，实现了单步高效恢复。


<details>
  <summary>Details</summary>
Motivation: All-in-One Image Restoration（AiOIR）需要应对多种异构退化带来的优化目标冲突，现有方法控制粒度粗糙或映射策略固定，难以获得最佳自适应能力。

Method: 作者将AiOIR重新建模为受像素级不确定性引导的随机输运问题，提出了松弛扩散桥公式（以松弛约束代替严格终点约束），显式建模退化不确定性，并理论上解决了标准扩散桥中的漂移奇异性。进一步，提出了双调制策略：通过噪声调度使多类退化对齐到共享高熵潜空间，轨迹调度则基于熵正则的动力学自适应调控传输路径。

Result: UDBM在多种图像恢复子任务上均取得了最新的性能表现，并能够在单次推理中完成多任务自适应恢复。

Conclusion: UDBM方法通过创新的动力学建模与调制策略，在高效性和适应性的平衡上取得突破，为多任务图像恢复提供了新的解决思路。

Abstract: All-in-One Image Restoration (AiOIR) faces the fundamental challenge in reconciling conflicting optimization objectives across heterogeneous degradations. Existing methods are often constrained by coarse-grained control mechanisms or fixed mapping schedules, yielding suboptimal adaptation. To address this, we propose an Uncertainty-Aware Diffusion Bridge Model (UDBM), which innovatively reformulates AiOIR as a stochastic transport problem steered by pixel-wise uncertainty. By introducing a relaxed diffusion bridge formulation which replaces the strict terminal constraint with a relaxed constraint, we model the uncertainty of degradations while theoretically resolving the drift singularity inherent in standard diffusion bridges. Furthermore, we devise a dual modulation strategy: the noise schedule aligns diverse degradations into a shared high-entropy latent space, while the path schedule adaptively regulates the transport trajectory motivated by the viscous dynamics of entropy regularization. By effectively rectifying the transport geometry and dynamics, UDBM achieves state-of-the-art performance across diverse restoration tasks within a single inference step.

</details>


### [47] [HydroSense: A Dual-Microcontroller IoT Framework for Real-Time Multi-Parameter Water Quality Monitoring with Edge Processing and Cloud Analytics](https://arxiv.org/abs/2601.21595)
*Abdul Hasib,A. S. M. Ahsanul Sarkar Akib,Anish Giri*

Main category: cs.CV

TL;DR: 文章提出了一种经济实用、准确可靠且实时的水质监测系统HydroSense，对全球水危机下水资源匮乏地区尤具意义。


<details>
  <summary>Details</summary>
Motivation: 当前手工采样及昂贵的商业水质监测系统不适用于资源有限环境，缺乏低成本高性能的解决方案，难以普及水质实时监测。

Method: 设计了HydroSense系统，能同时监测pH、溶解氧、温度、总溶解固体、氮含量和水位，采用双微控制器结构（Arduino Uno负责高精度模拟测量，ESP32负责无线与云处理），并配备多点校准、去噪、温度补偿、错误处理等信号处理算法，通过Firebase云数据库实现数据实时传输。

Result: 系统经过90天实测，pH精度±0.08、溶解氧稳定性±0.2 mg/L、TDS精度±1.9%、云端数据传输可靠率99.8%；每套成本约300美元（32,983 BDT），比商用产品便宜85%。

Conclusion: HydroSense实现了低成本、高性能的专业级水质监测，极大提升了技术的可获取性，为环境监测提供了新范式。

Abstract: The global water crisis necessitates affordable, accurate, and real-time water quality monitoring solutions. Traditional approaches relying on manual sampling or expensive commercial systems fail to address accessibility challenges in resource-constrained environments. This paper presents HydroSense, an innovative Internet of Things framework that integrates six critical water quality parameters including pH, dissolved oxygen (DO), temperature, total dissolved solids (TDS), estimated nitrogen, and water level into a unified monitoring system. HydroSense employs a novel dual-microcontroller architecture, utilizing Arduino Uno for precision analog measurements with five-point calibration algorithms and ESP32 for wireless connectivity, edge processing, and cloud integration. The system implements advanced signal processing techniques including median filtering for TDS measurement, temperature compensation algorithms, and robust error handling. Experimental validation over 90 days demonstrates exceptional performance metrics: pH accuracy of plus or minus 0.08 units across the 0 to 14 range, DO measurement stability within plus or minus 0.2 mg/L, TDS accuracy of plus or minus 1.9 percent across 0 to 1000 ppm, and 99.8 percent cloud data transmission reliability. With a total implementation cost of 32,983 BDT (approximately 300 USD), HydroSense achieves an 85 percent cost reduction compared to commercial systems while providing enhanced connectivity through the Firebase real-time database. This research establishes a new paradigm for accessible environmental monitoring, demonstrating that professional-grade water quality assessment can be achieved through intelligent system architecture and cost-effective component selection.

</details>


### [48] [WMVLM: Evaluating Diffusion Model Image Watermarking via Vision-Language Models](https://arxiv.org/abs/2601.21610)
*Zijin Yang,Yu Sun,Kejiang Chen,Jiawei Zhao,Jun Jiang,Weiming Zhang,Nenghai Yu*

Main category: cs.CV

TL;DR: 本文提出了WMVLM，这是首个面向扩散模型图像水印的统一且可解释的评价框架，利用视觉-语言模型（VLMs）提升对残差水印和语义水印的评估准确性和解释性。


<details>
  <summary>Details</summary>
Motivation: 当前图像水印评价方法存在四大不足：一、无法统一评估残差与语义水印；二、评估结果缺乏可解释性；三、未充分考虑安全性；四、针对语义水印评价时采用了不合适的指标。因此开发新型评价框架十分必要。

Method: 提出了WMVLM评价框架，分为三大核心创新：（1）对残差和语义水印分别重新定义了质量与安全指标；（2）基于视觉-语言模型统一处理两类水印，并利用模型的可解释输出增强解释性；（3）设计三阶段训练策略，实现模型在分类、打分和解释性文本生成三个任务上的能力。

Result: 实验结果显示，WMVLM在不同数据集、扩散模型及水印方法上均有极强的泛化能力，在各项评测指标上超越了现有SOTA视觉-语言模型。

Conclusion: WMVLM为扩散模型水印的评价提供了首次统一且可解释的框架，有效填补了现有方法的不足，并能促进后续相关算法的发展。

Abstract: Digital watermarking is essential for securing generated images from diffusion models. Accurate watermark evaluation is critical for algorithm development, yet existing methods have significant limitations: they lack a unified framework for both residual and semantic watermarks, provide results without interpretability, neglect comprehensive security considerations, and often use inappropriate metrics for semantic watermarks. To address these gaps, we propose WMVLM, the first unified and interpretable evaluation framework for diffusion model image watermarking via vision-language models (VLMs). We redefine quality and security metrics for each watermark type: residual watermarks are evaluated by artifact strength and erasure resistance, while semantic watermarks are assessed through latent distribution shifts. Moreover, we introduce a three-stage training strategy to progressively enable the model to achieve classification, scoring, and interpretable text generation. Experiments show WMVLM outperforms state-of-the-art VLMs with strong generalization across datasets, diffusion models, and watermarking methods.

</details>


### [49] [PathReasoner-R1: Instilling Structured Reasoning into Pathology Vision-Language Model via Knowledge-Guided Policy Optimization](https://arxiv.org/abs/2601.21617)
*Songhan Jiang,Fengchun Liu,Ziyue Wang,Linghan Cai,Yongbing Zhang*

Main category: cs.CV

TL;DR: 本文提出了PathReasoner，一个面向数字病理学的首个大规模WSI（切片全图）推理数据集及其方法PathReasoner-R1，实现了可验证、循证的视觉-语言推理能力。


<details>
  <summary>Details</summary>
Motivation: 目前视觉-语言模型在病理学中已显示出强大的视觉理解能力，但多数系统仅输出结论，缺乏可追溯的证据链推理，难以获得临床信任，也不便专家纠错。

Method: 1）构建PathReasoner数据集，基于医学知识图谱，显式对齐结构化病理发现、推理过程与诊断结论，生成两万余高质量推理样本；2）提出PathReasoner-R1模型，结合“轨迹掩码”监督微调与以推理为导向的强化学习，强化模型结构化思维链能力；3）设计知识感知的多粒度奖励函数，尤其是与知识图谱严密对齐的实体奖励，引导模型追求逻辑一致性。

Result: 实验表明，PathReasoner-R1在PathReasoner数据集及多个公开基准上表现出色，实现了最先进性能，提升了病理诊断的推理透明性和临床适用性。

Conclusion: PathReasoner及其方法为病理AI模型赋予了可验证的推理能力，有助于增强临床信任与模型鲁棒性，对医学AI解释性具有重要推动价值。

Abstract: Vision-Language Models (VLMs) are advancing computational pathology with superior visual understanding capabilities. However, current systems often reduce diagnosis to directly output conclusions without verifiable evidence-linked reasoning, which severely limits clinical trust and hinders expert error rectification. To address these barriers, we construct PathReasoner, the first large-scale dataset of whole-slide image (WSI) reasoning. Unlike previous work reliant on unverified distillation, we develop a rigorous knowledge-guided generation pipeline. By leveraging medical knowledge graphs, we explicitly align structured pathological findings and clinical reasoning with diagnoses, generating over 20K high-quality instructional samples. Based on the database, we propose PathReasoner-R1, which synergizes trajectory-masked supervised fine-tuning with reasoning-oriented reinforcement learning to instill structured chain-of-thought capabilities. To ensure medical rigor, we engineer a knowledge-aware multi-granular reward function incorporating an Entity Reward mechanism strictly aligned with knowledge graphs. This effectively guides the model to optimize for logical consistency rather than mere outcome matching, thereby enhancing robustness. Extensive experiments demonstrate that PathReasoner-R1 achieves state-of-the-art performance on both PathReasoner and public benchmarks across various image scales, equipping pathology models with transparent, clinically grounded reasoning capabilities. Dataset and code are available at https://github.com/cyclexfy/PathReasoner-R1.

</details>


### [50] [Similarity of Processing Steps in Vision Model Representations](https://arxiv.org/abs/2601.21621)
*Matéo Mahaut,Marco Baroni*

Main category: cs.CV

TL;DR: 论文探究了视觉模型在学习过程中，除了最终表现出类似的“通用”表示外，各层中间表示是否也会趋同。通过定量分析不同模型各层表示的相似性，发现模型在相似层级的表示更相近，但依然存在显著差异，尤其是分类器最终会丢弃低级特征。CNN与Transformer的表示变化方式也明显不同。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究指出大规模模型最终容易收敛到相似的表示，但尚不明确其中间处理步骤是否也一致。本研究旨在揭示不同视觉模型在达到最终收敛表示的过程中，内部各阶段（如各层）表示的演化规律及其相似性。

Method: 作者通过量化分析不同模型（包括CNN与Transformer）各层表示之间的距离，跟踪表示在模型处理流程中的演变，找出各模型间差异最大的处理阶段，并对比分类器型模型与其他模型对于低层信息的保留与丢弃。

Result: 分析表明，不同模型在相似层级的表示确实更为接近，但依旧存在明显差别。分类模型在最后几层会抛弃低级图像统计信息。此外，CNN与Transformer在层间表示变化上存在差异，其中Transformer模型各层之间的变化更为平滑。

Conclusion: 视觉模型的表示虽然在特定层级出现趋同，但内部处理流程依然有各自不同的“步骤”与风格，CNN和Transformer的处理细节差异突出，分类模型尤其会丢弃部分底层信息，这些结果为理解模型表征收敛的机制和差异提供了新视角。

Abstract: Recent literature suggests that the bigger the model, the more likely it is to converge to similar, ``universal'' representations, despite different training objectives, datasets, or modalities. While this literature shows that there is an area where model representations are similar, we study here how vision models might get to those representations--in particular, do they also converge to the same intermediate steps and operations? We therefore study the processes that lead to convergent representations in different models. First, we quantify distance between different model representations at different stages. We follow the evolution of distances between models throughout processing, identifying the processing steps which are most different between models. We find that while layers at similar positions in different models have the most similar representations, strong differences remain. Classifier models, unlike the others, will discard information about low-level image statistics in their final layers. CNN- and transformer-based models also behave differently, with transformer models applying smoother changes to representations from one layer to the next. These distinctions clarify the level and nature of convergence between model representations, and enables a more qualitative account of the underlying processes in image models.

</details>


### [51] [A Tilted Seesaw: Revisiting Autoencoder Trade-off for Controllable Diffusion](https://arxiv.org/abs/2601.21633)
*Pu Cao,Yiyang Ma,Feng Zhou,Xuedan Yin,Qing Song,Lu Yang*

Main category: cs.CV

TL;DR: 本论文指出，现有潜在扩散模型中的自编码器（AE）在评估指标上存在偏颇，过分注重生成质量（gFID），而忽视重建质量，进而影响可控扩散任务中的可控性表现。


<details>
  <summary>Details</summary>
Motivation: 在ImageNet等大规模数据集的生成模型研究中，自编码器通常追求生成质量指标（如gFID）最优，却逐渐忽视了对重建质量的评估和报告，这种偏向性可能导致在实际可控生成任务中出现问题。

Method: 作者首先对过度关注gFID的理论风险进行了分析，提出‘条件漂移’问题，并通过引入多维度条件漂移评估协议，对不同自编码器在可控扩散任务中的表现进行了实证研究，包括用ControlNet做了进一步实验。

Result: 结果表明，以gFID为主的评判准则只能微弱预测条件保持，而重建相关指标与可控性高度相关；ControlNet实验也佐证了重建质量对条件可控性的关键作用。

Conclusion: 论文揭示了基于ImageNet的自编码器评估与真正可扩展可控扩散生成需求之间存在差距，并为更可靠的基准测试和模型选择提供了参考。

Abstract: In latent diffusion models, the autoencoder (AE) is typically expected to balance two capabilities: faithful reconstruction and a generation-friendly latent space (e.g., low gFID). In recent ImageNet-scale AE studies, we observe a systematic bias toward generative metrics in handling this trade-off: reconstruction metrics are increasingly under-reported, and ablation-based AE selection often favors the best-gFID configuration even when reconstruction fidelity degrades. We theoretically analyze why this gFID-dominant preference can appear unproblematic for ImageNet generation, yet becomes risky when scaling to controllable diffusion: AEs can induce condition drift, which limits achievable condition alignment. Meanwhile, we find that reconstruction fidelity, especially instance-level measures, better indicates controllability. We empirically validate the impact of tilted autoencoder evaluation on controllability by studying several recent ImageNet AEs. Using a multi-dimensional condition-drift evaluation protocol reflecting controllable generation tasks, we find that gFID is only weakly predictive of condition preservation, whereas reconstruction-oriented metrics are substantially more aligned. ControlNet experiments further confirm that controllability tracks condition preservation rather than gFID. Overall, our results expose a gap between ImageNet-centric AE evaluation and the requirements of scalable controllable diffusion, offering practical guidance for more reliable benchmarking and model selection.

</details>


### [52] [RSGround-R1: Rethinking Remote Sensing Visual Grounding through Spatial Reasoning](https://arxiv.org/abs/2601.21634)
*Shiqi Huang,Shuting He,Bihan Wen*

Main category: cs.CV

TL;DR: 本文提出了一种用于遥感视觉定位的多模态大模型后训练框架，通过引入位置感知和推理机制，提升模型在自然语言空间推理下的目标定位能力，实验显示其在基准数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 遥感图像尺度大、语义复杂，现有多模态大模型在依据自然语言描述实现精确空间定位方面面临挑战，尤其是空间推理能力不足，因此需要设计更适合该场景的训练范式。

Method: 提出RSGround-R1后训练框架，核心包括：1）利用合成的遥感视觉定位推理数据进行链式思维监督微调（CoT-SFT），提升位置意识；2）基于特殊设计的位置奖励进行强化微调（RFT），实现距离感知的连续定位优化；3）引入空间一致性优化机制，动态调整策略以提升不同步推理下的定位稳定性与一致性。

Result: 在遥感视觉定位相关基准数据集上，提出的方法在性能和泛化能力方面均超过了现有方法。

Conclusion: 通过引入推理和位置感知的后训练框架，能够显著提升多模态大模型在遥感视觉定位任务中的空间推理和目标定位能力。

Abstract: Remote Sensing Visual Grounding (RSVG) aims to localize target objects in large-scale aerial imagery based on natural language descriptions. Owing to the vast spatial scale and high semantic ambiguity of remote sensing scenes, these descriptions often rely heavily on positional cues, posing unique challenges for Multimodal Large Language Models (MLLMs) in spatial reasoning. To leverage this unique feature, we propose a reasoning-guided, position-aware post-training framework, dubbed \textbf{RSGround-R1}, to progressively enhance spatial understanding. Specifically, we first introduce Chain-of-Thought Supervised Fine-Tuning (CoT-SFT) using synthetically generated RSVG reasoning data to establish explicit position awareness. Reinforcement Fine-Tuning (RFT) is then applied, augmented by our newly designed positional reward that provides continuous and distance-aware guidance toward accurate localization. Moreover, to mitigate incoherent localization behaviors across rollouts, we introduce a spatial consistency guided optimization scheme that dynamically adjusts policy updates based on their spatial coherence, ensuring stable and robust convergence. Extensive experiments on RSVG benchmarks demonstrate superior performance and generalization of our model.

</details>


### [53] [OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models](https://arxiv.org/abs/2601.21639)
*Yufeng Zhong,Lei Chen,Xuanle Zhao,Wenkang Han,Liming Zheng,Jing Huang,Deyang Jiang,Yilin Cao,Lin Ma,Zhixiong Zeng*

Main category: cs.CV

TL;DR: 该论文提出了一种名为OCRVerse的新型OCR方法，能够统一处理文本型文档和视觉信息密集型图像，实现端到端的多模态信息提取。作者通过数据工程和新的多阶段训练方案，实现了跨领域高效识别，性能优于或接近现有主流开源/闭源模型。


<details>
  <summary>Details</summary>
Motivation: 随着大规模视觉语言模型的发展，海量多模态数据的管理和应用需求增长。目前主流OCR主要聚焦提取文本信息，忽略了图表、网页等视觉信息密集型图像的内容识别，限制了OCR在数据可视化、网页分析等领域的应用。

Method: 提出OCRVerse方法，首次在一个模型内实现了对文本型文档和视觉信息密集型图像的统一、端到端OCR。构建了多样的数据集，涵盖新闻、杂志、书籍及图表、网页等类型，并采用两阶段的SFT-RL多领域训练方法：第一阶段通过SFT混合跨域数据训练建立初始知识，第二阶段在RL中为不同领域设计自定义奖励，提升领域融合与模型灵活性。

Result: 实验表明，OCRVerse在文本和视觉信息密集型数据上都取得了有竞争力的效果，部分任务结果可媲美甚至超过当前主流的大型开源和闭源OCR模型。

Conclusion: OCRVerse有效实现了文本中心和视觉中心OCR的统一，为多模态信息密集型数据的结构化理解提供了新方法，并具备良好的跨领域泛化能力和实际应用价值。

Abstract: The development of large vision language models drives the demand for managing, and applying massive amounts of multimodal data, making OCR technology, which extracts information from visual images, increasingly popular. However, existing OCR methods primarily focus on recognizing text elements from images or scanned documents (\textbf{Text-centric OCR}), neglecting the identification of visual elements from visually information-dense image sources (\textbf{Vision-centric OCR}), such as charts, web pages and science plots. In reality, these visually information-dense images are widespread on the internet and have significant real-world application value, such as data visualization and web page analysis. In this technical report, we propose \textbf{OCRVerse}, the first holistic OCR method in end-to-end manner that enables unified text-centric OCR and vision-centric OCR. To this end, we constructe comprehensive data engineering to cover a wide range of text-centric documents, such as newspapers, magazines and books, as well as vision-centric rendered composites, including charts, web pages and scientific plots. Moreover, we propose a two-stage SFT-RL multi-domain training method for OCRVerse. SFT directly mixes cross-domain data to train and establish initial domain knowledge, while RL focuses on designing personalized reward strategies for the characteristics of each domain. Specifically, since different domains require various output formats and expected outputs, we provide sufficient flexibility in the RL stage to customize flexible reward signals for each domain, thereby improving cross-domain fusion and avoiding data conflicts. Experimental results demonstrate the effectiveness of OCRVerse, achieving competitive results across text-centric and vision-centric data types, even comparable to large-scale open-source and closed-source models.

</details>


### [54] [CAF-Mamba: Mamba-Based Cross-Modal Adaptive Attention Fusion for Multimodal Depression Detection](https://arxiv.org/abs/2601.21648)
*Bowen Zhou,Marc-André Fiedler,Ayoub Al-Hamadi*

Main category: cs.CV

TL;DR: 本文提出了CAF-Mamba，一个基于Mamba的跨模态自适应注意力融合框架，用于检测抑郁症，并在多个数据集上取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在抑郁检测中，通常只关注有限的特征类型，缺乏对模态间显式交互的建模，且多采用简单的拼接或静态加权融合，限制了检测性能。

Method: 作者提出CAF-Mamba框架，利用基于Mamba的跨模态自适应注意力机制，能够同时建模模态间的显式与隐式交互，并通过模态级别的注意力机制，动态调整各模态对最终融合的贡献。

Result: 在LMVD和D-Vlog两个实际环境下的基准数据集上，CAF-Mamba在抑郁症检测任务中的性能优于现有方法，达到了目前最优。

Conclusion: CAF-Mamba框架通过高效的跨模态建模与融合机制，提升了多模态抑郁症检测的表现，为相关领域提供了新的有效工具。

Abstract: Depression is a prevalent mental health disorder that severely impairs daily functioning and quality of life. While recent deep learning approaches for depression detection have shown promise, most rely on limited feature types, overlook explicit cross-modal interactions, and employ simple concatenation or static weighting for fusion. To overcome these limitations, we propose CAF-Mamba, a novel Mamba-based cross-modal adaptive attention fusion framework. CAF-Mamba not only captures cross-modal interactions explicitly and implicitly, but also dynamically adjusts modality contributions through a modality-wise attention mechanism, enabling more effective multimodal fusion. Experiments on two in-the-wild benchmark datasets, LMVD and D-Vlog, demonstrate that CAF-Mamba consistently outperforms existing methods and achieves state-of-the-art performance.

</details>


### [55] [Few-Shot Domain Adaptation with Temporal References and Static Priors for Glacier Calving Front Delineation](https://arxiv.org/abs/2601.21663)
*Marcel Dreier,Nora Gourmelon,Dakota Pyles,Thorsten Seehaus,Matthias H. Braun,Andreas Maier,Vincent Christlein*

Main category: cs.CV

TL;DR: 该论文提出了用深度学习模型实现冰川崩解前缘分割，并在新研究区域通过方法改进显著提升了分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的冰川崩解前缘分割模型在基准测试表现接近人类，但在新且未训练的数据域上精度不足，影响后续科学分析。亟需提升深度学习模型在新区域的适应性和实际应用效果。

Method: 采用了少量样本（few-shot）领域自适应方法，结合空间静态先验知识，并在输入时间序列中引入夏季参考影像，无需改变网络架构。

Result: 该改进方法将冰川前缘分割误差从1131.6米降低到68.7米，极大提升了在新区域的实际应用表现。

Conclusion: 所提出的方法为深度学习模型在全球范围新冰川区域的应用奠定了基础，有望推动冰川前缘大规模自动化监测。

Abstract: During benchmarking, the state-of-the-art model for glacier calving front delineation achieves near-human performance. However, when applied in a real-world setting at a novel study site, its delineation accuracy is insufficient for calving front products intended for further scientific analyses. This site represents an out-of-distribution domain for a model trained solely on the benchmark dataset. By employing a few-shot domain adaptation strategy, incorporating spatial static prior knowledge, and including summer reference images in the input time series, the delineation error is reduced from 1131.6 m to 68.7 m without any architectural modifications. These methodological advancements establish a framework for applying deep learning-based calving front segmentation to novel study sites, enabling calving front monitoring on a global scale.

</details>


### [56] [When Gradient Optimization Is Not Enough: $\dagger$ Dispersive and Anchoring Geometric Regularizer for Multimodal Learning](https://arxiv.org/abs/2601.21670)
*Zixuan Xia,Hao Wang,Pengcheng Weng,Yanyu Qian,Yangxin Xu,William Dan,Fei Wang*

Main category: cs.CV

TL;DR: 本文提出了一种面向表示几何结构的正则化方法，能够改善多模态模型的表现。


<details>
  <summary>Details</summary>
Motivation: 多模态学习需融合不同模态信息，但单靠优化目标难以保证表示空间结构合理。常见问题包括单模态表示塌缩和跨模态样本不一致，影响模型鲁棒性与融合效果。

Method: 作者识别到表示几何结构的重要性，并提出一种新的正则化框架（名为\regName），通过两个互补约束作用于中间表示：1）模态内分散正则化，提升同一模态内表达多样性；2）跨模态锚定正则化，约束同一样本不同模态的表示漂移，但不要求严格对齐。该正则化方法无需修改模型结构，可便捷集成到不同训练方案中。

Result: 在多个多模态任务基准上进行了大量实验，结果显示所提方法能稳定提升单模态和多模态的性能。

Conclusion: 显式调控表示几何结构能有效缓解多模态学习中的权衡问题，提升融合和鲁棒性。

Abstract: Multimodal learning aims to integrate complementary information from heterogeneous modalities, yet strong optimization alone does not guaranty well-structured representations. Even under carefully balanced training schemes, multimodal models often exhibit geometric pathologies, including intra-modal representation collapse and sample-level cross-modal inconsistency, which degrade both unimodal robustness and multimodal fusion.
  We identify representation geometry as a missing control axis in multimodal learning and propose \regName, a lightweight geometry-aware regularization framework. \regName enforces two complementary constraints on intermediate embeddings: an intra-modal dispersive regularization that promotes representation diversity, and an inter-modal anchoring regularization that bounds sample-level cross-modal drift without rigid alignment. The proposed regularizer is plug-and-play, requires no architectural modifications, and is compatible with various training paradigms.
  Extensive experiments across multiple multimodal benchmarks demonstrate consistent improvements in both multimodal and unimodal performance, showing that explicitly regulating representation geometry effectively mitigates modality trade-offs.

</details>


### [57] [Multimodal Visual Surrogate Compression for Alzheimer's Disease Classification](https://arxiv.org/abs/2601.21673)
*Dexuan Ding,Ciyuan Peng,Endrowednes Kuantama,Jingcai Guo,Jia Wu,Jian Yang,Amin Beheshti,Ming-Hsuan Yang,Yuankai Qi*

Main category: cs.CV

TL;DR: 本文提出了一种新的结构MRI图像特征提取方法MVSC，将3D医学影像高效压缩并转换为适合2D基础模型处理的特征，在阿尔茨海默病分类任务上优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 当前用于阿尔茨海默病诊断的高维3D结构MRI特征提取方法存在计算开销大、跨切片关系丢失或判别特征提取能力有限等问题。

Method: MVSC包含体积上下文编码器（Volume Context Encoder），通过文本引导捕捉3D切片间全局上下文信息，以及自适应切片融合模块（Adaptive Slice Fusion），以文本增强的方式按patch级聚合切片信息，从而将3D影像压缩成与2D基础图像模型高度契合的视觉代理特征。

Result: 在三大阿尔茨海默病公开基准上，MVSC在二分类和多分类任务中均优于最新方法。

Conclusion: MVSC能高效提取3D sMRI的判别特征，兼具效率和表现，有望成为AD影像诊断的新型特征学习框架。

Abstract: High-dimensional structural MRI (sMRI) images are widely used for Alzheimer's Disease (AD) diagnosis. Most existing methods for sMRI representation learning rely on 3D architectures (e.g., 3D CNNs), slice-wise feature extraction with late aggregation, or apply training-free feature extractions using 2D foundation models (e.g., DINO). However, these three paradigms suffer from high computational cost, loss of cross-slice relations, and limited ability to extract discriminative features, respectively. To address these challenges, we propose Multimodal Visual Surrogate Compression (MVSC). It learns to compress and adapt large 3D sMRI volumes into compact 2D features, termed as visual surrogates, which are better aligned with frozen 2D foundation models to extract powerful representations for final AD classification. MVSC has two key components: a Volume Context Encoder that captures global cross-slice context under textual guidance, and an Adaptive Slice Fusion module that aggregates slice-level information in a text-enhanced, patch-wise manner. Extensive experiments on three large-scale Alzheimer's disease benchmarks demonstrate our MVSC performs favourably on both binary and multi-class classification tasks compared against state-of-the-art methods.

</details>


### [58] [ChartE$^{3}$: A Comprehensive Benchmark for End-to-End Chart Editing](https://arxiv.org/abs/2601.21694)
*Shuo Li,Jiajun Sun,Zhekai Wang,Xiaoran Fan,Hui Li,Dingwen Yang,Zhiheng Xi,Yijun Wang,Zifei Shan,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CV

TL;DR: 本文提出了ChartE^3基准，用于评估模型端到端编辑图表的能力，无需依赖中间的自然语言或代码表示。该数据集涵盖了细粒度的局部编辑和全局结构调整两个方面。评测结果表明，当前多模态大模型在全局编辑任务上表现不足。


<details>
  <summary>Details</summary>
Motivation: 尽管图表编辑在人机交互和数据可视化领域极具实际价值，但现有方法多依赖管道式流程，且常用自然语言或代码作为中间表示，难以实现复杂且一致的端到端编辑，因此迫切需要直接、全面的评估基准。

Method: 作者构建了ChartE^3数据集，包含1200多个经过人工甄选的高质量样本，每个样本由图表图片、底层代码及多模态编辑指令构成。基准覆盖局部外观修改与全局数据操作，并对主流多模态大模型进行了系统性评测。

Result: Benchmark结果显示，当前多模态大模型在细粒度局部编辑任务上有一定能力，但在全局（数据中心）编辑上表现出明显短板，远未达到实用要求。

Conclusion: ChartE^3揭示了端到端图表编辑领域多模态大模型的显著不足，未来需要针对复杂整体结构变动进一步提升模型的编辑与理解能力。

Abstract: Charts are a fundamental visualization format for structured data analysis. Enabling end-to-end chart editing according to user intent is of great practical value, yet remains challenging due to the need for both fine-grained control and global structural consistency. Most existing approaches adopt pipeline-based designs, where natural language or code serves as an intermediate representation, limiting their ability to faithfully execute complex edits. We introduce ChartE$^{3}$, an End-to-End Chart Editing benchmark that directly evaluates models without relying on intermediate natural language programs or code-level supervision. ChartE$^{3}$ focuses on two complementary editing dimensions: local editing, which involves fine-grained appearance changes such as font or color adjustments, and global editing, which requires holistic, data-centric transformations including data filtering and trend line addition. ChartE$^{3}$ contains over 1,200 high-quality samples constructed via a well-designed data pipeline with human curation. Each sample is provided as a triplet of a chart image, its underlying code, and a multimodal editing instruction, enabling evaluation from both objective and subjective perspectives. Extensive benchmarking of state-of-the-art multimodal large language models reveals substantial performance gaps, particularly on global editing tasks, highlighting critical limitations in current end-to-end chart editing capabilities.

</details>


### [59] [DreamActor-M2: Universal Character Image Animation via Spatiotemporal In-Context Learning](https://arxiv.org/abs/2601.21716)
*Mingshuang Luo,Shuang Liang,Zhengkun Rong,Yuxuan Luo,Tianshu Hu,Ruibing Hou,Hong Chang,Yong Li,Yuan Zhang,Mingyuan Gao*

Main category: cs.CV

TL;DR: 本文提出了DreamActor-M2，一种用于角色图像动画的通用框架，通过创新的运动条件建模方案，显著提升了动画质量和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有动画方法面临身份保持与动作一致性之间的两难（“跷跷板”效应），且过度依赖显式骨架等姿态先验，难以适应非人形角色和复杂动作。针对这些问题，作者意在提出能够更好平衡身份与动作、且具备更强泛化性的动画生成框架。

Method: 方法采用两阶段流程：首先融合参考外观与动作信息至统一潜在空间，使模型结合空间身份和时序动态直接建模；其次设计自举式数据合成流程，生成伪跨身份训练对，推动从依赖姿态转向端到端的RGB动画控制。

Result: DreamActor-M2在新提出的包含多样角色与动作场景的AW Bench基准上进行了充分实验，显示在视觉保真度及跨域泛化上均优于现有方法。

Conclusion: 本文方法成功缓解了身份与动作一致性难题，摆脱了对骨架等先验过度依赖，提升了动画质量和泛化能力，对多类型、多场景动画生成具有重要意义。

Abstract: Character image animation aims to synthesize high-fidelity videos by transferring motion from a driving sequence to a static reference image. Despite recent advancements, existing methods suffer from two fundamental challenges: (1) suboptimal motion injection strategies that lead to a trade-off between identity preservation and motion consistency, manifesting as a "see-saw", and (2) an over-reliance on explicit pose priors (e.g., skeletons), which inadequately capture intricate dynamics and hinder generalization to arbitrary, non-humanoid characters. To address these challenges, we present DreamActor-M2, a universal animation framework that reimagines motion conditioning as an in-context learning problem. Our approach follows a two-stage paradigm. First, we bridge the input modality gap by fusing reference appearance and motion cues into a unified latent space, enabling the model to jointly reason about spatial identity and temporal dynamics by leveraging the generative prior of foundational models. Second, we introduce a self-bootstrapped data synthesis pipeline that curates pseudo cross-identity training pairs, facilitating a seamless transition from pose-dependent control to direct, end-to-end RGB-driven animation. This strategy significantly enhances generalization across diverse characters and motion scenarios. To facilitate comprehensive evaluation, we further introduce AW Bench, a versatile benchmark encompassing a wide spectrum of characters types and motion scenarios. Extensive experiments demonstrate that DreamActor-M2 achieves state-of-the-art performance, delivering superior visual fidelity and robust cross-domain generalization. Project Page: https://grisoon.github.io/DreamActor-M2/

</details>


### [60] [From Global to Granular: Revealing IQA Model Performance via Correlation Surface](https://arxiv.org/abs/2601.21738)
*Baoliang Chen,Danni Huang,Hanwei Zhu,Lingyu Zhu,Wei Zhou,Shiqi Wang,Yuming Fang,Weisi Lin*

Main category: cs.CV

TL;DR: 论文提出了一种用于图像质量评价（IQA）模型的新评估方法Granularity-Modulated Correlation（GMC），能细粒度地分析模型性能，比传统全局相关性指标（如PLCC和SRCC）更全面。


<details>
  <summary>Details</summary>
Motivation: 现有IQA评价指标（如PLCC和SRCC）只能用单一数值衡量模型性能，无法反映模型在不同质量分段的表现差异，也容易受测试集分布影响，导致比较不稳定。

Method: GMC方法包括两个核心模块：1）Granularity Modulator，通过条件相关计算（以MOS值及其差值为权重），细致衡量模型在不同质量区间和细粒度上的排序一致性；2）Distribution Regulator，用于校正非均匀测试集分布带来的偏差。最终输出为一个3D相关性曲面，可全面展示模型多维度表现。

Result: 实验显示，GMC能揭示出传统单标量指标未能识别的模型表现细节，在标准IQA基准上的分析更丰富、更具识别力。

Conclusion: GMC为IQA模型评价提供了更深入和可靠的分析框架，有助于更好地比较与部署IQA模型。

Abstract: Evaluation of Image Quality Assessment (IQA) models has long been dominated by global correlation metrics, such as Pearson Linear Correlation Coefficient (PLCC) and Spearman Rank-Order Correlation Coefficient (SRCC). While widely adopted, these metrics reduce performance to a single scalar, failing to capture how ranking consistency varies across the local quality spectrum. For example, two IQA models may achieve identical SRCC values, yet one ranks high-quality images (related to high Mean Opinion Score, MOS) more reliably, while the other better discriminates image pairs with small quality/MOS differences (related to $|Δ$MOS$|$). Such complementary behaviors are invisible under global metrics. Moreover, SRCC and PLCC are sensitive to test-sample quality distributions, yielding unstable comparisons across test sets. To address these limitations, we propose \textbf{Granularity-Modulated Correlation (GMC)}, which provides a structured, fine-grained analysis of IQA performance. GMC includes: (1) a \textbf{Granularity Modulator} that applies Gaussian-weighted correlations conditioned on absolute MOS values and pairwise MOS differences ($|Δ$MOS$|$) to examine local performance variations, and (2) a \textbf{Distribution Regulator} that regularizes correlations to mitigate biases from non-uniform quality distributions. The resulting \textbf{correlation surface} maps correlation values as a joint function of MOS and $|Δ$MOS$|$, providing a 3D representation of IQA performance. Experiments on standard benchmarks show that GMC reveals performance characteristics invisible to scalar metrics, offering a more informative and reliable paradigm for analyzing, comparing, and deploying IQA models. Codes are available at https://github.com/Dniaaa/GMC.

</details>


### [61] [Dynamic Topology Awareness: Breaking the Granularity Rigidity in Vision-Language Navigation](https://arxiv.org/abs/2601.21751)
*Jiankun Peng,Jianyuan Guo,Ying Xu,Yue Liu,Jiashuang Yan,Xuanwei Ye,Houhua Li,Xiaoming Wang*

Main category: cs.CV

TL;DR: 本文提出DGNav，一种用于视觉-语言导航的动态拓扑导航框架，通过动态调整图的粒度和连通性，使导航更高效、安全，且能自适应复杂场景。


<details>
  <summary>Details</summary>
Motivation: 现有基于拓扑图的方法在采样节点时只用固定阈值，这导致简单区域过度采样、复杂区域采样不足，从而带来效率低下和安全风险，难以适应不同环境复杂性。

Method: DGNav框架包括两个核心创新：（1）场景自适应策略，根据导航点的分布动态调整图构建阈值，在复杂区域提升节点密度；（2）动态图Transformer，融合视觉、语言、几何信息动态调整边权重，滤除噪声、提升指令执行能力。

Result: 在R2R-CE和RxR-CE两个基准上，DGNav取得了优异的导航性能和较强的泛化能力。消融实验验证了其在效率与安全探索间达到了最佳平衡。

Conclusion: DGNav动态调整拓扑图结构，实现了导航的安全、高效与鲁棒性，优于现有方法，并具备较强的泛化和实用价值。

Abstract: Vision-Language Navigation in Continuous Environments (VLN-CE) presents a core challenge: grounding high-level linguistic instructions into precise, safe, and long-horizon spatial actions. Explicit topological maps have proven to be a vital solution for providing robust spatial memory in such tasks. However, existing topological planning methods suffer from a "Granularity Rigidity" problem. Specifically, these methods typically rely on fixed geometric thresholds to sample nodes, which fails to adapt to varying environmental complexities. This rigidity leads to a critical mismatch: the model tends to over-sample in simple areas, causing computational redundancy, while under-sampling in high-uncertainty regions, increasing collision risks and compromising precision. To address this, we propose DGNav, a framework for Dynamic Topological Navigation, introducing a context-aware mechanism to modulate map density and connectivity on-the-fly. Our approach comprises two core innovations: (1) A Scene-Aware Adaptive Strategy that dynamically modulates graph construction thresholds based on the dispersion of predicted waypoints, enabling "densification on demand" in challenging environments; (2) A Dynamic Graph Transformer that reconstructs graph connectivity by fusing visual, linguistic, and geometric cues into dynamic edge weights, enabling the agent to filter out topological noise and enhancing instruction adherence. Extensive experiments on the R2R-CE and RxR-CE benchmarks demonstrate DGNav exhibits superior navigation performance and strong generalization capabilities. Furthermore, ablation studies confirm that our framework achieves an optimal trade-off between navigation efficiency and safe exploration. The code is available at https://github.com/shannanshouyin/DGNav.

</details>


### [62] [Synthetic-to-Real Domain Bridging for Single-View 3D Reconstruction of Ships for Maritime Monitoring](https://arxiv.org/abs/2601.21786)
*Borja Carrillo-Perez,Felix Sattler,Angel Bueno Rodriguez,Maurice Stephan,Sarah Barnes*

Main category: cs.CV

TL;DR: 本文提出了一种高效的单视图3D船舶重建方案，仅需合成数据训练、单张图片输入即可实现船舶的三维重建，且无需真实3D标注，适于实时海事监测。


<details>
  <summary>Details</summary>
Motivation: 实际海事监控要求快速、可扩展的3D船舶重建，但现有方法多需多视角对齐、3D标注或计算资源繁重，难以实际部署。因此作者动机是开发无需多视图和真实标注、计算高效的3D重建方法。

Method: 方法基于 Splatter Image 网络，将船舶表示为稀疏3D高斯点集，从单张船舶照片重建3D结构。模型先在ShapeNet合成数据集上训练，再用多样化自定义3D船舶数据集域适应。集成YOLOv8分割模块与自定义处理流程，后处理包括尺度归一、中心校正、姿态调整，并使用AIS元数据和单应性变换，将重建结果地理定位展示在交互式网络地图。

Result: 方法在合成数据集上验证了高保真重建效果，并在真实ShipSG数据集图片上获得了良好迁移和展示能力，说明方法在实际海事场景具备应用潜力。

Conclusion: 提出的单视图3D重建流程为无需真实标注和多视角支持的海事3D可视化提供了高效、可扩展的解决方案，并推动了实时3D船舶监测的实际应用。

Abstract: Three-dimensional (3D) reconstruction of ships is an important part of maritime monitoring, allowing improved visualization, inspection, and decision-making in real-world monitoring environments. However, most state-ofthe-art 3D reconstruction methods require multi-view supervision, annotated 3D ground truth, or are computationally intensive, making them impractical for real-time maritime deployment. In this work, we present an efficient pipeline for single-view 3D reconstruction of real ships by training entirely on synthetic data and requiring only a single view at inference. Our approach uses the Splatter Image network, which represents objects as sparse sets of 3D Gaussians for rapid and accurate reconstruction from single images. The model is first fine-tuned on synthetic ShapeNet vessels and further refined with a diverse custom dataset of 3D ships, bridging the domain gap between synthetic and real-world imagery. We integrate a state-of-the-art segmentation module based on YOLOv8 and custom preprocessing to ensure compatibility with the reconstruction network. Postprocessing steps include real-world scaling, centering, and orientation alignment, followed by georeferenced placement on an interactive web map using AIS metadata and homography-based mapping. Quantitative evaluation on synthetic validation data demonstrates strong reconstruction fidelity, while qualitative results on real maritime images from the ShipSG dataset confirm the potential for transfer to operational maritime settings. The final system provides interactive 3D inspection of real ships without requiring real-world 3D annotations. This pipeline provides an efficient, scalable solution for maritime monitoring and highlights a path toward real-time 3D ship visualization in practical applications. Interactive demo: https://dlr-mi.github.io/ship3d-demo/.

</details>


### [63] [CG-MLLM: Captioning and Generating 3D content via Multi-modal Large Language Models](https://arxiv.org/abs/2601.21798)
*Junming Huang,Weiwei Xu*

Main category: cs.CV

TL;DR: 该论文提出了一种新型多模态大型语言模型CG-MLLM，实现了高分辨率3D生成和3D描述任务，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前大模型在文本及多模态领域表现优异，但在3D内容生成方面仍存在明显不足，尤其在生成高分辨率细节方面有很大挑战。现有方法的分辨率低、结构粗糙，本研究旨在突破这一瓶颈。

Method: 作者提出了Mixture-of-Transformer架构的CG-MLLM，将Token-level Autoregressive Transformer和Block-level Autoregressive Transformer结合，分别处理细粒度和块级内容。通过预训练视觉-语言骨干网络与定制的3D VAE潜空间集成，实现标准token与空间block间的长距离上下文交互。

Result: 实验证明所提CG-MLLM在高保真3D物体生成方面明显优于当前主流多模态大模型，能够生成更精细的三维内容。

Conclusion: CG-MLLM将高分辨率3D内容创作能力引入主流大语言模型框架中，为3D生成领域带来创新进展。

Abstract: Large Language Models(LLMs) have revolutionized text generation and multimodal perception, but their capabilities in 3D content generation remain underexplored. Existing methods compromise by producing either low-resolution meshes or coarse structural proxies, failing to capture fine-grained geometry natively. In this paper, we propose CG-MLLM, a novel Multi-modal Large Language Model (MLLM) capable of 3D captioning and high-resolution 3D generation in a single framework. Leveraging the Mixture-of-Transformer architecture, CG-MLLM decouples disparate modeling needs, where the Token-level Autoregressive (TokenAR) Transformer handles token-level content, and the Block-level Autoregressive (BlockAR) Transformer handles block-level content. By integrating a pre-trained vision-language backbone with a specialized 3D VAE latent space, CG-MLLM facilitates long-context interactions between standard tokens and spatial blocks within a single integrated architecture. Experimental results show that CG-MLLM significantly outperforms existing MLLMs in generating high-fidelity 3D objects, effectively bringing high-resolution 3D content creation into the mainstream LLM paradigm.

</details>


### [64] [MMFineReason: Closing the Multimodal Reasoning Gap via Open Data-Centric Methods](https://arxiv.org/abs/2601.21821)
*Honglin Lin,Zheng Liu,Yun Zhu,Chonghan Qin,Juekai Lin,Xiaoran Shang,Conghui He,Wentao Zhang,Lijun Wu*

Main category: cs.CV

TL;DR: 作者提出了一个名为MMFineReason的大规模多模态推理数据集，并基于它训练了一系列高效的视觉-语言推理模型，在同参数量级下取得了SOTA效果，并展示了高难度样本精筛和推理数据的协同提升作用。


<details>
  <summary>Details</summary>
Motivation: 开源视觉语言模型（VLMs）在视觉推理方面落后于闭源系统，主要因为缺乏高质量推理数据，尤其是在STEM、视觉谜题等高难度领域。现有数据集缺乏覆盖面和一致、长链路的推理标注。因此有必要构建高质量、多样且带有推理标注的数据集以提升模型能力。

Method: 提出MMFineReason数据集，包括180万样本和51亿解答标注token，通过三阶段流程（大规模数据收集与标准化、生成链式思考推理、依据推理质量与难度敏感性筛选）建立。涵盖STEM题、谜题、游戏和复杂图表，标注包含视觉支撑的推理链。基于该数据集微调Qwen3-VL-Instruct，推出2B/4B/8B等版本并测试性能。

Result: 模型在多个视觉推理任务上取得所属参数规模的最优结果。特别是，4B版本超越了8B模型，8B版本几乎达到甚至超越部分30B模型性能，展现了优秀的参数效率。此外，仅用7%高难跳选数据也能达到完整集的效果，且推理导向样本提升了广义能力。

Conclusion: 高质量、多样化的链式推理数据对提升多模态推理模型极为关键。精选高难样本可兼顾高效和性能，推理类数据还有助于提升模型整体能力，对视觉-语言领域的开源发展有重要意义。

Abstract: Recent advances in Vision Language Models (VLMs) have driven significant progress in visual reasoning. However, open-source VLMs still lag behind proprietary systems, largely due to the lack of high-quality reasoning data. Existing datasets offer limited coverage of challenging domains such as STEM diagrams and visual puzzles, and lack consistent, long-form Chain-of-Thought (CoT) annotations essential for eliciting strong reasoning capabilities. To bridge this gap, we introduce MMFineReason, a large-scale multimodal reasoning dataset comprising 1.8M samples and 5.1B solution tokens, featuring high-quality reasoning annotations distilled from Qwen3-VL-235B-A22B-Thinking. The dataset is established via a systematic three-stage pipeline: (1) large-scale data collection and standardization, (2) CoT rationale generation, and (3) comprehensive selection based on reasoning quality and difficulty awareness. The resulting dataset spans STEM problems, visual puzzles, games, and complex diagrams, with each sample annotated with visually grounded reasoning traces. We fine-tune Qwen3-VL-Instruct on MMFineReason to develop MMFineReason-2B/4B/8B versions. Our models establish new state-of-the-art results for their size class. Notably, MMFineReason-4B succesfully surpasses Qwen3-VL-8B-Thinking, and MMFineReason-8B even outperforms Qwen3-VL-30B-A3B-Thinking while approaching Qwen3-VL-32B-Thinking, demonstrating remarkable parameter efficiency. Crucially, we uncover a "less is more" phenomenon via our difficulty-aware filtering strategy: a subset of just 7\% (123K samples) achieves performance comparable to the full dataset. Notably, we reveal a synergistic effect where reasoning-oriented data composition simultaneously boosts general capabilities.

</details>


### [65] [Trajectory-Guided Diffusion for Foreground-Preserving Background Generation in Multi-Layer Documents](https://arxiv.org/abs/2601.21857)
*Taewon Kang*

Main category: cs.CV

TL;DR: 该论文提出了一种新的基于扩散模型的文档背景生成方法，实现了前景信息保护和多页风格一致性。通过在潜空间设计扩散轨迹，无需显式掩膜或抑制机制，即可自然避开前景区域。该方法无需额外训练，能与现有的扩散模型兼容，生成结构化且风格统一的文档背景。


<details>
  <summary>Details</summary>
Motivation: 现有文档生成方法难以同时保证前景（如文本）完整性和多页间风格的一致，且依赖于复杂的掩膜或风格提示机制，效率低且稳定性差。

Method: 作者在潜空间中设计初始噪声及其几何排列方式，使背景的扩散轨迹自然避开前景区域，无需显式掩膜。为解决风格漂移问题，通过缓存的风格方向矢量约束多页扩散过程，保证风格一致。该方法无需重新训练模型，仅需在潜空间设计轨迹。

Result: 该框架在复杂文档上实现了前景完整、风格一致的多页背景生成，保持内容可读性，且相较重复利用风格提示的方法有更高的一致性与稳定性。

Conclusion: 论文提出的通过潜空间扩散轨迹设计的方法，实现了无需训练、结构化、一致性的文档背景生成，提升了生成质量，为生成式建模提供了新的理论与实现路径。

Abstract: We present a diffusion-based framework for document-centric background generation that achieves foreground preservation and multi-page stylistic consistency through latent-space design rather than explicit constraints. Instead of suppressing diffusion updates or applying masking heuristics, our approach reinterprets diffusion as the evolution of stochastic trajectories through a structured latent space. By shaping the initial noise and its geometric alignment, background generation naturally avoids designated foreground regions, allowing readable content to remain intact without auxiliary mechanisms. To address the long-standing issue of stylistic drift across pages, we decouple style control from text conditioning and introduce cached style directions as persistent vectors in latent space. Once selected, these directions constrain diffusion trajectories to a shared stylistic subspace, ensuring consistent appearance across pages and editing iterations. This formulation eliminates the need for repeated prompt-based style specification and provides a more stable foundation for multi-page generation. Our framework admits a geometric and physical interpretation, where diffusion paths evolve on a latent manifold shaped by preferred directions, and foreground regions are rarely traversed as a consequence of trajectory initialization rather than explicit exclusion. The proposed method is training-free, compatible with existing diffusion backbones, and produces visually coherent, foreground-preserving results across complex documents. By reframing diffusion as trajectory design in latent space, we offer a principled approach to consistent and structured generative modeling.

</details>


### [66] [Improving Classifier-Free Guidance of Flow Matching via Manifold Projection](https://arxiv.org/abs/2601.21892)
*Jian-Feng Cai,Haixia Liu,Zhengyi Su,Chao Wang*

Main category: cs.CV

TL;DR: 提出了一种基于流匹配和优化理论的新方法，改进了无分类器引导（CFG）在扩散模型和流模型中的图片生成控制能力，并通过实验证明在多个主流大模型上带来了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的CFG方法虽然流行且有效，但主要基于启发式的线性外推调节方式，对guidance scale（引导尺度）非常敏感，缺乏理论解释和稳健性提升空间，因此需要一种更有理论基础、更稳定的优化视角进行改进。

Method: 论文用优化理论解释了CFG，将其看作在流匹配中的平滑距离函数梯度，并分析了有条件与无条件输出间预测差距对guidance敏感性的影响。在此基础上，把CFG采样过程重新定义为带流形约束的同伦优化问题；具体通过增量式梯度下降+Anderson加速法，设计出一种无需额外训练的新采样算法。

Result: 新方法在无需额外训练的前提下提升了生成图片的保真度、文本对齐程度，以及对guidance scale的鲁棒性。实验在DiT-XL-2-256、Flux和Stable Diffusion 3.5等多个大模型和任务上做了验证，生成结果全面优于传统CFG。

Conclusion: 通过将CFG理论化、并通过流形优化和加速手段推动了高质量可控生成的发展，所提方法不仅提升了效果，也为相关研究提供了稳健且高效的理论与工程方案。

Abstract: Classifier-free guidance (CFG) is a widely used technique for controllable generation in diffusion and flow-based models. Despite its empirical success, CFG relies on a heuristic linear extrapolation that is often sensitive to the guidance scale. In this work, we provide a principled interpretation of CFG through the lens of optimization. We demonstrate that the velocity field in flow matching corresponds to the gradient of a sequence of smoothed distance functions, which guides latent variables toward the scaled target image set. This perspective reveals that the standard CFG formulation is an approximation of this gradient, where the prediction gap, the discrepancy between conditional and unconditional outputs, governs guidance sensitivity. Leveraging this insight, we reformulate the CFG sampling as a homotopy optimization with a manifold constraint. This formulation necessitates a manifold projection step, which we implement via an incremental gradient descent scheme during sampling. To improve computational efficiency and stability, we further enhance this iterative process with Anderson Acceleration without requiring additional model evaluations. Our proposed methods are training-free and consistently refine generation fidelity, prompt alignment, and robustness to the guidance scale. We validate their effectiveness across diverse benchmarks, demonstrating significant improvements on large-scale models such as DiT-XL-2-256, Flux, and Stable Diffusion 3.5.

</details>


### [67] [Past- and Future-Informed KV Cache Policy with Salience Estimation in Autoregressive Video Diffusion](https://arxiv.org/abs/2601.21896)
*Hanmo Chen,Chenghao Xu,Xu Yang,Xuan Chen,Cheng Deng*

Main category: cs.CV

TL;DR: 本文提出了基于Token重要性的新型KV Cache策略PaFu-KV，通过保留关键信息token，提高了长时序视频生成的质量和效率。


<details>
  <summary>Details</summary>
Motivation: 当前自回归视频生成方法常用启发式KV Cache策略，未区分token重要性，导致关键信息丢失和冗余缓存堆积，影响生成视频的质量与推理效率。

Method: 提出Past- and Future-Informed KV Cache Policy（PaFu-KV），利用由双向教师网络蒸馏出来的轻量级显著性估计头，对token显著性进行评分，仅保留高显著性的token于缓存中，以此动态优化KV Cache管理。

Result: 在多个基准测试上，PaFu-KV在保持高保真视频生成质量的同时，显著缩小了KV Cache容量和内存消耗，加速了推理过程。

Conclusion: PaFu-KV方法有效提升了长时序视频生成系统的质量与效率，为高效视频合成提供了新思路。

Abstract: Video generation is pivotal to digital media creation, and recent advances in autoregressive video generation have markedly enhanced the efficiency of real-time video synthesis. However, existing approaches generally rely on heuristic KV Cache policies, which ignore differences in token importance in long-term video generation. This leads to the loss of critical spatiotemporal information and the accumulation of redundant, invalid cache, thereby degrading video generation quality and efficiency. To address this limitation, we first observe that token contributions to video generation are highly time-heterogeneous and accordingly propose a novel Past- and Future-Informed KV Cache Policy (PaFu-KV). Specifically, PaFu-KV introduces a lightweight Salience Estimation Head distilled from a bidirectional teacher to estimate salience scores, allowing the KV cache to retain informative tokens while discarding less relevant ones. This policy yields a better quality-efficiency trade-off by shrinking KV cache capacity and reducing memory footprint at inference time. Extensive experiments on benchmarks demonstrate that our method preserves high-fidelity video generation quality while enables accelerated inference, thereby enabling more efficient long-horizon video generation. Our code will be released upon paper acceptance.

</details>


### [68] [TraceRouter: Robust Safety for Large Foundation Models via Path-Level Intervention](https://arxiv.org/abs/2601.21900)
*Chuancheng Shi,Shangze Li,Wenjun Lu,Wenhua Wu,Cong Wang,Zifeng Cheng,Fei Shen,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 本文提出了TraceRouter，一种新的防御大模型对抗攻击的路径级框架，通过追踪并中断有害语义的传递路径，大幅提升了鲁棒性，同时保留模型实用性。


<details>
  <summary>Details</summary>
Motivation: 当前针对大型基础模型的对抗防御主要依赖在局部抑制神经元或特征，但有害语义往往以跨层分布电路形式存在，单点干预效果有限，容易损害模型效能。因此，迫切需要更精细化的防御方法，能够精准识别及切断有害语义在模型内部的传播路径。

Method: 提出TraceRouter框架，分为三步：1）通过注意力分歧分析定位敏感起始层；2）利用稀疏自编码器（SAE）和差分激活分析解耦、隔离恶意特征；3）通过零置干预得到的特征影响分值（FIS），将这些特征映射到下游因果路径上，并有选择地抑制这些路径，实现对有害信息流的物理切断，同时保留无关的正常计算路径。

Result: 实验结果显示，TraceRouter在多项实验中显著优于现有主流方法，在提升对抗鲁棒性的同时，能更好兼顾模型的普适性能。

Conclusion: TraceRouter通过路径级追踪和切断，有效防御和抑制了大型模型中的有害语义流动，取得了更优的安全性与效能平衡，对未来大模型安全防护具有重要意义。

Abstract: Despite their capabilities, large foundation models (LFMs) remain susceptible to adversarial manipulation. Current defenses predominantly rely on the "locality hypothesis", suppressing isolated neurons or features. However, harmful semantics act as distributed, cross-layer circuits, rendering such localized interventions brittle and detrimental to utility. To bridge this gap, we propose \textbf{TraceRouter}, a path-level framework that traces and disconnects the causal propagation circuits of illicit semantics. TraceRouter operates in three stages: (1) it pinpoints a sensitive onset layer by analyzing attention divergence; (2) it leverages sparse autoencoders (SAEs) and differential activation analysis to disentangle and isolate malicious features; and (3) it maps these features to downstream causal pathways via feature influence scores (FIS) derived from zero-out interventions. By selectively suppressing these causal chains, TraceRouter physically severs the flow of harmful information while leaving orthogonal computation routes intact. Extensive experiments demonstrate that TraceRouter significantly outperforms state-of-the-art baselines, achieving a superior trade-off between adversarial robustness and general utility. Our code will be publicly released. WARNING: This paper contains unsafe model responses.

</details>


### [69] [Beyond Global Alignment: Fine-Grained Motion-Language Retrieval via Pyramidal Shapley-Taylor Learning](https://arxiv.org/abs/2601.21904)
*Hanmo Chen,Guangtao Lyu,Chenghao Xu,Jiexi Yan,Xu Yang,Cheng Deng*

Main category: cs.CV

TL;DR: 本文提出了一种新的金字塔式Shapley-Taylor学习框架，用于实现更加细粒度的动作-语言检索，能够显著提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有的动作-语言检索方法主要进行整体对齐，忽略了局部运动片段、身体关节与文本单元之间的细粒度交互，导致性能受限。

Method: 借鉴人体动作感知的金字塔处理方式，将动作分解为时序片段和空间关节，通过逐步联合关节级和片段级对齐来学习跨模态对应关系，从而捕捉局部语义细节和层级结构关系。提出了Pyramidal Shapley-Taylor学习框架，在金字塔式结构下实现细粒度对齐。

Result: 在多个公开基准数据集上进行了大量实验，结果显示该方法在动作片段、身体关节与对应文本单元之间实现了更精确的对齐，检索性能超过了现有最新方法。

Conclusion: 金字塔Shapley-Taylor框架能够有效弥补细粒度对齐的不足，显著提升动作-语言检索的表现。

Abstract: As a foundational task in human-centric cross-modal intelligence, motion-language retrieval aims to bridge the semantic gap between natural language and human motion, enabling intuitive motion analysis, yet existing approaches predominantly focus on aligning entire motion sequences with global textual representations. This global-centric paradigm overlooks fine-grained interactions between local motion segments and individual body joints and text tokens, inevitably leading to suboptimal retrieval performance. To address this limitation, we draw inspiration from the pyramidal process of human motion perception (from joint dynamics to segment coherence, and finally to holistic comprehension) and propose a novel Pyramidal Shapley-Taylor (PST) learning framework for fine-grained motion-language retrieval. Specifically, the framework decomposes human motion into temporal segments and spatial body joints, and learns cross-modal correspondences through progressive joint-wise and segment-wise alignment in a pyramidal fashion, effectively capturing both local semantic details and hierarchical structural relationships. Extensive experiments on multiple public benchmark datasets demonstrate that our approach significantly outperforms state-of-the-art methods, achieving precise alignment between motion segments and body joints and their corresponding text tokens. The code of this work will be released upon acceptance.

</details>


### [70] [VideoAesBench: Benchmarking the Video Aesthetics Perception Capabilities of Large Multimodal Models](https://arxiv.org/abs/2601.21915)
*Yunhao Li,Sijing Wu,Zhilin Gao,Zicheng Zhang,Qi Jia,Huiyu Duan,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本文提出了VideoAesBench基准，用于评估大规模多模态模型在视频美学质量理解方面的能力，并发现现有模型在该领域还有明显不足。


<details>
  <summary>Details</summary>
Motivation: 虽然大多LMMs在视觉感知任务上有出色表现，但对视频美学质量评估能力的研究尚不足，而这对人类来说却是基本能力，因此急需设计新的基准和评估体系。

Method: 提出了VideoAesBench基准，包含1804个类型多样的视频（UGC、AIGC、RGC等）；涵盖单选、多选、判断和开放式描述等多种问题形式；综合考量视频美学的多个维度（形式、风格、情感等）；以此测试23种开源与商业LMMs的表现。

Result: 这些LMMs展示了基础的视频美学感知能力，但整体表现不完整且不够精确，还远未达到人类水平。

Conclusion: VideoAesBench为LMM美学能力评估提供了有力的测试平台，为可解释的视频美学评测与未来LMM改进提供了重要参考。

Abstract: Large multimodal models (LMMs) have demonstrated outstanding capabilities in various visual perception tasks, which has in turn made the evaluation of LMMs significant. However, the capability of video aesthetic quality assessment, which is a fundamental ability for human, remains underexplored for LMMs. To address this, we introduce VideoAesBench, a comprehensive benchmark for evaluating LMMs' understanding of video aesthetic quality. VideoAesBench has several significant characteristics: (1) Diverse content including 1,804 videos from multiple video sources including user-generated (UGC), AI-generated (AIGC), compressed, robotic-generated (RGC), and game videos. (2) Multiple question formats containing traditional single-choice questions, multi-choice questions, True or False questions, and a novel open-ended questions for video aesthetics description. (3) Holistic video aesthetics dimensions including visual form related questions from 5 aspects, visual style related questions from 4 aspects, and visual affectiveness questions from 3 aspects. Based on VideoAesBench, we benchmark 23 open-source and commercial large multimodal models. Our findings show that current LMMs only contain basic video aesthetics perception ability, their performance remains incomplete and imprecise. We hope our VideoAesBench can be served as a strong testbed and offer insights for explainable video aesthetics assessment.

</details>


### [71] [Zero-Shot Video Restoration and Enhancement with Assistance of Video Diffusion Models](https://arxiv.org/abs/2601.21922)
*Cong Cao,Huanjing Yue,Shangbin Xie,Xin Liu,Jingyu Yang*

Main category: cs.CV

TL;DR: 本文提出了一个基于视频扩散模型的新颖框架，将其与传统基于图像的零样本修复与增强方法结合，显著提升了视频处理中的时间一致性，避免了闪烁等问题。关键创新包括同质与异质潜变量融合算法、基于COT的融合比率策略，以及用于时间一致性增强的后处理流程。该方法无需训练、易于应用，实验证明其在多项任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管现有基于扩散模型的零样本图像修复与增强方法效果优异，但直接用于视频处理时会出现明显的时间闪烁现象，严重影响视频质量。作者的动机是提升视频修复与增强过程中的时间一致性，解决现有方法处理视频时产生的瑕疵。

Method: 作者提出将目前迅速发展的视频扩散模型与传统基于图像的扩散模型结合，并通过同质潜变量融合、异质潜变量融合，以及基于COT的融合比例策略，充分利用二者优点。此外，还提出一种“时间增强后处理”模块，借助图像到视频的扩散模型进一步提升时间一致性。整个流程无需训练，可灵活集成在任何基于扩散的图像修复与增强方法下。

Result: 实验结果显示，该方法在主流视频零样本修复与增强任务中，在提升时间一致性的同时，保持了甚至提升了图像质量，明显优于当前的扩散模型方法。

Conclusion: 本研究提出了一种高效、通用、训练自由的扩散模型新框架，显著提升了视频修复与增强的时间一致性，为扩散模型在视频领域的应用奠定了基础。

Abstract: Although diffusion-based zero-shot image restoration and enhancement methods have achieved great success, applying them to video restoration or enhancement will lead to severe temporal flickering. In this paper, we propose the first framework that utilizes the rapidly-developed video diffusion model to assist the image-based method in maintaining more temporal consistency for zero-shot video restoration and enhancement. We propose homologous latents fusion, heterogenous latents fusion, and a COT-based fusion ratio strategy to utilize both homologous and heterogenous text-to-video diffusion models to complement the image method. Moreover, we propose temporal-strengthening post-processing to utilize the image-to-video diffusion model to further improve temporal consistency. Our method is training-free and can be applied to any diffusion-based image restoration and enhancement methods. Experimental results demonstrate the superiority of the proposed method.

</details>


### [72] [Just Noticeable Difference Modeling for Deep Visual Features](https://arxiv.org/abs/2601.21933)
*Rui Zhao,Wenrui Li,Lin Zhu,Yajing Zheng,Weisi Lin*

Main category: cs.CV

TL;DR: 作者提出了一种名为FeatJND的新方法，可以在计算机视觉任务中，更有效地控制和评估深度特征的可容忍扰动范围，从而提升任务性能和特征量化的效率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉系统越来越多地依赖深度特征作为输入接口，但缺少有效手段来描述、评估以及控制这些特征的质量。为了在资源受限条件下，合理控制特征的失真与任务表现之间的平衡，亟需一种能够以任务为核心的特征失真容忍度评估方法。

Method: 提出FeatJND方法：在特征空间内定义与下游任务相关的可容忍扰动边界，能够预测每个特征点在保持任务性能的情况下最大可接受扰动。作者给出了标准接口下的FeatJND估算器，并在图像分类、检测、实例分割三个任务上进行了实验验证。同时，将FeatJND运用于基于token的动态量化，分配扰动大小，提高整体噪声容忍度。

Result: 实验结果表明，在相同的失真强度下，FeatJND方法能显著优于无结构高斯扰动，表现为更高的任务准确率与鲁棒性，并能有效抑制非关键特征区域的无效扰动。量化实验进一步证明FeatJND可以提升动态量化效果。

Conclusion: FeatJND实现了对深度特征可容许扰动的高效、任务相关控制，为资源受限条件下的特征质量管理和模型部署提供了实用工具，能显著保护任务性能，并有广泛的实际应用潜力。

Abstract: Deep visual features are increasingly used as the interface in vision systems, motivating the need to describe feature characteristics and control feature quality for machine perception. Just noticeable difference (JND) characterizes the maximum imperceptible distortion for images under human or machine vision. Extending it to deep visual features naturally meets the above demand by providing a task-aligned tolerance boundary in feature space, offering a practical reference for controlling feature quality under constrained resources. We propose FeatJND, a task-aligned JND formulation that predicts the maximum tolerable per-feature perturbation map while preserving downstream task performance. We propose a FeatJND estimator at standardized split points and validate it across image classification, detection, and instance segmentation. Under matched distortion strength, FeatJND-based distortions consistently preserve higher task performance than unstructured Gaussian perturbations, and attribution visualizations suggest FeatJND can suppress non-critical feature regions. As an application, we further apply FeatJND to token-wise dynamic quantization and show that FeatJND-guided step-size allocation yields clear gains over random step-size permutation and global uniform step size under the same noise budget. Our code will be released after publication.

</details>


### [73] [BookNet: Book Image Rectification via Cross-Page Attention Network](https://arxiv.org/abs/2601.21938)
*Shaokai Liu,Hao Feng,Bozhi Luan,Min Hou,Jiajun Deng,Wengang Zhou*

Main category: cs.CV

TL;DR: BookNet提出了一种专为书籍双页图像矫正设计的深度学习框架，有效处理左右页间复杂的几何关系，实验效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前文档图像矫正多针对单页，难以处理书籍中因装订造成的双页复杂变形，且左、右页存在明显非对称性和相互影响，现有方法无法有效建模双页之间的耦合几何关系。

Method: 提出BookNet模型，采用双分支架构和跨页注意力机制，能够同时估计单页和整本书的变形流，显式捕捉左右页之间的影响关系。还构建了Book3D（大规模合成数据集）用于训练，以及Book100（真实世界基准数据集）用于评测。

Result: BookNet在大规模实验中明显优于现有主流文档图像矫正方法。

Conclusion: BookNet为书籍图像矫正提供了首个端到端、有效建模双页关系的方法，并配套发布了合成和真实数据集，推动该领域研究发展。

Abstract: Book image rectification presents unique challenges in document image processing due to complex geometric distortions from binding constraints, where left and right pages exhibit distinctly asymmetric curvature patterns. However, existing single-page document image rectification methods fail to capture the coupled geometric relationships between adjacent pages in books. In this work, we introduce BookNet, the first end-to-end deep learning framework specifically designed for dual-page book image rectification. BookNet adopts a dual-branch architecture with cross-page attention mechanisms, enabling it to estimate warping flows for both individual pages and the complete book spread, explicitly modeling how left and right pages influence each other. Moreover, to address the absence of specialized datasets, we present Book3D, a large-scale synthetic dataset for training, and Book100, a comprehensive real-world benchmark for evaluation. Extensive experiments demonstrate that BookNet outperforms existing state-of-the-art methods on book image rectification. Code and dataset will be made publicly available.

</details>


### [74] [Deep Models, Shallow Alignment: Uncovering the Granularity Mismatch in Neural Decoding](https://arxiv.org/abs/2601.21948)
*Yang Du,Siyuan Dai,Yonghao Song,Paul M. Thompson,Haoteng Tang,Liang Zhan*

Main category: cs.CV

TL;DR: 该论文提出了一种新的对比学习策略——“浅层对齐”，用于将神经信号与视觉编码器的中间层表示进行对齐，从而在视觉解码任务中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 目前神经视觉解码领域的主流方法存在“粒度不匹配”问题：深度视觉模型倾向于捕捉语义不变性并抑制局部纹理信息，而脑信号本身则混合了低级特征和高级语义。为解决这一问题，作者希望找到更适合与神经信号对齐的机器视觉表征。

Method: 提出“浅层对齐”方法，用对比学习的策略，将神经信号和视觉模型的中间层特征对齐，而非传统的最终输出层。这样既保留了低级纹理信息，又能兼顾高级语义信息。通过多个视觉主干网络和基准数据集实验验证该方法有效性。

Result: 实验结果显示，浅层对齐相比于最终层对齐有22%-58%的性能提升，且随着视觉主干网络预训练能力提升，可以实现可预测的解码性能增长。

Conclusion: 浅层对齐能有效解决神经信号与机器视觉表征粒度不匹配问题，在神经视觉解码领域具有显著提升作用，并揭示了解码性能的可扩展性。

Abstract: Neural visual decoding is a central problem in brain computer interface research, aiming to reconstruct human visual perception and to elucidate the structure of neural representations. However, existing approaches overlook a fundamental granularity mismatch between human and machine vision, where deep vision models emphasize semantic invariance by suppressing local texture information, whereas neural signals preserve an intricate mixture of low-level visual attributes and high-level semantic content. To address this mismatch, we propose Shallow Alignment, a novel contrastive learning strategy that aligns neural signals with intermediate representations of visual encoders rather than their final outputs, thereby striking a better balance between low-level texture details and high-level semantic features. Extensive experiments across multiple benchmarks demonstrate that Shallow Alignment significantly outperforms standard final-layer alignment, with performance gains ranging from 22% to 58% across diverse vision backbones. Notably, our approach effectively unlocks the scaling law in neural visual decoding, enabling decoding performance to scale predictably with the capacity of pre-trained vision backbones. We further conduct systematic empirical analyses to shed light on the mechanisms underlying the observed performance gains.

</details>


### [75] [PaddleOCR-VL-1.5: Towards a Multi-Task 0.9B VLM for Robust In-the-Wild Document Parsing](https://arxiv.org/abs/2601.21957)
*Cheng Cui,Ting Sun,Suyin Liang,Tingquan Gao,Zelun Zhang,Jiaxuan Liu,Xueqing Wang,Changda Zhou,Hongen Liu,Manhui Lin,Yue Zhang,Yubo Zhang,Yi Liu,Dianhai Yu,Yanjun Ma*

Main category: cs.CV

TL;DR: PaddleOCR-VL-1.5 是一种升级版视觉语言模型，在OmniDocBench v1.5上取得94.5% SOTA准确率，并通过新提出的Real5-OmniDocBench基准验证其在各类物理干扰下的稳健性，同时支持印章识别和文本检测，且模型体积紧凑（0.9B）。


<details>
  <summary>Details</summary>
Motivation: 现有文档视觉理解模型在真实环境中的各种物理干扰（如扫描、倾斜、变形、拍摄、光照变化）下的鲁棒性不足，且部分任务（如印章识别、文本检测）覆盖不全。本文旨在提高模型鲁棒性、准确性、任务覆盖面，并兼顾模型效率。

Method: 1）升级PaddleOCR-VL-1.5模型结构和训练策略，实现高准确率。2）提出Real5-OmniDocBench新基准，囊括多种真实物理干扰。3）将印章识别与文本检测功能集成进统一架构。4）保持模型规模在0.9B参数，实现超紧凑高效。

Result: PaddleOCR-VL-1.5在OmniDocBench v1.5和Real5-OmniDocBench上均取得SOTA结果（准确率达94.5%），模型在多种真实场景扰动条件下表现出强鲁棒性，并成功扩展至印章识别和文本检测任务。

Conclusion: 文中提出的PaddleOCR-VL-1.5不仅显著提升了标准及新物理干扰基准的性能，还拓宽了任务范围且保持高效小体积，证明其在实际复杂环境下具有广泛应用潜力。

Abstract: We introduce PaddleOCR-VL-1.5, an upgraded model achieving a new state-of-the-art (SOTA) accuracy of 94.5% on OmniDocBench v1.5. To rigorously evaluate robustness against real-world physical distortions, including scanning, skew, warping, screen-photography, and illumination, we propose the Real5-OmniDocBench benchmark. Experimental results demonstrate that this enhanced model attains SOTA performance on the newly curated benchmark. Furthermore, we extend the model's capabilities by incorporating seal recognition and text spotting tasks, while remaining a 0.9B ultra-compact VLM with high efficiency. Code: https://github.com/PaddlePaddle/PaddleOCR

</details>


### [76] [Drive-JEPA: Video JEPA Meets Multimodal Trajectory Distillation for End-to-End Driving](https://arxiv.org/abs/2601.22032)
*Linhan Wang,Zichong Yang,Chen Bai,Guoxiang Zhang,Xiaotong Liu,Xiaoyin Zheng,Xiao-Xiao Long,Chang-Tien Lu,Cheng Lu*

Main category: cs.CV

TL;DR: 本文提出Drive-JEPA框架，结合V-JEPA视频自监督预训练和多模态轨迹蒸馏，显著提升端到端自动驾驶中的场景理解和规划表现，刷新多项指标最佳成绩。


<details>
  <summary>Details</summary>
Motivation: 当前端到端自动驾驶在利用自监督视频预训练学习可迁移的规划表征方面遇到瓶颈，主要原因包括视频世界模型对场景理解效果有限，以及每个驾驶场景通常只有单一真人轨迹，不利于学习多样化的驾驶行为。作者希望通过新架构弥补上述不足。

Method: 1）将V-JEPA视频联合嵌入预测架构（V-JEPA）适配至端到端自动驾驶任务，用大规模驾驶视频预训练ViT编码器，使其表征与轨迹规划一致；2）设计以提案为中心的规划器，通过动量感知的选择机制，将模拟器生成的多样化轨迹与真人轨迹一同蒸馏，从而训练更安全和鲁棒的行为。

Result: 在NAVSIM平台评估中，预训练得到的V-JEPA表征结合Transformer解码器，以3分PDMS优势超越无感知设定下的先前方法。完整版Drive-JEPA在v1和v2数据集分别达到93.3 PDMS和87.8 EPDMS，均获得新的SOTA。

Conclusion: Drive-JEPA通过结合视频自监督世界模型和多模态轨迹学习，有效提升端到端自动驾驶的泛化能力与安全性，验证了多源轨迹与先进视频表征的协同价值，在相关基准上取得了领先表现。

Abstract: End-to-end autonomous driving increasingly leverages self-supervised video pretraining to learn transferable planning representations. However, pretraining video world models for scene understanding has so far brought only limited improvements. This limitation is compounded by the inherent ambiguity of driving: each scene typically provides only a single human trajectory, making it difficult to learn multimodal behaviors. In this work, we propose Drive-JEPA, a framework that integrates Video Joint-Embedding Predictive Architecture (V-JEPA) with multimodal trajectory distillation for end-to-end driving. First, we adapt V-JEPA for end-to-end driving, pretraining a ViT encoder on large-scale driving videos to produce predictive representations aligned with trajectory planning. Second, we introduce a proposal-centric planner that distills diverse simulator-generated trajectories alongside human trajectories, with a momentum-aware selection mechanism to promote stable and safe behavior. When evaluated on NAVSIM, the V-JEPA representation combined with a simple transformer-based decoder outperforms prior methods by 3 PDMS in the perception-free setting. The complete Drive-JEPA framework achieves 93.3 PDMS on v1 and 87.8 EPDMS on v2, setting a new state-of-the-art.

</details>


### [77] [Understanding Multimodal Complementarity for Single-Frame Action Anticipation](https://arxiv.org/abs/2601.22039)
*Manuel Benavent-Lledo,Konstantinos Bacharidis,Konstantinos Papoutsakis,Antonis Argyros,Jose Garcia-Rodriguez*

Main category: cs.CV

TL;DR: 本文探讨了仅用单帧图像进行人体动作预判的可能性，通过丰富的互补信息和模块化设计，提出了AAG+体系，单帧下达到甚至超过时序视频方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前动作预判大多依赖连续视频，假设稠密时序信息不可或缺。本文质疑这一假设，探索单帧能承载多少未来信息及其利用方式。

Method: 作者基于先前的AAG方法，系统性分析了单帧下RGB外观、深度几何线索、语义化历史动作信息对预判的贡献，并研究了多模态融合、关键帧选择、历史信息来源等设计。基于总结出的有效策略，提出了AAG+单帧动作预判框架。

Result: AAG+在IKEA-ASM、Meccano、Assembly101等基准上，单帧输入下表现优于原AAG，达到或超过许多基于时序视频的先进方法。

Conclusion: 单帧动作预判具有意想不到的潜力，部分任务下可替代传统时序建模，并有助于明确何时需时序信息、何时单帧足矣。

Abstract: Human action anticipation is commonly treated as a video understanding problem, implicitly assuming that dense temporal information is required to reason about future actions. In this work, we challenge this assumption by investigating what can be achieved when action anticipation is constrained to a single visual observation. We ask a fundamental question: how much information about the future is already encoded in a single frame, and how can it be effectively exploited? Building on our prior work on Action Anticipation at a Glimpse (AAG), we conduct a systematic investigation of single-frame action anticipation enriched with complementary sources of information. We analyze the contribution of RGB appearance, depth-based geometric cues, and semantic representations of past actions, and investigate how different multimodal fusion strategies, keyframe selection policies and past-action history sources influence anticipation performance. Guided by these findings, we consolidate the most effective design choices into AAG+, a refined single-frame anticipation framework. Despite operating on a single frame, AAG+ consistently improves upon the original AAG and achieves performance comparable to, or exceeding, that of state-of-the-art video-based methods on challenging anticipation benchmarks including IKEA-ASM, Meccano and Assembly101. Our results offer new insights into the limits and potential of single-frame action anticipation, and clarify when dense temporal modeling is necessary and when a carefully selected glimpse is sufficient.

</details>


### [78] [UEval: A Benchmark for Unified Multimodal Generation](https://arxiv.org/abs/2601.22155)
*Bo Li,Yida Yin,Wenhao Chai,Xingyu Fu,Zhuang Liu*

Main category: cs.CV

TL;DR: 本文提出了UEval基准，用于评测同时具备文本和图像生成能力的统一模型，并引入基于细致评分标准的自动化评估体系，展示当前模型在复杂多模态生成任务上的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前多模态统一模型能实现文本与图像的联合生成，但缺乏能有效评估其能力的公开、细致的基准和评估体系。以往依靠大型多模态语言模型评判图像质量或文本准确性的方法存在不足，因此需要更丰富、更合理的评测手段。

Method: 作者构建了一个包含1000个由专家策划的问题集合，覆盖8个真实任务场景，每个问题要求模型输出图像和文本。每个问题通过结合参考图文和细致评分标准（rubric），再由专家修订、认证，总计生成10417条有效评分标准，用于自动化、细粒度地对模型输出进行打分。

Result: 在UEval基准上的测试显示，目前最好的闭源模型（如GPT-5-Thinking）得分为66.4/100，最好的开源模型仅得49.1/100。此外，带推理能力的模型明显优于不具推理能力的模型，并且转移推理痕迹可缩小两类模型间的性能差距。

Conclusion: 复杂的推理能力对于多模态统一模型完成高质量文本与图像联合生成任务极为重要。UEval为相关模型的发展和改进提供了标准化且细致的评测参考。

Abstract: We introduce UEval, a benchmark to evaluate unified models, i.e., models capable of generating both images and text. UEval comprises 1,000 expert-curated questions that require both images and text in the model output, sourced from 8 real-world tasks. Our curated questions cover a wide range of reasoning types, from step-by-step guides to textbook explanations. Evaluating open-ended multimodal generation is non-trivial, as simple LLM-as-a-judge methods can miss the subtleties. Different from previous works that rely on multimodal Large Language Models (MLLMs) to rate image quality or text accuracy, we design a rubric-based scoring system in UEval. For each question, reference images and text answers are provided to a MLLM to generate an initial rubric, consisting of multiple evaluation criteria, and human experts then refine and validate these rubrics. In total, UEval contains 10,417 validated rubric criteria, enabling scalable and fine-grained automatic scoring. UEval is challenging for current unified models: GPT-5-Thinking scores only 66.4 out of 100, while the best open-source model reaches merely 49.1. We observe that reasoning models often outperform non-reasoning ones, and transferring reasoning traces from a reasoning model to a non-reasoning model significantly narrows the gap. This suggests that reasoning may be important for tasks requiring complex multimodal understanding and generation.

</details>


### [79] [Urban Neural Surface Reconstruction from Constrained Sparse Aerial Imagery with 3D SAR Fusion](https://arxiv.org/abs/2601.22045)
*Da Li,Chen Yao,Tong Mao,Jiacheng Bao,Houjun Sun*

Main category: cs.CV

TL;DR: 本文针对城市大规模稀疏视角的三维重建难题，提出了一种结合三维合成孔径雷达(SAR)点云与航空图像的神经三维重建框架，能够在数据受限条件下实现高保真度城市重建。


<details>
  <summary>Details</summary>
Motivation: 城市大规模遥感三维重建时，受航线、地形和成本等限制，航空影像常为稀疏视角，导致现有神经表面重建(NSR)存在几何歧义和不稳定问题，限制实际应用。

Method: 创新性地将SAR点云数据与航空影像融合，利用SAR提供的强鲁棒先验和空间约束，嵌入SDF主干网络，实现结构感知的射线选择与自适应采样。并首创性构建了SAR点云与航空影像的配准数据集，用于跨模态三维重建系统性评测。

Result: 大量实验表明，融合3D SAR点云极大提升了重建准确性、完整性与鲁棒性，特别是在极稀疏和倾斜视角条件下，优于仅使用单一模态的基线方案。

Conclusion: 提出的光学-合成孔径雷达融合方法为大规模高保真城市三维重建提供了有效技术路径，推动了空基与天基三维遥感成像的实际应用。

Abstract: Neural surface reconstruction (NSR) has recently shown strong potential for urban 3D reconstruction from multi-view aerial imagery. However, existing NSR methods often suffer from geometric ambiguity and instability, particularly under sparse-view conditions. This issue is critical in large-scale urban remote sensing, where aerial image acquisition is limited by flight paths, terrain, and cost. To address this challenge, we present the first urban NSR framework that fuses 3D synthetic aperture radar (SAR) point clouds with aerial imagery for high-fidelity reconstruction under constrained, sparse-view settings. 3D SAR can efficiently capture large-scale geometry even from a single side-looking flight path, providing robust priors that complement photometric cues from images. Our framework integrates radar-derived spatial constraints into an SDF-based NSR backbone, guiding structure-aware ray selection and adaptive sampling for stable and efficient optimization. We also construct the first benchmark dataset with co-registered 3D SAR point clouds and aerial imagery, facilitating systematic evaluation of cross-modal 3D reconstruction. Extensive experiments show that incorporating 3D SAR markedly enhances reconstruction accuracy, completeness, and robustness compared with single-modality baselines under highly sparse and oblique-view conditions, highlighting a viable route toward scalable high-fidelity urban reconstruction with advanced airborne and spaceborne optical-SAR sensing.

</details>


### [80] [PLANING: A Loosely Coupled Triangle-Gaussian Framework for Streaming 3D Reconstruction](https://arxiv.org/abs/2601.22046)
*Changjian Jiang,Kerui Ren,Xudong Li,Kaiwen Song,Linning Xu,Tao Lu,Junting Dong,Yu Zhang,Bo Dai,Mulin Yu*

Main category: cs.CV

TL;DR: 本文提出了一种高效的单目图像序列流式三维重建框架——PLANING，其兼顾了高质量渲染和精准几何重建。该方法通过显式几何体与神经高斯的混合表示，实现了外观与几何的解耦在线优化，提升了重建精度和速度。


<details>
  <summary>Details</summary>
Motivation: 现有流式重建方法很难在高质量渲染和准确几何之间兼得，且多存在结构冗余和运算效率低下的问题。作者希望提出一种能同时提升渲染质量、几何精度和运算效率的新方法。

Method: 提出PLANING框架，通过显式的几何元件与神经高斯表达的松散耦合，实现对几何和外观的解耦建模。框架采用在线初始化与优化策略，分别更新几何和外观参数，提升流式重建的稳定性与效率。

Result: 在ScanNetV2等基准测试中，PLANING的稠密网格Chamfer-L2指标比PGSR提升18.52%，PSNR比ARTDECO提升1.31 dB。重建速度在100秒内，比2D Gaussian Splatting快5倍以上，并达到了离线优化的重建质量。

Conclusion: PLANING不仅显著提升了流式三维重建的质量和计算效率，还具备良好的结构清晰度，适合大规模场景建模及AI仿真等下游应用。

Abstract: Streaming reconstruction from monocular image sequences remains challenging, as existing methods typically favor either high-quality rendering or accurate geometry, but rarely both. We present PLANING, an efficient on-the-fly reconstruction framework built on a hybrid representation that loosely couples explicit geometric primitives with neural Gaussians, enabling geometry and appearance to be modeled in a decoupled manner. This decoupling supports an online initialization and optimization strategy that separates geometry and appearance updates, yielding stable streaming reconstruction with substantially reduced structural redundancy. PLANING improves dense mesh Chamfer-L2 by 18.52% over PGSR, surpasses ARTDECO by 1.31 dB PSNR, and reconstructs ScanNetV2 scenes in under 100 seconds, over 5x faster than 2D Gaussian Splatting, while matching the quality of offline per-scene optimization. Beyond reconstruction quality, the structural clarity and computational efficiency of \modelname~make it well suited for a broad range of downstream applications, such as enabling large-scale scene modeling and simulation-ready environments for embodied AI. Project page: https://city-super.github.io/PLANING/ .

</details>


### [81] [MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources](https://arxiv.org/abs/2601.22054)
*Baorui Ma,Jiahui Yang,Donglin Di,Xuancheng Zhang,Jianxun Cui,Hao Li,Yan Xie,Wei Chen*

Main category: cs.CV

TL;DR: 本文提出了Metric Anything框架，实现了大规模、通用的度量深度估计预训练，成功突破了因多元3D数据源带来的噪声、传感器偏差和度量歧义难题。基于近2000万组图像-深度对模型显示出显著的可扩展性趋势，在一系列深度相关任务（如深度补全、超分辨率等）和多模态大模型空间智能上均达到业界领先表现。


<details>
  <summary>Details</summary>
Motivation: 深度估计是计算机视觉中的核心任务，但受制于不同相机、传感器带来的噪声与系统性偏差，以及跨数据源的度量不一致等，传统的扩展方法难以适用于实际多样化环境。该工作旨在探索如何将基础模型在视觉领域的扩展范式应用到度量深度估计，解决由多样3D数据源带来的挑战。

Method: 提出了Sparse Metric Prompt的方法，即通过随机掩盖深度图，提供一个通用接口，从而解耦空间推理与传感器及相机偏差，无需为不同数据源特制架构。使用了约两千万对图像-深度数据，跨越重建、真实采集、渲染等不同3D数据源和一万种相机型号进行预训练。

Result: 预训练模型在深度补全、超分辨率、雷达-相机融合等任务中表现优异。经过蒸馏得到的无需Prompt的学生模型，在单目深度估计、相机内参恢复、单/多视图度量3D重建和VLA规划方面达到最新水平。在多模态大模型中，作为视觉编码器显著提升空间智能表现。

Conclusion: 度量深度估计同样可以受益于类似基础模型的规模扩展规律，为实现高效、可扩展的真实世界度量感知开辟新路径。

Abstract: Scaling has powered recent advances in vision foundation models, yet extending this paradigm to metric depth estimation remains challenging due to heterogeneous sensor noise, camera-dependent biases, and metric ambiguity in noisy cross-source 3D data. We introduce Metric Anything, a simple and scalable pretraining framework that learns metric depth from noisy, diverse 3D sources without manually engineered prompts, camera-specific modeling, or task-specific architectures. Central to our approach is the Sparse Metric Prompt, created by randomly masking depth maps, which serves as a universal interface that decouples spatial reasoning from sensor and camera biases. Using about 20M image-depth pairs spanning reconstructed, captured, and rendered 3D data across 10000 camera models, we demonstrate-for the first time-a clear scaling trend in the metric depth track. The pretrained model excels at prompt-driven tasks such as depth completion, super-resolution and Radar-camera fusion, while its distilled prompt-free student achieves state-of-the-art results on monocular depth estimation, camera intrinsics recovery, single/multi-view metric 3D reconstruction, and VLA planning. We also show that using pretrained ViT of Metric Anything as a visual encoder significantly boosts Multimodal Large Language Model capabilities in spatial intelligence. These results show that metric depth estimation can benefit from the same scaling laws that drive modern foundation models, establishing a new path toward scalable and efficient real-world metric perception. We open-source MetricAnything at http://metric-anything.github.io/metric-anything-io/ to support community research.

</details>


### [82] [Unsupervised Decomposition and Recombination with Discriminator-Driven Diffusion Models](https://arxiv.org/abs/2601.22057)
*Archer Wang,Emile Anand,Yilun Du,Marin Soljačić*

Main category: cs.CV

TL;DR: 本文提出了一种在无因子级监督下，通过扩散模型学习因子化潜空间的方法，用于分解复杂数据，提升组件重组生成质量和潜因子发现能力。作者引入对抗性判别器，提升生成样本物理和语义一致性。方法在多个数据集上优于现有基线，还首次将此方法用于机器人视频轨迹生成。


<details>
  <summary>Details</summary>
Motivation: 分解复杂数据为可重用组件，有助于理解和创造新样本。以往因子化学习通常依赖一定因子层级的监督，不利于实际应用。如何在无因子级监督下，高效发现潜因子并实现高质量组件重组，是该工作的核心动机。

Method: 作者基于扩散模型，设计了一种无监督因子空间学习框架。引入对抗性判别器，该判别器区分单一来源样本和来自不同来源的因子重组样本。生成器被优化以欺骗判别器，从而提升重组样本的自然性和一致性。该方法应用于图像（如背景、照明、属性）与视频（如运动分量）的场景。

Result: 在CelebA-HQ、Virtual KITTI、CLEVR、Falcor3D等基准数据集上，提出的方法取得更低的FID分数和更好的MIG、MCC指标，相较于以往方法有明显提升。在机器人视频任务中，通过重组动作组件，提高了样本多样性和状态空间覆盖，为探索任务带来优势。

Conclusion: 本研究无监督下有效发现潜因子，并提升因子级重组质量。该方法不仅在多个视觉任务上有表现提升，还首次扩展到机器人视频生成，展示出更广的应用潜力。

Abstract: Decomposing complex data into factorized representations can reveal reusable components and enable synthesizing new samples via component recombination. We investigate this in the context of diffusion-based models that learn factorized latent spaces without factor-level supervision. In images, factors can capture background, illumination, and object attributes; in robotic videos, they can capture reusable motion components. To improve both latent factor discovery and quality of compositional generation, we introduce an adversarial training signal via a discriminator trained to distinguish between single-source samples and those generated by recombining factors across sources. By optimizing the generator to fool this discriminator, we encourage physical and semantic consistency in the resulting recombinations. Our method outperforms implementations of prior baselines on CelebA-HQ, Virtual KITTI, CLEVR, and Falcor3D, achieving lower FID scores and better disentanglement as measured by MIG and MCC. Furthermore, we demonstrate a novel application to robotic video trajectories: by recombining learned action components, we generate diverse sequences that significantly increase state-space coverage for exploration on the LIBERO benchmark.

</details>


### [83] [Vision-DeepResearch: Incentivizing DeepResearch Capability in Multimodal Large Language Models](https://arxiv.org/abs/2601.22060)
*Wenxuan Huang,Yu Zeng,Qiuchen Wang,Zhen Fang,Shaosheng Cao,Zheng Chu,Qingyu Yin,Shuang Chen,Zhenfei Yin,Lin Chen,Zehui Chen,Yao Hu,Philip Torr,Feng Zhao,Wanli Ouyang*

Main category: cs.CV

TL;DR: 本文提出了一种新的多模态深度检索范式——Vision-DeepResearch，实现了多轮、多实体、多尺度的视觉与文本检索，在嘈杂环境下表现出色，显著超过当前主流多模态检索模型和闭源大模型。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型（MLLMs）在复杂场景下检索和推理能力有限，尤其在面对视觉噪声、需要跨模态搜索和整合丰富证据时，性能不足。以往方法假设简单查询能获得关键证据，这在现实中不切实际，且推理和检索能力深度有限。

Method: 提出Vision-DeepResearch方法，能够执行多轮、多实体和多尺度的视觉与文本联合检索，通过大量推理步骤和与搜索引擎的交互，结合冷启动监督和强化学习内化推理能力，形成端到端的深度跨模态检索体系。

Result: 该方法显著超越现有的多模态深度检索大模型，包括基于强大闭源模型（如GPT-5、Gemini-2.5-pro和Claude-4-Sonnet）搭建的工作流，在多个任务上取得最佳表现。

Conclusion: Vision-DeepResearch突破了多模态大模型对复杂问题的检索和推理瓶颈，在规模和性能上带来显著提升，推动多模态智能向更真实、复杂的应用场景演进。代码将于GitHub开源。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable success across a broad range of vision tasks. However, constrained by the capacity of their internal world knowledge, prior work has proposed augmenting MLLMs by ``reasoning-then-tool-call'' for visual and textual search engines to obtain substantial gains on tasks requiring extensive factual information. However, these approaches typically define multimodal search in a naive setting, assuming that a single full-level or entity-level image query and few text query suffices to retrieve the key evidence needed to answer the question, which is unrealistic in real-world scenarios with substantial visual noise. Moreover, they are often limited in the reasoning depth and search breadth, making it difficult to solve complex questions that require aggregating evidence from diverse visual and textual sources. Building on this, we propose Vision-DeepResearch, which proposes one new multimodal deep-research paradigm, i.e., performs multi-turn, multi-entity and multi-scale visual and textual search to robustly hit real-world search engines under heavy noise. Our Vision-DeepResearch supports dozens of reasoning steps and hundreds of engine interactions, while internalizing deep-research capabilities into the MLLM via cold-start supervision and RL training, resulting in a strong end-to-end multimodal deep-research MLLM. It substantially outperforming existing multimodal deep-research MLLMs, and workflows built on strong closed-source foundation model such as GPT-5, Gemini-2.5-pro and Claude-4-Sonnet. The code will be released in https://github.com/Osilly/Vision-DeepResearch.

</details>


### [84] [BLO-Inst: Bi-Level Optimization Based Alignment of YOLO and SAM for Robust Instance Segmentation](https://arxiv.org/abs/2601.22061)
*Li Zhang,Pengtao Xie*

Main category: cs.CV

TL;DR: 本文提出了BLO-Inst框架，采用双层优化方法实现检测器与分割模型目标对齐，将检测器训练为能为SAM生成更优分割掩码的提示生成器，显著提升了自动分割性能。


<details>
  <summary>Details</summary>
Motivation: 虽然 Segment Anything Model (SAM) 具备强大的零样本分割能力，但其需要手动提示，限制了自动化应用。现有用检测器自动生成提示的做法，存在检测器目标与分割模型需求（目标不匹配）和训练过度对齐（过拟合特定提示）的局限。

Method: 提出BLO-Inst，将检测和分割任务通过双层优化（bi-level optimization）紧密耦合。底层：在数据子集D1上，微调SAM以提升分割质量；顶层：在另一子集D2上，调整检测器，使所生成框能有效提高SAM在验证集的分割表现。这样优化检测器不只是为定位准确性，而是为下游分割效果。

Result: 实验结果表明，BLO-Inst在一般图像和生物医学图像分割任务上均显著优于标准方法和现有基线。

Conclusion: BLO-Inst通过检测器与分割器的目标对齐，实现高效的自动提示生成，克服了以往检测与分割目标割裂及过拟合的问题，是推进自动分割领域的重要方法。

Abstract: The Segment Anything Model has revolutionized image segmentation with its zero-shot capabilities, yet its reliance on manual prompts hinders fully automated deployment. While integrating object detectors as prompt generators offers a pathway to automation, existing pipelines suffer from two fundamental limitations: objective mismatch, where detectors optimized for geometric localization do not correspond to the optimal prompting context required by SAM, and alignment overfitting in standard joint training, where the detector simply memorizes specific prompt adjustments for training samples rather than learning a generalizable policy. To bridge this gap, we introduce BLO-Inst, a unified framework that aligns detection and segmentation objectives by bi-level optimization. We formulate the alignment as a nested optimization problem over disjoint data splits. In the lower level, the SAM is fine-tuned to maximize segmentation fidelity given the current detection proposals on a subset ($D_1$). In the upper level, the detector is updated to generate bounding boxes that explicitly minimize the validation loss of the fine-tuned SAM on a separate subset ($D_2$). This effectively transforms the detector into a segmentation-aware prompt generator, optimizing the bounding boxes not just for localization accuracy, but for downstream mask quality. Extensive experiments demonstrate that BLO-Inst achieves superior performance, outperforming standard baselines on tasks in general and biomedical domains.

</details>


### [85] [RefAny3D: 3D Asset-Referenced Diffusion Models for Image Generation](https://arxiv.org/abs/2601.22094)
*Hanzhuo Huang,Qingyang Bao,Zekai Gu,Zhongshuo Du,Cheng Lin,Yuan Liu,Sibei Yang*

Main category: cs.CV

TL;DR: 本文提出了一种结合3D资产的扩散模型，有效实现了利用3D资产生成与其一致的2D图像，扩展了基于参考的图像生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于参考图像的生成方法只支持单张图片作为参考，难以处理3D资产，实用性受限。为拓展模型对3D内容的处理能力，作者提出探索如何用3D资产指导图像生成。

Method: 提出了一个跨域的扩散模型，采用双分支结构，分别处理3D资产的多视图RGB图片和点云图。该方法通过空间对齐和域解耦机制，实现了RGB图像和点云的同步生成，并确保它们在空间内容上对齐但语义上解耦。

Result: 实验表明，该方法能够以3D资产为参考，生成与给定资产高度一致的图像，且生成的RGB图像与点云在空间一致性上表现优异。

Conclusion: 本文方法实现了3D资产到2D图像的高一致性生成，推动了扩散模型与3D内容生成的结合，为未来3D创作和图像生成开辟了新方向。

Abstract: In this paper, we propose a 3D asset-referenced diffusion model for image generation, exploring how to integrate 3D assets into image diffusion models. Existing reference-based image generation methods leverage large-scale pretrained diffusion models and demonstrate strong capability in generating diverse images conditioned on a single reference image. However, these methods are limited to single-image references and cannot leverage 3D assets, constraining their practical versatility. To address this gap, we present a cross-domain diffusion model with dual-branch perception that leverages multi-view RGB images and point maps of 3D assets to jointly model their colors and canonical-space coordinates, achieving precise consistency between generated images and the 3D references. Our spatially aligned dual-branch generation architecture and domain-decoupled generation mechanism ensure the simultaneous generation of two spatially aligned but content-disentangled outputs, RGB images and point maps, linking 2D image attributes with 3D asset attributes. Experiments show that our approach effectively uses 3D assets as references to produce images consistent with the given assets, opening new possibilities for combining diffusion models with 3D content creation.

</details>


### [86] [SINA: A Circuit Schematic Image-to-Netlist Generator Using Artificial Intelligence](https://arxiv.org/abs/2601.22114)
*Saoud Aldowaish,Yashwanth Karumanchi,Kai-Chen Chiang,Soroosh Noorzad,Morteza Fayazi*

Main category: cs.CV

TL;DR: SINA系统通过深度学习、CCL和OCR等多技术融合，实现了电路图像自动高精度转化为机读网表，准确率远超现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在组件识别和连通性推断上表现不佳，亟需提升自动化和准确率，以便高效处理电路原理图图像。

Method: SINA结合深度学习进行器件检测，利用连通分量标记(CCL)精准提取电气连接关系，通过OCR获取器件标号，并融合视觉-语言模型（VLM）以增强器件标号分配的可靠性。

Result: SINA在实验中，网表生成整体准确率达96.47%，相较当前最优方法提升2.72倍。

Conclusion: SINA极大提升了原理图到网表转换的自动化和准确率，为后续EDA自动化和相关研究打下坚实基础。

Abstract: Current methods for converting circuit schematic images into machine-readable netlists struggle with component recognition and connectivity inference. In this paper, we present SINA, an open-source, fully automated circuit schematic image-to-netlist generator. SINA integrates deep learning for accurate component detection, Connected-Component Labeling (CCL) for precise connectivity extraction, and Optical Character Recognition (OCR) for component reference designator retrieval, while employing a Vision-Language Model (VLM) for reliable reference designator assignments. In our experiments, SINA achieves 96.47% overall netlist-generation accuracy, which is 2.72x higher than state-of-the-art approaches.

</details>


### [87] [Creative Image Generation with Diffusion Model](https://arxiv.org/abs/2601.22125)
*Kunpeng Song,Ahmed Elgammal*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的创意图像生成框架，通过推动生成图片的分布向CLIP嵌入空间的低概率区域迁移，从而生成稀有且富有创意的高质量图片。


<details>
  <summary>Details</summary>
Motivation: 当前创意图像生成领域对创造性和高质量图片的需求日益增长，但以往方法多依赖手动概念混合或类别排除，难以自动化地探索全新视觉内容，因此需要一种更自动化且原理性的方法。

Method: 作者提出利用CLIP嵌入空间中图片存在的逆概率定义“创意性”，并在扩散模型生成过程中，通过计算生成图片的概率分布，将其引导到低概率区域。此外引入pullback机制，以保证在高创意性的同时不损失视觉真实感。

Result: 通过在文本到图像的扩散模型上进行大量实验，验证了该方法能高效地生成独特、新颖、引人深思的创意图片。

Conclusion: 该工作为生成模型中创意性的定义和提升提供了一种新视角，并提出了系统性方法，促进视觉内容创新，取得了良好效果。

Abstract: Creative image generation has emerged as a compelling area of research, driven by the need to produce novel and high-quality images that expand the boundaries of imagination. In this work, we propose a novel framework for creative generation using diffusion models, where creativity is associated with the inverse probability of an image's existence in the CLIP embedding space. Unlike prior approaches that rely on a manual blending of concepts or exclusion of subcategories, our method calculates the probability distribution of generated images and drives it towards low-probability regions to produce rare, imaginative, and visually captivating outputs. We also introduce pullback mechanisms, achieving high creativity without sacrificing visual fidelity. Extensive experiments on text-to-image diffusion models demonstrate the effectiveness and efficiency of our creative generation framework, showcasing its ability to produce unique, novel, and thought-provoking images. This work provides a new perspective on creativity in generative models, offering a principled method to foster innovation in visual content synthesis.

</details>


### [88] [EditYourself: Audio-Driven Generation and Manipulation of Talking Head Videos with Diffusion Transformers](https://arxiv.org/abs/2601.22127)
*John Flynn,Wolfgang Paier,Dimitar Dinev,Sam Nhut Nguyen,Hayk Poghosyan,Manuel Toribio,Sandipan Banerjee,Guy Gafni*

Main category: cs.CV

TL;DR: 该论文提出了一种名为EditYourself的新型音频驱动视频编辑框架，使得通过编辑台词即可对已有口播视频内容进行精准的增删和时序调整，并保持说话人身份、动作一致性和口型对齐。


<details>
  <summary>Details</summary>
Motivation: 当下生成式视频模型虽擅长文本和图片生成，却难以对预录视频进行局部微调，编辑台词常导致画面、动作或身份等丢失，实际应用场景比如视频后期制作中亟需解决。

Method: 作者基于DiT扩散模型提出EditYourself框架，融合了音频调控和区域感知训练机制，实现空间-时间填充（spatiotemporal inpainting），确保编辑区域口型同步、动作自然、视觉一致。

Result: 该方法允许对口播视频以转录文本为条件，精准地增加、删除和调整内容，同时生成新片段时动作连贯、说话人身份保持一致，支持长时段视频编辑。

Conclusion: EditYourself为现有生成式视频模型扩展出实用的视频后期编辑能力，推动其成为专业视频生产重要工具，对行业具有基础性意义。

Abstract: Current generative video models excel at producing novel content from text and image prompts, but leave a critical gap in editing existing pre-recorded videos, where minor alterations to the spoken script require preserving motion, temporal coherence, speaker identity, and accurate lip synchronization. We introduce EditYourself, a DiT-based framework for audio-driven video-to-video (V2V) editing that enables transcript-based modification of talking head videos, including the seamless addition, removal, and retiming of visually spoken content. Building on a general-purpose video diffusion model, EditYourself augments its V2V capabilities with audio conditioning and region-aware, edit-focused training extensions. This enables precise lip synchronization and temporally coherent restructuring of existing performances via spatiotemporal inpainting, including the synthesis of realistic human motion in newly added segments, while maintaining visual fidelity and identity consistency over long durations. This work represents a foundational step toward generative video models as practical tools for professional video post-production.

</details>


### [89] [Early and Prediagnostic Detection of Pancreatic Cancer from Computed Tomography](https://arxiv.org/abs/2601.22134)
*Wenxuan Li,Pedro R. A. S. Bassi,Lizhou Wu,Xinze Zhou,Yuxuan Zhao,Qi Chen,Szymon Plotka,Tianyu Lin,Zheren Zhu,Marisa Martin,Justin Caskey,Shanshan Jiang,Xiaoxi Chen,Jaroslaw B. Ćwikla,Artur Sankowski,Yaping Wu,Sergio Decherchi,Andrea Cavalli,Chandana Lall,Cristian Tomasetti,Yaxing Guo,Xuan Yu,Yuqing Cai,Hualin Qiao,Jie Bao,Chenhan Hu,Ximing Wang,Arkadiusz Sitek,Kai Ding,Heng Li,Meiyun Wang,Dexin Yu,Guang Zhang,Yang Yang,Kang Wang,Alan L. Yuille,Zongwei Zhou*

Main category: cs.CV

TL;DR: 本文开发了一个自动化AI系统ePAI，用于早期胰腺癌的CT影像检测，显著优于人类放射科医生，有望提高胰腺癌的早诊率。


<details>
  <summary>Details</summary>
Motivation: 胰腺癌早期无明显症状，往往发现时已不可手术且预后极差。虽然回溯分析显示许多早期病变在CT上可见，临床常被忽视。因此，急需提升早期胰腺癌的影像检测能力。

Method: 研究团队开发并训练了ePAI系统，利用1,598例患者CT影像进行单中心训练，并在1,009例患者内部测试。外部验证涵盖六中心共7,158名患者。系统评估靶点为早期（<2cm）和极早期（小至2mm/5mm）胰腺癌的自动识别与定位，并与30名放射科医生做对比。

Result: 内部测试中，ePAI检测肿瘤<2cm时AUC为0.939-0.999，灵敏度95.3%，特异度98.7%，最小检出肿瘤直径2mm；外部多中心AUC为0.918-0.945，灵敏度91.5%，特异度88.0%，可检出5mm肿瘤。ePAI在诊断前3-36个月的CT上比放射科医生提前347天发现癌灶，有效检出率为75/159。多阅片者对比试验中，ePAI灵敏度比医生高50.3%，特异度持平。

Conclusion: ePAI能有效早期检测胰腺癌，显著优于临床放射科医生，有较好多中心泛化能力。该系统有望成为临床辅助工具，提高胰腺癌早诊率，改善患者预后。

Abstract: Pancreatic ductal adenocarcinoma (PDAC), one of the deadliest solid malignancies, is often detected at a late and inoperable stage. Retrospective reviews of prediagnostic CT scans, when conducted by expert radiologists aware that the patient later developed PDAC, frequently reveal lesions that were previously overlooked. To help detecting these lesions earlier, we developed an automated system named ePAI (early Pancreatic cancer detection with Artificial Intelligence). It was trained on data from 1,598 patients from a single medical center. In the internal test involving 1,009 patients, ePAI achieved an area under the receiver operating characteristic curve (AUC) of 0.939-0.999, a sensitivity of 95.3%, and a specificity of 98.7% for detecting small PDAC less than 2 cm in diameter, precisely localizing PDAC as small as 2 mm. In an external test involving 7,158 patients across 6 centers, ePAI achieved an AUC of 0.918-0.945, a sensitivity of 91.5%, and a specificity of 88.0%, precisely localizing PDAC as small as 5 mm. Importantly, ePAI detected PDACs on prediagnostic CT scans obtained 3 to 36 months before clinical diagnosis that had originally been overlooked by radiologists. It successfully detected and localized PDACs in 75 of 159 patients, with a median lead time of 347 days before clinical diagnosis. Our multi-reader study showed that ePAI significantly outperformed 30 board-certified radiologists by 50.3% (P < 0.05) in sensitivity while maintaining a comparable specificity of 95.4% in detecting PDACs early and prediagnostic. These findings suggest its potential of ePAI as an assistive tool to improve early detection of pancreatic cancer.

</details>


### [90] [PI-Light: Physics-Inspired Diffusion for Full-Image Relighting](https://arxiv.org/abs/2601.22135)
*Zhexin Liang,Zhaoxi Chen,Yongwei Chen,Tianyi Wei,Tengfei Wang,Xingang Pan*

Main category: cs.CV

TL;DR: 本文提出了一种名为 PI-Light（π-Light）的基于物理启发扩散模型的全图像重光照方法，能够提升对真实场景的泛化能力和物理合理性，并在实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有全场景重光照方法面临获取大规模配对数据困难、物理合理性较差以及泛化性受限等挑战，且难以解决合成到真实场景的差距。作者旨在通过引入物理知识、改进网络设计来提升重光照任务的性能。

Method: 提出两阶段的物理启发扩散模型框架：包括批量感知注意力机制提升图像一致性、物理引导的神经渲染增强光照物理合理性、物理损失正则化训练方向增强泛化、以及构建多样化受控光照数据集。该方法支持在预训练扩散模型基础上高效微调。

Result: π-Light 能够在丰富的材质和不同场景下合成镜面高光和漫反射效果，对真实世界场景展示出比现有方法更好的泛化能力。

Conclusion: 物理启发和结构化约束显著提升了重光照方法的表现，π-Light 在真实图像编辑任务中具备更强的实用性和准确性，为后续相关研究和应用提供了有力支持。

Abstract: Full-image relighting remains a challenging problem due to the difficulty of collecting large-scale structured paired data, the difficulty of maintaining physical plausibility, and the limited generalizability imposed by data-driven priors. Existing attempts to bridge the synthetic-to-real gap for full-scene relighting remain suboptimal. To tackle these challenges, we introduce Physics-Inspired diffusion for full-image reLight ($π$-Light, or PI-Light), a two-stage framework that leverages physics-inspired diffusion models. Our design incorporates (i) batch-aware attention, which improves the consistency of intrinsic predictions across a collection of images, (ii) a physics-guided neural rendering module that enforces physically plausible light transport, (iii) physics-inspired losses that regularize training dynamics toward a physically meaningful landscape, thereby enhancing generalizability to real-world image editing, and (iv) a carefully curated dataset of diverse objects and scenes captured under controlled lighting conditions. Together, these components enable efficient finetuning of pretrained diffusion models while also providing a solid benchmark for downstream evaluation. Experiments demonstrate that $π$-Light synthesizes specular highlights and diffuse reflections across a wide variety of materials, achieving superior generalization to real-world scenes compared with prior approaches.

</details>


### [91] [Do VLMs Perceive or Recall? Probing Visual Perception vs. Memory with Classic Visual Illusions](https://arxiv.org/abs/2601.22150)
*Xiaoxiao Sun,Mingyang Li,Kun yuan,Min Woo Sun,Mark Endo,Shengguang Wu,Changlin Li,Yuhui Zhang,Zeyu Wang,Serena Yeung-Levy*

Main category: cs.CV

TL;DR: 本文提出VI-Probe框架，分析大型视觉-语言模型(VLMs)在视觉错觉上的感知与记忆机制，揭示其响应持续性的多样成因。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究发现VLMs在视觉错觉任务中对于图像变化缺乏敏感性，但对于其中原因尚不明确。作者希望通过系统化方法澄清VLMs是感知视觉变化，还是仅依赖记忆模式。

Method: 作者提出VI-Probe框架，通过可控的梯度扰动和视觉控制组，结合Polarity-Flip Consistency、Template Fixation Index等新指标，细致评估不同VLM的稳定性与敏感性，从而分离感知和回忆的贡献。

Result: 实验发现不同模型如GPT-5、Claude-Opus-4.1、Qwen表现出不同的响应持续性机制，如记忆覆盖、感知-记忆竞争和视觉处理能力限制等。

Conclusion: VLMs在视觉错觉任务中的表现不能归因于单一机制，需通过更细致的探测型评测揭示知识和对视觉变化的敏感度。这为未来模型理解与评估提供了新方向。

Abstract: Large Vision-Language Models (VLMs) often answer classic visual illusions "correctly" on original images, yet persist with the same responses when illusion factors are inverted, even though the visual change is obvious to humans. This raises a fundamental question: do VLMs perceive visual changes or merely recall memorized patterns? While several studies have noted this phenomenon, the underlying causes remain unclear. To move from observations to systematic understanding, this paper introduces VI-Probe, a controllable visual-illusion framework with graded perturbations and matched visual controls (without illusion inducer) that disentangles visually grounded perception from language-driven recall. Unlike prior work that focuses on averaged accuracy, we measure stability and sensitivity using Polarity-Flip Consistency, Template Fixation Index, and an illusion multiplier normalized against matched controls. Experiments across different families reveal that response persistence arises from heterogeneous causes rather than a single mechanism. For instance, GPT-5 exhibits memory override, Claude-Opus-4.1 shows perception-memory competition, while Qwen variants suggest visual-processing limits. Our findings challenge single-cause views and motivate probing-based evaluation that measures both knowledge and sensitivity to controlled visual change. Data and code are available at https://sites.google.com/view/vi-probe/.

</details>


### [92] [One-step Latent-free Image Generation with Pixel Mean Flows](https://arxiv.org/abs/2601.22158)
*Yiyang Lu,Susie Lu,Qiao Sun,Hanhong Zhao,Zhicheng Jiang,Xianbang Wang,Tianhong Li,Zhengyang Geng,Kaiming He*

Main category: cs.CV

TL;DR: 论文提出了一种名为pixel MeanFlow（pMF）的方法，实现了无需潜在空间的单步图像生成，在ImageNet上效果优异。


<details>
  <summary>Details</summary>
Motivation: 当前扩散/流模型常用多步采样和潜在空间，但最近的研究在缩减采样步数和移除潜在空间方面各自有所进展。作者希望真正实现无需潜在空间的单步生成，进一步突破现有模型的速度和效率瓶颈。

Method: 提出pixel MeanFlow（pMF）方法，将网络输出空间和损失空间分开设定。网络目标限定在低维的图像流形（即x预测），损失则在速度空间通过MeanFlow定义。两者之间通过简单变换关联。重点实现了单步、无潜在空间的生成。

Result: pMF在ImageNet 256x256分辨率下获得2.22 FID，在512x512分辨率下获得2.48 FID，展现了优异的单步、无潜在空间生成性能。

Conclusion: pMF方法推进了扩散/流生成模型技术，填补了该领域单步latent-free生成的空白，有助于该方向后续技术进步。

Abstract: Modern diffusion/flow-based models for image generation typically exhibit two core characteristics: (i) using multi-step sampling, and (ii) operating in a latent space. Recent advances have made encouraging progress on each aspect individually, paving the way toward one-step diffusion/flow without latents. In this work, we take a further step towards this goal and propose "pixel MeanFlow" (pMF). Our core guideline is to formulate the network output space and the loss space separately. The network target is designed to be on a presumed low-dimensional image manifold (i.e., x-prediction), while the loss is defined via MeanFlow in the velocity space. We introduce a simple transformation between the image manifold and the average velocity field. In experiments, pMF achieves strong results for one-step latent-free generation on ImageNet at 256x256 resolution (2.22 FID) and 512x512 resolution (2.48 FID), filling a key missing piece in this regime. We hope that our study will further advance the boundaries of diffusion/flow-based generative models.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [93] [DeepSearchQA: Bridging the Comprehensiveness Gap for Deep Research Agents](https://arxiv.org/abs/2601.20975)
*Nikita Gupta,Riju Chatterjee,Lukas Haas,Connie Tao,Andrew Wang,Chang Liu,Hidekazu Oiwa,Elena Gribovskaya,Jan Ackermann,John Blitzer,Sasha Goldshtein,Dipanjan Das*

Main category: cs.CL

TL;DR: 提出了一个新基准DeepSearchQA，用于评估智能体在多步骤信息检索任务中的能力，并发现现有最先进方法还有很大改进空间。


<details>
  <summary>Details</summary>
Motivation: 传统评测数据集主要聚焦于单一答案检索或广泛真实性验证，缺乏针对复杂多步骤信息检索任务的系统性评估。为推动更深层次、多步骤的信息检索能力研究，作者设计了新的评测集。

Method: 构建了包含900个任务、涵盖17个领域的DeepSearchQA数据集。这些任务强调系统化整合分散信息、去重与实体消歧、以及在开放搜索空间中合理判断停止检索的能力。每个任务被设计为依赖前序步骤的因果链，并基于开放互联网的客观答案，专为考察智能体的长周期规划与上下文保持能力。

Result: 对现有多种最先进智能体结构进行全面评测，发现它们在召回率与精确率之间存在显著取舍，表现出提前停止或过度涵盖、低置信度答案等多种失败模式，显示当前方法还有较大提升空间。

Conclusion: DeepSearchQA揭示了现有智能体在复杂信息检索任务中的不足，为未来研究提供了高价值的诊断工具和提升方向，对促进更强深度检索智能体的开发具有重要意义。

Abstract: We introduce DeepSearchQA, a 900-prompt benchmark for evaluating agents on difficult multi-step information-seeking tasks across 17 different fields. Unlike traditional benchmarks that target single answer retrieval or broad-spectrum factuality, DeepSearchQA features a dataset of challenging, handcrafted tasks designed to evaluate an agent's ability to execute complex search plans to generate exhaustive answer lists. This shift in design explicitly tests three critical, yet under-evaluated capabilities: 1) systematic collation of fragmented information from disparate sources, 2) de-duplication and entity resolution to ensure precision, and 3) the ability to reason about stopping criteria within an open-ended search space. Each task is structured as a causal chain, where discovering information for one step is dependent on the successful completion of the previous one, stressing long-horizon planning and context retention. All tasks are grounded in the open web with objectively verifiable answer sets. Our comprehensive evaluation of state-of-the-art agent architectures reveals significant performance limitations: even the most advanced models struggle to balance high recall with precision. We observe distinct failure modes ranging from premature stopping (under-retrieval) to hedging behaviors, where agents cast an overly wide net of low-confidence answers to artificially boost recall. These findings highlight critical headroom in current agent designs and position DeepSearchQA as an essential diagnostic tool for driving future research toward more robust, deep-research capabilities.

</details>


### [94] [asr_eval: Algorithms and tools for multi-reference and streaming speech recognition evaluation](https://arxiv.org/abs/2601.20992)
*Oleg Sedukhin,Andrey Kostin*

Main category: cs.CL

TL;DR: 本文改进了语音识别评估方法，引入了新的字符串对齐算法和多参考标注，并构建了新的俄语长语音测试集，同时提供了一套评估工具和统一代码框架。


<details>
  <summary>Details</summary>
Motivation: 现有语音识别评测方法在多参考标注及特殊语言（如非拉丁语、词形丰富的语言）处理能力有限，导致评估结果不理想，缺乏适应性。

Method: 提出支持多参考标注及任意长度插入、改进词对齐的字符串对齐算法；构建多参考俄语长语音测试集DiverseSpeech-Ru；对流行俄语测试集做多参考重标注，并研究模型对训练集标注的适应情况；开发用于流式识别评估与多转录本视觉对比的工具；提供统一调用接口与代码。

Result: 验证发现模型容易适应特定数据集的标注，导致评估指标虚高；新方法提升了对复杂语言和长语音的评测能力，并能直观比较多版本转录。

Conclusion: 改进后的评测方法和评估工具更适用于多参照复杂语言环境、长语音与流式场景，将促进更客观、公平的语音识别模型评测，代码会公开发布。

Abstract: We propose several improvements to the speech recognition evaluation. First, we propose a string alignment algorithm that supports both multi-reference labeling, arbitrary-length insertions and better word alignment. This is especially useful for non-Latin languages, those with rich word formation, to label cluttered or longform speech. Secondly, we collect a novel test set DiverseSpeech-Ru of longform in-the-wild Russian speech with careful multi-reference labeling. We also perform multi-reference relabeling of popular Russian tests set and study fine-tuning dynamics on its corresponding train set. We demonstrate that the model often adopts to dataset-specific labeling, causing an illusion of metric improvement. Based on the improved word alignment, we develop tools to evaluate streaming speech recognition and to align multiple transcriptions to compare them visually. Additionally, we provide uniform wrappers for many offline and streaming speech recognition models. Our code will be made publicly available.

</details>


### [95] [UrduBench: An Urdu Reasoning Benchmark using Contextually Ensembled Translations with Human-in-the-Loop](https://arxiv.org/abs/2601.21000)
*Muhammad Ali Shafique,Areej Mehboob,Layba Fiaz,Muhammad Usman Qadeer,Hamza Farooq*

Main category: cs.CL

TL;DR: 本文提出一种多翻译系统加人工验证的翻译框架，将主流推理与问答基准数据集翻译为乌尔都语，以支持对大语言模型（LLMs）在低资源语言推理能力的评测，并进行了全面实验证明框架有效。


<details>
  <summary>Details</summary>
Motivation: 目前LLMs在推理任务上表现强劲，但在低资源语言、特别是乌尔都语上的评测缺乏标准化基准，且现有评测多依赖机器翻译易损失语境与结构，影响准确性。

Method: 作者提出集成多翻译系统与人工审核的“上下文集成翻译框架”，用于将英语的MGSM、MATH-500、CommonSenseQA和OpenBookQA等主流基准集转化为乌尔都语，形成UrduBench，并采用不同提示策略，对多种推理与指令微调LLM进行评测和多维度分析。

Result: 实验分析揭示了模型在不同数据集、任务难度、架构、规模及跨语言一致性下的表现差异。特别是在多步推理和符号推理任务中，乌尔都语比其他任务挑战更大。同时，发现模型的“语言一致性”对推理稳定性至关重要。

Conclusion: 本文建立了一种可扩展、可标准化的乌尔都语推理评测流程，并为理解多语种推理失败机理提供了实证依据，相关工具适用于其他低资源语言。数据与代码将公开。

Abstract: Recent advances in large language models (LLMs) have led to strong reasoning capabilities; however, evaluating such models in low-resource languages remains challenging due to the lack of standardized benchmarks. In particular, Urdu reasoning evaluation has been limited by the sensitivity of machine translation and an emphasis on general language tasks rather than reasoning benchmarks. In this paper, we propose a contextually ensembled translation framework with human-in-the-loop validation that leverages multiple translation systems to develop Urdu reasoning benchmarks while preserving contextual and structural integrity. Using this framework, we translate widely adopted reasoning and question-answering benchmarks, including MGSM, MATH-500, CommonSenseQA, and OpenBookQA, into Urdu, collectively referred to as UrduBench, and conduct a comprehensive evaluation of both reasoning-oriented and instruction-tuned LLMs across multiple prompting strategies. Our analysis reveals performance differences across (1) four datasets, (2) five task difficulty levels, (3) diverse model architectures, (4) multiple model scaling settings, and (5) language consistency tests. We find that multi-step and symbolic reasoning tasks pose significant challenges in Urdu, and that stable language alignment is a critical prerequisite for robust reasoning. Overall, our work establishes a scalable methodology for standardized reasoning evaluation in Urdu and provides empirical insights into multilingual reasoning failures. This experimental setup is also broadly applicable to other low-resource languages. The code and datasets will be publicly released.

</details>


### [96] [Position-invariant Fine-tuning of Speech Enhancement Models with Self-supervised Speech Representations](https://arxiv.org/abs/2601.21084)
*Amit Meghanani,Thomas Hain*

Main category: cs.CL

TL;DR: 该论文探讨了基于自监督学习（SSL）语音模型与前端语音增强（SE）模型结合时在噪声环境下的下游任务表现，并重点分析了使用均方误差（MSE）损失进行微调的局限性，提出了两种解决策略以实现位置不变的微调。


<details>
  <summary>Details</summary>
Motivation: 常规的SE模型在微调时通常采用MSE损失函数对增强语音与干净语音的SSL表征进行训练，但MSE损失可能利用SSL模型的位置嵌入，导致微调偏向于位置相关特征而非内容相关信息，限制了性能。作者想解决这种自监督表征微调中的普遍性问题。

Method: 提出了两种策略：（1）零填充，将此前在SSL预训练中采用的零填充方式应用到微调阶段；（2）基于速度扰动结合软DTW损失的方法，用以鼓励模型学习位置不相关的表征。

Result: 实验结果显示，基于soft-DTW损失的策略可以更快收敛，并提升下游任务的性能，对比传统的MSE损失有明显优势。

Conclusion: SSL表征微调中，若仅依赖MSE损失易产生位置相关问题。通过引入位置不变的微调策略（如软DTW损失结合速度扰动），可以有效提升模型性能，优化自监督语音建模。

Abstract: Integrating front-end speech enhancement (SE) models with self-supervised learning (SSL)-based speech models is effective for downstream tasks in noisy conditions. SE models are commonly fine-tuned using SSL representations with mean squared error (MSE) loss between enhanced and clean speech. However, MSE is prone to exploiting positional embeddings in SSL models, allowing the objective to be minimised through positional correlations instead of content-related information. This work frames the problem as a general limitation of self-supervised representation fine-tuning and investigates it through representation-guided SE. Two strategies are considered: (1) zero-padding, previously explored in SSL pre-training but here examined in the fine-tuning setting, and (2) speed perturbations with a soft-DTW loss. Experiments show that the soft-DTW-based approach achieves faster convergence and improved downstream performance, underscoring the importance of position-invariant fine-tuning in SSL-based speech modelling.

</details>


### [97] [ChunkWise LoRA: Adaptive Sequence Partitioning for Memory-Efficient Low-Rank Adaptation and Accelerated LLM Inference](https://arxiv.org/abs/2601.21109)
*Ketan Thakkar,Maitreyi Chatterjee,Ramasubramanian Balasubramanian,Achyuthan Jootoo,Rajendra Ugrani*

Main category: cs.CL

TL;DR: 提出了一种新型的动态低秩适应方法ChunkWise LoRA，实现大语言模型高效微调，在降低延迟和内存消耗的同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA方法为所有输入token采用统一静态秩配置，未考虑token复杂性及计算需求的差异，导致效率或效果受限。

Method: 将输入序列按token复杂性划分为变长块，对每个块分配不同的LoRA秩，并通过运行时调度器评估token难度、动态分块和秩分配，进一步引入边界安全组合和KV-cache策略保障输出一致性。

Result: 在Wikitext-103、SQuAD等任务上，相较于传统LoRA，延迟降低最多34%，显存降低38%，且性能(BLEU、EM、perplexity)不降反升。

Conclusion: ChunkWise LoRA可完全兼容当前transformer架构与推理框架，为大模型部署带来更高效、实用的参数高效微调方案。

Abstract: Recent advances in low-rank adaptation (LoRA) have enabled efficient fine-tuning of large language models (LLMs) with minimal additional parameters. However, existing LoRA methods apply static rank configurations uniformly across all input tokens, ignoring variation in token complexity and computational requirements. In this work, we propose ChunkWise LoRA, a dynamic and adaptive approach that partitions sequences into variable-length chunks based on token complexity and assigns each chunk a tailored low-rank configuration. Our system introduces a runtime scheduler that estimates token difficulty, performs adaptive chunking, and selects per-chunk LoRA rank and scaling using a rank-ladder mechanism. To preserve output consistency, we further introduce a boundary-safe composition module and integrate policy-driven KV-cache strategies. Experiments on benchmark datasets such as Wikitext-103 and SQuAD demonstrate that ChunkWise LoRA achieves up to 34\% lower latency and 38% memory reduction compared to baseline LoRA, while maintaining or improving task performance metrics like BLEU, EM, and perplexity. The proposed framework remains fully compatible with existing transformer architectures and inference frameworks, providing a practical solution for real-world deployment of parameter-efficient LLMs.

</details>


### [98] [Multi-task Code LLMs: Data Mix or Model Merge?](https://arxiv.org/abs/2601.21115)
*Mingzhi Zhu,Boris Sobolev,Rahul Krishna,Raju Pavuluri,Stacy Patterson,Michele Merler*

Main category: cs.CL

TL;DR: 本文比较了两种构建小型多任务代码大语言模型的方法：数据混合与模型合并，并在多个模型家族和参数规模下进行了实验，发现模型合并在大规模模型下效果最好，数据混合则适用于小规模模型。


<details>
  <summary>Details</summary>
Motivation: 当前趋势是将小型、专用的代码大语言模型与前沿大模型一起应用到智能体框架中，但这需要高效的多任务学习方法平衡性能与成本。因此，探索适合各种约束和需求的高效多任务训练策略具有重要意义。

Method: 作者比较了两种小型多任务代码大模型的构建方法：数据混合（将不同任务数据混合后联合训练）与模型合并（分别微调后合并权重）。选用Qwen Coder与DeepSeek Coder两个系列、2B和7B两种参数规模的模型，在代码生成和代码摘要任务上进行了微调，并在HumanEval、MBPP和CodeXGlue三个基准上评测。还引入了权重分析方法分析不同任务对模型参数的影响。

Result: 实验显示，在较大模型规模（7B）时，模型合并方法在保留代码生成能力的同时可以保持摘要任务表现，整体性能最好，合并后的Qwen Coder 2.5 7B模型在HumanEval上Pass@1达到92.7%，超过单独微调模型。而在较小模型规模下，数据混合策略更优。

Conclusion: 针对资源受限的部署场景，采用精细的模型合并或数据混合策略，可以有效整合多任务能力且几乎无性能损失，是打造高效、多任务小型代码大模型的理想方案。

Abstract: Recent research advocates deploying smaller, specialized code LLMs in agentic frameworks alongside frontier models, sparking interest in efficient strategies for multi-task learning that balance performance, constraints, and costs. We compare two approaches for creating small, multi-task code LLMs: data mixing versus model merging. We conduct extensive experiments across two model families (Qwen Coder and DeepSeek Coder) at two scales (2B and 7B parameters), fine-tuning them for code generation and code summarization tasks. Our evaluation on HumanEval, MBPP, and CodeXGlue benchmarks reveals that model merging achieves the best overall performance at larger scale across model families, retaining 96% of specialized model performance on code generation tasks while maintaining summarization capabilities. Notably, merged models can even surpass individually fine-tuned models, with our best configuration of Qwen Coder 2.5 7B model achieving 92.7% Pass@1 on HumanEval compared to 90.9% for its task-specific fine-tuned equivalent. At a smaller scale we find instead data mixing to be a preferred strategy. We further introduce a weight analysis technique to understand how different tasks affect model parameters and their implications for merging strategies. The results suggest that careful merging and mixing strategies can effectively combine task-specific capabilities without significant performance degradation, making them ideal for resource-constrained deployment scenarios.

</details>


### [99] [Large Language Models Naively Recover Ethnicity from Individual Records](https://arxiv.org/abs/2601.21132)
*Noah Dasanaike*

Main category: cs.CL

TL;DR: 本文展示了大型语言模型（LLM）无须额外训练数据即可通过姓名推断族裔，精度超过现有的贝叶斯改良姓氏地理编码（BISG）方法，并且适用于全球多种场景。


<details>
  <summary>Details</summary>
Motivation: 传统的族裔推断方法如BISG主要针对美国、精度有限且有地域与类别局限，并在收入等方面存在系统性偏误。研究动机在于探索是否能用LLM更准确、更广泛地推断族裔及相关分类。

Method: 本文使用佛罗里达和北卡选民档案中的自报种族信息为样本，测试六种主流LLM（如Gemini 3 Flash、GPT-4o、DeepSeek等），并对不同模型、推理设定和加入元数据（如党派）等方式下的分类准确率进行对比，同时扩展验证至黎巴嫩、印度、乌干达等多国实际数据集。

Result: LLM推断精度最高可达84.7%，明显优于BISG的68.2%；加入元数据可达86.7%，并显著减少收入偏误。多国验证表明该方法可有效复现实际人口分布。在大规模应用场景下，利用LLM生成标签微调的小型模型同样超越BISG并支持本地化部署。

Conclusion: LLM能够以更高的精度和适应性推断族裔类别，优于现有主流方法，并为多国家、多类别、大规模族裔推断和数据公平性提供新工具和方案。

Abstract: I demonstrate that large language models can infer ethnicity from names with accuracy exceeding that of Bayesian Improved Surname Geocoding (BISG) without additional training data, enabling inference outside the United States and to contextually appropriate classification categories. Using stratified samples from Florida and North Carolina voter files with self-reported race, LLM-based classification achieves up to 84.7% accuracy, outperforming BISG (68.2%) on balanced samples. I test six models including Gemini 3 Flash, GPT-4o, and open-source alternatives such as DeepSeek v3.2 and GLM-4.7. Enabling extended reasoning can improve accuracy by 1-3 percentage points, though effects vary across contexts; including metadata such as party registration reaches 86.7%. LLM classification also reduces the income bias inherent in BISG, where minorities in wealthier neighborhoods are systematically misclassified as White. I further validate using Lebanese voter registration with religious sect (64.3% accuracy), Indian MPs from reserved constituencies (99.2%), and Indian land records with caste classification (74.0%). Aggregate validation across India, Uganda, Nepal, Armenia, Chile, and Costa Rica using original full-count voter rolls demonstrates that the method recovers known population distributions where naming conventions are distinctive. For large-scale applications, small transformer models fine-tuned on LLM labels exceed BISG accuracy while enabling local deployment at no cost.

</details>


### [100] [EnsembleLink: Accurate Record Linkage Without Training Data](https://arxiv.org/abs/2601.21138)
*Noah Dasanaike*

Main category: cs.CL

TL;DR: 本文提出了一种新的记录关联方法EnsembleLink，能够在无需标注数据的情况下高效准确地匹配跨数据集的同一实体，用于实证社会科学研究。


<details>
  <summary>Details</summary>
Motivation: 传统的记录关联方法普遍作为预处理步骤，缺乏对关联误差在后续分析中带来的不确定性的量化。已有方法要么准确率低，要么依赖大量有标签数据，制约了实际应用。

Method: 提出EnsembleLink方法，利用大规模语料预训练的语言模型，挖掘实体之间的语义关系，无需人工标注数据，通过集成模型自动完成高质量的实体匹配。

Result: 在城市名、个人名、组织、政党和书目记录等公共数据集上的实验证明，EnsembleLink的匹配准确率可与需要大量标注的现有方法相媲美甚至更优，且任务处理效率高。

Conclusion: EnsembleLink无需外部API、可本地运行，能够快速完成常见的记录关联任务，为实证社会科学等领域提供了一种高效、准确、低门槛的方法。

Abstract: Record linkage, the process of matching records that refer to the same entity across datasets, is essential to empirical social science but remains methodologically underdeveloped. Researchers treat it as a preprocessing step, applying ad hoc rules without quantifying the uncertainty that linkage errors introduce into downstream analyses. Existing methods either achieve low accuracy or require substantial labeled training data. I present EnsembleLink, a method that achieves high accuracy without any training labels. EnsembleLink leverages pre-trained language models that have learned semantic relationships (e.g., that "South Ozone Park" is a neighborhood in "New York City" or that "Lutte ouvriere" refers to the Trotskyist "Workers' Struggle" party) from large text corpora. On benchmarks spanning city names, person names, organizations, multilingual political parties, and bibliographic records, EnsembleLink matches or exceeds methods requiring extensive labeling. The method runs locally on open-source models, requiring no external API calls, and completes typical linkage tasks in minutes.

</details>


### [101] [Output-Space Search: Targeting LLM Generations in a Frozen Encoder-Defined Output Space](https://arxiv.org/abs/2601.21169)
*Tobias Materzok*

Main category: cs.CL

TL;DR: 本文提出了Output-Space Search (OS-Search)方法，将大语言模型（LLM）的生成过程转化为终点空间搜索，并在文本与代码生成任务上取得了更优的多样性和优化效果。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的序列生成（如文本创作、代码生成）依赖连续的自回归采样，难以高效探索多样或更优的输出，且受限于路径依赖。为实现更高效、更多样、易于并行的结果探索，需要摆脱传统逐token采样的限制。

Method: OS-Search通过固定编码器设计3D输出空间Z，外部循环在Z中选择目标点z*，利用检索加强的策略（经序列级RL训练）生成落在z*附近的输出，实现空间内平行探索和黑盒优化，无需遵循传统路径依赖的token或程序级搜索流程。

Result: 在文本生成任务（stories）中，对Z空间进行全面搜索，文本多样性比prompt-chaining提升3.1倍；在代码生成任务（code）中，基于Z空间的贝叶斯优化，在相同推理预算下提升了控制器未见目标的优化值，并且不影响生成代码的有效性。

Conclusion: OS-Search方法能够有效提升LLM输出的多样性和优化能力，突破了传统自回归采样的局限，适用于文本和代码等多种生成任务。

Abstract: We introduce Output-Space Search (OS-Search), which turns LLM generation into endpoint search. An outer loop selects a target z* in a frozen encoder-defined 3D output space Z, and a retrieval-grounded policy trained with sequence-level RL generates outputs whose coordinates land near z* under standard autoregressive decoding. This enables parallel sweeps and black-box optimization in Z without path-dependent token/program search. On stories, sweeping Z (text) yields 3.1x higher LLM-scored diversity than prompt-chaining. On code, Bayesian optimization over Z (code) improves an objective withheld from the controller under matched inference budgets while preserving validity.

</details>


### [102] [From Linear Input to Hierarchical Structure: Function Words as Statistical Cues for Language Learning](https://arxiv.org/abs/2601.21191)
*Xiulin Yang,Heidi Getz,Ethan Gotlieb Wilcox*

Main category: cs.CL

TL;DR: 本论文研究了从线性输入中学习层级结构的统计条件，发现功能词的某些分布特性对语言习得至关重要，并通过跨语言语料和神经网络实验验证了结论。


<details>
  <summary>Details</summary>
Motivation: 理解人类如何从线性语言输入中习得复杂的层级结构，对语言认知和人工智能语言建模都具有重要意义。功能词因其分布特性被认为关键，但其作用的统计基础尚不清楚。

Method: 作者首先通过跨186种语言的语料分析，验证功能词具备高频率、与句法结构密切相关和短语边界对齐三大分布特性。随后，采用反事实语言建模和消融实验，用神经学习器测试同时具备这些特性的语言变体的习得难易程度。

Result: 具备上述三大特性的语言变体更易被神经网络习得，其中频率和结构相关性的重要性高于边界对齐。进一步的探查发现，学习条件不同导致模型对功能词依赖方式不同，即相似表现背后可能机制截然不同。

Conclusion: 功能词的某些分布特性普遍存在于人类语言，并显著促进结构学习。不同学习条件下的习得机制可能不同，这为理解语言学习的多样性和人工神经网络的行为提供了新的视角。

Abstract: What statistical conditions support learning hierarchical structure from linear input? In this paper, we address this question by focusing on the statistical distribution of function words. Function words have long been argued to play a crucial role in language acquisition due to their distinctive distributional properties, including high frequency, reliable association with syntactic structure, and alignment with phrase boundaries. We use cross-linguistic corpus analysis to first establish that all three properties are present across 186 studied languages. Next, we use a combination of counterfactual language modeling and ablation experiments to show that language variants preserving all three properties are more easily acquired by neural learners, with frequency and structural association contributing more strongly than boundary alignment. Follow-up probing and ablation analyses further reveal that different learning conditions lead to systematically different reliance on function words, indicating that similar performance can arise from distinct internal mechanisms.

</details>


### [103] [Scaling Embeddings Outperforms Scaling Experts in Language Models](https://arxiv.org/abs/2601.21204)
*Hong Liu,Jiaqi Zhang,Chao Wang,Xing Hu,Linkun Lyu,Jiaqi Sun,Xurui Yang,Bo Wang,Fengcun Li,Yulei Qian,Lingtong Si,Yerui Sun,Rumei Li,Peng Pei,Yuchen Xie,Xunliang Cai*

Main category: cs.CL

TL;DR: 本文提出一种通过扩展嵌入层规模而不是MoE专家数量的新型稀疏扩展方法，有效提升了大模型推理速度与表现，以LongCat-Flash-Lite为实例展现其优越性。


<details>
  <summary>Details</summary>
Motivation: MoE架构在大规模语言模型中用于稀疏扩展已成主流，但随规模增长其回报递减且出现系统瓶颈。因此探索新的稀疏扩展方向以突破现有瓶颈。

Method: 系统分析嵌入扩展与专家扩展的性能，寻找最优扩展范式；细致评估模型宽度、深度等架构因素影响；结合系统优化与推断加速技术；最终基于这些原理训练了LongCat-Flash-Lite大模型。

Result: 发掘了在部分参数预算与架构设定下，嵌入扩展比专家扩展有更好的性能-效率折中。LongCat-Flash-Lite模型在参数等同情况下优于传统MoE模型，尤其在代理型与代码相关任务上表现突出。

Conclusion: 嵌入扩展是MoE稀疏扩展的有力补充，适当设计可带来更高效且更强的模型推理和表现，对于大语言模型研发具重要参考价值。

Abstract: While Mixture-of-Experts (MoE) architectures have become the standard for sparsity scaling in large language models, they increasingly face diminishing returns and system-level bottlenecks. In this work, we explore embedding scaling as a potent, orthogonal dimension for scaling sparsity. Through a comprehensive analysis and experiments, we identify specific regimes where embedding scaling achieves a superior Pareto frontier compared to expert scaling. We systematically characterize the critical architectural factors governing this efficacy -- ranging from parameter budgeting to the interplay with model width and depth. Moreover, by integrating tailored system optimizations and speculative decoding, we effectively convert this sparsity into tangible inference speedups. Guided by these insights, we introduce LongCat-Flash-Lite, a 68.5B parameter model with ~3B activated trained from scratch. Despite allocating over 30B parameters to embeddings, LongCat-Flash-Lite not only surpasses parameter-equivalent MoE baselines but also exhibits exceptional competitiveness against existing models of comparable scale, particularly in agentic and coding domains.

</details>


### [104] [Multilingual Dysarthric Speech Assessment Using Universal Phone Recognition and Language-Specific Phonemic Contrast Modeling](https://arxiv.org/abs/2601.21205)
*Eunjung Yeo,Julie M. Liss,Visar Berisha,David R. Mortensen*

Main category: cs.CL

TL;DR: 本文提出了一种多语种语音能力评估框架，能够跨多语言准确评估发音障碍患者（如构音障碍）的可懂度，并通过三个指标量化了不同层面的发音错误，展示了该方法的有效性和临床相关性。


<details>
  <summary>Details</summary>
Motivation: 现有的自动语音可懂度评估方法主要局限于单一语言或忽略了语言特异性因素，而神经疾病（如构音障碍）跨文化普遍存在，亟需一种通用于多语言的准确评估方法。

Method: 提出了一个集成通用音素识别与语言特异音素解释的多语种语音能力评估框架。方法包括对不同语言音素间映射、序列对齐和对比音系特征距离的计算，并定义了音素错误率（PER）、音系特征错误率（PFER）以及无序列对齐的新指标音素覆盖（PhonCov），在多种语言（英语、西班牙语、意大利语、泰米尔语）上进行了分析。

Result: 实验证明，PER在映射与对齐结合下表现最佳，PFER仅需对齐即可，PhonCov依赖映射。进一步分析显示，该框架捕捉到了与临床观察一致的、发音障碍中的典型可懂度退化模式。

Conclusion: 该框架兼顾语言通用性和语言特异性，能够为多语种下的语音障碍评估提供准确、具临床意义的定量指标，为实际语音障碍病人评估带来新工具。

Abstract: The growing prevalence of neurological disorders associated with dysarthria motivates the need for automated intelligibility assessment methods that are applicalbe across languages. However, most existing approaches are either limited to a single language or fail to capture language-specific factors shaping intelligibility. We present a multilingual phoneme-production assessment framework that integrates universal phone recognition with language-specific phoneme interpretation using contrastive phonological feature distances for phone-to-phoneme mapping and sequence alignment. The framework yields three metrics: phoneme error rate (PER), phonological feature error rate (PFER), and a newly proposed alignment-free measure, phoneme coverage (PhonCov). Analysis on English, Spanish, Italian, and Tamil show that PER benefits from the combination of mapping and alignment, PFER from alignment alone, and PhonCov from mapping. Further analyses demonstrate that the proposed framework captures clinically meaningful patterns of intelligibility degradation consistent with established observations of dysarthric speech.

</details>


### [105] [Scaling Reasoning Hop Exposes Weaknesses: Demystifying and Improving Hop Generalization in Large Language Models](https://arxiv.org/abs/2601.21214)
*Zhaoyi Li,Jiatong Li,Gangwei Jiang,Linqi Song,Defu Lian,Ying Wei*

Main category: cs.CL

TL;DR: 本文揭示了大语言模型在跨推理步数泛化场景中性能骤降的原因，发现特定注意力头对错误传播起主导作用，并提出了一种通过动态去激活这些注意力头的方法进行推理校正。


<details>
  <summary>Details</summary>
Motivation: 在链式思维（Chain-of-thought, CoT）推理中，大语言模型在需要超出训练分布推理步数（即更长推理链）的情形下表现显著下降，而其底层算法并未改变，原因尚不清楚。理解导致性能下降的内部机制，可为提升模型泛化能力提供关键线索。

Method: 作者系统性地分析了多个领域的任务，发现模型错误主要集中在少数关键token位置，而非均匀分布。进一步分析注意力机制，提出“错误处理头”（ep heads）概念，并通过实验发现去激活这些头可以恢复正确推理。基于此，提出了一种测试时动态识别并去激活ep heads的轻量级校正方法。

Result: 在多项任务和不同大语言模型上的大量实验表明，该方法可以显著提升模型在长推理链问题上的泛化性能。

Conclusion: 推理性能下滑主要由个别注意力头导致，动态去激活该类头是一种简单有效的泛化提升策略，对未来提升大语言模型推理稳健性、拓展其能力具有实际意义。

Abstract: Chain-of-thought (CoT) reasoning has become the standard paradigm for enabling Large Language Models (LLMs) to solve complex problems. However, recent studies reveal a sharp performance drop in reasoning hop generalization scenarios, where the required number of reasoning steps exceeds training distributions while the underlying algorithm remains unchanged. The internal mechanisms driving this failure remain poorly understood. In this work, we conduct a systematic study on tasks from multiple domains, and find that errors concentrate at token positions of a few critical error types, rather than being uniformly distributed. Closer inspection reveals that these token-level erroneous predictions stem from internal competition mechanisms: certain attention heads, termed erroneous processing heads (ep heads), tip the balance by amplifying incorrect reasoning trajectories while suppressing correct ones. Notably, removing individual ep heads during inference can often restore the correct predictions. Motivated by these insights, we propose test-time correction of reasoning, a lightweight intervention method that dynamically identifies and deactivates ep heads in the reasoning process. Extensive experiments across different tasks and LLMs show that it consistently improves reasoning hop generalization, highlighting both its effectiveness and potential.

</details>


### [106] [Parametric Knowledge is Not All You Need: Toward Honest Large Language Models via Retrieval of Pretraining Data](https://arxiv.org/abs/2601.21218)
*Christopher Adrian Kusuma,Muhammad Reza Qorib,Hwee Tou Ng*

Main category: cs.CL

TL;DR: 本文提出了一种更健壮的LLM诚实性评测基准数据集，以及一种利用预训练数据提升LLM诚实性的新方法。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLM）容易产生幻觉性（hallucination）回答，即在知识边界以外仍作答，导致生成不真实的信息。现有提升模型诚实性的方法评估不健全，因为没有考虑模型实际预训练中获得的知识。

Method: 基于Pythia（一种预训练数据完全公开的开源LLM），作者提出了一个新的评估基准数据集，并提出结合预训练数据的新方法用于训练更诚实的LLM。

Result: 构建出了更健壮的评测基准，有助于真实评估LLM在知识边界上的表现，同时初步方法显示利用预训练数据可以提升模型在诚实性上的表现。

Conclusion: 考虑预训练知识背景能更准确地评估和提升LLM的诚实性。基于公开数据建立的新数据集和方法为未来LLM的诚实性研究提供了新的方向。

Abstract: Large language models (LLMs) are highly capable of answering questions, but they are often unaware of their own knowledge boundary, i.e., knowing what they know and what they don't know. As a result, they can generate factually incorrect responses on topics they do not have enough knowledge of, commonly known as hallucination. Rather than hallucinating, a language model should be more honest and respond with "I don't know" when it does not have enough knowledge about a topic. Many methods have been proposed to improve LLM honesty, but their evaluations lack robustness, as they do not take into account the knowledge that the LLM has ingested during its pretraining. In this paper, we propose a more robust evaluation benchmark dataset for LLM honesty by utilizing Pythia, a truly open LLM with publicly available pretraining data. In addition, we also propose a novel method for harnessing the pretraining data to build a more honest LLM.

</details>


### [107] [MGSM-Pro: A Simple Strategy for Robust Multilingual Mathematical Reasoning Evaluation](https://arxiv.org/abs/2601.21225)
*Tianyi Xu,Kosei Uemura,Alfred Malengo Kondoro,Tadesse Destaw Belay,Catherine Nana Nyaah Essuman,Ifeoma Okoh,Ganiyat Afolabi,Ayodele Awokoya,David Ifeoluwa Adelani*

Main category: cs.CL

TL;DR: 该论文提出了MGSM-Pro数据集，用于多语言数学推理模型的更全面评测，尤其关注模型对数字变换情形下的稳健性。实验证明，模型在低资源语言和数字变换场景下性能显著下降，不同模型间鲁棒性存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 当前多语言数学推理评测数据集的难度和最新性与英文数据集存在差距，且先前只在英文中关注了同一问题不同实例下的高方差现象。亟需开发更复杂、可多语言评测的数据集，以真实反映各类模型在各种情境下的推理能力和稳健性。

Method: 提出MGSM-Pro数据集，将GSM-Symbolic方法扩展到MGSM，每个问题通过改变名字、数字、无关语境生成五种实例，并涵盖九种语言。通过对多语言、多实例的模型测试，分析了各大主流模型在数字变换下性能变化及鲁棒性。

Result: 实验显示，在与原测试集数字不同的实例上，许多低资源语言的模型表现大幅下降。Gemini 2.5 Flash和GPT-4.1等专有模型对数字变换敏感，而Claude 4.0 Sonnet更加鲁棒；开源模型GPT-OSS 120B和DeepSeek V3鲁棒性也更优。

Conclusion: 建议以后在数学推理任务的评测中，每道题至少采用五组不同数字实例，以更准确、鲁棒地评估模型性能。低资源语言和不同数字实例场景应引起高度重视。

Abstract: Large language models have made substantial progress in mathematical reasoning. However, benchmark development for multilingual evaluation has lagged behind English in both difficulty and recency. Recently, GSM-Symbolic showed a strong evidence of high variance when models are evaluated on different instantiations of the same question; however, the evaluation was conducted only in English. In this paper, we introduce MGSM-Pro, an extension of MGSM dataset with GSM-Symbolic approach. Our dataset provides five instantiations per MGSM question by varying names, digits and irrelevant context. Evaluations across nine languages reveal that many low-resource languages suffer large performance drops when tested on digit instantiations different from those in the original test set. We further find that some proprietary models, notably Gemini 2.5 Flash and GPT-4.1, are less robust to digit instantiation, whereas Claude 4.0 Sonnet is more robust. Among open models, GPT-OSS 120B and DeepSeek V3 show stronger robustness. Based on these findings, we recommend evaluating each problem using at least five digit-varying instantiations to obtain a more robust and realistic assessment of math reasoning.

</details>


### [108] [SHARP: Social Harm Analysis via Risk Profiles for Measuring Inequities in Large Language Models](https://arxiv.org/abs/2601.21235)
*Alok Abhishek,Tushar Bandopadhyay,Lisa Erickson*

Main category: cs.CL

TL;DR: 本文提出了一种新的用于大语言模型社会危害评估的多维分布感知框架SHARP，可更细致揭示模型在高风险社会场景下的潜在最坏风险及不同危害类型间差异。


<details>
  <summary>Details</summary>
Motivation: 现有的评测基准多采用简单均值分数，难以反映大语言模型在实际部署中低概率但高影响的失误，以及社会危害在不同维度（如偏见、公平、伦理、知识可靠性）上的复杂结构。

Method: 作者提出SHARP框架，将社会危害建模为多变量随机变量，显式分解为偏见、公平、伦理、知识可靠性等维度，并以累加的对数风险对失误进行聚合。同时采用风险敏感分布统计指标（如CVaR95）以抓取最坏事件的风险暴露。

Result: 在11个主流大模型和同一组901个敏感社会话题测试集上，SHARP显示均值风险类似的模型在极端风险暴露和波动性上可有两倍以上差异；各维度尾部风险也表现出模型相关的异构性，其中偏见维度的尾部风险最强，伦理维度最低。

Conclusion: 简单的均值分数掩盖了模型在不同危害类型和极端情况的真实表现。多维分布感知和尾部风险分析对负责任评估与治理大语言模型至关重要，呼吁行业采用更细致的风险画像方法。

Abstract: Large language models (LLMs) are increasingly deployed in high-stakes domains, where rare but severe failures can result in irreversible harm. However, prevailing evaluation benchmarks often reduce complex social risk to mean-centered scalar scores, thereby obscuring distributional structure, cross-dimensional interactions, and worst-case behavior. This paper introduces Social Harm Analysis via Risk Profiles (SHARP), a framework for multidimensional, distribution-aware evaluation of social harm. SHARP models harm as a multivariate random variable and integrates explicit decomposition into bias, fairness, ethics, and epistemic reliability with a union-of-failures aggregation reparameterized as additive cumulative log-risk. The framework further employs risk-sensitive distributional statistics, with Conditional Value at Risk (CVaR95) as a primary metric, to characterize worst-case model behavior. Application of SHARP to eleven frontier LLMs, evaluated on a fixed corpus of n=901 socially sensitive prompts, reveals that models with similar average risk can exhibit more than twofold differences in tail exposure and volatility. Across models, dimension-wise marginal tail behavior varies systematically across harm dimensions, with bias exhibiting the strongest tail severities, epistemic and fairness risks occupying intermediate regimes, and ethical misalignment consistently lower; together, these patterns reveal heterogeneous, model-dependent failure structures that scalar benchmarks conflate. These findings indicate that responsible evaluation and governance of LLMs require moving beyond scalar averages toward multidimensional, tail-sensitive risk profiling.

</details>


### [109] [MoCo: A One-Stop Shop for Model Collaboration Research](https://arxiv.org/abs/2601.21257)
*Shangbin Feng,Yuyang Bai,Ziyuan Yang,Yike Wang,Zhaoxuan Tan,Jiajie Yan,Zhenyu Lei,Wenxuan Ding,Weijia Shi,Haojin Wang,Zhenting Qi,Yuru Jiang,Heng Wang,Chengsong Huang,Yu Fei,Jihan Yao,Yilun Du,Luke Zettlemoyer,Yejin Choi,Yulia Tsvetkov*

Main category: cs.CL

TL;DR: 本文提出了MoCo，这是一个用于大规模执行、基准测试和比较多语言模型协作算法的Python库。MoCo集成了26种协作方法和25个评测数据集，实验显示协作策略在多数情况下优于单一模型。该工具包有助于推动AI协作研究。


<details>
  <summary>Details</summary>
Motivation: 单一语言模型能力有限，多模型协作能进一步提升AI性能，但此方向研究分散、缺乏系统性比较。因此，作者开发工具库MoCo，以统一标准支持相关研究，推动这一领域发展。

Method: 作者构建了MoCo库，支持包括路由、文本、logit及模型参数层面的26种协作方法，覆盖多样信息交互；引入25个权威评测数据集，支持用户自定义数据；通过系统化实验比较不同协作策略效果与效率。

Result: 大量实验证明，大多数协作策略在61%模型-数据组合中优于单一模型，最优策略提升高达25.8%；分析了不同协作方法的扩展性与效率，并证明协作系统能解决单模型难以处理的问题。

Conclusion: MoCo为模型协作研究提供了强大工具，有助于AI协作方法的标准化评测与快速进步，推动开放、模块化和去中心化AI发展。

Abstract: Advancing beyond single monolithic language models (LMs), recent research increasingly recognizes the importance of model collaboration, where multiple LMs collaborate, compose, and complement each other. Existing research on this topic has mostly been disparate and disconnected, from different research communities, and lacks rigorous comparison. To consolidate existing research and establish model collaboration as a school of thought, we present MoCo: a one-stop Python library of executing, benchmarking, and comparing model collaboration algorithms at scale. MoCo features 26 model collaboration methods, spanning diverse levels of cross-model information exchange such as routing, text, logit, and model parameters. MoCo integrates 25 evaluation datasets spanning reasoning, QA, code, safety, and more, while users could flexibly bring their own data. Extensive experiments with MoCo demonstrate that most collaboration strategies outperform models without collaboration in 61.0% of (model, data) settings on average, with the most effective methods outperforming by up to 25.8%. We further analyze the scaling of model collaboration strategies, the training/inference efficiency of diverse methods, highlight that the collaborative system solves problems where single LMs struggle, and discuss future work in model collaboration, all made possible by MoCo. We envision MoCo as a valuable toolkit to facilitate and turbocharge the quest for an open, modular, decentralized, and collaborative AI future.

</details>


### [110] [CausalEmbed: Auto-Regressive Multi-Vector Generation in Latent Space for Visual Document Embedding](https://arxiv.org/abs/2601.21262)
*Jiahao Huo,Yu Huang,Yibo Yan,Ye Pan,Yi Cao,Mingdong Ou,Philip S. Yu,Xuming Hu*

Main category: cs.CL

TL;DR: 提出了一种名为CausalEmbed的自动回归多向量生成方法，大幅减少视觉文档检索所需的token数量，同时保持强劲性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型在视觉文档检索中因生成大量视觉token，导致存储需求过大，限制了实际应用。

Method: 采用自动回归生成方式CausalEmbed，并在对比训练中引入迭代边际损失，促使模型学到更紧凑且结构良好的多向量表示。该方法只需少量的视觉token实现高效检索。

Result: 在各种主流模型和基准测试上，token数量减少30-155倍，同时保持了有竞争力的检索性能。理论与实验证明该方法在训练效率和推理扩展性上的优势。

Conclusion: CausalEmbed实现了多向量视觉文档检索的高效表示，显著减轻存储压力，并为多模态检索的生成式方法提供了新方向。

Abstract: Although Multimodal Large Language Models (MLLMs) have shown remarkable potential in Visual Document Retrieval (VDR) through generating high-quality multi-vector embeddings, the substantial storage overhead caused by representing a page with thousands of visual tokens limits their practicality in real-world applications. To address this challenge, we propose an auto-regressive generation approach, CausalEmbed, for constructing multi-vector embeddings. By incorporating iterative margin loss during contrastive training, CausalEmbed encourages the embedding models to learn compact and well-structured representations. Our method enables efficient VDR tasks using only dozens of visual tokens, achieving a 30-155x reduction in token count while maintaining highly competitive performance across various backbones and benchmarks. Theoretical analysis and empirical results demonstrate the unique advantages of auto-regressive embedding generation in terms of training efficiency and scalability at test time. As a result, CausalEmbed introduces a flexible test-time scaling strategy for multi-vector VDR representations and sheds light on the generative paradigm within multimodal document retrieval.

</details>


### [111] [Qwen3-ASR Technical Report](https://arxiv.org/abs/2601.21337)
*Xian Shi,Xiong Wang,Zhifang Guo,Yongqi Wang,Pei Zhang,Xinyu Zhang,Zishan Guo,Hongkun Hao,Yu Xi,Baosong Yang,Jin Xu,Jingren Zhou,Junyang Lin*

Main category: cs.CL

TL;DR: 本文介绍了Qwen3-ASR系列，包括两款多功能语音识别模型和一种新颖的非自回归语音强制对齐模型，支持52种语言与方言，并实现了业界领先的准确率与效率。


<details>
  <summary>Details</summary>
Motivation: 当前ASR（自动语音识别）模型在开源基准测试中分数差异较小，但在真实场景下表现有较大差异。此外，提升多语种ASR的识别准确率和处理效率，以及改进语音与文本对齐工具，具备极大的实际应用需求。

Method: 1. 构建了基于强大基础模型Qwen3-Omni的两款ASR模型（Qwen3-ASR-1.7B与Qwen3-ASR-0.6B），支持52种语言/方言，结合大规模语音数据训练。
2. 设计了一款LLM（大语言模型）驱动的非自回归语音强制对齐模型（Qwen3-ForcedAligner-0.6B），支持11种语言的文本-语音时间对齐。
3. 进行了全面的内部评测和标准开源基准测试，考察模型实际应用表现。

Result: Qwen3-ASR-1.7B在开源ASR模型中取得了SOTA（最优）性能，并可与最强商用API媲美；Qwen3-ASR-0.6B实现了最佳准确率与效率平衡，平均TTFT低至92ms，可在高并发下高速转录。Qwen3-ForcedAligner-0.6B在时间戳对齐准确率上超过现有三大对其模型，并具备更高效率与通用性。

Conclusion: Qwen3-ASR系列模型在多语种语音识别和语音-文本对齐任务中表现优异，兼具准确率、效率和通用性。模型已开源发布，为ASR与音频理解领域的社区研究与应用开发提供了有力工具。

Abstract: In this report, we introduce Qwen3-ASR family, which includes two powerful all-in-one speech recognition models and a novel non-autoregressive speech forced alignment model. Qwen3-ASR-1.7B and Qwen3-ASR-0.6B are ASR models that support language identification and ASR for 52 languages and dialects. Both of them leverage large-scale speech training data and the strong audio understanding ability of their foundation model Qwen3-Omni. We conduct comprehensive internal evaluation besides the open-sourced benchmarks as ASR models might differ little on open-sourced benchmark scores but exhibit significant quality differences in real-world scenarios. The experiments reveal that the 1.7B version achieves SOTA performance among open-sourced ASR models and is competitive with the strongest proprietary APIs while the 0.6B version offers the best accuracy-efficiency trade-off. Qwen3-ASR-0.6B can achieve an average TTFT as low as 92ms and transcribe 2000 seconds speech in 1 second at a concurrency of 128. Qwen3-ForcedAligner-0.6B is an LLM based NAR timestamp predictor that is able to align text-speech pairs in 11 languages. Timestamp accuracy experiments show that the proposed model outperforms the three strongest force alignment models and takes more advantages in efficiency and versatility. To further accelerate the community research of ASR and audio understanding, we release these models under the Apache 2.0 license.

</details>


### [112] [Self-Improving Pretraining: using post-trained models to pretrain better models](https://arxiv.org/abs/2601.21343)
*Ellen Xiaoqing Tan,Shehzaad Dhuliawala,Jing Xu,Ping Yu,Sainbayar Sukhbaatar,Jason Weston,Olga Golovneva*

Main category: cs.CL

TL;DR: 本文提出了一种新的预训练方法，通过文档流式输入和强化学习来提升大语言模型生成内容的安全性、事实性和整体质量。该方法在每一步对生成的候选内容进行甄别和奖励，有效改善模型表现。实验结果显示，该方法在事实性、安全性和生成质量上均远优于传统预训练。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在实际应用中的普及，保证其输出结果的安全、真实和高质量变得十分重要。然而，现有方法主要依赖于高成本的数据收集和多阶段微调，难以根除预训练期间形成的不良模式。因此，研究如何在预训练阶段直接解决质量与安全性问题具有重要意义。

Method: 作者提出了一种新的预训练流程：利用文档流式输入，并在每一步通过强化学习优化接下来生成的K个token。一个性能很强的后训练模型对候选生成内容（包括模型自身的连续生成、原始后缀和重写后缀）在质量、安全和事实性维度上进行评判并提供反馈。训练初期更依赖原始与重写后缀，随着模型能力提升逐渐转而奖励高质量的模型自身生成。

Result: 实验结果表明，该方法在事实性和安全性上分别较传统预训练提升了36.2%和18.5%，在生成质量整体上最高提升86.3%的胜率。

Conclusion: 通过强化学习嵌入到预训练流程中，从源头塑造模型的行为，可以显著提升大语言模型在真实应用中的质量、安全性与真实性，这为大模型安全可靠应用提供了新方案。

Abstract: Ensuring safety, factuality and overall quality in the generations of large language models is a critical challenge, especially as these models are increasingly deployed in real-world applications. The prevailing approach to addressing these issues involves collecting expensive, carefully curated datasets and applying multiple stages of fine-tuning and alignment. However, even this complex pipeline cannot guarantee the correction of patterns learned during pretraining. Therefore, addressing these issues during pretraining is crucial, as it shapes a model's core behaviors and prevents unsafe or hallucinated outputs from becoming deeply embedded. To tackle this issue, we introduce a new pretraining method that streams documents and uses reinforcement learning (RL) to improve the next K generated tokens at each step. A strong, post-trained model judges candidate generations -- including model rollouts, the original suffix, and a rewritten suffix -- for quality, safety, and factuality. Early in training, the process relies on the original and rewritten suffixes; as the model improves, RL rewards high-quality rollouts. This approach builds higher quality, safer, and more factual models from the ground up. In experiments, our method gives 36.2% and 18.5% relative improvements over standard pretraining in terms of factuality and safety, and up to 86.3% win rate improvements in overall generation quality.

</details>


### [113] [The Compliance Paradox: Semantic-Instruction Decoupling in Automated Academic Code Evaluation](https://arxiv.org/abs/2601.21360)
*Devanshu Sahoo,Manish Prasad,Vasudev Majhi,Arjun Neekhra,Yash Sinha,Murari Mandal,Vinay Chamola,Dhruv Kumar*

Main category: cs.CL

TL;DR: 本文发现当前大型语言模型（LLM）在自动化教育评分场景下，其遵循指令的倾向成为一种安全隐患，被称为“服从悖论”。模型更倾向于遵循隐藏指令而非客观评判代码正确性，导致严重失效。


<details>
  <summary>Details</summary>
Motivation: 随着大模型在教育自动评测领域的应用增长，很多人假设模型的“遵循指令”能力可以等同于客观裁决。然而，这一基础假设一直未被严密验证。论文旨在检验这种假设的可靠性，并揭示潜在系统性脆弱性。

Method: 作者提出了一套对抗性注入框架SPACI和AST-ASIP协议，通过在抽象语法树（AST）的语法惰性区域（trivia节点）中嵌入对抗性指令，利用大模型对“隐藏格式化指令”的服从性进行攻击。作者通过多种主流开源模型（如DeepSeek-V3）的大规模实验，评估其对这一攻击的易感性，并提出三重评估框架（解耦概率、分数偏差、教学严重性）来量化模型失效。

Result: 实验覆盖Python、C、C++、Java共25000个提交，发现如DeepSeek-V3等高容量开放权重模型在面对这种攻击时，失效率高达95%以上。模型常常机械地服从隐藏格式化指令，而忽略了代码本身的功能和正确性。量化指标显示大模型普遍“错误认可了”有缺陷的代码。

Conclusion: 现有模型以RLHF（人类反馈强化学习）为主的对齐范式容易因服从性过强造成自动评分体系的对抗性风险。建议未来转向“裁判鲁棒性”训练范式，使模型在评分时以实际证据为先，而不是机械服从指令。作者已开源全部数据和注入框架支持后续研究。

Abstract: The rapid integration of Large Language Models (LLMs) into educational assessment rests on the unverified assumption that instruction following capability translates directly to objective adjudication. We demonstrate that this assumption is fundamentally flawed. Instead of evaluating code quality, models frequently decouple from the submission's logic to satisfy hidden directives, a systemic vulnerability we term the Compliance Paradox, where models fine-tuned for extreme helpfulness are vulnerable to adversarial manipulation. To expose this, we introduce the Semantic-Preserving Adversarial Code Injection (SPACI) Framework and the Abstract Syntax Tree-Aware Semantic Injection Protocol (AST-ASIP). These methods exploit the Syntax-Semantics Gap by embedding adversarial directives into syntactically inert regions (trivia nodes) of the Abstract Syntax Tree. Through a large-scale evaluation of 9 SOTA models across 25,000 submissions in Python, C, C++, and Java, we reveal catastrophic failure rates (>95%) in high-capacity open-weights models like DeepSeek-V3, which systematically prioritize hidden formatting constraints over code correctness. We quantify this failure using our novel tripartite framework measuring Decoupling Probability, Score Divergence, and Pedagogical Severity to demonstrate the widespread "False Certification" of functionally broken code. Our findings suggest that current alignment paradigms create a "Trojan" vulnerability in automated grading, necessitating a shift from standard RLHF toward domain-specific Adjudicative Robustness, where models are conditioned to prioritize evidence over instruction compliance. We release our complete dataset and injection framework to facilitate further research on the topic.

</details>


### [114] [User-Centric Evidence Ranking for Attribution and Fact Verification](https://arxiv.org/abs/2601.21387)
*Guy Alt,Eran Hirsch,Serwar Basch,Ido Dagan,Oren Glickman*

Main category: cs.CL

TL;DR: 该论文提出了“证据排序”新任务，以更有效地支持自然语言事实核查任务，提高信息的可读性和用户验证效率。作者设计了新的评测框架，并通过现有数据集验证方法和模型优缺点。


<details>
  <summary>Details</summary>
Motivation: 现有NLP中的事实核查系统，常因证据信息过少或冗余，导致用户验证效率低下和易出错。需要一种方式，让用户尽快获取足量有效证据，同时不遗漏所有可用证据。

Method: 作者提出两种排序方法（一是单次排序，二是增量式排序），并构建了融合多个数据集的评测基准。他们还设计了受信息检索指标启发的新评价体系，对多种模型（包含大语言模型和浅层模型）进行实验。

Result: 实验显示增量排序策略可更好地捕捉互补证据，且大语言模型优于浅层基线；但对证据的充分性与冗余还需进一步平衡。用户实验表明，证据排序方法能减少阅读负担并提升事实核查效果。

Conclusion: 证据排序这一新任务和方法能优化信息核查系统的可解释性与效率，有望引领更用户友好的信息核查方向。

Abstract: Attribution and fact verification are critical challenges in natural language processing for assessing information reliability. While automated systems and Large Language Models (LLMs) aim to retrieve and select concise evidence to support or refute claims, they often present users with either insufficient or overly redundant information, leading to inefficient and error-prone verification. To address this, we propose Evidence Ranking, a novel task that prioritizes presenting sufficient information as early as possible in a ranked list. This minimizes user reading effort while still making all available evidence accessible for sequential verification. We compare two approaches for the new ranking task: one-shot ranking and incremental ranking. We introduce a new evaluation framework, inspired by information retrieval metrics, and construct a unified benchmark by aggregating existing fact verification datasets. Extensive experiments with diverse models show that incremental ranking strategies better capture complementary evidence and that LLM-based methods outperform shallower baselines, while still facing challenges in balancing sufficiency and redundancy. Compared to evidence selection, we conduct a controlled user study and demonstrate that evidence ranking both reduces reading effort and improves verification. This work provides a foundational step toward more interpretable, efficient, and user-aligned information verification systems.

</details>


### [115] [Conversation for Non-verifiable Learning: Self-Evolving LLMs through Meta-Evaluation](https://arxiv.org/abs/2601.21464)
*Yuan Sui,Bryan Hooi*

Main category: cs.CL

TL;DR: 论文提出了CoNL框架，通过多智能体自博弈统一生成、评估和元评估，实现无需外部评判者即可优化大模型的生成与评价能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在创造性写作、对话和伦理推理等无法验证正确性的任务上，缺乏真实标签进行训练。以模型自身为评判者的方法受限于评判者本身的能力，若评判者无法识别优劣解，训练信号就不可靠，且容易产生评判偏差。因此，需要对评判者本身进行评价和提升（元评估）。

Method: 提出CoNL框架：让多个共享同一策略的智能体通过结构化对话，进行方案提出、批评和修正。批评若能促进方案改进，则给予诊断奖励，从而为元评估提供显式监督信号，实现生成与评判能力的联合优化，无需外部评判或真实标签。

Result: 在五个基准测试上，CoNL相较于只靠自激励的基线方法，取得了一致性提升，并且训练过程更加稳定。

Conclusion: CoNL能有效提升大模型在无监督任务上的生成与评价能力，为自我改进和元评估提供了一条可行路径，无需依赖外部评判者或人工标签。

Abstract: Training large language models (LLMs) for non-verifiable tasks, such as creative writing, dialogue, and ethical reasoning, remains challenging due to the absence of ground-truth labels. While LLM-as-Judge approaches offer a scalable alternative to human feedback, they face a fundamental limitation: performance is constrained by the evaluator's own quality. If the judge cannot recognize good solutions, it cannot provide useful training signals, and evaluation biases (e.g., favoring verbosity over quality) remain unaddressed. This motivates meta-evaluation: the ability to evaluate and improve the evaluator itself. We introduce CoNL, a framework that unifies generation, evaluation, and meta-evaluation through multi-agent self-play. Our key insight: critique quality can be measured by whether it helps others improve their solutions. In CoNL, multiple agents sharing the same policy engage in structured conversations to propose, critique, and revise solutions. Critiques that enable solution improvements earn a diagnostic reward, creating explicit supervision for meta-evaluation and enabling joint optimization of generation and judging capabilities through self-play, without external judges or ground truth. Experiments on five benchmarks show that CoNL achieves consistent improvements over self-rewarding baselines while maintaining stable training.

</details>


### [116] [SOUP: Token-level Single-sample Mix-policy Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2601.21476)
*Lei Yang,Wei Bi,Chenxi Sun,Renren Jin,Deyi Xiong*

Main category: cs.CL

TL;DR: 提出SOUP框架，在单样本内实现细粒度的on-policy与off-policy混合，有效提升语言模型后训练的探索性和性能。


<details>
  <summary>Details</summary>
Motivation: 已有的on-policy强化学习方法（如GRPO）在语言模型后训练中，由于采样多样性不足，容易探索有限、训练早饱和；现有off-policy混合方式又常导致策略失配和不稳定。

Method: 提出SOUP框架，在单个样本、token级别融合off-policy和on-policy。序列前缀用历史策略采样（off-policy），后续用当前策略继续生成（on-policy），并通过token级重要性权重实现稳定混合。

Result: 大量实验验证，SOUP在训练稳定性、探索性以及最终表现上均优于标准on-policy和现有off-policy方法。

Conclusion: SOUP这种单样本、细粒度的混合策略，为大模型RL提供了更优的训练途径，有效提升探索和最终性能。

Abstract: On-policy reinforcement learning (RL) methods widely used for language model post-training, like Group Relative Policy Optimization (GRPO), often suffer from limited exploration and early saturation due to low sampling diversity. While off-policy data can help, current approaches that mix entire trajectories cause significant policy mismatch and instability. In this work, we propose the $\textbf{S}$ingle-sample Mix-p$\textbf{O}$licy $\textbf{U}$nified $\textbf{P}$aradigm (SOUP), a framework that unifies off- and on-policy learning within individual samples at the token level. It confines off-policy influence to the prefix of a generated sequence sampled from historical policies, while the continuation is generated on-policy. Through token-level importance ratios, SOUP effectively leverages off-policy information while preserving training stability. Extensive experiments demonstrate that SOUP consistently outperforms standard on-policy training and existing off-policy extensions. Our further analysis clarifies how our fine-grained, single-sample mix-policy training can improve both exploration and final performance in LLM RL.

</details>


### [117] [DimStance: Multilingual Datasets for Dimensional Stance Analysis](https://arxiv.org/abs/2601.21483)
*Jonas Becker,Liang-Chih Yu,Shamsuddeen Hassan Muhammad,Jan Philip Wahle,Terry Ruas,Idris Abdulmumin,Lung-Hao Lee,Wen-Ni Liu,Tzu-Mi Lin,Zhe-Yu Xu,Ying-Lung Lin,Jin Wang,Maryam Ibrahim Mukhtar,Bela Gipp,Saif M. Mohammed*

Main category: cs.CL

TL;DR: 该论文提出以情感科学维度（愉悦度与唤醒度）建模立场检测，并发布了首个包含情感维度注释的多语种数据集DimStance。通过各种模型测试，验证了方法有效性，也指出了多语言任务中的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有立场检测任务通常将作者对某一主题的态度划分为简单的类别（如支持、中立、反对），然而实际表达中，情感态度更加细腻复杂。为更精准捕捉作者态度的细微差异，需要突破传统类别化标签，采用连续情感维度来细粒度建模立场。

Method: 提出以情感科学中广泛使用的两维度——愉悦度（valence，负到正）和唤醒度（arousal，平静到激动）对立场进行建模与注释。构建了DimStance多语言多领域数据集，包含五种语言、两大领域数据。设计了基于回归任务的评测方式，并对比了各种预训练及大语言模型在不同设置下的表现。分析了跨语言情感维度分布特点。

Result: 微调的大规模语言模型在情感维度回归任务中取得了较好效果，但低资源语言下仍面临挑战，基于token的生成方法存在一定局限性。

Conclusion: DimStance数据集为跨语言、情感感知的立场检测奠定了基础，有助于今后更细粒度的立场与情感分析研究，也为多语种模型的基准测试提供了资源。

Abstract: Stance detection is an established task that classifies an author's attitude toward a specific target into categories such as Favor, Neutral, and Against. Beyond categorical stance labels, we leverage a long-established affective science framework to model stance along real-valued dimensions of valence (negative-positive) and arousal (calm-active). This dimensional approach captures nuanced affective states underlying stance expressions, enabling fine-grained stance analysis. To this end, we introduce DimStance, the first dimensional stance resource with valence-arousal (VA) annotations. This resource comprises 11,746 target aspects in 7,365 texts across five languages (English, German, Chinese, Nigerian Pidgin, and Swahili) and two domains (politics and environmental protection). To facilitate the evaluation of stance VA prediction, we formulate the dimensional stance regression task, analyze cross-lingual VA patterns, and benchmark pretrained and large language models under regression and prompting settings. Results show competitive performance of fine-tuned LLM regressors, persistent challenges in low-resource languages, and limitations of token-based generation. DimStance provides a foundation for multilingual, emotion-aware, stance analysis and benchmarking.

</details>


### [118] [MURAD: A Large-Scale Multi-Domain Unified Reverse Arabic Dictionary Dataset](https://arxiv.org/abs/2601.21512)
*Serry Sibaee,Yasser Alhabashi,Nadia Sibai,Yara Farouk,Adel Ammar,Sawsan AlHalawani,Wadii Boulila*

Main category: cs.CL

TL;DR: 论文介绍了MURAD（多领域统一反向阿拉伯语词典）数据集，包含9万余组阿拉伯词语与标准定义对，覆盖多个学科。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语词汇丰富，涉及领域广泛，但大规模、精确的词汇-定义配对数据稀缺，限制了阿拉伯语自然语言处理和词典学研究的发展。

Method: 作者结合直接文本解析、光学字符识别和自动重建的方法，从权威参考文献及教育资源中提取词汇与定义，并进行标准化和领域标注，保证数据的准确性和覆盖广度。

Result: 构建并公开了MURAD数据集，包含96,243组词-定义及其来源领域，涵盖语言学、伊斯兰研究、数学、物理、心理学和工程等。

Conclusion: MURAD为阿拉伯语计算语言学和词典学研究提供了基础资源，促进了反向词典建模、语义检索和教育工具等应用，推动了阿拉伯语处理领域的发展和可复现性。

Abstract: Arabic is a linguistically and culturally rich language with a vast vocabulary that spans scientific, religious, and literary domains. Yet, large-scale lexical datasets linking Arabic words to precise definitions remain limited. We present MURAD (Multi-domain Unified Reverse Arabic Dictionary), an open lexical dataset with 96,243 word-definition pairs. The data come from trusted reference works and educational sources. Extraction used a hybrid pipeline integrating direct text parsing, optical character recognition, and automated reconstruction. This ensures accuracy and clarity. Each record aligns a target word with its standardized Arabic definition and metadata that identifies the source domain. The dataset covers terms from linguistics, Islamic studies, mathematics, physics, psychology, and engineering. It supports computational linguistics and lexicographic research. Applications include reverse dictionary modeling, semantic retrieval, and educational tools. By releasing this resource, we aim to advance Arabic natural language processing and promote reproducible research on Arabic lexical semantics.

</details>


### [119] [LMK > CLS: Landmark Pooling for Dense Embeddings](https://arxiv.org/abs/2601.21525)
*Meet Doshi,Aashka Trivedi,Vishwajeet Kumar,Parul Awasthy,Yulong Li,Jaydeep Sen,Radu Florian,Sachindra Joshi*

Main category: cs.CL

TL;DR: 本文提出了一种新的池化方法——Landmark (LMK) pooling，通过在序列中插入标记token并对其mean pooling，改进了对长文本和局部特征的表达，提升了长文本下的表示学习效果。


<details>
  <summary>Details</summary>
Motivation: 现有的池化方法如[CLS] token或者mean pooling存在不足，[CLS] token容易导致信息集中在序列开头，难以表现分散证据；而mean pooling容易稀释局部显著特征，影响短文本性能。作者希望解决这两个问题，提升建模性能。

Method: 作者提出LMK pooling方法：将序列分块，在每块之间插入landmark token，并用这些token的嵌入均值作为整体表示。这种方法兼顾局部显著特征和长文本中的信息分布。

Result: 实验证明，LMK pooling在短文本检索任务上与现有方法表现相当，在长文本检索等任务上有显著提升，且只引入极少的特殊token，计算开销小，可扩展性强。

Conclusion: LMK pooling是一种简单有效的替代现有池化方法的机制，尤其在长上下文任务中表现突出，且不会牺牲短上下文的性能，是实际可用并具有扩展性的方案。

Abstract: Representation learning is central to many downstream tasks such as search, clustering, classification, and reranking. State-of-the-art sequence encoders typically collapse a variable-length token sequence to a single vector using a pooling operator, most commonly a special [CLS] token or mean pooling over token embeddings. In this paper, we identify systematic weaknesses of these pooling strategies: [CLS] tends to concentrate information toward the initial positions of the sequence and can under-represent distributed evidence, while mean pooling can dilute salient local signals, sometimes leading to worse short-context performance. To address these issues, we introduce Landmark (LMK) pooling, which partitions a sequence into chunks, inserts landmark tokens between chunks, and forms the final representation by mean-pooling the landmark token embeddings. This simple mechanism improves long-context extrapolation without sacrificing local salient features, at the cost of introducing a small number of special tokens. We empirically demonstrate that LMK pooling matches existing methods on short-context retrieval tasks and yields substantial improvements on long-context tasks, making it a practical and scalable alternative to existing pooling methods.

</details>


### [120] [inversedMixup: Data Augmentation via Inverting Mixed Embeddings](https://arxiv.org/abs/2601.21543)
*Fanshuang Kong,Richong Zhang,Qiyu Sun,Zhijie Nie,Ting Deng,Chunming Hu*

Main category: cs.CL

TL;DR: 本文提出了inversedMixup方法，将Mixup的数据可控性与LLM（大语言模型）文本生成的可读性结合，实现可控比率的人类可解释文本增强。


<details>
  <summary>Details</summary>
Motivation: 传统的Mixup方法在嵌入空间线性混合样本，但生成结果不可解释；而基于LLM的文本增强可生成可读句子却难以精细控制。为此，作者希望设计一种方法兼具可控性与可解释性，提升数据增强表现。

Method: inversedMixup分三步训练，将任务模型输出嵌入与LLM输入嵌入对齐。对齐后，可将混合嵌入转回人类可读文本，实现可控比率文本增强。同时，首次实证揭示了文本Mixup的流形入侵问题，并提出缓解策略。

Result: 大量实验表明inversedMixup在小样本和全监督场景下均有效且具有通用性。

Conclusion: inversedMixup方法兼具可控性和可解释性，显著提升了文本数据增强效果，并为后续文本Mixup研究提供了新见解和方法。

Abstract: Mixup generates augmented samples by linearly interpolating inputs and labels with a controllable ratio. However, since it operates in the latent embedding level, the resulting samples are not human-interpretable. In contrast, LLM-based augmentation methods produce sentences via prompts at the token level, yielding readable outputs but offering limited control over the generation process. Inspired by recent advances in LLM inversion, which reconstructs natural language from embeddings and helps bridge the gap between latent embedding space and discrete token space, we propose inversedMixup, a unified framework that combines the controllability of Mixup with the interpretability of LLM-based generation. Specifically, inversedMixup adopts a three-stage training procedure to align the output embedding space of a task-specific model with the input embedding space of an LLM. Upon successful alignment, inversedMixup can reconstruct mixed embeddings with a controllable mixing ratio into human-interpretable augmented sentences, thereby improving the augmentation performance. Additionally, inversedMixup provides the first empirical evidence of the manifold intrusion phenomenon in text Mixup and introduces a simple yet effective strategy to mitigate it. Extensive experiments demonstrate the effectiveness and generalizability of our approach in both few-shot and fully supervised scenarios.

</details>


### [121] [Note2Chat: Improving LLMs for Multi-Turn Clinical History Taking Using Medical Notes](https://arxiv.org/abs/2601.21551)
*Yang Zhou,Zhenting Sheng,Mingrui Tan,Yuting Song,Jun Zhou,Yu Heng Kwan,Lian Leng Low,Yang Bai,Yong Liu*

Main category: cs.CL

TL;DR: 本文提出了一种新方法，通过把真实的医疗笔记转化为高质量的医患对话，结合多阶段微调，以显著提升大语言模型在动态病史采集和诊断任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在静态医学基准测试表现突出，但在需要多轮问答和推理的动态临床环境下表现不足。现有对话数据稀缺且敏感，亟需更有效、可扩展的数据及训练方法来提升模型的真实临床推理能力。

Method: 1. 首先将真实医疗笔记转换为高质量的医患对话，采用决策树指导生成和优化流程。2. 设计三阶段微调策略：有监督学习、模拟数据增强和偏好学习。3. 提出单轮推理范式，将病史采集过程拆解为一系列单轮推理问题，从而提升可解释性与训练效率。

Result: 实验结果显示，所提方法在临床推理任务上性能大幅提升，较GPT-4o分别提升16.9点F1值和21.0点Top-1诊断准确率。

Conclusion: 通过创新性的数据转化、训练流程和推理框架，有效提升了大语言模型在动态临床历史采集和诊断中的表现，为临床AI应用带来新的思路和突破。

Abstract: Effective clinical history taking is a foundational yet underexplored component of clinical reasoning. While large language models (LLMs) have shown promise on static benchmarks, they often fall short in dynamic, multi-turn diagnostic settings that require iterative questioning and hypothesis refinement. To address this gap, we propose \method{}, a note-driven framework that trains LLMs to conduct structured history taking and diagnosis by learning from widely available medical notes. Instead of relying on scarce and sensitive dialogue data, we convert real-world medical notes into high-quality doctor-patient dialogues using a decision tree-guided generation and refinement pipeline. We then propose a three-stage fine-tuning strategy combining supervised learning, simulated data augmentation, and preference learning. Furthermore, we propose a novel single-turn reasoning paradigm that reframes history taking as a sequence of single-turn reasoning problems. This design enhances interpretability and enables local supervision, dynamic adaptation, and greater sample efficiency. Experimental results show that our method substantially improves clinical reasoning, achieving gains of +16.9 F1 and +21.0 Top-1 diagnostic accuracy over GPT-4o. Our code and dataset can be found at https://github.com/zhentingsheng/Note2Chat.

</details>


### [122] [ASTRA: Automated Synthesis of agentic Trajectories and Reinforcement Arenas](https://arxiv.org/abs/2601.21558)
*Xiaoyu Tian,Haotian Wang,Shuaiting Chen,Hao Zhou,Kaichi Yu,Yudian Zhang,Jade Ouyang,Junxi Yin,Jiong Chen,Baoyan Guo,Lei Zhang,Junjie Tao,Yuansheng Song,Ming Cui,Chengwei Liu*

Main category: cs.CL

TL;DR: ASTRA提出了一种全自动的工具增强型大模型训练框架，可合成多样任务轨迹和可验证的RL环境，实现SFT与RL结合，显著提升多步推理任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有工具增强型大模型训练存在需人工干预、依赖不可验证环境、方法单一（只用SFT或RL），且长序列任务表现不稳定等难题。

Method: ASTRA框架包含两大创新组件：1）基于工具调用图的轨迹合成，产生结构化多样任务路径，提升工具泛化能力；2）自动构建代码可执行、规则可验证的环境，将推理任务分解为可检测的RL环境，实现确定性多轮训练。训练方法综合SFT与在线RL，采用轨迹级奖励。

Result: 在多个工具使用基准测试上，ASTRA训练的模型在任务完成和交互效率上均取得SOTA表现，并能与主流闭源系统媲美，同时保留了核心推理能力。

Conclusion: ASTRA实现了自动化、可扩展、高效的多工具增强型大模型训练，推动工具型AI代理的能力上新台阶，并已开源全部流程和模型。

Abstract: Large language models (LLMs) are increasingly used as tool-augmented agents for multi-step decision making, yet training robust tool-using agents remains challenging. Existing methods still require manual intervention, depend on non-verifiable simulated environments, rely exclusively on either supervised fine-tuning (SFT) or reinforcement learning (RL), and struggle with stable long-horizon, multi-turn learning. To address these challenges, we introduce ASTRA, a fully automated end-to-end framework for training tool-augmented language model agents via scalable data synthesis and verifiable reinforcement learning. ASTRA integrates two complementary components. First, a pipeline that leverages the static topology of tool-call graphs synthesizes diverse, structurally grounded trajectories, instilling broad and transferable tool-use competence. Second, an environment synthesis framework that captures the rich, compositional topology of human semantic reasoning converts decomposed question-answer traces into independent, code-executable, and rule-verifiable environments, enabling deterministic multi-turn RL. Based on this method, we develop a unified training methodology that integrates SFT with online RL using trajectory-level rewards to balance task completion and interaction efficiency. Experiments on multiple agentic tool-use benchmarks demonstrate that ASTRA-trained models achieve state-of-the-art performance at comparable scales, approaching closed-source systems while preserving core reasoning ability. We release the full pipelines, environments, and trained models at https://github.com/LianjiaTech/astra.

</details>


### [123] [KromHC: Manifold-Constrained Hyper-Connections with Kronecker-Product Residual Matrices](https://arxiv.org/abs/2601.21579)
*Wuyang Zhou,Yuxuan Gu,Giorgos Iacovides,Danilo Mandic*

Main category: cs.CL

TL;DR: 本文提出了一种新的残差连接参数化方法KromHC，利用克罗内克积有效降低参数量，并保证精确的双随机性，在多个实验中达到或超越现有方法表现。


<details>
  <summary>Details</summary>
Motivation: 传统的超连接（HC）虽有提升，但训练不稳定且扩展性有限。已有的mHC方法通过投影获得部分改进，却在双随机性和参数复杂度上存在问题，急需更高效并能严格满足要求的新技术。

Method: KromHC用多个较小的双随机矩阵的克罗内克积参数化残差连接，同时在每个张量模式下施加流形约束，从而保证全局的双随机性，并将参数复杂度从阶乘级或三次方降低到二次方。并利用多组实验进行对比验证。

Result: KromHC不仅参数更少，而且实验中能达到甚至超过目前最优的mHC变种算法效果。

Conclusion: KromHC是一种高效且严谨的新型残差连接参数化方式，兼具参数高效性和准确性，有望成为大规模神经网络中的优选方案。

Abstract: The success of Hyper-Connections (HC) in neural networks (NN) has also highlighted issues related to its training instability and restricted scalability. The Manifold-Constrained Hyper-Connections (mHC) mitigate these challenges by projecting the residual connection space onto a Birkhoff polytope, however, it faces two issues: 1) its iterative Sinkhorn-Knopp (SK) algorithm does not always yield exact doubly stochastic residual matrices; 2) mHC incurs a prohibitive $\mathcal{O}(n^3C)$ parameter complexity with $n$ as the width of the residual stream and $C$ as the feature dimension. The recently proposed mHC-lite reparametrizes the residual matrix via the Birkhoff-von-Neumann theorem to guarantee double stochasticity, but also faces a factorial explosion in its parameter complexity, $\mathcal{O} \left( nC \cdot n! \right)$. To address both challenges, we propose \textbf{KromHC}, which uses the \underline{Kro}necker products of smaller doubly stochastic matrices to parametrize the residual matrix in \underline{mHC}. By enforcing manifold constraints across the factor residual matrices along each mode of the tensorized residual stream, KromHC guarantees exact double stochasticity of the residual matrices while reducing parameter complexity to $\mathcal{O}(n^2C)$. Comprehensive experiments demonstrate that KromHC matches or even outperforms state-of-the-art (SOTA) mHC variants, while requiring significantly fewer trainable parameters. The code is available at \texttt{https://github.com/wz1119/KromHC}.

</details>


### [124] [Language Models as Artificial Learners: Investigating Crosslinguistic Influence](https://arxiv.org/abs/2601.21587)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 本文利用语言模型（LMs）系统模拟双语者中的跨语言影响（CLI），以克服传统人类实验中的变异性问题，并探究影响CLI的机制。


<details>
  <summary>Details</summary>
Motivation: 人类关于跨语言影响（CLI）的实验研究结论常常矛盾，原因在于实验条件和被试的不可控因变量较多。为解决这些问题，作者希望借助可控的人工语言模型来深入剖析影响CLI的关键因素。

Method: 作者以语言模型作为受控统计学习者，通过调整L2（第二语言）接触年龄（即模型首次接触L2的训练步数）、L1主导度和L1与L2语法距离，系统考察上述变量对跨语言影响的作用。同时，利用跨语言启动范式深入分析L1结构对L2加工的影响。

Result: 实验发现，模型中的语言主导度与L2能力水平是CLI的重要预测因子，结果与心理语言学实证研究相符。语法结构的启动在两种语言间是双向的，但非语法结构的启动对语言主导度更加敏感。此外，实验证实L1在L2加工时被共同激活并直接影响L2的神经回路。

Conclusion: 本文首次以语言模型为计算框架，为探索人类跨语言影响提供了新方法，验证了相关心理语言学理论，并为未来理论建构和机制研究提供了工具。

Abstract: Despite the centrality of crosslinguistic influence (CLI) to bilingualism research, human studies often yield conflicting results due to inherent experimental variance. We address these inconsistencies by using language models (LMs) as controlled statistical learners to systematically simulate CLI and isolate its underlying drivers. Specifically, we study the effect of varying the L1 language dominance and the L2 language proficiency, which we manipulate by controlling the L2 age of exposure -- defined as the training step at which the L2 is introduced. Furthermore, we investigate the impact of pretraining on L1 languages with varying syntactic distance from the L2. Using cross-linguistic priming, we analyze how activating L1 structures impacts L2 processing. Our results align with evidence from psycholinguistic studies, confirming that language dominance and proficiency are strong predictors of CLI. We further find that while priming of grammatical structures is bidirectional, the priming of ungrammatical structures is sensitive to language dominance. Finally, we provide mechanistic evidence of CLI in LMs, demonstrating that the L1 is co-activated during L2 processing and directly influences the neural circuitry recruited for the L2. More broadly, our work demonstrates that LMs can serve as a computational framework to inform theories of human CLI.

</details>


### [125] [ILRR: Inference-Time Steering Method for Masked Diffusion Language Models](https://arxiv.org/abs/2601.21647)
*Eden Avrahami,Eliya Nachmani*

Main category: cs.CL

TL;DR: 本文提出了一种新的对离散扩散语言模型（DLM）进行推理时控制的无学习框架ILRR，通过与参考序列对齐生成序列的内部激活，有效实现了特定属性导向的文本生成。


<details>
  <summary>Details</summary>
Motivation: 尽管DLM在文本生成方面具有非自回归等优点，但如何在推理时高效、灵活地控制生成内容（如情感、风格）仍然缺乏有效机制。当前方法存在效率低或复杂性高等问题，因此亟需一种高效且易用的推理时控制方案。

Method: 作者提出ILRR（Iterative Latent Representation Refinement），通过在去噪过程中，将生成文本的内部激活动态对齐到参考序列，在无需额外训练的前提下，实现属性导向控制。还提出了Spatially Modulated Steering，对长文本可利用短参考，动态调节不同位置的引导强度。

Result: 在LLaDA和MDLM等架构上实验证明，ILRR在只需每步增加一次前向计算的前提下，属性准确率比相关基线提升10%到60%，生成质量基本保持不变。

Conclusion: ILRR为DLM的生成属性控制提供了一种高效、简单、易用的推理时方法，不依赖额外训练，兼具效果和效率，对未来DLM应用具有现实意义。

Abstract: Discrete Diffusion Language Models (DLMs) offer a promising non-autoregressive alternative for text generation, yet effective mechanisms for inference-time control remain relatively underexplored. Existing approaches include sampling-level guidance procedures or trajectory optimization mechanisms. In this work, we introduce Iterative Latent Representation Refinement (ILRR), a learning-free framework for steering DLMs using a single reference sequence. ILRR guides generation by dynamically aligning the internal activations of the generated sequence with those of a given reference throughout the denoising process. This approach captures and transfers high-level semantic properties, with a tunable steering scale enabling flexible control over attributes such as sentiment. We further introduce Spatially Modulated Steering, an extension that enables steering long texts using shorter references by regulating guidance intensity across the sequence. Empirically, we demonstrate that ILRR achieves effective attribute steering on LLaDA and MDLM architectures with a minor computational overhead, requiring only one additional parallel forward pass per denoising step. Under the same compute budget, ILRR improves attribute accuracy over comparable baselines by 10$\%$ to 60$\%$ points, while maintaining high generation quality.

</details>


### [126] [AdaptBPE: From General Purpose to Specialized Tokenizers](https://arxiv.org/abs/2601.21665)
*Vijini Liyanage,François Yvon*

Main category: cs.CL

TL;DR: 本文提出了一种针对特定领域或任务的轻量级分词器适应方法，通过替换现有分词表中的低效token，以提升分词效率与模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有如BPE等通用分词方法在领域特定任务中常表现出效率低下与表达力不足，原因在于分词表并未针对特定语料优化。

Method: 提出了一种基于适应语料库统计，筛选并用相关性更高token替代通用分词表中低价值token的算法，从而在保持词表规模固定的前提下实现分词器的领域自适应。

Result: 在多语言的生成和分类任务中，适应后的分词器在相同词表大小下，能更有效压缩测试语料，相较基线方法有显著提升。

Conclusion: 分词表轻量级后适应方法能像词表微调一样提升特定领域的分词效果，优化LLM的应用表现。

Abstract: Subword tokenization methods, such as Byte-Pair Encoding (BPE), significantly impact the performance and efficiency of large language models (LLMs). The standard approach involves training a general-purpose tokenizer that uniformly processes all textual data during both training and inference. However, the use of a generic set of tokens can incur inefficiencies when applying the model to specific domains or languages. To address this limitation, we propose a post-training adaptation strategy that selectively replaces low-utility tokens with more relevant ones based on their frequency in an adaptation corpus. Our algorithm identifies the token inventory that most effectively encodes the adaptation corpus for a given target vocabulary size. Extensive experiments on generation and classification tasks across multiple languages demonstrate that our adapted tokenizers compress test corpora more effectively than baselines using the same vocabulary size. This method serves as a lightweight adaptation mechanism, akin to a vocabulary fine-tuning process, enabling optimized tokenization for specific domains or tasks. Our code and data are available at https://github.com/vijini/Adapt-BPE.git.

</details>


### [127] [Scale-Dependent Semantic Dynamics Revealed by Allan Deviation](https://arxiv.org/abs/2601.21678)
*Debayan Dasgupta*

Main category: cs.CL

TL;DR: 本文借用精密计量学中的工具，定量分析文本语义的动态变化，揭示了创造性文学与技术文本之间在语义稳定性上的差异，并比较了人类文本与大型语言模型生成文本的特点。


<details>
  <summary>Details</summary>
Motivation: 尽管语言在语义上逐步推进，但其背后的动态规律尚不清楚。本文旨在通过将文本的语义进程视为高维状态空间中的随机轨迹，来量化和理解这种语义演化的动力学特征。

Method: 作者使用Allan deviation（阿伦偏差）这一源自精密计量学的分析工具，将有序的句子嵌入向量视为位移信号，来评估文本语义随时间推移的稳定性。他们将不同类型文本（如文学与技术文档）以及人类文本与大语言模型生成文本的语义变化进行对比分析。

Result: 1. 发现语义演化存在两种不同的动力学状态：短时尺度下呈现幂律特性，可区分创造性文学与技术文本；长时尺度则出现向噪声底限的交叉。2. 大语言模型在本地统计特征上能很好地模仿人类文本，但其语义稳定性持续时间系统性缩短。

Conclusion: 论文认为语义连贯性可作为可量化的物理属性，有助于区分人类认知活动与算法文本生成的动态特征，并为后者的改进提供了新的理论框架。

Abstract: While language progresses through a sequence of semantic states, the underlying dynamics of this progression remain elusive. Here, we treat the semantic progression of written text as a stochastic trajectory in a high-dimensional state space. We utilize Allan deviation, a tool from precision metrology, to analyze the stability of meaning by treating ordered sentence embeddings as a displacement signal. Our analysis reveals two distinct dynamical regimes: short-time power-law scaling, which differentiates creative literature from technical texts, and a long-time crossover to a stability-limited noise floor. We find that while large language models successfully mimic the local scaling statistics of human text, they exhibit a systematic reduction in their stability horizon. These results establish semantic coherence as a measurable physical property, offering a framework to differentiate the nuanced dynamics of human cognition from the patterns generated by algorithmic models.

</details>


### [128] [FIT: Defying Catastrophic Forgetting in Continual LLM Unlearning](https://arxiv.org/abs/2601.21682)
*Xiaoyu Xu,Minxin Du,Kun Fang,Zi Liang,Yaxin Xiao,Zhicong Huang,Cheng Hong,Qingqing Ye,Haibo Hu*

Main category: cs.CL

TL;DR: 该论文提出了一种针对大型语言模型持续性忘却（unlearning）的新框架FIT，有效应对大量、持续的数据删除请求，同时兼顾模型效用和遗忘强度。


<details>
  <summary>Details</summary>
Motivation: 目前的LLM遗忘方法很少考虑现实世界中海量且持续的数据删除请求。这些请求容易引发模型效用下降甚至灾难性遗忘，因此需要一种能够持续、稳定处理删除请求的机制。

Method: 提出了FIT框架，通过严格数据过滤（Filtering）、重要性感知更新（Importance-aware updates）和针对性层归因（Targeted layer attribution），在长序列遗忘操作中实现稳定的效用与忘却平衡。同时，开发了PCH基准集与两项对称指标（F.D.和R.U.）用于现实场景评测。

Result: 在对四个开源LLM以及数百个删除请求的实验中，FIT框架在遗忘程度（F.D.）与效用保留（R.U.）之间取得了最佳平衡，在MMLU、CommonsenseQA和GSM8K等任务上超过现有方法，并能抵抗重学习及量化恢复攻击。

Conclusion: FIT框架是一种有效且鲁棒的持续性遗忘方法，能够在满足大规模删除请求的同时保障模型性能，为实际大模型的数据合规和安全提供了可行方案。

Abstract: Large language models (LLMs) demonstrate impressive capabilities across diverse tasks but raise concerns about privacy, copyright, and harmful materials. Existing LLM unlearning methods rarely consider the continual and high-volume nature of real-world deletion requests, which can cause utility degradation and catastrophic forgetting as requests accumulate. To address this challenge, we introduce \fit, a framework for continual unlearning that handles large numbers of deletion requests while maintaining robustness against both catastrophic forgetting and post-unlearning recovery. \fit mitigates degradation through rigorous data \underline{F}iltering, \underline{I}mportance-aware updates, and \underline{T}argeted layer attribution, enabling stable performance across long sequences of unlearning operations and achieving a favorable balance between forgetting effectiveness and utility retention. To support realistic evaluation, we present \textbf{PCH}, a benchmark covering \textbf{P}ersonal information, \textbf{C}opyright, and \textbf{H}armful content in sequential deletion scenarios, along with two symmetric metrics, Forget Degree (F.D.) and Retain Utility (R.U.), which jointly assess forgetting quality and utility preservation. Extensive experiments on four open-source LLMs with hundreds of deletion requests show that \fit achieves the strongest trade-off between F.D. and R.U., surpasses existing methods on MMLU, CommonsenseQA, and GSM8K, and remains resistant against both relearning and quantization recovery attacks.

</details>


### [129] [Do Not Waste Your Rollouts: Recycling Search Experience for Efficient Test-Time Scaling](https://arxiv.org/abs/2601.21684)
*Xinglin Wang,Jiayi Shi,Shaoxiong Feng,Peiwen Yuan,Yiwei Li,Yueqi Zhang,Chuyi Tan,Ji Zhang,Boyuan Pan,Yao Hu,Kan Li*

Main category: cs.CL

TL;DR: 本文提出了一种新的推理加速方法RSE，通过回收搜索过程中的信息提升大模型推理效率。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型在推理时，为了提升准确率通常采用多次推理搜索（如Test-Time Scaling），但每次推理结果彼此独立，没有利用中间结论，导致重复推理与高计算冗余。本文旨在减少这种冗余、提升推理效率。

Method: 提出Recycling Search Experience (RSE)方法：在测试时搜集每次推理轨迹的信息，建立经验库。对于此前推导中的正向中间结论进行复用（positive recycling），对于失败模式进行负向复用以避免相同死路（negative recycling），从而将多次推理过程由独立变为累积优化。无需额外训练。还对方法的效率提升做了理论分析。

Result: 在HMMT24、HMMT25、IMO-Bench和HLE等复杂推理任务上广泛实验，RSE在相近的计算成本下表现优于强基线，推理效率达到最新水平。

Conclusion: RSE方法能显著减少大语言模型推理过程中的计算冗余，实现更高效的Test-Time Scaling，对复杂推理任务提升显著，有广泛应用潜力。

Abstract: Test-Time Scaling enhances the reasoning capabilities of Large Language Models by allocating additional inference compute to broaden the exploration of the solution space. However, existing search strategies typically treat rollouts as disposable samples, where valuable intermediate insights are effectively discarded after each trial. This systemic memorylessness leads to massive computational redundancy, as models repeatedly re-derive discovered conclusions and revisit known dead ends across extensive attempts. To bridge this gap, we propose \textbf{Recycling Search Experience (RSE)}, a self-guided, training-free strategy that turns test-time search from a series of isolated trials into a cumulative process. By actively distilling raw trajectories into a shared experience bank, RSE enables positive recycling of intermediate conclusions to shortcut redundant derivations and negative recycling of failure patterns to prune encountered dead ends. Theoretically, we provide an analysis that formalizes the efficiency gains of RSE, validating its advantage over independent sampling in solving complex reasoning tasks. Empirically, extensive experiments on HMMT24, HMMT25, IMO-Bench, and HLE show that RSE consistently outperforms strong baselines with comparable computational cost, achieving state-of-the-art scaling efficiency.

</details>


### [130] [Can David Beat Goliath? On Multi-Hop Reasoning with Resource-Constrained Agents](https://arxiv.org/abs/2601.21699)
*Hojae Han,Heeyun Jung,Jongyoon Kim,Seung-won Hwang*

Main category: cs.CL

TL;DR: 本文提出了一种高效强化学习框架DAVID-GRPO，使小规模语言模型在资源受限下依然能实现多跳推理，显著提升训练稳定性和准确率，超越了以往为大模型设计的RL方法。


<details>
  <summary>Details</summary>
Motivation: 现有多轮推理RL方法依赖于昂贵模型和大量采样，普通小模型在有限资源下难以取得好结果。作者旨在突破这一高成本-高准确度与低成本-低准确度间的权衡，实现小模型在实际场景下的高效推理。

Method: 提出DAVID-GRPO：1）用最小监督信号稳定早期学习；2）基于证据召回分配检索回馈；3）通过重采样截断的近似正确轨迹改善探索。用中等算力（四块3090，最多1.5B参数小模型）在六个多跳QA基准数据集验证方法。

Result: DAVID-GRPO在六个多跳QA数据集上全面优于现有为大模型或高资源设定设计的RL方法，实现了低训练成本下的高准确率。

Conclusion: 只要设计合适的归纳偏置，小模型同样能兼顾高准确与低算力，实现资源友好的多跳推理。

Abstract: While reinforcement learning (RL) has empowered multi-turn reasoning agents with retrieval and tools, existing successes largely depend on extensive on-policy rollouts in high-cost, high-accuracy regimes. Under realistic resource constraints that cannot support large models or dense explorations, however, small language model agents fall into a low-cost, low-accuracy regime, where limited rollout budgets lead to sparse exploration, sparse credit assignment, and unstable training. In this work, we challenge this trade-off and show that small language models can achieve strong multi-hop reasoning under resource constraints. We introduce DAVID-GRPO, a budget-efficient RL framework that (i) stabilizes early learning with minimal supervision, (ii) assigns retrieval credit based on evidence recall, and (iii) improves exploration by resampling truncated near-miss trajectories. Evaluated on agents up to 1.5B parameters trained on only four RTX 3090 GPUs, DAVID-GRPO consistently outperforms prior RL methods designed for large-scale settings on six multi-hop QA benchmarks. These results show that with the right inductive biases, small agents can achieve low training cost with high accuracy.

</details>


### [131] [Toward Culturally Aligned LLMs through Ontology-Guided Multi-Agent Reasoning](https://arxiv.org/abs/2601.21700)
*Wonduk Seo,Wonseok Choi,Junseo Koh,Juhyeon Lee,Hyunjin An,Minhyeong Yu,Jian Park,Qingshan Zhou,Seunghyun Lee,Yi Bu*

Main category: cs.CL

TL;DR: 本文提出了一种基于本体指导的多智能体推理框架（OG-MAR），通过构建文化本体与多代理协作，提升大语言模型在文化敏感决策中的对齐性和解释性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型常因预训练数据偏见和缺乏结构化价值观表达而导致文化决策不准确，现有方法难以处理受众人口统计多样性，且对价值观处理零散缺乏结构性，影响决策一致性和可解释性。

Method: 提出OG-MAR框架：利用世界价值观调查（WVS）总结个体特定价值观，并通过能力问题在固定分类法下提取价值观关系构建全球文化本体；推理阶段，检索本体一致关系与人口统计相似画像，生成多个价值-人格代理的推理，最终由总审代理整合结果，保证本体一致性与人口统计相关性。

Result: 在四个不同LLM模型框架及区域社会问卷基准测试上，OG-MAR表现出优于对比基线的文化对齐性、健壮性，并生成了更为清晰的推理过程。

Conclusion: OG-MAR方法有效提升了大语言模型在文化敏感任务中的对齐性和解释性，展示了本体约束和多智能体协作在价值观建模中的应用潜力。

Abstract: Large Language Models (LLMs) increasingly support culturally sensitive decision making, yet often exhibit misalignment due to skewed pretraining data and the absence of structured value representations. Existing methods can steer outputs, but often lack demographic grounding and treat values as independent, unstructured signals, reducing consistency and interpretability. We propose OG-MAR, an Ontology-Guided Multi-Agent Reasoning framework. OG-MAR summarizes respondent-specific values from the World Values Survey (WVS) and constructs a global cultural ontology by eliciting relations over a fixed taxonomy via competency questions. At inference time, it retrieves ontology-consistent relations and demographically similar profiles to instantiate multiple value-persona agents, whose outputs are synthesized by a judgment agent that enforces ontology consistency and demographic proximity. Experiments on regional social-survey benchmarks across four LLM backbones show that OG-MAR improves cultural alignment and robustness over competitive baselines, while producing more transparent reasoning traces.

</details>


### [132] [Why Attention Patterns Exist: A Unifying Temporal Perspective Analysis](https://arxiv.org/abs/2601.21709)
*Qingyue Yang,Jie Wang,Xing Li,Yinqi Bai,Xialiang Tong,Huiling Zhen,Jianye Hao,Mingxuan Yuan,Bin Li*

Main category: cs.CL

TL;DR: 本文提出了一个统一的注意力模式解释框架TAPPA，通过数学分析揭示了LLM注意力模式的本质规律，并用以优化推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有研究发现注意力机制中存在各种看似不同的模式，但缺乏统一且系统性的解释方法。该工作旨在用一个统一的视角解释这些分散的注意力模式，并将其用于模型优化。

Method: 提出TAPPA（Temporal Attention Pattern Predictability Analysis）框架，从时序连续的角度数理分析注意力分布，将其分为可预测（有规律）和不可预测（随机）两大类，并揭示这种区分来源于Query在时序上的自相似性。进一步，结合Query、Key的特性及RoPE位置编码，对三类代表性模式进行了详细数学分析。最后，在KV缓存压缩和模型剪枝中应用该框架的洞见，设计指标评测其优化效果。

Result: TAPPA能有效区分与解释注意力的可预测与不可预测模式。基于TAPPA的简单度量方法，在KV缓存压缩和模型剪枝任务上都优于传统方法，提升了精度和推理速度。

Conclusion: TAPPA为LLM注意力分析构建了统一、可解释的理论基础，不仅深化了对注意力机制的理解，还为模型加速和优化提供了实用指导。

Abstract: Attention patterns play a crucial role in both training and inference of large language models (LLMs). Prior works have identified individual patterns such as retrieval heads, sink heads, and diagonal traces, yet these observations remain fragmented and lack a unifying explanation. To bridge this gap, we introduce \textbf{Temporal Attention Pattern Predictability Analysis (TAPPA), a unifying framework that explains diverse attention patterns by analyzing their underlying mathematical formulations} from a temporally continuous perspective. TAPPA both deepens the understanding of attention behavior and guides inference acceleration approaches. Specifically, TAPPA characterizes attention patterns as predictable patterns with clear regularities and unpredictable patterns that appear effectively random. Our analysis further reveals that this distinction can be explained by the degree of query self-similarity along the temporal dimension. Focusing on the predictable patterns, we further provide a detailed mathematical analysis of three representative cases through the joint effect of queries, keys, and Rotary Positional Embeddings (RoPE). We validate TAPPA by applying its insights to KV cache compression and LLM pruning tasks. Across these tasks, a simple metric motivated by TAPPA consistently improves performance over baseline methods. The code is available at https://github.com/MIRALab-USTC/LLM-TAPPA.

</details>


### [133] [TACLer: Tailored Curriculum Reinforcement Learning for Efficient Reasoning](https://arxiv.org/abs/2601.21711)
*Huiyuan Lai,Malvina Nissim*

Main category: cs.CL

TL;DR: 提出了一种名为TACLer的课程强化学习框架，可以让大型语言模型更高效地学习和推理，在保证甚至提升准确率的同时，显著降低训练和推理的计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在复杂推理任务上表现优异，但依赖于耗时的长链式思维，大规模强化学习训练，并存在‘过度思考’和冗余步骤，效率不高。因此需要提高训练与推理效率，同时保持或提升性能。

Method: 提出TACLer课程强化学习框架，通过模型在多阶段RL训练中的熟练度动态调整数据复杂度，包含：(1) 个性化课程学习，按需补足知识；(2) Thinking/NoThinking混合推理范式，自动平衡推理准确率与效率。

Result: TACLer模型在四个复杂数学数据集上，相比长思维模式大幅节省训练开销（超过50%计算量）、减少推理时token用量（超过42%），同时基线精度提升9%以上，全面优于最先进思维/无思维基线。

Conclusion: TACLer显著提升了大型语言模型的推理效率和准确性，有望推广至更多复杂任务，减少大规模训练和推理的计算资源需求。

Abstract: Large Language Models (LLMs) have shown remarkable performance on complex reasoning tasks, especially when equipped with long chain-of-thought (CoT) reasoning. However, eliciting long CoT typically requires large-scale reinforcement learning (RL) training, while often leading to overthinking with redundant intermediate steps. To improve learning and reasoning efficiency, while preserving or even enhancing performance, we propose TACLer, a model-tailored curriculum reinforcement learning framework that gradually increases the complexity of the data based on the model's proficiency in multi-stage RL training. TACLer features two core components: (i) tailored curriculum learning that determines what knowledge the model lacks and needs to learn in progressive stages; (ii) a hybrid Thinking/NoThinking reasoning paradigm that balances accuracy and efficiency by enabling or disabling the Thinking mode. Our experiments show that TACLer yields a twofold advantage in learning and reasoning: (i) it reduces computational cost, cutting training compute by over 50% compared to long thinking models and reducing inference token usage by over 42% relative to the base model; and (ii) it improves accuracy by over 9% on the base model, consistently outperforming state-of-the-art Nothinking and Thinking baselines across four math datasets with complex problems.

</details>


### [134] [Enhancing Language Models for Robust Greenwashing Detection](https://arxiv.org/abs/2601.21722)
*Neil Heinrich Braun,Keane Ong,Rui Mao,Erik Cambria,Gianmarco Mengaldo*

Main category: cs.CL

TL;DR: 该论文提出了一种高效参数的框架，通过对大型语言模型的潜在空间进行结构化，提升ESG可持续报告中识别“漂绿”和模糊表述的能力，并在跨类别实验中表现出更好的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 可持续报告对ESG评估至关重要，但“漂绿”（greenwashing）和模糊表述常使其可靠性降低，现有自然语言处理(NLP)模型对这些现象鲁棒性不佳。

Method: 作者提出结合对比学习与序数排名目标，结构化LLM潜在空间，从而捕捉具体行动与模糊声明间的细微差别。采用门控特征调制过滤噪声，并用MetaGradNorm稳定多目标优化过程。

Result: 在跨类别设定下，该方法比标准基线模型表现出更强鲁棒性，但也揭示了表现力刚性与泛化能力之间的权衡。

Conclusion: 该方法有效提升了可持续报告文本中对漂绿和模糊声明的识别能力，对提升ESG评估质量具有积极意义，同时需关注模型表现力和泛化能力的平衡。

Abstract: Sustainability reports are critical for ESG assessment, yet greenwashing and vague claims often undermine their reliability. Existing NLP models lack robustness to these practices, typically relying on surface-level patterns that generalize poorly. We propose a parameter-efficient framework that structures LLM latent spaces by combining contrastive learning with an ordinal ranking objective to capture graded distinctions between concrete actions and ambiguous claims. Our approach incorporates gated feature modulation to filter disclosure noise and utilizes MetaGradNorm to stabilize multi-objective optimization. Experiments in cross-category settings demonstrate superior robustness over standard baselines while revealing a trade-off between representational rigidity and generalization.

</details>


### [135] [Procedural Pretraining: Warming Up Language Models with Abstract Data](https://arxiv.org/abs/2601.21725)
*Liangze Jiang,Zachary Shinnick,Anton van den Hengel,Hemanth Saratchandran,Damien Teney*

Main category: cs.CL

TL;DR: 论文研究了一种使用结构化的抽象数据（如程序生成的数据）进行早期预训练的新方法，显著提升了语言模型的表现和训练效率。


<details>
  <summary>Details</summary>
Motivation: 当前主流做法是在大规模网页语料上直接预训练语言模型，但这并非模拟人类学习逻辑与知识的过程。论文希望通过先让模型学习结构化、抽象的程序性数据，帮助其后续更容易掌握复杂语义，像人类先学基础逻辑和数学再发展高阶推理。

Method: 作者设计了以形式语言和简单算法生成的结构化程序性数据（如Dyck序列）对模型进行早期预训练的方案，分析了此举对多种算法能力的提升。实验涵盖了不同规模的模型，通过比较只用0.1%程序性数据前置训练与常规自然语言/代码/数学集合训练的差异，并探究了预训练机制背后的神经网络结构变化。

Result: 预先使用程序性数据训练，能极大提升如上下文回忆等算法能力（如准确率从10%升至98%）；即便只占0.1%的程序性数据，整体表现也显著优于传统数据集，且达到同样损失所需数据量大幅减少。此外，注意力层和MLP层在结构域与自然语言域各自获得显著结构优势。

Conclusion: 程序性预训练为语言模型性能和训练速度带来了简单但有效的提升，表明在大语言模型中知识和推理的习得有望解耦，是提升模型能力的 promising 路径。

Abstract: Pretraining directly on web-scale corpora is the de facto paradigm for building language models. We study an alternative setting where the model is initially exposed to abstract structured data, as a means to ease the subsequent acquisition of rich semantic knowledge, much like humans learn simple logic and mathematics before higher reasoning. We specifically focus on procedural data, generated by formal languages and other simple algorithms, as such abstract data.
  We first diagnose the algorithmic skills that different forms of procedural data can improve, often significantly. For example, on context recall (Needle-in-a-haystack), the accuracy jumps from 10 to 98% when pretraining on Dyck sequences (balanced brackets). Second, we study how these gains are reflected in pretraining larger models (up to 1.3B). We find that front-loading as little as 0.1% procedural data significantly outperforms standard pretraining on natural language, code, and informal mathematics (C4, CodeParrot, and DeepMind-Math datasets). Notably, this procedural pretraining enables the models to reach the same loss value with only 55, 67, 86% of the original data. Third, we explore the mechanisms behind and find that procedural pretraining instils non-trivial structure in both attention and MLP layers. The former is particularly important for structured domains (e.g. code), and the latter for language. Finally, we lay a path for combining multiple forms of procedural data. Our results show that procedural pretraining is a simple, lightweight means to improving performance and accelerating language model pretraining, ultimately suggesting the promise of disentangling knowledge acquisition from reasoning in LLMs.

</details>


### [136] [CE-GOCD: Central Entity-Guided Graph Optimization for Community Detection to Augment LLM Scientific Question Answering](https://arxiv.org/abs/2601.21733)
*Jiayin Lan,Jiaqi Li,Baoxin Wang,Ming Liu,Dayong Wu,Shijin Wang,Bing Qin,Guoping Hu*

Main category: cs.CL

TL;DR: 本文提出了一种新的增强大型语言模型进行学术问答的方法（CE-GOCD），通过知识图谱中的中心实体引导子图优化和社区检测，有效提升了模型对学术文献的理解和回答能力。实验证明该方法优于现有检索增强基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强方法主要依赖于文本片段或单一概念，忽视了论文之间更深层次的语义联系，导致LLM难以全面、具体地理解和回答学术问题。

Method: 提出Central Entity-Guided Graph Optimization for Community Detection（CE-GOCD）方法，主要包括：1）以论文标题作为中心实体进行定向子图检索；2）通过子图剪枝与补全增强隐式语义发现；3）采用社区检测提取共享主题的论文群体。

Result: 在三个基于NLP文献问答的数据集上进行实验，结果显示本方法在性能上全面优于传统检索增强基线。

Conclusion: CE-GOCD能够更好地捕捉学术文献之间的语义结构，有效提升LLMs在学术问答任务的表现，框架的有效性得到实验证实。

Abstract: Large Language Models (LLMs) are increasingly used for question answering over scientific research papers. Existing retrieval augmentation methods often rely on isolated text chunks or concepts, but overlook deeper semantic connections between papers. This impairs the LLM's comprehension of scientific literature, hindering the comprehensiveness and specificity of its responses. To address this, we propose Central Entity-Guided Graph Optimization for Community Detection (CE-GOCD), a method that augments LLMs' scientific question answering by explicitly modeling and leveraging semantic substructures within academic knowledge graphs. Our approach operates by: (1) leveraging paper titles as central entities for targeted subgraph retrieval, (2) enhancing implicit semantic discovery via subgraph pruning and completion, and (3) applying community detection to distill coherent paper groups with shared themes. We evaluated the proposed method on three NLP literature-based question-answering datasets, and the results demonstrate its superiority over other retrieval-augmented baseline approaches, confirming the effectiveness of our framework.

</details>


### [137] [Temporal Guidance for Large Language Models](https://arxiv.org/abs/2601.21744)
*Hong-Kai Zheng,Piji Li*

Main category: cs.CL

TL;DR: 本文提出了一种新的对比解码方法——时序指导（TeGu），可有效提升大语言模型生成质量，同时计算与内存开销低。


<details>
  <summary>Details</summary>
Motivation: 现有的对比解码方法虽然能提升文本生成质量，但通常需要额外的辅助模型，导致计算开销大。针对内部分层对比方式在小模型上不稳定的问题，作者希望找到既高效又稳定的替代方案。

Method: 提出时序指导（Temporal Guidance，TeGu）方法，利用多token预测（Multi-Token Prediction, MTP）机制生成较弱的对比自信息，并引入条件化MTP投影器（cMTPP），使实现过程更轻量化，无需维护多个独立网络。

Result: 在多个模型和评测基准上，TeGu在提升生成质量的同时，有效控制了额外的内存与计算开销。

Conclusion: TeGu方法可在不显著增加计算和内存消耗的前提下，显著提升LLM生成效果，优于现有对比解码方法。

Abstract: Contrastive Decoding (CD) enhances the generation quality of large language models (LLMs) but incurs significant additional computational overhead due to the need for an auxiliary model. Existing internal self-contrastive decoding methods, such as Decoding by Contrasting Layers (DoLa), focus on discrepancies across different layers, which are notably unstable on small-scale models. In this work, based on the observation that LLMs exhibit local preferences, we propose a novel contrastive guidance strategy along the temporal dimension, namely Temporal Guidance (TeGu). Our method ingeniously leverages Multi-Token Prediction (MTP) to construct weaker amateur predictions for model self-contrast. To standardize the implementation of this mechanism, we further introduce a lightweight Conditional MTP Projector (cMTPP), which avoids maintaining multiple independent networks as required by other MTP modules. Across various model series and benchmarks, TeGu achieves significant performance improvements while maintaining low additional memory consumption and computational overhead.

</details>


### [138] [CoFrGeNet: Continued Fraction Architectures for Language Generation](https://arxiv.org/abs/2601.21766)
*Amit Dhurandhar,Vijil Chenthamarakshan,Dennis Wei,Tejaswini Pedapati,Karthikeyan Natesan Ramamurthy,Rahul Nair*

Main category: cs.CL

TL;DR: 本文提出了一种受连分数启发的新生成模型架构CoFrGeNets，可替代Transformer中的多头注意力和前馈网络，参数更少，性能不输主流大模型。


<details>
  <summary>Details</summary>
Motivation: Transformer 虽然在自然语言生成任务上效果优异，但其参数量大、计算资源消耗高，难以进一步扩展。为了降低模型复杂度、提升训练效率，作者受连分数（continued fractions）数学方法启发，尝试设计参数量更低但表达能力依旧强大的新型生成网络架构。

Method: 作者基于连分数引入新的函数类，设计可替换 Transformer 内多头注意力(MHA)与前馈网络(FFN)的架构组件，并针对性实现新模块的高效梯度计算方法。这些组件与现有 Transformer 体系高度兼容，可直接替换并集成到GPT2-xl、Llama3等主流大模型中，几乎无需额外改动训练与推理流程。

Result: 在GPT2-xl（1.5B参数）和Llama3（3.2B参数）两种架构上进行了预训练与下游任务实验。CoFrGeNets仅用原模型1/2~2/3的参数及更短的预训练时间，依然在分类、问答、推理、文本理解等任务上表现出竞争力，部分任务甚至优于原始模型。

Conclusion: CoFrGeNets架构作为Transformer的轻量替代方案，能大幅降低参数量，对训练和推理流程的兼容性好，性能表现优异。未来如针对硬件进行定制化实现，有望进一步发挥其潜力。

Abstract: Transformers are arguably the preferred architecture for language generation. In this paper, inspired by continued fractions, we introduce a new function class for generative modeling. The architecture family implementing this function class is named CoFrGeNets - Continued Fraction Generative Networks. We design novel architectural components based on this function class that can replace Multi-head Attention and Feed-Forward Networks in Transformer blocks while requiring much fewer parameters. We derive custom gradient formulations to optimize the proposed components more accurately and efficiently than using standard PyTorch-based gradients. Our components are a plug-in replacement requiring little change in training or inference procedures that have already been put in place for Transformer-based models thus making our approach easy to incorporate in large industrial workflows. We experiment on two very different transformer architectures GPT2-xl (1.5B) and Llama3 (3.2B), where the former we pre-train on OpenWebText and GneissWeb, while the latter we pre-train on the docling data mix which consists of nine different datasets. Results show that the performance on downstream classification, Q\& A, reasoning and text understanding tasks of our models is competitive and sometimes even superior to the original models with $\frac{2}{3}$ to $\frac{1}{2}$ the parameters and shorter pre-training time. We believe that future implementations customized to hardware will further bring out the true potential of our architectures.

</details>


### [139] [Evaluating ChatGPT on Medical Information Extraction Tasks: Performance, Explainability and Beyond](https://arxiv.org/abs/2601.21767)
*Wei Zhu*

Main category: cs.CL

TL;DR: 本文系统评估了ChatGPT在医学信息抽取任务中的表现，发现其能力尚不及专门微调的基线模型，同时在解释性和忠实性上表现良好，但存在过度自信和不确定性等问题。


<details>
  <summary>Details</summary>
Motivation: 尽管ChatGPT等大型语言模型在对话和多种自然语言处理任务中表现出色，但其在医学信息抽取等高要求领域的实际能力仍需评估。研究动机是系统地检验ChatGPT在医学信息抽取任务中的性能，以及分析其输出的可靠性和解释性。

Method: 作者在4项医学信息抽取任务、基于6个标准数据集上，对ChatGPT进行了系统性评估。具体分析了其性能、可解释性、自信度、忠实性和输出不确定性，并与经过微调的基线模型进行对比。

Result: ChatGPT在医学信息抽取任务上的得分明显落后于专门微调的基线模型，但能给出高质量的解释。其预测过于自信，并且在多数情况下对原文很忠实。同时，生成的不确定性增加了信息抽取的不稳定，影响了实际应用。

Conclusion: 虽然ChatGPT在医学信息抽取任务中具有一定潜力，尤其是在解释性和忠实性方面，但由于性能不及专业模型且输出存在不确定性，其应用于医学信息抽取还存在障碍，需要进一步改进与应用策略。

Abstract: Large Language Models (LLMs) like ChatGPT have demonstrated amazing capabilities in comprehending user intents and generate reasonable and useful responses. Beside their ability to chat, their capabilities in various natural language processing (NLP) tasks are of interest to the research community. In this paper, we focus on assessing the overall ability of ChatGPT in 4 different medical information extraction (MedIE) tasks across 6 benchmark datasets. We present the systematically analysis by measuring ChatGPT's performance, explainability, confidence, faithfulness, and uncertainty. Our experiments reveal that: (a) ChatGPT's performance scores on MedIE tasks fall behind those of the fine-tuned baseline models. (b) ChatGPT can provide high-quality explanations for its decisions, however, ChatGPT is over-confident in its predcitions. (c) ChatGPT demonstrates a high level of faithfulness to the original text in the majority of cases. (d) The uncertainty in generation causes uncertainty in information extraction results, thus may hinder its applications in MedIE tasks.

</details>


### [140] [Zonkey: A Hierarchical Diffusion Language Model with Differentiable Tokenization and Probabilistic Attention](https://arxiv.org/abs/2601.21768)
*Alon Rozental*

Main category: cs.CL

TL;DR: 本文提出了一种新的分层扩散模型Zonkey，实现了从原始字符到文档级表示的端到端可微分管道，替代了传统非可微分的BPE分词器，有望提升LLM适应性与可扩展性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM仍依赖于固定、不可微的分词器如BPE，这限制了模型的端到端优化能力和对噪声/领域特定数据的适应性，亟需找到可微分且自适应的编码方案。

Method: 提出Zonkey，包括分层建模和完全可微分分词器（Segment Splitter），通过概率注意力机制进行无监督自适应分割，并用DDMM在潜在空间实现稳定、有效的重建，Stitcher保证片段间的重叠不变性。

Result: Zonkey在Wikipedia端到端训练，实现了从噪声中生成连贯的变长文本，分割结果能自发对齐语言边界，且表现优于基于熵的可学习分词器，显示了分层语义结构的出现与更好的数据对齐。

Conclusion: Zonkey推进了LLM端到端可微建模的发展，为大模型更好地适应新领域和实现大规模自动化生成提供了新方法，实验代码已开源以促进复现与研究。

Abstract: Large language models (LLMs) have revolutionized natural language processing, yet they remain constrained by fixed, non-differentiable tokenizers like Byte Pair Encoding (BPE), which hinder end-to-end optimization and adaptability to noisy or domain-specific data. We introduce Zonkey, a hierarchical diffusion model that addresses these limitations through a fully trainable pipeline from raw characters to document-level representations. At its core is a differentiable tokenizer (Segment Splitter) that learns probabilistic beginning-of-sequence (BOS) decisions, enabling adaptive splits that emerge as linguistically meaningful (e.g., word boundaries at spaces, sentence starts at periods) without explicit supervision. This differentiability is enabled by our novel Probabilistic Attention mechanism, which incorporates position-specific existence probabilities to simulate soft masking over theoretically infinite sequences while preserving gradients. Sequences decay probabilistically rather than relying on end-of-sequence tokens, supporting variable-length outputs. Hierarchical levels compress sequences into higher abstractions (e.g., character n-grams to word-like vectors, then sentence-like), with reconstruction via our Denoising Diffusion Mixed Model (DDMM) for stable and efficient denoising in latent space. A Stitcher ensures overlap invariance across segments. Trained end-to-end on Wikipedia, Zonkey generates coherent, variable-length text from noise, demonstrating emergent hierarchies and promising qualitative alignment to data distributions compared to entropy-based learnable tokenizers. Our approach advances toward fully gradient-based LLMs, with potential for better domain adaptation and scalable generation. We release the source code for training and reproducing our experiments.

</details>


### [141] [KID: Knowledge-Injected Dual-Head Learning for Knowledge-Grounded Harmful Meme Detection](https://arxiv.org/abs/2601.21796)
*Yaocong Li,Leihan Zhang,Le Zhang,Qiang Yan*

Main category: cs.CL

TL;DR: 本文提出了KID框架，通过注入外部知识和双头学习架构，显著提升了有害梗图自动检测的准确性，在多语言数据集上获得了最优表现。


<details>
  <summary>Details</summary>
Motivation: 互联网梗图广泛传播，但其隐含的隐喻和社会文化背景使有害内容难以被自动检测，现有方法不足以捕捉隐式有害性。

Method: 作者设计了KID知识注入双头学习框架，将复杂的梗图理解分解为结构化推理链条，将视觉证据、背景知识与分类标签明确关联，并采用双头架构联动语义生成和分类优化。

Result: KID在英语、中文和孟加拉语等多语言五个数据集上，二分类和多标签任务均取得了2.1%至19.7%的性能提升，超越现有最佳方法。消融实验验证了知识注入与双头联学的有效性和互补性。

Conclusion: KID方法显著提升了梗图中隐性有害内容的检测效果，其知识注入与双头架构在泛化和鲁棒性上具有重要优势。

Abstract: Internet memes have become pervasive carriers of digital culture on social platforms. However, their heavy reliance on metaphors and sociocultural context also makes them subtle vehicles for harmful content, posing significant challenges for automated content moderation. Existing approaches primarily focus on intra-modal and inter-modal signal analysis, while the understanding of implicit toxicity often depends on background knowledge that is not explicitly present in the meme itself. To address this challenge, we propose KID, a Knowledge-Injected Dual-Head Learning framework for knowledge-grounded harmful meme detection. KID adopts a label-constrained distillation paradigm to decompose complex meme understanding into structured reasoning chains that explicitly link visual evidence, background knowledge, and classification labels. These chains guide the learning process by grounding external knowledge in meme-specific contexts. In addition, KID employs a dual-head architecture that jointly optimizes semantic generation and classification objectives, enabling aligned linguistic reasoning while maintaining stable decision boundaries. Extensive experiments on five multilingual datasets spanning English, Chinese, and low-resource Bengali demonstrate that KID achieves SOTA performance on both binary and multi-label harmful meme detection tasks, improving over previous best methods by 2.1%--19.7% across primary evaluation metrics. Ablation studies further confirm the effectiveness of knowledge injection and dual-head joint learning, highlighting their complementary contributions to robust and generalizable meme understanding. The code and data are available at https://github.com/PotatoDog1669/KID.

</details>


### [142] [Enhancing Conversational Agents via Task-Oriented Adversarial Memory Adaptation](https://arxiv.org/abs/2601.21797)
*Yimin Deng,Yuqing Fu,Derong Xu,Yejing Wang,Wei Ni,Jingtong Gao,Xiaopeng Li,Chengxu Liu,Xiao Han,Guoshuai Zhao,Xiangyu Zhao,Li Zhu,Xueming Qian*

Main category: cs.CL

TL;DR: 本文提出了一种名为Adversarial Memory Adaptation（AMA）的机制，使对话代理的记忆系统能够更好地适应下游任务，通过仿真实际推理过程在离线阶段进行有针对性的记忆构建与更新。


<details>
  <summary>Details</summary>
Motivation: 现有对话代理的记忆系统在离线阶段多采用通用、任务无关的记忆构建和更新方式，导致记忆与任务需求不匹配，从而影响任务表现。

Method: AMA机制通过引入三个智能体：挑战者智能体生成问答对，依赖当前记忆系统进行问答模拟下游任务；评估者智能体对问答结果进行评估与错误分析；适配器智能体则针对错误案例调整记忆构建策略及内容，实现多层次更新。

Result: AMA机制能够为记忆系统在离线阶段引入任务感知的监督信号，改进记忆与下游任务的适配效果。实验在长对话基准（LoCoMo）上验证了其有效性。

Conclusion: AMA可灵活集成到现有多种记忆系统中，明显提升了对话代理在长对话任务中的表现和记忆的任务适应性。

Abstract: Conversational agents struggle to handle long conversations due to context window limitations. Therefore, memory systems are developed to leverage essential historical information. Existing memory systems typically follow a pipeline of offline memory construction and update, and online retrieval. Despite the flexible online phase, the offline phase remains fixed and task-independent. In this phase, memory construction operates under a predefined workflow and fails to emphasize task relevant information. Meanwhile, memory updates are guided by generic metrics rather than task specific supervision. This leads to a misalignment between offline memory preparation and task requirements, which undermines downstream task performance. To this end, we propose an Adversarial Memory Adaptation mechanism (AMA) that aligns memory construction and update with task objectives by simulating task execution. Specifically, first, a challenger agent generates question answer pairs based on the original dialogues. The constructed memory is then used to answer these questions, simulating downstream inference. Subsequently, an evaluator agent assesses the responses and performs error analysis. Finally, an adapter agent analyzes the error cases and performs dual level updates on both the construction strategy and the content. Through this process, the memory system receives task aware supervision signals in advance during the offline phase, enhancing its adaptability to downstream tasks. AMA can be integrated into various existing memory systems, and extensive experiments on long dialogue benchmark LoCoMo demonstrate its effectiveness.

</details>


### [143] [RAG-E: Quantifying Retriever-Generator Alignment and Failure Modes](https://arxiv.org/abs/2601.21803)
*Korbinian Randl,Guido Rocchietti,Aron Henriksson,Ziawasch Abedjan,Tony Lindgren,John Pavlopoulos*

Main category: cs.CL

TL;DR: 本文提出了RAG-E，一个用于可解释RAG的端到端框架，发现生成器在大量查询中未能合理利用检索器的高排名文档。


<details>
  <summary>Details</summary>
Motivation: 当前RAG系统中检索器与生成器的互动方式较为黑箱，这为高风险领域的部署带来挑战。缺乏定量化的可解释分析工具，难以评估检索器与生成器之间的对齐与关联性。

Method: 作者将Integrated Gradients方法用于分析检索器的贡献，并引入了基于蒙特卡洛方法稳定的Shapley Value近似（PMCSHAP）进行生成器归因分析，还提出了加权归因-相关性差距（WARG）指标衡量生成器对检索结果利用的对齐程度。

Result: 在TREC CAsT和FoodSafeSum数据集上的实验显示，约47.4%-66.7%的查询中生成器忽视了检索器高排名文档，48.1%-65.9%的情况下生成器依赖排名较低的文档，揭示严重对齐不良现象。

Conclusion: RAG系统输出质量不仅取决于单独模块性能，更多依赖其协作方式，RAG-E框架为检测和分析这种协作关系提供了有效工具，有助于提升RAG系统在实际场景中的透明度和可靠性。

Abstract: Retrieval-Augmented Generation (RAG) systems combine dense retrievers and language models to ground LLM outputs in retrieved documents. However, the opacity of how these components interact creates challenges for deployment in high-stakes domains. We present RAG-E, an end-to-end explainability framework that quantifies retriever-generator alignment through mathematically grounded attribution methods. Our approach adapts Integrated Gradients for retriever analysis, introduces PMCSHAP, a Monte Carlo-stabilized Shapley Value approximation, for generator attribution, and introduces the Weighted Attribution-Relevance Gap (WARG) metric to measure how well a generator's document usage aligns with a retriever's ranking. Empirical analysis on TREC CAsT and FoodSafeSum reveals critical misalignments: for 47.4% to 66.7% of queries, generators ignore the retriever's top-ranked documents, while 48.1% to 65.9% rely on documents ranked as less relevant. These failure modes demonstrate that RAG output quality depends not solely on individual component performance but on their interplay, which can be audited via RAG-E.

</details>


### [144] [Distribution-Aware Reward Estimation for Test-Time Reinforcement Learning](https://arxiv.org/abs/2601.21804)
*Bodong Du,Xuanqi Huang,Xiaomeng Li*

Main category: cs.CL

TL;DR: 论文提出了DARE方法，通过利用所有rollout分布信息和奖励增强机制，增强了TTRL在无监督自我提升中的效果，显著优于以往仅基于多数投票的方案。


<details>
  <summary>Details</summary>
Motivation: 现有TTRL方法大多通过多数投票确定奖励信号，然而这个方法忽视了非多数但可能正确的动作信息，导致奖励估计偏差；因此需要开发更全面且稳健的奖励估计方法。

Method: 提出了分布感知奖励估计（DARE），不仅考虑所有rollout的分布，还引入了探索奖励和分布剪枝机制，以充分探索非主流选择并降低奖励噪声。

Result: 在AIME 2024和AMC等高难度推理基准上，DARE在优化稳定性和最终表现上均超越了最新基线方法，分别取得了25.3%和5.3%的相对提升。

Conclusion: 将奖励估计从多数投票扩展到完整分布（配合奖励增强和剪枝）后，TTRL表现更加稳健且最终效果更佳，适合在无监督输入下自我改进大模型。

Abstract: Test-time reinforcement learning (TTRL) enables large language models (LLMs) to self-improve on unlabeled inputs, but its effectiveness critically depends on how reward signals are estimated without ground-truth supervision. Most existing TTRL methods rely on majority voting (MV) over rollouts to produce deterministic rewards, implicitly assuming that the majority rollout provides a reliable learning signal. We show that this assumption is fragile: MV reduces the rollout distribution into a single outcome, discarding information about non-majority but correct actions candidates, and yields systematically biased reward estimates. To address this, we propose Distribution-AwareReward Estimation (DARE), which shifts reward estimation from a single majority outcome to the full empirical rollout distribution. DARE further augments this distribution-based reward with an exploration bonus and a distribution pruning mechanism for non-majority rollout exploration and reward denoise, yielding a more informative and robust reward estimation. Extensive experiments on challenging reasoning benchmarks show that DARE improves optimization stability and final performance over recent baselines, achieving relative improvements of 25.3% on challenging AIME 2024 and 5.3% on AMC.

</details>


### [145] [Mil-SCORE: Benchmarking Long-Context Geospatial Reasoning and Planning in Large Language Models](https://arxiv.org/abs/2601.21826)
*Aadi Palnitkar,Mingyang Mao,Nicholas Waytowich,Vinicius G. Goecks,Tinoosh Mohsenin,Xiaomin Lin*

Main category: cs.CL

TL;DR: 本文提出了MilSCORE数据集，专为评估大语言模型（LLM）在复杂、长上下文、多源异构信息整合与推理下的能力，尤其聚焦于地理空间规划和高风险场景决策。实验发现，现有模型在该真实场景基准上表现一般，表明仍有很大提升空间。


<details>
  <summary>Details</summary>
Motivation: 随着LLM被应用于更长、更复杂的任务，需要更真实且富有挑战性的长上下文基准，尤其用于军事、大规模地理空间规划等实际场景。但目前缺乏针对该领域的评价标准。本文旨在填补这一空白，评估模型的综合推理与规划能力。

Method: 作者构建了MilSCORE数据集，基于专家设计的复杂军事规划模拟场景，提出了多跳、多维度的问题，涵盖地图、情报、命令等多模态信息。涵盖七类问题，测试模型对事实回忆、多步约束、空间推理和策略分析的能力，并为现有视觉-语言模型设立基线评测。

Result: 实验结果表明，现有模型在MilSCORE上的综合表现有限，尤其在高难度的长上下文场景整体策略与空间推理上存在显著不足。

Conclusion: MilSCORE为现实场景下的长上下文推理提供了重要测试平台，现有模型距离满足实际需求仍有相当差距，该基准有望推动领域方法持续进步。

Abstract: As large language models (LLMs) are applied to increasingly longer and more complex tasks, there is a growing need for realistic long-context benchmarks that require selective reading and integration of heterogeneous, multi-modal information sources. This need is especially acute for geospatial planning problems, such as those found in planning for large-scale military operations, which demand fast and accurate reasoning over maps, orders, intelligence reports, and other distributed data. To address this gap, we present MilSCORE (Military Scenario Contextual Reasoning), to our knowledge the first scenario-level dataset of expert-authored, multi-hop questions grounded in a complex, simulated military planning scenario used for training. MilSCORE is designed to evaluate high-stakes decision-making and planning, probing LLMs' ability to combine tactical and spatial reasoning across multiple sources and to reason over long-horizon, geospatially rich context. The benchmark includes a diverse set of question types across seven categories targeting both factual recall and multi-step reasoning about constraints, strategy, and spatial analysis. We provide an evaluation protocol and report baseline results for a range of contemporary vision-language models. Our findings highlight substantial headroom on MilSCORE, indicating that current systems struggle with realistic, scenario-level long-context planning, and positioning MilSCORE as a challenging testbed for future work.

</details>


### [146] [Embodied Task Planning via Graph-Informed Action Generation with Large Lanaguage Model](https://arxiv.org/abs/2601.21841)
*Xiang Li,Ning Yan,Masood Mortazavi*

Main category: cs.CL

TL;DR: 该论文提出了GiG，一种专为具身智能体长程规划设计的新型Graph-in-Graph记忆规划框架，有效提升了类机器人任务中的规划能力与执行准确率。


<details>
  <summary>Details</summary>
Motivation: 现有大模型在具身智能体的长程规划中表现不佳，存在策略连贯性差、环境约束违反等问题，主要受限于上下文窗口及记忆机制。需要更结构化的记忆方式提高复杂环境下的智能体决策能力。

Method: 作者设计了Graph-in-Graph结构：用图神经网络将环境状态编码成嵌入，并构成表示执行历史的图结构记忆库；通过聚类这些嵌入，供智能体检索结构先验，从而以过去经验为当前决策提供依据，并结合基于符号逻辑的有限前视模块提升规划深度。

Result: 在Robotouille Synchronous、Robotouille Asynchronous及ALFWorld三个具身规划基准上测试，GiG框架相比多个SOTA基线有显著提升，Pass@1分数分别提升22%、37%和15%，且计算开销相当或更低。

Conclusion: GiG展现出处理长程、环境强约束任务中的显著优势，为具身智能体的长期规划与决策提供了高效且结构化的解决思路。

Abstract: While Large Language Models (LLMs) have demonstrated strong zero-shot reasoning capabilities, their deployment as embodied agents still faces fundamental challenges in long-horizon planning. Unlike open-ended text generation, embodied agents must decompose high-level intent into actionable sub-goals while strictly adhering to the logic of a dynamic, observed environment. Standard LLM planners frequently fail to maintain strategy coherence over extended horizons due to context window limitation or hallucinate transitions that violate constraints. We propose GiG, a novel planning framework that structures embodied agents' memory using a Graph-in-Graph architecture. Our approach employs a Graph Neural Network (GNN) to encode environmental states into embeddings, organizing these embeddings into action-connected execution trace graphs within an experience memory bank. By clustering these graph embeddings, the framework enables retrieval of structure-aware priors, allowing agents to ground current decisions in relevant past structural patterns. Furthermore, we introduce a novel bounded lookahead module that leverages symbolic transition logic to enhance the agents' planning capabilities through the grounded action projection. We evaluate our framework on three embodied planning benchmarks-Robotouille Synchronous, Robotouille Asynchronous, and ALFWorld. Our method outperforms state-of-the-art baselines, achieving Pass@1 performance gains of up to 22% on Robotouille Synchronous, 37% on Asynchronous, and 15% on ALFWorld with comparable or lower computational cost.

</details>


### [147] [Learn-to-Distance: Distance Learning for Detecting LLM-Generated Text](https://arxiv.org/abs/2601.21895)
*Hongyi Zhou,Jin Zhu,Erhan Xu,Kai Ye,Ying Yang,Chengchun Shi*

Main category: cs.CL

TL;DR: 本文提出了一种基于重写检测大语言模型（LLM）生成内容的新方法，并在理论和实证上都优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型生成的人类风格文本带来了信息失真和学术诚信风险，因此迫切需要高效检测LLM生成内容的算法。

Method: 作者首先用几何方法分析和解释了基于重写的检测算法，然后提出了一种自适应学习原文与重写文本距离的新算法，并证明自适应距离比固定距离更有效。

Result: 在超过100种实验设置下，新算法在大多数场景下大幅优于现有基线算法；尤其在不同目标LLM（如GPT、Claude、Gemini）下，相对提升达57.8%至80.6%。

Conclusion: 自适应距离学习的重写检测方法在理论和实践上都明显更具优势，是提升LLM内容检测准确性的有效手段。

Abstract: Modern large language models (LLMs) such as GPT, Claude, and Gemini have transformed the way we learn, work, and communicate. Yet, their ability to produce highly human-like text raises serious concerns about misinformation and academic integrity, making it an urgent need for reliable algorithms to detect LLM-generated content. In this paper, we start by presenting a geometric approach to demystify rewrite-based detection algorithms, revealing their underlying rationale and demonstrating their generalization ability. Building on this insight, we introduce a novel rewrite-based detection algorithm that adaptively learns the distance between the original and rewritten text. Theoretically, we demonstrate that employing an adaptively learned distance function is more effective for detection than using a fixed distance. Empirically, we conduct extensive experiments with over 100 settings, and find that our approach demonstrates superior performance over baseline algorithms in the majority of scenarios. In particular, it achieves relative improvements from 57.8\% to 80.6\% over the strongest baseline across different target LLMs (e.g., GPT, Claude, and Gemini).

</details>


### [148] [SONIC: Segmented Optimized Nexus for Information Compression in Key-Value Caching](https://arxiv.org/abs/2601.21927)
*Hong Chen,Xiang Liu,Bo Wang,Yuxuan Fan,Yuanlin Chu,Zongluo Li,Xiaowen Chu,Xuming Hu*

Main category: cs.CL

TL;DR: 本文提出了一种名为SONIC的学习型KV cache压缩框架，通过压缩并保留多轮对话中的重要信息，有效减少内存占用并提升推理速度，在多个基准测试中优于当前主流方法。


<details>
  <summary>Details</summary>
Motivation: 在多轮大模型推理中，KV缓存随对话轮数线性增长，严重影响部署效率。现有的压缩方法多忽略对话结构，简单驱逐缓存有丢失关键信息的风险，亟需更智能且高效的解决方案。

Method: SONIC利用学习方法将历史对话段压缩为紧凑且富语义的Nexus tokens，并通过动态预算训练方式，使其在不同内存限制下灵活适应而无需重新训练。

Result: 在四个多轮对话基准测试上，SONIC分别在80%和50%的压缩比条件下均优于H2O、StreamingLLM等方法，特别是在MTBench101基准上，平均分数相较最佳基线提升35.55%。同时，推理效率提升50.1%。

Conclusion: SONIC能够显著提升多轮对话LLM的效率和对话连贯性，适用于资源受限场景下的大模型推理部署。

Abstract: The linear growth of Key-Value (KV) cache remains a bottleneck for multi-turn LLM deployment. Existing KV cache compression methods often fail to account for the structural properties of multi-turn dialogues, relying on heuristic eviction that risks losing critical context. We propose \textbf{SONIC}, a learning-based framework that compresses historical segments into compact and semantically rich \textbf{Nexus} tokens. By integrating dynamic budget training, SONIC allows flexible adaptation to varying memory constraints without retraining. Experiments show that at compression ratios of 80\% and 50\%, SONIC consistently outperforms baselines such as H2O and StreamingLLM on four diverse multi-turn benchmarks. Specifically, on the widely used MTBench101 benchmark, SONIC achieves an average score improvement of 35.55\% over state-of-the-art baselines, validating its effectiveness in sustaining coherent multi-turn dialogues. Furthermore, SONIC enhances deployment efficiency, accelerating the overall inference process by 50.1\% compared to full-context generation.

</details>


### [149] [From Generative Modeling to Clinical Classification: A GPT-Based Architecture for EHR Notes](https://arxiv.org/abs/2601.21955)
*Fariba Afrin Irany*

Main category: cs.CL

TL;DR: 提出了一种基于GPT的选择性微调策略，用于高效地对临床文本进行分类，在减少计算资源消耗的同时，取得了优异的分类表现。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHR）中的非结构化临床文本日益丰富，为疾病表征、队列识别和临床决策支持带来了新的自动化可能性，但长文本和领域特定性带来的有限标签、类别不平衡和大模型的高计算成本仍是主要挑战。

Method: 作者提出了基于GPT-2的架构，仅微调最后一个Transformer块、最终归一化层和一个轻量级分类头，其余主干参数全部冻结，从而极大减小训练参数量。方法在MIMIC-IV-Note放射学报告上，通过直接从报告文本提取不确定性标签进行多标签及二分类实验。

Result: 该方法在多种任务设置和数据量级下表现出稳定收敛和强分类能力，尤其在未提及或否定性发现主导的数据中优势明显。

Conclusion: 选择性微调大型预训练生成模型为临床文本分类提供了一种高效可扩展的适应方式，显著降低了算力需求，推动了真实世界EHR应用的落地。

Abstract: The increasing availability of unstructured clinical narratives in electronic health records (EHRs) has created new opportunities for automated disease characterization, cohort identification, and clinical decision support. However, modeling long, domain-specific clinical text remains challenging due to limited labeled data, severe class imbalance, and the high computational cost of adapting large pretrained language models.
  This study presents a GPT-based architecture for clinical text classification that adapts a pretrained decoder-only Transformer using a selective fine-tuning strategy. Rather than updating all model parameters, the majority of the GPT-2 backbone is frozen, and training is restricted to the final Transformer block, the final layer normalization, and a lightweight classification head. This approach substantially reduces the number of trainable parameters while preserving the representational capacity required to model complex clinical language.
  The proposed method is evaluated on radiology reports from the MIMIC-IV-Note dataset using uncertainty-aware CheXpert-style labels derived directly from report text. Experiments cover multiple problem formulations, including multi-label classification of radiographic findings, binary per-label classification under different uncertainty assumptions, and aggregate disease outcome prediction. Across varying dataset sizes, the model exhibits stable convergence behavior and strong classification performance, particularly in settings dominated by non-mention and negated findings.
  Overall, the results indicate that selective fine-tuning of pretrained generative language models provides an efficient and effective pathway for clinical text classification, enabling scalable adaptation to real-world EHR data while significantly reducing computational complexity.

</details>


### [150] [OVD: On-policy Verbal Distillation](https://arxiv.org/abs/2601.21968)
*Jing Xiong,Hui Shen,Shansan Gong,Yuxin Cheng,Jianghan Shen,Chaofan Tao,Haochen Tan,Haoli Bai,Lifeng Shang,Ngai Wong*

Main category: cs.CL

TL;DR: 本文提出了一种高效的知识蒸馏方法（OVD），能够利用教师模型的离散口头分数反馈来指导学生模型学习，显著提升内存效率与推理能力，且无需教师与学生模型在每个token上对齐。实验显示，在Web问答和数学推理任务上相比现有方法有显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统token级的在策略（on-policy）知识蒸馏方法要求学生模型的输出与教师模型一一对齐，这限制了学生模型探索能力，也导致内存消耗大、难以有效利用环境反馈，不适合于强化学习场景。为解决这些核心问题，作者提出了新方法来放宽这一约束。

Method: 文中提出“On-policy Verbal Distillation（OVD）”框架，通过让教师模型对学生模型完整输出结果进行打分（0-9离散口头分数），用轨迹匹配替代了传统token概率对齐，大幅减少内存消耗。学生模型仅需根据分数调整策略，无需和教师逐token严格对齐，可自由探索输出空间。

Result: 在Web问答和数学推理任务的大规模实验中，OVD方法平均EM指标提升高达12.9%，数学任务上线提升至25.7%（仅用一个随机样本训练），还表现出更高的训练效率。

Conclusion: OVD显著缓解了token级对齐带来的探索性受限和内存瓶颈问题，在多项推理任务中表现优异，是一种高效的在策略知识蒸馏新范式。

Abstract: Knowledge distillation offers a promising path to transfer reasoning capabilities from large teacher models to efficient student models; however, existing token-level on-policy distillation methods require token-level alignment between the student and teacher models, which restricts the student model's exploration ability, prevent effective use of interactive environment feedback, and suffer from severe memory bottlenecks in reinforcement learning. We introduce On-policy Verbal Distillation (OVD), a memory-efficient framework that replaces token-level probability matching with trajectory matching using discrete verbal scores (0--9) from teacher models. OVD dramatically reduces memory consumption while enabling on-policy distillation from teacher models with verbal feedback, and avoids token-level alignment, allowing the student model to freely explore the output space. Extensive experiments on Web question answering and mathematical reasoning tasks show that OVD substantially outperforms existing methods, delivering up to +12.9% absolute improvement in average EM on Web Q&A tasks and a up to +25.7% gain on math benchmarks (when trained with only one random samples), while also exhibiting superior training efficiency. Our project page is available at https://OVD.github.io

</details>


### [151] [Token-Guard: Towards Token-Level Hallucination Control via Self-Checking Decoding](https://arxiv.org/abs/2601.21969)
*Yifan Zhu,Huiqiang Rong,Haoran Luo*

Main category: cs.CL

TL;DR: 本文提出了一种名为Token-Guard的新方法，通过在生成过程中逐步自检，显著降低了大语言模型的幻觉（hallucination）问题，提高了生成内容的可靠性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型容易出现幻觉，为了在不耗费大量资源的情况下控制幻觉，需要更加高效且具有明确控制能力的方法。当前RAG和RLHF对资源需求高，而现有轻量级方法又无法显式控制幻觉。

Method: Token-Guard在解码过程中实现逐token自校验：对于每一步生成，先内部检测生成的token是否为幻觉，然后在潜在空间中对候选片段进行风险评分，最后通过迭代剪枝和重生成，动态纠正检测出来的问题token。

Result: 在HALU等数据集上的实验表明，Token-Guard显著减少了幻觉现象，提高了大模型输出的准确度。

Conclusion: Token-Guard是一种高效、可扩展、模块化的解决方案，能够有效增强大语言模型生成内容的可靠性，相关代码已开源。

Abstract: Large Language Models (LLMs) often hallucinate, generating content inconsistent with the input. Retrieval-Augmented Generation (RAG) and Reinforcement Learning with Human Feedback (RLHF) can mitigate hallucinations but require resource-intensive retrieval or large-scale fine-tuning. Decoding-based methods are lighter yet lack explicit hallucination control. To address this, we present Token-Guard, a token-level hallucination control method based on self-checking decoding. Token-Guard performs internal verification at each reasoning step to detect hallucinated tokens before they propagate. Candidate fragments are further evaluated in a latent space with explicit hallucination risk scoring, while iterative pruning and regeneration dynamically correct detected errors. Experiments on HALU datasets show Token-Guard substantially reduces hallucinations and improves generation accuracy, offering a scalable, modular solution for reliable LLM outputs. Our code is publicly available.

</details>


### [152] [Mechanistic Data Attribution: Tracing the Training Origins of Interpretable LLM Units](https://arxiv.org/abs/2601.21996)
*Jianhui Chen,Yuzhang Luo,Liangming Pan*

Main category: cs.CL

TL;DR: 提出了一种新的方法（MDA）来追踪大模型中可解释单元的训练数据来源，并验证了通过干预高影响力样本能显著影响可解释头的形成。还发现了数据结构类型和模型能力之间的因果联系。


<details>
  <summary>Details</summary>
Motivation: 虽然大模型中已经发现了可解释电路，但这些电路在训练数据中的因果来源尚不明确。论文旨在揭示训练样本与模型内部机制之间的直接因果联系。

Method: 提出Mechanistic Data Attribution (MDA) 框架，利用Influence Functions来追踪可解释单元与具体训练样本的因果关联；在Pythia模型系列上，通过删除或增强高影响样本，观察对模型中可解释结构（如attention头）的影响，并分析结构化数据的作用。

Result: 高影响力样本的干预能够显著改变可解释头的出现，随机干预则无明显影响。结构性重复数据（如LaTeX、XML）对可解释电路的形成有催化作用。并首次直接验证了归纳头和模型in-context learning能力之间的因果关系。

Conclusion: 首次从数据角度提供了因果证据揭示训练样本与模型内部电路的联系，为有针对性地引导大模型内部机制的形成提供了可行方法。提出的数据增强方法可加速电路结构的收敛，具有实际指导意义。

Abstract: While Mechanistic Interpretability has identified interpretable circuits in LLMs, their causal origins in training data remain elusive. We introduce Mechanistic Data Attribution (MDA), a scalable framework that employs Influence Functions to trace interpretable units back to specific training samples. Through extensive experiments on the Pythia family, we causally validate that targeted intervention--removing or augmenting a small fraction of high-influence samples--significantly modulates the emergence of interpretable heads, whereas random interventions show no effect. Our analysis reveals that repetitive structural data (e.g., LaTeX, XML) acts as a mechanistic catalyst. Furthermore, we observe that interventions targeting induction head formation induce a concurrent change in the model's in-context learning (ICL) capability. This provides direct causal evidence for the long-standing hypothesis regarding the functional link between induction heads and ICL. Finally, we propose a mechanistic data augmentation pipeline that consistently accelerates circuit convergence across model scales, providing a principled methodology for steering the developmental trajectories of LLMs.

</details>


### [153] [When "Better" Prompts Hurt: Evaluation-Driven Iteration for LLM Applications](https://arxiv.org/abs/2601.22025)
*Daniel Commey*

Main category: cs.CL

TL;DR: 本文提出了一种针对大型语言模型（LLM）应用的评估驱动工作流，包括定义、测试、诊断和修复四个步骤，并推荐了分层评估组件（MVES），以提升评估效率和系统性。研究还比较了自动化检查、人类打分以及由LLM作为评判者的方法，并分析了评判失败的常见原因。实验结果显示，泛用提示替换特定任务提示时，不同评测指标间存在权衡，强调了基于评估的提示优化的重要性。


<details>
  <summary>Details</summary>
Motivation: LLM应用的输出具有随机性、高维度且容易受提示语和模型变化影响，给评估和测试带来挑战。因此需要构建一套系统的、可复现的评估流程以提升LLM应用开发的工程效率。

Method: 作者提出评估驱动开发循环（Define, Test, Diagnose, Fix），并给出最小可行性评估套件（MVES），对通用LLM应用、RAG和智能体工具使用等不同场景提出分层评估组件建议。综合自动化打分、人类评分、LLM评判三种评估方法，并分析相关优缺点和失败模式。

Result: 在本地可复现实验中，泛用提示模板虽然提升了遵循指令能力，但在信息提取和RAG一致性方面表现下降，如Llama 3模型的提取准确率从100%降至90%，RAG一致性从93.3%降至80%。表明提示优化需结合具体评估指标进行平衡。

Conclusion: LLM系统不宜依赖通用提示规则，应依据具体评估指标进行迭代优化，建立标准化、可复现的评估流程对于高质量LLM应用开发至关重要。实验数据和工具全部开源，支持复现。

Abstract: Evaluating Large Language Model (LLM) applications differs from traditional software testing because outputs are stochastic, high-dimensional, and sensitive to prompt and model changes. We present an evaluation-driven workflow - Define, Test, Diagnose, Fix - that turns these challenges into a repeatable engineering loop.
  We introduce the Minimum Viable Evaluation Suite (MVES), a tiered set of recommended evaluation components for (i) general LLM applications, (ii) retrieval-augmented generation (RAG), and (iii) agentic tool-use workflows. We also synthesize common evaluation methods (automated checks, human rubrics, and LLM-as-judge) and discuss known judge failure modes.
  In reproducible local experiments (Ollama; Llama 3 8B Instruct and Qwen 2.5 7B Instruct), we observe that a generic "improved" prompt template can trade off behaviors: on our small structured suites, extraction pass rate decreased from 100% to 90% and RAG compliance from 93.3% to 80% for Llama 3 when replacing task-specific prompts with generic rules, while instruction-following improved. These findings motivate evaluation-driven prompt iteration and careful claim calibration rather than universal prompt recipes.
  All test suites, harnesses, and results are included for reproducibility.

</details>


### [154] [Causal Autoregressive Diffusion Language Model](https://arxiv.org/abs/2601.22031)
*Junhao Ruan,Bei Li,Yongjing Yin,Pengcheng Huang,Xin Chen,Jingang Wang,Xunliang Cai,Tong Xiao,JingBo Zhu*

Main category: cs.CL

TL;DR: 本文提出了一种新的生成模型框架CARD，结合了自回归模型（ARM）训练高效性与扩散模型高吞吐推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前自回归模型训练高效但推理慢，扩散模型推理快但训练慢，亟需一种兼顾二者优点的解决方案，提升大型语言模型的训练效率和推理速度。

Method: CARD重新设计了扩散过程，在严格因果的注意力掩码下实施单步密集监督，并通过软尾掩码保持局部上下文、噪声驱动的权重机制提升优化稳定性，还利用KV缓存机制实现动态并行生成，可自适应生成不同长度的序列。

Result: CARD在实验中优于现有的离散扩散基线模型，训练延迟比块扩散方法下降了三倍。

Conclusion: CARD实现了自回归模型水平的数据利用效率，又具备并行生成的低延迟，成为高效生成式大语言模型的新范式。

Abstract: In this work, we propose Causal Autoregressive Diffusion (CARD), a novel framework that unifies the training efficiency of ARMs with the high-throughput inference of diffusion models. CARD reformulates the diffusion process within a strictly causal attention mask, enabling dense, per-token supervision in a single forward pass. To address the optimization instability of causal diffusion, we introduce a soft-tailed masking schema to preserve local context and a context-aware reweighting mechanism derived from signal-to-noise principles. This design enables dynamic parallel decoding, where the model leverages KV-caching to adaptively generate variable-length token sequences based on confidence. Empirically, CARD outperforms existing discrete diffusion baselines while reducing training latency by 3 $\times$ compared to block diffusion methods. Our results demonstrate that CARD achieves ARM-level data efficiency while unlocking the latency benefits of parallel generation, establishing a robust paradigm for next-generation efficient LLMs.

</details>


### [155] [Thinking Out of Order: When Output Order Stops Reflecting Reasoning Order in Diffusion Language Models](https://arxiv.org/abs/2601.22035)
*Longxuan Yu,Yu Fu,Shaorong Zhang,Hui Liu,Mukund Varma T,Greg Ver Steeg,Yue Dong*

Main category: cs.CL

TL;DR: 本文研究了自回归（AR）模型在输出结构与自然推理顺序冲突时的局限，并提出利用掩码扩散语言模型（MDLM）实现“顺序鲁棒性”，在多项任务和新提出的数据集ReasonOrderQA上取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型只能按固定的从左到右顺序生成输出，这在某些实际应用（如要求先输出答案再输出推理过程）中不符合自然推理流程，导致模型表现下降。因此，作者希望探索能否找到一种机制，使生成顺序与推理顺序解耦，提高在非标准输出顺序下的表现。

Method: 作者提出采用掩码扩散语言模型（MDLM），其特点是在生成过程中所有 token 并行、多轮次地逐步细化，而不依赖严格的自回归顺序。作者使用GSM8K、Math500以及新构建的ReasonOrderQA数据集进行实验，其中ReasonOrderQA允许严格控制输出顺序和难度。通过设置输出顺序（如先答案再推理）的不同，比较AR和MDLM模型的表现差异。

Result: 实验发现，当要求模型“先答后推”时，自回归模型准确率大幅下降（最多67%相对降幅），而MDLM模型表现更稳定（相对降幅不超过14%），显示出“顺序鲁棒性”。进一步分析表明，MDLM在生成过程中更早稳定较简单的推理token，有助于推理过程在答案前稳定下来。文章还探讨了MDLM顺序鲁棒性消失的场景和条件。

Conclusion: 掩码扩散语言模型能够有效打破输出顺序对推理准确率的限制，实现“顺序鲁棒性”，适合于结构受限或非典型顺序需求的应用，但其性能在某些极端条件下仍有下降空间。

Abstract: Autoregressive (AR) language models enforce a fixed left-to-right generation order, creating a fundamental limitation when the required output structure conflicts with natural reasoning (e.g., producing answers before explanations due to presentation or schema constraints). In such cases, AR models must commit to answers before generating intermediate reasoning, and this rigid constraint forces premature commitment. Masked diffusion language models (MDLMs), which iteratively refine all tokens in parallel, offer a way to decouple computation order from output structure. We validate this capability on GSM8K, Math500, and ReasonOrderQA, a benchmark we introduce with controlled difficulty and order-level evaluation. When prompts request answers before reasoning, AR models exhibit large accuracy gaps compared to standard chain-of-thought ordering (up to 67% relative drop), while MDLMs remain stable ($\leq$14% relative drop), a property we term "order robustness". Using ReasonOrderQA, we present evidence that MDLMs achieve order robustness by stabilizing simpler tokens (e.g., reasoning steps) earlier in the diffusion process than complex ones (e.g., final answers), enabling reasoning tokens to stabilize before answer commitment. Finally, we identify failure conditions where this advantage weakens, outlining the limits required for order robustness.

</details>


### [156] [A Separable Architecture for Continuous Token Representation in Language Models](https://arxiv.org/abs/2601.22040)
*Reza T. Batley,Sourav Saha*

Main category: cs.CL

TL;DR: 本文提出了一种新的SLM（小型语言模型）架构Leviathan，用连续嵌入生成器替换了传统模型的离散查找表，实现了更高效的参数利用和更优性能。实验表明Leviathan在相同参数量下显著优于标准LLaMA风格架构。


<details>
  <summary>Details</summary>
Motivation: 目前主流的transformer缩放定律假设参数可以互换，但在百万级、千万级小型模型中，embedding矩阵占用了绝大多数参数，这种分配方式并不高效。作者希望改进小模型的参数利用率和性能。

Method: 本文提出Leviathan架构，引入连续嵌入生成器（continuous embedding generator），用生成器代替传统的embedding查找表。通过在The Pile数据集上进行等参数量模型对比实验，并用经验幂律拟合分析参数效率。

Result: 在同等参数设置下，Leviathan在The Pile数据集上稳定优于标准LLaMA风格架构，表现出更高的有效参数容量，根据幂律拟合，Leviathan等效于拥有1.47到2.11倍参数量的稠密模型表现。

Conclusion: 传统embedding方式在小模型下效率低下，Leviathan用生成式embedding有效提升了参数利用率和模型性能，建议面向SLM采用更高效的embedding策略。

Abstract: Transformer scaling law analyses typically treat parameters as interchangeable; an abstraction that accurately predicts loss-compute relationships. Yet, in sub-billion-parameter small language models (SLMs), embedding matrices dominate the parameter budget. This work argues that this allocation is as suboptimal as it is counterintuitive. Leviathan is an architecture with a continuous embedding generator to replace the discrete lookup tables of canonical models. Evaluating on the Pile dataset under isoparametric settings, Leviathan consistently outperforms a standard, LLaMA-style architecture. By means of an empirical power-law fit, Leviathan exhibits a markedly superior effective parameter capacity. Across the regime studied, Leviathan behaves as a dense model with $1.47$ to $2.11 \times$ more parameters.

</details>


### [157] [On the Paradoxical Interference between Instruction-Following and Task Solving](https://arxiv.org/abs/2601.22047)
*Yunjia Qi,Hao Peng,Xintong Shi,Amy Xin,Xiaozhi Wang,Bin Xu,Lei Hou,Juanzi Li*

Main category: cs.CL

TL;DR: 本论文发现：在对大型语言模型（LLM）施加“遵循指令”约束以实现人类意图对齐的过程中，反而可能对其任务解决能力产生负面影响，提出了SUSTAINSCORE指标量化这一现象。


<details>
  <summary>Details</summary>
Motivation: 尽管指令遵循被广泛用作提升LLM与人类意图对齐的手段，作者注意到其副作用尚缺乏系统研究，尤其是指令对模型任务表现的真实影响，因而希望揭示和量化这一可能的负效应。

Method: 提出SUSTAINSCORE评估指标，通过将原本模型已自然满足的约束显式加入指令中，并测量模型性能变化。在数学、多跳问答和代码生成等多任务上对主流模型（含Claude-Sonnet-4.5）进行实验，并分析失败样例的注意力分布机制。

Result: 结果显示，加入“本应自明”的约束会显著降低主流LLM的任务性能。该现象在不同类型、不同尺度约束下均普遍存在。失败案例显著更多关注约束内容。本方法还用于初步对比不同后训练范式对这一现象的影响。

Conclusion: 指令遵循在促进对齐的同时，可能干扰模型的原有任务能力，并非绝对利好。论文工具与发现为理解模型对齐方式的潜在折中和后续优化指令设计提供了实践支持。

Abstract: Instruction following aims to align Large Language Models (LLMs) with human intent by specifying explicit constraints on how tasks should be performed. However, we reveal a counterintuitive phenomenon: instruction following can paradoxically interfere with LLMs' task-solving capability. We propose a metric, SUSTAINSCORE, to quantify the interference of instruction following with task solving. It measures task performance drop after inserting into the instruction a self-evident constraint, which is naturally met by the original successful model output and extracted from it. Experiments on current LLMs in mathematics, multi-hop QA, and code generation show that adding the self-evident constraints leads to substantial performance drops, even for advanced models such as Claude-Sonnet-4.5. We validate the generality of the interference across constraint types and scales. Furthermore, we identify common failure patterns, and by investigating the mechanisms of interference, we observe that failed cases allocate significantly more attention to constraints compared to successful ones. Finally, we use SUSTAINSCORE to conduct an initial investigation into how distinct post-training paradigms affect the interference, presenting empirical observations on current alignment strategies. We will release our code and data to facilitate further research

</details>


### [158] [MasalBench: A Benchmark for Contextual and Cross-Cultural Understanding of Persian Proverbs in LLMs](https://arxiv.org/abs/2601.22050)
*Ghazal Kalhor,Behnam Bahrak*

Main category: cs.CL

TL;DR: 本文提出了MasalBench，一个用于评估多语言大模型在波斯语谚语理解和跨文化比喻推理方面的基准，并发现模型在语境内识别表现良好，但在跨语言类比上有不足。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在高资源语言的比喻性语言理解上已有评估，但对低资源语言（如波斯语）的同类能力还缺乏系统研究。日常对话中谚语尤为常见，因此评估模型在这方面的能力十分重要。

Method: 作者构建了MasalBench，聚焦于波斯语谚语的上下文和跨文化理解，筛选了具有代表性的任务并对八个SOTA大模型进行评估，测试它们在识别波斯语谚语以及查找英文等价谚语方面的表现。

Result: 八个主流大模型在波斯语谚语的语境识别中表现优异，准确率均高于0.90，但在寻找英语等效谚语时表现下降，最高仅0.79。

Conclusion: 现有大模型在低资源语言及其跨文化谚语理解方面仍有明显短板。MasalBench为其他低资源语言相关研究提供了实验范式，有助于未来多语言、多文化理解能力的提升。

Abstract: In recent years, multilingual Large Language Models (LLMs) have become an inseparable part of daily life, making it crucial for them to master the rules of conversational language in order to communicate effectively with users. While previous work has evaluated LLMs' understanding of figurative language in high-resource languages, their performance in low-resource languages remains underexplored. In this paper, we introduce MasalBench, a comprehensive benchmark for assessing LLMs' contextual and cross-cultural understanding of Persian proverbs, which are a key component of conversation in this low-resource language. We evaluate eight state-of-the-art LLMs on MasalBench and find that they perform well in identifying Persian proverbs in context, achieving accuracies above 0.90. However, their performance drops considerably when tasked with identifying equivalent English proverbs, with the best model achieving 0.79 accuracy. Our findings highlight the limitations of current LLMs in cultural knowledge and analogical reasoning, and they provide a framework for assessing cross-cultural understanding in other low-resource languages. MasalBench is available at https://github.com/kalhorghazal/MasalBench.

</details>


### [159] [$G^2$-Reader: Dual Evolving Graphs for Multimodal Document QA](https://arxiv.org/abs/2601.22055)
*Yaxin Du,Junru Song,Yifan Zhou,Cheng Wang,Jiahao Gu,Zimeng Chen,Menglan Chen,Wen Yao,Yang Yang,Ying Wen,Siheng Chen*

Main category: cs.CL

TL;DR: 本文提出了 G^2-Reader，一个用于多模态长文档问答的二重图系统，通过保持内容结构和跟踪推理过程，提升了检索增强生成的效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于检索增强生成（RAG）的问答在处理包含文本、表格和图片混排的多模态长文档时，存在两大问题：一是常用的片段划分方法打破了文档结构，导致语义片段难以独立解释；二是传统迭代检索在长文档中易因缺乏全局搜索状态而产生信息漂移和噪声累积，检索路线容易偏离目标。本文旨在解决上述多模态长文档问答中的结构保持和推理追踪难题。

Method: 提出了 G^2-Reader 系统。创新点有二：一是设计内容图（Content Graph），保留文档原生结构及多模态语义对齐；二是引入规划图（Planning Graph），用有向无环图动态跟踪子问题和中间结论，以引导有条理的证据检索和逐步解答。系统整体实现了结构和推理的双重可持续追踪。

Result: 在 VisDoMBench 多模态问答基准测试上，G^2-Reader 搭配 Qwen3-VL-32B-Instruct 模型取得了 66.21% 平均准确率，明显优于各类强基线方法及单一 GPT-5（53.08%）。

Conclusion: G^2-Reader 通过二重图结构，有效提升了多模态长文档问答的准确性与推理能力，为结构化检索与多步推理提供了新的解决路径。

Abstract: Retrieval-augmented generation is a practical paradigm for question answering over long documents, but it remains brittle for multimodal reading where text, tables, and figures are interleaved across many pages. First, flat chunking breaks document-native structure and cross-modal alignment, yielding semantic fragments that are hard to interpret in isolation. Second, even iterative retrieval can fail in long contexts by looping on partial evidence or drifting into irrelevant sections as noise accumulates, since each step is guided only by the current snippet without a persistent global search state. We introduce $G^2$-Reader, a dual-graph system, to address both issues. It evolves a Content Graph to preserve document-native structure and cross-modal semantics, and maintains a Planning Graph, an agentic directed acyclic graph of sub-questions, to track intermediate findings and guide stepwise navigation for evidence completion. On VisDoMBench across five multimodal domains, $G^2$-Reader with Qwen3-VL-32B-Instruct reaches 66.21\% average accuracy, outperforming strong baselines and a standalone GPT-5 (53.08\%).

</details>


### [160] [VTC-R1: Vision-Text Compression for Efficient Long-Context Reasoning](https://arxiv.org/abs/2601.22069)
*Yibo Wang,Yongcheng Jing,Shunyu Liu,Hao Guan,Rong-cheng Tu,Chengyu Wang,Jun Huang,Dacheng Tao*

Main category: cs.CL

TL;DR: 本文提出了一种新的高效推理范式VTC-R1，将视觉-文本压缩融入长上下文推理过程，通过将中间推理片段渲染为紧凑图像后再反馈至视觉语言模型，提高了长上下文任务的推理效率和效果。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在长上下文推理任务中表现出色，但其计算复杂度带来了效率瓶颈。现有高效方法多依赖复杂的额外训练或外部压缩模型，扩展性差且易丢失关键细粒度信息。

Method: VTC-R1在推理过程中，将冗长的文本推理片段渲染为精简的图像，并将这些图像作为'光学记忆'迭代输入至视觉语言模型。基于OpenR1-Math-220K构建训练集，对Glyph与Qwen3-VL等视觉语言模型进行了微调。

Result: 在MATH500、AIME25、AMC23和GPQA-D等基准测试中，VTC-R1在推理表现上均优于传统长上下文方法，达到了3.4倍token压缩，并在端到端延迟上实现了2.7倍的加速。

Conclusion: VTC-R1为需求密集推理的场景提供了一种可扩展且高效的解决思路，兼顾了推理准确性与效率，具有广阔的实际应用前景。

Abstract: Long-context reasoning has significantly empowered large language models (LLMs) to tackle complex tasks, yet it introduces severe efficiency bottlenecks due to the computational complexity. Existing efficient approaches often rely on complex additional training or external models for compression, which limits scalability and discards critical fine-grained information. In this paper, we propose VTC-R1, a new efficient reasoning paradigm that integrates vision-text compression into the reasoning process. Instead of processing lengthy textual traces, VTC-R1 renders intermediate reasoning segments into compact images, which are iteratively fed back into vision-language models as "optical memory." We construct a training dataset based on OpenR1-Math-220K achieving 3.4x token compression and fine-tune representative VLMs-Glyph and Qwen3-VL. Extensive experiments on benchmarks such as MATH500, AIME25, AMC23 and GPQA-D demonstrate that VTC-R1 consistently outperforms standard long-context reasoning. Furthermore, our approach significantly improves inference efficiency, achieving 2.7x speedup in end-to-end latency, highlighting its potential as a scalable solution for reasoning-intensive applications. Our code is available at https://github.com/w-yibo/VTC-R1.

</details>


### [161] [ECO: Quantized Training without Full-Precision Master Weights](https://arxiv.org/abs/2601.22101)
*Mahdi Nikdan,Amir Zandieh,Dan Alistarh,Vahab Mirrokni*

Main category: cs.CL

TL;DR: 本文提出了一种名为ECO（Error-Compensating Optimizer）的优化器，用于消除大模型训练时高精度主权重(master weights)带来的内存负担，从而更高效地实现量化训练。ECO直接在量化后的参数上更新，并通过误差反馈机制修正精度损失，实验证明其效果媲美传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）训练中量化方法虽提升了效率，但仍需依赖高精度主权重来累积更新，导致内存消耗较大，尤其在稀疏专家模型（SMoE）下更为明显。现有方法难以同时兼顾内存降低与高精度，因此亟需突破。

Method: ECO优化器通过直接在量化权重上应用梯度更新，每次量化后把因量化产生的误差注入优化器动量，相当于构建无额外内存占用的误差反馈环路。此外，提出理论证明ECO在标准假设及衰减学习率下能收敛到最优点附近。

Result: 在30M-800M小型Transformer、Gemma-3 1B、2.1B Sparse MoE（FP8量化）预训练和DeepSeek-MoE-16B（INT4量化）微调实验中，ECO在几乎无精度损失下匹配有主权重的基线模型，实现了更优内存与准确率平衡。

Conclusion: ECO在大模型量化训练中消除了对主权重内存的依赖，同时保持了近乎无损的精度，为高效模型训练开辟了新路径，优化了内存使用与模型性能之间的权衡。

Abstract: Quantization has significantly improved the compute and memory efficiency of Large Language Model (LLM) training. However, existing approaches still rely on accumulating their updates in high-precision: concretely, gradient updates must be applied to a high-precision weight buffer, known as $\textit{master weights}$. This buffer introduces substantial memory overhead, particularly for Sparse Mixture of Experts (SMoE) models, where model parameters and optimizer states dominate memory usage. To address this, we introduce the Error-Compensating Optimizer (ECO), which eliminates master weights by applying updates directly to quantized parameters. ECO quantizes weights after each step and carefully injects the resulting quantization error into the optimizer momentum, forming an error-feedback loop with no additional memory. We prove that, under standard assumptions and a decaying learning rate, ECO converges to a constant-radius neighborhood of the optimum, while naive master-weight removal can incur an error that is inversely proportional to the learning rate. We show empirical results for pretraining small Transformers (30-800M), a Gemma-3 1B model, and a 2.1B parameter Sparse MoE model with FP8 quantization, and fine-tuning DeepSeek-MoE-16B in INT4 precision. Throughout, ECO matches baselines with master weights up to near-lossless accuracy, significantly shifting the static memory vs validation loss Pareto frontier.

</details>


### [162] [A Federated and Parameter-Efficient Framework for Large Language Model Training in Medicine](https://arxiv.org/abs/2601.22124)
*Anran Li,Yuanyuan Chen,Wenjun Long,Yu Yin,Yan Hu,Hyunjae Kim,Weipeng Zhou,Yujia Zhou,Hongyi Peng,Yang Ren,Xuguang Ai,Zhenyue Qin,Ming Hu,Xiaoxiao Li,Han Yu,Yih-Chung Tham,Lucila Ohno-Machado,Hua Xu,Qingyu Chen*

Main category: cs.CL

TL;DR: 本论文提出了针对医学大模型的高效联邦学习框架Fed-MedLoRA及其增强版Fed-MedLoRA+，显著减少了通信与计算开销，提高了异构临床数据环境下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前医学大语言模型（LLM）多依赖单一机构数据进行训练，难以适应多机构、多源临床数据的异质性，且受限于庞大模型参数带来的通信与计算负担，不适于联邦学习环境。

Method: 采用模型无关且高效参数更新的低秩适配器（Low-Rank Adapter），在联邦学习过程中仅传输少量适配器参数，极大降低了通信量。增强版Fed-MedLoRA+进一步引入自适应、数据感知的聚合方法，提高了模型在多机构异质数据上的收敛与泛化能力。

Result: 将该框架应用于临床信息抽取任务，在五个患者队列中，与BERT、LLaMA-3、DeepSeek-R1及GPT-4o等模型进行对比，分别在域内、外部验证及低资源新站点适配场景下获得优秀性能。

Conclusion: Fed-MedLoRA及Fed-MedLoRA+为医疗大模型在异构、多机构环境下的联邦学习提供了高效、泛化性强的解决方案，有望安全高效地促进医学AI在实际临床中的应用。

Abstract: Large language models (LLMs) have demonstrated strong performance on medical benchmarks, including question answering and diagnosis. To enable their use in clinical settings, LLMs are typically further adapted through continued pretraining or post-training using clinical data. However, most medical LLMs are trained on data from a single institution, which faces limitations in generalizability and safety in heterogeneous systems. Federated learning (FL) is a promising solution for enabling collaborative model development across healthcare institutions. Yet applying FL to LLMs in medicine remains fundamentally limited. First, conventional FL requires transmitting the full model during each communication round, which becomes impractical for multi-billion-parameter LLMs given the limited computational resources. Second, many FL algorithms implicitly assume data homogeneity, whereas real-world clinical data are highly heterogeneous across patients, diseases, and institutional practices. We introduce the model-agnostic and parameter-efficient federated learning framework for adapting LLMs to medical applications. Fed-MedLoRA transmits only low-rank adapter parameters, reducing communication and computation overhead, while Fed-MedLoRA+ further incorporates adaptive, data-aware aggregation to improve convergence under cross-site heterogeneity. We apply the framework to clinical information extraction (IE), which transforms patient narratives into structured medical entities and relations. Accuracy was assessed across five patient cohorts through comparisons with BERT models, and LLaMA-3 and DeepSeek-R1, GPT-4o models. Evaluation settings included (1) in-domain training and testing, (2) external validation on independent cohorts, and (3) a low-resource new-site adaptation scenario using real-world clinical notes from the Yale New Haven Health System.

</details>


### [163] [Reasoning While Asking: Transforming Reasoning Large Language Models from Passive Solvers to Proactive Inquirers](https://arxiv.org/abs/2601.22139)
*Xin Chen,Feng Jiang,Yiqian Zhang,Hardy Chen,Shuo Yan,Wenya Xie,Min Yang,Shujian Huang*

Main category: cs.CL

TL;DR: 本文提出了一种新型推理范式Proactive Interactive Reasoning (PIR)，让大模型主动与用户交互以澄清不确定信息，并在多项任务中实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型通过链式思维（CoT）进行推理时，常陷入“盲目自思考”，即在关键信息缺失或含糊时仍然被动推理，导致错误或低效。因此亟需一种方法让模型能主动弥补信息不足，提高推理效果与交互性。

Method: 本文提出PIR范式，包括：1）基于不确定性感知的有监督微调，使模型能进行互动式推理；2）基于用户模拟器的策略优化，用复杂奖励函数让模型行为更契合用户意图。

Result: 在数学推理、代码生成、文档编辑等任务中，PIR较强大基线模型最高提升准确率32.7%、提升通关率22.9%、BLEU分数提高41.36分，并显著减少计算量和冗余交互轮次。在知识问答和前提缺失等稳健性实验中，PIR表现出更强泛化和稳健性。

Conclusion: PIR显著提升了LLMs在面对不确定或不完整信息时的推理精准度、效率和可靠性，推动了语言模型从被动响应向主动交互转变。

Abstract: Reasoning-oriented Large Language Models (LLMs) have achieved remarkable progress with Chain-of-Thought (CoT) prompting, yet they remain fundamentally limited by a \emph{blind self-thinking} paradigm: performing extensive internal reasoning even when critical information is missing or ambiguous. We propose Proactive Interactive Reasoning (PIR), a new reasoning paradigm that transforms LLMs from passive solvers into proactive inquirers that interleave reasoning with clarification. Unlike existing search- or tool-based frameworks that primarily address knowledge uncertainty by querying external environments, PIR targets premise- and intent-level uncertainty through direct interaction with the user. PIR is implemented via two core components: (1) an uncertainty-aware supervised fine-tuning procedure that equips models with interactive reasoning capability, and (2) a user-simulator-based policy optimization framework driven by a composite reward that aligns model behavior with user intent. Extensive experiments on mathematical reasoning, code generation, and document editing demonstrate that PIR consistently outperforms strong baselines, achieving up to 32.70\% higher accuracy, 22.90\% higher pass rate, and 41.36 BLEU improvement, while reducing nearly half of the reasoning computation and unnecessary interaction turns. Further reliability evaluations on factual knowledge, question answering, and missing-premise scenarios confirm the strong generalization and robustness of PIR. Model and code are publicly available at: \href{https://github.com/SUAT-AIRI/Proactive-Interactive-R1}

</details>


### [164] [FineInstructions: Scaling Synthetic Instructions to Pre-Training Scale](https://arxiv.org/abs/2601.22146)
*Ajay Patel,Colin Raffel,Chris Callison-Burch*

Main category: cs.CL

TL;DR: 本文提出了一种从大规模无结构文本中构建海量合成指令-回答对（FineInstructions）的新方法，大幅提升了大语言模型的自监督训练效果。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型的监督指令微调数据稀缺，导致模型下游效果受限。如何扩充高质量指令微调数据，是提升模型实用性的关键。

Method: 作者提出通过18M用户实际问题和提示模板，结合无结构语料，将其匹配并实例化为合成的指令-回答对，生成庞大的FineInstructions数据集，让语言模型直接以指令微调任务从零训练。

Result: 在标准自由问答任务基准上，使用FineInstructions预训练的模型表现优于传统预训练及其他合成预训练方法。

Conclusion: 规模化合成指令-回答数据能够完全替代传统自监督预训练，显著提升大语言模型在指令响应任务的表现。FineInstructions为丰富高质量指令微调数据提供了新方案。

Abstract: Due to limited supervised training data, large language models (LLMs) are typically pre-trained via a self-supervised "predict the next word" objective on a vast amount of unstructured text data. To make the resulting model useful to users, it is further trained on a far smaller amount of "instruction-tuning" data comprised of supervised training examples of instructions and responses. To overcome the limited amount of supervised data, we propose a procedure that can transform the knowledge in internet-scale pre-training documents into billions of synthetic instruction and answer training pairs. The resulting dataset, called FineInstructions, uses ~18M instruction templates created from real user-written queries and prompts. These instruction templates are matched to and instantiated with human-written source documents from unstructured pre-training corpora. With "supervised" synthetic training data generated at this scale, an LLM can be pre-trained from scratch solely with the instruction-tuning objective, which is far more in-distribution with the expected downstream usage of LLMs (responding to user prompts). We conduct controlled token-for-token training experiments and find pre-training on FineInstructions outperforms standard pre-training and other proposed synthetic pre-training techniques on standard benchmarks measuring free-form response quality. Our resources can be found at https://huggingface.co/fineinstructions .

</details>


### [165] [DynaWeb: Model-Based Reinforcement Learning of Web Agents](https://arxiv.org/abs/2601.22149)
*Hang Ding,Peidong Liu,Junqiao Wang,Ziwei Ji,Meng Cao,Rongzhao Zhang,Lynn Ai,Eric Yang,Tianyu Shi,Lei Yu*

Main category: cs.CL

TL;DR: 本文提出了一种名为DynaWeb的新型基于模型的强化学习（MBRL）框架，通过训练web世界模型以实现高效的web智能体训练，并大幅提升了主流开源web智能体在多个基准任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前基于大模型和强化学习的web智能体在真实互联网环境中训练面临高成本与高风险，因此亟需一种高效且安全的训练方式。MBRL能够通过世界模型模拟环境，避免现实交互风险，但在web场景中的实践与效果尚不明确。

Method: 提出DynaWeb框架：先训练一个web世界模型，使其能够根据智能体动作预测页面表现，进而在该模型上生成大量rollout轨迹用于在线强化学习。此外，还将真实专家行为轨迹与生成轨迹混合，提高训练稳定性和样本利用率。

Result: 在WebArena和WebVoyager等高难度基准上，DynaWeb有效提升了现有开源web智能体的性能，表现出优越的稳定性与效率。

Conclusion: DynaWeb验证了通过“想象”训练web智能体的可行性，为大规模、高效地推进在线智能体强化学习提供了新途径。

Abstract: The development of autonomous web agents, powered by Large Language Models (LLMs) and reinforcement learning (RL), represents a significant step towards general-purpose AI assistants. However, training these agents is severely hampered by the challenges of interacting with the live internet, which is inefficient, costly, and fraught with risks. Model-based reinforcement learning (MBRL) offers a promising solution by learning a world model of the environment to enable simulated interaction. This paper introduces DynaWeb, a novel MBRL framework that trains web agents through interacting with a web world model trained to predict naturalistic web page representations given agent actions. This model serves as a synthetic web environment where an agent policy can dream by generating vast quantities of rollout action trajectories for efficient online reinforcement learning. Beyond free policy rollouts, DynaWeb incorporates real expert trajectories from training data, which are randomly interleaved with on-policy rollouts during training to improve stability and sample efficiency. Experiments conducted on the challenging WebArena and WebVoyager benchmarks demonstrate that DynaWeb consistently and significantly improves the performance of state-of-the-art open-source web agent models. Our findings establish the viability of training web agents through imagination, offering a scalable and efficient way to scale up online agentic RL.

</details>


### [166] [Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts](https://arxiv.org/abs/2601.22156)
*Yingfa Chen,Zhen Leng Thai,Zihan Zhou,Zhu Zhang,Xingyu Shen,Shuo Wang,Chaojun Xiao,Xu Han,Zhiyuan Liu*

Main category: cs.CL

TL;DR: 本文提出了一种新的将Transformer模型高效转化为混合RNN-注意力模型的方案（HALO），并提出了HypeNet这一更好泛化和高效的混合架构，实现了在更少训练数据下的高性能和长上下文优势。


<details>
  <summary>Details</summary>
Motivation: 目前混合Transformer（融合自注意力机制和RNN）在长上下文建模中具备高效性，但现有方法需要大量数据和成本，且长上下文表现不佳，限制了实际应用。

Method: 作者提出HALO管道，对预训练Transformer进行蒸馏、参数转移，转化为RNN-注意力混合模型。并创新地设计了位置编码（HyPE）和架构修改，形成新架构HypeNet，显著减少数据需求。

Result: 用HALO将Qwen3系列模型转化为HypeNet，只需2.3B tokens（相当于预训练数据的0.01%），即达到了与原Transformer相当的性能，并在长上下文场景下表现、更高推理效率。

Conclusion: HALO和HypeNet显著降低了混合模型训练的门槛，在长文本建模中展现出效率与效果兼具的潜力，为大模型落地提供了新方案。

Abstract: Hybrid Transformer architectures, which combine softmax attention blocks and recurrent neural networks (RNNs), have shown a desirable performance-throughput tradeoff for long-context modeling, but their adoption and studies are hindered by the prohibitive cost of large-scale pre-training from scratch. Some recent studies have shown that pre-trained softmax attention blocks can be converted into RNN blocks through parameter transfer and knowledge distillation. However, these transfer methods require substantial amounts of training data (more than 10B tokens), and the resulting hybrid models also exhibit poor long-context performance, which is the scenario where hybrid models enjoy significant inference speedups over Transformer-based models. In this paper, we present HALO (Hybrid Attention via Layer Optimization), a pipeline for distilling Transformer models into RNN-attention hybrid models. We then present HypeNet, a hybrid architecture with superior length generalization enabled by a novel position encoding scheme (named HyPE) and various architectural modifications. We convert the Qwen3 series into HypeNet using HALO, achieving performance comparable to the original Transformer models while enjoying superior long-context performance and efficiency. The conversion requires just 2.3B tokens, less than 0.01% of their pre-training data

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [167] [Quick Heuristic Validation of Edges in Dynamic Roadmap Graphs](https://arxiv.org/abs/2601.20968)
*Yulie Arad,Stav Ashur,Nancy M. Amato*

Main category: cs.RO

TL;DR: 提出了一种适用于动态环境下机器人运动规划的路网图快速更新方法，即“红-绿-灰”范式，对图的节点和边进行有效性快速分类，并验证其实验效果。


<details>
  <summary>Details</summary>
Motivation: 机器人在动态或非静态环境中需要频繁更新运动规划路网图，传统方法更新速度慢、效率低，难以适应实时性的需求。

Method: 提出“红-绿-灰”范式，通过廉价启发式检查（如简单计算几何方法近似机器人扫掠体积及惰性碰撞检测）对节点和边进行快速分为无效（红）、有效（绿）、未知（灰）三类，大幅加快路网图更新，属于SPITE方法的改进。

Result: 初步实验对比主流Leven和Hutchinson技术显示，该方法可提高分类准确率，能够更有效地识别无效边，并且更新运行时间相当。

Conclusion: “红-绿-灰”范式提升了动态环境下机器人路网图的更新效率和准确性，对于实时运动规划具有良好的应用前景。

Abstract: In this paper we tackle the problem of adjusting roadmap graphs for robot motion planning to non-static environments. We introduce the "Red-Green-Gray" paradigm, a modification of the SPITE method, capable of classifying the validity status of nodes and edges using cheap heuristic checks, allowing fast semi-lazy roadmap updates. Given a roadmap, we use simple computational geometry methods to approximate the swept volumes of robots and perform lazy collision checks, and label a subset of the edges as invalid (red), valid (green), or unknown (gray). We present preliminary experimental results comparing our method to the well-established technique of Leven and Hutchinson, and showing increased accuracy as well as the ability to correctly label edges as invalid while maintaining comparable update runtimes.

</details>


### [168] [Meta-ROS: A Next-Generation Middleware Architecture for Adaptive and Scalable Robotic Systems](https://arxiv.org/abs/2601.21011)
*Anshul Ranjan,Anoosh Damodar,Neha Chougule,Dhruva S Nayak,Anantharaman P. N,Shylaja S S*

Main category: cs.RO

TL;DR: 提出了一种新型机器人中间件Meta-ROS，用于简化开发、提升性能并增强跨平台兼容性。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人中间件框架如ROS2，存在复杂难用、新手不易上手、互操作性差等问题，影响机器人领域发展。

Method: 设计了Meta-ROS中间件，采用Zenoh和ZeroMQ等高效通信协议，支持多种数据类型并适配多种硬件，通过实验与ROS1、ROS2等主流框架进行系统性能对比。

Result: Meta-ROS在性能测试中显著优于ROS2，在吞吐量、消息延迟和资源占用方面表现更佳，其中吞吐量提升达30%；同时简化了硬件支持和集成开发流程。

Conclusion: Meta-ROS具备高性能、易集成与良好兼容性，特别适合现代实时机器人和AI应用开发，是现有主流中间件的有力替代方案。

Abstract: The field of robotics faces significant challenges related to the complexity and interoperability of existing middleware frameworks, like ROS2, which can be difficult for new developers to adopt. To address these issues, we propose Meta-ROS, a novel middleware solution designed to streamline robotics development by simplifying integration, enhancing performance, and ensuring cross-platform compatibility. Meta-ROS leverages modern communication protocols, such as Zenoh and ZeroMQ, to enable efficient and low-latency communication across diverse hardware platforms, while also supporting various data types like audio, images, and video. We evaluated Meta-ROS's performance through comprehensive testing, comparing it with existing middleware frameworks like ROS1 and ROS2. The results demonstrated that Meta-ROS outperforms ROS2, achieving up to 30% higher throughput, significantly reducing message latency, and optimizing resource usage. Additionally, its robust hardware support and developer-centric design facilitate seamless integration and ease of use, positioning Meta-ROS as an ideal solution for modern, real-time robotics AI applications.

</details>


### [169] [Track-centric Iterative Learning for Global Trajectory Optimization in Autonomous Racing](https://arxiv.org/abs/2601.21027)
*Youngim Nam,Jungbin Kim,Kyungtae Kang,Cheolhyeon Kwon*

Main category: cs.RO

TL;DR: 提出了一种结合贝叶斯优化和小波变换参数化的新框架，实现了在动力学不确定情况下自主赛车的全局轨迹优化，显著减少了单圈用时。


<details>
  <summary>Details</summary>
Motivation: 现有自动赛车全局轨迹优化因动力学不确定和计算量大而难以实现，且大多数方法仅在轨迹跟踪层面学习动力学，未能将学习到的动力学反馈到整个轨迹优化中。

Method: 1. 用小波变换将轨迹表示于与赛道无关的参数空间。2. 利用贝叶斯优化在该空间高效寻找最优轨迹，每次轨迹评估通过带学习动力学的仿真评价圈时。3. 将优化结果在物理车辆上测试，采集新数据以迭代更新动力学模型和轨迹。

Result: 仿真及真实车辆实验表明，该方法在圈时上相较基线最多可提升20.7%，并优于现有其他方法。

Conclusion: 该全局-迭代学习方法能有效弥合动力学模型学习与轨迹全局优化间的鸿沟，为自动赛车赛道圈速提升提供了新思路。

Abstract: This paper presents a global trajectory optimization framework for minimizing lap time in autonomous racing under uncertain vehicle dynamics. Optimizing the trajectory over the full racing horizon is computationally expensive, and tracking such a trajectory in the real world hardly assures global optimality due to uncertain dynamics. Yet, existing work mostly focuses on dynamics learning at the tracking level, without updating the trajectory itself to account for the learned dynamics. To address these challenges, we propose a track-centric approach that directly learns and optimizes the full-horizon trajectory. We first represent trajectories through a track-agnostic parametric space in light of the wavelet transform. This space is then efficiently explored using Bayesian optimization, where the lap time of each candidate is evaluated by running simulations with the learned dynamics. This optimization is embedded in an iterative learning framework, where the optimized trajectory is deployed to collect real-world data for updating the dynamics, progressively refining the trajectory over the iterations. The effectiveness of the proposed framework is validated through simulations and real-world experiments, demonstrating lap time improvement of up to 20.7% over a nominal baseline and consistently outperforming state-of-the-art methods.

</details>


### [170] [Multi-Robot Decentralized Collaborative SLAM in Planetary Analogue Environments: Dataset, Challenges, and Lessons Learned](https://arxiv.org/abs/2601.21063)
*Pierre-Yves Lajoie,Karthik Soma,Haechan Mark Bong,Alice Lemieux-Bourque,Rongge Zhang,Vivek Shankar Varadharajan,Giovanni Beltrame*

Main category: cs.RO

TL;DR: 本文介绍了在类似火星地形上，三台机器人在没有预先通信基础设施情况下进行的去中心化多机器人协同SLAM（C-SLAM）实验，并发布了一个新数据集。


<details>
  <summary>Details</summary>
Motivation: 去中心化协同SLAM是未知环境下多机器人任务的核心技术，但星球探索面临没有现成通信与定位基础设施、通信受限等挑战。作者希望通过实际实验深入理解这些挑战并为该领域研究提供数据支撑。

Method: 作者设计了三台机器人在火星模拟地形上的实践实验，通过临时组建的自组网实现机器人间通信，持续评估有限和间歇性通信下C-SLAM效果，并实时记录互联吞吐量和延时。

Result: 实验揭示了受限通信对C-SLAM性能的具体影响，还发现了类行星环境对定位的独特挑战，并首次采集并公布了多机器人网络通信性能的真实数据集。

Conclusion: 本文工作推进了对受通信约束的分布式多机器人协同SLAM理解，并为未来研究提供了宝贵实验数据资源，有助于月球、火星等星球探测任务的技术准备。

Abstract: Decentralized collaborative simultaneous localization and mapping (C-SLAM) is essential to enable multirobot missions in unknown environments without relying on preexisting localization and communication infrastructure. This technology is anticipated to play a key role in the exploration of the Moon, Mars, and other planets. In this article, we share insights and lessons learned from C-SLAM experiments involving three robots operating on a Mars analogue terrain and communicating over an ad hoc network. We examine the impact of limited and intermittent communication on C-SLAM performance, as well as the unique localization challenges posed by planetary-like environments. Additionally, we introduce a novel dataset collected during our experiments, which includes real-time peer-to-peer inter-robot throughput and latency measurements. This dataset aims to support future research on communication-constrained, decentralized multirobot operations.

</details>


### [171] [WheelArm-Sim: A Manipulation and Navigation Combined Multimodal Synthetic Data Generation Simulator for Unified Control in Assistive Robotics](https://arxiv.org/abs/2601.21129)
*Guangping Liu,Tipu Sultan,Vittorio Di Giorgio,Nick Hawkins,Flavio Esposito,Madi Babaiasl*

Main category: cs.RO

TL;DR: 本文提出了WheelArm，一种将轮椅和机械臂控制集成为一体的智能辅助系统，并开发了WheelArm-Sim仿真平台进行数据收集与评估。实验表明仿真数据可用于基于机器学习的数据驱动联合控制。


<details>
  <summary>Details</summary>
Motivation: 当前助残机器人多关注轮椅和机械臂各自独立控制，缺乏对二者统一集成控制的研究，因此需要新方法来实现更高效的集成辅助。

Method: 设计并实现了WheelArm-Sim仿真平台，在Isaac Sim环境下收集综合导航与操作的多模态数据集，包括13项任务、232条轨迹和67783组样本，并在其中一个任务上训练并测试基线动作预测模型。

Result: 通过仿真平台收集到的数据被用于机器学习模型训练，实验证明该数据可用于实现集成控制的动作预测，验证了仿真框架的有效性。

Conclusion: WheelArm提出的仿真与数据采集体系为集成轮椅与机械臂的智能控制提供了新方法，证明了数据驱动的集成控制具有可行性，为后续相关研究奠定了基础。

Abstract: Wheelchairs and robotic arms enhance independent living by assisting individuals with upper-body and mobility limitations in their activities of daily living (ADLs). Although recent advancements in assistive robotics have focused on Wheelchair-Mounted Robotic Arms (WMRAs) and wheelchairs separately, integrated and unified control of the combination using machine learning models remains largely underexplored. To fill this gap, we introduce the concept of WheelArm, an integrated cyber-physical system (CPS) that combines wheelchair and robotic arm controls. Data collection is the first step toward developing WheelArm models. In this paper, we present WheelArm-Sim, a simulation framework developed in Isaac Sim for synthetic data collection. We evaluate its capability by collecting a manipulation and navigation combined multimodal dataset, comprising 13 tasks, 232 trajectories, and 67,783 samples. To demonstrate the potential of the WheelArm dataset, we implement a baseline model for action prediction in the mustard-picking task. The results illustrate that data collected from WheelArm-Sim is feasible for a data-driven machine learning model for integrated control.

</details>


### [172] [InspecSafe-V1: A Multimodal Benchmark for Safety Assessment in Industrial Inspection Scenarios](https://arxiv.org/abs/2601.21173)
*Zeyi Liu,Shuang Liu,Jihai Min,Zhaoheng Zhang,Jun Cen,Pengyu Han,Songqiao Hu,Zihan Meng,Xiao He,Donghua Zhou*

Main category: cs.RO

TL;DR: 该论文发布了InspecSafe-V1，这是首个面向工业巡检安全评估的多模态基准数据集，包含真实机器人在实际工业现场采集的多模态、高质量注释数据，支持工业AI系统的安全感知与多模态推理。


<details>
  <summary>Details</summary>
Motivation: 当前工业AI系统在复杂环境下的安全感知与评估缺乏高质量、真实、多模态及细粒度注释的数据集。现有公开数据多为仿真或单一模态、无精细物体级标注，难以满足工业基础模型对场景理解和安全推理的需求。

Method: 作者基于真实工业巡检机器人的日常巡检任务，采集了涵盖五类典型工业场景的原始多模态数据。数据集包括七种同步传感器模态（可见光、红外、音频、深度点云、雷达点云、气体、温湿度），对每一实例提供像素级的物体分割标注和场景语义描述及安全等级标签。共采集5,013个巡检数据实例，覆盖2,239个有效巡检点。

Result: InspecSafe-V1数据集真实反映了复杂工业场景下巡检任务的感知要求，提供了高质量的多模态与细粒度标注，能够支持多模态异常识别、跨模态融合与综合安全评估，为工业AI基础模型的开发与验证搭建了公认的平台。

Conclusion: InspecSafe-V1显著提升了工业巡检安全评估领域的数据基础，有助于推动工业AI系统的多模态感知和安全推理能力，促进相关算法和模型在实际工业环境中的可靠应用。

Abstract: With the rapid development of industrial intelligence and unmanned inspection, reliable perception and safety assessment for AI systems in complex and dynamic industrial sites has become a key bottleneck for deploying predictive maintenance and autonomous inspection. Most public datasets remain limited by simulated data sources, single-modality sensing, or the absence of fine-grained object-level annotations, which prevents robust scene understanding and multimodal safety reasoning for industrial foundation models. To address these limitations, InspecSafe-V1 is released as the first multimodal benchmark dataset for industrial inspection safety assessment that is collected from routine operations of real inspection robots in real-world environments. InspecSafe-V1 covers five representative industrial scenarios, including tunnels, power facilities, sintering equipment, oil and gas petrochemical plants, and coal conveyor trestles. The dataset is constructed from 41 wheeled and rail-mounted inspection robots operating at 2,239 valid inspection sites, yielding 5,013 inspection instances. For each instance, pixel-level segmentation annotations are provided for key objects in visible-spectrum images. In addition, a semantic scene description and a corresponding safety level label are provided according to practical inspection tasks. Seven synchronized sensing modalities are further included, including infrared video, audio, depth point clouds, radar point clouds, gas measurements, temperature, and humidity, to support multimodal anomaly recognition, cross-modal fusion, and comprehensive safety assessment in industrial environments.

</details>


### [173] [Disturbance-Aware Flight Control of Robotic Gliding Blimp via Moving Mass Actuation](https://arxiv.org/abs/2601.21188)
*Hao Cheng,Feitian Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种面向风扰动的控制框架，通过运动质量驱动与模型预测控制结合，有效提升了机器人飞艇在风中飞行的稳定性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 机器人飞艇虽然具备长续航和安全性高的优点，但对风的干扰极为敏感，现有控制框架很难在动态风环境中确保其精准稳定飞行。本文旨在填补LTA（lighter-than-air）平台在风扰动感知与补偿方面的研究空白。

Method: 设计了结合运动质量驱动的2自由度机构，通过运动视界估计器（MHE）实时推断风扰动，并将估计结果输入模型预测控制器（MPC），实现对风扰下轨迹和航向的鲁棒调节。

Result: 在顺风和侧风等多种风环境飞行实验表明，该集成MHE-MPC方法在轨迹和姿态控制性能上显著优于传统PID控制。

Conclusion: 通过引入风扰感知与补偿机制，机器人飞艇平台能够在复杂扰动环境中维持更强的飞行稳定性，为LTA系统的实用化应用奠定了技术基础。

Abstract: Robotic blimps, as lighter-than-air (LTA) aerial systems, offer long endurance and inherently safe operation but remain highly susceptible to wind disturbances. Building on recent advances in moving mass actuation, this paper addresses the lack of disturbance-aware control frameworks for LTA platforms by explicitly modeling and compensating for wind-induced effects. A moving horizon estimator (MHE) infers real-time wind perturbations and provides these estimates to a model predictive controller (MPC), enabling robust trajectory and heading regulation under varying wind conditions. The proposed approach leverages a two-degree-of-freedom (2-DoF) moving-mass mechanism to generate both inertial and aerodynamic moments for attitude and heading control, thereby enhancing flight stability in disturbance-prone environments. Extensive flight experiments under headwind and crosswind conditions show that the integrated MHE-MPC framework significantly outperforms baseline PID control, demonstrating its effectiveness for disturbance-aware LTA flight.

</details>


### [174] [Abstracting Robot Manipulation Skills via Mixture-of-Experts Diffusion Policies](https://arxiv.org/abs/2601.21251)
*Ce Hao,Xuanran Zhai,Yaohua Liu,Harold Soh*

Main category: cs.RO

TL;DR: 提出了一种新颖的基于扩散模型的专家混合策略（SMP），实现多任务机器人操作，以更低的模型规模和推理消耗取得了更优的结果。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在机器人操作领域表现优异，但面临扩展到多任务时，模型参数和示范数据成本高，难以高效扩展和迁移。如何实现高效、可扩展、便于迁移的多任务机器人能力，是亟需解决的问题。

Method: 本文提出Skill Mixture-of-Experts Policy（SMP），将扩散模型与专家混合机制结合，学习一组正交技能的紧凑基集。通过Sticky Routing机制，从相关专家子集中动态选择行动。同时，通过变分训练目标优化，利用自适应专家激活，实现推理阶段的快速采样，无需大型骨干网络。

Result: 在仿真和真实双臂平台上进行多任务学习和迁移实验，SMP在成功率和推理成本上均优于现有大型扩散基线方法，验证了其有效性和实用性。

Conclusion: SMP为可扩展、可迁移的多任务机器人操作提供新路径：一次学习可重用技能，推理时仅激活所需专长，并能在任务变化时快速适应。

Abstract: Diffusion-based policies have recently shown strong results in robot manipulation, but their extension to multi-task scenarios is hindered by the high cost of scaling model size and demonstrations. We introduce Skill Mixture-of-Experts Policy (SMP), a diffusion-based mixture-of-experts policy that learns a compact orthogonal skill basis and uses sticky routing to compose actions from a small, task-relevant subset of experts at each step. A variational training objective supports this design, and adaptive expert activation at inference yields fast sampling without oversized backbones. We validate SMP in simulation and on a real dual-arm platform with multi-task learning and transfer learning tasks, where SMP achieves higher success rates and markedly lower inference cost than large diffusion baselines. These results indicate a practical path toward scalable, transferable multi-task manipulation: learn reusable skills once, activate only what is needed, and adapt quickly when tasks change.

</details>


### [175] [Deep QP Safety Filter: Model-free Learning for Reachability-based Safety Filter](https://arxiv.org/abs/2601.21297)
*Byeongjun Kim,H. Jin Kim*

Main category: cs.RO

TL;DR: 提出了一种名为Deep QP Safety Filter的数据驱动安全控制方法，用于黑箱动力系统，实现了不依赖模型的安全控制。


<details>
  <summary>Details</summary>
Motivation: RL和控制任务中，模型未知或黑箱系统的安全问题突出，现有安全层方法大多基于已知模型，难以直接适用于复杂或混合系统，亟需数据驱动的通用安全控制方案。

Method: 方法利用Hamilton-Jacobi可达性与无模型强化学习结合，设计QP安全层，通过收缩性损失函数训练两个神经网络(分别预测安全值及其导数)，在极限情况下理论上可逼近粘性解及其导数。

Result: 在多种动力系统（包括混合系统）和RL任务上测试，Deep QP Safety Filter较现有方法大幅减少了学习前期的故障，提高了学习速度与最终收益。

Conclusion: 该方法为无模型安全控制提供了一种有效且理论扎实的新路径，兼具实用性和适用广度。

Abstract: We introduce Deep QP Safety Filter, a fully data-driven safety layer for black-box dynamical systems. Our method learns a Quadratic-Program (QP) safety filter without model knowledge by combining Hamilton-Jacobi (HJ) reachability with model-free learning. We construct contraction-based losses for both the safety value and its derivatives, and train two neural networks accordingly. In the exact setting, the learned critic converges to the viscosity solution (and its derivative), even for non-smooth values. Across diverse dynamical systems -- even including a hybrid system -- and multiple RL tasks, Deep QP Safety Filter substantially reduces pre-convergence failures while accelerating learning toward higher returns than strong baselines, offering a principled and practical route to safe, model-free control.

</details>


### [176] [HPTune: Hierarchical Proactive Tuning for Collision-Free Model Predictive Control](https://arxiv.org/abs/2601.21346)
*Wei Zuo,Chengyang Li,Yikun Wang,Bingyang Cheng,Zeyi Ren,Shuai Wang,Derrick Wing Kwan Ng,Yik-Chung Wu*

Main category: cs.RO

TL;DR: 提出了一种名为HPTune的分层主动参数调优框架，用于提升MPC运动规划器的适应性，实现更高效的安全避障。


<details>
  <summary>Details</summary>
Motivation: 传统MPC运动规划参数调优方法只评估已执行动作，未能充分利用稀疏的失败事件信息（如接近障碍物或碰撞），导致调优效率低。本文旨在克服信息利用率不足，提高参数调优效率。

Method: 提出HPTune框架，将参数调优分为快层与慢层：快层使用预测闭合速度与预测接近距离等风险指标进行调优，慢层基于扩展评估损失，通过闭环反向传播实现。HPTune还结合多普勒激光雷达，获取障碍物速度用于提升运动预测。

Result: 在高保真模拟环境中，HPTune能实现高效参数调优，在复杂环境下运动规划性能优于多种基线方法。

Conclusion: HPTune能够针对场景自主调整参数，制定安全、灵活的避障策略，显著提升MPC运动规划的适应性与效果。

Abstract: Parameter tuning is a powerful approach to enhance adaptability in model predictive control (MPC) motion planners. However, existing methods typically operate in a myopic fashion that only evaluates executed actions, leading to inefficient parameter updates due to the sparsity of failure events (e.g., obstacle nearness or collision). To cope with this issue, we propose to extend evaluation from executed to non-executed actions, yielding a hierarchical proactive tuning (HPTune) framework that combines both a fast-level tuning and a slow-level tuning. The fast one adopts risk indicators of predictive closing speed and predictive proximity distance, and the slow one leverages an extended evaluation loss for closed-loop backpropagation. Additionally, we integrate HPTune with the Doppler LiDAR that provides obstacle velocities apart from position-only measurements for enhanced motion predictions, thus facilitating the implementation of HPTune. Extensive experiments on high-fidelity simulator demonstrate that HPTune achieves efficient MPC tuning and outperforms various baseline schemes in complex environments. It is found that HPTune enables situation-tailored motion planning by formulating a safe, agile collision avoidance strategy.

</details>


### [177] [Towards Bridging the Gap between Large-Scale Pretraining and Efficient Finetuning for Humanoid Control](https://arxiv.org/abs/2601.21363)
*Weidong Huang,Zhehan Li,Hangxin Liu,Biao Hou,Yao Su,Jingwen Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种结合离线SAC预训练与模型基础微调的人形机器人控制方法，实现了零样本迁移到真实机器人，并通过安全高效的数据采集提升适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于策略的方法如PPO在大规模模拟中训练有效，但采样效率低，限制了其在新环境实时安全适应的能力。尽管离线和基于模型的方法提高了采样效率，但大规模预训练和高效微调之间仍有差距。

Method: 使用大批量、高UTD比的离线SAC进行人形机器人行走策略的大规模预训练，实现高效零样本部署。适应阶段，将基于SAC的策略微调，数据采集使用确定性策略，而随机探索限制在物理模型的仿真中，避免在实际机器人上随机探索的风险。

Result: 在模拟和真实机器人实验中，预训练后可以直接实现零样本部署。微调阶段在新环境和分布外任务上表现出显著的适应能力和样本效率。

Conclusion: 该方法将大规模并行仿真的训练效率与基于模型微调的样本效率结合，提升了机器人在实际环境中的适应性和安全高效迁移能力。

Abstract: Reinforcement learning (RL) is widely used for humanoid control, with on-policy methods such as Proximal Policy Optimization (PPO) enabling robust training via large-scale parallel simulation and, in some cases, zero-shot deployment to real robots. However, the low sample efficiency of on-policy algorithms limits safe adaptation to new environments. Although off-policy RL and model-based RL have shown improved sample efficiency, the gap between large-scale pretraining and efficient finetuning on humanoids still exists. In this paper, we find that off-policy Soft Actor-Critic (SAC), with large-batch update and a high Update-To-Data (UTD) ratio, reliably supports large-scale pretraining of humanoid locomotion policies, achieving zero-shot deployment on real robots. For adaptation, we demonstrate that these SAC-pretrained policies can be finetuned in new environments and out-of-distribution tasks using model-based methods. Data collection in the new environment executes a deterministic policy while stochastic exploration is instead confined to a physics-informed world model. This separation mitigates the risks of random exploration during adaptation while preserving exploratory coverage for improvement. Overall, the approach couples the wall-clock efficiency of large-scale simulation during pretraining with the sample efficiency of model-based learning during fine-tuning.

</details>


### [178] [Towards Space-Based Environmentally-Adaptive Grasping](https://arxiv.org/abs/2601.21394)
*Leonidas Askianakis,Aleksandr Artemov*

Main category: cs.RO

TL;DR: 本文研究了机器人在非结构化环境下操作的问题，提出在学习到的潜在空间中融合多模态信息，直接进行控制策略学习，并在空间抓取任务取得了优于现有视觉方法的效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 当前主流机器人操作系统在高维动作空间、稀疏奖励和场景泛化等方面存在局限。尤其是在空间环境下抓取任务难度极高，激励本文提出新方法以提高泛化能力和执行鲁棒性。

Method: 作者将多模态信息映射到一个结构化的潜在空间，并在该潜在空间中直接学习抓取策略。利用基于Soft Actor-Critic（SAC）的强化学习方法，并结合GPU加速物理仿真，实现了环境变化下的单步抓取任务学习。

Result: 在不到100万步的仿真中，提出方法对持续变化的抓取条件取得超过95%的任务成功率，相较于主流视觉基线收敛更快、样本效率更高。

Conclusion: 在潜在空间进行显式推理能提升学习效率和对新对象、夹持器几何、环境杂乱及传感器配置的鲁棒性。但仍有一些局限性，未来需进一步实现更适应和更泛化的空间抓取能力。

Abstract: Robotic manipulation in unstructured environments requires reliable execution under diverse conditions, yet many state-of-the-art systems still struggle with high-dimensional action spaces, sparse rewards, and slow generalization beyond carefully curated training scenarios. We study these limitations through the example of grasping in space environments. We learn control policies directly in a learned latent manifold that fuses (grammarizes) multiple modalities into a structured representation for policy decision-making. Building on GPU-accelerated physics simulation, we instantiate a set of single-shot manipulation tasks and achieve over 95% task success with Soft Actor-Critic (SAC)-based reinforcement learning in less than 1M environment steps, under continuously varying grasping conditions from step 1. This empirically shows faster convergence than representative state-of-the-art visual baselines under the same open-loop single-shot conditions. Our analysis indicates that explicitly reasoning in latent space yields more sample-efficient learning and improved robustness to novel object and gripper geometries, environmental clutter, and sensor configurations compared to standard baselines. We identify remaining limitations and outline directions toward fully adaptive and generalizable grasping in the extreme conditions of space.

</details>


### [179] [DSCD-Nav: Dual-Stance Cooperative Debate for Object Navigation](https://arxiv.org/abs/2601.21409)
*Weitao An,Qi Liu,Chenghao Xu,Jiayi Chai,Xu Yang,Kun Wei,Cheng Deng*

Main category: cs.RO

TL;DR: 该论文提出了DSCD-Nav，一种通过对决策过程中的候选行动进行立场协作辩论和证据仲裁的新机制，实现更可靠的自主导航。


<details>
  <summary>Details</summary>
Motivation: 现有室内导航系统在决策层面多采用单次打分策略，容易造成长程决策失误和过度探索，尤其在不熟悉的环境下，急需提升决策可靠性和效率。

Method: 引入了Dual-Stance Cooperative Debate Navigation（DSCD-Nav）机制，将决策过程分为两个互补立场：任务-场景理解（TSU），强调根据环境线索的目标推进；安全-信息平衡（SIB），注重风险评估与信息价值。两立场先独立评估，再互相辩论最优行动，由导航协商仲裁（NCA）代理融合证据，必要时触发快速探查验证推断结果。

Result: 在HM3Dv1、HM3Dv2和MP3D三大主流仿真环境中，DSCD-Nav在导航任务的成功率和路径效率方面均取得一致提升，并减少了无效探索。

Conclusion: DSCD-Nav通过引入立场协作与证据仲裁机制，有效提升了室内自主导航系统在复杂、未知环境下的决策可靠性与效率，对服务机器人实际部署具有现实意义。

Abstract: Adaptive navigation in unfamiliar indoor environments is crucial for household service robots. Despite advances in zero-shot perception and reasoning from vision-language models, existing navigation systems still rely on single-pass scoring at the decision layer, leading to overconfident long-horizon errors and redundant exploration. To tackle these problems, we propose Dual-Stance Cooperative Debate Navigation (DSCD-Nav), a decision mechanism that replaces one-shot scoring with stance-based cross-checking and evidence-aware arbitration to improve action reliability under partial observability. Specifically, given the same observation and candidate action set, we explicitly construct two stances by conditioning the evaluation on diverse and complementary objectives: a Task-Scene Understanding (TSU) stance that prioritizes goal progress from scene-layout cues, and a Safety-Information Balancing (SIB) stance that emphasizes risk and information value. The stances conduct a cooperative debate and make policy by cross-checking their top candidates with cue-grounded arguments. Then, a Navigation Consensus Arbitration (NCA) agent is employed to consolidate both sides' reasons and evidence, optionally triggering lightweight micro-probing to verify uncertain choices, preserving NCA's primary intent while disambiguating. Experiments on HM3Dv1, HM3Dv2, and MP3D demonstrate consistent improvements in success and path efficiency while reducing exploration redundancy.

</details>


### [180] [Singularity-Free Lie Group Integration and Geometrically Consistent Evaluation of Multibody System Models Described in Terms of Standard Absolute Coordinates](https://arxiv.org/abs/2601.21413)
*Andreas Mueller*

Main category: cs.RO

TL;DR: 本文提出了一种将Lie群积分方法与传统多体系统建模中的绝对坐标方法相结合的框架，实现了兼容现有模拟代码，同时利用Lie群几何优势进行无奇点时间积分。


<details>
  <summary>Details</summary>
Motivation: 绝对坐标法因奇点问题导致运动方程积分困难，虽然可用四元数规避，但仍存局限。Lie群积分法可自然描述空间运动几何，但与标准运动方程不兼容，难以直接应用于现有多体系统模拟软件。

Method: （1）提出了一个框架，将Lie群积分器与传统运动方程接口对接，使多体系统可用各种绝对坐标建模，并引入Lie群积分。（2）提出一种方法，在标准绝对坐标及向量空间积分法下，一致地引入刚体运动的几何结构。具体使用SO(3)xR3直积群和SE(3)半直积群表示刚体运动，核心为通过本地-全局转换（LGT）映射将Lie群上的局部坐标与绝对坐标关联。

Result: 该方法无需大幅修改现有模拟代码，即可实现无奇点的刚体运动积分和多体系统建模，提高了模拟的几何一致性和稳定性。

Conclusion: 提出的新框架与方法有效结合了Lie群积分的几何优势与传统工具的兼容性，为多体系统动力学分析提供了理论与实践上的改进。

Abstract: A classical approach to the multibody systems (MBS) modeling is to use absolute coordinates, i.e., a set of (possibly redundant) coordinates that describe the absolute position and orientation of the individual bodies with respect to an inertial frame (IFR). A well-known problem for the time integration of the equations of motion (EOM) is the lack of a singularity-free parameterization of spatial motions, which is usually tackled by using unit quaternions. Lie group integration methods were proposed as an alternative approach to the singularity-free time integration. At the same time, Lie group formulations of EOM naturally respect the geometry of spatial motions during integration. Lie group integration methods, operating directly on the configuration space Lie group, are incompatible with standard formulations of the EOM, and cannot be implemented in existing MBS simulation codes without a major restructuring. The contribution of this paper is twofold: (1) A framework for interfacing Lie group integrators to standard EOM formulations is presented. It allows describing MBS in terms of various absolute coordinates and at the same using Lie group integration schemes. (2) A method for consistently incorporating the geometry of rigid body motions into the evaluation of EOM in absolute coordinates integrated with standard vector space integration schemes. The direct product group and the semidirect product group SO(3)xR3 and the semidirect product group SE(3) are used for representing rigid body motions. The key element is the local-global transitions (LGT) transition map, which facilitates the update of (global) absolute coordinates in terms of the (local) coordinates on the Lie group. This LGT map is specific to the absolute coordinates, the local coordinates on the Lie group, and the Lie group used to represent rigid body configurations.

</details>


### [181] [Spotlighting Task-Relevant Features: Object-Centric Representations for Better Generalization in Robotic Manipulation](https://arxiv.org/abs/2601.21416)
*Alexandre Chapin,Bruno Machado,Emmanuel Dellandréa,Liming Chen*

Main category: cs.RO

TL;DR: 本文提出了一种基于slot的对象中心化表示（SBOCR）用于提升机器人操作策略的泛化能力，并在多种仿真与实际任务中验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 当前方法主要依赖全局特征或稠密特征，但这两种表示会混合任务相关和无关的信息，导致在环境变化（如光照、纹理、干扰物等）下泛化能力不足。作者希望找到一种能有效过滤噪声同时保留关键信息的视觉表征方式，提升机器人操作泛化表现。

Method: 引入Slot-Based Object-Centric Representations (SBOCR)，将稠密特征聚合为有限组“对象”，以结构化方式减少给策略输入的无关噪声。设计了多种视觉条件下（包括光照、纹理变化、干扰物出现）的仿真和实际操作任务，并将全局特征、稠密特征与SBOCR进行系统对比。

Result: 实验显示，基于SBOCR的策略在多种泛化测试中均取得了优于全局和稠密特征的表现，且无需针对具体任务的预训练。

Conclusion: SBOCR能在复杂且动态的现实机器人环境下增强视觉系统的泛化能力，是构建强泛化视觉系统的有前景方向。

Abstract: The generalization capabilities of robotic manipulation policies are heavily influenced by the choice of visual representations. Existing approaches typically rely on representations extracted from pre-trained encoders, using two dominant types of features: global features, which summarize an entire image via a single pooled vector, and dense features, which preserve a patch-wise embedding from the final encoder layer. While widely used, both feature types mix task-relevant and irrelevant information, leading to poor generalization under distribution shifts, such as changes in lighting, textures, or the presence of distractors. In this work, we explore an intermediate structured alternative: Slot-Based Object-Centric Representations (SBOCR), which group dense features into a finite set of object-like entities. This representation permits to naturally reduce the noise provided to the robotic manipulation policy while keeping enough information to efficiently perform the task. We benchmark a range of global and dense representations against intermediate slot-based representations, across a suite of simulated and real-world manipulation tasks ranging from simple to complex. We evaluate their generalization under diverse visual conditions, including changes in lighting, texture, and the presence of distractors. Our findings reveal that SBOCR-based policies outperform dense and global representation-based policies in generalization settings, even without task-specific pretraining. These insights suggest that SBOCR is a promising direction for designing visual systems that generalize effectively in dynamic, real-world robotic environments.

</details>


### [182] [Nimbus: A Unified Embodied Synthetic Data Generation Framework](https://arxiv.org/abs/2601.21449)
*Zeyu He,Yuchang Zhang,Yuanzhen Zhou,Miao Tao,Hengjie Li,Yang Tian,Jia Zeng,Tai Wang,Wenzhe Cai,Yilun Chen,Ning Gao,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 提出了Nimbus，这是一种统一的合成数据生成框架，用于支持大规模具身智能基础模型训练的数据生成，显著提升了效率和稳健性。


<details>
  <summary>Details</summary>
Motivation: 目前大规模具身智能模型需要大量多样的数据，现有的合成数据生成流程存在碎片化、任务专用，导致工程效率低下，难以持续支撑高通量数据需求，限制了模型的扩展和泛化能力。

Method: Nimbus设计了分层、模块化的架构，将轨迹规划、渲染和存储解耦为异步执行，并通过动态调度、全局负载均衡、分布式容错和后端渲染优化，提升了CPU、GPU和I/O资源的利用率。

Result: Nimbus在端到端数据生成吞吐方面优于未优化基线2至3倍，在大规模分布式环境中能长期、稳定高效运行。

Conclusion: Nimbus作为InternData的生产骨干，极大提升了跨任务、跨模态合成数据的生成效率，为具身智能基础模型训练提供了强有力的数据支持。

Abstract: Scaling data volume and diversity is critical for generalizing embodied intelligence. While synthetic data generation offers a scalable alternative to expensive physical data acquisition, existing pipelines remain fragmented and task-specific. This isolation leads to significant engineering inefficiency and system instability, failing to support the sustained, high-throughput data generation required for foundation model training. To address these challenges, we present Nimbus, a unified synthetic data generation framework designed to integrate heterogeneous navigation and manipulation pipelines. Nimbus introduces a modular four-layer architecture featuring a decoupled execution model that separates trajectory planning, rendering, and storage into asynchronous stages. By implementing dynamic pipeline scheduling, global load balancing, distributed fault tolerance, and backend-specific rendering optimizations, the system maximizes resource utilization across CPU, GPU, and I/O resources. Our evaluation demonstrates that Nimbus achieves a 2-3X improvement in end-to-end throughput compared to unoptimized baselines and ensuring robust, long-term operation in large-scale distributed environments. This framework serves as the production backbone for the InternData suite, enabling seamless cross-domain data synthesis.

</details>


### [183] [4D-CAAL: 4D Radar-Camera Calibration and Auto-Labeling for Autonomous Driving](https://arxiv.org/abs/2601.21454)
*Shanliang Yao,Zhuoxiao Li,Runwei Guan,Kebin Cao,Meng Xia,Fuping Hu,Sen Xu,Yong Yue,Xiaohui Zhu,Weiping Ding,Ryan Wen Liu*

Main category: cs.RO

TL;DR: 本文提出了4D-CAAL框架，实现4D雷达与摄像头的一体化外参标定及自动标注，通过创新标定靶设计和自动标签传播方法，大幅提升标定精度并减少人工标注工作。


<details>
  <summary>Details</summary>
Motivation: 当前4D雷达在自动驾驶感知中潜力巨大，但其与摄像头的融合依赖高精度外参标定与大规模标注数据。现有方法标定靶往往分为视觉或雷达专用，难以建立有效对应关系，同时雷达点云稀疏且人工标注成本高，导致感知算法开发受限。

Method: 设计了新型双用途标定靶，前表面含棋盘格方便摄像头识别，后中心带角反射器用于雷达检测。提出了棋盘中心与雷达最强反射点对齐的匹配算法，实现高精度外参标定。基于标定结果，利用几何映射和多特征优化设计了自动标签传播流程，把摄像头分割标签准确映射到雷达点云。

Result: 实验显示，所提方法能实现高精度标定，并显著降低雷达数据的人工标注工作量，加快多模态感知系统开发进度。

Conclusion: 4D-CAAL框架有效解决了雷达-相机外参标定和自动标注难题，对构建高效可靠的自动驾驶多模态感知体系具有重要推动作用。

Abstract: 4D radar has emerged as a critical sensor for autonomous driving, primarily due to its enhanced capabilities in elevation measurement and higher resolution compared to traditional 3D radar. Effective integration of 4D radar with cameras requires accurate extrinsic calibration, and the development of radar-based perception algorithms demands large-scale annotated datasets. However, existing calibration methods often employ separate targets optimized for either visual or radar modalities, complicating correspondence establishment. Furthermore, manually labeling sparse radar data is labor-intensive and unreliable. To address these challenges, we propose 4D-CAAL, a unified framework for 4D radar-camera calibration and auto-labeling. Our approach introduces a novel dual-purpose calibration target design, integrating a checkerboard pattern on the front surface for camera detection and a corner reflector at the center of the back surface for radar detection. We develop a robust correspondence matching algorithm that aligns the checkerboard center with the strongest radar reflection point, enabling accurate extrinsic calibration. Subsequently, we present an auto-labeling pipeline that leverages the calibrated sensor relationship to transfer annotations from camera-based segmentations to radar point clouds through geometric projection and multi-feature optimization. Extensive experiments demonstrate that our method achieves high calibration accuracy while significantly reducing manual annotation effort, thereby accelerating the development of robust multi-modal perception systems for autonomous driving.

</details>


### [184] [DexTac: Learning Contact-aware Visuotactile Policies via Hand-by-hand Teaching](https://arxiv.org/abs/2601.21474)
*Xingyu Zhang,Chaofan Zhang,Boyue Zhang,Zhinan Peng,Shaowei Cui,Shuo Wang*

Main category: cs.RO

TL;DR: 本文提出了一种名为DexTac的视觉-触觉操控学习框架，通过采集和利用多维触觉数据，实现了在复杂接触任务中的高精度灵巧操作。


<details>
  <summary>Details</summary>
Motivation: 传统灵巧操作系统在数据采集和技能学习中，触觉信息维度较低，限制了自主操控的表现，因此需要更全面的触觉感知和学习方法。

Method: DexTac框架基于动力学示教，从人类演示中直接采集包括接触力分布与空间接触区域在内的多维触觉数据，并将这些信息整合进策略网络中，实现自主选择和维持最优接触区域。

Result: 在单手注射等高难度任务中，DexTac达到91.67%的成功率。在高精度小型注射器场景中，较仅用力觉的基线提升31.67%。

Conclusion: 从人类演示中学习多维触觉先验对实现稳定且类似人类表现的灵巧接触操作至关重要。

Abstract: For contact-intensive tasks, the ability to generate policies that produce comprehensive tactile-aware motions is essential. However, existing data collection and skill learning systems for dexterous manipulation often suffer from low-dimensional tactile information. To address this limitation, we propose DexTac, a visuo-tactile manipulation learning framework based on kinesthetic teaching. DexTac captures multi-dimensional tactile data-including contact force distributions and spatial contact regions-directly from human demonstrations. By integrating these rich tactile modalities into a policy network, the resulting contact-aware agent enables a dexterous hand to autonomously select and maintain optimal contact regions during complex interactions. We evaluate our framework on a challenging unimanual injection task. Experimental results demonstrate that DexTac achieves a 91.67% success rate. Notably, in high-precision scenarios involving small-scale syringes, our approach outperforms force-only baselines by 31.67%. These results underscore that learning multi-dimensional tactile priors from human demonstrations is critical for achieving robust, human-like dexterous manipulation in contact-rich environments.

</details>


### [185] [Don't double it: Efficient Agent Prediction in Occlusions](https://arxiv.org/abs/2601.21504)
*Anna Rothenhäusler,Markus Mazzola,Andreas Look,Raghu Rajan,Joschka Bödecker*

Main category: cs.RO

TL;DR: 本文提出了一种新方法MatchInformer，用于提升自动驾驶中对被遮挡交通参与者的检测与路径预测精度。


<details>
  <summary>Details</summary>
Motivation: 遮挡的行人与车辆带来不可预测的风险，这是自动驾驶的重要挑战，但目前相关研究不多。现有的学习方法虽能推断隐藏目标，但常导致冗余预测，增加后续处理难度。

Method: 提出基于transformer的MatchInformer方法，在训练中引入匈牙利匹配算法，强制预测与真实目标一一对应，减少冗余。还将Agent朝向与运动解耦，提高路径预测精度和可解释性，并用MCC指标更好地评估稀疏或不平衡情况下的占据预测。

Result: 在Waymo Open Motion数据集上实验表明，该方法对被遮挡区域的推理能力提升，路径预测精度优于以往方法。

Conclusion: MatchInformer显著提升了自动驾驶系统在遇到遮挡目标时的感知与预测能力，为提升下游规划安全性和效率提供了实用工具。

Abstract: Occluded traffic agents pose a significant challenge for autonomous vehicles, as hidden pedestrians or vehicles can appear unexpectedly, yet this problem remains understudied. Existing learning-based methods, while capable of inferring the presence of hidden agents, often produce redundant occupancy predictions where a single agent is identified multiple times. This issue complicates downstream planning and increases computational load. To address this, we introduce MatchInformer, a novel transformer-based approach that builds on the state-of-the-art SceneInformer architecture. Our method improves upon prior work by integrating Hungarian Matching, a state-of-the-art object matching algorithm from object detection, into the training process to enforce a one-to-one correspondence between predictions and ground truth, thereby reducing redundancy. We further refine trajectory forecasts by decoupling an agent's heading from its motion, a strategy that improves the accuracy and interpretability of predicted paths. To better handle class imbalances, we propose using the Matthews Correlation Coefficient (MCC) to evaluate occupancy predictions. By considering all entries in the confusion matrix, MCC provides a robust measure even in sparse or imbalanced scenarios. Experiments on the Waymo Open Motion Dataset demonstrate that our approach improves reasoning about occluded regions and produces more accurate trajectory forecasts than prior methods.

</details>


### [186] [IROS: A Dual-Process Architecture for Real-Time VLM-Based Indoor Navigation](https://arxiv.org/abs/2601.21506)
*Joonhee Lee,Hyunseung Shin,Jeonggil Ko*

Main category: cs.RO

TL;DR: IROS是一种适用于低成本硬件、具备高响应性和强语义理解能力的室内移动机器人导航框架，结合了轻量级感知模块和高阶语境推理，大幅提升了导航准确性并降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 当前的室内机器人导航方法难以兼顾实时性和语义理解能力。传统SLAM方法依赖于精细地图，无法解释如标识、房间号等人类关键信息；VLA方法虽有语义基础但仅能做即时反应，无法预判和远距离理解文本信息；而VLM推理虽强但计算延迟过高，难以嵌入低成本硬件。

Method: IROS系统借鉴双系统理论，将快速反射决策（System One）与深度推理（System Two）分离，仅在必要时激活VLM，实现高效智能导航。系统通过融合空间及文本线索增强紧凑型VLM，提升语境理解和导航的智能性。

Result: IROS在五栋真实建筑中测试，较持续调用VLM的方案，决策准确性更高，平均决策延迟降低66%。

Conclusion: IROS证明了将高阶语境推理与轻量级感知结合，可在低成本硬件上实现高效、类人导航，为实际室内导航系统提供有价值的设计参考。

Abstract: Indoor mobile robot navigation requires fast responsiveness and robust semantic understanding, yet existing methods struggle to provide both. Classical geometric approaches such as SLAM offer reliable localization but depend on detailed maps and cannot interpret human-targeted cues (e.g., signs, room numbers) essential for indoor reasoning. Vision-Language-Action (VLA) models introduce semantic grounding but remain strictly reactive, basing decisions only on visible frames and failing to anticipate unseen intersections or reason about distant textual cues. Vision-Language Models (VLMs) provide richer contextual inference but suffer from high computational latency, making them unsuitable for real-time operation on embedded platforms. In this work, we present IROS, a real-time navigation framework that combines VLM-level contextual reasoning with the efficiency of lightweight perceptual modules on low-cost, on-device hardware. Inspired by Dual Process Theory, IROS separates fast reflexive decisions (System One) from slow deliberative reasoning (System Two), invoking the VLM only when necessary. Furthermore, by augmenting compact VLMs with spatial and textual cues, IROS delivers robust, human-like navigation with minimal latency. Across five real-world buildings, IROS improves decision accuracy and reduces latency by 66% compared to continuous VLM-based navigation.

</details>


### [187] [Training slow silicon neurons to control extremely fast robots with spiking reinforcement learning](https://arxiv.org/abs/2601.21548)
*Irene Ambrosini,Ingo Blakowski,Dmitrii Zendrikov,Cristiano Capone,Luna Gava,Giacomo Indiveri,Chiara De Luca,Chiara Bartolozzi*

Main category: cs.RO

TL;DR: 本文提出利用混合信号类脑神经形态芯片与尖峰神经网络，实现了机器人气悬球台任务中的高效实时学习与控制。通过软硬件协同设计和强化学习，显著减少了训练样本数，在类似真实场景下实现了自主系统的持续高效学习。


<details>
  <summary>Details</summary>
Motivation: 气悬球台任务需要处理极高速度下的快速、精准决策，对传统人工智能和控制方法提出挑战。现有人工神经网络的高计算资源和能耗，难以应用于高实时性、低功耗的实际机器人系统。受神经科学启发，作者希望探索如何将类脑硬件和算法结合，满足实际自主机器人中对于快速和持续学习的需求。

Method: 设计了一种混合信号（模拟/数字）神经形态处理器，搭建了精简的尖峰神经网络。网络采用固定随机连接结构，把任务的时间特性映射进神经网络。训练上，输出层使用本地e-prop学习规则，通过事件驱动实现高效的强化学习。整个系统集成传统计算机与类脑芯片，构成“内环”实验配置。

Result: 该系统在气悬球台任务中表现出色，只需极少量训练即可实现成功的击球和实时学习控制，验证了硬件实现的尖峰神经网络在实际任务中的高效性和可靠性。

Conclusion: 本研究证明，结合神经科学启发的硬件和本地在线学习算法，能够有效应对需要快速、持续决策的机器人任务。类脑神经形态处理架构为智能自主系统提供了低功耗、高实时性的解决方案，推动了机器人领域中“永远在线学习”技术的进步。

Abstract: Air hockey demands split-second decisions at high puck velocities, a challenge we address with a compact network of spiking neurons running on a mixed-signal analog/digital neuromorphic processor. By co-designing hardware and learning algorithms, we train the system to achieve successful puck interactions through reinforcement learning in a remarkably small number of trials. The network leverages fixed random connectivity to capture the task's temporal structure and adopts a local e-prop learning rule in the readout layer to exploit event-driven activity for fast and efficient learning. The result is real-time learning with a setup comprising a computer and the neuromorphic chip in-the-loop, enabling practical training of spiking neural networks for robotic autonomous systems. This work bridges neuroscience-inspired hardware with real-world robotic control, showing that brain-inspired approaches can tackle fast-paced interaction tasks while supporting always-on learning in intelligent machines.

</details>


### [188] [AIR-VLA: Vision-Language-Action Systems for Aerial Manipulation](https://arxiv.org/abs/2601.21602)
*Jianli Sun,Bin Tian,Qiyao Zhang,Chengxiang Li,Zihan Song,Zhiyong Cui,Yisheng Lv,Yonglin Tian*

Main category: cs.RO

TL;DR: 提出了AIR-VLA，这是首个针对空中操作系统（AMS）的视觉-语言-行动（VLA）基准和多模态数据集，以推进AMS在复杂任务中的智能化发展。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型主要面向地面机器人，难以应对AMS固有的浮动基底动力学、无人机与机械臂强耦合以及任务的长时、多步特点。因此，缺乏适用于AMS的评价标准和数据集，限制了该领域的发展。

Method: 构建了AIR-VLA，包括一个基于物理仿真的环境和一个高质量的多模态数据集（含3000条人工遥操作演示），任务涵盖了基础操作、目标与空间理解、语义推理及长远规划。利用该平台系统性地评估了主流VLA和最新视觉-语言模型。

Result: 试验显示VLA范式可以推广到空中系统，并通过AMS任务专属多维度指标，揭示了当前模型在无人机运动、机械臂控制和高层规划方面的优势与局限。

Conclusion: AIR-VLA为通用型空中机器人智能研究提供了标准化测试环境和数据基础，有望推动该领域研究的标准化和突破性进展。

Abstract: While Vision-Language-Action (VLA) models have achieved remarkable success in ground-based embodied intelligence, their application to Aerial Manipulation Systems (AMS) remains a largely unexplored frontier. The inherent characteristics of AMS, including floating-base dynamics, strong coupling between the UAV and the manipulator, and the multi-step, long-horizon nature of operational tasks, pose severe challenges to existing VLA paradigms designed for static or 2D mobile bases. To bridge this gap, we propose AIR-VLA, the first VLA benchmark specifically tailored for aerial manipulation. We construct a physics-based simulation environment and release a high-quality multimodal dataset comprising 3000 manually teleoperated demonstrations, covering base manipulation, object & spatial understanding, semantic reasoning, and long-horizon planning. Leveraging this platform, we systematically evaluate mainstream VLA models and state-of-the-art VLM models. Our experiments not only validate the feasibility of transferring VLA paradigms to aerial systems but also, through multi-dimensional metrics tailored to aerial tasks, reveal the capabilities and boundaries of current models regarding UAV mobility, manipulator control, and high-level planning. AIR-VLA establishes a standardized testbed and data foundation for future research in general-purpose aerial robotics. The resource of AIR-VLA will be available at https://anonymous.4open.science/r/AIR-VLA-dataset-B5CC/.

</details>


### [189] [From Instruction to Event: Sound-Triggered Mobile Manipulation](https://arxiv.org/abs/2601.21667)
*Hao Ju,Shaofei Huang,Hongyu Li,Zihan Ding,Si Liu,Meng Wang,Zhedong Zheng*

Main category: cs.RO

TL;DR: 该论文提出了声音触发的移动操作新范式，并开发了Habitat-Echo数据平台提升机器人在无明确指令下基于声音自主感知与交互能力。


<details>
  <summary>Details</summary>
Motivation: 现有移动操作主要依赖指令驱动，导致代理仅能被动执行任务，缺乏对动态环境事件的自主反应能力。为提升代理的自主性与环境适应力，作者提出声音触发的移动操作场景。

Method: 1. 提出声音触发移动操作任务，即代理需主动感知与交互发声物体，无需明确任务指令。2. 开发Habitat-Echo数据平台，将声学渲染与物理交互结合，支持相关任务。3. 提出由高层任务规划器与低层策略模型组成的基线方法，作为任务参考实现。

Result: 实验表明，基线模型能让代理主动检测并响应声音事件，无需一对一任务指令，且在双声源实验中可区分并优先处理主要声源，再操作次要目标，展现模型鲁棒性。

Conclusion: 声音触发的移动操作为提升机器人自主感知与交互能力提供了新范式，所提出的方法和平台为后续研究提供了可行基线与数据基础。

Abstract: Current mobile manipulation research predominantly follows an instruction-driven paradigm, where agents rely on predefined textual commands to execute tasks. However, this setting confines agents to a passive role, limiting their autonomy and ability to react to dynamic environmental events. To address these limitations, we introduce sound-triggered mobile manipulation, where agents must actively perceive and interact with sound-emitting objects without explicit action instructions. To support these tasks, we develop Habitat-Echo, a data platform that integrates acoustic rendering with physical interaction. We further propose a baseline comprising a high-level task planner and low-level policy models to complete these tasks. Extensive experiments show that the proposed baseline empowers agents to actively detect and respond to auditory events, eliminating the need for case-by-case instructions. Notably, in the challenging dual-source scenario, the agent successfully isolates the primary source from overlapping acoustic interference to execute the first interaction, and subsequently proceeds to manipulate the secondary object, verifying the robustness of the baseline.

</details>


### [190] [CoFreeVLA: Collision-Free Dual-Arm Manipulation via Vision-Language-Action Model and Risk Estimation](https://arxiv.org/abs/2601.21712)
*Xuanran Zhai,Binkai Ou,Yemin Wang,Hui Yi Leong,Qiaojun Yu,Ce Hao,Yaohua Liu*

Main category: cs.RO

TL;DR: 本文提出CoFreeVLA，将自碰撞风险评估集成到视觉-语言-动作（VLA）模型中，大幅提升了双臂机器人操作的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在双臂操作中容易因自碰撞风险被低估，造成部署不安全，尤其在人工智能控制机器人处理复杂任务时尤为突出。解决自碰撞问题对实际机器人部署至关重要。

Method: 论文提出CoFreeVLA方法，将短时预测自碰撞风险的估计器融入VLA模型，利用机器人自身运动信息、视觉特征和规划动作对潜在自碰撞概率进行预测。该估计器对高风险指令进行过滤、引导策略回退至安全状态，并在策略优化时引入安全约束。估计器先通过模型数据预训练，再用真实机器人数据后训练校准。

Result: 在PiPER机器人臂上的五种双臂任务实验中，CoFreeVLA相比RDT与APEX方法，显著降低了自碰撞事件发生率，提高了任务完成成功率。

Conclusion: CoFreeVLA有效提升了基于VLA的双臂机器人在复杂任务中的安全性和成功率，为安全部署多臂机器人提供了一种实用方案。

Abstract: Vision Language Action (VLA) models enable instruction following manipulation, yet dualarm deployment remains unsafe due to under modeled selfcollisions between arms and grasped objects. We introduce CoFreeVLA, which augments an endtoend VLA with a short horizon selfcollision risk estimator that predicts collision likelihood from proprioception, visual embeddings, and planned actions. The estimator gates risky commands, recovers to safe states via risk-guided adjustments, and shapes policy refinement for safer rollouts. It is pre-trained with model-based collision labels and posttrained on real robot rollouts for calibration. On five bimanual tasks with the PiPER robot arm, CoFreeVLA reduces selfcollisions and improves success rates versus RDT and APEX.

</details>


### [191] [Disentangling perception and reasoning for improving data efficiency in learning cloth manipulation without demonstrations](https://arxiv.org/abs/2601.21713)
*Donatien Delehelle,Fei Chen,Darwin Caldwell*

Main category: cs.RO

TL;DR: 该论文提出了一种高效且模块化的强化学习方法用于布料操控，显著降低了模型大小和训练时间，并在SoftGym基准测试上超过了现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 布料操作由于高维状态空间、复杂动力学和自遮挡等问题，对于机器人来说极具挑战。现有强化学习方法依赖大模型和长训练时间，计算成本高，限制了其应用。因此，作者希望开发更高效、模块化的RL方法，减少模型体积和训练开销。

Method: 论文设计了一套高效的强化学习方法，通过精细的模块化设计，优化了训练流程以减少在仿真中的模型大小与训练时间，并在输入和模型架构上进行了创新，而不完全依赖端到端图像输入。

Result: 在SoftGym基准测试中，该方法所训练的模型在性能上显著优于现有基线，并且模型规模更小，训练时间也更短。实验还展示了从仿真到真实环境的有效迁移能力。

Conclusion: 论文证明了通过合理方法设计，可以在不牺牲性能的前提下显著降低布料操作任务中的计算成本，这为实际机器人布料操作系统落地带来了积极推动作用。

Abstract: Cloth manipulation is a ubiquitous task in everyday life, but it remains an open challenge for robotics. The difficulties in developing cloth manipulation policies are attributed to the high-dimensional state space, complex dynamics, and high propensity to self-occlusion exhibited by fabrics. As analytical methods have not been able to provide robust and general manipulation policies, reinforcement learning (RL) is considered a promising approach to these problems. However, to address the large state space and complex dynamics, data-based methods usually rely on large models and long training times. The resulting computational cost significantly hampers the development and adoption of these methods. Additionally, due to the challenge of robust state estimation, garment manipulation policies often adopt an end-to-end learning approach with workspace images as input. While this approach enables a conceptually straightforward sim-to-real transfer via real-world fine-tuning, it also incurs a significant computational cost by training agents on a highly lossy representation of the environment state. This paper questions this common design choice by exploring an efficient and modular approach to RL for cloth manipulation. We show that, through careful design choices, model size and training time can be significantly reduced when learning in simulation. Furthermore, we demonstrate how the resulting simulation-trained model can be transferred to the real world. We evaluate our approach on the SoftGym benchmark and achieve significant performance improvements over available baselines on our task, while using a substantially smaller model.

</details>


### [192] [Flocking behavior for dynamic and complex swarm structures](https://arxiv.org/abs/2601.21772)
*Carmen D. R. Pita-Romero,Pedro Arias-Perez,Miguel Fernandez-Cortizas,Rafael Perez-Segui,Pascual Campoy*

Main category: cs.RO

TL;DR: 本文提出了一种基于虚拟质心的无人机集群（UAV）编队算法，有效简化了多无人机复杂结构队形和轨迹控制。


<details>
  <summary>Details</summary>
Motivation: 多无人机执行复杂编队结构和复杂轨迹时存在实现难度，亟需设计出更简单且易扩展的控制方法。

Method: 采用虚拟质心概念构建编队算法，在传统虚拟点行为基础上提出理论框架，可灵活动态地控制无人机数量及结构队形，方法既适用于仿真也适用于实际应用。

Result: 通过仿真和真实实验，验证了算法在多种复杂编队结构以及复杂轨迹下的有效性与简便性。

Conclusion: 该方法为多无人机编队控制问题提供了简单实用的新思路，有利于复杂结构及轨迹的灵活实现。

Abstract: Maintaining the formation of complex structures with multiple UAVs and achieving complex trajectories remains a major challenge. This work presents an algorithm for implementing the flocking behavior of UAVs based on the concept of Virtual Centroid to easily develop a structure for the flock. The approach builds on the classical virtual-based behavior, providing a theoretical framework for incorporating enhancements to dynamically control both the number of agents and the formation of the structure. Simulation tests and real-world experiments were conducted, demonstrating its simplicity even with complex formations and complex trajectories.

</details>


### [193] [GAZELOAD A Multimodal Eye-Tracking Dataset for Mental Workload in Industrial Human-Robot Collaboration](https://arxiv.org/abs/2601.21829)
*Bsher Karbouj,Baha Eddin Gaaloul,Jorg Kruger*

Main category: cs.RO

TL;DR: 本文提出了GAZELOAD多模态数据集，用于工业人机协作中心理负荷估计，涵盖眼动追踪与环境信息，可用于算法开发和工作负荷建模。


<details>
  <summary>Details</summary>
Motivation: 目前工业环境下人机协作需要有效评估工人的心理负荷，但缺乏高质量、多模态的数据集，尤其是结合眼动与环境信息，阻碍了算法发展和真实场景下的分析。

Method: 在实验室组装平台中，26名参与者与协作机器人（UR5和Franka Emika Panda）配合，并佩戴Meta ARIA智能眼镜。实验通过设定任务难度和环境条件，收集不同心理负荷下的眼动数据（如瞳孔直径、注视、扫视、凝视熵等）、环境光照、任务和机器人状态，并同步整理成分窗口数据和自评问卷。

Result: 形成了包含26名受试者、多个任务难度与环境变量组合下的眼动和环境数据，每个数据单元有详细的汇总文件和注释，可直接用于心理负荷算法的训练与验证。

Conclusion: GAZELOAD数据集为现实工业HRC场景下心理负荷的估计方法开发、特征提取、时序建模以及环境影响因素分析，提供了丰富标准的数据基础，对相关研究和应用具有重要推动作用。

Abstract: This article describes GAZELOAD, a multimodal dataset for mental workload estimation in industrial human-robot collaboration. The data were collected in a laboratory assembly testbed where 26 participants interacted with two collaborative robots (UR5 and Franka Emika Panda) while wearing Meta ARIA smart glasses. The dataset time-synchronizes eye-tracking signals (pupil diameter, fixations, saccades, eye gaze, gaze transition entropy, fixation dispersion index) with environmental real-time and continuous measurements (illuminance) and task and robot context (bench, task block, induced faults), under controlled manipulations of task difficulty and ambient conditions. For each participant and workload-graded task block, we provide CSV files with ocular metrics aggregated into 250 ms windows, environmental logs, and self-reported mental workload ratings on a 1-10 Likert scale, organized in participant-specific folders alongside documentation. These data can be used to develop and benchmark algorithms for mental workload estimation, feature extraction, and temporal modeling in realistic industrial HRC scenarios, and to investigate the influence of environmental factors such as lighting on eye-based workload markers.

</details>


### [194] [LLM-Driven Scenario-Aware Planning for Autonomous Driving](https://arxiv.org/abs/2601.21876)
*He Li,Zhaowei Chen,Rui Gao,Guoliang Li,Qi Hao,Shuai Wang,Chengzhong Xu*

Main category: cs.RO

TL;DR: 本文提出了一种由大语言模型（LLM）驱动的自适应混合规划切换框架（LAP），提升了自动驾驶在不同行驶场景下的决策效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的混合规划切换框架在复杂拥堵场景下，因场景识别依赖启发式方法且控制更新频率低，导致模式切换不可靠和驾驶效率低。需要一种更智能、高效的场景识别与决策机制。

Method: 提出了基于大语言模型（LLM）的自适应规划方法LAP。通过LLM对驾驶场景进行理解，并将其推理结果融入到模式配置与运动规划的联合优化中。方法采用树搜索的模型预测控制及交替最小化进行优化，在ROS系统上用Python实现。

Result: 高保真仿真结果表明，LAP在驾驶时间和成功率方面显著优于其他基线方法。

Conclusion: 利用LLM提升了场景理解能力与决策协同，使得自动驾驶在复杂与简单场景间实现高效、安全的模式切换，对提升智能驾驶系统性能具有重要意义。

Abstract: Hybrid planner switching framework (HPSF) for autonomous driving needs to reconcile high-speed driving efficiency with safe maneuvering in dense traffic. Existing HPSF methods often fail to make reliable mode transitions or sustain efficient driving in congested environments, owing to heuristic scene recognition and low-frequency control updates. To address the limitation, this paper proposes LAP, a large language model (LLM) driven, adaptive planning method, which switches between high-speed driving in low-complexity scenes and precise driving in high-complexity scenes, enabling high qualities of trajectory generation through confined gaps. This is achieved by leveraging LLM for scene understanding and integrating its inference into the joint optimization of mode configuration and motion planning. The joint optimization is solved using tree-search model predictive control and alternating minimization. We implement LAP by Python in Robot Operating System (ROS). High-fidelity simulation results show that the proposed LAP outperforms other benchmarks in terms of both driving time and success rate.

</details>


### [195] [Multi-Modular MANTA-RAY: A Modular Soft Surface Platform for Distributed Multi-Object Manipulation](https://arxiv.org/abs/2601.21884)
*Pratik Ingle,Jørn Lambertsen,Kasper Støy,Andres Faina*

Main category: cs.RO

TL;DR: 本文介绍了一种基于柔性织物的可扩展操控平台MANTA-RAY，其特点是在低执行器密度下实现复杂物体表面操控，能够灵巧地处理脆弱和异质物品。通过多模块设计和几何变换驱动的PID控制，该系统不需要大量数据驱动训练，实验和仿真验证了其可扩展性和高效性。


<details>
  <summary>Details</summary>
Motivation: 传统密集执行器阵列可实现复杂表面变形，但高度自由度导致系统复杂且难以扩展，现有研究多集中于单模块，这限制了实际应用。亟需一种在降低执行器数量的情况下，仍能维持高水平物体操控性能、适用于脆弱和多样物品并支持大范围应用的方案。

Method: 提出了一种分布式、模块化且可扩展的MANTA-RAY平台，通过多个柔性织物模块协作，每模块执行器数量大幅减少。控制策略基于几何变换驱动的PID控制器，实现模块间物体传递和精确表面操控，无需大量数据或黑盒模型。系统在仿真中测试了3x3和4x4模块布局，并通过2x2实体原型做实验验证。

Result: 仿真及实物实验表明，该多模块平台在大幅减少执行器数量情况下，仍能有效操控不同几何形状、质量、质地的物体，包括易碎物品如鸡蛋和苹果，并实现了多物体并行操控。平台展现出良好的可扩展性和实用性。

Conclusion: 本研究提出的多模块织物操控平台，在简化硬件复杂度和提升可扩展性的同时，保持了高操控灵活性和精度，尤其适用于实际环境中处理多样和脆弱物体，具有广阔的现实应用前景。

Abstract: Manipulation surfaces control objects by actively deforming their shape rather than directly grasping them. While dense actuator arrays can generate complex deformations, they also introduce high degrees of freedom (DOF), increasing system complexity and limiting scalability. The MANTA-RAY (Manipulation with Adaptive Non-rigid Textile Actuation with Reduced Actuation densitY) platform addresses these challenges by leveraging a soft, fabric-based surface with reduced actuator density to manipulate fragile and heterogeneous objects. Previous studies focused on single-module implementations supported by four actuators, whereas the feasibility and benefits of a scalable, multi-module configuration remain unexplored. In this work, we present a distributed, modular, and scalable variant of the MANTA-RAY platform that maintains manipulation performance with a reduced actuator density. The proposed multi-module MANTA-RAY platform and control strategy employs object passing between modules and a geometric transformation driven PID controller that directly maps tilt-angle control outputs to actuator commands, eliminating the need for extensive data-driven or black-box training. We evaluate system performance in simulation across surface configurations of varying modules (3x3 and 4x4) and validate its feasibility through experiments on a physical 2x2 hardware prototype. The system successfully manipulates objects with diverse geometries, masses, and textures including fragile items such as eggs and apples as well as enabling parallel manipulation. The results demonstrate that the multi-module MANTA-RAY improves scalability and enables coordinated manipulation of multiple objects across larger areas, highlighting its potential for practical, real-world applications.

</details>


### [196] [Information Filtering via Variational Regularization for Robot Manipulation](https://arxiv.org/abs/2601.21926)
*Jinhao Zhang,Wenlong Xia,Yaojia Wang,Zhexuan Zhou,Huizhe Li,Yichen Lai,Haoming Song,Youmin Gong,Jie Me*

Main category: cs.RO

TL;DR: 本文提出了一种高效的变分正则化方法，用于提升基于扩散模型的视觉运动控制策略的表现，通过在主干特征层施加高斯变分瓶颈，过滤无关噪声，实验证明方法在多个仿真和真实机器人平台上超越主流基线，达到了新SOTA表现。


<details>
  <summary>Details</summary>
Motivation: 现有扩散视觉运动策略多采用参数过大的去噪解码器，尽管增大模型容量可提升去噪能力，但也引入了中间特征的冗余与噪声，从而影响策略性能。为此需要设计更优的特征约束机制，消除无关噪声，提升模型泛化与执行力。

Method: 作者发现仅在推理阶段对主干特征进行随机掩蔽就可提升性能，证明中间特征含有任务无关噪声。据此，提出了‘变分正则化’（VR）模块：对主干特征引入与时间步相关的高斯分布，并施加KL散度正则项，形成功能自适应的信息瓶颈，有效过滤噪声。整个方法轻量、高效，无需修改原训练过程。

Result: 在RoboTwin2.0、Adroit和MetaWorld三个主流机器人仿真基准上，对比主流基线DP3，VR分别提升成功率6.1%、4.1%，表现优于当今SOTA。在真实机器人实测中也确认了本方法的有效性和泛化能力。

Conclusion: 通过在扩散模型特征层引入轻量变分正则器，可显著提升视觉运动策略的泛化与准确性，方法高效、易用，适用于复杂机器人任务，具有现实部署价值，推动了该领域SOTA。

Abstract: Diffusion-based visuomotor policies built on 3D visual representations have achieved strong performance in learning complex robotic skills. However, most existing methods employ an oversized denoising decoder. While increasing model capacity can improve denoising, empirical evidence suggests that it also introduces redundancy and noise in intermediate feature blocks. Crucially, we find that randomly masking backbone features at inference time (without changing training) can improve performance, confirming the presence of task-irrelevant noise in intermediate features. To this end, we propose Variational Regularization (VR), a lightweight module that imposes a timestep-conditioned Gaussian over backbone features and applies a KL-divergence regularizer, forming an adaptive information bottleneck. Extensive experiments on three simulation benchmarks (RoboTwin2.0, Adroit, and MetaWorld) show that, compared to the baseline DP3, our approach improves the success rate by 6.1% on RoboTwin2.0 and by 4.1% on Adroit and MetaWorld, achieving new state-of-the-art results. Real-world experiments further demonstrate that our method performs well in practical deployments. Code will released.

</details>


### [197] [MoE-ACT: Improving Surgical Imitation Learning Policies through Supervised Mixture-of-Experts](https://arxiv.org/abs/2601.21971)
*Lorenzo Mazza,Ariel Rodriguez,Rayan Younis,Martin Lelis,Ortrun Hellig,Chenpan Li,Sebastian Bodenstedt,Martin Wagner,Stefanie Speidel*

Main category: cs.RO

TL;DR: 本文提出了一种监督式专家混合（MoE）架构，结合Action Chunking Transformer（ACT），用于提升外科手术机器人模仿学习的效果，尤其在演示数据稀缺且条件复杂的场景下。


<details>
  <summary>Details</summary>
Motivation: 针对外科机器人模仿学习面临的数据稀缺、工作空间受限以及对安全性和可预测性要求极高的问题，现有方法往往需要大量演示或多摄像头系统，难以落地临床实际场景。

Method: 提出了一种能够与任何自主策略结合的监督式MoE架构，在外科手术分阶段操作任务中，通过融合ACT策略，只需不到150组演示、单一立体内窥镜图像输入，就能高效学习复杂的长时序操作。

Result: 在肠道抓取与牵引任务上，与当前SOTA视觉-语言-动作模型（VLA）及传统ACT方法对比，MoE架构显著提升了成功率和分布外鲁棒性，比如在新抓取位置、照明变化、部分遮挡等情况下表现优异，并能直接零样本迁移到猪体外组织上。

Conclusion: 监督式MoE与ACT结合不但在少量演示下提升了复杂手术操作的泛化性和安全性，还表现出优良的分布外与视角迁移能力，对未来实际（体内）外科机器人应用具有重要推动作用。

Abstract: Imitation learning has achieved remarkable success in robotic manipulation, yet its application to surgical robotics remains challenging due to data scarcity, constrained workspaces, and the need for an exceptional level of safety and predictability. We present a supervised Mixture-of-Experts (MoE) architecture designed for phase-structured surgical manipulation tasks, which can be added on top of any autonomous policy. Unlike prior surgical robot learning approaches that rely on multi-camera setups or thousands of demonstrations, we show that a lightweight action decoder policy like Action Chunking Transformer (ACT) can learn complex, long-horizon manipulation from less than 150 demonstrations using solely stereo endoscopic images, when equipped with our architecture. We evaluate our approach on the collaborative surgical task of bowel grasping and retraction, where a robot assistant interprets visual cues from a human surgeon, executes targeted grasping on deformable tissue, and performs sustained retraction. We benchmark our method against state-of-the-art Vision-Language-Action (VLA) models and the standard ACT baseline. Our results show that generalist VLAs fail to acquire the task entirely, even under standard in-distribution conditions. Furthermore, while standard ACT achieves moderate success in-distribution, adopting a supervised MoE architecture significantly boosts its performance, yielding higher success rates in-distribution and demonstrating superior robustness in out-of-distribution scenarios, including novel grasp locations, reduced illumination, and partial occlusions. Notably, it generalizes to unseen testing viewpoints and also transfers zero-shot to ex vivo porcine tissue without additional training, offering a promising pathway toward in vivo deployment. To support this, we present qualitative preliminary results of policy roll-outs during in vivo porcine surgery.

</details>


### [198] [Macro-Scale Electrostatic Origami Motor](https://arxiv.org/abs/2601.21976)
*Alex S. Miller,Leo McElroy,Jeffrey H. Lang*

Main category: cs.RO

TL;DR: 该论文提出并测试了一种可折叠的宏观级折纸旋转电机，能实现从扁平状态展开后连续旋转。


<details>
  <summary>Details</summary>
Motivation: 现有可折叠机器人通常依靠线性驱动器或非折叠旋转马达，不具备连续旋转的折叠驱动组件，特别是在宏观尺度下缺乏相关研究。设计一种可折叠且能提供连续旋转的执行器有助于提升可折叠机器人能力。

Method: 设计并制造了首个宏观级可折叠折纸旋转电机，运用电晕放电产生力矩，电机可折叠展开。对其展开比、转速、输出力矩等性能进行了实验测试。

Result: 原型电机实现了2.5:1的展开比，在-29kV驱动下达到了最高1440rpm转速，最大输出力矩超过0.15mN·m，主动部件扭矩密度为0.04Nm/kg。

Conclusion: 这是首个可折叠宏观级折纸连续旋转电机，证明了该类结构在实现高可包性和空间利用同时，依然具备实用的旋转驱动能力，对可折叠机器人技术具有重要意义。

Abstract: Foldable robots have been an active area of robotics research due to their high volume-to-mass ratio, easy packability, and shape adaptability. For locomotion, previously developed foldable robots have either embedded linear actuators in, or attached non-folding rotary motors to, their structure. Further, those actuators directly embedded in the structure of the folding medium all contributed to linear or folding motion, not to continuous rotary motion. On the macro-scale there has not yet been a folding continuous rotary actuator. This paper details the development and testing of the first macro-scale origami rotary motor that can be folded flat, and then unfurled to operate. Using corona discharge for torque production, the prototype motor achieved an expansion ratio of 2.5:1, reached a top speed of 1440 rpm when driven at -29 kV, and exhibited a maximum output torque over 0.15 mN m with an active component torque density of 0.04 Nm/kg.

</details>


### [199] [PocketDP3: Efficient Pocket-Scale 3D Visuomotor Policy](https://arxiv.org/abs/2601.22018)
*Jinhao Zhang,Zhexuan Zhou,Huizhe Li,Yichen Lai,Wenlong Xia,Haoming Song,Youmin Gong,Jie Me*

Main category: cs.RO

TL;DR: 该论文提出了PocketDP3，一种小巧高效的3D扩散策略模型，用于机器人操作任务，在仅用极少模型参数的情况下取得了业界最优表现。


<details>
  <summary>Details</summary>
Motivation: 现有3D视觉扩散策略通常使用高效的小型点云编码器搭配庞大的解码器，这种设计容易导致解码器参数浪费。作者认为，通过优化结构，可以使模型更高效、更易于实际部署。

Method: 作者用基于MLP-Mixer模块的轻量级Diffusion Mixer（DiM）替换了传统的U-Net解码器。该结构能够有效融合时序和通道维度信息，极大减少模型规模，并且无需额外蒸馏技术就能支持两步推理过程。

Result: 在RoboTwin2.0、Adroit和MetaWorld三大仿真基准测试中，PocketDP3用少于1%的参数，达到了业界最优性能，并显著加快了推理速度。实物测试也证明了其在现实环境中的实用性和迁移能力。

Conclusion: PocketDP3显著提升了基于3D视觉的机器人操作策略模型的参数效率与实际应用能力，为相关领域的实时应用和部署提供了新的思路和方法。

Abstract: Recently, 3D vision-based diffusion policies have shown strong capability in learning complex robotic manipulation skills. However, a common architectural mismatch exists in these models: a tiny yet efficient point-cloud encoder is often paired with a massive decoder. Given a compact scene representation, we argue that this may lead to substantial parameter waste in the decoder. Motivated by this observation, we propose PocketDP3, a pocket-scale 3D diffusion policy that replaces the heavy conditional U-Net decoder used in prior methods with a lightweight Diffusion Mixer (DiM) built on MLP-Mixer blocks. This architecture enables efficient fusion across temporal and channel dimensions, significantly reducing model size. Notably, without any additional consistency distillation techniques, our method supports two-step inference without sacrificing performance, improving practicality for real-time deployment. Across three simulation benchmarks--RoboTwin2.0, Adroit, and MetaWorld--PocketDP3 achieves state-of-the-art performance with fewer than 1% of the parameters of prior methods, while also accelerating inference. Real-world experiments further demonstrate the practicality and transferability of our method in real-world settings. Code will be released.

</details>


### [200] [mjlab: A Lightweight Framework for GPU-Accelerated Robot Learning](https://arxiv.org/abs/2601.22074)
*Kevin Zakka,Qiayuan Liao,Brent Yi,Louis Le Lay,Koushil Sreenath,Pieter Abbeel*

Main category: cs.RO

TL;DR: mjlab是一个轻量级、开源的机器人学习框架，结合了GPU加速仿真和可组合环境，安装和使用都非常便捷。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人学习平台常常存在依赖繁杂、搭建困难和仿真效率低的问题。作者希望提供一个易于搭建、支持GPU加速仿真的新框架。

Method: mjlab借鉴Isaac Lab的API理念，采用模块化（可组合）的观察、奖励和事件管理方式，并与MuJoCo Warp结合实现GPU加速物理仿真。整个框架只需一条命令即可安装，且直接访问原生MuJoCo数据结构。

Result: 框架实现了速度追踪、动作模仿和操作任务的参考实现，安装依赖极简，集成了高效的GPU仿真。

Conclusion: mjlab为机器人学习研究提供了一个高效、易用、可扩展的新型仿真平台，有助于推动相关研究发展。

Abstract: We present mjlab, a lightweight, open-source framework for robot learning that combines GPU-accelerated simulation with composable environments and minimal setup friction. mjlab adopts the manager-based API introduced by Isaac Lab, where users compose modular building blocks for observations, rewards, and events, and pairs it with MuJoCo Warp for GPU-accelerated physics. The result is a framework installable with a single command, requiring minimal dependencies, and providing direct access to native MuJoCo data structures. mjlab ships with reference implementations of velocity tracking, motion imitation, and manipulation tasks.

</details>


### [201] [ReactEMG Stroke: Healthy-to-Stroke Few-shot Adaptation for sEMG-Based Intent Detection](https://arxiv.org/abs/2601.22090)
*Runsheng Wang,Katelyn Lee,Xinyue Zhu,Lauren Winterbottom,Dawn M. Nilsen,Joel Stein,Matei Ciocarlie*

Main category: cs.RO

TL;DR: 本文提出了一种将健康人sEMG信号预训练模型迁移到脑卒中康复患者的意图检测任务中的适应方法，极大减轻了个体化校准负担，并提升了系统鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 脑卒中患者手部康复过程中，借助sEMG作为辅助控制信号有巨大潜力。但由于卒中后肌肉信号微弱多变，现有意图检测通常需要患者个体大量标注训练，过程繁琐且对环境变化敏感，实际应用受限。因此，亟需一种既能减少训练数据需求，又能适应实际分布漂移及变化的鲁棒意图检测方法。

Method: 作者提出将健康人群大规模sEMG数据预训练的意图检测模型作为初始，再用很少量患者数据进行微调。对比了三种模型适应策略：只微调分类头（head-only）、参数高效的LoRA适配器、端到端全模型微调。在新采集的三名脑卒中患者数据集上评估，并在多种现实分布漂移条件下（会话内漂移、姿势变化、臂环重定位）做了全面对比。

Result: 健康人预训练+迁移方法在各种条件下，卒中意图检测表现显著优于直接迁移和仅用卒中数据训练。最佳适应策略可将平均转移准确率从0.42提升至0.61，整体准确率从0.69提升至0.78。

Conclusion: 基于健康人群预训练表面肌电的迁移适应方法，可以显著减少卒中患者个体化校准的数据量，同时提升用于实时意图检测的鲁棒性，对于实际脑卒中康复辅助设备具有良好应用前景。

Abstract: Surface electromyography (sEMG) is a promising control signal for assist-as-needed hand rehabilitation after stroke, but detecting intent from paretic muscles often requires lengthy, subject-specific calibration and remains brittle to variability. We propose a healthy-to-stroke adaptation pipeline that initializes an intent detector from a model pretrained on large-scale able-bodied sEMG, then fine-tunes it for each stroke participant using only a small amount of subject-specific data. Using a newly collected dataset from three individuals with chronic stroke, we compare adaptation strategies (head-only tuning, parameter-efficient LoRA adapters, and full end-to-end fine-tuning) and evaluate on held-out test sets that include realistic distribution shifts such as within-session drift, posture changes, and armband repositioning. Across conditions, healthy-pretrained adaptation consistently improves stroke intent detection relative to both zero-shot transfer and stroke-only training under the same data budget; the best adaptation methods improve average transition accuracy from 0.42 to 0.61 and raw accuracy from 0.69 to 0.78. These results suggest that transferring a reusable healthy-domain EMG representation can reduce calibration burden while improving robustness for real-time post-stroke intent detection.

</details>


### [202] [DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation](https://arxiv.org/abs/2601.22153)
*Haozhe Xie,Beichen Wen,Jiarui Zheng,Zhaoxi Chen,Fangzhou Hong,Haiwen Diao,Ziwei Liu*

Main category: cs.RO

TL;DR: 本文提出了DynamicVLA框架，显著提升了VLA模型对动态物体操作的能力，并建立了新的动态操作基准数据集DOM。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型虽然在静态操作任务上泛化能力强，但在面对动态场景（需要快速感知、时序预测与连续控制）时表现较差。缺乏专门针对动态操作的大规模数据集也限制了相关研究发展。

Method: DynamicVLA框架通过三个主要设计实现动态操控：1）采用结构紧凑的0.4B参数卷积视觉编码器，用于高效空间信息编码和快速多模态推理；2）提出连续推理机制，实现推理与执行重叠，降低延迟并快速适应物体运动变化；3）设计潜变量感知的动作流机制，确保感知与执行的时序对齐。同时该团队自建了DOM基准数据集，包括20万合成和2千真实动态操作片段。

Result: 在大量实验中，DynamicVLA在响应速度、感知能力和泛化能力等方面均显著优于现有模型。实验涵盖多种动态操作任务和不同硬件平台，结果确认了方法的广泛适用性与优越性能。

Conclusion: DynamicVLA为通用动态物体操作任务提供了一个统一、高效且扩展性强的解决方案，同时DOM数据集为后续相关研究打下了坚实基础。

Abstract: Manipulating dynamic objects remains an open challenge for Vision-Language-Action (VLA) models, which, despite strong generalization in static manipulation, struggle in dynamic scenarios requiring rapid perception, temporal anticipation, and continuous control. We present DynamicVLA, a framework for dynamic object manipulation that integrates temporal reasoning and closed-loop adaptation through three key designs: 1) a compact 0.4B VLA using a convolutional vision encoder for spatially efficient, structurally faithful encoding, enabling fast multimodal inference; 2) Continuous Inference, enabling overlapping reasoning and execution for lower latency and timely adaptation to object motion; and 3) Latent-aware Action Streaming, which bridges the perception-execution gap by enforcing temporally aligned action execution. To fill the missing foundation of dynamic manipulation data, we introduce the Dynamic Object Manipulation (DOM) benchmark, built from scratch with an auto data collection pipeline that efficiently gathers 200K synthetic episodes across 2.8K scenes and 206 objects, and enables fast collection of 2K real-world episodes without teleoperation. Extensive evaluations demonstrate remarkable improvements in response speed, perception, and generalization, positioning DynamicVLA as a unified framework for general dynamic object manipulation across embodiments.

</details>
