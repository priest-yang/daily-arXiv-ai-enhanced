<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 134]
- [cs.CL](#cs.CL) [Total: 144]
- [cs.RO](#cs.RO) [Total: 33]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [HyperTopo-Adapters: Geometry- and Topology-Aware Segmentation of Leaf Lesions on Frozen Encoders](https://arxiv.org/abs/2601.06067)
*Chimdi Walter Ndubuisi,Toni Kazic*

Main category: cs.CV

TL;DR: 该论文提出了HyperTopo-Adapters，用于提高叶片病斑分割的拓扑敏感性，并开源了完整的训练与评估套件。


<details>
  <summary>Details</summary>
Motivation: 叶斑分割任务中，细微的区域合并、裂分或假洞都有重要生物意义，但常规像素级损失不足以捕捉这些拓扑特征。

Method: 作者在冻结的视觉编码器顶层训练HyperTopo-Adapters，将特征嵌入到双曲+欧几里得+球面（H+E+S）乘积流形空间，实现分层、局部、全局拓扑信息融合。拓扑先验以持久同调距离与可微欧拉特征结合全变差正则化两种方式引入，同时结合结构感知评估指标和动态checkpoint选择策略。

Result: 在Kaggle叶斑数据集上，方法在边界和拓扑指标上有9%的提升，同时Dice/IoU指标亦具竞争力。通过消融实验验证了不同超参数和网络结构假设的有效性。

Conclusion: 论文为拓扑敏感的分割提供了新的方法论和开源工具，对未来设计严格保存拓扑结构的模型有启发意义。

Abstract: Leaf-lesion segmentation is topology-sensitive: small merges, splits, or false holes can be biologically meaningful descriptors of biochemical pathways, yet they are weakly penalized by standard pixel-wise losses in Euclidean latents. I explore HyperTopo-Adapters, a lightweight, parameter-efficient head trained on top of a frozen vision encoder, which embeds features on a product manifold -- hyperbolic + Euclidean + spherical (H + E + S) -- to encourage hierarchical separation (H), local linear detail (E), and global closure (S). A topology prior complements Dice/BCE in two forms: (i) persistent-homology (PH) distance for evaluation and selection, and (ii) a differentiable surrogate that combines a soft Euler-characteristic match with total variation regularization for stable training. I introduce warm-ups for both the hyperbolic contrastive term and the topology prior, per-sample evaluation of structure-aware metrics (Boundary-F1, Betti errors, PD distance), and a min-PD within top-K Dice rule for checkpoint selection. On a Kaggle leaf-lesion dataset (N=2,940), early results show consistent gains in boundary and topology metrics (reducing Delta beta_1 hole error by 9%) while Dice/IoU remain competitive. The study is diagnostic by design: I report controlled ablations (curvature learning, latent dimensions, contrastive temperature, surrogate settings), and ongoing tests varying encoder strength (ResNet-50, DeepLabV3, DINOv2/v3), input resolution, PH weight, and partial unfreezing of late blocks. The contribution is an open, reproducible train/eval suite (available at https://github.com/ChimdiWalter/HyperTopo-Adapters) that isolates geometric/topological priors and surfaces failure modes to guide stronger, topology-preserving architectures.

</details>


### [2] [OptFormer: Optical Flow-Guided Attention and Phase Space Reconstruction for SST Forecasting](https://arxiv.org/abs/2601.06078)
*Yin Wang,Chunlin Gong,Zhuozhen Xu,Lehan Zhang,Xiang Wu*

Main category: cs.CV

TL;DR: 本文提出了一种新的编码器-解码器模型OptFormer，通过结合相空间重建和基于光流的运动感知注意力机制，有效提升了海表温度（SST）预测的准确性和鲁棒性。实验表明，该方法在多个尺度上的公开数据集上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: SST预测对气候建模和灾害预警至关重要，但其高度非线性的时空动态和长期预测需求使得预测任务极具挑战。现有方法通常难以捕捉动态变化区域和长期依赖。

Method: 作者提出OptFormer模型，将相空间重建与创新的运动感知注意力机制结合。该注意力机制利用光流引导，从多个帧的运动信息中突出捕捉区域变化特征，加强对高动态区域和长时依赖性的建模能力。

Result: 在NOAA的SST数据集上，模型在不同空间尺度下均超过主流基线方法，特别是在1:1训练与预测长度设置下展现出显著的准确率和鲁棒性提升。

Conclusion: OptFormer模型有效解决了SST预测中的时空动态与长期依赖建模难题，为气候预测提供了更强的方法论基础，具备较强的推广前景。

Abstract: Sea Surface Temperature (SST) prediction plays a vital role in climate modeling and disaster forecasting. However, it remains challenging due to its nonlinear spatiotemporal dynamics and extended prediction horizons. To address this, we propose OptFormer, a novel encoder-decoder model that integrates phase-space reconstruction with a motion-aware attention mechanism guided by optical flow. Unlike conventional attention, our approach leverages inter-frame motion cues to highlight relative changes in the spatial field, allowing the model to focus on dynamic regions and capture long-range temporal dependencies more effectively. Experiments on NOAA SST datasets across multiple spatial scales demonstrate that OptFormer achieves superior performance under a 1:1 training-to-prediction setting, significantly outperforming existing baselines in accuracy and robustness.

</details>


### [3] [Semantic Event Graphs for Long-Form Video Question Answering](https://arxiv.org/abs/2601.06097)
*Aradhya Dixit,Tianxi Liang*

Main category: cs.CV

TL;DR: 本文提出了语义事件图（SEG）作为视频和语言之间的轻量级符号接口，用临时交互日志代替原始视频帧，大幅提升长视频问答系统的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉-语言模型难以在不超出计算和token预算的情况下处理长时长视频，现有方法在时间覆盖范围和分析成本之间存在权衡。

Method: 提出SEG流程：用YOLOv11检测跟踪对象，根据接近模式生成人-物体事件（START/END），组织成时序场景图（TSG）；推理时，利用与问题相关的剪枝模块选出核心事件和实体，转为文本后输入大语言模型Gemini 2.5 Flash作答。

Result: SEG在5个YouTube长视频和120个自动生成的问题集上，使用每问仅3.47k个token，实现了65.0%的准确率（几乎持平于完整日志方案），且token消耗降低91.4%。只看最后30秒的基线方法准确率骤降至2.5%。

Conclusion: SEG证明了符号化的时序图结构可作为通用视觉-语言模型的高效长时记忆层，显著提升长视频问答的可扩展性和经济性。代码和工具即将开源以促进复现和后续研究。

Abstract: Long-form video question answering remains challenging for modern vision-language models, which struggle to reason over hour-scale footage without exceeding practical token and compute budgets. Existing systems typically downsample frames or feed dense visual embeddings to large-context language models, trading off temporal coverage against cost. We propose Semantic Event Graphs (SEG), a lightweight symbolic interface between video and language that replaces raw frames with compact temporal interaction logs. Our pipeline detects and tracks objects with YOLOv11, converts proximity patterns into START/END human-object events, and organizes them into a Temporal Scene Graph (TSG). At inference time, a query-aware pruning module identifies anchor entities and lexically relevant events, returning only a small subgraph which is verbalized and passed to Gemini 2.5 Flash for answer generation. On five YouTube videos (300-500 interactions each) and 120 automatically generated long-horizon questions, SEG achieves 65.0% accuracy using only 3.47k tokens per query, closely matching a full-log baseline (62.5% at 40.39k tokens) while reducing token usage by 91.4%. A short-context baseline restricted to the last 30 seconds collapses to 2.5% accuracy, underscoring the need for explicit temporal memory. These results show that symbolic temporal graphs can serve as an effective, plug-and-play memory layer for off-the-shelf vision-language models, preserving long-range reasoning ability while making long-form video question answering substantially more token- and cost-efficient. Code, logs, and event-extraction tools will be released for reproducibility.

</details>


### [4] [COVR:Collaborative Optimization of VLMs and RL Agent for Visual-Based Control](https://arxiv.org/abs/2601.06122)
*Canming Xia,Peixi Peng,Guang Tan,Zhan Su,Haoran Xu,Zhenxian Liu,Luntong Li*

Main category: cs.CV

TL;DR: 提出COVR框架，实现视觉-语言模型(VLM)与强化学习(RL)政策的协同优化，通过RL数据提升VLM语义推理，并反过来指导RL策略，提高样本效率与任务表现。


<details>
  <summary>Details</summary>
Motivation: 视觉强化学习面临高维观测导致的样本效率低下问题。以往研究多关注VLM知识迁移到RL，忽视利用RL生成交互数据反哺VLM潜力。为提升VLM与RL双向性能，需探索二者协同优化的新方法。

Method: 提出COVR框架，通过微调VLM以适应RL任务，增强其任务相关的语义理解力，再利用改进后的VLM通过先验指导RL策略。引入两个关键模块：1）探索驱动动态过滤器模块，根据探索程度自适应保留高价值样本；2）回报感知自适应损失加权模块，通过回报信号量化样本动作选择的不一致性，提升训练稳定性。同时设计逐步微调策略降低资源消耗。

Result: COVR在多个具有挑战性的视觉控制任务中表现优异，显著提升了样本效率和最终任务成功率。

Conclusion: COVR实现了VLM和RL策略的双向提升，有效利用RL数据提升VLM能力，增强VLM指导下的RL表现，推动了视觉强化学习高效研究的进展。

Abstract: Visual reinforcement learning (RL) suffers from poor sample efficiency due to high-dimensional observations in complex tasks. While existing works have shown that vision-language models (VLMs) can assist RL, they often focus on knowledge distillation from the VLM to RL, overlooking the potential of RL-generated interaction data to enhance the VLM. To address this, we propose COVR, a collaborative optimization framework that enables the mutual enhancement of the VLM and RL policies. Specifically, COVR fine-tunes the VLM with RL-generated data to enhance the semantic reasoning ability consistent with the target task, and uses the enhanced VLM to further guide policy learning via action priors. To improve fine-tuning efficiency, we introduce two key modules: (1) an Exploration-Driven Dynamic Filter module that preserves valuable exploration samples using adaptive thresholds based on the degree of exploration, and (2) a Return-Aware Adaptive Loss Weight module that improves the stability of training by quantifying the inconsistency of sampling actions via return signals of RL. We further design a progressive fine-tuning strategy to reduce resource consumption. Extensive experiments show that COVR achieves strong performance across various challenging visual control tasks.

</details>


### [5] [Low-Back Pain Physical Rehabilitation by Movement Analysis in Clinical Trial](https://arxiv.org/abs/2601.06138)
*Sao Mai Nguyen*

Main category: cs.CV

TL;DR: 本文提出了一个用于低背痛康复训练的临床医疗数据集（Keraal dataset），并用以评测最先进的人体动作分析算法，以支持智能辅导系统在康复领域的发展。


<details>
  <summary>Details</summary>
Motivation: 为推动智能辅导系统在康复医学中的应用，急需包含真实患者康复运动的高质量数据集，以支持算法的开发与评测。

Method: 收集临床患者完成低背痛康复训练的运动数据，创建Keraal数据集，并以此为基准测试现有的人体动作分析算法，同时针对动作评估、错误识别、空间定位和时间定位四大监测挑战进行研究。

Result: 构建了具有临床代表性的Keraal数据集，并初步对现有动作分析方法在四大挑战（动作评估、错误识别、空间定位、时间定位）上的表现进行了基准测试。

Conclusion: Keraal数据集为康复智能辅导系统的开发和评测提供了重要资源，有助于智能康复技术面向实际临床应用的进一步发展和完善。

Abstract: To allow the development and assessment of physical rehabilitation by an intelligent tutoring system, we propose a medical dataset of clinical patients carrying out low back-pain rehabilitation exercises and benchmark on state of the art human movement analysis algorithms. This dataset is valuable because it includes rehabilitation motions in a clinical setting with patients in their rehabilitation program. This paper introduces the Keraal dataset, a clinically collected dataset to enable intelligent tutoring systems (ITS) for rehabilitation. It addresses four challenges in exercise monitoring: motion assessment, error recognition, spatial localization, temporal localization

</details>


### [6] [Forget-It-All: Multi-Concept Machine Unlearning via Concept-Aware Neuron Masking](https://arxiv.org/abs/2601.06163)
*Kaiyuan Deng,Bo Hui,Gen Li,Jie Ji,Minghai Qin,Geng Yuan,Xiaolong Ma*

Main category: cs.CV

TL;DR: 本文提出了一种名为FIA（Forget It All）的新型方法，用于在不重新训练的情况下，从文本到图像扩散模型中高效移除多个不良概念，实现多概念遗忘，同时保持生成质量与语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型可能生成受版权、敏感或不当内容影响的图像，造成合规和道德风险。机器遗忘技术能选择性移除这些内容，但现有方法难以应对实际场景下的多概念同时遗忘，影响实用性。因此亟需更高效强大的多概念遗忘方法。

Method: 提出FIA方法：（1）利用对比概念显著性评估每条参数对目标概念的贡献；（2）结合时间和空间特征识别概念敏感神经元；（3）根据识别结果生成遮罩，多概念遗忘中通过融合，仅移除特定概念神经元，保留通用内容。该方法无需重新训练，仅需少量超参数调整，易于部署。

Result: 通过三类不同遗忘任务的大量实验，FIA在多概念遗忘有效性、语义一致性和生成质量等方面，均优于现有方法，表现更为可靠和稳定。

Conclusion: FIA是一种高效、免训练、超参数不敏感的多概念遗忘框架，可实际解决扩散模型合规性和内容安全问题，为机器遗忘提供了更为实用和可扩展的解决方案。

Abstract: The widespread adoption of text-to-image (T2I) diffusion models has raised concerns about their potential to generate copyrighted, inappropriate, or sensitive imagery learned from massive training corpora. As a practical solution, machine unlearning aims to selectively erase unwanted concepts from a pre-trained model without retraining from scratch. While most existing methods are effective for single-concept unlearning, they often struggle in real-world scenarios that require removing multiple concepts, since extending them to this setting is both non-trivial and problematic, causing significant challenges in unlearning effectiveness, generation quality, and sensitivity to hyperparameters and datasets. In this paper, we take a unique perspective on multi-concept unlearning by leveraging model sparsity and propose the Forget It All (FIA) framework. FIA first introduces Contrastive Concept Saliency to quantify each weight connection's contribution to a target concept. It then identifies Concept-Sensitive Neurons by combining temporal and spatial information, ensuring that only neurons consistently responsive to the target concept are selected. Finally, FIA constructs masks from the identified neurons and fuses them into a unified multi-concept mask, where Concept-Agnostic Neurons that broadly support general content generation are preserved while concept-specific neurons are pruned to remove the targets. FIA is training-free and requires only minimal hyperparameter tuning for new tasks, thereby promoting a plug-and-play paradigm. Extensive experiments across three distinct unlearning tasks demonstrate that FIA achieves more reliable multi-concept unlearning, improving forgetting effectiveness while maintaining semantic fidelity and image quality.

</details>


### [7] [What Users Leave Unsaid: Under-Specified Queries Limit Vision-Language Models](https://arxiv.org/abs/2601.06165)
*Dasol Choi,Guijin Son,Hanwool Lee,Minhyuk Kim,Hyunwoo Ko,Teabin Lim,Ahn Eungyeol,Jungwhan Kim,Seunghyeok Hong,Youngsook Song*

Main category: cs.CV

TL;DR: 该论文提出了HAERAE-Vision基准，专注于处理自然而含糊的真实用户视觉查询，发现当今视觉语言模型在这类任务上表现远低于结构化任务。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言基准多为明确、规范的问题，而真实用户的查询往往口语化、信息不充分，模型在此类情境下真实能力未知，有必要建立新的基准来评估并推动模型向真实应用接轨。

Method: 研究者从韩国线上社区收集了86,000个视觉问题，最终精选653个真实非结构化查询，并为每个查询设计对应的明确化重述，共得到1,306个查询。随后评测了39个主流视觉语言模型在原始查询和明确化查询上的表现，并进一步探索了结合网络检索的影响。

Result: 主流模型（包括GPT-5、Gemini 2.5 Pro）在原始非结构化问题上的正确率均不足50%。将查询明确化后，模型表现提升8-22个百分点，提升在小规模模型上更为显著。即使追加网络检索，非结构化问题的表现仍落后于明确化的问题，说明现有检索难以弥补用户未说明的隐含信息。

Conclusion: 视觉语言模型在真实模糊查询上的性能低于基准测试结果，主要受限于用户查询的天然含糊性而非模型本身能力，揭示了评测与实际应用间的重要鸿沟，强调未来基准和模型需更关注处理不完整、含糊查询。

Abstract: Current vision-language benchmarks predominantly feature well-structured questions with clear, explicit prompts. However, real user queries are often informal and underspecified. Users naturally leave much unsaid, relying on images to convey context. We introduce HAERAE-Vision, a benchmark of 653 real-world visual questions from Korean online communities (0.76% survival from 86K candidates), each paired with an explicit rewrite, yielding 1,306 query variants in total. Evaluating 39 VLMs, we find that even state-of-the-art models (GPT-5, Gemini 2.5 Pro) achieve under 50% on the original queries. Crucially, query explicitation alone yields 8 to 22 point improvements, with smaller models benefiting most. We further show that even with web search, under-specified queries underperform explicit queries without search, revealing that current retrieval cannot compensate for what users leave unsaid. Our findings demonstrate that a substantial portion of VLM difficulty stem from natural query under-specification instead of model capability, highlighting a critical gap between benchmark evaluation and real-world deployment.

</details>


### [8] [B-FIRE: Binning-Free Diffusion Implicit Neural Representation for Hyper-Accelerated Motion-Resolved MRI](https://arxiv.org/abs/2601.06166)
*Di Xu,Hengjie Liu,Yang Yang,Mary Feng,Jin Ning,Xin Miao,Jessica E. Scholey,Alexandra E. Hotca-cho,William C. Chen,Michael Ohliger,Martina Descovich,Huiming Dong,Wensha Yang,Ke Sheng*

Main category: cs.CV

TL;DR: 本研究提出了一种新的4D动态MRI重建方法B-FIRE，能够从极度欠采样的非笛卡尔k空间数据中恢复腹部瞬时三维解剖结构。实验显示，该方法在成像真实性、运动一致性和推理速度上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前4DMRI方法通常对呼吸周期进行分箱（binning）平均，导致运动信息模糊和瞬时动态信息丢失，而恢复高质量、时刻分辨的动态成像需要建立新的重建范式。

Method: 提出了B-FIRE框架，无需分箱，利用CNN-INR编码器-解码器架构，并结合扩散优化和包含时域及频域约束的综合损失函数进行训练。以分箱运动对图像作为训练参考，切实在未经分箱、极度欠采样的数据上推理，并与多种主流重建方法进行了对比实验。

Result: 在T1加权StarVIBE肝脏MRI数据上，B-FIRE在图像重建质量、运动轨迹一致性和推理速度方面均优于直接NuFFT、GRASP-CS和卷积神经网络展开方法。

Conclusion: B-FIRE能够在极高加速比下实现高保真度动态MRI重建，为实时、瞬时三维腹部成像和动态医学应用提供了新的解决方案。

Abstract: Accelerated dynamic volumetric magnetic resonance imaging (4DMRI) is essential for applications relying on motion resolution. Existing 4DMRI produces acceptable artifacts of averaged breathing phases, which can blur and misrepresent instantaneous dynamic information. Recovery of such information requires a new paradigm to reconstruct extremely undersampled non-Cartesian k-space data. We propose B-FIRE, a binning-free diffusion implicit neural representation framework for hyper-accelerated MR reconstruction capable of reflecting instantaneous 3D abdominal anatomy. B-FIRE employs a CNN-INR encoder-decoder backbone optimized using diffusion with a comprehensive loss that enforces image-domain fidelity and frequency-aware constraints. Motion binned image pairs were used as training references, while inference was performed on binning-free undersampled data. Experiments were conducted on a T1-weighted StarVIBE liver MRI cohort, with accelerations ranging from 8 spokes per frame (RV8) to RV1. B-FIRE was compared against direct NuFFT, GRASP-CS, and an unrolled CNN method. Reconstruction fidelity, motion trajectory consistency, and inference latency were evaluated.

</details>


### [9] [Analyzing the Structure of Handwritten Digits: A Comparative Study of PCA, Factor Analysis, and UMAP](https://arxiv.org/abs/2601.06168)
*Jyotiraditya Gupta*

Main category: cs.CV

TL;DR: 本文使用PCA、FA和UMAP三种降维方法分析MNIST手写数字数据集，揭示了手写数字在高维空间中的低维结构。


<details>
  <summary>Details</summary>
Motivation: 尽管手写数字以高维像素形式存在，但其真实结构具有强烈的几何和统计规律。作者意在揭示这些潜在结构及不同降维方法展现的互补特征。

Method: 论文采用PCA、FA和UMAP三种常用降维方法。PCA用于揭示方差主方向和高保真还原；FA分解出与笔画、圈、对称性等可解释的潜在因子；UMAP分析非线性流形，展示数字类别间风格的平滑过渡。

Result: PCA可用少量主成分重构大部分数字信息；FA分解出了字形的基础构件；UMAP揭示了手写数字在类别间的非线性过渡结构。三种方法从不同侧面分析了手写数字的低维结构。

Conclusion: 手写数字数据本质上分布在低维有结构的流形上，不同的统计降维框架能补充性地揭示这种结构的多样侧面。

Abstract: Handwritten digit images lie in a high-dimensional pixel space but exhibit strong geometric and statistical structure. This paper investigates the latent organization of handwritten digits in the MNIST dataset using three complementary dimensionality reduction techniques: Principal Component Analysis (PCA), Factor Analysis (FA), and Uniform Manifold Approximation and Projection (UMAP). Rather than focusing on classification accuracy, we study how each method characterizes intrinsic dimensionality, shared variation, and nonlinear geometry. PCA reveals dominant global variance directions and enables high-fidelity reconstructions using a small number of components. FA decomposes digits into interpretable latent handwriting primitives corresponding to strokes, loops, and symmetry. UMAP uncovers nonlinear manifolds that reflect smooth stylistic transitions between digit classes. Together, these results demonstrate that handwritten digits occupy a structured low-dimensional manifold and that different statistical frameworks expose complementary aspects of this structure.

</details>


### [10] [Think Bright, Diffuse Nice: Enhancing T2I-ICL via Inductive-Bias Hint Instruction and Query Contrastive Decoding](https://arxiv.org/abs/2601.06169)
*Zhiyong Ma,Zhenpeng Li,Yuanjie Shi,Zhengping Li,Jiahao Chen,Qingyuan Chuai*

Main category: cs.CV

TL;DR: 本文提出了一种无需额外训练的Text-to-Image In-Context Learning（T2I-ICL）方法TBDN，通过两个互补机制提升生成质量，在多个数据集和不同模型下都取得了领先效果。


<details>
  <summary>Details</summary>
Motivation: T2I-ICL用于根据文本与示例图片生成定制图片，但存在合规性失败和先验主导幻觉两大瓶颈，影响生成质量。以往方法依赖特定训练，缺乏灵活性且部署成本高。因此，本研究旨在解决上述双重瓶颈，提升方法通用性和实用性。

Method: 提出TBDN框架，无需再训练模型。其核心是两个闭环机制：Hint Instruction（HI）用轻量级提示工程为模型引入任务适应性归纳偏置，解决合规性失败；Query Contrastive Decoding（QCD）通过比较完整输入和省略查询后的分布调整生成过程，抑制因先验主导引发的幻觉。

Result: TBDN在CoBSAT和Text-to-Image Fast Mini-ImageNet等基准上实现最优性能，并在不同模型、提示方式和超参数下表现出良好泛化性。此外，在Dreambench++上保持对概念保留和提示遵循方面的优异表现。

Conclusion: TBDN突破了T2I-ICL领域长期存在的两大瓶颈，提供了一个简洁、高效且灵活的生成框架，为高效可靠的定制化图像生成提供了有力工具。

Abstract: Text-to-Image In-Context Learning (T2I-ICL) enables customized image synthesis via interleaved text-image examples but faces two mutually reinforcing bottlenecks, compliance failure and prior-dominated hallucination, that form a vicious cycle degrading generation quality. Existing methods rely on tailored training, which limits flexibility and raises deployment costs. To address these challenges effectively, we propose TBDN, a training-free framework integrating two complementary closed-loop mechanisms: Hint Instruction (HI) and Query Contrastive Decoding (QCD). HI injects task-aware inductive bias via lightweight prompt engineering to anchor models on contextual mapping rules, thereby mitigating compliance failure. QCD adjusts the decoding distributions of language models by contrasting full-input and query-omitted distributions, suppressing prior-dominated hallucination. TBDN achieves State-of-the-Art performance on CoBSAT and Text-to-Image Fast Mini-ImageNet, with robust generalization across model backbones, prompt designs, and hyperparameters. It also maintains promising performance in concept preservation and prompt following on Dreambench++. By breaking the two bottlenecks, TBDN establishes a simple yet effective framework for efficient and reliable T2I-ICL.

</details>


### [11] [TIR-Flow: Active Video Search and Reasoning with Frozen VLMs](https://arxiv.org/abs/2601.06176)
*Hongbo Jin,Siyi Xie,Jiayu Ding,Kuanwei Lin,Ge Li*

Main category: cs.CV

TL;DR: 本文提出一种名为TIR-Flow的新框架，将大规模视频语言模型从被动处理转变为主动视频搜索和推理，实现更强的视频推理能力，无需额外数据或参数更新，并在多个基准任务上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的视频语言模型虽然感知能力强，但推理能力受限，现有提升方法多依赖大规模数据构造和复杂训练流程，不能激发模型主动探索和推理的潜力。

Method: 提出TIR-Flow框架，包含三大模块：HDD模块将复杂问题分解为可验证子任务；HAP模块主动引导视觉注意力收集高分辨率证据；EBA模块维护工作空间积累和更新发现的线索进行逻辑推理。整个流程无需增加新数据或更新参数。

Result: 在七个基准测试上的实验表明，TIR-Flow在各项指标上显著优于现有强基线方法，平均性能提升5.9%，在Egoschema基准中提升达10.5%。

Conclusion: 通过赋予冻结的VLM主动感知与推理能力，能显著提升其长程视频推理表现，为提升视频-语言模型的推理能力提供了一条可扩展的路径。

Abstract: While Large Video-Language Models (Video-LLMs) have achieved remarkable progress in perception, their reasoning capabilities remain a bottleneck. Existing solutions typically resort to a heavy "data engineering" paradigm-synthesizing large-scale Chain-of-Thought (CoT) datasets followed by Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL). This pipeline primarily optimizes probability sampling efficiency and aligns output distributions, but fails to activate the intrinsic intelligence required for dynamic visual exploration. In this work, we propose TIR-Flow, a novel framework that shifts the paradigm from passive processing to active video searching and reasoning without additional data or parameter updating. Concretely, our framework operates through three synergistic modules: HDD decomposes complex queries into a set of verifiable sub-tasks; HAP actively directs visual attention to gather high-resolution evidence for hypothesis validation; EBA maintains a persistent workspace to accumulate and update the discovered clues for logical reasoning. Extensive experiments on seven benchmarks demonstrate that TIR-Flow significantly outperforms recent strong baselines, delivering an average performance boost of 5.9%, with gains reaching 10.5% on Egoschema. Our analysis confirms that empowering frozen VLMs with System-2-like active perception is a scalable path toward solving long-horizon video reasoning.

</details>


### [12] [A Unified Attention U-Net Framework for Cross-Modality Tumor Segmentation in MRI and CT](https://arxiv.org/abs/2601.06187)
*Nishan Rai,Pushpa R. Dahal*

Main category: cs.CV

TL;DR: 本研究提出了一个统一的Attention U-Net架构，在MRI（BraTS 2021）和CT（LIDC-IDRI）数据集上联合训练，用于跨模态肿瘤分割，并取得了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 目前大多数医学图像分割方法主要针对单一成像模态（如仅MRI或仅CT），缺乏通用性。针对不同模态和解剖部位建立统一的分割模型有助于降低模型开发和维护成本，促进实际应用。

Method: 本文设计了一个Attention U-Net模型，结合模态协调预处理、带注意力门控的跳跃连接、以及模态感知的Focal Tversky损失函数，并在BraTS（MRI）和LIDC-IDRI（CT）两个肿瘤数据集上同时训练。相比以往无需特定模态编码器或领域自适应。

Result: 所提出的统一模型在Dice系数、IoU和AUC等多项指标上，在MRI和CT两个领域均表现出具有竞争力的分割性能。

Conclusion: 本文验证了单一Attention U-Net可同时适用于不同影像模态和解剖部位，为跨模态肿瘤分割研究提供了一个可复现且强健的新基线。

Abstract: This study presents a unified Attention U-Net architecture trained jointly on MRI (BraTS 2021) and CT (LIDC-IDRI) datasets to investigate the generalizability of a single model across diverse imaging modalities and anatomical sites. Our proposed pipeline incorporates modality-harmonized preprocessing, attention-gated skip connections, and a modality-aware Focal Tversky loss function. To the best of our knowledge, this study is among the first to evaluate a single Attention U-Net trained simultaneously on separate MRI (BraTS) and CT (LIDC-IDRI) tumor datasets, without relying on modality-specific encoders or domain adaptation. The unified model demonstrates competitive performance in terms of Dice coefficient, IoU, and AUC on both domains, thereby establishing a robust and reproducible baseline for future research in cross-modality tumor segmentation.

</details>


### [13] [How Does India Cook Biryani?](https://arxiv.org/abs/2601.06198)
*Shubham Goel,Farzana S,C V Rishi,Aditya Arun,C V Jawahar*

Main category: cs.CV

TL;DR: 该论文创建了首个涵盖12种区域分布的大规模Biryani烹饪视频数据集，提出基于视觉-语言模型（VLM）的分段与对比方法，并通过新型问答基准测试模型对多模态料理理解能力。


<details>
  <summary>Details</summary>
Motivation: 尽管印度Biryani菜肴地区多样，但以往视频理解方法很难捕捉其细致、多模态及文化差异。随着线上烹饪视频激增，研究团队希望通过计算方法系统性地分析这些烹饪差异。

Method: 论文采集了12种不同区域风格的120个高清视频，提出多阶段框架，利用最新视觉-语言模型（VLM）分割视频、对齐音频文本与标准食谱，实现细粒度步骤标记及比较，并建立了多层次推理的问答基准。方法融合多个VLM、引入人工验证，并在零样本和微调场景下测试多种模型表现。

Result: 建立了首个大规模、经策划的Biryani烹饪视频数据集，开发了自动对比和解释不同地方制作差异的流程。证明多VLM组合及人工干预提供高精度任务结果，并对现有SOTA模型做了基准测试。

Conclusion: 团队数据集、对比流程与QA基准，为VLM在结构化多模态推理提供全新评测途径，也促进对厨艺及文化遗产的计算分析研究，成果包括数据、代码、网站全部开放。

Abstract: Biryani, one of India's most celebrated dishes, exhibits remarkable regional diversity in its preparation, ingredients, and presentation. With the growing availability of online cooking videos, there is unprecedented potential to study such culinary variations using computational tools systematically. However, existing video understanding methods fail to capture the fine-grained, multimodal, and culturally grounded differences in procedural cooking videos. This work presents the first large-scale, curated dataset of biryani preparation videos, comprising 120 high-quality YouTube recordings across 12 distinct regional styles. We propose a multi-stage framework leveraging recent advances in vision-language models (VLMs) to segment videos into fine-grained procedural units and align them with audio transcripts and canonical recipe text. Building on these aligned representations, we introduce a video comparison pipeline that automatically identifies and explains procedural differences between regional variants. We construct a comprehensive question-answer (QA) benchmark spanning multiple reasoning levels to evaluate procedural understanding in VLMs. Our approach employs multiple VLMs in complementary roles, incorporates human-in-the-loop verification for high-precision tasks, and benchmarks several state-of-the-art models under zero-shot and fine-tuned settings. The resulting dataset, comparison methodology, and QA benchmark provide a new testbed for evaluating VLMs on structured, multimodal reasoning tasks and open new directions for computational analysis of cultural heritage through cooking videos. We release all data, code, and the project website at https://farzanashaju.github.io/how-does-india-cook-biryani/.

</details>


### [14] [QwenStyle: Content-Preserving Style Transfer with Qwen-Image-Edit](https://arxiv.org/abs/2601.06202)
*Shiwen Zhang,Haibin Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 该论文提出了一种基于Qwen-Image-Edit的内容保持型风格迁移模型QwenStyle V1，通过课程持续学习框架，实现了在风格多样性与内容精确保真的平衡，并在多个指标上达到了先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散Transformer（DiT）在风格迁移任务中，由于内容和风格特征纠缠难以解耦，难以在保持原始内容同时准确迁移风格；因此，亟需开发一种能兼顾内容保持与风格自定义能力的高质量风格迁移方法。

Method: 作者首先采集并筛选高质量、有限风格的数据，并通过合成成千上万类别的风格图像三元组扩充数据集；随后提出课程持续学习（Curriculum Continual Learning）框架，对混合的高质量及噪声数据进行训练，提升模型在坚守内容一致性基础上对新风格的泛化能力。最终模型（QwenStyle V1）以Qwen-Image-Edit为核心实现端到端训练。

Result: QwenStyle V1 在风格相似性、内容一致性及美学质量三项核心指标上均达到或超越当前最优水平，展现出对未见风格良好的泛化能力。

Conclusion: 所提出的QwenStyle V1模型能够有效兼顾风格多样迁移与内容保持，解决了内容与风格特征纠缠难题，为风格迁移领域提供了新的高性能解决方案。

Abstract: Content-Preserving Style transfer, given content and style references, remains challenging for Diffusion Transformers (DiTs) due to its internal entangled content and style features. In this technical report, we propose the first content-preserving style transfer model trained on Qwen-Image-Edit, which activates Qwen-Image-Edit's strong content preservation and style customization capability. We collected and filtered high quality data of limited specific styles and synthesized triplets with thousands categories of style images in-the-wild. We introduce the Curriculum Continual Learning framework to train QwenStyle with such mixture of clean and noisy triplets, which enables QwenStyle to generalize to unseen styles without degradation of the precise content preservation capability. Our QwenStyle V1 achieves state-of-the-art performance in three core metrics: style similarity, content consistency, and aesthetic quality.

</details>


### [15] [Cascading multi-agent anomaly detection in surveillance systems via vision-language models and embedding-based classification](https://arxiv.org/abs/2601.06204)
*Tayyab Rehman,Giovanni De Gasperis,Aly Shmahell*

Main category: cs.CV

TL;DR: 本文提出了一种级联多智能体方法，实现高效、可解释的动态视觉异常检测，兼具实时性与高语义解释能力，显著提升了检测效率与质量。


<details>
  <summary>Details</summary>
Motivation: 当前动态视觉环境下的异常检测需兼顾实时性能与语义可解释性，但传统方法无法全面满足这两者。重建类模型缺乏语境推理，对象检测速度快但语义有限，大型视觉-语言模型解释性强但计算开销大，因此需要一种将多种优势整合的创新方法。

Method: 作者提出级联多智能体框架，将重建-门控筛选、对象级评估与高层语义推理模块结合，通过自适应升级阈值与异步发布-订阅通信结构，实现不同级别智能体对事件的高效、可扩展处理。

Result: 在大规模监控数据上的实验显示，该方法在保持高感知保真度（PSNR=38.3 dB, SSIM=0.965）和一致语义标注的前提下，检测延迟比直接视觉-语言推理降低三倍。

Conclusion: 该框架突破了传统检测路线，结合了早停效率、自适应多智能体推理和可解释异常归因，为可扩展、节能的智能视觉监控奠定了新基础。

Abstract: Intelligent anomaly detection in dynamic visual environments requires reconciling real-time performance with semantic interpretability. Conventional approaches address only fragments of this challenge. Reconstruction-based models capture low-level deviations without contextual reasoning, object detectors provide speed but limited semantics, and large vision-language systems deliver interpretability at prohibitive computational cost. This work introduces a cascading multi-agent framework that unifies these complementary paradigms into a coherent and interpretable architecture. Early modules perform reconstruction-gated filtering and object-level assessment, while higher-level reasoning agents are selectively invoked to interpret semantically ambiguous events. The system employs adaptive escalation thresholds and a publish-subscribe communication backbone, enabling asynchronous coordination and scalable deployment across heterogeneous hardware. Extensive evaluation on large-scale monitoring data demonstrates that the proposed cascade achieves a threefold reduction in latency compared to direct vision-language inference, while maintaining high perceptual fidelity (PSNR = 38.3 dB, SSIM = 0.965) and consistent semantic labeling. The framework advances beyond conventional detection pipelines by combining early-exit efficiency, adaptive multi-agent reasoning, and explainable anomaly attribution, establishing a reproducible and energy-efficient foundation for scalable intelligent visual monitoring.

</details>


### [16] [When Imbalance Comes Twice: Active Learning under Simulated Class Imbalance and Label Shift in Binary Semantic Segmentation](https://arxiv.org/abs/2601.06209)
*Julien Combes,Alexandre Derville,Jean-François Coeurjolly*

Main category: cs.CV

TL;DR: 本文研究了在数据高度不平衡和标签漂移（label shift）情况下主动学习（Active Learning）策略的表现与效率。通过模拟公开数据集，比较了三种常见的主动学习方法，并检验其在实际工业视觉任务中的适用性和局限性。


<details>
  <summary>Details</summary>
Motivation: 在工业视觉任务等实际应用中，缺陷样本极少且数据量巨大，导致标注代价高昂且无法存储全部数据。这形成了极端的类别不平衡和因储存限制带来的标签分布发生漂移。需要探索主流主动学习算法在这些特殊现实场景下的表现及优化空间。

Method: 采用两个公开数据集，人工设定不同的类别不平衡程度与标签分布漂移，模拟真实工业场景。比较了随机采样、基于熵的选择和核心集选择三种常见主动学习方法，分析其挑选高信息样本时的效率变化。

Result: 实验显示，即使在极端类别不平衡的情况下，基于熵和核心集的主动学习方法仍能显著提升标注效率。然而，在强烈标签漂移环境下，这些方法的效率会有所下降，损失可被量化。

Conclusion: 主动学习策略，尤其是熵与核心集方法，在数据极度不平衡时依然有效，但标签漂移会造成效率损耗，因此在实际部署时需权衡存储和数据采样策略以获得最佳性能。

Abstract: The aim of Active Learning is to select the most informative samples from an unlabelled set of data. This is useful in cases where the amount of data is large and labelling is expensive, such as in machine vision or medical imaging. Two particularities of machine vision are first, that most of the images produced are free of defects, and second, that the amount of images produced is so big that we cannot store all acquired images. This results, on the one hand, in a strong class imbalance in defect distribution and, on the other hand, in a potential label shift caused by limited storage. To understand how these two forms of imbalance affect active learning algorithms, we propose a simulation study based on two open-source datasets. We artificially create datasets for which we control the levels of class imbalance and label shift. Three standard active learning selection strategies are compared: random sampling, entropy-based selection, and core-set selection. We demonstrate that active learning strategies, and in particular the entropy-based and core-set selections, remain interesting and efficient even for highly imbalanced datasets. We also illustrate and measure the loss of efficiency that occurs in the situation a strong label shift.

</details>


### [17] [Akasha 2: Hamiltonian State Space Duality and Visual-Language Joint Embedding Predictive Architectur](https://arxiv.org/abs/2601.06212)
*Yani Meziani*

Main category: cs.CV

TL;DR: 本文提出Akasha 2，一个新型多模态架构，结合物理先验与视觉-语言联合嵌入，显著提升视频预测与视觉合成速度与质量。


<details>
  <summary>Details</summary>
Motivation: 当前多模态世界模型在实现高时空一致性和物理规律保留方面仍有不足，尤其是在移动端效率和长时预测能量守恒上存在挑战。本文旨在引入物理约束和高效推理机制来解决这些关键问题。

Method: Akasha 2集成了Hamiltonian State Space Duality（H-SSD）和视觉-语言联合嵌入预测架构（VL-JEPA），采用Mamba-3选择性状态空间模型，并通过稀疏混合Hamiltonian专家（SMoE-HE）利用辛集成保持物理守恒。视觉合成方面，提出Hamiltonian Flow Matching（HFM）和3D高斯投射（3DGS），提升移动端合成速度。

Result: 方法在视频预测中实现了前沿表现（FVD: 287）、合成速度比扩散模型快4倍、推理速度比Transformer快3-18倍，并能在长时间保持能量守恒。

Conclusion: 通过在神经架构中引入物理启发的归纳偏置，Akasha 2在世界建模、推理速度和能量守恒等方面树立了新的技术标杆，对多模态世界模型领域具有重要意义。

Abstract: We present Akasha 2, a state-of-the-art multimodal architecture that integrates Hamiltonian State Space Duality (H-SSD) with Visual-Language Joint Embedding Predictive Architecture (VL-JEPA). The system leverages the Mamba-3 Selective State Space Model (SSM) augmented by a Sparse Mixture of Hamiltonian Experts (SMoE-HE) that enforces latent physical conservation laws through symplectic integration. For visual synthesis, we introduce Hamiltonian Flow Matching (HFM) and persistent 3D Gaussian Splatting (3DGS), enabling ultra-low latency (<50ms) on mobile hardware. This work establishes a new paradigm in latent world models, achieving unprecedented spatiotemporal coherence through a holographic memory architecture. Our approach demonstrates that incorporating physics-inspired inductive biases into neural architectures yields significant improvements: state-of-the-art video prediction (FVD: 287), 4x faster visual synthesis than diffusion models, and 3-18x inference speedup over transformer baselines while maintaining energy conservation over extended horizons.

</details>


### [18] [Two-step Authentication: Multi-biometric System Using Voice and Facial Recognition](https://arxiv.org/abs/2601.06218)
*Kuan Wei Chen,Ting Yi Lin,Wen Ren Yang,Aryan Kesarwani,Riya Singh*

Main category: cs.CV

TL;DR: 本文提出了一种成本低廉的双重身份认证系统，结合人脸识别和语音识别，仅需常见设备上的摄像头和麦克风即可运行。系统在准确性和计算效率之间取得了良好平衡。


<details>
  <summary>Details</summary>
Motivation: 当前多因素身份认证常常依赖额外的硬件设备或高计算资源，增加了成本和使用门槛，本文旨在利用常见设备提升认证的安全性和易用性。

Method: 系统分为两步：先用裁剪后的VGG-16网络对MTCNN定位的人脸图像进行识别，从小样本（5人、924张图片）中确定候选用户；再仅对已识别人脸的用户进行语音身份验证，语音模型采用CNN并在LibriSpeech数据集训练。

Result: 人脸识别准确率达到95.1%，语音识别准确率98.9%，EER为3.456%。证明该方法在保证高准确度的同时也保持了较低的计算负担。

Conclusion: 双重认证系统兼顾低成本和高准确率，适合常规设备，实现便捷且安全的身份认证。相关代码和模型已公开，有利于实际部署和后续研究。

Abstract: We present a cost-effective two-step authentication system that integrates face identification and speaker verification using only a camera and microphone available on common devices. The pipeline first performs face recognition to identify a candidate user from a small enrolled group, then performs voice recognition only against the matched identity to reduce computation and improve robustness. For face recognition, a pruned VGG-16 based classifier is trained on an augmented dataset of 924 images from five subjects, with faces localized by MTCNN; it achieves 95.1% accuracy. For voice recognition, a CNN speaker-verification model trained on LibriSpeech (train-other-360) attains 98.9% accuracy and 3.456% EER on test-clean. Source code and trained models are available at https://github.com/NCUE-EE-AIAL/Two-step-Authentication-Multi-biometric-System.

</details>


### [19] [SAPL: Semantic-Agnostic Prompt Learning in CLIP for Weakly Supervised Image Manipulation Localization](https://arxiv.org/abs/2601.06222)
*Xinghao Wang,Changtao Miao,Dianmo Sheng,Tao Gong,Qi Chu,Nenghai Yu,Quanchen Zou,Deyue Zhang,Xiangzheng Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种无需像素级标注、能高效定位恶意图像篡改的新方法——SAPL，结合改进的文本提示学习与边缘对比学习，有效提升了图像篡改定位性能。


<details>
  <summary>Details</summary>
Motivation: 图像篡改威胁公共安全，精确定位篡改区域非常重要。现有方法依赖昂贵的像素级标注或忽视本地边缘信息，降低了实际可用性。本文旨在降低训练成本并提升定位精度。

Method: 提出了面向边界的语义无关Prompt学习方法（SAPL），在CLIP框架下结合边缘感知上下文Prompt学习（ECPL）与层次化边缘对比学习（HECL）：ECPL通过注意力机制将边缘信息蕴含进可学习的文本Prompt；HECL对真实与篡改边缘块采用对比学习提升辨别能力，从而在多模态特征相似性中突出篡改边缘。

Result: 在多个公开数据集上，SAPL显著优于已有方法，在无需像素级标注情况下取得了最优的篡改区域定位表现。

Conclusion: SAPL有效利用边界信息，通过在CLIP中引入边缘相关的提示和层次对比特征，显著提升了弱监督图像篡改定位能力，具有更高的实际应用价值。

Abstract: Malicious image manipulation threatens public safety and requires efficient localization methods. Existing approaches depend on costly pixel-level annotations which make training expensive. Existing weakly supervised methods rely only on image-level binary labels and focus on global classification, often overlooking local edge cues that are critical for precise localization. We observe that feature variations at manipulated boundaries are substantially larger than in interior regions. To address this gap, we propose Semantic-Agnostic Prompt Learning (SAPL) in CLIP, which learns text prompts that intentionally encode non-semantic, boundary-centric cues so that CLIPs multimodal similarity highlights manipulation edges rather than high-level object semantics. SAPL combines two complementary modules Edge-aware Contextual Prompt Learning (ECPL) and Hierarchical Edge Contrastive Learning (HECL) to exploit edge information in both textual and visual spaces. The proposed ECPL leverages edge-enhanced image features to generate learnable textual prompts via an attention mechanism, embedding semantic-irrelevant information into text features, to guide CLIP focusing on manipulation edges. The proposed HECL extract genuine and manipulated edge patches, and utilize contrastive learning to boost the discrimination between genuine edge patches and manipulated edge patches. Finally, we predict the manipulated regions from the similarity map after processing. Extensive experiments on multiple public benchmarks demonstrate that SAPL significantly outperforms existing approaches, achieving state-of-the-art localization performance.

</details>


### [20] [Ground What You See: Hallucination-Resistant MLLMs via Caption Feedback, Diversity-Aware Sampling, and Conflict Regularization](https://arxiv.org/abs/2601.06224)
*Miao Pan,Wangjie Gan,Jintao Chen,Wenqi Zhang,Bing Sun,Jianwei Yin,Xuhong Zhang*

Main category: cs.CV

TL;DR: 本文分析了多模态大语言模型（MLLMs）在通过强化学习（RL）优化过程中出现幻觉（hallucination）问题的根源，并提出了一套有效的解决框架，实验表明该方法能显著降低幻觉率，提高推理准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLMs在实际部署时经常因输出幻觉内容而受限，特别是在强化学习训练下更易放大这一问题，因此亟需找出问题根源并设计有针对性的解决方案，以提升模型的可靠性和安全性。

Method: 作者系统分析了幻觉生成的三个主要原因：（1）过度依赖链式视觉推理导致错误推理被持续放大；（2）策略优化中的探索多样性不足使模型输出自信但错误的答案；（3）训练样本间存在参数更新冲突。针对上述问题，作者提出三模块解决方案：一、引入规划与描述阶段提升视觉定位和初始信息质量；二、基于奖励分布的均值和方差优先采样高方差样本，提高探索多样性；三、分组调控样本间NTK相似性，通过InfoNCE loss缓解样本干扰。

Result: 实验结果显示，所提方法显著减少了MLLMs的幻觉现象，并提升了推理的准确率。

Conclusion: 论文提出的模块化框架系统性解决了RL优化下MLLMs易出现的幻觉问题，为多模态大模型的稳定实用提供了重要支持。

Abstract: While Multimodal Large Language Models (MLLMs) have achieved remarkable success across diverse tasks, their practical deployment is severely hindered by hallucination issues, which become particularly acute during Reinforcement Learning (RL) optimization. This paper systematically analyzes the root causes of hallucinations in MLLMs under RL training, identifying three critical factors: (1) an over-reliance on chained visual reasoning, where inaccurate initial descriptions or redundant information anchor subsequent inferences to incorrect premises; (2) insufficient exploration diversity during policy optimization, leading the model to generate overly confident but erroneous outputs; and (3) destructive conflicts between training samples, where Neural Tangent Kernel (NTK) similarity causes false associations and unstable parameter updates. To address these challenges, we propose a comprehensive framework comprising three core modules. First, we enhance visual localization by introducing dedicated planning and captioning stages before the reasoning phase, employing a quality-based caption reward to ensure accurate initial anchoring. Second, to improve exploration, we categorize samples based on the mean and variance of their reward distributions, prioritizing samples with high variance to focus the model on diverse and informative data. Finally, to mitigate sample interference, we regulate NTK similarity by grouping sample pairs and applying an InfoNCE loss to push overly similar pairs apart and pull dissimilar ones closer, thereby guiding gradient interactions toward a balanced range. Experimental results demonstrate that our proposed method significantly reduces hallucination rates and effectively enhances the inference accuracy of MLLMs.

</details>


### [21] [Synthetic FMCW Radar Range Azimuth Maps Augmentation with Generative Diffusion Model](https://arxiv.org/abs/2601.06228)
*Zhaoze Wang,Changxu Zhang,Tai Fei,Christopher Grimm,Yi Jin,Claas Tebruegge,Ernst Warsitz,Markus Gardill*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散生成模型的条件生成框架，可合成真实感的汽车雷达数据，并提升下游感知模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有汽车雷达数据集标注稀缺且多样性有限，导致基于深度学习的感知性能受限，因此需要数据合成新方法以弥补数据不足。

Method: 作者利用条件扩散生成模型，输入为不同类型目标（如行人、车辆、自行车）的信心图，结合专门为雷达设计的几何感知条件和时序一致性正则，以生成多类别的雷达距离-方位图。

Result: 在ROD2021数据集上，所提方法的信号重构峰值信噪比比传统方法提升3.6dB，真实与合成数据混合训练下均值平均精度提升4.15%。

Conclusion: 该生成框架能够生成物理合理且多样的雷达数据，有效增强下游任务模型的泛化能力。

Abstract: The scarcity and low diversity of well-annotated automotive radar datasets often limit the performance of deep-learning-based environmental perception. To overcome these challenges, we propose a conditional generative framework for synthesizing realistic Frequency-Modulated Continuous-Wave radar Range-Azimuth Maps. Our approach leverages a generative diffusion model to generate radar data for multiple object categories, including pedestrians, cars, and cyclists. Specifically, conditioning is achieved via Confidence Maps, where each channel represents a semantic class and encodes Gaussian-distributed annotations at target locations. To address radar-specific characteristics, we incorporate Geometry Aware Conditioning and Temporal Consistency Regularization into the generative process. Experiments on the ROD2021 dataset demonstrate that signal reconstruction quality improves by \SI{3.6}{dB} in Peak Signal-to-Noise Ratio over baseline methods, while training with a combination of real and synthetic datasets improves overall mean Average Precision by 4.15% compared with conventional image-processing-based augmentation. These results indicate that our generative framework not only produces physically plausible and diverse radar spectrum but also substantially improves model generalization in downstream tasks.

</details>


### [22] [A survey of facial recognition techniques](https://arxiv.org/abs/2601.06239)
*Aya Kaysan Bahjat*

Main category: cs.CV

TL;DR: 本文综述了当前面部识别领域中的主要挑战（如光照、年龄、姿态变化、遮挡、表情变化），并系统总结了主流检测方法与应用。


<details>
  <summary>Details</summary>
Motivation: 随着多媒体内容的快速增长，面部识别作为计算机视觉和图像处理领域的核心问题之一，受到了极大关注。人脸由于其复杂和独特特征，为识别带来极高挑战。

Method: 综述了多种先进的人脸检测和识别方法，包括隐马尔可夫模型（HMM）、主成分分析（PCA）、弹性聚类匹配、支持向量机（SVM）、Gabor小波、人工神经网络（ANN）、特征脸（Eigenfaces）、独立成分分析（ICA）以及三维可变形模型（3D Morphable Model）。此外，利用多个公开人脸数据库（如JAFEE、FEI、Yale、LFW、AT&T/ORL、AR）对方法进行实验分析和结果讨论。

Result: 对各种方法在不同数据库上的表现和适用场景进行了分析，列举其优缺点，并对比其在复杂条件（如光照、表情、遮挡）下的鲁棒性。

Conclusion: 本文通过全面文献回顾和实证分析，提炼出现有面部识别方法和应用的现状、挑战及未来发展方向，为后续研究和实际应用提供参考。

Abstract: As multimedia content is quickly growing, the field of facial recognition has become one of the major research fields, particularly in the recent years. The most problematic area to researchers in image processing and computer vision is the human face which is a complex object with myriads of distinctive features that can be used to identify the face. The survey of this survey is particularly focused on most challenging facial characteristics, including differences in the light, ageing, variation in poses, partial occlusion, and facial expression and presents methodological solutions. The factors, therefore, are inevitable in the creation of effective facial recognition mechanisms used on facial images. This paper reviews the most sophisticated methods of facial detection which are Hidden Markov Models, Principal Component Analysis (PCA), Elastic Cluster Plot Matching, Support Vector Machine (SVM), Gabor Waves, Artificial Neural Networks (ANN), Eigenfaces, Independent Component Analysis (ICA), and 3D Morphable Model. Alongside the works mentioned above, we have also analyzed the images of a number of facial databases, namely JAFEE, FEI, Yale, LFW, AT&T (then called ORL), and AR (created by Martinez and Benavente), to analyze the results. However, this survey is aimed at giving a thorough literature review of face recognition, and its applications, and some experimental results are provided at the end after a detailed discussion.

</details>


### [23] [EyeTheia: A Lightweight and Accessible Eye-Tracking Toolbox](https://arxiv.org/abs/2601.06279)
*Stevenson Pather,Niels Martignène,Arnaud Bugnet,Fouad Boutaleb,Fabien D'Hondt,Deise Santana Maia*

Main category: cs.CV

TL;DR: EyeTheia是一套轻量级的开源网络摄像头注视点估计深度学习管线，适用于网页实验平台及实际认知与临床研究，仅需普通笔记本摄像头即可实现实时眼动追踪，并已开源相关资源。


<details>
  <summary>Details</summary>
Motivation: 高质量的眼动追踪一般需要昂贵专用硬件，限制了大规模及低成本实验的普及。为解决这一问题，作者开发了一种依靠普通网络摄像头即可使用的注视估计算法，以促进实验和临床研究的可扩展性和再现性。

Method: EyeTheia结合了MediaPipe的人脸特征点提取和受iTracker启发的卷积神经网络架构，可选用户特定微调。作者比较了在移动端数据预训练模型适配和桌面端数据上从头训练两种方案，并进行用户微调。

Result: 无校准前，两种训练策略在MPIIFaceGaze数据集上的性能相当，用户特定微调可显著降低误差。在Dot-Probe任务中，EyeTheia与商用SeeSo SDK在左右注视分配上高度一致，尽管时间变异性稍高。

Conclusion: EyeTheia为低成本、可扩展、可重复的实验和临床研究提供了有效的眼动追踪解决方案，具有开放性与可扩展性。代码、模型及材料均已公开。

Abstract: We introduce EyeTheia, a lightweight and open deep learning pipeline for webcam-based gaze estimation, designed for browser-based experimental platforms and real-world cognitive and clinical research. EyeTheia enables real-time gaze tracking using only a standard laptop webcam, combining MediaPipe-based landmark extraction with a convolutional neural network inspired by iTracker and optional user-specific fine-tuning. We investigate two complementary strategies: adapting a model pretrained on mobile data and training the same architecture from scratch on a desktop-oriented dataset. Validation results on MPIIFaceGaze show comparable performance between both approaches prior to calibration, while lightweight user-specific fine-tuning consistently reduces gaze prediction error. We further evaluate EyeTheia in a realistic Dot-Probe task and compare it to the commercial webcam-based tracker SeeSo SDK. Results indicate strong agreement in left-right gaze allocation during stimulus presentation, despite higher temporal variability. Overall, EyeTheia provides a transparent and extensible solution for low-cost gaze tracking, suitable for scalable and reproducible experimental and clinical studies. The code, trained models, and experimental materials are publicly available.

</details>


### [24] [NAS-GS: Noise-Aware Sonar Gaussian Splatting](https://arxiv.org/abs/2601.06285)
*Shida Xu,Jingqi Jiang,Jonatan Scharff Willners,Sen Wang*

Main category: cs.CV

TL;DR: 本论文提出了针对水下声纳成像的NAS-GS框架，有效提升了3D重建和新视角合成的质量和效率，在真实和模拟场景下均取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 水下声纳图像因噪声复杂和缺乏高度信息，难以实现高质量3D重建和新视角合成。现有方法难以同时处理效率、画质和噪声过拟合问题，因此亟需新的方法来提升声纳成像任务表现。

Method: 1. 提出NAS-GS噪声感知声纳高斯涂抹框架。2. 创新性地引入双向涂抹(Two-Ways Splatting)技术，分别从强度累积和透射率两方面建模声纳成像过程，提升渲染速度和质量。3. 构建基于高斯混合模型(GMM)的噪声建模，有效捕捉各类声纳噪声特性，提升图像真实感，并防止3D高斯对噪声的过拟合。

Result: 在大规模海上模拟和真实数据集上测试，NAS-GS在新视角合成与3D重建任务上均取得了业界领先的表现，渲染速度快且图像质量优异。

Conclusion: NAS-GS有效解决了传统方法无法兼顾效率、质量与噪声过拟合的问题，为声纳影像的3D重建与新视角合成提供了先进可靠的解决方案，具备较强的应用前景。

Abstract: Underwater sonar imaging plays a crucial role in various applications, including autonomous navigation in murky water, marine archaeology, and environmental monitoring. However, the unique characteristics of sonar images, such as complex noise patterns and the lack of elevation information, pose significant challenges for 3D reconstruction and novel view synthesis. In this paper, we present NAS-GS, a novel Noise-Aware Sonar Gaussian Splatting framework specifically designed to address these challenges. Our approach introduces a Two-Ways Splatting technique that accurately models the dual directions for intensity accumulation and transmittance calculation inherent in sonar imaging, significantly improving rendering speed without sacrificing quality. Moreover, we propose a Gaussian Mixture Model (GMM) based noise model that captures complex sonar noise patterns, including side-lobes, speckle, and multi-path noise. This model enhances the realism of synthesized images while preventing 3D Gaussian overfitting to noise, thereby improving reconstruction accuracy. We demonstrate state-of-the-art performance on both simulated and real-world large-scale offshore sonar scenarios, achieving superior results in novel view synthesis and 3D reconstruction.

</details>


### [25] [Perception Test 2025: Challenge Summary and a Unified VQA Extension](https://arxiv.org/abs/2601.06287)
*Joseph Heyward,Nikhil Pathasarathy,Tyler Zhu,Aravindh Mahendran,João Carreira,Dima Damen,Andrew Zisserman,Viorica Pătrăucean*

Main category: cs.CV

TL;DR: 该论文介绍了Perception Test 2025挑战，通过统一多模态感知任务来全面评测视频模型能力，推动相关领域发展。


<details>
  <summary>Details</summary>
Motivation: 多模态感知任务种类繁多，现有方法往往使用专门为每类任务设计的模型，缺乏统一评测标准。本次挑战旨在推动将多种感知任务统一在同一框架下，以检验和促进多模态模型的泛化能力。

Method: 本次挑战共设置五个合并后的主线任务，包括统一视频问答、统一目标与点追踪、统一行为及声音定位、带定位的视频问答和超长视频问答，同时设有分析和可解释性分支。特别强调统一接口，要求参赛者使用统一方法处理多类任务，部分任务创新性地将传统感知任务转化为多项选择视频问答。

Result: 该报告汇总了各项挑战的结果与排行榜，反映出现有最先进的多模态模型在完成不同类型感知任务时，采用统一方法面临较大困难。

Conclusion: Perception Test 2025通过任务统一为多模态感知模型设定了新的挑战标准，揭示了当前模型能力的不足，为未来多模态模型的发展提供了方向。

Abstract: The Third Perception Test challenge was organised as a full-day workshop alongside the IEEE/CVF International Conference on Computer Vision (ICCV) 2025. Its primary goal is to benchmark state-of-the-art video models and measure the progress in multimodal perception. This year, the workshop featured 2 guest tracks as well: KiVA (an image understanding challenge) and Physic-IQ (a video generation challenge). In this report, we summarise the results from the main Perception Test challenge, detailing both the existing tasks as well as novel additions to the benchmark. In this iteration, we placed an emphasis on task unification, as this poses a more challenging test for current SOTA multimodal models. The challenge included five consolidated tracks: unified video QA, unified object and point tracking, unified action and sound localisation, grounded video QA, and hour-long video QA, alongside an analysis and interpretability track that is still open for submissions. Notably, the unified video QA track introduced a novel subset that reformulates traditional perception tasks (such as point tracking and temporal action localisation) as multiple-choice video QA questions that video-language models can natively tackle. The unified object and point tracking merged the original object tracking and point tracking tasks, whereas the unified action and sound localisation merged the original temporal action localisation and temporal sound localisation tracks. Accordingly, we required competitors to use unified approaches rather than engineered pipelines with task-specific models. By proposing such a unified challenge, Perception Test 2025 highlights the significant difficulties existing models face when tackling diverse perception tasks through unified interfaces.

</details>


### [26] [VideoWeave: A Data-Centric Approach for Efficient Video Understanding](https://arxiv.org/abs/2601.06309)
*Zane Durante,Silky Singh,Arpandeep Khatua,Shobhit Agarwal,Reuben Tan,Yong Jae Lee,Jianfeng Gao,Ehsan Adeli,Li Fei-Fei*

Main category: cs.CV

TL;DR: 提出了一种名为VideoWeave的方法，通过拼接现有短视频数据，合成长视频数据样本，以提升视频-语言模型的数据效率，而无需变更模型结构或训练目标。实验表明，在相同计算资源下，VideoWeave提升了下游任务表现。


<details>
  <summary>Details</summary>
Motivation: 长视频的数据标注稀缺，且训练此类模型计算成本极高。该工作旨在通过改进数据利用方式，提高训练效率，降低对真实长视频的依赖。

Method: VideoWeave通过将多个带有字幕的短视频拼接成合成的长视频样本，构建更具时间多样性的数据。方法对比了随机拼接、基于视觉特征聚类拼接以及字幕增强等多种数据组合策略，对下游视频问答任务的影响进行了系统性研究。

Result: 在同等计算资源条件下，采用VideoWeave组织训练数据的视频-语言模型，在下游视频问答任务中表现优于传统微调方法。

Conclusion: 通过重组训练数据而非改动模型结构，可以简单且高效地提升视频-语言模型的训练效果和数据利用率。

Abstract: Training video-language models is often prohibitively expensive due to the high cost of processing long frame sequences and the limited availability of annotated long videos. We present VideoWeave, a simple yet effective approach to improve data efficiency by constructing synthetic long-context training samples that splice together short, captioned videos from existing datasets. Rather than modifying model architectures or optimization objectives, VideoWeave reorganizes available video-text pairs to expand temporal diversity within fixed compute. We systematically study how different data composition strategies like random versus visually clustered splicing and caption enrichment affect downstream performance on downstream video question answering. Under identical compute constraints, models trained with VideoWeave achieve higher accuracy than conventional video finetuning. Our results highlight that reorganizing training data, rather than altering architectures, may offer a simple and scalable path for training video-language models. We link our code for all experiments here.

</details>


### [27] [Object-WIPER : Training-Free Object and Associated Effect Removal in Videos](https://arxiv.org/abs/2601.06391)
*Saksham Singh Kushwaha,Sayan Nag,Yapeng Tian,Kuldeep Kulkarni*

Main category: cs.CV

TL;DR: 本文提出了Object-WIPER，一种无需训练即可去除视频中动态物体及其相关视觉效果，并用语义一致且时序连贯内容进行修复的方法。基于预训练的文本-视频扩散模型，结合用户掩码和文本查询实现物体定位与修复，且首次提出了面向对象去除的新评测指标。实验结果在多个基准上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频动态物体去除方法需训练且难以处理复杂视觉效果，且缺乏衡量物体去除后时序和语义一致性的评估指标。因此，需要更通用且无需重新训练的方法，同时完善评测体系。

Method: 方法依赖于预训练的文本-视频扩散变换器。用户输入视频、物体掩码及文本描述，通过视觉-文本交叉注意力和视觉自注意力，提取相关视觉特征并生成效果掩码，与用户掩码融合得到最终前景掩码。对前景掩码的tokens加噪，背景保持不变，通过扩散逆过程实现重建。新设计的指标关注去除后前景跨帧一致性、前背景帧内协调性和前景去除完整性。

Result: 在DAVIS及新构建的WIPER-Bench数据集上，无需训练地实现了对动态物体的彻底去除与连续帧时序稳定修复，指标显著优于训练及无训练基准方法。

Conclusion: Object-WIPER可自适应实现视频动态物体与其效果的高质量去除及语义修复，无需额外训练，性能优异。方法、数据和代码将公开，促进相关研究社区进步。

Abstract: In this paper, we introduce Object-WIPER, a training-free framework for removing dynamic objects and their associated visual effects from videos, and inpainting them with semantically consistent and temporally coherent content. Our approach leverages a pre-trained text-to-video diffusion transformer (DiT). Given an input video, a user-provided object mask, and query tokens describing the target object and its effects, we localize relevant visual tokens via visual-text cross-attention and visual self-attention. This produces an intermediate effect mask that we fuse with the user mask to obtain a final foreground token mask to replace. We first invert the video through the DiT to obtain structured noise, then reinitialize the masked tokens with Gaussian noise while preserving background tokens. During denoising, we copy values for the background tokens saved during inversion to maintain scene fidelity. To address the lack of suitable evaluation, we introduce a new object removal metric that rewards temporal consistency among foreground tokens across consecutive frames, coherence between foreground and background tokens within each frame, and dissimilarity between the input and output foreground tokens. Experiments on DAVIS and a newly curated real-world associated effect benchmark (WIPER-Bench) show that Object-WIPER surpasses both training-based and training-free baselines in terms of the metric, achieving clean removal and temporally stable reconstruction without any retraining. Our new benchmark, source code, and pre-trained models will be publicly available.

</details>


### [28] [Context Matters: Peer-Aware Student Behavioral Engagement Measurement via VLM Action Parsing and LLM Sequence Classification](https://arxiv.org/abs/2601.06394)
*Ahmed Abdelkawy,Ahmed Elsayed,Asem Ali,Aly Farag,Thomas Tretter,Michael McIntyre*

Main category: cs.CV

TL;DR: 本论文提出了一种用视频和视觉-语言模型结合大语言模型的新方法，以小样本训练下有效识别学生课堂参与度。


<details>
  <summary>Details</summary>
Motivation: 现有方法对数据标注依赖大，但隐私问题限制了数据共享，而且往往忽视了课堂同伴行为的情境影响。作者希望解决数据匮乏和情境建模的双重困难。

Method: 提出一个三阶段的方法：（1）用视觉-语言模型，通过少量样本微调以识别学生动作类别；（2）将每段2分钟学生视频用滑动时间窗口分割，每段由VLM判定动作，形成动作序列；（3）利用大语言模型结合动作序列及课堂情境，判断学生是参与还是不参与的状态。

Result: 实验表明，所提方法在区分学生参与和未参与方面效果良好，有效识别了学生的参与度。

Conclusion: 该方法能在数据有限且考虑情境的条件下，有效提升学生课堂参与度的自动识别能力，为教育研究和教室管理提供了新思路。

Abstract: Understanding student behavior in the classroom is essential to improve both pedagogical quality and student engagement. Existing methods for predicting student engagement typically require substantial annotated data to model the diversity of student behaviors, yet privacy concerns often restrict researchers to their own proprietary datasets. Moreover, the classroom context, represented in peers' actions, is ignored. To address the aforementioned limitation, we propose a novel three-stage framework for video-based student engagement measurement. First, we explore the few-shot adaptation of the vision-language model for student action recognition, which is fine-tuned to distinguish among action categories with a few training samples. Second, to handle continuous and unpredictable student actions, we utilize the sliding temporal window technique to divide each student's 2-minute-long video into non-overlapping segments. Each segment is assigned an action category via the fine-tuned VLM model, generating a sequence of action predictions. Finally, we leverage the large language model to classify this entire sequence of actions, together with the classroom context, as belonging to an engaged or disengaged student. The experimental results demonstrate the effectiveness of the proposed approach in identifying student engagement.

</details>


### [29] [GlobalPaint: Spatiotemporal Coherent Video Outpainting with Global Feature Guidance](https://arxiv.org/abs/2601.06413)
*Yueming Pan,Ruoyu Feng,Jianmin Bao,Chong Luo,Nanning Zheng*

Main category: cs.CV

TL;DR: 本文提出了一个名为GlobalPaint的视频外延（outpainting）扩展系统，利用扩散模型在保证空间和时间一致性的基础上生成视频边界内容。该方法在关键帧和补全帧之间采用分层处理，提升了效果并减少误差累积。实验结果显示方法在视频画质和运动自然性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统图像外延仅需关注单帧的空间连贯性，而视频外延还必须保证跨帧的时序连贯性，尤其是在运动镜头或物体运动导致新区域暴露时。已有方法难以同时兼顾两者，因此需要新的方法来提升空间与时序的综合一致性与质量。

Method: 提出GlobalPaint方法，采用扩散模型为核心，通过分层流程先对关键帧进行外延生成，再通过插值模型补全中间帧，并利用已完成边界的信息提升中间帧质量。模型框架基于预训练图像修复网络，并加入增强时空模块（如3D局部注意力机制）以强化时空建模能力，同时通过全局特征引导机制对所有帧的区域特征进行整合，提取紧凑的全局信息进行指导。

Result: 在公开基准数据集上的全面实验验证了GlobalPaint的有效性。该方法能够生成更高质量的重建内容，并在外延区域表现出比以往方法更自然流畅的运动效果。

Conclusion: GlobalPaint通过多层级处理流程和创新模型设计，实现了时空一致性强、内容自然的高质量视频外延，优于现阶段主流方法。

Abstract: Video outpainting extends a video beyond its original boundaries by synthesizing missing border content. Compared with image outpainting, it requires not only per-frame spatial plausibility but also long-range temporal coherence, especially when outpainted content becomes visible across time under camera or object motion. We propose GlobalPaint, a diffusion-based framework for spatiotemporal coherent video outpainting. Our approach adopts a hierarchical pipeline that first outpaints key frames and then completes intermediate frames via an interpolation model conditioned on the completed boundaries, reducing error accumulation in sequential processing. At the model level, we augment a pretrained image inpainting backbone with (i) an Enhanced Spatial-Temporal module featuring 3D windowed attention for stronger spatiotemporal interaction, and (ii) global feature guidance that distills OpenCLIP features from observed regions across all frames into compact global tokens using a dedicated extractor. Comprehensive evaluations on benchmark datasets demonstrate improved reconstruction quality and more natural motion compared to prior methods. Our demo page is https://yuemingpan.github.io/GlobalPaint/

</details>


### [30] [WHU-PCPR: A cross-platform heterogeneous point cloud dataset for place recognition in complex urban scenes](https://arxiv.org/abs/2601.06442)
*Xianghong Zou,Jianping Li,Yandi Yang,Weitong Wu,Yuan Wang,Qiegen Liu,Zhen Dong*

Main category: cs.CV

TL;DR: 本文提出了WHU-PCPR数据集，专为点云场所识别（PCPR）设计，弥补现有数据集在场景、平台与传感器多样性方面的不足。该数据集涵盖多平台、多类型激光雷达及多时空复杂场景，并对主流PCPR方法进行了评测分析。


<details>
  <summary>Details</summary>
Motivation: 当前PCPR在自动驾驶、机器人定位与导航、地图更新等领域应用广泛，但现有数据集大多源自单一平台和传感器，场景多样性不足，限制了相关研究方法向更通用和实际环境的扩展。本文旨在建立一个跨平台、异构且丰富多样的点云数据集，以推动PCPR领域的发展。

Method: 作者采集了来自高精度车载移动激光扫描（MLS）与低成本头戴便携激光扫描（PLS）系统的点云数据，装备不同类型的机械式和固态激光雷达。数据涵盖城市与校园道路场景的实时及长期变化，空间跨度大，并持续采集长达60个月。基于该数据集，作者对多种主流PCPR方法进行了系统评测和分析。

Result: 数据集包含82.3公里轨迹、30公里不重复路线，兼顾多平台、复杂场景和长时序特性。实验证明该数据集能够有效揭示不同PCPR方法在更真实复杂环境下的性能差异，并总结了相关挑战和未来方向。数据集及基准代码公开发布。

Conclusion: WHU-PCPR数据集极大丰富了PCPR研究中的数据多样性，有助于推动相关方法向更加鲁棒和实际应用方向发展，为后续学术和工程研究提供了重要支撑。

Abstract: Point Cloud-based Place Recognition (PCPR) demonstrates considerable potential in applications such as autonomous driving, robot localization and navigation, and map update. In practical applications, point clouds used for place recognition are often acquired from different platforms and LiDARs across varying scene. However, existing PCPR datasets lack diversity in scenes, platforms, and sensors, which limits the effective development of related research. To address this gap, we establish WHU-PCPR, a cross-platform heterogeneous point cloud dataset designed for place recognition. The dataset differentiates itself from existing datasets through its distinctive characteristics: 1) cross-platform heterogeneous point clouds: collected from survey-grade vehicle-mounted Mobile Laser Scanning (MLS) systems and low-cost Portable helmet-mounted Laser Scanning (PLS) systems, each equipped with distinct mechanical and solid-state LiDAR sensors. 2) Complex localization scenes: encompassing real-time and long-term changes in both urban and campus road scenes. 3) Large-scale spatial coverage: featuring 82.3 km of trajectory over a 60-month period and an unrepeated route of approximately 30 km. Based on WHU-PCPR, we conduct extensive evaluation and in-depth analysis of several representative PCPR methods, and provide a concise discussion of key challenges and future research directions. The dataset and benchmark code are available at https://github.com/zouxianghong/WHU-PCPR.

</details>


### [31] [How to Build Robust, Scalable Models for GSV-Based Indicators in Neighborhood Research](https://arxiv.org/abs/2601.06443)
*Xiaoya Tang,Xiaohe Yue,Heran Mane,Dapeng Li,Quynh Nguyen,Tolga Tasdizen*

Main category: cs.CV

TL;DR: 本文探讨了如何将计算机视觉模型应用于社区环境健康研究，尤其是在数据有限的情况下选择和调整基础模型以及无监督训练的实际应用效果。


<details>
  <summary>Details</summary>
Motivation: 近年来，计算机视觉技术为大规模、系统化的社区环境表征带来了可能，但不同数据域（如ImageNet与Google街景图像）之间的模型泛化能力存在不确定性。实际应用中，研究者面临模型选择、训练策略、计算资源及下游性能提升等难题，因此亟需系统性分析以指导模型应用于有限有标签和大量无标签数据集。

Method: 作者通过实证分析，对比了不同计算机视觉模型（包括无监督训练方法）在数据量有限和大量无标签数据下的性能表现，并结合定量和可视化方式系统性评估模型在社区环境图像上的适应性变化。

Result: 研究发现，不同基础模型和无监督训练方法对下游任务表现影响显著。通过无监督训练可充分利用大规模无标签数据，在标签受限情况下显著提升模型效果。定量结果和可视化分析均展现了无监督适应前后的性能差异。

Conclusion: 本研究为健康社会领域如何选择与调整基础视觉模型提出了切实指导建议，强调在有限标签条件下利用无监督手段能有效提升任务表现，为后续相关研究和应用提供参考。

Abstract: A substantial body of health research demonstrates a strong link between neighborhood environments and health outcomes. Recently, there has been increasing interest in leveraging advances in computer vision to enable large-scale, systematic characterization of neighborhood built environments. However, the generalizability of vision models across fundamentally different domains remains uncertain, for example, transferring knowledge from ImageNet to the distinct visual characteristics of Google Street View (GSV) imagery. In applied fields such as social health research, several critical questions arise: which models are most appropriate, whether to adopt unsupervised training strategies, what training scale is feasible under computational constraints, and how much such strategies benefit downstream performance. These decisions are often costly and require specialized expertise.
  In this paper, we answer these questions through empirical analysis and provide practical insights into how to select and adapt foundation models for datasets with limited size and labels, while leveraging larger, unlabeled datasets through unsupervised training. Our study includes comprehensive quantitative and visual analyses comparing model performance before and after unsupervised adaptation.

</details>


### [32] [Tone Matters: The Impact of Linguistic Tone on Hallucination in VLMs](https://arxiv.org/abs/2601.06460)
*Weihao Hong,Zhiyuan Jiang,Bingyu Shen,Xinlei Guan,Yangyi Feng,Meng Xu,Boyang Li*

Main category: cs.CV

TL;DR: 本文分析了视觉-语言模型（VLM）在不同提示压力下产生幻觉（hallucination）的行为，提出了Ghost-100数据集用于精细研究由“缺失”促发的幻觉，并发现模型对结构性提示压力的处理存在局限。


<details>
  <summary>Details</summary>
Motivation: VLM正用于越来越多需要高可靠性视觉定位的安全敏感领域，但这些模型在满足用户提示时容易凭空捏造图像中没有的细节。现有的评测大多只关注物体的有无，忽略了提示措辞和结构性要求对幻觉的系统性诱发作用，因此，理解不同提示压力如何引发幻觉对改进模型安全性尤为重要。

Method: 作者提出了Ghost-100合成场景数据集，将关键视觉细节故意移除，以可控方式诱发‘缺失型’幻觉。结合5级提示压力框架（由中性问题到苛刻命令及严格格式限制），对3个主流开源VLM（MiniCPM-V 2.6-8B、Qwen2-VL-7B、Qwen3-VL-8B）在不同压力下的幻觉表现进行系统测试和分析。

Result: 实验发现，所有模型在提示强度增加时，幻觉发生率并非单调增加，部分模型在高提示强度下反而出现幻觉率下降，但在最大压力时有的模型降幅不明显。

Conclusion: 当前VLM的安全对齐对识别语义敌意（如恶意命令）更有效，对结构性提示压力（如格式要求）下的幻觉抑制效果较弱，模型在处理合规性压力方面存在特定局限性。

Abstract: Vision-Language Models (VLMs) are increasingly used in safety-critical applications that require reliable visual grounding. However, these models often hallucinate details that are not present in the image to satisfy user prompts. While recent datasets and benchmarks have been introduced to evaluate systematic hallucinations in VLMs, many hallucination behaviors remain insufficiently characterized. In particular, prior work primarily focuses on object presence or absence, leaving it unclear how prompt phrasing and structural constraints can systematically induce hallucinations. In this paper, we investigate how different forms of prompt pressure influence hallucination behavior. We introduce Ghost-100, a procedurally generated dataset of synthetic scenes in which key visual details are deliberately removed, enabling controlled analysis of absence-based hallucinations. Using a structured 5-Level Prompt Intensity Framework, we vary prompts from neutral queries to toxic demands and rigid formatting constraints. We evaluate three representative open-weight VLMs: MiniCPM-V 2.6-8B, Qwen2-VL-7B, and Qwen3-VL-8B. Across all three models, hallucination rates do not increase monotonically with prompt intensity. All models exhibit reductions at higher intensity levels at different thresholds, though not all show sustained reduction under maximum coercion. These results suggest that current safety alignment is more effective at detecting semantic hostility than structural coercion, revealing model-specific limitations in handling compliance pressure. Our dataset is available at: https://github.com/bli1/tone-matters

</details>


### [33] [On the Adversarial Robustness of 3D Large Vision-Language Models](https://arxiv.org/abs/2601.06464)
*Chao Liu,Ngai-Man Cheung*

Main category: cs.CV

TL;DR: 本论文首次系统性研究了基于点云的3D视觉语言模型（VLMs）在对抗攻击下的鲁棒性，发现其在非定向攻击下表现出明显脆弱性，但比2D VLMs对定向攻击更具抗性。


<details>
  <summary>Details</summary>
Motivation: 以往2D视觉-语言模型的研究表明，视觉输入整合使模型更容易遭受对抗攻击，产生有害输出。而3D视觉语言模型的对抗鲁棒性尚未被系统探索，因此有必要研究3D信息是否导致类似脆弱性，尤其是在其被应用于安全关键场景时。

Method: 作者提出两种互补的攻击策略：1）视觉攻击，通过扰动3D编码器及投影器产生的视觉特征，考查视觉-语言对齐的鲁棒性；2）文本攻击，直接操纵输出文本序列评估端到端系统鲁棒性。每种攻击均设计了无目标（普遍脆弱性）与有目标（定向误导）两种形式。

Result: 实验证明，3D VLMs 在无目标对抗攻击下存在显著脆弱性，但比2D模型在被定向操控生成有害输出方面表现出更强的抗攻击性。

Conclusion: 研究强调了加强3D视觉语言模型对抗鲁棒性的必要性，特别是其在安全关键领域落地应用时。

Abstract: 3D Vision-Language Models (VLMs), such as PointLLM and GPT4Point, have shown strong reasoning and generalization abilities in 3D understanding tasks. However, their adversarial robustness remains largely unexplored. Prior work in 2D VLMs has shown that the integration of visual inputs significantly increases vulnerability to adversarial attacks, making these models easier to manipulate into generating toxic or misleading outputs. In this paper, we investigate whether incorporating 3D vision similarly compromises the robustness of 3D VLMs. To this end, we present the first systematic study of adversarial robustness in point-based 3D VLMs. We propose two complementary attack strategies: \textit{Vision Attack}, which perturbs the visual token features produced by the 3D encoder and projector to assess the robustness of vision-language alignment; and \textit{Caption Attack}, which directly manipulates output token sequences to evaluate end-to-end system robustness. Each attack includes both untargeted and targeted variants to measure general vulnerability and susceptibility to controlled manipulation. Our experiments reveal that 3D VLMs exhibit significant adversarial vulnerabilities under untargeted attacks, while demonstrating greater resilience against targeted attacks aimed at forcing specific harmful outputs, compared to their 2D counterparts. These findings highlight the importance of improving the adversarial robustness of 3D VLMs, especially as they are deployed in safety-critical applications.

</details>


### [34] [SparseOccVLA: Bridging Occupancy and Vision-Language Models via Sparse Queries for Unified 4D Scene Understanding and Planning](https://arxiv.org/abs/2601.06474)
*Chenxu Dang,Jie Wang,Guang Li,Zhiwen Hou,Zihan You,Hangjun Ye,Jie Ma,Long Chen,Yan Wang*

Main category: cs.CV

TL;DR: 论文提出了SparseOccVLA模型，将视觉语言模型与稀疏语义占据建模相结合，实现了场景理解、占据预测和轨迹规划的统一。实验在多个基准上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前视觉语言模型（VLMs）擅长高层次推理但缺乏空间细节，而语义占据则提供细致空间信息但难以高效与VLMs集成。二者各有优缺，急需将这两种范式有机结合以提升自动驾驶的整体能力。

Method: 提出SparseOccVLA模型，采用稀疏占据编码器生成信息丰富的稀疏占据查询，将其对齐至语言空间，通过语言大模型进行统一场景理解和未来占据预测。另外，提出LLM引导的锚点扩散规划器，结合了锚点评分与去噪、跨模型轨迹条件融合。

Result: 在OmniDrive-nuScenes数据集上，CIDEr指标较最优现有方法提升7%；在Occ3D-nuScenes上，mIoU提升0.5；在nuScenes基准的开放式规划指标上达到最新最优。

Conclusion: SparseOccVLA实现了视觉、语言、动作的高效融合，在场景理解、占据预测和轨迹规划等方面均取得了领先效果，展示了其在自动驾驶领域的强大整体能力。

Abstract: In autonomous driving, Vision Language Models (VLMs) excel at high-level reasoning , whereas semantic occupancy provides fine-grained details. Despite significant progress in individual fields, there is still no method that can effectively integrate both paradigms. Conventional VLMs struggle with token explosion and limited spatiotemporal reasoning, while semantic occupancy provides a unified, explicit spatial representation but is too dense to integrate efficiently with VLMs. To address these challenges and bridge the gap between VLMs and occupancy, we propose SparseOccVLA, a novel vision-language-action model that unifies scene understanding, occupancy forecasting, and trajectory planning powered by sparse occupancy queries. Starting with a lightweight Sparse Occupancy Encoder, SparseOccVLA generates compact yet highly informative sparse occupancy queries that serve as the single bridge between vision and language. These queries are aligned into the language space and reasoned by the LLM for unified scene understanding and future occupancy forecasting. Furthermore, we introduce an LLM-guided Anchor-Diffusion Planner featuring decoupled anchor scoring and denoising, as well as cross-model trajectory-condition fusion. SparseOccVLA achieves a 7% relative improvement in CIDEr over the state-of-the-art on OmniDrive-nuScenes, a 0.5 increase in mIoU score on Occ3D-nuScenes, and sets state-of-the-art open-loop planning metric on nuScenes benchmark, demonstrating its strong holistic capability.

</details>


### [35] [VVTRec: Radio Interferometric Reconstruction through Visual and Textual Modality Enrichment](https://arxiv.org/abs/2601.06475)
*Kai Cheng,Ruoqi Wang,Qiong Luo*

Main category: cs.CV

TL;DR: 本文提出了一种多模态射电干涉数据重建方法VVTRec，通过结合视觉与文本特征，有效提升天文射电望远镜成像质量。


<details>
  <summary>Details</summary>
Motivation: 射电望远镜获取的能见度数据在图像重建过程中，现有方法仅依赖单一模态，导致成像中仍残存伪影和相关性建模不足。为了提升有效信息利用及成像质量，亟需引入更多信息模态和更强特征融合能力。

Method: 提出VVTRec方法，将稀疏能见度转换为图像和文本两种表征，融合视觉和语义特征。进一步引入视觉-语言大模型（VLMs），实现无训练开销下的能力增强，并使稀疏能见度可利用预训练知识提升重建效果。

Result: 实验表明，VVTRec能在不显著增加计算量的前提下，显著提升成像结构完整性和准确性，减少伪影。

Conclusion: VVTRec通过多模态特征增强，提升了稀疏能见度射电天文数据的重建质量，为天文成像提供了一种高效、优质的新方法。

Abstract: Radio astronomy is an indispensable discipline for observing distant celestial objects. Measurements of wave signals from radio telescopes, called visibility, need to be transformed into images for astronomical observations. These dirty images blend information from real sources and artifacts. Therefore, astronomers usually perform reconstruction before imaging to obtain cleaner images. Existing methods consider only a single modality of sparse visibility data, resulting in images with remaining artifacts and insufficient modeling of correlation. To enhance the extraction of visibility information and emphasize output quality in the image domain, we propose VVTRec, a multimodal radio interferometric data reconstruction method with visibility-guided visual and textual modality enrichment. In our VVTRec, sparse visibility is transformed into image-form and text-form features to obtain enhancements in terms of spatial and semantic information, improving the structural integrity and accuracy of images. Also, we leverage Vision-Language Models (VLMs) to achieve additional training-free performance improvements. VVTRec enables sparse visibility, as a foreign modality unseen by VLMs, to accurately extract pre-trained knowledge as a supplement. Our experiments demonstrate that VVTRec effectively enhances imaging results by exploiting multimodal information without introducing excessive computational overhead.

</details>


### [36] [SRFlow: A Dataset and Regularization Model for High-Resolution Facial Optical Flow via Splatting Rasterization](https://arxiv.org/abs/2601.06479)
*JiaLin Zhang,Dong Li*

Main category: cs.CV

TL;DR: 该论文提出了高分辨率人脸光流数据集SRFlow，并基于此设计了专用的光流估计模型SRFlowNet，显著提升了人脸微表情识别与光流估计的精度。


<details>
  <summary>Details</summary>
Motivation: 人脸运动分析需要高质量的人脸光流数据，但目前缺乏高分辨率的人脸光流数据集，限制了相关领域的突破。

Method: 作者采集并公布了SRFlow高分辨率人脸光流数据集；提出了SRFlowNet模型，采用掩码与梯度损失（基于差分或Sobel算子）指导光流估计，有效抑制高频噪声和纹理缺失区域中的大尺度误差，首次实现由高斯splatting引导的高分辨率皮肤运动建模。

Result: 与SRFlow数据集配合，主流人脸光流模型的终点误差（EPE）最高降低了42%；SRFlowNet模型在三个人脸微表情数据集上的F1分数提升高达48%。

Conclusion: 高分辨率的人脸光流数据和特定正则化方法能显著提升人脸光流估计和微表情识别精度，对相关领域的发展具有重大推动作用。

Abstract: Facial optical flow supports a wide range of tasks in facial motion analysis. However, the lack of high-resolution facial optical flow datasets has hindered progress in this area. In this paper, we introduce Splatting Rasterization Flow (SRFlow), a high-resolution facial optical flow dataset, and Splatting Rasterization Guided FlowNet (SRFlowNet), a facial optical flow model with tailored regularization losses. These losses constrain flow predictions using masks and gradients computed via difference or Sobel operator. This effectively suppresses high-frequency noise and large-scale errors in texture-less or repetitive-pattern regions, enabling SRFlowNet to be the first model explicitly capable of capturing high-resolution skin motion guided by Gaussian splatting rasterization. Experiments show that training with the SRFlow dataset improves facial optical flow estimation across various optical flow models, reducing end-point error (EPE) by up to 42% (from 0.5081 to 0.2953). Furthermore, when coupled with the SRFlow dataset, SRFlowNet achieves up to a 48% improvement in F1-score (from 0.4733 to 0.6947) on a composite of three micro-expression datasets. These results demonstrate the value of advancing both facial optical flow estimation and micro-expression recognition.

</details>


### [37] [Learning Domain Agnostic Latent Embeddings of 3D Faces for Zero-shot Animal Expression Transfer](https://arxiv.org/abs/2601.06484)
*Yue Wang,Lawrence Amadi,Xiang Gao,Yazheng Chen,Yuanpeng Liu,Ning Lu,Xianfeng Gu*

Main category: cs.CV

TL;DR: 本文提出了一种零样本人脸表情迁移方法，可将人类表情准确迁移到动物的3D面部网格上。


<details>
  <summary>Details</summary>
Motivation: 动物的面部表情数据稀缺，但模拟动物生动表情对于动画、虚拟现实等领域具有重要价值，因此需探索无需动物表情数据的跨物种表情迁移方法。

Method: 方法结合了HKS/WKS几何描述符与可分离身份和表情的无网格嵌入空间。身份空间捕捉不同物种间通用的脸部结构，表情空间编码可在物种间泛化的变形模式。仅用人类表情对数据训练，通过解耦-重耦方式实现了零样本跨身份迁移；使用Jacobian损失、顶点位置损失与Laplacian损失确保几何稳定性。

Result: 实验证明，该方法可有效实现人类到动物的3D面部表情迁移，在几何上逼真并显著缩小了人类与动物面部结构的差异。

Conclusion: 所提方法无需动物表情数据即可达成可信的跨物种表情迁移，对动画等应用具有实用价值，并为后续相关研究提供了新的思路。

Abstract: We present a zero-shot framework for transferring human facial expressions to 3D animal face meshes. Our method combines intrinsic geometric descriptors (HKS/WKS) with a mesh-agnostic latent embedding that disentangles facial identity and expression. The ID latent space captures species-independent facial structure, while the expression latent space encodes deformation patterns that generalize across humans and animals. Trained only with human expression pairs, the model learns the embeddings, decoupling, and recoupling of cross-identity expressions, enabling expression transfer without requiring animal expression data. To enforce geometric consistency, we employ Jacobian loss together with vertex-position and Laplacian losses. Experiments show that our approach achieves plausible cross-species expression transfer, effectively narrowing the geometric gap between human and animal facial shapes.

</details>


### [38] [3D CoCa v2: Contrastive Learners with Test-Time Search for Generalizable Spatial Intelligence](https://arxiv.org/abs/2601.06496)
*Hao Tang,Ting Huang,Zeyu Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一种新的3D场景描述模型3D CoCa v2，具有较强的领域泛化能力，并显著提升3D场景自动生成文本描述任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的3D场景描述（captioning）方法在处理点云稀疏、不规则等特点时效果有限，尤其在不同环境（如室内外）下存在泛化能力不足，难以准确描述新颖场景。研究动机是提升3D场景自动描述的稳健性和泛化能力。

Method: 作者提出3D CoCa v2框架，结合对比式视觉-语言预训练（CLIP）、面向空间感知的3D场景编码器以及多模态解码器，联合优化对比和描述生成目标。在推理阶段，引入测试时搜索（TTS）机制，生成多样化描述并结合简要场景摘要进行奖励引导选择，无需外部检测器或手工特征。

Result: 在ScanRefer、Nr3D和TOD3Cap等数据集上新方法均明显优于前作（3D CoCa），如在ScanRefer和Nr3D上CIDEr@0.5IoU分别提升+1.50和+1.61，在TOD3Cap零样本OOD评测上提升+3.8。

Conclusion: 3D CoCa v2有助于提升3D场景描述模型在不同场景和分布下的泛化能力和表述准确性，不依赖外部检测器和手工提议，具有较强的实用潜力。

Abstract: Spatial intelligence refers to the ability to perceive, reason about, and describe objects and their relationships within three-dimensional environments, forming a foundation for embodied perception and scene understanding. 3D captioning aims to describe 3D scenes in natural language; however, it remains challenging due to the sparsity and irregularity of point clouds and, more critically, the weak grounding and limited out-of-distribution (OOD) generalization of existing captioners across drastically different environments, including indoor and outdoor 3D scenes. To address this challenge, we propose 3D CoCa v2, a generalizable 3D captioning framework that unifies contrastive vision-language learning with 3D caption generation and further improves robustness via test-time search (TTS) without updating the captioner parameters. 3D CoCa v2 builds on a frozen CLIP-based semantic prior, a spatially-aware 3D scene encoder for geometry, and a multimodal decoder jointly optimized with contrastive and captioning objectives, avoiding external detectors or handcrafted proposals. At inference, TTS produces diverse caption candidates and performs reward-guided selection using a compact scene summary. Experiments show improvements over 3D CoCa of +1.50 CIDEr@0.5IoU on ScanRefer and +1.61 CIDEr@0.5IoU on Nr3D, and +3.8 CIDEr@0.25 in zero-shot OOD evaluation on TOD3Cap. Code will be released at https://github.com/AIGeeksGroup/3DCoCav2.

</details>


### [39] [Bridging Robustness and Efficiency: Real-Time Low-Light Enhancement via Attention U-Net GAN](https://arxiv.org/abs/2601.06518)
*Yash Thesia,Meera Suthar*

Main category: cs.CV

TL;DR: 本文提出了一种结合Attention U-Net和GAN的低照度图像增强方法，在保持高感知质量的同时实现了接近实时的推理速度，并显著优于现有效率模型。


<details>
  <summary>Details</summary>
Motivation: 现有低照度图像增强方法中，扩散模型虽能生成高质量结果，但推理耗时较长；而CNN模型速度快但细节恢复能力差，二者存在实际应用的性能与效率权衡问题。

Method: 提出了一种混合Attention U-Net GAN架构，通过在轻量级U-Net骨干中集成注意力门控，并采用条件对抗训练，实现了无需扩散模型多步采样即可恢复高频细节。

Result: 在SID数据集上，所提方法在高效模型中取得了最优的LPIPS分数（0.112），相比主流高效基线（如SID、EnlightenGAN）有显著提升，且推理延迟仅为0.06秒，相较扩散方法快40倍。

Conclusion: 该方法在保持近实时速度的同时实现了生成模型级别的细节恢复，为低照度图像增强领域提供了兼具高质量与高效率的新方案，适合实际部署。

Abstract: Recent advancements in Low-Light Image Enhancement (LLIE) have focused heavily on Diffusion Probabilistic Models, which achieve high perceptual quality but suffer from significant computational latency (often exceeding 2-4 seconds per image). Conversely, traditional CNN-based baselines offer real-time inference but struggle with "over-smoothing," failing to recover fine structural details in extreme low-light conditions. This creates a practical gap in the literature: the lack of a model that provides generative-level texture recovery at edge-deployable speeds. In this paper, we address this trade-off by proposing a hybrid Attention U-Net GAN. We demonstrate that the heavy iterative sampling of diffusion models is not strictly necessary for texture recovery. Instead, by integrating Attention Gates into a lightweight U-Net backbone and training within a conditional adversarial framework, we can approximate the high-frequency fidelity of generative models in a single forward pass. Extensive experiments on the SID dataset show that our method achieves a best-in-class LPIPS score of 0.112 among efficient models, significantly outperforming efficient baselines (SID, EnlightenGAN) while maintaining an inference latency of 0.06s. This represents a 40x speedup over latent diffusion models, making our approach suitable for near real-time applications.

</details>


### [40] [BabyVision: Visual Reasoning Beyond Language](https://arxiv.org/abs/2601.06521)
*Liang Chen,Weichu Xie,Yiyan Liang,Hongfeng He,Hans Zhao,Zhibo Yang,Zhiqi Huang,Haoning Wu,Haoyu Lu,Y. charles,Yiping Bao,Yuantao Fan,Guopeng Li,Haiyang Shen,Xuanzhong Chen,Wendong Xu,Shuzheng Si,Zefan Cai,Wenhao Chai,Ziqi Huang,Fangfu Liu,Tianyu Liu,Baobao Chang,Xiaobo Hu,Kaiyuan Chen,Yixin Ren,Yang Liu,Yuan Gong,Kuan Li*

Main category: cs.CV

TL;DR: 本文发现当前主流多模态大模型（MLLMs）在基础视觉任务上表现很差，推出了一套新基准 BabyVision 来专门评测视觉能力，并提出了新评价方法，研究结果显示 MLLMs 远不如人类，尤其是儿童。


<details>
  <summary>Details</summary>
Motivation: 现有 MLLMs 虽然在语言和知识任务上表现优异，但实际视觉理解能力很弱，远不及人类甚至是幼儿，因此需要系统地检验和提升机器的核心视觉能力。

Method: 开发并发布了 BabyVision 基准，涵盖 22 个子类、四大主要类别共 388 个视觉任务项，这些任务避免依赖语言知识，以考察 MLLMs 的纯视觉能力。同时提出 BabyVision-Gen 及自动评测工具，用于生成式模型的视觉推理能力测试。

Result: 主流 MLLMs（如 Gemini3-Pro-Preview）在 BabyVision 的得分仅 49.7，远低于6岁儿童甚至与人类成人标准（94.1分）差距显著；人类评估和实测均证明其视觉理解基础薄弱。

Conclusion: 尽管多模态大模型在复杂知识型任务上已很强大，但在基础视觉能力方面与人类仍有巨大差距。BabyVision 为未来模型的视觉能力提升提供了重要参考和挑战。

Abstract: While humans develop core visual skills long before acquiring language, contemporary Multimodal LLMs (MLLMs) still rely heavily on linguistic priors to compensate for their fragile visual understanding. We uncovered a crucial fact: state-of-the-art MLLMs consistently fail on basic visual tasks that humans, even 3-year-olds, can solve effortlessly. To systematically investigate this gap, we introduce BabyVision, a benchmark designed to assess core visual abilities independent of linguistic knowledge for MLLMs. BabyVision spans a wide range of tasks, with 388 items divided into 22 subclasses across four key categories. Empirical results and human evaluation reveal that leading MLLMs perform significantly below human baselines. Gemini3-Pro-Preview scores 49.7, lagging behind 6-year-old humans and falling well behind the average adult score of 94.1. These results show despite excelling in knowledge-heavy evaluations, current MLLMs still lack fundamental visual primitives. Progress in BabyVision represents a step toward human-level visual perception and reasoning capabilities. We also explore solving visual reasoning with generation models by proposing BabyVision-Gen and automatic evaluation toolkit. Our code and benchmark data are released at https://github.com/UniPat-AI/BabyVision for reproduction.

</details>


### [41] [SpatialNav: Leveraging Spatial Scene Graphs for Zero-Shot Vision-and-Language Navigation](https://arxiv.org/abs/2601.06806)
*Jiwen Zhang,Zejun Li,Siyuan Wang,Xiangyu Shi,Zhongyu Wei,Qi Wu*

Main category: cs.CV

TL;DR: 提出了一种新的零样本视觉-语言导航（VLN）方法SpatialNav，通过先探索环境并构建空间场景图（SSG），大幅提升零样本导航效率，缩小与有监督学习方法的性能差距。


<details>
  <summary>Details</summary>
Motivation: 零样本VLN缺乏通过大量训练数据习得空间知识的过程，导航时仅依赖局部观测，导致探索效率低，性能远落后于学习型方法。作者希望解决这一低效和性能差距的问题。

Method: 提出允许零样本VLN代理在任务前完整探索环境，并基于探索结果构建空间场景图（SSG），显式捕捉全局空间关系和语义信息。SpatialNav结合了以代理为中心的空间地图、与指南针对齐的视觉表征和远程目标定位策略，提升导航效率。

Result: 在离散和连续环境中的全面实验表明，SpatialNav明显优于现有零样本代理，并显著缩小与最先进学习方法的性能差距。

Conclusion: 全局空间表示（如SSG）对提升零样本VLN泛化性和效率至关重要。

Abstract: Although learning-based vision-and-language navigation (VLN) agents can learn spatial knowledge implicitly from large-scale training data, zero-shot VLN agents lack this process, relying primarily on local observations for navigation, which leads to inefficient exploration and a significant performance gap. To deal with the problem, we consider a zero-shot VLN setting that agents are allowed to fully explore the environment before task execution. Then, we construct the Spatial Scene Graph (SSG) to explicitly capture global spatial structure and semantics in the explored environment. Based on the SSG, we introduce SpatialNav, a zero-shot VLN agent that integrates an agent-centric spatial map, a compass-aligned visual representation, and a remote object localization strategy for efficient navigation. Comprehensive experiments in both discrete and continuous environments demonstrate that SpatialNav significantly outperforms existing zero-shot agents and clearly narrows the gap with state-of-the-art learning-based methods. Such results highlight the importance of global spatial representations for generalizable navigation.

</details>


### [42] [Toward Generalizable Deblurring: Leveraging Massive Blur Priors with Linear Attention for Real-World Scenarios](https://arxiv.org/abs/2601.06525)
*Yuanting Gao,Shuo Cao,Xiaohui Li,Yuandong Pu,Yihao Liu,Kai Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种通用性更强的图像去模糊方法GLOWDeblur，通过引入模糊模式预训练（BPP）和运动及语义引导（MoSeG），显著提升了在不同数据集和真实场景下的去模糊效果。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习图像去模糊方法在真实世界泛化性能较弱，主要由于训练数据集覆盖有限、算法过度关注局部细节忽视结构与语义一致性。本研究旨在解决现有方法难以在多样复杂模糊条件下推广适用的问题。

Method: （1）提出模糊模式预训练（BPP）方法，先在模拟数据集中习得模糊先验，再在真实数据集联合微调迁移。（2）设计运动与语义引导（MoSeG）以增强模型在严重退化下的模糊先验获取能力。（3）整合为轻量级的GLOWDeblur模型，结合卷积预重建、领域对齐模块与轻量扩散骨干网络。

Result: 在六个主流基准和两个真实世界数据集上进行大量实验验证。结果显示所提方法能有效提升模型在不同模糊类型和真实模糊场景下的泛化性和实用性。

Conclusion: 本工作指出模糊模式多样性对去模糊模型泛化至关重要，并通过提出的BPP、MoSeG及GLOWDeblur实现了强鲁棒性和高效能。研究拓宽了去模糊领域的现实落地场景。

Abstract: Image deblurring has advanced rapidly with deep learning, yet most methods exhibit poor generalization beyond their training datasets, with performance dropping significantly in real-world scenarios. Our analysis shows this limitation stems from two factors: datasets face an inherent trade-off between realism and coverage of diverse blur patterns, and algorithmic designs remain restrictive, as pixel-wise losses drive models toward local detail recovery while overlooking structural and semantic consistency, whereas diffusion-based approaches, though perceptually strong, still fail to generalize when trained on narrow datasets with simplistic strategies. Through systematic investigation, we identify blur pattern diversity as the decisive factor for robust generalization and propose Blur Pattern Pretraining (BPP), which acquires blur priors from simulation datasets and transfers them through joint fine-tuning on real data. We further introduce Motion and Semantic Guidance (MoSeG) to strengthen blur priors under severe degradation, and integrate it into GLOWDeblur, a Generalizable reaL-wOrld lightWeight Deblur model that combines convolution-based pre-reconstruction & domain alignment module with a lightweight diffusion backbone. Extensive experiments on six widely-used benchmarks and two real-world datasets validate our approach, confirming the importance of blur priors for robust generalization and demonstrating that the lightweight design of GLOWDeblur ensures practicality in real-world applications. The project page is available at https://vegdog007.github.io/GLOWDeblur_Website/.

</details>


### [43] [OSCAR: Open-Set CAD Retrieval from a Language Prompt and a Single Image](https://arxiv.org/abs/2601.07333)
*Tessa Pulli,Jean-Baptiste Weibel,Peter Hönig,Matthias Hirschmanner,Markus Vincze,Andreas Holzinger*

Main category: cs.CV

TL;DR: 该论文提出OSCAR方法，实现了无需训练即可通过文本和单图像检索3D模型，并在多个基准上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前6D姿态估计算法在场景理解和机器人等应用中非常重要，但传统方法要求针对每个对象专门训练或依赖于CAD模型，难以应对频繁变化和多样化的物体集合。为解决实用部署中的CAD模型难获和对象集不断更新的问题，作者提出了无需训练即可跨域检索3D模型的方法。

Method: OSCAR为训练免疫方法。首先，将未标注3D数据库中的所有对象模型进行多视角渲染，并利用图像描述模型生成文本描述。推理时，采用GroundedSAM检测图像中目标，计算ROI和模型描述的多模态嵌入。检索分为两步：1) 利用CLIP的文本过滤筛选候选模型；2) 用DINOv2的图像特征进一步精细筛选出最相似的模型。

Result: 在跨域3D模型检索基准MI3DOR上，OSCAR超过了当前所有最优方法。在YCB-V数据集上，OSCAR的对象检索平均准确率达到90.48%，并可用于6D姿态估计，获得比基于重建方法更好的效果。

Conclusion: OSCAR能够自动化为6D姿态估计提供最合适的对象模型，在无需专门训练和实例CAD模型的场景下表现优异，显著提升了泛化能力和实用性。

Abstract: 6D object pose estimation plays a crucial role in scene understanding for applications such as robotics and augmented reality. To support the needs of ever-changing object sets in such context, modern zero-shot object pose estimators were developed to not require object-specific training but only rely on CAD models. Such models are hard to obtain once deployed, and a continuously changing and growing set of objects makes it harder to reliably identify the instance model of interest. To address this challenge, we introduce an Open-Set CAD Retrieval from a Language Prompt and a Single Image (OSCAR), a novel training-free method that retrieves a matching object model from an unlabeled 3D object database. During onboarding, OSCAR generates multi-view renderings of database models and annotates them with descriptive captions using an image captioning model. At inference, GroundedSAM detects the queried object in the input image, and multi-modal embeddings are computed for both the Region-of-Interest and the database captions. OSCAR employs a two-stage retrieval: text-based filtering using CLIP identifies candidate models, followed by image-based refinement using DINOv2 to select the most visually similar object. In our experiments we demonstrate that OSCAR outperforms all state-of-the-art methods on the cross-domain 3D model retrieval benchmark MI3DOR. Furthermore, we demonstrate OSCAR's direct applicability in automating object model sourcing for 6D object pose estimation. We propose using the most similar object model for pose estimation if the exact instance is not available and show that OSCAR achieves an average precision of 90.48\% during object retrieval on the YCB-V object dataset. Moreover, we demonstrate that the most similar object model can be utilized for pose estimation using Megapose achieving better results than a reconstruction-based approach.

</details>


### [44] [Towards Egocentric 3D Hand Pose Estimation in Unseen Domains](https://arxiv.org/abs/2601.06537)
*Wiktor Mucha,Michael Wray,Martin Kampel*

Main category: cs.CV

TL;DR: V-HPOT是一种针对3D手势姿态估计跨领域泛化能力提升的新方法，通过归一化处理实现对相机内参的无关性，并加入自监督优化，大幅提升了不同数据集下的表现。


<details>
  <summary>Details</summary>
Motivation: 现有3D手势姿态估计算法在单一领域表现良好，但容易过拟合具体相机参数，泛化到新领域及新环境时性能急剧下降，因此亟需跨域鲁棒性更强的方法。

Method: V-HPOT在虚拟相机空间下估算关键点的z坐标，并用焦距和图像大小进行归一化，消除相机内参影响；同时在推理阶段引入自监督优化，通过3D一致性损失引导模型适应目标领域，无需实际标签。

Result: 在跨领域测评中，V-HPOT在H2O数据集上将平均姿态误差减少了71%，在AssemblyHands数据集减少了41%；在所有数据集上都超过了现有的单阶段方法，并在数据量远少于二阶段方法时取得了可竞争表现。

Conclusion: V-HPOT结合归一化相机空间表示与自监督优化，有效提升了3D手势姿态估计的跨领域泛化能力，为实际应用向不同设备和环境迁移铺平了道路。

Abstract: We present V-HPOT, a novel approach for improving the cross-domain performance of 3D hand pose estimation from egocentric images across diverse, unseen domains. State-of-the-art methods demonstrate strong performance when trained and tested within the same domain. However, they struggle to generalise to new environments due to limited training data and depth perception -- overfitting to specific camera intrinsics. Our method addresses this by estimating keypoint z-coordinates in a virtual camera space, normalised by focal length and image size, enabling camera-agnostic depth prediction. We further leverage this invariance to camera intrinsics to propose a self-supervised test-time optimisation strategy that refines the model's depth perception during inference. This is achieved by applying a 3D consistency loss between predicted and in-space scale-transformed hand poses, allowing the model to adapt to target domain characteristics without requiring ground truth annotations. V-HPOT significantly improves 3D hand pose estimation performance in cross-domain scenarios, achieving a 71% reduction in mean pose error on the H2O dataset and a 41% reduction on the AssemblyHands dataset. Compared to state-of-the-art methods, V-HPOT outperforms all single-stage approaches across all datasets and competes closely with two-stage methods, despite needing approximately x3.5 to x14 less data.

</details>


### [45] [FMAC: a Fair Fiducial Marker Accuracy Comparison Software](https://arxiv.org/abs/2601.07723)
*Guillaume J. Laurent,Patrick Sandoz*

Main category: cs.CV

TL;DR: 本文提出了一种基于高保真合成图像进行定位精度公平比较的方法，并公开相关代码。


<details>
  <summary>Details</summary>
Motivation: 现有基于标记物的位姿估计算法在不同条件下表现不一，且缺乏高保真、可控的测试环境来公平对比其精度。因此需要开发可直接使用相机标准参数，能真实反映各种影响因素的图像生成和评估方法。

Method: 利用物理基础的光线追踪算法生成大批量高保真合成图像，全面覆盖六自由度空间，并使用低差异采样检查各自由度与定位误差之间的相关性。渲染过程包括成像畸变、离焦和衍射模糊，同时对锐利边缘采用亚像素采样，以提高图像保真度。之后设计并验证了用于位姿准确性对比的评估方法。

Result: 通过实验，评估了多种常用标记物在位姿估计中的优缺点，实验验证了渲染算法和评估方法的有效性。全部代码已开源。

Conclusion: 该方法实现了位姿估计算法在可控条件下的公平比较，为算法研究和优化提供了高效工具。开源代码也为社区进一步研究打下了基础。

Abstract: This paper presents a method for carrying fair comparisons of the accuracy of pose estimation using fiducial markers. These comparisons rely on large sets of high-fidelity synthetic images enabling deep exploration of the 6 degrees of freedom. A low-discrepancy sampling of the space allows to check the correlations between each degree of freedom and the pose errors by plotting the 36 pairs of combinations. The images are rendered using a physically based ray tracing code that has been specifically developed to use the standard calibration coefficients of any camera directly. The software reproduces image distortions, defocus and diffraction blur. Furthermore, sub-pixel sampling is applied to sharp edges to enhance the fidelity of the rendered image. After introducing the rendering algorithm and its experimental validation, the paper proposes a method for evaluating the pose accuracy. This method is applied to well-known markers, revealing their strengths and weaknesses for pose estimation. The code is open source and available on GitHub.

</details>


### [46] [LLMTrack: Semantic Multi-Object Tracking with Multi-modal Large Language Models](https://arxiv.org/abs/2601.06550)
*Pan Liao,Feng Yang,Di Wu,Jinwen Yu,Yuhua Zhu,Wenhui Zhao*

Main category: cs.CV

TL;DR: 该论文提出了LLMTrack，一个结合大模型和视觉追踪的新型多目标跟踪（MOT）框架，不仅能够精准定位和关联，还能理解目标行为的语义，实现几何感知与认知推理的结合。


<details>
  <summary>Details</summary>
Motivation: 传统多目标跟踪只关注目标的位置（在哪）和身份（是谁），但忽视了对目标行为的语义理解（是什么，为什么），难以支持更高阶的智能感知。

Method: 提出一种仿生设计思想，将高精度定位模块和深层语义理解模块解耦：用Grounding DINO负责视觉检测，用LLaVA-OneVision多模态大模型进行高阶推理。设计时空融合模块，聚合实例与全局视频上下文特征；通过视觉对齐、时间微调与语义注入三阶段训练策略（LoRA技术），提升追踪语义能力。

Result: 在BenSMOT基准集上的实验结果显示，LLMTrack在实例描述、交互识别和视频摘要等方面均大幅优于现有方法，并保持了强健的追踪性能。

Conclusion: LLMTrack有效打通了视觉跟踪和认知语义推理的瓶颈，为多目标跟踪领域引入了深层语义理解能力，显著提升了跟踪系统的智能化水平。

Abstract: Traditional Multi-Object Tracking (MOT) systems have achieved remarkable precision in localization and association, effectively answering \textit{where} and \textit{who}. However, they often function as autistic observers, capable of tracing geometric paths but blind to the semantic \textit{what} and \textit{why} behind object behaviors. To bridge the gap between geometric perception and cognitive reasoning, we propose \textbf{LLMTrack}, a novel end-to-end framework for Semantic Multi-Object Tracking (SMOT). We adopt a bionic design philosophy that decouples strong localization from deep understanding, utilizing Grounding DINO as the eyes and the LLaVA-OneVision multimodal large model as the brain. We introduce a Spatio-Temporal Fusion Module that aggregates instance-level interaction features and video-level contexts, enabling the Large Language Model (LLM) to comprehend complex trajectories. Furthermore, we design a progressive three-stage training strategy, Visual Alignment, Temporal Fine-tuning, and Semantic Injection via LoRA to efficiently adapt the massive model to the tracking domain. Extensive experiments on the BenSMOT benchmark demonstrate that LLMTrack achieves state-of-the-art performance, significantly outperforming existing methods in instance description, interaction recognition, and video summarization while maintaining robust tracking stability.

</details>


### [47] [ArrowGEV: Grounding Events in Video via Learning the Arrow of Time](https://arxiv.org/abs/2601.06559)
*Fangxu Yu,Ziyao Lu,Liqiang Niu,Fandong Meng,Jie Zhou*

Main category: cs.CV

TL;DR: 本文提出了ArrowGEV框架，通过显式建模事件的时间方向性，提升视觉-语言模型在视频事件定位与理解中的表现。它引入奖励机制区分时间敏感与不敏感事件，在区分正反播放视频及一致性定位上实现提升。实验表明该方法显著提升定位准确率及模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 目前基于视觉-语言模型的视频事件定位方法，往往只训练模型将事件与正向视频时间轴关联，忽略了事件本身的时间结构与方向性，这限制了模型的健壮性与泛化能力。为提升模型对视频时序和方向性的感知能力，作者受到物理学“时间之箭”概念的启发，提出了新的框架。

Method: 本文提出了ArrowGEV框架，利用强化学习方法对视觉-语言模型进行训练。该框架将事件分为时间敏感与不敏感两类，并针对性设定奖励机制。对于时间敏感事件，训练模型区分正向与反向视频；对于时间不敏感事件，则要求模型在任意方向下都能正确定位事件。

Result: 实验结果显示，ArrowGEV能够显著提升事件的定位准确率，强化模型对事件时间方向性的识别能力，并提升了视频理解与推理的整体性能。

Conclusion: ArrowGEV有助于视觉-语言模型学习和理解视频中事件的时间结构与方向性，提升了事件定位的准确性和模型的泛化能力，为视频分析应用提供了更坚实的技术基础。

Abstract: Grounding events in videos serves as a fundamental capability in video analysis. While Vision-Language Models (VLMs) are increasingly employed for this task, existing approaches predominantly train models to associate events with timestamps in the forward video only. This paradigm hinders VLMs from capturing the inherent temporal structure and directionality of events, thereby limiting robustness and generalization. To address this limitation, inspired by the arrow of time in physics, which characterizes the intrinsic directionality of temporal processes, we propose ArrowGEV, a reinforcement learning framework that explicitly models temporal directionality in events to improve both event grounding and temporal directionality understanding in VLMs. Specifically, we categorize events into time-sensitive (e.g., putting down a bag) and time-insensitive (e.g., holding a towel in the left hand). The former denote events whose reversal substantially alters their meaning, while the latter remain semantically unchanged under reversal. For time-sensitive events, ArrowGEV introduces a reward that encourages VLMs to discriminate between forward and backward videos, whereas for time-insensitive events, it enforces consistent grounding across both directions. Extensive experiments demonstrate that ArrowGEV not only improves grounding precision and temporal directionality recognition, but also enhances general video understanding and reasoning ability.

</details>


### [48] [QCaption: Video Captioning and Q&A through Fusion of Large Multimodal Models](https://arxiv.org/abs/2601.06566)
*Jiale Wang,Gee Wah Ng,Lee Onn Mak,Randall Cher,Ng Ding Hei Ryan,Davis Wang*

Main category: cs.CV

TL;DR: 本文提出了QCaption，这是一个结合关键帧提取、多模态大模型（LMM）及大语言模型（LLM）的创新视频描述和问答系统，相较现有方法，在视频描述和问答任务上均显著提升效果。


<details>
  <summary>Details</summary>
Motivation: 当前视频分析中，视频字幕生成和视频问答仍面临准确率与灵活性不足的问题，同时对数据融合与本地化部署的需求也日益增强。为此，作者希望设计一个集成多模型、支持本地运行、且性能优异的新系统。

Method: QCaption系统由三部分组成：首先提取视频关键帧；其次用LMM进行图文分析；最后用LLM进行文本分析，并完成视频描述和问答任务。同时，加入消融实验验证了LLM在模型融合中的作用，对比了多种视频描述方案。

Result: QCaption在实验中，视频字幕自动生成和视频问答任务的性能分别提升了44.2%和48.9%。此外，与其他方法的基准对比也显示QCaption具有更优表现。

Conclusion: 多模型融合策略能显著提升视频分析性能，QCaption为本地化和自主可控的视频处理提供了有效方案，展示了其在视频分析领域的潜力。

Abstract: This paper introduces QCaption, a novel video captioning and Q&A pipeline that enhances video analytics by fusing three models: key frame extraction, a Large Multimodal Model (LMM) for image-text analysis, and a Large Language Model (LLM) for text analysis. This approach enables integrated analysis of text, images, and video, achieving performance improvements over existing video captioning and Q&A models; all while remaining fully self-contained, adept for on-premises deployment. Experimental results using QCaption demonstrated up to 44.2% and 48.9% improvements in video captioning and Q&A tasks, respectively. Ablation studies were also performed to assess the role of LLM on the fusion on the results. Moreover, the paper proposes and evaluates additional video captioning approaches, benchmarking them against QCaption and existing methodologies. QCaption demonstrate the potential of adopting a model fusion approach in advancing video analytics.

</details>


### [49] [APEX: Learning Adaptive Priorities for Multi-Objective Alignment in Vision-Language Generation](https://arxiv.org/abs/2601.06574)
*Dongliang Chen,Xinlin Zhuang,Junjie Xu,Luojian Xie,Zehui Wang,Jiaxi Zhuang,Haolin Yang,Liang Dou,Xiao He,Xingjiao Wu,Ying Qian*

Main category: cs.CV

TL;DR: 本文提出APEX方法，用于文本到图像生成任务中的多目标对齐，通过自适应归一化和优先级动态调整，有效缓解了高方差目标主导训练信号和目标梯度冲突的问题，实现了各异质性目标之间更平衡的优化结果。


<details>
  <summary>Details</summary>
Motivation: 多目标对齐现有方法采用固定权重的线性归一化，难以同时优化变异性高、响应性强（如OCR）与感知类目标，容易导致模型只关注部分目标，训练不平衡。

Method: 作者分析了多目标训练不稳定的两大机制（方差劫持和梯度冲突），提出了APEX方法：1）双阶段自适应归一化处理异质性奖励信号；2）P^3自适应优先级，根据学习潜力、冲突惩罚和进度需求动态调整训练目标优先级。

Result: 在Stable Diffusion 3.5模型上，APEX在四个异质性目标上取得了更佳的帕累托优化结果：PickScore提升1.31分、DeQA提升0.35分、美学分提升0.53分，并保持OCR准确率，表现出多目标优化的稳定性和均衡性。

Conclusion: APEX方法有效解决了多目标文本到图像生成中异质性奖励导致的优化失衡问题，实现了目标间更平衡、鲁棒的优化结果，展现了较强的实用价值。

Abstract: Multi-objective alignment for text-to-image generation is commonly implemented via static linear scalarization, but fixed weights often fail under heterogeneous rewards, leading to optimization imbalance where models overfit high-variance, high-responsiveness objectives (e.g., OCR) while under-optimizing perceptual goals. We identify two mechanistic causes: variance hijacking, where reward dispersion induces implicit reweighting that dominates the normalized training signal, and gradient conflicts, where competing objectives produce opposing update directions and trigger seesaw-like oscillations. We propose APEX (Adaptive Priority-based Efficient X-objective Alignment), which stabilizes heterogeneous rewards with Dual-Stage Adaptive Normalization and dynamically schedules objectives via P^3 Adaptive Priorities that combine learning potential, conflict penalty, and progress need. On Stable Diffusion 3.5, APEX achieves improved Pareto trade-offs across four heterogeneous objectives, with balanced gains of +1.31 PickScore, +0.35 DeQA, and +0.53 Aesthetics while maintaining competitive OCR accuracy, mitigating the instability of multi-objective alignment.

</details>


### [50] [Sissi: Zero-shot Style-guided Image Synthesis via Semantic-style Integration](https://arxiv.org/abs/2601.06605)
*Yingying Deng,Xiangyu He,Fan Tang,Weiming Dong,Xucheng Yin*

Main category: cs.CV

TL;DR: 提出了一种无需训练的新方法，将风格化看作上下文学习任务，通过预训练的ReFlow修复模型，实现文本引导下的高保真风格迁移。


<details>
  <summary>Details</summary>
Motivation: 现有图像风格迁移方法依赖特定任务重新训练或复杂的反演，导致内容失真、风格不准确及语义与风格平衡受损。作者期望找到一种更便捷且效果更佳的替代方案。

Method: 将参考风格图与带掩码的目标图像拼接输入，通过多模态注意力融合利用预训练ReFlow修复模型，实现风格与内容的无缝结合。同时提出动态语义-风格集成（DSSI）机制，自适应地调整文本与风格特征的注意权重，解决指导冲突并提升输出一致性。

Result: 实验证明，该方法可实现高保真风格迁移，在语义与风格平衡，以及视觉质量上优于复杂且易产生伪影的以往方法。

Conclusion: 本文方法无需额外训练，结构简单、效果优异，为高质量风格迁移任务提供了更实用的技术选择。

Abstract: Text-guided image generation has advanced rapidly with large-scale diffusion models, yet achieving precise stylization with visual exemplars remains difficult. Existing approaches often depend on task-specific retraining or expensive inversion procedures, which can compromise content integrity, reduce style fidelity, and lead to an unsatisfactory trade-off between semantic prompt adherence and style alignment. In this work, we introduce a training-free framework that reformulates style-guided synthesis as an in-context learning task. Guided by textual semantic prompts, our method concatenates a reference style image with a masked target image, leveraging a pretrained ReFlow-based inpainting model to seamlessly integrate semantic content with the desired style through multimodal attention fusion. We further analyze the imbalance and noise sensitivity inherent in multimodal attention fusion and propose a Dynamic Semantic-Style Integration (DSSI) mechanism that reweights attention between textual semantic and style visual tokens, effectively resolving guidance conflicts and enhancing output coherence. Experiments show that our approach achieves high-fidelity stylization with superior semantic-style balance and visual quality, offering a simple yet powerful alternative to complex, artifact-prone prior methods.

</details>


### [51] [Boosting Overlapping Organoid Instance Segmentation Using Pseudo-Label Unmixing and Synthesis-Assisted Learning](https://arxiv.org/abs/2601.06642)
*Gui Huang,Kangyuan Zheng,Xuan Cai,Jiaqi Wang,Jianjia Zhang,Kaida Ning,Wenbo Wei,Yujuan Zhu,Jiong Zhang,Mengting Liu*

Main category: cs.CV

TL;DR: 该论文提出了一种针对类器官实例分割的高效半监督学习方法，通过结合伪标签解混（PLU）和基于轮廓的合成技术，显著提升了在重叠区域的分割准确性，仅用少量标注数据就能达到媲美全监督的方法效果。


<details>
  <summary>Details</summary>
Motivation: 类器官作为体外人类组织模型，在精准医疗和药物筛选等领域具有重要价值。有效的类器官实例分割是分析其行为的基础，但受限于标注数据稀缺和显微图像中普遍存在的类器官重叠。传统半监督学习方法容易受重叠伪标签噪声影响，导致分割效果不佳。

Method: 作者首次将Synthesis-assisted SSL（SA-SSL）方法应用于类器官实例分割，发现其在处理重叠领域时存在表现不佳的问题。为此，提出伪标签解混（PLU），可识别重叠区的伪标签错误并通过实例分解进行重建；并使用基于轮廓的图像合成方法高效生成重叠类器官的合成图像。同时，在图像合成前对伪标签进行实例级增强，以提升合成数据的多样性和训练效果，并通过消融实验验证各组成部分的贡献。

Result: 在两个类器官实例分割数据集上的大量实验表明，该方法在仅使用10%标注数据情况下即可达到全监督方法的分割性能，并取得了当前最优结果。各模块（PLU、轮廓合成、增强训练）的有效性均通过消融实验得到验证。

Conclusion: 本文提出的PLU与基于轮廓的合成相结合的半监督实例分割框架，显著缓解了重叠区域的分割难题，提升了标签利用效率，为高通量、低成本的类器官研究与精准医疗应用提供了强有力的技术支持。

Abstract: Organoids, sophisticated in vitro models of human tissues, are crucial for medical research due to their ability to simulate organ functions and assess drug responses accurately. Accurate organoid instance segmentation is critical for quantifying their dynamic behaviors, yet remains profoundly limited by high-quality annotated datasets and pervasive overlap in microscopy imaging. While semi-supervised learning (SSL) offers a solution to alleviate reliance on scarce labeled data, conventional SSL frameworks suffer from biases induced by noisy pseudo-labels, particularly in overlapping regions. Synthesis-assisted SSL (SA-SSL) has been proposed for mitigating training biases in semi-supervised semantic segmentation. We present the first adaptation of SA-SSL to organoid instance segmentation and reveal that SA-SSL struggles to disentangle intertwined organoids, often misrepresenting overlapping instances as a single entity. To overcome this, we propose Pseudo-Label Unmixing (PLU), which identifies erroneous pseudo-labels for overlapping instances and then regenerates organoid labels through instance decomposition. For image synthesis, we apply a contour-based approach to synthesize organoid instances efficiently, particularly for overlapping cases. Instance-level augmentations (IA) on pseudo-labels before image synthesis further enhances the effect of synthetic data (SD). Rigorous experiments on two organoid datasets demonstrate our method's effectiveness, achieving performance comparable to fully supervised models using only 10% labeled data, and state-of-the-art results. Ablation studies validate the contributions of PLU, contour-based synthesis, and augmentation-aware training. By addressing overlap at both pseudo-label and synthesis levels, our work advances scalable, label-efficient organoid analysis, unlocking new potential for high-throughput applications in precision medicine.

</details>


### [52] [eSkiTB: A Synthetic Event-based Dataset for Tracking Skiers](https://arxiv.org/abs/2601.06647)
*Krishna Vinod,Joseph Raj Vishal,Kaustav Chanda,Prithvi Jai Ramesh,Yezhou Yang,Bharatesh Chakravarthi*

Main category: cs.CV

TL;DR: 本文提出了一个基于事件相机的合成滑雪跟踪数据集eSkiTB，并通过对比实验证明事件相机在拥挤和干扰环境下能更好地跟踪滑雪运动员。


<details>
  <summary>Details</summary>
Motivation: 在传统RGB视频中，滑雪运动员由于高速运动、画面模糊、静态遮挡和杂乱背景等问题，难以准确跟踪。事件相机虽然具备天然抗干扰能力，但此前缺少冬季运动场景的标准化数据集和评测基准。

Method: 作者提出eSkiTB数据集，通过直接将SkiTB视频数据转换为事件数据（无神经网络插值），实现了RGB与事件数据同等信息量对比。同时对比了事件相机的SDTrack（spiking transformer）方法与RGB相机的STARK（transformer）方法在滑雪跟踪上的性能。

Result: 在存在严重广播干扰和静态覆盖物的场景下，事件相机跟踪法IoU达0.685，比RGB提升20个百分点。全数据集平均IoU为0.711，表明事件相机在视觉复杂环境下表现稳定。

Conclusion: eSkiTB填补了冬季运动领域事件相机跟踪基准的空白，验证了事件相机对滑雪跟踪的巨大潜力，提供了新工具和数据助力相关研究推进。

Abstract: Tracking skiers in RGB broadcast footage is challenging due to motion blur, static overlays, and clutter that obscure the fast-moving athlete. Event cameras, with their asynchronous contrast sensing, offer natural robustness to such artifacts, yet a controlled benchmark for winter-sport tracking has been missing. We introduce event SkiTB (eSkiTB), a synthetic event-based ski tracking dataset generated from SkiTB using direct video-to-event conversion without neural interpolation, enabling an iso-informational comparison between RGB and event modalities. Benchmarking SDTrack (spiking transformer) against STARK (RGB transformer), we find that event-based tracking is substantially resilient to broadcast clutter in scenes dominated by static overlays, achieving 0.685 IoU, outperforming RGB by +20.0 points. Across the dataset, SDTrack attains a mean IoU of 0.711, demonstrating that temporal contrast is a reliable cue for tracking ballistic motion in visually congested environments. eSkiTB establishes the first controlled setting for event-based tracking in winter sports and highlights the promise of event cameras for ski tracking. The dataset and code will be released at https://github.com/eventbasedvision/eSkiTB.

</details>


### [53] [Quantification and Classification of Carbon Nanotubes in Electron Micrographs using Vision Foundation Models](https://arxiv.org/abs/2601.06673)
*Sanjay Pradeep,Chen Wang,Matthew M. Dahm,Jeff D. Eldredge,Candace S. J. Tsai*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉基础模型的自动化碳纳米管（CNT）形貌定量与分类方法，大大提升了效率和准确率，突破了以往主观且繁琐的手动分割流程。


<details>
  <summary>Details</summary>
Motivation: 现有电子显微镜下碳纳米管形貌分析高度依赖手工分割，流程慢且结果受人为主观影响严重，亟需高效、自动化且客观的定量和分类工具以推动纳米材料的暴露评估和毒理学研究。

Method: 作者首先结合Segment Anything Model（SAM）推出了互动式高精度分割工具，只需极少用户操作即可完成粒子分割。其次，提出利用分割掩膜指导DINOv2 Transformer，仅聚焦粒子区域特征提取，有效抑制背景噪声，并实现分类。

Result: 在1800张透射电镜图像集上，该方法以远少于传统方法的训练数据，实现了95.5%的四类CNT形貌分类准确率，显著优于基线模型。且可在单视野内识别并分类混合样本中不同形貌颗粒。

Conclusion: 该体系通过零样本分割与自监督特征学习的集成，实现了高通量、可复现的纳米材料分析，将原本费时耗力的工作转变为可扩展的数据驱动流程。

Abstract: Accurate characterization of carbon nanotube morphologies in electron microscopy images is vital for exposure assessment and toxicological studies, yet current workflows rely on slow, subjective manual segmentation. This work presents a unified framework leveraging vision foundation models to automate the quantification and classification of CNTs in electron microscopy images. First, we introduce an interactive quantification tool built on the Segment Anything Model (SAM) that segments particles with near-perfect accuracy using minimal user input. Second, we propose a novel classification pipeline that utilizes these segmentation masks to spatially constrain a DINOv2 vision transformer, extracting features exclusively from particle regions while suppressing background noise. Evaluated on a dataset of 1,800 TEM images, this architecture achieves 95.5% accuracy in distinguishing between four different CNT morphologies, significantly outperforming the current baseline despite using a fraction of the training data. Crucially, this instance-level processing allows the framework to resolve mixed samples, correctly classifying distinct particle types co-existing within a single field of view. These results demonstrate that integrating zero-shot segmentation with self-supervised feature learning enables high-throughput, reproducible nanomaterial analysis, transforming a labor-intensive bottleneck into a scalable, data-driven process.

</details>


### [54] [When Humans Judge Irises: Pupil Size Normalization as an Aid and Synthetic Irises as a Challenge](https://arxiv.org/abs/2601.06725)
*Mahsa Mitcheff,Adam Czajka*

Main category: cs.CV

TL;DR: 该论文研究了在虹膜识别中，人类在两种控制场景下进行虹膜验证的表现，探讨了瞳孔大小对判断准确率的影响，并首次系统分析了真实与合成虹膜图像对比时人类的识别能力。


<details>
  <summary>Details</summary>
Motivation: 虽然虹膜识别技术高度成熟且用于大规模生物识别，但特殊场景下（如法医或遭遇伪造攻击）依然需要人工确认结果。本研究动机在于探明：1）瞳孔大小变化对人工识别精度的影响；2）在真实和高质量合成虹膜混合场景下，人类专家的识别表现如何。

Method: 设计两组实验：一是对比瞳孔大小不同、经过线性/非线性对齐后的虹膜图像对人工验证表现的影响；二是通过真实-真实、合成-合成及真实-合成的虹膜配对，让受试者判断是否属于同一只眼。合成图像采用基于自编码器的身份保持型图像到图像生成模型。

Result: 1）瞳孔大小归一化（尤其用现代自编码器生成模型）显著提升了人类的判断准确率；2）对真实或合成成对图像，人类基本能区分同异眼；3）对真实与相应高质量合成虹膜的比对中，人类准确率下降，更难分辨是否属于同一只眼。

Conclusion: 1）在涉及人工判断的虹膜识别任务中，瞳孔大小对齐非常重要；2）尽管生成模型可生成高保真合成虹膜图像，但人类更倾向于认为‘同眼’的合成-真实配对是‘异眼’，安全隐患需关注。

Abstract: Iris recognition is a mature biometric technology offering remarkable precision and speed, and allowing for large-scale deployments to populations exceeding a billion enrolled users (e.g., AADHAAR in India). However, in forensic applications, a human expert may be needed to review and confirm a positive identification before an iris matching result can be presented as evidence in court, especially in cases where processed samples are degraded (e.g., in post-mortem cases) or where there is a need to judge whether the sample is authentic, rather than a result of a presentation attack.
  This paper presents a study that examines human performance in iris verification in two controlled scenarios: (a) under varying pupil sizes, with and without a linear/nonlinear alignment of the pupil size between compared images, and (b) when both genuine and impostor iris image pairs are synthetically generated. The results demonstrate that pupil size normalization carried out by a modern autoencoder-based identity-preserving image-to-image translation model significantly improves verification accuracy. Participants were also able to determine whether iris pairs corresponded to the same or different eyes when both images were either authentic or synthetic. However, accuracy declined when subjects were comparing authentic irises against high-quality, same-eye synthetic counterparts. These findings (a) demonstrate the importance of pupil-size alignment for iris matching tasks in which humans are involved, and (b) indicate that despite the high fidelity of modern generative models, same-eye synthetic iris images are more often judged by humans as different-eye images, compared to same-eye authentic image pairs.
  We offer data and human judgments along with this paper to allow full replicability of this study and future works.

</details>


### [55] [Benchmarking Egocentric Clinical Intent Understanding Capability for Medical Multimodal Large Language Models](https://arxiv.org/abs/2601.06750)
*Shaonan Liu,Guo Yu,Xiaoling Luo,Shiyi Zheng,Wenting Chen,Jie Liu,Linlin Shen*

Main category: cs.CV

TL;DR: 本文提出了MedGaze-Bench基准，以临床医师视线为认知游标，专注评估医疗多模态大模型对一线临床意图理解的能力，是首个此类基准。在手术、急诊与诊断任务中，该基准检验模型基于空间、时间与规范三维意图框架的表现，并设计了陷阱QA以考验模型的可靠性。实验表明现有模型在临床意图理解上存在明显短板。


<details>
  <summary>Details</summary>
Motivation: 医学场景中真实部署的多模态大模型（Med-MLLMs）需具备理解临床医师主观意图的能力，而现有评价基准无法有效测试这一关键能力，因此亟需一个能够评估这种“以自身为中心”的临床意图理解的专业基准。

Method: 作者提出MedGaze-Bench，首次利用“医师视线”（Cognitive Cursor）来评估模型对临床意图的理解，涵盖外科手术、急诊模拟和诊断解释三大应用场景。基准基于三维意图框架：空间意图、时间意图和规范意图，并引入陷阱QA机制，从多个维度系统性评价模型准确性和可靠性。

Result: 实验结果显示，现有医疗多模态大模型普遍依赖全局特征，导致在主观意图理解方面表现不佳，容易幻觉（fabricate）事实或盲从无效指令，暴露出在真实临床环境中部署的潜在风险。

Conclusion: MedGaze-Bench不仅揭示了现有模型在临床意图理解上的不足，还为未来高可靠性的医疗AI模型的开发和评估提供了新的标准和工具。

Abstract: Medical Multimodal Large Language Models (Med-MLLMs) require egocentric clinical intent understanding for real-world deployment, yet existing benchmarks fail to evaluate this critical capability. To address these challenges, we introduce MedGaze-Bench, the first benchmark leveraging clinician gaze as a Cognitive Cursor to assess intent understanding across surgery, emergency simulation, and diagnostic interpretation. Our benchmark addresses three fundamental challenges: visual homogeneity of anatomical structures, strict temporal-causal dependencies in clinical workflows, and implicit adherence to safety protocols. We propose a Three-Dimensional Clinical Intent Framework evaluating: (1) Spatial Intent: discriminating precise targets amid visual noise, (2) Temporal Intent: inferring causal rationale through retrospective and prospective reasoning, and (3) Standard Intent: verifying protocol compliance through safety checks. Beyond accuracy metrics, we introduce Trap QA mechanisms to stress-test clinical reliability by penalizing hallucinations and cognitive sycophancy. Experiments reveal current MLLMs struggle with egocentric intent due to over-reliance on global features, leading to fabricated observations and uncritical acceptance of invalid instructions.

</details>


### [56] [The Normalized Difference Layer: A Differentiable Spectral Index Formulation for Deep Learning](https://arxiv.org/abs/2601.06777)
*Ali Lotfi,Adam Carter,Mohammad Meysami,Thuan Ha,Kwabena Nketia,Steve Shirtliffe*

Main category: cs.CV

TL;DR: 本文提出了一种可微分的归一化差分层（Normalized Difference Layer），可集成到深度学习模型中，通过自适应学习输入波段的系数，使传统遥感中的归一化差分指数在端到端任务中表现更优。该方法同时保持了抗照明变化、输出有界等优势，并显著减少了参数量，提高了对噪声的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的归一化差分指数（Normalized Difference Indices, NDIs）广泛用于遥感领域，其对光照变化鲁棒、输出有界、与生物物理信号关联紧密，但通常作为固定预处理，无法针对具体学习任务进行优化，限制了其潜力。因此，本文旨在让这些指标的系数在神经网络中可学习，以提升适应性和效率。

Method: 作者提出了可微分的归一化差分层，集成到神经网络架构中，使波段系数通过反向传播以梯度下降的方式进行学习。该方法利用softplus重参数化保证系数为正且分母有界，支持端到端训练，并扩展到带符号输入和层叠结构。具体的前向与反向传播算法均有详细描述。

Result: 实验证明，该归一化差分层的模型在分类准确率上与标准多层感知机（MLP）相当，但参数量减少约75%。此外，在面对10%乘性噪声时，准确率仅下降0.17%，而基准MLP下降3.03%；学习到的系数模式在不同深度下也较为稳定。

Conclusion: 可微分的归一化差分层不仅保持了传统NDA的优点，还为其带来了可适应性和参数高效性，大幅提高了模型在实际遥感任务中的表现，特别是在噪声环境下的鲁棒性。

Abstract: Normalized difference indices have been a staple in remote sensing for decades. They stay reliable under lighting changes produce bounded values and connect well to biophysical signals. Even so, they are usually treated as a fixed pre processing step with coefficients set to one, which limits how well they can adapt to a specific learning task. In this study, we introduce the Normalized Difference Layer that is a differentiable neural network module. The proposed method keeps the classical idea but learns the band coefficients from data. We present a complete mathematical framework for integrating this layer into deep learning architectures that uses softplus reparameterization to ensure positive coefficients and bounded denominators. We describe forward and backward pass algorithms enabling end to end training through backpropagation. This approach preserves the key benefits of normalized differences, namely illumination invariance and outputs bounded to $[-1,1]$ while allowing gradient descent to discover task specific band weightings. We extend the method to work with signed inputs, so the layer can be stacked inside larger architectures. Experiments show that models using this layer reach similar classification accuracy to standard multilayer perceptrons while using about 75\% fewer parameters. They also handle multiplicative noise well, at 10\% noise accuracy drops only 0.17\% versus 3.03\% for baseline MLPs. The learned coefficient patterns stay consistent across different depths.

</details>


### [57] [CliffordNet: All You Need is Geometric Algebra](https://arxiv.org/abs/2601.06793)
*Zhongping Ji*

Main category: cs.CV

TL;DR: 本文提出了一种全新的视觉主干网络——Clifford Algebra Network（CliffordNet），仅基于几何代数而非传统的空间与通道混合模块，在参数量极小的情况下取得了媲美甚至超过现有主流模型的准确率。


<details>
  <summary>Details</summary>
Motivation: 当前主流计算机视觉架构（如CNN和Transformer）依赖空间混合+通道混合的模块堆叠，这种设计较为工程化与启发式。作者希望回归数学本原，利用几何代数建立统一且原理完备的特征交互机制，以避免人为切分和重复模块，提高表达能力和效率。

Method: 作者设计了基于Clifford几何积（包括内积和外积）的CliffordNet，实现了空间和通道信息的统一混合。模型以高效稀疏滚动机制实现，并具有严格O(N)线性复杂度。最终模型不再需要额外的Feed-Forward Network（FFN）模块。

Result: 在CIFAR-100数据集上，CliffordNet Nano版仅用1.4M参数实现了76.41%准确率，与参数量为11.2M的ResNet-18相当；Base版获得了78.05%，刷新了小模型SOTA。

Conclusion: 基于完备几何代数的局部交互机制有望实现对视觉任务的全局理解，且无需传统分离模块，表明“geometry is all you need”有望成为新范式。

Abstract: Modern computer vision architectures, from CNNs to Transformers, predominantly rely on the stacking of heuristic modules: spatial mixers (Attention/Conv) followed by channel mixers (FFNs). In this work, we challenge this paradigm by returning to mathematical first principles. We propose the \textbf{Clifford Algebra Network (CAN)}, also referred to as CliffordNet, a vision backbone grounded purely in Geometric Algebra. Instead of engineering separate modules for mixing and memory, we derive a unified interaction mechanism based on the \textbf{Clifford Geometric Product} ($uv = u \cdot v + u \wedge v$). This operation ensures algebraic completeness regarding the Geometric Product by simultaneously capturing feature coherence (via the generalized inner product) and structural variation (via the exterior wedge product).
  Implemented via an efficient sparse rolling mechanism with \textbf{strict linear complexity $\mathcal{O}(N)$}, our model reveals a surprising emergent property: the geometric interaction is so representationally dense that standard Feed-Forward Networks (FFNs) become redundant. Empirically, CliffordNet establishes a new Pareto frontier: our \textbf{Nano} variant achieves \textbf{76.41\%} accuracy on CIFAR-100 with only \textbf{1.4M} parameters, effectively matching the heavy-weight ResNet-18 (11.2M) with \textbf{$8\times$ fewer parameters}, while our \textbf{Base} variant sets a new SOTA for tiny models at \textbf{78.05\%}. Our results suggest that global understanding can emerge solely from rigorous, algebraically complete local interactions, potentially signaling a shift where \textit{geometry is all you need}. Code is available at https://github.com/ParaMind2025/CAN.

</details>


### [58] [SARA: Scene-Aware Reconstruction Accelerator](https://arxiv.org/abs/2601.06831)
*Jee Won Lee,Hansol Lim,Minhyeok Im,Dohyeon Lee,Jongseong Brad Choi*

Main category: cs.CV

TL;DR: SARA是一种在SfM中用于高效选择配对图像的新模块，能大幅减少计算量并显著提升定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有三维重建（SfM）流程通常依赖视觉相似度选择图像对，导致配对数庞大、计算开销高，且不总能保证最优的几何信息提取。作者希望减少不必要的匹配，提高配对效率，并提升重建精度。

Method: 提出SARA模块，先用轻量级的配对前估算（利用最近邻和RANSAC）对图像对的重建信息量（重叠度×视差）进行评分，并用此信息建立加强环路、锚点和弱视图的加权生成树（IWST）进行配对，显著筛减需做精确匹配的图像对数量。

Result: 与传统穷举法相比，SARA在现代学习型特征点检测器上的旋转误差降低46.5%、平移误差降低12.5%；同时最大加速50倍，配对数减至2%，并使复杂度从二次变为准线性。重建精度与主流方法（如3D Gaussian Splatting和SVRaster）仅有±3%的差距。

Conclusion: SARA大幅减少了SfM配对数量和计算量，同时提升了配准精度，为后续三维重建流程带来更高效和准确的选择依据，具备很强的实用和推广价值。

Abstract: We present SARA (Scene-Aware Reconstruction Accelerator), a geometry-driven pair selection module for Structure-from-Motion (SfM). Unlike conventional pipelines that select pairs based on visual similarity alone, SARA introduces geometry-first pair selection by scoring reconstruction informativeness - the product of overlap and parallax - before expensive matching. A lightweight pre-matching stage uses mutual nearest neighbors and RANSAC to estimate these cues, then constructs an Information-Weighted Spanning Tree (IWST) augmented with targeted edges for loop closure, long-baseline anchors, and weak-view reinforcement. Compared to exhaustive matching, SARA reduces rotation errors by 46.5+-5.5% and translation errors by 12.5+-6.5% across modern learned detectors, while achieving at most 50x speedup through 98% pair reduction (from 30,848 to 580 pairs). This reduces matching complexity from quadratic to quasi-linear, maintaining within +-3% of baseline reconstruction metrics for 3D Gaussian Splatting and SVRaster.

</details>


### [59] [Enhancing Low-resolution Image Representation Through Normalizing Flows](https://arxiv.org/abs/2601.06834)
*Chenglong Bao,Tongyao Pang,Zuowei Shen,Dihan Zheng,Yihang Zou*

Main category: cs.CV

TL;DR: 本文提出一种结合小波紧框架和归一化流的非线性低分辨率图像表征框架LR2Flow，能够在保留重要视觉内容的同时，实现对原始图像的准确重构。


<details>
  <summary>Details</summary>
Motivation: 低分辨率图像表征有助于降低存储和传输成本，并对图像重缩放、压缩和去噪等任务有益，但挑战在于要尽量少损失原始图像的关键信息。

Method: 作者提出了LR2Flow框架，将小波紧框架区块与可逆的归一化流神经网络结合，并从重建误差角度分析网络设计的重要性，强调在小波紧框架域构建可逆网络的必要性。

Result: 实验结果表明所提出方法在图像缩放、压缩和去噪等任务表现优异，学得的表征效果好，且模型表现出较强鲁棒性。

Conclusion: LR2Flow能有效保留图像关键信息同时兼顾高质量重建，验证了在小波紧框架域设计可逆网络的有效性，适合多种图像处理任务。

Abstract: Low-resolution image representation is a special form of sparse representation that retains only low-frequency information while discarding high-frequency components. This property reduces storage and transmission costs and benefits various image processing tasks. However, a key challenge is to preserve essential visual content while maintaining the ability to accurately reconstruct the original images. This work proposes LR2Flow, a nonlinear framework that learns low-resolution image representations by integrating wavelet tight frame blocks with normalizing flows. We conduct a reconstruction error analysis of the proposed network, which demonstrates the necessity of designing invertible neural networks in the wavelet tight frame domain. Experimental results on various tasks, including image rescaling, compression, and denoising, demonstrate the effectiveness of the learned representations and the robustness of the proposed framework.

</details>


### [60] [OSCAR: Optical-aware Semantic Control for Aleatoric Refinement in Sar-to-Optical Translation](https://arxiv.org/abs/2601.06835)
*Hyunseo Lee,Sang Min Kim,Ho Kyung Shin,Taeheon Kim,Woo-Jeoung Nam*

Main category: cs.CV

TL;DR: 本文提出了一种新的SAR到光学图像的生成框架，通过跨模态语义对齐、语义控制生成和不确定性自适应目标，有效提升了合成光学图像的感知质量与语义一致性。


<details>
  <summary>Details</summary>
Motivation: SAR雷达具备全天候成像能力，但由SAR影像生成真实感光学图像面临本质困难，现有方法受噪声和几何失真影响，难以获得高质量且语义准确的光学图像，需求改进。

Method: 提出了三项核心创新：(1)跨模态语义对齐——通过教师-学生方式，把光学先验注入SAR编码器；(2)语义引导生成——基于ControlNet，利用文本和图像提示多粒度控制生成过程；(3)不确定性自适应目标——显式建模不确定性，引导生成过程更聚焦于不确定区域，减少伪影。

Result: 大量实验表明，新方法在合成光学图像的感知效果和语义一致性上，显著优于同类最先进方法。

Conclusion: 该方法为SAR到光学翻译任务提供了有效的技术路线，为高质量、多语义一致的合成光学影像生成开拓了新方向。

Abstract: Synthetic Aperture Radar (SAR) provides robust all-weather imaging capabilities; however, translating SAR observations into photo-realistic optical images remains a fundamentally ill-posed problem. Current approaches are often hindered by the inherent speckle noise and geometric distortions of SAR data, which frequently result in semantic misinterpretation, ambiguous texture synthesis, and structural hallucinations. To address these limitations, a novel SAR-to-Optical (S2O) translation framework is proposed, integrating three core technical contributions: (i) Cross-Modal Semantic Alignment, which establishes an Optical-Aware SAR Encoder by distilling robust semantic priors from an Optical Teacher into a SAR Student (ii) Semantically-Grounded Generative Guidance, realized by a Semantically-Grounded ControlNet that integrates class-aware text prompts for global context with hierarchical visual prompts for local spatial guidance; and (iii) an Uncertainty-Aware Objective, which explicitly models aleatoric uncertainty to dynamically modulate the reconstruction focus, effectively mitigating artifacts caused by speckle-induced ambiguity. Extensive experiments demonstrate that the proposed method achieves superior perceptual quality and semantic consistency compared to state-of-the-art approaches.

</details>


### [61] [PRISM: Color-Stratified Point Cloud Sampling](https://arxiv.org/abs/2601.06839)
*Hansol Lim,Minhyeok Im,Jongseong Brad Choi*

Main category: cs.CV

TL;DR: 本文提出了一种新的RGB-LiDAR点云采样方法PRISM，该方法根据颜色多样性进行分层采样，能更好保留具有高色彩变化的区域，提高点云的表达效率。


<details>
  <summary>Details</summary>
Motivation: 现有点云下采样方法只关注空间分布，忽略了颜色信息，导致纹理丰富区域可能被过度稀释，视觉同质区域又无效保留太多点。作者认为颜色能够反映场景的特征独特性，因此有必要结合颜色信息优化采样。

Method: PRISM方法以RGB颜色空间为分层依据，在每个颜色分箱中设定最大点数k，采样密度根据颜色多样性动态分配。这样能优先保留色彩丰富、纹理复杂的点，而减少色彩单一、重复区域的采样。

Result: 相较随机采样、体素格采样等传统方法，PRISM生成的点云较稀疏但纹理特征保留更充分，有助于3D重建等任务中获取关键视觉信息。

Conclusion: 通过突出色彩多样性，PRISM提升了点云采样在表达视觉复杂性方面的效率，对纹理丰富区域更加友好，适合在需要点云特征表达的3D视觉任务中应用。

Abstract: We present PRISM, a novel color-guided stratified sampling method for RGB-LiDAR point clouds. Our approach is motivated by the observation that unique scene features often exhibit chromatic diversity while repetitive, redundant features are homogeneous in color. Conventional downsampling methods (Random Sampling, Voxel Grid, Normal Space Sampling) enforce spatial uniformity while ignoring this photometric content. In contrast, PRISM allocates sampling density proportional to chormatic diversity. By treating RGB color space as the stratification domain and imposing a maximum capacity k per color bin, the method preserves texture-rich regions with high color variation while substantially reducing visually homogeneous surfaces. This shifts the sampling space from spatial coverage to visual complexity to produce sparser point clouds that retain essential features for 3D reconstruction tasks.

</details>


### [62] [Speak While Watching: Unleashing TRUE Real-Time Video Understanding Capability of Multimodal Large Language Models](https://arxiv.org/abs/2601.06843)
*Junyan Lin,Junlong Tong,Hao Wu,Jialiang Zhang,Jinming Liu,Xin Jin,Xiaoyu Shen*

Main category: cs.CV

TL;DR: 论文提出了一种新的并行推理框架，使多模态大模型（MLLMs）能够在处理视频流输入时，同步进行感知与生成操作，实现实时交互，并大幅降低延迟。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型通常只能离线推理，需要接收完整输入后才能生成输出，且主流的流式方法感知与生成流程仍然是串行的，难以满足实时视频理解和交互的需求。核心瓶颈是传统位置编码要求输入具备全局连续性，导致输入输出高度耦合，影响并行推理能力。

Method: 作者提出了一套并行流式推理框架，通过三种不同位置编解码设计（Overlapped、Group-Decoupled、Gap-Isolated）放宽位置连续性约束，使模型能够在接收新输入的同时同步输出。

Result: 实验表明，Group-Decoupled设计在效率与性能之间达到了最佳平衡，大幅降低了推理延迟，同时保持了输出的流畅性和准确性。在感知与生成负载均衡情况下推理加速最高可达2倍。

Conclusion: 论文方案显著提升了多模态模型的流式处理能力，为“边看边说”等现实场景下的实时系统奠定了基础。相关代码已开源。

Abstract: Multimodal Large Language Models (MLLMs) have achieved strong performance across many tasks, yet most systems remain limited to offline inference, requiring complete inputs before generating outputs. Recent streaming methods reduce latency by interleaving perception and generation, but still enforce a sequential perception-generation cycle, limiting real-time interaction. In this work, we target a fundamental bottleneck that arises when extending MLLMs to real-time video understanding: the global positional continuity constraint imposed by standard positional encoding schemes. While natural in offline inference, this constraint tightly couples perception and generation, preventing effective input-output parallelism. To address this limitation, we propose a parallel streaming framework that relaxes positional continuity through three designs: Overlapped, Group-Decoupled, and Gap-Isolated. These designs enable simultaneous perception and generation, allowing the model to process incoming inputs while producing responses in real time. Extensive experiments reveal that Group-Decoupled achieves the best efficiency-performance balance, maintaining high fluency and accuracy while significantly reducing latency. We further show that the proposed framework yields up to 2x acceleration under balanced perception-generation workloads, establishing a principled pathway toward speak-while-watching real-time systems. We make all our code publicly available: https://github.com/EIT-NLP/Speak-While-Watching.

</details>


### [63] [MedGround: Bridging the Evidence Gap in Medical Vision-Language Models with Verified Grounding Data](https://arxiv.org/abs/2601.06847)
*Mengmeng Zhang,Xiaoping Wu,Hao Luo,Fan Wang,Yisheng Lv*

Main category: cs.CV

TL;DR: 本文提出了MedGround自动化系统，将医学图像分割资源自动转化为高质量‘指称-定位’配对数据，并发布了新的多模态医疗数据集MedGround-35K，以提升视觉-语言模型（VLMs）在医疗场景下的指称定位表现。


<details>
  <summary>Details</summary>
Motivation: 当前VLM虽然能生成有说服力的医学叙述，但其表述经常缺乏与图像的准确匹配，作者归因于高质量医学图像-文本定位数据的稀缺，因此希望通过新的数据生成方法解决该瓶颈。

Method: 提出MedGround流程，利用专家分割得到的掩膜，并通过多步验证（格式、几何/医学规则、视觉检查），自动生成医学图像的指称-定位配对数据，并据此构建了MedGround-35K数据集。

Result: 采用MedGround-35K训练的VLM，指称定位能力显著提升，能更好地多对象语义消歧，对未见数据也有良好的泛化能力。

Conclusion: MedGround方法可扩展且数据驱动，有效增强了医学场景下语言-视觉锚定的可信度，对医学人工智能研究具有重要意义。

Abstract: Vision-Language Models (VLMs) can generate convincing clinical narratives, yet frequently struggle to visually ground their statements. We posit this limitation arises from the scarcity of high-quality, large-scale clinical referring-localization pairs. To address this, we introduce MedGround, an automated pipeline that transforms segmentation resources into high-quality medical referring grounding data. Leveraging expert masks as spatial anchors, MedGround precisely derives localization targets, extracts shape and spatial cues, and guides VLMs to synthesize natural, clinically grounded queries that reflect morphology and location. To ensure data rigor, a multi-stage verification system integrates strict formatting checks, geometry- and medical-prior rules, and image-based visual judging to filter out ambiguous or visually unsupported samples. Finally, we present MedGround-35K, a novel multimodal medical dataset. Extensive experiments demonstrate that VLMs trained with MedGround-35K consistently achieve improved referring grounding performance, enhance multi-object semantic disambiguation, and exhibit strong generalization to unseen grounding settings. This work highlights MedGround as a scalable, data-driven approach to anchor medical language to verifiable visual evidence. Dataset and code will be released publicly upon acceptance.

</details>


### [64] [MVGGT: Multimodal Visual Geometry Grounded Transformer for Multiview 3D Referring Expression Segmentation](https://arxiv.org/abs/2601.06874)
*Changli Wu,Haodong Wang,Jiayi Ji,Yutian Yao,Chunsai Du,Jihua Kang,Yanwei Fu,Liujuan Cao*

Main category: cs.CV

TL;DR: 本文针对真实场景下多视图稀疏图像中的3D指代表达分割任务，提出了一种新型高效的端到端方法，并构建了相关评测基准。方法显著提升了分割精度与推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有3D指代分割方法依赖稠密高质量点云，而实际机器人等仅能获取少量稀疏视角RGB图，并且对计算延迟有严格要求。传统两阶段方案重建点云后再分割，效率慢且易导致目标重建粗糙，无法适应真实落地需求。

Method: 提出了一种多模态视觉-几何-语言耦合变换器（MVGGT），实现语言指导下，从稀疏多视图直接推理目标分割。方法采用双分支结构，将语言信息与几何推理深度融合。为解决训练中前景梯度稀释（FGD）问题，作者提出了逐视角消除无目标抑制优化(PVSO)，平衡梯度，提升训练稳定性与效率。同时设计并发布标准化评测基准MVRefer。

Result: 实验证明MVGGT在该设定下首次建立了强基线，准确率与速度均优于现有其他方法。

Conclusion: MVGGT为真实稀疏多视图3D指代分割提供了高效新方案，结合创新优化策略和统一评测体系，为实际应用带来明显优势。代码与模型开源，推动社区发展。

Abstract: Most existing 3D referring expression segmentation (3DRES) methods rely on dense, high-quality point clouds, while real-world agents such as robots and mobile phones operate with only a few sparse RGB views and strict latency constraints. We introduce Multi-view 3D Referring Expression Segmentation (MV-3DRES), where the model must recover scene structure and segment the referred object directly from sparse multi-view images. Traditional two-stage pipelines, which first reconstruct a point cloud and then perform segmentation, often yield low-quality geometry, produce coarse or degraded target regions, and run slowly. We propose the Multimodal Visual Geometry Grounded Transformer (MVGGT), an efficient end-to-end framework that integrates language information into sparse-view geometric reasoning through a dual-branch design. Training in this setting exposes a critical optimization barrier, termed Foreground Gradient Dilution (FGD), where sparse 3D signals lead to weak supervision. To resolve this, we introduce Per-view No-target Suppression Optimization (PVSO), which provides stronger and more balanced gradients across views, enabling stable and efficient learning. To support consistent evaluation, we build MVRefer, a benchmark that defines standardized settings and metrics for MV-3DRES. Experiments show that MVGGT establishes the first strong baseline and achieves both high accuracy and fast inference, outperforming existing alternatives. Code and models are publicly available at https://mvggt.github.io.

</details>


### [65] [Unsupervised Domain Adaptation with SAM-RefiSeR for Enhanced Brain Tumor Segmentation](https://arxiv.org/abs/2601.06882)
*Dillan Imans,Phuoc-Nguyen Bui,Duc-Tai Le,Hyunseung Choo*

Main category: cs.CV

TL;DR: 本文提出了一种结合SAM与RefiSeR策略的无监督领域自适应方法，用于提升脑肿瘤分割的精度。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤分割任务中，不同数据集（如不同医院或扫描仪）之间存在领域差异，导致训练好的模型在新数据集上性能下降。为了解决领域迁移带来的性能损失，需要有效的无监督领域适应方法。

Method: 文章提出了一种基于SAM（可调节自注意力机制）和RefiSeR（区域细化重采样）相结合的无监督领域适应框架，能够自动调整对源域和目标域特征的关注，有效缩小跨域差异，通过细化重采样进一步提升目标域的分割精度。

Result: 在公开的脑肿瘤分割数据集上，所提出方法相比现有主流无监督领域适应方法有更优的分割性能，表现为更高的Dice系数和分割准确率。

Conclusion: 该方法实现了无监督情况下高效的脑肿瘤分割，为医学影像分析领域的领域适应提供了新思路，有利于模型在不同临床环境下稳健应用。

Abstract: Unsupervised Domain Adaptation with SAM-RefiSeR for Enhanced Brain Tumor Segmentation

</details>


### [66] [MixRI: Mixing Features of Reference Images for Novel Object Pose Estimation](https://arxiv.org/abs/2601.06883)
*Xinhang Liu,Jiawei Shi,Zheng Dang,Yuchao Dai*

Main category: cs.CV

TL;DR: MixRI是一种轻量级网络，面向在RGB图像中基于CAD模型的新物体位姿估计问题，无需微调即可应用于新物体，具备低内存和快速推理能力。


<details>
  <summary>Details</summary>
Motivation: 目前方法需要大量参考图像和较大的网络参数，导致内存和推理效率难以满足实际应用需求。

Method: 通过多视角信息进行点对匹配，提出参考图像融合策略，减少参考图像数量，并采用轻量级网络结构实现高效推理。

Result: 在BOP挑战的七个核心数据集上，即使使用更少的参考图像，MixRI与需要更多参考图像和更大网络参数的方法取得了可比的结果。

Conclusion: MixRI能够以更低的资源消耗，在新物体位姿估计任务中达到与主流方法相当的性能，更适合实际应用。

Abstract: We present MixRI, a lightweight network that solves the CAD-based novel object pose estimation problem in RGB images. It can be instantly applied to a novel object at test time without finetuning. We design our network to meet the demands of real-world applications, emphasizing reduced memory requirements and fast inference time. Unlike existing works that utilize many reference images and have large network parameters, we directly match points based on the multi-view information between the query and reference images with a lightweight network. Thanks to our reference image fusion strategy, we significantly decrease the number of reference images, thus decreasing the time needed to process these images and the memory required to store them. Furthermore, with our lightweight network, our method requires less inference time. Though with fewer reference images, experiments on seven core datasets in the BOP challenge show that our method achieves comparable results with other methods that require more reference images and larger network parameters.

</details>


### [67] [CLIMP: Contrastive Language-Image Mamba Pretraining](https://arxiv.org/abs/2601.06891)
*Nimrod Shabtay,Itamar Zimerman,Eli Schwartz,Raja Giryes*

Main category: cs.CV

TL;DR: 本文提出了CLIMP，这是首个基于Mamba的对比视觉-语言预训练模型，用Mamba替换了视觉和文本编码器，提升了跨模态检索和鲁棒性，性能超过了OpenAI的CLIP-ViT-B。


<details>
  <summary>Details</summary>
Motivation: CLIP模型依赖于Vision Transformer，存在对输入空间分辨率扩展性差且注意力机制容易产生虚假相关性的问题。为了解决这些局限性，作者尝试用Mamba替代，同时简化模型结构并提升泛化性和实际应用能力。

Method: 作者提出了CLIMP模型，使用Mamba结构分别作为视觉和文本编码器。VMamba能更好地编码视觉空间结构、减少虚假相关性；文本编码器采用自回归结构突破上下文长度固定的限制。同时，CLIMP支持可变输入分辨率，无需位置编码插值或特殊训练。

Result: CLIMP在ImageNet-O等跨模态检索和分布外测试中，比OpenAI CLIP-ViT-B高出7.5%；高分辨率下检索精度提升6.6%，显存节省达5倍，FLOPs减少1.8倍。文本部分实现了密集描述检索能力。

Conclusion: Mamba结构在视觉-语言学习中展现出优异性能，是Transformer在CLIP等任务的有力替代者，具有更高的泛化性和效率。

Abstract: Contrastive Language-Image Pre-training (CLIP) relies on Vision Transformers whose attention mechanism is susceptible to spurious correlations, and scales quadratically with resolution. To address these limitations, We present CLIMP, the first fully Mamba-based contrastive vision-language model that replaces both the vision and text encoders with Mamba. The new architecture encodes sequential structure in both vision and language, with VMamba capturing visual spatial inductive biases, reducing reliance on spurious correlations and producing an embedding space favorable for cross-modal retrieval and out-of-distribution robustness-surpassing OpenAI's CLIP-ViT-B by 7.5% on ImageNet-O. CLIMP naturally supports variable input resolutions without positional encoding interpolation or specialized training, achieving up to 6.6% higher retrieval accuracy at 16x training resolution while using 5x less memory and 1.8x fewer FLOPs. The autoregressive text encoder further overcomes CLIP's fixed context limitation, enabling dense captioning retrieval. Our findings suggest that Mamba exhibits advantageous properties for vision-language learning, making it a compelling alternative to Transformer-based CLIP.

</details>


### [68] [UDPNet: Unleashing Depth-based Priors for Robust Image Dehazing](https://arxiv.org/abs/2601.06909)
*Zengyuan Zuo,Junjun Jiang,Gang Wu,Xianming Liu*

Main category: cs.CV

TL;DR: 本文提出了UDPNet，利用大规模预训练深度估计算法的深度先验，有效提升了图像去雾模型的性能，在多个主流数据集上超越现有最优方法。


<details>
  <summary>Details</summary>
Motivation: 以往图像去雾方法大多仅依赖RGB特征，忽视了深度与雾分布的相关性，或者未能充分利用准确的深度信息，导致性能不理想。因此，亟需一种能有效整合深度先验的新型去雾框架。

Method: UDPNet结构包括两个核心模块：深度引导注意力模块（DGAM）通过轻量级的深度通道注意力自适应调整特征；深度先验融合模块（DPFM）实现多尺度深度特征的分层融合，采用双滑窗多头交叉注意力机制。整个架构以大规模预训练的DepthAnything V2深度模型为先验指导。

Result: UDPNet在主流去雾数据集上表现优异，相较最新方法，在SOTS、Haze4K、NHR数据集PSNR分别提升0.85 dB、1.19 dB、1.79 dB，实验结果充分验证了其有效性和泛化能力。

Conclusion: UDPNet为深度感知的去雾任务建立了新基准，显著提升了现有模型的性能，并能适应不同雾密度、光照条件和真实/合成数据域的变化。

Abstract: Image dehazing has witnessed significant advancements with the development of deep learning models. However, a few methods predominantly focus on single-modal RGB features, neglecting the inherent correlation between scene depth and haze distribution. Even those that jointly optimize depth estimation and image dehazing often suffer from suboptimal performance due to inadequate utilization of accurate depth information. In this paper, we present UDPNet, a general framework that leverages depth-based priors from large-scale pretrained depth estimation model DepthAnything V2 to boost existing image dehazing models. Specifically, our architecture comprises two typical components: the Depth-Guided Attention Module (DGAM) adaptively modulates features via lightweight depth-guided channel attention, and the Depth Prior Fusion Module (DPFM) enables hierarchical fusion of multi-scale depth map features by dual sliding-window multi-head cross-attention mechanism. These modules ensure both computational efficiency and effective integration of depth priors. Moreover, the intrinsic robustness of depth priors empowers the network to dynamically adapt to varying haze densities, illumination conditions, and domain gaps across synthetic and real-world data. Extensive experimental results demonstrate the effectiveness of our UDPNet, outperforming the state-of-the-art methods on popular dehazing datasets, such as 0.85 dB PSNR improvement on the SOTS dataset, 1.19 dB on the Haze4K dataset and 1.79 dB PSNR on the NHR dataset. Our proposed solution establishes a new benchmark for depth-aware dehazing across various scenarios. Pretrained models and codes will be released at our project https://github.com/Harbinzzy/UDPNet.

</details>


### [69] [RenderFlow: Single-Step Neural Rendering via Flow Matching](https://arxiv.org/abs/2601.06928)
*Shenghao Zhang,Runtao Liu,Christopher Schroers,Yang Zhang*

Main category: cs.CV

TL;DR: 该论文提出了RenderFlow，一种基于flow matching的新型单步神经渲染框架，能够实现高效、确定性且具有物理真实性的实时渲染，并通过稀疏关键帧指导提升结果质量和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于物理的渲染（PBR）方法计算量大，渲染缓慢；而深度学习方法如扩散模型虽然高效，但推理慢且输出不稳定、物理精确性欠缺。作者希望结合两者优点，实现高效、物理现实、质量可控的神经渲染。

Method: 作者提出RenderFlow，即采用flow matching范式，实现单步、确定性的神经渲染，不再需要扩散模型的多步生成。并引入稀疏关键帧指导模块，利用少量高质量关键帧提升渲染的物理精度和一致性。此外框架可通过适配模块高效处理逆向渲染任务（如内部属性分解）。

Result: 方法显著加快了渲染速度，在保持接近传统PBR质量基础上实现近实时渲染。通过稀疏关键帧提升了物理准确性和视觉效果。实验还验证了其用于逆渲染任务的高效性和通用性。

Conclusion: RenderFlow有效结合了神经生成与物理渲染优势，实现了物理真实性和高效率的平衡，同时具备良好的扩展性与应用前景（如逆向分解任务）。

Abstract: Conventional physically based rendering (PBR) pipelines generate photorealistic images through computationally intensive light transport simulations. Although recent deep learning approaches leverage diffusion model priors with geometry buffers (G-buffers) to produce visually compelling results without explicit scene geometry or light simulation, they remain constrained by two major limitations. First, the iterative nature of the diffusion process introduces substantial latency. Second, the inherent stochasticity of these generative models compromises physical accuracy and temporal consistency. In response to these challenges, we propose a novel, end-to-end, deterministic, single-step neural rendering framework, RenderFlow, built upon a flow matching paradigm. To further strengthen both rendering quality and generalization, we propose an efficient and effective module for sparse keyframe guidance. Our method significantly accelerates the rendering process and, by optionally incorporating sparsely rendered keyframes as guidance, enhances both the physical plausibility and overall visual quality of the output. The resulting pipeline achieves near real-time performance with photorealistic rendering quality, effectively bridging the gap between the efficiency of modern generative models and the precision of traditional physically based rendering. Furthermore, we demonstrate the versatility of our framework by introducing a lightweight, adapter-based module that efficiently repurposes the pretrained forward model for the inverse rendering task of intrinsic decomposition.

</details>


### [70] [Measuring Social Bias in Vision-Language Models with Face-Only Counterfactuals from Real Photos](https://arxiv.org/abs/2601.06931)
*Haodong Chen,Qiang Huang,Jiaqi Zhao,Qiuping Jiang,Xiaojun Chang,Jun Yu*

Main category: cs.CV

TL;DR: 该论文提出了一种“仅面部反事实评估范式”，并构建了相关数据集与基准，以严格控制视觉变量下评估视觉-语言模型( VLMs )中的社会偏见。结果发现，即使在严格控制图像干扰时，VLMs 仍表现出明显的人口统计偏见。


<details>
  <summary>Details</summary>
Motivation: 随着视觉-语言模型广泛应用于与社会密切相关的场景，人们对其在涉及种族、性别等人口统计特征方面产生的社会偏见表示担忧。然而，现实世界中的图像环境复杂，种族与性别与背景、服饰等因素相互交织，使得对偏见的归因变得困难。为了解决归因中的视觉混杂问题，需要更为精细和可控的评估方法。

Method: 作者提出了一种面部特征反事实编辑方法：在保持现实照片的除面部种族与性别属性之外的所有视觉信息不变的情况下，仅编辑人脸，以生成不同种族和性别的图像反事实对。基于此方法，构建出FOCUS数据集（含480组、六种职业、十个人口统计群体的场景匹配反事实图像）和REFLECT基准任务（涵盖强制二选、社会经济属性多选推断、薪资推荐三个任务）。通过这些工具，对五种主流VLMs进行严格的偏见测试。

Result: 实验显示，即便在最大程度控制视觉干扰的情况下，视觉-语言模型在不同人口统计属性间依然表现出持续的社会偏见。而且，这种偏见在不同的任务设计下表现差异显著。

Conclusion: 社会偏见在VLMs中受控情况下依然存在，因此反事实和精细、受控的审查机制是评估多模态模型社会偏见的必要手段；同时，任务设计的方式对评估结果有重要影响，未来相关工作需要把控任务形式及评测方式。

Abstract: Vision-Language Models (VLMs) are increasingly deployed in socially consequential settings, raising concerns about social bias driven by demographic cues. A central challenge in measuring such social bias is attribution under visual confounding: real-world images entangle race and gender with correlated factors such as background and clothing, obscuring attribution. We propose a \textbf{face-only counterfactual evaluation paradigm} that isolates demographic effects while preserving real-image realism. Starting from real photographs, we generate counterfactual variants by editing only facial attributes related to race and gender, keeping all other visual factors fixed. Based on this paradigm, we construct \textbf{FOCUS}, a dataset of 480 scene-matched counterfactual images across six occupations and ten demographic groups, and propose \textbf{REFLECT}, a benchmark comprising three decision-oriented tasks: two-alternative forced choice, multiple-choice socioeconomic inference, and numeric salary recommendation. Experiments on five state-of-the-art VLMs reveal that demographic disparities persist under strict visual control and vary substantially across task formulations. These findings underscore the necessity of controlled, counterfactual audits and highlight task design as a critical factor in evaluating social bias in multimodal models.

</details>


### [71] [Watching, Reasoning, and Searching: A Video Deep Research Benchmark on Open Web for Agentic Video Reasoning](https://arxiv.org/abs/2601.06943)
*Chengwen Liu,Xiaomin Yu,Zhuoyue Chang,Zhe Huang,Shuo Zhang,Heng Lian,Kunyi Wang,Rui Xu,Sen Hu,Jianheng Hou,Hao Peng,Chengwei Qin,Xiaobin Hu,Hong Peng,Ronghao Chen,Huacan Wang*

Main category: cs.CV

TL;DR: 本文提出了首个面向开放域视频深度研究的基准数据集VideoDR，聚焦于视频条件下的网页检索、多跳推理与验证能力评测。


<details>
  <summary>Details</summary>
Motivation: 现有视频问答场景中，视频仅提供局部线索，而可验证答案常分布于开放网络，要求模型具备跨帧信息提取、交互式网页检索、多跳推理等能力，然而相关基准匮乏。

Method: 作者构建了VideoDR数据集，包含六大语义域下经高质量人工标注的视频，设计任务要求模型完成从视频线索抽取、网页检索到联合多源证据多跳推理，同时对不同范式（固定流程Workflow与智能体Agentic）下多种主流多模态大模型评测。

Result: 实验发现，Agentic范式在视频锚点长期追踪能力不足情况下，其表现未必优于Workflow；长程任务中的目标漂移和一致性问题成为主要瓶颈。

Conclusion: VideoDR为开放网络下的视频智能体研究提供了系统性基准，揭示了此类智能体亟待解决的核心挑战（如目标保持、一致性等），为下代视频深度研究智能体的发展指明了方向。

Abstract: In real-world video question answering scenarios, videos often provide only localized visual cues, while verifiable answers are distributed across the open web; models therefore need to jointly perform cross-frame clue extraction, iterative retrieval, and multi-hop reasoning-based verification. To bridge this gap, we construct the first video deep research benchmark, VideoDR. VideoDR centers on video-conditioned open-domain video question answering, requiring cross-frame visual anchor extraction, interactive web retrieval, and multi-hop reasoning over joint video-web evidence; through rigorous human annotation and quality control, we obtain high-quality video deep research samples spanning six semantic domains. We evaluate multiple closed-source and open-source multimodal large language models under both the Workflow and Agentic paradigms, and the results show that Agentic is not consistently superior to Workflow: its gains depend on a model's ability to maintain the initial video anchors over long retrieval chains. Further analysis indicates that goal drift and long-horizon consistency are the core bottlenecks. In sum, VideoDR provides a systematic benchmark for studying video agents in open-web settings and reveals the key challenges for next-generation video deep research agents.

</details>


### [72] [SketchJudge: A Diagnostic Benchmark for Grading Hand-drawn Diagrams with Multimodal Large Language Models](https://arxiv.org/abs/2601.06944)
*Yuhang Su,Mei Wang,Yaoyao Zhong,Guozhang Li,Shixing Li,Yihan Feng,Hua Huang*

Main category: cs.CV

TL;DR: 本文提出SketchJudge新基准，用于评估多模态大模型（MLLMs）在手绘STEM图表诊断与评分任务中的能力，发现现有模型在人类生成草图上的表现显著落后于人类。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLMs在视觉理解方面取得了进展，但在人类手绘、结构和语义都不规则的草图理解和诊断上表现较差，特别是在需要分析错误的视觉评分任务中，这一能力的研究很有限。

Method: 作者提出SketchJudge基准，包含四个领域（几何、物理、图表、流程图）共1015份学生手绘答卷，涵盖多样化的风格和错误类型，用于系统评估MLLMs的评分和诊断能力。

Result: 基于SketchJudge的评测显示，当前先进的MLLMs在手绘草图的视觉评分和错误诊断方面远逊于人类，说明模型在处理符号性和噪声较大的场景时存在明显短板。

Conclusion: SketchJudge基准有效揭示了当前视觉-语言模型在复杂和不规则视觉场景下的局限，为未来模型的提升和相关任务的研究提供了重要工具和参考。

Abstract: While Multimodal Large Language Models (MLLMs) have achieved remarkable progress in visual understanding, they often struggle when faced with the unstructured and ambiguous nature of human-generated sketches. This limitation is particularly pronounced in the underexplored task of visual grading, where models should not only solve a problem but also diagnose errors in hand-drawn diagrams. Such diagnostic capabilities depend on complex structural, semantic, and metacognitive reasoning. To bridge this gap, we introduce SketchJudge, a novel benchmark tailored for evaluating MLLMs as graders of hand-drawn STEM diagrams. SketchJudge encompasses 1,015 hand-drawn student responses across four domains: geometry, physics, charts, and flowcharts, featuring diverse stylistic variations and distinct error types. Evaluations on SketchJudge demonstrate that even advanced MLLMs lag significantly behind humans, validating the benchmark's effectiveness in exposing the fragility of current vision-language alignment in symbolic and noisy contexts. All data, code, and evaluation scripts are publicly available at https://github.com/yuhangsu82/SketchJudge.

</details>


### [73] [Unified Personalized Understanding, Generating and Editing](https://arxiv.org/abs/2601.06965)
*Yu Zhong,Tianwei Lin,Ruike Zhu,Yuqian Yuan,Haoyu Zheng,Liang Liang,Wenqiao Zhang,Feifei Shao,Haoyuan Li,Wanggui He,Hao Jiang,Yueting Zhuang*

Main category: cs.CV

TL;DR: 本文提出了OmniPersona框架，实现了统一大多模态模型（LMMs）的端到端个性化，能够在理解、生成和图像编辑任务中一致而可控地建模用户特定概念。通过结构性解耦的概念Token和知识回放机制，OmniPersona有效减少了任务间干扰，并实现了个性化知识的跨任务传播。新引入的OmniPBench基准，整合了多任务个性化的评测。实验表明OmniPersona在各类个性化任务上表现优越和稳健。


<details>
  <summary>Details</summary>
Motivation: 现有大多模态模型难以对用户特定的个性化概念持续一致地进行理解和生成。主流提升方法依赖外部检索或复杂训练，效率低且易出现任务干扰。因此，亟需一个统一、高效、可控的个性化多模态框架以提升模型在个性化任务上的表现。

Method: OmniPersona提出结构性解耦的概念Token，将不同任务分配至独立子空间，减少任务间干扰；引入显式知识回放机制，实现个性化属性知识的跨任务传播。此外，构建了OmniPBench评测集，系统地涵盖了多任务和个性化编辑评估。

Result: OmniPersona在理解、生成和图像编辑等多种个性化任务中表现出竞争力和稳健性，优于或不逊色于现有方法，在新提出的OmniPBench基准中实现了高水平的统一个性化性能。

Conclusion: OmniPersona作为首个统一端到端个性化多模态框架，显著提升了个性化任务中的一致性与可控性，同时新基准OmniPBench为后续相关研究提供了重要的测评工具和标准。

Abstract: Unified large multimodal models (LMMs) have achieved remarkable progress in general-purpose multimodal understanding and generation. However, they still operate under a ``one-size-fits-all'' paradigm and struggle to model user-specific concepts (e.g., generate a photo of \texttt{<maeve>}) in a consistent and controllable manner. Existing personalization methods typically rely on external retrieval, which is inefficient and poorly integrated into unified multimodal pipelines. Recent personalized unified models introduce learnable soft prompts to encode concept information, yet they either couple understanding and generation or depend on complex multi-stage training, leading to cross-task interference and ultimately to fuzzy or misaligned personalized knowledge. We present \textbf{OmniPersona}, an end-to-end personalization framework for unified LMMs that, for the first time, integrates personalized understanding, generation, and image editing within a single architecture. OmniPersona introduces structurally decoupled concept tokens, allocating dedicated subspaces for different tasks to minimize interference, and incorporates an explicit knowledge replay mechanism that propagates personalized attribute knowledge across tasks, enabling consistent personalized behavior. To systematically evaluate unified personalization, we propose \textbf{\texttt{OmniPBench}}, extending the public UnifyBench concept set with personalized editing tasks and cross-task evaluation protocols integrating understanding, generation, and editing. Experimental results demonstrate that OmniPersona delivers competitive and robust performance across diverse personalization tasks. We hope OmniPersona will serve as a strong baseline and spur further research on controllable, unified personalization.

</details>


### [74] [Can Textual Reasoning Improve the Performance of MLLMs on Fine-grained Visual Classification?](https://arxiv.org/abs/2601.06993)
*Jie Zhu,Yiyang Su,Xiaoming Liu*

Main category: cs.CV

TL;DR: 本文系统研究了多模态大型语言模型（MLLM）在细粒度视觉分类（FGVC）任务中引入Chain-of-Thought（CoT）推理的影响，发现推理长度增加会显著降低分类准确率，并提出了新的优化方法ReFine-RFT来解决这一问题，实现了SOTA表现。


<details>
  <summary>Details</summary>
Motivation: MLLMs虽具通用能力，但在区分细微视觉差异的FGVC任务上表现不佳。虽然CoT推理提升了如数学、编程等任务性能，但其在视觉感知任务中反而有负面影响，具体原因未明。因此，作者希望系统性分析CoT推理对FGVC的影响并加以优化。

Method: 作者采用零样本评估与多种训练范式，系统地分析了CoT推理在FGVC任务中的作用。提出了CoT推理长度越长，准确率越低的“Cost of Thinking”现象。在此基础上，提出（1）alg——一种通用奖励归一化方法平衡多目标奖励，（2）ReFine-RFT框架，结合奖励集成与归一化约束推理长度并提供密集准确率反馈。

Result: 实验证明，提出的方法显著提升了MLLM在多个FGVC基准上的表现，实现了当前最优（SOTA）成绩。

Conclusion: 长文本推理会损害MLLM在感知密集型任务如FGVC的表现，归因于冗余推理带来的“Cost of Thinking”。通过优化推理长度和奖励机制，MLLM可取得更优的视觉分类效果。

Abstract: Multi-modal large language models (MLLMs) exhibit strong general-purpose capabilities, yet still struggle on Fine-Grained Visual Classification (FGVC), a core perception task that requires subtle visual discrimination and is crucial for many real-world applications. A widely adopted strategy for boosting performance on challenging tasks such as math and coding is Chain-of-Thought (CoT) reasoning. However, several prior works have reported that CoT can actually harm performance on visual perception tasks. These studies, though, examine the issue from relatively narrow angles and leave open why CoT degrades perception-heavy performance. We systematically re-examine the role of CoT in FGVC through the lenses of zero-shot evaluation and multiple training paradigms. Across these settings, we uncover a central paradox: the degradation induced by CoT is largely driven by the reasoning length, in which longer textual reasoning consistently lowers classification accuracy. We term this phenomenon the ``Cost of Thinking''. Building on this finding, we make two key contributions: (1) \alg, a simple and general plug-and-play normalization method for multi-reward optimization that balances heterogeneous reward signals, and (2) ReFine-RFT, a framework that combines ensemble rewards with \alg to constrain reasoning length while providing dense accuracy-oriented feedback. Extensive experiments demonstrate the effectiveness of our findings and the proposed ReFine-RFT, achieving state-of-the-art performance across FGVC benchmarks. Code and models are available at \href{https://github.com/jiezhu23/ReFine-RFT}{Project Link}.

</details>


### [75] [Spatial Multi-Task Learning for Breast Cancer Molecular Subtype Prediction from Single-Phase DCE-MRI](https://arxiv.org/abs/2601.07001)
*Sen Zeng,Hong Zhou,Zheng Zhu,Yang Liu*

Main category: cs.CV

TL;DR: 本文提出了一种基于单期DCE-MRI的空间多任务学习框架，实现乳腺癌分子分型主要生物标志物的非侵入性预测，并显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前乳腺癌个体化治疗需要精准的分子分型，而传统方法如免疫组化依赖侵入性活检且易受取样偏倚影响。临床常规DCE-MRI扫描节省时间和造影剂剂量，只获取单期对比增强图像，如何利用这些有限数据实现分子分型预测成为亟需解决的难题。

Method: 作者设计了一个深度学习的空间多任务学习框架，该架构整合多尺度空间注意力模块，关注肿瘤及其周围区域特征，并引入ROI加权模块突出肿瘤核心、边缘和肿瘤周围组织。同时，通过多任务学习分支，利用标志物间的生物学关系进行联合建模。模型在886个内部案例（按7:1:2分训练/验证/测试）及74个外部案例（5折交叉验证）上评估性能。

Result: 框架在ER、PR、HER2分类上的AUC分别为0.893、0.824、0.857，Ki-67回归的平均绝对误差为8.2%。该方法在各任务上均显著优于传统影像组学和单任务深度学习基线模型。

Conclusion: 结果表明仅用标准单期DCE-MRI数据，即可实现乳腺癌分子分型的高精度、非侵入式预测，有望提升临床诊断效率与精准治疗水平。

Abstract: Accurate molecular subtype classification is essential for personalized breast cancer treatment, yet conventional immunohistochemical analysis relies on invasive biopsies and is prone to sampling bias. Although dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) enables non-invasive tumor characterization, clinical workflows typically acquire only single-phase post-contrast images to reduce scan time and contrast agent dose. In this study, we propose a spatial multi-task learning framework for breast cancer molecular subtype prediction from clinically practical single-phase DCE-MRI. The framework simultaneously predicts estrogen receptor (ER), progesterone receptor (PR), human epidermal growth factor receptor 2 (HER2) status, and the Ki-67 proliferation index -- biomarkers that collectively define molecular subtypes. The architecture integrates a deep feature extraction network with multi-scale spatial attention to capture intratumoral and peritumoral characteristics, together with a region-of-interest weighting module that emphasizes the tumor core, rim, and surrounding tissue. Multi-task learning exploits biological correlations among biomarkers through shared representations with task-specific prediction branches. Experiments on a dataset of 960 cases (886 internal cases split 7:1:2 for training/validation/testing, and 74 external cases evaluated via five-fold cross-validation) demonstrate that the proposed method achieves an AUC of 0.893, 0.824, and 0.857 for ER, PR, and HER2 classification, respectively, and a mean absolute error of 8.2\% for Ki-67 regression, significantly outperforming radiomics and single-task deep learning baselines. These results indicate the feasibility of accurate, non-invasive molecular subtype prediction using standard imaging protocols.

</details>


### [76] [Adversarial Attacks on Medical Hyperspectral Imaging Exploiting Spectral-Spatial Dependencies and Multiscale Features](https://arxiv.org/abs/2601.07056)
*Yunrui Gu,Zhenzhe Gao,Cong Kong,Zhaoxia Yin*

Main category: cs.CV

TL;DR: 本文提出了一种针对医学高光谱成像（HSI）模型的新型对抗攻击框架，能够有效干扰模型的分类性能，尤其在肿瘤区域表现显著，同时具有很强的隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习提升了医学高光谱成像在疾病诊断中的准确性，但其对抗攻击脆弱性问题尚未得到充分研究和解决。论文旨在揭示HSI模型脆弱的根本原因，并为保障临床应用的安全性和可靠性打下基础。

Method: 作者分析了HSI模型的两大脆弱本源：对局部像素依赖和多尺度频谱-空间特征编码依赖，并据此提出了两种有针对性的攻击方式：局部像素依赖攻击（Local Pixel Dependency Attack）和多尺度信息攻击（Multiscale Information Attack），分别针对空间相关和多尺度特征进行扰动。

Result: 在Brain和MDC公开数据集上的实验表明，所提攻击方法可在视觉难以察觉的情况下，显著降低HSI模型的分类准确率，尤其在肿瘤区域影响更大。相比现有对抗攻击方法，本文方法专门揭示了HSI模型的独特脆弱性。

Conclusion: 论文结果强调，医学高光谱成像模型在临床实际应用中亟需结构感知的鲁棒防御措施，以提升其安全性与可靠性。

Abstract: Medical hyperspectral imaging (HSI) enables accurate disease diagnosis by capturing rich spectral-spatial tissue information, but recent advances in deep learning have exposed its vulnerability to adversarial attacks. In this work, we identify two fundamental causes of this fragility: the reliance on local pixel dependencies for preserving tissue structure and the dependence on multiscale spectral-spatial representations for hierarchical feature encoding. Building on these insights, we propose a targeted adversarial attack framework for medical HSI, consisting of a Local Pixel Dependency Attack that exploits spatial correlations among neighboring pixels, and a Multiscale Information Attack that perturbs features across hierarchical spectral-spatial scales. Experiments on the Brain and MDC datasets demonstrate that our attacks significantly degrade classification performance, especially in tumor regions, while remaining visually imperceptible. Compared with existing methods, our approach reveals the unique vulnerabilities of medical HSI models and underscores the need for robust, structure-aware defenses in clinical applications.

</details>


### [77] [Billboard in Focus: Estimating Driver Gaze Duration from a Single Image](https://arxiv.org/abs/2601.07073)
*Carlos Pizarroso,Zuzana Berger Haladová,Zuzana Černeková,Viktor Kocur*

Main category: cs.CV

TL;DR: 本文提出了一种全自动检测路边广告牌及估算驾驶员注视时长的流程，无需人工标注或眼动追踪设备，结合YOLO目标检测和DINOv2特征分类，取得较好精度。


<details>
  <summary>Details</summary>
Motivation: 路边广告牌是户外广告的重要载体，但可能分散驾驶员注意力并增加事故风险。为定量分析广告牌对驾驶员的影响，亟需无需人工注释或昂贵设备的新方法。

Method: 流程分为两阶段：第一阶段基于YOLO模型，在Mapillary Vistas上预训练后，针对BillboardLamac数据集微调，进行广告牌检测并获得94%的mAP@50；第二阶段利用检测到的包围框及DINOv2特征训练分类器，用于估算驾驶员对广告牌的注视时长。

Result: YOLO检测模型在广告牌检测任务中达到94%的mAP@50。基于包围框位置与DINOv2特征的分类器，在BillboardLamac数据集的单帧注视时长估算上达到68.1%准确率。方法还在Google街景图片中得到验证。

Conclusion: 文中提出的方法能够自动、有效地检测广告牌并估算驾驶员注视时长，为评估道路广告对于驾驶行为的影响提供了新工具，对交通安全研究和广告行业具有潜在应用价值。

Abstract: Roadside billboards represent a central element of outdoor advertising, yet their presence may contribute to driver distraction and accident risk. This study introduces a fully automated pipeline for billboard detection and driver gaze duration estimation, aiming to evaluate billboard relevance without reliance on manual annotations or eye-tracking devices. Our pipeline operates in two stages: (1) a YOLO-based object detection model trained on Mapillary Vistas and fine-tuned on BillboardLamac images achieved 94% mAP@50 in the billboard detection task (2) a classifier based on the detected bounding box positions and DINOv2 features. The proposed pipeline enables estimation of billboard driver gaze duration from individual frames. We show that our method is able to achieve 68.1% accuracy on BillboardLamac when considering individual frames. These results are further validated using images collected from Google Street View.

</details>


### [78] [Efficient Visual Question Answering Pipeline for Autonomous Driving via Scene Region Compression](https://arxiv.org/abs/2601.07092)
*Yuliang Cai,Dongqiangzi Ye,Zitian Chen,Chongruo Wu*

Main category: cs.CV

TL;DR: 本文提出了一种用于自动驾驶视觉问答（VQA）任务的高效视觉-语言模型框架SRC-Pipeline，大幅降低了计算量，并保持了良好性能。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶对VQA的实时性和低延迟有极高要求，现有大规模视觉-语言模型虽性能优异，但推理延迟大、计算量高，不利于实际部署。

Method: 作者提出SRC-Pipeline，通过将早期帧的视觉token压缩成少量高层次token，仅对最近帧保留全部patch token，从而降低每帧的处理量。

Result: 在自动驾驶视频问答任务上，SRC-Pipeline将FLOPs（计算量）减少了66%，而性能仍能与主流方法媲美。

Conclusion: SRC-Pipeline使大模型更易于在自动驾驶等实时性极高的应用场景中部署和运行，提高了实用性和安全性。

Abstract: Autonomous driving increasingly relies on Visual Question Answering (VQA) to enable vehicles to understand complex surroundings by analyzing visual inputs and textual queries. Currently, a paramount concern for VQA in this domain is the stringent requirement for fast latency and real-time processing, as delays directly impact real-world safety in this safety-critical application. However, current state-of-the-art VQA models, particularly large vision-language models (VLMs), often prioritize performance over computational efficiency. These models typically process dense patch tokens for every frame, leading to prohibitive computational costs (FLOPs) and significant inference latency, especially with long video sequences. This focus limits their practical deployment in real-time autonomous driving scenarios. To tackle this issue, we propose an efficient VLM framework for autonomous driving VQA tasks, SRC-Pipeline. It learns to compress early frame tokens into a small number of high-level tokens while retaining full patch tokens for recent frames. Experiments on autonomous driving video question answering tasks show that our approach achieves 66% FLOPs reduction while maintaining comparable performance, enabling VLMs to operate more effectively in real-time, safety-critical autonomous driving settings.

</details>


### [79] [3D Wavelet-Based Structural Priors for Controlled Diffusion in Whole-Body Low-Dose PET Denoising](https://arxiv.org/abs/2601.07093)
*Peiyuan Jing,Yue Tang,Chun-Wun Cheng,Zhenxuan Zhang,Liutao Yang,Thiago V. Lima,Klaus Strobel,Antoine Leimgruber,Angelica Aviles-Rivero,Guang Yang,Javier Montoya*

Main category: cs.CV

TL;DR: 本文提出了一种新型的三维扩散模型——Wavelet-Conditioned ControlNet (WCC-Net)，通过引入小波域结构先验，有效提升低剂量PET图像的去噪效果，在多个实验和基准任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 低剂量PET成像虽然减少了患者的辐射暴露，但噪声明显增大，导致图像质量和诊断可靠性下降。扩散模型虽有优秀去噪性能，但易损失解剖结构连续性，特别是在信噪比较低的全身成像场景。因此，亟需一种能够兼顾去噪效果与解剖结构一致性的解决方案。

Method: 作者提出基于小波结构引导的3D扩散模型WCC-Net。其核心创新在于通过轻量级控制分支将小波域结构信息注入一个冻结的预训练扩散主干，从而实现去噪过程中的结构引导，既分离了噪声与结构又保持了生成能力和三维结构连续性。

Result: WCC-Net在低剂量(1/20)PET测试集上，PSNR比强扩散基线提升+1.21 dB，SSIM提升+0.008，同时结构失真（GMSD）和强度误差（NMAE）降低。模型还在未见过的剂量（1/50、1/4）测试下表现出很好的泛化能力和结构一致性。

Conclusion: WCC-Net能够在极低剂量PET影像中显著提升三维去噪表现，优于传统CNN、GAN及扩散模型基线，并具备良好的泛化能力和保持解剖结构一致性的优势。

Abstract: Low-dose Positron Emission Tomography (PET) imaging reduces patient radiation exposure but suffers from increased noise that degrades image quality and diagnostic reliability. Although diffusion models have demonstrated strong denoising capability, their stochastic nature makes it challenging to enforce anatomically consistent structures, particularly in low signal-to-noise regimes and volumetric whole-body imaging. We propose Wavelet-Conditioned ControlNet (WCC-Net), a fully 3D diffusion-based framework that introduces explicit frequency-domain structural priors via wavelet representations to guide volumetric PET denoising. By injecting wavelet-based structural guidance into a frozen pretrained diffusion backbone through a lightweight control branch, WCC-Net decouples anatomical structure from noise while preserving generative expressiveness and 3D structural continuity. Extensive experiments demonstrate that WCC-Net consistently outperforms CNN-, GAN-, and diffusion-based baselines. On the internal 1/20-dose test set, WCC-Net improves PSNR by +1.21 dB and SSIM by +0.008 over a strong diffusion baseline, while reducing structural distortion (GMSD) and intensity error (NMAE). Moreover, WCC-Net generalizes robustly to unseen dose levels (1/50 and 1/4), achieving superior quantitative performance and improved volumetric anatomical consistency.

</details>


### [80] [MEDVISTAGYM: A Scalable Training Environment for Thinking with Medical Images via Tool-Integrated Reinforcement Learning](https://arxiv.org/abs/2601.07107)
*Meng Lu,Yuxing Lu,Yuchen Zhuang,Megan Mullins,Yang Xie,Guanghua Xiao,Charles Fleming,Wenqi Shi,Xuan Wang*

Main category: cs.CV

TL;DR: 本文提出了MedVistaGym，一种为医学视觉-语言模型（VLMs）设计的可扩展、交互式训练环境，显著提升了模型在医学图像理解任务中的多步推理能力。


<details>
  <summary>Details</summary>
Motivation: 大多数通用VLM在医学图像多步推理任务中表现不佳，主要因为其依赖静态视觉嵌入和单次推理，无法有效进行工具选择和多模态推理。该问题阻碍了医学VLM应用于复杂任务的发展。

Method: 作者提出MedVistaGym训练框架，使模型在分析医学图像时能主动决定何时、如何调用工具，并将子图像信息多步集成到推理链中。该环境支持模型与工具的交互式训练，并采用了端到端强化学习优化。

Result: 训练得到的MedVistaGym-R1-8B模型，在六个医学视觉问答基准测试中，较同规模带工具增强的基线模型提升了19.10%到24.21%。

Conclusion: 结构化的agentic（自主代理）训练，而非单纯增加工具访问，是提升医学图像多工具推理能力的关键。MedVistaGym为这一方向提供了有效范例。

Abstract: Vision language models (VLMs) achieve strong performance on general image understanding but struggle to think with medical images, especially when performing multi-step reasoning through iterative visual interaction. Medical VLMs often rely on static visual embeddings and single-pass inference, preventing models from re-examining, verifying, or refining visual evidence during reasoning. While tool-integrated reasoning offers a promising path forward, open-source VLMs lack the training infrastructure to learn effective tool selection, invocation, and coordination in multi-modal medical reasoning. We introduce MedVistaGym, a scalable and interactive training environment that incentivizes tool-integrated visual reasoning for medical image analysis. MedVistaGym equips VLMs to determine when and which tools to invoke, localize task-relevant image regions, and integrate single or multiple sub-image evidence into interleaved multimodal reasoning within a unified, executable interface for agentic training. Using MedVistaGym, we train MedVistaGym-R1 to interleave tool use with agentic reasoning through trajectory sampling and end-to-end reinforcement learning. Across six medical VQA benchmarks, MedVistaGym-R1-8B exceeds comparably sized tool-augmented baselines by 19.10% to 24.21%, demonstrating that structured agentic training--not tool access alone--unlocks effective tool-integrated reasoning for medical image analysis.

</details>


### [81] [Few-shot Class-Incremental Learning via Generative Co-Memory Regularization](https://arxiv.org/abs/2601.07117)
*Kexin Bao,Yong Li,Dan Zeng,Shiming Ge*

Main category: cs.CV

TL;DR: 本文提出了一种生成式协同记忆正则化方法，用于提升FSCIL（小样本类增量学习）的表现，能够在有效防止旧类遗忘及新类过拟合的同时，提升识别准确率。


<details>
  <summary>Details</summary>
Motivation: FSCIL任务中，模型需要从极少的样本持续学习新类别，容易出现对旧类别遗忘和对新类别过拟合的问题。因此，亟需兼具强泛化和适应能力的方法，以提升增量学习表现。

Method: 方法包括生成式领域自适应微调，利用MAE解码器和全连接分类器共同微调预训练编码器，获得通用可迁移的特征表达。细致管理两类记忆：类别特征均值的表示记忆和分类器权重记忆，并在增量学习阶段以协同正则化方式动态优化分类器，同时更新上述记忆，实现类增量下的高效学习。

Result: 实验证明，该方法在多个主流基准上显著优于现有技术，有效提高识别准确率，并缓解了遗忘和过拟合问题。

Conclusion: 文中方法显著改善了FSCIL任务中的表现，能够协同防止模型遗忘与过拟合，兼具稳健性和准确性。

Abstract: Few-shot class-incremental learning (FSCIL) aims to incrementally learn models from a small amount of novel data, which requires strong representation and adaptation ability of models learned under few-example supervision to avoid catastrophic forgetting on old classes and overfitting to novel classes. This work proposes a generative co-memory regularization approach to facilitate FSCIL. In the approach, the base learning leverages generative domain adaptation finetuning to finetune a pretrained generative encoder on a few examples of base classes by jointly incorporating a masked autoencoder (MAE) decoder for feature reconstruction and a fully-connected classifier for feature classification, which enables the model to efficiently capture general and adaptable representations. Using the finetuned encoder and learned classifier, we construct two class-wise memories: representation memory for storing the mean features for each class, and weight memory for storing the classifier weights. After that, the memory-regularized incremental learning is performed to train the classifier dynamically on the examples of few-shot classes in each incremental session by simultaneously optimizing feature classification and co-memory regularization. The memories are updated in a class-incremental manner and they collaboratively regularize the incremental learning. In this way, the learned models improve recognition accuracy, while mitigating catastrophic forgetting over old classes and overfitting to novel classes. Extensive experiments on popular benchmarks clearly demonstrate that our approach outperforms the state-of-the-arts.

</details>


### [82] [Motion Focus Recognition in Fast-Moving Egocentric Video](https://arxiv.org/abs/2601.07154)
*Daniel Hong,James Tribble,Hao Wang,Chaoyi Zhou,Ashish Bastola,Siyu Huang,Abolfazl Razi*

Main category: cs.CV

TL;DR: 本文提出了一种实时运动聚焦识别方法，能够从第一视角视频中估计主体的运动意图，并实现高效实时推理，尤其适用于运动和高速移动场景。


<details>
  <summary>Details</summary>
Motivation: 现有第一视角数据集多关注动作识别，忽视了运动分析在体育等高速动作中的作用。因此，迫切需要能在相关场景中高效实现运动意图识别的方法。

Method: 方法基于主流的相机姿态估计基础模型，结合系统级推理优化，提出滑动批次推理策略，确保在边缘设备上实现低内存、实时处理。

Result: 在新收集的第一视角动作数据集上测试，方法实现了实时性能，并通过滑动批次推理显著降低了内存消耗。

Conclusion: 此方法让运动中心分析在边缘部署变为可行，丰富了现有针对运动和高速动作的第一视角研究。

Abstract: From Vision-Language-Action (VLA) systems to robotics, existing egocentric datasets primarily focus on action recognition tasks, while largely overlooking the inherent role of motion analysis in sports and other fast-movement scenarios. To bridge this gap, we propose a real-time motion focus recognition method that estimates the subject's locomotion intention from any egocentric video. Our approach leverages the foundation model for camera pose estimation and introduces system-level optimizations to enable efficient and scalable inference. Evaluated on a collected egocentric action dataset, our method achieves real-time performance with manageable memory consumption through a sliding batch inference strategy. This work makes motion-centric analysis practical for edge deployment and offers a complementary perspective to existing egocentric studies on sports and fast-movement activities.

</details>


### [83] [Test-time Adaptive Hierarchical Co-enhanced Denoising Network for Reliable Multimodal Classification](https://arxiv.org/abs/2601.07163)
*Shu Shen,C. L. Philip Chen,Tong Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为TAHCD的网络，用于在低质量多模态数据下实现更可靠的学习，并在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多模态数据中噪声广泛且复杂，现有方法难以去除异质噪声且在新噪声场景下适应性和泛化性有限。在安全关键应用中，这一问题尤为突出。

Method: 提出TAHCD（测试时自适应分层协同增强去噪网络），包括：自适应稳定子空间对齐、样本自适应置信度对齐（分别从全局和实例层面处理模态特有及跨模态噪声）；并通过测试时协同增强机制，自适应地（无需标签）对模型进行更新以提高适应性和泛化能力。

Result: 实验表明TAHCD在多个公开基准上的分类性能、鲁棒性和泛化性均超过当前最优多模态学习方法。

Conclusion: TAHCD能有效去除多模态数据中的复杂异质噪声，实现了更可靠和更具泛化能力的多模态学习，适合应用于对安全性要求高的场景。

Abstract: Reliable learning on low-quality multimodal data is a widely concerning issue, especially in safety-critical applications. However, multimodal noise poses a major challenge in this domain and leads existing methods to suffer from two key limitations. First, they struggle to reliably remove heterogeneous data noise, hindering robust multimodal representation learning. Second, they exhibit limited adaptability and generalization when encountering previously unseen noise. To address these issues, we propose Test-time Adaptive Hierarchical Co-enhanced Denoising Network (TAHCD). On one hand, TAHCD introduces the Adaptive Stable Subspace Alignment and Sample-Adaptive Confidence Alignment to reliably remove heterogeneous noise. They account for noise at both global and instance levels and enable jointly removal of modality-specific and cross-modality noise, achieving robust learning. On the other hand, TAHCD introduces test-time cooperative enhancement, which adaptively updates the model in response to input noise in a label-free manner, improving adaptability and generalization. This is achieved by collaboratively enhancing the joint removal process of modality-specific and cross-modality noise across global and instance levels according to sample noise. Experiments on multiple benchmarks demonstrate that the proposed method achieves superior classification performance, robustness, and generalization compared with state-of-the-art reliable multimodal learning approaches.

</details>


### [84] [DIVER: Dynamic Iterative Visual Evidence Reasoning for Multimodal Fake News Detection](https://arxiv.org/abs/2601.07178)
*Weilin Zhou,Zonghao Ying,Chunlei Meng,Jiahui Liu,Hengyang Zhou,Quanchen Zou,Deyue Zhang,Dongdong Yang,Xiangzheng Zhang*

Main category: cs.CV

TL;DR: 本文提出一种新颖的多模态假新闻检测方法DIVER，通过动态推理和逐步引入视觉证据，提升检测准确性并降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有多模态假新闻检测方法，如静态多模态融合和大模型（LLM）方案，受限于视觉基础弱、计算冗余与幻觉风险。因此，亟需一种更高效、鲁棒且能有效处理模态间证据差异的方法。

Method: DIVER框架采取逐步、基于证据的推理流程。首先，通过文本分析建立强大的文本基准，对文本内部一致性进行检查筛除不可靠或幻觉生成的信息；若文本证据不足，则自适应引入视觉证据，并通过模态对齐进一步判断是否需要更深入的视觉分析。对于存在显著语义差异的样本，DIVER会有选择地调用精细视觉工具（如OCR与密集描述），提取任务相关证据并进行不确定性感知融合，实现多模态推理。

Result: 在Weibo、Weibo21和GossipCop三个主流数据集上，DIVER相较于最先进方法平均性能提升2.72%，同时推理效率提升，延迟降低4.12秒。

Conclusion: DIVER通过动态、逐步引入视觉证据并自适应推理，能够更有效、更高效地进行多模态假新闻检测，优于当前主流方法。

Abstract: Multimodal fake news detection is crucial for mitigating adversarial misinformation. Existing methods, relying on static fusion or LLMs, face computational redundancy and hallucination risks due to weak visual foundations. To address this, we propose DIVER (Dynamic Iterative Visual Evidence Reasoning), a framework grounded in a progressive, evidence-driven reasoning paradigm. DIVER first establishes a strong text-based baseline through language analysis, leveraging intra-modal consistency to filter unreliable or hallucinated claims. Only when textual evidence is insufficient does the framework introduce visual information, where inter-modal alignment verification adaptively determines whether deeper visual inspection is necessary. For samples exhibiting significant cross-modal semantic discrepancies, DIVER selectively invokes fine-grained visual tools (e.g., OCR and dense captioning) to extract task-relevant evidence, which is iteratively aggregated via uncertainty-aware fusion to refine multimodal reasoning. Experiments on Weibo, Weibo21, and GossipCop demonstrate that DIVER outperforms state-of-the-art baselines by an average of 2.72\%, while optimizing inference efficiency with a reduced latency of 4.12 s.

</details>


### [85] [ShowUI-Aloha: Human-Taught GUI Agent](https://arxiv.org/abs/2601.07181)
*Yichun Zhang,Xiangwu Guo,Yauhong Goh,Jessica Hu,Zhiheng Chen,Xin Wang,Difei Gao,Mike Zheng Shou*

Main category: cs.CV

TL;DR: 本文提出了一套名为ShowUI-Aloha的流水线，可以将未经结构化处理的真实人类屏幕录制转化为结构化、可操作的任务，对通用GUI智能体的训练具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 目前自动化GUI任务面临主要难题是缺乏可扩展、高质量的训练数据。虽然现实中存在大量人类操作录屏数据，但它们通常时间长、结构混乱且无注释，难以直接用于智能体学习。

Method: 提出了ShowUI-Aloha流水线，包括四个关键模块：1）录制器，捕获屏幕及用户精细交互数据（鼠标、键盘、滚动）；2）学习器，语义解析交互和视觉上下文并生成自然语言描述；3）规划器，解析操作、维持任务状态并基于上下文推理出高层操作计划；4）执行器，在操作系统层精确还原并执行这些动作，带安全检查和实时反馈。

Result: 该框架能够高效收集和解析真实用户数据，成功将无结构的人机交互录制转为可供智能体学习的结构化任务数据。

Conclusion: ShowUI-Aloha展示了利用人类演示数据来构建通用GUI智能体的可行之路，有望推动更高效的界面自动化及人机协作。

Abstract: Graphical User Interfaces (GUIs) are central to human-computer interaction, yet automating complex GUI tasks remains a major challenge for autonomous agents, largely due to a lack of scalable, high-quality training data. While recordings of human demonstrations offer a rich data source, they are typically long, unstructured, and lack annotations, making them difficult for agents to learn from.To address this, we introduce ShowUI-Aloha, a comprehensive pipeline that transforms unstructured, in-the-wild human screen recordings from desktop environments into structured, actionable tasks. Our framework includes four key components: A recorder that captures screen video along with precise user interactions like mouse clicks, keystrokes, and scrolls. A learner that semantically interprets these raw interactions and the surrounding visual context, translating them into descriptive natural language captions. A planner that reads the parsed demonstrations, maintains task states, and dynamically formulates the next high-level action plan based on contextual reasoning. An executor that faithfully carries out these action plans at the OS level, performing precise clicks, drags, text inputs, and window operations with safety checks and real-time feedback. Together, these components provide a scalable solution for collecting and parsing real-world human data, demonstrating a viable path toward building general-purpose GUI agents that can learn effectively from simply observing humans.

</details>


### [86] [SIRR-LMM: Single-image Reflection Removal via Large Multimodal Model](https://arxiv.org/abs/2601.07209)
*Yu Guo,Zhiqiang Lao,Xiyun Song,Yubin Zhou,Heather Yu*

Main category: cs.CV

TL;DR: 本论文提出了一种利用3D玻璃模型路径追踪和真实背景生成物理真实合成数据集，并通过大模型多模态技术改进单幅图像反射去除（SIRR）表现的方法。


<details>
  <summary>Details</summary>
Motivation: 现有单幅图像反射去除（SIRR）研究中，合成数据集物理真实性不足，而真实拍摄数据规模有限，限制了相关算法研究和应用。

Method: 作者提出用路径追踪对3D玻璃模型叠加于真实背景图像生成物理真实的合成数据集，控制玻璃属性、相机参数和后处理效果多样性。在算法上，将图像分层拼接后进行联合描述（captions），采用LoRA进行大语言视觉模型微调，实现高效训练。

Result: 实验表明，所提方法在反射去除与前景背景分离任务上优于当前主流方法。

Conclusion: 通过更真实的数据生成和大模型的高效微调，本文方法提升了SIRR问题的处理效果，为后续相关应用和研究提供了更优的解决方案。

Abstract: Glass surfaces create complex interactions of reflected and transmitted light, making single-image reflection removal (SIRR) challenging. Existing datasets suffer from limited physical realism in synthetic data or insufficient scale in real captures. We introduce a synthetic dataset generation framework that path-traces 3D glass models over real background imagery to create physically accurate reflection scenarios with varied glass properties, camera settings, and post-processing effects. To leverage the capabilities of Large Multimodal Model (LMM), we concatenate the image layers into a single composite input, apply joint captioning, and fine-tune the model using task-specific LoRA rather than full-parameter training. This enables our approach to achieve improved reflection removal and separation performance compared to state-of-the-art methods.

</details>


### [87] [SceneNAT: Masked Generative Modeling for Language-Guided Indoor Scene Synthesis](https://arxiv.org/abs/2601.07218)
*Jeongjun Choi,Yeonsoo Park,H. Jin Kim*

Main category: cs.CV

TL;DR: 本文提出了SceneNAT，一种高效的单阶段非自回归Transformer模型，实现了从自然语言直接高效生成3D室内场景，并在表现和效率上超过了现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前3D室内场景生成方法普遍存在效率低下、难以满足复杂语义和空间关系建模等问题，因此亟需一种既高效又能精准理解语义指令的生成方法。

Method: SceneNAT采用掩码建模，在完全离散化的语义和空间属性上训练，通过在属性和实例层级施加掩码以更好捕捉物体内外部结构。该方法还引入了专用三元组预测器，用于更有效地表达对象间的布局和关系。

Result: SceneNAT在3D-FRONT数据集上进行了大量实验，在语义符合性和空间排列准确度上均优于现有自回归和扩散模型，同时计算成本大幅降低。

Conclusion: SceneNAT为3D室内场景生成提供了一种高效且高性能的解决方案，显著提升了生成质量和效率，为相关应用提供了支持。

Abstract: We present SceneNAT, a single-stage masked non-autoregressive Transformer that synthesizes complete 3D indoor scenes from natural language instructions through only a few parallel decoding passes, offering improved performance and efficiency compared to prior state-of-the-art approaches. SceneNAT is trained via masked modeling over fully discretized representations of both semantic and spatial attributes. By applying a masking strategy at both the attribute level and the instance level, the model can better capture intra-object and inter-object structure. To boost relational reasoning, SceneNAT employs a dedicated triplet predictor for modeling the scene's layout and object relationships by mapping a set of learnable relation queries to a sparse set of symbolic triplets (subject, predicate, object). Extensive experiments on the 3D-FRONT dataset demonstrate that SceneNAT achieves superior performance compared to state-of-the-art autoregressive and diffusion baselines in both semantic compliance and spatial arrangement accuracy, while operating with substantially lower computational cost.

</details>


### [88] [VENUS: Visual Editing with Noise Inversion Using Scene Graphs](https://arxiv.org/abs/2601.07219)
*Thanh-Nhan Vo,Trong-Thuan Nguyen,Tam V. Nguyen,Minh-Triet Tran*

Main category: cs.CV

TL;DR: 提出了一种全新的、无需训练的图像编辑框架VENUS，在保证背景保真的同时提升了语义一致性，并大幅降低了运算时间。


<details>
  <summary>Details</summary>
Motivation: 现有的文本驱动图像编辑方法难以兼顾背景保真和语义一致性，而基于场景图的方法尽管控制力好，却需模型微调，计算成本高、扩展性差。作者希望实现无需训练且高效、保真、易扩展的场景图引导图像编辑方法。

Method: 提出VENUS，该方法利用噪声逆变+场景图进行编辑，并采用分离目标物体与背景上下文的提示分割策略。VENUS将多模态大模型提取的场景图与扩散模型结合，无需额外训练即可实现高效编辑。

Result: 在PIE-Bench和EditVal等数据集上，VENUS在背景保真（PSNR、SSIM）和语义一致性（CLIP相似度、DINO分数）指标上均显著超越了SGEdit等先进方法，同时单张图编辑时间由6-10分钟降至20-30秒，且在文本驱动基线下同样表现优异。

Conclusion: VENUS实现了无需训练的高效场景图引导图像编辑，兼顾了背景保真与编辑语义一致性，并大幅降低计算成本，拓展性强，适用于多种图像编辑场景。

Abstract: State-of-the-art text-based image editing models often struggle to balance background preservation with semantic consistency, frequently resulting either in the synthesis of entirely new images or in outputs that fail to realize the intended edits. In contrast, scene graph-based image editing addresses this limitation by providing a structured representation of semantic entities and their relations, thereby offering improved controllability. However, existing scene graph editing methods typically depend on model fine-tuning, which incurs high computational cost and limits scalability. To this end, we introduce VENUS (Visual Editing with Noise inversion Using Scene graphs), a training-free framework for scene graph-guided image editing. Specifically, VENUS employs a split prompt conditioning strategy that disentangles the target object of the edit from its background context, while simultaneously leveraging noise inversion to preserve fidelity in unedited regions. Moreover, our proposed approach integrates scene graphs extracted from multimodal large language models with diffusion backbones, without requiring any additional training. Empirically, VENUS substantially improves both background preservation and semantic alignment on PIE-Bench, increasing PSNR from 22.45 to 24.80, SSIM from 0.79 to 0.84, and reducing LPIPS from 0.100 to 0.070 relative to the state-of-the-art scene graph editing model (SGEdit). In addition, VENUS enhances semantic consistency as measured by CLIP similarity (24.97 vs. 24.19). On EditVal, VENUS achieves the highest fidelity with a 0.87 DINO score and, crucially, reduces per-image runtime from 6-10 minutes to only 20-30 seconds. Beyond scene graph-based editing, VENUS also surpasses strong text-based editing baselines such as LEDIT++ and P2P+DirInv, thereby demonstrating consistent improvements across both paradigms.

</details>


### [89] [Language-Grounded Multi-Domain Image Translation via Semantic Difference Guidance](https://arxiv.org/abs/2601.07221)
*Jongwon Ryu,Joonhyung Park,Jaeho Han,Yeong-Seok Kim,Hye-rin Kim,Sunjae Yoon,Junyeong Kim*

Main category: cs.CV

TL;DR: 提出了LACE方法，实现了基于自然语言多域可控图像翻译，显著提升了结构保留和属性控制能力，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多域图像翻译方法难以在涉及多个域时保持结构完整和实现细粒度属性控制，尤其是将自然语言描述映射为准确的视觉变化时表现不佳。

Method: 提出LACE模型，包含两大模块：（1）GLIP-Adapter用于融合全局语义和局部结构，实现一致性；（2）多域控制引导机制，将源/目标语言描述的语义差异映射为逐属性翻译向量，精细对齐语义与图像变化。实现了多属性独立且可控的翻译。

Result: 在CelebA(Dialog)和BDD100K数据集上，LACE在图像保真度、结构保留和解释性、多域控制能力等方面均超越主流基线方法。

Conclusion: LACE作为跨模态内容生成框架，有效桥接了语言语义与可控视觉翻译，推进了多域、属性可控的图像生成研究。

Abstract: Multi-domain image-to-image translation re quires grounding semantic differences ex pressed in natural language prompts into corresponding visual transformations, while preserving unrelated structural and seman tic content. Existing methods struggle to maintain structural integrity and provide fine grained, attribute-specific control, especially when multiple domains are involved. We propose LACE (Language-grounded Attribute Controllable Translation), built on two compo nents: (1) a GLIP-Adapter that fuses global semantics with local structural features to pre serve consistency, and (2) a Multi-Domain Control Guidance mechanism that explicitly grounds the semantic delta between source and target prompts into per-attribute translation vec tors, aligning linguistic semantics with domain level visual changes. Together, these modules enable compositional multi-domain control with independent strength modulation for each attribute. Experiments on CelebA(Dialog) and BDD100K demonstrate that LACE achieves high visual fidelity, structural preservation, and interpretable domain-specific control, surpass ing prior baselines. This positions LACE as a cross-modal content generation framework bridging language semantics and controllable visual translation.

</details>


### [90] [Universal Adversarial Purification with DDIM Metric Loss for Stable Diffusion](https://arxiv.org/abs/2601.07253)
*Li Zheng,Liangbin Xie,Jiantao Zhou,He YiMin*

Main category: cs.CV

TL;DR: 本文提出了UDAP框架，用于针对Stable Diffusion模型的对抗性攻击进行净化，显著提升了模型在各类攻击下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: Stable Diffusion（SD）模型在训练集包含对抗性噪声时，输出质量容易下降。现有的对抗性净化方法主要针对分类任务，难以应对SD模型中特有的攻击策略（如VAE编码器、UNet去噪器目标等），因此亟需专门针对SD模型的防御方法。

Method: 提出了Universal Diffusion Adversarial Purification（UDAP）框架，该框架利用Denoising Diffusion Implicit Models（DDIM）反演过程中干净与对抗图片的重构差异，引入DDIM度量损失最小化准则以去除对抗性噪声。此外采用动态迭代轮次调整机制，根据重构误差动态优化循环次数，提高效率且不损失净化效果。

Result: 实验结果表明，UDAP在应对多种对抗方法（包括PID、Anti-DreamBooth、MIST及Anti-Diffusion、MetaCloak等增强型方法）时表现出较强鲁棒性，并可在多个SD模型版本和不同文本提示下良好泛化。

Conclusion: UDAP可以有效提升Stable Diffusion模型在多种对抗性攻击下的安全性和实际应用中的可靠性，具备广泛的应用前景。

Abstract: Stable Diffusion (SD) often produces degraded outputs when the training dataset contains adversarial noise. Adversarial purification offers a promising solution by removing adversarial noise from contaminated data. However, existing purification methods are primarily designed for classification tasks and fail to address SD-specific adversarial strategies, such as attacks targeting the VAE encoder, UNet denoiser, or both. To address the gap in SD security, we propose Universal Diffusion Adversarial Purification (UDAP), a novel framework tailored for defending adversarial attacks targeting SD models. UDAP leverages the distinct reconstruction behaviors of clean and adversarial images during Denoising Diffusion Implicit Models (DDIM) inversion to optimize the purification process. By minimizing the DDIM metric loss, UDAP can effectively remove adversarial noise. Additionally, we introduce a dynamic epoch adjustment strategy that adapts optimization iterations based on reconstruction errors, significantly improving efficiency without sacrificing purification quality. Experiments demonstrate UDAP's robustness against diverse adversarial methods, including PID (VAE-targeted), Anti-DreamBooth (UNet-targeted), MIST (hybrid), and robustness-enhanced variants like Anti-Diffusion (Anti-DF) and MetaCloak. UDAP also generalizes well across SD versions and text prompts, showcasing its practical applicability in real-world scenarios.

</details>


### [91] [From Landslide Conditioning Factors to Satellite Embeddings: Evaluating the Utilisation of Google AlphaEarth for Landslide Susceptibility Mapping using Deep Learning](https://arxiv.org/abs/2601.07268)
*Yusen Cheng,Qinfeng Zhu,Lei Fan*

Main category: cs.CV

TL;DR: 本研究探讨了Google AlphaEarth嵌入向量作为滑坡易发性制图（LSM）预测因子的可行性，并与传统滑坡影响因子（LCFs）进行了多种模型和地区下的系统对比。结果表明，AlphaEarth嵌入在精度和稳定性上明显优于传统因子。


<details>
  <summary>Details</summary>
Motivation: 滑坡易发性制图高度依赖各种影响因子，这些因子的获取与预处理存在不确定性，影响制图效果。近年来，多源遥感数据嵌入（如AlphaEarth）提供了统一且信息丰富的地表表征方式，有望优化LSM方法。

Method: 在台湾南投、香港、意大利埃米利亚-罗马涅三个区域，使用三种深度学习模型（1D-CNN、2D-CNN和Vision Transformer），分别比较传统LCFs和两种AlphaEarth嵌入（保留主成分与全部64维嵌入）的表现。评估指标包括ROC-AUC、F1-score、误差统计与空间分布一致性。

Result: 在所有地区和模型中，基于AlphaEarth嵌入的模型，F1分数提升约4%-15%，AUC提升0.04-0.11，误差更稳定，空间分布与实际滑坡更吻合，尤其是在采用全部64维嵌入时效果最佳。该优势在南投与意大利地区尤为显著。

Conclusion: AlphaEarth嵌入作为标准化且富含地表信息的新型预测因子，在滑坡易发性制图中展现出强大潜力，可为这一领域带来更高效和稳健的分析工具。

Abstract: Data-driven landslide susceptibility mapping (LSM) typically relies on landslide conditioning factors (LCFs), whose availability, heterogeneity, and preprocessing-related uncertainties can constrain mapping reliability. Recently, Google AlphaEarth (AE) embeddings, derived from multi-source geospatial observations, have emerged as a unified representation of Earth surface conditions. This study evaluated the potential of AE embeddings as alternative predictors for LSM. Two AE representations, including retained principal components and the full set of 64 embedding bands, were systematically compared with conventional LCFs across three study areas (Nantou County, Taiwan; Hong Kong; and part of Emilia-Romagna, Italy) using three deep learning models (CNN1D, CNN2D, and Vision Transformer). Performance was assessed using multiple evaluation metrics, ROC-AUC analysis, error statistics, and spatial pattern assessment. Results showed that AE-based models consistently outperformed LCFs across all regions and models, yielding higher F1-scores, AUC values, and more stable error distributions. Such improvement was most pronounced when using the full 64-band AE representation, with F1-score improvements of approximately 4% to 15% and AUC increased ranging from 0.04 to 0.11, depending on the study area and model. AE-based susceptibility maps also exhibited clearer spatial correspondence with observed landslide occurrences and enhanced sensitivity to localised landslide-prone conditions. Performance improvements were more evident in Nantou and Emilia than in Hong Kong, revealing that closer temporal alignment between AE embeddings and landslide inventories may lead to more effective LSM outcomes. These findings highlight the strong potential of AE embeddings as a standardised and information-rich alternative to conventional LCFs for LSM.

</details>


### [92] [PALUM: Part-based Attention Learning for Unified Motion Retargeting](https://arxiv.org/abs/2601.07272)
*Siqi Liu,Maoyu Wang,Bo Dai,Cewu Lu*

Main category: cs.CV

TL;DR: PALUM方法通过将关节划分为语义身体部位，并结合注意力机制，学习不同骨架结构下的通用运动表示，实现高质量、高语义一致性的动作重定向。


<details>
  <summary>Details</summary>
Motivation: 面对源对象和目标对象骨骼结构差异巨大时，传统动作重定向方法难以兼顾动作语义和质量，解决骨架无关的高保真动作迁移成为迫切需求。

Method: 首先将关节根据语义划分为不同身体部位，再采用注意力机制建模时空关系，学习针对不同骨架结构的通用动作表示；动作迁移时结合目标骨架的特定结构信息，并引入循环一致性机制，保持全流程的语义连贯性。

Result: 在各种骨架结构及运动场景下，PALUM在保持动作真实感和语义一致性上效果优于其他方法，且能泛化至未见过的骨架与动作组合。

Conclusion: PALUM有效提升了针对多样骨架结构的动作重定向质量，具有很好的通用性和语义保持能力，将为后续相关研究提供工具支持。

Abstract: Retargeting motion between characters with different skeleton structures is a fundamental challenge in computer animation. When source and target characters have vastly different bone arrangements, maintaining the original motion's semantics and quality becomes increasingly difficult. We present PALUM, a novel approach that learns common motion representations across diverse skeleton topologies by partitioning joints into semantic body parts and applying attention mechanisms to capture spatio-temporal relationships. Our method transfers motion to target skeletons by leveraging these skeleton-agnostic representations alongside target-specific structural information. To ensure robust learning and preserve motion fidelity, we introduce a cycle consistency mechanism that maintains semantic coherence throughout the retargeting process. Extensive experiments demonstrate superior performance in handling diverse skeletal structures while maintaining motion realism and semantic fidelity, even when generalizing to previously unseen skeleton-motion combinations. We will make our implementation publicly available to support future research.

</details>


### [93] [GenDet: Painting Colored Bounding Boxes on Images via Diffusion Model for Object Detection](https://arxiv.org/abs/2601.07273)
*Chen Min,Chengyang Li,Fanjie Kong,Qi Zhu,Dawei Zhao,Liang Xiao*

Main category: cs.CV

TL;DR: GenDet提出用生成式模型进行目标检测，直接生成含有语义注释的边界框，准确性可与传统方法媲美，且保留生成模型的灵活性。


<details>
  <summary>Details</summary>
Motivation: 传统目标检测采用判别式方法，往往设计复杂，难以与生成模型统一，缺乏灵活性。该论文希望探索用生成模型统一视觉理解任务。

Method: 使用大规模预训练的Stable Diffusion模型，将目标检测任务设为在潜变量空间加入语义约束的条件生成任务，根据输入图片直接生成包含位置信息和类别的边界框。

Result: GenDet在准确率上与传统判别式检测器相当，同时拥有生成模型的灵活性。

Conclusion: GenDet为视觉理解提供了判别与生成一体的新思路，拓展了生成模型的应用边界。

Abstract: This paper presents GenDet, a novel framework that redefines object detection as an image generation task. In contrast to traditional approaches, GenDet adopts a pioneering approach by leveraging generative modeling: it conditions on the input image and directly generates bounding boxes with semantic annotations in the original image space. GenDet establishes a conditional generation architecture built upon the large-scale pre-trained Stable Diffusion model, formulating the detection task as semantic constraints within the latent space. It enables precise control over bounding box positions and category attributes, while preserving the flexibility of the generative model. This novel methodology effectively bridges the gap between generative models and discriminative tasks, providing a fresh perspective for constructing unified visual understanding systems. Systematic experiments demonstrate that GenDet achieves competitive accuracy compared to discriminative detectors, while retaining the flexibility characteristic of generative methods.

</details>


### [94] [Focal Guidance: Unlocking Controllability from Semantic-Weak Layers in Video Diffusion Models](https://arxiv.org/abs/2601.07287)
*Yuanyang Yin,Yufan Deng,Shenghai Yuan,Kaipeng Zhang,Xiao Yang,Feng Zhao*

Main category: cs.CV

TL;DR: 本论文针对图像到视频生成（I2V）任务提出了一种名为Focal Guidance (FG) 的方法，提高了生成视频对文本指令的遵循性。该方法在性能基准上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有I2V扩散模型过于关注视觉一致性，却未能深入探索如何结合视觉与文本的双重引导，以确保对文本指令的强遵从性。

Method: 作者提出Focal Guidance方法，包括两个机制：1）细粒度语义引导（FSG），利用CLIP识别参考帧关键区域并用于引导语义弱层；2）注意力缓存，将有语义响应的层的注意力图传递给语义弱响应层，增强其对文本的响应。

Result: 在作者新构建的I2V指令遵循性评测基准上，FG方法将Wan2.1-I2V总分提升至0.7250（提升3.97%），MMDiT基础的HunyuanVideo-I2V提升至0.5571（提升7.44%）。

Conclusion: Focal Guidance不仅在提升视频对文本指令遵循性方面有效，而且具有良好的通用性，为I2V领域带来了新的评测基准。

Abstract: The task of Image-to-Video (I2V) generation aims to synthesize a video from a reference image and a text prompt. This requires diffusion models to reconcile high-frequency visual constraints and low-frequency textual guidance during the denoising process. However, while existing I2V models prioritize visual consistency, how to effectively couple this dual guidance to ensure strong adherence to the text prompt remains underexplored. In this work, we observe that in Diffusion Transformer (DiT)-based I2V models, certain intermediate layers exhibit weak semantic responses (termed Semantic-Weak Layers), as indicated by a measurable drop in text-visual similarity. We attribute this to a phenomenon called Condition Isolation, where attention to visual features becomes partially detached from text guidance and overly relies on learned visual priors. To address this, we propose Focal Guidance (FG), which enhances the controllability from Semantic-Weak Layers. FG comprises two mechanisms: (1) Fine-grained Semantic Guidance (FSG) leverages CLIP to identify key regions in the reference frame and uses them as anchors to guide Semantic-Weak Layers. (2) Attention Cache transfers attention maps from semantically responsive layers to Semantic-Weak Layers, injecting explicit semantic signals and alleviating their over-reliance on the model's learned visual priors, thereby enhancing adherence to textual instructions. To further validate our approach and address the lack of evaluation in this direction, we introduce a benchmark for assessing instruction following in I2V models. On this benchmark, Focal Guidance proves its effectiveness and generalizability, raising the total score on Wan2.1-I2V to 0.7250 (+3.97\%) and boosting the MMDiT-based HunyuanVideo-I2V to 0.5571 (+7.44\%).

</details>


### [95] [VideoLoom: A Video Large Language Model for Joint Spatial-Temporal Understanding](https://arxiv.org/abs/2601.07290)
*Jiapeng Shi,Junke Wang,Zuyao You,Bo He,Zuxuan Wu*

Main category: cs.CV

TL;DR: 本文提出了VideoLoom，一个统一的视频大语言模型（Video LLM），实现空间和时间的联合理解，并提供了新的数据集与评测基准。


<details>
  <summary>Details</summary>
Motivation: 当前视频理解任务面临空间和时间信息难以统一处理的问题，现有模型难以同时精细地进行空间位置和时间段的关联。缺乏高质量数据和全面性评测基准也限制了模型性能。

Method: 作者提出VideoLoom模型，并构建了LoomData-8.7k数据集（带有时间锚点和空间定位的描述），以及用于多元评测的LoomBench基准。模型在多个空间和时间任务上进行了联合训练和评测。

Result: VideoLoom在多个空间（如ReVOS J&F 63.1）和时间（如Charades-STA 48.3 R1@0.7）基准数据集上达到SOTA或极具竞争力的表现。LoomBench能够更全面地评估视频大模型的能力。

Conclusion: 该工作提供了一种有效的空间-时间视频理解新范式，推动了多模态智能领域的发展，并为后续研究建立了新标准。

Abstract: This paper presents VideoLoom, a unified Video Large Language Model (Video LLM) for joint spatial-temporal understanding. To facilitate the development of fine-grained spatial and temporal localization capabilities, we curate LoomData-8.7k, a human-centric video dataset with temporally grounded and spatially localized captions. With this, VideoLoom achieves state-of-the-art or highly competitive performance across a variety of spatial and temporal benchmarks (e.g., 63.1 J&F on ReVOS for referring video object segmentation, and 48.3 R1@0.7 on Charades-STA for temporal grounding). In addition, we introduce LoomBench, a novel benchmark consisting of temporal, spatial, and compositional video-question pairs, enabling a comprehensive evaluation of Video LLMs from diverse aspects. Collectively, these contributions offer a universal and effective suite for joint spatial-temporal video understanding, setting a new standard in multimodal intelligence.

</details>


### [96] [A Visual Semantic Adaptive Watermark grounded by Prefix-Tuning for Large Vision-Language Model](https://arxiv.org/abs/2601.07291)
*Qi Zheng,Shuliang Liu,Yu Huang,Sihang Jia,Jungang Li,Lyuhao Chen,Junhao Chen,Hanqian Li,Aiwei Liu,Yibo Yan,Xuming Hu*

Main category: cs.CV

TL;DR: 本文提出了一种新型视觉-语义自适应水印（VISA-Mark）方法，能在保护视觉一致性和语义准确性的同时，提高水印检测的准确率和鲁棒性，并且保证高效的推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉-语言模型中的水印方案存在两个主要问题：一是与视觉无关的水印会引入无关信息，破坏图文对齐；二是部分考虑语义的方法由于采用拒绝采样，导致推理延迟过高。因此，亟需一种既能嵌入高质量水印、又能充分保持视觉和语义一致性的高效方法。

Method: 作者提出VISA-Mark，利用轻量级prefix-tuning技术，从视觉输入中动态提取Visual-Evidence Weights，量化每个候选token与视觉内容的关系。该权重用于自适应调整词汇划分和对logits扰动，使具备视觉支撑的token承担更多水印信息，从而提升图文对齐和水印嵌入质量。

Result: 实验证明，VISA-Mark在视觉一致性（Chair-I提升7.8%）、语义保真度显著优于传统方法。同时，水印检测AUC高达96.88%、对攻击鲁棒性达到99.3%，整体推理速度未显著受损。

Conclusion: VISA-Mark作为一种视觉语义自适应的水印框架，有效平衡了视觉和语义的保真度，实现了高效、鲁棒且易检测的多模态水印嵌入，为保护多模态模型内容的可追溯性树立了新标杆。

Abstract: Watermarking has emerged as a pivotal solution for content traceability and intellectual property protection in Large Vision-Language Models (LVLMs). However, vision-agnostic watermarks introduce visually irrelevant tokens and disrupt visual grounding by enforcing indiscriminate pseudo-random biases, while some semantic-aware methods incur prohibitive inference latency due to rejection sampling. In this paper, we propose the VIsual Semantic Adaptive Watermark (VISA-Mark), a novel framework that embeds detectable signals while strictly preserving visual fidelity. Our approach employs a lightweight, efficiently trained prefix-tuner to extract dynamic Visual-Evidence Weights, which quantify the evidentiary support for candidate tokens based on the visual input. These weights guide an adaptive vocabulary partitioning and logits perturbation mechanism, concentrating watermark strength specifically on visually-supported tokens. By actively aligning the watermark with visual evidence, VISA-Mark effectively maintains visual fidelity. Empirical results confirm that VISA-Mark outperforms conventional methods with a 7.8% improvement in visual consistency (Chair-I) and superior semantic fidelity. The framework maintains highly competitive detection accuracy (96.88% AUC) and robust attack resilience (99.3%) without sacrificing inference efficiency, effectively establishing a new standard for reliability-preserving multimodal watermarking.

</details>


### [97] [Inference-Time Scaling for Visual AutoRegressive modeling by Searching Representative Samples](https://arxiv.org/abs/2601.07293)
*Weidong Tang,Xinyan Wan,Siyu Li,Xiumei Wang*

Main category: cs.CV

TL;DR: 该论文提出了VAR-Scaling，这是首个适用于向量量化视觉自回归模型（VAR）推理阶段的扩展框架，有效提升了生成样本的质量和多样性。


<details>
  <summary>Details</summary>
Motivation: 虽然大型模型推理时的扩展技术大幅度提升了生成质量，但在VQ视觉自回归模型上的应用仍未被探索。VQ模型离散的潜变量空间使得传统的连续采样策略不可用，因此需要新的推理方法以改善生成表现。

Method: 提出了一种通过核密度估计（KDE）将采样空间映射到准连续特征空间的方法。在该特征空间中，高密度样本可视为高质量、稳定的解。论文设计了一种密度自适应混合采样策略：Top-k采样针对高密度区域以提升样本质量，Random-k采样探索低密度区域以维持多样性，防止模型收敛过早。

Result: 在类别条件生成和文本到图像的评测任务中，VAR-Scaling显著提升了模型推理过程中的生成质量和多样性。

Conclusion: VAR-Scaling为VQ视觉自回归模型提供了一套有效的推理时间采样扩展方法，在保持样本多样性的同时，大幅提升了输出质量。

Abstract: While inference-time scaling has significantly enhanced generative quality in large language and diffusion models, its application to vector-quantized (VQ) visual autoregressive modeling (VAR) remains unexplored. We introduce VAR-Scaling, the first general framework for inference-time scaling in VAR, addressing the critical challenge of discrete latent spaces that prohibit continuous path search. We find that VAR scales exhibit two distinct pattern types: general patterns and specific patterns, where later-stage specific patterns conditionally optimize early-stage general patterns. To overcome the discrete latent space barrier in VQ models, we map sampling spaces to quasi-continuous feature spaces via kernel density estimation (KDE), where high-density samples approximate stable, high-quality solutions. This transformation enables effective navigation of sampling distributions. We propose a density-adaptive hybrid sampling strategy: Top-k sampling focuses on high-density regions to preserve quality near distribution modes, while Random-k sampling explores low-density areas to maintain diversity and prevent premature convergence. Consequently, VAR-Scaling optimizes sample fidelity at critical scales to enhance output quality. Experiments in class-conditional and text-to-image evaluations demonstrate significant improvements in inference process. The code is available at https://github.com/WD7ang/VAR-Scaling.

</details>


### [98] [Mimic Human Cognition, Master Multi-Image Reasoning: A Meta-Action Framework for Enhanced Visual Understanding](https://arxiv.org/abs/2601.07298)
*Jianghao Yin,Qingbin Li,Kun Sun,Cheng Ding,Jie Wang,Qin Chen,Jie Zhou,Nan Wang,Changqing Li,Pei Wu,Jian Xu,Zheming Yang,Liang He*

Main category: cs.CV

TL;DR: 本文提出了CINEMA认知启发元动作框架，将多图推理分解为五个结构化的步骤，显著提升了多图、多帧、多任务推理的表现，在多个基准上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型虽然在单图像理解上表现优异，但在多图像推理中表现明显下降，主要因多图间关系复杂且关键信息分散，亟需更有效的推理机制。

Method: 提出CINEMA框架，将多图推理分解为全局、聚焦、提示、思考和回答五个类似人类认知的结构化步骤。冷启动阶段，利用检索式树采样方法生成高质量推理轨迹。强化学习阶段，采用两阶段方法：先用多样性保持策略探索，后用退火式DAPO增强利用。该框架利用新构建的多模态数据集进行训练。

Result: 在多图推理、视频理解及单图像等多个基准集上进行大量实验，CINEMA在MUIR、MVMath等任务上超越GPT-4o，在视频推理上优于专业视频模型。

Conclusion: 以人类认知为启发的推理框架有效提升了多图推理能力，具有良好的泛化性和实用价值。

Abstract: While Multimodal Large Language Models (MLLMs) excel at single-image understanding, they exhibit significantly degraded performance in multi-image reasoning scenarios. Multi-image reasoning presents fundamental challenges including complex inter-relationships between images and scattered critical information across image sets. Inspired by human cognitive processes, we propose the Cognition-Inspired Meta-Action Framework (CINEMA), a novel approach that decomposes multi-image reasoning into five structured meta-actions: Global, Focus, Hint, Think, and Answer which explicitly modeling the sequential cognitive steps humans naturally employ. For cold-start training, we introduce a Retrieval-Based Tree Sampling strategy that generates high-quality meta-action trajectories to bootstrap the model with reasoning patterns. During reinforcement learning, we adopt a two-stage paradigm: an exploration phase with Diversity-Preserving Strategy to avoid entropy collapse, followed by an annealed exploitation phase with DAPO to gradually strengthen exploitation. To train our model, we construct a dataset of 57k cold-start and 58k reinforcement learning instances spanning multi-image, multi-frame, and single-image tasks. We conduct extensive evaluations on multi-image reasoning benchmarks, video understanding benchmarks, and single-image benchmarks, achieving competitive state-of-the-art performance on several key benchmarks. Our model surpasses GPT-4o on the MUIR and MVMath benchmarks and notably outperforms specialized video reasoning models on video understanding benchmarks, demonstrating the effectiveness and generalizability of our human cognition-inspired reasoning framework.

</details>


### [99] [Revisiting the Ordering of Channel and Spatial Attention: A Comprehensive Study on Sequential and Parallel Designs](https://arxiv.org/abs/2601.07310)
*Zhongming Liu,Bingbing Jiang*

Main category: cs.CV

TL;DR: 本文系统比较了通道注意力与空间注意力的不同组合方式，并提出了在不同数据规模和任务场景下选择最佳注意力融合结构的原则。


<details>
  <summary>Details</summary>
Motivation: 注意力机制是深度学习中重要的构件，但目前其空间与通道注意力的组合方式（串行或并行）大多依赖经验，缺乏系统性分析与统一指导。

Method: 作者构建了一个统一的评测框架，涵盖18种主流注意力组合拓扑（包括串行、并行、多尺度、残差等），并在2个视觉与9个医学数据集上进行了系统实验和对比分析。

Result: 发现了数据规模、方法与性能之间的耦合规律：少样本任务下以“通道-多尺度空间”级联结构最佳；中等规模任务中并行可学习融合架构效果最好；大规模任务中带动态门控的并行结构表现优异。此外，“空间-通道”顺序对细粒度分类更稳定有效，残差结构可缓解不同规模下的梯度消失问题。

Conclusion: 总结并提出了基于具体场景选择注意力模块的实用指导原则，为后续模型设计提供了系统化建议。

Abstract: Attention mechanisms have become a core component of deep learning models, with Channel Attention and Spatial Attention being the two most representative architectures. Current research on their fusion strategies primarily bifurcates into sequential and parallel paradigms, yet the selection process remains largely empirical, lacking systematic analysis and unified principles. We systematically compare channel-spatial attention combinations under a unified framework, building an evaluation suite of 18 topologies across four classes: sequential, parallel, multi-scale, and residual. Across two vision and nine medical datasets, we uncover a "data scale-method-performance" coupling law: (1) in few-shot tasks, the "Channel-Multi-scale Spatial" cascaded structure achieves optimal performance; (2) in medium-scale tasks, parallel learnable fusion architectures demonstrate superior results; (3) in large-scale tasks, parallel structures with dynamic gating yield the best performance. Additionally, experiments indicate that the "Spatial-Channel" order is more stable and effective for fine-grained classification, while residual connections mitigate vanishing gradient problems across varying data scales. We thus propose scenario-based guidelines for building future attention modules. Code is open-sourced at https://github.com/DWlzm.

</details>


### [100] [Reconstruction Guided Few-shot Network For Remote Sensing Image Classification](https://arxiv.org/abs/2601.07335)
*Mohit Jaiswal,Naman Jain,Shivani Pathak,Mainak Singha,Nikunja Bihari Kar,Ankit Jha,Biplab Banerjee*

Main category: cs.CV

TL;DR: 本文提出了一种基于重建引导的少样本遥感图像分类网络（RGFS-Net），通过引入带掩码的图像重建辅助任务，有效提升了对新类别的泛化能力及已见类别的一致性。实验证明该方法优于现有基线，在低样本条件下表现突出。


<details>
  <summary>Details</summary>
Motivation: 遥感图像类别多样且标注样本稀少，传统方法难以应对少样本情况下的高类间差异性，因此亟需提升模型在样本稀缺时的泛化能力及判别能力。

Method: 本文设计了RGFS-Net网络，结合主分类任务与掩码图像重建辅助任务，将输入图像部分遮挡并重建，促使模型学习到更具语义和空间信息的特征，从而提升分类性能。

Result: 在EuroSAT与PatternNet数据集下，1-shot和5-shot实验中，本方法在准确率等指标上均超过现有主流基线方法，验证了其有效性与优越性。

Conclusion: RGFS-Net方法结构简单、提升显著且兼容常规主干网络，适合作为少样本遥感图像分类的通用且鲁棒解决方案。

Abstract: Few-shot remote sensing image classification is challenging due to limited labeled samples and high variability in land-cover types. We propose a reconstruction-guided few-shot network (RGFS-Net) that enhances generalization to unseen classes while preserving consistency for seen categories. Our method incorporates a masked image reconstruction task, where parts of the input are occluded and reconstructed to encourage semantically rich feature learning. This auxiliary task strengthens spatial understanding and improves class discrimination under low-data settings. We evaluated the efficacy of EuroSAT and PatternNet datasets under 1-shot and 5-shot protocols, our approach consistently outperforms existing baselines. The proposed method is simple, effective, and compatible with standard backbones, offering a robust solution for few-shot remote sensing classification. Codes are available at https://github.com/stark0908/RGFS.

</details>


### [101] [PulseMind: A Multi-Modal Medical Model for Real-World Clinical Diagnosis](https://arxiv.org/abs/2601.07344)
*Jiao Xu,Junwei Liu,Jiangwei Lao,Qi Zhu,Yunpeng Zhao,Congyun Jin,Shinan Liu,Zhihong Lu,Lihe Zhang,Xin Chen,Jian Wang,Ping Wang*

Main category: cs.CV

TL;DR: 本文提出了PulseMind，一个面向多模态医疗诊断的模型家族，包含了大规模真实咨询数据集、评估基准以及创新的训练方法，旨在贴合现实临床需求，并在多项任务中取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 现有医疗多模态模型大多聚焦于单一图像领域（如皮肤科、放射科等），无法全面覆盖真实临床诊断中多样输入与复杂互动的需求。本文旨在通过系统方法更贴近实际医疗场景，提升模型实用性与表现力。

Method: 作者首先构建了MediScope数据集，包含9.8万组多轮医疗咨询及60多万张医学图像，涵盖10大科室和200余亚专业，并提出了PulseMind基准，采用主动性、准确性、有用性和语言质量四维度评测。最后，设计了以比较为基础的强化学习优化方法CRPO，利用相对偏好信号指导模型训练。

Result: PulseMind在自建多轮咨询基准和公开医学评测中表现均具竞争力，验证了数据集、评测框架和训练方法的有效性。

Conclusion: 本研究通过构建多模态数据集与定制化多维评测体系，并提出创新性训练框架，推动了多模态医疗诊断模型更贴近临床实际场景，对医学AI发展具有重要意义。

Abstract: Recent advances in medical multi-modal models focus on specialized image analysis like dermatology, pathology, or radiology. However, they do not fully capture the complexity of real-world clinical diagnostics, which involve heterogeneous inputs and require ongoing contextual understanding during patient-physician interactions. To bridge this gap, we introduce PulseMind, a new family of multi-modal diagnostic models that integrates a systematically curated dataset, a comprehensive evaluation benchmark, and a tailored training framework. Specifically, we first construct a diagnostic dataset, MediScope, which comprises 98,000 real-world multi-turn consultations and 601,500 medical images, spanning over 10 major clinical departments and more than 200 sub-specialties. Then, to better reflect the requirements of real-world clinical diagnosis, we develop the PulseMind Benchmark, a multi-turn diagnostic consultation benchmark with a four-dimensional evaluation protocol comprising proactiveness, accuracy, usefulness, and language quality. Finally, we design a training framework tailored for multi-modal clinical diagnostics, centered around a core component named Comparison-based Reinforcement Policy Optimization (CRPO). Compared to absolute score rewards, CRPO uses relative preference signals from multi-dimensional com-parisons to provide stable and human-aligned training guidance. Extensive experiments demonstrate that PulseMind achieves competitive performance on both the diagnostic consultation benchmark and public medical benchmarks.

</details>


### [102] [Seeing Right but Saying Wrong: Inter- and Intra-Layer Refinement in MLLMs without Training](https://arxiv.org/abs/2601.07359)
*Shezheng Song,Shasha Li,Jie Yu*

Main category: cs.CV

TL;DR: 本文揭示了多模态大语言模型在视觉-语言任务中“看对说错”的内部推理不一致现象，并提出了无需额外训练就能提升推理一致性的DualPD解码优化策略，有效提升多种基准任务准确率。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大模型在视觉-语言任务上表现优异，但其推理流程中存在层与层之间关注区域不一致的问题。即深层能够关注正确视觉区域，却因为早期层的噪声注意力导致最终回答错误，即“看对却说错”。该问题影响了模型的输出可信度和实际应用效果，因此亟需一种能提升推理一致性的方法。

Method: 文中提出DualPD（双视角解码优化）策略，包括：1）层间注意力对比logits模块，捕捉各层关注转移，每层输出logits对比提升对正确答案的信念表达；2）头内信息过滤模块，抑制关注非关键信息的注意力头，提升层内注意力质量。该方法无需额外训练，可直接应用于各类现有多模态大模型。

Result: 在LLaVA和Qwen-VL等多模态模型及多个基准测试集上，DualPD策略均显著提升了模型准确率，且策略具有通用性与免训练的优势。

Conclusion: DualPD能够有效缓解多模态大模型推理一致性不足的问题，无需训练即可提升推理和输出一致性，对多种模型和任务均适用，具有实际应用价值。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated strong capabilities across a variety of vision-language tasks. However, their internal reasoning often exhibits a critical inconsistency: although deeper layers may attend to the correct visual regions, final predictions are frequently misled by noisy attention from earlier layers. This results in a disconnect between what the model internally understands and what it ultimately expresses, a phenomenon we describe as seeing it right but saying it wrong. To address this issue, we propose DualPD, a dual-perspective decoding refinement strategy that enhances the visual understanding without any additional training. DualPD consists of two components. (1) The layer-wise attention-guided contrastive logits module captures how the belief in the correct answer evolves by comparing output logits between layers that exhibit the largest attention shift. (2) The head-wise information filtering module suppresses low-contribution attention heads that focus on irrelevant regions, thereby improving attention quality within each layer. Experiments conducted on both the LLaVA and Qwen-VL model families across multiple multimodal benchmarks demonstrate that DualPD consistently improves accuracy without training, confirming its effectiveness and generalizability. The code will be released upon publication.

</details>


### [103] [HiVid-Narrator: Hierarchical Video Narrative Generation with Scene-Primed ASR-anchored Compression](https://arxiv.org/abs/2601.07366)
*Haoxuan Li,Mengyan Li,Junjun Zheng*

Main category: cs.CV

TL;DR: 本文提出了一种用于电商视频的分层叙事生成方法，并构建了新的E-HVC数据集，设计了SPA-Compressor进行高效多模态压缩，最终框架（HiVid-Narrator）在减少输入token数量的同时提升了叙事质量。


<details>
  <summary>Details</summary>
Motivation: 现有的视频叙事模型难以兼顾细粒度视觉理解和高层次叙事，特别是在节奏快速、信息密集的电商视频场景。缺乏能够分层结构化刻画电商视频内容的数据集和高效处理此类多模态冗余输入的方法。

Method: 1. 构建E-HVC双粒度数据集，包括基于时间锚定的事件链（Temporal Chain-of-Thought）和章节级摘要，用分阶段证明推导章节；2. 设计SPA-Compressor，根据ASR语义线索，将视频与ASR的多模态token压缩为层次化scene/event表征，降低输入token数量；3. 基于上述设计提出HiVid-Narrator框架。

Result: HiVid-Narrator相比现有方法，在输入更少token的情况下，生成的电商视频叙述语句更具事实性、连贯性，也更贴合用户关心的整体故事。

Conclusion: 提出的数据集、分层方法与高效压缩技术，为复杂情景（如电商）视频叙事提供了新思路，显著提高了视频自动叙述质量与处理速度，有望扩展到更多实际场景。

Abstract: Generating structured narrations for real-world e-commerce videos requires models to perceive fine-grained visual details and organize them into coherent, high-level stories--capabilities that existing approaches struggle to unify. We introduce the E-commerce Hierarchical Video Captioning (E-HVC) dataset with dual-granularity, temporally grounded annotations: a Temporal Chain-of-Thought that anchors event-level observations and Chapter Summary that compose them into concise, story-centric summaries. Rather than directly prompting chapters, we adopt a staged construction that first gathers reliable linguistic and visual evidence via curated ASR and frame-level descriptions, then refines coarse annotations into precise chapter boundaries and titles conditioned on the Temporal Chain-of-Thought, yielding fact-grounded, time-aligned narratives. We also observe that e-commerce videos are fast-paced and information-dense, with visual tokens dominating the input sequence. To enable efficient training while reducing input tokens, we propose the Scene-Primed ASR-anchored Compressor (SPA-Compressor), which compresses multimodal tokens into hierarchical scene and event representations guided by ASR semantic cues. Built upon these designs, our HiVid-Narrator framework achieves superior narrative quality with fewer input tokens compared to existing methods.

</details>


### [104] [Learning Dynamic Collaborative Network for Semi-supervised 3D Vessel Segmentation](https://arxiv.org/abs/2601.07377)
*Jiao Xu,Xin Chen,Lihe Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新的动态协作网络（DiCo），旨在提升3D血管半监督分割的性能，通过动态切换教师-学生模型角色、多视图整合以及对未标注数据进行对抗式监督，实现了当前最佳效果。


<details>
  <summary>Details</summary>
Motivation: 传统的mean teacher（MT）半监督方法中，教师模型与学生模型角色固定；然而，在复杂的3D血管分割任务中，教师模型并不总是优于学生模型，这种静态分工可能导致性能受限。为了提升模型表现和有效利用未标注数据，亟需更灵活、更接近医学实际判读过程的协作方法。

Method: 提出一种动态协作网络（DiCo），允许教师与学生模型根据实际表现动态切换角色，解决模型层次固定带来的偏差。同时设计了多视图整合模块，使模型能够借鉴医生多角度分析的方法，对输入数据进行多视角捕捉。还在无标签数据上引入对抗式监督，通过将3D体投影为2D视图，有效缓解标签不一致带来的影响，提升分割形状的精准约束。

Result: 在三个主流3D血管分割基准数据集上，DiCo方法均获得了新的最新最好性能（state-of-the-art），验证了方法的有效性和通用性。代码已经开源。

Conclusion: 动态切换教师-学生角色、多视图模块以及对抗式监督的结合，能够有效提升3D血管分割的准确性和泛化能力。该方法为医疗图像半监督分割提供了新的解决思路与实践基础。

Abstract: In this paper, we present a new dynamic collaborative network for semi-supervised 3D vessel segmentation, termed DiCo. Conventional mean teacher (MT) methods typically employ a static approach, where the roles of the teacher and student models are fixed. However, due to the complexity of 3D vessel data, the teacher model may not always outperform the student model, leading to cognitive biases that can limit performance. To address this issue, we propose a dynamic collaborative network that allows the two models to dynamically switch their teacher-student roles. Additionally, we introduce a multi-view integration module to capture various perspectives of the inputs, mirroring the way doctors conduct medical analysis. We also incorporate adversarial supervision to constrain the shape of the segmented vessels in unlabeled data. In this process, the 3D volume is projected into 2D views to mitigate the impact of label inconsistencies. Experiments demonstrate that our DiCo method sets new state-of-the-art performance on three 3D vessel segmentation benchmarks. The code repository address is https://github.com/xujiaommcome/DiCo

</details>


### [105] [Forecast the Principal, Stabilize the Residual: Subspace-Aware Feature Caching for Efficient Diffusion Transformers](https://arxiv.org/abs/2601.07396)
*Guantao Chen,Shikang Zheng,Yuqi Lin,Linfeng Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为SVD-Cache的新型子空间感知缓存方法，通过奇异值分解将扩散模型的特征分为主、残差子空间，分别采用不同的处理方式，有效加速扩散Transformer模型推理，提升了生成效率且保持近乎无损的质量。


<details>
  <summary>Details</summary>
Motivation: 现有扩散Transformer（DiT）在图像与视频生成任务中效果优异，但其推理过程耗时较长，现有缓存加速方法未能区分处理特征的不同子空间，影响预测精度与效率，因此亟需更细粒度的缓存与预测策略。

Method: 作者分析DiT中的特征空间，将其分解为主子空间和残差子空间，前者变化平滑可预测、后者则快速震荡且难预测。提出SVD-Cache：对主子空间用指数滑动平均（EMA）预测特征，对残差子空间则直接重用缓存，以此提升推理速度。

Result: SVD-Cache在多个主流模型如FLUX、HunyuanVideo上实现了高达5.55倍的推理加速，且在蒸馏、量化、稀疏注意力等加速方法兼容的前提下，几乎不损失生成质量。

Conclusion: SVD-Cache有效地利用扩散模型特征空间的结构性差异，实现了高效且高质量的生成任务加速。该方法具备良好的通用性和实际应用前景。

Abstract: Diffusion Transformer (DiT) models have achieved unprecedented quality in image and video generation, yet their iterative sampling process remains computationally prohibitive. To accelerate inference, feature caching methods have emerged by reusing intermediate representations across timesteps. However, existing caching approaches treat all feature components uniformly. We reveal that DiT feature spaces contain distinct principal and residual subspaces with divergent temporal behavior: the principal subspace evolves smoothly and predictably, while the residual subspace exhibits volatile, low-energy oscillations that resist accurate prediction. Building on this insight, we propose SVD-Cache, a subspace-aware caching framework that decomposes diffusion features via Singular Value Decomposition (SVD), applies exponential moving average (EMA) prediction to the dominant low-rank components, and directly reuses the residual subspace. Extensive experiments demonstrate that SVD-Cache achieves near-lossless across diverse models and methods, including 5.55$\times$ speedup on FLUX and HunyuanVideo, and compatibility with model acceleration techniques including distillation, quantization and sparse attention. Our code is in supplementary material and will be released on Github.

</details>


### [106] [SDHSI-Net: Learning Better Representations for Hyperspectral Images via Self-Distillation](https://arxiv.org/abs/2601.07416)
*Prachet Dev Singh,Shyamsundar Paramasivam,Sneha Barman,Mainak Singha,Ankit Jha,Girish Mishra,Biplab Banerjee*

Main category: cs.CV

TL;DR: 本文提出通过自蒸馏（Self-distillation, SD）方法提升高光谱图像分类性能，增强模型的准确度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像分类由于高光谱维度和标注数据稀缺，传统深度学习模型容易过拟合并计算成本高，因此需要有效提升性能的新方法。

Method: 采用自蒸馏技术，将模型中较早阶段的输出视为软目标，与最终预测进行一致性学习，以强化特征空间中类内紧凑性与类间分离性。

Result: 在两个高光谱图像基准数据集上验证方法，有明显精度和鲁棒性提升，优于传统模型。

Conclusion: 自蒸馏是一种有效提升高光谱图像分类性能的策略，有助于缓解过拟合问题，并提升模型泛化能力。

Abstract: Hyperspectral image (HSI) classification presents unique challenges due to its high spectral dimensionality and limited labeled data. Traditional deep learning models often suffer from overfitting and high computational costs. Self-distillation (SD), a variant of knowledge distillation where a network learns from its own predictions, has recently emerged as a promising strategy to enhance model performance without requiring external teacher networks. In this work, we explore the application of SD to HSI by treating earlier outputs as soft targets, thereby enforcing consistency between intermediate and final predictions. This process improves intra-class compactness and inter-class separability in the learned feature space. Our approach is validated on two benchmark HSI datasets and demonstrates significant improvements in classification accuracy and robustness, highlighting the effectiveness of SD for spectral-spatial learning. Codes are available at https://github.com/Prachet-Dev-Singh/SDHSI.

</details>


### [107] [PanoSAMic: Panoramic Image Segmentation from SAM Feature Encoding and Dual View Fusion](https://arxiv.org/abs/2601.07447)
*Mahdi Chamseddine,Didier Stricker,Jason Rambach*

Main category: cs.CV

TL;DR: PanoSAMic提出了一种适用于全景图像的语义分割模型，通过对SAM编码器进行多阶段特征扩展，并设计空间-模态融合模块与球面注意力机制，显著提升了各类模态下全景图像的分割性能，在公开数据集上取得SotA结果。


<details>
  <summary>Details</summary>
Motivation: 现有大模型主要针对普通透视图像训练，难以直接应用于具有球面失真和边缘不连续问题的全景图像。缺乏对全景图像多种模态（如RGB、RGB-D等）统一且高效的语义分割解决方案。

Method: 1. 对预训练的SAM编码器进行修改，使其能输出多阶段特征；2. 设计新的时空-模态融合模块，动态选取不同区域的最佳特征和模态信息；3. 在解码器中引入球面注意力和双视角融合，以应对全景图像中的失真与边缘问题。

Result: 在Stanford2D3DS (RGB, RGB-D, RGB-D-N)及Matterport3D (RGB, RGB-D)数据集上，PanoSAMic在全景图像语义分割任务中取得最新的SotA成绩。

Conclusion: 通过整合SAM大模型和新颖的融合机制，PanoSAMic能有效弥补普通模型在全景图像上的不足，大幅提升语义分割性能，为多模态全景视觉理解提供了先进解决方案。

Abstract: Existing image foundation models are not optimized for spherical images having been trained primarily on perspective images. PanoSAMic integrates the pre-trained Segment Anything (SAM) encoder to make use of its extensive training and integrate it into a semantic segmentation model for panoramic images using multiple modalities. We modify the SAM encoder to output multi-stage features and introduce a novel spatio-modal fusion module that allows the model to select the relevant modalities and best features from each modality for different areas of the input. Furthermore, our semantic decoder uses spherical attention and dual view fusion to overcome the distortions and edge discontinuity often associated with panoramic images. PanoSAMic achieves state-of-the-art (SotA) results on Stanford2D3DS for RGB, RGB-D, and RGB-D-N modalities and on Matterport3D for RGB and RGB-D modalities. https://github.com/dfki-av/PanoSAMic

</details>


### [108] [Improving Video Question Answering through query-based frame selection](https://arxiv.org/abs/2601.07459)
*Himanshu Patil,Geo Jolly,Ramana Raja Buddala,Ganesh Ramakrishnan,Rohit Saluja*

Main category: cs.CV

TL;DR: 文章提出用基于问题的帧选择方法，提升视频问答模型在有限算力下的问题对齐能力，验证有效性并获得准确率提升。


<details>
  <summary>Details</summary>
Motivation: 传统大模型在视频问答任务中通常采用均匀抽帧策略，但这种方式难以挑选关键信息帧，导致无法充分捕捉问题相关语境，从而影响问答准确性。为提升效果，迫切需要一种能根据问题选择最具信息量帧的方法。

Method: 提出基于子模互信息（SMI）函数的查询驱动帧挑选方法。该方法根据用户问题，智能选取与问题最相关且互补的信息帧，取代传统的均匀抽帧，提升框架在有限采样下的有效信息量。

Result: 在MVBench数据集和两种主流模型（Video-LLaVA和LLaVA-NeXT）上对比实验，使用基于问题的抽帧方法，准确率较均匀抽帧策略最高提升4%。定性分析也说明新策略能更好地选择与问题相关帧。

Conclusion: 基于问题的帧选择方法优于传统均匀取样策略，对于依赖部分视频帧的多种任务都能带来显著准确率提升，具有较广泛应用前景。

Abstract: Video Question Answering (VideoQA) models enhance understanding and interaction with audiovisual content, making it more accessible, searchable, and useful for a wide range of fields such as education, surveillance, entertainment, and content creation. Due to heavy compute requirements, most large visual language models (VLMs) for VideoQA rely on a fixed number of frames by uniformly sampling the video. However, this process does not pick important frames or capture the context of the video. We present a novel query-based selection of frames relevant to the questions based on the submodular mutual Information (SMI) functions. By replacing uniform frame sampling with query-based selection, our method ensures that the chosen frames provide complementary and essential visual information for accurate VideoQA. We evaluate our approach on the MVBench dataset, which spans a diverse set of multi-action video tasks. VideoQA accuracy on this dataset was assessed using two VLMs, namely Video-LLaVA and LLaVA-NeXT, both of which originally employed uniform frame sampling. Experiments were conducted using both uniform and query-based sampling strategies. An accuracy improvement of up to \textbf{4\%} was observed when using query-based frame selection over uniform sampling. Qualitative analysis further highlights that query-based selection, using SMI functions, consistently picks frames better aligned with the question. We opine that such query-based frame selection can enhance accuracy in a wide range of tasks that rely on only a subset of video frames.

</details>


### [109] [From Sketch to Fresco: Efficient Diffusion Transformer with Progressive Resolution](https://arxiv.org/abs/2601.07462)
*Shikang Zheng,Guantao Chen,Lixuan He,Jiacheng Liu,Yuqi Lin,Chang Zou,Linfeng Zhang*

Main category: cs.CV

TL;DR: Fresco是一种加速Diffusion Transformer生成的动态分辨率框架，实现了高效与高保真的统一，通过逐步上采样和对跨分辨率转换过程的优化，显著提升采样速度且几乎无损于生成质量。


<details>
  <summary>Details</summary>
Motivation: Diffusion Transformer虽然生成能力强，但由于需要多次迭代采样，因此计算开销大。现有动态分辨率加速方案在分辨率切换时采用启发式重噪音，打破了不同阶段的一致性，影响全局结构，还会无差别上采样导致误差积累和可见伪影。为解决这些效率和质量上的问题，提出一种新的加速框架。

Method: 提出Fresco框架，通过逐步的动态分辨率采样，在上采样与精细化阶段统一重噪音策略，保证各阶段对准同一生成目标。同时，Fresco在上采样过程中判断哪些区域已收敛，仅对尚未收敛区域进行精细处理，避免误差累积和伪影生成。

Result: Fresco框架在多种任务和模型上表现优异。例如，在FLUX模型上提升采样速度达10倍，在HunyuanVideo上提升5倍。同时，当与蒸馏等其他加速方法结合时，总加速可达22倍，且生成质量几乎无损。

Conclusion: Fresco有效破解了动态分辨率采样中质量与速度的矛盾，实现了高效且高保真的加速方案，有广泛的适应性和与其他加速技术的兼容性。

Abstract: Diffusion Transformers achieve impressive generative quality but remain computationally expensive due to iterative sampling. Recently, dynamic resolution sampling has emerged as a promising acceleration technique by reducing the resolution of early sampling steps. However, existing methods rely on heuristic re-noising at every resolution transition, injecting noise that breaks cross-stage consistency and forces the model to relearn global structure. In addition, these methods indiscriminately upsample the entire latent space at once without checking which regions have actually converged, causing accumulated errors, and visible artifacts. Therefore, we propose \textbf{Fresco}, a dynamic resolution framework that unifies re-noise and global structure across stages with progressive upsampling, preserving both the efficiency of low-resolution drafting and the fidelity of high-resolution refinement, with all stages aligned toward the same final target. Fresco achieves near-lossless acceleration across diverse domains and models, including 10$\times$ speedup on FLUX, and 5$\times$ on HunyuanVideo, while remaining orthogonal to distillation, quantization and feature caching, reaching 22$\times$ speedup when combined with distilled models. Our code is in supplementary material and will be released on Github.

</details>


### [110] [FocalOrder: Focal Preference Optimization for Reading Order Detection](https://arxiv.org/abs/2601.07483)
*Fuyuan Liu,Dianyu Yu,He Ren,Nayu Liu,Xiaomian Kang,Delai Qiu,Fa Zhang,Genpeng Zhen,Shengping Liu,Jiaen Liang,Wei Huang,Yining Wang,Junnan Zhu*

Main category: cs.CV

TL;DR: 本文提出了FocalOrder方法，通过关注难学过渡区域，有效提升了文档阅读顺序检测的性能，并在多个基准上取得了领先的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的文档阅读顺序检测方法普遍假设布局区域难度分布均匀，忽略了实际中模型对起始与结束区域表现优异，但在复杂的中间区域性能下降的问题（即位置差异）。这种情况源于标准训练时容易样本覆盖稀有、难学模式，削弱模型对复杂布局的学习能力。

Method: 提出了一种基于Focal Preference Optimization（FPO）的FocalOrder框架。其核心是利用指数滑动平均的方式自适应地发现学习难度较高的过渡，并通过难度校准的排序损失函数，强化模型对全局逻辑一致性的学习。

Result: 在OmniDocBench v1.0 和 Comp-HRDoc等基准数据集上，FocalOrder取得了新SOTA（state-of-the-art）性能。模型小巧，明显优于其他专业基线和大规模通用视觉语言模型。

Conclusion: 针对文档固有结构模糊性优化训练目标，对于掌握复杂文档结构至关重要。FocalOrder为文档阅读顺序检测提供了更有效的解决思路。

Abstract: Reading order detection is the foundation of document understanding. Most existing methods rely on uniform supervision, implicitly assuming a constant difficulty distribution across layout regions. In this work, we challenge this assumption by revealing a critical flaw: \textbf{Positional Disparity}, a phenomenon where models demonstrate mastery over the deterministic start and end regions but suffer a performance collapse in the complex intermediate sections. This degradation arises because standard training allows the massive volume of easy patterns to drown out the learning signals from difficult layouts. To address this, we propose \textbf{FocalOrder}, a framework driven by \textbf{Focal Preference Optimization (FPO)}. Specifically, FocalOrder employs adaptive difficulty discovery with exponential moving average mechanism to dynamically pinpoint hard-to-learn transitions, while introducing a difficulty-calibrated pairwise ranking objective to enforce global logical consistency. Extensive experiments demonstrate that FocalOrder establishes new state-of-the-art results on OmniDocBench v1.0 and Comp-HRDoc. Our compact model not only outperforms competitive specialized baselines but also significantly surpasses large-scale general VLMs. These results demonstrate that aligning the optimization with intrinsic structural ambiguity of documents is critical for mastering complex document structures.

</details>


### [111] [Anatomy Aware Cascade Network: Bridging Epistemic Uncertainty and Geometric Manifold for 3D Tooth Segmentation](https://arxiv.org/abs/2601.07499)
*Bing Yu,Liu Shi,Haitao Wang,Deran Qi,Xiang Cai,Wei Zhong,Qiegen Liu*

Main category: cs.CV

TL;DR: 本论文提出了AACNet，一种针对CBCT牙齿影像高精度三维分割的深度学习框架，通过新颖的网络结构和机制显著提升了分割性能，验证了在临床应用中的可靠性。


<details>
  <summary>Details</summary>
Motivation: CBCT牙齿分割对于数字化口腔诊疗至关重要，但现有方法难以应对扫描时因牙齿黏连和边界模糊造成的分割难题。

Method: 提出了Anatomy Aware Cascade Network（AACNet）框架，包含粗到细的分割流程，创新性地引入了Ambiguity Gated Boundary Refiner（AGBR）和Signed Distance Map guided Anatomical Attention（SDMAA）这两个机制。AGBR通过熵门控方法在高不确定性区域修正特征；SDMAA通过有符号距离图引入空间拓扑约束，保证整体结构一致性。

Result: 在125个CBCT数据集上，AACNet的Dice系数达到90.17%，HD95距离为3.63mm，均大幅优于现有技术。在外部测试集上HD95更优，为2.19mm，展现了优秀的泛化能力。

Conclusion: AACNet显著提升了牙齿分割的精度和泛化性，为临床外科规划等工作提供了可靠基础。代码已开源，便于后续研究和应用。

Abstract: Accurate three-dimensional (3D) tooth segmentation from Cone-Beam Computed Tomography (CBCT) is a prerequisite for digital dental workflows. However, achieving high-fidelity segmentation remains challenging due to adhesion artifacts in naturally occluded scans, which are caused by low contrast and indistinct inter-arch boundaries. To address these limitations, we propose the Anatomy Aware Cascade Network (AACNet), a coarse-to-fine framework designed to resolve boundary ambiguity while maintaining global structural consistency. Specifically, we introduce two mechanisms: the Ambiguity Gated Boundary Refiner (AGBR) and the Signed Distance Map guided Anatomical Attention (SDMAA). The AGBR employs an entropy based gating mechanism to perform targeted feature rectification in high uncertainty transition zones. Meanwhile, the SDMAA integrates implicit geometric constraints via signed distance map to enforce topological consistency, preventing the loss of spatial details associated with standard pooling. Experimental results on a dataset of 125 CBCT volumes demonstrate that AACNet achieves a Dice Similarity Coefficient of 90.17 \% and a 95\% Hausdorff Distance of 3.63 mm, significantly outperforming state-of-the-art methods. Furthermore, the model exhibits strong generalization on an external dataset with an HD95 of 2.19 mm, validating its reliability for downstream clinical applications such as surgical planning. Code for AACNet is available at https://github.com/shiliu0114/AACNet.

</details>


### [112] [Mon3tr: Monocular 3D Telepresence with Pre-built Gaussian Avatars as Amortization](https://arxiv.org/abs/2601.07518)
*Fangyu Lin,Yingdong Hu,Zhening Liu,Yufan Zhuang,Zehong Lin,Jun Zhang*

Main category: cs.CV

TL;DR: 本文提出了Mon3tr，一种只需单目RGB摄像头即可实现高质量全身三维远程虚拟呈现的低成本高效系统，极大降低带宽和硬件需求，在AR/VR远程协作中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有全息远程呈现依赖多摄像头和高带宽，难以在移动设备上实现实时、低成本应用，亟需突破技术瓶颈。

Method: 作者首次将三维高斯泼溅（3DGS）参数化人体建模融入远程呈现。方法包括：1）离线多视角重建生成用户专属Avatar；2）实时阶段单目摄像头捕捉人体动作与表情，通过极低带宽(<0.2Mbps)传输特征；3）接收端通过轻量级3DGS属性变形网络动态调整Avatar，实现高帧率高保真再现。

Result: 实验结果显示，方法支持多场景实时单目输入远程协作，在新姿态下PSNR>28dB，端到端延迟约80ms，带宽需求相比点云流传输降低约1000倍，性能业界领先。

Conclusion: Mon3tr实现了低带宽、低成本、实时、高质量的全身3D远程虚拟呈现，为移动端AR/VR远程协作提供了高效可行的解决方案，推动了该领域应用普及。

Abstract: Immersive telepresence aims to transform human interaction in AR/VR applications by enabling lifelike full-body holographic representations for enhanced remote collaboration. However, existing systems rely on hardware-intensive multi-camera setups and demand high bandwidth for volumetric streaming, limiting their real-time performance on mobile devices. To overcome these challenges, we propose Mon3tr, a novel Monocular 3D telepresence framework that integrates 3D Gaussian splatting (3DGS) based parametric human modeling into telepresence for the first time. Mon3tr adopts an amortized computation strategy, dividing the process into a one-time offline multi-view reconstruction phase to build a user-specific avatar and a monocular online inference phase during live telepresence sessions. A single monocular RGB camera is used to capture body motions and facial expressions in real time to drive the 3DGS-based parametric human model, significantly reducing system complexity and cost. The extracted motion and appearance features are transmitted at < 0.2 Mbps over WebRTC's data channel, allowing robust adaptation to network fluctuations. On the receiver side, e.g., Meta Quest 3, we develop a lightweight 3DGS attribute deformation network to dynamically generate corrective 3DGS attribute adjustments on the pre-built avatar, synthesizing photorealistic motion and appearance at ~ 60 FPS. Extensive experiments demonstrate the state-of-the-art performance of our method, achieving a PSNR of > 28 dB for novel poses, an end-to-end latency of ~ 80 ms, and > 1000x bandwidth reduction compared to point-cloud streaming, while supporting real-time operation from monocular inputs across diverse scenarios. Our demos can be found at https://mon3tr3d.github.io.

</details>


### [113] [ViewMorpher3D: A 3D-aware Diffusion Framework for Multi-Camera Novel View Synthesis in Autonomous Driving](https://arxiv.org/abs/2601.07540)
*Farhad G. Zanjani,Hong Cai,Amirhossein Habibian*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的多视角图像增强框架ViewMorpher3D，用于提升自动驾驶场景中的虚拟仿真图像的真实感和多视角一致性。实验表明，该方法显著减少了伪影并提升了图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有3D重建方法（如Gaussian Splatting）在新视点渲染时易产生伪影，尤其是在数据稀疏或外插视角下，严重影响自动驾驶模拟器中感知与决策模块的开发和评估。因此亟需增强模拟仿真场景的真实感和一致性。

Method: 提出ViewMorpher3D，利用扩散模型对多视角渲染结果进行联合处理，结合相机位姿、几何先验和邻近时空的参考视图作为条件，有效推断细节、抑制伪影并增强跨视图一致性。该方法能适配不同数量摄像头和灵活的参考/目标视图配置。

Result: 在真实世界自动驾驶数据集上，实验结果显示该框架显著提升了图像质量指标，减少了伪影，同时保持了几何精度。

Conclusion: ViewMorpher3D大幅提升了自动驾驶仿真场景的图像真实感和一致性，为感知和规划算法开发提供了更可靠的模拟数据，对自动驾驶系统开发具有重要意义。

Abstract: Autonomous driving systems rely heavily on multi-view images to ensure accurate perception and robust decision-making. To effectively develop and evaluate perception stacks and planning algorithms, realistic closed-loop simulators are indispensable. While 3D reconstruction techniques such as Gaussian Splatting offer promising avenues for simulator construction, the rendered novel views often exhibit artifacts, particularly in extrapolated perspectives or when available observations are sparse.
  We introduce ViewMorpher3D, a multi-view image enhancement framework based on image diffusion models, designed to elevate photorealism and multi-view coherence in driving scenes. Unlike single-view approaches, ViewMorpher3D jointly processes a set of rendered views conditioned on camera poses, 3D geometric priors, and temporally adjacent or spatially overlapping reference views. This enables the model to infer missing details, suppress rendering artifacts, and enforce cross-view consistency.
  Our framework accommodates variable numbers of cameras and flexible reference/target view configurations, making it adaptable to diverse sensor setups. Experiments on real-world driving datasets demonstrate substantial improvements in image quality metrics, effectively reducing artifacts while preserving geometric fidelity.

</details>


### [114] [BenchSeg: A Large-Scale Dataset and Benchmark for Multi-View Food Video Segmentation](https://arxiv.org/abs/2601.07581)
*Ahmad AlMughrabi,Guillermo Rivo,Carlos Jiménez-Farfán,Umair Haroon,Farid Al-Areqi,Hyunjun Jung,Benjamin Busam,Ricardo Marques,Petia Radeva*

Main category: cs.CV

TL;DR: 该论文提出了BenchSeg，一个面向多视角的食物视频分割数据集与基准，填补了食物分割领域多视角数据和泛化能力不足的空白。


<details>
  <summary>Details</summary>
Motivation: 目前的食物图像分割方法受限于缺乏多视角数据，对新视角下的泛化能力较弱。这对饮食分析等实际应用造成困难，因此需要全新的多视角分割数据集和评测基准。

Method: 作者整合了55个菜品场景（来源于Nutrition5k、Vegetables & Fruits、MetaFood3D和FoodKit），生成了包含25284帧全方位360°摄像机运动下的精确标注视频数据集BenchSeg。随后对20种先进分割模型（包括SAM、Transformers、CNN和大模型等）以及它们与视频记忆模块结合表现进行系统评测。

Result: 定量与定性结果显示，常规图像分割器在新视角下性能严重下降，而引入记忆模块的方法可维持帧间的时序一致性。作者的最佳方法（SeTR-MLA结合XMem2）在BenchSeg上表现优异，mAP提升约2.63%，超越现有方法。

Conclusion: BenchSeg为多视角食物分割研究搭建了新平台，验证了记忆增强方案的有效性，为食物分割和追踪提供了新思路，并公开了数据集和模型促进后续研究。

Abstract: Food image segmentation is a critical task for dietary analysis, enabling accurate estimation of food volume and nutrients. However, current methods suffer from limited multi-view data and poor generalization to new viewpoints. We introduce BenchSeg, a novel multi-view food video segmentation dataset and benchmark. BenchSeg aggregates 55 dish scenes (from Nutrition5k, Vegetables & Fruits, MetaFood3D, and FoodKit) with 25,284 meticulously annotated frames, capturing each dish under free 360° camera motion. We evaluate a diverse set of 20 state-of-the-art segmentation models (e.g., SAM-based, transformer, CNN, and large multimodal) on the existing FoodSeg103 dataset and evaluate them (alone and combined with video-memory modules) on BenchSeg. Quantitative and qualitative results demonstrate that while standard image segmenters degrade sharply under novel viewpoints, memory-augmented methods maintain temporal consistency across frames. Our best model based on a combination of SeTR-MLA+XMem2 outperforms prior work (e.g., improving over FoodMem by ~2.63% mAP), offering new insights into food segmentation and tracking for dietary analysis. We release BenchSeg to foster future research. The project page including the dataset annotations and the food segmentation models can be found at https://amughrabi.github.io/benchseg.

</details>


### [115] [Robust Multicentre Detection and Classification of Colorectal Liver Metastases on CT: Application of Foundation Models](https://arxiv.org/abs/2601.07585)
*Shruti Atul Mali,Zohaib Salahuddin,Yumeng Zhang,Andre Aichert,Xian Zhong,Henry C. Woodruff,Maciej Bobowicz,Katrine Riklund,Juozas Kupčinskas,Lorenzo Faggioni,Roberto Francischello,Razvan L Miclea,Philippe Lambin*

Main category: cs.CV

TL;DR: 本研究开发了一个基于基础模型的人工智能流水线，用于在多中心CT数据中进行结直肠肝转移瘤（CRLM）检测与分类，表现出较高的性能和良好的解释性。


<details>
  <summary>Details</summary>
Motivation: 结直肠肝转移瘤是癌症相关死亡的主要原因，但在多中心造影CT上可靠检测非常有挑战性，因此需要一种鲁棒、可解释的自动化检测方法。

Method: 研究者利用EuCanImage联盟（n=2437）和外部TCIA（n=197）的对比增强CT数据，评估多种预训练基础模型。最终选用UMedPT模型，结合多层感知机（MLP）头用于分类，FCOS头用于病灶检测，并纳入不确定性量化与可解释模块。

Result: 分类模型在测试集上的AUC为0.90，敏感性为0.82，在外部队列敏感性为0.85；剔除最不确定的20%样本后AUC提升至0.91，平衡准确率0.86。决策曲线分析显示在0.30~0.40阈值下有临床获益。检测模型对所有病灶的识别率为69.1%，且随病灶大小递增，最大可达98%。Grad-CAM解释性分析突出高置信病例的病灶相关区域。

Conclusion: 基于基础模型的AI流水线能够在异质性CT数据中实现鲁棒、可解释的CRLM自动检测与分类，有潜力辅助多中心环境下的临床决策。

Abstract: Colorectal liver metastases (CRLM) are a major cause of cancer-related mortality, and reliable detection on CT remains challenging in multi-centre settings. We developed a foundation model-based AI pipeline for patient-level classification and lesion-level detection of CRLM on contrast-enhanced CT, integrating uncertainty quantification and explainability. CT data from the EuCanImage consortium (n=2437) and an external TCIA cohort (n=197) were used. Among several pretrained models, UMedPT achieved the best performance and was fine-tuned with an MLP head for classification and an FCOS-based head for lesion detection. The classification model achieved an AUC of 0.90 and a sensitivity of 0.82 on the combined test set, with a sensitivity of 0.85 on the external cohort. Excluding the most uncertain 20 percent of cases improved AUC to 0.91 and balanced accuracy to 0.86. Decision curve analysis showed clinical benefit for threshold probabilities between 0.30 and 0.40. The detection model identified 69.1 percent of lesions overall, increasing from 30 percent to 98 percent across lesion size quartiles. Grad-CAM highlighted lesion-corresponding regions in high-confidence cases. These results demonstrate that foundation model-based pipelines can support robust and interpretable CRLM detection and classification across heterogeneous CT data.

</details>


### [116] [Diffusion in SPAD Signals](https://arxiv.org/abs/2601.07599)
*Lior Dvir,Nadav Torem,Yoav Y. Schechner*

Main category: cs.CV

TL;DR: 本文推导了单光子雪崩二极管（SPAD）在固定光子通量下原始信号的似然函数，并基于此为逆问题求解提供了基础。作者结合扩散模型作为图像先验，并分析了不同光子计数条件下检测事件时序的影响。


<details>
  <summary>Details</summary>
Motivation: SPAD在成像等领域用于探测单光子，信号受到非线性和随机性的影响，难以直接用于高质量图像重构，因此需要对SPAD信号的统计特性进行建模，为逆问题（如图像恢复）提供理论基础。

Method: 1. 推导SPAD信号（即检测事件时序）的概率似然函数；2. 构建SPAD信号的score函数，用于逆问题优化；3. 用扩散模型表达图像的先验分布，结合SPAD信号开展图像重建实验。

Result: 实验展示了在低光子计数和高光子计数两种条件下，检测事件时序对重建质量的影响。结果还说明了利用检测事件时序的优势。

Conclusion: 本文为基于SPAD的信号建模提供了理论依据，score函数结合扩散模型有效提升了成像等逆问题的求解效果，尤其在低光子条件下提升明显。

Abstract: We derive the likelihood of a raw signal in a single photon avalanche diode (SPAD), given a fixed photon flux. The raw signal comprises timing of detection events, which are nonlinearly related to the flux. Moreover, they are naturally stochastic. We then derive a score function of the signal. This is a key for solving inverse problems based on SPAD signals. We focus on deriving solutions involving a diffusion model, to express image priors. We demonstrate the effect of low or high photon counts, and the consequence of exploiting timing of detection events.

</details>


### [117] [UIKA: Fast Universal Head Avatar from Pose-Free Images](https://arxiv.org/abs/2601.07603)
*Zijian Wu,Boyao Zhou,Liangxiao Hu,Hongyu Liu,Yuan Sun,Xuan Wang,Xun Cao,Yujun Shen,Hao Zhu*

Main category: cs.CV

TL;DR: UIKA是一种新的高斯头像模型，可以仅凭单张图片、多视角图像或视频就实现动画化人头的重建，且精度优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统头像重建需要昂贵的多视角捕捉设备和耗时的优化过程，限制了其应用。作者希望开发一种高效、低成本、输入灵活的重建方法。

Method: 1. 提出UV引导的头像建模，将每个输入图像的像素精准对应到标准UV空间。
2. 利用可学习的UV token和跨屏幕—UV的注意力机制，融合多视角信息。
3. 借助合成的大规模、高身份多样性的头像数据进行端到端训练。

Result: UIKA在单视图及多视图输入情况下，相较现有方法表现更佳，实现了更高质量与灵活的人头动画重建。

Conclusion: 论文提出的UIKA方法在无须复杂设备与繁琐优化的情况下，实现了高效、高质量的动画头像重建，推动了虚拟人等应用的发展。

Abstract: We present UIKA, a feed-forward animatable Gaussian head model from an arbitrary number of unposed inputs, including a single image, multi-view captures, and smartphone-captured videos. Unlike the traditional avatar method, which requires a studio-level multi-view capture system and reconstructs a human-specific model through a long-time optimization process, we rethink the task through the lenses of model representation, network design, and data preparation. First, we introduce a UV-guided avatar modeling strategy, in which each input image is associated with a pixel-wise facial correspondence estimation. Such correspondence estimation allows us to reproject each valid pixel color from screen space to UV space, which is independent of camera pose and character expression. Furthermore, we design learnable UV tokens on which the attention mechanism can be applied at both the screen and UV levels. The learned UV tokens can be decoded into canonical Gaussian attributes using aggregated UV information from all input views. To train our large avatar model, we additionally prepare a large-scale, identity-rich synthetic training dataset. Our method significantly outperforms existing approaches in both monocular and multi-view settings. Project page: https://zijian-wu.github.io/uika-page/

</details>


### [118] [PARL: Position-Aware Relation Learning Network for Document Layout Analysis](https://arxiv.org/abs/2601.07620)
*Fuyuan Liu,Dianyu Yu,He Ren,Nayu Liu,Xiaomian Kang,Delai Qiu,Fa Zhang,Genpeng Zhen,Shengping Liu,Jiaen Liang,Wei Huang,Yining Wang,Junnan Zhu*

Main category: cs.CV

TL;DR: 该论文提出PARL（Position-Aware Relation Learning Network），是一种不依赖OCR，纯视觉的文档版面分析方法，实现了更高的准确率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有文档版面分析方法高度依赖OCR，将视觉特征与文本融合。这样的做法存在识别错误传播和高计算消耗的问题，影响了实际应用和结果的鲁棒性。作者认为可以仅依赖视觉结构来实现更优结果。

Method: 1. 提出Bidirectional Spatial Position-Guided Deformable Attention模块，将显式位置信息嵌入视觉特征，实现版面元素间位置依赖建模。
2. 设计Graph Refinement Classifier (GRC)，通过动态构建布局图，建模元素间上下文关系，细化分类预测。

Result: 在DocLayNet数据集上设立了纯视觉方法的新基准，在M6Doc上表现优于强大的多模态模型；参数量（65M）远低于多模态方法（256M），效率和性能兼优。

Conclusion: 通过精细的视觉结构建模，PARL不仅能够超越多模态模型，还可大幅提升效率，为文档版面分析提供了更鲁棒、高效的纯视觉解决思路。

Abstract: Document layout analysis aims to detect and categorize structural elements (e.g., titles, tables, figures) in scanned or digital documents. Popular methods often rely on high-quality Optical Character Recognition (OCR) to merge visual features with extracted text. This dependency introduces two major drawbacks: propagation of text recognition errors and substantial computational overhead, limiting the robustness and practical applicability of multimodal approaches. In contrast to the prevailing multimodal trend, we argue that effective layout analysis depends not on text-visual fusion, but on a deep understanding of documents' intrinsic visual structure. To this end, we propose PARL (Position-Aware Relation Learning Network), a novel OCR-free, vision-only framework that models layout through positional sensitivity and relational structure. Specifically, we first introduce a Bidirectional Spatial Position-Guided Deformable Attention module to embed explicit positional dependencies among layout elements directly into visual features. Second, we design a Graph Refinement Classifier (GRC) to refine predictions by modeling contextual relationships through a dynamically constructed layout graph. Extensive experiments show PARL achieves state-of-the-art results. It establishes a new benchmark for vision-only methods on DocLayNet and, notably, surpasses even strong multimodal models on M6Doc. Crucially, PARL (65M) is highly efficient, using roughly four times fewer parameters than large multimodal models (256M), demonstrating that sophisticated visual structure modeling can be both more efficient and robust than multimodal fusion.

</details>


### [119] [GeoMotionGPT: Geometry-Aligned Motion Understanding with Large Language Models](https://arxiv.org/abs/2601.07632)
*Zhankai Ye,Bofan Li,Yukai Jin,Shuoqiu Li,Wei Wang,Yanfu Zhang,Shangqian Gao,Xin Liu*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的运动离散化与语言模型对齐方法，通过正交化保障运动 token 与大语言模型（LLM）嵌入空间在几何结构上的一致性，使得LLM能更好地处理与推理复杂运动信息，实验在HumanML3D上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有运动token化与语义嵌入多为解耦训练，只以token id联系，导致运动空间的几何关系难以和嵌入空间对齐，最终影响LLM对运动细粒度推理的能力。动机在于寻找一种能让运动空间和嵌入空间几何结构统一的方法以提升推理能力。

Method: 采用仅解码量化器（decoder-only quantizer）和Gumbel-Softmax实现差分训练与均衡的codebook使用，通过稀疏投影将运动code投影到LLM嵌入空间，并在两个阶段分别对tokenizer和LLM微调时进行正交正则化，保持对齐性同时不影响语义适应。

Result: 在HumanML3D数据集上，该方法达到比当前SOTA高20%的性能提升，显示在细致的运动推理任务上具有显著优势。

Conclusion: 通过保持运动token与LLM嵌入空间的几何一致性，可以大幅增强LLM在运动推理与理解任务中的表现，证明了统一几何基础的重要性。

Abstract: Discrete motion tokenization has recently enabled Large Language Models (LLMs) to serve as versatile backbones for motion understanding and motion-language reasoning. However, existing pipelines typically decouple motion quantization from semantic embedding learning, linking them solely via token IDs. This approach fails to effectively align the intrinsic geometry of the motion space with the embedding space, thereby hindering the LLM's capacity for nuanced motion reasoning. We argue that alignment is most effective when both modalities share a unified geometric basis. Therefore, instead of forcing the LLM to reconstruct the complex geometry among motion tokens from scratch, we present a novel framework that explicitly enforces orthogonality on both the motion codebook and the LLM embedding space, ensuring that their relational structures naturally mirror each other. Specifically, we employ a decoder-only quantizer with Gumbel-Softmax for differentiable training and balanced codebook usage. To bridge the modalities, we use a sparse projection that maps motion codes into the LLM embedding space while preserving orthogonality. Finally, a two-stage orthonormal regularization schedule enforces soft constraints during tokenizer training and LLM fine-tuning to maintain geometric alignment without hindering semantic adaptation. Extensive experiments on HumanML3D demonstrate that our framework achieves a 20% performance improvement over current state-of-the-art methods, validating that a unified geometric basis effectively empowers the LLM for nuanced motion reasoning.

</details>


### [120] [StdGEN++: A Comprehensive System for Semantic-Decomposed 3D Character Generation](https://arxiv.org/abs/2601.07660)
*Yuze He,Yanning Zhou,Wang Zhao,Jingwen Ye,Zhongkai Wu,Ran Yi,Yong-Jin Liu*

Main category: cs.CV

TL;DR: 本论文提出了StdGEN++，一个能够从多种输入生成高保真、语义分解3D角色的新系统。该方法同时优化了几何、颜色和各部件的语义分割，显著提升了结构灵活性和工业可用性。


<details>
  <summary>Details</summary>
Motivation: 现有的3D角色生成方法通常产生整体网格，难以满足游戏和动画工业中对结构灵活性和语义分解的需求。作者旨在解决这一缺陷，并提高角色生成的真实性及可编辑性。

Method: 作者提出了一个双分支的语义感知大重建模型（Dual-Branch S-LRM)，能够同时恢复几何、颜色和部件语义。创新地引入了兼容混合隐式场的语义曲面提取机制，并通过粗到细的提议方案加速处理及减少内存消耗，同时采用基于视频扩散的纹理分解模块，实现外观多层可编辑。

Result: 实验结果表明StdGEN++在几何准确率和语义解耦方面均达到当前最佳水平，显著超越现有方案，并验证了各组成模块在高保真、高分辨率角色生成中的有效性。

Conclusion: StdGEN++不仅提升了3D角色生成的质量，还实现了各结构部件的独立性，使后续可实现无损编辑、符合物理的动画及注视跟踪等先进功能，是自动化角色资产生产的有力解决方案。

Abstract: We present StdGEN++, a novel and comprehensive system for generating high-fidelity, semantically decomposed 3D characters from diverse inputs. Existing 3D generative methods often produce monolithic meshes that lack the structural flexibility required by industrial pipelines in gaming and animation. Addressing this gap, StdGEN++ is built upon a Dual-branch Semantic-aware Large Reconstruction Model (Dual-Branch S-LRM), which jointly reconstructs geometry, color, and per-component semantics in a feed-forward manner. To achieve production-level fidelity, we introduce a novel semantic surface extraction formalism compatible with hybrid implicit fields. This mechanism is accelerated by a coarse-to-fine proposal scheme, which significantly reduces memory footprint and enables high-resolution mesh generation. Furthermore, we propose a video-diffusion-based texture decomposition module that disentangles appearance into editable layers (e.g., separated iris and skin), resolving semantic confusion in facial regions. Experiments demonstrate that StdGEN++ achieves state-of-the-art performance, significantly outperforming existing methods in geometric accuracy and semantic disentanglement. Crucially, the resulting structural independence unlocks advanced downstream capabilities, including non-destructive editing, physics-compliant animation, and gaze tracking, making it a robust solution for automated character asset production.

</details>


### [121] [Variational Contrastive Learning for Skeleton-based Action Recognition](https://arxiv.org/abs/2601.07666)
*Dang Dinh Nguyen,Decky Aspandi Latif,Titus Zaharia*

Main category: cs.CV

TL;DR: 论文提出了一种结合概率潜在建模（variational）与对比自监督学习的新框架，用于骨架动作识别任务，并在多个数据集上取得了优于现有方法的表现，特别是在标注较少的情况下。


<details>
  <summary>Details</summary>
Motivation: 现有基于对比学习的自监督方法主要为判别式，难以建模人体动作的多样性和不确定性。为能学习到更有结构和语义的特征表示，需要一种能捕捉这些特性的框架。

Method: 提出了一种变分对比学习框架，将概率潜在建模与传统对比学习融合，通过自监督方式学习可泛化、语义丰富的骨架动作表征。

Result: 在三个主流骨架动作识别基准数据集上，该方法在各类监督尤其是低标注情境下都超过了已有方法。在特征层面，该方法关注度更高地聚焦于关键骨骼关节。

Conclusion: 所提框架能够更有效地学习到泛化且语义明确的骨架动作表征，在实际应用中具有较好的性能和解释性优势。

Abstract: In recent years, self-supervised representation learning for skeleton-based action recognition has advanced with the development of contrastive learning methods. However, most of contrastive paradigms are inherently discriminative and often struggle to capture the variability and uncertainty intrinsic to human motion. To address this issue, we propose a variational contrastive learning framework that integrates probabilistic latent modeling with contrastive self-supervised learning. This formulation enables the learning of structured and semantically meaningful representations that generalize across different datasets and supervision levels. Extensive experiments on three widely used skeleton-based action recognition benchmarks show that our proposed method consistently outperforms existing approaches, particularly in low-label regimes. Moreover, qualitative analyses show that the features provided by our method are more relevant given the motion and sample characteristics, with more focus on important skeleton joints, when compared to the other methods.

</details>


### [122] [Advancing Multinational License Plate Recognition Through Synthetic and Real Data Fusion: A Comprehensive Evaluation](https://arxiv.org/abs/2601.07671)
*Rayson Laroca,Valter Estevam,Gladston J. P. Moreira,Rodrigo Minetto,David Menotti*

Main category: cs.CV

TL;DR: 本文通过整合真实与合成车牌数据，系统提升了自动车牌识别模型在多个数据集上的表现。


<details>
  <summary>Details</summary>
Motivation: 车牌识别在实际生活中应用广泛，但受限于训练数据不足。虽然近年来采用合成数据提升识别效果成为趋势，但如何高效融合真实与合成数据，以及不同合成方法的实际效果尚不清楚。

Method: 作者在12个公开数据集和16种OCR模型上做系统性测试，比较了三种主流合成数据生成方式（模板生成、字符置换、GAN生成），并探索了合成数据与真实数据结合的效果，考察了准确率与模型推理速度的权衡。

Result: 大量引入合成数据显著提升模型在同域和跨域上的识别性能。不仅三种合成方法均有助于性能提升，结合使用还产生协同增益，最终超过了当前最优方法和商业系统。同时，合成数据有效缓解了训练数据稀缺带来的问题，部分场景甚至只需原始数据的一小部分即可获得优异效果。作者还筛选出在准确率与速度之间折中最优的模型。

Conclusion: 合成数据在提升车牌识别表现上作用突出，特别是在数据有限的情况下。多种合成策略结合可进一步提升性能，同时在实际部署中可根据需求选择精度和速度最佳平衡的模型。

Abstract: Automatic License Plate Recognition is a frequent research topic due to its wide-ranging practical applications. While recent studies use synthetic images to improve License Plate Recognition (LPR) results, there remain several limitations in these efforts. This work addresses these constraints by comprehensively exploring the integration of real and synthetic data to enhance LPR performance. We subject 16 Optical Character Recognition (OCR) models to a benchmarking process involving 12 public datasets acquired from various regions. Several key findings emerge from our investigation. Primarily, the massive incorporation of synthetic data substantially boosts model performance in both intra- and cross-dataset scenarios. We examine three distinct methodologies for generating synthetic data: template-based generation, character permutation, and utilizing a Generative Adversarial Network (GAN) model, each contributing significantly to performance enhancement. The combined use of these methodologies demonstrates a notable synergistic effect, leading to end-to-end results that surpass those reached by state-of-the-art methods and established commercial systems. Our experiments also underscore the efficacy of synthetic data in mitigating challenges posed by limited training data, enabling remarkable results to be achieved even with small fractions of the original training data. Finally, we investigate the trade-off between accuracy and speed among different models, identifying those that strike the optimal balance in each intra-dataset and cross-dataset settings.

</details>


### [123] [Leveraging 3D Representation Alignment and RGB Pretrained Priors for LiDAR Scene Generation](https://arxiv.org/abs/2601.07692)
*Nicolas Sereyjol-Garros,Ellington Kirby,Victor Besnier,Nermin Samet*

Main category: cs.CV

TL;DR: 本文提出R3DPA方法，通过引入图像预训练先验和自监督3D表征，在LiDAR场景生成任务上刷新表现。


<details>
  <summary>Details</summary>
Motivation: 由于深度学习应用需要大量3D数据，而当前LiDAR点云数据稀缺、难以获得，限制了自动驾驶等机器人的发展。虽然已有扩散模型用于生成LiDAR场景，但相比于RGB大数据，LiDAR数据规模有限，因此急需能提升点云生成质量的新方法。

Method: R3DPA创新性地将图像预训练的大模型知识迁移到LiDAR生成，通过（1）对齐生成模型的中间特征与自监督得到的3D特征、（2）利用大规模图像模型进行知识迁移、（3）通过无条件模型支持点云推理时对物体修复和场景融合控制。

Result: R3DPA在KITTI-360等基准上取得了当前最佳生成表现，显著提升了点云质量和多样性，并支持灵活编辑。

Conclusion: 该方法突破性地利用多模态知识融合，有效缓解了点云数据匮乏问题，为LiDAR场景合成和下游机器人任务提供了更强的基础数据支撑。

Abstract: LiDAR scene synthesis is an emerging solution to scarcity in 3D data for robotic tasks such as autonomous driving. Recent approaches employ diffusion or flow matching models to generate realistic scenes, but 3D data remains limited compared to RGB datasets with millions of samples. We introduce R3DPA, the first LiDAR scene generation method to unlock image-pretrained priors for LiDAR point clouds, and leverage self-supervised 3D representations for state-of-the-art results. Specifically, we (i) align intermediate features of our generative model with self-supervised 3D features, which substantially improves generation quality; (ii) transfer knowledge from large-scale image-pretrained generative models to LiDAR generation, mitigating limited LiDAR datasets; and (iii) enable point cloud control at inference for object inpainting and scene mixing with solely an unconditional model. On the KITTI-360 benchmark R3DPA achieves state of the art performance. Code and pretrained models are available at https://github.com/valeoai/R3DPA.

</details>


### [124] [Smooth Operator: Smooth Verifiable Reward Activates Spatial Reasoning Ability of Vision-Language Model](https://arxiv.org/abs/2601.07695)
*Siwen Jiao,Tianxiong Lv,Kangan Qian,Chenxu Zhao,Xiuyuan Zhu,Tianlun Li,Xiaolong Cheng,Jinyu Li,Zhihao Liao,Yang Cai*

Main category: cs.CV

TL;DR: 该论文提出针对视觉-语言模型（VLM）在3D场景理解中数值预测不准确的问题，设计了新的强化学习方法和奖励机制，以提升其数值推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法对3D场景建模多依赖相对排序，难以捕捉精细的数值反馈，导致奖励稀疏和梯度不稳定，特别是在“near-miss”样本（即误差虽小但不为零）被优化过程中损失掉，影响模型利用重要边界数据。

Method: 提出了Smooth Numerical Reward Activation（SNRA）操作符，通过可动态调整的Sigmoid函数将原始反馈转为连续平滑的奖励；同时提出Absolute-Preserving GRPO（AP-GRPO）框架，引入绝对数值梯度，补偿传统相对排名机制损失的信息。这些方法综合应用于构建的Numerical3D-50k数据集上。

Result: 实验证明，AP-GRPO在不修改VLM结构的前提下激发了其潜在的3D数值推理能力，在数据利用率更高的情况下，性能达到大规模有监督方法同等水平。

Conclusion: 论文展示了通过新奖励机制和优化框架，VLM能够高效学习3D数值推理任务，对进一步提升多模态模型的理解和推理能力具有启发意义。

Abstract: Vision-Language Models (VLMs) face a critical bottleneck in achieving precise numerical prediction for 3D scene understanding. Traditional reinforcement learning (RL) approaches, primarily based on relative ranking, often suffer from severe reward sparsity and gradient instability, failing to effectively exploit the verifiable signals provided by 3D physical constraints. Notably, in standard GRPO frameworks, relative normalization causes "near-miss" samples (characterized by small but non-zero errors) to suffer from advantage collapse. This leads to a severe data utilization bottleneck where valuable boundary samples are discarded during optimization. To address this, we introduce the Smooth Numerical Reward Activation (SNRA) operator and the Absolute-Preserving GRPO (AP-GRPO) framework. SNRA employs a dynamically parameterized Sigmoid function to transform raw feedback into a dense, continuous reward continuum. Concurrently, AP-GRPO integrates absolute scalar gradients to mitigate the numerical information loss inherent in conventional relative-ranking mechanisms. By leveraging this approach, we constructed Numerical3D-50k, a dataset comprising 50,000 verifiable 3D subtasks. Empirical results indicate that AP-GRPO achieves performance parity with large-scale supervised methods while maintaining higher data efficiency, effectively activating latent 3D reasoning in VLMs without requiring architectural modifications.

</details>


### [125] [Hidden Monotonicity: Explaining Deep Neural Networks via their DC Decomposition](https://arxiv.org/abs/2601.07700)
*Jakob Paul Zimmermann,Georg Loho*

Main category: cs.CV

TL;DR: 本文提出将单调性用于提升神经网络可解释性的两种方法，包括对神经网络分解和训练方式的创新，并在主流网络和指标上获得了较好效果。


<details>
  <summary>Details</summary>
Motivation: 当前已知单调性有助于提升神经网络可解释性，但并非所有函数都能被单调神经网络良好拟合，因此需寻找更广泛应用单调性的方式提升可解释性。

Method: 1）提出将训练好的ReLU网络分解为两个单调且凸的部分，克服了权重爆炸的数值问题，结合提出的SplitCAM和SplitLRP显著提升显著性方法表现。2）通过将模型训练为两个单调神经网络之差来增强系统的自解释能力。

Result: 在VGG16和Resnet18等主流网络，以及ImageNet-S数据集全量Quantus显著性评估指标上，新方法SplitCAM和SplitLRP均超越已有最佳结果。

Conclusion: 适当引入和分解单调结构，不仅能提升神经网络解释性，还能取得实证性能提升，是提升网络自解释能力的有效方法。

Abstract: It has been demonstrated in various contexts that monotonicity leads to better explainability in neural networks. However, not every function can be well approximated by a monotone neural network. We demonstrate that monotonicity can still be used in two ways to boost explainability. First, we use an adaptation of the decomposition of a trained ReLU network into two monotone and convex parts, thereby overcoming numerical obstacles from an inherent blowup of the weights in this procedure. Our proposed saliency methods -- SplitCAM and SplitLRP -- improve on state of the art results on both VGG16 and Resnet18 networks on ImageNet-S across all Quantus saliency metric categories. Second, we exhibit that training a model as the difference between two monotone neural networks results in a system with strong self-explainability properties.

</details>


### [126] [Evaluating the encoding competence of visual language models using uncommon actions](https://arxiv.org/abs/2601.07737)
*Chen Ling,Nai Ding*

Main category: cs.CV

TL;DR: 提出了一个用于评估视觉语言模型对非常识动作场景理解能力的新数据集UAIT，揭示了当前模型在非常识语义推理上的明显不足。


<details>
  <summary>Details</summary>
Motivation: 现有数据集大多关注常见场景，模型在这些场景上容易利用统计规律答题，难以评估其真正的语义理解和推理能力。因此，需要一个能够挑战模型非常识理解能力的新型评测集。

Method: 设计了UAIT数据集，通过大语言模型、少样本提示词技术和图文生成手段半自动化合成了大量非常识的高质量图文样本，并为每个样本设计了细致的多项选择题以考察模型的细粒度推理能力。

Result: 实验测试了多种主流视觉语言模型和对比学习方法，结果显示它们在非常识语义判断方面明显不如人类，尤其难以区分语法正确性和语义合理性；进一步微调后模型准确率有所提高，呈现良好适应潜力。

Conclusion: 本研究揭示了当前视觉语言模型在真实语义推理能力方面的关键短板，同时为研发更具鲁棒性的视觉语义理解模型提供了诊断工具和研究方向。

Abstract: We propose UAIT (Uncommon-sense Action Image-Text) dataset, a new evaluation benchmark designed to test the semantic understanding ability of visual language models (VLMs) in uncommon-sense action scenes. Unlike previous datasets that focus on common visual scenes with statistical frequency advantages, UAIT challenges models with grammatically reasonable but semantically counter-common sense image-text pairs. Such tasks require models to go beyond superficial pattern recognition and demonstrate a deep understanding of agent-patient relationships and physical feasibility. To build UAIT, we designed a semi-automated process to synthesize high-quality uncommon-sense image-text samples using large language models, few-shot prompt engineering, and text-to-image generation. Each sample is accompanied by a carefully designed multiple-choice question to test the model's competence in fine-grained reasoning. We evaluate multiple state-of-the-art visual language models and compare them with models based on contrastive learning. Experiments show that all models perform significantly worse than humans in semantic judgment, especially in distinguishing grammatical correctness from semantic rationality. Further experiments show that even the lightweight model can improve its accuracy after fine-tuning, demonstrating the great potential of directional adaptation. This study not only reveals the key weaknesses of VLMs, but also provides diagnostic tools and research directions for the development of robust models with real visual semantic reasoning capabilities.

</details>


### [127] [On the application of the Wasserstein metric to 2D curves classification](https://arxiv.org/abs/2601.07749)
*Agnieszka Kaliszewska,Monika Syga*

Main category: cs.CV

TL;DR: 本文提出了多种Wasserstein距离的变体，用于2D曲线特定片段的分类，并通过考古领域的数据实验进行了聚类分析验证。


<details>
  <summary>Details</summary>
Motivation: 在许多实际应用中，尤其是考古学中，2D曲线的某些部分（片段）对于分类至关重要。然而，传统距离度量方法往往未能针对性地关注这些关键片段。作者希望通过调整Wasserstein距离来强调曲线的重要片段，提升分类效果。

Method: 作者提出基于多个离散概率测度（反映曲线重要片段）的Wasserstein距离变体。通过调整这些概率测度，方法能够让距离度量更加关注指定片段。随后，作者将这些方法应用于考古领域2D曲线的数据，开展聚类实验，测试其效果。

Result: 通过考古数据上的聚类实验，证明了所提出的Wasserstein距离变体在关注特定片段的曲线分类上表现优异。实验结果显示该方法能有效提升聚类分析的准确度和针对性。

Conclusion: Wasserstein距离的片段加权变体能够更好地聚焦于2D曲线中的关键片段，有助于在需要强调部分结构的实际场景中提升分类与聚类的表现。

Abstract: In this work we analyse a number of variants of the Wasserstein distance which allow to focus the classification on the prescribed parts (fragments) of classified 2D curves. These variants are based on the use of a number of discrete probability measures which reflect the importance of given fragments of curves. The performance of this approach is tested through a series of experiments related to the clustering analysis of 2D curves performed on data coming from the field of archaeology.

</details>


### [128] [Video Evidence to Reasoning Efficient Video Understanding via Explicit Evidence Grounding](https://arxiv.org/abs/2601.07761)
*Yanxiang Huang,Guohua Gao,Zhaoyang Wei,Jianyuan Ni*

Main category: cs.CV

TL;DR: 本文提出Chain of Evidence（CoE）框架，通过架构化分离视觉证据提取与推理过程，提升大规模视听语言模型的视频推理准确性与效率，同时降低幻想（Hallucination）风险。


<details>
  <summary>Details</summary>
Motivation: 大规模视听语言模型在视频推理中面临两难：详尽推理计算成本高，简化推理易产生幻觉且不可信。解决既高效又可信的视频理解需求。

Method: 提出CoE框架，包括：1）轻量级证据锚定模块（EGM）根据问句动态筛选关键视觉证据；2）基于强化学习的证据锚定协议，并设计奖励机制，强制推理过程与所选证据锚点对齐。构建了带双标注的大规模CoE-Instruct数据集以分离感知与推理标注。

Result: 在Video-MME、MVBench、VSI-Bench等五个基准上广泛实验，CoE框架显著提升模型准确率，取得最新最强性能，超越现有方法。

Conclusion: Chain of Evidence方法为可靠高效的视频理解提供了新范式，有效提升LVLM的推理能力并缓解幻觉问题。

Abstract: Large Vision-Language Models (LVLMs) face a fundamental dilemma in video reasoning: they are caught between the prohibitive computational costs of verbose reasoning and the hallucination risks of efficient, ungrounded approaches. To resolve this, we introduce the Chain of Evidence (CoE), a novel framework that architecturally decouples and co-optimizes perceptual grounding and reasoning efficiency. CoE incorporates two core innovations: (1) A lightweight Evidence Grounding Module (EGM) that acts as a query-guided filter, dynamically identifying and extracting a compact set of high-fidelity visual evidence; and (2) An Evidence-Anchoring Protocol optimized via Reinforcement Learning. Crucially, we design a composite reward mechanism that enforces process alignment, compelling the model to strictly reference identified temporal anchors during deduction, thereby mitigating hallucinations. To enable this, we construct CoE-Instruct, a large-scale dataset (164k samples) featuring a novel dual-annotation schema for separate perception and reasoning supervision. Extensive experiments on five benchmarks, including Video-MME, MVBench, and VSI-Bench, demonstrate that CoE-enhanced models establish a new state-of-the-art. They significantly outperform existing methods in accuracy, proving CoE to be a powerful and practical paradigm for reliable video understanding.

</details>


### [129] [Beyond External Guidance: Unleashing the Semantic Richness Inside Diffusion Transformers for Improved Training](https://arxiv.org/abs/2601.07773)
*Lingchen Sun,Rongyuan Wu,Zhengqiang Zhang,Ruibin Li,Yujing Sun,Shuaizheng Liu,Lei Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种不依赖外部预训练网络的新方法（Self-Transcendence），可加速Diffusion Transformer（DiT）的训练，并提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有利用外部语义特征（如DINO）引导DiT训练的方法依赖额外的预训练网络，带来依赖性和灵活性问题。作者希望开发一种自包含、无需外部网络即可加速训练的方案。

Method: 方法分两阶段：先让DiT浅层特征对齐预训练VAE的潜在表示以加快学习，再对中间特征采用无分类器引导，提升其判别和语义能力，最后用这些内部特征引导新一轮训练。整个过程仅用模型自身内部特征。

Result: 新方法在生成质量和收敛速度上都超过现有自包含方法，甚至优于依赖外部特征的REPA，同时无外部依赖、适配更灵活。

Conclusion: Self-Transcendence方法无需外部预训练网络即可有效加速和提升DiT性能，具备更强泛化潜力，可应用于更多扩散生成任务。

Abstract: Recent works such as REPA have shown that guiding diffusion models with external semantic features (e.g., DINO) can significantly accelerate the training of diffusion transformers (DiTs). However, this requires the use of pretrained external networks, introducing additional dependencies and reducing flexibility. In this work, we argue that DiTs actually have the power to guide the training of themselves, and propose \textbf{Self-Transcendence}, a simple yet effective method that achieves fast convergence using internal feature supervision only. It is found that the slow convergence in DiT training primarily stems from the difficulty of representation learning in shallow layers. To address this, we initially train the DiT model by aligning its shallow features with the latent representations from the pretrained VAE for a short phase (e.g., 40 epochs), then apply classifier-free guidance to the intermediate features, enhancing their discriminative capability and semantic expressiveness. These enriched internal features, learned entirely within the model, are used as supervision signals to guide a new DiT training. Compared to existing self-contained methods, our approach brings a significant performance boost. It can even surpass REPA in terms of generation quality and convergence speed, but without the need for any external pretrained models. Our method is not only more flexible for different backbones but also has the potential to be adopted for a wider range of diffusion-based generative tasks. The source code of our method can be found at https://github.com/csslc/Self-Transcendence.

</details>


### [130] [Vision-Language Model for Accurate Crater Detection](https://arxiv.org/abs/2601.07795)
*Patrick Bauer,Marius Schwinning,Florian Renk,Andreas Weinmann,Hichem Snoussi*

Main category: cs.CV

TL;DR: 提出了一种基于Vision Transformer（OWLv2模型）的深度学习月球陨石坑检测方法，在高分辨率月球图像上表现优异，达到高召回率和精确率，有助于未来月球探测任务的安全着陆。


<details>
  <summary>Details</summary>
Motivation: 为了满足欧洲航天局（ESA）阿尔戈探测器月球着陆任务对安全性高的陨石坑识别需求。由于月表陨石坑众多、尺度和形态复杂，以及光照、地形条件变化大，传统方法难以有效自动检测，亟需更鲁棒的解决方案。

Method: 基于Vision Transformer的OWLv2模型，采用IMPACT项目手动标注的高分辨率月球观测数据进行微调；引入低秩自适应（LoRA）高效参数训练，并优化联合损失函数（CIoU用于定位，对比损失用于分类）。

Result: 方法在IMPACT测试数据集上获得最高94.0%的召回率和73.1%的精确率，同时获得较好视觉效果，能够可靠地适应多变的月球成像环境。

Conclusion: 该方法在复杂月面条件下实现了高效、可靠的陨石坑检测，为未来月球探测与着陆安全提供了坚实技术基础。

Abstract: The European Space Agency (ESA), driven by its ambitions on planned lunar missions with the Argonaut lander, has a profound interest in reliable crater detection, since craters pose a risk to safe lunar landings. This task is usually addressed with automated crater detection algorithms (CDA) based on deep learning techniques. It is non-trivial due to the vast amount of craters of various sizes and shapes, as well as challenging conditions such as varying illumination and rugged terrain. Therefore, we propose a deep-learning CDA based on the OWLv2 model, which is built on a Vision Transformer, that has proven highly effective in various computer vision tasks. For fine-tuning, we utilize a manually labeled dataset fom the IMPACT project, that provides crater annotations on high-resolution Lunar Reconnaissance Orbiter Camera Calibrated Data Record images. We insert trainable parameters using a parameter-efficient fine-tuning strategy with Low-Rank Adaptation, and optimize a combined loss function consisting of Complete Intersection over Union (CIoU) for localization and a contrastive loss for classification. We achieve satisfactory visual results, along with a maximum recall of 94.0% and a maximum precision of 73.1% on a test dataset from IMPACT. Our method achieves reliable crater detection across challenging lunar imaging conditions, paving the way for robust crater analysis in future lunar exploration.

</details>


### [131] [Exchange Is All You Need for Remote Sensing Change Detection](https://arxiv.org/abs/2601.07805)
*Sijun Dong,Siming Fu,Kaiyu Li,Xiangyong Cao,Xiaoliang Meng,Bo Du*

Main category: cs.CV

TL;DR: 该文提出了一种名为SEED的新型遥感变化检测架构，用简洁的特征交换机制替代了传统的显式差分计算，并在多个数据集和主流骨干网络上达到了优越或持平的效果。


<details>
  <summary>Details</summary>
Motivation: 现有遥感变化检测方法常用Siamese结构及手工差分模块（如减法或拼接），导致模型复杂且信息可能丢失，因此需要一种更简洁且信息保留的方法。

Method: 提出SEED（Siamese Encoder-Exchange-Decoder）架构：在Siamese编码器和解码器之间采用无参数的特征交换操作，阐述其数学原理，并证明在像素一致下能最大限度保留信息且最优，且将此机制拓展到语义分割模型（SEG2CD）。

Result: 在SYSU-CD、LEVIR-CD、PX-CLCD、WaterCD及CDD五个主流遥感变化检测数据集，以及SwinT、EfficientNet、ResNet三种骨干网络上，SEED的表现达到或优于现有最佳方法。

Conclusion: SEED通过极其简化的特征交换在充分利用信息的同时，取得了高性能和统一的变化检测框架，证明复杂差分模块其实并非必要。

Abstract: Remote sensing change detection fundamentally relies on the effective fusion and discrimination of bi-temporal features. Prevailing paradigms typically utilize Siamese encoders bridged by explicit difference computation modules, such as subtraction or concatenation, to identify changes. In this work, we challenge this complexity with SEED (Siamese Encoder-Exchange-Decoder), a streamlined paradigm that replaces explicit differencing with parameter-free feature exchange. By sharing weights across both Siamese encoders and decoders, SEED effectively operates as a single parameter set model. Theoretically, we formalize feature exchange as an orthogonal permutation operator and prove that, under pixel consistency, this mechanism preserves mutual information and Bayes optimal risk, whereas common arithmetic fusion methods often introduce information loss. Extensive experiments across five benchmarks, including SYSU-CD, LEVIR-CD, PX-CLCD, WaterCD, and CDD, and three backbones, namely SwinT, EfficientNet, and ResNet, demonstrate that SEED matches or surpasses state of the art methods despite its simplicity. Furthermore, we reveal that standard semantic segmentation models can be transformed into competitive change detectors solely by inserting this exchange mechanism, referred to as SEG2CD. The proposed paradigm offers a robust, unified, and interpretable framework for change detection, demonstrating that simple feature exchange is sufficient for high performance information fusion. Code and full training and evaluation protocols will be released at https://github.com/dyzy41/open-rscd.

</details>


### [132] [More Images, More Problems? A Controlled Analysis of VLM Failure Modes](https://arxiv.org/abs/2601.07812)
*Anurag Das,Adrian Bulat,Alberto Baldrati,Ioannis Maniadis Metaxas,Bernt Schiele,Georgios Tzimiropoulos,Brais Martinez*

Main category: cs.CV

TL;DR: 这篇论文提出了MIMIC基准，用于系统测试和分析大规模视觉语言模型（LVLMs）在多图像理解与推理上的能力，并提出了两种提升模型表现的方法，有效改善多图像任务表现。


<details>
  <summary>Details</summary>
Motivation: 尽管LVLMs展现出强大能力，但其在多图像理解和推理方面的弱点尚未被充分挖掘和研究。现有评测基准无法全面揭示其深层次问题及成因，因此需要更细致、更系统的分析工具和方法。

Method: （1）提出MIMIC基准：系统评测LVLMs在多图像场景下的表现，并通过诊断实验发现模型在跨图整合、概念追踪与关注上的固有缺陷。 （2）数据增强：通过程序生成，将单图像标注复合成复杂的多图像训练样本。 （3）优化改进：分析层级注意力机制，提出适用于多图输入的注意力掩码方案以提高聚合效果。

Result: 采用两种改进方法后，模型在跨图像信息整合和多概念关注能力上显著提升，同时在多个公开多图像基准上优于现有SOTA模型。

Conclusion: 论文证实LVLMs的多图像处理仍有明显短板，但通过有针对性的训练数据和优化机制，模型表现可以获得显著提升。MIMIC为社区理解和改进多图像LVLMs提供了有力工具。

Abstract: Large Vision Language Models (LVLMs) have demonstrated remarkable capabilities, yet their proficiency in understanding and reasoning over multiple images remains largely unexplored. While existing benchmarks have initiated the evaluation of multi-image models, a comprehensive analysis of their core weaknesses and their causes is still lacking. In this work, we introduce MIMIC (Multi-Image Model Insights and Challenges), a new benchmark designed to rigorously evaluate the multi-image capabilities of LVLMs. Using MIMIC, we conduct a series of diagnostic experiments that reveal pervasive issues: LVLMs often fail to aggregate information across images and struggle to track or attend to multiple concepts simultaneously. To address these failures, we propose two novel complementary remedies. On the data side, we present a procedural data-generation strategy that composes single-image annotations into rich, targeted multi-image training examples. On the optimization side, we analyze layer-wise attention patterns and derive an attention-masking scheme tailored for multi-image inputs. Experiments substantially improved cross-image aggregation, while also enhancing performance on existing multi-image benchmarks, outperforming prior state of the art across tasks. Data and code will be made available at https://github.com/anurag-198/MIMIC.

</details>


### [133] [MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head](https://arxiv.org/abs/2601.07832)
*Kewei Zhang,Ye Huang,Yufan Deng,Jincheng Yu,Junsong Chen,Huan Ling,Enze Xie,Daquan Zhou*

Main category: cs.CV

TL;DR: 本文提出了多头线性注意力（MHLA）机制，有效解决了线性注意力导致表现下降的问题，兼顾了效率和性能，在多个领域大幅提升了表现。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer的自注意力复杂度为二次方，限制了其在大规模应用中的使用。虽然线性注意力提高了效率，但往往效果不好，现有改进方案又会引入额外开销，因此急需一种兼顾效率与性能的新方法。

Method: 作者分析了现有线性注意力方法失败的原因（全球上下文信息塌缩），并提出将注意力计算分散到token维度的不同头（Multi-Head Linear Attention, MHLA），用以保留表示多样性，同时维持线性复杂度。理论上证明了其方法的有效性，并在多个领域进行了实验验证。

Result: 在同等时间复杂度下，MHLA在ImageNet分类任务上提升3.6%，在NLP任务上提升6.3%，在图像生成上提升12.6%，在视频生成任务上提升41%。

Conclusion: MHLA能够保持线性时间复杂度，同时恢复到接近Softmax注意力的表达能力，在多个任务上显著提升线性注意力表现，是高效大规模应用的有力工具。

Abstract: While the Transformer architecture dominates many fields, its quadratic self-attention complexity hinders its use in large-scale applications. Linear attention offers an efficient alternative, but its direct application often degrades performance, with existing fixes typically re-introducing computational overhead through extra modules (e.g., depthwise separable convolution) that defeat the original purpose. In this work, we identify a key failure mode in these methods: global context collapse, where the model loses representational diversity. To address this, we propose Multi-Head Linear Attention (MHLA), which preserves this diversity by computing attention within divided heads along the token dimension. We prove that MHLA maintains linear complexity while recovering much of the expressive power of softmax attention, and verify its effectiveness across multiple domains, achieving a 3.6\% improvement on ImageNet classification, a 6.3\% gain on NLP, a 12.6\% improvement on image generation, and a 41\% enhancement on video generation under the same time complexity.

</details>


### [134] [Tuning-free Visual Effect Transfer across Videos](https://arxiv.org/abs/2601.07833)
*Maxwell Jones,Rameen Abdal,Or Patashnik,Ruslan Salakhutdinov,Sergey Tulyakov,Jun-Yan Zhu,Kuan-Chieh Jackson Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新的视觉效果迁移框架RefVFX，可以将参考视频中的复杂时序效果迁移到目标视频或图像上，且效果显著优于基于文本或关键帧的方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑方法在处理动态时序效果（如光照变化、人物变身）时表现有限，因为这些效果难以通过文本描述或静态条件指定，所以需要一种更直接、灵活的迁移机制。

Method: 作者构建了一个大规模三元组数据集（三元组包含参考效果视频、输入图片或视频、以及带转移效果的输出视频），并提出了一套自动化生成高质量配对视频流程。结合LoRA适配器及代码生成的时序效果，利用最新文本生成视频骨架训练参考条件模型，实现时序效果迁移。

Result: 实验证明RefVFX在视觉一致性、时序连贯性方面表现突出，对新颖未见过的效果有良好泛化能力，在定量指标和用户偏好上均优于以提示为基础的对比方法。

Conclusion: RefVFX有效解决了复杂动态视觉效果的迁移问题，为视频编辑提供了新手段，在多个维度上超过现有主流方法。

Abstract: We present RefVFX, a new framework that transfers complex temporal effects from a reference video onto a target video or image in a feed-forward manner. While existing methods excel at prompt-based or keyframe-conditioned editing, they struggle with dynamic temporal effects such as dynamic lighting changes or character transformations, which are difficult to describe via text or static conditions. Transferring a video effect is challenging, as the model must integrate the new temporal dynamics with the input video's existing motion and appearance. % To address this, we introduce a large-scale dataset of triplets, where each triplet consists of a reference effect video, an input image or video, and a corresponding output video depicting the transferred effect. Creating this data is non-trivial, especially the video-to-video effect triplets, which do not exist naturally. To generate these, we propose a scalable automated pipeline that creates high-quality paired videos designed to preserve the input's motion and structure while transforming it based on some fixed, repeatable effect. We then augment this data with image-to-video effects derived from LoRA adapters and code-based temporal effects generated through programmatic composition. Building on our new dataset, we train our reference-conditioned model using recent text-to-video backbones. Experimental results demonstrate that RefVFX produces visually consistent and temporally coherent edits, generalizes across unseen effect categories, and outperforms prompt-only baselines in both quantitative metrics and human preference. See our website $\href{https://tuningfreevisualeffects-maker.github.io/Tuning-free-Visual-Effect-Transfer-across-Videos-Project-Page/}{at\ this\ URL}$.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [135] [TeleMem: Building Long-Term and Multimodal Memory for Agentic AI](https://arxiv.org/abs/2601.06037)
*Chunliang Chen,Ming Guan,Xiao Lin,Jiaxu Li,Qiyi Wang,Xiangyu Chen,Jixiang Luo,Changzhi Sun,Dell Zhang,Xuelong Li*

Main category: cs.CL

TL;DR: 本文提出了TeleMem系统，一种面向长时、多模态对话的高效记忆机制，有效提升了大模型在长期多轮交互中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在多轮长时对话或多模态推理时，由于注意力窗口限制和记忆管理不善，容易丢失上下文、产生幻觉，且记忆写入和更新低效，严重影响实际应用。

Method: 提出了TeleMem系统，包括：（1）动态叙事信息抽取，保证保留的信息均有对话依据，完善用户画像；（2）结构化的记忆写入管线，实现记忆批量处理、聚类与合并，优化存储与检索的效率；（3）多模态记忆模块结合ReAct风格推理，实现封闭环的‘观察-思考-行动’流程，增强对复杂视频内容的理解。

Result: 在ZH-4O长时角色扮演任务中，TeleMem系统准确率提升19%，Token使用量减少43%，记忆操作速度提升2.1倍，表现明显优于现有最强基线Mem0。

Conclusion: TeleMem显著提升了大模型长时对话与推理能力，在长时多模态交互场景下具备高效率、强可靠性的记忆管理机制，推动了多模态智能体的应用落地。

Abstract: Large language models (LLMs) excel at many NLP tasks but struggle to sustain long-term interactions due to limited attention over extended dialogue histories. Retrieval-augmented generation (RAG) mitigates this issue but lacks reliable mechanisms for updating or refining stored memories, leading to schema-driven hallucinations, inefficient write operations, and minimal support for multimodal reasoning.To address these challenges, we propose TeleMem, a unified long-term and multimodal memory system that maintains coherent user profiles through narrative dynamic extraction, ensuring that only dialogue-grounded information is preserved. TeleMem further introduces a structured writing pipeline that batches, retrieves, clusters, and consolidates memory entries, substantially improving storage efficiency, reducing token usage, and accelerating memory operations. Additionally, a multimodal memory module combined with ReAct-style reasoning equips the system with a closed-loop observe, think, and act process that enables accurate understanding of complex video content in long-term contexts. Experimental results show that TeleMem surpasses the state-of-the-art Mem0 baseline with 19% higher accuracy, 43% fewer tokens, and a 2.1x speedup on the ZH-4O long-term role-play gaming benchmark.

</details>


### [136] [Operation Veja: Fixing Fundamental Concepts Missing from Modern Roleplaying Training Paradigms](https://arxiv.org/abs/2601.06039)
*Yueze Liu,Ajay Nagi Reddy Kumdam,Ronit Kanjilal,Hao Yang,Yichi Zhang*

Main category: cs.CL

TL;DR: 目前主流的角色扮演模型难以刻画真实、有深度的人物。本论文提出了VEJA框架（价值观、经验、判断和能力），并通过实验表明该框架优化了模型生成角色的真实性和连贯性。


<details>
  <summary>Details</summary>
Motivation: 尽管现有角色扮演AI日益复杂，但它们在创造可信、引人入胜的虚拟角色方面仍有明显不足。作者认为原因在于训练范式忽视了角色内在世界的动态互动。

Method: 提出了VEJA（价值观、经验、判断、能力）框架，作为数据策展的新范式。然后以此框架手工整理了一组数据集，并与当前基准的合成数据集进行对比，通过大模型担任评判者进行质性评估。

Result: 实验发现，基于VEJA框架的数据集在角色真实性和叙事连贯性方面有显著提升，远超当前主流合成数据基线。

Conclusion: 通过采用以VEJA为核心概念的数据策展，可以大幅提升角色扮演模型的真实感和故事一致性。未来构建高质量虚拟角色应注重语义层面的数据设计。

Abstract: Modern roleplaying models are increasingly sophisticated, yet they consistently struggle to capture the essence of believable, engaging characters. We argue this failure stems from training paradigms that overlook the dynamic interplay of a character's internal world. Current approaches, including Retrieval-Augmented Generation (RAG), fact-based priming, literature-based learning, and synthetic data generation, exhibit recurring limitations in modeling the deliberative, value-conflicted reasoning that defines human interaction. In this paper, we identify four core concepts essential for character authenticity: Values, Experiences, Judgments, and Abilities (VEJA). We propose the VEJA framework as a new paradigm for data curation that addresses these systemic limitations. To illustrate the qualitative ceiling enabled by our framework, we present a pilot study comparing a manually curated, VEJA-grounded dataset against a state-of-the-art synthetic baseline. Using an LLM-as-judge evaluation, our findings demonstrate a significant quality gap, suggesting that a shift toward conceptually grounded data curation, as embodied by VEJA, is necessary for creating roleplaying agents with genuine depth and narrative continuity. The full dataset is available at https://github.com/HyouinKyoumaIRL/Operation-Veja

</details>


### [137] [Lexical and Statistical Analysis of Bangla Newspaper and Literature: A Corpus-Driven Study on Diversity, Readability, and NLP Adaptation](https://arxiv.org/abs/2601.06041)
*Pramit Bhattacharyya,Arnab Bhattacharya*

Main category: cs.CL

TL;DR: 本文通过分析孟加拉文学文本和报纸文本，比较了两者在词汇多样性、结构复杂性和可读性等语言学特性的差异，发现文学文本在这些方面表现更为丰富和复杂。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理和文本分析的发展，对不同类型文本的语言属性（如词汇多样性、复杂性）的深入理解可推动相关模型和应用的进步。此前针对孟加拉语的系统性大规模研究较少，本文填补这一空白。

Method: 作者基于两大孟加拉语语料库（Vacaspati文学语料库和IndicCorp报纸语料库），分析了如type-token ratio（TTR）、hapax legomena ratio（HLR）、Bigram多样性、平均音节和词长、Zipf定律遵循程度、困惑度等语言特征，并评估不同语料对下游任务的影响，同时用Flesch和Coleman-Liau等可读性指标评判文本复杂性。

Result: 文学语料在词汇丰富性、结构多样性、困惑度、熵和可读性方面均显著高于报纸语料，并更好地符合Zipf定律。合并文学与报纸语料能改善模型的下游任务表现。

Conclusion: 孟加拉文学文本在语言结构和多样性上远超新闻文本，加入文学语料可以提升NLP模型对任务的适应性。该发现具有一定的通用性，对其他语言和应用同样有启发意义。

Abstract: In this paper, we present a comprehensive corpus-driven analysis of Bangla literary and newspaper texts to investigate their lexical diversity, structural complexity and readability. We undertook Vacaspati and IndicCorp, which are the most extensive literature and newspaper-only corpora for Bangla. We examine key linguistic properties, including the type-token ratio (TTR), hapax legomena ratio (HLR), Bigram diversity, average syllable and word lengths, and adherence to Zipfs Law, for both newspaper (IndicCorp) and literary corpora (Vacaspati).For all the features, such as Bigram Diversity and HLR, despite its smaller size, the literary corpus exhibits significantly higher lexical richness and structural variation. Additionally, we tried to understand the diversity of corpora by building n-gram models and measuring perplexity. Our findings reveal that literary corpora have higher perplexity than newspaper corpora, even for similar sentence sizes. This trend can also be observed for the English newspaper and literature corpus, indicating its generalizability. We also examined how the perfor- mance of models on downstream tasks is influenced by the inclusion of literary data alongside newspaper data. Our findings suggest that inte- grating literary data with newspapers improves the performance of models on various downstream tasks. We have also demonstrated that a literary corpus adheres more closely to global word distribution proper- ties, such as Zipfs law, than a newspaper corpus or a merged corpus of both literary and newspaper texts. Literature corpora also have higher entropy and lower redundancy values compared to a newspaper corpus. We also further assess the readability using Flesch and Coleman-Liau in- dices, showing that literary texts are more complex.

</details>


### [138] [Reinforcement Learning for Chain of Thought Compression with One-Domain-to-All Generalization](https://arxiv.org/abs/2601.06052)
*Hanyu Li,Jiangshan Duo,Bofei Gao,Hailin Zhang,Sujian Li,Xiaotie Deng,Liang Zhao*

Main category: cs.CL

TL;DR: 本论文提出了一种样本级的强化学习压缩方法，通过惩罚不必要的长推理过程，有效减短大型语言模型的平均输出长度20-40%，同时维持甚至提升准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的链式思维推理方法容易导致过度思考，带来高昂的计算成本和延迟，却无法保证准确率提升。此前的解决方案主要是全局静态控制，容易误伤必要的推理步骤，因此需要更精细、动态的控制方法。

Method: 本文提出一种基于软强化学习的样本级压缩策略，仅对模型已掌握且能生成更简洁推理的问题样本进行长推理惩罚，从而在不影响模型关键推理过程的基础上促使其精简输出。

Result: 实验显示，该方法能使模型平均响应长度降低20-40%，且准确率与原模型基本持平或有所提升。同时，这种精简能力在新领域（如代码、指令和常识问答）上表现出良好的跨领域泛化性。

Conclusion: 作者证明了一种稳定的后训练课程（准确率-压缩-准确率）可以最终产出更精炼、更准确的推理模型，建议在高效推理模型开发流程中，将该压缩阶段设为标准步骤。

Abstract: Chain-of-thought reasoning in large language models often creates an "overthinking trap," leading to excessive computational cost and latency for unreliable accuracy gains. Prior work has typically relied on global, static controls that risk penalizing necessary reasoning. We introduce a sample-level, soft reinforcement learning compression method that penalizes inefficiently long rollouts, but only on problems where the model has already mastered and already produced a more concise rollout. Our experiments show that this method reduces average response length by 20-40% with comparable or higher accuracy. Crucially, the compression exhibits strong cross-domain generalization; a model trained on math spontaneously shortens responses on unseen tasks like code, instruction following, and general knowledge QA, with stable or improved accuracy. We demonstrate a stable post-training curriculum (accuracy-compression-accuracy) that can ultimately produce models that are more accurate and reason more concisely, arguing that such compression method should be a standard phase in developing efficient reasoning models.

</details>


### [139] [A Multi-Stage Workflow for the Review of Marketing Content with Reasoning Large Language Models](https://arxiv.org/abs/2601.06054)
*Alberto Purpura,Emily Chen,Swapnil Shinde*

Main category: cs.CL

TL;DR: 本文提出并评估了一种多阶段工作流程，利用微调后的推理大模型（LLM）自动审查营销文本内容的合规性，并比较了不同微调方法与奖励机制对模型表现的影响。


<details>
  <summary>Details</summary>
Motivation: 当前营销内容需严格合规，而复杂多变的规则使人工审核负担加重。借助推理能力强的LLM，有望实现更高效且自动化的文本合规检查。

Method: 提出无需外部知识表示的新方法，自动识别文本合规性问题，并采用监督微调（SFT）、群体相对策略优化（GRPO）等不同微调策略进行对比实验。同时，评估小型LLM在生成推理步骤token后再输出结果的有效性，并考察GRPO训练时不同奖励函数组合对模型表现的影响。

Result: 实验展示了上述方法在精准识别合规问题及多种微调策略表现对比的成效。具体结果包括各微调方法和奖励函数组合带来的性能差异。

Conclusion: 微调推理LLM具有有效自动检测营销内容合规性的潜力；不同微调和奖励机制对模型表现存在显著影响，为后续推广和优化提供了方向。

Abstract: Reasoning Large Language Models (LLMs) have shown promising results when tasked with solving complex problems. In this paper, we propose and evaluate a multi-stage workflow that leverages the capabilities of fine-tuned reasoning LLMs to assist in the review process of marketing content, making sure they comply with a given list of requirements. The contributions of this paper are the following: (i) we present a novel approach -- that does not rely on any external knowledge representation -- for the automatic identification of compliance issues in textual content; (ii) compare the effectiveness of different fine-tuning strategies like Supervised Fine-Tuning (SFT) and Group Relative Policy Optimization (GRPO) in training models to solve this problem; (iii) we evaluate the effectiveness of training small LLMs to generate reasoning tokens before providing their final response; (iv) we evaluate how the choice and combinations of different reward functions affects the performance of a model trained with GRPO.

</details>


### [140] [AzeroS: Extending LLM to Speech with Self-Generated Instruction-Free Tuning](https://arxiv.org/abs/2601.06086)
*Yiwen Shao,Wei Liu,Jiahong Li,Tianzi Wang,Kun Wei,Meng Yu,Dong Yu*

Main category: cs.CL

TL;DR: 该论文提出了一种无需特定任务指令微调的语音大语言模型SIFT方法，并基于该方法提出了AZeroS模型。AZeroS在不微调核心模块、仅小规模训练下，在多个主流基准上取得了最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有将大型语言模型扩展到语音领域的方法，需要大量针对性指令微调数据，且泛化能力较差，收集数据耗时耗力。研究动机在于提升语音大模型对新任务的泛化能力，并减少训练成本。

Method: 作者提出SIFT（Self-Generated Instruction-Free Tuning）范式，通过冻结的大语言模型基于语音的文本表示生成监督信号，无需任务特定的问答数据。基于SIFT提出AZeroS模型，利用公开数据集的语音-文本和语音-副语言标签对进行训练，仅训练两个轻量级投影模块，冻结主干模型和音频编码器。

Result: AZeroS只利用约2.8万个小时的多样语音数据，且仅训练小规模模块，就在VoiceBench、AIR-Bench Foundation (Speech)、AIR-Bench Chat (Speech)等语义和副语言任务上取得了现有最优性能。

Conclusion: 无需特定任务指令和大规模人工数据收集，SIFT范式和AZeroS模型实现了极低训练成本下的优异性能和强泛化能力，为语音领域大模型应用提供了新方向。

Abstract: Extending large language models (LLMs) to the speech domain has recently gained significant attention. A typical approach connects a pretrained LLM with an audio encoder through a projection module and trains the resulting model on large-scale, task-specific instruction-tuning datasets. However, curating such instruction-tuning data for specific requirements is time-consuming, and models trained in this manner often generalize poorly to unseen tasks. In this work, we first formulate that the strongest generalization of a speech-LLM is achieved when it is trained with Self-Generated Instruction-Free Tuning (SIFT), in which supervision signals are generated by a frozen LLM using textual representations of speech as input. Our proposed SIFT paradigm eliminates the need for collecting task-specific question-answer pairs and yields the theoretically best generalization to unseen tasks. Building upon this paradigm, we introduce AZeroS (Auden Zero-instruction-tuned Speech-LLM), which is trained on speech-text pairs derived from publicly available corpora, including approximately 25,000 hours of speech with ASR transcripts and 3,000 hours of speech with paralinguistic labels. Built upon Qwen2.5-7B-Instruct, the model updates only two lightweight projection modules (23.8 million parameters each), while keeping both the LLM and audio encoders frozen. Despite the minimal training cost and modest data scale, AZeroS achieves state-of-the-art performance on both semantic and paralinguistic benchmarks, including VoiceBench, AIR-Bench Foundation (Speech), and AIR-Bench Chat (Speech).

</details>


### [141] [Is Sanskrit the most token-efficient language? A quantitative study using GPT, Gemini, and SentencePiece](https://arxiv.org/abs/2601.06142)
*Anshul Kumar*

Main category: cs.CL

TL;DR: 本文分析了大型语言模型中标记化器对梵语、英语和印地语的标记效率，发现梵语每个标记所包含的信息量更大，存在显著的标记数差异。最新一代标记器虽改进了对梵语紧凑性的捕捉，但仍有偏差。


<details>
  <summary>Details</summary>
Motivation: 梵语因其复杂的词形和语法结构，被认为能以更少的标记传达更多信息，但之前未有研究实证比较梵语与其他语言的标记效率。理解这一点对节省计算资源和提升模型效率有重要意义。

Method: 作者使用包含梵语、英语和印地语三语对齐的《薄伽梵歌》数据集，对多种主流标记化器（如SentencePiece、GPT旧新模型、Gemini等）进行评测，通过标记数量、平均每个标记的字符数、以及单位字符对应的标记数等指标衡量标记效率和成本。

Result: 在公平基线下，梵语与英语/印地语标记数相差约2倍；将梵语注释翻译为英语/印地语后，标记数增加约20倍。GPT-4o时代的最新标记器相较于早期版本大幅减少了对梵语的偏差，但仍无法完全捕捉梵语的高效性，导致非英语用户有“标记惩罚”。

Conclusion: 当前主流标记化器对梵语仍存低效与偏见。本文为未来更高效、更公平的标记器设计提供了数据基础，梵语的高信息密度有潜力有效降低训练与推理成本。

Abstract: Tokens are the basic units of Large Language Models (LLMs). LLMs rely on tokenizers to segment text into these tokens, and tokenization is the primary determinant of computational and inference cost. Sanskrit, one of the oldest languages, is hypothesized to express more meaning per token due to its morphology and grammar rules; however, no prior work has quantified this. We use a dataset of 701 parallel verses of the Bhagavad Gita, which comprises three languages-Sanskrit, English, and Hindi along with transliteration of Sanskrit into English. We test tokenizers including SentencePiece (SPM), older GPT models, and the latest generation tokenizers from Gemini and GPT. We use metrics of token count, characters per token (token efficiency), and tokens per character (token cost). Results show a ~2x difference in token counts between Sanskrit and English/Hindi under the unbiased SPM baseline. English/Hindi translations of Sanskrit commentary resulted in an approximately 20x increase in token count. GPT o200k base (latest, used by GPT-4o) and Gemini (latest) reduce bias by a significant degree compared to GPT cl100k base (used until GPT-4), but still fail to fully capture Sanskrit's compactness. This matters because there might be a penalty bias for non-English users, which inflates the token count. This research provides a foundation for improving future tokenizer design and shows the potential of Sanskrit for highly compact encoding, saving on cost while speeding up training and inference. The code and dataset are available at https://github.com/anshulkr713/sanskrit-token-efficiency

</details>


### [142] [Amory: Building Coherent Narrative-Driven Agent Memory through Agentic Reasoning](https://arxiv.org/abs/2601.06282)
*Yue Zhou,Xiaobo Guo,Belhassen Bayar,Srinivasan H. Sengamedu*

Main category: cs.CL

TL;DR: 本文提出了一种新的对话智能体长期记忆框架 “Amory”，有效提升了长期对话中的推理与记忆能力，并极大提升了效率。


<details>
  <summary>Details</summary>
Motivation: 随着对话持续时间变长，反复处理完整对话历史的计算成本变得不可接受。现有方法通常将对话切割为孤立片段进行高效检索，牺牲了类人记忆的连贯性和细腻度。因此亟需一种平衡效率和记忆质量的方案。

Method: 提出Amory框架，通过在离线时间主动构建结构化记忆，使智能体能以更类似人类的方式整理和巩固对话。具体包括：将片段组织为叙事体，利用“动量”机制巩固记忆，将边缘事实语义化为长期记忆，并在检索时基于叙事连贯性推理，而非仅仅靠嵌入相似度。

Result: 在LOCOMO长期推理基准上，Amory在推理和记忆效果上显著优于现有技术。不仅在大幅减少响应时间（50%）的同时，实现了与全历史推理方法相当的效果，并在记忆覆盖、质量和连贯性上有显著提升。

Conclusion: Amory证明了结合结构化叙事记忆和连贯性驱动检索能够显著提升长期对话智能体的推理效率和质量，优于碎片化嵌入检索方法，为长期对话系统提供了新方向。

Abstract: Long-term conversational agents face a fundamental scalability challenge as interactions extend over time: repeatedly processing entire conversation histories becomes computationally prohibitive. Current approaches attempt to solve this through memory frameworks that predominantly fragment conversations into isolated embeddings or graph representations and retrieve relevant ones in a RAG style. While computationally efficient, these methods often treat memory formation minimally and fail to capture the subtlety and coherence of human memory. We introduce Amory, a working memory framework that actively constructs structured memory representations through enhancing agentic reasoning during offline time. Amory organizes conversational fragments into episodic narratives, consolidates memories with momentum, and semanticizes peripheral facts into semantic memory. At retrieval time, the system employs coherence-driven reasoning over narrative structures. Evaluated on the LOCOMO benchmark for long-term reasoning, Amory achieves considerable improvements over previous state-of-the-art, with performance comparable to full context reasoning while reducing response time by 50%. Analysis shows that momentum-aware consolidation significantly enhances response quality, while coherence-driven retrieval provides superior memory coverage compared to embedding-based approaches.

</details>


### [143] [How well can off-the-shelf LLMs elucidate molecular structures from mass spectra using chain-of-thought reasoning?](https://arxiv.org/abs/2601.06289)
*Yufeng Wang,Lu Wei,Lin Liu,Hao Xu,Haibin Ling*

Main category: cs.CL

TL;DR: 本文提出一种基于Chain-of-Thought（CoT）提示的大语言模型（LLM）推理框架，评估LLMs在解析质谱（MS/MS）数据并预测分子结构方面的能力。尽管LLMs能够生成语法和部分化学上合理的结构，但在准确性和化学推理方面依然不足。


<details>
  <summary>Details</summary>
Motivation: 基于质谱的分子结构解析因碎片化模式复杂和化学空间多样性大而面临挑战。现有LLM虽展现科学推理潜力，但其在化学解读领域能力尚不明确。本文旨在检验LLMs是否能胜任复杂的化学谱图推理任务。

Method: 作者将化学专家的推理步骤（如双键当量分析、中性丢失识别和碎片组装）结构化为CoT提示，使用MassSpecGym数据集，在零样本情境下评估多种主流LLMs（Claude-3.5-Sonnet、GPT-4o-mini、Llama-3系列）对分子结构的预测表现。

Result: 实验表明，LLMs能够输出语法正确且部分合理的分子结构（SMILES），但在化学准确性和推理与正确结构的关联性上表现不佳。

Conclusion: LLM对质谱数据解读具有潜力，但目前在分子结构推断上存在明显不足。研究为将来结合领域知识与强化学习实现更具化学基础的AI推理奠定基础。

Abstract: Mass spectrometry (MS) is a powerful analytical technique for identifying small molecules, yet determining complete molecular structures directly from tandem mass spectra (MS/MS) remains a long-standing challenge due to complex fragmentation patterns and the vast diversity of chemical space. Recent progress in large language models (LLMs) has shown promise for reasoning-intensive scientific tasks, but their capability for chemical interpretation is still unclear. In this work, we introduce a Chain-of-Thought (CoT) prompting framework and benchmark that evaluate how LLMs reason about mass spectral data to predict molecular structures. We formalize expert chemists' reasoning steps-such as double bond equivalent (DBE) analysis, neutral loss identification, and fragment assembly-into structured prompts and assess multiple state-of-the-art LLMs (Claude-3.5-Sonnet, GPT-4o-mini, and Llama-3 series) in a zero-shot setting using the MassSpecGym dataset. Our evaluation across metrics of SMILES validity, formula consistency, and structural similarity reveals that while LLMs can produce syntactically valid and partially plausible structures, they fail to achieve chemical accuracy or link reasoning to correct molecular predictions. These findings highlight both the interpretive potential and the current limitations of LLM-based reasoning for molecular elucidation, providing a foundation for future work that combines domain knowledge and reinforcement learning to achieve chemically grounded AI reasoning.

</details>


### [144] [$\texttt{AMEND++}$: Benchmarking Eligibility Criteria Amendments in Clinical Trials](https://arxiv.org/abs/2601.06300)
*Trisha Das,Mandis Beigi,Jacob Aptekar,Jimeng Sun*

Main category: cs.CL

TL;DR: 本文提出了一种预测临床试验方案中入选标准是否会被后续修订的新NLP任务，并发布了相应数据集和方法。实验表明提出的预训练方法能够有效提升预测效果。


<details>
  <summary>Details</summary>
Motivation: 临床试验方案的修订会带来延误、成本增加及行政负担，尤其入选标准经常被修改。能够提前预测哪些标准将被修订，有助于优化试验设计，减少不必要的成本和时间浪费。

Method: （1）提出"eligibility criteria amendment prediction"任务；（2）构建并公开AMEND++基准套件，包括包含历史版本和修订标签的数据集AMEND及通过LLM降噪得到的AMEND_LLM子集；（3）提出基于历史修订的预训练策略CAMLM，提升模型对修订变化的敏感度。

Result: 实验证明，在多种基线方法下，CAMLM方法在修订预测任务上效果更好，能更准确地预测入选标准的修订可能性。

Conclusion: CAMLM制定的历史修订敏感表达方式，可以有效提升临床试验修订预测，为更高效、更低成本的临床设计提供技术支持。

Abstract: Clinical trial amendments frequently introduce delays, increased costs, and administrative burden, with eligibility criteria being the most commonly amended component. We introduce \textit{eligibility criteria amendment prediction}, a novel NLP task that aims to forecast whether the eligibility criteria of an initial trial protocol will undergo future amendments. To support this task, we release $\texttt{AMEND++}$, a benchmark suite comprising two datasets: $\texttt{AMEND}$, which captures eligibility-criteria version histories and amendment labels from public clinical trials, and $\verb|AMEND_LLM|$, a refined subset curated using an LLM-based denoising pipeline to isolate substantive changes. We further propose $\textit{Change-Aware Masked Language Modeling}$ (CAMLM), a revision-aware pretraining strategy that leverages historical edits to learn amendment-sensitive representations. Experiments across diverse baselines show that CAMLM consistently improves amendment prediction, enabling more robust and cost-effective clinical trial design.

</details>


### [145] [Why LoRA Fails to Forget: Regularized Low-Rank Adaptation Against Backdoors in Language Models](https://arxiv.org/abs/2601.06305)
*Hoang-Chau Luong,Lingwei Chen*

Main category: cs.CL

TL;DR: 本文分析了LoRA在移除后门攻击时的局限，发现其根本问题在于谱特性，并提出了改进方法RoRA，有效提升了防御能力。


<details>
  <summary>Details</summary>
Motivation: 目前低秩适应（LoRA）虽然广泛用于大模型高效参数微调，但在用干净数据微调被植入后门的大模型以消除后门时表现很差。大家普遍认为是由于低秩限制了LoRA修改模型能力。

Method: 作者通过谱分析指出，LoRA失败的原因在于：1）参数更新的谱强度过弱，其奇异值远低于预训练权重；2）谱方向对齐不佳，对任务的正向改动弱，但对后门激活子空间依然有重叠。作者进一步提出了Regularized Low-Rank Adaptation (RoRA)，采用增强谱强度、正则化、去敏约束、谱重缩放等方法，有效调整参数更新的谱特性。

Result: 在多个NLP基准和攻击场景下实验表明，RoRA显著降低了后门攻击的成功率，同时保持了在干净任务上的高准确率。

Conclusion: 文章指出了LoRA移除后门时的本质弱点，并通过RoRA方法实现了更好的后门淡忘和任务保持效果，对以谱分析为核心的模型安全微调提供了新方向。

Abstract: Low-Rank Adaptation (LoRA) is widely used for parameter-efficient fine-tuning of large language models, but it is notably ineffective at removing backdoor behaviors from poisoned pretrained models when fine-tuning on clean dataset. Contrary to the common belief that this weakness is caused primarily by low rank, we show that LoRA's vulnerability is fundamentally spectral. Our analysis identifies two key factors: LoRA updates (i) possess insufficient spectral strength, with singular values far below those of pretrained weights, and (ii) exhibit unfavorable spectral alignment, weakly matching clean-task directions while retaining overlap with trigger-sensitive subspaces. We further establish a critical scaling threshold beyond which LoRA can theoretically suppress trigger-induced activations, and we show empirically that standard LoRA rarely reaches this regime. We introduce Regularized Low-Rank Adaptation (RoRA), which improves forgetting by increasing spectral strength and correcting alignment through clean-strengthened regularization, trigger-insensitive constraints, and post-training spectral rescaling. Experiments across multiple NLP benchmarks and attack settings show that RoRA substantially reduces attack success rates while maintaining clean accuracy.

</details>


### [146] [SyntaxMind at BLP-2025 Task 1: Leveraging Attention Fusion of CNN and GRU for Hate Speech Detection](https://arxiv.org/abs/2601.06306)
*Md. Shihab Uddin Riad*

Main category: cs.CL

TL;DR: 本文提出了一个融合BanglaBERT嵌入、GRU与CNN多分支结构的统一模型，用于孟加拉语仇恨言论检测，并在相关竞赛中取得优异成绩。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语社交媒体上仇恨言论日益增多，准确检测对于维护网络环境和社会稳定至关重要。目前针对孟加拉语的高效仇恨言论检测方法有限，急需提升模型性能，以满足实际需求。

Method: 作者提出了一种统一的神经网络架构，将BanglaBERT用于文本嵌入，并设计了包括GRU和CNN的多分支结构，用于捕捉句子的上下文语义和局部语言特征，同时加入注意力机制与全连接层进行最终分类。

Result: 在BLP-2025任务1的子任务1A中，该模型获得了0.7345的micro F1分数（排名第2），在子任务1B中获得0.7317的micro F1分数（排名第5），展现出较强的竞争力。

Conclusion: 融合BERT嵌入与GRU、CNN多分支处理的统一架构可以有效提升孟加拉语仇恨言论检测效果，为多语言低资源场景下的文本分类提供了有益实践和经验。

Abstract: This paper describes our system used in the BLP-2025 Task 1: Hate Speech Detection. We participated in Subtask 1A and Subtask 1B, addressing hate speech classification in Bangla text. Our approach employs a unified architecture that integrates BanglaBERT embeddings with multiple parallel processing branches based on GRUs and CNNs, followed by attention and dense layers for final classification. The model is designed to capture both contextual semantics and local linguistic cues, enabling robust performance across subtasks. The proposed system demonstrated high competitiveness, obtaining 0.7345 micro F1-Score (2nd place) in Subtask 1A and 0.7317 micro F1-Score (5th place) in Subtask 1B.

</details>


### [147] [A Rising Tide Lifts All Boats: MTQE Rewards for Idioms Improve General Translation Quality](https://arxiv.org/abs/2601.06307)
*Ishika Agarwal,Zhenlin He,Dhruva Patil,Dilek Hakkani-Tür*

Main category: cs.CL

TL;DR: 本文针对神经机器翻译系统难以处理成语、谚语、隐喻等非组合性表达的问题，提出利用基于质量评估模型的GRPO风格微调方法，显著提升了成语翻译和跨语言泛化能力。


<details>
  <summary>Details</summary>
Motivation: 神经机器翻译系统在翻译像成语、谚语和隐喻等非组合性表达时效果不佳，因为这些表达的整体含义无法由单词逐一推断，且具有丰富文化内涵和双重（字面及引申）含义。

Method: 作者使用Machine Translation Quality Estimation（MTQE）模型作为奖励函数，通过GRPO（类似强化学习）的方式对翻译模型进行微调。实验在中文和印地语成语数据集上进行评估。

Result: 成语翻译能力提升了约14分，普通非成语文本翻译也提升了约8分，跨语言泛化能力提升了约6分。

Conclusion: 该研究为量化非组合性表达翻译难题提供了新方法，并对开发拥有更强跨文化和比喻理解能力的大型语言模型提供了有益启示。

Abstract: Non-compositional expressions (e.g., idioms, proverbs, and metaphors) pose significant challenges for neural machine translation systems because their meanings cannot be derived from individual words alone. These expressions encode rich, cultural meaning, and have both figurative and literal meanings, making accurate translation difficult. Because models are fairly good at translating compositional text, we investigate GRPO-style fine-tuning using Machine Translation Quality Estimation (MTQE) models as reward functions to train models to better translate idioms. Using Chinese and Hindi idiom datasets, we find that idiom translation abilities improve by ~14 points, general, non-idiomatic translation implicitly improves by ~8 points, and cross-lingual translation abilities (trained on one language, evaluated on another) improves by ~6 points. Overall, our work quantifies the non-compositional translation gap and offers insights for developing LLMs with stronger cross-cultural and figurative language understanding.

</details>


### [148] [Annotating Dimensions of Social Perception in Text: The First Sentence-Level Dataset of Warmth and Competence](https://arxiv.org/abs/2601.06316)
*Mutaz Ayesh,Saif M. Mohammad,Nedjma Ousidhoum*

Main category: cs.CL

TL;DR: 该论文介绍了首个用于句子级温暖和能力标签的数据集W&C-Sent，并评估了大语言模型在识别文本中信任、社交性和能力的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管温暖和能力在社会心理学领域早已被证实为评估个体或群体的核心维度，但在自然语言处理领域的研究较少，且现有资源多为词汇级，难以捕捉句子和篇章层面的表达。

Method: 作者构建了一个包含1600多对英文句子及其目标对象的数据集，对每对句子进行信任、社交性（均为温暖子维度）和能力标签标注，并详细描述了数据采集和质量控制流程。此外，作者还评估了多种大语言模型对信任、社交性和能力维度的识别能力。

Result: 作者获得了高质量的句子级温暖和能力标签数据集，并发现部分大语言模型在识别这些社会属性方面具有一定能力，但仍有改进空间。

Conclusion: W&C-Sent数据集为分析和研究文本中的温暖与能力维度，尤其是社会计算与NLP交叉领域，提供了新资源和基础，将促进后续相关研究。

Abstract: Warmth (W) (often further broken down into Trust (T) and Sociability (S)) and Competence (C) are central dimensions along which people evaluate individuals and social groups (Fiske, 2018). While these constructs are well established in social psychology, they are only starting to get attention in NLP research through word-level lexicons, which do not completely capture their contextual expression in larger text units and discourse. In this work, we introduce Warmth and Competence Sentences (W&C-Sent), the first sentence-level dataset annotated for warmth and competence. The dataset includes over 1,600 English sentence--target pairs annotated along three dimensions: trust and sociability (components of warmth), and competence. The sentences in W&C-Sent are from social media and often express attitudes and opinions about specific individuals or social groups (the targets of our annotations). We describe the data collection, annotation, and quality-control procedures in detail, and evaluate a range of large language models (LLMs) on their ability to identify trust, sociability, and competence in text. W&C-Sent provides a new resource for analyzing warmth and competence in language and supports future research at the intersection of NLP and computational social science.

</details>


### [149] [On the Fallacy of Global Token Perplexity in Spoken Language Model Evaluation](https://arxiv.org/abs/2601.06329)
*Jeff Chan-Jan Sju,Liang-Hsuan Tseng,Yi-Cheng Lin,Yen-Chun Kuo,Ju-Chieh Chou,Kai-Wei Chang,Hung-yi Lee,Carlos Busso*

Main category: cs.CL

TL;DR: 该论文针对生成式口语模型的评估问题，提出了一系列新颖的用于替代传统全局token困惑度的评估方法，并验证这些新方法与人工主观评分的相关性更强，可更真实反映口语生成质量。


<details>
  <summary>Details</summary>
Motivation: 当前主流的口语生成模型评估指标（如全局token困惑度）直接借用了文本领域的做法，却忽视了语音与文本模态的本质差异，可能低估了口语生成的特性与质量。因此，急需更适合语音模态的评估方法。

Method: 提出多种基于似然性和生成质量的新评估方法，并将其应用于主流生成式口语模型，通过与人类打分（MOS）的相关性对比，检验新指标的有效性。

Result: 新提出的评估方法与人类主观意见得分（MOS）之间的相关性显著高于传统困惑度指标。采用新评估标准后，不同模型间的性能差距较原有评价体系更小，部分优秀模型的性能接近人工上限。

Conclusion: 合理的评估方法对于口语生成模型的进展衡量至关重要。新指标能更准确反映模型实际效果，建议未来相关领域采用更贴近人类感知的评价方案。

Abstract: Generative spoken language models pretrained on large-scale raw audio can continue a speech prompt with appropriate content while preserving attributes like speaker and emotion, serving as foundation models for spoken dialogue. In prior literature, these models are often evaluated using ``global token perplexity'', which directly applies the text perplexity formulation to speech tokens. However, this practice overlooks fundamental differences between speech and text modalities, possibly leading to an underestimation of the speech characteristics. In this work, we propose a variety of likelihood- and generative-based evaluation methods that serve in place of naive global token perplexity. We demonstrate that the proposed evaluations more faithfully reflect perceived generation quality, as evidenced by stronger correlations with human-rated mean opinion scores (MOS). When assessed under the new metrics, the relative performance landscape of spoken language models is reshaped, revealing a significantly reduced gap between the best-performing model and the human topline. Together, these results suggest that appropriate evaluation is critical for accurately assessing progress in spoken language modeling.

</details>


### [150] [What Matters When Building Universal Multilingual Named Entity Recognition Models?](https://arxiv.org/abs/2601.06347)
*Jonas Golde,Patrick Haller,Alan Akbik*

Main category: cs.CL

TL;DR: 本文提出了Otter，多语言通用命名实体识别（NER）模型，支持100多种语言，并在现有NER基线模型上取得了显著性能提升，同时模型更加高效。


<details>
  <summary>Details</summary>
Motivation: 目前多语言NER领域虽然进展迅速，但许多架构组件、训练目标和数据来源的设计决策缺乏系统性分析，行业难以明确哪些决定真正提升了模型性能。因此，作者希望通过拆解这些设计因素，推动领域发展并提升透明度。

Method: 作者对现有多语言NER模型的架构、transformer主干网络、训练目标以及数据组合进行了系统对比实验。基于实验结论，作者设计并提出了新的通用NER模型Otter，并对其进行了广泛测试和评估。

Result: Otter模型在100多种语言上取得了优于GLiNER-x-base模型（F1提升5.3个百分点），同时在性能和效率方面优于大规模生成式模型（如Qwen3-32B）。

Conclusion: Otter是一款高效且强大的多语言NER模型，显著推动了多语言NER任务的进展，并通过开源模型权重和代码促进领域复现与后续研究。

Abstract: Recent progress in universal multilingual named entity recognition (NER) has been driven by advances in multilingual transformer models and task-specific architectures, loss functions, and training datasets. Despite substantial prior work, we find that many critical design decisions for such models are made without systematic justification, with architectural components, training objectives, and data sources evaluated only in combination rather than in isolation. We argue that these decisions impede progress in the field by making it difficult to identify which choices improve model performance. In this work, we conduct extensive experiments around architectures, transformer backbones, training objectives, and data composition across a wide range of languages. Based on these insights, we introduce Otter, a universal multilingual NER model supporting over 100 languages. Otter achieves consistent improvements over strong multilingual NER baselines, outperforming GLiNER-x-base by 5.3pp in F1 and achieves competitive performance compared to large generative models such as Qwen3-32B, while being substantially more efficient. We release model checkpoints, training and evaluation code to facilitate reproducibility and future research.

</details>


### [151] [Average shortest-path length in word-adjacency networks: Chinese versus English](https://arxiv.org/abs/2601.06361)
*Jakub Dec,Michał Dolina,Stanisław Drożdż,Jarosław Kwapień,Jin Liu,Tomasz Stanisz*

Main category: cs.CL

TL;DR: 本文利用复杂网络理论，分析了包含标点符号的中英文文学作品中的词邻接网络，发现将标点作为词后两种语言的网络性质更趋近，为语言和文体研究提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 传统语言网络研究多忽略标点符号，但标点实际承载情感、组织语句并有助理解。前期研究还发现标点在统计特征上类似于词，将其纳入可提升作者识别的准确性，因此有必要系统分析其对语言网络结构的影响。

Method: 以不同年代的中英文文学作品为文本，构建“词-邻接网络”，创新性地将标点作为等同词处理，对比包含和不包含标点时网络平均最短路径长度$L(N)$与节点数$N$的关系，并与翻译文本进行交叉分析。用增长型网络模型对实证结果拟合以解释观测规律。

Result: 实测得包含标点的中英文网络中平均最短路径随规模增长的规律较为一致，拟合模型能较好地复现实证数据。若忽略标点，则中文网络的$L(N)$较英文显著增大。

Conclusion: 标点符号在语言网络结构分析中起到重要作用，将其视为词后有助统一不同语言的网络性质，有助于提高文本风格判别等任务的准确性，对自然语言处理和语言认知研究具有启发意义。

Abstract: Complex networks provide powerful tools for analyzing and understanding the intricate structures present in various systems, including natural language. Here, we analyze topology of growing word-adjacency networks constructed from Chinese and English literary works written in different periods. Unconventionally, instead of considering dictionary words only, we also include punctuation marks as if they were ordinary words. Our approach is based on two arguments: (1) punctuation carries genuine information related to emotional state, allows for logical grouping of content, provides a pause in reading, and facilitates understanding by avoiding ambiguity, and (2) our previous works have shown that punctuation marks behave like words in a Zipfian analysis and, if considered together with regular words, can improve authorship attribution in stylometric studies. We focus on a functional dependence of the average shortest path length $L(N)$ on a network size $N$ for different epochs and individual novels in their original language as well as for translations of selected novels into the other language. We approximate the empirical results with a growing network model and obtain satisfactory agreement between the two. We also observe that $L(N)$ behaves asymptotically similar for both languages if punctuation marks are included but becomes sizably larger for Chinese if punctuation marks are neglected.

</details>


### [152] [Talking to Extraordinary Objects: Folktales Offer Analogies for Interacting with Technology](https://arxiv.org/abs/2601.06372)
*Martha Larson*

Main category: cs.CL

TL;DR: 本论文探讨了童话故事中与非常规物体对话的现象，提出将这些类比应用于人机交互领域，在技术交流中摆脱对类人化的依赖。


<details>
  <summary>Details</summary>
Motivation: 随着与技术互动的日益广泛，社会对通过语言与技术沟通时人性化倾向的反思逐渐增多。童话故事中语言交流对象的多样性为新的交互方式提供了启示。

Method: 本文通过回顾和分析童话故事中的相关案例，归纳总结了非人类物体具备语言和智能的多样表现，并探讨其对当代人机语音交互的借鉴意义。

Result: 论文发现，童话故事中的非凡物品通常具备多样和令人深刻记忆的特征，其语言能力和智能与人类属性并非总是相关。类比方法为我们提供了跳出人型框架、设计新的技术互动方式的思路。

Conclusion: 借鉴童话中与非凡物件对话的经验，有助于技术产品在语言与语音交互设计上摆脱类人化限制，获得更具创意与包容性的互动体验。

Abstract: Speech and language are valuable for interacting with technology. It would be ideal to be able to decouple their use from anthropomorphization, which has recently met an important moment of reckoning. In the world of folktales, language is everywhere and talking to extraordinary objects is not unusual. This overview presents examples of the analogies that folktales offer. Extraordinary objects in folktales are diverse and also memorable. Language capacity and intelligence are not always connected to humanness. Consideration of folktales can offer inspiration and insight for using speech and language for interacting with technology.

</details>


### [153] [AfriqueLLM: How Data Mixing and Model Architecture Impact Continued Pre-training for African Languages](https://arxiv.org/abs/2601.06395)
*Hao Yu,Tianyi Xu,Michael A. Hedderich,Wassim Hamidouche,Syed Waqas Zamir,David Ifeoluwa Adelani*

Main category: cs.CL

TL;DR: 本文推出了AfriqueLLM，一套为20种非洲语言适配的大型开放语言模型，通过连续预训练提升了模型在多语言任务中的表现，尤其是逻辑推理类任务。


<details>
  <summary>Details</summary>
Motivation: 开放大型语言模型在多语言，尤其是低资源非洲语言上的表现不及专有模型，且面临数据领域覆盖不足、任务相关知识缺乏等挑战。

Method: 作者对不同架构和规模（如Llama 3.1, Gemma 3, Qwen 3）的基础模型，在26B标记的多样化数据（含数学、代码、合成翻译语料）上进行连续预训练，并通过多语言基准系统性评估数据组成对性能的影响。

Result: 实验证明数据组成是连续预训练效果的关键驱动因素。引入数学、代码及合成翻译数据可持续提升模型，尤其是在推理类测试上有明显收益。模型架构对性能的影响大于模型规模，不同基础模型的多语言能力不直接等同于预训练之后的表现。

Conclusion: 只要选对模型架构并用任务相关的数据进行适配，就能显著提升非洲语言 LLM 的能力。AfriqueLLM 在长上下文和文档级翻译中表现优异，已开源发布。

Abstract: Large language models (LLMs) are increasingly multilingual, yet open models continue to underperform relative to proprietary systems, with the gap most pronounced for African languages. Continued pre-training (CPT) offers a practical route to language adaptation, but improvements on demanding capabilities such as mathematical reasoning often remain limited. This limitation is driven in part by the uneven domain coverage and missing task-relevant knowledge that characterize many low-resource language corpora. We present \texttt{AfriqueLLM}, a suite of open LLMs adapted to 20 African languages through CPT on 26B tokens. We perform a comprehensive empirical study across five base models spanning sizes and architectures, including Llama 3.1, Gemma 3, and Qwen 3, and systematically analyze how CPT data composition shapes downstream performance. In particular, we vary mixtures that include math, code, and synthetic translated data, and evaluate the resulting models on a range of multilingual benchmarks. Our results identify data composition as the primary driver of CPT gains. Adding math, code, and synthetic translated data yields consistent improvements, including on reasoning-oriented evaluations. Within a fixed architecture, larger models typically improve performance, but architectural choices dominate scale when comparing across model families. Moreover, strong multilingual performance in the base model does not reliably predict post-CPT outcomes; robust architectures coupled with task-aligned data provide a more dependable recipe. Finally, our best models improve long-context performance, including document-level translation. Models have been released on [Huggingface](https://huggingface.co/collections/McGill-NLP/afriquellm).

</details>


### [154] [MITRA: A Large-Scale Parallel Corpus and Multilingual Pretrained Language Model for Machine Translation and Semantic Retrieval for Pāli, Sanskrit, Buddhist Chinese, and Tibetan](https://arxiv.org/abs/2601.06400)
*Sebastian Nehrdich,Kurt Keutzer*

Main category: cs.CL

TL;DR: 该论文提出了MITRA框架，包括多语种平行语料挖掘管道、一套大规模平行语料库，以及针对佛教古文献多语机器翻译和语义嵌入的专用预训练语言模型和其衍生模型。实验表明，该框架相关模型在跨语言机器翻译和语义嵌入任务上均达到了先进水平。


<details>
  <summary>Details</summary>
Motivation: 佛教古文献中存在大量分布于多种语言的未注释文本平行片段。手动比对这些资料极为耗时且不可行，因此亟需自动化、多语种处理工具，助力相关文献研究和自然语言处理任务。

Method: 1. 构建MITRA-parallel管道，实现梵文、中文、藏文等多语种平行句对的自动挖掘，构建了包含174万句对的大型语料库。
2. 基于新语料库，训练了专用预训练语言模型Gemma 2 MITRA，并开发了两个衍生模型：Gemma 2 MITRA-MT（用于机器翻译任务）和Gemma 2 MITRA-E（用于语义嵌入）。
3. 通过开源数据集、模型权重和新颖的语义相似性基准，为后续相关研究提供资源。

Result: Gemma 2 MITRA-MT在梵文、藏文、中文向英文的机器翻译任务中达到或者超过现有最优开源模型，其中包括比其体量更大的模型。Gemma 2 MITRA-E在新提出的细粒度语义嵌入基准上同样实现了先进性能。

Conclusion: MITRA框架有效解决了佛教古文献多语平行片段挖掘、翻译和语义理解的难题，为跨语种古文献研究和NLP相关任务提供了高质量资源和基线模型，推动了领域技术发展。

Abstract: Ancient Buddhist literature features frequent, yet often unannotated, textual parallels spread across diverse languages: Sanskrit, Pāli, Buddhist Chinese, Tibetan, and more. The scale of this material makes manual examination prohibitive. We present the MITRA framework, which consists of a novel pipeline for multilingual parallel passage mining, MITRA-parallel, a large-scale corpus of 1.74 million parallel sentence pairs between Sanskrit, Chinese, and Tibetan, and the development of the domain-specific pretrained language model Gemma 2 MITRA. We present Gemma 2 MITRA-MT, a version of this base model fine-tuned on machine translation tasks, reaching state-of-the-art performance for machine translation of these languages into English and outperforming even much larger open-source models. We also present Gemma 2 MITRA-E, a semantic embedding model that shows state-of-the-art performance on a novel, detailed semantic embedding benchmark. We make the parallel dataset, model weights, and semantic similarity benchmark openly available to aid both NLP research and philological studies in Buddhist and classical Asian literature.

</details>


### [155] [Steer Model beyond Assistant: Controlling System Prompt Strength via Contrastive Decoding](https://arxiv.org/abs/2601.06403)
*Yijiang River Dong,Tiancheng Hu,Zheng Hui,Nigel Collier*

Main category: cs.CL

TL;DR: 提出了一种训练外即可调节大模型行为的新方法，通过放大系统提示词的行为信号，有效增强模型对目标角色的服从性和可控性。


<details>
  <summary>Details</summary>
Motivation: 当前大模型虽然能理解复杂指令，但因后训练过程中形成的“有用助手”角色先验，导致难以服从与角色冲突的指示，缺乏灵活可调的行为控制手段。

Method: 提出了“系统提示词强度”（system prompt strength）方法：不需重新训练，通过对比目标和默认系统提示词下的logits，提取出目标角色的独特行为信号，并用标量alpha放大，从而实现对模型服从性的连续控制。

Result: 在五个不同方向的基准上（包括约束满足、行为控制、多元对齐、能力调节和风格控制），该方法带来了显著提升：IFEval准确率提升8.5，OffTopicEval拒绝率提升45%，Prompt-Steering可控性提升13%。

Conclusion: 该方法为大模型用户和开发者提供了动态调节系统提示词影响强度的能力，无需重新训练即可灵活控制模型行为，实现更精细的个性化对齐。

Abstract: Large language models excel at complex instructions yet struggle to deviate from their helpful assistant persona, as post-training instills strong priors that resist conflicting instructions. We introduce system prompt strength, a training-free method that treats prompt adherence as a continuous control. By contrasting logits from target and default system prompts, we isolate and amplify the behavioral signal unique to the target persona by a scalar factor alpha. Across five diverse benchmarks spanning constraint satisfaction, behavioral control, pluralistic alignment, capability modulation, and stylistic control, our method yields substantial improvements: up to +8.5 strict accuracy on IFEval, +45pp refusal rate on OffTopicEval, and +13% steerability on Prompt-Steering. Our approach enables practitioners to modulate system prompt strength, providing dynamic control over model behavior without retraining.

</details>


### [156] [Value of Information: A Framework for Human-Agent Communication](https://arxiv.org/abs/2601.06407)
*Yijiang River Dong,Tiancheng Hu,Zheng Hui,Caiqi Zhang,Ivan Vulić,Andreea Bobu,Nigel Collier*

Main category: cs.CL

TL;DR: 本文提出了一种基于信息价值(Value of Information, VoI)的决策理论框架，使LLM智能体能在面对信息不完全的实际任务时，动态平衡主动询问用户与自行决策的取舍，无需繁琐的超参数调优，在多种任务领域中性能优越。


<details>
  <summary>Details</summary>
Motivation: 现实中用户请求常常不完整，LLM智能体既需要避免在信息不足下冒险行动，又要减少频繁追问用户带来的体验负担。现有方法要么过于依赖人工调参、适应性差，要么忽略不同决策所带来的后果风险差异。

Method: 作者引入决策理论中的信息价值（VoI）作为权衡标准，使智能体在推理阶段自动计算主动询问的预期收益与对用户造成的认知负担。该方法无需任务相关的超参数调优，能自适应于不同任务和背景。

Result: 在20个问题猜测、医学诊断、航班预订和电商四个领域的实验显示，VoI方法在高代价环境下可比最佳手动调优基线高出多达1.36个效用分。在所有情境下，VoI能够始终与最优基线持平或优于其表现。

Conclusion: 本文提出的无参数自适应沟通框架可根据任务风险、查询不确定性和用户努力之间的平衡，优化LLM智能体与用户的交互，具有广泛的实际应用价值。

Abstract: Large Language Model (LLM) agents deployed for real-world tasks face a fundamental dilemma: user requests are underspecified, yet agents must decide whether to act on incomplete information or interrupt users for clarification. Existing approaches either rely on brittle confidence thresholds that require task-specific tuning, or fail to account for the varying stakes of different decisions. We introduce a decision-theoretic framework that resolves this trade-off through the Value of Information (VoI), enabling agents to dynamically weigh the expected utility gain from asking questions against the cognitive cost imposed on users. Our inference-time method requires no hyperparameter tuning and adapts seamlessly across contexts-from casual games to medical diagnosis. Experiments across four diverse domains (20 Questions, medical diagnosis, flight booking, and e-commerce) show that VoI consistently matches or exceeds the best manually-tuned baselines, achieving up to 1.36 utility points higher in high-cost settings. This work provides a parameter-free framework for adaptive agent communication that explicitly balances task risk, query ambiguity, and user effort.

</details>


### [157] [Structured Episodic Event Memory](https://arxiv.org/abs/2601.06411)
*Zhengxuan Lu,Dongfang Li,Yukun Shi,Beilun Wang,Longyue Wang,Baotian Hu*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的结构化记忆框架SEEM，有效提升了大语言模型在长时推理与叙事连贯性方面的能力，超越现有静态RAG方法。


<details>
  <summary>Details</summary>
Motivation: 当前主流的RAG方法在检索强化生成时，存在碎片化检索，难以捕捉复杂推理中事件间的结构依赖。对于自主智能体，这类方法缺乏模拟真实长期动态互动所需的认知组织性。

Method: 作者提出了SEEM（Structured Episodic Event Memory），包括分层的图结构记忆层（用于关系事实）和动态情节记忆层（叙述推进），以认知框架理论为基础，将交互流转化为有精确溯源指针的结构化Episodic Event Frames（EEF）。此外，设计了Agentic Associative Fusion和Reverse Provenance Expansion（RPE）机制，用于从碎片证据中重建连贯叙事上下文。

Result: SEEM在LoCoMo和LongMemEval两个基准集上显著优于现有方法，尤其在保持叙事连贯性和逻辑一致性方面表现突出。

Conclusion: SEEM通过结构化的事件记忆与溯源机制，为大语言模型和自主代理提供了更强的复杂推理与长期互动能力，推动了智能体记忆系统的发展。

Abstract: Current approaches to memory in Large Language Models (LLMs) predominantly rely on static Retrieval-Augmented Generation (RAG), which often results in scattered retrieval and fails to capture the structural dependencies required for complex reasoning. For autonomous agents, these passive and flat architectures lack the cognitive organization necessary to model the dynamic and associative nature of long-term interaction. To address this, we propose Structured Episodic Event Memory (SEEM), a hierarchical framework that synergizes a graph memory layer for relational facts with a dynamic episodic memory layer for narrative progression. Grounded in cognitive frame theory, SEEM transforms interaction streams into structured Episodic Event Frames (EEFs) anchored by precise provenance pointers. Furthermore, we introduce an agentic associative fusion and Reverse Provenance Expansion (RPE) mechanism to reconstruct coherent narrative contexts from fragmented evidence. Experimental results on the LoCoMo and LongMemEval benchmarks demonstrate that SEEM significantly outperforms baselines, enabling agents to maintain superior narrative coherence and logical consistency.

</details>


### [158] [Can a Unimodal Language Agent Provide Preferences to Tune a Multimodal Vision-Language Model?](https://arxiv.org/abs/2601.06424)
*Sazia Tabasum Mim,Jack Morris,Manish Dhakal,Yanming Xiu,Maria Gorlatova,Yi Ding*

Main category: cs.CL

TL;DR: 本文提出了一种让语言生成模型（LLM）为视觉-语言模型（VLM）提供反馈的方法，从而提升VLM多模态描述能力，实验表明该方法有效提升了多模态模型的准确性和人类偏好一致性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大模型发展迅速，但如何为现有单模态LLM无缝扩展多模态能力仍是难题。论文关注：单靠文本的LLM能否识别自身信息需求，并为VLM提供优化反馈？

Method: 提出让LLM作为agent，对VLM生成的多模态描述进行审视，并提供偏好反馈；VLM据此调整生成内容。设计多项实验检验方法有效性，并通过人类评价进一步验证。

Result: 方法使VLM多模态场景描述获得最大13%的绝对准确率提升，并在人类偏好一致率上达到了64.6%。

Conclusion: LLM生成的反馈能有效优化VLM输出，提升多模态场景理解和人机一致性，验证了单模态LLM可助力多模态模型改进，但方法仍有局限需进一步研究。

Abstract: To explore a more scalable path for adding multimodal capabilities to existing LLMs, this paper addresses a fundamental question: Can a unimodal LLM, relying solely on text, reason about its own informational needs and provide effective feedback to optimize a multimodal model? To answer this, we propose a method that enables a language agent to give feedback to a vision-language model (VLM) to adapt text generation to the agent's preferences. Our results from different experiments affirm this hypothesis, showing that LLM preference feedback significantly enhances VLM descriptions. Using our proposed method, we find that the VLM can generate multimodal scene descriptions to help the LLM better understand multimodal context, leading to improvements of maximum 13% in absolute accuracy compared to the baseline multimodal approach. Furthermore, a human study validated our AI-driven feedback, showing a 64.6% preference alignment rate between the LLM's choices and human judgments. Extensive experiments provide insights on how and why the method works and its limitations.

</details>


### [159] [NC-Bench: An LLM Benchmark for Evaluating Conversational Competence](https://arxiv.org/abs/2601.06426)
*Robert J. Moore,Sungeun An,Farhan Ahmed,Jay Pankaj Gala*

Main category: cs.CL

TL;DR: NC-Bench提出了一种基于对话结构和形式，而非内容的新型大模型（LLMs）对话能力评测基准。分为基础对话、RAG和复杂请求三套评测，测试模型在不同对话情境下的表现。


<details>
  <summary>Details</summary>
Motivation: 现有大模型对话评测多关注于内容相关性，忽略了对话本身结构和自然性。本文旨在以人类自然对话为基础，系统评价模型在实际对话管理能力上的表现。

Method: 基于IBM自然对话框架（NCF），设计三类评测集：基础对话能力（如问答、修复、收尾）、RAG结合型、复杂请求型。每类聚焦于一组对话序列管理模式，评测14类互动模式下6个开源模型的表现。

Result: 模型在基础问答任务表现良好，在对话修复（尤其是重复）方面表现较弱，收尾表现一般；面对复杂多轮请求显著受挑战。Qwen模型在基础对话表现突出，Granite模型在RAG与复杂请求上更优。

Conclusion: NC-Bench以对话基本原理为基础，提供了一套轻量、可扩展、理论支撑的LLM对话评测框架，为模型能力改进和多样化应用场景评估奠定基础。

Abstract: The Natural Conversation Benchmark (NC-Bench) introduce a new approach to evaluating the general conversational competence of large language models (LLMs). Unlike prior benchmarks that focus on the content of model behavior, NC-Bench focuses on the form and structure of natural conversation. Grounded in the IBM Natural Conversation Framework (NCF), NC-Bench comprises three distinct sets. The Basic Conversation Competence set evaluates fundamental sequence management practices, such as answering inquiries, repairing responses, and closing conversational pairs. The RAG set applies the same sequence management patterns as the first set but incorporates retrieval-augmented generation (RAG). The Complex Request set extends the evaluation to complex requests involving more intricate sequence management patterns. Each benchmark tests a model's ability to produce contextually appropriate conversational actions in response to characteristic interaction patterns. Initial evaluations across 6 open-source models and 14 interaction patterns show that models perform well on basic answering tasks, struggle more with repair tasks (especially repeat), have mixed performance on closing sequences, and find complex multi-turn requests most challenging, with Qwen models excelling on the Basic set and Granite models on the RAG set and the Complex Request set. By operationalizing fundamental principles of human conversation, NC-Bench provides a lightweight, extensible, and theory-grounded framework for assessing and improving the conversational abilities of LLMs beyond topical or task-specific benchmarks.

</details>


### [160] [Time Travel Engine: A Shared Latent Chronological Manifold Enables Historical Navigation in Large Language Models](https://arxiv.org/abs/2601.06437)
*Jingmin An,Wei Liu,Qian Wang,Fang Fang*

Main category: cs.CL

TL;DR: 本文提出Time Travel Engine（TTE）框架，揭示大语言模型中的时间信息以连续几何形式组织，实现模型输出随历史时期平滑变化，跨中英文具备共性。


<details>
  <summary>Details</summary>
Motivation: 现有对大语言模型理解其如何编码时间（年代）进展的机制有限，尤其不清楚时间信息在模型潜空间中的表现形式。该研究试图解答：LLM是如何认知与表达随时代变化的语言特征及知识的？

Method: 提出TTE框架，直接在潜表示空间中对时间特性进行可控操作，而不是通过传统的prompt。在残差流内将历时（diachronic）演变参数化为连续流形（manifold），实现输出风格、用词、概念随目标时期变化。

Result: 实验验证TTE不仅使输出能够随时间平滑变化；且在不同架构及中英文对比下，模型内部编码时间信息的子空间具备拓扑同构性，表明跨语言的演化几何逻辑趋同。

Conclusion: 本工作为历史语言学与神经网络可解释性架起桥梁，提出了控制神经网络时间推理的新范式，为深入理解LLM的时间认知机制带来新视角。

Abstract: Time functions as a fundamental dimension of human cognition, yet the mechanisms by which Large Language Models (LLMs) encode chronological progression remain opaque. We demonstrate that temporal information in their latent space is organized not as discrete clusters but as a continuous, traversable geometry. We introduce the Time Travel Engine (TTE), an interpretability-driven framework that projects diachronic linguistic patterns onto a shared chronological manifold. Unlike surface-level prompting, TTE directly modulates latent representations to induce coherent stylistic, lexical, and conceptual shifts aligned with target eras. By parameterizing diachronic evolution as a continuous manifold within the residual stream, TTE enables fluid navigation through period-specific "zeitgeists" while restricting access to future knowledge. Furthermore, experiments across diverse architectures reveal topological isomorphism between the temporal subspaces of Chinese and English-indicating that distinct languages share a universal geometric logic of historical evolution. These findings bridge historical linguistics with mechanistic interpretability, offering a novel paradigm for controlling temporal reasoning in neural networks.

</details>


### [161] [LitVISTA: A Benchmark for Narrative Orchestration in Literary Text](https://arxiv.org/abs/2601.06445)
*Mingzhe Lu,Yiwen Wang,Yanbing Liu,Qi You,Chong Liu,Ruize Qin,Haoyu Dong,Wenyu Zhang,Jiarui Zhang,Yue Hu,Yunpeng Li*

Main category: cs.CL

TL;DR: 论文指出现有大模型生成故事时，过于关注因果连贯性，忽视了文学文本中的复杂结构和叙事编排。为此，作者提出了一种高维叙事表示框架VISTA Space，并构建了相应的文学基准数据集LitVISTA，用于系统评估模型在文学叙事编排方面的能力。结果显示，主流大模型在构建全局叙事结构和捕捉叙事功能方面表现不足，即使启用更高级的推理模式，提升有限。


<details>
  <summary>Details</summary>
Motivation: 现有大模型虽能生成连贯长篇故事，但对故事的节奏、张力和情感动态等复杂文学因素把握不足，只强调故事表层因果结构，无法胜任高层次的人类叙事模式。为解决人类与模型叙事实践的结构错位，需要一个更加贴近文学本质的评估与表征体系。

Method: 提出VISTA Space，一种多维度、高表示力的叙事结构建模框架，能够统一人类和模型的叙事视角。同时，构建了LitVISTA基准数据集，对经典文学作品进行结构化标注，用以严格测试不同大模型的叙事能力。对GPT、Claude、Grok、Gemini等先进大模型进行了系统评测。

Result: 实验证明，当前前沿大模型在统一全局叙事结构、联动管理叙事功能方面表现存在系统性不足，即便采用更复杂的推理或思考模式，模型在理解和构建高级文学叙事结构上依然收效甚微。

Conclusion: 现有大模型在文学叙事理解与结构化生成方面存在根本性短板，仅提高因果连贯性和推理复杂度不足以弥补这一缺陷。提出的新方法与数据集为后续模型更好地理解与生成文学叙事提供了研究基础。

Abstract: Computational narrative analysis aims to capture rhythm, tension, and emotional dynamics in literary texts. Existing large language models can generate long stories but overly focus on causal coherence, neglecting the complex story arcs and orchestration inherent in human narratives. This creates a structural misalignment between model- and human-generated narratives. We propose VISTA Space, a high-dimensional representational framework for narrative orchestration that unifies human and model narrative perspectives. We further introduce LitVISTA, a structurally annotated benchmark grounded in literary texts, enabling systematic evaluation of models' narrative orchestration capabilities. We conduct oracle evaluations on a diverse selection of frontier LLMs, including GPT, Claude, Grok, and Gemini. Results reveal systematic deficiencies: existing models fail to construct a unified global narrative view, struggling to jointly capture narrative function and structure. Furthermore, even advanced thinking modes yield only limited gains for such literary narrative understanding.

</details>


### [162] [PRISP: Privacy-Safe Few-Shot Personalization via Lightweight Adaptation](https://arxiv.org/abs/2601.06471)
*Junho Park,Dohoon Kim,Taesup Moon*

Main category: cs.CL

TL;DR: 该论文提出了PRISP，一种面向隐私安全和资源受限场景的轻量级大语言模型个性化方案，能有效降低计算和隐私风险，在少量数据下性能优越。


<details>
  <summary>Details</summary>
Motivation: 现实环境下，大语言模型部署后需进行个性化，但通常面临用户数据极少、算力有限及隐私保护等问题，而现有方法大都假设数据和资源充足，并存在隐私风险。

Method: 提出PRISP方法：通过Text-to-LoRA超网络根据任务描述生成LoRA参数，结合少量用户样本，优化少量参数及额外微小模块，达到高效、安全的用户个性化。

Result: 在LaMP基准的few-shot任务上，PRISP在总体性能上优于先前方法，同时计算开销更低、且消除了隐私隐患。

Conclusion: PRISP为资源受限、数据稀缺及隐私要求高的个性化大模型场景提供了优越解决方案，兼具高效性与隐私安全性。

Abstract: Large language model (LLM) personalization aims to adapt general-purpose models to individual users. Most existing methods, however, are developed under data-rich and resource-abundant settings, often incurring privacy risks. In contrast, realistic personalization typically occurs after deployment under (i) extremely limited user data, (ii) constrained computational resources, and (iii) strict privacy requirements. We propose PRISP, a lightweight and privacy-safe personalization framework tailored to these constraints. PRISP leverages a Text-to-LoRA hypernetwork to generate task-aware LoRA parameters from task descriptions, and enables efficient user personalization by optimizing a small subset of task-aware LoRA parameters together with minimal additional modules using few-shot user data. Experiments on a few-shot variant of the LaMP benchmark demonstrate that PRISP achieves strong overall performance compared to prior approaches, while reducing computational overhead and eliminating privacy risks.

</details>


### [163] [IndRegBias: A Dataset for Studying Indian Regional Biases in English and Code-Mixed Social Media Comments](https://arxiv.org/abs/2601.06477)
*Debasmita Panda,Akash Anil,Neelesh Kumar Shukla*

Main category: cs.CL

TL;DR: 本文主要关注印度区域性偏见，构建了包含印度社交媒体评论的区域偏见数据集（IndRegBias），并评估了多种语言模型在检测和识别这些偏见方面的表现。


<details>
  <summary>Details</summary>
Motivation: 虽然性别、种族、社会经济等社会偏见已被NLP领域广泛研究，但区域性偏见因数据难获取、标注有分歧及常被忽略，研究相对较少。作者希望填补印度区域偏见相关数据和模型的空白。

Method: 作者从Reddit和YouTube收集了25,000条印度网友就区域问题的评论，构建数据集IndRegBias，并采用多级标注策略，对评论中区域偏见的严重程度进行标注。随后，评估了开源大型语言模型（LLMs）和印度本地语言模型（ILMs）在零样本、少样本和微调三种模式下的偏见检测能力。

Result: 零样本和少样本方法在大多数模型中检测准确率较低；通过微调后，模型在识别区域偏见及其严重程度方面表现显著提升。

Conclusion: 针对印度区域偏见，数据集和微调后的模型表现良好，为更好识别和研究南亚地区的社会偏见问题提供了新的工具和数据基础。

Abstract: Warning: This paper consists of examples representing regional biases in Indian regions that might be offensive towards a particular region. While social biases corresponding to gender, race, socio-economic conditions, etc., have been extensively studied in the major applications of Natural Language Processing (NLP), biases corresponding to regions have garnered less attention. This is mainly because of (i) difficulty in the extraction of regional bias datasets, (ii) disagreements in annotation due to inherent human biases, and (iii) regional biases being studied in combination with other types of social biases and often being under-represented. This paper focuses on creating a dataset IndRegBias, consisting of regional biases in an Indian context reflected in users' comments on popular social media platforms, namely Reddit and YouTube. We carefully selected 25,000 comments appearing on various threads in Reddit and videos on YouTube discussing trending topics on regional issues in India. Furthermore, we propose a multilevel annotation strategy to annotate the comments describing the severity of regional biased statements. To detect the presence of regional bias and its severity in IndRegBias, we evaluate open-source Large Language Models (LLMs) and Indic Language Models (ILMs) using zero-shot, few-shot, and fine-tuning strategies. We observe that zero-shot and few-shot approaches show lower accuracy in detecting regional biases and severity in the majority of the LLMs and ILMs. However, the fine-tuning approach significantly enhances the performance of the LLM in detecting Indian regional bias along with its severity.

</details>


### [164] [Spec-o3: A Tool-Augmented Vision-Language Agent for Rare Celestial Object Candidate Vetting via Automated Spectral Inspection](https://arxiv.org/abs/2601.06498)
*Minghui Jia,Qichao Zhang,Ali Luo,Linjing Li,Shuo Ye,Hailing Lu,Wen Hou,Dongbin Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种多模态视觉-语言智能体Spec-o3，可辅助天文学家高效、可靠地筛选稀有天体光谱，极大提高了处理效率与准确性，并且具备出色的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习分类器在天体筛查方面泛化能力和可解释性有限，罕见天体的最终确认仍需专家手动目视核查，随着光谱观测数据爆炸式增长，这一人工流程成为天文学研究的瓶颈。

Method: Spec-o3是一个结合工具辅助的视觉-语言智能体。模型采用两阶段训练策略：首先对专家质检过程进行冷启动监督微调，然后在稀有天体判别任务上用基于结果的强化学习优化。其核心创新是引入多模态逐步推理，模拟天文学家实际的光谱检查与推理逻辑，并能灵活调用专业分析工具。

Result: 在LAMOST五项稀有天体识别任务中，Spec-o3显著提升了宏F1分数，从28.3提升至76.5（基于7B参数基础模型），优于商用VLM和传统深度模型。模型还展现了良好的跨巡天（如从LAMOST泛化到SDSS/DESI）的鲁棒性。专家评价其推理过程逻辑自洽、物理合理，决策过程透明可靠。

Conclusion: Spec-o3不仅大幅提高了稀有天体自动筛查的效率和准确性，还为天文数据智能分析提供了透明、可信的推理范式，对于应对未来大数据天文巡天具有重要应用价值。

Abstract: Due to the limited generalization and interpretability of deep learning classifiers, The final vetting of rare celestial object candidates still relies on expert visual inspection--a manually intensive process. In this process, astronomers leverage specialized tools to analyze spectra and construct reliable catalogs. However, this practice has become the primary bottleneck, as it is fundamentally incapable of scaling with the data deluge from modern spectroscopic surveys. To bridge this gap, we propose Spec-o3, a tool-augmented vision-language agent that performs astronomer-aligned spectral inspection via interleaved multimodal chain-of-thought reasoning. Spec-o3 is trained with a two-stage post-training recipe: cold-start supervised fine-tuning on expert inspection trajectories followed by outcome-based reinforcement learning on rare-type verification tasks. Evaluated on five rare-object identification tasks from LAMOST, Spec-o3 establishes a new State-of-the-Art, boosting the macro-F1 score from 28.3 to 76.5 with a 7B parameter base model and outperforming both proprietary VLMs and specialized deep models. Crucially, the agent demonstrates strong generalization to unseen inspection tasks across survey shifts (from LAMOST to SDSS/DESI). Expert evaluations confirm that its reasoning traces are coherent and physically consistent, supporting transparent and trustworthy decision-making. Code, data, and models are available at \href{https://github.com/Maxwell-Jia/spec-o3}{Project HomePage}.

</details>


### [165] [MedRAGChecker: Claim-Level Verification for Biomedical Retrieval-Augmented Generation](https://arxiv.org/abs/2601.06519)
*Yuelyu Ji,Min Gu Kwak,Hang Zhang,Xizhi Wu,Chenyu Li,Yanshan Wang*

Main category: cs.CL

TL;DR: MedRAGChecker是一个专为生物医学检索增强生成（RAG）设计的核查工具，能自动识别长文本答案中的无依据或矛盾性医学断言，并对其进行细致诊断。


<details>
  <summary>Details</summary>
Motivation: 长文本生物医学RAG模型有时会生成无支撑或相互矛盾的医学主张，这可能带来安全隐患，因此亟需开发可自动检测和分析此类风险的工具。

Method: 提出MedRAGChecker系统，把生成的答案拆分为原子主张，并结合基于证据的自然语言推理和知识图谱一致性信号，逐条判断主张的依据情况。汇总主张判据后，给出整句或整体答案的诊断，包括是否忠实于证据、证据不足、矛盾及安全风险等。该系统用轻量级模型和集成验证器方法实现高效评估。

Result: 在4个主流生物医学问答基准上测试，MedRAGChecker能较准确地识别被证据支持、无依据或矛盾的主张，并区分不同生成器的风险特征，尤其在涉及安全关键关系时表现突出。

Conclusion: MedRAGChecker为生物医学RAG提供了细致、自动化、可扩展的风险分析方法，有助于提升医学大模型输出的可靠性和安全性。

Abstract: Biomedical retrieval-augmented generation (RAG) can ground LLM answers in medical literature, yet long-form outputs often contain isolated unsupported or contradictory claims with safety implications.
  We introduce MedRAGChecker, a claim-level verification and diagnostic framework for biomedical RAG.
  Given a question, retrieved evidence, and a generated answer, MedRAGChecker decomposes the answer into atomic claims and estimates claim support by combining evidence-grounded natural language inference (NLI) with biomedical knowledge-graph (KG) consistency signals.
  Aggregating claim decisions yields answer-level diagnostics that help disentangle retrieval and generation failures, including faithfulness, under-evidence, contradiction, and safety-critical error rates.
  To enable scalable evaluation, we distill the pipeline into compact biomedical models and use an ensemble verifier with class-specific reliability weighting.
  Experiments on four biomedical QA benchmarks show that MedRAGChecker reliably flags unsupported and contradicted claims and reveals distinct risk profiles across generators, particularly on safety-critical biomedical relations.

</details>


### [166] [Atomic-SNLI: Fine-Grained Natural Language Inference through Atomic Fact Decomposition](https://arxiv.org/abs/2601.06528)
*Minghui Huang*

Main category: cs.CL

TL;DR: 现有NLI系统在原子推理层面表现较差，本文提出了Atomic-SNLI数据集来提升NLI系统的细粒度推理能力，实现更好的可解释性和整体性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有自然语言推断（NLI）系统主要在句子层面进行判断，缺乏解释性。原子级NLI虽然能提升解释性，但当前模型在原子推理上表现不佳，因此有必要针对原子层面推理能力做提升。

Method: 作者提出了Atomic-SNLI数据集，该数据集通过对SNLI的句子进行分解，使用语言学驱动的策略生成高质量的原子级实例，并用于强化模型的原子推理能力。

Result: 实验显示，使用Atomic-SNLI数据集微调后的模型，在原子推理能力上显著提升，同时仍能保持较强的句子层面性能，实现更准确且可解释的判断。

Conclusion: 通过Atomic-SNLI，NLI模型在增强可解释性和细粒度推理能力的同时，并未妥协整体性能，为NLI系统带来了更强的解释力和准确性。

Abstract: Current Natural Language Inference (NLI) systems primarily operate at the sentence level, providing black-box decisions that lack explanatory power. While atomic-level NLI offers a promising alternative by decomposing hypotheses into individual facts, we demonstrate that the conventional assumption that a hypothesis is entailed only when all its atomic facts are entailed fails in practice due to models' poor performance on fine-grained reasoning. Our analysis reveals that existing models perform substantially worse on atomic level inference compared to sentence level tasks. To address this limitation, we introduce Atomic-SNLI, a novel dataset constructed by decomposing SNLI and enriching it with carefully curated atomic level examples through linguistically informed generation strategies. Experimental results demonstrate that models fine-tuned on Atomic-SNLI achieve significant improvements in atomic reasoning capabilities while maintaining strong sentence level performance, enabling both accurate judgements and transparent, explainable results at the fact level.

</details>


### [167] [Exposía: Academic Writing Assessment of Exposés and Peer Feedback](https://arxiv.org/abs/2601.06536)
*Dennis Zyska,Alla Rozovskaya,Ilia Kuznetsov,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本文介绍了Exposía数据集，这是首个连接学术写作与反馈评估的公开高等教育数据集，并利用该数据集对大型语言模型（LLMs）在自动评分方面进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 缺乏公开的高等教育学生写作与反馈评估数据，限制了教育背景下学术写作自动评估方法的研究进展。

Method: 构建并公开了Exposía数据集，包含学生项目提案、同行及教师反馈与评分。利用该数据集，基准测试了现有开源LLM在自动评分学生写作和同行评议任务的表现，并比较不同任务设计及提示策略的效果。

Result: 强大的LLM在无需特定领域知识的评分维度上与人类评分一致，但在内容类维度上的表现较弱。此外，LLM的评分倾向于与给高分的教师更为一致。多方面联合评分的提示策略表现最佳。

Conclusion: Exposía为学术写作评价研究提供有力工具，LLM虽可用于部分自动评分任务，但其在评估内容深度方面仍有限。多维度评分提示策略对实际部署有积极意义。

Abstract: We present Exposía, the first public dataset that connects writing and feedback assessment in higher education, enabling research on educationally grounded approaches to academic writing evaluation. Exposía includes student research project proposals and peer and instructor feedback consisting of comments and free-text reviews. The dataset was collected in the "Introduction to Scientific Work" course of the Computer Science undergraduate program that focuses on teaching academic writing skills and providing peer feedback on academic writing. Exposía reflects the multi-stage nature of the academic writing process that includes drafting, providing and receiving feedback, and revising the writing based on the feedback received. Both the project proposals and peer feedback are accompanied by human assessment scores based on a fine-grained, pedagogically-grounded schema for writing and feedback assessment that we develop.
  We use Exposía to benchmark state-of-the-art open-source large language models (LLMs) for two tasks: automated scoring of (1) the proposals and (2) the student reviews. The strongest LLMs attain high agreement on scoring aspects that require little domain knowledge but degrade on dimensions evaluating content, in line with human agreement values. We find that LLMs align better with the human instructors giving high scores. Finally, we establish that a prompting strategy that scores multiple aspects of the writing together is the most effective, an important finding for classroom deployment.

</details>


### [168] [SimLLM: Fine-Tuning Code LLMs for SimPy-Based Queueing System Simulation](https://arxiv.org/abs/2601.06543)
*Jun-Qi Chen,Kun Zhang,Rui Zheng,Ying Zhong*

Main category: cs.CL

TL;DR: 本文通过对开源大模型（Qwen-Coder-7B 和 DeepSeek-Coder-6.7B）在 SimPy 排队系统代码生成任务上的多阶段微调，实现了可与闭源模型媲美的代码生成能力，并为学术与应用场景提供低成本、隐私友好的解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前，利用大语言模型自动生成 SimPy 排队系统仿真代码在教育与研究领域非常有用，但直接使用如 GPT-4o 等闭源模型存在高昂成本与数据隐私风险。因此，亟需开源且高效的替代方案。

Method: 作者对两个开源代码大模型（Qwen-Coder-7B 和 DeepSeek-Coder-6.7B）以精心构建的 SimPy 排队数据集进行多阶段微调，包括两个阶段的有监督微调(SFT)和一个阶段的直接偏好优化(DPO)，逐步提升模型的代码生成表现。

Result: 微调后的两个模型在代码可执行性、输出格式一致性以及指令-代码一致性等多个维度上均取得大幅提升，效果明显优于原始模型。

Conclusion: 对开源模型的领域微调能有效提升其在特定代码生成任务中的性能，使其成为实用、低成本且隐私友好的闭源大模型替代方案，适用于教育、科研及决策支持等场景。

Abstract: The Python package SimPy is widely used for modeling queueing systems due to its flexibility, simplicity, and smooth integration with modern data analysis and optimization frameworks. Recent advances in large language models (LLMs) have shown strong ability in generating clear and executable code, making them powerful and suitable tools for writing SimPy queueing simulation code. However, directly employing closed-source models like GPT-4o to generate such code may lead to high computational costs and raise data privacy concerns. To address this, we fine-tune two open-source LLMs, Qwen-Coder-7B and DeepSeek-Coder-6.7B, on curated SimPy queueing data, which enhances their code-generating performance in executability, output-format compliance, and instruction-code consistency. Particularly, we proposed a multi-stage fine-tuning framework comprising two stages of supervised fine-tuning (SFT) and one stage of direct preference optimization (DPO), progressively enhancing the model's ability in SimPy-based queueing simulation code generation. Extensive evaluations demonstrate that both fine-tuned models achieve substantial improvements in executability, output-format compliance, and instruct consistency. These results confirm that domain-specific fine-tuning can effectively transform compact open-source code models into reliable SimPy simulation generators which provide a practical alternative to closed-source LLMs for education, research, and operational decision support.

</details>


### [169] [CSR-RAG: An Efficient Retrieval System for Text-to-SQL on the Enterprise Scale](https://arxiv.org/abs/2601.06564)
*Rajpreet Singh,Novak Boškov,Lawrence Drabeck,Aditya Gudal,Manzoor A. Khan*

Main category: cs.CL

TL;DR: 本文提出了一种适用于企业级数据库的混合检索增强生成（RAG）系统CSR-RAG，提高了从自然语言到SQL的表检索效率与准确度。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL任务多在输入中直接提供数据库表结构，而实际企业应用经常需要先检索相关数据表，现有方案在大规模数据库效能和精度上均不能满足需求。

Method: 提出CSR-RAG系统，结合上下文、结构化信息及关系关联进行高效的表检索，然后辅助LLM完成SQL生成。

Result: 在企业级数据库基准测试中，提出的方法精确率达40%，召回率超过80%，且单次查询延迟只有30毫秒，适合大规模企业级应用场景。

Conclusion: CSR-RAG系统在保证准确率的同时显著提高了检索速度，非常契合当前基于LLM的企业级Text-to-SQL需求。

Abstract: Natural language to SQL translation (Text-to-SQL) is one of the long-standing problems that has recently benefited from advances in Large Language Models (LLMs). While most academic Text-to-SQL benchmarks request schema description as a part of natural language input, enterprise-scale applications often require table retrieval before SQL query generation. To address this need, we propose a novel hybrid Retrieval Augmented Generation (RAG) system consisting of contextual, structural, and relational retrieval (CSR-RAG) to achieve computationally efficient yet sufficiently accurate retrieval for enterprise-scale databases. Through extensive enterprise benchmarks, we demonstrate that CSR-RAG achieves up to 40% precision and over 80% recall while incurring a negligible average query generation latency of only 30ms on commodity data center hardware, which makes it appropriate for modern LLM-based enterprise-scale systems.

</details>


### [170] [EVM-QuestBench: An Execution-Grounded Benchmark for Natural-Language Transaction Code Generation](https://arxiv.org/abs/2601.06565)
*Pei Yang,Wanyi Chen,Ke Wang,Lynn Ai,Eric Yang,Tianyu Shi*

Main category: cs.CL

TL;DR: 论文提出了EVM-QuestBench，这是一个面向EVM兼容链、以执行为基础的自然语言交易脚本生成基准，用于更加准确评估大语言模型在链上交易任务中的实际表现，强调了安全和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在链上交易场景应用增多，但传统评测忽略了链上脚本在真实执行时的准确性和安全性，尤其在任何小错误都可能造成无法挽回损失的背景下，亟需更真实、更精准的评测基准。

Method: 作者设计了EVM-QuestBench：包含107道任务（原子任务和组合任务），通过动态评测方法，随机采样指令模板和数值参数，用验证器自动检验执行结果。基准的架构模块化，支持快速开发任务，脚本在带快照隔离的EVM链分叉上执行，组合任务还考虑效率衰减。

Result: 基于EVM-QuestBench评测了20个模型，发现模型在各项任务上的表现存在显著差距，尤其是单步操作精度和多步工作流完成度之间存在明显不对称现象。

Conclusion: EVM-QuestBench有效揭示了大语言模型在链上事务生成中的安全性、准确性短板，为未来模型开发和应用部署提供了更实际的评估工具，可推动链上AI agent更安全落地。

Abstract: Large language models are increasingly applied to various development scenarios. However, in on-chain transaction scenarios, even a minor error can cause irreversible loss for users. Existing evaluations often overlook execution accuracy and safety. We introduce EVM-QuestBench, an execution-grounded benchmark for natural-language transaction-script generation on EVM-compatible chains. The benchmark employs dynamic evaluation: instructions are sampled from template pools, numeric parameters are drawn from predefined intervals, and validators verify outcomes against these instantiated values. EVM-QuestBench contains 107 tasks (62 atomic, 45 composite). Its modular architecture enables rapid task development. The runner executes scripts on a forked EVM chain with snapshot isolation; composite tasks apply step-efficiency decay. We evaluate 20 models and find large performance gaps, with split scores revealing persistent asymmetry between single-action precision and multi-step workflow completion. Code: https://anonymous.4open.science/r/bsc_quest_bench-A9CF/.

</details>


### [171] [Are Emotions Arranged in a Circle? Geometric Analysis of Emotion Representations via Hyperspherical Contrastive Learning](https://arxiv.org/abs/2601.06575)
*Yusuke Yamauchi,Akiko Aizawa*

Main category: cs.CL

TL;DR: 本文提出了一种基于对比学习的方法，将心理学中的“情感圆环模型”直接引入到语言模型的表示学习中，以增强深度学习中情感表征的可解释性。


<details>
  <summary>Details</summary>
Motivation: 心理学情感圆环模型被广泛用来结构化情感，但在语言模型的训练和表示中通常未被直接应用，其几何有效性也没有被充分验证。本研究动机是探索如何更直接和有效地把该理论模型融入语言模型的学习过程。

Method: 作者提出了一种在超球面上通过对比学习诱导情感的圆形结构化表示的方法，使相似情感在嵌入空间靠近，对立情感分布在圆环的对角。实施过程中直接约束embedding的空间结构。

Result: 实验证明，圆环对齐结构在降维和解释性上优于传统方法，但在高维表示和细粒度类别判别任务中效果不如传统高维设计。

Conclusion: 将心理学圆环模型引入深度学习表征可提升可解释性和鲁棒性，但会牺牲一定的分类精度，实际应用中需衡量解释性与性能间的权衡。

Abstract: Psychological research has long utilized circumplex models to structure emotions, placing similar emotions adjacently and opposing ones diagonally. Although frequently used to interpret deep learning representations, these models are rarely directly incorporated into the representation learning of language models, leaving their geometric validity unexplored. This paper proposes a method to induce circular emotion representations within language model embeddings via contrastive learning on a hypersphere. We show that while this circular alignment offers superior interpretability and robustness against dimensionality reduction, it underperforms compared to conventional designs in high-dimensional settings and fine-grained classification. Our findings elucidate the trade-offs involved in applying psychological circumplex models to deep learning architectures.

</details>


### [172] [Stylistic Evolution and LLM Neutrality in Singlish Language](https://arxiv.org/abs/2601.06580)
*Linus Tze En Foo,Weihan Angela Ng,Wenkai Li,Lynnette Hui Xian Ng*

Main category: cs.CL

TL;DR: 本文通过分析新加坡本地英语（Singlish）过去十年非正式数字信息，揭示Singlish在社会和技术变化中的演变，同时评估大语言模型（LLMs）模拟Singlish及其变化的效果与局限。


<details>
  <summary>Details</summary>
Motivation: Singlish作为新加坡多语环境下形成的本地英语，其随时代和环境不断变化，但其具体演变过程及与新技术（如大型语言模型）的关联亟需深入研究。

Method: 作者提出了一种风格相似性框架，横跨多个年度，用词、结构、语用、心理语言学及编码特征对比Singlish的演变，并测试LLMs生成Singlish的时序中性特点及其局限。

Result: 研究发现Singlish在语气、表现力和句式上随时间发生了显著变化；部分LLMs能仿真生成“像真”Singlish，但无法完全去除时间特征，即仍含有年代信号。

Conclusion: Singlish作为方言不断动态演化，而当前LLMs虽可初步模拟其表现，却难以精准建模其社会语言和时间维度的复杂性。

Abstract: Singlish is a creole rooted in Singapore's multilingual environment and continues to evolve alongside social and technological change. This study investigates the evolution of Singlish over a decade of informal digital text messages. We propose a stylistic similarity framework that compares lexico-structural, pragmatic, psycholinguistic, and encoder-derived features across years to quantify temporal variation. Our analysis reveals notable diachronic changes in tone, expressivity and sentence construction over the years. Conversely, while some LLMs were able to generate superficially realistic Singlish messages, they do not produce temporally neutral outputs, and residual temporal signals remain detectable despite prompting and fine-tuning. Our findings highlight the dynamic evolution of Singlish, as well as the capabilities and limitations of current LLMs in modeling sociolectal and temporal variations in the colloquial language.

</details>


### [173] [Detecting LLM-Generated Text with Performance Guarantees](https://arxiv.org/abs/2601.06586)
*Hongyi Zhou,Jin Zhu,Ying Yang,Chengchun Shi*

Main category: cs.CL

TL;DR: 本文提出了一种新的文本检测器，用于区分大型语言模型（LLM）和人类生成的文本，具有更高精度且无需额外信息。


<details>
  <summary>Details</summary>
Motivation: 随着GPT等LLM的大量应用，人类文本与AI文本难以区分，可能导致虚假信息传播、学术不端等问题，因此亟需有效检测工具。

Method: 训练了一个分类器，输入文本后判断其作者为人类或LLM。该方法不依赖水印或模型信息，并引入统计推断功能，并在CPU平台实际部署。

Result: 实验表明该分类器较现有检测器有更高的准确率，同时能控制第一类错误、保持高统计效能和良好计算效率。

Conclusion: 新检测器提升了LLM与人类文本区分能力，有望缓解LLM文本滥用风险，在实际场景具有良好应用前景。

Abstract: Large language models (LLMs) such as GPT, Claude, Gemini, and Grok have been deeply integrated into our daily life. They now support a wide range of tasks -- from dialogue and email drafting to assisting with teaching and coding, serving as search engines, and much more. However, their ability to produce highly human-like text raises serious concerns, including the spread of fake news, the generation of misleading governmental reports, and academic misconduct. To address this practical problem, we train a classifier to determine whether a piece of text is authored by an LLM or a human. Our detector is deployed on an online CPU-based platform https://huggingface.co/spaces/stats-powered-ai/StatDetectLLM, and contains three novelties over existing detectors: (i) it does not rely on auxiliary information, such as watermarks or knowledge of the specific LLM used to generate the text; (ii) it more effectively distinguishes between human- and LLM-authored text; and (iii) it enables statistical inference, which is largely absent in the current literature. Empirically, our classifier achieves higher classification accuracy compared to existing detectors, while maintaining type-I error control, high statistical power, and computational efficiency.

</details>


### [174] [How Context Shapes Truth: Geometric Transformations of Statement-level Truth Representations in LLMs](https://arxiv.org/abs/2601.06599)
*Shivam Adarsh,Maria Maistro,Christina Lioma*

Main category: cs.CL

TL;DR: 本文分析了大型语言模型（LLM）中与真假判断相关的向量（truth vectors）在有无上下文条件下的变化，首次用几何方法刻画了上下文对真假向量的影响。


<details>
  <summary>Details</summary>
Motivation: 此前已有研究发现LLM会通过特定向量在残差流激活中表达真假，但这些向量在不同上下文下的变化方式尚未被系统研究。理解这个过程有助于揭示模型内部表征和知识整合机制。

Method: 作者利用几何方法在四个LLM与四个数据集上，量化分析了加入上下文前后truth vectors的方向变化（θ）和幅值变化。考察了不同模型规模、上下文相关性，以及上下文与参数知识一致/冲突的情形。

Result: （1）early layer中truth vectors近乎正交，中间层趋于一致，后期层可能稳定或继续分化；（2）上下文通常增大了truth vector的幅度，加强了真假区分；（3）大模型主要通过方向变化区分上下文，小模型则更依赖幅度变化；（4）与参数知识冲突的上下文会导致更大幅度的几何变化。

Conclusion: 作者首次系统性地展示了上下文如何在LLM激活空间中以几何方式转化真假向量，这对于理解模型内部知识融合模式及真假判断机制有重要意义。

Abstract: Large Language Models (LLMs) often encode whether a statement is true as a vector in their residual stream activations. These vectors, also known as truth vectors, have been studied in prior work, however how they change when context is introduced remains unexplored. We study this question by measuring (1) the directional change ($θ$) between the truth vectors with and without context and (2) the relative magnitude of the truth vectors upon adding context. Across four LLMs and four datasets, we find that (1) truth vectors are roughly orthogonal in early layers, converge in middle layers, and may stabilize or continue increasing in later layers; (2) adding context generally increases the truth vector magnitude, i.e., the separation between true and false representations in the activation space is amplified; (3) larger models distinguish relevant from irrelevant context mainly through directional change ($θ$), while smaller models show this distinction through magnitude differences. We also find that context conflicting with parametric knowledge produces larger geometric changes than parametrically aligned context. To the best of our knowledge, this is the first work that provides a geometric characterization of how context transforms the truth vector in the activation space of LLMs.

</details>


### [175] [Probing Multimodal Large Language Models on Cognitive Biases in Chinese Short-Video Misinformation](https://arxiv.org/abs/2601.06600)
*Jen-tse Huang,Chang Chen,Shiyang Lai,Wenxuan Wang,Michelle R. Kaufman,Mark Dredze*

Main category: cs.CL

TL;DR: 本文建立了一个专门用于评测多模态大语言模型(MLLMs)在短视频健康类虚假信息识别能力的数据集和评测框架，对当前主流模型进行系统性对比。


<details>
  <summary>Details</summary>
Motivation: 短视频平台已成为虚假信息传播重灾区，现有多模态大语言模型应对包含认知偏差与视觉误导等复杂短视频虚假信息的能力尚未深入探索。

Method: 作者构建了一个涵盖四类健康领域、共计200个短视频的高质量数据集，对三类欺骗模式（实验错误、逻辑谬误、伪造主张）进行精细标注，并以标准与学术文献作为校验依据。使用此数据集，评测了8个前沿MLLMs在5种模态下对健康虚假信息的辨识能力。

Result: 实验发现，在多模态情境下，Gemini-2.5-Pro表现最佳，信念评分为71.5/100；o3表现最差为35.2分。同时，分析社会性线索（如权威频道ID）发现模型易受到此类偏见影响。

Conclusion: 现有MLLMs在识别短视频健康虚假信息时仍有提升空间，容易被社会性线索误导。文中框架和数据集可作为该方向后续研究评测标准。

Abstract: Short-video platforms have become major channels for misinformation, where deceptive claims frequently leverage visual experiments and social cues. While Multimodal Large Language Models (MLLMs) have demonstrated impressive reasoning capabilities, their robustness against misinformation entangled with cognitive biases remains under-explored. In this paper, we introduce a comprehensive evaluation framework using a high-quality, manually annotated dataset of 200 short videos spanning four health domains. This dataset provides fine-grained annotations for three deceptive patterns, experimental errors, logical fallacies, and fabricated claims, each verified by evidence such as national standards and academic literature. We evaluate eight frontier MLLMs across five modality settings. Experimental results demonstrate that Gemini-2.5-Pro achieves the highest performance in the multimodal setting with a belief score of 71.5/100, while o3 performs the worst at 35.2. Furthermore, we investigate social cues that induce false beliefs in videos and find that models are susceptible to biases like authoritative channel IDs.

</details>


### [176] [N2N-GQA: Noise-to-Narrative for Graph-Based Table-Text Question Answering Using LLMs](https://arxiv.org/abs/2601.06603)
*Mohamed Sharafath,Aravindh Annamalai,Ganesh Murugan,Aravindakumar Venugopalan*

Main category: cs.CL

TL;DR: 本文提出了N2N-GQA，这是一种针对开放域混合表格文本问答（QA）的零样本多跳推理新方法，通过从噪声检索结果中动态构建证据图，有效提升推理能力。实验表明，证据图结构能大幅提升多跳QA的准确率，且无需任务特定训练即可媲美甚至接近复杂的微调模型。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法将检索到的文档平铺为排名列表，导致检索噪声掩盖了多跳推理所需的证据链，制约了混合表格-文本数据的多证据、多步推理问答性能。作者提出通过构建动态证据图，以结构化方式组织检索证据，从而更好支持复杂推理。

Method: N2N-GQA将检索到的文本和表格证据以语义关系构建为图，节点为文档、边为语义关系。通过识别“桥接”文档，动态组织推理链，避免了旧有列表检索方法的噪声干扰，无需对下游任务专门训练即可直接推理。

Result: 在OTT-QA 数据集上，N2N-GQA方法在精确匹配（EM）分数上优于多种强基线，提升19.9个百分点，零样本条件下达到48.8 EM，接近或媲美已微调的检索模型（CORE: 49.0，COS: 56.9）。

Conclusion: 证据检索结构化为图对于开放域多跳QA至关重要。即使无需下游微调，简单可解释的证据图结构也能大幅提升推理能力，表明该方法适合大规模、通用多跳问答应用。

Abstract: Multi-hop question answering over hybrid table-text data requires retrieving and reasoning across multiple evidence pieces from large corpora, but standard Retrieval-Augmented Generation (RAG) pipelines process documents as flat ranked lists, causing retrieval noise to obscure reasoning chains. We introduce N2N-GQA. To our knowledge, it is the first zeroshot framework for open-domain hybrid table-text QA that constructs dynamic evidence graphs from noisy retrieval outputs. Our key insight is that multi-hop reasoning requires understanding relationships between evidence pieces: by modeling documents as graph nodes with semantic relationships as edges, we identify bridge documents connecting reasoning steps, a capability absent in list-based retrieval. On OTT-QA, graph-based evidence curation provides a 19.9-point EM improvement over strong baselines, demonstrating that organizing retrieval results as structured graphs is critical for multihop reasoning. N2N-GQA achieves 48.80 EM, matching finetuned retrieval models (CORE: 49.0 EM) and approaching heavily optimized systems (COS: 56.9 EM) without any task specific training. This establishes graph-structured evidence organization as essential for scalable, zero-shot multi-hop QA systems and demonstrates that simple, interpretable graph construction can rival sophisticated fine-tuned approaches.

</details>


### [177] [Pragya: An AI-Based Semantic Recommendation System for Sanskrit Subhasitas](https://arxiv.org/abs/2601.06607)
*Tanisha Raorane,Prasenjit Kole*

Main category: cs.CL

TL;DR: 本文提出了Pragya系统，结合检索增强生成（RAG）方法，实现了对梵文谚语的智能语义推荐与自动解读。


<details>
  <summary>Details</summary>
Motivation: 梵文谚语蕴含丰富文化与哲学智慧，但由于语言和语境障碍，在数字时代应用受限。因此，亟需用AI技术提升其可访问性和实用性。

Method: 1）构建200条梵文谚语数据集并添加主题标签；2）基于IndicBERT句子嵌入，实现针对用户查询的top-k语义检索；3）将检索结果输入Mistral大语言模型，生成梵文转写、翻译与语境解释。

Result: 实验表明，基于语义的检索在精度与相关性上明显优于关键词检索；用户调研显示，通过生成摘要显著提升了谚语的可访问性。

Conclusion: 该研究首次将AI中的检索与生成技术应用于梵文谚语推荐与解读，有效促进了文化遗产与现代人工智能的融合。

Abstract: Sanskrit Subhasitas encapsulate centuries of cultural and philosophical wisdom, yet remain underutilized in the digital age due to linguistic and contextual barriers. In this work, we present Pragya, a retrieval-augmented generation (RAG) framework for semantic recommendation of Subhasitas. We curate a dataset of 200 verses annotated with thematic tags such as motivation, friendship, and compassion. Using sentence embeddings (IndicBERT), the system retrieves top-k verses relevant to user queries. The retrieved results are then passed to a generative model (Mistral LLM) to produce transliterations, translations, and contextual explanations. Experimental evaluation demonstrates that semantic retrieval significantly outperforms keyword matching in precision and relevance, while user studies highlight improved accessibility through generated summaries. To our knowledge, this is the first attempt at integrating retrieval and generation for Sanskrit Subhasitas, bridging cultural heritage with modern applied AI.

</details>


### [178] [Efficient and Reliable Estimation of Named Entity Linking Quality: A Case Study on GutBrainIE](https://arxiv.org/abs/2601.06624)
*Marco Martinelli,Stefano Marchesin,Gianmaria Silvello*

Main category: cs.CL

TL;DR: 本文提出了一种基于抽样的方法，在专家标注预算有限的情况下，对大规模生物医学命名实体链接（NEL）结果的准确率进行统计学保证的估算，显著减少了人工评估成本。


<details>
  <summary>Details</summary>
Motivation: 大规模生物医学文本中的命名实体链接（NEL）是信息抽取关键环节，但人工标注其准确性耗时耗力且费用高昂，因此需要在保证统计意义下，控制标注成本的准确率评估新方法。

Method: 作者将NEL准确率估算建模为受限优化问题，通过设定目标误差边界（Margin of Error, MoE），采用“分层两阶段簇抽样”（STWCS）策略，依据标签和表面形式聚类定义抽样分层，不依赖已有NEL标注。该框架在GutBrainIE新语料库上评估了11,184个NEL标注，仅需额外人工标注2,749个三元组。

Result: 仅人工标注24.6%样本即可将NEL准确率的误差边界降至≤0.05，估算准确率为0.915±0.0473。与简单随机抽样相比，专家标注时间减少29%。

Conclusion: 该框架具有通用性，可扩展应用于其他NEL基准数据集和需要大规模准确率评估的信息抽取流水线，兼顾了准确性与成本效益。

Abstract: Named Entity Linking (NEL) is a core component of biomedical Information Extraction (IE) pipelines, yet assessing its quality at scale is challenging due to the high cost of expert annotations and the large size of corpora. In this paper, we present a sampling-based framework to estimate the NEL accuracy of large-scale IE corpora under statistical guarantees and constrained annotation budgets. We frame NEL accuracy estimation as a constrained optimization problem, where the objective is to minimize expected annotation cost subject to a target Margin of Error (MoE) for the corpus-level accuracy estimate. Building on recent works on knowledge graph accuracy estimation, we adapt Stratified Two-Stage Cluster Sampling (STWCS) to the NEL setting, defining label-based strata and global surface-form clusters in a way that is independent of NEL annotations. Applied to 11,184 NEL annotations in GutBrainIE -- a new biomedical corpus openly released in fall 2025 -- our framework reaches a MoE $\leq 0.05$ by manually annotating only 2,749 triples (24.6%), leading to an overall accuracy estimate of $0.915 \pm 0.0473$. A time-based cost model and simulations against a Simple Random Sampling (SRS) baseline show that our design reduces expert annotation time by about 29% at fixed sample size. The framework is generic and can be applied to other NEL benchmarks and IE pipelines that require scalable and statistically robust accuracy assessment.

</details>


### [179] [Labels have Human Values: Value Calibration of Subjective Tasks](https://arxiv.org/abs/2601.06631)
*Mohammed Fayiz Parappan,Ricardo Henao*

Main category: cs.CL

TL;DR: 该论文提出了一种用于主观任务的NLP多群体校准学习框架（MC-STL），通过聚类和特定群体嵌入提升模型对不同价值观的识别和校准能力，在多个主观任务数据集上显著超过基线方法。


<details>
  <summary>Details</summary>
Motivation: 主观性任务在NLP领域中很常见，由于不同注释者可能基于不同的价值观做出判断，如何让模型对这些差异进行校准，从而更好地符合不同人群的评价标准，是一个重要挑战。

Method: 作者提出MC-STL框架，将注释者根据其理由相似性、专家价值观分类或社会文化属性等分组成价值观群体，并采用为每个群体学习独立表征的方式，对模型预测进行多群体校准，提升对主观注释差异的捕捉能力。

Result: 在有序、二元和偏好学习等多个主观任务上，以及有毒聊天、冒犯社交发言和人类偏好对齐等数据集上，MC-STL在判别能力、针对特定价值观的校准、以及考量分歧的指标上均优于无视潜在价值结构的基线模型。

Conclusion: MC-STL能够有效提升主观性任务中模型对不同群体价值观的对齐，减轻因忽略注释价值差异带来的性能损失，具备广泛应用前景。

Abstract: Building NLP systems for subjective tasks requires one to ensure their alignment to contrasting human values. We propose the MultiCalibrated Subjective Task Learner framework (MC-STL), which clusters annotations into identifiable human value clusters by three approaches (similarity of annotator rationales, expert-value taxonomies or rater's sociocultural descriptors) and calibrates predictions for each value cluster by learning cluster-specific embeddings. We demonstrate MC-STL on several subjective learning settings, including ordinal, binary, and preference learning predictions, and evaluate it on multiple datasets covering toxic chatbot conversations, offensive social media posts, and human preference alignment. The results show that MC-STL consistently outperforms the baselines that ignore the latent value structure of the annotations, delivering gains in discrimination, value-specific calibration, and disagreement-aware metrics.

</details>


### [180] [MedEinst: Benchmarking the Einstellung Effect in Medical LLMs through Counterfactual Differential Diagnosis](https://arxiv.org/abs/2601.06636)
*Wenting Chen,Zhongrui Zhu,Guolin Huang,Wenxuan Wang*

Main category: cs.CL

TL;DR: 大语言模型（LLM）在医学基准测试上表现良好，但在临床诊断中存在“定势效应”，即倾向于依赖统计捷径而不是病人特异性证据，导致非典型病例误诊。作者提出MedEinst新基准，通过对比正常与故意“设陷”病例，评价模型误入诊断陷阱的概率。结果显示主流LLM高准确率但“陷阱率”高。为此，提出ECR-Agent模型，用因果推理和图结构记忆等方法促进循证医疗标准的一致性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLM）能在常规医疗问题测试中取得高分，但在临床实际中，模型容易受到“Einstellung效应”影响，主要依赖表层统计规律而非具体证据，导致难以发现非典型病例，增加误诊风险。现有基准无法有效揭示这一潜在风险，因此作者希望通过新基准更好评估并提升LLM在医疗场景下的可靠性。

Method: 作者设计了MedEinst基准，包括5383对临床案例（涵盖49种疾病），每对包含一个标准病例和一个含有诊断“陷阱”的对照病例。通过统计模型在面对“陷阱病例”时的误诊率（Bias Trap Rate）衡量模型脆弱性，并在17种主流LLM上进行评测。同时，提出ECR-Agent框架，结合动态因果推理（DCI）和批判驱动的图谱与记忆进化（CGME），帮助模型动态整合和复用疾病相关知识，提高诊断推理质量。

Result: 实验结果显示，虽然主流LLM在通常病例上准确率较高，但在被设计“设陷”反转证据的病例上，误诊率显著升高，暴露出原有模型存在的关键弱点。

Conclusion: 当前LLM医疗推理存在定势易陷阱的实际风险。新提出的MedEinst基准能够有效揭示这一问题。ECR-Agent方法有助于提升LLM的循证医疗推理能力，为未来安全可靠的AI医疗系统提供了新方向。

Abstract: Despite achieving high accuracy on medical benchmarks, LLMs exhibit the Einstellung Effect in clinical diagnosis--relying on statistical shortcuts rather than patient-specific evidence, causing misdiagnosis in atypical cases. Existing benchmarks fail to detect this critical failure mode. We introduce MedEinst, a counterfactual benchmark with 5,383 paired clinical cases across 49 diseases. Each pair contains a control case and a "trap" case with altered discriminative evidence that flips the diagnosis. We measure susceptibility via Bias Trap Rate--probability of misdiagnosing traps despite correctly diagnosing controls. Extensive Evaluation of 17 LLMs shows frontier models achieve high baseline accuracy but severe bias trap rates. Thus, we propose ECR-Agent, aligning LLM reasoning with Evidence-Based Medicine standard via two components: (1) Dynamic Causal Inference (DCI) performs structured reasoning through dual-pathway perception, dynamic causal graph reasoning across three levels (association, intervention, counterfactual), and evidence audit for final diagnosis; (2) Critic-Driven Graph and Memory Evolution (CGME) iteratively refines the system by storing validated reasoning paths in an exemplar base and consolidating disease-specific knowledge into evolving illness graphs. Source code is to be released.

</details>


### [181] [Efficient Aspect Term Extraction using Spiking Neural Network](https://arxiv.org/abs/2601.06637)
*Abhishek Kumar Mishra,Arya Somasundaram,Anup Das,Nagarajan Kandasamy*

Main category: cs.CL

TL;DR: 本文提出了一种新的高效方法SpikeATE，用于在评论句子中提取方面词（ATE），能够在显著降低能耗的同时，保持与现有深度神经网络相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有ATE方法多依赖于高能耗的深度神经网络，实际应用中亟需更节能且性能优秀的替代方法。

Method: 将脉冲神经网络（SNNs）引入ATE任务，构建SpikeATE架构，利用稀疏激活和事件驱动推理，采用三值脉冲神经元和伪梯度直接训练，并在多个主流数据集上验证效果。

Result: SpikeATE在四个SemEval基准数据集上取得了与现有最先进DNN模型相当的表现，同时大幅降低了能耗。

Conclusion: SNNs（如SpikeATE架构）为ATE任务提供了可行且可持续的解决方案，是深度学习方法的有力补充。

Abstract: Aspect Term Extraction (ATE) identifies aspect terms in review sentences, a key subtask of sentiment analysis. While most existing approaches use energy-intensive deep neural networks (DNNs) for ATE as sequence labeling, this paper proposes a more energy-efficient alternative using Spiking Neural Networks (SNNs). Using sparse activations and event-driven inferences, SNNs capture temporal dependencies between words, making them suitable for ATE. The proposed architecture, SpikeATE, employs ternary spiking neurons and direct spike training fine-tuned with pseudo-gradients. Evaluated on four benchmark SemEval datasets, SpikeATE achieves performance comparable to state-of-the-art DNNs with significantly lower energy consumption. This highlights the use of SNNs as a practical and sustainable choice for ATE tasks.

</details>


### [182] [Do Language Models Reason Across Languages?](https://arxiv.org/abs/2601.06644)
*Yan Meng,Wafaa Mohammed,Christof Monz*

Main category: cs.CL

TL;DR: 本文研究了多语言信息源下的两跳问答任务，并提出了提升语言模型推理能力的新方法。


<details>
  <summary>Details</summary>
Motivation: 实际世界的信息往往是多语言的，如何让语言模型跨语言整合推理成为一个重要问题。

Method: 提出两跳问答设置，即需要通过跨越两种语言的文档进行推理。分析语言模型在子问题推理和整体问题解答中的表现，并提出三阶段SUBQ提示方法，通过子问题分步引导模型推理。

Result: 发现模型对包含答案的文档比提供桥接信息的文档更敏感，在多语种任务中，多至33%的情况下，模型未正确推理桥接信息但仍能答对最终问题，存在约18%的推理组合失败。SUBQ提示法将准确率从10.1%提升至66.5%。

Conclusion: 现有语言模型在多语言两跳推理中不总是忠实分步推理，易导致失误。采用结构化的分步提示可显著提升推理准确率，有助于多语言信息整合。

Abstract: The real-world information sources are inherently multilingual, which naturally raises a question about whether language models can synthesize information across languages. In this paper, we introduce a simple two-hop question answering setting, where answering a question requires making inferences over two multilingual documents. We find that language models are more sensitive to language variation in answer-span documents than in those providing bridging information, despite the equal importance of both documents for answering a question. Under a step-by-step sub-question evaluation, we further show that in up to 33% of multilingual cases, models fail to infer the bridging information in the first step yet still answer the overall question correctly. This indicates that reasoning in language models, especially in multilingual settings, does not follow a faithful step-by-step decomposition. Subsequently, we show that the absence of reasoning decomposition leads to around 18% composition failure, where both sub-questions are answered correctly but fail for the final two-hop questions. To mitigate this, we propose a simple three-stage SUBQ prompting method to guide the multi-step reasoning with sub-questions, which boosts accuracy from 10.1% to 66.5%.

</details>


### [183] [What makes for an enjoyable protagonist? An analysis of character warmth and competence](https://arxiv.org/abs/2601.06658)
*Hannes Rosenbusch*

Main category: cs.CL

TL;DR: 本研究探讨了电影主角的温暖度和能力感是否能预测IMDb评分，以及这一效应在不同类型影片中的表现。结果表明温暖度和能力感对评分有一定影响，但作用较小。


<details>
  <summary>Details</summary>
Motivation: 受心理学和文学理论启发，作者想了解主角的性格特质（如温暖、能力）是否会影响电影的受欢迎程度，以及这种影响会不会因类型不同而变化。

Method: 作者利用AI与大语言模型（LLM_annotate）对2,858部影视剧的主角进行标注，量化其温暖和能力。通过先验注册的贝叶斯回归分析，考察这些特质与IMDb评分的关系，并检验不同类型间的差异。

Result: 温暖和能力与观众评分呈现理论预期的一致但较弱的关联，不同类型的交互作用影响不大。男性主角的温暖度略低于女性主角，但由男性主角出演的电影平均评分更高，这一关联远强于性格特质与评分的关系。AI标注方法对大规模分析有效，但与人工标注相比偶有不足。

Conclusion: 观众普遍偏好温暖且有能力的主角，但主角性格对电影评分的影响有限，评分受多种因素共同影响。AI辅助方法为大规模性格标签研究提供了可行方案，但仍需优化。

Abstract: Drawing on psychological and literary theory, we investigated whether the warmth and competence of movie protagonists predict IMDb ratings, and whether these effects vary across genres. Using 2,858 films and series from the Movie Scripts Corpus, we identified protagonists via AI-assisted annotation and quantified their warmth and competence with the LLM_annotate package ([1]; human-LLM agreement: r = .83). Preregistered Bayesian regression analyses revealed theory-consistent but small associations between both warmth and competence and audience ratings, while genre-specific interactions did not meaningfully improve predictions. Male protagonists were slightly less warm than female protagonists, and movies with male leads received higher ratings on average (an association that was multiple times stronger than the relationships between movie ratings and warmth/competence). These findings suggest that, although audiences tend to favor warm, competent characters, the effects on movie evaluations are modest, indicating that character personality is only one of many factors shaping movie ratings. AI-assisted annotation with LLM_annotate and gpt-4.1-mini proved effective for large-scale analyses but occasionally fell short of manually generated annotations.

</details>


### [184] [InFi-Check: Interpretable and Fine-Grained Fact-Checking of LLMs](https://arxiv.org/abs/2601.06666)
*Yuzhuo Bai,Shuzheng Si,Kangyang Luo,Qingyi Wang,Wenhao Li,Gang Chen,Fanchao Qi,Maosong Sun*

Main category: cs.CL

TL;DR: 本文提出了InFi-Check框架，实现对大型语言模型输出结果的可解释、细粒度事实核查。通过高质量数据和新模型，提升了事实性评价的精度和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有论文多将事实性核查当作二分类问题，缺乏细节和可解释性。LLM存在幻觉现象，实际应用中需要更细粒度、可溯源的事实核查方法。

Method: 提出了一个包含可控数据生成流程，生成包含证据、错误类型标签、理由和修正的高质量训练数据集；基于数据集构建了benchmark，并设计InFi-Checker模型，实现证据挖掘、细粒度错误分类以及理由和修正输出。

Result: InFi-Checker在InFi-Check-FG基准上达到最优性能，并在多项下游任务上展现出良好泛化能力，提升了事实性核查的效果。

Conclusion: InFi-Check框架和InFi-Checker模型有效提升了LLM输出事实性核查的可解释性、细粒度和实用性，有望提高大模型输出结果的可信度与应用价值。

Abstract: Large language models (LLMs) often hallucinate, yet most existing fact-checking methods treat factuality evaluation as a binary classification problem, offering limited interpretability and failing to capture fine-grained error types. In this paper, we introduce InFi-Check, a framework for interpretable and fine-grained fact-checking of LLM outputs. Specifically, we first propose a controlled data synthesis pipeline that generates high-quality data featuring explicit evidence, fine-grained error type labels, justifications, and corrections. Based on this, we further construct large-scale training data and a manually verified benchmark InFi-Check-FG for fine-grained fact-checking of LLM outputs. Building on these high-quality training data, we further propose InFi-Checker, which can jointly provide supporting evidence, classify fine-grained error types, and produce justifications along with corrections. Experiments show that InFi-Checker achieves state-of-the-art performance on InFi-Check-FG and strong generalization across various downstream tasks, significantly improving the utility and trustworthiness of factuality evaluation.

</details>


### [185] [Will it Merge? On The Causes of Model Mergeability](https://arxiv.org/abs/2601.06672)
*Adir Rahamim,Asaf Yehudai,Boaz Carmeli,Leshem Choshen,Yosi Mass,Yonatan Belinkov*

Main category: cs.CL

TL;DR: 该论文研究了模型合并技术，提出了衡量模型“易合并性”的新方法，并发现基础模型的知识掌握程度是影响合并效果的关键因素。


<details>
  <summary>Details</summary>
Motivation: 尽管模型合并可以将多个微调模型合成为一个多任务模型，但合并成功与否的影响因素尚不清楚。论文旨在揭示导致模型合并成功或失败的原因，为优化模型合并提供理论依据。

Method: 作者首先提出具体的、可度量的“易合并性”定义，并通过实验分析哪些因素会影响模型的易合并性，重点考察了基础模型对训练实例的掌握情况。同时，探索了一种加权合并方法，以更好保留基础模型的弱知识。

Result: 实验结果显示，若微调数据是基础模型本就擅长的任务，则这些模型更容易顺利合并。而基础模型对某些实例掌握较差时，微调所得模型难以合并。新提出的加权合并方法能够更好地保留基础模型的弱知识。

Conclusion: 基础模型的知识水平显著影响模型合并效果。未来可通过优化合并策略（如加权合并）提升多任务模型的性能和通用性。

Abstract: Model merging has emerged as a promising technique for combining multiple fine-tuned models into a single multitask model without retraining. However, the factors that determine whether merging will succeed or fail remain poorly understood. In this work, we investigate why specific models are merged better than others. To do so, we propose a concrete, measurable definition of mergeability. We investigate several potential causes for high or low mergeability, highlighting the base model knowledge as a dominant factor: Models fine-tuned on instances that the base model knows better are more mergeable than models fine-tuned on instances that the base model struggles with. Based on our mergeability definition, we explore a simple weighted merging technique that better preserves weak knowledge in the base model.

</details>


### [186] [Evaluating Cross-Lingual Unlearning in Multilingual Language Models](https://arxiv.org/abs/2601.06675)
*Tyler Lizzo,Larry Heck*

Main category: cs.CL

TL;DR: 本文首次系统性评估了多语言大模型中的跨语言遗忘（unlearning）能力，发现传统方法难以去除多语言信息，但子空间投影法表现突出。


<details>
  <summary>Details</summary>
Motivation: 当前大模型在多语言环境下如何有效移除特定知识（如隐私或有害信息），尤其是跨语言的遗忘效果尚不明确，需要系统评估。

Method: 作者采用七种语言或文字变体的TOFU基准任务，对多种主流的遗忘算法进行测试，并引入子空间投影方法。同时对模型权重空间的几何结构进行分析。

Result: 大多数遗忘算法无法有效移除训练语言以外的事实，但子空间投影法可以在保持模型能力的基础上，实现较强的跨语言遗忘。权重空间分析发现存在共享的“中介语言”子空间，这对遗忘有关键影响。

Conclusion: 多语言遗忘与权重空间中的几何结构密切相关，子空间投影是有前景的跨语言遗忘方法。未来的遗忘系统应关注权重子空间的结构。

Abstract: We present the first comprehensive evaluation of cross-lingual unlearning in multilingual LLMs. Using translated TOFU benchmarks in seven language/script variants, we test major unlearning algorithms and show that most fail to remove facts outside the training language, even when utility remains high. However, subspace-projection consistently outperforms the other methods, achieving strong cross-lingual forgetting with minimal degradation. Analysis of learned task subspaces reveals a shared interlingua structure: removing this shared subspace harms all languages, while removing language-specific components selectively affects one. These results demonstrate that multilingual forgetting depends on geometry in weight space, motivating subspace-based approaches for future unlearning systems.

</details>


### [187] [IDRBench: Interactive Deep Research Benchmark](https://arxiv.org/abs/2601.06676)
*Yingchaojie Feng,Qiang Huang,Xiaoya Xie,Zhaorui Yang,Jun Yu,Wei Chen,Anthony K. H. Tung*

Main category: cs.CL

TL;DR: 本文提出了IDRBench，这是首个用于系统性评估交互式深度研究的基准，旨在弥补现有LLM研究agent缺乏用户交互建模与评估的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大型语言模型（LLM）的研究agent大多假定用户意图完全且静态，忽略了真实研究过程中目标经常变化且强交互需求。因此，需要一种能够系统建模并评估人机交互对研究质量与成本影响的方法。

Method: 作者设计了IDRBench基准，包括1）一个模块化多agent研究框架，支持按需交互；2）可扩展的参考标准用户模拟器；3）结合质量与交互成本的评估体系。通过实验系统地对比不同LLM在模拟研究任务中的交互表现。

Result: 在七类主流LLM实验中，加入交互显著提升了研究质量与稳健性，这一提升有时甚至超越模型规模带来的性能差异。同时，实验揭示了交互效率与消耗之间的显著权衡。

Conclusion: 交互对于提升LLM驱动的研究agent质量至关重要，IDRBench为交互式研究agent的客观评估提供了标准工具，有助于推动该领域从单纯自治向高效人机协作发展。

Abstract: Deep research agents powered by Large Language Models (LLMs) can perform multi-step reasoning, web exploration, and long-form report generation. However, most existing systems operate in an autonomous manner, assuming fully specified user intent and evaluating only final outputs. In practice, research goals are often underspecified and evolve during exploration, making sustained interaction essential for robust alignment. Despite its importance, interaction remains largely invisible to existing deep research benchmarks, which neither model dynamic user feedback nor quantify its costs. We introduce IDRBench, the first benchmark for systematically evaluating interactive deep research. IDRBench combines a modular multi-agent research framework with on-demand interaction, a scalable reference-grounded user simulator, and an interaction-aware evaluation suite that jointly measures interaction benefits (quality and alignment) and costs (turns and tokens). Experiments across seven state-of-the-art LLMs show that interaction consistently improves research quality and robustness, often outweighing differences in model capacity, while revealing substantial trade-offs in interaction efficiency.

</details>


### [188] [Characterising Toxicity in Generative Large Language Models](https://arxiv.org/abs/2601.06700)
*Zhiyao Zhang,Yazan Mash'Al,Yuhan Wu*

Main category: cs.CL

TL;DR: 本文探讨了当前主流基于transformer的解码式大语言模型（LLMs）在特定提示下生成有害（toxic）内容的现象，以及影响这类内容生成的语言因素。


<details>
  <summary>Details</summary>
Motivation: 随着注意力机制和transformer模型推动NLP进步，文本生成能力大幅提升，但仍存在输出不恰当、冒犯性或有害内容的风险。虽然有RLHF等对策，但在精心设计的提示下这些防护仍可能被绕过，因此有必要系统评估和理解LLMs生成toxic内容的现状及其影响因素。

Method: 本文通过为大语言模型设计特定的提示，对其生成内容进行分析。进一步，研究分析了影响toxic内容生成的词汇（lexical）和句法（syntactic）因素。

Result: 研究发现，大语言模型在特定提示下仍能生成toxic内容，且一定的词汇及句法结构会显著影响这种内容生成的概率与方式。

Conclusion: 当前LLMs的toxic内容防护仍有不足，仅依靠RLHF等机制难以完全杜绝有害内容生成。深入理解其生成机制有助于下一步提升模型安全性及实用性。

Abstract: In recent years, the advent of the attention mechanism has significantly advanced the field of natural language processing (NLP), revolutionizing text processing and text generation. This has come about through transformer-based decoder-only architectures, which have become ubiquitous in NLP due to their impressive text processing and generation capabilities. Despite these breakthroughs, language models (LMs) remain susceptible to generating undesired outputs: inappropriate, offensive, or otherwise harmful responses. We will collectively refer to these as ``toxic'' outputs. Although methods like reinforcement learning from human feedback (RLHF) have been developed to align model outputs with human values, these safeguards can often be circumvented through carefully crafted prompts. Therefore, this paper examines the extent to which LLMs generate toxic content when prompted, as well as the linguistic factors -- both lexical and syntactic -- that influence the production of such outputs in generative models.

</details>


### [189] [GRASP LoRA: GRPO Guided Adapter Sparsity Policy for Cross Lingual Transfer](https://arxiv.org/abs/2601.06702)
*Besher Hassan,Xiuying Chen*

Main category: cs.CL

TL;DR: 该论文提出了一种高效参数微调方法GRASP LoRA，实现了更精确、更高效地为大语言模型（LLM）适配新语言，显著节省算力和数据需求。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型适配新语言时，通常通过全局裁剪比例网格搜索来选择参数微调方案，但这一方式计算量大且对开发集依赖高。作者希望优化该过程，降低微调计算消耗，提升低资源场景下的实用性。

Method: 提出GRASP LoRA方法，将全局稀疏率视为可学习控制变量。在训练过程中使用GRPO控制器，通过在小型开发集上周期性探测多个裁剪比例，并在线调整全局稀疏率，最终确定单一最优裁剪比例。整个流程仅需一轮控制器训练和一次最终裁剪微调，而无需多次网格搜索。

Result: 在从英文到阿拉伯语和中文的跨语言任务（如XL-Sum摘要和MLQA抽取式问答，模型为Llama 3 8B）中，GRASP LoRA在语义一致性、内容覆盖度和答案质量上均优于目标语言微调和合并裁剪等强基线，并且总运行时是网格搜索的数倍以内，大幅降低了对大型开发集的依赖。

Conclusion: GRASP LoRA实现了高效、低资源的大模型跨语言微调，提升了适配精度及实用性，有效降低了开发集和计算资源消耗，使适配器的重复利用更具可行性。

Abstract: Parameter efficient fine tuning is a way to adapt LLMs to new languages when compute or data are limited, yet adapter pipelines usually choose a global prune ratio by grid search. This practice is computationally expensive and development set intensive, since it repeats training, freezes sparsity, and misses fractional optima. We introduce GRASP LoRA (GRPO Guided Adapter Sparsity Policy), which treats global sparsity as a learnable control variable. A GRPO controller interleaves with training, periodically probing candidate prune ratios on a small micro development set and updating a single global prune ratio online from its reward signal. It operates on merged source and target LoRA adapters on a frozen backbone and replaces grid search with one controller run that learns a prune ratio, followed by a single final merge and prune fine tuning run with pruning fixed to that ratio. On cross lingual transfer from English into Arabic and Chinese, including XL-Sum summarization and MLQA extractive question answering with Llama 3 8B, GRASP LoRA improves semantic faithfulness, content coverage, and answer quality over strong target only and merge and prune baselines. It reduces end to end runtime by multiple times relative to grid search, lowers reliance on large development sets, and makes adapter reuse practical for low resource deployment.

</details>


### [190] [Evaluating Accounting Reasoning Capabilities of Large Language Models](https://arxiv.org/abs/2601.06707)
*Jie Zhou,Xin Chen,Jie Zhang,Hai Li,Jie Wang,Zhe Li*

Main category: cs.CL

TL;DR: 本文提出针对会计领域推理的评测标准，并对主流大语言模型在会计推理任务上的表现进行对比和分析。结果显示GPT-4表现最佳，但目前所有模型距离实际企业需求仍有差距，需要进一步优化。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在各领域变革了学习和研究方式，将其有效应用于专业领域如会计，是企业数字化转型的关键挑战。需要专门的评测标准来系统性研究和提升其在会计推理上的表现。

Method: 通过分析主流GLM模型的训练数据，提出了会计领域垂直推理的评测标准，并以此标准评测了GLM-6B、GLM-130B、GLM-4和OpenAI GPT-4在会计推理任务中的表现。

Result: 实验证明提示词设计对模型结果有显著影响，GPT-4在会计推理任务中表现最强。

Conclusion: 尽管部分模型在会计推理任务上取得明显进步，但距离满足实际企业会计需求仍不够，需对模型进一步优化，发挥其真正应用价值。

Abstract: Large language models are transforming learning, cognition, and research across many fields. Effectively integrating them into professional domains, such as accounting, is a key challenge for enterprise digital transformation. To address this, we define vertical domain accounting reasoning and propose evaluation criteria derived from an analysis of the training data characteristics of representative GLM models. These criteria support systematic study of accounting reasoning and provide benchmarks for performance improvement. Using this framework, we evaluate GLM-6B, GLM-130B, GLM-4, and OpenAI GPT-4 on accounting reasoning tasks. Results show that prompt design significantly affects performance, with GPT-4 demonstrating the strongest capability. Despite these gains, current models remain insufficient for real-world enterprise accounting, indicating the need for further optimization to unlock their full practical value.

</details>


### [191] [Towards Computational Chinese Paleography](https://arxiv.org/abs/2601.06753)
*Yiran Rex Ma*

Main category: cs.CL

TL;DR: 中国古文字学正在由人工智能驱动，经历从单点视觉任务向综合数字学术生态系统转变，呼吁以多模态、少样本和以人为本的AI推动学科发展。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能的发展，传统的中国古文字研究面对着数据资源碎片化、学术研究流程分割、AI与人文学科结合有限等诸多挑战。本文旨在梳理该领域的现状与技术演进，明确未来研究方向。

Method: 首先系统分析甲骨文、青铜器铭文、简牍等多种古文字数字资源，梳理学科关键数据集。在方法论层面，解析从基础的视觉图像处理（如图像修复、文字识别）、到上下文分析（如断裂补全、断代）、再到高级推理（自动释读、人机协同）等全流程。对比传统计算机视觉方法和现代深度学习（如transformer与多模态大模型）的范式转变，并总结AI应用中的技术瓶颈。

Result: 揭示该领域面临数据稀缺、AI能力单一与人文学科综合性不匹配等核心挑战，AI技术虽取得突破，但离学者全面需求仍有较大差距。

Conclusion: 认为未来研究需聚焦多模态、少样本学习与以人为本的AI，推动AI成为学者的智能助手，促进古文字学的创新发展。

Abstract: Chinese paleography, the study of ancient Chinese writing, is undergoing a computational turn powered by artificial intelligence. This position paper charts the trajectory of this emerging field, arguing that it is evolving from automating isolated visual tasks to creating integrated digital ecosystems for scholarly research. We first map the landscape of digital resources, analyzing critical datasets for oracle bone, bronze, and bamboo slip scripts. The core of our analysis follows the field's methodological pipeline: from foundational visual processing (image restoration, character recognition), through contextual analysis (artifact rejoining, dating), to the advanced reasoning required for automated decipherment and human-AI collaboration. We examine the technological shift from classical computer vision to modern deep learning paradigms, including transformers and large multimodal models. Finally, we synthesize the field's core challenges -- notably data scarcity and a disconnect between current AI capabilities and the holistic nature of humanistic inquiry -- and advocate for a future research agenda focused on creating multimodal, few-shot, and human-centric systems to augment scholarly expertise.

</details>


### [192] [MTMCS-Bench: Evaluating Contextual Safety of Multimodal Large Language Models in Multi-Turn Dialogues](https://arxiv.org/abs/2601.06757)
*Zheyuan Liu,Dongwhi Kim,Yixin Wan,Xiangchi Yuan,Zhaoxuan Tan,Fengran Mo,Meng Jiang*

Main category: cs.CL

TL;DR: 本文提出了一个用于评估多模态大语言模型（MLLM）上下文安全性的多轮对话和图像基准数据集MTMCS-Bench，并分析了当前模型与防护措施在实际应用中的不足。


<details>
  <summary>Details</summary>
Motivation: 随着MLLM被越来越多地应用于处理文本和图像的场景，其在多轮对话中对安全性的评估变得尤为重要，尤其当风险来自于视觉信息和动态对话的组合时。现有基准多以单轮为主，未能捕捉恶意意图的渐进性或同一场景下善意/恶意目的的区别。

Method: 作者构建了包含30,000余个多模态（图像+文本）及单模态（仅文本）样本的MTMCS-Bench，设计了升级风险和情境转换风险两类场景，每个样本配有安全和不安全对话对，并采用多项独立指标衡量意图识别、安全意识和有益性。此外，评估了15个主流MLLM和5项安全防护措施。

Result: 横跨15款模型（8开源、7闭源）的实验发现，现有MLLM在安全与可用性间存在权衡：模型要么无法发现渐进风险，要么过度拒绝无害对话。现有5项安全防护措施虽能缓解部分问题，但对多轮上下文风险无法完全解决。

Conclusion: 提出的基准更真实反映了多模态对话中的安全挑战，为未来安全机制和模型改进提供了测试平台。当前MLLM及其防护仍面临多轮对话下的安全风险，需进一步优化。

Abstract: Multimodal large language models (MLLMs) are increasingly deployed as assistants that interact through text and images, making it crucial to evaluate contextual safety when risk depends on both the visual scene and the evolving dialogue. Existing contextual safety benchmarks are mostly single-turn and often miss how malicious intent can emerge gradually or how the same scene can support both benign and exploitative goals. We introduce the Multi-Turn Multimodal Contextual Safety Benchmark (MTMCS-Bench), a benchmark of realistic images and multi-turn conversations that evaluates contextual safety in MLLMs under two complementary settings, escalation-based risk and context-switch risk. MTMCS-Bench offers paired safe and unsafe dialogues with structured evaluation. It contains over 30 thousand multimodal (image+text) and unimodal (text-only) samples, with metrics that separately measure contextual intent recognition, safety-awareness on unsafe cases, and helpfulness on benign ones. Across eight open-source and seven proprietary MLLMs, we observe persistent trade-offs between contextual safety and utility, with models tending to either miss gradual risks or over-refuse benign dialogues. Finally, we evaluate five current guardrails and find that they mitigate some failures but do not fully resolve multi-turn contextual risks.

</details>


### [193] [GanitLLM: Difficulty-Aware Bengali Mathematical Reasoning through Curriculum-GRPO](https://arxiv.org/abs/2601.06767)
*Shubhashis Roy Dipta,Khairul Mahbub,Nadia Najjar*

Main category: cs.CL

TL;DR: 提出了一种适用于孟加拉语数学推理的模型GanitLLM，以及一个考虑题目难度的新孟加拉语数学语料库和循序渐进的训练流程。


<details>
  <summary>Details</summary>
Motivation: 现有大模型在处理孟加拉语数学推理任务时表现不佳，主要因为相关训练资源稀缺、强化学习方法难以适用低资源语言，导致推理能力有限。

Method: 构建了经过严格过滤和难度标注的孟加拉语数学数据集（Ganit），并提出了Curriculum-GRPO训练方法，通过多阶段训练、难度感知采样和可验证奖励机制提升模型推理能力。

Result: GanitLLM-4B在两个公共孟加拉语数学数据集上，比基础模型Qwen3-4B分别提升8和7个百分点的准确率，孟加拉语推理占比大幅提升，解题长度显著缩短。

Conclusion: 专为孟加拉语开发的数学推理模型能有效提升推理表现，为低资源语言的相关任务提供了新的方法参考。

Abstract: We present a Bengali mathematical reasoning model called GanitLLM (named after the Bangla word for mathematics, "Ganit"), together with a new difficulty-aware Bengali math corpus and a curriculum-based GRPO pipeline. Bengali is one of the world's most widely spoken languages, yet existing LLMs either reason in English and then translate, or simply fail on multi-step Bengali math, in part because reinforcement learning recipes are tuned for high-resource languages and collapse under reward sparsity in low-resource settings. To address this, we construct Ganit, a rigorously filtered and decontaminated Bengali math dataset with automatic difficulty tags derived from the pass@k of a strong evaluator model. Building on this dataset, we propose Curriculum-GRPO, which combines multi-stage training (SFT + GRPO) with difficulty-aware sampling and verifiable rewards for format, numerical correctness, and Bengali reasoning. On Bn-MGSM and Bn-MSVAMP, GanitLLM-4B improves over its Qwen3-4B base by +8 and +7 accuracy points, respectively, while increasing the percentage of Bengali reasoning tokens from 14% to over 88% and reducing average solution length from 943 to 193 words.

</details>


### [194] [Multi-Stage Evolutionary Model Merging with Meta Data Driven Curriculum Learning for Sentiment-Specialized Large Language Modeling](https://arxiv.org/abs/2601.06780)
*Keito Inoshita,Xiaokang Zhou,Akira Kawai*

Main category: cs.CL

TL;DR: 本文提出了一种结合演化模型合并与元数据驱动课程学习的新型情感分析模型（MEM-MCL），在大语言模型基础上实现多任务更高效、准确的情感分析。


<details>
  <summary>Details</summary>
Motivation: 现有情感分析方法多聚焦某一具体任务，难以应对实际应用中需要高准确率、强扩展性的多任务情感分析。大语言模型虽泛化能力强，但在具体情感任务中准确率往往不足。作者旨在解决多任务高效融合与学习顺序优化难题。

Method: 作者提出MEM-MCL方法，包含：(1)针对不同情感分析子任务，先通过指令微调训练专家模型；(2)使用演化算法将这些专家模型合并为统一模型，并利用弱数据优化融合过程，提高多任务表现；(3)引入元数据驱动的课程学习，根据任务难度安排学习顺序，提升知识提取能力。

Result: 实验结果显示，MEM-MCL模型在大多数情感分析任务及各类子任务上均优于常规大语言模型，取得更高准确率和泛化能力。

Conclusion: MEM-MCL能有效统一多子任务情感分析，实现高准确率与高扩展性，为多任务自然语言理解提供新思路。

Abstract: The emergence of large language models (LLMs) has significantly transformed natural language processing (NLP), enabling more generalized models to perform various tasks with minimal training. However, traditional sentiment analysis methods, which focus on individual tasks such as sentiment classification or aspect-based analysis, are not practical for real-world applications that usually require handling multiple tasks. While offering flexibility, LLMs in sentiment-specific tasks often fall short of the required accuracy. Techniques like fine-tuning and evolutionary model merging help integrate models into a unified framework, which can improve the learning performance while reducing computational costs. The use of task meta-data and curriculum learning to optimize learning processes remains underexplored, while sentiment analysis is a critical task in NLP that requires high accuracy and scalability across multiple subtasks. In this study, we propose a hybrid learning model called Multi-stage Evolutionary Model Merging with Meta data driven Curriculum Learning (MEM-MCL), to enhance the sentiment analysis in large language modeling. In particular, expert models are created through instruction tuning for specific sentiment tasks and then merged using evolutionary algorithms to form a unified model. The merging process is optimized with weak data to enhance performance across tasks. The curriculum learning is incorporated to provide a learning sequence based on task difficulty, improving knowledge extraction from LLMs. Experiment results demonstrate that the proposed MEM-MCL model outperforms conventional LLMs in a majority of sentiment analysis tasks, achieving superior results across various subtasks.

</details>


### [195] [EpiCaR: Knowing What You Don't Know Matters for Better Reasoning in LLMs](https://arxiv.org/abs/2601.06786)
*Jewon Yeom,Jaewon Sok,Seonghyeon Park,Jeongjae Park,Taesup Kim*

Main category: cs.CL

TL;DR: 本文提出了一种名为EpiCaR的新训练方法，在提升大语言模型（LLMs）推理能力的同时，显著改善其不确定性校准问题。实验表明，该方法在准确率与校准之间获得了更优的平衡，提高了模型推理可靠性，并大大减少了推理所需的计算资源。


<details>
  <summary>Details</summary>
Motivation: 现有提升LLM推理能力的方法依赖模型自生成数据的迭代训练，虽然提高了准确率，但导致模型过于自信且难以反应不确定性，带来所谓的“对齐塌缩”问题。本研究动机在于从根本上改进推理训练框架，使模型能够同时学习何时自信和何时表现不确定。

Method: 提出了EpiCaR（Epistemically-calibrated Reasoning）训练目标，将推理性能和校准能力共同最优化，并在迭代式有监督微调框架中结合显式自我评估信号应用该方法，通过实验在Llama-3和Qwen-3等主流模型上进行验证。

Result: EpiCaR在准确率和校准能力之间取得了优于标准基线的帕累托最优表现，尤其在大于3B参数量的模型上表现突出。该方法同样在数学推理（GSM8K）和代码生成（MBPP）等不同领域任务上泛化性良好。推理计算成本上，对能力充足模型，采用10个样本即可达到标准STaR方法30个样本的效果，实现了3倍效率提升。

Conclusion: EpiCaR训练框架提升了大模型的推理准确性与校准表现，实现了更可靠的模型输出，并有效降低了推理资源消耗，具有较高的实际应用价值。

Abstract: Improving the reasoning abilities of large language models (LLMs) has largely relied on iterative self-training with model-generated data. While effective at boosting accuracy, existing approaches primarily reinforce successful reasoning paths, incurring a substantial calibration cost: models become overconfident and lose the ability to represent uncertainty. This failure has been characterized as a form of model collapse in alignment, where predictive distributions degenerate toward low-variance point estimates. We address this issue by reframing reasoning training as an epistemic learning problem, in which models must learn not only how to reason, but also when their reasoning should be trusted. We propose epistemically-calibrated reasoning (EpiCaR) as a training objective that jointly optimizes reasoning performance and calibration, and instantiate it within an iterative supervised fine-tuning framework using explicit self-evaluation signals. Experiments on Llama-3 and Qwen-3 families demonstrate that our approach achieves Pareto-superiority over standard baselines in both accuracy and calibration, particularly in models with sufficient reasoning capacity (e.g., 3B+). This framework generalizes effectively to OOD mathematical reasoning (GSM8K) and code generation (MBPP). Ultimately, our approach enables a 3X reduction in inference compute, matching the K=30 performance of STaR with only K=10 samples in capable models.

</details>


### [196] [Garbage Attention in Large Language Models: BOS Sink Heads and Sink-aware Pruning](https://arxiv.org/abs/2601.06787)
*Jaewon Sok,Jewon Yeom,Seonghyeon Park,Jeongjae Park,Taesup Kim*

Main category: cs.CL

TL;DR: 本文提出了BOS sink现象作为解释大型语言模型（LLMs）高层存在大量冗余的主要机制，并据此提出更有效的剪枝策略。


<details>
  <summary>Details</summary>
Motivation: LLMs存在大量冗余，尤其高层的部分组件冗余度高，但缺乏系统性解释及高效的剪枝方法。

Method: 作者发现具有高BOS sink分数的注意力头（attention head）功能上往往冗余，尤其在模型深层。基于此提出移除高BOS sink分数头的简单剪枝策略，并在多个主流模型（Gemma-3、Llama-3.1、Qwen3）上进行实验。

Result: 与传统基于权重或激活的剪枝方法相比，BOS sink剪枝法能更可靠地识别冗余组件，在大幅剪枝下仍可保持接近未剪枝模型的性能。此外，sink头的行为在不同序列长度下表现稳定。

Conclusion: 基于注意力机制结构属性的剪枝方法比传统幅值型剪枝更直观可靠，为模型压缩理论和实际应用提供了新思路。

Abstract: Large Language Models (LLMs) are known to contain significant redundancy, yet a systematic explanation for why certain components, particularly in higher layers, are more redundant has remained elusive. In this work, we identify the BOS sink phenomenon as a key mechanism driving this layer-wise sensitivity. We show that attention heads with high BOS sink scores are strongly associated with functional redundancy: such heads, especially in deeper layers, contribute little to predictive performance and effectively serve as \emph{dumping grounds} for superfluous attention weights. This provides a concrete functional explanation for the structural redundancy reported in prior studies. Leveraging this insight, we introduce a simple pruning strategy that removes high-BOS sink heads. Experiments on Gemma-3, Llama-3.1, and Qwen3 demonstrate that this approach identifies redundant transformer components more reliably than weight- or activation-based criteria, while preserving performance close to dense baselines even under aggressive pruning. Moreover, we find that the behavior of sink heads remains stable across different sequence lengths. Overall, our results suggest that structural properties of attention offer a more intuitive and robust basis for model compression than magnitude-based methods.

</details>


### [197] [CIRAG: Construction-Integration Retrieval and Adaptive Generation for Multi-hop Question Answering](https://arxiv.org/abs/2601.06799)
*Zili Wei,Xiaocui Yang,Yilin Wang,Zihan Wang,Weidong Bao,Shi Feng,Daling Wang,Yifei Zhang*

Main category: cs.CL

TL;DR: 本文提出一种改进的多跳问答检索增强生成框架CIRAG，在信息检索和噪声控制方面效果优于现有iRAG模型。


<details>
  <summary>Details</summary>
Motivation: 现有iRAG方法在处理多跳问答时，存在单路径扩展带来的早期错误累积和证据信息捕获不足，以及证据粒度难以平衡噪声与上下文完整性的难题。

Method: CIRAG包含两个关键模块：（1）迭代构建-整合模块，能保留多条合理证据链并基于历史上下文筛选和集成候选三元组，生成下一跳查询；（2）自适应级联多粒度生成模块，根据问题需求递进地扩展证据粒度，从三元组到句子再到段落。同时用轨迹蒸馏技巧将教师模型的整合策略迁移到轻量学生模型，以提升推理效率和可靠性。

Result: 实验证明，CIRAG在多项指标上相较于现有iRAG方法表现更优，能够有效整合多源证据，提升长链推理与回答准确率。

Conclusion: CIRAG在避免单路径贪婪陷阱、增强多分支推理、以及证据多粒度自适应扩展方面带来了显著进步，有效推动了多跳问答系统的检索与生成能力。

Abstract: Triple-based Iterative Retrieval-Augmented Generation (iRAG) mitigates document-level noise for multi-hop question answering. However, existing methods still face limitations: (i) greedy single-path expansion, which propagates early errors and fails to capture parallel evidence from different reasoning branches, and (ii) granularity-demand mismatch, where a single evidence representation struggles to balance noise control with contextual sufficiency. In this paper, we propose the Construction-Integration Retrieval and Adaptive Generation model, CIRAG. It introduces an Iterative Construction-Integration module that constructs candidate triples and history-conditionally integrates them to distill core triples and generate the next-hop query. This module mitigates the greedy trap by preserving multiple plausible evidence chains. Besides, we propose an Adaptive Cascaded Multi-Granularity Generation module that progressively expands contextual evidence based on the problem requirements, from triples to supporting sentences and full passages. Moreover, we introduce Trajectory Distillation, which distills the teacher model's integration policy into a lightweight student, enabling efficient and reliable long-horizon reasoning. Extensive experiments demonstrate that CIRAG achieves superior performance compared to existing iRAG methods.

</details>


### [198] [Doing More with Less: Data Augmentation for Sudanese Dialect Automatic Speech Recognition](https://arxiv.org/abs/2601.06802)
*Ayman Mansour*

Main category: cs.CL

TL;DR: 本文针对苏丹阿拉伯语方言的自动语音识别（ASR），通过数据增强提升了Whisper模型的识别效果，并建立了首个相关基准，实验数据与模型公众开放。


<details>
  <summary>Details</summary>
Motivation: 目前大多数阿拉伯语ASR研究集中在现代标准阿拉伯语（MSA）或主流方言，较少关注如苏丹阿拉伯语这样极低资源的阿拉伯方言。该领域缺少数据、基准和有效模型，限制了技术普及。

Method: 对OpenAI Whisper模型采用两种数据增强策略：（1）对未标注语音利用伪标签进行自训练；（2）用TTS系统合成语音进行训练。分别及组合实验提升表现。

Result: 结合自训练与TTS增强的Whisper-Medium模型，在苏丹方言评测集上WER 57.1%，域外集WER 51.6%，显著优于零样本Whisper（78.8%）及MSA模型（73.8-123%）。

Conclusion: 低成本的策略性数据增强可有效提升低资源阿拉伯方言ASR性能，为相关语种ASR建设提供实用路线，实验、模型与基准均已公开，有助于后续研究。

Abstract: Although many Automatic Speech Recognition (ASR) systems have been developed for Modern Standard Arabic (MSA) and Dialectal Arabic (DA), few studies have focused on dialect-specific implementations, particularly for low-resource Arabic dialects such as Sudanese. This paper presents a comprehensive study of data augmentation techniques for fine-tuning OpenAI Whisper models and establishes the first benchmark for the Sudanese dialect. Two augmentation strategies are investigated: (1) self-training with pseudo-labels generated from unlabeled speech, and (2) TTS-based augmentation using synthetic speech from the Klaam TTS system. The best-performing model, Whisper-Medium fine-tuned with combined self-training and TTS augmentation (28.4 hours), achieves a Word Error Rate (WER) of 57.1% on the evaluation set and 51.6% on an out-of-domain holdout set substantially outperforming zero-shot multilingual Whisper (78.8% WER) and MSA-specialized Arabic models (73.8-123% WER). All experiments used low-cost resources (Kaggle free tier and Lightning.ai trial), demonstrating that strategic data augmentation can overcome resource limitations for low-resource dialects and provide a practical roadmap for developing ASR systems for low-resource Arabic dialects and other marginalized language varieties. The models, evaluation benchmarks, and reproducible training pipelines are publicly released to facilitate future research on low-resource Arabic ASR.

</details>


### [199] [Forest Before Trees: Latent Superposition for Efficient Visual Reasoning](https://arxiv.org/abs/2601.06803)
*Yubo Wang,Juntian Zhang,Yichen Wu,Yankai Lin,Nils Lukas,Yuhan Liu*

Main category: cs.CL

TL;DR: 论文提出了一种名为Laser的新方法，旨在提升大规模视觉-语言模型的推理能力，通过动态窗口对齐学习克服以往链式推理方法中的信息瓶颈与语义崩塌问题，并在多个基准上取得了优异效果。


<details>
  <summary>Details</summary>
Motivation: 链式推理（Chain-of-Thought）虽然能够增强多模态模型的推理能力，但由于将连续的视觉信息离散化，会损失大量细节，形成信息带宽瓶颈。现有的隐空间推理方法虽欲解决该问题，但因自回归目标过于僵化，易导致语义提前崩塌，影响模型表现。

Method: 论文提出Laser范式，核心是动态窗口对齐学习（DWAL）方法，不再采用逐点预测，而是利用动态有效窗口，将潜在状态与未来语义对齐，从而先捕获全局信息再细化到局部细节。此外，还引入自我精炼叠加机制，实现稳定高效的无约束学习，并保持推理过程的可解释性。

Result: Laser在6个基准数据集上取得了领先于其它隐空间推理方法的效果，在平均性能上较Monet基线提升5.03%。同时，Laser显著提升了推理效率，推理时使用的token数量减少超过97%，并且在分布外泛化任务上表现强健。

Conclusion: Laser方法有效缓解了视觉-语言大模型推理中的信息损失与语义崩塌难题，实现了更高效、泛化性更强、且可解释的多步推理能力，推动了多模态推理研究进展。

Abstract: While Chain-of-Thought empowers Large Vision-Language Models with multi-step reasoning, explicit textual rationales suffer from an information bandwidth bottleneck, where continuous visual details are discarded during discrete tokenization. Recent latent reasoning methods attempt to address this challenge, but often fall prey to premature semantic collapse due to rigid autoregressive objectives. In this paper, we propose Laser, a novel paradigm that reformulates visual deduction via Dynamic Windowed Alignment Learning (DWAL). Instead of forcing a point-wise prediction, Laser aligns the latent state with a dynamic validity window of future semantics. This mechanism enforces a "Forest-before-Trees" cognitive hierarchy, enabling the model to maintain a probabilistic superposition of global features before narrowing down to local details. Crucially, Laser maintains interpretability via decodable trajectories while stabilizing unconstrained learning via Self-Refined Superposition. Extensive experiments on 6 benchmarks demonstrate that Laser achieves state-of-the-art performance among latent reasoning methods, surpassing the strong baseline Monet by 5.03% on average. Notably, it achieves these gains with extreme efficiency, reducing inference tokens by more than 97%, while demonstrating robust generalization to out-of-distribution domains.

</details>


### [200] [AgentHallu: Benchmarking Automated Hallucination Attribution of LLM-based Agents](https://arxiv.org/abs/2601.06818)
*Xuannan Liu,Xiao Yang,Zekun Li,Peipei Li,Ran He*

Main category: cs.CL

TL;DR: 该论文提出了自动化归因大模型（LLM）代理多步骤推理过程中的幻觉（hallucination）来源的新任务，并建立了一个全面基准AgentHallu用于评测和推动相关研究。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测主要聚焦于单步响应，而多步骤推理任务中，幻觉可能发生在中间任一步骤，若无法定位源头，会影响整体系统的可靠性。因此，亟需一种方法能自动发现并归因幻觉最初产生的步骤。

Method: 提出了自动幻觉归因任务，并构建了AgentHallu基准数据集，包括7个代理框架、5个领域的693条高质量推理轨迹。设计了包含5大类、14个子类的幻觉分类体系，并由人工多层次标注幻觉、致因步骤及因果解释。

Result: 对13种顶级模型进行了实验评估，结果显示即使是最新的大模型（如GPT-5、Gemini-2.5-Pro）在该任务上的表现有限，最佳模型步骤定位准确率仅为41.1%，其中工具使用类幻觉最难，准确率仅11.6%。

Conclusion: 论文工作填补了当前多步推理幻觉归因的空白，AgentHallu可促进后续开发更健壮、透明、可靠的智能代理系统。

Abstract: As LLM-based agents operate over sequential multi-step reasoning, hallucinations arising at intermediate steps risk propagating along the trajectory, thus degrading overall reliability. Unlike hallucination detection in single-turn responses, diagnosing hallucinations in multi-step workflows requires identifying which step causes the initial divergence. To fill this gap, we propose a new research task, automated hallucination attribution of LLM-based agents, aiming to identify the step responsible for the hallucination and explain why. To support this task, we introduce AgentHallu, a comprehensive benchmark with: (1) 693 high-quality trajectories spanning 7 agent frameworks and 5 domains, (2) a hallucination taxonomy organized into 5 categories (Planning, Retrieval, Reasoning, Human-Interaction, and Tool-Use) and 14 sub-categories, and (3) multi-level annotations curated by humans, covering binary labels, hallucination-responsible steps, and causal explanations. We evaluate 13 leading models, and results show the task is challenging even for top-tier models (like GPT-5, Gemini-2.5-Pro). The best-performing model achieves only 41.1\% step localization accuracy, where tool-use hallucinations are the most challenging at just 11.6\%. We believe AgentHallu will catalyze future research into developing robust, transparent, and reliable agentic systems.

</details>


### [201] [PDR: A Plug-and-Play Positional Decay Framework for LLM Pre-training Data Detection](https://arxiv.org/abs/2601.06827)
*Jinhan Liu,Yibo Yang,Ruiying Lu,Piotr Piekos,Yimeng Chen,Peng Wang,Dandan Guo*

Main category: cs.CL

TL;DR: 该论文提出了一种无训练、即插即用的检测大语言模型预训练数据的算法PDR，通过对自回归生成中前期高熵token位置信号加权提升检测效果，在数据隐私和版权审计中表现优异。


<details>
  <summary>Details</summary>
Motivation: 在数据隐私和版权合规要求下，需检测LLM是否记忆和引用了受限数据，但现有黑盒、零样本环境下的方法难以高效发挥，而主流方法忽略了自回归生成过程中token信息贡献的变化。

Method: 提出Positional Decay Reweighting (PDR) 方法，在不需训练的情况下，对每个token的位置进行加权，突出前期高熵token的信号，抑制后期noise，实现检测分数的自适应聚合。

Result: 大量实验证明PDR对多种先进方法均有较强的提升作用，在多个基准测试上表现出更强的鲁棒性。

Conclusion: PDR是一种简洁高效的检测框架，能在实际受限场景（黑盒、无标签/训练数据）下提升预训练数据检测性能，有助于大语言模型的数据审计。

Abstract: Detecting pre-training data in Large Language Models (LLMs) is crucial for auditing data privacy and copyright compliance, yet it remains challenging in black-box, zero-shot settings where computational resources and training data are scarce. While existing likelihood-based methods have shown promise, they typically aggregate token-level scores using uniform weights, thereby neglecting the inherent information-theoretic dynamics of autoregressive generation. In this paper, we hypothesize and empirically validate that memorization signals are heavily skewed towards the high-entropy initial tokens, where model uncertainty is highest, and decay as context accumulates. To leverage this linguistic property, we introduce Positional Decay Reweighting (PDR), a training-free and plug-and-play framework. PDR explicitly reweights token-level scores to amplify distinct signals from early positions while suppressing noise from later ones. Extensive experiments show that PDR acts as a robust prior and can usually enhance a wide range of advanced methods across multiple benchmarks.

</details>


### [202] [Explainable Multimodal Aspect-Based Sentiment Analysis with Dependency-guided Large Language Model](https://arxiv.org/abs/2601.06848)
*Zhongzheng Wang,Yuanhe Tian,Hongzhi Wang,Yan Song*

Main category: cs.CL

TL;DR: 本文提出了一种基于多模态大语言模型（MLLMs）的生成式可解释多模态细粒度情感分析方法，同时预测方面级情感及生成自然语言解释，并引入依存句法引导的情感线索机制提升推理与可解释性。实验验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态方面级情感分析(MABSA)主要依赖判别式分类方法和复杂的多模态融合，但缺乏显式的情感可解释性。社交媒体的意见理解需要模型不仅能做出判别，还应能给出易于理解的解释。

Method: 作者将MABSA任务改为生成式任务，构建了统一框架，用prompt驱动的生成范式，借助MLLMs联合生成情感和解释。同时，提出依存句法引导的情感线索策略，将以方面为中心的依存句法树修剪并文本化，引导模型区分不同情感方面。最后，构建带情感解释的数据集进行微调。

Result: 所提方法在情感分类准确率上获得稳定提升，同时生成了忠实、以方面为基础的自然语言解释。

Conclusion: 本文方法兼顾情感判别性能和可解释性，推进了可解释多模态情感分析的发展。

Abstract: Multimodal aspect-based sentiment analysis (MABSA) aims to identify aspect-level sentiments by jointly modeling textual and visual information, which is essential for fine-grained opinion understanding in social media. Existing approaches mainly rely on discriminative classification with complex multimodal fusion, yet lacking explicit sentiment explainability. In this paper, we reformulate MABSA as a generative and explainable task, proposing a unified framework that simultaneously predicts aspect-level sentiment and generates natural language explanations. Based on multimodal large language models (MLLMs), our approach employs a prompt-based generative paradigm, jointly producing sentiment and explanation. To further enhance aspect-oriented reasoning capabilities, we propose a dependency-syntax-guided sentiment cue strategy. This strategy prunes and textualizes the aspect-centered dependency syntax tree, guiding the model to distinguish different sentiment aspects and enhancing its explainability. To enable explainability, we use MLLMs to construct new datasets with sentiment explanations to fine-tune. Experiments show that our approach not only achieves consistent gains in sentiment classification accuracy, but also produces faithful, aspect-grounded explanations.

</details>


### [203] [†DAGGER: Distractor-Aware Graph Generation for Executable Reasoning in Math Problems](https://arxiv.org/abs/2601.06853)
*Zabir Al Nazi,Shubhashis Roy Dipta,Sudipta Kar*

Main category: cs.CL

TL;DR: 该论文研究了在数学问题求解中，当前主流Chain-of-Thought（CoT）提示方法对无关信息（干扰项）的鲁棒性问题，并提出了一种新方法提高模型表现。


<details>
  <summary>Details</summary>
Motivation: 虽然CoT提示在各语种的数学问题求解中已被广泛采用，但其在包含无关干扰信息时的表现尚不清楚。特别是在低资源语言环境下，评估和提升模型对干扰项的鲁棒性具有重要意义。

Method: 作者构建了DISTRACTMATH-BN基准，面向孟加拉语，将数学题数据集（MGSM、MSVAMP）加入意味相关但算术无关的干扰信息，系统性测试7个模型。提出新的DAGGER方法，将求解过程转化为可执行的计算图，并显式建模干扰节点。

Result: 标准模型在加入干扰信息后性能大幅下降（最高降41分），即便是专门优化推理能力的模型也下降14-20分。DAGGER方法下，经过精细调整的模型在消耗更少token的情况下取得了与推理专用模型相当的表现和更高的鲁棒性。

Conclusion: 采用结构化的中间表示（计算图）可以显著提升模型在数学推理任务中的鲁棒性和推理效率，特别适用于低资源、含噪环境。

Abstract: Chain-of-Thought (CoT) prompting is widely adopted for mathematical problem solving, including in low-resource languages, yet its behavior under irrelevant context remains underexplored. To systematically study this challenge, we introduce DISTRACTMATH-BN, a Bangla benchmark that augments MGSM and MSVAMP with semantically coherent but computationally irrelevant information. Evaluating seven models ranging from 3B to 12B parameters, we observe substantial performance degradation under distractors: standard models drop by up to 41 points, while reasoning-specialized models decline by 14 to 20 points despite consuming five times more tokens. We propose †DAGGER, which reformulates mathematical problem solving as executable computational graph generation with explicit modeling of distractor nodes. Fine-tuning Gemma-3 models using supervised fine-tuning followed by Group Relative Policy Optimization achieves comparable weighted accuracy on augmented benchmarks while using 89 percent fewer tokens than reasoning models. Importantly, this robustness emerges without explicit training on distractor-augmented examples. Our results suggest that enforcing structured intermediate representations improves robustness and inference efficiency in mathematical reasoning compared to free-form approaches, particularly in noisy, low-resource settings.

</details>


### [204] [BiasLab: A Multilingual, Dual-Framing Framework for Robust Measurement of Output-Level Bias in Large Language Models](https://arxiv.org/abs/2601.06861)
*William Guey,Wei Zhang,Pei-Luen Patrick Rau,Pierrick Bougault,Vitor D. de Moura,Bertan Ucar,Jose O. Gomes*

Main category: cs.CL

TL;DR: 本文提出了BiasLab，一个用于多语言及鲁棒性导向的LLM输出偏见评估的新平台，旨在提供标准化、可复现的跨模型偏见比较方法。


<details>
  <summary>Details</summary>
Motivation: 当前大模型在实际高风险场景中应用广泛，但其输出的偏见评估因提示词敏感、多语言覆盖有限、缺乏统一评估标准等原因存在困难，因此亟需一种通用、可靠的新方法。

Method: BiasLab通过“镜像探针对”设计，将同一问题分别以正向和逆向叙述对待不同目标群体，保证语法结构一致性，并在不同随机化指令下多次评测。采用固定格式的Likert量表收集答案，再用LLM判定答案极性并标准化结果，最终通过量化统计指标展现偏见水平。实验支持多种偏见类型，并输出可复现的报告和可视化结果。

Result: BiasLab能够跨多语言、多主题对各种LLM进行系统偏见对比，生成结构化、量化且可复现的报告，并提升评测鲁棒性及结果的客观性。

Conclusion: BiasLab为LLM的跨语言、对提示词敏感的输出偏见评估提供了可靠、标准化的方法，能为学界及业界进行模型部署前的风险及公正性评估提供有力工具，补充现有的偏见审计方法。

Abstract: Large Language Models (LLMs) are increasingly deployed in high-stakes contexts where their outputs influence real-world decisions. However, evaluating bias in LLM outputs remains methodologically challenging due to sensitivity to prompt wording, limited multilingual coverage, and the lack of standardized metrics that enable reliable comparison across models. This paper introduces BiasLab, an open-source, model-agnostic evaluation framework for quantifying output-level (extrinsic) bias through a multilingual, robustness-oriented experimental design. BiasLab constructs mirrored probe pairs under a strict dual-framing scheme: an affirmative assertion favoring Target A and a reverse assertion obtained by deterministic target substitution favoring Target B, while preserving identical linguistic structure. To reduce dependence on prompt templates, BiasLab performs repeated evaluation under randomized instructional wrappers and enforces a fixed-choice Likert response format to maximize comparability across models and languages. Responses are normalized into agreement labels using an LLM-based judge, aligned for polarity consistency across framings, and aggregated into quantitative bias indicators with descriptive statistics including effect sizes and neutrality rates. The framework supports evaluation across diverse bias axes, including demographic, cultural, political, and geopolitical topics, and produces reproducible artifacts such as structured reports and comparative visualizations. BiasLab contributes a standardized methodology for cross-lingual and framing-sensitive bias measurement that complements intrinsic and dataset-based audits, enabling researchers and institutions to benchmark robustness and make better-informed deployment decisions.

</details>


### [205] [Paraphrasing Adversarial Attack on LLM-as-a-Reviewer](https://arxiv.org/abs/2601.06884)
*Masahiro Kaneko*

Main category: cs.CL

TL;DR: 本论文提出了一种称为“释义对抗攻击（PAA）”的新方法，能够在保持原文语义和自然性的前提下，通过改变论文表达方式提高大语言模型（LLM）在同行评审系统中的评分。实验表明，这种方法有效且难以被察觉。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在同行评审系统中的使用增多，人们担心这些模型可能存在被恶意操纵的漏洞，尤其是以往基于提示注入的攻击方式，经常引入评估稳健性的混淆。因此需要新的、更隐蔽的攻击方式以检验现有同行评审的安全性。

Method: 作者提出了一种“释义对抗攻击”（PAA），这是一种黑盒优化方法，利用上下文学习，通过不断生成和评分释义版本，在不改变原意的前提下寻找能够诱导LLM给出更高评分的表达方式。该方法结合了多种LLM和攻击模型，在不同学术会议评审数据集上进行了实验。

Result: 实验结果显示，PAA攻击能够一致性地提升被评论文的评分，而且释义后的论文在语义和自然性方面仍能被人类评审认可。同时，攻击论文的评审困惑度有所增加，可以作为检测线索；而主动对论文进行释义能在一定程度上减缓这种攻击。

Conclusion: 在LLM同行评审系统下，释义对抗攻击表现出比以往方法更隐蔽和有效的得分提升能力，现有评审机制面临新的攻击挑战。困惑度升高可能有助于检测此类攻击，同时自动释义可作为一定的防御手段。

Abstract: The use of large language models (LLMs) in peer review systems has attracted growing attention, making it essential to examine their potential vulnerabilities. Prior attacks rely on prompt injection, which alters manuscript content and conflates injection susceptibility with evaluation robustness. We propose the Paraphrasing Adversarial Attack (PAA), a black-box optimization method that searches for paraphrased sequences yielding higher review scores while preserving semantic equivalence and linguistic naturalness. PAA leverages in-context learning, using previous paraphrases and their scores to guide candidate generation. Experiments across five ML and NLP conferences with three LLM reviewers and five attacking models show that PAA consistently increases review scores without changing the paper's claims. Human evaluation confirms that generated paraphrases maintain meaning and naturalness. We also find that attacked papers exhibit increased perplexity in reviews, offering a potential detection signal, and that paraphrasing submissions can partially mitigate attacks.

</details>


### [206] [Fine-grained Verbal Attack Detection via a Hierarchical Divide-and-Conquer Framework](https://arxiv.org/abs/2601.06907)
*Quan Zheng,Yuanhe Tian,Ming Wang,Yan Song*

Main category: cs.CL

TL;DR: 本文提出了一个新的“分层攻击评论检测”数据集，并基于时空信息构建了细粒度分而治之的攻击识别框架，对多轮中文社交媒体评论中的语言攻击进行有效检测。


<details>
  <summary>Details</summary>
Motivation: 现有网络攻击检测方法在建模对话结构和上下文关系上存在不足，特别是在中文社交媒体中隐性攻击频繁，导致隐性与依赖上下文的攻击难以识别。此研究旨在弥补这一空白，提升攻击检测的准确性和细致性。

Method: 作者构建了一个能够显式编码回复层级结构和时序信息的新数据集，并提出分解攻击检测为分层子任务的新框架。该框架利用轻量化模型分别处理显性攻击检测、隐性意图推断和受害目标识别，各模型在有限上下文下协同工作。

Result: 大量实验表明，采用该细粒度分层框架的小模型，在本文提出的数据集及意图检测基准数据集上的表现，显著优于仅通过扩大参数规模的单一大模型。

Conclusion: 结构化、分层任务分解和充分利用对话时空结构，可以提升攻击检测的准确性和效率，为后续研究提供了行之有效的解决方案。

Abstract: In the digital era, effective identification and analysis of verbal attacks are essential for maintaining online civility and ensuring social security. However, existing research is limited by insufficient modeling of conversational structure and contextual dependency, particularly in Chinese social media where implicit attacks are prevalent. Current attack detection studies often emphasize general semantic understanding while overlooking user response relationships, hindering the identification of implicit and context-dependent attacks. To address these challenges, we present the novel "Hierarchical Attack Comment Detection" dataset and propose a divide-and-conquer, fine-grained framework for verbal attack recognition based on spatiotemporal information. The proposed dataset explicitly encodes hierarchical reply structures and chronological order, capturing complex interaction patterns in multi-turn discussions. Building on this dataset, the framework decomposes attack detection into hierarchical subtasks, where specialized lightweight models handle explicit detection, implicit intent inference, and target identification under constrained context. Extensive experiments on the proposed dataset and benchmark intention detection datasets show that smaller models using our framework significantly outperform larger monolithic models relying on parameter scaling, demonstrating the effectiveness of structured task decomposition.

</details>


### [207] [Distributional Clarity: The Hidden Driver of RL-Friendliness in Large Language Models](https://arxiv.org/abs/2601.06911)
*Shaoning Sun,Mingzhu Cai,Huang He,Bingjin Chen,Siqi Bao,Yujiu Yang,Hua Wu,Haifeng Wang*

Main category: cs.CL

TL;DR: 本文发现大语言模型家族在强化学习（RL）中表现出不同的提升能力，这种能力与概率分布空间中的结构属性——分布清晰度紧密相关，并提出了衡量指标及新的训练方法以提升所有模型在RL中的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管使用相同的RL训练方法，不同语言模型（如Qwen与Llama）获得的性能提升存在显著差异。以往多关注数据或算法，但对于模型本身的结构属性缺乏系统分析。本文旨在揭示导致这种RL敏感性差别的内在机制。

Method: 通过三阶段分析（现象-机制-解释），作者提出'分布清晰度'概念，利用Silhouette Coefficient（$S$）衡量模型对正确与错误响应概率分布的类间分离和类内紧凑性，并发现在RL友好的模型中分布清晰度更高。进一步，作者提出Silhouette-Aware Reweighting训练策略，优先学习低$S$样本，验证其能提升多种模型的RL性能。

Result: 实验证明分布清晰度指标$S$与模型RL提升高度相关，低$S$样本易出现逻辑和推理错误。新训练策略在六个数学基准测试集上为所有模型带来一致提升，最高提升5.9分。

Conclusion: 分布清晰度是影响模型RL友好性的核心可训练属性，通过关注和优化该特征可以显著提升各种语言模型在RL任务中的表现。

Abstract: Language model families exhibit striking disparity in their capacity to benefit from reinforcement learning: under identical training, models like Qwen achieve substantial gains, while others like Llama yield limited improvements. Complementing data-centric approaches, we reveal that this disparity reflects a hidden structural property: \textbf{distributional clarity} in probability space. Through a three-stage analysis-from phenomenon to mechanism to interpretation-we uncover that RL-friendly models exhibit intra-class compactness and inter-class separation in their probability assignments to correct vs. incorrect responses. We quantify this clarity using the \textbf{Silhouette Coefficient} ($S$) and demonstrate that (1) high $S$ correlates strongly with RL performance; (2) low $S$ is associated with severe logic errors and reasoning instability. To confirm this property, we introduce a Silhouette-Aware Reweighting strategy that prioritizes low-$S$ samples during training. Experiments across six mathematical benchmarks show consistent improvements across all model families, with gains up to 5.9 points on AIME24. Our work establishes distributional clarity as a fundamental, trainable property underlying RL-Friendliness.

</details>


### [208] [TreePS-RAG: Tree-based Process Supervision for Reinforcement Learning in Agentic RAG](https://arxiv.org/abs/2601.06922)
*Tianhua Zhang,Kun Li,Junan Li,Yunxiang Li,Hongyin Luo,Xixin Wu,James Glass,Helen Meng*

Main category: cs.CL

TL;DR: 本文提出了一种名为TreePS-RAG的树结构在线强化学习框架，用于提升Agentic RAG在多步推理问答任务中的表现。该框架避免了对中间标签或复杂过程监督的依赖，实现了细粒度的逐步奖励分配，实验结果显著优于现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的Agentic RAG多依赖最终结果奖励，无法精准指导中间推理和搜索步骤，导致奖励分配稀疏且中间过程学习效果有限，而已有过程级监督方法存在数据分布偏移或高昂标注代价。

Method: TreePS-RAG方法将多步推理过程建模为树结构，其中每个推理步骤对应树的一个节点，通过对节点后代结果进行蒙特卡洛估计，实现更细致的逐步奖励分配。同时，提出高效的在线树构建策略，在有限计算资源下保证推理多样性。

Result: 在七个多跳及通用问答基准上的实验显示，TreePS-RAG以与强基线（如Search-R1）可比的计算代价，实现了对仅结果监督和先进过程级强化学习方法的显著超越，不论模型规模如何均保持领先。

Conclusion: TreePS-RAG有效地解决了多步问答中奖赏传递稀疏和过程带宽不足的问题，无需依赖额外中间标签，以高效树结构提升了推理精度，为Agentic RAG进一步发展提供了新思路。

Abstract: Agentic retrieval-augmented generation (RAG) formulates question answering as a multi-step interaction between reasoning and information retrieval, and has recently been advanced by reinforcement learning (RL) with outcome-based supervision. While effective, relying solely on sparse final rewards limits step-wise credit assignment and provides weak guidance for intermediate reasoning and actions. Recent efforts explore process-level supervision, but typically depend on offline constructed training data, which risks distribution shift, or require costly intermediate annotations. We present TreePS-RAG, an online, tree-based RL framework for agentic RAG that enables step-wise credit assignment while retaining standard outcome-only rewards. Our key insight is to model agentic RAG reasoning as a rollout tree, where each reasoning step naturally maps to a node. This tree structure allows step utility to be estimated via Monte Carlo estimation over its descendant outcomes, yielding fine-grained process advantages without requiring intermediate labels. To make this paradigm practical, we introduce an efficient online tree construction strategy that preserves exploration diversity under a constrained computational budget. With a rollout cost comparable to strong baselines like Search-R1, experiments on seven multi-hop and general QA benchmarks across multiple model scales show that TreePS-RAG consistently and significantly outperforms both outcome-supervised and leading process-supervised RL methods.

</details>


### [209] [Symphonym: Universal Phonetic Embeddings for Cross-Script Toponym Matching via Teacher-Student Distillation](https://arxiv.org/abs/2601.06932)
*Stephen Gadd*

Main category: cs.CL

TL;DR: 本论文提出Symphonym，一个可将20种文字系统的地名映射到统一的128维音素空间的神经嵌入系统，实现跨语种、跨文字地名的对齐。


<details>
  <summary>Details</summary>
Motivation: 现有地名匹配方法依赖语言特定的音素算法或音译规则，在跨文字系统情况下（如俄语、西里尔字母与阿拉伯字母）往往失效，提升全球范围内地名对齐和搜索效果需求迫切。

Method: 提出Symphonym框架：通过教师网络（由音系特征训练输出目标嵌入）和学生网络（从字符原始表示逼近教师输出）。训练采用三阶段课程学习，数据量巨大，并专门设计了困难负样本以提高判别力。推理阶段仅需轻量学生网络，无需实时音素转换。

Result: 在MEHDIE希伯来语-阿拉伯语基准上Recall@1达到89.2%，超过传统拼写距离方法。系统对跨文字匹配尤为优化，并对67百万地名的历史地名库具备实际应用价值。

Conclusion: Symphonym显著提升了跨语种、跨文字地名的音素匹配和搜索能力，代码与模型已开源，便于实际部署和进一步研究。

Abstract: Linking place names across languages and writing systems is a fundamental challenge in digital humanities and geographic information retrieval. Existing approaches rely on language-specific phonetic algorithms or transliteration rules that fail when names cross script boundaries -- no string metric can determine that "Moscow" when rendered in Cyrillic or Arabic refer to the same city.
  I present Symphonym, a neural embedding system that maps toponyms from 20 writing systems into a unified 128-dimensional phonetic space. A Teacher network trained on articulatory phonetic features (via Epitran and PanPhon) produces target embeddings, while a Student network learns to approximate these from raw characters. At inference, only the lightweight Student (1.7M parameters) is required, enabling deployment without runtime phonetic conversion.
  Training uses a three-phase curriculum on 57 million toponyms from GeoNames, Wikidata, and the Getty Thesaurus of Geographic Names. Phase 1 trains the Teacher on 467K phonetically-grounded triplets. Phase 2 aligns the Student to Teacher outputs across 23M samples, achieving 96.6% cosine similarity. Phase 3 fine-tunes on 3.3M hard negative triplets -- negatives sharing prefix and script with the anchor but referring to different places -- to sharpen discrimination.
  Evaluation on the MEHDIE Hebrew-Arabic benchmark achieves 89.2% Recall@1, outperforming Levenshtein (81.5%) and Jaro-Winkler (78.5%). The system is optimised for cross-script matching; same-script variants can be handled by complementary string methods. Symphonym will enable fuzzy phonetic reconciliation and search across the World Historical Gazetteer's 67 million toponyms. Code and models are publicly available.

</details>


### [210] [X-Coder: Advancing Competitive Programming with Fully Synthetic Tasks, Solutions, and Tests](https://arxiv.org/abs/2601.06953)
*Jie Wu,Haoling Li,Xin Zhang,Jiani Guo,Jane Luo,Steven Liu,Yangyu Huang,Ruihang Chu,Scarlett Li,Yujiu Yang*

Main category: cs.CL

TL;DR: 本论文提出了一种完全依赖合成数据训练代码大模型的方法，通过生成任务、解答与测试用例，绕过真实世界数据的依赖，取得了与主流模型相当甚至更优的编程推理表现。


<details>
  <summary>Details</summary>
Motivation: 当前主流代码大模型严重依赖真实世界数据，导致其可扩展性受限，且难以适用于推理复杂、逻辑密集的竞赛编程任务。因此，作者希望突破数据依赖瓶颈，探索用全合成数据支持代码推理的可行性。

Method: 作者设计了名为SynthSmith的数据合成管道，基于特征合成自动生成多样、难度高且自带验证的编程任务及解答，用于监督微调与强化学习训练。并推出了X-Coder模型系列，专以合成数据训练，并对比同参数量主流模型进行了实测评估和详细消融分析。

Result: X-Coder模型系列在LiveCodeBench v5和v6上分别达到62.9和55.8的avg@8通过率，超过DeepCoder-14B-Preview和AReal-boba2-14B等参数体量更大的模型。实验还揭示了合成数据上的scale规律与哪些规模维度更有效。

Conclusion: 高质量、可扩展的合成数据以及分阶段训练策略，能显著提升代码推理能力，并减少对真实编程数据的依赖，为代码大模型发展带来新方向。

Abstract: Competitive programming presents great challenges for Code LLMs due to its intensive reasoning demands and high logical complexity. However, current Code LLMs still rely heavily on real-world data, which limits their scalability. In this paper, we explore a fully synthetic approach: training Code LLMs with entirely generated tasks, solutions, and test cases, to empower code reasoning models without relying on real-world data. To support this, we leverage feature-based synthesis to propose a novel data synthesis pipeline called SynthSmith. SynthSmith shows strong potential in producing diverse and challenging tasks, along with verified solutions and tests, supporting both supervised fine-tuning and reinforcement learning. Based on the proposed synthetic SFT and RL datasets, we introduce the X-Coder model series, which achieves a notable pass rate of 62.9 avg@8 on LiveCodeBench v5 and 55.8 on v6, outperforming DeepCoder-14B-Preview and AReal-boba2-14B despite having only 7B parameters. In-depth analysis reveals that scaling laws hold on our synthetic dataset, and we explore which dimensions are more effective to scale. We further provide insights into code-centric reinforcement learning and highlight the key factors that shape performance through detailed ablations and analysis. Our findings demonstrate that scaling high-quality synthetic data and adopting staged training can greatly advance code reasoning, while mitigating reliance on real-world coding data.

</details>


### [211] [RealMem: Benchmarking LLMs in Real-World Memory-Driven Interaction](https://arxiv.org/abs/2601.06966)
*Haonan Bian,Zhiyuan Yao,Sen Hu,Zishan Xu,Shaolei Zhang,Yifu Guo,Ziliang Yang,Xueran Han,Huacan Wang,Ronghao Chen*

Main category: cs.CL

TL;DR: 论文针对大语言模型在项目长期记忆中的表现提出评测基准RealMem，发现现有记忆系统在复杂动态项目任务中表现有限。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型向自主通用智能体发展，研究者发现对长期一致性的有效记忆变得越来越重要，但现有评测主要关注闲聊或单次任务，无法反映真实项目中的长期目标追踪与记忆需求。

Method: 提出了RealMem基准，涵盖2000余个跨会话真实项目场景对话，模拟长周期、目标动态变化情景，并设计生成流水线集成项目基础构建、多智能体对话、记忆与计划管理各环节，实现复杂的动态记忆演化仿真。

Result: 通过实验证明，目前的记忆系统在真实项目中的长期状态管理与动态上下文依赖性处理上存在明显短板。

Conclusion: RealMem为评测和改进大模型长期记忆机制提供了更具挑战性和现实意义的基准，为未来长周期智能体任务能力的提升指明方向。

Abstract: As Large Language Models (LLMs) evolve from static dialogue interfaces to autonomous general agents, effective memory is paramount to ensuring long-term consistency. However, existing benchmarks primarily focus on casual conversation or task-oriented dialogue, failing to capture **"long-term project-oriented"** interactions where agents must track evolving goals.
  To bridge this gap, we introduce **RealMem**, the first benchmark grounded in realistic project scenarios. RealMem comprises over 2,000 cross-session dialogues across eleven scenarios, utilizing natural user queries for evaluation.
  We propose a synthesis pipeline that integrates Project Foundation Construction, Multi-Agent Dialogue Generation, and Memory and Schedule Management to simulate the dynamic evolution of memory. Experiments reveal that current memory systems face significant challenges in managing the long-term project states and dynamic context dependencies inherent in real-world projects.
  Our code and datasets are available at [https://github.com/AvatarMemory/RealMemBench](https://github.com/AvatarMemory/RealMemBench).

</details>


### [212] [Categorize Early, Integrate Late: Divergent Processing Strategies in Automatic Speech Recognition](https://arxiv.org/abs/2601.06972)
*Nathan Roll,Pranav Bhalerao,Martijn Bartelds,Arjun Pawar,Yuka Tatsumi,Tolulope Ogunremi,Chen Shani,Calbert Graham,Meghan Sumner,Dan Jurafsky*

Main category: cs.CL

TL;DR: 本文提出了一种新的分析框架Architectural Fingerprinting，对比了Transformer和Conformer架构在语音建模任务中的表示与处理机制，发现二者存在本质上的分层差异。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer和Conformer在语音模型上性能相近，但尚不清楚其过程处理机制是趋同的还是各具特点，因此需要一种方法来探查其内部表示和处理策略。

Method: 提出Architectural Fingerprinting探针框架，针对24个参数规模从39M到3.3B的预训练语音编码器，系统分析其内部表示随深度演化的层级结构。

Result: Conformer倾向于“早分类”，能在浅层较早分辨音素和说话人性别（分别早29%、16%深度），而Transformer将音素、口音时长等编码推迟到更深层（49-57%深度）。

Conclusion: Conformer适合需要低延迟的流式应用（因早期分类），而Transformer则适合需要丰富上下文和跨语句归一化的任务（因深层整合）。

Abstract: In speech language modeling, two architectures dominate the frontier: the Transformer and the Conformer. However, it remains unknown whether their comparable performance stems from convergent processing strategies or distinct architectural inductive biases. We introduce Architectural Fingerprinting, a probing framework that isolates the effect of architecture on representation, and apply it to a controlled suite of 24 pre-trained encoders (39M-3.3B parameters). Our analysis reveals divergent hierarchies: Conformers implement a "Categorize Early" strategy, resolving phoneme categories 29% earlier in depth and speaker gender by 16% depth. In contrast, Transformers "Integrate Late," deferring phoneme, accent, and duration encoding to deep layers (49-57%). These fingerprints suggest design heuristics: Conformers' front-loaded categorization may benefit low-latency streaming, while Transformers' deep integration may favor tasks requiring rich context and cross-utterance normalization.

</details>


### [213] [LLMs Can't Play Hangman: On the Necessity of a Private Working Memory for Language Agents](https://arxiv.org/abs/2601.06973)
*Davide Baldelli,Ali Parviz,Amal Zouaq,Sarath Chandar*

Main category: cs.CL

TL;DR: 本文提出并验证了当前基于对话界面的LLM在需要隐私状态维持的交互任务中存在理论和实践上的局限，并提出了带有私有工作记忆的新架构进行改进。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型主要通过公开的对话历史进行记忆和交互，缺乏“隐私工作记忆”，因此无法在涉及隐藏状态的交互式任务中保证信息私密性和响应一致性。作者希望明确并克服这一局限。

Method: 1）提出并形式化定义了Private State Interactive Tasks (PSITs)；2）给出了理论上的“不可能性定理”，证明仅利用对话历史无法兼顾一致性和隐私；3）设计了一种自洽性测试协议，通过测试分支对话中隐藏信息的维持能力，对比主流模型和检索式记忆方案的表现；4）提出包含私有工作记忆的全新交互架构。

Result: 理论上证明基于公开对话历史的代理无法解决PSITs。实验证明，无论模型规模和检索策略如何，主流聊天模型和记忆检索方案在自洽性测试中均失败。新架构通过引入私有记忆，恢复了状态一致性。

Conclusion: 仅有检索式记忆和对话历史不足以支撑有隐私状态需求的LLM交互任务，私有工作记忆是构建强健自主语言代理的关键模块。

Abstract: As LLMs move from text completion toward autonomous agents, they remain constrained by the standard chat interface, which lacks private working memory. This raises a fundamental question: can agents reliably perform interactive tasks that depend on hidden state? We define Private State Interactive Tasks (PSITs), which require agents to generate and maintain hidden information while producing consistent public responses. We show theoretically that any agent restricted to the public conversation history cannot simultaneously preserve secrecy and consistency in PSITs, yielding an impossibility theorem. To empirically validate this limitation, we introduce a self-consistency testing protocol that evaluates whether agents can maintain a hidden secret across forked dialogue branches. Standard chat-based LLMs and retrieval-based memory baselines fail this test regardless of scale, demonstrating that semantic retrieval does not enable true state maintenance. To address this, we propose a novel architecture incorporating an explicit private working memory; we demonstrate that this mechanism restores consistency, establishing private state as a necessary component for interactive language agents.

</details>


### [214] [UETQuintet at BioCreative IX - MedHopQA: Enhancing Biomedical QA with Selective Multi-hop Reasoning and Contextual Retrieval](https://arxiv.org/abs/2601.06974)
*Quoc-An Nguyen,Thi-Minh-Thu Vu,Bich-Dat Nguyen,Dinh-Quang-Minh Tran,Hoang-Quynh Le*

Main category: cs.CL

TL;DR: 本文提出了一种能同时处理直接与多跳医学问答的模型，并在BioCreative IX - MedHopQA数据集上获得了第二名的成绩。


<details>
  <summary>Details</summary>
Motivation: 现有生物医学问答系统在应对多步推理和复杂医学数据方面存在挑战，因此需要新的方法来提升其在处理直接和多跳问题时的效果。

Method: 针对直接问题，模型直接处理以保证效率；针对序列性问题，则将其分解为子问题，进行多步推理。此外，方法结合多源信息检索和in-context learning，增强回答内容的丰富性和相关性。

Result: 在BioCreative IX - MedHopQA问答任务数据集上的评测中，该方法的准确匹配（Exact Match）分数为0.84，目前排行第二。

Conclusion: 提出的模型能够有效应对生物医学问答场景中的复杂推理和信息整合需求，对推进医学研究和实际应用具有积极意义。

Abstract: Biomedical Question Answering systems play a critical role in processing complex medical queries, yet they often struggle with the intricate nature of medical data and the demand for multi-hop reasoning. In this paper, we propose a model designed to effectively address both direct and sequential questions. While sequential questions are decomposed into a chain of sub-questions to perform reasoning across a chain of steps, direct questions are processed directly to ensure efficiency and minimise processing overhead. Additionally, we leverage multi-source information retrieval and in-context learning to provide rich, relevant context for generating answers. We evaluated our model on the BioCreative IX - MedHopQA Shared Task datasets. Our approach achieves an Exact Match score of 0.84, ranking second on the current leaderboard. These results highlight the model's capability to meet the challenges of Biomedical Question Answering, offering a versatile solution for advancing medical research and practice.

</details>


### [215] [MedTutor: A Retrieval-Augmented LLM System for Case-Based Medical Education](https://arxiv.org/abs/2601.06979)
*Dongsuk Jang,Ziyao Shangguan,Kyle Tegtmeyer,Anurag Gupta,Jan Czerminski,Sophie Chheang,Arman Cohan*

Main category: cs.CL

TL;DR: 本论文提出MedTutor系统，通过自动从临床病例报告中生成有证据支持的教学内容和选择题，辅助住院医生学习，提高学习效率。


<details>
  <summary>Details</summary>
Motivation: 住院医生需要高效理解复杂病例报告，并快速从可靠来源获得医学知识，但查找相关材料和证据通常耗时且困难。

Method: 提出MedTutor系统，采用RAG（检索增强生成）管线。其混合检索模块结合本地图书知识库与最新学术文献（通过PubMed、Semantic Scholar等API），结果经重排序与大模型生成最终教学内容及题目。

Result: 经过严格评测，三位放射科医生认为生成内容具有较高的临床与教学价值。利用LLM自动评价系统输出的质量，并与专家判断相关性分析，发现中度一致性，但仍需专家监督。

Conclusion: MedTutor在提升医学住院医生的教学内容生成方面有效，结合大模型可辅助自动评估，但完全取代专家还不可行，需持续监督。

Abstract: The learning process for medical residents presents significant challenges, demanding both the ability to interpret complex case reports and the rapid acquisition of accurate medical knowledge from reliable sources. Residents typically study case reports and engage in discussions with peers and mentors, but finding relevant educational materials and evidence to support their learning from these cases is often time-consuming and challenging. To address this, we introduce MedTutor, a novel system designed to augment resident training by automatically generating evidence-based educational content and multiple-choice questions from clinical case reports. MedTutor leverages a Retrieval-Augmented Generation (RAG) pipeline that takes clinical case reports as input and produces targeted educational materials. The system's architecture features a hybrid retrieval mechanism that synergistically queries a local knowledge base of medical textbooks and academic literature (using PubMed, Semantic Scholar APIs) for the latest related research, ensuring the generated content is both foundationally sound and current. The retrieved evidence is filtered and ordered using a state-of-the-art reranking model and then an LLM generates the final long-form output describing the main educational content regarding the case-report. We conduct a rigorous evaluation of the system. First, three radiologists assessed the quality of outputs, finding them to be of high clinical and educational value. Second, we perform a large scale evaluation using an LLM-as-a Judge to understand if LLMs can be used to evaluate the output of the system. Our analysis using correlation between LLMs outputs and human expert judgments reveals a moderate alignment and highlights the continued necessity of expert oversight.

</details>


### [216] [Lexicalized Constituency Parsing for Middle Dutch: Low-resource Training and Cross-Domain Generalization](https://arxiv.org/abs/2601.07008)
*Yiming Liang,Fang Zhao*

Main category: cs.CL

TL;DR: 本文将基于Transformer的成分句法分析器应用于中世纪荷兰语（一种低资源历史语言），并探索如何提升其在同域和跨域下的表现。联合训练与辅助高资源语言可提升F1分数，且神经网络分析器明显优于当前主流的基于概率上下文无关文法（PCFG）的分析器。


<details>
  <summary>Details</summary>
Motivation: 目前神经网络和上下文化词表示在历史语言句法分析中应用热度增加，但绝大多数进展集中在依存句法分析，低资源历史语言的成分句法分析却缺乏关注；中世纪荷兰语领域尤其如此。本文旨在弥补该领域的研究空白。

Method: 采用Transformer架构的成分句法分析器，针对中世纪荷兰语进行适配。通过联合训练与地理和时间上接近的高资源辅助语言，并尝试多种新加标注数据的利用策略（如微调和数据合并），同时采用特征分离技术做领域自适应。不同数据量的门槛实验以探索跨域能力提升的关键。

Result: 1. 辅助语言联合训练最多提升F1分数0.73，地理和时间上越接近提升越大；2. 微调和数据合并对跨域数据的利用提升相当；3. 神经分析器全面超越传统PCFG分析器；4. 域自适应时每个新域至少需要约200例标注数据才能取得实际效果。

Conclusion: Transformer神经成分分析器在中世纪荷兰语成分句法分析中表现优越，辅助高资源语言、适量新域数据和特征分离技术能有效提升同域与跨域表现，为低资源历史语言的句法分析提供了有效方法。

Abstract: Recent years have seen growing interest in applying neural networks and contextualized word embeddings to the parsing of historical languages. However, most advances have focused on dependency parsing, while constituency parsing for low-resource historical languages like Middle Dutch has received little attention. In this paper, we adapt a transformer-based constituency parser to Middle Dutch, a highly heterogeneous and low-resource language, and investigate methods to improve both its in-domain and cross-domain performance. We show that joint training with higher-resource auxiliary languages increases F1 scores by up to 0.73, with the greatest gains achieved from languages that are geographically and temporally closer to Middle Dutch. We further evaluate strategies for leveraging newly annotated data from additional domains, finding that fine-tuning and data combination yield comparable improvements, and our neural parser consistently outperforms the currently used PCFG-based parser for Middle Dutch. We further explore feature-separation techniques for domain adaptation and demonstrate that a minimum threshold of approximately 200 examples per domain is needed to effectively enhance cross-domain performance.

</details>


### [217] [TurkBench: A Benchmark for Evaluating Turkish Large Language Models](https://arxiv.org/abs/2601.07020)
*Çağrı Toraman,Ahmet Kaan Sever,Ayse Aysu Cengiz,Elif Ecem Arslan,Görkem Sevinç,Mete Mert Birdal,Yusuf Faruk Güldemir,Ali Buğra Kanburoğlu,Sezen Felekoğlu,Osman Gürlek,Sarp Kantar,Birsen Şahin Kütük,Büşra Tufan,Elif Genç,Serkan Coşkun,Gupse Ekin Demir,Muhammed Emin Arayıcı,Olgun Dursun,Onur Gungor,Susan Üsküdarlı,Abdullah Topraksoy,Esra Darıcı*

Main category: cs.CL

TL;DR: 该论文介绍了TurkBench，这是一个用于评估大语言模型在土耳其语能力上的综合基准测试，以填补非英语语言模型评测工具的空白。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型大多以英语为主，其他语言（如土耳其语）的评测基准和资源相对缺乏，影响了多语言模型的发展和评估的全面性。该研究旨在为土耳其语模型的评测提供一个标准化工具。

Method: 作者构建了包含8,151个数据样本、涵盖21个子任务、分为六大类别（知识、语言理解、推理、内容审核、土耳其语语法与词汇、指令遵循）的TurkBench基准测试，并将其开放至huggingface供公众使用和提交模型成绩。

Result: TurkBench为研究者和开发者提供了多样、文化相关的土耳其语数据用于模型评估，揭示了模型在土耳其语多维能力上的优势与不足。

Conclusion: TurkBench有效弥补了土耳其语语言模型评测的空白，为多语言大模型的研发与改进提供了实际工具，推动了非英语语言AI技术的发展。

Abstract: With the recent surge in the development of large language models, the need for comprehensive and language-specific evaluation benchmarks has become critical. While significant progress has been made in evaluating English language models, benchmarks for other languages, particularly those with unique linguistic characteristics such as Turkish, remain less developed. Our study introduces TurkBench, a comprehensive benchmark designed to assess the capabilities of generative large language models in the Turkish language. TurkBench involves 8,151 data samples across 21 distinct subtasks. These are organized under six main categories of evaluation: Knowledge, Language Understanding, Reasoning, Content Moderation, Turkish Grammar and Vocabulary, and Instruction Following. The diverse range of tasks and the culturally relevant data would provide researchers and developers with a valuable tool for evaluating their models and identifying areas for improvement. We further publish our benchmark for online submissions at https://huggingface.co/turkbench

</details>


### [218] [Solar Open Technical Report](https://arxiv.org/abs/2601.07022)
*Sungrae Park,Sanghoon Kim,Jungho Cho,Gyoungjin Gim,Dawoon Jung,Mikyoung Cha,Eunhae Choo,Taekgyu Hong,Minbyul Jeong,SeHwan Joo,Minsoo Khang,Eunwon Kim,Minjeong Kim,Sujeong Kim,Yunsu Kim,Hyeonju Lee,Seunghyun Lee,Sukyung Lee,Siyoung Park,Gyungin Shin,Inseo Song,Wonho Song,Seonghoon Yang,Seungyoun Yi,Sanghoon Yoon,Jeonghyun Ko,Seyoung Song,Keunwoo Choi,Hwalsuk Lee,Sunghun Kim,Du-Seong Chang,Kyunghyun Cho,Junsuk Choe,Hwaran Lee,Jae-Gil Lee,KyungTae Lim,Alice Oh*

Main category: cs.CL

TL;DR: Solar Open提出了一种解决数据稀缺语言LLM构建挑战的系统方法，并取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 许多小语种资源稀缺，导致难以训练具有竞争力的大型语言模型。本文旨在通过系统设计，提高这类语言的AI能力，缩小主流与非主流语言间的差距。

Method: 1）合成4.5万亿高质量、领域相关且具有强化学习导向的数据；2）设计进阶式curriculum优化数据的组成、质量与覆盖面（总数据量20万亿）；3）提出SnapPO框架，实现大规模RL高效优化。

Result: Solar Open在英、韩两种语言的基准测试中表现出色，与现有模型具有竞争力。

Conclusion: 所提方法有效推动了资源稀缺语言的LLM开发，Solar Open为小语种大模型技术提供了有力支撑。

Abstract: We introduce Solar Open, a 102B-parameter bilingual Mixture-of-Experts language model for underserved languages. Solar Open demonstrates a systematic methodology for building competitive LLMs by addressing three interconnected challenges. First, to train effectively despite data scarcity for underserved languages, we synthesize 4.5T tokens of high-quality, domain-specific, and RL-oriented data. Second, we coordinate this data through a progressive curriculum jointly optimizing composition, quality thresholds, and domain coverage across 20 trillion tokens. Third, to enable reasoning capabilities through scalable RL, we apply our proposed framework SnapPO for efficient optimization. Across benchmarks in English and Korean, Solar Open achieves competitive performance, demonstrating the effectiveness of this methodology for underserved language AI development.

</details>


### [219] [Codified Foreshadowing-Payoff Text Generation](https://arxiv.org/abs/2601.07033)
*Longfei Yun,Kun Zhou,Yupeng Hou,Letian Peng,Jingbo Shang*

Main category: cs.CL

TL;DR: 本文提出了一个新的叙事生成评估与增强框架CFPG，可有效提升大语言模型在故事生成中的伏笔与回收能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在故事叙述上，常常能生成表面连贯的内容，但易出现伏笔未回收等结构性问题，缺乏对叙事承诺的合理兑现。现有评估偏重于表面连贯性，忽略了叙事结构中伏笔与回收的逻辑实现。本文旨在解决此类长距离叙事依赖的挑战。

Method: 作者提出Codified Foreshadowing-Payoff Generation (CFPG) 框架，将叙事连续性形式化为一组可执行的因果谓词。通过在BookSum语料库中挖掘并编码“伏笔-触发-回收”三元组，为模型提供结构化监督，保证伏笔既被提及且在时间和逻辑上得到实现。

Result: 实验表明，CFPG在伏笔回收的准确性与叙事一致性方面，明显优于常规提示式（prompting）基线方法。

Conclusion: 明确编码叙事机制，对提升大语言模型从表层流畅性到真实叙事能力至关重要。CFPG为后续自动故事生成提供了更具结构性的解决方案。

Abstract: Foreshadowing and payoff are ubiquitous narrative devices through which authors introduce commitments early in a story and resolve them through concrete, observable outcomes. However, despite advances in story generation, large language models (LLMs) frequently fail to bridge these long-range narrative dependencies, often leaving "Chekhov's guns" unfired even when the necessary context is present. Existing evaluations largely overlook this structural failure, focusing on surface-level coherence rather than the logical fulfillment of narrative setups. In this paper, we introduce Codified Foreshadowing-Payoff Generation (CFPG), a novel framework that reframes narrative quality through the lens of payoff realization. Recognizing that LLMs struggle to intuitively grasp the "triggering mechanism" of a foreshadowed event, CFPG transforms narrative continuity into a set of executable causal predicates. By mining and encoding Foreshadow-Trigger-Payoff triples from the BookSum corpus, we provide structured supervision that ensures foreshadowed commitments are not only mentioned but also temporally and logically fulfilled. Experiments demonstrate that CFPG significantly outperforms standard prompting baselines in payoff accuracy and narrative alignment. Our findings suggest that explicitly codifying narrative mechanics is essential for moving LLMs from surface-level fluency to genuine narrative competence.

</details>


### [220] [Mid-Think: Training-Free Intermediate-Budget Reasoning via Token-Level Triggers](https://arxiv.org/abs/2601.07036)
*Wang Yang,Debargha Ganguly,Xinpeng Li,Chaoda Song,Shouren Wang,Vikash Singh,Vipin Chaudhary,Xiaotian Han*

Main category: cs.CL

TL;DR: 该论文发现混合推理语言模型并非主要通过高层指令切换推理模式，而是受少量“触发词”如“Okay”及特殊换行模式的显著影响。据此，提出了一种名为Mid-Think的新型提示方法，可在准确率和长度之间取得更优权衡，并在推理推断和强化学习训练中均有效提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 当前混合推理语言模型常用显性指令（如Think/No-think）来调控推理行为，但实际模型响应往往效果有限，因此亟需深入探究模型推理行为的实际激活机制，并寻找更高效的控制方法。

Method: 通过注意力分析与受控提示实验，发现模型推理行为主要由先导词（如“Okay”）与特殊换行模式（如“</think>”后的换行）决定。在此基础上，提出Mid-Think提示格式，无需再训练，结合多种触发词，实现中等预算推理。

Result: Mid-Think在准确率-长度权衡上优于传统固定token或基于提示的对照模型。针对Qwen3-8B模型，Mid-Think将AIME基准测试准确率由69.8%提升至72.4%，GPQA由58.5%提升至61.1%，并且RL训练时间缩短约15%。

Conclusion: 该工作揭示了混合推理语言模型实际受触发词而非高层指令控制，并提出的Mid-Think方法可显著提升推理控制与训练效率，在推理推断及RL训练场景均表现优异。

Abstract: Hybrid reasoning language models are commonly controlled through high-level Think/No-think instructions to regulate reasoning behavior, yet we found that such mode switching is largely driven by a small set of trigger tokens rather than the instructions themselves. Through attention analysis and controlled prompting experiments, we show that a leading ``Okay'' token induces reasoning behavior, while the newline pattern following ``</think>'' suppresses it. Based on this observation, we propose Mid-Think, a simple training-free prompting format that combines these triggers to achieve intermediate-budget reasoning, consistently outperforming fixed-token and prompt-based baselines in terms of the accuracy-length trade-off. Furthermore, applying Mid-Think to RL training after SFT reduces training time by approximately 15% while improving final performance of Qwen3-8B on AIME from 69.8% to 72.4% and on GPQA from 58.5% to 61.1%, demonstrating its effectiveness for both inference-time control and RL-based reasoning training.

</details>


### [221] [Task Arithmetic with Support Languages for Low-Resource ASR](https://arxiv.org/abs/2601.07038)
*Emma Rafkin,Dan DeGenaro,Xiulin Yang*

Main category: cs.CL

TL;DR: 该论文提出了一种利用高资源语言提升低资源语言自动语音识别（ASR）性能的新方法，通过对Whisper ASR变体进行微调并线性组合任务向量，使低资源语言识别效果得到显著提升。


<details>
  <summary>Details</summary>
Motivation: 由于许多低资源语言缺乏可用数据，开发能在资源受限条件下工作的ASR方法受到关注。现有很多方法尝试利用与目标低资源语言密切相关的高资源语言数据以提升表现。

Method: 作者将对特定语言的训练视为一个“任务”，通过微调Whisper ASR系统获得任务向量，再对高、低资源语言的任务向量进行线性组合，根据低资源语言的验证集词错误率优化线性组合权重。

Result: 线性组合任务向量的方法在目标低资源语言的ASR任务上表现出一致性的提升。

Conclusion: 结合高、低资源语言的任务向量对低资源语言ASR具备实际提升效果，为提升低资源语言的语音识别能力提供了有效路径。

Abstract: The development of resource-constrained approaches to automatic speech recognition (ASR) is of great interest due to its broad applicability to many low-resource languages for which there is scant usable data. Existing approaches to many low-resource natural language processing tasks leverage additional data from higher-resource languages that are closely related to a target low-resource language. One increasingly popular approach uses task arithmetic to combine models trained on different tasks to create a model for a task where there is little to no training data. In this paper, we consider training on a particular language to be a task, and we generate task vectors by fine-tuning variants of the Whisper ASR system. For pairings of high- and low-resource languages, we merge task vectors via a linear combination, optimizing the weights of the linear combination on the downstream word error rate on the low-resource target language's validation set. We find that this approach consistently improves performance on the target languages.

</details>


### [222] [When Abundance Conceals Weakness: Knowledge Conflict in Multilingual Models](https://arxiv.org/abs/2601.07041)
*Jiaqi Zhao,Qiang Huang,Haodong Chen,Xiaoxing You,Jun Yu*

Main category: cs.CL

TL;DR: 该论文提出了CLEAR框架，系统地评估多语言大模型在面对跨语言知识冲突时的表现，并发现冲突解决方式随任务类型和语言资源变化。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型虽然具备多语言知识，但其内部知识随语言分布不均。一旦模型记忆与多语言外部证据矛盾（跨语言知识冲突），部分现象仍未被深入研究，尤其是在非英语环境下。论文旨在系统分析与评价多语言大模型处理这类冲突时的行为。

Method: 作者提出了CLEAR框架，将冲突解决过程分为四种递进式场景，结合两个具有代表性和不同任务特点的问答数据集（ConflictQA和ConflictingQA）构建了覆盖10种语言的新测试集，并对6个典型的多语言大语言模型进行了实验和评价。

Result: 实验发现，模型在依赖推理任务时，语言资源丰富度决定了冲突解决走向；资源丰富的语言有更强影响力。而在实体型事实冲突上，语言亲缘性而非资源量成为关键，资源较少但与目标语言亲近的语言可优于资源丰富且距离远的语言。

Conclusion: 论文指出多语种大模型的冲突解决行为会随任务类型和语言间关系（资源量、亲缘性）有显著变化，这为多语言场景下知识建模和模型设计提供了基础。

Abstract: Large Language Models (LLMs) encode vast world knowledge across multiple languages, yet their internal beliefs are often unevenly distributed across linguistic spaces. When external evidence contradicts these language-dependent memories, models encounter \emph{cross-lingual knowledge conflict}, a phenomenon largely unexplored beyond English-centric settings. We introduce \textbf{CLEAR}, a \textbf{C}ross-\textbf{L}ingual knowl\textbf{E}dge conflict ev\textbf{A}luation f\textbf{R}amework that systematically examines how multilingual LLMs reconcile conflicting internal beliefs and multilingual external evidence. CLEAR decomposes conflict resolution into four progressive scenarios, from multilingual parametric elicitation to competitive multi-source cross-lingual induction, and systematically evaluates model behavior across two complementary QA benchmarks with distinct task characteristics. We construct multilingual versions of ConflictQA and ConflictingQA covering 10 typologically diverse languages and evaluate six representative LLMs. Our experiments reveal a task-dependent decision dichotomy. In reasoning-intensive tasks, conflict resolution is dominated by language resource abundance, with high-resource languages exerting stronger persuasive power. In contrast, for entity-centric factual conflicts, linguistic affinity, not resource scale, becomes decisive, allowing low-resource but linguistically aligned languages to outperform distant high-resource ones.

</details>


### [223] [Engineering of Hallucination in Generative AI: It's not a Bug, it's a Feature](https://arxiv.org/abs/2601.07046)
*Tim Fingscheidt,Patrick Blumenberg,Björn Möller*

Main category: cs.CL

TL;DR: 本文讨论了生成式AI系统（如大型语言模型和视觉模型）在实际应用时，适当的“幻想”或虚构内容，即“幻觉”行为，反而可能有助于达成所需结果。作者提出通过概率工程技术适度诱导幻觉可能是生成式AI的一个有益特征。


<details>
  <summary>Details</summary>
Motivation: 虽然生成式AI（如ChatGPT或GAIA-1）被要求基于真实数据输出结果，但作者观察到这些模型在被允许有一定的幻觉时表现更佳。因此，作者希望探讨幻觉是否真的是缺陷，还是生成式AI独有的优势或功能。

Method: 作者回顾并介绍了一些概率工程的简单方法，用于适度地鼓励生成式AI系统出现幻觉（即不完全基于事实的创造性输出），以获得预期的结果。

Result: 幻觉并非总是负面的。适度的幻觉可以提升生成式AI系统的实用性与创造性，具体取决于应用场景。通过概率工程，用户能够有效引导AI在事实与创新之间取得平衡。

Conclusion: 适当引入和管理AI幻觉，也许是生成式AI的本质特征之一，而不是一个单纯的缺陷。对于很多任务，合理利用这种特性可能会带来更理想的结果。

Abstract: Generative artificial intelligence (AI) is conquering our lives at lightning speed. Large language models such as ChatGPT answer our questions or write texts for us, large computer vision models such as GAIA-1 generate videos on the basis of text descriptions or continue prompted videos. These neural network models are trained using large amounts of text or video data, strictly according to the real data employed in training. However, there is a surprising observation: When we use these models, they only function satisfactorily when they are allowed a certain degree of fantasy (hallucination). While hallucination usually has a negative connotation in generative AI - after all, ChatGPT is expected to give a fact-based answer! - this article recapitulates some simple means of probability engineering that can be used to encourage generative AI to hallucinate to a limited extent and thus lead to the desired results. We have to ask ourselves: Is hallucination in gen-erative AI probably not a bug, but rather a feature?

</details>


### [224] [Fine-Tuning vs. RAG for Multi-Hop Question Answering with Novel Knowledge](https://arxiv.org/abs/2601.07054)
*Zhuoyi Yang,Yurun Song,Iftekhar Ahmed,Ian Harris*

Main category: cs.CL

TL;DR: 本文系统性地比较了参数化与非参数化知识注入方法在多跳问答任务中的有效性，发现检索增强生成（RAG）和有监督微调相比无监督微调表现更佳，尤其在处理新颖知识时。


<details>
  <summary>Details</summary>
Motivation: 多跳问答能评估大模型推理和整合多元知识的能力，但目前不同知识注入方式（如微调、RAG）对于包含新颖知识的问题表现的有效性尚未明确。

Method: 作者在三个7B参数开源LLM上，针对QASC和2024年Wikipedia事件生成的新多跳问答集，分别测试了无监督微调（持续预训练）、有监督微调，以及检索增强生成三种知识注入机制，比较其多跳问答表现。

Result: 实验发现，无监督微调仅有有限提升，无法显著改善多跳推理效果；而RAG在需要应对新知识的问题上有显著、持续的提升；有监督微调在各模型和数据集上均获得最高准确率。

Conclusion: 不同知识注入方式对多跳问答的支持有本质区别，RAG对于需要外部或新颖知识的多跳问题尤为重要，持续预训练单独用处有限。

Abstract: Multi-hop question answering is widely used to evaluate the reasoning capabilities of large language models (LLMs), as it requires integrating multiple pieces of supporting knowledge to arrive at a correct answer. While prior work has explored different mechanisms for providing knowledge to LLMs, such as finetuning and retrieval-augmented generation (RAG), their relative effectiveness for multi-hop question answering remains insufficiently understood, particularly when the required knowledge is temporally novel.
  In this paper, we systematically compare parametric and non-parametric knowledge injection methods for open-domain multi-hop question answering. We evaluate unsupervised fine-tuning (continual pretraining), supervised fine-tuning, and retrieval-augmented generation across three 7B-parameter open-source LLMs. Experiments are conducted on two benchmarks: QASC, a standard multi-hop science question answering dataset, and a newly constructed dataset of over 10,000 multi-hop questions derived from Wikipedia events in 2024, designed to test knowledge beyond the models' pretraining cutoff.
  Our results show that unsupervised fine-tuning provides only limited gains over base models, suggesting that continual pretraining alone is insufficient for improving multi-hop reasoning accuracy. In contrast, retrieval-augmented generation yields substantial and consistent improvements, particularly when answering questions that rely on temporally novel information. Supervised fine-tuning achieves the highest overall accuracy across models and datasets. These findings highlight fundamental differences in how knowledge injection mechanisms support multi-hop question answering and underscore the importance of retrieval-based methods when external or compositional knowledge is required.

</details>


### [225] [The Need for a Socially-Grounded Persona Framework for User Simulation](https://arxiv.org/abs/2601.07110)
*Pranav Narayanan Venkit,Yu Li,Yada Pruksachatkun,Chien-Sheng Wu*

Main category: cs.CL

TL;DR: 本文提出了SCOPE框架，通过深度采集社会心理属性，改进语言模型中人设（persona）的构建方式，并证明新方法能更好预测行为、减少偏见，并优于以往以人口学为主的人设。


<details>
  <summary>Details</summary>
Motivation: 现有的大模型人设大多只基于人口学属性，过于粗糙，对行为预测和真实模拟存在局限，缺乏科学的个体差异刻画。作者希望通过更社会心理化的变量，提高人设的真实性和实用性。

Method: 作者采用141项为期两小时的社会心理学问卷，从124位美国参与者处收集数据，开发了SCOPE框架；对比七类不同模型下用人口学信息、人设摘要、与基于社会心理等变量建构的人设，在行为预测准确性、偏见等角度综合评估。

Result: 人口学属性仅能解释1.5%的行为反应相似性，引入社会心理特征后，行为预测能力显著增强、模型偏见减小；基于价值观和身份等变量重建人设后，模型表现进一步优于主流的默认人设和Nemotron人设。

Conclusion: 高质量的语言模型人设应基于社会心理属性而非单纯人口学模板，这样能获得更真实、低偏见、更高行为预测性的模拟效果，SCOPE提供了新范式。

Abstract: Synthetic personas are widely used to condition large language models (LLMs) for social simulation, yet most personas are still constructed from coarse sociodemographic attributes or summaries. We revisit persona creation by introducing SCOPE, a socially grounded framework for persona construction and evaluation, built from a 141-item, two-hour sociopsychological protocol collected from 124 U.S.-based participants. Across seven models, we find that demographic-only personas are a structural bottleneck: demographics explain only ~1.5% of variance in human response similarity. Adding sociopsychological facets improves behavioral prediction and reduces over-accentuation, and non-demographic personas based on values and identity achieve strong alignment with substantially lower bias. These trends generalize to SimBench (441 aligned questions), where SCOPE personas outperform default prompting and NVIDIA Nemotron personas, and SCOPE augmentation improves Nemotron-based personas. Our results indicate that persona quality depends on sociopsychological structure rather than demographic templates or summaries.

</details>


### [226] [ReMIND: Orchestrating Modular Large Language Models for Controllable Serendipity A REM-Inspired System Design for Emergent Creative Ideation](https://arxiv.org/abs/2601.07121)
*Makoto Sato*

Main category: cs.CL

TL;DR: 本文提出了ReMIND框架，通过将大语言模型的创意思维过程分为四个阶段，实现新颖性与一致性的兼得，提升了罕见但高质量创意的产生概率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在创意生成领域虽能产生新颖内容，但往往难以确保内容的一致性和内在连贯性。现有方法如随机采样虽能提升新奇性，却经常损害结果的合理性，因此亟需新框架平衡这两者。

Method: 提出了ReMIND框架，将创意生成过程分为wake（生成稳定基线）、dream（高温探索生成）、judge（粗略筛选过滤）、re-wake（重表达巩固）四步，每步由独立的LLM实例完成，实现探索与收敛功能分离。通过参数调整和嵌入分析，考察各阶段作用。

Result: ReMIND通过参数实验和嵌入分析，证明dream阶段能有效推动语义探索，而最终输出具备更高下游稳定性。外部评估显示，优质创意是偶发的罕见产物，并非取决于任何单一指标的最值。

Conclusion: 高质量创意的偶然诞生适合通过系统级设计实现，ReMIND框架为理解和提高大语言模型的偶得性提供了理论和方法，并证明了模块化多模型编排在创意生成中的有效性。

Abstract: Large language models (LLMs) are used not only for problem solving but also for creative ideation; however, eliciting serendipitous insights that are both novel and internally coherent remains difficult. While stochastic sampling promotes novelty, it often degrades consistency. Here, we propose ReMIND, a REM-inspired modular framework for ideation. ReMIND consists of four stages: wake, which generates a stable low-temperature semantic baseline; dream, which performs high-temperature exploratory generation; judge, which applies coarse evaluation to filter incoherent outputs and extract candidate ideas; and re-wake, which re-articulates selected ideas into coherent final outputs. By instantiating each stage as an independent LLM, ReMIND enables functional separation between exploration and consolidation. Parameter sweeps show that ReMIND reliably induces semantic exploration while preserving downstream stability. Embedding-based analyses confirm substantial semantic displacement during the dream phase, whereas external evaluations reveal that high-quality ideas emerge sporadically rather than as extrema along any single metric. These results suggest that serendipitous ideation in LLMs is a rare-event process best approached through system level design that shapes the conditions under which valuable ideas can emerge and be stabilized. ReMIND provides a general framework for studying the computational basis of serendipity and illustrates how modular LLM orchestration can bridge exploration and stabilization.

</details>


### [227] [Measuring Iterative Temporal Reasoning with TimePuzzles](https://arxiv.org/abs/2601.07148)
*Zhengxiang Wang,Zeyu Dong*

Main category: cs.CL

TL;DR: 本文提出了TimePuzzles，一种基于约束的日期推断任务，用于评测大语言模型（LLM）的时间推理能力，具备生成性强、可控性高等特点，在对13种LLM的测试中表现出较高区分度。


<details>
  <summary>Details</summary>
Motivation: 当前大模型在涉及时间推理、复杂日历关系时表现有限，缺乏系统性的基准评测手段。为及时发现并分析工具辅助下及无辅助下的推理能力差距，作者设计了该任务。

Method: 设计并自动生成基于多个时间事实和日历关系的约束题目，每题可能有一个或多个有效答案。对13种主流LLM进行评测，并对比无工具、网页检索、代码执行等多种辅助条件下的表现。

Result: GPT-5准确率仅49.3%，其他模型不超过31%；网页搜索提升显著，代码解释器效果不一。当题目约束用显式日期表达时，模型表现明显提升，说明现有模型对隐含时间关系推理仍有较大不足。

Conclusion: TimePuzzles为评估LLM在工具辅助与非辅助下的时间推理提供了简单、有效、低成本的新基准，有助于推动工具增强型推理模型发展。

Abstract: We introduce TimePuzzles, a constraint-based date inference task for evaluating iterative temporal reasoning. Each puzzle combines factual temporal anchors with (cross-cultural) calendar relations, admits one or multiple valid solution dates, and is algorithmically generated for controlled, dynamic, and continual evaluation. Across 13 diverse LLMs, TimePuzzles well distinguishes their iterative temporal reasoning capabilities and remains challenging without tools: GPT-5 reaches only 49.3% accuracy and all other models stay below 31%, despite the dataset's simplicity. Web search consistently yields substantial gains and using code interpreter shows mixed effects, but all models perform much better when constraints are rewritten with explicit dates, revealing a gap in reliable tool use. Overall, TimePuzzles presents a simple, cost-effective diagnostic for tool-augmented iterative temporal reasoning.

</details>


### [228] [Can Large Language Models Understand, Reason About, and Generate Code-Switched Text?](https://arxiv.org/abs/2601.07153)
*Genta Indra Winata,David Anugraha,Patrick Amadeus Irawan,Anirban Das,Haneul Yoo,Paresh Dashore,Shreyas Kulkarni,Ruochen Zhang,Haruki Sakajo,Frederikus Hudi,Anaelia Ovalle,Syrielle Montariol,Felix Gaschi,Michael Anugraha,Rutuj Ravindra Puranik,Zawad Hayat Ahmed,Adril Putra Merin,Emmanuele Chersoni*

Main category: cs.CL

TL;DR: 本研究系统评估了大型语言模型（LLMs）在混合语言（code-switching）环境下的理解、推理与生成能力，提出并公开了新基准数据集CodeMixQA，揭示了现有模型在混合语言处理中的持续挑战。


<details>
  <summary>Details</summary>
Motivation: 多语言交流中混合语言（code-switching）现象广泛存在，但当前LLMs在此类环境下的稳健性尚不明确。研究动机在于评估与提升LLMs在混合语言语境下的表现。

Method: 作者构建了一个包含16种不同语对、涵盖地理和切换模式多样性的高质量注释基准数据集CodeMixQA，原文和转写同时覆盖。通过该基准，分析了LLMs在混合语言问答任务中的推理表现，并系统评估了模型合成混合语言文本的自然性与语义保真度。

Result: 结果显示，当前LLMs在code-switching的推理和生成任务上均面临显著挑战，特别是在文本自然性与语义一致性方面存在不足。

Conclusion: 尽管LLMs具备一定多语言能力，但在混合语言环境下仍然有待加强。该研究为提升多语言模型的稳健性提供了方向，并公开了数据集和代码以支持后续研究。

Abstract: Code-switching is a pervasive phenomenon in multilingual communication, yet the robustness of large language models (LLMs) in mixed-language settings remains insufficiently understood. In this work, we present a comprehensive evaluation of LLM capabilities in understanding, reasoning over, and generating code-switched text. We introduce CodeMixQA a novel benchmark with high-quality human annotations, comprising 16 diverse parallel code-switched language-pair variants that span multiple geographic regions and code-switching patterns, and include both original scripts and their transliterated forms. Using this benchmark, we analyze the reasoning behavior of LLMs on code-switched question-answering tasks, shedding light on how models process and reason over mixed-language inputs. We further conduct a systematic evaluation of LLM-generated synthetic code-switched text, focusing on both naturalness and semantic fidelity, and uncover key limitations in current generation capabilities. Our findings reveal persistent challenges in both reasoning and generation under code-switching conditions and provide actionable insights for building more robust multilingual LLMs. We release the dataset and code as open source.

</details>


### [229] [Structured Reasoning for Large Language Models](https://arxiv.org/abs/2601.07180)
*Jinyi Han,Zixiang Di,Zishang Jiang,Ying Liao,Jiaqing Liang,Yongqi Wang,Yanghua Xiao*

Main category: cs.CL

TL;DR: 该论文提出了一种结构化推理（SCR）框架，通过生成-验证-修订（Generate-Verify-Revise）范式优化大语言模型的推理流程，提升推理效率并减少冗余步骤。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在推理过程中往往生成过长、冗余的思维链，即使已得出正确答案也会进行不必要的验证和修订，主要由于推理轨迹非结构化且缺乏针对性监督。该问题影响了推理效率和答案质量。

Method: 作者提出SCR框架，将推理过程拆解为显式、可评估和可训练的组成部分，采用Generate-Verify-Revise模式，并通过动态终止监督引导模型何时结束推理。此外，分两阶段进行强化学习，分别针对初步生成和自我验证，以及后续修订，避免能力间信号干扰。

Result: 在三种主流大模型上进行大量实验，结果显示SCR显著提升了推理效率和自我验证能力，推理输出长度最多降低50%。

Conclusion: 结构化推理框架能有效减少冗余推理步骤，增强模型有效推理与验证能力，优于现有推理范式。

Abstract: Large language models (LLMs) achieve strong performance by generating long chains of thought, but longer traces always introduce redundant or ineffective reasoning steps. One typical behavior is that they often perform unnecessary verification and revisions even if they have reached the correct answers. This limitation stems from the unstructured nature of reasoning trajectories and the lack of targeted supervision for critical reasoning abilities. To address this, we propose Structured Reasoning (SCR), a framework that decouples reasoning trajectories into explicit, evaluable, and trainable components. We mainly implement SCR using a Generate-Verify-Revise paradigm. Specifically, we construct structured training data and apply Dynamic Termination Supervision to guide the model in deciding when to terminate reasoning. To avoid interference between learning signals for different reasoning abilities, we adopt a progressive two-stage reinforcement learning strategy: the first stage targets initial generation and self-verification, and the second stage focuses on revision. Extensive experiments on three backbone models show that SCR substantially improves reasoning efficiency and self-verification. Besides, compared with existing reasoning paradigms, it reduces output token length by up to 50%.

</details>


### [230] [Relink: Constructing Query-Driven Evidence Graph On-the-Fly for GraphRAG](https://arxiv.org/abs/2601.07192)
*Manzong Huang,Chenyang Bu,Yi He,Xingrui Zhuo,Xindong Wu*

Main category: cs.CL

TL;DR: Relink提出了一种动态构建证据图的新范式，提高了图结构增强生成（GraphRAG）的问答表现，在五个公开问答基准上大幅优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有GraphRAG方法依赖于静态预构建知识图谱，面临知识不完整和干扰事实过多的问题，导致大模型推理路径中断和信息噪声增加，影响问答准确性。

Method: Relink采用“先推理再构图”的范式，针对每个查询动态构建专属证据图。具体做法包括：1）根据原始文本语料生成潜在关系池，动态实例化缺失事实，修复推理路径；2）通过统一的、面向查询的评价方法，综合考虑知识图谱和潜在关系中的候选事实，主动剔除干扰信息，保留最有助于回答查询的证据构成证据路径。

Result: 在五个开放域问答基准数据集上，Relink平均准确率（EM）提升5.4%，F1得分提升5.2%，显著优于现有GraphRAG方法。

Conclusion: Relink能够动态构建更精准、可靠的证据图，有效缓解知识不全和干扰信息问题，提升开放域问答的表现，展现出比传统GraphRAG方法更优的效果。

Abstract: Graph-based Retrieval-Augmented Generation (GraphRAG) mitigates hallucinations in Large Language Models (LLMs) by grounding them in structured knowledge. However, current GraphRAG methods are constrained by a prevailing \textit{build-then-reason} paradigm, which relies on a static, pre-constructed Knowledge Graph (KG). This paradigm faces two critical challenges. First, the KG's inherent incompleteness often breaks reasoning paths. Second, the graph's low signal-to-noise ratio introduces distractor facts, presenting query-relevant but misleading knowledge that disrupts the reasoning process.
  To address these challenges, we argue for a \textit{reason-and-construct} paradigm and propose Relink, a framework that dynamically builds a query-specific evidence graph. To tackle incompleteness, \textbf{Relink} instantiates required facts from a latent relation pool derived from the original text corpus, repairing broken paths on the fly. To handle misleading or distractor facts, Relink employs a unified, query-aware evaluation strategy that jointly considers candidates from both the KG and latent relations, selecting those most useful for answering the query rather than relying on their pre-existence. This empowers Relink to actively discard distractor facts and construct the most faithful and precise evidence path for each query.
  Extensive experiments on five Open-Domain Question Answering benchmarks show that Relink achieves significant average improvements of 5.4\% in EM and 5.2\% in F1 over leading GraphRAG baselines, demonstrating the superiority of our proposed framework.

</details>


### [231] [MI-PRUN: Optimize Large Language Model Pruning via Mutual Information](https://arxiv.org/abs/2601.07212)
*Hao Zhang,Zhibin Zhang,Guangxin Wu,He Chen,Jiafeng Guo,Xueqi Cheng*

Main category: cs.CL

TL;DR: 本文提出了一种新的大语言模型（LLMs）块剪枝方法MI-PRUN，基于互信息与数据处理不等式理论，提升剪枝的稳定性和效果，并通过高效区块选择算法优化全局组合，在多个模型和数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在各领域的广泛应用，其庞大的计算和内存需求成为主要瓶颈。模型剪枝已被用于减小模型体积和加速推理，但现有的块剪枝方法存在稳定性不足、难以全局优化等问题。本文旨在开发更有效且稳定的块剪枝新方案。

Method: 提出基于互信息的剪枝MI-PRUN方法，通过评估隐藏状态变化来衡量各区块冗余性，并引入数据处理不等式（DPI）分析区块整体及其内部的重要性。此外，设计了Fast-Block-Select算法，能够高效搜索并更新区块组合，实现接近全局最优的剪枝结果。

Result: 在多个大语言模型及数据集上进行实验，结果表明所提方法在模型压缩率、推理加速和剪枝后模型性能保持方面，均优于现有块剪枝方法，且表现出更高的稳定性和效率。

Conclusion: MI-PRUN能够有效且高效地对大语言模型进行块剪枝，既提升了剪枝的全局最优性，也增强了方法的稳定性和实际应用可行性，有助于大模型在资源受限环境下的落地应用。

Abstract: Large Language Models (LLMs) have become indispensable across various domains, but this comes at the cost of substantial computational and memory resources. Model pruning addresses this by removing redundant components from models. In particular, block pruning can achieve significant compression and inference acceleration. However, existing block pruning methods are often unstable and struggle to attain globally optimal solutions. In this paper, we propose a mutual information based pruning method MI-PRUN for LLMs. Specifically, we leverages mutual information to identify redundant blocks by evaluating transitions in hidden states. Additionally, we incorporate the Data Processing Inequality (DPI) to reveal the relationship between the importance of entire contiguous blocks and that of individual blocks. Moreover, we develop the Fast-Block-Select algorithm, which iteratively updates block combinations to achieve a globally optimal solution while significantly improving the efficiency. Extensive experiments across various models and datasets demonstrate the stability and effectiveness of our method.

</details>


### [232] [The Roots of Performance Disparity in Multilingual Language Models: Intrinsic Modeling Difficulty or Design Choices?](https://arxiv.org/abs/2601.07220)
*Chen Shani,Yuval Reif,Nathan Roll,Dan Jurafsky,Ekaterina Shutova*

Main category: cs.CL

TL;DR: 多语种语言模型在不同语言上的表现不均衡，本文归纳产生这一差距的原因及可能的优化设计建议。


<details>
  <summary>Details</summary>
Motivation: 尽管多语种语言模型可以极大拓展NLP的适用范围，但它们在全球不同语言间的效果差异较大。本调查旨在探究这种差异是由语言本身的固有复杂性还是模型设计上的选择所致。

Method: 本文梳理总结了相关文献，从两个核心问题出发：1）语言间的表现差异主要源于模型的表示与资源分配选择（如分词、编码、数据暴露、参数共享），而非语言本身的复杂性吗？2）哪些设计方法可以减少不同类型语言间的不平等？文中还逐一分析了正字法、形态学、词汇多样性、句法、信息密度、类型学距离等语言特征与具体模型机制的联系。

Result: 研究发现，当分词、编码和数据暴露标准化后，不同语言间的表现差距显著缩小，表明许多“难以建模”的现象其实是因现有模型设计方式造成的。

Conclusion: 文章基于综合分析，提出了在分词、采样、模型架构和评估方面的具体设计建议，以支持更加均衡和公平的多语种语言模型开发。

Abstract: Multilingual language models (LMs) promise broader NLP access, yet current systems deliver uneven performance across the world's languages. This survey examines why these gaps persist and whether they reflect intrinsic linguistic difficulty or modeling artifacts. We organize the literature around two questions: do linguistic disparities arise from representation and allocation choices (e.g., tokenization, encoding, data exposure, parameter sharing) rather than inherent complexity; and which design choices mitigate inequities across typologically diverse languages. We review linguistic features, such as orthography, morphology, lexical diversity, syntax, information density, and typological distance, linking each to concrete modeling mechanisms. Gaps often shrink when segmentation, encoding, and data exposure are normalized, suggesting much apparent difficulty stems from current modeling choices. We synthesize these insights into design recommendations for tokenization, sampling, architectures, and evaluation to support more balanced multilingual LMs.

</details>


### [233] [ActiShade: Activating Overshadowed Knowledge to Guide Multi-Hop Reasoning in Large Language Models](https://arxiv.org/abs/2601.07260)
*Huipeng Ma,Luan Zhang,Dandan Song,Linmei Hu,Yuhang Tian,Jun Yang,Changzhi Zhou,Chenhao Li,Yizhou Jin,Xudong Li,Meng Lin,Mingxing Zhang,Shuhao Zhang*

Main category: cs.CL

TL;DR: 论文提出ActiShade方法，通过检测并激活被掩盖的关键信息，增强LLM在多跳推理任务中的表现，有效缓解知识掩盖及误差累积问题。


<details>
  <summary>Details</summary>
Motivation: 多轮RAG方法会因为LLM生成查询过程中关键信息被掩盖，导致检索偏离、推理误差累积。因此需要新方法解决知识掩盖难题。

Method: 提出ActiShade，能迭代检测查询中被掩盖的关键信息（keyphrase），对原查询和被掩盖keyphrase同时检索相关文档，再基于检索结果生成新查询，引导下一轮迭代，补齐知识空缺并减少噪声。

Result: 在多个数据集和大语言模型上，ActiShade实验性能优于当前主流RAG方法。

Conclusion: ActiShade能够缓解知识掩盖现象，提升多跳推理过程中RAG方法的准确性和鲁棒性。

Abstract: In multi-hop reasoning, multi-round retrieval-augmented generation (RAG) methods typically rely on LLM-generated content as the retrieval query. However, these approaches are inherently vulnerable to knowledge overshadowing - a phenomenon where critical information is overshadowed during generation. As a result, the LLM-generated content may be incomplete or inaccurate, leading to irrelevant retrieval and causing error accumulation during the iteration process. To address this challenge, we propose ActiShade, which detects and activates overshadowed knowledge to guide large language models (LLMs) in multi-hop reasoning. Specifically, ActiShade iteratively detects the overshadowed keyphrase in the given query, retrieves documents relevant to both the query and the overshadowed keyphrase, and generates a new query based on the retrieved documents to guide the next-round iteration. By supplementing the overshadowed knowledge during the formulation of next-round queries while minimizing the introduction of irrelevant noise, ActiShade reduces the error accumulation caused by knowledge overshadowing. Extensive experiments show that ActiShade outperforms existing methods across multiple datasets and LLMs.

</details>


### [234] [The Confidence Dichotomy: Analyzing and Mitigating Miscalibration in Tool-Use Agents](https://arxiv.org/abs/2601.07264)
*Weihao Xuan,Qingcheng Zeng,Heli Qi,Yunze Xiao,Junjue Wang,Naoto Yokoya*

Main category: cs.CL

TL;DR: 本文关注于基于大语言模型（LLM）的自主智能体在多轮任务中的可信度校准问题，并提出一种结合强化学习微调的新方法，有效提升工具型智能体的自信度表达与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着基于大模型的自主智能体广泛应用于需要调用外部工具的复杂任务，如何确保其在不确定性条件下作出可靠的自信度表达成为提升信任度的关键环节。然而，当前关于此类agent自信度校准的研究主要集中在静态模型，对于集成外部工具、动态交互的智能体校准研究不足。

Method: 作者系统性地研究了智能体在使用不同类型工具时的自信度表达，发现“检索型工具”和“验证型工具”在人为自信表达时呈现显著差异。随后，作者提出了一个基于强化学习的微调框架，联合优化任务准确性与自信度校准，并设计了完整的奖励基准以支撑训练。

Result: 实验发现，使用检索型工具（如网页搜索）会导致智能体自信度严重过高，因为外部信息本身噪声大，而验证型工具（如代码解释器）通过可判定反馈有助于减少误校准。提出的方法显著提升了智能体在多场景下的自信度校准准确度，并展示了在噪声环境和新领域（如数学推理）上的泛化能力。

Conclusion: 智能体在不同工具类型下需要采用领域定制的校准策略，提出的RL微调方法为构建能精确传达自身不确定性的自知型智能体奠定了基础，对实际高风险场景具有重要意义。

Abstract: Autonomous agents based on large language models (LLMs) are rapidly evolving to handle multi-turn tasks, but ensuring their trustworthiness remains a critical challenge. A fundamental pillar of this trustworthiness is calibration, which refers to an agent's ability to express confidence that reliably reflects its actual performance. While calibration is well-established for static models, its dynamics in tool-integrated agentic workflows remain underexplored. In this work, we systematically investigate verbalized calibration in tool-use agents, revealing a fundamental confidence dichotomy driven by tool type. Specifically, our pilot study identifies that evidence tools (e.g., web search) systematically induce severe overconfidence due to inherent noise in retrieved information, while verification tools (e.g., code interpreters) can ground reasoning through deterministic feedback and mitigate miscalibration. To robustly improve calibration across tool types, we propose a reinforcement learning (RL) fine-tuning framework that jointly optimizes task accuracy and calibration, supported by a holistic benchmark of reward designs. We demonstrate that our trained agents not only achieve superior calibration but also exhibit robust generalization from local training environments to noisy web settings and to distinct domains such as mathematical reasoning. Our results highlight the necessity of domain-specific calibration strategies for tool-use agents. More broadly, this work establishes a foundation for building self-aware agents that can reliably communicate uncertainty in high-stakes, real-world deployments.

</details>


### [235] [Document-Level Zero-Shot Relation Extraction with Entity Side Information](https://arxiv.org/abs/2601.07271)
*Mohan Raj Chanthran,Soon Lay Ki,Ong Huey Fang,Bhawani Selvaretnam*

Main category: cs.CL

TL;DR: 本文提出了一种结合实体辅助信息的文档级零样本关系抽取方法，在无需大语言模型合成数据的条件下，实现对低资源语言关系抽取任务的稳健改进。


<details>
  <summary>Details</summary>
Motivation: 现有文档级零样本关系抽取方法严重依赖大语言模型生成的合成数据，但这些方法在低资源语言（如马来西亚英语）中存在语言特色难以体现及事实错误等问题。急需更可靠、高效的解决方案。

Method: 提出DocZSRE-SI框架，利用实体辅助信息（如实体描述、实体杂类词）辅助关系抽取任务，无需依赖LLM的数据合成，模型结构低复杂度。

Result: 与基线及现有方法相比，该方法宏平均F1分数提升了11.6%，显著优于LLM合成数据驱动的方法，尤其擅长处理低资源语言和多样语言背景下的数据。

Conclusion: DocZSRE-SI为低资源语言和多样语境下的零样本关系抽取提供了强健且高效的方案，有效克服了LLM-based方法在此类任务中的不足，具有良好推广应用前景。

Abstract: Document-Level Zero-Shot Relation Extraction (DocZSRE) aims to predict unseen relation labels in text documents without prior training on specific relations. Existing approaches rely on Large Language Models (LLMs) to generate synthetic data for unseen labels, which poses challenges for low-resource languages like Malaysian English. These challenges include the incorporation of local linguistic nuances and the risk of factual inaccuracies in LLM-generated data. This paper introduces Document-Level Zero-Shot Relation Extraction with Entity Side Information (DocZSRE-SI) to address limitations in the existing DocZSRE approach. The DocZSRE-SI framework leverages Entity Side Information, such as Entity Mention Descriptions and Entity Mention Hypernyms, to perform ZSRE without depending on LLM-generated synthetic data. The proposed low-complexity model achieves an average improvement of 11.6% in the macro F1-Score compared to baseline models and existing benchmarks. By utilizing Entity Side Information, DocZSRE-SI offers a robust and efficient alternative to error-prone, LLM-based methods, demonstrating significant advancements in handling low-resource languages and linguistic diversity in relation extraction tasks. This research provides a scalable and reliable solution for ZSRE, particularly in contexts like Malaysian English news articles, where traditional LLM-based approaches fall short.

</details>


### [236] [Towards Comprehensive Semantic Speech Embeddings for Chinese Dialects](https://arxiv.org/abs/2601.07274)
*Kalvin Chang,Yiwen Shao,Jiahong Li,Dong Yu*

Main category: cs.CL

TL;DR: 本文提出并实现了能够实现中文方言与普通话语义对齐的语音编码器，利用ASR数据进行训练，在构建中文方言到普通话的语音大模型上取得了重要突破。作者还贡献了一个新的方言语音基准数据集，并在其上达到了最优的ASR表现。


<details>
  <summary>Details</summary>
Motivation: 当前中文方言语音技术发展缓慢，缺少有效的数据与模型，方言的主要应用场景更适合方言转普通话语音大模型，因此需要跨方言语义对齐的语音表示。

Method: 作者提出采用仅依赖ASR数据训练的语音编码器，实现了中文多方言与普通话之间的语义对齐。同时，针对方言语音检索任务提出了新的评测基准并共享。

Result: 所提出的语音编码器在方言语音识别任务上取得了业界领先的效果，并在新的方言语音检索基准上验证了跨方言语义对齐的有效性。

Conclusion: 本文为中文方言到普通话语音大模型的构建奠定了基础，提出的数据集、方法和评测标准推动了中文方言语音技术的发展。

Abstract: Despite having hundreds of millions of speakers, Chinese dialects lag behind Mandarin in speech and language technologies. Most varieties are primarily spoken, making dialect-to-Mandarin speech-LLMs (large language models) more practical than dialect LLMs. Building dialect-to-Mandarin speech-LLMs requires speech representations with cross-dialect semantic alignment between Chinese dialects and Mandarin. In this paper, we achieve such a cross-dialect semantic alignment by training a speech encoder with ASR (automatic speech recognition)-only data, as demonstrated by speech-to-speech retrieval on a new benchmark of spoken Chinese varieties that we contribute. Our speech encoder further demonstrates state-of-the-art ASR performance on Chinese dialects. Together, our Chinese dialect benchmark, semantically aligned speech representations, and speech-to-speech retrieval evaluation lay the groundwork for future Chinese dialect speech-LLMs. We release the benchmark at https://github.com/kalvinchang/yubao.

</details>


### [237] [ReasonTabQA: A Comprehensive Benchmark for Table Question Answering from Real World Industrial Scenarios](https://arxiv.org/abs/2601.07280)
*Changzai Pan,Jie Zhang,Kaiwen Wei,Chenshuo Pan,Yu Zhao,Jingwang Huang,Jian Yang,Zhenhe Wu,Haoyang Zeng,Xiaoyan Gu,Weichao Sun,Yanbo Zhai,Yujie Mao,Zhuoru Jiang,Jiang Zhong,Shuangyong Song,Yongxiang Li,Zhongjiang He*

Main category: cs.CL

TL;DR: 本文提出了一个大规模工业场景的双语TableQA基准ReasonTabQA，并提出了基于强化学习的TabCodeRL以提升复杂表格推理能力。实验证明该方法提升了开源LLM在TableQA上的性能，但仍存在挑战。


<details>
  <summary>Details</summary>
Motivation: 目前的TableQA基准大多不涵盖多表结构、嵌套表头和大规模数据的复杂工业场景，现有方法难以满足深度结构化推理需求。针对这一不足，亟需构建更具挑战性的工业级TableQA基准并探索有效推理方法。

Method: 构建了ReasonTabQA基准，覆盖30个行业、1,932张工业级表格，包含高质量答案和推理链，支持多种推理范式。提出TabCodeRL方法，利用以表格为中心的可验证奖励，引导逻辑推理路径生成，通过强化学习提升TableQA能力。

Result: 在ReasonTabQA及4个公开TableQA数据集上实验，TabCodeRL显著提升了开源大模型的表格问答能力。但于ReasonTabQA上的表现仍表明工业级复杂推理任务极具挑战。

Conclusion: 所提出数据集和方法有效推动了TableQA在复杂工业场景中的能力提升，但要完全解决深度结构化推理问题还需进一步探索，ReasonTabQA为真实场景下TableQA研究提供了新基准和方向。

Abstract: Recent advancements in Large Language Models (LLMs) have significantly catalyzed table-based question answering (TableQA). However, existing TableQA benchmarks often overlook the intricacies of industrial scenarios, which are characterized by multi-table structures, nested headers, and massive scales. These environments demand robust table reasoning through deep structured inference, presenting a significant challenge that remains inadequately addressed by current methodologies. To bridge this gap, we present ReasonTabQA, a large-scale bilingual benchmark encompassing 1,932 tables across 30 industry domains such as energy and automotive. ReasonTabQA provides high-quality annotations for both final answers and explicit reasoning chains, supporting both thinking and no-thinking paradigms. Furthermore, we introduce TabCodeRL, a reinforcement learning method that leverages table-aware verifiable rewards to guide the generation of logical reasoning paths. Extensive experiments on ReasonTabQA and 4 TableQA datasets demonstrate that while TabCodeRL yields substantial performance gains on open-source LLMs, the persistent performance gap on ReasonTabQA underscores the inherent complexity of real-world industrial TableQA.

</details>


### [238] [PsyCLIENT: Client Simulation via Conversational Trajectory Modeling for Trainee Practice and Model Evaluation in Mental Health Counseling](https://arxiv.org/abs/2601.07312)
*Huachuan Qiu,Zhaoming Chen,Yuqian Chen,Yuan Xie,Yu Lu,Zhenzhong Lan*

Main category: cs.CL

TL;DR: 本文提出了一个基于大型语言模型（LLM）的心理咨询客户端模拟框架PsyCLIENT，通过对话轨迹建模，实现了更加真实、多样化的模拟客户端。同时，推出了首个开源中文客户端档案数据集。实验表明，该方法在真实性和训练有效性上优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在心理咨询训练和评估中应用的客户端模拟方法存在三大问题：1）客户端档案多样性和真实性不足；2）缺乏合理行为建模框架；3）中文场景资源匮乏。这些问题限制了自动化咨询系统及咨询师训练的应用效果。

Method: 作者提出了PsyCLIENT，通过将LLM生成过程与预定义、具备行为标签和内容约束的真实对话轨迹结合，实现了对话多样性和真实性。同时发布了PsyCLIENT-CP中文客户端档案数据集，涵盖60个咨询主题。

Result: 在专业持证咨询师评测下，PsyCLIENT在客户端模拟的真实性和训练有效性两方面均显著优于现有基线。模拟客户端与真实人的可区分度仅5%（即专家有95%的混淆率）。

Conclusion: 对话轨迹建模能有效提升模拟客户端的现实感和多样性，为心理健康领域的教育和研究提供了有力工具。框架及数据将开源，促进相关研究发展。

Abstract: LLM-based client simulation has emerged as a promising tool for training novice counselors and evaluating automated counseling systems. However, existing client simulation approaches face three key challenges: (1) limited diversity and realism in client profiles, (2) the lack of a principled framework for modeling realistic client behaviors, and (3) a scarcity in Chinese-language settings. To address these limitations, we propose PsyCLIENT, a novel simulation framework grounded in conversational trajectory modeling. By conditioning LLM generation on predefined real-world trajectories that incorporate explicit behavior labels and content constraints, our approach ensures diverse and realistic interactions. We further introduce PsyCLIENT-CP, the first open-source Chinese client profile dataset, covering 60 distinct counseling topics. Comprehensive evaluations involving licensed professional counselors demonstrate that PsyCLIENT significantly outperforms baselines in terms of authenticity and training effectiveness. Notably, the simulated clients are nearly indistinguishable from human clients, achieving an about 95\% expert confusion rate in discrimination tasks. These findings indicate that conversational trajectory modeling effectively bridges the gap between theoretical client profiles and dynamic, realistic simulations, offering a robust solution for mental health education and research. Code and data will be released to facilitate future research in mental health counseling.

</details>


### [239] [Mitrasamgraha: A Comprehensive Classical Sanskrit Machine Translation Dataset](https://arxiv.org/abs/2601.07314)
*Sebastian Nehrdich,David Allport,Sven Sellmer,Jivnesh Sandhan,Manoj Balaji Jagadeeshan,Pawan Goyal,Sujeet Kumar,Kurt Keutzer*

Main category: cs.CL

TL;DR: 该论文提出了Mitrasamgraha，一个大规模高质量的梵文-英文机器翻译数据集，并用它分析和提升了不同模型在梵文各领域的翻译表现。


<details>
  <summary>Details</summary>
Motivation: 尽管机器翻译在高资源语言上已有卓越进展，但对于包含诗歌、哲学、多层隐喻等复杂表述的梵文文学，现有数据和模型依然难以胜任。梵文领域高质量公开资源极度稀缺，严重制约了相关NLP研究和应用的发展。

Method: 作者构建了Mitrasamgraha数据集，包含391,548对高质量梵文-英文句对，涵盖三千多年的梵文文本和多个领域（如仪式、史诗、哲学、诗歌、科学）。数据集包含详细的时间和领域标注，并且还发布了经过人工修正的验证集和测试集。利用该数据集，作者对主流商用与开源模型进行了基准实验，并对NLLB和Gemma模型进行了微调，同时分析了上下文学习对模型表现的影响。

Result: Mitrasamgraha是目前最大且覆盖最广的梵文-英文翻译数据集。微调后的NLLB和Gemma模型在实验中取得了显著性能提升，商用和开源模型也因上下文学习受益。不过，模型在复杂复合词、哲学概念和多层隐喻方面仍存在明显困难。

Conclusion: Mitrasamgraha为梵文机器翻译和NLP研究提供了宝贵资源，对模型在不同时期和领域的表现进行了细致评估。但复杂语言和内容特性的翻译依旧具有重大挑战，有待未来进一步研究。

Abstract: While machine translation is regarded as a "solved problem" for many high-resource languages, close analysis quickly reveals that this is not the case for content that shows challenges such as poetic language, philosophical concepts, multi-layered metaphorical expressions, and more. Sanskrit literature is a prime example of this, as it combines a large number of such challenges in addition to inherent linguistic features like sandhi, compounding, and heavy morphology, which further complicate NLP downstream tasks. It spans multiple millennia of text production time as well as a large breadth of different domains, ranging from ritual formulas via epic narratives, philosophical treatises, poetic verses up to scientific material. As of now, there is a strong lack of publicly available resources that cover these different domains and temporal layers of Sanskrit. We therefore introduce Mitrasamgraha, a high-quality Sanskrit-to-English machine translation dataset consisting of 391,548 bitext pairs, more than four times larger than the largest previously available Sanskrit dataset Itih=asa. It covers a time period of more than three millennia and a broad range of historical Sanskrit domains. In contrast to web-crawled datasets, the temporal and domain annotation of this dataset enables fine-grained study of domain and time period effects on MT performance. We also release a validation set consisting of 5,587 and a test set consisting of 5,552 post-corrected bitext pairs. We conduct experiments benchmarking commercial and open models on this dataset and fine-tune NLLB and Gemma models on the dataset, showing significant improvements, while still recognizing significant challenges in the translation of complex compounds, philosophical concepts, and multi-layered metaphors. We also analyze how in-context learning on this dataset impacts the performance of commercial models

</details>


### [240] [How to predict creativity ratings from written narratives: A comparison of co-occurrence and textual forma mentis networks](https://arxiv.org/abs/2601.07327)
*Roberto Passaro,Edith Haim,Massimo Stella*

Main category: cs.CL

TL;DR: 本文提供了基于文本语义网络分析创意文本的系统流程，并比较了两种常见的文本转网络方法，评估了其预测人类创造力评分的能力及网络建构选择对预测准确性的影响。


<details>
  <summary>Details</summary>
Motivation: 旨在为研究人员提供一个实用、易复制的文本语义网络分析流程，特别是帮助认知与创造力研究领域的人士更好地利用网络方法量化和预测创造性表现。

Method: 采用两种文本转网络的方法：词共现网络和文本形态心智网络（TFMN），以1029个短故事为语料，演示文本预处理、网络构建、特征提取（结构性指标、扩散激活指标、情感分数）以及回归模型建模，并定量比较不同网络构建方式下的网络结构和预测效果。

Result: TFMN 在所有建模设置下的预测误差优于词共现网络（最佳MAE=0.581 vs 0.592）。网络结构特征在预测上表现最佳（TFMN: MAE=0.591），情感特征表现较差（MAE=0.711），扩散激活指标贡献最小（MAE=0.788）。

Conclusion: TFMN对于创意文本的创造性评估优于表层共现网络。网络结构特征是效果最好的预测因子。该文为初学者和进阶研究者都提供了详实的实操指导及方法论洞见，强调了合理选择网络构建方式的重要性和开放可复现的流程。

Abstract: This tutorial paper provides a step-by-step workflow for building and analysing semantic networks from short creative texts. We introduce and compare two widely used text-to-network approaches: word co-occurrence networks and textual forma mentis networks (TFMNs). We also demonstrate how they can be used in machine learning to predict human creativity ratings. Using a corpus of 1029 short stories, we guide readers through text preprocessing, network construction, feature extraction (structural measures, spreading-activation indices, and emotion scores), and application of regression models. We evaluate how network-construction choices influence both network topology and predictive performance. Across all modelling settings, TFMNs consistently outperformed co-occurrence networks through lower prediction errors (best MAE = 0.581 for TFMN, vs 0.592 for co-occurrence with window size 3). Network-structural features dominated predictive performance (MAE = 0.591 for TFMN), whereas emotion features performed worse (MAE = 0.711 for TFMN) and spreading-activation measures contributed little (MAE = 0.788 for TFMN). This paper offers practical guidance for researchers interested in applying network-based methods for cognitive fields like creativity research. we show when syntactic networks are preferable to surface co-occurrence models, and provide an open, reproducible workflow accessible to newcomers in the field, while also offering deeper methodological insight for experienced researchers.

</details>


### [241] [BayesRAG: Probabilistic Mutual Evidence Corroboration for Multimodal Retrieval-Augmented Generation](https://arxiv.org/abs/2601.07329)
*Xuan Li,Yining Wang,Haocai Luo,Shengping Liu,Jerry Liang,Ying Fu,Weihuang,Jun Yu,Junnan Zhu*

Main category: cs.CL

TL;DR: 本文提出了BayesRAG，一种基于贝叶斯推断和证据理论的多模态检索增强生成（RAG）框架，能够有效整合文本与图像，提高多模态检索表现。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法将文本与图像视为独立检索对象，无法充分利用两者间的语义强化和版面一致性，对多模态文档处理能力有限。

Method: BayesRAG利用贝叶斯推断结合Dempster-Shafer证据理论，将跨模态（文本-图像）候选结果的内在一致性作为概率证据进行建模，并计算多模态结果组合的后验相关概率，从而整合和排序能够在语义和版式上相互印证的文本图像对。

Result: BayesRAG在多个具有挑战性的多模态基准上显著优于现有主流方法，检索准确率和鲁棒性均有提升。

Conclusion: BayesRAG为多模态检索融合建立了新范式，有效打通了异质模态之间的信息孤岛，并增强了检索结果的鲁棒性。

Abstract: Retrieval-Augmented Generation (RAG) has become a pivotal paradigm for Large Language Models (LLMs), yet current approaches struggle with visually rich documents by treating text and images as isolated retrieval targets. Existing methods relying solely on cosine similarity often fail to capture the semantic reinforcement provided by cross-modal alignment and layout-induced coherence. To address these limitations, we propose BayesRAG, a novel multimodal retrieval framework grounded in Bayesian inference and Dempster-Shafer evidence theory. Unlike traditional approaches that rank candidates strictly by similarity, BayesRAG models the intrinsic consistency of retrieved candidates across modalities as probabilistic evidence to refine retrieval confidence. Specifically, our method computes the posterior association probability for combinations of multimodal retrieval results, prioritizing text-image pairs that mutually corroborate each other in terms of both semantics and layout. Extensive experiments demonstrate that BayesRAG significantly outperforms state-of-the-art (SOTA) methods on challenging multimodal benchmarks. This study establishes a new paradigm for multimodal retrieval fusion that effectively resolves the isolation of heterogeneous modalities through an evidence fusion mechanism and enhances the robustness of retrieval outcomes. Our code is available at https://github.com/TioeAre/BayesRAG.

</details>


### [242] [Beyond Literal Mapping: Benchmarking and Improving Non-Literal Translation Evaluation](https://arxiv.org/abs/2601.07338)
*Yanzhi Tian,Cunxiang Wang,Zeming Liu,Heyan Huang,Wenbo Yu,Dawei Song,Jie Tang,Yuhang Guo*

Main category: cs.CL

TL;DR: 该论文提出了针对非字面翻译的机器翻译评价新框架RATE，并构建了MENT数据集，展示了传统评价指标和LLM评估的不准确性，RATE在评价准确性和一致性上均有提升。


<details>
  <summary>Details</summary>
Motivation: 传统的机器翻译评价方法在面对包含大量非字面表达（如社交网络、文学领域等）的复杂文本时，评价结果可能不准确，尤其是在用大语言模型直接打分时存在知识截止和一致性问题。论文旨在系统性地研究、解决非字面领域MT评价工具的可靠性问题。

Method: 作者首先构建了专注于非字面翻译的评价数据集MENT，涵盖四个非字面翻译领域，包含来自不同MT系统的译文和7,530个人工打分。随后提出了新颖的自动评价框架RATE，该框架基于一个反思型核心代理，能灵活调用各种专门子代理，模拟更具判断力的动态评测流程。

Result: 实验结果显示，传统MT指标和直接用LLM打分方法在非字面领域表现不佳，存在准确性和一致性不足的问题。RATE框架在评价得分和一致性上优于现有方法，对比提升不少于3.2分。同时，进一步实验表明RATE在通用领域翻译评价上也表现出良好的鲁棒性。

Conclusion: 针对非字面翻译场景，作者提出的RATE框架显著提升了机器翻译的自动评价性能，弥补了传统指标和LLM评测的不足，具备可靠性和通用性，对未来机器翻译的实际应用和评价体系建设具有推动作用。

Abstract: Large Language Models (LLMs) have significantly advanced Machine Translation (MT), applying them to linguistically complex domains-such as Social Network Services, literature etc. In these scenarios, translations often require handling non-literal expressions, leading to the inaccuracy of MT metrics. To systematically investigate the reliability of MT metrics, we first curate a meta-evaluation dataset focused on non-literal translations, namely MENT. MENT encompasses four non-literal translation domains and features source sentences paired with translations from diverse MT systems, with 7,530 human-annotated scores on translation quality. Experimental results reveal the inaccuracies of traditional MT metrics and the limitations of LLM-as-a-Judge, particularly the knowledge cutoff and score inconsistency problem. To mitigate these limitations, we propose RATE, a novel agentic translation evaluation framework, centered by a reflective Core Agent that dynamically invokes specialized sub-agents. Experimental results indicate the efficacy of RATE, achieving an improvement of at least 3.2 meta score compared with current metrics. Further experiments demonstrate the robustness of RATE to general-domain MT evaluation. Code and dataset are available at: https://github.com/BITHLP/RATE.

</details>


### [243] [DiffER: Diffusion Entity-Relation Modeling for Reversal Curse in Diffusion Large Language Models](https://arxiv.org/abs/2601.07347)
*Shaokai He,Kaiwen Wei,Xinyi Zeng,Xiang Chen,Xue Yang,Zhenyang Li,Jiang Zhong,Yu Tian*

Main category: cs.CL

TL;DR: 本论文探讨了大语言模型在处理双向逻辑关系时常出现的“反转诅咒”现象，并提出了一种新方法DiffER，有效缓解了该问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究发现大语言模型在处理表面上双向的知识关联时只表现出单向推理能力，这种“反转诅咒”会限制其知识表达和推理能力。即使采用双向训练方式的Diffusion LLMs（DLLMs）仍未能摆脱这一问题，这促使作者探索其深层原因并寻求改进方法。

Method: 作者对DLLMs进行了系统性实验，归纳出导致反转诅咒的三大原因：1）训练过程中的实体碎片化；2）训练数据之间的不对称性；3）数据中实体关系缺失。为此，作者提出了Diffusion Entity-Relation Modeling（DiffER）方法，结合实体感知训练与数据均衡构建，包括整体实体掩码、分布对称和关系增强三大策略。

Result: 实验结果显示，DiffER在多个评测任务上显著缓解了DLLMs的反转诅咒问题，有效提升了模型处理双向关系的能力。

Conclusion: DiffER方法为解决大语言模型的反转诅咒提供了新的有效方案，对未来模型结构和训练数据设计具有重要启示意义。

Abstract: The "reversal curse" refers to the phenomenon where large language models (LLMs) exhibit predominantly unidirectional behavior when processing logically bidirectional relationships. Prior work attributed this to autoregressive training -- predicting the next token inherently favors left-to-right information flow over genuine bidirectional knowledge associations. However, we observe that Diffusion LLMs (DLLMs), despite being trained bidirectionally, also suffer from the reversal curse. To investigate the root causes, we conduct systematic experiments on DLLMs and identify three key reasons: 1) entity fragmentation during training, 2) data asymmetry, and 3) missing entity relations. Motivated by the analysis of these reasons, we propose Diffusion Entity-Relation Modeling (DiffER), which addresses the reversal curse through entity-aware training and balanced data construction. Specifically, DiffER introduces whole-entity masking, which mitigates entity fragmentation by predicting complete entities in a single step. DiffER further employs distribution-symmetric and relation-enhanced data construction strategies to alleviate data asymmetry and missing relations. Extensive experiments demonstrate that DiffER effectively alleviates the reversal curse in Diffusion LLMs, offering new perspectives for future research.

</details>


### [244] [Controlled Self-Evolution for Algorithmic Code Optimization](https://arxiv.org/abs/2601.07348)
*Tu Hu,Ronghao Chen,Shuo Zhang,Jianghao Yin,Mou Xiao Feng,Jingping Liu,Shaolei Zhang,Wenqi Jiang,Yuqi Fang,Sen Hu,Yi Xu,Huacan Wang*

Main category: cs.CL

TL;DR: 本文提出了一种受控自演化（CSE）方法，通过更智能的进化过程显著提升代码生成任务的效率和效果。


<details>
  <summary>Details</summary>
Motivation: 当前自演化（generate-verify-refine）在代码生成中探索效率低，难以在有限预算下发现复杂更优解。主要瓶颈包括初始解偏倚、进化过程随机性无反馈指导，以及经验利用不足。

Method: CSE包含三个核心模块：（1）多样化规划初始化，生成结构多样的算法策略，覆盖更大解空间；（2）遗传进化，晋升为反馈引导的变异与重组机制，提升探索效率；（3）分层进化记忆，在任务内外积累成功及失败经验，加强学习利用。

Result: 在EffiBench-X基准和多个主流大模型骨干测试中，CSE在各项指标均优于现有方法，尤其在早期迭代即表现出更高效率，并在后续持续提升表现。

Conclusion: CSE显著提升了代码生成进化效率与质量，有望作为大模型代码生成的新范式。代码已开源。

Abstract: Self-evolution methods enhance code generation through iterative "generate-verify-refine" cycles, yet existing approaches suffer from low exploration efficiency, failing to discover solutions with superior complexity within limited budgets. This inefficiency stems from initialization bias trapping evolution in poor solution regions, uncontrolled stochastic operations lacking feedback guidance, and insufficient experience utilization across tasks.To address these bottlenecks, we propose Controlled Self-Evolution (CSE), which consists of three key components. Diversified Planning Initialization generates structurally distinct algorithmic strategies for broad solution space coverage. Genetic Evolution replaces stochastic operations with feedback-guided mechanisms, enabling targeted mutation and compositional crossover. Hierarchical Evolution Memory captures both successful and failed experiences at inter-task and intra-task levels.Experiments on EffiBench-X demonstrate that CSE consistently outperforms all baselines across various LLM backbones. Furthermore, CSE achieves higher efficiency from early generations and maintains continuous improvement throughout evolution. Our code is publicly available at https://github.com/QuantaAlpha/EvoControl.

</details>


### [245] [Reward Modeling from Natural Language Human Feedback](https://arxiv.org/abs/2601.07349)
*Zongqi Wang,Rui Wang,Yuchuan Wu,Yiyao Yu,Pinyi Zhang,Shaoning Sun,Yujiu Yang,Yongbin Li*

Main category: cs.CL

TL;DR: 本论文提出利用自然语言反馈来改进生成奖励模型（GRM）的训练方法，通过衡量生成与人类评价的相似度，提升奖励信号准确性，摆脱只依赖二分类偏好标签的局限。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法依赖二分类偏好标签作为奖励信号，但这导致GRM可以不用扎实推理、仅凭猜测也能获得正确结果，产生噪声，训练效果下降。

Method: 作者提出RM-NLHF方法，引入自然语言反馈，通过比较模型和人类批评的相似性来构造奖励信号。同时引入MetaRM模型，使得即使在没有大量人类批评的情况下也能泛化获得过程奖励。

Result: 在多个基准任务上，RM-NLHF与MetaRM方法显著优于只用二分类标签训练的主流奖励模型。

Conclusion: 综合自然语言反馈显著提升奖励建模效果，相较传统二分类监督有明显优势。

Abstract: Reinforcement Learning with Verifiable reward (RLVR) on preference data has become the mainstream approach for training Generative Reward Models (GRMs). Typically in pairwise rewarding tasks, GRMs generate reasoning chains ending with critiques and preference labels, and RLVR then relies on the correctness of the preference labels as the training reward. However, in this paper, we demonstrate that such binary classification tasks make GRMs susceptible to guessing correct outcomes without sound critiques. Consequently, these spurious successes introduce substantial noise into the reward signal, thereby impairing the effectiveness of reinforcement learning. To address this issue, we propose Reward Modeling from Natural Language Human Feedback (RM-NLHF), which leverages natural language feedback to obtain process reward signals, thereby mitigating the problem of limited solution space inherent in binary tasks. Specifically, we compute the similarity between GRM-generated and human critiques as the training reward, which provides more accurate reward signals than outcome-only supervision. Additionally, considering that human critiques are difficult to scale up, we introduce Meta Reward Model (MetaRM) which learns to predict process reward from datasets with human critiques and then generalizes to data without human critiques. Experiments on multiple benchmarks demonstrate that our method consistently outperforms state-of-the-art GRMs trained with outcome-only reward, confirming the superiority of integrating natural language over binary human feedback as supervision.

</details>


### [246] [Beyond Hard Masks: Progressive Token Evolution for Diffusion Language Models](https://arxiv.org/abs/2601.07351)
*Linhao Zhong,Linyu Wu,Bozhen Fang,Tianjian Feng,Chenchen Jing,Wen Wang,Jiaheng Zhang,Hao Chen,Chunhua Shen*

Main category: cs.CL

TL;DR: 该论文提出了一种名为EvoToken-DLM的新型扩散式语言建模方法，通过软分布进化替代传统硬掩码，改善了并行解码过程中的表达与修正能力，实验结果优于现有相关模型。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散式语言模型大多依赖于硬二值掩码和离散token分配，导致模型在早期决策上的可修正性较差，并未充分利用中间的概率分布信息。为提升语言模型的解码质量和灵活性，需要探索更高效的编码与解码机制。

Method: 提出EvoToken-DLM，将硬二值掩码替换为可进化的软Token分布，实现从掩码状态平滑过渡到最终离散输出；为此引入连续轨迹监督，以便训练目标与每次迭代的概率性更新对齐，增强模型对概率演化过程的捕捉与利用。

Result: 在多个权威基准测试中，EvoToken-DLM表现优异，稳定超越强有力的扩散基础模型和掩码类DLM基线。

Conclusion: EvoToken-DLM在扩散式语言建模中提出了有效的新机制，显著提升了模型性能和解码可修正性，证明了软token分布和连续演化监督在该领域的应用潜力。

Abstract: Diffusion Language Models (DLMs) offer a promising alternative for language modeling by enabling parallel decoding through iterative refinement. However, most DLMs rely on hard binary masking and discrete token assignments, which hinder the revision of early decisions and underutilize intermediate probabilistic representations. In this paper, we propose EvoToken-DLM, a novel diffusion-based language modeling approach that replaces hard binary masks with evolving soft token distributions. EvoToken-DLM enables a progressive transition from masked states to discrete outputs, supporting revisable decoding. To effectively support this evolution, we introduce continuous trajectory supervision, which aligns training objectives with iterative probabilistic updates. Extensive experiments across multiple benchmarks show that EvoToken-DLM consistently achieves superior performance, outperforming strong diffusion-based and masked DLM baselines. Project webpage: https://aim-uofa.github.io/EvoTokenDLM.

</details>


### [247] [TALON: Confidence-Aware Speculative Decoding with Adaptive Token Trees](https://arxiv.org/abs/2601.07353)
*Tianyu Liu,Qitan Lv,Yuhao Shen,Xiao Sun,Xiaoyan Sun*

Main category: cs.CL

TL;DR: 提出了一种全新的自适应树扩展推理框架TALON，用于加速大型语言模型的推理。


<details>
  <summary>Details</summary>
Motivation: 当前树结构speculative decoding方法通常采用固定宽度和深度，无法根据不同token和上下文的难度自适应调整草稿树，导致加速和质量无法兼顾。

Method: TALON框架无需额外训练，采用预算驱动、逐层自适应分配节点预算、迭代扩展草稿树，实现灵活深度与宽度调整，简单token多扩展，困难token提前终止，兼容现有树结构推理方法。

Result: 在5个模型和6个数据集上的实验表明，TALON在加速效果和输出质量方面均优于现有最优方法EAGLE-3，最高能达5.16倍推理加速。

Conclusion: TALON显著优化了树结构speculative decoding方法的加速与质量权衡，为大模型推理提供了更高效的技术路径。

Abstract: Speculative decoding (SD) has become a standard technique for accelerating LLM inference without sacrificing output quality. Recent advances in speculative decoding have shifted from sequential chain-based drafting to tree-structured generation, where the draft model constructs a tree of candidate tokens to explore multiple possible drafts in parallel. However, existing tree-based SD methods typically build a fixed-width, fixed-depth draft tree, which fails to adapt to the varying difficulty of tokens and contexts. As a result, the draft model cannot dynamically adjust the tree structure to early stop on difficult tokens and extend generation for simple ones. To address these challenges, we introduce TALON, a training-free, budget-driven adaptive tree expansion framework that can be plugged into existing tree-based methods. Unlike static methods, TALON constructs the draft tree iteratively until a fixed token budget is met, using a hybrid expansion strategy that adaptively allocates the node budget to each layer of the draft tree. This framework naturally shapes the draft tree into a "deep-and-narrow" form for deterministic contexts and a "shallow-and-wide" form for uncertain branches, effectively optimizing the trade-off between exploration width and generation depth under a given budget. Extensive experiments across 5 models and 6 datasets demonstrate that TALON consistently outperforms state-of-the-art EAGLE-3, achieving up to 5.16x end-to-end speedup over auto-regressive decoding.

</details>


### [248] [Semantic Compression of LLM Instructions via Symbolic Metalanguages](https://arxiv.org/abs/2601.07354)
*Ernst van Gassen*

Main category: cs.CL

TL;DR: MetaGlyph是一种用数学符号压缩AI提示词的符号语言，能大幅减小提示词长度，并在部分主流大模型中取得了较好的语义等价性与操作符忠诚度。


<details>
  <summary>Details</summary>
Motivation: 当前生成式AI在应用中提示词（prompt）长度过长，不仅增加API调用成本，也影响本地部署效率，因此需要一种方法压缩提示词数据。

Method: 提出MetaGlyph符号语言，通过使用常见数学符号（如∈、⇒）表达逐步指令，避免复杂的解码规则。其创意在于模型训练时早已见过这些符号，无需专门教学。通过对8个不同规模、开放性大模型进行各类任务评测，包括API商用模型与本地开源模型，对比符号指令和常规文字指令的表现。

Result: 在所有任务类型和模型中，MetaGlyph符号提示平均可缩短62-81%的token数量。对于API，可显著降低费用；对于本地部署，则减少了延迟和内存压力。不同模型对符号提示的理解度差异大：Gemini 2.5 Flash语义等价75%，成员操作符忠诚度49.9%；Kimi K2对蕴含操作符忠诚度98.1%，对选择任务实现100%准确率；GPT-5.2 Chat达到最高成员操作符忠诚度91.3%；Claude Haiku 4.5符号解析成功率100%但成员操作符忠诚度仅26%；中等规模模型如Qwen 2.5 7B抽取任务等价性62%；开源7B-12B模型符号理解几乎为零，表明规模足够大后才能克服指令微调带来的偏差。

Conclusion: MetaGlyph显著压缩提示长度并在主流大模型中取得一定的符号理解表现，能节省API成本和提升本地部署效率，但其有效性主要依赖模型规模和类型，开源中小模型效果有限。

Abstract: We introduce MetaGlyph, a symbolic language for compressing prompts by encoding instructions as mathematical symbols rather than prose. Unlike systems requiring explicit decoding rules, MetaGlyph uses symbols like $\in$ (membership) and $\Rightarrow$ (implication) that models already understand from their training data. We test whether these symbols work as ''instruction shortcuts'' that models can interpret without additional teaching.
  We evaluate eight models across two dimensions relevant to practitioners: scale (3B-1T parameters) and accessibility (open-source for local deployment vs. proprietary APIs). MetaGlyph achieves 62-81% token reduction across all task types. For API-based deployments, this translates directly to cost savings; for local deployments, it reduces latency and memory pressure.
  Results vary by model. Gemini 2.5 Flash achieves 75% semantic equivalence between symbolic and prose instructions on selection tasks, with 49.9% membership operator fidelity. Kimi K2 reaches 98.1% fidelity for implication ($\Rightarrow$) and achieves perfect (100%) accuracy on selection tasks with symbolic prompts. GPT-5.2 Chat shows the highest membership fidelity observed (91.3%), though with variable parse success across task types. Claude Haiku 4.5 achieves 100% parse success with 26% membership fidelity. Among mid-sized models, Qwen 2.5 7B shows 62% equivalence on extraction tasks. Mid-sized open-source models (7B-12B) show near-zero operator fidelity, suggesting a U-shaped relationship where sufficient scale overcomes instruction-tuning biases.

</details>


### [249] [Interpretable Text Classification Applied to the Detection of LLM-generated Creative Writing](https://arxiv.org/abs/2601.07368)
*Minerva Suvanto,Andrea McGlinchey,Mattias Wahde,Peter J Barclay*

Main category: cs.CL

TL;DR: 本文研究了如何区分人类创作的小说片段和大型语言模型（LLM）生成的类似文本，发现机器学习模型在二分类任务上表现远超人类，准确率达0.93-0.98。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI技术的发展，AI生成文本与人类文本日益相似，区分两者变得越来越难，这在内容审核、学术诚信等领域引发关注。因此，明确LLM生成文本的可检测特征及判别机制具有重要现实意义。

Method: 作者收集了人类和LLM生成的小说文本，在同等长度的文本片段上，人类和机器模型进行二分类判断。研究采用包括可解释的线性分类器（基于unigram特征）在内的多种机器学习模型，并分析模型用以判别的具体特征。

Result: 人类受试者在判别任务上表现接近随机，准确率很低，而多种机器学习模型准确率稳定在0.93-0.98。线性模型分析揭示，LLM生成文本往往使用同义词更多，出现明显概率分布偏移，此外还表现出时序漂移、美式表达、外语使用和口语用词等可辨识特征。

Conclusion: 当前LLM生成文本与人类文本在细粒度特征上存在各类可识别差异，机器学习模型判别效果远超人类，基于多特征组合的判别机制使伪装LLM文本变得相对困难。

Abstract: We consider the problem of distinguishing human-written creative fiction (excerpts from novels) from similar text generated by an LLM. Our results show that, while human observers perform poorly (near chance levels) on this binary classification task, a variety of machine-learning models achieve accuracy in the range 0.93 - 0.98 over a previously unseen test set, even using only short samples and single-token (unigram) features. We therefore employ an inherently interpretable (linear) classifier (with a test accuracy of 0.98), in order to elucidate the underlying reasons for this high accuracy. In our analysis, we identify specific unigram features indicative of LLM-generated text, one of the most important being that the LLM tends to use a larger variety of synonyms, thereby skewing the probability distributions in a manner that is easy to detect for a machine learning classifier, yet very difficult for a human observer. Four additional explanation categories were also identified, namely, temporal drift, Americanisms, foreign language usage, and colloquialisms. As identification of the AI-generated text depends on a constellation of such features, the classification appears robust, and therefore not easy to circumvent by malicious actors intent on misrepresenting AI-generated text as human work.

</details>


### [250] [Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models](https://arxiv.org/abs/2601.07372)
*Xin Cheng,Wangding Zeng,Damai Dai,Qinyu Chen,Bingxuan Wang,Zhenda Xie,Kezhao Huang,Xingkai Yu,Zhewen Hao,Yukun Li,Han Zhang,Huishuai Zhang,Dongyan Zhao,Wenfeng Liang*

Main category: cs.CL

TL;DR: 本文提出一种新的条件记忆（conditional memory）机制，通过新设计的Engram模块，为Transformer模型引入高效知识检索能力，并在推理和多任务表现上优于传统MoE方法。


<details>
  <summary>Details</summary>
Motivation: 虽然Mixture-of-Experts (MoE) 可以利用条件计算提升模型容量，但Transformer本身缺乏原生高效知识检索机制，需依赖低效的计算模拟检索。因此，研究者希望填补Transformer高效知识查找的能力缺口。

Method: 文章提出了Engram条件记忆模块，这是一种现代化的N-gram嵌入方式，可实现O(1)高效查找。作者构建并分析'稀疏性分配'（Sparsity Allocation）问题，给出了神经计算（MoE）和静态记忆（Engram）间的最优权衡法则，并将Engram扩展至270亿参数以验证其效果。

Result: 扩展后的Engram模型在知识检索、复杂推理、代码和数学等任务的多项基准上均取得显著提升，相较同参数和FLOPs的MoE基线表现更优。尤其在长上下文检索等场景提升明显。此外，机制分析显示该模块能有效分担主干网络的任务，提高神经计算资源利用效率。

Conclusion: Engram模块为Transformer引入一种效率极高的知识查找方式，提升模型处理复杂推理与长文档的能力，并可通过硬件友好的方式预加载到内存中。文章认为条件记忆将成为下一代稀疏模型不可或缺的基础元件。

Abstract: While Mixture-of-Experts (MoE) scales capacity via conditional computation, Transformers lack a native primitive for knowledge lookup, forcing them to inefficiently simulate retrieval through computation. To address this, we introduce conditional memory as a complementary sparsity axis, instantiated via Engram, a module that modernizes classic $N$-gram embedding for O(1) lookup. By formulating the Sparsity Allocation problem, we uncover a U-shaped scaling law that optimizes the trade-off between neural computation (MoE) and static memory (Engram). Guided by this law, we scale Engram to 27B parameters, achieving superior performance over a strictly iso-parameter and iso-FLOPs MoE baseline. Most notably, while the memory module is expected to aid knowledge retrieval (e.g., MMLU +3.4; CMMLU +4.0), we observe even larger gains in general reasoning (e.g., BBH +5.0; ARC-Challenge +3.7) and code/math domains~(HumanEval +3.0; MATH +2.4). Mechanistic analyses reveal that Engram relieves the backbone's early layers from static reconstruction, effectively deepening the network for complex reasoning. Furthermore, by delegating local dependencies to lookups, it frees up attention capacity for global context, substantially boosting long-context retrieval (e.g., Multi-Query NIAH: 84.2 to 97.0). Finally, Engram establishes infrastructure-aware efficiency: its deterministic addressing enables runtime prefetching from host memory, incurring negligible overhead. We envision conditional memory as an indispensable modeling primitive for next-generation sparse models.

</details>


### [251] [GROKE: Vision-Free Navigation Instruction Evaluation via Graph Reasoning on OpenStreetMap](https://arxiv.org/abs/2601.07375)
*Farzad Shami,Subhrasankha Dey,Nico Van de Weghe,Henrikki Tenkanen*

Main category: cs.CL

TL;DR: 提出了一种基于OpenStreetMap和LLM的导航指令评估框架GROKE，无需视觉信息，能更准确评估指令有效性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言导航(VLN)任务评估指标（如BLEU、ROUGE）不能有效判断导航指令是否能带领导航者正确到达目的地。视觉模拟器作为评估器存在高成本、授权限制及感知误差问题，因此需开发新方法。

Method: 提出GROKE：一种基于OpenStreetMap知识、无需视觉和训练的分层LLM评估框架。利用结构化JSON和文本空间信息，结合分步规划和拓扑图导航，无需视觉模拟器即可评估导航指令的“可导航性”。

Result: 在Map2Seq数据集上，GROKE的导航误差相比启发式方法和采样基线降低68.5%。结构化格式（JSON/文本）显著优于传统网格和视觉图表示。方法通过执行成功率、轨迹一致性等代理指标衡量指令的实际可导航性。

Conclusion: GROKE为导航指令评估建立了无需视觉、可扩展、易解释的新范式，适合以OSM地标与拓扑为基础的功能性导航任务。代码和数据已开源。

Abstract: The evaluation of navigation instructions remains a persistent challenge in Vision-and-Language Navigation (VLN) research. Traditional reference-based metrics such as BLEU and ROUGE fail to capture the functional utility of spatial directives, specifically whether an instruction successfully guides a navigator to the intended destination. Although existing VLN agents could serve as evaluators, their reliance on high-fidelity visual simulators introduces licensing constraints and computational costs, and perception errors further confound linguistic quality assessment. This paper introduces GROKE(Graph-based Reasoning over OSM Knowledge for instruction Evaluation), a vision-free training-free hierarchical LLM-based framework for evaluating navigation instructions using OpenStreetMap data. Through systematic ablation studies, we demonstrate that structured JSON and textual formats for spatial information substantially outperform grid-based and visual graph representations. Our hierarchical architecture combines sub-instruction planning with topological graph navigation, reducing navigation error by 68.5% compared to heuristic and sampling baselines on the Map2Seq dataset. The agent's execution success, trajectory fidelity, and decision patterns serve as proxy metrics for functional navigability given OSM-visible landmarks and topology, establishing a scalable and interpretable evaluation paradigm without visual dependencies. Code and data are available at https://anonymous.4open.science/r/groke.

</details>


### [252] [Outcome-Grounded Advantage Reshaping for Fine-Grained Credit Assignment in Mathematical Reasoning](https://arxiv.org/abs/2601.07408)
*Ziheng Li,Liu Kang,Feng Xiao,Luxi Xing,Qingyi Si,Zhuoran Li,Weikang Gong,Deqing Yang,Yanghua Xiao,Hongcheng Guo*

Main category: cs.CL

TL;DR: 该论文提出了一种名为Outcome-grounded Advantage Reshaping (OAR)的细粒度奖励分配机制，有效提升了对复杂推理任务中各步骤贡献度的识别和利用，并显著提升了现有无评判器强化学习方法GRPO在数学推理基准上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的GRPO方法在序列推理任务中采用粗粒度奖励分配，无法区分不同token（推理步骤）对最终结果的重要性，导致模型难以充分学习关键决策步，影响了强化学习推理任务的效果。

Method: 作者提出OAR方法，通过识别各token对最终答案的影响力，分配更为精确的奖励。具体包括：1) OAR-P：通过反事实token扰动，精细估计每个token对结果的敏感度，实现高保真影响归因；2) OAR-G：通过输入梯度代理，利用单次反向传播高效近似token重要性。二者结合保守双层加权方案，增强关键token奖励、削弱次要token奖励，并保持奖励总和不变。

Result: 在多个数学推理基准测试上，OAR-P取得了最高的性能上限，而OAR-G以极低的计算开销实现了与OAR-P接近的性能提升，两者均大幅优于GRPO基线方法。

Conclusion: OAR机制有效解决了GRPO中奖励分配过于粗糙的问题，通过细粒度信号提升了大模型“无评判器”方式下的推理能力，为推理型强化学习方法提供了新方向。

Abstract: Group Relative Policy Optimization (GRPO) has emerged as a promising critic-free reinforcement learning paradigm for reasoning tasks. However, standard GRPO employs a coarse-grained credit assignment mechanism that propagates group-level rewards uniformly to to every token in a sequence, neglecting the varying contribution of individual reasoning steps. We address this limitation by introducing Outcome-grounded Advantage Reshaping (OAR), a fine-grained credit assignment mechanism that redistributes advantages based on how much each token influences the model's final answer. We instantiate OAR via two complementary strategies: (1) OAR-P, which estimates outcome sensitivity through counterfactual token perturbations, serving as a high-fidelity attribution signal; (2) OAR-G, which uses an input-gradient sensitivity proxy to approximate the influence signal with a single backward pass. These importance signals are integrated with a conservative Bi-Level advantage reshaping scheme that suppresses low-impact tokens and boosts pivotal ones while preserving the overall advantage mass. Empirical results on extensive mathematical reasoning benchmarks demonstrate that while OAR-P sets the performance upper bound, OAR-G achieves comparable gains with negligible computational overhead, both significantly outperforming a strong GRPO baseline, pushing the boundaries of critic-free LLM reasoning.

</details>


### [253] [Two Pathways to Truthfulness: On the Intrinsic Encoding of LLM Hallucinations](https://arxiv.org/abs/2601.07422)
*Wen Luo,Guangyue Peng,Wei Li,Shaohang Wei,Feifan Song,Liang Wang,Nan Yang,Xingxing Zhang,Jing Jin,Furu Wei,Houfeng Wang*

Main category: cs.CL

TL;DR: 本文揭示了大语言模型（LLM）内部真实信号源于两个不同信息路径，并利用这些发现提升了幻觉检测能力。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM表现突出，但幻觉问题普遍存在。此前研究发现其内部状态可体现真实信号，但信号来源和机制尚不明确，因此需要研究其内部真实性感知机制。

Method: 作者提出并验证了两条信息路径：问题锚定路径（问题与答案之间信息流）和答案锚定路径（仅凭答案本身证据）。通过注意力敲除与token修补等实验手段进行归因分析，并进一步探究路径属性与知识边界的关联。

Result: 两条路径被有效区分并验证，且分别与模型知识边界密切相关，内部表征能感知两者差异。基于这些发现提出了提升LLM幻觉检测的应用方法。

Conclusion: 研究揭示了LLM内部真实信号的结构与机制，为开发更可靠和自知的生成系统提供了新视角和设计方向。

Abstract: Despite their impressive capabilities, large language models (LLMs) frequently generate hallucinations. Previous work shows that their internal states encode rich signals of truthfulness, yet the origins and mechanisms of these signals remain unclear. In this paper, we demonstrate that truthfulness cues arise from two distinct information pathways: (1) a Question-Anchored pathway that depends on question-answer information flow, and (2) an Answer-Anchored pathway that derives self-contained evidence from the generated answer itself. First, we validate and disentangle these pathways through attention knockout and token patching. Afterwards, we uncover notable and intriguing properties of these two mechanisms. Further experiments reveal that (1) the two mechanisms are closely associated with LLM knowledge boundaries; and (2) internal representations are aware of their distinctions. Finally, building on these insightful findings, two applications are proposed to enhance hallucination detection performance. Overall, our work provides new insight into how LLMs internally encode truthfulness, offering directions for more reliable and self-aware generative systems.

</details>


### [254] [SAD: A Large-Scale Strategic Argumentative Dialogue Dataset](https://arxiv.org/abs/2601.07423)
*Yongkang Liu,Jiayang Yu,Mingyang Wang,Yiqun Zhang,Ercong Nie,Shi Feng,Daling Wang,Kaisong Song,Hinrich Schütze*

Main category: cs.CL

TL;DR: 本文提出了一个大规模多轮策略性论证对话数据集SAD，并对其中的发言进行了策略类型标注，支持更复杂的对话论证建模。


<details>
  <summary>Details</summary>
Motivation: 现有论证文本数据主要集中于非交互式、单轮场景，缺乏对于多轮、带有策略的实际辩论对话的建模支持。

Method: 研究者构建了SAD数据集，包含39万多例，依据论证理论标注了每句发言的五种策略类别（每句可多标）。数据集要求模型根据对话历史、立场和目标策略生成合适的对话内容，并在多个生成模型上进行了基准测试和策略使用模式分析。

Result: SAD数据集为多轮策略性论证对话建模提供了新资源。实验分析了模型生成策略对话的能力，并揭示了实际论证中策略类型的使用规律。

Conclusion: SAD数据集为研究多轮、策略驱动的论证对话开辟了新的空间，为后续高质量对话论证模型研究提供了基准和分析工具。

Abstract: Argumentation generation has attracted substantial research interest due to its central role in human reasoning and decision-making. However, most existing argumentative corpora focus on non-interactive, single-turn settings, either generating arguments from a given topic or refuting an existing argument. In practice, however, argumentation is often realized as multi-turn dialogue, where speakers defend their stances and employ diverse argumentative strategies to strengthen persuasiveness. To support deeper modeling of argumentation dialogue, we present the first large-scale \textbf{S}trategic \textbf{A}rgumentative \textbf{D}ialogue dataset, SAD, consisting of 392,822 examples. Grounded in argumentation theories, we annotate each utterance with five strategy types, allowing multiple strategies per utterance. Unlike prior datasets, SAD requires models to generate contextually appropriate arguments conditioned on the dialogue history, a specified stance on the topic, and targeted argumentation strategies. We further benchmark a range of pretrained generative models on SAD and present in-depth analysis of strategy usage patterns in argumentation.

</details>


### [255] [KALE: Enhancing Knowledge Manipulation in Large Language Models via Knowledge-aware Learning](https://arxiv.org/abs/2601.07430)
*Qitan Lv,Tianyu Liu,Qiaosheng Zhang,Xingcheng Xu,Chaochao Lu*

Main category: cs.CL

TL;DR: 提出一种名为KALE的后训练框架，用知识图谱生成解释，提升大语言模型知识操作能力，并在多个基准上显著提升准确率。


<details>
  <summary>Details</summary>
Motivation: 现有大模型在知识操作（召回、推理、迁移）上仍有不足，特别是‘已知但答错’现象突出。

Method: KALE框架包含两个核心：一，利用知识图谱多跳推理路径自动生成高质量解释；二，引入基于解释的合理性蒸馏方法，通过KL散度最小化，实现知识操作能力的内化提升。

Result: 在六种LLMs、八个常见基准上，KALE带来显著准确率提升，最高可达11.72%，平均提升4.18%。

Conclusion: KALE能系统性提升LLMs的知识操作能力，通过知识图谱辅助的解释生成及合理性内化，有效缓解‘明知故错’问题。

Abstract: Despite the impressive performance of large language models (LLMs) pretrained on vast knowledge corpora, advancing their knowledge manipulation-the ability to effectively recall, reason, and transfer relevant knowledge-remains challenging. Existing methods mainly leverage Supervised Fine-Tuning (SFT) on labeled datasets to enhance LLMs' knowledge manipulation ability. However, we observe that SFT models still exhibit the known&incorrect phenomenon, where they explicitly possess relevant knowledge for a given question but fail to leverage it for correct answers. To address this challenge, we propose KALE (Knowledge-Aware LEarning)-a post-training framework that leverages knowledge graphs (KGs) to generate high-quality rationales and enhance LLMs' knowledge manipulation ability. Specifically, KALE first introduces a Knowledge-Induced (KI) data synthesis method that efficiently extracts multi-hop reasoning paths from KGs to generate high-quality rationales for question-answer pairs. Then, KALE employs a Knowledge-Aware (KA) fine-tuning paradigm that enhances knowledge manipulation by internalizing rationale-guided reasoning through minimizing the KL divergence between predictions with and without rationales. Extensive experiments on eight popular benchmarks across six different LLMs demonstrate the effectiveness of KALE, achieving accuracy improvements of up to 11.72% and an average of 4.18%.

</details>


### [256] [Judging Against the Reference: Uncovering Knowledge-Driven Failures in LLM-Judges on QA Evaluation](https://arxiv.org/abs/2601.07506)
*Dongryeol Lee,Yerin Hwang,Taegwan Kang,Minwoo Lee,Younhyung Chae,Kyomin Jung*

Main category: cs.CL

TL;DR: 本文发现大语言模型（LLM）作为自动判分员时，在参考答案与其自身知识冲突时，无法可靠地根据参考评分，导致评估准确性显著下降。


<details>
  <summary>Details</summary>
Motivation: 目前LLM广泛应用于自动化问答等基于参考答案的任务评测，但对于模型能否严格遵循参考信息仍缺乏系统性理解。作者希望揭示并分析LLM在其知识和参考冲突时的表现与局限。

Method: 作者提出并使用了一套“参考答案调包”QA评测框架，通过将正确参考答案替换为错误内容、并精心构造候选答案配对，系统测试LLM评分时对参考与自身知识冲突的反应以及打分可靠性。

Result: 多种判分模型在“调包参考”情况下评分可靠性大幅下降，显示它们过度依赖模型固有知识而忽视给定参考。常见的基于prompt的缓解方法也不能有效解决该问题。

Conclusion: LLM作为评测判分员时存在根本性局限，一旦知识与参考冲突则偏向自有知识，导致判分失准。需要设计更有效的参考约束协议，以确保根据指定参考可靠评估。

Abstract: While large language models (LLMs) are increasingly used as automatic judges for question answering (QA) and other reference-conditioned evaluation tasks, little is known about their ability to adhere to a provided reference. We identify a critical failure mode of such reference-based LLM QA evaluation: when the provided reference conflicts with the judge model's parametric knowledge, the resulting scores become unreliable, substantially degrading evaluation fidelity. To study this phenomenon systematically, we introduce a controlled swapped-reference QA framework that induces reference-belief conflicts. Specifically, we replace the reference answer with an incorrect entity and construct diverse pairings of original and swapped references with correspondingly aligned candidate answers. Surprisingly, grading reliability drops sharply under swapped references across a broad set of judge models. We empirically show that this vulnerability is driven by judges' over-reliance on parametric knowledge, leading judges to disregard the given reference under conflict. Finally, we find that this failure persists under common prompt-based mitigation strategies, highlighting a fundamental limitation of LLM-as-a-judge evaluation and motivating reference-based protocols that enforce stronger adherence to the provided reference.

</details>


### [257] [High-Rank Structured Modulation for Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2601.07507)
*Yongkang Liu,Xing Li,Mengjie Zhao,Shanru Zhang,Zijing Wang,Qian Li,Shi Feng,Feiliang Ren,Daling Wang,Hinrich Schütze*

Main category: cs.CL

TL;DR: 本文提出了一种新的高秩结构化调制适配器SMoA，在参数量更少的情况下保持更高秩，从而提升了大模型微调的表现能力，实验优于现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 随着大模型参数规模增长，参数高效微调方法（PEFT）成为主流。但主流方法例如LoRA通过降低秩减少资源消耗，却牺牲了模型容量，导致表现受限。作者希望在参数高效的同时提升（或保持）代表性能力。

Method: 提出SMoA，用结构化的高秩子空间，对冻结的预训练权重进行调制——在不同子空间内对重要特征选择性放大/抑制，增强表达能力。配合理论分析与丰富实验，包括消融实验。

Result: SMoA在10项任务上均超过LoRA及其变体，展示了更优的性能。

Conclusion: SMoA能够在少量训练参数前提下提升模型容量与表现，对参数高效微调领域具有显著价值。

Abstract: As the number of model parameters increases, parameter-efficient fine-tuning (PEFT) has become the go-to choice for tailoring pre-trained large language models. Low-rank Adaptation (LoRA) uses a low-rank update method to simulate full parameter fine-tuning, which is widely used to reduce resource requirements. However, decreasing the rank encounters challenges with limited representational capacity when compared to full parameter fine-tuning. We present \textbf{SMoA}, a high-rank \textbf{S}tructured \textbf{MO}dulation \textbf{A}dapter that uses fewer trainable parameters while maintaining a higher rank, thereby improving the model's representational capacity and offering improved performance potential. The core idea is to freeze the original pretrained weights and selectively amplify or suppress important features of the original weights across multiple subspaces. The subspace mechanism provides an efficient way to increase the capacity and complexity of a model. We conduct both theoretical analyses and empirical studies on various tasks. Experiment results show that SMoA outperforms LoRA and its variants on 10 tasks, with extensive ablation studies validating its effectiveness.

</details>


### [258] [Controlling Multimodal Conversational Agents with Coverage-Enhanced Latent Actions](https://arxiv.org/abs/2601.07516)
*Yongqi Li,Hao Lang,Tieyun Qian,Yongbin Li*

Main category: cs.CL

TL;DR: 本论文提出了一种基于紧凑潜在动作空间的视觉-语言多模态对话系统的强化学习微调方法，显著提升了对话任务的效果。


<details>
  <summary>Details</summary>
Motivation: 多模态对话系统（MCAs）在适应不同人机交互场景时，虽然通过强化学习（RL）提升了泛化性能，但由于极其庞大的文本token空间，微调过程仍然比较困难。

Method: 本文通过学习紧凑的潜在动作空间代替原有的庞大text token空间用于RL微调。具体做法包括：利用observation learning机制构建潜在动作空间的codebook，通过未来观测估算当前潜在动作，再用以重建未来观测。为解决配对图文数据稀缺带来的覆盖不足问题，作者借助跨模态投影器，将大规模文本嵌入投射到图文嵌入空间。该投影器首先在配对图文数据上初始化，再通过创新的循环一致性损失在海量文本数据上增强鲁棒性。

Result: 基于紧凑潜在动作空间的方法，在两个对话任务和多种RL算法下均优于现有强基线方法。

Conclusion: 紧凑潜在动作空间不仅缓解了大token空间带来的优化难点，而且能更好地结合多模态和大量文本信息，有效提升对话任务表现。

Abstract: Vision-language models are increasingly employed as multimodal conversational agents (MCAs) for diverse conversational tasks. Recently, reinforcement learning (RL) has been widely explored for adapting MCAs to various human-AI interaction scenarios. Despite showing great enhancement in generalization performance, fine-tuning MCAs via RL still faces challenges in handling the extremely large text token space. To address this, we learn a compact latent action space for RL fine-tuning instead. Specifically, we adopt the learning from observation mechanism to construct the codebook for the latent action space, where future observations are leveraged to estimate current latent actions that could further be used to reconstruct future observations. However, the scarcity of paired image-text data hinders learning a codebook with sufficient coverage. Thus, we leverage both paired image-text data and text-only data to construct the latent action space, using a cross-modal projector for transforming text embeddings into image-text embeddings. We initialize the cross-modal projector on paired image-text data, and further train it on massive text-only data with a novel cycle consistency loss to enhance its robustness. We show that our latent action based method outperforms competitive baselines on two conversation tasks across various RL algorithms.

</details>


### [259] [Thinking Before Constraining: A Unified Decoding Framework for Large Language Models](https://arxiv.org/abs/2601.07525)
*Ngoc Trinh Hung Nguyen,Alonso Silva,Laith Zumot,Liubov Tupikina,Armen Aghasaryan,Mehwish Alam*

Main category: cs.CL

TL;DR: 论文提出了一种结合自然生成和结构化生成优点的新方法，在提升输出内容可解析性和准确性的同时，保持大模型的自然推理能力。


<details>
  <summary>Details</summary>
Motivation: 自然生成可以让大语言模型（LLMs）输出自由形式、富有推理的内容，但缺乏结构，难以解析和验证；而结构化生成虽然输出规范但会限制模型的推理表现。作者希望设计出结合两者优点的方法。

Method: 方法允许LLM在生成特定触发词前自由推理，当触发词出现后切换至结构化生成，实现表达力和结构化输出的兼顾。

Result: 在多个包含分类和推理的数据集上评估该方法，与完全自然生成相比，准确率最高提升27%；且只需少量额外的10-20个token。

Conclusion: 新方法同时保留了自然推理能力和结构化可靠性，比传统自然生成更准确，比完全结构化生成更灵活，具有实际应用价值。

Abstract: Natural generation allows Language Models (LMs) to produce free-form responses with rich reasoning, but the lack of guaranteed structure makes outputs difficult to parse or verify. Structured generation, or constrained decoding, addresses this drawback by producing content in standardized formats such as JSON, ensuring consistency and guaranteed-parsable outputs, but it can inadvertently restrict the model's reasoning capabilities. In this work, we propose a simple approach that combines the advantages of both natural and structured generation. By allowing LLMs to reason freely until specific trigger tokens are generated, and then switching to structured generation, our method preserves the expressive power of natural language reasoning while ensuring the reliability of structured outputs. We further evaluate our approach on several datasets, covering both classification and reasoning tasks, to demonstrate its effectiveness, achieving a substantial gain of up to 27% in accuracy compared to natural generation, while requiring only a small overhead of 10-20 extra tokens.

</details>


### [260] [From RAG to Agentic RAG for Faithful Islamic Question Answering](https://arxiv.org/abs/2601.07528)
*Gagan Bhatia,Hamdy Mubarak,Mustafa Jarrar,George Mikros,Fadi Zaraket,Mahmoud Alhirthani,Mutaz Al-Khatib,Logan Cochrane,Kareem Darwish,Rashid Yahiaoui,Firoj Alam*

Main category: cs.CL

TL;DR: 本文提出了ISLAMICFAITHQA基准，用于评估大型语言模型（LLM）在伊斯兰教问答中的幻觉和回避能力，构建了相关工具链，并提出了agentic RAG方法，在伊斯兰教语境下显著提升了模型表现。


<details>
  <summary>Details</summary>
Motivation: 标准的选择题或阅读理解式评测难以检测到模型生成的幻觉信息及在无充分证据情况下的回避能力，然而在伊斯兰教等敏感领域，虚假或不准确回答会造成严重后果，因此需要更贴切实际应用的新型评测与工具。

Method: 1）构建了一个3,810条、阿拉伯语-英语双语的ISLAMICFAITHQA生成式数据集，用于直接测量幻觉和回避。2）开发了包括2.5万对阿拉伯语证据推理对、5千条对齐偏好标注、以及约6千条古兰经经文检索语料在内的完整建模套件。3）提出了基于agentic RAG的框架，整合结构化工具调用，实现迭代证据检索与答案修订。

Result: 实验证明：在阿拉伯语为主及多语言LLM中，agentic RAG显著提升了检索正确性和模型表现，超过传统RAG方法，即使是Qwen3 4B等小模型也能达到领先成果，并且阿拉伯语-英语鲁棒性更强。

Conclusion: ISLAMICFAITHQA及配套工具和agentic RAG框架，为敏感领域的文本生成模型评估与强化（尤其是在伊斯兰教语境下）提供了有力资源，对实际及未来的相关研究都具重要价值，并将公开相应数据与工具。

Abstract: LLMs are increasingly used for Islamic question answering, where ungrounded responses may carry serious religious consequences. Yet standard MCQ/MRC-style evaluations do not capture key real-world failure modes, notably free-form hallucinations and whether models appropriately abstain when evidence is lacking. To shed a light on this aspect we introduce ISLAMICFAITHQA, a 3,810-item bilingual (Arabic/English) generative benchmark with atomic single-gold answers, which enables direct measurement of hallucination and abstention. We additionally developed an end-to-end grounded Islamic modelling suite consisting of (i) 25K Arabic text-grounded SFT reasoning pairs, (ii) 5K bilingual preference samples for reward-guided alignment, and (iii) a verse-level Qur'an retrieval corpus of $\sim$6k atomic verses (ayat). Building on these resources, we develop an agentic Quran-grounding framework (agentic RAG) that uses structured tool calls for iterative evidence seeking and answer revision. Experiments across Arabic-centric and multilingual LLMs show that retrieval improves correctness and that agentic RAG yields the largest gains beyond standard RAG, achieving state-of-the-art performance and stronger Arabic-English robustness even with a small model (i.e., Qwen3 4B). We will make the experimental resources and datasets publicly available for the community.

</details>


### [261] [A Unified Framework for Emotion Recognition and Sentiment Analysis via Expert-Guided Multimodal Fusion with Large Language Models](https://arxiv.org/abs/2601.07565)
*Jiaqi Qiao,Xiujuan Xu,Xinran Li,Yu Liu*

Main category: cs.CL

TL;DR: 本文提出了一种结合专家引导的多模态融合与大型语言模型的统一框架EGMF，用于多模态情感理解，在多个中英文数据集上取得了超越最新方法的效果。


<details>
  <summary>Details</summary>
Motivation: 多模态情感理解需要高效整合文本、音频与视觉信息，并兼顾分类与回归任务，当前方法在表征和跨语言方面仍有限。

Method: EGMF框架包含三个专家网络：细粒度专家、语义相关专家和全局上下文专家；通过分层动态门控自适应整合这些专家特征。增强后的多模态特征通过伪token注入和基于提示的方式与LLM结合，实现统一的生成式情感任务处理。此外，采用LoRA微调以提升效率。

Result: 在MELD、CHERMA、MOSEI、SIMS-V2四个中英双语基准数据集上，EGMF框架在分类和回归任务中均取得了优于SOTA的表现，显示出更强的跨语言鲁棒性。

Conclusion: EGMF能够统一高效地处理多模态情感任务，并展现了较强的通用性和跨语言能力，为多模态情感理解提供了新思路和工具，代码将公开发布。

Abstract: Multimodal emotion understanding requires effective integration of text, audio, and visual modalities for both discrete emotion recognition and continuous sentiment analysis. We present EGMF, a unified framework combining expert-guided multimodal fusion with large language models. Our approach features three specialized expert networks--a fine-grained local expert for subtle emotional nuances, a semantic correlation expert for cross-modal relationships, and a global context expert for long-range dependencies--adaptively integrated through hierarchical dynamic gating for context-aware feature selection. Enhanced multimodal representations are integrated with LLMs via pseudo token injection and prompt-based conditioning, enabling a single generative framework to handle both classification and regression through natural language generation. We employ LoRA fine-tuning for computational efficiency. Experiments on bilingual benchmarks (MELD, CHERMA, MOSEI, SIMS-V2) demonstrate consistent improvements over state-of-the-art methods, with superior cross-lingual robustness revealing universal patterns in multimodal emotional expressions across English and Chinese. We will release the source code publicly.

</details>


### [262] [ES-Mem: Event Segmentation-Based Memory for Long-Term Dialogue Agents](https://arxiv.org/abs/2601.07582)
*Huhai Zou,Tianhao Sun,Chuanjiang He,Yu Tian,Zhenyang Li,Li Jin,Nayu Liu,Jiang Zhong,Kaiwen Wei*

Main category: cs.CL

TL;DR: 本文针对对话智能体在长期对话中记忆机制存在的粒度僵化和检索表浅两个主要问题，提出了基于事件分割理论的ES-Mem方法，用动态事件分割与分层记忆结构提升语义完整性和检索精准度，实验验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有对话记忆方法粒度单一和检索扁平，容易造成信息碎片化和语境定位不准确，影响对话连贯性和长期适应性，亟需提升记忆的结构化和语义一致性。

Method: 论文提出ES-Mem框架，包含两个模块：（1）动态事件分割模块，将长对话动态划分为语义完整的事件片段；（2）分层记忆架构，利用事件边界构建多层记忆，仅依靠语义内容，还结合对话结构进行精确回溯和定位。

Result: 在两个主流记忆评测基准数据集上，ES-Mem在存储与检索表现均好于现有方法；事件分割模块在对话分割任务上展现出强泛化能力。

Conclusion: ES-Mem显著提升了对话智能体记忆的连贯性与检索精度，同时具备良好的通用性，为长程对话机制优化提供了有效方法。

Abstract: Memory is critical for dialogue agents to maintain coherence and enable continuous adaptation in long-term interactions. While existing memory mechanisms offer basic storage and retrieval capabilities, they are hindered by two primary limitations: (1) rigid memory granularity often disrupts semantic integrity, resulting in fragmented and incoherent memory units; (2) prevalent flat retrieval paradigms rely solely on surface-level semantic similarity, neglecting the structural cues of discourse required to navigate and locate specific episodic contexts. To mitigate these limitations, drawing inspiration from Event Segmentation Theory, we propose ES-Mem, a framework incorporating two core components: (1) a dynamic event segmentation module that partitions long-term interactions into semantically coherent events with distinct boundaries; (2) a hierarchical memory architecture that constructs multi-layered memories and leverages boundary semantics to anchor specific episodic memory for precise context localization. Evaluations on two memory benchmarks demonstrate that ES-Mem yields consistent performance gains over baseline methods. Furthermore, the proposed event segmentation module exhibits robust applicability on dialogue segmentation datasets.

</details>


### [263] [Proof of Time: A Benchmark for Evaluating Scientific Idea Judgments](https://arxiv.org/abs/2601.07606)
*Bingyang Ye,Shan Chen,Jingxuan Tu,Chen Liu,Zidi Xiong,Samuel Schmidgall,Danielle S. Bitterman*

Main category: cs.CL

TL;DR: 本文提出了PoT，一个可半验证的大语言模型评估框架，用于以科学领域的未来可观测信号（如引用数、研究热点转移）来衡量模型对科学创意的判断质量。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型被用来评估和预测科学研究创意，但缺乏可扩展的方法来精准评估这些判断的质量。科研领域需要跟踪和检验模型预测的长期有效性与可靠性。

Method: PoT框架基于预先冻结的科学数据快照，让模型预测“截止点”之后发生的结果（如未来论文引用、研究趋势变化），待事实发生后再验证预测的准确性。它还允许系统性地对比代理技术、提示工程和工具使用对模型判断力的影响。

Result: 基于超3万个实例，在四大基准任务领域中，实验发现：相比于不使用代理的基线，增加互动预算一般能提升代理模型的表现；工具的使用效果强依赖具体任务类型。

Conclusion: PoT为科学创意判断类的模型评测提供了未来可验证、无需大规模人工标注的可扩展方案，有助于推动科学评审任务的自动化和可靠性分析。

Abstract: Large language models are increasingly being used to assess and forecast research ideas, yet we lack scalable ways to evaluate the quality of models' judgments about these scientific ideas. Towards this goal, we introduce PoT, a semi-verifiable benchmarking framework that links scientific idea judgments to downstream signals that become observable later (e.g., citations and shifts in researchers' agendas). PoT freezes a pre-cutoff snapshot of evidence in an offline sandbox and asks models to forecast post-cutoff outcomes, enabling verifiable evaluation when ground truth arrives, scalable benchmarking without exhaustive expert annotation, and analysis of human-model misalignment against signals such as peer-review awards. In addition, PoT provides a controlled testbed for agent-based research judgments that evaluate scientific ideas, comparing tool-using agents to non-agent baselines under prompt ablations and budget scaling. Across 30,000+ instances spanning four benchmark domains, we find that, compared with non-agent baselines, higher interaction budgets generally improve agent performance, while the benefit of tool use is strongly task-dependent. By combining time-partitioned, future-verifiable targets with an offline sandbox for tool use, PoT supports scalable evaluation of agents on future-facing scientific idea judgment tasks.

</details>


### [264] [Integrating Machine-Generated Short Descriptions into the Wikipedia Android App: A Pilot Deployment of Descartes](https://arxiv.org/abs/2601.07631)
*Marija Šakota,Dmitry Brant,Cooltey Feng,Shay Nowick,Amal Ramadan,Robin Schoenbaechler,Joseph Seddon,Jazmin Tanner,Isaac Johnson,Robert West*

Main category: cs.CL

TL;DR: 本论文报告了多语言短描述生成模型Descartes在维基百科Android应用中的试点部署实验，结果显示模型生成的描述质量接近人工且被编辑者采用。


<details>
  <summary>Details</summary>
Motivation: 维基百科的短描述在不同语言和主题下覆盖率不均，影响用户体验。因此，研究自动生成高质量描述的可行性，以帮助编辑者弥补内容缺口。

Method: 作者在维基百科Android应用中部署了Descartes模型，为编辑者编辑短描述时提供自动建议，覆盖12种语言、3900多篇文章和375名编辑者。通过收集用户采用、修改、评价及后续撤销等数据，评估模型效果。

Result: Descartes生成的描述中有90%被采纳后获得至少3分（满分5分）的质量评分，平均分与人工编写的描述相当。编辑者既直接采用也会修改建议，撤销及举报率较低。

Conclusion: Descartes模型生成的短描述能够有效支持编辑者减少内容差距，但实际部署需关注系统延迟、语言特异性不足与敏感话题防护等问题。

Abstract: Short descriptions are a key part of the Wikipedia user experience, but their coverage remains uneven across languages and topics. In previous work, we introduced Descartes, a multilingual model for generating short descriptions. In this report, we present the results of a pilot deployment of Descartes in the Wikipedia Android app, where editors were offered suggestions based on outputs from Descartes while editing short descriptions. The experiment spanned 12 languages, with over 3,900 articles and 375 editors participating. Overall, 90% of accepted Descartes descriptions were rated at least 3 out of 5 in quality, and their average ratings were comparable to human-written ones. Editors adopted machine suggestions both directly and with modifications, while the rate of reverts and reports remained low. The pilot also revealed practical considerations for deployment, including latency, language-specific gaps, and the need for safeguards around sensitive topics. These results indicate that Descartes's short descriptions can support editors in reducing content gaps, provided that technical, design, and community guardrails are in place.

</details>


### [265] [PlaM: Training-Free Plateau-Guided Model Merging for Better Visual Grounding in MLLMs](https://arxiv.org/abs/2601.07645)
*Zijing Wang,Yongkang Liu,Mingyang Wang,Ercong Nie,Deyuan Chen,Zhengjie Zhao,Shi Feng,Daling Wang,Xiaocui Yang,Yifei Zhang,Hinrich Schütze*

Main category: cs.CL

TL;DR: 多模态大语言模型（MLLMs）在经过多模态指令微调后，文本推理能力往往下降。本文提出了一种无需额外训练的模型融合框架，有效缓解了此类推理能力退化问题，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: MLLM依赖基础语言模型的推理能力，但多模态微调会削弱文本推理力，影响整体性能。需要方法在不牺牲多模态优势的前提下，恢复或提升推理效果。

Method: 通过分层视觉token掩码，揭示MLLM三个阶段的推理模式，并提出基于平台期引导的模型融合方法，有针对性地将基础语言模型参数注入MLLM，过程无需再训练。

Result: 在五个MLLM和九个基准测试上，提出的方法有效提升模型性能。注意力分析显示模型融合后，注意力由分散转向聚焦于任务相关区域。

Conclusion: 无需重新训练，通过模型融合可显著缓解MLLM推理能力退化，提升性能，为多模态模型优化提供了新方向。

Abstract: Multimodal Large Language Models (MLLMs) rely on strong linguistic reasoning inherited from their base language models. However, multimodal instruction fine-tuning paradoxically degrades this text's reasoning capability, undermining multimodal performance. To address this issue, we propose a training-free framework to mitigate this degradation. Through layer-wise vision token masking, we reveal a common three-stage pattern in multimodal large language models: early-modal separation, mid-modal alignment, and late-modal degradation. By analyzing the behavior of MLLMs at different stages, we propose a plateau-guided model merging method that selectively injects base language model parameters into MLLMs. Experimental results based on five MLLMs on nine benchmarks demonstrate the effectiveness of our method. Attention-based analysis further reveals that merging shifts attention from diffuse, scattered patterns to focused localization on task-relevant visual regions. Our repository is on https://github.com/wzj1718/PlaM.

</details>


### [266] [Order in the Evaluation Court: A Critical Analysis of NLG Evaluation Trends](https://arxiv.org/abs/2601.07648)
*Jing Yang,Nils Feldhus,Salar Mohtaj,Leonhard Hennig,Qianli Wang,Eleni Metheniti,Sherzod Hakimov,Charlott Jakob,Veronika Solopova,Konrad Rieck,David Schlangen,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 本文对自然语言生成（NLG）领域评测方式的演进进行了系统性综述，分析了6年内14171篇论文的评测方法发展趋势，揭示了评测实践中的主要分歧和不足，并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: NLG评测手段快速发展，新评测指标和大模型裁判（LaaJ）方法涌现，但仍以人工评测为金标准。当前缺乏系统性的大规模分析，难以掌握各类NLG任务中评测手段的演变及优劣。因此，迫切需要分析全行业对评测手段的采用与实际效果。

Method: 作者设计自动信息抽取方案，从ACL、EMNLP、NAACL、INLG四大会议近6年共14171篇论文中，抽取涉及评测方法（覆盖自动指标、LaaJ、人工评测）的元数据，系统分析不同任务、评测方法的使用趋势和相互关系。

Result: 研究发现：(1) 对话生成迅速采用LaaJ评测（2025年占比超40%），机器翻译仍依赖传统n-gram指标，问答任务则人工评测占比明显下降；(2) 普通指标（BLEU、ROUGE等）在多任务中被广泛使用，尽管缺乏判别力，也未被充分论证；(3) LaaJ与人工评测关注点显著不同，两者比较和验证稀缺（<8%论文涉及），且相关性一般。

Conclusion: 当前NLG评测实践存在明显分歧和惯性，LaaJ与人工评测不可互换，传统指标亟待反思与改进。建议未来研究提升评测严谨性，加强对LaaJ与人工评测的比对和方法创新，以推动NLG评测科学化发展。

Abstract: Despite advances in Natural Language Generation (NLG), evaluation remains challenging. Although various new metrics and LLM-as-a-judge (LaaJ) methods are proposed, human judgment persists as the gold standard. To systematically review how NLG evaluation has evolved, we employ an automatic information extraction scheme to gather key information from NLG papers, focusing on different evaluation methods (metrics, LaaJ and human evaluation). With extracted metadata from 14,171 papers across four major conferences (ACL, EMNLP, NAACL, and INLG) over the past six years, we reveal several critical findings: (1) Task Divergence: While Dialogue Generation demonstrates a rapid shift toward LaaJ (>40% in 2025), Machine Translation remains locked into n-gram metrics, and Question Answering exhibits a substantial decline in the proportion of studies conducting human evaluation. (2) Metric Inertia: Despite the development of semantic metrics, general-purpose metrics (e.g., BLEU, ROUGE) continue to be widely used across tasks without empirical justification, often lacking the discriminative power to distinguish between specific quality criteria. (3) Human-LaaJ Divergence: Our association analysis challenges the assumption that LLMs act as mere proxies for humans; LaaJ and human evaluations prioritize very different signals, and explicit validation is scarce (<8% of papers comparing the two), with only moderate to low correlation. Based on these observations, we derive practical recommendations to improve the rigor of future NLG evaluation.

</details>


### [267] [Adaptive Layer Selection for Layer-Wise Token Pruning in LLM Inference](https://arxiv.org/abs/2601.07667)
*Rei Taniguchi,Yuyang Dong,Makoto Onizuka,Chuan Xiao*

Main category: cs.CL

TL;DR: 本文提出ASL方法，通过自适应地选择KV缓存层，实现大语言模型(LM)推理时KV内存的高效减少，无需训练，同时保持性能和速度，在多个基准测试上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型(LLM)应用普及，推理时KV（Key-Value）缓存占用成为性能瓶颈。主流的分层token裁剪虽有效，但分层方式生硬，面对复杂任务（如KV检索）准确性下降，缺乏灵活适配不同任务的能力，因此需要一种能动态自适应的KV缓存裁剪方法。

Method: 提出ASL，一种无需训练、通过计算attention score排序后token rank的方差，自适应选择KV缓存裁剪层的方法。ASL可在prefilling阶段工作，并与如SnapKV等现有KV cache裁剪方法联合使用以进一步优化解码阶段。

Result: 实验证明，ASL在InfiniteBench、RULER和NIAH等多个评测基准上，在“one-shot”token选择机制下，比最先进的分层token选择方法在准确率、解码速度和KV缓存裁剪比上均有更好表现。

Conclusion: ASL实现了无需训练的自适应KV缓存层选择，兼顾不同任务下的性能和KV预算需求，超越当前主流方法，是大语言模型高效推理内存管理的有力方案。

Abstract: Due to the prevalence of large language models (LLMs), key-value (KV) cache reduction for LLM inference has received remarkable attention. Among numerous works that have been proposed in recent years, layer-wise token pruning approaches, which select a subset of tokens at particular layers to retain in KV cache and prune others, are one of the most popular schemes. They primarily adopt a set of pre-defined layers, at which tokens are selected. Such design is inflexible in the sense that the accuracy significantly varies across tasks and deteriorates in harder tasks such as KV retrieval. In this paper, we propose ASL, a training-free method that adaptively chooses the selection layer for KV cache reduction, exploiting the variance of token ranks ordered by attention score. The proposed method balances the performance across different tasks while meeting the user-specified KV budget requirement. ASL operates during the prefilling stage and can be jointly used with existing KV cache reduction methods such as SnapKV to optimize the decoding stage. By evaluations on the InfiniteBench, RULER, and NIAH benchmarks, we show that equipped with one-shot token selection, where tokens are selected at a layer and propagated to deeper layers, ASL outperforms state-of-the-art layer-wise token selection methods in accuracy while maintaining decoding speed and KV cache reduction.

</details>


### [268] [Exploring the Meta-level Reasoning of Large Language Models via a Tool-based Multi-hop Tabular Question Answering Task](https://arxiv.org/abs/2601.07696)
*Nick Ferguson,Alan Bundy,Kwabena Nuamah*

Main category: cs.CL

TL;DR: 该论文提出了一个基于地缘政治指标的新型问答任务，用于分析大模型的元层次推理与对象层次推理能力，并发现大模型具有一定的元推理能力，但在任务理解和数值计算上仍有不足。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）在推理能力上的研究日益深入，但'推理'本身定义模糊且多样，论文希望通过系统性分类（元层次与对象层次推理）提高对模型推理能力的理解与评估。

Method: 作者设计了一个依赖地缘政治指标（如不同国家不同年份的数值数据）的新型问答任务，需要模型分解问题、检索数据并进行运算。通过分析LLM在选择解决问题工具时所表现出的元推理能力，并用“关键操作”作为量化工具调用输出的依据。

Result: LLM在元层次推理任务中表现良好，但在部分任务理解方面存在缺陷。实验还发现：n-shot提示对准确率影响较小，错误提示对模型表现影响不大，同时再次印证了LLM在数值处理上的不足。

Conclusion: LLM在某些复杂任务中具备较强的元推理能力，但任务理解和数学运算依然是短板，相关结论对其他领域的任务具有一定的推广意义，也指出了当前方法的局限。

Abstract: Recent advancements in Large Language Models (LLMs) are increasingly focused on "reasoning" ability, a concept with many overlapping definitions in the LLM discourse. We take a more structured approach, distinguishing meta-level reasoning (denoting the process of reasoning about intermediate steps required to solve a task) from object-level reasoning (which concerns the low-level execution of the aforementioned steps.) We design a novel question answering task, which is based around the values of geopolitical indicators for various countries over various years. Questions require breaking down into intermediate steps, retrieval of data, and mathematical operations over that data. The meta-level reasoning ability of LLMs is analysed by examining the selection of appropriate tools for answering questions. To bring greater depth to the analysis of LLMs beyond final answer accuracy, our task contains 'essential actions' against which we can compare the tool call output of LLMs to infer the strength of reasoning ability. We find that LLMs demonstrate good meta-level reasoning on our task, yet are flawed in some aspects of task understanding. We find that n-shot prompting has little effect on accuracy; error messages encountered do not often deteriorate performance; and provide additional evidence for the poor numeracy of LLMs. Finally, we discuss the generalisation and limitation of our findings to other task domains.

</details>


### [269] [Emotional Support Evaluation Framework via Controllable and Diverse Seeker Simulator](https://arxiv.org/abs/2601.07698)
*Chaewon Heo,Cheyon Jin,Yohan Jo*

Main category: cs.CL

TL;DR: 该论文提出了一种基于心理和语言特征、可控性更强的求助者模拟器，用于更真实和多样化地测试情感支持聊天机器人。新模拟器提升了行为多样性和特定画像的可控度，揭示了现有机器人模型在现实场景下的潜在问题。


<details>
  <summary>Details</summary>
Motivation: 现有求助者模拟器过于单一与合作，无法反映真实世界的行为多样性，也缺乏对不同求助者画像的可控性，导致情感支持聊天机器人的评估不够全面准确。

Method: 作者提出一种基于九种心理和语言特征驱动的可控求助者模拟器，并采用混合专家（Mixture-of-Experts, MoE）架构，在Reddit真实对话数据上训练模型，实现多样化行为和画像的精准控制。

Result: 新模拟器在画像一致性和行为多样性方面均优于现有方法，并能揭示7种主流情感支持机器人在更真实压力测试下的性能退化。

Conclusion: 该方法有效提升了情感支持机器人评估的真实性和挑战性，对行业和学术界开发更健壮的情感支持系统具有重要意义。

Abstract: As emotional support chatbots have recently gained significant traction across both research and industry, a common evaluation strategy has emerged: use help-seeker simulators to interact with supporter chatbots. However, current simulators suffer from two critical limitations: (1) they fail to capture the behavioral diversity of real-world seekers, often portraying them as overly cooperative, and (2) they lack the controllability required to simulate specific seeker profiles. To address these challenges, we present a controllable seeker simulator driven by nine psychological and linguistic features that underpin seeker behavior. Using authentic Reddit conversations, we train our model via a Mixture-of-Experts (MoE) architecture, which effectively differentiates diverse seeker behaviors into specialized parameter subspaces, thereby enhancing fine-grained controllability. Our simulator achieves superior profile adherence and behavioral diversity compared to existing approaches. Furthermore, evaluating 7 prominent supporter models with our system uncovers previously obscured performance degradations. These findings underscore the utility of our framework in providing a more faithful and stress-tested evaluation for emotional support chatbots.

</details>


### [270] [Is Agentic RAG worth it? An experimental comparison of RAG approaches](https://arxiv.org/abs/2601.07711)
*Pietro Ferrazzi,Milica Cvjeticanin,Alessio Piraccini,Davide Giannuzzi*

Main category: cs.CL

TL;DR: 本文比较了两种主流检索增强生成（RAG）系统：增强型RAG和具备自主决策能力的Agentic RAG，并针对不同场景进行了广泛实验评估，总结两者的优缺点与适用场景。


<details>
  <summary>Details</summary>
Motivation: 传统RAG架构存在检索质量低、查询识别不佳、检索匹配弱以及生成器成本高等一系列问题，促使学界提出了增强型RAG与自我反思的Agentic RAG新范式，但这两种方案在实际应用中孰优孰劣尚无定论。

Method: 本文通过实证方法，在多个应用场景和评测维度下，系统对比了增强型RAG与Agentic RAG的效果与成本性能，对两种机制的主要特性进行了深入对比分析。

Result: 实验数据揭示了增强型RAG和Agentic RAG在性能、成本和灵活性等方面的权衡点，总结了各自在不同应用场景下的优势与不足。

Conclusion: 研究为实际应用中如何选择和部署RAG系统提供了具体参考，指导在兼顾成本与效果下选用最合适的RAG范式。

Abstract: Retrieval-Augmented Generation (RAG) systems are usually defined by the combination of a generator and a retrieval component that extracts textual context from a knowledge base to answer user queries. However, such basic implementations exhibit several limitations, including noisy or suboptimal retrieval, misuse of retrieval for out-of-scope queries, weak query-document matching, and variability or cost associated with the generator. These shortcomings have motivated the development of "Enhanced" RAG, where dedicated modules are introduced to address specific weaknesses in the workflow. More recently, the growing self-reflective capabilities of Large Language Models (LLMs) have enabled a new paradigm, which we refer to as "Agentic" RAG. In this approach, the LLM orchestrates the entire process-deciding which actions to perform, when to perform them, and whether to iterate-thereby reducing reliance on fixed, manually engineered modules. Despite the rapid adoption of both paradigms, it remains unclear which approach is preferable under which conditions. In this work, we conduct an extensive, empirically driven evaluation of Enhanced and Agentic RAG across multiple scenarios and dimensions. Our results provide practical insights into the trade-offs between the two paradigms, offering guidance on selecting the most effective RAG design for real-world applications, considering both costs and performance.

</details>


### [271] [Structure First, Reason Next: Enhancing a Large Language Model using Knowledge Graph for Numerical Reasoning in Financial Documents](https://arxiv.org/abs/2601.07754)
*Aryan Mishra,Akash Anil*

Main category: cs.CL

TL;DR: 本文针对金融文档中数值推理任务，提出通过知识图谱（KG）辅助大语言模型（LLM）提升数值推理能力，实验表明该框架在FinQA数据集上将LLM执行准确率提升了约12%。


<details>
  <summary>Details</summary>
Motivation: 金融文档包含大量复杂的数值信息，数值推理对于金融分析非常关键，但现有LLM在处理金融报告中的数值识别和运算时表现有限，需要结合结构化信息以提升数值推理表现。

Method: 提出了一种框架，将从金融文档中抽取且自动结构化的知识图谱与LLM结合用于数值推理。知识图谱根据所提出的模式从文档中抽取，再辅助LLM进行金融问答任务。

Result: 在FinQA基准数据集上，使用开源LLM（Llama 3.1 8B Instruct）进行实验，新框架相较于原生LLM使执行准确率提升了约12%。

Conclusion: 将文档内在结构化信息通过知识图谱与LLM融合，能够有效提高金融数值推理的能力，对金融自动化分析系统具有显著应用价值。

Abstract: Numerical reasoning is an important task in the analysis of financial documents. It helps in understanding and performing numerical predictions with logical conclusions for the given query seeking answers from financial texts. Recently, Large Language Models (LLMs) have shown promising results in multiple Question-Answering (Q-A) systems with the capability of logical reasoning. As documents related to finance often consist of long and complex financial contexts, LLMs appear well-suited for building high-quality automated financial question-answering systems. However, LLMs often face challenges in accurately processing the various numbers within financial reports. Extracting numerical data from unstructured text and semi-structured tables, and reliably performing accurate calculations, remains a significant bottleneck for numerical reasoning in most state-of-the-art LLMs. Recent studies have shown that structured data augmentations, such as Knowledge Graphs (KGs), have notably improved the predictions of LLMs along with logical explanations. Thus, it is an important requirement to consider inherent structured information in financial reports while using LLMs for various financial analytics. This paper proposes a framework to incorporate structured information using KGs along with LLM predictions for numerical reasoning tasks. The KGs are extracted using a proposed schema inherently from the document under processing. We evaluated our proposed framework over the benchmark data FinQA, using an open-source LLM, namely Llama 3.1 8B Instruct. We observed that the proposed framework improved execution accuracy by approximately 12% relative to the vanilla LLM.

</details>


### [272] [Contrastive Learning with Narrative Twins for Modeling Story Salience](https://arxiv.org/abs/2601.07765)
*Igor Sterner,Alex Lascarides,Frank Keller*

Main category: cs.CL

TL;DR: 该论文提出了一种基于对比学习的新方法，通过学习叙事“孪生体”（同情节但表述不同的故事）获得故事嵌入，提升对叙事重点事件的识别能力。


<details>
  <summary>Details</summary>
Motivation: 理解故事叙述时，识别哪些事件对故事推进最为关键（即叙事显著性）是一个核心任务；现有方法常忽视叙事结构而更关注表层特征，因此有改进空间。

Method: 作者提出利用叙事孪生体，通过对比学习训练模型辨别同一情节的不同故事，与仅表面相似但情节不同的干扰故事区分。用此方法学到的故事嵌入，结合叙事学驱动的操作（删除、移动、打乱、摘要）衡量事件显著性。

Result: 在ROCStories短篇故事和Wikipedia长篇剧情摘要上，所提模型优于基于掩码语言模型的基线方法。此外，'摘要'操作对显著句子的识别最为有效。缺少孪生体时，可用随机dropout生成替代；有效干扰项既可用LLM生成，也可内部采样原文片段。

Conclusion: 基于对比学习的故事表示方法优于传统表征，通过孪生体机制显著提升核心事件识别能力，为叙事智能理解和自动文摘等应用奠定基础。

Abstract: Understanding narratives requires identifying which events are most salient for a story's progression. We present a contrastive learning framework for modeling narrative salience that learns story embeddings from narrative twins: stories that share the same plot but differ in surface form. Our model is trained to distinguish a story from both its narrative twin and a distractor with similar surface features but different plot. Using the resulting embeddings, we evaluate four narratologically motivated operations for inferring salience (deletion, shifting, disruption, and summarization). Experiments on short narratives from the ROCStories corpus and longer Wikipedia plot summaries show that contrastively learned story embeddings outperform a masked-language-model baseline, and that summarization is the most reliable operation for identifying salient sentences. If narrative twins are not available, random dropout can be used to generate the twins from a single story. Effective distractors can be obtained either by prompting LLMs or, in long-form narratives, by using different parts of the same story.

</details>


### [273] [Enhancing Self-Correction in Large Language Models through Multi-Perspective Reflection](https://arxiv.org/abs/2601.07780)
*Mariana Costa,Alberlucia Rafael Soarez,Daniel Kim,Camila Ferreira*

Main category: cs.CL

TL;DR: 本文提出了一种多维度自我反思链式思维（PR-CoT）方法，通过引导大模型从多个角度自我评估推理过程，提高结果的一致性、准确性及自我纠错能力，显著优于传统单一链式思维方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于Chain-of-Thought（CoT, 链式思维）的提示方法虽然提升了大模型的推理能力，但在处理复杂或敏感任务时，仍存在一致性不足、准确度有限和自我纠错能力弱等问题，现有的一维自反思方法提升有限。

Method: 作者提出PR-CoT方法：在初步链式思维推理后，通过提示工程让模型从逻辑一致性、信息完整性、偏见/伦理、备选方案等多个维度对自身推理进行结构化反思，以此精炼并修正初始答案。该方法完全基于提示工程，无需模型重新训练。

Result: 在算术、常识、伦理决策、逻辑推理等任务，以及GPT-3.5和GPT-4模型上，PR-CoT方法在逻辑一致性和错误修正上均明显优于传统CoT及已有反思方法，尤其在伦理决策等复杂领域表现突出。消融实验、人类评测和定性分析均证明了各反思视角的贡献与方法整体有效性。

Conclusion: 多维度自反思链式思维有效提升了大语言模型的推理可靠性，为实现更健壮、可信AI推理提供了新范式。

Abstract: While Chain-of-Thought (CoT) prompting advances LLM reasoning, challenges persist in consistency, accuracy, and self-correction, especially for complex or ethically sensitive tasks. Existing single-dimensional reflection methods offer insufficient improvements. We propose MyGO Poly-Reflective Chain-of-Thought (PR-CoT), a novel methodology employing structured multi-perspective reflection. After initial CoT, PR-CoT guides the LLM to self-assess its reasoning across multiple predefined angles: logical consistency, information completeness, biases/ethics, and alternative solutions. Implemented purely via prompt engineering, this process refines the initial CoT into a more robust and accurate final answer without model retraining. Experiments across arithmetic, commonsense, ethical decision-making, and logical puzzles, using GPT-three point five and GPT-four models, demonstrate PR-CoT's superior performance. It significantly outperforms traditional CoT and existing reflection methods in logical consistency and error correction, with notable gains in nuanced domains like ethical decision-making. Ablation studies, human evaluations, and qualitative analyses further validate the contribution of each reflection perspective and the overall efficacy of our poly-reflective paradigm in fostering more reliable LLM reasoning.

</details>


### [274] [Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning](https://arxiv.org/abs/2601.07782)
*Wei Fang,James Glass*

Main category: cs.CL

TL;DR: 本文提出TOOLQP框架，通过迭代式查询规划提升大规模工具库中LLM agent的工具检索效果，显著超过传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统稠密检索方法在面对复杂请求和大规模、动态工具库时表现不佳，主要原因在于用户目标与工具文档表达之间存在语义鸿沟，以及固定长度嵌入难以处理工具组合的复杂性。

Method: 提出TOOLQP框架，将检索问题分解为子任务，采用迭代查询方案动态生成针对性检索请求。训练方法包括合成查询轨迹训练和基于可验证奖励的强化学习优化。

Result: 实验结果显示，TOOLQP在零样本泛化、对不同检索器的适应性和后续智能体执行等方面均取得了最优性能。

Conclusion: TOOLQP有效提升了LLM agent在大规模工具库中的操作能力，为复杂任务的自动化检索与执行提供了更强能力。

Abstract: LLM agents operating over massive, dynamic tool libraries rely on effective retrieval, yet standard single-shot dense retrievers struggle with complex requests. These failures primarily stem from the disconnect between abstract user goals and technical documentation, and the limited capacity of fixed-size embeddings to model combinatorial tool compositions. To address these challenges, we propose TOOLQP, a lightweight framework that models retrieval as iterative query planning. Instead of single-shot matching, TOOLQP decomposes instructions into sub-tasks and dynamically generates queries to interact with the retriever, effectively bridging the semantic gap by targeting the specific sub-tasks required for composition. We train TOOLQP using synthetic query trajectories followed by optimization via Reinforcement Learning with Verifiable Rewards (RLVR). Experiments demonstrate that TOOLQP achieves state-of-the-art performance, exhibiting superior zero-shot generalization, robustness across diverse retrievers, and significant improvements in downstream agentic execution.

</details>


### [275] [Kinship Data Benchmark for Multi-hop Reasoning](https://arxiv.org/abs/2601.07794)
*Tianda Sun,Dimitar Kazakov*

Main category: cs.CL

TL;DR: KinshipQA是一个用于测试大语言模型多跳推理能力的新基准，侧重于亲属关系推理，通过自动生成多样、真实、文化敏感的家谱数据，系统评估多种LLM在不同文化和推理深度下的表现。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在多跳推理任务（需要结合多条信息得出结论）上表现不稳定，缺少针对复杂关系网络、特别是亲属关系推理的专门测试数据和基准。因此，作者设计KinshipQA基准，用于细致考察LLM在现实、复杂且受文化影响的亲属关系推理中的能力差异。

Method: 作者提出了一套生成流程，可以大规模、按需生成带有特定婚姻和家族结构约束的家谱数据，覆盖多种文化背景。基于这些数据，作者设计了文本推理任务，要求模型基于隐含的关系链进行推断。随后，他们用六个主流LLM（包括开源和闭源）在统一zero-shot设置和确定性解码下进行了评测，用准确匹配和集合匹配等指标进行表现对比。

Result: KinshipQA测试结果显示，不同模型间在亲属关系多跳推理方面表现差异显著；相同模型在不同文化设置下也体现出系统性区别，说明该基准有效揭示了模型多跳推理潜力和局限。

Conclusion: KinshipQA作为新基准能系统性检测LLM多跳推理能力、文化泛化性和推理深度敏感性，对相关模型改进和研究具有推动意义。

Abstract: Large language models (LLMs) are increasingly evaluated on their ability to perform multi-hop reasoning, i.e., to combine multiple pieces of information into a coherent inference. We introduce KinshipQA, a benchmark designed to probe this capability through reasoning over kinship relations. The central contribution of our work is a generative pipeline that produces, on demand, large-scale, realistic, and culture-specific genealogical data: collections of interconnected family trees that satisfy explicit marriage constraints associated with different kinship systems. This allows task difficulty, cultural assumptions, and relational depth to be systematically controlled and varied. From these genealogies, we derive textual inference tasks that require reasoning over implicit relational chains. We evaluate the resulting benchmark using six state-of-the-art LLMs, spanning both open-source and closed-source models, under a uniform zero-shot protocol with deterministic decoding. Performance is measured using exact-match and set-based metrics. Our results demonstrate that KinshipQA yields a wide spread of outcomes and exposes systematic differences in multi-hop reasoning across models and cultural settings.

</details>


### [276] [Learning Through Dialogue: Unpacking the Dynamics of Human-LLM Conversations on Political Issues](https://arxiv.org/abs/2601.07796)
*Shaz Furniturewala,Gerard Christopher Yeo,Kokil Jaidka*

Main category: cs.CL

TL;DR: 本研究分析397次人类与大型语言模型（LLM）就社会政治议题的对话，探讨LLM解释如何影响用户政治知识与信心。结果发现，LLM对话带来的学习成效取决于用户的互动与参与状态，而非单纯解释质量。


<details>
  <summary>Details</summary>
Motivation: 随着LLM被广泛用于学习对话，研究者关注其如何通过互动提升用户的学习效果，尤其在政治知识和自信方面，但相关互动机制尚不明确。

Method: 本研究收集并分析了397次人-LLM关于社会政治议题的对话内容，考察了LLM与用户的语言及互动特征，并采用中介和调节分析探讨LLM解释丰富性对知识和信心变化的作用机制。

Result: 分析发现，LLM解释的丰富性可部分通过促进用户反思提升其信心，而知识获得完全取决于用户的认知参与。此外，这些效果受到用户政治效能感影响，高效能用户需通过解决不确定性及延长互动来获得更多提升。

Conclusion: LLM学习成效依赖于其与用户的互动成就，而非单纯解释优劣。设计人机对话系统需重视LLM解释与用户参与状态的匹配，以促进更有效的学习。

Abstract: Large language models (LLMs) are increasingly used as conversational partners for learning, yet the interactional dynamics supporting users' learning and engagement are understudied. We analyze the linguistic and interactional features from both LLM and participant chats across 397 human-LLM conversations about socio-political issues to identify the mechanisms and conditions under which LLM explanations shape changes in political knowledge and confidence. Mediation analyses reveal that LLM explanatory richness partially supports confidence by fostering users' reflective insight, whereas its effect on knowledge gain operates entirely through users' cognitive engagement. Moderation analyses show that these effects are highly conditional and vary by political efficacy. Confidence gains depend on how high-efficacy users experience and resolve uncertainty. Knowledge gains depend on high-efficacy users' ability to leverage extended interaction, with longer conversations benefiting primarily reflective users. In summary, we find that learning from LLMs is an interactional achievement, not a uniform outcome of better explanations. The findings underscore the importance of aligning LLM explanatory behavior with users' engagement states to support effective learning in designing Human-AI interactive systems.

</details>


### [277] [The Confidence Trap: Gender Bias and Predictive Certainty in LLMs](https://arxiv.org/abs/2601.07806)
*Ahmed Sabir,Markus Kängsepp,Rajesh Sharma*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLM）在处理敏感领域时，模型置信分数与公平性和偏见之间的对应关系，重点分析了性别偏见下置信度的校准情况，并提出了新的性别公平性度量指标。


<details>
  <summary>Details</summary>
Motivation: 随着LLM应用于越来越多的敏感场景，学界和业界对于模型预测置信度是否能反映模型的公平性和偏见（尤其是性别偏见）产生了关注。了解置信度校准与公平性的关系，有助于更好地指导LLM在关键场景下的伦理部署。

Method: 研究以六个主流LLM为对象，分析它们在性别化指代消解（gendered pronoun resolution）场景下的概率置信度校准表现，并设计了新的性别公平度量指标Gender-ECE用于评估模型在性别相关任务中的校准程度。

Result: 实验结果显示，这六个模型在性别偏见基准下表现不同，其中Gemma-2模型的置信度校准效果最差。

Conclusion: 本文为LLM置信度校准提供了公平性视角的评估方法，并提出了新的性别校准指标Gender-ECE，对模型的伦理安全部署具有参考价值。

Abstract: The increased use of Large Language Models (LLMs) in sensitive domains leads to growing interest in how their confidence scores correspond to fairness and bias. This study examines the alignment between LLM-predicted confidence and human-annotated bias judgments. Focusing on gender bias, the research investigates probability confidence calibration in contexts involving gendered pronoun resolution. The goal is to evaluate if calibration metrics based on predicted confidence scores effectively capture fairness-related disparities in LLMs. The results show that, among the six state-of-the-art models, Gemma-2 demonstrates the worst calibration according to the gender bias benchmark. The primary contribution of this work is a fairness-aware evaluation of LLMs' confidence calibration, offering guidance for ethical deployment. In addition, we introduce a new calibration metric, Gender-ECE, designed to measure gender disparities in resolution tasks.

</details>


### [278] [Reference Games as a Testbed for the Alignment of Model Uncertainty and Clarification Requests](https://arxiv.org/abs/2601.07820)
*Manar Ali,Judith Sieker,Sina Zarrieß,Hendrik Buschmeier*

Main category: cs.CL

TL;DR: 本文研究了语言模型是否能够像人类对话者一样，在不确定时主动请求澄清，但结果显示现有视觉-语言模型在这一能力上表现有限。


<details>
  <summary>Details</summary>
Motivation: 在人类对话中，听众遇到疑惑时通常会主动请求澄清，而目前尚不清楚语言模型能否具备类似的能力，即识别自身不确定性并作出澄清请求。因此，需要寻找可控且易于度量的测试环境来检验这一点。

Method: 作者提出采用参考游戏（reference games）作为测试环境，并对三种视觉-语言模型进行评估，比较模型在标准参考识别任务和被要求在不确定时主动请求澄清之间的表现差异。

Result: 实验结果表明，即使在简单任务中，这些模型依然难以识别自身的不确定性，并且无法很好地将不确定性转化为适当的澄清行为。

Conclusion: 参考游戏为考察视觉/语言模型交互能力提供了有价值的测试平台，但现有模型在识别并表达自身不确定性方面仍面临巨大挑战。

Abstract: In human conversation, both interlocutors play an active role in maintaining mutual understanding. When addressees are uncertain about what speakers mean, for example, they can request clarification. It is an open question for language models whether they can assume a similar addressee role, recognizing and expressing their own uncertainty through clarification. We argue that reference games are a good testbed to approach this question as they are controlled, self-contained, and make clarification needs explicit and measurable. To test this, we evaluate three vision-language models comparing a baseline reference resolution task to an experiment where the models are instructed to request clarification when uncertain. The results suggest that even in such simple tasks, models often struggle to recognize internal uncertainty and translate it into adequate clarification behavior. This demonstrates the value of reference games as testbeds for interaction qualities of (vision and) language models.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [279] [Walk the PLANC: Physics-Guided RL for Agile Humanoid Locomotion on Constrained Footholds](https://arxiv.org/abs/2601.06286)
*Min Dai,William D. Compton,Junheng Li,Lizhi Yang,Aaron D. Ames*

Main category: cs.RO

TL;DR: 论文提出了一种结合物理规划与强化学习的新方法，实现了在复杂地形（如跳石、狭窄踏板）上更鲁棒和可靠的人形机器人行走。


<details>
  <summary>Details</summary>
Motivation: 传统优化/控制方法在处理精准约束上表现优异，但高度依赖地形的精确感知，对感知误差极度敏感；而端到端强化学习在应对扰动和建模误差时有优势，但很难学习到在不连续地形下精细的步伐和踏点控制。两者各有短板，亟需结构化引导学习的新策略。

Method: 提出一个运动框架：使用简化的步伐规划器生成动态一致的运动目标，作为RL训练的引导，利用控制Lyapunov函数（CLF）奖励进行学习。这样结构化地引导RL，使其融合了物理可解释规划和数据驱动自适应的优点。

Result: 该方法在现实机器人硬件上验证，能在跳石等不连续复杂地形上实现精确、灵活和高可靠性的步行，显著优于常规的无模型强化学习方法。

Conclusion: 通过在强化学习训练中引入基于物理结构的规划器，实现了对复杂约束地形的有效行走，大幅提升了机器人运动的鲁棒性和可靠性。

Abstract: Bipedal humanoid robots must precisely coordinate balance, timing, and contact decisions when locomoting on constrained footholds such as stepping stones, beams, and planks -- even minor errors can lead to catastrophic failure. Classical optimization and control pipelines handle these constraints well but depend on highly accurate mathematical representations of terrain geometry, making them prone to error when perception is noisy or incomplete. Meanwhile, reinforcement learning has shown strong resilience to disturbances and modeling errors, yet end-to-end policies rarely discover the precise foothold placement and step sequencing required for discontinuous terrain. These contrasting limitations motivate approaches that guide learning with physics-based structure rather than relying purely on reward shaping. In this work, we introduce a locomotion framework in which a reduced-order stepping planner supplies dynamically consistent motion targets that steer the RL training process via Control Lyapunov Function (CLF) rewards. This combination of structured footstep planning and data-driven adaptation produces accurate, agile, and hardware-validated stepping-stone locomotion on a humanoid robot, substantially improving reliability compared to conventional model-free reinforcement-learning baselines.

</details>


### [280] [BlazeAIoT: A Modular Multi-Layer Platform for Real-Time Distributed Robotics Across Edge, Fog, and Cloud Infrastructures](https://arxiv.org/abs/2601.06344)
*Cedric Melancon,Julien Gascon-Samson,Maarouf Saad,Kuljeet Kaur,Simon Savard*

Main category: cs.RO

TL;DR: 本文提出了BlazeAIoT，一种模块化、多层次的分布式机器人平台，集成边缘、雾和云计算，具备高实时性、弹性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 分布式机器人系统日益复杂，对能无缝整合不同计算层并满足严格实时性的基础设施平台需求迫切。

Method: 利用基于Kubernetes的集群、服务中间件（如DDS、Kafka、Redis、ROS2）和自适应数据分发机制，实现数据和服务动态传输、配置和监控，并通过多层配置服务、动态桥接和分级速率控制应对大规模消息。

Result: 通过机器人导航和大规模AI消息处理场景实验证明，该平台可在实际不完整拓扑中动态分配服务，保持系统健康并降低延迟。

Conclusion: BlazeAIoT是一种具有良好弹性、可扩展性和低延迟的分布式机器人与物联网平台，适用于智能城市和工厂等广泛应用场景。

Abstract: The increasing complexity of distributed robotics has driven the need for platforms that seamlessly integrate edge, fog, and cloud computing layers while meeting strict real-time constraints. This paper introduces BlazeAIoT, a modular multi-layer platform designed to unify distributed robotics across heterogeneous infrastructures. BlazeAIoT provides dynamic data transfer, configurable services, and integrated monitoring, while ensuring resilience, security, and programming language flexibility. The architecture leverages Kubernetes-based clusters, broker interoperability (DDS, Kafka, Redis, and ROS2), and adaptive data distribution mechanisms to optimize communication and computation across diverse environments. The proposed solution includes a multi-layer configuration service, dynamic and adaptive data bridging, and hierarchical rate limiting to handle large messages. The platform is validated through robotics scenarios involving navigation and artificial intelligence-driven large-scale message processing, demonstrating robust performance under real-time constraints. Results highlight BlazeAIoT's ability to dynamically allocate services across incomplete topologies, maintain system health, and minimize latency, making it a cost-aware, scalable solution for robotics and broader IoT applications, such as smart cities and smart factories.

</details>


### [281] [Semantic Enrichment of CAD-Based Industrial Environments via Scene Graphs for Simulation and Reasoning](https://arxiv.org/abs/2601.06415)
*Nathan Pascal Walus,Ranulfo Bezerra,Shotaro Kojima,Tsige Tadesse Alemayoh,Satoshi Tadokoro,Kazunori Ohno*

Main category: cs.RO

TL;DR: 本文提出了一种从CAD环境中离线生成详细3D场景图的方法，丰富了仿真环境中的语义、空间和功能信息，提升了机器人训练和高阶场景理解的能力。相关代码和结果已开源。


<details>
  <summary>Details</summary>
Motivation: 传统CAD文件虽然能精确描述工业环境的几何和视觉特征，但缺乏语义、关系和功能信息，限制了在机器人训练和复杂仿真中的应用。为提升仿真环境的真实感和功能性，需要更丰富的环境描述。

Method: 本文采用一种离线方法，利用大型视觉-语言模型（LVLM）对CAD环境进行语义、空间及功能信息的丰富，构建详细的3D场景图，并包括功能及可操作元素的关系。

Result: 实验获得了生成语义标签的定量结果，同时对场景图结构（尤其是管道结构和功能关系识别）进行了定性分析，证明了方法的有效性。

Conclusion: 生成的详细3D场景图为后续机器人动态仿真和推理提供了坚实基础，有利于提升工业环境中机器人的智能和自主能力。相关成果已开源，方便社区进一步研究和应用。

Abstract: Utilizing functional elements in an industrial environment, such as displays and interactive valves, provide effective possibilities for robot training. When preparing simulations for robots or applications that involve high-level scene understanding, the simulation environment must be equally detailed. Although CAD files for such environments deliver an exact description of the geometry and visuals, they usually lack semantic, relational and functional information, thus limiting the simulation and training possibilities. A 3D scene graph can organize semantic, spatial and functional information by enriching the environment through a Large Vision-Language Model (LVLM). In this paper we present an offline approach to creating detailed 3D scene graphs from CAD environments. This will serve as a foundation to include the relations of functional and actionable elements, which then can be used for dynamic simulation and reasoning. Key results of this research include both quantitative results of the generated semantic labels as well as qualitative results of the scene graph, especially in hindsight of pipe structures and identified functional relations. All code, results and the environment will be made available at https://cad-scenegraph.github.io

</details>


### [282] [CulinaryCut-VLAP: A Vision-Language-Action-Physics Framework for Food Cutting via a Force-Aware Material Point Method](https://arxiv.org/abs/2601.06451)
*Hyunseo Koh,Chang-Yong Song,Youngjae Choi,Misa Viveiros,David Hyde,Heewon Kim*

Main category: cs.RO

TL;DR: 本文提出了一个结合视觉、语言与动作（VLA）数据集和基于物质点法（MPM）的高精度食物切割模拟器的统一框架，用于推动机器人在变形物体切割领域的研究。


<details>
  <summary>Details</summary>
Motivation: 食物切割涉及复杂的刀具与可变形材料相互作用，因强非线性、大形变和频繁接触等因素，难以实现大规模、稳定且安全的数据采集，使得自动化和智能化研究受限。

Method: 作者提出一个统一框架，将含有视觉、语言指令及多类标签的VLA数据集和以MLS-MPM为核心的切割物理模拟器结合。模拟器通过粒子与网格间脉冲交换估算受力和应力分布，实现高保真的物理交互仿真。数据集采集了多视角图像、精细切割轨迹、力-扭矩与刀具位姿等多模态信息。

Result: 所提出的数据集和仿真系统，能够稳定追踪复杂切割过程中的物理量，支持大规模、物理一致的训练信号生成，并为VLA相关模型在变形物切割任务中提供了可靠、可扩展的评测与训练基准。

Conclusion: 文中方法为机器人操作变形物体（如食物）的学习与评估建立了安全、可复现且可扩展的基础设施，对推进VLA模型在实际应用场景的能力具有重要意义。

Abstract: Food cutting is a highly practical yet underexplored application at the intersection of vision and robotic manipulation. The task remains challenging because interactions between the knife and deformable materials are highly nonlinear and often entail large deformations, frequent contact, and topological change, which in turn hinder stable and safe large-scale data collection.
  To address these challenges, we propose a unified framework that couples a vision-language-action (VLA) dataset with a physically realistic cutting simulator built on the material point method (MPM). Our simulator adopts MLS-MPM as its computational core, reducing numerical dissipation and energy drift while preserving rotational and shear responses even under topology-changing cuts. During cutting, forces and stress distributions are estimated from impulse exchanges between particles and the grid, enabling stable tracking of transient contact forces and energy transfer.
  We also provide a benchmark dataset that integrates diverse cutting trajectories, multi-view visual observations, and fine-grained language instructions, together with force--torque and tool--pose labels to provide physically consistent training signals.
  These components realize a learning--evaluation loop that respects the core physics of cutting and establishes a safe, reproducible, and scalable foundation for advancing VLA models in deformable object manipulation.

</details>


### [283] [Precision Meets Art: Autonomous Multi-UAV System for Large Scale Mural Drawing](https://arxiv.org/abs/2601.06508)
*Andrei A. Korigodskii,Artem E. Vasiunik,Georgii A. Varin,Adilia M. Zukhurova,Matvei V. Urvantsev,Semen A. Osipenkov,Igor S. Efremov,Georgii E. Bondar*

Main category: cs.RO

TL;DR: 本文开发了一套多无人机协作系统，使其能在户外自动绘制巨型壁画，并通过实际案例验证了系统效果。这一技术显著提升了艺术类大规模自动化创作的效率和精度。


<details>
  <summary>Details</summary>
Motivation: 当前无人机多应用于巡检、物流等领域，在艺术创作中的自动化与大规模应用受限，单无人机方案执行效率较低，需探索更高效、协作性更强的无人系统来推动机器人艺术的发展。

Method: 提出了一套新型的多无人机壁画绘制系统，包括同时调度多架无人机的软件平台、结合运动追踪摄像头与机载激光雷达的2D定位系统、以及基于状态机的多无人机任务分配算法和高精度轨迹控制算法。

Result: 实际在户外用本系统完成了100平方米的壁画绘制任务，结果表明多无人机方案较单机方案在执行速度、规模化和稳定性上有显著提升，系统可在恶劣天气下保持稳定运行。

Conclusion: 多无人机自主协作具备应用于艺术等创意场景的巨大潜力，有望推动机器人在大规模自动化艺术领域的进一步发展。

Abstract: The integration of autonomous unmanned aerial vehicles (UAVs) into large-scale artistic projects has emerged as a new application in robotics. This paper presents the design, deployment, and testing of a novel multi-drone system for automated mural painting in outdoor settings. This technology makes use of new software that coordinates multiple drones simultaneously, utilizing state-machine algorithms for task execution. Key advancements are the complex positioning system that combines 2D localization using a single motion tracking camera with onboard LiDAR for precise positioning, and a novel flight control algorithm, which works differently along the trajectory and normally to it, ensuring smoothness and high precision of the drawings at the same time. A 100 square meters mural was created using the developed multi-drone system, validating the system's efficacy. Compared to single-drone approaches, our multi-UAV solution significantly improves scalability and operational speed while maintaining high stability even in harsh weather conditions. The findings highlight the potential of autonomous robotic swarms in creative applications, paving the way for further advancements in large-scale robotic art.

</details>


### [284] [Model Reconciliation through Explainability and Collaborative Recovery in Assistive Robotics](https://arxiv.org/abs/2601.06552)
*Britt Besch,Tai Mai,Jeremias Thun,Markus Huff,Jörn Vogel,Freek Stulp,Samuel Bustamante*

Main category: cs.RO

TL;DR: 本文提出了一种利用大型语言模型（LLM）解释人机协作中模型分歧的框架，并在辅助机器人领域进行了实证验证。


<details>
  <summary>Details</summary>
Motivation: 在人机协作场景下，人与机器人常常因对世界或任务的理解不同而产生分歧，这可能导致用户不理解甚至不信任机器人的行为，因此需要能够解释并调和这种分歧的机制。

Method: 提出使用模型调和（model reconciliation）框架，利用大型语言模型去预测和解释人类与机器人之间的认知模型差异，无需明确定义用户的心理模型。解释之后，还允许用户主动纠正机器人的模型，从而实现人机模型的一致性。同时在轮椅式移动操作臂及其数字孪生系统上进行了实验验证。

Result: 通过真实机器人和数字孪生环境的实验，验证了所提出框架的有效性，能够帮助用户理解并纠正机器人行为。

Conclusion: 所提框架提升了人机协作系统中用户对机器人决策的可解释性和信任度，有助于解决因模型分歧带来的协作障碍。

Abstract: Whenever humans and robots work together, it is essential that unexpected robot behavior can be explained to the user. Especially in applications such as shared control the user and the robot must share the same model of the objects in the world, and the actions that can be performed on these objects.
  In this paper, we achieve this with a so-called model reconciliation framework. We leverage a Large Language Model to predict and explain the difference between the robot's and the human's mental models, without the need of a formal mental model of the user. Furthermore, our framework aims to solve the model divergence after the explanation by allowing the human to correct the robot. We provide an implementation in an assistive robotics domain, where we conduct a set of experiments with a real wheelchair-based mobile manipulator and its digital twin.

</details>


### [285] [UMLoc: Uncertainty-Aware Map-Constrained Inertial Localization with Quantified Bounds](https://arxiv.org/abs/2601.06602)
*Mohammed S. Alharbi,Shinkyu Park*

Main category: cs.RO

TL;DR: 本文提出了一种结合不确定性建模与地图约束的惯性定位框架（UMLoc），显著降低了IMU定位漂移，提升了室内定位精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 仅依靠惯性测量单元（IMU）进行定位时，受运动噪声和传感器偏差影响容易产生漂移，尤其在没有GPS的室内环境中，急需一种能抑制漂移并量化定位不确定性的解决方案。

Method: 提出UMLoc方法，包括两大模块：1）LSTM分位回归器用于估计68%、90%、95%分位数，衡量定位不确定性区间；2）带交叉注意力的条件生成对抗网络（CGAN），将IMU动态数据与基于距离的平面地图融合，生成符合几何约束的轨迹。两模块联合训练，实现不确定性贯穿轨迹生成全过程。

Result: UMLoc在三个数据集（包含新收集带地面实测轨迹和地图的2小时室内数据）上验证，平均漂移率仅5.9%（70米路径），平均绝对轨迹误差（ATE）1.36米，并能输出高可信度的预测区间。

Conclusion: 该方法能显著减小纯IMU定位的漂移，同时精准地量化定位不确定性，为室内无GPS环境下的高鲁棒性惯性定位提供了有效新思路。

Abstract: Inertial localization is particularly valuable in GPS-denied environments such as indoors. However, localization using only Inertial Measurement Units (IMUs) suffers from drift caused by motion-process noise and sensor biases. This paper introduces Uncertainty-aware Map-constrained Inertial Localization (UMLoc), an end-to-end framework that jointly models IMU uncertainty and map constraints to achieve drift-resilient positioning. UMLoc integrates two coupled modules: (1) a Long Short-Term Memory (LSTM) quantile regressor, which estimates the specific quantiles needed to define 68%, 90%, and 95% prediction intervals serving as a measure of localization uncertainty and (2) a Conditioned Generative Adversarial Network (CGAN) with cross-attention that fuses IMU dynamic data with distance-based floor-plan maps to generate geometrically feasible trajectories. The modules are trained jointly, allowing uncertainty estimates to propagate through the CGAN during trajectory generation. UMLoc was evaluated on three datasets, including a newly collected 2-hour indoor benchmark with time-aligned IMU data, ground-truth poses and floor-plan maps. Results show that the method achieves a mean drift ratio of 5.9% over a 70 m travel distance and an average Absolute Trajectory Error (ATE) of 1.36 m, while maintaining calibrated prediction bounds.

</details>


### [286] [Robotic Tele-Operation for Upper Aerodigestive Tract Microsurgery: System Design and Validation](https://arxiv.org/abs/2601.06617)
*Giovani Braglia,José Jair Alves Mendes Junior,Augusto Tetsuo Prado Inafuco,Federico Mariano,Leonardo S. Mattos*

Main category: cs.RO

TL;DR: 本文提出了一种用于上呼吸消化道手术（UADT）的新型机器人组织操作系统，并通过实验验证了其有效性和适用性。


<details>
  <summary>Details</summary>
Motivation: TLM（经口激光显微手术）虽然广泛用于UADT手术，但目前组织钳的操控主要依靠手工，存在精度、控制性和人体工学上的局限。

Method: 提出了基于新型末端执行器的机器人系统，将其集成到一个远程操作框架中，实现了精确受限的器械运动，并改善了外科医生的人体工学体验。系统采用遥操作和远程运动中心（RCM）编程。

Result: 通过两项实验研究和专门的可用性评估，证实了所提系统的有效性和手术适用性。

Conclusion: 该机器人系统可提升UADT手术中组织操作的精度和外科医生的舒适性，有潜力成为TLM等手术的新选择。

Abstract: Upper aerodigestive tract (UADT) treatments frequently employ transoral laser microsurgery (TLM) for procedures such as the removal of tumors or polyps. In TLM, a laser beam is used to cut target tissue, while forceps are employed to grasp, manipulate, and stabilize tissue within the UADT. Although TLM systems may rely on different technologies and interfaces, forceps manipulation is still predominantly performed manually, introducing limitations in ergonomics, precision, and controllability. This paper proposes a novel robotic system for tissue manipulation in UADT procedures, based on a novel end-effector designed for forceps control. The system is integrated within a teleoperation framework that employs a robotic manipulator with a programmed remote center of motion (RCM), enabling precise and constrained instrument motion while improving surgeon ergonomics. The proposed approach is validated through two experimental studies and a dedicated usability evaluation, demonstrating its effectiveness and suitability for UADT surgical applications.

</details>


### [287] [Follow the Signs: Using Textual Cues and LLMs to Guide Efficient Robot Navigation](https://arxiv.org/abs/2601.06652)
*Jing Cao,Nishanth Kumar,Aidan Curtis*

Main category: cs.RO

TL;DR: 本文提出了一种结合大语言模型（LLMs）推理与机器人导航的方法，实现机器人在未知环境中根据语义线索（如房间号、标识等）更高效地找到目标位置，并显著优于传统仅依赖几何信息的方法。


<details>
  <summary>Details</summary>
Motivation: 传统自主导航系统主要依赖于几何地图和规划，忽略了环境中的丰富语义信息，如标识和文本标签，导致在实际应用中效率不足。针对目标位置用文本标号标记（如“8号房间”）的实际场景，需要让机器人理解并利用这些语义规律提升导航效率。

Method: 方法结合局部感知输入、基于前沿的探索策略与定期对大语言模型的询问，通过LLM自动提取环境中的符号模式（如房间编号、布局结构），并动态更新用于导航的置信网格，从而指导探索动作。机器人可提前预测和聚焦目标区域，而不依赖于直接观测。

Result: 在基于真实楼层平面建模的稀疏、部分可观测网格环境中，提出的方法通过利用符号模式，导航效率显著提升。在Success weighted by Path Length指标上，相较基线方法提升超过25%，并达近最优路径表现。

Conclusion: 利用大语言模型推理语义规则能够显著增强机器人在结构化真实环境中基于文本目标的自主导航能力，方法通用性和效率突出，有望改进实际智能机器人应用。

Abstract: Autonomous navigation in unfamiliar environments often relies on geometric mapping and planning strategies that overlook rich semantic cues such as signs, room numbers, and textual labels. We propose a novel semantic navigation framework that leverages large language models (LLMs) to infer patterns from partial observations and predict regions where the goal is most likely located. Our method combines local perceptual inputs with frontier-based exploration and periodic LLM queries, which extract symbolic patterns (e.g., room numbering schemes and building layout structures) and update a confidence grid used to guide exploration. This enables robots to move efficiently toward goal locations labeled with textual identifiers (e.g., "room 8") even before direct observation. We demonstrate that this approach enables more efficient navigation in sparse, partially observable grid environments by exploiting symbolic patterns. Experiments across environments modeled after real floor plans show that our approach consistently achieves near-optimal paths and outperforms baselines by over 25% in Success weighted by Path Length.

</details>


### [288] [Robust Evacuation for Multi-Drone Failure in Drone Light Shows](https://arxiv.org/abs/2601.06728)
*Minhyuk Park,Aloysius K. Mok,Tsz-Chiu Au*

Main category: cs.RO

TL;DR: 本文提出了一种专为无人机灯光秀场景设计的多机失效应对算法，通过预测失效无人机轨迹、优化撤离路径，以及快速替换失效无人机，显著提升了系统鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 近年来无人机灯光秀流行，但多架无人机同时掉落导致的事故频发，引发了对其安全性和可靠性的担忧。为了解决在多人机协作表演中，由无人机故障引发的级联撞击风险及表演中断问题，亟需更高鲁棒性的应急方案。

Method: 算法结合了带注意力机制的Social LSTM模型预测失效无人机的运动轨迹，计算幸存无人机最优撤离路径以减小被击中的概率。同时，系统中设置了躲藏（LED关闭）的备用无人机，在有无人机失败时及时补位，确保灯光秀流畅进行。

Result: 实验结果表明，基于深度学习轨迹预测的方法和备用无人机机制，能显著提高多无人机系统对突发失效的鲁棒性。

Conclusion: 结合轨迹预测、合理撤离和失效快速补位，有效降低了级联事故风险，保证了无人机灯光秀的连续性与安全性。

Abstract: Drone light shows have emerged as a popular form of entertainment in recent years. However, several high-profile incidents involving large-scale drone failures -- where multiple drones simultaneously fall from the sky -- have raised safety and reliability concerns. To ensure robustness, we propose a drone parking algorithm designed specifically for multiple drone failures in drone light shows, aimed at mitigating the risk of cascading collisions by drone evacuation and enabling rapid recovery from failures by leveraging strategically placed hidden drones. Our algorithm integrates a Social LSTM model with attention mechanisms to predict the trajectories of failing drones and compute near-optimal evacuation paths that minimize the likelihood of surviving drones being hit by fallen drones. In the recovery node, our system deploys hidden drones (operating with their LED lights turned off) to replace failed drones so that the drone light show can continue. Our experiments showed that our approach can greatly increase the robustness of a multi-drone system by leveraging deep learning to predict the trajectories of fallen drones.

</details>


### [289] [On-the-Fly VLA Adaptation via Test-Time Reinforcement Learning](https://arxiv.org/abs/2601.06748)
*Changyu Liu,Yiyang Liu,Taowen Wang,Qiao Zhuang,James Chenhao Liang,Wenhao Yang,Renjing Xu,Qifan Wang,Dongfang Liu,Cheng Han*

Main category: cs.RO

TL;DR: 本文提出了一种新的视觉-语言-动作（VLA）模型推理阶段自适应方法，称为TT-VLA，通过在测试时引入密集奖励机制提升机器人适应性和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型高度依赖有监督微调和训练时的强化学习，这导致它们在真实复杂环境中部署时灵活性和适应性有限，需要人工干预或严格的数据收集，不适合自主响应不断变化的场景。

Method: 提出TT-VLA框架，它在推理时利用任务进展信号形成密集奖励，通过测试时强化学习对策略进行实时优化，同时保留原有模型在SFT（有监督微调）或RL（强化学习）阶段学到的先验知识。

Result: 实验证明，TT-VLA能够在模拟和真实环境下动态、未知场景中显著提升VLA模型的适应性、稳定性和任务成功率。

Conclusion: TT-VLA为实现能够自我提升、随时部署的VLA模型提供了有效途径，推动机器人在动态环境下的实用化发展。

Abstract: Vision-Language-Action models have recently emerged as a powerful paradigm for general-purpose robot learning, enabling agents to map visual observations and natural-language instructions into executable robotic actions. Though popular, they are primarily trained via supervised fine-tuning or training-time reinforcement learning, requiring explicit fine-tuning phases, human interventions, or controlled data collection. Consequently, existing methods remain unsuitable for challenging simulated- or physical-world deployments, where robots must respond autonomously and flexibly to evolving environments. To address this limitation, we introduce a Test-Time Reinforcement Learning for VLAs (TT-VLA), a framework that enables on-the-fly policy adaptation during inference. TT-VLA formulates a dense reward mechanism that leverages step-by-step task-progress signals to refine action policies during test time while preserving the SFT/RL-trained priors, making it an effective supplement to current VLA models. Empirical results show that our approach enhances overall adaptability, stability, and task success in dynamic, previously unseen scenarios under simulated and real-world settings. We believe TT-VLA offers a principled step toward self-improving, deployment-ready VLAs.

</details>


### [290] [SPINE Gripper: A Twisted Underactuated Mechanism-based Passive Mode-Transition Gripper](https://arxiv.org/abs/2601.06833)
*JaeHyung Jang,JunHyeong Park,Joong-Ku Lee,Jee-Hwan Ryu*

Main category: cs.RO

TL;DR: 本文提出了一种仅用单个执行器和机械编码传动逻辑的无源夹爪，实现了稳定抓取和连续双向物内旋转，无需多执行器、传感器或复杂控制。


<details>
  <summary>Details</summary>
Motivation: 现有多功能夹爪通常依赖多个执行器、传感器或复杂的动作切换控制，而这增加了系统的复杂度和成本。为简化结构和控制，实现更可靠高效的机械抓取和物内操作，亟需全新机制。

Method: 提出Twisted Underactuated Mechanism（TUM）实现单输入驱动下的轴向收缩与旋转，并通过机械摩擦阈值定义夹爪从抓取到旋转的无源切换。采用理论建模和实验验证，包括夹持成功率、摩擦调节夹持力和双向旋转性能评估。

Result: 理论模型得到实验验证。所制夹爪在夹持、摩擦调节和双向旋转实验中表现优异。系统示例（如螺栓操作、物体再定向、机械臂集成操作）证明其无需主动感知与控制也可稳定完成抓握与旋转任务。

Conclusion: 基于机械设计和传动逻辑，无需复杂的控制系统也可实现多功能抓取与旋转操作，为机械手设计提供了新思路和强有力的低成本解决方案。

Abstract: This paper presents a single-actuator passive gripper that achieves both stable grasping and continuous bidirectional in-hand rotation through mechanically encoded power transmission logic. Unlike conventional multifunctional grippers that require multiple actuators, sensors, or control-based switching, the proposed gripper transitions between grasping and rotation solely according to the magnitude of the applied input torque. The key enabler of this behavior is a Twisted Underactuated Mechanism (TUM), which generates non-coplanar motions, namely axial contraction and rotation, from a single rotational input while producing identical contraction regardless of rotation direction. A friction generator mechanically defines torque thresholds that govern passive mode switching, enabling stable grasp establishment before autonomously transitioning to in-hand rotation without sensing or active control. Analytical models describing the kinematics, elastic force generation, and torque transmission of the TUM are derived and experimentally validated. The fabricated gripper is evaluated through quantitative experiments on grasp success, friction-based grasp force regulation, and bidirectional rotation performance. System-level demonstrations, including bolt manipulation, object reorientation, and manipulator-integrated tasks driven solely by wrist torque, confirm reliable grasp to rotate transitions in both rotational directions. These results demonstrate that non-coplanar multifunctional manipulation can be realized through mechanical design alone, establishing mechanically encoded power transmission logic as a robust alternative to actuator and control intensive gripper architectures.

</details>


### [291] [Semilinear single-track vehicle models with distributed tyre friction dynamics](https://arxiv.org/abs/2601.06854)
*Luigi Romano,Ole Morten Aamo,Jan Åslund,Erik Frisk*

Main category: cs.RO

TL;DR: 本文提出了一种新型单轮迹车辆模型，引入了分布式轮胎瞬态动力学和摩擦非线性效应，能够更真实地模拟车辆侧向动力学。


<details>
  <summary>Details</summary>
Motivation: 现有车辆模型在描述轮胎瞬态动态和摩擦非线性方面不足，难以准确反映实际行驶工况中的轮胎-路面相互作用。为提升车辆动态模型的物理真实性和理论严谨性，有必要开发更先进的建模方法。

Method: 提出分布式摩擦-毛刷动力学（FrBD）模型，把轮胎滚动接触描述为由半线性偏微分方程（PDEs）控制的空间分布系统。将该模型系统性集成到单轮迹车辆建模框架下，包括刚性及柔性轮胎骨架两种形式，并给出其状态空间表达。对耦合系统的局部和全局适定性进行了严格理论证明，还介绍了线性化及频谱分析方法。

Result: 仿真结果显示，该模型能有效捕捉微颤振荡及复杂转向下的侧向瞬态响应，突出轮胎瞬态与有限摩擦效应对车辆动态的影响。

Conclusion: 该模型在物理基础、数学严谨性和可计算性方面显著优于经典模型，为侧向车辆动力学中精确描述轮胎瞬态和有限摩擦效应提供了先进新方法。

Abstract: This paper introduces a novel family of single-track vehicle models that incorporate a distributed representation of transient tyre dynamics, whilst simultaneously accounting for nonlinear effects induced by friction. The core of the proposed framework is represented by the distributed Friction with Bristle Dynamics (FrBD) model, which unifies and extends classical formulations such as Dahl and LuGre by describing the rolling contact process as a spatially distributed system governed by semilinear partial differential equations (PDEs). This model is systematically integrated into a single-track vehicle framework, where the resulting semilinear ODE-PDE interconnection captures the interaction between lateral vehicle motion and tyre deformation. Two main variants are considered: one with rigid tyre carcass and another with flexible carcass, each admitting a compact state-space representation. Local and global well-posedness properties for the coupled system are established rigorously, highlighting the dissipative and physically consistent properties of the distributed FrBD model. A linearisation procedure is also presented, enabling spectral analysis and transfer function derivation, and potentially facilitating the synthesis of controllers and observers. Numerical simulations demonstrate the model's capability to capture micro-shimmy oscillations and transient lateral responses to advanced steering manoeuvres. The proposed formulation advances the state-of-the-art in vehicle dynamics modelling by providing a physically grounded, mathematically rigorous, and computationally tractable approach to incorporating transient tyre behaviour in lateral vehicle dynamics, when accounting for the effect of limited friction.

</details>


### [292] [Observability-Enhanced Target Motion Estimation via Bearing-Box: Theory and MAV Applications](https://arxiv.org/abs/2601.06887)
*Yin Zhang,Zian Ning,Shiyu Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种基于单目视觉的全新运动目标估计算法——bearing-box方法，无需以往限制性假设即可同时估计目标运动和物理尺寸，并在多旋翼无人机上展现出优势。


<details>
  <summary>Details</summary>
Motivation: 以往单目视觉运动估计算法多依赖于目标形状各向同性、侧向运动等限制性假设，且很少深度利用3D检测框的信息。本文致力于突破这些限制，以提升运动估计的准确性与适用范围。

Method: 提出一种bearing-box估计算法，通过充分利用现代3D检测框数据，联合估计目标的运动状态与实际尺寸。在多旋翼无人机应用场景下，还利用了机体加速度与推力的耦合关系，进一步免去对高阶运动的假设。

Result: 理论上进行了可观测性分析，并在真实环境中进行了大量实验验证，结果显示该方法在精度和适应性方面优于现有方法。

Conclusion: bearing-box方法能在不依赖传统假设的情况下，有效提升运动估计的性能，尤其适用于现代3D检测能力和无人机等场景，具有重要应用前景。

Abstract: Monocular vision-based target motion estimation is a fundamental challenge in numerous applications. This work introduces a novel bearing-box approach that fully leverages modern 3D detection measurements that are widely available nowadays but have not been well explored for motion estimation so far. Unlike existing methods that rely on restrictive assumptions such as isotropic target shape and lateral motion, our bearing-box estimator can estimate both the target's motion and its physical size without these assumptions by exploiting the information buried in a 3D bounding box. When applied to multi-rotor micro aerial vehicles (MAVs), the estimator yields an interesting advantage: it further removes the need for higher-order motion assumptions by exploiting the unique coupling between MAV's acceleration and thrust. This is particularly significant, as higher-order motion assumptions are widely believed to be necessary in state-of-the-art bearing-based estimators. We support our claims with rigorous observability analyses and extensive experimental validation, demonstrating the estimator's superior performance in real-world scenarios.

</details>


### [293] [ObjSplat: Geometry-Aware Gaussian Surfels for Active Object Reconstruction](https://arxiv.org/abs/2601.06997)
*Yuetao Li,Zhizhou Jia,Yu Zhang,Qun Hao,Shaohui Zhang*

Main category: cs.RO

TL;DR: ObjSplat是一种主动高保真物体重建框架，通过高斯表面元统一表示，实现高质量、快速、准确的三维重建，在几何和外观上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在机器人应用和数字资产制作中，需要能够自动、高效地重建具有真实外观和精细几何结构的三维物体，解决已知方法在复杂几何和遮挡情况下复原不全、效率低等问题。

Method: 提出用高斯表面元(gassian surfels)来统一表示物体表面，同时设计了考虑背面可见性和多视角联合可见性的观点评价方法，能精确识别哪些区域重建不足。再结合一个多步前瞻的路径规划器（NBP），在生成运动轨迹时平衡信息增益与移动成本，提升重建效率。

Result: 实验证明，ObjSplat能在数分钟内建立物理一致的模型，在表面完整性和重建保真度上都超过现有方法，并明显缩短了扫描时间和路径长度。在真实文物等复杂物体上也取得优异表现。

Conclusion: ObjSplat显著提升了自主三维重建的质量与效率，可广泛应用于机器人感知和数字化等领域，优于当前主流算法。

Abstract: Autonomous high-fidelity object reconstruction is fundamental for creating digital assets and bridging the simulation-to-reality gap in robotics. We present ObjSplat, an active reconstruction framework that leverages Gaussian surfels as a unified representation to progressively reconstruct unknown objects with both photorealistic appearance and accurate geometry. Addressing the limitations of conventional opacity or depth-based cues, we introduce a geometry-aware viewpoint evaluation pipeline that explicitly models back-face visibility and occlusion-aware multi-view covisibility, reliably identifying under-reconstructed regions even on geometrically complex objects. Furthermore, to overcome the limitations of greedy planning strategies, ObjSplat employs a next-best-path (NBP) planner that performs multi-step lookahead on a dynamically constructed spatial graph. By jointly optimizing information gain and movement cost, this planner generates globally efficient trajectories. Extensive experiments in simulation and on real-world cultural artifacts demonstrate that ObjSplat produces physically consistent models within minutes, achieving superior reconstruction fidelity and surface completeness while significantly reducing scan time and path length compared to state-of-the-art approaches. Project page: https://li-yuetao.github.io/ObjSplat-page/ .

</details>


### [294] [A Sliding Mode Controller Based on Timoshenko Beam Theory Developed for a Tendon-Driven Robotic Wrist](https://arxiv.org/abs/2601.07009)
*Shifa Sulaiman,Mohammad Gohari,Francesco Schetter,Fanny Ficuciello*

Main category: cs.RO

TL;DR: 本文提出了一种肌腱驱动的机器人手腕关节以及高效的滑模控制器，能够实现精确的运动控制，且相较于现有方法在精度与响应速度上有明显提升。


<details>
  <summary>Details</summary>
Motivation: 提升机器人手腕的灵巧性和操作精度，推动复杂操作任务的发展，对机器人关节本体和控制器提出新的高性能需求。

Method: 设计了一种基于Timoshenko梁理论建模的肌腱驱动机器人手腕，并开发了滑模控制器（SMC），实现高效精确的运动控制。通过模拟和实验对比分析，与既有控制方法进行性能检验。

Result: 模拟结果下均方根误差约为1.67e-2弧度，实验误差为0.2弧度，系统稳定时间小于3秒，稳态误差低于1e-1弧度。整体性能优于已有的控制策略。

Conclusion: 基于滑模控制的肌腱驱动机器人手腕机制在精度、响应速度和稳定性上优于现有方法，为相关领域的后续研究奠定了基础。

Abstract: Development of dexterous robotic joints is essential for advancing manipulation capabilities in robotic systems. This paper presents the design and implementation of a tendon-driven robotic wrist joint together with an efficient Sliding Mode Controller (SMC) for precise motion control. The wrist mechanism is modeled using a Timoshenko-based approach to accurately capture its kinematic and dynamic properties, which serve as the foundation for tendon force calculations within the controller. The proposed SMC is designed to deliver fast dynamic response and computational efficiency, enabling accurate trajectory tracking under varying operating conditions. The effectiveness of the controller is validated through comparative analyses with existing controllers for similar wrist mechanisms. The proposed SMC demonstrates superior performance in both simulation and experimental studies. The Root Mean Square Error (RMSE) in simulation is approximately 1.67e-2 radians, while experimental validation yields an error of 0.2 radians. Additionally, the controller achieves a settling time of less than 3 seconds and a steady-state error below 1e-1 radians, consistently observed across both simulation and experimental evaluations. Comparative analyses confirm that the developed SMC surpasses alternative control strategies in motion accuracy, rapid convergence, and steady-state precision. This work establishes a foundation for future exploration of tendon-driven wrist mechanisms and control strategies in robotic applications.

</details>


### [295] [RSLCPP - Deterministic Simulations Using ROS 2](https://arxiv.org/abs/2601.07052)
*Simon Sagmeister,Marcel Weinmann,Phillip Pitschi,Markus Lienkamp*

Main category: cs.RO

TL;DR: 本文提出了一种在ROS 2系统下实现确定性可复现仿真的方法，并发布了开源库RSLCPP，使机器人仿真在不同硬件平台上可得到完全一致的结果。


<details>
  <summary>Details</summary>
Motivation: 现实中的机器人应用依赖仿真来进行开发与测试，但由于ROS的异步多进程特性，在不同的硬件平台上很难保证仿真的可复现性。这种问题影响了科研基准、连续集成等工作的一致性，因此亟需解决这一难题。

Method: 作者提出了一种基于ROS 2节点的确定性仿真方法，具体实现为RSLCPP C++库。该库允许现有ROS 2节点无须修改源代码就能被纳入确定性仿真流程，通过特殊的机制使仿真过程在不同硬件及CPU架构上都能得到一致的结果。

Result: 作者分别在合成基准测试和实际机器人系统上验证了方法的有效性，结果显示在各种CPU和架构之间均能得到完全一致的仿真输出。

Conclusion: 该方法及其实现（RSLCPP库）极大提升了机器人仿真的可复现性，有助于推动科学基准测试和工程持续集成。相关代码已开放源代码以供学术与工业界使用。

Abstract: Simulation is crucial in real-world robotics, offering safe, scalable, and efficient environments for developing applications, ranging from humanoid robots to autonomous vehicles and drones. While the Robot Operating System (ROS) has been widely adopted as the backbone of these robotic applications in both academia and industry, its asynchronous, multiprocess design complicates reproducibility, especially across varying hardware platforms. Deterministic callback execution cannot be guaranteed when computation times and communication delays vary. This lack of reproducibility complicates scientific benchmarking and continuous integration, where consistent results are essential. To address this, we present a methodology to create deterministic simulations using ROS 2 nodes. Our ROS Simulation Library for C++ (RSLCPP) implements this approach, enabling existing nodes to be combined into a simulation routine that yields reproducible results without requiring any code changes. We demonstrate that our approach yields identical results across various CPUs and architectures when testing both a synthetic benchmark and a real-world robotics system. RSLCPP is open-sourced at https://github.com/TUMFTM/rslcpp.

</details>


### [296] [PALM: Progress-Aware Policy Learning via Affordance Reasoning for Long-Horizon Robotic Manipulation](https://arxiv.org/abs/2601.07060)
*Yuanzhe Liu,Jingyuan Zhu,Yuchen Mo,Gen Li,Xu Cao,Jin Jin,Yifan Shen,Zhengyuan Li,Tianjiao Yu,Wenzhen Yuan,Fangqiang Ding,Ismini Lourentzou*

Main category: cs.RO

TL;DR: 本文提出一种新颖的视觉-语言-动作(VLA)模型PALM，通过引入交互中心的可供性推理和子任务进展机制，大幅提升机器人长时序多步操作任务的表现。


<details>
  <summary>Details</summary>
Motivation: 当前的VLA模型在处理复杂的长时序、多步骤任务时，常出现重复操作、遗漏步骤和过早终止等问题，主要因为缺乏内部推理机制来识别任务关键的信息或跟踪子任务的进展。亟需新的方法提升VLA模型的推理和执行能力。

Method: PALM框架围绕任务相关的交互可供性推理和子任务进展提示，提炼包括物体相关性、接触几何、空间位置和运动动态的可供性特征，并将其作为视觉运动控制的锚点。同时，PALM还能预测连续的子任务进展，实现无缝的子任务切换。

Result: 大量仿真和现实实验表明，PALM优于现有主流方法。在LIBERO-LONG数据集上获得91.8%的成功率，在CALVIN ABC->D任务平均长度提升12.5%，在现实三种泛化场景下性能提升2倍。

Conclusion: PALM通过结构化的可供性推理与子任务进展机制，有效解决VLA模型在长时序、多步机器人操作中的推理与执行缺陷，为机器人智能操作带来新的进展。

Abstract: Recent advancements in vision-language-action (VLA) models have shown promise in robotic manipulation, yet they continue to struggle with long-horizon, multi-step tasks. Existing methods lack internal reasoning mechanisms that can identify task-relevant interaction cues or track progress within a subtask, leading to critical execution errors such as repeated actions, missed steps, and premature termination. To address these challenges, we introduce PALM, a VLA framework that structures policy learning around interaction-centric affordance reasoning and subtask progress cues. PALM distills complementary affordance representations that capture object relevance, contact geometry, spatial placements, and motion dynamics, and serve as task-relevant anchors for visuomotor control. To further stabilize long-horizon execution, PALM predicts continuous within-subtask progress, enabling seamless subtask transitions. Across extensive simulation and real-world experiments, PALM consistently outperforms baselines, achieving a 91.8% success rate on LIBERO-LONG, a 12.5% improvement in average length on CALVIN ABC->D, and a 2x improvement over real-world baselines across three long-horizon generalization settings.

</details>


### [297] [PROTEA: Securing Robot Task Planning and Execution](https://arxiv.org/abs/2601.07186)
*Zainab Altaweel,Mohaiminul Al Nahian,Jake Juettner,Adnan Siraj Rakin,Shiqi Zhang*

Main category: cs.RO

TL;DR: 提出了一种名为PROTEA的以大语言模型（LLM）为裁判的防御机制，用以评估机器人任务规划方案的安全性，并在自建数据集上测试了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人任务规划器在对抗性攻击下存在显著安全漏洞，尤其是基于基础模型的系统，亟需提升其对恶意行为的检测与防护能力。

Method: 提出PROTEA防御机制，利用不同的大语言模型作为安全评估裁判，对任务规划方案进行历史和维度上的全面安全性评估。构建包含良性和多级隐蔽恶意行为的任务规划数据集，系统对比不同版本的PROTEA效能。

Result: 多版本PROTEA在自建数据集上对机器人任务规划方案的安全评估表现出良好效果，并给出面向实际系统增强鲁棒性和安全性的建议。

Conclusion: PROTEA有效提升了机器人任务规划系统的安全性和鲁棒性，为相关领域实践者提供了实用的安全检测工具和新思路。数据集和演示资源也公开供社区使用。

Abstract: Robots need task planning methods to generate action sequences for complex tasks. Recent work on adversarial attacks has revealed significant vulnerabilities in existing robot task planners, especially those built on foundation models. In this paper, we aim to address these security challenges by introducing PROTEA, an LLM-as-a-Judge defense mechanism, to evaluate the security of task plans. PROTEA is developed to address the dimensionality and history challenges in plan safety assessment. We used different LLMs to implement multiple versions of PROTEA for comparison purposes. For systemic evaluations, we created a dataset containing both benign and malicious task plans, where the harmful behaviors were injected at varying levels of stealthiness. Our results provide actionable insights for robotic system practitioners seeking to enhance robustness and security of their task planning systems. Details, dataset and demos are provided: https://protea-secure.github.io/PROTEA/

</details>


### [298] [HERE: Hierarchical Active Exploration of Radiance Field with Epistemic Uncertainty Minimization](https://arxiv.org/abs/2601.07242)
*Taekbeom Lee,Dabin Kim,Youngseok Jang,H. Jin Kim*

Main category: cs.RO

TL;DR: 本文提出了一种基于神经辐射场（NeRF）的主动三维场景重建框架，通过主动学习策略和不确定性量化，实现更高效和高保真的三维重建。


<details>
  <summary>Details</summary>
Motivation: 当前三维重建方法对场景未观测区域的识别和探索效率不足，导致重建完整度受限。作者旨在通过更精确的未观测区域探测，提升数据采集效率和重建质量。

Method: 1）利用证据深度学习进行本体不确定性量化，准确检测数据不足区域；2）提出分层主动探索策略，包括基于不确定性体素的局部路径规划和基于全局不确定性的整体规划，用于指导相机轨迹生成和高效数据采集。

Result: 在不同规模的真实感仿真场景中，本文方法在重建完整度指标上优于以往方法，并在实际硬件上进行了验证，体现出良好的现实应用能力。

Conclusion: 利用深度证据学习与主动探索策略，有效提升了神经隐式三维重建的效率与完整性，为实际应用提供了更具前景的解决方案。

Abstract: We present HERE, an active 3D scene reconstruction framework based on neural radiance fields, enabling high-fidelity implicit mapping. Our approach centers around an active learning strategy for camera trajectory generation, driven by accurate identification of unseen regions, which supports efficient data acquisition and precise scene reconstruction. The key to our approach is epistemic uncertainty quantification based on evidential deep learning, which directly captures data insufficiency and exhibits a strong correlation with reconstruction errors. This allows our framework to more reliably identify unexplored or poorly reconstructed regions compared to existing methods, leading to more informed and targeted exploration. Additionally, we design a hierarchical exploration strategy that leverages learned epistemic uncertainty, where local planning extracts target viewpoints from high-uncertainty voxels based on visibility for trajectory generation, and global planning uses uncertainty to guide large-scale coverage for efficient and comprehensive reconstruction. The effectiveness of the proposed method in active 3D reconstruction is demonstrated by achieving higher reconstruction completeness compared to previous approaches on photorealistic simulated scenes across varying scales, while a hardware demonstration further validates its real-world applicability.

</details>


### [299] [AdaMorph: Unified Motion Retargeting via Embodiment-Aware Adaptive Transformers](https://arxiv.org/abs/2601.07284)
*Haoyu Zhang,Shibo Jin,Lvsong Li,Jun Li,Liang Lin,Xiaodong He,Zecui Zeng*

Main category: cs.RO

TL;DR: AdaMorph提出了一种通用的神经网络模型，实现人类动作向不同机器人上的自适应迁移，突破了以往需要为每种机器人单独训练模型的难题。


<details>
  <summary>Details</summary>
Motivation: 现有方法需为每类机器人单独训练模型，导致扩展性差，并且未能充分利用动作的共性语义。研究目标是在不牺牲动作本质的前提下，以统一、高效的方式实现跨机器人动作迁移。

Method: 将动作迁移任务视为条件生成任务。首先将人类动作映射到与机器人结构无关的潜在空间，并通过双重提示机制对生成过程进行调控。关键技术在于采用自适应层归一化（AdaLN），动态调整解码器特征空间以匹配不同机器人的结构约束。此外，通过基于课程学习的训练目标，保障生成动作在物理上的合理性，包括朝向和轨迹的一致性。

Result: 在12种不同的人形机器人上做实验，发现AdaMorph能很好地统一控制不同拓扑结构的机器人，对于未见过的复杂动作也能实现较强的零样本泛化，并保留人类动作的动态本质。

Conclusion: AdaMorph框架统一了解决异构机器人动作迁移问题，具备良好的泛化能力和物理一致性，为机器人领域的通用动作迁移提供了新思路。

Abstract: Retargeting human motion to heterogeneous robots is a fundamental challenge in robotics, primarily due to the severe kinematic and dynamic discrepancies between varying embodiments. Existing solutions typically resort to training embodiment-specific models, which scales poorly and fails to exploit shared motion semantics. To address this, we present AdaMorph, a unified neural retargeting framework that enables a single model to adapt human motion to diverse robot morphologies. Our approach treats retargeting as a conditional generation task. We map human motion into a morphology-agnostic latent intent space and utilize a dual-purpose prompting mechanism to condition the generation. Instead of simple input concatenation, we leverage Adaptive Layer Normalization (AdaLN) to dynamically modulate the decoder's feature space based on embodiment constraints. Furthermore, we enforce physical plausibility through a curriculum-based training objective that ensures orientation and trajectory consistency via integration. Experimental results on 12 distinct humanoid robots demonstrate that AdaMorph effectively unifies control across heterogeneous topologies, exhibiting strong zero-shot generalization to unseen complex motions while preserving the dynamic essence of the source behaviors.

</details>


### [300] [Heterogeneous Multi-Expert Reinforcement Learning for Long-Horizon Multi-Goal Tasks in Autonomous Forklifts](https://arxiv.org/abs/2601.07304)
*Yun Chen,Bowei Huang,Fan Guo,Kang Song*

Main category: cs.RO

TL;DR: 本文为仓库环境下自主叉车提出了异构多专家强化学习（HMER）框架，将导航与操作子任务解耦提升整体性能。


<details>
  <summary>Details</summary>
Motivation: 传统端到端学习方法难以同时兼顾大尺度导航与高精度操作，任务冲突导致训练效率低下及性能受限。

Method: 提出HMER框架，通过语义任务规划器将长时序任务分解为导航与操作两个专家子策略，分别处理不同任务需求，采用混合模仿-强化训练，借助专家演示提升探索效率，强化学习微调政策。

Result: 在Gazebo仿真中，HMER在任务成功率、操作时间与定位精度等方面均显著优于传统顺序式及端到端方法，分别达到94.2%的成功率，操作时间缩短21.4%，物料放置误差小于1.5cm。

Conclusion: HMER框架有效解决了多阶段复杂任务的优化干扰与探索稀疏性问题，实现了高效且高精度的自主物料搬运，验证了该方法的实用性与优越性。

Abstract: Autonomous mobile manipulation in unstructured warehouses requires a balance between efficient large-scale navigation and high-precision object interaction. Traditional end-to-end learning approaches often struggle to handle the conflicting demands of these distinct phases. Navigation relies on robust decision-making over large spaces, while manipulation needs high sensitivity to fine local details. Forcing a single network to learn these different objectives simultaneously often causes optimization interference, where improving one task degrades the other. To address these limitations, we propose a Heterogeneous Multi-Expert Reinforcement Learning (HMER) framework tailored for autonomous forklifts. HMER decomposes long-horizon tasks into specialized sub-policies controlled by a Semantic Task Planner. This structure separates macro-level navigation from micro-level manipulation, allowing each expert to focus on its specific action space without interference. The planner coordinates the sequential execution of these experts, bridging the gap between task planning and continuous control. Furthermore, to solve the problem of sparse exploration, we introduce a Hybrid Imitation-Reinforcement Training Strategy. This method uses expert demonstrations to initialize the policy and Reinforcement Learning for fine-tuning. Experiments in Gazebo simulations show that HMER significantly outperforms sequential and end-to-end baselines. Our method achieves a task success rate of 94.2\% (compared to 62.5\% for baselines), reduces operation time by 21.4\%, and maintains placement error within 1.5 cm, validating its efficacy for precise material handling.

</details>


### [301] [Large-Scale Autonomous Gas Monitoring for Volcanic Environments: A Legged Robot on Mount Etna](https://arxiv.org/abs/2601.07362)
*Julia Richter,Turcan Tuna,Manthan Patel,Takahiro Miki,Devon Higgins,James Fox,Cesar Cadena,Andres Diaz,Marco Hutter*

Main category: cs.RO

TL;DR: 该论文提出利用四足机器人ANYmal进行火山气体的自主分析，克服传统轮式系统在崎岖地形中难以移动的问题，并在埃特纳火山测试中取得高自主性和有效检测结果。


<details>
  <summary>Details</summary>
Motivation: 传统的火山气体检测由于地形复杂且环境危险，人力或轮式机器人都难以实现高效、可靠的近地表测量，因此亟需能够自主适应复杂地形的解决方案。

Method: 作者开发了一套基于四足机器人ANYmal的自主火山气体分析系统，搭载四极杆质谱仪，通过集成任务规划、全局/局部导航和高精度定位，实现在复杂火山地形下的自主作业，并进行了野外实测验证。

Result: 该系统在埃特纳火山进行了三次自主任务测试，在多种地形条件下自主检测到气体源，自主化率高达93-100%；同时还在遥操作下对天然气孔进行了分析，检测到二氧化硫和二氧化碳气体。

Conclusion: 四足机器人平台可以有效增强火山气体检测的安全性和覆盖范围。系统展现出较高自主能力，但仍需在感知策略、自主导航协同和硬件设计上进一步优化。

Abstract: Volcanic gas emissions are key precursors of eruptive activity. Yet, obtaining accurate near-surface measurements remains hazardous and logistically challenging, motivating the need for autonomous solutions. Limited mobility in rough volcanic terrain has prevented wheeled systems from performing reliable in situ gas measurements, reducing their usefulness as sensing platforms. We present a legged robotic system for autonomous volcanic gas analysis, utilizing the quadruped ANYmal, equipped with a quadrupole mass spectrometer system. Our modular autonomy stack integrates a mission planning interface, global planner, localization framework, and terrain-aware local navigation. We evaluated the system on Mount Etna across three autonomous missions in varied terrain, achieving successful gas-source detections with autonomy rates of 93-100%. In addition, we conducted a teleoperated mission in which the robot measured natural fumaroles, detecting sulfur dioxide and carbon dioxide. We discuss lessons learned from the gas-analysis and autonomy perspectives, emphasizing the need for adaptive sensing strategies, tighter integration of global and local planning, and improved hardware design.

</details>


### [302] [LOONG: Online Time-Optimal Autonomous Flight for MAVs in Cluttered Environments](https://arxiv.org/abs/2601.07434)
*Xin Guan,Fangguo Zhao,Qianyi Wang,Chengcheng Zhao,Jiming Chen,Shuo Li*

Main category: cs.RO

TL;DR: 本文提出了一种用于微型飞行器（MAV）在未知、复杂环境中实现高速度自主演飞的规划与控制框架，能够提升飞行效率并确保安全。


<details>
  <summary>Details</summary>
Motivation: 在时效性要求高、环境复杂的任务中，MAV通常采用保守策略，导致飞行速度慢且效率低，亟需突破技术以实现高效自主飞行。

Method: 每个重规划周期内（100Hz），基于多项式形式生成时间最优轨迹，并通过模仿学习加速分配时间。随后利用时间最优的模型预测轮廓控制（MPCC），在可变时域内引入安全飞行走廊（SFC）约束，实现激进但安全的操控，并充分利用MAV的动态特性。

Result: 在自建的基于LiDAR的MAV平台上进行了大量测试。仿真实验显示该方法的激进性优于现有技术，实际测试中在复杂环境下达到峰值速度18m/s，并连续10次试飞均从不同起点成功完成任务。

Conclusion: 该方法兼顾了安全性与高效性，能大幅提升MAV在复杂环境下的自主飞行性能，具备实际应用潜力。

Abstract: Autonomous flight of micro air vehicles (MAVs) in unknown, cluttered environments remains challenging for time-critical missions due to conservative maneuvering strategies. This article presents an integrated planning and control framework for high-speed, time-optimal autonomous flight of MAVs in cluttered environments. In each replanning cycle (100 Hz), a time-optimal trajectory under polynomial presentation is generated as a reference, with the time-allocation process accelerated by imitation learning. Subsequently, a time-optimal model predictive contouring control (MPCC) incorporates safe flight corridor (SFC) constraints at variable horizon steps to enable aggressive yet safe maneuvering, while fully exploiting the MAV's dynamics. We validate the proposed framework extensively on a custom-built LiDAR-based MAV platform. Simulation results demonstrate superior aggressiveness compared to the state of the art, while real-world experiments achieve a peak speed of 18 m/s in a cluttered environment and succeed in 10 consecutive trials from diverse start points. The video is available at the following link: https://youtu.be/vexXXhv99oQ.

</details>


### [303] [WaveMan: mmWave-Based Room-Scale Human Interaction Perception for Humanoid Robots](https://arxiv.org/abs/2601.07454)
*Yuxuan Hu,Kuangji Zuo,Boyu Ma,Shihao Li,Zhaoyang Xia,Feng Xu,Jianfei Yang*

Main category: cs.RO

TL;DR: 提出了WaveMan，一种适应房间空间的毫米波感知系统，实现了在不同用户位置下的可靠、隐私保护的人机交互。该方法在空间泛化性和准确率上大幅优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 现有的毫米波感知交互系统在面对不同距离或视角时空间泛化能力差，难以满足家庭环境中用户位置不限和隐私保护的双重要求。

Method: 提出WaveMan系统，结合视角对齐和谱图增强技术，并采用双通道注意力机制实现鲁棒特征提取，从而提升空间一致性与泛化能力。

Result: 实验表明，在固定位置下，WaveMan使用五分之一的训练位置即可达到基线方法的跨位置准确率；在随机自由位置测试中，准确率从33.00%提升到94.33%。

Conclusion: WaveMan系统实现了在家用场景下，对任意用户位置的可靠且隐私保护的人形机器人交互，展示了其实用可行性。

Abstract: Reliable humanoid-robot interaction (HRI) in household environments is constrained by two fundamental requirements, namely robustness to unconstrained user positions and preservation of user privacy. Millimeter-wave (mmWave) sensing inherently supports privacy-preserving interaction, making it a promising modality for room-scale HRI. However, existing mmWave-based interaction-sensing systems exhibit poor spatial generalization at unseen distances or viewpoints. To address this challenge, we introduce WaveMan, a spatially adaptive room-scale perception system that restores reliable human interaction sensing across arbitrary user positions. WaveMan integrates viewpoint alignment and spectrogram enhancement for spatial consistency, with dual-channel attention for robust feature extraction. Experiments across five participants show that, under fixed-position evaluation, WaveMan achieves the same cross-position accuracy as the baseline with five times fewer training positions. In random free-position testing, accuracy increases from 33.00% to 94.33%, enabled by the proposed method. These results demonstrate the feasibility of reliable, privacy-preserving interaction for household humanoid robots across unconstrained user positions.

</details>


### [304] [NanoCockpit: Performance-optimized Application Framework for AI-based Autonomous Nanorobotics](https://arxiv.org/abs/2601.07476)
*Elia Cereda,Alessandro Giusti,Daniele Palossi*

Main category: cs.RO

TL;DR: 本文提出了NanoCockpit软件框架，用于提升基于TinyML（微型机器学习）视觉的自主纳米无人机的系统性能，实现更高吞吐量和更低延迟。


<details>
  <summary>Details</summary>
Motivation: 当前纳米无人机受限于极小的计算资源，在现有软件缺乏高效的多任务调度、图像采集管道和数据交换机制，因此未能高效利用机载硬件，导致无人机的控制性能不佳。

Method: 提出名为NanoCockpit的软件框架，通过协程（coroutine）实现多任务调度，有效管理多缓冲图像采集、多核计算、芯片间数据交换与无线流传输，提升整体流程效率。并在三个实际TinyML纳米机器人应用场景下进行实地实验。

Result: 实验证明，该框架实现了理想的端到端延迟（即任务间无串行化带来的额外负担），并显著提高了闭环控制性能，包括平均位置误差降低30%，任务成功率从40%提升至100%。

Conclusion: NanoCockpit显著提升了纳米无人机的TinyML应用性能，降低了开发复杂性，优化了系统资源利用，有助于推动资源受限嵌入式系统上的智能无人机技术发展。

Abstract: Autonomous nano-drones, powered by vision-based tiny machine learning (TinyML) models, are a novel technology gaining momentum thanks to their broad applicability and pushing scientific advancement on resource-limited embedded systems. Their small form factor, i.e., a few 10s grams, severely limits their onboard computational resources to sub-\SI{100}{\milli\watt} microcontroller units (MCUs). The Bitcraze Crazyflie nano-drone is the \textit{de facto} standard, offering a rich set of programmable MCUs for low-level control, multi-core processing, and radio transmission. However, roboticists very often underutilize these onboard precious resources due to the absence of a simple yet efficient software layer capable of time-optimal pipelining of multi-buffer image acquisition, multi-core computation, intra-MCUs data exchange, and Wi-Fi streaming, leading to sub-optimal control performances. Our \textit{NanoCockpit} framework aims to fill this gap, increasing the throughput and minimizing the system's latency, while simplifying the developer experience through coroutine-based multi-tasking. In-field experiments on three real-world TinyML nanorobotics applications show our framework achieves ideal end-to-end latency, i.e. zero overhead due to serialized tasks, delivering quantifiable improvements in closed-loop control performance ($-$30\% mean position error, mission success rate increased from 40\% to 100\%).

</details>


### [305] [FlyCo: Foundation Model-Empowered Drones for Autonomous 3D Structure Scanning in Open-World Environments](https://arxiv.org/abs/2601.07558)
*Chen Feng,Guiyong Zheng,Tengkai Zhuang,Yongqian Wu,Fangzhan He,Haojia Li,Juepeng Zheng,Shaojie Shen,Boyu Zhou*

Main category: cs.RO

TL;DR: 本文提出了一种利用基础模型(FM)的无人机自主3D扫描系统——FlyCo，能够在开放世界环境下根据低成本的人类提示实现精准扫描。


<details>
  <summary>Details</summary>
Motivation: 现有无人机3D扫描方案要么假设条件苛刻，要么需要大量人工先验，限制了其广泛实际应用，难以适应复杂、开放环境。基础模型（如视觉语言模型）的泛化能力为提升系统自适应性与自主性提供新机遇。

Method: 设计了FlyCo系统，其核心是将基础模型知识注入“感知-预测-规划”闭环流程，通过人类简单提示（文本或视觉标注）、多模态融合的目标感知与跟踪、形状预测与几何补全、高效路径规划实现无人机对未知目标结构的自主三维扫描。同时针对开放环境，分别提升了目标定位、几何预测精度、零样本泛化能力以及实时规划和避障效率。

Result: 在现实和仿真等多种复杂环境下进行了大量实验，结果显示FlyCo能精准理解场景，扫描效率高、实时安全强，对比现有方案表现更优，且对人工依赖显著降低。消融实验验证了各个关键模块的有效性。

Conclusion: FlyCo不仅验证了FM融入无人机自主扫描系统的可行性和优越性，还为未来基础模型与机器人系统的结合提供了可扩展的模板，具备良好的实用性和可拓展性。代码未来会开源。

Abstract: Autonomous 3D scanning of open-world target structures via drones remains challenging despite broad applications. Existing paradigms rely on restrictive assumptions or effortful human priors, limiting practicality, efficiency, and adaptability. Recent foundation models (FMs) offer great potential to bridge this gap. This paper investigates a critical research problem: What system architecture can effectively integrate FM knowledge for this task? We answer it with FlyCo, a principled FM-empowered perception-prediction-planning loop enabling fully autonomous, prompt-driven 3D target scanning in diverse unknown open-world environments. FlyCo directly translates low-effort human prompts (text, visual annotations) into precise adaptive scanning flights via three coordinated stages: (1) perception fuses streaming sensor data with vision-language FMs for robust target grounding and tracking; (2) prediction distills FM knowledge and combines multi-modal cues to infer the partially observed target's complete geometry; (3) planning leverages predictive foresight to generate efficient and safe paths with comprehensive target coverage. Building on this, we further design key components to boost open-world target grounding efficiency and robustness, enhance prediction quality in terms of shape accuracy, zero-shot generalization, and temporal stability, and balance long-horizon flight efficiency with real-time computability and online collision avoidance. Extensive challenging real-world and simulation experiments show FlyCo delivers precise scene understanding, high efficiency, and real-time safety, outperforming existing paradigms with lower human effort and verifying the proposed architecture's practicality. Comprehensive ablations validate each component's contribution. FlyCo also serves as a flexible, extensible blueprint, readily leveraging future FM and robotics advances. Code will be released.

</details>


### [306] [Stable In-hand Manipulation for a Lightweight Four-motor Prosthetic Hand](https://arxiv.org/abs/2601.07559)
*Yuki Kuroda,Tomoya Takahashi,Cristian C. Beltran-Hernandez,Kazutoshi Tanaka,Masashi Hamaya*

Main category: cs.RO

TL;DR: 本研究改进了PLEXUS电动假手，让其可自动适应不同物体宽度和重量，实现更稳定、更复杂的旋转类抓取与日常操作任务。


<details>
  <summary>Details</summary>
Motivation: 现有假手需轻便、美观、内部保护电机，还需实现复杂手内操作（如转动笔），但传统控制器只能应对已知物体宽度和轻质物体，实际应用受限。

Method: 新方法利用电机电流反馈，结合单轴拇指设计，无需预设物体宽度，通过估算宽度和调整食指，实现自适应、稳定的物体持握与旋转。

Result: 经实验，系统对5-30 mm宽、不同形状物体（圆柱、棱柱）操作轻质物体成功率100％，重物（289g）也有≥80％，未用食指协调时仅40％。能完成旋转瓶盖、调整笔姿等任务。

Conclusion: 采用电流反馈与手指协调大幅提升了假手在不同情景下的适应性和操作能力，表现出优异的日常实用价值。

Abstract: Electric prosthetic hands should be lightweight to decrease the burden on the user, shaped like human hands for cosmetic purposes, and designed with motors enclosed inside to protect them from damage and dirt. Additionally, in-hand manipulation is necessary to perform daily activities such as transitioning between different postures, particularly through rotational movements, such as reorienting a pen into a writing posture after picking it up from a desk. We previously developed PLEXUS hand (Precision-Lateral dEXteroUS manipulation hand), a lightweight (311 g) prosthetic hand driven by four motors. This prosthetic performed reorientation between precision and lateral grasps with various objects. However, its controller required predefined object widths and was limited to handling lightweight objects (of weight up to 34 g). This study addresses these limitations by employing motor current feedback. Combined with the hand's previously optimized single-axis thumb, this approach achieves more stable manipulation by estimating the object's width and adjusting the index finger position to maintain stable object holding during the reorientation. Experimental validation using primitive objects of various widths (5-30 mm) and shapes (cylinders and prisms) resulted in a 100% success rate with lightweight objects and maintained a high success rate (>=80) even with heavy aluminum prisms (of weight up to 289 g). By contrast, the performance without index finger coordination dropped to just 40% on the heaviest 289 g prism. The hand also successfully executed several daily tasks, including closing bottle caps and orienting a pen for writing.

</details>


### [307] [Deep Whole-body Parkour](https://arxiv.org/abs/2601.07701)
*Ziwen Zhuang,Shaoting Zhu,Mengjie Zhao,Hang Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种将感知与全身运动控制相结合的新框架，使得人形机器人能够在不规则地形上完成多种高难度动态动作，不再仅限于简单行走。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人控制方法通常分为能够适应地形但仅限于踩踏步态的感知性步行，以及忽略环境却能还原复杂动作的运动跟踪两类，这两种方法都存在明显局限。该研究动机在于融合两者优点，让机器人既能感知环境，又能完成多样化运动。

Method: 作者提出了一种将外部感知（exteroceptive sensing）融入全身运动跟踪的新方法。具体做法是训练单一的策略，使机器人能够在不同地形和环境下完成多样动作，将环境信息引入运动决策和控制环路。

Result: 实验证明该框架能让机器人在非结构化地形上完成多接触、动态性极强的动作（如撑杆跨越、翻滚等），运动表现显著优于传统控制方法，机器人适应地形和复杂任务的能力大大增强。

Conclusion: 将环境感知融入全身运动跟踪极大地提升了人形机器人在复杂地形上的运动能力，为机器人真正实现多样性、强适应性的动态运动迈出了关键一步。

Abstract: Current approaches to humanoid control generally fall into two paradigms: perceptive locomotion, which handles terrain well but is limited to pedal gaits, and general motion tracking, which reproduces complex skills but ignores environmental capabilities. This work unites these paradigms to achieve perceptive general motion control. We present a framework where exteroceptive sensing is integrated into whole-body motion tracking, permitting a humanoid to perform highly dynamic, non-locomotion tasks on uneven terrain. By training a single policy to perform multiple distinct motions across varied terrestrial features, we demonstrate the non-trivial benefit of integrating perception into the control loop. Our results show that this framework enables robust, highly dynamic multi-contact motions, such as vaulting and dive-rolling, on unstructured terrain, significantly expanding the robot's traversability beyond simple walking or running. https://project-instinct.github.io/deep-whole-body-parkour

</details>


### [308] [Hiking in the Wild: A Scalable Perceptive Parkour Framework for Humanoids](https://arxiv.org/abs/2601.07718)
*Shaoting Zhu,Ziwen Zhuang,Mengjie Zhao,Kun-Ying Lee,Hang Zhao*

Main category: cs.RO

TL;DR: 该论文提出了一种面向类人机器人在野外复杂地形健步行走的端到端感知框架，实现了鲁棒而高效的徒步移动，避免传统感知与状态估计方法的缺陷。


<details>
  <summary>Details</summary>
Motivation: 在现实世界中，环境复杂且不可控，仅靠本体感知（如关节传感器）难以应对，需要机器人具备前瞻性的环境感知能力。然而，将外部感知（如深度、激光雷达）高效、准确地整合进运动决策仍有很大挑战，现有方法实际运用受限。

Method: 提出了“Hiking in the Wild”框架，采用单阶段强化学习，将原始深度输入和本体感觉直接映射到关节动作，无需依赖外部状态估计。引入可扩展的地形边缘检测与足部点云体积机制，避免踩空滑落；结合平坦区块采样策略，缓解奖励作弊问题，提高训练稳定性和安全性。

Result: 在全尺寸类人机器人上进行大量实地测试，方法实现了在复杂地形上2.5 m/s的健步行走，表现出较强鲁棒性。相关训练和部署代码开源，可直接复现，且易于部署到实际硬件中。

Conclusion: 所提方法有效解决了类人机器人野外健步面临的外感知整合和安全稳定训练难题，为实际大规模部署提供了可能。

Abstract: Achieving robust humanoid hiking in complex, unstructured environments requires transitioning from reactive proprioception to proactive perception. However, integrating exteroception remains a significant challenge: mapping-based methods suffer from state estimation drift; for instance, LiDAR-based methods do not handle torso jitter well. Existing end-to-end approaches often struggle with scalability and training complexity; specifically, some previous works using virtual obstacles are implemented case-by-case. In this work, we present \textit{Hiking in the Wild}, a scalable, end-to-end parkour perceptive framework designed for robust humanoid hiking. To ensure safety and training stability, we introduce two key mechanisms: a foothold safety mechanism combining scalable \textit{Terrain Edge Detection} with \textit{Foot Volume Points} to prevent catastrophic slippage on edges, and a \textit{Flat Patch Sampling} strategy that mitigates reward hacking by generating feasible navigation targets. Our approach utilizes a single-stage reinforcement learning scheme, mapping raw depth inputs and proprioception directly to joint actions, without relying on external state estimation. Extensive field experiments on a full-size humanoid demonstrate that our policy enables robust traversal of complex terrains at speeds up to 2.5 m/s. The training and deployment code is open-sourced to facilitate reproducible research and deployment on real robots with minimal hardware modifications.

</details>


### [309] [THETA: Triangulated Hand-State Estimation for Teleoperation and Automation in Robotic Hand Control](https://arxiv.org/abs/2601.07768)
*Alex Huang,Akshay Karthik*

Main category: cs.RO

TL;DR: 该论文提出了一种仅用三台普通网络摄像头进行人手关节角度追踪的方法，可实现低成本远程机器人手控制。结合深度学习与机器视觉，替代了昂贵的深度相机和传感手套。


<details>
  <summary>Details</summary>
Motivation: 当前远程操作机器人手多采用深度摄像头与传感手套，这类方案价格昂贵、普及受限。因此，研究团队致力于开发一种低成本、易用的非穿戴视觉追踪方案。

Method: 用三台安排在相互120度的网络摄像头采集多角度RGB图片，采用DeepLabV3-ResNet50进行手分割，利用HSV滤波，构成9通道输入，通过MobileNetV2卷积神经网络对手部姿态多视图进行分类，实现关节角度（theta）推断。输出经串口传至Arduino，驱动改进型DexHand机械手完成动作复刻。

Result: 模型在40种手势、4.8万多帧数据上评估，关节角度分类准确率达97.18%，召回率98.72%、F1值0.9274、精度0.8906；系统支持实时推理和机器人复现。

Conclusion: 三摄像头加深度学习的方案在准确率与成本之间取得良好平衡，未来将提升数据多样性、加入手腕识别并引入更前沿计算机视觉技术，有望广泛应用于医疗、交流和制造等领域的低成本远程机器人手操作场景。

Abstract: The teleoperation of robotic hands is limited by the high costs of depth cameras and sensor gloves, commonly used to estimate hand relative joint positions (XYZ). We present a novel, cost-effective approach using three webcams for triangulation-based tracking to approximate relative joint angles (theta) of human fingers. We also introduce a modified DexHand, a low-cost robotic hand from TheRobotStudio, to demonstrate THETA's real-time application. Data collection involved 40 distinct hand gestures using three 640x480p webcams arranged at 120-degree intervals, generating over 48,000 RGB images. Joint angles were manually determined by measuring midpoints of the MCP, PIP, and DIP finger joints. Captured RGB frames were processed using a DeepLabV3 segmentation model with a ResNet-50 backbone for multi-scale hand segmentation. The segmented images were then HSV-filtered and fed into THETA's architecture, consisting of a MobileNetV2-based CNN classifier optimized for hierarchical spatial feature extraction and a 9-channel input tensor encoding multi-perspective hand representations. The classification model maps segmented hand views into discrete joint angles, achieving 97.18% accuracy, 98.72% recall, F1 Score of 0.9274, and a precision of 0.8906. In real-time inference, THETA captures simultaneous frames, segments hand regions, filters them, and compiles a 9-channel tensor for classification. Joint-angle predictions are relayed via serial to an Arduino, enabling the DexHand to replicate hand movements. Future research will increase dataset diversity, integrate wrist tracking, and apply computer vision techniques such as OpenAI-Vision. THETA potentially ensures cost-effective, user-friendly teleoperation for medical, linguistic, and manufacturing applications.

</details>


### [310] [Data-driven control of hydraulic impact hammers under strict operational and control constraints](https://arxiv.org/abs/2601.07813)
*Francisco Leiva,Claudio Canales,Michelle Valenzuela,Javier Ruiz-del-Solar*

Main category: cs.RO

TL;DR: 本文提出了一种基于数据的方法，通过监督学习建模液压冲击锤（碎石机）动力学，并采用强化学习和模型预测控制算法，实现端执行器精确到达目标姿态，用于矿业中岩石破碎自动化。实际应用在Bobcat E10 挖掘机上，仅用约68分钟遥操作数据训练，真实环境中位置误差小于12厘米。


<details>
  <summary>Details</summary>
Motivation: 矿业中广泛使用液压冲击锤进行岩石破碎，但目前操作依靠人工控制，难以自动化，且存在传感器受限和控制接口离散等实际约束。因此亟需开发一种能够实现高精度自动控制、易于Sim2Real迁移的方法。

Method: 首先通过液压臂遥操作数据，用监督学习训练动力学模型，然后基于所学模型分别利用强化学习（RL）和模型预测控制（MPC）算法合成控制策略。方法兼顾未观测状态变量和离散控制接口约束。在Bobcat E10实机和仿真中开展系统辨识与控制策略评估。

Result: 学习得到的RL控制策略在真实环境中能将锤头精准定位，位置误差小于12厘米，俯仰角误差小于0.08弧度，满足4厘米钻头实际作业精度需求。整个训练与评估仅用了68分钟遥操作和8分钟评估数据，无需专门Sim2Real调参。

Conclusion: 提出方法能在传感约束和离散控制条件下，用较少数据成功实现液压冲击锤自动化精确定位，并具备良好Sim2Real迁移能力，有效推动矿石破碎作业自动化发展。

Abstract: This paper presents a data-driven methodology for the control of static hydraulic impact hammers, also known as rock breakers, which are commonly used in the mining industry. The task addressed in this work is that of controlling the rock-breaker so its end-effector reaches arbitrary target poses, which is required in normal operation to place the hammer on top of rocks that need to be fractured. The proposed approach considers several constraints, such as unobserved state variables due to limited sensing and the strict requirement of using a discrete control interface at the joint level. First, the proposed methodology addresses the problem of system identification to obtain an approximate dynamic model of the hydraulic arm. This is done via supervised learning, using only teleoperation data. The learned dynamic model is then exploited to obtain a controller capable of reaching target end-effector poses. For policy synthesis, both reinforcement learning (RL) and model predictive control (MPC) algorithms are utilized and contrasted. As a case study, we consider the automation of a Bobcat E10 mini-excavator arm with a hydraulic impact hammer attached as end-effector. Using this machine, both the system identification and policy synthesis stages are studied in simulation and in the real world. The best RL-based policy consistently reaches target end-effector poses with position errors below 12 cm and pitch angle errors below 0.08 rad in the real world. Considering that the impact hammer has a 4 cm diameter chisel, this level of precision is sufficient for breaking rocks. Notably, this is accomplished by relying only on approximately 68 min of teleoperation data to train and 8 min to evaluate the dynamic model, and without performing any adjustments for a successful policy Sim2Real transfer. A demonstration of policy execution in the real world can be found in https://youtu.be/e-7tDhZ4ZgA.

</details>


### [311] [Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning with Self-Recovery for Real-World Manipulation](https://arxiv.org/abs/2601.07821)
*Huanyu Li,Kun Lei,Sheng Zang,Kaizhe Hu,Yongyuan Liang,Bo An,Xiaoli Li,Huazhe Xu*

Main category: cs.RO

TL;DR: 本文提出了一种针对深度强化学习中现实探索中不可避免失败（如机器人打碎玻璃等）的问题的算法FARL，并构建了FailureBench基准数据集。该方法通过结合模型预测的安全评估与离线训练的恢复策略，在实际训练中显著减少需要人工干预的失败事件，提升了强化学习的实际部署能力。实验表明，FARL能将干预失败降低73.1%，同时将性能提升11.3%。


<details>
  <summary>Details</summary>
Motivation: 在强化学习应用于机器人等现实场景时，离线算法在安全、泛化和性能上有优势，但在在线探索阶段不可避免地会发生严重失败，需要人工干预，这大大限制了其实际部署。推动安全、高效地将离线学到的能力迁移到现实世界，成为重要挑战。

Method: 提出Failure-Aware Offline-to-Online Reinforcement Learning (FARL)范式，并设计FailureBench作为测试基准。算法方面，结合了基于世界模型的安全评价器（safety critic）和在离线数据上训练的恢复策略，在线探索时实时评估和预防高风险动作，减少失败的发生。

Result: 大量仿真与现实机器人实验验证了FARL的有效性。在实际强化学习后训练阶段，平均将需要干预的失败次数降低了73.1%，性能提升了11.3%。

Conclusion: FARL为现实世界强化学习探索提供了更安全且高效的范式，为实际部署打下了基础。同时，FailureBench为该问题领域的算法发展提供了有价值的评测平台。

Abstract: Post-training algorithms based on deep reinforcement learning can push the limits of robotic models for specific objectives, such as generalizability, accuracy, and robustness. However, Intervention-requiring Failures (IR Failures) (e.g., a robot spilling water or breaking fragile glass) during real-world exploration happen inevitably, hindering the practical deployment of such a paradigm. To tackle this, we introduce Failure-Aware Offline-to-Online Reinforcement Learning (FARL), a new paradigm minimizing failures during real-world reinforcement learning. We create FailureBench, a benchmark that incorporates common failure scenarios requiring human intervention, and propose an algorithm that integrates a world-model-based safety critic and a recovery policy trained offline to prevent failures during online exploration. Extensive simulation and real-world experiments demonstrate the effectiveness of FARL in significantly reducing IR Failures while improving performance and generalization during online reinforcement learning post-training. FARL reduces IR Failures by 73.1% while elevating performance by 11.3% on average during real-world RL post-training. Videos and code are available at https://failure-aware-rl.github.io.

</details>
