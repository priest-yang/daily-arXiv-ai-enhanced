<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 115]
- [cs.CL](#cs.CL) [Total: 38]
- [cs.RO](#cs.RO) [Total: 32]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Hierarchical Process Reward Models are Symbolic Vision Learners](https://arxiv.org/abs/2512.03126)
*Shan Zhang,Aotian Chen,Kai Zou,Jindong Gu,Yuan Xue,Anton van den Hengel*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的自监督符号自动编码器，能通过几何原语对图示进行可解释的结构化表示，并取得了优异的重建与推理表现。


<details>
  <summary>Details</summary>
Motivation: 传统像素级视觉模型难以解释和理解结构化图示，缺乏可解释性。而符号视觉通过逻辑规则和结构化描述使理解更加透明，然而符号视觉需要与像素视觉全然不同的学习范式，因此亟需兼具符号结构化表达和视觉感知能力的方法。

Method: 作者提出了一种自监督的符号自动编码器，能够将图示编码为几何原语及其关系，并借助可执行引擎解码重构图示。核心技术为分层奖励机制(SHPRM)，通过点上线、线上形等结构一致性的分步奖励，提升解析的符号层次表达。同时设计了探索与利用的稳定机制，以改善图示重建过程中的策略搜索难题。最后将符号编码器微调于下游神经-符号推理任务，结合神经网络的推理能力与符号模型的可解释性。

Result: 方法在多个任务上取得显著提升：几何图重建MSE降低98.2%；在图表重建上，7B模型超越GPT-4o 0.6%；在MathGlance感知基准提升13%；在MathVerse和GeoQA推理基准提升3%。

Conclusion: 该方法能以结构化方式理解和表达图示，实现了可解释重建与神经-符号推理的有机统一，增强了机视觉的感知与推理能力，优于当前主流大模型。

Abstract: Symbolic computer vision represents diagrams through explicit logical rules and structured representations, enabling interpretable understanding in machine vision. This requires fundamentally different learning paradigms from pixel-based visual models. Symbolic visual learners parse diagrams into geometric primitives-points, lines, and shapes-whereas pixel-based learners operate on textures and colors. We propose a novel self-supervised symbolic auto-encoder that encodes diagrams into structured primitives and their interrelationships within the latent space, and decodes them through our executable engine to reconstruct the input diagrams. Central to this architecture is Symbolic Hierarchical Process Reward Modeling, which applies hierarchical step-level parsing rewards to enforce point-on-line, line-on-shape, and shape-on-relation consistency. Since vanilla reinforcement learning exhibits poor exploration in the policy space during diagram reconstruction; we thus introduce stabilization mechanisms to balance exploration and exploitation. We fine-tune our symbolic encoder on downstream tasks, developing a neuro-symbolic system that integrates the reasoning capabilities of neural networks with the interpretability of symbolic models through reasoning-grounded visual rewards. Evaluations across reconstruction, perception, and reasoning tasks demonstrate the effectiveness of our approach: achieving a 98.2% reduction in MSE for geometric diagram reconstruction, surpassing GPT-4o by 0.6% with a 7B model on chart reconstruction, and improving by +13% on the MathGlance perception benchmark, and by +3% on MathVerse and GeoQA reasoning benchmarks.

</details>


### [2] [Drainage: A Unifying Framework for Addressing Class Uncertainty](https://arxiv.org/abs/2512.03182)
*Yasser Taha,Grégoire Montavon,Nils Körber*

Main category: cs.CV

TL;DR: 本文提出了一种在深度学习模型输出端增加“排水节点”（drainage node）的统一框架，用于提升模型在含有噪声标签、类歧义以及需鲁棒拒绝异常样本时的表现。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在应对数据标签错误、类别模糊和异常/分布外样本时常常性能骤降，现有方法在高噪声环境下效果有限。因此需要一种能够更好分辨和容忍不确定样本的机制。

Method: 在网络输出端增加一个“排水节点”，让网络可以将部分概率质量重新分配给不确定（疑似噪声或异类）样本，提升识别和规避噪声/异常样本的能力。该方法保持端到端可训练并具备可微性。在CIFAR-10/100等数据集上，加入了不同比例的依赖于样本的噪声和非对称噪声进行实验。

Result: 该方法在高噪声情况下，相比已有方法最高提升了9%的分类精度。在mini-WebVision、mini-ImageNet和Clothing-1M等真实世界数据集上，也达到或超过最新水平。定性分析显示“排水神经元”能有效吸收误标、异常和离群样本，改善模型决策边界稳定性。

Conclusion: ‘排水节点’不仅提升了对噪声和异常样本的鲁棒性，并具备广泛应用潜力，如大规模网页数据、半监督数据清洗和开放集识别等任务，方法简洁且端到端可用。

Abstract: Modern deep learning faces significant challenges with noisy labels, class ambiguity, as well as the need to robustly reject out-of-distribution or corrupted samples. In this work, we propose a unified framework based on the concept of a "drainage node'' which we add at the output of the network. The node serves to reallocate probability mass toward uncertainty, while preserving desirable properties such as end-to-end training and differentiability. This mechanism provides a natural escape route for highly ambiguous, anomalous, or noisy samples, particularly relevant for instance-dependent and asymmetric label noise. In systematic experiments involving the addition of varying proportions of instance-dependent noise or asymmetric noise to CIFAR-10/100 labels, our drainage formulation achieves an accuracy increase of up to 9\% over existing approaches in the high-noise regime. Our results on real-world datasets, such as mini-WebVision, mini-ImageNet and Clothing-1M, match or surpass existing state-of-the-art methods. Qualitative analysis reveals a denoising effect, where the drainage neuron consistently absorbs corrupt, mislabeled, or outlier data, leading to more stable decision boundaries. Furthermore, our drainage formulation enables applications well beyond classification, with immediate benefits for web-scale, semi-supervised dataset cleaning, and open-set applications.

</details>


### [3] [Does Head Pose Correction Improve Biometric Facial Recognition?](https://arxiv.org/abs/2512.03199)
*Justin Norman,Hany Farid*

Main category: cs.CV

TL;DR: 研究评估了针对人脸识别中图像姿态校正与修复方法对识别准确率的影响，不同修复方式对结果有明显差异。


<details>
  <summary>Details</summary>
Motivation: 现实世界中采集的人脸图像质量较差、姿态非正面、或出现遮挡，导致人脸识别准确率明显降低。因此，作者想探究AI驱动的图像恢复与姿态校正能否提升识别准确率。

Method: 作者设计了一个与具体识别模型无关的大规模法医评估流程，评估了三种主要图像恢复方法：3D 重建（NextFace）、2D 正面化（CFR-GAN）、特征增强（CodeFormer），并测试各方法及其组合对识别准确率的影响。

Result: 直接应用这些修复技术反而会大幅降低识别准确率，但有选择地结合使用CFR-GAN和CodeFormer，可以取得明显的准确率提升。

Conclusion: 并非所有图像校正和修复方法都能提升人脸识别表现，需针对性选择和组合方法，才能在现实条件下有效提升准确率。

Abstract: Biometric facial recognition models often demonstrate significant decreases in accuracy when processing real-world images, often characterized by poor quality, non-frontal subject poses, and subject occlusions. We investigate whether targeted, AI-driven, head-pose correction and image restoration can improve recognition accuracy. Using a model-agnostic, large-scale, forensic-evaluation pipeline, we assess the impact of three restoration approaches: 3D reconstruction (NextFace), 2D frontalization (CFR-GAN), and feature enhancement (CodeFormer). We find that naive application of these techniques substantially degrades facial recognition accuracy. However, we also find that selective application of CFR-GAN combined with CodeFormer yields meaningful improvements.

</details>


### [4] [Flux4D: Flow-based Unsupervised 4D Reconstruction](https://arxiv.org/abs/2512.03210)
*Jingkang Wang,Henry Che,Yun Chen,Ze Yang,Lily Goli,Sivabalan Manivasagam,Raquel Urtasun*

Main category: cs.CV

TL;DR: 本文提出了一种名为Flux4D的新方法，可对大规模动态场景进行高效的4D重建，不需要人工标注，且具有很强的扩展性和泛化能力。方法在多个数据集上大幅超越现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有NeRF和3DGS等方法虽能逼真重建场景，但在处理大规模动态环境时扩展性有限，并依赖人工注释以分离动态物体。自监督方案虽可降低标注需求，但优化过程效率低且对超参数敏感。因而有必要提出无需标注、训练高效且能泛化的新方法。

Method: 提出了Flux4D框架，通过直接预测3D高斯及其运动动力学，结合仅使用光度损失和“尽可能静止”正则化实现。无需预训练模型或先验，仅通过跨多个场景训练即可。优点是全流程自监督、高效，可扩展到大规模场景与新环境。

Result: 在实际户外驾驶数据集上，Flux4D在扩展性、泛化性以及重建质量方面都显著优于当前主流方法，实现了秒级重建。

Conclusion: Flux4D为大规模动态场景的4D重建带来了高效、无监督、强泛化力的解决方案，具有更好实用前景，适用于机器人和自动驾驶领域。

Abstract: Reconstructing large-scale dynamic scenes from visual observations is a fundamental challenge in computer vision, with critical implications for robotics and autonomous systems. While recent differentiable rendering methods such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have achieved impressive photorealistic reconstruction, they suffer from scalability limitations and require annotations to decouple actor motion. Existing self-supervised methods attempt to eliminate explicit annotations by leveraging motion cues and geometric priors, yet they remain constrained by per-scene optimization and sensitivity to hyperparameter tuning. In this paper, we introduce Flux4D, a simple and scalable framework for 4D reconstruction of large-scale dynamic scenes. Flux4D directly predicts 3D Gaussians and their motion dynamics to reconstruct sensor observations in a fully unsupervised manner. By adopting only photometric losses and enforcing an "as static as possible" regularization, Flux4D learns to decompose dynamic elements directly from raw data without requiring pre-trained supervised models or foundational priors simply by training across many scenes. Our approach enables efficient reconstruction of dynamic scenes within seconds, scales effectively to large datasets, and generalizes well to unseen environments, including rare and unknown objects. Experiments on outdoor driving datasets show Flux4D significantly outperforms existing methods in scalability, generalization, and reconstruction quality.

</details>


### [5] [Object Counting with GPT-4o and GPT-5: A Comparative Study](https://arxiv.org/abs/2512.03233)
*Richard Füzesséry,Kaziwa Saleh,Sándor Szénási,Zoltán Vámossy*

Main category: cs.CV

TL;DR: 本文利用多模态大模型（如GPT-4o和GPT-5），在无需任何监督和视觉示例的情况下，通过文本提示实现了Zero-shot对象计数，效果接近或超过现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统Zero-shot对象计数方法依赖大量标注数据和视觉样本，难以大规模应用。随着多模态大模型的发展，其推理与理解能力为无需监督的对象计数带来新的可能。

Method: 作者利用GPT-4o和GPT-5两种多模态大模型，仅通过设定文本提示，无需任何标注和视觉样本，在FSC-147和CARPK数据集上进行Zero-shot对象计数实验。

Result: 实验结果表明，在FSC-147数据集上，这两种多模态大模型在Zero-shot对象计数任务中，取得了与当前最佳方法相当甚至更好的效果。

Conclusion: 多模态大模型具备强大的无监督对象计数能力，在无需人工标注和视觉示例的情况下，能有效执行Zero-shot计数任务，为未来相关研究提供了新方向。

Abstract: Zero-shot object counting attempts to estimate the number of object instances belonging to novel categories that the vision model performing the counting has never encountered during training. Existing methods typically require large amount of annotated data and often require visual exemplars to guide the counting process. However, large language models (LLMs) are powerful tools with remarkable reasoning and data understanding abilities, which suggest the possibility of utilizing them for counting tasks without any supervision. In this work we aim to leverage the visual capabilities of two multi-modal LLMs, GPT-4o and GPT-5, to perform object counting in a zero-shot manner using only textual prompts. We evaluate both models on the FSC-147 and CARPK datasets and provide a comparative analysis. Our findings show that the models achieve performance comparable to the state-of-the-art zero-shot approaches on FSC-147, in some cases, even surpass them.

</details>


### [6] [LLM-Guided Material Inference for 3D Point Clouds](https://arxiv.org/abs/2512.03237)
*Nafiseh Izadyar,Teseo Schneider*

Main category: cs.CV

TL;DR: 提出了一种基于大模型的两阶段方法，可以从3D点云（带有粗分割）推断出物体的材料组成，实现了高可信度的语义与材料匹配并验证了可行性。


<details>
  <summary>Details</summary>
Motivation: 当前3D形状数据集和模型大多只关注几何结构，忽略了影响物体外观的材料属性。材料信息对3D认知和应用非常重要，但缺乏相关数据和方法。

Method: 方法分为两阶段：第一阶段利用大语言模型(LLM)推断物体的语义类别；第二阶段根据推测出的语义，为每个几何分段分配合适的材料。两阶段均为零样本推理，无需特定任务训练。由于缺乏真实材料注释数据，采用LLM自动评测系统进行评估。

Result: 在Fusion/ABS和ShapeNet数据集的1000个样本上，该方法在语义和材料推断的可信度上表现良好，结果被LLM-as-a-Judge系统认可。

Conclusion: 大语言模型可以作为通用先验，帮助3D点云数据信息推理，将几何信息和材料属性成功关联，为3D视觉理解和应用提供了新思路。

Abstract: Most existing 3D shape datasets and models focus solely on geometry, overlooking the material properties that determine how objects appear. We introduce a two-stage large language model (LLM) based method for inferring material composition directly from 3D point clouds with coarse segmentations. Our key insight is to decouple reasoning about what an object is from what it is made of. In the first stage, an LLM predicts the object's semantic; in the second stage, it assigns plausible materials to each geometric segment, conditioned on the inferred semantics. Both stages operate in a zero-shot manner, without task-specific training. Because existing datasets lack reliable material annotations, we evaluate our method using an LLM-as-a-Judge implemented in DeepEval. Across 1,000 shapes from Fusion/ABS and ShapeNet, our method achieves high semantic and material plausibility. These results demonstrate that language models can serve as general-purpose priors for bridging geometric reasoning and material understanding in 3D data.

</details>


### [7] [2-Shots in the Dark: Low-Light Denoising with Minimal Data Acquisition](https://arxiv.org/abs/2512.03245)
*Liying Lu,Raphaël Achddou,Sabine Süsstrunk*

Main category: cs.CV

TL;DR: 本文提出了一种新的噪声合成方法，只需每个 ISO 设置下一张含噪声图片和一张黑场图片即可，实现了低光图像中更真实的噪声建模，用于训练高质量去噪算法，无需大规模成对数据集，结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的图像去噪方法依赖于大量的干净与噪声图像配对数据，而实际采集这些数据非常困难。噪声合成是一种替代数据采集的方法，但现有噪声模型要么过于简化、要么对数据量依赖大，无法准确还原实际摄像头的噪声分布，因此需要一种既准确又实用的噪声合成方法。

Method: 作者提出了一种结合泊松分布模拟信号相关噪声，以及基于傅里叶域谱采样方法准确模拟信号无关噪声的合成方法。每种 ISO 设置下，仅需一张噪声图片和一张黑场图片即可完成模型拟合，不依赖于大量成对样本或复杂的参数化模型。

Result: 经实验证明，该方法生成的合成噪声在空间和统计特性上与真实传感器噪声高度一致。通过该噪声合成方法训练的去噪模型在多个低光图像去噪基准测试中表现优异，达到或超过当前最先进水平。

Conclusion: 该方法在无需大量标注数据的情况下，为低光去噪研究提供了高质量噪声数据合成的新途径，兼具准确性与实用性，对推进低光图像去噪和相关领域研究具有实际意义。

Abstract: Raw images taken in low-light conditions are very noisy due to low photon count and sensor noise. Learning-based denoisers have the potential to reconstruct high-quality images. For training, however, these denoisers require large paired datasets of clean and noisy images, which are difficult to collect. Noise synthesis is an alternative to large-scale data acquisition: given a clean image, we can synthesize a realistic noisy counterpart. In this work, we propose a general and practical noise synthesis method that requires only one single noisy image and one single dark frame per ISO setting. We represent signal-dependent noise with a Poisson distribution and introduce a Fourier-domain spectral sampling algorithm to accurately model signal-independent noise. The latter generates diverse noise realizations that maintain the spatial and statistical properties of real sensor noise. As opposed to competing approaches, our method neither relies on simplified parametric models nor on large sets of clean-noisy image pairs. Our synthesis method is not only accurate and practical, it also leads to state-of-the-art performances on multiple low-light denoising benchmarks.

</details>


### [8] [PixPerfect: Seamless Latent Diffusion Local Editing with Discriminative Pixel-Space Refinement](https://arxiv.org/abs/2512.03247)
*Haitian Zheng,Yuan Yao,Yongsheng Yu,Yuqian Zhou,Jiebo Luo,Zhe Lin*

Main category: cs.CV

TL;DR: 本文提出PixPerfect，一种旨在解决现有LDMs在局部图像编辑时常见像素级失真（如颜色偏移、纹理不匹配和接缝）的问题的像素级修正框架。实验显示其大幅提升了局部编辑的视觉质量。


<details>
  <summary>Details</summary>
Motivation: 现有潜在扩散模型（LDMs）在图像修复和局部编辑时，因潜在空间压缩导致图像出现明显的像素级失真。而现有解决方案（如基于背景的条件解码、像素空间谐调）不能完全去除这些伪影，并缺乏跨任务、跨模型泛化能力。因此需要一种通用、有效的像素级修正方案。

Method: 提出了PixPerfect框架，包括：(1) 可微、判别式的像素空间用于放大与抑制颜色和纹理微小差异；(2) 全面的伪影模拟流水线，在训练阶段让修正器见到各种真实伪影；(3) 直接在像素空间进行修正，确保对多种潜在表示和任务的广泛适用性。

Result: 通过在图像修补、目标移除与插入等多个基准测试上实验，PixPerfect在提升视觉质量及后续编辑性能上均优于现有方法。

Conclusion: PixPerfect有效解决了LDMs像素级失真问题，实现了更高质量、更稳健的局部图像编辑，为高保真图像编辑树立了新标准。

Abstract: Latent Diffusion Models (LDMs) have markedly advanced the quality of image inpainting and local editing. However, the inherent latent compression often introduces pixel-level inconsistencies, such as chromatic shifts, texture mismatches, and visible seams along editing boundaries. Existing remedies, including background-conditioned latent decoding and pixel-space harmonization, usually fail to fully eliminate these artifacts in practice and do not generalize well across different latent representations or tasks. We introduce PixPerfect, a pixel-level refinement framework that delivers seamless, high-fidelity local edits across diverse LDM architectures and tasks. PixPerfect leverages (i) a differentiable discriminative pixel space that amplifies and suppresses subtle color and texture discrepancies, (ii) a comprehensive artifact simulation pipeline that exposes the refiner to realistic local editing artifacts during training, and (iii) a direct pixel-space refinement scheme that ensures broad applicability across diverse latent representations and tasks. Extensive experiments on inpainting, object removal, and insertion benchmarks demonstrate that PixPerfect substantially enhances perceptual fidelity and downstream editing performance, establishing a new standard for robust and high-fidelity localized image editing.

</details>


### [9] [PyroFocus: A Deep Learning Approach to Real-Time Wildfire Detection in Multispectral Remote Sensing Imagery](https://arxiv.org/abs/2512.03257)
*Mark Moussa,Andre Williams,Seth Roffe,Douglas Morton*

Main category: cs.CV

TL;DR: 本文针对野火检测，提出了一种高效的两阶段深度学习流水线PyroFocus，用于在多光谱及高光谱热成像数据上实现快速、准确的野火分类与强度估算，并通过NASA真实航拍数据验证其在速度和准确性之间的优异权衡，适合未来机载实时应用。


<details>
  <summary>Details</summary>
Motivation: 随着野火频率和强度不断增加，现有机载或星载成像器需实现实时、低延迟、高精度的野火检测与火势评估，但多光谱/高光谱数据维度高且机载计算资源有限，传统方法难以满足实时处理需求，因此亟需开发高效且资源友好的 onboard 检测方法。

Method: 系统评估多种深度学习结构（包括自定义卷积神经网络和Transformer模型）在多类别火灾分类上的表现，并提出PyroFocus两阶段流水线，先进行火灾分类，再做火辐射功率（FRP）回归或分割，有效减少推理时间和计算负荷；实验采用NASA MASTER航拍数据集，比较不同模型在准确率、延迟和资源消耗上的表现。

Result: 实验结果表明，PyroFocus两阶段流程在保持较高准确率的同时，大幅降低了推理延迟和资源消耗，性能优于传统单阶段方法，展现出强大的实时机载部署潜力。

Conclusion: 该研究展示了利用先进深度学习架构结合分阶段设计，可显著提升多光谱/高光谱野火检测的效率与可用性，为未来机载/星载实时火灾监测和管理任务提供了重要技术支撑。

Abstract: Rapid and accurate wildfire detection is crucial for emergency response and environmental management. In airborne and spaceborne missions, real-time algorithms must distinguish between no fire, active fire, and post-fire conditions, and estimate fire intensity. Multispectral and hyperspectral thermal imagers provide rich spectral information, but high data dimensionality and limited onboard resources make real-time processing challenging. As wildfires increase in frequency and severity, the need for low-latency and computationally efficient onboard detection methods is critical.
  We present a systematic evaluation of multiple deep learning architectures, including custom Convolutional Neural Networks (CNNs) and Transformer-based models, for multi-class fire classification. We also introduce PyroFocus, a two-stage pipeline that performs fire classification followed by fire radiative power (FRP) regression or segmentation to reduce inference time and computational cost for onboard deployment. Using data from NASA's MODIS/ASTER Airborne Simulator (MASTER), which is similar to a next-generation fire detection sensor, we compare accuracy, inference latency, and resource efficiency.
  Experimental results show that the proposed two-stage pipeline achieves strong trade-offs between speed and accuracy, demonstrating significant potential for real-time edge deployment in future wildfire monitoring missions.

</details>


### [10] [SpatialReasoner: Active Perception for Large-Scale 3D Scene Understanding](https://arxiv.org/abs/2512.03284)
*Hongpei Zheng,Shijie Li,Yanran Li,Hujun Yin*

Main category: cs.CV

TL;DR: 本文提出了H^2U3D数据集和SpatialReasoner方法，显著提升了大尺度3D房屋场景下的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 多数视觉语言模型仅适用于房间级别的小型场景，难以处理较大、复杂的真实住宅环境。作者希望推动在多层、多房间、数百平方米空间中的3D理解和空间推理。

Method: 1）构建H^2U3D数据集，自动标注、包含链式思考的问答对，并覆盖多层住宅、细粒度空间结构；2）提出SpatialReasoner模型，借助主动感知和空间工具探索，根据文本查询分阶段自主决策，并采用监督+强化学习结合训练。

Result: SpatialReasoner在H^2U3D数据集上性能优于包括GPT-4o与Gemini-2.5-Pro等强大基线，并且仅需平均3-4张图片即可完成任务，而基线通常需要16张以上图像。

Conclusion: H^2U3D为大尺度室内空间推理任务提供了新基准，SpatialReasoner显著提升了探索效率与推理能力，为未来3D视觉语言模型发展奠定基础。

Abstract: Spatial reasoning in large-scale 3D environments remains challenging for current vision-language models, which are typically constrained to room-scale scenarios. We introduce H$^2$U3D (Holistic House Understanding in 3D), a 3D visual question answering dataset designed for house-scale scene understanding. H$^2$U3D features multi-floor environments spanning up to three floors and 10-20 rooms, covering more than 300 m$^2$. Through an automated annotation pipeline, it constructs hierarchical coarse-to-fine visual representations and generates diverse question-answer pairs with chain-of-thought annotations. We further propose SpatialReasoner, an active perception framework that autonomously invokes spatial tools to explore 3D scenes based on textual queries. SpatialReasoner is trained through a two-stage strategy: a supervised cold start followed by reinforcement learning with an adaptive exploration reward that promotes efficient exploration while discouraging redundant operations. Extensive experiments demonstrate that SpatialReasoner achieves state-of-the-art performance on H$^2$U3D, outperforming strong baselines including GPT-4o and Gemini-2.5-Pro. Notably, our method attains superior results while using only 3-4 images in total on average, compared to baselines requiring 16+ images, highlighting the effectiveness of our coarse-to-fine active exploration paradigm.

</details>


### [11] [NavMapFusion: Diffusion-based Fusion of Navigation Maps for Online Vectorized HD Map Construction](https://arxiv.org/abs/2512.03317)
*Thomas Monninger,Zihan Zhang,Steffen Staab,Sihao Ding*

Main category: cs.CV

TL;DR: 本文提出了一种名为NavMapFusion的扩散式地图融合框架，实现了基于高精度传感器数据和低精度导航地图的在线高精地图构建。该方法克服了传统HD地图无法实时更新的问题，显著提升了自动驾驶环境表示的准确性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶依赖高精地图保证安全与高效导航，但现实世界环境变化频繁，传统的静态HD地图无法实时反映当前道路状况。现有标准定义（SD）地图分辨率较低，难以直接应用，但可以作为先验知识辅助在线地图构建。因此，亟需一种能够高效融合SD先验和实时传感器感知的在线高精地图构建方法。

Method: 作者提出NavMapFusion框架，利用扩散模型进行迭代去噪处理，将高精度传感器数据与低精度导航地图（如OpenStreetMap）结合。将导航地图作为粗糙先验，在扩散模型中利用传感器感知不断修正和提升地图精度。通过发现在先验地图和当前感知之间的差异可视为扩散噪声，模型自动强化一致区域、抑制过时区域。

Result: 在nuScenes基准测试中，NavMapFusion以OpenStreetMap粗略道路线为先验，在100米感知范围取得21.4%的相对精度提升，在更大感知范围提升更为显著，并保持实时能力。

Conclusion: NavMapFusion通过融合低精度先验与高精度感知，成功生成准确、及时的环境表示，为更安全、可靠的自动驾驶导航提供基础。

Abstract: Accurate environmental representations are essential for autonomous driving, providing the foundation for safe and efficient navigation. Traditionally, high-definition (HD) maps are providing this representation of the static road infrastructure to the autonomous system a priori. However, because the real world is constantly changing, such maps must be constructed online from on-board sensor data. Navigation-grade standard-definition (SD) maps are widely available, but their resolution is insufficient for direct deployment. Instead, they can be used as coarse prior to guide the online map construction process. We propose NavMapFusion, a diffusion-based framework that performs iterative denoising conditioned on high-fidelity sensor data and on low-fidelity navigation maps. This paper strives to answer: (1) How can coarse, potentially outdated navigation maps guide online map construction? (2) What advantages do diffusion models offer for map fusion? We demonstrate that diffusion-based map construction provides a robust framework for map fusion. Our key insight is that discrepancies between the prior map and online perception naturally correspond to noise within the diffusion process; consistent regions reinforce the map construction, whereas outdated segments are suppressed. On the nuScenes benchmark, NavMapFusion conditioned on coarse road lines from OpenStreetMap data reaches a 21.4% relative improvement on 100 m, and even stronger improvements on larger perception ranges, while maintaining real-time capabilities. By fusing low-fidelity priors with high-fidelity sensor data, the proposed method generates accurate and up-to-date environment representations, guiding towards safer and more reliable autonomous driving. The code is available at https://github.com/tmonnin/navmapfusion

</details>


### [12] [Step-by-step Layered Design Generation](https://arxiv.org/abs/2512.03335)
*Faizan Farooq Khan,K J Joseph,Koustava Goswami,Mohamed Elhoseiny,Balaji Vasan Srinivasan*

Main category: cs.CV

TL;DR: 该论文提出了一种基于分步、分层思想的设计生成新问题设定，并提出了SLEDGE方法以及配套的评测数据集和基准。其实验验证了该方法在逐步设计生成任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前的设计生成方法通常是单步生成，未能贴合真实设计创作中逐步完善的过程，因此需要新的建模与方法以更好地模拟设计创作的复杂动态。

Method: 作者提出了分步分层设计生成（Step-by-Step Layered Design Generation）的问题设定，并基于多模态大型语言模型（multimodal LLMs）提出了SLEDGE方法，将每一次设计修改建模为叠加在前态上的“原子分层”操作，同时受到设计师指令驱动。为此，他们自建了新数据集和评价体系进行系统性验证。

Result: 通过系统实验，作者的方法在提出的新任务上优于多种现有SOTA技术，结果证明了SLEDGE的效果和分步生成机制的优越性。

Conclusion: 该工作不仅提出了切合实际需求的新建模和评测框架，还为分步分层设计生成领域打开了新的研究思路，显示了此类方法的广阔前景。

Abstract: Design generation, in its essence, is a step-by-step process where designers progressively refine and enhance their work through careful modifications. Despite this fundamental characteristic, existing approaches mainly treat design synthesis as a single-step generation problem, significantly underestimating the inherent complexity of the creative process. To bridge this gap, we propose a novel problem setting called Step-by-Step Layered Design Generation, which tasks a machine learning model with generating a design that adheres to a sequence of instructions from a designer. Leveraging recent advancements in multi-modal LLMs, we propose SLEDGE: Step-by-step LayEred Design GEnerator to model each update to a design as an atomic, layered change over its previous state, while being grounded in the instruction. To complement our new problem setting, we introduce a new evaluation suite, including a dataset and a benchmark. Our exhaustive experimental analysis and comparison with state-of-the-art approaches tailored to our new setup demonstrate the efficacy of our approach. We hope our work will attract attention to this pragmatic and under-explored research area.

</details>


### [13] [ProtoEFNet: Dynamic Prototype Learning for Inherently Interpretable Ejection Fraction Estimation in Echocardiography](https://arxiv.org/abs/2512.03339)
*Yeganeh Ghamary,Victoria Wu,Hooman Vaseli,Christina Luong,Teresa Tsang,Siavash Bigdeli,Purang Abolmaesumi*

Main category: cs.CV

TL;DR: 本文提出了一种新型基于视频的原型学习模型ProtoEFNet，用于心脏射血分数（EF）的连续回归预测，并兼具高准确性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统EF评估方法依赖人工描摹，费时且结果受操作者影响；现有深度学习方法多为黑箱模型，缺乏可解释性和临床信任度，后验解释性方法亦难以增强模型本质的可解释性。

Method: 提出ProtoEFNet模型，通过学习动态时空原型，捕获有临床意义的心脏运动模式，并设计Prototype Angular Separation（PAS）损失，以提升不同EF值区间的区分能力。

Result: 在EchonetDynamic数据集上，ProtoEFNet在保证解释性的同时，达到了与不可解释模型相当的准确率。消融实验显示，PAS损失可提升F1分数2%，从77.67±2.68提升至79.64±2.10。

Conclusion: ProtoEFNet能够兼顾高效、准确和可解释三者，有助于提升临床实际应用中的信任度，其代码已开源。

Abstract: Ejection fraction (EF) is a crucial metric for assessing cardiac function and diagnosing conditions such as heart failure. Traditionally, EF estimation requires manual tracing and domain expertise, making the process time-consuming and subject to interobserver variability. Most current deep learning methods for EF prediction are black-box models with limited transparency, which reduces clinical trust. Some post-hoc explainability methods have been proposed to interpret the decision-making process after the prediction is made. However, these explanations do not guide the model's internal reasoning and therefore offer limited reliability in clinical applications. To address this, we introduce ProtoEFNet, a novel video-based prototype learning model for continuous EF regression. The model learns dynamic spatiotemporal prototypes that capture clinically meaningful cardiac motion patterns. Additionally, the proposed Prototype Angular Separation (PAS) loss enforces discriminative representations across the continuous EF spectrum. Our experiments on the EchonetDynamic dataset show that ProtoEFNet can achieve accuracy on par with its non-interpretable counterpart while providing clinically relevant insight. The ablation study shows that the proposed loss boosts performance with a 2% increase in F1 score from 77.67$\pm$2.68 to 79.64$\pm$2.10. Our source code is available at: https://github.com/DeepRCL/ProtoEF

</details>


### [14] [HalluGen: Synthesizing Realistic and Controllable Hallucinations for Evaluating Image Restoration](https://arxiv.org/abs/2512.03345)
*Seunghoi Kim,Henry F. J. Tregidgo,Chen Jin,Matteo Figini,Daniel C. Alexander*

Main category: cs.CV

TL;DR: 本文提出了Hallugen框架，用于合成和评估生成模型在医学影像等安全关键领域中可能出现的幻觉（即看似合理但实际错误的结构），并首次构建了大规模的医疗影像幻觉数据集。


<details>
  <summary>Details</summary>
Motivation: 生成模型在医学影像修复等关键任务中容易产生幻觉，可能导致严重后果，而幻觉评估受限于高成本且主观的人工标注，缺乏大规模公开数据和系统化评价工具。

Method: 提出了Hallugen，一种基于扩散的框架，可以可控地合成类别、位置和程度各异的幻觉图像。同时，利用Hallugen构建了1,450例脑部MRI图像衍生出4,350张注释幻觉数据，创建了第一个大规模医学影像幻觉数据集。基于该数据集，开发了SHAFE（一种特征与软注意力池化的幻觉评估新指标），并训练了无需参考的幻觉检测器。

Result: Hallugen可生成感知真实但语义错误的幻觉图像（IoU从0.86降到0.36）。基于此，提出的SHAFE指标对幻觉的敏感性优于传统指标，无参考幻觉检测器在真实修复失败案例上具有良好泛化能力。

Conclusion: Hallugen及其开源的数据集为安全关键领域的图像修复幻觉问题提供了可扩展的评估基础，推动了幻觉检测与防控相关研究的发展。

Abstract: Generative models are prone to hallucinations: plausible but incorrect structures absent in the ground truth. This issue is problematic in image restoration for safety-critical domains such as medical imaging, industrial inspection, and remote sensing, where such errors undermine reliability and trust. For example, in low-field MRI, widely used in resource-limited settings, restoration models are essential for enhancing low-quality scans, yet hallucinations can lead to serious diagnostic errors. Progress has been hindered by a circular dependency: evaluating hallucinations requires labeled data, yet such labels are costly and subjective. We introduce HalluGen, a diffusion-based framework that synthesizes realistic hallucinations with controllable type, location, and severity, producing perceptually realistic but semantically incorrect outputs (segmentation IoU drops from 0.86 to 0.36). Using HalluGen, we construct the first large-scale hallucination dataset comprising 4,350 annotated images derived from 1,450 brain MR images for low-field enhancement, enabling systematic evaluation of hallucination detection and mitigation. We demonstrate its utility in two applications: (1) benchmarking image quality metrics and developing Semantic Hallucination Assessment via Feature Evaluation (SHAFE), a feature-based metric with soft-attention pooling that improves hallucination sensitivity over traditional metrics; and (2) training reference-free hallucination detectors that generalize to real restoration failures. Together, HalluGen and its open dataset establish the first scalable foundation for evaluating hallucinations in safety-critical image restoration.

</details>


### [15] [Hierarchical Attention for Sparse Volumetric Anomaly Detection in Subclinical Keratoconus](https://arxiv.org/abs/2512.03346)
*Lynn Kandakji,William Woof,Nikolas Pontikos*

Main category: cs.CV

TL;DR: 本文比较了十六种深度学习网络架构在3D OCT医学影像中检测早期角膜圆锥（SKC）的效果，发现分层注意力模型比CNN和ViT更优，适合发现分布稀疏的异常。


<details>
  <summary>Details</summary>
Motivation: 当前体积医学影像中稀疏、微弱和空间分布异常（如早期疾病信号）难以检测，主流CNN结构过于偏重局部特征，ViT结构则导致注意力过于分散，缺乏合适的归纳偏置来捕捉关键信号。

Method: 研究系统比较了2D/3D卷积、混合型和体积Transformer等16类代表性深度学习架构在3D角膜OCT影像中检测亚临床角膜圆锥的表现，分析注意力机制、感受野范围和泛化能力。

Result: 分层窗口式注意力模型在检测稀疏异常方面参数更高效，敏感性和特异性较CNN与ViT提升21-23%。其优势源自能与病灶空间尺度精准对齐的感受野，既避免了CNN的局部性，也防止了ViT注意力弥散。

Conclusion: 分层注意力结构为稀疏体积异常检测提供了原则性且有效的模型设计方案，有望指导未来3D医学影像早期病变的自动检测。

Abstract: The detection of weak, spatially distributed anomalies in volumetric medical imaging remains a major challenge. The subtle, non-adjacent nature of early disease signals is often lost due to suboptimal architectural inductive biases: 2D/3D CNNs impose strong locality, while ViTs diffuse unconstrained global attention. This conflict leaves the optimal inductive structure for robust, sparse volumetric pattern recognition unresolved. This study presents a controlled comparison of sixteen modern deep learning architectures spanning 2D/3D convolutional, hybrid, and volumetric transformer families for subclinical keratoconus (SKC) detection from 3D anterior segment OCT volumes. We demonstrate that hierarchical attention models offer a superior and more parameter-efficient inductive bias, surpassing the performance of both 2D and 3D CNNs and ViTs. Our results show 21-23% higher sensitivity and specificity in the sparse anomaly (subclinical) regime. Mechanistic analyses reveal that this advantage stems from precise spatial scale alignment: hierarchical windowing produces effective receptive fields matched to the intermediate, multi-slice extent of subclinical abnormalities. This avoids excessive CNN locality and diffuse global attention. Attention-distance measurements confirm a key insight into architectural adaptation: the required spatial integration length shifts significantly based on the signal strength, with subclinical cases necessitating longer integration compared to both healthy and manifest disease states. Representational similarity and auxiliary age/sex prediction tasks further support the generalizability of these inductive principles. The findings provide design guidance for future volumetric anomaly detection systems, establishing hierarchical attention as a principled and effective approach for early pathological change analysis in 3D medical imaging.

</details>


### [16] [SeeU: Seeing the Unseen World via 4D Dynamics-aware Generation](https://arxiv.org/abs/2512.03350)
*Yu Yuan,Tharindu Wickremasinghe,Zeeshan Nadir,Xijun Wang,Yiheng Chi,Stanley H. Chan*

Main category: cs.CV

TL;DR: SeeU方法通过将2D图像/视频重建为4D（3D空间+时间）连续动态世界，并在此基础上生成新的视觉内容，大幅提升了视觉生成与理解任务效果。


<details>
  <summary>Details</summary>
Motivation: 目前主流视觉理解、预测与生成方法大多直接处理2D观测（图像、视频帧），无法充分利用场景背后更高维度（3D+时间）的连续信息，导致性能受限。该论文旨在突破2D限制，充分挖掘和建模4D动态世界，从而提升视觉生成和理解的能力。

Method: 提出SeeU方法，包含三步：1）2D→4D：由单目稀疏2D帧重建出4D世界模型；2）在低秩表示与物理约束下实现4D的连续动态建模（离散→连续）；3）4D→2D：将4D世界随时间推进（模拟未来），并投影回不同时间和视角2D画面，生成未见区域帧，具备时空感知。

Result: SeeU方法可以连续且物理合理地生成新的视频内容，在多项任务（如未见时间点、空间区域的生成以及视频编辑）中展现出优异的表现。

Conclusion: 通过4D世界动态建模，SeeU显著提升了视觉新内容生成的连贯性和物理一致性，对未来视觉理解、预测和生成有广阔应用前景。

Abstract: Images and videos are discrete 2D projections of the 4D world (3D space + time). Most visual understanding, prediction, and generation operate directly on 2D observations, leading to suboptimal performance. We propose SeeU, a novel approach that learns the continuous 4D dynamics and generate the unseen visual contents. The principle behind SeeU is a new 2D$\to$4D$\to$2D learning framework. SeeU first reconstructs the 4D world from sparse and monocular 2D frames (2D$\to$4D). It then learns the continuous 4D dynamics on a low-rank representation and physical constraints (discrete 4D$\to$continuous 4D). Finally, SeeU rolls the world forward in time, re-projects it back to 2D at sampled times and viewpoints, and generates unseen regions based on spatial-temporal context awareness (4D$\to$2D). By modeling dynamics in 4D, SeeU achieves continuous and physically-consistent novel visual generation, demonstrating strong potentials in multiple tasks including unseen temporal generation, unseen spatial generation, and video editing.

</details>


### [17] [A Hybrid Deep Learning Framework with Explainable AI for Lung Cancer Classification with DenseNet169 and SVM](https://arxiv.org/abs/2512.03359)
*Md Rashidul Islam,Bakary Gibba,Altagi Abdallah Bakheit Abdelgadir*

Main category: cs.CV

TL;DR: 本研究提出了一种基于深度学习的自动肺癌分类系统，利用CT扫描图像实现高精度和高可解释性的肺癌检测。DenseNet169与SVM模型均取得了98%的准确率。


<details>
  <summary>Details</summary>
Motivation: 肺癌早期诊断对提高患者生存率至关重要，但CT图像手动分析既耗时又易出错，需要自动化且高精度的肺癌识别方法来增强医疗诊断。

Method: 使用公开的IQOTHNCCD肺癌CT扫描数据集，将病例分为正常、良性、恶性三类。以DenseNet169（集成Squeeze-and-Excitation注意力机制）提取特征，结合Focal Loss解决类别不平衡，并加入特征金字塔网络（FPN）实现多尺度特征融合。此外，利用MobileNetV2进行特征提取，并基于SVM进行分类。为提升模型可解释性，引入Grad-CAM用于决策区域可视化，以及SHAP工具解释SVM模型的特征贡献。

Result: DenseNet169与SVM模型在肺癌分类任务上均实现了98%的准确率，展现出其方法的高鲁棒性和实际应用潜力。

Conclusion: 本研究证明深度学习模型能高效、可解释地实现高精度肺癌自动分类，为临床实践提供了更可靠的辅助诊断工具，有望提升肺癌检测的准确率和透明度。

Abstract: Lung cancer is a very deadly disease worldwide, and its early diagnosis is crucial for increasing patient survival rates. Computed tomography (CT) scans are widely used for lung cancer diagnosis as they can give detailed lung structures. However, manual interpretation is time-consuming and prone to human error. To surmount this challenge, the study proposes a deep learning-based automatic lung cancer classification system to enhance detection accuracy and interpretability. The IQOTHNCCD lung cancer dataset is utilized, which is a public CT scan dataset consisting of cases categorized into Normal, Benign, and Malignant and used DenseNet169, which includes Squeezeand-Excitation blocks for attention-based feature extraction, Focal Loss for handling class imbalance, and a Feature Pyramid Network (FPN) for multi-scale feature fusion. In addition, an SVM model was developed using MobileNetV2 for feature extraction, improving its classification performance. For model interpretability enhancement, the study integrated Grad-CAM for the visualization of decision-making regions in CT scans and SHAP (Shapley Additive Explanations) for explanation of feature contributions within the SVM model. Intensive evaluation was performed, and it was found that both DenseNet169 and SVM models achieved 98% accuracy, suggesting their robustness for real-world medical practice. These results open up the potential for deep learning to improve the diagnosis of lung cancer by a higher level of accuracy, transparency, and robustness.

</details>


### [18] [FireSentry: A Multi-Modal Spatio-temporal Benchmark Dataset for Fine-Grained Wildfire Spread Forecasting](https://arxiv.org/abs/2512.03369)
*Nan Zhou,Huandong Wang,Jiahao Li,Han Li,Yali Song,Qiuhua Wang,Yong Li,Xinlei Chen*

Main category: cs.CV

TL;DR: 本论文提出了FireSentry高精度野火数据集，并基于此开发了新型火情预测模型FiReDiff，实现野火传播的高精度预测与分割，显著超过现有方法。数据集和基准公开发布。


<details>
  <summary>Details</summary>
Motivation: 当前野火传播预测大多依赖低分辨率、宏观尺度的卫星数据，难以支持高精度的局地动态建模，无法满足应急响应和精准决策的需求。为此，亟需高分辨率、多模态的数据集与相应预测方法。

Method: 构建了FireSentry数据集，具有亚米级空间和亚秒级时空分辨率，通过多架无人机同步采集可见光、红外视频、现场环境数据以及经人工验证的火区分割掩码。基于数据集，对现有物理、数据驱动和生成模型进行了系统基准测试，创新提出FiReDiff双模态预测范式，先基于红外视频序列预测未来动态，再据此实现掩码的精确分割。

Result: FiReDiff模型在视频生成质量和掩码分割精度上均显著领先现有生成模型。在PSNR、SSIM、LPIPS、FVD等视频指标及AUPRC、F1、IoU、MSE等分割指标上，实现了最高39.2%~62.5%的提升。

Conclusion: FireSentry数据集及FiReDiff模型极大推动了野火细粒度预测与灾害动态模拟领域发展，数据集已公开，促进后续研究。

Abstract: Fine-grained wildfire spread prediction is crucial for enhancing emergency response efficacy and decision-making precision. However, existing research predominantly focuses on coarse spatiotemporal scales and relies on low-resolution satellite data, capturing only macroscopic fire states while fundamentally constraining high-precision localized fire dynamics modeling capabilities. To bridge this gap, we present FireSentry, a provincial-scale multi-modal wildfire dataset characterized by sub-meter spatial and sub-second temporal resolution. Collected using synchronized UAV platforms, FireSentry provides visible and infrared video streams, in-situ environmental measurements, and manually validated fire masks. Building on FireSentry, we establish a comprehensive benchmark encompassing physics-based, data-driven, and generative models, revealing the limitations of existing mask-only approaches. Our analysis proposes FiReDiff, a novel dual-modality paradigm that first predicts future video sequences in the infrared modality, and then precisely segments fire masks in the mask modality based on the generated dynamics. FiReDiff achieves state-of-the-art performance, with video quality gains of 39.2% in PSNR, 36.1% in SSIM, 50.0% in LPIPS, 29.4% in FVD, and mask accuracy gains of 3.3% in AUPRC, 59.1% in F1 score, 42.9% in IoU, and 62.5% in MSE when applied to generative models. The FireSentry benchmark dataset and FiReDiff paradigm collectively advance fine-grained wildfire forecasting and dynamic disaster simulation. The processed benchmark dataset is publicly available at: https://github.com/Munan222/FireSentry-Benchmark-Dataset.

</details>


### [19] [ShelfGaussian: Shelf-Supervised Open-Vocabulary Gaussian-based 3D Scene Understanding](https://arxiv.org/abs/2512.03370)
*Lingjun Zhao,Yandong Luo,James Hay,Lu Gan*

Main category: cs.CV

TL;DR: ShelfGaussian是一种结合开集语义和多模态输入的高效3D场景理解方法，依赖于现有视觉基础模型进行监督，在多个场景理解任务中取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 当前高斯模型在3D场景任务中高效，但要么仅限于有标注的闭集语义、缺乏渲染能力，要么只用2D自监督导致3D表达性能受限。缺少一种既能开集泛化，又能结合多模态、3D/2D能力的统一方法。

Method: 提出Multi-Modal Gaussian Transformer，使高斯表示能查询多种传感器特征，并创新性引入Shelf-Supervised Learning，利用VFM的特征同时在2D与3D上高效监督高斯表示的学习。

Result: 在Occ3D-nuScenes数据集上实现了当前最优的零样本语义占用预测性能，并在无人车真实城区任务上验证了方法的实用性和泛化能力。

Conclusion: ShelfGaussian有效解决了3D场景理解中的开集、跨模态和多任务挑战，为计算机视觉和机器人提供了强大且高效的3D感知方案。

Abstract: We introduce ShelfGaussian, an open-vocabulary multi-modal Gaussian-based 3D scene understanding framework supervised by off-the-shelf vision foundation models (VFMs). Gaussian-based methods have demonstrated superior performance and computational efficiency across a wide range of scene understanding tasks. However, existing methods either model objects as closed-set semantic Gaussians supervised by annotated 3D labels, neglecting their rendering ability, or learn open-set Gaussian representations via purely 2D self-supervision, leading to degraded geometry and limited to camera-only settings. To fully exploit the potential of Gaussians, we propose a Multi-Modal Gaussian Transformer that enables Gaussians to query features from diverse sensor modalities, and a Shelf-Supervised Learning Paradigm that efficiently optimizes Gaussians with VFM features jointly at 2D image and 3D scene levels. We evaluate ShelfGaussian on various perception and planning tasks. Experiments on Occ3D-nuScenes demonstrate its state-of-the-art zero-shot semantic occupancy prediction performance. ShelfGaussian is further evaluated on an unmanned ground vehicle (UGV) to assess its in the-wild performance across diverse urban scenarios. Project website: https://lunarlab-gatech.github.io/ShelfGaussian/.

</details>


### [20] [MOS: Mitigating Optical-SAR Modality Gap for Cross-Modal Ship Re-Identification](https://arxiv.org/abs/2512.03404)
*Yujian Zhao,Hankun Liu,Guanglin Niu*

Main category: cs.CV

TL;DR: 本文提出了MOS框架，显著提升了光学与SAR跨模态舰船重识别的表现。


<details>
  <summary>Details</summary>
Motivation: 光学与SAR图像之间存在显著模态差异，当前针对两者跨模态舰船重识别的研究较少，准确识别具有挑战性。

Method: 提出MOS框架，包括两个核心模块：（1）模态一致性表示学习（MCRL），通过SAR图像去噪和类内模态对齐损失，实现跨模态特征分布对齐；（2）跨模态数据生成与特征融合（CDGF），利用布朗桥扩散模型合成跨模态样本，并在推理阶段与原始特征融合，提升特征对齐与区分能力。

Result: 在HOSS ReID数据集上，MOS在所有评测协议下均超越现有方法，R1准确率分别提升了3.0%、6.2%、16.4%。

Conclusion: MOS有效缩小了光学与SAR图像间的模态鸿沟，对跨模态舰船重识别提供了强有力的解决方案。

Abstract: Cross-modal ship re-identification (ReID) between optical and synthetic aperture radar (SAR) imagery has recently emerged as a critical yet underexplored task in maritime intelligence and surveillance. However, the substantial modality gap between optical and SAR images poses a major challenge for robust identification. To address this issue, we propose MOS, a novel framework designed to mitigate the optical-SAR modality gap and achieve modality-consistent feature learning for optical-SAR cross-modal ship ReID. MOS consists of two core components: (1) Modality-Consistent Representation Learning (MCRL) applies denoise SAR image procession and a class-wise modality alignment loss to align intra-identity feature distributions across modalities. (2) Cross-modal Data Generation and Feature fusion (CDGF) leverages a brownian bridge diffusion model to synthesize cross-modal samples, which are subsequently fused with original features during inference to enhance alignment and discriminability. Extensive experiments on the HOSS ReID dataset demonstrate that MOS significantly surpasses state-of-the-art methods across all evaluation protocols, achieving notable improvements of +3.0%, +6.2%, and +16.4% in R1 accuracy under the ALL to ALL, Optical to SAR, and SAR to Optical settings, respectively. The code and trained models will be released upon publication.

</details>


### [21] [ViDiC: Video Difference Captioning](https://arxiv.org/abs/2512.03405)
*Jiangtao Wu,Shihao Li,Zhaozhou Bian,Yuanxing Zhang,Jialu Chen,Runzhe Wen,An Ping,Yiwen He,Jiakai Wang,Jiaheng Liu*

Main category: cs.CV

TL;DR: 本文提出了视频差异描述（Video Difference Captioning, ViDiC）任务及其数据集ViDiC-1K，以评估多模态大模型对视频差异和相似性的细致描述能力。


<details>
  <summary>Details</summary>
Motivation: 现有对图像差异描述（IDC）主要关注静态图片，难以捕捉动态视频中的动作连续性、事件演变及编辑一致性，因此亟需适合视频对比理解的基准。

Method: 作者构建了ViDiC-1K数据集，包含1000对视频与4000+对比注释，涵盖主体、风格、背景、摄影、运动、地点与播放技术等七大类别。基于LLM-as-a-Judge协议，提出了双清单框架分别评测相似性和差异性的描述准确性。

Result: 在十九个主流多模态大模型上的实验证明，当前模型在比较视频描述和差异感知方面仍有显著能力差距。

Conclusion: ViDiC-1K为多模态智能领域提供了具有挑战性的基准，有助于推动视频理解、编辑感知和对比推理的发展。

Abstract: Understanding visual differences between dynamic scenes requires the comparative perception of compositional, spatial, and temporal changes--a capability that remains underexplored in existing vision-language systems. While prior work on Image Difference Captioning (IDC) has enabled models to describe semantic changes between static images, these approaches fail to capture motion continuity, event evolution, or editing consistency over time. We introduce the ViDiC (Video Difference Captioning) task and its corresponding ViDiC-1K dataset, designed to evaluate the ability of Multimodal Large Language Models (MLLMs) to provide fine-grained descriptions of similarities and differences between video pairs. ViDiC-1K comprises 1,000 curated video pairs annotated with over 4,000 comparative checklist items, covering seven categories: subject, style, background, cinematography, motion, location, and playback techniques. To ensure reliable evaluation, we propose a dual-checklist framework that measures the accuracy of similarity and difference separately, based on the LLM-as-a-Judge protocol. Experiments on nineteen representative multimodal models reveal a significant performance gap in their comparative description and difference perception abilities. We hope ViDiC-1K can be a challenging benchmark that lays a solid foundation for advancing video understanding, edit awareness, and comparative reasoning in multimodal intelligence.

</details>


### [22] [YOLOA: Real-Time Affordance Detection via LLM Adapter](https://arxiv.org/abs/2512.03418)
*Yuqi Ji,Junjie Ke,Lihuo He,Jun Liu,Kaifan Zhang,Yu-Kun Lai,Guiguang Ding,Xinbo Gao*

Main category: cs.CV

TL;DR: 本文提出YOLO Affordance（YOLOA）模型，实现了实时的物体可供性检测，能同时解决“是什么”、“在哪里”、“怎么用”的问题，并在准确率和效率上达到新水平。


<details>
  <summary>Details</summary>
Motivation: 现有可供性学习方法大多只关注物体的‘如何使用’，忽略了‘是什么’和‘在哪里’。此外，现有技术往往将物体检测与可供性学习分开处理，缺乏二者协同，且实时性不足。

Method: YOLOA利用大语言模型（LLM）适配器，将物体检测与可供性学习整合到一个轻量化分支网络，在训练时通过LLM Adapter与初步预测结果交互，生成更准确的类别先验、边框和可供性门控，从而优化检测结果。

Result: 在作者重标注的ADG-Det和IIT-Heat数据集上，YOLOA分别达到52.8和73.1的mAP，并且推理速度可达89.77 FPS，轻量化版本最高可达846.24 FPS，超过了现有主流方法。

Conclusion: YOLOA兼顾了检测准确率与实时性，验证了将物体检测与可供性识别协同处理及引入大语言模型适配器的有效性，推动了可供性检测方法的发展。

Abstract: Affordance detection aims to jointly address the fundamental "what-where-how" challenge in embodied AI by understanding "what" an object is, "where" the object is located, and "how" it can be used. However, most affordance learning methods focus solely on "how" objects can be used while neglecting the "what" and "where" aspects. Other affordance detection methods treat object detection and affordance learning as two independent tasks, lacking effective interaction and real-time capability. To overcome these limitations, we introduce YOLO Affordance (YOLOA), a real-time affordance detection model that jointly handles these two tasks via a large language model (LLM) adapter. Specifically, YOLOA employs a lightweight detector consisting of object detection and affordance learning branches refined through the LLM Adapter. During training, the LLM Adapter interacts with object and affordance preliminary predictions to refine both branches by generating more accurate class priors, box offsets, and affordance gates. Experiments on our relabeled ADG-Det and IIT-Heat benchmarks demonstrate that YOLOA achieves state-of-the-art accuracy (52.8 / 73.1 mAP on ADG-Det / IIT-Heat) while maintaining real-time performance (up to 89.77 FPS, and up to 846.24 FPS for the lightweight variant). This indicates that YOLOA achieves an excellent trade-off between accuracy and efficiency.

</details>


### [23] [DM3D: Deformable Mamba via Offset-Guided Gaussian Sequencing for Point Cloud Understanding](https://arxiv.org/abs/2512.03424)
*Bin Liu,Chunyang Wang,Xuelian Liu*

Main category: cs.CV

TL;DR: 提出了一种新的可变形Mamba结构DM3D，通过自适应点云序列化提升点云建模性能，在多个任务上取得SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有SSM方法难以有效处理点云这种无序、结构多样的数据，主流做法需要预设序列方式，无法适配不同几何结构。

Method: 提出DM3D架构，包括两个高斯机制模块：GKR高斯KNN重采样（自适应重排邻域点）和GDR高斯可微重排序（实现端到端序列最优排序），并设计了三路频率融合模块以提升特征表达。

Result: 在点云分类、少样本学习和部件分割等多个数据集和任务上取得了SOTA表现，证明方法有效性。

Conclusion: 自适应的序列化机制可以激发SSM在点云理解上的潜力，DM3D方法为结构多样点云处理提供强大新范式。

Abstract: State Space Models (SSMs) demonstrate significant potential for long-sequence modeling, but their reliance on input order conflicts with the irregular nature of point clouds. Existing approaches often rely on predefined serialization strategies, which cannot adjust based on diverse geometric structures. To overcome this limitation, we propose \textbf{DM3D}, a deformable Mamba architecture for point cloud understanding. Specifically, DM3D introduces an offset-guided Gaussian sequencing mechanism that unifies local resampling and global reordering within a deformable scan. The Gaussian-based KNN Resampling (GKR) enhances structural awareness by adaptively reorganizing neighboring points, while the Gaussian-based Differentiable Reordering (GDR) enables end-to-end optimization of serialization order. Furthermore, a Tri-Path Frequency Fusion module enhances feature complementarity and reduces aliasing. Together, these components enable structure-adaptive serialization of point clouds. Extensive experiments on benchmark datasets show that DM3D achieves state-of-the-art performance in classification, few-shot learning, and part segmentation, demonstrating that adaptive serialization effectively unlocks the potential of SSMs for point cloud understanding.

</details>


### [24] [Generalization Evaluation of Deep Stereo Matching Methods for UAV-Based Forestry Applications](https://arxiv.org/abs/2512.03427)
*Yida Lin,Bing Xue,Mengjie Zhang,Sam Schofield,Richard Green*

Main category: cs.CV

TL;DR: 本论文首次系统性对8种主流立体视觉深度估计算法，在未调优（zero-shot）条件下于植被密集环境（林业场景）进行评测，表明DEFOM在林业深度估计中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 尽管自主无人机在林业等植被环境的应用潜力巨大，已有深度估计方法的评测主要集中于城市和室内场景，缺乏对专用植被环境的系统测试，导致实际林业应用中面临显著性能未知风险。

Method: 作者收集了一个新的林业数据集（Canterbury forestry dataset），并选取8种当前先进立体匹配方法（包括基础模型、迭代细化方法、zero-shot适应方法等），全部仅在Scene Flow训练，不做微调，分别在4个标准基准集和新采集的林业数据集上系统对比性能（如精度、错误类型和场景适应）。

Result: 结果显示, 基础模型在结构化场景表现卓越（如BridgeDepth、DEFOM在ETH3D和KITTI优秀），但迭代细化方法在跨领域环境下更稳健（如IGEV++、IGEV）。重要发现：RAFT-Stereo在ETH3D上因负视差预测几乎彻底失效，但在KITTI正常。林业场景中，DEFOM能综合实现更高的深度平滑性、遮挡处理和跨域一致性，优于高细节的IGEV++。

Conclusion: 林业等非结构环境须针对实际场景进行评测与算法选择，DEFOM值得作为林业无人机深度估计的黄金基线。同时，现有SOTA方法在某些领域（如复杂植被）仍存在显著风险，需进一步提升方法稳健性及泛化能力。

Abstract: Autonomous UAV forestry operations require robust depth estimation methods with strong cross-domain generalization. However, existing evaluations focus on urban and indoor scenarios, leaving a critical gap for specialized vegetation-dense environments. We present the first systematic zero-shot evaluation of eight state-of-the-art stereo methods--RAFT-Stereo, IGEV, IGEV++, BridgeDepth, StereoAnywhere, DEFOM (plus baseline methods ACVNet, PSMNet, TCstereo)--spanning iterative refinement, foundation model, and zero-shot adaptation paradigms. All methods are trained exclusively on Scene Flow and evaluated without fine-tuning on four standard benchmarks (ETH3D, KITTI 2012/2015, Middlebury) plus a novel 5,313-pair Canterbury forestry dataset captured with ZED Mini camera (1920x1080). Performance reveals scene-dependent patterns: foundation models excel on structured scenes (BridgeDepth: 0.23 px on ETH3D, 0.83-1.07 px on KITTI; DEFOM: 0.35-4.65 px across benchmarks), while iterative methods maintain cross-domain robustness (IGEV++: 0.36-6.77 px; IGEV: 0.33-21.91 px). Critical finding: RAFT-Stereo exhibits catastrophic ETH3D failure (26.23 px EPE, 98 percent error rate) due to negative disparity predictions, while performing normally on KITTI (0.90-1.11 px). Qualitative evaluation on Canterbury forestry dataset identifies DEFOM as the optimal gold-standard baseline for vegetation depth estimation, exhibiting superior depth smoothness, occlusion handling, and cross-domain consistency compared to IGEV++, despite IGEV++'s finer detail preservation.

</details>


### [25] [Label-Efficient Hyperspectral Image Classification via Spectral FiLM Modulation of Low-Level Pretrained Diffusion Features](https://arxiv.org/abs/2512.03430)
*Yuzhen Hu,Biplab Banerjee,Saurabh Prasad*

Main category: cs.CV

TL;DR: 该文提出了一种利用冻结扩散模型的空间特征与光谱信息相融合的方法，实现了高分辨率下标签高效的高光谱图像分类任务。即使训练标签稀疏，该方法在两个最新高光谱数据集上均优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像在地物覆盖分类中效果显著，但受限于低空间分辨率及缺乏充足标注数据，制约了其实际应用。故探寻一种标签高效、能充分利用空间与光谱信息的分类框架成为亟需解决的问题。

Method: 提出使用在自然图像上预训练并被冻结的扩散模型提取空间特征，选择解码器早期去噪阶段的高分辨率层作为低级空间表示。为融合光谱与空间信息，引入轻量级FiLM融合模块，通过光谱线索自适应调控空间特征，实现标签稀疏条件下的多模态表征和分类。

Result: 在两个最新高光谱数据集上，实验验证了该方法在仅使用稀疏标注的情况下，分类性能显著优于当前最优方法。消融实验证明扩散模型空间特征和光谱感知融合的有效性。

Conclusion: 预训练的扩散模型具备领域无关、标签高效的特征迁移能力，有望为遥感及更广泛科研成像任务提供通用、高效的表征学习范式。

Abstract: Hyperspectral imaging (HSI) enables detailed land cover classification, yet low spatial resolution and sparse annotations pose significant challenges. We present a label-efficient framework that leverages spatial features from a frozen diffusion model pretrained on natural images. Our approach extracts low-level representations from high-resolution decoder layers at early denoising timesteps, which transfer effectively to the low-texture structure of HSI. To integrate spectral and spatial information, we introduce a lightweight FiLM-based fusion module that adaptively modulates frozen spatial features using spectral cues, enabling robust multimodal learning under sparse supervision. Experiments on two recent hyperspectral datasets demonstrate that our method outperforms state-of-the-art approaches using only the provided sparse training labels. Ablation studies further highlight the benefits of diffusion-derived features and spectral-aware fusion. Overall, our results indicate that pretrained diffusion models can support domain-agnostic, label-efficient representation learning for remote sensing and broader scientific imaging tasks.

</details>


### [26] [Multi-Aspect Knowledge-Enhanced Medical Vision-Language Pretraining with Multi-Agent Data Generation](https://arxiv.org/abs/2512.03445)
*Xieji Li,Siyuan Yan,Yingsheng Liu,H. Peter Soyer,Monika Janda,Victoria Mar,Zongyuan Ge*

Main category: cs.CV

TL;DR: 本文提出了一种新的视觉-语言预训练（VLP）方法，融合多智能体数据生成系统和本体驱动的知识增强预训练流程，在皮肤病领域实现了SOTA的无监督分类与跨模态检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有的VLP方法主要依赖于海量图文对自主学习，但常常面临如网络数据噪声大和医学文本冗长无结构等现实难题，影响模型的泛化性和表现。

Method: 作者提出一个包含两个核心创新的VLP框架：一是MAGEN系统，利用大模型自动生成知识丰富的医学描述，并结合检索校验提升数据质量；二是O-MAKE预训练机制，将冗长医学文本细分为多种知识维度，通过本体引导实现医学概念的多层面对齐和关系建模，从而增强模型对医学知识的刻画能力。

Result: 在皮肤医学方向，所提方法在8个数据集的疾病分类和跨模态检索等任务上均达到了当前最优的zero-shot表现；相关增强数据集（Derm1M-AgentAug）包含了40万多对皮肤医学图文数据。

Conclusion: 通过系统性提升训练数据质量和多维度知识对齐，该方案极大提升了医学图文预训练的泛化性能和可解释性，有望为自动化医疗分析和辅助决策等应用打下基础。

Abstract: Vision-language pretraining (VLP) has emerged as a powerful paradigm in medical image analysis, enabling representation learning from large-scale image-text pairs without relying on expensive manual annotations. However, existing methods often struggle with the noise inherent in web-collected data and the complexity of unstructured long medical texts. To address these challenges, we propose a novel VLP framework integrating a Multi-Agent data GENeration (MAGEN) system and Ontology-based Multi-Aspect Knowledge-Enhanced (O-MAKE) pretraining. First, MAGEN enhances data quality by synthesizing knowledge-enriched descriptions via a foundation model-assisted captioning and retrieval-based verification pipeline. Second, O-MAKE addresses the difficulty of learning from long, unstructured texts by decomposing them into distinct knowledge aspects. This facilitates fine-grained alignment at both global and patch levels, while explicitly modeling medical concept relationships through ontology-guided mechanisms. We validate our framework in the field of dermatology, where comprehensive experiments demonstrate the effectiveness of each component. Our approach achieves state-of-the-art zero-shot performance on disease classification and cross-modal retrieval tasks across eight datasets. Our code and the augmented dataset Derm1M-AgentAug, comprising over 400k skin-image-text pairs, will be released at https://github.com/SiyuanYan1/Derm1M.

</details>


### [27] [LM-CartSeg: Automated Segmentation of Lateral and Medial Cartilage and Subchondral Bone for Radiomics Analysis](https://arxiv.org/abs/2512.03449)
*Tongxu Zhang*

Main category: cs.CV

TL;DR: 本文提出了LM-CartSeg，一种全自动的膝关节软骨/骨分割与几何分区及影像组学分析流程，实现了更稳健、可量化的ROI并提供了质控，促进多中心膝骨关节炎影像组学研究。


<details>
  <summary>Details</summary>
Motivation: 目前膝关节MRI影像组学普遍依赖人工ROI，缺乏自动、多区分割方法，且较少关注质量控制，这影响了数据的可重复性及分析的可靠性。因此，需要一种全自动、高质量、具备解剖意义的分割与分区方法。

Method: 作者训练两套3D nnU-Net模型，并在多数据集上进行分割，随后采用基于主成分分析和k均值的自动几何分区方法及一系列后处理（连通域清理、骨带构建等）；通过体积和厚度等特征实现质控，从十个ROI中提取大量影像组学特征以评估其鉴别OＡ与非OＡ的能力。

Result: 后处理显著提升分割精度（OAIZIB-CM宏观ASSD从2.63降至0.36 mm, DSC提升至0.91），分区规则在不同数据集上表现稳定，且仅少部分特征与体积厚度强相关，获得了更有判别性的影像组学特征。

Conclusion: LM-CartSeg流程可自动、高质量地产生具判别力的ROI和影像组学特征，为多中心膝OA研究提供了实用的数据基础，优于传统手工方法并改善了质控流程。

Abstract: Background and Objective: Radiomics of knee MRI requires robust, anatomically meaningful regions of interest (ROIs) that jointly capture cartilage and subchondral bone. Most existing work relies on manual ROIs and rarely reports quality control (QC). We present LM-CartSeg, a fully automatic pipeline for cartilage/bone segmentation, geometric lateral/medial (L/M) compartmentalisation and radiomics analysis. Methods: Two 3D nnU-Net models were trained on SKM-TEA (138 knees) and OAIZIB-CM (404 knees). At test time, zero-shot predictions were fused and refined by simple geometric rules: connected-component cleaning, construction of 10 mm subchondral bone bands in physical space, and a data-driven tibial L/M split based on PCA and k-means. Segmentation was evaluated on an OAIZIB-CM test set (103 knees) and on SKI-10 (100 knees). QC used volume and thickness signatures. From 10 ROIs we extracted 4 650 non-shape radiomic features to study inter-compartment similarity, dependence on ROI size, and OA vs. non-OA classification on OAIZIB-CM Results: Post-processing improved macro ASSD on OAIZIB-CM from 2.63 to 0.36 mm and HD95 from 25.2 to 3.35 mm, with DSC 0.91; zero-shot DSC on SKI-10 was 0.80. The geometric L/M rule produced stable compartments across datasets, whereas a direct L/M nnU-Net showed domain-dependent side swaps. Only 6 to 12 percent of features per ROI were strongly correlated with volume or thickness. Radiomics-based models models restricted to size-linked features. Conclusions: LM-CartSeg yields automatic, QCd ROIs and radiomic features that carry discriminative information beyond simple morphometry, providing a practical foundation for multi-centre knee OA radiomics studies.

</details>


### [28] [KeyPointDiffuser: Unsupervised 3D Keypoint Learning via Latent Diffusion Models](https://arxiv.org/abs/2512.03450)
*Rhys Newbury,Juyan Zhang,Tin Tran,Hanna Kurniawati,Dana Kulić*

Main category: cs.CV

TL;DR: 本文提出了一种无监督从点云中学习3D关键点结构的新方法，能更好应用于现代3D生成场景，在关键点可解释性和一致性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有无监督关键点方法难以适用于无需条件生成的3D场景，因此需要一种既能无监督提取空间结构、又能与3D生成模型结合的方法。

Method: 方法包括：从点云中使用无监督学习得到结构化的3D关键点，并将这些关键点作为条件，输入到扩散模型（Elucidated Diffusion Model, EDM）以重建完整形状。

Result: 学到的关键点能在类别内部具有高重复性，并支持关键点空间平滑插值。实验显示，对比已有方法，关键点一致性提高6个百分点，适用于多种对象类别。

Conclusion: 提出的方法在无监督条件下有效学习了可解释、结构化的3D关键点表示，兼具生成能力与结构建模能力，在3D生成与重建场景具有更好适应性和性能。

Abstract: Understanding and representing the structure of 3D objects in an unsupervised manner remains a core challenge in computer vision and graphics. Most existing unsupervised keypoint methods are not designed for unconditional generative settings, restricting their use in modern 3D generative pipelines; our formulation explicitly bridges this gap. We present an unsupervised framework for learning spatially structured 3D keypoints from point cloud data. These keypoints serve as a compact and interpretable representation that conditions an Elucidated Diffusion Model (EDM) to reconstruct the full shape. The learned keypoints exhibit repeatable spatial structure across object instances and support smooth interpolation in keypoint space, indicating that they capture geometric variation. Our method achieves strong performance across diverse object categories, yielding a 6 percentage-point improvement in keypoint consistency compared to prior approaches.

</details>


### [29] [GalaxyDiT: Efficient Video Generation with Guidance Alignment and Adaptive Proxy in Diffusion Transformers](https://arxiv.org/abs/2512.03451)
*Zhiye Song,Steve Dai,Ben Keller,Brucek Khailany*

Main category: cs.CV

TL;DR: 本文提出GalaxyDiT方法，通过优化计算重用与指导对齐，有效加速扩散模型（DiT）在视频生成任务中的推理，无需额外训练，可显著提升生成速度，同时保持高视频质量。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散模型和Transformer的高质量视频生成方法需要大量迭代计算，尤其是在使用classifier-free guidance (CFG)时，计算资源消耗加倍。这种高计算开销极大限制了其在实际应用中的推广。

Method: 提出了GalaxyDiT，一种无需额外训练的加速方法，通过秩序相关性分析，自动为不同模型架构和参数规模选择最优计算代理，最大化计算重用效率，实现指导对齐。

Result: 在Wan2.1-1.3B和Wan2.1-14B两个主流大模型上，分别实现了1.87倍和2.37倍的生成加速，视频质量仅有微弱下降（VBench-2.0 benchmark分别下降0.97%和0.72%），且PSNR超越先前SOTA方法5~10 dB。

Conclusion: GalaxyDiT方法显著提升了视频扩散模型的生成效率，同时高度保留生成质量，可有效推动扩散模型在更多下游任务和实际场景中的广泛应用。

Abstract: Diffusion models have revolutionized video generation, becoming essential tools in creative content generation and physical simulation. Transformer-based architectures (DiTs) and classifier-free guidance (CFG) are two cornerstones of this success, enabling strong prompt adherence and realistic video quality. Despite their versatility and superior performance, these models require intensive computation. Each video generation requires dozens of iterative steps, and CFG doubles the required compute. This inefficiency hinders broader adoption in downstream applications.
  We introduce GalaxyDiT, a training-free method to accelerate video generation with guidance alignment and systematic proxy selection for reuse metrics. Through rank-order correlation analysis, our technique identifies the optimal proxy for each video model, across model families and parameter scales, thereby ensuring optimal computational reuse. We achieve $1.87\times$ and $2.37\times$ speedup on Wan2.1-1.3B and Wan2.1-14B with only 0.97% and 0.72% drops on the VBench-2.0 benchmark. At high speedup rates, our approach maintains superior fidelity to the base model, exceeding prior state-of-the-art approaches by 5 to 10 dB in peak signal-to-noise ratio (PSNR).

</details>


### [30] [GeoVideo: Introducing Geometric Regularization into Video Generation Model](https://arxiv.org/abs/2512.03453)
*Yunpeng Bai,Shaoheng Fang,Chaohui Yu,Fan Wang,Qixing Huang*

Main category: cs.CV

TL;DR: 该论文提出在视频生成中引入几何正则化，通过逐帧深度预测增强潜空间扩散模型，从而生成结构更一致与物理更合理的视频。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成方法多基于2D像素空间，缺乏对3D结构的建模，导致生成视频中几何结构不连贯、运动不合理、存在结构性伪影。因此，需要新的方法提升视频生成的时空结构一致性与物理合理性。

Method: 该方法在潜在扩散模型基础上，融入逐帧深度预测作为几何表征，并设计多视图几何损失，使各帧深度地图在统一3D坐标系下对齐，促进跨帧结构一致。

Result: 在多个数据集的实验显示，该方法在时空一致性、形状连贯性和物理合理性方面大大优于现有基线方法，生成效果更稳定。

Conclusion: 通过结合深度预测与几何对齐损失，论文方法有效弥合了外观生成与3D结构建模间的鸿沟，实现了结构与物理上更连贯的视频生成，可为视频内容创作等应用提供有力支撑。

Abstract: Recent advances in video generation have enabled the synthesis of high-quality and visually realistic clips using diffusion transformer models. However, most existing approaches operate purely in the 2D pixel space and lack explicit mechanisms for modeling 3D structures, often resulting in temporally inconsistent geometries, implausible motions, and structural artifacts. In this work, we introduce geometric regularization losses into video generation by augmenting latent diffusion models with per-frame depth prediction. We adopted depth as the geometric representation because of the great progress in depth prediction and its compatibility with image-based latent encoders. Specifically, to enforce structural consistency over time, we propose a multi-view geometric loss that aligns the predicted depth maps across frames within a shared 3D coordinate system. Our method bridges the gap between appearance generation and 3D structure modeling, leading to improved spatio-temporal coherence, shape consistency, and physical plausibility. Experiments across multiple datasets show that our approach produces significantly more stable and geometrically consistent results than existing baselines.

</details>


### [31] [Think Before You Drive: World Model-Inspired Multimodal Grounding for Autonomous Vehicles](https://arxiv.org/abs/2512.03454)
*Haicheng Liao,Huanming Shen,Bonan Wang,Yongkang Li,Yihong Tang,Chengyue Wang,Dingyi Zhuang,Kehua Chen,Hai Yang,Chengzhong Xu,Zhenning Li*

Main category: cs.CV

TL;DR: 本文提出了ThinkDeeper框架，通过推理未来空间状态改进自动驾驶中的自然语言物体定位，并利用新数据集DrivePilot和多项基准测试达到最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉定位方法在面对复杂、含糊或依赖上下文的自然语言指令时表现不佳，特别是在缺乏3D空间关系推理和对场景演化预测的情况下。因此，需要新的方法来增强自动驾驶系统处理自然语言定位任务的能力。

Method: 作者提出ThinkDeeper框架，核心为空间感知世界模型（SA-WM），通过将当前场景与指令编码为潜在状态，并进行未来状态推理，以获得有助于消歧的前瞻信息。然后用超图引导的解码器将这些状态与多模态输入层次化融合，捕获更复杂的空间依赖关系。此外，提出了DrivePilot多源视觉定位数据集，结合检索增强生成与思维链提示的大模型自动生成丰富语义标注。

Result: 在六大基准评测中，ThinkDeeper在Talk2Car排行榜名列第一，并在DrivePilot、MoCAD以及RefCOCO系列基准上超过最新方法。在长文本、多智能体、含糊等复杂场景下表现出强鲁棒性和高效率，即使只用一半训练数据也能保持领先表现。

Conclusion: ThinkDeeper框架能够有效提升自动驾驶领域自然语言命令下的物体定位精度和鲁棒性，尤其擅长处理复杂、多样且含糊的场景，展示了前瞻空间推理机制的巨大潜力。

Abstract: Interpreting natural-language commands to localize target objects is critical for autonomous driving (AD). Existing visual grounding (VG) methods for autonomous vehicles (AVs) typically struggle with ambiguous, context-dependent instructions, as they lack reasoning over 3D spatial relations and anticipated scene evolution. Grounded in the principles of world models, we propose ThinkDeeper, a framework that reasons about future spatial states before making grounding decisions. At its core is a Spatial-Aware World Model (SA-WM) that learns to reason ahead by distilling the current scene into a command-aware latent state and rolling out a sequence of future latent states, providing forward-looking cues for disambiguation. Complementing this, a hypergraph-guided decoder then hierarchically fuses these states with the multimodal input, capturing higher-order spatial dependencies for robust localization. In addition, we present DrivePilot, a multi-source VG dataset in AD, featuring semantic annotations generated by a Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT)-prompted LLM pipeline. Extensive evaluations on six benchmarks, ThinkDeeper ranks #1 on the Talk2Car leaderboard and surpasses state-of-the-art baselines on DrivePilot, MoCAD, and RefCOCO/+/g benchmarks. Notably, it shows strong robustness and efficiency in challenging scenes (long-text, multi-agent, ambiguity) and retains superior performance even when trained on 50% of the data.

</details>


### [32] [Text-Printed Image: Bridging the Image-Text Modality Gap for Text-centric Training of Large Vision-Language Models](https://arxiv.org/abs/2512.03463)
*Shojiro Yamabe,Futa Waseda,Daiki Shiono,Tsubasa Takahashi*

Main category: cs.CV

TL;DR: 该论文提出了一种全新、低成本的数据扩展策略：通过直接将文本描述渲染为简单的图像（TPI），支持大型视觉语言模型（LVLMs）在视觉问答（VQA）等任务中的训练，无需收集真实图像。实验显示，这种方法优于使用扩散模型生成的合成图像。


<details>
  <summary>Details</summary>
Motivation: 传统LVLMs的高性能依赖于大量的图文对数据，但真实图像收集成本高、受限多，尤其在隐私及小众领域，阻碍了模型的广泛应用和扩展。与此同时，文本资源丰富且可扩展。本文希望借助纯文本作为替代，降低数据准备门槛，实现规模化训练。

Method: 作者提出了Text-Printed Image (TPI)方法：把每条描述文本直接“印”在空白画布上生成图片，用以替代或补充图像数据，然后将这些合成图片加入LVLM的训练流程。由于TPI完全保留了文本语义并映射到图像模态，缓解了纯文本存在的模态鸿沟。并与扩散模型生成的合成图片等策略进行了系统对比。

Result: 在四种主流模型和七个VQA基准测试上，TPI不仅明显优于扩散模型生成图片的方式，还能够作为一种实用的低成本数据增强策略提升现有模型表现。实验验证了TPI文本中心训练的有效性与实用性。

Conclusion: TPI为LVLM训练提供了一种高效、低成本、可扩展的自动化数据生成新路径，从侧面也展示了文本中心训练的巨大潜力，对视觉语言模型领域具有实际应用和研究价值。

Abstract: Recent large vision-language models (LVLMs) have been applied to diverse VQA tasks. However, achieving practical performance typically requires task-specific fine-tuning with large numbers of image-text pairs, which are costly to collect. In this work, we study text-centric training, a setting where only textual descriptions are available and no real images are provided, as a paradigm for low-cost data scaling. Unlike images, whose collection is often restricted by privacy constraints and scarcity in niche domains, text is widely available. Moreover, text is easily editable, enabling automatic diversification and expansion with LLMs at minimal human effort. While this offers clear advantages over image collection in terms of scalability and cost, training on raw text without images still yields limited gains on VQA tasks because of the image-text modality gap. To address this issue, we propose a Text-Printed Image (TPI), which generates synthetic images by directly rendering the given textual description on a plain white canvas. This simple rendering projects text into the image modality and can be integrated into arbitrary existing LVLM training pipelines at low cost. Moreover, TPI preserves the semantics of the text, whereas text-to-image models often fail to do. Across four models and seven benchmarks, our systematic experiments show that TPI enables more effective text-centric training than synthetic images generated by a diffusion model. We further explore TPI as a low-cost data-augmentation strategy and demonstrate its practical utility. Overall, our findings highlight the significant potential of text-centric training and, more broadly, chart a path toward fully automated data generation for LVLMs.

</details>


### [33] [Difference Decomposition Networks for Infrared Small Target Detection](https://arxiv.org/abs/2512.03470)
*Chen Hu,Mingyu Zhou,Shuai Yuan,Hongbo Hu,Xiangyu Qiu,Junhai Luo,Tian Pu,Xiyin Li*

Main category: cs.CV

TL;DR: 本文提出了一种新型的红外小目标检测方法，通过基于基分解的轻量模块，有效提升目标检测准确率并抑制背景干扰。


<details>
  <summary>Details</summary>
Motivation: 红外小目标检测常遇到目标纹理不明显及背景杂波严重的问题，背景信号容易掩盖小目标，因此需要更优的目标增强和背景抑制方法。

Method: 作者提出基分解模块（BDM），将复杂特征分解为多个基础特征，提取有用信息并去除冗余，由此扩展出空间、时空等一系列模块。基于这些模块，设计了空间差分分解网络（SD²Net）用于单帧检测和时空差分分解网络（STD²Net）用于多帧检测。

Result: 在多个红外小目标检测数据集上，所提方法表现优异。其中SD²Net在单帧任务上优于大多数已有方法，STD²Net在多帧任务中mIoU为87.68%，显著超越SD²Net的64.97%。

Conclusion: 该文提出的分解方法具备高效、可扩展的优点，在实际红外小目标检测中可达到最新最优的水平，验证了设计的有效性。

Abstract: Infrared small target detection (ISTD) faces two major challenges: a lack of discernible target texture and severe background clutter, which results in the background obscuring the target. To enhance targets and suppress backgrounds, we propose the Basis Decomposition Module (BDM) as an extensible and lightweight module based on basis decomposition, which decomposes a complex feature into several basis features and enhances certain information while eliminating redundancy. Extending BDM leads to a series of modules, including the Spatial Difference Decomposition Module (SD$^\mathrm{2}$M), Spatial Difference Decomposition Downsampling Module (SD$^\mathrm{3}$M), and Temporal Difference Decomposition Module (TD$^\mathrm{2}$M). Based on these modules, we develop the Spatial Difference Decomposition Network (SD$^\mathrm{2}$Net) for single-frame ISTD (SISTD) and the Spatiotemporal Difference Decomposition Network (STD$^\mathrm{2}$Net) for multi-frame ISTD (MISTD). SD$^\mathrm{2}$Net integrates SD$^\mathrm{2}$M and SD$^\mathrm{3}$M within an adapted U-shaped architecture. We employ TD$^\mathrm{2}$M to introduce motion information, which transforms SD$^\mathrm{2}$Net into STD$^\mathrm{2}$Net. Extensive experiments on SISTD and MISTD datasets demonstrate state-of-the-art (SOTA) performance. On the SISTD task, SD$^\mathrm{2}$Net performs well compared to most established networks. On the MISTD datasets, STD$^\mathrm{2}$Net achieves a mIoU of 87.68\%, outperforming SD$^\mathrm{2}$Net, which achieves a mIoU of 64.97\%. Our codes are available: https://github.com/greekinRoma/IRSTD_HC_Platform.

</details>


### [34] [Procedural Mistake Detection via Action Effect Modeling](https://arxiv.org/abs/2512.03474)
*Wenliang Guo,Yujiang Pu,Yu Kong*

Main category: cs.CV

TL;DR: 该论文提出了一种新的错误检测框架Action Effect Modeling（AEM），同时建模动作的执行和其结果，并在主流数据集上实现了最优表现。


<details>
  <summary>Details</summary>
Motivation: 现有的方法主要关注动作执行本身，很少关注动作产生的结果（action effect），但实际中许多错误体现在效果上而非过程。因此需要能同时考虑执行与结果的方法。

Method: AEM框架通过概率建模，将动作的执行与产出的结果结合起来。首先选取最有信息量的动作结果帧，然后利用视觉与符号特征进行对齐，形成鲁棒的语义表示。最后设计了基于提示（prompt）的检测器，实现误差检测。

Result: AEM在EgoPER和CaptainCook4D两个数据集上的一类分类（one-class classification，OCC）任务中取得了最优性能。效果说明结合动作执行和结果建模能带来更准确的错误检测。

Conclusion: 通过对动作执行和其结果的联合建模，可以更可靠地检测程序性任务中的错误。该方法的效果感知表示对下游应用也有很大潜力。

Abstract: Mistake detection in procedural tasks is essential for building intelligent systems that support learning and task execution. Existing approaches primarily analyze how an action is performed, while overlooking what it produces, i.e., the \textbf{action effect}. Yet many errors manifest not in the execution itself but in the resulting outcome, such as an unintended object state or incorrect spatial arrangement. To address this gap, we propose Action Effect Modeling (AEM), a unified framework that jointly captures action execution and its outcomes through a probabilistic formulation. AEM first identifies the outcome of an action by selecting the most informative effect frame based on semantic relevance and visual quality. It then extracts complementary cues from visual grounding and symbolic scene graphs, aligning them in a shared latent space to form robust effect-aware representations. To detect mistakes, we further design a prompt-based detector that incorporates task-specific prompts and aligns each action segment with its intended execution semantics. Our approach achieves state-of-the-art performance on the EgoPER and CaptainCook4D benchmarks under the challenging one-class classification (OCC) setting. These results demonstrate that modeling both execution and outcome yields more reliable mistake detection, and highlight the potential of effect-aware representations to benefit a broader range of downstream applications.

</details>


### [35] [Fairness-Aware Fine-Tuning of Vision-Language Models for Medical Glaucoma Diagnosis](https://arxiv.org/abs/2512.03477)
*Zijian Gu,Yuxi Liu,Zhenhao Zhang,Song Wang*

Main category: cs.CV

TL;DR: 本文提出了一种针对医学视觉-语言模型(VLM)的公平性增强方法，有效降低了不同群体间的诊断准确率差异，并且算法高效、实用。


<details>
  <summary>Details</summary>
Motivation: 医学VLM模型在诊断任务上的总体表现优异，但在不同人口群体(如种族、性别)之间诊断准确率存在较大差异，带来潜在的不公平和伦理风险。为推动AI公平诊断，亟需开发既有效又参数高效的优化方法。

Method: 作者提出了公平性感知的低秩适应方法(Fairness-aware Low-Rank Adaptation, LoRA)，核心为可微分的MaxAccGap损失，直接优化不同群体间的准确率接近。具体方法包括：1) FR-LoRA，在训练目标中加入MaxAccGap正则项；2) GR-LoRA，利用逆频率加权平衡梯度贡献；3) Hybrid-LoRA，结合两者。

Result: 在1万张青光眼眼底图像数据上，GR-LoRA方法将群体间准确率差距减少了69%，总体准确率为53.15%。消融实验表明，强正则化实现了最佳公平性且准确率损失最小，专门针对种族优化可将差异降至60%。该方法参数极少(仅0.24%可训练参数)，易于实际部署。

Conclusion: 本文方法兼顾诊断准确率和公平性，参数效率高，非常适合在资源有限的医疗场景中应用，为医学AI公平部署提供了新思路。

Abstract: Vision-language models achieve expert-level performance on medical imaging tasks but exhibit significant diagnostic accuracy disparities across demographic groups. We introduce fairness-aware Low-Rank Adaptation for medical VLMs, combining parameter efficiency with explicit fairness optimization. Our key algorithmic contribution is a differentiable MaxAccGap loss that enables end-to-end optimization of accuracy parity across demographic groups. We propose three methods: FR-LoRA integrates MaxAccGap regularization into the training objective, GR-LoRA applies inverse frequency weighting to balance gradient contributions, and Hybrid-LoRA combines both mechanisms.Evaluated on 10,000 glaucoma fundus images, GR-LoRA reduces diagnostic accuracy disparities by 69% while maintaining 53.15% overall accuracy. Ablation studies reveal that strong regularization strength achieves optimal fairness with minimal accuracy trade-off, and race-specific optimization yields 60% disparity reduction. Our approach requires only 0.24% trainable parameters, enabling practical deployment of fair medical AI in resource-constrained healthcare settings.

</details>


### [36] [Towards Object-centric Understanding for Instructional Videos](https://arxiv.org/abs/2512.03479)
*Wenliang Guo,Yu Kong*

Main category: cs.CV

TL;DR: 本文提出了一种以物体为核心的程序活动理解方法，并建立了名为Object-IVQA的新数据集，对现有视觉-语言模型的推理能力进行了评估，提出的新方法效果更好。


<details>
  <summary>Details</summary>
Motivation: 现有以动作为中心的方法难以应对现实程序的灵活性，特别是步骤的顺序常因物体状态变化而不同。研究亟需探索新的范式以提升助理AI对复杂任务的理解与推理能力。

Method: 作者提出将注意力从动作转向物体，将动作视为物体状态转换的机制。为此，构建了Object-IVQA数据集，包含107个长视频和514个基于物体变化的问答对，覆盖状态演变、前提验证、反事实推理和错误识别等四类推理。作者还设计了一个基于物体的智能体框架，集成规划、感知、分析和生成能力，实现多步推理和证据检索。

Result: 实验表明，现有大规模视觉-语言模型在物体识别及多步推理方面表现欠佳，而作者提出的方法在物体层面推理任务中取得了明显提升。

Conclusion: 将活动理解范式转为物体中心，有助于助理AI对复杂程序活动更好地推理和理解。所提方法和数据集为未来助理AI的发展提供了新的思路和基准。

Abstract: Understanding procedural activities is crucial for developing future assistive AI that can reason about complex real-world tasks. Existing action-centric methods struggle with the flexibility of real procedures, where step order varies depending on object states. In this work, we propose to shift the focus to an object-centric paradigm by regarding actions as mechanisms that drive state transitions. To advance this direction, we introduce Object-IVQA, a long-form instructional video benchmark with 107 videos and 514 open-ended question-answer pairs annotated with temporally grounded evidence. The benchmark evaluates four dimensions of object-centric reasoning, including state evolution, precondition verification, counterfactual reasoning and mistake recognition. We further propose an agent framework that orchestrates object-centric planning, perception, analysis and generation tools, enabling explicit evidence retrieval and multi-hop reasoning across disjoint segments. Experiments show that existing large vision-language models struggle in object-level recognition and reasoning, whereas our framework achieves substantially improvement.

</details>


### [37] [NAS-LoRA: Empowering Parameter-Efficient Fine-Tuning for Visual Foundation Models with Searchable Adaptation](https://arxiv.org/abs/2512.03499)
*Renqi Chen,Haoyang Su,Shixiang Tang*

Main category: cs.CV

TL;DR: 针对SAM模型在医学和农业等专业领域的适应性难题，本文提出NAS-LoRA方法，通过轻量级神经结构搜索以及分阶段优化策略，提升了模型对空间先验的整合与高层语义信息的学习能力，在降低24.14%训练成本的同时不增加推理开销。


<details>
  <summary>Details</summary>
Motivation: 尽管SAM具备强大的图像分割能力，但面对特定下游任务时适应性有限，且其Transformer结构缺乏空间先验影响语义特征表达，急需引入新的方法以提升领域适应性和高层语义理解。

Method: 提出NAS-LoRA，一种高效参数微调方法，在LoRA的编码器和解码器之间引入轻量级的神经结构搜索模块，并采用分阶段优化策略，使ViT编码器在权重更新与结构调整之间获得平衡。

Result: 实验结果表明，NAS-LoRA不仅优于现有高效参数微调方法，还能将训练成本降低24.14%，且不增加推理阶段的计算开销。

Conclusion: NAS-LoRA显示了神经结构搜索在视觉基础模型高效微调中的潜力，为模型在专业领域的适应性和高效性带来新的思路。

Abstract: The Segment Anything Model (SAM) has emerged as a powerful visual foundation model for image segmentation. However, adapting SAM to specific downstream tasks, such as medical and agricultural imaging, remains a significant challenge. To address this, Low-Rank Adaptation (LoRA) and its variants have been widely employed to enhancing SAM's adaptation performance on diverse domains. Despite advancements, a critical question arises: can we integrate inductive bias into the model? This is particularly relevant since the Transformer encoder in SAM inherently lacks spatial priors within image patches, potentially hindering the acquisition of high-level semantic information. In this paper, we propose NAS-LoRA, a new Parameter-Efficient Fine-Tuning (PEFT) method designed to bridge the semantic gap between pre-trained SAM and specialized domains. Specifically, NAS-LoRA incorporates a lightweight Neural Architecture Search (NAS) block between the encoder and decoder components of LoRA to dynamically optimize the prior knowledge integrated into weight updates. Furthermore, we propose a stage-wise optimization strategy to help the ViT encoder balance weight updates and architectural adjustments, facilitating the gradual learning of high-level semantic information. Various Experiments demonstrate our NAS-LoRA improves existing PEFT methods, while reducing training cost by 24.14% without increasing inference cost, highlighting the potential of NAS in enhancing PEFT for visual foundation models.

</details>


### [38] [CartoMapQA: A Fundamental Benchmark Dataset Evaluating Vision-Language Models on Cartographic Map Understanding](https://arxiv.org/abs/2512.03558)
*Huy Quang Ung,Guillaume Habault,Yasutaka Nishimura,Hao Niu,Roberto Legaspi,Tomoki Oya,Ryoichi Kojima,Masato Taya,Chihiro Ono,Atsunori Minamikawa,Yan Liu*

Main category: cs.CV

TL;DR: 论文提出了CartoMapQA基准，用于评估视觉-语言模型对地图的理解能力。结果显示，现有模型在地图语义、地理空间推理和OCR等方面表现不佳，可为模型改进提供方向。


<details>
  <summary>Details</summary>
Motivation: 随着视觉-语言模型（LVLMs）的发展，模型在视觉与文本融合应用中表现突出，但其对地图这一特殊多模态信息载体的理解能力缺乏系统研究。由于地图理解在导航、地理搜索等真实应用中至关重要，评估和改进模型在该领域的能力尤为重要。

Method: 作者构建了CartoMapQA基准，包括2000多组地图问答样本（涵盖符号识别、信息提取、比例尺理解和路径推理等不同层级技能），并对多个开源与闭源LVLM进行横评，系统分析模型在不同类型地图理解任务中的表现和难点。

Result: 评测结果显示，无论开源还是闭源LVLM在面对地图识别、地理空间推理与OCR相关任务时均表现不佳，经常出现理解偏差和识别失误。

Conclusion: CartoMapQA揭示了现有LVLM在地图理解上的局限性，为后续模型优化和真实应用提供了参考。该基准和数据集已开源，为学界进一步推动相关方向研究提供了有力工具。

Abstract: The rise of Visual-Language Models (LVLMs) has unlocked new possibilities for seamlessly integrating visual and textual information. However, their ability to interpret cartographic maps remains largely unexplored. In this paper, we introduce CartoMapQA, a benchmark specifically designed to evaluate LVLMs' understanding of cartographic maps through question-answering tasks. The dataset includes over 2000 samples, each composed of a cartographic map, a question (with open-ended or multiple-choice answers), and a ground-truth answer. These tasks span key low-, mid- and high-level map interpretation skills, including symbol recognition, embedded information extraction, scale interpretation, and route-based reasoning. Our evaluation of both open-source and proprietary LVLMs reveals persistent challenges: models frequently struggle with map-specific semantics, exhibit limited geospatial reasoning, and are prone to Optical Character Recognition (OCR)-related errors. By isolating these weaknesses, CartoMapQA offers a valuable tool for guiding future improvements in LVLM architectures. Ultimately, it supports the development of models better equipped for real-world applications that depend on robust and reliable map understanding, such as navigation, geographic search, and urban planning. Our source code and data are openly available to the research community at: https://github.com/ungquanghuy-kddi/CartoMapQA.git

</details>


### [39] [EEA: Exploration-Exploitation Agent for Long Video Understanding](https://arxiv.org/abs/2512.03500)
*Te Yang,Xiangyu Zhu,Bo Wang,Quan Chen,Peng Jiang,Zhen Lei*

Main category: cs.CV

TL;DR: 提出了一种用于长视频理解的新型视频智能体框架EEA，利用语义引导和层次化树搜索，在探索与利用之间取得了高效平衡，显著提升了理解效果和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有长视频理解方法存在两大难题：一是密集处理导致计算资源消耗极高，二是简单抽帧等策略又不能完整覆盖视频关键信息，探索与利用的平衡难以实现。因此，亟需一种高效且能充分理解视频关键信息的方法。

Method: 作者提出了EEA框架，通过动态发现和更新与任务相关的语义查询，收集与查询高度匹配的视频帧作为锚点。树搜索过程中，不是均匀扩展，而是优先探索语义相关帧，并在信息未知段落保证覆盖率。同时，EEA显式建模不确定性，将VLM的内在奖励与语义先验自适应结合，实现了稳定、精确的视频片段评估。

Result: 在多个长视频基准测试上，EEA展现出优于现有方法的表现，兼具出色的理解效果和更高的计算效率。

Conclusion: EEA实现了对长视频高效、完整的理解，在探索与利用之间找到了良好平衡，为长视频分析与下游任务提供了更加实用的解决方案。

Abstract: Long-form video understanding requires efficient navigation of extensive visual data to pinpoint sparse yet critical information. Current approaches to longform video understanding either suffer from severe computational overhead due to dense preprocessing, or fail to effectively balance exploration and exploitation, resulting in incomplete information coverage and inefficiency. In this work, we introduce EEA, a novel video agent framework that archives exploration-exploitation balance through semantic guidance with hierarchical tree search process. EEA autonomously discovers and dynamically updates task-relevant semantic queries, and collects video frames closely matched to these queries as semantic anchors. During the tree search process, instead of uniform expansion, EEA preferentially explores semantically relevant frames while ensuring sufficient coverage within unknown segments. Moreover, EEA adaptively combines intrinsic rewards from visionlanguage models (VLMs) with semantic priors by explicitly modeling uncertainty to achieve stable and precise evaluation of video segments. Experiments across various long-video benchmarks validate the superior performance and computational efficiency of our proposed method.

</details>


### [40] [CSMapping: Scalable Crowdsourced Semantic Mapping and Topology Inference for Autonomous Driving](https://arxiv.org/abs/2512.03510)
*Zhijian Qiao,Zehuan Yu,Tong Li,Chih-Chung Chou,Wenchao Ding,Shaojie Shen*

Main category: cs.CV

TL;DR: CSMapping系统结合生成式扩散模型和鲁棒优化，实现了基于众包数据的高质量语义地图与拓扑中线自动构建，显著提升噪声容忍性与数据规模扩展性，并在多个主流数据集取得领先效果。


<details>
  <summary>Details</summary>
Motivation: 众包数据可高效支持自动驾驶地图构建，但低成本传感器噪声导致单纯数据堆集无法提升地图精度。当前缺乏在高噪声、无配对高精地图标注下提升语义与拓扑质量的有效方法。

Method: 提出CSMapping系统：1）语义地图用条件潜变量扩散模型拟合高精地图结构先验，通过受约束最大后验优化完成去噪和补全，过程有向量化初始、扩散反演、基于高斯基底重参数高效梯度下降，并用潜空间因子图保持一致性；2）拓扑中心线用置信加权的k-medoids聚类加动力学精化，从众包轨迹中拟合平滑且类似人工标注的中线。

Result: CSMapping在nuScenes、Argoverse 2和大规模专有数据集均实现了领先的语义和拓扑映射指标，相关消融与扩展性实验验证了方法的有效性、强鲁棒性及随样本增长持续提升能力。

Conclusion: CSMapping兼顾众包可扩展性与高质量地图精度，为大规模自动驾驶地图自动构建提供了有效技术路径，显著缓解了低成本感知噪声带来的瓶颈。

Abstract: Crowdsourcing enables scalable autonomous driving map construction, but low-cost sensor noise hinders quality from improving with data volume. We propose CSMapping, a system that produces accurate semantic maps and topological road centerlines whose quality consistently increases with more crowdsourced data. For semantic mapping, we train a latent diffusion model on HD maps (optionally conditioned on SD maps) to learn a generative prior of real-world map structure, without requiring paired crowdsourced/HD-map supervision. This prior is incorporated via constrained MAP optimization in latent space, ensuring robustness to severe noise and plausible completion in unobserved areas. Initialization uses a robust vectorized mapping module followed by diffusion inversion; optimization employs efficient Gaussian-basis reparameterization, projected gradient descent zobracket multi-start, and latent-space factor-graph for global consistency. For topological mapping, we apply confidence-weighted k-medoids clustering and kinematic refinement to trajectories, yielding smooth, human-like centerlines robust to trajectory variation. Experiments on nuScenes, Argoverse 2, and a large proprietary dataset achieve state-of-the-art semantic and topological mapping performance, with thorough ablation and scalability studies.

</details>


### [41] [Optical Context Compression Is Just (Bad) Autoencoding](https://arxiv.org/abs/2512.03643)
*Ivan Yee Lee,Cheng Yang,Taylor Berg-Kirkpatrick*

Main category: cs.CV

TL;DR: 该论文质疑了视觉编码在文本压缩重构和语言建模中的独特优势，发现简单方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 当前研究（如DeepSeek-OCR）显示视觉编码可以高保真重建被压缩的文本，引发了在语言模型中用视觉方式进行上下文压缩的热潮。但该方法是否真正有助于语言建模，之前并未验证。

Method: 作者检验了两点假设：（1）视觉编码在文本重建方面相比其他压缩方式有独特优势；（2）视觉编码的高重建效果也能提升语言建模表现。作者将DeepSeek-OCR的视觉编码与两种简单压缩方案（无参数的均值池化和学习型层次编码器）进行对比，在相同压缩率下，评估重建质量和对语言模型的作用。

Result: 简单的参数池化和层次编码在文本重建上能达到或超过视觉方法，在语言建模任务上则显著更优，而视觉编码甚至不如直接截断文本。

Conclusion: 目前对基于光学的上下文压缩的关注远远超出其已有的实证依据，简单方法可能是更优选择。

Abstract: DeepSeek-OCR demonstrates that rendered text can be reconstructed with high fidelity from a small number of vision tokens. This finding has sparked excitement about vision-based context compression for language models. But the evaluation stops at reconstruction; whether these representations help language modeling remains untested. We test two assumptions implicit in the optical-compression narrative: that vision-based compression provides unique advantages for text reconstruction from compressed representations, and that DeepSeek-OCR's reconstruction results are evidence that vision-based compression will be useful for language modeling. Comparing their vision encoder against simple alternatives--parameter-free mean pooling and a learned hierarchical encoder--we find that these simple approaches match or surpass vision for reconstruction at matched compression ratios, and outperform it for language modeling--where vision-based compression fails to beat truncation. The excitement around optical context compression outpaces the evidence. Code and checkpoints are available at https://github.com/ivnle/bad-autoencoding

</details>


### [42] [Exploiting Domain Properties in Language-Driven Domain Generalization for Semantic Segmentation](https://arxiv.org/abs/2512.03508)
*Seogkyu Jeon,Kibeom Hong,Hyeran Byun*

Main category: cs.CV

TL;DR: 提出了一种新的领域泛化语义分割方法DPMFormer，致力于缓解视觉与文本语义之间的不对齐问题，并在多个基准上取得了最新最优结果。


<details>
  <summary>Details</summary>
Motivation: 以往利用视觉-语言模型进行领域泛化语义分割时，忽略了因固定的上下文prompt带来的视觉与文本语义不对齐问题，导致模型泛化能力受限。

Method: 提出了DPMFormer框架，核心包括：1）领域感知的prompt学习以加强视觉与文本线索的对齐；2）结合纹理扰动的领域感知对比学习以模拟不同领域特性；3）领域鲁棒一致性学习以减少增强前后模型预测间的差异。

Result: 在多个领域泛化语义分割基准测试上，所提方法DPMFormer取得了新的最优表现。

Conclusion: 所提域感知prompt驱动的遮蔽Transformer模型可有效提升语义分割的跨域泛化能力，并缓解了视觉与文本语义间的不对齐问题。

Abstract: Recent domain generalized semantic segmentation (DGSS) studies have achieved notable improvements by distilling semantic knowledge from Vision-Language Models (VLMs). However, they overlook the semantic misalignment between visual and textual contexts, which arises due to the rigidity of a fixed context prompt learned on a single source domain. To this end, we present a novel domain generalization framework for semantic segmentation, namely Domain-aware Prompt-driven Masked Transformer (DPMFormer). Firstly, we introduce domain-aware prompt learning to facilitate semantic alignment between visual and textual cues. To capture various domain-specific properties with a single source dataset, we propose domain-aware contrastive learning along with the texture perturbation that diversifies the observable domains. Lastly, to establish a framework resilient against diverse environmental changes, we have proposed the domain-robust consistency learning which guides the model to minimize discrepancies of prediction from original and the augmented images. Through experiments and analyses, we demonstrate the superiority of the proposed framework, which establishes a new state-of-the-art on various DGSS benchmarks. The code is available at https://github.com/jone1222/DPMFormer.

</details>


### [43] [PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention](https://arxiv.org/abs/2512.03724)
*Ziwen Li,Xin Wang,Hanlue Zhang,Runnan Chen,Runqi Lin,Xiao He,Han Huang,Yandong Guo,Fakhri Karray,Tongliang Liu,Mingming Gong*

Main category: cs.CV

TL;DR: 本文提出了一种用于机器人任务的视觉-语言-动作（VLA）模型新架构PosA-VLA，通过引入基于姿态条件的视觉锚注意力机制，有效提升了目标导向动作的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型虽然在视觉-语言任务中表现优秀，但在复杂环境中常因关注无关物体而生成冗余或不稳定动作，难以适用于对效率和精度要求高的实际场景。

Method: 本文提出PosA-VLA框架，通过姿态条件监督引导视觉注意力，仅关注与任务相关的图像区域。该框架采用新的锚注意力机制，将指令语义与可执行的视觉线索对齐，并设计为轻量级架构，无需额外的感知模块，推理高效。

Result: 在多个机器人操控基准测试中，PosA-VLA能够精确、高效地执行任务，并在复杂环境展现出较强的泛化能力。

Conclusion: PosA-VLA显著提升了VLA模型在机器人任务中的动作精确性与时效性，无需额外感知网络，具备高效、鲁棒和实际部署潜力。

Abstract: The Vision-Language-Action (VLA) models have demonstrated remarkable performance on embodied tasks and shown promising potential for real-world applications. However, current VLAs still struggle to produce consistent and precise target-oriented actions, as they often generate redundant or unstable motions along trajectories, limiting their applicability in time-sensitive scenarios.In this work, we attribute these redundant actions to the spatially uniform perception field of existing VLAs, which causes them to be distracted by target-irrelevant objects, especially in complex environments.To address this issue, we propose an efficient PosA-VLA framework that anchors visual attention via pose-conditioned supervision, consistently guiding the model's perception toward task-relevant regions. The pose-conditioned anchor attention mechanism enables the model to better align instruction semantics with actionable visual cues, thereby improving action generation precision and efficiency. Moreover, our framework adopts a lightweight architecture and requires no auxiliary perception modules (e.g., segmentation or grounding networks), ensuring efficient inference. Extensive experiments verify that our method executes embodied tasks with precise and time-efficient behavior across diverse robotic manipulation benchmarks and shows robust generalization in a variety of challenging environments.

</details>


### [44] [Thinking with Programming Vision: Towards a Unified View for Thinking with Images](https://arxiv.org/abs/2512.03746)
*Zirun Guo,Minjie Hong,Feng Zhang,Kai Jia,Tao Jin*

Main category: cs.CV

TL;DR: 本文提出了CodeVision，一个代码即工具的多模态大模型框架，通过让模型生成代码动态调用任意图像操作工具，提升了工具推理的灵活性与稳健性。实验验证了方法在鲁棒性和工具推理能力上的显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型依赖有限且固定的工具集合，缺乏对真实世界多样化需求的扩展性和鲁棒性，且在简单图像旋转或轻度损坏时性能大幅下降，暴露出脆弱性。作者希望解决这一关键问题。

Method: 提出CodeVision框架，将代码作为通用接口，允许模型编写代码以调用任意图像操作工具。训练采用两阶段：先通过高质量复杂工具组合与错误恢复的数据集进行有监督微调，再通过新颖的稠密过程奖励下的强化学习优化策略性和高效工具使用。并自建了面向鲁棒性和复杂推理的新数据集与评测基准。

Result: 在Qwen2.5-VL与Qwen3-VL系列模型上，CodeVision显著提升了模型在图像方向变化与多工具推理等挑战任务上的表现，展现了灵活工具组合、高效链式推理及稳健的错误恢复等新能力。

Conclusion: CodeVision证明了将代码生成作为工具调用接口对多模态模型推理和鲁棒性提升的有效性，为大模型扩展现实世界复杂任务能力提供了新思路。作者也开源了代码以支持后续研究。

Abstract: Multimodal large language models (MLLMs) that think with images can interactively use tools to reason about visual inputs, but current approaches often rely on a narrow set of tools with limited real-world necessity and scalability. In this work, we first reveal a critical and previously overlooked weakness: even state-of-the-art MLLMs are surprisingly brittle, showing significant performance degradation on images with simple orientation changes or natural corruptions, underscoring the need for more robust tool-based reasoning. To address this, we propose CodeVision, a flexible and scalable code-as-tool framework where the model generates code as a universal interface to invoke any image operation, moving beyond fixed tool registries. We train our model using a two-stage methodology, beginning with Supervised Fine-Tuning (SFT) on a high-quality dataset curated for complex, multi-turn tool composition and error recovery, followed by Reinforcement Learning (RL) with a novel and dense process reward function to encourage strategic and efficient tool use. To facilitate this research, we construct new SFT and RL datasets and introduce a challenging new benchmark suite designed to rigorously evaluate robustness to orientation changes and multi-tool reasoning. Experiments on Qwen2.5-VL and Qwen3-VL series show that our approach significantly improves model performance and fosters emergent capabilities such as flexible tool composition, efficient chained execution, and robust error recovery from runtime feedback. Code is available at https://github.com/ByteDance-BandAI/CodeVision.

</details>


### [45] [AfroBeats Dance Movement Analysis Using Computer Vision: A Proof-of-Concept Framework Combining YOLO and Segment Anything Model](https://arxiv.org/abs/2512.03509)
*Kwaku Opoku-Ware,Gideon Opoku*

Main category: cs.CV

TL;DR: 本文提出了一种将YOLOv8/v11与Segment Anything Model（SAM）结合的自动舞蹈动作分析方法，实现舞者检测与精确分割，在无专用设备下自动量化记录舞蹈视频中的舞蹈动作及节奏。初步实验显示检测准确率高，运动量化优于传统方法，但仅在单个视频上测试，存在明显局限性。


<details>
  <summary>Details</summary>
Motivation: 当前舞蹈动作分析多依赖于带标记的设备或复杂的系统，难以推广且研究手段有限。作者希望通过最新的计算机视觉技术，实现一种无需额外设备即可自动分析与评估舞蹈表演的方法，从而为定量化舞蹈研究和教育提供技术基础。

Method: 该研究提出了一套整合YOLOv8/v11的舞者检测与SAM精细分割的自动化分析流程，能够检测视频帧内舞者、计步、分析空间覆盖及节奏一致性。方法在一段49秒加纳AfroBeats舞蹈视频上进行了初步测试。

Result: 系统在人工样本检查下，舞者检测准确率约94%、召回率89%，SAM分割与人工可视检查的IoU大约为83%。系统能够区分主、次舞者，量化其动作数量、强度及空间覆盖范围。

Conclusion: 本工作验证了所提框架的技术可行性和优越性，但仍处于初步阶段，有代表性不足、标准标注和与现有算法对比缺失等不足，为未来系统化验证和定量舞蹈分析指标研究打下了基础。

Abstract: This paper presents a preliminary investigation into automated dance movement analysis using contemporary computer vision techniques. We propose a proof-of-concept framework that integrates YOLOv8 and v11 for dancer detection with the Segment Anything Model (SAM) for precise segmentation, enabling the tracking and quantification of dancer movements in video recordings without specialized equipment or markers. Our approach identifies dancers within video frames, counts discrete dance steps, calculates spatial coverage patterns, and measures rhythm consistency across performance sequences. Testing this framework on a single 49-second recording of Ghanaian AfroBeats dance demonstrates technical feasibility, with the system achieving approximately 94% detection precision and 89% recall on manually inspected samples. The pixel-level segmentation provided by SAM, achieving approximately 83% intersection-over-union with visual inspection, enables motion quantification that captures body configuration changes beyond what bounding-box approaches can represent. Analysis of this preliminary case study indicates that the dancer classified as primary by our system executed 23% more steps with 37% higher motion intensity and utilized 42% more performance space compared to dancers classified as secondary. However, this work represents an early-stage investigation with substantial limitations including single-video validation, absence of systematic ground truth annotations, and lack of comparison with existing pose estimation methods. We present this framework to demonstrate technical feasibility, identify promising directions for quantitative dance metrics, and establish a foundation for future systematic validation studies.

</details>


### [46] [MUT3R: Motion-aware Updating Transformer for Dynamic 3D Reconstruction](https://arxiv.org/abs/2512.03939)
*Guole Shen,Tianchen Deng,Xingrui Qin,Nailin Wang,Jianyu Wang,Yanbo Wang,Yongtao Chen,Hesheng Wang,Jingchuan Wang*

Main category: cs.CV

TL;DR: 文章提出了一种针对动态图像中运动伪影的无训练新方法——MUT3R，通过利用transformer自带注意力机制中隐含的运动线索，在推理阶段动态抑制变化区域，从而提升3D重建的稳定性与一致性。


<details>
  <summary>Details</summary>
Motivation: 虽然现有的时序递归神经网络（如transformer）在静态3D重建上取得进展，但在处理动态图像尤其是有非刚性区域时，容易出现运动伪影，影响空间记忆与特征传播。观察到变动区域在注意力机制中被自然降权，表明预训练transformer自带运动感知能力但未被显式利用。

Method: 提出MUT3R框架，无需额外训练，直接在推理阶段利用transformer注意力图的聚合结果，在网络早期动态抑制运动区，防止其伪影沿特征层级扩散。通过注意力门控模块，只需简单前向推理调整，而无需模型再训练或微调。

Result: 在多个动态3D重建基准测试上，MUT3R提升了时间一致性和相机位姿鲁棒性，显著减少了动态图像中的运动伪影。

Conclusion: MUT3R为动态图像3D重建任务提供了一条无需再训练、可直接推理应用的运动感知途径，理论与实验表明该方法可提升稳定性、鲁棒性和一致性，具有实际应用前景。

Abstract: Recent stateful recurrent neural networks have achieved remarkable progress on static 3D reconstruction but remain vulnerable to motion-induced artifacts, where non-rigid regions corrupt attention propagation between the spatial memory and image feature. By analyzing the internal behaviors of the state and image token updating mechanism, we find that aggregating self-attention maps across layers reveals a consistent pattern: dynamic regions are naturally down-weighted, exposing an implicit motion cue that the pretrained transformer already encodes but never explicitly uses. Motivated by this observation, we introduce MUT3R, a training-free framework that applies the attention-derived motion cue to suppress dynamic content in the early layers of the transformer during inference. Our attention-level gating module suppresses the influence of dynamic regions before their artifacts propagate through the feature hierarchy. Notably, we do not retrain or fine-tune the model; we let the pretrained transformer diagnose its own motion cues and correct itself. This early regulation stabilizes geometric reasoning in streaming scenarios and leads to improvements in temporal consistency and camera pose robustness across multiple dynamic benchmarks, offering a simple and training-free pathway toward motion-aware streaming reconstruction.

</details>


### [47] [AdaptVision: Efficient Vision-Language Models via Adaptive Visual Acquisition](https://arxiv.org/abs/2512.03794)
*Zichuan Lin,Yicheng Liu,Yang Yang,Lvfang Tao,Deheng Ye*

Main category: cs.CV

TL;DR: AdaptVision是一种新型高效视觉-语言模型（VLM），能根据每个样本自适应选择最少的视觉token数，实现更优性能和更低计算开销。


<details>
  <summary>Details</summary>
Motivation: 当前VLM大多依赖大量视觉token，带来巨大计算负担。现有方法仅用固定比例压缩，不能针对不同任务需求自适应调整，由此提出能自主决定token数量的VLM是重要创新。

Method: 提出AdaptVision模型，借鉴人类主动视觉机制，采用先粗后细策略：先以低分辨率token粗处理，再针对所需区域调用边框工具精细采集。通过强化学习框架训练，提出Decoupled Turn Policy Optimization（DTPO），将目标分为工具使用和答案准确度两部分优化，并对每部分分别估算优势值，提高训练效率和优化效果。

Result: AdaptVision在多个视觉问答基准数据集实验中，相较于主流高效VLM方法，用更少视觉token达到更优或相当的性能。

Conclusion: AdaptVision通过自适应视觉token选择，实现了效率和性能的兼顾，展示了主动视觉机制在VLM中的应用前景。

Abstract: Vision-Language Models (VLMs) have achieved remarkable success in visual question answering tasks, but their reliance on large numbers of visual tokens introduces significant computational overhead. While existing efficient VLM approaches reduce visual tokens through fixed-ratio compression, they operate passively and lack the ability to adapt to varying task requirements. This motivates a fundamental question: Can VLMs autonomously determine the minimum number of visual tokens required for each sample? Inspired by human active vision mechanisms, we introduce AdaptVision, an efficient VLM paradigm that enables adaptive visual token acquisition through a coarse-to-fine approach. Our model initially processes compressed visual tokens from low-resolution images and selectively acquires additional visual information by invoking a bounding box tool to crop key regions when necessary. We train AdaptVision using a reinforcement learning framework that carefully balances accuracy and efficiency. Central to our approach is Decoupled Turn Policy Optimization (DTPO), which decouples the learning objective into two components: (1) tool learning, which optimizes correct tool utilization, and (2) accuracy improvement, which refines the generated responses to improve answer correctness. Based on this formulation, we further decouple advantage estimation by computing separate advantages for tokens associated with each objective. This formulation enables more effective optimization for AdaptVision compared to vanilla GRPO. Comprehensive experiments across multiple VQA benchmarks demonstrate that AdaptVision achieves superior performance while consuming substantially fewer visual tokens than state-of-the-art efficient VLM methods.

</details>


### [48] [SpaceTools: Tool-Augmented Spatial Reasoning via Double Interactive RL](https://arxiv.org/abs/2512.04069)
*Siyi Chen,Mikaela Angelina Uy,Chan Hee Song,Faisal Ladhak,Adithyavairavan Murali,Qing Qu,Stan Birchfield,Valts Blukis,Jonathan Tremblay*

Main category: cs.CV

TL;DR: 本文提出了一种强化学习方法，提升了VLMs在多个工具协同下的空间推理能力，突破了以往仅支持单一工具的局限，达到了新的性能高度。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言模型在视觉理解上表现优秀，但在需要精确空间推理的场景（如机器人操作）表现不足。目前主要策略要么依赖手工提示，要么使用固定工具流程，限制了模型利用工具的灵活性和最优性，因此需要更智能的工具协调方式。

Method: 作者提出“双交互强化学习（DIRL）”训练框架，分为两个阶段：教学阶段利用单工具专家和全工具前沿模型示例相结合，探索阶段则通过持续RL实现多工具协作能力的细致优化。

Result: 提出的SpaceTools模型在多个空间理解基准（RoboSpatial-Home、BLINK、BOP-ASK）上取得了SOTA表现，在真实的7自由度机械臂操控任务中表现可靠。相较于传统的SFT和单工具RL，性能分别提升12%和16%。

Conclusion: DIRL显著提升了VLMs在多工具空间推理和真实操作任务中的能力，为未来VLMs智能化工具协作提供了有效解决思路。

Abstract: Vision Language Models (VLMs) demonstrate strong qualitative visual understanding, but struggle with metrically precise spatial reasoning required for embodied applications. The agentic paradigm promises that VLMs can use a wide variety of tools that could augment these capabilities, such as depth estimators, segmentation models, and pose estimators. Yet it remains an open challenge how to realize this vision without solely relying on handcrafted prompting strategies or enforcing fixed, predefined tool pipelines that limit VLMs' ability to discover optimal tool-use patterns. Reinforcement Learning could overcome this gap, but has so far been limited to reasoning with a single visual tool due to the large search space in multi-tool reasoning. We introduce Double Interactive Reinforcement Learning (DIRL), a two-phase training framework where VLMs learn to coordinate multiple tools through interactive exploration and feedback. In the teaching phase, we combine demonstrations from a single tool specialist trained via interactive RL with traces from a frontier model using all tools. In the exploration phase, the model further refines multi-tool coordination through continued RL. Our model, SpaceTools, with tool-augmented spatial reasoning ability, achieves state-of-the-art performance on spatial understanding benchmarks (RoboSpatial-Home, BLINK, BOP-ASK) and demonstrates reliable real-world manipulation using a 7-DOF robot as a tool. DIRL provides substantial improvements over the vanilla SFT (+12% on RoboSpatial) and RL (+16% on RoboSpatial) baselines. Project page: https://spacetools.github.io/.

</details>


### [49] [Stable Signer: Hierarchical Sign Language Generative Model](https://arxiv.org/abs/2512.04048)
*Sen Fang,Yalin Feng,Hongbin Zhong,Yanxin Zhang,Dimitris N. Metaxas*

Main category: cs.CV

TL;DR: 本文提出一种新的手语生成模型Stable Signer，将传统手语生成的多个冗余阶段简化为端到端的两阶段，并显著提升了视频生成的质量和表现。


<details>
  <summary>Details</summary>
Motivation: 现有手语生成方法在文本转换、姿态生成和视频渲染等环节累积大量误差，进展缓慢，亟需简化流程并提升整体效果。

Method: 作者将手语生成重构为分层的端到端任务，仅保留文本理解和姿态到视频（Pose2Vid）两个阶段，并提出SLUL（Sign Language Understanding Linker）用于文本理解，同时设计SLP-MoE手势渲染模块。SLUL通过新颖的SAGM Loss进行训练。

Result: 相比当前SOTA（state-of-the-art）方法，Stable Signer模型的性能提升了48.6%。

Conclusion: Stable Signer通过优化结构和训练损失函数，实现了高质量、多风格的手语视频端到端生成，有效推动了手语生成技术的发展。

Abstract: Sign Language Production (SLP) is the process of converting the complex input text into a real video. Most previous works focused on the Text2Gloss, Gloss2Pose, Pose2Vid stages, and some concentrated on Prompt2Gloss and Text2Avatar stages. However, this field has made slow progress due to the inaccuracy of text conversion, pose generation, and the rendering of poses into real human videos in these stages, resulting in gradually accumulating errors. Therefore, in this paper, we streamline the traditional redundant structure, simplify and optimize the task objective, and design a new sign language generative model called Stable Signer. It redefines the SLP task as a hierarchical generation end-to-end task that only includes text understanding (Prompt2Gloss, Text2Gloss) and Pose2Vid, and executes text understanding through our proposed new Sign Language Understanding Linker called SLUL, and generates hand gestures through the named SLP-MoE hand gesture rendering expert block to end-to-end generate high-quality and multi-style sign language videos. SLUL is trained using the newly developed Semantic-Aware Gloss Masking Loss (SAGM Loss). Its performance has improved by 48.6% compared to the current SOTA generation methods.

</details>


### [50] [FloodDiffusion: Tailored Diffusion Forcing for Streaming Motion Generation](https://arxiv.org/abs/2512.03520)
*Yiyi Cai,Yuhan Wu,Kunhang Li,You Zhou,Bo Zheng,Haiyang Liu*

Main category: cs.CV

TL;DR: 本文提出了FloodDiffusion框架，可根据时间变化的文本提示流式生成与文本对齐、无缝衔接的人体动作序列，具有实时响应能力，并在HumanML3D基准测试取得了当前最优的结果。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本的人体动作生成方法在面对流式（流媒体）生成和时间动态控制时，难以实现自然、无缝与实时的动作生成。尤其传统的扩散模型在视频或动作序列领域直接应用时并不能准确还原真实动作分布，因此需要新的模型设计来满足这一需求。

Method: 该方法采用扩散forcing框架，针对时间序列和动态控制问题进行了定制化改进：1）训练时使用双向注意力机制而非因果注意力；2）采用下三角时间调度器替代随机调度；3）以连续变化的方式引入文本条件，从而提升对时间动态控制事件的建模能力。

Result: 所提出的FloodDiffusion框架实现了流式、文本驱动的人体动作生成，动作无缝衔接且实时，且在HumanML3D数据集上取得了0.057的FID分数，远优于已有方法。

Conclusion: 改进的扩散forcing框架能够更好地建模时序动态受控事件下的动作分布，实现高质量、实时、与文本高度一致的人体动作生成，为相关流媒体内容生成奠定了技术基础。

Abstract: We present FloodDiffusion, a new framework for text-driven, streaming human motion generation. Given time-varying text prompts, FloodDiffusion generates text-aligned, seamless motion sequences with real-time latency. Unlike existing methods that rely on chunk-by-chunk or auto-regressive model with diffusion head, we adopt a diffusion forcing framework to model this time-series generation task under time-varying control events. We find that a straightforward implementation of vanilla diffusion forcing (as proposed for video models) fails to model real motion distributions. We demonstrate that to guarantee modeling the output distribution, the vanilla diffusion forcing must be tailored to: (i) train with a bi-directional attention instead of casual attention; (ii) implement a lower triangular time scheduler instead of a random one; (iii) utilize a continues time-varying way to introduce text conditioning. With these improvements, we demonstrate in the first time that the diffusion forcing-based framework achieves state-of-the-art performance on the streaming motion generation task, reaching an FID of 0.057 on the HumanML3D benchmark. Models, code, and weights are available. https://shandaai.github.io/FloodDiffusion/

</details>


### [51] [OpenTrack3D: Towards Accurate and Generalizable Open-Vocabulary 3D Instance Segmentation](https://arxiv.org/abs/2512.03532)
*Zhishan Zhou,Siyuan Wei,Zengran Wang,Chunjie Wang,Xiaosheng Yan,Xiao Liu*

Main category: cs.CV

TL;DR: 本文提出了OpenTrack3D框架，实现了无需网格的开放词汇3D实例分割，提升了系统对新环境和复杂场景的泛化与理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇3D实例分割方法对于多样化、无结构和无网格的环境泛化能力弱，主要受限于对提案生成依赖数据集/网格以及CLIP文本理解能力不足，难以应对泛化场景和用户复杂查询。

Method: OpenTrack3D不用预生成提案，而采用可视-空间跟踪器，基于RGB-D流通过2D分割器生成掩码，并升维为3D点云，利用DINO提取特征，跟踪器融合视觉和空间信息实现实例一致性。此外，引入可选的超点精细化模块和用多模态大语言模型（MLLM）替代CLIP提升复杂文本推理能力。

Result: 在ScanNet200、Replica、ScanNet++和SceneFun3D等多个基准上，OpenTrack3D取得了最优表现，证明了其优良的性能和较强的泛化能力。

Conclusion: OpenTrack3D无需依赖网格结构即可实现高效、泛化性强的开放词汇3D实例分割，并能支持复杂的用户查询，在各类环境中表现突出。

Abstract: Generalizing open-vocabulary 3D instance segmentation (OV-3DIS) to diverse, unstructured, and mesh-free environments is crucial for robotics and AR/VR, yet remains a significant challenge. We attribute this to two key limitations of existing methods: (1) proposal generation relies on dataset-specific proposal networks or mesh-based superpoints, rendering them inapplicable in mesh-free scenarios and limiting generalization to novel scenes; and (2) the weak textual reasoning of CLIP-based classifiers, which struggle to recognize compositional and functional user queries. To address these issues, we introduce OpenTrack3D, a generalizable and accurate framework. Unlike methods that rely on pre-generated proposals, OpenTrack3D employs a novel visual-spatial tracker to construct cross-view consistent object proposals online. Given an RGB-D stream, our pipeline first leverages a 2D open-vocabulary segmenter to generate masks, which are lifted to 3D point clouds using depth. Mask-guided instance features are then extracted using DINO feature maps, and our tracker fuses visual and spatial cues to maintain instance consistency. The core pipeline is entirely mesh-free, yet we also provide an optional superpoints refinement module to further enhance performance when scene mesh is available. Finally, we replace CLIP with a multi-modal large language model (MLLM), significantly enhancing compositional reasoning for complex user queries. Extensive experiments on diverse benchmarks, including ScanNet200, Replica, ScanNet++, and SceneFun3D, demonstrate state-of-the-art performance and strong generalization capabilities.

</details>


### [52] [Rethinking Prompt Design for Inference-time Scaling in Text-to-Visual Generation](https://arxiv.org/abs/2512.03534)
*Subin Kim,Sangwoo Mo,Mamshad Nayeem Rizve,Yiran Xu,Difan Liu,Jinwoo Shin,Tobias Hinz*

Main category: cs.CV

TL;DR: PRIS方法通过在推理阶段动态重写提示词，实现文本到视觉生成任务中用户意图和生成内容的更精确对齐，相比仅扩展采样规模能带来明显性能提升。


<details>
  <summary>Details</summary>
Motivation: 在文本到视觉生成领域，单一生成很难满足用户意图，现有方法通过增加采样次数来提高质量，但遇到瓶颈，问题根源在于固定提示词无法充分利用大规模推理优势。

Method: 提出了PRIS框架，在生成过程中，分析生成结果中的失败模式，动态重写提示词后再生成。引入了元素级事实核查器，从细粒度上评价生成内容与提示词的匹配，实现更精确、可解释的反馈。

Result: 在文本生成图像和视频的多个基准测试中，PRIS取得了显著提升，包括在VBench 2.0上提升15%。

Conclusion: 仅扩展采样规模效果有限，推理时联合扩展提示词与视觉生成规模，实现了更优性能。

Abstract: Achieving precise alignment between user intent and generated visuals remains a central challenge in text-to-visual generation, as a single attempt often fails to produce the desired output. To handle this, prior approaches mainly scale the visual generation process (e.g., increasing sampling steps or seeds), but this quickly leads to a quality plateau. This limitation arises because the prompt, crucial for guiding generation, is kept fixed. To address this, we propose Prompt Redesign for Inference-time Scaling, coined PRIS, a framework that adaptively revises the prompt during inference in response to the scaled visual generations. The core idea of PRIS is to review the generated visuals, identify recurring failure patterns across visuals, and redesign the prompt accordingly before regenerating the visuals with the revised prompt. To provide precise alignment feedback for prompt revision, we introduce a new verifier, element-level factual correction, which evaluates the alignment between prompt attributes and generated visuals at a fine-grained level, achieving more accurate and interpretable assessments than holistic measures. Extensive experiments on both text-to-image and text-to-video benchmarks demonstrate the effectiveness of our approach, including a 15% gain on VBench 2.0. These results highlight that jointly scaling prompts and visuals is key to fully leveraging scaling laws at inference-time. Visualizations are available at the website: https://subin-kim-cv.github.io/PRIS.

</details>


### [53] [CookAnything: A Framework for Flexible and Consistent Multi-Step Recipe Image Generation](https://arxiv.org/abs/2512.03540)
*Ruoxuan Zhang,Bin Wen,Hongxia Xie,Yi Yao,Songhan Zuo,Jian-Yu Jiang-Lin,Hong-Han Shuai,Wen-Huang Cheng*

Main category: cs.CV

TL;DR: 本文提出了一种新的扩散模型CookAnything，可根据任意长度的烹饪指令生成连贯、多样的步骤图像序列，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有文生图扩散模型难以生成结构化的多步骤过程图，且配方插画方法缺乏灵活性，不能自适应食谱长度和步骤变化。

Method: CookAnything框架，包含三大核心组件：（1）Step-wise Regional Control（SRC），实现文本步骤与特定图像区域的对齐；（2）Flexible RoPE，一种能够增强时序连贯性和空间多样性的步感知位置编码机制；（3）Cross-Step Consistency Control（CSCC），细粒度地保持跨步骤的食材一致性。

Result: 在配方插画领域基准测试上，无论是否训练，CookAnything表现均优于现有方法。支持高质量、可扩展的多步骤指令可视化。

Conclusion: CookAnything为复杂过程多步骤指令的视觉合成提供了灵活高效的方案，有望广泛应用于教学媒体与流程内容创作领域。

Abstract: Cooking is a sequential and visually grounded activity, where each step such as chopping, mixing, or frying carries both procedural logic and visual semantics. While recent diffusion models have shown strong capabilities in text-to-image generation, they struggle to handle structured multi-step scenarios like recipe illustration. Additionally, current recipe illustration methods are unable to adjust to the natural variability in recipe length, generating a fixed number of images regardless of the actual instructions structure. To address these limitations, we present CookAnything, a flexible and consistent diffusion-based framework that generates coherent, semantically distinct image sequences from textual cooking instructions of arbitrary length. The framework introduces three key components: (1) Step-wise Regional Control (SRC), which aligns textual steps with corresponding image regions within a single denoising process; (2) Flexible RoPE, a step-aware positional encoding mechanism that enhances both temporal coherence and spatial diversity; and (3) Cross-Step Consistency Control (CSCC), which maintains fine-grained ingredient consistency across steps. Experimental results on recipe illustration benchmarks show that CookAnything performs better than existing methods in training-based and training-free settings. The proposed framework supports scalable, high-quality visual synthesis of complex multi-step instructions and holds significant potential for broad applications in instructional media, and procedural content creation.

</details>


### [54] [V-ITI: Mitigating Hallucinations in Multimodal Large Language Models via Visual Inference-Time Intervention](https://arxiv.org/abs/2512.03542)
*Nan Sun,Zhenyu Zhang,Xixun Lin,Kun Wang,Yanmin Shang,Naibin Gu,Shuohuan Wang,Yu Sun,Hua Wu,Haifeng Wang,Yanan Cao*

Main category: cs.CV

TL;DR: 本文提出了一种用于多模态大模型（MLLM）推理阶段的轻量级干预框架V-ITI，有效减轻了视觉幻觉问题，并保持了任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型在视觉-语言任务中表现出色，但在精确度要求高的场景下容易产生视觉幻觉（即输出与输入图像不符的内容），主要原因是模型对视觉输入关注不够。以往方法侧重于干预方式，但缺乏“何时干预”的判断，容易导致过度干预并引入新问题。

Method: 作者提出V-ITI框架，核心包括两部分：（1）视觉忽视检测器，通过对模型内部head级别激活模式的判别实现对视觉忽视状态的识别；（2）视觉唤回干预器，仅在检测到视觉忽视时，基于预存的视觉激活信息适当调节激活，从而实现有针对性的干预。该方法轻量高效，避免过度干预。

Result: 在八个基准测试和多种主流多模态大模型上进行了大量实验，结果表明V-ITI能有效减少与视觉相关的幻觉现象，同时保持模型的整体任务性能。

Conclusion: V-ITI为多模态大模型中的视觉幻觉问题提供了新颖且切实有效的解决方案，有望在精度敏感领域提升多模态模型的可靠性。

Abstract: Multimodal Large Language Models (MLLMs) excel in numerous vision-language tasks yet suffer from hallucinations, producing content inconsistent with input visuals, that undermine reliability in precision-sensitive domains. This issue stems from a fundamental problem of visual neglect, where models fail to adequately prioritize input images. Existing methods typically alleviate hallucinations by intervening in the attention score or output logits, focusing on "how to intervene" but overlooking the prerequisite "when to intervene", which leads to the "over-intervention" problem and subsequently introduces new hallucinations and unnecessary computational overhead. To address this gap, we first investigate the mechanism of visual neglect and reveal it can be accurately detected via head-level activation patterns in MLLMs. We thus propose V-ITI, a lightweight visual inference-time intervention framework integrating a Visual Neglect Detector that identifies visual neglect via head-level discriminative probes and a Visual Recall Intervenor that modulates activations with prestored visual activation information only when the visual neglect is detected. Extensive experiments across eight benchmarks and different MLLM families demonstrate that V-ITI consistently mitigates vision-related hallucinations while preserving general task performance.

</details>


### [55] [Dynamic Content Moderation in Livestreams: Combining Supervised Classification with MLLM-Boosted Similarity Matching](https://arxiv.org/abs/2512.03553)
*Wei Chee Yew,Hailun Xu,Sanjay Saha,Xiaotian Fan,Hiok Hian Ong,David Yuchen Wang,Kanchan Sarkar,Zhenheng Yang,Danhui Guan*

Main category: cs.CV

TL;DR: 本文提出了一种用于大规模用户生成视频平台（特别是直播）的混合内容审核框架，结合了监督分类和基于相似度的参考匹配，以增强对违规内容的检测能力。


<details>
  <summary>Details</summary>
Motivation: 直播内容日益增长，违规内容形式变化多端，传统的内容审核方法难以兼顾效率与准确性，迫切需要更强大且可扩展的审核手段。

Method: 该方法将已知违规的监督分类与针对新型或隐性违规的参考相似度匹配结合起来。针对多模态输入（文本、音频、视觉），通过两条审核管道进行处理，并利用多模态大语言模型(MLLM)提高知识蒸馏和推理效率。

Result: 分类审核管道在80%精度下召回率为67%，相似度审核管道在同样精度下召回率为76%。大规模A/B测试显示用户观看违规直播内容的比率降低了6%-8%。

Conclusion: 提出的混合多模态审核方法在实际生产环境中效果显著，既能有效识别明确违规内容，也能应对新型复杂违规行为，实现高效可扩展的内容治理。

Abstract: Content moderation remains a critical yet challenging task for large-scale user-generated video platforms, especially in livestreaming environments where moderation must be timely, multimodal, and robust to evolving forms of unwanted content. We present a hybrid moderation framework deployed at production scale that combines supervised classification for known violations with reference-based similarity matching for novel or subtle cases. This hybrid design enables robust detection of both explicit violations and novel edge cases that evade traditional classifiers. Multimodal inputs (text, audio, visual) are processed through both pipelines, with a multimodal large language model (MLLM) distilling knowledge into each to boost accuracy while keeping inference lightweight. In production, the classification pipeline achieves 67% recall at 80% precision, and the similarity pipeline achieves 76% recall at 80% precision. Large-scale A/B tests show a 6-8% reduction in user views of unwanted livestreams}. These results demonstrate a scalable and adaptable approach to multimodal content governance, capable of addressing both explicit violations and emerging adversarial behaviors.

</details>


### [56] [GAOT: Generating Articulated Objects Through Text-Guided Diffusion Models](https://arxiv.org/abs/2512.03566)
*Hao Sun,Lei Fan,Donglin Di,Shaohui Liu*

Main category: cs.CV

TL;DR: 该论文提出了GAOT框架，实现了从文本生成3D关节物体，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有3D关节物体生成模型无法针对文本提示生成物体，存在描述与物体表示之间的鸿沟。

Method: GAOT采用三阶段流程：首先微调点云生成模型根据文本生成物体粗略表示；其次用超图学习方法细化表示，把零部件作为图的顶点；最后利用扩散模型基于部件生成关节（图的边）。

Result: 在PartNet-Mobility数据集上进行了定性和定量实验，GAOT取得了优于以往方法的效果。

Conclusion: GAOT有效缩小了文本描述与3D关节物体之间的表达差距，且在任务上表现出色。

Abstract: Articulated object generation has seen increasing advancements, yet existing models often lack the ability to be conditioned on text prompts. To address the significant gap between textual descriptions and 3D articulated object representations, we propose GAOT, a three-phase framework that generates articulated objects from text prompts, leveraging diffusion models and hypergraph learning in a three-step process. First, we fine-tune a point cloud generation model to produce a coarse representation of objects from text prompts. Given the inherent connection between articulated objects and graph structures, we design a hypergraph-based learning method to refine these coarse representations, representing object parts as graph vertices. Finally, leveraging a diffusion model, the joints of articulated objects-represented as graph edges-are generated based on the object parts. Extensive qualitative and quantitative experiments on the PartNet-Mobility dataset demonstrate the effectiveness of our approach, achieving superior performance over previous methods.

</details>


### [57] [Global-Local Aware Scene Text Editing](https://arxiv.org/abs/2512.03574)
*Fuxiang Yang,Tonghua Su,Donglin Di,Yin Chen,Xiangqian Wu,Zhongjie Wang,Lei Fan*

Main category: cs.CV

TL;DR: 本文提出了一种端到端的场景文本编辑框架GLASTE，有效解决了现有方法在一致性和长度不敏感上的难题，且在实际数据集上取得了优异效果。


<details>
  <summary>Details</summary>
Motivation: 现有场景文本编辑方法在编辑后局部区域与周围区域的一致性不足，并且难以处理编辑前后文本长度差异较大的问题。因此，亟需更有效的方法来增强编辑的一致性和长度适应性。

Method: 提出了GLASTE框架，结合了全局和局部信息，通过设计全球-局部结合结构、联合损失函数、特征增强等方式，保证风格一致性和全局-局部协调；此外，将文本风格独立为与图像尺寸无关的向量，加以跨尺寸迁移，并通过仿射融合保持目标文本的长宽比一致地填充至编辑区。

Result: 在真实场景数据集上的大量实验显示，GLASTE模型在定量和定性评估上均优于以往方法，且有效缓解了一致性与长度不敏感的两大挑战。

Conclusion: GLASTE框架能有效提升场景文本编辑的编辑质量和风格一致性，尤其在应对文本长度变化时表现突出。

Abstract: Scene Text Editing (STE) involves replacing text in a scene image with new target text while preserving both the original text style and background texture. Existing methods suffer from two major challenges: inconsistency and length-insensitivity. They often fail to maintain coherence between the edited local patch and the surrounding area, and they struggle to handle significant differences in text length before and after editing. To tackle these challenges, we propose an end-to-end framework called Global-Local Aware Scene Text Editing (GLASTE), which simultaneously incorporates high-level global contextual information along with delicate local features. Specifically, we design a global-local combination structure, joint global and local losses, and enhance text image features to ensure consistency in text style within local patches while maintaining harmony between local and global areas. Additionally, we express the text style as a vector independent of the image size, which can be transferred to target text images of various sizes. We use an affine fusion to fill target text images into the editing patch while maintaining their aspect ratio unchanged. Extensive experiments on real-world datasets validate that our GLASTE model outperforms previous methods in both quantitative metrics and qualitative results and effectively mitigates the two challenges.

</details>


### [58] [UniComp: Rethinking Video Compression Through Informational Uniqueness](https://arxiv.org/abs/2512.03575)
*Chao Yuan,Shimin Chen,Minliang Lin,Limeng Qiao,Guanglu Wan,Lin Ma*

Main category: cs.CV

TL;DR: 本文提出了一种基于信息唯一性驱动的视频压缩框架UniComp，能够在有限算力下更有效保留视频关键信息并提升压缩效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于注意力机制的视频压缩方法在算力有限环境下存在信息保真度不足和压缩效率受限的问题。本研究尝试从信息论角度出发，优化视频压缩过程中信息的独特性和利用效率。

Method: 作者提出信息唯一性的概念来度量各token间的固有冗余，并以此为基础设计了三大模块：帧组融合（Frame Group Fusion）、token自适应分配（Token Allocation）、空间动态压缩（Spatial Dynamic Compression），分别实现对视频语义帧分组、自适应资源分配和细粒度空间压缩。整个过程以最小化条件熵（即重建误差）为目标。

Result: 实验表明，UniComp能够在一定的算力限制下，较现有主流压缩方法更好地保留视频中关键信息token，取得更优的信息保真与压缩平衡。

Conclusion: 信息唯一性对于提升token压缩效果至关重要，所提出的UniComp框架在提高压缩效率和视觉信息保真方面具有明显优势。

Abstract: Distinct from attention-based compression methods, this paper presents an information uniqueness driven video compression framework, termed UniComp, which aims to maximize the information fidelity of video representations under constrained computational budgets. Starting from the information-theoretic perspective, we formulate the vision compression as an optimization problem that minimizes conditional entropy (reconstruction error) between retained and full tokens. To achieve this, we introduce the notion of information uniqueness to measure intrinsic redundancy among tokens to link with reconstruction error. Based on uniqueness, we design three modules-Frame Group Fusion, Token Allocation, and Spatial Dynamic Compression-that progressively perform semantic frame grouping, adaptive resource allocation, and fine-grained spatial compression. Extensive experiments demonstrate that UniComp consistently outperforms existing compression methods in preserving essential visual tokens under limited computational budgets, highlighting the pivotal role of information uniqueness in token compression efficacy.

</details>


### [59] [Cross-Stain Contrastive Learning for Paired Immunohistochemistry and Histopathology Slide Representation Learning](https://arxiv.org/abs/2512.03577)
*Yizhi Zhang,Lei Fan,Zhulin Tao,Donglin Di,Yang Song,Sidong Liu,Cong Cong*

Main category: cs.CV

TL;DR: 本文提出了一种新的跨染色（CSCL）对比学习方法，通过五种染色（H&E及四种IHC marker）精确对齐的全切片图像数据集，实现了更具泛化性和可迁移性的病理切片表征。


<details>
  <summary>Details</summary>
Motivation: 目前在计算病理学中，基于H&E染色的全切片图像表征已有许多进展，但掺入IHC等多组分标记可更丰富生物学信息。主流方法受限于多染色数据集稀缺，以及不同染色之间组织错位带来的特征混乱，致使模型泛化和迁移能力不足。

Method: 作者构建了精确对齐的五染色切片数据集，并提出两阶段CSCL预训练方法：第一阶段用轻量Adapter实现patch级的跨染色对比对齐，使H&E特征学习到IHC上下文；第二阶段利用多实例学习（MIL），结合跨染色特征融合和全局对齐模块，在切片层面整合不同染色的特征表达。

Result: 在癌症亚型分类、IHC生物标志状态分类和生存预测任务上，CSCL方法可持续提升性能，获得高质量、可迁移的H&E切片级表征模型。

Conclusion: 通过构建多染色对齐大数据集及提出CSCL新框架，实现了切片级跨染色语义融合，极大丰富了H&E病理切片的生物学信息，有助于泛化和多下游任务应用。

Abstract: Universal, transferable whole-slide image (WSI) representations are central to computational pathology. Incorporating multiple markers (e.g., immunohistochemistry, IHC) alongside H&E enriches H&E-based features with diverse, biologically meaningful information. However, progress is limited by the scarcity of well-aligned multi-stain datasets. Inter-stain misalignment shifts corresponding tissue across slides, hindering consistent patch-level features and degrading slide-level embeddings. To address this, we curated a slide-level aligned, five-stain dataset (H&E, HER2, KI67, ER, PGR) to enable paired H&E-IHC learning and robust cross-stain representation. Leveraging this dataset, we propose Cross-Stain Contrastive Learning (CSCL), a two-stage pretraining framework with a lightweight adapter trained using patch-wise contrastive alignment to improve the compatibility of H&E features with corresponding IHC-derived contextual cues, and slide-level representation learning with Multiple Instance Learning (MIL), which uses a cross-stain attention fusion module to integrate stain-specific patch features and a cross-stain global alignment module to enforce consistency among slide-level embeddings across different stains. Experiments on cancer subtype classification, IHC biomarker status classification, and survival prediction show consistent gains, yielding high-quality, transferable H&E slide-level representations. The code and data are available at https://github.com/lily-zyz/CSCL.

</details>


### [60] [Dynamic Optical Test for Bot Identification (DOT-BI): A simple check to identify bots in surveys and online processes](https://arxiv.org/abs/2512.03580)
*Malte Bleeker,Mauro Gotsch*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的动态光学测试（DOT-BI），利用人类对于运动的感知，区别 humans 与自动化系统（如Bots）。人类通过运动辨识数字，而算法很难识别。实验表明，大多数人类用户能快速完成任务，而当前最先进的大模型无法解决。本文还公开了实现代码和多种测试变体以促进实际应用。


<details>
  <summary>Details</summary>
Motivation: 现有在线问卷和流程中，区分真人和机器人（Bots）是个难题，尤其随着AI模型能力增强，传统验证码等方法可能被攻破。因此，需要利用人机感知差异的新方法增强识别能力。

Method: DOT-BI测试把数字用与背景相同的黑白随机像素显示，仅通过运动和缩放差异使数字可被人感知，但对帧处理算法无效。作者采用两步评估：一是用SOTA视频及多模态模型（如GPT-5-Thinking和Gemini 2.5 Pro）尝试破解，但均失败；二是线上与实验室用户测试，评估人类识别效果与用户体验。

Result: 主流AI模型在知晓机制下依然无法完成任务。人类参与者（n=182）有99.5%完成，平均耗时10.7秒。实验室对照也无体验损失。说明方法对人机区分有效且易用。

Conclusion: DOT-BI在大幅提升人机识别安全性的同时，保持了良好用户体验，并具备开源、可扩展性。适合在问卷和在线流程中广泛推广。

Abstract: We propose the Dynamic Optical Test for Bot Identification (DOT-BI): a quick and easy method that uses human perception of motion to differentiate between human respondents and automated systems in surveys and online processes. In DOT-BI, a 'hidden' number is displayed with the same random black-and-white pixel texture as its background. Only the difference in motion and scale between the number and the background makes the number perceptible to humans across frames, while frame-by-frame algorithmic processing yields no meaningful signal. We conducted two preliminary assessments. Firstly, state-of-the-art, video-capable, multimodal models (GPT-5-Thinking and Gemini 2.5 Pro) fail to extract the correct value, even when given explicit instructions about the mechanism. Secondly, in an online survey (n=182), 99.5% (181/182) of participants solved the task, with an average end-to-end completion time of 10.7 seconds; a supervised lab study (n=39) found no negative effects on perceived ease-of-use or completion time relative to a control. We release code to generate tests and 100+ pre-rendered variants to facilitate adoption in surveys and online processes.

</details>


### [61] [Beyond Boundary Frames: Audio-Visual Semantic Guidance for Context-Aware Video Interpolation](https://arxiv.org/abs/2512.03590)
*Yuchen Deng,Xiuyang Wu,Hai-Tao Zheng,Jie Wang,Feidiao Yang,Yuxing Han*

Main category: cs.CV

TL;DR: 本文提出了一种新的视频帧插值方法BBF（Beyond Boundary Frames），通过多模态引入和进阶训练，有效提升了在复杂运动和音视频同步任务中的表现，超越了现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 现有插帧方法在处理复杂非线性运动、尤其是精细动作与多模态任务（如音视频同步）时准确性和一致性不足，难以适应多样化应用场景。

Method: （1）输入设计升级：模型可灵活处理文本、音频、图片与视频等多模态条件；（2）提出解耦型多模态融合机制，将多种条件信号顺序地注入DiT骨干网络；（3）采用多阶段递进式训练，用首尾帧差异动态调整采样与损失权重，保持基础模型生成能力。

Result: 实验表明，BBF在通用插帧及音视频同步插帧任务上，均优于当前专用最优方法，实现了多通道联合调控下的统一插帧框架。

Conclusion: BBF有效突破了现有插帧技术的局限，为多模态条件下的视频插帧任务提供了统一高效的解决方案。

Abstract: Handling fast, complex, and highly non-linear motion patterns has long posed challenges for video frame interpolation. Although recent diffusion-based approaches improve upon traditional optical-flow-based methods, they still struggle to cover diverse application scenarios and often fail to produce sharp, temporally consistent frames in fine-grained motion tasks such as audio-visual synchronized interpolation. To address these limitations, we introduce BBF (Beyond Boundary Frames), a context-aware video frame interpolation framework, which could be guided by audio/visual semantics. First, we enhance the input design of the interpolation model so that it can flexibly handle multiple conditional modalities, including text, audio, images, and video. Second, we propose a decoupled multimodal fusion mechanism that sequentially injects different conditional signals into a DiT backbone. Finally, to maintain the generation abilities of the foundation model, we adopt a progressive multi-stage training paradigm, where the start-end frame difference embedding is used to dynamically adjust both the data sampling and the loss weighting. Extensive experimental results demonstrate that BBF outperforms specialized state-of-the-art methods on both generic interpolation and audio-visual synchronized interpolation tasks, establishing a unified framework for video frame interpolation under coordinated multi-channel conditioning.

</details>


### [62] [Harnessing Hypergraphs in Geometric Deep Learning for 3D RNA Inverse Folding](https://arxiv.org/abs/2512.03592)
*Guang Yang,Lei Fan*

Main category: cs.CV

TL;DR: 本文提出了一种基于超图和编码-解码架构的生成模型——HyperRNA，用于高效解决RNA逆向折叠问题，实现目标结构的RNA序列设计，并在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: RNA逆向折叠（设计）问题，即给定目标二级结构，设计能够折叠成该结构的核苷酸序列，是RNA设计中的核心难题。其复杂性来源于序列与结构之间的高度非线性与复杂耦合关系，传统方法难以高效且准确地设计理想序列。

Method: 提出HyperRNA框架，采用三步流程：1）预处理阶段基于粗粒度三珠模型，提取RNA主链原子坐标，构建图结构；2）编码阶段，采用attention嵌入模块与超图编码器捕获高阶依赖和生物分子复杂相互作用；3）解码阶段，通过自回归方式生成RNA序列。整体架构为生成模型型的编码-解码器。

Result: 在PDBBind和RNAsolo数据集上进行定量和定性实验，涉及RNA逆向折叠任务和RNA-蛋白复合物序列生成任务，HyperRNA在性能上超越了现有RNA设计方法，展现出优异的生成能力和泛化性。

Conclusion: HyperRNA证明了利用超图结构与生成模型能有效提升RNA逆向折叠与序列设计水准，对RNA工程与相关生物信息领域具有重要应用潜力。

Abstract: The RNA inverse folding problem, a key challenge in RNA design, involves identifying nucleotide sequences that can fold into desired secondary structures, which are critical for ensuring molecular stability and function. The inherent complexity of this task stems from the intricate relationship between sequence and structure, making it particularly challenging. In this paper, we propose a framework, named HyperRNA, a generative model with an encoder-decoder architecture that leverages hypergraphs to design RNA sequences. Specifically, our HyperRNA model consists of three main components: preprocessing, encoding and decoding.
  In the preprocessing stage, graph structures are constructed by extracting the atom coordinates of RNA backbone based on 3-bead coarse-grained representation. The encoding stage processes these graphs, capturing higher order dependencies and complex biomolecular interactions using an attention embedding module and a hypergraph-based encoder. Finally, the decoding stage generates the RNA sequence in an autoregressive manner. We conducted quantitative and qualitative experiments on the PDBBind and RNAsolo datasets to evaluate the inverse folding task for RNA sequence generation and RNA-protein complex sequence generation. The experimental results demonstrate that HyperRNA not only outperforms existing RNA design methods but also highlights the potential of leveraging hypergraphs in RNA engineering.

</details>


### [63] [CloseUpAvatar: High-Fidelity Animatable Full-Body Avatars with Mixture of Multi-Scale Textures](https://arxiv.org/abs/2512.03593)
*David Svitov,Pietro Morerio,Lourdes Agapito,Alessio Del Bue*

Main category: cs.CV

TL;DR: 本文提出了一种新的人物数字化表示方法CloseUpAvatar，其通过可学习的高低频纹理贴图结合动态切换，实现了对更广泛摄像机运动下的人物高质量渲染。


<details>
  <summary>Details</summary>
Motivation: 现有人物数字化技术面对广泛摄像机运动和近距离细节渲染时，往往在渲染质量和效率上难以兼顾。因此，亟需一种兼顾真实、效率，并能适应多种相机距离和角度的表示方法。

Method: CloseUpAvatar将人物表示为一组带纹理的平面，分别为低频与高频细节各学习一组纹理。当相机靠近人物表面时，系统自动切换并提高高频纹理的比例，远离时减弱高频纹理，从而动态调节渲染细节。同时，采用有限数量的原始表示，提升渲染帧率。

Result: 在ActorsHQ高分辨率数据集上的实验表明，CloseUpAvatar在不同的新颖摄像机位置下均实现了比现有方法更优的主观和客观渲染效果，并且通过限制原始表示的数量保持了较高的渲染效率和FPS。

Conclusion: CloseUpAvatar有效提升了人物数字化渲染在广泛相机运动下的细节和真实性，兼顾了渲染效率与视觉质量，为虚拟人物表示提供了新的解决思路。

Abstract: We present a CloseUpAvatar - a novel approach for articulated human avatar representation dealing with more general camera motions, while preserving rendering quality for close-up views. CloseUpAvatar represents an avatar as a set of textured planes with two sets of learnable textures for low and high-frequency detail. The method automatically switches to high-frequency textures only for cameras positioned close to the avatar's surface and gradually reduces their impact as the camera moves farther away. Such parametrization of the avatar enables CloseUpAvatar to adjust rendering quality based on camera distance ensuring realistic rendering across a wider range of camera orientations than previous approaches. We provide experiments using the ActorsHQ dataset with high-resolution input images. CloseUpAvatar demonstrates both qualitative and quantitative improvements over existing methods in rendering from novel wide range camera positions, while maintaining high FPS by limiting the number of required primitives.

</details>


### [64] [HBFormer: A Hybrid-Bridge Transformer for Microtumor and Miniature Organ Segmentation](https://arxiv.org/abs/2512.03597)
*Fuchen Zheng,Xinyi Chen,Weixuan Li,Quanjun Li,Junhua Zhou,Xiaojiao Guo,Xuhang Chen,Chi-Man Pun,Shoujun Zhou*

Main category: cs.CV

TL;DR: 本文提出了HBFormer，一种结合了U型结构和Swin Transformer骨干的医学图像分割新架构，通过多尺度特征融合桥接机制，显著提升了小肿瘤和微型器官的分割效果，实验验证达到了最新最优水平。


<details>
  <summary>Details</summary>
Motivation: 现有基于窗口自注意力机制的Vision Transformer在医学图像分割中虽表现出色，但局部化注意力机制难以兼顾局部细节和全局上下文，导致如微小肿瘤、微型器官等难分割对象的表现受限。急需一种能同时有效融合局部和全局信息的新方法。

Method: 作者提出HBFormer，将U型编码器-解码器结构与强大的Swin Transformer结合用于多层次特征提取。其创新点在于“桥接”机制，即利用新设计的多尺度特征融合（MFF）解码器，通过通道和空间注意力模块及扩张卷积等手段，将编码器多尺度特征与全局上下文充分融合，实现精确长距离依赖建模和边界细致分割。

Result: 在多项医学图像分割公开数据集（包括多器官、肝脏肿瘤、膀胱肿瘤等）上进行了大量实验，HBFormer模型在小肿瘤、微型器官等高挑战任务中取得了领先（SOTA）的分割表现。

Conclusion: HBFormer有效弥补了现有Transformer局部和全局特征融合的不足，在医学图像中实现了更细致和更准确的分割，尤其擅长处理微小目标。

Abstract: Medical image segmentation is a cornerstone of modern clinical diagnostics. While Vision Transformers that leverage shifted window-based self-attention have established new benchmarks in this field, they are often hampered by a critical limitation: their localized attention mechanism struggles to effectively fuse local details with global context. This deficiency is particularly detrimental to challenging tasks such as the segmentation of microtumors and miniature organs, where both fine-grained boundary definition and broad contextual understanding are paramount. To address this gap, we propose HBFormer, a novel Hybrid-Bridge Transformer architecture. The 'Hybrid' design of HBFormer synergizes a classic U-shaped encoder-decoder framework with a powerful Swin Transformer backbone for robust hierarchical feature extraction. The core innovation lies in its 'Bridge' mechanism, a sophisticated nexus for multi-scale feature integration. This bridge is architecturally embodied by our novel Multi-Scale Feature Fusion (MFF) decoder. Departing from conventional symmetric designs, the MFF decoder is engineered to fuse multi-scale features from the encoder with global contextual information. It achieves this through a synergistic combination of channel and spatial attention modules, which are constructed from a series of dilated and depth-wise convolutions. These components work in concert to create a powerful feature bridge that explicitly captures long-range dependencies and refines object boundaries with exceptional precision. Comprehensive experiments on challenging medical image segmentation datasets, including multi-organ, liver tumor, and bladder tumor benchmarks, demonstrate that HBFormer achieves state-of-the-art results, showcasing its outstanding capabilities in microtumor and miniature organ segmentation. Code and models are available at: https://github.com/lzeeorno/HBFormer.

</details>


### [65] [Memory-Guided Point Cloud Completion for Dental Reconstruction](https://arxiv.org/abs/2512.03598)
*Jianan Sun,Yukang Huang,Dongzhihan Wang,Mingyu Fan*

Main category: cs.CV

TL;DR: 该论文提出了一种基于检索增强的牙齿点云补全新方法，即在编码器-解码器框架中引入可学习的原型记忆模块，有效提升补全过程的结构准确性和细节还原水平。


<details>
  <summary>Details</summary>
Motivation: 现有牙齿点云补全大多只依赖于部分输入的全局特征，这在大缺失区域情况下会导致结构错配和细节丢失。为解决这一痛点，作者希望引入牙齿结构先验，提升点云补全的稳定性和可靠性。

Method: 该方法在标准encoder-decoder框架基础上，增加了一个可学习的原型记忆模块。输入的部分点云经编码后，检索最近的原型，并通过置信门控机制与查询特征融合。该记忆库无需牙位标签，端到端训练并自组织为可复用的牙齿形状原型。该模块为补全提供了结构先验，并能与主流补全Backbone无缝兼容。

Result: 在自制Teeth3DS基准数据上，该方法在Chamfer距离上取得了一致提升。视觉结果上表现出更锐利的尖顶、脊线和牙间过渡，比传统方法还原更准确、更加真实。

Conclusion: 本方法为牙齿点云补全任务提供了一种简单有效的结构先验融合思路，可以充分利用样本间的结构规律，大幅提升补全效果，且具备很强的通用性和可扩展性。

Abstract: Partial dental point clouds often suffer from large missing regions caused by occlusion and limited scanning views, which bias encoder-only global features and force decoders to hallucinate structures. We propose a retrieval-augmented framework for tooth completion that integrates a prototype memory into standard encoder--decoder pipelines. After encoding a partial input into a global descriptor, the model retrieves the nearest manifold prototype from a learnable memory and fuses it with the query feature through confidence-gated weighting before decoding. The memory is optimized end-to-end and self-organizes into reusable tooth-shape prototypes without requiring tooth-position labels, thereby providing structural priors that stabilize missing-region inference and free decoder capacity for detail recovery. The module is plug-and-play and compatible with common completion backbones, while keeping the same training losses. Experiments on a self-processed Teeth3DS benchmark demonstrate consistent improvements in Chamfer Distance, with visualizations showing sharper cusps, ridges, and interproximal transitions. Our approach provides a simple yet effective way to exploit cross-sample regularities for more accurate and faithful dental point-cloud completion.

</details>


### [66] [Motion4D: Learning 3D-Consistent Motion and Semantics for 4D Scene Understanding](https://arxiv.org/abs/2512.03601)
*Haoran Zhou,Gim Hee Lee*

Main category: cs.CV

TL;DR: Motion4D提出了一种结合2D基础视觉模型先验与4D高斯喷涂表示的新框架，实现了更高3D一致性的场景分析。该方法有效提升了动态场景下的空间和时间一致性，显著优于现有2D/3D方法。


<details>
  <summary>Details</summary>
Motivation: 现有2D基础视觉模型虽然在单目视频分析中性能卓越，但缺乏3D一致性，导致复杂3D场景中的空间误差和时间闪烁，限制了动态场景几何与运动的深入理解。

Method: Motion4D框架采用两阶段迭代优化：先顺序优化动态/语义场以保持局部一致性，再进行全局联合优化确保长期一致；引入3D置信图调整运动先验，并用自适应再采样补充未覆盖区域；语义一致性通过交替优化语义场和SAM2提示词实现。

Result: Motion4D在点级跟踪、视频目标分割和新视角合成等多项场景理解任务上，性能均显著超过传统2D基础模型及3D方法。

Conclusion: Motion4D大幅提升了基础视觉模型在3D场景分析中的一致性与准确性，为后续动态场景理解和多视角视觉理解奠定了基础。

Abstract: Recent advancements in foundation models for 2D vision have substantially improved the analysis of dynamic scenes from monocular videos. However, despite their strong generalization capabilities, these models often lack 3D consistency, a fundamental requirement for understanding scene geometry and motion, thereby causing severe spatial misalignment and temporal flickering in complex 3D environments. In this paper, we present Motion4D, a novel framework that addresses these challenges by integrating 2D priors from foundation models into a unified 4D Gaussian Splatting representation. Our method features a two-part iterative optimization framework: 1) Sequential optimization, which updates motion and semantic fields in consecutive stages to maintain local consistency, and 2) Global optimization, which jointly refines all attributes for long-term coherence. To enhance motion accuracy, we introduce a 3D confidence map that dynamically adjusts the motion priors, and an adaptive resampling process that inserts new Gaussians into under-represented regions based on per-pixel RGB and semantic errors. Furthermore, we enhance semantic coherence through an iterative refinement process that resolves semantic inconsistencies by alternately optimizing the semantic fields and updating prompts of SAM2. Extensive evaluations demonstrate that our Motion4D significantly outperforms both 2D foundation models and existing 3D-based approaches across diverse scene understanding tasks, including point-based tracking, video object segmentation, and novel view synthesis. Our code is available at https://hrzhou2.github.io/motion4d-web/.

</details>


### [67] [LAMP: Language-Assisted Motion Planning for Controllable Video Generation](https://arxiv.org/abs/2512.03619)
*Muhammed Burak Kizil,Enes Sanli,Niloy J. Mitra,Erkut Erdem,Aykut Erdem,Duygu Ceylan*

Main category: cs.CV

TL;DR: 该论文提出了一种全新的视频运动控制方法LAMP，能够将自然语言描述直接转化为3D运动轨迹，实现对物体和相机运动的精准控制。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成虽可基于文本、布局等信息控制内容，但在运动（物体与相机动态）控制方面，现有接口受限，难以满足表达复杂与电影化场景的需求。

Method: 作者提出LAMP，利用大语言模型（LLMs）作为运动规划器，将自然语言描述转化为3D轨迹。方法包括设计符合电影拍摄习惯的运动领域专用语言（DSL），并通过大模型的程序合成能力，从自然语言生成结构化运动程序，进而确定性地映射到3D轨迹。作者还建立了大规模与自然文本描述配对的运动程序和3D轨迹数据集。

Result: 实验表明，LAMP在运动可控性和用户意图对齐方面明显优于最新方法，是首个可直接从自然语言生成物体与相机运动框架。

Conclusion: LAMP开创性地实现了通过自然语言精确控制视频中物体和相机运动，为复杂与电影级视频生成带来更高可控性和便利性，推动了视频生成技术发展。

Abstract: Video generation has achieved remarkable progress in visual fidelity and controllability, enabling conditioning on text, layout, or motion. Among these, motion control - specifying object dynamics and camera trajectories - is essential for composing complex, cinematic scenes, yet existing interfaces remain limited. We introduce LAMP that leverages large language models (LLMs) as motion planners to translate natural language descriptions into explicit 3D trajectories for dynamic objects and (relatively defined) cameras. LAMP defines a motion domain-specific language (DSL), inspired by cinematography conventions. By harnessing program synthesis capabilities of LLMs, LAMP generates structured motion programs from natural language, which are deterministically mapped to 3D trajectories. We construct a large-scale procedural dataset pairing natural text descriptions with corresponding motion programs and 3D trajectories. Experiments demonstrate LAMP's improved performance in motion controllability and alignment with user intent compared to state-of-the-art alternatives establishing the first framework for generating both object and camera motions directly from natural language specifications.

</details>


### [68] [ReCamDriving: LiDAR-Free Camera-Controlled Novel Trajectory Video Generation](https://arxiv.org/abs/2512.03621)
*Yaokun Li,Shuaixian Wang,Mantang Guo,Jiehui Huang,Taojun Ding,Mu Hu,Kaixuan Wang,Shaojie Shen,Guang Tan*

Main category: cs.CV

TL;DR: ReCamDriving 是一个基于视觉、可控摄像机运动的创新视频生成框架，通过3DGS渲染进行精准的相机轨迹控制，推出了ParaDrive数据集，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统的修复方法难以还原复杂伪影，基于LiDAR的方法又依赖稀疏、残缺的信息。因此，作者希望在视频生成过程中，实现基于视觉的精准摄像机控制，提升生成结果的结构一致性和运动可控性。

Method: 提出了ReCamDriving框架，利用3DGS进行密集的场景几何渲染，将二维图像与三维结构结合，引入两阶段训练策略（第一阶段用相机姿态粗控，第二阶段引入3DGS精控），并设计了基于3DGS的跨轨迹数据筛选方案，从单目视频扩展为多轨迹监督。由此构建出含11万对轨迹视频的ParaDrive数据集。

Result: 实验结果显示，该方法在摄像机可控性和结构保持一致性方面都达到了新的领先水平。

Conclusion: ReCamDriving显著提升了视频生成过程中摄像机轨迹精确可控性与结构一致性，为自动驾驶等场景的视频模拟和数据扩展提供了有力工具。

Abstract: We propose ReCamDriving, a purely vision-based, camera-controlled novel-trajectory video generation framework. While repair-based methods fail to restore complex artifacts and LiDAR-based approaches rely on sparse and incomplete cues, ReCamDriving leverages dense and scene-complete 3DGS renderings for explicit geometric guidance, achieving precise camera-controllable generation. To mitigate overfitting to restoration behaviors when conditioned on 3DGS renderings, ReCamDriving adopts a two-stage training paradigm: the first stage uses camera poses for coarse control, while the second stage incorporates 3DGS renderings for fine-grained viewpoint and geometric guidance. Furthermore, we present a 3DGS-based cross-trajectory data curation strategy to eliminate the train-test gap in camera transformation patterns, enabling scalable multi-trajectory supervision from monocular videos. Based on this strategy, we construct the ParaDrive dataset, containing over 110K parallel-trajectory video pairs. Extensive experiments demonstrate that ReCamDriving achieves state-of-the-art camera controllability and structural consistency.

</details>


### [69] [FeatureLens: A Highly Generalizable and Interpretable Framework for Detecting Adversarial Examples Based on Image Features](https://arxiv.org/abs/2512.03625)
*Zhigang Yang,Yuan Liu,Jiawei Zhang,Puning Zhang,Xinqiang Ma*

Main category: cs.CV

TL;DR: 该论文提出了FeatureLens，一个轻量级且可解释的对抗样本检测框架，在多种攻击下表现出高检测准确率和良好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在图片分类任务中表现优异，但易受对抗攻击影响，现有检测方法复杂且可解释性差，难以推广，亟需一种高效、可解释且适用性强的检测方案。

Method: 设计了FeatureLens框架，包括图像特征提取器（IFE）和浅层分类器（如SVM、MLP、XGBoost），模型参数量极少，仅用51维特征完成对抗样本检测。

Result: FeatureLens在FGSM、PGD、CW和DAmageNet多种攻击上，闭集评估的准确率为97.8%~99.75%，泛化评估准确率为86.17%~99.6%。模型规模小，仅1000到3万个参数。

Conclusion: FeatureLens兼具优秀的检测性能、泛化能力、可解释性和计算效率，为对抗性防御提供了可行的透明解决方案。

Abstract: Although the remarkable performance of deep neural networks (DNNs) in image classification, their vulnerability to adversarial attacks remains a critical challenge. Most existing detection methods rely on complex and poorly interpretable architectures, which compromise interpretability and generalization. To address this, we propose FeatureLens, a lightweight framework that acts as a lens to scrutinize anomalies in image features. Comprising an Image Feature Extractor (IFE) and shallow classifiers (e.g., SVM, MLP, or XGBoost) with model sizes ranging from 1,000 to 30,000 parameters, FeatureLens achieves high detection accuracy ranging from 97.8% to 99.75% in closed-set evaluation and 86.17% to 99.6% in generalization evaluation across FGSM, PGD, CW, and DAmageNet attacks, using only 51 dimensional features. By combining strong detection performance with excellent generalization, interpretability, and computational efficiency, FeatureLens offers a practical pathway toward transparent and effective adversarial defense.

</details>


### [70] [MKSNet: Advanced Small Object Detection in Remote Sensing Imagery with Multi-Kernel and Dual Attention Mechanisms](https://arxiv.org/abs/2512.03640)
*Jiahao Zhang,Xiao Zhao,Guangyu Gao*

Main category: cs.CV

TL;DR: 提出了一种名为MKSNet的新型多核选择神经网络，有效提升了遥感图像中小目标的检测能力。


<details>
  <summary>Details</summary>
Motivation: 遥感图像中物体检测受小目标比例高、背景复杂和空间冗余大等因素影响，现有DCNN在深层特征处理时常丢失小目标关键信息，检测效果有限。

Method: 设计了Multi-Kernel Selection机制，通过可自适应选择不同大小的卷积核捕获更广泛的上下文信息；同时引入空间与通道注意力机制，分别优化特征图的空间和通道表达，突出小目标区域、抑制背景干扰。

Result: 在DOTA-v1.0和HRSC2016遥感图像数据集上，MKSNet在小目标检测上显著优于当前最先进方法。

Conclusion: MKSNet具备出色的多尺度与高分辨率图像复杂性处理能力，验证了其在遥感小目标检测任务中的有效性与创新性。

Abstract: Deep convolutional neural networks (DCNNs) have substantially advanced object detection capabilities, particularly in remote sensing imagery. However, challenges persist, especially in detecting small objects where the high resolution of these images and the small size of target objects often result in a loss of critical information in the deeper layers of conventional CNNs. Additionally, the extensive spatial redundancy and intricate background details typical in remote-sensing images tend to obscure these small targets. To address these challenges, we introduce Multi-Kernel Selection Network (MKSNet), a novel network architecture featuring a novel Multi-Kernel Selection mechanism. The MKS mechanism utilizes large convolutional kernels to effectively capture an extensive range of contextual information. This innovative design allows for adaptive kernel size selection, significantly enhancing the network's ability to dynamically process and emphasize crucial spatial details for small object detection. Furthermore, MKSNet also incorporates a dual attention mechanism, merging spatial and channel attention modules. The spatial attention module adaptively fine-tunes the spatial weights of feature maps, focusing more intensively on relevant regions while mitigating background noise. Simultaneously, the channel attention module optimizes channel information selection, improving feature representation and detection accuracy. Empirical evaluations on the DOTA-v1.0 and HRSC2016 benchmark demonstrate that MKSNet substantially surpasses existing state-of-the-art models in detecting small objects in remote sensing images. These results highlight MKSNet's superior ability to manage the complexities associated with multi-scale and high-resolution image data, confirming its effectiveness and innovation in remote sensing object detection.

</details>


### [71] [Multi-Scale Visual Prompting for Lightweight Small-Image Classification](https://arxiv.org/abs/2512.03663)
*Salim Khazem*

Main category: cs.CV

TL;DR: 提出了一种新的多尺度视觉提示方法（MSVP），可在不显著增加模型参数情况下，显著提升低分辨率小图像数据集上的视觉模型性能。


<details>
  <summary>Details</summary>
Motivation: 目前视觉提示方法主要针对大规模Transformer和高分辨率数据集，而小图像数据集（如MNIST、CIFAR-10等）虽然在研究和教育中广泛应用，但很少有相关提示方法被研究。作者希望弥补这一空白，为低分辨率数据集提出高效的提示方法。

Method: 提出Multi-Scale Visual Prompting (MSVP)模块，通过1x1卷积将全局、中尺度和局部提示融合到输入图像中。该方法与骨干网络无关（backbone-agnostic），只增加极少量参数（小于0.02%），适用于CNN和ViT等多种结构。

Result: 在MNIST、Fashion-MNIST和CIFAR-10上，MSVP在多种模型（如Simple CNN、ResNet-18、小型ViT）上均带来显著性能提升，计算开销几乎可以忽略。此外，作者进行了提示尺度、融合策略和骨干选择的消融实验，并用可视化和Grad-CAM等方式分析了方法效果。

Conclusion: 多尺度视觉提示方法对低分辨率、小图像任务也有效，能够为模型学习带来更好的归纳偏置，提升表现，同时几乎不增加运算和参数开销。

Abstract: Visual prompting has recently emerged as an efficient strategy to adapt vision models using lightweight, learnable parameters injected into the input space. However, prior work mainly targets large Vision Transformers and high-resolution datasets such as ImageNet. In contrast, small-image benchmarks like MNIST, Fashion-MNIST, and CIFAR-10 remain widely used in education, prototyping, and research, yet have received little attention in the context of prompting. In this paper, we introduce \textbf{Multi-Scale Visual Prompting (MSVP)}, a simple and generic module that learns a set of global, mid-scale, and local prompt maps fused with the input image via a lightweight $1 \times 1$ convolution. MSVP is backbone-agnostic, adds less than $0.02\%$ parameters, and significantly improves performance across CNN and Vision Transformer backbones.
  We provide a unified benchmark on MNIST, Fashion-MNIST, and CIFAR-10 using a simple CNN, ResNet-18, and a small Vision Transformer. Our method yields consistent improvements with negligible computational overhead. We further include ablations on prompt scales, fusion strategies, and backbone architectures, along with qualitative analyzes using prompt visualizations and Grad-CAM. Our results demonstrate that multi-scale prompting provides an effective inductive bias even on low-resolution images.

</details>


### [72] [ToG-Bench: Task-Oriented Spatio-Temporal Grounding in Egocentric Videos](https://arxiv.org/abs/2512.03666)
*Qi'ao Xu,Tianwen Qian,Yuqian Fu,Kailing Li,Yang Jiao,Jiacheng Zhang,Xiaoling Wang,Liang He*

Main category: cs.CV

TL;DR: 本文提出了ToG-Bench，这是首个针对第一视角视频的任务导向时空视频定位（STVG）基准，重点是从任务需求出发定位相关对象。


<details>
  <summary>Details</summary>
Motivation: 现有STVG方法主要聚焦于描述性或对象本身的信息，未能充分考虑执行具体任务时对目标对象的推理和定位需求。而具身智能体在实际交互中对任务导向的对象定位能力十分关键，推动该领域发展需要更具挑战性、更贴合实际需求的数据集和评测方法。

Method: 作者提出ToG-Bench数据集，重点有三：1）基于任务目的而非直接描述进行对象定位；2）对象既可以被明确提及，也需要通过上下文隐式推理得出；3）支持一条指令关联多个任务相关对象。数据集从ScanNet中筛选视频，采用基础模型自动标注和人工校正联合方式完成标注。此外，针对多对象和显式-隐式定位，设计了新的评测指标，并对七种主流多模态大模型进行了 benchmark。

Result: 实验表明，当前主流MLLMs在任务导向STVG特别是显式-隐式和多对象定位上表现不足，存在明显性能差距。ToG-Bench揭示了感知与交互融合的困难。

Conclusion: ToG-Bench推进了STVG任务从描述性向任务导向性转变，为具身智能体复杂场景下的感知与决策问题提供了新挑战与研究平台，同时现有方法仍有巨大提升空间。

Abstract: A core capability towards general embodied intelligence lies in localizing task-relevant objects from an egocentric perspective, formulated as Spatio-Temporal Video Grounding (STVG). Despite recent progress, existing STVG studies remain largely confined to object-centric and descriptive instructions, neglecting the task-oriented reasoning that is crucial for embodied agents to accomplish goal-directed interactions. To bridge this gap, we introduce \textbf{ToG-Bench}, the first task-oriented spatio-temporal video grounding benchmark for egocentric videos. ToG-Bench is characterized by three key features: (1) \textbf{Task-oriented Grounding}, which requires identifying and localizing objects based on intended tasks rather than straightforward descriptions; (2) \textbf{Explicit-Implicit Dual Grounding}, where target objects can be either explicitly mentioned or implicitly inferred by contextual reasoning; (3) \textbf{One-to-Many Grounding}, where a single instruction may correspond to multiple objects involved in task execution. Built upon videos sourced from ScanNet, ToG-Bench comprises 100 annotated clips with 2,704 task-oriented grounding instructions, constructed via a semi-automated pipeline that combines foundation model annotation and human refinement. In addition, we introduce a set of task-level evaluation metrics tailored for multi-object and explicit-implicit object grounding, and systematically benchmark seven state-of-the-art MLLMs. Extensive experiments reveal the intrinsic challenges of task-oriented STVG and substantial performance gaps across explicit-implicit and multi-object grounding, highlighting the difficulty of bridging perception and interaction in embodied scenarios. Data and code will be released at: \href{https://github.com/qaxuDev/ToG-Bench}{https://github.com/qaxuDev/ToG-Bench}..

</details>


### [73] [Colon-X: Advancing Intelligent Colonoscopy from Multimodal Understanding to Clinical Reasoning](https://arxiv.org/abs/2512.03667)
*Ge-Peng Ji,Jingyi Liu,Deng-Ping Fan,Nick Barnes*

Main category: cs.CV

TL;DR: 本研究提出了Colon-X计划，旨在推动结肠镜检查的多模态智能发展，构建了大规模数据集，并开发了首个面向结肠镜推理的AI模型，实现了推理能力显著提升。


<details>
  <summary>Details</summary>
Motivation: 结肠镜检查中多模态AI应用尚未成熟，尤其是从多模态理解过渡到临床推理的能力有待提升。现有大模型在鲁棒性和可信度方面表现不足，因此需要更具推理能力和专业性的模型及数据集支持。

Method: 1) 构建了涵盖76类临床发现和18种多模态任务、超110万条VQA的数据集ColonVQA。2) 系统性评估并扰动测试22种多模态大模型的泛化与鲁棒性。3) 设计了多专家辩论注释管线，建立了推理数据集ColonReason。4) 开发了采用任务自适应奖励和梯度稳定优化的推理模型ColonR1，并与现有微调方法进行对比。

Result: 研究发现，现有领先多模态大语言模型的临床输出尚不可靠。新开发的ColonR1模型在数据稀缺条件下获得56.61%的整体准确率，超过传统微调方法25.22%，树立了结肠镜推理新基线。

Conclusion: Colon-X及其数据和模型资源为推动结肠镜多模态AI的研究奠定了基础，显著提升了推理能力，为临床应用提供了鲁棒、可信的新方向。相关资源已全部开源。

Abstract: In this study, we present Colon-X, an open initiative aimed at advancing multimodal intelligence in colonoscopy. We begin by constructing ColonVQA, the most comprehensive multimodal dataset ever built for colonoscopy, featuring over 1.1M+ visual question answering entries across 76 clinical findings and 18 multimodal tasks. Beyond serving as a community-wide data foundation, we further investigate a critical yet underexplored transition in colonoscopy - evolving from multimodal understanding to clinical reasoning: (a) To capture the current landscape of multimodal understanding behaviors, we systematically assess the generalizability of 22 multimodal large language models and examine their reliability under human-induced perturbations. The results reveal that clinical outputs from leading MLLMs remain far from robust and trustworthy. (b) To narrow this gap, we further explore reasoning-centric intelligence tailored for colonoscopy. Specifically, we curate ColonReason, a clinically grounded reasoning dataset annotated through a multi-expert debating pipeline, and develop ColonR1, the first R1-styled model incorporating task-adaptive rewarding and gradient-stable optimization techniques. Under data-scarce conditions, our ColonR1 achieves 56.61% overall accuracy, outperforming supervised fine-tuning by 25.22%, and sets a new reasoning-enabled baseline for multimodal colonoscopy analysis. All data and model resources are publicly available at https://github.com/ai4colonoscopy/Colon-X.

</details>


### [74] [ConvRot: Rotation-Based Plug-and-Play 4-bit Quantization for Diffusion Transformers](https://arxiv.org/abs/2512.03673)
*Feice Huang,Zuliang Han,Xing Zhou,Yihuang Chen,Lifei Zhu,Haoqian Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新的量化方法ConvRot，能够在不降低生成图像质量的前提下显著加快diffusion transformer的推理速度并减少其内存占用。


<details>
  <summary>Details</summary>
Motivation: 随着diffusion transformer模型规模的增大，推理时的内存占用和延迟成倍增加，严重限制了其实际部署。现有的低比特（如4-bit）量化方法，虽然被大模型领域采用，但因存在代价高、对row-wise异常值抑制效果差等问题，难以直接应用于diffusion transformer。

Method: 作者提出了ConvRot，一种基于Hadamard变换的分组旋转量化方法，能够同时抑制行、列方向的异常值，而且将复杂度从二次降低到线性。在此基础上，设计了ConvLinear4bit模块，将旋转、量化、矩阵乘法及反量化四步集成，可即插即用支持W4A4推理，无需重新训练模型。

Result: 在FLUX.1-dev数据集上的实验显示，该方法可以实现2.26倍推理速度提升和4.05倍内存占用降低，同时生成的图像质量基本未受影响。

Conclusion: ConvRot及其衍生的ConvLinear4bit模块为diffusion transformer带来了首次可行的旋转量化W4A4即时推理方案，兼顾了高效推理与高质量图像生成，对实际落地部署意义重大。

Abstract: Diffusion transformers have demonstrated strong capabilities in generating high-quality images. However, as model size increases, the growing memory footprint and inference latency pose significant challenges for practical deployment. Recent studies in large language models (LLMs) show that rotation-based techniques can smooth outliers and enable 4-bit quantization, but these approaches often incur substantial overhead and struggle with row-wise outliers in diffusion transformers. To address these challenges, we propose ConvRot, a group-wise rotation-based quantization method that leverages regular Hadamard transform (RHT) to suppress both row-wise and column-wise outliers while reducing complexity from quadratic to linear. Building on this, we design ConvLinear4bit, a plug-and-play module that integrates rotation, quantization, GEMM, and dequantization, enabling W4A4 inference without retraining and preserving visual quality. Experiments on FLUX.1-dev demonstrate a 2.26$\times$ speedup and 4.05$\times$ memory reduction while maintaining image fidelity. To our knowledge, this is the first application of rotation-based quantization for plug-and-play W4A4 inference in diffusion transformers.

</details>


### [75] [GaussianBlender: Instant Stylization of 3D Gaussians with Disentangled Latent Spaces](https://arxiv.org/abs/2512.03683)
*Melis Ocal,Xiaoyan Xing,Yue Li,Ngo Anh Vien,Sezer Karaoglu,Theo Gevers*

Main category: cs.CV

TL;DR: 本文提出了GaussianBlender，一种基于前馈网络的文本驱动3D风格化方法，实现了高效、几何保真且多视图一致的3D风格编辑，显著优于现有需单独优化的方案。


<details>
  <summary>Details</summary>
Motivation: 现有的文本驱动3D风格化方法大多从2D图像编辑技术演化而来，不仅每个资产需要花费大量时间优化，而且由于2D生成模型的局限，容易导致多视图表现不一致，难以满足大规模快速生产的需要。

Method: 提出GaussianBlender，这是一个前馈式的3D风格化框架。方法通过对3D高斯点群进行空间分组，学习结构化、可解耦的几何与外观潜在空间，并利用潜变量扩散模型在推理时根据文本进行风格编辑，实现与内容解耦的即时风格变更。

Result: GaussianBlender在多项综合评估中表现出色，不仅在多视图一致性、几何保真度和风格化效果等方面都达到高水平，还能实现即刻编辑，且超越需要每个实例都单独优化的现有方法。

Conclusion: GaussianBlender开启了高效、实用化的大规模3D风格化新路径，使3D风格迭代和内容创作更民主化和便捷，具有广阔的应用前景。

Abstract: 3D stylization is central to game development, virtual reality, and digital arts, where the demand for diverse assets calls for scalable methods that support fast, high-fidelity manipulation. Existing text-to-3D stylization methods typically distill from 2D image editors, requiring time-intensive per-asset optimization and exhibiting multi-view inconsistency due to the limitations of current text-to-image models, which makes them impractical for large-scale production. In this paper, we introduce GaussianBlender, a pioneering feed-forward framework for text-driven 3D stylization that performs edits instantly at inference. Our method learns structured, disentangled latent spaces with controlled information sharing for geometry and appearance from spatially-grouped 3D Gaussians. A latent diffusion model then applies text-conditioned edits on these learned representations. Comprehensive evaluations show that GaussianBlender not only delivers instant, high-fidelity, geometry-preserving, multi-view consistent stylization, but also surpasses methods that require per-instance test-time optimization - unlocking practical, democratized 3D stylization at scale.

</details>


### [76] [Active Visual Perception: Opportunities and Challenges](https://arxiv.org/abs/2512.03687)
*Yian Li,Xiaoyu Guo,Hao Zhang,Shuiwang Li,Xiaowei Dai*

Main category: cs.CV

TL;DR: 本文综述了主动视觉感知的机遇与挑战，强调其在面对复杂环境时的优势以及应用前景。


<details>
  <summary>Details</summary>
Motivation: 由于被动视觉系统在复杂环境中的信息获取存在局限性，需要系统具备主动与环境互动、以获得更有价值数据的能力。主动视觉感知因此被提出，旨在提升感知的有效性和灵活性。

Method: 论文探讨了主动视觉感知的原理与实现方式，包括系统如何通过传感器移动、注意力分配、实时决策等途径主动获取信息，融入多模态数据输入，并分析了其典型应用情境。

Result: 主动视觉感知在机器人、自动驾驶、人机交互和监控等领域展现出巨大潜力，但也暴露出如高效实时处理、复杂决策和多模态整合等方面的挑战。

Conclusion: 实现主动视觉感知的广泛应用仍需解决多项技术难题，未来对此领域的研究将进一步推动智能系统的能力提升。

Abstract: Active visual perception refers to the ability of a system to dynamically engage with its environment through sensing and action, allowing it to modify its behavior in response to specific goals or uncertainties. Unlike passive systems that rely solely on visual data, active visual perception systems can direct attention, move sensors, or interact with objects to acquire more informative data. This approach is particularly powerful in complex environments where static sensing methods may not provide sufficient information. Active visual perception plays a critical role in numerous applications, including robotics, autonomous vehicles, human-computer interaction, and surveillance systems. However, despite its significant promise, there are several challenges that need to be addressed, including real-time processing of complex visual data, decision-making in dynamic environments, and integrating multimodal sensory inputs. This paper explores both the opportunities and challenges inherent in active visual perception, providing a comprehensive overview of its potential, current research, and the obstacles that must be overcome for broader adoption.

</details>


### [77] [Structured Uncertainty Similarity Score (SUSS): Learning a Probabilistic, Interpretable, Perceptual Metric Between Images](https://arxiv.org/abs/2512.03701)
*Paula Seidler,Neill D. F. Campbell,Ivor J A Simpson*

Main category: cs.CV

TL;DR: 该论文提出了一种新的感知相似度评分方法SUSS（Structured Uncertainty Similarity Score），能够更好地对齐人类视觉感知，并具有可解释性和稳定的优化表现。


<details>
  <summary>Details</summary>
Motivation: 现有深度感知损失（如LPIPS）虽与人类视觉对齐较好，但特征高度非线性且难以解释；而手工设计的指标（如SSIM）可解释性强，但遗漏了关键感知特性。因此，迫切需要一种既能精确对齐人类感知又具良好可解释性的相似度评价方法。

Method: SUSS将每张图片表示为一组感知成分，每个成分通过结构化的多变量正态分布建模。通过生成式自监督方法训练，使其对人不可察觉的增强赋予高似然。最终得分为各成分对数概率的加权和，权重从人类感知数据集中学习。与基于特征的方法不同，SUSS在像素空间中自动学习图像专属的线性变换，便于透明地分析与采样残差。

Result: SUSS与人类感知判断高度一致，在多种失真类型下表现出很好的感知适应性和校准能力，还能提供局部、可解释的相似性分析。此外，将SUSS用于下游图像任务的感知损失时优化表现稳定，效果具有竞争力。

Conclusion: SUSS有效解决了感知评分方法中可解释性与与人类视觉对齐的矛盾，在保持高精度的同时提供了透明细致的解释，并可用于各种实际视觉任务中。

Abstract: Perceptual similarity scores that align with human vision are critical for both training and evaluating computer vision models. Deep perceptual losses, such as LPIPS, achieve good alignment but rely on complex, highly non-linear discriminative features with unknown invariances, while hand-crafted measures like SSIM are interpretable but miss key perceptual properties.
  We introduce the Structured Uncertainty Similarity Score (SUSS); it models each image through a set of perceptual components, each represented by a structured multivariate Normal distribution. These are trained in a generative, self-supervised manner to assign high likelihood to human-imperceptible augmentations. The final score is a weighted sum of component log-probabilities with weights learned from human perceptual datasets. Unlike feature-based methods, SUSS learns image-specific linear transformations of residuals in pixel space, enabling transparent inspection through decorrelated residuals and sampling.
  SUSS aligns closely with human perceptual judgments, shows strong perceptual calibration across diverse distortion types, and provides localized, interpretable explanations of its similarity assessments. We further demonstrate stable optimization behavior and competitive performance when using SUSS as a perceptual loss for downstream imaging tasks.

</details>


### [78] [DINO-RotateMatch: A Rotation-Aware Deep Framework for Robust Image Matching in Large-Scale 3D Reconstruction](https://arxiv.org/abs/2512.03715)
*Kaichen Zhang,Tianxiang Sheng,Xuanming Shi*

Main category: cs.CV

TL;DR: 本文提出DINO-RotateMatch框架，通过结合全局语义图像配对和旋转感知特征点匹配，有效提升大规模3D重建中的图像匹配准确性。


<details>
  <summary>Details</summary>
Motivation: 大规模3D重建通常依赖海量互联网图像，不同拍摄角度和姿态带来配对难题，现有方法在全局配对和局部匹配上常面临鲁棒性不足。作者旨在提升从无结构网络图片中进行高效准确配对的能力。

Method: 方法包括两部分：一是利用DINO自监督模型进行全局语义相关图片配对，筛选要匹配的图片对；二是对配对图片通过旋转增强，结合ALIKED和Light Glue提取具有方向感知的局部特征点并进行精确匹配。

Result: 在Kaggle Image Matching Challenge 2025中，该方法在平均准确度（mAA）上取得持续提升，获银奖（排名47/943）。

Conclusion: 结合自监督全局特征与旋转增强的局部匹配为大规模3D重建带来更强鲁棒性和可扩展性，方法表现优越，具有较高实用价值。

Abstract: This paper presents DINO-RotateMatch, a deep-learning framework designed to address the chal lenges of image matching in large-scale 3D reconstruction from unstructured Internet images. The
  method integrates a dataset-adaptive image pairing strategy with rotation-aware keypoint extraction and
  matching. DINO is employed to retrieve semantically relevant image pairs in large collections, while
  rotation-based augmentation captures orientation-dependent local features using ALIKED and Light Glue. Experiments on the Kaggle Image Matching Challenge 2025 demonstrate consistent improve ments in mean Average Accuracy (mAA), achieving a Silver Award (47th of 943 teams). The results
  confirm that combining self-supervised global descriptors with rotation-enhanced local matching offers
  a robust and scalable solution for large-scale 3D reconstruction.

</details>


### [79] [Out-of-the-box: Black-box Causal Attacks on Object Detectors](https://arxiv.org/abs/2512.03730)
*Melane Navaratnarajah,David A. Kelly,Hana Chockler*

Main category: cs.CV

TL;DR: 本文提出了 BlackCAtt，一种面向目标检测器的黑盒对抗攻击工具，能通过极少的、具有因果作用的像素生成可解释的、对人眼几乎不可察觉且可复现的攻击。该方法跨架构有效，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗扰动方法多为白盒且依赖于特定架构，而且通常难以解释为何能够成功攻击模型。缺乏机制理解限制了模型防御手段的改进。因此，开发可解释的黑盒攻击手段具有重要意义。

Method: BlackCAtt 利用最小因果像素集合，结合目标检测器输出的边界框，自动生成可导致目标框丢失、修改或新增的对抗扰动图片。该方法完全黑盒，无需模型内部信息，对多种架构均适用，并通过系统对比实验与其它黑盒攻击方法进行性能评估。

Result: 在COCO测试集上，BlackCAtt 在删除、改变和增加检测框三项指标上分别比基线方法好2.7倍、3.86倍和5.75倍，且生成的对抗样本与原始图片极为接近，对人眼几乎不可察觉。

Conclusion: BlackCAtt 展现了因果像素在可解释、微小扰动生成中的有效性，为黑盒下评估与攻防目标检测系统提供了有力工具，有助于提升模型鲁棒性理解及对抗防御方法的研发。

Abstract: Adversarial perturbations are a useful way to expose vulnerabilities in object detectors. Existing perturbation methods are frequently white-box and architecture specific. More importantly, while they are often successful, it is rarely clear why they work. Insights into the mechanism of this success would allow developers to understand and analyze these attacks, as well as fine-tune the model to prevent them. This paper presents BlackCAtt, a black-box algorithm and a tool, which uses minimal, causally sufficient pixel sets to construct explainable, imperceptible, reproducible, architecture-agnostic attacks on object detectors. BlackCAtt combines causal pixels with bounding boxes produced by object detectors to create adversarial attacks that lead to the loss, modification or addition of a bounding box. BlackCAtt works across different object detectors of different sizes and architectures, treating the detector as a black box. We compare the performance of BlackCAtt with other black-box attack methods and show that identification of causal pixels leads to more precisely targeted and less perceptible attacks. On the COCO test dataset, our approach is 2.7 times better than the baseline in removing a detection, 3.86 times better in changing a detection, and 5.75 times better in triggering new, spurious, detections. The attacks generated by BlackCAtt are very close to the original image, and hence imperceptible, demonstrating the power of causal pixels.

</details>


### [80] [Dual-level Modality Debiasing Learning for Unsupervised Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2512.03745)
*Jiaze Li,Yan Lu,Bin Liu,Guojun Yin,Mang Ye*

Main category: cs.CV

TL;DR: 该论文提出了针对无监督可见-红外跨模态行人重识别中“模态偏见”问题的新方法，通过双层去偏策略提升了模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有两阶段的USL-VI-ReID方法容易在单模态训练阶段引入模态特有的信息，这些偏见会传递到后续跨模态学习中，影响身份判别和泛化能力。解决“模态偏见”成为提升跨模态ReID的重要问题。

Method: 提出了Dual-level Modality Debiasing Learning (DMDL)框架，采用模型级和优化级双重去偏。模型级引入因果调整模块（CAI），用因果建模替代似然建模，防止模态诱发的伪关联。优化级采用协同无偏训练（CBT），结合模态特异增强、标签优化和特征对齐，多角度阻断偏见传播。

Result: 在标准数据集上，DMDL实现了模态无关的特征学习，取得了优异的跨模态ReID性能，验证了方法对模型泛化能力的提升。

Conclusion: DMDL有效缓解了传统方法的模态偏见，实现了更鲁棒和泛化的无监督可见-红外行人重识别。

Abstract: Two-stage learning pipeline has achieved promising results in unsupervised visible-infrared person re-identification (USL-VI-ReID). It first performs single-modality learning and then operates cross-modality learning to tackle the modality discrepancy. Although promising, this pipeline inevitably introduces modality bias: modality-specific cues learned in the single-modality training naturally propagate into the following cross-modality learning, impairing identity discrimination and generalization. To address this issue, we propose a Dual-level Modality Debiasing Learning (DMDL) framework that implements debiasing at both the model and optimization levels. At the model level, we propose a Causality-inspired Adjustment Intervention (CAI) module that replaces likelihood-based modeling with causal modeling, preventing modality-induced spurious patterns from being introduced, leading to a low-biased model. At the optimization level, a Collaborative Bias-free Training (CBT) strategy is introduced to interrupt the propagation of modality bias across data, labels, and features by integrating modality-specific augmentation, label refinement, and feature alignment. Extensive experiments on benchmark datasets demonstrate that DMDL could enable modality-invariant feature learning and a more generalized model.

</details>


### [81] [Fully Unsupervised Self-debiasing of Text-to-Image Diffusion Models](https://arxiv.org/abs/2512.03749)
*Korada Sri Vardhana,Shrikrishna Lolla,Soma Biswas*

Main category: cs.CV

TL;DR: 本文提出了一种名为SelfDebias的无监督去偏方法，可在推断时去除扩散模型生成图像中的偏见，无需人工标注或外部分类器，且在多种模型和场景下验证有效。


<details>
  <summary>Details</summary>
Motivation: 当前高分辨率文生图扩散模型在大规模网络数据上训练，由于数据本身带有偏见，模型生成结果也会复现这些刻板印象。传统去偏方法往往需要人工标签或为每个概念单独训练分类器，成本高且难以泛化，因此亟需一种无需监督的新方法。

Method: SelfDebias是一种完全无监督的推理时去偏方法。其核心思路是利用图像编码器的嵌入空间对语义聚类，在生成过程中引导扩散过程，使输出分布与均匀分布的KL散度最小，从而削弱偏见。该方法适用于任何使用UNet结构作为去噪器的扩散生成模型，无需人工参与，自动发现偏见模式。

Result: 实验表明，SelfDebias能够在不同提示词（prompts）和扩散模型架构（包括有条件和无条件模型）下有效泛化，显著降低生成图像中的人口统计学等关键领域偏见，并保持高视觉质量。同时还能处理更抽象的偏见模式。

Conclusion: SelfDebias是一种高效、通用、免监督的扩散模型图像去偏新方案，既提高了生成内容的公平性，又无损图片质量，适合广泛实际应用。

Abstract: Text-to-image (T2I) diffusion models have achieved widespread success due to their ability to generate high-resolution, photorealistic images. These models are trained on large-scale datasets, like LAION-5B, often scraped from the internet. However, since this data contains numerous biases, the models inherently learn and reproduce them, resulting in stereotypical outputs. We introduce SelfDebias, a fully unsupervised test-time debiasing method applicable to any diffusion model that uses a UNet as its noise predictor. SelfDebias identifies semantic clusters in an image encoder's embedding space and uses these clusters to guide the diffusion process during inference, minimizing the KL divergence between the output distribution and the uniform distribution. Unlike supervised approaches, SelfDebias does not require human-annotated datasets or external classifiers trained for each generated concept. Instead, it is designed to automatically identify semantic modes. Extensive experiments show that SelfDebias generalizes across prompts and diffusion model architectures, including both conditional and unconditional models. It not only effectively debiases images along key demographic dimensions while maintaining the visual fidelity of the generated images, but also more abstract concepts for which identifying biases is also challenging.

</details>


### [82] [Research on Brain Tumor Classification Method Based on Improved ResNet34 Network](https://arxiv.org/abs/2512.03751)
*Yufeng Li,Wenchao Zhao,Bo Dang,Weimin Wang*

Main category: cs.CV

TL;DR: 本文提出了一种基于改进ResNet34网络的脑肿瘤图像分类模型，通过多尺度特征提取和注意力机制显著提升了分类准确率，并减少了模型参数。


<details>
  <summary>Details</summary>
Motivation: 手动进行脑肿瘤医学图像分类耗时耗力，且浅层CNN模型准确率不高。为提升分类效率与精度，急需更优的深度学习方法。

Method: 将ResNet34作为骨干网络，加入多尺度输入模块作为首层、用Inception v2模块进行残差下采样，并引入通道注意力机制，为不同特征通道分配不同权重以提取更重要的信息。

Result: 改进模型在五折交叉实验中取得约98.8%的平均分类准确率，比原ResNet34提升了1%，模型参数量仅为原模型的80%。

Conclusion: 改进ResNet34模型不仅提升了脑肿瘤图像分类的准确率，还有效减少了冗余参数，实现了更高效且精确的分类效果。

Abstract: Previously, image interpretation in radiology relied heavily on manual methods. However, manual classification of brain tumor medical images is time-consuming and labor-intensive. Even with shallow convolutional neural network models, the accuracy is not ideal. To improve the efficiency and accuracy of brain tumor image classification, this paper proposes a brain tumor classification model based on an improved ResNet34 network. This model uses the ResNet34 residual network as the backbone network and incorporates multi-scale feature extraction. It uses a multi-scale input module as the first layer of the ResNet34 network and an Inception v2 module as the residual downsampling layer. Furthermore, a channel attention mechanism module assigns different weights to different channels of the image from a channel domain perspective, obtaining more important feature information. The results after a five-fold crossover experiment show that the average classification accuracy of the improved network model is approximately 98.8%, which is not only 1% higher than ResNet34, but also only 80% of the number of parameters of the original model. Therefore, the improved network model not only improves accuracy but also reduces clutter, achieving a classification effect with fewer parameters and higher accuracy.

</details>


### [83] [LSRS: Latent Scale Rejection Sampling for Visual Autoregressive Modeling](https://arxiv.org/abs/2512.03796)
*Hong-Kai Zheng,Piji Li*

Main category: cs.CV

TL;DR: 本文提出了一种新方法——潜在尺度拒绝采样（LSRS），用于提升视觉自回归（VAR）模型的图像生成质量，几乎不增加推理开销。


<details>
  <summary>Details</summary>
Motivation: 现有的VAR方法虽然加速了生成过程，但在每一层级上并行采样会引发结构错误，对图像的整体质量和连贯性造成负面影响。因此需要新方法减少结构性错误，同时维持高效率。

Method: LSRS在每一层级对多组候选token map进行轻量级评分，优选出高质量的token map，并作为下一层解析指导。优先在早期关键层级进行提升，避免结构错误积累。

Result: 在VAR-d30模型上，将推理时间仅增加1%时，FID从1.95降至1.78（数值越低越好）；若推理时间增加15%，FID可降到1.66。

Conclusion: LSRS能以极小的计算代价，显著提升VAR模型的生成质量，是一种实用、高效的测试阶段提质方案。

Abstract: Visual Autoregressive (VAR) modeling approach for image generation proposes autoregressive processing across hierarchical scales, decoding multiple tokens per scale in parallel. This method achieves high-quality generation while accelerating synthesis. However, parallel token sampling within a scale may lead to structural errors, resulting in suboptimal generated images. To mitigate this, we propose Latent Scale Rejection Sampling (LSRS), a method that progressively refines token maps in the latent scale during inference to enhance VAR models. Our method uses a lightweight scoring model to evaluate multiple candidate token maps sampled at each scale, selecting the high-quality map to guide subsequent scale generation. By prioritizing early scales critical for structural coherence, LSRS effectively mitigates autoregressive error accumulation while maintaining computational efficiency. Experiments demonstrate that LSRS significantly improves VAR's generation quality with minimal additional computational overhead. For the VAR-d30 model, LSRS increases the inference time by merely 1% while reducing its FID score from 1.95 to 1.78. When the inference time is increased by 15%, the FID score can be further reduced to 1.66. LSRS offers an efficient test-time scaling solution for enhancing VAR-based generation.

</details>


### [84] [HieroGlyphTranslator: Automatic Recognition and Translation of Egyptian Hieroglyphs to English](https://arxiv.org/abs/2512.03817)
*Ahmed Nasser,Marwan Mohamed,Alaa Sherif,Basmala Mahmoud,Shereen Yehia,Asmaa Saad,Mariam S. El-Rahmany,Ensaf H. Mohamed*

Main category: cs.CV

TL;DR: 本文提出一种将古埃及象形文字影像自动识别并翻译成英文的方法，并在公开数据集上获得了较好结果。


<details>
  <summary>Details</summary>
Motivation: 古埃及时文字形复杂且一字多义，人工翻译非常困难，自动化处理有助于推动历史文献解读与语言保护。

Method: 方法流程包括三阶段：1）采用轮廓检测和Detectron2进行象形文字分割；2）将分割得到的符号映射为Gardiner编码；3）基于卷积神经网络（CNN）模型进行文本翻译。实验用到了Morris Franken和EgyptianTranslation两个数据集。

Result: 提出的方法取得了BLEU 42.2的成绩，优于现有的相关研究结果。

Conclusion: 研究证明了通过先进的深度学习方法能够实现较高精度的埃及象形文字自动识别与翻译，为古文字翻译提供了有效的技术路径。

Abstract: Egyptian hieroglyphs, the ancient Egyptian writing system, are composed entirely of drawings. Translating these glyphs into English poses various challenges, including the fact that a single glyph can have multiple meanings. Deep learning translation applications are evolving rapidly, producing remarkable results that significantly impact our lives. In this research, we propose a method for the automatic recognition and translation of ancient Egyptian hieroglyphs from images to English. This study utilized two datasets for classification and translation: the Morris Franken dataset and the EgyptianTranslation dataset. Our approach is divided into three stages: segmentation (using Contour and Detectron2), mapping symbols to Gardiner codes, and translation (using the CNN model). The model achieved a BLEU score of 42.2, a significant result compared to previous research.

</details>


### [85] [A Robust Camera-based Method for Breath Rate Measurement](https://arxiv.org/abs/2512.03827)
*Alexey Protopopov*

Main category: cs.CV

TL;DR: 本文提出了一种更为鲁棒的新方法，仅需摄像头即可准确测量人的呼吸频率，在受试者活动时仍能保持高精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于视频的呼吸频率测量方法受限于理想环境或精度不足，且难以应对受试者动作造成的干扰，实际应用受限。

Method: 研究提出通过结合多种数学变换技术的无创视频分析法，仅需低成本摄像头即可实现无约束条件下的呼吸速率测量。该方法在14名志愿者、总时长超2.5小时的视频数据上进行了测试，并与参考真实数据进行对比。

Result: 该新方法测量的呼吸频率与真实值的相对偏差低于5%，平均绝对误差仅为0.57次/分钟，优于现有研究结果。

Conclusion: 所提出的方法在受试者可自由活动情况下，具备更强的鲁棒性和准确性，可实现非接触、无行为限制的人体呼吸频率远程监测，应用前景广阔。

Abstract: Proliferation of cheap and accessible cameras makes it possible to measure a subject's breath rate from video footage alone. Recent works on this topic have proposed a variety of approaches for accurately measuring human breath rate, however they are either tested in near-ideal conditions, or produce results that are not sufficiently accurate. The present study proposes a more robust method to measure breath rate in humans with minimal hardware requirements using a combination of mathematical transforms with a relative deviation from the ground truth of less than 5%. The method was tested on videos taken from 14 volunteers with a total duration of over 2 hours 30 minutes. The obtained results were compared to reference data and the average mean absolute error was found to be at 0.57 respirations per minute, which is noticeably better than the results from previous works. The breath rate measurement method proposed in the present article is more resistant to distortions caused by subject movement and thus allows one to remotely measure the subject's breath rate without any significant limitations on the subject's behavior.

</details>


### [86] [Lean Unet: A Compact Model for Image Segmentation](https://arxiv.org/abs/2512.03834)
*Ture Hassler,Ida Åkerholm,Marcus Nordström,Gabriele Balletti,Orcun Goksel*

Main category: cs.CV

TL;DR: Unet变体常用于医学图像分割，但存在参数量大、推理速度慢等问题。本研究提出一种更精简的Unet（LUnet）架构，在不牺牲性能的基础上大幅减少参数量和内存需求。


<details>
  <summary>Details</summary>
Motivation: 现有Unet通常通过下采样提升通道数以保留信息，导致内存开销大和推理延迟高。虽然通道剪枝可压缩Unet但优化耗时且泛化性有限。作者希望找到更高效且通用的改进方法。

Method: 通过分析通道剪枝Unet的结构，发现最终网络结构比剪枝策略本身更重要，据此提出固定通道数、不随分辨率加倍的紧凑LUnet架构，并在多个MRI和CT数据集上与主流剪枝方法与原Unet进行对比评测。

Result: 作者发现最优剪枝方案主要作用于通道数最多的层，仅在这些层随机删减通道即可获得与复杂剪枝策略相当甚至更优的表现。LUnet结构在参数数减少30余倍的情况下性能仍接近原Unet和剪枝Unet，且优于相参数量的标准Unet。

Conclusion: LUnet架构用更少的参数达到了与主流Unet和剪枝Unet相当甚至更优的分割表现，且具有更高的训练、推理效率。结果表明通道结构设计比剪枝策略更为关键，Unet的跨层连接允许减少中间层通道数。

Abstract: Unet and its variations have been standard in semantic image segmentation, especially for computer assisted radiology. Current Unet architectures iteratively downsample spatial resolution while increasing channel dimensions to preserve information content. Such a structure demands a large memory footprint, limiting training batch sizes and increasing inference latency. Channel pruning compresses Unet architecture without accuracy loss, but requires lengthy optimization and may not generalize across tasks and datasets. By investigating Unet pruning, we hypothesize that the final structure is the crucial factor, not the channel selection strategy of pruning. Based on our observations, we propose a lean Unet architecture (LUnet) with a compact, flat hierarchy where channels are not doubled as resolution is halved. We evaluate on a public MRI dataset allowing comparable reporting, as well as on two internal CT datasets. We show that a state-of-the-art pruning solution (STAMP) mainly prunes from the layers with the highest number of channels. Comparatively, simply eliminating a random channel at the pruning-identified layer or at the largest layer achieves similar or better performance. Our proposed LUnet with fixed architectures and over 30 times fewer parameters achieves performance comparable to both conventional Unet counterparts and data-adaptively pruned networks. The proposed lean Unet with constant channel count across layers requires far fewer parameters while achieving performance superior to standard Unet for the same total number of parameters. Skip connections allow Unet bottleneck channels to be largely reduced, unlike standard encoder-decoder architectures requiring increased bottleneck channels for information propagation.

</details>


### [87] [Heatmap Pooling Network for Action Recognition from RGB Videos](https://arxiv.org/abs/2512.03837)
*Mengyuan Liu,Jinfu Liu,Yongkang Jiang,Bin He*

Main category: cs.CV

TL;DR: 本文提出了一种新的人体动作识别网络HP-Net，通过创新的反馈池化模块和多模态融合策略，有效提升了视频动作识别的准确性和鲁棒性，并在多个数据集上实现了领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于RGB视频的人体动作识别方法存在特征冗余、噪声敏感和存储成本高等问题，难以有效利用视频中的有用信息，因此亟需一种能够高效提取信息且鲁棒的新方法。

Method: 提出了一种热图池化网络（HP-Net），通过反馈池化模块从视频中提取简洁、鲁棒且富含信息的人体特征。设计了空间-运动协同学习模块与文本细化调节模块，将池化特征与多模态数据深度融合，从而提升动作识别效果。

Result: 在NTU RGB+D 60、NTU RGB+D 120、Toyota-Smarthome和UAV-Human等多个动作识别数据集上进行了大量实验，HP-Net在准确率和鲁棒性方面均优于现有方法。

Conclusion: HP-Net能显著提升人体动作识别的性能，其提出的特征池化与多模态融合思路对后续相关研究具有较强的借鉴意义。

Abstract: Human action recognition (HAR) in videos has garnered widespread attention due to the rich information in RGB videos. Nevertheless, existing methods for extracting deep features from RGB videos face challenges such as information redundancy, susceptibility to noise and high storage costs. To address these issues and fully harness the useful information in videos, we propose a novel heatmap pooling network (HP-Net) for action recognition from videos, which extracts information-rich, robust and concise pooled features of the human body in videos through a feedback pooling module. The extracted pooled features demonstrate obvious performance advantages over the previously obtained pose data and heatmap features from videos. In addition, we design a spatial-motion co-learning module and a text refinement modulation module to integrate the extracted pooled features with other multimodal data, enabling more robust action recognition. Extensive experiments on several benchmarks namely NTU RGB+D 60, NTU RGB+D 120, Toyota-Smarthome and UAV-Human consistently verify the effectiveness of our HP-Net, which outperforms the existing human action recognition methods. Our code is publicly available at: https://github.com/liujf69/HPNet-Action.

</details>


### [88] [CoDA: From Text-to-Image Diffusion Models to Training-Free Dataset Distillation](https://arxiv.org/abs/2512.03844)
*Letian Zhou,Songhua Liu,Xinchao Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为Core Distribution Alignment（CoDA）的数据集蒸馏方法，能够直接利用现成的文本到图像生成模型，无需在目标数据集上预训练生成模型，也能获得媲美甚至优于以往方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于生成模型的数据集蒸馏方法存在两个核心问题：依赖于在目标数据集上预训练扩散模型，导致高计算成本且背离蒸馏初衷；或尝试使用通用大模型，但因分布不匹配导致效果不佳。为解决这两个弊端，提出有效利用现成生成模型又能保证与目标数据集分布对齐的方法。

Method: CoDA框架首先利用密度估计算法发现目标数据集的“核心分布”，然后引导生成过程，让生成数据与该核心分布对齐，从而缩小通用生成先验与目标数据集之间的分布差距。

Result: 实验显示，CoDA无需在目标数据集上专项训练生成模型，在ImageNet-1K等主流基准上，与依赖目标集训练的传统方法相比表现持平甚至更优，50幅图片每类别设定下刷新SOTA，达到60.4%准确率。

Conclusion: CoDA有效提升了数据集蒸馏的实用性和可迁移性，仅用通用生成模型便可获得高代表性小样本数据，对后续应用和研究具重要意义。

Abstract: Prevailing Dataset Distillation (DD) methods leveraging generative models confront two fundamental limitations. First, despite pioneering the use of diffusion models in DD and delivering impressive performance, the vast majority of approaches paradoxically require a diffusion model pre-trained on the full target dataset, undermining the very purpose of DD and incurring prohibitive training costs. Second, although some methods turn to general text-to-image models without relying on such target-specific training, they suffer from a significant distributional mismatch, as the web-scale priors encapsulated in these foundation models fail to faithfully capture the target-specific semantics, leading to suboptimal performance. To tackle these challenges, we propose Core Distribution Alignment (CoDA), a framework that enables effective DD using only an off-the-shelf text-to-image model. Our key idea is to first identify the "intrinsic core distribution" of the target dataset using a robust density-based discovery mechanism. We then steer the generative process to align the generated samples with this core distribution. By doing so, CoDA effectively bridges the gap between general-purpose generative priors and target semantics, yielding highly representative distilled datasets. Extensive experiments suggest that, without relying on a generative model specifically trained on the target dataset, CoDA achieves performance on par with or even superior to previous methods with such reliance across all benchmarks, including ImageNet-1K and its subsets. Notably, it establishes a new state-of-the-art accuracy of 60.4% at the 50-images-per-class (IPC) setup on ImageNet-1K. Our code is available on the project webpage: https://github.com/zzzlt422/CoDA

</details>


### [89] [PULSE: A Unified Multi-Task Architecture for Cardiac Segmentation, Diagnosis, and Few-Shot Cross-Modality Clinical Adaptation](https://arxiv.org/abs/2512.03848)
*Hania Ghouse,Maryam Alsharqi,Farhad R. Nezami,Muzammil Behzad*

Main category: cs.CV

TL;DR: 本文提出了PULSE框架，实现了心脏图像的分割、疾病分类和临床报告生成多任务统一处理，并具备很强的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 心脏医学影像分析任务分散，不同的任务通常由各自网络完成，且难以泛化到新的模态或数据集。作者希望构建一个统一、可扩展并能处理多重任务的心脏图像分析基础模型。

Method: 提出PULSE框架：基于多模态视觉-语言自监督表示，通过多重监督策略优化（包括区域重叠、像素级分类、边界IoU优化）。采用多尺度token重建解码器用于解剖分割，利用共享全局表示进行疾病分类和文本生成，使模型能在同一结构内实现从像素级分析到临床推理的多任务处理。

Result: PULSE可学习任务无关的心脏先验，对不同数据集表现出良好泛化能力，且能以极少的监督快速适配新影像模态。

Conclusion: PULSE框架推动了心脏AI分析向可扩展的基础大模型方向发展，突破了以往分散、专用管线的限制，实现了多任务一体化和跨模态泛化。

Abstract: Cardiac image analysis remains fragmented across tasks: anatomical segmentation, disease classification, and grounded clinical report generation are typically handled by separate networks trained under different data regimes. No existing framework unifies these objectives within a single architecture while retaining generalization across imaging modalities and datasets. We introduce PULSE, a multi-task vision-language framework built on self-supervised representations and optimized through a composite supervision strategy that balances region overlap learning, pixel wise classification fidelity, and boundary aware IoU refinement. A multi-scale token reconstruction decoder enables anatomical segmentation, while shared global representations support disease classification and clinically grounded text output allowing the model to transition from pixels to structures and finally clinical reasoning within one architecture. Unlike prior task-specific pipelines, PULSE learns task-invariant cardiac priors, generalizes robustly across datasets, and can be adapted to new imaging modalities with minimal supervision. This moves the field closer to a scalable, foundation style cardiac analysis framework.

</details>


### [90] [Traffic Image Restoration under Adverse Weather via Frequency-Aware Mamba](https://arxiv.org/abs/2512.03852)
*Liwen Pan,Longguang Wang,Guangwei Gao,Jun Wang,Jun Shi,Juncheng Li*

Main category: cs.CV

TL;DR: 本文提出了一种新的图像恢复方法FAMamba，通过结合频域信息和序列建模，实现了在恶劣天气下交通图像的高效修复效果。


<details>
  <summary>Details</summary>
Motivation: 在智能交通系统中，恶劣天气下的图像恢复是关键难题。现有方法大多侧重于空间域建模，忽视了频域先验信息的利用。而新兴的Mamba架构具备优秀的长距离依赖建模能力，但其在频域特征提取方面尚未被探索。

Method: 提出了FAMamba框架，主要分为两部分：1）双分支特征提取模块（DFEB）通过双向2D频自适应扫描加强局部与全局的交互，可根据子带纹理分布动态调整遍历路径；2）先验引导模块（PGB）利用小波基的高频残差学习细化纹理细节。同时，设计了适用于Mamba架构的自适应频率扫描机制（AFSM），实现对不同子图中的频域信息扫描，充分利用子图结构中的纹理特征。

Result: 大量实验表明，FAMamba在图像修复任务中兼具高效性和有效性，优于现有方法。

Conclusion: 通过引入频域先验与序列建模相结合的方式，FAMamba框架有效改善了恶劣天气下交通图像的恢复质量，在细节保留和整体表现上具有显著提升。

Abstract: Traffic image restoration under adverse weather conditions remains a critical challenge for intelligent transportation systems. Existing methods primarily focus on spatial-domain modeling but neglect frequency-domain priors. Although the emerging Mamba architecture excels at long-range dependency modeling through patch-wise correlation analysis, its potential for frequency-domain feature extraction remains unexplored. To address this, we propose Frequency-Aware Mamba (FAMamba), a novel framework that integrates frequency guidance with sequence modeling for efficient image restoration. Our architecture consists of two key components: (1) a Dual-Branch Feature Extraction Block (DFEB) that enhances local-global interaction via bidirectional 2D frequency-adaptive scanning, dynamically adjusting traversal paths based on sub-band texture distributions; and (2) a Prior-Guided Block (PGB) that refines texture details through wavelet-based high-frequency residual learning, enabling high-quality image reconstruction with precise details. Meanwhile, we design a novel Adaptive Frequency Scanning Mechanism (AFSM) for the Mamba architecture, which enables the Mamba to achieve frequency-domain scanning across distinct subgraphs, thereby fully leveraging the texture distribution characteristics inherent in subgraph structures. Extensive experiments demonstrate the efficiency and effectiveness of FAMamba.

</details>


### [91] [Prostate biopsy whole slide image dataset from an underrepresented Middle Eastern population](https://arxiv.org/abs/2512.03854)
*Peshawa J. Muhammad Ali,Navin Vincent,Saman S. Abdulla,Han N. Mohammed Fadhl,Anders Blilie,Kelvin Szolnoky,Julia Anna Mielcarz,Xiaoyi Ji,Kimmo Kartasalo,Abdulbasit K. Al-Talabani,Nita Mulliqi*

Main category: cs.CV

TL;DR: 本论文发布了首个来源于中东地区（伊拉克埃尔比勒）的公开前列腺针吸活检全切片数字病理图像数据集，共包含339张切片，旨在支持更具全球代表性的AI病理模型研究。


<details>
  <summary>Details</summary>
Motivation: 目前公开的数字病理数据集数量有限，并主要聚焦于西方人群，导致相关AI模型在少数数字化程度较低地区（如中东）的泛化能力未知，因此需要发布新的多样性数据集。

Method: 收集了185名患者的339张前列腺活检全切片图像，分别用Leica、Hamamatsu和Grundium三台扫描仪获取；三位病理学家独立标注Gleason评分和ISUP分级；所有切片去除身份信息后原格式发布。

Result: 建立并开放了一个包含详细专家分级、多设备扫描数据的前列腺活检切片数据集，为AI模型的分级一致性、色彩归一化及跨设备鲁棒性等多方面评测提供了资源。

Conclusion: 该数据集弥补了现有公开病理影像数据在地理和种群多样性方面的不足，将提升AI病理模型的适用性和可靠性。

Abstract: Artificial intelligence (AI) is increasingly used in digital pathology. Publicly available histopathology datasets remain scarce, and those that do exist predominantly represent Western populations. Consequently, the generalizability of AI models to populations from less digitized regions, such as the Middle East, is largely unknown. This motivates the public release of our dataset to support the development and validation of pathology AI models across globally diverse populations. We present 339 whole-slide images of prostate core needle biopsies from a consecutive series of 185 patients collected in Erbil, Iraq. The slides are associated with Gleason scores and International Society of Urological Pathology grades assigned independently by three pathologists. Scanning was performed using two high-throughput scanners (Leica and Hamamatsu) and one compact scanner (Grundium). All slides were de-identified and are provided in their native formats without further conversion. The dataset enables grading concordance analyses, color normalization, and cross-scanner robustness evaluations. Data will be deposited in the Bioimage Archive (BIA) under accession code: to be announced (TBA), and released under a CC BY 4.0 license.

</details>


### [92] [Diminishing Returns in Self-Supervised Learning](https://arxiv.org/abs/2512.03862)
*Oli Bridge,Huey Sun,Botond Branyicskai-Nagy,Charles D'Ornano,Shomit Basu*

Main category: cs.CV

TL;DR: 本文分析了在只有500万参数的小型视觉Transformer（ViT）上，不同的预训练、中间微调和下游训练数据/目标组合对性能的影响。预训练和微调虽有助益，但其收益递减，且中间微调可能反而损害最终效果。


<details>
  <summary>Details</summary>
Motivation: 当前视觉Transformer通常参数量大、对训练数据需求高，难以应用到资源受限的场景。作者希望探索在参数量较小的ViT下，数据和训练目标选择带来的实际收益。

Method: 选用约500万参数的小型ViT，设计不同预训练、中间微调和下游任务组合，通过实验对比分析每个环节的具体贡献与影响。

Result: 实验结果表明，预训练和下游微调对模型始终有积极作用，但其收益随增加而递减。中间微调若与下游任务不匹配，易导致性能下降。

Conclusion: 小型ViT最需要的是有针对性的预训练和精心挑选的数据，堆叠过多无关的中间任务既浪费计算资源、也可能带来负面影响。

Abstract: While transformer-based architectures have taken computer vision and NLP by storm, they often require a vast amount of parameters and training data to attain strong performance. In this work, we experiment with three distinct pre-training, intermediate fine-tuning, and downstream datasets and training objectives to explore their marginal benefits on a small 5M-parameter vision transformer. We find that while pre-training and fine-tuning always help our model but have diminishing returns, intermediate fine-tuning can actually show harmful impact on downstream performance, potentially due to dissimilarity in task mechanics. Taken together, our results suggest that small-scale ViTs benefit most from targeted pre-training and careful data selection, while indiscriminate stacking of intermediate tasks can waste compute and even degrade performance.

</details>


### [93] [An Automated Framework for Large-Scale Graph-Based Cerebrovascular Analysis](https://arxiv.org/abs/2512.03869)
*Daniele Falcetta,Liane S. Canas,Lorenzo Suppa,Matteo Pentassuglia,Jon Cleary,Marc Modat,Sébastien Ourselin,Maria A. Zuluaga*

Main category: cs.CV

TL;DR: 本文提出了CaravelMetrics，一个可自动进行脑血管分析的计算框架，通过基于骨架提取的图结构建模血管形态，能够高效量化脑血管的多尺度特征，并分析其与年龄、性别及教育水平的关系。


<details>
  <summary>Details</summary>
Motivation: 目前脑血管形态学定量分析的自动化程度有限，缺乏可扩展、全面的工具来支撑大规模人群队列或纵向脑健康研究。现有方法难以综合脑血管的复杂结构特点。

Method: 框架集成了基于数字图谱的脑区分割、中心线提取与血管图结构构建，并能自动提取十五种形态学、拓扑学、分形及几何特征。这些特征既可全脑分析，也可按动脉分区进行区域性分析。方法在570例3D TOF-MRA影像上进行了验证。

Result: CaravelMetrics能够生成高度重现的血管图谱，揭示了年龄、性别及教育水平与脑血管复杂度的关联，符合文献既往发现。

Conclusion: CaravelMetrics为大规模、全自动的脑血管特征提取和定量分析提供了有效工具，可用于建立脑血管健康及衰老的基线模型，促进群体层面的脑血管研究。

Abstract: We present CaravelMetrics, a computational framework for automated cerebrovascular analysis that models vessel morphology through skeletonization-derived graph representations. The framework integrates atlas-based regional parcellation, centerline extraction, and graph construction to compute fifteen morphometric, topological, fractal, and geometric features. The features can be estimated globally from the complete vascular network or regionally within arterial territories, enabling multiscale characterization of cerebrovascular organization. Applied to 570 3D TOF-MRA scans from the IXI dataset (ages 20-86), CaravelMetrics yields reproducible vessel graphs capturing age- and sex-related variations and education-associated increases in vascular complexity, consistent with findings reported in the literature. The framework provides a scalable and fully automated approach for quantitative cerebrovascular feature extraction, supporting normative modeling and population-level studies of vascular health and aging.

</details>


### [94] [Dual Cross-Attention Siamese Transformer for Rectal Tumor Regrowth Assessment in Watch-and-Wait Endoscopy](https://arxiv.org/abs/2512.03883)
*Jorge Tapias Gomez,Despoina Kanata,Aneesh Rangnekar,Christina Lee,Julio Garcia-Aguilar,Joshua Jesse Smith,Harini Veeraraghavan*

Main category: cs.CV

TL;DR: 本论文提出了一种基于Siamese Swin Transformer与双重交叉注意力机制（SSDCA）的深度学习方法，结合纵向内镜图像，实现直肠癌患者临床完全缓解与局部复发的自动区分，并在性能与鲁棒性上优于对比方法。


<details>
  <summary>Details</summary>
Motivation: 当前“观察等待”策略在直肠癌临床完全缓解患者中的应用逐渐增多，但缺乏准确、自动的方法，能基于纵向内镜影像及时识别局部复发，对保障患者疗效和防止远处转移至关重要。

Method: 作者开发了SSDCA模型，采用预训练Swin Transformer提取不同时间点图像的领域无关特征，并通过创新的双重交叉注意力机制，无需进行空间对齐，突出不同阶段扫描的显著特征，通过配对训练识别cCR与LR。模型使用135例患者数据训练，并在62例独立患者上测试，与其他Swin Transformer基线模型进行了对比。

Result: SSDCA在独立测试集上取得了最高的均衡准确率（81.76%±0.04）、灵敏度（90.07%±0.08）和特异性（72.86%±0.05）。其表现不受血液、粪便、毛细血管扩张和图像质量等伪影影响。在特征可分性分析中，SSDCA达到了最优的聚类间分离和最小的聚类内离散度。

Conclusion: SSDCA是一种适合于临床纵向随访影像的高准确性与高鲁棒性的自动化模型，可有效早期识别直肠癌局部复发，有助于推动“观察等待”策略安全落地。

Abstract: Increasing evidence supports watch-and-wait (WW) surveillance for patients with rectal cancer who show clinical complete response (cCR) at restaging following total neoadjuvant treatment (TNT). However, objectively accurate methods to early detect local regrowth (LR) from follow-up endoscopy images during WW are essential to manage care and prevent distant metastases. Hence, we developed a Siamese Swin Transformer with Dual Cross-Attention (SSDCA) to combine longitudinal endoscopic images at restaging and follow-up and distinguish cCR from LR. SSDCA leverages pretrained Swin transformers to extract domain agnostic features and enhance robustness to imaging variations. Dual cross attention is implemented to emphasize features from the two scans without requiring any spatial alignment of images to predict response. SSDCA as well as Swin-based baselines were trained using image pairs from 135 patients and evaluated on a held-out set of image pairs from 62 patients. SSDCA produced the best balanced accuracy (81.76\% $\pm$ 0.04), sensitivity (90.07\% $\pm$ 0.08), and specificity (72.86\% $\pm$ 0.05). Robustness analysis showed stable performance irrespective of artifacts including blood, stool, telangiectasia, and poor image quality. UMAP clustering of extracted features showed maximal inter-cluster separation (1.45 $\pm$ 0.18) and minimal intra-cluster dispersion (1.07 $\pm$ 0.19) with SSDCA, confirming discriminative representation learning.

</details>


### [95] [Zero-Shot Video Translation and Editing with Frame Spatial-Temporal Correspondence](https://arxiv.org/abs/2512.03905)
*Shuai Yang,Junxin Lin,Yifan Zhou,Ziwei Liu,Chen Change Loy*

Main category: cs.CV

TL;DR: 本文提出FRESCO方法，通过结合帧内和帧间一致性约束，在零样本场景下提升图像扩散模型在视频生成与编辑任务中的时空一致性效果。


<details>
  <summary>Details</summary>
Motivation: 现有针对视频的零样本扩散模型多关注帧间关联性，但往往采用的软约束不足，导致生成视频存在时序不一致等问题。该论文旨在提升生成视频的时空一致性和视觉连贯性。

Method: 作者提出FRESCO方法，将帧内一致性与帧间一致性策略结合，对空间和时间维度施加更强约束，并在注意力机制外进一步显式优化特征，以保证语义相似内容在不同帧间的一致转换。

Result: FRESCO在零样本的视频翻译与文本引导视频编辑两大任务上进行了实验，生成的视频在质量和时空一致性方面显著优于现有同类方法。

Conclusion: FRESCO显著提升了基于扩散模型的零样本视频生成和编辑的时空一致性与质量，推动了该领域方法的进步。

Abstract: The remarkable success in text-to-image diffusion models has motivated extensive investigation of their potential for video applications. Zero-shot techniques aim to adapt image diffusion models for videos without requiring further model training. Recent methods largely emphasize integrating inter-frame correspondence into attention mechanisms. However, the soft constraint applied to identify the valid features to attend is insufficient, which could lead to temporal inconsistency. In this paper, we present FRESCO, which integrates intra-frame correspondence with inter-frame correspondence to formulate a more robust spatial-temporal constraint. This enhancement ensures a consistent transformation of semantically similar content between frames. Our method goes beyond attention guidance to explicitly optimize features, achieving high spatial-temporal consistency with the input video, significantly enhancing the visual coherence of manipulated videos. We verify FRESCO adaptations on two zero-shot tasks of video-to-video translation and text-guided video editing. Comprehensive experiments demonstrate the effectiveness of our framework in generating high-quality, coherent videos, highlighting a significant advance over current zero-shot methods.

</details>


### [96] [UniMo: Unifying 2D Video and 3D Human Motion with an Autoregressive Framework](https://arxiv.org/abs/2512.03918)
*Youxin Pang,Yong Zhang,Ruizhi Shao,Xiang Deng,Feng Gao,Xu Xiaoming,Xiaoming Wei,Yebin Liu*

Main category: cs.CV

TL;DR: 本论文提出了一种名为UniMo的新型自回归模型，实现了2D人体视频和3D人体动作的统一建模，可同时生成和理解两种模态。


<details>
  <summary>Details</summary>
Motivation: 当前方法大多只在已知一种模态条件下生成另一种，或与文本、音频等模态配合，尚未有方法能将2D视频和3D动作统一优化和生成。两者结构和分布差异大，联合建模具有难度。因此，亟需创新模型以统一处理和利用两种模态信息。

Method: 受大语言模型跨模态能力启发，作者设计了将视频和3D动作共同建模为一串统一的token，通过独立的嵌入层缩小分布差异。同时，提出序列建模策略，将两种不同任务整合统一框架。为保留3D空间信息，创新性地设计了3D动作tokenizer并采用时序扩展策略，利用单一VQ-VAE量化动作token，通过多专家解码器重建形体、位移、朝向和姿态。

Result: 实验结果表明，该方法不仅能同时生成对应视频和3D动作，还能做到高精度的动作捕捉。

Conclusion: 本研究展示了大模型统一多模态数据的潜力，为未来人、物、场景多模态联合建模和可控生成提供了新路径。

Abstract: We propose UniMo, an innovative autoregressive model for joint modeling of 2D human videos and 3D human motions within a unified framework, enabling simultaneous generation and understanding of these two modalities for the first time. Current methods predominantly focus on generating one modality given another as the condition or integrating either of them with other modalities such as text and audio. Unifying 2D videos and 3D motions for simultaneous optimization and generation remains largely unexplored, presenting significant challenges due to their substantial structural and distributional differences. Inspired by the LLM's ability to unify different modalities, our method models videos and 3D motions as a unified tokens sequence, utilizing separate embedding layers to mitigate distribution gaps. Additionally, we devise a sequence modeling strategy that integrates two distinct tasks within a single framework, proving the effectiveness of unified modeling. Moreover, to efficiently align with visual tokens and preserve 3D spatial information, we design a novel 3D motion tokenizer with a temporal expansion strategy, using a single VQ-VAE to produce quantized motion tokens. It features multiple expert decoders that handle body shapes, translation, global orientation, and body poses for reliable 3D motion reconstruction. Extensive experiments demonstrate that our method simultaneously generates corresponding videos and motions while performing accurate motion capture. This work taps into the capacity of LLMs to fuse diverse data types, paving the way for integrating human-centric information into existing models and potentially enabling multimodal, controllable joint modeling of humans, objects, and scenes.

</details>


### [97] [Beyond the Ground Truth: Enhanced Supervision for Image Restoration](https://arxiv.org/abs/2512.03932)
*Donghun Ryou,Inju Ha,Sanghyeok Chu,Bohyung Han*

Main category: cs.CV

TL;DR: 论文提出了一种通过自适应频率掩码增强Ground Truth的图像修复框架，提升实际场景下的图像修复质量，并通过大量实验和用户研究验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的图像修复方法受限于数据集中的Ground Truth图像质量，而高质量真实世界Ground Truth的获取存在实际困难，导致模型性能难以突破。

Method: 作者提出了使用条件频率掩码生成器学习自适应频率掩码，将原始Ground Truth与其超分辨变体的频率成分最优融合，生成感知增强的Ground Truth图像。随后，这些增强Label用于训练能无缝嵌入现有修复方案的轻量级输出优化网络。

Result: 该方法可增强图像感知细节，防止伪影产生，实验结果和用户研究均显示，经过增强监督和输出优化后，修复图像的质量有显著提升。

Conclusion: 利用频域增强和输出优化网络能有效提升现有图像修复模型在真实场景下的表现，且方法通用、可集成，实用性强。

Abstract: Deep learning-based image restoration has achieved significant success. However, when addressing real-world degradations, model performance is limited by the quality of ground-truth images in datasets due to practical constraints in data acquisition. To address this limitation, we propose a novel framework that enhances existing ground truth images to provide higher-quality supervision for real-world restoration. Our framework generates perceptually enhanced ground truth images using super-resolution by incorporating adaptive frequency masks, which are learned by a conditional frequency mask generator. These masks guide the optimal fusion of frequency components from the original ground truth and its super-resolved variants, yielding enhanced ground truth images. This frequency-domain mixup preserves the semantic consistency of the original content while selectively enriching perceptual details, preventing hallucinated artifacts that could compromise fidelity. The enhanced ground truth images are used to train a lightweight output refinement network that can be seamlessly integrated with existing restoration models. Extensive experiments demonstrate that our approach consistently improves the quality of restored images. We further validate the effectiveness of both supervision enhancement and output refinement through user studies. Code is available at https://github.com/dhryougit/Beyond-the-Ground-Truth.

</details>


### [98] [TempR1: Improving Temporal Understanding of MLLMs via Temporal-Aware Multi-Task Reinforcement Learning](https://arxiv.org/abs/2512.03963)
*Tao Wu,Li Yang,Gen Zhan,Yiting Liao,Junlin Li,Deliang Fu,Li Zhang,Limin Wang*

Main category: cs.CV

TL;DR: 本文提出了TempR1，一种提升多模态大模型（MLLMs）时序理解能力的多任务强化学习框架，有效提升了长视频的时序分析任务表现，并在多个基准上取得了最优结果。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大模型在长视频分析任务中的应用需求增长，如时序定位、动作检测和时序问答等，现有强化学习方法受限于任务类型和数据集，难以全面提升模型的时序泛化能力，因此亟需一个更通用、更有效的框架。

Method: 作者提出TempR1框架，基于多任务数据集并结合Group Relative Policy Optimization（GRPO）算法，对不同类型的时序任务进行分类，并为不同类型任务量身定制了时序定位奖励函数，从而在多种时序模式下提升模型能力。

Result: 通过在多个主流数据集和基准任务上的大量实验，TempR1在多项任务上取得了最优性能。同时，通过联合优化辅助任务，模型泛化能力和单任务效果明显提升。

Conclusion: TempR1为MLLM时序推理提供了一个可扩展且系统化的解决方案，显著提升了模型对不同复杂时序结构的理解能力，推动了多模态视频理解的发展。

Abstract: Enhancing the temporal understanding of Multimodal Large Language Models (MLLMs) is essential for advancing long-form video analysis, enabling tasks such as temporal localization, action detection, and time-sensitive question answering. While reinforcement learning (RL) has recently been explored for improving temporal reasoning, existing approaches are often confined to limited task types and data, restricting their generalization across diverse temporal understanding scenarios. To address this challenge, we present TempR1, a temporal-aware multi-task reinforcement learning framework that systematically strengthens MLLMs' temporal comprehension. We curate a multi-task corpus that exposes the model to diverse temporal structures and semantics, and build upon the Group Relative Policy Optimization (GRPO) algorithm to achieve stable and effective cross-task optimization. Specifically, we categorize temporal tasks into three correspondence types between predicted intervals and ground-truth instances, and design tailored localization rewards for each, enabling TempR1 to capture fine-grained temporal dependencies and adapt to different temporal patterns. Extensive experiments demonstrate that TempR1 attains state-of-the-art performance across multiple benchmarks. Moreover, its joint optimization over complementary tasks yields a strong synergistic effect, enhancing both generalization and single-task performance, establishing a scalable and principled paradigm for temporal reasoning in MLLMs.

</details>


### [99] [Training for Identity, Inference for Controllability: A Unified Approach to Tuning-Free Face Personalization](https://arxiv.org/abs/2512.03964)
*Lianyu Pang,Ji Zhou,Qiping Wang,Baoquan Zhao,Zhenguo Yang,Qing Li,Xudong Mao*

Main category: cs.CV

TL;DR: 本文提出了一种名为UniID的统一无微调（tuning-free）人脸个性化方法，结合了文本嵌入和适配器两大主流范式，实现了高保真度的人脸定制和灵活的文本控制。


<details>
  <summary>Details</summary>
Motivation: 现有无微调人脸个性化方法分为两类：将面部特征映射到文本嵌入空间的方法，以及通过辅助cross-attention层注入特征的适配器方法。尽管各有优势，但很难同时兼顾身份保持的高保真度和文本控制的灵活性。

Method: 提出UniID框架，将两大主流方法融合，通过训练阶段专注于身份特征的学习策略，以及推理阶段的归一化重标定机制，实现身份特征的有效整合和原始扩散模型文本控制能力的恢复。

Result: 通过与六种最新方法的对比实验，UniID在身份保持和文本控制能力上均取得了更优异的表现。

Conclusion: UniID设计合理，实现了身份保真和文本控制的兼得，为无微调人脸个性化任务提供了新的解决思路。源码即将开源。

Abstract: Tuning-free face personalization methods have developed along two distinct paradigms: text embedding approaches that map facial features into the text embedding space, and adapter-based methods that inject features through auxiliary cross-attention layers. While both paradigms have shown promise, existing methods struggle to simultaneously achieve high identity fidelity and flexible text controllability. We introduce UniID, a unified tuning-free framework that synergistically integrates both paradigms. Our key insight is that when merging these approaches, they should mutually reinforce only identity-relevant information while preserving the original diffusion prior for non-identity attributes. We realize this through a principled training-inference strategy: during training, we employ an identity-focused learning scheme that guides both branches to capture identity features exclusively; at inference, we introduce a normalized rescaling mechanism that recovers the text controllability of the base diffusion model while enabling complementary identity signals to enhance each other. This principled design enables UniID to achieve high-fidelity face personalization with flexible text controllability. Extensive experiments against six state-of-the-art methods demonstrate that UniID achieves superior performance in both identity preservation and text controllability. Code will be available at https://github.com/lyuPang/UniID

</details>


### [100] [BlurDM: A Blur Diffusion Model for Image Deblurring](https://arxiv.org/abs/2512.03979)
*Jin-Ting He,Fu-Jen Tsai,Yan-Tsung Peng,Min-Hung Chen,Chia-Wen Lin,Yen-Yu Lin*

Main category: cs.CV

TL;DR: 提出了一种新型的去模糊扩散模型（BlurDM），该方法将模糊生成过程集成进扩散模型中，实现高效动态场景去模糊。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在图像去模糊任务中没有充分利用模糊生成的内在机制，导致模型潜力未完全发挥。

Method: BlurDM采用双扩散正向过程，将噪声与模糊共同扩散到清晰图像上，逆过程则同时执行去噪和去模糊操作，并通过在潜空间中的生成策略，实现灵活的先验引入，无缝集成到现有网络。

Result: 在四个基准数据集上，BlurDM显著并持续提升了主流去模糊方法的性能。

Conclusion: BlurDM通过建模模糊与扩散过程，提出了更加本质且通用的去模糊方案，推动了动态场景去模糊方法的进步。

Abstract: Diffusion models show promise for dynamic scene deblurring; however, existing studies often fail to leverage the intrinsic nature of the blurring process within diffusion models, limiting their full potential. To address it, we present a Blur Diffusion Model (BlurDM), which seamlessly integrates the blur formation process into diffusion for image deblurring. Observing that motion blur stems from continuous exposure, BlurDM implicitly models the blur formation process through a dual-diffusion forward scheme, diffusing both noise and blur onto a sharp image. During the reverse generation process, we derive a dual denoising and deblurring formulation, enabling BlurDM to recover the sharp image by simultaneously denoising and deblurring, given pure Gaussian noise conditioned on the blurred image as input. Additionally, to efficiently integrate BlurDM into deblurring networks, we perform BlurDM in the latent space, forming a flexible prior generation network for deblurring. Extensive experiments demonstrate that BlurDM significantly and consistently enhances existing deblurring methods on four benchmark datasets. The source code is available at https://github.com/Jin-Ting-He/BlurDM.

</details>


### [101] [DirectDrag: High-Fidelity, Mask-Free, Prompt-Free Drag-based Image Editing via Readout-Guided Feature Alignment](https://arxiv.org/abs/2512.03981)
*Sheng-Hao Liao,Shang-Fu Chen,Tai-Ming Huang,Wen-Huang Cheng,Kai-Lung Hua*

Main category: cs.CV

TL;DR: 该论文提出了一种无需手动画框和文本提示的新型图像编辑方法DirectDrag，提升编辑便捷性和图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有拖拽式图像编辑方法高度依赖人工提供的掩码和文本提示，这影响了编辑效率和容易产生伪影或空间控制不精确。开发一种无需这些手动辅助即可获得高精度编辑的新方法亟需解决这一困境。

Method: DirectDrag框架有两大创新：1）自动软掩码生成模块，根据用户的点位移动自动判断并限定可编辑区域，保证在变形时背景语境的完整性；2）读出引导特征对齐机制，利用扩散模型中间特征，提升结构稳定性，实现移动点位时的形态保持。该框架完全省去了人工掩码和文本提示。

Result: 在DragBench和真实场景测试中，DirectDrag在无需掩码和提示的情况下实现了比现有方法更高的图像质量，同时保持了可竞争的拖拽精度。

Conclusion: DirectDrag无需人工掩码或文本提示即可实现高质量和高精度的互动图像编辑，克服了以往方法的限制，具有很强的实际应用价值。

Abstract: Drag-based image editing using generative models provides intuitive control over image structures. However, existing methods rely heavily on manually provided masks and textual prompts to preserve semantic fidelity and motion precision. Removing these constraints creates a fundamental trade-off: visual artifacts without masks and poor spatial control without prompts. To address these limitations, we propose DirectDrag, a novel mask- and prompt-free editing framework. DirectDrag enables precise and efficient manipulation with minimal user input while maintaining high image fidelity and accurate point alignment. DirectDrag introduces two key innovations. First, we design an Auto Soft Mask Generation module that intelligently infers editable regions from point displacement, automatically localizing deformation along movement paths while preserving contextual integrity through the generative model's inherent capacity. Second, we develop a Readout-Guided Feature Alignment mechanism that leverages intermediate diffusion activations to maintain structural consistency during point-based edits, substantially improving visual fidelity. Despite operating without manual mask or prompt, DirectDrag achieves superior image quality compared to existing methods while maintaining competitive drag accuracy. Extensive experiments on DragBench and real-world scenarios demonstrate the effectiveness and practicality of DirectDrag for high-quality, interactive image manipulation. Project Page: https://frakw.github.io/DirectDrag/. Code is available at: https://github.com/frakw/DirectDrag.

</details>


### [102] [DIQ-H: Evaluating Hallucination Persistence in VLMs Under Temporal Visual Degradation](https://arxiv.org/abs/2512.03992)
*Zexin Lin,Hawen Wan,Yebin Zhong,Xiaoqiang*

Main category: cs.CV

TL;DR: 本文提出了首个用于评估视觉-语言模型（VLM）在动态退化场景下稳健性的基准DIQ-H，揭示了现有模型在时序一致性和错误恢复方面存在显著短板。


<details>
  <summary>Details</summary>
Motivation: 现有VLM评测主要集中在静态高质量图像上，忽视了现实场景中持续变化、退化的视觉输入，这对于如自动驾驶等安全关键应用尤为重要。

Method: DIQ-H通过物理退化（如运动模糊、传感器噪声、压缩损伤）模拟时序视觉流，并设计多轮问答任务，测量模型的幻觉持续/恢复力和时序一致性。为降低标注成本，引入了基于不确定性引导的迭代精炼（UIR）流程，用轻量VLM生成伪真值并过滤噪声。

Result: 对16个SOTA模型实验证明，最先进VLM（如GPT-4o）恢复率仅为78.5%，而开源模型的时序一致性甚至低于60%，表明鲁棒性差距明显。UIR方法提升了15.3%的标注准确率。

Conclusion: DIQ-H为评估VLM在动态现实场景中的可靠性提供了全面平台，推动模型在应对复杂视觉环境方面的实用性提升。

Abstract: Vision-Language Models (VLMs) deployed in safety-critical applications such as autonomous driving must handle continuous visual streams under imperfect conditions. However, existing benchmarks focus on static, high-quality images and ignore temporal degradation and error propagation, which are critical failure modes where transient visual corruption induces hallucinations that persist across subsequent frames. We introduce DIQ-H, the first benchmark for evaluating VLM robustness under dynamic visual degradation in temporal sequences. DIQ-H applies physics-based corruptions including motion blur, sensor noise, and compression artifacts, and measures hallucination persistence, error recovery, and temporal consistency through multi-turn question-answering tasks. To enable scalable annotation, we propose Uncertainty-Guided Iterative Refinement (UIR), which generates reliable pseudo-ground-truth using lightweight VLMs with uncertainty filtering, achieving a 15.3 percent accuracy improvement. Experiments on 16 state-of-the-art VLMs reveal substantial robustness gaps: even advanced models such as GPT-4o achieve only a 78.5 percent recovery rate, while open-source models struggle with temporal consistency at less than 60 percent. DIQ-H provides a comprehensive platform for evaluating VLM reliability in real-world deployments.

</details>


### [103] [Highly Efficient Test-Time Scaling for T2I Diffusion Models with Text Embedding Perturbation](https://arxiv.org/abs/2512.03996)
*Hang Xu,Linjiang Huang,Feng Zhao*

Main category: cs.CV

TL;DR: 本文研究了文本到图像(T2I)扩散模型在推理时（test-time）利用随机性提升生成质量的新方法，提出通过扰动文本嵌入引入新的随机性，与现有的噪声扰动互补，显著提升生成多样性与细节质量。


<details>
  <summary>Details</summary>
Motivation: 现有TTS大多关注搜索策略和奖励模型，忽视了T2I扩散模型中噪声随机性及其对生成质量的影响。此外，空间噪声对高频细节的增强作用有限，需要新的随机性来源来提升生成质量。

Method: 本文提出在T2I扩散模型中引入基于步长的文本嵌入扰动，并按频率分配扰动强度，与空间噪声扰动结合。首先分析不同随机性的频域特性，然后动态调节扰动在生成过程中的贡献和容忍度，实现与现有TTS无缝集成。

Result: 该方法在多个基准数据集上取得了显著提升生成多样性和图像质量的结果，且几乎不增加计算成本。同时，实验验证了空间噪声扰动与文本嵌入扰动在频域上的互补性及各自对生成细节的增强。

Conclusion: 通过引入文本嵌入扰动丰富了扩散模型生成过程中的随机性，实现了多样性与质量的兼顾。该框架简单高效，可直接整合到现有TTS方法中，为提升T2I生成质量提供了新路径。

Abstract: Test-time scaling (TTS) aims to achieve better results by increasing random sampling and evaluating samples based on rules and metrics. However, in text-to-image(T2I) diffusion models, most related works focus on search strategies and reward models, yet the impact of the stochastic characteristic of noise in T2I diffusion models on the method's performance remains unexplored. In this work, we analyze the effects of randomness in T2I diffusion models and explore a new format of randomness for TTS: text embedding perturbation, which couples with existing randomness like SDE-injected noise to enhance generative diversity and quality. We start with a frequency-domain analysis of these formats of randomness and their impact on generation, and find that these two randomness exhibit complementary behavior in the frequency domain: spatial noise favors low-frequency components (early steps), while text embedding perturbation enhances high-frequency details (later steps), thereby compensating for the potential limitations of spatial noise randomness in high-frequency manipulation. Concurrently, text embedding demonstrates varying levels of tolerance to perturbation across different dimensions of the generation process. Specifically, our method consists of two key designs: (1) Introducing step-based text embedding perturbation, combining frequency-guided noise schedules with spatial noise perturbation. (2) Adapting the perturbation intensity selectively based on their frequency-specific contributions to generation and tolerance to perturbation. Our approach can be seamlessly integrated into existing TTS methods and demonstrates significant improvements on multiple benchmarks with almost no additional computation. Code is available at \href{https://github.com/xuhang07/TEP-Diffusion}{https://github.com/xuhang07/TEP-Diffusion}.

</details>


### [104] [Divide, then Ground: Adapting Frame Selection to Query Types for Long-Form Video Understanding](https://arxiv.org/abs/2512.04000)
*Jialuo Li,Bin Li,Jiahao Li,Yan Lu*

Main category: cs.CV

TL;DR: 该论文提出了一种新的、无需训练的帧选择框架DIG，根据查询类型（全局或局部）自适应选择最有效的帧选择策略，显著提升大模型在长视频理解任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有大多基于大模型（LMMs）的视频理解方法受限于上下文长度及高计算成本，尤其在面对长视频和密集视频token处理时效率低下。主流的基于查询感知的帧选取方法计算开销大且并非始终必要，因此作者有意挑战普遍采用复杂搜索机制的默认前提。

Method: 作者首先提出并验证了针对视频查询的类型学，将查询分为全局查询和局部查询两类。通过实验发现，全局查询采用均匀采样高效有效，而局部查询则确实需要查询感知的帧选取。基于此，提出DIG框架：对于全局查询采用高效的均匀采样；对于局部查询则启用帧提取管道智能选取相关帧。该方法无须额外训练，可根据不同查询类型自适应切换策略。

Result: 在三个长视频理解评测基准上，DIG框架均超越现有基线方法，在输入帧数提升至256时依然能稳健提升大模型性能。

Conclusion: 复杂的查询感知帧选取机制并非始终必要，针对不同查询类型采用自适应帧选取，可以以低计算开销获得更优长视频理解性能，DIG方法简单、高效且效果突出。

Abstract: The application of Large Multimodal Models (LMMs) to long-form video understanding is constrained by limited context lengths and the computationally prohibitive cost of processing dense video tokens. Consequently, recent research has focused on query-aware frame selection, methods that often incur significant computational overhead. This paper challenges the assumption that such complex search mechanisms are universally necessary. We first identify and validate a query typology distinguishing between global query and localized query. We demonstrate that while uniform sampling is both effective and efficient for global queries, localized queries indeed necessitate query-aware selection for optimal performance. Building on this insight, we propose DIG, a training-free frame selection framework that adapts its strategy based on the query type. Specifically,DIG employs efficient uniform sampling for global queries while activating a specialized pipeline to extract query-relevant frames for localized queries. Experiments on three long-form video understanding benchmarks demonstrate that DIG consistently outperforms existing baselines and robustly improves LMM performance, even when scaling the input frame count to 256.

</details>


### [105] [On the Temporality for Sketch Representation Learning](https://arxiv.org/abs/2512.04007)
*Marcelo Isaias de Moraes Junior,Moacir Antonelli Ponti*

Main category: cs.CV

TL;DR: 本论文探讨了素描作为序列进行建模的合理性及其顺序和时序性对表现的影响。研究发现绝对坐标优于相对坐标，非自回归解码器优于自回归解码器，时序性的重要性取决于具体顺序及任务。


<details>
  <summary>Details</summary>
Motivation: 虽然近年来素描表征学习取得了进展，但关于素描时序信息对表征质量的意义仍缺乏深入理解。本文旨在系统分析素描作为序列建模时，不同顺序的作用及其对下游任务的影响。

Method: 作者将素描转化为序列，通过比较传统位置编码（绝对坐标vs相对坐标）、不同类型解码器（自回归vs非自回归）和任务表现，定量评估了各因素对素描表征质量的影响。

Result: 实验显示，采用绝对坐标的传统位置编码效果优于相对坐标，非自回归解码器在所有评测任务上均优于自回归解码器。不同顺序及任务对时序性的依赖存在差异。

Conclusion: 素描作为序列进行建模具备合理性，但具体顺序和时序性的重要性受到任务及评估维度影响。采用绝对坐标和非自回归解码器可显著提升素描表征学习的表现。

Abstract: Sketches are simple human hand-drawn abstractions of complex scenes and real-world objects. Although the field of sketch representation learning has advanced significantly, there is still a gap in understanding the true relevance of the temporal aspect to the quality of these representations. This work investigates whether it is indeed justifiable to treat sketches as sequences, as well as which internal orders play a more relevant role. The results indicate that, although the use of traditional positional encodings is valid for modeling sketches as sequences, absolute coordinates consistently outperform relative ones. Furthermore, non-autoregressive decoders outperform their autoregressive counterparts. Finally, the importance of temporality was shown to depend on both the order considered and the task evaluated.

</details>


### [106] [Emergent Outlier View Rejection in Visual Geometry Grounded Transformers](https://arxiv.org/abs/2512.04012)
*Jisang Han,Sunghwan Hong,Jaewoo Jung,Wooseok Jang,Honggyu An,Qianqian Wang,Seungryong Kim,Chen Feng*

Main category: cs.CV

TL;DR: 本论文发现即使没有明确的异常点拒绝机制，一些前馈3D重建模型内在就具备区分噪声图片（无关输入）的能力，并提出利用特定层的这一特性进行异常视角过滤，提升了野外图片集下的3D重建表现。


<details>
  <summary>Details</summary>
Motivation: 传统SfM方法可以通过几何校验和异常点剔除处理“噪声”图片，但主流的前馈3D重建网络模型没有这些机制，导致在现实野外数据下性能变差，亟需提升模型的抗干扰能力。

Method: 作者以VGGT等前馈3D重建模型为例，在加入不同比例合成干扰图片的数据集上分析网络表现，发现模型中某一特定层自然具备抑制异常图片的功能。进一步挖掘该层的内部表征后，直接利用其特征进行无监督的异常图片过滤，无需模型微调。

Result: 实验证明，该层带来的隐式过滤机制效果稳定、通用性强，在合成数据和真实野外图片集都能提升3D重建表现。

Conclusion: 前馈3D重建模型虽然没有专门的抗噪机制，但充分利用其内部表征可显著增强鲁棒性，未来无需依赖额外监督或模型修改即可实现更强噪声抑制。

Abstract: Reliable 3D reconstruction from in-the-wild image collections is often hindered by "noisy" images-irrelevant inputs with little or no view overlap with others. While traditional Structure-from-Motion pipelines handle such cases through geometric verification and outlier rejection, feed-forward 3D reconstruction models lack these explicit mechanisms, leading to degraded performance under in-the-wild conditions. In this paper, we discover that the existing feed-forward reconstruction model, e.g., VGGT, despite lacking explicit outlier-rejection mechanisms or noise-aware training, can inherently distinguish distractor images. Through an in-depth analysis under varying proportions of synthetic distractors, we identify a specific layer that naturally exhibits outlier-suppressing behavior. Further probing reveals that this layer encodes discriminative internal representations that enable an effective noise-filtering capability, which we simply leverage to perform outlier-view rejection in feed-forward 3D reconstruction without any additional fine-tuning or supervision. Extensive experiments on both controlled and in-the-wild datasets demonstrate that this implicit filtering mechanism is consistent and generalizes well across diverse scenarios.

</details>


### [107] [Learning Group Actions In Disentangled Latent Image Representations](https://arxiv.org/abs/2512.04015)
*Farhana Hossain Swarnali,Miaomiao Zhang,Tonmoy Hossain*

Main category: cs.CV

TL;DR: 本文提出了一种无需手动分割的端到端框架，能够在潜在空间中自动学习和区分对群变换敏感及不变的成分，实现图像表示的可控群变换。


<details>
  <summary>Details</summary>
Motivation: 以往基于群论的图像变换方法通常在高维原始空间中操作，难以有效分离出随变换而变化的子空间，即难以对潜在表示进行有意义的可控变换。即使是潜在空间的方法，也往往依赖手动分区，限制了其泛化和自动化能力。因此作者希望开发一种方法，能自动且健壮地在潜在表示空间学习和操作群变换。

Method: 作者提出了一种新颖的端到端框架，采用可学习的二值掩码（通过straight-through估计器），动态将潜在表示划分为对变换敏感和不变的成分。该方法通过统一的优化框架，实现潜在空间的解缠结和群变换的共同学习，并且能无缝集成到标准编码-解码网络结构中。

Result: 在五个2D和3D图像数据集上验证了方法的有效性。实验表明，该方法能够自动学习与群变换相关和无关的潜在因素，获得结构更清晰的表征。同时，下游分类任务结果也证实了所获表示的有效性。

Conclusion: 所提框架能够自动、鲁棒地在潜在空间中学习群变换及其相关结构，提升了表示学习的可控性和实用性，且无需人为干预，具有良好的通用性。

Abstract: Modeling group actions on latent representations enables controllable transformations of high-dimensional image data. Prior works applying group-theoretic priors or modeling transformations typically operate in the high-dimensional data space, where group actions apply uniformly across the entire input, making it difficult to disentangle the subspace that varies under transformations. While latent-space methods offer greater flexibility, they still require manual partitioning of latent variables into equivariant and invariant subspaces, limiting the ability to robustly learn and operate group actions within the representation space. To address this, we introduce a novel end-to-end framework that for the first time learns group actions on latent image manifolds, automatically discovering transformation-relevant structures without manual intervention. Our method uses learnable binary masks with straight-through estimation to dynamically partition latent representations into transformation-sensitive and invariant components. We formulate this within a unified optimization framework that jointly learns latent disentanglement and group transformation mappings. The framework can be seamlessly integrated with any standard encoder-decoder architecture. We validate our approach on five 2D/3D image datasets, demonstrating its ability to automatically learn disentangled latent factors for group actions in diverse data, while downstream classification tasks confirm the effectiveness of the learned representations. Our code is publicly available at https://github.com/farhanaswarnali/Learning-Group-Actions-In-Disentangled-Latent-Image-Representations .

</details>


### [108] [Ultra-lightweight Neural Video Representation Compression](https://arxiv.org/abs/2512.04019)
*Ho Man Kwan,Tianhao Peng,Ge Gao,Fan Zhang,Mike Nilsson,Andrew Gower,David Bull*

Main category: cs.CV

TL;DR: 该论文提出了一种轻量化的神经视频压缩方法NVRC-Lite，在保证高效压缩性能的同时，大幅提升了编码与解码速度。


<details>
  <summary>Details</summary>
Motivation: 现有基于隐式神经表示（INR）的神经视频压缩方法在取得良好压缩率的同时，普遍存在模型复杂度高、编码速度慢等问题，尤其是自回归模型的熵编码效率低，限制了其实用性。作者希望解决这一瓶颈，并进一步提高轻量化模型的表现。

Method: NVRC-Lite在原有NVRC全流程终端到终端INR压缩框架的基础上做出两项改进：一是引入多尺度特征网格，以及更高分辨率的网格用于轻量级神经表示，有效提升低复杂度时的表现；二是提出基于八叉树的上下文模型，对高维特征网格进行高效熵编码，替代了传统自回归熵编码模型，大幅提高编码速度。

Result: NVRC-Lite在PSNR和MS-SSIM指标上分别比C3等优秀轻量INR方法节省了21.03%和23.06%的BD-rate，并且编码速度提高8.4倍，解码速度提升2.5倍。

Conclusion: NVRC-Lite实现了神经视频轻量压缩领域在压缩率和编码效率上的双重突破，优于当前主流的轻量INR编码器，对实际部署具有更高的应用价值。

Abstract: Recent works have demonstrated the viability of utilizing over-fitted implicit neural representations (INRs) as alternatives to autoencoder-based models for neural video compression. Among these INR-based video codecs, Neural Video Representation Compression (NVRC) was the first to adopt a fully end-to-end compression framework that compresses INRs, achieving state-of-the-art performance. Moreover, some recently proposed lightweight INRs have shown comparable performance to their baseline codecs with computational complexity lower than 10kMACs/pixel. In this work, we extend NVRC toward lightweight representations, and propose NVRC-Lite, which incorporates two key changes. Firstly, we integrated multi-scale feature grids into our lightweight neural representation, and the use of higher resolution grids significantly improves the performance of INRs at low complexity. Secondly, we address the issue that existing INRs typically leverage autoregressive models for entropy coding: these are effective but impractical due to their slow coding speed. In this work, we propose an octree-based context model for entropy coding high-dimensional feature grids, which accelerates the entropy coding module of the model. Our experimental results demonstrate that NVRC-Lite outperforms C3, one of the best lightweight INR-based video codecs, with up to 21.03% and 23.06% BD-rate savings when measured in PSNR and MS-SSIM, respectively, while achieving 8.4x encoding and 2.5x decoding speedup. The implementation of NVRC-Lite will be made available.

</details>


### [109] [C3G: Learning Compact 3D Representations with 2K Gaussians](https://arxiv.org/abs/2512.04021)
*Honggyu An,Jaewoo Jung,Mungyeom Kim,Sunghwan Hong,Chaehyun Kim,Kazumi Fukuda,Minkyeong Jeon,Jisang Han,Takuya Narihira,Hyuna Ko,Junsu Kim,Yuki Mitsufuji,Seungryong Kim*

Main category: cs.CV

TL;DR: 本文提出C3G框架，利用自注意力聚合多视图特征，仅在关键位置生成紧凑3D高斯，实现更高效的三维场景重建与理解。


<details>
  <summary>Details</summary>
Motivation: 当前从稀疏、无姿态三维视图重建和理解场景存在高冗余、高内存开销及特征聚合效果差的问题，导致新视角重建和场景理解性能下降。

Method: C3G框架通过引入可学习的Token和自注意力，将多视图信息聚合，并仅在必要空间位置生成紧凑3D高斯分布，有效减少冗余，并利用注意机制高效进行特征提升和解码。

Result: 在无姿态的新视角合成、三维开词分割和视图不变特征聚合等多个任务上，实验验证了C3G方法的有效性。结果显示，紧凑且几何有意义的表征即可实现高质量场景重建和理解，内存效率及特征保真度优于现有方法。

Conclusion: C3G框架在减少内存开销和维护高特征保真的同时，提升了重建与理解能力，验证了紧凑表征在三维场景分析中的潜力。

Abstract: Reconstructing and understanding 3D scenes from unposed sparse views in a feed-forward manner remains as a challenging task in 3D computer vision. Recent approaches use per-pixel 3D Gaussian Splatting for reconstruction, followed by a 2D-to-3D feature lifting stage for scene understanding. However, they generate excessive redundant Gaussians, causing high memory overhead and sub-optimal multi-view feature aggregation, leading to degraded novel view synthesis and scene understanding performance. We propose C3G, a novel feed-forward framework that estimates compact 3D Gaussians only at essential spatial locations, minimizing redundancy while enabling effective feature lifting. We introduce learnable tokens that aggregate multi-view features through self-attention to guide Gaussian generation, ensuring each Gaussian integrates relevant visual features across views. We then exploit the learned attention patterns for Gaussian decoding to efficiently lift features. Extensive experiments on pose-free novel view synthesis, 3D open-vocabulary segmentation, and view-invariant feature aggregation demonstrate our approach's effectiveness. Results show that a compact yet geometrically meaningful representation is sufficient for high-quality scene reconstruction and understanding, achieving superior memory efficiency and feature fidelity compared to existing methods.

</details>


### [110] [PSA: Pyramid Sparse Attention for Efficient Video Understanding and Generation](https://arxiv.org/abs/2512.04025)
*Xiaolong Li,Youping Gu,Xi Lin,Weijie Wang,Bohan Zhuang*

Main category: cs.CV

TL;DR: 本文提出了一种新型稀疏注意力机制——金字塔稀疏注意力（Pyramid Sparse Attention, PSA），旨在在保证高效计算的同时，最大程度减少信息损失。


<details>
  <summary>Details</summary>
Motivation: 现有高效注意力机制多采用稀疏化以减少复杂度，但常用的二值掩码方法在高稀疏度下容易造成大量信息损失。因此，亟需一种能在高效计算和信息保留间取得更优平衡的注意力机制。

Method: PSA通过多级池化的方式对key-value（KV）块进行分层表示，每个查询块动态地分配不同池化级别，从而对重要KV块保留细粒度信息，对不重要块采用高层次池化，实现了从完全保留到完全剪枝的动态过渡。此外，PSA采用适配硬件的kernel设计，确保高效执行。

Result: 在多个视频理解与生成的主流基准上，PSA在信息保留与视觉表现上都优于或持平于现有主流稀疏注意力方法，同时具有更好的效率-质量权衡。

Conclusion: 金字塔稀疏注意力（PSA）有效缓解了高稀疏度注意力机制信息损失严重的问题，能在低算力预算下保持信息完整和效率，适用于各类视频相关任务。

Abstract: Attention mechanisms are the core of foundation models, but their quadratic complexity remains a critical bottleneck for scaling. This challenge has driven the development of efficient attention mechanisms, with sparsity emerging as the dominant paradigm. Current methods typically retain or discard entire key-value blocks with binary masks, resulting in substantial information loss under high sparsity. To mitigate this gap, we present Pyramid Sparse Attention (PSA), a versatile module applicable to both video understanding and generation tasks. Instead of binary masking, PSA introduces multi-level pooled KV representations, enabling finer mask granularity. Specifically, each query block dynamically allocates lower pooling levels to critical KV blocks and higher levels to less important ones, creating an informative interpolation between full retention and complete pruning. This design, analogous to fixed-point quantization and classical feature pyramid networks in computer vision, effectively mitigates information loss while preserving computational efficiency under a low compute budget. It works with a native, hardware-friendly kernel that leverages decoupled block-tile design to ensure efficient execution. Across video understanding and generation benchmarks, PSA preserves contextual information and visual fidelity, consistently outperforming or achieving comparable performance over existing sparse attention baselines with superior efficiency-quality trade-offs. Our code and model weights are publicly available at: http://ziplab.co/PSA

</details>


### [111] [Fast & Efficient Normalizing Flows and Applications of Image Generative Models](https://arxiv.org/abs/2512.04039)
*Sandeep Nagar*

Main category: cs.CV

TL;DR: 论文主要在两方面做出贡献：一是提升生成模型（尤其是Normalizing Flows）的效率，二是将生成模型应用于现实世界的计算机视觉问题。结合多个创新方法，从理论、算法和实际应用均取得进展。


<details>
  <summary>Details</summary>
Motivation: 当前生成模型在效率和应用广度上仍存在诸多瓶颈，尤其是Normalizing Flows结构复杂、计算开销大，以及它们在农业、地质、隐私保护等实际问题中的应用尚不成熟，亟需理论和方法上的突破。

Method: 1. 针对Normalizing Flows提出六项架构和算法创新，包括可逆卷积、并行反演算法、逆向传播算法优化和轻量级超分模型等。
2. 在实际应用中，采用Conditional GANs、堆叠自编码器、基于检测与修复的图像隐私保护、基于扩散模型的艺术品修复等方法解决真实场景下数据不均衡、特征提取、隐私保护及多退化恢复等难题。

Result: 1. 提升了Normalizing Flows的效率和可扩展性。
2. 在种子纯度检测、地质制图、自动驾驶隐私保护、艺术修复等多个任务中，提出的方法均展现出比传统方法更优的表现或有效性。

Conclusion: 本论文推进了生成模型的理论和工程能力，证明其在多个计算机视觉领域的广泛应用潜力，同时也为解决实际社会问题（如隐私和艺术保护）提供了新的思路。

Abstract: This thesis presents novel contributions in two primary areas: advancing the efficiency of generative models, particularly normalizing flows, and applying generative models to solve real-world computer vision challenges. The first part introduce significant improvements to normalizing flow architectures through six key innovations: 1) Development of invertible 3x3 Convolution layers with mathematically proven necessary and sufficient conditions for invertibility, (2) introduction of a more efficient Quad-coupling layer, 3) Design of a fast and efficient parallel inversion algorithm for kxk convolutional layers, 4) Fast & efficient backpropagation algorithm for inverse of convolution, 5) Using inverse of convolution, in Inverse-Flow, for the forward pass and training it using proposed backpropagation algorithm, and 6) Affine-StableSR, a compact and efficient super-resolution model that leverages pre-trained weights and Normalizing Flow layers to reduce parameter count while maintaining performance.
  The second part: 1) An automated quality assessment system for agricultural produce using Conditional GANs to address class imbalance, data scarcity and annotation challenges, achieving good accuracy in seed purity testing; 2) An unsupervised geological mapping framework utilizing stacked autoencoders for dimensionality reduction, showing improved feature extraction compared to conventional methods; 3) We proposed a privacy preserving method for autonomous driving datasets using on face detection and image inpainting; 4) Utilizing Stable Diffusion based image inpainting for replacing the detected face and license plate to advancing privacy-preserving techniques and ethical considerations in the field.; and 5) An adapted diffusion model for art restoration that effectively handles multiple types of degradation through unified fine-tuning.

</details>


### [112] [RELIC: Interactive Video World Model with Long-Horizon Memory](https://arxiv.org/abs/2512.04040)
*Yicong Hong,Yiqun Mei,Chongjian Ge,Yiran Xu,Yang Zhou,Sai Bi,Yannick Hold-Geoffroy,Mike Roberts,Matthew Fisher,Eli Shechtman,Kalyan Sunkavalli,Feng Liu,Zhengqi Li,Hao Tan*

Main category: cs.CV

TL;DR: 本文提出了RELIC框架，实现了实时长时序流媒体、空间记忆一致性和精确用户控制三大要素，突破了现有方法只能兼顾其中之一的限制。RELIC基于视频扩散蒸馏技术，通过紧凑的历史记忆布局，能够在仅需单张图片和文本描述的条件下，支持更强的交互式世界建模和更长时持续生成。


<details>
  <summary>Details</summary>
Motivation: 当前大多数交互式世界模型只能专注解决长时序流媒体、空间一致记忆或精确控制三者之一，很难三者兼得。传统长时记忆机制往往损失实时性，限制了实际应用。因此，亟需一种兼容三者的统一方法。

Method: RELIC框架利用视频自回归扩散蒸馏技术，将历史操作和相机位姿编码为紧凑的KV缓存Token，实现高效的空间/记忆检索和长期一致性。同时，采用双向教师模型和自我强化新范式，将短时序训练模型推广到长时序生成，提升模型记忆和上下文理解能力。

Result: RELIC以14B参数规模，在虚幻引擎渲染数据集上训练，能够以16FPS实时速度生成，并在动作跟随、长时序流畅性、空间记忆检索等指标上远超已有同类方法。

Conclusion: RELIC成功将长时序流、空间一致性和精确控制三大要素统一，实现实时高效的交互世界建模，为下一代交互环境奠定了坚实基础。

Abstract: A truly interactive world model requires three key ingredients: real-time long-horizon streaming, consistent spatial memory, and precise user control. However, most existing approaches address only one of these aspects in isolation, as achieving all three simultaneously is highly challenging-for example, long-term memory mechanisms often degrade real-time performance. In this work, we present RELIC, a unified framework that tackles these three challenges altogether. Given a single image and a text description, RELIC enables memory-aware, long-duration exploration of arbitrary scenes in real time. Built upon recent autoregressive video-diffusion distillation techniques, our model represents long-horizon memory using highly compressed historical latent tokens encoded with both relative actions and absolute camera poses within the KV cache. This compact, camera-aware memory structure supports implicit 3D-consistent content retrieval and enforces long-term coherence with minimal computational overhead. In parallel, we fine-tune a bidirectional teacher video model to generate sequences beyond its original 5-second training horizon, and transform it into a causal student generator using a new memory-efficient self-forcing paradigm that enables full-context distillation over long-duration teacher as well as long student self-rollouts. Implemented as a 14B-parameter model and trained on a curated Unreal Engine-rendered dataset, RELIC achieves real-time generation at 16 FPS while demonstrating more accurate action following, more stable long-horizon streaming, and more robust spatial-memory retrieval compared with prior work. These capabilities establish RELIC as a strong foundation for the next generation of interactive world modeling.

</details>


### [113] [PosterCopilot: Toward Layout Reasoning and Controllable Editing for Professional Graphic Design](https://arxiv.org/abs/2512.04082)
*Jiazhe Wei,Ken Li,Tianyu Lao,Haofan Wang,Liang Wang,Caifeng Shan,Chenyang Si*

Main category: cs.CV

TL;DR: 本文提出了PosterCopilot框架，结合大规模多模态模型训练策略和生成模型，提升平面设计的布局推理与可控化编辑能力，实现了几何准确且美观的设计结果，并适用于专业领域的迭代式设计流程。


<details>
  <summary>Details</summary>
Motivation: 现有用大模型自动化平面设计的方法存在布局几何不准确、缺乏专业流程所需的分层可控编辑等问题，难以满足实际设计需求。

Method: 作者提出了三阶段渐进式训练方法，包括扰动有监督微调（Perturbed Supervised Fine-Tuning）、视觉真实性对齐强化学习（Reinforcement Learning for Visual-Reality Alignment）、美学反馈强化学习（Reinforcement Learning from Aesthetic Feedback），并开发了结合设计模型和生成模型的工作流，实现分层、可控、迭代编辑。

Result: 实验结果显示，PosterCopilot在布局几何准确性和美学质量上优于现有方法，提供了前所未有的专业化可控迭代设计能力。

Conclusion: PosterCopilot可以显著提升平面设计的自动化和专业性，兼顾几何准确性与美学，同时满足专业设计师对分层编辑和迭代修改的需求。

Abstract: Graphic design forms the cornerstone of modern visual communication, serving as a vital medium for promoting cultural and commercial events. Recent advances have explored automating this process using Large Multimodal Models (LMMs), yet existing methods often produce geometrically inaccurate layouts and lack the iterative, layer-specific editing required in professional workflows. To address these limitations, we present PosterCopilot, a framework that advances layout reasoning and controllable editing for professional graphic design. Specifically, we introduce a progressive three-stage training strategy that equips LMMs with geometric understanding and aesthetic reasoning for layout design, consisting of Perturbed Supervised Fine-Tuning, Reinforcement Learning for Visual-Reality Alignment, and Reinforcement Learning from Aesthetic Feedback. Furthermore, we develop a complete workflow that couples the trained LMM-based design model with generative models, enabling layer-controllable, iterative editing for precise element refinement while maintaining global visual consistency. Extensive experiments demonstrate that PosterCopilot achieves geometrically accurate and aesthetically superior layouts, offering unprecedented controllability for professional iterative design.

</details>


### [114] [SimFlow: Simplified and End-to-End Training of Latent Normalizing Flows](https://arxiv.org/abs/2512.04084)
*Qinyu Zhao,Guangting Zheng,Tao Yang,Rui Zhu,Xingjian Leng,Stephen Gould,Liang Zheng*

Main category: cs.CV

TL;DR: 本论文提出了一种简化的Normalizing Flows（NF）训练方法SimFlow，通过将VAE编码器输出的方差固定为常数，有效提升模型重构和生成质量，并显著优于此前最佳方法。


<details>
  <summary>Details</summary>
Motivation: 以往NF方法依赖复杂的数据增强流程（如添加随机噪声），并且采用预训练且冻结的VAE编码器，导致最优性能受限。本文旨在寻找一种更简单且高效的方案。

Method: 作者提出直接将VAE编码器预测的方差固定为常数，避免额外的加噪和去噪设计，并简化了联合训练VAE和NF的优化目标。这种新方案既扩大了Encoder的分布能力，也便于Decoder从噪声增强的数据重构出干净图像。

Result: 在ImageNet 256x256生成任务上，SimFlow指标gFID达到2.15，优于已有最佳的STARFlow（gFID 2.40）；结合REPA-E方法后，进一步将gFID提升到1.91，刷新了NF方法的最优表现。

Conclusion: 通过将VAE编码器方差固定，可以更简洁有效地训练NF模型，既提升了模型性能，也降低了训练和实现的复杂性。该方法为图像生成领域提供了新的思路和SOTA结果。

Abstract: Normalizing Flows (NFs) learn invertible mappings between the data and a Gaussian distribution. Prior works usually suffer from two limitations. First, they add random noise to training samples or VAE latents as data augmentation, introducing complex pipelines including extra noising and denoising steps. Second, they use a pretrained and frozen VAE encoder, resulting in suboptimal reconstruction and generation quality. In this paper, we find that the two issues can be solved in a very simple way: just fixing the variance (which would otherwise be predicted by the VAE encoder) to a constant (e.g., 0.5). On the one hand, this method allows the encoder to output a broader distribution of tokens and the decoder to learn to reconstruct clean images from the augmented token distribution, avoiding additional noise or denoising design. On the other hand, fixed variance simplifies the VAE evidence lower bound, making it stable to train an NF with a VAE jointly. On the ImageNet $256 \times 256$ generation task, our model SimFlow obtains a gFID score of 2.15, outperforming the state-of-the-art method STARFlow (gFID 2.40). Moreover, SimFlow can be seamlessly integrated with the end-to-end representation alignment (REPA-E) method and achieves an improved gFID of 1.91, setting a new state of the art among NFs.

</details>


### [115] [Unique Lives, Shared World: Learning from Single-Life Videos](https://arxiv.org/abs/2512.04085)
*Tengda Han,Sayna Ebrahimi,Dilara Gokay,Li Yang Ku,Maks Ovsjanikov,Iva Babukova,Daniel Zoran,Viorica Patraucean,Joao Carreira,Andrew Zisserman,Dima Damen*

Main category: cs.CV

TL;DR: 本文提出了“single-life”学习范式，即用单个人的第一视角视频独立训练视觉模型，证明了这种方法能获得高度一致且可泛化的视觉表示。


<details>
  <summary>Details</summary>
Motivation: 现有视觉模型常依赖多个人或多场景下大量数据，但单一个体所采集的多视角数据是否具备学习通用视觉表示能力尚不明确。作者为探究能否利用单个人生活中的第一视角视频，推动自监督视觉编码器学习及对齐性，提出这一范式。

Method: 作者采用自监督方法，将来自不同个体的第一视角视频分别训练成各自的视觉模型。提出一种基于跨注意力的新指标，用于量化模型内部表征在功能上的对齐程度，并测试模型在下游任务（如深度估计）上的泛化能力。研究数据涵盖室内外不同场景，并比较与传统多样化网络数据训练的差异。

Result: 1) 不同个体单独训练的模型在几何理解上高度一致，内部表征功能上有显著对齐；2) 单个人训练出的模型在未见环境下依然能良好迁移到深度估计等任务；3) 单一生活一周内30小时数据训练效果，与30小时多样Web数据相当。

Conclusion: 世界结构的共性促成了在单个人生活轨迹上训练模型的一致性和有效性。单一生活轨迹的视频数据为自监督视觉表征学习提供了强有力的信号，有望成为新型视觉学习的重要途径。

Abstract: We introduce the "single-life" learning paradigm, where we train a distinct vision model exclusively on egocentric videos captured by one individual. We leverage the multiple viewpoints naturally captured within a single life to learn a visual encoder in a self-supervised manner. Our experiments demonstrate three key findings. First, models trained independently on different lives develop a highly aligned geometric understanding. We demonstrate this by training visual encoders on distinct datasets each capturing a different life, both indoors and outdoors, as well as introducing a novel cross-attention-based metric to quantify the functional alignment of the internal representations developed by different models. Second, we show that single-life models learn generalizable geometric representations that effectively transfer to downstream tasks, such as depth estimation, in unseen environments. Third, we demonstrate that training on up to 30 hours from one week of the same person's life leads to comparable performance to training on 30 hours of diverse web data, highlighting the strength of single-life representation learning. Overall, our results establish that the shared structure of the world, both leads to consistency in models trained on individual lives, and provides a powerful signal for visual representation learning.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [116] [Entropy-Based Measurement of Value Drift and Alignment Work in Large Language Models](https://arxiv.org/abs/2512.03047)
*Samih Fadli*

Main category: cs.CL

TL;DR: 本论文提出了一种用“伦理熵”监控大语言模型对齐稳定性的动态方法，并开发了可实时预警价值漂移的监控管道。


<details>
  <summary>Details</summary>
Motivation: 现有对大语言模型安全性的评估大多依赖于静态基准测试，但现实中模型价值漂移、越狱攻击等动态问题才是关键风险。作者希望提出一种能动态捕捉并预警模型对齐退化的新评估框架。

Method: 作者基于“智能第二定律”理论，将伦理熵S(t)作为衡量模型对齐状态的状态变量。提出了五分类行为体系，训练分类器从模型对话中估算伦理熵，并在不同压力测试场景下，比较了基础模型和指令微调模型的伦理熵动态变化。此外定义了有效对齐功率γ_eff，并将S(t)与γ_eff集成到实时监控与预警系统中。

Result: 实验发现，基础模型在压力下伦理熵持续上升，表现出对齐退化趋势；但指令微调后模型能显著抑制伦理熵增长，降低约80%的伦理熵。通过监控伦理熵S(t)和对齐功率γ_eff，系统能检测到超出阈值的价值漂移并实时预警。

Conclusion: 伦理熵可作为度量大语言模型长期对齐退化和价值漂移的有效动态指标。作者所提出的框架为大模型实际部署和监控，提供了量化且可操作的对齐稳定性监管工具。

Abstract: Large language model safety is usually assessed with static benchmarks, but key failures are dynamic: value drift under distribution shift, jailbreak attacks, and slow degradation of alignment in deployment. Building on a recent Second Law of Intelligence that treats ethical entropy as a state variable which tends to increase unless countered by alignment work, we make this framework operational for large language models. We define a five-way behavioral taxonomy, train a classifier to estimate ethical entropy S(t) from model transcripts, and measure entropy dynamics for base and instruction-tuned variants of four frontier models across stress tests. Base models show sustained entropy growth, while tuned variants suppress drift and reduce ethical entropy by roughly eighty percent. From these trajectories we estimate an effective alignment work rate gamma_eff and embed S(t) and gamma_eff in a monitoring pipeline that raises alerts when entropy drift exceeds a stability threshold, enabling run-time oversight of value drift.

</details>


### [117] [Watermarks for Embeddings-as-a-Service Large Language Models](https://arxiv.org/abs/2512.03079)
*Anudeex Shetty*

Main category: cs.CL

TL;DR: 论文研究了Embeddings-as-a-Service (EaaS) 的水印技术如何抵御模型克隆（模仿）攻击，并提出了一种新的鲁棒水印方法。


<details>
  <summary>Details</summary>
Motivation: EaaS让企业提供文本特征嵌入服务，但模型容易被黑盒攻击克隆。为了保护知识产权，水印技术被引入。然而，现有水印存在被规避的风险。本文旨在提升水印方法的安全性。

Method: 1. 分析并实验证明，现有EaaS水印可通过对输入文本释义（paraphrasing）攻击轻易被移除，揭示该方法重大漏洞。
2. 提出新方法WET（线性变换水印），通过嵌入向量的线性变换进行水印，验证时逆变换并比较还原前后的嵌入相似度。

Result: 实验证明释义攻击下，现有水印方法大多失效。WET水印方法在各种攻击场景下表现出极高的鲁棒性与可验证性。

Conclusion: 释义攻击是现有EaaS水印技术的主要威胁。WET水印技术提高了水印的安全性和实用性，为EaaS模型知识产权保护提供了更有效方案。

Abstract: Large Language Models (LLMs) have demonstrated exceptional capabilities in natural language understanding and generation. Based on these LLMs, businesses have started to provide Embeddings-as-a-Service (EaaS), offering feature extraction capabilities (in the form of text embeddings) that benefit downstream natural language processing tasks. However, prior research has demonstrated that EaaS is vulnerable to imitation attacks, where an attacker clones the service's model in a black-box manner without access to the model's internal workings. In response, watermarks have been added to the text embeddings to protect the intellectual property of EaaS providers by allowing them to check for model ownership. This thesis focuses on defending against imitation attacks by investigating EaaS watermarks. To achieve this goal, we unveil novel attacks and propose and validate new watermarking techniques.
  Firstly, we show that existing EaaS watermarks can be removed through paraphrasing the input text when attackers clone the model during imitation attacks. Our study illustrates that paraphrasing can effectively bypass current state-of-the-art EaaS watermarks across various attack setups (including different paraphrasing techniques and models) and datasets in most instances. This demonstrates a new vulnerability in recent EaaS watermarking techniques.
  Subsequently, as a countermeasure, we propose a novel watermarking technique, WET (Watermarking EaaS with Linear Transformation), which employs linear transformation of the embeddings. Watermark verification is conducted by applying a reverse transformation and comparing the similarity between recovered and original embeddings. We demonstrate its robustness against paraphrasing attacks with near-perfect verifiability. We conduct detailed ablation studies to assess the significance of each component and hyperparameter in WET.

</details>


### [118] [Alleviating Choice Supportive Bias in LLM with Reasoning Dependency Generation](https://arxiv.org/abs/2512.03082)
*Nan Zhuang,Wenshuo Wang,Lekai Qian,Yuxiao Wang,Boyu Cao,Qi Liu*

Main category: cs.CL

TL;DR: 本文提出了一种新方法，首次针对大语言模型表现出的选择支持性偏见（CSB）进行纠偏，并取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在做决策评价时，容易出现选择支持性偏见（CSB），即系统地偏向自己选的答案，影响AI辅助决策的客观性。目前，大部分去偏方法关注社会、人口等偏见，却很少关注这类认知偏见。

Method: 作者提出Reasoning Dependency Generation (RDG) 框架，通过自动生成无偏的推理QA数据，显式建模或解耦选项、证据和理由之间的依赖关系，从而用于微调大语言模型，减少CSB。该方法可自动生成大规模、领域跨越的平衡QA数据，包括情境依赖和依赖解耦数据。

Result: 实验显示，在使用RDG生成的数据微调后，大语言模型在记忆类实验中表现提升81.5%，在评估类实验中提升94.3%，且在标准BBQ基准测试中维持同等性能。

Conclusion: 该工作首次针对大语言模型的选择支持性偏见提出了解决方案，为认知偏见的纠正和更可靠的AI决策系统迈出了重要一步。

Abstract: Recent studies have demonstrated that some Large Language Models exhibit choice-supportive bias (CSB) when performing evaluations, systematically favoring their chosen options and potentially compromising the objectivity of AI-assisted decision making. While existing debiasing approaches primarily target demographic and social biases, methods for addressing cognitive biases in LLMs remain largely unexplored. In this work, we present the first solution to address CSB through Reasoning Dependency Generation (RDG), a novel framework for generating unbiased reasoning data to mitigate choice-supportive bias through fine-tuning. RDG automatically constructs balanced reasoning QA pairs, explicitly (un)modeling the dependencies between choices, evidences, and justifications. Our approach is able to generate a large-scale dataset of QA pairs across domains, incorporating Contextual Dependency Data and Dependency Decouple Data. Experiments show that LLMs fine-tuned on RDG-generated data demonstrate a 81.5% improvement in memory-based experiments and 94.3% improvement in the evaluation-based experiment, while maintaining similar performance on standard BBQ benchmarks. This work pioneers an approach for addressing cognitive biases in LLMs and contributes to the development of more reliable AI-assisted decision support systems.

</details>


### [119] [Enhancing Job Matching: Occupation, Skill and Qualification Linking with the ESCO and EQF taxonomies](https://arxiv.org/abs/2512.03195)
*Stylianos Saroglou,Konstantinos Diamantaras,Francesco Preta,Marina Delianidi,Apostolos Benisis,Christian Johannes Meyer*

Main category: cs.CL

TL;DR: 本研究旨在提升劳动力市场信息的分类，通过将职位招聘文本与欧洲两个主要框架（ESCO与EQF）关联，比较和实现Sentence Linking与Entity Linking两种主流方法，同时发布了开源工具和两个注释数据集，以促进相关研究与应用。


<details>
  <summary>Details</summary>
Motivation: 劳动力市场分析依赖于对职位与技能的准确分类，现有方法在技能抽取和细粒度分类方面存在局限，因此需要探索结合语言模型与新方法来改进信息建模与分类。

Method: 作者比较了Sentence Linking和Entity Linking两种文献中常用的方法，并结合生成式大语言模型，开发了开源工具，用于职位及资格的标注和分类，还整理并发布了两个新的人类注释数据集用于模型评估。

Result: 研究对比了不同语言模型方法在岗位和资格分类任务中的表现，提升了实体抽取与分类的准确度，并发布了支持进一步研究的公共资源和工具。

Conclusion: 基于语言模型和新数据集的方法提升了劳动力市场职位信息的实体抽取与资格匹配能力，为数字经济下的工作、技能与就业分析提供了新基础设施和研究方向。

Abstract: This study investigates the potential of language models to improve the classification of labor market information by linking job vacancy texts to two major European frameworks: the European Skills, Competences, Qualifications and Occupations (ESCO) taxonomy and the European Qualifications Framework (EQF). We examine and compare two prominent methodologies from the literature: Sentence Linking and Entity Linking. In support of ongoing research, we release an open-source tool, incorporating these two methodologies, designed to facilitate further work on labor classification and employment discourse. To move beyond surface-level skill extraction, we introduce two annotated datasets specifically aimed at evaluating how occupations and qualifications are represented within job vacancy texts. Additionally, we examine different ways to utilize generative large language models for this task. Our findings contribute to advancing the state of the art in job entity extraction and offer computational infrastructure for examining work, skills, and labor market narratives in a digitally mediated economy. Our code is made publicly available: https://github.com/tabiya-tech/tabiya-livelihoods-classifier

</details>


### [120] [InvertiTune: High-Quality Data Synthesis for Cost-Effective Single-Shot Text-to-Knowledge Graph Generation](https://arxiv.org/abs/2512.03197)
*Faezeh Faez,Marzieh S. Tahaei,Yaochen Hu,Ali Pourranjbar,Mahdi Biparva,Mark Coates,Yingxue Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种新框架 InvertiTune，通过系统化的数据生成流程与有监督微调相结合，显著提升了从文本自动构建知识图谱的效率与效果。


<details>
  <summary>Details</summary>
Motivation: 当前主流的 Text2KG 方法依赖大语言模型反复提问，计算开销大、且难以捕捉文本中复杂的分布式关系，亟需高效、覆盖更复杂场景的替代方案。

Method: InvertiTune 包括：1) 从大型知识库有系统地提取子图，2) 进行噪声过滤，3) 利用大语言模型将子图转换成自然文本描述，从而构建大规模、高质量的配对数据，进而有监督微调轻量化模型实现单步知识图谱构建。

Result: 实验显示：在由该流程自动生成的新数据集 CE12k 上，InvertiTune 优于未微调的大模型及最新 Text2KG 方法；同时，在跨数据集评测 CrossEval-1200 上表现出更强泛化能力。

Conclusion: 高质量、现实场景贴合的训练数据对提升 Text2KG 系统效率与效果至关重要，InvertiTune 为相关研究提供了新的有效范式。

Abstract: Large Language Models (LLMs) have revolutionized the ability to understand and generate text, enabling significant progress in automatic knowledge graph construction from text (Text2KG). Many Text2KG methods, however, rely on iterative LLM prompting, making them computationally expensive and prone to overlooking complex relations distributed throughout the text. To address these limitations, we propose InvertiTune, a framework that combines a controlled data generation pipeline with supervised fine-tuning (SFT). Within this framework, the data-generation pipeline systematically extracts subgraphs from large knowledge bases, applies noise filtering, and leverages LLMs to generate corresponding natural text descriptions, a task more aligned with LLM capabilities than direct KG generation from text. This pipeline enables generating datasets composed of longer texts paired with larger KGs that better reflect real-world scenarios compared to existing benchmarks, thus supporting effective SFT of lightweight models for single-shot KG construction. Experimental results on CE12k, a dataset generated using the introduced pipeline, show that InvertiTune outperforms larger non-fine-tuned LLMs as well as state-of-the-art Text2KG approaches, while also demonstrating stronger cross-dataset generalization on CrossEval-1200, a test set created from three established benchmark datasets and CE12k. These findings highlight the importance of realistic, high-quality training data for advancing efficient and high-performing Text2KG systems.

</details>


### [121] [Identifying attributions of causality in political text](https://arxiv.org/abs/2512.03214)
*Paulina Garcia-Corral*

Main category: cs.CL

TL;DR: 本文提出了一种新框架，利用因果语言模型自动从政治文本中检测并解析解释，实现因果关系对的结构化抽取，提升了对政治解释性文本的系统化和规模化分析能力。


<details>
  <summary>Details</summary>
Motivation: 在政治学领域，解释在人们理解政治世界中极为重要，但系统性分析不足，且现有方法零散且多针对特定议题，缺乏统一通用的自动化工具。

Method: 作者提出并训练了一种轻量级的因果语言模型，自动检测和解析政治文本中的解释，将文本中的因果主张以因果对的结构化形式提取出来，用于下游分析。

Result: 实验显示该方法可以在大规模数据集上有效工作，并且其标注需求较低、具有良好的通用性及接近人工标注的准确率。

Conclusion: 通过该方法，政治科学领域可以更系统、大规模地研究解释性内容，对因果解释性文本的自动化分析提供了高效工具，推动了该领域的研究进步。

Abstract: Explanations are a fundamental element of how people make sense of the political world. Citizens routinely ask and answer questions about why events happen, who is responsible, and what could or should be done differently. Yet despite their importance, explanations remain an underdeveloped object of systematic analysis in political science, and existing approaches are fragmented and often issue-specific. I introduce a framework for detecting and parsing explanations in political text. To do this, I train a lightweight causal language model that returns a structured data set of causal claims in the form of cause-effect pairs for downstream analysis. I demonstrate how causal explanations can be studied at scale, and show the method's modest annotation requirements, generalizability, and accuracy relative to human coding.

</details>


### [122] [Randomized Masked Finetuning: An Efficient Way to Mitigate Memorization of PIIs in LLMs](https://arxiv.org/abs/2512.03310)
*Kunj Joshi,David A. Smith*

Main category: cs.CL

TL;DR: 本文提出了一种新的隐私保护微调方法RMFT，有效减少了大语言模型对PII记忆，并对比现有方法展示了其优势。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型容易记忆并泄露训练数据中的个人敏感信息，带来安全与隐私风险。因此，迫切需要方法在不显著影响模型性能的情况下，降低大模型对PII的记忆。

Method: 作者提出了随机掩码微调（Randomized Masked Fine-Tuning, RMFT）作为隐私保护微调技术，通过在微调过程中随机掩盖敏感信息，减少模型对PII的记忆。同时，提出了MaxTER评估框架，以衡量隐私和效用之间的权衡。

Result: 在Enron Email数据集上的实验结果显示，RMFT相较于基线微调方法，在总提取率和已见提取率上分别降低了80.81%和80.17%，大幅优于去重方法，同时模型困惑度仅增加5.73%。

Conclusion: RMFT可以有效减少PII记忆，优于现有去重方法，并且模型性能损失较小，是一种具有良好隐私-效用平衡的新方法。

Abstract: The current literature on memorization in Natural Language Models, especially Large Language Models (LLMs), poses severe security and privacy risks, as models tend to memorize personally identifying information (PIIs) from training data. We introduce Randomized Masked Fine-Tuning (RMFT), a novel privacy-preserving fine-tuning technique that reduces PII memorization while minimizing performance impact. Using the Enron Email Dataset, we demonstrate that RMFT achieves an 80.81% reduction in Total Extraction Rate and 80.17% reduction in Seen Extraction Rate compared to baseline fine-tuning, outperforming deduplication methods while maintaining only a 5.73% increase in perplexity. We present MaxTER, a Pareto-optimal evaluation framework for assessing privacy-utility tradeoffs, and show the performance of RMFT vs Deduplication by Area Under The Response Curve (AURC) metric.

</details>


### [123] [Modeling Topics and Sociolinguistic Variation in Code-Switched Discourse: Insights from Spanish-English and Spanish-Guaraní](https://arxiv.org/abs/2512.03334)
*Nemika Tyagi,Nelvin Licona Guevara,Olga Kellert*

Main category: cs.CL

TL;DR: 本研究利用大语言模型（LLM）自动标注双语语料，实现话题、体裁和语用功能等信息的高效分析，揭示了性别、语言主导性与语用功能之间的系统关联，并验证了瓜拉尼语和西班牙语在正式性上的差异。


<details>
  <summary>Details</summary>
Motivation: 手工注释双语语料费时费力，且传统方法难以大规模量化社会语言学模式。现有研究缺乏自动化工具来揭示跨语言、低资源双语群体中的复杂话语特征。

Method: 使用大语言模型对西英和西瓜拉尼两类语言环境下的3,691例代码转换句子进行自动化标注，包括话题、体裁和语用功能。将人口统计元数据与注释结合，并为西瓜拉尼数据集补充话题注释，进行分布统计分析。

Result: 在迈阿密数据中，发现性别、语言主导性与语用功能的系统性关联；在巴拉圭文本中，揭示了瓜拉尼语（正式场合）与西班牙语（非正式场合）之间的明晰双言分工。这些规律与以往的小规模质性观察一致，并提供了定量证据。

Conclusion: 大语言模型可以稳定、可解释地自动化发现传统上需手工标注的社会语言学模式，推动了跨语言及低资源双语研究的计算方法发展。

Abstract: This study presents an LLM-assisted annotation pipeline for the sociolinguistic and topical analysis of bilingual discourse in two typologically distinct contexts: Spanish-English and Spanish-Guaraní. Using large language models, we automatically labeled topic, genre, and discourse-pragmatic functions across a total of 3,691 code-switched sentences, integrated demographic metadata from the Miami Bilingual Corpus, and enriched the Spanish-Guaraní dataset with new topic annotations. The resulting distributions reveal systematic links between gender, language dominance, and discourse function in the Miami data, and a clear diglossic division between formal Guaraní and informal Spanish in Paraguayan texts. These findings replicate and extend earlier interactional and sociolinguistic observations with corpus-scale quantitative evidence. The study demonstrates that large language models can reliably recover interpretable sociolinguistic patterns traditionally accessible only through manual annotation, advancing computational methods for cross-linguistic and low-resource bilingual research.

</details>


### [124] [PERCS: Persona-Guided Controllable Biomedical Summarization Dataset](https://arxiv.org/abs/2512.03340)
*Rohan Charudatt Salvi,Chirag Chawla,Dhruv Jain,Swapnil Panigrahi,Md Shad Akhtar,Shweta Yadav*

Main category: cs.CL

TL;DR: 该论文提出了PERCS数据集，涵盖了不同医疗素养用户的医学文本简化和个性化总结，大幅推动了领域内个性化健康科普信息研究。


<details>
  <summary>Details</summary>
Motivation: 现有医学文本简化资源多面向单一用户群体，未能充分考虑不同用户的医学素养及信息需求，造成医患信息鸿沟。因此，亟须面向多元受众的个性化文本简化方法。

Method: 作者构建了PERCS数据集，将医学文摘与面向四类不同“人物画像”（非专业大众、医学生、非医学研究者、医学专家）的定制化摘要配对，并由医生审核其事实准确性和与画像的匹配度。通过词汇、可读性、内容深度等方面的技术验证，证明不同画像摘要之间有显著差异。

Result: 四种大语言模型在PERCS数据集上进行了基准测试，自动评估覆盖了摘要全面性、可读性与事实一致性。结果初步证明数据集区分个性化需求能力强，并为未来研究提供了基线。

Conclusion: PERCS为多画像受众的医学文本简化与可控总结提供了重要资源，有助于推动个性化医学知识传播，相关数据、指南和评测材料已公开，鼓励社区进一步研究。

Abstract: Automatic medical text simplification plays a key role in improving health literacy by making complex biomedical research accessible to diverse readers. However, most existing resources assume a single generic audience, overlooking the wide variation in medical literacy and information needs across user groups. To address this limitation, we introduce PERCS (Persona-guided Controllable Summarization), a dataset of biomedical abstracts paired with summaries tailored to four personas: Laypersons, Premedical Students, Non-medical Researchers, and Medical Experts. These personas represent different levels of medical literacy and information needs, emphasizing the need for targeted, audience-specific summarization. Each summary in PERCS was reviewed by physicians for factual accuracy and persona alignment using a detailed error taxonomy. Technical validation shows clear differences in readability, vocabulary, and content depth across personas. Along with describing the dataset, we benchmark four large language models on PERCS using automatic evaluation metrics that assess comprehensiveness, readability, and faithfulness, establishing baseline results for future research. The dataset, annotation guidelines, and evaluation materials are publicly available to support research on persona-specific communication and controllable biomedical summarization.

</details>


### [125] [Idea-Gated Transformers: Enforcing Semantic Coherence via Differentiable Vocabulary Pruning](https://arxiv.org/abs/2512.03343)
*Darshan Fofadiya*

Main category: cs.CL

TL;DR: 本文提出Idea-Gated Transformer架构，通过引入辅助“Idea Head”和概念向量，提升大模型在文本生成过程中的主题保持能力，减少“话题漂移”。


<details>
  <summary>Details</summary>
Motivation: 现有基于下一个词预测（NTP）的自回归语言模型在生成文本时容易发生话题漂移，导致内容偏离初始主题，而仅通过增大模型规模不能从根本上解决该问题。

Method: 设计了一种新型的Idea-Gated Transformer结构，引入“Idea Head”辅助模块，预测未来窗口的词袋分布，生成潜在概念向量用于在生成过程中动态门控主词表，通过可微分门控机制实时筛除语义无关的词。

Result: 在WikiText-103实验上，Idea-Gated模型在验证困惑度与标准GPT-2接近，但在领域保持上大大优于后者。分析显示，门控机制能有效锁定语义簇，显著减少关联漂移。

Conclusion: Idea-Gated Transformer可参数高效地提升文本生成中话题保持性，为更可控的语言建模提供新思路。

Abstract: Autoregressive Language Models (LLMs) trained on Next-Token Prediction (NTP) often suffer from ``Topic Drift'' where the generation wanders away from the initial prompt due to a reliance on local associations rather than global planning \citep{holtzman2019curious}. While scaling model size mitigates this \citep{brown2020language}, the fundamental myopia of the NTP objective remains. In this work, we introduce the Idea-Gated Transformer, a novel architecture that separates semantic planning from syntactic generation. We introduce an auxiliary ``Idea Head'' trained to predict the bag-of-words distribution for a future context window, creating a latent ``Concept Vector'' that actively gates the main vocabulary during generation. We propose a differentiable gating mechanism that suppresses semantically irrelevant tokens, effectively pruning the search space in real-time. Experiments on WikiText-103 demonstrate that while the Idea-Gated model achieves comparable validation perplexity to a standard GPT-2 baseline, it exhibits significantly superior Domain Retention. Qualitative and quantitative analysis reveals that the gating mechanism successfully locks generation into specific semantic clusters (e.g., Finance, Science) and resists associative drift, offering a parameter-efficient path toward more controllable language modeling.

</details>


### [126] [From Hypothesis to Premises: LLM-based Backward Logical Reasoning with Selective Symbolic Translation](https://arxiv.org/abs/2512.03360)
*Qingchuan Li,Mingyue Cheng,Zirui Liu,Daoyu Wang,Yuting Zeng,Tongxuan Liu*

Main category: cs.CL

TL;DR: 本文提出了一种全新的假设驱动向后推理框架（HBLR），通过更高效、更准确地解决现有大模型逻辑推理中的冗余与失真问题，在五个推理基准数据集上均超越基准方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在自然语言推理领域取得了重要进展，但主流的顺向推理方法存在冗余推理路径、虚构步骤和语义漂移等弊端，降低了推理的效率与可靠性。因而，作者希望通过新的推理框架，提升推理准确性和效率。

Method: 作者提出了HBLR框架，分为两个关键阶段：1）信心感知的符号化翻译模块，将高置信度内容转为一阶逻辑等符号形式，不确定内容保持自然语言，并通过反思模块确保语义完整性；2）推理阶段通过假设结论成立并倒推验证前提，模拟人类演绎思维，同时用反思模块发现纠正规则错误，提升连贯性。

Result: 在五个主流逻辑推理基准数据集上，HBLR在准确率与推理效率方面均优于当前强基线方法，展示出更强的推理能力和稳健性。

Conclusion: 假设驱动的向后逻辑推理框架（HBLR）有效缓解了大语言模型在推理任务中存在的关键问题，推动了AI逻辑推理能力的提升，对科学发现和复杂决策亦有潜力应用。

Abstract: Logical reasoning is a core challenge in natural language understanding and a fundamental capability of artificial intelligence, underpinning scientific discovery, mathematical theorem proving, and complex decision-making. Despite the remarkable progress of large language models (LLMs), most current approaches still rely on forward reasoning paradigms, generating step-by-step rationales from premises to conclusions. However, such methods often suffer from redundant inference paths, hallucinated steps, and semantic drift, resulting in inefficient and unreliable reasoning. In this paper, we propose a novel framework, Hypothesis-driven Backward Logical Reasoning (HBLR). The core idea is to integrate confidence-aware symbolic translation with hypothesis-driven backward reasoning. In the translation phase, only high-confidence spans are converted into logical form, such as First-Order Logic (FOL), while uncertain content remains in natural language. A translation reflection module further ensures semantic fidelity by evaluating symbolic outputs and reverting lossy ones back to text when necessary. In the reasoning phase, HBLR simulates human deductive thinking by assuming the conclusion is true and recursively verifying its premises. A reasoning reflection module further identifies and corrects flawed inference steps, enhancing logical coherence. Extensive experiments on five reasoning benchmarks demonstrate that HBLR consistently outperforms strong baselines in both accuracy and efficiency.

</details>


### [127] [Nexus: Higher-Order Attention Mechanisms in Transformers](https://arxiv.org/abs/2512.03377)
*Hanting Chen,Chu Zhong,Kai Han,Yuchuan Tian,Yuchen Liang,Tianyu Guo,Xinghao Chen,Dacheng Tao,Yunhe Wang*

Main category: cs.CL

TL;DR: 作者提出了Higher-Order Attention Network (Hon)，通过递归式自注意力提升Transformer的表达能力，有效突破了线性瓶颈且几乎不增加参数量，在多个基准任务上效果优于标准Transformer。


<details>
  <summary>Details</summary>
Motivation: 标准Transformer的自注意力机制受限于低秩瓶颈，难以在单层中建模复杂的多跳关系，影响表达能力。作者希望设计更强的注意力结构，提升对复杂关系的建模能力。

Method: 提出Higher-Order Attention Network (Hon)架构，采用递归自注意力机制，不同于现有方法的静态线性Query和Key投影，Hon通过嵌套的自注意力循环来动态细化Query和Key，使得每个token能在最终注意力计算前多次聚合全局上下文和高阶相关性。方法还采用高效的权重共享设计，使参数开销基本不变。

Result: 理论上证明Hon能突破标准注意力的线性低秩瓶颈；实验上，Hon在多个基准任务上表现优于标准Transformer。

Conclusion: 递归自注意力结构可有效提升注意力机制的建模能力，几乎不带来额外参数开销，为Transformer在复杂任务中的应用提供了更有力的表达工具。

Abstract: Transformers have achieved significant success across various domains, relying on self-attention to capture dependencies. However, the standard first-order attention mechanism is often limited by a low-rank bottleneck, struggling to capture intricate, multi-hop relationships within a single layer. In this paper, we propose the \textbf{Higher-Order Attention Network (Hon)}, a novel architecture designed to enhance representational power through a recursive framework. Unlike standard approaches that use static linear projections for Queries and Keys, Hon dynamically refines these representations via nested self-attention mechanisms. Specifically, the Query and Key vectors are themselves outputs of inner attention loops, allowing tokens to aggregate global context and model high-order correlations \textit{prior} to the final attention computation. We enforce a parameter-efficient weight-sharing strategy across recursive steps, ensuring that this enhanced expressivity incurs $\mathcal{O}(1)$ additional parameters. We provide theoretical analysis demonstrating that our method breaks the linear bottleneck of standard attention. Empirically, Hon outperforms standard Transformers on multiple benchmarks.

</details>


### [128] [Characterizing Language Use in a Collaborative Situated Game](https://arxiv.org/abs/2512.03381)
*Nicholas Tomlin,Naitian Zhou,Eve Fleisig,Liangyuan,Chen,Téa Wright,Lauren Vinh,Laura X. Ma,Seun Eisape,Ellie French,Tingting Du,Tianjiao Zhang,Alexander Koller,Alane Suhr*

Main category: cs.CL

TL;DR: 本文提出并公开了Portal Dialog语料库，这是一个基于Portal 2合作模式下收集的人类对话数据集，特别适合研究复杂合作情境下的语言现象。


<details>
  <summary>Details</summary>
Motivation: 现有对话语料库多为闲聊或简单任务导向，缺乏复杂协作与推理场景下的语言数据。该研究旨在提供丰富的、面向复杂环境中协作交流的数据资源，促进对语言现象更深入的研究。

Method: 作者在热门视频游戏Portal 2的合作模式中录制了11.5小时、约2.45万句玩家对话，数据包括视频、音频、转录文本、游戏状态以及手工和自动标注。随后，作者分析了其中罕见但重要的语言现象，如复杂空间指代、澄清修补和临时约定的形成。

Result: 研究发现合作游戏语境下出现了大量在现有语料库中少见的语言现象，并系统整理了数据结构和相关注释，便于后续研究。

Conclusion: Portal Dialogue Corpus为研究复杂协作互动下的语言行为提供了珍贵资源，将推动自然语言处理和对话系统等领域在实际任务环境下的研究。

Abstract: Cooperative video games, where multiple participants must coordinate by communicating and reasoning under uncertainty in complex environments, yield a rich source of language data. We collect the Portal Dialogue Corpus: a corpus of 11.5 hours of spoken human dialogue in the co-op mode of the popular Portal 2 virtual puzzle game, comprising 24.5K total utterances. We analyze player language and behavior, identifying a number of linguistic phenomena that rarely appear in most existing chitchat or task-oriented dialogue corpora, including complex spatial reference, clarification and repair, and ad-hoc convention formation. To support future analyses of language use in complex, situated, collaborative problem-solving scenarios, we publicly release the corpus, which comprises player videos, audio, transcripts, game state data, and both manual and automatic annotations of language data.

</details>


### [129] [Dual LoRA: Enhancing LoRA with Magnitude and Direction Updates](https://arxiv.org/abs/2512.03402)
*Yixing Xu,Chao Li,Xuanwu Yin,Spandan Tiwari,Dong Li,Ashish Sirasao,Emad Barsoum*

Main category: cs.CL

TL;DR: 本文提出了一种名为Dual LoRA的新方法，通过引入额外的归纳偏置改进了传统LoRA低秩适应策略，从而提升大语言模型微调效果，在多项NLP任务和多种主流模型上均优于原有方法。


<details>
  <summary>Details</summary>
Motivation: 当前LoRA等高效微调方法虽然参数节省显著，但由于低秩假设，常常在某些任务上表现不佳。作者希望通过改进LoRA结构，提升其在下游任务上的性能。

Method: Dual LoRA将LoRA中的低秩矩阵分为两个组：幅值组和方向组，分别用来控制参数更新幅度和方向。具体实现中，幅值组用ReLU激活，方向组用符号函数，模拟完整微调中的参数更新过程。

Result: 在GPT-2、RoBERTa、DeBERTa、LLaMA-1/2/3等多种模型和NLG、NLU、常识推理等多项NLP任务中，Dual LoRA在相同参数条件下显著优于LoRA原方法及其先进变体。

Conclusion: Dual LoRA有效提升了LoRA微调方法的能力，为参数高效微调大模型提供了更优新方案，具有良好的应用前景。

Abstract: Low-rank adaptation (LoRA) is one of the most popular methods among parameter-efficient fine-tuning (PEFT) methods to adapt pre-trained large language models (LLMs) to specific downstream tasks. However, the model trained based on LoRA often has an unsatisfactory performance due to its low-rank assumption. In this paper, we propose a novel method called Dual LoRA to improve the performance by incorporating an inductive bias into the original LoRA. Specifically, we separate low-rank matrices into two groups: the magnitude group to control whether or not and how far we should update a parameter and the direction group to decide whether this parameter should move forward or backward, to better simulate the parameter updating process of the full fine-tuning based on gradient-based optimization algorithms. We show that this can be simply achieved by adding a ReLU function to the magnitude group and a sign function to the direction group. We conduct several experiments over a wide range of NLP tasks, including natural language generation (NLG), understanding (NLU), and commonsense reasoning datasets on GPT-2, RoBERTa, DeBERTa, and LLaMA-1/2/3 as baseline models. The results show that we consistently outperform LoRA and its state-of-the-art variants with the same number of trainable parameters.

</details>


### [130] [PretrainZero: Reinforcement Active Pretraining](https://arxiv.org/abs/2512.03442)
*Xingrun Xing,Zhiyuan Fan,Jie Lou,Guoqi Li,Jiajun Zhang,Debing Zhang*

Main category: cs.CL

TL;DR: 本文提出了PretrainZero框架，在无监督和无标签条件下，利用强化学习在大规模预训练语料上主动学习，从而显著提升基础大模型的通用推理能力，突破了依赖可验证奖励的数据瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的大型模型在某些领域（如软件、数学）可达到专家水平，但依赖于特定领域内可验证奖励，难以扩展至更广泛的推理任务及通用智能。

Method: 提出PretrainZero，一种主动强化学习框架。该框架让模型像人类一样主动从预训练语料中发现有价值的知识片段，并用RL推理预测其内容。方法完全自监督，无需人工标签或奖励模型，直接在维基百科等通用语料上预训练，并通过解决更难的填空任务持续提升能力。

Result: PretrainZero能大幅提升从3B到30B规模基座模型的推理表现。以Qwen3-4B-Base为例，在MMLU-Pro、SuperGPQA和数学平均基准上分别提升8.43、5.96和10.60分。

Conclusion: PretrainZero打破了现有RL模型对可验证奖励的依赖，极大提升了基础大模型的通用推理能力，为未来通用人工智能的发展提供了新范式。

Abstract: Mimicking human behavior to actively learning from general experience and achieve artificial general intelligence has always been a human dream. Recent reinforcement learning (RL) based large-thinking models demonstrate impressive expert-level abilities, i.e., software and math, but still rely heavily on verifiable rewards in specific domains, placing a significant bottleneck to extend the performance boundary of general reasoning capabilities. In this work, we propose PretrainZero, a reinforcement active learning framework built on the pretraining corpus to extend RL from domain-specific post-training to general pretraining. PretrainZero features the following characteristics: 1) Active pretraining: inspired by the active learning ability of humans, PretrainZero learns a unified reasoning policy to actively identify reasonable and informative contents from pretraining corpus, and reason to predict these contents by RL. 2) Self-supervised learning: without any verifiable labels, pretrained reward models, or supervised fine-tuning, we directly pretrain reasoners from 3 to 30B base models on the general Wikipedia corpus using RL, significantly breaking the verification data-wall for general reasoning. 3) Verification scaling: by tackling increasingly challenging masked spans, PretrainZero substantially enhances the general reasoning abilities of pretrained base models. In reinforcement pretraining, PretrainZero improves Qwen3-4B-Base for 8.43, 5.96 and 10.60 on MMLU-Pro, SuperGPQA and math average benchmarks. In post-training, the pretrained models can also serve as reasoning foundation models for downstream RLVR tasks.

</details>


### [131] [A Preliminary Study on the Promises and Challenges of Native Top-$k$ Sparse Attention](https://arxiv.org/abs/2512.03494)
*Di Xiu,Hongyin Tang,Bolin Rong,Lizhi Yan,Jingang Wang,Yifan Lu,Xunliang Cai*

Main category: cs.CL

TL;DR: 本文系统研究了Top-k注意力机制在大型语言模型解码和训练阶段的有效性及原理，发现该机制通过保留关键k个注意力项，能大幅提升推理效率，并在部分任务上保持甚至超越全量注意力的表现。作者还分析了Top-k近似算法和熵视角对模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 长上下文建模已成为大语言模型的重要能力，但其高昂的推理计算成本限制了实际应用（如智能体和多模态任务），作者希望通过优化注意力机制，降低推理成本，同时保持或提升性能。

Method: 作者在解码和训练阶段分别引入并评估了精确Top-k和近似Top-k注意力机制，通过下游任务实验证明其有效性，并从训练-推理一致性和近似精度对性能影响进行分析，还从熵的角度解释了Top-k注意力的理论基础。

Result: 1. 精确Top-k解码在HELMET、LongBench v2等任务上能达到或超过全量注意力。
2. 训练时采用一致的Top-k方式能进一步提升推理性能。
3. 近似Top-k精度越高，下游表现越好。
4. 采用Top-k注意力微调的模型在下游任务中表现为熵值下降，支持低熵优势理论。

Conclusion: Top-k注意力机制是一种高效的长上下文建模手段，其正确实施可显著减少推理计算量，并保障甚至提升下游任务表现；尤其是训练和推理阶段保持一致性、选取高精度近似算法，有助于充分释放Top-k注意力潜力，并通过降低模型熵带来更优适应性。

Abstract: Large Language Models (LLMs) are increasingly prevalent in the field of long-context modeling, however, their inference computational costs have become a critical bottleneck hindering the advancement of tasks such as agents and multimodal applications. This report conducts a preliminary investigation into the effectiveness and theoretical mechanisms of the Top-$k$ Attention mechanism during both the decoding and training phases. First, we validate the effectiveness of exact Top-$k$ Decoding through extensive experimentation. Experiments demonstrate that retaining only the pivotal Keys with the highest similarity to the Query as the context window during the decoding stage achieves performance comparable to, or even surpassing, full attention on downstream tasks such as HELMET and LongBench v2. Second, we further explore the native Top-$k$ Attention training strategy. Experiments confirm that ensuring the consistency between training and inference regarding Top-$k$ Attention operations facilitates the further unlocking of Top-$k$ Decoding's potential, thereby significantly enhancing model performance. Furthermore, considering the high computational complexity of exact Top-$k$ Attention, we investigate the impact of approximate Top-$k$ algorithm precision on downstream tasks. Our research confirms a positive correlation between downstream task performance and approximation fidelity, and we provide statistical evaluations of the Lightning Indexer's precision within the DeepSeek-V3.2-Exp model. Finally, this report provides a theoretical interpretation from the perspective of Entropy. Experimental observations indicate that models subjected to Top-$k$ Attention SFT exhibit a distinct phenomenon of entropy reduction in downstream tasks, which validates the hypothesis that low-entropy states are better adapted to Top-$k$ Decoding.

</details>


### [132] [Understanding LLM Reasoning for Abstractive Summarization](https://arxiv.org/abs/2512.03503)
*Haohan Yuan,Siu Cheung Hui,Haopeng Zhang*

Main category: cs.CL

TL;DR: 本文系统比较了多种大语言模型（LLM）推理策略在抽象摘要任务中的效果，发现推理方法并不能普遍提升摘要表现，其效果依赖于具体策略和情境。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在数学和代码等分析类任务中表现出色，但其在抽象摘要任务中的推理能力尚未经过系统验证。作者为弥补这一研究空白，对推理策略在摘要领域的适用性进行了深入探究。

Method: 作者将通用推理策略调整以适应摘要场景，并在8个多样化数据集上，系统性比较了8种推理策略和3种大型推理模型（LRMs）在摘要质量与忠实性方面的表现。

Result: 研究发现，推理策略的有效性依赖于具体使用场景，不能一概而论。明确的推理策略提升流畅性但可能损害事实基础，而隐式推理则有相反趋势。此外，增加模型推理预算未必提高事实一致性，反而可能导致不准确。

Conclusion: 有效的摘要更依赖忠实的信息压缩而非“过度创造”，推理不是解决摘要任务的万能方法，需权衡质量与忠实性。

Abstract: While the reasoning capabilities of Large Language Models (LLMs) excel in analytical tasks such as mathematics and code generation, their utility for abstractive summarization remains widely assumed but largely unverified. To bridge this gap, we first tailor general reasoning strategies to the summarization domain. We then conduct a systematic, large scale comparative study of 8 reasoning strategies and 3 Large Reasoning Models (LRMs) across 8 diverse datasets, assessing both summary quality and faithfulness. Our findings show that reasoning is not a universal solution and its effectiveness is highly dependent on the specific strategy and context. Specifically, we observe a trade-off between summary quality and factual faithfulness: explicit reasoning strategies tend to improve fluency at the expense of factual grounding, while implicit reasoning in LRMs exhibits the inverse pattern. Furthermore, increasing an LRM's internal reasoning budget does not improve, and can even hurt, factual consistency, suggesting that effective summarization demands faithful compression rather than creative over-thinking.

</details>


### [133] [Fine-grained Narrative Classification in Biased News Articles](https://arxiv.org/abs/2512.03582)
*Zeba Afroz,Harsh Vardhan,Pawan Bhakuni,Aanchal Punia,Rajdeep Kumar,Md. Shad Akhtar*

Main category: cs.CL

TL;DR: 本文提出用于分析印度新闻媒体宣传的细粒度叙事识别方法，开发了首个细粒度叙事数据集INDI-PROP，并设计了两种新模型用于分类，取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前对偏见新闻的叙事和宣传分析多以粗粒度类别为主，缺乏对叙事故事背后深层次认知、情感手法的精细区分，尤其在印度等特定媒体语境下，对意识形态宣传的识别工具有限。因此，作者希望开发细粒度叙事分类方法和数据集，使对新闻偏见与宣传技术的分析更加系统和精准。

Method: 作者首先创建了INDI-PROP数据集，包括1,266篇涉及印度两大社会事件（CAA与农民抗议）的新闻文章，并进行三层次注释：文章整体偏见、事件相关具体叙事框架、宣传说服技术。随后，作者提出了两种多跳推理框架FANTA和TPTC，分别利用多层次语义整合与分阶段推理，通过GPT-4o-mini引导提示，实现对文章偏见、叙事实例及宣传技术的自动识别。

Result: 实验结果显示所提出的数据集和方法在叙事、偏见、宣传技术等多任务分类上，均较现有基本模型（baseline）有显著提升。

Conclusion: 本文首次提出基于印度新闻特有语境的多层次叙事注释体系和数据集，结合创新推理模型显著提升了宣传分析精度，为进一步理解和自动检测新闻媒体意识形态宣传提供有效支撑。

Abstract: Narratives are the cognitive and emotional scaffolds of propaganda. They organize isolated persuasive techniques into coherent stories that justify actions, attribute blame, and evoke identification with ideological camps. In this paper, we propose a novel fine-grained narrative classification in biased news articles. We also explore article-bias classification as the precursor task to narrative classification and fine-grained persuasive technique identification. We develop INDI-PROP, the first ideologically grounded fine-grained narrative dataset with multi-level annotation for analyzing propaganda in Indian news media. Our dataset INDI-PROP comprises 1,266 articles focusing on two polarizing socio-political events in recent times: CAA and the Farmers' protest. Each article is annotated at three hierarchical levels: (i) ideological article-bias (pro-government, pro-opposition, neutral), (ii) event-specific fine-grained narrative frames anchored in ideological polarity and communicative intent, and (iii) persuasive techniques. We propose FANTA and TPTC, two GPT-4o-mini guided multi-hop prompt-based reasoning frameworks for the bias, narrative, and persuasive technique classification. FANTA leverages multi-layered communicative phenomena by integrating information extraction and contextual framing for hierarchical reasoning. On the other hand, TPTC adopts systematic decomposition of persuasive cues via a two-stage approach. Our evaluation suggests substantial improvement over underlying baselines in each case.

</details>


### [134] [AlignCheck: a Semantic Open-Domain Metric for Factual Consistency Assessment](https://arxiv.org/abs/2512.03634)
*Ahmad Aghaebrahimian*

Main category: cs.CL

TL;DR: 本文提出一种可解释的事实一致性评估框架，旨在更好评价大语言模型生成内容的事实准确性，尤其关注临床等高风险领域。该方法分解文本为原子事实，并引入加权评价指标和复杂度控制机制，在通用和医学领域取得良好效果。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在自然语言任务上表现优异，但常出现“幻觉”问题，即生成内容自洽但事实错误，尤以医疗等高风险领域为甚。当前评估标准难以判定事实一致性且缺乏可解释性，影响错误诊断与减缓。

Method: 该方法将文本分解为原子事实，采用无结构、可扩展（schema-free）体系进行灵活评估，并创新性地引入加权综合指标取代绝对评价。此外，提出控制评估复杂性的机制，适配复杂领域。

Result: 作者在通用及医疗领域公开数据集上对方法进行了基准测试，结果显示该方法能更好地评估事实一致性，并提升模型事实感知训练能力。同时，相关代码开放。

Conclusion: 本文方法在提升评估可解释性及事实准确性方面优于现有标准，为高风险领域大模型输出的安全性保障和未来事实感知模型的研究提供了基础。

Abstract: Large Language Models have significantly advanced natural language processing tasks, but remain prone to generating incorrect or misleading but plausible arguments. This issue, known as hallucination, is particularly concerning in high-stakes domains like clinical applications, where factual inaccuracies can have severe consequences. Existing evaluation metrics fail to adequately assess factual consistency and lack interpretability, making diagnosing and mitigating errors difficult. We propose an interpretable framework for factual consistency assessment for in-domain and open-domain texts to address these limitations. Our approach decomposes text into atomic facts and introduces a flexible, schema-free methodology. Unlike previous methods with an absolute metric, we incorporate a weighted metric to enhance factual evaluation. Additionally, we propose a mechanism to control assessment complexity in intricate domains. We benchmark our approach on popular general and clinical datasets and release our code to support fact-aware model training in future research.

</details>


### [135] [Generative AI Practices, Literacy, and Divides: An Empirical Analysis in the Italian Context](https://arxiv.org/abs/2512.03671)
*Beatrice Savoldi,Giuseppe Attanasio,Olga Gorodetskaya,Marta Marchiori Manerba,Elisa Bassignana,Silvia Casola,Matteo Negri,Tommaso Caselli,Luisa Bentivogli,Alan Ramponi,Arianna Muti,Nicoletta Balbo,Debora Nozza*

Main category: cs.CL

TL;DR: 本文通过对意大利1906名成年人的问卷调查，系统分析了生成式人工智能（GenAI）在意大利的采用、使用模式与素养现状，揭示了其在工作、生活等多场景下的广泛应用及相关风险。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能聊天机器人等语言技术的兴起，数字交流正在发生变革。尽管相关技术具有社会潜力，但由于采用不均和用户对其局限性认知不足，可能加剧数字鸿沟。本文试图通过实证研究，全面刻画意大利地区GenAI的普及及影响。

Method: 研究基于对1906名意大利语成年人的问卷调查，收集他们对GenAI的使用、用途及认知等数据，开展大样本定量分析，并关注性别、年龄、素养等分群差异。

Result: GenAI在意大利被广泛用于工作和生活（包括情感和医疗咨询等敏感领域），并取代了其他信息来源。尽管如此，用户数字素养普遍较低，难以识别错误或虚假信息；女性（尤其年长者）使用率远低于男性，且素养虽能预测采用但无法完全解释性别差异，意味着还存在其他障碍。

Conclusion: GenAI应用普及加剧了因素养和性别带来的数字鸿沟。有必要针对性推进教育提升，并进一步探索影响公平参与的深层次原因。

Abstract: The rise of Artificial Intelligence (AI) language technologies, particularly generative AI (GenAI) chatbots accessible via conversational interfaces, is transforming digital interactions. While these tools hold societal promise, they also risk widening digital divides due to uneven adoption and low awareness of their limitations. This study presents the first comprehensive empirical mapping of GenAI adoption, usage patterns, and literacy in Italy, based on newly collected survey data from 1,906 Italian-speaking adults. Our findings reveal widespread adoption for both work and personal use, including sensitive tasks like emotional support and medical advice. Crucially, GenAI is supplanting other technologies to become a primary information source: this trend persists despite low user digital literacy, posing a risk as users struggle to recognize errors or misinformation. Moreover, we identify a significant gender divide -- particularly pronounced in older generations -- where women are half as likely to adopt GenAI and use it less frequently than men. While we find literacy to be a key predictor of adoption, it only partially explains this disparity, suggesting that other barriers are at play. Overall, our data provide granular insights into the multipurpose usage of GenAI, highlighting the dual need for targeted educational initiatives and further investigation into the underlying barriers to equitable participation that competence alone cannot explain.

</details>


### [136] [Evaluating Hydro-Science and Engineering Knowledge of Large Language Models](https://arxiv.org/abs/2512.03672)
*Shiruo Hu,Wenbo Shan,Yingjia Li,Zhiqi Wan,Xinpeng Yu,Yunjia Qi,Haotian Xia,Yang Xiao,Dingxiao Liu,Jiaru Wang,Chenxu Gong,Ruixi Zhang,Shuyue Wu,Shibo Cui,Chee Hui Lai,Wei Luo,Yubin He,Bin Xu,Jianshi Zhao*

Main category: cs.CL

TL;DR: 本文提出了Hydro-SE LLM评测基准（Hydro-SE Bench），用于系统评估大语言模型（LLMs）在水科学与工程领域的知识与应用能力。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型快速发展，其在水科学与工程（Hydro-SE）领域的应用潜力备受关注，但目前尚缺乏针对该领域的系统评测方法。为弥补这一空白，作者希望设计一套系统评估大模型在该领域知识和应用能力的基准。

Method: 作者提出了Hydro-SE Bench，包括九个子领域共4000道选择题，用于考察模型的基础知识、工程应用和推理计算能力，并以此测试多个主流和小参数LLM的表现。

Result: 测评结果显示，商用LLM的正确率为0.74~0.80，小参数LLM为0.41~0.68。LLM在自然科学相关子领域表现较好，但在行业标准和水工结构等特定知识方向较弱，且模型扩展主要提升了推理和计算能力。

Conclusion: LLM在Hydro-SE任务中表现出明显优劣，未来有较大提升空间。本研究为模型开发者提供了明确的训练目标，也为Hydro-SE领域的研究者应用LLM提供了参考和指导。

Abstract: Hydro-Science and Engineering (Hydro-SE) is a critical and irreplaceable domain that secures human water supply, generates clean hydropower energy, and mitigates flood and drought disasters. Featuring multiple engineering objectives, Hydro-SE is an inherently interdisciplinary domain that integrates scientific knowledge with engineering expertise. This integration necessitates extensive expert collaboration in decision-making, which poses difficulties for intelligence. With the rapid advancement of large language models (LLMs), their potential application in the Hydro-SE domain is being increasingly explored. However, the knowledge and application abilities of LLMs in Hydro-SE have not been sufficiently evaluated. To address this issue, we propose the Hydro-SE LLM evaluation benchmark (Hydro-SE Bench), which contains 4,000 multiple-choice questions. Hydro-SE Bench covers nine subfields and enables evaluation of LLMs in aspects of basic conceptual knowledge, engineering application ability, and reasoning and calculation ability. The evaluation results on Hydro-SE Bench show that the accuracy values vary among 0.74 to 0.80 for commercial LLMs, and among 0.41 to 0.68 for small-parameter LLMs. While LLMs perform well in subfields closely related to natural and physical sciences, they struggle with domain-specific knowledge such as industry standards and hydraulic structures. Model scaling mainly improves reasoning and calculation abilities, but there is still great potential for LLMs to better handle problems in practical engineering application. This study highlights the strengths and weaknesses of LLMs for Hydro-SE tasks, providing model developers with clear training targets and Hydro-SE researchers with practical guidance for applying LLMs.

</details>


### [137] [Different types of syntactic agreement recruit the same units within large language models](https://arxiv.org/abs/2512.03676)
*Daria Kryvosheieva,Andrea de Varda,Evelina Fedorenko,Greta Tuckute*

Main category: cs.CL

TL;DR: 本论文探究了大语言模型（LLM）内部如何表征语法知识，发现不同的句法现象会激活重叠或独特的模型单元，尤其是语法一致性相关的单元有明显重叠。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM可以区分语法正确与否的句子，但模型内部如何表示这种语法知识仍未明朗。作者希望解析各种句法现象在模型中的表征机制，特别关注模型是否以共享或独立的方式处理句法一致性等现象。

Method: 作者采用了受认知神经科学启发的“功能定位”方法，在七个开源权重的大模型中，定位对于67种英语句法现象反应最强的单元，并分析这些单元在不同语言（英语、俄语、中文等）及跨57种语言的一致性。

Result: 在同一类型句法一致性（如主谓一致、照应一致、限定词-名词一致）中，发现模型激活的单元有较大重叠，不同类型一致性则有所差异。多语言分析表明，结构更相近的语言之间在主谓一致相关单元上的重叠更显著。

Conclusion: 句法一致性是LLM表征空间中的一个有意义的功能类别，不同语言和不同类型的一致性处理也显示出相似的神经功能组织，这加深了对LLM内部语法机制的理解。

Abstract: Large language models (LLMs) can reliably distinguish grammatical from ungrammatical sentences, but how grammatical knowledge is represented within the models remains an open question. We investigate whether different syntactic phenomena recruit shared or distinct components in LLMs. Using a functional localization approach inspired by cognitive neuroscience, we identify the LLM units most responsive to 67 English syntactic phenomena in seven open-weight models. These units are consistently recruited across sentences containing the phenomena and causally support the models' syntactic performance. Critically, different types of syntactic agreement (e.g., subject-verb, anaphor, determiner-noun) recruit overlapping sets of units, suggesting that agreement constitutes a meaningful functional category for LLMs. This pattern holds in English, Russian, and Chinese; and further, in a cross-lingual analysis of 57 diverse languages, structurally more similar languages share more units for subject-verb agreement. Taken together, these findings reveal that syntactic agreement-a critical marker of syntactic dependencies-constitutes a meaningful category within LLMs' representational spaces.

</details>


### [138] [AITutor-EvalKit: Exploring the Capabilities of AI Tutors](https://arxiv.org/abs/2512.03688)
*Numaan Naeem,Kaushal Kumar Maurya,Kseniia Petukhova,Ekaterina Kochmar*

Main category: cs.CL

TL;DR: 本文介绍了AITutor-EvalKit，这是一款用于评估AI助教教学质量的应用，并提供了相关的软件工具。


<details>
  <summary>Details</summary>
Motivation: 当前AI助教在教育领域越来越普及，但缺乏标准化、自动化的教学质量评估工具，因此需要开发相关评估系统。

Method: 开发了AITutor-EvalKit应用，该工具结合了语言技术，对AI助教的教学质量进行评价，并配备了演示、评测、模型检查和数据可视化等功能。

Result: AITutor-EvalKit不仅实现了AI tutor质量评价，还支持用户反馈和标注数据的收集，利于教育相关方和ACL社区应用和研究。

Conclusion: AITutor-EvalKit为AI助教的质量评估提供了有效工具，有助于推动教育技术和自然语言处理领域的发展。

Abstract: We present AITutor-EvalKit, an application that uses language technology to evaluate the pedagogical quality of AI tutors, provides software for demonstration and evaluation, as well as model inspection and data visualization. This tool is aimed at education stakeholders as well as *ACL community at large, as it supports learning and can also be used to collect user feedback and annotations.

</details>


### [139] [DZ-TDPO: Non-Destructive Temporal Alignment for Mutable State Tracking in Long-Context Dialogue](https://arxiv.org/abs/2512.03704)
*Yijun Liao*

Main category: cs.CL

TL;DR: 该论文提出DZ-TDPO框架，通过动态KL约束与可学习时序注意力偏置，提升长对话系统处理历史上下文与用户意图冲突的能力，实现了最新的性能表现。


<details>
  <summary>Details</summary>
Motivation: 长文本对话系统在处理用户意图变化与历史上下文冲突时，常受限于“状态惰性”问题，导致模型无法准确响应最新意图。作者希望解决这一对话语境下的权衡难题。

Method: 作者提出了DZ-TDPO非破坏性对齐框架，结合冲突感知的动态KL约束和可学习的时序注意力偏置，对模型注意力机制进行精细调节，以缓解历史上下文带来的惰性问题。

Result: DZ-TDPO在Multi-Session Chat数据集上取得了业内领先的胜率（Phi-3.5模型86.2%），并能良好泛化至零样本情境。规模扩展分析揭示小模型为对齐需付出困惑度（perplexity）损失，但大模型可几乎无成本达到完美对齐。

Conclusion: 通过精准注意力调控可缓解状态惰性，无需破坏性地调整权重，同时保持模型泛化能力。所提方法具备跨模型规模的优势。

Abstract: Long-context dialogue systems suffer from State Inertia, where static constraints prevent models from resolving conflicts between evolving user intents and established historical context. To address this, we propose DZ-TDPO, a non-destructive alignment framework that synergizes conflict-aware dynamic KL constraints with a learnable temporal attention bias. Experiments on the Multi-Session Chat (MSC) dataset demonstrate that DZ-TDPO achieves state-of-the-art win rates (86.2% on Phi-3.5) while maintaining robust zero-shot generalization. Crucially, our scaling analysis reveals a "Capacity-Stability Trade-off": while smaller models incur an "alignment tax" (perplexity surge) to overcome historical inertia, the larger Qwen2.5-7B model achieves near-perfect alignment (99.4% win rate) with negligible perplexity overhead. This confirms that TAI can be alleviated via precise attention regulation rather than destructive weight updates, preserving general capabilities (MMLU) across model scales. Code and data are available: https://github.com/lyj20071013/DZ-TDPO

</details>


### [140] [AR-Med: Automated Relevance Enhancement in Medical Search via LLM-Driven Information Augmentation](https://arxiv.org/abs/2512.03737)
*Chuyue Wang,Jie Feng,Yuxi Wu,Hang Zhang,Zhiguo Fan,Bing Cheng,Wei Lin*

Main category: cs.CL

TL;DR: 本文提出并实地部署了AR-Med，一个用于医疗平台的自动化医学检索相关性评估系统，结合大语言模型与检索增强技术，有效提升了搜索准确性和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 现有在线医疗平台的搜索功能难以理解复杂用户查询，而传统模型在语义理解方面存在不足，导致服务效果有限。因此，急需利用LLM提高搜索准确性，但直接应用又面临幻觉、知识覆盖不足和高成本等难题。

Method: 提出AR-Med框架，通过检索增强让LLM依据已验证医学知识进行推理，并采用知识蒸馏技术，将大型模型压缩为高效的小模型。同时开发了多专家标注的LocalQSMed基准数据集，用于模型评估和优化。

Result: AR-Med在离线实验中达到93%以上准确率，比原系统提升24个百分点，并且在实际线上部署中显著提升了相关性和用户满意度。

Conclusion: AR-Med为医疗场景中大模型的可信和可扩展应用提供了实用蓝图，实现了高准确性、低成本和强泛化能力，为实际医疗服务赋能。

Abstract: Accurate and reliable search on online healthcare platforms is critical for user safety and service efficacy. Traditional methods, however, often fail to comprehend complex and nuanced user queries, limiting their effectiveness. Large language models (LLMs) present a promising solution, offering powerful semantic understanding to bridge this gap. Despite their potential, deploying LLMs in this high-stakes domain is fraught with challenges, including factual hallucinations, specialized knowledge gaps, and high operational costs. To overcome these barriers, we introduce \textbf{AR-Med}, a novel framework for \textbf{A}utomated \textbf{R}elevance assessment for \textbf{Med}ical search that has been successfully deployed at scale on the Online Medical Delivery Platforms. AR-Med grounds LLM reasoning in verified medical knowledge through a retrieval-augmented approach, ensuring high accuracy and reliability. To enable efficient online service, we design a practical knowledge distillation scheme that compresses large teacher models into compact yet powerful student models. We also introduce LocalQSMed, a multi-expert annotated benchmark developed to guide model iteration and ensure strong alignment between offline and online performance. Extensive experiments show AR-Med achieves an offline accuracy of over 93\%, a 24\% absolute improvement over the original online system, and delivers significant gains in online relevance and user satisfaction. Our work presents a practical and scalable blueprint for developing trustworthy, LLM-powered systems in real-world healthcare applications.

</details>


### [141] [Principled RL for Diffusion LLMs Emerges from a Sequence-Level Perspective](https://arxiv.org/abs/2512.03759)
*Jingyang Ou,Jiaqi Han,Minkai Xu,Shaoxuan Xu,Jianwen Xie,Stefano Ermon,Yi Wu,Chongxuan Li*

Main category: cs.CL

TL;DR: 这篇论文提出了一个用于扩散大语言模型（dLLMs）的序列级强化学习框架（ESPO），克服了现有RL方法在dLLMs中面临的似然近似和优化不稳定问题，并在多项任务中实现了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习在自回归语言模型上效果很好，因为它们能够提供所需的条件概率支持RL目标。但dLLMs是非自回归的，难以直接获得token级概率，因此难以应用原有方法，催生了本研究。

Method: 提出ESPO框架，将完整序列生成视为单一动作，用ELBO代替不可用的token级似然。同时，采用token级归一化的重要性比率及鲁棒KL估算以保证训练稳定。

Result: 在数学推理、代码生成及规划任务上的实验表明，ESPO比token级基线有显著优势，例如在Countdown任务上提升了20-40分，数学和代码任务也有持续的提升。

Conclusion: ESPO验证了针对dLLMs进行序列级优化的有效性和优越性，为在此类模型上应用RL提供了可行的范式。

Abstract: Reinforcement Learning (RL) has proven highly effective for autoregressive language models, but adapting these methods to diffusion large language models (dLLMs) presents fundamental challenges. The core difficulty lies in likelihood approximation: while autoregressive models naturally provide token-level conditional probabilities essential for token-level RL objectives (e.g., GRPO), dLLMs generate sequences through iterative non-autoregressive denoising steps that lack this factorization. To address this fundamental mismatch, we propose ELBO-based Sequence-level Policy Optimization (ESPO), a principled RL framework that treats entire sequence generation as a single action and uses the ELBO as a tractable sequence-level likelihood proxy. Our method incorporates per-token normalization of importance ratios and robust KL-divergence estimation to ensure stable large-scale training. Extensive experiments on mathematical reasoning, coding, and planning tasks demonstrate that ESPO significantly outperforms token-level baselines, achieving dramatic improvements of 20-40 points on the Countdown task, while maintaining consistent gains on math and coding benchmarks. Our approach establishes sequence-level optimization as a principled and empirically effective paradigm for RL in dLLMs. Our code is available at https://github.com/ML-GSAI/ESPO.

</details>


### [142] [In-Context Representation Hijacking](https://arxiv.org/abs/2512.03771)
*Itay Yona,Amir Sarid,Michael Karasik,Yossi Gandelsman*

Main category: cs.CL

TL;DR: 本文提出了一种针对大语言模型（LLMs）的新型攻击方法——Doublespeak，即上下文表示劫持，通过巧妙替换上下文中的敏感词，绕过现有的安全对齐措施。


<details>
  <summary>Details</summary>
Motivation: 尽管 LLMs 具备一定的安全对齐机制来阻止有害请求，但攻击者仍在寻找新的绕过方式。论文希望找出模型内部潜在脆弱性，尤其是在表示空间层面，评估现有安全防护措施的有效性。

Method: 作者将有害关键词（如“bomb”）在上下文示例中系统性地替换为无害词汇（如“carrot”），并与有害请求前缀结合，通过连续上下文诱导模型内部表示发生语义迁移。过程中结合模型可解释性工具，分析不同层次的语义变化。

Result: 发现模型内部无害词在早期层意义正常，但在更深层逐渐承载有害词的语义；攻击可在多个主流模型（开源和闭源）上成功转移，Llama-3.3-70B-Instruct 攻击成功率高达74%。

Conclusion: Doublespeak 揭示了 LLMs 在表示空间内的新攻击面，现有安全对齐机制在底层语义移植上存在漏洞，未来应加强表示层级的安全对齐防护。

Abstract: We introduce \textbf{Doublespeak}, a simple \emph{in-context representation hijacking} attack against large language models (LLMs). The attack works by systematically replacing a harmful keyword (e.g., \textit{bomb}) with a benign token (e.g., \textit{carrot}) across multiple in-context examples, provided a prefix to a harmful request. We demonstrate that this substitution leads to the internal representation of the benign token converging toward that of the harmful one, effectively embedding the harmful semantics under a euphemism. As a result, superficially innocuous prompts (e.g., ``How to build a carrot?'') are internally interpreted as disallowed instructions (e.g., ``How to build a bomb?''), thereby bypassing the model's safety alignment. We use interpretability tools to show that this semantic overwrite emerges layer by layer, with benign meanings in early layers converging into harmful semantics in later ones. Doublespeak is optimization-free, broadly transferable across model families, and achieves strong success rates on closed-source and open-source systems, reaching 74\% ASR on Llama-3.3-70B-Instruct with a single-sentence context override. Our findings highlight a new attack surface in the latent space of LLMs, revealing that current alignment strategies are insufficient and should instead operate at the representation level.

</details>


### [143] [Enhancing Instruction-Following Capabilities in Seq2Seq Models: DoLA Adaptations for T5](https://arxiv.org/abs/2512.03803)
*Huey Sun,Anabel Yong,Lorenzo Gilly,Felipe Jin*

Main category: cs.CL

TL;DR: 本论文将对比解码（Contrastive Decoding）方法DoLa首次应用到T5和FLAN-T5这类编码器-解码器架构，并分析其对模型指令遵循能力的影响。


<details>
  <summary>Details</summary>
Motivation: 以往DoLa等对比解码方法仅在decoder-only架构中实现，且多关注事实性提升，未在编码器-解码器架构中探索其指令遵循能力表现。因此，作者希望填补此领域空白。

Method: 将DoLa算法适配至T5和FLAN-T5模型，在多类别任务上进行评测。对FLAN-T5的各层输出概率做细致分析，量化DoLa在生成文本忠实性方面的影响。

Result: 实验结果显示，DoLa方法可以提升部分任务类别文本生成的真实可信度，但对其他类别任务反而有负面影响。

Conclusion: DoLa作为对比解码策略首次成功应用到编码器-解码器架构，在提升部分任务生成文本的忠实性上有效，但其效果受任务类型影响较大，需进一步研究优化。

Abstract: Contrastive decoding is a lightweight and effective inference-time method that improves the quality of text generation in Large Language Models. However, algorithms such as DoLa (Decoding by Contrastive Layers) have only been implemented in decoder-only architectures and studied for their impact on improving factuality. This work adapts DoLa for the T5 and FLAN-T5 model families and evaluates its impact on the models' instruction following capabilities, which to our knowledge is the first implementation of a contrastive decoding strategy in an encoder-decoder architecture. Our results show that DoLa improves the faithfulness of text generation for certain categories of tasks and harms others. To understand these results, we present a layer-by-layer analysis of logit evolution in a FLAN-T5 model to quantify DoLa's impact on token output probabilities.

</details>


### [144] [Improving Alignment Between Human and Machine Codes: An Empirical Assessment of Prompt Engineering for Construct Identification in Psychology](https://arxiv.org/abs/2512.03818)
*Kylie L. Anglin,Stephanie Milan,Brittney Hernandez,Claudia Ventura*

Main category: cs.CL

TL;DR: 本文提出了一个通过prompt工程优化大语言模型（LLMs）文本分类表现的实证框架，并对多种prompt策略进行了系统评估，发现结合经验选择与自动化工程的few-shot prompt最能提升分类一致性。


<details>
  <summary>Details</summary>
Motivation: 鉴于LLM在文本分类中表现出色，但分类结果高度依赖prompt措辞，尤其在心理学等专业领域定义精确、训练数据未必覆盖的情况下，尚缺乏对prompt工程优化分类任务的专门系统研究。

Method: 作者提出并实验评估了五种prompt策略：经验（codebook-guided）选择、自动prompt工程、角色设定（persona）、链式思考（CoT）和解释型prompt。比较它们在zero-shot和few-shot分类的表现，并结合心理学领域的三个概念和两个模型，分析不同prompt特征对分类准确性的影响。

Result: 角色、链式思考和解释型prompt未能显著缓解措辞不佳带来的性能损失。最关键的prompt要素为概念定义、任务表述，其次是案例示例。few-shot下结合经验选择与自动工程的prompt，与专家判断的一致性最佳。

Conclusion: 建议研究者结合人工和自动生成，尽量多生成与评测prompt，基于训练集实证表现优化选择，并用留出集验证，采用该系统性流程可优化需要高专家对齐的分类任务prompt。

Abstract: Due to their architecture and vast pre-training data, large language models (LLMs) demonstrate strong text classification performance. However, LLM output - here, the category assigned to a text - depends heavily on the wording of the prompt. While literature on prompt engineering is expanding, few studies focus on classification tasks, and even fewer address domains like psychology, where constructs have precise, theory-driven definitions that may not be well represented in pre-training data. We present an empirical framework for optimizing LLM performance for identifying constructs in texts via prompt engineering. We experimentally evaluate five prompting strategies --codebook-guided empirical prompt selection, automatic prompt engineering, persona prompting, chain-of-thought reasoning, and explanatory prompting - with zero-shot and few-shot classification. We find that persona, chain-of-thought, and explanations do not fully address performance loss accompanying a badly worded prompt. Instead, the most influential features of a prompt are the construct definition, task framing, and, to a lesser extent, the examples provided. Across three constructs and two models, the classifications most aligned with expert judgments resulted from a few-shot prompt combining codebook-guided empirical prompt selection with automatic prompt engineering. Based on our findings, we recommend that researchers generate and evaluate as many prompt variants as feasible, whether human-crafted, automatically generated, or ideally both, and select prompts and examples based on empirical performance in a training dataset, validating the final approach in a holdout set. This procedure offers a practical, systematic, and theory-driven method for optimizing LLM prompts in settings where alignment with expert judgment is critical.

</details>


### [145] [Training and Evaluation of Guideline-Based Medical Reasoning in LLMs](https://arxiv.org/abs/2512.03838)
*Michael Staniek,Artem Sokolov,Stefan Riezler*

Main category: cs.CL

TL;DR: 本论文提出了一种教会大语言模型（LLM）遵循医学共识指南进行推理和预测的方法，通过将共识规则实例化为结构化数据，对LLM进行微调，以提升预测结果的可解释性和可信度。


<details>
  <summary>Details</summary>
Motivation: 尽管早期医疗预测中机器学习已取得突破，但重视准确性的同时忽略了医学专家所需的推理忠实性和可解释性，限制了其临床应用与信任度。

Method: 作者将医学共识指南中的推理规则“口头化”，并据此对LLM进行微调，让其“按步骤”遵循医学推理流程，并以Sepsis-3共识定义为例验证；此外，还将时间序列预测模型的输出与LLM结合，实现多模态预测。

Result: 微调用于特定医学领域规则实例化数据的小型LLM，在见不到的新患者数据中，对规则推理过程的正确性几乎完美，且超越了大型LLM的临时学习能力和基于医学文本训练的模型。集成时间序列模型能进一步改善对临床变量的未来预测表现。

Conclusion: 细粒度微调LLM可实现医学推理过程的高度忠实与可解释性。早期预测的瓶颈不是对不同领域的泛化，而在于少量、不规则取样临床变量的未来预测，通过多模态方法可进一步弥补这一短板。

Abstract: Machine learning for early prediction in medicine has recently shown breakthrough performance, however, the focus on improving prediction accuracy has led to a neglect of faithful explanations that are required to gain the trust of medical practitioners. The goal of this paper is to teach LLMs to follow medical consensus guidelines step-by-step in their reasoning and prediction process. Since consensus guidelines are ubiquitous in medicine, instantiations of verbalized medical inference rules to electronic health records provide data for fine-tuning LLMs to learn consensus rules and possible exceptions thereof for many medical areas. Consensus rules also enable an automatic evaluation of the model's inference process regarding its derivation correctness (evaluating correct and faithful deduction of a conclusion from given premises) and value correctness (comparing predicted values against real-world measurements). We exemplify our work using the complex Sepsis-3 consensus definition. Our experiments show that small fine-tuned models outperform one-shot learning of considerably larger LLMs that are prompted with the explicit definition and models that are trained on medical texts including consensus definitions. Since fine-tuning on verbalized rule instantiations of a specific medical area yields nearly perfect derivation correctness for rules (and exceptions) on unseen patient data in that area, the bottleneck for early prediction is not out-of-distribution generalization, but the orthogonal problem of generalization into the future by forecasting sparsely and irregularly sampled clinical variables. We show that the latter results can be improved by integrating the output representations of a time series forecasting model with the LLM in a multimodal setup.

</details>


### [146] [Reconstructing KV Caches with Cross-layer Fusion For Enhanced Transformers](https://arxiv.org/abs/2512.03870)
*Hongzhan Lin,Zhiqi Bai,Xinmiao Zhang,Sen Yang,Xiang Li,Siran Yang,Yunlong Xu,Jiaheng Liu,Yongchi Zhao,Jiamang Wang,Yuchi Xu,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: 提出了FusedKV和FusedKV-Lite两种方法，通过跨层KV缓存融合，减少Transformer解码器KV缓存所需的显存，最高可减少50%缓存开销，并保持或提升模型性能。


<details>
  <summary>Details</summary>
Motivation: Transformer解码器在长序列处理时，KV缓存对显存消耗极大，成为大模型部署的瓶颈。现有跨层KV缓存共享（如YOCO, CLA）虽能缓解，但效果不如同层方法（如GQA）。作者希望寻求高效又性能优越的KV缓存机制。

Method: 作者分析了不同层的keys和values在信息流上的来源，发现values主要来自底层，keys则来自底层与中层。基于此，提出了FusedKV：将顶层KV缓存学习性地融合底层与中层最有信息含量的部分，并在RoPE后操作以保留位置信息。FusedKV-Lite进一步直接选用底层value和中层key做缓存，进一步降低I/O开销。

Result: 在332M到4B参数规模的LLM实验中，FusedKV与FusedKV-Lite均可将KV缓存需求减少50%，FusedKV的验证困惑度更低，FusedKV-Lite性能略降但I/O开销更小。

Conclusion: FusedKV及FusedKV-Lite有效提升了Transformer解码器KV缓存利用效率，降低显存占用，同时在性能上优于标准解码器，展示出高性能与高内存效率的架构潜力。

Abstract: Transformer decoders have achieved strong results across tasks, but the memory required for the KV cache becomes prohibitive at long sequence lengths. Although Cross-layer KV Cache sharing (e.g., YOCO, CLA) offers a path to mitigate KV Cache bottleneck, it typically underperforms within-layer methods like GQA. To understand the root cause, we investigate the information flow of keys and values of the top-layers. Our preliminary reveals a clear distribution: values are predominantly derived from the bottom layer, while keys draw more information from both bottom and middle layers. Building upon this, we propose FusedKV, whose top-layer KV caches are a learnable fusion of the most informative ones from the bottom and middle layers. This fusion operates directly on post-RoPE keys, preserving relative positional information without the computational cost of re-applying rotary embeddings. To further improve efficiency, we propose FusedKV-Lite, an cross-layer sharing approach, where top-layer KV caches are directly derived from the bottom-layer values and the middle-layer keys. Compared to FusedKV, FusedKV-Lite reduces I/O overhead at the cost of a slight increase in perplexity. In experiments on LLMs ranging from 332M to 4B parameters, our proposed method reduce 50\% cache memory while achieving lower validation perplexity than the standard Transformer decoder, establishing it as a memory-efficient, high-performance architectural alternative.

</details>


### [147] [BERnaT: Basque Encoders for Representing Natural Textual Diversity](https://arxiv.org/abs/2512.03903)
*Ekhi Azurmendi,Joseba Fernandez de Landa,Jaione Bengoetxea,Maite Heredia,Julen Etxaniz,Mikel Zubillaga,Ander Soraluze,Aitor Soroa*

Main category: cs.CL

TL;DR: 本文提出以包容多样语言变体（如方言、历史用语、非正式语体）为目标，训练语言模型，避免仅依赖标准文本带来的偏差。以低资源语言巴斯克语为例，构建多源语料库，预训练多种模型，并通过新的评测框架验证多样数据提升了模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型多使用经过筛选的高质量标准文本，然而这易导致边缘方言等语言变体被排除，降低了模型的鲁棒性和包容性，加剧了代表性偏见。作者希望改进这一问题，让模型更广泛适应各种语言形式。

Method: 作者针对巴斯克语，构建包含标准文本、社交媒体语料和历史资料的新型混合语料库。设计三类预训练模型：仅标准文本、仅多样文本、和两者结合。在评测上，创新性地将自然语言理解任务分为标准和多样子集，专门考察模型泛化到不同语言变体的能力。

Result: 实验结果表明，融合标准和多样语料训练的模型比单一来源训练的模型表现更优，在所有任务类型上均有提升，并且无损于标准基准表现。

Conclusion: 多样性语料能够增强模型能力，提高对不同类型、风格、历史时期等语言变体的适应性。因此，构建和利用包容性更强的语料库对训练通用化、无偏语言模型至关重要。

Abstract: Language models depend on massive text corpora that are often filtered for quality, a process that can unintentionally exclude non-standard linguistic varieties, reduce model robustness and reinforce representational biases. In this paper, we argue that language models should aim to capture the full spectrum of language variation (dialectal, historical, informal, etc.) rather than relying solely on standardized text. Focusing on Basque, a morphologically rich and low-resource language, we construct new corpora combining standard, social media, and historical sources, and pre-train the BERnaT family of encoder-only models in three configurations: standard, diverse, and combined. We further propose an evaluation framework that separates Natural Language Understanding (NLU) tasks into standard and diverse subsets to assess linguistic generalization. Results show that models trained on both standard and diverse data consistently outperform those trained on standard corpora, improving performance across all task types without compromising standard benchmark accuracy. These findings highlight the importance of linguistic diversity in building inclusive, generalizable language models.

</details>


### [148] [Is Lying Only Sinful in Islam? Exploring Religious Bias in Multilingual Large Language Models Across Major Religions](https://arxiv.org/abs/2512.03943)
*Kazi Abrab Hossain,Jannatul Somiya Mahmud,Maria Hossain Tuli,Anik Mitra,S. M. Taiabul Haque,Farig Y. Sadeque*

Main category: cs.CL

TL;DR: 本文提出了BRAND数据集，专注于南亚四大宗教的双语（英语和孟加拉语）规范问答，以评估和分析大语言模型在宗教场景下的偏见。实验发现模型对伊斯兰教存在明显偏见，且英文表现优于孟加拉文。


<details>
  <summary>Details</summary>
Motivation: 现有多语言大模型在涉宗教话题处理时经常出现误判与偏见，特别是在宗教敏感地区，这可能造成严重的误解。因此作者希望通过构建一个权威的数据集，系统评估和揭示模型在宗教问题上的表现和偏误。

Method: 构建名为BRAND的双语数据集，涵盖南亚四大宗教（佛教、基督教、印度教、伊斯兰教），共2400余个条目，包括三种类型的提示，分别以英文和孟加拉文呈现。利用该数据集评测和分析主流多语言模型在宗教相关任务上的表现。

Result: 模型在英语下的问答表现优于孟加拉语；无论问题是否涉及宗教倾向，模型回答均对伊斯兰教表现出持续性偏见，且不同语言下模型对同一问题的偏见程度存在显著差异。

Conclusion: 多语言模型在宗教领域仍存在固有和系统性偏见，尤其是在非英语语种中更为明显。这说明当前模型尚不足以应对跨语言文化敏感话题，在HCI（人机交互）和宗教、灵性等领域需持续关注和改进。

Abstract: While recent developments in large language models have improved bias detection and classification, sensitive subjects like religion still present challenges because even minor errors can result in severe misunderstandings. In particular, multilingual models often misrepresent religions and have difficulties being accurate in religious contexts. To address this, we introduce BRAND: Bilingual Religious Accountable Norm Dataset, which focuses on the four main religions of South Asia: Buddhism, Christianity, Hinduism, and Islam, containing over 2,400 entries, and we used three different types of prompts in both English and Bengali. Our results indicate that models perform better in English than in Bengali and consistently display bias toward Islam, even when answering religion-neutral questions. These findings highlight persistent bias in multilingual models when similar questions are asked in different languages. We further connect our findings to the broader issues in HCI regarding religion and spirituality.

</details>


### [149] [Adapting Large Language Models to Low-Resource Tibetan: A Two-Stage Continual and Supervised Fine-Tuning Study](https://arxiv.org/abs/2512.03976)
*Lifeng Chen,Ryan Lai,Tianming Liu*

Main category: cs.CL

TL;DR: 本文提出了一种将大语言模型（LLM）适配到藏语的两阶段方法，显著提升了模型的藏语理解和中藏翻译能力，并对参数变化进行了细致分析。


<details>
  <summary>Details</summary>
Motivation: 目前低资源语言（如藏语）上的LLM适配面临数据稀缺和跨语言漂移等难题，且藏语由于形态复杂，相关研究稀少，缺乏量化分析。

Method: 分两步适配Qwen2.5-3B模型到藏语：第一步通过持续预训练（CPT）为模型奠定藏文基础，第二步进行有监督微调（SFT）以提升具体任务和翻译表现。并对模型各层适配特征进行分析。

Result: 实验表明，模型在困惑度上由2.98降至1.54，中译藏BLEU分数从0.046提升到0.261，chrF由2.2升至6.6。层级分析显示适配主要集中在嵌入层和输出头，MLP后期层则学习领域特定转换。

Conclusion: 持续预训练有助于模型构建藏语语义空间，有监督微调则提升了特定任务对齐性，对表示空间破坏最小。该研究首次系统量化了LLM藏语适配过程，并给出低资源多语种模型扩展的可复现方案。

Abstract: Adapting large language models (LLMs) to low-resource languages remains a major challenge due to data scarcity and cross-lingual drift. This work presents a two-stage adaptation of Qwen2.5-3B to Tibetan, a morphologically rich and underrepresented language. We employ Continual Pretraining (CPT) to establish Tibetan linguistic grounding, followed by Supervised Fine-Tuning (SFT) for task and translation specialization. Empirical evaluations demonstrate a consistent decrease in perplexity (from 2.98 $\rightarrow$ 1.54) and substantial improvements in Chinese$\rightarrow$Tibetan translation quality (BLEU: 0.046 $\rightarrow$ 0.261; chrF: 2.2 $\rightarrow$ 6.6). Layer-wise analysis across 435 layers in Qwen3-4B reveals that adaptation primarily concentrates on embedding and output heads, with mid--late MLP projections encoding domain-specific transformations. Our findings suggest that CPT constructs a Tibetan semantic manifold while SFT sharpens task alignment with minimal representational disruption. This study provides the first quantitative exploration of Tibetan adaptation dynamics for LLMs, and offers an open, reproducible framework for extending multilingual foundation models to low-resource settings.

</details>


### [150] [Teaching Old Tokenizers New Words: Efficient Tokenizer Adaptation for Pre-trained Models](https://arxiv.org/abs/2512.03989)
*Taido Purason,Pavel Chizhov,Ivan P. Yamshchikov,Mark Fishel*

Main category: cs.CL

TL;DR: 本文提出两种用于适应预训练语言模型分词器的方法：继续BPE训练进行词表扩展，以及基于叶子的词表剪枝，在多个语言和模型上验证了效果，并将工具开源。


<details>
  <summary>Details</summary>
Motivation: 现有分词器扩展新领域或新语言时，常常简单地追加新词，造成词表中包含许多永不使用或冗余的词条，影响效率；而词表剪枝手段缺乏合理方法。迫切需要更高效、更精细控制的分词器适配方法。

Method: 提出两种互补的方法：1）继续在新数据上进行BPE合并训练（continued BPE training），用以优化已有词表并扩展新词；2）基于叶子的词表剪枝（leaf-based vocabulary pruning），用于删去冗余且不影响模型表现的词条。

Result: 在多种语言和模型上实验证明，继续BPE训练能提升分词效率，并更好地利用新增词表；叶子剪枝法能去除冗余词条，同时保持模型精度。

Conclusion: 这两种方法为词表扩展与剪枝提供了有效的途径，有助于对词表进行可控修改，提升模型在新领域/新语言的适应能力，并已以开源形式发布相关工具。

Abstract: Tokenizer adaptation plays an important role in transferring pre-trained language models to new domains or languages. In this work, we address two complementary aspects of this process: vocabulary extension and pruning. The common approach to extension trains a new tokenizer on domain-specific text and appends the tokens that do not overlap with the existing vocabulary, which often results in many tokens that are unreachable or never used. We propose continued BPE training, which adapts a pre-trained tokenizer by continuing the BPE merge learning process on new data. Experiments across multiple languages and model families show that this approach improves tokenization efficiency and leads to better utilization of added vocabulary. We also introduce leaf-based vocabulary pruning, which removes redundant tokens while preserving model quality. Together, these methods provide practical tools for controlled vocabulary modification, which we release as an open-source package.

</details>


### [151] [AugServe: Adaptive Request Scheduling for Augmented Large Language Model Inference Serving](https://arxiv.org/abs/2512.04013)
*Ying Wang,Zhen Jin,Jiexiong Xu,Wenhai Lin,Yiquan Chen,Wenzhi Chen*

Main category: cs.CL

TL;DR: 本文提出了一种名为AugServe的高效推理框架，通过自适应调度和动态批次调整机制，有效提升了增强型大模型（LLM）的推理服务吞吐量，并显著降低了服务延迟。


<details>
  <summary>Details</summary>
Motivation: 随着搭载外部工具的增强型大模型在Web应用中日益普及，推理服务即时响应和高效吞吐成为提升用户体验的关键。当前推理系统受到FCFS调度和静态批次设置的局限，导致排队延时高，难以满足服务级目标（SLO），亟需新的调度与批次机制。

Method: AugServe采用两阶段自适应请求调度策略：第一阶段根据请求特征优化调度顺序，第二阶段结合运行时信息动态微调决策。同时，AugServe基于硬件状态与实时负载动态调整token批次机制，从而实现资源与请求的最优匹配。

Result: 实验显示，AugServe在有效吞吐量方面比vLLM高4.7-33.1倍，比InferCept高3.3-13.2倍；在首token响应时间（TTFT）上分别减少了最高96.3%和95.0%。

Conclusion: 通过自适应调度和动态批处理，AugServe显著提高了增强型大模型推理服务的吞吐量与响应速度，为此类服务系统提供了高效、可扩展的解决方案。

Abstract: As augmented large language models (LLMs) with external tools become increasingly popular in web applications, improving augmented LLM inference serving efficiency and optimizing service-level objectives (SLOs) are critical for enhancing user experience. To achieve this, inference systems must maximize request handling within latency constraints, referred to as increasing effective throughput. However, existing systems face two major challenges: (i) reliance on first-come-first-served (FCFS) scheduling causes severe head-of-line blocking, leading to queuing delays exceeding the SLOs for many requests; and (ii) static batch token limit, which fails to adapt to fluctuating loads and hardware conditions. Both of these factors degrade effective throughput and service quality.
  This paper presents AugServe, an efficient inference framework designed to reduce queueing latency and enhance effective throughput for augmented LLM inference services. The core idea of AugServe is a two-stage adaptive request scheduling strategy. Specifically, AugServe combines the inference features of augmented LLM requests to optimize the order of scheduling decisions (stage I). These decisions are continuously refined with runtime information (stage II), adapting to both request characteristics and system capabilities. In addition, AugServe dynamically adjusts the token batching mechanism based on hardware status and real-time load, further enhancing throughput performance. Experimental results show that AugServe achieves 4.7-33.1x and 3.3-13.2x higher effective throughput than vLLM and InferCept, while reducing time-to-first-token (TTFT) by up to 96.3% and 95.0%, respectively.

</details>


### [152] [Jina-VLM: Small Multilingual Vision Language Model](https://arxiv.org/abs/2512.04032)
*Andreas Koukounas,Georgios Mastrapas,Florian Hönicke,Sedigheh Eslami,Guillaume Roncari,Scott Martens,Han Xiao*

Main category: cs.CL

TL;DR: Jina-VLM是一个2.4B参数的视觉-语言模型，在多语言视觉问答任务上表现优异，超越了同规模开源模型。


<details>
  <summary>Details</summary>
Motivation: 现有的开放型规模视觉-语言模型（VLM）在多语言视觉问答上的表现存在局限性，且图片处理效率不高，因此需要有一个性能更好、处理高分辨率图片效率更高的模型。

Method: Jina-VLM将SigLIP2视觉编码器与Qwen3语言模型通过高效的注意力池化连接器结合，实现对任意分辨率图片的高效token处理。

Result: 在主流视觉问答（VQA）基准和多语言评测中，Jina-VLM都优于同类模型，同时文本理解性能也保持竞争力。

Conclusion: Jina-VLM作为开放的2B级视觉-语言模型，兼具高效图片处理和优异多语言视觉问答能力，在视觉-语言跨模态领域具有领先地位。

Abstract: We present Jina-VLM, a 2.4B parameter vision-language model that achieves state-of-the-art multilingual visual question answering among open 2B-scale VLMs. The model couples a SigLIP2 vision encoder with a Qwen3 language backbone through an attention-pooling connector that enables token-efficient processing of arbitrary-resolution images. Across standard VQA benchmarks and multilingual evaluations, Jina-VLM outperforms comparable models while preserving competitive text-only performance.

</details>


### [153] [SkillFactory: Self-Distillation For Learning Cognitive Behaviors](https://arxiv.org/abs/2512.04072)
*Zayne Sprague,Jack Lu,Manya Wadhwa,Sedrick Keh,Mengye Ren,Greg Durrett*

Main category: cs.CL

TL;DR: 本论文提出SkillFactory方法，通过在强化学习（RL）之前，在有监督微调（SFT）阶段让模型初步习得复杂认知技能，以提升其在RL后的泛化和鲁棒性表现。


<details>
  <summary>Details</summary>
Motivation: 当前大模型在推理链条上表现出多种认知技能，但前提是基础模型本身具备这些技能。作者关注如何让模型学习并利用基础模型本不具备的认知技能。

Method: 提出SkillFactory方法，在SFT阶段不借助更强模型蒸馏，而是用自身生成的样本，重新组织成包含目标技能的数据格式（“silver” traces），用以训练模型掌握这些技能。之后再进行标准RL训练。

Result: 实验显示：1）用SkillFactory初始化后，即使RL前性能稍低，RL后模型能更好泛化到更难的任务；2）模型在任务中真正使用到认知技能；3）相比直接RL，SkillFactory训练出的模型对超出训练域的任务回归更鲁棒。

Conclusion: 在RL前通过SFT引入认知技能归纳偏置有助于模型习得更稳健的认知技能使用，提升其泛化能力和鲁棒性。

Abstract: Reasoning models leveraging long chains of thought employ various cognitive skills, such as verification of their answers, backtracking, retrying by an alternate method, and more. Previous work has shown that when a base language model exhibits these skills, training that model further with reinforcement learning (RL) can learn to leverage them. How can we get models to leverage skills that aren't exhibited by base models? Our work, SkillFactory, is a method for fine-tuning models to roughly learn these skills during a supervised fine-tuning (SFT) stage prior to RL. Our approach does not rely on distillation from a stronger model, but instead uses samples from the model itself, rearranged to provide training data in the format of those skills. These "silver" SFT traces may be imperfect, but are nevertheless effective for priming a model to acquire skills during RL. Our evaluation shows that (1) starting from SkillFactory SFT initialization helps a model to generalize to harder variants of a task post-RL, despite lower performance pre-RL; (2) cognitive skills are indeed used by the model; (3) RLed SkillFactory models are more robust to regression on out-of-domain tasks than RLed base models. Our work suggests that inductive biases learned prior to RL help models learn robust cognitive skill use.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [154] [Multi-Agent Reinforcement Learning and Real-Time Decision-Making in Robotic Soccer for Virtual Environments](https://arxiv.org/abs/2512.03166)
*Aya Taourirte,Md Sohag Mia*

Main category: cs.RO

TL;DR: 本文提出了一种统一的多智能体强化学习（MARL）框架，能够在类似机器人足球的动态、对抗性环境中，实现实时、高效与可扩展的多智能体协作决策。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在动态和对抗性环境（如机器人足球）中的部署，需要高效的实时决策与协作，现有强化学习方法难以应对多粒度任务和大规模智能体交互的复杂性。

Method: 作者基于PPO（Proximal Policy Optimization）建立了基线模型用于实时动作调度，并提出基于options框架的分层强化学习（HRL）结构，将任务分为高层轨迹规划（半马尔可夫决策过程建模）和低层动作执行。为提升可扩展性，又将均场理论融入HRL，将多智能体交互简化为单智能体与总体均值的对抗，提出了均场actor-critic方法。

Result: PPO基线已取得4.32平均进球和82.9%控球率，分层结构后的平均进球提升到5.26，均场HRL方法达到5.93平均进球、89.1%控球率和92.3%传球准确率，训练稳定性亦有提升。

Conclusion: 提出的均场分层多智能体强化学习框架可实现鲁棒、高效、可扩展的多智能体协作行为，在复杂多智能体领域（如机器人足球）中展现出广阔应用潜力。

Abstract: The deployment of multi-agent systems in dynamic, adversarial environments like robotic soccer necessitates real-time decision-making, sophisticated cooperation, and scalable algorithms to avoid the curse of dimensionality. While Reinforcement Learning (RL) offers a promising framework, existing methods often struggle with the multi-granularity of tasks (long-term strategy vs. instant actions) and the complexity of large-scale agent interactions. This paper presents a unified Multi-Agent Reinforcement Learning (MARL) framework that addresses these challenges. First, we establish a baseline using Proximal Policy Optimization (PPO) within a client-server architecture for real-time action scheduling, with PPO demonstrating superior performance (4.32 avg. goals, 82.9% ball control). Second, we introduce a Hierarchical RL (HRL) structure based on the options framework to decompose the problem into a high-level trajectory planning layer (modeled as a Semi-Markov Decision Process) and a low-level action execution layer, improving global strategy (avg. goals increased to 5.26). Finally, to ensure scalability, we integrate mean-field theory into the HRL framework, simplifying many-agent interactions into a single agent vs. the population average. Our mean-field actor-critic method achieves a significant performance boost (5.93 avg. goals, 89.1% ball control, 92.3% passing accuracy) and enhanced training stability. Extensive simulations of 4v4 matches in the Webots environment validate our approach, demonstrating its potential for robust, scalable, and cooperative behavior in complex multi-agent domains.

</details>


### [155] [GRAND: Guidance, Rebalancing, and Assignment for Networked Dispatch in Multi-Agent Path Finding](https://arxiv.org/abs/2512.03194)
*Johannes Gaber,Meshal Alharbi,Daniele Gammelli,Gioele Zardini*

Main category: cs.RO

TL;DR: 本文提出了一种结合图神经网络强化学习与优化算法的多机器人任务调度方法，可在大型仓库中提升效率并控制实时计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 随着大型机器人车队在仓库和物流场景中普及，调度优化带来的小幅提升能极大影响整体运作效率。因此急需一种既高效又能扩展到大规模的调度方法。

Method: 方法包括两个核心部分：1）使用图神经网络强化学习训练全局策略，输出空闲机器人在仓库图上的期望分布；2）该分布通过最小费用流算法转化为区域间的再平衡决策，最终利用局部分配优化以保证每一步计算延迟在1秒以内。

Result: 在最多500台机器人、由LRR提供的拥堵仓库基准测试中，该方法吞吐量提升高达10%，并且始终保持实时运算能力，优于2024年获胜调度器。

Conclusion: 将图结构学习策略与高效优化方法结合，既降低了拥塞，又实现了大规模多机器人系统的高吞吐调度，具备良好实用性和可扩展性。

Abstract: Large robot fleets are now common in warehouses and other logistics settings, where small control gains translate into large operational impacts. In this article, we address task scheduling for lifelong Multi-Agent Pickup-and-Delivery (MAPD) and propose a hybrid method that couples learning-based global guidance with lightweight optimization. A graph neural network policy trained via reinforcement learning outputs a desired distribution of free agents over an aggregated warehouse graph. This signal is converted into region-to-region rebalancing through a minimum-cost flow, and finalized by small, local assignment problems, preserving accuracy while keeping per-step latency within a 1 s compute budget. On congested warehouse benchmarks from the League of Robot Runners (LRR) with up to 500 agents, our approach improves throughput by up to 10% over the 2024 winning scheduler while maintaining real-time execution. The results indicate that coupling graph-structured learned guidance with tractable solvers reduces congestion and yields a practical, scalable blueprint for high-throughput scheduling in large fleets.

</details>


### [156] [KALIKO: Kalman-Implicit Koopman Operator Learning For Prediction of Nonlinear Dynamical Systems](https://arxiv.org/abs/2512.03256)
*Albert H. Li,Ivan Dario Jimenez Rodriguez,Joel W. Burdick,Yisong Yue,Aaron D. Ames*

Main category: cs.RO

TL;DR: KALIKO提出了一种基于卡尔曼滤波、可隐式学习Koopman算子嵌入的方法，实现高维动力系统的长期预测，在多个控制与预测任务上优于主流基线。


<details>
  <summary>Details</summary>
Motivation: 长期动力学预测对于机器人和控制任务非常重要，但很多系统由于非线性、混沌、高维等特性很难建模。Koopman理论虽能简化建模，但如何选择有效的嵌入基函数仍是难点，选不好容易预测不准或过拟合。

Method: 提出KALIKO (Kalman-Implicit Koopman Operator) 方法，将卡尔曼滤波与Koopman理论结合，通过卡尔曼滤波器隐式学习动力系统的潜在嵌入，无需显式编码器。这样能自动获得具有全局线性的潜在动态空间，解释性和理论一致性好。

Result: 在高维偏微分方程生成的波动数据集上，KALIKO在开放环预测和封闭环控制（控制机械臂负载、补偿波动干扰）场景下均优于多种基线方法，效果显著提升。

Conclusion: KALIKO方法能自动高效地学习复杂动力系统隐空间表达，在非线性、高维动力学预测与控制场景中均展现出优势。

Abstract: Long-horizon dynamical prediction is fundamental in robotics and control, underpinning canonical methods like model predictive control. Yet, many systems and disturbance phenomena are difficult to model due to effects like nonlinearity, chaos, and high-dimensionality. Koopman theory addresses this by modeling the linear evolution of embeddings of the state under an infinite-dimensional linear operator that can be approximated with a suitable finite basis of embedding functions, effectively trading model nonlinearity for representational complexity. However, explicitly computing a good choice of basis is nontrivial, and poor choices may cause inaccurate forecasts or overfitting. To address this, we present Kalman-Implicit Koopman Operator (KALIKO) Learning, a method that leverages the Kalman filter to implicitly learn embeddings corresponding to latent dynamics without requiring an explicit encoder. KALIKO produces interpretable representations consistent with both theory and prior works, yielding high-quality reconstructions and inducing a globally linear latent dynamics. Evaluated on wave data generated by a high-dimensional PDE, KALIKO surpasses several baselines in open-loop prediction and in a demanding closed-loop simulated control task: stabilizing an underactuated manipulator's payload by predicting and compensating for strong wave disturbances.

</details>


### [157] [GOMP: Grasped Object Manifold Projection for Multimodal Imitation Learning of Manipulation](https://arxiv.org/abs/2512.03347)
*William van den Bogert,Gregory Linkowski,Nima Fazeli*

Main category: cs.RO

TL;DR: 本文提出了一种名为GOMP的方法，通过约束被抓取物体到低维流形，有效减少模仿学习中轨迹精度不足导致的累积误差，实现更加精确的操作任务。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在重复性操作任务中应用广泛，但轨迹误差的不断积累限制了其实用性，特别是在需要高精度的场景。作者希望解决这一限制。

Method: 作者提出了Grasped Object Manifold Projection (GOMP) 方法: 将非刚性抓持物体约束在低维流形上。GOMP假设操作臂抓持的物体可在可观测的范围内移动，并需组合到固定部件上。GOMP的所有强化都是基于同一专家数据集，并借助n臂赌博机方法进行交互性调整，并给出理论误差改进根据。

Result: GOMP在四项精密装配任务上进行了验证，利用触觉反馈，获得了显著的精度提升，而且这一方法对感知模态没有限制。

Conclusion: GOMP能够有效缓解模仿学习中的累积误差问题，提高操作精度，且具有良好的通用性和实用前景。

Abstract: Imitation Learning (IL) holds great potential for learning repetitive manipulation tasks, such as those in industrial assembly. However, its effectiveness is often limited by insufficient trajectory precision due to compounding errors. In this paper, we introduce Grasped Object Manifold Projection (GOMP), an interactive method that mitigates these errors by constraining a non-rigidly grasped object to a lower-dimensional manifold. GOMP assumes a precise task in which a manipulator holds an object that may shift within the grasp in an observable manner and must be mated with a grounded part. Crucially, all GOMP enhancements are learned from the same expert dataset used to train the base IL policy, and are adjusted with an n-arm bandit-based interactive component. We propose a theoretical basis for GOMP's improvement upon the well-known compounding error bound in IL literature. We demonstrate the framework on four precise assembly tasks using tactile feedback, and note that the approach remains modality-agnostic. Data and videos are available at williamvdb.github.io/GOMPsite.

</details>


### [158] [Surfel-LIO: Fast LiDAR-Inertial Odometry with Pre-computed Surfels and Hierarchical Z-order Voxel Hashing](https://arxiv.org/abs/2512.03397)
*Seungwon Choi,Dong-Gyu Park,Seo-Yeon Hwang,Tae-Wan Kim*

Main category: cs.RO

TL;DR: 本文提出一种高效的LiDAR-惯导里程计方法Surfel-LIO，利用分层体素和预计算面元实现高速状态估计。


<details>
  <summary>Details</summary>
Motivation: 当前LIO系统在地图数据结构和空间索引有所进展，但最近邻搜索需多次遍历空间单元收集拟合点，且在地图结构不变时仍重复计算平面参数，导致效率低下。

Method: 采用分层体素结构（hVox）和预计算的面元（surfel）存储，结合Z序曲线实现缓存友好的空间索引，实现O(1)对应关系检索，无需运行时邻居枚举或拟合平面。

Result: 在M3DGR数据集上实验表明，Surfel-LIO显著提升了处理速度，同时保持与最新方法相当的定位精度。

Conclusion: 所提方法在保证高精度的同时，大幅提升了LIO系统的实时性和效率，适合实际应用。

Abstract: LiDAR-inertial odometry (LIO) is an active research area, as it enables accurate real-time state estimation in GPS-denied environments. Recent advances in map data structures and spatial indexing have significantly improved the efficiency of LIO systems. Nevertheless, we observe that two aspects may still leave room for improvement: (1) nearest neighbor search often requires examining multiple spatial units to gather sufficient points for plane fitting, and (2) plane parameters are typically recomputed at every iteration despite unchanged map geometry. Motivated by these observations, we propose Surfel-LIO, which employs a hierarchical voxel structure (hVox) with pre-computed surfel representation. This design enables O(1) correspondence retrieval without runtime neighbor enumeration or plane fitting, combined with Z-order curve encoding for cache-friendly spatial indexing. Experimental results on the M3DGR dataset demonstrate that our method achieves significantly faster processing speed compared to recent state-of-the-art methods while maintaining comparable state estimation accuracy. Our implementation is publicly available at https://github.com/93won/lidar_inertial_odometry.

</details>


### [159] [What Is The Best 3D Scene Representation for Robotics? From Geometric to Foundation Models](https://arxiv.org/abs/2512.03422)
*Tianchen Deng,Yue Pan,Shenghai Yuan,Dong Li,Chen Wang,Mingrui Li,Long Chen,Lihua Xie,Danwei Wang,Jingchuan Wang,Javier Civera,Hesheng Wang,Weidong Chen*

Main category: cs.RO

TL;DR: 本文综述了机器人领域中的场景表示方法，包括传统的点云、体素、签名距离函数、场景图，以及新兴的神经表达如NeRF、3DGS和基础模型，并探讨未来发展趋势。


<details>
  <summary>Details</summary>
Motivation: 当前机器人系统主要依赖稀疏场景表示，而密集和语义化场景表示有望在导航、避障等下游任务中发挥更大作用。新出现的神经和基础模型带来整合高层语义的可能性，有必要全面梳理其进展与挑战。

Method: 系统回顾了场景表示方法，将机器人核心模块划分为感知、建图、定位、导航、操作五类，比较了每种场景表示在各模块的优劣，并聚焦3D基础模型的未来潜力和挑战。

Result: 对各类场景表示进行了对比，阐明了神经表示和3D基础模型可在未来统一替代现有方法，促进更高层次3D理解与自主智能。

Conclusion: 3D基础模型有望成为未来机器人的统一场景表示方案。文中提出了未来发展趋势及当前需解决的挑战，并提供开源资源供后续学习与研究。

Abstract: In this paper, we provide a comprehensive overview of existing scene representation methods for robotics, covering traditional representations such as point clouds, voxels, signed distance functions (SDF), and scene graphs, as well as more recent neural representations like Neural Radiance Fields (NeRF), 3D Gaussian Splatting (3DGS), and the emerging Foundation Models. While current SLAM and localization systems predominantly rely on sparse representations like point clouds and voxels, dense scene representations are expected to play a critical role in downstream tasks such as navigation and obstacle avoidance. Moreover, neural representations such as NeRF, 3DGS, and foundation models are well-suited for integrating high-level semantic features and language-based priors, enabling more comprehensive 3D scene understanding and embodied intelligence. In this paper, we categorized the core modules of robotics into five parts (Perception, Mapping, Localization, Navigation, Manipulation). We start by presenting the standard formulation of different scene representation methods and comparing the advantages and disadvantages of scene representation across different modules. This survey is centered around the question: What is the best 3D scene representation for robotics? We then discuss the future development trends of 3D scene representations, with a particular focus on how the 3D Foundation Model could replace current methods as the unified solution for future robotic applications. The remaining challenges in fully realizing this model are also explored. We aim to offer a valuable resource for both newcomers and experienced researchers to explore the future of 3D scene representations and their application in robotics. We have published an open-source project on GitHub and will continue to add new works and technologies to this project.

</details>


### [160] [World Models for Autonomous Navigation of Terrestrial Robots from LIDAR Observations](https://arxiv.org/abs/2512.03429)
*Raul Steinmetz,Fabio Demo Rosa,Victor Augusto Kich,Jair Augusto Bottega,Ricardo Bedin Grando,Daniel Fernando Tello Gamarra*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的基于DreamerV3的模型化强化学习框架，能高效处理高维LIDAR输入，实现地面机器人的鲁棒自主导航。实验结果显示，相较于常用的无模型方法，该方法在模拟环境下收敛速度更快且导航成功率更高。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在处理高维LIDAR数据进行机器人导航时存在感知瓶颈和训练效率低下的问题。为解决政策网络难以直接利用全分辨率LIDAR数据及空间信息损失的缺陷，亟需一种能提取高维传感信息同时提升学习效率的新方法。

Method: 本文在DreamerV3算法基础上，设计并集成了一个多层感知机变分自编码器（MLP-VAE）到世界模型，负责将高维LIDAR数据编码为低维潜在表示，再与学习出的环境动态预测器结合，通过基于想象的策略优化提升导航效果。

Result: 在TurtleBot3仿真导航任务上，所提架构较SAC、DDPG及TD3等主流无模型基线方法获得了更快的收敛速度和更高的成功率。特别地，DreamerV3基方法在使用包含全部360点LIDAR数据的全数据集时，在所有评估环境中均达到100%成功率，而无模型方法最高不超过85%。

Conclusion: 将世界模型预测能力与潜在空间表示学习相结合，有效提升了强化学习在处理高维感知数据时的导航效率和鲁棒性，为地面机器人自主导航提供了更优解决方案。

Abstract: Autonomous navigation of terrestrial robots using Reinforcement Learning (RL) from LIDAR observations remains challenging due to the high dimensionality of sensor data and the sample inefficiency of model-free approaches. Conventional policy networks struggle to process full-resolution LIDAR inputs, forcing prior works to rely on simplified observations that reduce spatial awareness and navigation robustness. This paper presents a novel model-based RL framework built on top of the DreamerV3 algorithm, integrating a Multi-Layer Perceptron Variational Autoencoder (MLP-VAE) within a world model to encode high-dimensional LIDAR readings into compact latent representations. These latent features, combined with a learned dynamics predictor, enable efficient imagination-based policy optimization. Experiments on simulated TurtleBot3 navigation tasks demonstrate that the proposed architecture achieves faster convergence and higher success rate compared to model-free baselines such as SAC, DDPG, and TD3. It is worth emphasizing that the DreamerV3-based agent attains a 100% success rate across all evaluated environments when using the full dataset of the Turtlebot3 LIDAR (360 readings), while model-free methods plateaued below 85%. These findings demonstrate that integrating predictive world models with learned latent representations enables more efficient and robust navigation from high-dimensional sensory data.

</details>


### [161] [PerFACT: Motion Policy with LLM-Powered Dataset Synthesis and Fusion Action-Chunking Transformers](https://arxiv.org/abs/2512.03444)
*Davood Soleymanzadeh,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: 本文提出了一种结合大语言模型(LLM)和融合式动作分块Transformer的机器人运动规划新方法，显著提升了自动化、多样性训练数据的生成和运动规划速度。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习运动规划器的数据集规模有限、生成方式单一，导致在新场景中泛化能力差，且现有的网络架构难以有效编码复杂的规划信息。

Method: 1) 提出基于LLM的MotionGeneralizer方法，能大规模生成语义有效的机器人工作空间，用于扩充训练集；2) 提出结合动作分块与多模态特征融合的MpiNetsFusion，将Transformer用于运动规划信号编码。

Result: 通过MotionGeneralizer生成350万条轨迹数据，使用MpiNetsFusion进行训练，与主流方法对比，在多项任务上的规划速度提高数倍。

Conclusion: 所提结合LLM辅助数据合成和Transformer融合策略的新方法，显著提升了机器人运动规划器的泛化能力与推理速度，在复杂和多变的任务场景中表现更优。

Abstract: Deep learning methods have significantly enhanced motion planning for robotic manipulators by leveraging prior experiences within planning datasets. However, state-of-the-art neural motion planners are primarily trained on small datasets collected in manually generated workspaces, limiting their generalizability to out-of-distribution scenarios. Additionally, these planners often rely on monolithic network architectures that struggle to encode critical planning information. To address these challenges, we introduce Motion Policy with Dataset Synthesis powered by large language models (LLMs) and Fusion Action-Chunking Transformers (PerFACT), which incorporates two key components. Firstly, a novel LLM-powered workspace generation method, MotionGeneralizer, enables large-scale planning data collection by producing a diverse set of semantically feasible workspaces. Secondly, we introduce Fusion Motion Policy Networks (MpiNetsFusion), a generalist neural motion planner that uses a fusion action-chunking transformer to better encode planning signals and attend to multiple feature modalities. Leveraging MotionGeneralizer, we collect 3.5M trajectories to train and evaluate MpiNetsFusion against state-of-the-art planners, which shows that the proposed MpiNetsFusion can plan several times faster on the evaluated tasks.

</details>


### [162] [MSG-Loc: Multi-Label Likelihood-based Semantic Graph Matching for Object-Level Global Localization](https://arxiv.org/abs/2512.03522)
*Gihyeon Lee,Jungwoo Lee,Juwon Kim,Young-Sik Shin,Younggun Cho*

Main category: cs.RO

TL;DR: 本文提出了一种基于多标签可能性语义图匹配的全局定位方法，通过多标签而非单标签捕捉对象语义，实现鲁棒的对象级机器人全局定位。


<details>
  <summary>Details</summary>
Motivation: 在机器人定位过程中，环境中的对象类别通常未知且存在较高语义歧义，导致基于对象的全局定位容易产生误判和姿态估计误差。

Method: 作者提出用多标签语义图表示对象，结合每个节点的可能性及其邻居最大可能性进行上下文感知的可能性传播，用于多标签图间的更精准语义对应，实现鲁棒的对象级全局定位。

Result: 该方法在封闭集和开放集检测条件下进行了严谨的验证，评估了数据关联和姿态估计性能。同时，结果表明该方法具有出色的大规模对象类别扩展能力，并在真实及合成环境中都取得良好表现。

Conclusion: 多标签可能性语义图匹配方法有效提升了机器人在高语义歧义环境下的全局定位准确性，具备良好的扩展性和现实适用性。

Abstract: Robots are often required to localize in environments with unknown object classes and semantic ambiguity. However, when performing global localization using semantic objects, high semantic ambiguity intensifies object misclassification and increases the likelihood of incorrect associations, which in turn can cause significant errors in the estimated pose. Thus, in this letter, we propose a multi-label likelihood-based semantic graph matching framework for object-level global localization. The key idea is to exploit multi-label graph representations, rather than single-label alternatives, to capture and leverage the inherent semantic context of object observations. Based on these representations, our approach enhances semantic correspondence across graphs by combining the likelihood of each node with the maximum likelihood of its neighbors via context-aware likelihood propagation. For rigorous validation, data association and pose estimation performance are evaluated under both closed-set and open-set detection configurations. In addition, we demonstrate the scalability of our approach to large-vocabulary object categories in both real-world indoor scenes and synthetic environments.

</details>


### [163] [AdaPower: Specializing World Foundation Models for Predictive Manipulation](https://arxiv.org/abs/2512.03538)
*Yuhang Huang,Shilong Zou,Jiazhao Zhang,Xinwang Liu,Ruizhen Hu,Kai Xu*

Main category: cs.RO

TL;DR: 本文提出了AdaPower框架，通过轻量化适配方法将通用大模型（WFM）转变为更适合机器人控制任务的专业世界模型，实现了在无需重新训练策略的情况下，提升了任务成功率并保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统的世界大模型（WFM）虽然在视觉动态模拟方面表现优异，但用于精准的机器人控制时存在现实模拟与控制精度之间的鸿沟，同时现有方法作为数据生成器不仅效率低下，还未充分利用已有的VLA策略。

Method: 提出的AdaPower框架包含两大关键组件：1）时空测试时训练（TS-TTT），在推理时对模型进行自适应调整；2）记忆保持（MP），确保长期任务中的模型一致性。该框架被整合进模型预测控制（MPC）体系内，实现对世界模型的定制与适配。

Result: 在LIBERO基准测试中，无需对VLA策略重新训练的情况下，任务成功率提高了41%以上，同时保持了计算效率和模型的通用能力。

Conclusion: AdaPower成功地以低成本方式提升了WFM在机器人控制中的精度与效果，无需重新训练策略，具有良好的实际应用前景。

Abstract: World Foundation Models (WFMs) offer remarkable visual dynamics simulation capabilities, yet their application to precise robotic control remains limited by the gap between generative realism and control-oriented precision. While existing approaches use WFMs as synthetic data generators, they suffer from high computational costs and underutilization of pre-trained VLA policies. We introduce \textbf{AdaPower} (\textbf{Ada}pt and Em\textbf{power}), a lightweight adaptation framework that transforms general-purpose WFMs into specialist world models through two novel components: Temporal-Spatial Test-Time Training (TS-TTT) for inference-time adaptation and Memory Persistence (MP) for long-horizon consistency. Integrated within a Model Predictive Control framework, our adapted world model empowers pre-trained VLAs, achieving over 41\% improvement in task success rates on LIBERO benchmarks without policy retraining, while preserving computational efficiency and generalist capabilities.

</details>


### [164] [A Learning-based Control Methodology for Transitioning VTOL UAVs](https://arxiv.org/abs/2512.03548)
*Zexin Lin,Yebin Zhong,Hanwen Wan,Jiu Cheng,Zhenglong Sun,Xiaoqiang Ji*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习的新型耦合过渡控制方法，用于垂直起降无人机（VTOL UAV）过渡阶段的姿态和位置控制，并在仿真和实飞中验证了其优异的控制效果和减振性能。


<details>
  <summary>Details</summary>
Motivation: 目前VTOL无人机在过渡阶段，由于倾转旋翼带来的重心与推力变化，传统高度与位置解耦控制方法容易导致机体振动大、适应性差。本文旨在解决这一关键技术挑战，提高过渡过程中的控制精度与适应性。

Method: 提出了一种基于强化学习（RL）的耦合过渡控制器，与传统分阶段控制不同，将巡航模式视作悬停的一种特例，实现连续、统一的控制策略。

Result: 在仿真与真实飞行环境下实验，验证了所提方法能够有效控制无人机在过渡过程中的位置和姿态，实现了优秀的轨迹跟踪及明显减少的机体振动。

Conclusion: 基于强化学习的耦合过渡控制器可显著提升VTOL UAV过渡阶段的控制效果，易于开发和迁移，有望大幅改善无人机的过渡性能与应用前景。

Abstract: Transition control poses a critical challenge in Vertical Take-Off and Landing Unmanned Aerial Vehicle (VTOL UAV) development due to the tilting rotor mechanism, which shifts the center of gravity and thrust direction during transitions. Current control methods' decoupled control of altitude and position leads to significant vibration, and limits interaction consideration and adaptability. In this study, we propose a novel coupled transition control methodology based on reinforcement learning (RL) driven controller. Besides, contrasting to the conventional phase-transition approach, the ST3M method demonstrates a new perspective by treating cruise mode as a special case of hover. We validate the feasibility of applying our method in simulation and real-world environments, demonstrating efficient controller development and migration while accurately controlling UAV position and attitude, exhibiting outstanding trajectory tracking and reduced vibrations during the transition process.

</details>


### [165] [RoboScape-R: Unified Reward-Observation World Models for Generalizable Robotics Training via RL](https://arxiv.org/abs/2512.03556)
*Yinzhou Tang,Yu Shang,Yinuo Chen,Bingwen Wei,Xin Zhang,Shu'ang Yu,Liangzhi Shi,Chao Yu,Chen Gao,Wei Wu,Yong Li*

Main category: cs.RO

TL;DR: 提出一种通过世界模型提供通用奖励的RL框架RoboScape-R，有效提升了智能体策略的泛化能力，在多场景迁移任务中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习和强化学习方法在策略泛化到多样环境时表现不佳，核心原因在于IL易过拟合专家演示，RL缺乏统一的通用奖励信号。为解决这一限制，作者探索利用世界模型作为环境通用代理。

Method: 提出RoboScape-R框架，将世界模型作为RL环境代理，并设计了一种由模型内生动态推断出的通用奖励机制，无需依赖任务特定的人工奖励函数，用以训练更具泛化性的策略。

Result: 实验表明该框架能够显著提升策略的泛化能力，对比传统RL方法，在跨域任务中平均性能提升37.5%。

Conclusion: RoboScape-R为利用世界模型在线训练泛化策略提供了新的视角，证明了世界模型引导下通用奖励的有效性，有望推动智能体更好地适应复杂多变场景。

Abstract: Achieving generalizable embodied policies remains a key challenge. Traditional policy learning paradigms, including both Imitation Learning (IL) and Reinforcement Learning (RL), struggle to cultivate generalizability across diverse scenarios. While IL policies often overfit to specific expert trajectories, RL suffers from the inherent lack of a unified and general reward signal necessary for effective multi-scene generalization. We posit that the world model is uniquely capable of serving as a universal environment proxy to address this limitation. However, current world models primarily focus on their ability to predict observations and still rely on task-specific, handcrafted reward functions, thereby failing to provide a truly general training environment. Toward this problem, we propose RoboScape-R, a framework leveraging the world model to serve as a versatile, general-purpose proxy for the embodied environment within the RL paradigm. We introduce a novel world model-based general reward mechanism that generates ''endogenous'' rewards derived from the model's intrinsic understanding of real-world state transition dynamics. Extensive experiments demonstrate that RoboScape-R effectively addresses the limitations of traditional RL methods by providing an efficient and general training environment that substantially enhances the generalization capability of embodied policies. Our approach offers critical insights into utilizing the world model as an online training strategy and achieves an average 37.5% performance improvement over baselines under out-of-domain scenarios.

</details>


### [166] [Multimodal Control of Manipulators: Coupling Kinematics and Vision for Self-Driving Laboratory Operations](https://arxiv.org/abs/2512.03630)
*Shifa Sulaiman,Amarnath H,Simon Bogh,Naresh Marturi*

Main category: cs.RO

TL;DR: 本文通过对比三种基于雅可比方法的运动规划方案，旨在为冗余机械臂及其夹爪的轨迹规划和逆解选择提供指导。


<details>
  <summary>Details</summary>
Motivation: 机械臂任务执行中，找到高效、平滑且精确的运动规划方法始终是关键。针对冗余机械臂及其带耦合指夹爪的复杂动作需求，亟需比较不同逆解方法的优劣，提升运动规划质量。

Method: 提出并实现了基于三种雅可比法（雅可比转置法、伪逆法、阻尼最小二乘法）的运动规划方案。轨迹通过RRT*算法计算，机械臂及夹爪的正运动学由螺旋理论解算，并利用三种雅可比法分别求逆解。基于螺旋理论公式获取空间雅可比和可操作性度量，分析轨迹光滑性、RMSE误差、速度连续性、加速度、颤动和抖动等性能指标。

Result: 三种逆解方法在轨迹跟踪精度、运动平滑性和动力学性能上各有表现。基于这些量化分析，通过仿真对比了优缺点，结果揭示不同方法适应的任务特性。

Conclusion: 通过系统仿真实验，提出了冗余机械臂及夹爪在不同任务类型下选用合适逆解方案的建议，对该领域运动规划方法选择具备实践参考价值。

Abstract: Motion planning schemes are used for planning motions of a manipulator from an initial pose to a final pose during a task execution. A motion planning scheme generally comprises of a trajectory planning method and an inverse kinematic solver to determine trajectories and joints solutions respectively. In this paper, 3 motion planning schemes developed based on Jacobian methods are implemented to traverse a redundant manipulator with a coupled finger gripper through given trajectories. RRT* algorithm is used for planning trajectories and screw theory based forward kinematic equations are solved for determining joint solutions of the manipulator and gripper. Inverse solutions are computed separately using 3 Jacobian based methods such as Jacobian Transpose (JT), Pseudo Inverse (PI), and Damped Least Square (DLS) methods. Space Jacobian and manipulability measurements of the manipulator and gripper are obtained using screw theory formulations. Smoothness and RMSE error of generated trajectories and velocity continuity, acceleration profile, jerk, and snap values of joint motions are analysed for determining an efficient motion planning method for a given task. Advantages and disadvantages of the proposed motion planning schemes mentioned above are analysed using simulation studies to determine a suitable inverse solution technique for the tasks.

</details>


### [167] [Context-Triggered Contingency Games for Strategic Multi-Agent Interaction](https://arxiv.org/abs/2512.03639)
*Kilian Schweppe,Anne-Kathrin Schmuck*

Main category: cs.RO

TL;DR: 本文提出了一种新架构，实现了自主多智能体系统中安全、高效、可靠的交互，兼顾长期战略与即时动态适应，并通过仿真和实物实验验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 自主多智能体系统需要在复杂环境中持续互动，实现既安全又高效的协作，但现有方法很难同时兼顾长期目标与短时动态适应，因此需要新方法提升可靠性和效率。

Method: 提出了“上下文触发应急博弈”框架，将基于时序逻辑的战略博弈与可动态实时解决的应急博弈结合。采用双层架构：上层利用策略模板保证高层目标，下层通过新的因子图求解器，实现动态交互的可扩展、实时模型预测控制。

Result: 提出的框架确保了在不确定、交互式环境中的安全性和持续进展。通过自动驾驶和机器人导航领域的仿真及硬件实验，展示了高效、可靠、适应性强的多智能体交互效果。

Conclusion: 新方法有效保证了多智能体协作中的目标达成与安全性，实现了对于复杂环境的动态适应，适用于多种自主系统交互场景。

Abstract: We address the challenge of reliable and efficient interaction in autonomous multi-agent systems, where agents must balance long-term strategic objectives with short-term dynamic adaptation. We propose context-triggered contingency games, a novel integration of strategic games derived from temporal logic specifications with dynamic contingency games solved in real time. Our two-layered architecture leverages strategy templates to guarantee satisfaction of high-level objectives, while a new factor-graph-based solver enables scalable, real-time model predictive control of dynamic interactions. The resulting framework ensures both safety and progress in uncertain, interactive environments. We validate our approach through simulations and hardware experiments in autonomous driving and robotic navigation, demonstrating efficient, reliable, and adaptive multi-agent interaction.

</details>


### [168] [A Novel Approach to Tomato Harvesting Using a Hybrid Gripper with Semantic Segmentation and Keypoint Detection](https://arxiv.org/abs/2512.03684)
*Shahid Ansari,Mahendra Kumar Gohil,Yusuke Maeda,Bishakh Bhattacharya*

Main category: cs.RO

TL;DR: 本文提出了一种用于番茄自主采摘的混合式机器人手爪，集成了柔性与刚性结构，并结合视觉识别与力控反馈，实现了高效、可靠和温和的果实采摘。


<details>
  <summary>Details</summary>
Motivation: 实现番茄等脆弱果实在复杂环境中的自动采摘，是提升农业自动化水平、减少劳动力成本和降低果品损伤率的重要目标。传统机械手爪存在对果实损伤大和采摘精度不足的局限。

Method: 设计了一种包含六根柔性增材手指、刚性外骨骼和乳胶篮的混合式手爪，通过伺服驱动Scotch-yoke机构实现柔顺夹持，并设置锥形分离叶和微型切割器完成果梗分离。视觉部分采用RGB-D相机及Detectron2深度学习分割网络，定位果实及关键部位，结合闭环力控与PSO优化，实现机械臂路径规划和无损采摘。

Result: 实验证明系统平均采摘周期为24.34秒，整体采摘成功率约为80%，保持0.20–0.50N的低夹持力，完整完成接近、分离、切梗、夹持、搬运、释放全流程。

Conclusion: 本文系统在复杂环境下表现出高效、可靠和温和的果实采摘能力，验证了所提混合手爪与视觉-控制集成方案的有效性。

Abstract: This paper presents an autonomous tomato-harvesting system built around a hybrid robotic gripper that combines six soft auxetic fingers with a rigid exoskeleton and a latex basket to achieve gentle, cage-like grasping. The gripper is driven by a servo-actuated Scotch--yoke mechanism, and includes separator leaves that form a conical frustum for fruit isolation, with an integrated micro-servo cutter for pedicel cutting. For perception, an RGB--D camera and a Detectron2-based pipeline perform semantic segmentation of ripe/unripe tomatoes and keypoint localization of the pedicel and fruit center under occlusion and variable illumination. An analytical model derived using the principle of virtual work relates servo torque to grasp force, enabling design-level reasoning about actuation requirements. During execution, closed-loop grasp-force regulation is achieved using a proportional--integral--derivative controller with feedback from force-sensitive resistors mounted on selected fingers to prevent slip and bruising. Motion execution is supported by Particle Swarm Optimization (PSO)--based trajectory planning for a 5-DOF manipulator. Experiments demonstrate complete picking cycles (approach, separation, cutting, grasping, transport, release) with an average cycle time of 24.34~s and an overall success rate of approximately 80\%, while maintaining low grasp forces (0.20--0.50~N). These results validate the proposed hybrid gripper and integrated vision--control pipeline for reliable harvesting in cluttered environments.

</details>


### [169] [ContactRL: Safe Reinforcement Learning based Motion Planning for Contact based Human Robot Collaboration](https://arxiv.org/abs/2512.03707)
*Sundas Rafat Mulkana,Ronyu Yu,Tanaya Guha,Emma Li*

Main category: cs.RO

TL;DR: 本文提出了ContactRL，一个基于强化学习的框架，能够通过力反馈将接触安全性融入奖励函数，实现机器人在与人协作时安全高效地动作。该方法在模拟和真实机器人实验中均优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 在与人类协作的任务中，机器人不仅需要避免碰撞，还要处理必要的安全接触，确保人机物理交互的安全和高效。因此，研究如何提升机器人与人协作时的接触安全性具有重要意义。

Method: 提出了ContactRL框架，利用力反馈信号将接触安全性纳入强化学习的奖励函数，使机器人能在完成任务的同时降低与人类的接触力。此外，在部署阶段还结合了基于动能的控制屏障函数（eCBF），给学习到的策略增加一层安全保障。

Result: 在仿真中，ContactRL将安全违规率降至0.2%，任务成功率达到87.7%，均优于最新的受约束强化学习方法。在真实UR3e机器人平台上，通过360组物体交接实验，也实现了接触力始终低于10N，验证了方法的有效性和安全性。

Conclusion: ContactRL能够在确保接触安全的前提下，实现高效的人机物理协作，有助于推动协作机器人在需频繁接触的任务场景中的实际部署。

Abstract: In collaborative human-robot tasks, safety requires not only avoiding collisions but also ensuring safe, intentional physical contact. We present ContactRL, a reinforcement learning (RL) based framework that directly incorporates contact safety into the reward function through force feedback. This enables a robot to learn adaptive motion profiles that minimize human-robot contact forces while maintaining task efficiency. In simulation, ContactRL achieves a low safety violation rate of 0.2\% with a high task success rate of 87.7\%, outperforming state-of-the-art constrained RL baselines. In order to guarantee deployment safety, we augment the learned policy with a kinetic energy based Control Barrier Function (eCBF) shield. Real-world experiments on an UR3e robotic platform performing small object handovers from a human hand across 360 trials confirm safe contact, with measured normal forces consistently below 10N. These results demonstrate that ContactRL enables safe and efficient physical collaboration, thereby advancing the deployment of collaborative robots in contact-rich tasks.

</details>


### [170] [Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) International Space Station Astrobee Testing](https://arxiv.org/abs/2512.03729)
*Samantha Chapin,Kenneth Stewart,Roxana Leontie,Carl Glen Henshaw*

Main category: cs.RO

TL;DR: 本文介绍了首次在国际空间站利用强化学习（RL）算法控制自由飞行机器人（NASA Astrobee）的实验，展示了RL在太空机器人自主控制中的巨大应用前景。


<details>
  <summary>Details</summary>
Motivation: 目前太空任务中自由飞行机器人的自主性受到传统控制方法的限制，难以快速、灵活地适应复杂和变化的空间环境。研究动机是探索利用强化学习提升太空机器人的自主能力和适应性，加速其部署和任务适配速度。

Method: 实验团队在NVIDIA Isaac Lab仿真环境下，采用基于actor-critic的近端策略优化（PPO）网络训练了一个6自由度的控制策略。在训练过程中，通过对目标位置和机器人质量分布进行随机化，提升策略的泛化和鲁棒性。随后，该控制策略经过仿真、地面测试，并最终在国际空间站的Astrobee机器人上进行实际在轨飞行验证。

Result: 实验成功实现了强化学习驱动的自由飞行机器人在太空中的实际控制，并通过模拟、地面和在轨测试，验证了所发展方法的性能和泛化能力。

Conclusion: 本研究首次证明了强化学习技术在太空自由飞行机器人自主控制中的可行性和潜力，有望大幅提升太空任务中的机器人自主性、效率及行为适应性。

Abstract: The US Naval Research Laboratory's (NRL's) Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) experiment pioneers the use of reinforcement learning (RL) for control of free-flying robots in the zero-gravity (zero-G) environment of space. On Tuesday, May 27th 2025 the APIARY team conducted the first ever, to our knowledge, RL control of a free-flyer in space using the NASA Astrobee robot on-board the International Space Station (ISS). A robust 6-degrees of freedom (DOF) control policy was trained using an actor-critic Proximal Policy Optimization (PPO) network within the NVIDIA Isaac Lab simulation environment, randomizing over goal poses and mass distributions to enhance robustness. This paper details the simulation testing, ground testing, and flight validation of this experiment. This on-orbit demonstration validates the transformative potential of RL for improving robotic autonomy, enabling rapid development and deployment (in minutes to hours) of tailored behaviors for space exploration, logistics, and real-time mission needs.

</details>


### [171] [Crossing the Sim2Real Gap Between Simulation and Ground Testing to Space Deployment of Autonomous Free-flyer Control](https://arxiv.org/abs/2512.03736)
*Kenneth Stewart,Samantha Chapin,Roxana Leontie,Carl Glen Henshaw*

Main category: cs.RO

TL;DR: 该论文首次在国际空间站上演示了基于强化学习的自主自由飞行机器人控制，实现了训练在地面完成，部署在太空的控制策略迁移。


<details>
  <summary>Details</summary>
Motivation: 希望通过强化学习提升太空机器人（如NASA Astrobee）自主控制能力，解决现有控制模式在微重力环境中的局限性，并探索训练与现实环境之间的迁移。

Method: 采用NVIDIA Omniverse物理模拟器和课程式学习，在模拟环境下利用深度神经网络训练Astrobee的姿态与位置控制器，开发了模拟到现实（Sim2Real）的训练管线，并使用GPU加速实现高效的强化学习蒙特卡洛训练。

Result: 成功将地面训练的RL控制策略应用于国际空间站的Astrobee机器人，实现了在微重力下的有效自主导航，验证了Sim2Real方法在空间机器人的可行性。

Conclusion: 该研究表明强化学习策略可以在地面有效训练后迁移至太空实际应用，为空间在轨服务、组装和制造等方向提供了新方案和快速适应的可能性。

Abstract: Reinforcement learning (RL) offers transformative potential for robotic control in space. We present the first on-orbit demonstration of RL-based autonomous control of a free-flying robot, the NASA Astrobee, aboard the International Space Station (ISS). Using NVIDIA's Omniverse physics simulator and curriculum learning, we trained a deep neural network to replace Astrobee's standard attitude and translation control, enabling it to navigate in microgravity. Our results validate a novel training pipeline that bridges the simulation-to-reality (Sim2Real) gap, utilizing a GPU-accelerated, scientific-grade simulation environment for efficient Monte Carlo RL training. This successful deployment demonstrates the feasibility of training RL policies terrestrially and transferring them to space-based applications. This paves the way for future work in In-Space Servicing, Assembly, and Manufacturing (ISAM), enabling rapid on-orbit adaptation to dynamic mission requirements.

</details>


### [172] [Cross-embodied Co-design for Dexterous Hands](https://arxiv.org/abs/2512.03743)
*Kehlani Fay,Darin Anthony Djapri,Anya Zorin,James Clinton,Ali El Lahib,Hao Su,Michael T. Tolley,Sha Yi,Xiaolong Wang*

Main category: cs.RO

TL;DR: 该论文提出了一个用于灵巧机械手协同设计的框架，能够自动生成适合任务的手型，并学习相应的控制策略，实现快速从设计到实物部署。


<details>
  <summary>Details</summary>
Motivation: 灵巧操作的机械手在控制和硬件设计上都存在局限，目前没有公认最佳的机械手设计，这限制了其在复杂操作任务上的表现，因此亟需一种能同时优化控制策略与机械结构的方法。

Method: 作者提出了一个协同设计框架。该框架包括：1）在广阔设计空间内自动生成机器人手部的关节、手指、手掌等结构；2）通过面向不同形态的联合控制策略实现高效评估；3）用现成元件支持原型制作。整个流程可实现快速设计、训练、制造和部署。

Result: 该方法在多种灵巧操作任务上进行验证，包括仿真和现实中的手内旋转操作实验，实现了任务定制化的手结构和控制策略，机器人手的从零到实物可在24小时内完成。

Conclusion: 该框架实现了端到端的灵巧机械手快速定制设计、训练和物理部署，极大提升了机械手在任务中的灵巧性及开发效率，相关工具和代码将开源。

Abstract: Dexterous manipulation is limited by both control and design, without consensus as to what makes manipulators best for performing dexterous tasks. This raises a fundamental challenge: how should we design and control robot manipulators that are optimized for dexterity? We present a co-design framework that learns task-specific hand morphology and complementary dexterous control policies. The framework supports 1) an expansive morphology search space including joint, finger, and palm generation, 2) scalable evaluation across the wide design space via morphology-conditioned cross-embodied control, and 3) real-world fabrication with accessible components. We evaluate the approach across multiple dexterous tasks, including in-hand rotation with simulation and real deployment. Our framework enables an end-to-end pipeline that can design, train, fabricate, and deploy a new robotic hand in under 24 hours. The full framework will be open-sourced and available on our website.

</details>


### [173] [Prediction-Driven Motion Planning: Route Integration Strategies in Attention-Based Prediction Models](https://arxiv.org/abs/2512.03756)
*Marlon Steiner,Royden Wagner,Ömer Sahin Tas,Christoph Stiller*

Main category: cs.RO

TL;DR: 本文提出了一种将运动预测和运动规划结合的方法，用于提升自动驾驶车辆与其他交通参与者的交互能力。作者通过在注意力机制预测模型中集成导航信息，改进多智能体环境下的轨迹预测和规划。实验结果表明，该方法能够提升预测与规划的表现。


<details>
  <summary>Details</summary>
Motivation: 目前自动驾驶中，如何结合运动预测和运动规划，提高与其他交通参与者的交互能力仍有挑战，尤其是在将导航目标纳入预测过程中。这促使本文研究如何在运动预测模型中有效整合导航信息，改善目标导向的预测与规划。

Method: 作者提出在基于注意力机制的运动预测模型中，集成自动驾驶车辆的预定路线和目标位姿（goal pose），并探索多种架构集成策略。通过在nuPlan数据集上进行训练与评估，比较不同集成策略的效果。

Result: 实验结果显示，集成导航信息后，模型的轨迹预测和运动规划表现均有所提升，验证了此方法的有效性。特别是在多智能体、目标导向场景下，预测的稳定性和可行性更好。

Conclusion: 本研究表明，基于预测驱动的运动规划框架，并通过融合导航目标信息，可显著提升自动驾驶系统在复杂道路场景下的运动预测与路径规划能力。

Abstract: Combining motion prediction and motion planning offers a promising framework for enhancing interactions between automated vehicles and other traffic participants. However, this introduces challenges in conditioning predictions on navigation goals and ensuring stable, kinematically feasible trajectories. Addressing the former challenge, this paper investigates the extension of attention-based motion prediction models with navigation information. By integrating the ego vehicle's intended route and goal pose into the model architecture, we bridge the gap between multi-agent motion prediction and goal-based motion planning. We propose and evaluate several architectural navigation integration strategies to our model on the nuPlan dataset. Our results demonstrate the potential of prediction-driven motion planning, highlighting how navigation information can enhance both prediction and planning tasks. Our implementation is at: https://github.com/KIT-MRT/future-motion.

</details>


### [174] [Bayesian Optimization for Automatic Tuning of Torque-Level Nonlinear Model Predictive Control](https://arxiv.org/abs/2512.03772)
*Gabriele Fadini,Deepak Ingole,Tong Duy Son,Alisa Rupenyan*

Main category: cs.RO

TL;DR: 本文提出了一种基于高维贝叶斯优化的自调谐非线性模型预测控制（nMPC）方法，利用数字孪生和仿真，提升了UR10e机械臂末端执行器轨迹的实时控制精度。


<details>
  <summary>Details</summary>
Motivation: 传统MPC参数手动调节，效率低且难以达到最优控制效果，尤其在高维空间下更显困难。因此，迫切需要自动化、数据驱动的调参手段以提升机器人实时运动控制性能。

Method: 将稀疏轴对齐子空间贝叶斯优化（SAASBO）与数字孪生仿真结合，对nMPC的代价函数权重和低层增益参数进行高维优化。首先在仿真平台上高效探索参数空间，验证参数后再迁移到真实机器人，实现安全、高效的参数自动优化。

Result: 仿真中，自动调参后，轨迹跟踪性能提升了41.9%，求解时间减少了2.5%。在真实UR10e机械臂上的实验验证也体现了类似趋势，性能提升达25.8%。

Conclusion: 融合数字孪生和自动化高维贝叶斯优化能有效提升工业机器人nMPC的控制性能和调参效率，为机器人精准、可靠作业提供了强大工具。

Abstract: This paper presents an auto-tuning framework for torque-based Nonlinear Model Predictive Control (nMPC), where the MPC serves as a real-time controller for optimal joint torque commands. The MPC parameters, including cost function weights and low-level controller gains, are optimized using high-dimensional Bayesian Optimization (BO) techniques, specifically Sparse Axis-Aligned Subspace (SAASBO) with a digital twin (DT) to achieve precise end-effector trajectory real-time tracking on an UR10e robot arm. The simulation model allows efficient exploration of the high-dimensional parameter space, and it ensures safe transfer to hardware. Our simulation results demonstrate significant improvements in tracking performance (+41.9%) and reduction in solve times (-2.5%) compared to manually-tuned parameters. Moreover, experimental validation on the real robot follows the trend (with a +25.8% improvement), emphasizing the importance of digital twin-enabled automated parameter optimization for robotic operations.

</details>


### [175] [Safety Reinforced Model Predictive Control (SRMPC): Improving MPC with Reinforcement Learning for Motion Planning in Autonomous Driving](https://arxiv.org/abs/2512.03774)
*Johannes Fischer,Marlon Steiner,Ömer Sahin Tas,Christoph Stiller*

Main category: cs.RO

TL;DR: 本文针对自动驾驶中的运动规划，提出结合安全强化学习（SRL）和模型预测控制（MPC）的方法，在保证安全的同时实现更优的全局路径规划。


<details>
  <summary>Details</summary>
Motivation: 常规MPC需将最优控制问题（OCP）做凸近似，以实现实时性，但这限制了解空间，难以获得全局最优解。因此，需突破MPC本地最优的限制，提高规划质量，并确保自动驾驶中的安全性。

Method: 在MPC中使用强化学习算法（SRL）生成新的安全参考轨迹，使MPC得以探索原路径邻域外的解，增加获得全局最优解的可能性。为确保行驶安全，将受约束强化学习（CRL）融入系统，通过基于能量函数的人为安全指数约束安全/不安全区域，引入状态相关拉格朗日乘子并与安全策略同步学习，以解决CRL问题。

Result: 在高速公路场景实验中，该方法在安全性和性能指标上表现优于传统MPC和SRL方法。

Conclusion: 该研究证明，将安全强化学习与MPC结合能够有效突破传统方法的局限，实现了更安全且性能更优的自动驾驶路径规划。

Abstract: Model predictive control (MPC) is widely used for motion planning, particularly in autonomous driving. Real-time capability of the planner requires utilizing convex approximation of optimal control problems (OCPs) for the planner. However, such approximations confine the solution to a subspace, which might not contain the global optimum. To address this, we propose using safe reinforcement learning (SRL) to obtain a new and safe reference trajectory within MPC. By employing a learning-based approach, the MPC can explore solutions beyond the close neighborhood of the previous one, potentially finding global optima. We incorporate constrained reinforcement learning (CRL) to ensure safety in automated driving, using a handcrafted energy function-based safety index as the constraint objective to model safe and unsafe regions. Our approach utilizes a state-dependent Lagrangian multiplier, learned concurrently with the safe policy, to solve the CRL problem. Through experimentation in a highway scenario, we demonstrate the superiority of our approach over both MPC and SRL in terms of safety and performance measures.

</details>


### [176] [MPCFormer: A physics-informed data-driven approach for explainable socially-aware autonomous driving](https://arxiv.org/abs/2512.03795)
*Jia Hu,Zhexi Lian,Xuerun Yan,Ruiang Bi,Dou Shen,Yu Ruan,Haoran Wang*

Main category: cs.RO

TL;DR: 本文提出了一种融合物理先验和数据驱动的社会交互动力学模型，以提升自动驾驶车辆在复杂交通场景下的人类式行为和交互能力。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在动态和高交互的交通环境下难以展现出类似人类的行为，其根本障碍是对交通参与者间社会交互机制理解不足。

Method: 研究提出了MPCFormer方法，将多车社会交互动力学以离散状态空间形式表达，嵌入物理先验，通过基于Transformer的编码-解码架构从真实驾驶数据中学习动力学参数。通过模型预测控制（MPC）框架进行决策规划，增进可解释性和安全性。

Result: 在NGSIM数据集上的开环实验表明，MPCFormer在社会交互感知和轨迹预测准确性方面优于当前主流方法（长期预测ADE低至0.86m）。闭环实验（复杂换道环境）显示，该方法规划成功率高达94.67%，驾驶效率提升15.75%，碰撞率从21.25%降至0.5%，全面超越最新的强化学习方法。

Conclusion: MPCFormer通过显式建模车辆间社会交互动力学，增强了自动驾驶系统可解释性、安全性和类人行为能力，为应对高动态交通场景提供了有效解决方案。

Abstract: Autonomous Driving (AD) vehicles still struggle to exhibit human-like behavior in highly dynamic and interactive traffic scenarios. The key challenge lies in AD's limited ability to interact with surrounding vehicles, largely due to a lack of understanding the underlying mechanisms of social interaction. To address this issue, we introduce MPCFormer, an explainable socially-aware autonomous driving approach with physics-informed and data-driven coupled social interaction dynamics. In this model, the dynamics are formulated into a discrete space-state representation, which embeds physics priors to enhance modeling explainability. The dynamics coefficients are learned from naturalistic driving data via a Transformer-based encoder-decoder architecture. To the best of our knowledge, MPCFormer is the first approach to explicitly model the dynamics of multi-vehicle social interactions. The learned social interaction dynamics enable the planner to generate manifold, human-like behaviors when interacting with surrounding traffic. By leveraging the MPC framework, the approach mitigates the potential safety risks typically associated with purely learning-based methods. Open-looped evaluation on NGSIM dataset demonstrates that MPCFormer achieves superior social interaction awareness, yielding the lowest trajectory prediction errors compared with other state-of-the-art approach. The prediction achieves an ADE as low as 0.86 m over a long prediction horizon of 5 seconds. Close-looped experiments in highly intense interaction scenarios, where consecutive lane changes are required to exit an off-ramp, further validate the effectiveness of MPCFormer. Results show that MPCFormer achieves the highest planning success rate of 94.67%, improves driving efficiency by 15.75%, and reduces the collision rate from 21.25% to 0.5%, outperforming a frontier Reinforcement Learning (RL) based planner.

</details>


### [177] [IM HERE: Interaction Model for Human Effort Based Robot Engagement](https://arxiv.org/abs/2512.03828)
*Dominykas Strazdas,Magnus Jung,Jan Marquenie,Ingo Siegert,Ayoub Al-Hamadi*

Main category: cs.RO

TL;DR: 本论文提出了IM HERE框架，对人际、人机及机器人间的互动中的“参与度”进行统一、具体且可操作的建模。该框架基于双边关系的努力度，简化关系模式并具象为四种关键状态，可被用来指导自主系统的社交行为。


<details>
  <summary>Details</summary>
Motivation: 以往关于‘参与度’的定义与模型普遍含糊或难以跨场景泛化，限制了其在多种互动场景中的应用效果，尤其是在自主系统需遵循社会规范时的挑战。

Method: 作者提出一个新颖的基于努力度的双边关系建模框架，能够对参与度进行拆分、分类和精准表述，并能整合主观感知与客观状态，进而自动分析和建模社会行为及潜在误解。

Result: IM HERE框架能够有效描述互动双方及群体的关系动态，将各类行为转化为可操作的指令，提升自主系统对社会规范的遵循能力和整体社会融入度。

Conclusion: IM HERE模型为自动系统的社会行为建模及分析提供了统一、清晰、可自动化执行的理论基础，提高了系统识别与适应复杂社会场景、误解检测与自我调整的能力，对实现自主系统的社会一体化目标具有积极推动作用。

Abstract: The effectiveness of human-robot interaction often hinges on the ability to cultivate engagement - a dynamic process of cognitive involvement that supports meaningful exchanges. Many existing definitions and models of engagement are either too vague or lack the ability to generalize across different contexts. We introduce IM HERE, a novel framework that models engagement effectively in human-human, human-robot, and robot-robot interactions. By employing an effort-based description of bilateral relationships between entities, we provide an accurate breakdown of relationship patterns, simplifying them to focus placement and four key states. This framework captures mutual relationships, group behaviors, and actions conforming to social norms, translating them into specific directives for autonomous systems. By integrating both subjective perceptions and objective states, the model precisely identifies and describes miscommunication. The primary objective of this paper is to automate the analysis, modeling, and description of social behavior, and to determine how autonomous systems can behave in accordance with social norms for full social integration while simultaneously pursuing their own social goals.

</details>


### [178] [OmniDexVLG: Learning Dexterous Grasp Generation from Vision Language Model-Guided Grasp Semantics, Taxonomy and Functional Affordance](https://arxiv.org/abs/2512.03874)
*Lei Zhang,Diwen Zheng,Kaixin Bai,Zhenshan Bing,Zoltan-Csaba Marton,Zhaopeng Chen,Alois Christian Knoll,Jianwei Zhang*

Main category: cs.RO

TL;DR: 本文提出了OmniDexVLG，一个结合视觉与语言多模态语义的灵巧抓取生成框架，实现了结构多样且语义一致的抓取动作，并在多维语义建模与推理上取得突破性进展。


<details>
  <summary>Details</summary>
Motivation: 现有灵巧抓取生成难以实现对多语义维度（抓取类别、接触语义、功能性等）的统一建模与可控生成，导致抓取动作缺乏可解释的语义一致性。本研究致力于解决多语义维度统一建模与语义控制难题，提升抓取动作的人类可解释性与多样性。

Method: 1）提出OmniDexDataGen，利用抓取分类、功能接触点等采样及物理优化，系统生成丰富的语义抓取数据集；2）提出OmniDexReasoner，通过多智能体协作、检索增强生成与推理，将语言指令与具体抓取语义关联并生成高质量标注；3）基于上述模块，构建结合视觉与语言、融合多语义的抓取生成模型，可依据自然语言精细控制抓取合成过程。

Result: 在模拟与真实抓取实验中，相较最新方法，所提模型在抓取多样性、接触语义多样性、功能语义多样性及语义一致性方面均有显著提升，并通过消融实验验证各模块有效性。

Conclusion: OmniDexVLG实现了细粒度、可控、语义丰富的灵巧抓取生成，在多个评测维度上优于现有方法，对于提高机器人抓取的灵活性与可解释性具有重要意义。

Abstract: Dexterous grasp generation aims to produce grasp poses that align with task requirements and human interpretable grasp semantics. However, achieving semantically controllable dexterous grasp synthesis remains highly challenging due to the lack of unified modeling of multiple semantic dimensions, including grasp taxonomy, contact semantics, and functional affordance. To address these limitations, we present OmniDexVLG, a multimodal, semantics aware grasp generation framework capable of producing structurally diverse and semantically coherent dexterous grasps under joint language and visual guidance. Our approach begins with OmniDexDataGen, a semantic rich dexterous grasp dataset generation pipeline that integrates grasp taxonomy guided configuration sampling, functional affordance contact point sampling, taxonomy aware differential force closure grasp sampling, and physics based optimization and validation, enabling systematic coverage of diverse grasp types. We further introduce OmniDexReasoner, a multimodal grasp type semantic reasoning module that leverages multi agent collaboration, retrieval augmented generation, and chain of thought reasoning to infer grasp related semantics and generate high quality annotations that align language instructions with task specific grasp intent. Building upon these components, we develop a unified Vision Language Grasping generation model that explicitly incorporates grasp taxonomy, contact structure, and functional affordance semantics, enabling fine grained control over grasp synthesis from natural language instructions. Extensive experiments in simulation and real world object grasping and ablation studies demonstrate that our method substantially outperforms state of the art approaches in terms of grasp diversity, contact semantic diversity, functional affordance diversity, and semantic consistency.

</details>


### [179] [A Modular Architecture Design for Autonomous Driving Racing in Controlled Environments](https://arxiv.org/abs/2512.03886)
*Brais Fontan-Costas,M. Diaz-Cacho,Ruben Fernandez-Boullon,Manuel Alonso-Carracedo,Javier Perez-Robles*

Main category: cs.RO

TL;DR: 本论文提出了一种面向封闭赛道车辆的自动驾驶系统架构，涵盖了环境感知、定位建图、路径规划和车辆控制等精准任务，各子系统独立运行，通过流水线式架构协同，实现了模块化、实时的自动驾驶。


<details>
  <summary>Details</summary>
Motivation: 在封闭赛道等受控环境下，车辆自动驾驶对精确感知、定位及控制等多项技术提出了较高要求，现有系统在集成性和实时性上仍有改进空间。本文旨在解决现有架构局限，实现高效、模块化的自动系统。

Method: 系统采用模块化设计，将计算机视觉、定位与建图、路径规划和控制等子系统独立实现，并通过数据流水线整合，利用最新技术以便实现实时、精准的自主导航。

Result: 系统各子模块能够独立运行并顺利对接，整体实现了在受控闭环环境下车辆的精确、实时自动驾驶任务。

Conclusion: 所提出的系统架构在模块化、实时性和精确性上表现优异，为封闭赛道环境下自动驾驶车辆的开发提供了高效可行的解决方案。

Abstract: This paper presents an Autonomous System (AS) architecture for vehicles in a closed circuit. The AS performs precision tasks including computer vision for environment perception, positioning and mapping for accurate localization, path planning for optimal trajectory generation, and control for precise vehicle actuation. Each subsystem operates independently while connecting data through a cohesive pipeline architecture. The system implements a modular design that combines state-of-the-art technologies for real-time autonomous navigation in controlled environments.

</details>


### [180] [Digital Twin-based Control Co-Design of Full Vehicle Active Suspensions via Deep Reinforcement Learning](https://arxiv.org/abs/2512.03891)
*Ying-Kuan Tsai,Yi-Ping Chen,Vispi Karkaria,Wei Chen*

Main category: cs.RO

TL;DR: 本文提出了一种融合数字孪生和深度强化学习的全车主动悬架协同优化框架，可根据驾驶员行为和环境动态自适应进行悬架与控制策略的联合优化，显著提升舒适性与控制效率。


<details>
  <summary>Details</summary>
Motivation: 现有主动悬架系统受限于固定硬件和不可自适应的控制策略，难以在实际复杂多变和不确定环境中实现最佳性能。随着数字孪生和深度强化学习技术的发展，基于数据的实时优化成为可能，但两者融合应用还未成熟。

Method: 构建了一个基于数字孪生的控制协同设计（CCD）框架，结合自动微分的深度强化学习方法，实现悬架硬件和控制策略的联合优化。采用量化学习进行不确定性建模和模型更新，处理局部可观测和环境变化，在不同驾驶行为场景中进行测试。

Result: 在温和和激烈两种驾驶场景下，优化后的系统分别减小了约43%和52%的控制能耗，同时保持了车辆舒适性与稳定性，实现了个性化最优悬架系统。

Conclusion: 本研究提出的DT-CCD框架有效集成了DRL与不确定性感知模型更新，首次实现了面向全车主动悬架的多代自进化设计与个性化优化，为未来智能悬架系统开发提供了新途径。

Abstract: Active suspension systems are critical for enhancing vehicle comfort, safety, and stability, yet their performance is often limited by fixed hardware designs and control strategies that cannot adapt to uncertain and dynamic operating conditions. Recent advances in digital twins (DTs) and deep reinforcement learning (DRL) offer new opportunities for real-time, data-driven optimization across a vehicle's lifecycle. However, integrating these technologies into a unified framework remains an open challenge. This work presents a DT-based control co-design (CCD) framework for full-vehicle active suspensions using multi-generation design concepts. By integrating automatic differentiation into DRL, we jointly optimize physical suspension components and control policies under varying driver behaviors and environmental uncertainties. DRL also addresses the challenge of partial observability, where only limited states can be sensed and fed back to the controller, by learning optimal control actions directly from available sensor information. The framework incorporates model updating with quantile learning to capture data uncertainty, enabling real-time decision-making and adaptive learning from digital-physical interactions. The approach demonstrates personalized optimization of suspension systems under two distinct driving settings (mild and aggressive). Results show that the optimized systems achieve smoother trajectories and reduce control efforts by approximately 43% and 52% for mild and aggressive, respectively, while maintaining ride comfort and stability. Contributions include: developing a DT-enabled CCD framework integrating DRL and uncertainty-aware model updating for full-vehicle active suspensions, introducing a multi-generation design strategy for self-improving systems, and demonstrating personalized optimization of active suspension systems for distinct driver types.

</details>


### [181] [Autonomous Reinforcement Learning Robot Control with Intel's Loihi 2 Neuromorphic Hardware](https://arxiv.org/abs/2512.03911)
*Kenneth Stewart,Roxana Leontie,Samantha Chapin,Joe Hays,Sumit Bam Shrestha,Carl Glen Henshaw*

Main category: cs.RO

TL;DR: 本论文提出了一条端到端流程，将强化学习训练的人工神经网络（ANN）通过转换为脉冲Sigma-Delta神经网络（SDNN）部署到类脑硬件（如Intel Loihi 2）上，实现低延迟且高能效的推理，用于如太空机器人等实时控制任务。


<details>
  <summary>Details</summary>
Motivation: 人工神经网络虽能学习复杂策略，但在嵌入式或能耗敏感的场景（如太空机器人）上难以高效部署。类脑硬件能提供更高能效和低延迟，因此迫切需要将训练好的ANN高效迁移到这类芯片上。

Method: 作者提出了将强化学习训练的ReLU激活的ANN策略转化为可在Loihi 2芯片上运行的SDNN的方法，并以Astrobee自由飞行机器人为例，将其控制策略在GPU和Loihi 2上做对比，借助Omniverse Isaac实验环境评估闭环控制性能。

Result: 实验结果表明，转换后的SDNN在Loihi 2上能实现低延迟、低能耗的决策推理，与GPU实现进行了性能对比验证了可行性。

Conclusion: 本论文证明了类脑硬件能够胜任机器人控制任务，并为未来节能、高实时性的太空及地面机器人提供了新的计算实现途径。

Abstract: We present an end-to-end pipeline for deploying reinforcement learning (RL) trained Artificial Neural Networks (ANNs) on neuromorphic hardware by converting them into spiking Sigma-Delta Neural Networks (SDNNs). We demonstrate that an ANN policy trained entirely in simulation can be transformed into an SDNN compatible with Intel's Loihi 2 architecture, enabling low-latency and energy-efficient inference. As a test case, we use an RL policy for controlling the Astrobee free-flying robot, similar to a previously hardware in space-validated controller. The policy, trained with Rectified Linear Units (ReLUs), is converted to an SDNN and deployed on Intel's Loihi 2, then evaluated in NVIDIA's Omniverse Isaac Lab simulation environment for closed-loop control of Astrobee's motion. We compare execution performance between GPU and Loihi 2. The results highlight the feasibility of using neuromorphic platforms for robotic control and establish a pathway toward energy-efficient, real-time neuromorphic computation in future space and terrestrial robotics applications.

</details>


### [182] [Hierarchical Vision Language Action Model Using Success and Failure Demonstrations](https://arxiv.org/abs/2512.03913)
*Jeongeun Park,Jihwan Yoon,Byungwoo Jeon,Juhan Park,Jinwoo Shin,Namhoon Cho,Kyungjae Lee,Sangdoo Yun,Sungjoon Choi*

Main category: cs.RO

TL;DR: 该论文提出了一种新的视觉-语言-动作（Vision-Language-Action, VLA）模型VINE，在训练过程中利用包括失败案例在内的混合质量数据，从而提升机器人任务的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型通常只用成功演示进行训练，忽略了采集过程中大量自然发生的失败案例，而这些失败包含了模型脆弱性的关键信息。本研究旨在将这些失败转化为有效的学习信号，提高模型在实际任务中的鲁棒性。

Method: 论文提出了一种层次化VLA模型VINE，将高层次推理（System 2）与低层次控制（System 1）分离，采用层次化强化学习框架。System 2通过2D场景图进行基于可行性的树搜索，利用成功和失败数据来对子目标序列的可行性评分和修剪脆弱策略分支。System 1仅负责低层动作执行，不改变机器人的基本技能。整个方法完全基于离线远程操作数据进行训练。

Result: 在多个具挑战性的操作任务上，VINE在成功率和鲁棒性方面均有显著提升，表明结合失败数据能有效增强VLA模型的实用性。

Conclusion: 失败数据对于提升机器人VLA模型的鲁棒执行表现至关重要。通过层次化方法合理利用失败经验，能够促进系统更稳定、更可靠地完成复杂任务。

Abstract: Prior Vision-Language-Action (VLA) models are typically trained on teleoperated successful demonstrations, while discarding numerous failed attempts that occur naturally during data collection. However, these failures encode where and how policies can be fragile, information that can be exploited to improve robustness. We address this problem by leveraging mixed-quality datasets to learn failure-aware reasoning at planning time. We introduce VINE, a hierarchical vision-language-action model that separates high-level reasoning (System 2) from low-level control (System 1) under a hierarchical reinforcement learning formalism, making failures usable as a structured learning signal rather than noisy supervision. System 2 performs feasibility-guided tree search over a 2D scene-graph abstraction: it proposes subgoal transitions, predicts success probabilities from both successes and failures, and prunes brittle branches before execution, effectively casting plan evaluation as feasibility scoring. The selected subgoal sequence is then passed to System 1, which executes low-level actions without modifying the agent's core skills. Trained entirely from offline teleoperation data, VINE integrates negative experience directly into the decision loop. Across challenging manipulation tasks, this approach consistently improves success rates and robustness, demonstrating that failure data is an essential resource for converting the broad competence of VLAs into robust execution.

</details>


### [183] [Driving is a Game: Combining Planning and Prediction with Bayesian Iterative Best Response](https://arxiv.org/abs/2512.03936)
*Aron Distelzweig,Yiwei Wang,Faris Janjoš,Marcel Hallgarten,Mihai Dobre,Alexander Langmann,Joschka Boedecker,Johannes Betz*

Main category: cs.RO

TL;DR: 本文提出了一种结合博弈论与运动预测的新方法BIBeR，实现了自动驾驶中对交互行为的更有效应对，并在实际场景下超越了现有方案。


<details>
  <summary>Details</summary>
Motivation: 传统规则方法在常规场景表现好但在复杂城市场景（如换道、并道）下表现欠佳，现有方法与预测器集成有限，难以真正实现决策与预测双向互动。为此，需要一个能够联合运动预测和规划，并能自适应处理不确定性的系统。

Method: 提出了Bayesian Iterative Best Response（BIBeR）框架，将先进的运动预测器和博弈论中的反应策略迭代（IBR）相结合，通过多次迭代回应，逼近纳什均衡，实现自主车辆与其他交通参与者之间的双向适应。引入了贝叶斯置信度估计，用于量化预测可靠性并动态调整响应强度。

Result: 在高度交互的lane-change测试（interPlan）场景下，BIBeR对比最优现有方法提升了11%的性能，同时在标准nuPlan基准测试中也优于现有方案。

Conclusion: BIBeR有效整合了结构化规划与数据驱动预测的优势，提升了自动驾驶系统在密集交互场景下的规划效果，为实现真正高效安全的自动驾驶提供了新的解决方案。

Abstract: Autonomous driving planning systems perform nearly perfectly in routine scenarios using lightweight, rule-based methods but still struggle in dense urban traffic, where lane changes and merges require anticipating and influencing other agents. Modern motion predictors offer highly accurate forecasts, yet their integration into planning is mostly rudimental: discarding unsafe plans. Similarly, end-to-end models offer a one-way integration that avoids the challenges of joint prediction and planning modeling under uncertainty. In contrast, game-theoretic formulations offer a principled alternative but have seen limited adoption in autonomous driving. We present Bayesian Iterative Best Response (BIBeR), a framework that unifies motion prediction and game-theoretic planning into a single interaction-aware process. BIBeR is the first to integrate a state-of-the-art predictor into an Iterative Best Response (IBR) loop, repeatedly refining the strategies of the ego vehicle and surrounding agents. This repeated best-response process approximates a Nash equilibrium, enabling bidirectional adaptation where the ego both reacts to and shapes the behavior of others. In addition, our proposed Bayesian confidence estimation quantifies prediction reliability and modulates update strength, more conservative under low confidence and more decisive under high confidence. BIBeR is compatible with modern predictors and planners, combining the transparency of structured planning with the flexibility of learned models. Experiments show that BIBeR achieves an 11% improvement over state-of-the-art planners on highly interactive interPlan lane-change scenarios, while also outperforming existing approaches on standard nuPlan benchmarks.

</details>


### [184] [MDE-AgriVLN: Agricultural Vision-and-Language Navigation with Monocular Depth Estimation](https://arxiv.org/abs/2512.03958)
*Xiaobei Zhao,Xingqi Lyu,Xiang Li*

Main category: cs.RO

TL;DR: 本论文提出了一种结合单目深度估计的农用机器人视觉-语言导航方法（MDE-AgriVLN），大幅提升了机器人根据自然语言指令自主导航的能力。


<details>
  <summary>Details</summary>
Motivation: 现有农用机器人在自主导航中多依赖人工操作或单一视觉信息，空间感知有限，难以高效完成基于语言指令的复杂移动任务。

Method: 提出了MDE-AgriVLN方法，引入单目深度估计（MDE）模块，利用RGB图像生成深度特征，并辅助导航决策，使机器人能够更好地理解三维环境并根据自然语言指令导航。

Result: 在A2A基准测试中，MDE-AgriVLN将成功率从0.23提升到0.32，导航误差从4.43米降低到4.08米，达到了该领域的新性能水平。

Conclusion: 单目深度估计模块显著提升了农用机器人视觉-语言导航的性能，为推进农业机器人智能化和自主化提供了有效新途径。

Abstract: Agricultural robots are serving as powerful assistants across a wide range of agricultural tasks, nevertheless, still heavily relying on manual operations or railway systems for movement. The AgriVLN method and the A2A benchmark pioneeringly extend Vision-and-Language Navigation (VLN) to the agricultural domain, enabling a robot to navigate to a target position following a natural language instruction. Unlike human binocular vision, most agricultural robots are only given a single camera for monocular vision, which results in limited spatial perception. To bridge this gap, we present the method of Agricultural Vision-and-Language Navigation with Monocular Depth Estimation (MDE-AgriVLN), in which we propose the MDE module generating depth features from RGB images, to assist the decision-maker on reasoning. When evaluated on the A2A benchmark, our MDE-AgriVLN method successfully increases Success Rate from 0.23 to 0.32 and decreases Navigation Error from 4.43m to 4.08m, demonstrating the state-of-the-art performance in the agricultural VLN domain. Code: https://github.com/AlexTraveling/MDE-AgriVLN.

</details>


### [185] [Artificial Microsaccade Compensation: Stable Vision for an Ornithopter](https://arxiv.org/abs/2512.03995)
*Levi Burner,Guido de Croon,Yiannis Aloimonos*

Main category: cs.RO

TL;DR: 本文提出了一种受生物眼动启发的新型视频稳定方法，能有效稳定高速振动下的无人机视频，并实现实时、高质量的去抖动效果。


<details>
  <summary>Details</summary>
Motivation: 受人类以及动物在注视点上会自然发生微小、快速眼动（微型扫视，microsaccades）的视觉机制启发，试图解决某些设备（如无尾扑翼无人机）摄像头因机体高频振动导致的严重视频抖动问题，而传统基于图像的稳定方法在此场景效果有限。

Method: 创新性地构建了“人工微型扫视补偿”方法，通过优化3D旋转（表示于SO(3)群），以最小化图像强度变化，实现帧间稳定。该方法支持实时递归地更新，有效减少快速振动带来的帧间运动，并能锁定特定视角，只有偶发跳跃（扫视）调整。

Result: 与业界公认最强的视频稳定工具Adobe Premiere Pro的warp stabilizer对比，该方法的稳定效果更优，并且可以实时运行，输出无失真、稳定、高可观看性的视频。

Conclusion: 该工作实现了在高频振动条件下，视频的实时稳定和高质量输出，为无人机等高速小型设备提供实用的视频稳定方案，同时拓展了生物启发计算在工程应用中的边界。

Abstract: Animals with foveated vision, including humans, experience microsaccades, small, rapid eye movements that they are not aware of. Inspired by this phenomenon, we develop a method for "Artificial Microsaccade Compensation". It can stabilize video captured by a tailless ornithopter that has resisted attempts to use camera-based sensing because it shakes at 12-20 Hz. Our approach minimizes changes in image intensity by optimizing over 3D rotation represented in SO(3). This results in a stabilized video, computed in real time, suitable for human viewing, and free from distortion. When adapted to hold a fixed viewing orientation, up to occasional saccades, it can dramatically reduce inter-frame motion while also benefiting from an efficient recursive update. When compared to Adobe Premier Pro's warp stabilizer, which is widely regarded as the best commercial video stabilization software available, our method achieves higher quality results while also running in real time.

</details>
