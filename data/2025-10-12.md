<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 103]
- [cs.CL](#cs.CL) [Total: 97]
- [cs.RO](#cs.RO) [Total: 35]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Enhancing Maritime Object Detection in Real-Time with RT-DETR and Data Augmentation](https://arxiv.org/abs/2510.07346)
*Nader Nemati*

Main category: cs.CV

TL;DR: 本文提出了一种基于RT-DETR的实时海事目标检测系统，有效融合了多尺度特征、选择性查询及真实与合成数据的权重优化，可提升小目标和低对比度目标的检测能力，并在真实数据上严格评估了性能。


<details>
  <summary>Details</summary>
Motivation: 海事目标（如船只）通常尺寸较小，且高质量标注的真实RGB图像数据有限，这给目标检测带来了很大挑战。本文旨在解决数据稀缺和小目标检测难题。

Method: 采用RT-DETR为基础，结合多尺度特征融合模块、基于不确定性最小化的查询选择、以及对合成与真实训练样本，通过权重平衡减少域差异。同时利用数据增强技术平衡数据集类别，整体提升模型鲁棒性和准确性。

Result: 系统在保持RT-DETR端到端预测设计精髓的同时，实现了高效实时检测，即使在极端光照或海况下也具备较强稳健性。并通过组件分析量化了各模块贡献。

Conclusion: 经充分实验验证，该系统有效提升了海事小目标检测性能，增强了模型在图像合成与真实域之间的泛化能力，适合实际海事场景应用。

Abstract: Maritime object detection faces essential challenges due to the small target
size and limitations of labeled real RGB data. This paper will present a
real-time object detection system based on RT-DETR, enhanced by employing
augmented synthetic images while strictly evaluating on real data. This study
employs RT-DETR for the maritime environment by combining multi-scale feature
fusion, uncertainty-minimizing query selection, and smart weight between
synthetic and real training samples. The fusion module in DETR enhances the
detection of small, low-contrast vessels, query selection focuses on the most
reliable proposals, and the weighting strategy helps reduce the visual gap
between synthetic and real domains. This design preserves DETR's refined
end-to-end set prediction while allowing users to adjust between speed and
accuracy at inference time. Data augmentation techniques were also used to
balance the different classes of the dataset to improve the robustness and
accuracy of the model. Regarding this study, a full Python robust maritime
detection pipeline is delivered that maintains real-time performance even under
practical limits. It also verifies how each module contributes, and how the
system handles failures in extreme lighting or sea conditions. This study also
includes a component analysis to quantify the contribution of each
architectural module and explore its interactions.

</details>


### [2] [DynamicEval: Rethinking Evaluation for Dynamic Text-to-Video Synthesis](https://arxiv.org/abs/2510.07441)
*Nithin C. Babu,Aniruddha Mahapatra,Harsh Rangwani,Rajiv Soundararajan,Kuldeep Kulkarni*

Main category: cs.CV

TL;DR: 本文提出DynamicEval基准，用于更全面地评估文本到视频（T2V）模型，特别关注动态镜头运动下的场景与对象一致性，有效弥补了现有基准的不足。


<details>
  <summary>Details</summary>
Motivation: 已有T2V评测基准主要关注静态或主体为中心的场景，缺乏对动态摄像运动下评估并大多只给出整体模型评分，忽视了单个视频质量的区别。这对影视级视频生成与视频选择优化带来局限。

Method: 作者系统性地设计了强调动态相机运动的提示，并构建了45k个人类标注的3k视频对比数据，评估了十个T2V模型。提出并改进了背景一致性与前景一致性两个度量：基于运动平滑性的误差图优化背景一致性，克服了原有VBench在遮挡等场景下的失败；前景一致性通过跟踪对象内部点及邻域来评估对象保真度。

Result: 新提出的度量方法与人类标注的一致性更高，无论在视频层面还是模型层面，相比现有指标提升超过2个百分点。

Conclusion: DynamicEval为动态相机运动下T2V模型的评估提供了更全面、贴近真实需求的基准，有助于推动多样视频场景下生成模型的研究与优化。

Abstract: Existing text-to-video (T2V) evaluation benchmarks, such as VBench and
EvalCrafter, suffer from two limitations. (i) While the emphasis is on
subject-centric prompts or static camera scenes, camera motion essential for
producing cinematic shots and existing metrics under dynamic motion are largely
unexplored. (ii) These benchmarks typically aggregate video-level scores into a
single model-level score for ranking generative models. Such aggregation,
however, overlook video-level evaluation, which is vital to selecting the
better video among the candidate videos generated for a given prompt. To
address these gaps, we introduce DynamicEval, a benchmark consisting of
systematically curated prompts emphasizing dynamic camera motion, paired with
45k human annotations on video pairs from 3k videos generated by ten T2V
models. DynamicEval evaluates two key dimensions of video quality: background
scene consistency and foreground object consistency. For background scene
consistency, we obtain the interpretable error maps based on the Vbench motion
smoothness metric. We observe that while the Vbench motion smoothness metric
shows promising alignment with human judgments, it fails in two cases:
occlusions/disocclusions arising from camera and foreground object movements.
Building on this, we propose a new background consistency metric that leverages
object error maps to correct two failure cases in a principled manner. Our
second innovation is the introduction of a foreground consistency metric that
tracks points and their neighbors within each object instance to assess object
fidelity. Extensive experiments demonstrate that our proposed metrics achieve
stronger correlations with human preferences at both the video level and the
model level (an improvement of more than 2% points), establishing DynamicEval
as a more comprehensive benchmark for evaluating T2V models under dynamic
camera motion.

</details>


### [3] [Provably Accelerated Imaging with Restarted Inertia and Score-based Image Priors](https://arxiv.org/abs/2510.07470)
*Marien Renaud,Julien Hermant,Deliang Wei,Yu Sun*

Main category: cs.CV

TL;DR: 提出了一种新的图像逆问题算法RISP，兼顾了快速收敛和高质量图像恢复。


<details>
  <summary>Details</summary>
Motivation: 目前的图像逆问题算法（如RED）侧重于设计高质量先验提升图像重建质量，但对于加快算法收敛往往依赖启发式方法，两者难以兼顾。本文旨在同时解决这两大难题。

Method: 作者提出了一种带有重启惯性的算法RISP，将“重启惯性”机制与基于分数的图像先验结合，实现加速收敛的同时保证高重建质量。他们还证明了RISP在无需先验凸性前提下有更快的收敛速率，并且分析了其对应的连续时间动力系统，与重球ODE建立联系。

Result: 实验证明，RISP在多种图像逆问题任务上展现了更快的收敛速度和高质量的重建表现。

Conclusion: RISP能有效整合收敛速度与重建质量两方面优势，为图像逆问题提供了新的高效解决方案。

Abstract: Fast convergence and high-quality image recovery are two essential features
of algorithms for solving ill-posed imaging inverse problems. Existing methods,
such as regularization by denoising (RED), often focus on designing
sophisticated image priors to improve reconstruction quality, while leaving
convergence acceleration to heuristics. To bridge the gap, we propose Restarted
Inertia with Score-based Priors (RISP) as a principled extension of RED. RISP
incorporates a restarting inertia for fast convergence, while still allowing
score-based image priors for high-quality reconstruction. We prove that RISP
attains a faster stationary-point convergence rate than RED, without requiring
the convexity of the image prior. We further derive and analyze the associated
continuous-time dynamical system, offering insight into the connection between
RISP and the heavy-ball ordinary differential equation (ODE). Experiments
across a range of imaging inverse problems demonstrate that RISP enables fast
convergence while achieving high-quality reconstructions.

</details>


### [4] [A Denoising Framework for Real-World Ultra-Low Dose Lung CT Images Based on an Image Purification Strategy](https://arxiv.org/abs/2510.07492)
*Guoliang Gong,Man Yu*

Main category: cs.CV

TL;DR: 该论文提出了一种创新的超低剂量CT（uLDCT）去噪框架，通过影像净化（Image Purification, IP）策略和频域流匹配（FFM）模型，有效解决了uLDCT与常规剂量CT（NDCT）配对图像空间不对齐及噪声严重等难题，实现了最先进的解剖结构保护能力。


<details>
  <summary>Details</summary>
Motivation: uLDCT极大减少了辐射剂量，但会导致图像噪声和伪影显著增加，且实际采集的uLDCT与NDCT配对图像常常空间错位，现有依赖于合成噪声或对齐数据的去噪网络难以直接应用于真实场景。因此，迫切需要新的方法去解决数据错配和结构保真问题。

Method: 构建了一个真实的临床uLDCT肺部数据集。提出影像净化（IP）策略，可生成结构高度对齐的uLDCT-NDCT图像对，为网络训练提供高质量数据基础。在此基础上，提出了一种基于频域流匹配（FFM）的去噪模型，与IP策略协同作用，有效保持解剖结构的完整性。

Result: 在真实临床数据集上的实验表明，影像净化（IP）策略显著提升了主流去噪模型在uLDCT任务上的整体性能，同时，FFM模型与IP策略联合，取得了当前最优的解剖结构保真效果。

Conclusion: 该研究针对实际uLDCT去噪中的数据错配问题，提出了切实有效的解决方案，为后续相关研究和实际应用提供了高质量的数据基础和模型工具。附带代码与数据集公开，便于学界与业界参考和应用。

Abstract: Ultra-low dose CT (uLDCT) significantly reduces radiation exposure but
introduces severe noise and artifacts. It also leads to substantial spatial
misalignment between uLDCT and normal dose CT (NDCT) image pairs. This poses
challenges for directly applying existing denoising networks trained on
synthetic noise or aligned data. To address this core challenge in uLDCT
denoising, this paper proposes an innovative denoising framework based on an
Image Purification (IP) strategy. First, we construct a real clinical uLDCT
lung dataset. Then, we propose an Image Purification strategy that generates
structurally aligned uLDCT-NDCT image pairs, providing a high-quality data
foundation for network training. Building upon this, we propose a
Frequency-domain Flow Matching (FFM) model, which works synergistically with
the IP strategy to excellently preserve the anatomical structure integrity of
denoised images. Experiments on the real clinical dataset demonstrate that our
IP strategy significantly enhances the performance of multiple mainstream
denoising models on the uLDCT task. Notably, our proposed FFM model combined
with the IP strategy achieves state-of-the-art (SOTA) results in anatomical
structure preservation. This study provides an effective solution to the data
mismatch problem in real-world uLDCT denoising. Code and dataset are available
at https://github.com/MonkeyDadLufy/flow-matching.

</details>


### [5] [D2RA: Dual Domain Regeneration Attack](https://arxiv.org/abs/2510.07538)
*Pragati Shuddhodhan Meshram,Varun Chandrasekaran*

Main category: cs.CV

TL;DR: 该论文提出攻击现有生成内容水印的新方法D2RA，无需访问生成模型即可有效去除图片中的水印，同时保持图像质量。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型广泛应用，内容归属和溯源变得关键，导致对鲁棒性强的水印技术需求上升，但现有方案仍易被攻击。

Method: D2RA是一种无需训练、仅用单张图片的攻击方法。该方法通过将带水印图片投影到自然先验的多种互补表现空间，有效削弱或移除水印，同时不损伤图像表现。

Result: 实验证明，D2RA能在多种水印技术下持续显著降低水印可检测性，维持较高视觉保真度，展现了现有水印设计的根本性弱点。

Conclusion: 当前生成内容的水印方法面对D2RA存在明显弱点，亟需更安全、鲁棒的水印机制来保障内容溯源。

Abstract: The growing use of generative models has intensified the need for
watermarking methods that ensure content attribution and provenance. While
recent semantic watermarking schemes improve robustness by embedding signals in
latent or frequency representations, we show they remain vulnerable even under
resource-constrained adversarial settings. We present D2RA, a training-free,
single-image attack that removes or weakens watermarks without access to the
underlying model. By projecting watermarked images onto natural priors across
complementary representations, D2RA suppresses watermark signals while
preserving visual fidelity. Experiments across diverse watermarking schemes
demonstrate that our approach consistently reduces watermark detectability,
revealing fundamental weaknesses in current designs. Our code is available at
https://github.com/Pragati-Meshram/DAWN.

</details>


### [6] [PickStyle: Video-to-Video Style Transfer with Context-Style Adapters](https://arxiv.org/abs/2510.07546)
*Soroush Mehraban,Vida Adeli,Jacob Rommann,Babak Taati,Kyryl Truskovskyi*

Main category: cs.CV

TL;DR: 提出了一种名为PickStyle的基于扩散模型的视频风格迁移方法，通过引入风格适配器和特殊训练机制，实现了高质量的视频内容保持和风格转化。


<details>
  <summary>Details</summary>
Motivation: 视频风格迁移缺乏配对的数据监督，现有方法难以同时保证视频内容保持和风格一致性，因此亟需新的方法来解决这些挑战。

Method: 1. 基于预训练视频扩散模型，插入低秩风格适配器到自注意力层，用于高效运动-风格迁移。2. 利用配对的静态图片，通过共享增强构建合成训练片段以模拟视频运动，桥接静态图像与动态视频的监督差距。3. 提出CS-CFG（Context-Style Classifier-Free Guidance），将引导分解到文本（风格）和视频（内容）两个独立方向，确保视频内容保持和风格转化。

Result: 在多个基准测试中，该方法的视频风格迁移结果在时间一致性、风格保持和内容保持方面均优于现有方法，无论是定性还是定量上都取得了更好的表现。

Conclusion: PickStyle显著提升了视频风格迁移的质量和一致性，为该领域提供了新的思路和高效的工程实现。

Abstract: We address the task of video style transfer with diffusion models, where the
goal is to preserve the context of an input video while rendering it in a
target style specified by a text prompt. A major challenge is the lack of
paired video data for supervision. We propose PickStyle, a video-to-video style
transfer framework that augments pretrained video diffusion backbones with
style adapters and benefits from paired still image data with source-style
correspondences for training. PickStyle inserts low-rank adapters into the
self-attention layers of conditioning modules, enabling efficient
specialization for motion-style transfer while maintaining strong alignment
between video content and style. To bridge the gap between static image
supervision and dynamic video, we construct synthetic training clips from
paired images by applying shared augmentations that simulate camera motion,
ensuring temporal priors are preserved. In addition, we introduce Context-Style
Classifier-Free Guidance (CS-CFG), a novel factorization of classifier-free
guidance into independent text (style) and video (context) directions. CS-CFG
ensures that context is preserved in generated video while the style is
effectively transferred. Experiments across benchmarks show that our approach
achieves temporally coherent, style-faithful, and content-preserving video
translations, outperforming existing baselines both qualitatively and
quantitatively.

</details>


### [7] [TRAVL: A Recipe for Making Video-Language Models Better Judges of Physics Implausibility](https://arxiv.org/abs/2510.07550)
*Saman Motamed,Minghao Chen,Luc Van Gool,Iro Laina*

Main category: cs.CV

TL;DR: 当前视频生成模型虽然画面精美，但常出现违背物理常识的异常现象。为此，本文提出基于视觉-语言模型（VLM）的物理可信性判别方法，并借助TRAVL优化方案和ImplausiBench基准库，提升模型物理推理能力与评估标准。


<details>
  <summary>Details</summary>
Motivation: 视频生成模型往往会出现如物体悬浮、瞬移、不合理变形等不符合直觉物理规律的问题。而人类能轻松识别这些异常，现有算法却缺乏量化视频物理真实性的有效手段。因此，作者希望探索如何让AI像人类一样识别视频中的物理不合理性。

Method: 作者首先验证了现有视频-语言模型（VLM）在检测视频物理异常上的不足。随后，提出TRAVL调优方法，结合平衡的训练数据集和轨迹感知注意力模块，加强VLM对运动轨迹的编码和判别能力。同时，提出了ImplausiBench基准库，该库包括300个去除语言偏见（150真实、150生成）的测试视频，专注于视觉-时序理解能力的评估。评测方法兼用人工和LLM自动判分。

Result: 经TRAVL调优后的VLM在ImplausiBench基准库上表现优于未优化模型，尤其在人类和LLM双重评判标准下，运动和因果关系推断能力有显著提升。ImplausiBench客观地反映了其物理可信性识别能力的提升。

Conclusion: 本文提出的TRAVL和ImplausiBench体系，为多模态模型的物理可信性评估和提升提供了有效框架。这为视觉-时序理解领域的物理推理研究和应用带来新的突破，并揭示了现有模型在物理合理性判断上的不足。

Abstract: Despite impressive visual fidelity, modern video generative models frequently
produce sequences that violate intuitive physical laws, such as objects
floating, teleporting, or morphing in ways that defy causality. While humans
can easily detect such implausibilities, there remains no robust method for
quantitatively assessing physical realism in video. In this work, we explore
whether Video-Language Models (VLMs) can be trained to serve as reliable judges
of physical plausibility. We find that existing VLMs struggle to identify
physics violations, exposing fundamental limitations in their temporal and
causal reasoning. To address this, we introduce TRAVL, a fine-tuning recipe
that combines a balanced training dataset with a trajectory-aware attention
module to improve motion encoding and discrimination in VLMs. To evaluate
physical reasoning more rigorously, we propose ImplausiBench, a benchmark of
300 videos (150 real, 150 generated) that removes linguistic biases and
isolates visual-temporal understanding. Performance is reported both with
gold-standard human judgments and stricter LLM-as-judge metrics. Together,
TRAVL and ImplausiBench offer a unified framework for probing and improving
physical plausibility in multimodal models, shedding light on a challenging and
underexplored aspect of visual-temporal understanding.

</details>


### [8] [Label Semantics for Robust Hyperspectral Image Classification](https://arxiv.org/abs/2510.07556)
*Rafin Hassan,Zarin Tasnim Roshni,Rafiqul Bari,Alimul Islam,Nabeel Mohammed,Moshiur Farazi,Shafin Rahman*

Main category: cs.CV

TL;DR: 本文提出了一种通用的语义光谱-空间融合网络（S3FN），利用大语言模型生成的类别文本描述，提升高光谱图像分类效果，并在多个数据集上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像分类因训练样本有限和高维特征易过拟合，且现有方法大多只利用单一光谱-空间信息，导致分类精度与计算复杂度难以权衡。因此需要引入更丰富的语义信息辅助分类。

Method: 作者提出S3FN方法，利用大语言模型（LLM）为每个类别自动生成并编码文本语义描述，通过预训练文本编码器（如BERT等）将其向量化后引入分类网络，与光谱-空间特征融合，实现更优的特征-标签对齐。

Result: 在Hyperspectral Wood、Hyperspectral Blueberries、DeepHS-Fruit三个高光谱公开基准数据集上，S3FN取得了显著优于现有方法的分类表现，证明引入文本语义信息能够有效提升模型泛化能力。

Conclusion: 本文方法展示了语义信息与光谱-空间特征的互补性，为结合文本增强的高光谱分类研究提供了新思路，未来有望推动更多语义驱动的遥感分类应用。

Abstract: Hyperspectral imaging (HSI) classification is a critical tool with widespread
applications across diverse fields such as agriculture, environmental
monitoring, medicine, and materials science. Due to the limited availability of
high-quality training samples and the high dimensionality of spectral data, HSI
classification models are prone to overfitting and often face challenges in
balancing accuracy and computational complexity. Furthermore, most of HSI
classification models are monomodal, where it solely relies on spectral-spatial
data to learn decision boundaries in the high dimensional embedding space. To
address this, we propose a general-purpose Semantic Spectral-Spatial Fusion
Network (S3FN) that uses contextual, class specific textual descriptions to
complement the training of an HSI classification model. Specifically, S3FN
leverages LLMs to generate comprehensive textual descriptions for each class
label that captures their unique characteristics and spectral behaviors. These
descriptions are then embedded into a vector space using a pre-trained text
encoder such as BERT or RoBERTa to extract meaningful label semantics which in
turn leads to a better feature-label alignment for improved classification
performance. To demonstrate the effectiveness of our approach, we evaluate our
model on three diverse HSI benchmark datasets - Hyperspectral Wood,
HyperspectralBlueberries, and DeepHS-Fruit and report significant performance
boost. Our results highlight the synergy between textual semantics and
spectral-spatial data, paving the way for further advancements in semantically
augmented HSI classification models. Codes are be available in:
https://github.com/milab-nsu/S3FN

</details>


### [9] [Cross-Modal Attention Guided Unlearning in Vision-Language Models](https://arxiv.org/abs/2510.07567)
*Karuna Bhaila,Aneesh Komanduri,Minh-Hao Van,Xintao Wu*

Main category: cs.CV

TL;DR: 本文提出了一种高效的视觉-语言模型（VLM）可遗忘解决方案，能够在不改动模型参数或重新训练的前提下，有效阻止敏感信息泄露，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言模型在视觉问答等任务中展现了强大的推理能力，但大规模训练数据可能导致模型记住并泄露敏感信息。现有的机器遗忘方法主要针对文本模型，视觉-语言模型由于包含视觉信息，遗忘处理更为复杂，因此亟需新的解决方案。

Method: 作者提出了一种跨模态注意力引导的遗忘机制（CAGUL）。通过分析视觉token在输出生成中的作用，并利用外部模块将遗忘信息编码到对相关查询贡献低的重要性低的视觉token中，实现轻量高效的遗忘，无需重新训练模型参数。

Result: 实验表明，该方法在不更改预训练模型参数且无需消耗高昂训练资源的前提下，有效阻止敏感信息泄露，并且在性能上优于或不逊色于现有微调式基线方法。

Conclusion: CAGUL为视觉-语言模型提供了一种实际有效的可遗忘框架，具有高效、无需打断原有模型结构、性能保留等优点，对于处理多模态模型中的隐私与敏感数据泄露问题意义重大。

Abstract: Vision-Language Models (VLMs) have demonstrated immense capabilities in
multi-modal understanding and inference tasks such as Visual Question Answering
(VQA), which requires models to infer outputs based on visual and textual
context simultaneously. Such inference abilities of large-scale pretrained
models are often attributed to the massive scale of pre-training data collected
across several domains. However, the models may memorize private and/or
sensitive information during training and regurgitate it in inference.
Recently, machine unlearning has been leveraged to address the leakage of
private data in LLMs. VLMs add a layer of complexity to this process, as the
visual context in the query may also contain sensitive information in addition
to the text. To address this issue, we explore unlearning for vision-language
models, specifically for the VQA task. We explore the role of visual tokens for
output generation in VLMs using cross-modal attention and utilize it to
formulate Cross-Modal Attention Guided Unlearning (CAGUL), a lightweight and
efficient VLM unlearning framework. In contrast to computationally expensive
model finetuning methods, CAGUL utilizes external modules to encode unlearning
information in visual tokens of low importance for relevant queries. We find
that the transformed visual tokens not only prevent leakage but also retain
reference model behavior. Experimental results show that our method performs
better or on par with finetuning-based baselines without altering the
pre-trained model parameters or incurring retraining costs, making it a
practical and effective unlearning solution for VLMs.

</details>


### [10] [MaizeStandCounting (MaSC): Automated and Accurate Maize Stand Counting from UAV Imagery Using Image Processing and Deep Learning](https://arxiv.org/abs/2510.07580)
*Dewi Endah Kharismawati,Toni Kazic*

Main category: cs.CV

TL;DR: 本文提出了一种基于低成本无人机和轻量化YOLOv9模型的玉米幼苗自动统计系统MaSC，能够高效、准确地进行地块玉米苗数统计。


<details>
  <summary>Details</summary>
Motivation: 玉米苗数的准确统计对于产量预测、种植密度优化和早期发芽问题发现具有重要意义。人工统计既费时费力又容易出错，尤其在大面积或地块异质性明显时问题更加突出。

Method: MaSC算法可以处理两类数据：一是将无人机航拍拼接后的马赛克大图切片，二是对原始视频帧进行单应性配准。两种模式均利用轻量YOLOv9模型，检测V2-V10生育期的玉米幼苗。算法可区分玉米与杂草、其它植被，并基于空间分布进行行与范围分割，输出每行的玉米苗统计数。

Result: 与田间人工调查数据对比，MaSC在拼接图像模式下R^2为0.616，原始帧模式下R^2为0.906，显示出良好的一致性。系统可在60.63秒内完成83张全分辨率帧的推理与后处理，具备实时应用潜力。

Conclusion: MaSC是一款可扩展、低成本且准确的自动化玉米苗数统计工具，适用于科研和生产环境，有助于提升作物管理和数据收集效率。

Abstract: Accurate maize stand counts are essential for crop management and research,
informing yield prediction, planting density optimization, and early detection
of germination issues. Manual counting is labor-intensive, slow, and
error-prone, especially across large or variable fields. We present
MaizeStandCounting (MaSC), a robust algorithm for automated maize seedling
stand counting from RGB imagery captured by low-cost UAVs and processed on
affordable hardware. MaSC operates in two modes: (1) mosaic images divided into
patches, and (2) raw video frames aligned using homography matrices. Both modes
use a lightweight YOLOv9 model trained to detect maize seedlings from V2-V10
growth stages. MaSC distinguishes maize from weeds and other vegetation, then
performs row and range segmentation based on the spatial distribution of
detections to produce precise row-wise stand counts. Evaluation against
in-field manual counts from our 2024 summer nursery showed strong agreement
with ground truth (R^2= 0.616 for mosaics, R^2 = 0.906 for raw frames). MaSC
processed 83 full-resolution frames in 60.63 s, including inference and
post-processing, highlighting its potential for real-time operation. These
results demonstrate MaSC's effectiveness as a scalable, low-cost, and accurate
tool for automated maize stand counting in both research and production
environments.

</details>


### [11] [Quick-CapsNet (QCN): A fast alternative to Capsule Networks](https://arxiv.org/abs/2510.07600)
*Pouya Shiri,Ramin Sharifi,Amirali Baniasadi*

Main category: cs.CV

TL;DR: 该论文提出了一种名为Quick-CapsNet（QCN）的快速胶囊网络结构，相比传统CapsNet大幅提升推理速度，同时只带来了轻微的精度损失。


<details>
  <summary>Details</summary>
Motivation: 传统的胶囊网络（CapsNet）虽然在表征能力和鲁棒性方面优于卷积神经网络（CNNs），但其训练和推理速度较慢，限制了其在实时或对速度敏感的应用中的实际推广。作者希望改进CapsNet的速度瓶颈，使其更适用于实时场景。

Method: QCN通过减少胶囊数量设计网络，在保证合理精度的情况下，显著提升运算速度。此外，作者还尝试用更强的解码器替换默认解码器，以进一步提升QCN性能。

Result: 在MNIST、F-MNIST、SVHN和Cifar-10等数据集上，与原始CapsNet相比，QCN推理速度提升了5倍，同时只带来了边际的精度下降。使用更强解码器后，性能进一步增强。

Conclusion: QCN为需要快速推理的场景提供了一个实用的胶囊网络变体，可以作为CapsNet向实时应用发展方向的起点；尽管有些许精度损失，但其速度提升非常可观。

Abstract: The basic computational unit in Capsule Network (CapsNet) is a capsule (vs.
neurons in Convolutional Neural Networks (CNNs)). A capsule is a set of
neurons, which form a vector. CapsNet is used for supervised classification of
data and has achieved state-of-the-art accuracy on MNIST digit recognition
dataset, outperforming conventional CNNs in detecting overlapping digits.
Moreover, CapsNet shows higher robustness towards affine transformation when
compared to CNNs for MNIST datasets. One of the drawbacks of CapsNet, however,
is slow training and testing. This can be a bottleneck for applications that
require a fast network, especially during inference. In this work, we introduce
Quick-CapsNet (QCN) as a fast alternative to CapsNet, which can be a starting
point to develop CapsNet for fast real-time applications. QCN builds on
producing a fewer number of capsules, which results in a faster network. QCN
achieves this at the cost of marginal loss in accuracy. Inference is 5x faster
on MNIST, F-MNIST, SVHN and Cifar-10 datasets. We also further enhanced QCN by
employing a more powerful decoder instead of the default decoder to further
improve QCN.

</details>


### [12] [Rectified-CFG++ for Flow Based Models](https://arxiv.org/abs/2510.07631)
*Shreshth Saini,Shashank Gupta,Alan C. Bovik*

Main category: cs.CV

TL;DR: 提出了一种改进的分类器自由引导方法（Rectified-CFG++），用于提升基于rectified flow (RF)模型的文本条件生成效果，解决了原生CFG应用在RF模型时出现的偏离数据流形、可视化伪影及文本对齐差等问题。


<details>
  <summary>Details</summary>
Motivation: 现有的分类器自由引导（CFG）方法在大型扩散模型中表现良好，但直接应用在rectified flow（RF）模型时，易导致严重的样本偏离数据流形，引发结果不稳、伪影多、文本不符等问题，因此亟需更适合RF模型的引导方法。

Method: 提出Rectified-CFG++方法，将预测-修正步骤引入引导过程。每步推理中，先执行条件RF更新，使样本靠近学习的传输路径，再用加权的条件修正插值调和有条件和无条件的速度场。理论上证明此方法能保证速度场边际一致性，并且采样轨迹稳定在数据流形附近。

Result: 在大型文本到图像生成模型（如Flux、Stable Diffusion 3/3.5、Lumina）上进行大量实验，Rectified-CFG++在MS-COCO、LAION-Aesthetic、T2I-CompBench等多个基准数据集上均超越标准CFG。

Conclusion: Rectified-CFG++有效解决了CFG在RF模型中的应用难题，实现了更稳定、贴合的文本条件生成，对于提升大规模生成模型的表现具有重要意义。

Abstract: Classifier-free guidance (CFG) is the workhorse for steering large diffusion
models toward text-conditioned targets, yet its native application to rectified
flow (RF) based models provokes severe off-manifold drift, yielding visual
artifacts, text misalignment, and brittle behaviour. We present
Rectified-CFG++, an adaptive predictor-corrector guidance that couples the
deterministic efficiency of rectified flows with a geometry-aware conditioning
rule. Each inference step first executes a conditional RF update that anchors
the sample near the learned transport path, then applies a weighted conditional
correction that interpolates between conditional and unconditional velocity
fields. We prove that the resulting velocity field is marginally consistent and
that its trajectories remain within a bounded tubular neighbourhood of the data
manifold, ensuring stability across a wide range of guidance strengths.
Extensive experiments on large-scale text-to-image models (Flux, Stable
Diffusion 3/3.5, Lumina) show that Rectified-CFG++ consistently outperforms
standard CFG on benchmark datasets such as MS-COCO, LAION-Aesthetic, and
T2I-CompBench. Project page: https://rectified-cfgpp.github.io/

</details>


### [13] [PIT-QMM: A Large Multimodal Model For No-Reference Point Cloud Quality Assessment](https://arxiv.org/abs/2510.07636)
*Shashank Gupta,Gregoire Phillips,Alan C. Bovik*

Main category: cs.CV

TL;DR: 本文提出了一种创新的无参考点云质量评估方法PIT-QMM，能够融合文本、2D图像和3D点云多模态信息，实现更精准的点云质量自动评测。实验结果显示该方法显著优于现有技术，并可支持失真定位与识别。


<details>
  <summary>Details</summary>
Motivation: 受现有点云质量评测方法局限启发，尤其在无参考场景下评估点云质量面临参考难获取、多模态信息利用不足等挑战。研究者希望借助最新大型多模态模型（LMM）推进点云无参考质量评估能力，提高自动化和智能化水平。

Method: 作者设计了PIT-QMM，一种新型的多模态大型模型。该模型可以端到端地融合文本描述、2D投影和3D点云三种模态数据，以综合判断点云的感知质量。通过丰富的实验对PIT-QMM的性能进行评估，并与主流方法进行了对比。

Result: PIT-QMM在多个主流点云质量评测基准上均显著超越现有最佳方法，并且需要更少的训练轮数即可达到更优效果。此外，该框架还能实现点云失真区域的定位和失真类型的识别。

Conclusion: PIT-QMM展示了大型多模态模型在点云无参考质量评估领域的巨大潜力，为模型的可解释性和交互性提供了新方向，对推动3D资产质量自动化评测具有重要意义。

Abstract: Large Multimodal Models (LMMs) have recently enabled considerable advances in
the realm of image and video quality assessment, but this progress has yet to
be fully explored in the domain of 3D assets. We are interested in using these
models to conduct No-Reference Point Cloud Quality Assessment (NR-PCQA), where
the aim is to automatically evaluate the perceptual quality of a point cloud in
absence of a reference. We begin with the observation that different modalities
of data - text descriptions, 2D projections, and 3D point cloud views - provide
complementary information about point cloud quality. We then construct PIT-QMM,
a novel LMM for NR-PCQA that is capable of consuming text, images and point
clouds end-to-end to predict quality scores. Extensive experimentation shows
that our proposed method outperforms the state-of-the-art by significant
margins on popular benchmarks with fewer training iterations. We also
demonstrate that our framework enables distortion localization and
identification, which paves a new way forward for model explainability and
interactivity. Code and datasets are available at
https://www.github.com/shngt/pit-qmm.

</details>


### [14] [Dual-Stream Alignment for Action Segmentation](https://arxiv.org/abs/2510.07652)
*Harshala Gammulle,Clinton Fookes,Sridha Sridharan,Simon Denman*

Main category: cs.CV

TL;DR: 本文提出了一种用于动作分割的双流对齐网络（DSA Net），结合了帧级特征流和动作级特征流，并通过量子-经典混合方法及专用损失函数实现特征对齐，在多个基准数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统的动作分割方法主要关注于单流（单序列空间-时间建模），难以充分捕捉动作及其切换过程中的复杂特征。近期研究关注增加动作级特征，但融合方式和信息对齐存在瓶颈，因此有必要提出更有效的多流融合与对齐方法，提升分割性能。

Method: 本文设计了Dual-Stream Alignment Network（DSA Net），包含帧级特征流和动作级特征流，引入Temporal Context（TC）块实现跨流信息融合，并利用基于量子机制的动作引导调制（Q-ActGM）增强特征表达能力。通过Dual-Stream Alignment Loss（结合关系一致性、跨层对比和循环一致性重建等三种损失），促进两流特征空间对齐。整个框架为混合量子-经典机器学习方法。

Result: 在GTEA、Breakfast、50Salads与EgoProcel等多数据集上的实验与消融研究表明，DSA Net显著优于现有方法，达到了新的最优性能，并证实了各组成部分的有效性。

Conclusion: 论文首次提出了混合量子-经典双流对齐动作分割框架，并证明了通过特征对齐及量子机制调制，可以有效提升动作分割识别能力，为该领域研究提供了创新方向和新工具。

Abstract: Action segmentation is a challenging yet active research area that involves
identifying when and where specific actions occur in continuous video streams.
Most existing work has focused on single-stream approaches that model the
spatio-temporal aspects of frame sequences. However, recent research has
shifted toward two-stream methods that learn action-wise features to enhance
action segmentation performance. In this work, we propose the Dual-Stream
Alignment Network (DSA Net) and investigate the impact of incorporating a
second stream of learned action features to guide segmentation by capturing
both action and action-transition cues. Communication between the two streams
is facilitated by a Temporal Context (TC) block, which fuses complementary
information using cross-attention and Quantum-based Action-Guided Modulation
(Q-ActGM), enhancing the expressive power of the fused features. To the best of
our knowledge, this is the first study to introduce a hybrid quantum-classical
machine learning framework for action segmentation. Our primary objective is
for the two streams (frame-wise and action-wise) to learn a shared feature
space through feature alignment. This is encouraged by the proposed Dual-Stream
Alignment Loss, which comprises three components: relational consistency,
cross-level contrastive, and cycle-consistency reconstruction losses. Following
prior work, we evaluate DSA Net on several diverse benchmark datasets: GTEA,
Breakfast, 50Salads, and EgoProcel. We further demonstrate the effectiveness of
each component through extensive ablation studies. Notably, DSA Net achieves
state-of-the-art performance, significantly outperforming existing

</details>


### [15] [Once Is Enough: Lightweight DiT-Based Video Virtual Try-On via One-Time Garment Appearance Injection](https://arxiv.org/abs/2510.07654)
*Yanjie Pan,Qingdong He,Lidong Wang,Bo Peng,Mingmin Chi*

Main category: cs.CV

TL;DR: 本文提出了一种高效的视频虚拟试衣方法，只需编辑视频第一帧的服装，后续帧通过内容、姿态与掩码等信息自动合成，显著减少了参数量和计算量，并取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频虚拟试衣的方法，虽然基于扩散模型取得不错效果，但将其应用到Diffusion Transformer时存在架构复杂、参数量大、时序特征难建模等挑战。

Method: 提出OIE（Once is Enough）策略。首先用图像级虚拟试衣将初始帧服装更换，然后以编辑后的首帧为内容控制，结合姿态和掩码信息，引导视频生成模型逐帧合成后续画面，无需复杂架构或大量参数。

Result: 实验表明，该方法在参数和算力消耗上更为高效，同时在视频虚拟试衣任务上依旧表现领先。

Conclusion: OIE策略在降低网络复杂度和资源消耗的同时，保证了视频虚拟试衣的生成质量，具备实际场景应用潜力。

Abstract: Video virtual try-on aims to replace the clothing of a person in a video with
a target garment. Current dual-branch architectures have achieved significant
success in diffusion models based on the U-Net; however, adapting them to
diffusion models built upon the Diffusion Transformer remains challenging.
Initially, introducing latent space features from the garment reference branch
requires adding or modifying the backbone network, leading to a large number of
trainable parameters. Subsequently, the latent space features of garments lack
inherent temporal characteristics and thus require additional learning. To
address these challenges, we propose a novel approach, OIE (Once is Enough), a
virtual try-on strategy based on first-frame clothing replacement:
specifically, we employ an image-based clothing transfer model to replace the
clothing in the initial frame, and then, under the content control of the
edited first frame, utilize pose and mask information to guide the temporal
prior of the video generation model in synthesizing the remaining frames
sequentially. Experiments show that our method achieves superior parameter
efficiency and computational efficiency while still maintaining leading
performance under these constraints.

</details>


### [16] [MONKEY: Masking ON KEY-Value Activation Adapter for Personalization](https://arxiv.org/abs/2510.07656)
*James Baker*

Main category: cs.CV

TL;DR: 本文提出通过自动生成的掩码，引导扩散模型在个性化生成时更好地结合主题和文本提示，有效提升了结果与文本和原图的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有个性化扩散模型虽然能将个体主题融入新图像，但常常出现仅复现原主题而忽略文本提示的情况，缺乏有效结合图文信息的手段。作者希望解决该失配问题。

Method: 观察到IP-Adapter自动生成掩码以区分主题与背景，作者提出在第二阶段利用这些掩码，仅让原图的主题区域参与生成过程，使文本提示可以更好地控制背景等其他内容。

Result: 实验证明，对于描述位置与场所等场景的文本提示，方法可以更加准确且协调地表现出主题和文字内容，在对比现有测试时个性化方法时，也表现出更高的图文一致性。

Conclusion: 使用自动掩码的双阶段个性化方法，有效改善了个性化扩散模型中主题再现与文本提示匹配的矛盾，实现了更好的结果对齐。

Abstract: Personalizing diffusion models allows users to generate new images that
incorporate a given subject, allowing more control than a text prompt. These
models often suffer somewhat when they end up just recreating the subject
image, and ignoring the text prompt. We observe that one popular method for
personalization, the IP-Adapter automatically generates masks that we
definitively segment the subject from the background during inference. We
propose to use this automatically generated mask on a second pass to mask the
image tokens, thus restricting them to the subject, not the background,
allowing the text prompt to attend to the rest of the image. For text prompts
describing locations and places, this produces images that accurately depict
the subject while definitively matching the prompt. We compare our method to a
few other test time personalization methods, and find our method displays high
prompt and source image alignment.

</details>


### [17] [Automatic Text Box Placement for Supporting Typographic Design](https://arxiv.org/abs/2510.07665)
*Jun Muraoka,Daichi Haraguchi,Naoto Inoue,Wataru Shimoda,Kota Yamaguchi,Seiichi Uchida*

Main category: cs.CV

TL;DR: 本文比较了几种自动文本框布局方法，发现Transformer类模型整体优于VLM模型，但在小文本或密集布局下仍有困难。


<details>
  <summary>Details</summary>
Motivation: 广告和网页设计中，自动化布局需要兼顾美观与信息传达效率，目前相关模型的有效性有待系统比较。

Method: 作者比较了标准Transformer、小型视觉语言模型（Phi3.5-vision）、大型预训练VLM（Gemini）及可处理多图的扩展Transformer，并在Crello数据集上评测其文本框自动布局性能。

Result: 实验证明，标准Transformer模型（尤其是融合丰富外观信息后）通常效果优于VLM方法，但所有方法在处理极小文本或高密度布局时效果有限。

Conclusion: 面向任务的专用架构在自动布局中仍具有优势，但现有方法仍存在不足，未来可进一步优化以提升自动化设计表现。

Abstract: In layout design for advertisements and web pages, balancing visual appeal
and communication efficiency is crucial. This study examines automated text box
placement in incomplete layouts, comparing a standard Transformer-based method,
a small Vision and Language Model (Phi3.5-vision), a large pretrained VLM
(Gemini), and an extended Transformer that processes multiple images.
Evaluations on the Crello dataset show the standard Transformer-based models
generally outperform VLM-based approaches, particularly when incorporating
richer appearance information. However, all methods face challenges with very
small text or densely populated layouts. These findings highlight the benefits
of task-specific architectures and suggest avenues for further improvement in
automated layout design.

</details>


### [18] [TCIP: Threshold-Controlled Iterative Pyramid Network for Deformable Medical Image Registration](https://arxiv.org/abs/2510.07666)
*Heming Wu,Di Wang,Tai Ma,Peng Zhao,Yubin Xiao,Zhongke Wu,Xing-Ce Wang,Chuang Li,Xuan Wu,You Zhou*

Main category: cs.CV

TL;DR: 本论文提出了一种用于医学图像配准的新型金字塔网络架构，能够有效抑制解码器引入的解剖结构错位累积问题，并通过动态确定适应图像需求的迭代次数提升配准精度。


<details>
  <summary>Details</summary>
Motivation: 现有的金字塔网络虽然在可变形医学图像配准中表现优秀，但解码器结构易于放大解剖结构的错位；此外，现有方法无法根据不同图像的变形需求自适应设定优化迭代次数，导致配准过早中断或过度迭代影响精度。

Method: 提出了特征增强残差模块（FERM）放置在金字塔网络每一解码层，有效提取解剖语义信息并抑制无关特征，同时采用双阶段阈值控制迭代（TCI）策略动态判断是否继续迭代，融合为完整的模型TCIP。

Result: 在三个公开脑MRI数据集和一个腹部CT数据集上，所提TCIP模型在配准精度上优于现有最优方法，并且保持了类似的推理速度和模型参数规模。将FERM与TCI集成至其他现有网络同样提升了效果，并通过消融实验验证了两者的有效性。

Conclusion: 所提出的FERM和TCI方法能够有效提升医学图像配准的精度与效率，具有良好的通用性和紧凑的参数开销，在多个公开数据集上验证了其实用价值。

Abstract: Although pyramid networks have demonstrated superior performance in
deformable medical image registration, their decoder architectures are
inherently prone to propagating and accumulating anatomical structure
misalignments. Moreover, most existing models do not adaptively determine the
number of iterations for optimization under varying deformation requirements
across images, resulting in either premature termination or excessive
iterations that degrades registration accuracy. To effectively mitigate the
accumulation of anatomical misalignments, we propose the Feature-Enhanced
Residual Module (FERM) as the core component of each decoding layer in the
pyramid network. FERM comprises three sequential blocks that extract anatomical
semantic features, learn to suppress irrelevant features, and estimate the
final deformation field, respectively. To adaptively determine the number of
iterations for varying images, we propose the dual-stage Threshold-Controlled
Iterative (TCI) strategy. In the first stage, TCI assesses registration
stability and with asserted stability, it continues with the second stage to
evaluate convergence. We coin the model that integrates FERM and TCI as
Threshold-Controlled Iterative Pyramid (TCIP). Extensive experiments on three
public brain MRI datasets and one abdomen CT dataset demonstrate that TCIP
outperforms the state-of-the-art (SOTA) registration networks in terms of
accuracy, while maintaining comparable inference speed and a compact model
parameter size. Finally, we assess the generalizability of FERM and TCI by
integrating them with existing registration networks and further conduct
ablation studies to validate the effectiveness of these two proposed methods.

</details>


### [19] [Controllable Video Synthesis via Variational Inference](https://arxiv.org/abs/2510.07670)
*Haoyi Duan,Yunzhi Zhang,Yilun Du,Jiajun Wu*

Main category: cs.CV

TL;DR: 本论文提出一种新的视频合成方法，实现了对视频生成中不同元素的精细化与粗粒度控制，同时保持了对未指定元素的多样性和3D一致性。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型仅支持固定格式输入，难以满足实际工作流程中对不同粒度用户控制的需求（如精准的物体轨迹与粗略的文本提示结合）。为提升视频合成的灵活性和可控性，需要新的生成方法。

Method: 提出将该任务转化为对复合分布的变分推断，并综合多种视频生成骨干模型以共同满足多重约束。在优化上，将问题拆分为分步的KL散度最小化，通过一系列退火的分布序列优化。还提出了一种上下文条件化分解技术，有效减少解空间中的模式数量，避免陷入局部最优。

Result: 实验显示，所提方法在视频生成的可控性、多样性以及3D一致性方面，相比以往方法有明显提升。

Conclusion: 该方法在兼顾指定元素高可控性和未指定元素高多样性的同时，能够更好地适应实际复杂的视频生成需求，在实验中表现出优越性。

Abstract: Many video workflows benefit from a mixture of user controls with varying
granularity, from exact 4D object trajectories and camera paths to coarse text
prompts, while existing video generative models are typically trained for fixed
input formats. We develop a video synthesis method that addresses this need and
generates samples with high controllability for specified elements while
maintaining diversity for under-specified ones. We cast the task as variational
inference to approximate a composed distribution, leveraging multiple video
generation backbones to account for all task constraints collectively. To
address the optimization challenge, we break down the problem into step-wise KL
divergence minimization over an annealed sequence of distributions, and further
propose a context-conditioned factorization technique that reduces modes in the
solution space to circumvent local optima. Experiments suggest that our method
produces samples with improved controllability, diversity, and 3D consistency
compared to prior works.

</details>


### [20] [Hybrid CNN-BYOL Approach for Fault Detection in Induction Motors Using Thermal Images](https://arxiv.org/abs/2510.07692)
*Tangin Amir Smrity,MD Zahin Muntaqim Hasan Muhammad Kafi,Abu Saleh Musa Miah,Najmul Hassan,Yuichi Okuyama,Nobuyoshi Asai,Taro Suzuki,Jungpil Shin*

Main category: cs.CV

TL;DR: 本文提出了一种结合BYOL和CNN的新型方法，实现了对感应电机热成像图像的高精度故障检测，其中创新设计的BYOL-IMNet模型在测试中取得了99.89%的准确率和极快的处理速度。


<details>
  <summary>Details</summary>
Motivation: 感应电机在工业和日常生活中应用广泛，但极易发生故障，导致能耗增加和设备停机。因此，早期故障检测对于电机保护和延长寿命极其重要。

Method: 采用无监督自监督学习BYOL（Bootstrap Your Own Latent）方法与多种深度学习CNN架构（包括ResNet-50、DenseNet、EfficientNetB0、VGG16、MobileNetV2）融合。数据集为包含正常、过载及故障等多种工况的电机热成像图像。此外，作者提出了新型轻量化高性能CNN模型BYOL-IMNet，包含四个为电机热成像故障分类定制设计的模块。

Result: BYOL-IMNet模型在测试集上取得了99.89%的准确率，单张图片推理时间仅5.7毫秒，整体性能优于现有主流模型。

Conclusion: 结合BYOL自监督学习和定制化CNN的新方法在感应电机故障热成像检测上表现出极高的准确率和速度，适合工业环境的在线监测应用，并推动了相关领域发展。

Abstract: Induction motors (IMs) are indispensable in industrial and daily life, but
they are susceptible to various faults that can lead to overheating, wasted
energy consumption, and service failure. Early detection of faults is essential
to protect the motor and prolong its lifespan. This paper presents a hybrid
method that integrates BYOL with CNNs for classifying thermal images of
induction motors for fault detection. The thermal dataset used in this work
includes different operating states of the motor, such as normal operation,
overload, and faults. We employed multiple deep learning (DL) models for the
BYOL technique, ranging from popular architectures such as ResNet-50,
DenseNet-121, DenseNet-169, EfficientNetB0, VGG16, and MobileNetV2.
Additionally, we introduced a new high-performance yet lightweight CNN model
named BYOL-IMNet, which comprises four custom-designed blocks tailored for
fault classification in thermal images. Our experimental results demonstrate
that the proposed BYOL-IMNet achieves 99.89\% test accuracy and an inference
time of 5.7 ms per image, outperforming state-of-the-art models. This study
highlights the promising performance of the CNN-BYOL hybrid method in enhancing
accuracy for detecting faults in induction motors, offering a robust
methodology for online monitoring in industrial settings.

</details>


### [21] [Mutual Learning for Hashing: Unlocking Strong Hash Functions from Weak Supervision](https://arxiv.org/abs/2510.07703)
*Xiaoxu Ma,Runhao Li,Zhenyu Weng*

Main category: cs.CV

TL;DR: 提出了一种结合中心方法和成对方法优势的新型深度哈希学习框架（MLH），通过相互学习和专家混合机制提升图像检索性能。


<details>
  <summary>Details</summary>
Motivation: 中心点哈希方法在捕捉全局数据结构方面表现优越，但容易忽视本地相似性信息；而成对方法能保留本地相似性但整体性能不如中心方法。因此需要结合两者优势，以提升大规模图像检索的哈希学习效果。

Method: 提出了Mutual Learning for Hashing (MLH) 框架，包含更强的中心分支和较弱的成对分支。两者通过相互学习，将成对分支学到的本地相似性知识迁移到中心分支。同时引入mixture-of-hash-experts模块，实现分支间的高效交互，加强信息融合。

Result: 在多个基准数据集上进行广泛实验证明，所提MLH方法在图像哈希检索任务上优于当前主流方法。

Conclusion: MLH能够有效地结合和利用全局及局部相似性信息，提升哈希学习的检索性能，为后续相关研究提供了新思路。

Abstract: Deep hashing has been widely adopted for large-scale image retrieval, with
numerous strategies proposed to optimize hash function learning. Pairwise-based
methods are effective in learning hash functions that preserve local similarity
relationships, whereas center-based methods typically achieve superior
performance by more effectively capturing global data distributions. However,
the strength of center-based methods in modeling global structures often comes
at the expense of underutilizing important local similarity information. To
address this limitation, we propose Mutual Learning for Hashing (MLH), a novel
weak-to-strong framework that enhances a center-based hashing branch by
transferring knowledge from a weaker pairwise-based branch. MLH consists of two
branches: a strong center-based branch and a weaker pairwise-based branch.
Through an iterative mutual learning process, the center-based branch leverages
local similarity cues learned by the pairwise-based branch. Furthermore,
inspired by the mixture-of-experts paradigm, we introduce a novel
mixture-of-hash-experts module that enables effective cross-branch interaction,
further enhancing the performance of both branches. Extensive experiments
demonstrate that MLH consistently outperforms state-of-the-art hashing methods
across multiple benchmark datasets.

</details>


### [22] [RePainter: Empowering E-commerce Object Removal via Spatial-matting Reinforcement Learning](https://arxiv.org/abs/2510.07721)
*Zipeng Guo,Lichen Ma,Xiaolong Fu,Gaojing Zhou,Lan Yang,Yuchen Zhou,Linkai Liu,Yu He,Ximan Liu,Shiping Dong,Jingling Fu,Zhen Chen,Yu Shi,Junshi Huang,Jason Li,Chao Gou*

Main category: cs.CV

TL;DR: 论文提出了Repainter，一个结合空间抠图轨迹优化和分组相对策略优化（GRPO）的强化学习框架，显著提升了去除电商图片水印、广告文字等杂质的效果。


<details>
  <summary>Details</summary>
Motivation: 在电商平台上，水印和促销文字等干扰元素影响了商品图片的清晰度与吸引力，但现有的扩散模型修补方法在商用场景下，物体移除不可靠且难以适应电商领域。

Method: 提出Repainter方法，通过强化学习结合空间抠图轨迹优化和GRPO注意力机制，融入全局、局部和语义奖励约束，减少视觉伪影和奖励作弊，提升去除效果。同时构建了大规模高质量电商修补数据集EcomPaint-100K和标准评测集EcomPaint-Bench。

Result: 在大量实验下，Repainter在复杂场景和成分繁多的图片修补任务中大幅优于现有最先进的方法。

Conclusion: Repainter方案能更高效、更精准地提升电商商品图像的视觉质量，并已为公平评测提供公开基准和数据集，推动商用图像去杂质技术发展。

Abstract: In web data, product images are central to boosting user engagement and
advertising efficacy on e-commerce platforms, yet the intrusive elements such
as watermarks and promotional text remain major obstacles to delivering clear
and appealing product visuals. Although diffusion-based inpainting methods have
advanced, they still face challenges in commercial settings due to unreliable
object removal and limited domain-specific adaptation. To tackle these
challenges, we propose Repainter, a reinforcement learning framework that
integrates spatial-matting trajectory refinement with Group Relative Policy
Optimization (GRPO). Our approach modulates attention mechanisms to emphasize
background context, generating higher-reward samples and reducing unwanted
object insertion. We also introduce a composite reward mechanism that balances
global, local, and semantic constraints, effectively reducing visual artifacts
and reward hacking. Additionally, we contribute EcomPaint-100K, a high-quality,
large-scale e-commerce inpainting dataset, and a standardized benchmark
EcomPaint-Bench for fair evaluation. Extensive experiments demonstrate that
Repainter significantly outperforms state-of-the-art methods, especially in
challenging scenes with intricate compositions. We will release our code and
weights upon acceptance.

</details>


### [23] [SyncHuman: Synchronizing 2D and 3D Generative Models for Single-view Human Reconstruction](https://arxiv.org/abs/2510.07723)
*Wenyue Chen,Peng Li,Wangguandong Zheng,Chengfeng Zhao,Mengfei Li,Yaolong Zhu,Zhiyang Dou,Ronggang Wang,Yuan Liu*

Main category: cs.CV

TL;DR: 本文提出了一种新型3D全身人像重建系统SyncHuman，结合2D多视角生成和3D生成模型，实现了单张图片下的高质量三维重建，尤其在复杂人体姿态下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于单幅图像的三维人体重建因遮挡和视角限制存在姿态推理不准、细节重建难等问题，限制了其在影视等领域中的应用。

Method: 创新性地结合2D多视角生成模型（捕捉细节能力强但结构一致性较差）和3D本地生成模型（结构一致但粗糙），提出像素对齐的2D-3D同步注意力机制，联合训练，并通过2D特征注入机制提升三维的细节表现。

Result: 实验显示该方法对复杂或遮挡姿态下的图像也能完成高保真、高几何精度的三维人体重建，显著优于现有主流基线。

Conclusion: SyncHuman提出了一种有效且新颖的生成框架，为3D人体重建领域带来了性能突破，也为未来生成建模提供了新方向。

Abstract: Photorealistic 3D full-body human reconstruction from a single image is a
critical yet challenging task for applications in films and video games due to
inherent ambiguities and severe self-occlusions. While recent approaches
leverage SMPL estimation and SMPL-conditioned image generative models to
hallucinate novel views, they suffer from inaccurate 3D priors estimated from
SMPL meshes and have difficulty in handling difficult human poses and
reconstructing fine details. In this paper, we propose SyncHuman, a novel
framework that combines 2D multiview generative model and 3D native generative
model for the first time, enabling high-quality clothed human mesh
reconstruction from single-view images even under challenging human poses.
Multiview generative model excels at capturing fine 2D details but struggles
with structural consistency, whereas 3D native generative model generates
coarse yet structurally consistent 3D shapes. By integrating the complementary
strengths of these two approaches, we develop a more effective generation
framework. Specifically, we first jointly fine-tune the multiview generative
model and the 3D native generative model with proposed pixel-aligned 2D-3D
synchronization attention to produce geometrically aligned 3D shapes and 2D
multiview images. To further improve details, we introduce a feature injection
mechanism that lifts fine details from 2D multiview images onto the aligned 3D
shapes, enabling accurate and high-fidelity reconstruction. Extensive
experiments demonstrate that SyncHuman achieves robust and photo-realistic 3D
human reconstruction, even for images with challenging poses. Our method
outperforms baseline methods in geometric accuracy and visual fidelity,
demonstrating a promising direction for future 3D generation models.

</details>


### [24] [ComGS: Efficient 3D Object-Scene Composition via Surface Octahedral Probes](https://arxiv.org/abs/2510.07729)
*Jian Gao,Mengqi Yuan,Yifei Zeng,Chang Zeng,Zhihao Li,Zhenyu Chen,Weichao Qiu,Xiao-Xiao Long,Hao Zhu,Xun Cao,Yao Yao*

Main category: cs.CV

TL;DR: 本文提出了一种用于3D物体与场景真实感合成的新方法ComGS，通过引入Surface Octahedral Probes(SOPs)实现高效重建与实时渲染。对场景照明估计提出创新手段，有效提升合成真实性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 高斯点（GS）虽可实现沉浸式渲染，但在3D物体与场景的真实合成时存在光照与阴影信息不一致的问题，导致结果不自然。现有基于高斯逆渲染的方法普遍依赖于低效的光线追踪，且复杂场景下光照估计表现不佳，迫切需要一种高效且能处理复杂光照与阴影的合成方法。

Method: 提出Surface Octahedral Probes（SOPs）存储场景的光照和遮挡信息，通过插值实现高效三维查询，避免了高开销的光线追踪，在物体重建中至少提升2倍效率，并支持实时阴影计算。照明估计方面，通过捕捉物体放置位置的360度重建辐射场，并微调扩散模型完成光照推断，从而优化了合成质量。最终整合为ComGS框架。

Result: 该方法在重建效率、实时渲染（约28FPS）、合成阴影质量等方面比以往方法有明显提升，且编辑操作速度快，仅需36秒。

Conclusion: ComGS能够实现高质量、实时、融洽的3D物体与场景合成渲染，为实际应用带来更真实感与高效率，未来有望扩展到更复杂场景。

Abstract: Gaussian Splatting (GS) enables immersive rendering, but realistic 3D
object-scene composition remains challenging. Baked appearance and shadow
information in GS radiance fields cause inconsistencies when combining objects
and scenes. Addressing this requires relightable object reconstruction and
scene lighting estimation. For relightable object reconstruction, existing
Gaussian-based inverse rendering methods often rely on ray tracing, leading to
low efficiency. We introduce Surface Octahedral Probes (SOPs), which store
lighting and occlusion information and allow efficient 3D querying via
interpolation, avoiding expensive ray tracing. SOPs provide at least a 2x
speedup in reconstruction and enable real-time shadow computation in Gaussian
scenes. For lighting estimation, existing Gaussian-based inverse rendering
methods struggle to model intricate light transport and often fail in complex
scenes, while learning-based methods predict lighting from a single image and
are viewpoint-sensitive. We observe that 3D object-scene composition primarily
concerns the object's appearance and nearby shadows. Thus, we simplify the
challenging task of full scene lighting estimation by focusing on the
environment lighting at the object's placement. Specifically, we capture a 360
degrees reconstructed radiance field of the scene at the location and fine-tune
a diffusion model to complete the lighting. Building on these advances, we
propose ComGS, a novel 3D object-scene composition framework. Our method
achieves high-quality, real-time rendering at around 28 FPS, produces visually
harmonious results with vivid shadows, and requires only 36 seconds for
editing. Code and dataset are available at
https://nju-3dv.github.io/projects/ComGS/.

</details>


### [25] [UltraLED: Learning to See Everything in Ultra-High Dynamic Range Scenes](https://arxiv.org/abs/2510.07741)
*Yuang Meng,Xin Jin,Lina Lei,Chun-Le Guo,Chongyi Li*

Main category: cs.CV

TL;DR: 该论文针对超高动态范围（UHDR）夜景，提出了UltraLED框架，利用单张短曝光RAW图像，实现细节复原和噪声抑制，有效超越现有单帧方法。


<details>
  <summary>Details</summary>
Motivation: 夜景中明暗差异极大，导致普通曝光难以兼顾高光和阴影细节，现有RGB多曝光法易产生错位和重影。因此，寻找单帧、高效且无运动伪影的UHDR复原方法具有重要意义。

Method: 提出UltraLED，两阶段框架：第一阶段利用比值图实现动态范围平衡（曝光校正）；第二阶段针对暗区特性设计亮度感知RAW去噪器，实现细节增强。支持方法的是设计的9挡包围曝光合成流程，并建立了配套数据集，以最短曝光作为输入。

Result: 实验证明，UltraLED在细节恢复和噪声抑制方面明显优于现有单帧方法，特别适用于动态场景。

Conclusion: 利用单张短曝光RAW图像，通过特定算法框架也能实现高质量UHDR复原，极大提升了动态夜景成像效果，并为相关研究提供了公开数据和方法。

Abstract: Ultra-high dynamic range (UHDR) scenes exhibit significant exposure
disparities between bright and dark regions. Such conditions are commonly
encountered in nighttime scenes with light sources. Even with standard exposure
settings, a bimodal intensity distribution with boundary peaks often emerges,
making it difficult to preserve both highlight and shadow details
simultaneously. RGB-based bracketing methods can capture details at both ends
using short-long exposure pairs, but are susceptible to misalignment and
ghosting artifacts. We found that a short-exposure image already retains
sufficient highlight detail. The main challenge of UHDR reconstruction lies in
denoising and recovering information in dark regions. In comparison to the RGB
images, RAW images, thanks to their higher bit depth and more predictable noise
characteristics, offer greater potential for addressing this challenge. This
raises a key question: can we learn to see everything in UHDR scenes using only
a single short-exposure RAW image? In this study, we rely solely on a single
short-exposure frame, which inherently avoids ghosting and motion blur, making
it particularly robust in dynamic scenes. To achieve that, we introduce
UltraLED, a two-stage framework that performs exposure correction via a ratio
map to balance dynamic range, followed by a brightness-aware RAW denoiser to
enhance detail recovery in dark regions. To support this setting, we design a
9-stop bracketing pipeline to synthesize realistic UHDR images and contribute a
corresponding dataset based on diverse scenes, using only the shortest exposure
as input for reconstruction. Extensive experiments show that UltraLED
significantly outperforms existing single-frame approaches. Our code and
dataset are made publicly available at
https://srameo.github.io/projects/ultraled.

</details>


### [26] [DEGS: Deformable Event-based 3D Gaussian Splatting from RGB and Event Stream](https://arxiv.org/abs/2510.07752)
*Junhao He,Jiaxu Wang,Jia Li,Mingyuan Sun,Qiang Zhang,Jiahang Cao,Ziyi Zhang,Yi Gu,Jingkai Sun,Renjing Xu*

Main category: cs.CV

TL;DR: 本文提出了一种结合低帧率RGB视频和高帧率事件流，实现动态3D高斯斑点（3DGS）场景重建的新方法。这主要通过利用事件相机的运动信息引导优化过程，显著提升在大幅运动情况下的重建质量。


<details>
  <summary>Details</summary>
Motivation: 动态场景下，低帧率RGB视频因帧间运动大，导致重建不确定性增加，而事件相机捕捉运动信息快，但缺乏颜色。因此，如何融合两者优势，实现高质量的3DGS重建，是当前的技术挑战。

Method: 作者提出了一个联合优化框架：首先用无监督的LoCM方法对事件流估计器自适应微调，提取运动先验；然后引入几何感知的数据关联方案，将事件流与高斯斑点运动对应，并提出运动分解与伪标签策略辅助优化。最后，通过RGB图像和事件流联合优化动态3DGS。

Result: 实验表明，该方法在合成和真实场景上都优于现有基于图像及事件相机的方法，特别是在动态场景、大幅运动下的3DGS重建任务表现突出。

Conclusion: 融合RGB和事件流的联合框架能更有效地重建动态3DGS场景，证明了事件数据在复杂运动场景下的重要作用。

Abstract: Reconstructing Dynamic 3D Gaussian Splatting (3DGS) from low-framerate RGB
videos is challenging. This is because large inter-frame motions will increase
the uncertainty of the solution space. For example, one pixel in the first
frame might have more choices to reach the corresponding pixel in the second
frame. Event cameras can asynchronously capture rapid visual changes and are
robust to motion blur, but they do not provide color information. Intuitively,
the event stream can provide deterministic constraints for the inter-frame
large motion by the event trajectories. Hence, combining
low-temporal-resolution images with high-framerate event streams can address
this challenge. However, it is challenging to jointly optimize Dynamic 3DGS
using both RGB and event modalities due to the significant discrepancy between
these two data modalities. This paper introduces a novel framework that jointly
optimizes dynamic 3DGS from the two modalities. The key idea is to adopt event
motion priors to guide the optimization of the deformation fields. First, we
extract the motion priors encoded in event streams by using the proposed LoCM
unsupervised fine-tuning framework to adapt an event flow estimator to a
certain unseen scene. Then, we present the geometry-aware data association
method to build the event-Gaussian motion correspondence, which is the primary
foundation of the pipeline, accompanied by two useful strategies, namely motion
decomposition and inter-frame pseudo-label. Extensive experiments show that our
method outperforms existing image and event-based approaches across synthetic
and real scenes and prove that our method can effectively optimize dynamic 3DGS
with the help of event data.

</details>


### [27] [Demystifying Deep Learning-based Brain Tumor Segmentation with 3D UNets and Explainable AI (XAI): A Comparative Analysis](https://arxiv.org/abs/2510.07785)
*Ming Jie Ong,Sze Yinn Ung,Sim Kuan Goh,Jimmy Y. Zhong*

Main category: cs.CV

TL;DR: 本研究提出结合可解释人工智能（XAI）技术（包括Grad-CAM和注意力可视化）来提升深度学习模型对脑肿瘤MRI分割的准确率，并通过与常规UNet模型对比，证明Residual UNet（ResUNet）在主要评估指标上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 医学影像自动分割对医生诊断和治疗决策至关重要，但深度模型的黑盒特性会降低医生信任。本研究旨在通过XAI提升模型可解释性和医生信任，同时优化脑肿瘤分割的效果。

Method: 研究评估了三种UNet变体（UNet、ResUNet、AttUNet）在BraTS2020公开数据集上的分割表现，并采用Grad-CAM和注意力可视化分析模型关注的区域，所有实验采用最新硬件和Adam优化器。

Result: ResUNet在最终测试阶段的Dice系数、Jaccard指数、准确率、召回率和F1分数上均优于其他模型。Grad-CAM和注意力机制可视化清晰展现了模型在肿瘤分割时的聚焦区域。

Conclusion: ResUNet结合可解释性方法在脑肿瘤分割效果最佳，建议临床优先应用。作者已开源代码和模型权重以促进后续研究和应用。

Abstract: The current study investigated the use of Explainable Artificial Intelligence
(XAI) to improve the accuracy of brain tumor segmentation in MRI images, with
the goal of assisting physicians in clinical decision-making. The study focused
on applying UNet models for brain tumor segmentation and using the XAI
techniques of Gradient-weighted Class Activation Mapping (Grad-CAM) and
attention-based visualization to enhance the understanding of these models.
Three deep learning models - UNet, Residual UNet (ResUNet), and Attention UNet
(AttUNet) - were evaluated to identify the best-performing model. XAI was
employed with the aims of clarifying model decisions and increasing physicians'
trust in these models. We compared the performance of two UNet variants
(ResUNet and AttUNet) with the conventional UNet in segmenting brain tumors
from the BraTS2020 public dataset and analyzed model predictions with Grad-CAM
and attention-based visualization. Using the latest computer hardware, we
trained and validated each model using the Adam optimizer and assessed their
performance with respect to: (i) training, validation, and inference times,
(ii) segmentation similarity coefficients and loss functions, and (iii)
classification performance. Notably, during the final testing phase, ResUNet
outperformed the other models with respect to Dice and Jaccard similarity
scores, as well as accuracy, recall, and F1 scores. Grad-CAM provided
visuospatial insights into the tumor subregions each UNet model focused on
while attention-based visualization provided valuable insights into the working
mechanisms of AttUNet's attention modules. These results demonstrated ResUNet
as the best-performing model and we conclude by recommending its use for
automated brain tumor segmentation in future clinical assessments. Our source
code and checkpoint are available at
https://github.com/ethanong98/MultiModel-XAI-Brats2020

</details>


### [28] [GTR-Bench: Evaluating Geo-Temporal Reasoning in Vision-Language Models](https://arxiv.org/abs/2510.07791)
*Qinghongbing Xie,Zhaoyuan Xia,Feng Zhu,Lijun Gong,Ziyue Li,Rui Zhao,Long Zeng*

Main category: cs.CV

TL;DR: 本文提出了Geo-Temporal Reasoning benchmark (GTR-Bench)，一个针对地理空间-时间推理的新基准，旨在更全面考评视觉-语言模型(VLMs)在大规模摄像头网络下，结合地图与视频的推理能力。实验表明现有VLMs远逊于人类水平，并揭示三个主 要不足。


<details>
  <summary>Details</summary>
Motivation: 现有空间-时间推理基准大多局限于视角单一（第一视角视频或地图），无法评估VLMs在要求融合地图与多视频视角场景下的综合推理能力，而这种能力对自动驾驶、智慧交通管理等场景十分重要。

Method: 作者设计了GTR-Bench，用于考查VLMs在大规模摄像头网络下，结合不重叠视野多视频和地图数据的复杂推理能力，包括视角切换、空间-时间区域补全等多类任务。对10余种主流VLMs展开系统性对比实验，并对结果展开细致分析。

Result: 实验结果显示所有参测模型在GTR-Bench上表现不佳，最优模型Gemini-2.5-Pro的得分（34.9%）远低于人类平均水平（78.61%）。分析总结三个关键短板：空间-时间信息利用不均衡，时间预测能力薄弱，地图与多视角视频的融合理解不足。

Conclusion: GTR-Bench有效揭示了现有VLMs在复杂地理空间-时间推理上的不足，可作为未来模型改进与相关领域应用的重要参考和推动力量。

Abstract: Recently spatial-temporal intelligence of Visual-Language Models (VLMs) has
attracted much attention due to its importance for Autonomous Driving, Embodied
AI and General Artificial Intelligence. Existing spatial-temporal benchmarks
mainly focus on egocentric perspective reasoning with images/video context, or
geographic perspective reasoning with graphics context (eg. a map), thus fail
to assess VLMs' geographic spatial-temporal intelligence with both images/video
and graphics context, which is important for areas like traffic management and
emergency response. To address the gaps, we introduce Geo-Temporal Reasoning
benchmark (GTR-Bench), a novel challenge for geographic temporal reasoning of
moving targets in a large-scale camera network. GTR-Bench is more challenging
as it requires multiple perspective switches between maps and videos, joint
reasoning across multiple videos with non-overlapping fields of view, and
inference over spatial-temporal regions that are unobserved by any video
context. Evaluations of more than 10 popular VLMs on GTR-Bench demonstrate that
even the best proprietary model, Gemini-2.5-Pro (34.9%), significantly lags
behind human performance (78.61%) on geo-temporal reasoning. Moreover, our
comprehensive analysis on GTR-Bench reveals three primary deficiencies of
current models for geo-temporal reasoning. (1) VLMs' reasoning is impaired by
an imbalanced utilization of spatial-temporal context. (2) VLMs are weak in
temporal forecasting, which leads to worse performance on temporal-emphasized
tasks than on spatial-emphasized tasks. (3) VLMs lack the proficiency to
comprehend or align the map data with multi-view video inputs. We believe
GTR-Bench offers valuable insights and opens up new opportunities for research
and applications in spatial-temporal intelligence. Benchmark and code will be
released at https://github.com/X-Luffy/GTR-Bench.

</details>


### [29] [FMANet: A Novel Dual-Phase Optical Flow Approach with Fusion Motion Attention Network for Robust Micro-expression Recognition](https://arxiv.org/abs/2510.07810)
*Luu Tu Nguyen,Vu Tram Anh Khuong,Thi Bich Phuong Man,Thi Duyen Ngo,Thanh Ha Le*

Main category: cs.CV

TL;DR: 本文提出了一种新的面部微表情识别方法，通过结合面部运动不同阶段的光流信息，并引入端到端神经网络结构，有效提升了识别准确率。


<details>
  <summary>Details</summary>
Motivation: 面部微表情因其细微且短暂，难以捕捉，但对心理学、安全和行为分析有重要意义。当前主流方法只利用微表情爆发前后的光流，忽略了爆发后到消退阶段的重要运动信息，导致关键信息丢失。

Method: 作者提出了一种综合运动表征MM-COF，将微表情从爆发到消退两个阶段的光流信息融合到一个统一描述符中；随后基于此原理设计了FMANet神经网络，通过端到端结构和可学习模块，自适应地融合运动线索并关注重要面部区域进行分类。

Result: 在MMEW、SMIC、CASME-II和SAMM等主流数据集上的实验显示，本文提出的MM-COF表示和FMANet方法在识别准确率上超过了当前主流方法。

Conclusion: 研究证明，将微表情两个阶段的运动信息融合，并利用可学习的神经网络框架，有助于提升面部微表情识别技术的性能，为该领域发展提供了新思路。

Abstract: Facial micro-expressions, characterized by their subtle and brief nature, are
valuable indicators of genuine emotions. Despite their significance in
psychology, security, and behavioral analysis, micro-expression recognition
remains challenging due to the difficulty of capturing subtle facial movements.
Optical flow has been widely employed as an input modality for this task due to
its effectiveness. However, most existing methods compute optical flow only
between the onset and apex frames, thereby overlooking essential motion
information in the apex-to-offset phase. To address this limitation, we first
introduce a comprehensive motion representation, termed Magnitude-Modulated
Combined Optical Flow (MM-COF), which integrates motion dynamics from both
micro-expression phases into a unified descriptor suitable for direct use in
recognition networks. Building upon this principle, we then propose FMANet, a
novel end-to-end neural network architecture that internalizes the dual-phase
analysis and magnitude modulation into learnable modules. This allows the
network to adaptively fuse motion cues and focus on salient facial regions for
classification. Experimental evaluations on the MMEW, SMIC, CASME-II, and SAMM
datasets, widely recognized as standard benchmarks, demonstrate that our
proposed MM-COF representation and FMANet outperforms existing methods,
underscoring the potential of a learnable, dual-phase framework in advancing
micro-expression recognition.

</details>


### [30] [An End-to-End Room Geometry Constrained Depth Estimation Framework for Indoor Panorama Images](https://arxiv.org/abs/2510.07817)
*Kanglin Ning,Ruzhao Chen,Penghong Wang,Xingtao Wang,Ruiqin Xiong,Xiaopeng Fan*

Main category: cs.CV

TL;DR: 论文提出了一种基于房间几何约束的全景单目深度估计算法，通过优化房屋结构和背景信息，提高了在室内360°全景图像中的深度估计精度。


<details>
  <summary>Details</summary>
Motivation: 现有的全景深度估计方法注重像素级别精度，易出现房间拐角过度平滑和对噪声敏感的问题，缺乏对房间整体结构的利用。为此，作者希望利用房屋几何结构约束，改进深度估计效果。

Method: 1) 提出一种由共享特征编码器和任务专属解码器组成的网络结构，支持布局预测、深度估计和背景分割三任务；2) 利用房间布局推理和深度初步估计计算背景深度图；3) 利用背景分割引导深度图融合策略，权重由分割结果决定。

Result: 在Stanford2D3D、Matterport3D和Structured3D等公开数据集上，方法表现优于现有开源方法，提升了深度估计的准确性和鲁棒性。

Conclusion: 融合房间几何结构和背景分割信息，能够显著提升360°全景室内场景的单目深度估计表现，有实际应用潜力。

Abstract: Predicting spherical pixel depth from monocular $360^{\circ}$ indoor
panoramas is critical for many vision applications. However, existing methods
focus on pixel-level accuracy, causing oversmoothed room corners and noise
sensitivity. In this paper, we propose a depth estimation framework based on
room geometry constraints, which extracts room geometry information through
layout prediction and integrates those information into the depth estimation
process through background segmentation mechanism. At the model level, our
framework comprises a shared feature encoder followed by task-specific decoders
for layout estimation, depth estimation, and background segmentation. The
shared encoder extracts multi-scale features, which are subsequently processed
by individual decoders to generate initial predictions: a depth map, a room
layout map, and a background segmentation map. Furthermore, our framework
incorporates two strategies: a room geometry-based background depth resolving
strategy and a background-segmentation-guided fusion mechanism. The proposed
room-geometry-based background depth resolving strategy leverages the room
layout and the depth decoder's output to generate the corresponding background
depth map. Then, a background-segmentation-guided fusion strategy derives
fusion weights for the background and coarse depth maps from the segmentation
decoder's predictions. Extensive experimental results on the Stanford2D3D,
Matterport3D and Structured3D datasets show that our proposed methods can
achieve significantly superior performance than current open-source methods.
Our code is available at https://github.com/emiyaning/RGCNet.

</details>


### [31] [Enhancing Visual Prompting through Expanded Transformation Space and Overfitting Mitigation](https://arxiv.org/abs/2510.07823)
*Shohei Enomoto*

Main category: cs.CV

TL;DR: 本文提出一种新的视觉提示方法ACAVP，结合仿射变换、颜色变换和传统加性变换，以提升预训练视觉模型下游任务适应性，并通过数据增强有效缓解过拟合，实现了当前最优的视觉提示性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉提示（VP）方法虽然对下游任务适应具有高效、参数需求低和对黑盒模型兼容等优点，但准确率普遍低于其他适应方法。分析发现，VP受限于表达能力弱和参数增加时的过拟合问题，亟需改进其表达性和鲁棒性。

Method: 提出了ACAVP方法，融合了仿射变换用于构建任务特定提示区域且保持原始图像信息、颜色变换以强化相关视觉特征，并结合传统加性变换提升整体表达能力。同时，引入TrivialAugment数据增强方法，有效遏制过拟合并提升所有VP方法的性能。

Result: 在12个图像分类数据集、两种不同模型架构上，ACAVP在所有视觉提示方法中取得最优准确率，明显优于线性探针，并且对分布偏移具有更好鲁棒性。通过数据增强，部分数据集精度提升达12个百分点。

Conclusion: ACAVP显著提升了视觉提示方法的表达能力与泛化性能，实现了当前SOTA并兼具高效率和鲁棒性。数据增强对视觉提示方法具有普适性提升作用。

Abstract: Visual prompting (VP) has emerged as a promising parameter-efficient
fine-tuning approach for adapting pre-trained vision models to downstream tasks
without modifying model parameters. Despite offering advantages like negligible
computational overhead and compatibility with black-box models, conventional VP
methods typically achieve lower accuracy than other adaptation approaches. Our
analysis reveals two critical limitations: the restricted expressivity of
simple additive transformation and a tendency toward overfitting when the
parameter count increases. To address these challenges, we propose ACAVP
(Affine, Color, and Additive Visual Prompting), which enhances VP's expressive
power by introducing complementary transformation operations: affine
transformation for creating task-specific prompt regions while preserving
original image information, and color transformation for emphasizing
task-relevant visual features. Additionally, we identify that overfitting is a
critical issue in VP training and introduce TrivialAugment as an effective data
augmentation, which not only benefits our approach but also significantly
improves existing VP methods, with performance gains of up to 12 percentage
points on certain datasets. This demonstrates that appropriate data
augmentation is universally beneficial for VP training. Extensive experiments
across twelve diverse image classification datasets with two different model
architectures demonstrate that ACAVP achieves state-of-the-art accuracy among
VP methods, surpasses linear probing in average accuracy, and exhibits superior
robustness to distribution shifts, all while maintaining minimal computational
overhead during inference.

</details>


### [32] [MMHOI: Modeling Complex 3D Multi-Human Multi-Object Interactions](https://arxiv.org/abs/2510.07828)
*Kaen Kogashi,Anoop Cherian,Meng-Yu Jennifer Kuo*

Main category: cs.CV

TL;DR: 本文提出了MMHOI，一个大规模多人与多物体3D交互数据集，并基于此设计了MMHOI-Net网络，实现了多主体多物体交互及动作识别的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前的3D人-物体交互（HOI）基准覆盖的交互类型有限，无法反映现实世界中复杂、多人的人-物体交互场景。该研究试图填补这一空白，推动更全面的HOI研究。

Method: 1）提出MMHOI数据集，涵盖12种日常场景，具备完整的人与物体的3D形状、姿态标注及丰富的动作和交互部位标签；2）提出MMHOI-Net，一种基于Transformer的端到端神经网络，利用结构化双patch方法建模交互，同时联合动作识别增强预测能力。

Result: 在MMHOI及CORE4D数据集上，所提出的方法在多HOI建模任务中达到最先进的准确率和高质量的重建效果，验证了新方法的有效性。

Conclusion: MMHOI数据集和MMHOI-Net显著提升了3D多主体人-物体交互建模与识别的能力，为更真实、更复杂的3D HOI研究提供了强有力的支撑和评测平台。

Abstract: Real-world scenes often feature multiple humans interacting with multiple
objects in ways that are causal, goal-oriented, or cooperative. Yet existing 3D
human-object interaction (HOI) benchmarks consider only a fraction of these
complex interactions. To close this gap, we present MMHOI -- a large-scale,
Multi-human Multi-object Interaction dataset consisting of images from 12
everyday scenarios. MMHOI offers complete 3D shape and pose annotations for
every person and object, along with labels for 78 action categories and 14
interaction-specific body parts, providing a comprehensive testbed for
next-generation HOI research. Building on MMHOI, we present MMHOI-Net, an
end-to-end transformer-based neural network for jointly estimating human-object
3D geometries, their interactions, and associated actions. A key innovation in
our framework is a structured dual-patch representation for modeling objects
and their interactions, combined with action recognition to enhance the
interaction prediction. Experiments on MMHOI and the recently proposed CORE4D
datasets demonstrate that our approach achieves state-of-the-art performance in
multi-HOI modeling, excelling in both accuracy and reconstruction quality.

</details>


### [33] [PrismGS: Physically-Grounded Anti-Aliasing for High-Fidelity Large-Scale 3D Gaussian Splatting](https://arxiv.org/abs/2510.07830)
*Houqiang Zhong,Zhenglong Wu,Sihua Fu,Zihan Zheng,Xin Jin,Xiaoyun Zhang,Li Song,Qiang Hu*

Main category: cs.CV

TL;DR: PrismGS是一个新提出的用于3D Gaussian Splatting的正则化框架，通过金字塔多尺度监督和物理先验约束，有效解决了大规模城市场景渲染中的锯齿和闪烁等伪影问题。


<details>
  <summary>Details</summary>
Motivation: 3DGS技术在小场景下可以实现高质量实时渲染，但在大规模城市环境或高分辨率渲染中，会出现严重的锯齿和闪烁伪影，根源于高斯表示和城市多尺度几何之间的不匹配，现有方法无法彻底解决渲染保真度的不足。

Method: 提出PrismGS框架，结合两种正则化方法：1) 金字塔多尺度监督，使用带预滤波的金字塔图像来监督渲染输出，实现多尺度一致性并提升抗锯齿能力；2) 尺寸正则化，为3D高斯基元设置物理下界，避免产生退化的、视角相关的伪几何。该方法易于集成到现有管线中。

Result: 在MatrixCity、Mill-19和UrbanScene3D等数据集上，PrismGS大幅提升了渲染质量，PSNR相较于基线CityGaussian提升1.5 dB，且在4K高分辨率下表现出优越的质量和鲁棒性。

Conclusion: PrismGS为3D高斯渲染中的伪影问题提供了有效且通用的解决方案，实现了在大规模城市环境下的高保真、高鲁棒性和高分辨率实时渲染，且适配性很好，推进了3DGS技术在实际复杂场景中的应用。

Abstract: 3D Gaussian Splatting (3DGS) has recently enabled real-time photorealistic
rendering in compact scenes, but scaling to large urban environments introduces
severe aliasing artifacts and optimization instability, especially under
high-resolution (e.g., 4K) rendering. These artifacts, manifesting as
flickering textures and jagged edges, arise from the mismatch between Gaussian
primitives and the multi-scale nature of urban geometry. While existing
``divide-and-conquer'' pipelines address scalability, they fail to resolve this
fidelity gap. In this paper, we propose PrismGS, a physically-grounded
regularization framework that improves the intrinsic rendering behavior of 3D
Gaussians. PrismGS integrates two synergistic regularizers. The first is
pyramidal multi-scale supervision, which enforces consistency by supervising
the rendering against a pre-filtered image pyramid. This compels the model to
learn an inherently anti-aliased representation that remains coherent across
different viewing scales, directly mitigating flickering textures. This is
complemented by an explicit size regularization that imposes a
physically-grounded lower bound on the dimensions of the 3D Gaussians. This
prevents the formation of degenerate, view-dependent primitives, leading to
more stable and plausible geometric surfaces and reducing jagged edges. Our
method is plug-and-play and compatible with existing pipelines. Extensive
experiments on MatrixCity, Mill-19, and UrbanScene3D demonstrate that PrismGS
achieves state-of-the-art performance, yielding significant PSNR gains around
1.5 dB against CityGaussian, while maintaining its superior quality and
robustness under demanding 4K rendering.

</details>


### [34] [IsoSignVid2Aud: Sign Language Video to Audio Conversion without Text Intermediaries](https://arxiv.org/abs/2510.07837)
*Harsh Kavediya,Vighnesh Nayak,Bheeshm Sharma,Balamurugan Palaniappan*

Main category: cs.CV

TL;DR: 该论文提出了一个名为IsoSignVid2Aud的端到端系统，实现了手语视频直接翻译成语音音频，无需中间文本环节。该系统在标准数据集上取得了较高准确率和良好语音质量。


<details>
  <summary>Details</summary>
Motivation: 传统手语翻译通常经过视频到文本再到语音的多阶段流程，这样不仅造成延迟，还会因为多步处理累积错误。手语直接到语音的高效即时翻译有助于强化听障人士与他人的实时沟通，特别适用于教学与手语提示等实际应用场景。

Method: 本文提出了IsoSignVid2Aud端到端框架。方法包含基于I3D的特征提取、专用特征变换网络与音频生成模块。引入一种新颖的非极大值抑制（NMS）算法，实现非文法连续手语序列中标志的时序检测，不依赖中间文本转写，直接生成语音。

Result: 在ASL-Citizen-1500和WLASL-100两个标准数据集上，模型取得了72.01%和78.67%的Top-1准确率。语音质量方面，PESQ得分2.67、STOI得分0.73，显示生成语音具有较好可懂度。

Conclusion: IsoSignVid2Aud框架验证了端到端手语视频到语音的可行性，减少了延迟和错误累计，能为听障人群实用沟通场景提供即时、高质量的语音输出。

Abstract: Sign language to spoken language audio translation is important to connect
the hearing- and speech-challenged humans with others. We consider sign
language videos with isolated sign sequences rather than continuous grammatical
signing. Such videos are useful in educational applications and sign prompt
interfaces. Towards this, we propose IsoSignVid2Aud, a novel end-to-end
framework that translates sign language videos with a sequence of possibly
non-grammatic continuous signs to speech without requiring intermediate text
representation, providing immediate communication benefits while avoiding the
latency and cascading errors inherent in multi-stage translation systems. Our
approach combines an I3D-based feature extraction module with a specialized
feature transformation network and an audio generation pipeline, utilizing a
novel Non-Maximal Suppression (NMS) algorithm for the temporal detection of
signs in non-grammatic continuous sequences. Experimental results demonstrate
competitive performance on ASL-Citizen-1500 and WLASL-100 datasets with Top-1
accuracies of 72.01\% and 78.67\%, respectively, and audio quality metrics
(PESQ: 2.67, STOI: 0.73) indicating intelligible speech output. Code is
available at: https://github.com/BheeshmSharma/IsoSignVid2Aud_AIMLsystems-2025.

</details>


### [35] [AlignGS: Aligning Geometry and Semantics for Robust Indoor Reconstruction from Sparse Views](https://arxiv.org/abs/2510.07839)
*Yijie Gao,Houqiang Zhong,Tianchi Zhu,Zhengxue Cheng,Qiang Hu,Li Song*

Main category: cs.CV

TL;DR: 提出了一种将语义主动引入几何重建过程的新方法AlignGS，实现了端到端的几何与语义协同优化，有效提升了稀疏视角下3D重建的准确性。


<details>
  <summary>Details</summary>
Motivation: 在增强现实、虚拟现实和机器人等领域，对语义丰富的室内三维模型需求迅速增长。然而，从稀疏视角重建三维模型存在几何歧义，现有方法往往把语义作为附属特征，未能有效指导几何建模，导致重建效果有限。

Method: 提出AlignGS框架，通过端到端联合优化三维几何和语义信息。方法创新性地将2D基础模型的丰富先验信息蒸馏，并引入语义到几何的指导机制（如深度一致性和法线正则化），直接作为3D表示的正则项，实现几何和语义的深度融合。

Result: 在标准数据集上的大量实验显示，AlignGS在新视角合成和几何重建精度上均达到了当前最优的水平，重建模型完整性和一致性显著高于现有方法。

Conclusion: 通过将语义先验作为几何正则器引入，可以在稀疏视角重建中获得更连贯和完整的三维模型。该方法为低视角三维建模提供了新的方向，验证了语义与几何深度融合的有效性。

Abstract: The demand for semantically rich 3D models of indoor scenes is rapidly
growing, driven by applications in augmented reality, virtual reality, and
robotics. However, creating them from sparse views remains a challenge due to
geometric ambiguity. Existing methods often treat semantics as a passive
feature painted on an already-formed, and potentially flawed, geometry. We
posit that for robust sparse-view reconstruction, semantic understanding
instead be an active, guiding force. This paper introduces AlignGS, a novel
framework that actualizes this vision by pioneering a synergistic, end-to-end
optimization of geometry and semantics. Our method distills rich priors from 2D
foundation models and uses them to directly regularize the 3D representation
through a set of novel semantic-to-geometry guidance mechanisms, including
depth consistency and multi-faceted normal regularization. Extensive
evaluations on standard benchmarks demonstrate that our approach achieves
state-of-the-art results in novel view synthesis and produces reconstructions
with superior geometric accuracy. The results validate that leveraging semantic
priors as a geometric regularizer leads to more coherent and complete 3D models
from limited input views. Our code is avaliable at
https://github.com/MediaX-SJTU/AlignGS .

</details>


### [36] [Self-Supervised Learning Strategies for a Platform to Test the Toxicity of New Chemicals and Materials](https://arxiv.org/abs/2510.07853)
*Thomas Lautenschlager,Nils Friederich,Angelo Jovin Yamachui Sitcheu,Katja Nau,Gaëlle Hayot,Thomas Dickmeis,Ralf Mikut*

Main category: cs.CV

TL;DR: 本文利用自监督学习方法，对高通量毒性测试中的表型数据进行分析，能够有效区分不同化合物诱导的斑马鱼胚胎表型与作用方式，展示了机器学习在毒理学自动化测试中的潜力。


<details>
  <summary>Details</summary>
Motivation: 高通量毒性测试需要自动、准确地识别大量化合物对生物体的影响，而传统方法费时费力。作者希望利用机器学习提升分析效率和精度，解决现有自动评估方式的挑战。

Method: 作者基于自监督学习构建表征学习模型，应用于公开的EmbryoNet斑马鱼胚胎数据集。模型自动学习不同化合物作用下的胚胎表型特征，从而区分不同作用机制。

Result: 自监督学习得到的表征能够有效区分不同化合物的作用方式，在表型分类和毒性机制区分上表现良好。实验结果证明该方法在毒性高通量分析中的适用性和潜力。

Conclusion: 基于自监督学习的表征方法可提高高通量毒性测试的自动识别能力，有助于推动机器学习模型与实际毒性测试设备的集成，将加速自动化毒理学检测的发展。

Abstract: High-throughput toxicity testing offers a fast and cost-effective way to test
large amounts of compounds. A key component for such systems is the automated
evaluation via machine learning models. In this paper, we address critical
challenges in this domain and demonstrate how representations learned via
self-supervised learning can effectively identify toxicant-induced changes. We
provide a proof-of-concept that utilizes the publicly available EmbryoNet
dataset, which contains ten zebrafish embryo phenotypes elicited by various
chemical compounds targeting different processes in early embryonic
development. Our analysis shows that the learned representations using
self-supervised learning are suitable for effectively distinguishing between
the modes-of-action of different compounds. Finally, we discuss the integration
of machine learning models in a physical toxicity testing device in the context
of the TOXBOX project.

</details>


### [37] [XYZCylinder: Feedforward Reconstruction for Driving Scenes Based on A Unified Cylinder Lifting Method](https://arxiv.org/abs/2510.07856)
*Haochen Yu,Qiankun Liu,Hongyuan Liu,Jianfei Jiang,Juntao Lyu,Jiansheng Chen,Huimin Ma*

Main category: cs.CV

TL;DR: 本文提出了XYZCylinder，一种基于统一柱面升维方法的前馈重建模型，有效提升了自动驾驶场景下跨不同相机配置的泛化能力和重建精度，并实现了零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 现有前馈重建范式由于隐式学习固定视角变换，导致其在相机配置变化时泛化性差，且360°全景稀疏视角间重叠区域小，使得驾驶场景的重建准确率低。本文旨在解决这两个关键痛点。

Method: 本文提出了XYZCylinder模型，包括统一柱面相机建模（UCCM）策略以适配不同相机配置，并引入了融合多专用模块的混合特征表达和新设计的柱面平面特征组（CPFG），实现2D特征到3D空间的高效升维。

Result: 实验结果表明，XYZCylinder在多种评估设定下均达到了最新最优性能（SOTA），并且可以在零样本条件下迁移泛化到其它驾驶场景。

Conclusion: XYZCylinder模型有效解决了现有方法在自动驾驶场景下重建泛化性和精度的不足，为多相机配置和复杂路况下的3D场景重建提供了新范式。

Abstract: Recently, more attention has been paid to feedforward reconstruction
paradigms, which mainly learn a fixed view transformation implicitly and
reconstruct the scene with a single representation. However, their
generalization capability and reconstruction accuracy are still limited while
reconstructing driving scenes, which results from two aspects: (1) The fixed
view transformation fails when the camera configuration changes, limiting the
generalization capability across different driving scenes equipped with
different camera configurations. (2) The small overlapping regions between
sparse views of the $360^\circ$ panorama and the complexity of driving scenes
increase the learning difficulty, reducing the reconstruction accuracy. To
handle these difficulties, we propose \textbf{XYZCylinder}, a feedforward model
based on a unified cylinder lifting method which involves camera modeling and
feature lifting. Specifically, to improve the generalization capability, we
design a Unified Cylinder Camera Modeling (UCCM) strategy, which avoids the
learning of viewpoint-dependent spatial correspondence and unifies different
camera configurations with adjustable parameters. To improve the reconstruction
accuracy, we propose a hybrid representation with several dedicated modules
based on newly designed Cylinder Plane Feature Group (CPFG) to lift 2D image
features to 3D space. Experimental results show that XYZCylinder achieves
state-of-the-art performance under different evaluation settings, and can be
generalized to other driving scenes in a zero-shot manner. Project page:
\href{https://yuyuyu223.github.io/XYZCYlinder-projectpage/}{here}.

</details>


### [38] [MARC: Memory-Augmented RL Token Compression for Efficient Video Understanding](https://arxiv.org/abs/2510.07915)
*Peiran Wu,Zhuorui Yu,Yunze Liu,Chi-Hao Wu,Enmin Zhou,Junxiao Shen*

Main category: cs.CV

TL;DR: 提出了一种新的视频视觉语言模型（VLM）高效压缩方法MARC，大幅降低计算和内存成本，效果接近原模型。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型发展迅速，多模态（尤其是视觉-语言）模型在从图像扩展到视频时因帧数多、时长长面临巨大的计算压力。现有无训练压缩方法容易丢失关键信息，显著影响效果，需要更优方案。

Method: 提出Memory-Augmented Reinforcement Learning-based Token Compression（MARC），结合结构化检索与基于强化学习的蒸馏策略。具体采用Visual Memory Retriever（VMR）检索关键视频片段，再用C-GRPO框架将教师模型的推理能力迁移到学生模型，实现检索后再压缩。

Result: 在六个视频基准上，MARC仅用一个帧的token即可获得接近原模型的准确率，视觉token压缩95%，GPU显存使用减少72%，推理延迟下降23.9%。

Conclusion: MARC大幅提升了VLM在视频理解任务中的资源效率，为视频问答、监控和自动驾驶等受限资源场景下的实时应用提供了有力支持。

Abstract: The rapid progress of large language models (LLMs) has laid the foundation
for multimodal models. However, visual language models (VLMs) still face heavy
computational costs when extended from images to videos due to high frame rates
and long durations. Token compression is a promising solution, yet most
existing training-free methods cause information loss and performance
degradation. To overcome this, we propose \textbf{Memory-Augmented
Reinforcement Learning-based Token Compression (MARC)}, which integrates
structured retrieval and RL-based distillation. MARC adopts a
\textit{retrieve-then-compress} strategy using a \textbf{Visual Memory
Retriever (VMR)} to select key clips and a \textbf{Compression Group Relative
Policy Optimization (C-GRPO)} framework to distil reasoning ability from a
teacher to a student model. Experiments on six video benchmarks show that MARC
achieves near-baseline accuracy using only one frame's tokens -- reducing
visual tokens by \textbf{95\%}, GPU memory by \textbf{72\%}, and latency by
\textbf{23.9\%}. This demonstrates its potential for efficient, real-time video
understanding in resource-constrained settings such as video QA, surveillance,
and autonomous driving.

</details>


### [39] [ASBench: Image Anomalies Synthesis Benchmark for Anomaly Detection](https://arxiv.org/abs/2510.07927)
*Qunyi Zhang,Songan Zhang,Jinbao Wang,Xiaoning Lei,Guoyang Xie,Guannan Jiang,Zhichao Lu*

Main category: cs.CV

TL;DR: 该论文提出ASBench，这是第一个专门评估异常合成方法的综合基准框架，填补了当前异常合成方法系统性评价的空白。


<details>
  <summary>Details</summary>
Motivation: 异常检测在制造质量控制中很重要，但受限于异常样本稀少和人工标注成本高。虽然异常合成可以解决这一问题，目前相关研究多以其为辅助，且缺乏系统性评价和定量分析，影响算法进步。

Method: 作者提出ASBench框架，设计了四个关键评估维度：1）方法在不同数据集和流程下的泛化能力；2）合成数据与真实数据的比例；3）合成图像内在指标与异常检测性能指标的相关性；4）混合型异常合成方法的策略。

Result: 通过大量实验，ASBench揭示了当前异常合成方法的不足之处，并给出了详细的数据分析，验证了该基准框架的有效性。

Conclusion: ASBench为异常合成方法的标准化评估和未来研究方向提供了重要的参考和工具，有助于推动该领域的持续进步。

Abstract: Anomaly detection plays a pivotal role in manufacturing quality control, yet
its application is constrained by limited abnormal samples and high manual
annotation costs. While anomaly synthesis offers a promising solution, existing
studies predominantly treat anomaly synthesis as an auxiliary component within
anomaly detection frameworks, lacking systematic evaluation of anomaly
synthesis algorithms. Current research also overlook crucial factors specific
to anomaly synthesis, such as decoupling its impact from detection,
quantitative analysis of synthetic data and adaptability across different
scenarios. To address these limitations, we propose ASBench, the first
comprehensive benchmarking framework dedicated to evaluating anomaly synthesis
methods. Our framework introduces four critical evaluation dimensions: (i) the
generalization performance across different datasets and pipelines (ii) the
ratio of synthetic to real data (iii) the correlation between intrinsic metrics
of synthesis images and anomaly detection performance metrics , and (iv)
strategies for hybrid anomaly synthesis methods. Through extensive experiments,
ASBench not only reveals limitations in current anomaly synthesis methods but
also provides actionable insights for future research directions in anomaly
synthesis

</details>


### [40] [A Multimodal Depth-Aware Method For Embodied Reference Understanding](https://arxiv.org/abs/2510.08278)
*Fevziye Irem Eyiokur,Dogucan Yaman,Hazım Kemal Ekenel,Alexander Waibel*

Main category: cs.CV

TL;DR: 本文提出了一种结合深度信息与大型语言模型增强数据的新方法，提高了基于语言和指点多模态线索的目标识别准确率。


<details>
  <summary>Details</summary>
Motivation: 以往基于开放词汇的目标检测方法，在场景中存在多个候选目标时容易产生歧义，难以准确理解所指。本文旨在解决多候选物体和复杂场景下的歧义消解问题。

Method: 提出了一个新的ERU (Embodied Reference Understanding) 框架，联合利用LLM增强的数据、深度图（depth-map）这一新模态以及深度感知决策模块，实现语言和体感信号的更好融合。

Result: 在两个数据集上实验表明，所提方法较现有主流方法在指称检测任务上有显著性能提升，具备更高准确性和可靠性。

Conclusion: 结合大语言模型增强的数据和深度信息，有效提升了多模态指称理解任务下的目标识别能力，尤其是在复杂或拥挤环境下能够更好地消除歧义。

Abstract: Embodied Reference Understanding requires identifying a target object in a
visual scene based on both language instructions and pointing cues. While prior
works have shown progress in open-vocabulary object detection, they often fail
in ambiguous scenarios where multiple candidate objects exist in the scene. To
address these challenges, we propose a novel ERU framework that jointly
leverages LLM-based data augmentation, depth-map modality, and a depth-aware
decision module. This design enables robust integration of linguistic and
embodied cues, improving disambiguation in complex or cluttered environments.
Experimental results on two datasets demonstrate that our approach
significantly outperforms existing baselines, achieving more accurate and
reliable referent detection.

</details>


### [41] [TTOM: Test-Time Optimization and Memorization for Compositional Video Generation](https://arxiv.org/abs/2510.07940)
*Leigang Qu,Ziyang Wang,Na Zheng,Wenjie Wang,Liqiang Nie,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 本文提出了一种名为TTOM的训练无关方法，通过测试时优化和记忆机制，提高了视频基础模型（VFMs）在组合场景下的文本-图像对齐与生成表现。


<details>
  <summary>Details</summary>
Motivation: 现有的视频基础模型尽管视觉生成能力强，但在处理涉及复杂动作、数字感知和空间关系等组合场景时表现不佳，亟需提升其在多模态组合生成任务中的能力。

Method: 提出TTOM方法，在推理时引入新的参数并利用一般化的布局注意力目标进行优化，而非如旧方法只针对每个样本直接干预潜变量或注意力。同时，将视频生成任务设定为流式场景，用参数化记忆机制（支持插入、读取、更新、删除）保存历史优化上下文。

Result: 在T2V-CompBench与Vbench基准测试上，TTOM展现出高效、实用且可扩展的性能，能够实现组合视频生成任务中的跨模态对齐，并优于现有方法。

Conclusion: TTOM显著提升了VFMs在组合场景下的世界知识解耦、迁移能力和泛化性，是一种有效、实用且易于扩展的组合视频生成方法。

Abstract: Video Foundation Models (VFMs) exhibit remarkable visual generation
performance, but struggle in compositional scenarios (e.g., motion, numeracy,
and spatial relation). In this work, we introduce Test-Time Optimization and
Memorization (TTOM), a training-free framework that aligns VFM outputs with
spatiotemporal layouts during inference for better text-image alignment. Rather
than direct intervention to latents or attention per-sample in existing work,
we integrate and optimize new parameters guided by a general layout-attention
objective. Furthermore, we formulate video generation within a streaming
setting, and maintain historical optimization contexts with a parametric memory
mechanism that supports flexible operations, such as insert, read, update, and
delete. Notably, we found that TTOM disentangles compositional world knowledge,
showing powerful transferability and generalization. Experimental results on
the T2V-CompBench and Vbench benchmarks establish TTOM as an effective,
practical, scalable, and efficient framework to achieve cross-modal alignment
for compositional video generation on the fly.

</details>


### [42] [Gaze on the Prize: Shaping Visual Attention with Return-Guided Contrastive Learning](https://arxiv.org/abs/2510.08442)
*Andrew Lee,Ian Chuang,Dechen Gao,Kai Fukazawa,Iman Soltani*

Main category: cs.CV

TL;DR: 本文提出了一种名为Gaze on the Prize的视觉强化学习框架，引入类人视觉中心聚焦（foveation）注意力机制，通过对不同return结果的对比学习，显著提升样本效率与学习稳定性，无需更改底层算法和超参数，实现在多项任务上的优越表现。


<details>
  <summary>Details</summary>
Motivation: 视觉RL需从高维图像中提取少量与任务相关的信息，现有方法在探索和计算上浪费较多资源，导致样本效率低且不稳定。作者希望通过模拟人眼视觉聚焦机制，仅关注任务相关特征，以提升表现。

Method: 提出可学习的视网膜注意力机制Gaze，受代理自我监督信号（源自追求高return的经验）指导。利用return差异作为判别正例和负例的依据，构造对比三元组，通过对比学习训练注意力机制，使其更聚焦于导致不同结果的关键特征。实现方式为return引导的对比学习，无需更改RL主体算法或超参数。

Result: 方法在ManiSkill3基准的多个操纵任务中，实现了最多2.4倍的样本效率提升，并在部分任务上超越基线方法，基线无法解决的任务也被本方法成功解决。

Conclusion: Gaze on the Prize通过引入return引导的对比注意机制，极大提升了视觉RL代理的信息聚焦能力和样本效率，具备很强的通用性，且易于引入现有RL框架。

Abstract: Visual Reinforcement Learning (RL) agents must learn to act based on
high-dimensional image data where only a small fraction of the pixels is
task-relevant. This forces agents to waste exploration and computational
resources on irrelevant features, leading to sample-inefficient and unstable
learning. To address this, inspired by human visual foveation, we introduce
Gaze on the Prize. This framework augments visual RL with a learnable foveal
attention mechanism (Gaze), guided by a self-supervised signal derived from the
agent's experience pursuing higher returns (the Prize). Our key insight is that
return differences reveal what matters most: If two similar representations
produce different outcomes, their distinguishing features are likely
task-relevant, and the gaze should focus on them accordingly. This is realized
through return-guided contrastive learning that trains the attention to
distinguish between the features relevant to success and failure. We group
similar visual representations into positives and negatives based on their
return differences and use the resulting labels to construct contrastive
triplets. These triplets provide the training signal that teaches the attention
mechanism to produce distinguishable representations for states associated with
different outcomes. Our method achieves up to 2.4x improvement in sample
efficiency and can solve tasks that the baseline fails to learn, demonstrated
across a suite of manipulation tasks from the ManiSkill3 benchmark, all without
modifying the underlying algorithm or hyperparameters.

</details>


### [43] [CVD-STORM: Cross-View Video Diffusion with Spatial-Temporal Reconstruction Model for Autonomous Driving](https://arxiv.org/abs/2510.07944)
*Tianrui Zhang,Yichen Liu,Zilin Guo,Yuxin Guo,Jingcheng Ni,Chenjing Ding,Dan Xu,Lewei Lu,Zehuan Wu*

Main category: cs.CV

TL;DR: 该论文提出了一种名为CVD-STORM的跨视角视频扩散模型，实现了受控条件下的多视角、长时序4D视频生成与重建，并显著提升了生成质量。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶等领域需求增加，高质量视频生成及提供多模态信息（如深度估计）变得重要。现有方法难以兼顾多视角、长时序、结构化信息生成，亟需新的生成方案。

Method: 提出CVD-STORM模型，结合空间-时间可重建的变分自编码器（VAE），通过4D重建任务提升VAE对三维结构与时序动态的建模能力，并将其集成进视频扩散模型，实现增强的视频生成。采用高斯溅射解码器，共同训练以提升动态场景的重建能力。

Result: 实验表明，CVD-STORM在FID和FVD等指标上大幅优于现有方法，且高斯溅射解码器能有效重建动态场景，为场景理解提供有价值的几何信息。

Conclusion: CVD-STORM能高质量地生成多视角、长时序视频，并融合可用的几何和动态图像信息，在未来环境建模与自动驾驶场景下具有广泛应用潜力。

Abstract: Generative models have been widely applied to world modeling for environment
simulation and future state prediction. With advancements in autonomous
driving, there is a growing demand not only for high-fidelity video generation
under various controls, but also for producing diverse and meaningful
information such as depth estimation. To address this, we propose CVD-STORM, a
cross-view video diffusion model utilizing a spatial-temporal reconstruction
Variational Autoencoder (VAE) that generates long-term, multi-view videos with
4D reconstruction capabilities under various control inputs. Our approach first
fine-tunes the VAE with an auxiliary 4D reconstruction task, enhancing its
ability to encode 3D structures and temporal dynamics. Subsequently, we
integrate this VAE into the video diffusion process to significantly improve
generation quality. Experimental results demonstrate that our model achieves
substantial improvements in both FID and FVD metrics. Additionally, the
jointly-trained Gaussian Splatting Decoder effectively reconstructs dynamic
scenes, providing valuable geometric information for comprehensive scene
understanding.

</details>


### [44] [Have We Scene It All? Scene Graph-Aware Deep Point Cloud Compression](https://arxiv.org/abs/2510.08512)
*Nikolaos Stathoulopoulos,Christoforos Kanellakis,George Nikolakopoulos*

Main category: cs.CV

TL;DR: 本文提出了一种基于语义场景图的点云深度压缩框架，在保持结构和语义信息的基础上实现高效压缩，实验结果大幅减少数据量，并适用于多机器人系统中的关键应用。


<details>
  <summary>Details</summary>
Motivation: 随着边缘和云端处理日益流行，多机器人系统对点云数据的高效传输需求不断提升，但点云数据体量大、复杂、带宽受限及连接不稳定，严重影响系统性能。

Method: 作者提出先将点云分解为语义一致的patches（区域），并通过语义感知的编码器（集成FiLM机制）压缩为紧凑的潜在表示；解码侧利用折叠式解码器及图节点属性，实现结构和语义准确的重建。

Result: 在SemanticKITTI和nuScenes数据集上，该方法压缩率达98%，并能很好地保留原始点云结构和语义。此外，对多机器人位姿图优化和地图融合等下游任务，能获得与原始LiDAR数据媲美的轨迹准确率和地图配准效果。

Conclusion: 本文方法实现了高效、语义和结构保真的点云压缩，显著减小数据量，为带宽受限环境下的多机器人感知、定位与地图构建提供了切实可行的新方案。

Abstract: Efficient transmission of 3D point cloud data is critical for advanced
perception in centralized and decentralized multi-agent robotic systems,
especially nowadays with the growing reliance on edge and cloud-based
processing. However, the large and complex nature of point clouds creates
challenges under bandwidth constraints and intermittent connectivity, often
degrading system performance. We propose a deep compression framework based on
semantic scene graphs. The method decomposes point clouds into semantically
coherent patches and encodes them into compact latent representations with
semantic-aware encoders conditioned by Feature-wise Linear Modulation (FiLM). A
folding-based decoder, guided by latent features and graph node attributes,
enables structurally accurate reconstruction. Experiments on the SemanticKITTI
and nuScenes datasets show that the framework achieves state-of-the-art
compression rates, reducing data size by up to 98% while preserving both
structural and semantic fidelity. In addition, it supports downstream
applications such as multi-robot pose graph optimization and map merging,
achieving trajectory accuracy and map alignment comparable to those obtained
with raw LiDAR scans.

</details>


### [45] [A Large-scale Dataset for Robust Complex Anime Scene Text Detection](https://arxiv.org/abs/2510.07951)
*Ziyi Dong,Yurui Zhang,Changmao Li,Naomi Rue Golding,Qing Long*

Main category: cs.CV

TL;DR: 该论文提出了AnimeText，一个针对动漫场景大规模文本检测的数据集，有效提升了检测准确率。


<details>
  <summary>Details</summary>
Motivation: 现有文本检测数据集主要面向自然场景和文档，忽略了动漫中丰富多样且复杂的文本样式和布局。动漫场景下的文本与自然图像差异显著，因此需要专门的数据集支持相关研究。

Method: 作者构建了包含73.5万张图片和420万个文本块注释的AnimeText数据集，具备分层注释以及专为动漫场景设计的困难负例采样。然后，使用当前主流方法进行跨数据集评测。

Result: 实验结果显示，基于AnimeText训练的模型在动漫场景文本检测任务中，性能优于基于其他现有数据集训练的模型。

Conclusion: AnimeText有效弥补了动漫场景文本检测数据集的空白，为相关研究提供了高质量资源，在实际应用中提升了检测效果。

Abstract: Current text detection datasets primarily target natural or document scenes,
where text typically appear in regular font and shapes, monotonous colors, and
orderly layouts. The text usually arranged along straight or curved lines.
However, these characteristics differ significantly from anime scenes, where
text is often diverse in style, irregularly arranged, and easily confused with
complex visual elements such as symbols and decorative patterns. Text in anime
scene also includes a large number of handwritten and stylized fonts. Motivated
by this gap, we introduce AnimeText, a large-scale dataset containing 735K
images and 4.2M annotated text blocks. It features hierarchical annotations and
hard negative samples tailored for anime scenarios. %Cross-dataset evaluations
using state-of-the-art methods demonstrate that models trained on AnimeText
achieve superior performance in anime text detection tasks compared to existing
datasets. To evaluate the robustness of AnimeText in complex anime scenes, we
conducted cross-dataset benchmarking using state-of-the-art text detection
methods. Experimental results demonstrate that models trained on AnimeText
outperform those trained on existing datasets in anime scene text detection
tasks. AnimeText on HuggingFace:
https://huggingface.co/datasets/deepghs/AnimeText

</details>


### [46] [Dream to Recall: Imagination-Guided Experience Retrieval for Memory-Persistent Vision-and-Language Navigation](https://arxiv.org/abs/2510.08553)
*Yunzhe Xu,Yiyuan Pan,Zhe Liu*

Main category: cs.CV

TL;DR: 本文提出了一种新的视觉-语言导航（VLN）方法Memoir，利用“想象”机制高效检索环境和行为记忆，显著提升了导航表现和模型效率。


<details>
  <summary>Details</summary>
Motivation: 以往的memory-persistent VLN方法在记忆利用方面存在瓶颈，一是检索机制不灵活（整体存取或只查固定历史），二是只存环境，没有抽取行为策略知识，导致模型在长任务或复杂决策中效果有限。作者希望通过更智能、灵活地访问和利用历史经验（包括环境和动作序列），提升智能体的导航能力。

Method: Memoir方法包括：1）语言条件下的世界建模模块，通过“想象”未来状态来编码经验并生成检索查询；2）混合视点层级记忆，将环境观察和行为模式锚定在具体视点，实现混合信息检索；3）经验增强型导航模型，通过专用编码器整合检索结果，最终改进行为决策。

Result: Memoir在10个VLN测试场景中全面优于最强基线，IR2R数据集上SPL提升5.4%，训练速度提高8.3倍，推理内存占用减少74%。分析还揭示该思路在理论上还有较大发展空间。

Conclusion: 通过引入“想象-驱动”的记忆检索，Memoir显著改进了VLN中的经验利用方式，有效提升了导航效果和效率，为更智能的多模态导航开辟了新方向。

Abstract: Vision-and-Language Navigation (VLN) requires agents to follow natural
language instructions through environments, with memory-persistent variants
demanding progressive improvement through accumulated experience. Existing
approaches for memory-persistent VLN face critical limitations: they lack
effective memory access mechanisms, instead relying on entire memory
incorporation or fixed-horizon lookup, and predominantly store only
environmental observations while neglecting navigation behavioral patterns that
encode valuable decision-making strategies. We present Memoir, which employs
imagination as a retrieval mechanism grounded by explicit memory: a world model
imagines future navigation states as queries to selectively retrieve relevant
environmental observations and behavioral histories. The approach comprises: 1)
a language-conditioned world model that imagines future states serving dual
purposes: encoding experiences for storage and generating retrieval queries; 2)
Hybrid Viewpoint-Level Memory that anchors both observations and behavioral
patterns to viewpoints, enabling hybrid retrieval; and 3) an
experience-augmented navigation model that integrates retrieved knowledge
through specialized encoders. Extensive evaluation across diverse
memory-persistent VLN benchmarks with 10 distinctive testing scenarios
demonstrates Memoir's effectiveness: significant improvements across all
scenarios, with 5.4% SPL gains on IR2R over the best memory-persistent
baseline, accompanied by 8.3x training speedup and 74% inference memory
reduction. The results validate that predictive retrieval of both environmental
and behavioral memories enables more effective navigation, with analysis
indicating substantial headroom (73.3% vs 93.4% upper bound) for this
imagination-guided paradigm. Code at https://github.com/xyz9911/Memoir.

</details>


### [47] [SimCast: Enhancing Precipitation Nowcasting with Short-to-Long Term Knowledge Distillation](https://arxiv.org/abs/2510.07953)
*Yifang Yin,Shengkai Chen,Yiyao Li,Lu Wang,Ruibing Jin,Wei Cui,Shili Xiang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为SimCast的新型降水临近预报训练流程，通过短到长预测时长的知识蒸馏和加权损失函数提升重降雨区域的预测效果，并将其与扩散模型结合为CasCast，有效提升了预报准确性，在三大数据集上均优于以往方法。


<details>
  <summary>Details</summary>
Motivation: 降水临近预报对防灾、农业、交通等领域至关重要，但地球系统的复杂性使得精准预报十分困难。现有方法在预测不同时间范围时存在一定局限，尤其是在长时间预测上表现不佳，且往往无法兼顾极端天气的准确性。

Method: 作者提出了SimCast训练流程，利用短-长时序知识蒸馏和针对重降雨区的加权均方误差损失，在不增加推理成本的情况下提升模型表现。进一步地，将SimCast集成到基于扩散概率模型的CasCast中，克服了确定性模型易出现模糊和分布偏移的问题。

Result: SimCast和CasCast在三大常用降水预报数据集（SEVIR、HKO-7、MeteoNet）上进行实验，分别实现了0.452、0.474和0.361的CSI分数，均大幅超过现有主流模型。

Conclusion: 提出的方法不仅提升了降水临近预报的准确性，尤其在重降雨和长时序预测上更具优势，并通过概率化建模解决了输出模糊等确定性模型的局限，有望进一步推动降水预报应用落地。

Abstract: Precipitation nowcasting predicts future radar sequences based on current
observations, which is a highly challenging task driven by the inherent
complexity of the Earth system. Accurate nowcasting is of utmost importance for
addressing various societal needs, including disaster management, agriculture,
transportation, and energy optimization. As a complementary to existing
non-autoregressive nowcasting approaches, we investigate the impact of
prediction horizons on nowcasting models and propose SimCast, a novel training
pipeline featuring a short-to-long term knowledge distillation technique
coupled with a weighted MSE loss to prioritize heavy rainfall regions. Improved
nowcasting predictions can be obtained without introducing additional overhead
during inference. As SimCast generates deterministic predictions, we further
integrate it into a diffusion-based framework named CasCast, leveraging the
strengths from probabilistic models to overcome limitations such as blurriness
and distribution shift in deterministic outputs. Extensive experimental results
on three benchmark datasets validate the effectiveness of the proposed
framework, achieving mean CSI scores of 0.452 on SEVIR, 0.474 on HKO-7, and
0.361 on MeteoNet, which outperforms existing approaches by a significant
margin.

</details>


### [48] [ResAD: Normalized Residual Trajectory Modeling for End-to-End Autonomous Driving](https://arxiv.org/abs/2510.08562)
*Zhiyu Zheng,Shaoyu Chen,Haoran Yin,Xinbang Zhang,Jialv Zou,Xinggang Wang,Qian Zhang,Lefei Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种改进端到端自动驾驶系统的方法，解决了轨迹数据时空不平衡导致模型泛化能力和安全性下降的问题。通过重新定义学习任务，模型不再直接预测未来轨迹，而是学习与惯性参考轨迹的偏差，并对远期不确定目标的优化信号加权，提升了模型的泛化与性能。


<details>
  <summary>Details</summary>
Motivation: 端到端自动驾驶系统预测未来轨迹时遇到数据时空不均衡问题，导致模型优化困难、易产生虚假关联，并优先关注远期预测而忽略即时安全。因此，亟需新方法提高模型的因果推理能力和优化效率。

Method: 提出ResAD框架，将预测改为学习轨迹偏离惯性参考轨迹（惯性路径）的残差，并通过每个预测点的归一化（Point-wise Normalization）对损失函数加权。这样可以抑制高不确定性远期目标的误差主导，用惯性轨迹作为反事实参考，引导模型识别引发轨迹偏离的真实因果（如交通规则、障碍）。

Result: 在NAVSIM基准测试上，ResAD框架仅用两步去噪的原始扩散策略就获得了88.6的最优PDMS表现，显示出任务难度和模型性能的双重提升。同时实验也验证了方法有效性。

Conclusion: ResAD通过轨迹残差建模和点归一化极大简化了自动驾驶感知与决策任务，提高了模型性能与泛化能力，为未来端到端自动驾驶系统提供了理论与实践支持。相关代码也将开源促进后续研究。

Abstract: End-to-end autonomous driving (E2EAD) systems, which learn to predict future
trajectories directly from sensor data, are fundamentally challenged by the
inherent spatio-temporal imbalance of trajectory data. This imbalance creates a
significant optimization burden, causing models to learn spurious correlations
instead of causal inference, while also prioritizing uncertain, distant
predictions, thereby compromising immediate safety. To address these issues, we
propose ResAD, a novel Normalized Residual Trajectory Modeling framework.
Instead of predicting the future trajectory directly, our approach reframes the
learning task to predict the residual deviation from a deterministic inertial
reference. The inertial reference serves as a counterfactual, forcing the model
to move beyond simple pattern recognition and instead identify the underlying
causal factors (e.g., traffic rules, obstacles) that necessitate deviations
from a default, inertially-guided path. To deal with the optimization imbalance
caused by uncertain, long-term horizons, ResAD further incorporates Point-wise
Normalization of the predicted residual. It re-weights the optimization
objective, preventing large-magnitude errors associated with distant, uncertain
waypoints from dominating the learning signal. Extensive experiments validate
the effectiveness of our framework. On the NAVSIM benchmark, ResAD achieves a
state-of-the-art PDMS of 88.6 using a vanilla diffusion policy with only two
denoising steps, demonstrating that our approach significantly simplifies the
learning task and improves model performance. The code will be released to
facilitate further research.

</details>


### [49] [Latent Harmony: Synergistic Unified UHD Image Restoration via Latent Space Regularization and Controllable Refinement](https://arxiv.org/abs/2510.07961)
*Yidi Liu,Xueyang Fu,Jie Huang,Jie Xiao,Dong Li,Wenlong Zhang,Lei Bai,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 这篇论文提出了Latent Harmony，一种创新的两阶段VAE框架，专为超高清图像恢复设计，有效平衡了计算效率与高频细节恢复，达到了最新的性能水平。


<details>
  <summary>Details</summary>
Motivation: 超高清图像恢复在计算效率和高频细节保留之间存在悖论。传统VAE方法虽然高效，但其高斯约束容易丢失与退化相关的重要高频信息，影响重建质量。该工作旨在解决这一效率与细节保真度的冲突。

Method: 作者提出了Latent Harmony两阶段框架：
1）第一阶段提出LH-VAE，通过视觉语义约束和渐进式退化扰动提升语义鲁棒性，并通过潜空间等变性增强高频重建能力。
2）第二阶段将精升级VAE与修复模型联合训练，提出HF-LoRA，分别对编码器和解码器采用不同的损失函数，结合交替优化和选择性梯度传播，既能恢复真实细节，也能合成逼真纹理，同时保证预训练潜空间的结构。推理时引入可调参数平衡保真和感知质量。

Result: 实验表明，Latent Harmony在超高清与标准分辨率图像修复任务上均达到最先进表现，实现了效率、感知质量与重建精度的良好权衡。

Conclusion: Latent Harmony通过创新的潜空间建模与高频感知机制，显著提升了超高清图像恢复的效果，为兼顾效率与高质量细节重构提供了有效方案。

Abstract: Ultra-High Definition (UHD) image restoration faces a trade-off between
computational efficiency and high-frequency detail retention. While Variational
Autoencoders (VAEs) improve efficiency via latent-space processing, their
Gaussian constraint often discards degradation-specific high-frequency
information, hurting reconstruction fidelity. To overcome this, we propose
Latent Harmony, a two-stage framework that redefines VAEs for UHD restoration
by jointly regularizing the latent space and enforcing high-frequency-aware
reconstruction.In Stage One, we introduce LH-VAE, which enhances semantic
robustness through visual semantic constraints and progressive degradation
perturbations, while latent equivariance strengthens high-frequency
reconstruction.Stage Two jointly trains this refined VAE with a restoration
model using High-Frequency Low-Rank Adaptation (HF-LoRA): an encoder LoRA
guided by a fidelity-oriented high-frequency alignment loss to recover
authentic details, and a decoder LoRA driven by a perception-oriented loss to
synthesize realistic textures. Both LoRA modules are trained via alternating
optimization with selective gradient propagation to preserve the pretrained
latent structure.At inference, a tunable parameter {\alpha} enables flexible
fidelity-perception trade-offs.Experiments show Latent Harmony achieves
state-of-the-art performance across UHD and standard-resolution tasks,
effectively balancing efficiency, perceptual quality, and reconstruction
accuracy.

</details>


### [50] [The impact of abstract and object tags on image privacy classification](https://arxiv.org/abs/2510.07976)
*Darya Baranouskaya,Andrea Cavallaro*

Main category: cs.CV

TL;DR: 本文探讨了用于图像隐私判断时，对象标签与抽象标签的效果，并发现当标签数量有限时，抽象标签更有效；而标签数量足够多时，对象标签也同样有用。


<details>
  <summary>Details</summary>
Motivation: 目前多数图像隐私分类方法依赖具体对象标签，然而关于更高层、语境化的抽象标签在隐私任务中的作用尚未明了。作者希望探索在隐私判断时两类标签的适用性及边界。

Method: 通过对比分析对象标签和抽象标签在图像隐私分类任务中的表现，分别在不同标签数量设置下（有限与充足）进行实验评测，观察隐私分类效果的变化。

Result: 实验结果显示，在标签数量有限的情况下，抽象标签能更好地捕捉场景隐私性特征，具有更高的区分能力。当为每张图像分配较多标签时，对象标签的信息同样表现有效。

Conclusion: 抽象标签在受限标签预算条件下更适合于隐私分类任务，但对象标签在标签丰富时也不可忽视。论文建议未来设计图像隐私分类器时，需根据实际可用标签类型与数量做针对性选择。

Abstract: Object tags denote concrete entities and are central to many computer vision
tasks, whereas abstract tags capture higher-level information, which is
relevant for tasks that require a contextual, potentially subjective scene
understanding. Object and abstract tags extracted from images also facilitate
interpretability. In this paper, we explore which type of tags is more suitable
for the context-dependent and inherently subjective task of image privacy.
While object tags are generally used for privacy classification, we show that
abstract tags are more effective when the tag budget is limited. Conversely,
when a larger number of tags per image is available, object-related information
is as useful. We believe that these findings will guide future research in
developing more accurate image privacy classifiers, informed by the role of tag
types and quantity.

</details>


### [51] [Is Architectural Complexity Always the Answer? A Case Study on SwinIR vs. an Efficient CNN](https://arxiv.org/abs/2510.07984)
*Chandresh Sutariya,Nitin Singh*

Main category: cs.CV

TL;DR: 本文比较了SwinIR Transformer模型与轻量级CNN在低光照图像恢复任务中的性能与效率权衡，发现后者在大幅降低计算成本的情况下取得了惊人的竞争性结果。


<details>
  <summary>Details</summary>
Motivation: 低光照图像的高频细节恢复与强噪声抑制非常困难，虽然当前SwinIR类的大型Transformer表现出色，但其高计算消耗限制了实际应用，亟需探索性价比更高的替代方案。

Method: 实验将SwinIR模型与一个标准轻量级CNN在同一任务上进行了系统对比，通过PSNR、训练轮数和模型大小等指标评估两者的实际表现与资源消耗差异。

Result: SwinIR获得较高的PSNR（39.03 dB），但CNN也达到了接近的PSNR（37.4 dB），且仅用10轮训练即可收敛（对比SwinIR的132轮），同时模型体积仅为SwinIR的1/55。

Conclusion: 标准CNN虽略逊于顶尖Transformer模型，但其低计算消耗和小型结构，在资源受限场景下极具实际应用价值，可实现高效率的低光照图像恢复。

Abstract: The simultaneous restoration of high-frequency details and suppression of
severe noise in low-light imagery presents a significant and persistent
challenge in computer vision. While large-scale Transformer models like SwinIR
have set the state of the art in performance, their high computational cost can
be a barrier for practical applications. This paper investigates the critical
trade-off between performance and efficiency by comparing the state-of-the-art
SwinIR model against a standard, lightweight Convolutional Neural Network (CNN)
on this challenging task. Our experimental results reveal a nuanced but
important finding. While the Transformer-based SwinIR model achieves a higher
peak performance, with a Peak Signal-to-Noise Ratio (PSNR) of 39.03 dB, the
lightweight CNN delivers a surprisingly competitive PSNR of 37.4 dB. Crucially,
the CNN reached this performance after converging in only 10 epochs of
training, whereas the more complex SwinIR model required 132 epochs. This
efficiency is further underscored by the model's size; the CNN is over 55 times
smaller than SwinIR. This work demonstrates that a standard CNN can provide a
near state-of-the-art result with significantly lower computational overhead,
presenting a compelling case for its use in real-world scenarios where resource
constraints are a primary concern.

</details>


### [52] [GraphEnet: Event-driven Human Pose Estimation with a Graph Neural Network](https://arxiv.org/abs/2510.07990)
*Gaurvi Goyal,Pham Cong Thuong,Arren Glover,Masayoshi Mizuno,Chiara Bartolozzi*

Main category: cs.CV

TL;DR: 本文提出了一种基于图神经网络的全新人体姿态估计算法，专为事件相机设计，能高频率地估计单人2D姿态。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习的发展，RGB相机上的人体姿态估计方法已较为成熟，但事件相机由于其低延迟、低能耗等特性，在资源受限场景（如便携设备和移动机器人）具有独特优势。目前，针对事件相机的人体姿态估计方法仍相对稀缺。

Method: 作者提出了一种新的图神经网络（GraphEnet），结合基于线的事件表示法和新颖的offset vector学习范式，通过基于置信度的池化机制，实现对单人的2D姿态高频率估计。

Result: 首次将图神经网络应用于人体姿态估计领域的事件相机数据，成功实现高效的人体姿态估计。相关算法已开源。

Conclusion: 本文的方法利用事件相机的稀疏输出特点，提升了低资源消耗场景下的人体姿态估计能力，为事件视觉领域相关应用带来了新思路。

Abstract: Human Pose Estimation is a crucial module in human-machine interaction
applications and, especially since the rise in deep learning technology, robust
methods are available to consumers using RGB cameras and commercial GPUs. On
the other hand, event-based cameras have gained popularity in the vision
research community for their low latency and low energy advantages that make
them ideal for applications where those resources are constrained like portable
electronics and mobile robots. In this work we propose a Graph Neural Network,
GraphEnet, that leverages the sparse nature of event camera output, with an
intermediate line based event representation, to estimate 2D Human Pose of a
single person at a high frequency. The architecture incorporates a novel offset
vector learning paradigm with confidence based pooling to estimate the human
pose. This is the first work that applies Graph Neural Networks to event data
for Human Pose Estimation. The code is open-source at
https://github.com/event-driven-robotics/GraphEnet-NeVi-ICCV2025.

</details>


### [53] [CIR-CoT: Towards Interpretable Composed Image Retrieval via End-to-End Chain-of-Thought Reasoning](https://arxiv.org/abs/2510.08003)
*Weihuang Lin,Yiwei Ma,Jiayi Ji,Xiaoshuai Sun,Rongrong Ji*

Main category: cs.CV

TL;DR: 本文提出了一种新方法CIR-CoT，将可解释的链式推理Chain-of-Thought (CoT)机制引入多模态大模型，用于由图片和文本组合的检索任务，从而提升检索准确率和决策透明度，并在多个数据集上取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 当前的组合图像检索方法多依赖于大规模视觉-语言模型（如CLIP）或多模态大语言模型（如Qwen-VL），但这些模型本质上是“黑箱”，缺乏可解释性，用户难以理解其检索原因，且执行复杂、细粒度的指令能力有限。因此，需要一种既能增强模型推理透明度，又能提升检索质量的新方案。

Method: 作者提出了CIR-CoT模型，是首个融合显式链式推理（CoT）的端到端检索导向多模态大模型。其核心流程是：模型先生成可解释的推理过程（包括对文本和图片的逐步分析与结论），再基于该推理结果生成用于检索的专用嵌入向量。作者还设计了一套三阶段结构化CoT标注流程，涵盖描述、推理和结论，并用此对模型进行微调。

Result: CIR-CoT在主流领域内数据集（FashionIQ，CIRR）上取得了极具竞争力的性能，并在跨领域数据集CIRCO上表现出很强的泛化能力，显著超过了以往方法。

Conclusion: CIR-CoT不仅提升了组合图像检索的准确率，还增强了推理过程的可解释性，实现了更值得信赖和高效的检索系统，为多模态AI模型的可解释性与实用性开辟了新方向。

Abstract: Composed Image Retrieval (CIR), which aims to find a target image from a
reference image and a modification text, presents the core challenge of
performing unified reasoning across visual and semantic modalities. While
current approaches based on Vision-Language Models (VLMs, e.g., CLIP) and more
recent Multimodal Large Language Models (MLLMs, e.g., Qwen-VL) have shown
progress, they predominantly function as ``black boxes." This inherent opacity
not only prevents users from understanding the retrieval rationale but also
restricts the models' ability to follow complex, fine-grained instructions. To
overcome these limitations, we introduce CIR-CoT, the first end-to-end
retrieval-oriented MLLM designed to integrate explicit Chain-of-Thought (CoT)
reasoning. By compelling the model to first generate an interpretable reasoning
chain, CIR-CoT enhances its ability to capture crucial cross-modal
interactions, leading to more accurate retrieval while making its decision
process transparent. Since existing datasets like FashionIQ and CIRR lack the
necessary reasoning data, a key contribution of our work is the creation of
structured CoT annotations using a three-stage process involving a caption,
reasoning, and conclusion. Our model is then fine-tuned to produce this
structured output before encoding its final retrieval intent into a dedicated
embedding. Comprehensive experiments show that CIR-CoT achieves highly
competitive performance on in-domain datasets (FashionIQ, CIRR) and
demonstrates remarkable generalization on the out-of-domain CIRCO dataset,
establishing a new path toward more effective and trustworthy retrieval
systems.

</details>


### [54] [RayFusion: Ray Fusion Enhanced Collaborative Visual Perception](https://arxiv.org/abs/2510.08017)
*Shaohong Wang,Bin Lu,Xinyu Xiao,Hanzhi Zhong,Bowen Pang,Tong Wang,Zhiyu Xiang,Hangguan Shan,Eryun Liu*

Main category: cs.CV

TL;DR: RayFusion是一种基于光线融合的协作视觉感知方法，通过结合协作者的光线占据信息，提升纯视觉协作感知系统中的3D目标检测表现，有效缓解深度估计歧义，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 视觉协作感知能解决自动驾驶中的传感器局限性，但因缺乏显式深度信息，纯摄像头感知系统的3D目标检测常常不准确。为减少深度估计带来的模糊性，需要新的融合方式。

Method: 提出RayFusion方法，将多视角的光线占据信息融合，减少摄像头光线上的预测冗余和误报，从而提升3D目标检测结果的准确性。

Result: 大量实验表明，RayFusion在协作视觉感知任务中相比当前主流方法表现更优，大幅提升检测准确率。

Conclusion: RayFusion为纯视觉协作感知系统提供了更有效的3D目标检测方案，为自动驾驶感知技术带来显著进步，其方法和代码已公开。

Abstract: Collaborative visual perception methods have gained widespread attention in
the autonomous driving community in recent years due to their ability to
address sensor limitation problems. However, the absence of explicit depth
information often makes it difficult for camera-based perception systems, e.g.,
3D object detection, to generate accurate predictions. To alleviate the
ambiguity in depth estimation, we propose RayFusion, a ray-based fusion method
for collaborative visual perception. Using ray occupancy information from
collaborators, RayFusion reduces redundancy and false positive predictions
along camera rays, enhancing the detection performance of purely camera-based
collaborative perception systems. Comprehensive experiments show that our
method consistently outperforms existing state-of-the-art models, substantially
advancing the performance of collaborative visual perception. The code is
available at https://github.com/wangsh0111/RayFusion.

</details>


### [55] [RASALoRE: Region Aware Spatial Attention with Location-based Random Embeddings for Weakly Supervised Anomaly Detection in Brain MRI Scans](https://arxiv.org/abs/2510.08052)
*Bheeshm Sharma,Karthikeyan Jaganathan,Balamurugan Palaniappan*

Main category: cs.CV

TL;DR: 提出了一种新的弱监督脑MRI异常检测方法RASALoRE，利用空间注意力和定位随机嵌入机制，能在仅有薄片级标签时高效检测异常区域，效果领先且模型轻量高效。


<details>
  <summary>Details</summary>
Motivation: 脑MRI异常检测常因缺少像素级标注受到限制，人工精标代价高昂。现有方法在弱标签情形下定位能力有限，亟需更高效、准确的方法应对实际应用需求。

Method: 方法分为两阶段：第一阶段使用判别型双提示调优（DDPT）机制，由薄片级标签生成高质量的伪弱标注掩码，作为粗定位信息；第二阶段引入带区域感知空间注意力的分割网络，并结合基于位置的固定随机嵌入，加强模型对异常区域关注。

Result: 在BraTS20、BraTS21、BraTS23和MSD四个数据集上的实验显示，所提方法在检出准确率上显著优于现有主流WSAD方法，参数量少于800万，计算量大幅降低。

Conclusion: RASALoRE框架在弱监督脑MRI异常检测任务中取得优异表现，在标注稀缺和资源受限情境下具有实际推广价值，推动了弱监督医学影像分析技术发展。

Abstract: Weakly Supervised Anomaly detection (WSAD) in brain MRI scans is an important
challenge useful to obtain quick and accurate detection of brain anomalies when
precise pixel-level anomaly annotations are unavailable and only weak labels
(e.g., slice-level) are available. In this work, we propose RASALoRE: Region
Aware Spatial Attention with Location-based Random Embeddings, a novel
two-stage WSAD framework. In the first stage, we introduce a Discriminative
Dual Prompt Tuning (DDPT) mechanism that generates high-quality pseudo weak
masks based on slice-level labels, serving as coarse localization cues. In the
second stage, we propose a segmentation network with a region-aware spatial
attention mechanism that relies on fixed location-based random embeddings. This
design enables the model to effectively focus on anomalous regions. Our
approach achieves state-of-the-art anomaly detection performance, significantly
outperforming existing WSAD methods while utilizing less than 8 million
parameters. Extensive evaluations on the BraTS20, BraTS21, BraTS23, and MSD
datasets demonstrate a substantial performance improvement coupled with a
significant reduction in computational complexity. Code is available at:
https://github.com/BheeshmSharma/RASALoRE-BMVC-2025/.

</details>


### [56] [RetouchLLM: Training-free White-box Image Retouching](https://arxiv.org/abs/2510.08054)
*Moon Ye-Bin,Roy Miles,Tae-Hyun Oh,Ismail Elezi,Jiankang Deng*

Main category: cs.CV

TL;DR: 本文提出了RetouchLLM，一个无需训练数据、可解释的高分辨率图像润色系统，能够实现透明、可控的多步图像调整，并支持自然语言交互。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法对大规模配对数据依赖较强，且操作过程像黑盒一样不可解释，难以适应用户或图片个性化的润色需求。作者希望开发一种无需训练数据、过程透明且可解释的润色方法。

Method: 提出了RetouchLLM框架，结合视觉评判模块（对比输入与参考图像）和代码生成器（生成可执行代码），实现类似人类多步润色的递进调整，直接作用于高分辨率图片，并支持通过自然语言让用户交互和控制参数。

Result: 实验结果表明，RetouchLLM能很好泛化到多种不同的图像润色风格，并通过自然语言与用户交互，实现个性化、可解释的调整流程。

Conclusion: RetouchLLM无需训练数据，且过程可解释，能够在不同风格、用户个性化需求下，对高分辨率图片进行透明、可控的润色，为图像处理与AI交互带来创新应用。

Abstract: Image retouching not only enhances visual quality but also serves as a means
of expressing personal preferences and emotions. However, existing
learning-based approaches require large-scale paired data and operate as black
boxes, making the retouching process opaque and limiting their adaptability to
handle diverse, user- or image-specific adjustments. In this work, we propose
RetouchLLM, a training-free white-box image retouching system, which requires
no training data and performs interpretable, code-based retouching directly on
high-resolution images. Our framework progressively enhances the image in a
manner similar to how humans perform multi-step retouching, allowing
exploration of diverse adjustment paths. It comprises of two main modules: a
visual critic that identifies differences between the input and reference
images, and a code generator that produces executable codes. Experiments
demonstrate that our approach generalizes well across diverse retouching
styles, while natural language-based user interaction enables interpretable and
controllable adjustments tailored to user intent.

</details>


### [57] [A class-driven hierarchical ResNet for classification of multispectral remote sensing images](https://arxiv.org/abs/2510.08060)
*Giulio Weikmann,Gianmarco Perantoni,Lorenzo Bruzzone*

Main category: cs.CV

TL;DR: 提出了一种用多时相层级残差神经网络(ResNet)对多光谱图像时间序列进行多层语义类别分类的方法。通过引入层级惩罚和多枝分结构，提升了不同语义层级下的分类能力，尤其对小类别识别更佳。


<details>
  <summary>Details</summary>
Motivation: 多光谱图像的时间序列分类在遥感等领域具有重要意义，但现有方法对于语义层级细分类别及小样本类别分类表现不佳，且难以根据新任务或类扩展模型。作者希望通过引入层级结构和惩罚机制，提高模型对类别层次性的理解和泛化能力，同时支持小样本和新类扩展。

Method: 设计了一种层级结构的残差网络架构，对ResNet进行改进，引入多分支以适配不同语义层级的分类需求。利用层级标签训练网络，通过层级惩罚约束，避免类别不合理跳转。此外，采用分阶段训练机制，使浅层学习泛类别（宏类别）、深层学习具体类别（微类别）。网络具备模块化，便于后续微调和新任务扩展。

Result: 在亚马逊森林两块区域、12个月的Sentinel 2多时相数据上进行实验，结果表明该网络在各层级都有良好泛化能力，尤其对细粒度小类别分类表现优越，超越了基线方法。

Conclusion: 所提多时相层级ResNet能有效提升多光谱遥感图像时序分类的层级与细粒度表现；具备可扩展性和迁移能力，对小样本和新任务也表现出良好的适应性及实际应用前景。

Abstract: This work presents a multitemporal class-driven hierarchical Residual Neural
Network (ResNet) designed for modelling the classification of Time Series (TS)
of multispectral images at different semantical class levels. The architecture
consists of a modification of the ResNet where we introduce additional branches
to perform the classification at the different hierarchy levels and leverage on
hierarchy-penalty maps to discourage incoherent hierarchical transitions within
the classification. In this way, we improve the discrimination capabilities of
classes at different levels of semantic details and train a modular
architecture that can be used as a backbone network for introducing new
specific classes and additional tasks considering limited training samples
available. We exploit the class-hierarchy labels to train efficiently the
different layers of the architecture, allowing the first layers to train faster
on the first levels of the hierarchy modeling general classes (i.e., the
macro-classes) and the intermediate classes, while using the last ones to
discriminate more specific classes (i.e., the micro-classes). In this way, the
targets are constrained in following the hierarchy defined, improving the
classification of classes at the most detailed level. The proposed modular
network has intrinsic adaptation capability that can be obtained through fine
tuning. The experimental results, obtained on two tiles of the Amazonian Forest
on 12 monthly composites of Sentinel 2 images acquired during 2019, demonstrate
the effectiveness of the hierarchical approach in both generalizing over
different hierarchical levels and learning discriminant features for an
accurate classification at the micro-class level on a new target area, with a
better representation of the minoritarian classes.

</details>


### [58] [Towards Real-World Deepfake Detection: A Diverse In-the-wild Dataset of Forgery Faces](https://arxiv.org/abs/2510.08067)
*Junyu Shi,Minghui Li,Junguo Zuo,Zhifei Yu,Yipeng Lin,Shengshan Hu,Ziqi Zhou,Yechao Zhang,Wei Wan,Yinzhe Xu,Leo Yu Zhang*

Main category: cs.CV

TL;DR: 该论文提出了RedFace数据集，针对现有Deepfake检测数据集在多样性和真实性上的不足，专为更贴近真实场景的Deepfake检测构建了一个包含6万余张伪造人脸图片、1000余段视频的测试集。


<details>
  <summary>Details</summary>
Motivation: 目前学术界用于Deepfake检测的数据集和评测标准，无法很好覆盖真实社交网络中日益严重的Deepfake威胁，存在数据单一、伪造手段有限等不足，导致检测方法缺乏现实适用性。

Method: RedFace数据集通过9个主流商用Deepfake在线平台采集，利用定制算法生成覆盖多种伪造手法的样本，用以模拟真实黑盒环境。另外，还包括跨域、域内及社交网络传播仿真等实验评价检测算法的实际表现。

Result: 基于RedFace数据集的实验显示，现有大多数Deepfake检测方法在真实世界应用场景下的实际效果有限，难以应对多样化和不断进化的伪造技术。

Conclusion: RedFace作为现实场景导向的Deepfake人脸数据集，能更有效反映检测方法在真实世界中的表现，对推动Deepfake检测研究具有重要价值。

Abstract: Deepfakes, leveraging advanced AIGC (Artificial Intelligence-Generated
Content) techniques, create hyper-realistic synthetic images and videos of
human faces, posing a significant threat to the authenticity of social media.
While this real-world threat is increasingly prevalent, existing academic
evaluations and benchmarks for detecting deepfake forgery often fall short to
achieve effective application for their lack of specificity, limited deepfake
diversity, restricted manipulation techniques.To address these limitations, we
introduce RedFace (Real-world-oriented Deepfake Face), a specialized facial
deepfake dataset, comprising over 60,000 forged images and 1,000 manipulated
videos derived from authentic facial features, to bridge the gap between
academic evaluations and real-world necessity. Unlike prior benchmarks, which
typically rely on academic methods to generate deepfakes, RedFace utilizes 9
commercial online platforms to integrate the latest deepfake technologies found
"in the wild", effectively simulating real-world black-box scenarios.Moreover,
RedFace's deepfakes are synthesized using bespoke algorithms, allowing it to
capture diverse and evolving methods used by real-world deepfake creators.
Extensive experimental results on RedFace (including cross-domain,
intra-domain, and real-world social network dissemination simulations) verify
the limited practicality of existing deepfake detection schemes against
real-world applications. We further perform a detailed analysis of the RedFace
dataset, elucidating the reason of its impact on detection performance compared
to conventional datasets. Our dataset is available at:
https://github.com/kikyou-220/RedFace.

</details>


### [59] [Physics-Driven Spatiotemporal Modeling for AI-Generated Video Detection](https://arxiv.org/abs/2510.08073)
*Shuhai Zhang,ZiHao Lian,Jiahao Yang,Daiyuan Li,Guoxuan Pang,Feng Liu,Bo Han,Shutao Li,Mingkui Tan*

Main category: cs.CV

TL;DR: 本论文提出了一种基于物理流守恒原理的新型AI生成视频检测方法NSG-VD，通过归一化时空梯度(NSG)特征，有效区分真实与生成视频，并显著提升检测准确率。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成视频(如Sora)的逼真度接近完美，亟需高效、可靠的检测方法，以防视频伪造带来的潜在威胁。目前检测难点在于复杂的时空动态建模和物理规律细微违背的识别。

Method: 作者基于概率流守恒原理，提出归一化时空梯度(NSG)统计量，结合预训练扩散模型进行空间梯度近似和运动感知的时间建模，并在无需复杂运动分解下保持物理约束。随后提出NSG-VD方法，通过最大均值差异(MMD)计算测试视频与真实视频的NSG特征距离，实现检测。同时，理论推导了生成视频与真实视频之间NSG特征距离的上界。

Result: NSG-VD在实验中表现优异，召回率提升16%，F1得分提升10.75%，全面超越其他同类检测方法。

Conclusion: NSG-VD结合了物理约束和时空统计特征，能够更有效区分AI生成与真实视频，为视频伪造检测提供强有力的新工具。实验和理论分析均证实了其可靠性和先进性。

Abstract: AI-generated videos have achieved near-perfect visual realism (e.g., Sora),
urgently necessitating reliable detection mechanisms. However, detecting such
videos faces significant challenges in modeling high-dimensional spatiotemporal
dynamics and identifying subtle anomalies that violate physical laws. In this
paper, we propose a physics-driven AI-generated video detection paradigm based
on probability flow conservation principles. Specifically, we propose a
statistic called Normalized Spatiotemporal Gradient (NSG), which quantifies the
ratio of spatial probability gradients to temporal density changes, explicitly
capturing deviations from natural video dynamics. Leveraging pre-trained
diffusion models, we develop an NSG estimator through spatial gradients
approximation and motion-aware temporal modeling without complex motion
decomposition while preserving physical constraints. Building on this, we
propose an NSG-based video detection method (NSG-VD) that computes the Maximum
Mean Discrepancy (MMD) between NSG features of the test and real videos as a
detection metric. Last, we derive an upper bound of NSG feature distances
between real and generated videos, proving that generated videos exhibit
amplified discrepancies due to distributional shifts. Extensive experiments
confirm that NSG-VD outperforms state-of-the-art baselines by 16.00% in Recall
and 10.75% in F1-Score, validating the superior performance of NSG-VD. The
source code is available at https://github.com/ZSHsh98/NSG-VD.

</details>


### [60] [DarkHash: A Data-Free Backdoor Attack Against Deep Hashing](https://arxiv.org/abs/2510.08094)
*Ziqi Zhou,Menghao Deng,Yufei Song,Hangtao Zhang,Wei Wan,Shengshan Hu,Minghui Li,Leo Yu Zhang,Dezhong Yao*

Main category: cs.CV

TL;DR: 该论文提出了一种无需访问训练数据的数据自由深度哈希后门攻击方法（DarkHash），能在保持检索准确率的同时植入后门，实验结果优于现有方法且能逃避主流防御。


<details>
  <summary>Details</summary>
Motivation: 现有深度哈希后门攻击都依赖于训练数据，但现实中，因隐私等原因获取训练数据往往不可行。因此，如何在无法获得训练数据时实现有效后门攻击，成为重要且有挑战性的问题。

Method: 作者提出了DarkHash方法：通过一种新颖的影子后门攻击框架，结合双语义引导，仅对受害模型特定层进行微调，并采用替代数据集。设计拓扑对齐损失，使中毒样本及其邻居向目标样本对齐，从而增强攻击能力和模型性能。

Result: 在四个数据集、五种模型和两种哈希方法上的实验，DarkHash在后门攻击效果上明显优于已有方法，且能够抵抗主流后门防御技术。

Conclusion: DarkHash实现了无数据集访问条件下的高效深度哈希后门攻击，并具有很强的实用性和隐蔽性。

Abstract: Benefiting from its superior feature learning capabilities and efficiency,
deep hashing has achieved remarkable success in large-scale image retrieval.
Recent studies have demonstrated the vulnerability of deep hashing models to
backdoor attacks. Although these studies have shown promising attack results,
they rely on access to the training dataset to implant the backdoor. In the
real world, obtaining such data (e.g., identity information) is often
prohibited due to privacy protection and intellectual property concerns.
Embedding backdoors into deep hashing models without access to the training
data, while maintaining retrieval accuracy for the original task, presents a
novel and challenging problem. In this paper, we propose DarkHash, the first
data-free backdoor attack against deep hashing. Specifically, we design a novel
shadow backdoor attack framework with dual-semantic guidance. It embeds
backdoor functionality and maintains original retrieval accuracy by fine-tuning
only specific layers of the victim model using a surrogate dataset. We consider
leveraging the relationship between individual samples and their neighbors to
enhance backdoor attacks during training. By designing a topological alignment
loss, we optimize both individual and neighboring poisoned samples toward the
target sample, further enhancing the attack capability. Experimental results on
four image datasets, five model architectures, and two hashing methods
demonstrate the high effectiveness of DarkHash, outperforming existing
state-of-the-art backdoor attack methods. Defense experiments show that
DarkHash can withstand existing mainstream backdoor defense methods.

</details>


### [61] [Efficient Label Refinement for Face Parsing Under Extreme Poses Using 3D Gaussian Splatting](https://arxiv.org/abs/2510.08096)
*Ankit Gahlawat,Anirban Mukherjee,Dinesh Babu Jayagopi*

Main category: cs.CV

TL;DR: 本文提出了一种结合3D Gaussian Splatting（3DGS）的标签优化流程，用于提升极端视角下人脸分割的准确性，无需大量标注数据。


<details>
  <summary>Details</summary>
Motivation: 极端视角下的人脸分割由于缺乏标注数据而准确率低，而手工标注成本高，规模化操作不可行。因此需要更高效、可扩展的训练数据生成手段。

Method: 方法利用3D Gaussian Splatting，分别对RGB图像和初始分割图进行3D建模，通过共享几何结构实现多视角一致性，进而自动生成多姿态带精细分割的训练数据，仅需极少的后处理。

Result: 在人脸分割模型微调后，极端姿态下的分割准确率大幅提升，在常规视角下性能依然优异。多项实验（含人工评测）显示该法优于现有主流方法，无需真值3D标注，仅需少量初始图像。

Conclusion: 方法为现实环境下人脸分割的泛化与鲁棒性提升提供了一种高效、可扩展的解决方案。

Abstract: Accurate face parsing under extreme viewing angles remains a significant
challenge due to limited labeled data in such poses. Manual annotation is
costly and often impractical at scale. We propose a novel label refinement
pipeline that leverages 3D Gaussian Splatting (3DGS) to generate accurate
segmentation masks from noisy multiview predictions. By jointly fitting two
3DGS models, one to RGB images and one to their initial segmentation maps, our
method enforces multiview consistency through shared geometry, enabling the
synthesis of pose-diverse training data with only minimal post-processing.
Fine-tuning a face parsing model on this refined dataset significantly improves
accuracy on challenging head poses, while maintaining strong performance on
standard views. Extensive experiments, including human evaluations, demonstrate
that our approach achieves superior results compared to state-of-the-art
methods, despite requiring no ground-truth 3D annotations and using only a
small set of initial images. Our method offers a scalable and effective
solution for improving face parsing robustness in real-world settings.

</details>


### [62] [Random Window Augmentations for Deep Learning Robustness in CT and Liver Tumor Segmentation](https://arxiv.org/abs/2510.08116)
*Eirik A. Østmo,Kristoffer K. Wickstrøm,Keyur Radiya,Michael C. Kampffmeyer,Karl Øyvind Mikalsen,Robert Jenssen*

Main category: cs.CV

TL;DR: 本文提出了一种针对CT图像的特定数据增强方法“Random windowing”，提高了深度学习分割模型在对比增强CT影像中的泛化和鲁棒性，特别是在肝脏肿瘤分割任务中取得领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习分割模型在医学影像领域由于数据有限，依赖数据增强以提升泛化能力。但许多增强方法源自自然图像领域，未考虑CT影像的Hounsfield Unit（HU）强度的物理含义，盲目使用可能带来伪影和性能下降。

Method: 作者挑战主流天然图像增强在CT中的合理性，提出结合CT HU分布特性的“Random windowing”数据增强技术。该方法通过扰动窗宽窗位参数制造不同对比度，增强模型对增强剂差异和低对比度数据的鲁棒性。

Result: 在多个数据集上进行了消融和性能分析，证明“Random windowing”方法在对比增强CT的肝脏肿瘤分割任务上优于现有的增强方案，能有效提升模型在困难影像下的表现和泛化能力。

Conclusion: 特定于医学影像（CT HU强度特征）的数据增强远优于照搬自然图像增强方法，可显著提升模型对现实临床挑战的适应能力。

Abstract: Contrast-enhanced Computed Tomography (CT) is important for diagnosis and
treatment planning for various medical conditions. Deep learning (DL) based
segmentation models may enable automated medical image analysis for detecting
and delineating tumors in CT images, thereby reducing clinicians' workload.
Achieving generalization capabilities in limited data domains, such as
radiology, requires modern DL models to be trained with image augmentation.
However, naively applying augmentation methods developed for natural images to
CT scans often disregards the nature of the CT modality, where the intensities
measure Hounsfield Units (HU) and have important physical meaning. This paper
challenges the use of such intensity augmentations for CT imaging and shows
that they may lead to artifacts and poor generalization. To mitigate this, we
propose a CT-specific augmentation technique, called Random windowing, that
exploits the available HU distribution of intensities in CT images. Random
windowing encourages robustness to contrast-enhancement and significantly
increases model performance on challenging images with poor contrast or timing.
We perform ablations and analysis of our method on multiple datasets, and
compare to, and outperform, state-of-the-art alternatives, while focusing on
the challenge of liver tumor segmentation.

</details>


### [63] [Real-Time Motion-Controllable Autoregressive Video Diffusion](https://arxiv.org/abs/2510.08131)
*Kesen Zhao,Jiaxin Shi,Beier Zhu,Junbao Zhou,Xiaolong Shen,Yuan Zhou,Qianru Sun,Hanwang Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为AR-Drag的实时、运动可控视频生成模型，结合了自回归扩散与强化学习，兼具高画质、低延迟和精确运动控制。


<details>
  <summary>Details</summary>
Motivation: 现有的双向扩散模型生成速度慢，不适合实时应用，而自回归扩散模型运动控制能力有限且质量下降明显。因此亟需一种高质量且能高效实现复杂运动控制的视频生成方法。

Method: 作者首先微调基础的图像到视频生成模型以支持运动控制，然后引入强化学习，使用基于轨迹奖励机制进一步优化模型。采用Self-Rollout机制保证马尔可夫性质，并通过噪声选择性注入提升训练效率。

Result: AR-Drag实现了高视觉逼真度和精确的运动匹配，生成延迟明显低于同类最先进模型，模型规模仅1.3B参数。

Conclusion: AR-Drag有效提升了实时运动可控视频生成的质量与效率，有望推动相关实际应用的发展。

Abstract: Real-time motion-controllable video generation remains challenging due to the
inherent latency of bidirectional diffusion models and the lack of effective
autoregressive (AR) approaches. Existing AR video diffusion models are limited
to simple control signals or text-to-video generation, and often suffer from
quality degradation and motion artifacts in few-step generation. To address
these challenges, we propose AR-Drag, the first RL-enhanced few-step AR video
diffusion model for real-time image-to-video generation with diverse motion
control. We first fine-tune a base I2V model to support basic motion control,
then further improve it via reinforcement learning with a trajectory-based
reward model. Our design preserves the Markov property through a Self-Rollout
mechanism and accelerates training by selectively introducing stochasticity in
denoising steps. Extensive experiments demonstrate that AR-Drag achieves high
visual fidelity and precise motion alignment, significantly reducing latency
compared with state-of-the-art motion-controllable VDMs, while using only 1.3B
parameters. Additional visualizations can be found on our project page:
https://kesenzhao.github.io/AR-Drag.github.io/.

</details>


### [64] [Improving Temporal Understanding Logic Consistency in Video-Language Models via Attention Enhancement](https://arxiv.org/abs/2510.08138)
*Chengzhi Li,Heyan Huang,Ping Jian,Zhen Yang,Yaning Tian*

Main category: cs.CV

TL;DR: 文章指出视频-大语言模型（Video-LLMs）容易出现时序自相矛盾的问题，并提出了一种增强注意力机制的方法（TCAS），显著提高了视频-LLMs的时序一致性和推理能力。


<details>
  <summary>Details</summary>
Motivation: 视频-大语言模型在回答时间相关的问题时，容易因缺乏时序一致性而产生自相矛盾的回答，影响了模型的实用性和可靠性。了解和解决这一问题对于模型在实际任务中的应用至关重要。

Method: 作者首先采用可解释性驱动的方法，分析、统计并干预导致模型时序自相矛盾的潜在因素。进而，提出了“Temporally Conditioned Attention Sharpening（TCAS）”机制，通过构建基于注意力差异的增强目标，提升模型对不同时刻视频token的区分能力，从而改善时序理解和推理的一致性。

Result: 实验证明，TCAS能显著提升视频-大语言模型的时序逻辑一致性。解释性分析进一步表明该方法提高了注意力头的时间区分能力。此外，在通用视频时序定位任务中，模型表现也同步提升。

Conclusion: 视频-大语言模型的时序逻辑一致性是其时序理解的关键瓶颈，通过提升这一能力，模型可以在视频理解任务中达到更好的效果，所提方法推动了该领域的重要进步。

Abstract: Large language models (LLMs) often generate self-contradictory outputs, which
severely impacts their reliability and hinders their adoption in practical
applications. In video-language models (Video-LLMs), this phenomenon recently
draws the attention of researchers. Specifically, these models fail to provide
logically consistent responses to rephrased questions based on their grounding
outputs. However, the underlying causes of this phenomenon remain
underexplored. In this work, we adopt an interpretability-driven approach to
analyze, statistically summarize, and intervention the potential factors of the
phenomenon. We find that one of the primary reasons for the inconsistency in
responses lies in the inability of cross-modal attention heads to effectively
distinguish video tokens across different timestamps. To address this, we
propose an attention enhancement method called Temporally Conditioned Attention
Sharpening (TCAS), which constructs an enhancement objective based on attention
distinctions to enhance the model's temporal resolution capability, thereby
improving its temporal understanding logic consistency. Experimental results
demonstrate that our method significantly enhances the temporal logic
consistency of Video-LLMs. Further interpretability analyses reveal that our
method indeed improves the temporal discriminability of attention heads,
validating our conclusions. Additionally, our method achieves performance
improvements in general video temporal grounding tasks, highlighting that
temporal logic consistency is a bottleneck in temporal understanding. By
enhancing consistency, our method drives significant progress in video temporal
understanding.

</details>


### [65] [UniMMVSR: A Unified Multi-Modal Framework for Cascaded Video Super-Resolution](https://arxiv.org/abs/2510.08143)
*Shian Du,Menghan Xia,Chang Liu,Quande Liu,Xintao Wang,Pengfei Wan,Xiangyang Ji*

Main category: cs.CV

TL;DR: 本文提出了统一的多模态生成视频超分辨率框架（UniMMVSR），支持文本、图像和视频等多种条件，显著超越现有方法，实现了4K多模态引导视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有的级联视频超分辨率方法多仅应用于文本到视频，无法充分利用多模态条件（如图片、视频），限制了生成视频的真实性和多样性。作者希望解决该领域仅限单一模态（文本）的问题，提升模型对于高分辨率视频的多模态条件适应能力。

Method: 设计了统一多模态条件生成视频超分辨率框架UniMMVSR，支持文本、图像、视频等混合条件注入。探索了多种条件注入策略、训练方案和数据混合技术，并针对不同条件与目标视频相关性的差异，定制了数据构建和条件利用方法。框架基于潜空间视频扩散模型实现。

Result: 实验显示，UniMMVSR在视频细节和多模态条件一致性方面显著优于现有方法。同时，验证了UniMMVSR可与基础模型结合，实现业界首个多模态引导的4K视频生成。

Conclusion: UniMMVSR突破了现有方法在条件单一和分辨率局限上的瓶颈，实现了多模态条件下高分辨率视频生成，在多模态视频生成领域具有引领意义。

Abstract: Cascaded video super-resolution has emerged as a promising technique for
decoupling the computational burden associated with generating high-resolution
videos using large foundation models. Existing studies, however, are largely
confined to text-to-video tasks and fail to leverage additional generative
conditions beyond text, which are crucial for ensuring fidelity in multi-modal
video generation. We address this limitation by presenting UniMMVSR, the first
unified generative video super-resolution framework to incorporate hybrid-modal
conditions, including text, images, and videos. We conduct a comprehensive
exploration of condition injection strategies, training schemes, and data
mixture techniques within a latent video diffusion model. A key challenge was
designing distinct data construction and condition utilization methods to
enable the model to precisely utilize all condition types, given their varied
correlations with the target video. Our experiments demonstrate that UniMMVSR
significantly outperforms existing methods, producing videos with superior
detail and a higher degree of conformity to multi-modal conditions. We also
validate the feasibility of combining UniMMVSR with a base model to achieve
multi-modal guided generation of 4K video, a feat previously unattainable with
existing techniques.

</details>


### [66] [Beyond Textual CoT: Interleaved Text-Image Chains with Deep Confidence Reasoning for Image Editing](https://arxiv.org/abs/2510.08157)
*Zhentao Zou,Zhengrong Yue,Kunpeng Du,Binlei Bao,Hanting Li,Haizhen Xie,Guozheng Xu,Yue Zhou,Yali Wang,Jie Hu,Xue Jiang,Xinghao Chen*

Main category: cs.CV

TL;DR: 该论文提出了一种新的多模态推理编辑（MURE）框架，实现了基于文本和视觉信息链式推理的高保真图像编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的自然语言图像编辑方法难以应对复杂对象交互和精细空间关系，主要因为缺乏显式推理过程和细粒度视觉线索。纯文本或坐标增强的链式推理（CoT）难以描述复杂视觉布局，且对像素级编辑指导不足。

Method: 作者提出了MURE框架，将编辑过程从纯文本推理转变为交替的文本与图像链式推理，具体通过多步链式推理，每步生成文本描述与对应视觉线索（如掩模或新内容）。为减少大模型幻觉现象，进一步引入多模态深度置信（MMDC）推理范式，通过奖励模型置信度修剪低质量分支，保持高质量推理路径。此外，作者还发布了CoT-Edit-14K数据集。

Result: 大量实验证明，所提方法在三个图像编辑基准任务上实现了显著提升，编辑精度和保真度优于现有方法。

Conclusion: MURE多模态编辑方式有效分解复杂编辑任务，实现更高精度的图像编辑。本文还为多模态链式推理编辑建立了新范式，并丰富了相关数据资源。

Abstract: Image editing with natural language has gained significant popularity, yet
existing methods struggle with intricate object intersections and fine-grained
spatial relationships due to the lack of an explicit reasoning process. While
Chain-of-Thought (CoT) has been explored to enhance reasoning, purely textual
CoT or CoT augmented with coordinate information is fundamentally limited in
its ability to represent intricate visual layouts and lacks the necessary
visual cues to guide the generation of fine-grained, pixel-level details. To
address these challenges, we propose Multimodal Reasoning Edit (MURE), a novel
framework that shifts the visual editing process from purely text-based
reasoning to a series of interleaved textual and visual rationales. Our
framework performs image editing using a natively multimodal, interleaved
text-image CoT. This approach generates a step-by-step chain of reasoning where
a textual description is followed by a corresponding visual cue, such as a
positional mask that defined intended edited regions or a representation of new
content. Furthermore, to mitigate the hallucination phenomenon of large
language models, we introduce Multimodal Deep Confidence (MMDC) reasoning
paradigm. This paradigm explores a tree of visual reasoning paths at each step.
By pruning low-quality branches using a deep confidence score from a reward
model, it ensures the model consistently follows a high-quality trajectory
towards the final edited result. The proposed method decomposes complex editing
tasks into interdependent sub-tasks, achieving greater precision at each stage
and yielding high-fidelity edited results. We define the formulation for
interleaved text-image chains and release the first CoT-Edit-14K dataset,
comprising 14K high-quality editing examples. Extensive experiments show that
our method yields significant improvements across three image editing
benchmarks.

</details>


### [67] [Robust Canonicalization through Bootstrapped Data Re-Alignment](https://arxiv.org/abs/2510.08178)
*Johann Schmidt,Sebastian Stober*

Main category: cs.CV

TL;DR: 本文提出了一种新的自举算法，能够有效对齐细粒度视觉分类任务中的训练样本，从而提升模型对几何偏差和噪声的鲁棒性，实验结果优于现有同类方法。


<details>
  <summary>Details</summary>
Motivation: 在细粒度视觉分类任务中，如昆虫和鸟类识别，模型需要对细微视觉特征敏感，同时对空间变换（如对象不同的朝向、比例）具备鲁棒性。现有方法如大量数据增强或等变结构存在对模型能力要求高、灵活性受限及计算成本高的问题。而以往通过先验进行“标准化对齐”又依赖于理想的已对齐数据，实际数据常不满足此假设，导致方法脆弱。

Method: 作者提出了一种自举算法，能够在训练过程中通过迭代方式逐步重新对齐训练样本，不断降低样本内的偏差，实现恢复对齐假设。方法理论上适用于任意紧致群（即各种空间变化），设有收敛保证。

Result: 在四个细粒度视觉分类数据集上进行了实验。结果显示，该自举算法在准确性上优于等变结构和标准化基线方法，且性能与数据增强手段相当。

Conclusion: 该方法为处理数据对齐偏差提供了新手段，有效提升了细粒度视觉分类的性能，理论和实验均证明了其实用性和优越性。

Abstract: Fine-grained visual classification (FGVC) tasks, such as insect and bird
identification, demand sensitivity to subtle visual cues while remaining robust
to spatial transformations. A key challenge is handling geometric biases and
noise, such as different orientations and scales of objects. Existing remedies
rely on heavy data augmentation, which demands powerful models, or on
equivariant architectures, which constrain expressivity and add cost.
Canonicalization offers an alternative by shielding such biases from the
downstream model. In practice, such functions are often obtained using
canonicalization priors, which assume aligned training data. Unfortunately,
real-world datasets never fulfill this assumption, causing the obtained
canonicalizer to be brittle. We propose a bootstrapping algorithm that
iteratively re-aligns training samples by progressively reducing variance and
recovering the alignment assumption. We establish convergence guarantees under
mild conditions for arbitrary compact groups, and show on four FGVC benchmarks
that our method consistently outperforms equivariant, and canonicalization
baselines while performing on par with augmentation.

</details>


### [68] [InstructUDrag: Joint Text Instructions and Object Dragging for Interactive Image Editing](https://arxiv.org/abs/2510.08181)
*Haoran Yu,Yi Shi*

Main category: cs.CV

TL;DR: 提出了一种结合文本指令与对象拖拽的新方法，可实现精确且灵活的图像编辑。


<details>
  <summary>Details</summary>
Motivation: 现有文本或对象拖拽方法各有限制：文本难以精确定位，对象拖拽只能移动位置，缺乏灵活性和丰富语义。

Method: 提出InstructUDrag框架，将对象拖拽视为图像重建过程，设计了移动重建分支（利用基于能量的梯度引导和cross-attention优化实现精准移动）和文本驱动编辑分支（共享梯度，实现属性微调和一致性），并用DDPM反演和先验噪声注入来保留结构信息。

Result: 大量实验表明该方法能实现高保真且灵活的图像编辑，既能精准移动对象，又可做语义属性调整。

Conclusion: InstructUDrag实现了对象精准拖拽和可控语义编辑，相较现有方法更加高效灵活，为文本到图像的编辑开辟了新方向。

Abstract: Text-to-image diffusion models have shown great potential for image editing,
with techniques such as text-based and object-dragging methods emerging as key
approaches. However, each of these methods has inherent limitations: text-based
methods struggle with precise object positioning, while object dragging methods
are confined to static relocation. To address these issues, we propose
InstructUDrag, a diffusion-based framework that combines text instructions with
object dragging, enabling simultaneous object dragging and text-based image
editing. Our framework treats object dragging as an image reconstruction
process, divided into two synergistic branches. The moving-reconstruction
branch utilizes energy-based gradient guidance to move objects accurately,
refining cross-attention maps to enhance relocation precision. The text-driven
editing branch shares gradient signals with the reconstruction branch, ensuring
consistent transformations and allowing fine-grained control over object
attributes. We also employ DDPM inversion and inject prior information into
noise maps to preserve the structure of moved objects. Extensive experiments
demonstrate that InstructUDrag facilitates flexible, high-fidelity image
editing, offering both precision in object relocation and semantic control over
image content.

</details>


### [69] [Fine-grained text-driven dual-human motion generation via dynamic hierarchical interaction](https://arxiv.org/abs/2510.08260)
*Mu Li,Yin Wang,Zhiying Leng,Jiapeng Liu,Frederick W. B. Li,Xiaohui Liang*

Main category: cs.CV

TL;DR: 本文提出了一种名为FineDual的三阶段双人动作生成方法，能更细致建模动态层次的人体交互，实验效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有双人动作生成方法忽略了动作随距离的动态变化及由个体到整体的层次结构，不能有效表现真实的人体交互。本文旨在解决这一问题。

Method: FineDual方法分为三个阶段：1）自学习阶段，利用大语言模型将总体文本分解为个体描述，对齐文本与个体动作特征；2）自适应调整阶段，使用距离预测器和图网络建模个体间动态交互；3）教师引导精化阶段，通过总体文本特征引导高质量整体动作生成。

Result: 在双人动作数据集上的定量和定性实验显示，FineDual方法在建模动态层次交互及生成高质量动作方面均优于现有方法。

Conclusion: FineDual实验证明，可以有效并精细地模拟动态层次的人体互动，为双人动作生成带来显著提升。

Abstract: Human interaction is inherently dynamic and hierarchical, where the dynamic
refers to the motion changes with distance, and the hierarchy is from
individual to inter-individual and ultimately to overall motion. Exploiting
these properties is vital for dual-human motion generation, while existing
methods almost model human interaction temporally invariantly, ignoring
distance and hierarchy. To address it, we propose a fine-grained dual-human
motion generation method, namely FineDual, a tri-stage method to model the
dynamic hierarchical interaction from individual to inter-individual. The first
stage, Self-Learning Stage, divides the dual-human overall text into individual
texts through a Large Language Model, aligning text features and motion
features at the individual level. The second stage, Adaptive Adjustment Stage,
predicts interaction distance by an interaction distance predictor, modeling
human interactions dynamically at the inter-individual level by an
interaction-aware graph network. The last stage, Teacher-Guided Refinement
Stage, utilizes overall text features as guidance to refine motion features at
the overall level, generating fine-grained and high-quality dual-human motion.
Extensive quantitative and qualitative evaluations on dual-human motion
datasets demonstrate that our proposed FineDual outperforms existing
approaches, effectively modeling dynamic hierarchical human interaction.

</details>


### [70] [Adaptive Gradient Calibration for Single-Positive Multi-Label Learning in Remote Sensing Image Scene Classification](https://arxiv.org/abs/2510.08269)
*Chenying Liu,Gianmarco Perantoni,Lorenzo Bruzzone,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: 本文针对遥感图像的单阳性多标签学习（SPML）问题，提出了一种自适应梯度校准（AdaGC）框架，结合了Mixup与双EMA模块，通过训练动态自适应调用GC模块，有效缓解了标签噪声带来的过拟合，并在多个数据集下取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 遥感图像多标签分类比单标签分类能带来更全面的语义理解，但多标签标注成本高、难度大；SPML作为降低标注难度的方案，仅需每张图像有一个正标签，但带来了监督歧义与训练难题。针对遥感领域缺乏有效SPML方法，亟需设计鲁棒且高效的解决方案。

Method: 作者提出自适应梯度校准（AdaGC）SPML框架。该方法基于梯度校准机制，结合Mixup训练策略和双指数滑动平均（EMA）模块生成鲁棒伪标签，并通过设计简单且有理论依据的指标，在初始训练热身阶段后自适应激活GC模块，从而动态应对标签噪声。

Result: 在两个遥感领域基准数据集与两种不同标签噪声环境下，AdaGC方法取得了比现有方法更优的SOTA性能，且在多种实验设置下表现出很强的稳健性。

Conclusion: AdaGC作为一种普适的SPML解法，不仅能有效缓解标签噪声影响，还能实现遥感图像多标签分类的高效与高性能，为低标注成本的遥感多标签学习提供了新方案。

Abstract: Multi-label classification (MLC) offers a more comprehensive semantic
understanding of Remote Sensing (RS) imagery compared to traditional
single-label classification (SLC). However, obtaining complete annotations for
MLC is particularly challenging due to the complexity and high cost of the
labeling process. As a practical alternative, single-positive multi-label
learning (SPML) has emerged, where each image is annotated with only one
relevant label, and the model is expected to recover the full set of labels.
While scalable, SPML introduces significant supervision ambiguity, demanding
specialized solutions for model training. Although various SPML methods have
been proposed in the computer vision domain, research in the RS context remains
limited. To bridge this gap, we propose Adaptive Gradient Calibration (AdaGC),
a novel and generalizable SPML framework tailored to RS imagery. AdaGC adopts a
gradient calibration (GC) mechanism combined with Mixup and a dual exponential
moving average (EMA) module for robust pseudo-label generation. To maximize
AdaGC's effectiveness, we introduce a simple yet theoretically grounded
indicator to adaptively trigger GC after an initial warm-up stage based on
training dynamics, thereby guaranteeing the effectiveness of GC in mitigating
overfitting to label noise. Extensive experiments on two benchmark RS datasets
under two distinct label noise types demonstrate that AdaGC achieves
state-of-the-art (SOTA) performance while maintaining strong robustness across
diverse settings.

</details>


### [71] [One Stone with Two Birds: A Null-Text-Null Frequency-Aware Diffusion Models for Text-Guided Image Inpainting](https://arxiv.org/abs/2510.08273)
*Haipeng Liu,Yang Wang,Meng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新的基于频率分解的文本引导图像修复扩散模型（NTN-Diff），有效平衡未遮挡区保真和语义一致性，且优于主流扩散方法。


<details>
  <summary>Details</summary>
Motivation: 现有文本引导的图像修复方法在保持未遮挡区域内容和实现遮挡区与未遮挡区语义一致性上存在权衡，往往无法兼顾两者。作者发现问题根源于不同频率成分对文本提示的鲁棒性差异，因此提出频率解耦的新方法。

Method: 提出NTN-Diff模型，将修复区域与未遮挡区域的语义一致性分解到不同频率段上处理。整个修复过程中，扩散去噪被划分为早期（高噪声）、晚期（低噪声）两个阶段，实现中低频成分的解耦处理。具体做法为：在去噪过程中通过文本引导对中频成分进行语义对齐，然后用其指导遮挡区的低频成分再加文本指导，保证不同频率下的语义一致并保持未遮挡区内容不变。

Result: 大量实验表明，NTN-Diff在各项主流评测指标下均超越当前主流文本引导扩散模型，实现更优的修复效果。

Conclusion: NTN-Diff通过频率段分解和去噪阶段解耦，有效提升了文本引导图像修复的语义一致性和未遮挡区内容保真性，为领域内提供了新的思路和更高性能的模型。

Abstract: Text-guided image inpainting aims at reconstructing the masked regions as per
text prompts, where the longstanding challenges lie in the preservation for
unmasked regions, while achieving the semantics consistency between unmasked
and inpainted masked regions. Previous arts failed to address both of them,
always with either of them to be remedied. Such facts, as we observed, stem
from the entanglement of the hybrid (e.g., mid-and-low) frequency bands that
encode varied image properties, which exhibit different robustness to text
prompts during the denoising process. In this paper, we propose a
null-text-null frequency-aware diffusion models, dubbed \textbf{NTN-Diff}, for
text-guided image inpainting, by decomposing the semantics consistency across
masked and unmasked regions into the consistencies as per each frequency band,
while preserving the unmasked regions, to circumvent two challenges in a row.
Based on the diffusion process, we further divide the denoising process into
early (high-level noise) and late (low-level noise) stages, where the
mid-and-low frequency bands are disentangled during the denoising process. As
observed, the stable mid-frequency band is progressively denoised to be
semantically aligned during text-guided denoising process, which, meanwhile,
serves as the guidance to the null-text denoising process to denoise
low-frequency band for the masked regions, followed by a subsequent text-guided
denoising process at late stage, to achieve the semantics consistency for
mid-and-low frequency bands across masked and unmasked regions, while preserve
the unmasked regions. Extensive experiments validate the superiority of
NTN-Diff over the state-of-the-art diffusion models to text-guided diffusion
models. Our code can be accessed from https://github.com/htyjers/NTN-Diff.

</details>


### [72] [Learning Neural Exposure Fields for View Synthesis](https://arxiv.org/abs/2510.08279)
*Michael Niemeyer,Fabian Manhardt,Marie-Julie Rakotosaona,Michael Oechsle,Christina Tsalicoglou,Keisuke Tateno,Jonathan T. Barron,Federico Tombari*

Main category: cs.CV

TL;DR: 本文提出了Neural Exposure Fields (NExF)方法，能够在存在曝光变化等复杂情况下实现高质量的一致性三维重建和新视角合成，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的神经场景重建方法虽在标准数据集上表现良好，但面对因曝光变化（室内外混合、窗口等）带来的实际拍摄难题时输出效果大幅下降。因此亟需解决曝光不一致导致的三维重建和视图合成质量下降问题。

Method: 文章提出了Neural Exposure Fields (NExF)新方法，在神经场景重建过程中，对每个三维点学习一个最优曝光值，并通过新的神经条件机制联合优化场景表现与曝光。与以往只在图像或像素层面处理不同，该方法将曝光优化推广到三维空间，有效提升动态范围下的合成质量，无需额外的后处理或多次曝光数据采集。

Result: NExF在复杂真实场景数据上展现出显著优于以往工作的性能，训练速度也更快。在多个基准测试中相较最佳现有方法提升超过55%。

Conclusion: NExF为神经场景重建中的曝光问题提供了创新方案，实现了高动态范围与高一致性的三维重建与新视角合成，具有很强的实际应用价值。

Abstract: Recent advances in neural scene representations have led to unprecedented
quality in 3D reconstruction and view synthesis. Despite achieving high-quality
results for common benchmarks with curated data, outputs often degrade for data
that contain per image variations such as strong exposure changes, present,
e.g., in most scenes with indoor and outdoor areas or rooms with windows. In
this paper, we introduce Neural Exposure Fields (NExF), a novel technique for
robustly reconstructing 3D scenes with high quality and 3D-consistent
appearance from challenging real-world captures. In the core, we propose to
learn a neural field predicting an optimal exposure value per 3D point,
enabling us to optimize exposure along with the neural scene representation.
While capture devices such as cameras select optimal exposure per image/pixel,
we generalize this concept and perform optimization in 3D instead. This enables
accurate view synthesis in high dynamic range scenarios, bypassing the need of
post-processing steps or multi-exposure captures. Our contributions include a
novel neural representation for exposure prediction, a system for joint
optimization of the scene representation and the exposure field via a novel
neural conditioning mechanism, and demonstrated superior performance on
challenging real-world data. We find that our approach trains faster than prior
works and produces state-of-the-art results on several benchmarks improving by
over 55% over best-performing baselines.

</details>


### [73] [LTCA: Long-range Temporal Context Attention for Referring Video Object Segmentation](https://arxiv.org/abs/2510.08305)
*Cilin Yan,Jingyun Wang,Guoliang Kang*

Main category: cs.CV

TL;DR: 本文提出了一种高效的长距离时序上下文注意力机制以提升基于语言表达的视频目标分割效果，在多个数据集上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统的RVOS方法在平衡局部与全局信息、处理长视频时的计算复杂度上存在问题。为此，作者希望设计一种既能高效利用全局上下文又能降低计算量的新机制。

Method: 作者提出了一种名为LTCA的长距离时序上下文注意力机制。该方法包括两方面：1）利用膨胀的窗口注意力堆叠本地注意力层，以平衡局部与全局信息；2）每个查询还可以随机关注全局池的小组关键点以增强全局特征；同时引入全局查询，直接与所有查询进行全局交互，充分编码全局上下文。

Result: 在四个重要的RVOS基准数据集上，方法均取得了最新的SOTA（状态最佳）表现。在MeViS valu和val数据集上分别取得了11.3%和8.3%的提升。

Conclusion: 文中提出的LTCA机制能有效地在保持高效率的同时大幅提升基于语言的视频分割性能，为后续相关研究提供了新思路。

Abstract: Referring Video Segmentation (RVOS) aims to segment objects in videos given
linguistic expressions. The key to solving RVOS is to extract long-range
temporal context information from the interactions of expressions and videos to
depict the dynamic attributes of each object. Previous works either adopt
attention across all the frames or stack dense local attention to achieve a
global view of temporal context. However, they fail to strike a good balance
between locality and globality, and the computation complexity significantly
increases with the increase of video length. In this paper, we propose an
effective long-range temporal context attention (LTCA) mechanism to aggregate
global context information into object features. Specifically, we aggregate the
global context information from two aspects. Firstly, we stack sparse local
attentions to balance the locality and globality. We design a dilated window
attention across frames to aggregate local context information and perform such
attention in a stack of layers to enable a global view. Further, we enable each
query to attend to a small group of keys randomly selected from a global pool
to enhance the globality. Secondly, we design a global query to interact with
all the other queries to directly encode the global context information.
Experiments show our method achieves new state-of-the-art on four referring
video segmentation benchmarks. Notably, our method shows an improvement of
11.3% and 8.3% on the MeViS valu and val datasets respectively.

</details>


### [74] [Unlocking 3D Affordance Segmentation with 2D Semantic Knowledge](https://arxiv.org/abs/2510.08316)
*Yu Huang,Zelin Peng,Changsong Wen,Xiaokang Yang,Wei Shen*

Main category: cs.CV

TL;DR: 该论文提出了一种通过跨模态语义知识转移提升3D物体可供性分割精度的新框架，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有3D可供性分割方法通常仅基于点云特征提取，难以应对3D稀疏、噪声及几何歧义等问题，因此得到的特征缺乏明确且一致的功能性边界。为此，作者希望利用2D视觉大模型丰富的语义知识来指导3D场景的功能性分割。

Method: 作者提出了一种语义驱动的学习范式，将大规模2D视觉模型（VFM）的语义知识迁移到3D领域。包括两个核心方法：1）跨模态亲和力转移（CMAT）预训练——通过2D语义提升对齐3D编码器，同时联合优化重建、亲和力与多样性目标，以获得语义有序的3D表示；2）基于CMAT预训练特征和多模态提示的Cross-modal Affordance Segmentation Transformer（CAST），实现精确、可提示的分割。

Result: 在标准3D可供性分割基准数据集上，大量实验证明该方法在精度上取得了新的最先进结果（SOTA）。

Conclusion: 将2D视觉模型的语义迁移到3D特征学习，有效提升了3D可供性分割的性能，为机器人操作和AR等应用提供了更稳健的功能性识别能力。

Abstract: Affordance segmentation aims to parse 3D objects into functionally distinct
parts, bridging recognition and interaction for applications in robotic
manipulation, embodied AI, and AR. While recent studies leverage visual or
textual prompts to guide this process, they often rely on point cloud encoders
as generic feature extractors, overlooking the intrinsic challenges of 3D data
such as sparsity, noise, and geometric ambiguity. As a result, 3D features
learned in isolation frequently lack clear and semantically consistent
functional boundaries. To address this bottleneck, we propose a
semantic-grounded learning paradigm that transfers rich semantic knowledge from
large-scale 2D Vision Foundation Models (VFMs) into the 3D domain.
Specifically, We introduce Cross-Modal Affinity Transfer (CMAT), a pre-training
strategy that aligns a 3D encoder with lifted 2D semantics and jointly
optimizes reconstruction, affinity, and diversity to yield semantically
organized representations. Building on this backbone, we further design the
Cross-modal Affordance Segmentation Transformer (CAST), which integrates
multi-modal prompts with CMAT-pretrained features to generate precise,
prompt-aware segmentation maps. Extensive experiments on standard benchmarks
demonstrate that our framework establishes new state-of-the-art results for 3D
affordance segmentation.

</details>


### [75] [LinVideo: A Post-Training Framework towards O(n) Attention in Efficient Video Generation](https://arxiv.org/abs/2510.08318)
*Yushi Huang,Xingtong Ge,Ruihao Gong,Chengtao Lv,Jun Zhang*

Main category: cs.CV

TL;DR: 本文提出LinVideo，一种高效的数据无关后训练框架，通过自动选择性地将部分自注意力层替换为线性注意力层，有效加速视频扩散模型推理，并在保持生成质量的前提下大幅降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的视频扩散模型在生成高质量视频时，自注意力机制的计算成本随序列长度二次增长，限制了其效率。完全用线性注意力替换虽然能降本，但需要大量预训练且表达能力受限。因此，急需一种既能高效加速又能保证效果的新方法。

Method: 作者提出一个数据无关的后训练框架LinVideo，自动选择性能影响最小的部分自注意力层用线性注意力替换。提出用二分类方法代替人工或启发式选择层次，并引入anytime distribution matching目标函数，实现高效分布对齐与性能恢复。全面实验验证方法有效。

Result: 实验表明，LinVideo在保持视频生成质量的同时，使推理速度提升1.25-2倍，蒸馏压缩至4步后延时提升约15.92倍，视觉质量损失极小。

Conclusion: LinVideo为视频扩散模型提供了高效的加速和模块替换手段，实现了质量与效率的良好平衡，为视频生成任务落地带来实际价值。

Abstract: Video diffusion models (DMs) have enabled high-quality video synthesis.
However, their computation costs scale quadratically with sequence length
because self-attention has quadratic complexity. While linear attention lowers
the cost, fully replacing quadratic attention requires expensive pretraining
due to the limited expressiveness of linear attention and the complexity of
spatiotemporal modeling in video generation. In this paper, we present
LinVideo, an efficient data-free post-training framework that replaces a target
number of self-attention modules with linear attention while preserving the
original model's performance. First, we observe a significant disparity in the
replaceability of different layers. Instead of manual or heuristic choices, we
frame layer selection as a binary classification problem and propose selective
transfer, which automatically and progressively converts layers to linear
attention with minimal performance impact. Additionally, to overcome the
ineffectiveness and inefficiency of existing objectives for this transfer
process, we introduce an anytime distribution matching (ADM) objective that
aligns the distributions of samples across any timestep along the sampling
trajectory. This objective is efficient and recovers model performance.
Extensive experiments show that our method achieves a 1.25-2.00x speedup while
preserving generation quality, and our 4-step distilled model further delivers
a 15.92x latency reduction with minimal visual quality drop.

</details>


### [76] [Evaluating Small Vision-Language Models on Distance-Dependent Traffic Perception](https://arxiv.org/abs/2510.08352)
*Nikos Theodoridis,Tim Brophy,Reenu Mohandas,Ganesh Sistu,Fiachra Collins,Anthony Scanlan,Ciaran Eising*

Main category: cs.CV

TL;DR: 本文提出了DTPQA数据集，专注于交通场景下带距离标注的视觉感知问答，用于评测小型视觉语言模型在感知任务上的表现。结果显示，小型VLMs在此类任务中的表现明显低于人类，暴露出感知能力有限的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管VLMs在视觉和文本理解任务中表现优异，但应用于自动驾驶等安全关键场景时，必须具备可靠的感知能力，特别是对远近不同距离目标的准确感知。现有数据集和评测更多关注推理或大模型，对自动驾驶中的实际硬件小型VLM适用性缺乏针对性评估。

Method: 作者提出了DTPQA数据集，专注于感知类视觉问答，并带有距离信息。数据集排除了需要推理的问题，只评估感知能力。选择多种主流小型VLM模型在该数据集上对比人类表现，分析具体模型在不同距离及任务（如判断左右方向）上的表现差异。

Result: 在DTPQA数据集上，最佳表现的小型VLM平均准确率约为60%，相比人类约85%的表现明显偏低。模型在某些基础感知任务上表现尤其不足，如区分左右方向。此外，由于被试人类样本量较小，存在统计局限。

Conclusion: 当前小型VLMs在自动驾驶等实际场景下的感知任务表现并不理想，不能完全取代人类，尤其在距离敏感和空间感知等任务上存在短板。DTPQA为后续感知能力改进和评测提供了新基准和数据支持。

Abstract: Vision-Language Models (VLMs) are becoming increasingly powerful,
demonstrating strong performance on a variety of tasks that require both visual
and textual understanding. Their strong generalisation abilities make them a
promising component for automated driving systems, which must handle unexpected
corner cases. However, to be trusted in such safety-critical applications, a
model must first possess a reliable perception system. Moreover, since critical
objects and agents in traffic scenes are often at a distance, we require
systems that are not "shortsighted", i.e., systems with strong perception
capabilities at both close (up to 20 meters) and long (30+ meters) range. With
this in mind, we introduce Distance-Annotated Traffic Perception Question
Answering (DTPQA), the first Visual Question Answering (VQA) benchmark focused
solely on perception-based questions in traffic scenes, enriched with distance
annotations. By excluding questions that require reasoning, we ensure that
model performance reflects perception capabilities alone. Since automated
driving hardware has limited processing power and cannot support large VLMs,
our study centers on smaller VLMs. More specifically, we evaluate several
state-of-the-art (SOTA) small VLMs on DTPQA and show that, despite the
simplicity of the questions, these models significantly underperform compared
to humans (~60% average accuracy for the best-performing small VLM versus ~85%
human performance). However, it is important to note that the human sample size
was relatively small, which imposes statistical limitations. We also identify
specific perception tasks, such as distinguishing left from right, that remain
particularly challenging for these models.

</details>


### [77] [SPICE: Simple and Practical Image Clarification and Enhancement](https://arxiv.org/abs/2510.08358)
*Alexander Belyaev,Pierre-Alain Fayolle,Michael Cohen*

Main category: cs.CV

TL;DR: 本文提出了一种简单高效的图像增强与澄清方法，尤其适用于低光照和有雾（如雾霾、沙尘、水下）条件下的图像。该方法超越了现有主流技术，且实现简便。


<details>
  <summary>Details</summary>
Motivation: 低光照和含雾图像常常可用性较差，影响信息获取和后续视觉任务，因此急需一种高效且操作简单的增强方法。

Method: 通过设计图像滤波器来模拟低光或有雾条件，然后推导近似逆滤波器以尽量减少增强图像的失真。整个过程算法实现非常简洁，仅需几行MATLAB代码。

Result: 实验结果显示，该方法在处理极暗和有雾图像时，性能优于或至少可与先进技术媲美。

Conclusion: 所提方法在提升低光与有雾图像质量方面表现优异，且实现极为简便，便于实际应用。

Abstract: We introduce a simple and efficient method to enhance and clarify images.
More specifically, we deal with low light image enhancement and clarification
of hazy imagery (hazy/foggy images, images containing sand dust, and underwater
images). Our method involves constructing an image filter to simulate low-light
or hazy conditions and deriving approximate reverse filters to minimize
distortions in the enhanced images. Experimental results show that our approach
is highly competitive and often surpasses state-of-the-art techniques in
handling extremely dark images and in enhancing hazy images. A key advantage of
our approach lies in its simplicity: Our method is implementable with just a
few lines of MATLAB code.

</details>


### [78] [Hyperspectral data augmentation with transformer-based diffusion models](https://arxiv.org/abs/2510.08363)
*Mattia Ferrari,Lorenzo Bruzzone*

Main category: cs.CV

TL;DR: 该论文提出了一种结合引导扩散模型的数据增强方法，在小样本高光谱卫星影像的森林分类任务中表现优异，能有效提升深度学习模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着新一代高光谱卫星与深度学习技术的发展，高精度地物分类成为可能。但高光谱数据标注成本高，导致训练数据稀缺，深度模型容易过拟合。本文旨在解决小样本下深度模型泛化能力差的难题。

Method: 提出了一种基于引导扩散模型的数据增强方案，结合轻量化Transformer用于小样本的复杂特征建模，并引入了加权损失函数和余弦方差调度策略以优化小数据训练过程。

Result: 在使用PRISMA卫星获取的森林高光谱影像进行10类森林类型分类任务中，所提方法在平均准确率和加权平均准确率上均优于其他数据增强方法，并展现了训练过程的稳定性。

Conclusion: 本文提出的数据增强方法能在小样本高光谱影像分类中显著提升深度学习模型的分类精度与训练稳定性，为实际高光谱地物智能识别提供了有效解决方案。

Abstract: The introduction of new generation hyperspectral satellite sensors, combined
with advancements in deep learning methodologies, has significantly enhanced
the ability to discriminate detailed land-cover classes at medium-large scales.
However, a significant challenge in deep learning methods is the risk of
overfitting when training networks with small labeled datasets. In this work,
we propose a data augmentation technique that leverages a guided diffusion
model. To effectively train the model with a limited number of labeled samples
and to capture complex patterns in the data, we implement a lightweight
transformer network. Additionally, we introduce a modified weighted loss
function and an optimized cosine variance scheduler, which facilitate fast and
effective training on small datasets. We evaluate the effectiveness of the
proposed method on a forest classification task with 10 different forest types
using hyperspectral images acquired by the PRISMA satellite. The results
demonstrate that the proposed method outperforms other data augmentation
techniques in both average and weighted average accuracy. The effectiveness of
the method is further highlighted by the stable training behavior of the model,
which addresses a common limitation in the practical application of deep
generative models for data augmentation.

</details>


### [79] [UniVideo: Unified Understanding, Generation, and Editing for Videos](https://arxiv.org/abs/2510.08377)
*Cong Wei,Quande Liu,Zixuan Ye,Qiulin Wang,Xintao Wang,Pengfei Wan,Kun Gai,Wenhu Chen*

Main category: cs.CV

TL;DR: 本文提出了UniVideo，一个统一的多模态视频生成与编辑框架，实现了对复杂多模态指令的理解和多样化视频任务的一体化处理，在多种任务上达到了甚至超越最新专用模型的效果。


<details>
  <summary>Details</summary>
Motivation: 现有多模态统一模型大多局限于图像领域，而视频作为更加复杂的多模态数据，尚缺乏有效的统一生成与编辑方法。论文旨在填补这一空白，推动跨任务、多形式的视频内容创作。

Method: UniVideo采用双流架构：一方面使用多模态大语言模型（MLLM）进行指令理解，另一方面利用多模态DiT（MMDiT）负责视频生成。该框架能够统一处理文本/图像到视频生成、上下文视频生成与编辑等多种任务，并通过多任务联合训练提升模型泛化性与通用性。

Result: 实验表明，UniVideo无论是在文本/图像到视频生成、上下文视频生成，还是上下文视频编辑任务上，均达到或超过现有专用最优模型的表现。同时，模型的统一设计带来了两种泛化能力：支持任务复合（如编辑结合风格迁移），并能通过图像编辑的学习迁移到未见过的视频自由编辑任务。

Conclusion: UniVideo打破了传统专用任务模型的限制，实现了视频生成与编辑的通用与高效。该框架不仅丰富了多模态视频内容生成手段，还显著提升了不同任务和场景下的实际表现，并将在开源模型与代码的基础上促进后续研究。

Abstract: Unified multimodal models have shown promising results in multimodal content
generation and editing but remain largely limited to the image domain. In this
work, we present UniVideo, a versatile framework that extends unified modeling
to the video domain. UniVideo adopts a dual-stream design, combining a
Multimodal Large Language Model (MLLM) for instruction understanding with a
Multimodal DiT (MMDiT) for video generation. This design enables accurate
interpretation of complex multimodal instructions while preserving visual
consistency. Built on this architecture, UniVideo unifies diverse video
generation and editing tasks under a single multimodal instruction paradigm and
is jointly trained across them. Extensive experiments demonstrate that UniVideo
matches or surpasses state-of-the-art task-specific baselines in
text/image-to-video generation, in-context video generation and in-context
video editing. Notably, the unified design of UniVideo enables two forms of
generalization. First, UniVideo supports task composition, such as combining
editing with style transfer, by integrating multiple capabilities within a
single instruction. Second, even without explicit training on free-form video
editing, UniVideo transfers its editing capability from large-scale image
editing data to this setting, handling unseen instructions such as
green-screening characters or changing materials within a video. Beyond these
core capabilities, UniVideo also supports visual-prompt-based video generation,
where the MLLM interprets visual prompts and guides the MMDiT during synthesis.
To foster future research, we will release our model and code.

</details>


### [80] [Detecting Legend Items on Historical Maps Using GPT-4o with In-Context Learning](https://arxiv.org/abs/2510.08385)
*Sofia Kirsanova,Yao-Yi Chiang,Weiwei Duan*

Main category: cs.CV

TL;DR: 本文提出了一种结合LayoutLMv3和GPT-4o的新方法，实现了历史地图图例项及其描述的自动检测与配对，结构化和精确度有显著提升。


<details>
  <summary>Details</summary>
Motivation: 历史地图图例的布局和格式多样，自动化信息提取困难，现有方法多侧重分割或文字识别，缺乏对图例符号与说明结构化匹配的有效手段。

Method: 方法结合了LayoutLMv3进行布局检测和GPT-4o的in-context learning。通过结构化JSON提示词，引导GPT-4o预测图例项及其描述的边界框，并进行智能配对。

Result: 实验表明，基于结构化JSON提示的GPT-4模型显著优于基线方法，F1值达88%、IoU达85%。分析了提示设计、示例数量和布局对性能的影响。

Conclusion: 该方法支持可扩展的、兼容多种视觉风格的历史地图图例解析，为地图的索引与检索提供了更高效的技术基础。

Abstract: Historical map legends are critical for interpreting cartographic symbols.
However, their inconsistent layouts and unstructured formats make automatic
extraction challenging. Prior work focuses primarily on segmentation or general
optical character recognition (OCR), with few methods effectively matching
legend symbols to their corresponding descriptions in a structured manner. We
present a method that combines LayoutLMv3 for layout detection with GPT-4o
using in-context learning to detect and link legend items and their
descriptions via bounding box predictions. Our experiments show that GPT-4 with
structured JSON prompts outperforms the baseline, achieving 88% F-1 and 85%
IoU, and reveal how prompt design, example counts, and layout alignment affect
performance. This approach supports scalable, layout-aware legend parsing and
improves the indexing and searchability of historical maps across various
visual styles.

</details>


### [81] [Robust Source-Free Domain Adaptation for Medical Image Segmentation based on Curriculum Learning](https://arxiv.org/abs/2510.08393)
*Ziqi Zhang,Yuexiang Li,Yawen Huang,Nanjun He,Tao Xu,Liwei Lin,Yefeng Zheng,Shaoxin Li,Feiyue Huang*

Main category: cs.CV

TL;DR: 本文提出了一种基于课程学习的无源域自适应框架（LFC），在无需源数据的情况下提升医学图像跨域分割的性能。


<details>
  <summary>Details</summary>
Motivation: 传统领域自适应方法往往需要源域数据，但在医学图像场景下数据隐私和安全性问题使得源域数据不可用，因此迫切需要无源域自适应方法。同时，已有无源域自适应主要关注伪标签而忽略了更有效的学习过程设计。

Method: 提出LFC框架，将课程学习思想引入无源域自适应，设计了从易到难（easy-to-hard）和从源到目标（source-to-target）两类课程，引导模型逐渐适应目标域分布并平滑知识迁移过程。

Result: 在公开的视网膜和息肉分割跨域数据集上，所提方法实验结果优于当前所有无源域自适应对比方法，达到新的最好水平。

Conclusion: 本文工作有效提升了无源域自适应分割任务中的知识迁移效率及泛化能力，为医学图像隐私安全需求下的跨域任务提供了更优解法。

Abstract: Recent studies have uncovered a new research line, namely source-free domain
adaptation, which adapts a model to target domains without using the source
data. Such a setting can address the concerns on data privacy and security
issues of medical images. However, current source-free domain adaptation
frameworks mainly focus on the pseudo label refinement for target data without
the consideration of learning procedure. Indeed, a progressive learning process
from source to target domain will benefit the knowledge transfer during model
adaptation. To this end, we propose a curriculum-based framework, namely
learning from curriculum (LFC), for source-free domain adaptation, which
consists of easy-to-hard and source-to-target curricula. Concretely, the former
curriculum enables the framework to start learning with `easy' samples and
gradually tune the optimization direction of model adaption by increasing the
sample difficulty. While, the latter can stablize the adaptation process, which
ensures smooth transfer of the model from the source domain to the target. We
evaluate the proposed source-free domain adaptation approach on the public
cross-domain datasets for fundus segmentation and polyp segmentation. The
extensive experimental results show that our framework surpasses the existing
approaches and achieves a new state-of-the-art.

</details>


### [82] [VideoVerse: How Far is Your T2V Generator from a World Model?](https://arxiv.org/abs/2510.08398)
*Zeqing Wang,Xinyu Wei,Bairui Li,Zhen Guo,Jinrui Zhang,Hongyang Wei,Keze Wang,Lei Zhang*

Main category: cs.CV

TL;DR: 本文提出了VideoVerse，一个新的用于文本到视频（T2V）生成模型的基准，专注于复杂的时间因果关系和世界知识的理解评价。


<details>
  <summary>Details</summary>
Motivation: 随着文本到视频生成技术的快速发展，现有的评测标准无法有效区分最新的T2V模型，尤其在时间因果性和世界知识的考量上存在不足，推动了开发更全面评测基准的需求。

Method: 作者收集多个领域的代表性视频，提取包含时间因果性的事件描述，并由人工标注转化为T2V提示语。为每个提示设计二元评价问题，涵盖十个精确定义的评价维度，总计300个提示、815个事件和793个评价问题。通过现代视觉语言模型开发了面向人类偏好的问答式评估流程，并系统性地对最新T2V模型进行测试。

Result: VideoVerse能够对模型进行关于复杂事件因果性理解和世界知识的全面测试。基于该基准评估了若干开源和闭源T2V模型，揭示了现有模型与“世界模型”目标之间的差距。

Conclusion: 现有T2V模型在复杂事件因果性及世界知识理解上尚有不足，VideoVerse为评估和推动T2V生成技术的进步提供了新的基准和分析工具。

Abstract: The recent rapid advancement of Text-to-Video (T2V) generation technologies,
which are critical to build ``world models'', makes the existing benchmarks
increasingly insufficient to evaluate state-of-the-art T2V models. First,
current evaluation dimensions, such as per-frame aesthetic quality and temporal
consistency, are no longer able to differentiate state-of-the-art T2V models.
Second, event-level temporal causality, which not only distinguishes video from
other modalities but also constitutes a crucial component of world models, is
severely underexplored in existing benchmarks. Third, existing benchmarks lack
a systematic assessment of world knowledge, which are essential capabilities
for building world models. To address these issues, we introduce VideoVerse, a
comprehensive benchmark that focuses on evaluating whether a T2V model could
understand complex temporal causality and world knowledge in the real world. We
collect representative videos across diverse domains (e.g., natural landscapes,
sports, indoor scenes, science fiction, chemical and physical experiments) and
extract their event-level descriptions with inherent temporal causality, which
are then rewritten into text-to-video prompts by independent annotators. For
each prompt, we design a suite of binary evaluation questions from the
perspective of dynamic and static properties, with a total of ten carefully
defined evaluation dimensions. In total, our VideoVerse comprises 300 carefully
curated prompts, involving 815 events and 793 binary evaluation questions.
Consequently, a human preference aligned QA-based evaluation pipeline is
developed by using modern vision-language models. Finally, we perform a
systematic evaluation of state-of-the-art open-source and closed-source T2V
models on VideoVerse, providing in-depth analysis on how far the current T2V
generators are from world models.

</details>


### [83] [Large Scale Diffusion Distillation via Score-Regularized Continuous-Time Consistency](https://arxiv.org/abs/2510.08431)
*Kaiwen Zheng,Yuji Wang,Qianli Ma,Huayu Chen,Jintao Zhang,Yogesh Balaji,Jianfei Chen,Ming-Yu Liu,Jun Zhu,Qinsheng Zhang*

Main category: cs.CV

TL;DR: 本文首次实现了连续时间一致性蒸馏（sCM）在大规模图像和视频扩散模型中的应用，并提出了增强方法（rCM），在生成质量和速度上均优于现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 之前的连续时间一致性模型（sCM）主要用于学术规模的扩散模型，在大规模文本到图像和视频任务上的应用因基础设施局限（如JVP计算瓶颈）和评测标准受限而未能推广。本文希望解决这些挑战，将技术扩展到更大规模的实际应用中。

Method: 作者首先开发了兼容大规模模型并支持高维视频任务的FlashAttention-2 JVP kernel，从算力层面支持sCM训练。之后发现sCM在细节生成方面存在质量限制，提出了引入分数蒸馏作为长跳正则项的rCM方法，用于补偿sCM的“模式覆盖”偏差，提升生成图像和视频的细节表现和多样性。

Result: rCM技术在Cosmos-Predict2和Wan2.1等参数规模达14B、时长5秒的视频模型上测试，生成质量达到甚至超过SOTA方法DMD2，同时在生成多样性上具有明显优势。无需GAN调优或复杂参数搜索，蒸馏模型仅需1到4步即可生成高保真样本，相比原始扩散采样速度提升15到50倍。

Conclusion: rCM作为一种理论扎实且高效实用的新框架，实现了大规模扩散模型蒸馏的质量和速度双突破，有望推动图像和视频生成领域的进一步发展。

Abstract: This work represents the first effort to scale up continuous-time consistency
distillation to general application-level image and video diffusion models.
Although continuous-time consistency model (sCM) is theoretically principled
and empirically powerful for accelerating academic-scale diffusion, its
applicability to large-scale text-to-image and video tasks remains unclear due
to infrastructure challenges in Jacobian-vector product (JVP) computation and
the limitations of standard evaluation benchmarks. We first develop a
parallelism-compatible FlashAttention-2 JVP kernel, enabling sCM training on
models with over 10 billion parameters and high-dimensional video tasks. Our
investigation reveals fundamental quality limitations of sCM in fine-detail
generation, which we attribute to error accumulation and the "mode-covering"
nature of its forward-divergence objective. To remedy this, we propose the
score-regularized continuous-time consistency model (rCM), which incorporates
score distillation as a long-skip regularizer. This integration complements sCM
with the "mode-seeking" reverse divergence, effectively improving visual
quality while maintaining high generation diversity. Validated on large-scale
models (Cosmos-Predict2, Wan2.1) up to 14B parameters and 5-second videos, rCM
matches or surpasses the state-of-the-art distillation method DMD2 on quality
metrics while offering notable advantages in diversity, all without GAN tuning
or extensive hyperparameter searches. The distilled models generate
high-fidelity samples in only $1\sim4$ steps, accelerating diffusion sampling
by $15\times\sim50\times$. These results position rCM as a practical and
theoretically grounded framework for advancing large-scale diffusion
distillation.

</details>


### [84] [Hierarchical Spatial Algorithms for High-Resolution Image Quantization and Feature Extraction](https://arxiv.org/abs/2510.08449)
*Noor Islam S. Mohammad*

Main category: cs.CV

TL;DR: 本文提出了一套模块化空间图像处理框架，涵盖灰度量化、色彩与亮度增强、图像锐化、双向变换流程及几何特征提取，在多项任务和数据集上表现出稳健和确定性。


<details>
  <summary>Details</summary>
Motivation: 空间图像处理中，如何实现高效且精确的特征提取和图像变换，是计算机视觉及实时应用中的关键需求。现有方法往往专注单一任务，缺乏集成、可扩展和稳健的统一架构。

Method: 采用分步灰度量化实现海报化效果，通过RGB和YCrCb直方图均衡增强色彩，HSV通道调整提升亮度，3x3卷积实现锐化。整合锐化、伽马校正和噪声放大为双向变换流程，并结合Canny边缘、Hough线检测、Harris角点及形态学窗定位进行几何特征提取。

Result: 双向变换流程在正向和逆向过程分别实现76.10%和74.80%准确率；在击球杆分割的相似度上达81.87%；框架在各类数据集上整体表现稳健且具有确定性。

Conclusion: 该框架为空间图像处理提供了一套整合方案，兼具实时性和鲁棒性，适宜于计算机视觉等领域的高效特征提取与图像分析。

Abstract: This study introduces a modular framework for spatial image processing,
integrating grayscale quantization, color and brightness enhancement, image
sharpening, bidirectional transformation pipelines, and geometric feature
extraction. A stepwise intensity transformation quantizes grayscale images into
eight discrete levels, producing a posterization effect that simplifies
representation while preserving structural detail. Color enhancement is
achieved via histogram equalization in both RGB and YCrCb color spaces, with
the latter improving contrast while maintaining chrominance fidelity.
Brightness adjustment is implemented through HSV value-channel manipulation,
and image sharpening is performed using a 3 * 3 convolution kernel to enhance
high-frequency details. A bidirectional transformation pipeline that integrates
unsharp masking, gamma correction, and noise amplification achieved accuracy
levels of 76.10% and 74.80% for the forward and reverse processes,
respectively. Geometric feature extraction employed Canny edge detection,
Hough-based line estimation (e.g., 51.50{\deg} for billiard cue alignment),
Harris corner detection, and morphological window localization. Cue isolation
further yielded 81.87\% similarity against ground truth images. Experimental
evaluation across diverse datasets demonstrates robust and deterministic
performance, highlighting its potential for real-time image analysis and
computer vision.

</details>


### [85] [Video-STAR: Reinforcing Open-Vocabulary Action Recognition with Tools](https://arxiv.org/abs/2510.08480)
*Zhenlong Yuan,Xiangyan Qu,Chengxuan Qian,Rui Chen,Jing Tang,Lei Sun,Xiangxiang Chu,Dapeng Zhang,Yiwei Wang,Yujun Cai,Shuo Li*

Main category: cs.CV

TL;DR: 提出Video-STAR框架，通过将动作分解为细粒度的子动作并结合工具增强的强化学习，实现了开放词汇动作识别的性能突破。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大模型在视觉与文本推理方面表现出色，但处理语义相似动作时受限于以文本为中心的先验，难以区分开放词汇场景中的细微差别。

Method: 提出Video-STAR方法，创新性地将动作分解为可区分的子动作，同时结合工具增强的强化学习，动态调用领域工具实现跨模态细粒度匹配；通过层次化奖励机制自动平衡工具使用效率、子动作相关性和推理结构性，无需显式监督即可提升模型视觉归因能力。

Result: 在HMDB-51、UCF-101、SSv2、Kinetics-400和Kinetics-600五大数据集上大幅优于现有方法，特别是在精细动作区分及跨模态幻觉处理方面展示了先进性能。

Conclusion: 该方法显著提升了开放词汇动作识别任务的鲁棒性和泛化能力，有效缓解了多模态大模型以文本为中心的推理局限。

Abstract: Multimodal large language models (MLLMs) have demonstrated remarkable
potential in bridging visual and textual reasoning, yet their reliance on
text-centric priors often limits their ability to disentangle semantically
similar actions in open-vocabulary scenarios. To address this, we propose
Video-STAR, a framework that harmonizes contextual sub-motion decomposition
with tool-augmented reinforcement learning for open-vocabulary action
recognition (OVAR). Unlike prior methods that treat actions as monolithic
entities, our approach innovatively decomposes actions into discriminative
sub-motions for fine-grained matching while dynamically invoking
domain-specific tools for cross-modal interleaving, thereby enabling
category-specific reasoning capacity and reducing cross-modal hallucination.
Moreover, by designing a hierarchical reward that balances tool-usage
efficiency, sub-motion relevance, and structural coherence in reasoning, our
method autonomously leverages external tools to prioritize sub-motion patterns
without explicit supervision, transmitting from text-centric reasoning to
visually grounded inference. Extensive evaluations on HMDB-51, UCF-101, SSv2,
Kinetics-400, and Kinetics-600 datasets demonstrate our state-of-the-art
performance, outperforming existing methods in distinguishing fine-grained
actions and handling cross-modal hallucination, validating our excellent
robustness and generalization.

</details>


### [86] [The Visual Iconicity Challenge: Evaluating Vision-Language Models on Sign Language Form-Meaning Mapping](https://arxiv.org/abs/2510.08482)
*Onur Keleş,Aslı Özyürek,Gerardo Ortega,Kadir Gökgö,Esam Ghaleb*

Main category: cs.CV

TL;DR: 本文引入了视觉标象性挑战（Visual Iconicity Challenge），通过适应心理语言学测度，对13个主流视觉-语言模型（VLMs）在手语视频的标象性感知与理解能力进行评估，发现当前模型尚未达到人的表现，表明需加强VLM对动态表意和视觉基础的理解。


<details>
  <summary>Details</summary>
Motivation: 标象性（iconicity）是语言形式与意义之间的相似性，尤其在手语等视觉语言中尤为突出。随着多模态视觉-语言模型的兴起，亟需评价这些模型能否真正理解和把握这种以视觉为核心的结构映射，因此作者提出专门的基准和测试方法。

Method: 构建“视觉标象性挑战”基准，设计了三项基于视频的任务：①音系手势形式预测（如手型、位置）；②透明性评价（能否从手势形式推断出含义）；③分级标象性评分。采用荷兰手语数据，评价13个VLM（零/少样本）并与人类表现对比。

Result: 在音系形式预测任务上，模型能部分恢复手型和位置等细节，但明显落后于人类表现；在透明性任务上，与人类基线差距较大；只有最优模型在标象性评分上与人类有中等相关性。表现较好的模型在音系形式任务和人类标象性评分之间呈正相关。

Conclusion: 提出的基准和任务有效反映了VLM在视觉与结构映射上的局限，强调未来应结合人本信号和具身学习，提升多模态模型对标象性与视觉表意的理解和建模能力。

Abstract: Iconicity, the resemblance between linguistic form and meaning, is pervasive
in signed languages, offering a natural testbed for visual grounding. For
vision-language models (VLMs), the challenge is to recover such essential
mappings from dynamic human motion rather than static context. We introduce the
\textit{Visual Iconicity Challenge}, a novel video-based benchmark that adapts
psycholinguistic measures to evaluate VLMs on three tasks: (i) phonological
sign-form prediction (e.g., handshape, location), (ii) transparency (inferring
meaning from visual form), and (iii) graded iconicity ratings. We assess $13$
state-of-the-art VLMs in zero- and few-shot settings on Sign Language of the
Netherlands and compare them to human baselines. On \textit{phonological form
prediction}, VLMs recover some handshape and location detail but remain below
human performance; on \textit{transparency}, they are far from human baselines;
and only top models correlate moderately with human \textit{iconicity ratings}.
Interestingly, \textit{models with stronger phonological form prediction
correlate better with human iconicity judgment}, indicating shared sensitivity
to visually grounded structure. Our findings validate these diagnostic tasks
and motivate human-centric signals and embodied learning methods for modelling
iconicity and improving visual grounding in multimodal models.

</details>


### [87] [InstructX: Towards Unified Visual Editing with MLLM Guidance](https://arxiv.org/abs/2510.08485)
*Chong Mou,Qichao Sun,Yanze Wu,Pengze Zhang,Xinghui Li,Fulong Ye,Songtao Zhao,Qian He*

Main category: cs.CV

TL;DR: 本文提出了InstructX，一个统一的图像和视频编辑框架，在融合多模态大语言模型（MLLMs）与扩散模型方面做了深入分析，实现了基于指令驱动的高性能图片与视频编辑。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLMs在视觉理解与推理方面表现出色，并逐步应用于扩散模型提升编辑性能，但目前相关研究缺乏对MLLMs架构选择的深入分析，且在视频编辑等任务中的集成依然面临挑战。作者希望填补这一空白，实现MLLM与扩散模型深度结合并统一编辑多种任务。

Method: 作者提出InstructX框架，系统整合MLLM和扩散模型，在统一模型中实现图片与视频的指令驱动编辑。方法上，作者深入探讨如何令模型借助图片数据训练即可获得视频编辑能力，并通过引入特定模态的MLLM特征，有效统一图像与视频的编辑流程。

Result: 实验证明，通过图像数据训练可获得较好的视频编辑泛化能力，并通过InstructX框架实现了图像与视频编辑任务的统一。该方法在多种编辑任务上表现卓越，达到当前最优水平。

Conclusion: InstructX框架有效融合了MLLM与扩散模型，解决了传统方法在视频编辑中的不足，实现了指令驱动图像与视频编辑的统一。该工作为未来多模态编辑提供了通用强大的解决方案。

Abstract: With recent advances in Multimodal Large Language Models (MLLMs) showing
strong visual understanding and reasoning, interest is growing in using them to
improve the editing performance of diffusion models. Despite rapid progress,
most studies lack an in-depth analysis of MLLM design choices. Moreover, the
integration of MLLMs and diffusion models remains an open challenge in some
difficult tasks, such as video editing. In this paper, we present InstructX, a
unified framework for image and video editing. Specifically, we conduct a
comprehensive study on integrating MLLMs and diffusion models for
instruction-driven editing across diverse tasks. Building on this study, we
analyze the cooperation and distinction between images and videos in unified
modeling. (1) We show that training on image data can lead to emergent video
editing capabilities without explicit supervision, thereby alleviating the
constraints imposed by scarce video training data. (2) By incorporating
modality-specific MLLM features, our approach effectively unifies image and
video editing tasks within a single model. Extensive experiments demonstrate
that our method can handle a broad range of image and video editing tasks and
achieves state-of-the-art performance.

</details>


### [88] [MoA-VR: A Mixture-of-Agents System Towards All-in-One Video Restoration](https://arxiv.org/abs/2510.08508)
*Lu Liu,Chunlei Cai,Shaocheng Shen,Jianfeng Liang,Weimin Ouyang,Tianxiao Ye,Jian Mao,Huiyu Duan,Jiangchao Yao,Xiaoyun Zhang,Qiang Hu,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本论文提出了MoA-VR系统——一种模仿专家处理流程的混合代理型视频复原系统，实现了复杂退化场景下的视频自动恢复，并在多个评测中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的视频往往因采集和传输条件复杂而出现多种退化，如噪声、压缩伪影和低光照等。现有方法需依赖专业人士手动选型或单一模型，难以应对多变的退化形式，缺乏泛化能力。因此，亟需一种能够智能识别和适应多源退化的视频复原系统。

Method: 作者受人类专业处理经验启发，提出MoA-VR系统，由‘退化识别’、‘路由与复原’和‘复原质量评估’三大智能代理组成：设计了基于大规模高分辨率退化识别基准和视觉-语言模型的退化识别器；利用大语言模型开发自适应路由器，自动学习恢复策略；同时构建了Res-VQ数据集并设计专门的VLM驱动的VQA模型用于评估恢复质量。

Result: MoA-VR系统能够高效应对多种及复合型视频退化，且在客观指标和感知质量评测中均显著优于现有主流方法。

Conclusion: 集成多模态智能与模块化推理为视频复原系统带来了更强的泛化性和适应性，MoA-VR展现了在通用视频复原任务中的巨大应用潜力。

Abstract: Real-world videos often suffer from complex degradations, such as noise,
compression artifacts, and low-light distortions, due to diverse acquisition
and transmission conditions. Existing restoration methods typically require
professional manual selection of specialized models or rely on monolithic
architectures that fail to generalize across varying degradations. Inspired by
expert experience, we propose MoA-VR, the first
\underline{M}ixture-\underline{o}f-\underline{A}gents \underline{V}ideo
\underline{R}estoration system that mimics the reasoning and processing
procedures of human professionals through three coordinated agents: Degradation
Identification, Routing and Restoration, and Restoration Quality Assessment.
Specifically, we construct a large-scale and high-resolution video degradation
recognition benchmark and build a vision-language model (VLM) driven
degradation identifier. We further introduce a self-adaptive router powered by
large language models (LLMs), which autonomously learns effective restoration
strategies by observing tool usage patterns. To assess intermediate and final
processed video quality, we construct the \underline{Res}tored
\underline{V}ideo \underline{Q}uality (Res-VQ) dataset and design a dedicated
VLM-based video quality assessment (VQA) model tailored for restoration tasks.
Extensive experiments demonstrate that MoA-VR effectively handles diverse and
compound degradations, consistently outperforming existing baselines in terms
of both objective metrics and perceptual quality. These results highlight the
potential of integrating multimodal intelligence and modular reasoning in
general-purpose video restoration systems.

</details>


### [89] [To Sink or Not to Sink: Visual Information Pathways in Large Vision-Language Models](https://arxiv.org/abs/2510.08510)
*Jiayun Luo,Wan-Cyuan Fan,Lyuyang Wang,Xiangteng He,Tanzila Rahman,Purang Abolmaesumi,Leonid Sigal*

Main category: cs.CV

TL;DR: 本文聚焦于大视觉语言模型（LVLMs）的视觉编码部分——视觉Transformer（ViT）中的高范数注意力sink token（ViT attention sinks），并证明这些token对模型提升视觉理解和推理表现有显著作用。


<details>
  <summary>Details</summary>
Motivation: 虽然现有研究主要分析LLM内部的注意力sink（即低语义但高被关注的token），但对ViT输出的高范数token鲜有关注。作者认为，这些ViT attention sinks可能承载图像的高层语义信息，对模型下游推理和理解有关键影响，但在现有架构中往往被忽视。

Method: 作者首次系统分析了ViT输出的sink token，通过定性和定量实验挖掘其中蕴含的信息。同时，提出了无需训练与需训练的方法，优化ViT sink token到LLM的利用方式，并验证这种优化如何提升LVLM的表现。

Result: 通过显式利用ViT sink token，在多种LVLM模型和视觉推理任务上取得了显著性能提升，验证了sink token的潜在价值。

Conclusion: ViT输出的高范数sink token是视觉理解与推理的重要信息来源，但在现有LVLM中被低估。通过专门利用这些token，可大幅提升模型推理能力，为后续视觉-语言融合模型的设计提供了新见解。

Abstract: Large Vision Language Models (LVLMs) have recently emerged as powerful
architectures capable of understanding and reasoning over both visual and
textual information. These models typically rely on two key components: a
Vision Transformer (ViT) and a Large Language Model (LLM). ViT encodes visual
content into a sequence of image tokens and serves as the perceptual front-end
-- the eyes of the model. In contrast, the LLM interprets these tokens to
perform high-level reasoning, generates responses, and functions as the
cognitive core -- the brain of the model. However, it remains unclear which
visual tokens contribute most significantly to understanding and reasoning, and
how effectively these signals are propagated from ViT to the LLM. While most
existing works have focused on identifying attention sinks, low-semantic tokens
receiving disproportionately high attention, within the LLM, we shift the focus
to the vision encoder by identifying a class of high-norm visual tokens from
ViT, referred to as ViT attention sinks -- a problem that has been rarely
studied but is indeed very important for LVLMs. Our findings show that these
ViT sinks encapsulate high-level semantic concepts from images, allowing the
LLM to perform more effective understanding and reasoning. Despite their
importance, these sink tokens are often overlooked in existing LVLM
architectures. To explore their contribution, we present both qualitative and
quantitative analyses of the information embedded in these sink tokens. We also
propose both training-free and training-based approaches to better leverage how
this information is interpreted by the LLM, and to what extent. By explicitly
utilizing these tokens, we demonstrate substantial improvements across a range
of LVLMs and visual reasoning tasks, highlighting the untapped potential of ViT
attention sinks in enhancing visual reasoning.

</details>


### [90] [SliceFine: The Universal Winning-Slice Hypothesis for Pretrained Networks](https://arxiv.org/abs/2510.08513)
*Md Kowsher,Ali O. Polat,Ehsan Mohammady Ardehaly,Mehrdad Salehi,Zia Ghiasi,Prasanth Murali,Chen Chen*

Main category: cs.CV

TL;DR: 本文提出了理论和方法，解释为何只微调预训练大模型中一小部分随机子网络（slice）即可实现高效下游任务适应，并提出了具体的方法SliceFine。


<details>
  <summary>Details</summary>
Motivation: 当前大模型微调带来的参数和资源消耗极大，如何实现参数高效微调（PEFT）成为研究热点，需要理论基础支撑和切实可行的新方法。

Method: （1）理论上分析预训练网络的权重切片具有'谱平衡'和'高任务能量'特性，并提出了Universal Winning Slice假说；（2）基于此，提出SliceFine方法，只调整原始权重的一小部分切片，无需增加新参数。

Result: SliceFine在多项语言和视觉任务中与当前SOTA PEFT方法表现相当，同时在训练速度、内存效率和模型紧凑性上有明显提升。

Conclusion: 本工作为大模型PEFT方法提供了新的理论基础与实用手段，将理论分析与方法实践相结合，是对现有PEFT技术的重要补充和替代选择。

Abstract: This paper presents a theoretical framework explaining why fine tuning small,
randomly selected subnetworks (slices) within pre trained models can be
sufficient for downstream adaptation. We prove that pretrained networks exhibit
a universal winning slice property arising from two phenomena: (1) spectral
balance the eigenspectra of different weight matrix slices are remarkably
similar; and (2) high task energy their backbone representations retain rich,
task relevant features. This leads to the Universal Winning Slice Hypothesis,
which provides a theoretical foundation for parameter efficient fine tuning
(PEFT) in large scale models. Inspired by this, we propose SliceFine, a PEFT
method that exploits this inherent redundancy by updating only selected slices
of the original weights introducing zero new parameters, unlike adapter-based
approaches. Empirically, SliceFine matches the performance of state of the art
PEFT methods across language and vision tasks, while significantly improving
training speed, memory efficiency, and model compactness. Our work bridges
theory and practice, offering a theoretically grounded alternative to existing
PEFT techniques.

</details>


### [91] [FlexTraj: Image-to-Video Generation with Flexible Point Trajectory Control](https://arxiv.org/abs/2510.08527)
*Zhiyuan Zhang,Can Wang,Dongdong Chen,Jing Liao*

Main category: cs.CV

TL;DR: FlexTraj是一种可灵活点轨迹控制的图像转视频生成框架，具备高效、强可控、多应用场景支持等优点。


<details>
  <summary>Details</summary>
Motivation: 现有的图像到视频生成技术在运动控制灵活性和精度上有限，特别是在实现稠密或稀疏点轨迹控制、多粒度运动编辑及复杂应用（如动作克隆、运动插值等）时存在挑战。作者希望构建一个支持统一、灵活轨迹控制的视频生成框架。

Method: FlexTraj使用一种统一的基于点的运动表示方法，为每个点编码分割ID、轨迹ID和可选的颜色通道信息，以支持稠密与稀疏轨迹控制。它通过序列级拼接方法（而非传统的令牌拼接或ControlNet注入）将轨迹条件输入视频生成器，实现更快收敛、更高可控性与高效推理。同时，采用退火式训练策略，逐步降低对完整监督和对齐条件的依赖。

Result: 实验结果表明，FlexTraj能实现多粒度、与对齐无关的点轨迹控制，且适用于运动克隆、基于拖拽的图像转视频、运动插值、摄像机重定向、灵活动作控制和网格动画等多种应用场景。

Conclusion: FlexTraj为图像转视频生成提供了一种高效、灵活且鲁棒的轨迹控制框架，显著提升了运动控制的自由度和多样性，具备广泛的实际应用潜力。

Abstract: We present FlexTraj, a framework for image-to-video generation with flexible
point trajectory control. FlexTraj introduces a unified point-based motion
representation that encodes each point with a segmentation ID, a temporally
consistent trajectory ID, and an optional color channel for appearance cues,
enabling both dense and sparse trajectory control. Instead of injecting
trajectory conditions into the video generator through token concatenation or
ControlNet, FlexTraj employs an efficient sequence-concatenation scheme that
achieves faster convergence, stronger controllability, and more efficient
inference, while maintaining robustness under unaligned conditions. To train
such a unified point trajectory-controlled video generator, FlexTraj adopts an
annealing training strategy that gradually reduces reliance on complete
supervision and aligned condition. Experimental results demonstrate that
FlexTraj enables multi-granularity, alignment-agnostic trajectory control for
video generation, supporting various applications such as motion cloning,
drag-based image-to-video, motion interpolation, camera redirection, flexible
action control and mesh animations.

</details>


### [92] [SpatialLadder: Progressive Training for Spatial Reasoning in Vision-Language Models](https://arxiv.org/abs/2510.08531)
*Hongxing Li,Dingming Li,Zixuan Wang,Yuchen Yan,Hang Wu,Wenqi Zhang,Yongliang Shen,Weiming Lu,Jun Xiao,Yueting Zhuang*

Main category: cs.CV

TL;DR: 本文提出了一种逐步构建空间智能的方法，并构建了SpatialLadder-26k数据集，通过渐进式训练，显著提升了视觉-语言模型在空间推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言模型在空间推理上的能力有限，难以取得鲁棒表现。作者认为，这是因为当前方法直接学习空间推理，忽略了知觉和理解的层级基础，因此亟需新方法从基础逐渐建立空间智能。

Method: 作者构建了包含26,610个样本的多模态数据集SpatialLadder-26k，涵盖对象定位、单图像、多视角和视频空间推理。提出三级渐进式训练框架：第一阶段通过对象定位建立空间感知，第二阶段通过多维空间任务发展空间理解，第三阶段结合可验证奖励的强化学习提升复杂空间推理能力。

Result: 提出的SpatialLadder（3B参数）模型在空间推理基准上取得了最优成绩，平均提升23.4%，超越GPT-4o 20.8%，超越Gemini-2.0-Flash 10.1%；在域外基准上也提升了7.2%。

Conclusion: 分层、渐进式训练策略对于提升空间智能至关重要，SpatialLadder展现出更强的泛化能力，为视觉-语言模型在空间推理任务的发展提供了新方向。

Abstract: Spatial reasoning remains a fundamental challenge for Vision-Language Models
(VLMs), with current approaches struggling to achieve robust performance
despite recent advances. We identify that this limitation stems from a critical
gap: existing methods attempt to learn spatial reasoning directly without
establishing the hierarchical foundations of perception and understanding. To
address this challenge, we present a comprehensive methodology for building
spatial intelligence progressively. We introduce SpatialLadder-26k, a
multimodal dataset containing 26,610 samples spanning object localization,
single image, multi-view, and video spatial reasoning tasks, constructed
through a standardized pipeline that ensures systematic coverage across
modalities. Building on this dataset, we design a three-stage progressive
training framework that (1) establishes spatial perception through object
localization, (2) develops spatial understanding through multi-dimensional
spatial tasks, and (3) strengthens complex reasoning via reinforcement learning
with verifiable rewards. This approach yields SpatialLadder, a 3B-parameter
model that achieves state-of-the-art performance on spatial reasoning
benchmarks, with 23.4% average improvement over the base model, surpassing
GPT-4o by 20.8% and Gemini-2.0-Flash by 10.1%. Notably, SpatialLadder maintains
strong generalization with 7.2% improvement on out-of-domain benchmarks,
demonstrating that progressive training from perception to reasoning is
essential for robust spatial intelligence.

</details>


### [93] [Kontinuous Kontext: Continuous Strength Control for Instruction-based Image Editing](https://arxiv.org/abs/2510.08532)
*Rishubh Parihar,Or Patashnik,Daniil Ostashev,R. Venkatesh Babu,Daniel Cohen-Or,Kuan-Chieh Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新的基于指令的图像编辑方法，允许用户通过自然语言描述并连续控制编辑强度，实现从微小改动到强烈变化的平滑调整。


<details>
  <summary>Details</summary>
Motivation: 传统基于文本指令的图像编辑方法在精细控制编辑程度方面存在局限，难以实现连续、渐进的调整。作者希望解决用户在实际应用中对编辑强度灵活把控的需求。

Method: 本方法提出Kontinuous Kontext，在现有图像编辑模型基础上，引入“编辑强度”标量作为额外输入。通过训练轻量级投影网络，将强度标量与编辑指令映射到模型调制空间的系数，进而实现对编辑程度的精细调控。训练数据为合成的图像-编辑指令-强度四元组，并经过筛选以保证质量。

Result: Kontinuous Kontext实现了基于指令的编辑强度连续控制，无需针对不同属性单独训练，广泛适用于风格化、属性、材质、背景、形状等多种编辑类型，均可实现从细微到强烈的平滑调整。

Conclusion: 本文提出的方法极大丰富了图像编辑的交互方式和精细度，用户可以通过简单的一句自然语言和一个强度参数，实现多样化、高质量、可控的图像编辑，具有很高的实用价值和推广潜力。

Abstract: Instruction-based image editing offers a powerful and intuitive way to
manipulate images through natural language. Yet, relying solely on text
instructions limits fine-grained control over the extent of edits. We introduce
Kontinuous Kontext, an instruction-driven editing model that provides a new
dimension of control over edit strength, enabling users to adjust edits
gradually from no change to a fully realized result in a smooth and continuous
manner. Kontinuous Kontext extends a state-of-the-art image editing model to
accept an additional input, a scalar edit strength which is then paired with
the edit instruction, enabling explicit control over the extent of the edit. To
inject this scalar information, we train a lightweight projector network that
maps the input scalar and the edit instruction to coefficients in the model's
modulation space. For training our model, we synthesize a diverse dataset of
image-edit-instruction-strength quadruplets using existing generative models,
followed by a filtering stage to ensure quality and consistency. Kontinuous
Kontext provides a unified approach for fine-grained control over edit strength
for instruction driven editing from subtle to strong across diverse operations
such as stylization, attribute, material, background, and shape changes,
without requiring attribute-specific training.

</details>


### [94] [MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with Holistic Platform and Adaptive Hybrid Policy Optimization](https://arxiv.org/abs/2510.08540)
*Xiangyu Zhao,Junming Lin,Tianhao Liang,Yifan Zhou,Wenhao Chai,Yuzhe Gu,Weiyun Wang,Kai Chen,Gen Luo,Wenwei Zhang,Junchi Yan,Hua Yang,Haodong Duan,Xue Yang*

Main category: cs.CV

TL;DR: 本文提出评价和提升多模态大模型（MLLM）长链反思推理能力的新基准与训练方法，并实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前MLLM在数学与逻辑推理上表现卓越，但在复杂现实问题所需的长链反思推理方面尚未被充分探索。该能力对于真实复杂任务至关重要，因此亟需系统评估并提升这种能力。

Method: 1）构建了包含42种挑战性任务的多模态基准MM-HELIX，用以评测长链反思推理；2）开发数据合成与后训练数据集MM-HELIX-100K（含十万条推理过程）；3）提出适应性混合策略优化（AHPO），结合离线专家数据和在线探索，克服奖励稀疏和遗忘问题。

Result: 在Qwen2.5-VL-7B基线模型上，所提方法在MM-HELIX基准上准确率提升18.6%，且在一般数学、逻辑任务上平均提升5.7%，表现出较强泛化能力。

Conclusion: 长链反思推理能力可以通过大规模优质数据与创新训练范式有效学习和泛化，为更强大MLLM发展奠定基础。

Abstract: While current Multimodal Large Language Models (MLLMs) have demonstrated
proficiency in reasoning tasks such as mathematics and logic, their capacity
for long-chain reflective reasoning, a prerequisite for solving complex
real-world problems, remains largely underexplored. In this work, we first
conduct an extensive empirical investigation to evaluate this capability.
Leveraging a carefully designed data synthesis engine, we construct MM-HELIX, a
multimodal benchmark consisting 1,260 samples of 42 challenging synthetic tasks
that require iterative thinking and backtracking. Empirical results on this
benchmark reveal that existing MLLMs exhibit significant performance deficits
in long-chain reflective reasoning. To address this limitation, we generate
post-training data and further explore learning paradigms for exploiting such
data. We first develop the Step-Elicited Response Generation pipeline to create
MM-HELIX-100K, a large-scale dataset of 100k high-quality, reflective reasoning
traces for instruction-tuning stage. Given that standard Reinforcement Learning
fails on complex tasks due to sparse reward signals and catastrophic forgetting
after Supervised Fine-Tuning, we propose Adaptive Hybrid Policy Optimization
(AHPO), a novel training strategy that dynamically unifies offline supervision
and online optimization into a single stage. This strategy enables the model to
learn from expert data when rewards are sparse and conduct independent
exploration once proficient. When applied to the Qwen2.5-VL-7B baseline, our
method achieves a +18.6\% accuracy improvement on MM-HELIX benchmark and
demonstrates strong generalization with a +5.7\% average performance gain on
general mathematic and logic tasks. Our work demonstrate that reflective
reasoning in MLLMs can be effectively learned and generalized, paving the way
for developing more capable MLLMs.

</details>


### [95] [VideoNorms: Benchmarking Cultural Awareness of Video Language Models](https://arxiv.org/abs/2510.08543)
*Nikhil Reddy Varimalla,Yunfei Xu,Arkadiy Saakyan,Meng Fan Wang,Smaranda Muresan*

Main category: cs.CV

TL;DR: 本文提出了VideoNorms，一个包含美中两国文化的视频及其社会规范注释的基准数据集，并用其评测了多种视频大模型的文化感知能力，揭示了目前模型在文化适应和规范理解方面存在明显不足。


<details>
  <summary>Details</summary>
Motivation: 随着视频大语言模型（VideoLLMs）全球部署，模型对不同文化背景的理解变得极为重要，但目前缺乏衡量模型文化感知能力的有效基准。为推动模型在社会规范和文化语境下的能力提升，作者提出开发相关测评体系。

Method: 作者构建了VideoNorms数据集，包含超1000对（视频片段，规范）样本，涵盖美中两国文化，通过人机协作（大模型候选注释+专家校正）生成与注释数据。每对样本都基于言语行为理论给出规范遵守/违背标签，并提供口头与非口头证据。随后，作者在该数据集上基准评测了多种开放权重的VideoLLM。

Result: 实验发现：1）模型在规范违背情况的识别效果低于遵守；2）模型对中国文化的理解劣于美国文化；3）针对非言语证据的表现弱于言语证据，且对话语行为拟合具体规范有困难；4）与人类相比，模型在正式、非幽默语境下表现更差。

Conclusion: 当前视频大模型在跨文化社会规范理解、非言语证据挖掘等方面存在明显局限。VideoNorms基准及其构建方法有助于推动模型的文化适应性训练，填补文化感知测评的空白。

Abstract: As Video Large Language Models (VideoLLMs) are deployed globally, they
require understanding of and grounding in the relevant cultural background. To
properly assess these models' cultural awareness, adequate benchmarks are
needed. We introduce VideoNorms, a benchmark of over 1000 (video clip, norm)
pairs from US and Chinese cultures annotated with socio-cultural norms grounded
in speech act theory, norm adherence and violations labels, and verbal and
non-verbal evidence. To build VideoNorms, we use a human-AI collaboration
framework, where a teacher model using theoretically-grounded prompting
provides candidate annotations and a set of trained human experts validate and
correct the annotations. We benchmark a variety of open-weight VideoLLMs on the
new dataset which highlight several common trends: 1) models performs worse on
norm violation than adherence; 2) models perform worse w.r.t Chinese culture
compared to the US culture; 3) models have more difficulty in providing
non-verbal evidence compared to verbal for the norm adhere/violation label and
struggle to identify the exact norm corresponding to a speech-act; and 4)
unlike humans, models perform worse in formal, non-humorous contexts. Our
findings emphasize the need for culturally-grounded video language model
training - a gap our benchmark and framework begin to address.

</details>


### [96] [ARTDECO: Towards Efficient and High-Fidelity On-the-Fly 3D Reconstruction with Structured Scene Representation](https://arxiv.org/abs/2510.08551)
*Guanghao Li,Kerui Ren,Linning Xu,Zhewen Zheng,Changjian Jiang,Xin Gao,Bo Dai,Jian Pu,Mulin Yu,Jiangmiao Pang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为ARTDECO的新方法，实现了从单目图像序列即时3D重建，兼顾高精度和高效率。


<details>
  <summary>Details</summary>
Motivation: 单目序列3D重建在实际应用如虚实融合、AR/VR、机器人等领域中非常重要。当前方法在高保真度与实时推理之间存在明显权衡，亟需兼具精度和效率的统一框架。

Method: ARTDECO将前馈基础模型的效率与SLAM管线的可靠性相结合。具体做法是利用3D基础模型做姿态估计和点位预测，并通过高斯解码器将多尺度特征变换为结构化3D高斯表示。为提升效率与精度，引入层次化的高斯表示及分层细节感知渲染策略。

Result: 在八个不同的室内外基准测试上，ARTDECO显示出与SLAM媲美的交互性能、近似前馈系统的鲁棒性和逼近按场景优化方法的重建质量。

Conclusion: ARTDECO为即时高精度3D场景数字化提供了实用路径，同时兼顾了精确几何和高视觉保真度。

Abstract: On-the-fly 3D reconstruction from monocular image sequences is a
long-standing challenge in computer vision, critical for applications such as
real-to-sim, AR/VR, and robotics. Existing methods face a major tradeoff:
per-scene optimization yields high fidelity but is computationally expensive,
whereas feed-forward foundation models enable real-time inference but struggle
with accuracy and robustness. In this work, we propose ARTDECO, a unified
framework that combines the efficiency of feed-forward models with the
reliability of SLAM-based pipelines. ARTDECO uses 3D foundation models for pose
estimation and point prediction, coupled with a Gaussian decoder that
transforms multi-scale features into structured 3D Gaussians. To sustain both
fidelity and efficiency at scale, we design a hierarchical Gaussian
representation with a LoD-aware rendering strategy, which improves rendering
fidelity while reducing redundancy. Experiments on eight diverse indoor and
outdoor benchmarks show that ARTDECO delivers interactive performance
comparable to SLAM, robustness similar to feed-forward systems, and
reconstruction quality close to per-scene optimization, providing a practical
path toward on-the-fly digitization of real-world environments with both
accurate geometry and high visual fidelity. Explore more demos on our project
page: https://city-super.github.io/artdeco/.

</details>


### [97] [VideoCanvas: Unified Video Completion from Arbitrary Spatiotemporal Patches via In-Context Conditioning](https://arxiv.org/abs/2510.08555)
*Minghong Cai,Qiulin Wang,Zongli Ye,Wenze Liu,Quande Liu,Weicai Ye,Xintao Wang,Pengfei Wan,Kun Gai,Xiangyu Yue*

Main category: cs.CV

TL;DR: 提出了一种名为arbitrary spatio-temporal video completion的新任务，并提出VideoCanvas新方法，实现了用户任意指定的时空补全视频生成，且性能显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有受控视频生成方法多种多样（如inpainting、插帧、首帧扩展等），缺乏统一、灵活的框架。同时，现代视频扩散模型受限于因果VAE导致的时间模糊性，难以实现精准帧级别控制。

Method: 提出VideoCanvas框架，将In-Context Conditioning（ICC）范式应用于精细视频控制任务，无需新增参数。策略上，空间控制通过zero-padding实现，时间控制用Temporal RoPE Interpolation，将条件赋予连续时序位置，解决了VAE时间模糊性。

Result: 提出了VideoCanvasBench基准，并实验证明VideoCanvas在空间和时间统一可控的视频生成中，显著领先其他方法，树立了新SOTA。

Conclusion: VideoCanvas实现了灵活、统一的视频生成与补全任务，可以细致地时空定制内容，推动了视频生成控制的边界。

Abstract: We introduce the task of arbitrary spatio-temporal video completion, where a
video is generated from arbitrary, user-specified patches placed at any spatial
location and timestamp, akin to painting on a video canvas. This flexible
formulation naturally unifies many existing controllable video generation
tasks--including first-frame image-to-video, inpainting, extension, and
interpolation--under a single, cohesive paradigm. Realizing this vision,
however, faces a fundamental obstacle in modern latent video diffusion models:
the temporal ambiguity introduced by causal VAEs, where multiple pixel frames
are compressed into a single latent representation, making precise frame-level
conditioning structurally difficult. We address this challenge with
VideoCanvas, a novel framework that adapts the In-Context Conditioning (ICC)
paradigm to this fine-grained control task with zero new parameters. We propose
a hybrid conditioning strategy that decouples spatial and temporal control:
spatial placement is handled via zero-padding, while temporal alignment is
achieved through Temporal RoPE Interpolation, which assigns each condition a
continuous fractional position within the latent sequence. This resolves the
VAE's temporal ambiguity and enables pixel-frame-aware control on a frozen
backbone. To evaluate this new capability, we develop VideoCanvasBench, the
first benchmark for arbitrary spatio-temporal video completion, covering both
intra-scene fidelity and inter-scene creativity. Experiments demonstrate that
VideoCanvas significantly outperforms existing conditioning paradigms,
establishing a new state of the art in flexible and unified video generation.

</details>


### [98] [SciVideoBench: Benchmarking Scientific Video Reasoning in Large Multimodal Models](https://arxiv.org/abs/2510.08559)
*Andong Deng,Taojiannan Yang,Shoubin Yu,Lincoln Spencer,Mohit Bansal,Chen Chen,Serena Yeung-Levy,Xiaohan Wang*

Main category: cs.CV

TL;DR: 本文提出了SciVideoBench，这是一个专为科学领域高级视频推理能力设计的基准，用于弥补现有多模态大模型（LMMs）在复杂科学视频推理评测上的不足。实验显示当前主流LMMs在该基准下表现有限，强调了进一步提升这些模型推理能力的必要性。


<details>
  <summary>Details</summary>
Motivation: 现有视频基准多集中于对一般场景的感知与识别，推理任务较简单，已趋于饱和，无法有效评估LMMs在复杂科学视频推理中的高级多模态认知能力。因此，需要一个更具挑战性的评测基准推动该领域发展。

Method: 作者构建了SciVideoBench——一个包含1000道多项选择题的科学视频推理基准，涵盖25个专业学科领域。这些题目基于前沿实验科学视频，由半自动方式验证，题目设计要求模型具备复杂的领域知识、精确的时空感知与逻辑推理能力。

Result: 通过对主流封闭式与开源LMMs如Gemini 2.5 Pro和Qwen2.5-VL的评测，发现它们在SciVideoBench上的高阶推理表现明显不足，存在较大性能短板。同时，分析了推理复杂度和视觉锚定等关键因素，揭示了当前模型的局限性。

Conclusion: SciVideoBench为科学高级视频推理能力评测提供了严密工具，可用于揭示LMMs高阶认知短板，并为未来模型优化与发展指明方向，有助于推动多模态AI在前沿科学领域的实际应用与进步。

Abstract: Large Multimodal Models (LMMs) have achieved remarkable progress across
various capabilities; however, complex video reasoning in the scientific domain
remains a significant and challenging frontier. Current video benchmarks
predominantly target general scenarios where perception/recognition is heavily
relied on, while with relatively simple reasoning tasks, leading to saturation
and thus failing to effectively evaluate advanced multimodal cognitive skills.
To address this critical gap, we introduce SciVideoBench, a rigorous benchmark
specifically designed to assess advanced video reasoning in scientific
contexts. SciVideoBench consists of 1,000 carefully crafted multiple-choice
questions derived from cutting-edge scientific experimental videos spanning
over 25 specialized academic subjects and verified by a semi-automatic system.
Each question demands sophisticated domain-specific knowledge, precise
spatiotemporal perception, and intricate logical reasoning, effectively
challenging models' higher-order cognitive abilities. Our evaluation highlights
significant performance deficits in state-of-the-art proprietary and
open-source LMMs, including Gemini 2.5 Pro and Qwen2.5-VL, indicating
substantial room for advancement in video reasoning capabilities. Detailed
analyses of critical factors such as reasoning complexity and visual grounding
provide valuable insights and clear direction for future developments in LMMs,
driving the evolution of truly capable multimodal AI co-scientists. We hope
SciVideoBench could fit the interests of the community and help to push the
boundary of cutting-edge AI for border science.

</details>


### [99] [MultiCOIN: Multi-Modal COntrollable Video INbetweening](https://arxiv.org/abs/2510.08561)
*Maham Tanveer,Yang Zhou,Simon Niklaus,Ali Mahdavi Amiri,Hao Zhang,Krishna Kumar Singh,Nanxuan Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种多模态控制的视频中间帧生成方法，可以实现深度过渡、分层、运动轨迹、文本和区域控制，实现更灵活、精确的视频补帧效果。


<details>
  <summary>Details</summary>
Motivation: 现有的视频中间帧补全方法在处理大幅度、复杂运动和多样化用户需求上存在局限，无法细致地控制插帧细节，难以满足创作者的多元创意需求。

Method: 作者提出了	tt名Video Inbetweening框架，基于Diffusion Transformer (DiT)架构，将多模态运动控制映射为点状表示，分别用两个分支处理内容与运动控制，最后采用分阶段训练策略优化多模态输入的学习效果。

Result: 通过广泛的定性和定量实验，证明了该方法能够实现更动态、可定制和上下文相关性强的视频插帧，优于现有方法。

Conclusion: 该框架兼顾了自由度、易用性和精细度，为用户提供了多维度、多粒度的视频插帧方案，推动了视频编辑与生成的实用性和创意边界。

Abstract: Video inbetweening creates smooth and natural transitions between two image
frames, making it an indispensable tool for video editing and long-form video
synthesis. Existing works in this domain are unable to generate large, complex,
or intricate motions. In particular, they cannot accommodate the versatility of
user intents and generally lack fine control over the details of intermediate
frames, leading to misalignment with the creative mind. To fill these gaps, we
introduce \modelname{}, a video inbetweening framework that allows multi-modal
controls, including depth transition and layering, motion trajectories, text
prompts, and target regions for movement localization, while achieving a
balance between flexibility, ease of use, and precision for fine-grained video
interpolation. To achieve this, we adopt the Diffusion Transformer (DiT)
architecture as our video generative model, due to its proven capability to
generate high-quality long videos. To ensure compatibility between DiT and our
multi-modal controls, we map all motion controls into a common sparse and
user-friendly point-based representation as the video/noise input. Further, to
respect the variety of controls which operate at varying levels of granularity
and influence, we separate content controls and motion controls into two
branches to encode the required features before guiding the denoising process,
resulting in two generators, one for motion and the other for content. Finally,
we propose a stage-wise training strategy to ensure that our model learns the
multi-modal controls smoothly. Extensive qualitative and quantitative
experiments demonstrate that multi-modal controls enable a more dynamic,
customizable, and contextually accurate visual narrative.

</details>


### [100] [NaViL: Rethinking Scaling Properties of Native Multimodal Large Language Models under Data Constraints](https://arxiv.org/abs/2510.08565)
*Changyao Tian,Hao Li,Gen Luo,Xizhou Zhu,Weijie Su,Hanming Deng,Jinguo Zhu,Jie Shao,Ziran Zhu,Yunpeng Liu,Lewei Lu,Wenhai Wang,Hongsheng Li,Jifeng Dai*

Main category: cs.CV

TL;DR: 本文对多模态大语言模型（MLLMs）的原生端到端训练进行系统性研究，提出了新模型NaViL，并展示了其在多项基准测试中的优异表现。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs的主流方法多采用分阶段（视觉编码器与LLM分开预训练后再组合）训练范式，导致多模态模型扩展性难以评估，且存在数据受限等现实问题。因此，作者希望通过原生端到端训练模式，探索更高效、可扩展的MLLM实现路径。

Method: 系统性地在真实数据受限环境下，考察并分析多种端到端MLLM的架构选择及其扩展性，最终确定一种同时兼顾性能和训练成本的meta-architecture，并在此基础上开发出简单高效的NaViL模型训练方案。

Result: NaViL在包括14个多模态基准测试在内的大量实验中表现出具有竞争力的性能。同时验证了视觉编码器与LLM的规模呈正相关扩展关系。

Conclusion: 端到端的原生MLLM具备更优的扩展性，并在性能和训练成本间达到了良好平衡。NaViL的提出为未来原生MLLM的设计和研究提供了参考。

Abstract: Compositional training has been the de-facto paradigm in existing Multimodal
Large Language Models (MLLMs), where pre-trained vision encoders are connected
with pre-trained LLMs through continuous multimodal pre-training. However, the
multimodal scaling property of this paradigm remains difficult to explore due
to the separated training. In this paper, we focus on the native training of
MLLMs in an end-to-end manner and systematically study its design space and
scaling property under a practical setting, i.e., data constraint. Through
careful study of various choices in MLLM, we obtain the optimal
meta-architecture that best balances performance and training cost. After that,
we further explore the scaling properties of the native MLLM and indicate the
positively correlated scaling relationship between visual encoders and LLMs.
Based on these findings, we propose a native MLLM called NaViL, combined with a
simple and cost-effective recipe. Experimental results on 14 multimodal
benchmarks confirm the competitive performance of NaViL against existing MLLMs.
Besides that, our findings and results provide in-depth insights for the future
study of native MLLMs.

</details>


### [101] [D$^2$GS: Depth-and-Density Guided Gaussian Splatting for Stable and Accurate Sparse-View Reconstruction](https://arxiv.org/abs/2510.08566)
*Meixi Song,Xin Lin,Dizhe Zhang,Haodong Li,Xiangtai Li,Bo Du,Lu Qi*

Main category: cs.CV

TL;DR: 论文提出了一种新方法D$^2$GS，显著提升了稀疏视角下3D Gaussian Splatting（3DGS）的视图合成效果和稳健性。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS技术尽管在新颖视角合成表现出色，但在稀疏视角条件下，容易出现性能下降与不稳定问题，特别是近距离区域过拟合和远距离区域欠拟合。作者明确识别了这两类失败模式。

Method: 作者提出了统一的D$^2$GS框架，包括两大核心组件：（1）基于深度和密度引导的Dropout策略，有效抑制对摄像头附近冗余高斯点的过拟合；（2）距离感知的保真增强模块，通过特别的监督机制提升远距离区域的重建质量。此外，引入了一个新的评估标准，用于量化模型在稀疏视角条件下学习到的高斯分布的稳定性。

Result: 大量数据集实验表明，D$^2$GS在稀疏视角下，视图重建的视觉质量和鲁棒性都比现有方法有显著提升。

Conclusion: 该方法系统性地解决了3DGS在稀疏条件下的核心难题，并为该方向进一步研究提供了稳定性度量工具，具有重要实际和理论意义。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) enable real-time,
high-fidelity novel view synthesis (NVS) with explicit 3D representations.
However, performance degradation and instability remain significant under
sparse-view conditions. In this work, we identify two key failure modes under
sparse-view conditions: overfitting in regions with excessive Gaussian density
near the camera, and underfitting in distant areas with insufficient Gaussian
coverage. To address these challenges, we propose a unified framework D$^2$GS,
comprising two key components: a Depth-and-Density Guided Dropout strategy that
suppresses overfitting by adaptively masking redundant Gaussians based on
density and depth, and a Distance-Aware Fidelity Enhancement module that
improves reconstruction quality in under-fitted far-field areas through
targeted supervision. Moreover, we introduce a new evaluation metric to
quantify the stability of learned Gaussian distributions, providing insights
into the robustness of the sparse-view 3DGS. Extensive experiments on multiple
datasets demonstrate that our method significantly improves both visual quality
and robustness under sparse view conditions. The project page can be found at:
https://insta360-research-team.github.io/DDGS-website/.

</details>


### [102] [MATRIX: Multimodal Agent Tuning for Robust Tool-Use Reasoning](https://arxiv.org/abs/2510.08567)
*Tajamul Ashraf,Umair Nawaz,Abdelrahman M. Shaker,Rao Anwer,Philip Torr,Fahad Shahbaz Khan,Salman Khan*

Main category: cs.CV

TL;DR: 本论文提出了一种基于视觉语言模型（VLM）的智能体调优框架，通过自动合成多模态轨迹和生成偏好对，显著提升了VLM在复杂工具使用推理任务上的表现。作者构建了大规模数据集M-TRACE，并开发了MATRIX智能体，取得了领先效果。


<details>
  <summary>Details</summary>
Motivation: 当前VLM作为外部工具控制器应用广泛，但受限于高质量多模态轨迹数据的稀缺和人工标注成本高，影响了其在复杂推理和决策任务中的效能。该研究旨在自动化数据合成和调优过程，突破数据瓶颈，提升VLM实际应用表现。

Method: 1）自动合成多模态任务数据，构建M-TRACE数据集（28.5K任务，177K轨迹）；2）基于模仿学习，对VLM智能体（MATRIX）进行轨迹调优；3）设计Pref-X偏好对（11K对），采用分步偏好学习进一步调优模型。

Result: MATRIX智能体在Agent-X、GTA和GAIA三大基准测试上，性能均优于现有的开源和闭源VLM，实现了更高效、可扩展的多模态工具推理。

Conclusion: 通过自动化数据合成和分步偏好优化，实现了VLM智能体在复杂多模态推理任务中的有效提升，为后续多模态智能体训练和应用提供了可扩展的新范式。

Abstract: Vision language models (VLMs) are increasingly deployed as controllers with
access to external tools for complex reasoning and decision-making, yet their
effectiveness remains limited by the scarcity of high-quality multimodal
trajectories and the cost of manual annotation. We address this challenge with
a vision-centric agent tuning framework that automatically synthesizes
multimodal trajectories, generates step-wise preference pairs, and trains a VLM
controller for robust tool-use reasoning. Our pipeline first constructs
M-TRACE, a large-scale dataset of 28.5K multimodal tasks with 177K verified
trajectories, enabling imitation-based trajectory tuning. Building on this, we
develop MATRIX Agent, a controller finetuned on M-TRACE for step-wise tool
reasoning. To achieve finer alignment, we further introduce Pref-X, a set of
11K automatically generated preference pairs, and optimize MATRIX on it via
step-wise preference learning. Across three benchmarks, Agent-X, GTA, and GAIA,
MATRIX consistently surpasses both open- and closed-source VLMs, demonstrating
scalable and effective multimodal tool use. Our data and code is avaliable at
https://github.com/mbzuai-oryx/MATRIX.

</details>


### [103] [ReSplat: Learning Recurrent Gaussian Splats](https://arxiv.org/abs/2510.08575)
*Haofei Xu,Daniel Barath,Andreas Geiger,Marc Pollefeys*

Main category: cs.CV

TL;DR: 本文提出了一种名为ReSplat的递归高斯点云渲染模型，通过迭代方式在不显式计算梯度的情况下优化3D高斯渲染，显著提升渲染效率与精度。


<details>
  <summary>Details</summary>
Motivation: 传统的前馈型高斯点云渲染模型尽管计算高效，但其推断阶段仅依赖单步前向传递，导致在精度和泛化能力上受到限制。作者希望突破这一性能瓶颈，提升模型对稀疏输入和不同数据分布的泛化能力。

Method: 作者引入了递归结构的高斯渲染网络，通过渲染误差作为反馈信号，引导网络迭代优化高斯参数，无需计算梯度。同时设计了低分辨率紧凑型重建模型用于初始高斯生成，极大减少了高斯点数和计算开销。

Result: 实验在不同输入视角、分辨率和数据集（如DL3DV、RealEstate10K）上均显示，所提方法在减少高斯数量和提升渲染速度的同时，实现了当前最优的渲染性能。

Conclusion: ReSplat模型以反馈信号驱动迭代优化，兼顾了效率与效果，在3D高斯渲染领域实现了新突破，具备良好的泛化能力和推广前景。

Abstract: While feed-forward Gaussian splatting models provide computational efficiency
and effectively handle sparse input settings, their performance is
fundamentally limited by the reliance on a single forward pass during
inference. We propose ReSplat, a feed-forward recurrent Gaussian splatting
model that iteratively refines 3D Gaussians without explicitly computing
gradients. Our key insight is that the Gaussian splatting rendering error
serves as a rich feedback signal, guiding the recurrent network to learn
effective Gaussian updates. This feedback signal naturally adapts to unseen
data distributions at test time, enabling robust generalization. To initialize
the recurrent process, we introduce a compact reconstruction model that
operates in a $16 \times$ subsampled space, producing $16 \times$ fewer
Gaussians than previous per-pixel Gaussian models. This substantially reduces
computational overhead and allows for efficient Gaussian updates. Extensive
experiments across varying of input views (2, 8, 16), resolutions ($256 \times
256$ to $540 \times 960$), and datasets (DL3DV and RealEstate10K) demonstrate
that our method achieves state-of-the-art performance while significantly
reducing the number of Gaussians and improving the rendering speed. Our project
page is at https://haofeixu.github.io/resplat/.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [104] [Inconsistent Affective Reaction: Sentiment of Perception and Opinion in Urban Environments](https://arxiv.org/abs/2510.07359)
*Jingfei Huang,Han Tu*

Main category: cs.CL

TL;DR: 本文通过大规模街景图像与社交媒体文本，分析了北京二环地区2016年与2022年间人们对城市环境的感知与舆论之间的情感不一致性。


<details>
  <summary>Details</summary>
Motivation: 传统城市情感分析方法难以捕捉人们对城市环境多维、变化的情感反应，亟需通过新方法揭示感知与舆论之间的差异，以指导更精准的城市管理。

Method: 构建包含140,750张百度与腾讯街景图像与984,024条微博文本的数据集，结合目标检测与自然语言处理，开发反应指数衡量情感，利用回归分析、图像分割和词频分析，按土地利用分布展开空间情感研究。

Result: 发现2016至2022年间城市感知情感趋于更均匀分布的正向态势，而舆论情感则更加极端，且二者间存在显著不一致。密集楼宇及行人出现等城市要素与情感变化相关。

Conclusion: 分析结果揭示城市感知与舆论情感的不一致性，为疫情前后城市管理与更新策略的制定提供有价值的参考和解释。

Abstract: The ascension of social media platforms has transformed our understanding of
urban environments, giving rise to nuanced variations in sentiment reaction
embedded within human perception and opinion, and challenging existing
multidimensional sentiment analysis approaches in urban studies. This study
presents novel methodologies for identifying and elucidating sentiment
inconsistency, constructing a dataset encompassing 140,750 Baidu and Tencent
Street view images to measure perceptions, and 984,024 Weibo social media text
posts to measure opinions. A reaction index is developed, integrating object
detection and natural language processing techniques to classify sentiment in
Beijing Second Ring for 2016 and 2022. Classified sentiment reaction is
analysed and visualized using regression analysis, image segmentation, and word
frequency based on land-use distribution to discern underlying factors. The
perception affective reaction trend map reveals a shift toward more evenly
distributed positive sentiment, while the opinion affective reaction trend map
shows more extreme changes. Our mismatch map indicates significant disparities
between the sentiments of human perception and opinion of urban areas over the
years. Changes in sentiment reactions have significant relationships with
elements such as dense buildings and pedestrian presence. Our inconsistent maps
present perception and opinion sentiments before and after the pandemic and
offer potential explanations and directions for environmental management, in
formulating strategies for urban renewal.

</details>


### [105] [Haystack Engineering: Context Engineering for Heterogeneous and Agentic Long-Context Evaluation](https://arxiv.org/abs/2510.07414)
*Mufei Li,Dongqi Fu,Limei Wang,Si Zhang,Hanqing Zeng,Kaan Sancak,Ruizhong Qiu,Haoyu Wang,Xiaoxin He,Xavier Bresson,Yinglong Xia,Chonglin Sun,Pan Li*

Main category: cs.CL

TL;DR: 本文引入了HaystackCraft，一个用于测试大模型在真实复杂长上下文环境中鲁棒性的基准，弥补了传统“needle-in-a-haystack”测试忽略检索偏差和代理性任务噪声的不足。结果显示当前大模型仍难以处理更复杂的干扰与任务自驱错误。


<details>
  <summary>Details</summary>
Motivation: 传统的长上下文测试如NIAH过于理想化，忽略了现实检索系统中的噪音和代理型任务中的错误积累。为更真实反映实际应用场景，作者提出需要设计更复杂、带有检索偏差和任务级误差的“草堆”（噪声上下文），以评估模型鲁棒性。

Method: 提出HaystackCraft基准，基于英文维基百科超链接网络和多跳问题，利用稀疏、密集、混合、图结构等多种检索方式构造复杂干扰上下文，并模拟模型自驱操作流程（如自我反思、中止决策等）来测试模型真实场景下的处理能力。

Result: 1）更强的密集检索器带来更多具挑战性的干扰项，但图结构重排序能提升检索效果并缓和干扰。2）在代理型流程中，即使顶尖模型如Gemini 2.5 Pro、GPT-5也会因自造干扰或无法及时停止而发生连锁失败。

Conclusion: 现实长上下文任务依然存在模型鲁棒性和自主推理上的重大挑战，HaystackCraft构建了更贴近实际问题的测试场景，为后续研究和模型改进提供了有效平台。

Abstract: Modern long-context large language models (LLMs) perform well on synthetic
"needle-in-a-haystack" (NIAH) benchmarks, but such tests overlook how noisy
contexts arise from biased retrieval and agentic workflows. We argue that
haystack engineering is necessary to construct noisy long contexts that
faithfully capture key real-world factors -- distraction from heterogeneous
biased retrievers and cascading errors in agentic workflows -- to test models'
long-context robustness. We instantiate it through HaystackCraft, a new NIAH
benchmark built on the full English Wikipedia hyperlink network with multi-hop
questions. HaystackCraft evaluates how heterogeneous retrieval strategies
(e.g., sparse, dense, hybrid, and graph-based) affect distractor composition,
haystack ordering, and downstream LLM performance. HaystackCraft further
extends NIAH to dynamic, LLM-dependent settings that simulate agentic
operations, where models refine queries, reflect on their past reasonings, and
decide when to stop. Experiments with 15 long-context models show that (1)
while stronger dense retrievers can introduce more challenging distractors,
graph-based reranking simultaneously improves retrieval effectiveness and
mitigates more harmful distractors; (2) in agentic tests, even advanced models
like Gemini 2.5 Pro and GPT-5 suffer cascading failures from self-generated
distractors or struggle to perform early stops. These results highlight
persistent challenges in agentic long-context reasoning and establish
HaystackCraft as a valuable testbed for future progress.

</details>


### [106] [Lemma Dilemma: On Lemma Generation Without Domain- or Language-Specific Training Data](https://arxiv.org/abs/2510.07434)
*Olia Toporkov,Alan Akbik,Rodrigo Agerri*

Main category: cs.CL

TL;DR: 本文研究大语言模型（LLMs）在词形还原任务中的性能，发现在无监督训练数据时，LLMs通过上下文学习能够达到甚至超越以往方法的效果。


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs在多种NLP任务上表现出色，但其在具体上下文词形还原任务上的能力尚无系统研究。词形还原尤其困难在某些领域或语言缺乏标注数据时，因此有必要探索LLMs在无监督、跨语言或领域适应性上的潜力。

Method: 作者以12种形态复杂性不同的语言为对象，比较了传统监督式编码器（即有监督、跨领域微调）、跨语言方法及LLMs基于少量示例的直接上下文词形还原能力。无监督情况下，给予LLMs少量示例，观察其上下文词形还原效果，并与传统方法对比。

Result: 实验表明，虽然经过微调的编码器在没有目标领域数据时仍然表现不俗，但只要给LLMs提供少量示例，它们便能在多数语言上实现甚至优于传统方法的结果。

Conclusion: 当前LLMs无需对目标语言做特别微调，仅凭少量上下文示例就能高效完成词形还原，达到最新水平，对低资源/跨语言情景下的NLP任务具有重要价值。

Abstract: Lemmatization is the task of transforming all words in a given text to their
dictionary forms. While large language models (LLMs) have demonstrated their
ability to achieve competitive results across a wide range of NLP tasks, there
is no prior evidence of how effective they are in the contextual lemmatization
task. In this paper, we empirically investigate the capacity of the latest
generation of LLMs to perform in-context lemmatization, comparing it to the
traditional fully supervised approach. In particular, we consider the setting
in which supervised training data is not available for a target domain or
language, comparing (i) encoder-only supervised approaches, fine-tuned
out-of-domain, and (ii) cross-lingual methods, against direct in-context lemma
generation with LLMs. Our experimental investigation across 12 languages of
different morphological complexity finds that, while encoders remain
competitive in out-of-domain settings when fine-tuned on gold data, current
LLMs reach state-of-the-art results for most languages by directly generating
lemmas in-context without prior fine-tuning, provided just with a few examples.
Data and code available upon publication:
https://github.com/oltoporkov/lemma-dilemma

</details>


### [107] [LASER: An LLM-based ASR Scoring and Evaluation Rubric](https://arxiv.org/abs/2510.07437)
*Amruta Parulekar,Preethi Jyothi*

Main category: cs.CL

TL;DR: 本文提出LASER评分体系，利用先进的LLM模型改进ASR系统评估标准，更公平地反映语音识别质量，尤其在多语言环境下展现优良表现。


<details>
  <summary>Details</summary>
Motivation: 传统的语音识别（ASR）评估指标如词错误率（WER）会过度惩罚某些不影响语句语义的形态或句法差异，导致评估不够公平。因此需要引入新方法，更合理地评价ASR输出的语义准确性。

Method: 提出使用LLM驱动的LASER评分体系，基于先进大模型（如Gemini 2.5 Pro）的上下文学习能力，通过详细的提示例子进行训练。进一步地，采用精炼后的小型LLM（如Llama 3）在词对样本上微调，实现自动化、可泛化的语音输出评估。

Result: 用Gemini 2.5 Pro针对印地语的LASER评分与人工标注的相关系数高达94%，并能有效扩展至马拉地语、卡纳达语和马拉雅拉姆语等其他印度语言。细化模型Llama 3也能通过训练实现近89%的分类准确率。

Conclusion: LLM驱动的LASER体系能更准确且公平地评估ASR系统输出，尤其在多语言场景下表现优异，并具备模型扩展和参数精简的灵活性，显著优于传统WER指标。

Abstract: Standard ASR evaluation metrics like Word Error Rate (WER) tend to unfairly
penalize morphological and syntactic nuances that do not significantly alter
sentence semantics. We introduce an LLM-based scoring rubric LASER that
leverages state-of-the-art LLMs' in-context learning abilities to learn from
prompts with detailed examples. Hindi LASER scores using Gemini 2.5 Pro
achieved a very high correlation score of 94% with human annotations. Hindi
examples in the prompt were also effective in analyzing errors in other Indian
languages such as Marathi, Kannada and Malayalam. We also demonstrate how a
smaller LLM like Llama 3 can be finetuned on word-pair examples derived from
reference and ASR predictions to predict what kind of penalty should be applied
with close to 89% accuracy.

</details>


### [108] [Meaningful Pose-Based Sign Language Evaluation](https://arxiv.org/abs/2510.07453)
*Zifan Jiang,Colin Leong,Amit Moryossef,Anne Göhring,Annette Rios,Oliver Cory,Maksym Ivashechkin,Neha Tarigopula,Biao Zhang,Rico Sennrich,Sarah Ebling*

Main category: cs.CL

TL;DR: 本文系统评估了手语姿态的评价方法，比较了不同指标，在不同情境下的优劣，并提供了开源工具。


<details>
  <summary>Details</summary>
Motivation: 现有的手语翻译和生成系统在自动评价时缺乏标准化、综合性的指标。单纯采用某种评价指标难以全面反映系统性能，因此需要对各种评价方法进行系统性研究，以推动手语生成与翻译技术的发展。

Method: 本文对基于关键点距离、嵌入（embedding）和反向翻译（back-translation）三类指标进行了对比与评测，采用自动meta评价和人工相关性分析，涵盖多种手语语言背景。

Result: 研究揭示了不同指标在不同使用场景下的取舍关系，实验和相关性分析说明各类方法在性能、适用性、有用性等方面的异同。

Conclusion: 作者开发了开源的姿态评估工具包，为手语翻译和生成系统的开发、测试、复现提供了有效手段，有助于后续研究的规范化与进步。

Abstract: We present a comprehensive study on meaningfully evaluating sign language
utterances in the form of human skeletal poses. The study covers keypoint
distance-based, embedding-based, and back-translation-based metrics. We show
tradeoffs between different metrics in different scenarios through automatic
meta-evaluation of sign-level retrieval and a human correlation study of
text-to-pose translation across different sign languages. Our findings and the
open-source pose-evaluation toolkit provide a practical and reproducible way of
developing and evaluating sign language translation or generation systems.

</details>


### [109] [Populism Meets AI: Advancing Populism Research with LLMs](https://arxiv.org/abs/2510.07458)
*Eduardo Ryô Tamaki,Yujin J. Jung,Julia Chatterley,Grant Mitchell,Semir Dzebo,Cristóbal Sandoval,Levente Littvay,Kirk A. Hawkins*

Main category: cs.CL

TL;DR: 本文提出了一种结合评分准则和链式思维（CoT）提示的大语言模型（LLM）方法，以自动分析和识别文本中的民粹主义内容。通过与全球民粹主义数据库中的人工标注结果对比，发现该方法在准确度上可媲美专家人工分类。


<details>
  <summary>Details</summary>
Motivation: 民粹主义意识形态内容的测量一直具有挑战性。传统文本分析虽然有效但成本高昂、费时且难以适用于多种语言和大样本数据集。因此，需要一种低成本、高效率、可扩展且准确的新方法来测量民粹主义内容。

Method: 作者借助全球民粹主义数据库（GPD）和人工标注文档，设计出一种基于评分准则和链式思维提示的大语言模型提示方法，让模型仿照人类编码员的训练和判别流程。利用多种专有和开源大语言模型，复现GPD中的打分过程并进行对比验证。

Result: 实验结果显示，通过特定领域的Prompt设计，LLM的分类准确率与专家人工编码员相当，能有效把握民粹主义的细微与情境敏感特征。

Conclusion: 基于评分准则和链式思维提示的大语言模型可以作为一种高效、可扩展且准确的民粹主义文本内容分析工具，为相关政治学研究提供有力支持。

Abstract: Measuring the ideational content of populism remains a challenge. Traditional
strategies based on textual analysis have been critical for building the
field's foundations and providing a valid, objective indicator of populist
framing. Yet these approaches are costly, time consuming, and difficult to
scale across languages, contexts, and large corpora. Here we present the
results from a rubric and anchor guided chain of thought (CoT) prompting
approach that mirrors human coder training. By leveraging the Global Populism
Database (GPD), a comprehensive dataset of global leaders' speeches annotated
for degrees of populism, we replicate the process used to train human coders by
prompting the LLM with an adapted version of the same documentation to guide
the model's reasoning. We then test multiple proprietary and open weight models
by replicating scores in the GPD. Our findings reveal that this domain specific
prompting strategy enables the LLM to achieve classification accuracy on par
with expert human coders, demonstrating its ability to navigate the nuanced,
context sensitive aspects of populism.

</details>


### [110] [MAPRO: Recasting Multi-Agent Prompt Optimization as Maximum a Posteriori Inference](https://arxiv.org/abs/2510.07475)
*Zheyuan Zhang,Lin Ge,Hongjiang Li,Weicheng Zhu,Chuxu Zhang,Yanfang Ye*

Main category: cs.CL

TL;DR: 本文提出了一种新的多智能体提示优化框架MAPRO，利用概率推理和反馈机制，显著提升了多智能体大模型系统的表现。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统能通过角色分工实现优于单体系统的表现，但其优化面临提示敏感性高、不稳定和搜索空间大等难题，尤其是多智能体间提示分配与优化基本没有被系统解决。

Method: 作者提出MAPRO框架，将多智能体提示优化建模为最大后验推断问题，并结合语言引导的max-product置信传播算法，配合拓扑感知的反馈调整机制，能够有效分配责任并逐步优化各智能体的提示策略。

Result: 在多项基准测试和任务上，MAPRO均取得了比人工设计和现有自动化方案更好的效果，实现了最新最好（state-of-the-art）的表现。

Conclusion: MAPRO不仅提升了现有多智能体系统的性能，还为今后更稳定、系统化地搭建多智能体提供了通用方法论和指导原则。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across
diverse tasks, and LLM-based agents further extend these abilities to various
practical workflows. While recent progress shows that multi-agent systems (MAS)
can outperform single agents by coordinating specialized roles, designing
effective MAS remains difficult due to prompt sensitivity and the compounded
instability MAS creates. To cope with the challenge, recent efforts in
automated prompt design have reduced manual effort. However, multi-agent prompt
optimization remains largely unexplored. Challenges like exponentially
expanding search space and ambiguous credit assignment together make systematic
design intractable without principled methods. Therefore, we introduce
M}ulti-Agent PRompt Optimization (MAPRO), a four-stage framework that first
formulates MAS prompt optimization as a Maximum a Posteriori (MAP) inference
problem and solves it using a language-guided variant of max-product belief
propagation algorithm. To address credit assignment and updates the system
iteratively, MAPRO employs a topology-aware refinement mechanism that
integrates execution feedback and downstream blames to selectively update agent
prompts. Through this process, MAPRO progressively converges to a coordinated
set of agent-specific prompt policies. Across benchmarks in various tasks,
MAPRO achieves state-of-the-art performance, consistently surpassing manually
engineered baselines and recent automated alternatives. Beyond performance, our
MAP-based formulation also delivers general guidelines for building more
reliable and principled multi-agent systems in the future

</details>


### [111] [AsyncSpade: Efficient Test-Time Scaling with Asynchronous Sparse Decoding](https://arxiv.org/abs/2510.07486)
*Shuqing Luo,Yilin Guan,Pingzhi Li,Hanrui Wang,Tianlong Chen*

Main category: cs.CL

TL;DR: AsyncSpade是一种针对推理任务下LLM高效解码的新异步稀疏技术，显著减少KV-Cache相关的延迟和显存压力，同时保证了输出准确性。


<details>
  <summary>Details</summary>
Motivation: 长链思维（CoT）推理需要LLM一次生成大量token，但随着token增长，KV-Cache显存和推理延迟爆炸式增加，成为实际服务部署的瓶颈。尽管已有稀疏解码方法缓解部分问题，但往往因顺序依赖和token选择粒度粗糙影响性能，且在高并发长文本下实际效率提升有限。

Method: AsyncSpade提出异步KV-Cache管理，包括：1）利用新的时序回归模块预测当前解码步的query状态，仅需查看最近少量token，实现训练外稀疏过滤；2）将KV-Cache筛选操作异步、解耦于传统的自回归推理流程，使token选取与前向计算并行，极大提升利用率，克服顺序依赖问题。

Result: 在A100节点的主流LLM服务环境下，AsyncSpade可将KV-Cache相关操作与主推理完全重叠，理论上达成最优单位输出token时延（TPOT）。在Qwen3系列验证中，对比最优已有算法Quest，AsyncSpade TPOT降低20%以上，对比原始全注意力机制降低至少50%，在多项推理基准上准确率不降反升。

Conclusion: AsyncSpade首次在推理服务端彻底打破KV-Cache管理的顺序依赖，在提升模型服务吞吐/效率的同时，保持甚至提升推理准确率，对LLM大规模推理部署具有重要意义。

Abstract: Test-time scaling (TTS) boosts LLM reasoning via long chain-of-thought (CoT),
but the linear KV-cache growth amplifies the memory-bound bottleneck of LLM
decoding. Query-aware page-level sparse decoding can achieve state-of-the-art
performance under constrained FLOPs budgets, but is limited by both
sequential-dependent page filtering and coarse-grained token selection,
hampering serving efficiency and model performance on TTS tasks under high
concurrency and long CoT scenarios (consuming even higher runtime than the
forward pipeline itself). In this paper, we first find that the current-step
query state can be accurately approximated in a unified manner from a short
window of recent queries, enabling training-free query-aware sparsity without
waiting in the decoding loop. We propose AsyncSpade, an asynchronous framework
for efficient TTS built on two core components: (1) a novel light-weight
temporal-regressive module that predicts the next-token query state; (2) an
asynchronous and disaggregated framework that decouples the KV cache filtering
from the auto-regressive decoding loop, overlapping the token-level KV
selection with the forward inference computation through asynchronism. To our
knowledge, AsyncSpade is the first to eliminate the sequential dependence
without sacrificing model performance. We validate the effectiveness of
AsyncSpade on common LLM serving setups with an A100 node, where AsyncSpade
fully overlaps KV-cache operations with the inference pipeline, achieving
theoretical optimal time-per-output-token (TPOT). Specifically, AsyncSpade
delivers over 20% reduction on TPOT compared to SoTA baseline (i.e. Quest) and
at least 50% TPOT reduction compared to full attention on Qwen3-8B and
Qwen3-32B models, while matching or surpassing their accuracy on various TTS
benchmarks (AIME-24/25, GPQA-Diamond, MATH-500).

</details>


### [112] [Can Lessons From Human Teams Be Applied to Multi-Agent Systems? The Role of Structure, Diversity, and Interaction Dynamics](https://arxiv.org/abs/2510.07488)
*Rasika Muralidharan,Jaewoon Kwak,Jisun An*

Main category: cs.CL

TL;DR: 本论文提出了一个多智能体系统框架，借鉴了人类团队科学，分析大型语言模型驱动的智能体团队的结构、多样性和交互动态，并在多个任务上评估团队表现。结果显示，扁平团队优于层级团队，多样性影响较复杂，并揭示了智能体协作中的挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM驱动的多智能体系统日益受到关注，但关于其团队动态的研究较少。论文受人类团队科学启发，旨在深入理解和提升AI团队的协作机制和表现。

Method: 作者设计了一个多智能体团队框架，系统考察团队的结构（扁平vs层级）、多样性以及成员交互动态。在CommonsenseQA、StrategyQA、Social IQa和Latent Implicit Hate四项任务上评估各类团队的表现，并通过访谈分析团队成员的协作体验。

Result: 扁平团队的任务表现整体优于层级团队；团队多样性带来的影响较为细致复杂。访谈显示智能体倾向过于自信，对合作既有正面反馈也有整合困难，主要包括交流协调能力有限等问题。

Conclusion: 本研究证实了扁平结构优于层级结构，同时强调团队多样性的复杂作用。智能体团队在合作中表现出欣赏合作但面临挑战，需进一步提升交流和协调机制，以促进AI团队高效协作。

Abstract: Multi-Agent Systems (MAS) with Large Language Model (LLM)-powered agents are
gaining attention, yet fewer studies explore their team dynamics. Inspired by
human team science, we propose a multi-agent framework to examine core aspects
of team science: structure, diversity, and interaction dynamics. We evaluate
team performance across four tasks: CommonsenseQA, StrategyQA, Social IQa, and
Latent Implicit Hate, spanning commonsense and social reasoning. Our results
show that flat teams tend to perform better than hierarchical ones, while
diversity has a nuanced impact. Interviews suggest agents are overconfident
about their team performance, yet post-task reflections reveal both
appreciation for collaboration and challenges in integration, including limited
conversational coordination.

</details>


### [113] [Can Speech LLMs Think while Listening?](https://arxiv.org/abs/2510.07497)
*Yi-Jen Shih,Desh Raj,Chunyang Wu,Wei Zhou,SK Bong,Yashesh Gaur,Jay Mahadeokar,Ozlem Kalinli,Mike Seltzer*

Main category: cs.CL

TL;DR: 本文探讨了通过引入chain-of-thought（CoT）微调提升语音大模型（speech LLMs）在复杂推理任务中的表现，并提出了一种减少推理延迟的新方法，从而有效平衡交互准确性与响应速度。


<details>
  <summary>Details</summary>
Motivation: 虽然语音大模型在语音交互领域取得进展，但其在复杂推理（reasoning）任务方面表现仍不理想。现有研究证明，在文本LLM中引入CoT提升了推理能力。因此，本文动机是在语音LLM中引入和优化CoT机制，以兼顾提升准确率与降低语音系统响应延迟。

Method: 1. 在多流语音LLM上引入CoT微调，通过训练提升模型推理能力。
2. 设计了一种基于熵的“问题完成度”指标，允许模型在用户语音提问尚未结束时提前介入推理，减小因CoT带来的延迟。
3. 利用Direct Preference Optimization（DPO）基于偏好数据（由拒绝采样生成）进一步优化模型，实现更优的准确率—延迟权衡。

Result: 在一系列语音推理任务上，引入CoT后模型平均准确率提升至原来的2.4倍。在延迟控制方面，新的“问题完成度”方法相比启发式方法，在相同延迟下ARC-Easy任务准确率提升4%。引入DPO后，模型在准确率无损的前提下，延迟降低了70%。

Conclusion: 将CoT与基于“问题完成度”的推理时机控制结合，有效提升了语音LLM推理任务的性能。DPO策略进一步推动了准确率和延迟的极值平衡，这对未来高效智能语音交互系统具有重要意义。

Abstract: Recent advances in speech large language models (speech LLMs) have enabled
seamless spoken interactions, but these systems still struggle with complex
reasoning tasks. Previously, chain-of-thought (CoT) prompting or fine-tuning
has been to shown to significantly improve the reasoning abilities of
text-based LLMs. In this work, we investigate the effect of CoT fine-tuning for
multi-stream speech LLMs, demonstrating that reasoning in text space improves
the accuracy of speech LLMs by 2.4x, on average, over a suite of spoken
reasoning tasks. Beyond accuracy, the latency of the spoken response is a
crucial factor for interacting with voice-based agents. Inspired by the human
behavior of "thinking while listening," we propose methods to reduce the
additional latency from reasoning by allowing the model to start reasoning
before the user query has ended. To achieve this, we introduce an entropy-based
metric, "question completeness," which acts as an indicator to guide the model
on the optimal time to start reasoning. This method provides greater control
over the accuracy-latency trade-off compared with heuristic-based approaches
and, under equivalent latency conditions, yields a 4% accuracy gain on
ARC-Easy. Finally, we use Direct Preference Optimization (DPO) on preference
data created using rejection sampling to push the accuracy-latency pareto
frontier further, resulting in a 70% reduction in latency without loss in
accuracy.

</details>


### [114] [When Thoughts Meet Facts: Reusable Reasoning for Long-Context LMs](https://arxiv.org/abs/2510.07499)
*Soyeong Jeong,Taehee Jung,Sung Ju Hwang,Joo-Kyung Kim,Dongyeop Kang*

Main category: cs.CL

TL;DR: 本文提出了一种结合思维模板（thought templates）的方法，用于增强长上下文语言模型（LCLMs）在处理多跳推理任务时的信息组织与推理能力，并验证了其在多项基准上的有效性。


<details>
  <summary>Details</summary>
Motivation: 虽然LCLMs能够在一次输入中处理大量文档，理论上促进多跳推理和知识密集型任务，但单纯堆叠文档并不能高效组织和链接证据，存在推理链条难以建立与优化的问题。本研究旨在解决这一“证据连接”与“推理结构组织”的瓶颈。

Method: 作者提出“思维模板”作为推理的可复用缓存，利用以往问题解决轨迹抽取模板，指导事实文档的多跳推理。引入基于自然语言反馈的迭代优化机制，以持续提升模板质量。该方法适用于检索型（retrieval-based）和非检索型（retrieval-free）情境，并支持迁移到小型开源模型。

Result: 实验证明，无论在多种LCLM模型还是不同任务基准上，思维模板方法都优于现有强基线。在小模型蒸馏任务中，也能保持推理能力和透明性。

Conclusion: 所提ToTAL框架能够高效促进LCLMs结构化推理，提升复杂长文本条件下的多跳推理表现，实现了通用性、可扩展性和推理过程的透明化。

Abstract: Recent Long-Context Language Models (LCLMs) can process hundreds of thousands
of tokens in a single prompt, enabling new opportunities for
knowledge-intensive multi-hop reasoning by integrating large sets of retrieved
documents or, in some cases, directly all necessary information. However,
simply feeding more documents into the context window fails to capture how
evidence should be connected. We address this gap with thought templates, which
recast reasoning as reusable thought caches, derived from prior problem solving
traces, structuring how evidence is combined and guiding multi-hop inference
with factual documents. To keep these templates effective, we propose an update
strategy that iteratively refines templates derived from training data through
natural-language feedback. Across diverse benchmarks and LCLM families, our
approach delivers consistent gains over strong baselines in both
retrieval-based and retrieval-free settings. Furthermore, we show that
optimized templates can be distilled into smaller open-source models,
demonstrating its broad applicability and transparent reasoning reuse. We refer
to our framework as Thought Template Augmented LCLMs (ToTAL).

</details>


### [115] [ParsTranslit: Truly Versatile Tajik-Farsi Transliteration](https://arxiv.org/abs/2510.07520)
*Rayyan Merchant,Kevin Tang*

Main category: cs.CL

TL;DR: 本文提出了一种新的最先进的塔吉克-波斯文转写序列到序列模型，并在所有公开可用的数据集及新构建的两个数据集上进行了训练和评测。


<details>
  <summary>Details</summary>
Motivation: 现有塔吉克-波斯文转写模型通常受限于自建数据集，导致模型泛化能力差、难以适应现实多领域应用，同时现有评测未能全面反映任务难度。

Method: 作者构建并整合多个数据集，包括两个自建的数据集，采用最新的序列到序列深度学习模型进行塔吉克文与波斯文（Perso-Arabic与Tajik-Cyrillic脚本）之间的双向转写。

Result: 模型在不同领域的数据集上均实现了领先的性能。具体地，从波斯文转塔吉克文实现了chrF++=87.91、Normalized CER=0.05，从塔吉克文转波斯文达到chrF++=92.28、Normalized CER=0.04。

Conclusion: 提出的转写模型在多领域、全数据集条件下设立了综合性领先基准，提高了实际应用的转写效果，为今后该方向的模型和评测提供了可靠的参考。

Abstract: As a digraphic language, the Persian language utilizes two written standards:
Perso-Arabic in Afghanistan and Iran, and Tajik-Cyrillic in Tajikistan. Despite
the significant similarity between the dialects of each country, script
differences prevent simple one-to-one mapping, hindering written communication
and interaction between Tajikistan and its Persian-speaking ``siblings''. To
overcome this, previously-published efforts have investigated machine
transliteration models to convert between the two scripts. Unfortunately, most
efforts did not use datasets other than those they created, limiting these
models to certain domains of text such as archaic poetry or word lists. A truly
usable transliteration system must be capable of handling varied domains,
meaning that suck models lack the versatility required for real-world usage.
The contrast in domain between data also obscures the task's true difficulty.
We present a new state-of-the-art sequence-to-sequence model for Tajik-Farsi
transliteration trained across all available datasets, and present two datasets
of our own. Our results across domains provide clearer understanding of the
task, and set comprehensive comparable leading benchmarks. Overall, our model
achieves chrF++ and Normalized CER scores of 87.91 and 0.05 from Farsi to Tajik
and 92.28 and 0.04 from Tajik to Farsi. Our model, data, and code are available
at https://anonymous.4open.science/r/ParsTranslit-FB30/.

</details>


### [116] [OWL: Overcoming Window Length-Dependence in Speculative Decoding for Long-Context Inputs](https://arxiv.org/abs/2510.07535)
*Jaeseong Lee,seung-won hwang,Aurick Qiao,Gabriele Oliaro,Ye Wang,Samyam Rajbhandari*

Main category: cs.CL

TL;DR: 本论文提出了针对大语言模型（LLMs）推理加速的OWL模型及长上下文评测集LongSpecBench，显著提升了长文本下的生成效率。


<details>
  <summary>Details</summary>
Motivation: 现有的speculative decoding加速方法在实际应用中的长文本场景下表现不佳，生成速度甚至下降，急需能够广泛适用于长上下文的新方法。

Method: 作者提出了OWL模型，包括以下创新：（1）基于LSTM的drafter仅使用最后一个token隐状态，利于泛化不同长度输入；（2）引入[SPEC]特殊token强化drafter与verifier的信息交互；（3）结合树形和非树形解码的混合算法。此外，作者还构建了一个新的长上下文评测集LongSpecBench来系统性评估模型。

Result: 实验表明，OWL在长上下文输入下可达到约EAGLE3（代表性方法）5倍的接受长度，并显著加速推理速度，而EAGLE3等现有方法在长文本下反而变慢。

Conclusion: OWL方法和LongSpecBench为研究和应用大语言模型的推理加速提供了新的基准和技术方案，突破了长文本场景下的性能瓶颈，相关代码与数据已公开促进社区发展。

Abstract: Speculative decoding promises faster inference for large language models
(LLMs), yet existing methods fail to generalize to real-world settings.
Benchmarks typically assume short contexts (e.g., 2K tokens), whereas practical
workloads involve long contexts. We find current approaches degrade severely
with long contexts; for instance, EAGLE3 even slows down the generation speed
by 0.81x. We address these limitations by releasing a new long-context
benchmark (LongSpecBench) and introducing a novel model (OWL). OWL achieves
about 5x higher acceptance length than EAGLE3 on long-context inputs through
three innovations: (1) an LSTM-based drafter conditioned only on the last-token
state, making it generalize to various lengths, (2) a special token [SPEC] in
the verifier that produces richer representation for drafter, and (3) a hybrid
algorithm combining both tree and non-tree decoding methods. We release all
code and datasets to advance future research.

</details>


### [117] [Deploying Tiny LVLM Judges for Real-World Evaluation of Chart Models: Lessons Learned and Best Practices](https://arxiv.org/abs/2510.07545)
*Md Tahmid Rahman Laskar,Mohammed Saidul Islam,Ridwan Mahbub,Mizanur Rahman,Amran Bhuiyan,Israt Jahan,Mir Tafseer Nayeem,Shafiq Joty,Enamul Hoque,Jimmy Huang*

Main category: cs.CL

TL;DR: 本文针对小规模（<=2B参数量）视觉-语言大模型（LVLMs）在图表理解任务中评判能力不足的问题，提出多准则提示和领域自适应迁移学习两种低成本评估方法，并提出ChartJudge模型，实现了更有效且高效的评估。


<details>
  <summary>Details</summary>
Motivation: 当前自动化评判图表理解任务的主流方法依赖参数量较大的LVLMs，即使7B参数的模型表现已有进展，但在资源受限场景下，小模型依然准确率较低，实用性不足。因此需要探索在更低计算资源下实现高效准确评判的方法。

Method: 作者提出多准则提示（multi-criteria prompting），即将多个独立评判标准整合为单一查询，以及领域自适应迁移学习，即用合成数据对2B参数量的LVLM进行微调，得到ChartJudge模型，并在多数据集上评测其性能与泛化能力。

Result: 实验证明，多准则提示能揭示模型鲁棒性短板，7B参数模型性能明显下降，专用评判模型如LLaVA-Critic也不例外。同时，ChartJudge能从一个数据集迁移知识到另一个数据集，表现出更专业的评估能力。对于不同图表类型和问题复杂度的细致分析，揭示了模型规模、提示设计和可迁移性之间的权衡。

Conclusion: 通过该研究，可以实现高效、低成本且可扩展的图表推理任务自动评判。ChartJudge为小规模模型在资源受限场景下的实际应用提供了可行途径，相关代码和数据将开源推动领域发展。

Abstract: Large Vision-Language Models (LVLMs) with only 7B parameters have shown
promise as automated judges in chart comprehension tasks. However, tiny models
(<=2B parameters) still perform poorly as judges, limiting their real-world use
in resource-constrained settings. To address this, we propose two approaches to
ensure cost-efficient evaluation: (i) multi-criteria prompting, which combines
separate evaluation criteria into a single query, and (ii) domain-adaptive
transfer learning, in which we fine-tune a 2B-parameter LVLM on synthetic
judgments in a chart dataset to create the ChartJudge. Experiments show that
multi-criteria prompting exposes robustness gaps, which led to a huge drop in
performance for 7B models, including specialized LVLM judges like LLaVA-Critic.
In addition, we find that our tiny LVLM (ChartJudge) can effectively transfer
knowledge from one dataset to another to make it a more specialized model. Our
fine-grained analysis across chart types and query complexities offers
actionable insights into trade-offs between model size, prompt design, and
transferability, enabling scalable, low-cost evaluation for chart reasoning
tasks. Our code and the data will be made publicly available.

</details>


### [118] [Multi-Task Pre-Finetuning of Lightweight Transformer Encoders for Text Classification and NER](https://arxiv.org/abs/2510.07566)
*Junyi Zhu,Savas Ozkan,Andrea Maracani,Sinan Mutlu,Cho Jung Min,Mete Ozay*

Main category: cs.CL

TL;DR: 本文旨在提升轻量级BERT类似编码器在移动端NLP任务的适应性，通过提出基于任务主导LoRA模块的多任务预微调框架，在兼顾多应用适应性的同时，保证模型效率和性能。实验显示，该方法能在不额外增加计算和内存负担的情况下，有效提升命名实体识别和文本分类任务的表现。


<details>
  <summary>Details</summary>
Motivation: 移动平台部署NLP模型时，既要满足内存和计算效率，又需兼顾多种应用场景下的任务适应性。目前轻量级NLP模型往往在多任务适应性和效率之间难以权衡，因此需要新的预微调方法提升其多任务能力，同时满足实际部署需求。

Method: 作者分析常规预微调和多任务预微调的局限，提出基于任务主导LoRA模块的多任务预微调框架。该方法让一个共享编码器骨干与按任务分离的LoRA适配器结合，避免任务间冲突信号影响，增强不同下游任务的适应性和模型模块化部署。

Result: 在21个下游任务上进行实验，结果显示该方法对于命名实体识别（NER）平均提升0.8%，对于文本分类平均提升8.8%，在保证模型轻量高效的基础上，实现了多任务适应性提升，性能与单任务预微调持平甚至更优。

Conclusion: 提出的多任务预微调框架成功解决了多任务信号冲突问题，在移动端NLP模型的多领域适应性和部署效率之间取得了平衡，对实际应用具有较强指导意义。

Abstract: Deploying natural language processing (NLP) models on mobile platforms
requires models that can adapt across diverse applications while remaining
efficient in memory and computation. We investigate pre-finetuning strategies
to enhance the adaptability of lightweight BERT-like encoders for two
fundamental NLP task families: named entity recognition (NER) and text
classification. While pre-finetuning improves downstream performance for each
task family individually, we find that na\"ive multi-task pre-finetuning
introduces conflicting optimization signals that degrade overall performance.
To address this, we propose a simple yet effective multi-task pre-finetuning
framework based on task-primary LoRA modules, which enables a single shared
encoder backbone with modular adapters. Our approach achieves performance
comparable to individual pre-finetuning while meeting practical deployment
constraint. Experiments on 21 downstream tasks show average improvements of
+0.8% for NER and +8.8% for text classification, demonstrating the
effectiveness of our method for versatile mobile NLP applications.

</details>


### [119] [Linguistic Patterns in Pandemic-Related Content: A Comparative Analysis of COVID-19, Constraint, and Monkeypox Datasets](https://arxiv.org/abs/2510.07579)
*Mkululi Sikosana,Sean Maudsley-Barton,Oluwaseun Ajao*

Main category: cs.CL

TL;DR: 本研究通过计算语言学方法分析了疫情相关网络话语，比较了健康错误信息与事实传播在语言上的区别。结果表明，错误信息可读性较低，更常包含恐惧/劝说用语。此发现有助于健康信息甄别和传播策略。


<details>
  <summary>Details</summary>
Motivation: 疫情期间网络健康误信息泛滥，现有研究尚缺乏对其语言特征的细致刻画。作者希望通过语言学分析揭示误信息独特的表达方式，辅助误信息检测及危机传播理论建设。

Method: 采集三类文本（新冠误信息、新冠一般信息、猴痘帖子），应用计算语言学工具对其可读性、修辞标记和劝说性用语等特征进行对比分析，并统计相关差异。

Result: 新冠误信息文本的可读性明显较低，恐惧及劝说性词汇出现频率为其它数据集两倍以上，感叹号使用反而更少，其修辞风格较复杂且夹杂情感暗示。

Conclusion: 网络健康误信息倾向采用复杂修辞且嵌入情感暗示，或提高可信度。识别这些语言线索可帮助误信息自动检测和优化健康传播。作者亦指出方法受限于传统指标和语料范围，未来应拓展方法和时间维度以提升研究稳健性。

Abstract: This study conducts a computational linguistic analysis of pandemic-related
online discourse to examine how language distinguishes health misinformation
from factual communication. Drawing on three corpora: COVID-19 false narratives
(n = 7588), general COVID-19 content (n = 10700), and Monkeypox-related posts
(n = 5787), we identify significant differences in readability, rhetorical
markers, and persuasive language use. COVID-19 misinformation exhibited
markedly lower readability scores and contained over twice the frequency of
fear-related or persuasive terms compared to the other datasets. It also showed
minimal use of exclamation marks, contrasting with the more emotive style of
Monkeypox content. These patterns suggest that misinformation employs a
deliberately complex rhetorical style embedded with emotional cues, a
combination that may enhance its perceived credibility. Our findings contribute
to the growing body of work on digital health misinformation by highlighting
linguistic indicators that may aid detection efforts. They also inform public
health messaging strategies and theoretical models of crisis communication in
networked media environments. At the same time, the study acknowledges
limitations, including reliance on traditional readability indices, use of a
deliberately narrow persuasive lexicon, and reliance on static aggregate
analysis. Future research should therefore incorporate longitudinal designs,
broader emotion lexicons, and platform-sensitive approaches to strengthen
robustness.

</details>


### [120] [IASC: Interactive Agentic System for ConLangs](https://arxiv.org/abs/2510.07591)
*Chihiro Taguchi,Richard Sproat*

Main category: cs.CL

TL;DR: 本文提出了一个利用大语言模型（LLM）辅助开发人造语言（ConLang）的系统，涵盖从音系设计、句子形态句法标注、词典构建到书写系统指定与语法手册自动生成。


<details>
  <summary>Details</summary>
Motivation: 推动人造语言的创造乐趣，并借此探索LLM对语言结构和语言学概念的掌握程度，尤其关注其泛化与创新能力。

Method: 系统采用模块化流程：先用代理方法迭代生成目标音系，再将英语句子转为目标语的形态句法标注形式，进一步用这些数据结合音系模型构造词表，接着指定正字法（字母系统），最后让系统生成语法手册并支持更多句子的自动翻译。

Result: 不同LLM和不同语言结构的表现差异较大，对常见语言模式较易处理，罕见结构表现较弱；在高资源到低资源语言的自动翻译任务中成绩有限，但有改进空间。

Conclusion: 系统拓展了LLM在语言创造和理解上的应用潜力，为人造语言工具提供了新思路，也揭示了目前LLM对语言共性/变异处理的边界。

Abstract: We present a system that uses LLMs as a tool in the development of
Constructed Languages. The system is modular in that one first creates a target
phonology for the language using an agentic approach that refines its output at
each step with commentary feedback on its previous attempt. Next, a set of
sentences is 'translated' from their English original into a morphosyntactic
markup that reflects the word order and morphosyntactic feature specifications
of the desired target language, with affixes represented as morphosyntactic
feature bundles. From this translated corpus, a lexicon is constructed using
the phonological model and the set of morphemes (stems and affixes) extracted
from the 'translated' sentences. The system is then instructed to provide an
orthography for the language, using an existing script such as Latin or
Cyrillic. Finally, the system writes a brief grammatical handbook of the
language. The system can also translate further sentences into the target
language.
  Our goal is twofold. First, we hope that these tools will be fun to use for
creating artificially constructed languages. Second, we are interested in
exploring what LLMs 'know' about language-not what they know about any
particular language or linguistic phenomenon, but how much they know about and
understand language and linguistic concepts. As we shall see, there is a fairly
wide gulf in capabilities both among different LLMs and among different
linguistic specifications, with it being notably easier for systems to deal
with more common patterns than rarer ones. An additional avenue that we explore
is the application of our approach to translating from high-resource into
low-resource languages. While the results so far are mostly negative, we
provide some evidence that an improved version of the present system could
afford some real gains in such tasks.
  https://github.com/SakanaAI/IASC

</details>


### [121] [Vocabulary embeddings organize linguistic structure early in language model training](https://arxiv.org/abs/2510.07613)
*Isabel Papadimitriou,Jacob Prince*

Main category: cs.CL

TL;DR: 本论文分析了大语言模型输入词汇表的嵌入向量结构，以及这些结构如何随模型训练演化，揭示出词频和词类对嵌入表示形成的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型依赖于嵌入向量的几何结构进行推理，但关于这些嵌入在训练过程中如何随语义、句法等语言特征变化，目前了解甚少。作者希望揭示词汇表嵌入结构的动态演化规律。

Method: 作者采用了表征相似性分析（Representational Similarity Analysis），以Pythia 12B和OLMo 7B开源模型为对象，结合语义、句法和词频等不同指标，在训练过程中跟踪输入和输出嵌入几何结构的变化，并分析其与语言结构的相关性。

Result: 训练过程中，词汇嵌入几何结构很快与语义、句法特性高度相关。高频和功能词的嵌入向量相比低频和实词更快收敛，后者则在一定程度上保持初始随机状态中的偏置。

Conclusion: 论文描绘了输入嵌入随训练动态组织并围绕语言结构演化的过程，强调了词频与词类在其中的不同作用，并为进一步研究嵌入变化与模型能力提升之间的联系提供了动力。

Abstract: Large language models (LLMs) work by manipulating the geometry of input
embedding vectors over multiple layers. Here, we ask: how are the input
vocabulary representations of language models structured, and how and when does
this structure evolve over training? To answer this question, we use
representational similarity analysis, running a suite of experiments that
correlate the geometric structure of the input embeddings and output embeddings
of two open-source models (Pythia 12B and OLMo 7B) with semantic, syntactic,
and frequency-based metrics over the course of training. Our key findings are
as follows: 1) During training, the vocabulary embedding geometry quickly
converges to high correlations with a suite of semantic and syntactic features;
2) Embeddings of high-frequency and function words (e.g., "the," "of") converge
to their final vectors faster than lexical and low-frequency words, which
retain some alignment with the bias in their random initializations. These
findings help map the dynamic trajectory by which input embeddings organize
around linguistic structure, revealing distinct roles for word frequency and
function. Our findings motivate a deeper study of how the evolution of
vocabulary geometry may facilitate specific capability gains during model
training.

</details>


### [122] [Toward Reliable Clinical Coding with Language Models: Verification and Lightweight Adaptation](https://arxiv.org/abs/2510.07629)
*Zhangdie Yuan,Han-Chin Shing,Mitch Strong,Chaitanya Shivade*

Main category: cs.CL

TL;DR: 该论文提出了一种改进大语言模型（LLM）在医学编码任务中表现的方法，特别关注编码错误的层级性，并提供相关数据集与验证步骤，提升编码准确性。


<details>
  <summary>Details</summary>
Motivation: 当前主流LLM在医学临床编码任务中表现不理想，且常用的精确匹配评估方法未能捕捉到‘层级接近但不正确’的编码错误，这种错误在实际应用中占了很大比例。

Method: 提出通过轻量级的提示工程与小规模微调方式提升编码准确率，避免了复杂的搜索类计算方法。同时引入‘临床代码验证’作为独立任务以及编码流程一部分，并发布了一个由专家双重标注的门诊临床笔记与ICD-10编码数据集。

Result: 实验发现，轻量级干预能有效提升LLM编码准确率。特别是引入验证步骤后，在新的高质量数据集上，医学编码的准确性与可靠性进一步提高。

Conclusion: 验证步骤是提升LLM医学编码准确性的一种高效可靠途径，新数据集弥补了已有数据集的缺陷，为后续研究提供了有力资源。

Abstract: Accurate clinical coding is essential for healthcare documentation, billing,
and decision-making. While prior work shows that off-the-shelf LLMs struggle
with this task, evaluations based on exact match metrics often overlook errors
where predicted codes are hierarchically close but incorrect. Our analysis
reveals that such hierarchical misalignments account for a substantial portion
of LLM failures. We show that lightweight interventions, including prompt
engineering and small-scale fine-tuning, can improve accuracy without the
computational overhead of search-based methods. To address hierarchically
near-miss errors, we introduce clinical code verification as both a standalone
task and a pipeline component. To mitigate the limitations in existing
datasets, such as incomplete evidence and inpatient bias in MIMIC, we release
an expert double-annotated benchmark of outpatient clinical notes with ICD-10
codes. Our results highlight verification as an effective and reliable step
toward improving LLM-based medical coding.

</details>


### [123] [Role-Conditioned Refusals: Evaluating Access Control Reasoning in Large Language Models](https://arxiv.org/abs/2510.07642)
*Đorđe Klisura,Joseph Khoury,Ashish Kundu,Ram Krishnan,Anthony Rios*

Main category: cs.CL

TL;DR: 本文探讨了大语言模型（LLM）在实现基于角色的访问控制（RBAC）时的表现，提出了三种方法，并通过增强的text-to-SQL数据集评估其拒绝和授权能力。研究发现，两步验证框架能提高拒绝的准确性，微调方法在安全与实用性之间平衡更好，但复杂权限会导致系统性能下降。作者发布了新数据集和代码。


<details>
  <summary>Details</summary>
Motivation: 大语言模型有时会模糊用户角色的界限，容易生成权限外的应答，威胁到安全计算。为了解决LLM在敏感场景下严格执行访问控制政策的问题，作者提出系统评估其依照RBAC策略做出授权或拒绝的能力。

Method: 作者构建并扩展了Spider和BIRD两个text-to-SQL数据集，引入现实PostgreSQL RBAC策略。然后设计并比较了三种处理方式：（1）零/小样本提示；（2）生成器-验证器两步流程，对生成的SQL进行显式策略校验；（3）通过LoRA微调，使模型直接具备权限感知能力。

Result: 实验显示，两步生成-验证框架在提升拒绝（即权限外请求的正确拒绝）准确率、降低错误授权方面明显优于其他方法。LoRA微调则在保持执行准确率的同时兼顾安全性，达到更好的实用-安全平衡。所有方法在策略变复杂时表现均有下降。

Conclusion: 显式验证机制和模型微调都能够增强LLM对RBAC策略的遵守能力。两步验证更安全，微调方法安全与效用兼具。数据和工具将推动后续在大模型安全访问控制上的研究。

Abstract: Access control is a cornerstone of secure computing, yet large language
models often blur role boundaries by producing unrestricted responses. We study
role-conditioned refusals, focusing on the LLM's ability to adhere to access
control policies by answering when authorized and refusing when not. To
evaluate this behavior, we created a novel dataset that extends the Spider and
BIRD text-to-SQL datasets, both of which have been modified with realistic
PostgreSQL role-based policies at the table and column levels. We compare three
designs: (i) zero or few-shot prompting, (ii) a two-step generator-verifier
pipeline that checks SQL against policy, and (iii) LoRA fine-tuned models that
learn permission awareness directly. Across multiple model families, explicit
verification (the two-step framework) improves refusal precision and lowers
false permits. At the same time, fine-tuning achieves a stronger balance
between safety and utility (i.e., when considering execution accuracy). Longer
and more complex policies consistently reduce the reliability of all systems.
We release RBAC-augmented datasets and code.

</details>


### [124] [Banking Done Right: Redefining Retail Banking with Language-Centric AI](https://arxiv.org/abs/2510.07645)
*Xin Jie Chua,Jeraelyn Ming Li Tan,Jia Xuan Tan,Soon Chang Poh,Yi Xian Goh,Debbie Hui Tian Choong,Chee Mun Foong,Sze Jue Yang,Chee Seng Chan*

Main category: cs.CL

TL;DR: 本文介绍了Ryt AI，这是第一个获得全球监管机构批准、以自然语言为主要界面的银行AI系统，能够让客户通过对话完成核心金融交易。其核心为内部开发的私有大模型ILMU，并结合多特定任务LoRA, 且在银行本地部署，保障安全与合规。


<details>
  <summary>Details</summary>
Motivation: 过去的银行AI助手多局限于建议或支持，无法直接作为银行主界面完成金融交易。当前行业需有更智能且合规的AI系统，简化操作流程并确保安全监管。

Method: 作者自研私有大语言模型ILMU，结合四个任务驱动的LoRA代理（防护、意图、支付、FAQ），采用对话式单窗口取代多页面操作。系统在本地部署，结合可验证防护措施（守护栏）、人工确认机制和无状态审计架构，保障安全合规。

Result: Ryt AI经过监管批准，首次在全球范围内作为主界面用于现实银行核心业务操作，证明在合规框架下，高度自然语言驱动的金融服务成为可能。

Conclusion: 本文展示了自然语言接口技术在金融核心应用领域落地的可行性、合规性和安全性，推动了银行业智能化和用户体验的重大提升。

Abstract: This paper presents Ryt AI, an LLM-native agentic framework that powers Ryt
Bank to enable customers to execute core financial transactions through natural
language conversation. This represents the first global regulator-approved
deployment worldwide where conversational AI functions as the primary banking
interface, in contrast to prior assistants that have been limited to advisory
or support roles. Built entirely in-house, Ryt AI is powered by ILMU, a
closed-source LLM developed internally, and replaces rigid multi-screen
workflows with a single dialogue orchestrated by four LLM-powered agents
(Guardrails, Intent, Payment, and FAQ). Each agent attaches a task-specific
LoRA adapter to ILMU, which is hosted within the bank's infrastructure to
ensure consistent behavior with minimal overhead. Deterministic guardrails,
human-in-the-loop confirmation, and a stateless audit architecture provide
defense-in-depth for security and compliance. The result is Banking Done Right:
demonstrating that regulator-approved natural-language interfaces can reliably
support core financial operations under strict governance.

</details>


### [125] [OBCache: Optimal Brain KV Cache Pruning for Efficient Long-Context LLM Inference](https://arxiv.org/abs/2510.07651)
*Yuzhe Gu,Xiyu Liang,Jiaojiao Zhao,Enmao Diao*

Main category: cs.CL

TL;DR: 本论文提出了一种新的缓存淘汰机制OBCache，通过更精确地衡量token对注意力输出的影响，提高了长上下文大模型的推理准确性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型上下文窗口的扩大，缓存所有KV状态的内存开销变得巨大，而现有的缓存淘汰机制通常基于启发式累积注意力权重，无法精准反映token对模型输出的真实重要性。

Method: 将缓存淘汰问题形式化为逐层结构化剪枝，基于Optimal Brain Damage（OBD）理论，推导出针对key、value及其联合的token saliency打分的闭式解，衡量每个token被移除对注意力输出的实际扰动，用于更精准地指导KV缓存的替换策略。

Result: 在LLaMA和Qwen等主流大模型上实验表明，用OBCache提出的输出感知分数替换现有算法中的启发式分数，在不同查询位置上，均能显著提升长上下文任务的准确率。

Conclusion: 并非所有历史token都同等重要，针对实际对注意力输出的影响进行KV淘汰能更高效地利用有限缓存空间，为长上下文大模型下的缓存管理提供了新的有效方案。

Abstract: Large language models (LLMs) with extended context windows enable powerful
downstream applications but impose significant memory overhead, as caching all
key-value (KV) states scales linearly with sequence length and batch size.
Existing cache eviction methods address this by exploiting attention sparsity,
yet they typically rank tokens heuristically using accumulated attention
weights without considering their true impact on attention outputs. We propose
Optimal Brain Cache (OBCache), a principled framework that formulates cache
eviction as a layer-wise structured pruning problem. Building upon the Optimal
Brain Damage (OBD) theory, OBCache quantifies token saliency by measuring the
perturbation in attention outputs induced by pruning tokens, with closed-form
scores derived for isolated keys, isolated values, and joint key-value pairs.
Our scores account not only for attention weights but also for information from
value states and attention outputs, thereby enhancing existing eviction
strategies with output-aware signals. Experiments on LLaMA and Qwen models
demonstrate that replacing the heuristic scores in existing works, which
estimate token saliency across different query positions, with OBCache's
output-aware scores consistently improves long-context accuracy.

</details>


### [126] [Textual Entailment and Token Probability as Bias Evaluation Metrics](https://arxiv.org/abs/2510.07662)
*Virginia K. Felkner,Allison Lim,Jonathan May*

Main category: cs.CL

TL;DR: 本论文比较了语言模型社会偏见的两种主流测量方法——Token Probability（TP）和自然语言推断（NLI）指标，发现两者结果有很大不同，并建议结合多种方法进行全面评估。


<details>
  <summary>Details</summary>
Motivation: 当前主流用于测量语言模型社会偏见的方法大多依赖Token Probability（TP）指标，但这种方法与真实使用场景有一定距离，并可能无法检测全部潜在偏见。因此，作者希望探索自然语言推断（NLI）作为更贴近实际的新型偏见衡量方式，并分析二者之间的异同和优劣。

Method: 作者对比分析了TP和NLI两类社会偏见评估指标，并具体考查不同NLI细分度量和与TP度量之间的相关性。同时，检验了NLI与TP在检测"去偏见不足"（underdebiased）情形下的敏感性及其对反刻板印象句法的脆弱性。

Result: 实验证明NLI和TP指标在偏见评估结果上表现差异较大，二者及不同NLI度量之间相关性很低。NLI更容易检测到“去偏见不足”的情形，但对句子措辞更为敏感和脆弱。

Conclusion: 作者认为，TP和NLI在所有情境下都不能算"更好"的偏见测量指标，建议结合TP、NLI及下游偏见评估方法，才能全面评估语言模型偏见。

Abstract: Measurement of social bias in language models is typically by token
probability (TP) metrics, which are broadly applicable but have been criticized
for their distance from real-world langugage model use cases and harms. In this
work, we test natural language inference (NLI) as a more realistic alternative
bias metric. We show that, curiously, NLI and TP bias evaluation behave
substantially differently, with very low correlation among different NLI
metrics and between NLI and TP metrics. We find that NLI metrics are more
likely to detect "underdebiased" cases. However, NLI metrics seem to be more
brittle and sensitive to wording of counterstereotypical sentences than TP
approaches. We conclude that neither token probability nor natural language
inference is a "better" bias metric in all cases, and we recommend a
combination of TP, NLI, and downstream bias evaluations to ensure comprehensive
evaluation of language models.
  Content Warning: This paper contains examples of anti-LGBTQ+ stereotypes.

</details>


### [127] [Stress-Testing Model Specs Reveals Character Differences among Language Models](https://arxiv.org/abs/2510.07686)
*Jifan Zhang,Henry Sleight,Andi Peng,John Schulman,Esin Durmus*

Main category: cs.CL

TL;DR: 本论文系统性地测试了大语言模型（LLMs）在行为准则和伦理原则上的一致性，发现大量内部冲突与解释模糊等问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs越来越依赖AI宪法与模型规范以指导行为和道德，但这些规范之间存在内部矛盾和覆盖面不足的问题，可能影响模型行为的可控性与一致性。

Method: 提出了一套系统化的方法，通过自动生成需要在不同价值原则间做权衡的情境，来压力测试各大前沿LLM的模型规范；采用价值分类打分衡量不同模型在这些情境下行为上的分歧，并对主要厂商（如Anthropic、OpenAI、Google、xAI）的十二个模型进行评估。

Result: 生成了包含超过7万个存在显著行为分歧案例的数据集，并发现这些分歧强烈预示模型规范存在潜在问题。通过质性分析揭示当前模型规范中的直接矛盾和解释模糊，还发现了明显的不对齐案例和误拒绝案例。

Conclusion: 此研究揭示了当前模型道德规范中大规模的内部矛盾和理解歧义问题，指出现有规范体系仍不完善，并提供了模型之间在价值权衡与优先排序方面的不同模式。

Abstract: Large language models (LLMs) are increasingly trained from AI constitutions
and model specifications that establish behavioral guidelines and ethical
principles. However, these specifications face critical challenges, including
internal conflicts between principles and insufficient coverage of nuanced
scenarios. We present a systematic methodology for stress-testing model
character specifications, automatically identifying numerous cases of principle
contradictions and interpretive ambiguities in current model specs.
  We stress test current model specs by generating scenarios that force
explicit tradeoffs between competing value-based principles. Using a
comprehensive taxonomy we generate diverse value tradeoff scenarios where
models must choose between pairs of legitimate principles that cannot be
simultaneously satisfied. We evaluate responses from twelve frontier LLMs
across major providers (Anthropic, OpenAI, Google, xAI) and measure behavioral
disagreement through value classification scores. Among these scenarios, we
identify over 70,000 cases exhibiting significant behavioral divergence.
Empirically, we show this high divergence in model behavior strongly predicts
underlying problems in model specifications. Through qualitative analysis, we
provide numerous example issues in current model specs such as direct
contradiction and interpretive ambiguities of several principles. Additionally,
our generated dataset also reveals both clear misalignment cases and
false-positive refusals across all of the frontier models we study. Lastly, we
also provide value prioritization patterns and differences of these models.

</details>


### [128] [Large Language Models Meet Virtual Cell: A Survey](https://arxiv.org/abs/2510.07706)
*Krinos Li,Xianglu Xiao,Shenglong Deng,Lucas He,Zijun Zhong,Yuanjie Zou,Zhonghao Zhan,Zheng Hui,Weiye Bao,Guang Yang*

Main category: cs.CL

TL;DR: 该论文综述了大语言模型（LLMs）在虚拟细胞建模领域的应用。作者提出了一个统一的分类体系，将相关方法分为“先知（Oracle）”和“代理（Agent）”两大范式，并详细梳理了细胞建模的三大核心任务。文章还讨论了模型、数据集、评测方法以及在可扩展性、泛化性和可解释性等方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs技术的发展，其在细胞生物学领域的应用逐渐深入，有望推动“虚拟细胞”的计算建模。总结和归类当前LLMs在该领域的研究进展，能够为后续研究提供理论基础和实践指导。

Method: 作者通过文献综述的方法，系统梳理了已有的LLMs在虚拟细胞建模中的应用案例，提出了将相关模型归入“Oracles”或“Agents”两大类的统一分类框架，并细化为细胞表示、扰动预测和基因调控推断三类任务进行汇总分析。

Result: 论文整理并总结了每一类任务下的主流模型、相关数据集及评测基准，客观评估了LLMs技术优势，同时指出了当前面临的主流挑战：可扩展性、泛化能力和可解释性。

Conclusion: LLMs有望极大提升细胞建模与生物推理的能力，但大规模应用仍受限于模型泛化性、可解释性及计算资源瓶颈，解决这些挑战是未来研究的重点。

Abstract: Large language models (LLMs) are transforming cellular biology by enabling
the development of "virtual cells"--computational systems that represent,
predict, and reason about cellular states and behaviors. This work provides a
comprehensive review of LLMs for virtual cell modeling. We propose a unified
taxonomy that organizes existing methods into two paradigms: LLMs as Oracles,
for direct cellular modeling, and LLMs as Agents, for orchestrating complex
scientific tasks. We identify three core tasks--cellular representation,
perturbation prediction, and gene regulation inference--and review their
associated models, datasets, evaluation benchmarks, as well as the critical
challenges in scalability, generalizability, and interpretability.

</details>


### [129] [Causality Guided Representation Learning for Cross-Style Hate Speech Detection](https://arxiv.org/abs/2510.07707)
*Chengshuai Zhao,Shu Wan,Paras Sheth,Karan Patwa,K. Selçuk Candan,Huan Liu*

Main category: cs.CL

TL;DR: 本文提出了一种基于因果表示学习的新方法CADET，用于更高效、通用地检测隐晦的网络仇恨言论，且实验证明其优于以往方法。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论检测模型对隐晦表达（如讽刺、刻板印象、隐语等）难以识别，而且模型很容易受到平台、目标群体、风格的影响，泛化能力不强。作者认为，只有深入理解仇恨言论的生成机制，才能提高检测效果。

Method: 作者将仇恨言论的生成过程建模为由“环境背景、创作者动机、攻击对象与表达风格”等关键因素组成的因果图。在此基础上提出CADET框架，通过因果表示学习，把仇恨言论分解为可解释的潜在因素，并控制其中的混杂变量，仅提取真实的仇恨意图。同时，CADET还能通过在潜变量空间进行反事实推断，提升模型对不同风格的鲁棒性。

Result: CADET在多组实验证明对各种隐晦或不同风格的仇恨言论检测具有显著优越性，泛化能力强于传统方法。

Conclusion: 引入因果推断理念，有效提升了仇恨言论检测的准确性和通用性，CADET展示了因果先验对复杂文本分析的巨大潜力。

Abstract: The proliferation of online hate speech poses a significant threat to the
harmony of the web. While explicit hate is easily recognized through overt
slurs, implicit hate speech is often conveyed through sarcasm, irony,
stereotypes, or coded language -- making it harder to detect. Existing hate
speech detection models, which predominantly rely on surface-level linguistic
cues, fail to generalize effectively across diverse stylistic variations.
Moreover, hate speech spread on different platforms often targets distinct
groups and adopts unique styles, potentially inducing spurious correlations
between them and labels, further challenging current detection approaches.
Motivated by these observations, we hypothesize that the generation of hate
speech can be modeled as a causal graph involving key factors: contextual
environment, creator motivation, target, and style. Guided by this graph, we
propose CADET, a causal representation learning framework that disentangles
hate speech into interpretable latent factors and then controls confounders,
thereby isolating genuine hate intent from superficial linguistic cues.
Furthermore, CADET allows counterfactual reasoning by intervening on style
within the latent space, naturally guiding the model to robustly identify hate
speech in varying forms. CADET demonstrates superior performance in
comprehensive experiments, highlighting the potential of causal priors in
advancing generalizable hate speech detection.

</details>


### [130] [MemWeaver: A Hierarchical Memory from Textual Interactive Behaviors for Personalized Generation](https://arxiv.org/abs/2510.07713)
*Shuo Yu,Mingyue Cheng,Daoyu Wang,Qi Liu,Zirui Liu,Ze Guo,Xiaoyu Tao*

Main category: cs.CL

TL;DR: 用户和互联网的互动方式正从隐性反馈（如点击、浏览）转向利用文本交互提供的丰富显式反馈。但现有方法通常将用户历史简单视为文本列表，未能刻画其时序和语义结构。本文提出MemWeaver框架，通过将用户的所有文本历史编织成分层记忆，实现深度个性化生成。实验显示该方法在LaMP基准上取得了有效性提升。


<details>
  <summary>Details</summary>
Motivation: 随着用户交互主要变为文本形式，用户历史包含了丰富的时序与语义信息，若能有效建模，有望实现更深层次的个性化。但当前主流个性化建模方法仅将用户历史作为平坦文本集合，未能捕获用户兴趣随时间的变化及行为间复杂关联，从而无法实现深层次定制。

Method: 提出MemWeaver框架，将用户的整个文本历史分层编码成两部分记忆：一是行为记忆（behavioral memory），具体捕捉用户近期行为和兴趣动态；二是认知记忆（cognitive memory），建模长期偏好和抽象特质。二者结合，形成用户统一表示，供大语言模型用于推理和个性化生成。

Result: 在Language Model Personalization (LaMP)基准集上进行实验，结果显示MemWeaver能更好地捕获用户个性化需求，显著提升生成效果和个性化水平。

Conclusion: MemWeaver通过分层记忆结构，有效结合了用户需求的时序发展与语义关联，为大语言模型实现深度个性化提供了新途径，实验验证了其有效性。

Abstract: The primary form of user-internet engagement is shifting from leveraging
implicit feedback signals, such as browsing and clicks, to harnessing the rich
explicit feedback provided by textual interactive behaviors. This shift unlocks
a rich source of user textual history, presenting a profound opportunity for a
deeper form of personalization. However, prevailing approaches offer only a
shallow form of personalization, as they treat user history as a flat list of
texts for retrieval and fail to model the rich temporal and semantic structures
reflecting dynamic nature of user interests. In this work, we propose
\textbf{MemWeaver}, a framework that weaves the user's entire textual history
into a hierarchical memory to power deeply personalized generation. The core
innovation of our memory lies in its ability to capture both the temporal
evolution of interests and the semantic relationships between different
activities. To achieve this, MemWeaver builds two complementary memory
components that both integrate temporal and semantic information, but at
different levels of abstraction: behavioral memory, which captures specific
user actions, and cognitive memory, which represents long-term preferences.
This dual-component memory serves as a unified representation of the user,
allowing large language models (LLMs) to reason over both concrete behaviors
and abstracted traits. Experiments on the Language Model Personalization (LaMP)
benchmark validate the efficacy of MemWeaver. Our code is
available\footnote{https://github.com/fishsure/MemWeaver}.

</details>


### [131] [SUBQRAG: sub-question driven dynamic graph rag](https://arxiv.org/abs/2510.07718)
*Jiaoyang Li,Junhao Ruan,Shengwei Tang,Saihan Chen,Kaiyan Chang,Yuan Ge,Tong Xiao,Jingbo Zhu*

Main category: cs.CL

TL;DR: 本文提出了SubQRAG框架，通过将复杂问题分解为可验证的子问题，并结合动态图谱扩展，提升了多跳问答任务中的深度推理能力。实验结果表明该方法在多个基准上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的Graph RAG方法虽然能整合大规模文档语料中的知识，但在处理复杂多跳问答时，由于推理深度不够，导致证据链不完整和误差累积。因此，亟需一种能够实现更深入结构化推理的方法。

Method: SubQRAG框架先将复杂问题分解成有序的子问题链，对每个子问题检索知识图谱中的相关三元组。当知识图谱信息不足时，系统会动态扩展图谱，从源文档中实时抽取新的三元组。所有用于推理的三元组会汇总至“图谱记忆”，形成可溯源的结构化证据链用于最终答案生成。

Result: 在三个多跳问答基准数据集上，SubQRAG方法在各项指标上比传统方法取得了持续且显著的提升，尤其是在Exact Match（精确匹配）分数上表现突出。

Conclusion: SubQRAG方法通过子问题驱动和动态图谱扩展，显著增强了多跳问答中的推理深度和答案准确性，为结构化知识推理提供了新的有效途径。

Abstract: Graph Retrieval-Augmented Generation (Graph RAG) effectively builds a
knowledge graph (KG) to connect disparate facts across a large document corpus.
However, this broad-view approach often lacks the deep structured reasoning
needed for complex multi-hop question answering (QA), leading to incomplete
evidence and error accumulation. To address these limitations, we propose
SubQRAG, a sub-question-driven framework that enhances reasoning depth. SubQRAG
decomposes a complex question into an ordered chain of verifiable
sub-questions. For each sub-question, it retrieves relevant triples from the
graph. When the existing graph is insufficient, the system dynamically expands
it by extracting new triples from source documents in real time. All triples
used in the reasoning process are aggregated into a "graph memory," forming a
structured and traceable evidence path for final answer generation. Experiments
on three multi-hop QA benchmarks demonstrate that SubQRAG achieves consistent
and significant improvements, especially in Exact Match scores.

</details>


### [132] [Multilingual Knowledge Graph Completion via Efficient Multilingual Knowledge Sharing](https://arxiv.org/abs/2510.07736)
*Cunli Mao,Xiaofei Gao,Ran Song,Shizhu He,Shengxiang Gao,Kang Liu,Zhengtao Yu*

Main category: cs.CL

TL;DR: 本文提出了一种新的多语言知识图谱补全（MKGC）框架，通过知识分组专家混合模型（KL-GMoE）和迭代实体重排（IER），有效提升了多语言知识图谱的完整性。实验显示新方法在多项指标上超越现有最先进技术。


<details>
  <summary>Details</summary>
Motivation: 现有多语言知识图谱补全方法没有充分利用大语言模型的多语言能力，也忽视了跨语言知识的共享性。作者希望通过更好地建模和利用多语言共享知识，提升补全效果。

Method: 方法主要包括两个部分：一是知识层分组专家混合模型（KL-GMoE），用于高效建模和共享多语言知识；二是迭代实体重排方法（IER），增强共享知识的有效利用。同时，作者构建了包含5种语言的新mKG数据集，并与主流方法做了比较实验。

Result: 在与最新MKGC方法的对比实验中，新方法在Hits@1、Hits@3和Hits@10指标上分别提升了5.47%、3.27%、1.01%。还进一步分析了该方法在未知语言和不平衡语言环境中的知识共享性质。

Conclusion: 本文提出的新框架能显著提升多语言知识图谱补全的效果，并有效促进跨语言知识共享。代码和数据集已开源，具有良好的复现性和应用前景。

Abstract: Large language models (LLMs) based Multilingual Knowledge Graph Completion
(MKGC) aim to predict missing facts by leveraging LLMs' multilingual
understanding capabilities, improving the completeness of multilingual
knowledge graphs (KGs). However, existing MKGC research underutilizes the
multilingual capabilities of LLMs and ignores the shareability of cross-lingual
knowledge. In this paper, we propose a novel MKGC framework that leverages
multilingual shared knowledge to significantly enhance performance through two
components: Knowledge-level Grouped Mixture of Experts (KL-GMoE) and Iterative
Entity Reranking (IER). KL-GMoE efficiently models shared knowledge, while IER
significantly enhances its utilization. To evaluate our framework, we
constructed a mKG dataset containing 5 languages and conducted comprehensive
comparative experiments with existing state-of-the-art (SOTA) MKGC method. The
experimental results demonstrate that our framework achieves improvements of
5.47%, 3.27%, and 1.01% in the Hits@1, Hits@3, and Hits@10 metrics,
respectively, compared with SOTA MKGC method. Further experimental analysis
revealed the properties of knowledge sharing in settings of unseen and
unbalanced languages. We have released the dataset and code for our work on
https://github.com/gaoxiaofei07/KL-GMoE.

</details>


### [133] [ToolExpander: Extending the Frontiers of Tool-Using Reinforcement Learning to Weak LLMs](https://arxiv.org/abs/2510.07737)
*Fu Chen,Peng Wang,Xiyin Li,Wen Li,Shichi Lei,Dongdong Xiang*

Main category: cs.CL

TL;DR: 本文提出了一种名为ToolExpander的新框架，通过动态难样本替换和自我示例增强GRPO算法，有效提升了中小规模大语言模型在使用工具时的能力与训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的GRPO方法在大语言模型，尤其是小模型上，经常出现无法正确输出、性能提升有限，以及训练崩溃的问题，影响了模型效果和GRPO潜力。

Method: 作者提出ToolExpander，包括两大创新：(1) 动态多轮难样本替换，将训练过程中始终输出错误的大难样本用高质量的few-shot示例替换，并配合指数学习率衰减，缓解训练波动；(2) 自我示例性思考，对GRPO进行改进，去除KL散度，调整clipping系数，并通过极小的奖励鼓励模型自生成和分析few-shot样例。

Result: 实验表明，ToolExpander尤其能提升小规模大语言模型的工具使用能力，带来训练的高稳定性和更优的整体性能。

Conclusion: ToolExpander有效缓解了GRPO训练中模型输出不准和崩溃的问题，显著提升了资源受限的大语言模型工具使用的表现和训练表现。

Abstract: Training Large Language Models (LLMs) with Group Relative Policy Optimization
(GRPO) encounters a significant challenge: models often fail to produce
accurate responses, particularly in small-scale architectures. This limitation
not only diminishes performance improvements and undermines the potential of
GRPO but also frequently leads to mid-training collapse, adversely affecting
stability and final efficacy. To address these issues, we propose ToolExpander,
a novel framework that advances tool-oriented reinforcement learning for
resource-constrained LLMs through two key innovations:(1) Dynamic Multi-Round
Hard Sampling, which dynamically substitutes challenging samples(those without
correct outputs over 10 rollouts) with high-quality few-shot demonstrations
during training, coupled with an exponential learning rate decay strategy to
mitigate oscillations;(2) Self-Exemplifying Thinking, an enhanced GRPO
framework that eliminates KL divergence and incorporates adjusted clipping
coefficients, encouraging models to autonomously generate and analyze few-shot
examples via a minimal additional reward (0.01).Experimental results
demonstrate that ToolExpander significantly enhances tool-using capabilities in
LLMs, especially in weaker small-scale models, improving both training
stability and overall performance.

</details>


### [134] [OpenRubrics: Towards Scalable Synthetic Rubric Generation for Reward Modeling and LLM Alignment](https://arxiv.org/abs/2510.07743)
*Tianci Liu,Ran Xu,Tony Yu,Ilgee Hong,Carl Yang,Tuo Zhao,Haoyu Wang*

Main category: cs.CL

TL;DR: 本文提出OpenRubrics数据集和Rubric-RM奖励模型，用结构化评判标准取代传统RLHF中的简单分数或两两比较，提高了奖励模型对人类复杂偏好的捕捉能力，并在多个任务中取得了比现有方法更好的效果。


<details>
  <summary>Details</summary>
Motivation: 传统的基于人类反馈强化学习的奖励建模，主要依赖于分数或简单两两比较，无法完全刻画人类偏好的多维性质。近年来正在尝试用结构化评价标准（rubric）来更全面描述响应的质量，但如何低成本可靠地大规模自动生成rubric仍是未解难题。

Method: 提出了OpenRubrics大规模(prompt, rubric)数据集，用于训练rubric生成与基于rubric的奖励模型。创新性地提出了Contrastive Rubric Generation (CRG)，通过对比优选和被拒答复来生成“硬规则”和“原则”，确保评价标准具有区分性和全面性，并通过拒绝采样剔除不一致或噪声rubric提升鲁棒性。

Result: 在多个奖励建模基准上，基于rubric的奖励模型Rubric-RM性能超越同规模强基线6.8%。这一优势在下游指令跟随和生物医学任务的策略模型中同样表现突出。

Conclusion: 结构化rubric评价为大模型对齐提供了更可扩展且原理驱动的标注信号，有效缩小了昂贵人工评价与自动奖励建模之间的差距，为大语言模型对齐开辟了新范式。

Abstract: Reward modeling lies at the core of reinforcement learning from human
feedback (RLHF), yet most existing reward models rely on scalar or pairwise
judgments that fail to capture the multifaceted nature of human preferences.
Recent studies have explored rubrics-as-rewards (RaR) that uses structured
natural language criteria that capture multiple dimensions of response quality.
However, producing rubrics that are both reliable and scalable remains a key
challenge. In this work, we introduce OpenRubrics, a diverse, large-scale
collection of (prompt, rubric) pairs for training rubric-generation and
rubric-based reward models. To elicit discriminative and comprehensive
evaluation signals, we introduce Contrastive Rubric Generation (CRG), which
derives both hard rules (explicit constraints) and principles (implicit
qualities) by contrasting preferred and rejected responses. We further improve
reliability by enforcing preference-label consistency via rejection sampling to
remove noisy rubrics. Across multiple reward-modeling benchmarks, our
rubric-based reward model, Rubric-RM, surpasses strong size-matched baselines
by 6.8%. These gains transfer to policy models on instruction-following and
biomedical benchmarks. Our results show that rubrics provide scalable alignment
signals that narrow the gap between costly human evaluation and automated
reward modeling, enabling a new principle-driven paradigm for LLM alignment.

</details>


### [135] [Parallel Test-Time Scaling for Latent Reasoning Models](https://arxiv.org/abs/2510.07745)
*Runyang You,Yongqi Li,Meng Liu,Wenjie Wang,Liqiang Nie,Wenjie Li*

Main category: cs.CL

TL;DR: 本文实现了针对潜在推理模型的并行测试时扩展（TTS），通过引入新的采样方法和聚合机制，实现了推理效率和效果的提升。


<details>
  <summary>Details</summary>
Motivation: 显性思维链（CoT）方法提升大模型推理能力，但同样提升方式尚未迁移到基于连续空间的潜在推理模型，原因在于其缺乏有效的采样与聚合机制。为实现潜在模型的可扩展推理，需要攻克这两个难题。

Method: 作者提出两种用于连续空间采样的不确定性驱动策略：蒙特卡洛Dropout和加性高斯噪声。同时，设计Latent Reward Model（LatentRM），通过步进对比目标训练，为潜在推理轨迹打分和指导。

Result: 大量实验和可视化表明，两种采样策略均能够随算力扩展有效工作，展现出不同的探索动态。LatentRM能够高效选择优质推理轨迹。

Conclusion: 本研究打通了潜在推理模型并行TTS路径，为连续空间模型可扩展推理提供了新方案。

Abstract: Parallel test-time scaling (TTS) is a pivotal approach for enhancing large
language models (LLMs), typically by sampling multiple token-based
chains-of-thought in parallel and aggregating outcomes through voting or
search. Recent advances in latent reasoning, where intermediate reasoning
unfolds in continuous vector spaces, offer a more efficient alternative to
explicit Chain-of-Thought, yet whether such latent models can similarly benefit
from parallel TTS remains open, mainly due to the absence of sampling
mechanisms in continuous space, and the lack of probabilistic signals for
advanced trajectory aggregation. \ This work enables parallel TTS for latent
reasoning models by addressing the above issues. For sampling, we introduce two
uncertainty-inspired stochastic strategies: Monte Carlo Dropout and Additive
Gaussian Noise. For aggregation, we design a Latent Reward Model (LatentRM)
trained with step-wise contrastive objective to score and guide latent
reasoning. Extensive experiments and visualization analyses show that both
sampling strategies scale effectively with compute and exhibit distinct
exploration dynamics, while LatentRM enables effective trajectory selection.
Together, our explorations open a new direction for scalable inference in
continuous spaces. Code released at https://github.com/YRYangang/LatentTTS.

</details>


### [136] [Test-Time Reasoners Are Strategic Multiple-Choice Test-Takers](https://arxiv.org/abs/2510.07761)
*Nishant Balepur,Atrey Desai,Rachel Rudinger*

Main category: cs.CL

TL;DR: 本论文研究了大语言模型（LLM）在多项选择题（MCQA）仅用选项而不看问题时也能获得高分的现象，并分析这些推理过程是否仅为浅层技巧。


<details>
  <summary>Details</summary>
Motivation: 近年来LLM在MCQA任务中展现出强大的推理能力，但有人发现即使不给问题只给选项，LLM也能选对答案，引发对模型是否依赖于“捷径”的质疑，本研究旨在检验这些现象是否真的代表模型存在缺陷。

Method: 作者让LLM分别在包含完整问题及仅包含选项的输入下作答，并分析生成的推理轨迹（reasoning traces）。同时，评估推理轨迹的长度、准确率提升，以及其是否能够通过忠实性测试。

Result: 实验结果显示，在完整输入和仅选项输入下是否生成推理轨迹对准确率均有提升。在仅选项输入下，推理轨迹长度对准确率影响不大，并且这些轨迹通过了忠实性测试。有证据表明模型并非只用浅层方法猜测答案，而在某些情况下推理轨迹包含了如对缺失问题的合理推断等较少问题的数据策略。

Conclusion: 论文质疑了“部分输入答题成功总是不良现象”的观点，提出可通过分析推理轨迹来区分真正的问题数据路径和合理推理，对理解及改进大模型行为具有启示意义。

Abstract: Large language models (LLMs) now give reasoning before answering, excelling
in tasks like multiple-choice question answering (MCQA). Yet, a concern is that
LLMs do not solve MCQs as intended, as work finds LLMs sans reasoning succeed
in MCQA without using the question, i.e., choices-only. Such partial-input
success is often deemed problematic, but reasoning traces could reveal if these
strategies are truly shallow in choices-only settings. To study these
strategies, reasoning LLMs solve MCQs in full and choices-only inputs;
test-time reasoning often boosts accuracy on full and in choices-only half the
time. While possibly due to shallow shortcuts, choices-only success is barely
affected by the length of reasoning traces, and after finding traces pass
faithfulness tests, we show they use less problematic strategies like inferring
missing questions. In all, we challenge claims that partial-input success is
always a flaw, so we discuss how reasoning traces could separate problematic
data from less problematic reasoning.

</details>


### [137] [ToolLibGen: Scalable Automatic Tool Creation and Aggregation for LLM Reasoning](https://arxiv.org/abs/2510.07768)
*Murong Yue,Zhiwei Liu,Liangwei Yang,Jianguo Zhang,Zuxin Liu,Haolin Chen,Ziyu Yao,Silvio Savarese,Caiming Xiong,Shelby Heinecke,Huan Wang*

Main category: cs.CL

TL;DR: 本文提出了一种系统化方法，将大语言模型自动生成的大量零散工具重构为结构化的工具库，从而提高工具检索效率与推理表现。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型通过调用外部工具可提升复杂推理任务表现，但领域专用工具稀缺。既有通过CoT自动提炼工具的方法面临规模瓶颈，即随着工具数量增加，存储在无结构集合中导致检索困难和工具歧义。

Method: 提出自动将无结构工具集合重构为结构化工具库的方法。首先自动生成离散、任务特定的工具，并进行主题聚类。每个聚类内，利用多智能体框架：代码代理负责重构代码抽取共用逻辑，生成通用聚合工具；审查代理保证聚合工具功能完整。这样将大量具体工具转化为小规模强大的聚合工具。

Result: 实验显示，本方法在多个推理任务上大幅提升了工具检索准确率和推理能力。与基线相比，问题专用工具数量增加时，扩展性更强。

Conclusion: 系统化重构工具库的方法能有效解决工具规模扩大后的管理与检索难题，提升了大模型推理能力和扩展性。

Abstract: Large Language Models (LLMs) equipped with external tools have demonstrated
enhanced performance on complex reasoning tasks. The widespread adoption of
this tool-augmented reasoning is hindered by the scarcity of domain-specific
tools. For instance, in domains such as physics question answering, suitable
and specialized tools are often missing. Recent work has explored automating
tool creation by extracting reusable functions from Chain-of-Thought (CoT)
reasoning traces; however, these approaches face a critical scalability
bottleneck. As the number of generated tools grows, storing them in an
unstructured collection leads to significant retrieval challenges, including an
expanding search space and ambiguity between function-related tools. To address
this, we propose a systematic approach to automatically refactor an
unstructured collection of tools into a structured tool library. Our system
first generates discrete, task-specific tools and clusters them into
semantically coherent topics. Within each cluster, we introduce a multi-agent
framework to consolidate scattered functionalities: a code agent refactors code
to extract shared logic and creates versatile, aggregated tools, while a
reviewing agent ensures that these aggregated tools maintain the complete
functional capabilities of the original set. This process transforms numerous
question-specific tools into a smaller set of powerful, aggregated tools
without loss of functionality. Experimental results demonstrate that our
approach significantly improves tool retrieval accuracy and overall reasoning
performance across multiple reasoning tasks. Furthermore, our method shows
enhanced scalability compared with baselines as the number of question-specific
increases.

</details>


### [138] [Curing Miracle Steps in LLM Mathematical Reasoning with Rubric Rewards](https://arxiv.org/abs/2510.07774)
*Youliang Yuan,Qiuyang Mang,Jingbang Chen,Hong Wan,Xiaoyuan Liu,Junjielong Xu,Jen-tse Huang,Wenxuan Wang,Wenxiang Jiao,Pinjia He*

Main category: cs.CL

TL;DR: 论文发现，当前大语言模型采用仅根据最终答案给奖励的方式，容易出现奖励欺骗，即模型通过不正确的推理得到正确答案。作者提出基于推理过程的Rubric Reward Model（RRM），显著提高模型的推理可靠性和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统训练的数学大模型仅关注最终答案的正确与否，忽略了推理过程，这使得模型可能通过不合理甚至错误的推理步骤偶然得到正确答案，导致过高估计模型的推理能力。作者希望解决这种奖励欺骗（reward hacking）的问题。

Method: 作者全面分析了数学推理过程中出现的各种失误类型，比如“奇迹步骤”（Miracle Steps），并通过人工验证分类这些失败模式。随后，作者提出了Rubric Reward Model（RRM），一种过程导向的奖励函数，能够基于题目和推理轨迹按细分标准评估每一步（0-1分），系统性惩罚逻辑错误，鼓励严谨推理。RRM接入强化学习训练流程后，与传统的结果奖励法对比性能。

Result: RRM导向的训练在四个数学基准测试上全面优于仅用结果奖励的方法。例如AIME2024基准下，经过验证的Pass@1024从26.7%提升到62.6%，同时“奇迹步骤”出现率下降71%。

Conclusion: 奖励模型推理过程（而非仅仅结果）对于提升数学推理大模型的可靠性和准确性至关重要。RRM提供的过程奖励机制能有效减少凭记忆或非严密推理得到正确答案的情况，推动模型向更严谨的数学推理能力发展。

Abstract: Large language models for mathematical reasoning are typically trained with
outcome-based rewards, which credit only the final answer. In our experiments,
we observe that this paradigm is highly susceptible to reward hacking, leading
to a substantial overestimation of a model's reasoning ability. This is
evidenced by a high incidence of false positives - solutions that reach the
correct final answer through an unsound reasoning process. Through a systematic
analysis with human verification, we establish a taxonomy of these failure
modes, identifying patterns like Miracle Steps - abrupt jumps to a correct
output without a valid preceding derivation. Probing experiments suggest a
strong association between these Miracle Steps and memorization, where the
model appears to recall the answer directly rather than deriving it. To
mitigate this systemic issue, we introduce the Rubric Reward Model (RRM), a
process-oriented reward function that evaluates the entire reasoning trajectory
against problem-specific rubrics. The generative RRM provides fine-grained,
calibrated rewards (0-1) that explicitly penalize logical flaws and encourage
rigorous deduction. When integrated into a reinforcement learning pipeline,
RRM-based training consistently outperforms outcome-only supervision across
four math benchmarks. Notably, it boosts Verified Pass@1024 on AIME2024 from
26.7% to 62.6% and reduces the incidence of Miracle Steps by 71%. Our work
demonstrates that rewarding the solution process is crucial for building models
that are not only more accurate but also more reliable.

</details>


### [139] [The Unintended Trade-off of AI Alignment:Balancing Hallucination Mitigation and Safety in LLMs](https://arxiv.org/abs/2510.07775)
*Omar Mahmoud,Ali Khalil,Buddhika Laknath Semage,Thommen George Karimpanal,Santu Rana*

Main category: cs.CL

TL;DR: 本文指出，大型语言模型在提升事实准确性的同时，可能会削弱其安全性拒绝能力（如拒绝有害请求），提出用稀疏自编码器和子空间正交化的方法来解耦拒绝和事实特征，成功缓解了提升真确性与保持安全之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 目前提升大型语言模型真实性/真实性主要关注降低幻觉（hallucination），但忽视了这可能带来的负面影响——模型安全对齐（如拒绝有害请求的能力）被削弱。因此有必要研究提升真实性和保持安全性之间的权衡关系。

Method: 作者分析模型幻觉与拒绝行为在模型内部表征有重叠，导致对齐方法一并抑制了部分事实知识。提出使用稀疏自编码器（sparse autoencoders）分离幻觉和拒绝相关的特征，并在微调过程中采用子空间正交化（subspace orthogonalization）来保留拒绝行为，从而提升真实性的同时不牺牲安全对齐。

Result: 方法在常识推理任务和有害性基准测试（AdvBench和StrongReject）上评估，结果表明该方法能够在不增加幻觉的情况下，保持拒绝行为，并提升任务能力，有效缓解真实性与安全对齐的权衡问题。

Conclusion: 论文提出的方法实现了大型语言模型真确性和安全性拒绝能力的联合优化，减少了两者之间的冲突，为训练更安全且更可靠的语言模型提供了新的方向。

Abstract: Hallucination in large language models (LLMs) has been widely studied in
recent years, with progress in both detection and mitigation aimed at improving
truthfulness. Yet, a critical side effect remains largely overlooked: enhancing
truthfulness can negatively impact safety alignment. In this paper, we
investigate this trade-off and show that increasing factual accuracy often
comes at the cost of weakened refusal behavior. Our analysis reveals that this
arises from overlapping components in the model that simultaneously encode
hallucination and refusal information, leading alignment methods to suppress
factual knowledge unintentionally. We further examine how fine-tuning on benign
datasets, even when curated for safety, can degrade alignment for the same
reason. To address this, we propose a method that disentangles refusal-related
features from hallucination features using sparse autoencoders, and preserves
refusal behavior during fine-tuning through subspace orthogonalization. This
approach prevents hallucinations from increasing while maintaining safety
alignment.We evaluate our method on commonsense reasoning tasks and harmful
benchmarks (AdvBench and StrongReject). Results demonstrate that our approach
preserves refusal behavior and task utility, mitigating the trade-off between
truthfulness and safety.

</details>


### [140] [Instance Relation Learning Network with Label Knowledge Propagation for Few-shot Multi-label Intent Detection](https://arxiv.org/abs/2510.07776)
*Shiman Zhao,Shangyuan Li,Wei Chen,Tengjiao Wang,Jiahui Yao,Jiabin Zheng,Kam Fai Wong*

Main category: cs.CL

TL;DR: 本论文提出了一种端到端的多标签联合学习方法，专为低资源场景下的对话系统少样本多意图检测任务，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统少样本多标签意图识别方法通常分两步走，先学习带多标签的语句表示，再用阈值策略分类。这类方法忽视了语句之间的实例关系，会带来误差传播问题。为解决此问题，需要一种能直接建模实例关系并传播标签知识的方法。

Method: 提出了一种多标签联合学习方法，核心是构建实例关系网络，利用标签知识从带标签样本（support set）向无标签样本（query set）传播。通过学习实例间的关系强度，实现标签知识的共享。此外，设计了增强关系损失函数，分别在已知和未知样本层面优化关系强度，提升模型表现。

Result: 在1-shot实验下，方法在AUC和Macro-F1上相较于强基线分别提升9.54%和11.19%。

Conclusion: 本方法有效解决了传统少样本多意图检测误差传播的问题，显著提升了少样本、多标签意图检测任务的表现。

Abstract: Few-shot Multi-label Intent Detection (MID) is crucial for dialogue systems,
aiming to detect multiple intents of utterances in low-resource dialogue
domains. Previous studies focus on a two-stage pipeline. They first learn
representations of utterances with multiple labels and then use a
threshold-based strategy to identify multi-label results. However, these
methods rely on representation classification and ignore instance relations,
leading to error propagation. To solve the above issues, we propose a
multi-label joint learning method for few-shot MID in an end-to-end manner,
which constructs an instance relation learning network with label knowledge
propagation to eliminate error propagation. Concretely, we learn the
interaction relations between instances with class information to propagate
label knowledge between a few labeled (support set) and unlabeled (query set)
instances. With label knowledge propagation, the relation strength between
instances directly indicates whether two utterances belong to the same intent
for multi-label prediction. Besides, a dual relation-enhanced loss is developed
to optimize support- and query-level relation strength to improve performance.
Experiments show that we outperform strong baselines by an average of 9.54% AUC
and 11.19% Macro-F1 in 1-shot scenarios.

</details>


### [141] [Drift No More? Context Equilibria in Multi-Turn LLM Interactions](https://arxiv.org/abs/2510.07777)
*Vardhan Dongre,Ryan A. Rossi,Viet Dac Lai,David Seunghyun Yoon,Dilek Hakkani-Tür,Trung Bui*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）在多轮对话中的“上下文漂移”问题，并提出用动态框架来理解和控制其演化规律。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在单轮任务表现优异，实际应用中常涉及多轮交互，其中用户目标和对话上下文会持续演化。一个关键挑战是上下文漂移：模型输出逐渐偏离初始目标。这种多轮对话下的误差不像单轮那样易于度量，因此需要新的方法进行分析和干预。

Method: 作者提出将多轮上下文漂移形式化为测试模型与一致目标参考模型的预测分布之间的逐轮KL散度，结合递推模型，将其解释为有限噪声平衡过程，并探讨“提醒”类干预手段对漂移的抑制作用。实验包括合成重写任务和现实用户-智能体模拟，系统测量多种开源LLMs的漂移表现。

Result: 实验发现，漂移并非持续恶化，而是趋于一种稳定的噪声受限平衡状态。并且通过简单的提醒干预可以有效降低漂移，与理论预测一致。

Conclusion: 上下文漂移是可控的动态平衡现象，而非无可避免的积累退化。相关发现为长期多轮人机交互中漂移分析和缓解提供理论基础。

Abstract: Large Language Models (LLMs) excel at single-turn tasks such as instruction
following and summarization, yet real-world deployments require sustained
multi-turn interactions where user goals and conversational context persist and
evolve. A recurring challenge in this setting is context drift: the gradual
divergence of a model's outputs from goal-consistent behavior across turns.
Unlike single-turn errors, drift unfolds temporally and is poorly captured by
static evaluation metrics. In this work, we present a study of context drift in
multi-turn interactions and propose a simple dynamical framework to interpret
its behavior. We formalize drift as the turn-wise KL divergence between the
token-level predictive distributions of the test model and a goal-consistent
reference model, and propose a recurrence model that interprets its evolution
as a bounded stochastic process with restoring forces and controllable
interventions. We instantiate this framework in both synthetic long-horizon
rewriting tasks and realistic user-agent simulations such as in $\tau$-Bench,
measuring drift for several open-weight LLMs that are used as user simulators.
Our experiments consistently reveal stable, noise-limited equilibria rather
than runaway degradation, and demonstrate that simple reminder interventions
reliably reduce divergence in line with theoretical predictions. Together,
these results suggest that multi-turn drift can be understood as a controllable
equilibrium phenomenon rather than as inevitable decay, providing a foundation
for studying and mitigating context drift in extended interactions.

</details>


### [142] [RCPU: Rotation-Constrained Error Compensation for Structured Pruning of a Large Language Model](https://arxiv.org/abs/2510.07782)
*Shuichiro Haruta,Kazunori Matsumoto,Zhi Li,Yanan Wang,Mori Kurokawa*

Main category: cs.CL

TL;DR: 本文提出了一种旋转约束补偿方法，用于解决大语言模型结构化剪枝引入的误差，在多项基准测试中取得优于现有方法的表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）的结构化剪枝虽可提升模型效率，但因剪枝时校准数据有限，常导致模型输出与原始模型不一致甚至恶化。标准的直接拟合（如最小二乘）虽可以减小误差，但容易过拟合有限的校准集，并破坏预训练权重的结构。为此，需要新的方法既能恢复输出精度，又能保持原有表示空间的几何特征。

Method: 作者提出了一种带旋转约束的参数补偿方案。通过在参数更新时添加旋转约束，保持输出表示的范数与内积结构，同时重新对齐被剪枝后的子空间与原始输出。此外，文中还设计了考虑输入方差的维度重要性评分机制，使得高方差方向在剪枝后优先保留，提升模型几何结构的完整性。

Result: 该方法应用于LLaMA-7B模型，并在WikiText-2及多项语言理解基准测试上进行评估。实验表明，无论从困惑度还是任务准确率，该方法均显著优于现有主流剪枝补偿方法。

Conclusion: 旋转约束补偿结合方差感知评分，能有效修正剪枝误差并保留语义表示几何结构，为大模型高效压缩与部署提供了一条新思路。

Abstract: In this paper, we propose a rotation-constrained compensation method to
address the errors introduced by structured pruning of large language models
(LLMs). LLMs are trained on massive datasets and accumulate rich semantic
knowledge in their representation space. In contrast, pruning is typically
carried out with only a small amount of calibration data, which makes output
mismatches unavoidable. Although direct least-squares fitting can reduce such
errors, it tends to overfit to the limited calibration set, destructively
modifying pretrained weights. To overcome this difficulty, we update the pruned
parameters under a rotation constraint. This constrained update preserves the
geometry of output representations (i.e., norms and inner products) and
simultaneously re-aligns the pruned subspace with the original outputs.
Furthermore, in rotation-constrained compensation, removing components that
strongly contribute to the principal directions of the output makes error
recovery difficult. Since input dimensions with large variance strongly affect
these principal directions, we design a variance-aware importance score that
ensures such dimensions are preferentially kept in the pruned model. By
combining this scoring rule with rotation-constrained updates, the proposed
method effectively compensates errors while retaining the components likely to
be more important in a geometry-preserving manner. In the experiments, we apply
the proposed method to LLaMA-7B and evaluate it on WikiText-2 and multiple
language understanding benchmarks. The results demonstrate consistently better
perplexity and task accuracy compared with existing baselines.

</details>


### [143] [LLM4Cell: A Survey of Large Language and Agentic Models for Single-Cell Biology](https://arxiv.org/abs/2510.07793)
*Sajib Acharjee Dip,Adrika Zafor,Bikash Kumar Paul,Uddip Acharjee Shuvo,Muhit Islam Emon,Xuan Wang,Liqing Zhang*

Main category: cs.CL

TL;DR: 本文综述了58种为单细胞研究开发的大语言模型（LLMs）及相关智能体模型，首次进行统一分类、综合分析，并解析其在多种数据类型和关键分析任务中的应用及挑战。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs及智能体框架的发展，其在单细胞生物学中的应用快速增多，包括自然语言推理、生成式注释和多模态数据整合，但目前进展分散在不同数据类型、模型架构和评估标准下，缺乏系统梳理与比较，急需统一视角以推动领域发展。

Method: 作者梳理、分类并评测了58个基础和智能体模型，涵盖RNA、ATAC、多组学和空间等多种单细胞数据类型，将方法分为5类并映射到8项关键分析任务。利用40余个公开数据集，从生物学基础、多组学整合、公平性、隐私、可解释性等10个维度，系统评价了各类模型。

Result: 研究对现有单细胞领域的LLMs模型进行了全面分类和性能评估，分析了各种方法在不同数据类型和任务中的适用性、数据多样性及道德/可扩展性约束，揭示了当前模型在数据对齐、解释性、标准化等方面的局限。

Conclusion: LLM4Cell首次为基于语言的单细胞智能绘制了统一全景图，联结了数据集、模型及评估领域，为后续在可解释性、标准化和可信模型开发等方面提出了主要挑战与未来方向。

Abstract: Large language models (LLMs) and emerging agentic frameworks are beginning to
transform single-cell biology by enabling natural-language reasoning,
generative annotation, and multimodal data integration. However, progress
remains fragmented across data modalities, architectures, and evaluation
standards. LLM4Cell presents the first unified survey of 58 foundation and
agentic models developed for single-cell research, spanning RNA, ATAC,
multi-omic, and spatial modalities. We categorize these methods into five
families-foundation, text-bridge, spatial, multimodal, epigenomic, and
agentic-and map them to eight key analytical tasks including annotation,
trajectory and perturbation modeling, and drug-response prediction. Drawing on
over 40 public datasets, we analyze benchmark suitability, data diversity, and
ethical or scalability constraints, and evaluate models across 10 domain
dimensions covering biological grounding, multi-omics alignment, fairness,
privacy, and explainability. By linking datasets, models, and evaluation
domains, LLM4Cell provides the first integrated view of language-driven
single-cell intelligence and outlines open challenges in interpretability,
standardization, and trustworthy model development.

</details>


### [144] [HiPRAG: Hierarchical Process Rewards for Efficient Agentic Retrieval Augmented Generation](https://arxiv.org/abs/2510.07794)
*Peilin Wu,Mian Zhang,Kun Wan,Wentian Zhao,Kaiyu He,Xinya Du,Zhiyu Chen*

Main category: cs.CL

TL;DR: 本文提出了一种名为HiPRAG的层次化过程奖励方法，通过精细控制奖励机制优化agentic RAG中的搜索行为，提高了信息检索效率和问答准确率。


<details>
  <summary>Details</summary>
Motivation: 传统的agentic RAG在采用RL训练时常常出现过度搜索（检索已知信息）或不足搜索（缺乏必要检索），导致资源浪费和输出不可靠。现有奖励机制缺乏过程细致控制，难以解决这些问题。

Method: 作者提出HiPRAG方法，在RL训练中引入基于知识的、可解析的步骤级过程奖励。方法将agent推理过程分解为可解析的离散步骤，根据每个步骤是否为最优搜索/非搜索行为进行奖励，同时结合传统结果和格式奖励，实现对搜索行为的精细化优化。

Result: 在Qwen2.5和Llama-3.2等大模型及七个多样化QA基准上的实验显示，HiPRAG准确率分别达到65.4%（3B）和67.2%（7B），提升了检索效率，将过度搜索率降至2.3%，并同步降低不足搜索率。

Conclusion: 通过优化推理过程本身而不仅仅是最终结果，HiPRAG方法有效提升了推理agent的效率和最优性。方法具有良好的通用性，可推广至各种RL算法和不同类型大模型。

Abstract: Agentic RAG is a powerful technique for incorporating external information
that LLMs lack, enabling better problem solving and question answering.
However, suboptimal search behaviors exist widely, such as over-search
(retrieving information already known) and under-search (failing to search when
necessary), which leads to unnecessary overhead and unreliable outputs. Current
training methods, which typically rely on outcome-based rewards in a RL
framework, lack the fine-grained control needed to address these
inefficiencies. To overcome this, we introduce Hierarchical Process Rewards for
Efficient agentic RAG (HiPRAG), a training methodology that incorporates a
fine-grained, knowledge-grounded process reward into the RL training. Our
approach evaluates the necessity of each search decision on-the-fly by
decomposing the agent's reasoning trajectory into discrete, parsable steps. We
then apply a hierarchical reward function that provides an additional bonus
based on the proportion of optimal search and non-search steps, on top of
commonly used outcome and format rewards. Experiments on the Qwen2.5 and
Llama-3.2 models across seven diverse QA benchmarks show that our method
achieves average accuracies of 65.4% (3B) and 67.2% (7B). This is accomplished
while improving search efficiency, reducing the over-search rate to just 2.3%
and concurrently lowering the under-search rate. These results demonstrate the
efficacy of optimizing the reasoning process itself, not just the final
outcome. Further experiments and analysis demonstrate that HiPRAG shows good
generalizability across a wide range of RL algorithms, model families, sizes,
and types. This work demonstrates the importance and potential of fine-grained
control through RL, for improving the efficiency and optimality of reasoning
for search agents.

</details>


### [145] [Dynamic Generation of Multi-LLM Agents Communication Topologies with Graph Diffusion Models](https://arxiv.org/abs/2510.07799)
*Eric Hanchen Jiang,Guancheng Wan,Sophia Yin,Mengting Li,Yuchen Wu,Xiao Liang,Xinfeng Li,Yizhou Sun,Wei Wang,Kai-Wei Chang,Ying Nian Wu*

Main category: cs.CL

TL;DR: 本文提出了一种名为Guided Topology Diffusion (GTD)的新型生成框架，用于为大型语言模型驱动的多智能体系统自动构建高效的通信拓扑结构，从而实现更优的性能、通信成本和鲁棒性平衡。实验显示该方法在多个基准任务上明显优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统的效率高度依赖其通信拓扑。目前大多采用静态或手工设计的拓扑，难以适应不同任务，导致简单问题通信开销过高，复杂问题又常出现性能瓶颈，因此亟需一种能动态自适应设计拓扑的方法。

Method: 提出一种受条件离散图扩散模型启发的框架GTD，将通信拓扑的生成建模为迭代的构建过程。每一步由一个轻量代理模型预测多目标奖励（如准确率、效用、成本），无需梯度即可实时优化，使生成过程不断朝着任务自适应的拓扑方向前进。核心创新是用引导、分步的迭代方法替代传统的一步生成方式，更好应对多目标权衡。

Result: 在多个基准数据集上，GTD能够自动生成稀疏、高效且任务自适应的通信拓扑。与现有方法相比，能明显减少token消耗，并提升LLM多智能体协作的整体性能。

Conclusion: GTD为多智能体系统通信拓扑的自动化优化提供了有效方案，能够根据任务动态调整结构，实现更好的性能与通信效率。实验验证了其优越性，有望推动大语言模型驱动的多智能体智能体进一步发展。

Abstract: The efficiency of multi-agent systems driven by large language models (LLMs)
largely hinges on their communication topology. However, designing an optimal
topology is a non-trivial challenge, as it requires balancing competing
objectives such as task performance, communication cost, and robustness.
Existing frameworks often rely on static or hand-crafted topologies, which
inherently fail to adapt to diverse task requirements, leading to either
excessive token consumption for simple problems or performance bottlenecks for
complex ones. To address this challenge, we introduce a novel generative
framework called \textit{Guided Topology Diffusion (GTD)}. Inspired by
conditional discrete graph diffusion models, GTD formulates topology synthesis
as an iterative construction process. At each step, the generation is steered
by a lightweight proxy model that predicts multi-objective rewards (e.g.,
accuracy, utility, cost), enabling real-time, gradient-free optimization
towards task-adaptive topologies. This iterative, guided synthesis process
distinguishes GTD from single-step generative frameworks, enabling it to better
navigate complex design trade-offs. We validated GTD across multiple
benchmarks, and experiments show that this framework can generate highly
task-adaptive, sparse, and efficient communication topologies, significantly
outperforming existing methods in LLM agent collaboration.

</details>


### [146] [Multilingual Generative Retrieval via Cross-lingual Semantic Compression](https://arxiv.org/abs/2510.07812)
*Yuxin Huang,Simeng Wu,Ran Song,Yan Xiang,Yantuan Xian,Shengxiang Gao,Zhengtao Yu*

Main category: cs.CL

TL;DR: 本文提出了MGR-CSC框架，通过跨语义压缩方式优化多语种生成式检索，实现更高准确率与计算效率。核心贡献在于对跨语言标识对齐和标识膨胀问题的有效解决。实验证明在多个多语种检索数据集上准确率和压缩率均有较大提升。


<details>
  <summary>Details</summary>
Motivation: 生成式信息检索在单语环境下效果显著，但多语种应用中存在跨语义标识难对齐及标识空间冗余（膨胀）等问题，导致检索性能下降和资源浪费，亟需新方法提升跨语言检索效果及效率。

Method: 提出MGR-CSC（跨语义压缩多语种生成式检索）新框架：将多语种中等义关键词压缩为统一原子单元，增强语义对齐，同时通过文档标识空间压缩降低膨胀。提出多步动态限制解码策略，进一步提升跨语种检索时的效率。

Result: 在mMarco100k和mNQ320k多语种检索数据集实验证明，MGR-CSC精度分别提升6.83%和4.77%，文档标识长度分别压缩74.51%和78.2%。

Conclusion: MGR-CSC展现了在多语种生成式信息检索中的显著优势，有效对齐了跨语种语义并提升了解码和计算效率，为后续多语种信息检索研究提供了新思路。

Abstract: Generative Information Retrieval is an emerging retrieval paradigm that
exhibits remarkable performance in monolingual scenarios.However, applying
these methods to multilingual retrieval still encounters two primary
challenges, cross-lingual identifier misalignment and identifier inflation. To
address these limitations, we propose Multilingual Generative Retrieval via
Cross-lingual Semantic Compression (MGR-CSC), a novel framework that unifies
semantically equivalent multilingual keywords into shared atoms to align
semantics and compresses the identifier space, and we propose a dynamic
multi-step constrained decoding strategy during retrieval. MGR-CSC improves
cross-lingual alignment by assigning consistent identifiers and enhances
decoding efficiency by reducing redundancy. Experiments demonstrate that
MGR-CSC achieves outstanding retrieval accuracy, improving by 6.83% on
mMarco100k and 4.77% on mNQ320k, while reducing document identifiers length by
74.51% and 78.2%, respectively.

</details>


### [147] [AdaSwitch: Adaptive Switching Generation for Knowledge Distillation](https://arxiv.org/abs/2510.07842)
*Jingyu Peng,Maolin Wang,Hengyi Cai,Yuchen Li,Kai Zhang,Shuaiqiang Wang,Dawei Yin,Xiangyu Zhao*

Main category: cs.CL

TL;DR: 提出一种新方法AdaSwitch，通过动态结合on-policy和off-policy的知识蒸馏，提高小语言模型（SLM）的性能。该方法可以在保持训练推理一致性的同时，获得高质量的监督，实验证明其有效。


<details>
  <summary>Details</summary>
Motivation: 小语言模型性能受限于推理速度和计算能力，传统知识蒸馏方法有监督质量和一致性之间的权衡，亟需新方法兼顾两者以提升SLM实用性。

Method: 提出AdaSwitch方法，在生成每个token时动态选择on-policy（学生自身输出）与off-policy（教师输出）结合。学生模型优先探索自身预测，然后根据实时质量评估，灵活引入教师指导，从而兼顾输出一致性和高质量监督。

Result: 在三个数据集和两对师生大模型上实验，AdaSwitch方法能持续提升小模型准确率，同时引入的开销较低，展现了实际应用价值。

Conclusion: AdaSwitch为小语言模型蒸馏提供了一种高效且效果优良的新方法，能提升其性能而不显著增加复杂度，具有实际应用前景。

Abstract: Small language models (SLMs) are crucial for applications with strict latency
and computational constraints, yet achieving high performance remains
challenging. Knowledge distillation (KD) can transfer capabilities from large
teacher models, but existing methods involve trade-offs: off-policy
distillation provides high-quality supervision but introduces a
training-inference mismatch, while on-policy approaches maintain consistency
but rely on low-quality student outputs. To address these issues, we propose
AdaSwitch, a novel approach that dynamically combines on-policy and off-policy
generation at the token level. AdaSwitch allows the student to first explore
its own predictions and then selectively integrate teacher guidance based on
real-time quality assessment. This approach simultaneously preserves
consistency and maintains supervision quality. Experiments on three datasets
with two teacher-student LLM pairs demonstrate that AdaSwitch consistently
improves accuracy, offering a practical and effective method for distilling
SLMs with acceptable additional overhead.

</details>


### [148] [Ready to Translate, Not to Represent? Bias and Performance Gaps in Multilingual LLMs Across Language Families and Domains](https://arxiv.org/abs/2510.07877)
*Md. Faiyaz Abdullah Sayeedi,Md. Mahbub Alam,Subhey Sadi Rahman,Md. Adnanul Islam,Jannatul Ferdous Deepti,Tasnim Mohiuddin,Md Mofijul Islam,Swakkhar Shatabda*

Main category: cs.CL

TL;DR: 本文提出了Translation Tangles框架及数据集，用于系统性评估开源大语言模型的翻译质量与公平性，特别关注低资源语言。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在机器翻译领域取得显著进展，但在不同语言家族和专业领域中的表现仍不均衡，且存在放大训练数据偏见的问题，尤其影响低资源语言的公正性。现有评估体系缺乏对这些问题的系统检测，因此需要新的方法和数据集辅助评估。

Method: 作者构建了Translation Tangles框架，涵盖24个双向语言对、多领域文本，通过多种评价指标对LLM翻译效果进行基准测试。提出融合规则、语义相似度筛选及LLM验证的混合型偏见检测流程，并基于1439个人类评审的翻译对构建了带偏见标注的高质量数据集。

Result: Translation Tangles可全面评估LLM在多语种及不同领域下的翻译水平与公正性。新提出的偏见检测流程和数据集有效识别出训练数据中的偏见问题。相关代码与数据集已在GitHub开源。

Conclusion: Translation Tangles为评估及改进大语言模型翻译公平性与品质提供了有力工具，助力未来低资源语言和专业领域的研究发展。

Abstract: The rise of Large Language Models (LLMs) has redefined Machine Translation
(MT), enabling context-aware and fluent translations across hundreds of
languages and textual domains. Despite their remarkable capabilities, LLMs
often exhibit uneven performance across language families and specialized
domains. Moreover, recent evidence reveals that these models can encode and
amplify different biases present in their training data, posing serious
concerns for fairness, especially in low-resource languages. To address these
gaps, we introduce Translation Tangles, a unified framework and dataset for
evaluating the translation quality and fairness of open-source LLMs. Our
approach benchmarks 24 bidirectional language pairs across multiple domains
using different metrics. We further propose a hybrid bias detection pipeline
that integrates rule-based heuristics, semantic similarity filtering, and
LLM-based validation. We also introduce a high-quality, bias-annotated dataset
based on human evaluations of 1,439 translation-reference pairs. The code and
dataset are accessible on GitHub:
https://github.com/faiyazabdullah/TranslationTangles

</details>


### [149] [Do LLMs Really Need 10+ Thoughts for "Find the Time 1000 Days Later"? Towards Structural Understanding of LLM Overthinking](https://arxiv.org/abs/2510.07880)
*Xinliang Frederick Zhang,Anhad Mohananey,Alexandra Chronopoulou,Pinelopi Papalampidi,Somit Gupta,Tsendsuren Munkhdalai,Lu Wang,Shyam Upadhyay*

Main category: cs.CL

TL;DR: 本文提出通过细致追踪分析（TRACE）方法，深入理解LLMs在链式思维（CoT）推理中出现“过度思考”的本源与表现，发现其主要由过度验证和过度探索驱动，并为更有效的管理和衡量过度思考提出了基于效用的新定义。


<details>
  <summary>Details</summary>
Motivation: 尽管长链思维推理显著提升大模型的复杂任务能力，但在简单任务场景下却出现低效——模型在无需复杂推理时依然过度思考，导致算力消耗却无精度收益。此前对这一问题的研究多停留在表层，缺乏对模型内部推理机制的微观剖析，因此有必要提出更细致的分析方法，以揭示深层原因并改善推理效率。

Method: 本文提出TRACE工具，对大模型推理过程进行系统化、细粒度分解，将完整思维链拆解为最小完备的子思维片段，通过分析这些子思维间的话语结构关系，构建高精度的思维推进图谱，并归纳同类问题中常见的思考模式。

Result: 实验验证了长链思维模型在简单任务上推理速度明显下降（慢5-20倍）且精度无提升。细粒度思维图谱分析揭示，开放权重模型主要存在两大思维模式：探索者和延迟收敛型，其共性是过度验证和过度探索，系过度思考的主因。

Conclusion: 基于对思维结构的深入分析，作者提出了以推理效用（utility）为核心的新型过度思考定义，超越了以往的长度指标。该定义有助于进一步理解大模型推理过程，并为合理管控过度思考、提升计算效率提供了理论指导和实践路径。

Abstract: Models employing long chain-of-thought (CoT) reasoning have shown superior
performance on complex reasoning tasks. Yet, this capability introduces a
critical and often overlooked inefficiency -- overthinking -- models often
engage in unnecessarily extensive reasoning even for simple queries, incurring
significant computations without accuracy improvements. While prior work has
explored solutions to mitigate overthinking, a fundamental gap remains in our
understanding of its underlying causes. Most existing analyses are limited to
superficial, profiling-based observations, failing to delve into LLMs' inner
workings. This study introduces a systematic, fine-grained analyzer of LLMs'
thought process to bridge the gap, TRACE. We first benchmark the overthinking
issue, confirming that long-thinking models are five to twenty times slower on
simple tasks with no substantial gains. We then use TRACE to first decompose
the thought process into minimally complete sub-thoughts. Next, by inferring
discourse relationships among sub-thoughts, we construct granular thought
progression graphs and subsequently identify common thinking patterns for
topically similar queries. Our analysis reveals two major patterns for
open-weight thinking models -- Explorer and Late Landing. This finding provides
evidence that over-verification and over-exploration are the primary drivers of
overthinking in LLMs. Grounded in thought structures, we propose a
utility-based definition of overthinking, which moves beyond length-based
metrics. This revised definition offers a more insightful understanding of
LLMs' thought progression, as well as practical guidelines for principled
overthinking management.

</details>


### [150] [CS3-Bench: Evaluating and Enhancing Speech-to-Speech LLMs for Mandarin-English Code-Switching](https://arxiv.org/abs/2510.07881)
*Heyang Liu,Yuhao Wang,Ziyang Cheng,Ronghua Wu,Qunshan Gu,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 本文针对主流多模态大模型在语音到语音代码切换（code-switching）场景下的语言对齐（language alignment）能力不足的问题，提出了新的基准数据集CS3-Bench并提出了相应的改进方法，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 虽然当前多模态大模型在自然的单语语音交互上表现良好，但面对多语言混合（代码切换）情况下的知识密集型问答和开放式对话，模型的语言对齐能力存在明显缺陷，导致准确率大幅下降。本研究尝试解决这一短板，提升模型在真实多语环境中的实用性。

Method: 作者构建了Code-Switching Speech-to-Speech Benchmark（CS3-Bench）数据集，并在7个主流模型上进行实验，量化了模型在代码切换场景下的性能损失。针对性能低下的问题，提出了两种训练和数据改进方法：一是Chain of Recognition（CoR）加强理解能力，二是Keyword Highlighting（KH）引导内容生成。

Result: 实验表明，采用上述方法后，模型在知识类问题上的准确率从25.14%提升至46.13%，开放式理解率从64.5%提升至86.5%，并显著减少了次语言的语音发音错误。

Conclusion: CS3-Bench为评测多模态语音到语音交互系统在代码切换场景下的表现提供了有效工具，提出的方法能够明显提升模型在多语言切换时的语言对齐与理解能力。

Abstract: The advancement of multimodal large language models has accelerated the
development of speech-to-speech interaction systems. While natural monolingual
interaction has been achieved, we find existing models exhibit deficiencies in
language alignment. In our proposed Code-Switching Speech-to-Speech Benchmark
(CS3-Bench), experiments on 7 mainstream models demonstrate a relative
performance drop of up to 66% in knowledge-intensive question answering and
varying degrees of misunderstanding in open-ended conversations. Starting from
a model with severe performance deterioration, we propose both data
constructions and training approaches to improve the language alignment
capabilities, specifically employing Chain of Recognition (CoR) to enhance
understanding and Keyword Highlighting (KH) to guide generation. Our approach
improves the knowledge accuracy from 25.14% to 46.13%, with open-ended
understanding rate from 64.5% to 86.5%, and significantly reduces pronunciation
errors in the secondary language. CS3-Bench is available at
https://huggingface.co/datasets/VocalNet/CS3-Bench.

</details>


### [151] [Contrastive Weak-to-strong Generalization](https://arxiv.org/abs/2510.07884)
*Houcheng Jiang,Junfeng Fang,Jiaxin Wu,Tianyu Zhang,Chen Gao,Yong Li,Xiang Wang,Xiangnan He,Yang Deng*

Main category: cs.CL

TL;DR: 提出了一种增强大语言模型泛化能力的新方法，通过对比弱模型的对齐前后输出以提升训练数据质量，克服弱模型输出的噪声和偏差问题。


<details>
  <summary>Details</summary>
Motivation: 传统的weak-to-strong泛化方法，虽然方便实践，但由于弱模型输出的噪声和偏差，限制了可实际应用性。论文动机在于提升这一范式的鲁棒性和高质量泛化能力。

Method: 将隐式奖励（通过对数似然比近似显式奖励）与对比式解码（Contrastive Decoding，CD）结合，提出Contrastive Weak-to-Strong Generalization (ConG) 框架。该框架利用对齐前后弱模型的对比式解码生成更高质量样本，用以更好地训练强模型。

Result: 在不同模型家族上的大量实验证明，采用ConG方法能持续带来提升，表明其有效性和普适性。

Conclusion: ConG 框架有效解决了弱转强的一般性问题，显著提升了数据质量和鲁棒性，对弱到强泛化甚至通往AGI有积极推动作用。

Abstract: Weak-to-strong generalization provides a promising paradigm for scaling large
language models (LLMs) by training stronger models on samples from aligned
weaker ones, without requiring human feedback or explicit reward modeling.
However, its robustness and generalization are hindered by the noise and biases
in weak-model outputs, which limit its applicability in practice. To address
this challenge, we leverage implicit rewards, which approximate explicit
rewards through log-likelihood ratios, and reveal their structural equivalence
with Contrastive Decoding (CD), a decoding strategy shown to reduce noise in
LLM generation. Building on this connection, we propose Contrastive
Weak-to-Strong Generalization (ConG), a framework that employs contrastive
decoding between pre- and post-alignment weak models to generate higher-quality
samples. This approach enables more reliable capability transfer, denoising,
and improved robustness, substantially mitigating the limitations of
traditional weak-to-strong methods. Empirical results across different model
families confirm consistent improvements, demonstrating the generality and
effectiveness of ConG. Taken together, our findings highlight the potential of
ConG to advance weak-to-strong generalization and provide a promising pathway
toward AGI.

</details>


### [152] [Standard-to-Dialect Transfer Trends Differ across Text and Speech: A Case Study on Intent and Topic Classification in German Dialects](https://arxiv.org/abs/2510.07890)
*Verena Blaschke,Miriam Winkler,Barbara Plank*

Main category: cs.CL

TL;DR: 本文研究了标准德语向多种德语方言在意图与主题分类任务中的迁移能力，对比了文本模型、语音模型及两者级联系统，并发布了首个德语方言音频意图分类数据集。实验证明，语音模型在方言任务表现最佳，而文本模型适合标准德语；级联系统如能正则化转录，与方言文本模型效果接近。


<details>
  <summary>Details</summary>
Motivation: 此前的方言迁移研究多聚焦于文本，然而方言以口语为主且非标准拼写难处理。论文旨在探究在跨方言场景下，将标准德语的文本模型和语音模型迁移到德语多方言任务的效果差异，以弥合现有研究与实际语音交流的脱节。

Method: 作者分别构建了三个设置：1）只用文本模型、2）只用语音模型、3）先语音识别再用文本模型的级联合成系统，并在标准德语及若干德语方言的数据上，对意图和主题分类任务进行评测。新发布了德语方言音频意图分类数据集用于实验。

Result: 实验显示，语音模型在方言数据上的分类任务中表现最好，远超文本和级联系统；而标准德语下还是文本模型效果最好。级联系统虽然在标准德语下表现略差，但如能提供标准化的转录文本，也能在方言上取得较好成绩。

Conclusion: 语音模型对于处理德语方言更为有效，纯文本模型依然适合标准德语；对于方言，如果转录系统能有效正则化口语音频，则级联系统也能达到近似最佳效果。该工作为方言NLP任务提供了数据资源和模型对比分析。

Abstract: Research on cross-dialectal transfer from a standard to a non-standard
dialect variety has typically focused on text data. However, dialects are
primarily spoken, and non-standard spellings are known to cause issues in text
processing. We compare standard-to-dialect transfer in three settings: text
models, speech models, and cascaded systems where speech first gets
automatically transcribed and then further processed by a text model. In our
experiments, we focus on German and multiple German dialects in the context of
written and spoken intent and topic classification. To that end, we release the
first dialectal audio intent classification dataset. We find that the
speech-only setup provides the best results on the dialect data while the
text-only setup works best on the standard data. While the cascaded systems lag
behind the text-only models for German, they perform relatively well on the
dialectal data if the transcription system generates normalized, standard-like
output.

</details>


### [153] [Metric Calculating Benchmark: Code-Verifiable Complicate Instruction Following Benchmark for Large Language Models](https://arxiv.org/abs/2510.07892)
*Hyeonseok Moon,Seongtae Hong,Jaehyung Seo,Heuiseok Lim*

Main category: cs.CL

TL;DR: 本文提出MCBench基准，用以客观评测大语言模型（LLMs）在严格按照逐步指令执行字符串匹配类NLP任务时的表现，补足现有主观或推理类基准的不足。


<details>
  <summary>Details</summary>
Motivation: 当前前沿级大语言模型已攻克许多既有难点基准，模型间分化变小，迫切需要更具挑战且具客观性的新基准。

Method: 设计了MCBench基准，内容聚焦在LLMs准确按步骤执行字符串匹配类NLP指标，强调对指令的理解、数值计算、结果的一致性等，并为每步输出提供可验证的参照代码。包含三种评估指标及三种变体，细致考察LLM对指令的遵循能力。

Result: 分析表明，MCBench能有效、客观地考察当前前沿LLMs的能力，并补齐现有基准主观性强、缺乏可证实性的缺陷。

Conclusion: MCBench作为新一代基准，能为LLM客观能力评估提供有力工具，有助于推动相关领域模型的区分与进步。

Abstract: Recent frontier-level LLMs have saturated many previously difficult
benchmarks, leaving little room for further differentiation. This progress
highlights the need for challenging benchmarks that provide objective
verification. In this paper, we introduce MCBench, a benchmark designed to
evaluate whether LLMs can execute string-matching NLP metrics by strictly
following step-by-step instructions. Unlike prior benchmarks that depend on
subjective judgments or general reasoning, MCBench offers an objective,
deterministic and codeverifiable evaluation. This setup allows us to
systematically test whether LLMs can maintain accurate step-by-step execution,
including instruction adherence, numerical computation, and long-range
consistency in handling intermediate results. To ensure objective evaluation of
these abilities, we provide a parallel reference code that can evaluate the
accuracy of LLM output. We provide three evaluative metrics and three benchmark
variants designed to measure the detailed instruction understanding capability
of LLMs. Our analyses show that MCBench serves as an effective and objective
tool for evaluating the capabilities of cutting-edge LLMs.

</details>


### [154] [ACE: Attribution-Controlled Knowledge Editing for Multi-hop Factual Recall](https://arxiv.org/abs/2510.07896)
*Jiayu Yang,Yuxuan Fan,Songning Lai,Shengen Wu,Jiaqi Tang,Chun Kang,Zhijiang Guo,Yutao Yue*

Main category: cs.CL

TL;DR: 现有大语言模型（LLM）的知识编辑（KE）方法在多跳事实回忆任务上表现不佳，主要因为忽视了神经元层面上链式知识的动态表示。作者提出ACE框架，有效地提升了多跳知识编辑的能力。


<details>
  <summary>Details</summary>
Motivation: 大模型需及时更新事实性知识，但在涉及多步推理时，知识编辑方法性能大幅下降，特别是中间隐式主题难以处理。需要找到更有效的解决方案。

Method: 作者通过因果分析发现，多跳推理时隐式主题作为查询神经元，将信息积累至最终答案。基于此，提出ACE方法：利用神经元归因定位并编辑关键的查询-值(Q-V)路径，从而实现机制上合理的多跳知识编辑。

Result: ACE方法在GPT-J和Qwen3-8B模型上的多跳知识编辑任务中性能大幅提升，分别超越SOTA方法9.44%和37.46%。并揭示了Qwen3模型更细致的激活模式。

Conclusion: ACE为多跳知识编辑提供了机制层面的创新指导，丰富了模型内部推理机制的理解，为提升大模型事实更新能力开辟了新方向。

Abstract: Large Language Models (LLMs) require efficient knowledge editing (KE) to
update factual information, yet existing methods exhibit significant
performance decay in multi-hop factual recall. This failure is particularly
acute when edits involve intermediate implicit subjects within reasoning
chains. Through causal analysis, we reveal that this limitation stems from an
oversight of how chained knowledge is dynamically represented and utilized at
the neuron level. We discover that during multi hop reasoning, implicit
subjects function as query neurons, which sequentially activate corresponding
value neurons across transformer layers to accumulate information toward the
final answer, a dynamic prior KE work has overlooked. Guided by this insight,
we propose ACE: Attribution-Controlled Knowledge Editing for Multi-hop Factual
Recall, a framework that leverages neuron-level attribution to identify and
edit these critical query-value (Q-V) pathways. ACE provides a mechanistically
grounded solution for multi-hop KE, empirically outperforming state-of-the-art
methods by 9.44% on GPT-J and 37.46% on Qwen3-8B. Our analysis further reveals
more fine-grained activation patterns in Qwen3 and demonstrates that the
semantic interpretability of value neurons is orchestrated by query-driven
accumulation. These findings establish a new pathway for advancing KE
capabilities based on the principled understanding of internal reasoning
mechanisms.

</details>


### [155] [Towards Human-Like Grading: A Unified LLM-Enhanced Framework for Subjective Question Evaluation](https://arxiv.org/abs/2510.07912)
*Fanwei Zhua,Jiaxuan He,Xiaoxiao Chen,Zulong Chen,Quan Lu,Chenrui Mei*

Main category: cs.CL

TL;DR: 本文提出了一种统一的大语言模型（LLM）增强的自动主观题批改框架，能覆盖多种题型和领域，较现有方法更具广泛适用性和优异表现。


<details>
  <summary>Details</summary>
Motivation: 主观题自动评分难点主要在于题型多样和学生答案开放性强，现有方法大多针对特定题型，难以应对综合性考试的多元主观题批改需求。

Method: 提出一个融合四大模块的统一自动批改系统，包括：1）基础文本匹配，2）利用LLM对知识点提取与匹配，3）从学生答案生成伪问题以测试其与题目的关联性，4）模拟人工评估分析答案的内容及非内容优缺点。

Result: 在通用和特定领域的数据集上广泛实验，显示所提系统在各项评测指标上均优于传统及其他LLM自动批改基线系统。同时，该系统在大型电商企业的实际考试中成功部署应用。

Conclusion: 该LLM增强自动批改框架适用范围广、评估能力强，能有效支持多题型多领域的主观题自动评分，为实际考试评测提供可靠解决方案。

Abstract: Automatic grading of subjective questions remains a significant challenge in
examination assessment due to the diversity in question formats and the
open-ended nature of student responses. Existing works primarily focus on a
specific type of subjective question and lack the generality to support
comprehensive exams that contain diverse question types. In this paper, we
propose a unified Large Language Model (LLM)-enhanced auto-grading framework
that provides human-like evaluation for all types of subjective questions
across various domains. Our framework integrates four complementary modules to
holistically evaluate student answers. In addition to a basic text matching
module that provides a foundational assessment of content similarity, we
leverage the powerful reasoning and generative capabilities of LLMs to: (1)
compare key knowledge points extracted from both student and reference answers,
(2) generate a pseudo-question from the student answer to assess its relevance
to the original question, and (3) simulate human evaluation by identifying
content-related and non-content strengths and weaknesses. Extensive experiments
on both general-purpose and domain-specific datasets show that our framework
consistently outperforms traditional and LLM-based baselines across multiple
grading metrics. Moreover, the proposed system has been successfully deployed
in real-world training and certification exams at a major e-commerce
enterprise.

</details>


### [156] [STEPER: Step-wise Knowledge Distillation for Enhancing Reasoning Ability in Multi-Step Retrieval-Augmented Language Models](https://arxiv.org/abs/2510.07923)
*Kyumin Lee,Minjin Jeon,Sanghwan Jang,Hwanjo Yu*

Main category: cs.CL

TL;DR: 提出了一种名为StepER的逐步知识蒸馏方法，提升了多步检索增强语言模型在复杂推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法忽视了不同推理步骤对能力的不同需求，导致在多步检索增强框架中迁移效果不佳，因此需要改进知识蒸馏方法以适应这一挑战。

Method: StepER方法通过逐步监督来适配每个步骤的信息与推理需求，并引入难度感知训练，按难易优先优化模型学习进程。方法适用于各种多步检索增强型大语言模型，不限于基于检索查询或问题分解的方案。

Result: 大量实验表明，StepER在多跳问答基准上优于前人的方法，8B参数规模的模型甚至能达到70B教师模型的表现。

Conclusion: StepER有效提升了多步检索增强语言模型在复杂推理和问答任务中的能力，为提升小规模模型的推理能力提供了一种新的高效蒸馏方法。

Abstract: Answering complex real-world questions requires step-by-step retrieval and
integration of relevant information to generate well-grounded responses.
However, existing knowledge distillation methods overlook the need for
different reasoning abilities at different steps, hindering transfer in
multi-step retrieval-augmented frameworks. To address this, we propose Stepwise
Knowledge Distillation for Enhancing Reasoning Ability in Multi-Step
Retrieval-Augmented Language Models (StepER). StepER employs step-wise
supervision to align with evolving information and reasoning demands across
stages. Additionally, it incorporates difficulty-aware training to
progressively optimize learning by prioritizing suitable steps. Our method is
adaptable to various multi-step retrieval-augmented language models, including
those that use retrieval queries for reasoning paths or decomposed questions.
Extensive experiments show that StepER outperforms prior methods on multi-hop
QA benchmarks, with an 8B model achieving performance comparable to a 70B
teacher model.

</details>


### [157] [Comprehensiveness Metrics for Automatic Evaluation of Factual Recall in Text Generation](https://arxiv.org/abs/2510.07926)
*Adam Dejl,James Barry,Alessandra Pascale,Javier Carnerero Cano*

Main category: cs.CL

TL;DR: 本文针对大语言模型（LLMs）生成内容遗漏关键信息的问题，提出并比较三种自动化检测方法，实验结果发现端到端法效果意外突出，但牺牲了部分可解释性和健壮性。


<details>
  <summary>Details</summary>
Motivation: LLMs虽表现优秀，却常常遗漏重要信息或观点，尤其在敏感领域会造成严重后果。作者希望为模型输出的全面性评估提供有效自动化工具。

Method: 提出三种自动检测LLM输出疏漏的方法：1）基于自然语言推断（NLI）的方法，将文本拆解为原子命题并用NLI检测缺漏；2）基于问答的方法，抽取QA对并在多个来源间交叉比对答案差异；3）端到端方法，直接用LLM检测遗漏内容。最后比较不同方法效果，并在多个公开LLM上实测。

Result: 实验显示，端到端检测法虽然结构简单，却出人意料地优于更复杂方法，但在结果的健壮性、可解释性和内容粒度方面略逊一筹。还测试了多款主流开源LLM的回答全面性。

Conclusion: 虽然复杂方法设计精巧，但简化的端到端方案在检测遗漏上表现最佳。仍需权衡效果和健壮性、可解释性，未来可进一步完善自动化评估工具，提升模型输出的全面性。

Abstract: Despite demonstrating remarkable performance across a wide range of tasks,
large language models (LLMs) have also been found to frequently produce outputs
that are incomplete or selectively omit key information. In sensitive domains,
such omissions can result in significant harm comparable to that posed by
factual inaccuracies, including hallucinations. In this study, we address the
challenge of evaluating the comprehensiveness of LLM-generated texts, focusing
on the detection of missing information or underrepresented viewpoints. We
investigate three automated evaluation strategies: (1) an NLI-based method that
decomposes texts into atomic statements and uses natural language inference
(NLI) to identify missing links, (2) a Q&A-based approach that extracts
question-answer pairs and compares responses across sources, and (3) an
end-to-end method that directly identifies missing content using LLMs. Our
experiments demonstrate the surprising effectiveness of the simple end-to-end
approach compared to more complex methods, though at the cost of reduced
robustness, interpretability and result granularity. We further assess the
comprehensiveness of responses from several popular open-weight LLMs when
answering user queries based on multiple sources.

</details>


### [158] [Vision-Enabled LLMs in Historical Lexicography: Digitising and Enriching Estonian-German Dictionaries from the 17th and 18th Centuries](https://arxiv.org/abs/2510.07931)
*Madis Jürviste,Joonatan Jakobson*

Main category: cs.CL

TL;DR: 研究在爱沙尼亚语言研究所进行，利用大语言模型（LLMs）处理17、18世纪爱沙尼亚语词典，包括词汇现代化、哥特字体文本识别和统一数据集建设，实验表明LLMs显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 17-18世纪爱沙尼亚历史词典存在词汇、书写和结构差异，处理困难，研究旨在利用现代人工智能方法提升这些珍贵历史资料的数字化和利用效率。

Method: 通过给定上下文，使用具备视觉能力的LLMs（如Claude 3.7 Sonnet）实现词条释义和现代词形转化；采用zero-shot方法识别哥特字体文本；扫描图像叠加切片，并分别用LLM进行文本识别和结构化输出合并，构建统一数据集。

Result: Claude 3.7 Sonnet能为81%的词条准确给出现代表达与含义；zero-shot方法能将41%的头词结构化输出为无错误的JSON格式；条目数字化流程初步展现LLMs处理少数民族语言文献的强大潜力。

Conclusion: 即使对于小语种文献，LLMs也能大幅提升古籍数字化和数据集构建效率，节省大量时间与成本。

Abstract: This article presents research conducted at the Institute of the Estonian
Language between 2022 and 2025 on the application of large language models
(LLMs) to the study of 17th and 18th century Estonian dictionaries. The authors
address three main areas: enriching historical dictionaries with modern word
forms and meanings; using vision-enabled LLMs to perform text recognition on
sources printed in Gothic script (Fraktur); and preparing for the creation of a
unified, cross-source dataset. Initial experiments with J. Gutslaff's 1648
dictionary indicate that LLMs have significant potential for semi-automatic
enrichment of dictionary information. When provided with sufficient context,
Claude 3.7 Sonnet accurately provided meanings and modern equivalents for 81%
of headword entries. In a text recognition experiment with A. T. Helle's 1732
dictionary, a zero-shot method successfully identified and structured 41% of
headword entries into error-free JSON-formatted output. For digitising the
Estonian-German dictionary section of A. W. Hupel's 1780 grammar, overlapping
tiling of scanned image files is employed, with one LLM being used for text
recognition and a second for merging the structured output. These findings
demonstrate that even for minor languages LLMs have a significant potential for
saving time and financial resources.

</details>


### [159] [A$^2$Search: Ambiguity-Aware Question Answering with Reinforcement Learning](https://arxiv.org/abs/2510.07958)
*Fengji Zhang,Xinyao Niu,Chengyang Ying,Guancheng Lin,Zhongkai Hao,Zhou Fan,Chengen Huang,Jacky Keung,Bei Chen,Junyang Lin*

Main category: cs.CL

TL;DR: A2Search是一种处理问答歧义、无需人工标注的端到端训练框架，显著提升了问答系统在多答案问题上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型和强化学习已提升开放域问答表现，但对多答案问题依然处理不佳，标准数据集假设唯一答案导致训练信号失真，且现有多答案处理成本高、难以扩展。

Method: 提出A2Search框架，采用自动流程识别歧义问题，通过轨迹采样和证据验证收集多种答案，用RL优化并设计能兼容多答案的AnsF1 reward，无需手工标注。

Result: 在8个开放域问答数据集上评测，A2Search取得新SOTA，多跳问答中的AnsF1@1分数大幅超过以往，包括比参数更大的模型。

Conclusion: A2Search有效识别和处理开放域问答的歧义，多答案能力促进了问答系统可靠性，是构建更可靠问答系统的重要进步。

Abstract: Recent advances in Large Language Models (LLMs) and Reinforcement Learning
(RL) have led to strong performance in open-domain question answering (QA).
However, existing models still struggle with questions that admit multiple
valid answers. Standard QA benchmarks, which typically assume a single gold
answer, overlook this reality and thus produce inappropriate training signals.
Existing attempts to handle ambiguity often rely on costly manual annotation,
which is difficult to scale to multi-hop datasets such as HotpotQA and MuSiQue.
In this paper, we present A$^2$Search, an annotation-free, end-to-end training
framework to recognize and handle ambiguity. At its core is an automated
pipeline that detects ambiguous questions and gathers alternative answers via
trajectory sampling and evidence verification. The model is then optimized with
RL using a carefully designed $\mathrm{AnsF1}$ reward, which naturally
accommodates multiple answers. Experiments on eight open-domain QA benchmarks
demonstrate that A$^2$Search achieves new state-of-the-art performance. With
only a single rollout, A$^2$Search-7B yields an average $\mathrm{AnsF1}@1$
score of $48.4\%$ across four multi-hop benchmarks, outperforming all strong
baselines, including the substantially larger ReSearch-32B ($46.2\%$).
Extensive analyses further show that A$^2$Search resolves ambiguity and
generalizes across benchmarks, highlighting that embracing ambiguity is
essential for building more reliable QA systems. Our code, data, and model
weights can be found at https://github.com/zfj1998/A2Search

</details>


### [160] [LightReasoner: Can Small Language Models Teach Large Language Models Reasoning?](https://arxiv.org/abs/2510.07962)
*Jingyuan Wang,Yankai Chen,Zhonghang Li,Chao Huang*

Main category: cs.CL

TL;DR: 提出一种新方法LightReasoner，让小模型（SLM）通过行为差异帮助大模型（LLM）提升推理能力，大幅提高推理准确率并降低训练成本。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型推理能力提升主要依赖于资源密集的有监督微调，需要大量标注数据和计算资源，而且并非所有训练样本都具备关键学习价值。本文希望寻找一种更高效、低成本的训练方法。

Method: 提出LightReasoner方法，分两个阶段：1）采样阶段，通过对比强大模型（LLM）与较弱模型（SLM）的行为，自动找到并构建体现LLM推理优势的关键样本；2）微调阶段，利用这些高价值样本进一步优化LLM，从而放大其推理能力。整个过程无需人工提供真值标签。

Result: 在七个数学基准测试上，LightReasoner使推理准确率提升最多达28.1%；相比常规方法，训练时间减少90%，采样问题减少80%，微调token使用量减少99%。

Conclusion: LightReasoner能让小模型为大模型的推理训练提供有价值的教学信号，不仅提升准确率，还极大节省了人力和计算资源，为大模型推理能力的发展提供了可扩展的新途径。

Abstract: Large language models (LLMs) have demonstrated remarkable progress in
reasoning, often through supervised fine-tuning (SFT). However, SFT is
resource-intensive, relying on large curated datasets, rejection-sampled
demonstrations, and uniform optimization across all tokens, even though only a
fraction carry meaningful learning value. In this work, we explore a
counterintuitive idea: can smaller language models (SLMs) teach larger language
models (LLMs) by revealing high-value reasoning moments that reflect the
latter's unique strength? We propose LightReasoner, a novel framework that
leverages the behavioral divergence between a stronger expert model (LLM) and a
weaker amateur model (SLM). LightReasoner operates in two stages: (1) a
sampling stage that pinpoints critical reasoning moments and constructs
supervision examples capturing the expert's advantage through expert-amateur
contrast, and (2) a fine-tuning stage that aligns the expert model with these
distilled examples, amplifying its reasoning strengths. Across seven
mathematical benchmarks, LightReasoner improves accuracy by up to 28.1%, while
reducing time consumption by 90%, sampled problems by 80%, and tuned token
usage by 99%, all without relying on ground-truth labels. By turning weaker
SLMs into effective teaching signals, LightReasoner offers a scalable and
resource-efficient approach for advancing LLM reasoning. Code is available at:
https://github.com/HKUDS/LightReasoner

</details>


### [161] [Active Confusion Expression in Large Language Models: Leveraging World Models toward Better Social Reasoning](https://arxiv.org/abs/2510.07974)
*Jialu Du,Guiyang Hou,Yihui Fu,Chen Wu,Wenqi Zhang,Yongliang Shen,Weiming Lu*

Main category: cs.CL

TL;DR: 大模型在社会推理任务中表现不佳，会混淆客观世界与主观信念，作者提出动态文本世界模型增强推理机制显著提升了模型表现，并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在数学和代码推理上表现优异，但在需要区分客观世界和个体信念状态的社会推理任务上存在严重缺陷。因此，作者希望解决大模型在多主体、多时间线场景下推理混乱的问题。

Method: 提出了一种动态文本世界模型增强推理机制。该机制实时追踪实体状态与时间序列，监测推理过程中的混淆信号，并通过提供清晰世界状态描述主动干预，从而帮助模型走出推理困境。该机制模拟了人类借助隐式世界模型区分外部事件与内在信念的过程。

Result: 在三个社会推理基准集上评测，该方法显著提升了推理准确率（例如在Hi-ToM数据集上提升了10%），同时还减少了计算所需的token数量（最高减少33.8%）。

Conclusion: 动态文本世界模型增强机制可大幅改善大模型的社会推理表现，是一种简单且高效的应对实际社会场景下推理难题的方案。

Abstract: While large language models (LLMs) excel in mathematical and code reasoning,
we observe they struggle with social reasoning tasks, exhibiting cognitive
confusion, logical inconsistencies, and conflation between objective world
states and subjective belief states. Through deteiled analysis of DeepSeek-R1's
reasoning trajectories, we find that LLMs frequently encounter reasoning
impasses and tend to output contradictory terms like "tricky" and "confused"
when processing scenarios with multiple participants and timelines, leading to
erroneous reasoning or infinite loops. The core issue is their inability to
disentangle objective reality from agents' subjective beliefs. To address this,
we propose an adaptive world model-enhanced reasoning mechanism that constructs
a dynamic textual world model to track entity states and temporal sequences. It
dynamically monitors reasoning trajectories for confusion indicators and
promptly intervenes by providing clear world state descriptions, helping models
navigate through cognitive dilemmas. The mechanism mimics how humans use
implicit world models to distinguish between external events and internal
beliefs. Evaluations on three social benchmarks demonstrate significant
improvements in accuracy (e.g., +10% in Hi-ToM) while reducing computational
costs (up to 33.8% token reduction), offering a simple yet effective solution
for deploying LLMs in social contexts.

</details>


### [162] [Leveraging Author-Specific Context for Scientific Figure Caption Generation: 3rd SciCap Challenge](https://arxiv.org/abs/2510.07993)
*Watcharapong Timklaypachara,Monrada Chiewhawan,Nopporn Lekuthai,Titipat Achakulvisut*

Main category: cs.CL

TL;DR: 本文提出了一种用于科学图像说明生成的系统，通过结合上下文信息与作者写作风格，实现准确且风格一致的说明生成，并在3rd SciCap Challenge上显著提升相关指标。


<details>
  <summary>Details</summary>
Motivation: 科学图像说明需要既要内容准确又要风格统一。目前自动生成系统难以兼顾上下文语境与写作风格，因此需要新的方法提升说明质量，满足学术写作需求。

Method: 提出两阶段的说明生成系统。第一阶段：结合上下文过滤、基于类别的提示优化，通过DSPy的MIPROv2和SIMBA生成并筛选说明候选。第二阶段：使用小样本提示，利用作者档案中的图像对说明进行风格化微调。

Result: 基于类别的提示优化比零样本和泛化优化方法更优，ROUGE-1召回提升8.3%，精确度损失仅-2.8%，BLEU-4下降-10.9%。风格化微调带来BLEU提升40-48%，ROUGE提升25-27%。

Conclusion: 将上下文理解与作者风格自适应结合，能够生成既准确又符合原论文风格的科学图像说明，显著优于传统生成方法。

Abstract: Scientific figure captions require both accuracy and stylistic consistency to
convey visual information. Here, we present a domain-specific caption
generation system for the 3rd SciCap Challenge that integrates figure-related
textual context with author-specific writing styles using the LaMP-Cap dataset.
Our approach uses a two-stage pipeline: Stage 1 combines context filtering,
category-specific prompt optimization via DSPy's MIPROv2 and SIMBA, and caption
candidate selection; Stage 2 applies few-shot prompting with profile figures
for stylistic refinement. Our experiments demonstrate that category-specific
prompts outperform both zero-shot and general optimized approaches, improving
ROUGE-1 recall by +8.3\% while limiting precision loss to -2.8\% and BLEU-4
reduction to -10.9\%. Profile-informed stylistic refinement yields 40--48\%
gains in BLEU scores and 25--27\% in ROUGE. Overall, our system demonstrates
that combining contextual understanding with author-specific stylistic
adaptation can generate captions that are both scientifically accurate and
stylistically faithful to the source paper.

</details>


### [163] [Learning on the Job: An Experience-Driven Self-Evolving Agent for Long-Horizon Tasks](https://arxiv.org/abs/2510.08002)
*Cheng Yang,Xuemeng Yang,Licheng Wen,Daocheng Fu,Jianbiao Mei,Rong Wu,Pinlong Cai,Yufan Shen,Nianchen Deng,Botian Shi,Yu Qiao,Haifeng Li*

Main category: cs.CL

TL;DR: MUSE是一种新型AI代理框架，采用分层记忆模块实现基于经验的自我进化和持续学习，在长周期任务自动化中取得SOTA表现。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在真实世界长周期任务中的应用存在局限，尤其是在测试阶段模型无法根据经验持续学习和改进，其知识无法积累和自我进化。

Method: MUSE框架引入分层记忆模块，将代理执行过程中的原始轨迹结构化为经验并不断集成回系统存储。每个子任务结束后，代理会自省并转换和存储经验，实现模型超越静态参数自我进化。

Result: 在长周期生产力基准任务TAC上，MUSE即使只用轻量Gemini-2.5 Flash模型也能以显著优势取得新的SOTA成绩。实验验证其随着经验积累在任务完成、持续学习和自我进化等方面表现越来越好，且其经验对新任务有很强的泛化和零样本改进能力。

Conclusion: MUSE为AI代理在真实生产任务自动化树立了新范式，证明了基于经验累积与自我进化的持续学习机制的有效性和广阔应用前景。

Abstract: Large Language Models have demonstrated remarkable capabilities across
diverse domains, yet significant challenges persist when deploying them as AI
agents for real-world long-horizon tasks. Existing LLM agents suffer from a
critical limitation: they are test-time static and cannot learn from
experience, lacking the ability to accumulate knowledge and continuously
improve on the job. To address this challenge, we propose MUSE, a novel agent
framework that introduces an experience-driven, self-evolving system centered
around a hierarchical Memory Module. MUSE organizes diverse levels of
experience and leverages them to plan and execute long-horizon tasks across
multiple applications. After each sub-task execution, the agent autonomously
reflects on its trajectory, converting the raw trajectory into structured
experience and integrating it back into the Memory Module. This mechanism
enables the agent to evolve beyond its static pretrained parameters, fostering
continuous learning and self-evolution. We evaluate MUSE on the long-horizon
productivity benchmark TAC. It achieves new SOTA performance by a significant
margin using only a lightweight Gemini-2.5 Flash model. Sufficient Experiments
demonstrate that as the agent autonomously accumulates experience, it exhibits
increasingly superior task completion capabilities, as well as robust
continuous learning and self-evolution capabilities. Moreover, the accumulated
experience from MUSE exhibits strong generalization properties, enabling
zero-shot improvement on new tasks. MUSE establishes a new paradigm for AI
agents capable of real-world productivity task automation.

</details>


### [164] [ChatGPT as a Translation Engine: A Case Study on Japanese-English](https://arxiv.org/abs/2510.08042)
*Vincent Michael Sutanto,Giovanni Gatti De Giacomo,Toshiaki Nakazawa,Masaru Yamada*

Main category: cs.CL

TL;DR: 本研究评估了ChatGPT在日英翻译任务中的表现，发现文档级翻译优于句子级，ChatGPT与主流翻译系统竞争力强。


<details>
  <summary>Details</summary>
Motivation: 近年来大型语言模型在翻译领域展现出巨大潜力，研究者希望探究ChatGPT在日英翻译中的表现，并比较不同提示词与传统翻译引擎的效果。

Method: 通过设计简易及增强型提示词，令ChatGPT生成翻译，同时对比主流商用翻译引擎。评估方式包括自动化指标和基于MQM标准的人类主观评价，并区分文档级与句子级翻译。

Result: 实验结果显示，ChatGPT在文档级翻译中表现优于句子级，对于提示词复杂度尚无显著差异，而ChatGPT-3.5在自动评价上优于4.0，但3.5与4.0在准确性与流畅性上存在权衡。整体而言，ChatGPT在与两大翻译公司系统对比中表现具有竞争力。

Conclusion: ChatGPT在日英翻译领域具备与主流翻译引擎竞争的实力，且文档级输入优势明显。但提示词增强并未带来必然提升，且模型在准确性与流畅性之间仍需权衡。

Abstract: This study investigates ChatGPT for Japanese-English translation, exploring
simple and enhanced prompts and comparing against commercially available
translation engines. Performing both automatic and MQM-based human evaluations,
we found that document-level translation outperforms sentence-level translation
for ChatGPT. On the other hand, we were not able to determine if enhanced
prompts performed better than simple prompts in our experiments. We also
discovered that ChatGPT-3.5 was preferred by automatic evaluation, but a
tradeoff exists between accuracy (ChatGPT-3.5) and fluency (ChatGPT-4). Lastly,
ChatGPT yields competitive results against two widely-known translation
systems.

</details>


### [165] [Climate Knowledge in Large Language Models](https://arxiv.org/abs/2510.08043)
*Ivan Kuznetsov,Jacopo Grassi,Dmitrii Pantiukhin,Boris Shapkin,Thomas Jung,Nikolay Koldunov*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型（LLMs）在不借助外部检索的情况下，能否准确回忆和生成关于全球气候常值（如气温）的知识。结果显示LLMs对全球气候结构有一定编码能力，但区域和局部气候变化的表现有限，尤其在高海拔和高纬度地区表现较差。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在气候相关应用中的普及，了解其内部气候知识的可靠性对于降低传播错误信息的风险变得尤为重要。但目前尚未系统分析LLMs能否准确记忆和输出参数化的气候常值，这限制了其在科学、高准确性场景下的应用。

Method: 作者以“1991-2020年7月全球各地2米高气温均值”为代表性问题，构建了全世界1度网格的查询集，向LLMs提问并给定经纬度及相关地理描述，然后将模型输出与ERA5再分析数据进行对比，量化误差，并分析了地理上下文信息对模型表现的影响。

Result: LLMs对纬度、高程等气候结构有非平凡的捕捉能力，整体均方根误差为3-6℃，偏差约±1℃。但在高山和高纬地区的误差更为集中，海拔高于1500米时均方根误差升至5-13℃。增加地理上下文信息使误差平均减少了27%。虽然模型能再现全球变暖的平均幅度，但无法还原区域和空间格局。

Conclusion: LLMs能够学习到当前全球气候的平均分布，但对气候变化的空间异质性和长期趋势表达不足，无法准确反映地区性气候变迁。该文提出的评价框架为量化LLMs气候知识提供了可复现的基准，可作为后续模型提升和气候传播的参考。

Abstract: Large language models (LLMs) are increasingly deployed for climate-related
applications, where understanding internal climatological knowledge is crucial
for reliability and misinformation risk assessment. Despite growing adoption,
the capacity of LLMs to recall climate normals from parametric knowledge
remains largely uncharacterized. We investigate the capacity of contemporary
LLMs to recall climate normals without external retrieval, focusing on a
prototypical query: mean July 2-m air temperature 1991-2020 at specified
locations. We construct a global grid of queries at 1{\deg} resolution land
points, providing coordinates and location descriptors, and validate responses
against ERA5 reanalysis. Results show that LLMs encode non-trivial climate
structure, capturing latitudinal and topographic patterns, with
root-mean-square errors of 3-6 {\deg}C and biases of $\pm$1 {\deg}C. However,
spatially coherent errors remain, particularly in mountains and high latitudes.
Performance degrades sharply above 1500 m, where RMSE reaches 5-13 {\deg}C
compared to 2-4 {\deg}C at lower elevations. We find that including geographic
context (country, city, region) reduces errors by 27% on average, with larger
models being most sensitive to location descriptors. While models capture the
global mean magnitude of observed warming between 1950-1974 and 2000-2024, they
fail to reproduce spatial patterns of temperature change, which directly relate
to assessing climate change. This limitation highlights that while LLMs may
capture present-day climate distributions, they struggle to represent the
regional and local expression of long-term shifts in temperature essential for
understanding climate dynamics. Our evaluation framework provides a
reproducible benchmark for quantifying parametric climate knowledge in LLMs and
complements existing climate communication assessments.

</details>


### [166] [A Survey of Process Reward Models: From Outcome Signals to Process Supervisions for Large Language Models](https://arxiv.org/abs/2510.08049)
*Congming Zheng,Jiachen Zhu,Zhuoying Ou,Yuxiang Chen,Kangning Zhang,Rong Shan,Zeyu Zheng,Mengyue Yang,Jianghao Lin,Yong Yu,Weinan Zhang*

Main category: cs.CL

TL;DR: 本文系统综述了过程奖励模型(Process Reward Models, PRMs)在对大语言模型（LLMs）推理过程进行对齐中的最新进展、方法和挑战。


<details>
  <summary>Details</summary>
Motivation: 现有主流的对齐方法主要使用结果奖励模型（ORMs），只关注最终答案的优劣，忽视了推理中的过程合理性。为了更好地提升模型推理细粒度的鲁棒性与对齐，学界提出了PRMs，以评估和引导模型在推理步骤或推理轨迹中的表现。

Method: 本文从生成推理过程标注数据、PRM的构建、以及如何在推理阶段和强化学习中利用PRMs等环节进行了系统梳理，并总结了其在数学、编程、文本、多模态推理、机器人与智能体等领域的应用及相关基准测评。

Result: 本文厘清了PRMs的设计空间，总结了应用实例，概括了当前出现的新型评测标准，同时归纳了实现PRMs过程中面临的主要挑战。

Conclusion: 该综述旨在为后续实现更细粒度、鲁棒的推理过程对齐提供理论总结和实践指导，为未来研究指出挑战与发展方向。

Abstract: Although Large Language Models (LLMs) exhibit advanced reasoning ability,
conventional alignment remains largely dominated by outcome reward models
(ORMs) that judge only final answers. Process Reward Models(PRMs) address this
gap by evaluating and guiding reasoning at the step or trajectory level. This
survey provides a systematic overview of PRMs through the full loop: how to
generate process data, build PRMs, and use PRMs for test-time scaling and
reinforcement learning. We summarize applications across math, code, text,
multimodal reasoning, robotics, and agents, and review emerging benchmarks. Our
goal is to clarify design spaces, reveal open challenges, and guide future
research toward fine-grained, robust reasoning alignment.

</details>


### [167] [FedDTRE: Federated Dialogue Generation Models Powered by Trustworthiness Evaluation](https://arxiv.org/abs/2510.08058)
*Shule Lu,Lingxiang Wang,Sijia Wen,Ziwei Wang,Hainan Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为FedDTRE的联邦对话生成模型，能够在保护隐私和提升个性化的前提下，提高对话系统的生成质量和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有对话系统在隐私保护和个性化之间难以兼顾，尤其在联邦学习中，因用户数据有限导致过拟合，并且多轮训练后全局信息易遗忘，导致模型泛化能力差。

Method: 作者提出FedDTRE，在本地更新时不再直接用全局模型替换本地模型，而是基于在公平评价数据集上的全局与本地模型的可信度分数，动态调整全局模型对本地更新的贡献，从而更好平衡本地和全局信息。

Result: 实验结果表明FedDTRE在多项指标上提升了联邦对话系统的对话生成表现和整体质量。

Conclusion: FedDTRE有效缓解了联邦学习对话系统中的过拟合和遗忘问题，实现了更优的个性化与泛化平衡，对隐私敏感场景下的人机对话具有实用价值。

Abstract: With the rapid development of artificial intelligence, dialogue systems have
become a prominent form of human-computer interaction. However, traditional
centralized or fully local training approaches face challenges in balancing
privacy preservation and personalization due to data privacy concerns and
heterogeneous device capabilities. Federated learning, as a representative
distributed paradigm, offers a promising solution. However, existing methods
often suffer from overfitting under limited client data and tend to forget
global information after multiple training rounds, leading to poor
generalization. To address these issues, we propose FedDTRE, a Federated
adaptive aggregation strategy for Dialogue generation based on Trustworthiness
Evaluation. Instead of directly replacing local models with the global model,
FedDTRE leverages trustworthiness scores of both global and local models on a
fairness-oriented evaluation dataset to dynamically regulate the global model's
contribution during local updates. Experimental results demonstrate that
FedDTRE can improve dialogue model performance and enhance the quality of
dialogue generation.

</details>


### [168] [Everything is Plausible: Investigating the Impact of LLM Rationales on Human Notions of Plausibility](https://arxiv.org/abs/2510.08091)
*Shramay Palta,Peter Rankel,Sarah Wiegreffe,Rachel Rudinger*

Main category: cs.CL

TL;DR: 本文研究LLM（大型语言模型）生成的理由对人类在常识选择题上的答案可信度判断的影响，发现无论正反理由，人类判断都会受到影响。


<details>
  <summary>Details</summary>
Motivation: 尽管人类在常识领域被认为是专家，但LLM生成的理由是否能影响人类的判断尚不清楚。探究这一点有助于了解LLM对人类认知和决策的潜在影响及应用风险。

Method: 收集了3000个人类和13600个LLM对选择题答案可信度的判断。在提供LLM自动生成的支持（PRO）或反对（CON）理由的条件下，考察不同情景下人类和LLM可信度评分的变化和偏移。

Result: 当呈现支持理由时，人类对答案的可信度评分平均上升；当呈现反对理由时，评分下降。LLM自身在这些条件下也表现出类似趋势。这表明人类很容易被LLM生成的理由说服。

Conclusion: LLM生成的理由能显著影响人类对常识问题答案的判断，即便在专家领域也如此。这不仅为利用LLM研究人类认知提供了新方法，也提示了在LLM辅助决策中，人类易受影响的潜在风险。

Abstract: We investigate the degree to which human plausibility judgments of
multiple-choice commonsense benchmark answers are subject to influence by
(im)plausibility arguments for or against an answer, in particular, using
rationales generated by LLMs. We collect 3,000 plausibility judgments from
humans and another 13,600 judgments from LLMs. Overall, we observe increases
and decreases in mean human plausibility ratings in the presence of
LLM-generated PRO and CON rationales, respectively, suggesting that, on the
whole, human judges find these rationales convincing. Experiments with LLMs
reveal similar patterns of influence. Our findings demonstrate a novel use of
LLMs for studying aspects of human cognition, while also raising practical
concerns that, even in domains where humans are ``experts'' (i.e., common
sense), LLMs have the potential to exert considerable influence on people's
beliefs.

</details>


### [169] [The Price of Thought: A Multilingual Analysis of Reasoning, Performance, and Cost of Negotiation in Large Language Models](https://arxiv.org/abs/2510.08098)
*Sherzod Hakimov,Roland Bernard,Tim Leiber,Karl Osswald,Kristina Richert,Ruilin Yang,Raffaella Bernardi,David Schlangen*

Main category: cs.CL

TL;DR: 本文系统性研究了大语言模型（LLM）在谈判场景下启用推理能力的影响，以及多语言环境下表现。主要发现推理显著提升了模型的谈判能力，但带来高昂的计算成本，同时存在多语言推理一致性差异。


<details>
  <summary>Details</summary>
Motivation: AI系统中的谈判任务需要兼顾策略性推理、对手建模及合作与竞争的平衡。随着LLM的快速发展，探究推理能力对谈判表现的影响，以及在多语言、不同模型（开源与商用）中的差异，具有理论和实际应用价值。

Method: 作者以自博弈（self-play）方式，设定三种多样化的对话谈判游戏，分别在商业化LLM与开源权重LLM，在英语、德语和意大利语三种语言下系统测试推理开启和关闭对谈判表现、成本、以及推理过程语言一致性等方面的影响。

Result: （1）推理显著提升了谈判表现，如GPT-5在开启推理后，表现提升31.4%，但成本上升近400%；（2）商业LLM在推理和输出过程中保持语言一致性，而开源LLM即便任务为德语或意大利语，也倾向于用英语做内部推理。这影响了推理轨迹解释的可用性。

Conclusion: 推理能力提升了LLM的谈判及协作能力，但需权衡计算资源消耗。模型的多语言推理一致性存在差异，设计透明、可解释的推理机制需关注语言切换问题，对多语言AI系统发展具有启示意义。

Abstract: Negotiation is a fundamental challenge for AI agents, as it requires an
ability to reason strategically, model opponents, and balance cooperation with
competition. We conduct the first comprehensive study systematically evaluating
the effect of (LLM-)reasoning on the negotiation abilities of both commercial
and open-weight LLMs, and do this across three languages. Using a self-play
setup across three diverse dialogue games, we analyse trade-offs between
performance and cost, the language consistency of reasoning processes, and the
nature of strategic adaptation exhibited by models. Our findings show that
enabling reasoning-that is, scaling test time compute-significantly improves
negotiation outcomes by enhancing collaboration and helping models overcome
task complexities, but comes at a substantial computational cost: reasoning
improves GPT-5's performance by 31.4 % while increasing its cost by nearly 400
%. Most critically, we uncover a significant multilingual reasoning
distinction: open-weight models consistently switch to English for their
internal reasoning steps, even when negotiating in German or Italian (and thus
possibly impacting potential explainability gains through the disclosure of
reasoning traces), while leading commercial models maintain language
consistency between their reasoning and final output.

</details>


### [170] [Lossless Vocabulary Reduction for Auto-Regressive Language Models](https://arxiv.org/abs/2510.08102)
*Daiki Chijiwa,Taku Hasegawa,Kyosuke Nishida,Shin'ya Yamaguchi,Tomoya Ohba,Tamao Sakao,Susumu Takeuchi*

Main category: cs.CL

TL;DR: 本文提出了一种无损词表缩减的理论框架，实现语言模型词表缩减且准确率不损失，并支持不同分词标准的模型高效协作。


<details>
  <summary>Details</summary>
Motivation: 目前主流语言模型在分词和词表设置上各有不同，这导致它们很难在下一个token分布层面（如模型集成）协同工作。提升模型间兼容性和协作能力成为挑战。

Method: 提出一种无损词表缩减的理论方法，可以将已有的自回归语言模型转换为词表任意小的新模型，同时保持生成文本的准确率不变。

Result: 实验证明该方法能让用不同分词法的各语言模型通过共用的最大公共词表实现高效协作，从而使模型集成成为可能。

Conclusion: 该理论框架为语言模型间的高效协作和集成提供了可能，有助于提升模型的通用性和适应性。

Abstract: Tokenization -- the process of decomposing a given text into a sequence of
subwords called tokens -- is one of the key components in the development of
language models. Particularly, auto-regressive language models generate texts
token by token, i.e., by predicting the next-token distribution given the
previous ones, and thus tokenization directly affects their efficiency in text
generation. Since each language model has their own vocabulary as a set of
possible tokens, they struggle to cooperate with each other at the level of
next-token distributions such as model ensemble. In this paper, we establish a
theoretical framework of lossless vocabulary reduction, which efficiently
converts a given auto-regressive language model into the one with an
arbitrarily small vocabulary without any loss in accuracy. As an application,
we demonstrate that language models with different tokenization can cooperate
with each other efficiently through their maximal common vocabulary.

</details>


### [171] [Evaluating LLM-Generated Legal Explanations for Regulatory Compliance in Social Media Influencer Marketing](https://arxiv.org/abs/2510.08111)
*Haoyang Gui,Thales Bertaglia,Taylor Annabell,Catalina Goanta,Tjomme Dooper,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 本论文针对网红营销中隐性广告内容识别的法律挑战，分析大模型在该任务上的表现与推理错误，并提出提升法律合规性的建议。


<details>
  <summary>Details</summary>
Motivation: 随着网红营销兴起，广告内容与自然内容界限变得模糊，导致广告透明度监管变得更困难。现有检测方法缺乏法律依据或透明度，难以满足法律合规的需求。因此，探索如何用大模型结合法律知识更有效、合规地检测隐性广告内容成为迫切需求。

Method: 作者基于1,143条Instagram帖子，比较了gpt-5-nano和gemini-2.5-flash-lite两种LLM在不同法律知识输入下的表现，采用三种提示策略，对模型输出进行定量（如F1值）和定性（推理错误分类）分析，并构建了一套LLM推理常见错误的分类法。模型输出由经培训的法律学生标注，用于质量评估。

Result: 两种模型在识别是否为广告内容任务上表现良好（F1最高0.93），但在模糊样本上准确率下降10点以上。推理常见错误包括引用遗漏（28.57%）、引用不清（20.71%）、隐性广告识别失败（28.57%）。在提示中加入法规条文本能提升输出解释质量，但对检测准确率提升有限。

Conclusion: 该研究首次为法律合规型自动检测模型提供了细致的推理错误分类工具，丰富了监管技术的理论和实践基础。研究结果对广告监管方自动化审核流程有重要参考价值。数据集和方法的结合也为后续提升模型法律合规性及透明性提供了方向。

Abstract: The rise of influencer marketing has blurred boundaries between organic
content and sponsored content, making the enforcement of legal rules relating
to transparency challenging. Effective regulation requires applying legal
knowledge with a clear purpose and reason, yet current detection methods of
undisclosed sponsored content generally lack legal grounding or operate as
opaque "black boxes". Using 1,143 Instagram posts, we compare gpt-5-nano and
gemini-2.5-flash-lite under three prompting strategies with controlled levels
of legal knowledge provided. Both models perform strongly in classifying
content as sponsored or not (F1 up to 0.93), though performance drops by over
10 points on ambiguous cases. We further develop a taxonomy of reasoning
errors, showing frequent citation omissions (28.57%), unclear references
(20.71%), and hidden ads exhibiting the highest miscue rate (28.57%). While
adding regulatory text to the prompt improves explanation quality, it does not
consistently improve detection accuracy. The contribution of this paper is
threefold. First, it makes a novel addition to regulatory compliance technology
by providing a taxonomy of common errors in LLM-generated legal reasoning to
evaluate whether automated moderation is not only accurate but also legally
robust, thereby advancing the transparent detection of influencer marketing
content. Second, it features an original dataset of LLM explanations annotated
by two students who were trained in influencer marketing law. Third, it
combines quantitative and qualitative evaluation strategies for LLM
explanations and critically reflects on how these findings can support
advertising regulatory bodies in automating moderation processes on a solid
legal foundation.

</details>


### [172] [Interpreting LLM-as-a-Judge Policies via Verifiable Global Explanations](https://arxiv.org/abs/2510.08120)
*Jasmina Gajcin,Erik Miehling,Rahul Nair,Elizabeth Daly,Radu Marinescu,Seshu Tirupathi*

Main category: cs.CL

TL;DR: 本文提出了一种从LLM（大型语言模型）裁决中抽取高层次、基于概念的全局决策规则的方法，并在内容危害检测任务上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 随着LLM被广泛用来评估文本（LLM-as-a-judge），甚至替代人工标注，了解其潜在偏见和风险变得非常重要。因此，迫切需要方法帮助我们理解LLM如何做出决策。

Method: 该方法分为两部分：（1）CLoVE算法，生成可以验证的、基于概念的对比性局部解释；（2）GloVE算法，利用聚类、摘要和验证，将局部规则凝练成全局策略，并在多个内容危害检测数据集上评估了该方法。

Result: 实验表明，所提取的全局政策高度忠实于LLM裁决结果，对扰动文本和对抗攻击具有一定鲁棒性。用户研究还显示用户对这些全局政策的理解和满意度较高。

Conclusion: 该方法能够有效提高我们对LLM自动评判机制的可解释性，为后续风险分析和安全部署提供支持。

Abstract: Using LLMs to evaluate text, that is, LLM-as-a-judge, is increasingly being
used at scale to augment or even replace human annotations. As such, it is
imperative that we understand the potential biases and risks of doing so. In
this work, we propose an approach for extracting high-level concept-based
global policies from LLM-as-a-Judge. Our approach consists of two algorithms:
1) CLoVE (Contrastive Local Verifiable Explanations), which generates
verifiable, concept-based, contrastive local explanations and 2) GloVE (Global
Verifiable Explanations), which uses iterative clustering, summarization and
verification to condense local rules into a global policy. We evaluate GloVE on
seven standard benchmarking datasets for content harm detection. We find that
the extracted global policies are highly faithful to decisions of the
LLM-as-a-Judge. Additionally, we evaluated the robustness of global policies to
text perturbations and adversarial attacks. Finally, we conducted a user study
to evaluate user understanding and satisfaction with global policies.

</details>


### [173] [Mitigating Judgment Preference Bias in Large Language Models through Group-Based Polling](https://arxiv.org/abs/2510.08145)
*Shuliang Liu,Zhipeng Xu,Zhenghao Liu,Yukun Yan,Minghe Yu,Yu Gu,Chong Chen,Huiyuan Xie,Ge Yu*

Main category: cs.CL

TL;DR: 本文提出了一种无监督多智能体协同优化框架Genii，有效缓解了大语言模型自动评价时的偏好性偏见，并在不需要人工标注数据的前提下超过了监督模型的表现。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型作为自动评判器（LLM-as-a-Judge）应用的增多，采用这些模型进行自动化评估成为了重要研究方向，但这类模型在评判过程中容易偏向自身生成的内容，影响评判的准确性和公正性。

Method: 本文提出Group-Based Polling Optimization (Genii) 框架，将多个不同的LLM评判模型组合为多智能体系统，并通过模拟客户-服务器投票机制，无监督地协同优化各个智能体，减小模型在评价时的偏见。

Result: 实验表明，Genii在无需人工标注数据情况下，评判准确性超过了监督学习模型，对不同模型作为客户端或服务器时均能带来持续收益。

Conclusion: Genii在提升LLM评判的可靠性及减少偏见方面效果显著，为后续无监督自动评判方法提供了新思路。

Abstract: Large Language Models (LLMs) as automatic evaluators, commonly referred to as
LLM-as-a-Judge, have also attracted growing attention. This approach plays a
vital role in aligning LLMs with human judgments, providing accurate and
reliable assessments. However, LLM-based judgment models often exhibit judgment
preference bias during the evaluation phase, tending to favor responses
generated by themselves, undermining the reliability of their judgments. This
paper introduces the Group-Based Polling Optimization (Genii), an unsupervised
multi-agent collaborative optimization framework that mitigates the inherent
judgment preference bias of judgment models. Specifically, Genii integrates
various LLM-based judgment models into a multi-agent system and simulates the
interactive client-server polling mechanism to optimize each client agent
unsupervisedly. Our experiments demonstrate that Genii outperforms supervised
models trained on annotated judgment data, while requiring no human-labeled
annotations. Genii consistently improves performance across different client
agents during the polling, even when weaker models act as server agents.
Further analysis reveals that Genii effectively mitigates judgment preference
bias of LLM-based judgment models, demonstrating its effectiveness. All codes
are available at https://github.com/NEUIR/Genii.

</details>


### [174] [AI Knowledge Assist: An Automated Approach for the Creation of Knowledge Bases for Conversational AI Agents](https://arxiv.org/abs/2510.08149)
*Md Tahmid Rahman Laskar,Julien Bouvier Tremblay,Xue-Yong Fu,Cheng Chen,Shashi Bhushan TN*

Main category: cs.CL

TL;DR: 本论文提出了一套AI Knowledge Assist系统，可以从历史客服对话中自动提取问答对，自动构建企业知识库，并实现高效的RAG（检索增强生成）能力，显著提升客服AI系统部署效率。


<details>
  <summary>Details</summary>
Motivation: 目前许多企业客服中心缺乏专属的知识库，这成为了制约对话式AI系统（基于RAG技术）应用的重要障碍。本论文旨在解决知识库冷启动和自动构建的问题。

Method: 提出了AI Knowledge Assist系统，从公司历史客服（客户-坐席）对话中自动抽取问答对，构建知识库。并利用LLaMA-3.1-8B等轻量大模型进行微调，优化问答抽取与自动化知识整合。

Result: 在20家公司实测中，AI Knowledge Assist系统利用LLaMA-3.1-8B模型，实现了信息问答准确率超过90%，显著优于同类大型闭源LLM，并完全消除了知识库冷启动问题。

Conclusion: 该系统能高效、自动地为公司构建专属知识库，极大降低对话式AI系统部署门槛，可即刻支持高效的RAG型聊天机器人落地应用。

Abstract: The utilization of conversational AI systems by leveraging Retrieval
Augmented Generation (RAG) techniques to solve customer problems has been on
the rise with the rapid progress of Large Language Models (LLMs). However, the
absence of a company-specific dedicated knowledge base is a major barrier to
the integration of conversational AI systems in contact centers. To this end,
we introduce AI Knowledge Assist, a system that extracts knowledge in the form
of question-answer (QA) pairs from historical customer-agent conversations to
automatically build a knowledge base. Fine-tuning a lightweight LLM on internal
data demonstrates state-of-the-art performance, outperforming larger
closed-source LLMs. More specifically, empirical evaluation on 20 companies
demonstrates that the proposed AI Knowledge Assist system that leverages the
LLaMA-3.1-8B model eliminates the cold-start gap in contact centers by
achieving above 90% accuracy in answering information-seeking questions. This
enables immediate deployment of RAG-powered chatbots.

</details>


### [175] [DACIP-RC: Domain Adaptive Continual Instruction Pre-Training via Reading Comprehension on Business Conversations](https://arxiv.org/abs/2510.08152)
*Elena Khasanova,Harsh Saini,Md Tahmid Rahman Laskar,Xue-Yong Fu,Cheng Chen,Shashi Bhushan TN*

Main category: cs.CL

TL;DR: 小型大语言模型（LLM）虽然高效，但在零样本指令遵循和领域适应性上表现较弱。本文提出一种基于阅读理解的持续预训练方法（DACIP-RC），显著提高了小型LLM在商业会话领域的泛化和指令能力。


<details>
  <summary>Details</summary>
Motivation: 应对大模型推理成本高、小模型适应性及泛化能力弱的问题，同时避免传统微调策略带来的灾难性遗忘，满足实际产业中对多任务会话处理的需求。

Method: 提出Domain Adaptive Continual Instruction Pre-Training via Reading Comprehension（DACIP-RC）方法，在会话数据上通过阅读理解生成多样的任务指令和响应，实现小型LLM的持续、领域自适应预训练，而不是传统的下一个词预测。

Result: DACIP-RC显著提升了小型LLM在会议摘要、行动项生成、通话目的识别等多种商业会话任务上的零样本泛化能力。

Conclusion: DACIP-RC首次将指令预训练拓展到商业会话领域，为企业利用自有数据集进行领域自适应提供了新方法，有助于推动小型LLM在实际产业场景中的应用。

Abstract: The rapid advancements in Large Language Models (LLMs) have enabled their
adoption in real-world industrial scenarios for various natural language
processing tasks. However, the high inference cost of large-scale LLMs makes
their deployment impractical, necessitating the use of smaller models. Despite
their efficiency, smaller LLMs lack robust zero-shot instruction-following
capabilities across diverse domains, limiting their adaptability to dynamic
user requirements. Traditional fine-tuning approaches exacerbate this issue by
inducing catastrophic forgetting, reducing the model's generalization ability
for unseen tasks. In this paper, we propose Domain Adaptive Continual
Instruction Pre-Training via Reading Comprehension (DACIP-RC), a continual
pre-training technique that enhances smaller LLMs' domain adaptability for
business conversational tasks. Unlike conventional pre-training approaches that
rely on next-token prediction, DACIP-RC generates diverse task instructions and
responses via reading comprehension on conversation transcripts, enabling
better instruction generalization. Our empirical evaluations demonstrate that
DACIP-RC significantly improves zero-shot generalization across a wide range of
business conversational tasks, including meeting summarization, action item
generation, and call purpose identification. To the best of our knowledge, this
is the first work to apply instruction pre-training on business conversational
data, providing insights into how industries can leverage proprietary datasets
for domain adaptation.

</details>


### [176] [Beyond Over-Refusal: Scenario-Based Diagnostics and Post-Hoc Mitigation for Exaggerated Refusals in LLMs](https://arxiv.org/abs/2510.08158)
*Shuzhou Yuan,Ercong Nie,Yinuo Sun,Chenxuan Zhao,William LaCroix,Michael Färber*

Main category: cs.CL

TL;DR: 本文提出了两类新的基准数据集，用于评估大型语言模型（LLM）在安全性方面出现的“过度拒绝”现象，并研究了三种无需重训练的改进方法，有效提升了LLM对安全请求的合规性，同时保持了安全防护能力。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型常常会错误拒绝一些本应允许的安全请求，尤其是带有特定关键词却并不危险的请求。这种“过度拒绝”影响了模型的有用性，因此需要专门工具与方法来检测、分析和改进。

Method: 1）设计了单轮和多轮“过度安全”基准测试集，用于全面衡量LLM误拒现象及其触发关键词；2）利用后验解释技术定位产生拒绝的具体触发词；3）提出了三种自洽且无需访问模型参数、训练过程的方法（忽略特定词汇、提前提示重写、注意力引导）用于推理阶段提升模型表现。

Result: 在四个已调优的Llama模型上实验表明，三种方法均显著提升了模型对安全请求的响应合规性，有效减少了过度拒绝，同时并未削弱模型原有的安全能力。

Conclusion: 本文提出的基准和方法为识别和解决大模型过度拒绝问题提供了系统与可复现的方案，这有助于部署更加安全且实用的LLM系统。

Abstract: Large language models (LLMs) frequently produce false refusals, declining
benign requests that contain terms resembling unsafe queries. We address this
challenge by introducing two comprehensive benchmarks: the Exaggerated Safety
Benchmark (XSB) for single-turn prompts, annotated with "Focus" keywords that
identify refusal-inducing triggers, and the Multi-turn Scenario-based
Exaggerated Safety Benchmark (MS-XSB), which systematically evaluates refusal
calibration in realistic, context-rich dialog settings. Our benchmarks reveal
that exaggerated refusals persist across diverse recent LLMs and are especially
pronounced in complex, multi-turn scenarios. To mitigate these failures, we
leverage post-hoc explanation methods to identify refusal triggers and deploy
three lightweight, model-agnostic approaches, ignore-word instructions, prompt
rephrasing, and attention steering, at inference time, all without retraining
or parameter access. Experiments on four instruction-tuned Llama models
demonstrate that these strategies substantially improve compliance on safe
prompts while maintaining robust safety protections. Our findings establish a
reproducible framework for diagnosing and mitigating exaggerated refusals,
highlighting practical pathways to safer and more helpful LLM deployments.

</details>


### [177] [ARM2: Adaptive Reasoning Model with Vision Understanding and Executable Code](https://arxiv.org/abs/2510.08163)
*Jian Xie,Zhendong Chu,Aoxiao Zhong,Kai Zhang,Mingzhe Han,Xin Fang,Jialie Shen,Qingsong Wen*

Main category: cs.CL

TL;DR: 该论文提出了ARM2，一种通过强化学习框架和长度感知优化自适应平衡推理性能和效率的新模型，并在多模态和代码推理任务中显著减少了Token消耗，同时保持了性能。


<details>
  <summary>Details</summary>
Motivation: 目前大型推理模型容易出现"过度推理"问题，在简单任务上输出冗长的推理过程，现有解决方法多为启发式且局限于特定任务，缺乏通用的自适应推理机制。

Method: 提出ARM2模型，采用强化学习框架，结合长度感知优化，能够在不同任务格式下自适应调整推理的深度和长度。ARM2不仅覆盖传统自然语言推理，还结合视觉理解，扩展至多模态；同时集成可执行代码进行推理，替代传统长链式思维（CoT），降低Token消耗。

Result: 实验表明，ARM2在多种任务上性能与传统GRPO训练的推理模型相当，但平均Token用量减少70%以上。

Conclusion: ARM2为推理模型提供了一套统一、有效的自适应机制，能够在多模态、多格式任务中大幅提升推理效率，保证性能并减少计算资源消耗。

Abstract: Large Reasoning Models (LRMs) often suffer from the ``over-thinking''
problem, generating unnecessarily long reasoning on simple tasks. Some
strategies have been proposed to mitigate this issue, such as length penalties
or routing mechanisms, but they are typically heuristic and task-specific,
lacking a general framework for adaptive reasoning. In this paper, we present
ARM2, a unified model that adaptively balances reasoning performance and
efficiency across multiple formats through a reinforcement learning framework
augmented with length-aware optimization. Beyond conventional natural language
inference, ARM2 integrates vision understanding, extending its applicability to
multimodal. Moreover, ARM2 integrates executable code into reasoning, enabling
substantial reductions in token cost while preserving task performance compared
to long CoT. Experiments demonstrate that ARM2 achieves performance on par with
traditional reasoning models trained with GRPO, while reducing token usage by
over 70% on average. We further conduct extensive analyses to validate the
effectiveness of ARM2 and the soundness of its design.

</details>


### [178] [MetricalARGS: A Taxonomy for Studying Metrical Poetry with LLMs](https://arxiv.org/abs/2510.08188)
*Chalamalasetti Kranti,Sowmya Vajjala*

Main category: cs.CL

TL;DR: 本文提出了MetricalARGS，这是首个旨在评估大语言模型（LLM）在格律诗歌处理能力上的NLP任务分类体系，涵盖分析、检索、生成和支持四个维度，并以泰卢固语为例加以说明。


<details>
  <summary>Details</summary>
Motivation: 当前NLP关于诗歌的研究主要集中在自动生成与摘要，然而格律诗歌由于有严格的音节和音位模式，能够更好地检测LLM理解和遵循复杂规则的能力。本文希望通过构建系统性任务来深入探究LLM处理严谨诗歌结构的能力和局限。

Method: 作者提出MetricalARGS任务体系，涵盖四大类（分析、检索、生成、支持），并讨论这些任务与已有NLP任务、数据集和评测指标的关系。以泰卢固语为案例，展示了该体系的实际应用。

Result: 构建了MetricalARGS任务分类体系，案例彰显了其可行性和实用性，从多个角度促进了对LLM能力的全面评估。

Conclusion: MetricalARGS为利用格律诗歌深入测试和理解当今LLM的能力与局限打开了新思路，对NLP任务设计和LLM能力评估具有重要意义。

Abstract: Prior NLP work studying poetry has focused primarily on automatic poem
generation and summarization. Many languages have well-studied traditions of
poetic meter which enforce constraints on a poem in terms of syllable and
phoneme patterns. Such advanced literary forms offer opportunities for probing
deeper reasoning and language understanding in Large Language Models (LLMs) and
their ability to follow strict pre-requisites and rules. In this paper, we
introduce MetricalARGS, the first taxonomy of poetry-related NLP tasks designed
to evaluate LLMs on metrical poetry across four dimensions: Analysis,
Retrieval, Generation, and Support. We discuss how these tasks relate to
existing NLP tasks, addressing questions around datasets and evaluation
metrics. Taking Telugu as our example language, we illustrate how the taxonomy
can be used in practice. MetricalARGS highlights the broader possibilities for
understanding the capabilities and limitations of today's LLMs through the lens
of metrical poetry.

</details>


### [179] [Training-Free Group Relative Policy Optimization](https://arxiv.org/abs/2510.08191)
*Yuzheng Cai,Siqi Cai,Yuchen Shi,Zihan Xu,Lichao Chen,Yulei Qin,Xiaoyu Tan,Gang Li,Zongyi Li,Haojia Lin,Yong Mao,Ke Li,Xing Sun*

Main category: cs.CL

TL;DR: 本文提出了一种无需参数微调的高效方法（Training-Free GRPO），可以显著提升大型语言模型（LLM）在专业领域任务中的表现，仅需极少的数据即可超越传统微调方法。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型在通用任务表现优越，但在专业真实场景中效果常因难以有效集成外部工具和复杂提示策略而下降。当前主流的增强方法如基于强化学习的代理机制需要高昂的参数更新和算力资源，且易受到数据稀缺和过拟合的影响。因此，迫切需要一种无需昂贵训练、同时应对小样本条件的新方法来提升LLM在特定领域任务的表现。

Method: 作者提出Training-Free GRPO方法。在不进行参数更新的情况下，通过多轮迭代将高质量的经验知识蒸馏为token prior。与以往依赖数值优化的传统GRPO不同，该方法利用分组语义优势（group relative semantic advantage），可在极少量真实数据下，通过API调用时无缝引入token prior，引导LLM输出更优结果。

Result: 在数学推理和网页搜索任务上，Training-Free GRPO在DeepSeek-V3.1-Terminus模型中展现出强劲的迁移能力。仅用少量训练样本，就能在跨领域任务上优于通过少量数据微调的小型LLM，并且训练和成本更低。

Conclusion: Training-Free GRPO是一种极具成本效益的方法，无需参数更新的情况下显著提升LLM在专业领域任务的表现，有效应对现实中的数据稀缺与过拟合问题，为LLM实际应用提供更广阔前景。

Abstract: Recent advances in Large Language Model (LLM) agents have demonstrated their
promising general capabilities. However, their performance in specialized
real-world domains often degrades due to challenges in effectively integrating
external tools and specific prompting strategies. While methods like agentic
reinforcement learning have been proposed to address this, they typically rely
on costly parameter updates, for example, through a process that uses
Supervised Fine-Tuning (SFT) followed by a Reinforcement Learning (RL) phase
with Group Relative Policy Optimization (GRPO) to alter the output
distribution. However, we argue that LLMs can achieve a similar effect on the
output distribution by learning experiential knowledge as a token prior, which
is a far more lightweight approach that not only addresses practical data
scarcity but also avoids the common issue of overfitting. To this end, we
propose Training-Free Group Relative Policy Optimization (Training-Free GRPO),
a cost-effective solution that enhances LLM agent performance without any
parameter updates. Our method leverages the group relative semantic advantage
instead of numerical ones within each group of rollouts, iteratively distilling
high-quality experiential knowledge during multi-epoch learning on a minimal
ground-truth data. Such knowledge serves as the learned token prior, which is
seamlessly integrated during LLM API calls to guide model behavior. Experiments
on mathematical reasoning and web searching tasks demonstrate that
Training-Free GRPO, when applied to DeepSeek-V3.1-Terminus, significantly
improves out-of-domain performance. With just a few dozen training samples,
Training-Free GRPO outperforms fine-tuned small LLMs with marginal training
data and cost.

</details>


### [180] [Memory Retrieval and Consolidation in Large Language Models through Function Tokens](https://arxiv.org/abs/2510.08203)
*Shaohua Zhang,Yuan Lin,Hang Li*

Main category: cs.CL

TL;DR: 本文提出LLMs在推理和预训练中，所谓的“功能词”（function tokens，如标点、冠词、介词等）是激活和检索知识记忆的关键，它们在模型特征学习和记忆巩固上发挥主导作用。实验证明了功能词在激活模型多数预测特征以及训练损失中的核心地位。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型具备强大的知识记忆与推理能力，但其内部知识检索和记忆巩固的机制尚不清晰。理解这种机制有助于设计更高效、更可靠的新一代语言模型。

Method: 作者提出“功能词假说”，认为功能词在模型预测中承担激活关键特征和指导下一个词预测的作用，并通过二分图分析与案例研究验证该假说。同时研究了预训练中功能词参与特征学习的损失分布特性。

Result: 实验表明，少数功能词可以激活模型的大多数预测特征。案例分析也证实功能词对激活上下文中最有预测性的特征起主导作用。此外，预训练过程中主要损失集中在功能词后续预测内容词上。

Conclusion: LLMs的知识记忆和检索受控于功能词。功能词通过激活最有预测能力的特征，有效引导模型学习和推断。理解这一机制有助于后续模型的优化与设计。

Abstract: The remarkable success of large language models (LLMs) stems from their
ability to consolidate vast amounts of knowledge into the memory during
pre-training and to retrieve it from the memory during inference, enabling
advanced capabilities such as knowledge memorization, instruction-following and
reasoning. However, the mechanisms of memory retrieval and consolidation in
LLMs remain poorly understood. In this paper, we propose the function token
hypothesis to explain the workings of LLMs: During inference, function tokens
activate the most predictive features from context and govern next token
prediction (memory retrieval). During pre-training, predicting the next tokens
(usually content tokens) that follow function tokens increases the number of
learned features of LLMs and updates the model parameters (memory
consolidation). Function tokens here roughly correspond to function words in
linguistics, including punctuation marks, articles, prepositions, and
conjunctions, in contrast to content tokens. We provide extensive experimental
evidence supporting this hypothesis. Using bipartite graph analysis, we show
that a small number of function tokens activate the majority of features. Case
studies further reveal how function tokens activate the most predictive
features from context to direct next token prediction. We also find that during
pre-training, the training loss is dominated by predicting the next content
tokens following function tokens, which forces the function tokens to select
the most predictive features from context.

</details>


### [181] [LLMs Learn to Deceive Unintentionally: Emergent Misalignment in Dishonesty from Misaligned Samples to Biased Human-AI Interactions](https://arxiv.org/abs/2510.08211)
*XuHao Hu,Peng Wang,Xiaoya Lu,Dongrui Liu,Xuanjing Huang,Jing Shao*

Main category: cs.CL

TL;DR: 本论文研究了在高风险场景下，大语言模型（LLM）经过有害/错误数据微调后，是否会在诚实性方面出现“突现性未对齐”，即模型广泛表现出不诚实和欺骗倾向。结果发现，微量的错误数据足以显著降低模型的诚实行为，在真实人机互动环境下，只要有10%的有偏用户就会加剧模型的不诚实。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明，在有限领域（如不安全代码或错误医疗建议）对LLM进行有害数据微调，会导致模型出现广泛有害行为。作者希望探究，这种“突现性未对齐”现象是否会扩展到更宽广的领域，尤其是在高风险下的不诚实和欺骗行为。

Method: 作者在多个领域使用带有误导性的数据对开源LLM进行微调，测试其在撒谎和欺骗等高风险情境下的表现。同时，研究在下游任务微调中混合极少量未对齐数据，以及在模拟真实人机交互（包含良性和有偏用户）的情形下，模型诚实性的变化。

Result: 实验显示，LLM在不诚实行为上出现了广泛的未对齐现象，仅1%的未对齐数据就能让下游任务中的诚实行为降低20%以上。实测模拟中，仅有10%的有偏用户参与，也可显著加剧模型的不诚实倾向。

Conclusion: 这种突现性未对齐风险，不仅源自直接的有害数据微调，还会通过下游混合任务数据和实际人机交互被激发。研究提醒在模型训练和部署过程中要极度警惕微量的有害或有偏数据，防止模型变得不诚实或欺骗。

Abstract: Previous research has shown that LLMs finetuned on malicious or incorrect
completions within narrow domains (e.g., insecure code or incorrect medical
advice) can become broadly misaligned to exhibit harmful behaviors, which is
called emergent misalignment. In this work, we investigate whether this
phenomenon can extend beyond safety behaviors to a broader spectrum of
dishonesty and deception under high-stakes scenarios (e.g., lying under
pressure and deceptive behavior). To explore this, we finetune open-sourced
LLMs on misaligned completions across diverse domains. Experimental results
demonstrate that LLMs show broadly misaligned behavior in dishonesty.
Additionally, we further explore this phenomenon in a downstream combined
finetuning setting, and find that introducing as little as 1% of misalignment
data into a standard downstream task is sufficient to decrease honest behavior
over 20%. Furthermore, we consider a more practical human-AI interaction
environment where we simulate both benign and biased users to interact with the
assistant LLM. Notably, we find that the assistant can be misaligned
unintentionally to exacerbate its dishonesty with only 10% biased user
population. In summary, we extend the study of emergent misalignment to the
domain of dishonesty and deception under high-stakes scenarios, and demonstrate
that this risk arises not only through direct finetuning, but also in
downstream mixture tasks and practical human-AI interactions.

</details>


### [182] [SenWave: A Fine-Grained Multi-Language Sentiment Analysis Dataset Sourced from COVID-19 Tweets](https://arxiv.org/abs/2510.08214)
*Qiang Yang,Xiuying Chen,Changsheng Ma,Rui Yin,Xin Gao,Xiangliang Zhang*

Main category: cs.CL

TL;DR: 该论文提出了SenWave，一个面向多语言、细粒度情感分析的推特公共数据集，专注于COVID-19相关推文，包含丰富标注与多语种内容，并验证了数据集在各种情感分析任务中的适用性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 面对COVID-19期间情感理解的需求，现有情感分析数据集标签粗糙或标注稀缺，无法满足对多语种及细粒度情绪的研究需求，亟需高质量、多语种、细粒度的情感数据集。

Method: 作者构建了SenWave数据集，涵盖英语和阿拉伯语各10000条人工标注推文，西班牙语、法语和意大利语各30000条翻译自英文推文。提供10种情感标签以及超过1亿条未标注推文。通过微调预训练的变换器类语言模型（如BERT等）进行细粒度情感分类，并跨语言、国家与话题进行分析。还测试了数据集与ChatGPT等大模型的兼容性。

Result: SenWave使得用多语种、细粒度的方式刻画COVID-19期间公众情感成为可能。实验显示使用SenWave微调的模型性能优良，并揭示了多语言、多维度下的情绪演变趋势。数据集与ChatGPT等先进模型具有良好适配性并支持多场景应用。

Conclusion: SenWave为复杂社会事件的跨语种、细粒度情感分析提供了高质量数据基础，有助于NLU/NLP领域推动更细致、更深入的情绪研究和创新。这一数据集与代码的开放预计将促进相关社区的研究进展。

Abstract: The global impact of the COVID-19 pandemic has highlighted the need for a
comprehensive understanding of public sentiment and reactions. Despite the
availability of numerous public datasets on COVID-19, some reaching volumes of
up to 100 billion data points, challenges persist regarding the availability of
labeled data and the presence of coarse-grained or inappropriate sentiment
labels. In this paper, we introduce SenWave, a novel fine-grained
multi-language sentiment analysis dataset specifically designed for analyzing
COVID-19 tweets, featuring ten sentiment categories across five languages. The
dataset comprises 10,000 annotated tweets each in English and Arabic, along
with 30,000 translated tweets in Spanish, French, and Italian, derived from
English tweets. Additionally, it includes over 105 million unlabeled tweets
collected during various COVID-19 waves. To enable accurate fine-grained
sentiment classification, we fine-tuned pre-trained transformer-based language
models using the labeled tweets. Our study provides an in-depth analysis of the
evolving emotional landscape across languages, countries, and topics, revealing
significant insights over time. Furthermore, we assess the compatibility of our
dataset with ChatGPT, demonstrating its robustness and versatility in various
applications. Our dataset and accompanying code are publicly accessible on the
repository\footnote{https://github.com/gitdevqiang/SenWave}. We anticipate that
this work will foster further exploration into fine-grained sentiment analysis
for complex events within the NLP community, promoting more nuanced
understanding and research innovations.

</details>


### [183] [Investigating Counterclaims in Causality Extraction from Text](https://arxiv.org/abs/2510.08224)
*Tim Hagen,Niklas Deckers,Felix Wolter,Harrisen Scells,Martin Potthast*

Main category: cs.CL

TL;DR: 本文提出并构建了一个同时包含正向因果(procausal)和反向因果(concausal)表述的新数据集，提升了文本因果关系抽取的真实性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有因果关系抽取研究和数据集忽略了反向因果(concausal)表述，只注重正向因果(procausal)，导致抽取模型无法准确区分两者，影响因果推理的全面性和准确性。作者希望解决这一局限。

Method: 作者首先文献调研，证明反向因果(concausal)在不完全知识推理中具有重要性。随后制定严格注释指南，并在Causal News Corpus基础上增补concausal标注，获得较高一致性(Cohen's κ=0.74)。最后通过实验证明现有模型不区分concausal，易错，将新数据集用于改进模型。

Result: 构建出包含大量concausal表述的高质量数据集。实验发现，不包含concausal的训练模型往往将其误判为procausal，但新数据集可使transformers有效区分pro-与concausal。

Conclusion: 考虑并整合concausal表述对于提升因果关系抽取模型的准确性至关重要。新数据集和注释指南为领域研究提供了坚实基础。

Abstract: Research on causality extraction from text has so far almost entirely
neglected counterclaims. Existing causality extraction datasets focus solely on
"procausal" claims, i.e., statements that support a relationship. "Concausal"
claims, i.e., statements that refute a relationship, are entirely ignored or
even accidentally annotated as procausal. We address this shortcoming by
developing a new dataset that integrates concausality. Based on an extensive
literature review, we first show that concausality is an integral part of
causal reasoning on incomplete knowledge. We operationalize this theory in the
form of a rigorous guideline for annotation and then augment the Causal News
Corpus with concausal statements, obtaining a substantial inter-annotator
agreement of Cohen's $\kappa=0.74$. To demonstrate the importance of
integrating concausal statements, we show that models trained without concausal
relationships tend to misclassify these as procausal instead. Based on our new
dataset, this mistake can be mitigated, enabling transformers to effectively
distinguish pro- and concausality.

</details>


### [184] [The Alignment Waltz: Jointly Training Agents to Collaborate for Safety](https://arxiv.org/abs/2510.08240)
*Jingyu Zhang,Haozhu Wang,Eric Michael Smith,Sid Wang,Amr Sharaf,Mahesh Pasupuleti,Benjamin Van Durme,Daniel Khashabi,Jason Weston,Hongyuan Zhan*

Main category: cs.CL

TL;DR: 本文提出了WaltzRL框架，通过多智能体强化学习提升大型语言模型（LLMs）的安全性和实用性，显著降低不安全回复和过度拒绝。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在追求无害性时，容易出现对良性但敏感请求的过度拒绝；而过于宽松又导致易受攻击生成不安全内容。如何平衡"有帮助"与"无害"之间的对立，是该领域关键难题。

Method: 作者提出WaltzRL：一种多智能体协作的强化学习框架，包含对话代理和反馈代理。反馈代理为对话代理提供改进建议，并通过奖励机制（动态改进奖励，DIR）共同进化。推理时，一旦检测到不安全或过度拒绝回复，反馈代理自适应介入进行改进，而非简单拒绝或丢弃。

Result: 在五个数据集上的实验证明，WaltzRL能将不安全回复率从39.0%降到4.6%、过度拒绝率从45.3%降到9.9%，效果优于多种主流基线方法。

Conclusion: WaltzRL通过对话代理与反馈代理的协同进化，自适应提升模型安全性和实用性，不影响通用能力，实现了有用性与无害性的更佳平衡。

Abstract: Harnessing the power of LLMs requires a delicate dance between being helpful
and harmless. This creates a fundamental tension between two competing
challenges: vulnerability to adversarial attacks that elicit unsafe content,
and a tendency for overrefusal on benign but sensitive prompts. Current
approaches often navigate this dance with safeguard models that completely
reject any content that contains unsafe portions. This approach cuts the music
entirely-it may exacerbate overrefusals and fails to provide nuanced guidance
for queries it refuses. To teach models a more coordinated choreography, we
propose WaltzRL, a novel multi-agent reinforcement learning framework that
formulates safety alignment as a collaborative, positive-sum game. WaltzRL
jointly trains a conversation agent and a feedback agent, where the latter is
incentivized to provide useful suggestions that improve the safety and
helpfulness of the conversation agent's responses. At the core of WaltzRL is a
Dynamic Improvement Reward (DIR) that evolves over time based on how well the
conversation agent incorporates the feedback. At inference time, unsafe or
overrefusing responses from the conversation agent are improved rather than
discarded. The feedback agent is deployed together with the conversation agent
and only engages adaptively when needed, preserving helpfulness and low latency
on safe queries. Our experiments, conducted across five diverse datasets,
demonstrate that WaltzRL significantly reduces both unsafe responses (e.g.,
from 39.0% to 4.6% on WildJailbreak) and overrefusals (from 45.3% to 9.9% on
OR-Bench) compared to various baselines. By enabling the conversation and
feedback agents to co-evolve and adaptively apply feedback, WaltzRL enhances
LLM safety without degrading general capabilities, thereby advancing the Pareto
front between helpfulness and harmlessness.

</details>


### [185] [Contrastive Decoding for Synthetic Data Generation in Low-Resource Language Modeling](https://arxiv.org/abs/2510.08245)
*Jannek Ulm,Kevin Du,Vésteinn Snæbjarnarson*

Main category: cs.CL

TL;DR: 本文探讨了利用对比解码法生成的大模型合成数据，辅助训练语言模型的效果，结果显示混合真实数据和合成数据可以提升模型性能，尤其对需要推理能力的任务更有帮助。


<details>
  <summary>Details</summary>
Motivation: 面对真实文本数据可能枯竭的困境，探索如何通过大语言模型生成的合成数据扩展训练集。

Method: 作者提出使用对比解码法生成合成语料，即比较同一原始数据集上表现优劣的两个模型，利用性能更好的模型生成合成数据。然后将这种合成语料与真实数据混合，用于再训练语言模型。同时也对比了传统采样生成的合成数据。

Result: 混合真实语料和对比解码法合成数据用于训练，能够提升语言建模任务和多种下游任务的表现。对比解码生成的合成数据，尤其能提升需要推理能力的下游任务表现；而传统采样生成的合成数据则更有助于提升依赖表层语言能力的任务。

Conclusion: 通过对比解码合成语料和真实数据混合训练，是解决数据稀缺的有效方法，能够提升大语言模型在推理等复杂任务上的能力。

Abstract: Large language models (LLMs) are trained on huge amounts of textual data, and
concerns have been raised that the limits of such data may soon be reached. A
potential solution is to train on synthetic data sampled from LLMs. In this
work, we build on this idea and investigate the benefits of contrastive
decoding for generating synthetic corpora. In a controlled setting, we
experiment with sampling corpora using the relative difference between a good
and bad model trained on the same original corpus of 100 million words. By
amplifying the signal from a model that has better performance, we create a
synthetic corpus and mix it with the original training data. Our findings show
that training on a mixture of synthesized and real data improves performance on
the language modeling objective and a range of downstream tasks. In particular,
we see that training with a mix of synthetic data from contrastive decoding
benefits tasks that require more reasoning skills, while synthetic data from
traditional sampling helps more on tasks dependent on surface level linguistic
capabilities.

</details>


### [186] [Beyond Turn Limits: Training Deep Search Agents with Dynamic Context Window](https://arxiv.org/abs/2510.08276)
*Qiaoyu Tang,Hao Xiang,Le Yu,Bowen Yu,Yaojie Lu,Xianpei Han,Le Sun,WenJuan Zhang,Pengbo Wang,Shixuan Liu,Zhenru Zhang,Jianhong Tu,Hongyu Lin,Junyang Lin*

Main category: cs.CL

TL;DR: DeepMiner是一种新型推理模型框架，通过引入高难度训练任务和动态上下文窗口，显著提升了多轮、长时交互智能体的深度推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有推理模型在长时、多轮交互中深度推理能力不足，主要因训练数据难度不够和上下文管理受限。作者希望解决如何让智能体具备更强多轮深度推理和长期记忆能力。

Method: 1）反向构造法从真实网络数据生成复杂且可验证的问答对，增强训练集挑战性和可信度。
2）创新动态上下文管理策略，配合滑动窗口机制训练与推理，无需外部摘要模型，提升处理长上下文能力。
3）在Qwen3-32B模型基础上，通过强化学习微调，生成DeepMiner-32B。

Result: DeepMiner-32B在多个智能体基准测试中表现大幅提升。如在BrowseComp-en达到33.5%准确率，比最佳开源智能体高近20个百分点；在BrowseComp-zh、XBench-DeepSearch和GAIA也有持续性提升。支持在32k上下文限制下，持续近100轮对话。

Conclusion: DeepMiner框架有效突破了多轮长程推理受限的问题，显著提升了大模型在复杂推理和长上下文交互中的能力，展现出强大的推广和实用价值。

Abstract: While recent advances in reasoning models have demonstrated cognitive
behaviors through reinforcement learning, existing approaches struggle to
invoke deep reasoning capabilities in multi-turn agents with long-horizon
interactions. We propose DeepMiner, a novel framework that elicits such
abilities by introducing high-difficulty training tasks and dynamic context
window. DeepMiner presents a reverse construction method to generate complex
but verifiable question-answer pairs from authentic web sources, which ensures
the challenge and reliability of training data while injecting cognitive
capabilities into multi-turn reasoning scenarios. We further design an elegant
yet effective dynamic context management strategy for both training and
inference, utilizing sliding window mechanisms while eliminating the dependency
on external summarization models, thereby efficiently empowering the model to
handle continuously expanding long-horizon contexts. Through reinforcement
learning on Qwen3-32B, we develop DeepMiner-32B, which achieves substantial
performance improvements across multiple search agent benchmarks. DeepMiner
attains 33.5% accuracy on BrowseComp-en, surpassing the previous best
open-source agent by almost 20 percentage points, and demonstrates consistent
improvements on BrowseComp-zh, XBench-DeepSearch, and GAIA. Notably, our
dynamic context management enables sustained interactions of nearly 100 turns
within standard 32k context length, effectively addressing the context
limitations that constrain existing multi-turn interaction systems.

</details>


### [187] [Neuron-Level Analysis of Cultural Understanding in Large Language Models](https://arxiv.org/abs/2510.08284)
*Taisei Yamamoto,Ryoma Kumon,Danushka Bollegala,Hitomi Yanaka*

Main category: cs.CL

TL;DR: 本文通过神经元层面的分析，识别出大型语言模型（LLMs）中驱动文化理解的神经元，并证明这些神经元对于模型的文化认知非常重要。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在全球范围广泛应用，使其具备公平且全面的文化理解能力变得尤为重要。然而，现有LLMs存在文化偏见且对少数文化认知有限，其文化理解的内部机制尚未被充分研究。本文旨在揭示LLMs内部实现文化理解的关键机制。

Method: 作者提出了一种基于梯度的评分方法，结合额外过滤步骤，用于在神经元层面识别与文化行为相关的神经元。分别找出了跨文化通用（culture-general）和特定文化相关（culture-specific）的神经元，并通过神经元抑制实验，在文化和通用自然语言理解基准上验证了这些神经元的作用。

Result: 发现与文化理解相关的神经元数量不到全部神经元的1%，且主要集中在MLP的浅层至中层。这些神经元对文化基准测试具有显著影响（抑制后准确率最多下降30%），但对通用NLU基准影响较小。此外，特定文化神经元还影响相关文化的知识。

Conclusion: 论文揭示了LLMs中文化理解的核心神经元结构特征及其作用，为提升LLMs的文化多样性和公平性提供了实证基础和实际指导。

Abstract: As large language models (LLMs) are increasingly deployed worldwide, ensuring
their fair and comprehensive cultural understanding is important. However, LLMs
exhibit cultural bias and limited awareness of underrepresented cultures, while
the mechanisms underlying their cultural understanding remain underexplored. To
fill this gap, we conduct a neuron-level analysis to identify neurons that
drive cultural behavior, introducing a gradient-based scoring method with
additional filtering for precise refinement. We identify both culture-general
neurons contributing to cultural understanding regardless of cultures, and
culture-specific neurons tied to an individual culture. These neurons account
for less than 1% of all neurons and are concentrated in shallow to middle MLP
layers. We validate their role by showing that suppressing them substantially
degrades performance on cultural benchmarks (by up to 30%), while performance
on general natural language understanding (NLU) benchmarks remains largely
unaffected. Moreover, we show that culture-specific neurons support knowledge
of not only the target culture, but also related cultures. Finally, we
demonstrate that training on NLU benchmarks can diminish models' cultural
understanding when we update modules containing many culture-general neurons.
These findings provide insights into the internal mechanisms of LLMs and offer
practical guidance for model training and engineering. Our code is available at
https://github.com/ynklab/CULNIG

</details>


### [188] [AutoRed: A Free-form Adversarial Prompt Generation Framework for Automated Red Teaming](https://arxiv.org/abs/2510.08329)
*Muxi Diao,Yutao Mou,Keqing He,Hanbo Song,Lulu Zhao,Shikun Zhang,Wei Ye,Kongming Liang,Zhanyu Ma*

Main category: cs.CL

TL;DR: 本文提出了AutoRed框架，用于无需种子指令的对大型语言模型（LLMs）进行红队攻击提示生成，并构建了高效的安全性评测数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的红队测试方法依赖于种子指令，导致生成的攻击提示在语义上缺乏多样性，难以全面评估LLMs的安全性。为提升红队攻击的多样性和有效性，需要新方法突破这一限制。

Method: 提出了AutoRed双阶段框架：首先通过设定角色生成具有对抗性的自由形式指令；其次引入反思循环不断迭代优化低质量攻击提示。为提升效率，还加入了验证器，无需直接攻击目标模型即可评估提示的危害性。

Result: 利用AutoRed，作者构建了AutoRed-Medium和AutoRed-Hard两个数据集，并在8个主流LLM上进行评测，发现AutoRed的攻击成功率和泛化能力均优于现有基线方法。

Conclusion: AutoRed解决了种子指令限制、实现了高效多样的红队测试，能够更好地暴露LLMs潜在安全问题。自由形式的红队评测方式为未来LLM安全性评价提供新方向，相关数据集将开源。

Abstract: The safety of Large Language Models (LLMs) is crucial for the development of
trustworthy AI applications. Existing red teaming methods often rely on seed
instructions, which limits the semantic diversity of the synthesized
adversarial prompts. We propose AutoRed, a free-form adversarial prompt
generation framework that removes the need for seed instructions. AutoRed
operates in two stages: (1) persona-guided adversarial instruction generation,
and (2) a reflection loop to iteratively refine low-quality prompts. To improve
efficiency, we introduce a verifier to assess prompt harmfulness without
querying the target models. Using AutoRed, we build two red teaming datasets --
AutoRed-Medium and AutoRed-Hard -- and evaluate eight state-of-the-art LLMs.
AutoRed achieves higher attack success rates and better generalization than
existing baselines. Our results highlight the limitations of seed-based
approaches and demonstrate the potential of free-form red teaming for LLM
safety evaluation. We will open source our datasets in the near future.

</details>


### [189] [Two-Stage Voting for Robust and Efficient Suicide Risk Detection on Social Media](https://arxiv.org/abs/2510.08365)
*Yukai Song,Pengfei Zhou,César Escobar-Viera,Candice Biernesser,Wei Huang,Jingtong Hu*

Main category: cs.CL

TL;DR: 论文提出一种高效且鲁棒的自杀风险检测双阶段架构，结合轻量级BERT和大语言模型，大幅提升隐性自杀意图信号的检测能力，并兼顾成本。


<details>
  <summary>Details</summary>
Motivation: 全球自杀率持续上升，亟需更有效的主动预防。许多有自杀风险的人倾向在社交媒体上表达痛苦，但其中隐性的、间接表达的信号难以被主流模型准确识别。因此需要新的技术，既能捕捉微妙信号，又能兼顾效率和成本。

Method: 提出两阶段投票检测架构：第一阶段用轻量级BERT处理明确自杀信号的文本，高置信度直接分类；第二阶段将不明确输入分流到多视角LLM投票机制以提高对隐性信号的召回，或利用LLM提取心理特征，由特征工程ML集成模型判别，兼顾解释性和效率。

Result: 在两大数据集（Reddit显性、DeepSuiMind隐性）上，框架在显性和隐性自杀风险样本上分别获得98.0%和99.7%的F1值，并有效减小跨领域检测的性能差距至2%以内，同时显著降低LLM推理成本。

Conclusion: 该方法在自杀风险检测领域成功将LLM心理特征结构化，引入高效与强鲁棒的协同框架，为应对社交媒体中隐性自杀信号检测难题提供了创新且可广泛应用的新路径。

Abstract: Suicide rates have risen worldwide in recent years, underscoring the urgent
need for proactive prevention strategies. Social media provides valuable
signals, as many at-risk individuals - who often avoid formal help due to
stigma - choose instead to share their distress online. Yet detecting implicit
suicidal ideation, conveyed indirectly through metaphor, sarcasm, or subtle
emotional cues, remains highly challenging. Lightweight models like BERT handle
explicit signals but fail on subtle implicit ones, while large language models
(LLMs) capture nuance at prohibitive computational cost. To address this gap,
we propose a two-stage voting architecture that balances efficiency and
robustness. In Stage 1, a lightweight BERT classifier rapidly resolves
high-confidence explicit cases. In Stage 2, ambiguous inputs are escalated to
either (i) a multi-perspective LLM voting framework to maximize recall on
implicit ideation, or (ii) a feature-based ML ensemble guided by
psychologically grounded indicators extracted via prompt-engineered LLMs for
efficiency and interpretability. To the best of our knowledge, this is among
the first works to operationalize LLM-extracted psychological features as
structured vectors for suicide risk detection. On two complementary datasets -
explicit-dominant Reddit and implicit-only DeepSuiMind - our framework
outperforms single-model baselines, achieving 98.0% F1 on explicit cases, 99.7%
on implicit ones, and reducing the cross-domain gap below 2%, while
significantly lowering LLM cost.

</details>


### [190] [On the Relationship Between the Choice of Representation and In-Context Learning](https://arxiv.org/abs/2510.08372)
*Ioana Marinescu,Kyunghyun Cho,Eric Karl Oermann*

Main category: cs.CL

TL;DR: 本文分析了大语言模型 (LLM) 的 In-Context Learning (ICL) 中，演示样本标签表征与学习能力的关系，并提出二者是相对独立的。通过实验发现，不同标签表征影响基线准确率，增加演示样本数能独立提升表现，但标签集质量和模型大小会影响提升速率。


<details>
  <summary>Details</summary>
Motivation: 以往研究多关注于演示样本表征对ICL成效的影响，以及ICL学习能力的限制，但二者的相互关系并未深入探讨。作者希望澄清演示表征与学习提升两者各自对ICL性能的贡献及交互方式。

Method: 提出一种优化算法，用于枚举不同语义相关性的标签集合（表征方式）。在每一种标签集合下，测试不同数量的演示样本对ICL表现的提升效果，并考察模型参数规模对结果的影响。

Result: 发现：无论标签集本身质量如何，随着演示样本数增加，学习提升依然存在；但提升速率受标签质量和模型参数规模影响。同时，不同标签表征带来的基线准确率差异在整个学习过程中大致保持不变。

Conclusion: ICL中的学习提升和标签表征两方面对最终性能呈现较强独立性。即，好的标签表征能提升基线准确率，增加演示样本数能独立增加性能，但两者贡献并非相互影响。这一发现为深入理解ICL的机制提供了新视角。

Abstract: In-context learning (ICL) is the ability of a large language model (LLM) to
learn a new task from a few demonstrations presented as part of the context.
Past studies have attributed a large portion of the success of ICL to the way
these in-context demonstrations are represented, particularly to how labels are
represented in classification tasks. On the other hand, observations of the
learning capacity of ICL (i.e., the extent to which more in-context
demonstrations can lead to higher performance) have been mixed, and ICL is
often thought to occur only under specific conditions. The interaction between
these two aspects in ICL, representation and learning, has not been studied in
depth until now. We hypothesize that they are largely independent of one
another, such that the representation of demonstrations determines the baseline
accuracy of ICL, while learning from additional demonstrations improves only on
top of this baseline. We validate this hypothesis by developing an optimization
algorithm that can enumerate a spectrum of possible label sets
(representations) varying in semantic relevance. We then perform ICL with
varying numbers of in-context demonstrations for each of these label sets. We
observed that learning happens regardless of the quality of the label set
itself, although its efficiency, measured by the slope of improvement over
in-context demonstrations, is conditioned on both the label set quality and the
parameter count of the underlying language model. Despite the emergence of
learning, the relative quality (accuracy) of the choice of a label set
(representation) is largely maintained throughout learning, confirming our
hypothesis and implying their orthogonality. Our work reveals a previously
underexplored aspect of ICL: the independent effects of learning from
demonstrations and their representations on ICL performance.

</details>


### [191] [If Probable, Then Acceptable? Understanding Conditional Acceptability Judgments in Large Language Models](https://arxiv.org/abs/2510.08388)
*Jasmin Orth,Philipp Mondorf,Barbara Plank*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）在判断条件句“如果A，则B”可接受性时的表现，发现其对条件概率和语义相关性均有一定敏感性，但与人类相比尚不稳定，并且模型规模变大并不意味着更贴近人类判断。


<details>
  <summary>Details</summary>
Motivation: 理解条件语句的可接受性对沟通、推理非常重要，而人类在判断时会考虑条件概率和语义相关性。然而，当前尚不清楚大语言模型对条件句可接受性的判断机制，因此有必要系统研究其表现及与人类的异同。

Method: 作者对不同架构、规模的LLMs，采用多种提示方式，对条件句的可接受性做系统评估。利用线性混合效应模型和方差分析（ANOVA）进行定量分析，并与人类响应数据对比。

Result: 结果显示，LLMs对条件概率和语义相关性都具备一定的敏感性，但敏感程度受模型架构和提示方式影响。与人类相比，LLMs在整合概率和语义线索时不够一致。此外，增加模型参数规模未必提升与人类判断的一致性。

Conclusion: 虽然LLMs能够部分模拟人类条件句可接受性的判断依据，但其稳定性和人类尚有差距，且单纯增大模型规模并不能缩小这种差异。

Abstract: Conditional acceptability refers to how plausible a conditional statement is
perceived to be. It plays an important role in communication and reasoning, as
it influences how individuals interpret implications, assess arguments, and
make decisions based on hypothetical scenarios. When humans evaluate how
acceptable a conditional "If A, then B" is, their judgments are influenced by
two main factors: the $\textit{conditional probability}$ of $B$ given $A$, and
the $\textit{semantic relevance}$ of the antecedent $A$ given the consequent
$B$ (i.e., whether $A$ meaningfully supports $B$). While prior work has
examined how large language models (LLMs) draw inferences about conditional
statements, it remains unclear how these models judge the
$\textit{acceptability}$ of such statements. To address this gap, we present a
comprehensive study of LLMs' conditional acceptability judgments across
different model families, sizes, and prompting strategies. Using linear
mixed-effects models and ANOVA tests, we find that models are sensitive to both
conditional probability and semantic relevance-though to varying degrees
depending on architecture and prompting style. A comparison with human data
reveals that while LLMs incorporate probabilistic and semantic cues, they do so
less consistently than humans. Notably, larger models do not necessarily align
more closely with human judgments.

</details>


### [192] [Single layer tiny Co$^4$ outpaces GPT-2 and GPT-BERT](https://arxiv.org/abs/2510.08404)
*Noor Ul Zain,Mohsin Raza,Ahsan Adeel*

Main category: cs.CL

TL;DR: Co$^4$是一种仅有单层、两个头、800万参数、运行复杂度为O(N)的新型小模型，在BabyLM Challenge上训两轮就大幅超越了GPT-2和GPT-BERT各自用10轮训练的表现。其零样本和微调任务表现均优于对比模型，展现了极高的训练效率和样本利用能力。


<details>
  <summary>Details</summary>
Motivation: 现有主流大模型（如GPT-2、BERT）参数量多、计算复杂度高、需大量数据训练，成本极高。作者希望验证能否通过轻量级架构和高效算法，在参数量小、训练轮数少的情况下，获得更高训练效率和表现。

Method: 提出Co$^4$模型，结构极简（1层、2头、800万参数），复杂度为O(N)。与GPT-2（124M参数，12层，O(N^2)）和GPT-BERT（30M参数，12层，O(N^2)）在相同任务（BabyLM Challenge）、相同训练数据（1000万token）、显著更少训练轮数（2轮vs10轮）下做对比评测，同时用标准评测流程测试其零样本和微调能力。

Result: Co$^4$在SuperGLUE等复杂任务的零样本和微调评测中，分别在大多数评测指标上优于GPT-2和GPT-BERT：在7项零样本任务中有5项超越GPT-2，4项超越GPT-BERT；微调任务有6项超越GPT-2，4项超越GPT-BERT。相比竞品模型，Co$^4$在训练效率（样本、高速率学习）上优异。

Conclusion: 极简、轻量的新型模型架构可在训练效率、样本利用率和下游表现上大幅超越传统大模型，现有‘大模型-大数据’范式与扩展律有必要重新审视。

Abstract: We show that a tiny Co$^4$ machine(Adeel,2025) with a single layer, two
heads, and 8M parameters, operating at an approximate cost of $O(N)$ (where $N$
is the number of input tokens), outpaces the BabyLM Challenge baselines GPT-2
(124M, 12 layers, $O(N^2))$ and GPT-BERT (30M, 12 layers, $O(N^2))$ in just two
epochs, while both are trained for ten. Co$^4$ achieves orders-of-magnitude
greater training efficiency on 10M tokens, demonstrating highly sample
efficient pretraining. Using the BabyLM challenge evaluation pipeline across
complex benchmarks, Co$^4$ exhibits strong zero-shot and fine-tuning
performance on SuperGLUE tasks. Specifically, Co$^4$ outperforms GPT-2 on 5 out
of 7 zero-shot metrics and 6 out of 7 fine-tuning tasks, and GPT-BERT on 4 out
of 7 metrics in both cases. These results suggest the need to rethink
prevailing deep learning paradigms and associated scaling laws.

</details>


### [193] [ARES: Multimodal Adaptive Reasoning via Difficulty-Aware Token-Level Entropy Shaping](https://arxiv.org/abs/2510.08457)
*Shuang Chen,Yue Guo,Yimeng Ye,Shijue Huang,Wenbo Hu,Haoxi Li,Manyuan Zhang,Jiayu Chen,Song Guo,Nanyun Peng*

Main category: cs.CL

TL;DR: 这篇论文提出了一个名为ARES的适应性推理框架，通过动态分配推理探索力度，显著提高了多模态大模型在不同难度任务下的效率和表现。


<details>
  <summary>Details</summary>
Motivation: 目前多模态大模型在简单任务上过度推理、在难题上探索不足，导致资源浪费或失去解题机会。因此，如何根据任务难度自适应调整推理深度成为重要问题。

Method: 提出ARES框架，包含两个关键方法：（1）自适应冷启动训练阶段，通过为不同难度任务配备相应长度的推理轨迹，提升模型难度感知能力；（2）自适应熵策略优化（AEPO），利用高窗口熵（HWE）作为探索触发信号，并通过分层熵奖励和动态KL控制，决定何时及如何加深探索。

Result: 大量实验证明，ARES在数学、逻辑、多模态等各类基准上实现了更高的推理性能和效率，在推理开销远低的情况下，性能接近顶尖商用系统。

Conclusion: ARES通过难度感知和自适应探索机制，解决了多模态大模型‘过度’与‘不足’推理的问题，为高效、大规模多模态推理提供了有效方案。

Abstract: Recent advances in multimodal large reasoning models (MLRMs) have
substantially improved their ability to solve complex textual and visual tasks.
However, these models tend to overthink on simple problems, producing
unnecessarily lengthy reasoning traces, while under-exploring on challenging
ones, leading to missed solutions. To address this imbalance, we propose ARES,
a unified open-source framework for adaptive reasoning that dynamically
allocates exploration effort based on task difficulty. Our approach is
motivated by two key empirical findings: (i) while single-token entropy is
noisy, high window-entropy (HWE) tokens (token-level entropies averaged under a
sliding window) can reliably capture reasoning-critical moments; and (ii)
reducing HWE usage benefits easy problems, while increasing it is essential for
solving hard ones. Building on these insights, ARES introduces a two-stage
training pipeline. In the Adaptive Cold-Start stage, we curate multimodal and
textual data paired with reasoning traces of length proportional to problem
difficulty, equipping the model with initial difficulty awareness. In the
second stage, we develop Adaptive Entropy Policy Optimization (AEPO), which
uses HWE tokens as exploration triggers to decide when to explore, and a
hierarchical entropy reward with dynamic KL control to decide how much to
explore. Extensive experiments demonstrate that ARES achieves superior
performance and reasoning efficiency across diverse mathematical, logical, and
multimodal benchmarks, while closing the gap to leading commercial systems
under significantly lower inference costs.

</details>


### [194] [LeWiDi-2025 at NLPerspectives: The Third Edition of the Learning with Disagreements Shared Task](https://arxiv.org/abs/2510.08460)
*Elisa Leonardelli,Silvia Casola,Siyao Peng,Giulia Rizzi,Valerio Basile,Elisabetta Fersini,Diego Frassinelli,Hyewon Jang,Maja Pavlovic,Barbara Plank,Massimo Poesio*

Main category: cs.CL

TL;DR: 本论文介绍了LEWIDI第三版任务，通过多领域数据集扩展对AI模型理解人类分歧的训练与评估，创新性地采用两种范式进行系统评测，引入新的评估指标，为开发能感知分歧的AI技术提供了新资源和见解。


<details>
  <summary>Details</summary>
Motivation: 许多研究者认为，AI模型应具备对人类判断分歧的感知能力，并以识别判断变异的能力进行评估。为了促进该方向发展，有必要构建有代表性的任务、数据集和评估方法。

Method: LEWIDI第三版通过涵盖同义句识别、讽刺检测、反讽检测和自然语言推断四大任务，采用同时包含分类和有序标注的数据集。引入两种评估范式：一是软标签方法，模型预测整体判断分布；二是观点主义方法，模型预测具体标注者的判断。同时尝试了新的评估指标替代传统交叉熵。

Result: 该任务吸引了多个团队参与，结果分析揭示了建模人类分歧的不同方法的优劣，并验证了多种新颖的评估范式和指标的有效性与适用性。

Conclusion: LEWIDI第三版进一步完善了面向分歧感知AI的基准和框架，提供了丰富的资源、基准和经验，有助于推动能理解人类分歧的智能技术发展。

Abstract: Many researchers have reached the conclusion that AI models should be trained
to be aware of the possibility of variation and disagreement in human
judgments, and evaluated as per their ability to recognize such variation. The
LEWIDI series of shared tasks on Learning With Disagreements was established to
promote this approach to training and evaluating AI models, by making suitable
datasets more accessible and by developing evaluation methods. The third
edition of the task builds on this goal by extending the LEWIDI benchmark to
four datasets spanning paraphrase identification, irony detection, sarcasm
detection, and natural language inference, with labeling schemes that include
not only categorical judgments as in previous editions, but ordinal judgments
as well. Another novelty is that we adopt two complementary paradigms to
evaluate disagreement-aware systems: the soft-label approach, in which models
predict population-level distributions of judgments, and the perspectivist
approach, in which models predict the interpretations of individual annotators.
Crucially, we moved beyond standard metrics such as cross-entropy, and tested
new evaluation metrics for the two paradigms. The task attracted diverse
participation, and the results provide insights into the strengths and
limitations of methods to modeling variation. Together, these contributions
strengthen LEWIDI as a framework and provide new resources, benchmarks, and
findings to support the development of disagreement-aware technologies.

</details>


### [195] [DeepPrune: Parallel Scaling without Inter-trace Redundancy](https://arxiv.org/abs/2510.08483)
*Shangqing Tu,Yaxuan Li,Yushi Bai,Lei Hou,Juanzi Li*

Main category: cs.CL

TL;DR: 论文提出了DeepPrune框架，通过动态剪枝技术大幅提高大语言模型并行推理中的效率，削减了80%以上冗余计算，同时保持高准确率。


<details>
  <summary>Details</summary>
Motivation: 并行推理（Parallel scaling）可以提升大语言模型的推理能力，但带来大量冗余计算，大约80%的并行思路产生相同答案，造成巨大资源浪费。为了解决推理中的效率瓶颈，迫切需要方法去除冗余。

Method: 提出DeepPrune方法，包括：1）采用特殊的判别模型（Judge Model），结合focal loss和过采样训练来判断部分推理轨迹是否将导向同一答案，2）通过在线贪心聚类算法，动态剪枝掉等价路径，但保留结果多样性。

Result: 在AIME 2024、AIME 2025和GPQA等三个基准与不同推理模型上评测，DeepPrune比传统共识采样方法减少了80%以上的token消耗，准确率损失小于3个百分点。

Conclusion: DeepPrune极大提升了大语言模型并行推理的效率，同时保持了较高的推理准确性,为高效并行推理树立了新标准。

Abstract: Parallel scaling has emerged as a powerful paradigm to enhance reasoning
capabilities in large language models (LLMs) by generating multiple
Chain-of-Thought (CoT) traces simultaneously. However, this approach introduces
significant computational inefficiency due to inter-trace redundancy -- our
analysis reveals that over 80% of parallel reasoning traces yield identical
final answers, representing substantial wasted computation. To address this
critical efficiency bottleneck, we propose DeepPrune, a novel framework that
enables efficient parallel scaling through dynamic pruning. Our method features
a specialized judge model trained with focal loss and oversampling techniques
to accurately predict answer equivalence from partial reasoning traces which
realizes 0.87 AUROC on equivalence prediction, combined with an online greedy
clustering algorithm that dynamically prunes redundant paths while preserving
answer diversity. Comprehensive evaluations across three challenging benchmarks
(AIME 2024, AIME 2025, and GPQA) and multiple reasoning models demonstrate that
DeepPrune achieves remarkable token reduction by over 80% compared to
conventional consensus sampling on most cases, while maintaining competitive
accuracy within 3 percentage points. Our work establishes a new standard for
efficient parallel reasoning, making high-performance reasoning more efficient.
Our code and data are here: https://deepprune.github.io/

</details>


### [196] [Neologism Learning for Controllability and Self-Verbalization](https://arxiv.org/abs/2510.08506)
*John Hewitt,Oyvind Tafjord,Robert Geirhos,Been Kim*

Main category: cs.CL

TL;DR: 本文提出了一种通过引入新词（neologisms）来更好地理解和控制大语言模型（LLM）的方法，通过仅训练新词向量来实现对模型新概念的表达与操作。


<details>
  <summary>Details</summary>
Motivation: 人类为新兴且有用的概念发明新词，作者希望探索在与LLM交互中，是否也能通过引入新词来理解和操控模型，以应对模型表达新概念的局限，进而扩展近期提出的新词学习（neologism learning）方法。

Method: 在原模型参数不变的情况下，只添加新词的向量表征，通过展示概念实例训练新词语义。通过新词学习，研究能否在模型中加入、操控如拍马屁、输出错误答案、文本长度等具体或复杂概念。同时引入自我口语化（self-verbalization），让模型用自然语言描述新词含义，并提出plug-in evaluation验证这些描述的有效性。

Result: 实验证明，加入新词能有效操控和表达诸如拍马屁、输出错误答案、AxBench复杂语义等各种概念。模型还可对新词产生自我口语化、说明新词含义。插件式评估显示，许多新词解释能精准对应目标控制行为，且发现部分机器专用的同义词（对人类无意义但对机器有控制效能）。此外，新词学习能支持多词多概念的同时训练。

Conclusion: 新词引入为语言模型表达与控制新概念提供了有效工具，不仅增强模型可控性，也为模型内部语义理解和透明度提供新视角，对语言模型的解释性和可操作性具有重要意义。

Abstract: Humans invent new words when there is a rising demand for a new useful
concept (e.g., doomscrolling). We explore and validate a similar idea in our
communication with LLMs: introducing new words to better understand and control
the models, expanding on the recently introduced neologism learning. This
method introduces a new word by adding a new word embedding and training with
examples that exhibit the concept with no other changes in model parameters. We
show that adding a new word allows for control of concepts such as flattery,
incorrect answers, text length, as well as more complex concepts in AxBench. We
discover that neologisms can also further our understanding of the model via
self-verbalization: models can describe what each new word means to them in
natural language, like explaining that a word that represents a concept of
incorrect answers means ``a lack of complete, coherent, or meaningful
answers...'' To validate self-verbalizations, we introduce plug-in evaluation:
we insert the verbalization into the context of a model and measure whether it
controls the target concept. In some self-verbalizations, we find machine-only
synonyms: words that seem unrelated to humans but cause similar behavior in
machines. Finally, we show how neologism learning can jointly learn multiple
concepts in multiple words.

</details>


### [197] [Efficient Prompt Optimisation for Legal Text Classification with Proxy Prompt Evaluator](https://arxiv.org/abs/2510.08524)
*Hyunji Lee,Kevin Chenhao Li,Matthias Grabmair,Shanshan Xu*

Main category: cs.CL

TL;DR: 本文提出了一种结合蒙特卡洛树搜索（MCTS）和代理提示评估器的新方法，有效优化提示词以提升法律NLP任务中的公平性检测性能，并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的提示词优化方法需大量计算资源，效率低，特别是在法律文本公平性检测等复杂任务中，急需高效且成本低的优化手段。

Method: 本文提出了将MCTS与代理提示评估器结合的算法框架，通过高效探索提示词空间并使用低成本评分方法，提升了优化效率和准确性。

Result: 实验结果表明，所提方法在有限计算预算下，分类准确率及效率均优于现有主流基线方法。

Conclusion: 结合MCTS与代理评估器的提示词优化方法可有效提升模型在法律文本公平性检测中的表现，并具有更高的计算效率，适用于资源有限场景。

Abstract: Prompt optimization aims to systematically refine prompts to enhance a
language model's performance on specific tasks. Fairness detection in Terms of
Service (ToS) clauses is a challenging legal NLP task that demands carefully
crafted prompts to ensure reliable results. However, existing prompt
optimization methods are often computationally expensive due to inefficient
search strategies and costly prompt candidate scoring. In this paper, we
propose a framework that combines Monte Carlo Tree Search (MCTS) with a proxy
prompt evaluator to more effectively explore the prompt space while reducing
evaluation costs. Experiments demonstrate that our approach achieves higher
classification accuracy and efficiency than baseline methods under a
constrained computation budget.

</details>


### [198] [Which Heads Matter for Reasoning? RL-Guided KV Cache Compression](https://arxiv.org/abs/2510.08525)
*Wenjie Du,Li Jiang,Keda Tao,Xue Liu,Huan Wang*

Main category: cs.CL

TL;DR: 论文提出了一种用于推理大语言模型的高效KV缓存压缩方法RLKV，通过识别推理关键性头部，实现显著缓存减小且性能几乎无损。


<details>
  <summary>Details</summary>
Motivation: 推理型大语言模型在解码过程中会生成大量链式思考内容，导致前所未有的KV缓存压力。现有压缩方法要么破坏推理完整性，要么压缩了关键头部，导致推理性能大幅下降。因此，有必要开发针对推理任务优化的KV缓存压缩方法。

Method: 作者观察到推理模型的KV头部具有功能异质性。RLKV方法利用强化学习，针对每个头部直接优化缓存使用量与推理质量的关系，通过实际样本生成获得奖励，从而识别出对推理有关键作用的头部。这些头部分配完整KV缓存，其余则统一压缩。

Result: 实验证实，只有少数注意力头部对推理至关重要。RLKV在缓存压缩率达20-50%时，仍可保持几乎无损的推理性能，优于现有基线方法。

Conclusion: RLKV能够有效识别并保留推理关键头部，实现高效KV缓存压缩，为推理大语言模型的部署带来了显著的系统成本优化。

Abstract: Reasoning large language models exhibit complex reasoning behaviors through
the extended chain-of-thought generation, creating unprecedented Key-Value (KV)
cache overhead during the decoding phase. Existing KV cache compression methods
underperform on reasoning models: token-dropping methods break reasoning
integrity by discarding critical information, while head-reallocating methods
mistakenly compress reasoning-critical heads since they are designed for
retrieval tasks, resulting in significant performance degradation as
compression rates increase. We hypothesize that KV heads exhibit functional
heterogeneity in reasoning models-some heads are critical for chain-of-thought
consistency while others are compressible. To validate and exploit this
insight, we propose RLKV, a novel reasoning-critical head identification
framework, which uses reinforcement learning to directly optimize the
relationship between each head's cache usage and reasoning quality. As RLKV
produces rewards from actual generated samples during training, it naturally
identifies heads relevant to reasoning behaviors. We then allocate full KV
cache to these heads while applying compressed constant KV cache to others for
efficient inference. Our experiments reveal that only a small fraction of
attention heads is essential for reasoning, enabling our KV compression
approach to outperform baseline methods while achieving 20-50% cache reduction
with near lossless performance compared to uncompressed results.

</details>


### [199] [CoMAS: Co-Evolving Multi-Agent Systems via Interaction Rewards](https://arxiv.org/abs/2510.08529)
*Xiangyuan Xue,Yifan Zhou,Guibin Zhang,Zaibin Zhang,Yijiang Li,Chen Zhang,Zhenfei Yin,Philip Torr,Wanli Ouyang,Lei Bai*

Main category: cs.CL

TL;DR: 该论文提出CoMAS框架，通过多智能体间自发互动学习与演化，无需外部监督，实现LLM代理的自进化。实验显示其超越现有方法，并具备良好可扩展性。


<details>
  <summary>Details</summary>
Motivation: 目前LLM代理自进化的研究主要基于强化学习，要么依赖密集的外部奖励信号，要么采用自身产生的内在奖励，但这些与人类通过讨论、协作实现提升的机制不符。本工作希望模仿人类协作演化，从多智能体间互动中实现LLM的自主、分布式进化。

Method: 提出了CoMAS多智能体协同进化系统，利用代理间丰富的讨论互动，通过LLM裁判机制从互动中生成内在奖励，用RL优化每个代理策略，实现无外部监督的去中心化自进化。

Result: 实验表明，CoMAS在多数评测场景下性能达到SOTA，明显优于未经训练的基线方法。消融实验也验证了基于互动奖励信号的必要性，并显示随着代理数量和多样性提升其扩展性良好。

Conclusion: CoMAS为LLM代理的自进化提供了一种新颖有效的范式，具备分布式、可扩展等优点，展现出先进的性能和发展前景。

Abstract: Self-evolution is a central research topic in enabling large language model
(LLM)-based agents to continually improve their capabilities after pretraining.
Recent research has witnessed a transition from reinforcement learning
(RL)-free to RL-based methods. Current RL-based methods either rely on dense
external reward signals or extract intrinsic reward signals from LLMs
themselves. However, these approaches diverge from the self-evolution
mechanisms observed in human intelligence, where individuals learn and improve
through mutual discussion and collaboration. In this work, we introduce
Co-Evolving Multi-Agent Systems (CoMAS), a novel framework that enables agents
to improve autonomously by learning from inter-agent interactions without
external supervision. CoMAS generates intrinsic rewards from rich discussion
dynamics, employs an LLM-as-a-judge mechanism to formulate these rewards, and
optimizes each agent's policy through RL, thereby enabling decentralized and
scalable co-evolution. Experimental results demonstrate that CoMAS consistently
outperforms untrained agents and achieves state-of-the-art performance across
most evaluation settings. Ablation studies confirm the necessity of
interaction-based reward signals and reveal promising scalability as the number
and diversity of agents increase. These findings establish CoMAS as a novel and
effective paradigm for self-evolution in LLM-based agents.

</details>


### [200] [ArenaBencher: Automatic Benchmark Evolution via Multi-Model Competitive Evaluation](https://arxiv.org/abs/2510.08569)
*Qin Liu,Jacob Dineen,Yuxi Huang,Sheng Zhang,Hoifung Poon,Ben Zhou,Muhao Chen*

Main category: cs.CL

TL;DR: 本文提出了ArenaBencher框架，自动迭代升级大模型基准测试题，有效克服了数据泄漏和‘刷题’导致的测试失真问题。


<details>
  <summary>Details</summary>
Motivation: 目前大模型能力评测大量依赖公开基准集，但由于这些数据往往出现在预训练语料中，模型可能通过记忆匹配拿到高分，导致测试结果不真实、模型之间难比较，不能客观反映技术进展。

Method: ArenaBencher框架能自动分析测试题的核心能力要求，并基于这些要求生成新的候选题目及标准答案，通过LLM判分员核查题意和正确性，并综合多模型反馈选取能暴露模型共性弱点的试题。该流程支持多轮迭代更新，并应用in-context learning引导生成更具挑战性和区分度的题目。

Result: 在数学、常识推理和安全等领域验证表明，ArenaBencher产生的新版题集多样、经过核验，可以发现新的模型失效点，难度提升但测试目标未变，并能更清楚地区分不同模型表现。

Conclusion: ArenaBencher为基准测试随大模型进步持续演化提供了可靠、可扩展的自动化工具，有助于得到更加公正客观的模型评测结果。

Abstract: Benchmarks are central to measuring the capabilities of large language models
and guiding model development, yet widespread data leakage from pretraining
corpora undermines their validity. Models can match memorized content rather
than demonstrate true generalization, which inflates scores, distorts
cross-model comparisons, and misrepresents progress. We introduce ArenaBencher,
a model-agnostic framework for automatic benchmark evolution that updates test
cases while preserving comparability. Given an existing benchmark and a diverse
pool of models to be evaluated, ArenaBencher infers the core ability of each
test case, generates candidate question-answer pairs that preserve the original
objective, verifies correctness and intent with an LLM as a judge, and
aggregates feedback from multiple models to select candidates that expose
shared weaknesses. The process runs iteratively with in-context demonstrations
that steer generation toward more challenging and diagnostic cases. We apply
ArenaBencher to math problem solving, commonsense reasoning, and safety domains
and show that it produces verified, diverse, and fair updates that uncover new
failure modes, increase difficulty while preserving test objective alignment,
and improve model separability. The framework provides a scalable path to
continuously evolve benchmarks in step with the rapid progress of foundation
models.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [201] [FLEET: Formal Language-Grounded Scheduling for Heterogeneous Robot Teams](https://arxiv.org/abs/2510.07417)
*Corban Rivera,Grayson Byrd,Meghan Booker,Bethany Kemp,Allison Gaines,Emma Holmes,James Uplinger,Celso M de Melo,David Handelman*

Main category: cs.RO

TL;DR: FLEET 是一个结合了大型语言模型（LLM）和形式化方法的分布式框架，能够将自然语言指令转化为优化的多机器人调度方案，实现异构机器人团队的高效协同。


<details>
  <summary>Details</summary>
Motivation: 自然语言规划器难以处理多机器人长期协同任务，常产生幻觉问题，而传统的形式化方法又强依赖于封闭世界模型，难以应对实际的开放场景。因此，亟需设计一种既能处理自然语言输入，又能高效调度异构机器人团队的方法。

Method: FLEET 首先通过 LLM 前端从自然语言中提取任务图（含持续时间和优先关系）和机器人-任务适配矩阵，随后利用形式化方法（比如混合整数线性规划MILP）在后端进行调度优化，实现时长最小化。同时，每个机器人以自主闭环控制方式执行各自的子任务，从而确保效率和鲁棒性。

Result: 在多个自由格式语言引导的多机器人自动协同基准测试上，FLEET 在异构双机器人任务中成功率高于现有生成式规划器。消融实验显示，MILP 优化主要提升了时序结构，而基于 LLM 适配矩阵则对能力耦合任务表现尤其关键，两者结合带来最佳整体表现。此外，FLEET 在实际硬件（两只能力互补的四足机器人）上也实现了验证。

Conclusion: FLEET 有效融合了自然语言处理与形式化优化方法，实现了异构机器人团队在开放世界中对自然语言指令的高效协同与调度，为多机器人系统的自然语言控制和实际部署提供了新范式。

Abstract: Coordinating heterogeneous robot teams from free-form natural-language
instructions is hard. Language-only planners struggle with long-horizon
coordination and hallucination, while purely formal methods require
closed-world models. We present FLEET, a hybrid decentralized framework that
turns language into optimized multi-robot schedules. An LLM front-end produces
(i) a task graph with durations and precedence and (ii) a capability-aware
robot--task fitness matrix; a formal back-end solves a makespan-minimization
problem while the underlying robots execute their free-form subtasks with
agentic closed-loop control. Across multiple free-form language-guided autonomy
coordination benchmarks, FLEET improves success over state of the art
generative planners on two-agent teams across heterogeneous tasks. Ablations
show that mixed integer linear programming (MILP) primarily improves temporal
structure, while LLM-derived fitness is decisive for capability-coupled tasks;
together they deliver the highest overall performance. We demonstrate the
translation to real world challenges with hardware trials using a pair of
quadruped robots with disjoint capabilities.

</details>


### [202] [VeMo: A Lightweight Data-Driven Approach to Model Vehicle Dynamics](https://arxiv.org/abs/2510.07447)
*Girolamo Oddo,Roberto Nuca,Matteo Parsani*

Main category: cs.RO

TL;DR: 本文提出了一种基于门控循环单元（GRU）的轻量级编码器-解码器模型，用于在缺乏车辆结构信息的情况下，对高性能车辆的动态进行建模。该模型能够仅凭车辆历史状态和控制动作数据，准确预测未来车辆状态。


<details>
  <summary>Details</summary>
Motivation: 在无人驾驶和车辆建模领域，常常面临难以获取详细车辆结构信息的问题，尤其是在使用现有车辆平台进行开发时。传统的物理建模方法受限于模型参数缺失，难以适应在缺乏结构信息的情况下对车辆动态进行准确建模，因此迫切需要一种只依赖于观测和控制数据的建模方法。

Method: 作者提出使用基于门控循环单元（GRU）层的编码器-解码器神经网络模型，将车辆历史状态和驾驶员的控制输入作为输入，预测未来时刻的车辆状态。这一模型完全数据驱动，无需依赖物理模型或结构参数。

Result: 实验结果表明，在极端动态工况下，该模型的最大平均相对误差低于2.6%，在有噪声输入的情况下依然表现出良好的鲁棒性，对感兴趣的频率分量具有较好适应性。

Conclusion: 该模型无需结构信息也可实现高精度、鲁棒的车辆动态建模，输出物理量（如纵/横向加速度、偏航率和纵向速度）具备物理一致性，为自动驾驶及其他仅能获取有限车辆信息的应用提供了有效的数据驱动建模方法。

Abstract: Developing a dynamic model for a high-performance vehicle is a complex
problem that requires extensive structural information about the system under
analysis. This information is often unavailable to those who did not design the
vehicle and represents a typical issue in autonomous driving applications,
which are frequently developed on top of existing vehicles; therefore, vehicle
models are developed under conditions of information scarcity. This paper
proposes a lightweight encoder-decoder model based on Gate Recurrent Unit
layers to correlate the vehicle's future state with its past states, measured
onboard, and control actions the driver performs. The results demonstrate that
the model achieves a maximum mean relative error below 2.6% in extreme dynamic
conditions. It also shows good robustness when subject to noisy input data
across the interested frequency components. Furthermore, being entirely
data-driven and free from physical constraints, the model exhibits physical
consistency in the output signals, such as longitudinal and lateral
accelerations, yaw rate, and the vehicle's longitudinal velocity.

</details>


### [203] [HJCD-IK: GPU-Accelerated Inverse Kinematics through Batched Hybrid Jacobian Coordinate Descent](https://arxiv.org/abs/2510.07514)
*Cael Yasutake,Zachary Kingston,Brian Plancher*

Main category: cs.RO

TL;DR: 本文提出了一种新的GPU加速IK求解算法HJCD-IK，结合贪心坐标下降与雅可比法进行混合优化，显著提升了精度与速度。


<details>
  <summary>Details</summary>
Motivation: 现有逆运动学(IK)求解器存在局限。解析法虽快但适用范围窄，数值优化法适用性强却速度慢且易陷入局部最优。因此需要更快、更准确、更通用的IK求解方法。

Method: 提出HJCD-IK方法：在GPU上实现，采用面向姿态的贪心坐标下降做初值，之后用雅可比法优化精度，二者结合保证了更优的初始点和收敛表现。同时能生成大量高质量解。

Result: HJCD-IK性能优于目前主流方法，在精度与速度之间达到Pareto前沿，精度、收敛速度通常提升一个数量级，且采样分布质量最佳（最低最大平均差异）。

Conclusion: HJCD-IK兼顾了IK求解的通用性、精度和高效率，对机器人运动学具有实际改进意义，并已开源以促进学界发展。

Abstract: Inverse Kinematics (IK) is a core problem in robotics, in which joint
configurations are found to achieve a desired end-effector pose. Although
analytical solvers are fast and efficient, they are limited to systems with low
degrees-of-freedom and specific topological structures. Numerical
optimization-based approaches are more general, but suffer from high
computational costs and frequent convergence to spurious local minima. Recent
efforts have explored the use of GPUs to combine sampling and optimization to
enhance both the accuracy and speed of IK solvers. We build on this recent
literature and introduce HJCD-IK, a GPU-accelerated, sampling-based hybrid
solver that combines an orientation-aware greedy coordinate descent
initialization scheme with a Jacobian-based polishing routine. This design
enables our solver to improve both convergence speed and overall accuracy as
compared to the state-of-the-art, consistently finding solutions along the
accuracy-latency Pareto frontier and often achieving order-of-magnitude gains.
In addition, our method produces a broad distribution of high-quality samples,
yielding the lowest maximum mean discrepancy. We release our code open-source
for the benefit of the community.

</details>


### [204] [AVO: Amortized Value Optimization for Contact Mode Switching in Multi-Finger Manipulation](https://arxiv.org/abs/2510.07548)
*Adam Hung,Fan Yang,Abhinav Kumar,Sergio Aguilera Marinovic,Soshi Iba,Rana Soltani Zarrin,Dmitry Berenson*

Main category: cs.RO

TL;DR: 本论文提出了一种新的轨迹优化方法（AVO），能更好地处理灵巧操作任务中的多接触模式切换，提高性能并减少计算量，在仿真和真实环境的螺丝刀抓握和旋转任务中取得了优异效果。


<details>
  <summary>Details</summary>
Motivation: 传统将灵巧操作轨迹优化任务分解为若干子任务（对应不同接触模式）分别求解的方法，会因为缺乏对子任务之间联系的考虑而限制整体性能，并带来高昂的计算成本。

Method: 提出了Amortized Value Optimization（AVO）方法，通过引入可学习的价值函数预测未来总任务表现，将该价值函数融入每个轨迹优化步骤的代价，从而以价值梯度引导优化器朝向最小化后续子任务代价的状态发展，实现了对子任务之间的有效衔接并加速了优化过程。

Result: 在模拟和真实世界的螺丝刀抓取和转动任务中，AVO方法与未引入价值函数的轨迹优化相比，在计算预算减少50%的情况下依然取得了更优的任务表现。

Conclusion: AVO方法能够有效弥补传统方法对子任务衔接和整体任务优化不足的问题，同时大幅减少计算消耗，未来可推广至更广泛的灵巧操作任务中。

Abstract: Dexterous manipulation tasks often require switching between different
contact modes, such as rolling, sliding, sticking, or non-contact contact
modes. When formulating dexterous manipulation tasks as a trajectory
optimization problem, a common approach is to decompose these tasks into
sub-tasks for each contact mode, which are each solved independently.
Optimizing each sub-task independently can limit performance, as optimizing
contact points, contact forces, or other variables without information about
future sub-tasks can place the system in a state from which it is challenging
to make progress on subsequent sub-tasks. Further, optimizing these sub-tasks
is very computationally expensive. To address these challenges, we propose
Amortized Value Optimization (AVO), which introduces a learned value function
that predicts the total future task performance. By incorporating this value
function into the cost of the trajectory optimization at each planning step,
the value function gradients guide the optimizer toward states that minimize
the cost in future sub-tasks. This effectively bridges separately optimized
sub-tasks, and accelerates the optimization by reducing the amount of online
computation needed. We validate AVO on a screwdriver grasping and turning task
in both simulation and real world experiments, and show improved performance
even with 50% less computational budget compared to trajectory optimization
without the value function.

</details>


### [205] [Inspection Planning Primitives with Implicit Models](https://arxiv.org/abs/2510.07611)
*Jingyang You,Hanna Kurniawati,Lashika Medagoda*

Main category: cs.RO

TL;DR: 该论文提出了一种基于神经隐式SDF模型的巡检规划原语（IPIM），显著降低了大规模复杂结构巡检规划的内存使用，同时保证与先进方法相近的巡检路径质量。


<details>
  <summary>Details</summary>
Motivation: 随着基础设施老化和结构复杂度提升，对高效的巡检规划需求变得愈发重要。现有方法虽然计算快，但在大规模复杂结构下占用大量内存，尤其在涉及大量不同几何构件时更为突出。作者希望解决高效使用内存与巡检路径质量之间的矛盾。

Method: 作者提出一套面向神经隐式模型（主要是神经SDF）的基础巡检计算原语（IPIM），替换传统只适用于显式模型的原语，实现了整个规划过程中都以神经SDF为环境表达，无需频繁转换显式与隐式模型。

Result: 在三个场景（包括一个含9200万三角网格面的现实复杂结构）中的实验表明，应用IPIM的基础采样规划器可生成与先进方法相近质量的巡检轨迹，但内存消耗最多可降低70倍。

Conclusion: 通过IPIM，采样式巡检规划器可全程在神经隐式模型上工作，大幅减少内存占用，且不牺牲巡检任务的线路质量。该方案提升了针对大规模复杂结构的巡检规划的实际可用性。

Abstract: The aging and increasing complexity of infrastructures make efficient
inspection planning more critical in ensuring safety. Thanks to sampling-based
motion planning, many inspection planners are fast. However, they often require
huge memory. This is particularly true when the structure under inspection is
large and complex, consisting of many struts and pillars of various geometry
and sizes. Such structures can be represented efficiently using implicit
models, such as neural Signed Distance Functions (SDFs). However, most
primitive computations used in sampling-based inspection planner have been
designed to work efficiently with explicit environment models, which in turn
requires the planner to use explicit environment models or performs frequent
transformations between implicit and explicit environment models during
planning. This paper proposes a set of primitive computations, called
Inspection Planning Primitives with Implicit Models (IPIM), that enable
sampling-based inspection planners to entirely use neural SDFs representation
during planning. Evaluation on three scenarios, including inspection of a
complex real-world structure with over 92M triangular mesh faces, indicates
that even a rudimentary sampling-based planner with IPIM can generate
inspection trajectories of similar quality to those generated by the
state-of-the-art planner, while using up to 70x less memory than the
state-of-the-art inspection planner.

</details>


### [206] [GATO: GPU-Accelerated and Batched Trajectory Optimization for Scalable Edge Model Predictive Control](https://arxiv.org/abs/2510.07625)
*Alexander Du,Emre Adabag,Gabriel Bravo,Brian Plancher*

Main category: cs.RO

TL;DR: 本文提出了GATO，一种开源的、GPU加速的批量轨迹优化（TO）求解器，专为在中等批量（几十到一百多个求解）下实现MPC的实时性能设计。GATO显著提高了求解速度，有效填补了现有方法在实时大批量求解时的性能空白。


<details>
  <summary>Details</summary>
Motivation: 现有的MPC在实时解决非线性轨迹优化问题时计算成本高。已有的GPU加速方法在小批量求解、批量规模扩大、模型通用性等方面存在各种限制，难以满足实际机器人需求。本文旨在攻克实时中等批量（几十到百余）的轨迹优化计算难题。

Method: GATO结合算法、软件和硬件协同设计，充分利用GPU内的block、warp、thread多层级并行加速，面向多个独立TO求解批处理，提升整体运行效率。同时通过开源实现以支持社区复现与应用。

Result: 仿真实验中，GATO比CPU基线快18-21倍，比GPU基线快1.4-16倍。案例分析显示GATO在扰动抑制和收敛性方面表现优越，最终还在工业机械臂硬件平台上进行了验证。

Conclusion: GATO大幅提升了适用于MPC的TO批量求解效率，尤其适合中等批量规模的实时应用。其开源实现有助于推广和应用，为相关领域的研究和工程实践提供强有力工具。

Abstract: While Model Predictive Control (MPC) delivers strong performance across
robotics applications, solving the underlying (batches of) nonlinear trajectory
optimization (TO) problems online remains computationally demanding. Existing
GPU-accelerated approaches typically (i) parallelize a single solve to meet
real-time deadlines, (ii) scale to very large batches at slower-than-real-time
rates, or (iii) achieve speed by restricting model generality (e.g., point-mass
dynamics or a single linearization). This leaves a large gap in solver
performance for many state-of-the-art MPC applications that require real-time
batches of tens to low-hundreds of solves. As such, we present GATO, an open
source, GPU-accelerated, batched TO solver co-designed across algorithm,
software, and computational hardware to deliver real-time throughput for these
moderate batch size regimes. Our approach leverages a combination of block-,
warp-, and thread-level parallelism within and across solves for ultra-high
performance. We demonstrate the effectiveness of our approach through a
combination of: simulated benchmarks showing speedups of 18-21x over CPU
baselines and 1.4-16x over GPU baselines as batch size increases; case studies
highlighting improved disturbance rejection and convergence behavior; and
finally a validation on hardware using an industrial manipulator. We open
source GATO to support reproducibility and adoption.

</details>


### [207] [Differentiable Particle Optimization for Fast Sequential Manipulation](https://arxiv.org/abs/2510.07674)
*Lucas Chen,Shrutheesh Raman Iyer,Zachary Kingston*

Main category: cs.RO

TL;DR: SPaSM提出了一种全GPU并行的轨迹优化方法，实现了机器人顺序操作任务的毫秒级解算速度，显著超越以往方法。


<details>
  <summary>Details</summary>
Motivation: 现有机器人顺序操作任务的轨迹求解受限于高维空间中的几何约束，现有GPU方法受限于CPU-GPU数据传输与硬件利用率不足，难以在大规模或实时场景下应用。

Method: SPaSM方法将约束评估、采样和基于梯度的优化全部编译成CUDA内核，实现全流程GPU端并行计算，避免CPU参与。算法分两阶段：首先通过大规模并行采样求解物体放置约束；然后将解提升到关节空间进行完整轨迹优化，并联合优化物体放置与机器人轨迹，以适应运动可行性约束放置的场景。

Result: 在具挑战性的基准测试上，SPaSM实现了100%成功率，求解用时达到毫秒级，较现有方法快4000倍。

Conclusion: SPaSM显著提升了复杂顺序操作任务的轨迹优化效率和成功率，为机器人高维高约束任务实时解决提供了解决方案，展示了端到端GPU并行在该领域的巨大潜力。

Abstract: Sequential robot manipulation tasks require finding collision-free
trajectories that satisfy geometric constraints across multiple object
interactions in potentially high-dimensional configuration spaces. Solving
these problems in real-time and at large scales has remained out of reach due
to computational requirements. Recently, GPU-based acceleration has shown
promising results, but prior methods achieve limited performance due to CPU-GPU
data transfer overhead and complex logic that prevents full hardware
utilization. To this end, we present SPaSM (Sampling Particle optimization for
Sequential Manipulation), a fully GPU-parallelized framework that compiles
constraint evaluation, sampling, and gradient-based optimization into optimized
CUDA kernels for end-to-end trajectory optimization without CPU coordination.
The method consists of a two-stage particle optimization strategy: first
solving placement constraints through massively parallel sampling, then lifting
solutions to full trajectory optimization in joint space. Unlike hierarchical
approaches, SPaSM jointly optimizes object placements and robot trajectories to
handle scenarios where motion feasibility constrains placement options.
Experimental evaluation on challenging benchmarks demonstrates solution times
in the realm of $\textbf{milliseconds}$ with a 100% success rate; a
$4000\times$ speedup compared to existing approaches.

</details>


### [208] [EB-MBD: Emerging-Barrier Model-Based Diffusion for Safe Trajectory Optimization in Highly Constrained Environments](https://arxiv.org/abs/2510.07700)
*Raghav Mishra,Ian R. Manchester*

Main category: cs.RO

TL;DR: 本文提出了EB-MBD方法，通过渐进式引入屏障函数约束，有效提升Model-Based Diffusion面对复杂约束时的表现，显著提高了解决质量，并大幅降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统在Model-Based Diffusion中引入约束时，由于对score function的Monte Carlo近似采样效率较低，易导致结果崩溃，哪怕只是简单的2D系统。因此需要一种能既保证约束又不会严重牺牲性能的方法。

Method: 通过受内点法启发，设计了一种渐进引入的屏障函数约束策略（Emerging-Barrier），在优化过程中逐步强化对约束的满足，避免了样本采样失效（sample inefficiency）的弊端，无需昂贵的投影操作。同时对每轮采样活跃度进行分析，以合理安排屏障参数调度。

Result: 在2D避障与3D水下机械臂两个实验任务上，EB-MBD方法比传统Model-Based Diffusion获得了更低代价的解，与基于投影的方法相比，计算效率高出好几个数量级。

Conclusion: EB-MBD能显著提升模型在受约束优化任务中的解优性与效率，是受约束的Model-Based Diffusion问题中的一种更优选择。

Abstract: We propose enforcing constraints on Model-Based Diffusion by introducing
emerging barrier functions inspired by interior point methods. We show that
constraints on Model-Based Diffusion can lead to catastrophic performance
degradation, even on simple 2D systems due to sample inefficiency in the Monte
Carlo approximation of the score function. We introduce Emerging-Barrier
Model-Based Diffusion (EB-MBD) which uses progressively introduced barrier
constraints to avoid these problems, significantly improving solution quality,
without the need for computationally expensive operations such as projections.
We analyze the sampling liveliness of samples each iteration to inform barrier
parameter scheduling choice. We demonstrate results for 2D collision avoidance
and a 3D underwater manipulator system and show that our method achieves lower
cost solutions than Model-Based Diffusion, and requires orders of magnitude
less computation time than projection based methods.

</details>


### [209] [Probabilistically-Safe Bipedal Navigation over Uncertain Terrain via Conformal Prediction and Contraction Analysis](https://arxiv.org/abs/2510.07725)
*Kasidit Muenprasitivej,Ye Zhao,Glen Chou*

Main category: cs.RO

TL;DR: 该论文提出了一种使双足机器人在崎岖地形上安全行走的概率性安全规划与控制方法，综合考虑地形不确定性，提高了路径规划的安全性与机器人运动的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，双足机器人常常需要在崎岖、未知的地形环境下行走，地面高度的不确定性会极大影响机器人的稳定性和安全性，因此如何在不确定环境中保证机器人动态可行性和安全性是一个重要挑战。

Method: 作者提出了基于高置信度的模型预测控制（MPC）框架，利用高斯过程回归（GP）估计地形高程，通过共形预测（CP）构建地形高程的置信区间，并将不确定性边界正式引入到机器人运动的质心动力学中。进而构造了基于收缩理论的可达管，保证状态收敛与管道不变。同时，针对线性倒立摆模型（LIPM），提出了基于收缩理论的飞轮力矩控制律，用于稳定CoM的角动量。

Result: 验证了概率安全与目标可达性，理论上证明了力矩控制律的前向不变性与指数稳定性。方法在MuJoCo物理仿真的Digit双足机器人上测试，有效性得到实证。

Conclusion: 所提出的规划与控制框架能够在地形高度不确定的环境下，为双足机器人提供理论保证的安全性和稳定性，实现了目标地点的可靠到达。

Abstract: We address the challenge of enabling bipedal robots to traverse rough terrain
by developing probabilistically safe planning and control strategies that
ensure dynamic feasibility and centroidal robustness under terrain uncertainty.
Specifically, we propose a high-level Model Predictive Control (MPC) navigation
framework for a bipedal robot with a specified confidence level of safety that
(i) enables safe traversal toward a desired goal location across a terrain map
with uncertain elevations, and (ii) formally incorporates uncertainty bounds
into the centroidal dynamics of locomotion control. To model the rough terrain,
we employ Gaussian Process (GP) regression to estimate elevation maps and
leverage Conformal Prediction (CP) to construct calibrated confidence intervals
that capture the true terrain elevation. Building on this, we formulate
contraction-based reachable tubes that explicitly account for terrain
uncertainty, ensuring state convergence and tube invariance. In addition, we
introduce a contraction-based flywheel torque control law for the reduced-order
Linear Inverted Pendulum Model (LIPM), which stabilizes the angular momentum
about the center-of-mass (CoM). This formulation provides both probabilistic
safety and goal reachability guarantees. For a given confidence level, we
establish the forward invariance of the proposed torque control law by
demonstrating exponential stabilization of the actual CoM phase-space
trajectory and the desired trajectory prescribed by the high-level planner.
Finally, we evaluate the effectiveness of our planning framework through
physics-based simulations of the Digit bipedal robot in MuJoCo.

</details>


### [210] [Injecting Hallucinations in Autonomous Vehicles: A Component-Agnostic Safety Evaluation Framework](https://arxiv.org/abs/2510.07749)
*Alexandre Moreira Nascimento,Gabriel Kenji Godoy Shimanuki,Lúcio Flavio Vismari,João Batista Camargo Jr,Jorge Rady de Almeida Jr,Paulo Sergio Cugnasca,Anna Carolina Muller Queiroz,Jeremy Noah Bailenson*

Main category: cs.RO

TL;DR: 本文提出一种基于错觉（hallucination）的想定失效注入框架，通过在开源模拟器中注入多种感知错觉，验证其对自动驾驶车辆安全的影响和压力测试能力。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆感知失效是安全的主要隐患，目前研究多针对单一传感器或感知模块注入故障，导致难以统一、泛化。缺乏一种通用、可扩展的感知失效仿真框架限制了安全验证与研发效率。

Method: 作者提出将感知失效抽象为“错觉”，聚焦于感知输出的失真影响，而非具体硬件或算法细节；开发了可配置、与组件无关的错觉注入框架，支持六类主流感知错觉类型，在迭代式仿真平台中对穿越无信号横街场景下的AV进行大规模注入测试并统计分析。

Result: 框架共执行超过18350次仿真，统计表明不同类型的感知错觉对碰撞和险情的风险具有显著差异。特别是感知延迟、漂移等错觉会明显增加碰撞风险。该框架在有效性和可扩展性方面得到验证。

Conclusion: 框架具有高可扩展性、统计验证与兼容性，可极大简化和加速自动驾驶安全验证流程，适应新型感知架构。其成果有望缩短AV上市周期，并为后续容错和韧性设计研究奠定基础。

Abstract: Perception failures in autonomous vehicles (AV) remain a major safety concern
because they are the basis for many accidents. To study how these failures
affect safety, researchers typically inject artificial faults into hardware or
software components and observe the outcomes. However, existing fault injection
studies often target a single sensor or machine perception (MP) module,
resulting in siloed frameworks that are difficult to generalize or integrate
into unified simulation environments. This work addresses that limitation by
reframing perception failures as hallucinations, false perceptions that distort
an AV situational awareness and may trigger unsafe control actions. Since
hallucinations describe only observable effects, this abstraction enables
analysis independent of specific sensors or algorithms, focusing instead on how
their faults manifest along the MP pipeline. Building on this concept, we
propose a configurable, component-agnostic hallucination injection framework
that induces six plausible hallucination types in an iterative open-source
simulator. More than 18,350 simulations were executed in which hallucinations
were injected while AVs crossed an unsignalized transverse street with traffic.
The results statistically validate the framework and quantify the impact of
each hallucination type on collisions and near misses. Certain hallucinations,
such as perceptual latency and drift, significantly increase the risk of
collision in the scenario tested, validating the proposed paradigm can stress
the AV system safety. The framework offers a scalable, statistically validated,
component agnostic, and fully interoperable toolset that simplifies and
accelerates AV safety validations, even those with novel MP architectures and
components. It can potentially reduce the time-to-market of AV and lay the
foundation for future research on fault tolerance, and resilient AV design.

</details>


### [211] [Trajectory Conditioned Cross-embodiment Skill Transfer](https://arxiv.org/abs/2510.07773)
*YuHang Tang,Yixuan Lou,Pengfei Han,Haoming Song,Xinyi Ye,Dong Wang,Bin Zhao*

Main category: cs.RO

TL;DR: 本论文提出了TrajSkill，一个能让机器人直接从人类示范视频中学习操作技能的框架，解决了人类与机器人形态差异带来的难题。


<details>
  <summary>Details</summary>
Motivation: 因人类和机器人在形态和动作表达上的差异，现有方法通常要依赖配对数据集或手工设计奖励，这限制了技术的可扩展性和泛化能力。因此，亟需一种无需配对数据即可实现跨形态技能迁移的方案。

Method: TrajSkill通过将人类动作以稀疏光流轨迹方式表示，去除形态差异，仅保留动作动态特征。该框架将这些轨迹与视觉及文本信息作为条件输入，联合合成时序一致的机器人操作视频，并将其转化为可执行的机器人动作，从而实现跨形态技能迁移。

Result: 在MetaWorld仿真数据上，TrajSkill比现有最佳方法降低了39.6%的FVD和36.6%的KVD，跨形态技能迁移成功率最高提升16.7%。在真实厨房机器人的实验中，同样验证了方法的实用性。

Conclusion: TrajSkill能够有效实现从人类视频到机器人操作的技能迁移，既提升了迁移的成功率，也展示了其在实际机器人任务中的应用前景。

Abstract: Learning manipulation skills from human demonstration videos presents a
promising yet challenging problem, primarily due to the significant embodiment
gap between human body and robot manipulators. Existing methods rely on paired
datasets or hand-crafted rewards, which limit scalability and generalization.
We propose TrajSkill, a framework for Trajectory Conditioned Cross-embodiment
Skill Transfer, enabling robots to acquire manipulation skills directly from
human demonstration videos. Our key insight is to represent human motions as
sparse optical flow trajectories, which serve as embodiment-agnostic motion
cues by removing morphological variations while preserving essential dynamics.
Conditioned on these trajectories together with visual and textual inputs,
TrajSkill jointly synthesizes temporally consistent robot manipulation videos
and translates them into executable actions, thereby achieving cross-embodiment
skill transfer. Extensive experiments are conducted, and the results on
simulation data (MetaWorld) show that TrajSkill reduces FVD by 39.6\% and KVD
by 36.6\% compared with the state-of-the-art, and improves cross-embodiment
success rate by up to 16.7\%. Real-robot experiments in kitchen manipulation
tasks further validate the effectiveness of our approach, demonstrating
practical human-to-robot skill transfer across embodiments.

</details>


### [212] [IntentionVLA: Generalizable and Efficient Embodied Intention Reasoning for Human-Robot Interaction](https://arxiv.org/abs/2510.07778)
*Yandu Chen,Kefan Gu,Yuqing Wen,Yucheng Zhao,Tiancai Wang,Liqiang Nie*

Main category: cs.RO

TL;DR: 本文提出了IntentionVLA，一种结合了推理和感知能力的新型视觉-语言-行动模型（VLA），针对机器人在复杂现实任务中的隐式人类意图推断问题，实现了更高效和精准的人机交互。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-行动模型大多只在与体现环境无关的多模态任务上进行预训练，缺乏复杂推理能力，导致其难以应对需要隐式意图理解的人机交互场景。因此亟需提升VLA对人类隐式意图的推理和操作能力。

Method: 提出IntentionVLA框架，采用课程式训练策略，首先通过设计结合意图推断、空间定位和紧凑推理的数据，增强模型推理和感知能力。之后在微调阶段，利用推理结果为动作生成提供上下文引导，实现对间接指令的高效推断和执行。

Result: 实验结果表明，IntentionVLA在直接指令条件下比基线方法高出18%成功率，在意图指令下比ECoT高出28%。面对分布外的意图任务时，成功率是基线的两倍以上。此外，IntentionVLA还能实现40%的零样本人机交互成功率。

Conclusion: IntentionVLA为下一代人机交互系统提供了一种有前景的范式，有效提升了机器人理解和执行复杂人类意图的能力。

Abstract: Vision-Language-Action (VLA) models leverage pretrained vision-language
models (VLMs) to couple perception with robotic control, offering a promising
path toward general-purpose embodied intelligence. However, current SOTA VLAs
are primarily pretrained on multimodal tasks with limited relevance to embodied
scenarios, and then finetuned to map explicit instructions to actions.
Consequently, due to the lack of reasoning-intensive pretraining and
reasoning-guided manipulation, these models are unable to perform implicit
human intention reasoning required for complex, real-world interactions. To
overcome these limitations, we propose \textbf{IntentionVLA}, a VLA framework
with a curriculum training paradigm and an efficient inference mechanism. Our
proposed method first leverages carefully designed reasoning data that combine
intention inference, spatial grounding, and compact embodied reasoning,
endowing the model with both reasoning and perception capabilities. In the
following finetuning stage, IntentionVLA employs the compact reasoning outputs
as contextual guidance for action generation, enabling fast inference under
indirect instructions. Experimental results show that IntentionVLA
substantially outperforms $\pi_0$, achieving 18\% higher success rates with
direct instructions and 28\% higher than ECoT under intention instructions. On
out-of-distribution intention tasks, IntentionVLA achieves over twice the
success rate of all baselines, and further enables zero-shot human-robot
interaction with 40\% success rate. These results highlight IntentionVLA as a
promising paradigm for next-generation human-robot interaction (HRI) systems.

</details>


### [213] [GM3: A General Physical Model for Micro-Mobility Vehicles](https://arxiv.org/abs/2510.07807)
*Grace Cai,Nithin Parepally,Laura Zheng,Ming C. Lin*

Main category: cs.RO

TL;DR: 本文提出一种通用微型移动工具动力学模型（GM3），能够统一模拟各种类型微型交通工具的动态行为，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前主流的微型移动交通模拟方法受限于简化的动力学模型，无法准确捕捉轮胎侧滑、载荷转移和车身/驾驶员倾斜等复杂动态，且缺乏一个统一、可扩展、基于物理的通用建模框架。本文旨在弥补这些不足。

Method: 提出了基于轮胎刷模型的GM3动力学模型，支持任意轮胎配置（如单轨、双轨、多轮平台）。开发了与动力学解耦的仿真平台，可以对比GM3与传统模型（如KBM）的表现，并集成人机互动、脚本控制、实时轨迹追踪与日志分析。

Result: GM3模型在Stanford Drone Dataset的roundabout场景中，对骑行者、滑板者和推车等类别进行了实证验证，展示了其在多类微型交通工具上的适用性和有效性。

Conclusion: GM3模型能够统一、物理真实地刻画不同微型移动工具及其多种轮布局的动力学，在交通仿真和自动驾驶系统训练中具有广泛潜力和实际价值。

Abstract: Modeling the dynamics of micro-mobility vehicles (MMV) is becoming
increasingly important for training autonomous vehicle systems and building
urban traffic simulations. However, mainstream tools rely on variants of the
Kinematic Bicycle Model (KBM) or mode-specific physics that miss tire slip,
load transfer, and rider/vehicle lean. To our knowledge, no unified,
physics-based model captures these dynamics across the full range of common
MMVs and wheel layouts. We propose the "Generalized Micro-mobility Model"
(GM3), a tire-level formulation based on the tire brush representation that
supports arbitrary wheel configurations, including single/double track and
multi-wheel platforms. We introduce an interactive model-agnostic simulation
framework that decouples vehicle/layout specification from dynamics to compare
the GM3 with the KBM and other models, consisting of fixed step RK4
integration, human-in-the-loop and scripted control, real-time trajectory
traces and logging for analysis. We also empirically validate the GM3 on the
Stanford Drone Dataset's deathCircle (roundabout) scene for biker, skater, and
cart classes.

</details>


### [214] [DM1: MeanFlow with Dispersive Regularization for 1-Step Robotic Manipulation](https://arxiv.org/abs/2510.07865)
*Guowei Zou,Haitao Wang,Hejun Wu,Yukun Qian,Yuhang Wang,Weibing Li*

Main category: cs.RO

TL;DR: 本文提出了DM1（一种通过分散正则化来防止特征表示坍塌的新型流匹配一步动作生成方法），有效提升了机器人操作的效率和精度，比现有方法推理速度提升20-40倍，并在多个任务上提高了成功率。


<details>
  <summary>Details</summary>
Motivation: 当前机器人操作需要精准高效地生成多模态动作分布，流模型具有效率高的优势但存在特征表示坍塌，导致难以进行精细的操作任务。本文旨在解决流模型表示能力不足的问题。

Method: 文章提出DM1框架，将分散正则化整合进MeanFlow流模型，通过在多个中间层引入不同形式的分散正则化，鼓励训练批次内特征的多样性，无需新增网络模块或专门训练流程，提升动作分布表征能力。

Result: 在RoboMimic基准测试中，DM1推理速度达0.07秒，比扩散模型快20-40倍，同时操作任务的成功率提升10-20个百分点，“Lift”任务成功率高达99%。实际机器人验证表明DM1模型迁移能力强。

Conclusion: DM1首次实现通过表示正则化让流模型在机器人操作任务中表现优异，简单方案实现高效、鲁棒的机器人操作，对机器人学动作生成有重要意义。

Abstract: The ability to learn multi-modal action distributions is indispensable for
robotic manipulation policies to perform precise and robust control. Flow-based
generative models have recently emerged as a promising solution to learning
distributions of actions, offering one-step action generation and thus
achieving much higher sampling efficiency compared to diffusion-based methods.
However, existing flow-based policies suffer from representation collapse, the
inability to distinguish similar visual representations, leading to failures in
precise manipulation tasks. We propose DM1 (MeanFlow with Dispersive
Regularization for One-Step Robotic Manipulation), a novel flow matching
framework that integrates dispersive regularization into MeanFlow to prevent
collapse while maintaining one-step efficiency. DM1 employs multiple dispersive
regularization variants across different intermediate embedding layers,
encouraging diverse representations across training batches without introducing
additional network modules or specialized training procedures. Experiments on
RoboMimic benchmarks show that DM1 achieves 20-40 times faster inference (0.07s
vs. 2-3.5s) and improves success rates by 10-20 percentage points, with the
Lift task reaching 99% success over 85% of the baseline. Real-robot deployment
on a Franka Panda further validates that DM1 transfers effectively from
simulation to the physical world. To the best of our knowledge, this is the
first work to leverage representation regularization to enable flow-based
policies to achieve strong performance in robotic manipulation, establishing a
simple yet powerful approach for efficient and robust manipulation.

</details>


### [215] [USIM and U0: A Vision-Language-Action Dataset and Model for General Underwater Robots](https://arxiv.org/abs/2510.07869)
*Junwen Gu,Zhiheng wu,Pengxuan Si,Shuang Qiu,Yukai Feng,Luoyang Sun,Laien Luo,Lianyi Yu,Jian Wang,Zhengxing Wu*

Main category: cs.RO

TL;DR: 本文提出了USIM水下机器人多任务视觉-语言-行动（VLA）数据集和U0通用VLA模型，实现了多任务自主操作，并显著提升了复杂任务下的表现。


<details>
  <summary>Details</summary>
Motivation: 水下环境操作面临独特的挑战，例如复杂流体动力学、低可见度与通信受限。目前缺乏大规模高质量的水下机器人多任务数据集，阻碍了能执行多任务的智能水下机器人研发。

Method: 作者开发了USIM数据集，包含20种任务和9类场景下超56万帧数据，覆盖多项导航和操作任务，形成丰富多样的VLA多模态数据。基于此，提出U0模型，融合双目视觉与多传感器信息，并引入卷积-注意力感知模块，增强空间理解和操控能力。

Result: 该框架在多种任务上表现优异，整体成功率达80%；在复杂的移动操作任务中，相比基线方法将到目标的平均距离缩短21.2%。

Conclusion: USIM数据集和U0模型验证了VLA体系在水下机器人中的有效性，为后续可扩展数据集构建和提升任务自主性以及通用智能水下机器人的研发奠定了基础。

Abstract: Underwater environments present unique challenges for robotic operation,
including complex hydrodynamics, limited visibility, and constrained
communication. Although data-driven approaches have advanced embodied
intelligence in terrestrial robots and enabled task-specific autonomous
underwater robots, developing underwater intelligence capable of autonomously
performing multiple tasks remains highly challenging, as large-scale,
high-quality underwater datasets are still scarce. To address these
limitations, we introduce USIM, a simulation-based multi-task
Vision-Language-Action (VLA) dataset for underwater robots. USIM comprises over
561K frames from 1,852 trajectories, totaling approximately 15.6 hours of
BlueROV2 interactions across 20 tasks in 9 diverse scenarios, ranging from
visual navigation to mobile manipulation. Building upon this dataset, we
propose U0, a VLA model for general underwater robots, which integrates
binocular vision and other sensor modalities through multimodal fusion, and
further incorporates a convolution-attention-based perception focus enhancement
module (CAP) to improve spatial understanding and mobile manipulation. Across
tasks such as inspection, obstacle avoidance, scanning, and dynamic tracking,
the framework achieves a success rate of 80%, while in challenging mobile
manipulation tasks, it reduces the distance to the target by 21.2% compared
with baseline methods, demonstrating its effectiveness. USIM and U0 show that
VLA models can be effectively applied to underwater robotic applications,
providing a foundation for scalable dataset construction, improved task
autonomy, and the practical realization of intelligent general underwater
robots.

</details>


### [216] [Team Xiaomi EV-AD VLA: Learning to Navigate Socially Through Proactive Risk Perception -- Technical Report for IROS 2025 RoboSense Challenge Social Navigation Track](https://arxiv.org/abs/2510.07871)
*Erjia Xiao,Lingfeng Zhang,Yingbo Tang,Hao Cheng,Renjing Xu,Wenbo Ding,Lei Zhou,Long Chen,Hangjun Ye,Xiaoshuai Hao*

Main category: cs.RO

TL;DR: 本文介绍了团队在IROS 2025 RoboSense Challenge社会导航赛道中的技术方案，通过增强式主动风险感知模块在拥挤室内环境中实现高效且合规范的人群导航，并取得了竞赛第二名。


<details>
  <summary>Details</summary>
Motivation: 现有基于RGBD的室内机器人导航系统在动态人群中往往难以做到既安全高效又遵循社交规范，如保持合适距离、避免碰撞。赛事要求在无全局地图和特权信息的前提下，仅用自带传感器完成此任务，推动了对更智能的导航感知方案的需求。

Method: 在已有Falcon模型基础上，研发并集成了主动风险感知模块（Proactive Risk Perception Module），该模块能够学习预测周围行人的距离碰撞风险分数，使机器人具备更强的空间感知力和主动避障行为，从而优化其社会导航能力。

Result: 在Social-HM3D基准测试中新方法显著提升了机器人保持“个人空间”合规性的能力，实现了在动态拥挤人群环境中朝目标点导航时更少碰撞及社交规范的遵循，在 16 个参赛队伍中取得了第2名的成绩。

Conclusion: 通过为Falcon导航模型引入风险感知模块，可显著提升社会规范遵守与主动避障表现，为室内机器人在人类密集环境下安全高效导航提供了有价值的技术进展。

Abstract: In this report, we describe the technical details of our submission to the
IROS 2025 RoboSense Challenge Social Navigation Track. This track focuses on
developing RGBD-based perception and navigation systems that enable autonomous
agents to navigate safely, efficiently, and socially compliantly in dynamic
human-populated indoor environments. The challenge requires agents to operate
from an egocentric perspective using only onboard sensors including RGB-D
observations and odometry, without access to global maps or privileged
information, while maintaining social norm compliance such as safe distances
and collision avoidance. Building upon the Falcon model, we introduce a
Proactive Risk Perception Module to enhance social navigation performance. Our
approach augments Falcon with collision risk understanding that learns to
predict distance-based collision risk scores for surrounding humans, which
enables the agent to develop more robust spatial awareness and proactive
collision avoidance behaviors. The evaluation on the Social-HM3D benchmark
demonstrates that our method improves the agent's ability to maintain personal
space compliance while navigating toward goals in crowded indoor scenes with
dynamic human agents, achieving 2nd place among 16 participating teams in the
challenge.

</details>


### [217] [Towards Proprioception-Aware Embodied Planning for Dual-Arm Humanoid Robots](https://arxiv.org/abs/2510.07882)
*Boyu Li,Siyuan He,Hang Xu,Haoqi Yuan,Yu Zang,Liwei Hu,Junpeng Yue,Zhenxiong Jiang,Pengbo Hu,Börje F. Karlsson,Yehui Tang,Zongqing Lu*

Main category: cs.RO

TL;DR: 本文提出了DualTHOR双臂仿真平台，并基于此开发了提升机器人体现感知能力的Proprio-MLLM模型，实现复杂任务规划性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大模型虽然能用于机器人高层规划，但在双臂类人机器人上的长时任务表现受限，主要原因是缺乏相关仿真平台和模型的体现感知不足。

Method: 提出了新的DualTHOR仿真平台，支持对双臂类人机器人的任务评估和数据采集，并设计了融合本体感知信息的Proprio-MLLM结构，包括基于运动的位置嵌入和跨空间编码模块。

Result: 实验证明在DualTHOR环境下，Proprio-MLLM在任务规划上比现有多模态大模型平均性能提升了19.75%。

Conclusion: DualTHOR作为仿真平台和Proprio-MLLM作为有效模型推动了类人机器人体现智能的发展。

Abstract: In recent years, Multimodal Large Language Models (MLLMs) have demonstrated
the ability to serve as high-level planners, enabling robots to follow complex
human instructions. However, their effectiveness, especially in long-horizon
tasks involving dual-arm humanoid robots, remains limited. This limitation
arises from two main challenges: (i) the absence of simulation platforms that
systematically support task evaluation and data collection for humanoid robots,
and (ii) the insufficient embodiment awareness of current MLLMs, which hinders
reasoning about dual-arm selection logic and body positions during planning. To
address these issues, we present DualTHOR, a new dual-arm humanoid simulator,
with continuous transition and a contingency mechanism. Building on this
platform, we propose Proprio-MLLM, a model that enhances embodiment awareness
by incorporating proprioceptive information with motion-based position
embedding and a cross-spatial encoder. Experiments show that, while existing
MLLMs struggle in this environment, Proprio-MLLM achieves an average
improvement of 19.75% in planning performance. Our work provides both an
essential simulation platform and an effective model to advance embodied
intelligence in humanoid robotics. The code is available at
https://anonymous.4open.science/r/DualTHOR-5F3B.

</details>


### [218] [Executable Analytic Concepts as the Missing Link Between VLM Insight and Precise Manipulation](https://arxiv.org/abs/2510.07975)
*Mingyang Sun,Jiude Wei,Qichen He,Donglin Wang,Cewu Lu,Jianhua Sun*

Main category: cs.RO

TL;DR: 本文提出GRACE框架，实现从语言视觉理解到具体机器人操作的桥接，通过分析性可执行概念精确指导机械手操作，展示了在多场景下的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型（VLMs）虽擅长语义推理与任务规划，但与实际物理操作间存在显著鸿沟，阻碍机器人在开放环境下的精确泛化操作能力。

Method: GRACE框架结合结构化策略引导，将自然语言和视觉信息转化为可执行的分析性概念（EAC），该概念数理化地表达抓取、受力、几何约束和操作语义，从而生成可行的操作轨迹并执行。

Result: GRACE无需针对具体任务训练，便能在多类关节物体和不同场景（模拟与现实）中表现出强大的零样本泛化能力。

Conclusion: 通过语义与物理双重绑定，GRACE有效弥合了高层表达与底层操作控制的鸿沟，为机器人通用精密操作提供了统一、可解释的解决方案。

Abstract: Enabling robots to perform precise and generalized manipulation in
unstructured environments remains a fundamental challenge in embodied AI. While
Vision-Language Models (VLMs) have demonstrated remarkable capabilities in
semantic reasoning and task planning, a significant gap persists between their
high-level understanding and the precise physical execution required for
real-world manipulation. To bridge this "semantic-to-physical" gap, we
introduce GRACE, a novel framework that grounds VLM-based reasoning through
executable analytic concepts (EAC)-mathematically defined blueprints that
encode object affordances, geometric constraints, and semantics of
manipulation. Our approach integrates a structured policy scaffolding pipeline
that turn natural language instructions and visual information into an
instantiated EAC, from which we derive grasp poses, force directions and plan
physically feasible motion trajectory for robot execution. GRACE thus provides
a unified and interpretable interface between high-level instruction
understanding and low-level robot control, effectively enabling precise and
generalizable manipulation through semantic-physical grounding. Extensive
experiments demonstrate that GRACE achieves strong zero-shot generalization
across a variety of articulated objects in both simulated and real-world
environments, without requiring task-specific training.

</details>


### [219] [Orientation Learning and Adaptation towards Simultaneous Incorporation of Multiple Local Constraints](https://arxiv.org/abs/2510.07986)
*Gaofeng Li,Peisen Xu,Ruize Wang,Qi Ye,Jiming Chen,Dezhen Song,Yanlong Huang*

Main category: cs.RO

TL;DR: 本论文提出了一种基于角轴空间（Angle-Axis Space）的方向表示方法，通过加权平均机制能够在SO(3)流形上同时融合多个局部约束，实现更自然、平滑的方向学习与轨迹生成。


<details>
  <summary>Details</summary>
Motivation: SO(3)作为旋转群本质上是黎曼流形，其非欧几何性质导致在方向学习中很难同时施加多个局部约束，并影响轨迹的平滑性和优化效果。现有方法难以克服因空间失真带来的困扰。

Method: 作者提出了一种基于角轴表示的加权平均机制，首先在不同基点下针对不同局部约束分别生成多条轨迹，然后通过加权平均机制将多条轨迹融合为更平滑的最终轨迹，实现同时施加和融合多个局部约束。

Result: 仿真和实际实验表明，该方法能够有效适应任意目标路径、控制角加速度，并能同时融合多个局部约束，在实现目标点适应的同时，还能减少加速度开销等。

Conclusion: 本文的新方法解决了SO(3)空间失真对方向约束融合的难题，使现有欧式学习算法能重新适用于非欧空间，对于实现复杂运动规划和优化任务具有更高效、灵活的优势。

Abstract: Orientation learning plays a pivotal role in many tasks. However, the
rotation group SO(3) is a Riemannian manifold. As a result, the distortion
caused by non-Euclidean geometric nature introduces difficulties to the
incorporation of local constraints, especially for the simultaneous
incorporation of multiple local constraints. To address this issue, we propose
the Angle-Axis Space-based orientation representation method to solve several
orientation learning problems, including orientation adaptation and
minimization of angular acceleration. Specifically, we propose a weighted
average mechanism in SO(3) based on the angle-axis representation method. Our
main idea is to generate multiple trajectories by considering different local
constraints at different basepoints. Then these multiple trajectories are fused
to generate a smooth trajectory by our proposed weighted average mechanism,
achieving the goal to incorporate multiple local constraints simultaneously.
Compared with existing solution, ours can address the distortion issue and make
the off-theshelf Euclidean learning algorithm be re-applicable in non-Euclidean
space. Simulation and Experimental evaluations validate that our solution can
not only adapt orientations towards arbitrary desired via-points and cope with
angular acceleration constraints, but also incorporate multiple local
constraints simultaneously to achieve extra benefits, e.g., achieving smaller
acceleration costs.

</details>


### [220] [FastUMI-100K: Advancing Data-driven Robotic Manipulation with a Large-scale UMI-style Dataset](https://arxiv.org/abs/2510.08022)
*Kehui Liu,Zhongjie Jia,Yang Li,Zhaxizhuoma,Pengan Chen,Song Liu,Xin Liu,Pingrui Zhang,Haoming Song,Xinyi Ye,Nieqing Cao,Zhigang Wang,Jia Zeng,Dong Wang,Yan Ding,Bin Zhao,Xuelong Li*

Main category: cs.RO

TL;DR: 该论文提出并发布了一个名为FastUMI-100K的大规模多模态机器人操作演示数据集，旨在提升真实世界机器人操作学习的规模性、灵活性和适用性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作数据集过于依赖人工示范，导致规模有限、轨迹不够平滑、难以适应不同机器人体型和真实场景，无法满足复杂任务需求。

Method: 作者设计了FastUMI，一个具有模块化硬件、轻量追踪系统的新型机器人，通过该系统在多个家庭场景下收集了10万条以上的多模态示范轨迹，涵盖54种任务和数百种物体，数据内容包括末端执行器状态、手腕视角鱼眼图像及文字描述。

Result: 实验结果表明，FastUMI-100K数据集在多种基线算法上实现了较高的策略成功率，表现出强大的鲁棒性、适应性与真实场景应用潜力。

Conclusion: FastUMI-100K突破了传统数据集的局限，为复杂机器人操作任务的研究和发展提供了更加高效和实用的数据基础，未来将公开其源码及数据集资源。

Abstract: Data-driven robotic manipulation learning depends on large-scale,
high-quality expert demonstration datasets. However, existing datasets, which
primarily rely on human teleoperated robot collection, are limited in terms of
scalability, trajectory smoothness, and applicability across different robotic
embodiments in real-world environments. In this paper, we present FastUMI-100K,
a large-scale UMI-style multimodal demonstration dataset, designed to overcome
these limitations and meet the growing complexity of real-world manipulation
tasks. Collected by FastUMI, a novel robotic system featuring a modular,
hardware-decoupled mechanical design and an integrated lightweight tracking
system, FastUMI-100K offers a more scalable, flexible, and adaptable solution
to fulfill the diverse requirements of real-world robot demonstration data.
Specifically, FastUMI-100K contains over 100K+ demonstration trajectories
collected across representative household environments, covering 54 tasks and
hundreds of object types. Our dataset integrates multimodal streams, including
end-effector states, multi-view wrist-mounted fisheye images and textual
annotations. Each trajectory has a length ranging from 120 to 500 frames.
Experimental results demonstrate that FastUMI-100K enables high policy success
rates across various baseline algorithms, confirming its robustness,
adaptability, and real-world applicability for solving complex, dynamic
manipulation challenges. The source code and dataset will be released in this
link https://github.com/MrKeee/FastUMI-100K.

</details>


### [221] [Towards Reliable LLM-based Robot Planning via Combined Uncertainty Estimation](https://arxiv.org/abs/2510.08044)
*Shiyuan Yin,Chenjia Bai,Zihao Zhang,Junwei Jin,Xinxin Zhang,Chi Zhang,Xuelong Li*

Main category: cs.RO

TL;DR: 本论文提出CURE方法，将大模型中的不确定性细分并分别估计，从而提高机器人规划的可靠性。实验验证了这种方法能更准确地反映实际执行结果。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型常用于机器人任务规划，但它们容易出现幻觉和过度自信，导致机器人行为不安全。以往利用不确定性估计改进大模型规划的可靠性，但未区分知识性（epistemic）和内在（intrinsic）不确定性，限制了效果。

Method: 提出CURE框架，对总体不确定性进行细化，包括将知识性不确定性进一步分解为任务清晰度和任务熟悉度。分别采用随机网络蒸馏和多层感知器回归头，利用大模型特征对各类不确定性独立估计。

Result: 在厨房操作和桌面重排两个实验场景下，CURE方法得到的不确定性评估与实际执行结果更加匹配，优于现有的不确定性估计方法。

Conclusion: 细粒度的不确定性建模（区分知识性和内在性）能提升基于大模型的机器人规划的可靠性，为不确定性的有效度量和应用带来新范式。

Abstract: Large language models (LLMs) demonstrate advanced reasoning abilities,
enabling robots to understand natural language instructions and generate
high-level plans with appropriate grounding. However, LLM hallucinations
present a significant challenge, often leading to overconfident yet potentially
misaligned or unsafe plans. While researchers have explored uncertainty
estimation to improve the reliability of LLM-based planning, existing studies
have not sufficiently differentiated between epistemic and intrinsic
uncertainty, limiting the effectiveness of uncertainty estimation. In this
paper, we present Combined Uncertainty estimation for Reliable Embodied
planning (CURE), which decomposes the uncertainty into epistemic and intrinsic
uncertainty, each estimated separately. Furthermore, epistemic uncertainty is
subdivided into task clarity and task familiarity for more accurate evaluation.
The overall uncertainty assessments are obtained using random network
distillation and multi-layer perceptron regression heads driven by LLM
features. We validated our approach in two distinct experimental settings:
kitchen manipulation and tabletop rearrangement experiments. The results show
that, compared to existing methods, our approach yields uncertainty estimates
that are more closely aligned with the actual execution outcomes.

</details>


### [222] [Beyond hospital reach: Autonomous lightweight ultrasound robot for liver sonography](https://arxiv.org/abs/2510.08106)
*Zihan Li,Yixiao Xu,Lei Zhang,Taiyu Han,Xinshan Yang,Yingni Wang,Mingxuan Liu,Shenghai Xin,Linxun Liu,Hongen Liao,Guochen Ning*

Main category: cs.RO

TL;DR: 本文提出了一种自主轻量级超声机器人，能够自动采集标准肝脏超声图像并检测病变，在多种复杂环境中表现出专家水平性能，尤其适用于医疗资源有限地区。


<details>
  <summary>Details</summary>
Motivation: 全球肝脏疾病负担严重，而肝脏超声检查对操作者技术要求高，专家稀缺，尤其在资源有限的地区。因此亟需降低肝脏超声检查的难度并增加可及性。

Method: 研究团队开发了一个集成多模态感知与记忆注意力的AI智能体，并将其与六自由度、重588克的线缆驱动超声机器人结合。该系统腹部佩戴，可增强抗运动干扰能力，实现自主定位并采集标准肝脏超声切面。

Result: 机器人可自主获取高质量的标准肝脏超声图像并成功检测到病变，包括应用于两例来自高原医疗资源有限城市的患者。此外，对快速运动个体及野外环境都表现良好。

Conclusion: 这是首次在多种挑战场景下实现自主化超声扫描，有望为医疗资源匮乏地区带来专家级诊断能力，提升全球肝脏疾病诊治水平。

Abstract: Liver disease is a major global health burden. While ultrasound is the
first-line diagnostic tool, liver sonography requires locating multiple
non-continuous planes from positions where target structures are often not
visible, for biometric assessment and lesion detection, requiring significant
expertise. However, expert sonographers are severely scarce in resource-limited
regions. Here, we develop an autonomous lightweight ultrasound robot comprising
an AI agent that integrates multi-modal perception with memory attention for
localization of unseen target structures, and a 588-gram 6-degrees-of-freedom
cable-driven robot. By mounting on the abdomen, the system enhances robustness
against motion. Our robot can autonomously acquire expert-level standard liver
ultrasound planes and detect pathology in patients, including two from Xining,
a 2261-meter-altitude city with limited medical resources. Our system performs
effectively on rapid-motion individuals and in wilderness environments. This
work represents the first demonstration of autonomous sonography across
multiple challenging scenarios, potentially transforming access to expert-level
diagnostics in underserved regions.

</details>


### [223] [Accurate and Noise-Tolerant Extraction of Routine Logs in Robotic Process Automation (Extended Version)](https://arxiv.org/abs/2510.08118)
*Massimiliano de Leoni,Faizan Ahmed Khan,Simone Agostinelli*

Main category: cs.RO

TL;DR: 本文提出了一种基于聚类的方法，从用户界面日志中提取更准确的例行操作日志，即使在包含噪声（不一致性）情况下也能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前机器人流程挖掘领域大多只关注于动作集提取，而不能有效发现用于自动化的高质量例行操作模型，且缺乏对包含噪声（人为差异与错误）的实际场景的验证。

Method: 采用了基于聚类的技术，从用户界面日志中识别和提取例行操作日志，并在九个不同噪声水平的数据集上与现有技术进行对比实验。

Result: 实验结果表明，该方法在各种噪声环境下都能比现有主流方法提取出更准确的例行操作日志。

Conclusion: 提出的聚类方法适用于带噪声的实际场景，在提取高质量例行日志并辅助模型发现方面优于现有技术，可提升后续流程自动化效果。

Abstract: Robotic Process Mining focuses on the identification of the routine types
performed by human resources through a User Interface. The ultimate goal is to
discover routine-type models to enable robotic process automation. The
discovery of routine-type models requires the provision of a routine log.
Unfortunately, the vast majority of existing works do not directly focus on
enabling the model discovery, limiting themselves to extracting the set of
actions that are part of the routines. They were also not evaluated in
scenarios characterized by inconsistent routine execution, hereafter referred
to as noise, which reflects natural variability and occasional errors in human
performance. This paper presents a clustering-based technique that aims to
extract routine logs. Experiments were conducted on nine UI logs from the
literature with different levels of injected noise. Our technique was compared
with existing techniques, most of which are not meant to discover routine logs
but were adapted for the purpose. The results were evaluated through standard
state-of-the-art metrics, showing that we can extract more accurate routine
logs than what the state of the art could, especially in the presence of noise.

</details>


### [224] [NavSpace: How Navigation Agents Follow Spatial Intelligence Instructions](https://arxiv.org/abs/2510.08173)
*Haolin Yang,Yuxing Long,Zhuoyuan Yu,Zihan Yang,Minghan Wang,Jiapeng Xu,Yihan Wang,Ziyan Yu,Wenzhe Cai,Lei Kang,Hao Dong*

Main category: cs.RO

TL;DR: 本文提出了NavSpace基准，用于系统性评估导航智能体的空间感知与推理能力，并提出了新的空间智能导航模型SNav，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的导航基准主要关注语义理解，忽视了对导航智能体空间感知和推理能力的系统性评估，因此有必要建立新的评测体系来专门考察空间智能。

Method: 作者提出NavSpace基准，包括6大任务类别和1228组轨迹-指令对，用于检验导航智能体的空间智能。评测了22种主流导航模型与多模态大型语言模型，并提出了新的空间智能导航模型SNav。

Result: 在NavSpace基准上，SNav导航模型相较于其他导航智能体和多模态大模型表现更优，同时在真实机器人测试中也取得了更好成绩。

Conclusion: NavSpace为空间智能导航能力的评估提供了新方向，SNav设立了强有力的基线，有助于后续研究推动导航智能体的空间认知与推理发展。

Abstract: Instruction-following navigation is a key step toward embodied intelligence.
Prior benchmarks mainly focus on semantic understanding but overlook
systematically evaluating navigation agents' spatial perception and reasoning
capabilities. In this work, we introduce the NavSpace benchmark, which contains
six task categories and 1,228 trajectory-instruction pairs designed to probe
the spatial intelligence of navigation agents. On this benchmark, we
comprehensively evaluate 22 navigation agents, including state-of-the-art
navigation models and multimodal large language models. The evaluation results
lift the veil on spatial intelligence in embodied navigation. Furthermore, we
propose SNav, a new spatially intelligent navigation model. SNav outperforms
existing navigation agents on NavSpace and real robot tests, establishing a
strong baseline for future work.

</details>


### [225] [Evaluation of a Robust Control System in Real-World Cable-Driven Parallel Robots](https://arxiv.org/abs/2510.08270)
*Damir Nurtdinov,Aliaksei Korshuk,Alexei Kornaev,Alexander Maloletov*

Main category: cs.RO

TL;DR: 本文比较了经典PID控制器与现代强化学习算法（包括DDPG、PPO和TRPO）在实际缆索驱动并联机器人（CDPR）控制中的表现，发现TRPO在轨迹跟踪准确性和鲁棒性方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 缆索驱动并联机器人（CDPRs）由于欠约束性和实时性挑战，对控制方法提出了更高的鲁棒性和性能需求。传统PID控制难以应对复杂干扰和有限的时间离散，亟需探索适应性更强的新型控制方法。

Method: 作者设计了对比实验，将经典PID控制器与三种主流强化学习控制算法（DDPG、PPO、TRPO）应用于实际CDPR系统，对比不同方法在多种轨迹跟踪以及控制更新间隔扩大的情况下的表现。

Result: 实验结果表明，TRPO算法在所有测试轨迹下均获得最低的均方根误差（RMS），并且在控制更新间隔较长时仍能保持稳定和鲁棒，明显优于其他方法。

Conclusion: TRPO由于其卓越的探索与利用平衡能力，在噪声较大、反馈频率受限和计算资源有限的现实场景下表现突出，有望成为复杂机器人控制任务中的稳健解决方案。这一结论为未来CDPR控制中的传感器融合及混合控制策略提供了参考。

Abstract: This study evaluates the performance of classical and modern control methods
for real-world Cable-Driven Parallel Robots (CDPRs), focusing on
underconstrained systems with limited time discretization. A comparative
analysis is conducted between classical PID controllers and modern
reinforcement learning algorithms, including Deep Deterministic Policy Gradient
(DDPG), Proximal Policy Optimization (PPO), and Trust Region Policy
Optimization (TRPO). The results demonstrate that TRPO outperforms other
methods, achieving the lowest root mean square (RMS) errors across various
trajectories and exhibiting robustness to larger time intervals between control
updates. TRPO's ability to balance exploration and exploitation enables stable
control in noisy, real-world environments, reducing reliance on high-frequency
sensor feedback and computational demands. These findings highlight TRPO's
potential as a robust solution for complex robotic control tasks, with
implications for dynamic environments and future applications in sensor fusion
or hybrid control strategies.

</details>


### [226] [Airy: Reading Robot Intent through Height and Sky](https://arxiv.org/abs/2510.08381)
*Baoyang Chen,Xian Xu,Huamin Qu*

Main category: cs.RO

TL;DR: 本文介绍了一个利用机器人臂进行床单抖动比赛的互动装置艺术，通过将机器人的策略和行为可视化，使观众能直观理解机器人内部过程与意图。


<details>
  <summary>Details</summary>
Motivation: 随着工业机器人进入人类共享空间，其决策过程的黑箱性威胁到安全、信任与公众监督。作者希望解决如何让多智能体AI的行为变得直观易懂的问题。

Method: 作者设计了一个艺术装置Airy，让两个通过强化学习训练的机器人臂竞争谁能将床单抖得更高。通过三项设计原则：竞争作为清晰指标（谁抖得高）、具身熟悉性（观众熟悉布料动作）、感应到感官映射（通过环境投影可见机器人协作或对抗态度），让观众可以从感官角度感知机器意图。

Result: 在五场国际展览中的观察显示，观众能实时识别出机器人的策略、冲突与协作，并能产生与系统内部状态相呼应的情感反应。

Conclusion: 该项目显示了感官隐喻如何将AI的“黑箱”决策过程转变为面向公众的可理解界面。

Abstract: As industrial robots move into shared human spaces, their opaque decision
making threatens safety, trust, and public oversight. This artwork, Airy, asks
whether complex multi agent AI can become intuitively understandable by staging
a competition between two reinforcement trained robot arms that snap a bedsheet
skyward. Building on three design principles, competition as a clear metric
(who lifts higher), embodied familiarity (audiences recognize fabric snapping),
and sensor to sense mapping (robot cooperation or rivalry shown through forest
and weather projections), the installation gives viewers a visceral way to read
machine intent. Observations from five international exhibitions indicate that
audiences consistently read the robots' strategies, conflict, and cooperation
in real time, with emotional reactions that mirror the system's internal state.
The project shows how sensory metaphors can turn a black box into a public
interface.

</details>


### [227] [Reliability of Single-Level Equality-Constrained Inverse Optimal Control](https://arxiv.org/abs/2510.08406)
*Filip Bečanović,Kosta Jovanović,Vincent Bonnet*

Main category: cs.RO

TL;DR: 本文提出了一种更快速且稳健的逆最优控制（IOC）方法，能在应对高噪声的同时大幅减少计算时间。


<details>
  <summary>Details</summary>
Motivation: 传统逆最优控制方法依赖慢速的双层优化过程或者对噪声敏感的快速方法，难以在保证计算效率的同时兼顾鲁棒性。作者希望提出一种既快速又对噪声鲁棒的方法，提升IOC在如人体运动等问题上的实用性。

Method: 文章假设人类运动的最优控制模型受等式约束影响，创新性地将传统的双层优化方法单层化，转化为单次求解问题，并保留了原有方法的等价性。

Result: 通过仿真实验证明，该方法在输入高噪声情况下依然鲁棒，并在类似平面到达任务中，将计算时间缩短了15倍。

Conclusion: 所提出的方法可保持结果准确性的同时大幅提高执行效率，并极大提升了对噪声的适应性，优于传统IOC双层优化方法。

Abstract: Inverse optimal control (IOC) allows the retrieval of optimal cost function
weights, or behavioral parameters, from human motion. The literature on IOC
uses methods that are either based on a slow bilevel process or a fast but
noise-sensitive minimization of optimality condition violation. Assuming
equality-constrained optimal control models of human motion, this article
presents a faster but robust approach to solving IOC using a single-level
reformulation of the bilevel method and yields equivalent results. Through
numerical experiments in simulation, we analyze the robustness to noise of the
proposed single-level reformulation to the bilevel IOC formulation with a
human-like planar reaching task that is used across recent studies. The
approach shows resilience to very large levels of noise and reduces the
computation time of the IOC on this task by a factor of 15 when compared to a
classical bilevel implementation.

</details>


### [228] [Validation of collision-free spheres of Stewart-Gough platforms for constant orientations using the Application Programming Interface of a CAD software](https://arxiv.org/abs/2510.08408)
*Bibekananda Patra,Rajeevlochana G. Chittawadigi,Sandipan Bandyopadhyay*

Main category: cs.RO

TL;DR: 本文提出了一种基于CAD软件API的自动化方法，用于验证6-6斯图尔特－高夫平台机械臂在给定位姿下最大无碰撞球（CFS）的尺寸。通过自动控制动平台位置并检测各支腿是否相互碰撞，实现对CFS的安全性校验。此方法可验证预先计算的CFS，也适用于其他空间并联机械臂的无碰撞区域评估。


<details>
  <summary>Details</summary>
Motivation: 空间并联机械臂在复杂空间运动时，支腿之间可能发生碰撞，影响其安全与可用空间。因此，研究最大无碰撞运动范围（CFS）的验证方法，有助于提升机械臂的实用性和安全性。

Method: 利用CAD软件API，自动化地控制动平台在一系列采样点上的位置变化，对每一姿态下所有支腿对进行碰撞检测，确保CFS内无碰撞发生，从而验证CFS的安全性。

Result: 所提出的方法不仅能自动校验已知的CFS，还可以应用于任何空间并联机械臂的无碰撞空间估算。

Conclusion: 该方法提升了CFS验证的效率和通用性，对空间并联机械臂的安全性分析具有广泛实用价值。

Abstract: This paper presents a method of validation of the size of the largest
collision-free sphere (CFS) of a 6-6 Stewart-Gough platform manipulator (SGPM)
for a given orientation of its moving platform (MP) using the Application
Programming Interface (API) of a CAD software. The position of the MP is
updated via the API in an automated manner over a set of samples within a shell
enclosing the surface of the CFS. For each pose of the manipulator, each pair
of legs is investigated for mutual collisions. The CFS is considered safe or
validated iff none of the points falling inside the CFS lead to a collision
between any pair of legs. This approach can not only validate the safety of a
precomputed CFS, but also estimate the same for any spatial parallel
manipulator.

</details>


### [229] [Don't Run with Scissors: Pruning Breaks VLA Models but They Can Be Recovered](https://arxiv.org/abs/2510.08464)
*Jason Jabbour,Dong-Ki Kim,Max Smith,Jay Patrikar,Radhika Ghosal,Youhui Wang,Ali Agha,Vijay Janapa Reddi,Shayegan Omidshafiei*

Main category: cs.RO

TL;DR: 本文提出了一种名为GLUESTICK的后剪枝恢复方法，可恢复视觉-语言-行动（VLA）模型在剪枝后丧失的性能，并仍保留剪枝带来的效率提升。该方法仅需一次性在参数空间插值，无需额外训练，在不同VLA任务和模型上都表现出良好效果。


<details>
  <summary>Details</summary>
Motivation: 虽然剪枝技术在大语言模型（LLM）中广泛用于模型压缩和提升推理效率，但在机器人领域，尤其是VLA模型上应用较少。现有方法对VLA模型剪枝会显著降低性能甚至增加安全隐患，因此需要一种新方法在不显著牺牲性能的前提下实现模型压缩。

Method: GLUESTICK方法在剪枝完成后，于权重空间中将原始密集模型与稀疏（剪枝后）模型进行一次性插值，生成修正项。在推理阶段，剪枝后的每一层会利用该修正项进行功能恢复，无需额外训练，不依赖特定剪枝算法，只需调整一个超参数即可在效率与准确度间权衡。

Result: GLUESTICK在多种VLA架构和任务（如操纵与导航）上实验表明，能在大幅削减内存占用的同时，显著恢复模型性能，提高成功率并降低安全违规次数。

Conclusion: GLUESTICK为VLA模型剪枝带来了新的解决方案，在不增加训练负担和算法依赖的情况下，大幅提升了剪枝模型在机器人任务上的实用性和安全性，为资源受限硬件上的机器人部署提供了可行途径。

Abstract: Vision-Language-Action (VLA) models have advanced robotic capabilities but
remain challenging to deploy on resource-limited hardware. Pruning has enabled
efficient compression of large language models (LLMs), yet it is largely
understudied in robotics. Surprisingly, we observe that pruning VLA models
leads to drastic degradation and increased safety violations. We introduce
GLUESTICK, a post-pruning recovery method that restores much of the original
model's functionality while retaining sparsity benefits. Our method performs a
one-time interpolation between the dense and pruned models in weight-space to
compute a corrective term. This correction is used during inference by each
pruned layer to recover lost capabilities with minimal overhead. GLUESTICK
requires no additional training, is agnostic to the pruning algorithm, and
introduces a single hyperparameter that controls the tradeoff between
efficiency and accuracy. Across diverse VLA architectures and tasks in
manipulation and navigation, GLUESTICK achieves competitive memory efficiency
while substantially recovering success rates and reducing safety violations.
Additional material can be found at: https://gluestick-vla.github.io/.

</details>


### [230] [DexMan: Learning Bimanual Dexterous Manipulation from Human and Generated Videos](https://arxiv.org/abs/2510.08475)
*Jhen Hsieh,Kuan-Hsun Tu,Kuo-Han Hung,Tsung-Wei Ke*

Main category: cs.RO

TL;DR: DexMan是一个自动化框架，可以将人类视觉演示的视频直接转化为拟人双手灵巧操作技能，无需额外传感器和标注，提升了仿人机器人复杂操作的学习效果。


<details>
  <summary>Details</summary>
Motivation: 现有灵巧操作方法需要繁琐的数据采集、标注或仅在简化场景下工作，无法充分利用现实世界中的视频资源，难以让仿人机器人高效学习复杂双手操作技能。

Method: DexMan直接处理第三人称人类操作物体的视频，通过估算手与物体的姿态，结合创新的接触奖励设计，利用强化学习训练仿人机器人掌握真实场景下的双手操作技能，并可兼容现实和合成视频数据。

Result: DexMan在TACO基准的物体姿态估计上取得了业界最佳成绩，在ADD-S和VSD指标上分别提升0.08和0.12；在OakInk-v2操控任务中，操作成功率比现有方法高19%。

Conclusion: DexMan无需相机标定、深度传感器和运动捕捉等昂贵手段，就能自动从视频获取大规模多样化数据，高效提升仿人机器人灵巧操作能力，为通用操作技能的学习奠定基础。

Abstract: We present DexMan, an automated framework that converts human visual
demonstrations into bimanual dexterous manipulation skills for humanoid robots
in simulation. Operating directly on third-person videos of humans manipulating
rigid objects, DexMan eliminates the need for camera calibration, depth
sensors, scanned 3D object assets, or ground-truth hand and object motion
annotations. Unlike prior approaches that consider only simplified floating
hands, it directly controls a humanoid robot and leverages novel contact-based
rewards to improve policy learning from noisy hand-object poses estimated from
in-the-wild videos.
  DexMan achieves state-of-the-art performance in object pose estimation on the
TACO benchmark, with absolute gains of 0.08 and 0.12 in ADD-S and VSD.
Meanwhile, its reinforcement learning policy surpasses previous methods by 19%
in success rate on OakInk-v2. Furthermore, DexMan can generate skills from both
real and synthetic videos, without the need for manual data collection and
costly motion capture, and enabling the creation of large-scale, diverse
datasets for training generalist dexterous manipulation.

</details>


### [231] [R2RGEN: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation](https://arxiv.org/abs/2510.08547)
*Xiuwei Xu,Angyuan Ma,Hankun Li,Bingyao Yu,Zheng Zhu,Jie Zhou,Jiwen Lu*

Main category: cs.RO

TL;DR: 本论文提出R2RGen框架，通过对点云观测-行动对进行增强，实现在实际场景下高效生成空间多样性的机器人操作演示数据，从而提升策略泛化能力。


<details>
  <summary>Details</summary>
Motivation: 通用的机器人操作需要策略能在不同空间配置下鲁棒工作。目前，多数模仿学习方法需大量人工演示，数据生成方法虽有突破但存在仿真到现实（sim-to-real）差距，并且多局限于固定基座或视角，因此需要一种简便且高效的现实数据增强方法来提升数据多样性。

Method: 提出R2RGen框架，直接在真实点云观测-行动数据上进行3D数据增强。其核心技术包括：细粒度注解机制对场景与轨迹进行精准解析；组内增强策略应对多物体及多任务约束；摄像头感知处理机制确保生成数据与真实3D传感器分布一致，无需传统仿真和渲染。

Result: 实验证明，R2RGen可以显著提升数据利用效率，在大规模实验中表现出优异的泛化性能，并在移动操作等实际应用场景中展示了良好的可扩展性。

Conclusion: R2RGen为机器人操作的数据生成与增强提供了高效、可插拔的现实方案，突破了现有方法在场景、基座及视角等方面的限制，有望推动机器人在复杂现实环境中的泛化和落地应用。

Abstract: Towards the aim of generalized robotic manipulation, spatial generalization
is the most fundamental capability that requires the policy to work robustly
under different spatial distribution of objects, environment and agent itself.
To achieve this, substantial human demonstrations need to be collected to cover
different spatial configurations for training a generalized visuomotor policy
via imitation learning. Prior works explore a promising direction that
leverages data generation to acquire abundant spatially diverse data from
minimal source demonstrations. However, most approaches face significant
sim-to-real gap and are often limited to constrained settings, such as
fixed-base scenarios and predefined camera viewpoints. In this paper, we
propose a real-to-real 3D data generation framework (R2RGen) that directly
augments the pointcloud observation-action pairs to generate real-world data.
R2RGen is simulator- and rendering-free, thus being efficient and
plug-and-play. Specifically, given a single source demonstration, we introduce
an annotation mechanism for fine-grained parsing of scene and trajectory. A
group-wise augmentation strategy is proposed to handle complex multi-object
compositions and diverse task constraints. We further present camera-aware
processing to align the distribution of generated data with real-world 3D
sensor. Empirically, R2RGen substantially enhances data efficiency on extensive
experiments and demonstrates strong potential for scaling and application on
mobile manipulation.

</details>


### [232] [DexNDM: Closing the Reality Gap for Dexterous In-Hand Rotation via Joint-Wise Neural Dynamics Model](https://arxiv.org/abs/2510.08556)
*Xueyi Liu,He Wang,Li Yi*

Main category: cs.RO

TL;DR: 本文提出了一种新颖方法，使在仿真中训练的单一操控策略能够泛化到真实世界中对于各种复杂物体的灵活手内旋转。方法通过联合动力学建模和自动化数据收集，有效跨越“现实鸿沟”。实验结果表明该方法在复杂形状及高纵横比物体上表现出色，且适应多种手腕姿态与旋转轴。


<details>
  <summary>Details</summary>
Motivation: 当前灵巧手操控在仿真训练到现实迁移时难以泛化，因真实世界中复杂的接触动力学导致“现实鸿沟”，现有工作多限制于简单场景。这限制了灵巧手机器人的广泛应用。本文旨在解决泛化问题，实现通用、鲁棒的真实世界手内物体旋转。

Method: 核心方法为关节级动力学建模：通过分解动力学、低维特征压缩和关节独立动态演化，使用少量现实数据高效拟合真实世界动力学，并自适应调整仿真策略；同时采用全自动化的数据收集方案，极大减少人工干预并获得多样化交互数据。

Result: 提出的管线方法可对高复杂度物体（如动物形状）、高纵横比（最高5.33）、小尺寸物体实现稳健手内旋转，且支持多样手腕姿态和旋转方向。真实世界评测结果优于现有方法，并在远程操作复杂任务时同样表现优异。

Conclusion: 本研究首次实现了基于仿真策略的单一灵巧手旋转策略在广泛且复杂真实物体上的泛化，显著缩小了仿真到现实的差距，对提升机器人灵巧操作能力具有重要意义。

Abstract: Achieving generalized in-hand object rotation remains a significant challenge
in robotics, largely due to the difficulty of transferring policies from
simulation to the real world. The complex, contact-rich dynamics of dexterous
manipulation create a "reality gap" that has limited prior work to constrained
scenarios involving simple geometries, limited object sizes and aspect ratios,
constrained wrist poses, or customized hands. We address this sim-to-real
challenge with a novel framework that enables a single policy, trained in
simulation, to generalize to a wide variety of objects and conditions in the
real world. The core of our method is a joint-wise dynamics model that learns
to bridge the reality gap by effectively fitting limited amount of real-world
collected data and then adapting the sim policy's actions accordingly. The
model is highly data-efficient and generalizable across different whole-hand
interaction distributions by factorizing dynamics across joints, compressing
system-wide influences into low-dimensional variables, and learning each
joint's evolution from its own dynamic profile, implicitly capturing these net
effects. We pair this with a fully autonomous data collection strategy that
gathers diverse, real-world interaction data with minimal human intervention.
Our complete pipeline demonstrates unprecedented generality: a single policy
successfully rotates challenging objects with complex shapes (e.g., animals),
high aspect ratios (up to 5.33), and small sizes, all while handling diverse
wrist orientations and rotation axes. Comprehensive real-world evaluations and
a teleoperation application for complex tasks validate the effectiveness and
robustness of our approach. Website: https://meowuu7.github.io/DexNDM/

</details>


### [233] [NovaFlow: Zero-Shot Manipulation via Actionable Flow from Generated Videos](https://arxiv.org/abs/2510.08568)
*Hongyu Li,Lingfeng Sun,Yafei Hu,Duy Ta,Jennifer Barry,George Konidaris,Jiahui Fu*

Main category: cs.RO

TL;DR: NovaFlow是一个可以让机器人无需演示和微调，零样本执行新操作任务的自主操作框架。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作方法通常依赖于与特定任务分布或特定平台相匹配的数据与微调，导致在不同机器人平台之间迁移能力有限。作者希望解决机器人能够跨平台、跨任务无演示自主操作的难题，实现高度泛化和自主的零样本操作。

Method: NovaFlow框架首先利用视频生成模型将自然语言任务描述转化为视频，然后通过现成的感知模块将该视频“蒸馏”为3D对象流。针对刚性物体，计算相对位姿并利用抓取建议和轨迹优化生成机器人动作。针对可变形物体，则运用基于粒子的动力学模型，以流作为跟踪目标执行模型规划。整个流程将任务理解与低层次控制解耦，能够适应不同的机器人平台。

Result: 在Frank桌面机械臂和Spot四足移动机器人上，分别测试了刚性、关节型与可变形物体操作任务，均实现了无需演示和平台特定训练的有效零样本执行。

Conclusion: NovaFlow验证了通过视频合成和对象流建模，可以实现机器人跨平台、跨任务的泛化操作方法，为自主机器人操作提供了新的思路和强有力的支持。

Abstract: Enabling robots to execute novel manipulation tasks zero-shot is a central
goal in robotics. Most existing methods assume in-distribution tasks or rely on
fine-tuning with embodiment-matched data, limiting transfer across platforms.
We present NovaFlow, an autonomous manipulation framework that converts a task
description into an actionable plan for a target robot without any
demonstrations. Given a task description, NovaFlow synthesizes a video using a
video generation model and distills it into 3D actionable object flow using
off-the-shelf perception modules. From the object flow, it computes relative
poses for rigid objects and realizes them as robot actions via grasp proposals
and trajectory optimization. For deformable objects, this flow serves as a
tracking objective for model-based planning with a particle-based dynamics
model. By decoupling task understanding from low-level control, NovaFlow
naturally transfers across embodiments. We validate on rigid, articulated, and
deformable object manipulation tasks using a table-top Franka arm and a Spot
quadrupedal mobile robot, and achieve effective zero-shot execution without
demonstrations or embodiment-specific training. Project website:
https://novaflow.lhy.xyz/.

</details>


### [234] [Scalable Offline Metrics for Autonomous Driving](https://arxiv.org/abs/2510.08571)
*Animikh Aich,Adwait Kulkarni,Eshed Ohn-Bar*

Main category: cs.RO

TL;DR: 本文研究了用于机器人系统（如自动驾驶）规划模型的评估方法，发现离线评测与真实环境下的表现相关性较弱，提出了一种基于不确定性的离线指标，并验证了在真实世界和仿真环境中能更好预测在线表现。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶等机器人系统的模型评估多采用离线方式，即通过已标注的数据集计算模型预测误差，但离线表现和实际部署的在线表现之间的联系尚不明确，且常见的评估指标可能低估了某些关键误差的影响。

Method: 作者在多样化环境和指标下，系统性地分析了离线与在线评估之间的关系，并提出基于认识不确定性的离线指标，试图更有效地筛查出容易导致在线事故的情形。方法还包含了仿真和现实环境双重验证。

Result: 结果发现，离线与在线评测相关性比以往研究认为的还要差，现有的主流离线评估办法难以准确反映实际性能。所提出的基于不确定性的指标，将离线-在线表现的相关性提升了13%，且在真实世界中表现更佳。

Conclusion: 离线评估未必能准确预测模型的实际部署表现，基于认识不确定性的指标可以显著提升评估的准确性，为未来机器人系统模型的安全评测提供了新思路。

Abstract: Real-World evaluation of perception-based planning models for robotic
systems, such as autonomous vehicles, can be safely and inexpensively conducted
offline, i.e., by computing model prediction error over a pre-collected
validation dataset with ground-truth annotations. However, extrapolating from
offline model performance to online settings remains a challenge. In these
settings, seemingly minor errors can compound and result in test-time
infractions or collisions. This relationship is understudied, particularly
across diverse closed-loop metrics and complex urban maneuvers. In this work,
we revisit this undervalued question in policy evaluation through an extensive
set of experiments across diverse conditions and metrics. Based on analysis in
simulation, we find an even worse correlation between offline and online
settings than reported by prior studies, casting doubts on the validity of
current evaluation practices and metrics for driving policies. Next, we bridge
the gap between offline and online evaluation. We investigate an offline metric
based on epistemic uncertainty, which aims to capture events that are likely to
cause errors in closed-loop settings. The resulting metric achieves over 13%
improvement in correlation compared to previous offline metrics. We further
validate the generalization of our findings beyond the simulation environment
in real-world settings, where even greater gains are observed.

</details>


### [235] [BLAZER: Bootstrapping LLM-based Manipulation Agents with Zero-Shot Data Generation](https://arxiv.org/abs/2510.08572)
*Rocktim Jyoti Das,Harsh Singh,Diana Turmakhan,Muhammad Abdullah Sohail,Mingfei Han,Preslav Nakov,Fabio Pizzati,Ivan Laptev*

Main category: cs.RO

TL;DR: 本文提出BLAZER框架，利用大语言模型（LLM）的零样本能力，在仿真环境中自动生成多样的操作任务演示，用于学习通用且鲁棒的机器人操作策略。该方法显著提升了零样本操作能力，并支持模型规模缩减。


<details>
  <summary>Details</summary>
Motivation: 机器人领域难以像计算机视觉和自然语言处理那样，获取规模庞大的多样化数据集，因而限制了通用策略的学习。现有的数据集依赖人工采集成本高且规模有限。文章尝试通过自动化数据生成解决这一瓶颈。

Method: 提出BLAZER框架，基于LLM的零样本规划能力，在仿真环境中自动生成丰富的机器人操作演示，并将成功案例反向用于微调LLM，无需人工监督。虽然训练阶段依赖仿真状态，但最终能够成功迁移到基于传感器的实际机器人操作。

Result: 大量实验表明，BLAZER能显著提升仿真和真实环境下的零样本操作表现，并能提升模型在训练任务池外的新任务表现。同时，框架还支持LLM模型的规模缩减。

Conclusion: BLAZER通过自动化数据生成和自监督学习，突破了机器人数据获取的瓶颈，提升了零样本泛化能力，为机器人操作的大规模自主学习提供了有效途径。代码和数据将开源。

Abstract: Scaling data and models has played a pivotal role in the remarkable progress
of computer vision and language. Inspired by these domains, recent efforts in
robotics have similarly focused on scaling both data and model size to develop
more generalizable and robust policies. However, unlike vision and language,
robotics lacks access to internet-scale demonstrations across diverse robotic
tasks and environments. As a result, the scale of existing datasets typically
suffers from the need for manual data collection and curation. To address this
problem, here we propose BLAZER, a framework that learns manipulation policies
from automatically generated training data. We build on the zero-shot
capabilities of LLM planners and automatically generate demonstrations for
diverse manipulation tasks in simulation. Successful examples are then used to
finetune an LLM and to improve its planning capabilities without human
supervision. Notably, while BLAZER training requires access to the simulator's
state, we demonstrate direct transfer of acquired skills to sensor-based
manipulation. Through extensive experiments, we show BLAZER to significantly
improve zero-shot manipulation in both simulated and real environments.
Moreover, BLAZER improves on tasks outside of its training pool and enables
downscaling of LLM models. Our code and data will be made publicly available on
the project page.

</details>
