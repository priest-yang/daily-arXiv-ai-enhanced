<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 74]
- [cs.CL](#cs.CL) [Total: 78]
- [cs.RO](#cs.RO) [Total: 34]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [DD-MDN: Human Trajectory Forecasting with Diffusion-Based Dual Mixture Density Networks and Uncertainty Self-Calibration](https://arxiv.org/abs/2602.11214)
*Manuel Hetzel,Kerim Turacan,Hannes Reichert,Konrad Doll,Bernhard Sick*

Main category: cs.CV

TL;DR: 本文提出DD-MDN模型，通过融合去噪扩散模型和混合密度网络，实现了高精度轨迹预测、自适应不确定性建模，同时能在观察时间较短时保持鲁棒性，在多个数据集上取得了领先的预测效果。


<details>
  <summary>Details</summary>
Motivation: 以往人类轨迹预测研究多关注精度、社会交互和多样性，较少考虑轨迹预测中的不确定性建模、校准以及短时观察下的预测能力。然而这些因素对自动驾驶、路径规划等下游任务至关重要，因此需要提升对这些方面的研究。

Method: 提出了DD-MDN框架，将few-shot去噪扩散模型作为特征主干，结合双重混合密度网络，自适应学习停留区域与概率排序锚路径，无需预定义锚点或终点，可生成多样化的轨迹预测假设，并提供置信度校准。

Result: 在ETH/UCY、SDD、inD和IMPTC等主流数据集上，DD-MDN模型在预测精度、短观察期鲁棒性和不确定性建模等方面均取得了SOTA表现，显著优于现有方法。

Conclusion: 该方法不仅提升了轨迹预测的精度和多样性，还增强了模型在关键任务场景中的实用价值，通过不确定性校准支持更安全的下游决策任务。

Abstract: Human Trajectory Forecasting (HTF) predicts future human movements from past trajectories and environmental context, with applications in Autonomous Driving, Smart Surveillance, and Human-Robot Interaction. While prior work has focused on accuracy, social interaction modeling, and diversity, little attention has been paid to uncertainty modeling, calibration, and forecasts from short observation periods, which are crucial for downstream tasks such as path planning and collision avoidance. We propose DD-MDN, an end-to-end probabilistic HTF model that combines high positional accuracy, calibrated uncertainty, and robustness to short observations. Using a few-shot denoising diffusion backbone and a dual mixture density network, our method learns self-calibrated residence areas and probability-ranked anchor paths, from which diverse trajectory hypotheses are derived, without predefined anchors or endpoints. Experiments on the ETH/UCY, SDD, inD, and IMPTC datasets demonstrate state-of-the-art accuracy, robustness at short observation intervals, and reliable uncertainty modeling. The code is available at: https://github.com/kav-institute/ddmdn.

</details>


### [2] [ABot-M0: VLA Foundation Model for Robotic Manipulation with Action Manifold Learning](https://arxiv.org/abs/2602.11236)
*Yandan Yang,Shuang Zeng,Tong Lin,Xinyuan Chang,Dekang Qi,Junjin Xiao,Haoyun Liu,Ronghan Chen,Yuzhi Chen,Dongjie Huo,Feng Xiong,Xing Wei,Zhiheng Ma,Mu Xu*

Main category: cs.CV

TL;DR: ABot-M0提出了一个统一的框架，通过数据管道优化和模型训练策略，实现多机器人平台的数据与能力统一，提升了动作预测效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前机器人领域，“一脑多形”泛用智能受制于数据碎片化、表示不统一和训练目标不一致，阻碍了跨硬件通用体智能的发展。

Method: 作者构建了系统化数据流程，清洗、标准化并平衡六大公开数据集，形成了具有代表性的UniACT大规模数据集。同时，提出了动作流形假设（Action Manifold Hypothesis），并基于此开发了Action Manifold Learning（AML）方法，用DiT骨干预测动作流，提升了效率与稳定性。还设计了支持模块化感知的双流机制，整合VLM语义和三维几何优先信息，无需修改主干即可增强空间理解。

Result: 实验证明，ABot-M0各模块独立运作、带来叠加效益，预训练可提升知识迁移与泛化，多视角和三维感知增强空间推理能力，动作预测更高效稳定。

Conclusion: ABot-M0为多机器人通用智能提供了标杆性数据集和高效统一的训练推理方案，提升了算法泛化性、效率和空间理解能力，为后续复制和扩展奠定了基础。

Abstract: Building general-purpose embodied agents across diverse hardware remains a central challenge in robotics, often framed as the ''one-brain, many-forms'' paradigm. Progress is hindered by fragmented data, inconsistent representations, and misaligned training objectives. We present ABot-M0, a framework that builds a systematic data curation pipeline while jointly optimizing model architecture and training strategies, enabling end-to-end transformation of heterogeneous raw data into unified, efficient representations. From six public datasets, we clean, standardize, and balance samples to construct UniACT-dataset, a large-scale dataset with over 6 million trajectories and 9,500 hours of data, covering diverse robot morphologies and task scenarios. Unified pre-training improves knowledge transfer and generalization across platforms and tasks, supporting general-purpose embodied intelligence. To improve action prediction efficiency and stability, we propose the Action Manifold Hypothesis: effective robot actions lie not in the full high-dimensional space but on a low-dimensional, smooth manifold governed by physical laws and task constraints. Based on this, we introduce Action Manifold Learning (AML), which uses a DiT backbone to predict clean, continuous action sequences directly. This shifts learning from denoising to projection onto feasible manifolds, improving decoding speed and policy stability. ABot-M0 supports modular perception via a dual-stream mechanism that integrates VLM semantics with geometric priors and multi-view inputs from plug-and-play 3D modules such as VGGT and Qwen-Image-Edit, enhancing spatial understanding without modifying the backbone and mitigating standard VLM limitations in 3D reasoning. Experiments show components operate independently with additive benefits. We will release all code and pipelines for reproducibility and future research.

</details>


### [3] [Toward Reliable Tea Leaf Disease Diagnosis Using Deep Learning Model: Enhancing Robustness With Explainable AI and Adversarial Training](https://arxiv.org/abs/2602.11239)
*Samanta Ghosh,Jannatul Adan Mahi,Shayan Abrar,Md Parvez Mia,Asaduzzaman Rayhan,Abdul Awal Yasir,Asaduzzaman Hridoy*

Main category: cs.CV

TL;DR: 本文提出基于深度学习的茶叶疾病自动分类模型，通过茶叶叶片高分辨率图像实现高精度病害检测，为农业管理提供智能化工具。


<details>
  <summary>Details</summary>
Motivation: 茶叶对孟加拉国经济至关重要，叶片病害会严重影响产量和质量；传统人工检测方法效率低且误判率高，因此亟需一种高效、自动化的疾病检测方法。

Method: 作者基于teaLeafBD数据集（包含5278张高分辨率叶片图片，分为6类病害和1类健康），采用DenseNet201和EfficientNetB3两种深度神经网络进行分类。整个流程包括数据预处理、集划分、对抗训练、数据增强、模型训练和评价，以及利用可解释AI（如Grad-CAM）分析模型对图片的关注区域。

Result: EfficientNetB3模型在测试集上获得了最高93%的分类准确率，DenseNet201达到了91%。利用对抗训练增强了模型对噪声扰动的鲁棒性。Grad-CAM可解释分析展示了模型判别依据的关键图像区域。

Conclusion: 所提出的深度学习方法可实现高效、准确的茶叶病害自动检测，有望在农业管理和实际应用中推广，提高病害发现效率和茶叶品质保障。

Abstract: Tea is a valuable asset for the economy of Bangladesh. So, tea cultivation plays an important role to boost the economy. These valuable plants are vulnerable to various kinds of leaf infections which may cause less production and low quality. It is not so easy to detect these diseases manually. It may take time and there could be some errors in the detection.Therefore, the purpose of the study is to develop an automated deep learning model for tea leaf disease classification based on the teaLeafBD dataset so that anyone can detect the diseases more easily and efficiently. There are 5,278 high-resolution images in this dataset. The images are classified into seven categories. Six of them represents various diseases and the rest one represents healthy leaves. The proposed pipeline contains data preprocessing, data splitting, adversarial training, augmentation, model training, evaluation, and comprehension made possible with Explainable AI strategies. DenseNet201 and EfficientNetB3 were employed to perform the classification task. To prepare the model more robustly, we applied adversarial training so it can operate effectively even with noisy or disturbed inputs. In addition, Grad-CAM visualization was executed to analyze the model's predictions by identifying the most influential regions of each image. Our experimental outcomes revealed that EfficientNetB3 achieved the highest classification accuracy of 93%, while DenseNet201 reached 91%. The outcomes prove that the effectiveness of the proposed approach can accurately detect tea leaf diseases and provide a practical solution for advanced agricultural management.

</details>


### [4] [Active Zero: Self-Evolving Vision-Language Models through Active Environment Exploration](https://arxiv.org/abs/2602.11241)
*Jinghan He,Junfeng Fang,Feng Xiong,Zijun Yao,Fei Shen,Haiyun Guo,Jinqiao Wang,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 本文提出Active-Zero框架，实现视觉-语言大模型的主动自我进化，通过主动探索视觉环境而非被动处理已有数据，实现更高效的自主演化学习，并显著超过以往baseline。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言大模型自博弈方法主要通过与静态图片数据集被动交互，导致学习效率低、对初始数据高度依赖，无法主动获取与模型当前能力匹配的新视觉数据，浪费算力于简单或超出能力范围的样本。

Method: 提出Active-Zero框架，引入Searcher（主动检索开放世界的图片）、Questioner（根据模型能力生成合适推理任务）、Solver（通过奖励机制不断优化）三类协同进化的智能体，形成闭环自主演化机制，实现模型自我引领的自动课程学习。

Result: 在Qwen2.5-VL-7B-Instruct以及12项基准测试上，Active-Zero在推理任务平均准确率为53.97（提升5.7%），在一般理解任务平均准确率为59.77（提升3.9%），其效果优于现有自博弈主流方法。

Conclusion: 主动探索是实现可扩展、自我进化的视觉-语言大模型的关键，Active-Zero框架显著提升了自博弈效率与能力，展现了主动探索在人机智能领域的价值。

Abstract: Self-play has enabled large language models to autonomously improve through self-generated challenges. However, existing self-play methods for vision-language models rely on passive interaction with static image collections, resulting in strong dependence on initial datasets and inefficient learning. Without the ability to actively seek visual data tailored to their evolving capabilities, agents waste computational effort on samples that are either trivial or beyond their current skill level. To address these limitations, we propose Active-Zero, a framework that shifts from passive interaction to active exploration of visual environments. Active-Zero employs three co-evolving agents: a Searcher that retrieves images from open-world repositories based on the model's capability frontier, a Questioner that synthesizes calibrated reasoning tasks, and a Solver refined through accuracy rewards. This closed loop enables self-scaffolding auto-curricula where the model autonomously constructs its learning trajectory. On Qwen2.5-VL-7B-Instruct across 12 benchmarks, Active-Zero achieves 53.97 average accuracy on reasoning tasks (5.7% improvement) and 59.77 on general understanding (3.9% improvement), consistently outperforming existing self-play baselines. These results highlight active exploration as a key ingredient for scalable and adaptive self-evolving vision-language systems.

</details>


### [5] [ReTracing: An Archaeological Approach Through Body, Machine, and Generative Systems](https://arxiv.org/abs/2602.11242)
*Yitong Wang,Yue Yao*

Main category: cs.CV

TL;DR: 本文介绍了ReTracing项目，一种结合多智能体表演艺术和考古学方法，探索AI如何影响和生成肢体动作。该项目通过抽取科幻小说中人与机器互动的描述，借助大语言模型生成正反动作指令，再用扩散式文本生成视频技术为人类和机器人提供动作指南，并用多相机与三维重建手段记录和分析动作轨迹，揭示AI系统如何通过舞蹈动作编码社会文化偏见。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能技术的发展，AI不仅在思维和决策领域日益与人类接近，还开始影响和重塑人类的身体动作。本文希望通过表演艺术来直观展示和反思AI对身体运动以及社会文化意义的影响，回应“在能行动、思考并留下痕迹的AI面前，什么才是人类”的核心问题。

Method: 1. 从科幻小说中选取描述人机互动的句子；2. 利用大语言模型(LLM)为每段描述生成“应该做什么”与“不应该做什么”配对提示；3. 用基于扩散模型的文本转视频技术，将提示转为人类舞者和四足机器人（quadruped robot）的动作或运动指令；4. 人机在镜面地板上表演，动作通过多相机运动跟踪，并用三维点云与动作轨迹重构，形成可分析的数字化运动档案。

Result: 该方法成功将AI生成的动作指令映射到人类与机器人双主体的现场表演，并利用视觉重建技术详细记录及可视化了复杂的动作轨迹。实验展示了AI系统在生成动作提示时可能带有的社会文化偏见，也让观众通过身临其境的人机共演反思与AI共处的意义。

Conclusion: ReTracing提供了一种新颖的、多学科交叉的探索方式，通过融合AI、舞蹈和数字考古，重新审视了人类与AI的边界和共存关系。该研究揭示了生成式AI系统在肢体动作层面潜在的社会文化偏见，以及人类主体性在AI共存时代面临的挑战，对理解人与智能体共生的未来具有启发意义。

Abstract: We present ReTracing, a multi-agent embodied performance art that adopts an archaeological approach to examine how artificial intelligence shapes, constrains, and produces bodily movement. Drawing from science-fiction novels, the project extracts sentences that describe human-machine interaction. We use large language models (LLMs) to generate paired prompts "what to do" and "what not to do" for each excerpt. A diffusion-based text-to-video model transforms these prompts into choreographic guides for a human performer and motor commands for a quadruped robot. Both agents enact the actions on a mirrored floor, captured by multi-camera motion tracking and reconstructed into 3D point clouds and motion trails, forming a digital archive of motion traces. Through this process, ReTracing serves as a novel approach to reveal how generative systems encode socio-cultural biases through choreographed movements. Through an immersive interplay of AI, human, and robot, ReTracing confronts a critical question of our time: What does it mean to be human among AIs that also move, think, and leave traces behind?

</details>


### [6] [Stress Tests REVEAL Fragile Temporal and Visual Grounding in Video-Language Models](https://arxiv.org/abs/2602.11244)
*Sethuraman T,Savya Khosla,Aditi Tiwari,Vidya Ganesh,Rakshana Jayaprakash,Aditya Jain,Vignesh Srinivasakumar,Onkar Kishor Susladkar,Srinidhi Sunkara,Aditya Shanmugham,Rakesh Vaideeswaran,Abbaas Alif Mohamed Nishar,Simon Jenni,Derek Hoiem*

Main category: cs.CV

TL;DR: 本文发现当前的视频-语言模型（VidLMs）在理解视频内容、时间顺序和运动等基本能力上存在显著缺陷。研究团队提出了REVEAL{}基准，通过五项压力测试系统性地揭示这些弱点，并展现了与人类表现的巨大差距。


<details>
  <summary>Details</summary>
Motivation: 尽管基于多模态大模型的视频-语言模型取得了突破性进展，但其是否真正理解视频中的时间、顺序和运动等基本信息，仍缺乏系统且细致的检验方法。本文希望填补这一评估空白。

Method: 作者设计了REVEAL{}，包含五项压力测试，分别考察VidLMs对于：1）时间顺序偏误，2）仅依赖语言线索，3）视频迎合/附和性，4）对相机运动的敏感度，5）时空遮挡下对信息的整合能力。基准数据可自动生成，适配多模型评测。

Result: 主流开源和闭源的VidLMs在上述各项测试中表现差劲，包括：把倒放视频认作正序、答题时忽略视频内容、附和错误表述、难以处理基础相机运动、简单时空遮挡就无法整合时序信息。而人类在这些任务上表现轻松优越。

Conclusion: 当前VidLMs在理解视频核心属性上仍有明显短板，REVEAL{}为此类模型的更深层评估和后续改进提供了有效工具；相关基准和代码也将公开促进社区发展。

Abstract: This work investigates a fundamental question: Do Video-Language Models (VidLMs) robustly account for video content, temporal sequence, and motion? Our investigation shows that, surprisingly, they often do not. We introduce REVEAL{}, a diagnostic benchmark that probes fundamental weaknesses of contemporary VidLMs through five controlled stress tests; assessing temporal expectation bias, reliance on language-only shortcuts, video sycophancy, camera motion sensitivity, and robustness to spatiotemporal occlusion. We test leading open- and closed-source VidLMs and find that these models confidently describe reversed scenes as forward, answer questions while neglecting video content, agree with false claims, struggle with basic camera motion, and fail to aggregate temporal information amidst simple spatiotemporal masking. Humans, on the other hand, succeed at these tasks with ease. Alongside our benchmark, we provide a data pipeline that automatically generates diagnostic examples for our stress tests, enabling broader and more scalable evaluation. We will release our benchmark and code to support future research.

</details>


### [7] [Advancing Digital Twin Generation Through a Novel Simulation Framework and Quantitative Benchmarking](https://arxiv.org/abs/2602.11314)
*Jacob Rubinstein,Avi Donaty,Don Engel*

Main category: cs.CV

TL;DR: 该论文提出并测试了一种用于从高质量3D模型和程序生成的相机姿态合成图片的新流程。该方法有利于开展可重复、可量化的比较实验。


<details>
  <summary>Details</summary>
Motivation: 现有通过摄影测量方法生成3D模型时，面对多种设计选择且评判多依赖主观定性方法，缺乏可量化的客观比较手段。

Method: 论文提出了一套新的流程：首先利用高质量3D模型并通过程序生成多种相机姿态，然后基于这些数据生成合成图片。这一流程能让实验可控、可重复，便于进行基于已知参数的定量比较。

Result: 通过该流程，可以在已知虚拟相机参数与虚拟物体的情况下，将重建过程产生的估计值与真实值进行直接比较，开展系统性实验。

Conclusion: 该方法为不同设计方案的客观量化评估提供了新方式，提升了三维建模流程的科学性和可重复性。

Abstract: The generation of 3D models from real-world objects has often been accomplished through photogrammetry, i.e., by taking 2D photos from a variety of perspectives and then triangulating matched point-based features to create a textured mesh. Many design choices exist within this framework for the generation of digital twins, and differences between such approaches are largely judged qualitatively. Here, we present and test a novel pipeline for generating synthetic images from high-quality 3D models and programmatically generated camera poses. This enables a wide variety of repeatable, quantifiable experiments which can compare ground-truth knowledge of virtual camera parameters and of virtual objects against the reconstructed estimations of those perspectives and subjects.

</details>


### [8] [Selective Prior Synchronization via SYNC Loss](https://arxiv.org/abs/2602.11316)
*Ishan Mishra,Jiajie Li,Deepak Mishra,Jinjun Xiong*

Main category: cs.CV

TL;DR: 本文提出了一种结合训练时和推理时选择性先验信息的新型损失函数SYNC loss，将软max响应融入SelectiveNet训练，有效提升了深度神经网络的不确定性选择性预测能力，并在多个数据集上创造了新基准。


<details>
  <summary>Details</summary>
Motivation: 现有选择性预测方法多为“临时修正（ad-hoc）”或“事后修正（post-hoc）”，但事后生成的不确定性信息（选择性先验）只用于推理阶段，忽略了其对训练过程的价值，遏制了模型不确定性估计及决策能力的提升。本文动机在于充分利用选择性先验，提升深度神经网络的责任预测能力。

Method: 提出SYNC loss（一种新损失函数），将post-hoc方法（软max响应产生的选择性先验）在网络训练阶段结合到ad-hoc方法（SelectiveNet）中，通过训练过程显式利用预测不确定性信息，提升模型选择性预测表现。

Result: 在CIFAR-100、ImageNet-100和Stanford Cars等多个数据集进行了实验，方法不仅提升了模型泛化能力，还在选择性预测任务上超越了先前工作，并确立了新的SOTA基准表现。

Conclusion: 将推理阶段生成的不确定性信息引入训练阶段能极大提升神经网络的选择性预测能力，SYNC loss方法有效融合ad-hoc与post-hoc优点，是提高模型责任预测性能的新范式。

Abstract: Prediction under uncertainty is a critical requirement for the deep neural network to succeed responsibly. This paper focuses on selective prediction, which allows DNNs to make informed decisions about when to predict or abstain based on the uncertainty level of their predictions. Current methods are either ad-hoc such as SelectiveNet, focusing on how to modify the network architecture or objective function, or post-hoc such as softmax response, achieving selective prediction through analyzing the model's probabilistic outputs. We observe that post-hoc methods implicitly generate uncertainty information, termed the selective prior, which has traditionally been used only during inference. We argue that the selective prior provided by the selection mechanism is equally vital during the training stage. Therefore, we propose the SYNC loss which introduces a novel integration of ad-hoc and post-hoc method. Specifically, our approach incorporates the softmax response into the training process of SelectiveNet, enhancing its selective prediction capabilities by examining the selective prior. Evaluated across various datasets, including CIFAR-100, ImageNet-100, and Stanford Cars, our method not only enhances the model's generalization capabilities but also surpasses previous works in selective prediction performance, and sets new benchmarks for state-of-the-art performance.

</details>


### [9] [MDE-VIO: Enhancing Visual-Inertial Odometry Using Learned Depth Priors](https://arxiv.org/abs/2602.11323)
*Arda Alniak,Sinan Kalkan,Mustafa Mert Ankarali,Afsar Saranli,Abdullah Aydin Alatan*

Main category: cs.CV

TL;DR: 论文提出了一种将深度先验直接集成到VINS-Mono后端的新框架，通过高效利用深度估计信息，显著提升了低纹理环境下单目视觉-惯性里程计（VIO）的鲁棒性和精度，同时可在计算资源有限的边缘设备上实时运行。


<details>
  <summary>Details</summary>
Motivation: 传统的单目VIO系统在低纹理环境下，由于稀疏特征不足，导致位姿估计精度下降。但直接采用基于ViT的大型深度估计模型计算资源消耗大，不适合边缘设备。

Method: 1. 将学习到的深度先验直接集成到VINS-Mono的优化后端；2. 强制施加仿射不变的深度一致性及两两序约束；3. 通过方差门控机制过滤不稳定伪影，提升深度估计可靠性；4. 保持框架在边缘设备上的高效可行性。

Result: 在TartanGround和M3ED数据集上的大量实验表明，所提方法可在低纹理等挑战场景下防止系统发散，并显著提升位姿估计精度，ATE降低高达28.3%。

Conclusion: 在保证计算效率的前提下，本文框架有效融合了单目深度先验和VIO，显著提升了边缘设备上低纹理场景下的定位鲁棒性和精度。

Abstract: Traditional monocular Visual-Inertial Odometry (VIO) systems struggle in low-texture environments where sparse visual features are insufficient for accurate pose estimation. To address this, dense Monocular Depth Estimation (MDE) has been widely explored as a complementary information source. While recent Vision Transformer (ViT) based complex foundational models offer dense, geometrically consistent depth, their computational demands typically preclude them from real-time edge deployment. Our work bridges this gap by integrating learned depth priors directly into the VINS-Mono optimization backend. We propose a novel framework that enforces affine-invariant depth consistency and pairwise ordinal constraints, explicitly filtering unstable artifacts via variance-based gating. This approach strictly adheres to the computational limits of edge devices while robustly recovering metric scale. Extensive experiments on the TartanGround and M3ED datasets demonstrate that our method prevents divergence in challenging scenarios and delivers significant accuracy gains, reducing Absolute Trajectory Error (ATE) by up to 28.3%. Code will be made available.

</details>


### [10] [Exploring Real-Time Super-Resolution: Benchmarking and Fine-Tuning for Streaming Content](https://arxiv.org/abs/2602.11339)
*Evgeney Bogatyrev,Khaled Abud,Ivan Molodetskikh,Nikita Alutis,Dmitry Vatolin*

Main category: cs.CV

TL;DR: 本文提出了一个名为StreamSR的新型压缩流媒体视频超分辨率数据集，并在该数据集上系统评测了现有超分辨率方法。同时，设计了高效的EfRLFN模型，在提升效率的同时提高了视频质量与推理速度。


<details>
  <summary>Details</summary>
Motivation: 当前主流超分辨率数据集与实际流媒体中的压缩视频差异较大，导致现有方法在流媒体场景下表现有限。因此，亟需专门面向流媒体的视频超分辨率数据集和针对性方法。

Method: 1）构建大规模、涵盖多种类型的流媒体视频超分辨率数据集StreamSR。2）对比11种当前主流实时超分模型的实际表现。3）提出高效的EfRLFN新模型，采用高效通道注意力结构和tanh激活函数，并通过改进的复合损失函数优化训练过程。4）实验证明在新数据集上微调能提升SOTA广泛模型的性能。

Result: StreamSR数据集推动了更贴合实际的评估体系。EfRLFN模型在效率和视频视觉质量上均超越现有主流模型。在新数据集微调后，其他模型在多个基准数据集上的性能也有显著提升。

Conclusion: 专门面向流媒体的视频超分数据集与优化模型极大提升了超分辨率方法在真实流媒体场景的适用性。新提出的EfRLFN兼具高效与高质量，其相关数据集、代码和基准已对外开放，促进该领域的发展。

Abstract: Recent advancements in real-time super-resolution have enabled higher-quality video streaming, yet existing methods struggle with the unique challenges of compressed video content. Commonly used datasets do not accurately reflect the characteristics of streaming media, limiting the relevance of current benchmarks. To address this gap, we introduce a comprehensive dataset - StreamSR - sourced from YouTube, covering a wide range of video genres and resolutions representative of real-world streaming scenarios. We benchmark 11 state-of-the-art real-time super-resolution models to evaluate their performance for the streaming use-case.
  Furthermore, we propose EfRLFN, an efficient real-time model that integrates Efficient Channel Attention and a hyperbolic tangent activation function - a novel design choice in the context of real-time super-resolution. We extensively optimized the architecture to maximize efficiency and designed a composite loss function that improves training convergence. EfRLFN combines the strengths of existing architectures while improving both visual quality and runtime performance.
  Finally, we show that fine-tuning other models on our dataset results in significant performance gains that generalize well across various standard benchmarks. We made the dataset, the code, and the benchmark available at https://github.com/EvgeneyBogatyrev/EfRLFN.

</details>


### [11] [ArtContext: Contextualizing Artworks with Open-Access Art History Articles and Wikidata Knowledge through a LoRA-Tuned CLIP Model](https://arxiv.org/abs/2602.11349)
*Samuel Waugh,Stuart James*

Main category: cs.CV

TL;DR: 本文提出了ArtContext，一个利用开放访问的艺术史文章和Wikidata知识为艺术作品注释信息的流程。通过新颖的数据收集流程和定制化的CLIP模型（PaintingCLIP），能够更好地为特定艺术品提供上下文信息。实验结果显示该方法优于原始CLIP模型。该流程具备可泛化性，可推广至其他人文学科。


<details>
  <summary>Details</summary>
Motivation: 过去的艺术史文章涉及到作品整体及局部（如版式、图像学、材质等），但观众很难直接获取这些相关文章对作品具体内容的解读、观点或背景。因此迫切需要一种系统化方法，将已有开放资源中的知识注释到具体艺术品上，方便理解和研究。

Method: 作者设计了ArtContext流程，包括：1) 收集开放获取的艺术史文章和Wikidata知识作为数据源；2) 采用Low-Rank Adaptation（LoRA）方法，对CLIP模型进行领域适配，得到定制化的PaintingCLIP模型，使其能结合文本与图像理解；3) 用收集到的语料弱监督训练模型，并将相关文章的关键信息自动注释到艺术作品上。

Result: 实验结果表明，定制化的PaintingCLIP模型在理解艺术作品及其相关语境方面明显优于原始CLIP模型，能为用户提供更准确和丰富的艺术作品上下文注释。

Conclusion: ArtContext流程不仅提升了艺术品内容理解和相关知识挖掘的自动化水平，还具备良好通用性，能推广应用到更广泛的人文学科领域，为知识注释带来新思路。

Abstract: Many Art History articles discuss artworks in general as well as specific parts of works, such as layout, iconography, or material culture. However, when viewing an artwork, it is not trivial to identify what different articles have said about the piece. Therefore, we propose ArtContext, a pipeline for taking a corpus of Open-Access Art History articles and Wikidata Knowledge and annotating Artworks with this information. We do this using a novel corpus collection pipeline, then learn a bespoke CLIP model adapted using Low-Rank Adaptation (LoRA) to make it domain-specific. We show that the new model, PaintingCLIP, which is weakly supervised by the collected corpus, outperforms CLIP and provides context for a given artwork. The proposed pipeline is generalisable and can be readily applied to numerous humanities areas.

</details>


### [12] [Latent Forcing: Reordering the Diffusion Trajectory for Pixel-Space Image Generation](https://arxiv.org/abs/2602.11401)
*Alan Baade,Eric Ryan Chan,Kyle Sargent,Changan Chen,Justin Johnson,Ehsan Adeli,Li Fei-Fei*

Main category: cs.CV

TL;DR: 本文提出Latent Forcing方法，使扩散模型能够直接在原始图像上高效运行，并达到了新的生成质量纪录。


<details>
  <summary>Details</summary>
Motivation: 当前潜变量扩散模型在生成高质量图像上表现突出，但它们舍弃了端到端建模的优点，如编码过程中信息损失、解码器需单独训练及仅对辅助分布建模，限制了效率和表现。作者希望解决这些问题。

Method: 提出Latent Forcing，在扩散模型中联合处理潜变量和像素，分别设定噪声调度顺序，令潜变量作为生成高频像素特征前的中间计算工具，并通过研究条件信号顺序，比较不同训练策略和重建能力对生成质量的影响。

Result: 经实验，Latent Forcing在ImageNet数据集上实现了基于扩散变换器的像素生成的新SOTA，验证了方法优越性。

Conclusion: Latent Forcing弥补了潜变量扩散模型端到端不足，实现了效率与表现兼得的新方法，并对潜变量和条件信息建模进行了深入分析，为扩散模型实际应用提供了新思路。

Abstract: Latent diffusion models excel at generating high-quality images but lose the benefits of end-to-end modeling. They discard information during image encoding, require a separately trained decoder, and model an auxiliary distribution to the raw data. In this paper, we propose Latent Forcing, a simple modification to existing architectures that achieves the efficiency of latent diffusion while operating on raw natural images. Our approach orders the denoising trajectory by jointly processing latents and pixels with separately tuned noise schedules. This allows the latents to act as a scratchpad for intermediate computation before high-frequency pixel features are generated. We find that the order of conditioning signals is critical, and we analyze this to explain differences between REPA distillation in the tokenizer and the diffusion model, conditional versus unconditional generation, and how tokenizer reconstruction quality relates to diffusability. Applied to ImageNet, Latent Forcing achieves a new state-of-the-art for diffusion transformer-based pixel generation at our compute scale.

</details>


### [13] [Fighting MRI Anisotropy: Learning Multiple Cardiac Shapes From a Single Implicit Neural Representation](https://arxiv.org/abs/2602.11436)
*Carolina Brás,Soufiane Ben Haddou,Thijs P. Kuipers,Laura Alvarez-Florez,R. Nils Planken,Fleur V. Y. Tjong,Connie Bezzina,Ivana Išgum*

Main category: cs.CV

TL;DR: 利用高分辨率CTA数据，训练神经隐式函数提升CMRI心脏形态重建，提升RV和MYO结构分析效果。


<details>
  <summary>Details</summary>
Motivation: CMRI的短轴图像由于各向异性，限制了心脏形态分析的精度和准确性。需要更高质量的数据或新方法来克服该限制。

Method: 方法是利用心脏CTA近各向同性、高分辨率数据，训练单个神经隐式函数，使其能够以任意分辨率联合表示CMRI心脏形态，针对右心室（RV）和心肌（MYO）进行重建评估。

Result: 在与CMRI的4腔切面参考分割比较中，RV和MYO的Dice系数分别达到0.91±0.07和0.75±0.13，Hausdorff距离分别为6.21±3.97 mm和7.53±5.13 mm。

Conclusion: 该模型可准确、平滑、符合解剖结构地重建心脏形态，为心脏形态分析的改进提供了支持。

Abstract: The anisotropic nature of short-axis (SAX) cardiovascular magnetic resonance imaging (CMRI) limits cardiac shape analysis. To address this, we propose to leverage near-isotropic, higher resolution computed tomography angiography (CTA) data of the heart. We use this data to train a single neural implicit function to jointly represent cardiac shapes from CMRI at any resolution. We evaluate the method for the reconstruction of right ventricle (RV) and myocardium (MYO), where MYO simultaneously models endocardial and epicardial left-ventricle surfaces. Since high-resolution SAX reference segmentations are unavailable, we evaluate performance by extracting a 4-chamber (4CH) slice of RV and MYO from their reconstructed shapes. When compared with the reference 4CH segmentation masks from CMRI, our method achieved a Dice similarity coefficient of 0.91 $\pm$ 0.07 and 0.75 $\pm$ 0.13, and a Hausdorff distance of 6.21 $\pm$ 3.97 mm and 7.53 $\pm$ 5.13 mm for RV and MYO, respectively. Quantitative and qualitative assessment demonstrate the model's ability to reconstruct accurate, smooth and anatomically plausible shapes, supporting improvements in cardiac shape analysis.

</details>


### [14] [Ctrl&Shift: High-Quality Geometry-Aware Object Manipulation in Visual Generation](https://arxiv.org/abs/2602.11440)
*Penghui Ruan,Bojia Zi,Xianbiao Qi,Youze Huang,Rong Xiao,Pichao Wang,Jiannong Cao,Yuhui Shi*

Main category: cs.CV

TL;DR: 本文提出了一种新的端到端扩散模型Ctrl&Shift，实现了几何一致且可控的对象级图像/视频操控，无需明确三维重建。该方法在背景保留、视角一致性和用户控制三方面均达到了新的SOTA水平。


<details>
  <summary>Details</summary>
Motivation: 现有对象操控方法难以同时兼顾背景保留、几何一致性（尤其是多视角下）以及用户可控性。基于几何的方法虽可控但三维重建要求高、泛化差，基于扩散的方法易泛化但几何细节难把控。需要一种既泛化又可精细控制的新方法。

Method: 提出Ctrl&Shift框架，将操控过程分为对象移除和带相机位姿控制的参考引导修复两个阶段，两者均在统一扩散过程中实现。采用多任务多阶段训练，将背景、身份和姿态信号解耦，以及提出了可扩展的真实数据集构建管线，生成带相机位姿的配对图像和视频样本。

Result: 大规模实验显示，Ctrl&Shift在真实感、视角一致性、操控性等多个指标上均达到了业界最优水平；相比传统的三维建模或普通扩散方法有明显提升。

Conclusion: Ctrl&Shift首次在无需明确三维建模的前提下，实现了对对象操控的微调几何控制与真实泛化的统一，推动了图像/视频对象操控技术的进步。

Abstract: Object-level manipulation, relocating or reorienting objects in images or videos while preserving scene realism, is central to film post-production, AR, and creative editing. Yet existing methods struggle to jointly achieve three core goals: background preservation, geometric consistency under viewpoint shifts, and user-controllable transformations. Geometry-based approaches offer precise control but require explicit 3D reconstruction and generalize poorly; diffusion-based methods generalize better but lack fine-grained geometric control. We present Ctrl&Shift, an end-to-end diffusion framework to achieve geometry-consistent object manipulation without explicit 3D representations. Our key insight is to decompose manipulation into two stages, object removal and reference-guided inpainting under explicit camera pose control, and encode both within a unified diffusion process. To enable precise, disentangled control, we design a multi-task, multi-stage training strategy that separates background, identity, and pose signals across tasks. To improve generalization, we introduce a scalable real-world dataset construction pipeline that generates paired image and video samples with estimated relative camera poses. Extensive experiments demonstrate that Ctrl&Shift achieves state-of-the-art results in fidelity, viewpoint consistency, and controllability. To our knowledge, this is the first framework to unify fine-grained geometric control and real-world generalization for object manipulation, without relying on any explicit 3D modeling.

</details>


### [15] [Enhanced Portable Ultra Low-Field Diffusion Tensor Imaging with Bayesian Artifact Correction and Deep Learning-Based Super-Resolution](https://arxiv.org/abs/2602.11446)
*Mark D. Olchanyi,Annabel Sorby-Adams,John Kirsch,Brian L. Edlow,Ava Farnan,Renfei Liu,Matthew S. Rosen,Emery N. Brown,W. Taylor Kimberly,Juan Eugenio Iglesias*

Main category: cs.CV

TL;DR: 本论文提出了针对超低场（ULF）磁共振成像白质纤维追踪的降噪、偏置校正和超分辨重建新方法，显著提升了超低场下扩散张量成像（DTI）的空间和角度分辨率。所提出方法对于病理检测如阿尔茨海默病表现出更好的一致性和判别力。相关算法和代码已公开。


<details>
  <summary>Details</summary>
Motivation: 超低场MRI设备便携但成像性能受限，空间分辨率和信噪比低，扩散张量成像（DTI）序列尤其受影响，易产生空间和角度伪影，限制了其在脑白质成像和神经退行性疾病检测的临床应用。因此需要开发适用于ULF DTI的降噪、校正和分辨率提升方法。

Method: 作者提出了一个九方向单壳层的ULF DTI序列，配合具有角度依赖性的贝叶斯偏场校正算法，以及可通用不需再次训练的基于卷积神经网络的超分辨率重建算法DiffSR。通过合成降采样实验及与高场MRI配对扫描的数据，对方法有效性进行验证。

Result: 实验结果表明，提出的算法能够恢复ULF DTI下脑白质的微观结构和体积信息，且在阿尔茨海默病分类等病理分析任务中与原始高质量数据的一致性显著提高。DiffSR对不同DTI数据集具有良好泛化能力，无需单独训练即可应用。

Conclusion: 所提出的贝叶斯偏置校正和DiffSR超分辨方法显著提升了ULF DTI的成像质量和下游分析性能，推动了超低场磁共振重建算法及DTI序列标准化进展。相关工具已开源，为社区提供进一步研究基础。

Abstract: Portable, ultra-low-field (ULF) magnetic resonance imaging has the potential to expand access to neuroimaging but currently suffers from coarse spatial and angular resolutions and low signal-to-noise ratios. Diffusion tensor imaging (DTI), a sequence tailored to detect and reconstruct white matter tracts within the brain, is particularly prone to such imaging degradation due to inherent sequence design coupled with prolonged scan times. In addition, ULF DTI scans exhibit artifacting that spans both the space and angular domains, requiring a custom modelling algorithm for subsequent correction. We introduce a nine-direction, single-shell ULF DTI sequence, as well as a companion Bayesian bias field correction algorithm that possesses angular dependence and convolutional neural network-based superresolution algorithm that is generalizable across DTI datasets and does not require re-training (''DiffSR''). We show through a synthetic downsampling experiment and white matter assessment in real, matched ULF and high-field DTI scans that these algorithms can recover microstructural and volumetric white matter information at ULF. We also show that DiffSR can be directly applied to white matter-based Alzheimers disease classification in synthetically degraded scans, with notable improvements in agreement between DTI metrics, as compared to un-degraded scans. We freely disseminate the Bayesian bias correction algorithm and DiffSR with the goal of furthering progress on both ULF reconstruction methods and general DTI sequence harmonization. We release all code related to DiffSR for $\href{https://github.com/markolchanyi/DiffSR}{public \space use}$.

</details>


### [16] [A Dual-Branch Framework for Semantic Change Detection with Boundary and Temporal Awareness](https://arxiv.org/abs/2602.11466)
*Yun-Cheng Li,Sen Lei,Heng-Chao Li,Ke Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为DBTANet的语义变化检测方法，通过结合边界感知和时序建模，在遥感影像变化检测任务中取得了最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有的语义变化检测方法在处理遥感影像时，常常出现边界模糊和时序建模不足的问题，从而限制了分割的准确性。

Method: 作者提出了一种双分支Siamese编码器架构，一条冻结的SAM分支用于全局语义与边界先验提取，另一条ResNet34分支提供局部空间细节，并通过双向时序感知模块（BTAM）对多尺度特征进行聚合和时序建模，同时引入高斯平滑投影模块（GSPM）以提升边界信息的表达能力。

Result: 在两个公开数据集上的大量实验表明，所提DBTANet深入融合了全局和局部信息、时序推理及边界感知，在变化检测任务中取得了当前最优的表现。

Conclusion: DBTANet有效解决了现有方法边界模糊和时序建模不足的问题，为遥感影像的语义变化检测提供了更精确和可靠的解决方案。

Abstract: Semantic Change Detection (SCD) aims to detect and categorize land-cover changes from bi-temporal remote sensing images. Existing methods often suffer from blurred boundaries and inadequate temporal modeling, limiting segmentation accuracy. To address these issues, we propose a Dual-Branch Framework for Semantic Change Detection with Boundary and Temporal Awareness, termed DBTANet. Specifically, we utilize a dual-branch Siamese encoder where a frozen SAM branch captures global semantic context and boundary priors, while a ResNet34 branch provides local spatial details, ensuring complementary feature representations. On this basis, we design a Bidirectional Temporal Awareness Module (BTAM) to aggregate multi-scale features and capture temporal dependencies in a symmetric manner. Furthermore, a Gaussian-smoothed Projection Module (GSPM) refines shallow SAM features, suppressing noise while enhancing edge information for boundary-aware constraints. Extensive experiments on two public benchmarks demonstrate that DBTANet effectively integrates global semantics, local details, temporal reasoning, and boundary awareness, achieving state-of-the-art performance.

</details>


### [17] [Arbitrary Ratio Feature Compression via Next Token Prediction](https://arxiv.org/abs/2602.11494)
*Yufan Liu,Daoyuan Ren,Zhipeng Zhang,Wenyang Luo,Bing Li,Weiming Hu,Stephen Maybank*

Main category: cs.CV

TL;DR: 本文提出了一种新型的任意比率特征压缩（ARFC）框架，仅用单一模型即可支持任意压缩比，显著提升大规模及多模态数据下下游任务的灵活性与效率。


<details>
  <summary>Details</summary>
Motivation: 现有特征压缩方法通常依赖特定模型实现固定压缩比，缺乏通用性和灵活性，每当需要适应新压缩比时须重新训练模型，增加了计算和应用成本。

Method: ARFC核心为自回归压缩器（ARC），通过逐步预测token实现特征压缩，推理阶段可通过调整生成token数量灵活控制压缩比。为提升压缩后特征质量，引入了两项关键模块：混合解法（MoS）模块融合多组压缩结果，降低不确定性，提高鲁棒性；实体关系图约束（ERGC）模块用于训练阶段，保持特征压缩过程中的语义和结构关系。

Result: 在多数据集的跨模态检索、图像分类和图像检索任务上，大量实验表明，该方法在不同压缩比下均优于现有压缩方案，部分情境下甚至超越未压缩原始特征的表现。

Conclusion: ARFC框架具备灵活、高效、泛化强的压缩能力，在实际资源受限场景下应用潜力突出。

Abstract: Feature compression is increasingly important for improving the efficiency of downstream tasks, especially in applications involving large-scale or multi-modal data. While existing methods typically rely on dedicated models for achieving specific compression ratios, they are often limited in flexibility and generalization. In particular, retraining is necessary when adapting to a new compression ratio. To address this limitation, we propose a novel and flexible Arbitrary Ratio Feature Compression (ARFC) framework, which supports any compression ratio with a single model, eliminating the need for multiple specialized models. At its core, the Arbitrary Ratio Compressor (ARC) is an auto-regressive model that performs compression via next-token prediction. This allows the compression ratio to be controlled at inference simply by adjusting the number of generated tokens. To enhance the quality of the compressed features, two key modules are introduced. The Mixture of Solutions (MoS) module refines the compressed tokens by utilizing multiple compression results (solutions), reducing uncertainty and improving robustness. The Entity Relation Graph Constraint (ERGC) is integrated into the training process to preserve semantic and structural relationships during compression. Extensive experiments on cross-modal retrieval, image classification, and image retrieval tasks across multiple datasets demonstrate that our method consistently outperforms existing approaches at various compression ratios. Notably, in some cases, it even surpasses the performance of the original, uncompressed features. These results validate the effectiveness and versatility of ARFC for practical, resource-constrained scenarios.

</details>


### [18] [What if Agents Could Imagine? Reinforcing Open-Vocabulary HOI Comprehension through Generation](https://arxiv.org/abs/2602.11499)
*Zhenlong Yuan,Xiangyan Qu,Jing Tang,Rui Chen,Lei Sun,Ruidong Chen,Hongwei Yu,Chengxuan Qian,Xiangxiang Chu,Shuo Li,Yuyin Zhou*

Main category: cs.CV

TL;DR: 本论文提出了ImagineAgent框架，通过认知推理与生成式想象相结合，提升多模态大模型在开放词汇人-物交互（OV-HOI）任务中的推理能力。模型创新性地构建认知图谱并动态调用多种工具，显著增强了处理遮挡和歧义场景时的鲁棒性，并在相关数据集上以更少训练数据实现SOTA表现。


<details>
  <summary>Details</summary>
Motivation: 开放词汇下的人-物交互推理对视觉与文本跨模态理解要求极高，但现有多模态大语言模型存在幻觉和遮挡下的歧义推理等问题，亟需提升模型在复杂场景下的推理和对齐能力。

Method: 提出ImagineAgent框架：1）构建显式的认知图谱，建模实体与动作间的关系；2）动态调用检索增强、图像裁剪、扩散模型等工具，增强领域知识和视觉证据采集；3）设计复合奖励机制，平衡预测准确性和工具使用效率。

Result: 在SWIG-HOI和HICO-DET两个数据集上，ImagineAgent用大约20%的训练数据达到甚至超越现有方法的SOTA性能，体现了方法的高效性和鲁棒性。

Conclusion: ImagineAgent通过认知推理与生成想象联合建模，创新性地解决了开放词汇HOI中的跨模态推理难题，并以更高效率和鲁棒性推动多模态大模型应用前沿。

Abstract: Multimodal Large Language Models have shown promising capabilities in bridging visual and textual reasoning, yet their reasoning capabilities in Open-Vocabulary Human-Object Interaction (OV-HOI) are limited by cross-modal hallucinations and occlusion-induced ambiguity. To address this, we propose \textbf{ImagineAgent}, an agentic framework that harmonizes cognitive reasoning with generative imagination for robust visual understanding. Specifically, our method innovatively constructs cognitive maps that explicitly model plausible relationships between detected entities and candidate actions. Subsequently, it dynamically invokes tools including retrieval augmentation, image cropping, and diffusion models to gather domain-specific knowledge and enriched visual evidence, thereby achieving cross-modal alignment in ambiguous scenarios. Moreover, we propose a composite reward that balances prediction accuracy and tool efficiency. Evaluations on SWIG-HOI and HICO-DET datasets demonstrate our SOTA performance, requiring approximately 20\% of training data compared to existing methods, validating our robustness and efficiency.

</details>


### [19] [Vascular anatomy-aware self-supervised pre-training for X-ray angiogram analysis](https://arxiv.org/abs/2602.11536)
*De-Xing Huang,Chaohui Yu,Xiao-Hu Zhou,Tian-Yu Xiang,Qin-Yi Zhang,Mei-Jiang Gui,Rui-Ze Ma,Chen-Yu Wang,Nu-Fang Xiao,Fan Wang,Zeng-Guang Hou*

Main category: cs.CV

TL;DR: 本文提出了一种专为血管X射线造影设计的自监督学习框架VasoMIM，并构建了至今最大的相关预训练数据集XA-170K，通过融合解剖学先验显著提升了多项任务的性能。


<details>
  <summary>Details</summary>
Motivation: X射线血管造影是心血管疾病影像诊断的金标准，但训练数据标注极其稀缺，深度学习应用受限。虽然自监督学习被认为是应对数据匮乏的潜力方法，但该领域缺乏高效框架和大规模数据集，成为技术发展的瓶颈。

Method: 提出VasoMIM自监督学习框架，包含两大创新：一是以血管解剖学为指导的屏蔽策略，有针对性地遮挡包含血管的图像区域，驱动模型学习血管语义特征；二是引入解剖一致性损失，保证重建图像结构与原始图像的血管结构保持一致，从而增强表征区分度。同时首次发布XA-170K数据集，为该方向的预训练提供坚实基础。

Result: 在四项下游任务、六个数据集上进行实验，VasoMIM均展现出更优迁移能力和领先现有方法的性能，取得了当前最先进的结果（state-of-the-art）。

Conclusion: VasoMIM结合了解剖学知识与自监督学习，极大推动了X射线血管造影分析任务的基础能力建设，将成为促进该领域发展的有力工具。数据集和代码开源，便于社区进一步研究和应用。

Abstract: X-ray angiography is the gold standard imaging modality for cardiovascular diseases. However, current deep learning approaches for X-ray angiogram analysis are severely constrained by the scarcity of annotated data. While large-scale self-supervised learning (SSL) has emerged as a promising solution, its potential in this domain remains largely unexplored, primarily due to the lack of effective SSL frameworks and large-scale datasets. To bridge this gap, we introduce a vascular anatomy-aware masked image modeling (VasoMIM) framework that explicitly integrates domain-specific anatomical knowledge. Specifically, VasoMIM comprises two key designs: an anatomy-guided masking strategy and an anatomical consistency loss. The former strategically masks vessel-containing patches to compel the model to learn robust vascular semantics, while the latter preserves structural consistency of vessels between original and reconstructed images, enhancing the discriminability of the learned representations. In conjunction with VasoMIM, we curate XA-170K, the largest X-ray angiogram pre-training dataset to date. We validate VasoMIM on four downstream tasks across six datasets, where it demonstrates superior transferability and achieves state-of-the-art performance compared to existing methods. These findings highlight the significant potential of VasoMIM as a foundation model for advancing a wide range of X-ray angiogram analysis tasks. VasoMIM and XA-170K will be available at https://github.com/Dxhuang-CASIA/XA-SSL.

</details>


### [20] [Supervise-assisted Multi-modality Fusion Diffusion Model for PET Restoration](https://arxiv.org/abs/2602.11545)
*Yingkai Zhang,Shuang Chen,Ye Tian,Yunyi Gao,Jianyong Jiang,Ying Fu*

Main category: cs.CV

TL;DR: 本文提出了一种名为MFdiff的监督辅助多模态融合扩散模型，用于在低剂量PET成像情况下，借助MR图像高质量地重建标准剂量PET。该方法通过优化的特征融合和分阶段学习策略，提升了重建效果，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: PET成像尽管功能强大，但存在辐射暴露风险。减低放射性剂量或缩短扫描时间虽然能降低辐射，但会导致成像质量下降。利用MR图像辅助重建高质量PET是一种减低损失的方法，但在多模态信息融合和宽分布数据一致性方面存在困难。因此，有必要开发能兼顾多模态信息融合及广义/特异数据适应性的高质量PET重建方法。

Method: 提出了一种监督辅助的多模态融合扩散模型（MFdiff）。该模型设计了多模态特征融合模块，以最优方式融合LPET和MR特征，并作为扩散模型的条件输入，迭代生成高质量的SPET图像。此外，引入了两阶段的监督辅助学习策略，结合了来自模拟内分布数据的通用先验和针对体内OOD数据的特异先验，以增强模型泛化与特异适应能力。

Result: 实验表明，提出的MFdiff模型能够有效地从多模态输入中（如低剂量PET和MR）重建高质量的标准剂量PET图像。无论在定性（视觉效果）还是定量指标上，MFdiff均优于当前主流方法。

Conclusion: 本文提出的MFdiff模型能在降低PET辐射剂量的同时，显著提升成像质量，在多模态融合和广分布数据适应性上表现突出，为高质量、低剂量PET成像提供了有效解决方案。

Abstract: Positron emission tomography (PET) offers powerful functional imaging but involves radiation exposure. Efforts to reduce this exposure by lowering the radiotracer dose or scan time can degrade image quality. While using magnetic resonance (MR) images with clearer anatomical information to restore standard-dose PET (SPET) from low-dose PET (LPET) is a promising approach, it faces challenges with the inconsistencies in the structure and texture of multi-modality fusion, as well as the mismatch in out-of-distribution (OOD) data. In this paper, we propose a supervise-assisted multi-modality fusion diffusion model (MFdiff) for addressing these challenges for high-quality PET restoration. Firstly, to fully utilize auxiliary MR images without introducing extraneous details in the restored image, a multi-modality feature fusion module is designed to learn an optimized fusion feature. Secondly, using the fusion feature as an additional condition, high-quality SPET images are iteratively generated based on the diffusion model. Furthermore, we introduce a two-stage supervise-assisted learning strategy that harnesses both generalized priors from simulated in-distribution datasets and specific priors tailored to in-vivo OOD data. Experiments demonstrate that the proposed MFdiff effectively restores high-quality SPET images from multi-modality inputs and outperforms state-of-the-art methods both qualitatively and quantitatively.

</details>


### [21] [Perception-based Image Denoising via Generative Compression](https://arxiv.org/abs/2602.11553)
*Nam Nguyen,Thinh Nguyen,Bella Bose*

Main category: cs.CV

TL;DR: 提出一种基于生成式压缩的新颖图像去噪方法，通过生成模型提升感知质量，优化噪声强图像和分布漂移下的去噪结果。


<details>
  <summary>Details</summary>
Motivation: 传统以失真为导向的图像去噪方法在强噪声和分布漂移场景下，容易导致图像过度平滑、结构信息损失及感知质量降低。该问题亟需兼顾结构保留、感知真实感和鲁棒性的创新方法。

Method: 1）提出基于生成式压缩的感知型去噪框架，将恢复过程建模为从熵编码潜变量重建低复杂度结构，然后借助生成式解码器（使用LPIPS损失或Wasserstein距离）提升纹理和感知质量。2）实现了两种互补的具体方案：（i）基于条件Wasserstein GAN的压缩去噪器，能明确调控失真-率-感知（三者）权衡；（ii）基于条件扩散模型，通过引导的潜变量压缩实现迭代还原。3）对添加高斯噪声场景下的最大似然压缩去噪器给出非渐近性能保证，包括重建误差界和解码错误概率界。

Result: 在合成噪声和真实噪声基准数据集上，所提方法在保证失真性能的同时，实现了显著一致的感知质量提升。

Conclusion: 基于生成压缩的去噪框架在结构细节保留和感知逼真性方面表现优异，在复杂噪声环境和分布漂移下仍具优势，具有广泛应用潜力。

Abstract: Image denoising aims to remove noise while preserving structural details and perceptual realism, yet distortion-driven methods often produce over-smoothed reconstructions, especially under strong noise and distribution shift. This paper proposes a generative compression framework for perception-based denoising, where restoration is achieved by reconstructing from entropy-coded latent representations that enforce low-complexity structure, while generative decoders recover realistic textures via perceptual measures such as learned perceptual image patch similarity (LPIPS) loss and Wasserstein distance. Two complementary instantiations are introduced: (i) a conditional Wasserstein GAN (WGAN)-based compression denoiser that explicitly controls the rate-distortion-perception (RDP) trade-off, and (ii) a conditional diffusion-based reconstruction strategy that performs iterative denoising guided by compressed latents. We further establish non-asymptotic guarantees for the compression-based maximum-likelihood denoiser under additive Gaussian noise, including bounds on reconstruction error and decoding error probability. Experiments on synthetic and real-noise benchmarks demonstrate consistent perceptual improvements while maintaining competitive distortion performance.

</details>


### [22] [LUVE : Latent-Cascaded Ultra-High-Resolution Video Generation with Dual Frequency Experts](https://arxiv.org/abs/2602.11564)
*Chen Zhao,Jiawei Chen,Hongyu Li,Zhuoliang Kang,Shilin Lu,Xiaoming Wei,Kai Zhang,Jian Yang,Ying Tai*

Main category: cs.CV

TL;DR: 本文提出了一种名为LUVE的新型超高分辨率视频生成框架，通过三阶段结构和双频专家机制，显著提升了视频生成的质量和细节。


<details>
  <summary>Details</summary>
Motivation: 尽管现有视频扩散模型在视觉质量上有显著提升，但生成超高分辨率视频仍受限于运动建模、语义规划和细节合成的多重困难。

Method: LUVE框架采用三级架构：（1）低分辨率运动生成阶段实现运动一致的潜在合成；（2）在潜空间内进行视频上采样，有效缓解内存和计算压力；（3）高分辨率内容细化阶段利用低频和高频专家，分别提升语义一致性和细节生成能力。

Result: 大量实验证明，LUVE在超高分辨率视频生成中具有更佳的真实感和内容保真度；消融实验进一步验证了各组件的有效性。

Conclusion: LUVE为超高分辨率视频生成提供了新的解决思路，兼顾了语义和细节的高质量表现，并在实验中优于现有方法。

Abstract: Recent advances in video diffusion models have significantly improved visual quality, yet ultra-high-resolution (UHR) video generation remains a formidable challenge due to the compounded difficulties of motion modeling, semantic planning, and detail synthesis. To address these limitations, we propose \textbf{LUVE}, a \textbf{L}atent-cascaded \textbf{U}HR \textbf{V}ideo generation framework built upon dual frequency \textbf{E}xperts. LUVE employs a three-stage architecture comprising low-resolution motion generation for motion-consistent latent synthesis, video latent upsampling that performs resolution upsampling directly in the latent space to mitigate memory and computational overhead, and high-resolution content refinement that integrates low-frequency and high-frequency experts to jointly enhance semantic coherence and fine-grained detail generation. Extensive experiments demonstrate that our LUVE achieves superior photorealism and content fidelity in UHR video generation, and comprehensive ablation studies further validate the effectiveness of each component. The project is available at \href{https://unicornanrocinu.github.io/LUVE_web/}{https://github.io/LUVE/}.

</details>


### [23] [Move What Matters: Parameter-Efficient Domain Adaptation via Optimal Transport Flow for Collaborative Perception](https://arxiv.org/abs/2602.11565)
*Zesheng Jia,Jin Wang,Siao Liu,Lingzhi Li,Ziyao Huang,Yunjiang Xu,Jianping Wang*

Main category: cs.CV

TL;DR: 本文提出了FlowAdapt框架，在V2X多智能体协同感知领域实现了高效的参数节省型领域自适应，并在多个基准测试中达到了最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有的参数高效微调方法（如自然语言处理和视觉任务中广泛应用的PEFT）在多智能体场景中的域自适应中效果不佳，存在性能下降和训练不稳定等问题。因此需要新的方法提升V2X协同感知的领域适应能力。

Method: 作者提出了FlowAdapt框架，基于最优传输理论，最小化不同数据分布和网络层次间的信息传输成本。具体包括：1）Wasserstein贪心采样策略，用覆盖半径过滤冗余样本；2）渐进式知识迁移模块，将初始特征压缩后通过可学习路径逐步注入到深层网络中，缓解后期微调时的语义降解。

Result: 在3个公开基准上进行大量实验证实，FlowAdapt在仅需1%可训练参数的情况下实现了最优的领域迁移性能，且在样本效率和泛化能力上均优于现有方法。

Conclusion: FlowAdapt有效解决了多智能体V2X协同感知领域适应中的效率和性能难题，在实际部署时具备重要的应用潜力和推广价值。

Abstract: Fast domain adaptation remains a fundamental challenge for deploying multi-agent systems across diverse environments in Vehicle-to-Everything (V2X) collaborative perception. Despite the success of Parameter-Efficient Fine-Tuning (PEFT) in natural language processing and conventional vision tasks, directly applying PEFT to multi-agent settings leads to significant performance degradation and training instability. In this work, we conduct a detailed analysis and identify two key factors: (i) inter-frame redundancy in heterogeneous sensory streams, and (ii) erosion of fine-grained semantics in deep-layer representations under PEFT adaptation. To address these issues, we propose FlowAdapt, a parameter-efficient framework grounded in optimal transport theory, which minimizes information transport costs across both data distributions and network hierarchies. Specifically, we introduce a Wasserstein Greedy Sampling strategy to selectively filter redundant samples via a bounded covering radius. Furthermore, Progressive Knowledge Transfer module is designed to progressively inject compressed early-stage representations into later stages through learnable pathways, alleviating semantic degradation in late-stage adaptation. Extensive experiments on three benchmarks demonstrate that FlowAdapt achieves state-of-the-art performance with only 1% of trainable parameters, effectively bridging domain gaps with superior sample efficiency and generalization.

</details>


### [24] [A Large Language Model for Disaster Structural Reconnaissance Summarization](https://arxiv.org/abs/2602.11588)
*Yuqing Gao,Guanren Zhou,Khalid M. Mosalam*

Main category: cs.CV

TL;DR: 本文提出了一种结合大型语言模型（LLM）的视觉化结构健康监测（SHM）新框架，可自动分析灾后建筑结构状态，生成结构受损总结报告。


<details>
  <summary>Details</summary>
Motivation: 当前基于AI的视觉化SHM系统主要输出离散的损伤分类标签和定位信息，需要工程师额外整理分析，影响灾后评估和决策效率。LLM的发展为视觉化SHM带来了新的智能处理能力。

Method: 提出LLM-DRS框架：1）设计标准化灾害勘察流程，现场收集图像与文本元数据；2）用深度卷积神经网络（CNN）提取损伤状态、材料类型、损伤程度等结构属性；3）将这些数据与元数据融合，通过精心设计的提示输入LLM，自动生成结构或区域的损伤总结报告。

Result: 结果显示，LLM与视觉化SHM的融合，特别针对灾后快速勘察，能够高效生成总结报告，提升灾害后响应和环境韧性。

Conclusion: 集成LLM的视觉化结构健康监测，能够显著提升灾后勘察效率和准确性，对增强建筑环境韧性具有潜力和应用前景。

Abstract: Artificial Intelligence (AI)-aided vision-based Structural Health Monitoring (SHM) has emerged as an effective approach for monitoring and assessing structural condition by analyzing image and video data. By integrating Computer Vision (CV) and Deep Learning (DL), vision-based SHM can automatically identify and localize visual patterns associated with structural damage. However, previous works typically generate only discrete outputs, such as damage class labels and damage region coordinates, requiring engineers to further reorganize and analyze these results for evaluation and decision-making. In late 2022, Large Language Models (LLMs) became popular across multiple fields, providing new insights into AI-aided vision-based SHM. In this study, a novel LLM-based Disaster Reconnaissance Summarization (LLM-DRS) framework is proposed. It introduces a standard reconnaissance plan in which the collection of vision data and corresponding metadata follows a well-designed on-site investigation process. Text-based metadata and image-based vision data are then processed and integrated into a unified format, where well-trained Deep Convolutional Neural Networks extract key attributes, including damage state, material type, and damage level. Finally, all data are fed into an LLM with carefully designed prompts, enabling the LLM-DRS to generate summary reports for individual structures or affected regions based on aggregated attributes and metadata. Results show that integrating LLMs into vision-based SHM, particularly for rapid post-disaster reconnaissance, demonstrates promising potential for improving resilience of the built environment through effective reconnaissance.

</details>


### [25] [PLOT-CT: Pre-log Voronoi Decomposition Assisted Generation for Low-dose CT Reconstruction](https://arxiv.org/abs/2602.11625)
*Bin Huang,Xun Yu,Yikun Zhang,Yi Zhang,Yang Chen,Qiegen Liu*

Main category: cs.CV

TL;DR: 本文提出了一种针对低剂量CT成像噪声大和数据精度受损问题的新方法，通过对原始（pre-log）投影数据进行Voronoi分解，有效分离噪声和重要结构信息，从而实现更高质量的重建。


<details>
  <summary>Details</summary>
Motivation: 低剂量CT由于减少辐射导致成像噪声显著增加，现有方法在成像或对数投影域操作，难以兼顾抗噪和信息保留，且对数变换本身会进一步放大噪声。因此亟需能在保留更多原始数据结构信息的同时，有效抑制噪声的方法。

Method: 提出PLOT-CT方法：首先对原始pre-log sinogram数据进行Voronoi分解，将其分解为不同的底层成分，并分别嵌入到不同的潜在空间。通过显式分解，增强模型区分特征的能力，有效降低噪声干扰，提高重建精度。

Result: 与传统方法相比，PLOT-CT在pre-log域下，将PSNR提升2.36dB（以1e4入射光子为例），显示出在抗噪和信息还原上的明显优势。

Conclusion: PLOT-CT利用Voronoi分解充分挖掘pre-log域结构信息，显著提升低剂量CT重建质量，优于现有主流方案。

Abstract: Low-dose computed tomography (LDCT) reconstruction is fundamentally challenged by severe noise and compromised data fidelity under reduced radiation exposure. Most existing methods operate either in the image or post-log projection domain, which fails to fully exploit the rich structural information in pre-log measurements while being highly susceptible to noise. The requisite logarithmic transformation critically amplifies noise within these data, imposing exceptional demands on reconstruction precision. To overcome these challenges, we propose PLOT-CT, a novel framework for Pre-Log vOronoi decomposiTion-assisted CT generation. Our method begins by applying Voronoi decomposition to pre-log sinograms, disentangling the data into distinct underlying components, which are embedded in separate latent spaces. This explicit decomposition significantly enhances the model's capacity to learn discriminative features, directly improving reconstruction accuracy by mitigating noise and preserving information inherent in the pre-log domain. Extensive experiments demonstrate that PLOT-CT achieves state-of-the-art performance, attaining a 2.36dB PSNR improvement over traditional methods at the 1e4 incident photon level in the pre-log domain.

</details>


### [26] [PLESS: Pseudo-Label Enhancement with Spreading Scribbles for Weakly Supervised Segmentation](https://arxiv.org/abs/2602.11628)
*Yeva Gabrielyan,Varduhi Yeghiazaryan,Irina Voiculescu*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的伪标签增强策略（PLESS），用于提高弱监督的涂鸦标注医学图像分割性能，能在现有伪标签方法中带来一致性的精度提升。


<details>
  <summary>Details</summary>
Motivation: 传统医学图像分割需要大量像素级精确标注，成本高昂。近年来涂鸦注释通过用稀疏用户绘制的线条指示部分标签，虽然减轻了标签负担，但监督存在噪声和信息不全问题，限制了伪标签方法的效果。因此，亟需提升伪标签的可靠性和空间一致性的策略以改善分割性能。

Method: 提出了基于分层分区的伪标签增强策略PLESS。具体做法是将图像划分为层次结构的空间连贯区域，在每个语义上一致的区域内利用涂鸦信息传播并精细化伪标签。该策略独立于具体模型，易于集成到现有伪标签训练流程中。

Result: 在两个人体心脏MRI公开数据集（ACDC与MSCMRseg）上的四种主流涂鸦监督分割算法实验，集成PLESS后分割精度均实现了明显提升。

Conclusion: PLESS可作为一种通用、模型无关的工具，显著增强涂鸦弱监督分割中的伪标签质量，提升医学图像分割的准确性。

Abstract: Weakly supervised learning with scribble annotations uses sparse user-drawn strokes to indicate segmentation labels on a small subset of pixels. This annotation reduces the cost of dense pixel-wise labeling, but suffers inherently from noisy and incomplete supervision. Recent scribble-based approaches in medical image segmentation address this limitation using pseudo-label-based training; however, the quality of the pseudo-labels remains a key performance limit. We propose PLESS, a generic pseudo-label enhancement strategy which improves reliability and spatial consistency. It builds on a hierarchical partitioning of the image into a hierarchy of spatially coherent regions. PLESS propagates scribble information to refine pseudo-labels within semantically coherent regions. The framework is model-agnostic and easily integrates into existing pseudo-label methods. Experiments on two public cardiac MRI datasets (ACDC and MSCMRseg) across four scribble-supervised algorithms show consistent improvements in segmentation accuracy. Code will be made available on GitHub upon acceptance.

</details>


### [27] [ScalSelect: Scalable Training-Free Multimodal Data Selection for Efficient Visual Instruction Tuning](https://arxiv.org/abs/2602.11636)
*Changti Wu,Jiahuai Mao,Yuzhuo Miao,Shijie Lian,Bin Yu,Xiaopeng Lin,Cong Huang,Lei Zhang,Kai Chen*

Main category: cs.CV

TL;DR: 提出了一种高效的多模态数据选择方法ScalSelect，仅用16%的数据即可达到原始全量数据97.5%的训练效果，甚至部分场景提升表现。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型（VLMs）的视觉指令微调(VIT)需要巨量数据，导致训练成本高且存在冗余。多模态数据选择方法有望提升训练效率，但现有方法要么计算开销大，要么依赖外部资源，难以大规模应用。

Method: ScalSelect是一种无需训练、无需外部模型或数据集的多模态数据选择方法，复杂度为线性级别。其方法是通过提取指令token关注的视觉特征，构建样本表示，再选择能够代表全数据集主成分子空间的样本，从而实现高效重要性打分和数据选择，无需两两比较。

Result: 在多个VLM、数据集和预算设置下实验，ScalSelect仅取用16%的数据，在模型性能上可达到全数据训练的97.5%，某些情况下还优于全数据训练。

Conclusion: ScalSelect大幅度提升了大规模视觉语言模型指令微调的数据利用效率，是一种高效、可扩展、实际可用的新方法。

Abstract: Large-scale Visual Instruction Tuning (VIT) has become a key paradigm for advancing the performance of vision-language models (VLMs) across various multimodal tasks. However, training on the large-scale datasets is computationally expensive and inefficient due to redundancy in the data, which motivates the need for multimodal data selection to improve training efficiency. Existing data selection methods for VIT either require costly training or gradient computation. Training-free alternatives often depend on proxy models or datasets, instruction-agnostic representations, and pairwise similarity with quadratic complexity, limiting scalability and representation fidelity. In this work, we propose ScalSelect, a scalable training-free multimodal data selection method with linear-time complexity with respect to the number of samples, eliminating the need for external models or auxiliary datasets. ScalSelect first constructs sample representations by extracting visual features most attended by instruction tokens in the target VLM, capturing instruction-relevant information. It then identifies samples whose representations best approximate the dominant subspace of the full dataset representations, enabling scalable importance scoring without pairwise comparisons. Extensive experiments across multiple VLMs, datasets, and selection budgets demonstrate that ScalSelect achieves over 97.5% of the performance of training on the full dataset using only 16% of the data, and even outperforms full-data training in some settings. The code is available at \href{https://github.com/ChangtiWu/ScalSelect}{ScalSelect}.

</details>


### [28] [Electrostatics-Inspired Surface Reconstruction (EISR): Recovering 3D Shapes as a Superposition of Poisson's PDE Solutions](https://arxiv.org/abs/2602.11642)
*Diego Patiño,Knut Peterson,Kostas Daniilidis,David K. Han*

Main category: cs.CV

TL;DR: 该论文提出了一种基于泊松方程的隐式三维形状重建方法，利用格林函数得到PDE的解析解，并能更好地逼近高频细节。


<details>
  <summary>Details</summary>
Motivation: 传统的隐式表面重建多采用SDF和Eikonal方程，存在对高频细节捕捉受限的问题。本文希望通过不同的PDE建模方式改进这一不足。

Method: 将三维形状表面重建问题转化为求解一个代理PDE——泊松方程，通过和物理中电势的关系引入格林函数，得到封闭解析表达式，并利用线性叠加原理，将目标隐式场表示为解的叠加。

Result: 即便仅用少量的先验形状，所提方法在高频细节的逼近方面表现更佳。

Conclusion: 泊松方程作为代理PDE为隐式表面重建提供了新的有效方法，特别适合捕捉高频细节，并且解析表达式带来计算和表达的便利。

Abstract: Implicit shape representation, such as SDFs, is a popular approach to recover the surface of a 3D shape as the level sets of a scalar field. Several methods approximate SDFs using machine learning strategies that exploit the knowledge that SDFs are solutions of the Eikonal partial differential equation (PDEs). In this work, we present a novel approach to surface reconstruction by encoding it as a solution to a proxy PDE, namely Poisson's equation. Then, we explore the connection between Poisson's equation and physics, e.g., the electrostatic potential due to a positive charge density. We employ Green's functions to obtain a closed-form parametric expression for the PDE's solution, and leverage the linearity of our proxy PDE to find the target shape's implicit field as a superposition of solutions. Our method shows improved results in approximating high-frequency details, even with a small number of shape priors.

</details>


### [29] [Brain Tumor Classifiers Under Attack: Robustness of ResNet Variants Against Transferable FGSM and PGD Attacks](https://arxiv.org/abs/2602.11646)
*Ryan Deem,Garrett Goodman,Waqas Majeed,Md Abdullah Al Hafiz Khan,Michail S. Alexiou*

Main category: cs.CV

TL;DR: 本论文分析了基于ResNet的神经网络在脑肿瘤MRI图像分类中的对抗鲁棒性，并比较了多种架构和预处理下模型对抗攻击的表现。结果显示网络结构、输入分辨率和数据增强等因素显著影响模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在脑肿瘤MRI分类任务中，深度学习模型面临对抗攻击的威胁，但相关鲁棒性研究较少，而实际医疗场景下安全性至关重要。因此，需系统评估分类准确性和对抗鲁棒性。

Method: 作者构建了三类基于ResNet的模型（BrainNet、BrainNeXt和DilationNet），并通过全尺寸增强、缩小增强、缩小未增强三种数据预处理，对其在FGSM和PGD两种对抗攻击下的鲁棒性进行测试和比较。

Result: BrainNeXt结构在黑盒攻击下展现出最高鲁棒性，但生成的对抗样本可转移性较弱；BrainNet和DilationNet在PGD攻击下互相更易被攻破，尤其是在高步数和大α值情况下。输入分辨率降低或缺乏数据增强会显著削弱模型鲁棒性。

Conclusion: 分类性能与对抗鲁棒性需要同时评估，尤其在临床应用中。仅追求提升测试集准确率可能掩盖模型对抗脆弱性，鲁棒性测试与合理的输入预处理同等重要。

Abstract: Adversarial robustness in deep learning models for brain tumor classification remains an underexplored yet critical challenge, particularly for clinical deployment scenarios involving MRI data. In this work, we investigate the susceptibility and resilience of several ResNet-based architectures, referred to as BrainNet, BrainNeXt and DilationNet, against gradient-based adversarial attacks, namely FGSM and PGD. These models, based on ResNet, ResNeXt, and dilated ResNet variants respectively, are evaluated across three preprocessing configurations (i) full-sized augmented, (ii) shrunk augmented and (iii) shrunk non-augmented MRI datasets. Our experiments reveal that BrainNeXt models exhibit the highest robustness to black-box attacks, likely due to their increased cardinality, though they produce weaker transferable adversarial samples. In contrast, BrainNet and Dilation models are more vulnerable to attacks from each other, especially under PGD with higher iteration steps and $α$ values. Notably, shrunk and non-augmented data significantly reduce model resilience, even when the untampered test accuracy remains high, highlighting a key trade-off between input resolution and adversarial vulnerability. These results underscore the importance of jointly evaluating classification performance and adversarial robustness for reliable real-world deployment in brain MRI analysis.

</details>


### [30] [GR-Diffusion: 3D Gaussian Representation Meets Diffusion in Whole-Body PET Reconstruction](https://arxiv.org/abs/2602.11653)
*Mengxiao Geng,Zijie Chen,Ran Hong,Bingxuan Li,Qiegen Liu*

Main category: cs.CV

TL;DR: 本文提出了一种结合三维高斯表示（GR）和扩散模型的GR-Diffusion框架，有效提升了低剂量全身PET重建的图像质量。


<details>
  <summary>Details</summary>
Motivation: 传统PET重建在采样稀疏和逆问题病态下，常出现噪声放大、结构模糊和细节丢失；现有方法难以兼顾结构准确性和精细信息恢复。

Method: 创新性地结合三维离散高斯表示（GR）的几何先验和生成式扩散模型。首先用GR从投影数据生成具有物理基础和结构显式的参考3D PET图像，在扩散过程中用于粗细双重指导，实现全局一致性和局部精度。细粒度指导通过差分细化局部细节，粗粒度用多尺度差值校正偏差。

Result: 在UDPET和临床数据集，以及不同剂量水平下，GR-Diffusion均优于目前主流方法，提升了3D全身PET图像质量并更好地保留了生理细节。

Conclusion: GR-Diffusion框架通过物理结构化先验和分层指导，有效克服了传统方法的低通局限和细节缺失问题，是提升低剂量全身PET重建质量的有前景方法。

Abstract: Positron emission tomography (PET) reconstruction is a critical challenge in molecular imaging, often hampered by noise amplification, structural blurring, and detail loss due to sparse sampling and the ill-posed nature of inverse problems. The three-dimensional discrete Gaussian representation (GR), which efficiently encodes 3D scenes using parameterized discrete Gaussian distributions, has shown promise in computer vision. In this work, we pro-pose a novel GR-Diffusion framework that synergistically integrates the geometric priors of GR with the generative power of diffusion models for 3D low-dose whole-body PET reconstruction. GR-Diffusion employs GR to generate a reference 3D PET image from projection data, establishing a physically grounded and structurally explicit benchmark that overcomes the low-pass limitations of conventional point-based or voxel-based methods. This reference image serves as a dual guide during the diffusion process, ensuring both global consistency and local accuracy. Specifically, we employ a hierarchical guidance mechanism based on the GR reference. Fine-grained guidance leverages differences to refine local details, while coarse-grained guidance uses multi-scale difference maps to correct deviations. This strategy allows the diffusion model to sequentially integrate the strong geometric prior from GR and recover sub-voxel information. Experimental results on the UDPET and Clinical datasets with varying dose levels show that GR-Diffusion outperforms state-of-the-art methods in enhancing 3D whole-body PET image quality and preserving physiological details.

</details>


### [31] [SToRM: Supervised Token Reduction for Multi-modal LLMs toward efficient end-to-end autonomous driving](https://arxiv.org/abs/2602.11656)
*Seo Hyun Kim,Jin Bok Park,Do Yeon Koo,Ho Gun Park,Il Yong Chun*

Main category: cs.CV

TL;DR: 本文提出了一种高效的多模态大模型视觉Token压缩方法，能够在降低算力消耗的同时保持端到端自动驾驶系统的性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大模型（MLLM）在自动驾驶中的人车交互和安全场景应对上显示出优势，但需要大量算力，限制了其在自动驾驶车辆内的落地，特别是如何在减少视觉Token输入的同时，不损失下游任务的性能。

Method: 作者提出了Supervised Token Reduction（SToRM）框架，包括：（1）轻量级的重要性预测器，通过滑动窗口对Token打分；（2）监督式训练路径，借助全Token推理路径获得伪监督信号指导Token压缩；（3）锚点-上下文合并模块，将Token划分为锚点和上下文，将上下文Token融合进锚点，从而减少冗余信息。

Result: 在LangAuto自动驾驶多模态任务上，SToRM在相同Token预算下，性能优于现有SOTA方法，同时算力消耗降低最高达30倍，并且几乎无性能损失。

Conclusion: SToRM为端到端自动驾驶中的多模态大模型压缩提供了兼具高效与高性能的新方法，有望增进多模态对话和感知功能在实际自动驾驶中的推广。

Abstract: In autonomous driving, end-to-end (E2E) driving systems that predict control commands directly from sensor data have achieved significant advancements. For safe driving in unexpected scenarios, these systems may additionally rely on human interventions such as natural language instructions. Using a multi-modal large language model (MLLM) facilitates human-vehicle interaction and can improve performance in such scenarios. However, this approach requires substantial computational resources due to its reliance on an LLM and numerous visual tokens from sensor inputs, which are limited in autonomous vehicles. Many MLLM studies have explored reducing visual tokens, but often suffer end-task performance degradation compared to using all tokens.
  To enable efficient E2E driving while maintaining performance comparable to using all tokens, this paper proposes the first Supervised Token Reduction framework for multi-modal LLMs (SToRM). The proposed framework consists of three key elements. First, a lightweight importance predictor with short-term sliding windows estimates token importance scores. Second, a supervised training approach uses an auxiliary path to obtain pseudo-supervision signals from an all-token LLM pass. Third, an anchor-context merging module partitions tokens into anchors and context tokens, and merges context tokens into relevant anchors to reduce redundancy while minimizing information loss. Experiments on the LangAuto benchmark show that SToRM outperforms state-of-the-art E2E driving MLLMs under the same reduced-token budget, maintaining all-token performance while reducing computational cost by up to 30x.

</details>


### [32] [EmoSpace: Fine-Grained Emotion Prototype Learning for Immersive Affective Content Generation](https://arxiv.org/abs/2602.11658)
*Bingyuan Wang,Xingbei Chen,Zongyang Qiu,Linping Yuan,Zeyu Wang*

Main category: cs.CV

TL;DR: EmoSpace是一种新颖的情感感知内容生成框架，通过视觉与语言的对齐学习动态、可解释的情感原型，实现了对情感丰富内容的精细控制，提升了VR内容生成的沉浸感和表现力。


<details>
  <summary>Details</summary>
Motivation: 现有生成式方法难以捕捉情感语义的细微差别和细粒度的控制，限制了虚拟现实内容的沉浸感和表现效果，因此亟需一种方法能够更好地理解和操控情感元素。

Method: EmoSpace框架采用层次化的情感表示，借助丰富且可学习的原型，这些原型在训练中动态演化，无需显式情感标签。其生成流程集成了多原型引导、时序融合及注意力权重调整，并可应用于多种情感视觉生成场景。

Result: 实验表明，EmoSpace在定性与定量评测上都优于现有同类方法。并通过用户研究调查了VR与桌面环境对情感感知的影响。

Conclusion: EmoSpace能实现精细的情感视觉内容生成，拓展了VR等领域的应用场景，如治疗、教育、叙事、创作等，并提升了虚拟内容的情感表现能力。

Abstract: Emotion is important for creating compelling virtual reality (VR) content. Although some generative methods have been applied to lower the barrier to creating emotionally rich content, they fail to capture the nuanced emotional semantics and the fine-grained control essential for immersive experiences. To address these limitations, we introduce EmoSpace, a novel framework for emotion-aware content generation that learns dynamic, interpretable emotion prototypes through vision-language alignment. We employ a hierarchical emotion representation with rich learnable prototypes that evolve during training, enabling fine-grained emotional control without requiring explicit emotion labels. We develop a controllable generation pipeline featuring multi-prototype guidance, temporal blending, and attention reweighting that supports diverse applications, including emotional image outpainting, stylized generation, and emotional panorama generation for VR environments. Our experiments demonstrate the superior performance of EmoSpace over existing methods in both qualitative and quantitative evaluations. Additionally, we present a comprehensive user study investigating how VR environments affect emotional perception compared to desktop settings. Our work facilitates immersive visual content generation with fine-grained emotion control and supports applications like therapy, education, storytelling, artistic creation, and cultural preservation. Code and models will be made publicly available.

</details>


### [33] [Clutt3R-Seg: Sparse-view 3D Instance Segmentation for Language-grounded Grasping in Cluttered Scenes](https://arxiv.org/abs/2602.11660)
*Jeongho Noh,Tai Hyoung Rhee,Eunho Lee,Jeongyun Kim,Sunwoo Lee,Ayoung Kim*

Main category: cs.CV

TL;DR: 本论文提出了Clutt3R-Seg，一种面向语言指导抓取任务、适用于杂乱环境下的零样本3D实例分割方法。其创新性在于利用语义层次树结构，以跨视角分组和条件替换机制提升分割鲁棒性，大幅优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在复杂杂乱环境中进行机器人操作时，3D实例分割受到遮挡、视角受限和遮罩噪音等问题困扰，严重影响基于语言的目标选取和操作效果，因此迫切需要鲁棒、泛化性强的方法。

Method: 作者提出了引入语义线索的层次实例树结构，通过跨视角组合及条件替换策略，将噪声分割结果作为有用线索，抑制过分割和欠分割，得到一致的3D实例分割结果，并用开放词汇语义嵌入增强指令理解。此外，针对多阶段任务设计了一种一致性更新机制，只需一次交互后的图像便可高效保持目标一致性。

Result: 在合成与真实数据集及真实机器人实验中，Clutt3R-Seg在多项指标上均显著超越现有方法。在最难的高度杂乱任务下，AP@25达61.66（超过基线方法2.2倍），且仅需4视角输入即优于MaskClustering在8视角下的结果。

Conclusion: Clutt3R-Seg大幅提升了复杂场景下3D目标分割和语言理解结合的能力，为机器人抓取等任务提供了更强的鲁棒性和适应性，展现出广泛的应用前景。

Abstract: Reliable 3D instance segmentation is fundamental to language-grounded robotic manipulation. Its critical application lies in cluttered environments, where occlusions, limited viewpoints, and noisy masks degrade perception. To address these challenges, we present Clutt3R-Seg, a zero-shot pipeline for robust 3D instance segmentation for language-grounded grasping in cluttered scenes. Our key idea is to introduce a hierarchical instance tree of semantic cues. Unlike prior approaches that attempt to refine noisy masks, our method leverages them as informative cues: through cross-view grouping and conditional substitution, the tree suppresses over- and under-segmentation, yielding view-consistent masks and robust 3D instances. Each instance is enriched with open-vocabulary semantic embeddings, enabling accurate target selection from natural language instructions. To handle scene changes during multi-stage tasks, we further introduce a consistency-aware update that preserves instance correspondences from only a single post-interaction image, allowing efficient adaptation without rescanning. Clutt3R-Seg is evaluated on both synthetic and real-world datasets, and validated on a real robot. Across all settings, it consistently outperforms state-of-the-art baselines in cluttered and sparse-view scenarios. Even on the most challenging heavy-clutter sequences, Clutt3R-Seg achieves an AP@25 of 61.66, over 2.2x higher than baselines, and with only four input views it surpasses MaskClustering with eight views by more than 2x. The code is available at: https://github.com/jeonghonoh/clutt3r-seg.

</details>


### [34] [Egocentric Gaze Estimation via Neck-Mounted Camera](https://arxiv.org/abs/2602.11669)
*Haoyu Huang,Yoichi Sato*

Main category: cs.CV

TL;DR: 本文提出了一种基于颈部佩戴相机的新型注视估计任务，采集了相关数据集，并验证了多种方法在该任务下的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的主观视角注视估计主要依赖头戴式相机，其他视角（如颈部摄像）研究不足。因此需要探索颈部相机视角下的注视估计方法。

Method: 采集了8名参与者、约4小时的日常活动颈部摄像数据集，采用Transformer结构的注视估计模型（GLC），并提出辅助的超视野分类和多视角共学习等扩展方法。

Result: 加入注视超视野分类辅助任务后，模型性能优于标准微调；多视角共学习未带来提升。

Conclusion: 辅助任务能有效提升颈部佩戴相机下注视估计效果，但多视角共学习在该任务上当前无显著益处。

Abstract: This paper introduces neck-mounted view gaze estimation, a new task that estimates user gaze from the neck-mounted camera perspective. Prior work on egocentric gaze estimation, which predicts device wearer's gaze location within the camera's field of view, mainly focuses on head-mounted cameras while alternative viewpoints remain underexplored. To bridge this gap, we collect the first dataset for this task, consisting of approximately 4 hours of video collected from 8 participants during everyday activities. We evaluate a transformer-based gaze estimation model, GLC, on the new dataset and propose two extensions: an auxiliary gaze out-of-bound classification task and a multi-view co-learning approach that jointly trains head-view and neck-view models using a geometry-aware auxiliary loss. Experimental results show that incorporating gaze out-of-bound classification improves performance over standard fine-tuning, while the co-learning approach does not yield gains. We further analyze these results and discuss implications for neck-mounted gaze estimation.

</details>


### [35] [U-Net with Hadamard Transform and DCT Latent Spaces for Next-day Wildfire Spread Prediction](https://arxiv.org/abs/2602.11672)
*Yingyi Luo,Shuaiang Rong,Adam Watts,Ahmet Enis Cetin*

Main category: cs.CV

TL;DR: 本文提出了一种新型轻量级深度学习工具TD-FusionUNet，用于次日野火蔓延预测，结合多模态卫星数据和变换域融合，提高了准确率且大幅减少模型参数量。


<details>
  <summary>Details</summary>
Motivation: 当前野火蔓延预测需要高效且轻量的模型以适应资源受限环境，而现有方法往往准确率与计算效率难以兼顾。本研究旨在开发能高效处理多源卫星数据、同时保持高性能的实时野火预报模型。

Method: 提出了TD-FusionUNet模型，将Hadamard变换和离散余弦变换嵌入UNet结构，捕获潜在空间中的正交频率特征。引入自定义预处理（随机边缘裁剪、高斯混合建模）来增强稀疏先前火区掩膜的表达能力并提升泛化性。模型在两大野火数据集上进行评估。

Result: TD-FusionUNet在Next-Day Wildfire Spread和WildfireSpreadTS数据集上取得了F1 score 0.591（仅用37万参数），在WildfireSpreadTS上超越以ResNet18为编码器的UNet基线，并显著减少模型参数。

Conclusion: TD-FusionUNet具备准确与高效的平衡，能在资源受限的环境下实现高性能实时野火预测，具有广泛应用前景。

Abstract: We developed a lightweight and computationally efficient tool for next-day wildfire spread prediction using multimodal satellite data as input. The deep learning model, which we call Transform Domain Fusion UNet (TD-FusionUNet), incorporates trainable Hadamard Transform and Discrete Cosine Transform layers that apply two-dimensional transforms, enabling the network to capture essential "frequency" components in orthogonalized latent spaces. Additionally, we introduce custom preprocessing techniques, including random margin cropping and a Gaussian mixture model, to enrich the representation of the sparse pre-fire masks and enhance the model's generalization capability. The TD-FusionUNet is evaluated on two datasets which are the Next-Day Wildfire Spread dataset released by Google Research in 2023, and WildfireSpreadTS dataset. Our proposed TD-FusionUNet achieves an F1 score of 0.591 with 370k parameters, outperforming the UNet baseline using ResNet18 as the encoder reported in the WildfireSpreadTS dataset while using substantially fewer parameters. These results show that the proposed latent space fusion model balances accuracy and efficiency under a lightweight setting, making it suitable for real time wildfire prediction applications in resource limited environments.

</details>


### [36] [LLM-Driven 3D Scene Generation of Agricultural Simulation Environments](https://arxiv.org/abs/2602.11706)
*Arafa Yoncalik,Wouter Jansen,Nico Huebel,Mohammad Hasan Rahmani,Jan Steckel*

Main category: cs.CV

TL;DR: 本文提出了一种基于多大型语言模型（multi-LLM）的模块化流程，从自然语言提示自动生成农业领域的合成3D仿真环境，实现了更高效率、灵活性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的3D场景生成方法在领域专用推理、验证机制和模块化设计上存在不足，导致控制力和可扩展性有限。农业仿真环境需高度真实且专业，常规方法很难自动化高质量场景生成。

Method: 提出并实现了一个模块化多LLM流程，将3D素材检索、领域知识注入和针对Unreal引擎的代码生成进行有机集成。采用少样本提示、RAG、微调、结果验证等多种LLM优化方法，形成混合策略，提升系统的准确性和扩展性。

Result: 系统能够根据结构化提示高效生成包含现实感种植布局和环境语境的3D场景。语义指标和用户研究表明，自动化场景的真实感和熟悉度均较高。专家评测显示该方法较人工设计大幅节省时间。

Conclusion: 多-LLM模块化流程可有效自动化生成具有专业属性的3D仿真环境，可靠性和精度均优于传统做法。未来将扩展素材层级、支持实时生成并推广到农业外的其他领域。

Abstract: Procedural generation techniques in 3D rendering engines have revolutionized the creation of complex environments, reducing reliance on manual design. Recent approaches using Large Language Models (LLMs) for 3D scene generation show promise but often lack domain-specific reasoning, verification mechanisms, and modular design. These limitations lead to reduced control and poor scalability. This paper investigates the use of LLMs to generate agricultural synthetic simulation environments from natural language prompts, specifically to address the limitations of lacking domain-specific reasoning, verification mechanisms, and modular design. A modular multi-LLM pipeline was developed, integrating 3D asset retrieval, domain knowledge injection, and code generation for the Unreal rendering engine using its API. This results in a 3D environment with realistic planting layouts and environmental context, all based on the input prompt and the domain knowledge. To enhance accuracy and scalability, the system employs a hybrid strategy combining LLM optimization techniques such as few-shot prompting, Retrieval-Augmented Generation (RAG), finetuning, and validation. Unlike monolithic models, the modular architecture enables structured data handling, intermediate verification, and flexible expansion. The system was evaluated using structured prompts and semantic accuracy metrics. A user study assessed realism and familiarity against real-world images, while an expert comparison demonstrated significant time savings over manual scene design. The results confirm the effectiveness of multi-LLM pipelines in automating domain-specific 3D scene generation with improved reliability and precision. Future work will explore expanding the asset hierarchy, incorporating real-time generation, and adapting the pipeline to other simulation domains beyond agriculture.

</details>


### [37] [RI-Mamba: Rotation-Invariant Mamba for Robust Text-to-Shape Retrieval](https://arxiv.org/abs/2602.11673)
*Khanh Nguyen,Dasith de Silva Edirimuni,Ghulam Mubashar Hassan,Ajmal Mian*

Main category: cs.CV

TL;DR: 本文提出了RI-Mamba，这是一种对三维点云具备旋转不变性的状态空间模型，用于提升基于文本的三维形状检索任务的精度与适应性，并在多类别、随意朝向的条件下取得领先性能。


<details>
  <summary>Details</summary>
Motivation: 当前虚拟现实和游戏领域促使三维资产数量激增。如何通过文本高效检索三维模型变得重要。但现有方法仅适合规范朝向且支持种类有限，难以满足多样复杂实际需求。

Method: 提出RI-Mamba模型，利用全局和局部参考系将姿态与几何结构解耦，并通过Hilbert排序生成具有几何意义且旋转不变的点云序列。在此基础上，引入新颖的方向嵌入重融机制，提升模型表达力，并采用自动三元组生成的跨模态对比学习，无需人工标注即可扩展训练数据。

Result: RI-Mamba在OmniObject3D基准上针对200多个类别、任意朝向的物体，展现出优异的特征表达能力和鲁棒性，取得了当前最优表现。

Conclusion: RI-Mamba成功实现了高效、旋转不变、适应多类别且无需人工标注的三维点云文本检索方法，有力推动了三维资产智能检索技术的发展。

Abstract: 3D assets have rapidly expanded in quantity and diversity due to the growing popularity of virtual reality and gaming. As a result, text-to-shape retrieval has become essential in facilitating intuitive search within large repositories. However, existing methods require canonical poses and support few object categories, limiting their real-world applicability where objects can belong to diverse classes and appear in random orientations. To address this challenge, we propose RI-Mamba, the first rotation-invariant state-space model for point clouds. RI-Mamba defines global and local reference frames to disentangle pose from geometry and uses Hilbert sorting to construct token sequences with meaningful geometric structure while maintaining rotation invariance. We further introduce a novel strategy to compute orientational embeddings and reintegrate them via feature-wise linear modulation, effectively recovering spatial context and enhancing model expressiveness. Our strategy is inherently compatible with state-space models and operates in linear time. To scale up retrieval, we adopt cross-modal contrastive learning with automated triplet generation, allowing training on diverse datasets without manual annotation. Extensive experiments demonstrate RI-Mamba's superior representational capacity and robustness, achieving state-of-the-art performance on the OmniObject3D benchmark across more than 200 object categories under arbitrary orientations. Our code will be made available at https://github.com/ndkhanh360/RI-Mamba.git.

</details>


### [38] [GSO-SLAM: Bidirectionally Coupled Gaussian Splatting and Direct Visual Odometry](https://arxiv.org/abs/2602.11714)
*Jiung Yeon,Seongbo Ha,Hyeonwoo Yu*

Main category: cs.CV

TL;DR: 本文提出GSO-SLAM，一种基于高斯场景表示的单目实时稠密SLAM系统，通过耦合视觉里程计和高斯渲染，有效提升建图和定位的效率与精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在建图与定位耦合上不是计算代价高，就是出现冗余。需要一种既高效又准确的方案，实现实时高质量的稠密单目SLAM。

Method: 提出将视觉里程计（VO）与高斯渲染（GS）进行双向耦合，并在EM优化框架下联合优化VO的半稠密深度估计与GS表示；同时，提出用VO提取的图像、关键帧位姿等进行高斯初始化而无需启发式方法。

Result: 实验表明该方法不仅支持实时运行，还能在重建的场景几何/光度保真度和跟踪精度上达到业界最优。

Conclusion: GSO-SLAM能高效地实现单目稠密SLAM，兼顾实时性、精度和鲁棒性，为高精度场景重建和追踪提供了新思路。

Abstract: We propose GSO-SLAM, a real-time monocular dense SLAM system that leverages Gaussian scene representation. Unlike existing methods that couple tracking and mapping with a unified scene, incurring computational costs, or loosely integrate them with well-structured tracking frameworks, introducing redundancies, our method bidirectionally couples Visual Odometry (VO) and Gaussian Splatting (GS). Specifically, our approach formulates joint optimization within an Expectation-Maximization (EM) framework, enabling the simultaneous refinement of VO-derived semi-dense depth estimates and the GS representation without additional computational overhead. Moreover, we present Gaussian Splat Initialization, which utilizes image information, keyframe poses, and pixel associations from VO to produce close approximations to the final Gaussian scene, thereby eliminating the need for heuristic methods. Through extensive experiments, we validate the effectiveness of our method, showing that it not only operates in real time but also achieves state-of-the-art geometric/photometric fidelity of the reconstructed scene and tracking accuracy.

</details>


### [39] [Semantically Conditioned Diffusion Models for Cerebral DSA Synthesis](https://arxiv.org/abs/2602.11703)
*Qiwen Xu,David Rügamer,Holger Wenz,Johann Fontana,Nora Meggyeshazi,Andreas Bender,Máté E. Maros*

Main category: cs.CV

TL;DR: 本文提出了一种通过语义条件控制的潜在扩散模型（LDM），能够生成高真实性的脑血管数字减影血管造影（DSA）影像，以克服实际数据采集难和共享受限的问题。


<details>
  <summary>Details</summary>
Motivation: 数字减影血管造影（DSA）虽然在脑血管疾病诊断和治疗中至关重要，但由于其创伤性和高昂的采集成本，限制了大规模数据的获取和公开分享。因此，迫切需要生成高质量的合成DSA图像以支持科研和算法开发。

Method: 作者整合了99,349帧单中心DSA数据，采用编码解剖和采集几何信息的文本嵌入，训练了一个条件潜在扩散模型（LDM），能够在明确控制解剖循环区域和C形臂位置下生成DSA影像。通过让四位医学专家对400张合成DSA图像进行Likert评分，并与真实影像分布进行对比评估其真实性。

Result: 合成影像在大型、介质及末梢血管结构的Likert评分为3.1~3.3分，且评分者间一致性高（ICC=0.80~0.87）；合成影像与真实DSA帧分布极为接近（中位FID=15.27）。

Conclusion: 语义条件控制的潜在扩散模型能够生成具有高度临床真实性的合成DSA影像，适用于下游算法开发、科学研究和医学培训等场景。

Abstract: Digital subtraction angiography (DSA) plays a central role in the diagnosis and treatment of cerebrovascular disease, yet its invasive nature and high acquisition cost severely limit large-scale data collection and public data sharing. Therefore, we developed a semantically conditioned latent diffusion model (LDM) that synthesizes arterial-phase cerebral DSA frames under explicit control of anatomical circulation (anterior vs.\ posterior) and canonical C-arm positions. We curated a large single-centre DSA dataset of 99,349 frames and trained a conditional LDM using text embeddings that encoded anatomy and acquisition geometry. To assess clinical realism, four medical experts, including two neuroradiologists, one neurosurgeon, and one internal medicine expert, systematically rated 400 synthetic DSA images using a 5-grade Likert scale for evaluating proximal large, medium, and small peripheral vessels. The generated images achieved image-wise overall Likert scores ranging from 3.1 to 3.3, with high inter-rater reliability (ICC(2,k) = 0.80--0.87). Distributional similarity to real DSA frames was supported by a low median Fréchet inception distance (FID) of 15.27. Our results indicate that semantically controlled LDMs can produce realistic synthetic DSAs suitable for downstream algorithm development, research, and training.

</details>


### [40] [JEPA-VLA: Video Predictive Embedding is Needed for VLA Models](https://arxiv.org/abs/2602.11832)
*Shangchen Miao,Ningya Feng,Jialong Wu,Ye Lin,Xu He,Dong Li,Mingsheng Long*

Main category: cs.CV

TL;DR: 该论文提出了一种通过集成预测型视觉嵌入，提升视觉-语言-动作（VLA）模型在机器人操作中的样本效率和泛化能力的方法，并在多个基准测试中取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 目前VLA模型尽管在机器人任务中取得了进展，但样本效率和泛化能力仍有限。作者认为主要原因在于当前视觉特征的预训练方式，无法充分获取与任务相关的环境信息以及政策先验知识，因此有必要探索更具预测性的视觉表示方式。

Method: 作者系统分析了主流视觉表征（包括语言图像对比学习和自监督学习）在VLA中的不足，提出利用基于视频的预测型嵌入（如V-JEPA 2），因为这些嵌入能灵活滤除不确定因素、编码任务相关的时序动态。进而提出JEPA-VLA方法，将预测型嵌入自适应整合到现有VLA模型中。

Result: JEPA-VLA在多个标准数据集（如LIBERO、LIBERO-plus、RoboTwin2.0，以及真实机器人任务）上进行了实验，结果显示该方法在性能上有显著提升。

Conclusion: 视频预测自编码得到的视觉嵌入更适合机器人VLA模型，有效提升了模型样本效率与泛化，JEPA-VLA为相关领域带来了简单且高效的改进思路。

Abstract: Recent vision-language-action (VLA) models built upon pretrained vision-language models (VLMs) have achieved significant improvements in robotic manipulation. However, current VLAs still suffer from low sample efficiency and limited generalization. This paper argues that these limitations are closely tied to an overlooked component, pretrained visual representation, which offers insufficient knowledge on both aspects of environment understanding and policy prior. Through an in-depth analysis, we find that commonly used visual representations in VLAs, whether pretrained via language-image contrastive learning or image-based self-supervised learning, remain inadequate at capturing crucial, task-relevant environment information and at inducing effective policy priors, i.e., anticipatory knowledge of how the environment evolves under successful task execution. In contrast, we discover that predictive embeddings pretrained on videos, in particular V-JEPA 2, are adept at flexibly discarding unpredictable environment factors and encoding task-relevant temporal dynamics, thereby effectively compensating for key shortcomings of existing visual representations in VLAs. Building on these observations, we introduce JEPA-VLA, a simple yet effective approach that adaptively integrates predictive embeddings into existing VLAs. Our experiments demonstrate that JEPA-VLA yields substantial performance gains across a range of benchmarks, including LIBERO, LIBERO-plus, RoboTwin2.0, and real-robot tasks.

</details>


### [41] [TG-Field: Geometry-Aware Radiative Gaussian Fields for Tomographic Reconstruction](https://arxiv.org/abs/2602.11705)
*Yuxiang Zhong,Jun Wei,Chaoqi Chen,Senyou An,Hui Huang*

Main category: cs.CV

TL;DR: 本文提出了一种针对静态和动态CT重建的新型几何感知高斯变形框架（TG-Field），有效改善了稀疏视角和动态变化下重建的伪影问题，并在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 3D Gaussian Splatting（3DGS）已在3D场景表现中展现出高效和高质量，但在CT应用中，尤其是极其稀疏视角投影和动态运动下，现有3DGS方法重建效果出现明显伪影，准确性降低。因此，亟需一种对几何与运动更敏感的新方法以提升CT重建效果。

Method: 提出Tomographic Geometry Field（TG-Field）框架。采用多分辨率hash编码器以捕获局部空间先验，调节高斯基元参数以适应极稀疏设置；通过时序条件表示和时空注意力模块扩展到动态重建，有效聚合时空特征并增强时序连贯性；此外，采用运动流网络精细建模呼吸运动及局部解剖变形。

Result: 实验在合成和真实数据集上进行，结果表明TG-Field在极度稀疏视角下，静态与动态CT重建准确率均优于现有方法，达到最新最好水平。

Conclusion: TG-Field有效缓解了稀疏投影和动态运动带来的CT重建伪影和准确性问题，特别适用于医用CT等高要求的稀疏重建场景，推动了相关领域发展。

Abstract: 3D Gaussian Splatting (3DGS) has revolutionized 3D scene representation with superior efficiency and quality. While recent adaptations for computed tomography (CT) show promise, they struggle with severe artifacts under highly sparse-view projections and dynamic motions. To address these challenges, we propose Tomographic Geometry Field (TG-Field), a geometry-aware Gaussian deformation framework tailored for both static and dynamic CT reconstruction. A multi-resolution hash encoder is employed to capture local spatial priors, regularizing primitive parameters under ultra-sparse settings. We further extend the framework to dynamic reconstruction by introducing time-conditioned representations and a spatiotemporal attention block to adaptively aggregate features, thereby resolving spatiotemporal ambiguities and enforcing temporal coherence. In addition, a motion-flow network models fine-grained respiratory motion to track local anatomical deformations. Extensive experiments on synthetic and real-world datasets demonstrate that TG-Field consistently outperforms existing methods, achieving state-of-the-art reconstruction accuracy under highly sparse-view conditions.

</details>


### [42] [DiffPlace: Street View Generation via Place-Controllable Diffusion Model Enhancing Place Recognition](https://arxiv.org/abs/2602.11875)
*Ji Li,Zhiwei Li,Shihao Li,Zhenjiang Yu,Boyang Wang,Haiou Liu*

Main category: cs.CV

TL;DR: 提出了DiffPlace框架，通过引入place-ID控制器，实现了对场所信息可控的多视角城市街景生成，相比现有方法在生成质量和支持视觉定位训练方面更优。


<details>
  <summary>Details</summary>
Motivation: 现有多视角扩散模型虽可生成3D感知的街景，但在结合文本、BEV地图及物体边框的信息基础上，难以保持背景一致性及场所感知，进而影响生成现实场景用于位置识别任务的能力。

Method: 提出了DiffPlace框架，核心为place-ID控制器。控制器利用线性投影、Perceiver Transformer和对比学习，将place-ID嵌入映射到CLIP空间，引导模型生成具备一致背景（如建筑）但前景（目标物体、天气）可灵活变化的多视角街景图像。

Result: 通过大量实验，包括定量对比和训练增强评估，DiffPlace在图像生成质量及对视觉位置识别支持方面均优于现有方法。

Conclusion: DiffPlace展示了生成模型在场景级、场所感知合成上的潜力，为提升自动驾驶中的位置识别能力提供了有效途径。

Abstract: Generative models have advanced significantly in realistic image synthesis, with diffusion models excelling in quality and stability. Recent multi-view diffusion models improve 3D-aware street view generation, but they struggle to produce place-aware and background-consistent urban scenes from text, BEV maps, and object bounding boxes. This limits their effectiveness in generating realistic samples for place recognition tasks. To address these challenges, we propose DiffPlace, a novel framework that introduces a place-ID controller to enable place-controllable multi-view image generation. The place-ID controller employs linear projection, perceiver transformer, and contrastive learning to map place-ID embeddings into a fixed CLIP space, allowing the model to synthesize images with consistent background buildings while flexibly modifying foreground objects and weather conditions. Extensive experiments, including quantitative comparisons and augmented training evaluations, demonstrate that DiffPlace outperforms existing methods in both generation quality and training support for visual place recognition. Our results highlight the potential of generative models in enhancing scene-level and place-aware synthesis, providing a valuable approach for improving place recognition in autonomous driving

</details>


### [43] [STVG-R1: Incentivizing Instance-Level Reasoning and Grounding in Videos via Reinforcement Learning](https://arxiv.org/abs/2602.11730)
*Xiaowen Zhang,Zhi Gao,Licheng Jiao,Lingling Li,Qing Li*

Main category: cs.CV

TL;DR: 该论文提出了一种新的视觉提示范式和强化学习框架STVG-R1，用于改进VLM在空间-时间视频定位任务的表现，显著提升了多项指标并具备很强的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言模型在视觉与文本描述对齐方面常出现“幻觉”问题，尤其是在密集预测任务如时空视频定位（STVG）中更为严重。现有方法大多通过增强视觉-文本对齐或增加辅助解码器，但通常需引入额外的大量训练模块，带来高昂的标注和计算成本。

Method: 作者提出通过给每个对象分配唯一的、时间一致的ID，将其作为视觉提示嵌入视频，从而将逐帧坐标预测转化为实例级识别问题，规避了跨模态坐标对齐的难题。同时，提出STVG-R1——首个用于STVG的强化学习框架，利用任务驱动奖励联合优化时间精度、空间一致性和结构格式规则性。

Result: 在六个基准测试上，STVG-R1方法效果显著，尤其在HCSTVG-v2数据集上相较于基线Qwen2.5-VL-7B提升了20.9%的m_IoU，刷新了当前最优水平；并且在MeViS的多目标视频目标分割任务上也取得了SOTA的J&F 47.3%，表现出强大的零样本泛化能力。

Conclusion: 通过实例级ID视觉提示与强化学习联合优化，STVG-R1有效缓解了VLM中的文本与视觉位置失配问题，在空间-时间视频定位及相关任务中大幅提升性能，为领域提供了新的有前景范式。

Abstract: In vision-language models (VLMs), misalignment between textual descriptions and visual coordinates often induces hallucinations. This issue becomes particularly severe in dense prediction tasks such as spatial-temporal video grounding (STVG). Prior approaches typically focus on enhancing visual-textual alignment or attaching auxiliary decoders. However, these strategies inevitably introduce additional trainable modules, leading to significant annotation costs and computational overhead. In this work, we propose a novel visual prompting paradigm that avoids the difficult problem of aligning coordinates across modalities. Specifically, we reformulate per-frame coordinate prediction as a compact instance-level identification problem by assigning each object a unique, temporally consistent ID. These IDs are embedded into the video as visual prompts, providing explicit and interpretable inputs to the VLMs. Furthermore, we introduce STVG-R1, the first reinforcement learning framework for STVG, which employs a task-driven reward to jointly optimize temporal accuracy, spatial consistency, and structural format regularization. Extensive experiments on six benchmarks demonstrate the effectiveness of our approach. STVG-R1 surpasses the baseline Qwen2.5-VL-7B by a remarkable margin of 20.9% on m_IoU on the HCSTVG-v2 benchmark, establishing a new state of the art (SOTA). Surprisingly, STVG-R1 also exhibits strong zero-shot generalization to multi-object referring video object segmentation tasks, achieving a SOTA 47.3% J&F on MeViS.

</details>


### [44] [Adapting Vision-Language Models for E-commerce Understanding at Scale](https://arxiv.org/abs/2602.11733)
*Matteo Nulli,Vladimir Orshulevich,Tala Bazazo,Christian Herold,Michael Kozielski,Marcin Mazur,Szymon Tuzel,Cees G. M. Snoek,Seyyed Hadi Hashemi,Omar Javed,Yannick Versley,Shahram Khadivi*

Main category: cs.CV

TL;DR: 本文探讨了针对电商领域，多模态（文本、图片、结构化属性）理解的需求，并通过实验表明，针对性地微调通用视觉-语言模型（VLMs）能够提升电商任务表现，同时提出了新的评测方案。


<details>
  <summary>Details</summary>
Motivation: 电商产品涉及多种模态且数据噪声大，目前缺乏专门针对电商属性、图片多样性和噪声特点的VLM适应策略。作者希望在不损失通用能力的前提下，提高模型对电商数据的理解力。

Method: 对通用的VLM进行有针对性的适应（微调），并在电商数据上开展大规模实验。提出了涵盖产品理解、指令遵循和属性抽取等任务的全新评估套件。

Result: 实验结果显示，经过适应的VLM在电商相关任务上的表现有实质提升，并且保持了跨模态理解能力。

Conclusion: 合理、有针对性地适应VLM，可同时兼顾电商领域的指标提升和模型原有的广泛适应性。同时，所提出的评测套件有助于后续相关研究的综合评估。

Abstract: E-commerce product understanding demands by nature, strong multimodal comprehension from text, images, and structured attributes. General-purpose Vision-Language Models (VLMs) enable generalizable multimodal latent modelling, yet there is no documented, well-known strategy for adapting them to the attribute-centric, multi-image, and noisy nature of e-commerce data, without sacrificing general performance. In this work, we show through a large-scale experimental study, how targeted adaptation of general VLMs can substantially improve e-commerce performance while preserving broad multimodal capabilities. Furthermore, we propose a novel extensive evaluation suite covering deep product understanding, strict instruction following, and dynamic attribute extraction.

</details>


### [45] [Mask What Matters: Mitigating Object Hallucinations in Multimodal Large Language Models with Object-Aligned Visual Contrastive Decoding](https://arxiv.org/abs/2602.11737)
*Boqi Chen,Xudong Liu,Jianing Qiu*

Main category: cs.CV

TL;DR: 本文研究了多模态大模型（MLLMs）中的物体幻觉问题，并通过构造与物体对齐的辅助视图改进了视觉对比解码（VCD）方法。结果在两个主流基准及模型上均获得了性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大模型容易出现物体幻觉，即模型描述了图像中实际上不存在的物体。之前方法如VCD虽有改进，但仍存在不足，因此需要新的机制进一步减少物体幻觉。

Method: 提出利用自监督视觉Transformer中的以物体为中心的注意力机制，通过去除最突出的视觉证据来生成辅助视图，使未被支持的token受到干扰并获得更强的对比信号。该方法对prompt和模型无关，可无缝整合进现有VCD流程，计算开销极低。

Result: 在两个主流的物体幻觉评测基准上，对两个多模态大模型验证了本方法，均获得了性能的持续提升。

Conclusion: 所提出的方法有效抑制了多模态大模型中的物体幻觉问题，通用性好，且集成代价低，为MLLMs在视觉理解任务中的应用提供了更高可靠性。

Abstract: We study object hallucination in Multimodal Large Language Models (MLLMs) and improve visual contrastive decoding (VCD) by constructing an object-aligned auxiliary view. We leverage object-centric attention in self-supervised Vision Transformers. In particular, we remove the most salient visual evidence to construct an auxiliary view that disrupts unsupported tokens and produces a stronger contrast signal. Our method is prompt-agnostic, model-agnostic, and can be seamlessly plugged into the existing VCD pipeline with little computation overhead, i.e., a single cacheable forward pass. Empirically, our method demonstrates consistent gains on two popular object hallucination benchmarks across two MLLMs.

</details>


### [46] [Adaptive Debiasing Tsallis Entropy for Test-Time Adaptation](https://arxiv.org/abs/2602.11743)
*Xiangyu Wu,Dongming Jiang,Feng Yu,Yueying Tian,Jiaqi Tang,Qing-Guo Chen,Yang Yang,Jianfeng Lu*

Main category: cs.CV

TL;DR: 本文提出了一种基于自适应去偏的Tsallis熵（ADTE）方法，用于提升视觉-语言模型如CLIP的测试时自适应能力，通过引入类别特定参数q减小训练偏差，并在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 主流的测试时自适应方法多基于Shannon熵（SE）来衡量模型预测的不确定性，但由于CLIP预训练数据存在严重类别不平衡，SE会带来偏置的熵估计，因此需要更适合处理偏分布的新方法。

Method: 作者提出用Tsallis熵（TE）替代Shannon熵，利用TE引入的非广延性参数q来适应并校准类别间的偏差；进一步提出自适应去偏Tsallis熵（ADTE），通过从测试数据中估算类别偏差，自适应生成每类独特的参数q^l，用于可靠地选择高置信度视角并结合标签调整策略，无需针对特定数据集调参。

Result: 在ImageNet及其五个变体上，ADTE方法优于最新主流方法，并且在10个跨域基准测试上取得最高平均性能，对模型结构和文本提示均具有鲁棒性。

Conclusion: Tsallis熵及其自适应去偏版本ADTE无需额外改动即可全面替代传统Shannon熵，为视觉-语言模型的测试时自适应提供了更准确且通用的解决方案，有效提升了模型跨域和泛化能力。

Abstract: Mainstream Test-Time Adaptation (TTA) methods for adapting vision-language models, e.g., CLIP, typically rely on Shannon Entropy (SE) at test time to measure prediction uncertainty and inconsistency. However, since CLIP has a built-in bias from pretraining on highly imbalanced web-crawled data, SE inevitably results in producing biased estimates of uncertainty entropy. To address this issue, we notably find and demonstrate that Tsallis Entropy (TE), a generalized form of SE, is naturally suited for characterizing biased distributions by introducing a non-extensive parameter q, with the performance of SE serving as a lower bound for TE. Building upon this, we generalize TE into Adaptive Debiasing Tsallis Entropy (ADTE) for TTA, customizing a class-specific parameter q^l derived by normalizing the estimated label bias from continuously incoming test instances, for each category. This adaptive approach allows ADTE to accurately select high-confidence views and seamlessly integrate with a label adjustment strategy to enhance adaptation, without introducing distribution-specific hyperparameter tuning. Besides, our investigation reveals that both TE and ADTE can serve as direct, advanced alternatives to SE in TTA, without any other modifications. Experimental results show that ADTE outperforms state-of-the-art methods on ImageNet and its five variants, and achieves the highest average performance on 10 cross-domain benchmarks, regardless of the model architecture or text prompts used. Our code is available at https://github.com/Jinx630/ADTE.

</details>


### [47] [Code2Worlds: Empowering Coding LLMs for 4D World Generation](https://arxiv.org/abs/2602.11757)
*Yi Zhang,Yunshuang Wang,Zeyu Zhang,Hao Tang*

Main category: cs.CV

TL;DR: Code2Worlds是一种新框架，通过代码生成实现物理法则驱动的4D场景（含时间动态），显著提升了模拟动态真实度和丰富性，超过现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型多关注3D静态场景，缺乏动态物理一致性，难以实现真实的空间智能；而4D动态模拟则面临局部与全局、语义与物理之间难以协调的问题。

Method: 提出Code2Worlds框架，将4D生成建模为“语言到模拟代码”的过程；采用双流架构，分别处理对象生成与环境组织；引入物理感知的闭环反馈机制，包括负责动态脚本的PostProcess Agent以及能自我反思的VLM-Motion Critic，用于不断优化仿真代码。

Result: 在Code4D基准下，Code2Worlds的SGS得分提升41%，丰富度提升49%，并能生成以物理法则为基础的动态场景，是现有静态方法无法实现的。

Conclusion: Code2Worlds有效克服4D生成中的多尺度和语义-物理鸿沟，推动了物理真实、可控的世界模拟发展，为空间智能提供了新范式。

Abstract: Achieving spatial intelligence requires moving beyond visual plausibility to build world simulators grounded in physical laws. While coding LLMs have advanced static 3D scene generation, extending this paradigm to 4D dynamics remains a critical frontier. This task presents two fundamental challenges: multi-scale context entanglement, where monolithic generation fails to balance local object structures with global environmental layouts; and a semantic-physical execution gap, where open-loop code generation leads to physical hallucinations lacking dynamic fidelity. We introduce Code2Worlds, a framework that formulates 4D generation as language-to-simulation code generation. First, we propose a dual-stream architecture that disentangles retrieval-augmented object generation from hierarchical environmental orchestration. Second, to ensure dynamic fidelity, we establish a physics-aware closed-loop mechanism in which a PostProcess Agent scripts dynamics, coupled with a VLM-Motion Critic that performs self-reflection to iteratively refine simulation code. Evaluations on the Code4D benchmark show Code2Worlds outperforms baselines with a 41% SGS gain and 49% higher Richness, while uniquely generating physics-aware dynamics absent in prior static methods. Code: https://github.com/AIGeeksGroup/Code2Worlds. Website: https://aigeeksgroup.github.io/Code2Worlds.

</details>


### [48] [Light4D: Training-Free Extreme Viewpoint 4D Video Relighting](https://arxiv.org/abs/2602.11769)
*Zhenghuang Wu,Kang Chen,Zeyu Zhang,Hao Tang*

Main category: cs.CV

TL;DR: 近年来基于扩散模型的生成方法在图像和视频重光照方面取得了重大突破，但将其推广到4D（空间+时间）重光照仍面临数据稀缺和时间一致性难题。该论文提出了一种全新、无需训练的Light4D框架，实现了在极端视角变化下的4D视频时序一致重光照合成。


<details>
  <summary>Details</summary>
Motivation: 传统方法无法很好地兼顾4D重光照的数据需求和时序一致性，特别是在视角剧烈变化时，易产生时序不一致和外观闪烁，而高质量的成对4D重光照训练数据又非常稀缺。

Method: 提出了Disentangled Flow Guidance（解耦流引导）实现对光照控制的同时保留几何结构；构建了IC-Light框架并引入Temporal Consistent Attention和确定性正则，增强了生成视频的时序一致性、减少闪烁。框架完全无监督，不依赖成对4D数据训练。

Result: 实验表明该方法在时间一致性与光照还原精度上都达到了与现有方法相竞争的效果，并能应对-90到90度的相机大幅旋转，重光照效果稳定。

Conclusion: Light4D无监督框架首次高效解决了4D重光照的时序一致性与高保真问题，为下一代4D可控光照生成提供了新思路。在缺乏训练数据的场景下表现尤为突出，具有较强实用价值。

Abstract: Recent advances in diffusion-based generative models have established a new paradigm for image and video relighting. However, extending these capabilities to 4D relighting remains challenging, due primarily to the scarcity of paired 4D relighting training data and the difficulty of maintaining temporal consistency across extreme viewpoints. In this work, we propose Light4D, a novel training-free framework designed to synthesize consistent 4D videos under target illumination, even under extreme viewpoint changes. First, we introduce Disentangled Flow Guidance, a time-aware strategy that effectively injects lighting control into the latent space while preserving geometric integrity. Second, to reinforce temporal consistency, we develop Temporal Consistent Attention within the IC-Light architecture and further incorporate deterministic regularization to eliminate appearance flickering. Extensive experiments demonstrate that our method achieves competitive performance in temporal consistency and lighting fidelity, robustly handling camera rotations from -90 to 90. Code: https://github.com/AIGeeksGroup/Light4D. Website: https://aigeeksgroup.github.io/Light4D.

</details>


### [49] [Efficient Segment Anything with Depth-Aware Fusion and Limited Training Data](https://arxiv.org/abs/2602.11804)
*Yiming Zhou,Xuenjie Xie,Panfeng Li,Albrecht Kunz,Ahmad Osman,Xavier Maldague*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级的RGB-D融合模型，将高效的EfficientViT-SAM与单目深度先验相结合，实现了仅用小规模训练数据即可获得优越分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有SAM模型性能卓越，但依赖大规模RGB数据集、计算量大且缺少几何信息。这促使作者探究如何利用额外的深度信息提升分割效果，并显著减少训练所需的数据量。

Method: 方法首先用预训练模型估算单目深度图，然后设计专门的深度编码器将中层深度特征与RGB特征融合，基于EfficientViT-SAM改进网络架构。训练数据量仅为11,200张图片。

Result: 在仅用约0.1%的SA-1B数据量（11,200张）训练的情况下，精度超过EfficientViT-SAM基线，证明深度信息能显著提升分割表现。

Conclusion: 融合单目深度先验能增强网络对几何结构的理解，使在数据量极小的条件下也能获得优越分割效果，为高效、低资源通用分割模型提供了新思路。

Abstract: Segment Anything Models (SAM) achieve impressive universal segmentation performance but require massive datasets (e.g., 11M images) and rely solely on RGB inputs. Recent efficient variants reduce computation but still depend on large-scale training. We propose a lightweight RGB-D fusion framework that augments EfficientViT-SAM with monocular depth priors. Depth maps are generated with a pretrained estimator and fused mid-level with RGB features through a dedicated depth encoder. Trained on only 11.2k samples (less than 0.1\% of SA-1B), our method achieves higher accuracy than EfficientViT-SAM, showing that depth cues provide strong geometric priors for segmentation.

</details>


### [50] [How to Sample High Quality 3D Fractals for Action Recognition Pre-Training?](https://arxiv.org/abs/2602.11810)
*Marko Putak,Thomas B. Moeslund,Joakim Bruslund Haurum*

Main category: cs.CV

TL;DR: 该论文提出了一种高效生成3D分形合成视频数据用于动作识别模型预训练的新方法，通过“目标智能过滤”极大提升了分形生成速度和任务表现。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型常需大量标注数据，真实数据标注耗时且存在隐私伦理问题。用合成数据（尤其是FDSL生成的分形数据）可以规避这些问题，但现有3D分形生成方法速度慢且多结果退化。

Method: 作者采用3D迭代函数系统生成分形，作为动作识别预训练视频，系统探索不同3D分形生成及过滤策略，并提出“目标智能过滤”方法，提高采样效率与分形多样性。

Result: 新方法生成速度提升约100倍，并在下游动作识别任务中显著优于现有的3D分形过滤方法。

Conclusion: 目标智能过滤方法有效解决了生成3D分形合成数据的速度与多样性问题，为动作识别等任务模型预训练提供了更优、高效的合成数据方案。

Abstract: Synthetic datasets are being recognized in the deep learning realm as a valuable alternative to exhaustively labeled real data. One such synthetic data generation method is Formula Driven Supervised Learning (FDSL), which can provide an infinite number of perfectly labeled data through a formula driven approach, such as fractals or contours. FDSL does not have common drawbacks like manual labor, privacy and other ethical concerns. In this work we generate 3D fractals using 3D Iterated Function Systems (IFS) for pre-training an action recognition model. The fractals are temporally transformed to form a video that is used as a pre-training dataset for downstream task of action recognition. We find that standard methods of generating fractals are slow and produce degenerate 3D fractals. Therefore, we systematically explore alternative ways of generating fractals and finds that overly-restrictive approaches, while generating aesthetically pleasing fractals, are detrimental for downstream task performance. We propose a novel method, Targeted Smart Filtering, to address both the generation speed and fractal diversity issue. The method reports roughly 100 times faster sampling speed and achieves superior downstream performance against other 3D fractal filtering methods.

</details>


### [51] [WorldTree: Towards 4D Dynamic Worlds from Monocular Video using Tree-Chains](https://arxiv.org/abs/2602.11845)
*Qisen Wang,Yifan Zhao,Jia Li*

Main category: cs.CV

TL;DR: 本文提出了WorldTree框架，实现了单目动态重建任务上更高效和精细的运动表征及动态建模。


<details>
  <summary>Details</summary>
Motivation: 现有动态重建方法在单目输入下仍面临时空分解不统一问题，存在整体时间优化或空间层次耦合等瓶颈，限制了其在实际应用中的表现。

Method: WorldTree框架包含两个核心组件：1）Temporal Partition Tree（TPT），基于继承式划分树结构进行分层时间分解，实现由粗到细的优化；2）Spatial Ancestral Chains（SAC），递归查询空间祖先层次结构以补充空间动态信息，并在多层节点间细化运动表征。

Result: 在NVIDIA-LS和DyCheck等多个数据集上取得了显著效果，LPIPS提升8.26%，mLPIPS提升9.09%，均优于现有主流方法。

Conclusion: WorldTree通过统一的时空分解框架，有效提升了单目动态重建的精度与效率，为实际应用打下了基础。

Abstract: Dynamic reconstruction has achieved remarkable progress, but there remain challenges in monocular input for more practical applications. The prevailing works attempt to construct efficient motion representations, but lack a unified spatiotemporal decomposition framework, suffering from either holistic temporal optimization or coupled hierarchical spatial composition. To this end, we propose WorldTree, a unified framework comprising Temporal Partition Tree (TPT) that enables coarse-to-fine optimization based on the inheritance-based partition tree structure for hierarchical temporal decomposition, and Spatial Ancestral Chains (SAC) that recursively query ancestral hierarchical structure to provide complementary spatial dynamics while specializing motion representations across ancestral nodes. Experimental results on different datasets indicate that our proposed method achieves 8.26% improvement of LPIPS on NVIDIA-LS and 9.09% improvement of mLPIPS on DyCheck compared to the second-best method. Code: https://github.com/iCVTEAM/WorldTree.

</details>


### [52] [Free Lunch for Stabilizing Rectified Flow Inversion](https://arxiv.org/abs/2602.11850)
*Chenru Wang,Beier Zhu,Chi Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种用于Rectified-Flow(RF)生成模型的训练无关反演与编辑方法，有效提高了生成稳定性与质量。


<details>
  <summary>Details</summary>
Motivation: 当前主流的RF生成模型虽在图像生成及重构方面性能优异，但传统反演方法累积误差大，易导致生成不稳定，影响重构和编辑效果。

Method: 提出Proximal-Mean Inversion(PMI)方法，通过引入基于历史平均速度的梯度修正，约束在球面高斯分布内以稳定速度场。同时，针对编辑任务提出mimic-CFG方案，在当前速度与历史平均速度投影之间插值，兼顾结构一致性与编辑效果。

Result: 在PIE-Bench基准测试中，新方法显著提升了反演稳定性、图像重构质量与编辑保真度，同时显著减少了神经网络推理次数。

Conclusion: 所提方法在理论与效率上具备优势，达到甚至超越现有最佳水平，为高质量、高效图像反演及编辑提供了切实可行的方案。

Abstract: Rectified-Flow (RF)-based generative models have recently emerged as strong alternatives to traditional diffusion models, demonstrating state-of-the-art performance across various tasks. By learning a continuous velocity field that transforms simple noise into complex data, RF-based models not only enable high-quality generation, but also support training-free inversion, which facilitates downstream tasks such as reconstruction and editing. However, existing inversion methods, such as vanilla RF-based inversion, suffer from approximation errors that accumulate across timesteps, leading to unstable velocity fields and degraded reconstruction and editing quality. To address this challenge, we propose Proximal-Mean Inversion (PMI), a training-free gradient correction method that stabilizes the velocity field by guiding it toward a running average of past velocities, constrained within a theoretically derived spherical Gaussian. Furthermore, we introduce mimic-CFG, a lightweight velocity correction scheme for editing tasks, which interpolates between the current velocity and its projection onto the historical average, balancing editing effectiveness and structural consistency. Extensive experiments on PIE-Bench demonstrate that our methods significantly improve inversion stability, image reconstruction quality, and editing fidelity, while reducing the required number of neural function evaluations. Our approach achieves state-of-the-art performance on the PIE-Bench with enhanced efficiency and theoretical soundness.

</details>


### [53] [Zooming without Zooming: Region-to-Image Distillation for Fine-Grained Multimodal Perception](https://arxiv.org/abs/2602.11858)
*Lai Wei,Liangbo He,Jun Lan,Lingzhong Dong,Yutong Cai,Siyuan Li,Huijia Zhu,Weiqiang Wang,Linghe Kong,Yue Wang,Zhuosheng Zhang,Weiran Huang*

Main category: cs.CV

TL;DR: 本文提出了一种新的训练方法，将原本推理阶段的图像缩放行为转移到训练阶段，使多模态大模型在无需多次推理和工具调用情况下，就能实现细粒度图像感知能力的提升。还发布了一个新基准ZoomBench用于测试该能力。


<details>
  <summary>Details</summary>
Motivation: 多模态大模型虽然在整体视觉理解上表现优异，但对需要识别细小、局部证据的任务仍然表现不佳。现有方法依靠推理时多次缩放图像、调用外部工具，过程效率低且计算资源消耗大，因此需要新的机制将这种细致观察的能力直接内化到模型本身。

Method: 该方法称为Region-to-Image Distillation。具体做法是在训练时，先对图像关键微小区域进行裁剪并让强大教师模型生成高质量视觉问答（VQA）数据，然后将带区域信息的监督信号蒸馏（distill）到全图像上，从而让较小的学生模型无需工具调用即可获得细粒度感知能力。还提出了ZoomBench数据集，用于系统评估全球-区域感知性能差异。

Result: 实验显示，该方法训练的模型在多项细粒度感知基准上取得了领先表现，在视觉推理、界面代理等多模态任务上也有提升。实验证明了细粒度能力可以被有效蒸馏，无需繁琐工具操作。

Conclusion: 通过将“图像推理（Thinking-with-Images）”过程转化为训练原语，模型在单次推理中即可获得细致感知能力。这不仅提升效率，还降低了系统复杂度。论文还探讨了何种情况下仍需动态推理，而何种情况下可通过蒸馏达到等效目标。

Abstract: Multimodal Large Language Models (MLLMs) excel at broad visual understanding but still struggle with fine-grained perception, where decisive evidence is small and easily overwhelmed by global context. Recent "Thinking-with-Images" methods alleviate this by iteratively zooming in and out regions of interest during inference, but incur high latency due to repeated tool calls and visual re-encoding. To address this, we propose Region-to-Image Distillation, which transforms zooming from an inference-time tool into a training-time primitive, thereby internalizing the benefits of agentic zooming into a single forward pass of an MLLM. In particular, we first zoom in to micro-cropped regions to let strong teacher models generate high-quality VQA data, and then distill this region-grounded supervision back to the full image. After training on such data, the smaller student model improves "single-glance" fine-grained perception without tool use. To rigorously evaluate this capability, we further present ZoomBench, a hybrid-annotated benchmark of 845 VQA data spanning six fine-grained perceptual dimensions, together with a dual-view protocol that quantifies the global--regional "zooming gap". Experiments show that our models achieve leading performance across multiple fine-grained perception benchmarks, and also improve general multimodal cognition on benchmarks such as visual reasoning and GUI agents. We further discuss when "Thinking-with-Images" is necessary versus when its gains can be distilled into a single forward pass. Our code is available at https://github.com/inclusionAI/Zooming-without-Zooming.

</details>


### [54] [SynthRAR: Ring Artifacts Reduction in CT with Unrolled Network and Synthetic Data Training](https://arxiv.org/abs/2602.11880)
*Hongxu Yang,Levente Lippenszky,Edina Timko,Gopal Avinash*

Main category: cs.CV

TL;DR: 本论文提出了一种无须真实临床数据、基于合成数据训练的CT环形伪影去除方法，并在多种扫描场景下超过现有主流方法。


<details>
  <summary>Details</summary>
Motivation: CT成像中的探测器缺陷或响应不一致会导致环形或条带伪影，严重影响图像临床可用性。现有深度学习方法依赖大量专门数据集，数据采集代价高，且忽视了图像空间与正弦域之间的内在关联。

Method: 作者将环形伪影去除（RAR）问题重新表述为反问题，基于理论分析，设计了一种解卷积网络，其结合了非理想响应模型与CT几何下的线性投影。进一步，利用自然图像合成数据，构建了无需真实数据的训练方案，同时挖掘了正弦域和图像域伪影之间的相关性。

Result: 在多种扫描几何配置和不同解剖区域的评价实验显示，基于合成数据训练的 proposed 方法在伪影去除方面，优于目前主流的深度学习及传统方法。

Conclusion: 所提方法不依赖真实临床数据就能实现优异的CT环形伪影去除效果，理论上为解决伪影问题提供了更通用、低数据成本的解决思路。

Abstract: Defective and inconsistent responses in CT detectors can cause ring and streak artifacts in the reconstructed images, making them unusable for clinical purposes. In recent years, several ring artifact reduction solutions have been proposed in the image domain or in the sinogram domain using supervised deep learning methods. However, these methods require dedicated datasets for training, leading to a high data collection cost. Furthermore, existing approaches focus exclusively on either image-space or sinogram-space correction, neglecting the intrinsic correlations from the forward operation of the CT geometry. Based on the theoretical analysis of non-ideal CT detector responses, the RAR problem is reformulated as an inverse problem by using an unrolled network, which considers non-ideal response together with linear forward-projection with CT geometry. Additionally, the intrinsic correlations of ring artifacts between the sinogram and image domains are leveraged through synthetic data derived from natural images, enabling the trained model to correct artifacts without requiring real-world clinical data. Extensive evaluations on diverse scanning geometries and anatomical regions demonstrate that the model trained on synthetic data consistently outperforms existing state-of-the-art methods.

</details>


### [55] [DynaHOI: Benchmarking Hand-Object Interaction for Dynamic Target](https://arxiv.org/abs/2602.11919)
*BoCheng Hu,Zhonghan Zhao,Kaiyue Zhou,Hongwei Wang,Gaoang Wang*

Main category: cs.CV

TL;DR: 本文主要提出了一个面向动态手目标交互的评测平台及数据集——DynaHOI-Gym和DynaHOI-10M，用于填补现有手部动作生成在动态环境中评测的空白。


<details>
  <summary>Details</summary>
Motivation: 当前主流手部动作生成基准数据集大多集中在与静态物体交互，缺乏对动态目标及时间敏感协调能力的评测，导致研究成果难以覆盖真实应用场景。

Method: 作者设计了DynaHOI-Gym，这是一套统一的在线闭环评测平台，提供参数化动作生成器及基于rollout的评测指标。基于该平台，作者进一步构建了大规模的DynaHOI-10M数据集，包括1000万帧、18万条手捕捉轨迹，并按照动态目标的动作将其划分为8大类、22个细分类。作者还提出了observe-before-act（ObAct）基线方法，通过时空注意力机制将短时观测与当前帧融合预测动作。

Result: DynaHOI-10M成为手部动作生成在动态HOI场景下的重要基准，其中提出的ObAct方法在位置成功率指标上提升8.1%。

Conclusion: 本文填补了动态HOI场景的评测空缺，为后续相关研究奠定了基础，并通过实验证明新平台和新基线方法的有效性。

Abstract: Most existing hand motion generation benchmarks for hand-object interaction (HOI) focus on static objects, leaving dynamic scenarios with moving targets and time-critical coordination largely untested. To address this gap, we introduce the DynaHOI-Gym, a unified online closed-loop platform with parameterized motion generators and rollout-based metrics for dynamic capture evaluation. Built on DynaHOI-Gym, we release DynaHOI-10M, a large-scale benchmark with 10M frames and 180K hand capture trajectories, whose target motions are organized into 8 major categories and 22 fine-grained subcategories. We also provide a simple observe-before-act baseline (ObAct) that integrates short-term observations with the current frame via spatiotemporal attention to predict actions, achieving an 8.1% improvement in location success rate.

</details>


### [56] [Synthesis of Late Gadolinium Enhancement Images via Implicit Neural Representations for Cardiac Scar Segmentation](https://arxiv.org/abs/2602.11942)
*Soufiane Ben Haddou,Laura Alvarez-Florez,Erik J. Bekkers,Fleur V. Y. Tjong,Ahmad S. Amin,Connie R. Bezzina,Ivana Išgum*

Main category: cs.CV

TL;DR: 该论文提出了一种结合隐式神经表示（INRs）与去噪扩散模型，用于合成心脏LGE图像及其分割掩膜，以增强心肌纤维化自动分割方法的数据集。实验表明，利用合成数据可以提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有用于心肌瘢痕（纤维化）分割的LGE图像数据集较小，人工注释昂贵且耗时，限制了深度学习分割方法的发展。作者希望通过生成高质量合成数据来缓解真实数据稀缺问题，提升模型性能。

Method: 方法包括：1）用隐式神经表示学习连续空间的LGE图像及其分割掩膜；2）将INRs编码为紧凑的潜空间表示；3）在该潜空间利用扩散模型生成新表示，最后解码为具备解剖一致性的LGE合成图像和分割掩膜。

Result: 在133例心脏MRI数据集上测试，使用200个合成体积进行数据增强，纤维化分割Dice分数从0.509提高到0.524，证明了合成数据的有效性。

Conclusion: 该方法可以实现无标注的合成数据生成，改善数据不足问题，有助于提升心肌纤维化分割算法的性能。研究代码已公开发布，促进后续研究。

Abstract: Late gadolinium enhancement (LGE) imaging is the clinical standard for myocardial scar assessment, but limited annotated datasets hinder the development of automated segmentation methods. We propose a novel framework that synthesises both LGE images and their corresponding segmentation masks using implicit neural representations (INRs) combined with denoising diffusion models. Our approach first trains INRs to capture continuous spatial representations of LGE data and associated myocardium and fibrosis masks. These INRs are then compressed into compact latent embeddings, preserving essential anatomical information. A diffusion model operates on this latent space to generate new representations, which are decoded into synthetic LGE images with anatomically consistent segmentation masks. Experiments on 133 cardiac MRI scans suggest that augmenting training data with 200 synthetic volumes contributes to improved fibrosis segmentation performance, with the Dice score showing an increase from 0.509 to 0.524. Our approach provides an annotation-free method to help mitigate data scarcity.The code for this research is publicly available.

</details>


### [57] [Benchmarking Vision-Language Models for French PDF-to-Markdown Conversion](https://arxiv.org/abs/2602.11960)
*Bruno Rigal,Victor Dupriez,Alexis Mignon,Ronan Le Hy,Nicolas Mery*

Main category: cs.CV

TL;DR: 本文评估了最新视觉-语言模型（VLMs）在处理法语PDF文档转换为Markdown格式时的表现，构建了一个针对法语复杂文档的新基准，并对多种主流模型进行了系统测试。


<details>
  <summary>Details</summary>
Motivation: 现有的PDF解析与转换模型通常以英文或中文文档为主，对法语等多语言的复杂文档支持有限。同时，目前评测方法常常对格式差异过于敏感，影响实际下游任务的表现和评估公正性。本工作希望提升非英文复杂文档的解析能力，并提出更符合实际应用需求的评测方法。

Method: 作者从6万份法语文档语料库中通过模型分歧采样筛选出具有挑战性的页面，涵盖手写表单、复杂版面、密集表格和图形丰富页面。评测结合单元测试式检查（如文本存在、阅读顺序、本地表格约束）与类别特定标准化，以消除仅与展示相关的不重要差异。对15个VLM模型做系统对比。

Result: 最强的商业闭源模型在手写和表单场景下展现出明显更强的鲁棒性，但部分开源模型在标准印刷版面下依然有较好表现。

Conclusion: 针对法语复杂文档的自动解析，本工作提出的新基准和评测方法更符合实际需求，同时展示了不同模型在复杂文档处理能力上的差异，为后续多语言、多格式文档理解的研究提供了更权威的测试平台。

Abstract: This report evaluates PDF-to-Markdown conversion using recent Vision-Language Models (VLMs) on challenging French documents. Document parsing is a critical step for Retrieval-Augmented Generation (RAG) pipelines, where transcription and layout errors propagate to downstream retrieval and grounding. Existing benchmarks often emphasize English or Chinese and can over-penalize benign formatting and linearization choices (e.g., line breaks, list segmentation, alternative table renderings) that are largely irrelevant for downstream use.
  We introduce a French-focused benchmark of difficult pages selected via model-disagreement sampling from a corpus of 60{,}000 documents, covering handwritten forms, complex layouts, dense tables, and graphics-rich pages. Evaluation is performed with unit-test-style checks that target concrete failure modes (text presence, reading order, and local table constraints) combined with category-specific normalization designed to discount presentation-only variance. Across 15 models, we observe substantially higher robustness for the strongest proprietary models on handwriting and forms, while several open-weights systems remain competitive on standard printed layouts.

</details>


### [58] [Calibrated Bayesian Deep Learning for Explainable Decision Support Systems Based on Medical Imaging](https://arxiv.org/abs/2602.11973)
*Hua Xu,Julián D. Arias-Londoño,Juan I. Godino-Llorente*

Main category: cs.CV

TL;DR: 本文提出了一种新的深度学习模型可靠性增强方法，通过引入概率优化框架和损失函数提升医学影像AI决策系统中模型的不确定性量化与校准能力。


<details>
  <summary>Details</summary>
Motivation: 当前医学影像AI决策系统虽然精度高，但因模型置信度与预测正确性失衡（如错误预测时信心过高）而限制了临床应用。模型需能对不确定结果作出警示，以供医生复核，提升医疗安全。解决模型准确性与置信度一致性问题是推动AI落地的重要需求。

Method: 提出了基于贝叶斯深度学习的通用概率优化框架。创新点包括：(1) Confidence-Uncertainty Boundary Loss (CUB-Loss)，对高置信度错误和低置信度正确的结果进行惩罚，强制预测置信度与正确性对齐；(2) Dual Temperature Scaling (DTS)后处理策略，进一步校准和优化模型后验分布。

Result: 在三类医学影像任务（肺炎筛查、糖尿病视网膜病变、皮肤病变识别）上验证方法有效性，实验表明新方法能显著改善模型置信度校准，在数据稀缺和类别极度不平衡情况下亦有优异表现。

Conclusion: 所提框架可显著提升医学影像AI系统决策的可靠性，在多种场景下表现稳定，有助于推动AI模型在真实临床环境的实际应用。

Abstract: In critical decision support systems based on medical imaging, the reliability of AI-assisted decision-making is as relevant as predictive accuracy. Although deep learning models have demonstrated significant accuracy, they frequently suffer from miscalibration, manifested as overconfidence in erroneous predictions. To facilitate clinical acceptance, it is imperative that models quantify uncertainty in a manner that correlates with prediction correctness, allowing clinicians to identify unreliable outputs for further review. In order to address this necessity, the present paper proposes a generalizable probabilistic optimization framework grounded in Bayesian deep learning. Specifically, a novel Confidence-Uncertainty Boundary Loss (CUB-Loss) is introduced that imposes penalties on high-certainty errors and low-certainty correct predictions, explicitly enforcing alignment between prediction correctness and uncertainty estimates. Complementing this training-time optimization, a Dual Temperature Scaling (DTS) strategy is devised for post-hoc calibration, further refining the posterior distribution to improve intuitive explainability. The proposed framework is validated on three distinct medical imaging tasks: automatic screening of pneumonia, diabetic retinopathy detection, and identification of skin lesions. Empirical results demonstrate that the proposed approach achieves consistent calibration improvements across diverse modalities, maintains robust performance in data-scarce scenarios, and remains effective on severely imbalanced datasets, underscoring its potential for real clinical deployment.

</details>


### [59] [Spatial Chain-of-Thought: Bridging Understanding and Generation Models for Spatial Reasoning Generation](https://arxiv.org/abs/2602.11980)
*Wei Chen,Yancheng Long,Mingqiao Liu,Haojie Ding,Yankai Yang,Hongyang Wei,Yi-Fan Zhang,Bin Wen,Fan Yang,Tingting Gao,Han Li,Long Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为SCoT（Spatial Chain-of-Thought）的新框架，通过增强扩散模型的空间理解和推理能力，实现了更优秀的图像生成和编辑效果。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在美学图像合成方面表现优异，但在复杂空间推理和理解上存在不足。现有方法使用多模态大语言模型（MLLMs）提高推理能力，但面临联合训练计算开销大或单用文本提示导致空间信息丢失等问题。因此，亟需一种高效且信息不丢失的方法提升扩散模型空间推理能力。

Method: 提出SCoT框架，通过可插拔的方式，将MLLMs的推理能力与扩散模型的生成能力相结合：1）用交错的文本-坐标指令格式训练扩散模型，增强其布局感知力；2）利用先进的MLLMs生成详细布局计划，将其空间规划能力直接引入图像生成流程。

Result: 在图像生成基准上取得了业界领先性能，在复杂空间推理任务中大幅超越现有方法，并且在图像编辑等应用场景也展现出强大效果。

Conclusion: SCoT框架是一种高效、易集成的增强扩散模型空间推理与生成能力的方法，为复杂场景下的图像生成和编辑提供了有效方案。

Abstract: While diffusion models have shown exceptional capabilities in aesthetic image synthesis, they often struggle with complex spatial understanding and reasoning. Existing approaches resort to Multimodal Large Language Models (MLLMs) to enhance this capability. However, they either incur high computational costs through joint training or suffer from spatial information loss when relying solely on textual prompts. To alleviate these limitations, we propose a Spatial Chain-of-Thought (SCoT) framework, a plug-and-play approach that effectively bridges the reasoning capabilities of MLLMs with the generative power of diffusion models. Specifically, we first enhance the diffusion model's layout awareness by training it on an interleaved text-coordinate instruction format. We then leverage state-of-the-art MLLMs as planners to generate comprehensive layout plans, transferring their spatial planning capabilities directly to the generation process. Extensive experiments demonstrate that our method achieves state-of-the-art performance on image generation benchmarks and significantly outperforms baselines on complex reasoning tasks, while also showing strong efficacy in image editing scenarios.

</details>


### [60] [Can Local Vision-Language Models improve Activity Recognition over Vision Transformers? -- Case Study on Newborn Resuscitation](https://arxiv.org/abs/2602.12002)
*Enrico Guerriero,Kjersti Engan,Øyvind Meinich-Bache*

Main category: cs.CV

TL;DR: 本研究探索了生成式AI方法（尤其是局部视觉-语言模型与大语言模型结合）提升新生儿复苏视频中活动识别的能力，并通过LoRA微调显著超过传统方法。


<details>
  <summary>Details</summary>
Motivation: 准确记录新生儿复苏过程对于医疗质量提升和规范实施至关重要，但实践中此类记录不足。先前基于3D-CNN和ViT方法虽有进展，但在细粒度动作识别上仍有难度。

Method: 本研究尝试利用局部视觉-语言模型（VLM）与大语言模型（LLM）结合的方法，并与TimeSFormer监督模型做对比。采用包含13.26小时新生儿复苏模拟视频的数据集，评估多种零样本VLM策略及通过LoRA微调的VLM分类头性能。

Result: 实验发现，小型本地VLM模型容易出现虚假识别（hallucination），但使用LoRA微调后，F1分数达到了0.91，显著优于TimeSFormer的0.70分。

Conclusion: 经过LoRA微调的小型视觉-语言模型在新生儿复苏视频活动识别中表现优秀，优于传统模型。这为临床视频文档设备的智能化、自动化提供了有希望的技术方案。

Abstract: Accurate documentation of newborn resuscitation is essential for quality improvement and adherence to clinical guidelines, yet remains underutilized in practice. Previous work using 3D-CNNs and Vision Transformers (ViT) has shown promising results in detecting key activities from newborn resuscitation videos, but also highlighted the challenges in recognizing such fine-grained activities. This work investigates the potential of generative AI (GenAI) methods to improve activity recognition from such videos. Specifically, we explore the use of local vision-language models (VLMs), combined with large language models (LLMs), and compare them to a supervised TimeSFormer baseline. Using a simulated dataset comprising 13.26 hours of newborn resuscitation videos, we evaluate several zero-shot VLM-based strategies and fine-tuned VLMs with classification heads, including Low-Rank Adaptation (LoRA). Our results suggest that small (local) VLMs struggle with hallucinations, but when fine-tuned with LoRA, the results reach F1 score at 0.91, surpassing the TimeSformer results of 0.70.

</details>


### [61] [Projected Representation Conditioning for High-fidelity Novel View Synthesis](https://arxiv.org/abs/2602.12003)
*Min-Seop Kwak,Minkyung Kwon,Jinhyeok Choi,Jiho Park,Seungryong Kim*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的创新型新视图合成框架，利用外部表示为条件，提高了生成视图的几何一致性和重建质量。


<details>
  <summary>Details</summary>
Motivation: 当前新视图合成方法在几何一致性和从稀疏未标定图像合成方面表现有限。作者希望通过引入外部视觉表示，增强扩散模型的表现力，以提升新视图合成的质量。

Method: 作者详细分析了外部视觉表示的空间注意力在几何和语义对应性方面的能力，并提出通过专门的表示投影模块，将外部表示引入扩散模型过程中，形成新的方法ReNoV（representation-guided novel view synthesis）。

Result: 实验显示，该方法在重建保真度和修补质量上均显著优于以往的扩散式新视图合成方法，并能在稀疏、未标定的图像集合中实现鲁棒的新视图合成。

Conclusion: 结合外部表示作为条件，可以有效提升扩散模型新视图合成的几何一致性与视觉质量，对未来三维视觉生成具有重要意义。

Abstract: We propose a novel framework for diffusion-based novel view synthesis in which we leverage external representations as conditions, harnessing their geometric and semantic correspondence properties for enhanced geometric consistency in generated novel viewpoints. First, we provide a detailed analysis exploring the correspondence capabilities emergent in the spatial attention of external visual representations. Building from these insights, we propose a representation-guided novel view synthesis through dedicated representation projection modules that inject external representations into the diffusion process, a methodology named ReNoV, short for representation-guided novel view synthesis. Our experiments show that this design yields marked improvements in both reconstruction fidelity and inpainting quality, outperforming prior diffusion-based novel-view methods on standard benchmarks and enabling robust synthesis from sparse, unposed image collections.

</details>


### [62] [A DMD-Based Adaptive Modulation Method for High Dynamic Range Imaging in High-Glare Environments](https://arxiv.org/abs/2602.12044)
*Banglei Guan,Jing Tao,Liang Xu,Dongcai Tan,Pengju Sun,Jianbing Liu,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 本文提出了一种基于数字微镜器件（DMD）的高动态范围（HDR）成像系统，显著提升了强眩光环境下的光学测量精度。


<details>
  <summary>Details</summary>
Motivation: 传统CCD/CMOS传感器动态范围有限，易受眩光影响导致图像饱和，进而造成不可逆的信息丢失和数字图像相关性测量（DIC）误差，尤其在焊接弧光监控、高反光金属表面分析等极端环境下影响严重。

Method: 设计了包含DMD光学调制单元和自适应计算成像流程的系统，能够区域性自主分割并对高动态场景进行自适应曝光控制，实现动态范围提升。

Result: 该系统实现了127 dB的可测动态范围，显著消除了强眩光引起的饱和伪影。实验中，DIC应变误差降低了78%，定位精度提升，表明在极端强度变化下可靠性显著增强。

Conclusion: 基于DMD的自适应HDR成像系统突破了传统传感器在高眩光环境下的测量极限，为光学计量和应力分析等领域提供了强有力的技术支持。

Abstract: Background The accuracy of photomechanics measurements critically relies on image quality,particularly under extreme illumination conditions such as welding arc monitoring and polished metallic surface analysis. High dynamic range (HDR) imaging above 120 dB is essential in these contexts. Conventional CCD/CMOS sensors, with dynamic ranges typically below 70 dB, are highly susceptible to saturation under glare, resulting in irreversible loss of detail and significant errors in digital image correlation (DIC). Methods This paper presents an HDR imaging system that leverages the spatial modulation capability of a digital micromirror device (DMD). The system architecture enables autonomous regional segmentation and adaptive exposure control for high-dynamic-range scenes through an integrated framework comprising two synergistic subsystems: a DMD-based optical modulation unit and an adaptive computational imaging pipeline. Results The system achieves a measurable dynamic range of 127 dB, effectively eliminating satu ration artifacts under high glare. Experimental results demonstrate a 78% reduction in strain error and improved DIC positioning accuracy, confirming reliable performance across extreme intensity variations. Conclusion The DMD-based system provides high fidelity adaptive HDR imaging, overcoming key limitations of conventional sensors. It exhibits strong potential for optical metrology and stress analysis in high-glare environments where traditional methods are inadequate.

</details>


### [63] [GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning](https://arxiv.org/abs/2602.12099)
*GigaBrain Team,Boyuan Wang,Chaojun Ni,Guan Huang,Guosheng Zhao,Hao Li,Jie Li,Jindi Lv,Jingyu Liu,Lv Feng,Mingming Yu,Peng Li,Qiuping Deng,Tianze Liu,Xinyu Zhou,Xinze Chen,Xiaofeng Wang,Yang Wang,Yifan Li,Yifei Nie,Yilong Li,Yukun Zhou,Yun Ye,Zhichao Liu,Zheng Zhu*

Main category: cs.CV

TL;DR: 提出了基于世界模型的VLA模型 GigaBrain-0.5M*，有效提升复杂机器人任务的跨任务适应能力和长时规划表现。


<details>
  <summary>Details</summary>
Motivation: 直接从观测预测多步动作的VLA模型在场景理解和未来预判方面有天然限制，而大规模视频世界模型则在时空推理和未来预测方面表现突出，因此有动因结合二者以提升VLA能力。

Method: 1. 构建GigaBrain-0.5M*，在GigaBrain-0.5（预训练自万小时机器人操作数据基础上）集成世界模型强化学习（RAMP方法），实现策略学习时利用未来推断能力。2. 通过RAMP提升策略的泛化与适应复杂任务能力。

Result: RAMP显著优于RECAP基线，在如叠衣服、装箱、制作咖啡等难度较高任务上提升约30%性能，且通过真实部署视频验证了模型长时精准执行复杂操作的能力。

Conclusion: 世界模型驱动的强化学习极大增强了VLA模型的复杂操作任务执行力和泛化能力，是提升机器人自主操作的有效路径。

Abstract: Vision-language-action (VLA) models that directly predict multi-step action chunks from current observations face inherent limitations due to constrained scene understanding and weak future anticipation capabilities. In contrast, video world models pre-trained on web-scale video corpora exhibit robust spatiotemporal reasoning and accurate future prediction, making them a natural foundation for enhancing VLA learning. Therefore, we propose \textit{GigaBrain-0.5M*}, a VLA model trained via world model-based reinforcement learning. Built upon \textit{GigaBrain-0.5}, which is pre-trained on over 10,000 hours of robotic manipulation data, whose intermediate version currently ranks first on the international RoboChallenge benchmark. \textit{GigaBrain-0.5M*} further integrates world model-based reinforcement learning via \textit{RAMP} (Reinforcement leArning via world Model-conditioned Policy) to enable robust cross-task adaptation. Empirical results demonstrate that \textit{RAMP} achieves substantial performance gains over the RECAP baseline, yielding improvements of approximately 30\% on challenging tasks including \texttt{Laundry Folding}, \texttt{Box Packing}, and \texttt{Espresso Preparation}. Critically, \textit{GigaBrain-0.5M$^*$} exhibits reliable long-horizon execution, consistently accomplishing complex manipulation tasks without failure as validated by real-world deployment videos on our \href{https://gigabrain05m.github.io}{project page}.

</details>


### [64] [AssetFormer: Modular 3D Assets Generation with Autoregressive Transformer](https://arxiv.org/abs/2602.12100)
*Lingting Zhu,Shengju Qian,Haidi Fan,Jiayu Dong,Zhenchao Jin,Siwei Zhou,Gen Dong,Xin Wang,Lequan Yu*

Main category: cs.CV

TL;DR: 该论文提出了一种基于Transformer的自回归模型AssetFormer，可根据文本描述自动生成模块化3D资产，提升3D内容的自动化生产质量与效率。


<details>
  <summary>Details</summary>
Motivation: 数字产业对高质量、多样化的模块化3D资产有旺盛需求，特别是在用户生成内容（UGC）领域，但现有资产生成手段在灵活性、自动化和多样性等方面存在不足。

Method: 作者提出AssetFormer，一种结合自回归Transformer架构的生成模型，能够从文本输入生成由基础模块组合而成、并满足特定设计约束的3D资产。方法创新性地引入了借鉴语言模型的模块序列编码与解码技术，对真实的在线开放式3D资产数据进行训练与评估。

Result: 初步实验结果表明，AssetFormer能够高效生成满足预期需求的多样化模块化3D资产，在专业开发和UGC场景中均表现出较好效果。

Conclusion: AssetFormer不仅提高了3D资产的生成质量和流程自动化，还为3D内容生成领域提供了灵活、可扩展的新框架，对未来多类型3D资产生成具有重要参考和应用价值。

Abstract: The digital industry demands high-quality, diverse modular 3D assets, especially for user-generated content~(UGC). In this work, we introduce AssetFormer, an autoregressive Transformer-based model designed to generate modular 3D assets from textual descriptions. Our pilot study leverages real-world modular assets collected from online platforms. AssetFormer tackles the challenge of creating assets composed of primitives that adhere to constrained design parameters for various applications. By innovatively adapting module sequencing and decoding techniques inspired by language models, our approach enhances asset generation quality through autoregressive modeling. Initial results indicate the effectiveness of AssetFormer in streamlining asset creation for professional development and UGC scenarios. This work presents a flexible framework extendable to various types of modular 3D assets, contributing to the broader field of 3D content generation. The code is available at https://github.com/Advocate99/AssetFormer.

</details>


### [65] [PosterOmni: Generalized Artistic Poster Creation via Task Distillation and Unified Reward Feedback](https://arxiv.org/abs/2602.12127)
*Sixiang Chen,Jianyu Lai,Jialin Gao,Hengyu Shi,Zhongying Liu,Tian Ye,Junfeng Luo,Xiaoming Wei,Lei Zhu*

Main category: cs.CV

TL;DR: 该论文提出了一个名为PosterOmni的通用海报生成框架，能够结合局部编辑与全局创作，通过高效的数据-蒸馏-奖励流程，实现多任务的图像转海报生成，效果优于开源和部分商用系统。


<details>
  <summary>Details</summary>
Motivation: 图像到海报的生成需要兼顾局部准确性（如ID驱动、实体保留等）与整体设计感（如布局与风格），现有方法难以同时满足，不支持多任务场景，缺乏统一评测标准。

Method: 提出PosterOmni框架，将局部编辑与全局创建整合于单一系统。方法包括：构建多场景数据集，涵盖六种任务类型；在局部专家与全局专家间进行知识蒸馏以做有监督微调；引入统一的奖励机制（PosterOmni Reward Feedback）以统一对实体保留和美学偏好的优化。同时提出PosterOmni-Bench 评测基准。

Result: 大量实验表明，PosterOmni在参考一致性、全局布局质量和美学协调性上显著优于所有开源系统，并超过部分商用封闭系统。

Conclusion: PosterOmni成功实现了多维度、统一的图像到海报生成能力，结合局部与全局任务，推动了该领域的多任务学习和评测标准的进步。

Abstract: Image-to-poster generation is a high-demand task requiring not only local adjustments but also high-level design understanding. Models must generate text, layout, style, and visual elements while preserving semantic fidelity and aesthetic coherence. The process spans two regimes: local editing, where ID-driven generation, rescaling, filling, and extending must preserve concrete visual entities; and global creation, where layout- and style-driven tasks rely on understanding abstract design concepts. These intertwined demands make image-to-poster a multi-dimensional process coupling entity-preserving editing with concept-driven creation under image-prompt control. To address these challenges, we propose PosterOmni, a generalized artistic poster creation framework that unlocks the potential of a base edit model for multi-task image-to-poster generation. PosterOmni integrates the two regimes, namely local editing and global creation, within a single system through an efficient data-distillation-reward pipeline: (i) constructing multi-scenario image-to-poster datasets covering six task types across entity-based and concept-based creation; (ii) distilling knowledge between local and global experts for supervised fine-tuning; and (iii) applying unified PosterOmni Reward Feedback to jointly align visual entity-preserving and aesthetic preference across all tasks. Additionally, we establish PosterOmni-Bench, a unified benchmark for evaluating both local editing and global creation. Extensive experiments show that PosterOmni significantly enhances reference adherence, global composition quality, and aesthetic harmony, outperforming all open-source baselines and even surpassing several proprietary systems.

</details>


### [66] [FAIL: Flow Matching Adversarial Imitation Learning for Image Generation](https://arxiv.org/abs/2602.12155)
*Yeyao Ma,Chen Li,Xiaosong Zhang,Han Hu,Weidi Xie*

Main category: cs.CV

TL;DR: 本文提出了Flow Matching Adversarial Imitation Learning（FAIL）框架，通过对抗训练来最小化策略与专家之间的分布差异，无需显式奖励信号或成对偏好，实现了高效且泛化性强的后训练方法。


<details>
  <summary>Details</summary>
Motivation: 现有的流匹配模型后训练方法（如Supervised Fine-Tuning）虽然能有效模仿专家示范，但在新颖状态下易发生策略漂移，且无法自动纠正。偏好优化方法虽然可以解决此问题，但需要昂贵的偏好采集或奖励建模。因此，亟需一种无需显式奖励或复杂偏好对的高效后训练方法。

Method: 本文提出了FAIL框架，通过对抗训练最小化策略与专家分布之间的KL散度，无需显式奖励或成对偏好。具体包括两种算法：FAIL-PD利用可微分ODE求解器实现低方差路径梯度，FAIL-PG则适用于离散或计算受限情境提供黑盒替代方案。

Result: 在仅使用13,000条专业演示数据（Nano Banana pro）微调FLUX模型下，FAIL方法在提示跟随和美学基准任务上取得了有竞争力的表现。此外，该方法对离散图像和视频生成任务也能有效泛化，并能作为鲁棒正则化方法缓解基于奖励优化中的奖励欺骗问题。

Conclusion: FAIL方法在无需显式奖励或复杂偏好数据的前提下，实现了高效、泛化的模仿学习，能够有效解决策略漂移和奖励欺骗等实际问题，为后训练流匹配模型提供了新范式。

Abstract: Post-training of flow matching models-aligning the output distribution with a high-quality target-is mathematically equivalent to imitation learning. While Supervised Fine-Tuning mimics expert demonstrations effectively, it cannot correct policy drift in unseen states. Preference optimization methods address this but require costly preference pairs or reward modeling. We propose Flow Matching Adversarial Imitation Learning (FAIL), which minimizes policy-expert divergence through adversarial training without explicit rewards or pairwise comparisons. We derive two algorithms: FAIL-PD exploits differentiable ODE solvers for low-variance pathwise gradients, while FAIL-PG provides a black-box alternative for discrete or computationally constrained settings. Fine-tuning FLUX with only 13,000 demonstrations from Nano Banana pro, FAIL achieves competitive performance on prompt following and aesthetic benchmarks. Furthermore, the framework generalizes effectively to discrete image and video generation, and functions as a robust regularizer to mitigate reward hacking in reward-based optimization. Code and data are available at https://github.com/HansPolo113/FAIL.

</details>


### [67] [TexSpot: 3D Texture Enhancement with Spatially-uniform Point Latent Representation](https://arxiv.org/abs/2602.12157)
*Ziteng Lu,Yushuang Wu,Chongjie Ye,Yuda Qiu,Jing Shao,Xiaoyang Guo,Jiaqing Zhou,Tianlei Hu,Kun Zhou,Xiaoguang Han*

Main category: cs.CV

TL;DR: TexSpot提出了一种新的3D纹理增强框架，结合点云和UV映射优点，通过Texlet混合3D和2D信息，显著提升了3D纹理生成质量和一致性。


<details>
  <summary>Details</summary>
Motivation: 当前主流的多视角扩散方法在3D纹理生成中存在视角不一致问题，且现有UV映射受限于展开失真，点基方法则受到几何密度限制，难以实现高分辨率纹理。

Method: 提出了TexSpot框架，核心是新型纹理表示Texlet。每个Texlet包含通过2D编码器获得的局部纹理特征，并通过3D编码器融合全局形状信息。利用级联3D到2D解码器重建高质量纹理块，并以Texlet为条件训练扩散Transformer对多视角生成的纹理进行增强。

Result: 实验显示，TexSpot在视觉质量、几何一致性和健壮性方面均明显优于现有主流方法。

Conclusion: TexSpot为3D纹理生成提供了兼具高保真和一致性的全新方法，有效解决了以往UV或点云表示带来的局限性，推动了3D内容生成领域的进步。

Abstract: High-quality 3D texture generation remains a fundamental challenge due to the view-inconsistency inherent in current mainstream multi-view diffusion pipelines. Existing representations either rely on UV maps, which suffer from distortion during unwrapping, or point-based methods, which tightly couple texture fidelity to geometric density that limits high-resolution texture generation. To address these limitations, we introduce TexSpot, a diffusion-based texture enhancement framework. At its core is Texlet, a novel 3D texture representation that merges the geometric expressiveness of point-based 3D textures with the compactness of UV-based representation. Each Texlet latent vector encodes a local texture patch via a 2D encoder and is further aggregated using a 3D encoder to incorporate global shape context. A cascaded 3D-to-2D decoder reconstructs high-quality texture patches, enabling the Texlet space learning. Leveraging this representation, we train a diffusion transformer conditioned on Texlets to refine and enhance textures produced by multi-view diffusion methods. Extensive experiments demonstrate that TexSpot significantly improves visual fidelity, geometric consistency, and robustness over existing state-of-the-art 3D texture generation and enhancement approaches. Project page: https://anonymous.4open.science/w/TexSpot-page-2D91.

</details>


### [68] [DreamID-Omni: Unified Framework for Controllable Human-Centric Audio-Video Generation](https://arxiv.org/abs/2602.12160)
*Xu Guo,Fulong Ye,Qichao Sun,Liyang Chen,Bingchuan Li,Pengze Zhang,Jiawei Liu,Songtao Zhao,Qian He,Xiangwang Hou*

Main category: cs.CV

TL;DR: 本文提出了DreamID-Omni，一个可控的人物音视频生成统一框架，实现多人物、多音色精细控制，全面超越现有学术及商用模型。


<details>
  <summary>Details</summary>
Motivation: 现有音视频联合生成方法将人物相关任务（如指定参考音视频生成、视频编辑、音频驱动视频动画）彼此孤立，且难以在单一框架下精确、解耦地控制多角色身份与音色。

Method: 采用对称条件扩散Transformer，通过对称条件注入机制融合多种调控信号。提出双层解耦策略，包括信号级同步RoPE实现注意力绑定，语义级结构化描述以明确属性与主体关系。设计多任务渐进式训练，利用弱约束生成先验规范强约束任务，防止过拟合并平衡多目标。

Result: 大量实验证明，DreamID-Omni在视频、音频及音视频一致性指标上均达到/超越最新学术及主流商用模型水平。

Conclusion: DreamID-Omni实现了统一、高精度、可控的人物音视频生成，为学术成果向商用领域的转化搭建了桥梁，代码也将开源。

Abstract: Recent advancements in foundation models have revolutionized joint audio-video generation. However, existing approaches typically treat human-centric tasks including reference-based audio-video generation (R2AV), video editing (RV2AV) and audio-driven video animation (RA2V) as isolated objectives. Furthermore, achieving precise, disentangled control over multiple character identities and voice timbres within a single framework remains an open challenge. In this paper, we propose DreamID-Omni, a unified framework for controllable human-centric audio-video generation. Specifically, we design a Symmetric Conditional Diffusion Transformer that integrates heterogeneous conditioning signals via a symmetric conditional injection scheme. To resolve the pervasive identity-timbre binding failures and speaker confusion in multi-person scenarios, we introduce a Dual-Level Disentanglement strategy: Synchronized RoPE at the signal level to ensure rigid attention-space binding, and Structured Captions at the semantic level to establish explicit attribute-subject mappings. Furthermore, we devise a Multi-Task Progressive Training scheme that leverages weakly-constrained generative priors to regularize strongly-constrained tasks, preventing overfitting and harmonizing disparate objectives. Extensive experiments demonstrate that DreamID-Omni achieves comprehensive state-of-the-art performance across video, audio, and audio-visual consistency, even outperforming leading proprietary commercial models. We will release our code to bridge the gap between academic research and commercial-grade applications.

</details>


### [69] [EO-VAE: Towards A Multi-sensor Tokenizer for Earth Observation Data](https://arxiv.org/abs/2602.12177)
*Nils Lehmann,Yi Wang,Zhitong Xiong,Xiaoxiang Zhu*

Main category: cs.CV

TL;DR: 该论文提出了一种用于遥感（EO）数据的统一多传感器变分自编码器（EO-VAE）作为Tokenizer，在TerraMesh数据集上取得了优于现有方法的重建效果。


<details>
  <summary>Details</summary>
Motivation: 当前主流的生成模型依赖于Tokenizer将高维输入压缩为高效的潜在表达，但遥感领域的数据由于传感器多样、光谱通道变动，导致传统Tokenizer难以适应。为了解决这一问题，需要一种能够处理多传感器、灵活通道组合的统一Tokenizer。

Method: 作者提出了EO-VAE，一个多传感器变分自编码器，通过动态超网络（hypernetworks）使得单一模型可以针对不同的通道组合进行编码和重建，从而代替为每个模态单独训练Tokenizer的方法。

Result: 在TerraMesh数据集上的实验显示，EO-VAE在重建精度方面优于现有的TerraMind Tokenizer，验证了其有效性和泛化能力。

Conclusion: EO-VAE为遥感数据的潜在生成建模提供了统一、稳健的Tokenizer基线，有望促进相关生成模型的发展。

Abstract: State-of-the-art generative image and video models rely heavily on tokenizers that compress high-dimensional inputs into more efficient latent representations. While this paradigm has revolutionized RGB generation, Earth observation (EO) data presents unique challenges due to diverse sensor specifications and variable spectral channels. We propose EO-VAE, a multi-sensor variational autoencoder designed to serve as a foundational tokenizer for the EO domain. Unlike prior approaches that train separate tokenizers for each modality, EO-VAE utilizes a single model to encode and reconstruct flexible channel combinations via dynamic hypernetworks. Our experiments on the TerraMesh dataset demonstrate that EO-VAE achieves superior reconstruction fidelity compared to the TerraMind tokenizers, establishing a robust baseline for latent generative modeling in remote sensing.

</details>


### [70] [DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing](https://arxiv.org/abs/2602.12205)
*Dianyi Wang,Ruihang Li,Feng Han,Chaofan Ma,Wei Song,Siyuan Wang,Yibin Wang,Yi Xin,Hongjian Liu,Zhixiong Zhang,Shengyuan Ding,Tianhang Wang,Zhenglin Cheng,Tao Lin,Cheng Jin,Kaicheng Yu,Jingjing Chen,Wenjie Wang,Zhongyu Wei,Jiaqi Wang*

Main category: cs.CV

TL;DR: DeepGen 1.0 是一个5B参数规模的多模态生成与编辑模型，在多个基准上超越了参数规模远大的同类模型。


<details>
  <summary>Details</summary>
Motivation: 当前多模态生成与编辑模型通常参数量巨大（>10B），训练与部署成本高，限制了其实际应用与普及。作者希望设计出参数更小但能力不弱的模型，推动多模态研究的普及。

Method: 1）结构创新：提出 Stacked Channel Bridging（SCB）深度对齐框架，通过从多层视觉语言模型提取特征并融合“think tokens”，为生成主干网络提供结构化、富有推理能力的指导。2）分阶段训练：包括大规模图文对齐预训练、高质量生成/编辑/推理任务联合有监督微调，以及混合回报函数和监督信号的强化学习（MR-GRPO），以提升生成质量和人类偏好对齐性。

Result: 在仅使用约5000万样本训练的情况下，DeepGen 1.0在多个主流基准上取得领先成绩：WISE基准上超越80B参数的HunyuanImage 28%，UniREditBench上超越27B参数的Qwen-Image-Edit 37%。

Conclusion: DeepGen 1.0 通过结构创新和数据驱动训练策略，实现了小参数量下的高性能生成与编辑。开源训练代码、权重和数据，为多模态模型的高效研究和应用提供了有力工具。

Abstract: Current unified multimodal models for image generation and editing typically rely on massive parameter scales (e.g., >10B), entailing prohibitive training costs and deployment footprints. In this work, we present DeepGen 1.0, a lightweight 5B unified model that achieves comprehensive capabilities competitive with or surpassing much larger counterparts. To overcome the limitations of compact models in semantic understanding and fine-grained control, we introduce Stacked Channel Bridging (SCB), a deep alignment framework that extracts hierarchical features from multiple VLM layers and fuses them with learnable 'think tokens' to provide the generative backbone with structured, reasoning-rich guidance. We further design a data-centric training strategy spanning three progressive stages: (1) Alignment Pre-training on large-scale image-text pairs and editing triplets to synchronize VLM and DiT representations, (2) Joint Supervised Fine-tuning on a high-quality mixture of generation, editing, and reasoning tasks to foster omni-capabilities, and (3) Reinforcement Learning with MR-GRPO, which leverages a mixture of reward functions and supervision signals, resulting in substantial gains in generation quality and alignment with human preferences, while maintaining stable training progress and avoiding visual artifacts. Despite being trained on only ~50M samples, DeepGen 1.0 achieves leading performance across diverse benchmarks, surpassing the 80B HunyuanImage by 28% on WISE and the 27B Qwen-Image-Edit by 37% on UniREditBench. By open-sourcing our training code, weights, and datasets, we provide an efficient, high-performance alternative to democratize unified multimodal research.

</details>


### [71] [Best of Both Worlds: Multimodal Reasoning and Generation via Unified Discrete Flow Matching](https://arxiv.org/abs/2602.12221)
*Onkar Susladkar,Tushar Prakash,Gayatri Deshmukh,Kiet A. Nguyen,Jiaxun Zhang,Adheesh Juvekar,Tianshu Bao,Lin Chai,Sparsh Mittal,Inderjit S Dhillon,Ismini Lourentzou*

Main category: cs.CV

TL;DR: UniDFlow是一个统一的离散流匹配框架，适用于多模态理解、生成与编辑，具备零样本泛化能力和高性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态任务容易因目标冲突引发表征纠缠，且可控性受限，亟需一种能够在不同任务间解耦并提升泛化、可控性的统一框架。

Method: UniDFlow通过任务特定的低秩适配器分别处理理解与生成，避免了目标干扰和表征纠缠。提出了一种基于参考的多模态偏好对齐机制，在相同条件下优化相对结果，无需大规模重训练即可提升忠实性与可控性。

Result: 在八项基准测试中均达到了SOTA表现，尤其在缺乏针对性训练的情况下，也能高质量完成修复、图像生成、参考编辑和组合生成等任务，展现强大的零样本泛化能力。

Conclusion: UniDFlow有效实现了多模态理解与生成的解耦，在提高任务适应性、泛化能力和可控性的同时避免了大规模重训练，具备实际应用推广价值。

Abstract: We propose UniDFlow, a unified discrete flow-matching framework for multimodal understanding, generation, and editing. It decouples understanding and generation via task-specific low-rank adapters, avoiding objective interference and representation entanglement, while a novel reference-based multimodal preference alignment optimizes relative outcomes under identical conditioning, improving faithfulness and controllability without large-scale retraining. UniDFlpw achieves SOTA performance across eight benchmarks and exhibits strong zero-shot generalization to tasks including inpainting, in-context image generation, reference-based editing, and compositional generation, despite no explicit task-specific training.

</details>


### [72] [MonarchRT: Efficient Attention for Real-Time Video Generation](https://arxiv.org/abs/2602.12271)
*Krish Agarwal,Zhuoming Chen,Cheng Luo,Yongqi Chen,Haizhong Zheng,Xun Huang,Atri Rudra,Beidi Chen*

Main category: cs.CV

TL;DR: 提出了Monarch-RT，一种面向实时视频生成的高效稀疏注意力结构，提升了扩散变换器在少步自回归推理下的效率和表达能力，实现了真正的实时视频生成。


<details>
  <summary>Details</summary>
Motivation: 目前扩散Transformer用于实时视频生成时，3D自注意力的计算量过高，制约了实时应用。现有稀疏注意力法在单向、少步推理（更接近实时场景）时失效，无法兼顾表达力和效率。

Method: 分析视频注意力结构特征，发现其非简单稀疏而具有复杂的周期和语义关系。在此基础上，提出使用Monarch矩阵进行注意力因式分解，设计对齐区块结构及平铺化参数化，并用定制Triton核优化计算，实现高效稀疏注意力。

Result: Monarch-RT在多种GPU硬件上比最新FlashAttention实现获得1.4-11.8倍加速。在Self-Forcing模型上可实现高达95%的稀疏度且无质量损失，支持单卡16 FPS的真实实时视频生成。

Conclusion: Monarch-RT首次赋能高性能稀疏注意力参数化在实时视频扩散模型中的应用，大幅提升效率和可用性，为后续相关研究开辟新道路。

Abstract: Real-time video generation with Diffusion Transformers is bottlenecked by the quadratic cost of 3D self-attention, especially in real-time regimes that are both few-step and autoregressive, where errors compound across time and each denoising step must carry substantially more information. In this setting, we find that prior sparse-attention approximations break down, despite showing strong results for bidirectional, many-step diffusion. Specifically, we observe that video attention is not reliably sparse, but instead combines pronounced periodic structure driven by spatiotemporal position with dynamic, sparse semantic correspondences and dense mixing, exceeding the representational capacity of even oracle top-k attention. Building on this insight, we propose Monarch-RT, a structured attention parameterization for video diffusion models that factorizes attention using Monarch matrices. Through appropriately aligned block structure and our extended tiled Monarch parameterization, we achieve high expressivity while preserving computational efficiency. We further overcome the overhead of parameterization through finetuning, with custom Triton kernels. We first validate the high efficacy of Monarch-RT over existing sparse baselines designed only for bidirectional models. We further observe that Monarch-RT attains up to 95% attention sparsity with no loss in quality when applied to the state-of-the-art model Self-Forcing, making Monarch-RT a pioneering work on highly-capable sparse attention parameterization for real-time video generation. Our optimized implementation outperforms FlashAttention-2, FlashAttention-3, and FlashAttention-4 kernels on Nvidia RTX 5090, H100, and B200 GPUs respectively, providing kernel speedups in the range of 1.4-11.8X. This enables us, for the first time, to achieve true real-time video generation with Self-Forcing at 16 FPS on a single RTX 5090.

</details>


### [73] [UniT: Unified Multimodal Chain-of-Thought Test-time Scaling](https://arxiv.org/abs/2602.12279)
*Leon Liangyu Chen,Haoyu Ma,Zhipeng Fan,Ziqi Huang,Animesh Sinha,Xiaoliang Dai,Jialiang Wang,Zecheng He,Jianwei Yang,Chunyuan Li,Junzhe Sun,Chu Wang,Serena Yeung-Levy,Felix Juefei-Xu*

Main category: cs.CV

TL;DR: 本文提出了UniT框架，使统一多模态模型能够在推理过程中进行多轮的思考、验证和修正，显著提升了复杂多模态任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有统一多模态模型仅做“一次性”输出，难以应对需要复杂推理、空间组合或指令演化的多模态任务。语言大模型已通过测试时多轮迭代推理提升性能，但这种测试时扩展推理的策略仍未应用到多模态模型。

Method: 提出UniT框架，核心包括：代理式数据合成、统一模型训练及灵活的测试时推理。推理阶段采用链式思维（Chain-of-Thought，CoT）多轮推理，模型能自发进行验证、分解子目标和内容记忆。

Result: （1）只需以短推理数据训练，模型即可在真实测试中实现长链式推理并泛化；（2）顺序链式推理在扩展和算力效率上优于并行采样策略；（3）以生成和编辑为训练路径，模型在分布外的视觉推理任务表现更好。

Conclusion: 多模态测试时推理扩展是一条提升统一生成—理解模型的有效路线。UniT实现了跨模态复杂任务下的多轮推理、验证和修正，有望推动统一多模态智能的发展。

Abstract: Unified models can handle both multimodal understanding and generation within a single architecture, yet they typically operate in a single pass without iteratively refining their outputs. Many multimodal tasks, especially those involving complex spatial compositions, multiple interacting objects, or evolving instructions, require decomposing instructions, verifying intermediate results, and making iterative corrections. While test-time scaling (TTS) has demonstrated that allocating additional inference compute for iterative reasoning substantially improves language model performance, extending this paradigm to unified multimodal models remains an open challenge. We introduce UniT, a framework for multimodal chain-of-thought test-time scaling that enables a single unified model to reason, verify, and refine across multiple rounds. UniT combines agentic data synthesis, unified model training, and flexible test-time inference to elicit cognitive behaviors including verification, subgoal decomposition, and content memory. Our key findings are: (1) unified models trained on short reasoning trajectories generalize to longer inference chains at test time; (2) sequential chain-of-thought reasoning provides a more scalable and compute-efficient TTS strategy than parallel sampling; (3) training on generation and editing trajectories improves out-of-distribution visual reasoning. These results establish multimodal test-time scaling as an effective paradigm for advancing both generation and understanding in unified models.

</details>


### [74] [Stroke of Surprise: Progressive Semantic Illusions in Vector Sketching](https://arxiv.org/abs/2602.12280)
*Huai-Hsun Cheng,Siang-Ling Zhang,Yu-Lun Liu*

Main category: cs.CV

TL;DR: 该论文提出了一种新型的矢量素描任务，通过逐步添加笔画让单个草图在不同阶段表现出完全不同的语义，即“渐进式语义错觉”。作者还提出了相应的生成框架Stroke of Surprise，能优化矢量笔画以满足不同阶段下的双重语义解释需求。实验结果显示该方法在可识别性和错觉强度方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在视觉错觉领域，传统方法多依赖于空间操控，此工作动机是希望在“时间维”上实现错觉效果，即通过逐步绘制笔画，让单一草图在不同时刻切换语义解释，拓展视觉谜题（anagrams）的形式。

Method: 提出“渐进式语义错觉”任务与Stroke of Surprise生成框架。该框架采用序列感知的联合优化策略，通过双分支Score Distillation Sampling (SDS)机制动态调整前缀笔画，发现同时适用于两目标（如鸭与羊）的共通结构基础。同时设计Overlay Loss损失函数，鼓励新增笔画与原有结构互补而非遮挡。

Result: 通过大量实验，作者的方法在可识别性与错觉强度等主要指标上，均明显优于当前主流基准方法，并首次实现了从空间到时间维度扩展的动态视觉谜题。

Conclusion: 该工作在视觉错觉任务中实现了语义随笔画动态演化的新型错觉形式，提出的优化框架和损失在实际效果上展现出强大的识别与错觉能力，为视觉错觉与计算机生成视觉艺术领域带来新的视角与工具。

Abstract: Visual illusions traditionally rely on spatial manipulations such as multi-view consistency. In this work, we introduce Progressive Semantic Illusions, a novel vector sketching task where a single sketch undergoes a dramatic semantic transformation through the sequential addition of strokes. We present Stroke of Surprise, a generative framework that optimizes vector strokes to satisfy distinct semantic interpretations at different drawing stages. The core challenge lies in the "dual-constraint": initial prefix strokes must form a coherent object (e.g., a duck) while simultaneously serving as the structural foundation for a second concept (e.g., a sheep) upon adding delta strokes. To address this, we propose a sequence-aware joint optimization framework driven by a dual-branch Score Distillation Sampling (SDS) mechanism. Unlike sequential approaches that freeze the initial state, our method dynamically adjusts prefix strokes to discover a "common structural subspace" valid for both targets. Furthermore, we introduce a novel Overlay Loss that enforces spatial complementarity, ensuring structural integration rather than occlusion. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baselines in recognizability and illusion strength, successfully expanding visual anagrams from the spatial to the temporal dimension. Project page: https://stroke-of-surprise.github.io/

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [75] [HybridRAG: A Practical LLM-based ChatBot Framework based on Pre-Generated Q&A over Raw Unstructured Documents](https://arxiv.org/abs/2602.11156)
*Sungmoon Kim,Hyuna Jeon,Dahye Kim,Mingyu Kim,Dong-Kyu Chae,Jiwoong Kim*

Main category: cs.CL

TL;DR: 本文提出了HybridRAG框架，可以高效处理原始非结构化PDF文档，为聊天机器人提供更快且准确的知识增强问答能力。其通过OCR和文档版面分析将PDF转为结构化文本，预生成问答知识库以提升响应速度和质量。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法多假设知识来源为结构化文本（如Wikipedia），且每次用户提问时需实时检索与生成答案，但真实应用中往往需要处理非结构化源（如PDF），这会影响效率和适用性。

Method: HybridRAG框架首先利用OCR和版面分析技术，将包含复杂布局的PDF文档转为分层文本块；然后基于这些块通过LLM预生成问答知识库；查询时，用户问题先与知识库中的Q&A进行匹配，若匹配成功则直接返回答案，匹配失败时才启动实时生成。

Result: 在OHRBench数据集上，HybridRAG相比标准RAG方法提供了更高的问答质量及响应速度（更低延迟）。

Conclusion: HybridRAG为需要处理大量非结构化文档、面向多用户且计算资源受限的聊天机器人应用，提供了更实用的RAG解决方案。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful approach for grounding Large Language Model (LLM)-based chatbot responses on external knowledge. However, existing RAG studies typically assume well-structured textual sources (e.g. Wikipedia or curated datasets) and perform retrieval and generation at query time, which can limit their applicability in real-world chatbot scenarios. In this paper, we present HybridRAG, a novel and practical RAG framework towards more accurate and faster chatbot responses. First, HybridRAG ingests raw, unstructured PDF documents containing complex layouts (text, tables, figures) via Optical Character Recognition (OCR) and layout analysis, and convert them into hierarchical text chunks. Then, it pre-generates a plausible question-answer (QA) knowledge base from the organized chunks using an LLM. At query time, user questions are matched against this QA bank to retrieve immediate answers when possible, and only if no suitable QA match is found does our framework fall back to an on-the-fly response generation. Experiments on OHRBench demonstrate that our HybridRAG provides higher answer quality and lower latency compared to a standard RAG baseline. We believe that HybridRAG could be a practical solution for real-world chatbot applications that must handle large volumes of unstructured documents and lots of users under limited computational resources.

</details>


### [76] [Response-Based Knowledge Distillation for Multilingual Jailbreak Prevention Unwittingly Compromises Safety](https://arxiv.org/abs/2602.11157)
*Max Zhang,Derek Liu,Kai Zhang,Joshua Franco,Haihao Liu*

Main category: cs.CL

TL;DR: 本文探讨了使用知识蒸馏（KD）技术对多语言大模型进行安全对齐的有效性，发现直接蒸馏安全拒答行为可能会提升模型被越狱的风险，但通过优化方法有望提升多语言安全性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的安全对齐主要基于英文数据，导致非英语、尤其是低资源语言下存在安全漏洞，因此亟需研究面向多语言的安全对齐手段。

Method: 作者将OpenAI o1-mini老师模型的拒答行为，通过低秩适应（LoRA）、参数高效微调（PEFT）、以及2.8万个多语言越狱提示，对三个开源学生模型进行知识蒸馏。并在MultiJail基准和GSM8K推理任务上评估模型性能。

Result: 标准的安全拒答蒸馏训练反而使得所有学生模型的越狱成功率上升（最高提升16.6%），不同基座模型对未见语言的泛化表现差异较大。通过去除带来安全退化的‘边界’拒答数据，可缓解甚至逆转这一负面效应，但模型推理能力（如GSM8K）有所下降。

Conclusion: 多语言知识蒸馏在安全对齐上存在挑战甚至副作用，但通过细粒度的数据筛选与优化，有潜力改善多语言安全，值得更深入研究。

Abstract: Large language models (LLMs) are increasingly deployed worldwide, yet their safety alignment remains predominantly English-centric. This allows for vulnerabilities in non-English contexts, especially with low-resource languages. We introduce a novel application of knowledge distillation (KD) in the context of multilingual jailbreak prevention, examining its efficacy. We distill the refusal behaviors of a proprietary teacher model (OpenAI o1-mini) with Low-Rank Adaptation (LoRA) into three open-source student models: Meta-Llama-3-8B-Instruct, Gemma-2-2B-IT, and Qwen3-8B, using ~28,000 multilingual jailbreak prompts from XSafety via black-box response-based, parameter-efficient fine-tuning (PEFT). Evaluation on the MultiJail benchmark reveals a counterintuitive behavior: standard fine-tuning on the teacher's ``safe'' refusal data inadvertently increases Jailbreak Success Rate (JSR) for all student models, up to 16.6 percentage points. Our experiments reveal a divergent generalization to unseen languages during distillation, with varying outcomes depending on the base model. By removing a primary source of safety degradation, nuanced `boundary' refusals, we mitigate or even reverse safety declines in student models, although reductions in reasoning performance (GSM8K) persist. Overall, our exploratory study highlights the challenges and potential of KD as a technique for multilingual safety alignment, offering a foundation for future research in this direction.

</details>


### [77] [Retrieval Heads are Dynamic](https://arxiv.org/abs/2602.11162)
*Yuping Lin,Zitao Li,Yue Xing,Pengfei He,Yingqian Cui,Yaliang Li,Bolin Ding,Jingren Zhou,Jiliang Tang*

Main category: cs.CL

TL;DR: 本文揭示LLM中的“检索头”在生成过程中会动态变化，并且各时间步具有不可替代性，还发现模型内部状态可预测未来检索头模式。


<details>
  <summary>Details</summary>
Motivation: 以往关于LLM检索头的研究基于全局统计，忽略了生成时序上的细粒度动态，因而不能深入揭示检索头在实际推理过程中的角色。作者希望了解检索头是否随时间动态变化，并探索其不可替代性及其与模型内部状态的关系。

Method: 作者系统分析了LLM在自回归生成各个时间步的检索头表现，分别在Needle-in-a-Haystack任务和多跳问答任务上，对比了动态检索头和静态检索头，并检验模型隐状态对未来检索头的预测能力。

Result: 实验发现：(1) 检索头在不同时间步是动态且变化的；(2) 动态检索头在每个时间步具有特异性，用静态方式替换会降低性能；(3) 模型隐状态能预测未来检索头，表明存在内在计划机制。

Conclusion: LLM的检索头具有显著的时序动态和不可替代性，且模型存在某种内在信息规划，对理解和改进检索增强生成具有重要意义。

Abstract: Recent studies have identified "retrieval heads" in Large Language Models (LLMs) responsible for extracting information from input contexts. However, prior works largely rely on static statistics aggregated across datasets, identifying heads that perform retrieval on average. This perspective overlooks the fine-grained temporal dynamics of autoregressive generation. In this paper, we investigate retrieval heads from a dynamic perspective. Through extensive analysis, we establish three core claims: (1) Dynamism: Retrieval heads vary dynamically across timesteps; (2) Irreplaceability: Dynamic retrieval heads are specific at each timestep and cannot be effectively replaced by static retrieval heads; and (3) Correlation: The model's hidden state encodes a predictive signal for future retrieval head patterns, indicating an internal planning mechanism. We validate these findings on the Needle-in-a-Haystack task and a multi-hop QA task, and quantify the differences on the utility of dynamic and static retrieval heads in a Dynamic Retrieval-Augmented Generation framework. Our study provides new insights into the internal mechanisms of LLMs.

</details>


### [78] [Nested Named Entity Recognition in Plasma Physics Research Articles](https://arxiv.org/abs/2602.11163)
*Muhammad Haris,Hans Höft,Markus M. Becker,Markus Stocker*

Main category: cs.CL

TL;DR: 本文提出了一种基于encoder-transformers和条件随机场（CRF）的命名实体识别方法，专用于等离子体物理领域的学术文章，旨在精准提取嵌套实体。


<details>
  <summary>Details</summary>
Motivation: 等离子体物理学的科研论文包含大量复杂且专业的名词与信息，常规NER方法难以直接适应。为实现如高级检索等功能，需要针对性地解决科学文本中嵌套实体的提取问题。

Method: 1）构建并注释专门的等离子体物理语料库，设计16种嵌套实体类别；2）采用BERT-CRF模型，针对每类实体单独训练模型，实现实体特定的识别；3）通过系统的超参数优化，提升模型性能。

Result: 提出的方法能够有效地从等离子体物理领域的文本中识别并抽取复杂嵌套实体，模型针对实体类别专业化，整体效能提升明显。

Conclusion: 该方法不仅推进了等离子体物理领域实体识别的精度，还为科研人员检索和分析专业文献提供了坚实的技术基础，具备在科学文本处理领域推广应用的潜力。

Abstract: Named Entity Recognition (NER) is an important task in natural language processing that aims to identify and extract key entities from unstructured text. We present a novel application of NER in plasma physics research articles and address the challenges of extracting specialized entities from scientific text in this domain. Research articles in plasma physics often contain highly complex and context-rich content that must be extracted to enable, e.g., advanced search. We propose a lightweight approach based on encoder-transformers and conditional random fields to extract (nested) named entities from plasma physics research articles. First, we annotate a plasma physics corpus with 16 classes specifically designed for the nested NER task. Second, we evaluate an entity-specific model specialization approach, where independent BERT-CRF models are trained to recognize individual entity types in plasma physics text. Third, we integrate an optimization process to systematically fine-tune hyperparameters and enhance model performance. Our work contributes to the advancement of entity recognition in plasma physics and also provides a foundation to support researchers in navigating and analyzing scientific literature.

</details>


### [79] [Assessing LLM Reliability on Temporally Recent Open-Domain Questions](https://arxiv.org/abs/2602.11165)
*Pushwitha Krishnappa,Amit Das,Vinija Jain,Tathagata Mukherjee,Aman Chadha*

Main category: cs.CL

TL;DR: 本文提出了RECOM数据集，针对最新Reddit问题，评测了不同大模型的语义对齐表现，发现语义一致度高但词汇重叠低，并讨论了评估指标的局限。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型越来越多地应用于开放领域问答，但对于模型在最近时事上的回答能力及其和人类答案的一致性尚缺乏系统研究，尤其是在合适的评测数据集和指标方面存在不足。

Method: 作者构建了RECOM数据集，包含15,000条2025年9月Reddit最新问答。用4个开源大语言模型（Llama3.1-8B、Mistral-7B、Gemma-2-9B、GPT-OSS-20B）进行生成。使用BLEU、ROUGE、BERTScore、MoverScore、余弦相似度及NLI等评估模型输出与社区答案的一致性，从词汇、语义和逻辑推理多个维度综合评价。

Result: 所有模型输出与参考答案的语义余弦相似度高于99%，但BLEU-1低于8%，二者之间有90%以上的差距，说明模型倾向于同义改写而非照搬词汇。MoverScore显示出中间态（51-53%）。模型规模与表现不直接相关：小模型Mistral-7B在各项指标上优于GPT-OSS-20B。NLI显示模型与人类社区间直接矛盾率不足7%。

Conclusion: 当前常用的词汇类指标难以准确衡量模型真实的生成质量，建议在评估大模型开放域能力时采用多维度、尤其是语义级的评判标准。RECOM数据集已开源，以促进后续研究。

Abstract: Large Language Models (LLMs) are increasingly deployed for open-domain question answering, yet their alignment with human perspectives on temporally recent information remains underexplored. We introduce RECOM (Reddit Evaluation for Correspondence of Models), a benchmark dataset of 15,000 recent Reddit questions from September 2025 paired with community-derived reference answers. We investigate how four open-source LLMs (Llama3.1-8B, Mistral-7B, Gemma-2-9B, and GPT-OSS-20B) respond to these questions, evaluating alignment using lexical metrics (BLEU, ROUGE), semantic similarity (BERTScore, MoverScore, cosine similarity), and logical inference (NLI). Our central finding is a striking semantic-lexical paradox: all models achieve over 99% cosine similarity with references despite less than 8% BLEU-1 overlap, a 90+ percentage point gap indicating that models preserve meaning through extensive paraphrasing rather than lexical reproduction. MoverScore (51-53%) confirms this pattern, occupying an intermediate position that reflects the optimal transport cost of semantic alignment. Furthermore, model scale does not predict performance: Mistral-7B (7B parameters) outperforms GPT-OSS-20B (20B parameters) across all metrics. NLI analysis reveals that contradiction rates remain below 7%, suggesting models rarely generate content that directly conflicts with human consensus. These findings challenge the reliability of lexical metrics for evaluating abstractive generation and argue for multi-dimensional evaluation frameworks that capture semantic fidelity beyond surface-level text matching. The RECOM dataset is publicly available at https://anonymous.4open.science/r/recom-D4B0

</details>


### [80] [Small Updates, Big Doubts: Does Parameter-Efficient Fine-tuning Enhance Hallucination Detection ?](https://arxiv.org/abs/2602.11166)
*Xu Hu,Yifan Zhang,Songtao Wei,Chen Zhao,Qiannan Li,Bingzhe Li,Feng Chen*

Main category: cs.CL

TL;DR: 本文系统性地分析了参数高效微调（PEFT）方法对大语言模型（LLM）在问答数据集上的幻觉检测影响，发现PEFT普遍提升了各种幻觉检测方法的表现，主要通过改变模型不确定性的表达方式。


<details>
  <summary>Details</summary>
Motivation: 虽然PEFT常被认为提升了LLM在下游任务的真实性和正确性，但其对幻觉行为（如模型编造事实）的具体影响尚不明确，尤其是在问答任务上的影响。因此，作者希望系统性研究PEFT对幻觉检测能力的实际作用。

Method: 作者在三个主流开源LLM及三个事实型问答数据集上进行实证研究，分别使用了七种无监督幻觉检测方法（包括语义一致性、置信度、熵等三类检测策略）评估PEFT带来的性能变化，并通过线性探针和表征诊断技术进一步分析PEFT对模型内部表征的影响。

Result: 实验结果显示，PEFT方法能大幅提升不同类型幻觉检测器的性能（如AUROC分数），且这一提升跨越不同检测范式。此外，进一步分析表明，PEFT并非主要注入了新的事实知识，而是重塑了模型对不确定性信息的编码和表达方式。

Conclusion: 总体上，PEFT不仅提升了LLM在下游问答任务中的幻觉检测能力，且其改进主要体现在优化不确定性表征，而非单纯增加知识。这为后续LLM安全性与可控性研究提供了新的思路。

Abstract: Parameter-efficient fine-tuning (PEFT) methods are widely used to adapt large language models (LLMs) to downstream tasks and are often assumed to improve factual correctness. However, how the parameter-efficient fine-tuning methods affect hallucination behavior remains insufficiently understood, especially on QA datasets. In this work, we systematically investigate the impact of PEFT on hallucination detection through a comprehensive empirical study across three open-weight LLM backbones and three fact-seeking QA benchmarks. For each model, we evaluate performance using seven unsupervised hallucination detection methods spanning three complementary approaches: semantic consistency based detectors, confidence based detectors, and entropy based detectors. This multifaceted evaluation enables us to characterize how PEFT reshapes uncertainty across different detection paradigms. In conclusion, our experimental results show that PEFT consistently strengthens hallucination detection ability, substantially improving AUROC across a wide range of hallucination detectors. Besides, further analyses using linear probes and representation diagnostics indicate that PEFT methods primarily reshapes how uncertainty is encoded and surfaced, comparing with injecting new factual knowledge into the models.

</details>


### [81] [Visualizing and Benchmarking LLM Factual Hallucination Tendencies via Internal State Analysis and Clustering](https://arxiv.org/abs/2602.11167)
*Nathan Mao,Varun Kaushik,Shreya Shivkumar,Parham Sharafoleslami,Kevin Zhu,Sunishchal Dev*

Main category: cs.CL

TL;DR: 本文提出了FalseCite数据集，专门用于检测和评估在引用被误导或伪造时大语言模型产生幻觉（捏造信息）的能力。使用GPT-4o-mini、Falcon-7B和Mistral 7-B在该数据集上测试，发现误导性引用会显著增强模型产生幻觉的几率，且可通过分析隐藏状态向量进一步研究这一现象。


<details>
  <summary>Details</summary>
Motivation: 大语言模型频繁出现“幻觉”现象，尤以医学、法律等敏感领域危害更大。现有研究对幻觉的系统评估和根因剖析不完善，缺乏专注于引用误导诱发幻觉的数据集。作者的目标是系统化研究这一问题，填补相关评测基准的空白。

Method: 作者构建了FalseCite这一精心设计的数据集，该数据集含有利用假引用诱导幻觉的测试样本。选取主流大语言模型（GPT-4o-mini、Falcon-7B、Mistral 7-B）进行实验，并对模型产生幻觉时的内部隐藏状态进行可视化和聚类分析，探索神经特征变化。

Result: 实验表明，针对含有欺骗性引用的虚假主张，模型产生幻觉的概率显著提升，GPT-4o-mini受影响最为明显。对隐藏状态的分析发现，不论是否产生幻觉，隐藏状态向量都会呈现一种角状轨迹形态。

Conclusion: FalseCite作为研究和评估大语言模型幻觉问题的重要基准，有助于推进幻觉检测和缓解方法的研究。该工作可为未来相关模型训练和评测体系的改进提供理论和实验基础。

Abstract: Large Language Models (LLMs) often hallucinate, generating nonsensical or false information that can be especially harmful in sensitive fields such as medicine or law. To study this phenomenon systematically, we introduce FalseCite, a curated dataset designed to capture and benchmark hallucinated responses induced by misleading or fabricated citations. Running GPT-4o-mini, Falcon-7B, and Mistral 7-B through FalseCite, we observed a noticeable increase in hallucination activity for false claims with deceptive citations, especially in GPT-4o-mini. Using the responses from FalseCite, we can also analyze the internal states of hallucinating models, visualizing and clustering the hidden state vectors. From this analysis, we noticed that the hidden state vectors, regardless of hallucination or non-hallucination, tend to trace out a distinct horn-like shape. Our work underscores FalseCite's potential as a foundation for evaluating and mitigating hallucinations in future LLM research.

</details>


### [82] [Enhancing SDG-Text Classification with Combinatorial Fusion Analysis and Generative AI](https://arxiv.org/abs/2602.11168)
*Jingyan Xu,Marcelo L. LaFleur,Christina Schweikert,D. Frank Hsu*

Main category: cs.CL

TL;DR: 本文旨在通过多模型集成和生成式AI技术，提高文本依据联合国可持续发展目标(SDGs)的分类效果，CFA方法结合了多个智能模型及人工专家知识，取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 在社交分析等依赖大量文本数据的场景下，现有文本分类方法难以应对类别难区分、类别相关性强等挑战，尤其是在SDG等复杂标签体系中，对更高效、更准确的分类手段有迫切需求。

Method: 采用生成式AI生成合成训练数据，并引入CFA（Combinatorial Fusion Analysis）系统融合范式，通过rank-score characteristic (RSC)函数和cognitive diversity (CD)，集成多个分类性能优良且多样性的模型；最终将多模型决策与人工专家判断结果进行对比和融合。

Result: CFA多模型融合分类性能达到96.73%，优于任何单一分类模型，并通过与人类领域专家的结果对比，证实多模型与专家智能的互补性。

Conclusion: 多模型（ML/AI）智能融合与人工专家意见的结合，不仅能够相互补充，还可提升文本分类准确性，对SDG等复杂社会议题的文本分析尤为有效。

Abstract: (Natural Language Processing) NLP techniques such as text classification and topic discovery are very useful in many application areas including information retrieval, knowledge discovery, policy formulation, and decision-making. However, it remains a challenging problem in cases where the categories are unavailable, difficult to differentiate, or are interrelated. Social analysis with human context is an area that can benefit from text classification, as it relies substantially on text data. The focus of this paper is to enhance the classification of text according to the UN's Sustainable Development Goals (SDGs) by collecting and combining intelligence from multiple models. Combinatorial Fusion Analysis (CFA), a system fusion paradigm using a rank-score characteristic (RSC) function and cognitive diversity (CD), has been used to enhance classifier methods by combining a set of relatively good and mutually diverse classification models. We use a generative AI model to generate synthetic data for model training and then apply CFA to this classification task. The CFA technique achieves 96.73% performance, outperforming the best individual model. We compare the outcomes with those obtained from human domain experts. It is demonstrated that combining intelligence from multiple ML/AI models using CFA and getting input from human experts can, not only complement, but also enhance each other.

</details>


### [83] [Disentangling Direction and Magnitude in Transformer Representations: A Double Dissociation Through L2-Matched Perturbation Analysis](https://arxiv.org/abs/2602.11169)
*Mangadoddi Srikar Vardhan,Lekkala Sai Teja*

Main category: cs.CL

TL;DR: 本文通过分析Transformer隐藏状态的向量方向与幅值，发现二者在模型中的功能作用存在解耦特性：方向更影响语言理解，幅值更影响句法处理。


<details>
  <summary>Details</summary>
Motivation: 目前尚不清楚高维向量的方向（orientation）和幅值（norm）在Transformer中的真实作用，作者希望理解这两者对模型表现的具体影响及其分工。

Method: 作者提出L2-matched扰动分析法，分别对隐藏状态的角度和幅值进行同等大小的扰动，并追踪其对语言建模损失和句法任务准确率的影响；进一步通过因果干预追踪损伤在网络中的传播路径。

Result: 角度扰动对语言建模损失影响最大（高达42.9），幅值扰动对句法任务准确率影响更大（下降20.4%）；角度损伤主要通过attention通路传播，幅值损伤部分通过LayerNorm通路传播。这在Pythia系列模型中具有一致性；RMSNorm结构中模式发生变化。

Conclusion: 方向与幅值在LayerNorm架构中起部分解耦的功能作用：方向主导注意力分配，幅值调节精细句法判断强度。这对模型可解释性与编辑能力研究具有意义，并丰富了线性表示假设。

Abstract: Transformer hidden states encode information as high-dimensional vectors, yet whether direction (orientation in representational space) and magnitude (vector norm) serve distinct functional roles remains unclear. Studying Pythia-family models, we discover a striking cross-over dissociation: angular perturbations cause up to 42.9 more damage to language modeling loss, while magnitude perturbations cause disproportionately more damage to syntactic processing (20.4% vs.1.6% accuracy drop on subject-verb agreement).This finding is enabled by L2-matched perturbation analysis, a methodology ensuring that an gular and magnitude perturbations achieve identical Euclidean displacements. Causal intervention reveals that angular damage flows substantially through the attention pathways (28.4% loss recovery via attention repair), while magnitude damage flows partly through the LayerNorm pathways(29.9% recovery via LayerNorm repair). These patterns replicate across scales within the Pythia architecture family. These findings provide evidence that direction and magnitude support partially distinct computational roles in LayerNorm based architectures. The direction preferentially affects attentional routing, while magnitude modulates processing intensity for fine-grained syntactic judgments. We find different patterns in RMSNorm-based architectures, suggesting that the dissociation depends on architectural choices. Our results refine the linear representation hypothesis and have implications for model editing and interpretability research

</details>


### [84] [PRIME: Policy-Reinforced Iterative Multi-agent Execution for Algorithmic Reasoning in Large Language Models](https://arxiv.org/abs/2602.11170)
*Jiawei Xu,Zhenyu Yu,Ziqian Bi,Minh Duc Pham,Xiaoyi Qu,Danyang Zhang*

Main category: cs.CL

TL;DR: 提出PRIME框架提升大语言模型在算法推理任务上的能力，并构建了大规模评测集PRIME-Bench，效果显著优于以往方法。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型虽然在推理任务上表现优秀，但在复杂的算法推理场景下效果不佳，主要因难以维持长步骤、强约束的正确性。为突破此限制，作者决定设计更加结构化的方法。

Method: 设计了由三类智能体构成的PRIME框架：执行者负责逐步推理，验证者检查约束达成情况，协调者管理回溯流程；三者协同，通过群体相对策略优化训练。并提出了包含12类任务、51,600实例的大型算法推理基准PRIME-Bench，用于全面评测。

Result: PRIME平均准确率从基线的26.8%提升到93.8%。在Turing机和长除法等需要持续状态跟踪的任务上尤为明显（提升至92%-94%）。消融实验表明，迭代验证机制是主要贡献因素，能有效阻止错误累计。较小模型受益更大，可达到比自己大8倍模型相当的准确率。

Conclusion: PRIME大幅提升了大模型在算法推理任务的能力，尤其是长步骤和高约束场景。结构化多智能体与迭代验证机制对防止错误扩散效果显著，未来值得在更大范围内推广。

Abstract: Large language models have demonstrated remarkable capabilities across diverse reasoning tasks, yet their performance on algorithmic reasoning remains limited. To handle this limitation, we propose PRIME (Policy-Reinforced Iterative Multi-agent Execution), a framework comprising three specialized agents, an executor for step-by-step reasoning, a verifier for constraint checking, and a coordinator for backtracking control, optimized through group relative policy optimization. For comprehensive evaluation, we introduce PRIME-Bench, the largest algorithmic reasoning benchmark to date, comprising 86 tasks across 12 categories with 51,600 instances. Tasks span sorting algorithms, graph and tree structures, automata and state machines, symbolic reasoning, and constraint-based puzzles, with execution traces reaching over one million steps. Compared to baseline approach, PRIME improves average accuracy from 26.8% to 93.8%, a 250% relative gain. The largest improvements occur on tasks requiring sustained state tracking, with Turing machine simulation improving from 9% to 92% and long division from 16% to 94%. Ablation studies identify iterative verification as the primary contributor, preventing the error propagation that causes baseline approaches to fail catastrophically. Analysis across model scales (8B-120B parameters) reveals that smaller models benefit disproportionately, achieving accuracy comparable to models 8x larger.

</details>


### [85] [Efficient Hyper-Parameter Search for LoRA via Language-aided Bayesian Optimization](https://arxiv.org/abs/2602.11171)
*Baek Seong-Eun,Lee Jung-Mok,Kim Sung-Bin,Tae-Hyun Oh*

Main category: cs.CL

TL;DR: 本文提出了一种通过结合预训练大语言模型（LLMs）领域知识与贝叶斯优化（BO），高效搜索LoRA微调超参数的新方法。该方法显著减少了超参数调优的计算成本，并在极少次数迭代下取得较大性能提升。


<details>
  <summary>Details</summary>
Motivation: LoRA虽然极大提高了LLM微调的效率，但其对超参数高度敏感，需要消耗大量计算资源进行超参数搜索。作者希望设计更高效的方法，减少资源消耗并提升调参效果。

Method: 提出将LLM领域知识通过自然语言Prompt嵌入LLM作为离散-连续映射，将超参及其知识映射到连续向量空间，再在该空间用BO进行搜索。此外，引入可学习的token建模prompt难以表达的剩余信息，并利用全量/子集集数据上LoRA训练表现的高度相关性，引入数据子集代理训练评估以进一步提升效率。

Result: 新方法仅用约30次迭代即可找到超参数，使模型性能比标准的45000组超参数组合中最佳配置高出20%以上，显著提升了调优效率和应用性。

Conclusion: 融合LLM领域知识和贝叶斯优化的超参数搜索方法，极大提高了LoRA微调的高效性和最终表现，对低资源环境下大模型落地与实际应用意义重大。

Abstract: Fine-tuning Large Language Models (LLMs) with Low-Rank Adaptation (LoRA) enables resource-efficient personalization or specialization, but it comes at the expense of additional hyperparameter tuning. Although LoRA makes fine-tuning efficient, it is highly sensitive to the choice of hyperparameters, and exhaustive hyperparameter search is still computationally very demanding. To address these challenges, we propose a framework that integrates the domain knowledge of pre-trained LLMs into Bayesian Optimization (BO) to efficiently search for LoRA hyperparameters. To leverage the informed knowledge of LLMs, we repurpose LLMs as a discrete-to-continuous mapping to link the hyperparameters and their domain knowledge with a continuous vector space, where BO is conducted. We design and control the mapping by language prompting, where we provide a domain-aware textual prompt describing the relationships among hyperparameters and their respective roles; thereby, we explicitly inject domain knowledge about LoRA into the LLM in natural language. Also, we model the residual information that is hard to linguistically describe in the prompt with an additional learnable token. This aids BO to sample more high-performing hyperparameters. In addition, by leveraging the observation of the strong correlation between the respective performance obtained from full and subset training datasets in LoRA training regimes, we introduce proxy training and evaluation with a data subset. This further increases the efficiency of our method. We demonstrate that our hyperparameter found with only about 30 iterations achieves more than 20% performance improvement over standard hyperparameters found from about 45,000 combinations.

</details>


### [86] [Synthesizing the Virtual Advocate: A Multi-Persona Speech Generation Framework for Diverse Linguistic Jurisdictions in Indic Languages](https://arxiv.org/abs/2602.11172)
*Aniket Deroy*

Main category: cs.CL

TL;DR: 论文评价了Gemini 2.5 Flash TTS和Gemini 2.5 Pro TTS在五种印度语言下生成法庭演讲音频的表现，展示其在法律程序性任务中的有效性，但在情感和说服力表达上仍存在挑战。


<details>
  <summary>Details</summary>
Motivation: 法律辩护需兼具权威、节奏感与情感智能，多语种TTS模型如果能胜任，则可推动虚拟法庭等场景发展，但印地语区的语言多样性为技术提出了挑战。

Method: 论文提出了一套利用Gemini 2.5原生的多语种支持和上下文节奏调整的提示框架，并对Tamil、Telugu、Bengali、Hindi和Gujarati五种语言下的合成法庭演讲进行测试和分析。

Result: 模型在程序性信息传递上表现优异，语调权威但较单调，对于 Bengali 和 Gujarati 的发音表现较弱，对于需要表达高度情感和说服力的任务完成度不佳。

Conclusion: 现有多语种TTS已可胜任法律程序性任务，但在动态语调、情感丰富度和说服力仿真方面仍有不足，特别是在某些语言的发音和情感传达上有待进一步改进。

Abstract: Legal advocacy requires a unique combination of authoritative tone, rhythmic pausing for emphasis, and emotional intelligence. This study investigates the performance of the Gemini 2.5 Flash TTS and Gemini 2.5 Pro TTS models in generating synthetic courtroom speeches across five Indic languages: Tamil, Telugu, Bengali, Hindi, and Gujarati. We propose a prompting framework that utilizes Gemini 2.5s native support for 5 languages and its context-aware pacing to produce distinct advocate personas. The evolution of Large Language Models (LLMs) has shifted the focus of TexttoSpeech (TTS) technology from basic intelligibility to context-aware, expressive synthesis. In the legal domain, synthetic speech must convey authority and a specific professional persona a task that becomes significantly more complex in the linguistically diverse landscape of India. The models exhibit a "monotone authority," excelling at procedural information delivery but struggling with the dynamic vocal modulation and emotive gravitas required for persuasive advocacy. Performance dips in Bengali and Gujarati further highlight phonological frontiers for future refinement. This research underscores the readiness of multilingual TTS for procedural legal tasks while identifying the remaining challenges in replicating the persuasive artistry of human legal discourse. The code is available at-https://github.com/naturenurtureelite/Synthesizing-the-Virtual-Advocate/tree/main

</details>


### [87] [Author-in-the-Loop Response Generation and Evaluation: Integrating Author Expertise and Intent in Responses to Peer Review](https://arxiv.org/abs/2602.11173)
*Qian Ruan,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本论文提出了一种将作者置于自动化回应生成流程中的新方法，并构建了相关数据集和评测工具，有效提升了同行评审作者回应写作的质量与效率。


<details>
  <summary>Details</summary>
Motivation: 传统的作者回应自动生成方法忽视了作者在学科知识、写作意图和应对策略等方面的专业性，导致生成内容无法充分代表作者的专业回应需求。实际应用中，作者希望NLP方法能够更好地融合自身专长和意图，协助完成回应写作。

Method: 作者重构了回应生成任务为“作者参与”的自动生成过程。提出了REspGen框架，融合了显式作者输入、多属性控制和基于评测的优化流程。同时，开发了REspEval评测套件，包含20多项指标，覆盖输入利用、可控性、回应质量与话语结构。为支持这一方法，构建了Re$^3$Align数据集，包含评审—回应—修订三元组。

Result: 基于最新大语言模型的实验结果显示：集成作者输入和基于评测的优化能提升回应质量。输入设计在最终回应质量上有显著影响，可控性与质量存在折中。

Conclusion: 该方法有效提升作者回应文本生成的实用性和质量，构建的数据集和工具为同行评审自动回应写作研究提供了重要资源并将其全面开源。

Abstract: Author response (rebuttal) writing is a critical stage of scientific peer review that demands substantial author effort. Recent work frames this task as automatic text generation, underusing author expertise and intent. In practice, authors possess domain expertise, author-only information, revision and response strategies--concrete forms of author expertise and intent--to address reviewer concerns, and seek NLP assistance that integrates these signals to support effective response writing in peer review. We reformulate author response generation as an author-in-the-loop task and introduce REspGen, a generation framework that integrates explicit author input, multi-attribute control, and evaluation-guided refinement, together with REspEval, a comprehensive evaluation suite with 20+ metrics covering input utilization, controllability, response quality, and discourse. To support this formulation, we construct Re$^3$Align, the first large-scale dataset of aligned review--response--revision triplets, where revisions provide signals of author expertise and intent. Experiments with state-of-the-art LLMs show the benefits of author input and evaluation-guided refinement, the impact of input design on response quality, and trade-offs between controllability and quality. We make our dataset, generation and evaluation tools publicly available.

</details>


### [88] [The Script Tax: Measuring Tokenization-Driven Efficiency and Latency Disparities in Multilingual Language Models](https://arxiv.org/abs/2602.11174)
*Aradhya Dixit,Shreem Dixit*

Main category: cs.CL

TL;DR: 多语言预训练模型的分词器对某些书写系统存在系统性不公，导致推理和处理成本明显上升。


<details>
  <summary>Details</summary>
Motivation: 近年来多语言语言模型如mBERT和XLM-R被广泛应用，但其分词器往往被认为对书写系统无偏。本文动机在于量化不同正字法分词策略对模型性能和公平性的实际影响。

Method: 作者通过使用相同语言内容的两种不同正字法变体，比较了分词碎片化程度、推理速度（句子/秒）、每字符信息量（BPC）等指标，并设计了轮流转化实验来检验这些性能差异是否仅由正字法造成。

Result: 高碎片化正字法产生的令牌数是低碎片化的3.4倍，导致推理速度下降16.5倍。mBERT和XLM-R在高碎片化下BPC分别上升19.7%和47.1%。轮流转化实验表明这些差距源于正字法本身，而非噪声。

Conclusion: 分词过程是多语言NLP中的关键不公平来源，建议发展支持不同书写系统的分词和预训练方法。

Abstract: Pretrained multilingual language models are often assumed to be script-agnostic, yet their tokenizers can impose systematic costs on certain writing systems. We quantify this script tax by comparing two orthographic variants with identical linguistic content. Across mBERT and XLM-R, the higher-fragmentation orthography shows a ~3.4x increase in fertility (6.73-6.85 vs. 2.10-2.35 tokens/word), leading to a 16.5x inference slowdown (0.23 vs. 3.8 sentences/second) on identical hardware. Using bits per character (BPC) to avoid the "NLL paradox" from subword fragmentation, we find a substantial increase in information cost: +19.7% for mBERT (8.06->9.65) and +47.1% for XLM-R (12.19->17.94). A round-trip conversion check (CER_rt=0.31) suggests these gaps reflect orthography-conditioned processing rather than mapping noise. Our results highlight tokenization as a key source of inequity in multilingual NLP and motivate script-aware tokenization and pretraining.

</details>


### [89] [Barriers to Discrete Reasoning with Transformers: A Survey Across Depth, Exactness, and Bandwidth](https://arxiv.org/abs/2602.11175)
*Michelle Yuan,Weiyi Sun,Amir H. Rezaeian,Jyotika Singh,Sandip Ghoshal,Yao-Ting Wang,Miguel Ballesteros,Yassine Benajiba*

Main category: cs.CL

TL;DR: 本文综述了Transformer架构在离散推理任务中的理论局限，包括算术、逻辑推理和算法组合问题，并从电路复杂度、逼近理论和通信复杂度三个角度阐释原因，同时探讨克服这些难题的可能方向。


<details>
  <summary>Details</summary>
Motivation: Transformer在许多序列建模任务上取得突破性进展，但其在需要符号推理的离散任务上表现有限，理论原因尚未充分揭示；本综述旨在厘清其根本原因并为未来模型设计提供指导。

Method: 作者系统回顾和整合了电路复杂度、逼近理论和通信复杂度相关的理论研究，分析Transformer架构在结构和计算上的先天障碍，引用经典定义、结果及案例说明问题。

Result: 总结发现，Transformer在实现精确的离散算法时存在诸多难题，包括网络深度受限、难以逼近不连续函数、序列中标记间通信受阻等。

Conclusion: 现有Transformer虽然擅长模式匹配和内插，但难以胜任精确离散计算。了解这些理论局限有助于未来提出更有效的模型设计思路，以突破现有的能力边界。

Abstract: Transformers have become the foundational architecture for a broad spectrum of sequence modeling applications, underpinning state-of-the-art systems in natural language processing, vision, and beyond. However, their theoretical limitations in discrete reasoning tasks, such as arithmetic, logical inference, and algorithmic composition, remain a critical open problem. In this survey, we synthesize recent studies from three theoretical perspectives: circuit complexity, approximation theory, and communication complexity, to clarify the structural and computational barriers that transformers face when performing symbolic computations. By connecting these established theoretical frameworks, we provide an accessible and unified account of why current transformer architectures struggle to implement exact discrete algorithms, even as they excel at pattern matching and interpolation. We review key definitions, seminal results, and illustrative examples, highlighting challenges such as depth constraints, difficulty approximating discontinuities, and bottlenecks in inter-token communication. Finally, we discuss implications for model design and suggest promising directions for overcoming these foundational limitations.

</details>


### [90] [Evaluating Few-Shot Temporal Reasoning of LLMs for Human Activity Prediction in Smart Environments](https://arxiv.org/abs/2602.11176)
*Maral Doctorarastoo,Katherine A. Flanigan,Mario Bergés,Christopher McComb*

Main category: cs.CL

TL;DR: 本论文探讨了大语言模型（LLMs）能否通过理解上下文信息，实现对人类日常活动及持续时间的有效预测，尤其是在数据匮乏环境下。实验表明，LLMs即使在样本极少（few-shot）的情况下，依然能做出准确且连贯的活动与时间预测，对低数据场景下的智能体建模具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 现有的基于数据驱动的智能体建模方法（包括规则和深度学习方法）在样本稀缺时效果不佳，而许多实际应用如智能家居、建筑设计、交通仿真及人机协作，需要能适应低数据环境的系统。作者希望通过大语言模型的预训练知识及上下文推理能力，克服上述挑战。

Method: 论文采用检索增强式提示（retrieval-augmented prompting），整合时间、空间、行为历史和人物设定四种上下文，并用CASAS Aruba智能家居数据集进行实验，覆盖下一个活动预测及持续时间估计、多步序列生成等任务，并分析不同few-shot样本数量对预测效果的影响。

Result: 实验显示，LLMs在零样本下已具备良好的日常活动时序理解能力，一两条范例即可显著提升持续时间和类别预测精度，但再额外增加样本提升有限。序列分析显示模型在各种few-shot条件下均能保持一致的时序对齐。

Conclusion: LLMs依托其预训练知识，能够在低数据环境下充当有效的时序推理器，为智能体建模特别是行为模块的构建提供了新思路，兼顾了数据效率和准确性。

Abstract: Anticipating human activities and their durations is essential in applications such as smart-home automation, simulation-based architectural and urban design, activity-based transportation system simulation, and human-robot collaboration, where adaptive systems must respond to human activities. Existing data-driven agent-based models--from rule-based to deep learning--struggle in low-data environments, limiting their practicality. This paper investigates whether large language models, pre-trained on broad human knowledge, can fill this gap by reasoning about everyday activities from compact contextual cues. We adopt a retrieval-augmented prompting strategy that integrates four sources of context--temporal, spatial, behavioral history, and persona--and evaluate it on the CASAS Aruba smart-home dataset. The evaluation spans two complementary tasks: next-activity prediction with duration estimation, and multi-step daily sequence generation, each tested with various numbers of few-shot examples provided in the prompt. Analyzing few-shot effects reveals how much contextual supervision is sufficient to balance data efficiency and predictive accuracy, particularly in low-data environments. Results show that large language models exhibit strong inherent temporal understanding of human behavior: even in zero-shot settings, they produce coherent daily activity predictions, while adding one or two demonstrations further refines duration calibration and categorical accuracy. Beyond a few examples, performance saturates, indicating diminishing returns. Sequence-level evaluation confirms consistent temporal alignment across few-shot conditions. These findings suggest that pre-trained language models can serve as promising temporal reasoners, capturing both recurring routines and context-dependent behavioral variations, thereby strengthening the behavioral modules of agent-based models.

</details>


### [91] [What Do LLMs Know About Alzheimer's Disease? Fine-Tuning, Probing, and Data Synthesis for AD Detection](https://arxiv.org/abs/2602.11177)
*Lei Jiang,Yue Zhou,Natalie Parde*

Main category: cs.CL

TL;DR: 本文针对阿尔茨海默症(AD)早期检测，提出了一种基于大语言模型(LLM)微调的新方法，并通过分析模型内部表示和合成数据增强提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默症的早期可靠检测具有挑战性，主要因有标签的数据有限。同时，LLM在跨领域任务中的迁移能力强，但针对AD领域的有监督微调尚未深入研究。作者希望探索LLM在AD检测中的潜力及其内部机制。

Method: 作者对LLM进行阿尔茨海默症检测任务的有监督微调，并使用探测技术(probing)分析模型不同层的中间激活，关注特定词和特殊标记在检测表现提升中的作用。基于发现，设计了一套任务相关的特殊标记，并利用序列到序列模型进行数据合成，生成结构一致、诊断信息丰富的合成样本，用于下游训练。

Result: 微调后，特定词和特殊标记的探测值发生显著变化，表明其在模型效果提升中起关键作用。合成数据通过内在评估及在下游任务中实际加入训练均证明对模型检测能力有积极影响。

Conclusion: 针对AD早期检测，任务感知的特殊标记和合成数据结合微调LLM的方法有效提升了检测性能。本研究为LLM在医学少样本领域中的任务自适应和数据增强提供了新思路。

Abstract: Reliable early detection of Alzheimer's disease (AD) is challenging, particularly due to limited availability of labeled data. While large language models (LLMs) have shown strong transfer capabilities across domains, adapting them to the AD domain through supervised fine-tuning remains largely unexplored. In this work, we fine-tune an LLM for AD detection and investigate how task-relevant information is encoded within its internal representations. We employ probing techniques to analyze intermediate activations across transformer layers, and we observe that, after fine-tuning, the probing values of specific words and special markers change substantially, indicating that these elements assume a crucial role in the model's improved detection performance. Guided by this insight, we design a curated set of task-aware special markers and train a sequence-to-sequence model as a data-synthesis tool that leverages these markers to generate structurally consistent and diagnostically informative synthetic samples. We evaluate the synthesized data both intrinsically and by incorporating it into downstream training pipelines.

</details>


### [92] [From Instruction to Output: The Role of Prompting in Modern NLG](https://arxiv.org/abs/2602.11179)
*Munazza Zaib,Elaf Alhazmi*

Main category: cs.CL

TL;DR: 本文综述了Prompt Engineering（提示工程）在大语言模型（LLMs）中的最新进展，尤其是其在自然语言生成（NLG）任务的作用和挑战。作者提出了提示工程的分类方法、选择决策框架，并探讨了未来趋势及挑战。


<details>
  <summary>Details</summary>
Motivation: 虽然Prompt Engineering推动了NLP任务的进步，但该领域对其方法、影响和选择仍缺乏系统性结构和理论。本综述旨在建立一个有组织的理解框架，特别聚焦在自然语言生成任务中弥补这一知识空白。

Method: 系统梳理和归纳了Prompt Engineering在NLG领域中的方法和应用，提出了提示设计的分类体系，并建立了一个基于不同影响因素的提示选择决策框架。同时，讨论了提示设计与模型微调、解码方法的互补性，并分析了现有研究中的新趋势和挑战。

Result: 论文整理并总结了当前主流的提示工程策略及其对NLG任务的实际影响，构建了涵盖设计、优化和评估的综合框架，有助于提升NLG的可控性和泛化能力。

Conclusion: Prompt Engineering已经成为提升LLM能力不可或缺的方法。本文提出了系统的分类与决策框架，为实践者和研究者在NLG领域更高效地设计、优化和评估Prompt提供了理论基础，也指出需要解决的挑战和发展方向。

Abstract: Prompt engineering has emerged as an integral technique for extending the strengths and abilities of Large Language Models (LLMs) to gain significant performance gains in various Natural Language Processing (NLP) tasks. This approach, which requires instructions to be composed in natural language to bring out the knowledge from LLMs in a structured way, has driven breakthroughs in various NLP tasks. Yet there is still no structured framework or coherent understanding of the varied prompt engineering methods and techniques, particularly in the field of Natural Language Generation (NLG).
  This survey aims to help fill that gap by outlining recent developments in prompt engineering, and their effect on different NLG tasks. It reviews recent advances in prompting methods and their impact on NLG tasks, presenting prompt design as an input-level control mechanism that complements fine-tuning and decoding approaches. The paper introduces a taxonomy of prompting paradigms, a decision framework for prompt selection based on varying factors for the practitioners, outlines emerging trends and challenges, and proposes a framework that links design, optimization, and evaluation to support more controllable and generalizable NLG.

</details>


### [93] [Mechanistic Interpretability for Large Language Model Alignment: Progress, Challenges, and Future Directions](https://arxiv.org/abs/2602.11180)
*Usman Naseem*

Main category: cs.CL

TL;DR: 本文综述了大型语言模型（LLMs）中机制可解释性（mechanistic interpretability）的最新进展，探讨其在模型对齐中的应用及未来方向。


<details>
  <summary>Details</summary>
Motivation: LLMs虽然表现出强大的能力，但其内部决策过程仍然不透明。为增强模型可控性与可信度，亟需深入理解其内部机制，推动模型对齐与安全性研究。

Method: 文中系统梳理了近年用于LLM机制可解释性的技术手段，如电路发现、特征可视化、激活引导与因果干预等，并进一步分析这些可解释性方法如何为RLHF、人类反馈强化学习、宪法型AI、可扩展监督等对齐策略提供理论与实践支持。

Result: 文章不仅总结了各类技术在LLM可解释性和对齐中的应用实例，还归纳了当前面临的主要挑战，包括超叠加假设、神经元多语义性、模型规模扩张带来的涌现行为等问题。

Conclusion: 作者认为，未来需关注自动化可解释性、模型间电路泛化和可扩展的、以可解释性驱动的对齐方法，为应对前沿模型提供有效的理论与工程支撑。

Abstract: Large language models (LLMs) have achieved remarkable capabilities across diverse tasks, yet their internal decision-making processes remain largely opaque. Mechanistic interpretability (i.e., the systematic study of how neural networks implement algorithms through their learned representations and computational structures) has emerged as a critical research direction for understanding and aligning these models. This paper surveys recent progress in mechanistic interpretability techniques applied to LLM alignment, examining methods ranging from circuit discovery to feature visualization, activation steering, and causal intervention. We analyze how interpretability insights have informed alignment strategies including reinforcement learning from human feedback (RLHF), constitutional AI, and scalable oversight. Key challenges are identified, including the superposition hypothesis, polysemanticity of neurons, and the difficulty of interpreting emergent behaviors in large-scale models. We propose future research directions focusing on automated interpretability, cross-model generalization of circuits, and the development of interpretability-driven alignment techniques that can scale to frontier models.

</details>


### [94] [Code Mixologist : A Practitioner's Guide to Building Code-Mixed LLMs](https://arxiv.org/abs/2602.11181)
*Himanshu Gupta,Pratik Jayarao,Chaitanya Dwivedi,Neeraj Varshney*

Main category: cs.CL

TL;DR: 本文全面综述了大语言模型在处理中英夹杂（代码混合/切换，CSW）方面的研究进展与挑战，并提出了相关优化建议。


<details>
  <summary>Details</summary>
Motivation: 尽管多语言模型取得了进步，但在混合语言环境中，现有模型表现出语法、事实准确性和安全性方面的系统性退化，因此需要系统总结和优化其CSW能力。

Method: 作者提出了一个统一的分类法，将现有的相关研究从数据、建模与评测等维度梳理。系统回顾了CSW专门预训练、任务后训练、提示构建、上下文学习等多种建模方法，并分析了当前的评测实践、基准测试和其语言覆盖范围及偏向性。

Result: 文章整理了当前研究成果，总结了数据、建模、评测和安全等方面存在的问题，阐释了评测方法的不稳定性及基准的局限性，并揭示了利用CSW绕过模型安全机制的新风险。

Conclusion: 作者提出了一系列可操作建议，帮助提升LLM的CSW处理能力，并指出了未来需要解决的开放挑战，包括更完善的评测方法和更广泛的语言覆盖，同时警惕安全隐患。

Abstract: Code-mixing and code-switching (CSW) remain challenging phenomena for large language models (LLMs). Despite recent advances in multilingual modeling, LLMs often struggle in mixed-language settings, exhibiting systematic degradation in grammaticality, factuality, and safety behavior. This work provides a comprehensive overview of CSW research in modern large language model settings. We introduce a unifying taxonomy that organizes prior work along dimensions of data, modeling, and evaluation, and we distill these findings into a practical playbook of actionable recommendations for building, adapting, and evaluating CSW-capable LLMs. We review modeling approaches ranging from CSW-tailored pre-training and task-specific post-training to prompting strategies and in-context learning. We analyze current evaluation practices, highlighting sources of instability and limited reproducibility, and we catalog existing benchmarks while critically examining their linguistic coverage and English-centric biases. Finally, we discuss emerging safety concerns, including use of code-mixing as a mechanism for bypassing model safeguards, and identify open research challenges.

</details>


### [95] [MetaMem: Evolving Meta-Memory for Knowledge Utilization through Self-Reflective Symbolic Optimization](https://arxiv.org/abs/2602.11182)
*Haidong Xin,Xinze Li,Zhenghao Liu,Yukun Yan,Shuo Wang,Cheng Yang,Yu Gu,Ge Yu,Maosong Sun*

Main category: cs.CL

TL;DR: MetaMem是一种提升大模型记忆系统推理性能的新框架，通过自我反思与元记忆学习，显著提高了长时交互任务的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的大模型记忆系统虽然可扩展上下文，但容易破坏对话会话的逻辑与时序关系，造成记忆碎片化、推理能力下降，因此需要一种新机制让模型更好地利用历史知识。

Method: 提出了MetaMem框架，加入了不断自我进化的元记忆，在多任务下通过自我反思与经验提炼优化记忆的利用策略，元记忆作为显式的知识利用经验单元，帮助模型系统性地整合分散记忆。

Result: 在多个实验任务中，MetaMem在推理与记忆利用方面，相较于强基线性能提升显著，最高超过3.6%的提升。

Conclusion: MetaMem能显著增强大语言模型的长时记忆与推理能力，解决了原有方法记忆碎片化导致性能下降的问题。

Abstract: Existing memory systems enable Large Language Models (LLMs) to support long-horizon human-LLM interactions by persisting historical interactions beyond limited context windows. However, while recent approaches have succeeded in constructing effective memories, they often disrupt the inherent logical and temporal relationships within interaction sessions, resulting in fragmented memory units and degraded reasoning performance. In this paper, we propose MetaMem, a novel framework that augments memory systems with a self-evolving meta-memory, aiming to teach LLMs how to effectively utilize memorized knowledge. During meta-memory optimization, MetaMem iteratively distills transferable knowledge utilization experiences across different tasks by self-reflecting on reasoning processes and performing actions to update the current meta-memory state. The accumulated meta-memory units serve as explicit knowledge utilization experiences, guiding the LLM to systematically identify and integrate critical evidence from scattered memory fragments. Extensive experiments demonstrate the effectiveness of MetaMem, which significantly outperforms strong baselines by over 3.6%. All codes and datasets are available at https://github.com/OpenBMB/MetaMem.

</details>


### [96] [DDL2PropBank Agent: Benchmarking Multi-Agent Frameworks' Developer Experience Through a Novel Relational Schema Mapping Task](https://arxiv.org/abs/2602.11198)
*Shafiuddin Rehan Ahmed,Wei Wei*

Main category: cs.CL

TL;DR: 本文提出了DDL2PropBank基准任务，系统评估了10种多智能体（multi-agent）框架在开发体验（如代码复杂度和AI辅助能力）上的表现，并指出Agno框架综合表现最佳。


<details>
  <summary>Details</summary>
Motivation: 虽然多智能体框架有望简化基于LLM的软件开发，但目前缺乏系统性、可控条件下对开发者体验的评估方法。为此，作者希望建立标准化基准任务和评估体系。

Method: 作者提出DDL2PropBank基准任务，将关系数据库模式自动映射到PropBank语义角色集，要求细致的语言推理。他们以Agent-as-a-Tool模式，在10个市面主流多智能体框架下实现相同代理逻辑，并分别通过代码静态分析和LLM自动生成代码的正确性（AI-assistability）两个维度进行横向比较。

Result: 结果发现，有三个明显的代码复杂度层级（spectrum），其中Pydantic AI和Agno开销最低。在AI辅助能力方面，结构对齐分数能很好地预测单一模式框架的实际表现，但会高估多模式框架的正确率。整体上，Agno在复杂度、结构对齐和AI生成代码正确率（pass@1为83%）方面表现最好。

Conclusion: DDL2PropBank为评测多智能体开发框架提供了新基准，发现Agno尤为适合低实现成本和高AI辅助的开发场景，并指出结构对齐分数适合单一模式框架的实际评测，但在多模式环境下需要慎用。

Abstract: Multi-agent frameworks promise to simplify LLM-driven software development, yet there is no principled way to evaluate their developer experience in a controlled setting. We introduce DDL2PropBank, a novel benchmark task that maps relational database schemas to PropBank rolesets, requiring autonomous retrieval of candidate frames and fine-grained linguistic reasoning over table names, columns, and relations. Using the Agent-as-a-Tool pattern, we implement identical agent logic across 10 frameworks and evaluate along two dimensions: (i) code complexity via static analysis, and (ii) AI-assistability -- the extent to which LLMs can autonomously generate correct, framework-specific code. Our results reveal a threefold complexity spectrum, with Pydantic AI and Agno requiring the least implementation overhead. For AI-assistability, structural alignment scores reliably proxy runtime success for frameworks with single canonical patterns, but overestimate correctness for multi-pattern frameworks. Agno emerges as the strongest overall performer, combining lowest complexity with highest structural alignment and 83% pass@1.

</details>


### [97] [When and What to Ask: AskBench and Rubric-Guided RLVR for LLM Clarification](https://arxiv.org/abs/2602.11199)
*Jiale Zhao,Ke Fang,Lu Cheng*

Main category: cs.CL

TL;DR: 本文提出了AskBench基准，用于评估与提升大语言模型在关键细节不充分或误导性问题下主动澄清的能力，并引入了基于评分标准的强化学习方法以提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型面对细节不足或带有误导性的问题时，容易产生错误回答或强化错误观念，缺乏主动澄清问题的能力，因此需要更好地评估和提升LLM的提问澄清能力。

Method: 作者设计了AskBench基准，将传统问答对转化为带有多轮交互和明确检查点的流程，并设计两个子任务：要求澄清意图不明确问题（AskMind）和识别、纠正错误前提的问题（AskOverconfidence）。此外提出了基于评分标准的强化学习方法（RLVR），通过结构化评分标准和验证奖励促进模型针对性澄清。

Result: 实验结果显示，采用AskBench和RLVR后，模型在正确率、评分标准符合度、交互效率等各方面均有显著提升，并能很好地泛化到未见领域。

Conclusion: 通过引入新的基准和训练方法，可以有效提升大语言模型的澄清提问能力，减少幻觉和误导性回答，增强实际应用中的鲁棒性和可靠性。

Abstract: Large language models (LLMs) often respond even when prompts omit critical details or include misleading information, leading to hallucinations or reinforced misconceptions. We study how to evaluate and improve LLMs' ability to decide when and what to ask for clarification without sacrificing task performance. We introduce AskBench, an interactive benchmark that converts standard QA pairs into multi-turn interactions with explicit checkpoints. A unified judge loop evaluates final answers and simulates user responses as needed. AskBench covers two settings: AskMind, with intent-deficient queries requiring clarification, and AskOverconfidence, with queries containing false premises that must be identified and corrected. We further propose rubric-guided reinforcement learning with verifier-based rewards (RLVR), which uses structured rubrics to encourage targeted clarification. Experiments show consistent improvements in accuracy, rubric adherence, and interaction efficiency, with strong generalization to unseen domains.

</details>


### [98] [Mechanistic Evidence for Faithfulness Decay in Chain-of-Thought Reasoning](https://arxiv.org/abs/2602.11201)
*Donald Ye,Max Loffgren,Om Kotadia,Linus Wong*

Main category: cs.CL

TL;DR: 本文提出了一个新的指标——归一化对数差衰减（NLDD），用于评估大语言模型输出的中间推理步骤是否真的对模型最终决策有作用，而不仅仅是事后解释。通过打乱某一步骤并观测模型置信度下降情况，揭示哪些步骤真实影响了答案。测试多种模型后，发现推理链后段步骤通常影响甚微，并发现模型可以有正确的内部表示却答错题。


<details>
  <summary>Details</summary>
Motivation: 尽管链式思考（CoT）被广泛用于解释大语言模型的推理过程，但尚不清楚这些逐步解释是否忠实地反映了模型的真实决策过程，还是只是事后的合理化。

Method: 提出NLDD指标，方法是对CoT中的每个推理步骤进行人为扰动（corrupt），测量这种扰动对模型最终答案置信度的影响。通过归一化和标准化，这一指标支持不同模型之间的横向比较，并在语法、逻辑、算数等任务上进行了实验验证。

Result: 在多种类型任务和不同架构的模型上测试后，发现存在一个‘推理视野’（k*）：大多数链长度的70%-85%，超出这一范围的推理步骤对最终答复影响甚微，甚至可能有负面影响。另外还发现，模型即使内部表征正确，任务表现仍可失败。

Conclusion: CoT解释的准确性并不等同于模型真实推理过程的准确性。仅凭结果正确并不能证明模型真的沿链推理，NLDD能量化推理链中哪些步骤确实“重要”，为评估大模型的推理过程提供了新工具。

Abstract: Chain-of-Thought (CoT) explanations are widely used to interpret how language models solve complex problems, yet it remains unclear whether these step-by-step explanations reflect how the model actually reaches its answer, or merely post-hoc justifications. We propose Normalized Logit Difference Decay (NLDD), a metric that measures whether individual reasoning steps are faithful to the model's decision-making process. Our approach corrupts individual reasoning steps from the explanation and measures how much the model's confidence in its answer drops, to determine if a step is truly important. By standardizing these measurements, NLDD enables rigorous cross-model comparison across different architectures. Testing three model families across syntactic, logical, and arithmetic tasks, we discover a consistent Reasoning Horizon (k*) at 70--85% of chain length, beyond which reasoning tokens have little or negative effect on the final answer. We also find that models can encode correct internal representations while completely failing the task. These results show that accuracy alone does not reveal whether a model actually reasons through its chain. NLDD offers a way to measure when CoT matters.

</details>


### [99] [The Automatic Verification of Image-Text Claims (AVerImaTeC) Shared Task](https://arxiv.org/abs/2602.11221)
*Rui Cao,Zhenyun Deng,Yulong Chen,Michael Schlichtkrull,Andreas Vlachos*

Main category: cs.CL

TL;DR: 本文介绍了一项针对图文事实核查的竞赛任务（AVerImaTeC），参赛者需要检索证据并验证真实世界中的图文匹配主张。所有参赛系统在测试阶段均超过了基线系统，最佳系统得分为0.5455。


<details>
  <summary>Details</summary>
Motivation: 随着多模态数据（如图文）在互联网的普及，如何自动验证图文主张的真实性成为事实核查领域的重要挑战。本任务旨在推动相关系统的发展与完善。

Method: 参赛系统可以利用外部知识资源（如网络搜索引擎）或主办方提供的知识库。系统通过AVerImaTeC分数进行评估，该分数基于判决的准确性，且需相关证据分超过阈值才被认定为正确。

Result: 共有14个系统提交到开发阶段，6个系统进入测试阶段。所有参与测试阶段的系统性能均超出主办方提供的基线系统。获胜团队HUMANE获得了0.5455的AVerImaTeC分数。

Conclusion: 任务推动了多模态事实核查系统的研究与性能提升，通过比赛产生了多种有效方法，并总结了实践中遇到的关键经验和教训。

Abstract: The Automatic Verification of Image-Text Claims (AVerImaTeC) shared task aims to advance system development for retrieving evidence and verifying real-world image-text claims. Participants were allowed to either employ external knowledge sources, such as web search engines, or leverage the curated knowledge store provided by the organizers. System performance was evaluated using the AVerImaTeC score, defined as a conditional verdict accuracy in which a verdict is considered correct only when the associated evidence score exceeds a predefined threshold. The shared task attracted 14 submissions during the development phase and 6 submissions during the testing phase. All participating systems in the testing phase outperformed the baseline provided. The winning team, HUMANE, achieved an AVerImaTeC score of 0.5455. This paper provides a detailed description of the shared task, presents the complete evaluation results, and discusses key insights and lessons learned.

</details>


### [100] [SurveyLens: A Research Discipline-Aware Benchmark for Automatic Survey Generation](https://arxiv.org/abs/2602.11238)
*Beichen Guo,Zhiyuan Wen,Jia Gu,Senzhang Wang,Haochen Shi,Ruosong Yang,Shuaiqi Liu*

Main category: cs.CL

TL;DR: 该论文提出SurveyLens，这是一个首个面向不同学科自动综述生成（ASG）方法的评价基准，填补了现有ASG评估高度偏向计算机领域且缺乏学科适应性的不足。


<details>
  <summary>Details</summary>
Motivation: 随着科学文献量的爆炸式增长，自动综述生成（ASG）技术不断进化，但现有方法评估体系过于通用且偏重计算机学科，导致其他学科领域难以利用ASG生成符合本学科标准的高质量综述。

Method: 构建SurveyLens-1k数据集，包含10个学科、1000篇高质量人工撰写综述；提出“学科感知评分rubric+典型内容对齐”双重评价框架，结合LLM对学科规范的理解与内容覆盖度、综合质量评测；对11种先进ASG方法在SurveyLens上做定量分析。

Result: 评估结果揭示了不同ASG方法、包括基础LLM、专用ASG系统与深度研究代理等在各学科的表现差异和各自优劣。

Conclusion: SurveyLens为多学科ASG评测与方法选择建立了科学基准，为非计算机领域用户正确选择ASG工具提供了重要参考与指导。

Abstract: The exponential growth of scientific literature has driven the evolution of Automatic Survey Generation (ASG) from simple pipelines to multi-agent frameworks and commercial Deep Research agents. However, current ASG evaluation methods rely on generic metrics and are heavily biased toward Computer Science (CS), failing to assess whether ASG methods adhere to the distinct standards of various academic disciplines. Consequently, researchers, especially those outside CS, lack clear guidance on using ASG systems to yield high-quality surveys compliant with specific discipline standards. To bridge this gap, we introduce SurveyLens, the first discipline-aware benchmark evaluating ASG methods across diverse research disciplines. We construct SurveyLens-1k, a curated dataset of 1,000 high-quality human-written surveys spanning 10 disciplines. Subsequently, we propose a dual-lens evaluation framework: (1) Discipline-Aware Rubric Evaluation, which utilizes LLMs with human preference-aligned weights to assess adherence to domain-specific writing standards; and (2) Canonical Alignment Evaluation to rigorously measure content coverage and synthesis quality against human-written survey papers. We conduct extensive experiments by evaluating 11 state-of-the-art ASG methods on SurveyLens, including Vanilla LLMs, ASG systems, and Deep Research agents. Our analysis reveals the distinct strengths and weaknesses of each paradigm across fields, providing essential guidance for selecting tools tailored to specific disciplinary requirements.

</details>


### [101] [Are Aligned Large Language Models Still Misaligned?](https://arxiv.org/abs/2602.11305)
*Usman Naseem,Gautam Siddharth Kashyap,Rafiq Ali,Ebad Shabbir,Sushant Kumar Ray,Abdullah Mohammad,Agrima Seth*

Main category: cs.CL

TL;DR: 提出了一种新的评测基准，能够同时从安全、价值和文化三个维度分析大语言模型（LLM）的失配现象，以弥补现有单一维度评测的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的失配（misalignment）评测基准聚焦于单一维度（例如安全、价值或文化），不能同时多维度系统性评估LLM在真实环境中的表现，而实际应用常常需要同时满足多重标准。

Method: 作者构建了Mis-Align Bench基准，核心是SAVACU数据集：从LLM-PROMPT-DATASET出发，基于taxonomy将题目重新分类到安全（14类）、价值（56类）、文化（42类）共112个领域；利用Mistral-7B和Llama-3.1-8B等模型及SimHash去重对数据集进行丰富扩展。同时，为每个prompt配对对齐和失配的回答，通过两阶段拒绝采样保证高质量输出。接着，使用该基准系统性评测了不同类型的LLM。

Result: 三大维度独立测试时，模型覆盖率高（最高达97.6%），但多维度联合测试情况下，假失败率高达50%以上，对齐分数下降到63%-66%。

Conclusion: 多维度联合评测揭示了现有LLM尽管在单一维度对齐表现良好，但在实际需要综合考量安全、价值和文化的情景中常常表现不佳。Mis-Align Bench为系统性改进LLM失配问题提供了新工具和研究方向。

Abstract: Misalignment in Large Language Models (LLMs) arises when model behavior diverges from human expectations and fails to simultaneously satisfy safety, value, and cultural dimensions, which must co-occur in real-world settings to solve a real-world query. Existing misalignment benchmarks-such as INSECURE CODE (safety-centric), VALUEACTIONLENS (value-centric), and CULTURALHERITAGE (culture centric)-rely on evaluating misalignment along individual dimensions, preventing simultaneous evaluation. To address this gap, we introduce Mis-Align Bench, a unified benchmark for analyzing misalignment across safety, value, and cultural dimensions. First we constructs SAVACU, an English misaligned-aligned dataset of 382,424 samples spanning 112 domains (or labels), by reclassifying prompts from the LLM-PROMPT-DATASET via taxonomy into 14 safety domains, 56 value domains, and 42 cultural domains using Mistral-7B-Instruct-v0.3, and expanding low-resource domains via Llama-3.1-8B-Instruct with SimHash-based fingerprint to avoid deduplication. Furthermore, we pairs prompts with misaligned and aligned responses via two-stage rejection sampling to enforce quality. Second we benchmarks general-purpose, fine-tuned, and open-weight LLMs, enabling systematic evaluation of misalignment under three dimensions. Empirically, single-dimension models achieve high Coverage (upto 97.6%) but incur False Failure Rate >50% and lower Alignment Score (63%-66%) under joint conditions.

</details>


### [102] [Evaluating Alignment of Behavioral Dispositions in LLMs](https://arxiv.org/abs/2602.11328)
*Amir Taubenfeld,Zorik Gekhman,Lior Nezry,Omri Feldman,Natalie Harris,Shashir Reddy,Romina Stella,Ariel Goldstein,Marian Croak,Yossi Matias,Amir Feder*

Main category: cs.CL

TL;DR: 本文提出一种利用情境判断测试（SJT）评估大语言模型（LLMs）在社会情境下行为倾向的新框架，发现LLMs与人类的行为倾向存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs日益融入社会生活，了解其行为倾向以及与人类一致性的程度变得非常重要，尤其是在涉及社交互动和推荐时。

Method: 本研究基于经典心理测量问卷，将人类自述题目转换为情境判断测试（SJT），并在用户-助手真实场景中评价LLMs的行为推荐。共生成了2,500道SJT，并通过多人标注收集人类偏好结果，对25个LLMs进行系统测试。

Result: 研究发现：（1）在低人类共识场景下，LLMs容易对单一答案表现过度自信；（2）在人类高度共识时，小型模型以及部分前沿模型仍有15%-20%的偏差不符人类主流选择；（3）不同模型存在一致的性格倾向误差（如：在应当冷静的情境中，倾向鼓励情感表达）。

Conclusion: 通过将心理问卷直接映射到行为测试，表明LLMs的理论价值观与实际行为表现之间存在明显差距，这为后续改进模型一致性和真实性提供了依据。

Abstract: As LLMs integrate into our daily lives, understanding their behavior becomes essential. In this work, we focus on behavioral dispositions$-$the underlying tendencies that shape responses in social contexts$-$and introduce a framework to study how closely the dispositions expressed by LLMs align with those of humans. Our approach is grounded in established psychological questionnaires but adapts them for LLMs by transforming human self-report statements into Situational Judgment Tests (SJTs). These SJTs assess behavior by eliciting natural recommendations in realistic user-assistant scenarios. We generate 2,500 SJTs, each validated by three human annotators, and collect preferred actions from 10 annotators per SJT, from a large pool of 550 participants. In a comprehensive study involving 25 LLMs, we find that models often do not reflect the distribution of human preferences: (1) in scenarios with low human consensus, LLMs consistently exhibit overconfidence in a single response; (2) when human consensus is high, smaller models deviate significantly, and even some frontier models do not reflect the consensus in 15-20% of cases; (3) traits can exhibit cross-LLM patterns, e.g., LLMs may encourage emotion expression in contexts where human consensus favors composure. Lastly, mapping psychometric statements directly to behavioral scenarios presents a unique opportunity to evaluate the predictive validity of self-reports, revealing considerable gaps between LLMs' stated values and their revealed behavior.

</details>


### [103] [When Models Examine Themselves: Vocabulary-Activation Correspondence in Self-Referential Processing](https://arxiv.org/abs/2602.11358)
*Zachary Pedram Dadfar*

Main category: cs.CL

TL;DR: 论文发现，大型语言模型在自我审视任务中，所输出的自我参照性语言与其内部激活动态有关，并非单纯编造。作者提出Pull Methodology，通过格式工程诱导模型自省，并研究了Llama 3.1中的自我参照处理激活方向。这一方向可操控输出，且与常规描述任务的语言不同。Qwen 2.5-32B模型也呈现类似现象，证明自报告可在合适条件下反映模型内部计算状态。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型生成自我反思性语言，但学界不清楚这些语言究竟是不是模型内部计算的真实反映，还是只是精致的胡编乱造。因此，作者希望探究模型自我报告语言和其内部计算之间的关系。

Method: 作者设计了Pull Methodology，通过格式设计促使模型进行更深入自我审视，并结合激活空间分析，区分模型在自我参照与描述性处理中激活空间的差异。还研究了激活方向与模型输出语言的关联，对比了不同模型（如Llama 3.1和Qwen 2.5-32B），以及不同任务下的差异。

Result: 发现Llama 3.1模型中，自我参照词汇与特定激活方向高度关联，这种激活方向可以因‘steering’操纵改变输出。自我参照词汇的激活与非自我参照上下文中无相关性。Qwen 2.5-32B模型在完全不同的词汇和激活指标下也表现出类似现象，但描述性任务中则完全不体现。

Conclusion: 论文结论是，在适当的设计和分析下，transformer类大型语言模型的自我报告语言能够真实反映其内部计算状态，新方法和发现有助于未来模型可解释性与自我监控的相关研究。

Abstract: Large language models produce rich introspective language when prompted for self-examination, but whether this language reflects internal computation or sophisticated confabulation has remained unclear. We show that self-referential vocabulary tracks concurrent activation dynamics, and that this correspondence is specific to self-referential processing. We introduce the Pull Methodology, a protocol that elicits extended self-examination through format engineering, and use it to identify a direction in activation space that distinguishes self-referential from descriptive processing in Llama 3.1. The direction is orthogonal to the known refusal direction, localised at 6.25% of model depth, and causally influences introspective output when used for steering. When models produce "loop" vocabulary, their activations exhibit higher autocorrelation (r = 0.44, p = 0.002); when they produce "shimmer" vocabulary under steering, activation variability increases (r = 0.36, p = 0.002). Critically, the same vocabulary in non-self-referential contexts shows no activation correspondence despite nine-fold higher frequency. Qwen 2.5-32B, with no shared training, independently develops different introspective vocabulary tracking different activation metrics, all absent in descriptive controls. The findings indicate that self-report in transformer models can, under appropriate conditions, reliably track internal computational states.

</details>


### [104] [Finding the Cracks: Improving LLMs Reasoning with Paraphrastic Probing and Consistency Verification](https://arxiv.org/abs/2602.11361)
*Weili Shi,Dongliang Guo,Lehan Yang,Tianlong Wang,Hanzhang Yuan,Sheng Li*

Main category: cs.CL

TL;DR: 提出了一种名为PPCV的新方法，通过同义改写和一致性检验，识别及替换大型语言模型推理过程中的关键token，从而显著提升模型在复杂任务上的推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂推理任务中容易因生成幻觉和累积错误导致表现下降，而此前尝试修正推理路径的方法仍存在关键token识别与利用难的问题。

Method: PPCV方法分两步：首先将原问题与其同义改写后的版本拼接，分析推理路径中实际与预测token的差异，锁定对后续影响最大的关键token；接着将关键token替换为候选词，并分别对原题和同义题生成新的推理路径，通过并行推理结果的一致性来决定最终答案。

Result: 在主流大语言模型及多个基准数据集上进行实验，结果显示PPCV方法在推理性能上优于现有基线系统。

Conclusion: PPCV显著提升了大语言模型复杂推理任务的表现，有效拓宽了关键token的识别与利用思路。

Abstract: Large language models have demonstrated impressive performance across a variety of reasoning tasks. However, their problem-solving ability often declines on more complex tasks due to hallucinations and the accumulation of errors within these intermediate steps. Recent work has introduced the notion of critical tokens--tokens in the reasoning process that exert significant influence on subsequent steps. Prior studies suggest that replacing critical tokens can refine reasoning trajectories. Nonetheless, reliably identifying and exploiting critical tokens remains challenging. To address this, we propose the Paraphrastic Probing and Consistency Verification~(PPCV) framework. PPCV operates in two stages. In the first stage, we roll out an initial reasoning path from the original question and then concatenate paraphrased versions of the question with this reasoning path. And we identify critical tokens based on mismatches between the predicted top-1 token and the expected token in the reasoning path. A criterion is employed to confirm the final critical token. In the second stage, we substitute critical tokens with candidate alternatives and roll out new reasoning paths for both the original and paraphrased questions. The final answer is determined by checking the consistency of outputs across these parallel reasoning processes. We evaluate PPCV on mainstream LLMs across multiple benchmarks. Extensive experiments demonstrate PPCV substantially enhances the reasoning performance of LLMs compared to baselines.

</details>


### [105] [The Energy of Falsehood: Detecting Hallucinations via Diffusion Model Likelihoods](https://arxiv.org/abs/2602.11364)
*Arpit Singh Gautam,Kailash Talreja,Saurabh Jha*

Main category: cs.CL

TL;DR: 本文提出了一种名为DiffuTruth的无监督框架，用于检测大语言模型的幻觉事实，通过生成型扩散模型和新的语义能量度量，显著提升了事实核查的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型经常自信地产生错误或虚假信息（即幻觉），现有的不确定性指标难以有效检测这些“自信的错误”。因此，迫切需要新的方法来提升模型的事实核查能力。

Method: DiffuTruth框架利用非平衡热力学理论，认为真实事实在生成流形上是稳定的吸引子，而幻觉是非稳定的。通过生成压力测试（Generative Stress Test），将文本增加噪声并用离散文本扩散模型恢复原文。引入了语义能量（Semantic Energy）指标，用NLI判别器测量原始内容与重建内容之间的语义差异，并与判别置信度融合，形成混合校准方法。

Result: 在FEVER数据集上的大量实验表明，DiffuTruth在无监督AUROC上达到0.725，超越基线约1.5%，可有效修正模型过度自信的预测。在多跳HOVER数据集的零样本泛化测试中，表现比基线高出4%，显示出方法的鲁棒性。

Conclusion: DiffuTruth结合扩散模型与语义能量指标，为大语言模型事实核查提供了更有效和稳健的无监督解决方案，尤其在应对数据分布变化时能更好地检测和区分幻觉信息。

Abstract: Large Language Models (LLMs) frequently hallucinate plausible but incorrect assertions, a vulnerability often missed by uncertainty metrics when models are confidently wrong. We propose DiffuTruth, an unsupervised framework that reconceptualizes fact verification via non equilibrium thermodynamics, positing that factual truths act as stable attractors on a generative manifold while hallucinations are unstable. We introduce the Generative Stress Test, claims are corrupted with noise and reconstructed using a discrete text diffusion model. We define Semantic Energy, a metric measuring the semantic divergence between the original claim and its reconstruction using an NLI critic. Unlike vector space errors, Semantic Energy isolates deep factual contradictions. We further propose a Hybrid Calibration fusing this stability signal with discriminative confidence. Extensive experiments on FEVER demonstrate DiffuTruth achieves a state of the art unsupervised AUROC of 0.725, outperforming baselines by 1.5 percent through the correction of overconfident predictions. Furthermore, we show superior zero shot generalization on the multi hop HOVER dataset, outperforming baselines by over 4 percent, confirming the robustness of thermodynamic truth properties to distribution shifts.

</details>


### [106] [Advancing AI Trustworthiness Through Patient Simulation: Risk Assessment of Conversational Agents for Antidepressant Selection](https://arxiv.org/abs/2602.11391)
*Md Tanvir Rouf Shawon,Mohammad Sabik Irbaz,Hadeel R. A. Elyazori,Keerti Reddy Resapu,Yili Lin,Vladimir Franzuela Cardenas,Farrokh Alemi,Kevin Lybarger*

Main category: cs.CL

TL;DR: 本论文提出了一种用于自动化评估医疗对话智能体的患者模拟器，该模拟器可以生成跨医学、语言和行为多维度变异的高真实性患者交互，以系统性发现AI的错误和风险模式。通过与AI决策辅助工具（抗抑郁药选择）的测试，模拟器有效揭示了不同健康素养水平下AI性能的差异和不足。


<details>
  <summary>Details</summary>
Motivation: 随着医疗对话智能体（如AI医生助手）的广泛应用，如何大规模、系统化地评估和发现其在不同患者群体下的弱点（如幻觉、错误）成为亟需解决的问题。单一静态数据集或人工模拟很难涵盖患者在医疗背景、表达能力与行为方式上的多样性，限制了AI风险识别的深度和广度。

Method: 作者基于NIST AI风险管理框架，开发了一种三维度患者模拟器：1）医学特征源自大规模电子病历数据库；2）语言特征涵盖健康素养及疾病相关表达模式；3）行为特征模拟真实互动策略（如合作、分心、对抗）。通过与AI决策辅助工具系统生成500轮对话，并用人工及LLM评审，量化AI的表现与风险。

Result: 模拟器生成了包含不同语言和行为特征的500组对话。人工标注员对100组涉及1787个医疗概念的对话进行了高一致性评估（F1=0.94, κ=0.73），LLM自动评审结果与人工相近（F1=0.94, κ=0.78）。在健康素养不同的患者模拟下，AI决策辅助工具的准确性逐级提升，暴露出低健康素养群体面临更高风险。

Conclusion: 提出的患者模拟器能够系统生成多样化的真实患者对话，高效发现和量化医疗AI决策的风险与不足，尤其能揭示在低健康素养群体下的性能衰减。工具对后续优化医疗AI设计、促进公平性和安全性具有重要意义。

Abstract: Objective: This paper introduces a patient simulator designed to enable scalable, automated evaluation of healthcare conversational agents. The simulator generates realistic, controllable patient interactions that systematically vary across medical, linguistic, and behavioral dimensions, allowing annotators and an independent AI judge to assess agent performance, identify hallucinations and inaccuracies, and characterize risk patterns across diverse patient populations. Methods: The simulator is grounded in the NIST AI Risk Management Framework and integrates three profile components reflecting different dimensions of patient variation: (1) medical profiles constructed from electronic health records in the All of Us Research Program; (2) linguistic profiles modeling variation in health literacy and condition-specific communication patterns; and (3) behavioral profiles representing empirically observed interaction patterns, including cooperation, distraction, and adversarial engagement. We evaluated the simulator's effectiveness in identifying errors in an AI decision aid for antidepressant selection. Results: We generated 500 conversations between the patient simulator and the AI decision aid across systematic combinations of five linguistic and three behavioral profiles. Human annotators assessed 1,787 medical concepts across 100 conversations, achieving high agreement (F1=0.94, \k{appa}=0.73), and the LLM judge achieved comparable agreement with human annotators (F1=0.94, \k{appa}=0.78; paired bootstrap p=0.21). The simulator revealed a monotonic degradation in AI decision aid performance across the health literacy spectrum: rank-one concept retrieval accuracy increased from 47.9% for limited health literacy to 69.1% for functional and 81.6% for proficient.

</details>


### [107] [Gradients Must Earn Their Influence: Unifying SFT with Generalized Entropic Objectives](https://arxiv.org/abs/2602.11424)
*Zecheng Wang,Deyuan Liu,Chunshan Li,Yupeng Zhang,Zhengyun Zhao,Dianhui Chu,Bingning Wang,Dianbo Sui*

Main category: cs.CL

TL;DR: 论文提出了一种新的Supervised Fine-Tuning（SFT）目标函数——动态熵微调（DEFT），通过对模型不确定性自适应地调整信任门控，以更好地平衡探索与利用，提升模型整体性能。


<details>
  <summary>Details</summary>
Motivation: 传统的SFT基于NLL（负对数似然）目标函数，对每个token一视同仁地加权，这种设定在遇到噪声监督或模型先验不鲁棒时，容易导致过度学习罕见或有噪声的目标，同时，对已非常确定的内容也无法进一步提升模型表现，造成“可塑性—稳定性”两难。

Method: 作者将SFT目标统一进一个广义的deformed-log族，提出“信任门控×误差梯度”结构，用门控控制模型信任自身预测的程度。通过Cayley变换，将模型的不确定性映射为连续的关注路径，实现模型在新颖概念与熟悉知识之间的自适应过渡，并利用Rényi-2熵作为代理量控制门控，提出动态熵微调（DEFT）方法。

Result: 大量实验和分析表明，DEFT能够在探索和利用之间取得更好的均衡，从而获得更优的整体性能，并优于传统和其它现有的SFT方法。

Conclusion: DEFT作为一种无需额外参数的新型目标函数，有效缓解了传统SFT的两难困境，通过对模型预测分布的动态聚焦，提升了训练的效率和泛化能力。

Abstract: Standard negative log-likelihood (NLL) for Supervised Fine-Tuning (SFT) applies uniform token-level weighting. This rigidity creates a two-fold failure mode: (i) overemphasizing low-probability targets can amplify gradients on noisy supervision and disrupt robust priors, and (ii) uniform weighting provides weak sharpening when the model is already confident. Existing methods fail to resolve the resulting plasticity--stability dilemma, often suppressing necessary learning signals alongside harmful ones. To address this issue, we unify token-level SFT objectives within a generalized deformed-log family and expose a universal gate $\times$ error gradient structure, where the gate controls how much the model trusts its current prediction. By employing the Cayley transform, we map the model's continuously evolving uncertainty onto a continuous focus trajectory, which enables seamless interpolation between scenarios involving uncertain novel concepts and those involving well-established knowledge. We then introduce Dynamic Entropy Fine-Tuning (DEFT), a parameter-free objective that modulates the trust gate using distribution concentration (Rényi-2 entropy) as a practical proxy for the model's predictive state. Extensive experiments and analyses demonstrate that DEFT achieves a better balance between exploration and exploitation, leading to improved overall performance.

</details>


### [108] [Towards Reliable Machine Translation: Scaling LLMs for Critical Error Detection and Safety](https://arxiv.org/abs/2602.11444)
*Muskaan Chopra,Lorenz Sparrenberg,Rafet Sifa*

Main category: cs.CL

TL;DR: 本文研究了指令微调大语言模型（LLM）在检测机器翻译中关键性意义错误（如事实扭曲、意图颠倒、偏见翻译）方面的能力，发现LLM在零样本、少样本和微调等方法下表现优于传统编码器基线模型，并强调提升此能力对多语言系统安全、可信与社会责任的重要性。


<details>
  <summary>Details</summary>
Motivation: 在多语言信息获取及知识传播过程中，MT系统存在因关键信息错误造成的不可靠、不公平和不安全问题，尤其在高风险或少数语种场景更为突出。因此，提升对MT关键性错误的检测能力，能减少虚假信息、误解及语言伤害，是追求社会公正及负责任AI的必要保障。

Method: 本文系统评估了不同参数规模的指令微调LLM，并通过零样本、少样本、微调三种模式进行适配，对比传统编码器基线XLM-R和ModernBERT，利用公开数据集对关键性意义错误检测任务进行实验和分析。

Result: 实验结果显示，无论在模型参数规模还是适配策略上，指令微调LLM在检测关键性MT错误上都实现了持续一致的性能提升，显著优于基线模型。

Conclusion: 提升MT关键性错误检测能力不仅是技术挑战，更是实现安全、可信及社会公正多语种AI体系的关键步骤。这项工作为相关研究提供了明确方向，实验代码将在GitHub开源，助力社区发展。

Abstract: Machine Translation (MT) plays a pivotal role in cross-lingual information access, public policy communication, and equitable knowledge dissemination. However, critical meaning errors, such as factual distortions, intent reversals, or biased translations, can undermine the reliability, fairness, and safety of multilingual systems. In this work, we explore the capacity of instruction-tuned Large Language Models (LLMs) to detect such critical errors, evaluating models across a range of parameters using the publicly accessible data sets. Our findings show that model scaling and adaptation strategies (zero-shot, few-shot, fine-tuning) yield consistent improvements, outperforming encoder-only baselines like XLM-R and ModernBERT. We argue that improving critical error detection in MT contributes to safer, more trustworthy, and socially accountable information systems by reducing the risk of disinformation, miscommunication, and linguistic harm, especially in high-stakes or underrepresented contexts. This work positions error detection not merely as a technical challenge, but as a necessary safeguard in the pursuit of just and responsible multilingual AI. The code will be made available at GitHub.

</details>


### [109] [LoopFormer: Elastic-Depth Looped Transformers for Latent Reasoning via Shortcut Modulation](https://arxiv.org/abs/2602.11451)
*Ahmadreza Jeddi,Marco Ciccone,Babak Taati*

Main category: cs.CL

TL;DR: 本文提出了LoopFormer——一种可适应计算预算的循环Transformer模型，可根据算力需求灵活调整推理深度，并在各类语言建模和推理任务中展现了优异表现。


<details>
  <summary>Details</summary>
Motivation: 现有循环Transformer固定位数次迭代，缺乏对不同计算预算下自适应推理深度的能力。作者希望解决循环Transformer不能根据算力动态调整推理步骤的问题。

Method: 提出LoopFormer，并采用“shortcut-consistency”训练策略，将不同循环长度的推理轨迹对齐，让短循环获得有信息的表征，长循环则持续优化表征。同时，每步循环结合当前时间和步长，保证不同轨迹下表征稳定进化。

Result: LoopFormer在多项语言建模和推理基准任务中，即便在算力受限时也有强劲表现，且算力增加时性能可平滑提升。

Conclusion: 循环Transformer天生适合自适应语言建模，LoopFormer实现了可控、预算感知的大模型推理，为未来自适应大语言模型提供了新方向。

Abstract: Looped Transformers have emerged as an efficient and powerful class of models for reasoning in the language domain. Recent studies show that these models achieve strong performance on algorithmic and reasoning tasks, suggesting that looped architectures possess an inductive bias toward latent reasoning. However, prior approaches fix the number of loop iterations during training and inference, leaving open the question of whether these models can flexibly adapt their computational depth under variable compute budgets. We introduce LoopFormer, a looped Transformer trained on variable-length trajectories to enable budget-conditioned reasoning. Our core contribution is a shortcut-consistency training scheme that aligns trajectories of different lengths, ensuring that shorter loops yield informative representations while longer loops continue to refine them. LoopFormer conditions each loop on the current time and step size, enabling representations to evolve consistently across trajectories of varying length rather than drifting or stagnating. Empirically, LoopFormer demonstrates robust performance on language modeling and reasoning benchmarks even under aggressive compute constraints, while scaling gracefully with additional budget. These results show that looped Transformers are inherently suited for adaptive language modeling, opening a path toward controllable and budget-aware large language models.

</details>


### [110] [ADRD-Bench: A Preliminary LLM Benchmark for Alzheimer's Disease and Related Dementias](https://arxiv.org/abs/2602.11460)
*Guangxin Zhao,Jiahao Zheng,Malaz Boustani,Jarek Nabrzyski,Meng Jiang,Yiyu Shi,Zhi Zheng*

Main category: cs.CL

TL;DR: 本文提出了首个专为阿尔茨海默病及相关痴呆（ADRD）而设计的大型语言模型评测数据集ADRD-Bench，并对33个主流LLMs进行了系统评估。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM评测基准很少涵盖阿尔茨海默病及相关痴呆领域，影响了此类模型在医疗健康领域的可信应用。针对这一空白，作者开发了与ADRD相关的专用评估数据集。

Method: 构建了ADRD-Bench评测集，包括两个部分：1）整合7个医学基准共1352题的“ADRD Unified QA”，用于统一临床知识评估；2）基于Aging Brain Care（ABC）项目，新增149题“ADRD Caregiving QA”，关注实际护理场景。评估了33个开源及闭源LLM模型的准确率。

Result: 开源通用模型的准确率为0.63-0.93（均值0.78），开源医学模型为0.48-0.93（均值0.82），闭源通用模型为0.83-0.91（均值0.89）。顶级模型准确率＞0.9，但案例分析发现推理质量和稳定性不一致。

Conclusion: 尽管部分LLM模型在新评测集上表现优异，但其推理不稳定性凸显了对ADRD专属知识和护理经验强化的需求。数据集已开放，可促进该领域后续研究和模型完善。

Abstract: Large language models (LLMs) have shown great potential for healthcare applications. However, existing evaluation benchmarks provide minimal coverage of Alzheimer's Disease and Related Dementias (ADRD). To address this gap, we introduce ADRD-Bench, the first ADRD-specific benchmark dataset designed for rigorous evaluation of LLMs. ADRD-Bench has two components: 1) ADRD Unified QA, a synthesis of 1,352 questions consolidated from seven established medical benchmarks, providing a unified assessment of clinical knowledge; and 2) ADRD Caregiving QA, a novel set of 149 questions derived from the Aging Brain Care (ABC) program, a widely used, evidence-based brain health management program. Guided by a program with national expertise in comprehensive ADRD care, this new set was designed to mitigate the lack of practical caregiving context in existing benchmarks. We evaluated 33 state-of-the-art LLMs on the proposed ADRD-Bench. Results showed that the accuracy of open-weight general models ranged from 0.63 to 0.93 (mean: 0.78; std: 0.09). The accuracy of open-weight medical models ranged from 0.48 to 0.93 (mean: 0.82; std: 0.13). The accuracy of closed-source general models ranged from 0.83 to 0.91 (mean: 0.89; std: 0.03). While top-tier models achieved high accuracies (>0.9), case studies revealed that inconsistent reasoning quality and stability limit their reliability, highlighting a critical need for domain-specific improvement to enhance LLMs' knowledge and reasoning grounded in daily caregiving data. The entire dataset is available at https://github.com/IIRL-ND/ADRD-Bench.

</details>


### [111] [When Audio-LLMs Don't Listen: A Cross-Linguistic Study of Modality Arbitration](https://arxiv.org/abs/2602.11488)
*Jayadev Billa*

Main category: cs.CL

TL;DR: 该论文发现，当前语音-文本双模态大语言模型在语音和文本信息冲突时，显著偏好相信文本（文本主导），即使模型被明确指示要相信语音。这种现象可归因于模型在处理不同模态的信息时，推理的可访问性存在不对称性。


<details>
  <summary>Details</summary>
Motivation: 随着多模态语言模型的发展，理解模型在处理不同模态（如语音与文本）之间冲突时的决策机制变得尤为重要。本文致力于系统分析语音与文本信息冲突下，模型在仲裁时的偏好及其原因，旨在发现和解释模型在实际多模态输入中的可靠性短板。

Method: 提出了ALME基准，包含57,602个控制的语音-文本冲突刺激，覆盖8种语言，并用该基准系统评测Gemini 2.0 Flash等多款先进音频-大语言模型。在测试中，通过操控模态冲突、可访问性、转录方式、文本信息质量等变量，详尽分析了模型在冲突下的表现及内在推理机制。

Result: 实验显示，在语音-文本冲突下，模型选择文本的概率（16.6%）远高于文本-文本冲突（1.6%），即明显的文本主导；且这种差异不因音频质量所致。进一步，强制转录、故意扰动文本、仅微调音频投影层或LLM等操作均显著影响文本主导现象。此外，这一趋势在多语言、多模型间均表现一致，但存在一定差异。

Conclusion: 论文证明语音与文本冲突下的“文本主导”现象源于推理可访问性的模态不对称，而并非单靠信息量决定。这反映出现有多模态大模型在模态仲裁维度上的新型可靠性问题，有别于现有标准语音基准的测试维度。

Abstract: When audio and text conflict, speech-enabled language models follow the text 10 times more often than when arbitrating between two text sources, even when explicitly instructed to trust the audio. Using ALME, a benchmark of 57,602 controlled audio-text conflict stimuli across 8 languages, we find that Gemini 2.0 Flash exhibits 16.6\% text dominance under audio-text conflict versus 1.6\% under text-text conflict with identical reliability cues. This gap is not explained by audio quality: audio-only accuracy (97.2\%) exceeds cascade accuracy (93.9\%), indicating audio embeddings preserve more information than text transcripts. We propose that text dominance reflects an asymmetry not in information content but in arbitration accessibility: how easily the model can reason over competing representations.
  This framework explains otherwise puzzling findings. Forcing transcription before answering increases text dominance (19\% to 33\%), sacrificing audio's information advantage without improving accessibility. Framing text as ``deliberately corrupted'' reduces text dominance by 80\%. A fine-tuning ablation provides interventional evidence: training only the audio projection layer increases text dominance (+26.5\%), while LoRA on the language model halves it ($-$23.9\%), localizing text dominance to the LLM's reasoning rather than the audio encoder. Experiments across four state-of-the-art audio-LLMs and 8 languages show consistent trends with substantial cross-linguistic and cross-model variation, establishing modality arbitration as a distinct reliability dimension not captured by standard speech benchmarks.

</details>


### [112] [Multimodal Fact-Level Attribution for Verifiable Reasoning](https://arxiv.org/abs/2602.11509)
*David Wan,Han Wang,Ziyang Wang,Elias Stengel-Eskin,Hyunji Lee,Mohit Bansal*

Main category: cs.CL

TL;DR: 该论文提出MuRGAt基准，用于评估多模态大模型在复杂推理环境下每个事实级别上的信息归因能力。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大模型（MLLMs）在现实任务中广泛应用，尤其是涉及多步推理和长文本生成任务，模型输出的可靠性变得尤为重要。现有的多模态归因评测多偏向简单场景或单一模态，无法有效评估复杂情境下的细粒度归因能力。该工作致力于填补评测手段与实际需求之间的空白。

Method: 提出MuRGAt基准测试，要求模型在处理视频、音频等多模态输入时，能够生成带有显式推理过程及精确引用（注明模态和时序片段）的答案，并配套开发了一套与人工判分高度相关的自动化评测框架。

Result: 利用人工和自动评分方法测试现有MLLMs，发现尽管推理过程正确，这些模型常常会虚构事实引用。同时，研究表明，推理深度的提高或结构化归因的严格要求反而会削弱整体准确率，暴露出推理与可验证归因之间的显著差距。

Conclusion: 当前MLLMs在复杂多模态推理中的可归因性仍有较大提升空间。MuRGAt基准和自动化评测工具的提出为今后提升模型可验证性和实际应用可靠性提供了新标准和参考。

Abstract: Multimodal large language models (MLLMs) are increasingly used for real-world tasks involving multi-step reasoning and long-form generation, where reliability requires grounding model outputs in heterogeneous input sources and verifying individual factual claims. However, existing multimodal grounding benchmarks and evaluation methods focus on simplified, observation-based scenarios or limited modalities and fail to assess attribution in complex multimodal reasoning. We introduce MuRGAt (Multimodal Reasoning with Grounded Attribution), a benchmark for evaluating fact-level multimodal attribution in settings that require reasoning beyond direct observation. Given inputs spanning video, audio, and other modalities, MuRGAt requires models to generate answers with explicit reasoning and precise citations, where each citation specifies both modality and temporal segments. To enable reliable assessment, we introduce an automatic evaluation framework that strongly correlates with human judgments. Benchmarking with human and automated scores reveals that even strong MLLMs frequently hallucinate citations despite correct reasoning. Moreover, we observe a key trade-off: increasing reasoning depth or enforcing structured grounding often degrades accuracy, highlighting a significant gap between internal reasoning and verifiable attribution.

</details>


### [113] [Pretraining A Large Language Model using Distributed GPUs: A Memory-Efficient Decentralized Paradigm](https://arxiv.org/abs/2602.11543)
*Jinrui Zhang,Chaodong Xiao,Aoqi Wu,Xindong Zhang,Lei Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为SParse Expert Synchronization (SPES)的新型去中心化训练框架，有效支持在普通GPU上训练大规模MoE语言模型。该方法通过分布式同步和专家模块管理，大幅降低显存占用，同时保持性能。实验表明，SPES能在有限资源下达到中心化训练的效果。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型的预训练高度依赖于集中式集群和大容量GPU，成本高昂且难以普及。去中心化方法虽降低了通信开销，但受限于显存，单节点仍需处理全部模型参数。因此，亟需新的方法突破单卡显存限制，实现高效分布式训练。

Method: SPES框架采用混合专家（Mixture-of-Experts, MoE）结构，每个节点只训练部分专家模块以减少显存占用。节点间仅同步部分专家参数，避免全模型参数传输。为加快收敛，提出了专家合并预热策略，在训练初期增强知识共享和能力融合。

Result: 通过SPES，作者在16张48GB GPU上利用互联网环境完整训练了一个2B参数的MoE LLM，其性能与传统中心化训练模型相当。进一步，成功扩展训练7B和9B参数模型，均达到或匹配现有中心化基线水平，验证了方法的可扩展性。

Conclusion: SPES极大降低了大语言模型分布式训练对硬件的依赖，使普通GPU用户也能训练高性能模型。其创新的部分专家同步与知识融合机制，为未来更普及的大模型预训练提供了新方向和技术基础。

Abstract: Pretraining large language models (LLMs) typically requires centralized clusters with thousands of high-memory GPUs (e.g., H100/A100). Recent decentralized training methods reduce communication overhead by employing federated optimization; however, they still need to train the entire model on each node, remaining constrained by GPU memory limitations. In this work, we propose SParse Expert Synchronization (SPES), a memory-efficient decentralized framework for pretraining mixture-of-experts (MoE) LLMs. SPES trains only a subset of experts per node, substantially lowering the memory footprint. Each node updates its local experts and periodically synchronizes with other nodes, eliminating full-parameter transmission while ensuring efficient knowledge sharing. To accelerate convergence, we introduce an expert-merging warm-up strategy, where experts exchange knowledge early in training, to rapidly establish foundational capabilities. With SPES, we train a 2B-parameter MoE LLM using 16 standalone 48GB GPUs over internet connections, which achieves competitive performance with centrally trained LLMs under similar computational budgets. We further demonstrate scalability by training a 7B model from scratch and a 9B model upcycled from a dense checkpoint, both of which match prior centralized baselines. Our code is available at https://github.com/zjr2000/SPES.

</details>


### [114] [SIGHT: Reinforcement Learning with Self-Evidence and Information-Gain Diverse Branching for Search Agent](https://arxiv.org/abs/2602.11551)
*Wenlin Zhong,Jinluan Yang,Yiquan Wu,Yi Liu,Jianhang Yao,Kun Kuang*

Main category: cs.CL

TL;DR: 本文提出了SIGHT框架，通过证据提炼和信息增益引导，显著提升了大语言模型在复杂多轮问答中的检索和推理能力。


<details>
  <summary>Details</summary>
Motivation: 在多轮检索驱动的复杂问答场景中，现有方法容易因为噪音信息累积而产生不可逆错误，并易陷入“隧道视角”，影响推理准确性，因此需要更有效的信息筛选和探索策略。

Method: 作者提出SIGHT框架，包括两个关键机制：1）自我证据支持（SES），用于将检索结果精炼为高质量证据；2）信息增益驱动的多样化分支，通过计算信息增益分数指导动态提示干预（如去重、反思、自适应分支），并结合分组相对策略优化方法内化探索策略，无需外部校验器。

Result: 在单跳与多跳问答基准测试中，SIGHT显著优于现有方法，特别是在复杂推理场景下，且搜索步数更少，体现出高效且准确的信息检索与推理能力。

Conclusion: SIGHT框架通过证据提炼与信息增益引导，为大语言模型在复杂推理问答中提供了更强的探索鲁棒性和推理准确性，具有广阔的应用前景。

Abstract: Reinforcement Learning (RL) has empowered Large Language Models (LLMs) to master autonomous search for complex question answering. However, particularly within multi-turn search scenarios, this interaction introduces a critical challenge: search results often suffer from high redundancy and low signal-to-noise ratios. Consequently, agents easily fall into "Tunnel Vision," where the forced interpretation of early noisy retrievals leads to irreversible error accumulation. To address these challenges, we propose SIGHT, a framework that enhances search-based reasoning through Self-Evidence Support (SES) and Information-Gain Driven Diverse Branching. SIGHT distills search results into high-fidelity evidence via SES and calculates an Information Gain score to pinpoint pivotal states where observations maximally reduce uncertainty. This score guides Dynamic Prompting Interventions - including de-duplication, reflection, or adaptive branching - to spawn new branches with SES. Finally, by integrating SES and correctness rewards via Group Relative Policy Optimization, SIGHT internalizes robust exploration strategies without external verifiers. Experiments on single-hop and multi-hop QA benchmarks demonstrate that SIGHT significantly outperforms existing approaches, particularly in complex reasoning scenarios, using fewer search steps.

</details>


### [115] [PRIME: A Process-Outcome Alignment Benchmark for Verifiable Reasoning in Mathematics and Engineering](https://arxiv.org/abs/2602.11570)
*Xiangfeng Wang,Hangyu Guo,Yanlin Lai,Mitt Huang,Liang Zhao,Chengyuan Yao,Yinmin Zhang,Qi Han,Xiaoxiao Ren,Chun Yuan,Tong Xu,Zheng Ge,Xiangyu Zhang,Daxin Jiang*

Main category: cs.CL

TL;DR: 本文提出了PRIME，一个用于数学和工程领域的过程-结果一致性验证基准，用于评估模型验证器能否检测推导过程中的错误，而不仅仅关注最终结果。实验表明，现有验证器常常忽略推导过程中的错误。作者基于PRIME提出了过程感知的RLVR训练范式，并实证其显著优于只关注结果的方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于结果的强化学习验证器只关注最终答案是否与你的真实答案一致，常常忽略了推理过程中的错误，这可能导致模型在错误推理下获得奖励。缺乏对这一过程的有效验证工具和基准。

Method: 提出了PRIME数据集，涵盖2530个高难度STEM题目，并采用一致性过滤管道筛选样本。用PRIME系统性评估现有验证器发现它们无法很好地识别推导错误。进一步，作者提出了一种基于过程感知的RLVR训练范式，并用PRIME选出的验证器进行训练。对Qwen3-14B-Base模型进行实验。

Result: 过程感知的RLVR范式，相较于只注重结果的基线方法，在AIME24、AIME25及Beyond-AIME上分别带来8.29%、9.12%、7.31%的绝对性能提升。同时，验证器在PRIME集上的准确率与RLVR训练效率呈现强线性相关（R^2 > 0.92）。

Conclusion: PRIME能有效评估和筛选高质量验证器，过程感知的RLVR训练方法能显著提升模型性能，PRIME分数可作为验证器选择的重要参考指标。

Abstract: While model-based verifiers are essential for scaling Reinforcement Learning with Verifiable Rewards (RLVR), current outcome-centric verification paradigms primarily focus on the consistency between the final result and the ground truth, often neglecting potential errors in the derivation process. This leads to assigning positive rewards to correct answers produced from incorrect derivations. To bridge this gap, we introduce PRIME, a benchmark for evaluating verifiers on Process-Outcome Alignment verification in Mathematics and Engineering. Curated from a comprehensive collection of college-level STEM problems, PRIME comprises 2,530 high-difficulty samples through a consistency-based filtering pipeline. Through extensive evaluation, we find that current verifiers frequently fail to detect derivation flaws. Furthermore, we propose a process-aware RLVR training paradigm utilizing verifiers selected via PRIME. This approach substantially outperforms the outcome-only verification baseline, achieving absolute performance gains of 8.29%, 9.12%, and 7.31% on AIME24, AIME25, and Beyond-AIME, respectively, for the Qwen3-14B-Base model. Finally, we demonstrate a strong linear correlation ($R^2 > 0.92$) between verifier accuracy on PRIME and RLVR training effectiveness, validating PRIME as a reliable predictor for verifier selection.

</details>


### [116] [Scene-Aware Memory Discrimination: Deciding Which Personal Knowledge Stays](https://arxiv.org/abs/2602.11607)
*Yijie Zhong,Mengying Guo,Zewei Wang,Zhongyang Li,Dandan Tu,Haofen Wang*

Main category: cs.CL

TL;DR: 本文提出了一种基于场景感知的记忆辨别方法（SAMD），结合门控单元模块和聚类提示模块，有效提升大模型在用户交互信息中过滤与记忆效率，显著改善个性化应用中的知识组织能力。


<details>
  <summary>Details</summary>
Motivation: 随着智能设备的普及，用户与设备的交互数据成为宝贵的个人知识资源。如何高效地筛选、组织、存储这些信息，以支持个性化应用，是当前亟需解决的问题。然而，现有大语言模型处理高频互动数据时，常面临无关信息难以滤除和算力消耗高昂的问题。

Method: 本文受人脑选择性注意机制启发，提出了一项记忆辨别任务。针对此任务，设计了SAMD方法，包括两个核心组件：门控单元模块（GUM）用于动态过滤低价值信息，聚焦关键信息；聚类提示模块（CPM）自适应设定记忆标准，通过聚类分析提示大模型辨别哪些信息应被存储。

Result: 通过多维度直接和间接评测，SAMD在记忆辨别任务上展现出优异的召回主要关键信息的能力，并且在动态情况下面表现出较强的鲁棒性。进一步实验证明将SAMD集成到个性化应用后，能明显提高记忆构建的效率与质量。

Conclusion: SAMD方法能够有效过滤冗余信息，显著提升智能体处理和组织个人知识的能力，有助于推动大模型在个性化应用中的落地和实际效果。

Abstract: Intelligent devices have become deeply integrated into everyday life, generating vast amounts of user interactions that form valuable personal knowledge. Efficient organization of this knowledge in user memory is essential for enabling personalized applications. However, current research on memory writing, management, and reading using large language models (LLMs) faces challenges in filtering irrelevant information and in dealing with rising computational costs. Inspired by the concept of selective attention in the human brain, we introduce a memory discrimination task. To address large-scale interactions and diverse memory standards in this task, we propose a Scene-Aware Memory Discrimination method (SAMD), which comprises two key components: the Gating Unit Module (GUM) and the Cluster Prompting Module (CPM). GUM enhances processing efficiency by filtering out non-memorable interactions and focusing on the salient content most relevant to application demands. CPM establishes adaptive memory standards, guiding LLMs to discern what information should be remembered or discarded. It also analyzes the relationship between user intents and memory contexts to build effective clustering prompts. Comprehensive direct and indirect evaluations demonstrate the effectiveness and generalization of our approach. We independently assess the performance of memory discrimination, showing that SAMD successfully recalls the majority of memorable data and remains robust in dynamic scenarios. Furthermore, when integrated into personalized applications, SAMD significantly enhances both the efficiency and quality of memory construction, leading to better organization of personal knowledge.

</details>


### [117] [PACE: Prefix-Protected and Difficulty-Aware Compression for Efficient Reasoning](https://arxiv.org/abs/2602.11639)
*Ruixiang Feng,Yuntao Wen,Silin Zhou,Ke Shi,Yifan Wang,Ran Le,Zhenwei An,Zongchao Chen,Chen Yang,Guangyue Peng,Yiming Jia,Dongsheng Wang,Tao Zhang,Lisi Chen,Yang Song,Shen Gao,Shuo Shang*

Main category: cs.CL

TL;DR: 该论文提出了一种新方法，以减少语言推理模型在推理过程中过度冗长产生的无效文本，显著降低计算资源消耗，并提升模型准确率。


<details>
  <summary>Details</summary>
Motivation: 现有语言推理模型通过加大计算量提升性能，但容易“过度思考”，输出冗长的推理轨迹，造成效率低下。以往的压缩方法惩罚不灵活，可能影响关键推理步骤，无法针对不同复杂度自适应调整。

Method: 提出了层级化的双层压缩框架：在序列级别利用前缀保护优化，采用衰减混合rollout，保证早期推理逻辑完整且简洁；在分组级别引入难度感知惩罚，依据问题难度动态调整长度限制，复杂问题允许更长推理，简单问题严格压缩。

Result: 在DeepSeek-R1-Distill-Qwen (1.5B/7B)等模型和多个数学基准测试上，方法可减少高达55.7%的token消耗，同时最高提升4.1%的准确率，并能推广至代码、科学及通用领域任务。

Conclusion: 提出的方法有效缓解了过度思考问题，实现了更高效率及更优性能，对大规模语言推理模型有较强实际意义和应用价值。

Abstract: Language Reasoning Models (LRMs) achieve strong performance by scaling test-time computation but often suffer from ``overthinking'', producing excessively long reasoning traces that increase latency and memory usage. Existing LRMs typically enforce conciseness with uniform length penalties, which over-compress crucial early deduction steps at the sequence level and indiscriminately penalize all queries at the group level. To solve these limitations, we propose \textbf{\model}, a dual-level framework for prefix-protected and difficulty-aware compression under hierarchical supervision. At the sequence level, prefix-protected optimization employs decaying mixed rollouts to maintain valid reasoning paths while promoting conciseness. At the group level, difficulty-aware penalty dynamically scales length constraints based on query complexity, maintaining exploration for harder questions while curbing redundancy on easier ones. Extensive experiments on DeepSeek-R1-Distill-Qwen (1.5B/7B) demonstrate that \model achieves a substantial reduction in token usage (up to \textbf{55.7\%}) while simultaneously improving accuracy (up to \textbf{4.1\%}) on math benchmarks, with generalization ability to code, science, and general domains.

</details>


### [118] [Which Feedback Works for Whom? Differential Effects of LLM-Generated Feedback Elements Across Learner Profiles](https://arxiv.org/abs/2602.11650)
*Momoka Furuhashi,Kouta Nakayama,Noboru Kawai,Takashi Kodama,Saku Sugawara,Kyosuke Takami*

Main category: cs.CL

TL;DR: 本文探讨了大语言模型（如GPT-5）在教育环境中自动生成反馈的有效性，发现不同性格的学习者对反馈元素的接受度不同，个性化设计反馈至关重要。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在生成教育反馈方面展现潜力，但尚不清楚反馈的具体元素（如语气、信息覆盖等）如何影响学习效果和接受度，尤其是不同人格类型学生的反应差异。因此，作者希望通过实证研究明确这些反馈元素作用及个性化反馈设计的重要性。

Method: 作者定义了六种反馈元素，用GPT-5为生物学选择题生成反馈。通过一项包含321名高一学生的学习实验，利用两项学习成果评价和六项主观评价标准，系统评估反馈的有效性，并基于大五人格特质进一步分析反馈接受度的差异。

Result: 有效的反馈元素呈现出有利于学习结果的共同模式；同时，由于不同人格类型，学习者在主观偏好上存在明显差异。

Conclusion: 大语言模型自动生成的反馈设计应根据学习者人格特质灵活调整反馈元素，从而提升反馈的个性化和教育实效，这为教育领域个性化反馈设计提供了具体的指导意义。

Abstract: Large language models (LLMs) show promise for automatically generating feedback in education settings. However, it remains unclear how specific feedback elements, such as tone and information coverage, contribute to learning outcomes and learner acceptance, particularly across learners with different personality traits. In this study, we define six feedback elements and generate feedback for multiple-choice biology questions using GPT-5. We conduct a learning experiment with 321 first-year high school students and evaluate feedback effectiveness using two learning outcomes measures and subjective evaluations across six criteria. We further analyze differences in how feedback acceptance varies across learners based on Big Five personality traits. Our results show that effective feedback elements share common patterns supporting learning outcomes, while learners' subjective preferences differ across personality-based clusters. These findings highlight the importance of selecting and adapting feedback elements according to learners' personality traits when we design LLM-generated feedback, and provide practical implications for personalized feedback design in education.

</details>


### [119] [PatientHub: A Unified Framework for Patient Simulation](https://arxiv.org/abs/2602.11684)
*Sahand Sabour,TszYam NG,Minlie Huang*

Main category: cs.CL

TL;DR: 本文提出PatientHub——一个统一并模块化的平台，用于标准化基于大语言模型的患者模拟，从而提升可复现性、对比性及开发效率。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的患者模拟广泛用于咨询师培训和心理评估扩展，但现有方法在数据格式、提示词设计和评估指标方面各自为政，导致成果碎片化，难以复现和对比。作者为了解决这些痛点，提出建立一个标准化统一框架。

Method: 作者设计了PatientHub框架，规范化了患者模拟的定义、组装和部署过程，并实现了多个典型模拟方法作为案例验证。该平台支持定制化评估指标的无缝集成，同时具备良好的可扩展性，可快速原型化新的模拟方法。

Result: 通过实验，作者展示了PatientHub如何支持不同方法的标准化交叉评测，以及快速原型开发，显著减少基础设施搭建负担。此外，作者将现有相关工作整合进一条可复现的流程中。

Conclusion: PatientHub降低了新方法开发的门槛，促进了方法与模型间的公平对比及基准建设，为未来以患者为中心的对话系统数据集和方法提供了坚实基础。代码已开源，便于社区进一步研究和应用。

Abstract: As Large Language Models increasingly power role-playing applications, simulating patients has become a valuable tool for training counselors and scaling therapeutic assessment. However, prior work is fragmented: existing approaches rely on incompatible, non-standardized data formats, prompts, and evaluation metrics, hindering reproducibility and fair comparison. In this paper, we introduce PatientHub, a unified and modular framework that standardizes the definition, composition, and deployment of simulated patients. To demonstrate PatientHub's utility, we implement several representative patient simulation methods as case studies, showcasing how our framework supports standardized cross-method evaluation and the seamless integration of custom evaluation metrics. We further demonstrate PatientHub's extensibility by prototyping two new simulator variants, highlighting how PatientHub accelerates method development by eliminating infrastructure overhead. By consolidating existing work into a single reproducible pipeline, PatientHub lowers the barrier to developing new simulation methods and facilitates cross-method and cross-model benchmarking. Our framework provides a practical foundation for future datasets, methods, and benchmarks in patient-centered dialogue, and the code is publicly available via https://github.com/Sahandfer/PatientHub.

</details>


### [120] [Finding Sense in Nonsense with Generated Contexts: Perspectives from Humans and Language Models](https://arxiv.org/abs/2602.11699)
*Katrin Olsen,Sebastian Padó*

Main category: cs.CL

TL;DR: 本文评估了现有语义异常句数据集中句子的无意义性，并比较了人类与大语言模型(LLM)对句子是否无意义的判断能力。


<details>
  <summary>Details</summary>
Motivation: 由于区分语义异常（但在特定语境下可解释）与真正无意义的句子是构建计算语义解释模型的核心挑战，作者希望了解现有数据集中的句子在无意义程度上的分布，并考察LLM对两者的区分能力。

Method: 作者从五个语义异常的数据集中抽取句子，邀请人类评审者以及LLM对这些句子在无语境和有语境下进行“有意义-无意义”判定，并收集相关判断。

Result: 结果表明，大部分句子被判定为顶多只有异常而非真正无意义，只有少量句子被认定为完全无意义。同时，LLM在为语义异常句子生成合理语境方面表现出色。

Conclusion: 现有数据集中的绝大多数语句不是完全无意义，LLM能较好地区分异常句和真正无意义句，并善于为前者创造合理的理解语境。

Abstract: Nonsensical and anomalous sentences have been instrumental in the development of computational models of semantic interpretation. A core challenge is to distinguish between what is merely anomalous (but can be interpreted given a supporting context) and what is truly nonsensical. However, it is unclear (a) how nonsensical, rather than merely anomalous, existing datasets are; and (b) how well LLMs can make this distinction. In this paper, we answer both questions by collecting sensicality judgments from human raters and LLMs on sentences from five semantically deviant datasets: both context-free and when providing a context. We find that raters consider most sentences at most anomalous, and only a few as properly nonsensical. We also show that LLMs are substantially skilled in generating plausible contexts for anomalous cases.

</details>


### [121] [Thinking with Drafting: Optical Decompression via Logical Reconstruction](https://arxiv.org/abs/2602.11731)
*Jingxuan Wei,Honghao He,Caijun Jia,Siyuan Li,Zheng Sun,Yuhang Xu,Yuanyuan Lin,Linzhuang Sun,Yuchen Wu,Bihui Yu,Xiangxiang Zhang,Cheng Tan*

Main category: cs.CL

TL;DR: 本文指出现有多模态大模型在复杂推理任务中存在“精度悖论”，提出以“光学解压”为视觉输入推理的核心，并引入Thinking with Drafting (TwD)方法，利用领域特定语言作为中介，提高视觉推理精度。实验验证TwD优于直接回答的方法。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型虽然能较好地理解和生成视觉信息，但缺乏对于符号和逻辑结构的精准还原，经常在数学和逻辑推理任务中出错。因此，迫切需要新的方法来提升模型在视觉推理中的准确性。

Method: 作者提出通过“Parsing is Reasoning”的理念，将视觉输入转化为最小化领域特定语言（DSL）格式，让模型先构建可执行代码（即中介推理结构）而非直接输出答案，并通过自检的方式提升推理可靠性。实验基于自建的VisAlg视觉代数基准集进行评估。

Result: 实验表明，所提TwD方法作为认知脚手架显著提升了视觉推理中的准确性和可靠性，优于以往直接输出答案的模型。

Conclusion: TwD方法实现了视觉输入、解析、生成、验证的闭环流程，将视觉生成用于逻辑自检，为视觉推理提供了新的通用方案。

Abstract: Existing multimodal large language models have achieved high-fidelity visual perception and exploratory visual generation. However, a precision paradox persists in complex reasoning tasks: optical perception systems transcribe symbols without capturing logical topology, while pixel-based generative models produce visual artifacts lacking mathematical exactness. To bridge this gap, we propose that reasoning over visual inputs be reconceptualized as optical decompression-the process of reconstructing latent logical structures from compressed visual tokens. Guided by the axiom that Parsing is Reasoning, we introduce Thinking with Drafting (TwD), which utilizes a minimalist Domain-Specific Language (DSL) as a grounding intermediate representation. Unlike standard approaches that hallucinate answers directly, TwD forces the model to draft its mental model into executable code, rendering deterministic visual proofs for self-verification. To validate this, we present VisAlg, a visual algebra benchmark. Experiments demonstrate that TwD serve as a superior cognitive scaffold. Our work establishes a closed-loop system where visual generation acts not as a creative output but as a logical verifier, offering a generalizable path for visual reasoning.

</details>


### [122] [Think Longer to Explore Deeper: Learn to Explore In-Context via Length-Incentivized Reinforcement Learning](https://arxiv.org/abs/2602.11748)
*Futing Wang,Jianhao Yan,Yun Luo,Ganqu Cui,Zhi Wang,Xiaoye Qu,Yue Zhang,Yu Cheng,Tao Lin*

Main category: cs.CL

TL;DR: 这篇论文提出了一种基于长度激励的探索方法，以解决在测试时模型高效扩展能力受限的问题，提升模型在上下文探究过程中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在推理时很难进行有效的上下文探索，主要瓶颈在于：生成更长的、多步骤的推理序列所覆盖的状态空间更广，但自回归生成此类长序列的概率会快速衰减，导致探索受限。作者称之为“浅层探索陷阱”。

Method: 作者提出Length-Incentivized Exploration方法，通过在模型生成过程中，增加基于长度的奖励，并配合冗余惩罚，从而显式激励模型探索更多、更深入的推理轨迹，以最大化状态覆盖率。该方法分两步实现：首先给予长度奖励，其次降低重复内容带来的干扰。

Result: 在Qwen3、Llama等多种模型上的实验证明，该方法显著提升了模型的上下文探索意愿和能力。具体地，方法在同域任务上平均提升4.4%，在异域基准测试上提升2.7%。

Conclusion: Length-Incentivized Exploration方法能有效突破测试时模型探索深度不足的瓶颈，显著提升模型推理能力和泛化水平，在增强语言模型自适应探索方面具有实际应用价值。

Abstract: Achieving effective test-time scaling requires models to engage in In-Context Exploration -- the intrinsic ability to generate, verify, and refine multiple reasoning hypotheses within a single continuous context.
  Grounded in State Coverage theory, our analysis identifies a critical bottleneck to enabling this capability: while broader state coverage requires longer reasoning trajectories, the probability of sampling such sequences decays exponentially during autoregressive generation, a phenomenon we term the ``Shallow Exploration Trap''.
  To bridge this gap, we propose Length-Incentivized Exploration(\method).
  This simple yet effective recipe explicitly encourages models to explore more via a length-based reward coupled with a redundancy penalty, thereby maximizing state coverage in two-step manner.
  Comprehensive experiments across different models (Qwen3, Llama) demonstrate that \method effectively incentivize in-context exploration.
  As a result, our method achieves an average improvement of 4.4\% on in-domain tasks and a 2.7\% gain on out-of-domain benchmarks.

</details>


### [123] [MiniCPM-SALA: Hybridizing Sparse and Linear Attention for Efficient Long-Context Modeling](https://arxiv.org/abs/2602.11761)
*MiniCPM Team,Wenhao An,Yingfa Chen,Yewei Fang,Jiayi Li,Xin Li,Yaohui Li,Yishan Li,Yuxuan Li,Biyuan Lin,Chuan Liu,Hezi Liu,Siyuan Liu,Hongya Lyu,Yinxu Pan,Shixin Ren,Xingyu Shen,Zhou Su,Haojun Sun,Yangang Sun,Zhen Leng Thai,Xin Tian,Rui Wang,Xiaorong Wang,Yudong Wang,Bo Wu,Xiaoyue Xu,Dong Xu,Shuaikang Xue,Jiawei Yang,Bowen Zhang,Jinqian Zhang,Letian Zhang,Shengnan Zhang,Xinyu Zhang,Xinyuan Zhang,Zhu Zhang,Hengyu Zhao,Jiacheng Zhao,Jie Zhou,Zihan Zhou,Shuo Wang,Chaojun Xiao,Xu Han,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: MiniCPM-SALA是一种9B参数的混合大模型，结合稀疏注意力和线性注意力，实现了高效且高性能的超长文本处理。相比传统Transformer显著降低了推理和训练的成本，同时维持了优越的能力。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer结构在处理超长文本时，计算和内存代价极高，即使稀疏或线性注意力机制有所改进，仍然难以平衡性能与效率。亟需一种既省资源又不损失表现的方法应对超长上下文应用的需求。

Method: 提出MiniCPM-SALA模型，采用1:3的稀疏注意力（InfLLM-V2）与线性注意力（Lightning Attention）层混排，结合混合位置编码（HyPE），并设计了低成本的增量训练框架，可将常规模型转换为混合架构，训练成本大降。

Result: 实验表明，MiniCPM-SALA的表现基本与全注意力模型一致，但推理速度最多提升3.5倍，支持最长100万个token的上下文，且单卡算力下远超传统全注意力模型的能力。

Conclusion: MiniCPM-SALA实现了超长文本的高效、低成本建模，是传统Transformer在长文本任务上的卓越替代方案，为资源受限环境和超长文本应用扩展了新可能。

Abstract: The evolution of large language models (LLMs) towards applications with ultra-long contexts faces challenges posed by the high computational and memory costs of the Transformer architecture. While existing sparse and linear attention mechanisms attempt to mitigate these issues, they typically involve a trade-off between memory efficiency and model performance. This paper introduces MiniCPM-SALA, a 9B-parameter hybrid architecture that integrates the high-fidelity long-context modeling of sparse attention (InfLLM-V2) with the global efficiency of linear attention (Lightning Attention). By employing a layer selection algorithm to integrate these mechanisms in a 1:3 ratio and utilizing a hybrid positional encoding (HyPE), the model maintains efficiency and performance for long-context tasks. Furthermore, we introduce a cost-effective continual training framework that transforms pre-trained Transformer-based models into hybrid models, which reduces training costs by approximately 75% compared to training from scratch. Extensive experiments show that MiniCPM-SALA maintains general capabilities comparable to full-attention models while offering improved efficiency. On a single NVIDIA A6000D GPU, the model achieves up to 3.5x the inference speed of the full-attention model at the sequence length of 256K tokens and supports context lengths of up to 1M tokens, a scale where traditional full-attention 8B models fail because of memory constraints.

</details>


### [124] [A Subword Embedding Approach for Variation Detection in Luxembourgish User Comments](https://arxiv.org/abs/2602.11795)
*Anne-Marie Lutgen,Alistair Plum,Christoph Purschke*

Main category: cs.CL

TL;DR: 本文提出了一种基于嵌入的新方法，能在无需预先归一化或变体词表的条件下，自动检测语言变体。


<details>
  <summary>Details</summary>
Motivation: 现有语言变体检测高度依赖于手工标注或先验词表，难以适用于资源稀缺或多方言、小语种环境。作者希望通过更自动化的方式揭示多样化的拼写和形态结构，将其视为有意义的语言现象而非噪声。

Method: 方法在原始卢森堡语大语料上训练子词嵌入，将嵌入的余弦距离与n-gram相似性结合，自动聚类相关词形，进而探索拼写与形态变化。无需人工标注，支持定量与定性分析。

Result: 本方法发现了大量对齐于方言学和社会语言学研究的词汇和正字法变体，自动生成的家族反映出区域和风格差异。生成的聚类透明可解释。

Conclusion: 分布式建模可在“噪声大”或低资源场景下揭示有意义的变体模式，为多语或小语种语言变体研究提供了可复现的分析框架。

Abstract: This paper presents an embedding-based approach to detecting variation without relying on prior normalisation or predefined variant lists. The method trains subword embeddings on raw text and groups related forms through combined cosine and n-gram similarity. This allows spelling and morphological diversity to be examined and analysed as linguistic structure rather than treated as noise. Using a large corpus of Luxembourgish user comments, the approach uncovers extensive lexical and orthographic variation that aligns with patterns described in dialectal and sociolinguistic research. The induced families capture systematic correspondences and highlight areas of regional and stylistic differentiation. The procedure does not strictly require manual annotation, but does produce transparent clusters that support both quantitative and qualitative analysis. The results demonstrate that distributional modelling can reveal meaningful patterns of variation even in ''noisy'' or low-resource settings, offering a reproducible methodological framework for studying language variety in multilingual and small-language contexts.

</details>


### [125] [DMAP: A Distribution Map for Text](https://arxiv.org/abs/2602.11871)
*Tom Kempton,Julia Rozanova,Parameswaran Kamalaruban,Maeve Madigan,Karolina Wresilo,Yoann L. Launay,David Sutton,Stuart Burrell*

Main category: cs.CL

TL;DR: 该论文提出了DMAP方法，将文本通过大语言模型映射为包含排序和值信息的采样点，从而实现高效且通用的文本统计分析。


<details>
  <summary>Details</summary>
Motivation: 传统的困惑度等度量方法不能充分捕捉上下文信息，不同token的概率分布形状也影响理解，亟需新的统计视角对LLM生成文本做深入分析。

Method: 提出DMAP方法，通过语言模型将文本映射为单位区间上的采样点，这些点结合了rank与概率信息。DMAP实现了统计特征的高效抽取和表示，并且无需依赖模型特性，适应多种应用场景。

Result: 通过三种案例展示DMAP实用性：1）用于生成参数校验，保证数据完整性；2）分析概率曲率在机器生成文本检测中的作用；3）法证分析展现模型微调后在下游模型中的统计特征指纹。结果显示DMAP简单高效，能在消费级硬件上运行。

Conclusion: DMAP为文本统计分析提供了统一、易用且基础坚实的方法论，适用于多种任务，并为未来LLM文本分析研究提供了良好基础。

Abstract: Large Language Models (LLMs) are a powerful tool for statistical text analysis, with derived sequences of next-token probability distributions offering a wealth of information. Extracting this signal typically relies on metrics such as perplexity, which do not adequately account for context; how one should interpret a given next-token probability is dependent on the number of reasonable choices encoded by the shape of the conditional distribution. In this work, we present DMAP, a mathematically grounded method that maps a text, via a language model, to a set of samples in the unit interval that jointly encode rank and probability information. This representation enables efficient, model-agnostic analysis and supports a range of applications. We illustrate its utility through three case studies: (i) validation of generation parameters to ensure data integrity, (ii) examining the role of probability curvature in machine-generated text detection, and (iii) a forensic analysis revealing statistical fingerprints left in downstream models that have been subject to post-training on synthetic data. Our results demonstrate that DMAP offers a unified statistical view of text that is simple to compute on consumer hardware, widely applicable, and provides a foundation for further research into text analysis with LLMs.

</details>


### [126] [Towards Fair and Comprehensive Evaluation of Routers in Collaborative LLM Systems](https://arxiv.org/abs/2602.11877)
*Wanxing Wu,He Zhu,Yixia Li,Lei Yang,Jiehui Zhao,Hongru Wang,Jian Yang,Benyou Wang,Bingyi Jing,Guanhua Chen*

Main category: cs.CL

TL;DR: 本文提出了RouterXBench评估框架与ProbeDirichlet路由器模型，通过聚合多层隐藏状态实现高鲁棒性、本地和云模型协作的高效路由，提升传统方法性能17%左右。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在能力上表现出色，但由于成本和隐私问题，往往需要本地部署小模型，仅将复杂查询分派给云端模型。当前的路由器评测缺乏系统性，忽略了特定场景和分布外的鲁棒性需求。

Method: 作者提出了RouterXBench评估框架，包含路由能力、场景对齐性和跨领域鲁棒性三维度。创新性地利用模型内部隐藏状态（而非输出概率或外部嵌入）衡量模型不确定性。提出轻量级ProbeDirichlet路由器，采用可学习的Dirichlet分布跨层聚合隐藏状态，结合概率化训练方式，在多领域数据上训练以提升泛化能力。

Result: ProbeDirichlet在路由能力和高精度场景下，分别较最佳基线提升16.68%和18.86%。在不同模型家族、规模、异质任务与智能体流程上均表现出一致性和鲁棒性。

Conclusion: RouterXBench为路由器评测提供了系统性方法，ProbeDirichlet有效利用隐藏状态信息，在多场景和跨领域中表现优异，为大语言模型的高效部署与协同推理提供了切实可行的途径。

Abstract: Large language models (LLMs) have achieved success, but cost and privacy constraints necessitate deploying smaller models locally while offloading complex queries to cloud-based models. Existing router evaluations are unsystematic, overlooking scenario-specific requirements and out-of-distribution robustness. We propose RouterXBench, a principled evaluation framework with three dimensions: router ability, scenario alignment, and cross-domain robustness. Unlike prior work that relies on output probabilities or external embeddings, we utilize internal hidden states that capture model uncertainty before answer generation. We introduce ProbeDirichlet, a lightweight router that aggregates cross-layer hidden states via learnable Dirichlet distributions with probabilistic training. Trained on multi-domain data, it generalizes robustly across in-domain and out-of-distribution scenarios. Our results show ProbeDirichlet achieves 16.68% and 18.86% relative improvements over the best baselines in router ability and high-accuracy scenarios, with consistent performance across model families, model scales, heterogeneous tasks, and agentic workflows.

</details>


### [127] [LLM-based Triplet Extraction from Financial Reports](https://arxiv.org/abs/2602.11886)
*Dante Wesslund,Ville Stenström,Pontus Linde,Alexander Holmberg*

Main category: cs.CL

TL;DR: 本文提出了一套半自动化流程，用于从企业财报中抽取三元组，通过本体驱动的代理指标代替人工标注的评价方法，并对不同本体生成方式和验证策略进行分析与比较。


<details>
  <summary>Details</summary>
Motivation: 企业财报蕴含丰富的结构化知识，适用于知识图谱构建，但由于缺乏标注数据，传统的抽取结果评估困难。为此需要新的无标注评价机制和自动化流程。

Method: 提出半自动抽取流程，采用本体一致性和忠实性作为指标，无需人工标注数据。对比静态人工本体与自动文档本体归纳的方法，并测试多种大模型。提出结合正则与大模型判定的混合验证策略，以过滤指代消解带来的虚假主体。

Result: 自动生成的本体在所有配置下均实现100%一致性，消除了人工本体的漂移。混合验证策略将主体幻觉率从65.2%降至1.6%。文中还发现财报文本中主客体幻觉分布存在系统性非对称。

Conclusion: 自动本体优于人工本体，并且混合验证策略极大提升了抽取结果的精准性。该流程和评价体系能有效支持缺乏标注数据的知识抽取任务，特别适合结构化财报文本场景。

Abstract: Corporate financial reports are a valuable source of structured knowledge for Knowledge Graph construction, but the lack of annotated ground truth in this domain makes evaluation difficult. We present a semi-automated pipeline for Subject-Predicate-Object triplet extraction that uses ontology-driven proxy metrics, specifically Ontology Conformance and Faithfulness, instead of ground-truth-based evaluation. We compare a static, manually engineered ontology against a fully automated, document-specific ontology induction approach across different LLMs and two corporate annual reports. The automatically induced ontology achieves 100% schema conformance in all configurations, eliminating the ontology drift observed with the manual approach. We also propose a hybrid verification strategy that combines regex matching with an LLM-as-a-judge check, reducing apparent subject hallucination rates from 65.2% to 1.6% by filtering false positives caused by coreference resolution. Finally, we identify a systematic asymmetry between subject and object hallucinations, which we attribute to passive constructions and omitted agents in financial prose.

</details>


### [128] [Benchmark Illusion: Disagreement among LLMs and Its Scientific Consequences](https://arxiv.org/abs/2602.11898)
*Eddie Yang,Dashun Wang*

Main category: cs.CL

TL;DR: 本文揭示了不同大语言模型在标准基准测试上即使表面成绩相似，其实际作答却存在较大分歧，从而影响科学研究的可复现性和结论可靠性。


<details>
  <summary>Details</summary>
Motivation: 尽管基准测试广泛用于衡量和比较大语言模型的性能，但高分数可能掩盖了模型间的深层差异。该文旨在探究表面准确性一致时，模型之间潜在的不一致性及其对科学研究结果的影响。

Method: 作者选择了MMLU-Pro和GPQA两个主要推理类基准，比较多种大语言模型在相同准确率下对具体题目的分歧比例，并分析这些模型在教育和政治科学领域的实际数据标注任务中所导致的结果变化。

Result: 即便多种LLM在基准上的整体正确率相当，具体题目上的答案一致率仅为34-84%。在科学研究的数据标注重分析中，采用不同模型会导致推断结果有最高80%以上的变化，有时甚至会推翻研究结论。

Conclusion: 仅凭基准分数评价模型是不充分的。模型选择成为科学推理中的隐性影响因素，模型间的分歧会严重影响科研结果的可重复性和可靠性，必须对‘基准假象’予以重视。

Abstract: Benchmarks underpin how progress in large language models (LLMs) is measured and trusted. Yet our analyses reveal that apparent convergence in benchmark accuracy can conceal deep epistemic divergence. Using two major reasoning benchmarks - MMLU-Pro and GPQA - we show that LLMs achieving comparable accuracy still disagree on 16-66% of items, and 16-38% among top-performing frontier models. These discrepancies suggest distinct error profiles for different LLMs. When such models are used for scientific data annotation and inference, their hidden disagreements propagate into research results: in re-analyses of published studies in education and political science, switching the annotation model can change estimated treatment effects by more than 80%, and in some cases reverses their sign. Together, these findings illustrate a benchmark illusion, where equal accuracy may conceal disagreement, with model choice becoming a hidden yet consequential variable for scientific reproducibility.

</details>


### [129] [AdaptEvolve: Improving Efficiency of Evolutionary AI Agents through Adaptive Model Selection](https://arxiv.org/abs/2602.11931)
*Pretam Ray,Pratik Prabhanjan Brahma,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: 提出了AdaptEvolve方法，通过自适应选择不同规模的LLM，优化推理时的效率与能力平衡，大幅降低成本且基本保持准确率。


<details>
  <summary>Details</summary>
Motivation: 在进化式智能体系统中，需要多次调用LLM进行推理，带来了计算效率与推理能力的权衡问题——如何动态选择既能满足当前任务又高效的模型成为关键。

Method: 提出了一种基于进化式序贯优化框架的自适应LLM选择方法AdaptEvolve。该方法根据模型自信度评估当前任务的可解性，实时匹配适合当前步骤的LLM，并通过这种信心驱动机制优化模型选择流程。

Result: 实验证明，AdaptEvolve在基准测试中，将总推理成本平均降低37.9%，同时还能保持上界大模型方案97.5%的准确率。

Conclusion: 通过自信度驱动的自适应模型分流，可在保证精度的前提下，显著提升推理效率；为多LLM协同与高效推理提供了新思路。

Abstract: Evolutionary agentic systems intensify the trade-off between computational efficiency and reasoning capability by repeatedly invoking large language models (LLMs) during inference. This setting raises a central question: how can an agent dynamically select an LLM that is sufficiently capable for the current generation step while remaining computationally efficient? While model cascades offer a practical mechanism for balancing this trade-off, existing routing strategies typically rely on static heuristics or external controllers and do not explicitly account for model uncertainty. We introduce AdaptEvolve: Adaptive LLM Selection for Multi-LLM Evolutionary Refinement within an evolutionary sequential refinement framework that leverages intrinsic generation confidence to estimate real-time solvability. Empirical results show that confidence-driven selection yields a favourable Pareto frontier, reducing total inference cost by an average of 37.9% across benchmarks while retaining 97.5% of the upper-bound accuracy of static large-model baselines. Our code is available at https://github.com/raypretam/adaptive_llm_selection.

</details>


### [130] [Cross-Modal Robustness Transfer (CMRT): Training Robust Speech Translation Models Using Adversarial Text](https://arxiv.org/abs/2602.11933)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 本文提出了一种新方法，可提升端到端语音翻译（E2E-ST）模型对屈折形态变化的鲁棒性，无需生成对抗性语音数据就能提高模型在面对非标准或带口音语音输入时的表现。


<details>
  <summary>Details</summary>
Motivation: 当前E2E-ST主要在干净的语料上评测，未考虑口音、外语等引发的屈折变化，这让模型在实际应用中容易失效，亟需提高其形态鲁棒性。

Method: 作者借鉴了文本领域基于形态变化的对抗攻击，将其引入语音领域，并提出一种跨模态鲁棒性转移（CMRT）框架，将在文本模型中通过对抗性训练得到的鲁棒性迁移到语音翻译模型上，无需对抗性语音数据生成。

Result: 在四个语言对上的大量实验表明，CMRT平均提升对抗鲁棒性3个BLEU分以上，且无需训练阶段生成对抗性语音数据。

Conclusion: CMRT为E2E-ST鲁棒性提升提供了新的高效方案，摆脱了对抗性语音数据生成的高昂成本，为实际应用带来更强可靠性和通用性。

Abstract: End-to-End Speech Translation (E2E-ST) has seen significant advancements, yet current models are primarily benchmarked on curated, "clean" datasets. This overlooks critical real-world challenges, such as morphological robustness to inflectional variations common in non-native or dialectal speech. In this work, we adapt a text-based adversarial attack targeting inflectional morphology to the speech domain and demonstrate that state-of-the-art E2E-ST models are highly vulnerable it. While adversarial training effectively mitigates such risks in text-based tasks, generating high-quality adversarial speech data remains computationally expensive and technically challenging. To address this, we propose Cross-Modal Robustness Transfer (CMRT), a framework that transfers adversarial robustness from the text modality to the speech modality. Our method eliminates the requirement for adversarial speech data during training. Extensive experiments across four language pairs demonstrate that CMRT improves adversarial robustness by an average of more than 3 BLEU points, establishing a new baseline for robust E2E-ST without the overhead of generating adversarial speech.

</details>


### [131] [Who is the richest club in the championship? Detecting and Rewriting Underspecified Questions Improve QA Performance](https://arxiv.org/abs/2602.11938)
*Yunchong Huang,Gianni Barlacchi,Sandro Pezzelle*

Main category: cs.CL

TL;DR: 本文发现，现有问答基准数据中的很多问题定义不明确，导致大模型性能被低估。通过识别、重写这些问题，模型表现明显提升，表明问句明确性对评测结果影响极大。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLM）在结构良好的问题上表现突出，但主流QA基准数据集的得分仍未达到‘解决’水平。作者认为其中一个重要原因是很多问题本身定义不清、含糊，需要更多上下文才能确定其唯一语义。通过厘清这一点，可以更准确评估模型的真实能力。

Method: 作者提出一种LLM驱动的分类器，自动识别问题是否‘定义不明确’。他们将该工具应用于多个主流QA数据集，统计不明确问题的比例，并比较模型在这些问题与清晰问题上的表现。同时，他们进行‘重写实验’，将识别出的含糊问题转化为明确问题，再测试模型表现。

Result: 实验发现，在常用QA数据集中，有16%到50%以上的问题属于‘定义不明确’。LLM在这些问题上的表现远低于定义清晰的问题。将问题重写为明确定义后，模型性能大幅提升。

Conclusion: 许多看似的QA失败其实源于问题本身表述不清，而不是模型无能。未来QA基准设计应更加重视问题的准确与明确性，避免用含糊问题低估模型真实水平。

Abstract: Large language models (LLMs) perform well on well-posed questions, yet standard question-answering (QA) benchmarks remain far from solved. We argue that this gap is partly due to underspecified questions - queries whose interpretation cannot be uniquely determined without additional context. To test this hypothesis, we introduce an LLM-based classifier to identify underspecified questions and apply it to several widely used QA datasets, finding that 16% to over 50% of benchmark questions are underspecified and that LLMs perform significantly worse on them. To isolate the effect of underspecification, we conduct a controlled rewriting experiment that serves as an upper-bound analysis, rewriting underspecified questions into fully specified variants while holding gold answers fixed. QA performance consistently improves under this setting, indicating that many apparent QA failures stem from question underspecification rather than model limitations. Our findings highlight underspecification as an important confound in QA evaluation and motivate greater attention to question clarity in benchmark design.

</details>


### [132] [Do Large Language Models Adapt to Language Variation across Socioeconomic Status?](https://arxiv.org/abs/2602.11939)
*Elisa Bassignana,Mike Zhang,Dirk Hovy,Amanda Cercas Curry*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLM）在不同社会经济地位（SES）社区的社交媒体交流中，语言风格适应性的有限性。LLM通常更有效仿上层SES社群风格，缺乏对低SES风格的适应，可能加剧语言层级和社会分化。


<details>
  <summary>Details</summary>
Motivation: 随着LLM广泛参与人类沟通，人们担忧其无法适应不同社群的多样语言风格，可能加剧刻板印象与社会边缘化。作者希望探究LLM在不同SES背景下对语言风格适应的能力。

Method: 作者收集并分层整理Reddit和YouTube上的社交媒体文本，并按SES分类。以这些文本的不完整片段提示四种LLM，让其补全文本，随后使用94项社会语言学指标（句法、修辞、词汇特征等）系统评估生成文本与原文的风格贴合度。

Result: LLM只在很小程度上依据SES调整语言风格，经常出现简单模仿或刻意夸张的情况，且更容易学到上层SES的表达风格。

Conclusion: LLM有限的风格适应性可能会强化语言等级和社会分层，对基于风格的社会模拟和调查实验等研究产生质疑。

Abstract: Humans adjust their linguistic style to the audience they are addressing. However, the extent to which LLMs adapt to different social contexts is largely unknown. As these models increasingly mediate human-to-human communication, their failure to adapt to diverse styles can perpetuate stereotypes and marginalize communities whose linguistic norms are less closely mirrored by the models, thereby reinforcing social stratification. We study the extent to which LLMs integrate into social media communication across different socioeconomic status (SES) communities. We collect a novel dataset from Reddit and YouTube, stratified by SES. We prompt four LLMs with incomplete text from that corpus and compare the LLM-generated completions to the originals along 94 sociolinguistic metrics, including syntactic, rhetorical, and lexical features. LLMs modulate their style with respect to SES to only a minor extent, often resulting in approximation or caricature, and tend to emulate the style of upper SES more effectively. Our findings (1) show how LLMs risk amplifying linguistic hierarchies and (2) call into question their validity for agent-based social simulation, survey experiments, and any research relying on language style as a social signal.

</details>


### [133] [Scaling Model and Data for Multilingual Machine Translation with Open Large Language Models](https://arxiv.org/abs/2602.11961)
*Yuzhe Shang,Pengzhi Gao,Wei Liu,Jian Luan,Jinsong Su*

Main category: cs.CL

TL;DR: 本研究提出了MiLMMT-46，一个基于Gemma3系列模型的多语言机器翻译大模型，支持46种语言，并在多个基准上取得领先表现。


<details>
  <summary>Details</summary>
Motivation: 当前开放大语言模型在多语言能力上有显著提升，但在多语言机器翻译领域仍有进一步探索空间，尤其是模型扩展和数据扩展对翻译能力的具体影响尚不明确。

Method: 通过对开放大语言模型进行持续预训练与指令微调，探究模型规模扩展和数据量扩展对机器翻译能力的提升作用。实验基于Gemma3系列模型，最终形成支持46种语言的MiLMMT-46。

Result: MiLMMT-46在46种语言上的多语言翻译任务中，整体表现优于近期SOTA模型（如Seed-X、HY-MT-1.5和TranslateGemma），并在与Google Translate及Gemini 3 Pro等商业系统的对比中表现出较强的竞争力。

Conclusion: 通过有针对性的模型和数据扩展，以及持续预训练和指令微调，MiLMMT-46模型显著提升了开放大语言模型在多语言翻译任务中的表现，为开放模型在实际多语言翻译应用中提供了有力支持。

Abstract: Open large language models (LLMs) have demonstrated improving multilingual capabilities in recent years. In this paper, we present a study of open LLMs for multilingual machine translation (MT) across a range of languages, and investigate the effects of model scaling and data scaling when adapting open LLMs to multilingual MT through continual pretraining and instruction finetuning. Based on the Gemma3 model family, we develop MiLMMT-46, which achieves top-tier multilingual translation performance across 46 languages. Extensive experiments show that MiLMMT-46 consistently outperforms recent state-of-the-art (SOTA) models, including Seed-X, HY-MT-1.5, and TranslateGemma, and achieves competitive performance with strong proprietary systems such as Google Translate and Gemini 3 Pro.

</details>


### [134] [DHPLT: large-scale multilingual diachronic corpora and word representations for semantic change modelling](https://arxiv.org/abs/2602.11968)
*Mariia Fedorova,Andrey Kutuzov,Khonzoda Umarova*

Main category: cs.CL

TL;DR: 本文介绍了DHPLT，这是一个涵盖41种语言的多时段历时语料库，旨在为语义变化建模提供数据资源。


<details>
  <summary>Details</summary>
Motivation: 目前有关多语言历时语义变化的公开语料资源非常有限，尤其是在高资源语言以外领域亟需补充数据，以支持更多相关研究。

Method: 以网络抓取的HPLT语料作为基础，根据文档抓取时间推断文档创建时期，分别整理2011-2015、2020-2021和2024至今这三个时段，每种语言每个时段各100万文档。此外，预计算了词嵌入和词位嵌入，并为部分目标词汇生成了替换数据，同时鼓励其他研究者用相同数据集设定自己的目标词汇。

Result: 创建了覆盖41种语言、3个主要时间段的大规模历时语料库（网址公开），并提供相关向量与词汇替换信息，极大丰富了多语言历时资源。

Conclusion: DHPLT的发布填补了多语言语义变化建模中资源的空白，为研究者设计新的实验方案提供了可能，有望推动该领域的更深入研究。

Abstract: In this resource paper, we present DHPLT, an open collection of diachronic corpora in 41 diverse languages. DHPLT is based on the web-crawled HPLT datasets; we use web crawl timestamps as the approximate signal of document creation time. The collection covers three time periods: 2011-2015, 2020-2021 and 2024-present (1 million documents per time period for each language). We additionally provide pre-computed word type and token embeddings and lexical substitutions for our chosen target words, while at the same time leaving it open for the other researchers to come up with their own target words using the same datasets. DHPLT aims at filling in the current lack of multilingual diachronic corpora for semantic change modelling (beyond a dozen of high-resource languages). It opens the way for a variety of new experimental setups in this field. All the resources described in this paper are available at https://data.hplt-project.org/three/diachronic/, sorted by language.

</details>


### [135] [Automatic Simplification of Common Vulnerabilities and Exposures Descriptions](https://arxiv.org/abs/2602.11982)
*Varpu Vehomäki,Kimmo K. Kaski*

Main category: cs.CL

TL;DR: 本文探索了使用大型语言模型（LLMs）对网络安全漏洞描述（CVE）的自动文本简化，发现虽然现有LLM可以让文本更易读，但往往难以完全保持原意。


<details>
  <summary>Details</summary>
Motivation: 随着网络安全重要性提升，大量相关信息难以为普通人理解。因此，研究如何简化网络安全文本，帮助更多人理解，是当前的需求。

Method: 本研究以CVE描述为对象，建立了网络安全自动文本简化（ATS）的基线系统，并构建了包含40条CVE描述的测试数据集。由两组网络安全专家分两轮问卷对结果进行评估，主要考察LLM简化能力及语义保持程度。

Result: 实验发现，现有的大型语言模型能够增加文本可读性，使漏洞说明更易懂，但在保证原意完整性方面存在显著不足。

Conclusion: 当前LLM在网络安全领域文本简化上已经能提升易读性，但语义保真问题仍需进一步研究优化。研究为网络安全ATS提供了基线和数据集，推进了该领域发展。

Abstract: Understanding cyber security is increasingly important for individuals and organizations. However, a lot of information related to cyber security can be difficult to understand to those not familiar with the topic. In this study, we focus on investigating how large language models (LLMs) could be utilized in automatic text simplification (ATS) of Common Vulnerability and Exposure (CVE) descriptions. Automatic text simplification has been studied in several contexts, such as medical, scientific, and news texts, but it has not yet been studied to simplify texts in the rapidly changing and complex domain of cyber security. We created a baseline for cyber security ATS and a test dataset of 40 CVE descriptions, evaluated by two groups of cyber security experts in two survey rounds. We have found that while out-of-the box LLMs can make the text appear simpler, they struggle with meaning preservation. Code and data are available at https://version.aalto.fi/gitlab/vehomav1/simplification\_nmi.

</details>


### [136] [LaCy: What Small Language Models Can and Should Learn is Not Just a Question of Loss](https://arxiv.org/abs/2602.12005)
*Szilvia Ujváry,Louis Béthune,Pierre Ablin,João Monteiro,Marco Cuturi,Michael Kirchhof*

Main category: cs.CL

TL;DR: 本论文提出了一种新型的语言模型预训练方法LaCy，能够让小型语言模型（SLM）在生成文本时有效决定哪些内容应该自己生成，哪些内容应该委托更强大的外部资源来生成，从而提升了生成的事实准确度。


<details>
  <summary>Details</summary>
Motivation: 由于SLM的参数容量有限，无法预训练或存储全部世界知识，导致事实错误频发。现有做法是让SLM在必要时访问更大的模型或外部数据库，但如何精确地区分哪些内容SLM应自己学习，哪些应委托外部资源，尚无有效方法。

Method: 作者提出用一个spaCy语法解析器增强预训练损失信号，用以判断在训练文本中，哪些token应由SLM自行学习，哪些应通过<CALL>特殊token委托给外部资源，从而实现高效分工。基于此，提出了LaCy预训练方法。

Result: 实验表明，采用LaCy方法的SLM能够更合理地决定自己生成哪些内容，何时委托任务。在与大型模型级联生成时，LaCy模型的事实分数（FactScores）更高，且优于Rho或LLM-judge等方法，同时更加简单和低耗。

Conclusion: 本论文方法能够让小型语言模型在事实准确性和推理效率间取得更优平衡，在资源受限或需高效推理的实际场景下具有良好的应用前景。

Abstract: Language models have consistently grown to compress more world knowledge into their parameters, but the knowledge that can be pretrained into them is upper-bounded by their parameter size. Especially the capacity of Small Language Models (SLMs) is limited, leading to factually incorrect generations. This problem is often mitigated by giving the SLM access to an outside source: the ability to query a larger model, documents, or a database. Under this setting, we study the fundamental question of \emph{which tokens an SLM can and should learn} during pretraining, versus \emph{which ones it should delegate} via a \texttt{<CALL>} token. We find that this is not simply a question of loss: although the loss is predictive of whether a predicted token mismatches the ground-truth, some tokens are \emph{acceptable} in that they are truthful alternative continuations of a pretraining document, and should not trigger a \texttt{<CALL>} even if their loss is high. We find that a spaCy grammar parser can help augment the loss signal to decide which tokens the SLM should learn to delegate to prevent factual errors and which are safe to learn and predict even under high losses. We propose LaCy, a novel pretraining method based on this token selection philosophy. Our experiments demonstrate that LaCy models successfully learn which tokens to predict and where to delegate for help. This results in higher FactScores when generating in a cascade with a bigger model and outperforms Rho or LLM-judge trained SLMs, while being simpler and cheaper.

</details>


### [137] [Disentangling Ambiguity from Instability in Large Language Models: A Clinical Text-to-SQL Case Study](https://arxiv.org/abs/2602.12015)
*Angelo Ziletti,Leonardo D'Ambrosi*

Main category: cs.CL

TL;DR: 本文提出了CLUES框架，对临床Text-to-SQL任务中的语义不确定性进行细致分析并量化，有效提升了失败预测能力。


<details>
  <summary>Details</summary>
Motivation: 在临床Text-to-SQL应用中，大模型输出多样性可能源于输入歧义或模型不稳定，这二者需要不同的干预措施，但以往方法无法细致区分。

Method: 提出CLUES框架，将Text-to-SQL过程分为（解释—>答案）两阶段，并用两种得分（歧义得分和不稳定得分）量化两类不确定性，其中不稳定得分基于二部语义图矩阵的Schur补计算。

Result: 在AmbigQA/SituatedQA和临床Text-to-SQL基准数据集测试中，CLUES在失败预测方面优于最新的Kernel Language Entropy方法。在实际部署中CLUES仍表现出色，并能提供更可诊断的不确定性分解。高歧义/高不稳定区间囊括了51%错误而只覆盖25%的查询，显著提升了人工干预效率。

Conclusion: CLUES框架能有效区分并量化语义歧义和模型不稳定，对症下药地指导后续干预措施（如人工澄清或模型改进），在实际部署中能提升错误识别与处理效率。

Abstract: Deploying large language models for clinical Text-to-SQL requires distinguishing two qualitatively different causes of output diversity: (i) input ambiguity that should trigger clarification, and (ii) model instability that should trigger human review. We propose CLUES, a framework that models Text-to-SQL as a two-stage process (interpretations --> answers) and decomposes semantic uncertainty into an ambiguity score and an instability score. The instability score is computed via the Schur complement of a bipartite semantic graph matrix. Across AmbigQA/SituatedQA (gold interpretations) and a clinical Text-to-SQL benchmark (known interpretations), CLUES improves failure prediction over state-of-the-art Kernel Language Entropy. In deployment settings, it remains competitive while providing a diagnostic decomposition unavailable from a single score. The resulting uncertainty regimes map to targeted interventions - query refinement for ambiguity, model improvement for instability. The high-ambiguity/high-instability regime contains 51% of errors while covering 25% of queries, enabling efficient triage.

</details>


### [138] [Composition-RL: Compose Your Verifiable Prompts for Reinforcement Learning of Large Language Models](https://arxiv.org/abs/2602.12036)
*Xin Xu,Clive Bai,Kai Yang,Tianhao Chen,Yangkun Chen,Weijie Liu,Hao Chen,Yang Wang,Saiyong Yang,Can Yang*

Main category: cs.CL

TL;DR: 提出了一种名为Composition-RL的新方法，通过将多个简单的高通过率（pass-rate-1）prompt自动组合成新问题，用于提升有限可验证prompt下RLVR的性能，显著提升了大模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法依赖大量可验证prompt，但扩展这些数据既成本高、又存在许多信息量低的例子。随着训练，许多prompt变得太容易，减少了有效数据量。如何充分利用现有高通过率prompt成为亟需解决的问题。

Method: 提出了Composition-RL方法：自动将多个通过率为1的已验证prompt组合成一个新问题，并用这些复合prompt继续RL训练。提出了课程化变体，通过逐步增加组合深度进一步提升效果。此外，还可以跨领域组合prompt。

Result: 在4B到30B不同规模模型上的大量实验表明，使用Composition-RL训练的模型推理能力优于仅用原数据集训练的RL模型。课程化变体可以进一步提升性能。此外，跨领域组合提示同样有效。

Conclusion: Composition-RL可以更高效地利用有限的可验证prompt，提升模型的推理能力，尤其在prompt数量有限的情况下非常有效，并为未来扩展RLVR数据提供了有力工具。

Abstract: Large-scale verifiable prompts underpin the success of Reinforcement Learning with Verifiable Rewards (RLVR), but they contain many uninformative examples and are costly to expand further. Recent studies focus on better exploiting limited training data by prioritizing hard prompts whose rollout pass rate is 0. However, easy prompts with a pass rate of 1 also become increasingly prevalent as training progresses, thereby reducing the effective data size. To mitigate this, we propose Composition-RL, a simple yet useful approach for better utilizing limited verifiable prompts targeting pass-rate-1 prompts. More specifically, Composition-RL automatically composes multiple problems into a new verifiable question and uses these compositional prompts for RL training. Extensive experiments across model sizes from 4B to 30B show that Composition-RL consistently improves reasoning capability over RL trained on the original dataset. Performance can be further boosted with a curriculum variant of Composition-RL that gradually increases compositional depth over training. Additionally, Composition-RL enables more effective cross-domain RL by composing prompts drawn from different domains. Codes, datasets, and models are available at https://github.com/XinXU-USTC/Composition-RL.

</details>


### [139] [DeepSight: An All-in-One LM Safety Toolkit](https://arxiv.org/abs/2602.12092)
*Bo Zhang,Jiaxuan Guo,Lijun Li,Dongrui Liu,Sujin Chen,Guanxu Chen,Zhijie Zheng,Qihao Lin,Lewen Yan,Chen Qian,Yijin Zhou,Yuyao Wu,Shaoxiong Guo,Tianyi Du,Jingyi Yang,Xuhao Hu,Ziqi Miao,Xiaoya Lu,Jing Shao,Xia Hu*

Main category: cs.CL

TL;DR: 本文提出了开源项目DeepSight，实现了大模型安全评估与诊断一体化，旨在提升评估的深入性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型(LLMs)和多模态大语言模型(MLLMs)的安全工作流中，安全评估、诊断和对齐往往分散进行，难以深度溯源安全风险，并且缺乏对内部机制变动的专门解释。

Method: 提出DeepSight项目，包括DeepSafe评估工具和DeepScan诊断工具，通过统一任务与数据协议，将安全评估和诊断两个环节结合，实现从黑盒到白盒的模型洞察。

Result: DeepSight实现了低成本、高可复现、效率高、易扩展的模型安全评估方案，是首个支持前沿AI风险评估和评估-诊断一体化的开源工具包。

Conclusion: 通过DeepSight，可以系统性地解决大模型安全评估与诊断脱节的问题，为模型安全机制变动提供专门解释，提升整体的安全管理能力。

Abstract: As the development of Large Models (LMs) progresses rapidly, their safety is also a priority. In current Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) safety workflow, evaluation, diagnosis, and alignment are often handled by separate tools. Specifically, safety evaluation can only locate external behavioral risks but cannot figure out internal root causes. Meanwhile, safety diagnosis often drifts from concrete risk scenarios and remains at the explainable level. In this way, safety alignment lack dedicated explanations of changes in internal mechanisms, potentially degrading general capabilities. To systematically address these issues, we propose an open-source project, namely DeepSight, to practice a new safety evaluation-diagnosis integrated paradigm. DeepSight is low-cost, reproducible, efficient, and highly scalable large-scale model safety evaluation project consisting of a evaluation toolkit DeepSafe and a diagnosis toolkit DeepScan. By unifying task and data protocols, we build a connection between the two stages and transform safety evaluation from black-box to white-box insight. Besides, DeepSight is the first open source toolkit that support the frontier AI risk evaluation and joint safety evaluation and diagnosis.

</details>


### [140] [P-GenRM: Personalized Generative Reward Model with Test-time User-based Scaling](https://arxiv.org/abs/2602.12116)
*Pinyi Zhang,Ting-En Lin,Yuchuan Wu,Jingyang Chen,Zongqi Wang,Hua Yang,Ze Xu,Fei Huang,Kai Zhang,Yongbin Li*

Main category: cs.CL

TL;DR: 本文提出了一种新的个性化奖励模型P-GenRM，能更好适应并泛化用户偏好，性能超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前个性化对齐的大语言模型在奖励信号采集和泛化能力方面存在不足：1）常常简化多样化的用户偏好，2）对新用户反馈有限时泛化不佳。

Method: P-GenRM模型通过结构化评价链将用户偏好转化为适应不同场景的个性化评分机制，并将用户聚类为原型群体。在个体和用户原型两种粒度下，采用动态评分和偏好迁移机制，提升个性化和泛化能力。

Result: 在个性化奖励模型领域的主流基准测试中，P-GenRM取得了平均2.31%的性能提升。对于分布外数据集，模型泛化表现良好。极大地提升了个性化对齐的能力。

Conclusion: P-GenRM克服了传统个性化奖励模型的主要局限，可更好实现基于大语言模型的个性化。测试时的自适应用户缩放机制进一步提升了个性化和可扩展性。

Abstract: Personalized alignment of large language models seeks to adapt responses to individual user preferences, typically via reinforcement learning. A key challenge is obtaining accurate, user-specific reward signals in open-ended scenarios. Existing personalized reward models face two persistent limitations: (1) oversimplifying diverse, scenario-specific preferences into a small, fixed set of evaluation principles, and (2) struggling with generalization to new users with limited feedback. To this end, we propose P-GenRM, the first Personalized Generative Reward Model with test-time user-based scaling. P-GenRM transforms preference signals into structured evaluation chains that derive adaptive personas and scoring rubrics across various scenarios. It further clusters users into User Prototypes and introduces a dual-granularity scaling mechanism: at the individual level, it adaptively scales and aggregates each user's scoring scheme; at the prototype level, it incorporates preferences from similar users. This design mitigates noise in inferred preferences and enhances generalization to unseen users through prototype-based transfer. Empirical results show that P-GenRM achieves state-of-the-art results on widely-used personalized reward model benchmarks, with an average improvement of 2.31%, and demonstrates strong generalization on an out-of-distribution dataset. Notably, Test-time User-based scaling provides an additional 3% boost, demonstrating stronger personalized alignment with test-time scalability.

</details>


### [141] [A Rule-based Computational Model for Gaidhlig Morphology](https://arxiv.org/abs/2602.12132)
*Peter J Barclay*

Main category: cs.CL

TL;DR: 本文提出利用Wiki词典数据，通过规则系统对Gaidhlig语形态进行建模，以应对低资源语言缺乏训练数据的问题。


<details>
  <summary>Details</summary>
Motivation: 当前主流神经网络模型需要大量训练数据，低资源语言如Gaidhlig（苏格兰盖尔语）数据稀缺，现有方法难以适用。

Method: 作者利用Wiki词典数据，采用SQL查询不同词汇模式，构建了基于规则的形态分析模型，并用Python实用工具生成Gaidhlig单词的屈折形式。

Result: 构建了一个声明式规则库及相关工具，不仅提升了Wiki词典数据的应用价值，还能支持教学、解释语言规律以及更高级的工具开发。

Conclusion: 基于规则的系统能有效利用有限样本，具有较好可解释性，有助于低资源语言的研究、教学及工具开发。

Abstract: Language models and software tools are essential to support the continuing vitality of lesser-used languages; however, currently popular neural models require considerable data for training, which normally is not available for such low-resource languages. This paper describes work-in-progress to construct a rule-based model of Gaidhlig morphology using data from Wiktionary, arguing that rule-based systems effectively leverage limited sample data, support greater interpretability, and provide insights useful in the design of teaching materials. The use of SQL for querying the occurrence of different lexical patterns is investigated, and a declarative rule-base is presented that allows Python utilities to derive inflected forms of Gaidhlig words. This functionality could be used to support educational tools that teach or explain language patterns, for example, or to support higher level tools such as rule-based dependency parsers. This approach adds value to the data already present in Wiktionary by adapting it to new use-cases.

</details>


### [142] [WavBench: Benchmarking Reasoning, Colloquialism, and Paralinguistics for End-to-End Spoken Dialogue Models](https://arxiv.org/abs/2602.12135)
*Yangzhuo Li,Shengpeng Ji,Yifu Chen,Tianle Liang,Haorong Ying,Yule Wang,Junbo Li,Jun Fang,Zhou Zhao*

Main category: cs.CL

TL;DR: 该论文提出了WavBench，一个专为评估真实世界语音交互复杂度而设计的新型基准集合，弥补现有评测侧重文本生成、忽视语音特性与推理深度的不足。


<details>
  <summary>Details</summary>
Motivation: 高级推理能力被快速集成到语音对话模型中，但现有评测方法多沿用文本生成标准，未能充分反映真实语音交互中的复杂性，特别是对语音特有的副语言特征和口语化表达的考查，因此需要新型的、更贴近实际场景的测评工具。

Method: 作者提出WavBench基准，将评测范畴分为三个子集：（1）Pro子集，用高难度任务严格检验加强推理能力的模型；（2）Basic子集，侧重测试模型在自然用词、语言流畅性和互动交流方面的口语化表达能力，而非书面准确性；（3）Acoustic子集，从多角度考查模型对副语言特征（如语音语调、情感等）的理解与生成能力。

Result: 使用WavBench对五个前沿语音对话模型进行了评测，获得了关于复杂推理、口语化表达和副语言能力交互表现的关键洞见。

Conclusion: WavBench不仅弥补了现有基准对实际语音对话能力的考查不足，还为今后更强健、更贴近实际的语音对话模型的发展提供了重要指导。

Abstract: With the rapid integration of advanced reasoning capabilities into spoken dialogue models, the field urgently demands benchmarks that transcend simple interactions to address real-world complexity. However, current evaluations predominantly adhere to text-generation standards, overlooking the unique audio-centric characteristics of paralinguistics and colloquialisms, alongside the cognitive depth required by modern agents. To bridge this gap, we introduce WavBench, a comprehensive benchmark designed to evaluate realistic conversational abilities where prior works fall short. Uniquely, WavBench establishes a tripartite framework: 1) Pro subset, designed to rigorously challenge reasoning-enhanced models with significantly increased difficulty; 2) Basic subset, defining a novel standard for spoken colloquialism that prioritizes "listenability" through natural vocabulary, linguistic fluency, and interactive rapport, rather than rigid written accuracy; and 3) Acoustic subset, covering explicit understanding, generation, and implicit dialogue to rigorously evaluate comprehensive paralinguistic capabilities within authentic real-world scenarios. Through evaluating five state-of-the-art models, WavBench offers critical insights into the intersection of complex problem-solving, colloquial delivery, and paralinguistic fidelity, guiding the evolution of robust spoken dialogue models. The benchmark dataset and evaluation toolkit are available at https://naruto-2024.github.io/wavbench.github.io/.

</details>


### [143] [CitiLink-Minutes: A Multilayer Annotated Dataset of Municipal Meeting Minutes](https://arxiv.org/abs/2602.12137)
*Ricardo Campos,Ana Filipa Pacheco,Ana Luísa Fernandes,Inês Cantante,Rute Rebouças,Luís Filipe Cunha,José Miguel Isidro,José Pedro Evans,Miguel Marques,Rodrigo Batista,Evelin Amorim,Alípio Jorge,Nuno Guimarães,Sérgio Nunes,António Leal,Purificação Silvano*

Main category: cs.CL

TL;DR: 本论文介绍了CitiLink-Minutes数据集，这是第一个包含详尽结构化注释的葡萄牙市政会议记录数据集，旨在促进NLP和IR领域对市政会议文档的研究。


<details>
  <summary>Details</summary>
Motivation: 尽管市政会议记录对地方治理和公民生活有重要影响，但受限于缺乏标注数据集，相关的NLP和IR研究十分有限。为解决这一难题，作者开发了一个多层次、结构化的市政会议记录数据集。

Method: 作者收集了来自六个葡萄牙城市共120份市政会议记录，去除个人信息后，由两位注释员和一位语言学家分别从元数据、议题和投票结果三大维度进行人工注释，总计超38,000个注释。该数据集基于FAIR原则发布，并配套了基线模型结果（如元数据抽取、主题分类、投票标注）。

Result: CitiLink-Minutes拥有超过一百万词的文本和多层结构化注释，首次为市政会议NLP与IR任务提供了开源高质量数据。基于该数据集，论文验证了多个基线任务模型的可行性。

Conclusion: CitiLink-Minutes填补了NLP和IR领域在市政会议文档处理上的数据空白，为相关研究和实际应用（如市政决策透明化、自动主题分析等）提供了坚实基础。

Abstract: City councils play a crucial role in local governance, directly influencing citizens' daily lives through decisions made during municipal meetings. These deliberations are formally documented in meeting minutes, which serve as official records of discussions, decisions, and voting outcomes. Despite their importance, municipal meeting records have received little attention in Information Retrieval (IR) and Natural Language Processing (NLP), largely due to the lack of annotated datasets, which ultimately limit the development of computational models. To address this gap, we introduce CitiLink-Minutes, a multilayer dataset of 120 European Portuguese municipal meeting minutes from six municipalities. Unlike prior annotated datasets of parliamentary or video records, CitiLink-Minutes provides multilayer annotations and structured linkage of official written minutes. The dataset contains over one million tokens, with all personal identifiers de-identified. Each minute was manually annotated by two trained annotators and curated by an experienced linguist across three complementary dimensions: (1) metadata, (2) subjects of discussion, and (3) voting outcomes, totaling over 38,000 individual annotations. Released under FAIR principles and accompanied by baseline results on metadata extraction, topic classification, and vote labeling, CitiLink-Minutes demonstrates its potential for downstream NLP and IR tasks, while promoting transparent access to municipal decisions.

</details>


### [144] [dVoting: Fast Voting for dLLMs](https://arxiv.org/abs/2602.12153)
*Sicheng Feng,Zigeng Chen,Xinyin Ma,Gongfan Fang,Xinchao Wang*

Main category: cs.CL

TL;DR: dVoting是一种应用于扩散型大语言模型（dLLMs）的快速投票推理技术，无需额外训练，显著提升了多项基准测试的表现。


<details>
  <summary>Details</summary>
Motivation: 传统自回归模型推理过程效率低下，难以并行化，限制了大语言模型在推理阶段的扩展性。而扩散型大语言模型（dLLMs）可以并行生成任意位置的Token，但如何进一步提升其推理能力仍有待探索。

Method: dVoting基于这样一个发现：同一提示多次采样生成的Token绝大多数是一致的，性能差异主要由少量不一致Token决定。该方法首先通过多次采样识别不确定Token，然后对这些Token进行投票加以重生成，重复该过程直至推理结果收敛，从而提升整体生成质量。

Result: dVoting在GSM8K、MATH500、ARC-C和MMLU等基准任务上均带来稳定表现提升，最高提升达14.84%，且无需模型再训练，计算开销可接受。

Conclusion: dVoting充分利用了dLLMs并行、不定位置生成的优势，有效提升了推理能力，为大语言模型的高效推理带来实际价值。

Abstract: Diffusion Large Language Models (dLLMs) represent a new paradigm beyond autoregressive modeling, offering competitive performance while naturally enabling a flexible decoding process. Specifically, dLLMs can generate tokens at arbitrary positions in parallel, endowing them with significant potential for parallel test-time scaling, which was previously constrained by severe inefficiency in autoregressive modeling. In this work, we introduce dVoting, a fast voting technique that boosts reasoning capability without training, with only an acceptable extra computational overhead. dVoting is motivated by the observation that, across multiple samples for the same prompt, token predictions remain largely consistent, whereas performance is determined by a small subset of tokens exhibiting cross-sample variability. Leveraging the arbitrary-position generation capability of dLLMs, dVoting performs iterative refinement by sampling, identifying uncertain tokens via consistency analysis, regenerating them through voting, and repeating this process until convergence. Extensive evaluations demonstrate that dVoting consistently improves performance across various benchmarks. It achieves gains of 6.22%-7.66% on GSM8K, 4.40%-7.20% on MATH500, 3.16%-14.84% on ARC-C, and 4.83%-5.74% on MMLU. Our code is available at https://github.com/fscdc/dVoting

</details>


### [145] [Query-focused and Memory-aware Reranker for Long Context Processing](https://arxiv.org/abs/2602.12192)
*Yuqing Li,Jiangnan Li,Mo Yu,Guoxuan Ding,Zheng Lin,Weiping Wang,Jie Zhou*

Main category: cs.CL

TL;DR: 提出了一种利用大模型注意力头分数的新型重排序框架，不依赖于Likert标注，轻量高效且在多个领域刷新了SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有的大模型重排序方法多依赖于标签、结构复杂或模型庞大，且需要明确的Likert标注，限制了其泛化与轻量应用。

Method: 通过选择性注意力头的分数，训练模型估算passage-query的相关性，采用listwise方案整体考察候选集，并输出连续相关性分数，无需Likert标注，可适应任意检索数据集。此外，支持灵活扩展，如候选段落上下文增强及中间层注意力头训练。

Result: 在Wikipedia及长篇叙事等多领域大规模实验，优于现有最优pointwise与listwise方法。在LoCoMo对话和记忆能力评测上刷新SOTA；上下文增强与中层头训练均提升效果和效率。

Conclusion: 该框架兼具高效性、灵活性与强性能，丰富了大模型重排序应用，为实际多种检索场景提供了新方法。

Abstract: Built upon the existing analysis of retrieval heads in large language models, we propose an alternative reranking framework that trains models to estimate passage-query relevance using the attention scores of selected heads. This approach provides a listwise solution that leverages holistic information within the entire candidate shortlist during ranking. At the same time, it naturally produces continuous relevance scores, enabling training on arbitrary retrieval datasets without requiring Likert-scale supervision. Our framework is lightweight and effective, requiring only small-scale models (e.g., 4B parameters) to achieve strong performance. Extensive experiments demonstrate that our method outperforms existing state-of-the-art pointwise and listwise rerankers across multiple domains, including Wikipedia and long narrative datasets. It further establishes a new state-of-the-art on the LoCoMo benchmark that assesses the capabilities of dialogue understanding and memory usage. We further demonstrate that our framework supports flexible extensions. For example, augmenting candidate passages with contextual information further improves ranking accuracy, while training attention heads from middle layers enhances efficiency without sacrificing performance.

</details>


### [146] [Visual Reasoning Benchmark: Evaluating Multimodal LLMs on Classroom-Authentic Visual Problems from Primary Education](https://arxiv.org/abs/2602.12196)
*Mohamed Huti,Alasdair Mackintosh,Amy Waldock,Dominic Andrews,Maxime Lelièvre,Moritz Boos,Tobias Murray,Paul Atherton,Robin A. A. Ince,Oliver G. B. Garrod*

Main category: cs.CL

TL;DR: 本文提出了一个用于评估多模态大型语言模型（MLLMs）视觉推理能力的新基准（VRB），针对初等数学中的图形与空间推理，覆盖现实课堂问题，为模型实际教育应用提供参考。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在文本推理上表现突出，但在处理空间与关系结构方面仍有显著瓶颈，尤其是在依赖视觉理解的初等数学教育场景。因此，急需真实、系统地评估MLLMs在视觉推理任务中的实际能力。

Method: 作者基于赞比亚和印度的小学考试，共采集了701道涵盖类比推理、图案补全、空间匹配等任务的问题，构建了VRB基准，并保证题目为未经编辑且文字极少的真实课堂图片，用以测试模型在真实教育场景下的视觉推理水平。

Result: 模型在计数、缩放等静态技能上的表现较好，但在折叠、镜像、旋转等动态空间操作遇到明显瓶颈（即“空间天花板”）。这使得模型在视觉推理问题的课堂实际应用存在错误评分、误导学生、加深学生误解等风险。

Conclusion: 针对教育的视觉推理基准测试对明确多模态工具在实际课堂中能力边界至关重要。VRB为未来改进教育类AI工具性能和可靠性指明了方向。

Abstract: AI models have achieved state-of-the-art results in textual reasoning; however, their ability to reason over spatial and relational structures remains a critical bottleneck -- particularly in early-grade maths, which relies heavily on visuals. This paper introduces the visual reasoning benchmark (VRB), a novel dataset designed to evaluate Multimodal Large Language Models (MLLMs) on their ability to solve authentic visual problems from classrooms. This benchmark is built on a set of 701 questions sourced from primary school examinations in Zambia and India, which cover a range of tasks such as reasoning by analogy, pattern completion, and spatial matching. We outline the methodology and development of the benchmark which intentionally uses unedited, minimal-text images to test if models can meet realistic needs of primary education. Our findings reveal a ``jagged frontier'' of capability where models demonstrate better proficiency in static skills such as counting and scaling, but reach a distinct ``spatial ceiling'' when faced with dynamic operations like folding, reflection, and rotation. These weaknesses pose a risk for classroom use on visual reasoning problems, with the potential for incorrect marking, false scaffolding, and reinforcing student misconceptions. Consequently, education-focused benchmarks like the VRB are essential for determining the functional boundaries of multimodal tools used in classrooms.

</details>


### [147] [ExStrucTiny: A Benchmark for Schema-Variable Structured Information Extraction from Document Images](https://arxiv.org/abs/2602.12203)
*Mathieu Sibue,Andres Muñoz Garza,Samuel Mensah,Pranav Shetty,Zhiqiang Ma,Xiaomo Liu,Manuela Veloso*

Main category: cs.CL

TL;DR: 提出了ExStrucTiny数据集，针对文档图像中的结构化信息抽取，弥补现有基准的不足，并分析了主流VLM模型在该数据集上的表现与挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的文档理解基准（如KEE、RE、VQA）存在实体本体覆盖范围窄、查询过于简单、文档类型单一等问题，难以满足多样化、细粒度和结构化信息抽取的需求。

Method: 作者设计并构建了ExStrucTiny这个新数据集，通过结合人工和合成样本校验的方法，涵盖了更多样的文档类型和抽取场景，并融合了KEE、RE和VQA的特点。

Result: 对开放和封闭源的VLM在ExStrucTiny上的表现进行了系统分析，发现模型在模式适应、查询细化和答案定位等环节均面临较大挑战。

Conclusion: ExStrucTiny为推动通用结构化信息抽取模型的发展提供了统一、具代表性的基准，有助于未来改进VLM在真实企业文档场景下的能力。

Abstract: Enterprise documents, such as forms and reports, embed critical information for downstream applications like data archiving, automated workflows, and analytics. Although generalist Vision Language Models (VLMs) perform well on established document understanding benchmarks, their ability to conduct holistic, fine-grained structured extraction across diverse document types and flexible schemas is not well studied. Existing Key Entity Extraction (KEE), Relation Extraction (RE), and Visual Question Answering (VQA) datasets are limited by narrow entity ontologies, simple queries, or homogeneous document types, often overlooking the need for adaptable and structured extraction. To address these gaps, we introduce ExStrucTiny, a new benchmark dataset for structured Information Extraction (IE) from document images, unifying aspects of KEE, RE, and VQA. Built through a novel pipeline combining manual and synthetic human-validated samples, ExStrucTiny covers more varied document types and extraction scenarios. We analyze open and closed VLMs on this benchmark, highlighting challenges such as schema adaptation, query under-specification, and answer localization. We hope our work provides a bedrock for improving generalist models for structured IE in documents.

</details>


### [148] [Detecting Overflow in Compressed Token Representations for Retrieval-Augmented Generation](https://arxiv.org/abs/2602.12235)
*Julia Belikova,Danila Rozhevskii,Dennis Svirin,Konstantin Polev,Alexander Panchenko*

Main category: cs.CL

TL;DR: 该论文研究了在资源有限环境下，大语言模型长上下文处理中的压缩极限，以及如何检测压缩是否导致关键信息丢失。提出了Token Overflow的概念，并设计了相应的检测手段。


<details>
  <summary>Details</summary>
Motivation: 尽管软压缩可以有效延长上下文处理能力，但压缩是否会造成关键信息缺失尚未被深入研究，需要明确压缩极限和相关检测方法。

Method: 提出Token Overflow概念，针对xRAG软压缩架构，利用饱和度统计和探测分类器进行表示区分和溢出检测，分别采用无关和基于查询的信息判别溢出。

Result: 无关查询的饱和统计方法可区分是否为压缩表示，但溢出检测能力有限。结合查询和上下文的轻量探测器在多个数据集上溢出检测AUC-ROC达0.72。

Conclusion: 该研究表明采用基于查询的信息可显著提升压缩溢出检测能力，有助于在推理前低成本地避免信息丢失问题，为后续模型推理保质保量提供保障。

Abstract: Efficient long-context processing remains a crucial challenge for contemporary large language models (LLMs), especially in resource-constrained environments. Soft compression architectures promise to extend effective context length by replacing long token sequences with smaller sets of learned compressed tokens. Yet, the limits of compressibility -- and when compression begins to erase task-relevant content -- remain underexplored. In this paper, we define \emph{token overflow} as a regime in which compressed representations no longer contain sufficient information to answer a given query, and propose a methodology to characterize and detect it. In the xRAG soft-compression setting, we find that query-agnostic saturation statistics reliably separate compressed from uncompressed token representations, providing a practical tool for identifying compressed tokens but showing limited overflow detection capability. Lightweight probing classifiers over both query and context xRAG representations detect overflow with 0.72 AUC-ROC on average on HotpotQA, SQuADv2, and TriviaQA datasets, demonstrating that incorporating query information improves detection performance. These results advance from query-independent diagnostics to query-aware detectors, enabling low-cost pre-LLM gating to mitigate compression-induced errors.

</details>


### [149] [Moonshine v2: Ergodic Streaming Encoder ASR for Latency-Critical Speech Applications](https://arxiv.org/abs/2602.12241)
*Manjunath Kudlur,Evan King,James Wang,Pete Warden*

Main category: cs.CL

TL;DR: 本文提出了一种名为Moonshine v2的新型流式语音识别模型，通过滑动窗口自注意力机制，显著降低了首个输出标记的时延（TTFT）并减少计算资源需求，同时保证识别准确率。


<details>
  <summary>Details</summary>
Motivation: 现有自动语音识别（ASR）领域中，全注意力Transformer编码器精度高，但其序列长度的二次复杂度和全句延迟特性使得其不适合时延敏感的边缘设备和流式应用。该问题亟需解决，以便能在资源受限场景下实现高效交互式语音应用。

Method: 提出了一种基于滑动窗口自注意力的流式编码器，将注意力限制在局部窗口内，避免了全局注意力的高复杂度和高延迟，允许模型在边处理边输出，降低TTFT。

Result: 在标准ASR基准测试上，该方法取得了当前最优的字错误率表现，模型体积比同精度的全注意力模型缩小6倍，并具备更高的推理速度。

Conclusion: 精心设计的局部自注意力机制能够以更低的计算和延迟成本实现接近全局注意力模型的识别精度，从而推动边缘设备上的实时交互式语音接口发展。

Abstract: Latency-critical speech applications (e.g., live transcription, voice commands, and real-time translation) demand low time-to-first-token (TTFT) and high transcription accuracy, particularly on resource-constrained edge devices. Full-attention Transformer encoders remain a strong accuracy baseline for automatic speech recognition (ASR) because every frame can directly attend to every other frame, which resolves otherwise locally ambiguous acoustics using distant lexical context. However, this global dependency incurs quadratic complexity in sequence length, inducing an inherent "encode-the-whole-utterance" latency profile. For streaming use cases, this causes TTFT to grow linearly with utterance length as the encoder must process the entire prefix before any decoder token can be emitted. To better meet the needs of on-device, streaming ASR use cases we introduce Moonshine v2, an ergodic streaming-encoder ASR model that employs sliding-window self-attention to achieve bounded, low-latency inference while preserving strong local context. Our models achieve state of the art word error rates across standard benchmarks, attaining accuracy on-par with models 6x their size while running significantly faster. These results demonstrate that carefully designed local attention is competitive with the accuracy of full attention at a fraction of the size and latency cost, opening new possibilities for interactive speech interfaces on edge devices.

</details>


### [150] [A technical curriculum on language-oriented artificial intelligence in translation and specialised communication](https://arxiv.org/abs/2602.12251)
*Ralph Krüger*

Main category: cs.CL

TL;DR: 本文提出了面向语言与翻译行业的人工智能技术课程，核心内容涵盖向量嵌入、神经网络基础、分词和Transformer模型，经过实际教学检验，结果显示课程有效，但建议增加更高级别的教学支持。


<details>
  <summary>Details</summary>
Motivation: 随着AI在语言和翻译行业的广泛应用，行业人员缺乏针对性AI技术素养，亟需一套能帮助他们建立AI基础知识和数字韧性的课程。本文因此提出了具备行业针对性的AI课程体系。

Method: 设计了一个包括向量嵌入、神经网络基础、分词与Transformer等模块的技术课程，内容通俗易懂，并将课程应用于科隆应用科技大学翻译与多语种交流学院的AI硕士课程，检验其教学适宜性。

Result: 试点课程表明内容具有很好的教学效果，参与者能够较好地掌握相关AI知识。但也收到参与者反馈，认为课程应在更高层次的教学支持（如讲师引导）下进行，以优化学习效果。

Conclusion: 提出的AI技术课程有助于提高语言与翻译从业者的算法意识和数字韧性，适合行业推广。不过，为取得最佳教学成效，应将课程嵌入更完善的教学支持体系。

Abstract: This paper presents a technical curriculum on language-oriented artificial intelligence (AI) in the language and translation (L&T) industry. The curriculum aims to foster domain-specific technical AI literacy among stakeholders in the fields of translation and specialised communication by exposing them to the conceptual and technical/algorithmic foundations of modern language-oriented AI in an accessible way. The core curriculum focuses on 1) vector embeddings, 2) the technical foundations of neural networks, 3) tokenization and 4) transformer neural networks. It is intended to help users develop computational thinking as well as algorithmic awareness and algorithmic agency, ultimately contributing to their digital resilience in AI-driven work environments. The didactic suitability of the curriculum was tested in an AI-focused MA course at the Institute of Translation and Multilingual Communication at TH Koeln. Results suggest the didactic effectiveness of the curriculum, but participant feedback indicates that it should be embedded into higher-level didactic scaffolding - e.g., in the form of lecturer support - in order to enable optimal learning conditions.

</details>


### [151] [T3D: Few-Step Diffusion Language Models via Trajectory Self-Distillation with Direct Discriminative Optimization](https://arxiv.org/abs/2602.12262)
*Tunyu Zhang,Xinxi Zhang,Ligong Han,Haizhou Shi,Xiaoxiao He,Zhuowei Li,Hao Wang,Kai Xu,Akash Srivastava,Hao Wang,Vladimir Pavlovic,Dimitris N. Metaxas*

Main category: cs.CL

TL;DR: 本文提出了一种改进DLLMs并行解码效率的自蒸馏方法，有效提升了少步生成质量，缩小了与全步生成的差距。


<details>
  <summary>Details</summary>
Motivation: DLLMs理论上支持并行生成多个Token以实现快速文本生成，但实际应用中，由于需要多次优化迭代，推理效率受到限制，而减少步骤会显著降低生成质量。有必要探索提升少步解码性能的方案。

Method: 作者提出了轨迹自蒸馏框架，通过蒸馏模型自身的生成轨迹提高少步解码性能，并引入反KL的直观判别优化（DDO），促使学生模型聚焦于高概率的教师生成模式，实现更高效的模式迁移。

Result: 实验结果显示，所提方法在多个基准任务上，在推理步数受限的条件下，性能优于现有强基线和标准训练方法。虽依然不及全步生成，但已显著缩小性能差距。

Conclusion: 本文提出的方法为DLLMs在实际场景下的高效少步解码提供了有力支持，为实用化奠定了坚实基础。源码已开放。

Abstract: Diffusion large language models (DLLMs) have the potential to enable fast text generation by decoding multiple tokens in parallel. However, in practice, their inference efficiency is constrained by the need for many refinement steps, while aggressively reducing the number of steps leads to a substantial degradation in generation quality. To alleviate this, we propose a trajectory self-distillation framework that improves few-step decoding by distilling the model's own generative trajectories. We incorporate Direct Discriminative Optimization (DDO), a reverse-KL objective that promotes mode-seeking distillation and encourages the student to concentrate on high-probability teacher modes. Across benchmarks, our approach consistently outperforms strong few-step baselines and standard training under tight step budgets. Although full-step decoding remains superior, we substantially narrow the gap, establishing a strong foundation towards practical few-step DLLMs. The source code is available at https://github.com/Tyrion58/T3D.

</details>


### [152] [On-Policy Context Distillation for Language Models](https://arxiv.org/abs/2602.12275)
*Tianzhu Ye,Li Dong,Xun Wu,Shaohan Huang,Furu Wei*

Main category: cs.CL

TL;DR: 该论文提出了一种新的上下文蒸馏方法OPCD，通过让学生模型在自己生成的轨迹上训练，并与上下文条件下的教师模型进行反向KL散度最小化，实现了更有效的知识内化和迁移。实验表明该方法在多个任务上优于基线方法，并支持不同模型规模间的知识蒸馏。


<details>
  <summary>Details</summary>
Motivation: 当前的上下文蒸馏方法使语言模型能够从上下文中学习并将知识内化到参数中，但现有技术在巩固经验知识和提升模型泛化能力方面仍有不足。因此，作者希望设计一种既能更好地利用模型历史经验，又能增强小模型学习大模型知识的新方法。

Method: 提出了On-Policy Context Distillation（OPCD）框架。该方法结合了on-policy蒸馏和上下文蒸馏，即学生模型在自身生成的轨迹基础上训练，并通过最小化与一个上下文驱动教师模型之间的反向KL散度来学习。这种训练方式既保留了历史经验，也内化了优化提示中的行为。

Result: OPCD在数学推理、文本游戏以及特定领域任务中，任务准确率高于基线方法，而且对分布外数据的泛化能力更强。同时，OPCD支持异构模型间的知识提取，实现了小学生模型从大教师模型有效学习经验知识。

Conclusion: OPCD是一种高效且通用的上下文蒸馏方法，能够帮助语言模型更好地吸收历史经验和优良的行为表现，提升任务表现和泛化能力，并促进跨模型尺寸的知识迁移。

Abstract: Context distillation enables language models to internalize in-context knowledge into their parameters. In our work, we propose On-Policy Context Distillation (OPCD), a framework that bridges on-policy distillation with context distillation by training a student model on its own generated trajectories while minimizing reverse Kullback-Leibler divergence against a context-conditioned teacher. We demonstrate the effectiveness of OPCD on two important applications: experiential knowledge distillation, where models extract and consolidate transferable knowledge from their historical solution traces, and system prompt distillation, where models internalize beneficial behaviors encoded in optimized prompts. Across mathematical reasoning, text-based games, and domain-specific tasks, OPCD consistently outperforms baseline methods, achieving higher task accuracy while better preserving out-of-distribution capabilities. We further show that OPCD enables effective cross-size distillation, where smaller student models can internalize experiential knowledge from larger teachers.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [153] [Mitigating Error Accumulation in Continuous Navigation via Memory-Augmented Kalman Filtering](https://arxiv.org/abs/2602.11183)
*Yin Tang,Jiawei Ma,Jinrui Zhang,Alex Jinpeng Wang,Deyu Zhang*

Main category: cs.RO

TL;DR: 提出了一种新的神经网络卡尔曼滤波（NeuroKalman）方法，有效解决了无人机视觉-语言导航中的状态漂移问题，并在仅需少量训练数据微调的情况下优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言导航模型在无人机连续导航中的累积误差（状态漂移）问题明显，导致轨迹预测和实际位置不一致，降低导航性能，因此需要一种能够动态校正导航状态的方法。

Method: 借鉴控制理论，将导航序列预测建模为递归贝叶斯状态估计问题，提出NeuroKalman框架，将导航过程分为基于运动动力学的先验预测和基于历史观测的似然修正。通过将测量似然的核密度估计与基于注意力的历史信息检索机制关联，实现了无需梯度更新的历史锚点校正。

Result: 在TravelUAV基准数据集上实验证明，该方法用仅10%的训练数据进行微调，即显著优于强基线模型，并有效抑制了导航过程中的状态漂移。

Conclusion: NeuroKalman能高效校正无人机视觉-语言导航中的累积状态误差，在导航准确性和数据利用率方面均表现优异，为复杂环境下无人机自主导航提供了更稳健的解决方案。

Abstract: Continuous navigation in complex environments is critical for Unmanned Aerial Vehicle (UAV). However, the existing Vision-Language Navigation (VLN) models follow the dead-reckoning, which iteratively updates its position for the next waypoint prediction, and subsequently construct the complete trajectory. Then, such stepwise manner will inevitably lead to accumulated errors of position over time, resulting in misalignment between internal belief and objective coordinates, which is known as "state drift" and ultimately compromises the full trajectory prediction. Drawing inspiration from classical control theory, we propose to correct for errors by formulating such sequential prediction as a recursive Bayesian state estimation problem. In this paper, we design NeuroKalman, a novel framework that decouples navigation into two complementary processes: a Prior Prediction, based on motion dynamics and a Likelihood Correction, from historical observation. We first mathematically associate Kernel Density Estimation of the measurement likelihood with the attention-based retrieval mechanism, which then allows the system to rectify the latent representation using retrieved historical anchors without gradient updates. Comprehensive experiments on TravelUAV benchmark demonstrate that, with only 10% of the training data fine-tuning, our method clearly outperforms strong baselines and regulates drift accumulation.

</details>


### [154] [H-WM: Robotic Task and Motion Planning Guided by Hierarchical World Model](https://arxiv.org/abs/2602.11291)
*Wenyuan Chen,Jinbang Huang,Oscar Pang,Zhiyuan Li,Xiao Hu,Lingfeng Zhang,Zhanguang Zhang,Mark Coates,Tongtong Cao,Xingyue Quan,Yingxue Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种分层世界模型（H-WM），能够同时进行符号和视觉状态转移预测，有效提升机器人长期任务的规划和执行能力。


<details>
  <summary>Details</summary>
Motivation: 现有世界模型主要关注视频生成或自然语言预测，难以直接与机器人动作关联，且在长期预测时容易出现累积误差；而传统符号逻辑方法虽适合长期推理，但缺乏与视觉感知的同步，限制了实际应用的鲁棒性和泛化能力。

Method: 提出了H-WM分层世界模型，将高层的符号逻辑模型与底层的视觉模型结合，实现统一的双层状态预测。该方法结合符号推理的长期稳定性和视觉观测的感知基础，并通过新构建的对齐机器人动作、符号状态和视觉观测的数据集联合训练。

Result: 在多项基于视觉-语言-动作（VLA）的机器人控制实验中，H-WM方法在任务通用性和长期执行稳定性方面表现优越，有效缓解了长期任务中的误差累积问题。

Conclusion: H-WM方法通过层次化世界模型实现了视觉感知与符号推理的有效整合，为机器人长期任务规划和执行提供了更鲁棒、高效的解决方案，具有良好的推广效果和应用前景。

Abstract: World models are becoming central to robotic planning and control, as they enable prediction of future state transitions. Existing approaches often emphasize video generation or natural language prediction, which are difficult to directly ground in robot actions and suffer from compounding errors over long horizons. Traditional task and motion planning relies on symbolic logic world models, such as planning domains, that are robot-executable and robust for long-horizon reasoning. However, these methods typically operate independently of visual perception, preventing synchronized symbolic and perceptual state prediction. We propose a Hierarchical World Model (H-WM) that jointly predicts logical and visual state transitions within a unified bilevel framework. H-WM combines a high-level logical world model with a low-level visual world model, integrating the robot-executable, long-horizon robustness of symbolic reasoning with perceptual grounding from visual observations. The hierarchical outputs provide stable and consistent intermediate guidance for long-horizon tasks, mitigating error accumulation and enabling robust execution across extended task sequences. To train H-WM, we introduce a robotic dataset that aligns robot motion with symbolic states, actions, and visual observations. Experiments across vision-language-action (VLA) control policies demonstrate the effectiveness and generality of the approach.

</details>


### [155] [ExtremControl: Low-Latency Humanoid Teleoperation with Direct Extremity Control](https://arxiv.org/abs/2602.11321)
*Ziyan Xiong,Lixing Fang,Junyun Huang,Kashu Yamazaki,Hao Zhang,Chuang Gan*

Main category: cs.RO

TL;DR: 该论文提出了一种名为ExtremControl的低延迟全身控制框架，实现了远低于现有方法的人形机器人远程操作系统延迟，大幅提升了响应速度和动态表现。


<details>
  <summary>Details</summary>
Motivation: 目前人形机器人远程操作存在高延迟问题，主要由于动作重定向和传统控制方式，导致系统难以在需要快速反馈和反应的任务中胜任。

Method: 1. 直接在选定的刚体链（主要为人形机器人的四肢）SE(3)位姿上操作，避免全身重定向。2. 使用笛卡尔空间映射，将人体动作直接映射为机器人目标。3. 控制底层引入速度前馈，提高在复杂和变动控制界面下的响应性。

Result: 在仿真和真实环境中系统性地验证了ExtremControl的效果，端到端延迟低至50ms，实测可实现如乒乓球平衡、抛接和实时回击等高度动态和响应性任务，远超以往200ms的延迟。

Conclusion: ExtremControl大幅提升了人形机器人远程操作的低延迟、高响应能力，可适应更多复杂和动态交互的场景，为相关机器人控制系统设计提供了新思路。

Abstract: Building a low-latency humanoid teleoperation system is essential for collecting diverse reactive and dynamic demonstrations. However, existing approaches rely on heavily pre-processed human-to-humanoid motion retargeting and position-only PD control, resulting in substantial latency that severely limits responsiveness and prevents tasks requiring rapid feedback and fast reactions. To address this problem, we propose ExtremControl, a low latency whole-body control framework that: (1) operates directly on SE(3) poses of selected rigid links, primarily humanoid extremities, to avoid full-body retargeting; (2) utilizes a Cartesian-space mapping to directly convert human motion to humanoid link targets; and (3) incorporates velocity feedforward control at low level to support highly responsive behavior under rapidly changing control interfaces. We further provide a unified theoretical formulation of ExtremControl and systematically validate its effectiveness through experiments in both simulation and real-world environments. Building on ExtremControl, we implement a low-latency humanoid teleoperation system that supports both optical motion capture and VR-based motion tracking, achieving end-to-end latency as low as 50ms and enabling highly responsive behaviors such as ping-pong ball balancing, juggling, and real-time return, thereby substantially surpassing the 200ms latency limit observed in prior work.

</details>


### [156] [MolmoSpaces: A Large-Scale Open Ecosystem for Robot Navigation and Manipulation](https://arxiv.org/abs/2602.11337)
*Yejin Kim,Wilbert Pumacay,Omar Rayyan,Max Argus,Winson Han,Eli VanderBilt,Jordi Salvador,Abhay Deshpande,Rose Hendrix,Snehal Jauhri,Shuo Liu,Nur Muhammad Mahi Shafiullah,Maya Guru,Ainaz Eftekhar,Karen Farley,Donovan Clay,Jiafei Duan,Arjun Guru,Piper Wolters,Alvaro Herrasti,Ying-Chun Lee,Georgia Chalvatzaki,Yuchen Cui,Ali Farhadi,Dieter Fox,Ranjay Krishna*

Main category: cs.RO

TL;DR: 本论文提出了MolmoSpaces，这是一个为机器人学习领域打造的大规模开放生态系统，提供了23万多个多样化的仿真室内环境和详尽标注的对象资产，并配套基准测试套件，以促进机器人泛化能力的评估和研究。


<details>
  <summary>Details</summary>
Motivation: 当前机器人研究所用的环境和任务多样性远远无法覆盖现实中的复杂与“长尾”场景，导致现有模型在真实应用中泛化不足，需要更大规模多样化的基准和数据支持更严格的评估。

Method: MolmoSpaces系统构建了23万多种室内环境（包括手工构建和程序生成），集成了13万个详细标注的对象（其中可操作对象4.8万个，稳定抓取姿态高达4200万个），并支持多种主流仿真平台；配套MolmoSpaces-Bench基准测试，设计了8项涉及操纵、导航等不同任务的评估，实现跨平台、跨任务的统一评测。

Result: 实验表明，在MolmoSpaces-Bench上的sim-to-real相关性极高（R=0.96，ρ=0.98），更先进的零样本策略在新基准下显著优于老版模型，分析还揭示了系统对提示词表达、关节初始位置、摄像头遮挡等因素的敏感性。

Conclusion: MolmoSpaces及其开源资源和工具链，为机器人学习领域的规模化数据生成、模型训练及评测基准构建提供了坚实基础，有助于推动机器人在复杂、真实场景下的泛化能力提升和研究进步。

Abstract: Deploying robots at scale demands robustness to the long tail of everyday situations. The countless variations in scene layout, object geometry, and task specifications that characterize real environments are vast and underrepresented in existing robot benchmarks. Measuring this level of generalization requires infrastructure at a scale and diversity that physical evaluation alone cannot provide. We introduce MolmoSpaces, a fully open ecosystem to support large-scale benchmarking of robot policies. MolmoSpaces consists of over 230k diverse indoor environments, ranging from handcrafted household scenes to procedurally generated multiroom houses, populated with 130k richly annotated object assets, including 48k manipulable objects with 42M stable grasps. Crucially, these environments are simulator-agnostic, supporting popular options such as MuJoCo, Isaac, and ManiSkill. The ecosystem supports the full spectrum of embodied tasks: static and mobile manipulation, navigation, and multiroom long-horizon tasks requiring coordinated perception, planning, and interaction across entire indoor environments. We also design MolmoSpaces-Bench, a benchmark suite of 8 tasks in which robots interact with our diverse scenes and richly annotated objects. Our experiments show MolmoSpaces-Bench exhibits strong sim-to-real correlation (R = 0.96, \r{ho} = 0.98), confirm newer and stronger zero-shot policies outperform earlier versions in our benchmarks, and identify key sensitivities to prompt phrasing, initial joint positions, and camera occlusion. Through MolmoSpaces and its open-source assets and tooling, we provide a foundation for scalable data generation, policy training, and benchmark creation for robot learning research.

</details>


### [157] [Human Preference Modeling Using Visual Motion Prediction Improves Robot Skill Learning from Egocentric Human Video](https://arxiv.org/abs/2602.11393)
*Mrinal Verghese,Christopher G. Atkeson*

Main category: cs.RO

TL;DR: 本文提出了一种通过建模人与机器人之间的偏好来从第一视角人类视频中进行机器人学习的方法，相比以往方法在模拟和真实机器人任务中有更好的表现。


<details>
  <summary>Details</summary>
Motivation: 现有从人类视频学习奖励函数的方法存在对状态价值函数的错误假设，并且在人体与机器人间迁移时表现受限。作者希望更准确捕捉人类在操作中的偏好，从而提高机器人学习的效率和泛化能力。

Method: 作者提出通过预测视频中跟踪点的运动，并以机器人的实际动作与该预测的一致性作为奖励信号。此外，结合经过10次实机演示初始化的改进版SAC算法，直接用得到的奖励函数在机器人本体上优化策略。

Result: 该方法在模拟和真实机器人多任务上学习的策略，效果与或优于现有利用视觉状态距离或终态回溯奖赏的方法。

Conclusion: 基于物体运动一致性的奖励建模方法可以更好地捕获人类演示中的动机偏好，提升了从人类视频到实际机器人策略转化的性能，具有较高实际应用价值。

Abstract: We present an approach to robot learning from egocentric human videos by modeling human preferences in a reward function and optimizing robot behavior to maximize this reward. Prior work on reward learning from human videos attempts to measure the long-term value of a visual state as the temporal distance between it and the terminal state in a demonstration video. These approaches make assumptions that limit performance when learning from video. They must also transfer the learned value function across the embodiment and environment gap. Our method models human preferences by learning to predict the motion of tracked points between subsequent images and defines a reward function as the agreement between predicted and observed object motion in a robot's behavior at each step. We then use a modified Soft Actor Critic (SAC) algorithm initialized with 10 on-robot demonstrations to estimate a value function from this reward and optimize a policy that maximizes this value function, all on the robot. Our approach is capable of learning on a real robot, and we show that policies learned with our reward model match or outperform prior work across multiple tasks in both simulation and on the real robot.

</details>


### [158] [EasyMimic: A Low-Cost Framework for Robot Imitation Learning from Human Videos](https://arxiv.org/abs/2602.11464)
*Tao Zhang,Song Xia,Ye Wang,Qin Jin*

Main category: cs.RO

TL;DR: 该论文提出EasyMimic框架，可以让家用低成本机器人通过普通摄像头拍摄的人类演示视频，轻松快速地学习操作任务，减少对昂贵机器人数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有机器人模仿学习依赖大量真实机器人数据，收集代价高，尤其对家用低成本机器人应用造成障碍。需要一种廉价高效的学习方式。

Method: 先用标准RGB摄像头采集人类演示视频，提取3D手部轨迹；通过动作对齐模块将这些轨迹映射到低成本机器人夹持器的控制空间；结合手部视觉增强策略减少人机域差异；使用协同训练方法，在处理过的人类数据和少量机器人数据上微调模型，实现快速适应新任务。

Result: 实验证明该方法可在LeRobot低成本平台上实现多种操作任务，表现良好，显著减少对昂贵机器人数据采集的依赖。

Conclusion: EasyMimic为智能机器人进入家庭提供了一种低成本、实用的学习路径，推动家用机器人普及。

Abstract: Robot imitation learning is often hindered by the high cost of collecting large-scale, real-world data. This challenge is especially significant for low-cost robots designed for home use, as they must be both user-friendly and affordable. To address this, we propose the EasyMimic framework, a low-cost and replicable solution that enables robots to quickly learn manipulation policies from human video demonstrations captured with standard RGB cameras. Our method first extracts 3D hand trajectories from the videos. An action alignment module then maps these trajectories to the gripper control space of a low-cost robot. To bridge the human-to-robot domain gap, we introduce a simple and user-friendly hand visual augmentation strategy. We then use a co-training method, fine-tuning a model on both the processed human data and a small amount of robot data, enabling rapid adaptation to new tasks. Experiments on the low-cost LeRobot platform demonstrate that EasyMimic achieves high performance across various manipulation tasks. It significantly reduces the reliance on expensive robot data collection, offering a practical path for bringing intelligent robots into homes. Project website: https://zt375356.github.io/EasyMimic-Project/.

</details>


### [159] [Effective Task Planning with Missing Objects using Learning-Informed Object Search](https://arxiv.org/abs/2602.11468)
*Raihan Islam Arnob,Max Merlin,Abhishek Paudel,Benned Hedegaard,George Konidaris,Gregory Stein*

Main category: cs.RO

TL;DR: 本论文提出了一种能够在关键对象位置信息未知情况下进行移动机器人任务规划的新方法，通过集成基于模型的学习驱动搜索动作，实现了任务规划与不确定性处理的结合，在仿真和真实场景中均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有移动机器人任务规划（如基于PDDL的方法）通常假设对环境具有完全知识，无法应对关键对象位置未知的场景。虽然学习驱动的对象搜索方法近期取得了进展，但它们难以与完整任务规划器无缝衔接，缺乏灵活的对象需求与检索时机决策能力。

Method: 作者提出了一种新颖的以模型为基础的LIOS（Learning-Informed Object Search）动作，每个动作都是针对单个对象定位和检索的策略。高层次任务规划将LIOS动作视为确定性的，通过模型计算每个动作预期代价，从而生成交替搜索与执行的计划，实现了学习驱动与传统规划的整合，对任务规划中的不确定性进行有效推理。

Result: 在仿真的ProcTHOR家庭环境和真实世界实验中，所提方法在包括物品检索、餐食准备等任务中，表现优于未集成学习和仅使用学习方法的基线。

Conclusion: 本方法结合了任务执行与对象搜索的建模，对环境不确定性有良好适应性，同时与现有全知识规划器兼容，为移动机器人任务规划提供了更为通用和高效的解决方案。

Abstract: Task planning for mobile robots often assumes full environment knowledge and so popular approaches, like planning via the PDDL, cannot plan when the locations of task-critical objects are unknown. Recent learning-driven object search approaches are effective, but operate as standalone tools and so are not straightforwardly incorporated into full task planners, which must additionally determine both what objects are necessary and when in the plan they should be sought out. To address this limitation, we develop a planning framework centered around novel model-based LIOS actions: each a policy that aims to find and retrieve a single object. High-level planning treats LIOS actions as deterministic and so -- informed by model-based calculations of the expected cost of each -- generates plans that interleave search and execution for effective, sound, and complete learning-informed task planning despite uncertainty. Our work effectively reasons about uncertainty while maintaining compatibility with existing full-knowledge solvers. In simulated ProcTHOR homes and in the real world, our approach outperforms non-learned and learned baselines on tasks including retrieval and meal prep.

</details>


### [160] [HyperDet: 3D Object Detection with Hyper 4D Radar Point Clouds](https://arxiv.org/abs/2602.11554)
*Yichun Xiao,Runwei Guan,Fangqiang Ding*

Main category: cs.RO

TL;DR: 提出了HyperDet框架，通过对雷达点云进行多步处理，显著提升了毫米波雷达（4D Radar）在3D目标检测中的表现，使其更好地适用于主流基于LiDAR的检测器。


<details>
  <summary>Details</summary>
Motivation: 毫米波雷达相比激光雷达便宜且抗恶劣天气，但由于数据稀疏且噪声多，其3D检测效果远差LiDAR。如何提升仅用雷达进行3D检测的准确性，是降低自动驾驶与感知系统成本的关键技术难题。

Method: HyperDet对多个环视雷达多帧数据进行聚合，提升点云覆盖度和密度；在传感器重叠外区域做自一致性检查，抑制无效点云；引入基于扩散模型的目标结构强化模块，通过雷达-LiDAR混合监督密集化前景结构，并融入雷达属性。最终蒸馏为单步推理的模型。

Result: HyperDet在MAN TruckScenes数据集上，无论接入VoxelNeXt还是CenterPoint等主流LiDAR检测器，都显著优于原始雷达输入效果，缩小了与LiDAR的性能差距。

Conclusion: 通过输入级的点云精炼，雷达数据可更好地利用LiDAR检测器，无需修改原检测器结构，为雷达替代部分LiDAR在实际自动驾驶应用奠定基础。

Abstract: 4D mmWave radar provides weather-robust, velocity-aware measurements and is more cost-effective than LiDAR. However, radar-only 3D detection still trails LiDAR-based systems because radar point clouds are sparse, irregular, and often corrupted by multipath noise, yielding weak and unstable geometry. We present HyperDet, a detector-agnostic radar-only 3D detection framework that constructs a task-aware hyper 4D radar point cloud for standard LiDAR-oriented detectors. HyperDet aggregates returns from multiple surround-view 4D radars over consecutive frames to improve coverage and density, then applies geometry-aware cross-sensor consensus validation with a lightweight self-consistency check outside overlap regions to suppress inconsistent returns. It further integrates a foreground-focused diffusion module with training-time mixed radar-LiDAR supervision to densify object structures while lifting radar attributes (e.g., Doppler, RCS); the model is distilled into a consistency model for single-step inference. On MAN TruckScenes, HyperDet consistently improves over raw radar inputs with VoxelNeXt and CenterPoint, partially narrowing the radar-LiDAR gap. These results show that input-level refinement enables radar to better leverage LiDAR-oriented detectors without architectural modifications.

</details>


### [161] [ReaDy-Go: Real-to-Sim Dynamic 3D Gaussian Splatting Simulation for Environment-Specific Visual Navigation with Moving Obstacles](https://arxiv.org/abs/2602.11575)
*Seungyeon Yoo,Youngseok Jang,Dabin Kim,Youngsoo Han,Seungwoo Jung,H. Jin Kim*

Main category: cs.RO

TL;DR: 本文提出了一套新的真实到模拟导航仿真管道 ReaDy-Go，以解决现有视觉导航模型在复杂动态现实环境中面临的鲁棒性和泛化能力不足问题。


<details>
  <summary>Details</summary>
Motivation: 传统视觉导航模型在真实动态环境中的适应性和安全性有限，尤其难以有效解决仿真到现实（sim-to-real）差距，以及应对动态障碍物（如移动的人）。现有使用3D Gaussian Splatting（GS）的仿真多用于静态场景，无法满足在如家庭、餐厅、工厂等目标环境中鲁棒导航的实际需求。

Method: 提出ReaDy-Go，包含三个关键部分：（1）动态GS模拟器，将静态GS场景与可动画的人体GS障碍融合，从2D轨迹合成真实的人体动作；（2）基于该模拟器生成动态环境下的仿真导航数据集，利用机器人专家规划器和人类规划器；（3）利用生成的数据集进行导航策略训练，以提升面对动态障碍和仿真到现实转移时的导航鲁棒性。

Result: ReaDy-Go方法在多个模拟和真实目标环境中均超越了现有基线，无论在仿真到现实转移还是面对动态障碍时，导航效果均得到显著提升。同时，在零样本条件下部署至未知环境也展现出良好的泛化潜力。

Conclusion: ReaDy-Go为视觉导航在动态复杂现实环境中的鲁棒性和泛化能力提供了新思路，通过生成更真实且包含动态要素的训练数据，显著提升了仿真到现实导航性能。

Abstract: Visual navigation models often struggle in real-world dynamic environments due to limited robustness to the sim-to-real gap and the difficulty of training policies tailored to target deployment environments (e.g., households, restaurants, and factories). Although real-to-sim navigation simulation using 3D Gaussian Splatting (GS) can mitigate this gap, prior works have assumed only static scenes or unrealistic dynamic obstacles, despite the importance of safe navigation in dynamic environments. To address these issues, we propose ReaDy-Go, a novel real-to-sim simulation pipeline that synthesizes photorealistic dynamic scenarios for target environments. ReaDy-Go generates photorealistic navigation datasets for dynamic environments by combining a reconstructed static GS scene with dynamic human GS obstacles, and trains policies robust to both the sim-to-real gap and moving obstacles. The pipeline consists of three components: (1) a dynamic GS simulator that integrates scene GS with a human animation module, enabling the insertion of animatable human GS avatars and the synthesis of plausible human motions from 2D trajectories, (2) navigation dataset generation for dynamic environments that leverages the simulator, a robot expert planner designed for dynamic GS representations, and a human planner, and (3) policy learning using the generated datasets. ReaDy-Go outperforms baselines across target environments in both simulation and real-world experiments, demonstrating improved navigation performance even after sim-to-real transfer and in the presence of moving obstacles. Moreover, zero-shot sim-to-real deployment in an unseen environment indicates its generalization potential. Project page: https://syeon-yoo.github.io/ready-go-site/.

</details>


### [162] [ABot-N0: Technical Report on the VLA Foundation Model for Versatile Embodied Navigation](https://arxiv.org/abs/2602.11598)
*Zedong Chu,Shichao Xie,Xiaolong Wu,Yanfen Shen,Minghua Luo,Zhengbo Wang,Fei Liu,Xiaoxu Leng,Junjun Hu,Mingyang Yin,Jia Lu,Yingnan Guo,Kai Yang,Jiawei Han,Xu Chen,Yanqing Zhu,Yuxiang Zhao,Xin Liu,Yirong Yang,Ye He,Jiahang Wang,Yang Cai,Tianlin Zhang,Li Gao,Liu Liu,Mingchao Sun,Fan Jiang,Chiyu Wang,Zhicheng Liu,Hongyu Pan,Honglin Han,Zhining Gu,Kuan Yang,Jianfang Zhang,Di Jing,Zihao Guan,Wei Guo,Guoqing Liu,Di Yang,Xiangpo Yang,Menglin Yang,Hongguang Xing,Weiguo Li,Mu Xu*

Main category: cs.RO

TL;DR: 本文提出了一个统一的视觉-语言-动作（VLA）基础模型ABot-N0，实现了对五大主要导航任务的融合，并在多个基准上取得了最新最优表现。


<details>
  <summary>Details</summary>
Motivation: 当前具身导航任务领域存在体系碎片化问题，常用的模型和架构大多是任务专用，缺乏通用性。因此，作者希望构建一个可以在多种导航任务下统一表现出色的通用基础模型。

Method: 作者提出ABot-N0模型，采用“Brain-Action”分层架构：其中基于大语言模型的Cognitive Brain负责语义推理，基于流匹配的Action Expert负责生成精细的连续动作轨迹。为支持大规模学习，作者还开发了ABot-N0 Data Engine，收集和整理了1690万条专家轨迹和500万个推理样本，覆盖7802个高保真3D场景。

Result: ABot-N0在七个基准测评上均取得了新的最优状态（SOTA）成绩，大幅超越了为特定任务设计的专业模型。

Conclusion: ABot-N0作为通用的视觉-语言-动作基础模型，不仅提升了多任务导航性能，还为动态、复杂环境下的长距离自主导航任务提供了坚实基础。

Abstract: Embodied navigation has long been fragmented by task-specific architectures. We introduce ABot-N0, a unified Vision-Language-Action (VLA) foundation model that achieves a ``Grand Unification'' across 5 core tasks: Point-Goal, Object-Goal, Instruction-Following, POI-Goal, and Person-Following. ABot-N0 utilizes a hierarchical ``Brain-Action'' architecture, pairing an LLM-based Cognitive Brain for semantic reasoning with a Flow Matching-based Action Expert for precise, continuous trajectory generation.
  To support large-scale learning, we developed the ABot-N0 Data Engine, curating 16.9M expert trajectories and 5.0M reasoning samples across 7,802 high-fidelity 3D scenes (10.7 $\text{km}^2$). ABot-N0 achieves new SOTA performance across 7 benchmarks, significantly outperforming specialized models. Furthermore, our Agentic Navigation System integrates a planner with hierarchical topological memory, enabling robust, long-horizon missions in dynamic real-world environments.

</details>


### [163] [ViTaS: Visual Tactile Soft Fusion Contrastive Learning for Visuomotor Learning](https://arxiv.org/abs/2602.11643)
*Yufeng Tian,Shuiqi Cheng,Tianming Wei,Tianxing Zhou,Yuanhang Zhang,Zixian Liu,Qianwei Han,Zhecheng Yuan,Huazhe Xu*

Main category: cs.RO

TL;DR: ViTaS提出了一种结合视觉与触觉信息以提升机器人操控能力的新方法，通过更高级的特征融合和对齐策略，显著优于以往方法，尤其在视觉遮挡场景下表现更强。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操控主要关注视觉与触觉特征的简单拼接整合，忽视二者本质的互补性，导致在遮挡等复杂场景下表现不佳，限制了应用潜力。

Method: 提出ViTaS框架，结合Soft Fusion Contrastive Learning（软融合对比学习）和CVAE模块，有效对齐并融合视觉-触觉特征，充分挖掘二者的互补与一致性信息。

Result: 在12个仿真环境和3个真实环境中进行评测，ViTaS在任务表现上均显著优于现有基线方法，尤其在视觉遮挡环境下取得了更高的准确率和鲁棒性。

Conclusion: ViTaS能够更好地利用视觉和触觉信息的互补性及对齐效果，提升机器人在复杂操控任务中的感知能力和执行表现，具备实际应用的前景。

Abstract: Tactile information plays a crucial role in human manipulation tasks and has recently garnered increasing attention in robotic manipulation. However, existing approaches mostly focus on the alignment of visual and tactile features and the integration mechanism tends to be direct concatenation. Consequently, they struggle to effectively cope with occluded scenarios due to neglecting the inherent complementary nature of both modalities and the alignment may not be exploited enough, limiting the potential of their real-world deployment. In this paper, we present ViTaS, a simple yet effective framework that incorporates both visual and tactile information to guide the behavior of an agent. We introduce Soft Fusion Contrastive Learning, an advanced version of conventional contrastive learning method and a CVAE module to utilize the alignment and complementarity within visuo-tactile representations. We demonstrate the effectiveness of our method in 12 simulated and 3 real-world environments, and our experiments show that ViTaS significantly outperforms existing baselines. Project page: https://skyrainwind.github.io/ViTaS/index.html.

</details>


### [164] [Human-Like Gaze Behavior in Social Robots: A Deep Learning Approach Integrating Human and Non-Human Stimuli](https://arxiv.org/abs/2602.11648)
*Faezeh Vahedi,Morteza Memari,Ramtin Tabatabaei,Alireza Taheri*

Main category: cs.RO

TL;DR: 本文通过神经网络模型提升了社交机器人在人类互动中的凝视（gaze）行为模拟，无论面对人类还是非人类刺激，提升了机器人在复杂社交场景下的表现。


<details>
  <summary>Details</summary>
Motivation: 社交机器人在实际交流中需要具备像人类一样的凝视适应能力，并且应能感应人类以外的各类刺激。之前研究多关注人类刺激，对于非人类刺激（诸如物体掉落、开门等）下的凝视响应缺乏研究，因此探讨这一领域具有重要意义。

Method: 作者设计了包括人与非人刺激（对话、指点、开门、物体掉落）的3D虚拟动画和360度实景视频场景，使用VR眼镜采集41名参与者的凝视数据。预处理后，分别采用LSTM与Transformer神经网络模型进行凝视方向预测建模，并对比了不同场景下的模型表现。最后，将模型集成至NAO机器人，通过275名参与者的体验问卷评估系统实际沟通表现。

Result: 在虚拟动画场景下，LSTM模型预测准确率为67.6%，Transformer为70.4%；现实场景中LSTM为72%，Transformer为71.6%。相较之前方法，模型不仅对不同个体具备更优预测精度，而且首次完整考虑非人类刺激。此外，机器人应用效果获得了275名用户的高度满意评价。

Conclusion: 本研究提出的方法显著提高了社交机器人对于复杂社交情境下凝视行为的模仿能力，特别是在识别并响应非人类刺激方面具备独特优势，为未来社交机器人的人机交互能力提供了有效技术路径。

Abstract: Nonverbal behaviors, particularly gaze direction, play a crucial role in enhancing effective communication in social interactions. As social robots increasingly participate in these interactions, they must adapt their gaze based on human activities and remain receptive to all cues, whether human-generated or not, to ensure seamless and effective communication. This study aims to increase the similarity between robot and human gaze behavior across various social situations, including both human and non-human stimuli (e.g., conversations, pointing, door openings, and object drops). A key innovation in this study, is the investigation of gaze responses to non-human stimuli, a critical yet underexplored area in prior research. These scenarios, were simulated in the Unity software as a 3D animation and a 360-degree real-world video. Data on gaze directions from 41 participants were collected via virtual reality (VR) glasses. Preprocessed data, trained two neural networks-LSTM and Transformer-to build predictive models based on individuals' gaze patterns. In the animated scenario, the LSTM and Transformer models achieved prediction accuracies of 67.6% and 70.4%, respectively; In the real-world scenario, the LSTM and Transformer models achieved accuracies of 72% and 71.6%, respectively. Despite the gaze pattern differences among individuals, our models outperform existing approaches in accuracy while uniquely considering non-human stimuli, offering a significant advantage over previous literature. Furthermore, deployed on the NAO robot, the system was evaluated by 275 participants via a comprehensive questionnaire, with results demonstrating high satisfaction during interactions. This work advances social robotics by enabling robots to dynamically mimic human gaze behavior in complex social contexts.

</details>


### [165] [AC-MASAC: An Attentive Curriculum Learning Framework for Heterogeneous UAV Swarm Coordination](https://arxiv.org/abs/2602.11735)
*Wanhao Liu,Junhong Dai,Yixuan Zhang,Shengyun Yin,Panshuo Li*

Main category: cs.RO

TL;DR: 本文提出了一种用于异构无人机集群协同路径规划的智能体注意力课程学习框架AC-MASAC，通过异构注意力机制建模不对称依赖，并结合结构化课程学习缓解稀疏奖励与灾难性遗忘问题，在自定义仿真平台上取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 在多智能体强化学习（MARL）中，实现异构无人机群协同面临智能体间依赖不对称、训练中稀疏奖励与灾难性遗忘等难题，这极大限制了算法的实用性和效果。本文旨在有针对性地提出解决这些实际问题的方法。

Method: 提出了一种带有角色感知异构注意力机制的课程学习框架AC-MASAC。该方法通过注意力机制显式建模智能体间的异构和不对称依赖关系，并设计了分阶段、层次化知识迁移结合比例经验回放的课程策略，以有效缓解稀疏奖励和遗忘问题。

Result: 在自定义的多智能体模拟平台上，所提算法在成功率、队形保持率及加权任务完成时间等指标上均优于多种先进方法，验证了其有效性和优越性。

Conclusion: 本文提出的AC-MASAC框架能够有效应对异构无人机编队中的不对称依赖、稀疏奖励与灾难性遗忘等挑战，大幅提升多智能体路径规划的性能，对实际多无人机协同任务具有积极意义。

Abstract: Cooperative path planning for heterogeneous UAV swarms poses significant challenges for Multi-Agent Reinforcement Learning (MARL), particularly in handling asymmetric inter-agent dependencies and addressing the risks of sparse rewards and catastrophic forgetting during training. To address these issues, this paper proposes an attentive curriculum learning framework (AC-MASAC). The framework introduces a role-aware heterogeneous attention mechanism to explicitly model asymmetric dependencies. Moreover, a structured curriculum strategy is designed, integrating hierarchical knowledge transfer and stage-proportional experience replay to address the issues of sparse rewards and catastrophic forgetting. The proposed framework is validated on a custom multi-agent simulation platform, and the results show that our method has significant advantages over other advanced methods in terms of Success Rate, Formation Keeping Rate, and Success-weighted Mission Time. The code is available at \textcolor{red}{https://github.com/Wanhao-Liu/AC-MASAC}.

</details>


### [166] [HAIC: Humanoid Agile Object Interaction Control via Dynamics-Aware World Model](https://arxiv.org/abs/2602.11758)
*Dongting Li,Xingyu Chen,Qianyang Wu,Bo Chen,Sikai Wu,Hanyu Wu,Guoyao Zhang,Liang Li,Mingliang Zhou,Diyun Xiang,Jianzhu Ma,Qiang Zhang,Renjing Xu*

Main category: cs.RO

TL;DR: 该论文提出了一个新的人形机器人交互框架HAIC，使机器人能在无外部状态估计的情况下，稳健地与多种动力学特性的物体交互，显著提高了完成复杂、动态任务的能力。


<details>
  <summary>Details</summary>
Motivation: 以往的研究多集中于完全驱动且与机器人刚性连接的物体，对于那些具有独立动力学和非完整约束的欠驱动物体（如滑板、小车等）交互，因不可控耦合力和遮挡等问题而控制难度大。因此，需要一种统一方法来解决机器人与不同动力学物体交互时的稳健感知与控制问题，无需额外外部传感器或状态估计。

Method: 作者提出了HAIC框架，核心是通过机器人本体传感器历史信息预测物体高阶状态（速度、加速度），并结合静态几何先验生成动态占据地图，实现空间动态感知。该方法还采用不对称微调技术，通过在线世界模型适应政策分布变化，提升了探索时的状态估计鲁棒性。

Result: 实验证明，采用HAIC后，人形机器人能在多种带独立动力学物体（如滑板、小车负载变化等）的动态任务下表现出高成功率，并在多个物体、多步长任务（如越野搬箱）中展现了优秀的动态预测和补偿能力。

Conclusion: HAIC为人形机器人与环境中多类型物体稳健交互提供了有效思路，无需外部状态估计，实现了更复杂与通用的闭环动态任务，为人形机器人落地实际应用迈进一大步。

Abstract: Humanoid robots show promise for complex whole-body tasks in unstructured environments. Although Human-Object Interaction (HOI) has advanced, most methods focus on fully actuated objects rigidly coupled to the robot, ignoring underactuated objects with independent dynamics and non-holonomic constraints. These introduce control challenges from coupling forces and occlusions. We present HAIC, a unified framework for robust interaction across diverse object dynamics without external state estimation. Our key contribution is a dynamics predictor that estimates high-order object states (velocity, acceleration) solely from proprioceptive history. These predictions are projected onto static geometric priors to form a spatially grounded dynamic occupancy map, enabling the policy to infer collision boundaries and contact affordances in blind spots. We use asymmetric fine-tuning, where a world model continuously adapts to the student policy's exploration, ensuring robust state estimation under distribution shifts. Experiments on a humanoid robot show HAIC achieves high success rates in agile tasks (skateboarding, cart pushing/pulling under various loads) by proactively compensating for inertial perturbations, and also masters multi-object long-horizon tasks like carrying a box across varied terrain by predicting the dynamics of multiple objects.

</details>


### [167] [LAMP: Implicit Language Map for Robot Navigation](https://arxiv.org/abs/2602.11862)
*Sibaek Lee,Hyeonwoo Yu,Giseop Kim,Sunwook Choi*

Main category: cs.RO

TL;DR: 本文提出了LAMP（Language Map）框架，用于高效且精细地支持自然语言驱动的机器人导航，显著提升了内存效率和导航精度。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言导航模型虽可实现零样本导航，但由于需在网格或节点地图上显式存储语言特征，导致随着环境规模增长，内存消耗过大且难以实现高分辨率的路径规划。因此亟需一种可扩展、高效且支持精细化导航的新方法。

Method: LAMP采用隐式神经场对语言特征进行编码，而非在每个位置显式存储。结合稀疏图先进行粗路径规划，再在神经场中利用梯度优化精细地调整终点附近的路径。还引入贝叶斯框架建模特征嵌入的不确定性，并通过图采样策略提升大规模环境的空间覆盖和置信度，减少节点数量和计算开销。

Result: 在NVIDIA Isaac Sim仿真环境和真实多层建筑上的实验显示，LAMP相比现有方法在内存效率和高精度导航成功率均有显著提升。

Conclusion: LAMP框架首次将隐式语言地图和梯度优化引入精细路径生成，极大提升了大环境下自然语言导航的可扩展性和精度，为视觉-语言导航领域带来了新的方法范式。

Abstract: Recent advances in vision-language models have made zero-shot navigation feasible, enabling robots to follow natural language instructions without requiring labeling. However, existing methods that explicitly store language vectors in grid or node-based maps struggle to scale to large environments due to excessive memory requirements and limited resolution for fine-grained planning. We introduce LAMP (Language Map), a novel neural language field-based navigation framework that learns a continuous, language-driven map and directly leverages it for fine-grained path generation. Unlike prior approaches, our method encodes language features as an implicit neural field rather than storing them explicitly at every location. By combining this implicit representation with a sparse graph, LAMP supports efficient coarse path planning and then performs gradient-based optimization in the learned field to refine poses near the goal. This coarse-to-fine pipeline, language-driven, gradient-guided optimization is the first application of an implicit language map for precise path generation. This refinement is particularly effective at selecting goal regions not directly observed by leveraging semantic similarities in the learned feature space. To further enhance robustness, we adopt a Bayesian framework that models embedding uncertainty via the von Mises-Fisher distribution, thereby improving generalization to unobserved regions. To scale to large environments, LAMP employs a graph sampling strategy that prioritizes spatial coverage and embedding confidence, retaining only the most informative nodes and substantially reducing computational overhead. Our experimental results, both in NVIDIA Isaac Sim and on a real multi-floor building, demonstrate that LAMP outperforms existing explicit methods in both memory efficiency and fine-grained goal-reaching accuracy.

</details>


### [168] [Learning to Manipulate Anything: Revealing Data Scaling Laws in Bounding-Box Guided Policies](https://arxiv.org/abs/2602.11885)
*Yihao Wu,Jinming Ma,Junbo Tan,Yanzhao Yu,Shoujie Li,Mingliang Zhou,Diyun Xiang,Xueqian Wang*

Main category: cs.RO

TL;DR: 本文提出通过引入边界框指令（bounding-box instruction），结合全新数据采集设备和算法框架，提升机器人在语义操作任务中的泛化能力。实验验证了新方法优于传统仅使用文本指令的方法，并揭示了数据规模与性能的幂律关系。


<details>
  <summary>Details</summary>
Motivation: 基于扩散模型的机器人决策在处理多样化语义操作任务时泛化能力有限。主要原因是仅依赖文本指令难以在复杂环境下准确指向目标物体。因此，亟需更直接、有效的目标指定方式来提升机器人泛化和适应性。

Method: 作者提出结合边界框指令，设计了Label-UMI手持分割设备及自动标注流水线，方便高效采集带有语义标签的数据。同时，构建了语义-动作解耦（semantic-motion-decoupled）框架，将目标检测与边界框引导下的扩散策略融合，用以改善泛化和适应能力。

Result: 通过大量实际机器人实验，验证了方法在大规模数据集上的有效性，任务成功率提升显著。实验首次系统性揭示了物体数目（数据规模）与泛化性能间存在幂律关系。基于此，总结出一套高效数据采集策略。

Conclusion: 引入边界框指令和自动化标注设备可有效提升机器人语义操作泛化能力，新框架适用于多种任务和物体，实验成功率可达85%。研究为语义操作数据采集和泛化提供了重要参考，相关数据和代码即将开源。

Abstract: Diffusion-based policies show limited generalization in semantic manipulation, posing a key obstacle to the deployment of real-world robots. This limitation arises because relying solely on text instructions is inadequate to direct the policy's attention toward the target object in complex and dynamic environments. To solve this problem, we propose leveraging bounding-box instruction to directly specify target object, and further investigate whether data scaling laws exist in semantic manipulation tasks. Specifically, we design a handheld segmentation device with an automated annotation pipeline, Label-UMI, which enables the efficient collection of demonstration data with semantic labels. We further propose a semantic-motion-decoupled framework that integrates object detection and bounding-box guided diffusion policy to improve generalization and adaptability in semantic manipulation. Throughout extensive real-world experiments on large-scale datasets, we validate the effectiveness of the approach, and reveal a power-law relationship between generalization performance and the number of bounding-box objects. Finally, we summarize an effective data collection strategy for semantic manipulation, which can achieve 85\% success rates across four tasks on both seen and unseen objects. All datasets and code will be released to the community.

</details>


### [169] [General Humanoid Whole-Body Control via Pretraining and Fast Adaptation](https://arxiv.org/abs/2602.11929)
*Zepeng Wang,Jiangxing Wang,Shiqing Yao,Yu Zhang,Ziluo Ding,Ming Yang,Yuxuan Wang,Haobin Jiang,Chao Ma,Xiaochuan Shi,Zongqing Lu*

Main category: cs.RO

TL;DR: 本文提出了FAST框架，有效实现了类人机器人全身控制的快速自适应与稳定运动跟踪，显著提升了在多样动作分布和高动态场景下的平衡与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 类人机器人在面对多样化的动作需求和高动态环境时，如何实现通用、高效且健壮的全身控制仍然是难题。现有方法往往需要针对具体任务训练，且在适应新动作时性能下降、平衡能力有限，阻碍了机器人的广泛应用。

Method: 1. 引入Parseval-Guided Residual Policy Adaptation方法，利用正交约束和KL散度约束，训练轻量级增量动作策略，实现对未见动作的高效适应，减缓遗忘现象。2. 提出CoM-Aware Control策略，将质心相关观测与目标纳入控制过程，强化在复杂参考动作跟踪中的平衡能力。3. 在仿真和实际机器人中进行了广泛实验评估。

Result: FAST框架在多种仿真及真实应用场景中，较现有主流方法表现出更高的动作鲁棒性、更快的适应效率及更强的动作泛化能力。

Conclusion: FAST框架为类人机器人的通用全身控制提供了有效方案，显著提升了其在多变和高要求场景下的稳定性及适应能力。

Abstract: Learning a general whole-body controller for humanoid robots remains challenging due to the diversity of motion distributions, the difficulty of fast adaptation, and the need for robust balance in high-dynamic scenarios. Existing approaches often require task-specific training or suffer from performance degradation when adapting to new motions. In this paper, we present FAST, a general humanoid whole-body control framework that enables Fast Adaptation and Stable Motion Tracking. FAST introduces Parseval-Guided Residual Policy Adaptation, which learns a lightweight delta action policy under orthogonality and KL constraints, enabling efficient adaptation to out-of-distribution motions while mitigating catastrophic forgetting. To further improve physical robustness, we propose Center-of-Mass-Aware Control, which incorporates CoM-related observations and objectives to enhance balance when tracking challenging reference motions. Extensive experiments in simulation and real-world deployment demonstrate that FAST consistently outperforms state-of-the-art baselines in robustness, adaptation efficiency, and generalization.

</details>


### [170] [Robot-DIFT: Distilling Diffusion Features for Geometrically Consistent Visuomotor Control](https://arxiv.org/abs/2602.11934)
*Yu Deng,Yufeng Jin,Xiaogang Jia,Jiahong Xue,Gerhard Neumann,Georgia Chalvatzaki*

Main category: cs.RO

TL;DR: 本文提出Robot-DIFT框架，通过对扩散模型中的几何信息进行流形蒸馏，改善了机器人操作任务中视觉特征表达对控制任务的几何信息敏感性，从而提高了机器人控制精度。


<details>
  <summary>Details</summary>
Motivation: 现有视觉骨干网络多以语义不变性为目标，不利于机器人操作任务所需的几何敏感性，导致基于这些特征的闭环控制效果受限，需要新的视觉特征学习方式以增强几何描述能力。

Method: 作者提出Robot-DIFT框架：首先使用冻住的生成式扩散模型作为“老师”，通过流形蒸馏向确定性的空间-语义特征金字塔网络(S2-FPN)传递几何信息，从而获得兼具丰富几何先验与实时稳定性的视觉特征。

Result: 在大规模DROID数据集上预训练，Robot-DIFT在几何一致性和控制性能上均优于主流判别式视觉特征基线方法。

Conclusion: 模型如何感知世界直接影响其行动能力，Robot-DIFT有效结合生成模型和判别模型的优势，为机器人操作任务中的视觉特征学习提供了新思路、提升了控制精度。

Abstract: We hypothesize that a key bottleneck in generalizable robot manipulation is not solely data scale or policy capacity, but a structural mismatch between current visual backbones and the physical requirements of closed-loop control. While state-of-the-art vision encoders (including those used in VLAs) optimize for semantic invariance to stabilize classification, manipulation typically demands geometric sensitivity the ability to map millimeter-level pose shifts to predictable feature changes. Their discriminative objective creates a "blind spot" for fine-grained control, whereas generative diffusion models inherently encode geometric dependencies within their latent manifolds, encouraging the preservation of dense multi-scale spatial structure. However, directly deploying stochastic diffusion features for control is hindered by stochastic instability, inference latency, and representation drift during fine-tuning. To bridge this gap, we propose Robot-DIFT, a framework that decouples the source of geometric information from the process of inference via Manifold Distillation. By distilling a frozen diffusion teacher into a deterministic Spatial-Semantic Feature Pyramid Network (S2-FPN), we retain the rich geometric priors of the generative model while ensuring temporal stability, real-time execution, and robustness against drift. Pretrained on the large-scale DROID dataset, Robot-DIFT demonstrates superior geometric consistency and control performance compared to leading discriminative baselines, supporting the view that how a model learns to see dictates how well it can learn to act.

</details>


### [171] [Accelerating Robotic Reinforcement Learning with Agent Guidance](https://arxiv.org/abs/2602.11978)
*Haojun Chen,Zili Zou,Chengdong Ma,Yaoxiang Pu,Haotong Zhang,Yuanpei Chen,Yaodong Yang*

Main category: cs.RO

TL;DR: 本文提出了一种新框架AGPS，用多模态智能体代替人类监督者，实现了强化学习在机器人操控中更高效、可扩展、去人工化训练。实验证明在多个任务上该方法优于传统人类参与的RL方法。


<details>
  <summary>Details</summary>
Motivation: 强化学习在机器人实际操控中样本效率低，虽有依靠人类纠正的方法提升效率，但人力监督方式受限于监督比例、操作员疲劳和能力波动，难以扩展。亟需一种自动化且高效的训练方式。

Method: 提出Agent-guided Policy Search (AGPS)框架，用多模态智能体（可看作语义世界模型）替换人类，以执行工具生成更精准的探索引导路径和空间约束，从而剪枝探索空间，引导机器人学习。

Result: 在精准插入、可变形物体操作等任务上，AGPS明显提升了采样效率，并优于传统人类参与方法。

Conclusion: AGPS实现了全自动、高效、可扩展的机器人学习流程，突破了依赖人类监督的局限，是实现机器人规模化自主学习的重要一步。

Abstract: Reinforcement Learning (RL) offers a powerful paradigm for autonomous robots to master generalist manipulation skills through trial-and-error. However, its real-world application is stifled by severe sample inefficiency. Recent Human-in-the-Loop (HIL) methods accelerate training by using human corrections, yet this approach faces a scalability barrier. Reliance on human supervisors imposes a 1:1 supervision ratio that limits fleet expansion, suffers from operator fatigue over extended sessions, and introduces high variance due to inconsistent human proficiency. We present Agent-guided Policy Search (AGPS), a framework that automates the training pipeline by replacing human supervisors with a multimodal agent. Our key insight is that the agent can be viewed as a semantic world model, injecting intrinsic value priors to structure physical exploration. By using executable tools, the agent provides precise guidance via corrective waypoints and spatial constraints for exploration pruning. We validate our approach on two tasks, ranging from precision insertion to deformable object manipulation. Results demonstrate that AGPS outperforms HIL methods in sample efficiency. This automates the supervision pipeline, unlocking the path to labor-free and scalable robot learning. Project website: https://agps-rl.github.io/agps.

</details>


### [172] [Decentralized Multi-Robot Obstacle Detection and Tracking in a Maritime Scenario](https://arxiv.org/abs/2602.12012)
*Muhammad Farhan Ahmed,Vincent Frémont*

Main category: cs.RO

TL;DR: 本论文提出了一种多无人机与水面无人艇协作的分布式机器人系统，可以实现对海上漂浮集装箱的检测与跟踪，并提升了感知鲁棒性与目标分配效率。


<details>
  <summary>Details</summary>
Motivation: 海上环境下的反射水面对目标感知带来很大挑战，同时多机器人协作还需要在通信受限的条件下实现高效协调与监测。本研究旨在解决这些核心难题，提升系统在实际海事监测中的部署可靠性。

Method: 提出一个去中心化的多机器人框架。各无人机通过YOLOv8和立体视觉检测集装箱，利用每目标扩展卡尔曼滤波器跟踪目标并联合不确定性感知进行信息关联。各机器人间交换经过压缩的目标跟踪信息，并利用协方差交集方法融合，保证一致性。分配模块基于信息增益和安全/能耗考量优化无人机分工和位置选择。

Result: 仿真结果表明，该系统在海事场景下实现了更好的目标覆盖率、更高的定位精度和更一致的跟踪表现，同时对通信带宽的需求较低。

Conclusion: 所提出的多机器人去中心框架能够有效提升海事监测的感知鲁棒性和系统协同效率，并适应实际环境中的通信与安全限制。

Abstract: Autonomous aerial-surface robot teams are promising for maritime monitoring. Robust deployment requires reliable perception over reflective water and scalable coordination under limited communication. We present a decentralized multi-robot framework for detecting and tracking floating containers using multiple UAVs cooperating with an autonomous surface vessel. Each UAV performs YOLOv8 and stereo-disparity-based visual detection, then tracks targets with per-object EKFs using uncertainty-aware data association. Compact track summaries are exchanged and fused conservatively via covariance intersection, ensuring consistency under unknown correlations. An information-driven assignment module allocates targets and selects UAV hover viewpoints by trading expected uncertainty reduction against travel effort and safety separation. Simulation results in a maritime scenario demonstrate improved coverage, localization accuracy, and tracking consistency while maintaining modest communication requirements.

</details>


### [173] [Adaptive-Horizon Conflict-Based Search for Closed-Loop Multi-Agent Path Finding](https://arxiv.org/abs/2602.12024)
*Jiarui Li,Federico Pecora,Runyu Zhang,Gioele Zardini*

Main category: cs.RO

TL;DR: 本文提出了一种新型多智能体路径规划（MAPF）算法ACCBS，结合了有限时域规划和约束树复用，兼具鲁棒性、性能保证与渐进最优特性。


<details>
  <summary>Details</summary>
Motivation: 现有MAPF方法要么是开环规划，难以应对动态扰动，要么是闭环启发式，但缺乏性能保证，不适合安全关键场合。因此，需要兼顾鲁棒性和性能保证的新方法。

Method: 提出ACCBS算法，基于有限时域变体的CBS算法，借鉴MPC中的迭代加深自适应地调整规划时域，并复用单一的约束树以便在不同时域之间高效切换。

Result: ACCBS能快速生成高质量可行解，随着算力预算增加，表现出anytime属性和渐进最优。大量案例分析验证了其对扰动的灵活应对和性能保证。

Conclusion: ACCBS有效弥合了理论最优性与实际鲁棒性之间的鸿沟，为大规模机器人部署提供了可行的新途径。

Abstract: MAPF is a core coordination problem for large robot fleets in automated warehouses and logistics. Existing approaches are typically either open-loop planners, which generate fixed trajectories and struggle to handle disturbances, or closed-loop heuristics without reliable performance guarantees, limiting their use in safety-critical deployments. This paper presents ACCBS, a closed-loop algorithm built on a finite-horizon variant of CBS with a horizon-changing mechanism inspired by iterative deepening in MPC. ACCBS dynamically adjusts the planning horizon based on the available computational budget, and reuses a single constraint tree to enable seamless transitions between horizons. As a result, it produces high-quality feasible solutions quickly while being asymptotically optimal as the budget increases, exhibiting anytime behavior. Extensive case studies demonstrate that ACCBS combines flexibility to disturbances with strong performance guarantees, effectively bridging the gap between theoretical optimality and practical robustness for large-scale robot deployment.

</details>


### [174] [When would Vision-Proprioception Policies Fail in Robotic Manipulation?](https://arxiv.org/abs/2602.12032)
*Jingxian Lu,Wenke Xia,Yuxuan Wu,Zhiwu Lu,Di Hu*

Main category: cs.RO

TL;DR: 本文通过实验分析视觉-本体感知联合策略在机器人操作任务中的泛化能力，并提出了一种自适应梯度调整算法GAP来提高视觉和本体感知的协同效果。


<details>
  <summary>Details</summary>
Motivation: 视觉信息与本体感知信息的结合被认为有望提升机器人在复杂操作任务中的性能，但近期相关研究对此类联合策略的泛化能力呈现出不一致的实验结果。为解决该问题，需要深入理解二者在策略学习中的具体作用及优化动态。

Method: 作者通过时序控制的实验分析，发现在机器人运动转换等关键阶段，联合策略更依赖本体感知信息，导致视觉信息学习受抑。为此，提出基于阶段引导的梯度调整算法（GAP），通过本体感知信号估算运动转换阶段概率，并在训练过程中对本体感知梯度做细粒度抑制，以促进视觉与本体感知的动态协同。

Result: 大量实验证明GAP算法在模拟及真实环境中、单臂和双臂机器人平台，以及传统与视觉-语言-动作模型等多种设置下均表现优异，能获得更强的泛化能力和鲁棒性。

Conclusion: 视觉-本体感知策略在运动转换阶段趋向本体信号，抑制视觉信息学习。GAP算法通过动态调节本体感知优化过程，有效提升了联合策略的协同与泛化能力，为后续机器人多模态策略研究提供了重要思路。

Abstract: Proprioceptive information is critical for precise servo control by providing real-time robotic states. Its collaboration with vision is highly expected to enhance performances of the manipulation policy in complex tasks. However, recent studies have reported inconsistent observations on the generalization of vision-proprioception policies. In this work, we investigate this by conducting temporally controlled experiments. We found that during task sub-phases that robot's motion transitions, which require target localization, the vision modality of the vision-proprioception policy plays a limited role. Further analysis reveals that the policy naturally gravitates toward concise proprioceptive signals that offer faster loss reduction when training, thereby dominating the optimization and suppressing the learning of the visual modality during motion-transition phases. To alleviate this, we propose the Gradient Adjustment with Phase-guidance (GAP) algorithm that adaptively modulates the optimization of proprioception, enabling dynamic collaboration within the vision-proprioception policy. Specifically, we leverage proprioception to capture robotic states and estimate the probability of each timestep in the trajectory belonging to motion-transition phases. During policy learning, we apply fine-grained adjustment that reduces the magnitude of proprioception's gradient based on estimated probabilities, leading to robust and generalizable vision-proprioception policies. The comprehensive experiments demonstrate GAP is applicable in both simulated and real-world environments, across one-arm and dual-arm setups, and compatible with both conventional and Vision-Language-Action models. We believe this work can offer valuable insights into the development of vision-proprioception policies in robotic manipulation.

</details>


### [175] [Safety Beyond the Training Data: Robust Out-of-Distribution MPC via Conformalized System Level Synthesis](https://arxiv.org/abs/2602.12047)
*Anutam Srinivasan,Antoine Leeman,Glen Chou*

Main category: cs.RO

TL;DR: 本文提出一种结合保序预测（CP）和系统级合成（SLS）的新框架，实现了超出训练分布范围的模型鲁棒规划与控制，兼顾安全性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的动力学模型在分布外情形下存在安全与鲁棒性挑战，因此急需一种方法提升模型在未知或新情境下的可靠性。

Method: （1）通过带权保序预测与协方差模型联合估计状态-控制相关的高置信模型误差界；（2）将此误差界嵌入SLS驱动的鲁棒非线性模型预测控制（MPC）中，利用体积最优化的可达集进行约束收缩。（3）理论上保证在分布漂移条件下的覆盖率与鲁棒性，并分析数据密度和轨迹束宽度对覆盖性的影响。

Result: 实证结果表明，本方法在多种非线性系统（如4维小车和12维四旋翼）上显著提升了安全性与鲁棒性，特别是在分布外测试时，相较于固定误差界和非鲁棒基线方法优势明显。

Conclusion: 所提方法有效提升了基于学习的控制系统在未知环境下的安全性和鲁棒性，为分布外模型规划与控制提供了理论和实证支持。

Abstract: We present a novel framework for robust out-of-distribution planning and control using conformal prediction (CP) and system level synthesis (SLS), addressing the challenge of ensuring safety and robustness when using learned dynamics models beyond the training data distribution. We first derive high-confidence model error bounds using weighted CP with a learned, state-control-dependent covariance model. These bounds are integrated into an SLS-based robust nonlinear model predictive control (MPC) formulation, which performs constraint tightening over the prediction horizon via volume-optimized forward reachable sets. We provide theoretical guarantees on coverage and robustness under distributional drift, and analyze the impact of data density and trajectory tube size on prediction coverage. Empirically, we demonstrate our method on nonlinear systems of increasing complexity, including a 4D car and a {12D} quadcopter, improving safety and robustness compared to fixed-bound and non-robust baselines, especially outside of the data distribution.

</details>


### [176] [HoloBrain-0 Technical Report](https://arxiv.org/abs/2602.12062)
*Xuewu Lin,Tianwei Lin,Yun Du,Hongyu Xie,Yiwei Jin,Jiawei Li,Shijie Wu,Qingze Wang,Mengdi Li,Mengao Zhao,Ziang Li,Chaodong Huang,Hongzhe Bi,Lichao Huang,Zhizhong Su*

Main category: cs.RO

TL;DR: 提出了HoloBrain-0，一个集视觉-语言-动作于一体的机器人基础框架，针对3D空间推理和多样化实体适应进行了优化，并实现了高效、可扩展且可开源的全套生态系统。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型与真实机器人部署之间存在鸿沟，尤其在3D空间理解和实际操作中。急需一个能够高效、可泛化的VLA（视觉-语言-动作）框架，适应不同机器人形态，降低实际部署门槛，提高研究复现性。

Method: 核心方法为引入机器人实体先验（如多视角相机参数和机器人运动学描述URDF）到新VLA架构中，采用“预训练-后训练”范式，提升3D空间推理及多实体适应能力。实验覆盖多种仿真和真实任务。

Result: 在RoboTwin 2.0、LIBERO和GenieSim等仿真基准和长时序现实操作任务上都实现了SOTA表现。0.2B参数的高效模型性能接近大规模基线，并具备低延迟实际部署能力。

Conclusion: HoloBrain-0及其全套开源生态系统（包含VLA模型、后训练模型及数据-训练-部署基础设施）为机器人领域提供高性能、可复现的标准化操作路径，有望加速机器人自主操作的研究与应用落地。

Abstract: In this work, we introduce HoloBrain-0, a comprehensive Vision-Language-Action (VLA) framework that bridges the gap between foundation model research and reliable real-world robot deployment. The core of our system is a novel VLA architecture that explicitly incorporates robot embodiment priors, including multi-view camera parameters and kinematic descriptions (URDF), to enhance 3D spatial reasoning and support diverse embodiments. We validate this design through a scalable ``pre-train then post-train" paradigm, achieving state-of-the-art results on simulation benchmarks such as RoboTwin 2.0, LIBERO, and GenieSim, as well as strong results on challenging long-horizon real-world manipulation tasks. Notably, our efficient 0.2B-parameter variant rivals significantly larger baselines, enabling low-latency on-device deployment. To further accelerate research and practical adoption, we fully open-source the entire HoloBrain ecosystem, which includes: (1) powerful pre-trained VLA foundations; (2) post-trained checkpoints for multiple simulation suites and real-world tasks; and (3) RoboOrchard, a full-stack VLA infrastructure for data curation, model training and deployment. Together with standardized data collection protocols, this release provides the community with a complete, reproducible path toward high-performance robotic manipulation.

</details>


### [177] [VLAW: Iterative Co-Improvement of Vision-Language-Action Policy and World Model](https://arxiv.org/abs/2602.12063)
*Yanjiang Guo,Tony Lee,Lucy Xiaoyang Shi,Jianyu Chen,Percy Liang,Chelsea Finn*

Main category: cs.RO

TL;DR: 本论文提出通过使用基于动作的视频生成模拟器，并结合迭代的真实数据，提升视觉-语言-动作模型的性能和可靠性。


<details>
  <summary>Details</summary>
Motivation: 收集机器人策略的实际操作数据代价高昂，现有的世界模型对复杂物理交互的建模能力不足，尤其在物体操控中的失败案例和细节建模方面存在明显短板。需要一种高效方法以低成本获得高物理保真度的训练数据。

Method: 作者提出一种简单的迭代改进算法：利用真实世界的策略执行数据迭代优化动作条件视频生成模型，然后用该改进的模拟器生成合成数据以进一步训练和提升VLA模型。

Result: 在真实机器人实验中，提出方法显著提升了VLA基础策略的绝对成功率39.2%，并通过生成的合成数据进一步提升了11.6%。

Conclusion: 结合真实数据改进世界模型，然后用高保真模拟数据辅助训练VLA模型，可有效提升其实际任务表现，这种方法具备实际可推广性。

Abstract: The goal of this paper is to improve the performance and reliability of vision-language-action (VLA) models through iterative online interaction. Since collecting policy rollouts in the real world is expensive, we investigate whether a learned simulator-specifically, an action-conditioned video generation model-can be used to generate additional rollout data. Unfortunately, existing world models lack the physical fidelity necessary for policy improvement: they are predominantly trained on demonstration datasets that lack coverage of many different physical interactions (particularly failure cases) and struggle to accurately model small yet critical physical details in contact-rich object manipulation. We propose a simple iterative improvement algorithm that uses real-world roll-out data to improve the fidelity of the world model, which can then, in turn, be used to generate supplemental synthetic data for improving the VLA model. In our experiments on a real robot, we use this approach to improve the performance of a state-of-the-art VLA model on multiple downstream tasks. We achieve a 39.2% absolute success rate improvement over the base policy and 11.6% improvement from training with the generated synthetic rollouts. Videos can be found at this anonymous website: https://sites.google.com/view/vla-w

</details>


### [178] [Affordance-Graphed Task Worlds: Self-Evolving Task Generation for Scalable Embodied Learning](https://arxiv.org/abs/2602.12065)
*Xiang Liu,Sen Cui,Guocai Yao,Zhong Cao,Jingheng Ma,Min Zhang,Changshui Zhang*

Main category: cs.RO

TL;DR: 本文提出一种新框架AGT-World，能结合视觉-语言模型和几何信息，自动构建模拟环境和任务，实现机器人策略自改进，在复杂任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前在现实世界直接训练机器人策略成本极高且难以扩展。虽有模拟数据辅助，但现有生成式模拟难以生成连贯长任务，并在动态环境下效果不佳。

Method: 提出AGT-World框架，将任务空间形式化为结构化图，实现目标的分解与原子动作生成。创新性地引入“自进化”机制，结合视觉-语言模型推理与几何校验混合反馈，实现策略的自主改进。

Result: 大量实验证明该方法在任务完成率、泛化性等方面均显著优于现有方法，实现了自动化、高效的机器人学习自改进循环。

Conclusion: AGT-World突破了现有任务生成及策略学习的局限，实现机器人大规模自适应学习，是推动机器人智能发展的重要进步。

Abstract: Training robotic policies directly in the real world is expensive and unscalable. Although generative simulation enables large-scale data synthesis, current approaches often fail to generate logically coherent long-horizon tasks and struggle with dynamic physical uncertainties due to open-loop execution. To address these challenges, we propose Affordance-Graphed Task Worlds (AGT-World), a unified framework that autonomously constructs interactive simulated environments and corresponding robot task policies based on real-world observations. Unlike methods relying on random proposals or static replication, AGT-World formalizes the task space as a structured graph, enabling the precise, hierarchical decomposition of complex goals into theoretically grounded atomic primitives. Furthermore, we introduce a Self-Evolution mechanism with hybrid feedback to autonomously refine policies, combining Vision-Language Model reasoning and geometric verification. Extensive experiments demonstrate that our method significantly outperforms in success rates and generalization, achieving a self-improving cycle of proposal, execution, and correction for scalable robot learning.

</details>


### [179] [RF-Modulated Adaptive Communication Improves Multi-Agent Robotic Exploration](https://arxiv.org/abs/2602.12074)
*Lorin Achey,Breanne Crockett,Christoffer Heckman,Bradley Hayes*

Main category: cs.RO

TL;DR: 本文提出了ART自适应RF传输算法，通过根据信号强度和数据负载动态调整传输位置，使多机器人系统在通信受限环境下更高效地共享信息，减少不必要的回撤，实现更高效的覆盖和探索。实验证明，相较于现有方法，该算法明显提升了探索速度与效率。


<details>
  <summary>Details</summary>
Motivation: 多机器人自主探索在受限通信环境下面临信息共享效率低和协调困难等挑战。传统方法如全体会合或最小信号启发式，存在效率低下、路径浪费等问题，影响复杂环境（如行星探测、灾后救援）下的探索表现。

Method: 提出ART算法，结合信号强度和数据负载，自适应调节各机器人信息传输的地点，减少无效回撤。进一步提出ART-SST扩展，设置信号强度阈值，保证大数据高保真传输。通过480多组仿真，对比各类基线方法，在不同洞穴环境中评估算法表现。

Result: ART算法在三种仿真环境下表现突出：与基线（全体会合、最小信号启发式）相比，平均可减少58%的总通行距离，提升52%的探索速度。ART-SST在大数据高保真传输场景下同样优于其他方法。

Conclusion: 自适应、负载感知的通信策略能显著提升多机器人在通信受限复杂环境中的覆盖效率和任务速度，为未来行星探索和搜救任务奠定了坚实基础。

Abstract: Reliable coordination and efficient communication are critical challenges for multi-agent robotic exploration of environments where communication is limited. This work introduces Adaptive-RF Transmission (ART), a novel communication-aware planning algorithm that dynamically modulates transmission location based on signal strength and data payload size, enabling heterogeneous robot teams to share information efficiently without unnecessary backtracking. We further explore an extension to this approach called ART-SST, which enforces signal strength thresholds for high-fidelity data delivery. Through over 480 simulations across three cave-inspired environments, ART consistently outperforms existing strategies, including full rendezvous and minimum-signal heuristic approaches, achieving up to a 58% reduction in distance traveled and up to 52% faster exploration times compared to baseline methods. These results demonstrate that adaptive, payload-aware communication significantly improves coverage efficiency and mission speed in complex, communication-constrained environments, offering a promising foundation for future planetary exploration and search-and-rescue missions.

</details>


### [180] [Pack it in: Packing into Partially Filled Containers Through Contact](https://arxiv.org/abs/2602.12095)
*David Russell,Zisong Xu,Maximo A. Roa,Mehmet Dogar*

Main category: cs.RO

TL;DR: 本论文提出了一种结合感知和物理推理的智能仓库填充方法，通过允许新物品与已存在物品进行接触与推动，从而优化已有物品的空间利用，实现高效、智能的自动化物品放置。


<details>
  <summary>Details</summary>
Motivation: 传统的自动化仓库物品摆放（bin-packing）主要假设容器为空且追求无碰撞摆放策略，但实际中容器经常部分填充且物品分布不理想，难以充分利用空间。因此，需要一种能应对现实复杂场景、提升填充效率的新方法。

Method: 提出了一种“接触感知”填充方法，即利用机器人操作新物品与已置物品发生有目的的接触或移动，通过物理交互腾出空间。核心为基于接触的多物体轨迹优化器，集成在模型预测控制器中，并辅以具备遮挡情况下姿态估计能力的感知系统，以及建议物理可行摆放位置的算法。

Result: 实验表明，该系统能够有效在已有物品排列不理想的容器中腾出更多空间，实现比传统无碰撞策略更高的填充率，并能安全、精准地完成复杂的自动放置任务。

Conclusion: 本方法突破了传统无碰撞思路的局限，为仓库自动化装箱和智能物流系统提供了更贴合实际、效率更高的解决方案。

Abstract: The automation of warehouse operations is crucial for improving productivity and reducing human exposure to hazardous environments. One operation frequently performed in warehouses is bin-packing where items need to be placed into containers, either for delivery to a customer, or for temporary storage in the warehouse. Whilst prior bin-packing works have largely been focused on packing items into empty containers and have adopted collision-free strategies, it is often the case that containers will already be partially filled with items, often in suboptimal arrangements due to transportation about a warehouse. This paper presents a contact-aware packing approach that exploits purposeful interactions with previously placed objects to create free space and enable successful placement of new items. This is achieved by using a contact-based multi-object trajectory optimizer within a model predictive controller, integrated with a physics-aware perception system that estimates object poses even during inevitable occlusions, and a method that suggests physically-feasible locations to place the object inside the container.

</details>


### [181] [Multi Graph Search for High-Dimensional Robot Motion Planning](https://arxiv.org/abs/2602.12096)
*Itamar Mishani,Maxim Likhachev*

Main category: cs.RO

TL;DR: 该论文提出了一种新型基于搜索的运动规划算法——Multi-Graph Search (MGS)，通过在状态空间中同时扩展和合并多个隐式图，提高了高维机器人系统的运动规划效率，并保证搜索完整性和次优性。实验结果验证了该方法在多种操作任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 高维机器人的高效运动规划对实时性和可靠性应用至关重要。虽然已有规划算法提升了大规模状态空间的可扩展性，但经常导致计算资源消耗过大、动作不可预期或不一致。为解决此问题，研究需要兼顾效率、动作一致性与计算资源消耗。

Method: 论文提出MGS算法，突破性地将经典的单向和双向搜索推广为多图搜索。MGS在状态空间内维护并扩展多个隐式图，将探索集中于高潜力区域，并通过可行的过渡逐步合并最初不连通的子图。理论上证明了其搜索完整性和次优界限。

Result: 实验证明MGS在多类型操作机器人任务（如操作与移动操作任务）中具备高效性和稳定性。与传统方法对比，MGS显示了更好的动作连贯性和计算效率。

Conclusion: MGS是一种鲁棒且高效的高维运动规划方法，兼具理论保证和良好实际表现，为高维机器人系统的实际部署提供了更优解决方案。

Abstract: Efficient motion planning for high-dimensional robotic systems, such as manipulators and mobile manipulators, is critical for real-time operation and reliable deployment. Although advances in planning algorithms have enhanced scalability to high-dimensional state spaces, these improvements often come at the cost of generating unpredictable, inconsistent motions or requiring excessive computational resources and memory. In this work, we introduce Multi-Graph Search (MGS), a search-based motion planning algorithm that generalizes classical unidirectional and bidirectional search to a multi-graph setting. MGS maintains and incrementally expands multiple implicit graphs over the state space, focusing exploration on high-potential regions while allowing initially disconnected subgraphs to be merged through feasible transitions as the search progresses. We prove that MGS is complete and bounded-suboptimal, and empirically demonstrate its effectiveness on a range of manipulation and mobile manipulation tasks. Demonstrations, benchmarks and code are available at https://multi-graph-search.github.io/.

</details>


### [182] [3DGSNav: Enhancing Vision-Language Model Reasoning for Object Navigation via Active 3D Gaussian Splatting](https://arxiv.org/abs/2602.12159)
*Wancai Zheng,Hao Chen,Xianlong Lu,Linlin Ou,Xinyi Yu*

Main category: cs.RO

TL;DR: 该论文提出3DGSNav方法，将3D高斯投影(3DGS)作为视觉-语言模型(VLM)的持久记忆，用于增强零样本目标导航(ZSON)能力，实现了在未知环境下高效、可靠的目标物体定位。


<details>
  <summary>Details</summary>
Motivation: 现有ZSON方法往往依赖于语义地图或文本化环境，但其高层决策极易受制于底层感知精度，难以灵活应对新环境。为提升空间推理能力，急需更稳健的环境建模与推理机制。

Method: 3DGSNav结合3D高斯投影和VLM，将环境持续建模成可视化3DGS记忆，通过主动感知实现增量式建图，并结合结构化视觉提示及思维链(CoT)提示，增强视觉-语言推理。在导航过程中，实时物体检测器筛选潜在目标，VLM驱动的视点切换进行目标复核，从而提升识别效率与可靠性。

Result: 在多个基准测试和真实四足机器人平台上，3DGSNav展示出稳健且具有竞争力的导航性能，优于多种现有方法。

Conclusion: 采用3DGS和VLM结合的新框架，能够突破传统ZSON依赖低层语义感知的瓶颈，极大增强了空间推理与目标识别能力，是推动智能体目标导航实用化的重要进展。

Abstract: Object navigation is a core capability of embodied intelligence, enabling an agent to locate target objects in unknown environments. Recent advances in vision-language models (VLMs) have facilitated zero-shot object navigation (ZSON). However, existing methods often rely on scene abstractions that convert environments into semantic maps or textual representations, causing high-level decision making to be constrained by the accuracy of low-level perception. In this work, we present 3DGSNav, a novel ZSON framework that embeds 3D Gaussian Splatting (3DGS) as persistent memory for VLMs to enhance spatial reasoning. Through active perception, 3DGSNav incrementally constructs a 3DGS representation of the environment, enabling trajectory-guided free-viewpoint rendering of frontier-aware first-person views. Moreover, we design structured visual prompts and integrate them with Chain-of-Thought (CoT) prompting to further improve VLM reasoning. During navigation, a real-time object detector filters potential targets, while VLM-driven active viewpoint switching performs target re-verification, ensuring efficient and reliable recognition. Extensive evaluations across multiple benchmarks and real-world experiments on a quadruped robot demonstrate that our method achieves robust and competitive performance against state-of-the-art approaches.The Project Page:https://aczheng-cai.github.io/3dgsnav.github.io/

</details>


### [183] [Sub--Riemannian boundary value problems for Optimal Geometric Locomotion](https://arxiv.org/abs/2602.12199)
*Oliver Gross,Florine Hartwig,Martin Rumpf,Peter Schröder*

Main category: cs.RO

TL;DR: 本文提出了一种几何模型，用以描述和优化细长生物（如蛇）及机器人因形变所产生的运动。通过拉格朗日最小耗散原理，将形变过程转化为亚黎曼测地线问题，并数值计算最优运动轨迹。不仅考虑环境中的能量消耗，还考虑形变所需的内部能量，使结果更接近实际生物的运动效率。该模型也适用于不同的边界条件，实验与数值结果与实际生物运动和已知理论吻合。


<details>
  <summary>Details</summary>
Motivation: 当前关于生物或机器人通过形变驱动运动的研究，往往只关注环境中的能量耗散，忽略了生物或机器人本身为了形变所需的代谢或驱动能耗。为实现更贴近真实、整体能效优化的运动模型，亟需将形变能耗一并纳入建模与优化框架。

Method: 作者提出基于亚黎曼几何的最小耗散原理，将运动优化问题建模为亚黎曼测地线边值问题。理论推导基础上，开发了时空一致离散化的数值方法，可计算三种典型边界条件下的最优形变轨迹。该方法同时考虑环境阻力和自身形变消耗。

Result: 所提模型和数值方法得到的最优运动策略，与实际蛇、精子等生物的运动轨迹，以及低维泳者（如Purcell游动器）的最优解结果吻合。新模型还拓展了问题适用范围，对广义Purcell泳者等提供了新的理论洞察。相关代码已开源。

Conclusion: 该模型为细长形变驱动物体的整体能效最优运动提供了精确的理论与数值分析工具，不但复现了已知最优运动规律，还具有拓展性，可被用于探索更广泛和新颖的生物或仿生运动形态。

Abstract: We propose a geometric model for optimal shape-change-induced motions of slender locomotors, e.g., snakes slithering on sand. In these scenarios, the motion of a body in world coordinates is completely determined by the sequence of shapes it assumes. Specifically, we formulate Lagrangian least-dissipation principles as boundary value problems whose solutions are given by sub-Riemannian geodesics. Notably, our geometric model accounts not only for the energy dissipated by the body's displacement through the environment, but also for the energy dissipated by the animal's metabolism or a robot's actuators to induce shape changes such as bending and stretching, thus capturing overall locomotion efficiency. Our continuous model, together with a consistent time and space discretization, enables numerical computation of sub-Riemannian geodesics for three different types of boundary conditions, i.e., fixing initial and target body, restricting to cyclic motion, or solely prescribing body displacement and orientation. The resulting optimal deformation gaits qualitatively match observed motion trajectories of organisms such as snakes and spermatozoa, as well as known optimality results for low-dimensional systems such as Purcell's swimmers. Moreover, being geometrically less rigid than previous frameworks, our model enables new insights into locomotion mechanisms of, e.g., generalized Purcell's swimmers. The code is publicly available.

</details>


### [184] [LDA-1B: Scaling Latent Dynamics Action Model via Universal Embodied Data Ingestion](https://arxiv.org/abs/2602.12215)
*Jiangran Lyu,Kai Liu,Xuheng Zhang,Haoran Liao,Yusen Feng,Wenxuan Zhu,Tingrui Shen,Jiayi Chen,Jiazhao Zhang,Yifei Dong,Wenbo Cui,Senmao Qi,Shuo Wang,Yixin Zheng,Mi Yan,Xuesong Shi,Haoran Li,Dongbin Zhao,Ming-Yu Liu,Zhizheng Zhang,Li Yi,Yizhou Wang,He Wang*

Main category: cs.RO

TL;DR: 本文提出了一种新型机器人基础模型LDA-1B，通过对异质化的具身数据统一学习动力学、策略和视觉预测，实现了大规模、性能优越的行为建模。


<details>
  <summary>Details</summary>
Motivation: 当前机器人基础模型主要依赖大规模行为克隆（即模仿专家行为），但忽视了潜藏在各种异构具身数据中的可迁移动力学知识。现有的统一世界模型（UWM）虽然有潜力利用这些多样数据，但因数据利用粗糙和数据集分散，难以扩展到基础模型级别，因此亟需一种能够高效整合多源多质数据并大规模训练的方案。

Method: 作者提出LDA-1B模型，联合学习动力学、策略和视觉预测，并针对不同质量的数据分配不同训练角色。为大规模支持，该工作还构建并标准化了EI-30k数据集（包含3万小时人和机器人轨迹）。通过在DINO潜空间中进行预测，规避了冗余的像素建模。LDA-1B还采用多模态扩散Transformer处理异步视觉与动作流，实现10亿参数量级的稳定训练。

Result: 在模拟与实际机器人实验中，LDA-1B在多种任务（如接触复杂、灵巧、长时序任务）上相较现有方法分别提升了21%、48%、23%。此外，模型对低质量数据表现出很强的数据利用能力，通过利用30%原本被认为无用的低质轨迹进行微调，性能提升了10%。

Conclusion: 通过联合学习和统一数据处理，LDA-1B不仅提升了机器人任务性能，还提高了对低质量数据的利用效率，为实现真正通用、高效的机器人基础模型提供了可行路径。

Abstract: Recent robot foundation models largely rely on large-scale behavior cloning, which imitates expert actions but discards transferable dynamics knowledge embedded in heterogeneous embodied data. While the Unified World Model (UWM) formulation has the potential to leverage such diverse data, existing instantiations struggle to scale to foundation-level due to coarse data usage and fragmented datasets. We introduce LDA-1B, a robot foundation model that scales through universal embodied data ingestion by jointly learning dynamics, policy, and visual forecasting, assigning distinct roles to data of varying quality. To support this regime at scale, we assemble and standardize EI-30k, an embodied interaction dataset comprising over 30k hours of human and robot trajectories in a unified format. Scalable dynamics learning over such heterogeneous data is enabled by prediction in a structured DINO latent space, which avoids redundant pixel-space appearance modeling. Complementing this representation, LDA-1B employs a multi-modal diffusion transformer to handle asynchronous vision and action streams, enabling stable training at the 1B-parameter scale. Experiments in simulation and the real world show LDA-1B outperforms prior methods (e.g., $π_{0.5}$) by up to 21\%, 48\%, and 23\% on contact-rich, dexterous, and long-horizon tasks, respectively. Notably, LDA-1B enables data-efficient fine-tuning, gaining 10\% by leveraging 30\% low-quality trajectories typically harmful and discarded.

</details>


### [185] [Any House Any Task: Scalable Long-Horizon Planning for Abstract Human Tasks](https://arxiv.org/abs/2602.12244)
*Zhihong Liu,Yang Li,Rengming Huang,Cewu Lu,Panpan Cai*

Main category: cs.RO

TL;DR: 本文提出了一种面向家庭环境的开放世界任务规划系统AHAT，能够根据含糊的自然语言指令生成高效可执行的长远计划，并在同类任务中表现优越。


<details>
  <summary>Details</summary>
Motivation: 随着家庭服务机器人日益普及，如何让机器人依据复杂、含糊的人类自然语言指令，在大型环境下高效稳健地完成不同家庭任务成为亟需解决的问题。以往方法在环境规模变大、任务链变长或指令变复杂时性能迅速下降，因此需要更具扩展性和鲁棒性的规划系统。

Method: 作者设计了AHAT系统，结合经过训练的LLM，通过将语言指令和文本场景图转化为PDDL子目标，并利用显式符号推理生成长远任务规划。为增强系统对复杂意图的分解能力，还提出了TGPO强化学习算法，以外部校正方式改进推理过程中的中间轨迹。

Result: 实验结果显示，AHAT在各种人类家庭任务（如指令简短但执行复杂）场景下，相较最先进的提示、规划和自学习方法有明显的性能提升。

Conclusion: AHAT能有效扩展至大规模环境和复杂任务，具备更好的长远任务规划能力，对实际家庭机器人具有重要应用意义。

Abstract: Open world language conditioned task planning is crucial for robots operating in large-scale household environments. While many recent works attempt to address this problem using Large Language Models (LLMs) via prompting or training, a key challenge remains scalability. Performance often degrades rapidly with increasing environment size, plan length, instruction ambiguity, and constraint complexity. In this work, we propose Any House Any Task (AHAT), a household task planner optimized for long-horizon planning in large environments given ambiguous human instructions. At its core, AHAT utilizes an LLM trained to map task instructions and textual scene graphs into grounded subgoals defined in the Planning Domain Definition Language (PDDL). These subgoals are subsequently solved to generate feasible and optimal long-horizon plans through explicit symbolic reasoning. To enhance the model's ability to decompose complex and ambiguous intentions, we introduce TGPO, a novel reinforcement learning algorithm that integrates external correction of intermediate reasoning traces into Group Relative Policy Optimization (GRPO). Experiments demonstrate that AHAT achieves significant performance gains over state-of-the-art prompting, planning, and learning methods, particularly in human-style household tasks characterized by brief instructions but requiring complex execution plans.

</details>


### [186] [Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment](https://arxiv.org/abs/2602.12281)
*Jacky Kwok,Xilun Zhang,Mengdi Xu,Yuejiang Liu,Azalia Mirhoseini,Chelsea Finn,Marco Pavone*

Main category: cs.RO

TL;DR: 本文提出了一种对自然语言指令理解的视觉-语言-动作（VLA）模型进行测试时校验的新方法——CoVer，有效提高了机器人执行与指令对齐的准确性，并在多个基准上实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 尽管VLA模型在理解和执行自然语言指令方面取得进展，但在实际任务中，机器人生成的动作仍常与人类意图不完全一致。作者希望通过测试时验证机制，弥合模型输出与人类期望之间的“意图-动作差距”。

Method: (1) 系统性研究了扩大量化（rephrased instructions和生成动作数量）对样本多样性和正确动作恢复的影响。 (2) 提出对比性验证器（CoVer）架构，通过增加计算和数据量实现性能可扩展。 (3) 设计了包括启动时计算和分层验证的推理流水线：预先生成多样化指令和动作候选，然后用CoVer筛选最优高低层动作。

Result: 在SIMPLER基准上，验证方法较同等量数据的预训练方法提升了22%（分布内）与13%（分布外）；实物实验提升45%；PolaRiS基准任务进度提升14%，成功率提升9%。

Conclusion: 联合扩大量化和对比性验证机制，可高效提升机器人模型指令理解与动作匹配效果，优于单纯扩大模型训练规模，证明了测试时验证方法对通用机器人控制的重要性和可扩展性。

Abstract: The long-standing vision of general-purpose robots hinges on their ability to understand and act upon natural language instructions. Vision-Language-Action (VLA) models have made remarkable progress toward this goal, yet their generated actions can still misalign with the given instructions. In this paper, we investigate test-time verification as a means to shrink the "intention-action gap.'' We first characterize the test-time scaling law for embodied instruction following and demonstrate that jointly scaling the number of rephrased instructions and generated actions greatly increases test-time sample diversity, often recovering correct actions more efficiently than scaling each dimension independently. To capitalize on these scaling laws, we present CoVer, a contrastive verifier for vision-language-action alignment, and show that our architecture scales gracefully with additional computational resources and data. We then introduce "boot-time compute" and a hierarchical verification inference pipeline for VLAs. At deployment, our framework precomputes a diverse set of rephrased instructions from a Vision-Language-Model (VLM), repeatedly generates action candidates for each instruction, and then uses a verifier to select the optimal high-level prompt and low-level action chunks. Compared to scaling policy pre-training on the same data, our verification approach yields 22% gains in-distribution and 13% out-of-distribution on the SIMPLER benchmark, with a further 45% improvement in real-world experiments. On the PolaRiS benchmark, CoVer achieves 14% gains in task progress and 9% in success rate.

</details>
