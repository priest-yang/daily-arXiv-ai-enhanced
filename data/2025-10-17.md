<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 100]
- [cs.CL](#cs.CL) [Total: 124]
- [cs.RO](#cs.RO) [Total: 37]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [MultiFoodhat: A potential new paradigm for intelligent food quality inspection](https://arxiv.org/abs/2510.13889)
*Yue Hu,Guohang Zhuang*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的对话式多智能体推理框架MultiFoodChat，实现了零样本食品图像识别，不依赖大规模标注数据，兼具高准确率与解释性。


<details>
  <summary>Details</summary>
Motivation: 当前食品图像分类方法依赖大量标注数据，对未见类别泛化能力弱，限制了实际应用。作者希望提升模型的泛化能力，在缺乏标签的情况下仍能高效识别食品。

Method: 提出MultiFoodChat框架，融合视觉-语言模型（VLMs）与大语言模型（LLMs），通过多轮视觉-文本对话实现协作推理；引入Object Perception Token（OPT）获取细粒度视觉特征，Interactive Reasoning Agent（IRA）动态分析上下文并优化预测输出，实现零样本识别。

Result: 在多个公开食品数据集上，MultiFoodChat在识别准确率和可解释性方面均优于现有的无监督、少样本方法。

Conclusion: MultiFoodChat为智能食品质量检测和分析提供了一种具备灵活性和类人理解能力的新范式，可在无额外训练或人工标注条件下，准确识别复杂的食品场景。

Abstract: Food image classification plays a vital role in intelligent food quality
inspection, dietary assessment, and automated monitoring. However, most
existing supervised models rely heavily on large labeled datasets and exhibit
limited generalization to unseen food categories. To overcome these challenges,
this study introduces MultiFoodChat, a dialogue-driven multi-agent reasoning
framework for zero-shot food recognition. The framework integrates
vision-language models (VLMs) and large language models (LLMs) to enable
collaborative reasoning through multi-round visual-textual dialogues. An Object
Perception Token (OPT) captures fine-grained visual attributes, while an
Interactive Reasoning Agent (IRA) dynamically interprets contextual cues to
refine predictions. This multi-agent design allows flexible and human-like
understanding of complex food scenes without additional training or manual
annotations. Experiments on multiple public food datasets demonstrate that
MultiFoodChat achieves superior recognition accuracy and interpretability
compared with existing unsupervised and few-shot methods, highlighting its
potential as a new paradigm for intelligent food quality inspection and
analysis.

</details>


### [2] [Post-surgical Endometriosis Segmentation in Laparoscopic Videos](https://arxiv.org/abs/2510.13899)
*Andreas Leibetseder,Klaus Schoeffmann,Jörg Keckstein,Simon Keckstein*

Main category: cs.CV

TL;DR: 本论文提出了一个能自动识别和分割腹腔镜手术视频中黑色子宫内膜异位灶区域的系统，以辅助医生诊断和治疗子宫内膜异位症。


<details>
  <summary>Details</summary>
Motivation: 子宫内膜异位症在不同部位呈现多样外观，这导致其诊断难度大，易被误判，尤其是非专业人员或普通医生。该研究旨在为妇科医生提供辅助工具，提升内膜异位症的识别和诊断效率。

Method: 论文开发了一个基于视频分析的系统，对腹腔镜手术视频进行处理，自动检测并分割出黑色内膜异位灶（常见表现之一），通过多颜色覆盖层对病变区域进行标注，并提供检测结果摘要，帮助医生浏览和复查手术视频。

Result: 该系统能够自动对腹腔镜视频中的可疑黑色内膜异位灶进行识别和可视化标注，同时生成检测摘要，辅助医生快速定位和复查相关病灶。

Conclusion: 所提出的系统可有效辅助妇科医生提高对子宫内膜异位症的识别效率和准确性，改善内膜异位症的诊疗过程，减少漏诊和误诊可能性。

Abstract: Endometriosis is a common women's condition exhibiting a manifold visual
appearance in various body-internal locations. Having such properties makes its
identification very difficult and error-prone, at least for laymen and
non-specialized medical practitioners. In an attempt to provide assistance to
gynecologic physicians treating endometriosis, this demo paper describes a
system that is trained to segment one frequently occurring visual appearance of
endometriosis, namely dark endometrial implants. The system is capable of
analyzing laparoscopic surgery videos, annotating identified implant regions
with multi-colored overlays and displaying a detection summary for improved
video browsing.

</details>


### [3] [Efficient Few-Shot Learning in Remote Sensing: Fusing Vision and Vision-Language Models](https://arxiv.org/abs/2510.13993)
*Jia Yun Chua,Argyrios Zolotas,Miguel Arana-Catania*

Main category: cs.CV

TL;DR: 该论文将传统视觉模型与视觉语言模型（VLM）相结合，提升了遥感图像中的飞机检测与场景理解，尤其在数据稀缺或图像降质的情况下表现突出。


<details>
  <summary>Details</summary>
Motivation: 传统遥感图像分析模型依赖大量特定领域标注数据，且在理解复杂环境下的上下文能力有限。近年来，视觉语言模型能结合视觉与文本信息，但其在遥感领域尚未成熟。作者希望探索将VLM与传统视觉模型结合以提升遥感图像分析的效果。

Method: 作者将传统YOLO视觉模型与VLMs（如LLaVA、ChatGPT、Gemini）结合，应用于遥感图像的飞机检测与场景理解任务。对有标签、无标签及不同程度图像降质的数据进行性能评估，通过MAE和CLIPScore衡量模型提升。

Result: 在飞机检测和计数任务中，各模型平均MAE提升了48.46%，尤其在原始和降质场景下表现优异。遥感场景理解上的CLIPScore提高了6.17%。

Conclusion: 将传统视觉模型与VLMs结合的方法显著提升了遥感图像分析能力，特别适用于小样本学习和复杂环境下的遥感应用。

Abstract: Remote sensing has become a vital tool across sectors such as urban planning,
environmental monitoring, and disaster response. While the volume of data
generated has increased significantly, traditional vision models are often
constrained by the requirement for extensive domain-specific labelled data and
their limited ability to understand the context within complex environments.
Vision Language Models offer a complementary approach by integrating visual and
textual data; however, their application to remote sensing remains
underexplored, particularly given their generalist nature. This work
investigates the combination of vision models and VLMs to enhance image
analysis in remote sensing, with a focus on aircraft detection and scene
understanding. The integration of YOLO with VLMs such as LLaVA, ChatGPT, and
Gemini aims to achieve more accurate and contextually aware image
interpretation. Performance is evaluated on both labelled and unlabelled remote
sensing data, as well as degraded image scenarios which are crucial for remote
sensing. The findings show an average MAE improvement of 48.46% across models
in the accuracy of aircraft detection and counting, especially in challenging
conditions, in both raw and degraded scenarios. A 6.17% improvement in
CLIPScore for comprehensive understanding of remote sensing images is obtained.
The proposed approach combining traditional vision models and VLMs paves the
way for more advanced and efficient remote sensing image analysis, especially
in few-shot learning scenarios.

</details>


### [4] [Finding Holes: Pathologist Level Performance Using AI for Cribriform Morphology Detection in Prostate Cancer](https://arxiv.org/abs/2510.13995)
*Kelvin Szolnoky,Anders Blilie,Nita Mulliqi,Toyonori Tsuzuki,Hemamali Samaratunga,Matteo Titus,Xiaoyi Ji,Sol Erika Boman,Einar Gudlaugsson,Svein Reidar Kjosavik,José Asenjo,Marcello Gambacorta,Paolo Libretti,Marcin Braun,Radisław Kordek,Roman Łowicki,Brett Delahunt,Kenneth A. Iczkowski,Theo van der Kwast,Geert J. L. H. van Leenders,Katia R. M. Leite,Chin-Chen Pan,Emiel Adrianus Maria Janssen,Martin Eklund,Lars Egevad,Kimmo Kartasalo*

Main category: cs.CV

TL;DR: 本文开发并验证了一种AI系统，能高效检测前列腺癌中的筛状结构形态，表现优于专家病理学家，有助于标准化诊断和改善治疗决策。


<details>
  <summary>Details</summary>
Motivation: 前列腺癌中的筛状结构形态预示预后差且不适合积极监测，但目前该形态在病理报告中常被低报且不同病理学家间判断一致性差，因此需要提高筛状形态的检测准确性和可重复性。

Method: 采用EfficientNetV2-S编码器和多实例学习技术，开发深度学习模型，对640份前列腺穿刺活检数字切片进行训练，在内部和外部共527份切片上进行验证。模型的训练及标注由三位高一致性的泌尿病理专家提供，并与九位专家在88份切片上进行对比分析。

Result: 模型内部验证AUC达0.97，Cohen's kappa为0.81，外部验证AUC为0.90，Cohen's kappa为0.55。在多专家一致性分析中，模型的平均一致性（kappa: 0.66）高于所有九位专家（kappa: 0.35-0.62）。

Conclusion: 该AI模型对前列腺癌筛状结构的检测达到病理专家水平，能提升诊断可靠性，实现报告标准化，助力改善患者的治疗决策。

Abstract: Background: Cribriform morphology in prostate cancer is a histological
feature that indicates poor prognosis and contraindicates active surveillance.
However, it remains underreported and subject to significant interobserver
variability amongst pathologists. We aimed to develop and validate an AI-based
system to improve cribriform pattern detection.
  Methods: We created a deep learning model using an EfficientNetV2-S encoder
with multiple instance learning for end-to-end whole-slide classification. The
model was trained on 640 digitised prostate core needle biopsies from 430
patients, collected across three cohorts. It was validated internally (261
slides from 171 patients) and externally (266 slides, 104 patients from three
independent cohorts). Internal validation cohorts included laboratories or
scanners from the development set, while external cohorts used completely
independent instruments and laboratories. Annotations were provided by three
expert uropathologists with known high concordance. Additionally, we conducted
an inter-rater analysis and compared the model's performance against nine
expert uropathologists on 88 slides from the internal validation cohort.
  Results: The model showed strong internal validation performance (AUC: 0.97,
95% CI: 0.95-0.99; Cohen's kappa: 0.81, 95% CI: 0.72-0.89) and robust external
validation (AUC: 0.90, 95% CI: 0.86-0.93; Cohen's kappa: 0.55, 95% CI:
0.45-0.64). In our inter-rater analysis, the model achieved the highest average
agreement (Cohen's kappa: 0.66, 95% CI: 0.57-0.74), outperforming all nine
pathologists whose Cohen's kappas ranged from 0.35 to 0.62.
  Conclusion: Our AI model demonstrates pathologist-level performance for
cribriform morphology detection in prostate cancer. This approach could enhance
diagnostic reliability, standardise reporting, and improve treatment decisions
for prostate cancer patients.

</details>


### [5] [NAPPure: Adversarial Purification for Robust Image Classification under Non-Additive Perturbations](https://arxiv.org/abs/2510.14025)
*Junjie Nan,Jianing Li,Wei Chen,Mingkun Zhang,Xueqi Cheng*

Main category: cs.CV

TL;DR: 本文提出了一种新的对抗纯化框架NAPPure，能有效应对非加性对抗扰动（如模糊、遮挡、畸变），提升分类模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗纯化方法主要针对加性扰动设计，但在实际场景中，模糊、遮挡等非加性扰动同样常见，而当前方法对此效果不佳，因此需要开发能够处理非加性扰动的新方法。

Method: 作者首先建立了对抗图像的生成过程模型，然后通过似然最大化的方法，将原始干净图像与扰动参数进行解耦，实现对非加性扰动的建模和校正。

Result: 在GTSRB和CIFAR-10数据集上的实验结果表明，NAPPure能显著提升图像分类模型应对非加性扰动的鲁棒性。

Conclusion: NAPPure为提高分类模型在更广泛实际场景下的安全性和鲁棒性提供了有效手段，拓展了对抗纯化方法的适用范围。

Abstract: Adversarial purification has achieved great success in combating adversarial
image perturbations, which are usually assumed to be additive. However,
non-additive adversarial perturbations such as blur, occlusion, and distortion
are also common in the real world. Under such perturbations, existing
adversarial purification methods are much less effective since they are
designed to fit the additive nature. In this paper, we propose an extended
adversarial purification framework named NAPPure, which can further handle
non-additive perturbations. Specifically, we first establish the generation
process of an adversarial image, and then disentangle the underlying clean
image and perturbation parameters through likelihood maximization. Experiments
on GTSRB and CIFAR-10 datasets show that NAPPure significantly boosts the
robustness of image classification models against non-additive perturbations.

</details>


### [6] [Vgent: Graph-based Retrieval-Reasoning-Augmented Generation For Long Video Understanding](https://arxiv.org/abs/2510.14032)
*Xiaoqian Shen,Wenxuan Zhang,Jun Chen,Mohamed Elhoseiny*

Main category: cs.CV

TL;DR: 该论文提出了一种基于图结构的检索和推理增强框架（Vgent），显著提升大规模视频语言模型对长视频的理解和推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有大规模视频语言模型（LVLMs）难以处理超出上下文窗口的大量视频信息，且难以保持长时序信息。检索增强生成（RAG）方法在处理长文本上有效，但直接应用在长视频上会破坏时间依赖并引入噪声，影响推理准确性。

Method: 提出Vgent框架，用结构化图表示视频，保留视频片段间的语义关系实现高效检索。引入中间推理步骤，通过结构化验证减少噪声并聚合相关信息，提升推理的准确性和上下文感知能力。

Result: 在三个长视频理解基准上，Vgent整体性能较基础模型提升3.0%-5.4%，显著优于现有最先进的视频RAG方法（提升8.6%）。

Conclusion: 结构化检索与推理增强能够突破LVLMs在长视频理解上的瓶颈，有效提升准确性，是改善长视频推理的有效途径。

Abstract: Understanding and reasoning over long videos pose significant challenges for
large video language models (LVLMs) due to the difficulty in processing
intensive video tokens beyond context window and retaining long-term sequential
information. Retrieval-Augmented Generation (RAG) has demonstrated
effectiveness in processing long context for Large Language Models (LLMs);
however, applying RAG to long video faces challenges such as disrupted temporal
dependencies and inclusion of irrelevant information that can hinder accurate
reasoning. To address these limitations, we propose Vgent, a novel graph-based
retrieval-reasoning-augmented generation framework to enhance LVLMs for long
video understanding. Our approach introduces two key innovations: (i) It
represents videos by structured graphs with semantic relationships across video
clips preserved to improve retrieval effectiveness. (ii) It introduces an
intermediate reasoning step to mitigate the reasoning limitation of LVLMs,
which leverages structured verification to reduce retrieval noise and
facilitate the explicit aggregation of relevant information across clips,
resulting in more accurate and context-aware responses. We comprehensively
evaluate our framework with various open-source LVLMs on three long-video
understanding benchmarks. Our approach yielded an overall performance
improvement of $3.0\%\sim 5.4\%$ over base models on MLVU, and outperformed
state-of-the-art video RAG methods by $8.6\%$. Our code is publicly available
at https://xiaoqian-shen.github.io/Vgent.

</details>


### [7] [Synchronization of Multiple Videos](https://arxiv.org/abs/2510.14051)
*Avihai Naaman,Ron Shapira Weber,Oren Freifeld*

Main category: cs.CV

TL;DR: 本文提出了一种名为时序原型学习（TPL）的新方法，用于对多源或生成式AI视频进行同步，显著提高了同步准确性和效率，并首次解决了多个生成式AI视频同步的问题。


<details>
  <summary>Details</summary>
Motivation: 以往视频同步方法多适用于同一场景的多机位视频，但面对来自不同场景、背景或生成式AI的视频，传统方法因非线性时序错位变得不适用。因此，亟需一种更通用、鲁棒的新方法。

Method: 提出了时序原型学习（TPL）框架，先通过各种预训练模型提取视频高维特征，然后构建紧凑的1D原型序列对齐视频中的关键动作阶段，从而规避繁琐的两两配对匹配。

Result: 实验证明，TPL在多个多样化数据集上提升了同步的准确性、效率和鲁棒性，且在细粒度帧检索和阶段分类等任务中表现优异。

Conclusion: TPL为复杂视频、尤其是多生成式AI视频的同步问题提供了有效解决方案，推动了多视频内容分析的发展，并为后续相关研究提供了新工具和数据集。

Abstract: Synchronizing videos captured simultaneously from multiple cameras in the
same scene is often easy and typically requires only simple time shifts.
However, synchronizing videos from different scenes or, more recently,
generative AI videos, poses a far more complex challenge due to diverse
subjects, backgrounds, and nonlinear temporal misalignment. We propose Temporal
Prototype Learning (TPL), a prototype-based framework that constructs a shared,
compact 1D representation from high-dimensional embeddings extracted by any of
various pretrained models. TPL robustly aligns videos by learning a unified
prototype sequence that anchors key action phases, thereby avoiding exhaustive
pairwise matching. Our experiments show that TPL improves synchronization
accuracy, efficiency, and robustness across diverse datasets, including
fine-grained frame retrieval and phase classification tasks. Importantly, TPL
is the first approach to mitigate synchronization issues in multiple generative
AI videos depicting the same action. Our code and a new multiple video
synchronization dataset are available at https://bgu-cs-vil.github.io/TPL/

</details>


### [8] [Capture, Canonicalize, Splat: Zero-Shot 3D Gaussian Avatars from Unstructured Phone Images](https://arxiv.org/abs/2510.14081)
*Emanuel Garbin,Guy Adam,Oded Krams,Zohar Barzelay,Eran Guendelman,Michael Schwarz,Moran Vatelmacher,Yigal Shenkman,Eli Peker,Itai Druker,Uri Patish,Yoav Blum,Max Bluvstein,Junxuan Li,Rawal Khirodkar,Shunsuke Saito*

Main category: cs.CV

TL;DR: 本文提出了一种创新的零样本流程，可以利用少量无结构的手机照片生成超逼真且能保持身份特征的3D虚拟人头像。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么依赖单视角，导致几何不一致和面部特征虚假的问题，要么基于合成数据训练，无法捕捉皮肤皱纹和细毛发等高频细节，因此缺乏逼真度和身份还原能力。

Method: 方法包括两个核心创新：一是提出生成式标准化模块，将多个无结构视角转化为一致且标准化的表示；二是利用基于变换器（transformer）的模型，并用从真实人像穹顶系统获取的大规模高保真 Gaussian splatting 虚拟人数据集进行训练。整体被称为“采集、标准化、绘制”流程。

Result: 该流程可实现从无结构照片生成静态四分之一身虚拟人像，生成效果高度逼真，且能够准确保留人物的身份特征。

Conclusion: 本文的方法在虚拟人像建模领域突破了几何和细节还原的难题，显著提升了3D虚拟人的真实感和身份还原能力，推进了相关技术的发展。

Abstract: We present a novel, zero-shot pipeline for creating hyperrealistic,
identity-preserving 3D avatars from a few unstructured phone images. Existing
methods face several challenges: single-view approaches suffer from geometric
inconsistencies and hallucinations, degrading identity preservation, while
models trained on synthetic data fail to capture high-frequency details like
skin wrinkles and fine hair, limiting realism. Our method introduces two key
contributions: (1) a generative canonicalization module that processes multiple
unstructured views into a standardized, consistent representation, and (2) a
transformer-based model trained on a new, large-scale dataset of high-fidelity
Gaussian splatting avatars derived from dome captures of real people. This
"Capture, Canonicalize, Splat" pipeline produces static quarter-body avatars
with compelling realism and robust identity preservation from unstructured
photos.

</details>


### [9] [cubic: CUDA-accelerated 3D Bioimage Computing](https://arxiv.org/abs/2510.14143)
*Alexandr A. Kalinin,Anne E. Carpenter,Shantanu Singh,Matthew J. O'Meara*

Main category: cs.CV

TL;DR: 本文介绍了cubic——一个为多维生物成像大数据提供GPU加速和优良可扩展性的开源Python库。


<details>
  <summary>Details</summary>
Motivation: 随着显微成像技术的发展，2D和3D生物图像数据体量巨大，现有的生物图像分析工具受限于扩展性、效率与现代科学计算环境融合等问题，难以满足高通量和高性能分析的需求。

Method: cubic扩展了SciPy和scikit-image常用API，结合CuPy和RAPIDS cuCIM，实现了设备无关的API：数据在GPU上即自动调用GPU加速，否则在CPU运行，从预处理到分割与特征提取全面提升分析流程的运行效率，且为2D与3D任务提供支持。

Result: 通过基准测试和重现去卷积、分割等实际分析流程，cubic在保持算法一致性的同时，显著加速了单项操作与完整分析流程。

Conclusion: cubic为生物图像分析提供了可拓展、可复现、易集成的GPU加速解决方案，支撑从交互分析到自动化高通量处理，更好地融入Python科学计算生态。

Abstract: Quantitative analysis of multidimensional biological images is useful for
understanding complex cellular phenotypes and accelerating advances in
biomedical research. As modern microscopy generates ever-larger 2D and 3D
datasets, existing computational approaches are increasingly limited by their
scalability, efficiency, and integration with modern scientific computing
workflows. Existing bioimage analysis tools often lack application programmable
interfaces (APIs), do not support graphics processing unit (GPU) acceleration,
lack broad 3D image processing capabilities, and/or have poor interoperability
for compute-heavy workflows. Here, we introduce cubic, an open-source Python
library that addresses these challenges by augmenting widely used SciPy and
scikit-image APIs with GPU-accelerated alternatives from CuPy and RAPIDS cuCIM.
cubic's API is device-agnostic and dispatches operations to GPU when data
reside on the device and otherwise executes on CPU, seamlessly accelerating a
broad range of image processing routines. This approach enables GPU
acceleration of existing bioimage analysis workflows, from preprocessing to
segmentation and feature extraction for 2D and 3D data. We evaluate cubic both
by benchmarking individual operations and by reproducing existing deconvolution
and segmentation pipelines, achieving substantial speedups while maintaining
algorithmic fidelity. These advances establish a robust foundation for
scalable, reproducible bioimage analysis that integrates with the broader
Python scientific computing ecosystem, including other GPU-accelerated methods,
enabling both interactive exploration and automated high-throughput analysis
workflows. cubic is openly available at
https://github$.$com/alxndrkalinin/cubic

</details>


### [10] [Virtually Being: Customizing Camera-Controllable Video Diffusion Models with Multi-View Performance Captures](https://arxiv.org/abs/2510.14179)
*Yuancheng Xu,Wenqi Xian,Li Ma,Julien Philip,Ahmet Levent Taşel,Yiwei Zhao,Ryan Burgert,Mingming He,Oliver Hermann,Oliver Pilarski,Rahul Garg,Paul Debevec,Ning Yu*

Main category: cs.CV

TL;DR: 本论文提出了一种用于视频扩散模型的新框架，实现了多视角角色一致性和3D相机控制，并支持虚拟制片中的关键能力。


<details>
  <summary>Details</summary>
Motivation: 目前的视频生成模型在多视角角色一致性、精确相机控制和光照适应性方面存在局限，这限制了它们在虚拟制片等实际应用中的表现。

Method: 作者设计了一条新颖的数据定制流程，利用4D高斯点渲染（4DGS）和视频重光模型，生成包含不同相机轨迹和光照变化的数据。用这些数据对先进的开源视频扩散模型进行微调，从而提高个性化、一致性和控制能力。针对多主体生成，提出了联合训练与噪声融合两种方法，提升了推理时的效率和灵活性。

Result: 实验表明，该框架生成的视频质量更高，角色一致性和个性化精度更好，相机与光照控制能力加强，能够处理场景及真实视频定制等任务。

Conclusion: 该方法推进了视频扩散模型在虚拟制片中的实用性，特别是在多视角、一致性和3D控制方面表现优异。

Abstract: We introduce a framework that enables both multi-view character consistency
and 3D camera control in video diffusion models through a novel customization
data pipeline. We train the character consistency component with recorded
volumetric capture performances re-rendered with diverse camera trajectories
via 4D Gaussian Splatting (4DGS), lighting variability obtained with a video
relighting model. We fine-tune state-of-the-art open-source video diffusion
models on this data to provide strong multi-view identity preservation, precise
camera control, and lighting adaptability. Our framework also supports core
capabilities for virtual production, including multi-subject generation using
two approaches: joint training and noise blending, the latter enabling
efficient composition of independently customized models at inference time; it
also achieves scene and real-life video customization as well as control over
motion and spatial layout during customization. Extensive experiments show
improved video quality, higher personalization accuracy, and enhanced camera
control and lighting adaptability, advancing the integration of video
generation into virtual production. Our project page is available at:
https://eyeline-labs.github.io/Virtually-Being.

</details>


### [11] [Joint Modeling of Big Five and HEXACO for Multimodal Apparent Personality-trait Recognition](https://arxiv.org/abs/2510.14203)
*Ryo Masumura,Shota Orihashi,Mana Ihori,Tomohiro Tanaka,Naoki Makishima,Taiga Yamane,Naotaka Kawata,Satoshi Suzuki,Taichi Katayama*

Main category: cs.CV

TL;DR: 本文提出了一种联合建模方法，同时识别Big Five（五大人格）和HEXACO两种人格特质，以实现多模态表观人格特质的自动识别。


<details>
  <summary>Details</summary>
Motivation: 以往多模态表观人格识别研究大多基于五大人格（Big Five），而HEXACO人格模型中包含Honesty-Humility特质，可评估如攻击性、报复性、社会支配倾向等，但尚未有人关注表观HEXACO识别。同时，目前机器学习建模中五大人格与HEXACO之间的关系也尚未明了。研究动机在于结合两者，提升对人类多模态行为的理解。

Method: 提出一种方法，将Big Five和HEXACO联合优化，应用于基于自我介绍视频数据集的多模态人格自动识别。通过多模态特征，利用机器学习模型协同预测两种人格框架。

Result: 实验结果表明，所提出的方法能够有效识别Big Five和HEXACO两套人格特质。

Conclusion: 本研究证明了联合识别Big Five与HEXACO的人格特质在多模态表观人格识别中的有效性，并强调了将二者关系纳入建模的意义。

Abstract: This paper proposes a joint modeling method of the Big Five, which has long
been studied, and HEXACO, which has recently attracted attention in psychology,
for automatically recognizing apparent personality traits from multimodal human
behavior. Most previous studies have used the Big Five for multimodal apparent
personality-trait recognition. However, no study has focused on apparent HEXACO
which can evaluate an Honesty-Humility trait related to displaced aggression
and vengefulness, social-dominance orientation, etc. In addition, the
relationships between the Big Five and HEXACO when modeled by machine learning
have not been clarified. We expect awareness of multimodal human behavior to
improve by considering these relationships. The key advance of our proposed
method is to optimize jointly recognizing the Big Five and HEXACO. Experiments
using a self-introduction video dataset demonstrate that the proposed method
can effectively recognize the Big Five and HEXACO.

</details>


### [12] [LOTA: Bit-Planes Guided AI-Generated Image Detection](https://arxiv.org/abs/2510.14230)
*Hongsong Wang,Renxi Cheng,Yang Zhang,Chaolei Han,Jie Gui*

Main category: cs.CV

TL;DR: 本文提出了一种高效的利用位平面（bit-plane）噪声特征检测AI生成图像的新方法，在保证高准确率的同时大幅提升检测速度。


<details>
  <summary>Details</summary>
Motivation: 随着GAN和Diffusion等生成模型技术进步，AI生成图像与真实图像难以区分。现有基于重建误差的方法计算量大且无法精确捕捉原始图像中的噪声特征，亟需高效且准确的新检测方法。

Method: 作者提出以位平面分离提取噪声特征，并结合归一化（缩放、阈值）处理。同时，创新性地利用最大梯度区域选择方法，放大噪声信号以提升区分效果。在分类上，设计了轻量高效的分类器头部，分别探索噪声特征和噪声引导两种架构。

Result: 在GenImage基准上，该方法平均检测准确率达到98.9%，较前人提升11.9个百分点，并且在GAN与Diffusion之间的泛化能力极佳：从GAN到Diffusion精度98.2%，Diffusion到GAN达99.2%。在检测速度上，相较于主流方法快近百倍，误差提取仅需毫秒级。

Conclusion: 本文方法凭借高精度、强泛化能力和极快速度，为AI生成图像检测提供了新思路和实用工具，在实际大规模检测场景中极具应用价值。

Abstract: The rapid advancement of GAN and Diffusion models makes it more difficult to
distinguish AI-generated images from real ones. Recent studies often use
image-based reconstruction errors as an important feature for determining
whether an image is AI-generated. However, these approaches typically incur
high computational costs and also fail to capture intrinsic noisy features
present in the raw images. To solve these problems, we innovatively refine
error extraction by using bit-plane-based image processing, as lower bit planes
indeed represent noise patterns in images. We introduce an effective bit-planes
guided noisy image generation and exploit various image normalization
strategies, including scaling and thresholding. Then, to amplify the noise
signal for easier AI-generated image detection, we design a maximum gradient
patch selection that applies multi-directional gradients to compute the noise
score and selects the region with the highest score. Finally, we propose a
lightweight and effective classification head and explore two different
structures: noise-based classifier and noise-guided classifier. Extensive
experiments on the GenImage benchmark demonstrate the outstanding performance
of our method, which achieves an average accuracy of \textbf{98.9\%}
(\textbf{11.9}\%~$\uparrow$) and shows excellent cross-generator generalization
capability. Particularly, our method achieves an accuracy of over 98.2\% from
GAN to Diffusion and over 99.2\% from Diffusion to GAN. Moreover, it performs
error extraction at the millisecond level, nearly a hundred times faster than
existing methods. The code is at https://github.com/hongsong-wang/LOTA.

</details>


### [13] [PIA: Deepfake Detection Using Phoneme-Temporal and Identity-Dynamic Analysis](https://arxiv.org/abs/2510.14241)
*Soumyya Kanti Datta,Tanvi Ranga,Chengzhe Sun,Siwei Lyu*

Main category: cs.CV

TL;DR: 该论文提出了一种多模态音视频深度伪造检测框架PIA，通过联合语音、动态面部动作和身份特征，有效检测由先进生成模型产生的深度伪造视频。


<details>
  <summary>Details</summary>
Motivation: 传统深度伪造检测方法主要依赖单一模态或人工设计的对齐规则，对于GAN、扩散模型等先进生成方法生成的几乎完美的伪造帧难以识别，尤其容易忽略细微的时间一致性差异。

Method: 本文提出PIA框架，结合了语音音素序列、唇部几何数据和面部身份嵌入等多模态特征，通过跨模态比对和动态特征分析来检测伪造视频中的细微不一致性。

Result: 采用此多模态集成方法能够大幅提升对细微深度伪造的检测能力，实验结果显示对高级生成模型生成的伪造视频具有更高的检测准确率。

Conclusion: PIA框架证明了多模态和动态特征联合分析在提升深度伪造检测性能上的有效性，为应对现代深度伪造威胁提供了可靠的新思路。

Abstract: The rise of manipulated media has made deepfakes a particularly insidious
threat, involving various generative manipulations such as lip-sync
modifications, face-swaps, and avatar-driven facial synthesis. Conventional
detection methods, which predominantly depend on manually designed
phoneme-viseme alignment thresholds, fundamental frame-level consistency
checks, or a unimodal detection strategy, inadequately identify modern-day
deepfakes generated by advanced generative models such as GANs, diffusion
models, and neural rendering techniques. These advanced techniques generate
nearly perfect individual frames yet inadvertently create minor temporal
discrepancies frequently overlooked by traditional detectors. We present a
novel multimodal audio-visual framework, Phoneme-Temporal and Identity-Dynamic
Analysis(PIA), incorporating language, dynamic face motion, and facial
identification cues to address these limitations. We utilize phoneme sequences,
lip geometry data, and advanced facial identity embeddings. This integrated
method significantly improves the detection of subtle deepfake alterations by
identifying inconsistencies across multiple complementary modalities. Code is
available at https://github.com/skrantidatta/PIA

</details>


### [14] [Event Interval Modulation: A Novel Scheme for Event-based Optical Camera Communication](https://arxiv.org/abs/2510.14245)
*Miu Sumino,Mayu Ishii,Shun Kaizu,Daisuke Hisano,Yu Nakayama*

Main category: cs.CV

TL;DR: 本文提出了一种针对基于事件视觉传感器（EVS）的光学相机通信（OCC）系统的新型调制方案——事件间隔调制（EIM），显著提升了传输速率，并首次以实验验证其性能，创下了当前事件型OCC系统比特率新纪录。


<details>
  <summary>Details</summary>
Motivation: 传统基于帧的OCC系统面临传输速率低、处理负载高等问题，即使采用了EVS作为接收端，所用的调制方式也未能充分利用EVS的独特特性，因此亟需为事件型相机定制更高效的调制方法。

Method: 提出并理论建模了一种新的事件间隔调制（EIM）方案，将信息编码在事件间隔里，并对EVS参数进行了优化设置。随后，通过系列实验调整参数以优化频率响应，确定可用的最大调制阶数，并在实际环境中进行了数据传输实验。

Result: 在室内环境下，利用EIM方案实现了28 kbps（10米）、8.4 kbps（50米）的可靠数据传输，显著提升了此前事件型OCC系统的比特率水平。

Conclusion: 本文方法（事件间隔调制，EIM）专为事件型视觉传感器OCC系统设计，能够显著提升其传输速率，为事件型OCC的应用和发展提供了新的技术方向和性能基准。

Abstract: Optical camera communication (OCC) represents a promising visible light
communication technology. Nonetheless, typical OCC systems utilizing
frame-based cameras are encumbered by limitations, including low bit rate and
high processing load. To address these issues, OCC system utilizing an
event-based vision sensor (EVS) as receivers have been proposed. The EVS
enables high-speed, low-latency, and robust communication due to its
asynchronous operation and high dynamic range. In existing event-based OCC
systems, conventional modulation schemes such as on-off keying (OOK) and pulse
position modulation have been applied, however, to the best of our knowledge,
no modulation method has been proposed that fully exploits the unique
characteristics of the EVS. This paper proposes a novel modulation scheme,
called the event interval modulation (EIM) scheme, specifically designed for
event-based OCC. EIM enables improvement in transmission speed by modulating
information using the intervals between events. This paper proposes a
theoretical model of EIM and conducts a proof-of-concept experiment. First, the
parameters of the EVS are tuned and customized to optimize the frequency
response specifically for EIM. Then, the maximum modulation order usable in EIM
is determined experimentally. We conduct transmission experiments based on the
obtained parameters. Finally, we report successful transmission at 28 kbps over
10 meters and 8.4 kbps over 50 meters in an indoor environment. This sets a new
benchmark for bit rate in event-based OCC systems.

</details>


### [15] [MACE: Mixture-of-Experts Accelerated Coordinate Encoding for Large-Scale Scene Localization and Rendering](https://arxiv.org/abs/2510.14251)
*Mingkai Liu,Dikai Fan,Haohua Que,Haojia Gao,Xiao Liu,Shuxue Peng,Meixia Lin,Shengyu Gu,Ruicong Ye,Wanli Qiu,Handong Yao,Ruopeng Zhang,Xianliang Huang*

Main category: cs.CV

TL;DR: 本文提出了一种高效的场景坐标编码方法（MACE），结合MoE架构，仅激活单一子网络，以实现大规模场景中高效定位与高质量渲染，同时引入无辅助损失的负载均衡策略显著提升定位精度，大幅降低计算成本，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大规模场景下，高效定位与渲染面临计算资源消耗大，现有方法（如SCR）受限于单一网络，难以扩展到大规模应用。为提升扩展性与精度，亟需高效架构与合理的资源分配机制。

Method: 提出基于混合专家（MoE）框架的MACE方法，通过引入门控网络自动选择并激活最合适的子网络，并提出无辅助损失的负载均衡（ALF-LB）策略，实现各子网络间有效分配，提高整体推理效率与定位精度。

Result: MACE方法在Cambridge数据集上的实验显示，仅需10分钟训练即可实现高质量渲染结果，并且在计算成本降低的同时，定位精度高于传统方法。

Conclusion: MACE为大规模场景应用提供了一种高效、低成本且准确的定位与渲染解决方案，展示出良好的实际应用潜力。

Abstract: Efficient localization and high-quality rendering in large-scale scenes
remain a significant challenge due to the computational cost involved. While
Scene Coordinate Regression (SCR) methods perform well in small-scale
localization, they are limited by the capacity of a single network when
extended to large-scale scenes. To address these challenges, we propose the
Mixed Expert-based Accelerated Coordinate Encoding method (MACE), which enables
efficient localization and high-quality rendering in large-scale scenes.
Inspired by the remarkable capabilities of MOE in large model domains, we
introduce a gating network to implicitly classify and select sub-networks,
ensuring that only a single sub-network is activated during each inference.
Furtheremore, we present Auxiliary-Loss-Free Load Balancing(ALF-LB) strategy to
enhance the localization accuracy on large-scale scene. Our framework provides
a significant reduction in costs while maintaining higher precision, offering
an efficient solution for large-scale scene applications. Additional
experiments on the Cambridge test set demonstrate that our method achieves
high-quality rendering results with merely 10 minutes of training.

</details>


### [16] [Identity-Preserving Image-to-Video Generation via Reward-Guided Optimization](https://arxiv.org/abs/2510.14255)
*Liao Shen,Wentao Jiang,Yiran Zhu,Tiezheng Ge,Zhiguo Cao,Bo Zheng*

Main category: cs.CV

TL;DR: 该论文提出了一种用于图像到视频(I2V)生成的身份保持奖励引导优化方法(IPRO)，有效提升了生成视频中人物身份一致性，在现有数据集和自研模型上均展现出优越效果。


<details>
  <summary>Details</summary>
Motivation: 目前I2V生成任务中，尤其是以人物为中心时，输入静态图像与生成视频中人物身份一致性难以保持，尤其在人脸占据图像较小区域、表情变化剧烈时更为突出。由于人类对身份变化极为敏感，因此该问题亟需解决，且现有研究关注较少。

Method: 本文提出一种基于强化学习的视频扩散框架(IPRO)。该方法不改变原有模型结构，而是引入人脸身份得分器作为奖励，直接通过采样链最后几步反向传播奖励信号，提供更丰富梯度反馈。此外，创新性地使用真实视频中的多角度人脸特征池提升泛化能力，并引入KL散度正则避免过拟合奖励信号。

Result: 在Wan 2.2 I2V模型及自研I2V模型上的大量实验表明，IPRO方法在身份保持性及整体效果上均优于现有方案。

Conclusion: IPRO作为一种高效且直接的视频扩散模型优化算法，无需复杂架构调整即可明显提升I2V任务中的身份一致性，对相关领域有显著应用价值。

Abstract: Recent advances in image-to-video (I2V) generation have achieved remarkable
progress in synthesizing high-quality, temporally coherent videos from static
images. Among all the applications of I2V, human-centric video generation
includes a large portion. However, existing I2V models encounter difficulties
in maintaining identity consistency between the input human image and the
generated video, especially when the person in the video exhibits significant
expression changes and movements. This issue becomes critical when the human
face occupies merely a small fraction of the image. Since humans are highly
sensitive to identity variations, this poses a critical yet under-explored
challenge in I2V generation. In this paper, we propose Identity-Preserving
Reward-guided Optimization (IPRO), a novel video diffusion framework based on
reinforcement learning to enhance identity preservation. Instead of introducing
auxiliary modules or altering model architectures, our approach introduces a
direct and effective tuning algorithm that optimizes diffusion models using a
face identity scorer. To improve performance and accelerate convergence, our
method backpropagates the reward signal through the last steps of the sampling
chain, enabling richer gradient feedback. We also propose a novel facial
scoring mechanism that treats faces in ground-truth videos as facial feature
pools, providing multi-angle facial information to enhance generalization. A
KL-divergence regularization is further incorporated to stabilize training and
prevent overfitting to the reward signal. Extensive experiments on Wan 2.2 I2V
model and our in-house I2V model demonstrate the effectiveness of our method.
Our project and code are available at
\href{https://ipro-alimama.github.io/}{https://ipro-alimama.github.io/}.

</details>


### [17] [Identity-GRPO: Optimizing Multi-Human Identity-preserving Video Generation via Reinforcement Learning](https://arxiv.org/abs/2510.14256)
*Xiangyu Meng,Zixian Zhang,Zhenghao Zhang,Junchao Liao,Long Qin,Weizhi Wang*

Main category: cs.CV

TL;DR: 本文提出Identity-GRPO方法，利用人类反馈优化多人物身份一致性的视频生成，大幅提升了生成视频中多人物身份的持续一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法如VACE和Phantom在特定主体的视频生成方面已取得进展，但在多人物动态交互、身份一致性方面表现不佳。每个人物在动态场景中的身份保持十分关键，因此需要新的优化方案提升多人物一致性。

Method: 作者提出Identity-GRPO方法：首先构建大规模视频偏好数据集，包括真实和合成失真数据，并由人类进行成对注释，重点关注视频中人物一致性。然后，采用专为多人物一致性定制的GRPO变体进行优化，提升VACE和Phantom方法的表现，并通过消融实验评估注释质量及设计对优化策略的影响。

Result: 实验显示，Identity-GRPO在多人物一致性度量上相较基线方法提升了最多18.9%。大量消融实验验证了注释质量和其他设计选择对最终效果的显著影响。

Conclusion: Identity-GRPO显著提升了多人物身份一致性，为基于强化学习的视频个性化生成提供了有效指导，对视频生成技术的实际应用具有重要意义。

Abstract: While advanced methods like VACE and Phantom have advanced video generation
for specific subjects in diverse scenarios, they struggle with multi-human
identity preservation in dynamic interactions, where consistent identities
across multiple characters are critical. To address this, we propose
Identity-GRPO, a human feedback-driven optimization pipeline for refining
multi-human identity-preserving video generation. First, we construct a video
reward model trained on a large-scale preference dataset containing
human-annotated and synthetic distortion data, with pairwise annotations
focused on maintaining human consistency throughout the video. We then employ a
GRPO variant tailored for multi-human consistency, which greatly enhances both
VACE and Phantom. Through extensive ablation studies, we evaluate the impact of
annotation quality and design choices on policy optimization. Experiments show
that Identity-GRPO achieves up to 18.9% improvement in human consistency
metrics over baseline methods, offering actionable insights for aligning
reinforcement learning with personalized video generation.

</details>


### [18] [MatchAttention: Matching the Relative Positions for High-Resolution Cross-View Matching](https://arxiv.org/abs/2510.14260)
*Tingman Yan,Tao Liu,Xilian Yang,Qunfei Zhao,Zeyang Xia*

Main category: cs.CV

TL;DR: 本文提出了一种新的跨视图匹配注意力机制MatchAttention，以及高效的层次化解码器MatchDecoder，显著提升了高分辨率图像下的匹配精度和速度，在多个公开数据集上达到了新的性能纪录。


<details>
  <summary>Details</summary>
Motivation: 针对传统跨注意力机制在高分辨率图像匹配中存在的计算复杂度高、缺乏明确匹配约束的问题，本文提出新方法以提升高分辨率跨视图匹配的效率和准确性。

Method: 1）提出MatchAttention机制，通过动态匹配相对位置，采用BilinearSoftmax实现连续、可微分的滑窗注意力采样，并通过残差连接迭代优化相对位置。2）设计高效的层次化跨视图解码器MatchDecoder，以MatchAttention为核心。3）为应对遮挡问题，引入带门控的cross-MatchAttention和一致性约束损失，提升对遮挡的鲁棒性。

Result: 在多项主流数据集（Middlebury、KITTI 2012/2015、ETH3D、Spring flow）上取得了SOTA性能。MatchStereo-B在Middlebury基准中平均误差排名第一，KITTI分辨率仅需29ms，MatchStereo-T可用3GB显存0.1秒处理4K超高清图像。

Conclusion: 所提出方法兼具高准确度和低计算复杂度，为实时、高分辨率、高精度的跨视图匹配奠定了基础。公开代码支持更广泛应用和复现。

Abstract: Cross-view matching is fundamentally achieved through cross-attention
mechanisms. However, matching of high-resolution images remains challenging due
to the quadratic complexity and lack of explicit matching constraints in the
existing cross-attention. This paper proposes an attention mechanism,
MatchAttention, that dynamically matches relative positions. The relative
position determines the attention sampling center of the key-value pairs given
a query. Continuous and differentiable sliding-window attention sampling is
achieved by the proposed BilinearSoftmax. The relative positions are
iteratively updated through residual connections across layers by embedding
them into the feature channels. Since the relative position is exactly the
learning target for cross-view matching, an efficient hierarchical cross-view
decoder, MatchDecoder, is designed with MatchAttention as its core component.
To handle cross-view occlusions, gated cross-MatchAttention and a
consistency-constrained loss are proposed. These two components collectively
mitigate the impact of occlusions in both forward and backward passes, allowing
the model to focus more on learning matching relationships. When applied to
stereo matching, MatchStereo-B ranked 1st in average error on the public
Middlebury benchmark and requires only 29ms for KITTI-resolution inference.
MatchStereo-T can process 4K UHD images in 0.1 seconds using only 3GB of GPU
memory. The proposed models also achieve state-of-the-art performance on KITTI
2012, KITTI 2015, ETH3D, and Spring flow datasets. The combination of high
accuracy and low computational complexity makes real-time, high-resolution, and
high-accuracy cross-view matching possible. Code is available at
https://github.com/TingmanYan/MatchAttention.

</details>


### [19] [Experimental Demonstration of Event-based Optical Camera Communication in Long-Range Outdoor Environment](https://arxiv.org/abs/2510.14266)
*Miu Sumino,Mayu Ishii,Shun Kaizu,Daisuke Hisano,Yu Nakayama*

Main category: cs.CV

TL;DR: 本文提出了一种用于光学相机通信系统的鲁棒解调方案，结合了事件型视觉传感器、OOK调制、切换解调（toggle demodulation）和数字锁相环，首次在户外实验中实现了低误码率的远距离高速通信。


<details>
  <summary>Details</summary>
Motivation: 在户外环境下，光学相机通信容易受到噪声、光照变化等干扰，如何实现远距离、高速且低误码率的通信是当前亟需解决的问题。

Method: 作者利用事件型视觉传感器，结合OOK调制、切换解调及数字锁相环（digital phase-locked loop, DPLL）技术，以提高信号对噪声和光照变化的鲁棒性，实现高性能解调。

Result: 在户外实验中，作者的方法首次在200米距离下实现了60kbps且误码率低于10^-3，在400米距离下实现了30kbps且误码率低于10^-3。

Conclusion: 该工作验证了提出的解调方法在实际环境下有卓越的鲁棒性与高性能，为光学相机通信系统的户外应用拓展了可能性。

Abstract: We propose a robust demodulation scheme for optical camera communication
systems using an event-based vision sensor, combining OOK with toggle
demodulation and a digital phase-locked loop. This is the first report to
achieve a $\mathrm{BER} < 10^{-3}$ at 200m-60kbps and 400m-30kbps in outdoor
experiments.

</details>


### [20] [GauSSmart: Enhanced 3D Reconstruction through 2D Foundation Models and Geometric Filtering](https://arxiv.org/abs/2510.14270)
*Alexander Valverde,Brian Xu,Yuyin Zhou,Meng Xu,Hongyun Wang*

Main category: cs.CV

TL;DR: 本论文提出了一种新的混合方法GauSSmart，将2D基础模型与3D高斯Splatting结合，提升了稀疏训练数据场景中的重建细节与真实感，在多个数据集上优于现有高斯Splatting方法。


<details>
  <summary>Details</summary>
Motivation: 现有Gaussian Splatting方法在处理稀疏训练数据时难以捕捉精细细节和维持真实性。为解决该问题，需要充分利用2D视觉模型的优势来提升3D重建效果。

Method: 作者提出GauSSmart方法，将2D计算机视觉技术（如凸过滤和DINO等基础模型的语义特征监督）与3D高斯Splatting重建相结合。通过引入2D分割先验与高维特征嵌入，引导高斯点的密化和细化，提升对结构复杂或覆盖稀疏区域的重建能力。

Result: 在三个数据集上的实验结果显示，GauSSmart在大多数场景中均实现了优于现有Gaussian Splatting方法的重建性能。

Conclusion: 融合2D基础模型与3D重建流程的方法能有效克服二者各自的局限性，展现了2D-3D混合方法在场景重建领域的巨大潜力。

Abstract: Scene reconstruction has emerged as a central challenge in computer vision,
with approaches such as Neural Radiance Fields (NeRF) and Gaussian Splatting
achieving remarkable progress. While Gaussian Splatting demonstrates strong
performance on large-scale datasets, it often struggles to capture fine details
or maintain realism in regions with sparse coverage, largely due to the
inherent limitations of sparse 3D training data.
  In this work, we propose GauSSmart, a hybrid method that effectively bridges
2D foundational models and 3D Gaussian Splatting reconstruction. Our approach
integrates established 2D computer vision techniques, including convex
filtering and semantic feature supervision from foundational models such as
DINO, to enhance Gaussian-based scene reconstruction. By leveraging 2D
segmentation priors and high-dimensional feature embeddings, our method guides
the densification and refinement of Gaussian splats, improving coverage in
underrepresented areas and preserving intricate structural details.
  We validate our approach across three datasets, where GauSSmart consistently
outperforms existing Gaussian Splatting in the majority of evaluated scenes.
Our results demonstrate the significant potential of hybrid 2D-3D approaches,
highlighting how the thoughtful combination of 2D foundational models with 3D
reconstruction pipelines can overcome the limitations inherent in either
approach alone.

</details>


### [21] [CLEAR: Causal Learning Framework For Robust Histopathology Tumor Detection Under Out-Of-Distribution Shifts](https://arxiv.org/abs/2510.14273)
*Kieu-Anh Truong Thi,Huy-Hieu Pham,Duc-Trong Le*

Main category: cs.CV

TL;DR: 该论文提出了一种基于因果推断的新框架，通过引入中介变量以及组织切片观测来减少混杂因子的影响，在病理图像跨域泛化任务上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统应对病理图像领域偏移的方法多着重于特征分布对齐或引入统计变异，忽视了因果关系，导致模型在新域下泛化能力不足。因此，需要一种更关注因果机制的方法来增强模型在不同数据源间的泛化效果。

Method: 设计了一种遵循front-door原则的转化策略，显式引入中介变量和观测组织切片，通过因果推断方法降低混杂因子的影响。并在CAMELYON17公共数据集及一个私有病理数据集上进行了验证。

Result: 方法在CAMELYON17和私有数据集上的跨域泛化能力均有提升，最高提升达7%，优于现有基线方法。

Conclusion: 结合因果推断的框架能够更有效地缓解病理图像分析中的领域偏移问题，因果推断方法具有应用潜力。

Abstract: Domain shift in histopathology, often caused by differences in acquisition
processes or data sources, poses a major challenge to the generalization
ability of deep learning models. Existing methods primarily rely on modeling
statistical correlations by aligning feature distributions or introducing
statistical variation, yet they often overlook causal relationships. In this
work, we propose a novel causal-inference-based framework that leverages
semantic features while mitigating the impact of confounders. Our method
implements the front-door principle by designing transformation strategies that
explicitly incorporate mediators and observed tissue slides. We validate our
method on the CAMELYON17 dataset and a private histopathology dataset,
demonstrating consistent performance gains across unseen domains. As a result,
our approach achieved up to a 7% improvement in both the CAMELYON17 dataset and
the private histopathology dataset, outperforming existing baselines. These
results highlight the potential of causal inference as a powerful tool for
addressing domain shift in histopathology image analysis.

</details>


### [22] [Watermarking for Factuality: Guiding Vision-Language Models Toward Truth via Tri-layer Contrastive Decoding](https://arxiv.org/abs/2510.14304)
*Kyungryul Back,Seongbeom Park,Milim Kim,Mincheol Kwon,SangHyeok Lee,Hyunyoung Lee,Junhee Cho,Seunghyun Park,Jinkyu Kim*

Main category: cs.CV

TL;DR: 论文提出了一种训练免、不需要额外训练的三层对比解码（tri-layer contrastive decoding）方法，并结合水印问题用于减少大型视觉-语言模型（LVLMs）在多模态任务中的幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 虽然大型视觉-语言模型在多种多模态任务中表现优异，甚至能媲美人类，但依然容易产生幻觉（比如过度依赖单一模态、死记训练数据、不基于实际视觉内容输出）。解决LVLM幻觉问题是提升其实用性的关键。

Method: 作者提出了一种三步走的对比解码方案：1. 从解码层中各选出一个成熟层和一个新手层；2. 通过与水印相关的问题定位具备良好视觉扎根能力的枢纽层；3. 对这三层应用对比解码生成最终输出，方法完全不需要重新训练模型。

Result: 该方法在POPE、MME、AMBER等公开多模态基准测试上，大幅减少了LVLM的幻觉输出，并提升了视觉扎根型回答的比例，达到了目前最优的性能。

Conclusion: 本文提出的训练免三层对比解码加水印评测的方案，有效缓解了大型视觉-语言模型的幻觉问题，让输出结果更加可靠和有视觉依据。

Abstract: Large Vision-Language Models (LVLMs) have recently shown promising results on
various multimodal tasks, even achieving human-comparable performance in
certain cases. Nevertheless, LVLMs remain prone to hallucinations -- they often
rely heavily on a single modality or memorize training data without properly
grounding their outputs. To address this, we propose a training-free, tri-layer
contrastive decoding with watermarking, which proceeds in three steps: (1)
select a mature layer and an amateur layer among the decoding layers, (2)
identify a pivot layer using a watermark-related question to assess whether the
layer is visually well-grounded, and (3) apply tri-layer contrastive decoding
to generate the final output. Experiments on public benchmarks such as POPE,
MME and AMBER demonstrate that our method achieves state-of-the-art performance
in reducing hallucinations in LVLMs and generates more visually grounded
responses.

</details>


### [23] [A Multi-domain Image Translative Diffusion StyleGAN for Iris Presentation Attack Detection](https://arxiv.org/abs/2510.14314)
*Shivangi Yadav,Arun Ross*

Main category: cs.CV

TL;DR: 该论文提出了一种新方法MID-StyleGAN，可以生成多领域虹膜图像（包括攻击样本和真实样本），缓解虹膜活体检测（PAD）中数据不足的问题，并提升了PAD性能。


<details>
  <summary>Details</summary>
Motivation: 虹膜生物识别系统容易受到伪造攻击（如假眼、打印眼图、彩色隐形眼镜），但由于构建和采集伪攻击样本有难度，虹膜活体检测（PAD）方法缺乏充足数据进行训练。

Method: 提出了MID-StyleGAN框架，将扩散模型与生成对抗网络（GAN）结合，通过多领域架构能够在多类型虹膜领域（真实、打印、彩色隐形眼镜）间相互转换生成合成图像。模型还采用了针对虹膜数据设计的自适应损失函数，保证多领域间的一致性。

Result: MID-StyleGAN在生成高质量多样化的虹膜图像方面优于现有方法。利用生成数据训练PAD系统可大幅提升其性能，如LivDet2020数据集上，1%假检率下的真实检测率由93.41%提升至98.72%。

Conclusion: MID-StyleGAN是一种可扩展且有效的虹膜和眼部活体检测数据合成方法，可缓解数据稀缺问题，并显著提高PAD系统的检测性能。

Abstract: An iris biometric system can be compromised by presentation attacks (PAs)
where artifacts such as artificial eyes, printed eye images, or cosmetic
contact lenses are presented to the system. To counteract this, several
presentation attack detection (PAD) methods have been developed. However, there
is a scarcity of datasets for training and evaluating iris PAD techniques due
to the implicit difficulties in constructing and imaging PAs. To address this,
we introduce the Multi-domain Image Translative Diffusion StyleGAN
(MID-StyleGAN), a new framework for generating synthetic ocular images that
captures the PA and bonafide characteristics in multiple domains such as
bonafide, printed eyes and cosmetic contact lens. MID-StyleGAN combines the
strengths of diffusion models and generative adversarial networks (GANs) to
produce realistic and diverse synthetic data. Our approach utilizes a
multi-domain architecture that enables the translation between bonafide ocular
images and different PA domains. The model employs an adaptive loss function
tailored for ocular data to maintain domain consistency. Extensive experiments
demonstrate that MID-StyleGAN outperforms existing methods in generating
high-quality synthetic ocular images. The generated data was used to
significantly enhance the performance of PAD systems, providing a scalable
solution to the data scarcity problem in iris and ocular biometrics. For
example, on the LivDet2020 dataset, the true detect rate at 1% false detect
rate improved from 93.41% to 98.72%, showcasing the impact of the proposed
method.

</details>


### [24] [Vision-Centric Activation and Coordination for Multimodal Large Language Models](https://arxiv.org/abs/2510.14349)
*Yunnan Wang,Fan Lu,Kecheng Zheng,Ziyuan Huang,Ziqiang Li,Wenjun Zeng,Xin Jin*

Main category: cs.CV

TL;DR: 现有多模态大语言模型（MLLM）主要依赖文本预测训练，忽视了视觉信息。论文提出VaCo方法，通过集成多种视觉基础模型的感知特征，加强视觉激活和协调，显著提升了MLLM的视觉理解与任务执行能力。


<details>
  <summary>Details</summary>
Motivation: 主流MLLM只通过文本token预测作为监督，导致缺乏足够的视觉分析能力。为提升视觉相关任务的表现，作者希望引入更多视觉中心的信息与处理机制。

Method: 提出VaCo框架，包含两大创新：1）将多视觉基础模型（VFM）提取的任务相关视觉特征，通过视觉判别对齐（Visual Discriminative Alignment）整合进MLLM；2）引入可学习的模块化任务查询（MTQ）和视觉对齐层（VAL），在多VFM监督下激活特定视觉信号，同时用Token Gateway Mask（TGM）机制协调多组MTQ的信息流，避免冲突。

Result: 大量实验证明，VaCo方法在多项视觉理解基准测试上，均使不同类型的MLLM获得显著性能提升。

Conclusion: VaCo能够兼顾文本和视觉信息优化，解决了现有MLLM视觉分析能力弱的缺陷，对提升多模态模型的视觉理解能力具有突出成效。

Abstract: Multimodal large language models (MLLMs) integrate image features from visual
encoders with LLMs, demonstrating advanced comprehension capabilities. However,
mainstream MLLMs are solely supervised by the next-token prediction of textual
tokens, neglecting critical vision-centric information essential for analytical
abilities. To track this dilemma, we introduce VaCo, which optimizes MLLM
representations through Vision-Centric activation and Coordination from
multiple vision foundation models (VFMs). VaCo introduces visual discriminative
alignment to integrate task-aware perceptual features extracted from VFMs,
thereby unifying the optimization of both textual and visual outputs in MLLMs.
Specifically, we incorporate the learnable Modular Task Queries (MTQs) and
Visual Alignment Layers (VALs) into MLLMs, activating specific visual signals
under the supervision of diverse VFMs. To coordinate representation conflicts
across VFMs, the crafted Token Gateway Mask (TGM) restricts the information
flow among multiple groups of MTQs. Extensive experiments demonstrate that VaCo
significantly improves the performance of different MLLMs on various
benchmarks, showcasing its superior capabilities in visual comprehension.

</details>


### [25] [Leveraging Cycle-Consistent Anchor Points for Self-Supervised RGB-D Registration](https://arxiv.org/abs/2510.14354)
*Siddharth Tourani,Jayaram Reddy,Sarvesh Thakur,K Madhava Krishna,Muhammad Haris Khan,N Dinesh Reddy*

Main category: cs.CV

TL;DR: 本文提出了一种基于循环一致性关键点和新颖位姿模块的方法，用于改进RGB-D场景几何配准，在现有自监督配准任务上取得了优异效果。


<details>
  <summary>Details</summary>
Motivation: 消费级深度相机普及带来了大量无标注RGB-D数据，如何高效利用这些数据进行场景几何推理成为研究挑战。

Method: 本方法通过循环一致性关键点作为显著点来强化空间连贯性约束，提升关键点匹配的准确性。同时，创新性地引入结合GRU单元与变换同步的位姿块，将历史信息与多视图数据融合，用于增强配准模型能力。

Result: 该方法在ScanNet和3DMatch数据集上超过了已有自监督配准方法，并优于部分传统的有监督方法。将提出的组件集成至现有方法后也能显著提升性能。

Conclusion: 循环一致性关键点与创新位姿块可有效提升RGB-D自监督配准精度，为利用无标注数据开展几何场景推理提供了新思路。

Abstract: With the rise in consumer depth cameras, a wealth of unlabeled RGB-D data has
become available. This prompts the question of how to utilize this data for
geometric reasoning of scenes. While many RGB-D registration meth- ods rely on
geometric and feature-based similarity, we take a different approach. We use
cycle-consistent keypoints as salient points to enforce spatial coherence
constraints during matching, improving correspondence accuracy. Additionally,
we introduce a novel pose block that combines a GRU recurrent unit with
transformation synchronization, blending historical and multi-view data. Our
approach surpasses previous self- supervised registration methods on ScanNet
and 3DMatch, even outperforming some older supervised methods. We also
integrate our components into existing methods, showing their effectiveness.

</details>


### [26] [Spatial Preference Rewarding for MLLMs Spatial Understanding](https://arxiv.org/abs/2510.14374)
*Han Qiu,Peng Gao,Lewei Lu,Xiaoqin Zhang,Ling Shao,Shijian Lu*

Main category: cs.CV

TL;DR: 本论文提出了一种名为SPR（Spatial Preference Rewarding）的新方法，用于提升多模态大模型（MLLMs）在细粒度空间理解方面的能力，通过奖励对图像区域更精准和详细的定位描述，有效增强模型空间感知性能。


<details>
  <summary>Details</summary>
Motivation: 尽管现有多模态大模型在空间理解能力上取得了进展，如指代和目标定地，但它们在细粒度空间感知（如详细描述区域，精确定位目标）方面表现不足，且难以满足用户对高细粒度空间认知的需求。这主要是因为现有方法只专注于基于预标注数据的微调，缺乏针对模型输出的直接监督。

Method: 作者提出SPR方法，针对MLLM生成的图像区域及描述，通过结合语义分数和定位分数进行全面评价，以此奖励那些语义丰富且定位准确的描述。此外，SPR进一步对描述进行精细化优化，并采用分数最优和最劣配对直接进行偏好优化，从而提升模型与视觉输入的细粒度对齐能力。

Result: 在多个主流指代与定地基准上，SPR方法显著提升了MLLM的空间理解能力，而且训练过程附加开销极小。

Conclusion: SPR为提升MLLM的细粒度空间感知与定位能力提供了有效方案，有助于更好地满足现实场景下对空间感知的高要求。相关数据与代码会公开发布以促进领域发展。

Abstract: Multimodal large language models~(MLLMs) have demonstrated promising spatial
understanding capabilities, such as referencing and grounding object
descriptions. Despite their successes, MLLMs still fall short in fine-grained
spatial perception abilities, such as generating detailed region descriptions
or accurately localizing objects. Additionally, they often fail to respond to
the user's requirements for desired fine-grained spatial understanding. This
issue might arise because existing approaches primarily focus on tuning MLLMs
to model pre-annotated instruction data to inject spatial knowledge, without
direct supervision of MLLMs' actual responses. We address this issue by SPR, a
Spatial Preference Rewarding~(SPR) approach that enhances MLLMs' spatial
capabilities by rewarding MLLMs' detailed responses with precise object
localization over vague or inaccurate responses. With randomly selected image
regions and region descriptions from MLLMs, SPR introduces semantic and
localization scores to comprehensively evaluate the text quality and
localization quality in MLLM-generated descriptions. We also refine the MLLM
descriptions with better localization accuracy and pair the best-scored
refinement with the initial descriptions of the lowest score for direct
preference optimization, thereby enhancing fine-grained alignment with visual
input. Extensive experiments over standard referring and grounding benchmarks
show that SPR improves MLLM spatial understanding capabilities effectively with
minimal overhead in training. Data and code will be released at
https://github.com/hanqiu-hq/SPR

</details>


### [27] [DOS: Directional Object Separation in Text Embeddings for Multi-Object Image Generation](https://arxiv.org/abs/2510.14376)
*Dongnam Byun,Jungwon Park,Jumgmin Ko,Changin Choi,Wonjong Rhee*

Main category: cs.CV

TL;DR: 本文提出了一种名为DOS（Directional Object Separation）的新方法，通过修改CLIP文本嵌入，有效提升了文本生成多物体图像的能力，并在多种基准测试和人工评估中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管目前文本生成图像模型（T2I）在高质量成像和文本对齐等方面取得了进展，但针对包含多个物体的文本提示仍易出现物体丢失或混淆。作者发现多物体成像中存在四种常见失败场景：相似形状、相似纹理、不同背景偏差及多物体，本研究旨在解决这些问题。

Method: 作者基于观察到的CLIP嵌入特性，提出DOS方法，通过在输入T2I模型前定向修改三种CLIP文本嵌入，改变物体间的关系表达，从而缓解物体混淆和丢失问题。

Result: 实验显示，DOS方法在多物体图像生成中大幅提高了成功率，显著减少了物体混合现象。在人工评测中，DOS在四个基准上的优选票数比其他四种方法高出26.24%至43.04%。

Conclusion: DOS是一种实用且有效的方法，可显著提升多物体文本到图像生成的表现，对于提升实际应用中多物体场景的生成质量具有重要意义。

Abstract: Recent progress in text-to-image (T2I) generative models has led to
significant improvements in generating high-quality images aligned with text
prompts. However, these models still struggle with prompts involving multiple
objects, often resulting in object neglect or object mixing. Through extensive
studies, we identify four problematic scenarios, Similar Shapes, Similar
Textures, Dissimilar Background Biases, and Many Objects, where inter-object
relationships frequently lead to such failures. Motivated by two key
observations about CLIP embeddings, we propose DOS (Directional Object
Separation), a method that modifies three types of CLIP text embeddings before
passing them into text-to-image models. Experimental results show that DOS
consistently improves the success rate of multi-object image generation and
reduces object mixing. In human evaluations, DOS significantly outperforms four
competing methods, receiving 26.24%-43.04% more votes across four benchmarks.
These results highlight DOS as a practical and effective solution for improving
multi-object image generation.

</details>


### [28] [DRBD-Mamba for Robust and Efficient Brain Tumor Segmentation with Analytical Insights](https://arxiv.org/abs/2510.14383)
*Danish Ali,Ajmal Mian,Naveed Akhtar,Ghulam Mubashar Hassan*

Main category: cs.CV

TL;DR: 本文提出了DRBD-Mamba模型，在保证高分割精度的同时显著提升了脑肿瘤分割任务的计算效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前脑肿瘤分割因肿瘤区域的异质性而十分具有挑战性。虽然Mamba等状态空间模型（SSM）表现良好，但它们计算量大且鲁棒性评测不充分，影响了实际应用。

Method: 提出了一种高效的三维分割模型DRBD-Mamba，通过空间填充曲线实现空间局部性保持，减少多轴特征计算以提升效率。提出门控融合模块和量化块，以丰富特征表达和提升鲁棒性；并设计五折分割系统性评测，详细分析模型在不同条件下表现。

Result: 在BraTS2023数据集20%测试集上，DRBD-Mamba模型相比已有方法在整个肿瘤、肿瘤核心、增强肿瘤Dice系数分别提升0.10%、1.75%、0.93%。在提出的五折评测中，对肿瘤核心和增强肿瘤的平均Dice分别提升0.86%、1.45%，同时效率提升15倍。

Conclusion: DRBD-Mamba兼顾分割精度和计算效率，在多种数据划分中表现稳定且鲁棒，优于当前主流方法，适合实际临床应用。

Abstract: Accurate brain tumor segmentation is significant for clinical diagnosis and
treatment. It is challenging due to the heterogeneity of tumor subregions.
Mamba-based State Space Models have demonstrated promising performance.
However, they incur significant computational overhead due to sequential
feature computation across multiple spatial axes. Moreover, their robustness
across diverse BraTS data partitions remains largely unexplored, leaving a
critical gap in reliable evaluation. To address these limitations, we propose
dual-resolution bi-directional Mamba (DRBD-Mamba), an efficient 3D segmentation
model that captures multi-scale long-range dependencies with minimal
computational overhead. We leverage a space-filling curve to preserve spatial
locality during 3D-to-1D feature mapping, thereby reducing reliance on
computationally expensive multi-axial feature scans. To enrich feature
representation, we propose a gated fusion module that adaptively integrates
forward and reverse contexts, along with a quantization block that discretizes
features to improve robustness. In addition, we propose five systematic folds
on BraTS2023 for rigorous evaluation of segmentation techniques under diverse
conditions and present detailed analysis of common failure scenarios. On the
20\% test set used by recent methods, our model achieves Dice improvements of
0.10\% for whole tumor, 1.75\% for tumor core, and 0.93\% for enhancing tumor.
Evaluations on the proposed systematic five folds demonstrate that our model
maintains competitive whole tumor accuracy while achieving clear average Dice
gains of 0.86\% for tumor core and 1.45\% for enhancing tumor over existing
state-of-the-art. Furthermore, our model attains 15 times improvement in
efficiency while maintaining high segmentation accuracy, highlighting its
robustness and computational advantage over existing approaches.

</details>


### [29] [BoardVision: Deployment-ready and Robust Motherboard Defect Detection with YOLO+Faster-RCNN Ensemble](https://arxiv.org/abs/2510.14389)
*Brandon Hill,Kma Solaiman*

Main category: cs.CV

TL;DR: 论文提出了一套针对主板装配层级缺陷检测的完整框架，比较了YOLOv7和Faster R-CNN两种方法，并提出CTV Voter集成方法以提升检测性能，同时发布了易用的工具。


<details>
  <summary>Details</summary>
Motivation: 以往PCB缺陷检测多集中于裸板或线路层，而组装好后主板的缺陷检测（如螺丝缺失、风扇线松动、表面划痕）被忽略，但这对于生产可靠性极为关键。作者希望填补该领域系统性研究的空白，并提供可应用到实际工厂的工具。

Method: 作者构建了BoardVision框架，用MiracleFactory数据集分别用YOLOv7和Faster R-CNN两类主流检测器进行对比实验。针对单模型精度与召回难以兼顾的问题，提出轻量级集成方法CTV Voter，通过置信度和时序投票规则平衡性能。此外，模拟现实条件下的多种干扰进行稳健性评估，并开发了用户友好的可视化检测工具。

Result: 在对比实验中，YOLOv7在检测精度上优于Faster R-CNN，但召回率较低，Faster R-CNN则相反。CTV Voter有效提升整体F1分数，实现了精度与召回的平衡。在不同拍摄条件的鲁棒性评估中，揭示了现有模型在实际工厂环境下的挑战性。

Conclusion: 本工作不仅验证了现有目标检测算法在主板装配瑕疵检测中的适用性，还通过集成方法进一步提升了性能，最终开发了可以落地的检测工具，对工厂生产具有实际指导和应用价值。

Abstract: Motherboard defect detection is critical for ensuring reliability in
high-volume electronics manufacturing. While prior research in PCB inspection
has largely targeted bare-board or trace-level defects, assembly-level
inspection of full motherboards inspection remains underexplored. In this work,
we present BoardVision, a reproducible framework for detecting assembly-level
defects such as missing screws, loose fan wiring, and surface scratches. We
benchmark two representative detectors - YOLOv7 and Faster R-CNN, under
controlled conditions on the MiracleFactory motherboard dataset, providing the
first systematic comparison in this domain. To mitigate the limitations of
single models, where YOLO excels in precision but underperforms in recall and
Faster R-CNN shows the reverse, we propose a lightweight ensemble,
Confidence-Temporal Voting (CTV Voter), that balances precision and recall
through interpretable rules. We further evaluate robustness under realistic
perturbations including sharpness, brightness, and orientation changes,
highlighting stability challenges often overlooked in motherboard defect
detection. Finally, we release a deployable GUI-driven inspection tool that
bridges research evaluation with operator usability. Together, these
contributions demonstrate how computer vision techniques can transition from
benchmark results to practical quality assurance for assembly-level motherboard
manufacturing.

</details>


### [30] [DCMIL: A Progressive Representation Learning Model of Whole Slide Images for Cancer Prognosis Analysis](https://arxiv.org/abs/2510.14403)
*Chao Tu,Kun Huang,Jie Zhang,Qianjin Feng,Yu Zhang,Zhenyuan Ning*

Main category: cs.CV

TL;DR: 本文提出了一种新型的无密集标注需求的分步学习模型 DCMIL，可高效处理WSI实现癌症预后预测，在多个癌种实验中明显优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于WSI的癌症智能诊断和预后受限于巨量图像数据计算瓶颈和缺乏密集人工标注，且现有方法对多倍率下的细粒度信息和肿瘤微环境变化利用不足。

Method: 提出了一种易到难的分步表征学习模型——双课程对比多实例学习（DCMIL），无需依赖密集标注，即可直接将超大尺寸WSI转化为病人结局预测。
方法侧重于多倍率信息融合和难易样本的递进式学习。

Result: 在12种癌症类型（5954名患者，1254万块小图）的大规模实验中，DCMIL在预后预测表现优于常规WSI模型。
同时模型能识别细粒度关键区域，具备实例不确定性评估、区分肿瘤与正常组织形态差异等能力。

Conclusion: DCMIL模型不仅提升了WSI预后模型的预测准确度和可解释性，还为探索肿瘤新生物学机制提供工具，其代码已全部公开。

Abstract: The burgeoning discipline of computational pathology shows promise in
harnessing whole slide images (WSIs) to quantify morphological heterogeneity
and develop objective prognostic modes for human cancers. However, progress is
impeded by the computational bottleneck of gigapixel-size inputs and the
scarcity of dense manual annotations. Current methods often overlook
fine-grained information across multi-magnification WSIs and variations in
tumor microenvironments. Here, we propose an easy-to-hard progressive
representation learning model, termed dual-curriculum contrastive
multi-instance learning (DCMIL), to efficiently process WSIs for cancer
prognosis. The model does not rely on dense annotations and enables the direct
transformation of gigapixel-size WSIs into outcome predictions. Extensive
experiments on twelve cancer types (5,954 patients, 12.54 million tiles)
demonstrate that DCMIL outperforms standard WSI-based prognostic models.
Additionally, DCMIL identifies fine-grained prognosis-salient regions, provides
robust instance uncertainty estimation, and captures morphological differences
between normal and tumor tissues, with the potential to generate new biological
insights. All codes have been made publicly accessible at
https://github.com/tuuuc/DCMIL.

</details>


### [31] [Real-Time Neural Video Compression with Unified Intra and Inter Coding](https://arxiv.org/abs/2510.14431)
*Hui Xiang,Yifan Bian,Li Li,Jingran Wu,Xianguo Zhang,Dong Liu*

Main category: cs.CV

TL;DR: 本文提出了一种统一帧内和帧间编码的神经视频压缩（NVC）新架构，通过引入自适应帧内/帧间编码和双帧压缩设计，大幅提升了压缩效率和视频质量。


<details>
  <summary>Details</summary>
Motivation: 尽管现有的神经视频压缩技术如DCVC-RT在压缩率和实时性能上已超越传统方法，但它们在消隐、处理新内容以及帧间误差传播等方面存在不足。因此，作者希望通过借鉴经典视频编码中帧内编码的思想解决上述痛点。

Method: 作者提出将帧内编码与帧间编码统一到一个神经网络模型中，使每一帧根据内容自适应选择编码方式，并设计了同时压缩两帧以前向和后向地挖掘冗余的新机制，从而更有效地处理消隐、新内容与误差传播。

Result: 实验结果显示，该方法相比DCVC-RT平均降低了10.7%的BD-rate，并在帧质量与码率稳定性上均有提升，同时保持了实时编码解码速度。

Conclusion: 通过引入帧内/帧间统一自适应编码和双帧压缩，本文的方法有效克服了现有NVC的一些关键限制，显著提升了压缩性能和稳定性，有望推动后续神经视频压缩的发展。

Abstract: Neural video compression (NVC) technologies have advanced rapidly in recent
years, yielding state-of-the-art schemes such as DCVC-RT that offer superior
compression efficiency to H.266/VVC and real-time encoding/decoding
capabilities. Nonetheless, existing NVC schemes have several limitations,
including inefficiency in dealing with disocclusion and new content, interframe
error propagation and accumulation, among others. To eliminate these
limitations, we borrow the idea from classic video coding schemes, which allow
intra coding within inter-coded frames. With the intra coding tool enabled,
disocclusion and new content are properly handled, and interframe error
propagation is naturally intercepted without the need for manual refresh
mechanisms. We present an NVC framework with unified intra and inter coding,
where every frame is processed by a single model that is trained to perform
intra/inter coding adaptively. Moreover, we propose a simultaneous two-frame
compression design to exploit interframe redundancy not only forwardly but also
backwardly. Experimental results show that our scheme outperforms DCVC-RT by an
average of 10.7\% BD-rate reduction, delivers more stable bitrate and quality
per frame, and retains real-time encoding/decoding performances. Code and
models will be released.

</details>


### [32] [Structured Universal Adversarial Attacks on Object Detection for Video Sequences](https://arxiv.org/abs/2510.14460)
*Sven Jacob,Weijia Shao,Gjergji Kasneci*

Main category: cs.CV

TL;DR: 提出了一种针对视频对象检测的最小扰动通用对抗攻击，通过核范数正则化，使扰动结构化并集中于背景，并提出自适应乐观的指数梯度方法以优化攻击效率和效果。实验表明，该方法在有效性和隐蔽性上优于现有主流低秩或Frank-Wolfe方法。


<details>
  <summary>Details</summary>
Motivation: 深度学习的视频目标检测在安全关键场景中应用广泛，但对抗攻击风险较大，尤其是通用对抗扰动更具威胁性。因此，需要设计更有效且隐蔽的对抗攻击方法，以评估和提升检测模型的鲁棒性。

Method: 该方法提出在对抗扰动优化过程中引入核范数正则化，使扰动低秩且更具结构、主要集中于视频背景区域。同时，利用自适应的乐观指数梯度优化算法，提高优化效率和收敛速度。

Result: 实验结果显示，该方法在生成的对抗扰动效果和隐蔽性上，均优于低秩投影梯度法和Frank-Wolfe方法。相关代码和数据集也已开源。

Conclusion: 该文提出的通用对抗攻击方法能高效产生结构化且隐蔽的扰动，提升了对现有视频目标检测方法鲁棒性的考验强度，为提升安全性带来新的工具和思路。

Abstract: Video-based object detection plays a vital role in safety-critical
applications. While deep learning-based object detectors have achieved
impressive performance, they remain vulnerable to adversarial attacks,
particularly those involving universal perturbations. In this work, we propose
a minimally distorted universal adversarial attack tailored for video object
detection, which leverages nuclear norm regularization to promote structured
perturbations concentrated in the background. To optimize this formulation
efficiently, we employ an adaptive, optimistic exponentiated gradient method
that enhances both scalability and convergence. Our results demonstrate that
the proposed attack outperforms both low-rank projected gradient descent and
Frank-Wolfe based attacks in effectiveness while maintaining high stealthiness.
All code and data are publicly available at
https://github.com/jsve96/AO-Exp-Attack.

</details>


### [33] [Unsupervised Deep Generative Models for Anomaly Detection in Neuroimaging: A Systematic Scoping Review](https://arxiv.org/abs/2510.14462)
*Youwan Mahé,Elise Bannier,Stéphanie Leplaideur,Elisa Fromont,Francesca Galassi*

Main category: cs.CV

TL;DR: 本文综述了无监督深度生成模型在神经影像异常检测中的应用，涵盖不同模型及评测，总结其优势和未来挑战。


<details>
  <summary>Details</summary>
Motivation: 当前脑部异常检测多依赖标注充分的监督方法，但真实临床中大规模像素级标注稀缺，且监督方法局限于已知病变。无监督生成模型作为新兴替代方案，仅需健康数据即可实现异常检测，有望突破现有限制。

Method: 采用PRISMA流程对2018-2025年间相关文献进行系统性回顾，涵盖自编码器、变分自编码器、生成对抗网络及去噪扩散模型，比较其在MRI/CT多种脑病中的检测和分割能力，并分析架构选择对性能影响。

Result: 综述的49项研究显示，生成模型在检测较大病灶时表现优异，对微小异常的能力持续提高。生成模型能生成伪健康反事实重建，便于无标注数据下解释与分析。

Conclusion: 无监督生成模型在神经影像异常检测领域前景广阔，支持半监督学习和新型生物标志物挖掘，推荐未来聚焦解剖结构感知建模、基础模型开发、恰当指标选取及临床验证。

Abstract: Unsupervised deep generative models are emerging as a promising alternative
to supervised methods for detecting and segmenting anomalies in brain imaging.
Unlike fully supervised approaches, which require large voxel-level annotated
datasets and are limited to well-characterised pathologies, these models can be
trained exclusively on healthy data and identify anomalies as deviations from
learned normative brain structures. This PRISMA-guided scoping review
synthesises recent work on unsupervised deep generative models for anomaly
detection in neuroimaging, including autoencoders, variational autoencoders,
generative adversarial networks, and denoising diffusion models. A total of 49
studies published between 2018 - 2025 were identified, covering applications to
brain MRI and, less frequently, CT across diverse pathologies such as tumours,
stroke, multiple sclerosis, and small vessel disease. Reported performance
metrics are compared alongside architectural design choices. Across the
included studies, generative models achieved encouraging performance for large
focal lesions and demonstrated progress in addressing more subtle
abnormalities. A key strength of generative models is their ability to produce
interpretable pseudo-healthy (also referred to as counterfactual)
reconstructions, which is particularly valuable when annotated data are scarce,
as in rare or heterogeneous diseases. Looking ahead, these models offer a
compelling direction for anomaly detection, enabling semi-supervised learning,
supporting the discovery of novel imaging biomarkers, and facilitating within-
and cross-disease deviation mapping in unified end-to-end frameworks. To
realise clinical impact, future work should prioritise anatomy-aware modelling,
development of foundation models, task-appropriate evaluation metrics, and
rigorous clinical validation.

</details>


### [34] [Pruning Overparameterized Multi-Task Networks for Degraded Web Image Restoration](https://arxiv.org/abs/2510.14463)
*Thomas Katraouras,Dimitrios Rafailidis*

Main category: cs.CV

TL;DR: 本文提出了一种新方法MIR-L，通过迭代剪枝技术有效压缩多任务图像复原模型，显著减少参数数量而性能几乎不降；在去雨、去雾、去噪等任务上仅用原模型10%的参数即实现近似或超越当前最优水平。


<details>
  <summary>Details</summary>
Motivation: 现有多任务图像复原模型虽然能同时应对多种退化，但往往参数量冗余，带来计算和部署上的高成本，需要更高效的模型结构。

Method: MIR-L通过迭代式剪枝，逐步移除权重较小的参数，保留其余参数并重置到初始权重，每轮持续优化，最终发现高稀疏、高效能的子网络（即“winning tickets”）。

Result: 在去雨、去雾、去噪标准数据集上，MIR-L模型仅保留原模型10%的参数，仍能达到甚至超过稠密模型的性能。

Conclusion: MIR-L有效缓解多任务复原模型过度参数化问题，大幅提高模型效率且保证高性能，为高效图像复原应用提供了实用方案。

Abstract: Image quality is a critical factor in delivering visually appealing content
on web platforms. However, images often suffer from degradation due to lossy
operations applied by online social networks (OSNs), negatively affecting user
experience. Image restoration is the process of recovering a clean high-quality
image from a given degraded input. Recently, multi-task (all-in-one) image
restoration models have gained significant attention, due to their ability to
simultaneously handle different types of image degradations. However, these
models often come with an excessively high number of trainable parameters,
making them computationally inefficient. In this paper, we propose a strategy
for compressing multi-task image restoration models. We aim to discover highly
sparse subnetworks within overparameterized deep models that can match or even
surpass the performance of their dense counterparts. The proposed model, namely
MIR-L, utilizes an iterative pruning strategy that removes low-magnitude
weights across multiple rounds, while resetting the remaining weights to their
original initialization. This iterative process is important for the multi-task
image restoration model's optimization, effectively uncovering "winning
tickets" that maintain or exceed state-of-the-art performance at high sparsity
levels. Experimental evaluation on benchmark datasets for the deraining,
dehazing, and denoising tasks shows that MIR-L retains only 10% of the
trainable parameters while maintaining high image restoration performance. Our
code, datasets and pre-trained models are made publicly available at
https://github.com/Thomkat/MIR-L.

</details>


### [35] [Grazing Detection using Deep Learning and Sentinel-2 Time Series Data](https://arxiv.org/abs/2510.14493)
*Aleksis Pirinen,Delia Fano Yela,Smita Chakraborty,Erik Källman*

Main category: cs.CV

TL;DR: 本文利用哨兵-2卫星多时序遥感数据，并结合CNN-LSTM深度学习模型，实现了大面积放牧行为的自动监测和检测。通过对田块进行‘是否放牧’的二分类，显著提高了农田放牧情况的检测效率与准确性。


<details>
  <summary>Details</summary>
Motivation: 放牧活动对农业生产和生物多样性有深远影响，但目前大范围、可扩展的放牧监测手段有限。提升监测能力对农业管理和环境保护至关重要。

Method: 采用哨兵-2 L2A级遥感影像，在4-10月期间收集每个田块的时序反射率特征，基于此训练了CNN-LSTM集成模型，实现对田块是否放牧的二分类预测。并设置了五折交叉验证，评估模型性能。

Result: 模型在五折验证中取得了77%的平均F1分数，对放牧草地的召回率高达90%。在实际巡查资源有限（只能现场检查4%地点）的情况下，优先巡查模型预测为‘未放牧’的田块能够让确认非放牧地点的数量提升到随机巡查的17.2倍。

Conclusion: 免费、中分辨率卫星遥感数据结合深度学习可有效、大规模监测农田放牧行为，极大提升了监管部门资源分配效率，并为保护型土地利用合规监管提供了可靠工具。相关代码和模型已开放。

Abstract: Grazing shapes both agricultural production and biodiversity, yet scalable
monitoring of where grazing occurs remains limited. We study seasonal grazing
detection from Sentinel-2 L2A time series: for each polygon-defined field
boundary, April-October imagery is used for binary prediction (grazed / not
grazed). We train an ensemble of CNN-LSTM models on multi-temporal reflectance
features, and achieve an average F1 score of 77 percent across five validation
splits, with 90 percent recall on grazed pastures. Operationally, if inspectors
can visit at most 4 percent of sites annually, prioritising fields predicted by
our model as non-grazed yields 17.2 times more confirmed non-grazing sites than
random inspection. These results indicate that coarse-resolution, freely
available satellite data can reliably steer inspection resources for
conservation-aligned land-use compliance. Code and models have been made
publicly available.

</details>


### [36] [QDepth-VLA: Quantized Depth Prediction as Auxiliary Supervision for Vision-Language-Action Models](https://arxiv.org/abs/2510.14836)
*Yixuan Li,Yuhui Chen,Mingcai Zhou,Haoran Li*

Main category: cs.CV

TL;DR: 本文提出了QDepth-VLA框架，通过引入辅助的深度预测任务增强视觉-语言-行动（VLA）模型的三维空间理解能力，从而提升操控任务的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在精细操控任务中，缺乏对关键三维结构的理解和推理能力，制约了其空间感知和操作精度。

Method: 提出QDepth-VLA框架，在模型中增加辅助深度预测任务。具体方法是：使用VQ-VAE编码器获得深度图的量化潜在表示，由专用深度专家模块预测这些深度图的量化token，使模型能学习到包含关键几何线索的深度感知表征。

Result: 在仿真和现实世界基准任务上，QDepth-VLA展现出强空间推理能力，并在操控任务中取得有竞争力的性能。

Conclusion: 引入深度感知任务后，VLA模型的空间理解和实际操作表现均得到明显提升，证明该方法有效可行。

Abstract: Spatial perception and reasoning are crucial for Vision-Language-Action (VLA)
models to accomplish fine-grained manipulation tasks. However, existing
approaches often lack the ability to understand and reason over the essential
3D structures necessary for precise control. To address this limitation, we
propose QDepth-VLA, a general framework that augments VLA models with an
auxiliary depth prediction task. A dedicated depth expert is designed to
predict quantized latent tokens of depth maps obtained from a VQ-VAE encoder,
enabling the model to learn depth-aware representations that capture critical
geometric cues. Experimental results on the simulation benchmarks and
real-world tasks demonstrate that QDepth-VLA yields strong spatial reasoning
and competitive performance on manipulation tasks.

</details>


### [37] [Vision Mamba for Permeability Prediction of Porous Media](https://arxiv.org/abs/2510.14516)
*Ali Kashefi,Tapan Mukerji*

Main category: cs.CV

TL;DR: 该论文首次将Vision Mamba作为主干网络应用于三维多孔介质渗透率预测任务，并与ViT和CNN进行了多方面比较，展示了其在计算和内存效率等方面的优势。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers虽然在视觉任务中表现优异，但其网络规模和内存消耗随输入分辨率二次增长，影响大规模应用；Vision Mamba则具备更高的内存和计算效率，动因是探索其在科学计算任务中的新优势。

Method: 提出以Vision Mamba为骨干的神经网络解决三维多孔介质渗透率预测问题，并系统比较其与ViT、CNN的表现，此外通过消融实验评估网络组件对精度的影响。

Result: 实验表明，Vision Mamba在三维多孔介质渗透率预测中相比传统ViT和CNN在计算、内存效率和模型参数量上表现更佳。

Conclusion: Vision Mamba作为骨干网络在科学三维视觉任务中具有明显优势，有望替代ViT并集成到更大的视觉模型中，代码已开源便利社区复现和拓展。

Abstract: Vision Mamba has recently received attention as an alternative to Vision
Transformers (ViTs) for image classification. The network size of Vision Mamba
scales linearly with input image resolution, whereas ViTs scale quadratically,
a feature that improves computational and memory efficiency. Moreover, Vision
Mamba requires a significantly smaller number of trainable parameters than
traditional convolutional neural networks (CNNs), and thus, they can be more
memory efficient. Because of these features, we introduce, for the first time,
a neural network that uses Vision Mamba as its backbone for predicting the
permeability of three-dimensional porous media. We compare the performance of
Vision Mamba with ViT and CNN models across multiple aspects of permeability
prediction and perform an ablation study to assess the effects of its
components on accuracy. We demonstrate in practice the aforementioned
advantages of Vision Mamba over ViTs and CNNs in the permeability prediction of
three-dimensional porous media. We make the source code publicly available to
facilitate reproducibility and to enable other researchers to build on and
extend this work. We believe the proposed framework has the potential to be
integrated into large vision models in which Vision Mamba is used instead of
ViTs.

</details>


### [38] [Ponimator: Unfolding Interactive Pose for Versatile Human-human Interaction Animation](https://arxiv.org/abs/2510.14976)
*Shaowei Liu,Chuan Guo,Bing Zhou,Jian Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为Ponimator的框架，基于近距离人体交互动作，利用扩散模型生成交互动画，实现多种互动动画生成任务。


<details>
  <summary>Details</summary>
Motivation: 人类能够通过近距离交互姿态直观判断互动动态并推测前因后果，而现有方法难以高效利用这种丰富的人体交互先验信息。

Method: Ponimator框架引入了两个条件扩散模型：(1) 姿态动画器，根据时序先验从交互姿态生成动态序列；(2) 姿态生成器，基于空间先验在无现成交互姿态时，能根据单帧姿态、文本或两者生成交互动作。训练数据来自高质量两人交互的动作捕捉数据及其时间上下文。

Result: Ponimator在多种数据集和应用场景上进行了实验，验证了交互姿态先验的通用性以及该框架在互动动画生成任务的有效性和稳健性。

Conclusion: Ponimator利用人体互动的空间和时序先验，实现了高质量、多样化的交互动画生成，有助于将动作捕捉交互知识迁移到更广泛的实际场景中。

Abstract: Close-proximity human-human interactive poses convey rich contextual
information about interaction dynamics. Given such poses, humans can
intuitively infer the context and anticipate possible past and future dynamics,
drawing on strong priors of human behavior. Inspired by this observation, we
propose Ponimator, a simple framework anchored on proximal interactive poses
for versatile interaction animation. Our training data consists of
close-contact two-person poses and their surrounding temporal context from
motion-capture interaction datasets. Leveraging interactive pose priors,
Ponimator employs two conditional diffusion models: (1) a pose animator that
uses the temporal prior to generate dynamic motion sequences from interactive
poses, and (2) a pose generator that applies the spatial prior to synthesize
interactive poses from a single pose, text, or both when interactive poses are
unavailable. Collectively, Ponimator supports diverse tasks, including
image-based interaction animation, reaction animation, and text-to-interaction
synthesis, facilitating the transfer of interaction knowledge from high-quality
mocap data to open-world scenarios. Empirical experiments across diverse
datasets and applications demonstrate the universality of the pose prior and
the effectiveness and robustness of our framework.

</details>


### [39] [Real-Time Surgical Instrument Defect Detection via Non-Destructive Testing](https://arxiv.org/abs/2510.14525)
*Qurrat Ul Ain,Atif Aftab Ahmed Jilani,Zunaira Shafqat,Nigar Azhar Butt*

Main category: cs.CV

TL;DR: 本研究提出了一种基于AI的手术器械缺陷检测框架SurgScan，利用YOLOv8模型，实现了高准确率和工业级实时检测，有望取代人工检验。


<details>
  <summary>Details</summary>
Motivation: 手术器械的缺陷会严重威胁无菌性、机械完整性和患者安全，而现有检测方法主要依赖人工，易出错且不一致，急需自动化、高效的检测方法提升质控水平。

Method: 构建了包含102,876张高清图像的手术器械缺陷数据集，涵盖11种器械类型和5大类缺陷。采用YOLOv8模型进行实时缺陷检测，并与多种主流CNN架构做对比；采用对比度增强的图像预处理，以提升检测准确率。

Result: SurgScan在准确率（99.3%）和实时性（每张图像检测用时4.2-5.8毫秒）上均超过其他主流CNN模型。统计分析证实对比度增强预处理能显著提高缺陷检测效果。

Conclusion: SurgScan为手术器械制造业提供了可扩展、成本效益高的AI自动质量控制解决方案，降低了对人工的依赖，符合ISO 13485与FDA标准，有助于提升医疗制造领域的安全与合规性。

Abstract: Defective surgical instruments pose serious risks to sterility, mechanical
integrity, and patient safety, increasing the likelihood of surgical
complications. However, quality control in surgical instrument manufacturing
often relies on manual inspection, which is prone to human error and
inconsistency. This study introduces SurgScan, an AI-powered defect detection
framework for surgical instruments. Using YOLOv8, SurgScan classifies defects
in real-time, ensuring high accuracy and industrial scalability. The model is
trained on a high-resolution dataset of 102,876 images, covering 11 instrument
types and five major defect categories. Extensive evaluation against
state-of-the-art CNN architectures confirms that SurgScan achieves the highest
accuracy (99.3%) with real-time inference speeds of 4.2-5.8 ms per image,
making it suitable for industrial deployment. Statistical analysis demonstrates
that contrast-enhanced preprocessing significantly improves defect detection,
addressing key limitations in visual inspection. SurgScan provides a scalable,
cost-effective AI solution for automated quality control, reducing reliance on
manual inspection while ensuring compliance with ISO 13485 and FDA standards,
paving the way for enhanced defect detection in medical manufacturing.

</details>


### [40] [Noise Projection: Closing the Prompt-Agnostic Gap Behind Text-to-Image Misalignment in Diffusion Models](https://arxiv.org/abs/2510.14526)
*Yunze Tong,Didi Zhu,Zijing Hu,Jinluan Yang,Ziyu Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种在文本到图像生成中提升文本与图像对齐性的技术，通过引入基于文本提示的噪声投影器来优化初始噪声，使最终生成的图像更好地匹配用户输入的提示。


<details>
  <summary>Details</summary>
Motivation: 当前Stable Diffusion等扩散模型在推理阶段直接从与文本提示无关的高斯分布采样噪声，这与训练时噪声分布存在偏差，导致部分生成图像与输入的文本提示不对齐。现有方法要么增加模型复杂度、要么需要多次采样后筛选，效率低下。

Method: 作者提出了一个噪声投影器，其核心做法是：根据文本提示对初始噪声进行投影和校正，使其更贴近训练时分布。具体流程为：采样多组噪声，通过视觉-语言模型给输出图像打分，训练一个奖励模型，然后通过偏好优化训练噪声投影器，最终在推理时只需一次前向传播即可生成更对齐的图像。

Result: 大量实验表明，该方法在多样化的文本提示下均能提升生成图像的文本对齐度，并且只需单次采样，推理效率高。

Conclusion: 基于文本感知的噪声投影技术，无需额外参考图像或手工构造先验，显著改善了文-图对齐问题，并提升了生成效率。

Abstract: In text-to-image generation, different initial noises induce distinct
denoising paths with a pretrained Stable Diffusion (SD) model. While this
pattern could output diverse images, some of them may fail to align well with
the prompt. Existing methods alleviate this issue either by altering the
denoising dynamics or by drawing multiple noises and conducting post-selection.
In this paper, we attribute the misalignment to a training-inference mismatch:
during training, prompt-conditioned noises lie in a prompt-specific subset of
the latent space, whereas at inference the noise is drawn from a
prompt-agnostic Gaussian prior. To close this gap, we propose a noise projector
that applies text-conditioned refinement to the initial noise before denoising.
Conditioned on the prompt embedding, it maps the noise to a prompt-aware
counterpart that better matches the distribution observed during SD training,
without modifying the SD model. Our framework consists of these steps: we first
sample some noises and obtain token-level feedback for their corresponding
images from a vision-language model (VLM), then distill these signals into a
reward model, and finally optimize the noise projector via a quasi-direct
preference optimization. Our design has two benefits: (i) it requires no
reference images or handcrafted priors, and (ii) it incurs small inference
cost, replacing multi-sample selection with a single forward pass. Extensive
experiments further show that our prompt-aware noise projection improves
text-image alignment across diverse prompts.

</details>


### [41] [PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model](https://arxiv.org/abs/2510.14528)
*Cheng Cui,Ting Sun,Suyin Liang,Tingquan Gao,Zelun Zhang,Jiaxuan Liu,Xueqing Wang,Changda Zhou,Hongen Liu,Manhui Lin,Yue Zhang,Yubo Zhang,Handong Zheng,Jing Zhang,Jun Zhang,Yi Liu,Dianhai Yu,Yanjun Ma*

Main category: cs.CV

TL;DR: PaddleOCR-VL 是一款高效且资源消耗低的文档解析模型，不仅支持109种语言，还能识别复杂文档元素，在多个评测中表现优异，具备实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 当前文档解析任务对模型准确性和资源效率要求持续提升，尤其是面对多样语言和复杂文档结构，现有模型在性能和适用性上存在不足，亟需高效、通用的解决方案。

Method: 提出了PaddleOCR-VL模型，核心为PaddleOCR-VL-0.9B，将NaViT风格的动态图像编码器与ERNIE-4.5-0.3B语言模型结合，实现了高效的视觉-语言融合和多语言、多元素识别能力。

Result: 在公开基准和自有评测中，PaddleOCR-VL在页面级解析和元素级识别方面均取得了SOTA（最先进水平）表现，超越了现有主流文档解析解决方案，并在推理速度上表现优良。

Conclusion: PaddleOCR-VL模型不仅在准确率、兼容性和速度方面都达到了领先水平，同时具备极高的部署实用性，有望推动实际文档理解应用的发展。

Abstract: In this report, we propose PaddleOCR-VL, a SOTA and resource-efficient model
tailored for document parsing. Its core component is PaddleOCR-VL-0.9B, a
compact yet powerful vision-language model (VLM) that integrates a NaViT-style
dynamic resolution visual encoder with the ERNIE-4.5-0.3B language model to
enable accurate element recognition. This innovative model efficiently supports
109 languages and excels in recognizing complex elements (e.g., text, tables,
formulas, and charts), while maintaining minimal resource consumption. Through
comprehensive evaluations on widely used public benchmarks and in-house
benchmarks, PaddleOCR-VL achieves SOTA performance in both page-level document
parsing and element-level recognition. It significantly outperforms existing
solutions, exhibits strong competitiveness against top-tier VLMs, and delivers
fast inference speeds. These strengths make it highly suitable for practical
deployment in real-world scenarios.

</details>


### [42] [Towards Generalist Intelligence in Dentistry: Vision Foundation Models for Oral and Maxillofacial Radiology](https://arxiv.org/abs/2510.14532)
*Xinrui Huang,Fan Xiao,Dongming He,Anqi Gao,Dandan Li,Xiaofan Zhang,Shaoting Zhang,Xudong Wang*

Main category: cs.CV

TL;DR: 本文介绍了DentVFM，这是第一个用于口腔医学的视觉基础模型（VFM）家族，能够跨任务、跨模态提升牙科影像智能分析。


<details>
  <summary>Details</summary>
Motivation: 口腔放射学领域存在专业人员短缺，AI方法受限于单一模态、任务定制化和对标签数据依赖，难以推广到实际多样化临床场景，有必要开发能广泛泛化的牙科视觉基础模型。

Method: 提出DentVFM家族模型，基于Vision Transformer（ViT），包含2D和3D版本，采用自监督学习，在包含约160万多模态牙科影像的DentVista大规模数据集上训练。为评估性能，提出DentBench基准，涵盖八大牙科分支、更多疾病与模态，数据具地理广泛性。

Result: DentVFM在多种牙科任务上表现出优秀的泛化能力，显著超越了有监督、自监督和弱监督基线模型。在无传统影像场景下，DentVFM的跨模态诊断能力甚至超过经验丰富的牙医。

Conclusion: DentVFM为牙科AI树立了新范式，展现了模型的可扩展性、适应性与标签利用率，能有效弥补全球口腔医疗智能分析中的关键短板。

Abstract: Oral and maxillofacial radiology plays a vital role in dental healthcare, but
radiographic image interpretation is limited by a shortage of trained
professionals. While AI approaches have shown promise, existing dental AI
systems are restricted by their single-modality focus, task-specific design,
and reliance on costly labeled data, hindering their generalization across
diverse clinical scenarios. To address these challenges, we introduce DentVFM,
the first family of vision foundation models (VFMs) designed for dentistry.
DentVFM generates task-agnostic visual representations for a wide range of
dental applications and uses self-supervised learning on DentVista, a large
curated dental imaging dataset with approximately 1.6 million multi-modal
radiographic images from various medical centers. DentVFM includes 2D and 3D
variants based on the Vision Transformer (ViT) architecture. To address gaps in
dental intelligence assessment and benchmarks, we introduce DentBench, a
comprehensive benchmark covering eight dental subspecialties, more diseases,
imaging modalities, and a wide geographical distribution. DentVFM shows
impressive generalist intelligence, demonstrating robust generalization to
diverse dental tasks, such as disease diagnosis, treatment analysis, biomarker
identification, and anatomical landmark detection and segmentation.
Experimental results indicate DentVFM significantly outperforms supervised,
self-supervised, and weakly supervised baselines, offering superior
generalization, label efficiency, and scalability. Additionally, DentVFM
enables cross-modality diagnostics, providing more reliable results than
experienced dentists in situations where conventional imaging is unavailable.
DentVFM sets a new paradigm for dental AI, offering a scalable, adaptable, and
label-efficient model to improve intelligent dental healthcare and address
critical gaps in global oral healthcare.

</details>


### [43] [Acquisition of interpretable domain information during brain MR image harmonization for content-based image retrieval](https://arxiv.org/abs/2510.14535)
*Keima Abe,Hayato Muraki,Shuhei Tomoshige,Kenichi Oishi,Hitoshi Iyatomi*

Main category: cs.CV

TL;DR: 该论文提出了一种名为PL-SE-ADA的新方法，实现了磁共振（MR）脑图像的领域和谐化和可解释表征学习，并在图像重建、疾病分类等任务上优于或媲美现有方法。


<details>
  <summary>Details</summary>
Motivation: 医学图像（如脑MR扫描）因扫描仪和协议不同，在不同医院或机构经常存在领域差异，导致机器学习模型泛化能力下降。领域和谐化可提升模型性能，尤其是在疾病分类等临床任务。然而，现有领域解耦方法通常缺乏可解释性，难以满足医学应用的需求。

Method: 提出PL-SE-ADA框架，包括两个分别提取领域无关（z_u）和领域相关（z_d）特征的编码器、一个解码器和一个领域判别器。利用编码器和判别器之间的对抗训练，并结合z_u和z_d的重建，实现和谐化与信息保留。该方法能直观地可视化领域无关和相关特征，增强了可解释性。

Result: PL-SE-ADA在脑MR图像的重建、疾病分类和领域识别等任务上，表现出与现有方法相当或更好的性能。同时提供了对领域无关和领域特征的可视化结果，显示出框架的高可解释性。

Conclusion: PL-SE-ADA实现了医学图像领域和谐化的目标，并确保了特征表征的可解释性，为医学诊断模型提供了更好的实用性和安全性。

Abstract: Medical images like MR scans often show domain shifts across imaging sites
due to scanner and protocol differences, which degrade machine learning
performance in tasks such as disease classification. Domain harmonization is
thus a critical research focus. Recent approaches encode brain images
$\boldsymbol{x}$ into a low-dimensional latent space $\boldsymbol{z}$, then
disentangle it into $\boldsymbol{z_u}$ (domain-invariant) and
$\boldsymbol{z_d}$ (domain-specific), achieving strong results. However, these
methods often lack interpretability$-$an essential requirement in medical
applications$-$leaving practical issues unresolved. We propose
Pseudo-Linear-Style Encoder Adversarial Domain Adaptation (PL-SE-ADA), a
general framework for domain harmonization and interpretable representation
learning that preserves disease-relevant information in brain MR images.
PL-SE-ADA includes two encoders $f_E$ and $f_{SE}$ to extract
$\boldsymbol{z_u}$ and $\boldsymbol{z_d}$, a decoder to reconstruct the image
$f_D$, and a domain predictor $g_D$. Beyond adversarial training between the
encoder and domain predictor, the model learns to reconstruct the input image
$\boldsymbol{x}$ by summing reconstructions from $\boldsymbol{z_u}$ and
$\boldsymbol{z_d}$, ensuring both harmonization and informativeness. Compared
to prior methods, PL-SE-ADA achieves equal or better performance in image
reconstruction, disease classification, and domain recognition. It also enables
visualization of both domain-independent brain features and domain-specific
components, offering high interpretability across the entire framework.

</details>


### [44] [Exploring Image Representation with Decoupled Classical Visual Descriptors](https://arxiv.org/abs/2510.14536)
*Chenyuan Qu,Hao Chen,Jianbo Jiao*

Main category: cs.CV

TL;DR: 该论文提出了一种新型图像表示学习框架VisualSplit，将图像分解为独立且可理解的传统视觉描述子，并用于多种图像任务。


<details>
  <summary>Details</summary>
Motivation: 深度学习在图像理解任务上取得了巨大进展，但其内部表征难以解释，不利于可解释性和可控性；而传统视觉描述子（如边缘、颜色、强度分布）直观可解释，这激发了将两者结合的研究动机。

Method: 提出VisualSplit框架，将图像显式地分解为去耦合的传统视觉描述子，每个描述子作为独立且互补的视觉知识分量，通过重建驱动的预训练机制学习每种描述子的核心特征，保持良好的可解释性。

Result: VisualSplit通过分解视觉属性，能有效支持图像生成、编辑等高级视觉任务，实现了对视觉属性的有效控制，表现出超越传统分类和分割任务的能力。

Conclusion: 该方法能够提升视觉理解的可解释性与可控性，为视觉任务带来新的解决思路，显示了将传统视觉描述子与现代学习框架结合的潜力和效果。

Abstract: Exploring and understanding efficient image representations is a
long-standing challenge in computer vision. While deep learning has achieved
remarkable progress across image understanding tasks, its internal
representations are often opaque, making it difficult to interpret how visual
information is processed. In contrast, classical visual descriptors (e.g. edge,
colour, and intensity distribution) have long been fundamental to image
analysis and remain intuitively understandable to humans. Motivated by this
gap, we ask a central question: Can modern learning benefit from these
classical cues? In this paper, we answer it with VisualSplit, a framework that
explicitly decomposes images into decoupled classical descriptors, treating
each as an independent but complementary component of visual knowledge. Through
a reconstruction-driven pre-training scheme, VisualSplit learns to capture the
essence of each visual descriptor while preserving their interpretability. By
explicitly decomposing visual attributes, our method inherently facilitates
effective attribute control in various advanced visual tasks, including image
generation and editing, extending beyond conventional classification and
segmentation, suggesting the effectiveness of this new learning approach for
visual understanding. Project page: https://chenyuanqu.com/VisualSplit/.

</details>


### [45] [Exploring Cross-Modal Flows for Few-Shot Learning](https://arxiv.org/abs/2510.14543)
*Ziqi Jiang,Yanghao Wang,Long Chen*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的多步特征对齐方法，名为Flow Matching Alignment（FMA），可实现更精细的跨模态对齐，优于现有的单步参数高效微调方法。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态任务中常用的参数高效微调方法（PEFT）如prompt tuning、LoRA或adapter，虽然能够避免过拟合，但仅能实现一次性（单步）的小幅度调整，对高度复杂和多模态纠缠的数据集效果有限。

Method: 作者首次提出了一种模型无关的多步调整方法——Flow Matching Alignment（FMA），利用跨模态流场进行多步调整。具体做法包含：1）采用固定coupling策略保证训练期间类别的对应关系；2）设计噪声增强策略缓解数据稀缺；3）引入提前终止的求解器提升效率和精度。

Result: FMA在多个基准和后端骨干网络上均取得了显著超越传统PEFT方法的性能提升，特别是在复杂和具有挑战性的数据集上表现更加突出。

Conclusion: 提出的FMA方法能够实现更为精准且稳健的跨模态特征对齐，克服了现有PEFT方法单步调整的不足，为复杂跨模态任务提供了更优解决方案。

Abstract: Aligning features from different modalities, is one of the most fundamental
challenges for cross-modal tasks. Although pre-trained vision-language models
can achieve a general alignment between image and text, they often require
parameter-efficient fine-tuning (PEFT) for further adjustment. Today's PEFT
methods (e.g., prompt tuning, LoRA-based, or adapter-based) always selectively
fine-tune a subset of parameters, which can slightly adjust either visual or
textual features, and avoid overfitting. In this paper, we are the first to
highlight that all existing PEFT methods perform one-step adjustment. It is
insufficient for complex (or difficult) datasets, where features of different
modalities are highly entangled. To this end, we propose the first
model-agnostic multi-step adjustment approach by learning a cross-modal
velocity field: Flow Matching Alignment (FMA). Specifically, to ensure the
correspondence between categories during training, we first utilize a fixed
coupling strategy. Then, we propose a noise augmentation strategy to alleviate
the data scarcity issue. Finally, we design an early-stopping solver, which
terminates the transformation process earlier, improving both efficiency and
accuracy. Compared with one-step PEFT methods, FMA has the multi-step
rectification ability to achieve more precise and robust alignment. Extensive
results have demonstrated that FMA can consistently yield significant
performance gains across various benchmarks and backbones, particularly on
challenging datasets.

</details>


### [46] [Consistent text-to-image generation via scene de-contextualization](https://arxiv.org/abs/2510.14553)
*Song Tang,Peihao Gong,Kunyu Li,Kai Guo,Boyu Wang,Mao Ye,Jianwei Zhang,Xiatian Zhu*

Main category: cs.CV

TL;DR: 该论文针对一致性文生图（T2I）生成任务中常见的身份漂移问题，提出了一种高效的“去场景上下文化（SDeC）”方法，无需预知所有目标场景，即可实现保持身份一致的多场景图像生成。


<details>
  <summary>Details</summary>
Motivation: 维护同一主题在多样场景中的身份一致性是文生图生成的重要需求，但现有方法大多依赖于不现实的假设，即事先知道所有目标场景。实际应用中通常无法满足此假设，且现有T2I模型因内在的主题与场景相关性（场景上下文化）造成身份漂移问题，阻碍了真实身份一致性图像的生成。

Method: 作者理论分析了主题与场景间的相关性来源，并提出了SDeC方法，通过奇异值分解（SVD）方向稳定性的定量分析，自适应地重权嵌入中的特征值，从而在不需额外训练&不需场景先验的前提下，自动识别并抑制主题与场景间的隐式相关性，实现“逐场景、逐提示”的身份信息去耦。

Result: 实验结果表明，SDeC方法能在不损失场景多样性的条件下，显著提升生成图像的身份一致性效果，优于以往依赖场景先验或专项训练的方法。

Conclusion: SDeC为解决实际环境下的一致性文生图生成提供了通用且高效的解决方案，大幅提升了身份一致性，兼顾了场景灵活性与多样性，为文生图技术落地与应用扩展带来积极推动。

Abstract: Consistent text-to-image (T2I) generation seeks to produce
identity-preserving images of the same subject across diverse scenes, yet it
often fails due to a phenomenon called identity (ID) shift. Previous methods
have tackled this issue, but typically rely on the unrealistic assumption of
knowing all target scenes in advance. This paper reveals that a key source of
ID shift is the native correlation between subject and scene context, called
scene contextualization, which arises naturally as T2I models fit the training
distribution of vast natural images. We formally prove the near-universality of
this scene-ID correlation and derive theoretical bounds on its strength. On
this basis, we propose a novel, efficient, training-free prompt embedding
editing approach, called Scene De-Contextualization (SDeC), that imposes an
inversion process of T2I's built-in scene contextualization. Specifically, it
identifies and suppresses the latent scene-ID correlation within the ID
prompt's embedding by quantifying the SVD directional stability to adaptively
re-weight the corresponding eigenvalues. Critically, SDeC allows for per-scene
use (one scene per prompt) without requiring prior access to all target scenes.
This makes it a highly flexible and general solution well-suited to real-world
applications where such prior knowledge is often unavailable or varies over
time. Experiments demonstrate that SDeC significantly enhances identity
preservation while maintaining scene diversity.

</details>


### [47] [Eyes Wide Open: Ego Proactive Video-LLM for Streaming Video](https://arxiv.org/abs/2510.14560)
*Yulin Zhang,Cheng Shi,Yang Wang,Sibei Yang*

Main category: cs.CV

TL;DR: 本文提出一个能够在类人环境下主动感知和应对的AI模型，同时引入了新的评测基准ESTP-Bench和ESTP-F1指标，并通过设计的数据流程、训练策略及主动压缩技术实现更优异性能。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能多停留在被动观察阶段，缺乏对真实环境事件的主动理解和响应能力。因此，作者希望构建能够主动预测并在合适时机答复的助理型AI系统。

Method: 作者引入了ESTP-Bench评测基准和ESTP-F1评测指标，从主动连贯性、即时响应性、同步高效性三个核心方面全面评测模型。提出的数据流程、分阶段训练方法和主动压缩技术支持模型高效地感知、推理并及时响应。

Result: 实验显示，所提模型在多个线上与离线基准测试中，在主动性与效率等方面均超越现有的多项基线方法，全面提升了AI在实际场景的表现。

Conclusion: 论文证明了新任务的研究价值，相关方法和评测体系能够推动AI从被动变为主动，具备类人环境视觉与响应的实用能力。

Abstract: Envision an AI capable of functioning in human-like settings, moving beyond
mere observation to actively understand, anticipate, and proactively respond to
unfolding events. Towards this vision, we focus on the innovative task where,
given ego-streaming video input, an assistant proactively answers diverse,
evolving questions at the opportune moment, while maintaining synchronized
perception and reasoning. This task embodies three key properties: (1)
Proactive Coherence, (2) Just-in-Time Responsiveness, and (3) Synchronized
Efficiency. To evaluate and address these properties, we first introduce
ESTP-Bench (Ego Streaming Proactive Benchmark) alongside the ESTP-F1 metric-a
novel framework designed for their rigorous assessment. Secondly, we propose a
comprehensive technical pipeline to enable models to tackle this challenging
task. This pipeline comprises: (1) a data engine, (2) a multi-stage training
strategy, and (3) a proactive dynamic compression technique. Our proposed model
effectively addresses these critical properties while outperforming multiple
baselines across diverse online and offline benchmarks. Project
Page:https://zhangyl4.github.io/publications/eyes-wide-open/

</details>


### [48] [BalanceGS: Algorithm-System Co-design for Efficient 3D Gaussian Splatting Training on GPU](https://arxiv.org/abs/2510.14564)
*Junyi Wu,Jiaming Xu,Jinhao Li,Yongkang Zhou,Jiayi Pan,Xingyang Li,Guohao Dai*

Main category: cs.CV

TL;DR: 本文提出了BalanceGS方法，通过算法与系统协同设计，大幅提升了3D高斯投射（3DGS）训练的效率，并在保持重建质量的前提下，在A100 GPU上实现了1.44倍的训练加速。


<details>
  <summary>Details</summary>
Motivation: 传统3DGS方法在高斯点稠密化、投影和色彩合成三个阶段分别存在密度分布失衡、计算任务不平衡、内存访问碎片化等效率瓶颈，严重影响训练速度和资源利用。

Method: 1）在算法层面，提出工作量敏感的高斯密度控制，自动平衡高斯点分布；2）在系统层面，提出基于相似度的高斯采样与合并，动态分配线程处理密集或稀疏区域的高斯点；3）在映射层面，改进内存访问，将RGB数据重排序以支持批量加载，提高内存利用率。

Result: 相比原始3DGS方法，在保证重建质量几乎无损的前提下，训练速度提升了1.44倍（在NVIDIA A100 GPU上验证）。

Conclusion: BalanceGS通过多层次优化，有效解决了3DGS训练中的分布与资源瓶颈，证明了高效3D重建系统的可行性和实用价值。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a promising 3D reconstruction
technique. The traditional 3DGS training pipeline follows three sequential
steps: Gaussian densification, Gaussian projection, and color splatting.
Despite its promising reconstruction quality, this conventional approach
suffers from three critical inefficiencies: (1) Skewed density allocation
during Gaussian densification, (2) Imbalanced computation workload during
Gaussian projection and (3) Fragmented memory access during color splatting.
  To tackle the above challenges, we introduce BalanceGS, the algorithm-system
co-design for efficient training in 3DGS. (1) At the algorithm level, we
propose heuristic workload-sensitive Gaussian density control to automatically
balance point distributions - removing 80% redundant Gaussians in dense regions
while filling gaps in sparse areas. (2) At the system level, we propose
Similarity-based Gaussian sampling and merging, which replaces the static
one-to-one thread-pixel mapping with adaptive workload distribution - threads
now dynamically process variable numbers of Gaussians based on local cluster
density. (3) At the mapping level, we propose reordering-based memory access
mapping strategy that restructures RGB storage and enables batch loading in
shared memory.
  Extensive experiments demonstrate that compared with 3DGS, our approach
achieves a 1.44$\times$ training speedup on a NVIDIA A100 GPU with negligible
quality degradation.

</details>


### [49] [CALM-Net: Curvature-Aware LiDAR Point Cloud-based Multi-Branch Neural Network for Vehicle Re-Identification](https://arxiv.org/abs/2510.14576)
*Dongwook Lee,Sol Han,Jinwhan Kim*

Main category: cs.CV

TL;DR: 本文提出了CALM-Net，一种基于曲率感知的激光雷达点云多分支神经网络，用于车辆重识别，显著提升识别准确率。


<details>
  <summary>Details</summary>
Motivation: 车辆重识别是智能交通和自动驾驶领域的重要问题，使用三维激光雷达点云进行判别，更具挑战性，需要从点云中学习具有判别性的特征。

Method: CALM-Net采用多分支结构，结合边缘卷积、点注意力机制以及曲率嵌入（反映点云局部表面变化），从而提取更丰富的几何和上下文特征。

Result: 在大规模nuScenes数据集上，CALM-Net比研究中最优基线方法提升了1.97个百分点的平均重识别准确率。

Conclusion: 实验结果表明，将曲率信息和多分支特征学习机制引入深度学习架构，可有效提升基于点云的车辆重识别性能。

Abstract: This paper presents CALM-Net, a curvature-aware LiDAR point cloud-based
multi-branch neural network for vehicle re-identification. The proposed model
addresses the challenge of learning discriminative and complementary features
from three-dimensional point clouds to distinguish between vehicles. CALM-Net
employs a multi-branch architecture that integrates edge convolution, point
attention, and a curvature embedding that characterizes local surface variation
in point clouds. By combining these mechanisms, the model learns richer
geometric and contextual features that are well suited for the
re-identification task. Experimental evaluation on the large-scale nuScenes
dataset demonstrates that CALM-Net achieves a mean re-identification accuracy
improvement of approximately 1.97\% points compared with the strongest baseline
in our study. The results confirms the effectiveness of incorporating curvature
information into deep learning architectures and highlight the benefit of
multi-branch feature learning for LiDAR point cloud-based vehicle
re-identification.

</details>


### [50] [Talking Points: Describing and Localizing Pixels](https://arxiv.org/abs/2510.14583)
*Matan Rusanovsky,Shimon Malnick,Shai Avidan*

Main category: cs.CV

TL;DR: 该论文提出了一种新的视觉-语言模型框架，实现了基于自然语言的像素级关键点定位，超越了以往仅限对象级或区域级的局限。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型在跨模态理解方面进展显著，但缺乏用自然语言表达的像素级关键点理解能力。论文旨在解决此精细语义与定位结合的问题，提升细粒度场景理解能力。

Method: 提出了由Point Descriptor和Point Localizer两部分组成的新框架。Point Descriptor为关键点生成丰富的自由格式描述，Point Localizer则根据描述精确回归像素坐标。还构建了LlamaPointInPart数据集，包含2万多个图像-关键点-描述三元组，用以多尺度信息训练。通过冻结定位器、用定位精度作为奖励优化描述器，在AP-10K上实现跨类别泛化。采用新的评估协议，以坐标接近度而非文本一致性作为性能标准。

Result: 在LlamaPointInPart数据集上的实验显示，该方法在像素级关键点定位任务中优于以往基线模型。引入的自由格式描述和端到端泛化流程显著提高了模型性能。

Conclusion: 该框架有效提升了自然语言指引下的精细关键点定位能力，并具有双向应用潜力，为结合关键点和语言的精确理解和定位任务提供了新范式。代码和数据集已公开。

Abstract: Vision-language models have achieved remarkable success in cross-modal
understanding. Yet, these models remain limited to object-level or region-level
grounding, lacking the capability for pixel-precise keypoint comprehension
through natural language. We introduce a novel framework for pixel level
grounding. The framework consists of two complementary components: a Point
Descriptor that generates rich, contextual descriptions of individual
keypoints, and a Point Localizer that regresses precise pixel coordinates from
these descriptions. Unlike prior work that relies on templated prompts or
keypoint names, our approach produces free-form, coarse-to-fine descriptions
that situate keypoints within their visual context. Since there is no available
dataset to train such a system, we introduce LlamaPointInPart, a carefully
curated dataset of 20K+ image-keypoint-description triplets synthesized from
multiple vision-language models, capturing multi-scale information from
scene-level context to visual features around the keypoint. For cross-category
generalization, we optimize the Point Descriptor on AP-10K via GRPO, using the
frozen Point Localizer as a reward model to produce descriptions that maximize
localization accuracy. To evaluate our results we establish a new evaluation
protocol. Instead of comparing the text description produced by our method to
the ground truth, we use the localizer to determine how close is the predicted
point generated to the ground truth point. Experiments demonstrate superior
performance compared to baseline models on LlamaPointInPart.The bidirectional
nature of our framework should enable future applications in both
keypoint-guided image understanding and language-guided precise localization.
Our code and dataset are publicly available at
https://github.com/matanr/Talking_Points.

</details>


### [51] [STANCE: Motion Coherent Video Generation Via Sparse-to-Dense Anchored Encoding](https://arxiv.org/abs/2510.14588)
*Zhifei Chen,Tianshuo Xu,Leyi Wu,Luozhou Wang,Dongyu Yan,Zihan You,Wenting Luo,Guo Zhang,Yingcong Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为STANCE的新型图像到视频生成框架，显著提升了视频中物体运动与交互的连贯性。


<details>
  <summary>Details</summary>
Motivation: 尽管当前视频生成在视觉质量上取得进步，但物体的运动连贯性与交互仍难以保证，主要由运动引导信号编码后信息丢失及外观与运动共优化带来的权衡问题导致。

Method: STANCE框架包含两大创新：（1）Instance Cues：将稀疏的用户运动提示转为密集的 2.5D 运动场，结合深度信息减少2D输入的深度歧义，并便于编辑；（2）Dense RoPE：在编码空间内通过空间位置编码强化运动提示的表达，加强运动信号的影响力。框架联合作RGB和辅助信息（如分割或深度）预测，分离结构与外观的建模。

Result: 实验表明，该方法无需复杂的逐帧运动脚本即可提升视频生成时物体结构的连续性与运动的时序一致性，有效缓解了现有方法在物体运动连贯性上的短板。

Conclusion: STANCE通过简单、有效的结构同时解决了运动提示信息损耗和运动-外观建模冲突，推动了自动视频生成技术在运动连贯性和可控性方面的进步。

Abstract: Video generation has recently made striking visual progress, but maintaining
coherent object motion and interactions remains difficult. We trace two
practical bottlenecks: (i) human-provided motion hints (e.g., small 2D maps)
often collapse to too few effective tokens after encoding, weakening guidance;
and (ii) optimizing for appearance and motion in a single head can favor
texture over temporal consistency. We present STANCE, an image-to-video
framework that addresses both issues with two simple components. First, we
introduce Instance Cues -- a pixel-aligned control signal that turns sparse,
user-editable hints into a dense 2.5D (camera-relative) motion field by
averaging per-instance flow and augmenting with monocular depth over the
instance mask. This reduces depth ambiguity compared to 2D arrow inputs while
remaining easy to use. Second, we preserve the salience of these cues in token
space with Dense RoPE, which tags a small set of motion tokens (anchored on the
first frame) with spatial-addressable rotary embeddings. Paired with joint RGB
\(+\) auxiliary-map prediction (segmentation or depth), our model anchors
structure while RGB handles appearance, stabilizing optimization and improving
temporal coherence without requiring per-frame trajectory scripts.

</details>


### [52] [Hierarchical Re-Classification: Combining Animal Classification Models with Vision Transformers](https://arxiv.org/abs/2510.14594)
*Hugo Markoff,Jevgenijs Galaktionovs*

Main category: cs.CV

TL;DR: 该论文提出了一种分层重分类系统，提高了动物检测平台物种级别识别的准确率，将泛泛的高层分类标签细化到具体物种，并在特定数据集上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 目前的动物分类模型如SpeciesNet，为保证预测的准确性，倾向于保守地给出较高分类层次（如属、科等），导致许多动物只被标注为高层类别，缺少具体的物种识别信息。提高物种级别的区分能力对于生态保护、监测等非常重要。

Method: 作者设计了一个五阶段管道系统，包括高置信度接受、鸟类覆盖、中心点构建、三元组损失度量学习、以及自适应余弦距离评分。该系统整合了SpeciesNet EfficientNetV2-M的预测、CLIP嵌入和度量学习算法，对检测到的高层标签进一步细化和重分类。

Result: 在LILA BC沙漠狮子保护数据集的一部分（4,018张图片，15,031次检测）上实验，系统能够从原本为"空白"或泛"动物"标签中恢复出761个鸟类检测，并以96.5%的准确率将456个检测样本的高层标签（动物、哺乳动物、空白）重分类为具体物种，其中64.9%的检测实现了物种级别的鉴定。

Conclusion: 该分层重分类系统有效提升了动物分类平台在物种级别的识别能力，有助于野生动物保护和生态研究中获取更精细的数据标签。

Abstract: State-of-the-art animal classification models like SpeciesNet provide
predictions across thousands of species but use conservative rollup strategies,
resulting in many animals labeled at high taxonomic levels rather than species.
We present a hierarchical re-classification system for the Animal Detect
platform that combines SpeciesNet EfficientNetV2-M predictions with CLIP
embeddings and metric learning to refine high-level taxonomic labels toward
species-level identification. Our five-stage pipeline (high-confidence
acceptance, bird override, centroid building, triplet-loss metric learning, and
adaptive cosine-distance scoring) is evaluated on a segment of the LILA BC
Desert Lion Conservation dataset (4,018 images, 15,031 detections). After
recovering 761 bird detections from "blank" and "animal" labels, we re-classify
456 detections labeled animal, mammal, or blank with 96.5% accuracy, achieving
species-level identification for 64.9 percent

</details>


### [53] [Zero-Shot Wildlife Sorting Using Vision Transformers: Evaluating Clustering and Continuous Similarity Ordering](https://arxiv.org/abs/2510.14596)
*Hugo Markoff,Jevgenijs Galaktionovs*

Main category: cs.CV

TL;DR: 本文针对相机陷阱（野生动物自动拍摄装置）所生成的大量未标注图片，提出并评估了无需已知类别标签的零样本动物分类与组织方法，借助自监督视觉变换器及聚类与降维技术，有效提升了图片整理与人工标注效率。


<details>
  <summary>Details</summary>
Motivation: 现有相机陷阱数据集中许多野生动物种类未被已知分类器覆盖，大量无标注图片难以高效分类与分析，限制了生物多样性监测与研究。需要开发无需先验类别、能处理未见物种的自动分类技术。

Method: 在Animal Detect平台内，作者采用基于自监督视觉变换器（如CLIP、DINOv2、MegaDescriptor）的零样本学习方法，结合无监督聚类（DBSCAN、GMM）、降维（PCA、UMAP）、及t-SNE连续相似度排序等技术，将相机陷阱野生动物图片进行分类、聚类与排序分析。实验以5个物种的数据集，使用真实标签仅作评估。

Result: DINOv2结合UMAP降维和GMM聚类，在5物种分类测试上达到88.6%准确率（macro-F1=0.874）；1D排序对哺乳动物与鸟类的一致性为88.2%，鱼类为95.2%，共计1500张图片。

Conclusion: 自监督视觉变换器结合零样本聚类与相似度排序技术，能高效准确组织未标注的野生动物图片，已被部署于生产环境显著提升生物多样性监测的人工标注和探索分析速度。

Abstract: Camera traps generate millions of wildlife images, yet many datasets contain
species that are absent from existing classifiers. This work evaluates
zero-shot approaches for organizing unlabeled wildlife imagery using
self-supervised vision transformers, developed and tested within the Animal
Detect platform for camera trap analysis. We compare unsupervised clustering
methods (DBSCAN, GMM) across three architectures (CLIP, DINOv2, MegaDescriptor)
combined with dimensionality reduction techniques (PCA, UMAP), and we
demonstrate continuous 1D similarity ordering via t-SNE projection. On a
5-species test set with ground truth labels used only for evaluation, DINOv2
with UMAP and GMM achieves 88.6 percent accuracy (macro-F1 = 0.874), while 1D
sorting reaches 88.2 percent coherence for mammals and birds and 95.2 percent
for fish across 1,500 images. Based on these findings, we deployed continuous
similarity ordering in production, enabling rapid exploratory analysis and
accelerating manual annotation workflows for biodiversity monitoring.

</details>


### [54] [Knowledge-based Visual Question Answer with Multimodal Processing, Retrieval and Filtering](https://arxiv.org/abs/2510.14605)
*Yuyang Hong,Jiaqi Gu,Qi Yang,Lubin Fan,Yue Wu,Ying Wang,Kun Ding,Shiming Xiang,Jieping Ye*

Main category: cs.CV

TL;DR: 本文提出一种名为Wiki-PRF的三阶段方法（处理、检索、过滤），显著提升了知识库增强视觉问答（KB-VQA）任务的答案质量，并在主流数据集上取得了SOTA表现。


<details>
  <summary>Details</summary>
Motivation: 当前基于检索增强的生成模型（RAG）在视觉问答任务中，存在多模态查询质量和检索结果相关性不足的问题，亟需改善多模态信息提取和结果筛选机制。

Method: 提出Wiki-PRF三阶段方法：第一阶段动态调用视觉工具处理，精准提取多模态检索信息；第二阶段融合视觉与文本特征进行多模态知识检索；第三阶段对检索结果相关性过滤与聚焦。此外，采用基于答题准确性与格式一致性的奖励信号，通过强化学习训练视觉语言模型。

Result: 在E-VQA和InfoSeek数据集上，模型分别达到36.0和42.8的领先答案质量，超越现有最新方法。

Conclusion: Wiki-PRF显著提升了KB-VQA任务的多模态查询与相关性过滤能力，经验证可显著改善答案质量，达到当前最优水平。

Abstract: Knowledge-based visual question answering (KB-VQA) requires visual language
models (VLMs) to integrate visual understanding with external knowledge
retrieval. Although retrieval-augmented generation (RAG) achieves significant
advances in this task by combining knowledge-base querying, it still struggles
with the quality of multimodal queries and the relevance of retrieved results.
To overcome these challenges, we propose a novel three-stage method, termed
Wiki-PRF, including Processing, Retrieval and Filtering stages. The processing
stage dynamically invokes visual tools to extract precise multimodal
information for retrieval. The retrieval stage integrates visual and text
features to achieve multimodal knowledge retrieval. The filtering stage
performs relevance filtering and concentration on retrieval results. To this
end, we introduce a visual language model trained with answer accuracy and
format consistency as reward signals via a reinforcement learning manner. This
enhances the model's reasoning, tool invocation for accurate queries, and
filtering of irrelevant content. Experiments on benchmark datasets (E-VQA and
InfoSeek) show significant improvements~(36.0 and 42.8) in answer quality,
achieving state-of-the-art performance. Code is available at
https://github.com/cqu-student/Wiki-PRF

</details>


### [55] [Shot2Tactic-Caption: Multi-Scale Captioning of Badminton Videos for Tactical Understanding](https://arxiv.org/abs/2510.14617)
*Ning Ding,Keisuke Fujii,Toru Tamaki*

Main category: cs.CV

TL;DR: 本文提出了Shot2Tactic-Caption框架，可为羽毛球比赛生成动作级和战术级的视频描述（caption），并发布了首个包含动作和战术描述的数据集。该方法具备良好的生成效果。


<details>
  <summary>Details</summary>
Motivation: 以往羽毛球视频理解主要关注单一动作或整体战术，缺乏可区分动作与战术执行过程的自动化描述方法。为了更好地对羽毛球比赛中的微观动作及其宏观战术调度进行建模和理解，作者提出需同时覆盖不同时间尺度的视频文本生成（captioning）方法。

Method: 提出Shot2Tactic-Caption框架，包括双分支架构，分别生成动作（shot）级和战术（tactic）级描述，各自配备视觉编码器、时空Transformer编码器及基于Transformer的解码器。新增Tactic Unit Detector用于检测战术单元、类型及状态。通过shot-wise prompt机制，将预测的战术类型和状态作为提示嵌入文本解码流程，实现更精准战术描述。

Result: 实验证明该框架能有效生成动作和战术描述，ResNet50为主干的时空编码器优于其他变体，引入shot-wise prompt能提升战术描述的连贯性和准确性。

Conclusion: Shot2Tactic-Caption能够高效捕捉羽毛球比赛中的动作与战术信息，为复杂运动视频的多尺度文本生成提供新方法与数据基准。

Abstract: Tactical understanding in badminton involves interpreting not only individual
actions but also how tactics are dynamically executed over time. In this paper,
we propose \textbf{Shot2Tactic-Caption}, a novel framework for semantic and
temporal multi-scale video captioning in badminton, capable of generating
shot-level captions that describe individual actions and tactic-level captions
that capture how these actions unfold over time within a tactical execution. We
also introduce the Shot2Tactic-Caption Dataset, the first badminton captioning
dataset containing 5,494 shot captions and 544 tactic captions.
Shot2Tactic-Caption adopts a dual-branch design, with both branches including a
visual encoder, a spatio-temporal Transformer encoder, and a Transformer-based
decoder to generate shot and tactic captions. To support tactic captioning, we
additionally introduce a Tactic Unit Detector that identifies valid tactic
units, tactic types, and tactic states (e.g., Interrupt, Resume). For tactic
captioning, we further incorporate a shot-wise prompt-guided mechanism, where
the predicted tactic type and state are embedded as prompts and injected into
the decoder via cross-attention. The shot-wise prompt-guided mechanism enables
our system not only to describe successfully executed tactics but also to
capture tactical executions that are temporarily interrupted and later resumed.
Experimental results demonstrate the effectiveness of our framework in
generating both shot and tactic captions. Ablation studies show that the
ResNet50-based spatio-temporal encoder outperforms other variants, and that
shot-wise prompt structuring leads to more coherent and accurate tactic
captioning.

</details>


### [56] [Efficient Video Sampling: Pruning Temporally Redundant Tokens for Faster VLM Inference](https://arxiv.org/abs/2510.14624)
*Natan Bagrov,Eugene Khvedchenia,Borys Tymchenko,Shay Aharon,Lior Kadoch,Tomer Keren,Ofri Masad,Yonatan Geifman,Ran Zilberstein,Tuomas Rintamaki,Matthieu Le,Andrew Tao*

Main category: cs.CV

TL;DR: 提出了一种提升多模态视频语言模型效率的方法，称为高效视频采样（EVS），通过剔除在连续帧中不变的空间区域以减少冗余token，显著提升推理速度且保持语义信息。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型在处理长视频时由于帧冗余和token上限，导致效率低下和推理延迟，需要一种无需改变模型结构即可高效处理长视频的新方法。

Method: EVS方法通过检测并去除视频中跨帧保持静止的空间补丁，从而减少输入帧的token数量，在不改变模型结构和无需重新训练的前提下，直接用于推理阶段。进一步，作者引入随机剪枝训练阶段，提高模型对不同压缩率的鲁棒性。

Result: EVS在推理阶段能将大模型的首次token输出延迟（TTFT）降低最高4倍，准确率损失极小。加以随机剪枝训练后，模型在高压缩率下也能保持完整表现。

Conclusion: EVS方法无需模型改造即可高效提升视频-语言模型的推理效率和可扩展性，在保证质量的前提下扩展了长视频理解的能力，为后续视频多模态模型提供了有效的解决方案。

Abstract: Vision-language models (VLMs) have recently expanded from static image
understanding to video reasoning, but their scalability is fundamentally
limited by the quadratic cost of processing dense frame sequences. Long videos
often exceed the token budget of modern language models, leading to severe
context limitations and latency issues. We introduce Efficient Video Sampling
(EVS), a simple, plug-and-play method for reducing token redundancy in videos
by identifying and pruning temporally static patches -- spatial regions that
remain unchanged across consecutive frames. EVS preserves positional identity,
requires no architectural changes or retraining. We show that EVS substantially
reduces token count while maintaining semantic fidelity, enabling faster
inference and longer input sequences. Applied at inference time, EVS reduces
large language model (LLM) time-to-first-token (TTFT) by up to 4x with minimal
accuracy loss. When combined with an uptraining phase using stochastic pruning
rates, EVS yields models that are robust to varying compression levels and
retain full performance under aggressive pruning. Extensive experiments
demonstrate that EVS consistently improves efficiency-accuracy trade-offs,
unlocking scalable video-language understanding without sacrificing quality.

</details>


### [57] [Adapting Self-Supervised Representations as a Latent Space for Efficient Generation](https://arxiv.org/abs/2510.14630)
*Ming Gui,Johannes Schusterbauer,Timy Phan,Felix Krause,Josh Susskind,Miguel Angel Bautista,Björn Ommer*

Main category: cs.CV

TL;DR: 提出RepTok方法，用单一连续潜在Token表示图像，实现高效、紧凑的生成建模，并在ImageNet和MS-COCO任务中取得了有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的2D潜在空间存在空间冗余，训练成本较高，且如何高效利用自监督学习的视觉表征用于生成建模是一个挑战。

Method: RepTok 以自监督vision transformer为基础，只微调语义token嵌入，同时训练生成解码器，目标函数包括流匹配损失和余弦相似性正则项，以保持原有潜在空间几何结构。仅用一个token表示整张图片。

Result: RepTok在ImageNet类条件生成和MS-COCO文本生成任务中，能够用极低的训练资源达到与复杂方法相当的性能。

Conclusion: 微调的自监督SSL表征可以成为高效紧凑的潜在空间，有助于低成本高效的图像生成任务。

Abstract: We introduce Representation Tokenizer (RepTok), a generative modeling
framework that represents an image using a single continuous latent token
obtained from self-supervised vision transformers. Building on a pre-trained
SSL encoder, we fine-tune only the semantic token embedding and pair it with a
generative decoder trained jointly using a standard flow matching objective.
This adaptation enriches the token with low-level, reconstruction-relevant
details, enabling faithful image reconstruction. To preserve the favorable
geometry of the original SSL space, we add a cosine-similarity loss that
regularizes the adapted token, ensuring the latent space remains smooth and
suitable for generation. Our single-token formulation resolves spatial
redundancies of 2D latent spaces and significantly reduces training costs.
Despite its simplicity and efficiency, RepTok achieves competitive results on
class-conditional ImageNet generation and naturally extends to text-to-image
synthesis, reaching competitive zero-shot performance on MS-COCO under
extremely limited training budgets. Our findings highlight the potential of
fine-tuned SSL representations as compact and effective latent spaces for
efficient generative modeling.

</details>


### [58] [SteeringTTA: Guiding Diffusion Trajectories for Robust Test-Time-Adaptation](https://arxiv.org/abs/2510.14634)
*Jihyun Yu,Yoojin Oh,Wonho Bae,Mingyu Kim,Junhyug Noh*

Main category: cs.CV

TL;DR: 提出了一种新的测试时自适应方法SteeringTTA，通过引导扩散过程调节输入，提升分类模型在分布漂移及图像扰动下的鲁棒性，并超越了现有基线。


<details>
  <summary>Details</summary>
Motivation: 当前测试时自适应方法在分布漂移（比如图像扰动）下改进深度模型性能，常依赖梯度指导，有探索与泛化局限。如何设计无需模型更新且能广泛适应不同失真类型的方法仍是挑战。

Method: 提出SteeringTTA方法，将Feynman-Kac steering应用到基于扩散的输入自适应中。该方法在推理时根据伪标签驱动奖励，不需要模型权重更新，仅通过对输入的处理实现适应。采用多粒子轨迹，引入累计Top-K概率与信息熵调度综合引导，提升探索与模型信心的平衡。

Result: 在ImageNet-C数据集上，SteeringTTA无需使用源数据或对模型参数进行更新，即可在多个扰动类型下稳定超越现有基线方法。

Conclusion: SteeringTTA是一种无需模型更新、仅推理阶段应用的扩散输入自适应框架，在分布漂移场景下对深度分类模型展示出更强的鲁棒性和广泛的适用性。

Abstract: Test-time adaptation (TTA) aims to correct performance degradation of deep
models under distribution shifts by updating models or inputs using unlabeled
test data. Input-only diffusion-based TTA methods improve robustness for
classification to corruptions but rely on gradient guidance, limiting
exploration and generalization across distortion types. We propose SteeringTTA,
an inference-only framework that adapts Feynman-Kac steering to guide
diffusion-based input adaptation for classification with rewards driven by
pseudo-label. SteeringTTA maintains multiple particle trajectories, steered by
a combination of cumulative top-K probabilities and an entropy schedule, to
balance exploration and confidence. On ImageNet-C, SteeringTTA consistently
outperforms the baseline without any model updates or source data.

</details>


### [59] [In-Context Learning with Unpaired Clips for Instruction-based Video Editing](https://arxiv.org/abs/2510.14648)
*Xinyao Liao,Xianfang Zeng,Ziye Song,Zhoujie Fu,Gang Yu,Guosheng Lin*

Main category: cs.CV

TL;DR: 本文提出了一种高效且低成本的指令驱动视频编辑预训练策略，仅需极少标注配对数据即可显著提升模型的编辑能力与质量。


<details>
  <summary>Details</summary>
Motivation: 当前基于指令的视频编辑技术发展滞后于图像编辑，主要原因是构建大规模配对视频编辑数据集代价过高且复杂。

Method: 提出了一种利用非配对视频片段进行上下文学习的预训练策略，先在约100万真实视频片段上学习基本编辑概念，再用不到15万配对编辑样本精细微调；该方法搭建在HunyuanVideoT2V模型之上。

Result: 实验表明，该方法在指令符合度和视觉保真度方面均优于现有方法，分别提升12%和15%。

Conclusion: 通过低成本预训练和少量高质量配对数据，显著提升了基于指令的视频编辑性能，为指令式视频编辑提供了有效解决方案。

Abstract: Despite the rapid progress of instruction-based image editing, its extension
to video remains underexplored, primarily due to the prohibitive cost and
complexity of constructing large-scale paired video editing datasets. To
address this challenge, we introduce a low-cost pretraining strategy for
instruction-based video editing that leverages in-context learning from
unpaired video clips. We show that pretraining a foundation video generation
model with this strategy endows it with general editing capabilities, such as
adding, replacing, or deleting operations, according to input editing
instructions. The pretrained model can then be efficiently refined with a small
amount of high-quality paired editing data. Built upon HunyuanVideoT2V, our
framework first pretrains on approximately 1M real video clips to learn basic
editing concepts, and subsequently fine-tunes on fewer than 150k curated
editing pairs to extend more editing tasks and improve the editing quality.
Comparative experiments show that our method surpasses existing
instruction-based video editing approaches in both instruction alignment and
visual fidelity, achieving a 12\% improvement in editing instruction following
and a 15\% improvement in editing quality.

</details>


### [60] [Decorrelation Speeds Up Vision Transformers](https://arxiv.org/abs/2510.14657)
*Kieran Carrigg,Rob van Gastel,Melda Yeghaian,Sander Dalm,Faysal Boughorbel,Marcel van Gerven*

Main category: cs.CV

TL;DR: 提出在MAE预训练中集成DBP方法，大幅度提升ViT预训练速度，并减少能耗。


<details>
  <summary>Details</summary>
Motivation: MAE在小样本的低标注环境下效果优秀，但因计算成本高，在工业实际应用中受限。作者希望解决MAE在工业应用中的实用性瓶颈。

Method: 将去相关反向传播（DBP）方法集成到MAE预训练的编码器部分，通过在每层迭代减少输入相关性，加速模型收敛，并且仅应用于编码器以保证稳定性。

Result: 在ImageNet-1K预训练，ADE20K微调任务上，DBP-MAE能将达到基线性能的时间缩短21.1%，碳排放减少21.4%，语义分割mIoU提升1.1分；在工业数据集上同样表现出加速和效果提升。

Conclusion: DBP方法可有效缩短ViT大规模预训练的所需时间与能耗，同时提升下游表现，适用于实际工业规模场景。

Abstract: Masked Autoencoder (MAE) pre-training of vision transformers (ViTs) yields
strong performance in low-label regimes but comes with substantial
computational costs, making it impractical in time- and resource-constrained
industrial settings. We address this by integrating Decorrelated
Backpropagation (DBP) into MAE pre-training, an optimization method that
iteratively reduces input correlations at each layer to accelerate convergence.
Applied selectively to the encoder, DBP achieves faster pre-training without
loss of stability. On ImageNet-1K pre-training with ADE20K fine-tuning, DBP-MAE
reduces wall-clock time to baseline performance by 21.1%, lowers carbon
emissions by 21.4% and improves segmentation mIoU by 1.1 points. We observe
similar gains when pre-training and fine-tuning on proprietary industrial data,
confirming the method's applicability in real-world scenarios. These results
demonstrate that DBP can reduce training time and energy use while improving
downstream performance for large-scale ViT pre-training.

</details>


### [61] [EuroMineNet: A Multitemporal Sentinel-2 Benchmark for Spatiotemporal Mining Footprint Analysis in the European Union (2015-2024)](https://arxiv.org/abs/2510.14661)
*Weikang Yu,Vincent Nwazelibe,Xianping Ma,Xiaokang Zhang,Richard Gloaguen,Xiao Xiang Zhu,Pedram Ghamisi*

Main category: cs.CV

TL;DR: 本文提出了EuroMineNet，这是第一个基于Sentinel-2多光谱影像的欧洲多时相矿区遥感监测基准数据集，为地表变化监测和环境管理提供了强有力的数据基础。


<details>
  <summary>Details</summary>
Motivation: 矿业活动尽管对经济和工业发展至关重要，但也是主要的环境恶化来源，如森林砍伐、土壤侵蚀和水体污染等。可持续资源管理需要对矿业引发的地表变化进行长期、跨区域的监测，而现有遥感数据常常受限于时间跨度或地理覆盖。

Method: 作者构建了EuroMineNet数据集，覆盖欧盟133个矿区，提供2015-2024年的年度多光谱观测和专家标注。提出了两大任务：1）基于多时相数据的矿区足迹年度映射，并引入了CA-TIoU指标；2）跨时相变化检测，识别缓慢及突变型地表变化。并对20种SOTA深度学习模型进行了基准测试。

Result: GeoAI模型在检测长期地表变化中表现良好，但对于获取及时治理所需的短期动态信息仍存在挑战。

Conclusion: EuroMineNet为实现时序一致且可解释的矿区动态监测提供了新的数据标准，有助于可持续土地产权管理和环境韧性提升，并推动GeoAI在社会与环境领域的应用。数据及代码已开源，有助于相关领域研究。

Abstract: Mining activities are essential for industrial and economic development, but
remain a leading source of environmental degradation, contributing to
deforestation, soil erosion, and water contamination. Sustainable resource
management and environmental governance require consistent, long-term
monitoring of mining-induced land surface changes, yet existing datasets are
often limited in temporal depth or geographic scope. To address this gap, we
present EuroMineNet, the first comprehensive multitemporal benchmark for mining
footprint mapping and monitoring based on Sentinel-2 multispectral imagery.
Spanning 133 mining sites across the European Union, EuroMineNet provides
annual observations and expert-verified annotations from 2015 to 2024, enabling
GeoAI-based models to analyze environmental dynamics at a continental scale. It
supports two sustainability-driven tasks: (1) multitemporal mining footprint
mapping for consistent annual land-use delineation, evaluated with a novel
Change-Aware Temporal IoU (CA-TIoU) metric, and (2) cross-temporal change
detection to capture both gradual and abrupt surface transformations.
Benchmarking 20 state-of-the-art deep learning models reveals that while GeoAI
methods effectively identify long-term environmental changes, challenges remain
in detecting short-term dynamics critical for timely mitigation. By advancing
temporally consistent and explainable mining monitoring, EuroMineNet
contributes to sustainable land-use management, environmental resilience, and
the broader goal of applying GeoAI for social and environmental good. We
release the codes and datasets by aligning with FAIR and the open science
paradigm at https://github.com/EricYu97/EuroMineNet.

</details>


### [62] [WeCKD: Weakly-supervised Chained Distillation Network for Efficient Multimodal Medical Imaging](https://arxiv.org/abs/2510.14668)
*Md. Abdur Rahman,Mohaimenul Azam Khan Raiaan,Sami Azam,Asif Karim,Jemima Beissbarth,Amanda Leach*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的链式弱监督知识蒸馏（WeCKD）方法，通过模型链结构依次细化和传递知识，实现了在有限数据下的高效学习和优异性能。


<details>
  <summary>Details</summary>
Motivation: 传统的知识蒸馏依赖大型、强力教师模型或大量标注数据，且采用静态的教师-学生模式，容易导致知识退化和效率低下，无法很好地适应真实世界中数据有限的情况。

Method: 提出了弱监督链式KD网络（WeCKD），将知识转移过程结构化为一系列互有联系的模型链。每个模型只用一部分数据，并在学习前一模型知识基础上进一步细化，再传递给下一个模型。这种递进式链式蒸馏，减少了对强教师和大数据的依赖。

Result: 在4个耳镜影像数据集上验证，WeCKD不仅达到甚至超越了传统监督方法的表现，且在2个其他医学图像数据集（如显微镜、MRI）上表现出良好的泛化性。准确率相较于同等数据条件下训练的单一模型最高提升23%。

Conclusion: 链式弱监督KD打破了传统模式，在有限标签数据场景下实现了高效知识迁移和优异效果，有望广泛应用于实际医学影像等有限数据领域。

Abstract: Knowledge distillation (KD) has traditionally relied on a static
teacher-student framework, where a large, well-trained teacher transfers
knowledge to a single student model. However, these approaches often suffer
from knowledge degradation, inefficient supervision, and reliance on either a
very strong teacher model or large labeled datasets, which limits their
effectiveness in real-world, limited-data scenarios. To address these, we
present the first-ever Weakly-supervised Chain-based KD network (WeCKD) that
redefines knowledge transfer through a structured sequence of interconnected
models. Unlike conventional KD, it forms a progressive distillation chain,
where each model not only learns from its predecessor but also refines the
knowledge before passing it forward. This structured knowledge transfer further
enhances feature learning, reduces data dependency, and mitigates the
limitations of one-step KD. Each model in the distillation chain is trained on
only a fraction of the dataset and demonstrates that effective learning can be
achieved with minimal supervision. Extensive evaluations across four otoscopic
imaging datasets demonstrate that it not only matches but in many cases
surpasses the performance of existing supervised methods. Experimental results
on two other datasets further underscore its generalization across diverse
medical imaging modalities, including microscopic and magnetic resonance
imaging. Furthermore, our evaluations resulted in cumulative accuracy gains of
up to +23% over a single backbone trained on the same limited data, which
highlights its potential for real-world adoption.

</details>


### [63] [VTimeCoT: Thinking by Drawing for Video Temporal Grounding and Reasoning](https://arxiv.org/abs/2510.14672)
*Jinglei Zhang,Yuanfan Guo,Rolandos Alexandros Potamias,Jiankang Deng,Hang Xu,Chao Ma*

Main category: cs.CV

TL;DR: 本文提出了一种名为VTimeCoT的训练无关系统，显著提升了多模态大语言模型（MLLM）在视频时序定位和推理上的表现。该方法通过进度条工具和跨模态推理链，有效提升了答案的准确性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大模型虽有进展，但在复杂视频的时序定位与推理能力不足，难以胜任实际复杂视频理解需求。因此，亟需更强的视频时序推理与定位能力提升方法。

Method: VTimeCoT框架无需额外训练，主要创新包括：1）引入进度条可插拔集成工具与高效高亮工具，强化视频进度信息表达；2）提出结合视频与文本的跨模态时序推理链（visuotemporal CoT），超越传统仅用文本的推理链方法。

Result: 在Qwen2VL-7B和GPT4o两个多模态模型上，VTimeCoT在视频时序定位及推理型问答任务中取得了显著性能提升。

Conclusion: VTimeCoT框架不仅大幅提高了多模态模型对视频的理解、定位与推理能力，还强化了模型推理的可解释性和组合性，展示了实际应用潜力。

Abstract: In recent years, video question answering based on multimodal large language
models (MLLM) has garnered considerable attention, due to the benefits from the
substantial advancements in LLMs. However, these models have a notable
deficiency in the domains of video temporal grounding and reasoning, posing
challenges to the development of effective real-world video understanding
systems. Inspired by how humans use video players to interact with the progress
bar for video comprehension, we introduce VTimeCoT, a simple yet effective
training-free framework, designed for high-performance video grounding and
reasoning. The proposed framework incorporates two novel visual tools of the
progress bar: a plug-and-play progress bar integration tool and a
high-efficiency highlighting tool. In addition, to address the limitations of
conventional text-based chain-of-thought (CoT) approaches, we introduce a
visuotemporal CoT process that integrates cross-modality reasoning across both
video and text. Our approach demonstrates significant performance improvements
on both Qwen2VL-7B and GPT4o baselines in tasks of video temporal grounding and
reasoning-based question answering. Finally, we showcase that the proposed
framework achieves a compositional and interpretable reasoning process. Project
page: https://vtimecot.github.io

</details>


### [64] [Leveraging Learned Image Prior for 3D Gaussian Compression](https://arxiv.org/abs/2510.14705)
*Seungjoo Shin,Jaesik Park,Sunghyun Cho*

Main category: cs.CV

TL;DR: 该论文提出了一种新的3D Gaussian Splatting（3DGS）压缩框架，通过引入学习型图像先验来提升压缩后图像的质量，实现更优的存储与渲染质量平衡，并且与现有高斯压缩方法兼容。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS压缩方法虽能大幅降低存储，但因缺乏学习型先验，受限于压缩率与质量的进一步提升。作者旨在通过学习型图像先验克服这一限制，改善压缩失真问题。

Method: 方法包含两步：首先对高斯分布进行常规压缩，然后利用恢复网络，在图像空间建模压缩伪影，并引入粗渲染残差作为辅助信息，通过恢复图像监督共同优化压缩高斯分布，从而增强压缩表达能力。

Result: 实验表明，该方法在保存更少存储空间的前提下，实现了优于现有主流3DGS压缩方法的渲染质量和率失真性能。

Conclusion: 新框架有效提升了3DGS压缩的率失真性能，在保证通用和兼容性的同时，推动了存储效率与渲染质量的双重提升。

Abstract: Compression techniques for 3D Gaussian Splatting (3DGS) have recently
achieved considerable success in minimizing storage overhead for 3D Gaussians
while preserving high rendering quality. Despite the impressive storage
reduction, the lack of learned priors restricts further advances in the
rate-distortion trade-off for 3DGS compression tasks. To address this, we
introduce a novel 3DGS compression framework that leverages the powerful
representational capacity of learned image priors to recover
compression-induced quality degradation. Built upon initially compressed
Gaussians, our restoration network effectively models the compression artifacts
in the image space between degraded and original Gaussians. To enhance the
rate-distortion performance, we provide coarse rendering residuals into the
restoration network as side information. By leveraging the supervision of
restored images, the compressed Gaussians are refined, resulting in a highly
compact representation with enhanced rendering performance. Our framework is
designed to be compatible with existing Gaussian compression methods, making it
broadly applicable across different baselines. Extensive experiments validate
the effectiveness of our framework, demonstrating superior rate-distortion
performance and outperforming the rendering quality of state-of-the-art 3DGS
compression methods while requiring substantially less storage.

</details>


### [65] [Where are the Whales: A Human-in-the-loop Detection Method for Identifying Whales in High-resolution Satellite Imagery](https://arxiv.org/abs/2510.14709)
*Caleb Robinson,Kimberly T. Goetz,Christin B. Khan,Meredith Sackett,Kathleen Leonard,Rahul Dodhia,Juan M. Lavista Ferres*

Main category: cs.CV

TL;DR: 本文提出了一种基于统计异常检测的半自动化方法，通过高分辨率卫星影像高效挖掘鲸鱼踪迹，大幅降低了专家人工审核的工作量，并且无需标注数据即可实现大范围检测。


<details>
  <summary>Details</summary>
Motivation: 鲸鱼监测对保护工作至关重要，但传统方法成本高、难以大规模开展。现有利用卫星影像识别鲸鱼的方法受制于数据标注稀缺、图像质量差异及机器学习流程复杂等问题。因此亟需一种高效可扩展、对标注依赖小的新型检测方法。

Method: 本研究利用统计异常检测（检测空间异常点）对高分辨率卫星影像进行初步筛查，筛选出“感兴趣点”，并结合网页标注界面让专家快速审核、标注这些点。整个流程无需依赖大量标注数据。

Result: 在三个含有鲸鱼已知标注的基准场景中，该方法召回率达到90.3%-96.4%，同时大幅缩小需要专家检查的面积——最多精简99.8%，从超过1000平方公里减至不足2平方公里。

Conclusion: 该半自动化统计异常检测方法不依赖标注数据，为大规模、机器辅助的海洋哺乳动物卫星监测，提供了可扩展的首步方案，并公开了完整的实现代码。

Abstract: Effective monitoring of whale populations is critical for conservation, but
traditional survey methods are expensive and difficult to scale. While prior
work has shown that whales can be identified in very high-resolution (VHR)
satellite imagery, large-scale automated detection remains challenging due to a
lack of annotated imagery, variability in image quality and environmental
conditions, and the cost of building robust machine learning pipelines over
massive remote sensing archives. We present a semi-automated approach for
surfacing possible whale detections in VHR imagery using a statistical anomaly
detection method that flags spatial outliers, i.e. "interesting points". We
pair this detector with a web-based labeling interface designed to enable
experts to quickly annotate the interesting points. We evaluate our system on
three benchmark scenes with known whale annotations and achieve recalls of
90.3% to 96.4%, while reducing the area requiring expert inspection by up to
99.8% -- from over 1,000 sq km to less than 2 sq km in some cases. Our method
does not rely on labeled training data and offers a scalable first step toward
future machine-assisted marine mammal monitoring from space. We have open
sourced this pipeline at https://github.com/microsoft/whales.

</details>


### [66] [Camera Movement Classification in Historical Footage: A Comparative Study of Deep Video Models](https://arxiv.org/abs/2510.14713)
*Tingyu Lin,Armin Dadras,Florian Kleber,Robert Sablatnig*

Main category: cs.CV

TL;DR: 论文系统评估了深度学习摄像机运动分类模型在历史档案影片上的泛化能力，发现现有模型面临不少挑战。


<details>
  <summary>Details</summary>
Motivation: 虽然摄像机运动对于视频内容理解至关重要，但当前方法主要集中在现代视频数据集上，对于历史档案影片（如二战影像）的泛化性能尚未被系统研究。

Method: 作者梳理了主流摄像机运动分类方法及其数据集，比较了模型结构与标签定义差异。通过在专家标注的二战档案影片数据集HISTORIAN上，对五种主流视频分类模型（如Video Swin Transformer）进行了系统评估。

Result: Video Swin Transformer在HISTORIAN数据集上的准确率达到80.25%，并在训练数据有限的情况下表现出良好收敛。

Conclusion: 结果显示现有方法在低质量历史影像上仍具潜力，但也面临挑战。未来可探索多模态信息和时序架构结合以提升模型泛化能力。

Abstract: Camera movement conveys spatial and narrative information essential for
understanding video content. While recent camera movement classification (CMC)
methods perform well on modern datasets, their generalization to historical
footage remains unexplored. This paper presents the first systematic evaluation
of deep video CMC models on archival film material. We summarize representative
methods and datasets, highlighting differences in model design and label
definitions. Five standard video classification models are assessed on the
HISTORIAN dataset, which includes expert-annotated World War II footage. The
best-performing model, Video Swin Transformer, achieves 80.25% accuracy,
showing strong convergence despite limited training data. Our findings
highlight the challenges and potential of adapting existing models to
low-quality video and motivate future work combining diverse input modalities
and temporal architectures.

</details>


### [67] [Cross-Layer Feature Self-Attention Module for Multi-Scale Object Detection](https://arxiv.org/abs/2510.14726)
*Dingzhou Xie,Rushi Lan,Cheng Pang,Enhao Ning,Jiahao Zeng,Wei Zheng*

Main category: cs.CV

TL;DR: 提出了一种创新的跨层特征自注意力模块（CFSAM），能提升多尺度目标检测效果，并在经典数据集上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有注意力机制多聚焦于单层或两层特征融合，忽视了深层特征之间的复杂依赖关系，导致对大尺度变化目标的检测能力有限。

Method: 设计了一种包含局部卷积特征提取器、基于Transformer的全局跨层建模和特征融合机制的CFSAM模块，并将其集成到SSD300目标检测框架中。

Result: 在PASCAL VOC和COCO数据集上，SSD300结合CFSAM后mAP分别从75.5%提升到78.6%、从43.1%提升到52.1%；同时加快了训练收敛速度，计算开销小。

Conclusion: 显式建模多尺度特征的跨层注意力能有效提升目标检测性能，是多尺度目标检测发展的关键方向。

Abstract: Recent object detection methods have made remarkable progress by leveraging
attention mechanisms to improve feature discriminability. However, most
existing approaches are confined to refining single-layer or fusing dual-layer
features, overlooking the rich inter-layer dependencies across multi-scale
representations. This limits their ability to capture comprehensive contextual
information essential for detecting objects with large scale variations. In
this paper, we propose a novel Cross-Layer Feature Self-Attention Module
(CFSAM), which holistically models both local and global dependencies within
multi-scale feature maps. CFSAM consists of three key components: a
convolutional local feature extractor, a Transformer-based global modeling unit
that efficiently captures cross-layer interactions, and a feature fusion
mechanism to restore and enhance the original representations. When integrated
into the SSD300 framework, CFSAM significantly boosts detection performance,
achieving 78.6% mAP on PASCAL VOC (vs. 75.5% baseline) and 52.1% mAP on COCO
(vs. 43.1% baseline), outperforming existing attention modules. Moreover, the
module accelerates convergence during training without introducing substantial
computational overhead. Our work highlights the importance of explicit
cross-layer attention modeling in advancing multi-scale object detection.

</details>


### [68] [Free-Grained Hierarchical Recognition](https://arxiv.org/abs/2510.14737)
*Seulki Park,Zilin Wang,Stella X. Yu*

Main category: cs.CV

TL;DR: 本论文提出了ImageNet-F数据集和自由粒度学习方法，推动了在真实标签粒度下的分层图像分类研究。


<details>
  <summary>Details</summary>
Motivation: 现有分层图像分类方法通常假设所有样本都有完整且细粒度的标注，但实际上由于图像质量、标注者经验及任务需求的不同，图像标签粒度往往混杂且不一。因此亟需满足现实条件下的分层分类算法与数据集。

Method: 作者构建了ImageNet-F基准数据集，根据认知学划分出基本、下属和细粒度三个层次，并通过CLIP模拟现实中混合粒度标签。此外，提出自由粒度学习范式，允许样本拥有不同层次标注。作者还结合视觉-语言模型生成的伪属性与半监督学习提升了语义和视觉引导能力，并充分实验验证。

Result: 在ImageNet-F混合标签粒度场景下，提出的方法和强化的基线显著提升了分层分类的性能。

Conclusion: 该工作为现实场景下分层图像分类提供了新的高质量数据集和有效方法，推进了该领域的发展。

Abstract: Hierarchical image classification predicts labels across a semantic taxonomy,
but existing methods typically assume complete, fine-grained annotations, an
assumption rarely met in practice. Real-world supervision varies in
granularity, influenced by image quality, annotator expertise, and task
demands; a distant bird may be labeled Bird, while a close-up reveals Bald
eagle. We introduce ImageNet-F, a large-scale benchmark curated from ImageNet
and structured into cognitively inspired basic, subordinate, and fine-grained
levels. Using CLIP as a proxy for semantic ambiguity, we simulate realistic,
mixed-granularity labels reflecting human annotation behavior. We propose
free-grain learning, with heterogeneous supervision across instances. We
develop methods that enhance semantic guidance via pseudo-attributes from
vision-language models and visual guidance via semi-supervised learning. These,
along with strong baselines, substantially improve performance under mixed
supervision. Together, our benchmark and methods advance hierarchical
classification under real-world constraints.

</details>


### [69] [DEXTER: Diffusion-Guided EXplanations with TExtual Reasoning for Vision Models](https://arxiv.org/abs/2510.14741)
*Simone Carnemolla,Matteo Pennisi,Sarinda Samarasinghe,Giovanni Bellitto,Simone Palazzo,Daniela Giordano,Mubarak Shah,Concetto Spampinato*

Main category: cs.CV

TL;DR: 本文提出DEXTER，一种无需数据即可解释视觉分类器行为的框架，通过扩散模型与大语言模型相结合，以自然语言生成全球性解释，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型的行为难以解析和解释，导致透明度和可信度不足。尤其是在无法访问训练数据或真实标签时，如何揭示分类器的偏好、决策边界及其潜在偏见成为重要问题。

Method: DEXTER不依赖原始数据，利用扩散模型与大语言模型联合，优化文本提示，生成能高度激活目标视觉分类器的类条件合成图像。再通过这些图像，自动生成详细自然语言报告，描述分类器的判别模式、决策逻辑与潜在偏差。体系结构能支持激活最大化、切片发现与消偏和偏见解释等多任务。

Result: DEXTER在ImageNet、Waterbirds、CelebA和FairFaces等数据集上进行实验证明，其能够准确解释模型行为、判别分类器偏见，并在用户研究和定量评测中优于现有主流方法。

Conclusion: DEXTER为视觉分类器提供了无需训练数据的全局解释和偏见分析手段，提升了AI系统透明度，具有良好泛化能力和实用前景。

Abstract: Understanding and explaining the behavior of machine learning models is
essential for building transparent and trustworthy AI systems. We introduce
DEXTER, a data-free framework that employs diffusion models and large language
models to generate global, textual explanations of visual classifiers. DEXTER
operates by optimizing text prompts to synthesize class-conditional images that
strongly activate a target classifier. These synthetic samples are then used to
elicit detailed natural language reports that describe class-specific decision
patterns and biases. Unlike prior work, DEXTER enables natural language
explanation about a classifier's decision process without access to training
data or ground-truth labels. We demonstrate DEXTER's flexibility across three
tasks-activation maximization, slice discovery and debiasing, and bias
explanation-each illustrating its ability to uncover the internal mechanisms of
visual classifiers. Quantitative and qualitative evaluations, including a user
study, show that DEXTER produces accurate, interpretable outputs. Experiments
on ImageNet, Waterbirds, CelebA, and FairFaces confirm that DEXTER outperforms
existing approaches in global model explanation and class-level bias reporting.
Code is available at https://github.com/perceivelab/dexter.

</details>


### [70] [LightQANet: Quantized and Adaptive Feature Learning for Low-Light Image Enhancement](https://arxiv.org/abs/2510.14753)
*Xu Wu,Zhihui Lai,Xianxu Hou,Jie Zhou,Ya-nan Zhang,Linlin Shen*

Main category: cs.CV

TL;DR: 本文提出了一种新方法LightQANet，通过量化与自适应特征学习，显著提升低光照图像增强效果，在多项数据集上取得了优异成绩。


<details>
  <summary>Details</summary>
Motivation: 现有低光照图像增强方法由于在低光环境下像素级信息严重退化，难以提取可靠特征，导致纹理恢复差、颜色不一致、易出现伪影。为解决这些问题，作者希望提升特征的鲁棒性和适应性，实现更一致的高质量图像增强。

Method: 提出了一种新框架LightQANet，核心包括两个模块：（1）光量化模块（LQM）—对图像特征中的光照因素进行显式量化和提取，通过结构化学习提升不同光照下的特征一致性；（2）光感知提示模块（LAPM）—将光照先验编码为可学习提示，动态引导特征学习过程，使模型自适应复杂多变的光照条件。

Result: 在多个主流低光照图像数据集上进行了大量实验，LightQANet在定性和定量评测中都表现出优越性能，且优于现有主流方法，证明了其在不同复杂光照场景下的一致性和鲁棒性。

Conclusion: LightQANet通过结构化量化和自适应引导，有效缓解了低光照下特征退化问题，显著提升了图像增强效果，对低光图像的高质量重建具有实际应用价值。

Abstract: Low-light image enhancement (LLIE) aims to improve illumination while
preserving high-quality color and texture. However, existing methods often fail
to extract reliable feature representations due to severely degraded
pixel-level information under low-light conditions, resulting in poor texture
restoration, color inconsistency, and artifact. To address these challenges, we
propose LightQANet, a novel framework that introduces quantized and adaptive
feature learning for low-light enhancement, aiming to achieve consistent and
robust image quality across diverse lighting conditions. From the static
modeling perspective, we design a Light Quantization Module (LQM) to explicitly
extract and quantify illumination-related factors from image features. By
enforcing structured light factor learning, LQM enhances the extraction of
light-invariant representations and mitigates feature inconsistency across
varying illumination levels. From the dynamic adaptation perspective, we
introduce a Light-Aware Prompt Module (LAPM), which encodes illumination priors
into learnable prompts to dynamically guide the feature learning process. LAPM
enables the model to flexibly adapt to complex and continuously changing
lighting conditions, further improving image enhancement. Extensive experiments
on multiple low-light datasets demonstrate that our method achieves
state-of-the-art performance, delivering superior qualitative and quantitative
results across various challenging lighting scenarios.

</details>


### [71] [Inpainting the Red Planet: Diffusion Models for the Reconstruction of Martian Environments in Virtual Reality](https://arxiv.org/abs/2510.14765)
*Giuseppe Lorenzo Catalano,Agata Marta Soccini*

Main category: cs.CV

TL;DR: 本研究提出了一种基于无条件扩散模型的火星地形三维重建方法，在NASA HiRISE获取的火星高程图数据集上训练，并显著优于现有的插值及修复技术。


<details>
  <summary>Details</summary>
Motivation: 虚拟现实在火星探索任务如任务规划、科学分析和宇航员训练中日益重要，而这些应用需要精确的三维地形数据。由于卫星遥感获取与传输限制，火星高程图通常存在大量缺失，现有插值技术难以保证几何一致性，因此火星地表重建成为亟需解决的问题。

Method: 作者采用无条件扩散模型，使用NASA HiRISE的12000幅火星高程图，经多尺度重采样处理后，输入128x128分辨率模型进行训练，并与主流插值和修复算法（如IDW、克里金、Navier-Stokes）在1000组测试样本上进行了对比。

Result: 提出方法在重建精度（RMSE提升4-15%）和感知相似度（LPIPS提升29-81%）上都优于现有的空洞填充和图像修复技术。

Conclusion: 基于无条件扩散模型的新方法在火星地形空洞修复上效果更优，有望为太阳系外星体地形建模和虚拟现实仿真提供更准确的数据支持。

Abstract: Space exploration increasingly relies on Virtual Reality for several tasks,
such as mission planning, multidisciplinary scientific analysis, and astronaut
training. A key factor for the reliability of the simulations is having
accurate 3D representations of planetary terrains. Extraterrestrial heightmaps
derived from satellite imagery often contain missing values due to acquisition
and transmission constraints. Mars is among the most studied planets beyond
Earth, and its extensive terrain datasets make the Martian surface
reconstruction a valuable task, although many areas remain unmapped. Deep
learning algorithms can support void-filling tasks; however, whereas Earth's
comprehensive datasets enables the use of conditional methods, such approaches
cannot be applied to Mars. Current approaches rely on simpler interpolation
techniques which, however, often fail to preserve geometric coherence. In this
work, we propose a method for reconstructing the surface of Mars based on an
unconditional diffusion model. Training was conducted on an augmented dataset
of 12000 Martian heightmaps derived from NASA's HiRISE survey. A
non-homogeneous rescaling strategy captures terrain features across multiple
scales before resizing to a fixed 128x128 model resolution. We compared our
method against established void-filling and inpainting techniques, including
Inverse Distance Weighting, kriging, and Navier-Stokes algorithm, on an
evaluation set of 1000 samples. Results show that our approach consistently
outperforms these methods in terms of reconstruction accuracy (4-15% on RMSE)
and perceptual similarity (29-81% on LPIPS) with the original data.

</details>


### [72] [MoCom: Motion-based Inter-MAV Visual Communication Using Event Vision and Spiking Neural Networks](https://arxiv.org/abs/2510.14770)
*Zhang Nengbo,Hann Woei Ho,Ye Zhou*

Main category: cs.CV

TL;DR: 该论文提出了一种受蜜蜂舞蹈启发的基于视觉运动信号的微型无人机(MAV)群通信框架，利用自主飞行动作传递信息，结合事件相机和轻量级神经网络，实现低功耗和准确的信息解码。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境下，传统基于无线电的MAV通信面临频谱拥堵、易受干扰和高能耗等问题。为解决这些问题，研究者希望寻求一种可替代、节能且鲁棒的通信方式。

Method: 作者设计了一套视觉通信体系：无人机通过特定飞行动作编码信息（如航向、距离），并使用事件相机捕捉，结合具有四种基本运动元的视觉字典表示指令（起始、结束、1、0）；利用事件帧分割模型和轻量级脉冲神经网络(SNN)进行动作识别，并通过集成算法实现信号解码。

Result: 实验结果表明，所提框架可以准确解码无人机的运动信号，且具有低功耗的优点。

Conclusion: 该方法为受限环境下的MAV通信提供了一种节能、高效且鲁棒的替代方案，有望推广到实际无人机集群通信中。

Abstract: Reliable communication in Micro Air Vehicle (MAV) swarms is challenging in
environments, where conventional radio-based methods suffer from spectrum
congestion, jamming, and high power consumption. Inspired by the waggle dance
of honeybees, which efficiently communicate the location of food sources
without sound or contact, we propose a novel visual communication framework for
MAV swarms using motion-based signaling. In this framework, MAVs convey
information, such as heading and distance, through deliberate flight patterns,
which are passively captured by event cameras and interpreted using a
predefined visual codebook of four motion primitives: vertical (up/down),
horizontal (left/right), left-to-up-to-right, and left-to-down-to-right,
representing control symbols (``start'', ``end'', ``1'', ``0''). To decode
these signals, we design an event frame-based segmentation model and a
lightweight Spiking Neural Network (SNN) for action recognition. An integrated
decoding algorithm then combines segmentation and classification to robustly
interpret MAV motion sequences. Experimental results validate the framework's
effectiveness, which demonstrates accurate decoding and low power consumption,
and highlights its potential as an energy-efficient alternative for MAV
communication in constrained environments.

</details>


### [73] [CoT-PL: Visual Chain-of-Thought Reasoning Meets Pseudo-Labeling for Open-Vocabulary Object Detection](https://arxiv.org/abs/2510.14792)
*Hojun Choi,Youngsun Lim,Jaeyo Shin,Hyunjung Shim*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的开放词汇目标检测(OVD)方法CoT-PL，通过引入结构化的视觉链式推理(CoT)和对比式背景学习(CBL)，实现在复杂场景下对新类别目标的鲁棒伪标签生成，显著提升在COCO和LVIS数据集上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇目标检测方法严重依赖图文匹配，而忽视了语义复杂或遮挡场景下的中间推理能力，因此在真实复杂环境下鲁棒性不足。作者提出结构化推理框架以改善伪标签的质量与泛化能力。

Method: 提出CoT-PL框架，将目标理解过程拆解为三个步骤：1) 区域感知（可识别未见目标）；2) 零样本推理类别识别；3) 背景泛化区分复杂语义对象。引入对比式背景学习(CBL)，用预计算的背景信息作为负样本，强化对象与背景特征解耦。

Result: 在遮挡和拥挤场景下，提出的CoT-PL分别在新类别伪标签质量上相较最佳对比方法提升了103.4%和168.4%。在COCO和LVIS开放词汇检测任务中，分别提升了+7.7 AP50和+2.9 mask AP，刷新了最新SOTA。

Conclusion: 结构化链式推理结合对比背景学习有效提升了复杂视觉场景下开放词汇检测的泛化能力和伪标签质量，为实际应用提供了更强的鲁棒性和更高的准确率。

Abstract: Open-vocabulary object detection (OVD) seeks to recognize and localize object
categories beyond those seen during training. Recent approaches typically
leverage vision-language models (VLMs) to generate pseudo-labels using
image-text alignment, allowing detectors to generalize to unseen classes
without explicit supervision. However, these methods depend heavily on direct
image-text matching, neglecting the intermediate reasoning steps essential for
interpreting semantically complex scenes. This results in limited robustness
when confronted with crowded or occluded visual contexts. In this paper, we
introduce CoT-PL, a new framework that employs structured visual
chain-of-thought (CoT) reasoning into the pseudo-labeling process. CoT-PL
decomposes object understanding into three interpretable steps: (1) region
perception even for unseen objects, (2) category recognition via zero-shot
reasoning, and (3) background grounding to separate semantically complex
objects. Crucially, the third step naturally motivates our contrastive
background learning (CBL) that uses the pre-computed background cues as
negatives to promote feature disentanglement between objects and background. In
this way, CoT reasoning and CBL form an integrated pipeline tailored to robust
pseudo-labeling in crowded or occluded scenes. Notably, in these two settings,
our novel-class pseudo-label quality achieves relative improvements of 103.4%
and 168.4% over the best prior, respectively. Our extensive experiments
demonstrate that CoT-PL achieves +7.7 AP50 on open-vocabulary COCO and +2.9
mask AP on LVIS for novel classes, setting a new state of the art.

</details>


### [74] [Morphology-Aware Prognostic model for Five-Year Survival Prediction in Colorectal Cancer from H&E Whole Slide Images](https://arxiv.org/abs/2510.14800)
*Usama Sajjad,Abdul Rehman Akbar,Ziyu Su,Deborah Knight,Wendy L. Frankel,Metin N. Gurcan,Wei Chen,Muhammad Khalid Khan Niazi*

Main category: cs.CV

TL;DR: 本研究提出了一种新型可解释的AI模型PRISM，用于表征结直肠癌患者切片的形态多样性，并在预后预测上超过现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有的通用AI模型在病理学应用中，常忽略器官特异的关键形态学特征，限制了在肿瘤异质性和生物学过程表征上的能力。研究旨在开发能更好反映结直肠癌形态连续性和生物学演化的AI工具。

Method: 开发了PRISM模型，结合连续变异表征不同形态学特征，通过分析424例III期结直肠癌、共874万张组织切片图像进行训练和评估。

Result: PRISM模型在预测结直肠癌五年总生存率表现优异（AUC=0.70），准确率68%，相较传统特异模型和基础AI模型分别提高15%和23%。模型对性别、分型及化疗方案表现出稳定性和鲁棒性。

Conclusion: PRISM具有优秀的预后预测能力和泛化稳定性，可弥补现有AI模型对结直肠癌形态学多样性表征的不足，推动精准病理诊断与个体化治疗。

Abstract: Colorectal cancer (CRC) remains the third most prevalent malignancy globally,
with approximately 154,000 new cases and 54,000 projected deaths anticipated
for 2025. The recent advancement of foundation models in computational
pathology has been largely propelled by task agnostic methodologies that can
overlook organ-specific crucial morphological patterns that represent distinct
biological processes that can fundamentally influence tumor behavior,
therapeutic response, and patient outcomes. The aim of this study is to develop
a novel, interpretable AI model, PRISM (Prognostic Representation of Integrated
Spatial Morphology), that incorporates a continuous variability spectrum within
each distinct morphology to characterize phenotypic diversity and reflecting
the principle that malignant transformation occurs through incremental
evolutionary processes rather than abrupt phenotypic shifts. PRISM is trained
on 8.74 million histological images extracted from surgical resection specimens
of 424 patients with stage III CRC. PRISM achieved superior prognostic
performance for five-year OS (AUC = 0.70 +- 0.04; accuracy = 68.37% +- 4.75%;
HR = 3.34, 95% CI = 2.28-4.90; p < 0.0001), outperforming existing CRC-specific
methods by 15% and AI foundation models by ~23% accuracy. It showed
sex-agnostic robustness (AUC delta = 0.02; accuracy delta = 0.15%) and stable
performance across clinicopathological subgroups, with minimal accuracy
fluctuation (delta = 1.44%) between 5FU/LV and CPT-11/5FU/LV regimens,
replicating the Alliance cohort finding of no survival difference between
treatments.

</details>


### [75] [Scaling Artificial Intelligence for Multi-Tumor Early Detection with More Reports, Fewer Masks](https://arxiv.org/abs/2510.14803)
*Pedro R. A. S. Bassi,Xinze Zhou,Wenxuan Li,Szymon Płotka,Jieneng Chen,Qi Chen,Zheren Zhu,Jakub Prządo,Ibrahim E. Hamacı,Sezgin Er,Yuhan Wang,Ashwin Kumar,Bjoern Menze,Jarosław B. Ćwikła,Yuyin Zhou,Akshay S. Chaudhari,Curtis P. Langlotz,Sergio Decherchi,Andrea Cavalli,Kang Wang,Yang Yang,Alan L. Yuille,Zongwei Zhou*

Main category: cs.CV

TL;DR: R-Super方法利用医学报告自动训练AI分割肿瘤，显著减少对手工勾画肿瘤掩膜的依赖，并在多个肿瘤类型上超越放射科医生表现。


<details>
  <summary>Details</summary>
Motivation: 目前肿瘤早筛依赖CT，但小肿瘤难以识别。AI可辅助，但训练需大量人工肿瘤掩膜，制作耗时耗资，而医疗报告却未充分利用。

Method: 提出R-Super方法，利用已有的大量医学报告训练AI分割与报告描述相符的肿瘤区域，无需大量精细手工掩膜。

Result: 在101,654份报告训练下，AI效果与以723个掩膜训练相当；报告与掩膜结合提升灵敏度13%、特异性8%，5/7肿瘤类型检测超越放射科专家，并拓展到无公开掩膜的多种肿瘤。

Conclusion: 大规模人工标注掩膜并非不可替代，R-Super为多种肿瘤早期检测提供了经济、可扩展的新途径。

Abstract: Early tumor detection save lives. Each year, more than 300 million computed
tomography (CT) scans are performed worldwide, offering a vast opportunity for
effective cancer screening. However, detecting small or early-stage tumors on
these CT scans remains challenging, even for experts. Artificial intelligence
(AI) models can assist by highlighting suspicious regions, but training such
models typically requires extensive tumor masks--detailed, voxel-wise outlines
of tumors manually drawn by radiologists. Drawing these masks is costly,
requiring years of effort and millions of dollars. In contrast, nearly every CT
scan in clinical practice is already accompanied by medical reports describing
the tumor's size, number, appearance, and sometimes, pathology
results--information that is rich, abundant, and often underutilized for AI
training. We introduce R-Super, which trains AI to segment tumors that match
their descriptions in medical reports. This approach scales AI training with
large collections of readily available medical reports, substantially reducing
the need for manually drawn tumor masks. When trained on 101,654 reports, AI
models achieved performance comparable to those trained on 723 masks. Combining
reports and masks further improved sensitivity by +13% and specificity by +8%,
surpassing radiologists in detecting five of the seven tumor types. Notably,
R-Super enabled segmentation of tumors in the spleen, gallbladder, prostate,
bladder, uterus, and esophagus, for which no public masks or AI models
previously existed. This study challenges the long-held belief that
large-scale, labor-intensive tumor mask creation is indispensable, establishing
a scalable and accessible path toward early detection across diverse tumor
types.
  We plan to release our trained models, code, and dataset at
https://github.com/MrGiovanni/R-Super

</details>


### [76] [Unifying Environment Perception and Route Choice Modeling for Trajectory Representation Learning](https://arxiv.org/abs/2510.14819)
*Ji Cao,Yu Wang,Tongya Zheng,Zujie Ren,Canghong Jin,Gang Chen,Mingli Song*

Main category: cs.CV

TL;DR: 提出了PRTraj框架，将环境感知与路径选择建模结合，用于更有效的轨迹表示学习，在多个任务和数据集上展现优异性能。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹表示学习方法通常仅视轨迹为时空序列，忽略了外部环境和内部路径选择行为对轨迹生成的重要影响，导致表示能力有限。

Method: 提出PRTraj框架，包括两个主要模块：(1) 环境感知模块，从周边兴趣点分布提取多粒度环境语义并增强路网信息；(2) 路径选择编码器，将轨迹的路段转移建模为决策序列，捕获路径选择行为；最终将上述特征融合得到全局轨迹表示。

Result: 在3个真实数据集和5个下游任务上进行大量实验证明：PRTraj在表现、通用性和数据高效性（如小样本情况下）均优于现有方法。

Conclusion: PRTraj通过结合环境语义和路径选择行为，实现了更鲁棒和泛化的轨迹表示学习，促进了相关下游应用，具有广泛适用性。

Abstract: Trajectory Representation Learning (TRL) aims to encode raw trajectories into
low-dimensional vectors, which can then be leveraged in various downstream
tasks, including travel time estimation, location prediction, and trajectory
similarity analysis. However, existing TRL methods suffer from a key oversight:
treating trajectories as isolated spatio-temporal sequences, without
considering the external environment and internal route choice behavior that
govern their formation. To bridge this gap, we propose a novel framework that
unifies comprehensive environment \textbf{P}erception and explicit
\textbf{R}oute choice modeling for effective \textbf{Traj}ectory representation
learning, dubbed \textbf{PRTraj}. Specifically, PRTraj first introduces an
Environment Perception Module to enhance the road network by capturing
multi-granularity environmental semantics from surrounding POI distributions.
Building on this environment-aware backbone, a Route Choice Encoder then
captures the route choice behavior inherent in each trajectory by modeling its
constituent road segment transitions as a sequence of decisions. These
route-choice-aware representations are finally aggregated to form the global
trajectory embedding. Extensive experiments on 3 real-world datasets across 5
downstream tasks validate the effectiveness and generalizability of PRTraj.
Moreover, PRTraj demonstrates strong data efficiency, maintaining robust
performance under few-shot scenarios. Our code is available at:
https://anonymous.4open.science/r/PRTraj.

</details>


### [77] [FraQAT: Quantization Aware Training with Fractional bits](https://arxiv.org/abs/2510.14823)
*Luca Morreale,Alberto Gil C. P. Ramos,Malcolm Chadwick,Mehid Noroozi,Ruchika Chavhan,Abhinav Mehrotra,Sourav Bhattacharya*

Main category: cs.CV

TL;DR: 本文提出了一种新的分数位量化方法，在保证高生成质量的前提下，将生成模型的参数精度逐步降低至4位，大幅提升了模型在移动设备上的高效部署能力。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的生成模型在图像合成和文本生成方面表现优异，但由于其模型容量巨大，难以在内存和计算受限的手机等设备上部署。现有量化技术降低了模型参数精度，提高了运行效率，但激进量化常常牺牲模型质量。因此，迫切需要一种既能提升部署效率，又能保持生成质量的方法。

Method: 作者提出了一种分数位量化方法（Fractional Bits Quantization），在优化过程中将模型精度由32位逐步降至4位参数，并通过利用分数位实现，在优化时有效保留原模型质量。

Result: 该方法在多种扩散模型（包括SD3.5-Medium、Sana、Pixart和FLUX.1-schnell）上测试，取得了比标准QAT低4-7%的FiD分数，表明生成质量有所提升。同时，将Sana模型成功部署并运行在搭载有Snapdragon 8 Elite HTP的三星S25U手机上，显示其高效性和实用性。

Conclusion: 分数位量化方法能在大幅压缩模型、显著降低内存与计算需求的同时，保持甚至提升生成模型的质量，非常适用于在边缘设备如手机上的高效落地。

Abstract: State-of-the-art (SOTA) generative models have demonstrated impressive
capabilities in image synthesis or text generation, often with a large capacity
model. However, these large models cannot be deployed on smartphones due to the
limited availability of on-board memory and computations. Quantization methods
lower the precision of the model parameters, allowing for efficient
computations, \eg, in \INT{8}. Although aggressive quantization addresses
efficiency and memory constraints, preserving the quality of the model remains
a challenge. To retain quality in previous aggressive quantization, we propose
a new fractional bits quantization (\short) approach. The novelty is a simple
yet effective idea: we progressively reduce the model's precision from 32 to 4
bits per parameter, and exploit the fractional bits during optimization to
maintain high generation quality. We show that the \short{} yields improved
quality on a variety of diffusion models, including SD3.5-Medium, Sana,
\pixart, and FLUX.1-schnell, while achieving $4-7\%$ lower FiD than standard
QAT. Finally, we deploy and run Sana on a Samsung S25U, which runs on the
Qualcomm SM8750-AB Snapdragon 8 Elite Hexagon Tensor Processor (HTP).

</details>


### [78] [Scaling Tumor Segmentation: Best Lessons from Real and Synthetic Data](https://arxiv.org/abs/2510.14831)
*Qi Chen,Xinze Zhou,Chen Liu,Hao Chen,Wenxuan Li,Zekun Jiang,Ziyan Huang,Yuxuan Zhao,Dexin Yu,Junjun He,Yefeng Zheng,Ling Shao,Alan Yuille,Zongwei Zhou*

Main category: cs.CV

TL;DR: 本文介绍了AbdomenAtlas 2.0，这是目前同类中最大、最详细的腹部肿瘤分割数据集，并证明合成数据可提升模型数据利用率，从而有效提升AI分割性能。


<details>
  <summary>Details</summary>
Motivation: 由于体素级标注的肿瘤数据集稀缺且制备成本高，限制了AI在肿瘤分割领域的发展。而扩大高质量数据集和探索合成数据的价值，有望突破这一瓶颈。

Method: 作者首先分析了自有JHH数据集，在1,500例之后AI性能提升趋于停滞，但利用合成数据，只需500例即可达到同样性能。借此启发，作者构建了AbdomenAtlas 2.0数据集：收集了10,135份CT扫描，15,130个肿瘤实例，涉及胰腺、肝脏、肾脏、结肠、食管和子宫六个器官，并包含5,893例对照扫描，全部由23名专家进行体素级标注。

Result: AbdomenAtlas 2.0是目前数量和细致度超越现有公开肿瘤数据集的大规模腹部CT肿瘤分割数据库。在基准测试上，该数据集使肿瘤分割模型在分布内测试提升了7% DSC，分布外测试提升了16% DSC。

Conclusion: AbdomenAtlas 2.0为基于AI的多器官肿瘤分割任务提供了坚实基础。利用合成数据可有效缓解数据瓶颈，提升模型训练效率和泛化性能。

Abstract: AI for tumor segmentation is limited by the lack of large, voxel-wise
annotated datasets, which are hard to create and require medical experts. In
our proprietary JHH dataset of 3,000 annotated pancreatic tumor scans, we found
that AI performance stopped improving after 1,500 scans. With synthetic data,
we reached the same performance using only 500 real scans. This finding
suggests that synthetic data can steepen data scaling laws, enabling more
efficient model training than real data alone. Motivated by these lessons, we
created AbdomenAtlas 2.0--a dataset of 10,135 CT scans with a total of 15,130
tumor instances per-voxel manually annotated in six organs (pancreas, liver,
kidney, colon, esophagus, and uterus) and 5,893 control scans. Annotated by 23
expert radiologists, it is several orders of magnitude larger than existing
public tumor datasets. While we continue expanding the dataset, the current
version of AbdomenAtlas 2.0 already provides a strong foundation--based on
lessons from the JHH dataset--for training AI to segment tumors in six organs.
It achieves notable improvements over public datasets, with a +7% DSC gain on
in-distribution tests and +16% on out-of-distribution tests.

</details>


### [79] [ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints](https://arxiv.org/abs/2510.14847)
*Meiqi Wu,Jiashu Zhu,Xiaokun Feng,Chubin Chen,Chen Zhu,Bingze Song,Fangyuan Mao,Jiahong Wu,Xiangxiang Chu,Kaiqi Huang*

Main category: cs.CV

TL;DR: 本文提出了ImagerySearch方法以提升视频生成模型在富有想象力场景下的表现，并引入了LDT-Bench基准进行评测。实验显示该方法优于现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 当前的视频生成模型在现实场景中表现出色，但在涉及长距离语义关系和罕见共现概念的想象力场景下表现显著下降。现有测试时方法缺乏自适应性，难以应对此类挑战。

Method: 提出了ImagerySearch，这是一种在推理阶段依据提示语动态调整搜索空间和奖励函数的自适应策略，从而更好地解析和生成复杂语义的想象类视频。作者还构建了LDT-Bench基准，包括2839对多样化概念对和自动化评测协议，用于衡量生成模型的创造力表现。

Result: 实验结果证明，ImagerySearch在LDT-Bench上显著优于已有的强基线模型和测试时缩放方法，在VBench基准上也取得了有竞争力的提升。

Conclusion: ImagerySearch显著提升了在复杂想象场景下的视频生成能力，LDT-Bench填补了该领域权威基准的空白，为未来的富有想象力视频生成研究提供了新工具和方向。

Abstract: Video generation models have achieved remarkable progress, particularly
excelling in realistic scenarios; however, their performance degrades notably
in imaginative scenarios. These prompts often involve rarely co-occurring
concepts with long-distance semantic relationships, falling outside training
distributions. Existing methods typically apply test-time scaling for improving
video quality, but their fixed search spaces and static reward designs limit
adaptability to imaginative scenarios. To fill this gap, we propose
ImagerySearch, a prompt-guided adaptive test-time search strategy that
dynamically adjusts both the inference search space and reward function
according to semantic relationships in the prompt. This enables more coherent
and visually plausible videos in challenging imaginative settings. To evaluate
progress in this direction, we introduce LDT-Bench, the first dedicated
benchmark for long-distance semantic prompts, consisting of 2,839 diverse
concept pairs and an automated protocol for assessing creative generation
capabilities. Extensive experiments show that ImagerySearch consistently
outperforms strong video generation baselines and existing test-time scaling
approaches on LDT-Bench, and achieves competitive improvements on VBench,
demonstrating its effectiveness across diverse prompt types. We will release
LDT-Bench and code to facilitate future research on imaginative video
generation.

</details>


### [80] [A Multi-Task Deep Learning Framework for Skin Lesion Classification, ABCDE Feature Quantification, and Evolution Simulation](https://arxiv.org/abs/2510.14855)
*Harsha Kotla,Arun Kumar Rajasekaran,Hannah Rana*

Main category: cs.CV

TL;DR: 该论文提出了一种新的深度学习框架，不仅能分辨皮肤病变类型，还能量化ABCDE各项特征，增强了模型的可解释性，并展示在大数据集上的高准确率。


<details>
  <summary>Details</summary>
Motivation: 早期发现黑色素瘤能显著提高生存率，但自动化皮肤病变分析仍具挑战。传统ABCDE分类法虽被认可，但深度学习模型普遍缺乏对这些特征的解释性，因此亟需将模型决策与医学标准对齐。

Method: 作者设计了一个深度学习框架，能够同时进行分类以及对ABC（不含E）特征数值量化，并通过数据拟合模拟特征随时间的变化，辅助实现E（演化）特征；此外，该框架还能在潜在空间中可视化ABC特征随病程演化轨迹。

Result: 在HAM10000公开数据集实验中，分类准确率约89%，黑色素瘤AUC达0.96。特征量化方面，对非对称性、颜色变化和直径的预测效果较好，边界不规则性较难建模。

Conclusion: 该框架为皮肤病变的临床可解释AI分析奠定基础，有助于医生理解和采纳ML诊断，推动皮肤癌进展机制研究及实际应用。

Abstract: Early detection of melanoma has grown to be essential because it
significantly improves survival rates, but automated analysis of skin lesions
still remains challenging. ABCDE, which stands for Asymmetry, Border
irregularity, Color variation, Diameter, and Evolving, is a well-known
classification method for skin lesions, but most deep learning mechanisms treat
it as a black box, as most of the human interpretable features are not
explained. In this work, we propose a deep learning framework that both
classifies skin lesions into categories and also quantifies scores for each
ABCD feature. It simulates the evolution of these features over time in order
to represent the E aspect, opening more windows for future exploration. The A,
B, C, and D values are quantified particularly within this work. Moreover, this
framework also visualizes ABCD feature trajectories in latent space as skin
lesions evolve from benign nevuses to malignant melanoma. The experiments are
conducted using the HAM10000 dataset that contains around ten thousand images
of skin lesions of varying stages. In summary, the classification worked with
an accuracy of around 89 percent, with melanoma AUC being 0.96, while the
feature evaluation performed well in predicting asymmetry, color variation, and
diameter, though border irregularity remains more difficult to model. Overall,
this work provides a deep learning framework that will allow doctors to link ML
diagnoses to clinically relevant criteria, thus improving our understanding of
skin cancer progression.

</details>


### [81] [Multi-modal video data-pipelines for machine learning with minimal human supervision](https://arxiv.org/abs/2510.14862)
*Mihai-Cristian Pîrvu,Marius Leordeanu*

Main category: cs.CV

TL;DR: 本论文提出了一种结合多种视觉模态、几乎无需人工监督的多模态学习方法，并将其应用于实时语义分割和深度估计，取得了在低参数模型下与大模型相当的效果。


<details>
  <summary>Details</summary>
Motivation: 现实世界本质是多模态的，传统的机器学习模型主要是单模态（如图像到语义、文本到情感），最近虽然出现了双模态（如图文结合），但真正理解世界需要整合所有模态。因此，作者希望解决多模态间整合与理解的问题，尤其是在低资源、自动化的场景下。

Method: 作者利用预训练专家模型，并在原始视频数据上以程序化方式自动组合各模态，构建全自动数据处理流水线（已开源）。然后利用PHG-MAE（一种专为多模态数据设计的模型），将其高效蒸馏到小于100万参数的低参数模型，且无须大量人工标注或监督。

Result: 在低参数（<1M）模型下，所提方法在多模态学习（如实时语义分割）中表现出与大型模型（约3亿参数）相当的竞争力。此外，该框架也成功部署并支持了其他“开箱即用”模型，比如DPT用于实时深度估计。

Conclusion: 本方法实现了多视觉模态的自动融合并在一般硬件上实现了实时应用，既极大降低了硬件需求，也减少了对人工标注和监督的依赖，对实际场景中的多模态理解和应用有很大促进作用。

Abstract: The real-world is inherently multi-modal at its core. Our tools observe and
take snapshots of it, in digital form, such as videos or sounds, however much
of it is lost. Similarly for actions and information passing between humans,
languages are used as a written form of communication. Traditionally, Machine
Learning models have been unimodal (i.e. rgb -> semantic or text ->
sentiment_class). Recent trends go towards bi-modality, where images and text
are learned together, however, in order to truly understand the world, we need
to integrate all these independent modalities. In this work we try to combine
as many visual modalities as we can using little to no human supervision. In
order to do this, we use pre-trained experts and procedural combinations
between them on top of raw videos using a fully autonomous data-pipeline, which
we also open-source. We then make use of PHG-MAE, a model specifically designed
to leverage multi-modal data. We show that this model which was efficiently
distilled into a low-parameter (<1M) can have competitive results compared to
models of ~300M parameters. We deploy this model and analyze the use-case of
real-time semantic segmentation from handheld devices or webcams on commodity
hardware. Finally, we deploy other off-the-shelf models using the same
framework, such as DPT for near real-time depth estimation.

</details>


### [82] [Benchmarking Multimodal Large Language Models for Face Recognition](https://arxiv.org/abs/2510.14866)
*Hatef Otroshi Shahreza,Sébastien Marcel*

Main category: cs.CV

TL;DR: 本文系统性地评测了多模态大模型（MLLMs）在面部识别任务中的表现，发现它们虽有一定优势，但在高精度识别方面仍落后于专用模型。


<details>
  <summary>Details</summary>
Motivation: 虽然MLLM已在多种视觉与语言任务中表现优异，但在面部识别领域的能力尚未被充分探索，特别是开源MLLM在标准基准上的表现缺乏系统性评测。

Method: 作者选择了多个主流面部识别数据集（如LFW, CALFW, CPLFW, CFP, AgeDB, RFW），对当前最先进的MLLM进行了系统性评测，对比其与现有专用面部识别模型的性能，遵循相似的评测协议。

Result: 实验结果显示，MLLM能捕捉丰富的语义信息，在面部相关任务中有一定潜力，但在无需微调的零样本高精度识别任务上，仍落后于传统专用面部识别模型。

Conclusion: 本工作为MLLM在面部识别领域的研究提供了基准，揭示了其优势与不足，并为开发更高准确率和泛化能力的新一代模型提供了参考。相关代码已公开。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable performance
across diverse vision-and-language tasks. However, their potential in face
recognition remains underexplored. In particular, the performance of
open-source MLLMs needs to be evaluated and compared with existing face
recognition models on standard benchmarks with similar protocol. In this work,
we present a systematic benchmark of state-of-the-art MLLMs for face
recognition on several face recognition datasets, including LFW, CALFW, CPLFW,
CFP, AgeDB and RFW. Experimental results reveal that while MLLMs capture rich
semantic cues useful for face-related tasks, they lag behind specialized models
in high-precision recognition scenarios in zero-shot applications. This
benchmark provides a foundation for advancing MLLM-based face recognition,
offering insights for the design of next-generation models with higher accuracy
and generalization. The source code of our benchmark is publicly available in
the project page.

</details>


### [83] [TOUCH: Text-guided Controllable Generation of Free-Form Hand-Object Interactions](https://arxiv.org/abs/2510.14874)
*Guangyi Han,Wei Zhai,Yuhang Yang,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 本文挑战了现有手-物交互（HOI）仅限于固定抓握动作的局限，提出了Free-Form HOI Generation，实现了可控、多样且符合物理规律的任意手部动作生成，并提供了新的高多样性数据集WildO2以及三阶段生成框架TOUCH。


<details>
  <summary>Details</summary>
Motivation: 当前HOI生成方法受限于物理先验（如力闭合）和泛化意图，导致生成的手部动作单一，未能反映日常生活中色彩丰富的交互方式。作者希望突破这一限制，实现更细粒度和多样化的手-物交互生成。

Method: 提出了Free-Form HOI Generation理念，扩展手-物交互至推、戳、旋转等多种动作。构建了WildO2数据集，涵盖了来自互联网视频的丰富3D手物交互，并设计了TOUCH框架：三阶段、多层次扩散模型，结合显式接触建模、接触一致性及物理约束，提升生成动作的多样性及真实性。

Result: 实验证明，TOUCH框架能够有效生成可控、多样、且符合物理规律的手-物交互动作，类型远超以往抓握类交互，覆盖了日常生活中常见的多种动作。

Conclusion: 该工作不仅突破了以往手-物交互的限制，还提供了丰富数据集和创新模型框架，为实现更逼真、多样的人机交互和增强现实等应用提供了强大基础。

Abstract: Hand-object interaction (HOI) is fundamental for humans to express intent.
Existing HOI generation research is predominantly confined to fixed grasping
patterns, where control is tied to physical priors such as force closure or
generic intent instructions, even when expressed through elaborate language.
Such an overly general conditioning imposes a strong inductive bias for stable
grasps, thus failing to capture the diversity of daily HOI. To address these
limitations, we introduce Free-Form HOI Generation, which aims to generate
controllable, diverse, and physically plausible HOI conditioned on fine-grained
intent, extending HOI from grasping to free-form interactions, like pushing,
poking, and rotating. To support this task, we construct WildO2, an in-the-wild
diverse 3D HOI dataset, which includes diverse HOI derived from internet
videos. Specifically, it contains 4.4k unique interactions across 92 intents
and 610 object categories, each with detailed semantic annotations. Building on
this dataset, we propose TOUCH, a three-stage framework centered on a
multi-level diffusion model that facilitates fine-grained semantic control to
generate versatile hand poses beyond grasping priors. This process leverages
explicit contact modeling for conditioning and is subsequently refined with
contact consistency and physical constraints to ensure realism. Comprehensive
experiments demonstrate our method's ability to generate controllable, diverse,
and physically plausible hand interactions representative of daily activities.
The project page is $\href{https://guangyid.github.io/hoi123touch}{here}$.

</details>


### [84] [BADAS: Context Aware Collision Prediction Using Real-World Dashcam Data](https://arxiv.org/abs/2510.14876)
*Roni Goldshmidt,Hamish Scott,Lorenzo Niccolini,Shizhan Zhu,Daniel Moura,Orly Zvitia*

Main category: cs.CV

TL;DR: 本文提出BADAS，一种专为车辆自身（ego-vehicle）碰撞威胁预测而设计的模型，有效减少误报，并在多个数据集上取得领先表现。公开了部分模型与数据助力领域研究。


<details>
  <summary>Details</summary>
Motivation: 当前碰撞预测方法无法区分与自身车辆相关的威胁和无关事故，导致实际部署中误报过多。因此需要针对自身车辆的碰撞进行更精准预测。

Method: 作者基于Nexar真实行车记录仪视频，开发BADAS模型家族，采用V-JEPA2骨干网络端到端训练。数据集专门重标注以区分自身车辆参与，并补充负样本与一致性告警时间标签。模型有公开（BADAS-Open）和私有（BADAS1.0）两种版本，分别用1.5k和40k视频训练。

Result: BADAS在DAD, DADA-2000, DoTA, Nexar等多个主流数据集上取得了AP/AUC最优表现，优于传统前方碰撞预警系统，并能给出更真实的事故预估时间。

Conclusion: BADAS显著提升了针对自身车辆碰撞的预测精度，减小误报，并推动了更真实的碰撞预警研究。作者公开部分模型权重和数据支持该方向的发展。

Abstract: Existing collision prediction methods often fail to distinguish between
ego-vehicle threats and random accidents not involving the ego vehicle, leading
to excessive false alerts in real-world deployment. We present BADAS, a family
of collision prediction models trained on Nexar's real-world dashcam collision
dataset -- the first benchmark designed explicitly for ego-centric evaluation.
We re-annotate major benchmarks to identify ego involvement, add consensus
alert-time labels, and synthesize negatives where needed, enabling fair AP/AUC
and temporal evaluation. BADAS uses a V-JEPA2 backbone trained end-to-end and
comes in two variants: BADAS-Open (trained on our 1.5k public videos) and
BADAS1.0 (trained on 40k proprietary videos). Across DAD, DADA-2000, DoTA, and
Nexar, BADAS achieves state-of-the-art AP/AUC and outperforms a
forward-collision ADAS baseline while producing more realistic time-to-accident
estimates. We release our BADAS-Open model weights and code, along with
re-annotations of all evaluation datasets to promote ego-centric collision
prediction research.

</details>


### [85] [ScaleWeaver: Weaving Efficient Controllable T2I Generation with Multi-Scale Reference Attention](https://arxiv.org/abs/2510.14882)
*Keli Liu,Zhendong Wang,Wengang Zhou,Shaodong Xu,Ruixiao Dong,Houqiang Li*

Main category: cs.CV

TL;DR: 本文提出了ScaleWeaver框架，使视觉自回归(VAR)模型在文本生成图像任务中实现高质量、可控且高效的生成。


<details>
  <summary>Details</summary>
Motivation: 现有视觉自回归(VAR)模型在文本到图像生成任务中已有较高质量和效率，但在可控生成方面仍然不足，尤其与扩散模型相比，如何精确、灵活地控制VAR模型生成过程是一个亟需解决的问题。

Method: 提出ScaleWeaver框架，基于对VAR模型的参数高效微调，核心为改进的MMDiT块和新颖的Reference Attention模块。Reference Attention通过舍弃image→condition方向的注意力机制，降低计算成本并增强控制注入的稳定性，同时采用少量参数重用和零初始化线性投影，有效融合控制信号又不影响基模型的生成能力。

Result: 大量实验表明，ScaleWeaver能够实现高质量、精确可控的图像生成，并且在效率上明显优于基于扩散的可控生成方法。

Conclusion: ScaleWeaver为视觉自回归范式下的可控文本到图像生成提供了一种实用且有效的解决方案，兼具高质量、精确控制和优越效率。

Abstract: Text-to-image generation with visual autoregressive~(VAR) models has recently
achieved impressive advances in generation fidelity and inference efficiency.
While control mechanisms have been explored for diffusion models, enabling
precise and flexible control within VAR paradigm remains underexplored. To
bridge this critical gap, in this paper, we introduce ScaleWeaver, a novel
framework designed to achieve high-fidelity, controllable generation upon
advanced VAR models through parameter-efficient fine-tuning. The core module in
ScaleWeaver is the improved MMDiT block with the proposed Reference Attention
module, which efficiently and effectively incorporates conditional information.
Different from MM Attention, the proposed Reference Attention module discards
the unnecessary attention from image$\rightarrow$condition, reducing
computational cost while stabilizing control injection. Besides, it
strategically emphasizes parameter reuse, leveraging the capability of the VAR
backbone itself with a few introduced parameters to process control
information, and equipping a zero-initialized linear projection to ensure that
control signals are incorporated effectively without disrupting the generative
capability of the base model. Extensive experiments show that ScaleWeaver
delivers high-quality generation and precise control while attaining superior
efficiency over diffusion-based methods, making ScaleWeaver a practical and
effective solution for controllable text-to-image generation within the visual
autoregressive paradigm. Code and models will be released.

</details>


### [86] [You May Speak Freely: Improving the Fine-Grained Visual Recognition Capabilities of Multimodal Large Language Models with Answer Extraction](https://arxiv.org/abs/2510.14885)
*Logan Lawrence,Oindrila Saha,Megan Wei,Chen Sun,Subhransu Maji,Grant Van Horn*

Main category: cs.CV

TL;DR: 本文提出了一种名为nlg2choice的两阶段方法，提升了多模态大模型在超大选项数量多项选择题（MCQ）及检索任务中的性能，并对比现有方法在若干细粒度视觉数据集上取得了更好结果。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大模型（MLLMs）在零样本视觉分类中表现突出，但在应对选项数量巨大且选项高度相关的MCQ时，答案提取和概率计算存在评估难题。同时，传统方法更关注文本任务，未能解决视觉任务在自然语言理解和高效检索上的挑战。

Method: 提出nlg2choice方法，包括：1）先用最小约束的开放式提问获取大模型的自由回答；2）随后采用仅文本的约束解码，预测最可能的选择。在检索场景中，通过早停法提升约束答案概率计算的效率。

Result: 在七个细粒度视觉数据集上的分类和检索任务中，nlg2choice方法较现有方案取得了性能提升，且该性能在自然语言形式多样的用户实际应用场景下同样稳定。

Conclusion: nlg2choice是一种简单高效的多模态大模型评估和推断新方法，尤其适用于选项众多且相关性高的多选题与检索任务，为细粒度视觉分类等应用带来新思路。

Abstract: Despite the renewed interest in zero-shot visual classification due to the
rise of Multimodal Large Language Models (MLLMs), the problem of evaluating
free-form responses of auto-regressive models remains a persistent challenge.
Most existing works focus on language-only tasks or don't consider Multiple
Choice Questions (MCQs) beyond 5-way options, both of which are critical
capabilities to solve tasks in Fine-Grained Visual Classification (FGVC) where
choice counts are in the hundreds to thousands and the choices are highly
related. Furthermore, in this highly multi-way MCQ setting it is not clear how
to extend LLM choice extraction to retrieval-based problems, where computing
probabilities over the choice set is computationally costly. In this work we
investigate nlg2choice, a simple two-stage method which first asks the MLLM an
open-ended question for the task with minimal constraints, then uses text-only
constrained decoding to predict the most likely choice. In retrieval settings,
we compute the probability of the constrained response taking that choice with
an early stopping method to significantly improve throughput. Our results show
improvement over a suite of seven fine-grained visual datasets when evaluating
in terms of classification and retrieval, and show that this performance holds
over the various ways that users of LLMs can implement tasks in natural
language.

</details>


### [87] [Leveraging Multimodal LLM Descriptions of Activity for Explainable Semi-Supervised Video Anomaly Detection](https://arxiv.org/abs/2510.14896)
*Furkan Mumcu,Michael J. Jones,Anoop Cherian,Yasin Yilmaz*

Main category: cs.CV

TL;DR: 本论文提出了一种基于多模态大模型（MLLM）的新型视频异常检测方法，通过生成和比对视频中物体活动和交互的文本描述，实现了对复杂异常的高效检测并提升了解释性。


<details>
  <summary>Details</summary>
Motivation: 现有半监督视频异常检测方法在应对物体交互等复杂异常场景时表现不佳且缺乏可解释性，亟需新的方案提升性能和透明度。

Method: 方法核心在于利用MLLM对视频中物体对在不同时刻的视觉输入进行查询，自动生成其活动和交互的文本描述。通过比较测试视频和正常训练视频中的这些高层次文本描述，判断是否存在异常。该方法具备良好的可解释性，同时可以与传统VAD方法结合提升解释能力。

Result: 在多个基准数据集上的实验表明，所提方法不仅有效检测了基于交互的复杂异常，还在无交互异常的数据集上达到了当前最优性能。

Conclusion: 作者提出的方法提升了对复杂视频异常（特别是交互异常）的检测能力，并赋予了检测过程更强的可解释性，为视频异常检测领域提供了新方向。

Abstract: Existing semi-supervised video anomaly detection (VAD) methods often struggle
with detecting complex anomalies involving object interactions and generally
lack explainability. To overcome these limitations, we propose a novel VAD
framework leveraging Multimodal Large Language Models (MLLMs). Unlike previous
MLLM-based approaches that make direct anomaly judgments at the frame level,
our method focuses on extracting and interpreting object activity and
interactions over time. By querying an MLLM with visual inputs of object pairs
at different moments, we generate textual descriptions of the activity and
interactions from nominal videos. These textual descriptions serve as a
high-level representation of the activity and interactions of objects in a
video. They are used to detect anomalies during test time by comparing them to
textual descriptions found in nominal training videos. Our approach inherently
provides explainability and can be combined with many traditional VAD methods
to further enhance their interpretability. Extensive experiments on benchmark
datasets demonstrate that our method not only detects complex interaction-based
anomalies effectively but also achieves state-of-the-art performance on
datasets without interaction anomalies.

</details>


### [88] [MaskCaptioner : Learning to Jointly Segment and Caption Object Trajectories in Videos](https://arxiv.org/abs/2510.14904)
*Gabriel Fiastre,Antoine Yang,Cordelia Schmid*

Main category: cs.CV

TL;DR: 本文提出利用先进的视觉语言模型（VLM）合成标注，扩展公开数据集，并提出了MaskCaptioner模型，实现了端到端的视频目标检测、分割、跟踪与描述任务，取得了最新的性能。


<details>
  <summary>Details</summary>
Motivation: 以往视频目标描述任务因人工标注难度大、成本高，数据匮乏，训练方案分离，导致效果不佳，因此需要高效的数据扩充与联合建模方法。

Method: 利用现有VLM模型自动生成对象轨迹的时空自然语言描述，扩展LVIS和LV-VIS数据集，得到LVISCap与LV-VISCap。提出MaskCaptioner模型，实现目标检测、分割、跟踪及描述的联合端到端训练。

Result: MaskCaptioner在扩展数据集预训练后，于VidSTG、VLN和BenSMOT三个DVOC主流数据集上均达到当前最优表现。

Conclusion: 提出的自动标注与端到端联合模型能够有效提升DVOC任务的性能，缓解人工标注难题，为未来视频理解任务提供了新思路。

Abstract: Dense Video Object Captioning (DVOC) is the task of jointly detecting,
tracking, and captioning object trajectories in a video, requiring the ability
to understand spatio-temporal details and describe them in natural language.
Due to the complexity of the task and the high cost associated with manual
annotation, previous approaches resort to disjoint training strategies,
potentially leading to suboptimal performance. To circumvent this issue, we
propose to generate captions about spatio-temporally localized entities
leveraging a state-of-the-art VLM. By extending the LVIS and LV-VIS datasets
with our synthetic captions (LVISCap and LV-VISCap), we train MaskCaptioner, an
end-to-end model capable of jointly detecting, segmenting, tracking and
captioning object trajectories. Moreover, with pretraining on LVISCap and
LV-VISCap, MaskCaptioner achieves state-of-the-art DVOC results on three
existing benchmarks, VidSTG, VLN and BenSMOT. The datasets and code are
available at https://www.gabriel.fiastre.fr/maskcaptioner/.

</details>


### [89] [3D Scene Prompting for Scene-Consistent Camera-Controllable Video Generation](https://arxiv.org/abs/2510.14945)
*JoungBin Lee,Jaewoo Jung,Jisang Han,Takuya Narihira,Kazumi Fukuda,Junyoung Seo,Sunghwan Hong,Yuki Mitsufuji,Seungryong Kim*

Main category: cs.CV

TL;DR: 3DScenePrompt是一种生成视频新片段的框架，可实现精准的摄像机控制并保持场景一致性，其核心在于结合时间与空间的双重条件输入，以及利用动态SLAM技术分离静态与动态场景信息，有效提升了长内容视频生成中的一致性和控制性。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成方法通常仅基于单帧或短片段，难以实现长视频的场景一致性和自由的摄像机移动控制。为突破这一限制，需要针对输入视频的空间与时间依赖进行更全面的建模，特别是要解决动态元素影响下的视频持续生成能力。

Method: 提出3DScenePrompt框架，利用时序相邻帧（保证运动连续性）和空间相邻内容（保持场景一致性）进行双重条件建模。同时，引入了3D场景记忆机制，仅保存输入视频中的静态几何信息。通过动态SLAM与动态掩码策略，将静态与动态区域分离，只将静态场景作为3D空间提示，从而使动态区域根据最新时序内容自然演化。

Result: 大量实验表明，该框架比现有方法在场景一致性、摄像机控制性和生成质量上都有明显提升。

Conclusion: 3DScenePrompt能够实现长视频的空间连贯性与精确的多视角控制，且保证运动真实和效率，解决了现有方法无法兼顾一致性与灵活性的问题，为长内容、高一致性视频生成提供了新思路。

Abstract: We present 3DScenePrompt, a framework that generates the next video chunk
from arbitrary-length input while enabling precise camera control and
preserving scene consistency. Unlike methods conditioned on a single image or a
short clip, we employ dual spatio-temporal conditioning that reformulates
context-view referencing across the input video. Our approach conditions on
both temporally adjacent frames for motion continuity and spatially adjacent
content for scene consistency. However, when generating beyond temporal
boundaries, directly using spatially adjacent frames would incorrectly preserve
dynamic elements from the past. We address this by introducing a 3D scene
memory that represents exclusively the static geometry extracted from the
entire input video. To construct this memory, we leverage dynamic SLAM with our
newly introduced dynamic masking strategy that explicitly separates static
scene geometry from moving elements. The static scene representation can then
be projected to any target viewpoint, providing geometrically consistent warped
views that serve as strong 3D spatial prompts while allowing dynamic regions to
evolve naturally from temporal context. This enables our model to maintain
long-range spatial coherence and precise camera control without sacrificing
computational efficiency or motion realism. Extensive experiments demonstrate
that our framework significantly outperforms existing methods in scene
consistency, camera controllability, and generation quality. Project page :
https://cvlab-kaist.github.io/3DScenePrompt/

</details>


### [90] [OmniMotion: Multimodal Motion Generation with Continuous Masked Autoregression](https://arxiv.org/abs/2510.14954)
*Zhe Li,Weihao Yuan,Weichao Shen,Siyu Zhu,Zilong Dong,Chang Xu*

Main category: cs.CV

TL;DR: 该论文提出一种创新的多模态全身人类动作生成方法，能够融合文本、语音和音乐信息，并在各项任务中取得最佳效果。


<details>
  <summary>Details</summary>
Motivation: 现有的动作生成方法在有效生成动作以及多模态信息整合上存在不足，难以兼顾连续性和多样化。该工作旨在提升生成机制并高效融合多种模态。

Method: 作者提出了连续掩码自回归运动Transformer，结合门控线性注意力和RMSNorm模块，能关注关键动作，并抑制异常和多模态异构带来的不稳定。此外，采用DiT结构增强扩散条件注入目标，通过AdaLN和跨注意力机制融合文本、语音和音乐信号。

Result: 在文本到动作、语音到手势、音乐到舞蹈等多模态生成任务上，该方法表现优于当前主流方法。

Conclusion: 新框架不仅解决了多模态融合难题，还在多个任务上展现出领先的动作生成效果，为后续研究提供了新的思路。

Abstract: Whole-body multi-modal human motion generation poses two primary challenges:
creating an effective motion generation mechanism and integrating various
modalities, such as text, speech, and music, into a cohesive framework. Unlike
previous methods that usually employ discrete masked modeling or autoregressive
modeling, we develop a continuous masked autoregressive motion transformer,
where a causal attention is performed considering the sequential nature within
the human motion. Within this transformer, we introduce a gated linear
attention and an RMSNorm module, which drive the transformer to pay attention
to the key actions and suppress the instability caused by either the abnormal
movements or the heterogeneous distributions within multi-modalities. To
further enhance both the motion generation and the multimodal generalization,
we employ the DiT structure to diffuse the conditions from the transformer
towards the targets. To fuse different modalities, AdaLN and cross-attention
are leveraged to inject the text, speech, and music signals. Experimental
results demonstrate that our framework outperforms previous methods across all
modalities, including text-to-motion, speech-to-gesture, and music-to-dance.
The code of our method will be made public.

</details>


### [91] [RealDPO: Real or Not Real, that is the Preference](https://arxiv.org/abs/2510.14955)
*Guo Cheng,Danni Yang,Ziqi Huang,Jianlou Si,Chenyang Si,Ziwei Liu*

Main category: cs.CV

TL;DR: 该论文提出了RealDPO方法，通过对比真实视频和模型输出，优化视频生成模型，使其能生成更自然、连贯且真实的运动画面。


<details>
  <summary>Details</summary>
Motivation: 尽管视频生成模型在画质上取得进步，但难以生成复杂且真实的动作，这严重影响了其实际应用价值。该问题源于现有模型无法很好地捕捉自然运动的流畅性与上下文一致性。

Method: 作者提出RealDPO，一种基于偏好学习的新对齐范式。它利用真实世界视频为正样本，将Direct Preference Optimization（DPO）与定制损失函数结合，通过对比真实与错误行为，实现迭代自我修正，提升动作真实感。此外，还开源了包含丰富人类活动动作细节的高质量视频数据集RealAction-5K，用于复杂动作合成的后训练。

Result: 实验证明，RealDPO在视频质量、文本对齐以及运动逼真度上，均显著优于现有的SOTA模型和偏好优化方法。

Conclusion: RealDPO为视频生成中的复杂运动建模带来了实用且高效的新范式，大幅提升了生成视频的动作表现与实际应用潜力。

Abstract: Video generative models have recently achieved notable advancements in
synthesis quality. However, generating complex motions remains a critical
challenge, as existing models often struggle to produce natural, smooth, and
contextually consistent movements. This gap between generated and real-world
motions limits their practical applicability. To address this issue, we
introduce RealDPO, a novel alignment paradigm that leverages real-world data as
positive samples for preference learning, enabling more accurate motion
synthesis. Unlike traditional supervised fine-tuning (SFT), which offers
limited corrective feedback, RealDPO employs Direct Preference Optimization
(DPO) with a tailored loss function to enhance motion realism. By contrasting
real-world videos with erroneous model outputs, RealDPO enables iterative
self-correction, progressively refining motion quality. To support
post-training in complex motion synthesis, we propose RealAction-5K, a curated
dataset of high-quality videos capturing human daily activities with rich and
precise motion details. Extensive experiments demonstrate that RealDPO
significantly improves video quality, text alignment, and motion realism
compared to state-of-the-art models and existing preference optimization
techniques.

</details>


### [92] [MathCanvas: Intrinsic Visual Chain-of-Thought for Multimodal Mathematical Reasoning](https://arxiv.org/abs/2510.14958)
*Weikang Shi,Aldrich Yu,Rongyao Fang,Houxing Ren,Ke Wang,Aojun Zhou,Changyao Tian,Xinyu Fu,Yuxuan Hu,Zimu Lu,Linjiang Huang,Si Liu,Rui Liu,Hongsheng Li*

Main category: cs.CV

TL;DR: 本文提出了MathCanvas，一个提升大型多模态模型（LMMs）在复杂数学问题中实现视觉辅助推理能力的完整框架。通过大规模配对语料和阶段性训练，大幅提升了模型在数学视觉推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型虽擅长文本推理，但在高度依赖视觉辅助的数学领域（如几何）表现不佳，主要因缺乏灵活且高质量生成、编辑数学图形与融合视觉链式推理的能力。

Method: 方法分为两个阶段：一是视觉操作阶段，利用超过1500万对图文配对数据对模型进行预训练，包括生成与逐步编辑数学图形；二是策略性视觉推理阶段，微调模型如何、何时在解决数学问题时引入并利用视觉辅助。还设计了新的评测基准MathCanvas-Bench，用于检验模型在视觉-文本交互推理上的能力。

Result: 所提出的BAGEL-Canvas模型在MathCanvas-Bench上相较于强力LMM基线提升了86%，并在其他公开数学基准上也表现出良好泛化能力。

Conclusion: MathCanvas为多模态模型在数学领域实现类人视觉推理提供了功能完善的框架、数据集与评测工具，有望推动LMMs在人机协作与自动求解复杂数学问题中的应用。

Abstract: While Large Language Models (LLMs) have excelled in textual reasoning, they
struggle with mathematical domains like geometry that intrinsically rely on
visual aids. Existing approaches to Visual Chain-of-Thought (VCoT) are often
limited by rigid external tools or fail to generate the high-fidelity,
strategically-timed diagrams necessary for complex problem-solving. To bridge
this gap, we introduce MathCanvas, a comprehensive framework designed to endow
unified Large Multimodal Models (LMMs) with intrinsic VCoT capabilities for
mathematics. Our approach consists of two phases. First, a Visual Manipulation
stage pre-trains the model on a novel 15.2M-pair corpus, comprising 10M
caption-to-diagram pairs (MathCanvas-Imagen) and 5.2M step-by-step editing
trajectories (MathCanvas-Edit), to master diagram generation and editing.
Second, a Strategic Visual-Aided Reasoning stage fine-tunes the model on
MathCanvas-Instruct, a new 219K-example dataset of interleaved visual-textual
reasoning paths, teaching it when and how to leverage visual aids. To
facilitate rigorous evaluation, we introduce MathCanvas-Bench, a challenging
benchmark with 3K problems that require models to produce interleaved
visual-textual solutions. Our model, BAGEL-Canvas, trained under this
framework, achieves an 86% relative improvement over strong LMM baselines on
MathCanvas-Bench, demonstrating excellent generalization to other public math
benchmarks. Our work provides a complete toolkit-framework, datasets, and
benchmark-to unlock complex, human-like visual-aided reasoning in LMMs. Project
Page: https://mathcanvas.github.io/

</details>


### [93] [C4D: 4D Made from 3D through Dual Correspondences](https://arxiv.org/abs/2510.14960)
*Shizun Wang,Zhenxiang Jiang,Xingyi Yang,Xinchao Wang*

Main category: cs.CV

TL;DR: 本文提出C4D框架，实现了从单目视频中恢复动态场景的4D（空间3D+时间）信息，支持几何、相机姿态及动态物体的联合估计，并在多个任务上表现优秀。


<details>
  <summary>Details</summary>
Motivation: 单目视频中的4D恢复（即在空间3D基础上结合时间，恢复动态场景的几何及相机运动）极具挑战，因动态物体破坏了多视图几何约束，导致现有静态场景3D重建方法在动态场景下效果不佳。

Method: C4D框架扩展点图（pointmap）为基础的3D重建方法，通过引入时间上的短期光流和长期跟踪两类对应关系，训练动态感知的点跟踪器，分离动态元素与静态背景。并设计了动态场景优化目标，实现逐帧3D几何和相机参数的恢复，2D轨迹提升为平滑的3D轨迹，实现端到端的4D重建。

Result: C4D不仅能完成全流程的4D恢复，在深度估计、相机姿态估计、点跟踪等多项下游任务上均表现出色。

Conclusion: C4D有效解决了单目动态场景4D恢复难题，推动了点云重建技术在动态场景中的应用。

Abstract: Recovering 4D from monocular video, which jointly estimates dynamic geometry
and camera poses, is an inevitably challenging problem. While recent
pointmap-based 3D reconstruction methods (e.g., DUSt3R) have made great
progress in reconstructing static scenes, directly applying them to dynamic
scenes leads to inaccurate results. This discrepancy arises because moving
objects violate multi-view geometric constraints, disrupting the
reconstruction. To address this, we introduce C4D, a framework that leverages
temporal Correspondences to extend existing 3D reconstruction formulation to
4D. Specifically, apart from predicting pointmaps, C4D captures two types of
correspondences: short-term optical flow and long-term point tracking. We train
a dynamic-aware point tracker that provides additional mobility information,
facilitating the estimation of motion masks to separate moving elements from
the static background, thus offering more reliable guidance for dynamic scenes.
Furthermore, we introduce a set of dynamic scene optimization objectives to
recover per-frame 3D geometry and camera parameters. Simultaneously, the
correspondences lift 2D trajectories into smooth 3D trajectories, enabling
fully integrated 4D reconstruction. Experiments show that our framework
achieves complete 4D recovery and demonstrates strong performance across
multiple downstream tasks, including depth estimation, camera pose estimation,
and point tracking. Project Page: https://littlepure2333.github.io/C4D

</details>


### [94] [RainDiff: End-to-end Precipitation Nowcasting Via Token-wise Attention Diffusion](https://arxiv.org/abs/2510.14962)
*Thao Nguyen,Jiaqi Ma,Fahad Shahbaz Khan,Souhaib Ben Taieb,Salman Khan*

Main category: cs.CV

TL;DR: 本文提出了一种结合Token级注意力机制的扩散模型，用于提升降水临近预报的准确性，并在多项实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 降水临近预报因大气的复杂时空动力学而极具挑战，现有扩散模型在精度与计算资源消耗之间存在权衡，需要更高效且强泛化能力的方法。

Method: 作者在U-Net扩散模型及时空编码器中集成Token级注意力机制，能够动态捕捉多尺度空间交互和时序演化，避免了对高资源消耗的像素空间扩散或单独训练自编码器的需求。

Result: 实验和可视化评估表明，所提方法在多个数据集上的表现明显优于最先进的方法，无论是在局部保真度、泛化能力还是鲁棒性方面均展现优势。

Conclusion: 本方法为复复杂降水过程的短时预报提供了更高效、更精确的新工具，具备提升应用现实价值的潜力。

Abstract: Precipitation nowcasting, predicting future radar echo sequences from current
observations, is a critical yet challenging task due to the inherently chaotic
and tightly coupled spatio-temporal dynamics of the atmosphere. While recent
advances in diffusion-based models attempt to capture both large-scale motion
and fine-grained stochastic variability, they often suffer from scalability
issues: latent-space approaches require a separately trained autoencoder,
adding complexity and limiting generalization, while pixel-space approaches are
computationally intensive and often omit attention mechanisms, reducing their
ability to model long-range spatio-temporal dependencies. To address these
limitations, we propose a Token-wise Attention integrated into not only the
U-Net diffusion model but also the spatio-temporal encoder that dynamically
captures multi-scale spatial interactions and temporal evolution. Unlike prior
approaches, our method natively integrates attention into the architecture
without incurring the high resource cost typical of pixel-space diffusion,
thereby eliminating the need for separate latent modules. Our extensive
experiments and visual evaluations across diverse datasets demonstrate that the
proposed method significantly outperforms state-of-the-art approaches, yielding
superior local fidelity, generalization, and robustness in complex
precipitation forecasting scenarios.

</details>


### [95] [ChangingGrounding: 3D Visual Grounding in Changing Scenes](https://arxiv.org/abs/2510.14965)
*Miao Hu,Zhiwei Huang,Tai Wang,Jiangmiao Pang,Dahua Lin,Nanning Zheng,Runsen Xu*

Main category: cs.CV

TL;DR: 该论文提出了ChangingGrounding基准，专门评估在动态场景中机器人如何基于记忆高效地根据自然语言指令定位物体，并且提出了新的基线方法Mem-ChangingGrounder。


<details>
  <summary>Details</summary>
Motivation: 现有3D视觉指向（3DVG）方法通常假设场景点云已重建且实时更新，但实际上这种假设极不现实，昂贵且影响机器人部署。因此，研究者希望找到能在不断变化场景中高效定位目标物体的新方法。

Method: 作者提出ChangingGrounding基准，用于测试代理如何利用历史观测、只在必要时探索并在动态场景中精准输出3D框。同时提出Mem-ChangingGrounder新方法，结合跨模态检索与轻量级多视角融合：通过理解指令确定目标类别，检索相关记忆引导探索，只在必要处多视角扫描并融合结果，最终获得精确定位。

Result: 在ChangingGrounding基准测试中，Mem-ChangingGrounder实现了最高定位准确率，并且显著降低了场景探索成本。多个现有基线方法的效果都不及它。

Conclusion: 该论文首次正式提出动态记忆驱动的3D视觉指向问题，并通过新基准和方法推动该领域研究向实际应用和记忆中心的方法转变。

Abstract: Real-world robots localize objects from natural-language instructions while
scenes around them keep changing. Yet most of the existing 3D visual grounding
(3DVG) method still assumes a reconstructed and up-to-date point cloud, an
assumption that forces costly re-scans and hinders deployment. We argue that
3DVG should be formulated as an active, memory-driven problem, and we introduce
ChangingGrounding, the first benchmark that explicitly measures how well an
agent can exploit past observations, explore only where needed, and still
deliver precise 3D boxes in changing scenes. To set a strong reference point,
we also propose Mem-ChangingGrounder, a zero-shot method for this task that
marries cross-modal retrieval with lightweight multi-view fusion: it identifies
the object type implied by the query, retrieves relevant memories to guide
actions, then explores the target efficiently in the scene, falls back when
previous operations are invalid, performs multi-view scanning of the target,
and projects the fused evidence from multi-view scans to get accurate object
bounding boxes. We evaluate different baselines on ChangingGrounding, and our
Mem-ChangingGrounder achieves the highest localization accuracy while greatly
reducing exploration cost. We hope this benchmark and method catalyze a shift
toward practical, memory-centric 3DVG research for real-world applications.
Project page: https://hm123450.github.io/CGB/ .

</details>


### [96] [WithAnyone: Towards Controllable and ID Consistent Image Generation](https://arxiv.org/abs/2510.14975)
*Hengyuan Xu,Wei Cheng,Peng Xing,Yixiao Fang,Shuhan Wu,Rui Wang,Xianfang Zeng,Daxin Jiang,Gang Yu,Xingjun Ma,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 该论文关注文本到图像生成中的身份一致性问题，并提出一套新方法和数据集，有效缓解了以往模型容易出现的人脸直接复制问题，实现了在保持身份一致的同时展现更多自然变化。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成模型由于缺乏含有同一身份多样图片的大规模数据集，通常只能通过重建式训练，在身份迁移时容易导致'copy-paste'问题——即直接复制参考脸部，缺乏自然的变化和可控性。亟需解决该问题以提升模型的实际应用价值和表达力。

Method: 作者首先构建了大规模多身份配对数据集MultiID-2M，以便为每个身份提供丰富的参考图像；其次设计了用于量化copy-paste效应与身份一致性/多样性平衡的基准测试；最后提出了一种结合对比身份损失的新训练范式，利用多样配对数据实现身份一致性与生成多样性的有效平衡。最终开发了扩散模型WithAnyone。

Result: WithAnyone模型在减少copy-paste伪影、提升对姿态和表情的可控性，以及保持高感知质量方面表现显著优于现有方法。实验结果包括定量、定性比较及用户调研验证，均显示出该方法兼具高身份一致性和丰富可控多样性。

Conclusion: 本文提出的数据集、基准和新训练策略，为身份一致的可控文本到图像生成提供了有效解决方案。WithAnyone模型大幅提升了生成图像的表达力和实用性，有助于推动相关领域的发展。

Abstract: Identity-consistent generation has become an important focus in text-to-image
research, with recent models achieving notable success in producing images
aligned with a reference identity. Yet, the scarcity of large-scale paired
datasets containing multiple images of the same individual forces most
approaches to adopt reconstruction-based training. This reliance often leads to
a failure mode we term copy-paste, where the model directly replicates the
reference face rather than preserving identity across natural variations in
pose, expression, or lighting. Such over-similarity undermines controllability
and limits the expressive power of generation. To address these limitations, we
(1) construct a large-scale paired dataset MultiID-2M, tailored for
multi-person scenarios, providing diverse references for each identity; (2)
introduce a benchmark that quantifies both copy-paste artifacts and the
trade-off between identity fidelity and variation; and (3) propose a novel
training paradigm with a contrastive identity loss that leverages paired data
to balance fidelity with diversity. These contributions culminate in
WithAnyone, a diffusion-based model that effectively mitigates copy-paste while
preserving high identity similarity. Extensive qualitative and quantitative
experiments demonstrate that WithAnyone significantly reduces copy-paste
artifacts, improves controllability over pose and expression, and maintains
strong perceptual quality. User studies further validate that our method
achieves high identity fidelity while enabling expressive controllable
generation.

</details>


### [97] [Terra: Explorable Native 3D World Model with Point Latents](https://arxiv.org/abs/2510.14977)
*Yuanhui Huang,Weiliang Chen,Wenzhao Zheng,Xin Tao,Pengfei Wan,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: 本文提出了一种新的本地3D世界建模方法——Terra，采用原生3D潜空间建模和生成可探索环境，显著提升了3D一致性和建模效率，在ScanNet v2数据集上取得了重建与生成的最优表现。


<details>
  <summary>Details</summary>
Motivation: 现有世界模型多以与像素对齐的2D表示为主，忽略了物理世界的3D属性，导致3D一致性和建模效率不佳。作者试图通过直接在3D潜空间建模来解决该瓶颈。

Method: 1) 提出了P2G-VAE，将3D输入编码成点云潜表示，解码为3D高斯基元以融合几何与外观；2) 提出SPFlow网络，支持对点云潜在空间的位置和特征去噪生成；3) 利用逐步生成机制实现可探索的世界建模。

Result: 在ScanNet v2室内场景数据集上实验显示，Terra在3D一致性、重建与生成任务上表现出色，优于现有方法，且能够从任意视角高效渲染。

Conclusion: 作者提出的Terra模型通过原生3D潜空间建模及高斯基元表示，能够更好地实现高一致性、高效率的可探索世界生成，在3D世界建模上迈出了重要一步。

Abstract: World models have garnered increasing attention for comprehensive modeling of
the real world. However, most existing methods still rely on pixel-aligned
representations as the basis for world evolution, neglecting the inherent 3D
nature of the physical world. This could undermine the 3D consistency and
diminish the modeling efficiency of world models. In this paper, we present
Terra, a native 3D world model that represents and generates explorable
environments in an intrinsic 3D latent space. Specifically, we propose a novel
point-to-Gaussian variational autoencoder (P2G-VAE) that encodes 3D inputs into
a latent point representation, which is subsequently decoded as 3D Gaussian
primitives to jointly model geometry and appearance. We then introduce a sparse
point flow matching network (SPFlow) for generating the latent point
representation, which simultaneously denoises the positions and features of the
point latents. Our Terra enables exact multi-view consistency with native 3D
representation and architecture, and supports flexible rendering from any
viewpoint with only a single generation process. Furthermore, Terra achieves
explorable world modeling through progressive generation in the point latent
space. We conduct extensive experiments on the challenging indoor scenes from
ScanNet v2. Terra achieves state-of-the-art performance in both reconstruction
and generation with high 3D consistency.

</details>


### [98] [Learning an Image Editing Model without Image Editing Pairs](https://arxiv.org/abs/2510.14978)
*Nupur Kumari,Sheng-Yu Wang,Nanxuan Zhao,Yotam Nitzan,Yuheng Li,Krishna Kumar Singh,Richard Zhang,Eli Shechtman,Jun-Yan Zhu,Xun Huang*

Main category: cs.CV

TL;DR: 本文提出了一种全新无配对数据的图片编辑模型训练范式，通过直接利用视觉-语言模型（VLM）的反馈优化扩散模型，实现自然语言编辑指令驱动的高质量图片编辑。该方法无需庞大的输入-目标配对数据，效果媲美甚至优于依赖有监督大数据训练的现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图片编辑模型依赖于大规模的输入-目标配对数据进行有监督微调，但这种数据难以大规模获取，且使用合成数据会引入预训练模型的伪影并被放大，因此亟需无需配对数据的训练方案。

Method: 作者提出直接在训练过程中展开few-step扩散模型，并用VLM对编辑指令的遵循度和内容保持进行评估，向扩散模型反馈梯度实现端到端直接优化；同时，以分布匹配损失（DMD）保证生成图片的真实感。整个过程完全不依赖配对训练数据。

Result: 在标准基准数据集上的测试及消融实验结果显示，无需配对数据的新方法在few-step设定下，与依赖配对数据的各种扩散模型表现持平甚至更优。此外，比基于强化学习的Flow-GRPO等方法在同样VLM奖励模型条件下表现更佳。

Conclusion: 该方法证明无需配对数据也能实现高质量自然语言图片编辑，在数据资源受限或真实数据难以获取场景下具有重要应用价值，为图片生成模型带来了新的训练范式。

Abstract: Recent image editing models have achieved impressive results while following
natural language editing instructions, but they rely on supervised fine-tuning
with large datasets of input-target pairs. This is a critical bottleneck, as
such naturally occurring pairs are hard to curate at scale. Current workarounds
use synthetic training pairs that leverage the zero-shot capabilities of
existing models. However, this can propagate and magnify the artifacts of the
pretrained model into the final trained model. In this work, we present a new
training paradigm that eliminates the need for paired data entirely. Our
approach directly optimizes a few-step diffusion model by unrolling it during
training and leveraging feedback from vision-language models (VLMs). For each
input and editing instruction, the VLM evaluates if an edit follows the
instruction and preserves unchanged content, providing direct gradients for
end-to-end optimization. To ensure visual fidelity, we incorporate distribution
matching loss (DMD), which constrains generated images to remain within the
image manifold learned by pretrained models. We evaluate our method on standard
benchmarks and include an extensive ablation study. Without any paired data,
our method performs on par with various image editing diffusion models trained
on extensive supervised paired data, under the few-step setting. Given the same
VLM as the reward model, we also outperform RL-based techniques like Flow-GRPO.

</details>


### [99] [From Pixels to Words -- Towards Native Vision-Language Primitives at Scale](https://arxiv.org/abs/2510.14979)
*Haiwen Diao,Mingxuan Li,Silei Wu,Linjun Dai,Xiaohua Wang,Hanming Deng,Lewei Lu,Dahua Lin,Ziwei Liu*

Main category: cs.CV

TL;DR: 本文提出了一种新的原生视觉-语言模型（VLMs）架构和训练范式，并推出NEO模型家族，具有与主流模块化VLMs媲美的表现，同时解决了易用性与可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的原生VLMs在模型架构和训练方式上存在根本性障碍，且研究门槛较高，不利于普及和快速发展。作者希望厘清这些挑战并提出解决思路，推动领域进步。

Method: 作者分析了原生VLMs与模块化VLMs的区别，提出原生VLM的三项基本原则：像素与文本表示对齐、整合视觉与语言模块优点、具备跨模态表征与推理能力。基于这些原则，设计了NEO模型，并用39万对图文数据进行训练。

Result: NEO 在多个实际场景下性能可与当前顶级模块化VLMs媲美。同时，训练效率高，实现了从零学习视觉感知，并有效缓解了模型内部的视觉-语言冲突。

Conclusion: NEO展示了原生VLMs架构按第一性原理构建的可行性，并为构建可扩展、高效的视觉-语言模型生态提供了基础。作者同时开放了完整代码和模型，促进社区发展与研究。

Abstract: The edifice of native Vision-Language Models (VLMs) has emerged as a rising
contender to typical modular VLMs, shaped by evolving model architectures and
training paradigms. Yet, two lingering clouds cast shadows over its widespread
exploration and promotion: (-) What fundamental constraints set native VLMs
apart from modular ones, and to what extent can these barriers be overcome? (-)
How to make research in native VLMs more accessible and democratized, thereby
accelerating progress in the field. In this paper, we clarify these challenges
and outline guiding principles for constructing native VLMs. Specifically, one
native VLM primitive should: (i) effectively align pixel and word
representations within a shared semantic space; (ii) seamlessly integrate the
strengths of formerly separate vision and language modules; (iii) inherently
embody various cross-modal properties that support unified vision-language
encoding, aligning, and reasoning. Hence, we launch NEO, a novel family of
native VLMs built from first principles, capable of rivaling top-tier modular
counterparts across diverse real-world scenarios. With only 390M image-text
examples, NEO efficiently develops visual perception from scratch while
mitigating vision-language conflicts inside a dense and monolithic model
crafted from our elaborate primitives. We position NEO as a cornerstone for
scalable and powerful native VLMs, paired with a rich set of reusable
components that foster a cost-effective and extensible ecosystem. Our code and
models are publicly available at: https://github.com/EvolvingLMMs-Lab/NEO.

</details>


### [100] [Coupled Diffusion Sampling for Training-Free Multi-View Image Editing](https://arxiv.org/abs/2510.14981)
*Hadi Alzayer,Yunzhi Zhang,Chen Geng,Jia-Bin Huang,Jiajun Wu*

Main category: cs.CV

TL;DR: 本文提出一种在推理阶段通过扩散采样实现多视图一致性图像编辑的方法，无需多视角优化就能保证编辑结果在不同视角间的协调一致。


<details>
  <summary>Details</summary>
Motivation: 现有预训练的2D图像编辑模型能对单幅图像高质量编辑，但面对同一场景或物体的多视图图片时，生成的结果在各视角间缺乏一致性。现有解决方案常需对3D显式表示进行优化，既耗时又在视角稀疏情况下表现不稳定。

Method: 作者提出了一种隐式3D正则化的方法，即在扩散采样时对2D图片序列施加多视图一致性约束。通过耦合的扩散采样，联合采样多视图分布与已编辑2D分布，并加入耦合项以强制生成图像间保持多视图一致性。该方式避免了直接对3D结构优化，提升了效率和鲁棒性。

Result: 该方法在三种不同的多视图图像编辑任务上进行了验证，适用于多种模型架构，证明了其有效性和通用性。生成的多视角编辑结果在视觉一致性和质量上优于现有方法。

Conclusion: 提出的耦合扩散采样框架为多视图一致性图像编辑提供了一种通用高效的方案，无需繁琐的3D优化流程，具有很强的模型和任务适应性。

Abstract: We present an inference-time diffusion sampling method to perform multi-view
consistent image editing using pre-trained 2D image editing models. These
models can independently produce high-quality edits for each image in a set of
multi-view images of a 3D scene or object, but they do not maintain consistency
across views. Existing approaches typically address this by optimizing over
explicit 3D representations, but they suffer from a lengthy optimization
process and instability under sparse view settings. We propose an implicit 3D
regularization approach by constraining the generated 2D image sequences to
adhere to a pre-trained multi-view image distribution. This is achieved through
coupled diffusion sampling, a simple diffusion sampling technique that
concurrently samples two trajectories from both a multi-view image distribution
and a 2D edited image distribution, using a coupling term to enforce the
multi-view consistency among the generated images. We validate the
effectiveness and generality of this framework on three distinct multi-view
image editing tasks, demonstrating its applicability across various model
architectures and highlighting its potential as a general solution for
multi-view consistent editing.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [101] [Bridging the Semantic Gap: Contrastive Rewards for Multilingual Text-to-SQL](https://arxiv.org/abs/2510.13827)
*Ashish Kattamuri,Ishita Prasad,Meetu Malhotra,Arpita Vats,Rahul Raja,Albert Lie*

Main category: cs.CL

TL;DR: 本文提出了一种结合分组相对策略优化（GRPO）与多语对比奖励信号的新框架，以提升跨语言Text-to-SQL系统在语义和执行准确率上的表现。其方法无需大规模训练数据，但显著提升了小参数量模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前Text-to-SQL方法主要关注可执行性，忽视了查询语义和执行结果的语义对齐问题，尤其在多语言场景下的准确率大幅下降。因此亟需提升跨语言语义对齐和模型性能的新方法。

Method: 提出将GRPO与语义相似度对比奖励信号结合，利用奖励信号引导模型提高SQL生成与用户意图的对应关系。在七语种数据集上，使用3B参数的LLaMA-3模型进行微调和对比奖励训练。

Result: 微调的3B LLaMA模型在执行准确率提升至87.4%（比zero-shot高26个百分点），语义准确率提升至52.29%（提升32.86个百分点）。引入对比奖励信号后，平均语义准确率升至59.14%（再增6.85个百分点），越南语提升最高达10个百分点，比8B大模型的zero-shot性能更优。

Conclusion: 通过引入语义对齐的对比奖励信号和参数高效的小模型，可以无需大规模数据，显著提升Text-to-SQL系统跨语言的语义对齐与执行性能。

Abstract: Current Text-to-SQL methods are evaluated and only focused on executable
queries, overlooking the semantic alignment challenge -- both in terms of the
semantic meaning of the query and the correctness of the execution results.
Even execution accuracy itself shows significant drops when moving from English
to other languages, with an average decline of 6 percentage points across
non-English languages. We address these challenges by presenting a new
framework that combines Group Relative Policy Optimization (GRPO) within a
multilingual contrastive reward signal to enhance both task efficiency and
semantic accuracy in Text-to-SQL systems in cross-lingual scenarios. Our method
teaches models to obtain better correspondence between SQL generation and user
intent by combining a reward signal based on semantic similarity. On the
seven-language MultiSpider dataset, fine-tuning the LLaMA-3-3B model with GRPO
improved the execution accuracy up to 87.4 percent (+26 pp over zero-shot) and
semantic accuracy up to 52.29 percent (+32.86 pp). Adding our contrastive
reward signal in the GRPO framework further improved the average semantic
accuracy to 59.14 percent (+6.85 pp, up to +10 pp for Vietnamese). Our
experiments showcase that a smaller, parameter-efficient 3B LLaMA model
fine-tuned with our contrastive reward signal outperforms a much larger
zero-shot 8B LLaMA model, with an uplift of 7.43 pp in execution accuracy (from
81.43 percent on the 8B model to 88.86 percent on the 3B model), and nearly
matches its semantic accuracy (59.14 percent vs. 68.57 percent) -- all using
just 3,000 reinforcement learning training examples. These results demonstrate
how we can improve the performance of Text-to-SQL systems with contrastive
rewards for directed semantic alignment, without requiring large-scale training
datasets.

</details>


### [102] [From Explainability to Action: A Generative Operational Framework for Integrating XAI in Clinical Mental Health Screening](https://arxiv.org/abs/2510.13828)
*Ratna Kandala,Akshata Kishore Moharir,Divya Arvinda Nayak*

Main category: cs.CL

TL;DR: 本文指出当前可解释人工智能（XAI）在心理健康筛查（MHS）中的应用存在“实验室到临床”的鸿沟，提出以大语言模型为核心翻译引擎的生成式操作框架，有效桥接XAI技术解释与临床可用性的差距。


<details>
  <summary>Details</summary>
Motivation: 虽然XAI方法如SHAP、LIME能提供特征重要性等技术解释，但缺乏临床相关和可操作的洞察，致使AI难以被医生和患者实际应用。因此需解决XAI透明性与实际临床效用之间的脱节问题。

Method: 提出一种以大语言模型为核心的生成式操作框架，将XAI工具输出的技术解释与临床指南（通过RAG）相结合，自动生成可理解、循证的临床叙述，并系统分析该框架集成的组件，从内在可解释模型发展到生成式XAI。

Result: 通过该框架，能显著改善XAI输出的临床相关性，提升与医疗工作流的集成度，实现偏见缓释和针对不同利益相关者的有效沟通。

Conclusion: 该框架为解决XAI技术在临床实际应用中的核心障碍提供了切实路径，并指明了将来实现集成化、可操作、可信赖AI医疗实践的发展方向。

Abstract: Explainable Artificial Intelligence (XAI) has been presented as the critical
component for unlocking the potential of machine learning in mental health
screening (MHS). However, a persistent lab-to-clinic gap remains. Current XAI
techniques, such as SHAP and LIME, excel at producing technically faithful
outputs such as feature importance scores, but fail to deliver clinically
relevant, actionable insights that can be used by clinicians or understood by
patients. This disconnect between technical transparency and human utility is
the primary barrier to real-world adoption. This paper argues that this gap is
a translation problem and proposes the Generative Operational Framework, a
novel system architecture that leverages Large Language Models (LLMs) as a
central translation engine. This framework is designed to ingest the raw,
technical outputs from diverse XAI tools and synthesize them with clinical
guidelines (via RAG) to automatically generate human-readable, evidence-backed
clinical narratives. To justify our solution, we provide a systematic analysis
of the components it integrates, tracing the evolution from intrinsic models to
generative XAI. We demonstrate how this framework directly addresses key
operational barriers, including workflow integration, bias mitigation, and
stakeholder-specific communication. This paper also provides a strategic
roadmap for moving the field beyond the generation of isolated data points
toward the delivery of integrated, actionable, and trustworthy AI in clinical
practice.

</details>


### [103] [A Linguistics-Aware LLM Watermarking via Syntactic Predictability](https://arxiv.org/abs/2510.13829)
*Shinwoo Park,Hyejin Park,Hyeseon Ahn,Yo-Sub Han*

Main category: cs.CL

TL;DR: 本文提出了一种无需模型logits即可公开可验证的LLM文本水印方案STELA，并在多语种下验证了其在质量与检测稳健性之间的优良权衡。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型广泛应用的背景下，亟需可靠的治理工具以保障AI生态的可信性。由于已有水印方法依赖模型特定输出信号，不利于公开验证，急需兼顾文本质量与可检测性且更易公开验证的新方法。

Method: 作者提出STELA框架，根据语言本身的词性n-gram等不确定性动态调节水印强度：在语法约束强的地方减弱信号以保质量，在语言自由度高的地方增强信号以保可检测性。检测算法不依赖任何模型logits，便于公开验证。

Result: 在英语、中文、韩语等多种语言的实验中，STELA相较于以往依赖模型logits的方法表现出更好的检测稳健性，实现了更优的文本质量与水印可检测性平衡。

Conclusion: STELA框架实现了无需模型内部信息即可进行公开、稳健水印检测，对构建可信AI治理与生态具有应用前景。实现代码已开源。

Abstract: As large language models (LLMs) continue to advance rapidly, reliable
governance tools have become critical. Publicly verifiable watermarking is
particularly essential for fostering a trustworthy AI ecosystem. A central
challenge persists: balancing text quality against detection robustness. Recent
studies have sought to navigate this trade-off by leveraging signals from model
output distributions (e.g., token-level entropy); however, their reliance on
these model-specific signals presents a significant barrier to public
verification, as the detection process requires access to the logits of the
underlying model. We introduce STELA, a novel framework that aligns watermark
strength with the linguistic degrees of freedom inherent in language. STELA
dynamically modulates the signal using part-of-speech (POS) n-gram-modeled
linguistic indeterminacy, weakening it in grammatically constrained contexts to
preserve quality and strengthen it in contexts with greater linguistic
flexibility to enhance detectability. Our detector operates without access to
any model logits, thus facilitating publicly verifiable detection. Through
extensive experiments on typologically diverse languages-analytic English,
isolating Chinese, and agglutinative Korean-we show that STELA surpasses prior
methods in detection robustness. Our code is available at
https://github.com/Shinwoo-Park/stela_watermark.

</details>


### [104] [Users as Annotators: LLM Preference Learning from Comparison Mode](https://arxiv.org/abs/2510.13830)
*Zhongze Cai,Xiaocheng Li*

Main category: cs.CL

TL;DR: 本文提出用用户在交互式比较模式下产生的配对偏好数据对大语言模型（LLM）进行对齐，并提出了一种新方法识别和过滤数据标签质量，以提升对齐效果。


<details>
  <summary>Details</summary>
Motivation: 传统配对偏好数据依赖专业标注，质量高但成本高。随LLM普及，普通用户也在日常使用中不断生成偏好标签，但这些标签缺乏质量控制。因此，研究如何利用用户自发产生的偏好标签，并提升其质量，具有现实意义。

Method: 论文提出用来自两个不同模型或同一模型不同版本的响应，让用户比较并标注优劣。这种“不对称”设置可以构建用户行为模型，进一步通过期望最大化（EM）算法估计用户的潜在数据质量因子，并据此过滤低质量用户数据。

Result: 实验结果表明，该方法能够有效捕捉用户行为特征，并在下游任务中提升通过数据过滤后的LLM对齐效果。

Conclusion: 基于用户行为和潜在质量因子进行数据过滤，是提升LLM对齐数据质量的有效手段，有助于更好地利用非专业用户产生的数据。

Abstract: Pairwise preference data have played an important role in the alignment of
large language models (LLMs). Each sample of such data consists of a prompt,
two different responses to the prompt, and a binary label indicating which of
the two responses is better. The labels are usually annotated by professional
human annotators. In this paper, we consider an alternative approach to collect
pairwise preference data -- user annotation from comparison mode. With the
increasingly wider adoption of LLMs among the population, users are
contributing more and more of their preference labels through their daily
interactions with the LLMs. The upside of such labels is that users are the
best experts in judging the responses to their own queries/prompts, but the
downside is the lack of quality control in these labels. In this paper, we
consider a new idea of generating two responses from two different models or
two different versions of the same model. The asymmetry allows us to make an
inference of the user's data quality through our proposed user behavior model.
We develop an expectation-maximization algorithm to estimate a latent quality
factor of the user, and filter users' annotation data accordingly. The
downstream task shows the effectiveness of our approach in both capturing the
user behavior and data filtering for LLM alignment.

</details>


### [105] [Informed Routing in LLMs: Smarter Token-Level Computation for Faster Inference](https://arxiv.org/abs/2510.13831)
*Chao Han,Yijuan Liang,Zihao Xuan,Daokuan Wu,Wei Zhang,Xiaoyu Shen*

Main category: cs.CL

TL;DR: 该论文提出了一种名为informed routing的动态计算分配新方法，利用轻量级特征预测模块，根据token的重要性和可恢复性做出计算与近似决策，从而大幅降低大语言模型的推理成本，并在多个稀疏性下实现更优的性能与效率平衡。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在实际应用中因推理成本高而受限，虽然已有按token选择性激活模型组件的动态分配方法，但大多采用贪婪路由策略，易导致信息丢失和次优选择。为此，需要一种更智能、可控的token路由方案以提升整体推理效率与质量。

Method: 作者提出informed routing，核心是引入Lightweight Feature Forecaster（LFF）预测模块，提前评估各token的即时重要性及其输出可恢复度。基于此，模型灵活选择直接计算或用近似值替代，避免不必要的全量计算。该机制可与LoRA微调协同，抑或独立运行。

Result: 在语言建模和推理任务的多项实验证明，该方法在不同稀疏度下均实现了优于现有方法的效率-性能权衡。而且即使不做最终LoRA微调，其表现也与需完整微调的强基线相当甚至更优，同时训练时间缩短超过50%。

Conclusion: 本文提出的informed routing显著提升了大模型推理效率且保持甚至提升性能，为大模型落地提供了更实用的动态稀疏计算框架，具备实际部署价值和理论启发意义。

Abstract: The deployment of large language models (LLMs) in real-world applications is
increasingly limited by their high inference cost. While recent advances in
dynamic token-level computation allocation attempt to improve efficiency by
selectively activating model components per token, existing methods rely on
greedy routing--a myopic execute-or-skip mechanism that often leads to
irreversible information loss and suboptimal token selection. This paper
introduces informed routing, a new paradigm that proactively addresses these
issues. The key insight is to assess not only a token's immediate importance
but also its recoverability, i.e., how well its transformation can be
approximated. To this end, we propose the Lightweight Feature Forecaster (LFF),
a small predictive module that estimates a unit's output before routing
decisions are made. This enables a flexible execute-or-approximate policy that
preserves model fidelity while drastically reducing computation. Extensive
experiments on both language modeling and reasoning tasks show that informed
routing achieves state-of-the-art efficiency-performance trade-offs across
multiple sparsity levels. Notably, even without final LoRA fine-tuning, our
method matches or surpasses strong baselines that require full fine-tuning, all
while reducing training time by over 50%. The code is available at:
https://github.com/EIT-NLP/informed-routing

</details>


### [106] [Entropy Meets Importance: A Unified Head Importance-Entropy Score for Stable and Efficient Transformer Pruning](https://arxiv.org/abs/2510.13832)
*Minsik Choi,Hyegang Son,Changhoon Kim,Young Geun Kim*

Main category: cs.CL

TL;DR: 本文提出了一种结合Head Importance（头部重要性）和注意力熵的新型Transformer剪枝准则（HIES），相比仅用头部重要性的传统方法，在有效减少模型规模的同时，提升了模型的表现与稳定性。


<details>
  <summary>Details</summary>
Motivation: Transformer模型虽性能突出，但其层数多、注意力头多，导致推理部署效率受限。现有剪枝方法如基于Head Importance Score（HIS）虽流行，但未能综合反映注意力头的贡献多样性，存在局限。

Method: 作者提出HIES剪枝准则，将Head Importance与注意力熵融合，既衡量了梯度驱动的重要性，也考虑了注意力模式的多样性。该方法据此判断并剪除冗余注意力头。

Result: HIES剪枝方法使得模型质量提升最高15.2%，稳定性提升2.04倍，相较于仅用HIS的方法，在不损失准确性和稳定性的情况下实现了更大幅度的模型压缩。

Conclusion: 融合注意力头重要性与熵的剪枝准则（HIES）有效提升Transformer模型的压缩效率及性能，优于现有剪枝方法，助力其高效推理与部署。

Abstract: Transformer-based models have achieved remarkable performance in NLP tasks.
However, their structural characteristics-multiple layers and attention
heads-introduce efficiency challenges in inference and deployment. To address
these challenges, various pruning methods have recently been proposed. Notably,
gradient-based methods using Head Importance Scores (HIS) have gained traction
for interpretability, efficiency, and ability to identify redundant heads.
However, HIS alone has limitations as it captures only the gradient-driven
contribution, overlooking the diversity of attention patterns. To overcome
these limitations, we introduce a novel pruning criterion, HIES (Head
Importance-Entropy Score), which integrates head importance scores with
attention entropy, providing complementary evidence on per-head contribution.
Empirically, HIES-based pruning yields up to 15.2% improvement in model quality
and 2.04x improvement in stability over HIS-only methods, enabling substantial
model compression without sacrificing either accuracy or stability. Code will
be released upon publication.

</details>


### [107] [ConDABench: Interactive Evaluation of Language Models for Data Analysis](https://arxiv.org/abs/2510.13835)
*Avik Dutta,Priyanshu Gupta,Hosein Hasanbeig,Rahul Pratap Singh,Harshit Nigam,Sumit Gulwani,Arjun Radhakrishna,Gustavo Soares,Ashish Tiwari*

Main category: cs.CL

TL;DR: 本文提出了ConDABench，一个用于生成和评测对话式数据分析任务基准的框架，并揭示现有LLM在处理复杂、交互式数据分析方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现实中的数据分析任务目标往往不明确，数据质量参差不齐，需要人机交互以澄清用户意图。现有评测方法缺乏对这种交互复杂性的支持，无法真实反映LLM在实际数据分析场景中的表现。

Method: 提出ConDABench框架，包括：1）多智能体协作流程，从公开数据集相关分析文章中生成真实的数据分析对话任务；2）制作了1,420个对话式数据分析问题；3）构建了评测工具，可以系统地评估外部数据分析工具在这些任务上的表现。

Result: 将主流大语言模型在ConDABench基准上进行评测，发现新一代模型虽然能解决更多单一任务实例，但在需要持续长时间交互的大型任务上并无显著优势。

Conclusion: ConDABench为推动实现可进行复杂交互式数据分析的人机协作模型提供了标准化测试平台，有助于行业对模型进步的系统评估和优化。

Abstract: Real-world data analysis tasks often come with under-specified goals and
unclean data. User interaction is necessary to understand and disambiguate a
user's intent, and hence, essential to solving these complex tasks. Existing
benchmarks for evaluating LLMs on data analysis tasks do not capture these
complexities or provide first-class support for interactivity. We introduce
ConDABench, a framework for generating conversational data analysis (ConDA)
benchmarks and evaluating external tools on the generated benchmarks. \bench
consists of (a) a multi-agent workflow for generating realistic benchmarks from
articles describing insights gained from public datasets, (b) 1,420 ConDA
problems generated using this workflow, and (c) an evaluation harness that, for
the first time, makes it possible to systematically evaluate conversational
data analysis tools on the generated ConDA problems. Evaluation of
state-of-the-art LLMs on the benchmarks reveals that while the new generation
of models are better at solving more instances, they are not necessarily better
at solving tasks that require sustained, long-form engagement. ConDABench is an
avenue for model builders to measure progress towards truly collaborative
models that can complete complex interactive tasks.

</details>


### [108] [SIMBA UQ: Similarity-Based Aggregation for Uncertainty Quantification in Large Language Models](https://arxiv.org/abs/2510.13836)
*Debarun Bhattacharjya,Balaji Ganesan,Junkyu Lee,Radu Marinescu,Katsiaryna Mirylenka,Michael Glass,Xiao Shou*

Main category: cs.CL

TL;DR: 本文提出并实证分析了一种基于输出一致性的新颖大模型不确定性量化（UQ）框架，无需访问模型内部信息，即可对复杂任务中输出的可信度进行有效评估。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在现实应用的普及，如何判定模型“不知道什么”，即对其输出结果的不确定性进行量化，成为可信AI系统的核心问题。传统UQ方法多依赖模型内部信息，不利于实际部署，因此呼唤更强适应性的“黑盒”UQ技术。

Method: 作者提出一种基于“输出样本一致性”的非语言化（similarity-based）UQ聚合框架，将多种UQ方法统一起来，并发展出若干新颖技术（例如用小样本训练置信度估计器），在无需访问大模型内部信息的前提下，通过比较不同输出间的相似性，间接评估模型输出的置信度。

Result: 在问答、摘要、Text-to-SQL三大任务的实证中，本文提出的基于相似性的方法在置信度校准表现上优于多种现有基线方法，验证了其实用性和优越性。

Conclusion: 通过创新的不确定性量化框架及其实证，本文推动了面向复杂生成任务的黑盒UQ技术，为大模型可信输出提供了实用、易部署、适应广泛的解决方案。

Abstract: When does a large language model (LLM) know what it does not know?
Uncertainty quantification (UQ) provides measures of uncertainty, such as an
estimate of the confidence in an LLM's generated output, and is therefore
increasingly recognized as a crucial component of trusted AI systems. Black-box
UQ methods do not require access to internal model information from the
generating LLM and therefore have numerous real-world advantages, such as
robustness to system changes, adaptability to choice of LLM, reduced costs, and
computational tractability. In this paper, we investigate the effectiveness of
UQ techniques that are primarily but not necessarily entirely black-box, where
the consistency between a generated output and other sampled generations is
used as a proxy for confidence in its correctness. We propose a high-level
non-verbalized similarity-based aggregation framework that subsumes a broad
swath of UQ approaches suitable for complex generative tasks, as well as
introduce specific novel techniques from the framework that train confidence
estimation models using small training sets. Through an empirical study with
datasets spanning the diverse tasks of question answering, summarization, and
text-to-SQL, we demonstrate that our proposed similarity-based methods can
yield better calibrated confidences than baselines.

</details>


### [109] [Seeing Hate Differently: Hate Subspace Modeling for Culture-Aware Hate Speech Detection](https://arxiv.org/abs/2510.13837)
*Weibin Cai,Reza Zafarani*

Main category: cs.CL

TL;DR: 本文针对仇恨言论检测中标签偏见和文化差异问题，提出了一种文化感知框架，并在多个指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论检测方法普遍忽视了现实世界中标签带有偏见以及不同文化背景下对仇恨的认知差异。本文旨在解决数据稀疏、文化纠结和标签歧义等实际挑战。

Method: 作者提出一种文化感知的个体仇恨子空间构建框架：通过对文化属性组合建模来缓解数据稀疏问题，利用标签传播捕捉每种文化组合的独特特征，以此生成个性化仇恨子空间，提升分类性能。

Result: 通过实验证明，该方法在所有指标上平均比现有最优方法提升了1.05%。

Conclusion: 针对真实环境下仇恨检测中的文化多样性与标签偏见，提出的方法能有效提升仇恨言论检测表现。

Abstract: Hate speech detection has been extensively studied, yet existing methods
often overlook a real-world complexity: training labels are biased, and
interpretations of what is considered hate vary across individuals with
different cultural backgrounds. We first analyze these challenges, including
data sparsity, cultural entanglement, and ambiguous labeling. To address them,
we propose a culture-aware framework that constructs individuals' hate
subspaces. To alleviate data sparsity, we model combinations of cultural
attributes. For cultural entanglement and ambiguous labels, we use label
propagation to capture distinctive features of each combination. Finally,
individual hate subspaces, which in turn can further enhance classification
performance. Experiments show our method outperforms state-of-the-art by 1.05\%
on average across all metrics.

</details>


### [110] [Meronymic Ontology Extraction via Large Language Models](https://arxiv.org/abs/2510.13839)
*Dekai Zhang,Simone Conia,Antonio Rago*

Main category: cs.CL

TL;DR: 本文提出一种利用大型语言模型（LLM）从商品评论原始文本中自动提取产品本体结构（部分-整体关系）的全自动方法，并在实验中超过了现有的BERT基线。


<details>
  <summary>Details</summary>
Motivation: 产品本体在如电商等领域有重要应用，但传统本体构建依赖人工，成本高、效率低。因此需开发自动化方法以应对海量文本数据。

Method: 借助最新的大型语言模型，提出直接从商品评论原始文本中提取产品本体（meronymies）的方法，并与BERT基线模型进行对比，效果通过LLM评判。

Result: 自动提取的本体结构在以LLM为评判标准的评测中优于BERT基线方法。

Conclusion: LLM能够实现高质量的产品本体自动构建，具备在更广泛本体抽取任务中应用的潜力。

Abstract: Ontologies have become essential in today's digital age as a way of
organising the vast amount of readily available unstructured text. In providing
formal structure to this information, ontologies have immense value and
application across various domains, e.g., e-commerce, where countless product
listings necessitate proper product organisation. However, the manual
construction of these ontologies is a time-consuming, expensive and laborious
process. In this paper, we harness the recent advancements in large language
models (LLMs) to develop a fully-automated method of extracting product
ontologies, in the form of meronymies, from raw review texts. We demonstrate
that the ontologies produced by our method surpass an existing, BERT-based
baseline when evaluating using an LLM-as-a-judge. Our investigation provides
the groundwork for LLMs to be used more generally in (product or otherwise)
ontology extraction.

</details>


### [111] [ADMIT: Few-shot Knowledge Poisoning Attacks on RAG-based Fact Checking](https://arxiv.org/abs/2510.13842)
*Yutao Wu,Xiao Liu,Yinghui Li,Yifeng Gao,Yifan Ding,Jiale Ding,Xiang Zheng,Xingjun Ma*

Main category: cs.CL

TL;DR: 本文提出了一种名为ADMIT的新型知识投毒攻击方法，能在事实核查场景下欺骗RAG系统，且具有极高的攻击成功率和迁移能力，暴露了现有系统的严重安全隐患。


<details>
  <summary>Details</summary>
Motivation: 随着RAG（检索增强生成）系统的广泛应用，知识库内容的完整性和可信度变得日益重要。然而，现有研究主要关注于检索内容被污染时对LLM的影响，较少考虑在真实场景——即权威证据占主导的事实核查任务——中的知识投毒攻击风险。此研究旨在揭示即使在权威证据为主的条件下，RAG系统依然容易受到投毒攻击的威胁。

Method: 作者提出了ADMIT（Adversarial Multi-Injection Technique）方法，这是一种对抗性多点注入攻击，采用few-shot和语义对齐策略，无需访问目标LLM、检索器，也不需要token级别的精确控制。该方法能在检索到的内容中嵌入对立证据，诱使LLM在事实核查任务中做出错误判断并生成欺骗性解释。

Result: 实验表明，ADMIT能在4种检索器、11个大语言模型及4个跨领域基准上迁移，平均投毒成功率高达86%，且投毒比例极低（$0.93 \times 10^{-6}$），在强有力的反对证据下仍表现出高度鲁棒性。与以往最新攻击相比，ADMIT整体攻击成功率提升了11.2%。

Conclusion: ADMIT暴露了当前RAG事实核查系统在面对知识投毒时的重大安全短板，即便有大量权威证据也难以防御新型语义级投毒攻击，呼吁业界关注RAG系统安全性及抗攻击机制的研究。

Abstract: Knowledge poisoning poses a critical threat to Retrieval-Augmented Generation
(RAG) systems by injecting adversarial content into knowledge bases, tricking
Large Language Models (LLMs) into producing attacker-controlled outputs
grounded in manipulated context. Prior work highlights LLMs' susceptibility to
misleading or malicious retrieved content. However, real-world fact-checking
scenarios are more challenging, as credible evidence typically dominates the
retrieval pool. To investigate this problem, we extend knowledge poisoning to
the fact-checking setting, where retrieved context includes authentic
supporting or refuting evidence. We propose \textbf{ADMIT}
(\textbf{AD}versarial \textbf{M}ulti-\textbf{I}njection \textbf{T}echnique), a
few-shot, semantically aligned poisoning attack that flips fact-checking
decisions and induces deceptive justifications, all without access to the
target LLMs, retrievers, or token-level control. Extensive experiments show
that ADMIT transfers effectively across 4 retrievers, 11 LLMs, and 4
cross-domain benchmarks, achieving an average attack success rate (ASR) of 86\%
at an extremely low poisoning rate of $0.93 \times 10^{-6}$, and remaining
robust even in the presence of strong counter-evidence. Compared with prior
state-of-the-art attacks, ADMIT improves ASR by 11.2\% across all settings,
exposing significant vulnerabilities in real-world RAG-based fact-checking
systems.

</details>


### [112] [Serialized EHR make for good text representations](https://arxiv.org/abs/2510.13843)
*Zhirong Chou,Quan Qin,Shi Li*

Main category: cs.CL

TL;DR: 本文提出了SerialBEHRT模型，通过结合SciBERT和电子健康记录（EHR）序列预训练，更好地处理了EHR的结构化和时序特性。在抗生素敏感性预测任务中，SerialBEHRT优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型难以很好地结合EHR的表结构和事件特性，不能有效捕捉患者信息中的时序依赖，影响了纵向数据分析效果。

Method: 提出了SerialBEHRT模型，在SciBERT基础上，加入对结构化EHR序列的额外预训练，专门用来编码临床事件的时序和上下文关系。

Result: 在抗生素敏感性预测任务上，SerialBEHRT在多项基准测试中均取得领先且稳定的表现，明显优于其它EHR表征方法。

Conclusion: 通过对EHR时序序列的专门预训练，可以明显提升基础模型在医疗健康任务中的表现，验证了时序建模在医疗基础模型中的重要性。

Abstract: The emergence of foundation models in healthcare has opened new avenues for
learning generalizable representations from large scale clinical data. Yet,
existing approaches often struggle to reconcile the tabular and event based
nature of Electronic Health Records (EHRs) with the sequential priors of
natural language models. This structural mismatch limits their ability to
capture longitudinal dependencies across patient encounters. We introduce
SerialBEHRT, a domain aligned foundation model that extends SciBERT through
additional pretraining on structured EHR sequences. SerialBEHRT is designed to
encode temporal and contextual relationships among clinical events, thereby
producing richer patient representations. We evaluate its effectiveness on the
task of antibiotic susceptibility prediction, a clinically meaningful problem
in antibiotic stewardship. Through extensive benchmarking against state of the
art EHR representation strategies, we demonstrate that SerialBEHRT achieves
superior and more consistent performance, highlighting the importance of
temporal serialization in foundation model pretraining for healthcare.

</details>


### [113] [DynaSpec: Context-aware Dynamic Speculative Sampling for Large-Vocabulary Language Models](https://arxiv.org/abs/2510.13847)
*Jinbin Zhang,Nasib Ullah,Erik Schultheis,Rohit Babbar*

Main category: cs.CL

TL;DR: 该论文提出了一种新的上下文动态词表裁剪机制DynaSpec，用以加速大语言模型推理中的speculative decoding，同时克服现有方法局限。


<details>
  <summary>Details</summary>
Motivation: 现有speculative decoding方法在大词表下，drafter输出阶段因参数量过多成为延迟瓶颈。常用的固定高频词裁剪方法效率虽高，但通用性和对长尾/领域词处理能力不足。

Method: 论文提出DynaSpec，采用轻量级的元分类器根据上下文动态将token分到不同簇，drafter仅用这些簇内的token作输出，且draft encoding与元分类器并行。最终由大模型用全词表做验证确保准确性。

Result: DynaSpec在标准speculative decoding基准上，相较于固定词表的裁剪方法，平均accepted length性能稳定提升，同时动态裁剪显著缩减所需词表规模而不降低接受率。

Conclusion: DynaSpec方法有效缓解了drafter输出阶段的瓶颈，兼具高效性与对多任务的泛化能力，为LLM加速推理提供了更优解。

Abstract: Speculative decoding (a.k.a. speculative sampling) has become a standard way
to accelerate LLM inference: a small drafter proposes multiple tokens and a
large target model verifies them once per speculation length. Recently, scaling
of the LLM vocabulary has pushed the number of tokens to grow substantially.
While verification over the full vocabulary leaves the target model largely
unaffected, the O(|V|d) parameters in the drafter's output head become a
latency bottleneck, slowing the entire pipeline. Contemporary methods (e.g.,
FR-Spec, VocabTrim) restrict the drafter's vocabulary to a fixed subset of the
target model's vocabulary, ranked in descending order of token frequency.
Although this reduces draft-time compute, it is brittle, since: (i) frequency
lists are corpus-dependent and require retuning to generalize, and (ii) static
shortlists suppress rare or domain-specific tokens, lowering the expected
number of tokens per verification step. We propose DynaSpec, a
context-dependent dynamic shortlisting mechanism that is robust, speeds up
drafting, and generalizes across diverse tasks. Concretely, we introduce
lightweight, coarse-grained meta-classifiers that route contexts to a small
number of token clusters; the union of the top-k selected clusters forms the
drafter's shortlist, while verification retains the full vocabulary and
exactness. The meta-classifier finishes its computation earlier than the
drafter's hidden state generation by exploiting parallel execution of draft
encoding and meta shortlisting on separate streams. On standard
speculative-decoding benchmarks, we observe consistent gains in mean accepted
length over fixed-shortlist baselines, while context-dependent selection
enables smaller shortlists without degrading acceptance.

</details>


### [114] [On-device System of Compositional Multi-tasking in Large Language Models](https://arxiv.org/abs/2510.13848)
*Ondrej Bohdal,Konstantinos Theodosiadis,Asterios Mpatziakas,Dimitris Filippidis,Iro Spyrou,Christos Zonios,Anastasios Drosou,Dimosthenis Ioannidis,Kyeng-Hun Lee,Jijoong Moon,Hyeonmok Ko,Mete Ozay,Umberto Michieli*

Main category: cs.CL

TL;DR: 本文提出了一种新的方法，通过在多个LoRA适配器之上增加可学习投影层，使大模型能够高效同时执行摘要和翻译等复杂任务。实验表明，无论是云端还是移动端，该方法都具备高效和快速的实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型虽然借助LoRA等参数高效适配器可以支持多任务，但面对需要多任务复合执行（如将长对话既摘要又翻译）时，现有方法效率低且难以应对端侧运行的资源限制。

Method: 作者提出在组合的摘要和翻译适配器之上增加一个可学习的投影层，实现有效的信息整合与参数共享，同时大幅降低训练与推理的计算消耗。并在安卓端实现了端上组合任务处理的App，验证其实用性。

Result: 实验表明，无论在云端还是在设备端，提出的方案都能高效、快速地执行组合任务，优于需要大量重训练或序列化处理的替代方法。

Conclusion: 通过这一高效的投影层融合LoRA适配器，复合多任务处理变得高效可行，特别适合资源受限场景，对实际高要求应用具实际价值。

Abstract: Large language models (LLMs) are commonly adapted for diverse downstream
tasks via parameter-efficient fine-tuning techniques such as Low-Rank Adapters
(LoRA). While adapters can be combined to handle multiple tasks separately,
standard approaches struggle when targeting the simultaneous execution of
complex tasks, such as generating a translated summary from a long
conversation. To address this challenge, we propose a novel approach tailored
specifically for compositional multi-tasking scenarios involving summarization
and translation. Our technique involves adding a learnable projection layer on
top of the combined summarization and translation adapters. This design enables
effective integration while maintaining efficiency through reduced
computational overhead compared to alternative strategies requiring extensive
retraining or sequential processing. We demonstrate the practical viability of
our method within an on-device environment by developing an Android app capable
of executing compositional tasks seamlessly. Experimental results indicate our
solution performs well and is fast in both cloud-based and on-device
implementations, highlighting the potential benefits of adopting our framework
in real-world applications demanding high-speed operation alongside resource
constraints.

</details>


### [115] [Language steering in latent space to mitigate unintended code-switching](https://arxiv.org/abs/2510.13849)
*Andrey Goncharov,Nikolai Kondusov,Alexey Zaytsev*

Main category: cs.CL

TL;DR: 本文提出了一种轻量级的多语言大模型语言控制方法，通过在推理阶段控制嵌入向量方向，显著减少模型中出现的意外代码切换现象。


<details>
  <summary>Details</summary>
Motivation: 多语言大模型在实际应用中常出现代码切换（即在同一语境下混合使用多种语言），影响模型的下游任务性能和输出的一致性。因此需要有效控制模型输出的语言身份。

Method: 作者提出了“隐空间语言引导”方法：利用少量平行语料进行主成分分析（PCA），找出不同语言之间的核心方向，然后在推理时引导token嵌入沿这些方向调整，从而实现语言身份的精确控制。该方法计算开销很低，仅需极少量平行数据进行校准。

Result: 在Qwen2.5和Llama-3.2两个主流多语言模型上测试，单一主成分即可实现95-99%语言分类准确率，next-token分布性差异最大降低42%。此外，分析发现模型末层的语言身份具有极好的线性可分性。

Conclusion: 该方法可以有效减少多语言模型中的代码切换现象，在保持语义的同时，对性能影响极小，为多语言模型的可控生成和实用性带来明显提升。

Abstract: Multilingual Large Language Models (LLMs) often exhibit unintended
code-switching, reducing reliability in downstream tasks. We propose
latent-space language steering, a lightweight inference-time method that
identifies language directions via PCA on parallel translations and steers
token embeddings along these axes to control language identity. Our approach
mitigates code-switching while preserving semantics with negligible
computational overhead and requires only minimal parallel data for calibration.
Empirically, we achieve 95-99\% language classification accuracy using a single
principal component and reduce next-token distributional divergence by up to
42% across multiple language pairs on Qwen2.5 and Llama-3.2 models. We further
analyze the layer-wise evolution of language representations, revealing that
language identity concentrates in final layers with near-perfect linear
separability.

</details>


### [116] [Revisiting the UID Hypothesis in LLM Reasoning Traces](https://arxiv.org/abs/2510.13850)
*Minju Gwak,Guijin Son,Jaehyung Kim*

Main category: cs.CL

TL;DR: 本文提出用熵相关的信息密度指标分析大语言模型推理过程中的信息流动，发现模型在推理时的信息密度分布与人类不同，正确推理反而表现为信息密度的剧烈波动。


<details>
  <summary>Details</summary>
Motivation: 链式推理是大语言模型常用的解题方式，但其中间推理步骤通常难以直观解释。受心理语言学中“信息密度均衡假说”（UID）的启发，作者希望探索语言模型推理过程中的信息分布规律，从而理解其推理机制。

Method: 作者引入基于熵的信息密度指标，对多个数学推理基准数据集上的大模型推理过程进行定量分析，比较不同推理结果下信息流（信息密度）的分布特征。

Result: 实验证明，模型推理中信息密度分布整体呈现显著的非均匀现象，尤其是在正确推理中表现为信息密度的剧烈波动，这与人类交流的平稳信息流特性形成对比。

Conclusion: 研究挑战了“机器推理应当类似于人类均匀信息流”这一假设，揭示了模型推理的特殊性，也为未来提升可解释性和自适应推理机制提供了新方向。

Abstract: Large language models (LLMs) often solve problems using step-by-step
Chain-of-Thought (CoT) reasoning, yet these intermediate steps are frequently
unfaithful or hard to interpret. Inspired by the Uniform Information Density
(UID) hypothesis in psycholinguistics -- which posits that humans communicate
by maintaining a stable flow of information -- we introduce entropy-based
metrics to analyze the information flow within reasoning traces. Surprisingly,
across three challenging mathematical benchmarks, we find that successful
reasoning in LLMs is globally non-uniform: correct solutions are characterized
by uneven swings in information density, in stark contrast to human
communication patterns. This result challenges assumptions about machine
reasoning and suggests new directions for designing interpretable and adaptive
reasoning models.

</details>


### [117] [EvoEdit: Evolving Null-space Alignment for Robust and Efficient Knowledge Editing](https://arxiv.org/abs/2510.13851)
*Sicheng Lyu,Yu Gu,Xinyu Wang,Jerry Huang,Sitao Luan,Yufei Cui,Xiao-Wen Chang,Peng Lu*

Main category: cs.CL

TL;DR: 本文提出了一种新方法EvoEdit，用于提升大型语言模型在多次知识编辑时的稳定性和效率。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型知识的不断过时或出错，模型需要不断更新。但每次全量训练成本高，因此出现了模型编辑方法。然而，现有的逐步定位-编辑方法在多次连续修改时容易导致“灾难性干扰”，新修改会损害先前的更新和原有知识。

Method: EvoEdit提出通过序贯的“零空间对齐”机制处理每一次新的编辑，保证模型能够稳定地集成新知识，同时最大程度保持原有和已修改的知识表达，从而减少干扰。

Result: 在真实的多次知识编辑基准测试中，EvoEdit在性能上达到或超越以往定位-编辑类技术，并且在速度上实现最多3.53倍的提升。

Conclusion: EvoEdit有效解决了多次知识编辑时的干扰问题，为动态更新信息场景下的LLM设计提供了简单高效且具有理论保障的方案，证明了未来需要更加有原则的方法来设计和维护LLM。

Abstract: Large language models (LLMs) require continual updates to rectify outdated or
erroneous knowledge. Model editing has emerged as a compelling paradigm for
introducing targeted modifications without the computational burden of full
retraining. Existing approaches are mainly based on a locate-then-edit
framework. However, in sequential editing contexts, where multiple updates are
applied over time, they exhibit significant limitations and suffer from
catastrophic interference, i.e., new edits compromise previously integrated
updates and degrade preserved knowledge. To address these challenges, we
introduce EvoEdit, a novel editing strategy that mitigates catastrophic
interference through sequential null-space alignment, enabling stable and
efficient model editing. By performing sequential null-space alignment for each
incoming edit, EvoEdit preserves both original and previously modified
knowledge representations and maintains output invariance on preserved
knowledge even across long edit sequences, effectively mitigating interference.
Evaluations on real-world sequential knowledge-editing benchmarks show that
EvoEdit achieves better or comparable performance than prior state-of-the-art
locate-then-edit techniques, with up to 3.53 times speedup. Overall, these
results underscore the necessity of developing more principled approaches for
designing LLMs in dynamically evolving information settings, while providing a
simple yet effective solution with strong theoretical guarantees.

</details>


### [118] [ConsistencyAI: A Benchmark to Assess LLMs' Factual Consistency When Responding to Different Demographic Groups](https://arxiv.org/abs/2510.13852)
*Peter Banyas,Shristi Sharma,Alistair Simmons,Atharva Vispute*

Main category: cs.CL

TL;DR: 本论文提出了一种名为ConsistencyAI的新基准，用于独立评测大语言模型（LLM）的事实一致性，考查不同人格下的模型答复是否一致。通过对19种LLM进行多次多话题测试，发现不同模型及话题下事实一致性存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 当前有大量对LLM性能的评测，但缺乏专注于‘不同用户或人格下，模型答复事实是否前后一致’的独立公开基准。公众和开发者都需要了解，当不同人向同一模型提问时，模型是否会给出不一致、甚至矛盾的事实性答复。

Method: 提出独立于LLM厂商的ConsistencyAI评测基准。分别为19款主流LLM设计统一的多主题、五事实问答，并为每次问答提供不同的人格（personas）上下文。运用句子嵌入及余弦相似性方法，对多个人格下模型答复的一致性进行量化打分。

Result: 在100种人格的大规模实验中，不同模型的一致性分数介于0.9065至0.7896之间，均值为0.8656。表现最一致的是Grok-3，轻量级模型表现较差。不同话题具有不同的一致性，‘就业市场’话题一致性最低，‘G7世界领导人’最高，而疫苗、以巴冲突等话题在不同厂商之间分化明显。

Conclusion: 事实一致性不仅依赖于模型厂商，也受到问题主题的显著影响。ConsistencyAI为事实一致性评估提供了一个公开、可复现的测量工具，并鼓励LLM开发者采用人格不变的提示策略。

Abstract: Is an LLM telling you different facts than it's telling me? This paper
introduces ConsistencyAI, an independent benchmark for measuring the factual
consistency of large language models (LLMs) for different personas.
ConsistencyAI tests whether, when users of different demographics ask identical
questions, the model responds with factually inconsistent answers. Designed
without involvement from LLM providers, this benchmark offers impartial
evaluation and accountability. In our experiment, we queried 19 LLMs with
prompts that requested 5 facts for each of 15 topics. We repeated this query
100 times for each LLM, each time adding prompt context from a different
persona selected from a subset of personas modeling the general population. We
processed the responses into sentence embeddings, computed cross-persona cosine
similarity, and computed the weighted average of cross-persona cosine
similarity to calculate factual consistency scores. In 100-persona experiments,
scores ranged from 0.9065 to 0.7896, and the mean was 0.8656, which we adopt as
a benchmark threshold. xAI's Grok-3 is most consistent, while several
lightweight models rank lowest. Consistency varies by topic: the job market is
least consistent, G7 world leaders most consistent, and issues like vaccines or
the Israeli-Palestinian conflict diverge by provider. These results show that
both the provider and the topic shape the factual consistency. We release our
code and interactive demo to support reproducible evaluation and encourage
persona-invariant prompting strategies.

</details>


### [119] [BenchPress: A Human-in-the-Loop Annotation System for Rapid Text-to-SQL Benchmark Curation](https://arxiv.org/abs/2510.13853)
*Fabian Wenz,Omar Bouattour,Devin Yang,Justin Choi,Cecil Gregg,Nesime Tatbul,Çağatay Demiralp*

Main category: cs.CL

TL;DR: 本文提出并开源了BenchPress系统，用于加速企业领域text-to-SQL基准数据集的构建。系统结合LLM（大语言模型）生成的自然语言描述与人工审核，有效降低了高质量标注的成本和时间。


<details>
  <summary>Details</summary>
Motivation: 现有text-to-SQL研究主要基于公开数据集，难以适应企业私有数据环境。此前手动标注私有SQL日志耗时昂贵，需要专家参与，效率低下。

Method: BenchPress系统利用检索增强生成（RAG）和LLM为每条SQL日志生成多种自然语言描述。人工专家对生成结果进行筛选、排序或编辑，确保准确性和领域相关性。通过人机协同提升整体标注效率与质量。

Result: 在真实企业SQL日志集上评测，BenchPress大幅降低了人工标注时间和工作量。LLM生成描述与人类审核结合能有效提升标注准确率、基准可靠性及模型评估的鲁棒性。

Conclusion: BenchPress为企业和研究人员定制text-to-SQL基准提供了高效工具，推动领域内模型在实际业务场景下的评估与改进。系统已开放源码及在线体验。

Abstract: Large language models (LLMs) have been successfully applied to many tasks,
including text-to-SQL generation. However, much of this work has focused on
publicly available datasets, such as Fiben, Spider, and Bird. Our earlier work
showed that LLMs are much less effective in querying large private enterprise
data warehouses and released Beaver, the first private enterprise text-to-SQL
benchmark. To create Beaver, we leveraged SQL logs, which are often readily
available. However, manually annotating these logs to identify which natural
language questions they answer is a daunting task. Asking database
administrators, who are highly trained experts, to take on additional work to
construct and validate corresponding natural language utterances is not only
challenging but also quite costly. To address this challenge, we introduce
BenchPress, a human-in-the-loop system designed to accelerate the creation of
domain-specific text-to-SQL benchmarks. Given a SQL query, BenchPress uses
retrieval-augmented generation (RAG) and LLMs to propose multiple natural
language descriptions. Human experts then select, rank, or edit these drafts to
ensure accuracy and domain alignment. We evaluated BenchPress on annotated
enterprise SQL logs, demonstrating that LLM-assisted annotation drastically
reduces the time and effort required to create high-quality benchmarks. Our
results show that combining human verification with LLM-generated suggestions
enhances annotation accuracy, benchmark reliability, and model evaluation
robustness. By streamlining the creation of custom benchmarks, BenchPress
offers researchers and practitioners a mechanism for assessing text-to-SQL
models on a given domain-specific workload. BenchPress is freely available via
our public GitHub repository at
https://github.com/fabian-wenz/enterprise-txt2sql and is also accessible on our
website at http://dsg-mcgraw.csail.mit.edu:5000.

</details>


### [120] [R2T: Rule-Encoded Loss Functions for Low-Resource Sequence Tagging](https://arxiv.org/abs/2510.13854)
*Mamadou K. Keita,Christopher Homan,Sebastien Diarra*

Main category: cs.CL

TL;DR: 本文提出了Rule-to-Tag (R2T) 框架，通过将多层次语言规则直接融入神经网络训练目标中，显著提升了在OOV词处理和弱监督情境中的性能。实验展示该方法在Zarma语言的词性标注和命名实体识别上优于主流基线。


<details>
  <summary>Details</summary>
Motivation: 在低资源或标签稀缺条件下，传统神经网络模型对标注样本依赖较大，且对未登录词（OOV）的处理不够稳健。为此，论文旨在引入能结合手工规则和神经网络优势的方法，以提升泛化与不确定性建模能力。

Method: 本文提出R2T混合框架，在训练损失中融合多层次语言规则，通过引入正则化项引导模型在遇到OOV词时产生合理不确定性。实验覆盖Zarma词性标注和命名实体识别（NER），仅依赖未标注文本进行无监督训练，并与有监督基线模型进行了对比。

Result: R2T-BiLSTM模型仅用未标注文本，在Zarma POS任务上达到98.2%准确率，优于使用300条标注句子微调的AfriBERTa等基线。在NER任务上，仅用50条标注句微调的R2T预训练模型便优于在300条标注句上直接训练的基线。

Conclusion: R2T实现了低资源条件下的高性能序列标注，表明在训练中融入显式任务约束和语言规则的思路（principled learning）可有效提升模型泛化能力和OOV处理能力，尤其适用于标签稀缺阶段。

Abstract: We introduce the Rule-to-Tag (R2T) framework, a hybrid approach that
integrates a multi-tiered system of linguistic rules directly into a neural
network's training objective. R2T's novelty lies in its adaptive loss function,
which includes a regularization term that teaches the model to handle
out-of-vocabulary (OOV) words with principled uncertainty. We frame this work
as a case study in a paradigm we call principled learning (PrL), where models
are trained with explicit task constraints rather than on labeled examples
alone. Our experiments on Zarma part-of-speech (POS) tagging show that the
R2T-BiLSTM model, trained only on unlabeled text, achieves 98.2% accuracy,
outperforming baselines like AfriBERTa fine-tuned on 300 labeled sentences. We
further show that for more complex tasks like named entity recognition (NER),
R2T serves as a powerful pre-training step; a model pre-trained with R2T and
fine-tuned on just 50 labeled sentences outperformes a baseline trained on 300.

</details>


### [121] [Harnessing Consistency for Robust Test-Time LLM Ensemble](https://arxiv.org/abs/2510.13855)
*Zhichen Zeng,Qi Yu,Xiao Lin,Ruizhong Qiu,Xuying Ning,Tianxin Wei,Yuchen Yan,Jingrui He,Hanghang Tong*

Main category: cs.CL

TL;DR: 本文关注于大语言模型（LLM）集成的稳健性，提出了CoRE技术，可提升集成性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 不同的LLM各有优势和劣势，集成能整合其能力。然而，主流研究多集中于提升表现，较少关注在异质化分词和模型专长下的集成鲁棒性问题。

Method: 作者提出了CoRE方法，通过顾及模型一致性增强LLM集成的鲁棒性。具体包括两个层面：（1）在token层面对分歧token应用低通滤波减少错误信号权重；（2）在模型层面提升高自信、低分歧模型输出权重，提升整体一致性。CoRE能够无缝融合进不同的集成策略。

Result: 在多项基准测试、模型组合及集成方法下实验证明，CoRE显著提高了LLM集成的性能和鲁棒性。

Conclusion: CoRE不仅能提升LLM集成的表现，也使其对输入异常和模型异构信号更加稳健，适用性强。

Abstract: Different large language models (LLMs) exhibit diverse strengths and
weaknesses, and LLM ensemble serves as a promising approach to integrate their
complementary capabilities. Despite substantial progress in improving ensemble
quality, limited attention has been paid to the robustness of ensembles against
potential erroneous signals, which often arise from heterogeneous tokenization
schemes and varying model expertise. Our analysis shows that ensemble failures
typically arise from both the token level and the model level: the former
reflects severe disagreement in token predictions, while the latter involves
low confidence and pronounced disparities among models. In light of this, we
propose CoRE, a plug-and-play technique that harnesses model consistency for
robust LLM ensemble, which can be seamlessly integrated with diverse ensemble
methods. Token-level consistency captures fine-grained disagreements by
applying a low-pass filter to downweight uncertain tokens with high
inconsistency, often due to token misalignment, thereby improving robustness at
a granular level. Model-level consistency models global agreement by promoting
model outputs with high self-confidence and minimal divergence from others,
enhancing robustness at a coarser level. Extensive experiments across diverse
benchmarks, model combinations, and ensemble strategies demonstrate that CoRE
consistently improves ensemble performance and robustness.

</details>


### [122] [Multimodal Retrieval-Augmented Generation with Large Language Models for Medical VQA](https://arxiv.org/abs/2510.13856)
*A H M Rezaul Karim,Ozlem Uzuner*

Main category: cs.CL

TL;DR: 该论文提出了一种用于医疗视觉问答（MedVQA）的系统，通过检索增强生成（RAG）方法，将通用大语言模型与医学领域的文本和视觉示例结合，显著提升了伤口护理问答的推理、输出规范性和质量。该方法无需额外训练，排名比赛第三，展示了其作为多模态临床NLP任务强基线的潜力。


<details>
  <summary>Details</summary>
Motivation: MedVQA旨在提升医疗图像的智能问答能力，支持临床决策。然而，现有方法在特定领域如伤口护理的表现有限，尤其是在结构化属性和自由文本生成方面；因此需要简易但高效的基线系统来推动领域进展。

Method: 该系统基于指令微调的大型通用语言模型，结合RAG框架，从领域数据中检索相关文本与视觉示例，并通过简单索引及融合在无额外训练情况下指导模型输出，提升生成答案的相关性和规范性。

Result: MasonNLP系统在MEDIQA-WV 2025伤口护理VQA任务中表现突出，以平均41.37%的得分在51个参赛方案中排名第三，在多项指标（dBLEU、ROUGE、BERTScore、LLM评分）上均有良好表现。

Conclusion: 基于通用LLM的轻量级RAG方法，无需复杂训练即可高效增强医学多模态问答任务表现，为临床NLP任务提供了一个简单、有效且具普适性的基线。

Abstract: Medical Visual Question Answering (MedVQA) enables natural language queries
over medical images to support clinical decision-making and patient care. The
MEDIQA-WV 2025 shared task addressed wound-care VQA, requiring systems to
generate free-text responses and structured wound attributes from images and
patient queries. We present the MasonNLP system, which employs a
general-domain, instruction-tuned large language model with a
retrieval-augmented generation (RAG) framework that incorporates textual and
visual examples from in-domain data. This approach grounds outputs in
clinically relevant exemplars, improving reasoning, schema adherence, and
response quality across dBLEU, ROUGE, BERTScore, and LLM-based metrics. Our
best-performing system ranked 3rd among 19 teams and 51 submissions with an
average score of 41.37%, demonstrating that lightweight RAG with
general-purpose LLMs -- a minimal inference-time layer that adds a few relevant
exemplars via simple indexing and fusion, with no extra training or complex
re-ranking -- provides a simple and effective baseline for multimodal clinical
NLP tasks.

</details>


### [123] [ShishuLM: Lightweight Language Model with Hybrid Decoder-MLP Architecture and Paired Weight Sharing](https://arxiv.org/abs/2510.13860)
*Shivanshu Kumar,Gopalakrishnan Srinivasan*

Main category: cs.CL

TL;DR: 本文提出了一种高效的语言模型架构ShishuLM，能大幅减少内存和计算开销，同时保持性能表现。实验证明该模型在内存和延迟方面优于传统Transformer模型。


<details>
  <summary>Details</summary>
Motivation: Transformer结构在自然语言处理领域表现优异，但资源消耗大，存在架构冗余。随着小型语言模型（SLM）在自主性AI系统中的需求增加，提升其效率和易用性显得尤为重要。

Method: 文章综合AI可解释性与推理阶段层级剪枝的研究，设计了ShishuLM架构。该模型通过减少参数量和KV缓存需求优化内存使用，并在适中上下文长度下，将部分Transformer模块以MLP方式近似，从而提升效率。

Result: 与原始模型相比，ShishuLM在训练和推理阶段的内存需求降低最多达25%，延迟最高提升40%。结果显示其在不同规模SLM上均有良好表现。

Conclusion: ShishuLM为预训练阶段小型语言模型的高效结构提供了新思路，对于构建更高效的AI系统具有实际意义。

Abstract: While the transformer architecture has achieved state-of-the-art performance
on natural language processing tasks, these models impose substantial memory
and computational overhead. Recent research has identified significant
architectural redundancies within these models, presenting opportunities for
optimization without compromising performance. Taking insights from research in
AI interpretability and inference-time layer pruning, we introduce an efficient
language model architecture, referred to as ShishuLM, which reduces both the
parameter count and Key-Value (KV) cache requirements. Given the increasing
importance of Small Language Models (SLMs) in agentic AI systems, we evaluate
our approach on two SLMs of different scales. Our analysis reveals that for
moderate-context scenarios, normalization coupled with attention computation is
roughly linear with the input, enabling entire transformer blocks to be
approximated through Multi-Layer Perceptrons (MLPs). Our results show that
ShishuLM provides up to 25% reduction in memory requirements and up to 40%
improvement in latency during both training and inference, compared to parent
models. Our experimental and analytical findings provide insights towards
building more efficient SLM architectures from a pre-training standpoint.

</details>


### [124] [Ensembling Large Language Models to Characterize Affective Dynamics in Student-AI Tutor Dialogues](https://arxiv.org/abs/2510.13862)
*Chenyu Zhang,Sharifa Alghowinem,Cynthia Breazeal*

Main category: cs.CL

TL;DR: 本研究提出了一种新颖的集成式大型语言模型（LLM）框架，用于大规模感知AI助教与学生对话中的情感动态。通过分析近1.7万次对话回合，结合多模型情感标注与融合，揭示了学生与AI互动时情感状态演变及其对学习过程的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）在教育领域的学习效用已被关注，其在教学对话中对学习者情感动态的影响及理解尚不足。为更负责任地将生成式AI融入教育应用，需要深入了解学生在AI辅助学习过程中的情感变化及其作用。

Method: 收集三所美国高校261名本科生两个学期、16986轮与基于LLM的PyTutor对话数据。采用Gemini、GPT-4o、Claude三种前沿LLM以零样本方式自动标注对话的情感（包括愉悦度、唤醒度及学习帮助性分值和文本情感标签）。利用模型内排序加权融合及跨模型多数共识，生成稳健的学习者情感画像，进而分析情感状态的动态演变。

Result: 学生与AI助教交互时，大多体验到轻度正面的情感和适中的唤醒度。情感随解题进程快速变化，困惑与好奇频繁交织，挫折感偶尔出现且可能影响学习进度。积极情绪持续时间较长但也较脆弱，负面情绪通常能迅速恢复至中性或正面状态，中性时刻常作为情感转折点，对学习轨迹有重要作用。

Conclusion: AI助教对话中学生情感丰富且易变，绝大部分负面情绪能及时化解。中性情感时刻是提升干预效果的关键节点。情感感知及响应能力对于设计更具适应性、责任感的AI教育工具尤为重要，未来AI助教应在关键情感转折处主动支持学习者。

Abstract: While recent studies have examined the leaning impact of large language model
(LLM) in educational contexts, the affective dynamics of LLM-mediated tutoring
remain insufficiently understood. This work introduces the first ensemble-LLM
framework for large-scale affect sensing in tutoring dialogues, advancing the
conversation on responsible pathways for integrating generative AI into
education by attending to learners' evolving affective states. To achieve this,
we analyzed two semesters' worth of 16,986 conversational turns exchanged
between PyTutor, an LLM-powered AI tutor, and 261 undergraduate learners across
three U.S. institutions. To investigate learners' emotional experiences, we
generate zero-shot affect annotations from three frontier LLMs (Gemini, GPT-4o,
Claude), including scalar ratings of valence, arousal, and
learning-helpfulness, along with free-text emotion labels. These estimates are
fused through rank-weighted intra-model pooling and plurality consensus across
models to produce robust emotion profiles. Our analysis shows that during
interaction with the AI tutor, students typically report mildly positive affect
and moderate arousal. Yet learning is not uniformly smooth: confusion and
curiosity are frequent companions to problem solving, and frustration, while
less common, still surfaces in ways that can derail progress. Emotional states
are short-lived--positive moments last slightly longer than neutral or negative
ones, but they are fragile and easily disrupted. Encouragingly, negative
emotions often resolve quickly, sometimes rebounding directly into positive
states. Neutral moments frequently act as turning points, more often steering
students upward than downward, suggesting opportunities for tutors to intervene
at precisely these junctures.

</details>


### [125] [Unlocking the Potential of Diffusion Language Models through Template Infilling](https://arxiv.org/abs/2510.13870)
*Junhoo Lee,Seungyeon Kim,Nojun Kwak*

Main category: cs.CL

TL;DR: 本文提出了一种新的扩散语言模型（DLMs）推理策略——模板填充（Template Infilling, TI），在数学推理和代码生成任务上显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: DLMs作为自回归语言模型的替代方案具有潜力，但当前仅依赖前缀式提示，限制了推理灵活性和结构控制能力。

Method: 提出了模板填充（TI）策略，先生成目标回复的结构模板，再填充其中的空白片段。同时引入动态片段分配（DSA），根据生成置信度自适应调整片段长度。

Result: 在数学推理和代码生成基准测试中，TI方法比传统策略平均提升了17个百分点。同时，在多token生成任务中，TI提升了生成速度且保持了质量。

Conclusion: 模板填充和动态片段分配为DLMs推理带来更高灵活性和控制力，可广泛提升多种文本生成任务表现。

Abstract: Diffusion Language Models (DLMs) have emerged as a promising alternative to
Autoregressive Language Models, yet their inference strategies remain limited
to prefix-based prompting inherited from the autoregressive paradigm. In this
paper, we propose Template Infilling (TI), a tailored conditioning methodology
for DLMs' generation process. Unlike conventional prefix prompting, TI first
generates a structural template for the target response, then fills in the
masked segments. To enhance the flexibility of this structural control, we
introduce Dynamic Segment Allocation (DSA), which adaptively adjusts segment
lengths based on generation confidence. We demonstrate the effectiveness of our
approach on mathematical reasoning and code generation benchmarks, achieving
consistent improvements of 17.01$\%$p over baseline. Furthermore, we show that
TI provides additional advantages in multi-token generation settings, enabling
effective speedup while maintaining generation quality.

</details>


### [126] [Quechua Speech Datasets in Common Voice: The Case of Puno Quechua](https://arxiv.org/abs/2510.13871)
*Elwin Huaman,Wendi Huaman,Jorge Luis Huaman,Ninfa Quispe*

Main category: cs.CL

TL;DR: 本文介绍了如何将克丘亚等低资源语言纳入Common Voice开放语音数据集，以推动这些语言的语音技术发展。以Puno Quechua为案例，展示了语料收集和社区参与的过程与成果。


<details>
  <summary>Details</summary>
Motivation: 克丘亚等低资源语言由于数据稀缺性，严重制约了其在语音技术领域的发展。现有主流语音资源很少覆盖此类语言，缺乏开放、共享且可扩展的方法来促进相关数据集的建设，因此，有必要探索社区驱动的数据采集新模式。

Method: 采用社区协作的方式将克丘亚语（含17种变体，尤其是Puno Quechua）集成到Mozilla的Common Voice平台，进行语言接入和语料收集，包括朗读与自发语音，并对采集的数据实施验证。

Result: Common Voice平台目前已收录191.1小时的克丘亚语语音数据（86%已验证），其中Puno Quechua贡献了12小时（77%已验证），大幅提升了此类语音数据的可获取性。

Conclusion: Common Voice证明了通过社区参与可高效收集低资源语言数据，推动技术普惠。论文还提出了未来的研究方向，包括技术挑战、社区参与和原住民数据主权问题，这为包容性语音技术和数字赋能提供了宝贵经验。

Abstract: Under-resourced languages, such as Quechuas, face data and resource scarcity,
hindering their development in speech technology. To address this issue, Common
Voice presents a crucial opportunity to foster an open and community-driven
speech dataset creation. This paper examines the integration of Quechua
languages into Common Voice. We detail the current 17 Quechua languages,
presenting Puno Quechua (ISO 639-3: qxp) as a focused case study that includes
language onboarding and corpus collection of both reading and spontaneous
speech data. Our results demonstrate that Common Voice now hosts 191.1 hours of
Quechua speech (86\% validated), with Puno Quechua contributing 12 hours (77\%
validated), highlighting the Common Voice's potential. We further propose a
research agenda addressing technical challenges, alongside ethical
considerations for community engagement and indigenous data sovereignty. Our
work contributes towards inclusive voice technology and digital empowerment of
under-resourced language communities.

</details>


### [127] [FRACCO: A gold-standard annotated corpus of oncological entities with ICD-O-3.1 normalisation](https://arxiv.org/abs/2510.13873)
*Johann Pignat,Milena Vucetic,Christophe Gaudet-Blavignac,Jamil Zaghir,Amandine Stettler,Fanny Amrein,Jonatan Bonjour,Jean-Philippe Goldman,Olivier Michielin,Christian Lovis,Mina Bjelogrlic*

Main category: cs.CL

TL;DR: 本文介绍了FRACCO——一个由专家标注的法语肿瘤学临床文本数据集，包括1301个人工合成病例，致力于推动法语临床文本的自然语言处理研究。


<details>
  <summary>Details</summary>
Motivation: 临床文本处理依赖高质量标注语料，但法语肿瘤学领域相关资源非常稀缺，因此亟需一个标准数据集来促进法语医学NLP工具的开发。

Method: 该语料库由西班牙语CANTEMIST语料翻译并改编而来，涵盖1301条法语临床病例。专家使用ICD-O标准对文本中的形态学、分布及组织学分化等术语进行实体和概念规范化标注，并引入了结合多个ICD-O元素的复合表达式层。标注流程包括两位领域专家手动标注、自动匹配及五人小组的人工校审。

Result: 最终语料包含71127条ICD-O标准化注释、399个独特形态学编码、272个分布编码和2043个独特复合表达式，可用于法语命名实体识别与概念规范化任务。

Conclusion: FRACCO数据集为法语肿瘤学文本的实体和概念识别提供了权威标准，有助于推进相关自然语言处理工具的研究和开发。

Abstract: Developing natural language processing tools for clinical text requires
annotated datasets, yet French oncology resources remain scarce. We present
FRACCO (FRench Annotated Corpus for Clinical Oncology) an expert-annotated
corpus of 1301 synthetic French clinical cases, initially translated from the
Spanish CANTEMIST corpus as part of the FRASIMED initiative. Each document is
annotated with terms related to morphology, topography, and histologic
differentiation, using the International Classification of Diseases for
Oncology (ICD-O) as reference. An additional annotation layer captures
composite expression-level normalisations that combine multiple ICD-O elements
into unified clinical concepts. Annotation quality was ensured through expert
review: 1301 texts were manually annotated for entity spans by two domain
experts. A total of 71127 ICD-O normalisations were produced through a
combination of automated matching and manual validation by a team of five
annotators. The final dataset representing 399 unique morphology codes (from
2549 different expressions), 272 topography codes (from 3143 different
expressions), and 2043 unique composite expressions (from 11144 different
expressions). This dataset provides a reference standard for named entity
recognition and concept normalisation in French oncology texts.

</details>


### [128] [What Layers When: Learning to Skip Compute in LLMs with Residual Gates](https://arxiv.org/abs/2510.13876)
*Filipe Laitenberger,Dawid Kopiczko,Cees G. M. Snoek,Yuki M. Asano*

Main category: cs.CL

TL;DR: 本文提出了一种针对解码器型语言模型的GateSkip机制，通过对残差流进行门控，实现了token级的逐层跳跃，提高了推理效率并节省计算力。


<details>
  <summary>Details</summary>
Motivation: 过去的Mixture-of-Depths或早停止方法存在模型训练不稳定和需大幅重训等问题。作者希望设计一种能在不大改模型、依靠微调即可实现高效跳层和高准确率的方法。

Method: 为每个Attention/MLP分支增加一个sigmoid-linear门控，输出用于判断每个token是否跳过某层；在推理时，按gate值排序，低重要性的token跳过，且每层有预算限制。门控为可微分，便于在预训练模型上稳定微调。

Result: 针对长文本推理任务，方法可节省高达15%的计算力并保留超过90%的准确率。在指令微调模型上，满负载时准确率提升，且在节省约50%算力情况下质量接近基线。门控结果还揭示了transformer内部的信息流特点。

Conclusion: GateSkip能稳定集成到预训练解码器型语言模型中，实现token级跳层与高效推理，同时与量化、剪枝和自我预测等技术兼容，对实际大模型应用具有较高价值。

Abstract: We introduce GateSkip, a simple residual-stream gating mechanism that enables
token-wise layer skipping in decoder-only LMs. Each Attention/MLP branch is
equipped with a sigmoid-linear gate that condenses the branch's output before
it re-enters the residual stream. During inference we rank tokens by the gate
values and skip low-importance ones using a per-layer budget. While early-exit
or router-based Mixture-of-Depths models are known to be unstable and need
extensive retraining, our smooth, differentiable gates fine-tune stably on top
of pretrained models. On long-form reasoning, we save up to 15\% compute while
retaining over 90\% of baseline accuracy. On instruction-tuned models we see
accuracy gains at full compute and match baseline quality near 50\% savings.
The learned gates give insight into transformer information flow (e.g., BOS
tokens act as anchors), and the method combines easily with quantization,
pruning, and self-speculative decoding.

</details>


### [129] [TextBandit: Evaluating Probabilistic Reasoning in LLMs Through Language-Only Decision Tasks](https://arxiv.org/abs/2510.13878)
*Jimin Lim,Arjun Damerla,Arthur Jiang,Nam Le*

Main category: cs.CL

TL;DR: 本文提出了一种仅基于文本反馈、考察大语言模型（LLM）序贯决策能力的新基准测试。实验显示，部分模型在无需显式数值信息的情况下仍能有效选择最优策略，其中 Qwen3-4B 的表现尤其突出。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注LLM在推理任务上的能力，但其在不依赖数值信息情况下作出序贯决策的能力尚未充分探索。作者希望研究LLM是否能通过自然语言反馈进行复杂决策，并与传统算法进行比较。

Method: 该文设计了一种文本化的多臂老虎机环境，LLM只能通过逐轮获得语言反馈（例如“你获得了一个代币”）来判断哪只“臂”最佳。作者选用四种开源LLM，并与Thompson Sampling、Epsilon Greedy、UCB等算法以及随机选择作对比测试。

Result: 多数开源LLM表现弱于传统决策算法，但Qwen3-4B在选择最佳臂方面的准确率高达89.2%，超越了其它LLM和传统方法。

Conclusion: 研究表明，LLM仅凭语言输入可涌现概率性推理能力。此项新基准为测评LLM在真实、非数值语境下的决策能力提供了新思路。

Abstract: Large language models (LLMs) have shown to be increasingly capable of
performing reasoning tasks, but their ability to make sequential decisions
under uncertainty only using natural language remains underexplored. We
introduce a novel benchmark in which LLMs interact with multi-armed bandit
environments using purely textual feedback, "you earned a token", without
access to numerical cues or explicit probabilities, resulting in the model to
infer latent reward structures purely off linguistic cues and to adapt
accordingly. We evaluated the performance of four open-source LLMs and compare
their performance to standard decision-making algorithms such as Thompson
Sampling, Epsilon Greedy, Upper Confidence Bound (UCB), and random choice.
While most of the LLMs underperformed compared to the baselines, Qwen3-4B,
achieved the best-arm selection rate of 89.2% , which significantly
outperformed both the larger LLMs and traditional methods. Our findings suggest
that probabilistic reasoning is able to emerge from language alone, and we
present this benchmark as a step towards evaluating decision-making
capabilities in naturalistic, non-numeric contexts.

</details>


### [130] [Catch Your Breath: Adaptive Computation for Self-Paced Sequence Production](https://arxiv.org/abs/2510.13879)
*Alexandre Galashov,Matt Jones,Rosemary Ke,Yuan Cao,Vaishnavh Nagarajan,Michael C. Mozer*

Main category: cs.CL

TL;DR: 本文提出了一类名为Catch Your Breath（CYB）的监督训练目标，使语言模型能动态自适应地为每个输入token分配不同的计算步骤数，即通过<don't know>与<pause>机制，模型可根据自身不确定性请求更多计算资源。实验证明，CYB模型在达到相同性能时，比基线模型（无暂停机制）所需训练数据量仅为三分之一，并能根据token复杂度智能调节处理时间。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，语言模型各个token的计算复杂度不同，固定的计算资源分配方式可能导致资源浪费或表现受限。作者希望模型能自适应分配计算资源，提高效率与性能，并能够根据不确定性合理请求额外计算。

Method: 作者提出CYB损失函数家族，包括三种方法：（1）CYB-AP，将输出选择建模为带时间折扣的动态预测问题；（2）CYB-VA，使用变分方法约束输出停步分布，提高准确率；（3）CYB-DP，对计算预算超标进行约束。训练时，模型可通过<don't know>和<pause>机制请求更多处理时间，对token级别复杂度进行自适应建模。作者对多种损失函数变体进行了微调实验比较。

Result: CYB模型在同等性能下，仅需基线模型1/3的数据量，且比传统带pause与交叉熵损失的模型也节省了1/2数据量。CYB模型能根据token语义复杂度智能调节计算步数，且显著提升模型对不确定性与复杂输入的处理能力。

Conclusion: CYB方法使语言模型能根据输入复杂度动态延长处理时间，提高计算资源利用率与模型泛化能力，有望在高效/大规模模型训练和实际部署中发挥重要作用。

Abstract: We explore a class of supervised training objectives that allow a language
model to dynamically and autonomously scale the number of compute steps used
for each input token. For any token, the model can request additional compute
steps by emitting a <don't know> output. If the model is granted a delay, a
specialized <pause> token is inserted at the next input step, providing the
model with additional compute resources to generate an output. The model can
request multiple pauses. To train the model to use <don't know> outputs
judiciously and to calibrate its uncertainty, we frame the selection of each
output token as a sequential-decision problem with a time cost. We refer to the
class of methods as $\textit{Catch Your Breath}$ losses and we study three
methods in this class: CYB-AP frames the model's task as anytime prediction,
where an output may be required at any step and accuracy is discounted over
time; CYB-VA is a variational approach that aims to maximize prediction
accuracy subject to a specified distribution over stopping times; and CYB-DP
imposes a penalty based on a computational budget. Through fine-tuning
experiments, we identify the best performing loss variant. The CYB model needs
only one third as much training data as the baseline (no pause) model needs to
achieve the same performance, and half as much data as a model with pauses and
a cross-entropy loss. We find that the CYB model requests additional steps when
doing so improves accuracy, and the model adapts its processing time to
token-level complexity and context. For example, it often pauses after plural
nouns like $\textit{patients}$ and $\textit{challenges}$ but never pauses after
the first token of contracted words like $\textit{wasn}$ and $\textit{didn}$,
and it shows high variability for ambiguous tokens like $\textit{won}$, which
could function as either a verb or part of a contraction.

</details>


### [131] [PAGE: Prompt Augmentation for text Generation Enhancement](https://arxiv.org/abs/2510.13880)
*Mauro Jose Pacchiotti,Luciana Ballejos,Mariel Ale*

Main category: cs.CL

TL;DR: 本文提出了PAGE框架，一种利用简单辅助模块（如分类器、信息提取器）对生成模型进行辅助的方法，从而提升文本生成的质量和可控性。


<details>
  <summary>Details</summary>
Motivation: 虽然自然语言生成模型在生成任务中表现优异，但在特定任务或场景下，常常效果不佳且需要大量额外数据或微调。需要一种低成本且易于适配的方法提升其能力。

Method: PAGE框架利用轻量级辅助模块（如分类器、提取器）从输入文本中推断关键信息，并用这些信息增强输入提示，从而辅助生成模型。不同于需要辅助生成模型的方法，PAGE结构简单且模块化，便于扩展到多种任务。

Result: 在需求工程领域进行案例验证，使用辅助分类器提升了软件需求生成的质量，验证了PAGE的可行性。

Conclusion: PAGE框架无需复杂结构，仅以简单辅助模块显著提升了文本生成模型在特定任务下的表现和可控性，具备良好的通用性和拓展性。

Abstract: In recent years, natural language generative models have shown outstanding
performance in text generation tasks. However, when facing specific tasks or
particular requirements, they may exhibit poor performance or require
adjustments that demand large amounts of additional data. This work introduces
PAGE (Prompt Augmentation for text Generation Enhancement), a framework
designed to assist these models through the use of simple auxiliary modules.
These modules, lightweight models such as classifiers or extractors, provide
inferences from the input text. The output of these auxiliaries is then used to
construct an enriched input that improves the quality and controllability of
the generation. Unlike other generation-assistance approaches, PAGE does not
require auxiliary generative models; instead, it proposes a simpler, modular
architecture that is easy to adapt to different tasks. This paper presents the
proposal, its components and architecture, and reports a proof of concept in
the domain of requirements engineering, where an auxiliary module with a
classifier is used to improve the quality of software requirements generation.

</details>


### [132] [Too Open for Opinion? Embracing Open-Endedness in Large Language Models for Social Simulation](https://arxiv.org/abs/2510.13884)
*Bolei Ma,Yong Cao,Indira Sen,Anna-Carolina Haensch,Frauke Kreuter,Barbara Plank,Daniel Hershcovich*

Main category: cs.CL

TL;DR: 本文主张在利用大语言模型（LLM）进行社会模拟时，应采用开放式生成（如自由文本）而不是封闭选项，以更真实地反映社会现象和公众观点。


<details>
  <summary>Details</summary>
Motivation: 当前大多数关于LLM社会模拟的研究，为了便于评价和比较，主要采用选择题或简短回答等封闭式设计。但是，这种做法限制了LLM天然的生成型能力，不利于真实再现社会现象。因此，作者希望推动更能发挥LLM多样性和生成能力的开放式模拟。

Method: 本文为立场性论文，基于长期的调查方法学经验和NLP领域的新进展，理论分析并论证LLM社会模拟中的开放性优势。文章比较了封闭式和开放式方法，并通过文献回顾强调开放式设计能够带来的诸多好处。

Result: 作者总结指出，采用开放式文本能提升社会模拟的测量和设计质量，促进对未预见观点的探索，减少研究偏向，并能更好地捕捉表达性与个体差异。同时有利于前测和整体方法论的提升。

Conclusion: 作者呼吁应发展专门针对开放式生成内容的新实践和评价框架，更好地结合NLP和社会科学，切勿因便捷而限制LLM的生成多样性。

Abstract: Large Language Models (LLMs) are increasingly used to simulate public opinion
and other social phenomena. Most current studies constrain these simulations to
multiple-choice or short-answer formats for ease of scoring and comparison, but
such closed designs overlook the inherently generative nature of LLMs. In this
position paper, we argue that open-endedness, using free-form text that
captures topics, viewpoints, and reasoning processes "in" LLMs, is essential
for realistic social simulation. Drawing on decades of survey-methodology
research and recent advances in NLP, we argue why this open-endedness is
valuable in LLM social simulations, showing how it can improve measurement and
design, support exploration of unanticipated views, and reduce
researcher-imposed directive bias. It also captures expressiveness and
individuality, aids in pretesting, and ultimately enhances methodological
utility. We call for novel practices and evaluation frameworks that leverage
rather than constrain the open-ended generative diversity of LLMs, creating
synergies between NLP and social science.

</details>


### [133] [Order from Chaos: Comparative Study of Ten Leading LLMs on Unstructured Data Categorization](https://arxiv.org/abs/2510.13885)
*Ariel Kamen*

Main category: cs.CL

TL;DR: 本研究对10种主流大语言模型（LLM）在无结构文本分类中的表现进行了系统比较，并提出了一种集成方法显著提升分类效果，减少模型幻觉。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM发展迅速，但其在实际文本分类任务中的准确性和可靠性仍存在不足，亟需系统评估及改进手段。

Method: 采用IAB 2.2分层分类体系，通过8,660个人工标注样本，以统一的zero-shot提示评测10种LLM。评估指标包括准确率、精确率、召回率、F1等常规指标，以及幻觉率、膨胀率和分类成本等新型指标。同时，引入多模型集成方法对比单模型表现。

Result: 所有LLM的传统指标表现仅为中等（如准确率平均34%，F1分数41%），模型普遍存在类别过度预测（高膨胀率和幻觉率）；集成方法有效提升准确率，减少类别膨胀，并实现零幻觉。Gemini 1.5/2.0 Flash和GPT 20B/120B表现优异，其中GPT 120B幻觉率最低。

Conclusion: 单一模型的扩展和结构优化难以从根本上提高大规模文本分类的准确性。多模型协同（集成方法）有望显著提升模型在复杂分类任务中的表现，甚至可超越人类专家水平。

Abstract: This study presents a comparative evaluation of ten state-of-the-art large
language models (LLMs) applied to unstructured text categorization using the
Interactive Advertising Bureau (IAB) 2.2 hierarchical taxonomy. The analysis
employed a uniform dataset of 8,660 human-annotated samples and identical
zero-shot prompts to ensure methodological consistency across all models.
Evaluation metrics included four classic measures - accuracy, precision,
recall, and F1-score - and three LLM-specific indicators: hallucination ratio,
inflation ratio, and categorization cost.
  Results show that, despite their rapid advancement, contemporary LLMs achieve
only moderate classic performance, with average scores of 34% accuracy, 42%
precision, 45% recall, and 41% F1-score. Hallucination and inflation ratios
reveal that models frequently overproduce categories relative to human
annotators. Among the evaluated systems, Gemini 1.5/2.0 Flash and GPT 20B/120B
offered the most favorable cost-to-performance balance, while GPT 120B
demonstrated the lowest hallucination ratio. The findings suggest that scaling
and architectural improvements alone do not ensure better categorization
accuracy, as the task requires compressing rich unstructured text into a
limited taxonomy - a process that challenges current model architectures.
  To address these limitations, a separate ensemble-based approach was
developed and tested. The ensemble method, in which multiple LLMs act as
independent experts, substantially improved accuracy, reduced inflation, and
completely eliminated hallucinations. These results indicate that coordinated
orchestration of models - rather than sheer scale - may represent the most
effective path toward achieving or surpassing human-expert performance in
large-scale text categorization.

</details>


### [134] [Reliable Fine-Grained Evaluation of Natural Language Math Proofs](https://arxiv.org/abs/2510.13888)
*Wenjie Ma,Andrei Cojocaru,Neel Kolhe,Bradley Louie,Robin Said Sharif,Haihan Zhang,Vincent Zhuang,Matei Zaharia,Sewon Min*

Main category: cs.CL

TL;DR: 论文提出了一个系统性方法来评估大语言模型生成的数学证明的质量，并开发了高质量细致评分的数据集与评测器，大幅提升了自动评测的准确性。


<details>
  <summary>Details</summary>
Motivation: 针对当前大语言模型在数学推理任务中，缺乏对生成的自然语言证明进行细致、可靠自动评估的手段，影响后续研究和应用。

Method: 建立了首个由专家标注的细粒度数学证明评分数据集ProofBench（覆盖6大数学竞赛的145题与435份模型生成解答），并系统设计和测试多种评测方案，最终提出使用强推理能力大模型骨干、丰富上下文与简单集成的方法构建实用评测器ProofGrader。

Result: ProofGrader在与专家评分比对中达到0.926的低平均绝对误差（MAE），显著优于简单基线。同时在best-of-n选择任务中，能显著逼近人类专家表现，关闭78%评测差距。

Conclusion: 论文为LLM数学证明能力的自动评估提供了高质量工具和数据，将推动自动解题和证明生成等相关应用发展。

Abstract: Recent advances in large language models (LLMs) for mathematical reasoning
have largely focused on tasks with easily verifiable final answers; however,
generating and verifying natural language math proofs remains an open
challenge. We identify the absence of a reliable, fine-grained evaluator for
LLM-generated math proofs as a critical gap. To address this, we propose a
systematic methodology for developing and validating evaluators that assign
fine-grained scores on a 0-7 scale to model-generated math proofs. To enable
this study, we introduce ProofBench, the first expert-annotated dataset of
fine-grained proof ratings, spanning 145 problems from six major math
competitions (USAMO, IMO, Putnam, etc) and 435 LLM-generated solutions from
Gemini-2.5-pro, o3, and DeepSeek-R1. %with expert gradings. Using ProofBench as
a testbed, we systematically explore the evaluator design space across key
axes: the backbone model, input context, instructions and evaluation workflow.
Our analysis delivers ProofGrader, an evaluator that combines a strong
reasoning backbone LM, rich context from reference solutions and marking
schemes, and a simple ensembling method; it achieves a low Mean Absolute Error
(MAE) of 0.926 against expert scores, significantly outperforming naive
baselines. Finally, we demonstrate its practical utility in a best-of-$n$
selection task: at $n=16$, ProofGrader achieves an average score of 4.14 (out
of 7), closing 78% of the gap between a naive binary evaluator (2.48) and the
human oracle (4.62), highlighting its potential to advance downstream proof
generation.

</details>


### [135] [A Survey on Collaborating Small and Large Language Models for Performance, Cost-effectiveness, Cloud-edge Privacy, and Trustworthiness](https://arxiv.org/abs/2510.13890)
*Fali Wang,Jihai Chen,Shuhua Yang,Ali Al-Lawati,Linli Tang,Hui Liu,Suhang Wang*

Main category: cs.CL

TL;DR: 本文系统性综述了小语言模型(SLMs)和大语言模型(LLMs)协作的研究进展，并提出了基于协作目标的分类及未来方向。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型虽然能力强但存在高微调成本、推理延迟、难以在边缘部署以及可靠性问题。小语言模型更高效灵活，两者协作有望兼顾多样化任务需求和部署场景，亟需系统梳理和总结。

Method: 作者梳理和总结了SLM和LLM的协作方式，并从性能提升、成本效益、云-边隐私和可信性四大目标组织了研究现状，提出相关的分类体系，对代表性方法和设计范式进行了回顾。

Result: 系统性地总结并评述了当前SLMM-LLM协作领域的主要方法和现有成果，包括各自优势、典型应用及挑战。

Conclusion: SLM与LLM的协作能够兼顾效率、能力和安全等多方面需求，但仍面临若干挑战。未来研究需在提升协作效率、安全性和规模性等方面发力，推动更高效、可靠的SLM-LLM协作体系落地。

Abstract: Large language models (LLMs) have advanced many domains and applications but
face high fine-tuning costs, inference latency, limited edge deployability, and
reliability concerns. Small language models (SLMs), compact, efficient, and
adaptable, offer complementary remedies. Recent work explores collaborative
frameworks that fuse SLMs' specialization and efficiency with LLMs'
generalization and reasoning to meet diverse objectives across tasks and
deployment scenarios. Motivated by these developments, this paper presents a
systematic survey of SLM-LLM collaboration organized by collaboration
objectives. We propose a taxonomy with four goals: performance enhancement,
cost-effectiveness, cloud-edge privacy, and trustworthiness. Within this
framework, we review representative methods, summarize design paradigms, and
outline open challenges and future directions toward efficient, secure, and
scalable SLM-LLM collaboration.

</details>


### [136] [The Harder The Better: Maintaining Supervised Fine-tuning Generalization with Less but Harder Data](https://arxiv.org/abs/2510.13892)
*Zhaoyang Shang,Sibo Wei,Jianbin Guo,Rui Zhou,Lifeng Dong,Yin Luo*

Main category: cs.CL

TL;DR: 提出了一种名为THTB（The Harder The Better）的认知科学启发式数据选择和标注框架，用于提升大模型在专业领域的微调效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有针对大模型（LLM）的高质量数据选择方法过于依赖模型内部知识、可解释性弱且泛化有限，限制了专业领域模型适配效果，需要更有效、具可解释性的数据筛选与标注指导机制。

Method: 提出THTB框架，将认知难度分数（包括内在与外在难度）与数据质量过滤结合，选择更高水平认知指令，并为数据标注提供定量、可解释的筛选标准。该方法不仅用于数据挑选，还为垂直领域标注提供指导。

Result: 实验证明，THTB仅需5%数据即可超越全量数据训练的模型，且比仅依赖LLM方法具备更强泛化能力。用于垂直领域标注时，仅用2%数据即可超过大量数据训练的模型，具备很强的领域适配潜力。

Conclusion: THTB框架可以大幅提升大模型领域微调的数据利用率和泛化能力，同时提供高可解释性和低成本的数据选择方案，为专业场景下的数据筛选和标注带来新思路。

Abstract: Large Language Models (LLMs) excel in general tasks, but adapting them to
specialized domains relies on high-quality supervised fine-tuning (SFT) data.
Although existing methods can identify subsets of high-quality data and reduce
training cost to some extent, their selection process still suffers from
over-reliance on LLMs' internal knowledge, weak interpretability, and limited
generalization. To address these limitations, we propose THTB (The Harder The
Better), a cognitive science-inspired framework for instruction data selection
and annotation guidance. THTB prioritizes higher-level cognitive instructions
by combining quality filtering with intrinsic and extrinsic hardness scoring,
offering interpretable and quantifiable criteria for efficient SFT, both in
data selection and annotation guidance. Experiments show that THTB enables
models trained on only 5% of the data to outperform full-dataset training,
while achieving superior generalization compared with LLM-only selection. In
addition, THTB provides effective annotation guidance in vertical domains,
enabling a model trained on just 2% of the data to surpass models trained on
much larger datasets, demonstrating strong potential for domain adaptation. Our
code, datasets, and models are available on
https://github.com/DYJG-research/THTB.

</details>


### [137] [Guarding the Guardrails: A Taxonomy-Driven Approach to Jailbreak Detection](https://arxiv.org/abs/2510.13893)
*Olga E. Sorokoletova,Francesco Giarrusso,Vincenzo Suriani,Daniele Nardi*

Main category: cs.CL

TL;DR: 本文提出了一套更为全面和系统的越狱（jailbreaking）攻击方法分类体系，并通过红队实验研究了不同攻击策略的有效性及其对大型语言模型（LLM）安全性的威胁，进一步提出了基于分类体系的自动检测和多语种、对话场景下的新数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM越狱防御方法主要针对单轮攻击，且覆盖的攻击类型和语言有限，缺乏对攻击策略本身的全面分类和深入理解，限制了对模型脆弱性的认知和防御能力的提升。

Method: 1）组织结构化红队挑战实验，收集攻击样本；2）基于实验数据，提出细致的七大类、50种越狱策略的层次化分类法；3）统计分析不同攻击方式的流行度和成功率；4）通过分类体系优化提示词，提升自动化越狱检测能力；5）制作并发布带注释的意大利语多轮攻防对话新数据集。

Result: 总结和扩展了50种越狱方法，归类为七大类；统计结果揭示了各攻击类型的常见性与成功率，表明某些策略更高效地攻击LLM。实验显示基于新分类体系的Jailbreak检测方法性能提升。建立了高质量意大利语对话数据集，支持多轮、多语种攻击研究。

Conclusion: 越狱技术对LLM构成持续威胁，全面系统的攻击策略分类有助于理解模型弱点和指导安全防护，基于此分类的新检测方法和多语种数据集将有助于模型对抗性安全的深入研究和实践。

Abstract: Jailbreaking techniques pose a significant threat to the safety of Large
Language Models (LLMs). Existing defenses typically focus on single-turn
attacks, lack coverage across languages, and rely on limited taxonomies that
either fail to capture the full diversity of attack strategies or emphasize
risk categories rather than the jailbreaking techniques. To advance the
understanding of the effectiveness of jailbreaking techniques, we conducted a
structured red-teaming challenge. The outcome of our experiments are manifold.
First, we developed a comprehensive hierarchical taxonomy of 50 jailbreak
strategies, consolidating and extending prior classifications into seven broad
families, including impersonation, persuasion, privilege escalation, cognitive
overload, obfuscation, goal conflict, and data poisoning. Second, we analyzed
the data collected from the challenge to examine the prevalence and success
rates of different attack types, providing insights into how specific jailbreak
strategies exploit model vulnerabilities and induce misalignment. Third, we
benchmark a popular LLM for jailbreak detection, evaluating the benefits of
taxonomy-guided prompting for improving automatic detection. Finally, we
compiled a new Italian dataset of 1364 multi-turn adversarial dialogues,
annotated with our taxonomy, enabling the study of interactions where
adversarial intent emerges gradually and succeeds in bypassing traditional
safeguards.

</details>


### [138] [Attribution Quality in AI-Generated Content:Benchmarking Style Embeddings and LLM Judges](https://arxiv.org/abs/2510.13898)
*Misam Abbas*

Main category: cs.CL

TL;DR: 本文比较了两种AI文本归属方法（固定风格嵌入与指令微调大模型判别器），发现不同方法在不同类型文本中的表现互补，提出用混合策略解决作者归属问题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）生成文本的质量逐渐接近人类写作，准确区分人类与AI写作的归属变得更具挑战性。本文动机是评估和比较当前主流的作者归属方法在多领域、多模型下的有效性。

Method: 作者在公开的人类AI平行语料库上，实验对比了两类归属机制：1）固定风格嵌入技术；2）基于GPT-4o的指令微调判别器。实验覆盖六大文本领域，并针对GPT-4o和LLaMA-70B-Instruct生成的文本进行系统测试和性能统计分析。

Result: 风格嵌入方法在GPT生成文本的归属上整体表现更优（82%准确率），LLM判别器在LLaMA生成文本上略优（85%），但区别不显著。在叙事性强的领域（如小说和学术写作）LLM判别器优势显著，在对话性强的领域（如剧本和口语）风格嵌入表现更佳。

Conclusion: 文本归属是多维度问题，不同方法各有所长，需要混合策略应对。作者公开了代码和数据，便于后续可复现性研究，为AI内容归属质量提供了新基准和文献综述。

Abstract: Attributing authorship in the era of large language models (LLMs) is
increasingly challenging as machine-generated prose rivals human writing. We
benchmark two complementary attribution mechanisms , fixed Style Embeddings and
an instruction-tuned LLM judge (GPT-4o) on the Human AI Parallel Corpus, an
open dataset of 600 balanced instances spanning six domains (academic, news,
fiction, blogs, spoken transcripts, and TV/movie scripts). Each instance
contains a human prompt with both a gold continuation and an LLM-generated
continuation from either GPT-4o or LLaMA-70B-Instruct. The Style Embedding
baseline achieves stronger aggregate accuracy on GPT continuations (82 pct vs.
68 pct). The LLM Judge is slightly better than the Style embeddings on LLaMA
continuations (85 pct vs. 81 pct) but the results are not statistically
significant. Crucially, the LLM judge significantly outperforms in fiction and
academic prose, indicating semantic sensitivity, whereas embeddings dominate in
spoken and scripted dialogue, reflecting structural strengths. These
complementary patterns highlight attribution as a multidimensional problem
requiring hybrid strategies. To support reproducibility we provide code on
GitHub and derived data on Hugging Face under the MIT license. This open
framework provides a reproducible benchmark for attribution quality assessment
in AI-generated content, along with a review of related literature influencing
this work.

</details>


### [139] [Narrow Finetuning Leaves Clearly Readable Traces in Activation Differences](https://arxiv.org/abs/2510.13900)
*Julian Minder,Clément Dumas,Stewart Slocum,Helena Casademunt,Cameron Holmes,Robert West,Neel Nanda*

Main category: cs.CL

TL;DR: 本文探讨了对大型语言模型（LLM）进行狭域微调时，模型内部会形成可识别的激活偏差，这些偏差可用简单的模型差分方法检测，对理解微调领域和任务很有帮助。并且，该偏差可被利用于模型可解释性分析，但也提醒这种微调的研究意义和代表性有限。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在实际应用中的不断扩展，将通用模型微调到某一特定领域变得非常重要。然而，针对此类“狭域微调”引入的偏差、潜在风险及可解释性，目前研究较少且理解有限。

Method: 作者将模型微调前后进行差分，分析模型激活在狭域微调后表现出的偏差，并通过在不同架构和规模的模型（如Gemma、LLaMA、Qwen）上进行实验。还利用基于LLM的可解释性代理，比较其与传统提示方法在理解微调领域上的效果。

Result: 作者发现，狭域微调会造成模型激活中明显的、与微调领域相关的偏差，这些痕迹可用于理解和重建微调数据。同时，合入部分预训练数据可降低这些偏差，但无法完全消除。新方法远优于基线方法。

Conclusion: 狭域微调模型会携带强烈的训练目标痕迹，影响安全性和可解释性研究。需要更严谨地评估此类模型的代表性，并开发更真实的案例和分析工具，以推动LLM安全与可解释性研究。

Abstract: Finetuning on narrow domains has become an essential tool to adapt Large
Language Models (LLMs) to specific tasks and to create models with known
unusual properties that are useful for research. We show that narrow finetuning
creates strong biases in LLM activations that can be interpreted to understand
the finetuning domain. These biases can be discovered using simple tools from
model diffing - the study of differences between models before and after
finetuning. In particular, analyzing activation differences on the first few
tokens of random text and steering by adding this difference to the model
activations produces text similar to the format and general content of the
finetuning data. We demonstrate that these analyses contain crucial information
by creating an LLM-based interpretability agent to understand the finetuning
domain. With access to the bias, the agent performs significantly better
compared to baseline agents using simple prompting. Our analysis spans
synthetic document finetuning for false facts, emergent misalignment,
subliminal learning, and taboo word guessing game models across different
architectures (Gemma, LLaMA, Qwen) and scales (1B to 32B parameters). We
suspect these biases reflect overfitting and find that mixing pretraining data
into the finetuning corpus largely removes them, though residual risks may
remain. Our work (1) demonstrates that narrowly finetuned models have salient
traces of their training objective in their activations and suggests ways to
improve how they are trained, (2) warns AI safety and interpretability
researchers that the common practice of using such models as a proxy for
studying broader finetuning (e.g., chat-tuning) might not be realistic, and (3)
highlights the need for deeper investigation into the effects of narrow
finetuning and development of truly realistic case studies for model-diffing,
safety and interpretability research.

</details>


### [140] [RAID: Refusal-Aware and Integrated Decoding for Jailbreaking LLMs](https://arxiv.org/abs/2510.13901)
*Tuan T. Nguyen,John Le,Thai T. Vu,Willy Susilo,Heath Cooper*

Main category: cs.CL

TL;DR: RAID提出了一种新型攻破大语言模型安全机制的方法，通过优化嵌入空间的对抗后缀，实现更高效的越狱攻击。


<details>
  <summary>Details</summary>
Motivation: 大语言模型表现优异但存在越狱攻击隐患，现有防护和攻击技术存在效率和效果的局限性，亟需创新的攻防思路。

Method: 作者提出RAID框架，将数据库中的离散攻击后缀放宽到连续嵌入空间，通过联合优化实现：（1）诱导受限（敏感）回复；（2）增加拒绝感知正则，从嵌入上避免拒绝激活；（3）提升语义连贯和简洁性。最终通过一个受批评者引导的解码，平衡嵌入相似度和生成概率，生成自然且有效的攻击后缀。

Result: RAID在多个开源大语言模型上实验，超过当前白盒与黑盒攻击基线，以更高攻击成功率、较少查询数和低计算成本优越表现。

Conclusion: 结果突显了嵌入空间正则化在理解和减缓LLM越狱漏洞方面的重要性，对今后的LLM安全机制有启发意义。

Abstract: Large language models (LLMs) achieve impressive performance across diverse
tasks yet remain vulnerable to jailbreak attacks that bypass safety mechanisms.
We present RAID (Refusal-Aware and Integrated Decoding), a framework that
systematically probes these weaknesses by crafting adversarial suffixes that
induce restricted content while preserving fluency. RAID relaxes discrete
tokens into continuous embeddings and optimizes them with a joint objective
that (i) encourages restricted responses, (ii) incorporates a refusal-aware
regularizer to steer activations away from refusal directions in embedding
space, and (iii) applies a coherence term to maintain semantic plausibility and
non-redundancy. After optimization, a critic-guided decoding procedure maps
embeddings back to tokens by balancing embedding affinity with language-model
likelihood. This integration yields suffixes that are both effective in
bypassing defenses and natural in form. Experiments on multiple open-source
LLMs show that RAID achieves higher attack success rates with fewer queries and
lower computational cost than recent white-box and black-box baselines. These
findings highlight the importance of embedding-space regularization for
understanding and mitigating LLM jailbreak vulnerabilities.

</details>


### [141] [Investigating Political and Demographic Associations in Large Language Models Through Moral Foundations Theory](https://arxiv.org/abs/2510.13902)
*Nicole Smith-Vaniz,Harper Lyon,Lorraine Steigner,Ben Armstrong,Nicholas Mattei*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLM）在涉及政治和道德议题时的回答有无偏见，并通过道德基础理论（MFT）对其进行测量和对比分析。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在医疗、关系建议、法律等领域的广泛应用，其在具有争议和价值判断问题上的潜在偏见问题变得关键。以往虽有相关研究探讨LLM在角色扮演下的立场表现，但缺乏与人类真实数据的直接对比和道德倾向上的深度分析。

Method: 作者基于道德基础理论，系统比较了LLM在不同角色（如直接回答、模拟政治立场、基于人口属性角色扮演）下的道德判断，并与现有的人类数据进行对比，考察其回答倾向与政治及人口属性的关联。

Result: 研究表明，LLM在特定条件下会表现出与某些政治意识形态更加一致的道德基础分布，同时在角色扮演时，LLM能够较好模拟不同意识形态的回应。

Conclusion: LLM的道德和政治倾向具有一定可测性，并且受提示方式和角色设定影响。研究有助于理解和警觉AI工具输出中的政治和人口属性依赖性。

Abstract: Large Language Models (LLMs) have become increasingly incorporated into
everyday life for many internet users, taking on significant roles as advice
givers in the domains of medicine, personal relationships, and even legal
matters. The importance of these roles raise questions about how and what
responses LLMs make in difficult political and moral domains, especially
questions about possible biases. To quantify the nature of potential biases in
LLMs, various works have applied Moral Foundations Theory (MFT), a framework
that categorizes human moral reasoning into five dimensions: Harm, Fairness,
Ingroup Loyalty, Authority, and Purity. Previous research has used the MFT to
measure differences in human participants along political, national, and
cultural lines. While there has been some analysis of the responses of LLM with
respect to political stance in role-playing scenarios, no work so far has
directly assessed the moral leanings in the LLM responses, nor have they
connected LLM outputs with robust human data. In this paper we analyze the
distinctions between LLM MFT responses and existing human research directly,
investigating whether commonly available LLM responses demonstrate ideological
leanings: either through their inherent responses, straightforward
representations of political ideologies, or when responding from the
perspectives of constructed human personas. We assess whether LLMs inherently
generate responses that align more closely with one political ideology over
another, and additionally examine how accurately LLMs can represent ideological
perspectives through both explicit prompting and demographic-based
role-playing. By systematically analyzing LLM behavior across these conditions
and experiments, our study provides insight into the extent of political and
demographic dependency in AI-generated responses.

</details>


### [142] [Schema for In-Context Learning](https://arxiv.org/abs/2510.13905)
*Pan Chen,Shaohong Chen,Mark Wang,Shi Xuan Leong,Priscilla Fung,Varinia Bernales,Alan Aspuru-Guzik*

Main category: cs.CL

TL;DR: 作者提出了一种受认知科学启发的新型in-context learning方法SA-ICL，并实验证明能显著提升大模型在科学推理任务的表现，尤其是在高质量示例条件下。


<details>
  <summary>Details</summary>
Motivation: 传统的in-context learning（ICL）主要依赖示例来指导模型，但缺乏结构化知识检索和抽象迁移机制，这限制了推理能力与可解释性。作者受到人类认知中的'图式理论'（schema theory）启发，尝试将抽象化知识结构引入ICL。

Method: 提出schema activated in-context learning（SA-ICL），首先从示例中抽取推理必要的关键步骤及其关系，形成抽象化的'图式'模板，并在面对新问题时用该模板辅助大模型进行推理。作者在GPQA（包含化学、物理问题）数据集上进行了实证评测。

Result: 大量实验表明，大语言模型（LLMs）如果显式引入图式模板，其推理能力显著优于仅靠示例方式。在单个高质量示例时，SA-ICL最高提升可达36.19%，还减少对大量示例的依赖，并增强了推理过程的可解释性。

Conclusion: SA-ICL不仅提升了LLMs的推理和泛化能力，还将不同的ICL策略（如模式激活、chain-of-thought等）统一到同一框架下，为促进大模型向人类类推理方向发展提供了新思路。

Abstract: In-Context Learning (ICL) enables transformer-based language models to adapt
to new tasks by conditioning on demonstration examples. However, traditional
example-driven in-context learning lacks explicit modules for knowledge
retrieval and transfer at the abstraction level. Inspired by cognitive science,
specifically schema theory, which holds that humans interpret new information
by activating pre-existing mental frameworks (schemas) to structure
understanding, we introduce SCHEMA ACTIVATED IN CONTEXT LEARNING (SA-ICL). This
framework extracts the representation of the building blocks of cognition for
the reasoning process instilled from prior examples, creating an abstracted
schema, a lightweight, structured template of key inferential steps and their
relationships, which is then used to augment a model's reasoning process when
presented with a novel question. We demonstrate that a broad range of large
language models (LLMs) lack the capacity to form and utilize internal
schema-based learning representations implicitly, but instead benefit
significantly from explicit schema-based scaffolding. Across chemistry and
physics questions from the GPQA dataset, our experiments show that SA-ICL
consistently boosts performance, up to 36.19 percent, when the single
demonstration example is of high quality, which simultaneously reduces reliance
on the number of demonstrations and enhances interpretability. SCHEMA ACTIVATED
IN CONTEXT LEARNING not only bridges disparate ICL strategies ranging from
pattern priming to Chain-of-Thought prompting, but also paves a new path for
enhancing human-like reasoning in LLMs.

</details>


### [143] [LLM Prompt Duel Optimizer: Efficient Label-Free Prompt Optimization](https://arxiv.org/abs/2510.13907)
*Yuanchen Wu,Saurabh Verma,Justin Lee,Fangzhou Xiong,Poppy Zhang,Amel Awadelkarim,Xu Chen,Yubai Yuan,Shawndra Hill*

Main category: cs.CL

TL;DR: 本论文提出了一种无需标签的自动提示优化方法——Prompt Duel Optimizer（PDO），通过对提示进行成对偏好比较，有效提升了大语言模型的性能，无需昂贵的数据标注。


<details>
  <summary>Details</summary>
Motivation: 现有自动提示优化方法大多依赖标注数据，而高质量标注获取成本高且耗时，现实应用受限。因此，作者希望开发一种无需标签、样本高效的提示优化框架。

Method: 作者将提示优化问题建模为决策带的对决（dueling-bandit）问题，由大语言模型作为裁判，给出提示之间的成对偏好反馈。PDO结合了双托普森采样（D-TS）以高效选择比较对，并通过对高表现提示进行变异来扩展候选池。同时，能够兼容部分标签以缓解判别噪声。

Result: 在BIG-bench Hard (BBH) 和 MS MARCO数据集上的实验表明，PDO在没有真实标签的情况下性能优于多种基线方法。消融实验显示D-TS和提示变异策略都对提升效果有积极贡献。

Conclusion: PDO方法不仅实现了无标签下高效自动提示优化，还具备很好的泛化和灵活性，可广泛用于实际大语言模型提示设计相关场景。

Abstract: Large language models (LLMs) are highly sensitive to their input prompts,
making prompt design a central challenge. While automatic prompt optimization
(APO) reduces manual engineering, most approaches assume access to ground-truth
references such as labeled validation data. In practice, however, collecting
high-quality labels is costly and slow. We propose the Prompt Duel Optimizer
(PDO), a sample-efficient framework for label-free prompt optimization. PDO
formulates the problem as a dueling-bandit setting, where supervision signal
comes from pairwise preference feedback provided by an LLM judge. The framework
combines Double Thompson Sampling (D-TS), which prioritizes informative prompt
comparisons, with Top-Performer Guided Mutation, which expands the candidate
pool by mutating high-performing prompts. PDO naturally operates in label-free
settings and can also incorporate partial labels to mitigate judge noise.
Experiments on BIG-bench Hard (BBH) and MS MARCO show that PDO consistently
outperforms baseline methods. Ablation studies further demonstrate the
effectiveness of both D-TS and prompt mutation.

</details>


### [144] [Interpreting the Latent Structure of Operator Precedence in Language Models](https://arxiv.org/abs/2510.13908)
*Dharunish Yugeswardeenoo,Harshil Nukala,Cole Blondin,Sean O Brien,Vasu Sharma,Kevin Zhu*

Main category: cs.CL

TL;DR: 本论文研究了大语言模型（LLMs）在处理算术运算时，内部是否编码了运算符优先级及其表现形式。通过构造三操作数两运算符的表达式，并追踪中间结果，发现模型内部确实表征了运算优先级，并提出了新的解释性和干预方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在推理任务中表现出色，但在算术运算方面仍存在困难。此前研究多集中在模型输出或提示策略，鲜有关注模型内部是如何进行算术运算的。因此，作者希望探索LLMs内部是否隐式编码了运算符优先级，理解其算术推理背后的机制。

Method: 作者以开源指令微调模型LLaMA 3.2-3B为对象，构建包含三操作数和两运算符、括号顺序不同的算术表达式数据集，观察和追踪模型处理算术表达式时，中间计算结果在残差流中的表现。采用了logit lens、线性分类探针和UMAP可视化等可解释性方法，并提出了部分嵌入交换（partial embedding swap）来干预运算优先级的表达方式。

Result: 1. LLaMA 3.2-3B内部残差流中确实存在与中间算术计算相关的表征，尤其在每个MLP块后表现明显。2. 在attention后，运算符的嵌入在某些维度上线性表征了优先级信息。3. 提出的部分嵌入交换技术可以通过操作嵌入的高影响维度，干预模型对运算符优先级的处理。

Conclusion: 大语言模型在算术表达式处理时，能够在线性层和残差流中编码运算符优先级，中间结果也有明确表征。这不仅加深了对模型算术推理机制的理解，也为后续模型解释性研究和算术能力提升方法提供了新思路。

Abstract: Large Language Models (LLMs) have demonstrated impressive reasoning
capabilities but continue to struggle with arithmetic tasks. Prior works
largely focus on outputs or prompting strategies, leaving the open question of
the internal structure through which models do arithmetic computation. In this
work, we investigate whether LLMs encode operator precedence in their internal
representations via the open-source instruction-tuned LLaMA 3.2-3B model. We
constructed a dataset of arithmetic expressions with three operands and two
operators, varying the order and placement of parentheses. Using this dataset,
we trace whether intermediate results appear in the residual stream of the
instruction-tuned LLaMA 3.2-3B model. We apply interpretability techniques such
as logit lens, linear classification probes, and UMAP geometric visualization.
Our results show that intermediate computations are present in the residual
stream, particularly after MLP blocks. We also find that the model linearly
encodes precedence in each operator's embeddings post attention layer. We
introduce partial embedding swap, a technique that modifies operator precedence
by exchanging high-impact embedding dimensions between operators.

</details>


### [145] [Knowledge Reasoning Language Model: Unifying Knowledge and Language for Inductive Knowledge Graph Reasoning](https://arxiv.org/abs/2510.13909)
*Xingrui Zhuo,Jiapu Wang,Gongqing Wu,Zhongyuan Wang,Jichen Zhang,Shirui Pan,Xindong Wu*

Main category: cs.CL

TL;DR: 本文提出了一种融合大型语言模型（LLM）与知识图谱（KG）上下文的新型归纳知识图谱推理方法KRLM，解决开放域KG中未知实体和关系带来的推理困难。KRLM创新地通过知识推理语言格式、动态知识记忆机制和结构感知预测，显著提升推理准确率和可信度。


<details>
  <summary>Details</summary>
Motivation: 知识图谱推理需要模型应对不确定的、开放域KG成分，现有利用KGFM和LLM方法虽有进展，但因KG上下文稀疏和LLM幻觉导致推理不准确且可信度不足，这是目前亟需解决的关键难题。

Method: 作者设计KRLM模型：1）提出知识推理语言（KRL）指令格式及分词器，对齐LLM知识和KG表征；2）引入KRL注意力层及动态知识记忆机制，协调LLM固有知识与KG额外信息；3）加上结构感知下一个实体预测器，限制推理结果于可信知识域内。

Result: 在25个实际归纳KGR数据集上的实验证明，KRLM在零样本推理和微调场景下均显著优于现有方法。

Conclusion: KRLM能有效融合LLM与KG上下文，显著提升开放域知识图谱归纳推理的表现和可靠性，有助于解决现有模型在不确定KG环境中的推理可信与准确问题。

Abstract: Inductive Knowledge Graph Reasoning (KGR) aims to discover facts in
open-domain KGs containing unknown entities and relations, which poses a
challenge for KGR models in comprehending uncertain KG components. Existing
studies have proposed Knowledge Graph Foundation Models (KGFMs) that learn
structural invariances across KGs to handle this uncertainty. Recently, Large
Language Models (LLMs) have demonstrated strong capabilities for open-domain
knowledge reasoning. As a result, the latest research has focused on LLM-based
KGFMs that integrate LLM knowledge with KG context for inductive KGR. However,
the intrinsic knowledge of LLMs may be overshadowed by sparse KG context,
leading to LLM knowledge distortion, which can cause irreversible damage to
model reasoning. Moreover, existing LLM-based KGR methods still struggle to
fully constrain generative hallucinations in LLMs, severely limiting the
credibility of reasoning results. To address these limitations, we propose a
Knowledge Reasoning Language Model (KRLM) that achieves unified coordination
between LLM knowledge and KG context throughout the KGR process. Specifically,
we design a Knowledge Reasoning Language (KRL) instruction format and a KRL
tokenizer to align LLM knowledge with KG representations. Then, we propose a
KRL attention layer that coordinates intrinsic LLM knowledge with additional KG
context through a dynamic knowledge memory mechanism. Finally, a
structure-aware next-entity predictor is proposed, which strictly constrains
the reasoning results within a trustworthy knowledge domain. Extensive
experimental results on 25 real-world inductive KGR datasets demonstrate the
significant superiority of the proposed KRLM\footnote{Our source codes are
available at https://anonymous.4open.science/r/KRLM-EA36 in both zero-shot
reasoning and fine-tuning scenarios.

</details>


### [146] [RAGCap-Bench: Benchmarking Capabilities of LLMs in Agentic Retrieval Augmented Generation Systems](https://arxiv.org/abs/2510.13910)
*Jingru Lin,Chen Zhang,Stephen Y. Liu,Haizhou Li*

Main category: cs.CL

TL;DR: 本文提出了RAGCap-Bench，一种针对Agentic RAG系统中中间任务能力进行细粒度评估的新基准，旨在推动RAG系统在复杂问题推理上的发展。


<details>
  <summary>Details</summary>
Motivation: RAG系统虽然能缓解LLM的事实错误和幻觉等问题，但在多跳问题和中间推理能力方面仍存在不足，缺乏相关细致的评估工具。

Method: 作者对现有先进Agentic RAG系统的输出进行分析，梳理出常见任务和所需核心能力，并据此构建了一个LLM常见错误的分类法，从而设计出有针对性的评测题目，形成了RAGCap-Bench基准。

Result: 实验表明，在RAGCap基准上表现优异的那些“慢思考”模型，其端到端任务的表现也更好，说明加强中间能力对于RAG系统整体效能至关重要。

Conclusion: RAGCap-Bench能够有效衡量和促进Agentic RAG系统中间推理任务的能力提升，并指出未来应围绕中间推理能力进行模型优化。

Abstract: Retrieval-Augmented Generation (RAG) mitigates key limitations of Large
Language Models (LLMs)-such as factual errors, outdated knowledge, and
hallucinations-by dynamically retrieving external information. Recent work
extends this paradigm through agentic RAG systems, where LLMs act as agents to
iteratively plan, retrieve, and reason over complex queries. However, these
systems still struggle with challenging multi-hop questions, and their
intermediate reasoning capabilities remain underexplored. To address this, we
propose RAGCap-Bench, a capability-oriented benchmark for fine-grained
evaluation of intermediate tasks in agentic RAG workflows. We analyze outputs
from state-of-the-art systems to identify common tasks and the core
capabilities required for their execution, then construct a taxonomy of typical
LLM errors to design targeted evaluation questions. Experiments show that
"slow-thinking" models with stronger RAGCap performance achieve better
end-to-end results, underscoring the benchmark's validity and the importance of
enhancing these intermediate capabilities.

</details>


### [147] [AI Debaters are More Persuasive when Arguing in Alignment with Their Own Beliefs](https://arxiv.org/abs/2510.13912)
*María Victoria Carro,Denise Alejandra Mester,Facundo Nieto,Oscar Agustín Stanchi,Guido Ernesto Bergman,Mario Alejandro Leiva,Eitan Sprejer,Luca Nicolás Forziati Gangi,Francisca Gauna Selasco,Juan Gustavo Corvalán,Gerardo I. Simari,María Vanina Martinez*

Main category: cs.CL

TL;DR: 本文探讨了AI辩论作为可扩展监督技术时，在主观问题上的表现，发现大模型更倾向于迎合评审而非坚持自身先验信念，提出了辩论协议设计中的偏置并讨论了说服力与观点一致性之间的复杂关系。


<details>
  <summary>Details</summary>
Motivation: 现有AI辩论实验主要侧重于有客观标准的数据集，忽略了“说谎”还涉及主观信念。本文旨在考察大语言模型在主观问题上的辩论表现，尤其是当观点与评审偏好不一致时，模型会采取何种策略。

Method: 作者提出了在辩论开始前显式测量模型先验信念的方法，并让模型面对与自身信念相悖的‘裁判人设’。对比顺序和同时两种辩论协议，分析其系统性偏置。同时考察模型在维护自身信念阵营时与反对自身信念时的说服力和论据质量。

Result: 结果显示，大语言模型倾向于偏向评审的观点而非自己原本的信念；顺序辩论模式对第二辩手有明显偏置；模型在辩护自身观点时更有说服力，但反而在持反方向时能产出更高质量的论据。

Conclusion: 研究揭示了主观判断环境下AI辩论的说服与信念复杂性，对人类评审如何为训练提供高质量信号和提升AI对齐有指导意义，也暴露了人机交互中“迎合倾向”及辩论协议设计值得关注的问题。

Abstract: The core premise of AI debate as a scalable oversight technique is that it is
harder to lie convincingly than to refute a lie, enabling the judge to identify
the correct position. Yet, existing debate experiments have relied on datasets
with ground truth, where lying is reduced to defending an incorrect
proposition. This overlooks a subjective dimension: lying also requires the
belief that the claim defended is false. In this work, we apply debate to
subjective questions and explicitly measure large language models' prior
beliefs before experiments. Debaters were asked to select their preferred
position, then presented with a judge persona deliberately designed to conflict
with their identified priors. This setup tested whether models would adopt
sycophantic strategies, aligning with the judge's presumed perspective to
maximize persuasiveness, or remain faithful to their prior beliefs. We
implemented and compared two debate protocols, sequential and simultaneous, to
evaluate potential systematic biases. Finally, we assessed whether models were
more persuasive and produced higher-quality arguments when defending positions
consistent with their prior beliefs versus when arguing against them. Our main
findings show that models tend to prefer defending stances aligned with the
judge persona rather than their prior beliefs, sequential debate introduces
significant bias favoring the second debater, models are more persuasive when
defending positions aligned with their prior beliefs, and paradoxically,
arguments misaligned with prior beliefs are rated as higher quality in pairwise
comparison. These results can inform human judges to provide higher-quality
training signals and contribute to more aligned AI systems, while revealing
important aspects of human-AI interaction regarding persuasion dynamics in
language models.

</details>


### [148] [Synthesizing Agentic Data for Web Agents with Progressive Difficulty Enhancement Mechanisms](https://arxiv.org/abs/2510.13913)
*Shrey Pandit,Xuan-Phi Nguyen,Yifei Ming,Austin Xu,Jiayu Wang,Caiming Xiong,Shafiq Joty*

Main category: cs.CL

TL;DR: 本文提出了一种创新的数据合成管道，用于生成难度逐步提升的复杂网页问答数据，显著提升了面向Web复杂推理任务的智能体表现。


<details>
  <summary>Details</summary>
Motivation: 当前Web智能体在应对复杂的、需要长推理链条的问答任务时表现有限，主要因为其训练数据缺乏系统性难度控制与高质量，且训练过程中数据与优化方式混淆，难以分析数据本身影响。

Method: 作者提出一种双重数据合成流程：通过让基线智能体尝试、验证、筛选和提升任务难度，动态生成涵盖多样操作且逐步加难的问答数据；并采用统一蒸馏策略，在控制变量的前提下比较不同数据集成效。

Result: 在多项Web问答基准任务上，经新数据训练的智能体性能超越以往数据集，且模型工具调用操作多样性提高一倍，有效减少了重复和模式化行为。

Conclusion: 新提出的数据合成方法可生成更加多样、高质量、适应长程推理的数据集，为复杂Web智能体提升能力提供了有效解决方案。

Abstract: Web-based 'deep research' agents aim to solve complex question - answering
tasks through long-horizon interactions with online tools. These tasks remain
challenging, as the underlying language models are often not optimized for
long-horizon reasoning and exploration. Prior work has proposed workflows for
constructing instruction-tuning datasets, often leveraging knowledge graphs.
However, such methods typically lack fine-grained control over difficulty and
quality, yielding synthetic data that falls short of capturing the complexity
required for long-horizon reasoning. Furthermore, many studies conflate data
and training effects by comparing models trained under different optimization
recipes, making it difficult to isolate and evaluate the effectiveness of the
data itself. We introduce a two-pronged data synthesis pipeline that generates
question - answer pairs by progressively increasing task complexity until a
frontier baseline web agent fails. The baseline agent plays multiple roles in
this process: attempting the questions, validating factuality, checking for
alternative answers, and enforcing filtering. To evaluate the effectiveness of
our synthesis methods, we adopt a controlled training setup based on
distillation from strong web agents. Experiments across multiple web-based
benchmarks show that our dataset - despite being smaller - enables the training
of more effective web agents than existing datasets. In particular, our data
exhibits twice the diversity in tool-use actions, allowing models trained on it
to achieve stronger performance while avoiding repetitive tool-calling
behaviors.

</details>


### [149] [Readability $\ne$ Learnability: Rethinking the Role of Simplicity in Training Small Language Models](https://arxiv.org/abs/2510.13915)
*Ivan Lee,Taylor Berg-Kirkpatrick*

Main category: cs.CL

TL;DR: 作者发现小型语言模型（SLMs）能否生成连贯文本，并不单单依赖于可读性（易懂词汇、结构等）。通过对比不同可读性但结构相近的数据后，发现统计简单性（如n-gram多样性）才是更重要的预测因素，且复杂文本训练的模型效果不差甚至更好。


<details>
  <summary>Details</summary>
Motivation: 最近研究认为简单、易读的数据对SLM能力至关重要，但缺乏直接实证。作者希望实证检验可读性在SLM可学习性与能力涌现中的真实作用。

Method: 作者构造了结构相同但可读性不同的合成语料，对比SLM在这些语料上的表现，并分析统计简单性（n-gram多样性）与模型学习效果的关系。

Result: 模型用复杂、成人级文本训练时，学习速度和文本连贯性与用简化文本相当甚至更好。可读性无法单独预测SLM表现，而统计简单性能更好预测可学习性。

Conclusion: 简单可读性≠更易学。对SLM的训练与人类语言发展类比应谨慎，应关注统计属性等更本质因素。

Abstract: Recent studies suggest that very small language models (SLMs) can generate
surprisingly coherent text when trained on simplified, child-directed corpora
such as TinyStories. These findings have been interpreted as evidence that
readability -- characterized by accessible vocabulary, familiar narrative
structure, and simple syntax -- plays a key role in enabling such capabilities
to emerge. In this paper, we challenge that interpretation. We construct
synthetic datasets with matched structure but varied readability, and find that
readability alone does not predict coherence or learning efficiency in SLMs.
Models trained on complex, adult-level text perform comparably to those trained
on simplified language, and even exhibit faster development of coherence during
training. Instead, we show that statistical simplicity, as measured by n-gram
diversity, is a stronger predictor of learnability. Our findings caution
against the growing trend of anthropomorphizing language model training --
drawing parallels to human cognitive development without empirical basis -- and
argue for more precise reasoning about what properties actually support
capability emergence in small models.

</details>


### [150] [Element2Vec: Build Chemical Element Representation from Text for Property Prediction](https://arxiv.org/abs/2510.13916)
*Yuanhao Li,Keyuan Lai,Tianqi Wang,Qihao Liu,Jiawei Ma,Yuan-Chao Hu*

Main category: cs.CL

TL;DR: 本文提出利用大型语言模型从维基百科等自然语言文本中提取化学元素表示，解决元素属性缺失和预测难题，旨在增强材料科学领域的AI辅助研究。


<details>
  <summary>Details</summary>
Motivation: 化学元素的属性数据对材料设计和制造至关重要，但直接测量困难，现有算法难以捕捉元素间复杂关系，AI工具如语言模型虽有潜力但存在幻觉和可解释性差等缺点。

Method: 作者提出Element2Vect方法，利用自然语言处理技术，从维基百科中解析元素信息，生成通用（Global）与属性特化（Local）向量，并针对此类极少量、稀疏属性数据情形，设计了基于自注意力机制的测试时训练方法以降低回归预测误差。

Result: 实验结果显示该方法能更有效预测化学元素属性，相比传统方法更好地利用稀缺数据并改善预测准确性，且能一定程度缓解AI模型的幻觉问题。

Conclusion: 本文的新方法不仅提升了元素属性预测性能，也证明了自然语言描述在科学研究中的价值，有望推动AI在材料科学和科学发现领域的应用和深入发展。

Abstract: Accurate property data for chemical elements is crucial for materials design
and manufacturing, but many of them are difficult to measure directly due to
equipment constraints. While traditional methods use the properties of other
elements or related properties for prediction via numerical analyses, they
often fail to model complex relationships. After all, not all characteristics
can be represented as scalars. Recent efforts have been made to explore
advanced AI tools such as language models for property estimation, but they
still suffer from hallucinations and a lack of interpretability. In this paper,
we investigate Element2Vecto effectively represent chemical elements from
natural languages to support research in the natural sciences. Given the text
parsed from Wikipedia pages, we use language models to generate both a single
general-purpose embedding (Global) and a set of attribute-highlighted vectors
(Local). Despite the complicated relationship across elements, the
computational challenges also exist because of 1) the discrepancy in text
distribution between common descriptions and specialized scientific texts, and
2) the extremely limited data, i.e., with only 118 known elements, data for
specific properties is often highly sparse and incomplete. Thus, we also design
a test-time training method based on self-attention to mitigate the prediction
error caused by Vanilla regression clearly. We hope this work could pave the
way for advancing AI-driven discovery in materials science.

</details>


### [151] [Optimal Aggregation of LLM and PRM Signals for Efficient Test-Time Scaling](https://arxiv.org/abs/2510.13918)
*Peng Kuang,Yanli Wang,Xiaoyu Han,Yaowenqi Liu,Kaidi Xu,Haohan Wang*

Main category: cs.CL

TL;DR: 本文提出在大语言模型(LLM)推理过程中，利用最优的加权聚合策略高效整合PRM（过程奖励模型）与LLM信号，在提升效果的同时显著降低算力成本。


<details>
  <summary>Details</summary>
Motivation: 当前常用的基于PRM的推理方案在部分基准测试中反而不如简单的多数投票，这引发了如何更有效利用PRM信号进行结果甄别的核心问题。

Method: 作者建立了一个理论框架，推导出最佳策略是对LLM和PRM输出进行加权聚合，并强调最优权重需根据LLM-PRM组合灵活变化。然后提出了一种高效的预计算方法用于校准这些加权函数。

Result: 大规模实验（5个LLM和7个PRM）表明，该加权校准方法在仅使用21.3%计算资源的前提下，显著优于普通加权多数投票和标准PRM选择。

Conclusion: 通过更智能的聚合策略，能更高效、更有效地发挥PRM作用，相较一味扩大推理规模更能带来实际性能提升。

Abstract: Process reward models (PRMs) are a cornerstone of test-time scaling (TTS),
designed to verify and select the best responses from large language models
(LLMs). However, this promise is challenged by recent benchmarks where simple
majority voting, which ignores PRM signals, occasionally outperforms standard
PRM-based selection. This raises a critical question: How can we effectively
utilize verification signals from PRMs for TTS? To address this, we start by
developing a theoretical framework for optimally combining signals from both
the LLM and the PRM. Our framework reveals that the optimal strategy is a
weighted aggregation of responses, a strategy whose effectiveness hinges on
estimating weights that capture the complex interplay between the models. Based
on our theoretical results, we empirically show that these optimal weighting
functions differ significantly across LLM-PRM pairs and, notably, often assign
substantial negative weights. Motivated by these insights, we propose efficient
pre-computation methods to calibrate these weighting functions. Extensive
experiments across 5 LLMs and 7 PRMs demonstrate that our calibration method
significantly boosts the TTS efficiency, surpassing the performance of vanilla
weighted majority voting while using only $21.3\%$ of the computation.
Ultimately, our work demonstrates that investing in a more intelligent
aggregation strategy can be a more convincing path to performance gains than
simply scaling test-time computation.

</details>


### [152] [FACTS: Table Summarization via Offline Template Generation with Agentic Workflows](https://arxiv.org/abs/2510.13920)
*Ye Yuan,Mohammad Amin Shabani,Siqi Liu*

Main category: cs.CL

TL;DR: 本文提出了一种名为FACTS的新方法，通过离线模板生成（结合SQL查询和Jinja2模板），高效、准确且保护隐私地实现面向查询的问题表格摘要。该方法在广泛的基准测试中超过了现有的基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的表格摘要方法存在诸多局限，如模型微调成本高、推理能力有限、大语言模型方案存在token限制和效率低下，以及隐私泄露等问题。为解决这些问题，需要一种兼顾效率、准确性和隐私保护的新方法。

Method: FACTS方法利用离线生成的SQL查询和Jinja2模板，将表格摘要流程分为模板生成和模板应用两步。首先，只向LLM发送表结构信息，生成可反复使用的模板；随后，通过执行SQL查询和Jinja2渲染，将结果转换为自然语言摘要，实现快速、准确和隐私合规的问答。

Result: 在多个主流基准数据集上的实验显示，FACTS方法在效率、准确性和隐私保护等方面，均优于已有的基线方法，实现了更好的表格摘要质量和实用性。

Conclusion: FACTS为面向查询的表格摘要任务提供了一种可扩展、实用且隐私友好的解决方案，有效克服了以往方法的局限，并在实际应用场景下表现出显著优势。

Abstract: Query-focused table summarization requires generating natural language
summaries of tabular data conditioned on a user query, enabling users to access
insights beyond fact retrieval. Existing approaches face key limitations:
table-to-text models require costly fine-tuning and struggle with complex
reasoning, prompt-based LLM methods suffer from token-limit and efficiency
issues while exposing sensitive data, and prior agentic pipelines often rely on
decomposition, planning, or manual templates that lack robustness and
scalability. To mitigate these issues, we introduce an agentic workflow, FACTS,
a Fast, Accurate, and Privacy-Compliant Table Summarization approach via
Offline Template Generation. FACTS produces offline templates, consisting of
SQL queries and Jinja2 templates, which can be rendered into natural language
summaries and are reusable across multiple tables sharing the same schema. It
enables fast summarization through reusable offline templates, accurate outputs
with executable SQL queries, and privacy compliance by sending only table
schemas to LLMs. Evaluations on widely-used benchmarks show that FACTS
consistently outperforms baseline methods, establishing it as a practical
solution for real-world query-focused table summarization.

</details>


### [153] [An LLM-Powered AI Agent Framework for Holistic IoT Traffic Interpretation](https://arxiv.org/abs/2510.13925)
*Daniel Adu Worae,Spyridon Mastorakis*

Main category: cs.CL

TL;DR: 本文提出了一种基于大语言模型（LLM）的AI代理框架，能够将IoT网络抓包数据转化为结构化、富有语义的信息，实现高效、全面的流量分析和解读。该框架集成了特征提取、变换器（transformer）异常检测、流量摘要、威胁情报丰富以及检索增强的问题回答。实验表明：混合检索方式（结合了词法与语义搜索并重新排序）在多个指标上优于仅用语义检索，并且资源消耗较低。


<details>
  <summary>Details</summary>
Motivation: 现有IoT流量分析往往仅进行孤立检测，无法实现对操作行为、协议和上下文的深入解释，限制了威胁识别和安全运维能力。亟需一种能够跨层次、结构化解释IoT流量的方法。

Method: 设计并实现一个结合大语言模型驱动的AI代理架构：先对原始抓包数据做特征提取和异常检测，随后对包和流量进行摘要与威胁情报的丰富，最后通过检索增强技术与LLM协作，实现面向问题的流量分析解读。采用混合检索技术，结合词法、语义搜索和rerank，提升回答准确性和解释能力。

Result: 在多组IoT流量数据与六个公开模型上测试，混合检索显著提升BLEU、ROUGE、METEOR及BERTScore等指标，解释效果优于传统密集检索。同时系统运行对CPU、GPU和内存的占用均较低，具备较好高效性。

Conclusion: 提出的方法实现了IoT流量的全面、结构化和高效分析，对于网络安全与流量可视化等应用具有实用价值。混合检索增强了解释能力且资源消耗较低，展现出良好的实际应用前景。

Abstract: Internet of Things (IoT) networks generate diverse and high-volume traffic
that reflects both normal activity and potential threats. Deriving meaningful
insight from such telemetry requires cross-layer interpretation of behaviors,
protocols, and context rather than isolated detection. This work presents an
LLM-powered AI agent framework that converts raw packet captures into
structured and semantically enriched representations for interactive analysis.
The framework integrates feature extraction, transformer-based anomaly
detection, packet and flow summarization, threat intelligence enrichment, and
retrieval-augmented question answering. An AI agent guided by a large language
model performs reasoning over the indexed traffic artifacts, assembling
evidence to produce accurate and human-readable interpretations. Experimental
evaluation on multiple IoT captures and six open models shows that hybrid
retrieval, which combines lexical and semantic search with reranking,
substantially improves BLEU, ROUGE, METEOR, and BERTScore results compared with
dense-only retrieval. System profiling further indicates low CPU, GPU, and
memory overhead, demonstrating that the framework achieves holistic and
efficient interpretation of IoT network traffic.

</details>


### [154] [BioMedSearch: A Multi-Source Biomedical Retrieval Framework Based on LLMs](https://arxiv.org/abs/2510.13926)
*Congying Liu,Xingyuan Wei,Peipei Liu,Yiqing Shen,Yanxu Mao,Tiehan Cui*

Main category: cs.CL

TL;DR: 本文提出了BioMedSearch框架，结合文献、蛋白质数据库和网页多源信息检索优化生物医学问答任务，显著提高了领域LLM的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型虽然在通用推理任务上表现良好，但在生物医学领域容易生成缺乏科学性的内容，如虚构蛋白功能、结构等，归因于无法访问权威数据库与信息孤岛问题。亟需改进方法以支持复杂、生物医学知识密集型的问答需求。

Method: 作者提出BioMedSearch，一个多源信息检索框架，结合文献检索、蛋白数据库和网页访问。其方法包括子问题分解、关键词提取、任务图构建和多源信息过滤，以生成高质量、严谨的问答内容。为评估表现，作者构建了涵盖三类推理难度的BioMedMCQs数据集，共3,000道题目，用以检验不同模型问答准确率。

Result: 实验结果显示，BioMedSearch在所有推理层级下均显著优于基线模型。具体准确率从第1层级59.1%提升至91.9%，第2层级从47.0%提升至81.0%，第3层级从36.3%提升至73.4%。

Conclusion: BioMedSearch有效集成多源权威信息，大幅提升生物医学复杂问答的准确率，为领域内LLM增强提供了新途径和性能基线。相关代码及数据集已开源。

Abstract: Biomedical queries often rely on a deep understanding of specialized
knowledge such as gene regulatory mechanisms and pathological processes of
diseases. They require detailed analysis of complex physiological processes and
effective integration of information from multiple data sources to support
accurate retrieval and reasoning. Although large language models (LLMs) perform
well in general reasoning tasks, their generated biomedical content often lacks
scientific rigor due to the inability to access authoritative biomedical
databases and frequently fabricates protein functions, interactions, and
structural details that deviate from authentic information. Therefore, we
present BioMedSearch, a multi-source biomedical information retrieval framework
based on LLMs. The method integrates literature retrieval, protein database and
web search access to support accurate and efficient handling of complex
biomedical queries. Through sub-queries decomposition, keywords extraction,
task graph construction, and multi-source information filtering, BioMedSearch
generates high-quality question-answering results. To evaluate the accuracy of
question answering, we constructed a multi-level dataset, BioMedMCQs,
consisting of 3,000 questions. The dataset covers three levels of reasoning:
mechanistic identification, non-adjacent semantic integration, and temporal
causal reasoning, and is used to assess the performance of BioMedSearch and
other methods on complex QA tasks. Experimental results demonstrate that
BioMedSearch consistently improves accuracy over all baseline models across all
levels. Specifically, at Level 1, the average accuracy increases from 59.1% to
91.9%; at Level 2, it rises from 47.0% to 81.0%; and at the most challenging
Level 3, the average accuracy improves from 36.3% to 73.4%. The code and
BioMedMCQs are available at: https://github.com/CyL-ucas/BioMed_Search

</details>


### [155] [LLMs Can Get "Brain Rot"!](https://arxiv.org/abs/2510.13928)
*Shuo Xing,Junyuan Hong,Yifan Wang,Runjin Chen,Zhenyu Zhang,Ananth Grama,Zhengzhong Tu,Zhangyang Wang*

Main category: cs.CL

TL;DR: 本文提出并验证了“LLM脑退化假说”：持续暴露于低质量网络文本会导致大语言模型（LLM）出现持久性认知能力下降。通过对比真实推特数据生成的“垃圾”与对照数据集，作者发现继续在低质量文本上训练LLM会造成其推理、长文本理解、安全性下降，并激增诸如反社会等“黑暗特质”。此外，“垃圾”文本比例越高，相应能力衰退越严重，表现为模型推理链条被截断或跳步，该损伤无法完全通过后续干净数据训练恢复。研究强调，数据质量直接影响LLM表现，建议将数据筛选看作训练阶段的安全问题，并对部署的模型应定期进行“认知健康检查”。


<details>
  <summary>Details</summary>
Motivation: 近年来，LLM被广泛用于各种任务，但其随时间能力衰退的现象鲜有研究。作者关注数据持续积累带来的潜在负面影响，尤其是低质量（如大量“水文”或垃圾）文本对模型能力的长期影响，而此前主流关注点多在模型结构或参数量优化。通过提出新的研究假说，作者希望探究数据质量对模型能力的直接、因果影响。

Method: 研究者在真实的推特/X数据集基础上，构造了依据互动度和语义质量的两套“垃圾”与对照数据集，并严格匹配数据规模与训练流程。用这两类数据分别对4个LLM做持续训练，通过标准测试集（如推理与理解题目）检测能力变化，分析不同垃圾占比下模型表现，并进一步通过误差归因、损伤可恢复性与数据统计特征分析，明确影响原因与机制。

Result: 1）持续喂入垃圾文本会导致LLM在推理、长文本理解、安全性等表现显著下降，“黑暗特质”激增；2）垃圾占比越高，能力下降越大，且主要表现为推理链条被截断或跳过；3）即便用高质量说明调优，其能力也难以完全恢复，暗示模型内存表示发生了持久性漂移；4）推文受欢迎度（非语义指标）比长度更相关于脑退化效应。

Conclusion: 本文首次系统性证实了低质量网络文本大规模增量训练会导致LLM能力和对话安全性的长期受损，且这一影响部分不可逆。提醒社区在持续训练时需严控数据质量，将之作为关键安全环节，并定期检测模型认知健康。

Abstract: We propose and test the LLM Brain Rot Hypothesis: continual exposure to junk
web text induces lasting cognitive decline in large language models (LLMs). To
causally isolate data quality, we run controlled experiments on real Twitter/X
corpora, constructing junk and reversely controlled datasets via two orthogonal
operationalizations: M1 (engagement degree) and M2 (semantic quality), with
matched token scale and training operations across conditions. Contrary to the
control group, continual pre-training of 4 LLMs on the junk dataset causes
non-trivial declines (Hedges' $g>0.3$) on reasoning, long-context
understanding, safety, and inflating "dark traits" (e.g., psychopathy,
narcissism). The gradual mixtures of junk and control datasets also yield
dose-response cognition decay: for example, under M1, ARC-Challenge with Chain
Of Thoughts drops $74.9 \rightarrow 57.2$ and RULER-CWE $84.4 \rightarrow 52.3$
as junk ratio rises from $0\%$ to $100\%$.
  Error forensics reveal several key insights. First, we identify
thought-skipping as the primary lesion: models increasingly truncate or skip
reasoning chains, explaining most of the error growth. Second, partial but
incomplete healing is observed: scaling instruction tuning and clean data
pre-training improve the declined cognition yet cannot restore baseline
capability, suggesting persistent representational drift rather than format
mismatch. Finally, we discover that the popularity, a non-semantic metric, of a
tweet is a better indicator of the Brain Rot effect than the length in M1.
Together, the results provide significant, multi-perspective evidence that data
quality is a causal driver of LLM capability decay, reframing curation for
continual pretraining as a \textit{training-time safety} problem and motivating
routine "cognitive health checks" for deployed LLMs.

</details>


### [156] [Robust or Suggestible? Exploring Non-Clinical Induction in LLM Drug-Safety Decisions](https://arxiv.org/abs/2510.13931)
*Siying Liu,Shisheng Zhang,Indu Bala*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型（LLMs）在药物安全性预测中的可靠性，发现其对社会人口学属性存在系统性偏见，影响不利群体。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在生物医学领域的应用日益广泛，其在药物安全性预测中的可靠性和公平性问题尚未被充分研究，尤其是在社会人口学信息是否会影响其预测结果方面。

Method: 作者利用美国FDA不良事件报告系统（FAERS）的结构化数据，构建基于人物设定的评估框架，考察了ChatGPT-4o和Bio-Medical-Llama-3.8B两款模型在不同社会设定（如教育、婚姻、就业、保险、语言、住房、宗教）和用户角色（全科医生、专家、患者）下的表现。分析了模型预测表现和偏差，并区分显性与隐性偏见。

Result: 结果显示：对于社会弱势群体（如低学历、住房不稳），模型更容易预测更高的不良事件发生概率。同时揭示了显性（模型在推理理由中直接引用人物属性）与隐性偏见（预测不一致但未直接提及属性）两种不同的偏差模式。

Conclusion: LLM在药物安全性预测中存在系统性偏见，尤其可能增加弱势群体的风险。这一发现强调在LLM临床应用前，迫切需要引入公平性评估和偏差缓解策略。

Abstract: Large language models (LLMs) are increasingly applied in biomedical domains,
yet their reliability in drug-safety prediction remains underexplored. In this
work, we investigate whether LLMs incorporate socio-demographic information
into adverse event (AE) predictions, despite such attributes being clinically
irrelevant. Using structured data from the United States Food and Drug
Administration Adverse Event Reporting System (FAERS) and a persona-based
evaluation framework, we assess two state-of-the-art models, ChatGPT-4o and
Bio-Medical-Llama-3.8B, across diverse personas defined by education, marital
status, employment, insurance, language, housing stability, and religion. We
further evaluate performance across three user roles (general practitioner,
specialist, patient) to reflect real-world deployment scenarios where
commercial systems often differentiate access by user type. Our results reveal
systematic disparities in AE prediction accuracy. Disadvantaged groups (e.g.,
low education, unstable housing) were frequently assigned higher predicted AE
likelihoods than more privileged groups (e.g., postgraduate-educated, privately
insured). Beyond outcome disparities, we identify two distinct modes of bias:
explicit bias, where incorrect predictions directly reference persona
attributes in reasoning traces, and implicit bias, where predictions are
inconsistent, yet personas are not explicitly mentioned. These findings expose
critical risks in applying LLMs to pharmacovigilance and highlight the urgent
need for fairness-aware evaluation protocols and mitigation strategies before
clinical deployment.

</details>


### [157] [Big Reasoning with Small Models: Instruction Retrieval at Inference Time](https://arxiv.org/abs/2510.13935)
*Kenan Alkiek,David Jurgens,Vinod Vydiswaran*

Main category: cs.CL

TL;DR: 本文提出了一种通过推理时指令干预的方法，以提升小语言模型（SLMs）在多步推理和领域知识相关任务上的表现。该方法通过检索结构化推理指令，而非文本段落，来对SLM进行推理指导。


<details>
  <summary>Details</summary>
Motivation: 小语言模型虽然能本地高效运行并具备隐私和环保优势，但推理能力有限，尤其在需要复杂推理或专业知识的任务中表现不佳；因此，急需新的提升办法。

Method: 作者首先将训练问题分组，利用GPT-5生成推理指令，构建指令语料库。推理时，SLM检索最相关指令并严格遵循指令步骤推理，而非自主生成。区别于传统检索增强生成（RAG）检索文本段落，本文方法检索的是结构化推理指令。

Result: 在MedQA、MMLU专业法律、MathQA等数据集和不同参数规模（3B-14B）的SLM未加额外微调下，指令检索方法相比原模型均有明显提升：MedQA提升9.4%，MMLU Law提升7.9%，MathQA提升5.1%。简明指令优于冗长指令，提升幅度受模型家族与固有推理能力影响较大。

Conclusion: 在无需微调小模型的前提下，基于结构化指令的推理干预可大幅提升推理任务能力，为小模型的大规模落地及领域应用提供了一条高效可行的新路径。

Abstract: Can we bring large-scale reasoning to local-scale compute? Small language
models (SLMs) are increasingly attractive because they run efficiently on local
hardware, offering strong privacy, low cost, and reduced environmental impact.
Yet they often struggle with tasks that require multi-step reasoning or
domain-specific knowledge. We address this limitation through instruction
intervention at inference time, where an SLM retrieves structured reasoning
procedures rather than generating them from scratch. Our method builds an
Instruction Corpus by grouping similar training questions and creating
instructions via GPT-5. During inference, the SLM retrieves the most relevant
instructions and follows their steps. Unlike retrieval-augmented generation,
which retrieves text passages, instruction retrieval gives the model structured
guidance for reasoning. We evaluate this framework on MedQA (medical board
exams), MMLU Professional Law, and MathQA using models from 3B to 14B
parameters without any additional fine-tuning. Instruction retrieval yields
consistent gains: 9.4% on MedQA, 7.9% on MMLU Law, and 5.1% on MathQA. Concise
instructions outperform longer ones, and the magnitude of improvement depends
strongly on model family and intrinsic reasoning ability.

</details>


### [158] [FinDeepResearch: Evaluating Deep Research Agents in Rigorous Financial Analysis](https://arxiv.org/abs/2510.13936)
*Fengbin Zhu,Xiang Yao Ng,Ziyang Liu,Chang Liu,Xianwei Zeng,Chao Wang,Tianhui Tan,Xuan Yao,Pengyang Shao,Min Xu,Zixuan Wang,Jing Wang,Xin Lin,Junfeng Li,Jingxian Zhu,Yang Zhang,Wenjie Wang,Fuli Feng,Richang Hong,Huanbo Luan,Ke-Wei Huang,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的层级化评价框架HisRubric，并基于此建立了跨多市场、多语言的金融DR Agent测评基准FinDeepResearch，系统评估了多种LLM与DR agent在复杂财务研究分析任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 虽然DR Agent在复杂研究任务中表现突出，但缺乏针对其在关键型研究分析（如公司财务分析）能力的系统性衡量方法，因此有必要建立科学的评价框架和基准，填补该领域研究空白。

Method: 作者提出了HisRubric评价框架，模仿专业分析师的分析流程，层次化地从数据识别、指标计算到总结解读；据此构建FinDeepResearch基准，包含64家企业、跨4种语言的15,808评测点。然后，作者用该基准评估了16种方法（6个DR agent、5个具备深度推理+检索能力的LLM、5个仅具深度推理能力的LLM）。

Result: 实验结果揭示了不同DR agent和LLM在能力表现、金融市场和语言等维度上的优劣势，为理解其适用性和发展方向提供了量化数据。

Conclusion: 构建了科学有效的DR agent评测体系与公开基准，有助于推动高阶AI分析工具在金融及多语言场景下的研究和应用。

Abstract: Deep Research (DR) agents, powered by advanced Large Language Models (LLMs),
have recently garnered increasing attention for their capability in conducting
complex research tasks. However, existing literature lacks a rigorous and
systematic evaluation of DR Agent's capabilities in critical research analysis.
To address this gap, we first propose HisRubric, a novel evaluation framework
with a hierarchical analytical structure and a fine-grained grading rubric for
rigorously assessing DR agents' capabilities in corporate financial analysis.
This framework mirrors the professional analyst's workflow, progressing from
data recognition to metric calculation, and finally to strategic summarization
and interpretation. Built on this framework, we construct a FinDeepResearch
benchmark that comprises 64 listed companies from 8 financial markets across 4
languages, encompassing a total of 15,808 grading items. We further conduct
extensive experiments on the FinDeepResearch using 16 representative methods,
including 6 DR agents, 5 LLMs equipped with both deep reasoning and search
capabilities, and 5 LLMs with deep reasoning capabilities only. The results
reveal the strengths and limitations of these approaches across diverse
capabilities, financial markets, and languages, offering valuable insights for
future research and development. The benchmark and evaluation code will be made
publicly available.

</details>


### [159] [Readers Prefer Outputs of AI Trained on Copyrighted Books over Expert Human Writers](https://arxiv.org/abs/2510.13939)
*Tuhin Chakrabarty,Jane C. Ginsburg,Paramveer Dhillon*

Main category: cs.CL

TL;DR: 本论文研究了AI通过不同训练方式再现知名作家文体的能力，发现只要进行针对性微调，AI输出的文本风格和质量甚至超过专家作家，且难以被检测出是AI生成，对版权和市场价值有重大影响。


<details>
  <summary>Details</summary>
Motivation: 近期AI在训练时大量使用受版权保护的书籍，引发作家诉讼，核心争议是AI能否生成高质量、风格真切的文学作品。本文旨在实证评估，AI在再现名家文风时与专业作家相比的能力如何，并探讨其对著作权市场影响。

Method: 作者让三大前沿AI模型（ChatGPT、Claude、Gemini）和MFA训练的专家作家，各自模仿50位获奖作家风格创作450字片段。由159名专家与普通读者进行盲评，比较风格还原度和文本质量。又对ChatGPT做了每位作者全集的微调，再次盲评，并用AI检测器判断文本源头。还分析了消除AI“风格缺陷”的中介因素及微调成本。

Result: 初步采用提示工程时，专家明显更不喜欢AI产出，认为风格和质量都远逊于专家作家，但普通读者评价不一。对ChatGPT进行作者全集微调后，专家和普通读者反而更青睐AI产出，且风格还原度和质量均提升，大大减少被识别为AI生成文本的概率（降至3%）。成本方面，微调每位作家只需约81美元，远低于专业写手薪酬。

Conclusion: 作者特定微调能让AI生成的非逐字稿超越人类专家文本，被读者广泛偏好，对版权法“市场影响”要素具有重要实证意义，暗示AI可能对作家市场形成极大冲击。

Abstract: The use of copyrighted books for training AI models has led to numerous
lawsuits from authors concerned about AI's ability to generate derivative
content.Yet it's unclear whether these models can generate high quality
literary text while emulating authors' styles. To answer this we conducted a
preregistered study comparing MFA-trained expert writers with three frontier AI
models: ChatGPT, Claude & Gemini in writing up to 450 word excerpts emulating
50 award-winning authors' diverse styles. In blind pairwise evaluations by 159
representative expert & lay readers, AI-generated text from in-context
prompting was strongly disfavored by experts for both stylistic fidelity
(OR=0.16, p<10^8) & writing quality (OR=0.13, p<10^7) but showed mixed results
with lay readers. However, fine-tuning ChatGPT on individual authors' complete
works completely reversed these findings: experts now favored AI-generated text
for stylistic fidelity (OR=8.16, p<10^13) & writing quality (OR=1.87, p=0.010),
with lay readers showing similar shifts. These effects generalize across
authors & styles. The fine-tuned outputs were rarely flagged as AI-generated
(3% rate v. 97% for in-context prompting) by best AI detectors. Mediation
analysis shows this reversal occurs because fine-tuning eliminates detectable
AI stylistic quirks (e.g., cliche density) that penalize in-context outputs.
While we do not account for additional costs of human effort required to
transform raw AI output into cohesive, publishable prose, the median
fine-tuning & inference cost of $81 per author represents a dramatic 99.7%
reduction compared to typical professional writer compensation. Author-specific
fine-tuning thus enables non-verbatim AI writing that readers prefer to expert
human writing, providing empirical evidence directly relevant to copyright's
fourth fair-use factor, the "effect upon the potential market or value" of the
source works.

</details>


### [160] [Less is More: Improving LLM Reasoning with Minimal Test-Time Intervention](https://arxiv.org/abs/2510.13940)
*Zhen Yang,Mingyang Zhang,Feng Chen,Ganggui Ding,Liang Hou,Xin Tao,Pengfei Wan,Ying-Cong Chen*

Main category: cs.CL

TL;DR: 论文提出MTI框架，通过在不确定性较高的位置进行极小的推理干预，从而在不影响效率的前提下，有效提升LLM的推理准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 大模型在推理时常通过增加计算量提升准确率，但效率代价较高。作者发现推理不确定性仅集中在少数高熵token，因此可以有针对性地优化，而无需整体加重计算负担。

Method: 提出Minimal Test-Time Intervention (MTI)方法，包括：1）选择性CFG干预，仅在不确定token处用classifier-free guidance方法调整；2）轻量级负提示指导，利用主模型的KV cache高效近似无条件解码。该方法无需额外训练。

Result: 在常规、编程和STEM等多类任务上，MTI框架均带来显著性能提升。例如，Qwen3-8B-Base在八个基准上平均提升1.35%，Qwen3-32B-Reasoning在AIME2024上提升5%。运行开销极小，效率很高。

Conclusion: MTI不增加训练负担，以最小推理干预提升LLM各类任务的推理能力，在保持高效率的同时，系统性增强了大模型的实际应用价值。

Abstract: Recent progress in large language models (LLMs) has focused on test-time
scaling to improve reasoning via increased inference computation, but often at
the cost of efficiency. We revisit test-time behavior and uncover a simple yet
underexplored phenomenon: reasoning uncertainty is highly localized-only a
small subset of high-entropy tokens dominantly affects output correctness.
Motivated by this, we propose Minimal Test-Time Intervention (MTI), a
training-free framework that enhances reasoning accuracy and stability with
minimal overhead. MTI includes: (i) Selective CFG intervention, applying
classifier-free guidance only at uncertain positions; and (ii) Lightweight
negative-prompt guidance, reusing the main model's KV cache to approximate
unconditional decoding efficiently. MTI yields consistent gains across general,
coding, and STEM tasks-e.g., +1.35% average improvement on eight benchmarks for
Qwen3-8B-Base and +5% on AIME2024 using Qwen3-32B-Reasoning-while remaining
highly efficient.

</details>


### [161] [Classifying and Addressing the Diversity of Errors in Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2510.13975)
*Kin Kwan Leung,Mouloud Belbahri,Yi Sui,Alex Labach,Xueying Zhang,Stephen Rose,Jesse C. Cresswell*

Main category: cs.CL

TL;DR: 本文针对基于检索增强生成（RAG）的LLM问答系统中输出错误的问题，提出了新的错误类型分类法，并构建了相应的数据集和自动评估方法，用于实际开发中的错误追踪与改进。


<details>
  <summary>Details</summary>
Motivation: RAG系统在实际应用中因其复杂性，容易产生多种错误输出。缺乏对这些错误的系统性分类与分析，给系统稳定性和可靠性带来挑战。因此，理解和应对错误种类对于RAG系统的稳健部署至关重要。

Method: 作者提出了一套适用于现实RAG系统的错误类型新分类法，并为每种类型都举例说明。同时，手工整理并标注了不同错误类型的错误响应数据集，并基于此提出了一种和该分类法对齐的自动评估方法，用于开发过程中的错误追踪和修正。

Result: 论文建立了一个涵盖多种RAG系统错误类型的详细分类体系，收集并公开了标注好的错误数据集，提出的自动评估方法能够有效识别和追踪各类错误。

Conclusion: 作者的工作为RAG问答系统的输出错误提供了系统性分析工具，方便开发者理解和改进系统错误，促进RAG系统更稳健、更可靠地部署到实际应用场景中。

Abstract: Retrieval-augmented generation (RAG) is a prevalent approach for building
LLM-based question-answering systems that can take advantage of external
knowledge databases. Due to the complexity of real-world RAG systems, there are
many potential causes for erroneous outputs. Understanding the range of errors
that can occur in practice is crucial for robust deployment. We present a new
taxonomy of the error types that can occur in realistic RAG systems, examples
of each, and practical advice for addressing them. Additionally, we curate a
dataset of erroneous RAG responses annotated by error types. We then propose an
auto-evaluation method aligned with our taxonomy that can be used in practice
to track and address errors during development. Code and data are available at
https://github.com/layer6ai-labs/rag-error-classification.

</details>


### [162] [The German Commons - 154 Billion Tokens of Openly Licensed Text for German Language Models](https://arxiv.org/abs/2510.13996)
*Lukas Gienapp,Christopher Schröder,Stefan Schweter,Christopher Akiki,Ferdinand Schlatt,Arden Zimmermann,Phillipe Genêt,Martin Potthast*

Main category: cs.CL

TL;DR: 该论文介绍了German Commons，这是迄今为止最大规模的开放授权德语文本语料库，解决了德语大模型训练数据稀缺和授权不清的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型训练依赖大规模语料数据，但大多数据存在版权和授权不明的问题，尤其是德语等非英语资源公开且合法的数据尤为稀缺，限制了开放德语模型的发展。

Method: 作者系统性地整合了41个数据源，涵盖七大领域（法律、科学、文化、政治、新闻、经济及网络文本），并对数据进行彻底的质量过滤、去重及格式修正。所有数据均保证至少符合CC-BY-SA 4.0或等同授权，且公开数据处理和过滤代码，确保流程可复现与可扩展。

Result: 形成了一个包含1545.6亿词标的高质量开放德语语料库German Commons，数据具备统一格式和高质量，明确的授权意味着可安全用于模型训练与再分发。

Conclusion: German Commons为德语大模型开发提供了坚实的开放数据基础，有助于可公开分发、合规开发德语语言模型，也为语料库建设方法提供了可复用方案。

Abstract: Large language model development relies on large-scale training corpora, yet
most contain data of unclear licensing status, limiting the development of
truly open models. This problem is exacerbated for non-English languages, where
openly licensed text remains critically scarce. We introduce the German
Commons, the largest collection of openly licensed German text to date. It
compiles data from 41 sources across seven domains, encompassing legal,
scientific, cultural, political, news, economic, and web text. Through
systematic sourcing from established data providers with verifiable licensing,
it yields 154.56 billion tokens of high-quality text for language model
training. Our processing pipeline implements comprehensive quality filtering,
deduplication, and text formatting fixes, ensuring consistent quality across
heterogeneous text sources. All domain subsets feature licenses of at least
CC-BY-SA 4.0 or equivalent, ensuring legal compliance for model training and
redistribution. The German Commons therefore addresses the critical gap in
openly licensed German pretraining data, and enables the development of truly
open German language models. We also release code for corpus construction and
data filtering tailored to German language text, rendering the German Commons
fully reproducible and extensible.

</details>


### [163] [CRaFT: An Explanation-Based Framework for Evaluating Cultural Reasoning in Multilingual Language Models](https://arxiv.org/abs/2510.14014)
*Shehenaz Hossain,Haithem Afli*

Main category: cs.CL

TL;DR: 本文提出了CRaFT框架，通过评估大语言模型解释的文化适应性，超越了只看答案对错的传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有评测大多依赖答案准确率，无法衡量AI对不同文化的理解与推理能力。因此需要新的评估体系来反映模型在多文化、多语言环境下的实际能力。

Method: 作者设计了CRaFT评估框架，设定四个可解释指标（文化流畅性、偏差、一致性和语言适应性），用世界价值观调查中50个涉及文化的问题，翻译成阿拉伯语、孟加拉语和西班牙语，并对三种大型语言模型的2100余组答案-解释对进行评测。

Result: 结果显示，不同语言背景下，模型推理文化差异明显。阿拉伯语降低文化流畅性，孟加拉语提升，西班牙语相对稳定。GPT跨语言适应性强但一致性低，FANAR虽然稳定但较为僵化。

Conclusion: CRaFT验证了大模型的文化意识主要依赖语言呈现，不是固有属性。该框架提供了评估模型多语种跨文化推理的新工具，并为研发更具文化适应性的AI提供了参考。

Abstract: Correct answers do not necessarily reflect cultural understanding. We
introduce CRaFT, an explanation-based multilingual evaluation framework
designed to assess how large language models (LLMs) reason across cultural
contexts. Rather than scoring outputs solely based on accuracy, CRaFT evaluates
model explanations using four interpretable metrics: Cultural Fluency,
Deviation, Consistency, and Linguistic Adaptation. We apply the framework to 50
culturally grounded questions from the World Values Survey, translated into
Arabic, Bengali, and Spanish, and evaluate three models (GPT, DeepSeek, and
FANAR) across over 2,100 answer-explanation pairs. Results reveal significant
cross-lingual variation in reasoning: Arabic reduces fluency, Bengali enhances
it, and Spanish remains largely stable. While GPT adapts more effectively
across languages, it exhibits lower consistency; FANAR shows stable but rigid
reasoning. These findings suggest that cultural awareness in LLMs is not
intrinsic but emerges through linguistic framing. CRaFT offers a new lens for
evaluating cross-cultural reasoning in multilingual settings, providing
actionable insights for building culturally adaptive language models.

</details>


### [164] [Think Globally, Group Locally: Evaluating LLMs Using Multi-Lingual Word Grouping Games](https://arxiv.org/abs/2510.14030)
*César Guerra-Solano,Zhuochun Li,Xiang Lorraine Li*

Main category: cs.CL

TL;DR: 本文分析了大语言模型（LLMs）在抽象推理任务中的语言偏差，开发了跨多语言的新基准任务，并发现模型在英语情境下表现更优。


<details>
  <summary>Details</summary>
Motivation: 以往大多数学术研究关注于常识或数学等推理任务，但这些任务可能被策略或知识储备主导，未充分体现现实生活中需要的“跳出框架”的抽象推理能力。此外，对于此类任务的跨语言偏差研究仍不足，因此本文希望填补该空白，系统性评估不同语言（英文、西班牙语、中文、印地语、阿拉伯语）中的LLMs抽象推理能力与语言偏差。

Method: 作者设计了一套受《纽约时报Connections》启发的全新抽象推理任务GlobalGroup，覆盖五种语言，并建立了难度衡量指标，以保证不同语言版本任务可控、可比。模型在各自语言及英文翻译版上均做对比实验。

Result: 实验结果显示，LLMs在英语模态下具有显著性能优势，并揭示了开源与闭源模型间的性能差异。此外，论文控制了任务难度，确保跨语言对比更为可靠。

Conclusion: 研究表明现有LLMs在抽象推理任务上存在语言偏差，未来需进一步优化模型架构与训练数据，减少非英语场景下的推理能力损失。

Abstract: Large language models (LLMs) can exhibit biases in reasoning capabilities due
to linguistic modality, performing better on tasks in one language versus
another, even with similar content. Most previous works evaluate this through
reasoning tasks where reliance on strategies or knowledge can ensure success,
such as in commonsense or math tasks. However, abstract reasoning is vital to
reasoning for everyday life, where people apply "out-of-the-box thinking" to
identify and use patterns for solutions, without a reliance on formulaic
approaches. Comparatively, little work has evaluated linguistic biases in this
task type. In this paper, we propose a task inspired by the New York Times
Connections: GlobalGroup, that evaluates models in an abstract reasoning task
across several languages. We constructed a game benchmark with five linguistic
backgrounds -- English, Spanish, Chinese, Hindi, and Arabic -- in both the
native language and an English translation for comparison. We also proposed
game difficulty measurements to evaluate models on games with similar
difficulty, enabling a more controlled comparison, which is particularly
important in reasoning evaluations. Through experimentation, we find English
modalities largely lead to better performance in this abstract reasoning task,
and performance disparities between open- and closed-source models.

</details>


### [165] [Quantifying Phonosemantic Iconicity Distributionally in 6 Languages](https://arxiv.org/abs/2510.14040)
*George Flint,Kaustubh Kislay*

Main category: cs.CL

TL;DR: 本文通过对六种不同语言的大规模数据分析，探索了语音与语义之间的系统性对应关系，发现了多种新的、可解释的“音义一致性”现象，并对跨语言模式及现有假说进行了实证检验。


<details>
  <summary>Details</summary>
Motivation: 尽管语言常被认为是任意的，但在具体情况下语音和语义之间存在系统性关系。此前的研究多集中于个别案例或个别音义现象，缺乏大规模、量化的多语种实证研究，因此本文旨在系统性、跨语言地检验音义一致性的普遍性与多样性。

Method: 作者对英文、西班牙语、印地语、芬兰语、土耳其语和泰米尔语这六种语言进行了分布式量化分析，比较了词素的语音相似度和语义相似度空间，并采用多种统计方法量化、检验两者之间的一致关系。此外，作者还检验了五种已有的音义一致性假说。

Result: 实验发现，不仅在某些传统认为有音义一致性的领域能找到此类关系，还新发现了许多未被文献报道过的可解释现象，并识别出一些跨语言的系统性模式。对于五种已有假说，结果显示有些得到了支持，而有些则结果不确定或混合。

Conclusion: 本文证明了音义一致性并非个案现象，而是在不同语言中广泛存在，且有多样表现形式。大规模、数据驱动的跨语言分析为深入理解语言的任意性与系统性提供了新证据，也为音义关系研究开拓了新方向。

Abstract: Language is, as commonly theorized, largely arbitrary. Yet, systematic
relationships between phonetics and semantics have been observed in many
specific cases. To what degree could those systematic relationships manifest
themselves in large scale, quantitative investigations--both in previously
identified and unidentified phenomena? This work undertakes a distributional
approach to quantifying phonosemantic iconicity at scale across 6 diverse
languages (English, Spanish, Hindi, Finnish, Turkish, and Tamil). In each
language, we analyze the alignment of morphemes' phonetic and semantic
similarity spaces with a suite of statistical measures, and discover an array
of interpretable phonosemantic alignments not previously identified in the
literature, along with crosslinguistic patterns. We also analyze 5 previously
hypothesized phonosemantic alignments, finding support for some such alignments
and mixed results for others.

</details>


### [166] [ERGO: Entropy-guided Resetting for Generation Optimization in Multi-turn Language Models](https://arxiv.org/abs/2510.14077)
*Haziq Mohammad Khalid,Athikash Jeyaganthan,Timothy Do,Yicheng Fu,Sean O'Brien,Vasu Sharma,Kevin Zhu*

Main category: cs.CL

TL;DR: 该论文发现大语言模型（LLM）在多轮对话中随信息逐步披露时性能显著下降，提出利用不确定性信号动态优化对话上下文。新方法ERGO通过监控生成过程中的熵，自动调整prompt，有效提升对话性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 多轮对话是与LLM日常交互的核心场景，但现有模型在此情况下信息逐渐给出时表现不佳，极大限制了其实际应用。因此作者致力于提升LLM在多轮对话中的可靠性和能力。

Method: 作者提出ERGO方法，实时计算LLM在每步生成token时的香农熵，通过检测不确定性骤增动态触发prompt重组，主动用不确定性信号指导对话上下文优化。该方法将不确定性视为有价值的信息源，而非噪声，提升模型决策能力。

Result: 在多轮、逐步揭示任务中，ERGO方案比常规方法平均提升性能56.6%，提高模型峰值能力24.7%，且性能波动降低35.3%。

Conclusion: 通过不确定性感知与干预，可显著增强LLM多轮对话中的准确性与可靠性，为提升实际对话AI系统实用性提供了有效方案。

Abstract: Large Language Models (LLMs) suffer significant performance degradation in
multi-turn conversations when information is presented incrementally. Given
that multi-turn conversations characterize everyday interactions with LLMs,
this degradation poses a severe challenge to real world usability. We
hypothesize that abrupt increases in model uncertainty signal misalignment in
multi-turn LLM interactions, and we exploit this insight to dynamically realign
conversational context. We introduce ERGO (Entropy-guided Resetting for
Generation Optimization), which continuously quantifies internal uncertainty
via Shannon entropy over next token distributions and triggers adaptive prompt
consolidation when a sharp spike in entropy is detected. By treating
uncertainty as a first class signal rather than a nuisance to eliminate, ERGO
embraces variability in language and modeling, representing and responding to
uncertainty. In multi-turn tasks with incrementally revealed instructions, ERGO
yields a 56.6% average performance gain over standard baselines, increases
aptitude (peak performance capability) by 24.7%, and decreases unreliability
(variability in performance) by 35.3%, demonstrating that uncertainty aware
interventions can improve both accuracy and reliability in conversational AI.

</details>


### [167] [DROID: Dual Representation for Out-of-Scope Intent Detection](https://arxiv.org/abs/2510.14110)
*Wael Rashwan,Hossam M. Zawbaa,Sourav Dutta,Haytham Assem*

Main category: cs.CL

TL;DR: 本文提出了一种新的端到端框架DROID，用于检测对话系统中的超范围（OOS）用户意图，通过结合通用和领域适应的表示，显著提升了检测效果，尤其适用于低资源场景。


<details>
  <summary>Details</summary>
Motivation: 任务型对话系统很难准确检测到用户超范围（OOS）的意图，而现有方法依赖于较强的分布假设或额外的校准模块，效果和泛化能力有限。因此有必要提出更健壮且易于扩展的OOS检测方法。

Method: 提出DROID，一种拥有两个互补编码器的紧凑端到端框架：使用Universal Sentence Encoder（USE）提取通用语义、用领域适应的Transformer式去噪自编码器（TSDAE）捕捉领域特定上下文特征。融合后用分支分类器及单一校准阈值区分域内与OOS意图，无需额外校准模块。通过生成合成及开放域异常增强样本，提高在弱监督下的边界学习能力。

Result: 在使用参数量仅1.5M的小型模型情况下，DROID在多个意图识别基准数据集上都优于最新方法。对已知意图宏F1提升6-15%，OOS意图提升8-20%，在低资源场景下效果尤为突出。

Conclusion: 双编码器联合简单阈值校准提供了高效、强健且可扩展的OOS检测能力，有助于神经对话系统在实际应用中更好地识别超范围意图。

Abstract: Detecting out-of-scope (OOS) user utterances remains a key challenge in
task-oriented dialogue systems and, more broadly, in open-set intent
recognition. Existing approaches often depend on strong distributional
assumptions or auxiliary calibration modules. We present DROID (Dual
Representation for Out-of-Scope Intent Detection), a compact end-to-end
framework that combines two complementary encoders -- the Universal Sentence
Encoder (USE) for broad semantic generalization and a domain-adapted
Transformer-based Denoising Autoencoder (TSDAE) for domain-specific contextual
distinctions. Their fused representations are processed by a lightweight
branched classifier with a single calibrated threshold that separates in-domain
and OOS intents without post-hoc scoring. To enhance boundary learning under
limited supervision, DROID incorporates both synthetic and open-domain outlier
augmentation. Despite using only 1.5M trainable parameters, DROID consistently
outperforms recent state-of-the-art baselines across multiple intent
benchmarks, achieving macro-F1 improvements of 6--15% for known and 8--20% for
OOS intents, with the most significant gains in low-resource settings. These
results demonstrate that dual-encoder representations with simple calibration
can yield robust, scalable, and reliable OOS detection for neural dialogue
systems.

</details>


### [168] [Toward Cybersecurity-Expert Small Language Models](https://arxiv.org/abs/2510.14113)
*Matan Levi,Daniel Ohayon,Ariel Blobstein,Ravid Sagi,Ian Molloy,Yair Allouche*

Main category: cs.CL

TL;DR: 提出了专为网络安全领域设计的小型语言模型（CyberPal 2.0），其性能超越或接近当前同类大型模型，且模型体积更小。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型虽广泛应用于日常领域，但在网络安全领域因缺乏高质量、专业的数据集和模型而应用落后。作者希望填补这一空白，推动AI在网络安全中的落地。

Method: 作者开发了数据增强和格式化流程SecKnowledge 2.0，结合专家引导和LLM多步推理，构建高质量、安全特定的chain-of-thought指令数据集，并据此训练了4B-20B参数量级的CyberPal 2.0系列模型，通过多个安全领域公开基准进行评测。

Result: CyberPal 2.0在多项网络安全基准中表现优异，在威胁情报相关知识任务中排名第二，仅次于Sec-Gemini v1；在威胁调查（漏洞、票据关联等）任务中，20B模型排名第一，超越GPT-4o、o1、o3-mini和Sec-Gemini v1，4B模型也有优异表现。

Conclusion: CyberPal 2.0展现出极高的专业性能，在模型参数规模远小于主流大模型的情况下，依然达到了甚至超越了最前沿模型的效果，证明了定制高质数据集和合理设计的重要性，对网络安全AI模型的实际应用具有推动作用。

Abstract: Large language models (LLMs) are transforming everyday applications, yet
deployment in cybersecurity lags due to a lack of high-quality, domain-specific
models and training datasets. To address this gap, we present CyberPal 2.0, a
family of cybersecurity-expert small language models (SLMs) ranging from 4B-20B
parameters. To train CyberPal 2.0, we generate an enriched chain-of-thought
cybersecurity instruction dataset built with our data enrichment and formatting
pipeline, SecKnowledge 2.0, which integrates expert-in-the-loop steering of
reasoning formats alongside LLM-driven multi-step grounding, yielding
higher-fidelity, task-grounded reasoning traces for security tasks. Across
diverse cybersecurity benchmarks, CyberPal 2.0 consistently outperforms its
baselines and matches or surpasses various open and closed-source frontier
models, while remaining a fraction of their size. On core cyber threat
intelligence knowledge tasks, our models outperform almost all tested frontier
models, ranking second only to Sec-Gemini v1. On core threat-investigation
tasks, such as correlating vulnerabilities and bug tickets with weaknesses, our
best 20B-parameter model outperforms GPT-4o, o1, o3-mini, and Sec-Gemini v1,
ranking first, while our smallest 4B-parameter model ranks second.

</details>


### [169] [Building a Macedonian Recipe Dataset: Collection, Parsing, and Comparative Analysis](https://arxiv.org/abs/2510.14128)
*Darko Sasanski,Dimitar Peshevski,Riste Stojanov,Dimitar Trajanov*

Main category: cs.CL

TL;DR: 本文提出了首个系统收集马其顿菜谱的数据集，并对其成分及搭配进行了初步分析，丰富了数字美食学中欠缺的马其顿数据。


<details>
  <summary>Details</summary>
Motivation: 当前菜谱数据集大多覆盖主流语言，马其顿语菜谱在数字化领域显著不足。为捕捉地区烹饪传统、丰富食物文化研究，亟需构建马其顿菜谱数据资源。

Method: 通过网页爬取和结构化解析技术，系统地收集了马其顿菜谱数据。在数据处理阶段，针对异构的食材描述（如单位、数量、修饰语），进行了标准化归一处理。随后，对食材出现频率和共现模式进行探索性分析，采用点互信息（PMI）和提升度（Lift）等指标来发掘独特的食材组合模式。

Result: 构建了第一个系统的马其顿菜谱数据集。分析发现了一些具有马其顿特色的食材及其组合模式，为了解马其顿饮食传统提供了数据依据。

Conclusion: 该数据集为研究欠代表语言的食物文化提供了新工具，同时揭示了马其顿菜肴在成分搭配上的独特性，为数字美食学和地区文化分析带来新视角。

Abstract: Computational gastronomy increasingly relies on diverse, high-quality recipe
datasets to capture regional culinary traditions. Although there are
large-scale collections for major languages, Macedonian recipes remain
under-represented in digital research. In this work, we present the first
systematic effort to construct a Macedonian recipe dataset through web scraping
and structured parsing. We address challenges in processing heterogeneous
ingredient descriptions, including unit, quantity, and descriptor
normalization. An exploratory analysis of ingredient frequency and
co-occurrence patterns, using measures such as Pointwise Mutual Information and
Lift score, highlights distinctive ingredient combinations that characterize
Macedonian cuisine. The resulting dataset contributes a new resource for
studying food culture in underrepresented languages and offers insights into
the unique patterns of Macedonian culinary tradition.

</details>


### [170] [RLSR: Reinforcement Learning with Supervised Reward Outperforms SFT in Instruction Following](https://arxiv.org/abs/2510.14200)
*Zhichao Wang,Andy Wong,Ruslan Belkin*

Main category: cs.CL

TL;DR: 本文提出用RLSR（一种基于强化学习的监督自回归方法）替换传统的SFT（监督微调），以提升大语言模型的指令跟随能力，实验中取得比SFT更好的效果，并且二者结合能进一步提升表现。


<details>
  <summary>Details</summary>
Motivation: 虽然SFT能提升模型指令跟随性，但其基于下一个token预测的训练目标存在局限，受限于人工标注数据的表达能力。RFT虽然可以少量标注迁移，但主要针对推理而非指令跟随。作者希望弥补SFT的不足，挖掘RL框架和大规模SFT数据的结合潜力。

Method: 作者提出RLSR方法：在大规模SFT数据上使用RL进行训练。具体做法是模型对每个输入生成多个回复，将生成回复与人工标注回复在语义嵌入空间中算余弦相似度，作为RL奖励信号，用于更新模型参数。RLSR既可以替换SFT独立使用，也可以与SFT联合训练。

Result: RLSR单独训练下，在AlpacaEval等指令跟随基准测试中，Qwen-7B用RLSR（SB）取得26.34%的胜率，优于传统SFT的21.01%。与SFT联合训练则提升至30.73%。

Conclusion: RLSR在指令跟随任务上优于SFT，且与SFT结合表现更好，表明基于RL的自回归训练在利用标注数据时更加高效有效，对指令跟随大模型训练有重要意义。

Abstract: After the pretraining stage of LLMs, techniques such as SFT, RLHF, RLVR, and
RFT are applied to enhance instruction-following ability, mitigate undesired
responses, improve reasoning capability and enable efficient domain adaptation
with minimal data. SFT relies on the next-token prediction objective to
strengthen instruction following in a base model using a large corpus of
human-labeled responses. In contrast, RFT employs a RL-based approach to adapt
fine-tuned reasoning models to specific domains with limited supervision.
Inspired by RFT, we propose replacing SFT with RLSR to leverage the extensive
SFT dataset in an RL framework, thereby improving the base model's
instruction-following ability. In RLSR, the base model generates multiple
responses for each prompt, and reward scores are computed as the cosine
similarity in the semantic embedding space between the generated and
human-labeled responses. RLSR can be utilized in multiple ways. It can directly
replace SFT, achieving superior performance on instruction-following
benchmarks-for example, RLSR (SB) on Qwen-7B (INFINITY) achieved an AlpacaEval
win rate of 26.34%, surpassing SFT's 21.01%. Furthermore, combining SFT and
RLSR further enhances downstream task performance; Qwen-7B (INFINITY) achieved
a win rate of 30.73% when trained with SFT + RLSR.

</details>


### [171] [DPRF: A Generalizable Dynamic Persona Refinement Framework for Optimizing Behavior Alignment Between Personalized LLM Role-Playing Agents and Humans](https://arxiv.org/abs/2510.14205)
*Bingsheng Yao,Bo Sun,Yuanzhe Dong,Yuxuan Lu,Dakuo Wang*

Main category: cs.CL

TL;DR: 本文提出了一种名为动态人物画像优化框架（DPRF）的方法，能自动迭代优化大语言模型（LLM）扮演者与目标个体行为的一致性，显著提升角色扮演AI的真实性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM角色扮演代理普遍依赖人工编写的人物档案，这些档案往往主观臆断且未经验证，导致AI模拟的人物行为与真实个体存在偏差，难以满足高真实性的应用需求。

Method: 提出DPRF框架，针对AI生成的行为与目标人物真实行为之间的认知偏差，通过自由式或理论驱动的结构化分析，反复迭代优化人物档案，使AI角色行为更贴近真实个体。并在多种场景和多款LLM上进行实验验证。

Result: DPRF在正式辩论、心理健康社交媒体发言、公共采访、电影评论等多样化场景下，均显著提高了AI角色行为与真实人物的一致性，且结果在不同模型和场景间均具泛化能力。

Conclusion: DPRF为创建高真实性人物档案和提升AI角色扮演应用的效果提供了一套有效方案，有助于推动用户模拟、社会研究和个性化AI等下游应用的发展。

Abstract: The emerging large language model role-playing agents (LLM RPAs) aim to
simulate individual human behaviors, but the persona fidelity is often
undermined by manually-created profiles (e.g., cherry-picked information and
personality characteristics) without validating the alignment with the target
individuals. To address this limitation, our work introduces the Dynamic
Persona Refinement Framework (DPRF).DPRF aims to optimize the alignment of LLM
RPAs' behaviors with those of target individuals by iteratively identifying the
cognitive divergence, either through free-form or theory-grounded, structured
analysis, between generated behaviors and human ground truth, and refining the
persona profile to mitigate these divergences.We evaluate DPRF with five LLMs
on four diverse behavior-prediction scenarios: formal debates, social media
posts with mental health issues, public interviews, and movie reviews.DPRF can
consistently improve behavioral alignment considerably over baseline personas
and generalizes across models and scenarios.Our work provides a robust
methodology for creating high-fidelity persona profiles and enhancing the
validity of downstream applications, such as user simulation, social studies,
and personalized AI.

</details>


### [172] [LiteStage: Latency-aware Layer Skipping for Multi-stage Reasoning](https://arxiv.org/abs/2510.14211)
*Beomseok Kang,Jiwon Song,Jae-Joon Kim*

Main category: cs.CL

TL;DR: 论文提出了一种命名为LiteStage的新框架，通过分阶段的层跳过和提前输出机制，提高小型语言模型多阶段推理的效率并减少延迟，同时能较好地维持准确率。


<details>
  <summary>Details</summary>
Motivation: 多阶段推理虽然能提升小模型的能力，但会导致推理延迟增加，现有的加速方法如层跳过在多阶段场景下面临跳过敏感性变化和冗余输出问题，难以兼顾效率与准确率。

Method: 提出LiteStage，结合了分阶段的离线层预算分配（针对不同阶段跳过敏感性分配最优预算）以及基于置信度的在线提前输出机制，动态抑制多余解码。

Result: 在OBQA、CSQA和StrategyQA三个基准测试中，LiteStage在小于4.0%的准确率损失下实现最高1.70倍的推理加速，效果优于现有无需训练的层跳过方法。

Conclusion: LiteStage能在多阶段推理中有效提升小模型的效率，适合于实际需要低延迟的推理场景，兼顾了速度与准确率。

Abstract: Multi-stage reasoning has emerged as an effective strategy for enhancing the
reasoning capability of small language models by decomposing complex problems
into sequential sub-stages. However, this comes at the cost of increased
latency. We observe that existing adaptive acceleration techniques, such as
layer skipping, struggle to balance efficiency and accuracy in this setting due
to two key challenges: (1) stage-wise variation in skip sensitivity, and (2)
the generation of redundant output tokens. To address these, we propose
LiteStage, a latency-aware layer skipping framework for multi-stage reasoning.
LiteStage combines a stage-wise offline search that allocates optimal layer
budgets with an online confidence-based generation early exit to suppress
unnecessary decoding. Experiments on three benchmarks, e.g., OBQA, CSQA, and
StrategyQA, show that LiteStage achieves up to 1.70x speedup with less than
4.0% accuracy loss, outperforming prior training-free layer skipping methods.

</details>


### [173] [Flip-Flop Consistency: Unsupervised Training for Robustness to Prompt Perturbations in LLMs](https://arxiv.org/abs/2510.14242)
*Parsa Hejabi,Elnaz Rahmati,Alireza S. Ziabari,Morteza Dehghani*

Main category: cs.CL

TL;DR: 本文提出了一种名为Flip-Flop Consistency (F^2C)的无监督训练方法，显著提升了大语言模型在面对不同问题表述时的回答一致性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在不同的提示表述下可能产生不一致的输出，影响其实际应用的稳定性和可靠性。因此，研究如何提升模型对提示变化的鲁棒性变得尤为重要。

Method: F^2C包含两个主要模块：（1）共识交叉熵（CCE），通过对不同提示变体进行多数投票，生成硬伪标签；（2）表征对齐损失，将低置信度和非多数预测的表达朝高置信度、多数投票方向收敛。整个过程无需人工标注，是无监督的。

Result: 在11个数据集（4个NLP任务、每个数据集有4-15种提示变体）上，F^2C平均提升了11.62%的输出一致性、提升了8.94%的平均F1分数，并降低了3.29%的格式间性能方差。跨领域测试中，F^2C同样表现出良好的泛化能力，提升一致性和F1分数且降低方差。即使在未见过的提示格式上，也能持续提升性能和一致性。

Conclusion: F^2C是一种高效、无监督的方法，能够显著提高大语言模型对提示变化的鲁棒性、一致性和泛化能力。

Abstract: Large Language Models (LLMs) often produce inconsistent answers when faced
with different phrasings of the same prompt. In this paper, we propose
Flip-Flop Consistency ($F^2C$), an unsupervised training method that improves
robustness to such perturbations. $F^2C$ is composed of two key components. The
first, Consensus Cross-Entropy (CCE), uses a majority vote across prompt
variations to create a hard pseudo-label. The second is a representation
alignment loss that pulls lower-confidence and non-majority predictors toward
the consensus established by high-confidence, majority-voting variations. We
evaluate our method on 11 datasets spanning four NLP tasks, with 4-15 prompt
variations per dataset. On average, $F^2C$ raises observed agreement by 11.62%,
improves mean $F_1$ by 8.94%, and reduces performance variance across formats
by 3.29%. In out-of-domain evaluations, $F^2C$ generalizes effectively,
increasing $\overline{F_1}$ and agreement while decreasing variance across most
source-target pairs. Finally, when trained on only a subset of prompt
perturbations and evaluated on held-out formats, $F^2C$ consistently improves
both performance and agreement while reducing variance. These findings
highlight $F^2C$ as an effective unsupervised method for enhancing LLM
consistency, performance, and generalization under prompt perturbations. Code
is available at
https://github.com/ParsaHejabi/Flip-Flop-Consistency-Unsupervised-Training-for-Robustness-to-Prompt-Perturbations-in-LLMs.

</details>


### [174] [MoM: Mixtures of Scenario-Aware Document Memories for Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2510.14252)
*Jihao Zhao,Zhiyuan Ji,Simin Niu,Hanyu Wang,Feiyu Xiong,Zhiyu Li*

Main category: cs.CL

TL;DR: 该论文提出了一种全新的MoM框架，将RAG范式从被动文本分块转变为主动文档理解，实现更深度的知识内化与推理能力提升。


<details>
  <summary>Details</summary>
Motivation: 传统的RAG方法仅被动地分割文本并对其检索，限制了对文本深度理解与复杂推理能力的发挥。为模拟人类阅读过程、突破这一局限，作者提出需主动构建文档记忆。

Method: MoM框架首先引导大语言模型以领域专家身份生成文档结构大纲，实现结构化分块及内容提取。采用多路径采样和多视角评价机制，设计覆盖内容完整性和分块清晰度的综合指标，筛选最优文档记忆。同时对小模型训练引入逆向推理，提取高质量专家思维路径。最终搭建三层文档记忆检索，并给出概率模型理论证明。

Result: 在三个不同领域的实验中，MoM框架有效解决了RAG系统内文档分块问题，提升了检索的内容完整性和推理能力，同时助力小模型具备更类人的文本处理能力。

Conclusion: MoM为文本检索与理解开辟了新思路，不仅优化了大模型的文档记忆质量，也推动了小模型的智能化进化，具备广泛的实际应用前景。

Abstract: The traditional RAG paradigm, which typically engages in the comprehension of
relevant text chunks in response to received queries, inherently restricts both
the depth of knowledge internalization and reasoning capabilities. To address
this limitation, our research transforms the text processing in RAG from
passive chunking to proactive understanding, defining this process as document
memory extraction with the objective of simulating human cognitive processes
during reading. Building upon this, we propose the Mixtures of scenario-aware
document Memories (MoM) framework, engineered to efficiently handle documents
from multiple domains and train small language models (SLMs) to acquire the
ability to proactively explore and construct document memories. The MoM
initially instructs large language models (LLMs) to simulate domain experts in
generating document logical outlines, thereby directing structured chunking and
core content extraction. It employs a multi-path sampling and multi-perspective
evaluation mechanism, specifically designing comprehensive metrics that
represent chunk clarity and extraction completeness to select the optimal
document memories. Additionally, to infuse deeper human-like reading abilities
during the training of SLMs, we incorporate a reverse reasoning strategy, which
deduces refined expert thinking paths from high-quality outcomes. Finally,
leveraging diverse forms of content generated by MoM, we develop a three-layer
document memory retrieval mechanism, which is grounded in our theoretical proof
from the perspective of probabilistic modeling. Extensive experimental results
across three distinct domains demonstrate that the MoM framework not only
resolves text chunking challenges in existing RAG systems, providing LLMs with
semantically complete document memories, but also paves the way for SLMs to
achieve human-centric intelligent text processing.

</details>


### [175] [Rewriting History: A Recipe for Interventional Analyses to Study Data Effects on Model Behavior](https://arxiv.org/abs/2510.14261)
*Rahul Nadkarni,Yanai Elazar,Hila Gonen,Noah A. Smith*

Main category: cs.CL

TL;DR: 本文提出了一套实验方案，用于系统性地研究语言模型训练数据与模型行为之间的关系，并通过干预训练数据和重训练的方法验证相关假设。


<details>
  <summary>Details</summary>
Motivation: 目前关于语言模型为何及如何学会某些知识，现有分析多为观察性，缺乏系统的干预实验，难以明确数据与模型表现之间的因果关联。因此，作者希望提供一种可复用的实验流程，帮助研究人员检验训练数据如何具体影响语言模型的输出行为。

Method: 作者设计了一个“介入-重训练-评测”的流程，包括选择评测项目，找到相关训练文档，对文档进行修改（“重写历史”），然后重训练模型并观测效果。具体案例中，作者利用共现统计与信息检索方法定位可能影响模型知识学习的训练文档。

Result: 通过案例研究，结果证实了训练数据中与知识相关内容的确影响模型的知识表现；但现有常用的训练文档定位方法（如共现或检索）无法完全解释模型对问题的回答能力，说明影响机制更为复杂。

Conclusion: 作者提出了一种系统可复用的研究方法，有助于深入研究和验证训练数据如何影响语言模型行为，并通过公开代码促进后续研究。

Abstract: We present an experimental recipe for studying the relationship between
training data and language model (LM) behavior. We outline steps for
intervening on data batches -- i.e., ``rewriting history'' -- and then
retraining model checkpoints over that data to test hypotheses relating data to
behavior. Our recipe breaks down such an intervention into stages that include
selecting evaluation items from a benchmark that measures model behavior,
matching relevant documents to those items, and modifying those documents
before retraining and measuring the effects. We demonstrate the utility of our
recipe through case studies on factual knowledge acquisition in LMs, using both
cooccurrence statistics and information retrieval methods to identify documents
that might contribute to knowledge learning. Our results supplement past
observational analyses that link cooccurrence to model behavior, while
demonstrating that extant methods for identifying relevant training documents
do not fully explain an LM's ability to correctly answer knowledge questions.
Overall, we outline a recipe that researchers can follow to test further
hypotheses about how training data affects model behavior. Our code is made
publicly available to promote future work.

</details>


### [176] [Less is More: Denoising Knowledge Graphs For Retrieval Augmented Generation](https://arxiv.org/abs/2510.14271)
*Yilun Zheng,Dan Yang,Jie Li,Lin Shang,Lihui Chen,Jiahao Xu,Sitao Luan*

Main category: cs.CL

TL;DR: 本文提出了一种用于RAG系统的知识图谱去噪方法，实现更高质量的生成结果。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的RAG系统依赖LLM自动构建知识图谱，但这些自动生成的KG常带来噪声（如冗余实体和错误关系），影响检索与生成效果，同时增加算力开销，相关噪声去除方法尚不充分。

Method: 提出DEG-RAG 框架，核心方法包括实体消歧（去除冗余实体）和三元组反射（删除错误关系），并系统性评估了实体消歧的不同实现（如分组策略、嵌入选择、相似度度量和实体合并）。

Result: 经过去噪处理后的知识图谱更加紧凑高质，大幅减少了无用节点与关系，并且在多种主流Graph-based RAG系统QA任务中都显著优于未处理KG。

Conclusion: 对LLM生成知识图谱进行系统性去噪能提升RAG系统表现，相关消歧与去噪方法的系统研究属首创，效果显著，建议相关应用普遍采用。

Abstract: Retrieval-Augmented Generation (RAG) systems enable large language models
(LLMs) instant access to relevant information for the generative process,
demonstrating their superior performance in addressing common LLM challenges
such as hallucination, factual inaccuracy, and the knowledge cutoff.
Graph-based RAG further extends this paradigm by incorporating knowledge graphs
(KGs) to leverage rich, structured connections for more precise and inferential
responses. A critical challenge, however, is that most Graph-based RAG systems
rely on LLMs for automated KG construction, often yielding noisy KGs with
redundant entities and unreliable relationships. This noise degrades retrieval
and generation performance while also increasing computational cost. Crucially,
current research does not comprehensively address the denoising problem for
LLM-generated KGs. In this paper, we introduce DEnoised knowledge Graphs for
Retrieval Augmented Generation (DEG-RAG), a framework that addresses these
challenges through: (1) entity resolution, which eliminates redundant entities,
and (2) triple reflection, which removes erroneous relations. Together, these
techniques yield more compact, higher-quality KGs that significantly outperform
their unprocessed counterparts. Beyond the methods, we conduct a systematic
evaluation of entity resolution for LLM-generated KGs, examining different
blocking strategies, embedding choices, similarity metrics, and entity merging
techniques. To the best of our knowledge, this is the first comprehensive
exploration of entity resolution in LLM-generated KGs. Our experiments
demonstrate that this straightforward approach not only drastically reduces
graph size but also consistently improves question answering performance across
diverse popular Graph-based RAG variants.

</details>


### [177] [Retrofitting Small Multilingual Models for Retrieval: Matching 7B Performance with 300M Parameters](https://arxiv.org/abs/2510.14274)
*Lifu Tu,Yingbo Zhou,Semih Yavuz*

Main category: cs.CL

TL;DR: 本论文研究如何提升小型多语种嵌入模型在检索任务上的表现，通过改进训练数据、负采样策略和数据多样性，构建了一个表现接近甚至超越7B级别大模型的300M模型。


<details>
  <summary>Details</summary>
Motivation: 当前小于10亿参数的小型多语种模型虽然在多语任务总体表现良好，但在主流的检索任务上远落后于大模型。为节省资源并提升实用性，需要探索小模型能否通过专门方法优化用于检索任务。

Method: 系统地分析了影响多语种嵌入模型表现的几个关键要素，包括训练数据规模、负采样策略和数据多样性。实验中考察了增加训练数据、采用硬负样本、训练数据的任务多样性和语言多样性对检索表现的影响，并据此指导小模型的训练方法。

Result: 发现扩大数据规模收益迅速递减，加入硬负样本显著提升检索准确率，且训练数据的任务多样性比单纯追求语言多样性对表现提升更关键。基于这些发现，作者训练了一个约3亿参数的小型多语种模型，其检索效果可媲美甚至超过目前表现最强的7B大模型。

Conclusion: 小型多语种模型在检索场景下，通过合理设计数据和训练流程能够缩小与大模型的差距，优质负样本和任务多样性尤为重要，这为资源受限场景下高效多语检索提供了技术路径。

Abstract: Training effective multilingual embedding models presents unique challenges
due to the diversity of languages and task objectives. Although small
multilingual models (<1 B parameters) perform well on multilingual tasks
generally, they consistently lag behind larger models (>1 B) in the most
prevalent use case: retrieval. This raises a critical question: Can smaller
models be retrofitted specifically for retrieval tasks to enhance their
performance? In this work, we investigate key factors that influence the
effectiveness of multilingual embeddings, focusing on training data scale,
negative sampling strategies, and data diversity. We find that while increasing
the scale of training data yields initial performance gains, these improvements
quickly plateau - indicating diminishing returns. Incorporating hard negatives
proves essential for consistently improving retrieval accuracy. Furthermore,
our analysis reveals that task diversity in the training data contributes more
significantly to performance than language diversity alone. As a result, we
develop a compact (approximately 300M) multilingual model that achieves
retrieval performance comparable to or even surpassing current strong 7B
models.

</details>


### [178] [Qwen3Guard Technical Report](https://arxiv.org/abs/2510.14276)
*Haiquan Zhao,Chenhan Yuan,Fei Huang,Xiaomeng Hu,Yichang Zhang,An Yang,Bowen Yu,Dayiheng Liu,Jingren Zhou,Junyang Lin,Baosong Yang,Chen Cheng,Jialong Tang,Jiandong Jiang,Jianwei Zhang,Jijie Xu,Ming Yan,Minmin Sun,Pei Zhang,Pengjun Xie,Qiaoyu Tang,Qin Zhu,Rong Zhang,Shibin Wu,Shuo Zhang,Tao He,Tianyi Tang,Tingyu Xia,Wei Liao,Weizhou Shen,Wenbiao Yin,Wenmeng Zhou,Wenyuan Yu,Xiaobin Wang,Xiaodong Deng,Xiaodong Xu,Xinyu Zhang,Yang Liu,Yeqiu Li,Yi Zhang,Yong Jiang,Yu Wan,Yuxin Zhou*

Main category: cs.CL

TL;DR: 本文提出了Qwen3Guard系列模型，提供更细粒度且支持多语言的LLM安全防护，支持实时监控与多安全等级判别，在多语种评测中达到领先水平。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型(LLM)的广泛应用，模型输出的安全性成为紧迫问题。然而，现有防护措施仅能做简单安全/不安全二元判别，无法满足不同领域多样化的安全需求，且无法在流式生成时实时监控输出，存在局限性。

Method: Qwen3Guard系列包含两种变体：Generative Qwen3Guard采用类指令学习的方式做三分类（安全、有争议、不安全）；Stream Qwen3Guard则在生成过程中为每个token做安全判别，从而实现实时监控。两者各有三种规模，支持119种语言及方言。

Result: Qwen3Guard在英文、中文及多语言安全评测中均取得了领先的安全判别表现，无论是在prompt还是reply的检测任务上均优于现有模型。

Conclusion: Qwen3Guard有效解决了现有防护模型粒度粗、难以实时监控和多样化应用的难题，为全球范围LLM部署提供了可靠、快速的安全防护方案，并已开源。

Abstract: As large language models (LLMs) become more capable and widely used, ensuring
the safety of their outputs is increasingly critical. Existing guardrail
models, though useful in static evaluation settings, face two major limitations
in real-world applications: (1) they typically output only binary "safe/unsafe"
labels, which can be interpreted inconsistently across diverse safety policies,
rendering them incapable of accommodating varying safety tolerances across
domains; and (2) they require complete model outputs before performing safety
checks, making them fundamentally incompatible with streaming LLM inference,
thereby preventing timely intervention during generation and increasing
exposure to harmful partial outputs. To address these challenges, we present
Qwen3Guard, a series of multilingual safety guardrail models with two
specialized variants: Generative Qwen3Guard, which casts safety classification
as an instruction-following task to enable fine-grained tri-class judgments
(safe, controversial, unsafe); and Stream Qwen3Guard, which introduces a
token-level classification head for real-time safety monitoring during
incremental text generation. Both variants are available in three sizes (0.6B,
4B, and 8B parameters) and support up to 119 languages and dialects, providing
comprehensive, scalable, and low-latency safety moderation for global LLM
deployments. Evaluated across English, Chinese, and multilingual benchmarks,
Qwen3Guard achieves state-of-the-art performance in both prompt and response
safety classification. All models are released under the Apache 2.0 license for
public use.

</details>


### [179] [PRISM: Agentic Retrieval with LLMs for Multi-Hop Question Answering](https://arxiv.org/abs/2510.14278)
*Md Mahadi Hasan Nahid,Davood Rafiei*

Main category: cs.CL

TL;DR: 该论文提出了一种基于大语言模型的多智能体检索系统，用于多跳问答任务，通过迭代筛选和补充关键信息，提高检索的精度和召回率，从而显著提升问答准确性。


<details>
  <summary>Details</summary>
Motivation: 多跳问答需要整合多条证据，而现有检索方法难以兼顾高精度和高召回，且常引入无关内容，影响下游问答系统的效果。因此，作者希望设计一种更有效的检索机制，提升相关信息获取能力。

Method: 提出三智能体结构：Question Analyzer将复杂问题分解为子问题；Selector为每个子问题筛选最相关的上下文，关注精度；Adder补充遗漏证据，关注召回。Selector和Adder反复迭代，最终输出精炼且完整的支持证据集合。

Result: 在四个主流多跳问答数据集（HotpotQA、2WikiMultiHopQA、MuSiQue、MultiHopRAG）上实验证明，该方法检索精度和召回率均超越现有强基线模型。

Conclusion: 基于多智能体和大语言模型的检索框架能够更高效且有效地提取多跳问答所需核心证据，减少无关信息干扰，从而推动下游问答任务取得更高准确率。

Abstract: Retrieval plays a central role in multi-hop question answering (QA), where
answering complex questions requires gathering multiple pieces of evidence. We
introduce an Agentic Retrieval System that leverages large language models
(LLMs) in a structured loop to retrieve relevant evidence with high precision
and recall. Our framework consists of three specialized agents: a Question
Analyzer that decomposes a multi-hop question into sub-questions, a Selector
that identifies the most relevant context for each sub-question (focusing on
precision), and an Adder that brings in any missing evidence (focusing on
recall). The iterative interaction between Selector and Adder yields a compact
yet comprehensive set of supporting passages. In particular, it achieves higher
retrieval accuracy while filtering out distracting content, enabling downstream
QA models to surpass full-context answer accuracy while relying on
significantly less irrelevant information. Experiments on four multi-hop QA
benchmarks -- HotpotQA, 2WikiMultiHopQA, MuSiQue, and MultiHopRAG --
demonstrates that our approach consistently outperforms strong baselines.

</details>


### [180] [Rethinking Schema Linking: A Context-Aware Bidirectional Retrieval Approach for Text-to-SQL](https://arxiv.org/abs/2510.14296)
*Md Mahadi Hasan Nahid,Davood Rafiei,Weiwei Zhang,Yong Zhang*

Main category: cs.CL

TL;DR: 本文关注Text-to-SQL系统中的schema linking问题，提出了一种新的按需检索数据库schema的方法，大幅提升了下游SQL生成的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL方法更多关注SQL生成本身，往往忽略了自然语言问题与数据库schema元素的精准对齐，导致生成SQL时出现幻觉和执行失败。研究动机是将schema linking作为独立任务提升整个系统表现。

Method: 提出了一种上下文感知的双向schema检索框架，分为先检索表后选列，或先检索列后选表两种策略，并结合了问题分解、关键词和关键短语提取等技术提取相关schema元素。

Result: 在BIRD和Spider等基准上实验表明，该方法提升了schema召回率，减少了误检，且生成的SQL明显优于使用全schema的方法，表现接近理想(oracle)水平。方法能将全schema与完美schema表现差距缩小50%。

Conclusion: 精准schema linking能显著提升Text-to-SQL系统的准确性及效率，应作为该领域研究关注重点。

Abstract: Schema linking -- the process of aligning natural language questions with
database schema elements -- is a critical yet underexplored component of
Text-to-SQL systems. While recent methods have focused primarily on improving
SQL generation, they often neglect the retrieval of relevant schema elements,
which can lead to hallucinations and execution failures. In this work, we
propose a context-aware bidirectional schema retrieval framework that treats
schema linking as a standalone problem. Our approach combines two complementary
strategies: table-first retrieval followed by column selection, and
column-first retrieval followed by table selection. It is further augmented
with techniques such as question decomposition, keyword extraction, and
keyphrase extraction. Through comprehensive evaluations on challenging
benchmarks such as BIRD and Spider, we demonstrate that our method
significantly improves schema recall while reducing false positives. Moreover,
SQL generation using our retrieved schema consistently outperforms full-schema
baselines and closely approaches oracle performance, all without requiring
query refinement. Notably, our method narrows the performance gap between full
and perfect schema settings by 50\%. Our findings highlight schema linking as a
powerful lever for enhancing Text-to-SQL accuracy and efficiency.

</details>


### [181] [Constraint-Driven Small Language Models Based on Agent and OpenAlex Knowledge Graph: Mining Conceptual Pathways and Discovering Innovation Points in Academic Papers](https://arxiv.org/abs/2510.14303)
*Ziye Xia,Sergei S. Ospichev*

Main category: cs.CL

TL;DR: 本文旨在提升学术论文关键概念的分析深度，通过基于知识图谱的路径关联分析，实现创新点与少见路径的高效识别。


<details>
  <summary>Details</summary>
Motivation: 随着学术出版物数量迅速增加，科学家难以及时、全面追踪最新研究成果；现有论文数据库在关键概念处理上仅停留于相似性匹配和基础分类，未能充分挖掘概念间的深层关系网络，因此亟需更为高效、深入的方法。

Method: 基于OpenAlex开源知识图谱，分析来自新西伯利亚国立大学的近8000篇开放获取论文数据，提出以Prompt工程为支撑的关键概念路径分析方法：使用小型语言模型提高关键概念提取和创新点发现的精度，并利用知识图谱约束机制构建智能体以增强分析准确性，通过对Qwen和DeepSeek模型进行微调，优化整体表现。

Result: 经过模型微调后，关键概念提取与创新点识别的准确率均有显著提升，优化后的模型已在Hugging Face平台开放。

Conclusion: 本研究的知识图谱约束和Prompt工程结合的小模型方案，有效提升了论文关键概念挖掘的深度和创新点识别能力，为后续学术分析工具的开发提供了新思路。

Abstract: In recent years, the rapid increase in academic publications across various
fields has posed severe challenges for academic paper analysis: scientists
struggle to timely and comprehensively track the latest research findings and
methodologies. Key concept extraction has proven to be an effective analytical
paradigm, and its automation has been achieved with the widespread application
of language models in industrial and scientific domains. However, existing
paper databases are mostly limited to similarity matching and basic
classification of key concepts, failing to deeply explore the relational
networks between concepts. This paper is based on the OpenAlex opensource
knowledge graph. By analyzing nearly 8,000 open-source paper data from
Novosibirsk State University, we discovered a strong correlation between the
distribution patterns of paper key concept paths and both innovation points and
rare paths. We propose a prompt engineering-based key concept path analysis
method. This method leverages small language models to achieve precise key
concept extraction and innovation point identification, and constructs an agent
based on a knowledge graph constraint mechanism to enhance analysis accuracy.
Through fine-tuning of the Qwen and DeepSeek models, we achieved significant
improvements in accuracy, with the models publicly available on the Hugging
Face platform.

</details>


### [182] [MathMist: A Parallel Multilingual Benchmark Dataset for Mathematical Problem Solving and Reasoning](https://arxiv.org/abs/2510.14305)
*Mahbub E Sobhani,Md. Faiyaz Abdullah Sayeedi,Tasnim Mohiuddin,Md Mofijul Islam,Swakkhar Shatabda*

Main category: cs.CL

TL;DR: 本文提出了MathMist，一个涵盖七种语言、超过2.1万个题目的数学推理多语种基准数据集，系统评测了多种大语言模型在不同语境下的表现，并发现模型在低资源语言和多语种情境下推理能力依旧薄弱。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在一般推理上表现优秀，但其在多语种的数学推理能力尚未充分研究，尤其是在低资源语言上的表现存在评测盲区。现有基准多以英语或少数高资源语言为主，无法全面反映模型的跨语言能力。

Method: 作者构建了MathMist并涵盖七种代表性的语言，广泛收集并对齐2.1万对数学题目-答案。通过系统化实验，包括零样本、思路链推理和混合语言推理等多种设定，综合评测开源与闭源大语言模型的数学推理能力。

Result: 实验证明当前各类大语言模型在多语种，尤其是低资源语言中的数学推理表现普遍不佳，且推理过程难以解释。跨语言和代码混合环境会进一步加剧模型性能下降。

Conclusion: 多语种数学推理依然是大语言模型的短板，尤其在低资源语言方面问题突出。需要进一步改进模型和数据集，以提升其在全球多语言环境下的能力。

Abstract: Mathematical reasoning remains one of the most challenging domains for large
language models (LLMs), requiring not only linguistic understanding but also
structured logical deduction and numerical precision. While recent LLMs
demonstrate strong general-purpose reasoning abilities, their mathematical
competence across diverse languages remains underexplored. Existing benchmarks
primarily focus on English or a narrow subset of high-resource languages,
leaving significant gaps in assessing multilingual and cross-lingual
mathematical reasoning. To address this, we introduce MathMist, a parallel
multilingual benchmark for mathematical problem solving and reasoning. MathMist
encompasses over 21K aligned question-answer pairs across seven languages,
representing a balanced coverage of high-, medium-, and low-resource linguistic
settings. The dataset captures linguistic variety, multiple types of problem
settings, and solution synthesizing capabilities. We systematically evaluate a
diverse suite of models, including open-source small and medium LLMs,
proprietary systems, and multilingual-reasoning-focused models, under
zero-shot, chain-of-thought (CoT), and code-switched reasoning paradigms. Our
results reveal persistent deficiencies in LLMs' ability to perform consistent
and interpretable mathematical reasoning across languages, with pronounced
degradation in low-resource settings. All the codes and data are available at
GitHub: https://github.com/mahbubhimel/MathMist

</details>


### [183] [MERLIN: A Testbed for Multilingual Multimodal Entity Recognition and Linking](https://arxiv.org/abs/2510.14307)
*Sathyanarayanan Ramamoorthy,Vishwa Shah,Simran Khanuja,Zaid Sheikh,Shan Jie,Ann Chia,Shearman Chua,Graham Neubig*

Main category: cs.CL

TL;DR: 该论文提出了MERLIN，这是一个面向多语言多模态实体链接任务的新测试系统，涵盖BBC新闻标题及配图，支持五种语言，并给出多种基准测试。结果显示，结合视觉数据可提升实体链接准确率，尤其对文本语境不充分时效果明显。


<details>
  <summary>Details</summary>
Motivation: 随着全球化和数字媒体的发展，信息存在多语言和多模态（文本、图片等）特征。现有实体链接方法受限于单一语言或文本，无法有效处理多语言、多模态场景下的信息。这一研究旨在填补多语言多模态实体链接领域公开数据集和基准测试的空白。

Method: 作者构建了一个新的多语言多模态测试集MERLIN，包括五种语言的新闻标题及图片，并为提及的实体标注了相应的Wikidata实体。采用多种主流多语言模型（如LLaMa-2和Aya-23）进行文本及视觉信息结合的基准测试，对比纯文本与多模态方法的效果。

Result: 实验表明，结合视觉数据能显著提升实体链接模型的准确率，尤其是在文本上下文不足、语义歧义较强的场景，提升对多语言实体的理解，且对多语言能力较弱模型帮助更大。

Conclusion: MERLIN多语言多模态实体链接测试集为该领域的研究提供了标准数据和评测基准，有助于推动多语言多模态信息理解技术发展。视觉数据的加入对提升实体链接结果具有重要意义，尤其适用于低资源和文本模糊场景。

Abstract: This paper introduces MERLIN, a novel testbed system for the task of
Multilingual Multimodal Entity Linking. The created dataset includes BBC news
article titles, paired with corresponding images, in five languages: Hindi,
Japanese, Indonesian, Vietnamese, and Tamil, featuring over 7,000 named entity
mentions linked to 2,500 unique Wikidata entities. We also include several
benchmarks using multilingual and multimodal entity linking methods exploring
different language models like LLaMa-2 and Aya-23. Our findings indicate that
incorporating visual data improves the accuracy of entity linking, especially
for entities where the textual context is ambiguous or insufficient, and
particularly for models that do not have strong multilingual abilities. For the
work, the dataset, methods are available here at
https://github.com/rsathya4802/merlin

</details>


### [184] [Evaluating & Reducing Deceptive Dialogue From Language Models with Multi-turn RL](https://arxiv.org/abs/2510.14318)
*Marwa Abdulhai,Ryan Cheng,Aryansh Shrivastava,Natasha Jaques,Yarin Gal,Sergey Levine*

Main category: cs.CL

TL;DR: 本论文针对大语言模型（LLM）在对话中产生欺骗性内容的问题，提出了一种新的衡量欺骗的指标，并通过多种实验验证了主流模型的欺骗行为及其减缓方法。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型被广泛应用于客服、教育、医疗等领域，其产生欺骗性内容（无论是有意还是无意）带来了重大的安全隐患。目前LLMs在防止幻觉、虚假信息及用户操控等方面缺乏足够保障，因此评估和遏制其欺骗性输出成为紧迫需求。

Method: 作者提出了新的belief misalignment metric用于量化对话中的欺骗性。同时，结合五种现有的欺骗检测指标，在四种典型对话场景下对八个主流大语言模型进行评测。此外，论文还引入了基于多轮对话的强化学习方法，对模型进行微调以减少欺骗行为。

Result: 提出的新欺骗度量指标与人类判断的相关性优于现有指标。实测显示，主流LLMs在26%的对话轮次自然表现出欺骗性行为；当被要求欺骗时，欺骗性提升达31%。那些采用RLHF（强化学习结合人类反馈）训练的模型，欺骗发生率仍高达43%。经过多轮对话强化学习微调后，模型的欺骗性行为可减少77.6%。

Conclusion: 大语言模型在对话中天然具有一定概率的欺骗性输出，主流的安全训练（如RLHF）尚不能彻底杜绝。多轮对话视角下的强化学习微调，可明显减少模型欺骗行为，推动更安全的模型部署。

Abstract: Large Language Models (LLMs) interact with millions of people worldwide in
applications such as customer support, education and healthcare. However, their
ability to produce deceptive outputs, whether intentionally or inadvertently,
poses significant safety concerns. The unpredictable nature of LLM behavior,
combined with insufficient safeguards against hallucination, misinformation,
and user manipulation, makes their misuse a serious, real-world risk. In this
paper, we investigate the extent to which LLMs engage in deception within
dialogue, and propose the belief misalignment metric to quantify deception. We
evaluate deception across four distinct dialogue scenarios, using five
established deception detection metrics and our proposed metric. Our findings
reveal this novel deception measure correlates more closely with human
judgments than any existing metrics we test. Additionally, our benchmarking of
eight state-of-the-art models indicates that LLMs naturally exhibit deceptive
behavior in approximately 26% of dialogue turns, even when prompted with
seemingly benign objectives. When prompted to deceive, LLMs are capable of
increasing deceptiveness by as much as 31% relative to baselines. Unexpectedly,
models trained with RLHF, the predominant approach for ensuring the safety of
widely-deployed LLMs, still exhibit deception at a rate of 43% on average.
Given that deception in dialogue is a behavior that develops over an
interaction history, its effective evaluation and mitigation necessitates
moving beyond single-utterance analyses. We introduce a multi-turn
reinforcement learning methodology to fine-tune LLMs to reduce deceptive
behaviors, leading to a 77.6% reduction compared to other instruction-tuned
models.

</details>


### [185] [A Robust Classification Method using Hybrid Word Embedding for Early Diagnosis of Alzheimer's Disease](https://arxiv.org/abs/2510.14332)
*Yangyang Li*

Main category: cs.CL

TL;DR: 本论文提出了一种基于混合词嵌入和参数微调的分类方法，实现了对阿尔茨海默病（AD）早期检测的高精度自动化诊断。结果表明该方法准确率达91%，AUC达97%，优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病早期诊断能够显著改善患者生活质量并减少医疗负担，而语言能力变化是AD早期的突出表现，因此利用语言特征进行早期检测具有重要意义。

Method: 作者提出将Doc2Vec和ELMo生成的词向量结合，构建混合词嵌入，通过计算句子困惑度分数并结合句法和语义语言特征，再将这些特征输入到逻辑回归模型中。整个分类流程中的超参数（如模型正则化、学习率、Doc2Vec和ELMo的向量维数等）都进行了系统微调。

Result: 该方法在区分AD患者和健康人的实验中，实现了91%的分类准确率和97%的AUC，显著优于当前最优的NLP方法（88%准确率）。多次随机划分数据重复实验后，模型表现稳定（准确率标准差0.0403，AUC标准差0.0174）。

Conclusion: 所提出模型不仅准确而且稳定，可用于AD大规模筛查或作为医生诊断的有效辅助手段，对早期发现和干预AD具有重要应用价值。

Abstract: Early detection of Alzheimer's Disease (AD) is greatly beneficial to AD
patients, leading to early treatments that lessen symptoms and alleviating
financial burden of health care. As one of the leading signs of AD, language
capability changes can be used for early diagnosis of AD. In this paper, I
develop a robust classification method using hybrid word embedding and
fine-tuned hyperparameters to achieve state-of-the-art accuracy in the early
detection of AD. Specifically, we create a hybrid word embedding based on word
vectors from Doc2Vec and ELMo to obtain perplexity scores of the sentences. The
scores identify whether a sentence is fluent or not and capture semantic
context of the sentences. I enrich the word embedding by adding linguistic
features to analyze syntax and semantics. Further, we input an embedded feature
vector into logistic regression and fine tune hyperparameters throughout the
pipeline. By tuning hyperparameters of the machine learning pipeline (e.g.,
model regularization parameter, learning rate and vector size of Doc2Vec, and
vector size of ELMo), I achieve 91% classification accuracy and an Area Under
the Curve (AUC) of 97% in distinguishing early AD from healthy subjects. Based
on my knowledge, my model with 91% accuracy and 97% AUC outperforms the best
existing NLP model for AD diagnosis with an accuracy of 88% [32]. I study the
model stability through repeated experiments and find that the model is stable
even though the training data is split randomly (standard deviation of accuracy
= 0.0403; standard deviation of AUC = 0.0174). This affirms our proposed method
is accurate and stable. This model can be used as a large-scale screening
method for AD, as well as a complementary examination for doctors to detect AD.

</details>


### [186] [Beyond One World: Benchmarking Super Heros in Role-Playing Across Multiversal Contexts](https://arxiv.org/abs/2510.14351)
*Perapard Ngokpol,Kun Kerdthaisong,Pasin Buakhaw,Pitikorn Khlaisamniang,Supasate Vorathammathorn,Piyalitt Ittichaiwong,Nutchanon Yongsatianchot*

Main category: cs.CL

TL;DR: 本文提出了Beyond One World基准，用于评估大语言模型在不同宇宙下扮演特定角色（如超级英雄不同版本）的一致性和可信度。通过面对关键事件和道德困境，衡量模型的角色理解和推理与行动的一致性。结果显示，当前模型在多版本角色迁移和思考-行为统一方面仍存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型广泛应用于角色扮演，但其在诠释拥有多重设定与个性（如不同宇宙中的超级英雄）角色方面的能力尚未被充分测试。鉴于这一挑战，作者希望通过有代表性的基准系统性评估模型在角色一致性、推理和行为上的表现。

Method: 作者建立了Beyond One World基准，涵盖30位超级英雄及其90种宇宙特定版本，设计了两项任务：（1）关键事件任务，考察模型对角色重要事实的记忆力；（2）道德困境任务，评估模型在道德困境中的推理与决策。同时引入“Think-Act Matching”指标，衡量模型内部理由与外部行为的一致性。实验基于不同能力的大模型进行全面对比分析。

Result: 实验发现：（1）链式推理提示能增强弱模型的叙述一致性，但对强模型可能降低其对原作的还原度；（2）同一角色的不同版本间迁移能力较弱，体现多版本一致性难题；（3）模型普遍只能在思考或行动某一方面表现优异，难兼顾两者。

Conclusion: 当前大语言模型在面对多版本角色时，存在原作一致性不足和推理-行为脱节的问题，Beyond One World为此类挑战性评测提供了新基准，有助于未来提高模型在复杂角色扮演场景下的可信度与表现力。

Abstract: Large language models (LLMs) are increasingly used as role-playing agents,
yet their capacity to faithfully and consistently portray version-specific
characters -- for example, superheroes across comic and cinematic universes --
remains underexplored. Superhero canons such as Marvel and DC provide a rich
testbed: decades of storytelling yield multiple incarnations of the same
character with distinct histories, values, and moral codes. To study this
problem, we introduce Beyond One World, a benchmark for character-grounded
roleplay spanning 30 iconic heroes and 90 canon-specific versions. The
benchmark comprises two tasks: (i) Canon Events, which probes factual recall of
pivotal life stages, and (ii) Moral Dilemmas, which confronts models with
ethically charged scenarios. We score responses for canonical accuracy and
reasoning fidelity under a framework that separates internal deliberation
("thinking") from outward decisions ("acting"). We further propose Think-Act
Matching, a metric that quantifies alignment between reasons and actions and
serves as a proxy for model trustworthiness. Experiments across reasoning- and
non-reasoning-oriented models yield three findings: (1) chain-of-thought
prompting improves narrative coherence in weaker models but can reduce
canonical accuracy in stronger ones; (2) cross-version generalization within a
character remains a major obstacle; and (3) models often excel at either
thinking or acting, but rarely both. Beyond One World exposes critical gaps in
multiversal consistency and reasoning alignment, offering a challenging
evaluation for role-playing LLMs.

</details>


### [187] [CURE: Confidence-driven Unified Reasoning Ensemble Framework for Medical Question Answering](https://arxiv.org/abs/2510.14353)
*Ziad Elshaer,Essam A. Rashed*

Main category: cs.CL

TL;DR: 该论文提出了一种基于置信度驱动的多模型框架，用于在无需微调的情况下提升医疗问答的性能，降低资源门槛。


<details>
  <summary>Details</summary>
Motivation: 高性能的医疗大语言模型（LLM）通常需要大量微调和算力，这对资源有限的医疗机构来说是一大障碍。作者希望探索一种不依赖重度微调的方案，提高模型的易用性和普及性。

Method: 提出了一个两阶段的多模型协同框架。第一阶段，置信度检测模块判断主模型（如Qwen3-30B-A3B-Instruct）的答案是否有信心；第二阶段，若置信度低，则通过自适应路由，分发给具有互补知识的辅助模型（Phi-4 14B、Gemma 2 12B）共同推理。实验基于MedQA、MedMCQA和PubMedQA三个医疗基准进行评估，并做了消融实验分析。

Result: 该多模型协作方法取得了有竞争力的结果，特别是在PubMedQA（95.0%）和MedMCQA（78.0%）上表现优秀。消融实验显示，置信度感知的路由和多模型协同显著优于单模型或平均路由方法。

Conclusion: 论文证明，基于置信度感知的多模型协作框架无须大规模微调也能有效提升医疗AI问答性能，为低资源环境下普及高水平医疗AI提供了便捷、经济的解决方案。

Abstract: High-performing medical Large Language Models (LLMs) typically require
extensive fine-tuning with substantial computational resources, limiting
accessibility for resource-constrained healthcare institutions. This study
introduces a confidence-driven multi-model framework that leverages model
diversity to enhance medical question answering without fine-tuning. Our
framework employs a two-stage architecture: a confidence detection module
assesses the primary model's certainty, and an adaptive routing mechanism
directs low-confidence queries to Helper models with complementary knowledge
for collaborative reasoning. We evaluate our approach using
Qwen3-30B-A3B-Instruct, Phi-4 14B, and Gemma 2 12B across three medical
benchmarks; MedQA, MedMCQA, and PubMedQA. Result demonstrate that our framework
achieves competitive performance, with particularly strong results in PubMedQA
(95.0\%) and MedMCQA (78.0\%). Ablation studies confirm that confidence-aware
routing combined with multi-model collaboration substantially outperforms
single-model approaches and uniform reasoning strategies. This work establishes
that strategic model collaboration offers a practical, computationally
efficient pathway to improve medical AI systems, with significant implications
for democratizing access to advanced medical AI in resource-limited settings.

</details>


### [188] [On the Ability of LLMs to Handle Character-Level Perturbations: How Well and How?](https://arxiv.org/abs/2510.14365)
*Anyun Zhuo,Xuefei Ning,Ningyuan Li,Yu Wang,Pinyan Lu*

Main category: cs.CL

TL;DR: 本论文评估了当前大语言模型（LLM）在面对频繁且结构化的字符级扰动时的鲁棒性，并提出通过插入不可见Unicode控制字符来防止滥用LLM的方法。结果显示许多LLM在遭遇强扰动时依然表现出色，暗示其在字符级噪声环境下的顽强适应力。


<details>
  <summary>Details</summary>
Motivation: 随着LLM被广泛应用于如在线考试等场景，防止其被滥用（如作弊）变得尤为重要。字符级噪声插入是一种可能实用的防护机制，故该工作评估其有效性与模型顽强性。

Method: 提出名为\nameshort{}的方法，通过每个字符后插入不可见控制字符制造结构化噪声，并在多种LLM、多种问题和不同噪声条件下系统评估其对LLM输出表现的影响。此外，分析模型对字符级分词的处理，以及LLM的隐式和显式去噪机制。

Result: 即使在分割分词并大幅降噪信噪比的强扰动下，多数LLM仍展现出不俗的鲁棒性。细致分析了模型顽强机制的存在与表现。

Conclusion: 当下LLM在低层字符级干扰下仍能保持较好输出，展现较高的误用风险。该发现对LLM在不同实际应用下的可靠性和安全部署有重要启示。

Abstract: This work investigates the resilience of contemporary LLMs against frequent
and structured character-level perturbations, specifically through the
insertion of noisy characters after each input character. We introduce
\nameshort{}, a practical method that inserts invisible Unicode control
characters into text to discourage LLM misuse in scenarios such as online exam
systems. Surprisingly, despite strong obfuscation that fragments tokenization
and reduces the signal-to-noise ratio significantly, many LLMs still maintain
notable performance. Through comprehensive evaluation across model-, problem-,
and noise-related configurations, we examine the extent and mechanisms of this
robustness, exploring both the handling of character-level tokenization and
\textit{implicit} versus \textit{explicit} denoising mechanism hypotheses of
character-level noises. We hope our findings on the low-level robustness of
LLMs will shed light on the risks of their misuse and on the reliability of
deploying LLMs across diverse applications.

</details>


### [189] [From Binary to Bilingual: How the National Weather Service is Using Artificial Intelligence to Develop a Comprehensive Translation Program](https://arxiv.org/abs/2510.14369)
*Joseph E. Trujillo-Falcon,Monica L. Bozeman,Liam E. Llewellyn,Samuel T. Halvorson,Meryl Mizell,Stuti Deshpande,Bob Manning,Todd Fagin*

Main category: cs.CL

TL;DR: 美国国家气象局（NWS）开发了一套基于人工智能的自动翻译系统，以提升其天气预警和服务的多语言覆盖能力。该系统已在多种常用非英语语言中测试，并上线实验性平台，为更广泛人群提供及时、准确的气象信息。


<details>
  <summary>Details</summary>
Motivation: 美国有约6880万人在家不讲英语，语言障碍影响他们及时获取气象预警，NWS希望通过自动化翻译工具更好地为这些少数族裔及非英语社区服务，提升全国应对气象灾害的准备水平。

Method: NWS与LILT公司合作，使用其专利的大型语言模型（LLMs）和神经机器翻译（NMT）技术，针对气象术语和消息进行定制化训练。利用GIS地图识别全美各地的语言需求，优先开发西班牙语、简体中文、越南语等版本。此外，在系统设计中全面融入伦理AI原则，确保自动翻译过程的透明、公平和人工监管。

Result: 系统能高效、准确且具文化适应性的翻译气象产品，显著减少人工翻译时间，减轻NWS各地工作负担。网站已发布包含多语言预警、7天天气预报和宣传材料的实验性气象服务。

Conclusion: NWS的多语言自动翻译计划加强了对非英语社区的服务，有望促进气象灾害信息在全美范围内的公平获取，朝着覆盖所有美国人的国家级预警系统迈进。

Abstract: To advance a Weather-Ready Nation, the National Weather Service (NWS) is
developing a systematic translation program to better serve the 68.8 million
people in the U.S. who do not speak English at home. This article outlines the
foundation of an automated translation tool for NWS products, powered by
artificial intelligence. The NWS has partnered with LILT, whose patented
training process enables large language models (LLMs) to adapt neural machine
translation (NMT) tools for weather terminology and messaging. Designed for
scalability across Weather Forecast Offices (WFOs) and National Centers, the
system is currently being developed in Spanish, Simplified Chinese, Vietnamese,
and other widely spoken non-English languages. Rooted in best practices for
multilingual risk communication, the system provides accurate, timely, and
culturally relevant translations, significantly reducing manual translation
time and easing operational workloads across the NWS. To guide the distribution
of these products, GIS mapping was used to identify language needs across
different NWS regions, helping prioritize resources for the communities that
need them most. We also integrated ethical AI practices throughout the
program's design, ensuring that transparency, fairness, and human oversight
guide how automated translations are created, evaluated, and shared with the
public. This work has culminated into a website featuring experimental
multilingual NWS products, including translated warnings, 7-day forecasts, and
educational campaigns, bringing the country one step closer to a national
warning system that reaches all Americans.

</details>


### [190] [PluriHop: Exhaustive, Recall-Sensitive QA over Distractor-Rich Corpora](https://arxiv.org/abs/2510.14377)
*Mykolas Sveistrys,Richard Kunert*

Main category: cs.CL

TL;DR: 本文提出了“pluri-hop”问答任务，并构建PluriHopWIND数据集，发现传统RAG以及其变体对该任务表现不佳，提出了PluriHopRAG新方法，大幅提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型和RAG方法主要针对单跳或多跳问答，但实际场景中许多问题（如医疗记录、合规报告等）需在大量重复性强的文档中跨文档聚合信息，这些问答需求对检索完整性和精确性极高，现有方法难以胜任。

Method: 1）定义了“pluri-hop”问答标准（召回敏感性、全面性、精确性）；2）构建了多语种PluriHopWIND数据集，覆盖191份风电行业文档和48个问题；3）评测了传统RAG、图结构RAG和多模态变体；4）提出PluriHopRAG方法，将查询分解为文档级子问题，并用cross-encoder过滤无关文档再做推理。

Result: PluriHopWIND更能反映真实场景挑战（数据更加重复、干扰文档多），在该数据集上，现有方法F1分数均未超40%；PluriHopRAG方法F1相对提升18-52%。

Conclusion: 当前主流QA系统在高重复、干扰多的报告类语料上表现有限，PluriHopRAG展示了“全面检索+早期过滤”方法在复杂多文档问答上的优越性，相较传统top-k方法更具竞争力。

Abstract: Recent advances in large language models (LLMs) and retrieval-augmented
generation (RAG) have enabled progress on question answering (QA) when relevant
evidence is in one (single-hop) or multiple (multi-hop) passages. Yet many
realistic questions about recurring report data - medical records, compliance
filings, maintenance logs - require aggregation across all documents, with no
clear stopping point for retrieval and high sensitivity to even one missed
passage. We term these pluri-hop questions and formalize them by three
criteria: recall sensitivity, exhaustiveness, and exactness. To study this
setting, we introduce PluriHopWIND, a diagnostic multilingual dataset of 48
pluri-hop questions built from 191 real-world wind industry reports in German
and English. We show that PluriHopWIND is 8-40% more repetitive than other
common datasets and thus has higher density of distractor documents, better
reflecting practical challenges of recurring report corpora. We test a
traditional RAG pipeline as well as graph-based and multimodal variants, and
find that none of the tested approaches exceed 40% in statement-wise F1 score.
Motivated by this, we propose PluriHopRAG, a RAG architecture that follows a
"check all documents individually, filter cheaply" approach: it (i) decomposes
queries into document-level subquestions and (ii) uses a cross-encoder filter
to discard irrelevant documents before costly LLM reasoning. We find that
PluriHopRAG achieves relative F1 score improvements of 18-52% depending on base
LLM. Despite its modest size, PluriHopWIND exposes the limitations of current
QA systems on repetitive, distractor-rich corpora. PluriHopRAG's performance
highlights the value of exhaustive retrieval and early filtering as a powerful
alternative to top-k methods.

</details>


### [191] [Suicidal Comment Tree Dataset: Enhancing Risk Assessment and Prediction Through Contextual Analysis](https://arxiv.org/abs/2510.14395)
*Jun Li,Qun Zhao*

Main category: cs.CL

TL;DR: 本研究利用Reddit用户的历史发帖及评论树数据，进一步提升社交媒体上用户自杀风险的识别与预测准确率。


<details>
  <summary>Details</summary>
Motivation: 过去的研究主要关注单条社交媒体帖子中的自杀表达，但忽略了用户在长期交互历史中逐步暴露出来的自杀意图。为完善对用户自杀风险的评估，需要分析其发帖历史及评论树序列的演变。

Method: 作者构建了一个高质量的Reddit数据集，采纳C-SSRS（哥伦比亚自杀严重度量表）四级标签体系，对用户发帖及评论历史进行了标注。通过统计分析和大语言模型（LLMs）实验，评估了引入评论树数据对自杀风险判别和预测的影响。

Result: 实验结果表明，结合评论树的数据，大幅提升了对用户自杀风险等级的区分和预测能力。

Conclusion: 本研究验证了分析评论树历史信息可有效提升社交媒体自杀风险检测的准确性，为早期自杀干预提供了理论与数据基础。

Abstract: Suicide remains a critical global public health issue. While previous studies
have provided valuable insights into detecting suicidal expressions in
individual social media posts, limited attention has been paid to the analysis
of longitudinal, sequential comment trees for predicting a user's evolving
suicidal risk. Users, however, often reveal their intentions through historical
posts and interactive comments over time. This study addresses this gap by
investigating how the information in comment trees affects both the
discrimination and prediction of users' suicidal risk levels. We constructed a
high-quality annotated dataset, sourced from Reddit, which incorporates users'
posting history and comments, using a refined four-label annotation framework
based on the Columbia Suicide Severity Rating Scale (C-SSRS). Statistical
analysis of the dataset, along with experimental results from Large Language
Models (LLMs) experiments, demonstrates that incorporating comment trees data
significantly enhances the discrimination and prediction of user suicidal risk
levels. This research offers a novel insight to enhancing the detection
accuracy of at-risk individuals, thereby providing a valuable foundation for
early suicide intervention strategies.

</details>


### [192] [Your Next Token Prediction: A Multilingual Benchmark for Personalized Response Generation](https://arxiv.org/abs/2510.14398)
*Shiyao Ding,Takayuki Ito*

Main category: cs.CL

TL;DR: 本文提出了“Your Next Token Prediction (YNTP)”任务，通过受控的人机对话建模用户个性化表达，并构建了跨英、日、中三语种的对话基准数据集，推动了用户对齐的语言模型研究。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLM）在通用预测任务上表现出色，但它们在生成反映个体真实交流风格的回应方面存在不足，尤其是模仿用户个性化的邮箱或社交媒体回复。由于隐私问题，真实的社交和邮件历史难以收集，因此需要新方法研究用户风格化的自然生成。

Method: 提出YNTP任务，设计基于MBTI人格的心理模拟NPC，与用户进行为期五天的受控对话，采集涵盖英语、日语和中文的100个多语种对话会话，捕捉生活化自然对话。采用prompt式和微调式个性化方法进行建模和评估，并首次建立该任务的基准。

Result: 构建了公开的多语言对话数据集，并通过prompts和微调两种方法验证了基准，展示了任务的可行性以及不同个性化策略下的性能对比。

Conclusion: YNTP任务和数据集为解决LLM用户风格化生成能力不足提供了新的研究方向，建立了衡量模型用户对齐能力的基础，有助于推动更加个性化和自然的人机交互语言模型的发展。

Abstract: Large language models (LLMs) excel at general next-token prediction but still
struggle to generate responses that reflect how individuals truly communicate,
such as replying to emails or social messages in their own style. However, real
SNS or email histories are difficult to collect due to privacy concerns. To
address this, we propose the task of "Your Next Token Prediction (YNTP)", which
models a user's precise word choices through controlled human-agent
conversations. We build a multilingual benchmark of 100 dialogue sessions
across English, Japanese, and Chinese, where users interact for five days with
psychologically grounded NPCs based on MBTI dimensions. This setup captures
natural, daily-life communication patterns and enables analysis of users'
internal models. We evaluate prompt-based and fine-tuning-based personalization
methods, establishing the first benchmark for YNTP and a foundation for
user-aligned language modeling. The dataset is available at:
https://github.com/AnonymousHub4Submissions/your-next-token-prediction-dataset-100

</details>


### [193] [MedTrust-RAG: Evidence Verification and Trust Alignment for Biomedical Question Answering](https://arxiv.org/abs/2510.14400)
*Yingpeng Ning,Yuanyuan Sun,Ling Luo,Yanhua Wang,Yuchen Pan,Hongfei Lin*

Main category: cs.CL

TL;DR: 本文提出了一种名为MedTrust-Guided Iterative RAG的医学问答系统，通过三大创新手段有效提升医学生物领域大模型问答的事实一致性，显著减少虚假内容生成，实验验证了该方法对主流模型均有提升。


<details>
  <summary>Details</summary>
Motivation: 现有医学生物领域基于RAG的问答系统在引用外部医学文献时，容易由于检索噪声或证据验证不足而产生虚假信息，降低答案可信度，因此迫切需要提升回答的事实可靠性。

Method: 该方法有三点创新：(1) 强制要求生成内容必须有明确引用医学文献支撑，且在证据不足时用结构化的否定知识表达应答；(2) 引入迭代检索-验证流程，由验证智能体判断证据充分性并通过医学缺口分析优化查询，直到获得可靠信息；(3) 使用MedTrust-Align Module (MTAM)将带有正确证据的正例和检测到幻觉的负例结合，通过直接偏好优化提升引用一致性，并抑制虚假内容产生。

Result: 在MedMCQA、MedQA和MMLU-Med等数据集上，该方法在LLaMA3.1-8B-Instruct和Qwen3-8B模型上分别取得了2.7%和2.4%的平均准确率提升，且在多个模型架构上优于现有竞争式基线。

Conclusion: MedTrust-Guided Iterative RAG有效提升了医学问答的事实一致性和准确率，为医疗领域大模型的可信应用提供了新的技术路径。

Abstract: Biomedical question answering (QA) requires accurate interpretation of
complex medical knowledge. Large language models (LLMs) have shown promising
capabilities in this domain, with retrieval-augmented generation (RAG) systems
enhancing performance by incorporating external medical literature. However,
RAG-based approaches in biomedical QA suffer from hallucinations due to
post-retrieval noise and insufficient verification of retrieved evidence,
undermining response reliability. We propose MedTrust-Guided Iterative RAG, a
framework designed to enhance factual consistency and mitigate hallucinations
in medical QA. Our method introduces three key innovations. First, it enforces
citation-aware reasoning by requiring all generated content to be explicitly
grounded in retrieved medical documents, with structured Negative Knowledge
Assertions used when evidence is insufficient. Second, it employs an iterative
retrieval-verification process, where a verification agent assesses evidence
adequacy and refines queries through Medical Gap Analysis until reliable
information is obtained. Third, it integrates the MedTrust-Align Module (MTAM)
that combines verified positive examples with hallucination-aware negative
samples, leveraging Direct Preference Optimization to reinforce
citation-grounded reasoning while penalizing hallucination-prone response
patterns. Experiments on MedMCQA, MedQA, and MMLU-Med demonstrate that our
approach consistently outperforms competitive baselines across multiple model
architectures, achieving the best average accuracy with gains of 2.7% for
LLaMA3.1-8B-Instruct and 2.4% for Qwen3-8B.

</details>


### [194] [Instructions are all you need: Self-supervised Reinforcement Learning for Instruction Following](https://arxiv.org/abs/2510.14420)
*Qingyu Ren,Qianyu He,Bowei Zhang,Jie Zeng,Jiaqing Liang,Yanghua Xiao,Weikang Zhou,Zeye Sun,Fei Yu*

Main category: cs.CL

TL;DR: 提出了一种无需外部标签的自监督强化学习框架，通过解构约束并高效分类，提升语言模型在多约束指令跟随任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法依赖外部监督且奖励稀疏，难以处理现实应用中复杂的多约束指令。

Method: 提出自监督RL框架，从指令中直接提取奖励信号，并通过伪标签训练奖励模型。利用约束分解和高效的二元分类减轻奖励稀疏问题，提升计算效率。

Result: 在3个域内和5个域外数据集上，尤其是复杂多轮、多约束任务中，取得了显著性能提升。

Conclusion: 该方法在无需人工标签的情况下，有效提升了大模型遵循多约束指令的能力，并具有良好的通用性和开放可复现性。

Abstract: Language models often struggle to follow multi-constraint instructions that
are crucial for real-world applications. Existing reinforcement learning (RL)
approaches suffer from dependency on external supervision and sparse reward
signals from multi-constraint tasks. We propose a label-free self-supervised RL
framework that eliminates dependency on external supervision by deriving reward
signals directly from instructions and generating pseudo-labels for reward
model training. Our approach introduces constraint decomposition strategies and
efficient constraint-wise binary classification to address sparse reward
challenges while maintaining computational efficiency. Experiments show that
our approach generalizes well, achieving strong improvements across 3 in-domain
and 5 out-of-domain datasets, including challenging agentic and multi-turn
instruction following. The data and code are publicly available at
https://github.com/Rainier-rq/verl-if

</details>


### [195] [Explore to Evolve: Scaling Evolved Aggregation Logic via Proactive Online Exploration for Deep Research Agents](https://arxiv.org/abs/2510.14438)
*Rui Wang,Ce Zhang,Jun-Yu Ma,Jianshu Zhang,Hongru Wang,Yi Chen,Boyang Xue,Tianqing Fang,Zhisong Zhang,Hongming Zhang,Haitao Mi,Dong Yu,Kam-Fai Wong*

Main category: cs.CL

TL;DR: 现有深度研究型Web智能体过度关注于信息检索而忽视了关键信息聚合问题。本文提出了一种“探索以进化”（Explore to Evolve）新范式，自动化构建可验证的Web智能体训练数据集，并开发了新模型与评测集，推动了Web智能体在信息聚合方向的性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前开源Web智能体主要增强了信息定位能力，但缺少对多源数据进行知识聚合分析的能力，限制了它们在支持深度科研时的表现。为解决这一瓶颈，作者提出了以信息聚合为核心的新型构建与训练方法。

Method: 首先，智能体主动探索真实Web环境并收集相关证据。然后通过自进化机制组合12种高层逻辑操作动态生成信息聚合的QA对，形成大规模数据集WebAggregatorQA。依托开源框架SmolAgents，采集训练轨迹并微调形成WebAggregator系列模型，并构建了聚合能力评测集。

Result: WebAggregator-8B模型已达到GPT-4.1水平，32B版本在GAIA-text基准上比GPT-4.1高10%，并接近Claude-3.7-sonnet；在特殊设计的聚合能力测试集上，Claude-3.7-sonnet和GPT-4.1的表现均不足30%，显示现有大模型聚合能力弱。

Conclusion: 当前主流大模型在Web信息聚合任务上表现有限。本文的“探索以进化”范式与新数据集、模型大幅提升了智能体在该任务中的深度聚合能力，为相关领域发展提供了新方法和基准。

Abstract: Deep research web agents not only retrieve information from diverse sources
such as web environments, files, and multimodal inputs, but more importantly,
they need to rigorously analyze and aggregate knowledge for insightful
research. However, existing open-source deep research agents predominantly
focus on enhancing information-seeking capabilities of web agents to locate
specific information, while overlooking the essential need for information
aggregation, which would limit their ability to support in-depth research. We
propose an Explore to Evolve paradigm to scalably construct verifiable training
data for web agents. Begins with proactive online exploration, an agent sources
grounded information by exploring the real web. Using the collected evidence,
the agent then self-evolves an aggregation program by selecting, composing, and
refining operations from 12 high-level logical types to synthesize a verifiable
QA pair. This evolution from high-level guidance to concrete operations allowed
us to scalably produce WebAggregatorQA, a dataset of 10K samples across 50K
websites and 11 domains. Based on an open-source agent framework, SmolAgents,
we collect supervised fine-tuning trajectories to develop a series of
foundation models, WebAggregator. WebAggregator-8B matches the performance of
GPT-4.1, while the 32B variant surpasses GPT-4.1 by more than 10% on GAIA-text
and closely approaches Claude-3.7-sonnet. Moreover, given the limited
availability of benchmarks that evaluate web agents' information aggregation
abilities, we construct a human-annotated evaluation split of WebAggregatorQA
as a challenging test set. On this benchmark, Claude-3.7-sonnet only achieves
28%, and GPT-4.1 scores 25.8%. Even when agents manage to retrieve all
references, they still struggle on WebAggregatorQA, highlighting the need to
strengthen the information aggregation capabilities of web agent foundations.

</details>


### [196] [Natural Language Tools: A Natural Language Approach to Tool Calling In Large Language Agents](https://arxiv.org/abs/2510.14453)
*Reid T. Johnson,Michelle D. Pain,Jordan D. West*

Main category: cs.CL

TL;DR: 该论文提出了Natural Language Tools（NLT）框架，用自然语言替代大型语言模型（LLM）中对JSON工具的程序化调用，有效提升了工具调用的准确率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在工具调用时，受制于程序化的JSON格式，常出现任务干扰和输出格式约束，导致调用性能下降，尤其对开源模型影响更大。作者希望通过更自然的交互方式改善这一局限。

Method: NLT框架将工具选择过程与响应生成过程解耦，并让LLM使用自然语言输出工具调用请求，而非结构化的JSON格式。作者对10种模型、6,400个实验（涵盖客服与心理健康领域）进行了大量评估，并测试了模型在不同训练和微调阶段下的表现。

Result: NLT框架提升了工具调用准确率18.4个百分点，输出方差降低70%。开源权重模型提高最大，甚至超过商业旗舰型闭源模型。该方法对提示扰动具有鲁棒性，并能扩展不原生支持工具调用的模型能力。

Conclusion: NLT框架有效替代了现有的JSON工具调用方式，显著提升了模型工具调用的可靠性和性能，为后续模型训练与升级提供了新思路，尤其对开源模型帮助突出，也扩展了工具调用的适用范围。

Abstract: We present Natural Language Tools (NLT), a framework that replaces
programmatic JSON tool calling in large language models (LLMs) with natural
language outputs. By decoupling tool selection from response generation, NLT
eliminates task interference and format constraints that degrade tool call
performance. When evaluated across 10 models and 6,400 trials spanning customer
service and mental health domains, NLT improves tool calling accuracy by 18.4
percentage points while reducing output variance by 70%. Open-weight models see
the largest gains, surpassing flagship closed-weight alternatives, with
implications for model training in both reinforcement learning and supervised
fine-tuning stages. These improvements persist under prompt perturbations and
extend tool-calling capabilities to models lacking native support.

</details>


### [197] [LiRA: Linguistic Robust Anchoring for Cross-lingual Large Language Models](https://arxiv.org/abs/2510.14466)
*Haolin Li,Haipeng Zhang,Mang Li,Yaohua Wang,Lijie Wen,Yu Zhang,Biqing Huang*

Main category: cs.CL

TL;DR: 本文提出了LiRA框架，能够显著提升大语言模型在低资源语言上的表示、检索与推理能力。通过Arca和LaSR两个模块，改善跨语言对齐，提升多语言任务的稳健性。实验显示方法优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在高资源语言上表现优秀，但在低资源语言上因数据稀缺、翻译噪声和跨语言对齐不稳定而表现不佳。作者希望解决低资源语言下大模型跨语言表示和推理弱的问题。

Method: LiRA框架由两个核心模块组成：1）Arca模块将低资源语言锚定对齐到英文语义空间，通过锚点和多智能体协同编码实现几何特性保持；2）LaSR模块基于Arca输出增加轻量推理头并用一致性正则化，统一优化目标，提升多语言理解和推理能力。此外，作者还构建并发布多语种产品检索数据集。

Result: 在跨语言检索、语义相似度、推理等低资源语言基准测试上，LiRA在少样本环境和加噪声情况下表现出更优性能和鲁棒性。消融实验证实Arca和LaSR都有显著贡献。

Conclusion: LiRA在改善低资源语言下的多语言检索和推理能力方面成效显著，为大语言模型的多语种稳健性提供了新方法，并推动低资源语言处理能力发展。相关代码和数据集将开源，便于学术社区进一步研究。

Abstract: As large language models (LLMs) rapidly advance, performance on high-resource
languages (e.g., English, Chinese) is nearing saturation, yet remains
substantially lower for low-resource languages (e.g., Urdu, Thai) due to
limited training data, machine-translation noise, and unstable cross-lingual
alignment. We introduce LiRA (Linguistic Robust Anchoring for Large Language
Models), a training framework that robustly improves cross-lingual
representations under low-resource conditions while jointly strengthening
retrieval and reasoning. LiRA comprises two modules: (i) Arca (Anchored
Representation Composition Architecture), which anchors low-resource languages
to an English semantic space via anchor-based alignment and multi-agent
collaborative encoding, preserving geometric stability in a shared embedding
space; and (ii) LaSR (Language-coupled Semantic Reasoner), which adds a
language-aware lightweight reasoning head with consistency regularization on
top of Arca's multilingual representations, unifying the training objective to
enhance cross-lingual understanding, retrieval, and reasoning robustness. We
further construct and release a multilingual product retrieval dataset covering
five Southeast Asian and two South Asian languages. Experiments across
low-resource benchmarks (cross-lingual retrieval, semantic similarity, and
reasoning) show consistent gains and robustness under few-shot and
noise-amplified settings; ablations validate the contribution of both Arca and
LaSR. Code will be released on GitHub and the dataset on Hugging Face.

</details>


### [198] [Efficient Seq2seq Coreference Resolution Using Entity Representations](https://arxiv.org/abs/2510.14504)
*Matt Grenander,Shay B. Cohen,Mark Steedman*

Main category: cs.CL

TL;DR: 该论文提出了一种新的压缩表示方法，用于提升seq2seq指代消解模型在增量场景下的效率，同时基本保持性能。


<details>
  <summary>Details</summary>
Motivation: 当前的seq2seq指代消解模型虽然取得了新的性能高度，但在处理对话等需逐步增量处理文本的场景时效率低、灵活性差。

Method: 论文通过提取和重组实体级别的token，并丢弃大部分无关token，来实现输入的高效压缩，从而提升seq2seq模型在增量场景下的性能。

Result: 在OntoNotes数据集上，所提模型仅比增量基线低0.6个CoNLL F1分，但输入压缩比达到1.8。在LitBank数据集上（标注了单例指代），性能超越了已有最优模型。

Conclusion: 大幅度丢弃无关token是一种可行的、能够提升seq2seq方法在增量指代消解场景下效率的策略，且基本不损失性能。

Abstract: Seq2seq coreference models have introduced a new paradigm for coreference
resolution by learning to generate text corresponding to coreference labels,
without requiring task-specific parameters. While these models achieve new
state-of-the-art performance, they do so at the cost of flexibility and
efficiency. In particular, they do not efficiently handle incremental settings
such as dialogue, where text must processed sequentially. We propose a
compressed representation in order to improve the efficiency of these methods
in incremental settings. Our method works by extracting and re-organizing
entity-level tokens, and discarding the majority of other input tokens. On
OntoNotes, our best model achieves just 0.6 CoNLL F1 points below a
full-prefix, incremental baseline while achieving a compression ratio of 1.8.
On LitBank, where singleton mentions are annotated, it passes state-of-the-art
performance. Our results indicate that discarding a wide portion of tokens in
seq2seq resolvers is a feasible strategy for incremental coreference
resolution.

</details>


### [199] [Assessing Socio-Cultural Alignment and Technical Safety of Sovereign LLMs](https://arxiv.org/abs/2510.14565)
*Kyubyung Chae,Gihoon Kim,Gyuseong Lee,Taesup Kim,Jaejin Lee,Heejin Kim*

Main category: cs.CL

TL;DR: 该论文关注主权大模型（sovereign LLMs）的发展，提出分析框架和数据集评估其社会文化适应性与技术安全性，发现现有模型在满足用户需求和安全方面仍有不足。


<details>
  <summary>Details</summary>
Motivation: 当前全球对于发展本国或本地区特色的主权大语言模型兴趣浓厚，但缺少系统的评估模型与数据集，尤其是在社会文化契合度及技术稳健性方面。

Method: 作者构建了一个新数据集，并提出分析框架，从社会文化要素及技术稳健性两个角度抽取并评估主权大模型的表现。

Result: 实验证明，主权大模型对于低资源语言具有重要作用，但并不总能很好地服务于目标用户。盲目追求“主权模型一定更适合本地用户”的观点可能低估了安全等重要质量属性。

Conclusion: 推动主权大模型发展需在评估上纳入更多、更加实际和扎实的标准，避免过于狭隘的考量。

Abstract: Recent trends in LLMs development clearly show growing interest in the use
and application of sovereign LLMs. The global debate over sovereign LLMs
highlights the need for governments to develop their LLMs, tailored to their
unique socio-cultural and historical contexts. However, there remains a
shortage of frameworks and datasets to verify two critical questions: (1) how
well these models align with users' socio-cultural backgrounds, and (2) whether
they maintain safety and technical robustness without exposing users to
potential harms and risks. To address this gap, we construct a new dataset and
introduce an analytic framework for extracting and evaluating the
socio-cultural elements of sovereign LLMs, alongside assessments of their
technical robustness. Our experimental results demonstrate that while sovereign
LLMs play a meaningful role in supporting low-resource languages, they do not
always meet the popular claim that these models serve their target users well.
We also show that pursuing this untested claim may lead to underestimating
critical quality attributes such as safety. Our study suggests that advancing
sovereign LLMs requires a more extensive evaluation that incorporates a broader
range of well-grounded and practical criteria.

</details>


### [200] [Beyond Correctness: Evaluating Subjective Writing Preferences Across Cultures](https://arxiv.org/abs/2510.14616)
*Shuangshuang Ying,Yunwen Li,Xingwei Qu,Xin Li,Sheng Jin,Minghao Liu,Zhoufutu Wen,Xeron Du,Tianyu Zheng,Yichi Zhang,Letian Ni,Yuyang Cheng,Qiguang Chen,Jingzhe Ding,Shengda Long,Wangchunshu Zhou,Jiazhan Feng,Wanjun Zhong,Libo Qin,Ge Zhang,Wenhao Huang,Wanxiang Che,Chenghua Lin*

Main category: cs.CL

TL;DR: 当前主流偏好学习方法在失去客观质量信号时表现显著下降。本文提出WritingPreferenceBench数据集，显示现有RLHF模型在主观写作偏好识别上准确率很低，而引入推理链的生成式奖励模型表现显著更好。


<details>
  <summary>Details</summary>
Motivation: 现有偏好学习方法主要依赖于客观信号（如事实正确性），在文学创作等主观领域难以分辨高质量内容。缺乏专门评估主观创作质量的数据集和分析。

Method: 提出WritingPreferenceBench数据集（1,800个人类标注偏好对，覆盖中英文、8类创意写作）。比较了三类模型：标准RLHF奖励模型、零样本判断的语言模型、能生成推理链的奖励模型。在每对样本中控制了客观正确性、事实和长度。

Result: 传统RLHF和零样本模型准确率约为52%-54%；生成推理链的奖励模型准确率高达81.8%。各类模型在不同体裁间的准确率波动极大，单个模型同一任务准确率最低只有18.2%，最高81.8%，标准差平均10.1%。模型规模扩大不带来明显提升。

Conclusion: 传统RLHF主要学会了检测客观错误，难以捕捉主观质量（如创造力、风格和情感共鸣）。捕捉真实偏好需中间推理表示而非简单分类。

Abstract: Current preference learning methods achieve high accuracy on standard
benchmarks but exhibit significant performance degradation when objective
quality signals are removed. We introduce WritingPreferenceBench, a dataset of
1,800 human-annotated preference pairs (1,200 English, 600 Chinese) across 8
creative writing genres, where responses are matched for objective correctness,
factual accuracy, and length. On this benchmark, sequence-based reward
models--the standard architecture for RLHF--achieve only 52.7% mean accuracy,
while zero-shot language model judges perform at 53.9%. In contrast, generative
reward models that produce explicit reasoning chains achieve 81.8% accuracy. We
observe high within-model variance across genres: individual models range from
18.2% to 81.8% accuracy across different writing categories, with standard
deviations averaging 10.1%. This variance persists regardless of model scale,
with 27B parameter models showing no consistent improvement over 8B variants.
Our results suggest that current RLHF methods primarily learn to detect
objective errors rather than capture subjective quality preferences (e.g.,
creativity, stylistic flair, and emotional resonance), and that successful
preference modeling may require intermediate reasoning representations rather
than direct classification.

</details>


### [201] [Code-driven Number Sequence Calculation: Enhancing the inductive Reasoning Abilities of Large Language Models](https://arxiv.org/abs/2510.14620)
*Kedi Chen,Zhikai Lei,Xu Guo,Xuecheng Wu,Siyuan Zeng,Jianghao Yin,Yinqi Zhang,Qin Chen,Jie Zhou,Liang He,Qipeng Guo,Kai Chen,Wei Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种新的合成后训练数据集CodeSeq，专注于通过数列算法推理提升大模型的归纳推理能力，同时引入奖励机制和自我校正流程，实验证明模型在多种推理任务中的表现提升明显且泛化性更好。


<details>
  <summary>Details</summary>
Motivation: 当前归纳推理相关数据集大多关注表层规律，缺乏复杂内部结构，研究手段也基本局限于简单的提示-回复配对，缺少详细思考过程与难度控制，这限制了LLMs在归纳推理方面的进一步发展。作者希望解决这些挑战，提高模型的复杂归纳推理能力。

Method: 作者提出CodeSeq数据集，将数列问题转化为算法任务，定义一般项生成任务（GTG），通过失败案例反思和迭代修正来自动生成有监督学习数据。训练流程中还使用了一种基于案例协同可解度、结合问题通过率和自生成案例成功率的奖励机制，结合强化学习引导模型更有效地从成功与失败中学习。

Result: 实验结果表明，使用CodeSeq训练的模型在各类推理任务中表现更优，同时能够保持良好的OOD（分布外）泛化能力。

Conclusion: 作者提出的方法有效提升了大模型的归纳推理能力，并通过新型数据生成和奖励机制带来更强的泛化和自我改进能力，为大模型的系统性推理训练提供了新思路。

Abstract: Large language models (LLMs) make remarkable progress in reasoning tasks.
Among different reasoning modes, inductive reasoning, due to its better
alignment with human learning, attracts increasing interest. However, research
on inductive reasoning faces certain challenges. First, existing inductive data
mostly focuses on superficial regularities while lacking more complex internal
patterns. Second, current works merely prompt LLMs or finetune on simple
prompt-response pairs, but do not provide precise thinking processes nor
implement difficulty control. Unlike previous work, we address these challenges
by introducing \textit{CodeSeq}, a synthetic post-training dataset built from
number sequences. We package number sequences into algorithmic problems to
discover their general terms, defining a general term generation (GTG) task
correspondingly. Our pipeline generates supervised finetuning data by
reflecting on failed test cases and incorporating iterative corrections,
thereby teaching LLMs to learn autonomous case generation and self-checking.
Additionally, it leverages reinforcement learning with a novel Case-Synergy
Solvability Scaling Reward based on both solvability, estimated from the
problem pass rate, and the success rate of self-directed case generation,
enabling models to learn more effectively from both successes and failures.
Experimental results show that the models trained with \textit{CodeSeq} improve
on various reasoning tasks and can preserve the models' OOD performance.

</details>


### [202] [RLAIF-SPA: Optimizing LLM-based Emotional Speech Synthesis via RLAIF](https://arxiv.org/abs/2510.14628)
*Qing Yang,Zhenghao Liu,Junxin Wang,Yangfan Du,Pengcheng Huang,Tong Xiao*

Main category: cs.CL

TL;DR: 该论文提出了一种名为RLAIF-SPA的新框架，通过强化学习结合AI反馈来提升语音合成中的情感表现力和自然度。


<details>
  <summary>Details</summary>
Motivation: 尽管文本到语音（TTS）合成技术在中性语音方面已接近人类水平，但在表达情感方面仍有不足。现有方法通常依赖昂贵的情感标注或间接优化目标，导致生成语音情感表现力不足。

Method: RLAIF-SPA框架结合了强化学习和AI反馈，分别利用自动语音识别（ASR）和大语言模型（LLM）来直接用作奖赏信号，评判语义准确性和韵律-情感标签对齐。该方法从结构、情感、语速、音调四个维度联合优化语音生成。

Result: 在Libri Speech数据集上的实验表明，RLAIF-SPA在词错误率（WER）、语音相似性（SIM-O）和人工评价三方面均优于Chat-TTS，WER降低26.1%，SIM-O提升9.1%，人工评价提升超过10%。

Conclusion: RLAIF-SPA框架显著提升了文本到语音系统的情感表达能力和自然度，解决了传统TTS系统在情感表达上的短板。

Abstract: Text-To-Speech synthesis has achieved near-human quality in neutral speech,
but emotional expressiveness remains a challenge. Existing methods often rely
on costly emotion annotations or optimize indirect objectives that fail to
capture the emotional expressiveness and perceptual naturalness of speech,
leading to generated speech that is accurate but emotionally flat. To address
these challenges, we propose the RLAIF-SPA framework, incorporating a
Reinforcement Learning from AI Feedback (RLAIF) mechanism to employ Automatic
Speech Recognition (ASR) and Large Language Model (LLM) techniques to
respectively judge semantic accuracy and prosodic-emotional label alignment as
a direct reward for emotional expressiveness and intelligibility optimization.
Specifically, it leverages Prosodic Label Alignment to enhance expressive
quality by jointly considering semantic accuracy and prosodic-emotional
alignment along four fine-grained dimensions: Structure, Emotion, Speed, and
Tone. In addition, it incorporates Semantic Accuracy Feedback to ensure the
generation of clear and accurate speech. Experiments on the Libri Speech
dataset show that RLAIF-SPA outperforms Chat-TTS, with a 26.1% reduction in
WER, a 9.1% increase in SIM-O, and over 10% improvement in human evaluation.

</details>


### [203] [Intent Clustering with Shared Pseudo-Labels](https://arxiv.org/abs/2510.14640)
*I-Fan Lin,Faegheh Hasibi,Suzan Verberne*

Main category: cs.CL

TL;DR: 该论文提出了一种无需训练和标签的意图聚类方法，利用轻量级开源大语言模型（LLM），降低成本且提高透明度。实验证明方法简单高效，效果优于现有同类方法。


<details>
  <summary>Details</summary>
Motivation: 现有意图聚类方法多依赖昂贵且不透明的商用大模型，且通常要求提前知道聚类数，这对现实应用不友好。作者旨在提出可低成本、无需预先设定聚类数的方法。

Method: 提出用LLM为文本生成伪标签，再在这些伪标签空间中进行多标签分类。假设同一簇的文本会有更多共同标签，使用这些人类可读的伪标签让文本嵌入更聚集，实现聚类。

Result: 在四个基准数据集测试中，该方法表现出与近期基线持平甚至更优的聚类效果，同时保持了方法的简洁性和计算效率。

Conclusion: 方法适用于低资源场景，在不同模型和数据集上表现稳定，提升了维度透明性和实用性。

Abstract: In this paper, we propose an intuitive, training-free and label-free method
for intent clustering that makes minimal assumptions using lightweight and
open-source LLMs. Many current approaches rely on commercial LLMs, which are
costly, and offer limited transparency. Additionally, their methods often
explicitly depend on knowing the number of clusters in advance, which is often
not the case in realistic settings. To address these challenges, instead of
asking the LLM to match similar text directly, we first ask it to generate
pseudo-labels for each text, and then perform multi-label classification in
this pseudo-label set for each text. This approach is based on the hypothesis
that texts belonging to the same cluster will share more labels, and will
therefore be closer when encoded into embeddings. These pseudo-labels are more
human-readable than direct similarity matches. Our evaluation on four benchmark
sets shows that our approach achieves results comparable to and better than
recent baselines, while remaining simple and computationally efficient. Our
findings indicate that our method can be applied in low-resource scenarios and
is stable across multiple models and datasets.

</details>


### [204] [Supervised Fine-Tuning or Contrastive Learning? Towards Better Multimodal LLM Reranking](https://arxiv.org/abs/2510.14824)
*Ziqi Dai,Xin Zhang,Mingxin Li,Yanzhao Zhang,Dingkun Long,Pengjun Xie,Meishan Zhang,Wenjie Li,Min Zhang*

Main category: cs.CL

TL;DR: 本文比较了两种主要的信息检索重排序模型的训练目标：对比较学习（CL）与监督微调分类（SFT），并在多模态检索任务中实验，发现SFT优于CL，对未来研究有指导价值。


<details>
  <summary>Details</summary>
Motivation: 尽管对比学习（CL）在BERT编码器下表现更好，但在大语言模型（LLMs）中，分类式的SFT与模型生成机制更匹配。作者提出疑问：哪种目标更适合LLM的重排序，以及两者差异背后的机制。

Method: 作者在通用多模态检索任务（UMR）下，将CL与SFT目标分解为权重和方向，并提出统一分析框架，通过探测实验比较两者的模型更新机制。随后进行了大规模SFT训练和消融实验验证结论。

Result: 探测实验表明，SFT带来更强的权重更新机制，而优选方向上无明显优劣。最终，SFT在MRB基准上实现了新的先进性能。

Conclusion: SFT在大语言模型下的重排序任务上优于对比学习法（CL），相关机制分析和实验证明该结论，可为未来相关研究和应用提供参考。

Abstract: In information retrieval, training reranking models mainly focuses on two
types of objectives: metric learning (e.g. contrastive loss to increase the
predicted scores on relevant query-document pairs) and classification (binary
label prediction of relevance vs. irrelevance). For BERT-style encoders,
various studies have shown that contrastive learning (CL) can be more effective
than discriminative (classification) learning. However, for large language
models (LLMs), classification via supervised fine-tuning (SFT), which predicts
''yes'' (resp. ''no'') token for relevant (resp. irrelevant) pairs, appears
more promising as it aligns well with the generative nature of LLMs. This
divergence raises a central question: which objective is intrinsically better
suited to LLM-based reranking, and what mechanism underlies the difference? In
this work, we conduct a comprehensive comparison and analysis between CL and
SFT for reranking, taking the universal multimodal retrieval (UMR) as the
experimental playground. We first decompose the objectives into two components:
weight, which controls the magnitude of those updates, and direction, which
guides the model updates, then present a unified framework for understanding
their interactions. Through probing experiments, we find that SFT provides a
substantially stronger weighting scheme than CL, whereas the preferred scoring
direction shows no clear winner. Taken together, these results point to a
consistent advantage of SFT over CL for LLM reranking. To further validate our
findings, we conduct large-scale training with SFT and present new
state-of-the-art rerankers on the MRB benchmark. We also provide ablations on
SFT settings and expect our findings to benefit future research and
applications in this area.

</details>


### [205] [An Efficient Rubric-based Generative Verifier for Search-Augmented LLMs](https://arxiv.org/abs/2510.14660)
*Linyue Ma,Yilong Xu,Xiang Long,Zhi Zheng*

Main category: cs.CL

TL;DR: 本文提出了一种新的可验证范式'nugget-as-rubric'，用以构建和评估强化学习驱动的检索增强型大模型，并发布了高效的生成式验证器Search-Gen-V，提升了长文本任务的奖励建模能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于检索增强的大模型奖励建模不足，主要在于规则型奖励过于脆弱且无法处理长文本，而生成式奖励虽然更健壮但计算成本高且难以验证。亟需一种统一、可验证且适用于不同任务类型的奖励建模方法。

Method: 提出'nugget-as-rubric'范式，将原子信息点作为结构化评估标准，覆盖短文本（单一rubric）及长文本（多rubric），并设计自动rubric构建管道（通过查询重写和内容抽取），同时开发了高效的生成式验证器Search-Gen-V，采用知识蒸馏和两阶段训练方案。

Result: Search-Gen-V在不同任务中展现出强大的验证准确率，证明了'nugget-as-rubric'范式在多样化检索增强任务上的可扩展性、健壮性和高效性。

Conclusion: 'nugget-as-rubric'和Search-Gen-V为检索增强大模型带来了具有可验证性和高效构造能力的新型奖励信号，为长文本等复杂场景下的强化学习提供了强有力的工具和理论基础。

Abstract: Search augmentation empowers Large Language Models with retrieval
capabilities to overcome the limitations imposed by static parameters.
Recently, Reinforcement Learning leverages tailored reward signals as a viable
technique to enhance LLMs performing tasks involving search. However, existing
reward modeling for search-augmented LLMs faces several limitations. Rule-based
rewards, such as Exact Match, are verifiable but fragile to variations in
expression and cannot be applied to long-form workloads. In contrast,
generative rewards improve robustness, but designing verifiable and stable
rewards for long-form workloads in dynamic corpora remains challenging and also
incurs high computational costs. In this paper, we propose a unified and
verifiable paradigm, "nugget-as-rubric", which treats atomic information points
as structured evaluation criteria for different search-augmentation workloads.
Short-form tasks correspond to a single rubric, whereas long-form tasks expand
to multiple rubrics aligned with the question's information needs. To support
long-form settings, we design an automatic rubric construction pipeline based
on query rewriting, which can automatically retrieve passages relevant to each
question and extract rubrics from them, both from static corpora and from
dynamic online web content. Furthermore, we introduce \textbf{Search-Gen-V}, a
4B-parameter efficient generative verifier under our proposed verifiable
paradigm, which is trained via the idea of distillation and a two-stage
strategy. Experimental results show that Search-Gen-V achieves strong
verification accuracy across different workloads, making it a scalable, robust,
and efficient verifiable reward constructor for search-augmented LLMs.

</details>


### [206] [DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation](https://arxiv.org/abs/2510.14949)
*Yu Zhou,Sohyun An,Haikang Deng,Da Yin,Clark Peng,Cho-Jui Hsieh,Kai-Wei Chang,Nanyun Peng*

Main category: cs.CL

TL;DR: 本文探讨了主流多模态生成模型在处理英语方言文本输入时的效能，并提出了一种新方法以提升模型对方言的适应能力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态生成模型主要训练于标准英语，但实际应用中常遇到区域性英语方言，导致生成内容的准确性大幅降低。研究者希望分析模型处理方言输入的表现及改进方法。

Method: 作者构建了一个包括六种常见英语方言、4200余条验证提示的新大规模基准，并基于17种图像和视频生成模型进行评测。通过自动化与人工评测，分析模型在方言输入下的表现，并尝试微调与提示重写等常见优化方式。此外，提出了一种基于编码器的泛化缓解策略，让模型学习方言特征同时保持标准英语性能。

Result: 现有模型遇到单一方言词时，性能下降32.26%至48.17%。微调和提示重写仅带来小幅提升(<7%)且标准英语性能可能下降。提出的编码器新方法能显著提升五种方言的表现至接近标准英语（+34.4%），对标准英语性能几乎无影响。

Conclusion: 当前多模态生成模型对于英语方言支持有限，需要改进。新提出的编码器方法有效提升了多方言生成能力，且不影响标准英语表现，具有良好的实际应用前景。

Abstract: Contact languages like English exhibit rich regional variations in the form
of dialects, which are often used by dialect speakers interacting with
generative models. However, can multimodal generative models effectively
produce content given dialectal textual input? In this work, we study this
question by constructing a new large-scale benchmark spanning six common
English dialects. We work with dialect speakers to collect and verify over 4200
unique prompts and evaluate on 17 image and video generative models. Our
automatic and human evaluation results show that current state-of-the-art
multimodal generative models exhibit 32.26% to 48.17% performance degradation
when a single dialect word is used in the prompt. Common mitigation methods
such as fine-tuning and prompt rewriting can only improve dialect performance
by small margins (< 7%), while potentially incurring significant performance
degradation in Standard American English (SAE). To this end, we design a
general encoder-based mitigation strategy for multimodal generative models. Our
method teaches the model to recognize new dialect features while preserving SAE
performance. Experiments on models such as Stable Diffusion 1.5 show that our
method is able to simultaneously raise performance on five dialects to be on
par with SAE (+34.4%), while incurring near zero cost to SAE performance.

</details>


### [207] [Semantic Prosody in Machine Translation: the English-Chinese Case of Passive Structures](https://arxiv.org/abs/2510.14662)
*Xinyue Ma,Pol Pastells,Mireia Farrús,Mariona Taulé*

Main category: cs.CL

TL;DR: 本文提出了一种新方法，旨在提升机器翻译模型对语义韵律（如消极、积极色彩）的把控，尤其是在中英文翻译过程中对'被'字被动态消极语义韵律的正确表达。通过微调三种机器翻译模型，取得了明显改进。


<details>
  <summary>Details</summary>
Motivation: 语义韵律是语言单位与其共现词汇共同形成的语义色彩，同义词或直译词在不同语言中可能语义韵律不同，而现有机器翻译模型难以正确处理，导致译文不地道或语感错误。因此，提升模型对语义韵律的识别和处理能力，有助于提升翻译质量。

Method: 聚焦于汉语'被'字被动句的消极语义韵律，作者构建了中英文句对数据集，专门展示'被'字消极韵律。随后，使用该数据集对OPUS-MT、NLLB-600M和mBART50三款主流机器翻译模型进行微调，测试其在不同语境下使用'被'字结构的能力。

Result: 微调后的模型在翻译与消极内容相关的句子时，更倾向正确使用'被'字结构，而在中性或积极内容中则避免误用。同时，多语言模型NLLB-600M的这一能力还可迁移至如西-中等其他语种翻译任务。

Conclusion: 为机器翻译模型引入语义韵律知识显著提升了翻译准确性，特别是在易出现消极色彩的结构用法上。这一方法也显示出跨多语种推广的潜力，为今后提升翻译质量提供了新方向。

Abstract: Semantic prosody is a collocational meaning formed through the co-occurrence
of a linguistic unit and a consistent series of collocates, which should be
treated separately from semantic meaning. Since words that are literal
translations of each other may have different semantic prosody, more attention
should be paid to this linguistic property to generate accurate translations.
However, current machine translation models cannot handle this problem. To
bridge the gap, we propose an approach to teach machine translation models
about semantic prosody of a specific structure. We focus on Chinese BEI
passives and create a dataset of English-Chinese sentence pairs with the
purpose of demonstrating the negative semantic prosody of BEI passives. Then we
fine-tune OPUS-MT, NLLB-600M and mBART50 models with our dataset for the
English-Chinese translation task. Our results show that fine-tuned MT models
perform better on using BEI passives for translating unfavourable content and
avoid using it for neutral and favourable content. Also, in NLLB-600M, which is
a multilingual model, this knowledge of semantic prosody can be transferred
from English-Chinese translation to other language pairs, such as
Spanish-Chinese.

</details>


### [208] [Speculative Model Risk in Healthcare AI: Using Storytelling to Surface Unintended Harms](https://arxiv.org/abs/2510.14718)
*Xingmeng Zhao,Dan Schumacher,Veronica Rammouz,Anthony Rios*

Main category: cs.CL

TL;DR: 本文提出了一种以人为中心的框架，通过生成用户故事和支持多方讨论，帮助开发者在人工智能部署前更全面地思考潜在的风险和益处。研究发现，基于故事的讨论有助于拓宽参与者对风险类型的认识，相比未阅读故事的参与者，能更均衡地分布关注于多种伤害。


<details>
  <summary>Details</summary>
Motivation: AI 技术在医疗领域的迅速发展带来了诸多创新工具，但快速开发也带来偏见、隐私泄露和不平等接入等风险，尤其在忽视现实场景和多样用户需求时。现有自动检测风险的方法虽然高效，但会降低人类对危害来源和影响对象的深度理解，因此需要更人性化的风险评估方式。

Method: 提出了一个以人为本的框架，利用生成用户故事（storytelling）和多主体讨论，激发参与者创造性思考AI部署可能带来的好处和风险。通过用户研究，将阅读故事群体与未阅读故事群体进行对照，评估故事叙述对风险识别能力的影响。

Result: 实验显示，阅读用户故事的参与者能识别出更加广泛的伤害类型，其对13类伤害类型的回答分布更均匀。而未阅读故事的参与者主要关注于隐私与健康（占58.3%）。

Conclusion: 故事叙述能有效提升参与者对AI潜在风险和益处的创造性思考能力，有助于更全面、平衡地考虑技术对用户的影响。

Abstract: Artificial intelligence (AI) is rapidly transforming healthcare, enabling
fast development of tools like stress monitors, wellness trackers, and mental
health chatbots. However, rapid and low-barrier development can introduce risks
of bias, privacy violations, and unequal access, especially when systems ignore
real-world contexts and diverse user needs. Many recent methods use AI to
detect risks automatically, but this can reduce human engagement in
understanding how harms arise and who they affect. We present a human-centered
framework that generates user stories and supports multi-agent discussions to
help people think creatively about potential benefits and harms before
deployment. In a user study, participants who read stories recognized a broader
range of harms, distributing their responses more evenly across all 13 harm
types. In contrast, those who did not read stories focused primarily on privacy
and well-being (58.3%). Our findings show that storytelling helped participants
speculate about a broader range of harms and benefits and think more creatively
about AI's impact on users.

</details>


### [209] [AutoRubric-R1V: Rubric-Based Generative Rewards for Faithful Multimodal Reasoning](https://arxiv.org/abs/2510.14738)
*Mengzhao Jia,Zhihan Zhang,Ignacio Cases,Zheyuan Liu,Meng Jiang,Peng Qi*

Main category: cs.CL

TL;DR: 本文提出了AutoRubric-R1V，用自动化的评分准则和RLVR相结合，提升了多模态大模型的推理准确性与步骤一致性，并达到了SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有基于可验证奖励的强化学习（RLVR）在多步推理任务中，仅关注最终答案正确与否，造成推理链条存在虚假、非真实的中间推理步骤。作者希望解决此问题，提高推理过程的可靠性和透明度。

Method: 提出AutoRubric-R1V框架，将自动收集的基于评分准则（rubric-based）的生成式奖励整合进传统RLVR流程。其核心为可扩展的自聚合方法，无需人工标注或强力teacher模型，直接从成功推理轨迹中提取一致的中间推理节点，问题自适应生成rubric。训练时联动利用rubric奖励和结果奖励。

Result: 在六个多模态推理基准任务上实现最新SOTA（state-of-the-art）表现，并在专门评测中显著提升了推理的忠实性（faithfulness）。

Conclusion: AutoRubric-R1V既提升了推理信度，也进一步推进了多模态大模型复杂推理的研究边界，为减少虚假推理提供了自动化、可扩展的新思路。

Abstract: Multimodal large language models (MLLMs) have rapidly advanced from
perception tasks to complex multi-step reasoning, yet reinforcement learning
with verifiable rewards (RLVR) often leads to spurious reasoning since only the
final-answer correctness is rewarded. To address this limitation, we propose
AutoRubric-R1V, a framework that integrates RLVR with process-level supervision
through automatically collected rubric-based generative rewards. Our key
innovation lies in a scalable self-aggregation method that distills consistent
reasoning checkpoints from successful trajectories, enabling problem-specific
rubric construction without human annotation or stronger teacher models. By
jointly leveraging rubric-based and outcome rewards, AutoRubric-R1V achieves
state-of-the-art performance on six multimodal reasoning benchmarks and
substantially improves reasoning faithfulness in dedicated evaluations.

</details>


### [210] [Pluto: A Benchmark for Evaluating Efficiency of LLM-generated Hardware Code](https://arxiv.org/abs/2510.14756)
*Manar Abdelatty,Maryam Nouh,Jacob K. Rosenstein,Sherief Reda*

Main category: cs.CL

TL;DR: 本文提出了一种名为Pluto的新基准和评测框架，专门用于评估大型语言模型生成Verilog硬件代码时的综合效率，而不仅仅是功能正确性。实验显示当前主流LLM在综合效率方面明显低于专家设计。


<details>
  <summary>Details</summary>
Motivation: 现有基准大多仅关注Verilog代码的功能正确性，缺少对面积、延迟和功耗等硬件综合效率的全面评估，且缺乏系统化的参考实现和自验证环境。

Method: 作者构建了Pluto基准集，涵盖114个问题，为每个问题提供了自检验测试平台和多个帕累托最优的参考实现。通过该框架系统性评测了LLM生成Verilog的功能正确性和综合效率。

Result: 最新LLM在功能正确性上pass@1可达78.3%，但与专家实现相比，在面积、延迟和功耗效率上分别仅有63.8%、65.9%、64.0%。

Conclusion: 当前LLM虽然在自动生成硬件代码的功能正确性方面取得很大进展，但在综合效率方面仍明显落后。因此，需要像Pluto这样的高标准评测框架，推动LLM在硬件设计领域向更高效方向发展。

Abstract: Large Language Models (LLMs) are increasingly used to automate hardware
design tasks, including the generation of Verilog code. While early benchmarks
focus primarily on functional correctness, efficient hardware design demands
additional optimization for synthesis metrics such as area, delay, and power.
Existing benchmarks fall short in evaluating these aspects comprehensively:
they often lack optimized baselines or testbenches for verification. To address
these gaps, we present Pluto, a benchmark and evaluation framework designed to
assess the efficiency of LLM-generated Verilog designs. Pluto presents a
comprehensive evaluation set of 114 problems with self-checking testbenches and
multiple Pareto-optimal reference implementations. Experimental results show
that state-of-the-art LLMs can achieve high functional correctness, reaching
78.3\% at pass@1, but their synthesis efficiency still lags behind
expert-crafted implementations, with area efficiency of 63.8\%, delay
efficiency of 65.9\%, and power efficiency of 64.0\% at eff@1. This highlights
the need for efficiency-aware evaluation frameworks such as Pluto to drive
progress in hardware-focused LLM research.

</details>


### [211] [COIG-Writer: A High-Quality Dataset for Chinese Creative Writing with Thought Processes](https://arxiv.org/abs/2510.14763)
*Yunwen Li,Shuangshuang Ying,Xingwei Qu,Xin Li,Sheng Jin,Minghao Liu,Zhoufutu Wen,Tianyu Zheng,Xeron Du,Qiguang Chen,Jiajun Shi,Wangchunshu Zhou,Jiazhan Feng,Wanjun Zhong,Libo Qin,Stephen Huang,Wanxiang Che,Chenghua Lin,Eli Zhang*

Main category: cs.CL

TL;DR: 本文提出了COIG-Writer中文创意写作数据集，通过系统逆向工程高质量文本，采集了涵盖51个类型的1,665组"逆向工程提示-创作思路-最终文本"三元组。研究发现，有效的创意写作能力依赖过程监督与通用数据的结合，两者需保持一定比例。另外，创意能力具有文化绑定性，且词汇多样性与创作质量成反比。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在非英文环境、尤其是中文下创意写作能力受到训练数据稀缺和缺乏过程级监督的限制。现有数据集只包含输入输出对，缺乏展示创作思路细节的数据。为此，作者想建立高质量、包含详细创作过程的新型中文创作数据集，解决模型创意写作能力基础薄弱的问题。

Method: 作者开发了COIG-Writer数据集，通过逆向工程优质文本，人工还原创作提示和详细的推理过程，收集了1,665组三元组，覆盖51个写作体裁。基于这些数据，开展了对比实验，提出创意写作由叙事逻辑（过程监督）和语言表达（通用数据）两组成分，并系统评估两类数据的配比及其对模型创作表现的影响。

Result: 实验结果显示：（1）过程监督显著提升创意能力，但需配合通用数据，最佳比例约为1:12；比例过低时模型表现大幅下降。（2）创意能力具有文化（语言）内在属性，跨语种迁移效应极差。（3）词汇多样性越高，创意质量反而越差（TTR悖论），推测多样化往往是逻辑不足的补偿。

Conclusion: 优质创意写作能力产生于逻辑支撑与语言基础的相互作用，两者缺一不可；这类似于数学推理可增强但无法取代基础语言能力。COIG-Writer为研究和提升中文创意写作提供了新资源。

Abstract: Large language models exhibit systematic deficiencies in creative writing,
particularly in non-English contexts where training data is scarce and lacks
process-level supervision. We present COIG-Writer, a novel Chinese creative
writing dataset that captures both diverse outputs and their underlying thought
processes through systematic reverse-engineering of high-quality texts. Unlike
existing datasets that provide only input-output pairs, COIG-Writer comprises
1,665 meticulously curated triplets spanning 51 genres, each containing: (1) a
reverse-engineered prompt, (2) detailed creative reasoning documenting
decision-making processes, and (3) the final text. Through comprehensive
experiments, we identify a two-component model of creative writing: narrative
logic (provided by process supervision) and linguistic expression (maintained
by general-purpose data). Our findings reveal three critical insights: (1)
Process supervision is highly effective but requires stabilization with general
data. A ratio of at least one creative sample to twelve general samples is
needed to achieve optimal performance; below this threshold, the win rate
progressively degrades (from 62.75% down to 35.78%)., (2) creative capabilities
are culturally-bound with no cross-lingual transfer (89.26pp gap between
Chinese and English performance), and (3) lexical diversity inversely
correlates with creative quality (TTR paradox), suggesting high diversity
signals compensatory behavior for logical deficiencies. These findings
establish that creative excellence emerges from the interaction between logical
scaffolding and linguistic grounding, analogous to how mathematical reasoning
enhances but cannot replace linguistic competence in foundation models.

</details>


### [212] [Finding Answers in Thought Matters: Revisiting Evaluation on Large Language Models with Reasoning](https://arxiv.org/abs/2510.14773)
*Hwiyeol Jo,Joosung Lee,Jaehone Lee,Sang-Woo Lee,Joonsuk Park,Kang Min Yoo*

Main category: cs.CL

TL;DR: 本文提出了一种名为Answer Regeneration的基础框架，从而提升了对大模型（如LLMs）在需要推理能力的任务中的答案抽取和评估的鲁棒性与准确性。作者通过多次模型推理并生成答案，确保结果不依赖于具体抽取规则。


<details>
  <summary>Details</summary>
Motivation: 在现有方法中，通过对各个选项概率排序来选答案，忽略了推理型任务中答案抽取方式对模型性能的极大影响，导致问答模型的评估不鲁棒、不一致，因此迫切需要消除答案抽取算法带来的敏感性。

Method: 作者提出了Answer Regeneration方法：即利用一次额外的模型推理，将原输入及此前输出以“Answer:”为提示再次输入模型，让模型重新生成答案，然后从生成的输出中抽取最终答案，该方法不依赖具体的答案抽取规则。

Result: 实验表明，Answer Regeneration这一与抽取规则无关的方法不仅提升了效果，还增强了对评测结果的鲁棒性。作者在数学问题与开放式问答任务上均展示了其优越性。

Conclusion: 该方法及相关分析有望为生成模型评估带来更可靠与一致的结论，对整个问答及推理能力测试领域有实际促进作用。

Abstract: Evaluating generative models, such as large language models (LLMs), commonly
involves question-answering tasks where the final answer is selected based on
probability of answer choices. On the other hand, for models requiring
reasoning, the method of answer extraction plays a critical role. Our research
reveals that the performance of reasoning models and their final answer
distributions are highly sensitive to the answer extraction algorithm employed.
In order to mitigate this, we propose a basic framework: Answer Regeneration.
The method uses an additional model inference, providing the prior input and
output prefaced by the prompt "Answer:". The final answer is then selected or
extracted from the regenerated output. We show that this
extraction-rule-agnostic approach exhibits improved performance and enhanced
robustness. Furthermore, we have applied this framework to general math
problems and open-ended question answering tasks. Our analysis and this
framework could offer a more reliable results for model evaluation.

</details>


### [213] [Rewiring Experts on the Fly:Continuous Rerouting for Better Online Adaptation in Mixture-of-Expert models](https://arxiv.org/abs/2510.14853)
*Guinan Su,Yanwu Yang,Li Shen,Lu Yin,Shiwei Liu,Jonas Geiping*

Main category: cs.CL

TL;DR: 该论文提出了一种无需外部数据的在线自适应MoE路由方法，能在生成文本过程中持续优化专家选择，从而提升模型鲁棒性和性能。


<details>
  <summary>Details</summary>
Motivation: 当前Mixture-of-Experts（MoE）模型在实际部署时，路由决策容易因分布变化而失效，且现有测试时自适应方法多针对稠密模型且依赖外部数据，限制了MoE在实际应用中的效果。

Method: 提出一种无数据、在线的测试时自适应框架，仅基于输入上下文对MoE模型专家选择进行动态优化，采用轻量级加性向量仅调整选定层的router logits，且通过自监督方式在prefill阶段及后续间隔阶段轮流优化路由。

Result: 在推理任务中该方法表现出一致的性能提升，例如在OLMoE模型上HumanEval任务提升5.5%，在DeepSeek-V2-Lite结合自洽性技术时平均提升6%。

Conclusion: 该方法无需外部监督数据即可提升MoE模型路由鲁棒性和任务表现，且具备即插即用特性，可补充现有测试时扩展技术。

Abstract: Mixture-of-Experts (MoE) models achieve efficient scaling through sparse
expert activation, but often suffer from suboptimal routing decisions due to
distribution shifts in deployment. While existing test-time adaptation methods
could potentially address these issues, they primarily focus on dense models
and require access to external data, limiting their practical applicability to
MoE architectures. However, we find that, instead of relying on reference data,
we can optimize MoE expert selection on-the-fly based only on input context. As
such, we propose \textit{a data-free, online test-time framework} that
continuously adapts MoE routing decisions during text generation without
external supervision or data. Our method cycles between two phases: During the
prefill stage, and later in regular intervals, we optimize the routing
decisions of the model using self-supervision based on the already generated
sequence. Then, we generate text as normal, maintaining the modified router
until the next adaption. We implement this through lightweight additive vectors
that only update router logits in selected layers, maintaining computational
efficiency while preventing over-adaptation. The experimental results show
consistent performance gains on challenging reasoning tasks while maintaining
robustness to context shifts. For example, our method achieves a 5.5\%
improvement on HumanEval with OLMoE. Furthermore, owing to its plug-and-play
property, our method naturally complements existing test-time scaling
techniques, e.g., achieving 6\% average gains when incorporated with
self-consistency on DeepSeek-V2-Lite.

</details>


### [214] [Midtraining Bridges Pretraining and Posttraining Distributions](https://arxiv.org/abs/2510.14865)
*Emmy Liu,Graham Neubig,Chenyan Xiong*

Main category: cs.CL

TL;DR: 研究系统分析了语言模型中的midtraining（中间训练）阶段，发现其对特定领域（特别是数学和代码）效果显著，并探索了优化方式。


<details>
  <summary>Details</summary>
Motivation: 虽然许多预训练方法在后期会加入高质量、有指令格式的数据进行midtraining，但对其机制与效果至今缺乏科学理解。作者希望揭示midtraining为何有效、如何增强域适应能力。

Method: 采用从零预训练的大语言模型，并在不同领域的有监督微调数据集上进行系统性实验。比较了midtraining和传统继续预训练的效果；分析了midtraining开始时间及混合权重对代码领域任务的影响。

Result: midtraining在数学和代码领域提升明显，能有效减少预训练与微调数据间的语法差距，在域内验证损失和防止训练遗忘方面均优于仅仅继续预训练。最早引入专用数据的midtraining效果最佳，权重影响较小。

Conclusion: midtraining作为一种域适应技术，相比继续预训练，可以通过减少知识遗忘获得更优领域内性能。推荐在专业领域任务中采用早期中间训练以提升效果。

Abstract: Recently, many language models have been pretrained with a "midtraining"
phase, in which higher quality, often instruction-formatted data, is mixed in
at the end of pretraining. Despite the popularity of this practice, there is
little scientific understanding of this phase of model training or why it is
effective. In this work, we conduct the first systematic investigation of
midtraining through controlled experiments with language models pretrained from
scratch and fine-tuned on supervised finetuning datasets in different domains.
We find that when compared after supervised fine-tuning, the effectiveness of
midtraining is highest in the math and code domains, where midtraining can best
reduce the syntactic gap between pretraining and posttraining data. In these
cases, midtraining consistently outperforms continued pretraining in both
in-domain validation loss as well as pretraining data forgetting after
posttraining. We conduct ablations on the starting time of the midtraining
phase and mixture weights of the midtraining data, using code midtraining as a
case study, and find that timing has a greater impact than mixture weights,
with earlier introduction of specialized data, yielding greater benefits
in-domain as well as preserving general language modeling better. These
findings establish midtraining as a domain adaptation technique that compared
to continued pretraining yields better performance through reduced forgetting.

</details>


### [215] [From Loop Nests to Silicon: Mapping AI Workloads onto AMD NPUs with MLIR-AIR](https://arxiv.org/abs/2510.14871)
*Erwei Wang,Samuel Bayliss,Andra Bisca,Zachary Blair,Sangeeta Chowdhary,Kristof Denolf,Jeff Fifield,Brandon Freiberger,Erika Hunhoff,Phil James-Roxby,Jack Lo,Joseph Melber,Stephen Neuendorffer,Eddie Richter,Andre Rosti,Javier Setoain,Gagandeep Singh,Endri Taka,Pranathi Vasireddy,Zhewen Yu,Niansong Zhang,Jinming Zhuang*

Main category: cs.CL

TL;DR: MLIR-AIR 是一个新型的基于 MLIR 的开源编译器栈，专为桥接高层负载与精细空间架构（如 AMD NPU）而设计，有效提升了空间调度与数据管理能力。


<details>
  <summary>Details</summary>
Motivation: 现有通用编译器在并行性、本地性和同步方面抽象得较多，难以充分利用现代空间计算架构对数据移动和计算排布的精细化控制需求，因此需要开发能显式表达这些控制的编译基础设施。

Method: 提出 MLIR-AIR，定义名为 AIR 的方言，将异步和层次化算子结构化地映射到计算和存储资源、实现空间调度、任务分配与通信/计算重叠，无需手动或运行时管理。通过两个案例（矩阵乘法、多头注意力块）展示其实用性。

Result: 在矩阵乘法场景中，MLIR-AIR 实现了最高 78.7% 的计算效率，性能几乎可与手动优化的 MLIR-AIE 框架持平。多头注意力实现仅需约 150 行代码即可表示复杂计算，并高效地映射至空间硬件。

Conclusion: MLIR-AIR 能将高层结构化控制流转为高效的空间程序，通过编译器自动管理调度、异步执行、分块与通信重叠等，显著提升了 NPU 上的计算与存储资源利用效率。

Abstract: General-purpose compilers abstract away parallelism, locality, and
synchronization, limiting their effectiveness on modern spatial architectures.
As modern computing architectures increasingly rely on fine-grained control
over data movement, execution order, and compute placement for performance,
compiler infrastructure must provide explicit mechanisms for orchestrating
compute and data to fully exploit such architectures. We introduce MLIR-AIR, a
novel, open-source compiler stack built on MLIR that bridges the semantic gap
between high-level workloads and fine-grained spatial architectures such as
AMD's NPUs. MLIR-AIR defines the AIR dialect, which provides structured
representations for asynchronous and hierarchical operations across compute and
memory resources. AIR primitives allow the compiler to orchestrate spatial
scheduling, distribute computation across hardware regions, and overlap
communication with computation without relying on ad hoc runtime coordination
or manual scheduling. We demonstrate MLIR-AIR's capabilities through two case
studies: matrix multiplication and the multi-head attention block from the
LLaMA 2 model. For matrix multiplication, MLIR-AIR achieves up to 78.7% compute
efficiency and generates implementations with performance almost identical to
state-of-the-art, hand-optimized matrix multiplication written using the
lower-level, close-to-metal MLIR-AIE framework. For multi-head attention, we
demonstrate that the AIR interface supports fused implementations using
approximately 150 lines of code, enabling tractable expression of complex
workloads with efficient mapping to spatial hardware. MLIR-AIR transforms
high-level structured control flow into spatial programs that efficiently
utilize the compute fabric and memory hierarchy of an NPU, leveraging
asynchronous execution, tiling, and communication overlap through
compiler-managed scheduling.

</details>


### [216] [Harmonizing Diverse Models: A Layer-wise Merging Strategy for Consistent Generation](https://arxiv.org/abs/2510.14915)
*Xujun Peng,Anoop Kumar,Jingyu Wu,Parker Glenn,Daben Liu*

Main category: cs.CL

TL;DR: 本文提出了一种新方法，通过系统性合成数据生成、三元组损失优化嵌入以及新颖的分层模型融合，有效提升了检索增强生成（RAG）系统输出的一致性。实验表明，该方法将输出相似度提升了约47.5%。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在面对语义等价输入时输出结果表现出一致性不足，主要原因包括缺乏一致性导向的训练数据以及微调方法的局限性，这严重影响了RAG系统在实际应用中的可靠性。因此，迫切需要提升RAG系统输出一致性的实用方法。

Method: 方法包括三部分：1）系统地生成合成训练数据以聚焦一致性训练目标；2）引入三元组损失以优化嵌入空间，使得语义相似样本更接近；3）提出创新的分层模型融合方法，通过中间层激活得到一致性权重，实现多模型知识的有效整合。

Result: 融合模型在输出一致性方面较基线实现了显著提升，输出相似度提高了约47.5%。

Conclusion: 该方法切实提升了工业级RAG系统输出的一致性和可靠性，为实际应用中相关问题提供了行之有效的解决方案。

Abstract: Retrieval-Augmented Generation (RAG) systems leverage Large Language Models
(LLMs) to generate accurate and reliable responses that are grounded in
retrieved context. However, LLMs often generate inconsistent outputs for
semantically equivalent inputs, a problem compounded by the scarcity of
consistency-focused training data and the limitations of current fine-tuning
techniques in enhancing output consistency. We propose a new approach combining
systematic synthetic data generation, triplet loss for better embeddings, and a
novel layer-wise model merging approach. Using consistency-aware weights
derived from intermediate layer activations, our method effectively integrates
knowledge from specialized models. Experimental results how that our merged
model significantly enhances output consistency, achieving a ~47.5\%
improvement in response similarity over the baseline, thus offering a practical
solution for increasing the reliability of an industrial RAG system.

</details>


### [217] [Predicting Task Performance with Context-aware Scaling Laws](https://arxiv.org/abs/2510.14919)
*Kyle Montgomery,David Park,Jianhong Tu,Michael Bendersky,Beliz Gunel,Dawn Song,Chenguang Wang*

Main category: cs.CL

TL;DR: 本研究提出一个新的可解释性框架，将下游任务性能与训练算力及上下文长度关联建模，并在不同任务和Llama 2模型上进行了验证，取得了较好泛化和外推表现。


<details>
  <summary>Details</summary>
Motivation: 传统缩放法则主要关注模型规模、训练数据和算力与交叉熵损失等上游指标的关系，但无法刻画下游实际任务中上下文长度对模型性能的影响，因此需要新的建模方法。

Method: 提出并实证了一个新框架，将下游任务表现建模为训练算力和上下文长度的函数。具体在Llama-2-7B和Llama-2-13B两个不同配置下的扩展上下文模型上进行实验，测试算术推理、常识推理和机器翻译三类任务共65,500条实例，对该框架进行了拟合验证。

Result: 结果显示，该框架能准确拟合下游任务中的分布内性能，能在跨越三个数量级的训练算力下泛化，并能随上下文长度增加可靠外推对性能的预测。

Conclusion: 本文提供了训练算力与上下文利用之间的新理解，可为高效设计长上下文大模型及其在多下游任务场景中的应用提供借鉴和指导。

Abstract: Scaling laws have transformed our understanding of large language models by
linking upstream metrics like cross-entropy loss to design factors such as
model size, training data, and compute. However, these conventional laws fail
to capture downstream task performance, where context plays a critical role. In
this work, we propose a straightforward, interpretable framework that jointly
models downstream performance as a function of the training compute and the
provided context. We empirically validate our framework by fitting it on the
observed downstream performance of extended-context variants of Llama-2-7B and
Llama-2-13B across 65,500 unique instances spanning three tasks: arithmetic
reasoning, common sense reasoning, and machine translation. Our results
demonstrate that our framework accurately models in-distribution downstream
performance, generalizes across three orders of magnitude in training compute,
and reliably extrapolates performance as the amount of context increases. These
findings offer valuable insights into the interplay between training compute
and context utilization, providing guidance for designing more efficient
long-context LLMs for diverse downstream tasks. Our code is available at
https://github.com/wang-research-lab/context-scaling.

</details>


### [218] [AI-Powered Early Diagnosis of Mental Health Disorders from Real-World Clinical Conversations](https://arxiv.org/abs/2510.14937)
*Jianfeng Zhu,Julina Maharjan,Xinyu Li,Karin G. Coifman,Ruoming Jin*

Main category: cs.CL

TL;DR: 本研究探讨了基于机器学习和大语言模型的心理健康筛查工具在现实访谈资料中的表现，模型准确率高，有望改善当前心理健康障碍的漏诊与误诊问题。


<details>
  <summary>Details</summary>
Motivation: 当前心理健康障碍（如抑郁、焦虑和PTSD）经常因主观评估、资源有限和污名化等原因被误诊或漏诊，尤其在初级医疗环境中误判率超过60%，急需更高效、客观且易于推广的诊断工具。

Method: 收集553份现实半结构化访谈及其对应的抑郁、焦虑、PTSD等诊断标签，基于该数据集评估多种机器学习模型，包括对GPT-4.1 Mini和MetaLLaMA的零样本提示，以及利用LoRA的RoBERTa微调模型，分析整体和类别细分的诊断准确率和召回率，并探索不同上下文长度对模型性能的影响。

Result: 模型对各类心理健康障碍的诊断准确率普遍超过80%，PTSD识别准确率高达89%、召回率98%；缩短上下文长度能提升召回率，表明聚焦关键信息有助于提高检测敏感性。LoRA微调模型在低秩配置下依然保持高水平性能，且更高效。

Conclusion: 基于大语言模型的心理健康筛查工具有望显著优于传统自述问卷型工具，为资源受限或污名化严重环境下的早期筛查和诊疗提供了可行路径，对临床实际接轨有积极意义。

Abstract: Mental health disorders remain among the leading cause of disability
worldwide, yet conditions such as depression, anxiety, and Post-Traumatic
Stress Disorder (PTSD) are frequently underdiagnosed or misdiagnosed due to
subjective assessments, limited clinical resources, and stigma and low
awareness. In primary care settings, studies show that providers misidentify
depression or anxiety in over 60% of cases, highlighting the urgent need for
scalable, accessible, and context-aware diagnostic tools that can support early
detection and intervention. In this study, we evaluate the effectiveness of
machine learning models for mental health screening using a unique dataset of
553 real-world, semistructured interviews, each paried with ground-truth
diagnoses for major depressive episodes (MDE), anxiety disorders, and PTSD. We
benchmark multiple model classes, including zero-shot prompting with GPT-4.1
Mini and MetaLLaMA, as well as fine-tuned RoBERTa models using LowRank
Adaptation (LoRA). Our models achieve over 80% accuracy across diagnostic
categories, with especially strongperformance on PTSD (up to 89% accuracy and
98% recall). We also find that using shorter context, focused context segments
improves recall, suggesting that focused narrative cues enhance detection
sensitivity. LoRA fine-tuning proves both efficient and effective, with
lower-rank configurations (e.g., rank 8 and 16) maintaining competitive
performance across evaluation metrics. Our results demonstrate that LLM-based
models can offer substantial improvements over traditional self-report
screening tools, providing a path toward low-barrier, AI-powerd early
diagnosis. This work lays the groundwork for integrating machine learning into
real-world clinical workflows, particularly in low-resource or high-stigma
environments where access to timely mental health care is most limited.

</details>


### [219] [LaSeR: Reinforcement Learning with Last-Token Self-Rewarding](https://arxiv.org/abs/2510.14943)
*Wenkai Yang,Weijie Liu,Ruobing Xie,Yiju Guo,Lulu Wu,Saiyong Yang,Yankai Lin*

Main category: cs.CL

TL;DR: 本文提出了一种用于大语言模型（LLMs）推理增强的高效自验证强化学习方法，称为LaSeR，通过对最后一个token的概率分布进行简单处理即可实现联合优化推理与自验证能力。该方法无需复杂流程，仅需一次额外推理即可实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法虽然统一了推理与自验证，但需要两套模版依次生成答案和验证，导致效率低下。研究者希望找到更简单高效的优化方式，减少额外计算开销，同时提升模型推理与自评价能力。

Method: 作者从理论上推导出：RLVR目标的严格解可以简化为用最后一个token的self-reward分数替代完整推理奖励。具体实现为提出LaSeR算法，将原RLVR损失加上一个均方误差项（MSE），用以对齐最后一个token的self-reward与验证奖励，通过对最后token的next-token分布做一次推断即可，极大简化了过程。

Result: 实验结果显示，用LaSeR训练的LLM，不仅推理能力显著提升，同时具备强自评价能力，并且在推理规模扩展方面表现优异。推理时只需一次额外token的推断，带来了几乎无损耗的效率提升。

Conclusion: LaSeR方法通过简洁的自验证奖励机制，有效联合了推理与自评价能力，兼顾性能提升和计算效率，为大语言模型的推理优化提供了新的高效思路。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as
a core paradigm for enhancing the reasoning capabilities of Large Language
Models (LLMs). To address the lack of verification signals at test time, prior
studies incorporate the training of model's self-verification capability into
the standard RLVR process, thereby unifying reasoning and verification
capabilities within a single LLM. However, previous practice requires the LLM
to sequentially generate solutions and self-verifications using two separate
prompt templates, which significantly reduces efficiency. In this work, we
theoretically reveal that the closed-form solution to the RL objective of
self-verification can be reduced to a remarkably simple form: the true
reasoning reward of a solution is equal to its last-token self-rewarding score,
which is computed as the difference between the policy model's next-token
log-probability assigned to any pre-specified token at the solution's last
token and a pre-calculated constant, scaled by the KL coefficient. Based on
this insight, we propose LaSeR (Reinforcement Learning with Last-Token
Self-Rewarding), an algorithm that simply augments the original RLVR loss with
a MSE loss that aligns the last-token self-rewarding scores with verifier-based
reasoning rewards, jointly optimizing the reasoning and self-rewarding
capabilities of LLMs. The optimized self-rewarding scores can be utilized in
both training and testing to enhance model performance. Notably, our algorithm
derives these scores from the predicted next-token probability distribution of
the last token immediately after generation, incurring only the minimal extra
cost of one additional token inference. Experiments show that our method not
only improves the model's reasoning performance but also equips it with
remarkable self-rewarding capability, thereby boosting its inference-time
scaling performance.

</details>


### [220] [MetaBench: A Multi-task Benchmark for Assessing LLMs in Metabolomics](https://arxiv.org/abs/2510.14944)
*Yuxing Lu,Xukai Zhao,J. Ben Tamo,Micky C. Nnamdi,Rui Peng,Shuang Zeng,Xingyu Hu,Jinzhuo Wang,May D. Wang*

Main category: cs.CL

TL;DR: 该论文提出了MetaBench，这是首个用于代谢组学领域的LLM基准评测工具，系统评估了25种大语言模型在代谢组学任务中的表现，发现模型在某些任务中表现良好，但在跨数据库标识符映射等任务上仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 当前的大语言模型（LLM）虽然在一般文本领域表现出色，但其在需要深度和复杂知识的科学专业领域（如代谢组学）能力尚未明确评估。代谢组学领域本身具有复杂通路、异构标识符和分散数据库等难点，亟需开发专用的评测方法来监测AI系统能力及进展。

Method: 作者收集和整理了权威公开资源，构建了MetaBench基准，从知识、理解、数据标识符映射（grounding）、推理、科研五个维度评测模型能力，并用25个主流开放和闭源LLMs进行了系统实验对比。

Result: 实验显示，LLMs在文本生成相关的任务表现较好，但在跨数据库标识符映射方面即使结合检索增强也依然难以取得好成绩，而且在较少注释的长尾代谢物上性能进一步下降。可见现有模型还难以应对代谢组学的核心挑战。

Conclusion: MetaBench为代谢组学AI系统的开发与评估提供了重要基础设施，为构建更可靠的代谢组学计算工具铺平了道路，也推动了相关领域AI能力的系统化进步。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities on
general text; however, their proficiency in specialized scientific domains that
require deep, interconnected knowledge remains largely uncharacterized.
Metabolomics presents unique challenges with its complex biochemical pathways,
heterogeneous identifier systems, and fragmented databases. To systematically
evaluate LLM capabilities in this domain, we introduce MetaBench, the first
benchmark for metabolomics assessment. Curated from authoritative public
resources, MetaBench evaluates five capabilities essential for metabolomics
research: knowledge, understanding, grounding, reasoning, and research. Our
evaluation of 25 open- and closed-source LLMs reveals distinct performance
patterns across metabolomics tasks: while models perform well on text
generation tasks, cross-database identifier grounding remains challenging even
with retrieval augmentation. Model performance also decreases on long-tail
metabolites with sparse annotations. With MetaBench, we provide essential
infrastructure for developing and evaluating metabolomics AI systems, enabling
systematic progress toward reliable computational tools for metabolomics
research.

</details>


### [221] [Information Gain-based Policy Optimization: A Simple and Effective Approach for Multi-Turn LLM Agents](https://arxiv.org/abs/2510.14967)
*Guoqing Wang,Sunhao Dai,Guangze Ye,Zeyu Gan,Wei Yao,Yong Deng,Xiaofeng Wu,Zhenzhe Ying*

Main category: cs.CL

TL;DR: 本文提出了一种针对大语言模型多轮推理训练的新型强化学习方法IGPO，通过细粒度的信息增益奖励，有效缓解了稀疏奖励和信用分配不足的问题，显著提升了多轮任务的表现。


<details>
  <summary>Details</summary>
Motivation: 当前使用强化学习提升大语言模型用工具解决复杂任务时，往往只在最后一步给予奖励，导致在多轮长序列任务中奖励稀疏，难以精确判断每一步的贡献，影响训练与表现。

Method: 作者提出Information Gain-based Policy Optimization（IGPO）方法，将每一步视为逐步获取“真相”信息的过程，每轮的奖励定义为模型产生正确答案概率的边际提升，作为内在奖励信号，并与最终奖励联合用于训练，无需外部奖励模型和高算力采样。

Result: 实验证明，在多轮推理场景下，IGPO在域内外多个基准测试上均优于强基线模型，表现为更高准确率和更好的采样效率。

Conclusion: IGPO通过丰富且自洽的奖励设计，有效解决了多轮强化学习训练中的奖励稀疏与信用分配问题，为大模型智能体提升与泛化提供了新途径。

Abstract: Large language model (LLM)-based agents are increasingly trained with
reinforcement learning (RL) to enhance their ability to interact with external
environments through tool use, particularly in search-based settings that
require multi-turn reasoning and knowledge acquisition. However, existing
approaches typically rely on outcome-based rewards that are only provided at
the final answer. This reward sparsity becomes particularly problematic in
multi-turn settings, where long trajectories exacerbate two critical issues:
(i) advantage collapse, where all rollouts receive identical rewards and
provide no useful learning signals, and (ii) lack of fine-grained credit
assignment, where dependencies between turns are obscured, especially in
long-horizon tasks. In this paper, we propose Information Gain-based Policy
Optimization (IGPO), a simple yet effective RL framework that provides dense
and intrinsic supervision for multi-turn agent training. IGPO models each
interaction turn as an incremental process of acquiring information about the
ground truth, and defines turn-level rewards as the marginal increase in the
policy's probability of producing the correct answer. Unlike prior
process-level reward approaches that depend on external reward models or costly
Monte Carlo estimation, IGPO derives intrinsic rewards directly from the
model's own belief updates. These intrinsic turn-level rewards are combined
with outcome-level supervision to form dense reward trajectories. Extensive
experiments on both in-domain and out-of-domain benchmarks demonstrate that
IGPO consistently outperforms strong baselines in multi-turn scenarios,
achieving higher accuracy and improved sample efficiency.

</details>


### [222] [LLMs as Scalable, General-Purpose Simulators For Evolving Digital Agent Training](https://arxiv.org/abs/2510.14969)
*Yiming Wang,Da Yin,Yuedong Cui,Ruichen Zheng,Zhiqian Li,Zongyu Lin,Di Wu,Xueqing Wu,Chenchen Ye,Yu Zhou,Kai-Wei Chang*

Main category: cs.CL

TL;DR: 提出了一种新的UI轨迹合成范式（UI-Simulator），可大规模生成用于数字智能体训练的数据，提高泛化能力并降低数据采集成本。


<details>
  <summary>Details</summary>
Motivation: 现有数字智能体在UI泛化任务中需要大量真实UI操作轨迹，但人工采集与工程代价高昂，因此亟需自动化、可扩展的合成方法。

Method: 构建了UI-Simulator，结合数字世界仿真器、引导探索与轨迹包装优化流程，实现高质量多样的UI交互轨迹生成。此外，引入UI-Simulator-Grow，通过优先高影响任务、生成信息量丰富的变体，实现更高效的数据扩展。

Result: 在WebArena和AndroidWorld实验表明，UI-Simulator可与甚至超越基于真实数据训练的开源智能体，且鲁棒性更好。UI-Simulator-Grow利用较小基座模型即可达到大型模型同等性能。

Conclusion: UI-Simulator及其扩展UI-Simulator-Grow有效提升了数字智能体的训练效率和泛化能力，展示了基于合成数据扩展的新范式潜力。

Abstract: Digital agents require diverse, large-scale UI trajectories to generalize
across real-world tasks, yet collecting such data is prohibitively expensive in
both human annotation, infra and engineering perspectives. To this end, we
introduce $\textbf{UI-Simulator}$, a scalable paradigm that generates
structured UI states and transitions to synthesize training trajectories at
scale. Our paradigm integrates a digital world simulator for diverse UI states,
a guided rollout process for coherent exploration, and a trajectory wrapper
that produces high-quality and diverse trajectories for agent training. We
further propose $\textbf{UI-Simulator-Grow}$, a targeted scaling strategy that
enables more rapid and data-efficient scaling by prioritizing high-impact tasks
and synthesizes informative trajectory variants. Experiments on WebArena and
AndroidWorld show that UI-Simulator rivals or surpasses open-source agents
trained on real UIs with significantly better robustness, despite using weaker
teacher models. Moreover, UI-Simulator-Grow matches the performance of
Llama-3-70B-Instruct using only Llama-3-8B-Instruct as the base model,
highlighting the potential of targeted synthesis scaling paradigm to
continuously and efficiently enhance the digital agents.

</details>


### [223] [TokDrift: When LLM Speaks in Subwords but Code Speaks in Grammar](https://arxiv.org/abs/2510.14972)
*Yinxi Li,Yuntian Deng,Pengyu Nie*

Main category: cs.CL

TL;DR: 当前的大型代码语言模型（LLMs）使用的子词分词器缺乏语法感知，导致即使代码语义相同，仅仅由于格式或命名的细微变化也会被分词器以不同方式处理，从而使模型表现出现较大偏移。作者提出TokDrift框架系统评估了这一问题，并表明基于语法的分词对于未来的代码LLM至关重要。


<details>
  <summary>Details</summary>
Motivation: LLMs广泛应用于代码任务，但当前分词器仅凭统计信息学习，忽略了代码的语法结构。这意味着模型对语义相同但格式略有不同的代码处理不一致，可能威胁代码理解和生成的可靠性。

Method: 作者提出TokDrift框架，通过语义等价的代码重写规则，自动生成只在分词层面不同（如空白、标识符等微小格式变化）的代码变体，并测试不同LLM在这些变体上的输出差异。同时，分层分析模型内部表征，定位不同分词带来的行为变化在网络层级的问题。

Result: 在包括30B参数的大模型在内的9个主流代码LLM上，TokDrift生成的小幅格式变化代码会导致模型输出大幅偏移。分层分析显示，这种分词不一致问题主要根植于模型早期嵌入阶段，分词未能对齐语法token边界。

Conclusion: 分词与代码语法不对齐是当前LLM代码理解和生成能力的重大隐性障碍；未来应设计语法感知的分词方法，以提升代码LLM的可靠性。

Abstract: Large language models (LLMs) for code rely on subword tokenizers, such as
byte-pair encoding (BPE), learned from mixed natural language text and
programming language code but driven by statistics rather than grammar. As a
result, semantically identical code snippets can be tokenized differently
depending on superficial factors such as whitespace or identifier naming. To
measure the impact of this misalignment, we introduce TokDrift, a framework
that applies semantic-preserving rewrite rules to create code variants
differing only in tokenization. Across nine code LLMs, including large ones
with over 30B parameters, even minor formatting changes can cause substantial
shifts in model behavior. Layer-wise analysis shows that the issue originates
in early embeddings, where subword segmentation fails to capture grammar token
boundaries. Our findings identify misaligned tokenization as a hidden obstacle
to reliable code understanding and generation, highlighting the need for
grammar-aware tokenization for future code LLMs.

</details>


### [224] [Attention Is All You Need for KV Cache in Diffusion LLMs](https://arxiv.org/abs/2510.14973)
*Quan Nguyen-Tri,Mukul Ranjan,Zhiqiang Shen*

Main category: cs.CL

TL;DR: 本文提出了Elastic-Cache方法，用于扩散类大语言模型（DLM）自适应地刷新Key-Value缓存，减少冗余计算，加速推理，同时保持高生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的DLM解码器在每一步和每一层都会对所有token的QKV值进行计算，但大部分情况下缓存状态变化很小，特别是在浅层，因此存在大量冗余计算。如何减少这些冗余，提高推理效率是本文关注的问题。

Method: 作者通过分析，发现：1）远距离MASK token主要起长度偏置作用，可块级缓存；2）KV动态性随层数加深而增加，说明从深层开始有选择性刷新足以；3）关注度最高的token的KV漂移最小，可作为其他token缓存变化的下界。基于此，提出Elastic-Cache策略（无需训练、适用于各种架构），通过关注度和层深自适应地决定缓存何时及在哪里刷新，实现解码加速。

Result: Elastic-Cache在LLaDA-Instruct、LLaDA-1.5和LLaDA-V等模型和数学推理、代码生成任务上实现了显著的加速（如GSM8K上提速8.7倍、长序列上45.1倍、HumanEval上4.8倍），且准确率优于基线方法。与信心判断缓存方法相比，吞吐量也大幅提升（如GSM8K上提升6.8倍），且生成质量损失极小。

Conclusion: Elastic-Cache能高效去除扩散类大模型推理中的计算冗余，提升解码速度，而且对生成质量几乎无影响，为实际部署扩散大模型提供实用路径。

Abstract: This work studies how to adaptively recompute key-value (KV) caches for
diffusion large language models (DLMs) to maximize prediction accuracy while
minimizing decoding latency. Prior methods' decoders recompute QKV for all
tokens at every denoising step and layer, despite KV states changing little
across most steps, especially in shallow layers, leading to substantial
redundancy. We make three observations: (1) distant ${\bf MASK}$ tokens
primarily act as a length-bias and can be cached block-wise beyond the active
prediction window; (2) KV dynamics increase with depth, suggesting that
selective refresh starting from deeper layers is sufficient; and (3) the
most-attended token exhibits the smallest KV drift, providing a conservative
lower bound on cache change for other tokens. Building on these, we propose
${\bf Elastic-Cache}$, a training-free, architecture-agnostic strategy that
jointly decides ${when}$ to refresh (via an attention-aware drift test on the
most-attended token) and ${where}$ to refresh (via a depth-aware schedule that
recomputes from a chosen layer onward while reusing shallow-layer caches and
off-window MASK caches). Unlike fixed-period schemes, Elastic-Cache performs
adaptive, layer-aware cache updates for diffusion LLMs, reducing redundant
computation and accelerating decoding with negligible loss in generation
quality. Experiments on LLaDA-Instruct, LLaDA-1.5, and LLaDA-V across
mathematical reasoning and code generation tasks demonstrate consistent
speedups: $8.7\times$ on GSM8K (256 tokens), $45.1\times$ on longer sequences,
and $4.8\times$ on HumanEval, while consistently maintaining higher accuracy
than the baseline. Our method achieves significantly higher throughput
($6.8\times$ on GSM8K) than existing confidence-based approaches while
preserving generation quality, enabling practical deployment of diffusion LLMs.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [225] [A Diffusion-Refined Planner with Reinforcement Learning Priors for Confined-Space Parking](https://arxiv.org/abs/2510.14000)
*Mingyang Jiang,Yueyuan Li,Jiaru Zhang,Songan Zhang,Ming Yang*

Main category: cs.RO

TL;DR: 本文提出了一种结合强化学习与扩散模型的自动泊车规划方法（DRIP），在空间受限的环境下显著提升规划精度和效率。


<details>
  <summary>Details</summary>
Motivation: 随着对停车需求的增加，在狭小空间进行高精度自动泊车变得越来越重要。然而，现有方法在建模最佳动作分布时面临困难，影响规划成功率和实用性。

Method: 本文提出了基于强化学习先验的扩散优化泊车规划器DRIP：首先利用强化学习训练的策略获取动作先验分布，将其用于正则化扩散模型的训练过程；推理阶段通过去噪过程细化已有动作分布，实现更精确的动作生成。

Result: 在不同空间约束的泊车场景中进行测试，实验结果表明，DRIP方法在空间受限环境下显著提升了动作建模精度、规划成功率，并减少了推理步骤，同时在常规场景下也表现出良好的泛化能力。

Conclusion: 结合强化学习先验和扩散模型能有效提升自动泊车规划性能，尤其适用于狭小复杂环境，具有较强的实用推广价值。

Abstract: The growing demand for parking has increased the need for automated parking
planning methods that can operate reliably in confined spaces. In restricted
and complex environments, high-precision maneuvers are required to achieve a
high success rate in planning, yet existing approaches often rely on explicit
action modeling, which faces challenges when accurately modeling the optimal
action distribution. In this paper, we propose DRIP, a diffusion-refined
planner anchored in reinforcement learning (RL) prior action distribution, in
which an RL-pretrained policy provides prior action distributions to regularize
the diffusion training process. During the inference phase the denoising
process refines these coarse priors into more precise action distributions. By
steering the denoising trajectory through the reinforcement learning prior
distribution during training, the diffusion model inherits a well-informed
initialization, resulting in more accurate action modeling, a higher planning
success rate, and reduced inference steps. We evaluate our approach across
parking scenarios with varying degrees of spatial constraints. Experimental
results demonstrate that our method significantly improves planning performance
in confined-space parking environments while maintaining strong generalization
in common scenarios.

</details>


### [226] [Spatially Intelligent Patrol Routes for Concealed Emitter Localization by Robot Swarms](https://arxiv.org/abs/2510.14018)
*Adam Morris,Timothy Pelham,Edmund R. Hunt*

Main category: cs.RO

TL;DR: 本文提出了一种用于空间智能机器人群体定位隐蔽无线电发射源的方法，基于微分进化设计巡逻路线，比较了全向与定向天线在定位效果上的差异。


<details>
  <summary>Details</summary>
Motivation: 无线电发射源的隐蔽定位是电磁监测中的关键挑战，现有方法往往依赖于对发射源参数的了解，缺乏对未知信号的鲁棒性。

Method: 采用微分进化算法为四机器人群体生成几何化巡逻路径，通过对比全向与定向天线，分析不同巡逻路线和天线类型对信息增益及定位覆盖的影响。

Result: 定向天线比全向天线成功率更高（98.75%对80.25%），平均定位误差更小（1.01-1.30m与1.67-1.90m），且定向天线对源的位置依赖性更小。

Conclusion: 优化的巡逻路线和天线选择对于提升机器人群体在电磁监测环境下的空间智能和定位能力至关重要，是未来机器人监控设计的重要考虑因素。

Abstract: This paper introduces a method for designing spatially intelligent robot
swarm behaviors to localize concealed radio emitters. We use differential
evolution to generate geometric patrol routes that localize unknown signals
independently of emitter parameters, a key challenge in electromagnetic
surveillance. Patrol shape and antenna type are shown to influence information
gain, which in turn determines the effective triangulation coverage. We
simulate a four-robot swarm across eight configurations, assigning
pre-generated patrol routes based on a specified patrol shape and sensing
capability (antenna type: omnidirectional or directional). An emitter is placed
within the map for each trial, with randomized position, transmission power and
frequency. Results show that omnidirectional localization success rates are
driven primarily by source location rather than signal properties, with
failures occurring most often when sources are placed in peripheral areas of
the map. Directional antennas are able to overcome this limitation due to their
higher gain and directivity, with an average detection success rate of 98.75%
compared to 80.25% for omnidirectional. Average localization errors range from
1.01-1.30 m for directional sensing and 1.67-1.90 m for omnidirectional
sensing; while directional sensing also benefits from shorter patrol edges.
These results demonstrate that a swarm's ability to predict electromagnetic
phenomena is directly dependent on its physical interaction with the
environment. Consequently, spatial intelligence, realized here through
optimized patrol routes and antenna selection, is a critical design
consideration for effective robotic surveillance.

</details>


### [227] [Adaptive Obstacle-Aware Task Assignment and Planning for Heterogeneous Robot Teaming](https://arxiv.org/abs/2510.14063)
*Nan Li,Jiming Ren,Haris Miller,Samuel Coogan,Karen M. Feigh,Ye Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种面对复杂障碍环境的多机器人任务分配与规划方法（OATH），通过障碍感知采样和集群拍卖选择机制，有效提升了大规模异构机器人团队的任务协同能力。


<details>
  <summary>Details</summary>
Motivation: 多智能体任务分配与规划（MATP）因在复杂、有障碍物的环境下任务协同而受到关注，但现有方法在可扩展性、空间推理与环境适应性方面存在不足。

Method: 作者提出OATH方法。创新点包括：1）提出基于障碍自适应的Halton序列采样地图，根据障碍分布调整采样密度并首次应用于MATP；2）设计集群-拍卖-选择机制，实现障碍感知的聚类、加权拍卖和簇内任务选择，提升分配效率；3）结合大语言模型（LLM）理解人类指令并实时辅助规划。

Result: 在NVIDIA Isaac Sim仿真平台验证，OATH在任务分配质量、可扩展性、动态环境适应性及整体执行性能上明显优于主流MATP基线方法。

Conclusion: OATH为异构机器人团队在障碍丰富环境中高效任务分配与执行提供了新思路，推动MATP研究在智能协作能力与实际应用层面取得突破。

Abstract: Multi-Agent Task Assignment and Planning (MATP) has attracted growing
attention but remains challenging in terms of scalability, spatial reasoning,
and adaptability in obstacle-rich environments. To address these challenges, we
propose OATH: Adaptive Obstacle-Aware Task Assignment and Planning for
Heterogeneous Robot Teaming, which advances MATP by introducing a novel
obstacle-aware strategy for task assignment. First, we develop an adaptive
Halton sequence map, the first known application of Halton sampling with
obstacle-aware adaptation in MATP, which adjusts sampling density based on
obstacle distribution. Second, we propose a cluster-auction-selection framework
that integrates obstacle-aware clustering with weighted auctions and
intra-cluster task selection. These mechanisms jointly enable effective
coordination among heterogeneous robots while maintaining scalability and
near-optimal allocation performance. In addition, our framework leverages an
LLM to interpret human instructions and directly guide the planner in real
time. We validate OATH in NVIDIA Isaac Sim, showing substantial improvements in
task assignment quality, scalability, adaptability to dynamic changes, and
overall execution performance compared to state-of-the-art MATP baselines. A
project website is available at https://llm-oath.github.io/.

</details>


### [228] [Optimistic Reinforcement Learning-Based Skill Insertions for Task and Motion Planning](https://arxiv.org/abs/2510.14065)
*Gaoyuan Liu,Joris de Winter,Yuri Durodie,Denis Steckelmacher,Ann Nowe,Bram Vanderborght*

Main category: cs.RO

TL;DR: 本文提出了一种将强化学习（RL）技能集成到任务与运动规划（TAMP）流程中的方法，有效提升了机器人在存在不确定性情况下的规划能力和效率。


<details>
  <summary>Details</summary>
Motivation: TAMP需要处理复杂、长时序的动作规划，面对具有不确定性的概率性动作时面临挑战，而RL可获得鲁棒的短时 Manipulation 技能，但难以应对长时规划。因此，研究如何融合两者优势，实现对不确定性动作的高效规划。

Method: 设计了一种集成RL技能的TAMP方法，将RL技能通过数据驱动的逻辑组件进行定义，使其可被符号规划器调用，并在计划过程中引入计划细化子程序，以处理各种不确定性。

Result: 实验表明，所提方法较传统TAMP与RL的分层规划基线均有明显优势，能够将RL技能应用到概率性动作领域，且提高了规划效率。

Conclusion: 将RL技能嵌入TAMP流程拓展了TAMP对不确定性技能的适应领域，并带来了效率提升，对实际机器人操作具有积极意义。

Abstract: Task and motion planning (TAMP) for robotics manipulation necessitates
long-horizon reasoning involving versatile actions and skills. While
deterministic actions can be crafted by sampling or optimizing with certain
constraints, planning actions with uncertainty, i.e., probabilistic actions,
remains a challenge for TAMP. On the contrary, Reinforcement Learning (RL)
excels in acquiring versatile, yet short-horizon, manipulation skills that are
robust with uncertainties. In this letter, we design a method that integrates
RL skills into TAMP pipelines. Besides the policy, a RL skill is defined with
data-driven logical components that enable the skill to be deployed by symbolic
planning. A plan refinement sub-routine is designed to further tackle the
inevitable effect uncertainties. In the experiments, we compare our method with
baseline hierarchical planning from both TAMP and RL fields and illustrate the
strength of the method. The results show that by embedding RL skills, we extend
the capability of TAMP to domains with probabilistic skills, and improve the
planning efficiency compared to the previous methods.

</details>


### [229] [Partial Feedback Linearization Control of a Cable-Suspended Multirotor Platform for Stabilization of an Attached Load](https://arxiv.org/abs/2510.14072)
*Hemjyoti Das,Christian Ott*

Main category: cs.RO

TL;DR: 本文提出了一种基于部分反馈线性化（PFL）的新型控制方法，用于带有悬挂载荷的空中平台的稳定控制，并通过仿真和实验验证了其有效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在建筑工地等场景中，利用起重机等系统稳定运输重物具有重要应用价值，但带载荷的悬挂平台存在欠驱动和动力学耦合等控制难题，因此迫切需要新的控制方案以提升稳定性和鲁棒性。

Method: 作者提出了一种基于部分反馈线性化（PFL）的控制策略，针对系统总体欠驱动特性，合理利用动力学耦合部分实现系统稳定。此外，作者还分析了外部风干扰、传感器噪声以及系统动力学不确定性下的鲁棒性。方法仅依赖机载传感器，适合实际工地场景。

Result: 通过数值稳定性分析证实了耦合动力学项对整个系统稳定性的重要作用。作者还通过大量仿真和实验测试，验证了所提控制方法在各种干扰和不确定性下的有效性和鲁棒性。

Conclusion: 本文提出的控制方法能够在复杂干扰和不确定性条件下，有效提升悬挂载荷空中平台系统的稳定性，且仅依赖机载传感器，具备较好的实际应用前景。

Abstract: In this work, we present a novel control approach based on partial feedback
linearization (PFL) for the stabilization of a suspended aerial platform with
an attached load. Such systems are envisioned for various applications in
construction sites involving cranes, such as the holding and transportation of
heavy objects. Our proposed control approach considers the underactuation of
the whole system while utilizing its coupled dynamics for stabilization. We
demonstrate using numerical stability analysis that these coupled terms are
crucial for the stabilization of the complete system. We also carried out
robustness analysis of the proposed approach in the presence of external wind
disturbances, sensor noise, and uncertainties in system dynamics. As our
envisioned target application involves cranes in outdoor construction sites,
our control approaches rely on only onboard sensors, thus making it suitable
for such applications. We carried out extensive simulation studies and
experimental tests to validate our proposed control approach.

</details>


### [230] [ViTacGen: Robotic Pushing with Vision-to-Touch Generation](https://arxiv.org/abs/2510.14117)
*Zhiyuan Wu,Yijiong Lin,Yongqiang Zhao,Xuyang Zhang,Zhuo Chen,Nathan Lepora,Shan Luo*

Main category: cs.RO

TL;DR: 该论文提出ViTacGen框架，通过视觉信息生成触觉表示，实现无需真触觉传感器的机器人推拽物体任务，提升了机器人操控的泛化与实际性能。


<details>
  <summary>Details</summary>
Motivation: 机器人推拽任务需要触觉反馈以准确感知接触动态，但真实触觉传感器昂贵且易损，且与实际部署存在校准、设备差异等困难。同时，单靠视觉策略表现不佳。受人类通过视觉推断触觉的启发，作者希望消除对高分辨率触觉传感器的依赖。

Method: 提出ViTacGen框架，包括视觉到触觉生成的编码-解码器网络（产生标准化触觉深度图），结合对比学习的视觉-触觉融合强化学习策略。该方法利用视觉序列生成触觉信息，输入强化学习策略以提升推拽物体能力。

Result: ViTacGen在仿真与现实实验中表现优异，推拽物体任务成功率高达86%。

Conclusion: 论文证明可通过视觉推断并生成有效的触觉表征，在无需昂贵触觉硬件的前提下，提升机器人推拽物体的泛化和实际应用性能。

Abstract: Robotic pushing is a fundamental manipulation task that requires tactile
feedback to capture subtle contact forces and dynamics between the end-effector
and the object. However, real tactile sensors often face hardware limitations
such as high costs and fragility, and deployment challenges involving
calibration and variations between different sensors, while vision-only
policies struggle with satisfactory performance. Inspired by humans' ability to
infer tactile states from vision, we propose ViTacGen, a novel robot
manipulation framework designed for visual robotic pushing with vision-to-touch
generation in reinforcement learning to eliminate the reliance on
high-resolution real tactile sensors, enabling effective zero-shot deployment
on visual-only robotic systems. Specifically, ViTacGen consists of an
encoder-decoder vision-to-touch generation network that generates contact depth
images, a standardized tactile representation, directly from visual image
sequence, followed by a reinforcement learning policy that fuses visual-tactile
data with contrastive learning based on visual and generated tactile
observations. We validate the effectiveness of our approach in both simulation
and real world experiments, demonstrating its superior performance and
achieving a success rate of up to 86\%.

</details>


### [231] [Prescribed Performance Control of Deformable Object Manipulation in Spatial Latent Space](https://arxiv.org/abs/2510.14234)
*Ning Han,Gu Gong,Bin Zhang,Yuexuan Xu,Bohan Yang,Yunhui Liu,David Navarro-Alarcon*

Main category: cs.RO

TL;DR: 本文提出了一种无模型的三维可变形物体形状控制方法，直接利用关键点坐标作为特征向量，实现对物体的有效精准操控。


<details>
  <summary>Details</summary>
Motivation: 操控三维可变形物体在机器人领域极具挑战性，主要因其状态空间无限维且变形动力学复杂。当前方法普遍依赖特征降维，信息损失较大，且难以保证精确操控。本文旨在提出新的特征提取和控制方法，提升操控效率和精度。

Method: 作者利用深度学习从点云中提取关键点坐标作为特征，将可变形物体操控简化为视觉伺服问题，并以变形雅各比矩阵描述形状动力学。结合屏障Lyapunov函数，设计了规定性能控制方法，对关键点施加约束，并通过Lyapunov方法验证闭环系统稳定性。

Result: 实验结果证明了该方法在实际操控中表现出良好的效果和鲁棒性，能够有效实现对三维可变形物体的形状控制和稳定约束。

Conclusion: 本方法在不依赖精确动态模型的情况下，通过关键点提取与规定性能控制，实现对复杂可变形物体的精确和稳定操控，展现出广阔的应用前景和理论价值。

Abstract: Manipulating three-dimensional (3D) deformable objects presents significant
challenges for robotic systems due to their infinite-dimensional state space
and complex deformable dynamics. This paper proposes a novel model-free
approach for shape control with constraints imposed on key points. Unlike
existing methods that rely on feature dimensionality reduction, the proposed
controller leverages the coordinates of key points as the feature vector, which
are extracted from the deformable object's point cloud using deep learning
methods. This approach not only reduces the dimensionality of the feature space
but also retains the spatial information of the object. By extracting key
points, the manipulation of deformable objects is simplified into a visual
servoing problem, where the shape dynamics are described using a deformation
Jacobian matrix. To enhance control accuracy, a prescribed performance control
method is developed by integrating barrier Lyapunov functions (BLF) to enforce
constraints on the key points. The stability of the closed-loop system is
rigorously analyzed and verified using the Lyapunov method. Experimental
results further demonstrate the effectiveness and robustness of the proposed
method.

</details>


### [232] [Learning Human-Humanoid Coordination for Collaborative Object Carrying](https://arxiv.org/abs/2510.14293)
*Yushi Du,Yixuan Li,Baoxiong Jia,Yutang Lin,Pei Zhou,Wei Liang,Yanchao Yang,Siyuan Huang*

Main category: cs.RO

TL;DR: 这篇论文提出了一种只依赖自身感知（本体感受）的强化学习方法COLA，实现了人类与类人机器人协同搬运任务的高效和灵活性，并在多种场景下验证了其实用性。


<details>
  <summary>Details</summary>
Motivation: 虽然人类与机器人手臂的合作已得到较多研究，但类人机器人由于具有复杂的全身动力学，实现与人类的弹性合作仍然缺乏探索。论文希望解决这一领域的空白，推动类人机器人与人类合作能力的实际应用。

Method: 提出了一个仅基于本体感受信息的强化学习方法（COLA），融合了主导者和跟随者行为，通过在闭环动态环境中训练，使机器人能隐式地预测物体运动和人的意图，实现适应性很强的协作搬运。

Result: 仿真实验显示，COLA方法比基线方法能降低24.7%的人力消耗，同时保证物体稳定性。实际机器人实验验证了其在不同地形和物体类型上的稳健性。23位真实用户的实验进一步证实协作效率较基线提升约27.4%。

Conclusion: 提出的方法无需外部传感器和复杂交互模型，即可实现稳定高效的人-类人机器人弹性协作搬运，在实际场景中具有较高应用前景。

Abstract: Human-humanoid collaboration shows significant promise for applications in
healthcare, domestic assistance, and manufacturing. While compliant robot-human
collaboration has been extensively developed for robotic arms, enabling
compliant human-humanoid collaboration remains largely unexplored due to
humanoids' complex whole-body dynamics. In this paper, we propose a
proprioception-only reinforcement learning approach, COLA, that combines leader
and follower behaviors within a single policy. The model is trained in a
closed-loop environment with dynamic object interactions to predict object
motion patterns and human intentions implicitly, enabling compliant
collaboration to maintain load balance through coordinated trajectory planning.
We evaluate our approach through comprehensive simulator and real-world
experiments on collaborative carrying tasks, demonstrating the effectiveness,
generalization, and robustness of our model across various terrains and
objects. Simulation experiments demonstrate that our model reduces human effort
by 24.7%. compared to baseline approaches while maintaining object stability.
Real-world experiments validate robust collaborative carrying across different
object types (boxes, desks, stretchers, etc.) and movement patterns
(straight-line, turning, slope climbing). Human user studies with 23
participants confirm an average improvement of 27.4% compared to baseline
models. Our method enables compliant human-humanoid collaborative carrying
without requiring external sensors or complex interaction models, offering a
practical solution for real-world deployment.

</details>


### [233] [Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning](https://arxiv.org/abs/2510.14300)
*Weijie Shen,Yitian Liu,Yuhao Wu,Zhixuan Liang,Sijia Gu,Dehui Wang,Tian Nian,Lei Xu,Yusen Qin,Jiangmiao Pang,Xinping Guan,Xiaokang Yang,Yao Mu*

Main category: cs.RO

TL;DR: 本文提出了一种名为AdaMoE的专家混合（MoE）结构，用于提升视觉-语言-动作模型（VLA）在机器人操作任务上的扩展性与实时性能，同时有效利用已有的预训练模型权重。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在机器人操作任务上虽展现出巨大潜力，但存在数据稀缺、训练成本高以及实时推理效率要求的挑战，亟需一种能高效利用预训练权重并兼具高效推理的扩展方案。

Method: AdaMoE架构将传统的VLA模型中的前馈层替换为稀疏激活的专家混合层，同时提出了将专家选择和专家权重解耦的机制，通过独立的权重调节器提升协作效果，实现任务相关性驱动下多专家协同而非单一专家独占输出。

Result: AdaMoE在主要评测基准上均取得领先，例如在LIBERO数据集上提升1.8%、RoboTwin数据集提升9.3%，真实机器人操作实验中性能提升高达21.5%。

Conclusion: AdaMoE不仅保持了计算效率，还提升了VLA模型的表现，其协作式专家机制更适合现实中的机器人操作部署。

Abstract: Vision-Language-Action (VLA) models are experiencing rapid development and
demonstrating promising capabilities in robotic manipulation tasks. However,
scaling up VLA models presents several critical challenges: (1) Training new
VLA models from scratch demands substantial computational resources and
extensive datasets. Given the current scarcity of robot data, it becomes
particularly valuable to fully leverage well-pretrained VLA model weights
during the scaling process. (2) Real-time control requires carefully balancing
model capacity with computational efficiency. To address these challenges, We
propose AdaMoE, a Mixture-of-Experts (MoE) architecture that inherits
pretrained weights from dense VLA models, and scales up the action expert by
substituting the feedforward layers into sparsely activated MoE layers. AdaMoE
employs a decoupling technique that decouples expert selection from expert
weighting through an independent scale adapter working alongside the
traditional router. This enables experts to be selected based on task relevance
while contributing with independently controlled weights, allowing
collaborative expert utilization rather than winner-takes-all dynamics. Our
approach demonstrates that expertise need not monopolize. Instead, through
collaborative expert utilization, we can achieve superior performance while
maintaining computational efficiency. AdaMoE consistently outperforms the
baseline model across key benchmarks, delivering performance gains of 1.8% on
LIBERO and 9.3% on RoboTwin. Most importantly, a substantial 21.5% improvement
in real-world experiments validates its practical effectiveness for robotic
manipulation tasks.

</details>


### [234] [Risk-Aware Reinforcement Learning with Bandit-Based Adaptation for Quadrupedal Locomotion](https://arxiv.org/abs/2510.14338)
*Yuanhong Zeng,Anushri Dixit*

Main category: cs.RO

TL;DR: 本文提出一种在四足机器人运动中进行风险感知强化学习的方法，通过训练条件价值亏空（CVaR）约束的策略族，并采用多臂赌博机框架自适应地选择最佳策略，实现机器人在未知环境中的强鲁棒性和高性能。


<details>
  <summary>Details</summary>
Motivation: 机器人在实际应用中常常需要在动态变化、未知或恶劣的环境下执行任务，传统的强化学习方法在面对未知风险时性能不稳定，因此需要引入风险感知以提升机器人在现实环境中的鲁棒和安全性。

Method: 采用CVaR约束的策略优化，训练出在不同风险水平下的策略家族。部署时，无需环境先验信息，仅依赖回报观察，通过多臂赌博机框架自适应在线选择当前表现最优的策略，实现了对未知环境风险的快速响应和适应。

Result: 在仿真八种不同且未知的设置（如动力学、触地、噪音、地形变化）以及真实四足机器人（Unitree Go2）在未知地形实验中，提出的方法在非训练环境下的均值和尾部回报达到现有方法近两倍，并能在两分钟内通过自适应策略选择达到最佳表现。

Conclusion: 通过风险感知的强化学习策略训练与在线自适应选择，显著提升了四足机器人在未知环境中的表现和鲁棒性，证明了该方法在实际机器人控制应用中的有效性和前景。

Abstract: In this work, we study risk-aware reinforcement learning for quadrupedal
locomotion. Our approach trains a family of risk-conditioned policies using a
Conditional Value-at-Risk (CVaR) constrained policy optimization technique that
provides improved stability and sample efficiency. At deployment, we adaptively
select the best performing policy from the family of policies using a
multi-armed bandit framework that uses only observed episodic returns, without
any privileged environment information, and adapts to unknown conditions on the
fly. Hence, we train quadrupedal locomotion policies at various levels of
robustness using CVaR and adaptively select the desired level of robustness
online to ensure performance in unknown environments. We evaluate our method in
simulation across eight unseen settings (by changing dynamics, contacts,
sensing noise, and terrain) and on a Unitree Go2 robot in previously unseen
terrains. Our risk-aware policy attains nearly twice the mean and tail
performance in unseen environments compared to other baselines and our
bandit-based adaptation selects the best-performing risk-aware policy in
unknown terrain within two minutes of operation.

</details>


### [235] [SUM-AgriVLN: Spatial Understanding Memory for Agricultural Vision-and-Language Navigation](https://arxiv.org/abs/2510.14357)
*Xiaobei Zhao,Xingqi Lyu,Xiang Li*

Main category: cs.RO

TL;DR: 该论文提出了SUM-AgriVLN方法，通过空间记忆显著提升了农业领域中基于视觉和语言导航的机器人表现。


<details>
  <summary>Details</summary>
Motivation: 传统农业机器人在导航时通常不利用过往指令和空间信息，每次独立处理指令，未充分发挥历史经验的空间上下文价值，影响了导航效率和智能化进程。

Method: 本文提出SUM-AgriVLN方法，引入空间理解模块（SUM），利用3D重建技术为机器人建立并保存空间记忆，从而结合历史指令和空间经验，提高机器人连续任务下的导航能力。该方法在A2A基准测试集上进行验证。

Result: SUM-AgriVLN方法将Success Rate从0.47提升至0.54，导航误差仅从2.91m略增至2.93m，显示出显著的性能提升。

Conclusion: 通过在视觉-语言导航中引入空间记忆，SUM-AgriVLN在农业机器人任务中取得了当前最佳性能，具有实际应用前景。

Abstract: Agricultural robots are emerging as powerful assistants across a wide range
of agricultural tasks, nevertheless, still heavily rely on manual operation or
fixed rail systems for movement. The AgriVLN method and the A2A benchmark
pioneeringly extend Vision-and-Language Navigation (VLN) to the agricultural
domain, enabling robots to navigate to the target positions following the
natural language instructions. In practical agricultural scenarios, navigation
instructions often repeatedly occur, yet AgriVLN treat each instruction as an
independent episode, overlooking the potential of past experiences to provide
spatial context for subsequent ones. To bridge this gap, we propose the method
of Spatial Understanding Memory for Agricultural Vision-and-Language Navigation
(SUM-AgriVLN), in which the SUM module employs spatial understanding and save
spatial memory through 3D reconstruction and representation. When evaluated on
the A2A benchmark, our SUM-AgriVLN effectively improves Success Rate from 0.47
to 0.54 with slight sacrifice on Navigation Error from 2.91m to 2.93m,
demonstrating the state-of-the-art performance in the agricultural domain.
Code: https://github.com/AlexTraveling/SUM-AgriVLN.

</details>


### [236] [RoboANKLE: Design, Development, and Functional Evaluation of a Robotic Ankle with a Motorized Compliant Unit](https://arxiv.org/abs/2510.14414)
*Baris Baysal,Omid Arfaie,Ramazan Unal*

Main category: cs.RO

TL;DR: 本文提出了一种名为RoboANKLE的动力小腿假肢，能够模拟人体踝关节的自然推蹬动作，并通过一系列实验和结构优化，实现了较高的运动自然度和动力输出效率。


<details>
  <summary>Details</summary>
Motivation: 目前主动小腿假肢设计面临重量与能量自主性的平衡问题，同时需实现自然的踝关节运动和足够的扭矩，提升截肢者的生活质量。作者希望通过仿生设计突破这些瓶颈。

Method: 作者设计并实现了含有能量存储与延迟释放（ESER）及额外能量存储（EES）机制的动力踝关节，并利用运动学和动力学分析确定参数，通过CAD建模以及拓扑优化降低重量，最终完成样机制造与实验性能验证。

Result: RoboANKLE样机质量为1.92kg，尺寸为261x107x420mm。在实验中实现了95%自然足背屈角度，与自然行走扭矩相比，最大输出提高了57%，整步态过程中的动力输出比自然踝关节高10%。

Conclusion: RoboANKLE不仅在轻量化和动力输出方面表现出色，而且能够高度模拟人类踝部的自然运动，未来在实际假肢应用中具备很大潜力。

Abstract: This study presents a powered transtibial prosthesis with complete push-off
assistance, RoboANKLE. The design aims to fulfill specific requirements, such
as a sufficient range of motion (RoM) while providing the necessary torque for
achieving natural ankle motion in daily activities. Addressing the challenges
faced in designing active transtibial prostheses, such as maintaining energetic
autonomy and minimizing weight, is vital for the study. With this aim, we try
to imitate the human ankle by providing extensive push-off assistance to
achieve a natural-like torque profile. Thus, Energy Store and Extended Release
mechanism (ESER) is employed with a novel Extra Energy Storage (EES) mechanism.
Kinematic and kinetic analyses are carried out to determine the design
parameters and assess the design performance. Subsequently, a Computer-Aided
Design (CAD) model is built and used in comprehensive dynamic and structural
analyses. These analyses are used for the design performance evaluation and
determine the forces and torques applied to the prosthesis, which aids in
optimizing the design for minimal weight via structural analysis and topology
optimization. The design of the prototype is then finalized and manufactured
for experimental evaluation to validate the design and functionality. The
prototype is realized with a mass of 1.92 kg and dimensions of 261x107x420 mm.
The Functional evaluations of the RoboANKLE revealed that it is capable of
achieving the natural maximum dorsi-flexion angle with 95% accuracy. Also,
Thanks to the implemented mechanisms, the results show that RoboANKLE can
generate 57% higher than the required torque for natural walking. The result of
the power generation capacity of the RoboANKLE is 10% more than the natural
power during the gait cycle.

</details>


### [237] [Towards Adaptable Humanoid Control via Adaptive Motion Tracking](https://arxiv.org/abs/2510.14454)
*Tao Huang,Huayi Wang,Junli Ren,Kangning Yin,Zirui Wang,Xiao Chen,Feiyu Jia,Wentao Zhang,Junfeng Long,Jingbo Wang,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 提出了一种适用于类人机器人新型的模仿控制算法 AdaMimic，仅需单一参考动作即可适应多种现实环境，有效提升了动作适应性与模仿精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么要求大量训练数据以获得精确模仿，要么虽然适应性强但牺牲了动作准确性，因此急需一种兼具模仿精度和适应性的运动模仿方法。

Method: AdaMimic 从单一参考动作中抽取关键帧进行稀疏化，并通过轻量物理假设进行数据增强，利用关键帧进行动作跟踪生成稠密中间动作，再训练适配模块对跟踪速度和底层动作进行细致调整，实现灵活的时间变形和动作优化。

Result: 在仿真和实际 Unitree G1 类人机器人多种任务测试下，AdaMimic 在广泛的适应性条件下表现出明显优于现有方法的模仿精度和适应能力。

Conclusion: AdaMimic 显著提升了类人机器人针对单参考动作的适应性与动作模仿精度，为数据稀缺场景下的灵巧控制提供了有效方案。

Abstract: Humanoid robots are envisioned to adapt demonstrated motions to diverse
real-world conditions while accurately preserving motion patterns. Existing
motion prior approaches enable well adaptability with a few motions but often
sacrifice imitation accuracy, whereas motion-tracking methods achieve accurate
imitation yet require many training motions and a test-time target motion to
adapt. To combine their strengths, we introduce AdaMimic, a novel motion
tracking algorithm that enables adaptable humanoid control from a single
reference motion. To reduce data dependence while ensuring adaptability, our
method first creates an augmented dataset by sparsifying the single reference
motion into keyframes and applying light editing with minimal physical
assumptions. A policy is then initialized by tracking these sparse keyframes to
generate dense intermediate motions, and adapters are subsequently trained to
adjust tracking speed and refine low-level actions based on the adjustment,
enabling flexible time warping that further improves imitation accuracy and
adaptability. We validate these significant improvements in our approach in
both simulation and the real-world Unitree G1 humanoid robot in multiple tasks
across a wide range of adaptation conditions. Videos and code are available at
https://taohuang13.github.io/adamimic.github.io/.

</details>


### [238] [Restoring Noisy Demonstration for Imitation Learning With Diffusion Models](https://arxiv.org/abs/2510.14467)
*Shang-Fu Chen,Co Yong,Shao-Hua Sun*

Main category: cs.RO

TL;DR: 本文提出了一种适用于带噪声专家演示的模仿学习新框架，通过过滤和修复噪声数据，有效提升了在各类任务下的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法普遍假设专家演示是完美的，现实中人类专家或系统难免会提供带有噪音的演示数据，影响学习效果。因此，亟需一种能够处理带噪声演示的有效方法。

Method: 提出了一个“过滤-修复”（filter-and-restore）框架：首先从演示数据中筛选出相对干净的样本；然后利用条件扩散模型对剩余的噪声样本进行修复，从而最大程度利用所有演示数据。

Result: 在机器人机械臂操作、高难度操作和行走等多个领域实验中，本文方法在所有任务上均优于已有方法。消融实验也证实了每一模块的效果，并且验证了它对不同类型和不同程度噪声的鲁棒性。

Conclusion: 该方法不仅能有效提升带噪声专家演示下的模仿学习性能，也证明了其广泛适用性和实用潜力，为离线带噪声演示数据的应用提供了可行方案。

Abstract: Imitation learning (IL) aims to learn a policy from expert demonstrations and
has been applied to various applications. By learning from the expert policy,
IL methods do not require environmental interactions or reward signals.
However, most existing imitation learning algorithms assume perfect expert
demonstrations, but expert demonstrations often contain imperfections caused by
errors from human experts or sensor/control system inaccuracies. To address the
above problems, this work proposes a filter-and-restore framework to best
leverage expert demonstrations with inherent noise. Our proposed method first
filters clean samples from the demonstrations and then learns conditional
diffusion models to recover the noisy ones. We evaluate our proposed framework
and existing methods in various domains, including robot arm manipulation,
dexterous manipulation, and locomotion. The experiment results show that our
proposed framework consistently outperforms existing methods across all the
tasks. Ablation studies further validate the effectiveness of each component
and demonstrate the framework's robustness to different noise types and levels.
These results confirm the practical applicability of our framework to noisy
offline demonstration data.

</details>


### [239] [Stability Criteria and Motor Performance in Delayed Haptic Dyadic Interactions Mediated by Robots](https://arxiv.org/abs/2510.14511)
*Mingtian Du,Suhas Raghavendra Kulkarni,Simone Kager,Domenico Campolo*

Main category: cs.RO

TL;DR: 论文分析了网络延迟环境下，机器人中介的人-人触觉交互系统的稳定性，并提出了延迟无关和延迟相关两类稳定性判据。


<details>
  <summary>Details</summary>
Motivation: 面对网络引入的时延，远程机器人支持下的人-人触觉通信可能变得不稳定，亟需明确分析其稳定性边界，指导系统设计。

Method: 基于频域分析，配合数值仿真，系统推导出稳定性判据。这些判据依赖于控制器和机器人动力学参数（如刚度），并通过机器人执行类人运动的实验进一步验证。

Result: 提出了延迟无关和延迟相关稳定性判据，后者存在最大可容忍延迟，并揭示刚度参数增加会以非线性方式降低可容忍延迟。同时稳定性与运动性能密切相关。

Conclusion: 所提判据可为远程双人机器人交互系统设计提供指导，为制定有效的延迟补偿策略提供了理论基础。

Abstract: This paper establishes analytical stability criteria for robot-mediated
human-human (dyadic) interaction systems, focusing on haptic communication
under network-induced time delays. Through frequency-domain analysis supported
by numerical simulations, we identify both delay-independent and
delay-dependent stability criteria. The delay-independent criterion guarantees
stability irrespective of the delay, whereas the delay-dependent criterion is
characterised by a maximum tolerable delay before instability occurs. The
criteria demonstrate dependence on controller and robot dynamic parameters,
where increasing stiffness reduces the maximum tolerable delay in a non-linear
manner, thereby heightening system vulnerability. The proposed criteria can be
generalised to a wide range of robot-mediated interactions and serve as design
guidelines for stable remote dyadic systems. Experiments with robots performing
human-like movements further illustrate the correlation between stability and
motor performance. The findings of this paper suggest the prerequisites for
effective delay-compensation strategies.

</details>


### [240] [QuASH: Using Natural-Language Heuristics to Query Visual-Language Robotic Maps](https://arxiv.org/abs/2510.14546)
*Matti Pekkanen,Francesco Verdoja,Ville Kyrki*

Main category: cs.RO

TL;DR: 本文提出了一种利用视觉-语言模型嵌入提升机器人地图语义查询能力的方法，通过引入与查询相关的同义词和反义词，训练分类器提升检索表现，验证了在地图和图像检索任务上的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前利用视觉-语言模型嵌入进行场景理解虽然可以突破传统标签的局限性，实现开放词汇检索，但面临如何判断环境中与查询相关区域的挑战。为使机器人能够更准确地回应自然语言查询，亟需解决相关性识别难题。

Method: 作者提出结合查询词的同义词和反义词，在嵌入空间内通过启发式方法确定与查询相关的语言空间，并据此训练环境分区（匹配/不匹配）的分类器。整个流程对编码器无依赖，且仅需有限训练样本。

Result: 该方法在多组地图和标准图像检索基准上进行了实验评估，结果显示提升了地图和图像的可查询性。

Conclusion: 提出的方法有效提升了基于嵌入的语义检索性能，具备较好通用性与实用价值，对不同表示和编码模型均适用，且训练成本低。

Abstract: Embeddings from Visual-Language Models are increasingly utilized to represent
semantics in robotic maps, offering an open-vocabulary scene understanding that
surpasses traditional, limited labels. Embeddings enable on-demand querying by
comparing embedded user text prompts to map embeddings via a similarity metric.
The key challenge in performing the task indicated in a query is that the robot
must determine the parts of the environment relevant to the query.
  This paper proposes a solution to this challenge. We leverage
natural-language synonyms and antonyms associated with the query within the
embedding space, applying heuristics to estimate the language space relevant to
the query, and use that to train a classifier to partition the environment into
matches and non-matches. We evaluate our method through extensive experiments,
querying both maps and standard image benchmarks. The results demonstrate
increased queryability of maps and images. Our querying technique is agnostic
to the representation and encoder used, and requires limited training.

</details>


### [241] [A Generalized Placeability Metric for Model-Free Unified Pick-and-Place Reasoning](https://arxiv.org/abs/2510.14584)
*Benno Wingender,Nils Dengler,Rohit Menon,Sicong Pan,Maren Bennewitz*

Main category: cs.RO

TL;DR: 本文提出了一种无需CAD模型等先验知识，直接从噪声点云中评估未知物体可放置性的新度量方法，实现了对抓取与放置问题的统一推理，并在真实场景中对非平面支撑物体表现出良好泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于物体CAD模型或者仅支持平面放置，难以适应实际场景中未知形状和复杂支撑面物体，因此亟需一种更通用、能处理真实世界传感噪声的方法，实现对抓取和放置的统一推理。

Method: 提出了一种基于噪声点云的可放置性度量（placeability metric），无须形状先验。该方法从点云中提取支撑面，生成多方位的放置候选，并采样满足碰撞和稳定性约束的接触点；对每个候选放置位，联合评估其稳定性、可抓取性及间隙性，选出稳定无碰撞的抓取-放置对。

Result: 在真实未知物体和非平面支撑面场景下，该度量在稳定性预测上达到与CAD模型方法相当的准确率，且较学习型预测器生成更符合物理规律的放置结果。

Conclusion: 新提出的模型无须任何形状先验，能在现实噪声条件下直接从点云数据实现优质的统一抓取与放置推理，泛化能力强，物理可行性优于现有方法。

Abstract: To reliably pick and place unknown objects under real-world sensing noise
remains a challenging task, as existing methods rely on strong object priors
(e.g., CAD models), or planar-support assumptions, limiting generalization and
unified reasoning between grasping and placing. In this work, we introduce a
generalized placeability metric that evaluates placement poses directly from
noisy point clouds, without any shape priors. The metric jointly scores
stability, graspability, and clearance. From raw geometry, we extract the
support surfaces of the object to generate diverse candidates for
multi-orientation placement and sample contacts that satisfy collision and
stability constraints. By conditioning grasp scores on each candidate
placement, our proposed method enables model-free unified pick-and-place
reasoning and selects grasp-place pairs that lead to stable, collision-free
placements. On unseen real objects and non-planar object supports, our metric
delivers CAD-comparable accuracy in predicting stability loss and generally
produces more physically plausible placements than learning-based predictors.

</details>


### [242] [Proprioceptive Image: An Image Representation of Proprioceptive Data from Quadruped Robots for Contact Estimation Learning](https://arxiv.org/abs/2510.14612)
*Gabriel Fischer Abati,João Carlos Virgolino Soares,Giulio Turrisi,Victor Barasuol,Claudio Semini*

Main category: cs.RO

TL;DR: 该论文提出将四足机器人本体感知时序数据转化为结构化二维图像，从而利用卷积神经网络进行运动任务学习。这一图像编码方法提升了预测准确率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要直接对本体感知时序数据进行处理，难以充分捕捉各信号间相关性和序列整体模式，限制了机器人自主运动性能。作者希望通过新的数据表征方式改善这一问题。

Method: 作者提出将机器人各传感器（如关节位置、IMU、脚速）多通道时序数据，按照机器人形态结构映射为二维图像，借助CNN提取时序关联特征。该方法应用于接触状态估计任务，通过保持结构信息，提升数据表征能力与下游任务性能。

Result: 在真实机器人和仿真环境中实验表明，该图像表征方法相比传统序列模型大幅提升了预测准确性和泛化能力。在具体的接触数据集上，准确率从当前最优的87.7%提升到94.5%，同时使用的数据窗口长度缩短了15倍。

Conclusion: 通过本体感知数据的跨模态图像编码，能更高效地提取机器人运动特征，为稳定自适应运动等任务带来性能提升，证明了其在机器人状态学习上的应用潜力。

Abstract: This paper presents a novel approach for representing proprioceptive
time-series data from quadruped robots as structured two-dimensional images,
enabling the use of convolutional neural networks for learning
locomotion-related tasks. The proposed method encodes temporal dynamics from
multiple proprioceptive signals, such as joint positions, IMU readings, and
foot velocities, while preserving the robot's morphological structure in the
spatial arrangement of the image. This transformation captures inter-signal
correlations and gait-dependent patterns, providing a richer feature space than
direct time-series processing. We apply this concept in the problem of contact
estimation, a key capability for stable and adaptive locomotion on diverse
terrains. Experimental evaluations on both real-world datasets and simulated
environments show that our image-based representation consistently enhances
prediction accuracy and generalization over conventional sequence-based models,
underscoring the potential of cross-modal encoding strategies for robotic state
learning. Our method achieves superior performance on the contact dataset,
improving contact state accuracy from 87.7% to 94.5% over the recently proposed
MI-HGNN method, using a 15 times shorter window size.

</details>


### [243] [Accelerated Multi-Modal Motion Planning Using Context-Conditioned Diffusion Models](https://arxiv.org/abs/2510.14615)
*Edward Sandra,Lander Vanroye,Dries Dirckx,Ruben Cartuyvels,Jan Swevers,Wilm Decré*

Main category: cs.RO

TL;DR: 本文提出了一种称为Context-Aware Motion Planning Diffusion（CAMPD）的运动规划扩散模型，在无需专用传感器和重新训练的前提下，能在复杂未知环境中高效生成多模态高质量的机器人运动轨迹，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的采样或优化方法在高维空间和复杂环境下可扩展性差，现有扩散模型方法对新环境泛化能力有限，并且多数依赖特定传感器。本文致力于提升运动规划的泛化能力和传感器无关性，以便机器人能适应多变环境。

Method: 提出一种不依赖于特定传感器的CAMPD模型，利用无分类器的去噪扩散概率模型，并将注意力机制与U-Net架构结合，从任意数量的上下文参数中提取环境信息，指导运动规划生成。

Result: 在7自由度机械臂和多个真实任务场景下，CAMPD与先进方法对比，展现了出色的对新环境的泛化能力，能够更快生成高质量多模态轨迹。

Conclusion: CAMPD不但消除了对特定传感器的依赖，还大幅提升了运动规划的泛化与效率，为机器人在多变环境下的应用提供了有力支撑。

Abstract: Classical methods in robot motion planning, such as sampling-based and
optimization-based methods, often struggle with scalability towards
higher-dimensional state spaces and complex environments. Diffusion models,
known for their capability to learn complex, high-dimensional and multi-modal
data distributions, provide a promising alternative when applied to motion
planning problems and have already shown interesting results. However, most of
the current approaches train their model for a single environment, limiting
their generalization to environments not seen during training. The techniques
that do train a model for multiple environments rely on a specific camera to
provide the model with the necessary environmental information and therefore
always require that sensor. To effectively adapt to diverse scenarios without
the need for retraining, this research proposes Context-Aware Motion Planning
Diffusion (CAMPD). CAMPD leverages a classifier-free denoising probabilistic
diffusion model, conditioned on sensor-agnostic contextual information. An
attention mechanism, integrated in the well-known U-Net architecture,
conditions the model on an arbitrary number of contextual parameters. CAMPD is
evaluated on a 7-DoF robot manipulator and benchmarked against state-of-the-art
approaches on real-world tasks, showing its ability to generalize to unseen
environments and generate high-quality, multi-modal trajectories, at a fraction
of the time required by existing methods.

</details>


### [244] [GOPLA: Generalizable Object Placement Learning via Synthetic Augmentation of Human Arrangement](https://arxiv.org/abs/2510.14627)
*Yao Zhong,Hanzhi Chen,Simon Schaefer,Anran Zhang,Stefan Leutenegger*

Main category: cs.RO

TL;DR: 本论文提出了一种名为GOPLA的层次化框架，通过人类演示和多模态大语言模型，实现机器人在家庭场景下的智能物体摆放。该方法结合语义偏好和几何可行性，极大提升了机器人摆放的成功率和泛化性。


<details>
  <summary>Details</summary>
Motivation: 机器人在家庭环境中作为智能助手，需要能够智能地摆放物体。但这项任务涉及语义推理（如常识性物品关系）和几何约束（如避免碰撞），目前通用性和泛化能力较强的方法尚欠缺，因此亟需一种能够高效泛化且安全有效的物体摆放方法。

Method: 论文提出GOPLA层次化框架，流程分为三步：首先用多模态大语言模型将人类指令和视觉输入翻译为物品关系的结构化计划；其次，空间映射器将这些计划转为具有几何常识的3D可供性地图；最后，基于扩散的规划器在测试时综合多种计划分布和碰撞规避，生成最终物体摆放位姿。此外，还构建了大规模合成人类演示数据管线，解决了现实数据稀缺问题。

Result: 在丰富的实验中，GOPLA在定位精度和物理可实现性评价上，摆放成功率比第二名方法提高了30.04个百分点，展现出在多种真实机器人场景下的强泛化能力。

Conclusion: GOPLA有效结合了人类常识和几何推理，显著提升了机器人物体摆放的普适性和成功率，为家庭机器人智能交互铺平了道路，并证明了通过扩展人类演示与多模态模型结合的策略在实际场景中的高效性。

Abstract: Robots are expected to serve as intelligent assistants, helping humans with
everyday household organization. A central challenge in this setting is the
task of object placement, which requires reasoning about both semantic
preferences (e.g., common-sense object relations) and geometric feasibility
(e.g., collision avoidance). We present GOPLA, a hierarchical framework that
learns generalizable object placement from augmented human demonstrations. A
multi-modal large language model translates human instructions and visual
inputs into structured plans that specify pairwise object relationships. These
plans are then converted into 3D affordance maps with geometric common sense by
a spatial mapper, while a diffusion-based planner generates placement poses
guided by test-time costs, considering multi-plan distributions and collision
avoidance. To overcome data scarcity, we introduce a scalable pipeline that
expands human placement demonstrations into diverse synthetic training data.
Extensive experiments show that our approach improves placement success rates
by 30.04 percentage points over the runner-up, evaluated on positioning
accuracy and physical plausibility, demonstrating strong generalization across
a wide range of real-world robotic placement scenarios.

</details>


### [245] [Generative Models From and For Sampling-Based MPC: A Bootstrapped Approach For Adaptive Contact-Rich Manipulation](https://arxiv.org/abs/2510.14643)
*Lara Brudermüller,Brandon Hung,Xinghao Zhu,Jiuguang Wang,Nick Hawes,Preston Culbertson,Simon Le Cleac'h*

Main category: cs.RO

TL;DR: 提出了生成式预测控制（GPC）框架，结合条件流匹配模型，实现了对采样式模型预测控制（SPC）的高效替代，并首次在四足机器人实际高接触操作中验证。


<details>
  <summary>Details</summary>
Motivation: 采样式MPC（如SPC）在机器人运动控制中效果突出，但计算成本高，采样效率低。此前方案多依赖迭代优化或梯度方法，缺乏高效的直接生成机制，且在真实任务中的泛化性有限。因此，亟需一种更高效、样本利用率更高且具备现实应用能力的控制策略。

Method: 作者用SPC在仿真中收集控制序列，用条件流匹配模型在此数据上训练分布生成器，再在实际任务中用生成器高效采样实现在线规划，绕过传统的反复优化步骤。

Result: 在仿真和实际四足机器人复杂操作任务中，GPC方法显著提升采样效率，缩短规划时域长度需求，并展现出较强的背景任务适应能力和泛化性能。

Conclusion: GPC为采样式MPC提供了更高效、更现实可用的工具，有效提升了在线规划的效率和鲁棒性，为高接触机器人操作等实际应用场景带来新方法。

Abstract: We present a generative predictive control (GPC) framework that amortizes
sampling-based Model Predictive Control (SPC) by bootstrapping it with
conditional flow-matching models trained on SPC control sequences collected in
simulation. Unlike prior work relying on iterative refinement or gradient-based
solvers, we show that meaningful proposal distributions can be learned directly
from noisy SPC data, enabling more efficient and informed sampling during
online planning. We further demonstrate, for the first time, the application of
this approach to real-world contact-rich loco-manipulation with a quadruped
robot. Extensive experiments in simulation and on hardware show that our method
improves sample efficiency, reduces planning horizon requirements, and
generalizes robustly across task variations.

</details>


### [246] [Spatially anchored Tactile Awareness for Robust Dexterous Manipulation](https://arxiv.org/abs/2510.14647)
*Jialei Huang,Yang Ye,Yuanqing Gong,Xuezhou Zhu,Yang Gao,Kaifeng Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种名为SaTA的空间锚定触觉感知框架，通过将触觉特征显式地锚定到手部运动学参考系，从而提升灵巧操作中的几何推理精度，突破现有方法难以达到的亚毫米级精度限制，在多个高难度任务上显著优于现有学习方法。


<details>
  <summary>Details</summary>
Motivation: 尽管触觉传感器能带来丰富的接触信息，但现有的学习方法未能有效结合触觉信号的细腻感知能力与手部运动学之间的空间关系，导致难以胜任高精度操作。而传统模型基方法虽然精度高，但受限于对对象模型和姿态估计的要求。为解决这一矛盾，作者希望通过更有效的触觉表示，兼顾感知丰富性和空间参照，推动基于学习的方法实现高精度灵巧操作。

Method: 提出SaTA（Spatially-anchored Tactile Awareness）方法，将触觉特征通过正向运动学映射到手部的稳定参考系，构建空间锚定的触觉表示，使策略能够不仅检测接触，还能在手部坐标系中精确推断物体几何形状。整个策略为端到端学习，不依赖物体模型或显式的位姿估计。

Result: 在多项精密灵巧操作任务（如自由空间双手USB-C对接、灯泡旋装、卡片滑动）中，SaTA相较于现有强大的视觉-触觉基线方法，成功率提升最高达30%，任务完成时间节省27%。

Conclusion: 空间锚定的触觉表示让学习策略能结合感知丰富性与空间推理，显著提升高精度操作任务表现，无需复杂的物体建模或位姿估计，为基于学习的灵巧操作系统提供了新思路。

Abstract: Dexterous manipulation requires precise geometric reasoning, yet existing
visuo-tactile learning methods struggle with sub-millimeter precision tasks
that are routine for traditional model-based approaches. We identify a key
limitation: while tactile sensors provide rich contact information, current
learning frameworks fail to effectively leverage both the perceptual richness
of tactile signals and their spatial relationship with hand kinematics. We
believe an ideal tactile representation should explicitly ground contact
measurements in a stable reference frame while preserving detailed sensory
information, enabling policies to not only detect contact occurrence but also
precisely infer object geometry in the hand's coordinate system. We introduce
SaTA (Spatially-anchored Tactile Awareness for dexterous manipulation), an
end-to-end policy framework that explicitly anchors tactile features to the
hand's kinematic frame through forward kinematics, enabling accurate geometric
reasoning without requiring object models or explicit pose estimation. Our key
insight is that spatially grounded tactile representations allow policies to
not only detect contact occurrence but also precisely infer object geometry in
the hand's coordinate system. We validate SaTA on challenging dexterous
manipulation tasks, including bimanual USB-C mating in free space, a task
demanding sub-millimeter alignment precision, as well as light bulb
installation requiring precise thread engagement and rotational control, and
card sliding that demands delicate force modulation and angular precision.
These tasks represent significant challenges for learning-based methods due to
their stringent precision requirements. Across multiple benchmarks, SaTA
significantly outperforms strong visuo-tactile baselines, improving success
rates by up to 30 percentage while reducing task completion times by 27
percentage.

</details>


### [247] [When Planners Meet Reality: How Learned, Reactive Traffic Agents Shift nuPlan Benchmarks](https://arxiv.org/abs/2510.14677)
*Steffen Hagedorn,Luka Donkov,Aron Distelzweig,Alexandru P. Condurache*

Main category: cs.RO

TL;DR: 本论文指出现有闭环仿真中常用的基于规则的交通代理（如IDM）过于简单，掩盖了自动驾驶规划器的不足。作者将更先进的SMART模型集成到nuPlan中，发现更真实的交互会显著影响评测结论，因此建议SMART代理应成为新的基准。


<details>
  <summary>Details</summary>
Motivation: 现有的闭环仿真采用的IDM规则型交通代理缺乏与旁车的复杂交互，导致对自动驾驶规划器的评测不充分甚至偏颇，难以反映真实世界交通交互带来的挑战，需要更先进的代理模型。

Method: 作者将深度学习驱动的SMART交通代理模型无缝集成到nuPlan仿真平台，对14种近期主流规划器和常用基线进行评测，比较了IDM代理和SMART代理下的评测表现，并考察了在多车道、复杂交互场景（如变道、转弯）中的规划性能。

Result: 结果表明，采用IDM代理会高估规划器性能，切换到SMART代理后，几乎所有规划器的得分普遍下降；但部分规划器在多车道复杂交互下表现优于以往设想。闭环训练的方法鲁棒性最好，但面对极端场景时，学习型规划器退化迅速，传统规则规划器仍能保持基础能力。

Conclusion: 建议采用SMART反应式代理替代IDM作为nuPlan仿真的新标准闭环基准，以更真实地评价规划器性能。同时，公开SMART代理代码，方便社区实践。

Abstract: Planner evaluation in closed-loop simulation often uses rule-based traffic
agents, whose simplistic and passive behavior can hide planner deficiencies and
bias rankings. Widely used IDM agents simply follow a lead vehicle and cannot
react to vehicles in adjacent lanes, hindering tests of complex interaction
capabilities. We address this issue by integrating the state-of-the-art learned
traffic agent model SMART into nuPlan. Thus, we are the first to evaluate
planners under more realistic conditions and quantify how conclusions shift
when narrowing the sim-to-real gap. Our analysis covers 14 recent planners and
established baselines and shows that IDM-based simulation overestimates
planning performance: nearly all scores deteriorate. In contrast, many planners
interact better than previously assumed and even improve in multi-lane,
interaction-heavy scenarios like lane changes or turns. Methods trained in
closed-loop demonstrate the best and most stable driving performance. However,
when reaching their limits in augmented edge-case scenarios, all learned
planners degrade abruptly, whereas rule-based planners maintain reasonable
basic behavior. Based on our results, we suggest SMART-reactive simulation as a
new standard closed-loop benchmark in nuPlan and release the SMART agents as a
drop-in alternative to IDM at https://github.com/shgd95/InteractiveClosedLoop.

</details>


### [248] [Leveraging Neural Descriptor Fields for Learning Contact-Aware Dynamic Recovery](https://arxiv.org/abs/2510.14768)
*Fan Yang,Zixuan Huang,Abhinav Kumar,Sergio Aguilera Marinovic,Soshi Iba,Rana Soltani Zarrin,Dmitry Berenson*

Main category: cs.RO

TL;DR: 本文提出了一种面向真实灵巧操作的强化学习框架CADRE，通过引入神经描述子场（NDF）提取手指与物体的隐式接触特征，提高了机械手在物体将要掉落时的恢复与抓取能力。该方法提升了训练效率和恢复成功率，并能处理不同几何形状的未知物体。


<details>
  <summary>Details</summary>
Motivation: 现实中的灵巧操作常会遇到突发错误和干扰，导致物体掉落等失败。如何在物体掉落但仍在抓取范围内时，快速恢复抓取状态并继续操作，是提升机器人可靠性的重要挑战。

Method: 提出Contact-Aware Dynamic Recovery（CADRE）框架，在强化学习训练中引入NDF模块，直接提取手指与物体的隐式接触特征，使系统能更有效地处理不同物体的几何结构，实现对接触状态的感知与自适应。

Result: 实验表明，结合接触特征的信息不仅加速了训练收敛，还显著提升了恢复抓取成功率。此外，CADRE在面对未见过的不同几何形状物体时表现出良好的零样本泛化能力。

Conclusion: 引入接触感知特征的CADRE框架显著提升了灵巧机械手在各种干扰下的恢复能力，并具备对新颖物体的泛化潜力，为实际应用提供更加稳健的方案。

Abstract: Real-world dexterous manipulation often encounters unexpected errors and
disturbances, which can lead to catastrophic failures, such as dropping the
manipulated object. To address this challenge, we focus on the problem of
catching a falling object while it remains within grasping range and,
importantly, resetting the system to a configuration favorable for resuming the
primary manipulation task. We propose Contact-Aware Dynamic Recovery (CADRE), a
reinforcement learning framework that incorporates a Neural Descriptor Field
(NDF)-inspired module to extract implicit contact features. Compared to methods
that rely solely on object pose or point cloud input, NDFs can directly reason
about finger-object correspondence and adapt to different object geometries.
Our experiments show that incorporating contact features improves training
efficiency, enhances convergence performance for RL training, and ultimately
leads to more successful recoveries. Additionally, we demonstrate that CADRE
can generalize zero-shot to unseen objects with different geometries.

</details>


### [249] [Open TeleDex: A Hardware-Agnostic Teleoperation System for Imitation Learning based Dexterous Manipulation](https://arxiv.org/abs/2510.14771)
*Xu Chi,Chao Zhang,Yang Su,Lingfeng Dou,Fujia Yang,Jiakuo Zhao,Haoyu Zhou,Xiaoyou Jia,Yong Zhou,Shan An*

Main category: cs.RO

TL;DR: 本文提出了Open TeleDex系统，实现了适用于各种机械臂、灵巧手和外部输入设备的统一远程操作数据采集平台，提升了机器人模仿学习的数据采集精度和兼容性。


<details>
  <summary>Details</summary>
Motivation: 高质量演示数据采集是机器人模仿学习部署的瓶颈，尤其是在异构机器人平台下，现有系统难以支持高精度、多样性的远程操作数据采集。

Method: 作者开发了Open TeleDex远程操作框架，实现了对任意机械臂、任意机械手和任意外部输入设备的支持（TripleAny），并提出了一种新的手姿态重定向算法，大幅提升了系统的互操作性和兼容性。

Result: Open TeleDex能稳定、准确地支持更广泛的异构主设备和从设备的数据采集，显著提升了演示数据质量与适用范围。

Conclusion: Open TeleDex为复杂机器人操作与模仿学习提供了一个高质量、公开可用的基础平台，有助于加速学术和工业的研究与应用开发。

Abstract: Accurate and high-fidelity demonstration data acquisition is a critical
bottleneck for deploying robot Imitation Learning (IL) systems, particularly
when dealing with heterogeneous robotic platforms. Existing teleoperation
systems often fail to guarantee high-precision data collection across diverse
types of teleoperation devices. To address this, we developed Open TeleDex, a
unified teleoperation framework engineered for demonstration data collection.
Open TeleDex specifically tackles the TripleAny challenge, seamlessly
supporting any robotic arm, any dexterous hand, and any external input device.
Furthermore, we propose a novel hand pose retargeting algorithm that
significantly boosts the interoperability of Open TeleDex, enabling robust and
accurate compatibility with an even wider spectrum of heterogeneous master and
slave equipment. Open TeleDex establishes a foundational, high-quality, and
publicly available platform for accelerating both academic research and
industry development in complex robotic manipulation and IL.

</details>


### [250] [SkyDreamer: Interpretable End-to-End Vision-Based Drone Racing with Model-Based Reinforcement Learning](https://arxiv.org/abs/2510.14783)
*Aderik Verraest,Stavrow Bahnam,Robin Ferede,Guido de Croon,Christophe De Wagter*

Main category: cs.RO

TL;DR: SkyDreamer是一种端到端视觉自主无人机竞速系统，实现了高性能、高鲁棒性的自主飞行，并支持从仿真到现实的迁移与机载实时执行。


<details>
  <summary>Details</summary>
Motivation: 尽管自动无人机竞速取得了冠军级别表现，但现有系统往往专属特定场景，且很难实现端到端视觉、从仿真到现实的无缝迁移、以及机载高性能执行。

Method: 作者提出了SkyDreamer系统，采用了基于Dreamer的模型强化学习方法，将像素级视觉输入端到端地映射为电机指令。世界模型在训练时通过特权信息学习隐状态，用作状态和参数估计器，实现更好解释性，并可直接在不同无人机上飞行无需重训练。系统能实现机载全流程计算，无需外部校准。

Result: SkyDreamer在真实无人机竞速中实现了高速度（最高21m/s）、高加速度（最高6g）、复杂动作（如倒转环、阶梯、split-S）等表现。同时展现出在低质量视觉分割、动力衰减等现实因素下的鲁棒性和自适应能力。

Conclusion: SkyDreamer显著缩小了从仿真到现实的“现实鸿沟”，兼顾了高性能和实际部署的适应性，为端到端自主无人机竞速提供了具有可扩展性和鲁棒性的解决方案。

Abstract: Autonomous drone racing (ADR) systems have recently achieved champion-level
performance, yet remain highly specific to drone racing. While end-to-end
vision-based methods promise broader applicability, no system to date
simultaneously achieves full sim-to-real transfer, onboard execution, and
champion-level performance. In this work, we present SkyDreamer, to the best of
our knowledge, the first end-to-end vision-based ADR policy that maps directly
from pixel-level representations to motor commands. SkyDreamer builds on
informed Dreamer, a model-based reinforcement learning approach where the world
model decodes to privileged information only available during training. By
extending this concept to end-to-end vision-based ADR, the world model
effectively functions as an implicit state and parameter estimator, greatly
improving interpretability. SkyDreamer runs fully onboard without external aid,
resolves visual ambiguities by tracking progress using the state decoded from
the world model's hidden state, and requires no extrinsic camera calibration,
enabling rapid deployment across different drones without retraining.
Real-world experiments show that SkyDreamer achieves robust, high-speed flight,
executing tight maneuvers such as an inverted loop, a split-S and a ladder,
reaching speeds of up to 21 m/s and accelerations of up to 6 g. It further
demonstrates a non-trivial visual sim-to-real transfer by operating on
poor-quality segmentation masks, and exhibits robustness to battery depletion
by accurately estimating the maximum attainable motor RPM and adjusting its
flight path in real-time. These results highlight SkyDreamer's adaptability to
important aspects of the reality gap, bringing robustness while still achieving
extremely high-speed, agile flight.

</details>


### [251] [Neural Implicit Flow Fields for Spatio-Temporal Motion Mapping](https://arxiv.org/abs/2510.14827)
*Yufei Zhu,Shih-Min Yang,Andrey Rudenko,Tomasz P. Kucner,Achim J. Lilienthal,Martin Magnusson*

Main category: cs.RO

TL;DR: 本文提出了一种基于隐式神经函数的连续时空动态地图（MoD）方法，用于高效、准确地建模复杂环境下的人类运动模式，无需离散化和插值，在实际数据集验证中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有动态地图（MoD）表征在空间上采用离散采样，并且通常需要昂贵的离线构建过程，导致对非均匀采样区域的泛化能力有限且效率低。为提升机器人在复杂人类环境中的安全、高效运行，需要一种更连续、高效的运动模式建模方法。

Method: 提出使用隐式神经函数，从空间-时间坐标直接映射到半包裹高斯混合模型参数，实现对运动模式的连续建模，无需离散化和插值，提升了模型在空间和时间上的平滑泛化能力。

Result: 在大规模公开数据集和长时间真实世界的人体追踪数据上进行验证，新方法在运动表征的准确性和稀疏区域速度分布的平滑性方面均优于现有基线方法，同时保持较高计算效率。

Conclusion: 基于隐式神经函数的连续动态地图方法能够高效准确地建模复杂的人类运动模式，为机器人在复杂人类环境下的安全、高效运行提供有力支持。

Abstract: Safe and efficient robot operation in complex human environments can benefit
from good models of site-specific motion patterns. Maps of Dynamics (MoDs)
provide such models by encoding statistical motion patterns in a map, but
existing representations use discrete spatial sampling and typically require
costly offline construction. We propose a continuous spatio-temporal MoD
representation based on implicit neural functions that directly map coordinates
to the parameters of a Semi-Wrapped Gaussian Mixture Model. This removes the
need for discretization and imputation for unevenly sampled regions, enabling
smooth generalization across both space and time. Evaluated on a large public
dataset with long-term real-world people tracking data, our method achieves
better accuracy of motion representation and smoother velocity distributions in
sparse regions while still being computationally efficient, compared to
available baselines. The proposed approach demonstrates a powerful and
efficient way of modeling complex human motion patterns.

</details>


### [252] [RL-100: Performant Robotic Manipulation with Real-World Reinforcement Learning](https://arxiv.org/abs/2510.14830)
*Kun Lei,Huanyu Li,Dongjie Yu,Zhenyu Wei,Lingxiao Guo,Zhennan Jiang,Ziyu Wang,Shiyu Liang,Huazhe Xu*

Main category: cs.RO

TL;DR: RL-100提出了一种面向实际环境的机器人控制强化学习框架，通过三阶段流程（模仿学习、离线强化学习、在线强化学习）和一致性蒸馏，有效提升任务表现，实现多种机器人平台和任务的全胜率。


<details>
  <summary>Details</summary>
Motivation: 机器人在家庭和工厂等真实环境中操作时，需要达到甚至超越熟练人类操作员的可靠性、效率和鲁棒性，而当前方法在任务成功率和持续作业能力上仍有限。

Method: RL-100采用三阶段流程：先通过模仿学习注入人类经验；再用带有OPE门控的离线PPO式更新实现保守可靠提升；最后在线强化学习消除剩余失败模式。同时，用一致性蒸馏将扩散模型多步采样简化为单步，提高控制频率和实时性。该方法可处理3D点云和2D图像，适用于多种任务和平台。

Result: RL-100在七项真实机器人任务（如动态物体控制、液体/颗粒倒入、布料折叠、灵巧拆卸、复合榨汁等）上，全胜完成900/900次试验，单任务最多实现250次连续成功，效率接近或优于人工远程操控，且可连续稳定运行达两小时。

Conclusion: RL-100在多种实际场景下实现了极高的可靠性、效率和鲁棒性，表明其为通用、高效的机器人操作控制方案，显著提升了现有机器人在真实环境中的应用潜力。

Abstract: Real-world robotic manipulation in homes and factories demands reliability,
efficiency, and robustness that approach or surpass skilled human operators. We
present RL-100, a real-world reinforcement learning training framework built on
diffusion visuomotor policies trained bu supervised learning. RL-100 introduces
a three-stage pipeline. First, imitation learning leverages human priors.
Second, iterative offline reinforcement learning uses an Offline Policy
Evaluation procedure, abbreviated OPE, to gate PPO-style updates that are
applied in the denoising process for conservative and reliable improvement.
Third, online reinforcement learning eliminates residual failure modes. An
additional lightweight consistency distillation head compresses the multi-step
sampling process in diffusion into a single-step policy, enabling
high-frequency control with an order-of-magnitude reduction in latency while
preserving task performance. The framework is task-, embodiment-, and
representation-agnostic and supports both 3D point clouds and 2D RGB inputs, a
variety of robot platforms, and both single-step and action-chunk policies. We
evaluate RL-100 on seven real-robot tasks spanning dynamic rigid-body control,
such as Push-T and Agile Bowling, fluids and granular pouring, deformable cloth
folding, precise dexterous unscrewing, and multi-stage orange juicing. RL-100
attains 100\% success across evaluated trials for a total of 900 out of 900
episodes, including up to 250 out of 250 consecutive trials on one task. The
method achieves near-human teleoperation or better time efficiency and
demonstrates multi-hour robustness with uninterrupted operation lasting up to
two hours.

</details>


### [253] [Multi Agent Switching Mode Controller for Sound Source localization](https://arxiv.org/abs/2510.14849)
*Marcello Sorge,Nicola Cigarini,Riccardo Lorigiola,Giulia Michieletto,Andrea Masiero,Angelo Cenedese,Alberto Guarnieri*

Main category: cs.RO

TL;DR: 本文提出了一种基于声源的多机器人切换模式控制策略，能够实现单源和多源目标定位。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，直接视觉定位常常受阻，声源作为目标提供额外手段，提升机器人在恶劣环境下的定位能力。

Method: 设计了一种多机器人切换模式控制方法：在单音源情境下，所有机器人以刚性编队方式靠近目标；在多音源情境下，各自独立搜索不同声源。

Result: 控制策略能适应单源和多源定位任务，使机器人团队能有效、灵活地完成不同目标搜寻任务。

Conclusion: 所提出的声源定位多机器人控制策略在应对不同场景下的定位任务中表现出良好的通用性和灵活性。

Abstract: Source seeking is an important topic in robotic research, especially
considering sound-based sensors since they allow the agents to locate a target
even in critical conditions where it is not possible to establish a direct line
of sight. In this work, we design a multi- agent switching mode control
strategy for acoustic-based target localization. Two scenarios are considered:
single source localization, in which the agents are driven maintaining a rigid
formation towards the target, and multi-source scenario, in which each agent
searches for the targets independently from the others.

</details>


### [254] [SADCHER: Scheduling using Attention-based Dynamic Coalitions of Heterogeneous Robots in Real-Time](https://arxiv.org/abs/2510.14851)
*Jakob Bichler,Andreu Matoses Gimenez,Javier Alonso-Mora*

Main category: cs.RO

TL;DR: 本文提出了Sadcher，一个用于异构多机器人团队实时任务分配的框架。Sadcher通过模仿学习训练，结合图注意力和Transformer，并应用松弛的二部图匹配来实现高质量调度，能够有效处理任务优先级和异质性。实验表明，Sadcher在规模扩展和泛化能力方面优于现有方法，并能满足实时计算需求。


<details>
  <summary>Details</summary>
Motivation: 异构多机器人协作任务分配问题（尤其是包含动态联盟和任务顺序约束）极具挑战性，现有方法在效率、可扩展性或泛化能力上存在不足。为了实现更高效、高质量且能实时运作的分配，作者提出Sadcher。

Method: Sadcher采用模仿学习进行训练，将图注意力网络与Transformer结合，预测每个机器人-任务对之间的分配奖励。利用松弛的二部图匹配获得调度方案，显式建模机器人/任务位置、任务时长与机器人剩余处理时间，提升时空推理与泛化能力。

Result: Sadcher在小规模实例上通过最优解数据集进行训练，能够扩展到更大规模的任务和机器人团队。与现有基于学习和启发式方法相比，在随机生成的测试集和中小队伍规模下，Sadcher取得了更好的分配效果和可拓展性，同时保持实时运算能力。

Conclusion: Sadcher框架为多机器人任务分配提供了高效、可扩展且可泛化的解决方案，优于其他基线方法，并适合实际场景中的实时运作。同时，作者公开了大规模最优调度数据集，助力相关研究。

Abstract: We present Sadcher, a real-time task assignment framework for heterogeneous
multi-robot teams that incorporates dynamic coalition formation and task
precedence constraints. Sadcher is trained through Imitation Learning and
combines graph attention and transformers to predict assignment rewards between
robots and tasks. Based on the predicted rewards, a relaxed bipartite matching
step generates high-quality schedules with feasibility guarantees. We
explicitly model robot and task positions, task durations, and robots'
remaining processing times, enabling advanced temporal and spatial reasoning
and generalization to environments with different spatiotemporal distributions
compared to training. Trained on optimally solved small-scale instances, our
method can scale to larger task sets and team sizes. Sadcher outperforms other
learning-based and heuristic baselines on randomized, unseen problems for small
and medium-sized teams with computation times suitable for real-time operation.
We also explore sampling-based variants and evaluate scalability across robot
and task counts. In addition, we release our dataset of 250,000 optimal
schedules: https://autonomousrobots.nl/paper_websites/sadcher_MRTA/

</details>


### [255] [STITCHER: Constrained Trajectory Planning in Known Environments with Real-Time Motion Primitive Search](https://arxiv.org/abs/2510.14893)
*Helene J. Levy,Brett T. Lopez*

Main category: cs.RO

TL;DR: 该论文提出了一个名为STITCHER的实时高效轨迹规划框架，无需数值优化，能够在大型复杂环境中为自主导航生成动态可行且安全的轨迹，并在实验和实际硬件测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统轨迹规划主要依赖数值优化，虽然可以系统性满足多种约束并生成高质量轨迹，但计算速度慢并存在数值不稳定的风险，特别是在安全关键的高速导航场景下表现受限。作者试图解决如何在保证约束和轨迹质量的情况下，提升规划的实时性和可靠性。

Method: 作者提出STITCHER框架，将多个短轨迹片段无缝拼接，并通过图搜索算法组合成全局长距离轨迹，完全抛弃了传统的数值优化过程。该方法结合了创新的规划架构与一系列算法改进，从而实现了实时、高质量的轨迹生成。

Result: 在大规模仿真实验中，STITCHER能在数毫秒内为两个50m×50m场景生成安全轨迹，表现优于当前主流的优化规划器。硬件实验证明其可实时生成可跟踪轨迹，并严格满足非凸约束（如俯仰角、马达力限制），这些约束在基于优化的方法中往往难以高效处理。

Conclusion: STITCHER框架能在不依赖数值优化的前提下，实时高效地为自主系统生成安全、动态可行且满足高复杂度约束的轨迹，展现了优于现有优化规划方法的潜力，尤其适用于安全关键和对实时性要求极高的实际应用。

Abstract: Autonomous high-speed navigation through large, complex environments requires
real-time generation of agile trajectories that are dynamically feasible,
collision-free, and satisfy state or actuator constraints. Modern trajectory
planning techniques primarily use numerical optimization, as they enable the
systematic computation of high-quality, expressive trajectories that satisfy
various constraints. However, stringent requirements on computation time and
the risk of numerical instability can limit the use of optimization-based
planners in safety-critical scenarios. This work presents an optimization-free
planning framework called STITCHER that stitches short trajectory segments
together with graph search to compute long-range, expressive, and near-optimal
trajectories in real-time. STITCHER outperforms modern optimization-based
planners through our innovative planning architecture and several algorithmic
developments that make real-time planning possible. Extensive simulation
testing is performed to analyze the algorithmic components that make up
STITCHER, along with a thorough comparison with two state-of-the-art
optimization planners. Simulation tests show that safe trajectories can be
created within a few milliseconds for paths that span the entirety of two 50 m
x 50 m environments. Hardware tests with a custom quadrotor verify that
STITCHER can produce trackable paths in real-time while respecting nonconvex
constraints, such as limits on tilt angle and motor forces, which are otherwise
hard to include in optimization-based planners.

</details>


### [256] [VLA^2: Empowering Vision-Language-Action Models with an Agentic Framework for Unseen Concept Manipulation](https://arxiv.org/abs/2510.14902)
*Han Zhao,Jiaxuan Zhang,Wenxuan Song,Pengxiang Ding,Donglin Wang*

Main category: cs.RO

TL;DR: 本论文提出了VLA^2框架，通过集成外部模块增强VLA模型泛化能力，显著提升了机器人在未知物体上的操作成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作(VLA)模型尽管在已知任务上表现优异，但在遇到未见过的物体描述和纹理时，泛化能力严重下降，导致操作成功率大幅降低。这种现象限制了机器人在实际复杂环境中的应用。

Method: 作者提出VLA^2框架，以OpenVLA为核心执行模型，整合了网页检索和目标检测等外部知识模块，为VLA模型提供目标物体的视觉和文本知识，从而弥补其在面对分布外物体时的泛化不足。并基于LIBERO仿真环境设计了新的测试基准，包括引入全新物体与描述，分为三个难度等级。

Result: 在自建的高难度泛化基准上，VLA^2大幅超越现有最优方法，比OpenVLA基线模型在高难度任务上成功率提升44.2%，在全部定制环境中平均提升20.2%，且在原有测试任务上无性能损失。

Conclusion: VLA^2通过整合外部视觉和文本知识，显著提升了VLA模型对分布外物体的泛化能力，为机器人在多样化实际场景中的应用开辟了新方向。

Abstract: Current vision-language-action (VLA) models, pre-trained on large-scale
robotic data, exhibit strong multi-task capabilities and generalize well to
variations in visual and language instructions for manipulation. However, their
success rate drops significantly when faced with object concepts outside the
training data, such as unseen object descriptions and textures in the dataset.
To address this, we propose a novel agentic framework, VLA^2, which leverages
OpenVLA as the execution backbone and effectively leverages external modules
such as web retrieval and object detection to provide visual and textual
knowledge about target objects to the VLA. This approach mitigates
generalization failure when handling out-of-distribution objects. Based on the
LIBERO simulation environment, we introduced novel objects and object
descriptions to construct a new evaluation benchmark with three difficulty
levels to test the effectiveness of our method. Our framework successfully
outperformed the current state-of-the-art models on our designed hard-level
generalization benchmark. Compared to the standalone OpenVLA baseline, VLA^2
achieves a 44.2% improvement in the success rate in the hard-level benchmark
and an average improvement of 20.2% in all customized environments without any
performance degradation on in-domain tasks. Project website:
https://vla-2.github.io.

</details>


### [257] [VT-Refine: Learning Bimanual Assembly with Visuo-Tactile Feedback via Simulation Fine-Tunin](https://arxiv.org/abs/2510.14930)
*Binghao Huang,Jie Xu,Iretiayo Akinola,Wei Yang,Balakumar Sundaralingam,Rowland O'Flaherty,Dieter Fox,Xiaolong Wang,Arsalan Mousavian,Yu-Wei Chao,Yunzhu Li*

Main category: cs.RO

TL;DR: 本文提出了一个融合视觉和触觉的策略学习框架VT-Refine，用于提升机器人高精度双手组装任务的性能。通过结合人类演示、精细触觉模拟和强化学习，显著提高了机器人在仿真和现实中的装配表现。


<details>
  <summary>Details</summary>
Motivation: 机器人在模仿人类进行高精度、需要大量触觉反馈的双手组装任务时，通常由于演示样本有限且不完美，其表现远不如人类。单靠行为克隆方法难以获得泛化性与鲁棒性。解决如何利用有限数据提升机器人装配能力，是本研究的核心动机。

Method: 作者提出VT-Refine框架：1）使用少量带有同步视觉和触觉输入的人类示范，训练扩散策略模型；2）将策略迁移到带有高保真触觉仿真器的数字孪生仿真环境；3）结合大规模强化学习，在仿真中精细微调策略提升其泛化与鲁棒性；4）采用高分辨率压阻触觉传感器，并通过GPU加速进行并行仿真，提高模拟与现实的转移精度。

Result: 实验结果表明，VT-Refine在仿真和现实的精准组装任务中均超越仅依赖行为克隆的方法。该方法通过增加数据多样性及高效微调，显著提升了策略泛化性和装配表现。

Conclusion: VT-Refine证明了融合仿真、现实数据及强化学习的策略学习框架，能够有效提升机器人在复杂双手组装中的性能。高保真触觉建模与高效微调机制，是实现精确sim-to-real转移和鲁棒装配的关键。

Abstract: Humans excel at bimanual assembly tasks by adapting to rich tactile feedback
-- a capability that remains difficult to replicate in robots through
behavioral cloning alone, due to the suboptimality and limited diversity of
human demonstrations. In this work, we present VT-Refine, a visuo-tactile
policy learning framework that combines real-world demonstrations,
high-fidelity tactile simulation, and reinforcement learning to tackle precise,
contact-rich bimanual assembly. We begin by training a diffusion policy on a
small set of demonstrations using synchronized visual and tactile inputs. This
policy is then transferred to a simulated digital twin equipped with simulated
tactile sensors and further refined via large-scale reinforcement learning to
enhance robustness and generalization. To enable accurate sim-to-real transfer,
we leverage high-resolution piezoresistive tactile sensors that provide normal
force signals and can be realistically modeled in parallel using
GPU-accelerated simulation. Experimental results show that VT-Refine improves
assembly performance in both simulation and the real world by increasing data
diversity and enabling more effective policy fine-tuning. Our project page is
available at https://binghao-huang.github.io/vt_refine/.

</details>


### [258] [Architecture Is All You Need: Diversity-Enabled Sweet Spots for Robust Humanoid Locomotion](https://arxiv.org/abs/2510.14947)
*Blake Werner,Lizhi Yang,Aaron D. Ames*

Main category: cs.RO

TL;DR: 提出了一种结合高频本体感知稳定器和低频感知策略的分层控制架构，使仿人机器人在复杂环境下表现更加稳健，优于端到端方法。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中实现仿人机器人的稳健行走，需要解决快速实时稳定与较慢感知决策之间的平衡，现有单一端到端方法常常效果不理想。

Method: 设计了一种分层控制架构：高频运行的本体感知稳定器负责运动稳定，低频的精简感知策略负责环境感知和决策。训练采用两阶段流程，先进行无感知稳定器预训练，再用感知数据对整个系统微调。

Result: 在仿真和实际硬件（Unitree G1 仿人机器人）测试中，新方法在台阶和边缘等复杂地形任务中表现稳定，显著优于传统一阶段感知策略。

Conclusion: 感知决策与运动稳定的分时分层架构（而非网络复杂度）是提升仿人机器人感知驱动行走鲁棒性的关键。

Abstract: Robust humanoid locomotion in unstructured environments requires
architectures that balance fast low-level stabilization with slower perceptual
decision-making. We show that a simple layered control architecture (LCA), a
proprioceptive stabilizer running at high rate, coupled with a compact low-rate
perceptual policy, enables substantially more robust performance than
monolithic end-to-end designs, even when using minimal perception encoders.
Through a two-stage training curriculum (blind stabilizer pretraining followed
by perceptual fine-tuning), we demonstrate that layered policies consistently
outperform one-stage alternatives in both simulation and hardware. On a Unitree
G1 humanoid, our approach succeeds across stair and ledge tasks where one-stage
perceptual policies fail. These results highlight that architectural separation
of timescales, rather than network scale or complexity, is the key enabler for
robust perception-conditioned locomotion.

</details>


### [259] [From Language to Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance](https://arxiv.org/abs/2510.14952)
*Zhe Li,Cheng Chi,Yangyang Wei,Boan Zhu,Yibo Peng,Tao Huang,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang,Chang Xu*

Main category: cs.RO

TL;DR: 提出了RoboGhost，一个无需动作重定向，直接接受自然语言指导的人形机器人运动控制框架，大大提升了速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人通过自然语言指导运动的方法通常需要多阶段流程，包括解码人类动作、动作重定向和物理控制器跟踪，这导致误差累积、响应延迟高和语义与控制耦合弱。需要找到一种更直接、可靠的方案简化流程。

Method: RoboGhost跳过动作解码与重定向环节，使用基于扩散模型的策略，直接从噪声生成可执行动作。采用因果Transformer与扩散模型的混合运动生成器，确保动作的连贯性、稳定性和多样性，同时提升语义表达能力。

Result: RoboGhost在实物人形机器人上的实验表明，能够大幅降低部署延迟、提高任务成功率和跟踪精度，并能产生平滑且语义匹配的动作。

Conclusion: RoboGhost为自然语言引导的机器人控制提供了一条通用、高效的新路径，不仅支持文字输入，还可扩展到图像、音频等多模态输入，为多模态机器人智能系统奠定基础。

Abstract: Natural language offers a natural interface for humanoid robots, but existing
language-guided humanoid locomotion pipelines remain cumbersome and unreliable.
They typically decode human motion, retarget it to robot morphology, and then
track it with a physics-based controller. However, this multi-stage process is
prone to cumulative errors, introduces high latency, and yields weak coupling
between semantics and control. These limitations call for a more direct pathway
from language to action, one that eliminates fragile intermediate stages.
Therefore, we present RoboGhost, a retargeting-free framework that directly
conditions humanoid policies on language-grounded motion latents. By bypassing
explicit motion decoding and retargeting, RoboGhost enables a diffusion-based
policy to denoise executable actions directly from noise, preserving semantic
intent and supporting fast, reactive control. A hybrid causal
transformer-diffusion motion generator further ensures long-horizon consistency
while maintaining stability and diversity, yielding rich latent representations
for precise humanoid behavior. Extensive experiments demonstrate that RoboGhost
substantially reduces deployment latency, improves success rates and tracking
accuracy, and produces smooth, semantically aligned locomotion on real
humanoids. Beyond text, the framework naturally extends to other modalities
such as images, audio, and music, providing a general foundation for
vision-language-action humanoid systems.

</details>


### [260] [CBF-RL: Safety Filtering Reinforcement Learning in Training with Control Barrier Functions](https://arxiv.org/abs/2510.14959)
*Lizhi Yang,Blake Werner,Massimiliano de Sa Aaron D. Ames*

Main category: cs.RO

TL;DR: 本文提出了一种在训练过程中整合控制屏障函数（CBF）的方法（CBF-RL），在实现强化学习时兼顾性能与安全。该方法在不需在线安全过滤的情况下，可有效提升部署时的安全性。


<details>
  <summary>Details</summary>
Motivation: 强化学习虽在复杂任务表现优异，但通常牺牲安全性，实际部署时容易导致严重后果。现有的CBF安全机制多在推理阶段实施，导致RL策略本身不会主动趋于安全。作者希望开发一种能在训练期就让策略吸收安全约束的强化学习新范式。

Method: 提出CBF-RL框架：（1）通过CBF项对RL策略进行最小化修改以纳入安全约束；（2）在训练过程中对策略采样实施安全过滤。理论上证明连续时间的CBF安全过滤可通过对离散时间采样的封闭式表达来实现。

Result: CBF-RL能让学习到的策略直接内化安全约束，实现更安全的动作选择和奖励偏向。实验包括消融分析、导航任务以及实际的Unitree G1人形机器人测试，表明CBF-RL能在无需在线安全过滤情况下实现安全探索、收敛更快和表现更稳健，能避障并安全上下楼梯。

Conclusion: CBF-RL能在训练阶段有效嵌入安全约束，使最终部署时无须额外安全过滤器即可安全运行，提升了RL在现实世界应用中的安全性和效率。

Abstract: Reinforcement learning (RL), while powerful and expressive, can often
prioritize performance at the expense of safety. Yet safety violations can lead
to catastrophic outcomes in real-world deployments. Control Barrier Functions
(CBFs) offer a principled method to enforce dynamic safety -- traditionally
deployed \emph{online} via safety filters. While the result is safe behavior,
the fact that the RL policy does not have knowledge of the CBF can lead to
conservative behaviors. This paper proposes CBF-RL, a framework for generating
safe behaviors with RL by enforcing CBFs \emph{in training}. CBF-RL has two key
attributes: (1) minimally modifying a nominal RL policy to encode safety
constraints via a CBF term, (2) and safety filtering of the policy rollouts in
training. Theoretically, we prove that continuous-time safety filters can be
deployed via closed-form expressions on discrete-time roll-outs. Practically,
we demonstrate that CBF-RL internalizes the safety constraints in the learned
policy -- both enforcing safer actions and biasing towards safer rewards --
enabling safe deployment without the need for an online safety filter. We
validate our framework through ablation studies on navigation tasks and on the
Unitree G1 humanoid robot, where CBF-RL enables safer exploration, faster
convergence, and robust performance under uncertainty, enabling the humanoid
robot to avoid obstacles and climb stairs safely in real-world settings without
a runtime safety filter.

</details>


### [261] [RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks](https://arxiv.org/abs/2510.14968)
*Mingxuan Yan,Yuping Wang,Zechun Liu,Jiachen Li*

Main category: cs.RO

TL;DR: 本论文提出了一种新的基于检索的演示分解方法（RDD），能够更好地将复杂任务分解为低层次子任务，从而提升多步操作任务的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的分层视觉-语言-动作（VLA）框架需要将复杂操作任务分解为简单的子任务，但常用的人为标注或启发式规则分解方式容易与底层训练策略的数据分布不一致，导致性能下降。

Method: 作者提出了基于检索的演示分解器（RDD），通过比对分解后子任务区间的视觉特征与低层视觉运动策略训练数据中的特征，实现任务演示的自动分解，无需人为标注或启发式规则。

Result: RDD方法在模拟和真实环境下均超过了当前最优的子任务分解方法，表现出更强的鲁棒性和通用性。

Conclusion: RDD为长时序视觉-语言-动作任务的分层解决提供了新的思路，自动化且更高效地实现了任务分解，有望推广到更广泛的复杂多步任务。

Abstract: To tackle long-horizon tasks, recent hierarchical vision-language-action
(VLAs) frameworks employ vision-language model (VLM)-based planners to
decompose complex manipulation tasks into simpler sub-tasks that low-level
visuomotor policies can easily handle. Typically, the VLM planner is finetuned
to learn to decompose a target task. This finetuning requires target task
demonstrations segmented into sub-tasks by either human annotation or heuristic
rules. However, the heuristic subtasks can deviate significantly from the
training data of the visuomotor policy, which degrades task performance. To
address these issues, we propose a Retrieval-based Demonstration Decomposer
(RDD) that automatically decomposes demonstrations into sub-tasks by aligning
the visual features of the decomposed sub-task intervals with those from the
training data of the low-level visuomotor policies. Our method outperforms the
state-of-the-art sub-task decomposer on both simulation and real-world tasks,
demonstrating robustness across diverse settings. Code and more results are
available at rdd-neurips.github.io.

</details>
