<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 162]
- [cs.CL](#cs.CL) [Total: 68]
- [cs.RO](#cs.RO) [Total: 49]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Label Smoothing++: Enhanced Label Regularization for Training Neural Networks](https://arxiv.org/abs/2509.05307)
*Sachin Chhabra,Hemanth Venkateswara,Baoxin Li*

Main category: cs.CV

TL;DR: 本文提出Label Smoothing++，通过对非目标类别分配非零概率并学习其关系，提升神经网络泛化能力，缓解过拟合和过度自信问题。


<details>
  <summary>Details</summary>
Motivation: 传统的one-hot标签训练会导致模型过度自信和过拟合，虽然标签平滑技术能部分改善，但其对所有非目标类别一视同仁，无视类别间关系。本工作旨在弥补这一不足。

Method: 提出Label Smoothing++标签正则化策略，对目标类采用固定标签，对非目标类分配非零概率，并使网络能学习非目标类之间的标签关系。

Result: 在多个数据集上的实验表明，Label Smoothing++能有效减弱预测过度自信，同时增强模型对类别间关系的理解和泛化能力。

Conclusion: Label Smoothing++是比传统标签平滑更优的正则化手段，能更好促进神经网络的泛化和合理利用类别间信息。

Abstract: Training neural networks with one-hot target labels often results in
overconfidence and overfitting. Label smoothing addresses this issue by
perturbing the one-hot target labels by adding a uniform probability vector to
create a regularized label. Although label smoothing improves the network's
generalization ability, it assigns equal importance to all the non-target
classes, which destroys the inter-class relationships. In this paper, we
propose a novel label regularization training strategy called Label
Smoothing++, which assigns non-zero probabilities to non-target classes and
accounts for their inter-class relationships. Our approach uses a fixed label
for the target class while enabling the network to learn the labels associated
with non-target classes. Through extensive experiments on multiple datasets, we
demonstrate how Label Smoothing++ mitigates overconfident predictions while
promoting inter-class relationships and generalization capabilities.

</details>


### [2] [VILOD: A Visual Interactive Labeling Tool for Object Detection](https://arxiv.org/abs/2509.05317)
*Isac Holm*

Main category: cs.CV

TL;DR: 本文提出了一款视觉交互标注工具VILOD，通过人机协作与可视化分析优化目标检测数据集标注流程，提高模型透明度与标注效率，并展示了其效果。


<details>
  <summary>Details</summary>
Motivation: 深度学习目标检测依赖于大量高质量标签数据，但人工标注成本高昂且耗时。传统主动学习(Active Learning, AL)虽可部分缓解，但存在缺乏透明度和不能充分发挥人工智慧的问题。为解决这些痛点，引入人机协作（Human-in-the-Loop, HITL）和视觉分析（Visual Analytics, VA）方法。

Method: 开发VILOD可视化交互标注工具，结合t-SNE特征投影、不确定性热力图和模型状态视图，让用户探索数据、理解模型状态及主动学习建议，并实现多样化的样本选择策略，在人机迭代流程中提升目标检测标注。

Result: 通过案例比较实验，VILOD的可视化交互显著提升了模型状态和数据集特征可解释性，用户可实现多种标注策略，不同策略下的性能与自动主动学习（不确定性采样）基线相当。

Conclusion: VILOD作为一种新型可交互HITL-AL标注工具，增强了目标检测任务中模型的透明度、任务的可管理性和潜在效率，为相关标注流程和工具设计提供了实证参考。

Abstract: The advancement of Object Detection (OD) using Deep Learning (DL) is often
hindered by the significant challenge of acquiring large, accurately labeled
datasets, a process that is time-consuming and expensive. While techniques like
Active Learning (AL) can reduce annotation effort by intelligently querying
informative samples, they often lack transparency, limit the strategic insight
of human experts, and may overlook informative samples not aligned with an
employed query strategy. To mitigate these issues, Human-in-the-Loop (HITL)
approaches integrating human intelligence and intuition throughout the machine
learning life-cycle have gained traction. Leveraging Visual Analytics (VA),
effective interfaces can be created to facilitate this human-AI collaboration.
This thesis explores the intersection of these fields by developing and
investigating "VILOD: A Visual Interactive Labeling tool for Object Detection".
VILOD utilizes components such as a t-SNE projection of image features,
together with uncertainty heatmaps and model state views. Enabling users to
explore data, interpret model states, AL suggestions, and implement diverse
sample selection strategies within an iterative HITL workflow for OD. An
empirical investigation using comparative use cases demonstrated how VILOD,
through its interactive visualizations, facilitates the implementation of
distinct labeling strategies by making the model's state and dataset
characteristics more interpretable (RQ1). The study showed that different
visually-guided labeling strategies employed within VILOD result in competitive
OD performance trajectories compared to an automated uncertainty sampling AL
baseline (RQ2). This work contributes a novel tool and empirical insight into
making the HITL-AL workflow for OD annotation more transparent, manageable, and
potentially more effective.

</details>


### [3] [Context-Aware Knowledge Distillation with Adaptive Weighting for Image Classification](https://arxiv.org/abs/2509.05319)
*Zhengda Li*

Main category: cs.CV

TL;DR: 本文提出了一种自适应知识蒸馏（AKD）方法，实现了更优的师生网络知识迁移。其核心是让损失函数中的权重参数α可训练，并结合师生预测差异以及上下文信息动态调整权重，提高了学生模型的精度和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统的知识蒸馏方法采用固定的权衡参数α来在硬标签和软标签损失之间平衡，但最佳的权衡比例在训练过程中可能会发生变化，固定α难以适应这种动态需求。为了解决这一不足，作者提出需要让α动态调整以提升知识迁移效率。

Method: 1. 将用于平衡硬标签损失与软标签损失的α设为可训练参数；2. 设计了一种根据师生网络间预测差距动态计算α的公式；3. 引入基于MLP和注意力机制的上下文感知模块（CAM），对教师模型输出的不同类别分配自适应权重。

Result: 在CIFAR-10数据集上，以ResNet-50为教师、ResNet-18为学生模型，实验表明AKD方法准确率优于固定α值的知识蒸馏方法，并且收敛过程更为稳定。

Conclusion: 自适应调整损失权重与教师输出权重，可以显著提升知识蒸馏的效果，该方法具有更好的鲁棒性和泛化能力。

Abstract: Knowledge distillation (KD) is a widely used technique to transfer knowledge
from a large teacher network to a smaller student model. Traditional KD uses a
fixed balancing factor alpha as a hyperparameter to combine the hard-label
cross-entropy loss with the soft-label distillation loss. However, a static
alpha is suboptimal because the optimal trade-off between hard and soft
supervision can vary during training.
  In this work, we propose an Adaptive Knowledge Distillation (AKD) framework.
First we try to make alpha as learnable parameter that can be automatically
learned and optimized during training. Then we introduce a formula to reflect
the gap between the student and the teacher to compute alpha dynamically,
guided by student-teacher discrepancies, and further introduce a Context-Aware
Module (CAM) using MLP + Attention to adaptively reweight class-wise teacher
outputs. Experiments on CIFAR-10 with ResNet-50 as teacher and ResNet-18 as
student demonstrate that our approach achieves superior accuracy compared to
fixed-weight KD baselines, and yields more stable convergence.

</details>


### [4] [A Dataset Generation Scheme Based on Video2EEG-SPGN-Diffusion for SEED-VD](https://arxiv.org/abs/2509.05321)
*Yunfei Guo,Tao Zhang,Wu Huang,Yao Song*

Main category: cs.CV

TL;DR: 提出了一个开源框架Video2EEG-SPGN-Diffusion，能够基于视频内容生成与之对应的脑电(EEG)信号，并公开了新的视频-EEG多模态数据集。


<details>
  <summary>Details</summary>
Motivation: 现有多模态情感分析和脑机接口研究受制于大规模视频-EEG配对数据稀缺，几乎没有能够由视频生成EEG信号的开放工具和数据集，限制了相关领域的发展。

Method: 构建了一个工程化流水线，对SEED-VD数据集的视频与EEG数据进行配对校准，并融合自对弈图神经网络(SPGN)与扩散模型，实现受视频内容调控（条件生成）的个性化脑电信号生成。

Result: 开放了含1000多组视频与生成的62通道、200Hz脑电信号及情感标签的配对数据集，并给出了数据构建和对齐的全过程。

Conclusion: 该开源框架及数据集为多模态情感分析、数据增强和脑机接口等研究提供了新的方法和工具，具有重要的研究和工程意义。

Abstract: This paper introduces an open-source framework, Video2EEG-SPGN-Diffusion,
that leverages the SEED-VD dataset to generate a multimodal dataset of EEG
signals conditioned on video stimuli. Additionally, we disclose an engineering
pipeline for aligning video and EEG data pairs, facilitating the training of
multimodal large models with EEG alignment capabilities. Personalized EEG
signals are generated using a self-play graph network (SPGN) integrated with a
diffusion model. As a major contribution, we release a new dataset comprising
over 1000 samples of SEED-VD video stimuli paired with generated 62-channel EEG
signals at 200 Hz and emotion labels, enabling video-EEG alignment and
advancing multimodal research. This framework offers novel tools for emotion
analysis, data augmentation, and brain-computer interface applications, with
substantial research and engineering significance.

</details>


### [5] [Application of discrete Ricci curvature in pruning randomly wired neural networks: A case study with chest x-ray classification of COVID-19](https://arxiv.org/abs/2509.05322)
*Pavithra Elumalai,Sudharsan Vijayaraghavan,Madhumita Mondal,Areejit Samal*

Main category: cs.CV

TL;DR: 本文探索了随机连接神经网络（RWNN）中利用三种以边为中心的网络测度（Forman-Ricci曲率、Ollivier-Ricci曲率和边介数中心性）进行剪枝的方法，并比较了其在COVID-19胸部X光图像分类任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 网络拓扑结构对深度学习性能有重要影响，RWNN为研究不同连接模式的影响提供了实验平台。同时，如何利用网络中边的特征来进行高效的模型压缩和剪枝，提升计算效率且保持性能，是当前的重要议题。

Method: 作者以ER、WS和BA三种网络生成器构建RWNN，并引入三种边测度（FRC、ORC、EBC）进行剪枝，保留重要边，去除冗余连接。在COVID-19胸部X光分类任务上训练RWNN，并对比不同剪枝方法的压缩比、理论加速效果、准确率、特异性和敏感性。同时，通过模块度和全局效率分析剪枝后网络的结构特性。

Result: 实验显示，FRC作为一种计算高效的曲率测度，其剪枝效果与ORC相当，能显著简化网络结构，同时保持分类性能；三种边测度在不同网络生成模式下剪枝效果有所差异。

Conclusion: FRC剪枝为RWNN压缩提供了一种高效且有效的方法，不仅带来运算优势，还可在保持模型性能的同时，对网络结构进行有益的简化。

Abstract: Randomly Wired Neural Networks (RWNNs) serve as a valuable testbed for
investigating the impact of network topology in deep learning by capturing how
different connectivity patterns impact both learning efficiency and model
performance. At the same time, they provide a natural framework for exploring
edge-centric network measures as tools for pruning and optimization. In this
study, we investigate three edge-centric network measures: Forman-Ricci
curvature (FRC), Ollivier-Ricci curvature (ORC), and edge betweenness
centrality (EBC), to compress RWNNs by selectively retaining important synapses
(or edges) while pruning the rest. As a baseline, RWNNs are trained for
COVID-19 chest x-ray image classification, aiming to reduce network complexity
while preserving performance in terms of accuracy, specificity, and
sensitivity. We extend prior work on pruning RWNN using ORC by incorporating
two additional edge-centric measures, FRC and EBC, across three network
generators: Erd\"{o}s-R\'{e}nyi (ER) model, Watts-Strogatz (WS) model, and
Barab\'{a}si-Albert (BA) model. We provide a comparative analysis of the
pruning performance of the three measures in terms of compression ratio and
theoretical speedup. A central focus of our study is to evaluate whether FRC,
which is computationally more efficient than ORC, can achieve comparable
pruning effectiveness. Along with performance evaluation, we further
investigate the structural properties of the pruned networks through modularity
and global efficiency, offering insights into the trade-off between modular
segregation and network efficiency in compressed RWNNs. Our results provide
initial evidence that FRC-based pruning can effectively simplify RWNNs,
offering significant computational advantages while maintaining performance
comparable to ORC.

</details>


### [6] [Optical Music Recognition of Jazz Lead Sheets](https://arxiv.org/abs/2509.05329)
*Juan Carlos Martinez-Sevilla,Francesco Foscarin,Patricia Garcia-Iasci,David Rizo,Jorge Calvo-Zaragoza,Gerhard Widmer*

Main category: cs.CV

TL;DR: 本文提出了一种针对手写爵士乐主旋律谱表（lead sheets）的光学乐谱识别（OMR）新方法，并发布了相应的数据集与代码。


<details>
  <summary>Details</summary>
Motivation: 现有OMR系统无法有效识别包含和弦的手写乐谱，且手写图像本身具有高度变异和质量问题。爵士乐主旋律谱对于研究和应用均非常重要，但缺乏专门的识别方法和数据集。作者希望解决这些难题。

Method: 1）构建了包含293张爵士乐手写主旋律谱表的数据集，共163首独特乐曲、2021行谱，配有Humdrum **kern和MusicXML标准标注，并提供基于标注生成的合成乐谱图像。2）提出针对该类谱表的OMR模型，重点讨论了针对和弦的特殊分词方法，以及合成谱图和预训练模型的使用优势。

Result: 作者发布了该数据集（真实手写+合成乐谱）和OMR模型（包括全部代码、数据与模型）。并通过相关实验，验证了方法和构建的数据集对提升手写爵士乐谱识别的有效性。

Conclusion: 该工作填补了手写爵士乐主旋律谱表OMR的研究空白，为领域发展提供了珍贵的数据与工具资源，并推动了后续相关研究。

Abstract: In this paper, we address the challenge of Optical Music Recognition (OMR)
for handwritten jazz lead sheets, a widely used musical score type that encodes
melody and chords. The task is challenging due to the presence of chords, a
score component not handled by existing OMR systems, and the high variability
and quality issues associated with handwritten images. Our contribution is
two-fold. We present a novel dataset consisting of 293 handwritten jazz lead
sheets of 163 unique pieces, amounting to 2021 total staves aligned with
Humdrum **kern and MusicXML ground truth scores. We also supply synthetic score
images generated from the ground truth. The second contribution is the
development of an OMR model for jazz lead sheets. We discuss specific
tokenisation choices related to our kind of data, and the advantages of using
synthetic scores and pretrained models. We publicly release all code, data, and
models.

</details>


### [7] [RT-VLM: Re-Thinking Vision Language Model with 4-Clues for Real-World Object Recognition Robustness](https://arxiv.org/abs/2509.05333)
*Junghyun Park,Tuan Anh Nguyen,Dugki Min*

Main category: cs.CV

TL;DR: 该论文提出了RT-VLM框架，通过综合多模态“线索”与自我纠正机制，显著提升模型在领域迁移时的鲁棒性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实部署中，目标识别模型面临领域偏移，导致识别准确率大幅下降。现有方法难以有效应对低层图像变化、姿态变化、遮挡等复杂问题。

Method: 核心方法为提出独特的合成数据生成管线，制作带有‘4-Clues’注释（精确框、类别名、目标级描述、全局场景描述）的图像，并对Llama 3.2 11B Vision Instruct进行高效有监督微调。推理时，模型先生成自己的四个线索，再自我批判性地复查并迭代修正输出。

Result: RT-VLM在针对领域偏移的各类鲁棒性基准测试中，表现均超过现有强基线方法。

Conclusion: 融合结构化多模态证据和显式自我纠错流程，是提升视觉理解可靠性和迁移能力的有效思路。

Abstract: Real world deployments often expose modern object recognition models to
domain shifts that precipitate a severe drop in accuracy. Such shifts encompass
(i) variations in low level image statistics, (ii) changes in object pose and
viewpoint, (iii) partial occlusion, and (iv) visual confusion across adjacent
classes. To mitigate this degradation, we introduce the Re-Thinking Vision
Language Model (RT-VLM) framework. The foundation of this framework is a unique
synthetic dataset generation pipeline that produces images annotated with
"4-Clues": precise bounding boxes, class names, detailed object-level captions,
and a comprehensive context-level caption for the entire scene. We then perform
parameter efficient supervised tuning of Llama 3.2 11B Vision Instruct on this
resource. At inference time, a two stage Re-Thinking scheme is executed: the
model first emits its own four clues, then re examines these responses as
evidence and iteratively corrects them. Across robustness benchmarks that
isolate individual domain shifts, RT-VLM consistently surpasses strong
baselines. These findings indicate that the integration of structured
multimodal evidence with an explicit self critique loop constitutes a promising
route toward reliable and transferable visual understanding.

</details>


### [8] [A Real-Time, Vision-Based System for Badminton Smash Speed Estimation on Mobile Devices](https://arxiv.org/abs/2509.05334)
*Diwen Huang*

Main category: cs.CV

TL;DR: 本文提出了一套利用智能手机，结合YOLOv5与卡尔曼滤波算法，实现羽毛球杀球速度自动测量的便捷低成本系统。系统集成于APP，普通用户也可轻松使用。


<details>
  <summary>Details</summary>
Motivation: 传统运动性能测量技术昂贵、复杂，业余和大众运动者难以获取数据反馈。羽毛球作为热门运动，缺乏简单可及的性能分析工具。论文旨在弥补此空白。

Method: 基于手机视频，首先用定制YOLOv5模型检测羽毛球，然后利用卡尔曼滤波跟踪轨迹，通过时空尺度校准，自动估算杀球速度，并将全部流程集成到移动应用上。

Result: 实现了在普通智能手机上，准确自动地测量羽毛球杀球速度，无需昂贵设备，用户体验良好。

Conclusion: 该系统极大降低了运动数据获取门槛，为广大羽毛球爱好者及非专业运动员提供了实用的性能分析工具，有助于推动运动科学的普及。

Abstract: Performance metrics in sports, such as shot speed and angle, provide crucial
feedback for athlete development. However, the technology to capture these
metrics has historically been expensive, complex, and largely inaccessible to
amateur and recreational players. This paper addresses this gap in the context
of badminton, one of the world's most popular sports, by introducing a novel,
cost-effective, and user-friendly system for measuring smash speed using
ubiquitous smartphone technology. Our approach leverages a custom-trained
YOLOv5 model for shuttlecock detection, combined with a Kalman filter for
robust trajectory tracking. By implementing a video-based kinematic speed
estimation method with spatiotemporal scaling, the system automatically
calculates the shuttlecock's velocity from a standard video recording. The
entire process is packaged into an intuitive mobile application, democratizing
access to high-level performance analytics and empowering players at all levels
to analyze and improve their game.

</details>


### [9] [A Stroke-Level Large-Scale Database of Chinese Character Handwriting and the OpenHandWrite_Toolbox for Handwriting Research](https://arxiv.org/abs/2509.05335)
*Zebo Xu,Shaoyun Yu,Mark Torrance,Guido Nottbusch,Nan Zhao,Zhenguang Cai*

Main category: cs.CV

TL;DR: 该论文构建了大规模中文手写数据库，并开发了便于批量处理和捕捉细粒度笔迹数据的工具箱，用以研究语言组件对汉字、部件和笔画各层级手写过程的影响。


<details>
  <summary>Details</summary>
Motivation: 当前关于语言系统各要素（如语音、语义、正字法）如何影响多层级（字、部件、笔画）中文手写过程的研究不足，且缺乏高效捕捉、批处理精细书写数据的工具。

Method: 招募42名中文母语者，每人手写1200个汉字；对手写数据进行收集；扩展并完善现有OpenHandWrite_Toolbox包，实现可修改实验设计、捕捉笔画级书写轨迹、批量处理各项书写指标。采用多元回归分析不同语言预测变量对手写准备和执行过程的影响。

Result: 正字法特征影响手写准备及执行，作用存在于字、部件和笔画各层级；语音成分也影响所有层级的书写执行。各语言成分的影响随层级呈递减趋势：字>部件>笔画。

Conclusion: 汉字书写的准备与执行过程深受语言系统多层级信息调控。本文构建的数据库和工具箱为后续心理语言学和神经语言学研究提供了宝贵资源，适用于不同语言环境下关于字符及其子结构书写的研究。

Abstract: Understanding what linguistic components (e.g., phonological, semantic, and
orthographic systems) modulate Chinese handwriting at the character, radical,
and stroke levels remains an important yet understudied topic. Additionally,
there is a lack of comprehensive tools for capturing and batch-processing
fine-grained handwriting data. To address these issues, we constructed a
large-scale handwriting database in which 42 Chinese speakers for each
handwriting 1200 characters in a handwriting-to-dictation task. Additionally,
we enhanced the existing handwriting package and provided comprehensive
documentation for the upgraded OpenHandWrite_Toolbox, which can easily modify
the experimental design, capture the stroke-level handwriting trajectory, and
batch-process handwriting measurements (e.g., latency, duration, and
pen-pressure). In analysing our large-scale database, multiple regression
results show that orthographic predictors impact handwriting preparation and
execution across character, radical, and stroke levels. Phonological factors
also influence execution at all three levels. Importantly, these lexical
effects demonstrate hierarchical attenuation - they were most pronounced at the
character level, followed by the radical, and were weakest at the stroke
levels. These findings demonstrate that handwriting preparation and execution
at the radical and stroke levels are closely intertwined with linguistic
components. This database and toolbox offer valuable resources for future
psycholinguistic and neurolinguistic research on the handwriting of characters
and sub-characters across different languages.

</details>


### [10] [Anticipatory Fall Detection in Humans with Hybrid Directed Graph Neural Networks and Long Short-Term Memory](https://arxiv.org/abs/2509.05337)
*Younggeol Cho,Gokhan Solak,Olivia Nocentini,Marta Lorenzini,Andrea Fortuna,Arash Ajoudani*

Main category: cs.CV

TL;DR: 本文提出了一种结合动态图神经网络（DGNN）与长短时记忆网络（LSTM）的预测性跌倒检测方法，通过对动作预测和步态分类任务解耦，实现了对跌倒的早期高准确率预测。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在跌倒发生后的检测，鲜有关注预测跌倒及稳定态与即将跌倒之间的过渡过程。提前预警跌倒对提升辅助机器人系统的实用性和有效性至关重要。

Method: 方法上，模型首先提取视频序列中的实时骨架特征，DGNN负责将步态划分为稳定、过渡和跌倒三类，LSTM再进行后续时间步的人体动作预测。通过将动作预测与步态分类任务分开处理，实现了预测与检测的协同优化。模型在OUMVLP-Pose和URFD数据集上进行了训练与验证。

Result: 实验结果显示，所提模型在跌倒预测误差和识别准确率上均优于单一DGNN模型及其他已有文献方法，特别是在对跌倒过渡阶段的检测方面表现突出。

Conclusion: 该研究表明，预测与分类任务的解耦能有效提升跌倒预测系统的性能，并可监控人类由稳定向跌倒过渡的中间状态，对未来智能辅助系统的完善具有借鉴意义。

Abstract: Detecting and preventing falls in humans is a critical component of assistive
robotic systems. While significant progress has been made in detecting falls,
the prediction of falls before they happen, and analysis of the transient state
between stability and an impending fall remain unexplored. In this paper, we
propose a anticipatory fall detection method that utilizes a hybrid model
combining Dynamic Graph Neural Networks (DGNN) with Long Short-Term Memory
(LSTM) networks that decoupled the motion prediction and gait classification
tasks to anticipate falls with high accuracy. Our approach employs real-time
skeletal features extracted from video sequences as input for the proposed
model. The DGNN acts as a classifier, distinguishing between three gait states:
stable, transient, and fall. The LSTM-based network then predicts human
movement in subsequent time steps, enabling early detection of falls. The
proposed model was trained and validated using the OUMVLP-Pose and URFD
datasets, demonstrating superior performance in terms of prediction error and
recognition accuracy compared to models relying solely on DGNN and models from
literature. The results indicate that decoupling prediction and classification
improves performance compared to addressing the unified problem using only the
DGNN. Furthermore, our method allows for the monitoring of the transient state,
offering valuable insights that could enhance the functionality of advanced
assistance systems.

</details>


### [11] [Comparative Evaluation of Hard and Soft Clustering for Precise Brain Tumor Segmentation in MR Imaging](https://arxiv.org/abs/2509.05340)
*Dibya Jyoti Bora,Mrinal Kanti Mishra*

Main category: cs.CV

TL;DR: 本文比较了磁共振成像（MRI）脑肿瘤分割中，硬聚类（K-Means）和软聚类（Fuzzy C-Means, FCM）两种主流聚类算法的性能，揭示了准确性与计算速度间的权衡。


<details>
  <summary>Details</summary>
Motivation: 由于脑肿瘤形态和信号分布高度异质，传统分割方法面临较大挑战。精确勾画肿瘤边界对临床诊断和治疗至关重要，因此需要系统分析主流聚类方法在实际MRI肿瘤分割中的表现。

Method: 采用BraTS2020公开数据集，并预处理（高斯滤波和CLAHE）。将K-Means和FCM聚类算法分别用于肿瘤分割，对比两者的分割准确性（DSC指标）和处理速度。

Result: K-Means分割速度快（平均0.3秒/张），但分割准确性低（DSC=0.43）；FCM分割准确性高（DSC=0.67），但速度慢（1.3秒/张）。两者表现存在明显权衡。

Conclusion: 在MRI脑肿瘤分割任务中，K-Means适合对时间要求高的场景，FCM适合对边界精度要求高的场景。选用方法需要结合实际需求权衡精度和效率。

Abstract: Segmentation of brain tumors from Magnetic Resonance Imaging (MRI) remains a
pivotal challenge in medical image analysis due to the heterogeneous nature of
tumor morphology and intensity distributions. Accurate delineation of tumor
boundaries is critical for clinical decision-making, radiotherapy planning, and
longitudinal disease monitoring. In this study, we perform a comprehensive
comparative analysis of two major clustering paradigms applied in MRI tumor
segmentation: hard clustering, exemplified by the K-Means algorithm, and soft
clustering, represented by Fuzzy C-Means (FCM). While K-Means assigns each
pixel strictly to a single cluster, FCM introduces partial memberships, meaning
each pixel can belong to multiple clusters with varying degrees of association.
Experimental validation was performed using the BraTS2020 dataset,
incorporating pre-processing through Gaussian filtering and Contrast Limited
Adaptive Histogram Equalization (CLAHE). Evaluation metrics included the Dice
Similarity Coefficient (DSC) and processing time, which collectively
demonstrated that K-Means achieved superior speed with an average runtime of
0.3s per image, whereas FCM attained higher segmentation accuracy with an
average DSC of 0.67 compared to 0.43 for K-Means, albeit at a higher
computational cost (1.3s per image). These results highlight the inherent
trade-off between computational efficiency and boundary precision.

</details>


### [12] [Handling imbalance and few-sample size in ML based Onion disease classification](https://arxiv.org/abs/2509.05341)
*Abhijeet Manoj Pal,Rajbabu Velmurugan*

Main category: cs.CV

TL;DR: 该论文提出了一种基于深度学习的洋葱作物病虫害多类别分类模型，并在真实田间图像集上获得了96.9%的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有方法多为二分类，难以满足实际中对特定病虫害种类识别的需求，因此研究多类别分类模型以提升实际应用价值。

Method: 对预训练CNN模型进行了加强，结合了注意力机制模块，并通过全面的数据增强处理以缓解类别不平衡问题。

Result: 在真实田间图像数据集上，模型整体准确率达96.9%，F1分数为0.96，优于同类数据集上的其他方法。

Conclusion: 所提模型具有较强的多类别病虫害识别能力，能提升洋葱作物病虫害的检测效果，适用于精准农业场景。

Abstract: Accurate classification of pests and diseases plays a vital role in precision
agriculture, enabling efficient identification, targeted interventions, and
preventing their further spread. However, current methods primarily focus on
binary classification, which limits their practical applications, especially in
scenarios where accurately identifying the specific type of disease or pest is
essential. We propose a robust deep learning based model for multi-class
classification of onion crop diseases and pests. We enhance a pre-trained
Convolutional Neural Network (CNN) model by integrating attention based modules
and employing comprehensive data augmentation pipeline to mitigate class
imbalance. We propose a model which gives 96.90% overall accuracy and 0.96 F1
score on real-world field image dataset. This model gives better results than
other approaches using the same datasets.

</details>


### [13] [Delta Velocity Rectified Flow for Text-to-Image Editing](https://arxiv.org/abs/2509.05342)
*Gaspard Beaudouin,Minghan Li,Jaeyeon Kim,Sunghoon Yoon,Mengyu Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新的无需反演、路径感知的文本到图像编辑方法DVRF（Delta Velocity Rectified Flow），显著减少了现有方法中的过度平滑现象并提升编辑质量。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像的编辑方法常常存在过度平滑、编辑质量不高的问题，尤其是在基于蒸馏采样的方案中。需要找到新的算法来减轻这些问题，提高编辑的精确度和控制力。

Method: DVRF利用蒸馏思想，显式建模源目标速率场之间的差异，并引入时变偏移项帮助噪声潜变量更好靠近目标分布轨迹。理论上也证明该方法在某些条件下可还原为现有的优化算法（如Delta Denoising Score、FlowEdit等），对其原理做出统一解释。

Result: 实验显示，DVRF无需更改原有网络结构，就能明显提升文本到图像编辑的质量、保真度和可控性。

Conclusion: DVRF不仅在理论上连通和解释了现有方法，在实践中也实现了高效、通用且优质的文本图像编辑效果，是一项兼具创新性和实用性的工作。

Abstract: We propose Delta Velocity Rectified Flow (DVRF), a novel inversion-free,
path-aware editing framework within rectified flow models for text-to-image
editing. DVRF is a distillation-based method that explicitly models the
discrepancy between the source and target velocity fields in order to mitigate
over-smoothing artifacts rampant in prior distillation sampling approaches. We
further introduce a time-dependent shift term to push noisy latents closer to
the target trajectory, enhancing the alignment with the target distribution. We
theoretically demonstrate that when this shift is disabled, DVRF reduces to
Delta Denoising Score, thereby bridging score-based diffusion optimization and
velocity-based rectified-flow optimization. Moreover, when the shift term
follows a linear schedule under rectified-flow dynamics, DVRF generalizes the
Inversion-free method FlowEdit and provides a principled theoretical
interpretation for it. Experimental results indicate that DVRF achieves
superior editing quality, fidelity, and controllability while requiring no
architectural modifications, making it efficient and broadly applicable to
text-to-image editing tasks. Code is available at
https://github.com/gaspardbd/DeltaVelocityRectifiedFlow.

</details>


### [14] [Systematic Integration of Attention Modules into CNNs for Accurate and Generalizable Medical Image Diagnosis](https://arxiv.org/abs/2509.05343)
*Zahid Ullah,Minki Hong,Tahir Mahmood,Jihie Kim*

Main category: cs.CV

TL;DR: 本文系统性地将注意力机制集成到五种常用CNN架构中，显著提升了医学图像分析的分类性能和特征定位能力，尤其是在脑肿瘤MRI和组织切片两类数据集上均表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统卷积神经网络在医学图像分析中难以有效捕捉关键的细粒度和复杂特征，影响其诊断准确性。因此需要探索新方法，提升模型关注图像显著区域的能力。

Method: 将Squeeze and Excitation（SE）块或卷积块注意力模块（CBAM）分别嵌入VGG16、ResNet18、InceptionV3、DenseNet121、EfficientNetB5等五种CNN中。比较原始模型与集成注意力机制后模型在脑肿瘤MRI和病理组织两类数据集上的表现。

Result: 集成注意力模块后的CNN在所有评估指标上均优于原始CNN，尤其是EfficientNetB5结合混合注意力时表现最佳。注意力机制还提升了特征定位能力和跨模态泛化能力。

Conclusion: 注意力机制可系统性提升不同CNN架构在医学图像分析中的表现，增强模型可解释性和泛化能力，为构建临床可用、健壮的辅助决策系统提供了有价值的实践指导。

Abstract: Deep learning has become a powerful tool for medical image analysis; however,
conventional Convolutional Neural Networks (CNNs) often fail to capture the
fine-grained and complex features critical for accurate diagnosis. To address
this limitation, we systematically integrate attention mechanisms into five
widely adopted CNN architectures, namely, VGG16, ResNet18, InceptionV3,
DenseNet121, and EfficientNetB5, to enhance their ability to focus on salient
regions and improve discriminative performance. Specifically, each baseline
model is augmented with either a Squeeze and Excitation block or a hybrid
Convolutional Block Attention Module, allowing adaptive recalibration of
channel and spatial feature representations. The proposed models are evaluated
on two distinct medical imaging datasets, a brain tumor MRI dataset comprising
multiple tumor subtypes, and a Products of Conception histopathological dataset
containing four tissue categories. Experimental results demonstrate that
attention augmented CNNs consistently outperform baseline architectures across
all metrics. In particular, EfficientNetB5 with hybrid attention achieves the
highest overall performance, delivering substantial gains on both datasets.
Beyond improved classification accuracy, attention mechanisms enhance feature
localization, leading to better generalization across heterogeneous imaging
modalities. This work contributes a systematic comparative framework for
embedding attention modules in diverse CNN architectures and rigorously
assesses their impact across multiple medical imaging tasks. The findings
provide practical insights for the development of robust, interpretable, and
clinically applicable deep learning based decision support systems.

</details>


### [15] [Vision-Based Object Detection for UAV Solar Panel Inspection Using an Enhanced Defects Dataset](https://arxiv.org/abs/2509.05348)
*Ashen Rodrigo,Isuru Munasinghe,Asanka Perera*

Main category: cs.CV

TL;DR: 本研究对五种主流目标检测模型在太阳能电池板缺陷与污染检测中的效果进行了系统评估，揭示了不同模型在检测精度与计算效率上的权衡，为实际应用选择合适方案提供参考。


<details>
  <summary>Details</summary>
Motivation: 太阳能电池板的高效运行依赖于及时发现物理、电气缺陷及表面污染，因此需要精准、快速的检测方法。现有目标检测模型在实际场景下的表现尚不明朗，缺乏专门的数据集和系统性对比。

Method: 作者自建了一个针对太阳能板缺陷和污染检测的COCO格式数据集，开发了用于训练和测试的用户界面，并依次对YOLOv3、Faster R-CNN、RetinaNet、EfficientDet和Swin Transformer五种模型进行训练与评测，通过mAP、precision、recall和推理速度等指标进行综合比较。

Result: 各模型在检测准确率和推理速度等方面表现不同，展示了在检测性能与计算效率之间的典型权衡。不同模型各有优势和不足。

Conclusion: 研究结果为实际监控和维护中如何选择适合的检测模型提供了依据，公开数据集也有助于推动太阳能板检测领域的发展。

Abstract: Timely and accurate detection of defects and contaminants in solar panels is
critical for maintaining the efficiency and reliability of photovoltaic
systems. This study presents a comprehensive evaluation of five
state-of-the-art object detection models: YOLOv3, Faster R-CNN, RetinaNet,
EfficientDet, and Swin Transformer, for identifying physical and electrical
defects as well as surface contaminants such as dust, dirt, and bird droppings
on solar panels. A custom dataset, annotated in the COCO format and
specifically designed for solar panel defect and contamination detection, was
developed alongside a user interface to train and evaluate the models. The
performance of each model is assessed and compared based on mean Average
Precision (mAP), precision, recall, and inference speed. The results
demonstrate the trade-offs between detection accuracy and computational
efficiency, highlighting the relative strengths and limitations of each model.
These findings provide valuable guidance for selecting appropriate detection
approaches in practical solar panel monitoring and maintenance scenarios.
  The dataset will be publicly available at
https://github.com/IsuruMunasinghe98/solar-panel-inspection-dataset.

</details>


### [16] [Unsupervised Instance Segmentation with Superpixels](https://arxiv.org/abs/2509.05352)
*Cuong Manh Hoang*

Main category: cs.CV

TL;DR: 提出了一种无需人工标注即可进行实例分割的新框架，通过自监督特征、MultiCut算法和自适应损失提升分割效果，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前实例分割方法依赖大量昂贵的人为标注，难以大规模获得，亟需无需人工标注的实例分割方法。

Method: 1. 使用MultiCut算法和自监督特征进行粗分割；2. 通过掩码过滤器获得高质量掩码；3. 基于粗掩码和图像超像素设计新型掩码损失（包含hard loss和soft loss）；4. 引入自训练及自适应损失进一步提升分割质量。

Result: 在公共实例分割和目标检测数据集上实验，框架性能优于以往的同类方法。

Conclusion: 该新颖框架能有效提升无需标签的实例分割精度，有望推动该领域发展。

Abstract: Instance segmentation is essential for numerous computer vision applications,
including robotics, human-computer interaction, and autonomous driving.
Currently, popular models bring impressive performance in instance segmentation
by training with a large number of human annotations, which are costly to
collect. For this reason, we present a new framework that efficiently and
effectively segments objects without the need for human annotations. Firstly, a
MultiCut algorithm is applied to self-supervised features for coarse mask
segmentation. Then, a mask filter is employed to obtain high-quality coarse
masks. To train the segmentation network, we compute a novel superpixel-guided
mask loss, comprising hard loss and soft loss, with high-quality coarse masks
and superpixels segmented from low-level image features. Lastly, a
self-training process with a new adaptive loss is proposed to improve the
quality of predicted masks. We conduct experiments on public datasets in
instance segmentation and object detection to demonstrate the effectiveness of
the proposed framework. The results show that the proposed framework
outperforms previous state-of-the-art methods.

</details>


### [17] [Augmented Structure Preserving Neural Networks for cell biomechanics](https://arxiv.org/abs/2509.05388)
*Juan Olalla-Pombo,Alberto Badías,Miguel Ángel Sanz-Gómez,José María Benítez,Francisco Javier Montáns*

Main category: cs.CV

TL;DR: 本文提出了一种结合结构保持神经网络与其他机器学习工具的新方法，实现了对细胞运动与分裂事件的高精度预测。


<details>
  <summary>Details</summary>
Motivation: 细胞生物力学过程极其复杂，并涉及生命进化、胚胎发生、组织修复和肿瘤生长等多种生命现象，现有研究难以全面理解各过程间的相互作用及其对细胞集体决策的影响，因此需要新的方法提升预测与解释能力。

Method: 作者将结构保持神经网络用于建模细胞作为纯粹力学体系的运动行为，同时结合人工神经网络等机器学习工具，融合基于计算机视觉从实验中提取的环境因素，构成一个能够同时考虑力学特性与环境影响的混合模型。该模型被应用于模拟与真实细胞迁移案例，并引入神经网络架构对细胞有丝分裂事件进行预测。

Result: 新方法在细胞运动完整轨迹预测上表现出高精度，且能够通过观测特征有效预测细胞分裂事件。实验覆盖了仿真数据和实际数据，验证了该模型的有效性。

Conclusion: 结合结构保持神经网络与多种机器学习工具的方法显著提升了细胞行为和重要事件（如有丝分裂）的预测能力，有助于加深对细胞集体决策和生物力学过程的理解。

Abstract: Cell biomechanics involve a great number of complex phenomena that are
fundamental to the evolution of life itself and other associated processes,
ranging from the very early stages of embryo-genesis to the maintenance of
damaged structures or the growth of tumors. Given the importance of such
phenomena, increasing research has been dedicated to their understanding, but
the many interactions between them and their influence on the decisions of
cells as a collective network or cluster remain unclear. We present a new
approach that combines Structure Preserving Neural Networks, which study cell
movements as a purely mechanical system, with other Machine Learning tools
(Artificial Neural Networks), which allow taking into consideration
environmental factors that can be directly deduced from an experiment with
Computer Vision techniques. This new model, tested on simulated and real cell
migration cases, predicts complete cell trajectories following a roll-out
policy with a high level of accuracy. This work also includes a mitosis event
prediction model based on Neural Networks architectures which makes use of the
same observed features.

</details>


### [18] [Advanced Brain Tumor Segmentation Using EMCAD: Efficient Multi-scale Convolutional Attention Decoding](https://arxiv.org/abs/2509.05431)
*GodsGift Uzor,Tania-Amanda Nkoyo Fredrick Eneye,Chukwuebuka Ijezue*

Main category: cs.CV

TL;DR: 本文提出了一种高效多尺度卷积注意力解码器（EMCAD），用于在计算资源有限的情况下提升脑肿瘤分割的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的脑肿瘤分割解码方法虽然有效，但通常计算量大，不利于实际应用。作者希望设计一种既高效又能保持性能的分割解码器，便于在资源有限的条件下应用。

Method: 设计了一种新的多尺度卷积注意力解码器（EMCAD），并在BraTs2020脑肿瘤MRI数据集上进行实验。对模型训练和验证集的性能进行了评估。

Result: 模型取得了最好Dice分数为0.31，平均Dice分数为0.285±0.015，训练过程表现稳定，无明显过拟合。

Conclusion: EMCAD在计算资源有限的前提下，在脑肿瘤分割任务上实现了较为稳定和温和的分割性能，兼顾了效率与效果。

Abstract: Brain tumor segmentation is a critical pre-processing step in the medical
image analysis pipeline that involves precise delineation of tumor regions from
healthy brain tissue in medical imaging data, particularly MRI scans. An
efficient and effective decoding mechanism is crucial in brain tumor
segmentation especially in scenarios with limited computational resources.
However these decoding mechanisms usually come with high computational costs.
To address this concern EMCAD a new efficient multi-scale convolutional
attention decoder designed was utilized to optimize both performance and
computational efficiency for brain tumor segmentation on the BraTs2020 dataset
consisting of MRI scans from 369 brain tumor patients. The preliminary result
obtained by the model achieved a best Dice score of 0.31 and maintained a
stable mean Dice score of 0.285 plus/minus 0.015 throughout the training
process which is moderate. The initial model maintained consistent performance
across the validation set without showing signs of over-fitting.

</details>


### [19] [FAVAE-Effective Frequency Aware Latent Tokenizer](https://arxiv.org/abs/2509.05441)
*Tejaswini Medi,Hsien-Yi Wang,Arianna Rampini,Margret Keuper*

Main category: cs.CV

TL;DR: 本文分析了现有高质量图像生成模型的编码器在频率分布上的偏差，并提出了一种频率感知的自编码框架，有效提升了纹理和细节的复原质量。


<details>
  <summary>Details</summary>
Motivation: 现有潜变量生成模型压缩图像时，常导致高频细节丢失，生成的图像过于平滑，真实性受损，尤其在高频纹理区域表现不佳。本研究旨在分析并解决现有方法忽略高频信息的问题，提高生成图像的真实感和细节。

Method: 首先对主流潜变量编码器进行频率分解分析，发现其目标函数更偏向低频重建。继而提出了一种基于小波变换的频率感知变分自编码器（FA-VAE），通过显式分离高低频优化流程，分别对不同频率成分进行优化，从而提升整体重建质量。

Result: 实验显示，FA-VAE在保持全局结构的前提下，显著提升了细腻纹理和高频区域的还原效果，缓解了过度平滑和视觉伪影问题。

Conclusion: 本文方法有效弥补了当前潜变量编码器在高频表现上的不足，显著提高了图像生成质量。频率感知优化对图像真实性有重要促进作用，对内容创作、神经渲染和医学影像等领域具有广泛应用前景。

Abstract: Latent generative models have shown remarkable progress in high-fidelity
image synthesis, typically using a two-stage training process that involves
compressing images into latent embeddings via learned tokenizers in the first
stage. The quality of generation strongly depends on how expressive and
well-optimized these latent embeddings are. While various methods have been
proposed to learn effective latent representations, the reconstructed images
often lack realism, particularly in textured regions with sharp transitions,
due to loss of fine details governed by high frequencies. We conduct a detailed
frequency decomposition of existing state-of-the-art (SOTA) latent tokenizers
and show that conventional objectives inherently prioritize low-frequency
reconstruction, often at the expense of high-frequency fidelity. Our analysis
reveals these latent tokenizers exhibit a bias toward low-frequency
information, when jointly optimized, leading to over-smoothed outputs and
visual artifacts that diminish perceptual quality. To address this, we propose
a wavelet-based, frequency-aware variational autoencoder (FA-VAE) framework
that explicitly decouples the optimization of low- and high-frequency
components. This decoupling enables improved reconstruction of fine textures
while preserving global structure. Our approach bridges the fidelity gap in
current latent tokenizers and emphasizes the importance of frequency-aware
optimization for realistic image representation, with broader implications for
applications in content creation, neural rendering, and medical imaging.

</details>


### [20] [Dynamic Sensitivity Filter Pruning using Multi-Agent Reinforcement Learning For DCNN's](https://arxiv.org/abs/2509.05446)
*Iftekhar Haider Chowdhury,Zaed Ikbal Syed,Ahmed Faizul Haque Dhrubo,Mohammad Abdul Qayum*

Main category: cs.CV

TL;DR: 本论文提出了一个新的卷积神经网络滤波器剪枝方法——差异敏感度融合剪枝（DSFP），能大幅降低模型复杂度，同时在高剪枝率下保持高精度。


<details>
  <summary>Details</summary>
Motivation: 深度卷积神经网络在各类视觉任务中表现优越，但其高计算与存储开销限制了实际部署，尤其是在边缘和移动平台上。因此，研究高效且有效的模型压缩方法成为迫切需求。

Method: 提出差异敏感度融合剪枝（DSFP），通过融合梯度敏感度、一阶泰勒展开与激活分布的KL散度三种标准，计算每个滤波器的差异敏感度分数。引入指数缩放机制，突出在各标准下重要性不一致的滤波器，然后进行一次性评分与剪枝，无需迭代或强化学习。

Result: 在不同剪枝率下（50%到70%），DSFP能够大幅度减少模型浮点运算量（超80%），并在70%剪枝时保持98.23%的原始精度，优于传统剪枝方法。

Conclusion: DSFP方法为深度神经网络高效、可扩展压缩提供了新思路，为边缘计算和移动平台的部署带来了实际可行性。

Abstract: Deep Convolutional Neural Networks have achieved state of the art performance
across various computer vision tasks, however their practical deployment is
limited by computational and memory overhead. This paper introduces
Differential Sensitivity Fusion Pruning, a novel single shot filter pruning
framework that focuses on evaluating the stability and redundancy of filter
importance scores across multiple criteria. Differential Sensitivity Fusion
Pruning computes a differential sensitivity score for each filter by fusing the
discrepancies among gradient based sensitivity, first order Taylor expansion,
and KL divergence of activation distributions. An exponential scaling mechanism
is applied to emphasize filters with inconsistent importance across metrics,
identifying candidates that are structurally unstable or less critical to the
model performance. Unlike iterative or reinforcement learning based pruning
strategies, Differential Sensitivity Fusion Pruning is efficient and
deterministic, requiring only a single forward-backward pass for scoring and
pruning. Extensive experiments across varying pruning rates between 50 to 70
percent demonstrate that Differential Sensitivity Fusion Pruning significantly
reduces model complexity, achieving over 80 percent Floating point Operations
Per Seconds reduction while maintaining high accuracy. For instance, at 70
percent pruning, our approach retains up to 98.23 percent of baseline accuracy,
surpassing traditional heuristics in both compression and generalization. The
proposed method presents an effective solution for scalable and adaptive Deep
Convolutional Neural Networks compression, paving the way for efficient
deployment on edge and mobile platforms.

</details>


### [21] [Veriserum: A dual-plane fluoroscopic dataset with knee implant phantoms for deep learning in medical imaging](https://arxiv.org/abs/2509.05483)
*Jinhao Wang,Florian Vogl,Pascal Schütz,Saša Ćuković,William R. Taylor*

Main category: cs.CV

TL;DR: Veriserum是一个开放获取的深度学习配准数据集，包含约11万张双平面X光图像及标注，专为医学计算机视觉算法开发与评估设计。


<details>
  <summary>Details</summary>
Motivation: 目前医学影像中2D/3D注册和分析的高质量标注数据集稀缺，尤其在人工膝关节植入分析领域，限制了深度学习算法的训练与验证。该数据集旨在解决这一瓶颈，促进相关研究进展。

Method: 收集了2种股骨和5种胫骨植入组合的膝关节模型在1600次试验下的双视角X光数据，标注自动作配准的真实位姿，并对部分图像进行了人工配准，用于基准测试。此外，公开了校准工具和相关注释信息。

Result: 数据集包含约11万张带有精确配准标签的X光图像，覆盖丰富的日常动作姿势，并对部分图像进行了人工精确对齐，适合2D/3D配准算法开发、分割、畸变校正和3D重建等多种医学影像任务。

Conclusion: Veriserum作为首个此类大规模开放双平面X光数据集，为医学计算机视觉领域提供了可复现的基准，推动了深度学习算法在骨科植入分析等多个方向的创新和验证。

Abstract: Veriserum is an open-source dataset designed to support the training of deep
learning registration for dual-plane fluoroscopic analysis. It comprises
approximately 110,000 X-ray images of 10 knee implant pair combinations (2
femur and 5 tibia implants) captured during 1,600 trials, incorporating poses
associated with daily activities such as level gait and ramp descent. Each
image is annotated with an automatically registered ground-truth pose, while
200 images include manually registered poses for benchmarking.
  Key features of Veriserum include dual-plane images and calibration tools.
The dataset aims to support the development of applications such as 2D/3D image
registration, image segmentation, X-ray distortion correction, and 3D
reconstruction. Freely accessible, Veriserum aims to advance computer vision
and medical imaging research by providing a reproducible benchmark for
algorithm development and evaluation. The Veriserum dataset used in this study
is publicly available via
https://movement.ethz.ch/data-repository/veriserum.html, with the data stored
at ETH Z\"urich Research Collections: https://doi.org/10.3929/ethz-b-000701146.

</details>


### [22] [An Analysis of Layer-Freezing Strategies for Enhanced Transfer Learning in YOLO Architectures](https://arxiv.org/abs/2509.05490)
*Andrzej D. Dobrzycki,Ana M. Bernardos,José R. Casar*

Main category: cs.CV

TL;DR: 本研究系统分析了在YOLOv8和YOLOv10架构上采用不同层冻结策略对目标检测性能的影响，重点关注训练动态、数据集特征与冻结深度之间的关系，为受限资源下实现高效迁移学习提供了实证建议。


<details>
  <summary>Details</summary>
Motivation: YOLO架构在实时目标检测中十分重要，但在受限资源环境（如无人机）下部署需高效迁移学习。常用的层冻结技术在新版YOLO（YOLOv8/v10）上的具体影响尚未深入探讨，尤其是冻结层深度、数据特性与训练动态的关系，因此本文旨在填补该研究空白。

Method: 对YOLOv8和YOLOv10多种变体进行系统实验，对比多种层冻结配置，并用四个代表关键基础设施监控的挑战性数据集。方法融合了梯度行为分析（L2范数）和可视化解释（Grad-CAM），系统揭示冻结策略对训练动力学的影响。

Result: 不同冻结配置下并无唯一最优策略，最佳策略取决于数据特性；如冻结backbone有助保持通用特征，应对类别极度失衡时浅层冻结更优。多项配置能在减少GPU显存消耗（最高28%）同时，部分情况下mAP@50还超越全量微调。梯度分析显示，适度冻结模型收敛特性不同。

Conclusion: 本研究为选择YOLO层冻结策略提供了实践指南和实证依据，推动在资源受限场景下基于证据的平衡迁移学习方法落地，兼顾算力效率与目标检测精度。

Abstract: The You Only Look Once (YOLO) architecture is crucial for real-time object
detection. However, deploying it in resource-constrained environments such as
unmanned aerial vehicles (UAVs) requires efficient transfer learning. Although
layer freezing is a common technique, the specific impact of various freezing
configurations on contemporary YOLOv8 and YOLOv10 architectures remains
unexplored, particularly with regard to the interplay between freezing depth,
dataset characteristics, and training dynamics. This research addresses this
gap by presenting a detailed analysis of layer-freezing strategies. We
systematically investigate multiple freezing configurations across YOLOv8 and
YOLOv10 variants using four challenging datasets that represent critical
infrastructure monitoring. Our methodology integrates a gradient behavior
analysis (L2 norm) and visual explanations (Grad-CAM) to provide deeper
insights into training dynamics under different freezing strategies. Our
results reveal that there is no universal optimal freezing strategy but,
rather, one that depends on the properties of the data. For example, freezing
the backbone is effective for preserving general-purpose features, while a
shallower freeze is better suited to handling extreme class imbalance. These
configurations reduce graphics processing unit (GPU) memory consumption by up
to 28% compared to full fine-tuning and, in some cases, achieve mean average
precision (mAP@50) scores that surpass those of full fine-tuning. Gradient
analysis corroborates these findings, showing distinct convergence patterns for
moderately frozen models. Ultimately, this work provides empirical findings and
practical guidelines for selecting freezing strategies. It offers a practical,
evidence-based approach to balanced transfer learning for object detection in
scenarios with limited resources.

</details>


### [23] [Quaternion Approximation Networks for Enhanced Image Classification and Oriented Object Detection](https://arxiv.org/abs/2509.05512)
*Bryce Grant,Peng Wang*

Main category: cs.CV

TL;DR: 本文提出了 Quaternion Approximate Networks (QUAN)，通过四元数代数实现旋转等变的高效图像分类和目标检测，在多个数据集与任务上优于传统卷积和四元数网络。


<details>
  <summary>Details</summary>
Motivation: 传统的卷积神经网络难以高效处理涉及旋转的视觉任务，而现有四元数神经网络实现复杂、效率低。为了解决这一矛盾，作者希望设计一种既能保持旋转等变特性，又有利于实际高效部署的神经网络结构。

Method: QUAN通过将四元数哈密尔顿积分解为实值运算来近似实现四元数卷积，结合自定义CUDA内核。为提升训练稳定性，提出了独立四元数批归一化（IQBN）。此外，将四元数操作扩展至空间注意力机制。

Result: 在CIFAR-10/100、ImageNet等分类任务中，QUAN以更少的参数实现了更高准确率和更快收敛速度。目标检测（如COCO、DOTA）中，QUAN展现更高参数效率与旋转处理能力，达到了四元数CNN的SOTA表现。

Conclusion: QUAN不仅实现了旋转感知的高效学习，对计算资源有限且需旋转感知的机器人等场景具有实际部署潜力，也为其他有类似需求的领域提供了新思路。

Abstract: This paper introduces Quaternion Approximate Networks (QUAN), a novel deep
learning framework that leverages quaternion algebra for rotation equivariant
image classification and object detection. Unlike conventional quaternion
neural networks attempting to operate entirely in the quaternion domain, QUAN
approximates quaternion convolution through Hamilton product decomposition
using real-valued operations. This approach preserves geometric properties
while enabling efficient implementation with custom CUDA kernels. We introduce
Independent Quaternion Batch Normalization (IQBN) for training stability and
extend quaternion operations to spatial attention mechanisms. QUAN is evaluated
on image classification (CIFAR-10/100, ImageNet), object detection (COCO,
DOTA), and robotic perception tasks. In classification tasks, QUAN achieves
higher accuracy with fewer parameters and faster convergence compared to
existing convolution and quaternion-based models. For objection detection, QUAN
demonstrates improved parameter efficiency and rotation handling over standard
Convolutional Neural Networks (CNNs) while establishing the SOTA for quaternion
CNNs in this downstream task. These results highlight its potential for
deployment in resource-constrained robotic systems requiring rotation-aware
perception and application in other domains.

</details>


### [24] [OpenEgo: A Large-Scale Multimodal Egocentric Dataset for Dexterous Manipulation](https://arxiv.org/abs/2509.05513)
*Ahad Jawaid,Yu Xiang*

Main category: cs.CV

TL;DR: 本论文提出了OpenEgo，一个大规模多模态第一人称手部操作数据集，包含标准化手部姿态标注和动作原语，以推动仿人操作学习。


<details>
  <summary>Details</summary>
Motivation: 现有的第一人称视频数据集在模仿学习中具有重要价值，但存在两个主要问题：要么缺乏细粒度的、时间定位的动作描述，要么缺乏灵巧手部注释，限制了复杂操作学习的发展。

Method: 作者构建了OpenEgo数据集，整合了六个公开数据集，总计1107小时，覆盖290种操作任务和600多个环境。数据集统一了手部姿态标注标准，并为每个动作配有详细、带时间戳的动作原语描述。此外，为了验证数据集的实用性，作者基于该数据训练了受语言指令引导的模仿学习策略，用于预测复杂手部动作轨迹。

Result: OpenEgo数据集不仅实现了手部姿态标注和动作原语的统一，还成功支持了基于视觉-语言-动作的模仿学习任务。实验表明使用该数据集能有效提升仿人手部动作路线的预测能力。

Conclusion: OpenEgo有效降低了从第一人称视频中学习灵巧手部操作的技术门槛，为视觉-语言-动作学习研究提供了标准平台，有助于推动领域的可复现研究和进一步发展。

Abstract: Egocentric human videos provide scalable demonstrations for imitation
learning, but existing corpora often lack either fine-grained, temporally
localized action descriptions or dexterous hand annotations. We introduce
OpenEgo, a multimodal egocentric manipulation dataset with standardized
hand-pose annotations and intention-aligned action primitives. OpenEgo totals
1107 hours across six public datasets, covering 290 manipulation tasks in 600+
environments. We unify hand-pose layouts and provide descriptive, timestamped
action primitives. To validate its utility, we train language-conditioned
imitation-learning policies to predict dexterous hand trajectories. OpenEgo is
designed to lower the barrier to learning dexterous manipulation from
egocentric video and to support reproducible research in vision-language-action
learning. All resources and instructions will be released at
www.openegocentric.com.

</details>


### [25] [Visibility-Aware Language Aggregation for Open-Vocabulary Segmentation in 3D Gaussian Splatting](https://arxiv.org/abs/2509.05515)
*Sen Wang,Kunyi Li,Siyun Liang,Elena Alegret,Jing Ma,Nassir Navab,Stefano Gasperini*

Main category: cs.CV

TL;DR: 本文提出了一种名为VALA（Visibility-Aware Language Aggregation）的方法，用于改进3D高斯表示中多视角语言特征蒸馏的准确性和一致性。该方法能增强3D场景中开放词汇的定位和分割能力，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法中，背景高斯与前景高斯享有相同的语言特征，且不同视角下的语言嵌入存在不一致性与噪声，影响了3D场景的交互与理解效果。

Method: VALA为每条射线计算边际贡献度，并用可见性门控筛除不可见高斯；同时提出了一种在余弦空间中进行流式加权几何中值的多视角特征聚合方法，有效消除视角间的特征噪声。

Result: 该方法实现了鲁棒且视角一致的语言特征嵌入，同时保持高效的计算速度和较低的内存消耗，在多个基准数据集上的开放词汇定位和分割任务中均优于现有方法。

Conclusion: VALA显著提升了3D高斯场景下基于语言的理解与交互能力，为开放词汇3D识别任务提供了更一致和高效的解决方案，展现出较强的应用前景。

Abstract: Recently, distilling open-vocabulary language features from 2D images into 3D
Gaussians has attracted significant attention. Although existing methods
achieve impressive language-based interactions of 3D scenes, we observe two
fundamental issues: background Gaussians contributing negligibly to a rendered
pixel get the same feature as the dominant foreground ones, and multi-view
inconsistencies due to view-specific noise in language embeddings. We introduce
Visibility-Aware Language Aggregation (VALA), a lightweight yet effective
method that computes marginal contributions for each ray and applies a
visibility-aware gate to retain only visible Gaussians. Moreover, we propose a
streaming weighted geometric median in cosine space to merge noisy multi-view
features. Our method yields a robust, view-consistent language feature
embedding in a fast and memory-efficient manner. VALA improves open-vocabulary
localization and segmentation across reference datasets, consistently
surpassing existing works.

</details>


### [26] [DuoCLR: Dual-Surrogate Contrastive Learning for Skeleton-based Human Action Segmentation](https://arxiv.org/abs/2509.05543)
*Haitao Tian,Pierre Payeur*

Main category: cs.CV

TL;DR: 本文提出了一种利用对比学习和新颖数据增强方法（Shuffle and Warp）进行人类动作分割的框架，通过在单一动作骨架序列上进行预训练，大幅提升了多类别、多标签动作分割的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的对比表征学习多关注于动作识别，并未充分利用动作序列中的多尺度特征和跨序列变化，导致对复杂动作分割任务的支持有限。该研究旨在解决这一不足。

Method: 方法上，作者提出了Shuffle and Warp数据增强策略生成多样化动作序列排列，并结合两种对比任务：CPC（跨排列对比）增强类内特征，ROR（相对顺序推理）优化类间关系，通过DuoCLR网络实现多尺度特征的学习和优化，提升分割性能。

Result: 在经过单一动作骨架数据集预训练后，所提方法在未剪辑数据集上的多类别和多标签动作分割任务上都显著优于现有方法。同时，消融实验验证了各组成部分的有效性。

Conclusion: DuoCLR通过创新的多尺度对比学习机制和数据增强方法，极大提升了人类动作分割的精度，对提升相关任务表现具有重要意义。

Abstract: In this paper, a contrastive representation learning framework is proposed to
enhance human action segmentation via pre-training using trimmed (single
action) skeleton sequences. Unlike previous representation learning works that
are tailored for action recognition and that build upon isolated sequence-wise
representations, the proposed framework focuses on exploiting multi-scale
representations in conjunction with cross-sequence variations. More
specifically, it proposes a novel data augmentation strategy, 'Shuffle and
Warp', which exploits diverse multi-action permutations. The latter effectively
assists two surrogate tasks that are introduced in contrastive learning: Cross
Permutation Contrasting (CPC) and Relative Order Reasoning (ROR). In
optimization, CPC learns intra-class similarities by contrasting
representations of the same action class across different permutations, while
ROR reasons about inter-class contexts by predicting relative mapping between
two permutations. Together, these tasks enable a Dual-Surrogate Contrastive
Learning (DuoCLR) network to learn multi-scale feature representations
optimized for action segmentation. In experiments, DuoCLR is pre-trained on a
trimmed skeleton dataset and evaluated on an untrimmed dataset where it
demonstrates a significant boost over state-the-art comparatives in both
multi-class and multi-label action segmentation tasks. Lastly, ablation studies
are conducted to evaluate the effectiveness of each component of the proposed
approach.

</details>


### [27] [RED: Robust Event-Guided Motion Deblurring with Modality-Specific Disentangled Representation](https://arxiv.org/abs/2509.05554)
*Yihong Leng,Siming Zheng,Jinwei Chen,Bo Li,Jiaojiao Li,Peng-Tao Jiang*

Main category: cs.CV

TL;DR: 本文提出了一种针对事件相机去模糊任务的新方法RED，兼顾了事件流不完整性和图像信息，显著提升了去模糊准确性和鲁棒性，并在多个数据集取得领先效果。


<details>
  <summary>Details</summary>
Motivation: 传统事件引导去模糊方法忽略了事件流因传感器阈值机制导致的不完整性问题，致使运动先验信息受损，影响方法效果。本文旨在提升去模糊方法对于事件流不完整及实例间变化的适应能力。

Method: 1）提出鲁棒性扰动策略（RPS），通过对事件流随机mask，使网络适应于不完整事件信息，增强鲁棒性；2）设计解耦OmniAttention模块，分别挖掘模态内、模态间及跨模态的运动相关性；3）构建两个交互模块，提升模糊图像的运动敏感区域表示，同时利用图像语义补全事件特征。

Result: 在合成及真实数据集上，RED网络无论在准确率还是鲁棒性上均优于当前所有主流方法，取得了最新最优的去模糊性能。

Conclusion: 将事件模态与图像模态特性充分结合，并通过扰动与解耦特征建模机制，RED成功克服了事件流不完整带来的性能退化问题，为事件引导去模糊任务近年来的发展带来新突破。

Abstract: Event cameras provide sparse yet temporally high-temporal-resolution motion
information, demonstrating great potential for motion deblurring. Existing
methods focus on cross-modal interaction, overlooking the inherent
incompleteness of event streams, which arises from the trade-off between
sensitivity and noise introduced by the thresholding mechanism of Dynamic
Vision Sensors (DVS). Such degradation compromises the integrity of motion
priors and limits the effectiveness of event-guided deblurring. To tackle these
challenges, we propose a Robust Event-guided Deblurring (RED) network with
modality-specific disentangled representation. First, we introduce a
Robustness-Oriented Perturbation Strategy (RPS) that applies random masking to
events, which exposes RED to incomplete patterns and then foster robustness
against various unknown scenario conditions.Next, a disentangled OmniAttention
is presented to explicitly model intra-motion, inter-motion, and cross-modality
correlations from two inherently distinct but complementary sources: blurry
images and partially disrupted events. Building on these reliable features, two
interactive modules are designed to enhance motion-sensitive areas in blurry
images and inject semantic context into incomplete event representations.
Extensive experiments on synthetic and real-world datasets demonstrate RED
consistently achieves state-of-the-art performance in both accuracy and
robustness.

</details>


### [28] [Sensitivity-Aware Post-Training Quantization for Deep Neural Networks](https://arxiv.org/abs/2509.05576)
*Zekang Zheng,Haokun Li,Yaofo Chen,Mingkui Tan,Qing Du*

Main category: cs.CV

TL;DR: 本文提出了一种高效的后训练量化（PTQ）方法，通过参数敏感性分析指导量化，显著降低计算复杂度，同时保持网络准确率，适用于边缘计算和实时推理场景。


<details>
  <summary>Details</summary>
Motivation: 现有PTQ方法为保证高压缩比下的精度，需大量迭代参数更新，带来高昂的计算和资源开销，难以应用于资源受限或需低延迟的场景。

Method: 提出先对参数做敏感性分析，优先量化高敏感度参数，利用未量化的低敏感度参数来补偿量化误差，减少精度损失。此外，结合参数敏感性在列上的聚类特性，引入行并行量化框架，并采用全局共享逆Hessian矩阵更新策略，大幅降低计算复杂度。

Result: 在ResNet-50和YOLOv5s上实验表明，量化速度提升了20-200倍（相较于Optimal Brain Quantization基线），平均精度损失低于0.3%。

Conclusion: 该方法在保证量化精度的同时，大幅提升了效率，非常适用于边缘计算和实时推理等场景。

Abstract: Model quantization reduces neural network parameter precision to achieve
compression, but often compromises accuracy. Existing post-training
quantization (PTQ) methods employ iterative parameter updates to preserve
accuracy under high compression ratios, incurring significant computational
complexity and resource overhead, which limits applicability in
resource-constrained edge computing and real-time inference scenarios. This
paper proposes an efficient PTQ method guided by parameter sensitivity
analysis. The approach prioritizes quantization of high-sensitivity parameters,
leveraging unquantized low-sensitivity parameters to compensate for
quantization errors, thereby mitigating accuracy degradation. Furthermore, by
exploiting column-wise clustering of parameter sensitivity, the method
introduces a row-parallel quantization framework with a globally shared inverse
Hessian matrix update mechanism, reducing computational complexity by an order
of magnitude. Experimental results on ResNet-50 and YOLOv5s demonstrate a
20-200-fold quantization speedup over the Optimal Brain Quantization baseline,
with mean accuracy loss below 0.3%, confirming the method's efficacy in
balancing efficiency and accuracy.

</details>


### [29] [Reconstruction and Reenactment Separated Method for Realistic Gaussian Head](https://arxiv.org/abs/2509.05582)
*Zhiling Ye,Cong Zhou,Xiubao Zhang,Haifeng Shen,Weihong Deng,Quan Lu*

Main category: cs.CV

TL;DR: 本文提出了一种基于3D高斯的头像重建与驱动分离框架，仅用单张人像即可生成可控虚拟人头像，具有更好泛化性、高效渲染与领先性能。


<details>
  <summary>Details</summary>
Motivation: 当前3D头像生成常受限于需多视角输入和驱动效率低等问题，作者旨在用单张图像生成可高效驱动且效果优异的3D头像。

Method: 方法分为重建和驱动两部分：先通过基于WebSSL的单视角3D高斯头像生成器和两阶段训练策略，提升重建效果及泛化、高频细节；再通过超轻量级渲染网络，实现高帧率控制与渲染，并采用分离设计保证效率；同时验证参数扩展可提升性能。

Result: 实验证明，提出的方法在重建质量和渲染性能上均超越现有领先方法，可在512x512分辨率下达到90帧每秒的渲染速度，且分离框架下驱动效率不受影响。

Conclusion: 本文框架实现了高质量、可控、高效的3D头像生成与驱动，突破了现有方法的局限，具有广泛应用价值，且经过多项实验验证其优越性。

Abstract: In this paper, we explore a reconstruction and reenactment separated
framework for 3D Gaussians head, which requires only a single portrait image as
input to generate controllable avatar. Specifically, we developed a large-scale
one-shot gaussian head generator built upon WebSSL and employed a two-stage
training approach that significantly enhances the capabilities of
generalization and high-frequency texture reconstruction. During inference, an
ultra-lightweight gaussian avatar driven by control signals enables high
frame-rate rendering, achieving 90 FPS at a resolution of 512x512. We further
demonstrate that the proposed framework follows the scaling law, whereby
increasing the parameter scale of the reconstruction module leads to improved
performance. Moreover, thanks to the separation design, driving efficiency
remains unaffected. Finally, extensive quantitative and qualitative experiments
validate that our approach outperforms current state-of-the-art methods.

</details>


### [30] [MFFI: Multi-Dimensional Face Forgery Image Dataset for Real-World Scenarios](https://arxiv.org/abs/2509.05592)
*Changtao Miao,Yi Zhang,Man Luo,Weiwei Feng,Kaiyuan Zheng,Qi Chu,Tao Gong,Jianshu Li,Yunfeng Diao,Wei Zhou,Joey Tianyi Zhou,Xiaoshuai Hao*

Main category: cs.CV

TL;DR: 本文提出了MFFI多维度人脸伪造图像数据集，能更好地模拟真实世界中的伪造场景，提升深度伪造检测方法的泛化与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测数据集存在多样性不足，导致检测算法在实际应用中的有效性受限，尤其是在高级伪造技术、场景变化、真实数据丰富性和真实传播退化等方面的缺陷。

Method: 作者构建了MFFI数据集，从更广泛的伪造手段、多样的面部场景、丰富的真实数据和多级质量退化四个维度提升数据的真实性。MFFI共包含50种不同的伪造方法，总计1024K张图像样本，支持复杂场景和多层次检测难度。

Result: 实验评测表明，MFFI在场景复杂性、跨域泛化能力和检测难度梯度方面优于目前已有的公开数据集。

Conclusion: MFFI显著提升了数据集在模拟真实场景和提升伪造检测算法有效性方面的水平，对于推动深度伪造检测领域发展具有实际价值。

Abstract: Rapid advances in Artificial Intelligence Generated Content (AIGC) have
enabled increasingly sophisticated face forgeries, posing a significant threat
to social security. However, current Deepfake detection methods are limited by
constraints in existing datasets, which lack the diversity necessary in
real-world scenarios. Specifically, these data sets fall short in four key
areas: unknown of advanced forgery techniques, variability of facial scenes,
richness of real data, and degradation of real-world propagation. To address
these challenges, we propose the Multi-dimensional Face Forgery Image
(\textbf{MFFI}) dataset, tailored for real-world scenarios. MFFI enhances
realism based on four strategic dimensions: 1) Wider Forgery Methods; 2) Varied
Facial Scenes; 3) Diversified Authentic Data; 4) Multi-level Degradation
Operations. MFFI integrates $50$ different forgery methods and contains $1024K$
image samples. Benchmark evaluations show that MFFI outperforms existing public
datasets in terms of scene complexity, cross-domain generalization capability,
and detection difficulty gradients. These results validate the technical
advance and practical utility of MFFI in simulating real-world conditions. The
dataset and additional details are publicly available at
{https://github.com/inclusionConf/MFFI}.

</details>


### [31] [Language-guided Recursive Spatiotemporal Graph Modeling for Video Summarization](https://arxiv.org/abs/2509.05604)
*Jungin Park,Jiyoung Lee,Kwanghoon Sohn*

Main category: cs.CV

TL;DR: 本文提出了一种基于语言引导和时空图网络的视频摘要方法VideoGraph，有效整合了物体间的语义关系和画面时序信息，在多个基准上取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 传统视频摘要方法主要关注帧间的全局时序关系，忽略了细粒度的视觉实体（如物体）和它们之间的语义联系。此外，最近的语言引导视频摘要需要更好地结合视频语义和文本信息，现有方法对此研究不足。

Method: 本文提出将视频摘要建模为语言引导的时空图问题，利用递归的时空图网络VideoGraph，将视频中的物体和帧分别作为图的节点，通过图边聚合节点之间的语义关系。为避免仅依赖视觉相似性将节点连接，引入由视频中提取的语言查询对节点进行表征，使节点拥有更丰富的语义知识，并递归式优化图结构，最终实现对关键帧的准确分类。

Result: VideoGraph在多种监督和无监督设置下，针对通用与查询驱动的视频摘要，在多个基准数据集上都实现了最优或领先的性能，优于现有主流方法。

Conclusion: 通过将语言查询与时空图建模相结合，VideoGraph有效提升了视频摘要的准确性与多样性，验证了细粒度语义建模和语言引导在视频理解任务中的重要性。

Abstract: Video summarization aims to select keyframes that are visually diverse and
can represent the whole story of a given video. Previous approaches have
focused on global interlinkability between frames in a video by temporal
modeling. However, fine-grained visual entities, such as objects, are also
highly related to the main content of the video. Moreover, language-guided
video summarization, which has recently been studied, requires a comprehensive
linguistic understanding of complex real-world videos. To consider how all the
objects are semantically related to each other, this paper regards video
summarization as a language-guided spatiotemporal graph modeling problem. We
present recursive spatiotemporal graph networks, called VideoGraph, which
formulate the objects and frames as nodes of the spatial and temporal graphs,
respectively. The nodes in each graph are connected and aggregated with graph
edges, representing the semantic relationships between the nodes. To prevent
the edges from being configured with visual similarity, we incorporate language
queries derived from the video into the graph node representations, enabling
them to contain semantic knowledge. In addition, we adopt a recursive strategy
to refine initial graphs and correctly classify each frame node as a keyframe.
In our experiments, VideoGraph achieves state-of-the-art performance on several
benchmarks for generic and query-focused video summarization in both supervised
and unsupervised manners. The code is available at
https://github.com/park-jungin/videograph.

</details>


### [32] [Patch-level Kernel Alignment for Self-Supervised Dense Representation Learning](https://arxiv.org/abs/2509.05606)
*Juan Yeo,Ijun Jang,Taesup Kim*

Main category: cs.CV

TL;DR: 本文提出了一种新的自监督学习框架，使预训练模型在图像的每个局部区域上也能学习到丰富语义，尤其用于需要空间精细度的视觉任务，并在多个基准测试中取得了最优表现。


<details>
  <summary>Details</summary>
Motivation: 现有自监督视觉表征学习方法以获取全局特征为主，难以满足分割、检测等对局部语义感知要求高的稠密预测任务，因此需要一种能提升局部特征表达能力的方法。

Method: 在已有预训练表征的基础上，通过额外的自监督过程，将全局的语义知识注入到稠密特征空间。具体方法为提出了Patch-level Kernel Alignment（PaKA），通过统计依赖对齐老师模型和学生模型的稠密特征分布。另外，设计了专门适用于稠密表示学习的数据增强策略。

Result: 在多个稠密视觉基准任务（如分割、检测等）上达到了state-of-the-art的表现，优于以往方法。

Conclusion: 通过提出的PaKA与改进数据增强，该框架能将全局语义知识有效迁移到稠密特征空间，显著增强了模型对稠密预测任务中的空间和细节信息的理解能力。

Abstract: Dense representations are essential for vision tasks that require spatial
precision and fine-grained detail. While most self-supervised representation
learning methods focus on global representations that summarize the image as a
whole, such approaches often fall short in capturing the localized semantics
necessary for dense prediction tasks. To overcome these limitations, we propose
a framework that builds on pretrained representations through additional
self-supervised learning, aiming to transfer existing semantic knowledge into
the dense feature space. Our method aligns the distributions of dense features
between a teacher and a student model. Specifically, we introduce Patch-level
Kernel Alignment (PaKA), a simple yet effective alignment objective that
captures statistical dependencies, thereby matching the structural
relationships of dense patches across the two models. In addition, we
investigate augmentation strategies specifically designed for dense
representation learning. Our framework achieves state-of-the-art results across
a variety of dense vision benchmarks, demonstrating the effectiveness of our
approach.

</details>


### [33] [SpecPrune-VLA: Accelerating Vision-Language-Action Models via Action-Aware Self-Speculative Pruning](https://arxiv.org/abs/2509.05614)
*Hanzhen Wang,Jiaming Xu,Jiayi Pan,Yongkang Zhou,Guohao Dai*

Main category: cs.CV

TL;DR: 本文提出了SpecPrune-VLA方法，通过结合本地与全局信息，在视觉-语言-动作模型（VLA）中进行高效剪枝，无需重新训练，有效加速推理并保持任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在剪枝时仅使用当前动作的本地信息，忽略了先前动作的全局上下文，导致模型成功率大幅下降且加速有限。这促使作者探索融合本地与全局历史信息，以提升剪枝策略的智能性和模型性能。

Method: SpecPrune-VLA方法分为两个剪枝层次：1）动作级静态剪枝，结合全局历史与本地上下文减少每步视觉token；2）层级动态剪枝，依据各层token重要性进行选择；此外引入轻量级动作感知控制器，根据动作的粗细粒度自适应调整剪枝强度。该方法无需训练。

Result: 在LIBERO数据集上，SpecPrune-VLA方法在NVIDIA A800和3090显卡上的推理速度分别提升1.46倍和1.57倍，并且任务成功率几乎未降低，相较于基线方法展现明显优势。

Conclusion: 与传统仅基于本地信息的剪枝相比，SpecPrune-VLA通过融合全局历史和动作粒度实现更高效的token选择，在不牺牲模型性能的前提下大幅提升推理加速，展示了良好的应用前景。

Abstract: Pruning accelerates compute-bound models by reducing computation. Recently
applied to Vision-Language-Action (VLA) models, existing methods prune tokens
using only local info from current action, ignoring global context from prior
actions, causing >20% success rate drop and limited speedup. We observe high
similarity across consecutive actions and propose leveraging both local
(current) and global (past) info for smarter token selection. We introduce
SpecPrune-VLA, a training-free method with two-level pruning and heuristic
control: (1) Static pruning at action level: uses global history and local
context to reduce visual tokens per action; (2) Dynamic pruning at layer level:
prunes tokens per layer based on layer-specific importance; (3) Lightweight
action-aware controller: classifies actions as coarse/fine-grained (by speed),
adjusting pruning aggressiveness since fine-grained actions are
pruning-sensitive. Experiments on LIBERO show SpecPrune-VLA achieves 1.46 times
speedup on NVIDIA A800 and 1.57 times on NVIDIA GeForce RTX 3090 vs.
OpenVLA-OFT, with negligible success rate loss.

</details>


### [34] [SuMa: A Subspace Mapping Approach for Robust and Effective Concept Erasure in Text-to-Image Diffusion Models](https://arxiv.org/abs/2509.05625)
*Kien Nguyen,Anh Tran,Cuong Pham*

Main category: cs.CV

TL;DR: 论文提出了一种新方法SuMa用于高效且稳健地在文本到图像扩散模型中抹除狭义概念（如名人或版权角色），解决了以往方法不能兼顾稳健性和图像质量的问题。


<details>
  <summary>Details</summary>
Motivation: 随着文本到图像扩散模型的快速发展，其生成有害或未经授权内容的风险引发关注。以往的概念抹除方法往往不能同时保证稳健性（目标概念能被完全抹除）和有效性（图像质量保持）。尤其对于窄域概念（如名人、特定角色等），因与其他概念距离较近，传统方法难以实现细粒度且有效的抹除。因此，需要新的方法来解决版权和法律相关的抹除难题。

Method: 本论文提出了Subspace Mapping（SuMa）方法。SuMa首先提取待抹除概念的向量子空间（target subspace），再通过映射将该子空间“中和”（neutralize）到一个参考子空间，从而最小化两者间的距离。这样可以有针对性地去除目标概念，同时最大程度保存图像质量。

Result: 通过在四个任务（子类、名人、艺术风格、实例抹除）上的广泛实验证明，SuMa方法在保证与高效方法相当图像质量的同时，也达到了与主打稳健性的现有方法相当的完整抹除效果。

Conclusion: SuMa有效平衡了稳健性和效果，在窄域概念的抹除上实现了当前最优性能，是解决扩散模型内容滥用问题的重要进展。

Abstract: The rapid growth of text-to-image diffusion models has raised concerns about
their potential misuse in generating harmful or unauthorized contents. To
address these issues, several Concept Erasure methods have been proposed.
However, most of them fail to achieve both robustness, i.e., the ability to
robustly remove the target concept., and effectiveness, i.e., maintaining image
quality. While few recent techniques successfully achieve these goals for NSFW
concepts, none could handle narrow concepts such as copyrighted characters or
celebrities. Erasing these narrow concepts is critical in addressing copyright
and legal concerns. However, erasing them is challenging due to their close
distances to non-target neighboring concepts, requiring finer-grained
manipulation. In this paper, we introduce Subspace Mapping (SuMa), a novel
method specifically designed to achieve both robustness and effectiveness in
easing these narrow concepts. SuMa first derives a target subspace representing
the concept to be erased and then neutralizes it by mapping it to a reference
subspace that minimizes the distance between the two. This mapping ensures the
target concept is robustly erased while preserving image quality. We conduct
extensive experiments with SuMa across four tasks: subclass erasure, celebrity
erasure, artistic style erasure, and instance erasure and compare the results
with current state-of-the-art methods. Our method achieves image quality
comparable to approaches focused on effectiveness, while also yielding results
that are on par with methods targeting completeness.

</details>


### [35] [Self-supervised Learning for Hyperspectral Images of Trees](https://arxiv.org/abs/2509.05630)
*Moqsadur Rahman,Saurav Kumar,Santosh S. Palmate,M. Shahriar Hossain*

Main category: cs.CV

TL;DR: 本文提出了一种自监督学习方法，用于从航空高光谱遥感图像中提取可以反映植被属性的树木表示，并证明了这些表示在下游机器学习任务中优于直接使用高光谱植被属性。


<details>
  <summary>Details</summary>
Motivation: 高光谱遥感图像中标签稀缺，数据分析存在困难，精准农业需要更高效的图像特征提取手段。

Method: 采用自监督学习神经网络，从航空高光谱图像中学习植被属性相关的嵌入表征，用于树木的表示。

Result: 实验结果显示，该嵌入空间构建的树木表示在下游机器学习任务中的表现优于直接采用高光谱植被属性特征。

Conclusion: 基于自监督学习的特征抽取方法能更好地反映树木植被属性，有效提升高光谱图像在农作物分析中的应用价值。

Abstract: Aerial remote sensing using multispectral and RGB imagers has provided a
critical impetus to precision agriculture. Analysis of the hyperspectral images
with limited or no labels is challenging. This paper focuses on self-supervised
learning to create neural network embeddings reflecting vegetation properties
of trees from aerial hyperspectral images of crop fields. Experimental results
demonstrate that a constructed tree representation, using a vegetation
property-related embedding space, performs better in downstream machine
learning tasks compared to the direct use of hyperspectral vegetation
properties as tree representations.

</details>


### [36] [Evaluating YOLO Architectures: Implications for Real-Time Vehicle Detection in Urban Environments of Bangladesh](https://arxiv.org/abs/2509.05652)
*Ha Meem Hossain,Pritam Nath,Mahitun Nesa Mahi,Imtiaz Uddin,Ishrat Jahan Eiste,Syed Nasibur Rahman Ratul,Md Naim Uddin Mozumdar,Asif Mohammed Saad*

Main category: cs.CV

TL;DR: 本文针对现有车辆检测系统在孟加拉国本地路况下无法识别本地特有车辆的问题，构建了包含29类本地车辆的数据集，并比较评估六种YOLO变体模型的检测性能。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶车辆检测大多训练于国外数据集，难以识别孟加拉国独有车辆类型，导致在本地环境下自动驾驶技术存在重大应用障碍。

Method: 作者自建包含29类本地车辆（如“Desi Nosimon”、“Leguna”、“Battery Rickshaw”、“CNG”等）的高分辨率图像数据集，并使用LabelImg手工标注YOLO格式边界框，随后评估YOLO六种主流变体在该数据集上的识别效果。

Result: 最优模型YOLOv11x在mAP@0.5上达到63.7%，mAP@0.5:0.95为43.8%，召回率61.4%，F1为61.6%，但推理时间较长（每张图45.8毫秒）；中等模型如YOLOv8m和YOLOv11m在检测性能及速度间表现均衡（mAP@0.5均在62%左右，推理时间在14-15毫秒）。部分罕见车辆（如Construction Vehicles、Desi Nosimon）因样本极少，检测准确率几乎为零。混淆矩阵显示部分外观相似车辆易被错误分类。

Conclusion: 该研究为孟加拉本土化车辆检测系统构建了基础数据和基线方法，显著改善了本地特殊路况下的检测能力，也为发展中地区自动驾驶车辆感知能力提升提供了新思路，对其他类似新兴市场亦具借鉴意义。

Abstract: Vehicle detection systems trained on Non-Bangladeshi datasets struggle to
accurately identify local vehicle types in Bangladesh's unique road
environments, creating critical gaps in autonomous driving technology for
developing regions. This study evaluates six YOLO model variants on a custom
dataset featuring 29 distinct vehicle classes, including region-specific
vehicles such as ``Desi Nosimon'', ``Leguna'', ``Battery Rickshaw'', and
``CNG''. The dataset comprises high-resolution images (1920x1080) captured
across various Bangladeshi roads using mobile phone cameras and manually
annotated using LabelImg with YOLO format bounding boxes. Performance
evaluation revealed YOLOv11x as the top performer, achieving 63.7\% mAP@0.5,
43.8\% mAP@0.5:0.95, 61.4\% recall, and 61.6\% F1-score, though requiring 45.8
milliseconds per image for inference. Medium variants (YOLOv8m, YOLOv11m)
struck an optimal balance, delivering robust detection performance with mAP@0.5
values of 62.5\% and 61.8\% respectively, while maintaining moderate inference
times around 14-15 milliseconds. The study identified significant detection
challenges for rare vehicle classes, with Construction Vehicles and Desi
Nosimons showing near-zero accuracy due to dataset imbalances and insufficient
training samples. Confusion matrices revealed frequent misclassifications
between visually similar vehicles, particularly Mini Trucks versus Mini Covered
Vans. This research provides a foundation for developing robust object
detection systems specifically adapted to Bangladesh traffic conditions,
addressing critical needs in autonomous vehicle technology advancement for
developing regions where conventional generic-trained models fail to perform
adequately.

</details>


### [37] [EditIDv2: Editable ID Customization with Data-Lubricated ID Feature Integration for Text-to-Image Generation](https://arxiv.org/abs/2509.05659)
*Guandong Li,Zhaobin Chu*

Main category: cs.CV

TL;DR: EditIDv2是一种针对复杂叙事场景和长文本输入，能够进行高质量、多层次角色编辑，且无需微调的新方法。


<details>
  <summary>Details</summary>
Motivation: 现有的人物编辑方法在处理简单提示时表现良好，但对包含多语义层次、时间逻辑和复杂上下文关系的长文本叙事容易出现编辑能力下降、语义理解偏差和身份一致性丧失的问题。因此，急需改进方法以在复杂场景下提升编辑质量并保证角色身份一致性。

Method: EditIDv2通过精细分解PerceiverAttention结构、引入ID loss及与扩散模型的联合动态训练，并提出ID特征融合模块的离线融合策略，从而实现复杂情境下的数据高效、深层次语义编辑，同时保持角色识别一致性，无需对模型进行微调，只需极少的数据润滑。

Result: 在IBench评测中，EditIDv2展现出对于长提示和高质量图像生成的优异能力，能够在复杂叙事环境下实现深层的、多语义层次的人物编辑并确保身份一致性。

Conclusion: EditIDv2有效解决了以往方法在复杂长文本场景中编辑能力不足和身份一致性差的问题，实现了在无需微调和极少数据下的高质量人物语义编辑。

Abstract: We propose EditIDv2, a tuning-free solution specifically designed for
high-complexity narrative scenes and long text inputs. Existing character
editing methods perform well under simple prompts, but often suffer from
degraded editing capabilities, semantic understanding biases, and identity
consistency breakdowns when faced with long text narratives containing multiple
semantic layers, temporal logic, and complex contextual relationships. In
EditID, we analyzed the impact of the ID integration module on editability. In
EditIDv2, we further explore and address the influence of the ID feature
integration module. The core of EditIDv2 is to discuss the issue of editability
injection under minimal data lubrication. Through a sophisticated decomposition
of PerceiverAttention, the introduction of ID loss and joint dynamic training
with the diffusion model, as well as an offline fusion strategy for the
integration module, we achieve deep, multi-level semantic editing while
maintaining identity consistency in complex narrative environments using only a
small amount of data lubrication. This meets the demands of long prompts and
high-quality image generation, and achieves excellent results in the IBench
evaluation.

</details>


### [38] [OOTSM: A Decoupled Linguistic Framework for Effective Scene Graph Anticipation](https://arxiv.org/abs/2509.05661)
*Xiaomeng Zhu,Changwei Wang,Haozhe Wang,Xinyu Liu,Fangzhen Lin*

Main category: cs.CV

TL;DR: 本文提出了一种新方法来提升场景图预测（SGA）的表现，利用大语言模型（LLM）增强对场景内对象及其关系的预测能力，实现了短期和长期显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有SGA方法主要依赖视觉信息，难以结合常识知识，导致长期预测效果有限，因此需要一种能更好地融合常识的新方法。

Method: 将SGA任务分为两步：首先用场景图捕捉模型将视频转为场景图序列，然后用基于文本的大语言模型（LSGA）预测未来帧的场景图。提出面向对象的双阶段方法（OOTSM），先由LLM预测对象的出现/消失，再生成具体的人-物关系。

Result: 在LSGA任务上，用微调的开源LLM与GPT-4o系列及DeepSeek-V3等API进行对比，在Action Genome数据集上评测，短期mean-Recall@10提升3.4%，长期mean-Recall@50提升21.9%。

Conclusion: 借助LLM协助场景图预测能有效增强模型的短期和长期推断能力，方法达到了新的最先进水平。

Abstract: A scene graph is a structured represention of objects and their relationships
in a scene. Scene Graph Anticipation (SGA) involves predicting future scene
graphs from video clips, enabling applications as intelligent surveillance and
human-machine collaboration. Existing SGA approaches primarily leverage visual
cues, often struggling to integrate valuable commonsense knowledge, thereby
limiting long-term prediction robustness. To explicitly leverage such
commonsense knowledge, we propose a new approach to better understand the
objects, concepts, and relationships in a scene graph. Our approach decouples
the SGA task in two steps: first a scene graph capturing model is used to
convert a video clip into a sequence of scene graphs, then a pure text-based
model is used to predict scene graphs in future frames. Our focus in this work
is on the second step, and we call it Linguistic Scene Graph Anticipation
(LSGA) and believes it should have independent interest beyond the use in SGA
discussed here. For LSGA, we introduce an Object-Oriented Two-Staged Method
(OOTSM) where an Large Language Model (LLM) first forecasts object appearances
and disappearances before generating detailed human-object relations. We
conduct extensive experiments to evaluate OOTSM in two settings. For LSGA, we
evaluate our fine-tuned open-sourced LLMs against zero-shot APIs (i.e., GPT-4o,
GPT-4o-mini, and DeepSeek-V3) on a benchmark constructed from Action Genome
annotations. For SGA, we combine our OOTSM with STTran++ from, and our
experiments demonstrate effective state-of-the-art performance: short-term
mean-Recall (@10) increases by 3.4% while long-term mean-Recall (@50) improves
dramatically by 21.9%. Code is available at https://github.com/ZhuXMMM/OOTSM.

</details>


### [39] [WIPUNet: A Physics-inspired Network with Weighted Inductive Biases for Image Denoising](https://arxiv.org/abs/2509.05662)
*Wasikul Islam*

Main category: cs.CV

TL;DR: 本文从高能物理中的叠加噪声消除方法得到启发，将物理先验（如守恒性、局部性、隔离性）嵌入神经网络结构以改进图像去噪鲁棒性，提出了一系列物理激励的神经网络方法，实验验证其在高噪声下较传统方法更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 高能物理实验中的碰撞数据经常被“叠加”噪声污染，研究物理学家用守恒、局部等物理主导的先验知识进行去噪。图像去噪领域也存在类似问题，因此作者希望将物理学中的去噪思想迁移，用物理先验提升神经网络去噪鲁棒性。

Method: 作者提出将物理先验（守恒性等）作为归纳偏置嵌入神经网络结构。具体实现包括：带守恒约束的残差CNN、加入高斯噪声的变体、以及将这些归纳偏置集成到UNet主干中的新型WIPUNet。用CIFAR-10与BSD500数据集在不同高斯噪声等级下，对这些物理先验网络与标准基线进行比较。

Result: PU激励的CNN在CIFAR-10高斯噪声测试下与常规基线性能相当，但WIPUNet在高噪声区域表现出更大的优势，BSD500实验也得到类似结论，说明引入物理归纳偏置的网络在噪声强烈时性能更稳定。

Conclusion: 将物理学中的噪声抑制原则作为可模块化的归纳偏置融入神经网络，能显著改进高噪声环境下的图像去噪鲁棒性，无需复杂或最新的SOTA技术。

Abstract: In high-energy particle physics, collider measurements are contaminated by
"pileup", overlapping soft interactions that obscure the hard-scatter signal of
interest. Dedicated subtraction strategies exploit physical priors such as
conservation, locality, and isolation. Inspired by this analogy, we investigate
how such principles can inform image denoising by embedding physics-guided
inductive biases into neural architectures. This paper is a proof of concept:
rather than targeting state-of-the-art (SOTA) benchmarks, we ask whether
physics-inspired priors improve robustness under strong corruption.
  We introduce a hierarchy of PU-inspired denoisers: a residual CNN with
conservation constraints, its Gaussian-noise variants, and the Weighted
Inductive Pileup-physics-inspired U-Network for Denoising (WIPUNet), which
integrates these ideas into a UNet backbone. On CIFAR-10 with Gaussian noise at
$\sigma\in\{15,25,50,75,100\}$, PU-inspired CNNs are competitive with standard
baselines, while WIPUNet shows a \emph{widening margin} at higher noise.
Complementary BSD500 experiments show the same trend, suggesting
physics-inspired priors provide stability where purely data-driven models
degrade. Our contributions are: (i) translating pileup-mitigation principles
into modular inductive biases; (ii) integrating them into UNet; and (iii)
demonstrating robustness gains at high noise without relying on heavy SOTA
machinery.

</details>


### [40] [Context-Aware Multi-Turn Visual-Textual Reasoning in LVLMs via Dynamic Memory and Adaptive Visual Guidance](https://arxiv.org/abs/2509.05669)
*Weijie Shen,Xinrui Wang,Yuanqi Nie,Apiradee Boonmee*

Main category: cs.CV

TL;DR: 提出了一种新的多轮视觉推理框架CAMVR，通过引入视觉-文本上下文记忆和自适应视觉关注机制，使视觉大模型在多轮对话推理中表现更优。


<details>
  <summary>Details</summary>
Motivation: 目前的大型语言模型和视觉-语言大模型在单轮任务表现优秀，但在多轮对话和复杂视觉推理中容易出现推理碎片化、上下文丢失和幻觉等问题。因此亟需提升其多轮推理和上下文管理能力。

Method: 提出了CAMVR框架，包含两个核心创新：视觉-文本上下文记忆单元（VCMU）用于动态存储和管理每轮交互产生的视觉和文本特征及其跨模态关系；自适应视觉关注引导机制（AVFG）利用VCMU记忆动态调整视觉编码器的关注区域。同时设计多层次推理整合方法以保证生成回复与历史上下文和当前输入高度一致。

Result: 在VisDial、A-OKVQA（修改版）及自建多轮指令跟随数据集MTIF上进行大量实验，CAMVR在这些具有挑战性的数据集上表现出一致的SOTA性能。

Conclusion: CAMVR显著提升了LVLM在多轮视觉-文本推理任务中的上下文理解、信息整合和推理连贯性，推进了多轮复杂对话系统的能力边界。

Abstract: Current Large Language Models (LLMs) and Vision-Language Large Models (LVLMs)
excel in single-turn tasks but face significant challenges in multi-turn
interactions requiring deep contextual understanding and complex visual
reasoning, often leading to fragmented reasoning, context loss, and
hallucinations. To address these limitations, we propose Context-Aware
Multi-Turn Visual Reasoning (CAMVR), a novel framework designed to empower
LVLMs with robust and coherent multi-turn visual-textual inference
capabilities. CAMVR introduces two key innovations: a Visual-Textual Context
Memory Unit (VCMU), a dynamic read-write memory network that stores and manages
critical visual features, textual semantic representations, and their
cross-modal correspondences from each interaction turn; and an Adaptive Visual
Focus Guidance (AVFG) mechanism, which leverages the VCMU's context to
dynamically adjust the visual encoder's attention to contextually relevant
image regions. Our multi-level reasoning integration strategy ensures that
response generation is deeply coherent with both current inputs and accumulated
historical context. Extensive experiments on challenging datasets, including
VisDial, an adapted A-OKVQA, and our novel Multi-Turn Instruction Following
(MTIF) dataset, demonstrate that CAMVR consistently achieves state-of-the-art
performance.

</details>


### [41] [MeshMetrics: A Precise Implementation of Distance-Based Image Segmentation Metrics](https://arxiv.org/abs/2509.05670)
*Gašper Podobnik,Tomaž Vrtovec*

Main category: cs.CV

TL;DR: 研究提出了一种名为MeshMetrics的网格基础度量计算框架，用于更精确地评估图像分割方法的性能，克服当前主流工具在距离型指标上的精度与一致性问题。


<details>
  <summary>Details</summary>
Motivation: 当前图像分割性能评估在度量指标的选择和实现方面存在可复现性危机，尤其是距离型指标（如Hausdorff距离）的实现导致不同开源工具之间有显著差异。这种实现层面的问题尚未被充分关注。

Method: 作者提出了MeshMetrics框架，利用网格（mesh）而非栅格（grid）来实现距离类分割指标的计算，从而提升度量的准确性和鲁棒性。通过理论分析和实证实验，比较了MeshMetrics与传统工具的性能。

Result: MeshMetrics相比传统的栅格工具在精度和准确性上有明显提升，对量化误差等离散化伪影更不敏感，并且实验中在多个距离类指标上效果更佳。

Conclusion: MeshMetrics为分割评估中的距离型指标带来更精确、可复现的计算方式，有望作为新一代标准工具。开源实现促进了科研公正与方法可复现性。

Abstract: The surge of research in image segmentation has yielded remarkable
performance gains but also exposed a reproducibility crisis. A major
contributor is performance evaluation, where both selection and implementation
of metrics play critical roles. While recent efforts have improved the former,
the reliability of metric implementation has received far less attention.
Pitfalls in distance-based metric implementation can lead to considerable
discrepancies between common open-source tools, for instance, exceeding 100 mm
for the Hausdorff distance and 30%pt for the normalized surface distance for
the same pair of segmentations. To address these pitfalls, we introduce
MeshMetrics, a mesh-based framework that provides a more precise computation of
distance-based metrics than conventional grid-based approaches. Through
theoretical analysis and empirical validation, we demonstrate that MeshMetrics
achieves higher accuracy and precision than established tools, and is
substantially less affected by discretization artifacts, such as distance
quantization. We release MeshMetrics as an open-source Python package,
available at https://github.com/gasperpodobnik/MeshMetrics.

</details>


### [42] [Leveraging Vision-Language Large Models for Interpretable Video Action Recognition with Semantic Tokenization](https://arxiv.org/abs/2509.05695)
*Jingwei Peng,Zhixuan Qiu,Boyu Jin,Surasakdi Siripong*

Main category: cs.CV

TL;DR: 本文提出了LVLM-VAR框架，首次将预训练视觉-语言大模型（LVLM）应用于视频动作识别，大幅提升了准确率与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有视频动作识别方法在理解深层语义、复杂语境和细粒度区分等方面存在不足，需要创新性方法提升性能，借鉴大语言模型的能力来突破瓶颈。

Method: 引入了Video-to-Semantic-Tokens（VST）模块，将视频序列转化为时序和语义一致的“动作语义token”，再结合自然语言指令输入到经过LoRA微调的LVLM（如LLaVA-13B）中，实现动作分类和语义推理。

Result: 在NTU RGB+D和NTU RGB+D 120等主流数据集取得了当前最优或极具竞争力的效果（如NTU RGB+D X-Sub上94.1%、NTU RGB+D 120 X-Set上90.0%），同时实现了预测结果的自然语言解释，显著提升可解释性。

Conclusion: LVLM-VAR框架突破了传统视频动作识别的局限，以创新的语义token方式结合视觉-语言大模型，在准确率和模型可解释性方面均有显著提升，推动了领域发展。

Abstract: Human action recognition often struggles with deep semantic understanding,
complex contextual information, and fine-grained distinction, limitations that
traditional methods frequently encounter when dealing with diverse video data.
Inspired by the remarkable capabilities of large language models, this paper
introduces LVLM-VAR, a novel framework that pioneers the application of
pre-trained Vision-Language Large Models (LVLMs) to video action recognition,
emphasizing enhanced accuracy and interpretability. Our method features a
Video-to-Semantic-Tokens (VST) Module, which innovatively transforms raw video
sequences into discrete, semantically and temporally consistent "semantic
action tokens," effectively crafting an "action narrative" that is
comprehensible to an LVLM. These tokens, combined with natural language
instructions, are then processed by a LoRA-fine-tuned LVLM (e.g., LLaVA-13B)
for robust action classification and semantic reasoning. LVLM-VAR not only
achieves state-of-the-art or highly competitive performance on challenging
benchmarks such as NTU RGB+D and NTU RGB+D 120, demonstrating significant
improvements (e.g., 94.1% on NTU RGB+D X-Sub and 90.0% on NTU RGB+D 120 X-Set),
but also substantially boosts model interpretability by generating natural
language explanations for its predictions.

</details>


### [43] [JRN-Geo: A Joint Perception Network based on RGB and Normal images for Cross-view Geo-localization](https://arxiv.org/abs/2509.05696)
*Hongyu Zhou,Yunzhou Zhang,Tingsong Huang,Fawei Ge,Man Qi,Xichen Zhang,Yizhong Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种结合RGB图像和法线图像几何结构信息的跨视角地理定位方法（JRN-Geo），在复杂视角变化下取得了最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有跨视角地理定位方法主要依赖RGB图像的语义特征，忽略了空间结构信息，导致在视角变化巨大时性能下降。作者旨在通过融合空间结构信息提升算法的视角不变性和定位精度。

Method: 作者提出JRN-Geo方法，采用双分支特征提取框架，分别处理RGB和法线图像，通过差异感知融合模块（DAFM）和联合约束交互聚合（JCIA）实现深度融合与联合表达。同时，设计了3D地理增强技术，生成多样化的视角变化样本以提升模型鲁棒性。

Result: 在University-1652和SUES-200数据集上进行的大量实验证明，所提方法在对抗复杂视角变化时表现出色，并取得了最新的最优性能。

Conclusion: 融合RGB与结构法线图像的JRN-Geo方法有效提升了跨视角地理定位的鲁棒性和准确率，为无人机等场景下的定位任务提供了新的解决思路。

Abstract: Cross-view geo-localization plays a critical role in Unmanned Aerial Vehicle
(UAV) localization and navigation. However, significant challenges arise from
the drastic viewpoint differences and appearance variations between images.
Existing methods predominantly rely on semantic features from RGB images, often
neglecting the importance of spatial structural information in capturing
viewpoint-invariant features. To address this issue, we incorporate geometric
structural information from normal images and introduce a Joint perception
network to integrate RGB and Normal images (JRN-Geo). Our approach utilizes a
dual-branch feature extraction framework, leveraging a Difference-Aware Fusion
Module (DAFM) and Joint-Constrained Interaction Aggregation (JCIA) strategy to
enable deep fusion and joint-constrained semantic and structural information
representation. Furthermore, we propose a 3D geographic augmentation technique
to generate potential viewpoint variation samples, enhancing the network's
ability to learn viewpoint-invariant features. Extensive experiments on the
University-1652 and SUES-200 datasets validate the robustness of our method
against complex viewpoint ariations, achieving state-of-the-art performance.

</details>


### [44] [Knowledge-Augmented Vision Language Models for Underwater Bioacoustic Spectrogram Analysis](https://arxiv.org/abs/2509.05703)
*Ragib Amin Nihal,Benjamin Yen,Takeshi Ashizawa,Kazuhiro Nakadai*

Main category: cs.CV

TL;DR: 本文探讨了Vision Language Models（VLMs）能否从生物声学频谱图中提取有意义的信息，并提出结合大语言模型（LLM）进行结果验证的框架，用于无监督海洋哺乳动物声学分析。


<details>
  <summary>Details</summary>
Motivation: 当前海洋哺乳动物声学分析高度依赖人工解读频谱图，耗时且需要专业知识。VLMs未针对该领域数据训练，其适用性未知，作者希望实现自动化、无监督的频谱图分析，减少人工标注与模型重训练的需求。

Method: 该方法将VLM用于对频谱图进行视觉模式识别，并结合LLM对VLM的解释结果进行语义层面的二次验证，以此构建面向海洋哺乳动物声学的知识体系，无需手工标注或模型重训练。

Result: 实验表明，通过该框架，VLM能在一定程度上识别频谱图中的有意义模式，而LLM的验证过程有助于增强理解和知识提取能力，实现了对声学数据的高效适应。

Conclusion: VLM结合LLM的解释验证机制，为海洋哺乳动物声学数据分析提供了一种自动化、无监督且无需领域标注的新途径，有望提升该领域的数据处理效率和知识积累。

Abstract: Marine mammal vocalization analysis depends on interpreting bioacoustic
spectrograms. Vision Language Models (VLMs) are not trained on these
domain-specific visualizations. We investigate whether VLMs can extract
meaningful patterns from spectrograms visually. Our framework integrates VLM
interpretation with LLM-based validation to build domain knowledge. This
enables adaptation to acoustic data without manual annotation or model
retraining.

</details>


### [45] [LiDAR-BIND-T: Improving SLAM with Temporally Consistent Cross-Modal LiDAR Reconstruction](https://arxiv.org/abs/2509.05728)
*Niels Balemans,Ali Anwar,Jan Steckel,Siegfried Mercelis*

Main category: cs.CV

TL;DR: 该论文提出LiDAR-BIND-T框架，通过加入时间一致性机制，显著提升多模态（雷达/声纳与激光雷达）融合时序和空间表现，优化SLAM任务表现。


<details>
  <summary>Details</summary>
Motivation: 原有的LiDAR-BIND多模态融合框架未能很好地保证传感器数据在时间上的一致性，影响了轨迹预测和地图构建的精度和稳定性。

Method: 1）引入时间嵌入相似性方法，对齐连续时刻的潜在空间；2）设计运动对齐转化损失，使模型对预测和真值激光雷达的位移进行匹配；3）开发专门的时间融合模块进行窗口内的时序特征处理，并改进了模型结构以更好地保持空间信息。此外，提出基于FVMD和相关性峰距的新评价指标。

Result: 在雷达/声纳到激光雷达的转换任务中，模型提升了时空一致性，降低绝对轨迹误差，提高SLAM中的占据图精度，实验验证了各时间质量指标的实用性。

Conclusion: LiDAR-BIND-T在保持灵活传感器融合能力的同时，大幅提升了时间稳定性，从而提升了SLAM任务中的鲁棒性与性能。

Abstract: This paper extends LiDAR-BIND, a modular multi-modal fusion framework that
binds heterogeneous sensors (radar, sonar) to a LiDAR-defined latent space,
with mechanisms that explicitly enforce temporal consistency. We introduce
three contributions: (i) temporal embedding similarity that aligns consecutive
latents, (ii) a motion-aligned transformation loss that matches displacement
between predictions and ground truth LiDAR, and (iii) windows temporal fusion
using a specialised temporal module. We further update the model architecture
to better preserve spatial structure. Evaluations on radar/sonar-to-LiDAR
translation demonstrate improved temporal and spatial coherence, yielding lower
absolute trajectory error and better occupancy map accuracy in
Cartographer-based SLAM (Simultaneous Localisation and Mapping). We propose
different metrics based on the Fr\'echet Video Motion Distance (FVMD) and a
correlation-peak distance metric providing practical temporal quality
indicators to evaluate SLAM performance. The proposed temporal LiDAR-BIND, or
LiDAR-BIND-T, maintains plug-and-play modality fusion while substantially
enhancing temporal stability, resulting in improved robustness and performance
for downstream SLAM.

</details>


### [46] [Multi-LVI-SAM: A Robust LiDAR-Visual-Inertial Odometry for Multiple Fisheye Cameras](https://arxiv.org/abs/2509.05740)
*Xinyu Zhang,Kai Huang,Junqiao Zhao,Zihan Yuan,Tiantian Feng*

Main category: cs.CV

TL;DR: 本文提出了一种融合多鱼眼相机、激光雷达和惯性传感器的多模态里程计算法Multi-LVI-SAM，通过全景视觉特征模型提升多相机视觉信息的整合和全局姿态优化能力，显著提升了定位精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在目前多相机激光雷达-视觉-惯性融合定位系统中，视觉信息难以高效一致地整合，多相机观测间约束复杂，导致设计冗余、优化效率和准确性受限。

Method: 提出基于全景视觉特征模型，将多鱼眼相机的观测统一到单一全景表示，作为全局几何优化的基础。引入外参补偿方法，校正单相机与全景模型间的误差，提升特征一致性与三角化精度，并将其嵌入因子图框架下的紧耦合激光雷达-视觉-惯性系统。

Result: 实验证明，全景视觉特征模型提升了多相机视角约束的质量与一致性，系统在公开数据集上定位精度和鲁棒性均优于已有同类系统。

Conclusion: 多相机激光雷达-视觉-惯性系统通过全景视觉特征融合与外参补偿，能够简化设计并提升姿态估计的准确性和鲁棒性，为高精度多传感器融合定位提供了有效方法。

Abstract: We propose a multi-camera LiDAR-visual-inertial odometry framework,
Multi-LVI-SAM, which fuses data from multiple fisheye cameras, LiDAR and
inertial sensors for highly accurate and robust state estimation. To enable
efficient and consistent integration of visual information from multiple
fisheye cameras, we introduce a panoramic visual feature model that unifies
multi-camera observations into a single representation. The panoramic model
serves as a global geometric optimization framework that consolidates
multi-view constraints, enabling seamless loop closure and global pose
optimization, while simplifying system design by avoiding redundant handling of
individual cameras. To address the triangulation inconsistency caused by the
misalignment between each camera's frame and the panoramic model's frame, we
propose an extrinsic compensation method. This method improves feature
consistency across views and significantly reduces triangulation and
optimization errors, leading to more accurate pose estimation. We integrate the
panoramic visual feature model into a tightly coupled LiDAR-visual-inertial
system based on a factor graph. Extensive experiments on public datasets
demonstrate that the panoramic visual feature model enhances the quality and
consistency of multi-camera constraints, resulting in higher accuracy and
robustness than existing multi-camera LiDAR-visual-inertial systems.

</details>


### [47] [Depth-Aware Super-Resolution via Distance-Adaptive Variational Formulation](https://arxiv.org/abs/2509.05746)
*Tianhao Guo,Bingjie Lu,Feng Wang,Zhengyang Lu*

Main category: cs.CV

TL;DR: 本文提出了一种基于理论的距离自适应单幅图像超分辨率方法，能够显著提升在深度可变场景下的重建质量，并在多个基准数据集上超过现有最佳方法。


<details>
  <summary>Details</summary>
Motivation: 现有超分辨率方法普遍假设退化过程在空间上是均匀的，但现实中由于大气散射、景深变化等因素，退化效果往往空间变化显著，造成方法泛化性和效果有限。因此，亟需一种能够结合场景几何特征、适应空间变化的超分策略。

Method: 作者提出将超分视为空间变异的反问题，退化算子建模为带有距离相关谱特性的伪微分算子，并用变分框架理论分析不同深度范围内重建极限。神经网络结构采用以深度为条件的卷积核及级联残差块实现离散梯度流，同时引入距离自适应正则项与光谱约束，结合大气散射理论防止远距离区域带宽与噪声放大，并通过卷积核生成网络实现深度到滤波器的连续映射。

Result: 在KITTI等五个基准集上进行大量实验，在2倍和4倍超分任务上分别取得36.89/0.9516和30.54/0.8721的PSNR/SSIM成绩，比当前方法分别提高0.44dB和0.36dB，表现出色。

Conclusion: 该方法首次从理论层面建立了距离自适应的超分框架，并在深度变化复杂的实际场景中显著提升了重建性能，同时兼具传统任务的竞争性表现。

Abstract: Single image super-resolution traditionally assumes spatially-invariant
degradation models, yet real-world imaging systems exhibit complex
distance-dependent effects including atmospheric scattering, depth-of-field
variations, and perspective distortions. This fundamental limitation
necessitates spatially-adaptive reconstruction strategies that explicitly
incorporate geometric scene understanding for optimal performance. We propose a
rigorous variational framework that characterizes super-resolution as a
spatially-varying inverse problem, formulating the degradation operator as a
pseudodifferential operator with distance-dependent spectral characteristics
that enable theoretical analysis of reconstruction limits across depth ranges.
Our neural architecture implements discrete gradient flow dynamics through
cascaded residual blocks with depth-conditional convolution kernels, ensuring
convergence to stationary points of the theoretical energy functional while
incorporating learned distance-adaptive regularization terms that dynamically
adjust smoothness constraints based on local geometric structure. Spectral
constraints derived from atmospheric scattering theory prevent bandwidth
violations and noise amplification in far-field regions, while adaptive kernel
generation networks learn continuous mappings from depth to reconstruction
filters. Comprehensive evaluation across five benchmark datasets demonstrates
state-of-the-art performance, achieving 36.89/0.9516 and 30.54/0.8721 PSNR/SSIM
at 2 and 4 scales on KITTI outdoor scenes, outperforming existing methods by
0.44dB and 0.36dB respectively. This work establishes the first
theoretically-grounded distance-adaptive super-resolution framework and
demonstrates significant improvements on depth-variant scenarios while
maintaining competitive performance across traditional benchmarks.

</details>


### [48] [InterAct: A Large-Scale Dataset of Dynamic, Expressive and Interactive Activities between Two People in Daily Scenarios](https://arxiv.org/abs/2509.05747)
*Leo Ho,Yinghao Huang,Dafei Qin,Mingyi Shi,Wangpok Tse,Wei Liu,Junichi Yamagishi,Taku Komura*

Main category: cs.CV

TL;DR: 本文提出了InterAct数据集，专注于捕捉两人在日常场景下动态、语义一致的互动行为，并展示了基于扩散模型的行为生成方法。


<details>
  <summary>Details</summary>
Motivation: 以往的工作多关注单人行为或双人非动态、位置不变的互动，缺乏对真实场景下长时间、空间变化大和具有目标导向性的双人互动建模。

Method: 1. 构建了包含241组双人动作序列的多模态数据集InterAct，涵盖音频、全身动作和面部表情，设定多样任务与情绪标签。2. 方法上，通过分层扩散模型从语音输入中生成两人的肢体和面部表情动作，并设计了精细调优机制提升唇动同步的准确性。

Result: InterAct数据集显著扩展了双人真实互动场景的多样性和复杂性。所提出的扩散模型方法能有效从语音预测出具有长时、目标驱动和语义一致的互动动作与表情，同时唇动精度提升明显。

Conclusion: 通过InterAct数据集和基于扩散模型的方法，推动了双人互动行为建模的研究，并为后续工作提供了公开的数据和代码资源。

Abstract: We address the problem of accurate capture of interactive behaviors between
two people in daily scenarios. Most previous works either only consider one
person or solely focus on conversational gestures of two people, assuming the
body orientation and/or position of each actor are constant or barely change
over each interaction. In contrast, we propose to simultaneously model two
people's activities, and target objective-driven, dynamic, and semantically
consistent interactions which often span longer duration and cover bigger
space. To this end, we capture a new multi-modal dataset dubbed InterAct, which
is composed of 241 motion sequences where two people perform a realistic and
coherent scenario for one minute or longer over a complete interaction. For
each sequence, two actors are assigned different roles and emotion labels, and
collaborate to finish one task or conduct a common interaction activity. The
audios, body motions, and facial expressions of both persons are captured.
InterAct contains diverse and complex motions of individuals and interesting
and relatively long-term interaction patterns barely seen before. We also
demonstrate a simple yet effective diffusion-based method that estimates
interactive face expressions and body motions of two people from speech inputs.
Our method regresses the body motions in a hierarchical manner, and we also
propose a novel fine-tuning mechanism to improve the lip accuracy of facial
expressions. To facilitate further research, the data and code is made
available at https://hku-cg.github.io/interact/ .

</details>


### [49] [Unleashing Hierarchical Reasoning: An LLM-Driven Framework for Training-Free Referring Video Object Segmentation](https://arxiv.org/abs/2509.05751)
*Bingrui Zhao,Lin Yuanbo Wu,Xiangtian Fan,Deyin Liu,Lu Zhang,Ruyi He,Jialie Shen,Ximing Li*

Main category: cs.CV

TL;DR: 本文提出了一种新的无训练Referring Video Object Segmentation（RVOS）方法PARSE-VOS，通过大型语言模型支持，实现跨文本与视频的分层、由粗到细的推理，并在主流数据集上取得了最佳表现。


<details>
  <summary>Details</summary>
Motivation: 现有RVOS方法在将语言描述与视频动态目标对齐时，尤其是面对相似外观、动作和姿态不一致的物体，存在视觉-语言融合能力不足，处理复杂描述时效果有限。需要更强的推理与对齐机制。

Method: 提出PARSE-VOS框架：1）利用LLM解析自然语言查询为结构化语义指令；2）时空定位模块在语义指导下生成所有目标物体候选轨迹；3）分层识别模块通过两阶段推理（先用LLM做粗粒度动作推理筛选候选，再根据需要引入精细姿态验证），确定最终目标并输出分割掩码。整个流程无需训练。

Result: PARSE-VOS在Ref-YouTube-VOS、Ref-DAVIS17和MeViS三个重要基准数据集上实现了最新最优的表现，超越了现有方法。

Conclusion: 利用LLM实现分层推理与结构化语义引导，不仅增强了语言与视频动态内容的对齐，提升了分割精度，还克服了以往方法对复杂描述适应性差的难题，推动了RVOS领域前沿。

Abstract: Referring Video Object Segmentation (RVOS) aims to segment an object of
interest throughout a video based on a language description. The prominent
challenge lies in aligning static text with dynamic visual content,
particularly when objects exhibiting similar appearances with inconsistent
motion and poses. However, current methods often rely on a holistic
visual-language fusion that struggles with complex, compositional descriptions.
In this paper, we propose \textbf{PARSE-VOS}, a novel, training-free framework
powered by Large Language Models (LLMs), for a hierarchical, coarse-to-fine
reasoning across text and video domains. Our approach begins by parsing the
natural language query into structured semantic commands. Next, we introduce a
spatio-temporal grounding module that generates all candidate trajectories for
all potential target objects, guided by the parsed semantics. Finally, a
hierarchical identification module select the correct target through a
two-stage reasoning process: it first performs coarse-grained motion reasoning
with an LLM to narrow down candidates; if ambiguity remains, a fine-grained
pose verification stage is conditionally triggered to disambiguate. The final
output is an accurate segmentation mask for the target object.
\textbf{PARSE-VOS} achieved state-of-the-art performance on three major
benchmarks: Ref-YouTube-VOS, Ref-DAVIS17, and MeViS.

</details>


### [50] [PictOBI-20k: Unveiling Large Multimodal Models in Visual Decipherment for Pictographic Oracle Bone Characters](https://arxiv.org/abs/2509.05773)
*Zijian Chen,Wenjie Hua,Jinhao Li,Lirong Deng,Fan Du,Tingzhu Chen,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本文提出了PictOBI-20k数据集，用于评估大型多模态模型(LMMs)在甲骨文视觉释读任务上的表现，发现现有LMMs尚未有效利用视觉信息，多受语言先验影响。


<details>
  <summary>Details</summary>
Motivation: 甲骨文是中文最早的书写形式，释读甲骨文有助于理解早期人类社会，但受限于考古发掘的偶然性及铭文数据有限，现有自动化释读方法进展缓慢。

Method: 作者提出并构建了PictOBI-20k数据集，包含2万组甲骨文字和实物图片，形成1.5万道多选题，还进行人工主观标注以分析人类和LMMs在视觉推理时的参照一致性。采用该数据集对多种通用大模型进行了测试分析。

Result: 实验表明当前LMMs具备一定的甲骨文视觉释读能力，但主要依赖语言推理，尚未实现充分的视觉信息利用。

Conclusion: PictOBI-20k数据集为甲骨文视觉解读任务提供了评测工具，有望促进未来多模态模型在甲骨文方向的视觉注意力优化。

Abstract: Deciphering oracle bone characters (OBCs), the oldest attested form of
written Chinese, has remained the ultimate, unwavering goal of scholars,
offering an irreplaceable key to understanding humanity's early modes of
production. Current decipherment methodologies of OBC are primarily constrained
by the sporadic nature of archaeological excavations and the limited corpus of
inscriptions. With the powerful visual perception capability of large
multimodal models (LMMs), the potential of using LMMs for visually deciphering
OBCs has increased. In this paper, we introduce PictOBI-20k, a dataset designed
to evaluate LMMs on the visual decipherment tasks of pictographic OBCs. It
includes 20k meticulously collected OBC and real object images, forming over
15k multi-choice questions. We also conduct subjective annotations to
investigate the consistency of the reference point between humans and LMMs in
visual reasoning. Experiments indicate that general LMMs possess preliminary
visual decipherment skills, and LMMs are not effectively using visual
information, while most of the time they are limited by language priors. We
hope that our dataset can facilitate the evaluation and optimization of visual
attention in future OBC-oriented LMMs. The code and dataset will be available
at https://github.com/OBI-Future/PictOBI-20k.

</details>


### [51] [Posterior shape models revisited: Improving 3D reconstructions from partial data using target specific models](https://arxiv.org/abs/2509.05776)
*Jonathan Aellen,Florian Burkhardt,Thomas Vetter,Marcel Lüthi*

Main category: cs.CV

TL;DR: 本文提出了一种高效的姿态对齐方法，可以在无需原始训练数据的情况下，将已有的点分布模型（PDM）调整到与目标部分形状的一致姿态，从而大幅提升部分医学形状重建的精度。


<details>
  <summary>Details</summary>
Motivation: 在使用点分布模型进行医学图像部分形状重建时，训练数据和目标形状的姿态（位置和朝向）不一致，容易导致重建结果有偏差，尤其是在观测到的形状片段较小时，这个问题尤为严重。现有研究很少关注训练数据和目标姿态对齐的重要性。

Method: 作者证明了姿态对齐对于部分形状重建的影响，并提出了一种高效的模型调整方法。这种方法能够在不访问原始训练数据的前提下，通过一个简单的预处理过程，将已有的线性模型对齐到目标形状，提升了形状重建的准确性和方差预测性能。该方法对于平移操作能够精确恢复对齐模型，对于小角度旋转有良好的近似效果。

Result: 所提方法能够准确地进行姿态对齐，在保证线性模型计算效率的同时，显著提高了部分形状重建的准确率和预测方差表现，特别是在面对姿态存在差异的数据时。

Conclusion: 本文方法允许现有的点分布模型快速适配到新的目标，无需重新训练或访问原始数据，适用于各种重建流程，使其更加灵活、广泛和易于应用。

Abstract: In medical imaging, point distribution models are often used to reconstruct
and complete partial shapes using a statistical model of the full shape. A
commonly overlooked, but crucial factor in this reconstruction process, is the
pose of the training data relative to the partial target shape. A difference in
pose alignment of the training and target shape leads to biased solutions,
particularly when observing small parts of a shape. In this paper, we
demonstrate the importance of pose alignment for partial shape reconstructions
and propose an efficient method to adjust an existing model to a specific
target. Our method preserves the computational efficiency of linear models
while significantly improving reconstruction accuracy and predicted variance.
It exactly recovers the intended aligned model for translations, and provides a
good approximation for small rotations, all without access to the original
training data. Hence, existing shape models in reconstruction pipelines can be
adapted by a simple preprocessing step, making our approach widely applicable
in plug-and-play scenarios.

</details>


### [52] [Multi-Modal Camera-Based Detection of Vulnerable Road Users](https://arxiv.org/abs/2509.06333)
*Penelope Brown,Julie Stephany Berrio Perez,Mao Shan,Stewart Worrall*

Main category: cs.CV

TL;DR: 本文提出了一种融合RGB和热红外成像的多模态检测框架，并针对微弱光照和不平衡数据下的弱势交通参与者（VRUs）检测进行了优化。通过多数据集训练和多种改进策略，显著提升了罕见类别的检测能力和整体检测性能。


<details>
  <summary>Details</summary>
Motivation: 全球超过一半的交通死亡事故涉及弱势交通参与者（行人、自行车、摩托车驾驶者），而在恶劣环境与数据不均衡条件下，这些群体的检测非常困难。

Method: 采用RGB+热红外双模态成像，结合经过微调的YOLOv8模型，利用KITTI、BDD100K和Teledyne FLIR数据集训练，通过类别重加权与轻度数据增强提升少数类表现，实验优化了输入分辨率与骨干网络冻结策略。

Result: 热红外模型取得了最高的精度；RGB到热红外增强则显著提升了召回率。640像素分辨率以及部分骨干冻结实现了最佳的准确率与效率，类别加权损失提升了罕见VRU检测召回率。

Conclusion: 多模态检测体系显著提升了交通参与者在复杂路口场景下的检测性能，有助于提升VRU的道路安全性，特别是在复杂或极端条件下表现突出。

Abstract: Vulnerable road users (VRUs) such as pedestrians, cyclists, and motorcyclists
represent more than half of global traffic deaths, yet their detection remains
challenging in poor lighting, adverse weather, and unbalanced data sets. This
paper presents a multimodal detection framework that integrates RGB and thermal
infrared imaging with a fine-tuned YOLOv8 model. Training leveraged KITTI,
BDD100K, and Teledyne FLIR datasets, with class re-weighting and light
augmentations to improve minority-class performance and robustness, experiments
show that 640-pixel resolution and partial backbone freezing optimise accuracy
and efficiency, while class-weighted losses enhance recall for rare VRUs.
Results highlight that thermal models achieve the highest precision, and
RGB-to-thermal augmentation boosts recall, demonstrating the potential of
multimodal detection to improve VRU safety at intersections.

</details>


### [53] [3DPillars: Pillar-based two-stage 3D object detection](https://arxiv.org/abs/2509.05780)
*Jongyoun Noh,Junghyup Lee,Hyekang Park,Bumsub Ham*

Main category: cs.CV

TL;DR: 本文提出了一种基于伪图像表示的两阶段3D目标检测新框架，提升了检测性能的同时保持高效率。


<details>
  <summary>Details</summary>
Motivation: PointPillars虽然高效，但因伪图像表示无法精确保留3D结构、难以扩展为两阶段检测，导致其性能落后于最新的3D检测方法。

Method: 1) 提出新CNN架构3DPillars，用2D卷积对伪图像堆叠学习3D体素特征，避免使用3D卷积。2) 设计RoI head结合稀疏场景上下文特征模块，汇聚3DPillars多尺度特征，使两阶段检测成为可能并利用场景信息优化提案。

Result: 在KITTI和Waymo Open数据集上，提出的方法在速度和精度上取得了良好平衡，验证了其有效性和高效性。

Conclusion: 该框架弥补了PointPillars在3D结构表达和两阶段检测方面的不足，缩小了其与最先进方法之间的性能差距，同时保持了推理效率。

Abstract: PointPillars is the fastest 3D object detector that exploits pseudo image
representations to encode features for 3D objects in a scene. Albeit efficient,
PointPillars is typically outperformed by state-of-the-art 3D detection methods
due to the following limitations: 1) The pseudo image representations fail to
preserve precise 3D structures, and 2) they make it difficult to adopt a
two-stage detection pipeline using 3D object proposals that typically shows
better performance than a single-stage approach. We introduce in this paper the
first two-stage 3D detection framework exploiting pseudo image representations,
narrowing the performance gaps between PointPillars and state-of-the-art
methods, while retaining its efficiency. Our framework consists of two novel
components that overcome the aforementioned limitations of PointPillars: First,
we introduce a new CNN architecture, dubbed 3DPillars, that enables learning 3D
voxel-based features from the pseudo image representation efficiently using 2D
convolutions. The basic idea behind 3DPillars is that 3D features from voxels
can be viewed as a stack of pseudo images. To implement this idea, we propose a
separable voxel feature module that extracts voxel-based features without using
3D convolutions. Second, we introduce an RoI head with a sparse scene context
feature module that aggregates multi-scale features from 3DPillars to obtain a
sparse scene feature. This enables adopting a two-stage pipeline effectively,
and fully leveraging contextual information of a scene to refine 3D object
proposals. Experimental results on the KITTI and Waymo Open datasets
demonstrate the effectiveness and efficiency of our approach, achieving a good
compromise in terms of speed and accuracy.

</details>


### [54] [Investigating Location-Regularised Self-Supervised Feature Learning for Seafloor Visual Imagery](https://arxiv.org/abs/2509.06660)
*Cailei Liang,Adrian Bodenmann,Emma J Curtis,Samuel Simmons,Kazunori Nagano,Stan Brown,Adam Riese,Blair Thornton*

Main category: cs.CV

TL;DR: 本研究评估了基于地理位置信息的正则化在六种主流自监督特征学习(SSL)框架中的作用，发现地理位置信息普遍提升了海底影像分类的准确性，尤其在低维潜空间表达中提升更为明显。


<details>
  <summary>Details</summary>
Motivation: 当前机器人收集的海底影像数据量巨大，高效自动解读这些数据对于海洋监测和探索具有重要意义。虽然已有研究指出结合位置元数据能提升自监督学习效果，但其在不同模型、方法和数据集中的作用尚未系统评估。

Method: 作者在三套海底影像数据集上，对六种代表性SSL方法（涵盖CNN和ViT模型，潜空间维度不同）分别加入或不加入位置正则化（location-regularisation），比较模型在下游分类任务上的表现差异。

Result: 引入地理位置正则化普遍提升了下游分类性能：平均F1提升CNN为4.9±4.0%，ViT为6.3±8.9%。对于CNN，低维潜空间时提升更显著。ViT使用高维潜空间则本身具有很强泛化能力，与最佳位置正则化模型表现持平（F1≈0.795）。

Conclusion: 位置元数据对于提升SSL特征学习显著有效，低维表达时提升尤为明显。而高维ViT模型具有很强的泛化能力，在无位置正则化时也能达到最佳性能。

Abstract: High-throughput interpretation of robotically gathered seafloor visual
imagery can increase the efficiency of marine monitoring and exploration.
Although recent research has suggested that location metadata can enhance
self-supervised feature learning (SSL), its benefits across different SSL
strategies, models and seafloor image datasets are underexplored. This study
evaluates the impact of location-based regularisation on six state-of-the-art
SSL frameworks, which include Convolutional Neural Network (CNN) and Vision
Transformer (ViT) models with varying latent-space dimensionality. Evaluation
across three diverse seafloor image datasets finds that location-regularisation
consistently improves downstream classification performance over standard SSL,
with average F1-score gains of $4.9 \pm 4.0%$ for CNNs and $6.3 \pm 8.9%$ for
ViTs, respectively. While CNNs pretrained on generic datasets benefit from
high-dimensional latent representations, dataset-optimised SSL achieves similar
performance across the high (512) and low (128) dimensional latent
representations. Location-regularised SSL improves CNN performance over
pre-trained models by $2.7 \pm 2.7%$ and $10.1 \pm 9.4%$ for high and
low-dimensional latent representations, respectively. For ViTs,
high-dimensionality benefits both pre-trained and dataset-optimised SSL.
Although location-regularisation improves SSL performance compared to standard
SSL methods, pre-trained ViTs show strong generalisation, matching the
best-performing location-regularised SSL with F1-scores of $0.795 \pm 0.075$
and $0.795 \pm 0.077$, respectively. The findings highlight the value of
location metadata for SSL regularisation, particularly when using
low-dimensional latent representations, and demonstrate strong generalisation
of high-dimensional ViTs for seafloor image analysis.

</details>


### [55] [CRAB: Camera-Radar Fusion for Reducing Depth Ambiguity in Backward Projection based View Transformation](https://arxiv.org/abs/2509.05785)
*In-Jae Lee,Sihwan Hwang,Youngseok Kim,Wonjune Kim,Sanmin Kim,Dongsuk Kum*

Main category: cs.CV

TL;DR: 本文提出了一种新的基于摄像头和毫米波雷达融合的三维目标检测和分割方法CRAB，有效解决了深度歧义和BEV特征稀疏等问题，在nuScenes数据集上取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 现有摄像头-雷达融合的BEV三维目标检测方法，要么因为前向投影导致BEV特征稀疏，要么因反向投影忽略了深度歧义，造成虚假检测，限制了性能提升。

Method: 提出CRAB模型，利用雷达数据在反向投影时减少深度歧义，通过融合来自图片的密集但不太可靠的深度信息和来自雷达的稀疏但精准的深度信息。此外，采用了包含雷达上下文的空间交叉注意力机制，提升3D场景理解。

Result: 在nuScenes公开数据集上，CRAB在基于反向投影的摄像头-雷达融合方法中取得了62.4%的NDS和54.0%的mAP，达到了目前最优水平。

Conclusion: CRAB模型通过创新性地结合了雷达和图像数据，显著消除了BEV深度歧义，提升了三维目标检测和分割的准确性，是后续相关领域研究和应用的重要进展。

Abstract: Recently, camera-radar fusion-based 3D object detection methods in bird's eye
view (BEV) have gained attention due to the complementary characteristics and
cost-effectiveness of these sensors. Previous approaches using forward
projection struggle with sparse BEV feature generation, while those employing
backward projection overlook depth ambiguity, leading to false positives. In
this paper, to address the aforementioned limitations, we propose a novel
camera-radar fusion-based 3D object detection and segmentation model named CRAB
(Camera-Radar fusion for reducing depth Ambiguity in Backward projection-based
view transformation), using a backward projection that leverages radar to
mitigate depth ambiguity. During the view transformation, CRAB aggregates
perspective view image context features into BEV queries. It improves depth
distinction among queries along the same ray by combining the dense but
unreliable depth distribution from images with the sparse yet precise depth
information from radar occupancy. We further introduce spatial cross-attention
with a feature map containing radar context information to enhance the
comprehension of the 3D scene. When evaluated on the nuScenes open dataset, our
proposed approach achieves a state-of-the-art performance among backward
projection-based camera-radar fusion methods with 62.4\% NDS and 54.0\% mAP in
3D object detection.

</details>


### [56] [Online Clustering of Seafloor Imagery for Interpretation during Long-Term AUV Operations](https://arxiv.org/abs/2509.06678)
*Cailei Liang,Adrian Bodenmann,Sam Fenton,Blair Thornton*

Main category: cs.CV

TL;DR: 本文提出了一种在线聚类框架（OCF），能在无需监督的情况下实时解释海底图像数据流，有效提升无人水下航行器实时任务适应性与通信效率。


<details>
  <summary>Details</summary>
Motivation: 随着长航时、驻底式无人水下航行器（AUVs）能力提升，海底图像解释需面对实时性和自适应性挑战，而现有离线分析方法依赖完整数据集和人工标注，难以满足实际需求。

Method: 作者开发了OCF算法，能在线、无监督地从连续海底图像中提取代表样本，支持聚类自适应合并和分裂，且无需重处理历史全量数据，具备可扩展性和自一致性。

Result: 该方法在三个不同海底图像数据集上测试，平均F1得分达0.68，且不同航线间方差低（3%），优于其他在线聚类方法。同时，随着数据增长，其计算资源消耗保持低且有界。

Conclusion: OCF方法具备优异的实时性和自适应聚类能力，有助于无人水下持续自主探测中的数据总结和任务路径智能规划。

Abstract: As long-endurance and seafloor-resident AUVs become more capable, there is an
increasing need for extended, real-time interpretation of seafloor imagery to
enable adaptive missions and optimise communication efficiency. Although
offline image analysis methods are well established, they rely on access to
complete datasets and human-labelled examples to manage the strong influence of
environmental and operational conditions on seafloor image
appearance-requirements that cannot be met in real-time settings. To address
this, we introduce an online clustering framework (OCF) capable of interpreting
seafloor imagery without supervision, which is designed to operate in real-time
on continuous data streams in a scalable, adaptive, and self-consistent manner.
The method enables the efficient review and consolidation of common patterns
across the entire data history in constant time by identifying and maintaining
a set of representative samples that capture the evolving feature distribution,
supporting dynamic cluster merging and splitting without reprocessing the full
image history. We evaluate the framework on three diverse seafloor image
datasets, analysing the impact of different representative sampling strategies
on both clustering accuracy and computational cost. The OCF achieves the
highest average F1 score of 0.68 across the three datasets among all
comparative online clustering approaches, with a standard deviation of 3%
across three distinct survey trajectories, demonstrating its superior
clustering capability and robustness to trajectory variation. In addition, it
maintains consistently lower and bounded computational time as the data volume
increases. These properties are beneficial for generating survey data summaries
and supporting informative path planning in long-term, persistent autonomous
marine exploration.

</details>


### [57] [Dual-Mode Deep Anomaly Detection for Medical Manufacturing: Structural Similarity and Feature Distance](https://arxiv.org/abs/2509.05796)
*Julio Zanon Diaz,Georgios Siogkas,Peter Corcoran*

Main category: cs.CV

TL;DR: 本文提出两种基于注意力机制的自动编码器架构，用于在医疗器械制造中的深度异常检测，分别通过结构相似性评分和特征距离评分，有效解决小样本、高分辨率和高监管要求下的缺陷检测问题，并在实际测试中超过对比基线方法，具备实时和后期检测双重能力。


<details>
  <summary>Details</summary>
Motivation: 在医疗器械制造中，视觉自动检测由于样本小且不平衡、图像高分辨、监管严格，导致传统检测方法难以满足高效、准确与合规等综合需求，急需针对性更强的方法。

Method: 提出两种异常检测架构：(1) 利用结构相似性（4-MS-SSIM）作为异常评分的注意力引导型自动编码器，兼顾轻量和高准确率，用于实时在线检测；(2) 基于特征马氏距离评分的降维嵌入空间方法，强调对分布偏移的灵敏度，强化监督监测、长期合规。两者分别通过无监督和有监督阈值下进行评估。

Result: 第一种方法在“-Surface Seal Image-Test”子集只用10%缺陷样本下，无监督检测准确率0.903，有监督达0.931；第二种方法在有监督下准确率0.722。实验表明新方法均超越重实现的基线，更适合高监管制造场景。

Conclusion: 两种方法互补：前者适合生产线实时缺陷检测，后者适合规模化后期检测及合规监控，为高风险AI系统的深度异常检测在受监管制造领域的落地应用提供了准确、高效且合规的实践路径。

Abstract: Automating visual inspection in medical device manufacturing remains
challenging due to small and imbalanced datasets, high-resolution imagery, and
stringent regulatory requirements. This work proposes two attention-guided
autoencoder architectures for deep anomaly detection designed to address these
constraints. The first employs a structural similarity-based anomaly score
(4-MS-SSIM), offering lightweight and accurate real-time defect detection,
yielding ACC 0.903 (unsupervised thresholding) and 0.931 (supervised
thresholding) on the - Surface Seal Image - Test split with only 10% of
defective samples. The second applies a feature-distance approach using
Mahalanobis scoring on reduced latent features, providing high sensitivity to
distributional shifts for supervisory monitoring, achieving ACC 0.722 with
supervised thresholding. Together, these methods deliver complementary
capabilities: the first supports reliable inline inspection, while the second
enables scalable post-production surveillance and regulatory compliance
monitoring. Experimental results demonstrate that both approaches surpass
re-implemented baselines and provide a practical pathway for deploying deep
anomaly detection in regulated manufacturing environments, aligning accuracy,
efficiency, and the regulatory obligations defined for high-risk AI systems
under the EU AI Act.

</details>


### [58] [Event Spectroscopy: Event-based Multispectral and Depth Sensing using Structured Light](https://arxiv.org/abs/2509.06741)
*Christian Geckeler,Niklas Neugebauer,Manasi Muglikar,Davide Scaramuzza,Stefano Mintchev*

Main category: cs.CV

TL;DR: 论文提出了一种新型用于无人机的事件光谱系统，可实现高分辨率、低延迟的深度与多光谱信息同步采集，显著提升森林环境下的无人机感知与数据收集效果。


<details>
  <summary>Details</summary>
Motivation: 传统多光谱和RGB传感器在森林环境下存在深度分辨率低、受环境光影响大、响应迟缓等问题，阻碍了无人机在复杂林区的安全导航和精准数据采集。亟需一种能够快速、准确、受光照影响小的新型传感方法。

Method: 本系统通过结构光实现深度重建，并通过调制投射结构光的波长采集650-850nm范围内受控波段的光谱信息。与市售多光谱和深度传感器对比，系统综合了一颗传感器实现多功能同步测量，并研制了便携版系统采集现实雨林数据，进行彩色图像重建与材质区分实验。

Result: 系统在深度重建方面，RMSE相较商用设备提升高达60%；在光谱信息准确性上与商用设备基本持平。实际雨林采集实验表明，利用同步获得的深度与光谱信息进行叶片与枝干区分，准确率比单纯颜色方法提升超30%。

Conclusion: 所提出系统在实验室与实际雨林环境均表现良好，为今后轻便集成、鲁棒性强的无人机森林感知与数据采集奠定了基础。

Abstract: Uncrewed aerial vehicles (UAVs) are increasingly deployed in forest
environments for tasks such as environmental monitoring and search and rescue,
which require safe navigation through dense foliage and precise data
collection. Traditional sensing approaches, including passive multispectral and
RGB imaging, suffer from latency, poor depth resolution, and strong dependence
on ambient light - especially under forest canopies. In this work, we present a
novel event spectroscopy system that simultaneously enables high-resolution,
low-latency depth reconstruction and multispectral imaging using a single
sensor. Depth is reconstructed using structured light, and by modulating the
wavelength of the projected structured light, our system captures spectral
information in controlled bands between 650 nm and 850 nm. We demonstrate up to
$60\%$ improvement in RMSE over commercial depth sensors and validate the
spectral accuracy against a reference spectrometer and commercial multispectral
cameras, demonstrating comparable performance. A portable version limited to
RGB (3 wavelengths) is used to collect real-world depth and spectral data from
a Masoala Rainforest. We demonstrate the use of this prototype for color image
reconstruction and material differentiation between leaves and branches using
spectral and depth data. Our results show that adding depth (available at no
extra effort with our setup) to material differentiation improves the accuracy
by over $30\%$ compared to color-only method. Our system, tested in both lab
and real-world rainforest environments, shows strong performance in depth
estimation, RGB reconstruction, and material differentiation - paving the way
for lightweight, integrated, and robust UAV perception and data collection in
complex natural environments.

</details>


### [59] [A Probabilistic Segment Anything Model for Ambiguity-Aware Medical Image Segmentation](https://arxiv.org/abs/2509.05809)
*Tyler Ward,Abdullah Imran*

Main category: cs.CV

TL;DR: 本文提出了一种名为Probabilistic SAM的概率性分割模型，能够针对每个提示条件下生成多样且合理的分割结果，适合应对医学图像中标注不确定和专家分歧问题。


<details>
  <summary>Details</summary>
Motivation: 现有的可提示分割模型（如SAM）在输入同一提示下只能输出单一分割结果，无法反映多样化、带有不确定性的分割需求，尤其在医学图像领域，存在专家间标注差异和固有的不确定性。为此，需开发能够输出多样化分割的概率模型以更好地满足实际需求。

Method: 本文提出Probabilistic SAM，通过在SAM框架中引入潜变量空间，并采用变分训练目标，使模型能够学习和输出与输入图像及提示条件相关的分割分布。具体地，模型架构中集成了先验和后验网络，使潜变量编码可在推理阶段调制提示嵌入，实现高效采样与不确定性感知分割输出。

Result: 在LIDC-IDRI公共肺结节数据集上的实验表明，Probabilistic SAM能生成贴合专业分歧的多样化分割结果，并在不确定性感知评估指标上优于现有概率分割基线方法。

Conclusion: Probabilistic SAM能有效提升分割多样性和表达不确定性，特别适用于面临标注不确定和专家分歧的医学影像等实际应用场景，相比现有方法在不确定性建模方面具有明显优势。

Abstract: Recent advances in promptable segmentation, such as the Segment Anything
Model (SAM), have enabled flexible, high-quality mask generation across a wide
range of visual domains. However, SAM and similar models remain fundamentally
deterministic, producing a single segmentation per object per prompt, and fail
to capture the inherent ambiguity present in many real-world tasks. This
limitation is particularly troublesome in medical imaging, where multiple
plausible segmentations may exist due to annotation uncertainty or inter-expert
variability. In this paper, we introduce Probabilistic SAM, a probabilistic
extension of SAM that models a distribution over segmentations conditioned on
both the input image and prompt. By incorporating a latent variable space and
training with a variational objective, our model learns to generate diverse and
plausible segmentation masks reflecting the variability in human annotations.
The architecture integrates a prior and posterior network into the SAM
framework, allowing latent codes to modulate the prompt embeddings during
inference. The latent space allows for efficient sampling during inference,
enabling uncertainty-aware outputs with minimal overhead. We evaluate
Probabilistic SAM on the public LIDC-IDRI lung nodule dataset and demonstrate
its ability to produce diverse outputs that align with expert disagreement,
outperforming existing probabilistic baselines on uncertainty-aware metrics.
Our code is available at: https://github.com/tbwa233/Probabilistic-SAM/.

</details>


### [60] [Near Real-Time Dust Aerosol Detection with 3D Convolutional Neural Networks on MODIS Data](https://arxiv.org/abs/2509.05887)
*Caleb Gates,Patrick Moorhead,Jayden Ferguson,Omar Darwish,Conner Stallman,Pablo Rivas,Paapa Quansah*

Main category: cs.CV

TL;DR: 本文提出了一种基于3D卷积神经网络的近实时卫星沙尘暴检测系统，能够在像素级别准确识别沙尘，并在全球范围内实现快速报警。


<details>
  <summary>Details</summary>
Motivation: 沙尘暴不仅危害人类健康，还会降低能见度。及时、准确地从卫星图像中检测沙尘暴，对于监测和防护至关重要。

Method: 采用3D卷积神经网络，利用NASA Terra与Aqua卫星（MODIS）的36个波段及分割热红外波段数据进行训练。通过简单归一化和局部填充处理缺失数据，并提升了模型训练和推理速度。

Result: 在17幅独立MODIS场景测试中，模型准确率约为0.92，均方误差0.014。结果显示沙尘暴主干区检测一致性强，边缘部分有一定漏检。

Conclusion: 联合波段和空间信息的学习策略能够实现全球范围内的沙尘暴快速、准确检测。未来若引入更大输入窗口或基于注意力机制的模型，或可进一步提升边界检测效果。

Abstract: Dust storms harm health and reduce visibility; quick detection from
satellites is needed. We present a near real-time system that flags dust at the
pixel level using multi-band images from NASA's Terra and Aqua (MODIS). A 3D
convolutional network learns patterns across all 36 bands, plus split thermal
bands, to separate dust from clouds and surface features. Simple normalization
and local filling handle missing data. An improved version raises training
speed by 21x and supports fast processing of full scenes. On 17 independent
MODIS scenes, the model reaches about 0.92 accuracy with a mean squared error
of 0.014. Maps show strong agreement in plume cores, with most misses along
edges. These results show that joint band-and-space learning can provide timely
dust alerts at global scale; using wider input windows or attention-based
models may further sharpen edges.

</details>


### [61] [Challenges in Deep Learning-Based Small Organ Segmentation: A Benchmarking Perspective for Medical Research with Limited Datasets](https://arxiv.org/abs/2509.05892)
*Phongsakon Mark Konrad,Andrei-Alexandru Popa,Yaser Sabzehmeidani,Liang Zhong,Elisa A. Liehn,Serkan Ayvaz*

Main category: cs.CV

TL;DR: 本研究系统评估了多种主流深度学习分割模型在心血管组织切片少量数据集上的表现，发现模型排名受数据划分影响大，并不稳定，质疑了传统基准测试结果的临床意义。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在心血管组织学分割任务中的应用受到标注数据稀缺的显著限制。准确分割对心血管疾病研究及诊断至关重要，因此有必要评估和比较当前先进模型在小样本条件下的实际效果。

Method: 选择了包括U-Net、DeepLabV3+（卷积网络）、SegFormer（视觉Transformer）、SAM系列（基础模型）等多种分割模型，在有限心血管组织切片图像数据集上进行训练和评估。采用贝叶斯搜索进行超参数优化，尽量挖掘模型潜力，并系统分析模型在不同数据划分下的表现稳定性。

Result: 发现所有模型的表现（如准确率等指标）对数据划分非常敏感，即使做了充分的超参数调优，各模型之间的性能差别往往由统计噪声主导，而非真实模型能力差异。

Conclusion: 在小样本医学影像分割任务中，传统的模型排名和基准测试可能无法真实反映模型的临床应用价值。当前的评测指标和流程在数据稀缺条件下存在可靠性和有效性问题，需要重思相关科研和实际应用标准。

Abstract: Accurate segmentation of carotid artery structures in histopathological
images is vital for advancing cardiovascular disease research and diagnosis.
However, deep learning model development in this domain is constrained by the
scarcity of annotated cardiovascular histopathological data. This study
investigates a systematic evaluation of state-of-the-art deep learning
segmentation models, including convolutional neural networks (U-Net,
DeepLabV3+), a Vision Transformer (SegFormer), and recent foundation models
(SAM, MedSAM, MedSAM+UNet), on a limited dataset of cardiovascular histology
images. Despite employing an extensive hyperparameter optimization strategy
with Bayesian search, our findings reveal that model performance is highly
sensitive to data splits, with minor differences driven more by statistical
noise than by true algorithmic superiority. This instability exposes the
limitations of standard benchmarking practices in low-data clinical settings
and challenges the assumption that performance rankings reflect meaningful
clinical utility.

</details>


### [62] [BTCChat: Advancing Remote Sensing Bi-temporal Change Captioning with Multimodal Large Language Model](https://arxiv.org/abs/2509.05895)
*Yujie Li,Wenjia Xu,Yuanben Zhang,Zhiwei Wei,Mugen Peng*

Main category: cs.CV

TL;DR: 论文提出了BTCChat，一种用于双时相卫星影像变化分析的多模态大模型，实现了在城市监测、灾害评估等场景下的变化描述和问答任务。


<details>
  <summary>Details</summary>
Motivation: 目前多模态大模型通过简单拼接进行双时相影像对处理，难以充分刻画时间变化与空间语义差异，限制了理解和应用的效果。

Method: 本文设计了Change Extraction模块以捕捉影像对中的时序特征与空间语义变化，并提出Prompt Augmentation机制，通过引入上下文线索提升模型对细节的关注和表现。模型BTCChat既能进行变化描述，也支持单幅图像理解。

Result: 实验表明，BTCChat在变化描述与视觉问答任务中都取得了最优的性能。

Conclusion: BTCChat有效提升了双时相影像多模态理解的能力，在城市变化监测与灾害评估等实际任务中具有重要应用价值。

Abstract: Bi-temporal satellite imagery supports critical applications such as urban
development monitoring and disaster assessment. Although powerful multimodal
large language models (MLLMs) have been applied in bi-temporal change analysis,
previous methods process image pairs through direct concatenation, inadequately
modeling temporal correlations and spatial semantic changes. This deficiency
hampers visual-semantic alignment in change understanding, thereby constraining
the overall effectiveness of current approaches. To address this gap, we
propose BTCChat, a multi-temporal MLLM with advanced bi-temporal change
understanding capability. BTCChat supports bi-temporal change captioning and
retains single-image interpretation capability. To better capture temporal
features and spatial semantic changes in image pairs, we design a Change
Extraction module. Moreover, to enhance the model's attention to spatial
details, we introduce a Prompt Augmentation mechanism, which incorporates
contextual clues into the prompt to enhance model performance. Experimental
results demonstrate that BTCChat achieves state-of-the-art performance on
change captioning and visual question answering tasks.

</details>


### [63] [A Fine-Grained Attention and Geometric Correspondence Model for Musculoskeletal Risk Classification in Athletes Using Multimodal Visual and Skeletal Features](https://arxiv.org/abs/2509.05913)
*Md. Abdur Rahman,Mohaimenul Azam Khan Raiaan,Tamanna Shermin,Md Rafiqul Islam,Mukhtar Hussain,Sami Azam*

Main category: cs.CV

TL;DR: 本文提出了一种新型多模态深度学习框架ViSK-GAT（Visual-Skeletal Geometric Attention Transformer），通过结合视觉和骨骼坐标特征，对运动员肌肉骨骼风险进行分类，并取得了优异的实验结果，显著超过目前主流方法。


<details>
  <summary>Details</summary>
Motivation: 目前大多数肌肉骨骼风险评估方法依赖单一数据源，仅适用于受控环境，难以在复杂场景中准确评估风险。因此，亟需一种能多模态融合且更鲁棒的风险评估方法。

Method: 构建了视觉数据和骨骼坐标融合的定制数据集，并提出ViSK-GAT框架：通过残差块和轻量级Transformer联合学习空间与时序依赖，设计了精细化注意力模块（FGAM）实现模态间的交互与特征优化，以及几何对应模块（MGCM）对齐不同模态特征。每个样本依据Rapid Entire Body Assessment分为八类风险等级。

Result: 在验证集和测试集上，ViSK-GAT分别取得了93.55%和93.89%的准确率，精度为93.86%，F1分数为93.85%，Kappa系数和Matthews相关系数均为93%，回归误差（RMSE、MAE）亦极低，对比9种主流迁移学习骨干网络均有明显提升。

Conclusion: ViSK-GAT显著提升了肌肉骨骼风险的多模态自动评估能力，有望推动人工智能在运动健康干预领域的应用，实现运动员早期风险发现与预防。

Abstract: Musculoskeletal disorders pose significant risks to athletes, and assessing
risk early is important for prevention. However, most existing methods are
designed for controlled settings and fail to reliably assess risk in complex
environments due to their reliance on a single type of data. This research
proposes ViSK-GAT (Visual-Skeletal Geometric Attention Transformer), a novel
multimodal deep learning framework designed to classify musculoskeletal risk
using visual and skeletal coordinate-based features. In addition, a custom
multimodal dataset is constructed by combining visual data and skeletal
coordinates for risk assessment. Each sample is labeled into eight risk
categories based on the Rapid Entire Body Assessment system. ViSK-GAT combines
a Residual Block with a Lightweight Transformer Block to learn spatial and
temporal dependencies jointly. It incorporates two novel modules: the
Fine-Grained Attention Module (FGAM), which enables precise inter-modal feature
refinement through cross-attention between visual and skeletal inputs, and the
Multimodal Geometric Correspondence Module (MGCM), which enhances cross-modal
coherence by aligning image features with coordinate-based representations.
ViSK-GAT achieved strong performance with validation and test accuracies of
93.55\% and 93.89\%, respectively; a precision of 93.86\%; an F1 score of
93.85\%; and Cohen's Kappa and Matthews Correlation Coefficient of 93\%. The
regression results also indicated a low Root Mean Square Error of the predicted
probability distribution of 0.1205 and a corresponding Mean Absolute Error of
0.0156. Compared to nine popular transfer learning backbones, ViSK-GAT
consistently outperformed previous methods. The ViSK-GAT model advances
artificial intelligence implementation and application, transforming
musculoskeletal risk classification and enabling impactful early interventions
in sports.

</details>


### [64] [Compression Beyond Pixels: Semantic Compression with Multimodal Foundation Models](https://arxiv.org/abs/2509.05925)
*Ruiqi Shen,Haotian Wu,Wenjing Zhang,Jiangjing Hu,Deniz Gunduz*

Main category: cs.CV

TL;DR: 本文提出了一种基于CLIP模型的语义型图像压缩方法，既极大地减少了所需比特率，又显著保持了图像的语义信息，尤其适用于多任务与分布外数据。


<details>
  <summary>Details</summary>
Motivation: 传统深度压缩方法虽然像素级重建效果好，但无法满足当前对语义信息保留和应对多样数据分布的需求。新兴应用需要比像素重建更重视语义表达的压缩方式。

Method: 该方法利用CLIP跨模态表征能力，将图像首先提取为CLIP特征嵌入向量，再将这些语义特征编码为极少比特，并不直接还原像素图，而是关注下游多任务上的语义信息传递效果。

Result: 实验表明，该方法在各类基准数据集上仅需大约2-3*10^(-3) bits/pixel的极低比特率，即常规方法的5%，却能保持相当的语义信息完整性，并且对任务分布变更具有零样本鲁棒性。

Conclusion: 该方法为语义优先的图像压缩提供了全新范式，兼具高效性和跨任务、跨分布的鲁棒性，为相关应用带来了切实改进。

Abstract: Recent deep learning-based methods for lossy image compression achieve
competitive rate-distortion performance through extensive end-to-end training
and advanced architectures. However, emerging applications increasingly
prioritize semantic preservation over pixel-level reconstruction and demand
robust performance across diverse data distributions and downstream tasks.
These challenges call for advanced semantic compression paradigms. Motivated by
the zero-shot and representational capabilities of multimodal foundation
models, we propose a novel semantic compression method based on the contrastive
language-image pretraining (CLIP) model. Rather than compressing images for
reconstruction, we propose compressing the CLIP feature embeddings into minimal
bits while preserving semantic information across different tasks. Experiments
show that our method maintains semantic integrity across benchmark datasets,
achieving an average bit rate of approximately 2-3* 10(-3) bits per pixel. This
is less than 5% of the bitrate required by mainstream image compression
approaches for comparable performance. Remarkably, even under extreme
compression, the proposed approach exhibits zero-shot robustness across diverse
data distributions and downstream tasks.

</details>


### [65] [AttriPrompt: Dynamic Prompt Composition Learning for CLIP](https://arxiv.org/abs/2509.05949)
*Qiqi Zhan,Shiwei Li,Qingjie Liu,Yunhong Wang*

Main category: cs.CV

TL;DR: AttriPrompt框架通过融合CLIP视觉编码器的中间层特征，动态检索并融合多样化、语义相关的提示，有效提升跨模态模型的性能，尤其在新类别上的泛化能力显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度文本提示学习方法过度依赖对比学习，忽视特征细节优化，同时对所有类别采用静态提示，缺乏内容自适应能力，限制了性能提升。

Method: 提出AttriPrompt框架：在CLIP的视觉端中间层聚类视觉特征，通过视觉语义相关性动态检索提示并融合到文本编码器各层输入；引入双流对比学习实现细粒度匹配，以及自监督正则防止过拟合。

Result: 在三个基准测试上，AttriPrompt显著超越现有最优方法，base-to-novel场景提升最高达7.37%。

Conclusion: AttriPrompt增强了视觉-文本预训练模型的语义适应性与通用性，在跨领域知识迁移中表现突出，有助于实际场景的应用落地。

Abstract: The evolution of prompt learning methodologies has driven exploration of
deeper prompt designs to enhance model performance. However, current deep text
prompting approaches suffer from two critical limitations: Over-reliance on
constrastive learning objectives that prioritize high-level semantic alignment,
neglecting fine-grained feature optimization; Static prompts across all input
categories, preventing content-aware adaptation. To address these limitations,
we propose AttriPrompt-a novel framework that enhances and refines textual
semantic representations by leveraging the intermediate-layer features of
CLIP's vision encoder. We designed an Attribute Retrieval module that first
clusters visual features from each layer. The aggregated visual features
retrieve semantically similar prompts from a prompt pool, which are then
concatenated to the input of every layer in the text encoder. Leveraging
hierarchical visual information embedded in prompted text features, we
introduce Dual-stream Contrastive Learning to realize fine-grained alignment.
Furthermore, we introduce a Self-Regularization mechanism by applying explicit
regularization constraints between the prompted and non-prompted text features
to prevent overfitting on limited training data. Extensive experiments across
three benchmarks demonstrate AttriPrompt's superiority over state-of-the-art
methods, achieving up to 7.37\% improvement in the base-to-novel setting. The
observed strength of our method in cross-domain knowledge transfer positions
vision-language pre-trained models as more viable solutions for real-world
implementation.

</details>


### [66] [Coefficients-Preserving Sampling for Reinforcement Learning with Flow Matching](https://arxiv.org/abs/2509.05952)
*Feng Wang,Zihao Yu*

Main category: cs.CV

TL;DR: 本文提出了一种新的采样方法用于提升基于强化学习的Flow Matching图像生成模型的质量和效率。该方法能有效消除传统随机采样引入的噪声伪影，从而提升奖励建模的准确性和优化收敛速度。


<details>
  <summary>Details</summary>
Motivation: 在利用强化学习提升扩散模型（Diffusion）和流映射模型（Flow Matching）图像生成质量时，通常需向原本确定性的框架中引入随机性，比如通过随机微分方程（SDE），但这会导致生成图像中出现明显噪声，阻碍了奖励模型的有效学习。

Method: 提出Coefficients-Preserving Sampling（CPS）方法。该方法借鉴了去噪扩散隐式模型（DDIM）的思想，重新设计了采样过程，消除了传统SDE采样带来的噪声伪影，使采样过程不仅具有随机性且更平滑，有利于奖励建模。

Result: 使用CPS后，在Flow Matching基础上的强化学习优化器（如Flow-GRPO、Dance-GRPO）能够更快、更稳定地收敛，生成的图像噪声显著减少，奖励学习更加准确。

Conclusion: Coefficients-Preserving Sampling方法有效解决了传统SDE采样在Flow Matching结合强化学习时带来的噪声伪影问题，提升了奖励建模和优化效率。这一改进推动了基于强化学习的扩散与流模型图像生成的发展。

Abstract: Reinforcement Learning (RL) has recently emerged as a powerful technique for
improving image and video generation in Diffusion and Flow Matching models,
specifically for enhancing output quality and alignment with prompts. A
critical step for applying online RL methods on Flow Matching is the
introduction of stochasticity into the deterministic framework, commonly
realized by Stochastic Differential Equation (SDE). Our investigation reveals a
significant drawback to this approach: SDE-based sampling introduces pronounced
noise artifacts in the generated images, which we found to be detrimental to
the reward learning process. A rigorous theoretical analysis traces the origin
of this noise to an excess of stochasticity injected during inference. To
address this, we draw inspiration from Denoising Diffusion Implicit Models
(DDIM) to reformulate the sampling process. Our proposed method,
Coefficients-Preserving Sampling (CPS), eliminates these noise artifacts. This
leads to more accurate reward modeling, ultimately enabling faster and more
stable convergence for reinforcement learning-based optimizers like Flow-GRPO
and Dance-GRPO. Code will be released at https://github.com/IamCreateAI/FlowCPS

</details>


### [67] [Dual Interaction Network with Cross-Image Attention for Medical Image Segmentation](https://arxiv.org/abs/2509.05953)
*Jeonghyun Noh,Wangsu Jeon,Jinsun Park*

Main category: cs.CV

TL;DR: 本论文提出了一种新的医学图像分割方法，通过双交互融合模块（DIFM）结合原始与增强图像的信息，改善分割效果，特别是在边界表现突出。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割在疾病诊断中至关重要，但医学图像通常存在噪声、模糊和低对比度等问题，现有增强技术虽能改善视觉效果，却易丢失原图的诊断信息。传统融合策略无法充分兼顾原始与增强图像的优势，因此需要更有效的融合方法提升分割精度，尤其是边界部分。

Method: 作者提出了DIFM（双交互融合模块），通过双向交叉注意力机制，在原始与增强图像之间进行特征交互，利用全局空间注意力进一步细化互补特征。此外，设计了基于梯度提取的多尺度边界损失函数，提升目标边界的分割精度。

Result: 在ACDC和Synapse两个医学图像分割数据集上，该方法在定量和定性实验中均优于现有方法，验证了其有效性。

Conclusion: DIFM能有效融合原始和增强图像信息，提升分割的准确性和边界表现，为医学图像分割领域提供了更优的解决方案。代码已开源。

Abstract: Medical image segmentation is a crucial method for assisting professionals in
diagnosing various diseases through medical imaging. However, various factors
such as noise, blurriness, and low contrast often hinder the accurate diagnosis
of diseases. While numerous image enhancement techniques can mitigate these
issues, they may also alter crucial information needed for accurate diagnosis
in the original image. Conventional image fusion strategies, such as feature
concatenation can address this challenge. However, they struggle to fully
leverage the advantages of both original and enhanced images while suppressing
the side effects of the enhancements. To overcome the problem, we propose a
dual interactive fusion module (DIFM) that effectively exploits mutual
complementary information from the original and enhanced images. DIFM employs
cross-attention bidirectionally to simultaneously attend to corresponding
spatial information across different images, subsequently refining the
complementary features via global spatial attention. This interaction leverages
low- to high-level features implicitly associated with diverse structural
attributes like edges, blobs, and object shapes, resulting in enhanced features
that embody important spatial characteristics. In addition, we introduce a
multi-scale boundary loss based on gradient extraction to improve segmentation
accuracy at object boundaries. Experimental results on the ACDC and Synapse
datasets demonstrate the superiority of the proposed method quantitatively and
qualitatively. Code available at: https://github.com/JJeong-Gari/DIN

</details>


### [68] [StripDet: Strip Attention-Based Lightweight 3D Object Detection from Point Cloud](https://arxiv.org/abs/2509.05954)
*Weichao Wang,Wendong Mao,Zhongfeng Wang*

Main category: cs.CV

TL;DR: 提出了StripDet，一种高效轻量级的点云3D目标检测框架，显著减少了参数量并提高精度，非常适合边缘设备部署。


<details>
  <summary>Details</summary>
Motivation: 当前高精度点云3D目标检测模型对计算和内存资源需求极高，不适合在设备端（如移动或嵌入式设备）部署，亟需高效、轻量的新方法。

Method: 1. 提出了Strip Attention Block（SAB），将2D卷积分解为异构的strip卷积，低成本捕获长程空间依赖，降低计算复杂度；2. 设计结合SAB和深度可分离卷积的层级骨干网络，并引入简单的多尺度融合机制，实现端到端高效建模。

Result: 在KITTI数据集上，StripDet模型仅用0.65M参数就达到79.97% mAP（汽车检测），参数量比baseline PointPillars减少7倍，同时精度更高，还优于最新轻量化和蒸馏类方法。

Conclusion: StripDet实现了更优的精度-效率权衡，非常适合实际场景下的边缘设备3D检测，验证了其作为实用解决方案的可行性和优势。

Abstract: The deployment of high-accuracy 3D object detection models from point cloud
remains a significant challenge due to their substantial computational and
memory requirements. To address this, we introduce StripDet, a novel
lightweight framework designed for on-device efficiency. First, we propose the
novel Strip Attention Block (SAB), a highly efficient module designed to
capture long-range spatial dependencies. By decomposing standard 2D
convolutions into asymmetric strip convolutions, SAB efficiently extracts
directional features while reducing computational complexity from quadratic to
linear. Second, we design a hardware-friendly hierarchical backbone that
integrates SAB with depthwise separable convolutions and a simple multiscale
fusion strategy, achieving end-to-end efficiency. Extensive experiments on the
KITTI dataset validate StripDet's superiority. With only 0.65M parameters, our
model achieves a 79.97% mAP for car detection, surpassing the baseline
PointPillars with a 7x parameter reduction. Furthermore, StripDet outperforms
recent lightweight and knowledge distillation-based methods, achieving a
superior accuracy-efficiency trade-off while establishing itself as a practical
solution for real-world 3D detection on edge devices.

</details>


### [69] [Neural Bloom: A Deep Learning Approach to Real-Time Lighting](https://arxiv.org/abs/2509.05963)
*Rafal Karp,Dawid Gruszka,Tomasz Trzcinski*

Main category: cs.CV

TL;DR: 该论文提出了一种利用神经网络进行实时Bloom光照效果生成的新方法，相比主流方法显著提升了速度且保证了高质量渲染效果。


<details>
  <summary>Details</summary>
Motivation: 传统Bloom光照效果方法依赖多次模糊处理和纹理采样，算法复杂且耗时，成为实时渲染的性能瓶颈。快速且高质量的Bloom效果对于提升实时渲染的真实感和沉浸体验极为重要。

Method: 作者提出两种基于神经网络的Bloom光照方法：Neural Bloom Lighting (NBL) 和 Fast Neural Bloom Lighting (FastNBL)。两者分别侧重于渲染质量与性能提升，通过训练神经网络直接生成3D场景的亮度遮罩，规避了传统方法中的多步骤模糊和分支操作。

Result: 在多种3D场景测试下，两种方法在亮度遮罩的精度和推理速度上显著优于主流方法。其中FastNBL速度提升28%，NBL提升12%，两者均能生成高质量Bloom特效。

Conclusion: 神经网络方法能更快生成高真实感的Bloom特效，提升实时渲染效率并节省算力，有助于未来更加沉浸且高帧率的实时渲染应用。

Abstract: We propose a novel method to generate bloom lighting effect in real time
using neural networks. Our solution generate brightness mask from given 3D
scene view up to 30% faster than state-of-the-art methods. The existing
traditional techniques rely on multiple blur appliances and texture sampling,
also very often have existing conditional branching in its implementation.
These operations occupy big portion of the execution time. We solve this
problem by proposing two neural network-based bloom lighting methods, Neural
Bloom Lighting (NBL) and Fast Neural Bloom Lighting (FastNBL), focusing on
their quality and performance. Both methods were tested on a variety of 3D
scenes, with evaluations conducted on brightness mask accuracy and inference
speed. The main contribution of this work is that both methods produce
high-quality bloom effects while outperforming the standard state-of-the-art
bloom implementation, with FastNBL being faster by 28% and NBL faster by 12%.
These findings highlight that we can achieve realistic bloom lighting phenomena
faster, moving us towards more realism in real-time environments in the future.
This improvement saves computational resources, which is a major bottleneck in
real-time rendering. Furthermore, it is crucial for sustaining immersion and
ensuring smooth experiences in high FPS environments, while maintaining
high-quality realism.

</details>


### [70] [Spatial-Aware Self-Supervision for Medical 3D Imaging with Multi-Granularity Observable Tasks](https://arxiv.org/abs/2509.05967)
*Yiqin Zhang,Meiling Chen,Zhengjie Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种提升医学3D图像自监督学习可解释性的多任务方法，通过更好地建模空间语义关系，兼顾有效性与模型内部过程的直观理解。


<details>
  <summary>Details</summary>
Motivation: 现有医学可视化中的自监督方法大多借鉴于2D视觉领域，缺乏对三维空间知识学习过程的展示，导致在医学上的可解释性较弱。针对这一问题，作者希望通过引入更具可解释性的自监督设计，提升3D医学图像分析的性能与 interpretability。

Method: 提出包含三个子任务的自监督学习方法，用于捕捉医学3D图像中的空间相关语义。这些子任务基于可观测原则设计，既保证了模型的解释性，又尽量减少由此带来的性能损失。同时利用3D图像额外的空间维度，实现多粒度的空间关系建模，保持训练稳定性。

Result: 实验结果表明，该方法与当前主流方法性能相当，同时能够帮助研究者直观理解自监督学习过程，提升可解释性。

Conclusion: 该方法在保证性能的同时显著增强了自监督3D医学图像分析的可解释性，为医学可视化领域模型设计提供了新的思路。

Abstract: The application of self-supervised techniques has become increasingly
prevalent within medical visualization tasks, primarily due to its capacity to
mitigate the data scarcity prevalent in the healthcare sector. The majority of
current works are influenced by designs originating in the generic 2D visual
domain, which lack the intuitive demonstration of the model's learning process
regarding 3D spatial knowledge. Consequently, these methods often fall short in
terms of medical interpretability. We propose a method consisting of three
sub-tasks to capture the spatially relevant semantics in medical 3D imaging.
Their design adheres to observable principles to ensure interpretability, and
minimize the performance loss caused thereby as much as possible. By leveraging
the enhanced semantic depth offered by the extra dimension in 3D imaging, this
approach incorporates multi-granularity spatial relationship modeling to
maintain training stability. Experimental findings suggest that our approach is
capable of delivering performance that is on par with current methodologies,
while facilitating an intuitive understanding of the self-supervised learning
process.

</details>


### [71] [OmniStyle2: Scalable and High Quality Artistic Style Transfer Data Generation via Destylization](https://arxiv.org/abs/2509.05970)
*Ye Wang,Zili Yi,Yibo Zhang,Peng Zheng,Xuping Xie,Jiang Lin,Yilin Wang,Rui Ma*

Main category: cs.CV

TL;DR: 该论文提出了一种全新的艺术风格迁移方法，将问题重新定义为数据驱动问题，并通过去风格化大量生成高质量数据集，极大提升了风格迁移的效果。


<details>
  <summary>Details</summary>
Motivation: 由于艺术风格迁移任务缺乏可靠的真值数据，对风格迁移模型的训练和评估造成了根本性挑战。作者希望构建一个能够大规模提供风格与内容对齐的真实数据集，以提升风格迁移效果。

Method: 作者提出去风格化（destylization）方法，通过去除艺术作品中的风格元素恢复自然内容。他们设计了（1）DST文本引导的去风格化模型生成无风格内容；（2）DST-Filter评估模型，基于链式推理自动过滤低质量样本，保证数据准确。借此构建了大规模数据集DST-100K。随后，基于该数据集训练了简单高效的OmniStyle2模型。

Result: OmniStyle2模型在多个定性和定量基准上，都优于当前主流的风格迁移方法，展现了强大的泛化和表现能力。

Conclusion: 通过去风格化生成大规模数据并进行有效监督，突破了艺术风格迁移领域缺少真值数据的瓶颈，为风格迁移提供了稳定和可靠的监督新范式。

Abstract: OmniStyle2 introduces a novel approach to artistic style transfer by
reframing it as a data problem. Our key insight is destylization, reversing
style transfer by removing stylistic elements from artworks to recover natural,
style-free counterparts. This yields DST-100K, a large-scale dataset that
provides authentic supervision signals by aligning real artistic styles with
their underlying content. To build DST-100K, we develop (1) DST, a text-guided
destylization model that reconstructs stylefree content, and (2) DST-Filter, a
multi-stage evaluation model that employs Chain-of-Thought reasoning to
automatically discard low-quality pairs while ensuring content fidelity and
style accuracy. Leveraging DST-100K, we train OmniStyle2, a simple feed-forward
model based on FLUX.1-dev. Despite its simplicity, OmniStyle2 consistently
surpasses state-of-the-art methods across both qualitative and quantitative
benchmarks. Our results demonstrate that scalable data generation via
destylization provides a reliable supervision paradigm, overcoming the
fundamental challenge posed by the lack of ground-truth data in artistic style
transfer.

</details>


### [72] [ConstStyle: Robust Domain Generalization with Unified Style Transformation](https://arxiv.org/abs/2509.05975)
*Nam Duong Tran,Nam Nguyen Phuong,Hieu H. Pham,Phi Le Nguyen,My T. Thai*

Main category: cs.CV

TL;DR: 本文提出了一种名为ConstStyle的新方法，通过将训练和测试样本映射到统一域，有效提升了深度神经网络在不同领域下的泛化能力。该方法尤其适用于训练域极少或与测试域差异较大的场景，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在测试数据分布与训练数据分布不一致时表现不佳。现有的领域泛化方法在训练域数量有限或训练与测试域差异大时效果有限，因此需要更鲁棒的新方法。

Method: 提出ConstStyle，将所有样本在训练时映射到一个统一的域，模型在此域内学习领域不变特征。测试时，也将新域数据打到统一域后再预测，从而缩小测试和训练之间的领域差异。理论分析也支持该方法的有效性。

Result: 实验表明，ConstStyle在多种领域泛化场景下均优于现有方法。尤其在可用训练域极少的情况下，准确率相比第二优秀的方法提升高达19.82%。

Conclusion: ConstStyle能够有效减少领域差异带来的影响，提高模型泛化性能，且在极端场景下依然保持显著优势。

Abstract: Deep neural networks often suffer performance drops when test data
distribution differs from training data. Domain Generalization (DG) aims to
address this by focusing on domain-invariant features or augmenting data for
greater diversity. However, these methods often struggle with limited training
domains or significant gaps between seen (training) and unseen (test) domains.
To enhance DG robustness, we hypothesize that it is essential for the model to
be trained on data from domains that closely resemble unseen test domains-an
inherently difficult task due to the absence of prior knowledge about the
unseen domains. Accordingly, we propose ConstStyle, a novel approach that
leverages a unified domain to capture domain-invariant features and bridge the
domain gap with theoretical analysis. During training, all samples are mapped
onto this unified domain, optimized for seen domains. During testing, unseen
domain samples are projected similarly before predictions. By aligning both
training and testing data within this unified domain, ConstStyle effectively
reduces the impact of domain shifts, even with large domain gaps or few seen
domains. Extensive experiments demonstrate that ConstStyle consistently
outperforms existing methods across diverse scenarios. Notably, when only a
limited number of seen domains are available, ConstStyle can boost accuracy up
to 19.82\% compared to the next best approach.

</details>


### [73] [Index-Preserving Lightweight Token Pruning for Efficient Document Understanding in Vision-Language Models](https://arxiv.org/abs/2509.06415)
*Jaemin Son,Sujin Choi,Inyong Yun*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级token裁剪框架，在文档处理前去除无信息背景区域，显著降低视觉-语言模型(VLMs)的计算消耗，同时保持准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型在文档理解任务中表现优异，但高计算需求成为实际应用的障碍。为解决这一痛点，需要减少不必要的计算开销。

Method: 设计一种二分类的patch级分类器，预处理文档图像，去除非文本区域。之后采用最大池化修正，恢复被裁剪的分散文本区域，增强空间连贯性。

Result: 在真实世界的文档数据集上，实验证明该方法能大幅降低VLM计算成本，同时准确率几乎不受影响。

Conclusion: 该轻量级裁剪方法有效降低了文档理解场景中的算力消耗，并兼顾了处理精度，对实际应用具有较高价值。

Abstract: Recent progress in vision-language models (VLMs) has led to impressive
results in document understanding tasks, but their high computational demands
remain a challenge. To mitigate the compute burdens, we propose a lightweight
token pruning framework that filters out non-informative background regions
from document images prior to VLM processing. A binary patch-level classifier
removes non-text areas, and a max-pooling refinement step recovers fragmented
text regions to enhance spatial coherence. Experiments on real-world document
datasets demonstrate that our approach substantially lowers computational
costs, while maintaining comparable accuracy.

</details>


### [74] [Multi-Strategy Guided Diffusion via Sparse Masking Temporal Reweighting Distribution Correction](https://arxiv.org/abs/2509.05992)
*Zekun Zhou,Yanru Gong,Liu Shi,Qiegen Liu*

Main category: cs.CV

TL;DR: 提出了一种创新的扩散模型STRIDE，用于稀疏视角CT重建，在实验中显著提升了重建图像的质量和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 稀疏视角CT因投影数据缺失导致重建图像存在细节丢失和结构失真，急需提升稀疏视角下的CT重建质量。

Method: 1. 提出STRIDE扩散模型，通过稀疏条件概率引导的联合训练机制，提升模型对丢失投影补全和全局信息建模能力；2. 设计时变稀疏条件重加权策略，动态调整去噪过程中的权重，使模型逐步感知稀疏信息；3. 利用线性回归校正生成数据和已知数据间的分布漂移，减少引导过程中产生的不一致性；4. 构建双网络并行架构，实现多子频段全局校正和优化，兼顾细节恢复与结构保持。

Result: 在公开和真实数据集上，本文方法在PSNR提升2.58dB，SSIM提升2.37%，MSE下降0.236，优于所有对比基线方法。重建图像在结构一致性、细节恢复和伪影抑制等方面表现突出。

Conclusion: STRIDE方法能有效提升稀疏视角CT重建质量，具备良好的泛化性和鲁棒性，为医学成像等应用带来新选择。

Abstract: Diffusion models have demonstrated remarkable generative capabilities in
image processing tasks. We propose a Sparse condition Temporal Rewighted
Integrated Distribution Estimation guided diffusion model (STRIDE) for
sparse-view CT reconstruction. Specifically, we design a joint training
mechanism guided by sparse conditional probabilities to facilitate the model
effective learning of missing projection view completion and global information
modeling. Based on systematic theoretical analysis, we propose a temporally
varying sparse condition reweighting guidance strategy to dynamically adjusts
weights during the progressive denoising process from pure noise to the real
image, enabling the model to progressively perceive sparse-view information.
The linear regression is employed to correct distributional shifts between
known and generated data, mitigating inconsistencies arising during the
guidance process. Furthermore, we construct a dual-network parallel
architecture to perform global correction and optimization across multiple
sub-frequency components, thereby effectively improving the model capability in
both detail restoration and structural preservation, ultimately achieving
high-quality image reconstruction. Experimental results on both public and real
datasets demonstrate that the proposed method achieves the best improvement of
2.58 dB in PSNR, increase of 2.37\% in SSIM, and reduction of 0.236 in MSE
compared to the best-performing baseline methods. The reconstructed images
exhibit excellent generalization and robustness in terms of structural
consistency, detail restoration, and artifact suppression.

</details>


### [75] [Interleaving Reasoning for Better Text-to-Image Generation](https://arxiv.org/abs/2509.06945)
*Wenxuan Huang,Shuang Chen,Zheyong Xie,Shaosheng Cao,Shixiang Tang,Yufan Shen,Qingyu Yin,Wenbo Hu,Xiaoman Wang,Yuntian Tang,Junbo Qiao,Yue Guo,Yao Hu,Zhenfei Yin,Philip Torr,Yu Cheng,Wanli Ouyang,Shaohui Lin*

Main category: cs.CV

TL;DR: 本文提出了一种交替进行文本推理与图像生成的新框架IRG，显著提升了文生图任务中的细节还原和指令理解，取得多项基准最佳成绩。


<details>
  <summary>Details</summary>
Motivation: 现有通用多模态理解与生成模型虽然图像生成能力强，但在指令跟随和细节还原方面与如GPT-4o等紧密结合理解与生成的系统存在差距。作者受最近交替推理进展启发，希望通过交替推理提升文本生成图像能力。

Method: 提出IRG（Interleaving Reasoning Generation）框架，模型先进行文本推理生成指导，再据此生成初步图像，然后基于生成结果进行反思与细节和美学微调。在训练上，提出IRGL算法，强化初步推理生成和后续高质量文本反思。并构建IRGL-300K数据集，涵盖多个学习阶段。通过两阶段训练，先增强推理与反思能力，再用完整推理-图像轨迹数据高效微调。

Result: 在GenEval、WISE、TIIF、GenAI-Bench、OneIG-EN等多个主流基准测试中，IRG取得了绝对5-10分提升，视觉质量和细粒度一致性显著优于现有方法。

Conclusion: 交替推理+生成的IRG框架有效提升了文生图的指令理解和细节还原能力，验证了分阶段推理与反思在多模态生成中的价值。代码、模型和数据即将开放。

Abstract: Unified multimodal understanding and generation models recently have achieve
significant improvement in image generation capability, yet a large gap remains
in instruction following and detail preservation compared to systems that
tightly couple comprehension with generation such as GPT-4o. Motivated by
recent advances in interleaving reasoning, we explore whether such reasoning
can further improve Text-to-Image (T2I) generation. We introduce Interleaving
Reasoning Generation (IRG), a framework that alternates between text-based
thinking and image synthesis: the model first produces a text-based thinking to
guide an initial image, then reflects on the result to refine fine-grained
details, visual quality, and aesthetics while preserving semantics. To train
IRG effectively, we propose Interleaving Reasoning Generation Learning (IRGL),
which targets two sub-goals: (1) strengthening the initial think-and-generate
stage to establish core content and base quality, and (2) enabling high-quality
textual reflection and faithful implementation of those refinements in a
subsequent image. We curate IRGL-300K, a dataset organized into six decomposed
learning modes that jointly cover learning text-based thinking, and full
thinking-image trajectories. Starting from a unified foundation model that
natively emits interleaved text-image outputs, our two-stage training first
builds robust thinking and reflection, then efficiently tunes the IRG pipeline
in the full thinking-image trajectory data. Extensive experiments show SoTA
performance, yielding absolute gains of 5-10 points on GenEval, WISE, TIIF,
GenAI-Bench, and OneIG-EN, alongside substantial improvements in visual quality
and fine-grained fidelity. The code, model weights and datasets will be
released in: https://github.com/Osilly/Interleaving-Reasoning-Generation .

</details>


### [76] [S-LAM3D: Segmentation-Guided Monocular 3D Object Detection via Feature Space Fusion](https://arxiv.org/abs/2509.05999)
*Diana-Alexandra Sas,Florin Oniga*

Main category: cs.CV

TL;DR: 本文提出了一种单目3D目标检测的新策略，即将预先计算好的分割信息节点输入到特征空间，从而提升检测性能，特别是在小目标（行人和骑行者）检测方面超越了仅依靠RGB信息的同架构方法。


<details>
  <summary>Details</summary>
Motivation: 单目3D目标检测由于只有2D图像输入，缺乏深度信息，是一个病态问题。目前方法多基于CNN或Transformer提取特征，但对提升小目标（例如行人、骑行者）的检测仍存在困难。作者意在探索如何利用额外分割信息提升现有检测管线性能，无需扩展模型或额外分支。

Method: 作者提出一种解耦方法，将预先计算好的分割（segmentation）先验信息直接融合到特征空间，用于指导3D检测。这不要求检测模型结构变大或多头联合训练，只需在特征提取阶段引入分割信息，评估其对提升下游检测的作用。

Result: 在KITTI 3D目标检测基准上，作者方法在行人和骑行者这两类小目标检测上，优于仅依靠RGB图像特征的同类方法。

Conclusion: 引入分割先验能提升单目3D检测性能，尤其是小目标，无需增加模型复杂度，对系统理解更加深入，可部分替代增加传感器或训练数据的方式。

Abstract: Monocular 3D Object Detection represents a challenging Computer Vision task
due to the nature of the input used, which is a single 2D image, lacking in any
depth cues and placing the depth estimation problem as an ill-posed one.
Existing solutions leverage the information extracted from the input by using
Convolutional Neural Networks or Transformer architectures as feature
extraction backbones, followed by specific detection heads for 3D parameters
prediction. In this paper, we introduce a decoupled strategy based on injecting
precomputed segmentation information priors and fusing them directly into the
feature space for guiding the detection, without expanding the detection model
or jointly learning the priors. The focus is on evaluating the impact of
additional segmentation information on existing detection pipelines without
adding additional prediction branches. The proposed method is evaluated on the
KITTI 3D Object Detection Benchmark, outperforming the equivalent architecture
that relies only on RGB image features for small objects in the scene:
pedestrians and cyclists, and proving that understanding the input data can
balance the need for additional sensors or training data.

</details>


### [77] [Motion Aware ViT-based Framework for Monocular 6-DoF Spacecraft Pose Estimation](https://arxiv.org/abs/2509.06000)
*Jose Sosa,Dan Pineau,Arunkumar Rathinam,Abdelrahman Shabayek,Djamila Aouada*

Main category: cs.CV

TL;DR: 该论文提出了一种结合时序信息的单目6自由度姿态估计算法，在航天器任务中表现优异，较现有单帧方法有显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前大多数姿态估计算法仅依赖单帧静态图像，未能有效利用航天任务中丰富的时序和运动信息，限制了精度和适用性。

Method: 借鉴人体姿态估计的深度学习框架，将ViT视觉编码器提取的图像特征与预训练光流模型获得的运动线索结合，生成运动感知的热力图精准定位2D关键点，最后利用PnP算法从2D-3D点对应关系恢复6自由度姿态。算法在SPADES-RGB和SPARK-2024数据集（含真实及合成数据）上进行了训练和评估。

Result: 该方法在2D关键点定位和6自由度姿态估计上均优于单帧基线，且在数据分布变化时表现出良好的泛化能力。

Conclusion: 利用时序中运动信息能有效提升单目航天器姿态估计的精度和泛化性，为实际空间任务提供更鲁棒的解决方案。

Abstract: Monocular 6-DoF pose estimation plays an important role in multiple
spacecraft missions. Most existing pose estimation approaches rely on single
images with static keypoint localisation, failing to exploit valuable temporal
information inherent to space operations. In this work, we adapt a deep
learning framework from human pose estimation to the spacecraft pose estimation
domain that integrates motion-aware heatmaps and optical flow to capture motion
dynamics. Our approach combines image features from a Vision Transformer (ViT)
encoder with motion cues from a pre-trained optical flow model to localise 2D
keypoints. Using the estimates, a Perspective-n-Point (PnP) solver recovers
6-DoF poses from known 2D-3D correspondences. We train and evaluate our method
on the SPADES-RGB dataset and further assess its generalisation on real and
synthetic data from the SPARK-2024 dataset. Overall, our approach demonstrates
improved performance over single-image baselines in both 2D keypoint
localisation and 6-DoF pose estimation. Furthermore, it shows promising
generalisation capabilities when testing on different data distributions.

</details>


### [78] [Khana: A Comprehensive Indian Cuisine Dataset](https://arxiv.org/abs/2509.06006)
*Omkar Prabhu*

Main category: cs.CV

TL;DR: 本论文提出了Khana，一个专注于印度菜肴的食物图像基准数据集，用于图像分类、分割和检索任务。


<details>
  <summary>Details</summary>
Motivation: 尽管已有大量食物相关的数据集，但由于印度菜肴的区域多样性和复杂制作过程，现有数据集无法全面覆盖印度美食，影响了相关AI应用的发展。

Method: 作者建立了印度菜肴的系统分类法，收集并清洗了约13.1万张、分属80个类别的高分辨率（500x500像素）图片，构建Khana数据集，并利用现有先进方法在该数据集上进行了分类、分割和检索任务的基线实验。

Result: Khana数据集覆盖了印度菜肴的多样性，为多种计算机视觉任务提供了大规模高质量的标注数据，并通过实验展示了当前技术水平，为后续模型改进提供基准。

Conclusion: Khana有效填补了印度菜肴图像数据集的空白，为研究人员和开发者在相关食物识别与应用开发方面提供了丰富资源。

Abstract: As global interest in diverse culinary experiences grows, food image models
are essential for improving food-related applications by enabling accurate food
recognition, recipe suggestions, dietary tracking, and automated meal planning.
Despite the abundance of food datasets, a noticeable gap remains in capturing
the nuances of Indian cuisine due to its vast regional diversity, complex
preparations, and the lack of comprehensive labeled datasets that cover its
full breadth. Through this exploration, we uncover Khana, a new benchmark
dataset for food image classification, segmentation, and retrieval of dishes
from Indian cuisine. Khana fills the gap by establishing a taxonomy of Indian
cuisine and offering around 131K images in the dataset spread across 80 labels,
each with a resolution of 500x500 pixels. This paper describes the dataset
creation process and evaluates state-of-the-art models on classification,
segmentation, and retrieval as baselines. Khana bridges the gap between
research and development by providing a comprehensive and challenging benchmark
for researchers while also serving as a valuable resource for developers
creating real-world applications that leverage the rich tapestry of Indian
cuisine. Webpage: https://khana.omkar.xyz

</details>


### [79] [BLaVe-CoT: Consistency-Aware Visual Question Answering for Blind and Low Vision Users](https://arxiv.org/abs/2509.06010)
*Wanyin Cheng,Zanxi Ruan*

Main category: cs.CV

TL;DR: 本文针对视障用户（BLV）在实际环境中使用视觉问答（VQA）时遇到的问题，提出了BLaVe-CoT框架，以更好地处理多义性和不确定性，实现更包容的辅助功能。


<details>
  <summary>Details</summary>
Motivation: BLV用户拍摄的图片往往模糊或取景不佳，且他们难以准确描述自己看不到的内容，导致视觉问题常常模糊且存在多解。然而，大多数现有VQA系统假设只有唯一答案，这与BLV用户实际需求不符。因此需要一个能处理多义性、适配实际不确定性的VQA系统，以更好地服务BLV用户。

Method: 提出BLaVe-CoT方法：首先用LoRA微调过的BLIP-2提出多样化候选答案，然后利用PolyFormer为每个答案进行空间定位，最后通过链式思考推理模块来判断这些答案是否对应相同或不同的图像区域。

Result: 在VQA-AnswerTherapy基准上，BLaVe-CoT表现优于以往方法，尤其对于多义性和视觉噪声有更强鲁棒性。

Conclusion: BLaVe-CoT更好满足了真实场景下BLV用户需求，强调VQA系统需要适应人类不确定性，提升辅助技术的包容性。项目代码已开源，有助于未来研究和实际应用。

Abstract: Visual Question Answering (VQA) holds great potential for assisting Blind and
Low Vision (BLV) users, yet real-world usage remains challenging. Due to visual
impairments, BLV users often take blurry or poorly framed photos and face
difficulty in articulating specific questions about what they cannot fully see.
As a result, their visual questions are frequently ambiguous, and different
users may interpret them in diverse ways. This leads to multiple valid answers,
each grounded in different image regions-posing a mismatch with conventional
VQA systems that assume a single answer and region. To bridge this gap, we
present BLaVe-CoT, a VQA framework designed to reason about answer consistency
in the face of ambiguity. Our method proposes diverse candidate answers using a
LoRA-tuned BLIP-2 model, then grounds each answer spatially using PolyFormer,
and finally applies a chain-of-thought reasoning module to assess whether the
answers refer to the same or different regions. Evaluated on the
VQA-AnswerTherapy benchmark, BLaVe-CoT outperforms previous methods and proves
more robust to the ambiguity and visual noise common in assistive settings.
This work highlights the need for VQA systems that can adapt to real human
uncertainty and provide inclusive support for BLV users. To foster further
research and accessibility applications, we have made the code publicly
available at https://github.com/Accecwan/BLaVe-CoT.

</details>


### [80] [Cross-Modal Enhancement and Benchmark for UAV-based Open-Vocabulary Object Detection](https://arxiv.org/abs/2509.06011)
*Zhenhai Weng,Zhongliang Yu*

Main category: cs.CV

TL;DR: 该论文针对无人机影像的开放词汇目标检测提出了新的数据集和改进的检测方法，并且在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 目前用于开放词汇目标检测（OVD）的大规模数据集主要是地面、自然场景的图片，与无人机视角的影像存在较大领域间隙，导致直接用这些数据训练的模型在无人机影像上的检测性能大幅下降。

Method: 1) 提出了一套更精确的无人机多目标标注系统UAV-Label engine；2) 构建了大规模无人机构建数据集UAVDE-2M（含200万实例和1800类）及UAVCAP-15k（1.5万张图片）；3) 提出Cross-Attention Gated Enhancement Fusion (CAGE)模块，将其集成到YOLO-World-v2架构中。

Result: 在VisDrone和SIMD等无人机遥感相关数据集上进行了大量实验证明了所提方法的有效性，表现优于现有基线。

Conclusion: 通过引入针对无人机影像场景标注、数据集和结构创新，大幅提升了开放词汇目标检测在无人机遥感图像领域的表现。

Abstract: Open-Vocabulary Object Detection (OVD) has emerged as a pivotal technology
for applications involving Unmanned Aerial Vehicles (UAVs). However, the
prevailing large-scale datasets for OVD pre-training are predominantly composed
of ground-level, natural images. This creates a significant domain gap, causing
models trained on them to exhibit a substantial drop in performance on UAV
imagery. To address this limitation, we first propose a refined UAV-Label
engine. Then we construct and introduce UAVDE-2M(contains over 2,000,000
instances and 1800 categories) and UAVCAP-15k(contains over 15,000 images).
Furthermore, we propose a novel Cross-Attention Gated Enhancement Fusion (CAGE)
module and integrate it into the YOLO-World-v2 architecture. Finally, extensive
experiments on the VisDrone and SIMD datasets verify the effectiveness of our
proposed method for applications in UAV-based imagery and remote sensing.

</details>


### [81] [Micro-Expression Recognition via Fine-Grained Dynamic Perception](https://arxiv.org/abs/2509.06015)
*Zhiwen Shao,Yifan Cheng,Fan Zhang,Xuehuai Shi,Canlin Li,Lizhuang Ma,Dit-yan Yeung*

Main category: cs.CV

TL;DR: 本文提出了一种全新的细粒度动态感知（FDP）框架，用于面部微表情识别，通过排序帧级特征捕捉动态信息，并结合动态图像生成任务，有效提升了多项数据集上的识别性能。


<details>
  <summary>Details</summary>
Motivation: 面部微表情因其短暂、微妙和动态性，识别难度极高。以往方法依赖手工特征（需提取关键帧）或深度网络（易受数据量和多样性限制），因此亟需一种新方法来更好捕捉微表情动态，缓解数据稀缺带来的问题。

Method: 作者提出FDP框架，核心方法为：将原始帧序列的帧级特征以时间顺序排序，排序过程编码了微表情的动态变化。具体实现上，设计了局部-全局特征感知Transformer用于帧特征学习；采用rank scorer给每帧特征判分，排序特征再在时间维度池化以获得动态表示。动态表示同时用于微表情分类和动态图像生成两个任务，后者通过编码-解码结构实现，有助于捕捉面部细微动作和缓解数据不足问题。

Result: 在CASME II、SAMM、CAS(ME)^2和CAS(ME)^3四个主流数据集上，FDP方法的F1-score分别比现有最佳方法提升了4.05%、2.50%、7.71%和2.11%；此外动态图像生成效果良好。

Conclusion: 所提出的FDP框架显著提升了微表情识别性能，并有效结合了辅助的动态图像生成任务，提升了模型对细微动态的感知和数据利用能力。

Abstract: Facial micro-expression recognition (MER) is a challenging task, due to the
transience, subtlety, and dynamics of micro-expressions (MEs). Most existing
methods resort to hand-crafted features or deep networks, in which the former
often additionally requires key frames, and the latter suffers from small-scale
and low-diversity training data. In this paper, we develop a novel fine-grained
dynamic perception (FDP) framework for MER. We propose to rank frame-level
features of a sequence of raw frames in chronological order, in which the rank
process encodes the dynamic information of both ME appearances and motions.
Specifically, a novel local-global feature-aware transformer is proposed for
frame representation learning. A rank scorer is further adopted to calculate
rank scores of each frame-level feature. Afterwards, the rank features from
rank scorer are pooled in temporal dimension to capture dynamic representation.
Finally, the dynamic representation is shared by a MER module and a dynamic
image construction module, in which the former predicts the ME category, and
the latter uses an encoder-decoder structure to construct the dynamic image.
The design of dynamic image construction task is beneficial for capturing
facial subtle actions associated with MEs and alleviating the data scarcity
issue. Extensive experiments show that our method (i) significantly outperforms
the state-of-the-art MER methods, and (ii) works well for dynamic image
construction. Particularly, our FDP improves by 4.05%, 2.50%, 7.71%, and 2.11%
over the previous best results in terms of F1-score on the CASME II, SAMM,
CAS(ME)^2, and CAS(ME)^3 datasets, respectively. The code is available at
https://github.com/CYF-cuber/FDP.

</details>


### [82] [DVLO4D: Deep Visual-Lidar Odometry with Sparse Spatial-temporal Fusion](https://arxiv.org/abs/2509.06023)
*Mengmeng Liu,Michael Ying Yang,Jiuming Liu,Yunpeng Zhang,Jiangtao Li,Sander Oude Elberink,George Vosselman,Hao Cheng*

Main category: cs.CV

TL;DR: 该论文提出了一种新颖的视觉-LiDAR里程计框架DVLO4D，在准确性和鲁棒性方面优于现有方法，并具备实时推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统视觉-LiDAR融合方法在于：传感器对齐难、时序信息利用不足、需要大量人工调参以适配不同配置，因而在高精度和高鲁棒性间难以兼得。

Method: 提出了稀疏时空融合的视觉-LiDAR里程计框架DVLO4D。主要包括三个创新：（1）稀疏查询融合，通过稀疏LiDAR查询实现多模态高效融合；（2）时序交互与更新模块，将时间预测位姿与当前帧结合，从而优化初始化值，抑制累积误差；（3）时序片段训练及集体均值损失机制，整合多帧误差实现全局优化，显著减少长序列下尺度漂移。

Result: 在KITTI和Argoverse Odometry数据集上，DVLO4D在位姿准确性和鲁棒性方面均取得了SOTA水平，推理速度仅82毫秒，优于现有主流方法。

Conclusion: DVLO4D能够有效融合视觉与LiDAR信息，提升了定位准确率与鲁棒性，并具备高效率，适合实际自动驾驶系统的实时应用。

Abstract: Visual-LiDAR odometry is a critical component for autonomous system
localization, yet achieving high accuracy and strong robustness remains a
challenge. Traditional approaches commonly struggle with sensor misalignment,
fail to fully leverage temporal information, and require extensive manual
tuning to handle diverse sensor configurations. To address these problems, we
introduce DVLO4D, a novel visual-LiDAR odometry framework that leverages sparse
spatial-temporal fusion to enhance accuracy and robustness. Our approach
proposes three key innovations: (1) Sparse Query Fusion, which utilizes sparse
LiDAR queries for effective multi-modal data fusion; (2) a Temporal Interaction
and Update module that integrates temporally-predicted positions with current
frame data, providing better initialization values for pose estimation and
enhancing model's robustness against accumulative errors; and (3) a Temporal
Clip Training strategy combined with a Collective Average Loss mechanism that
aggregates losses across multiple frames, enabling global optimization and
reducing the scale drift over long sequences. Extensive experiments on the
KITTI and Argoverse Odometry dataset demonstrate the superiority of our
proposed DVLO4D, which achieves state-of-the-art performance in terms of both
pose accuracy and robustness. Additionally, our method has high efficiency,
with an inference time of 82 ms, possessing the potential for the real-time
deployment.

</details>


### [83] [Analysis of Blood Report Images Using General Purpose Vision-Language Models](https://arxiv.org/abs/2509.06033)
*Nadia Bakhsheshi,Hamid Beigy*

Main category: cs.CV

TL;DR: 本文评估了三种视觉语言模型（VLM）在自动分析血液报告图像中的表现，证明了VLM在辅助患者理解健康报告方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 许多人难以解读血液检查报告，导致焦虑和健康问题被忽视，因此需要开发能够自动分析和解释血液报告的技术，提高健康认知水平。

Method: 作者对Qwen-VL-Max、Gemini 2.5 Pro和Llama 4 Maverick这三款通用视觉语言模型进行了评测，使用100份多样化血液报告图片，并对每个报告提出临床相关问题。通过Sentence-BERT对模型的回答进行相似度对比分析。

Result: 三种模型均能从血液报告图片中生成有意义的解读，展现出VLM自动解读医疗报告的可行性和应用潜力。

Conclusion: 普通VLM有望用于AI健康辅助工具，帮助公众初步解读血液报告并提升健康素养，但本研究样本有限，结论需谨慎对待。

Abstract: The reliable analysis of blood reports is important for health knowledge, but
individuals often struggle with interpretation, leading to anxiety and
overlooked issues. We explore the potential of general-purpose Vision-Language
Models (VLMs) to address this challenge by automatically analyzing blood report
images. We conduct a comparative evaluation of three VLMs: Qwen-VL-Max, Gemini
2.5 Pro, and Llama 4 Maverick, determining their performance on a dataset of
100 diverse blood report images. Each model was prompted with clinically
relevant questions adapted to each blood report. The answers were then
processed using Sentence-BERT to compare and evaluate how closely the models
responded. The findings suggest that general-purpose VLMs are a practical and
promising technology for developing patient-facing tools for preliminary blood
report analysis. Their ability to provide clear interpretations directly from
images can improve health literacy and reduce the limitations to understanding
complex medical information. This work establishes a foundation for the future
development of reliable and accessible AI-assisted healthcare applications.
While results are encouraging, they should be interpreted cautiously given the
limited dataset size.

</details>


### [84] [TinyDef-DETR:An Enhanced DETR Detector for UAV Power Line Defect Detection](https://arxiv.org/abs/2509.06035)
*Jiaming Cui*

Main category: cs.CV

TL;DR: 本文提出了一种名为TinyDef-DETR的新方法，用于提升无人机对输电线路细小缺陷的自动检测能力，并在多个数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有输电线路缺陷检测方法在面对细小、模糊缺陷以及复杂背景时表现不足，常因下采样等操作丢失重要细节，导致检测精度低，尤其对于轻量级网络和小目标检测任务。

Method: 提出了一种基于DETR的新检测框架TinyDef-DETR，包含无步幅空间降采样模块（保证特征细节）、边缘增强卷积（增强边界感知）、跨阶段双域多尺度注意力模块（结合全局与局部信息）、以及Focaler-Wise-SIoU回归损失（提升小目标定位）。

Result: 在CSG-ADCD数据集上，TinyDef-DETR在精度和召回率方面均优于主流竞争方法，在小目标检测方面提升尤为显著，同时计算开销较小。在VisDrone基准数据集上进一步验证了方法的泛化能力。

Conclusion: 结合细节保留降采样、边界感知特征、双域注意力和难度自适应回归的检测框架，为电网无人机小缺陷检测提供了高效且实用的技术方案。

Abstract: Automated inspection of transmission lines using UAVs is hindered by the
difficulty of detecting small and ambiguous defects against complex
backgrounds. Conventional detectors often suffer from detail loss due to
strided downsampling, weak boundary sensitivity in lightweight backbones, and
insufficient integration of global context with local cues. To address these
challenges, we propose TinyDef-DETR, a DETR-based framework designed for
small-defect detection. The method introduces a stride-free space-to-depth
module for lossless downsampling, an edge-enhanced convolution for
boundary-aware feature extraction, a cross-stage dual-domain multi-scale
attention module to jointly capture global and local information, and a
Focaler-Wise-SIoU regression loss to improve localization of small objects.
Experiments conducted on the CSG-ADCD dataset demonstrate that TinyDef-DETR
achieves substantial improvements in both precision and recall compared to
competitive baselines, with particularly notable gains on small-object subsets,
while incurring only modest computational overhead. Further validation on the
VisDrone benchmark confirms the generalization capability of the proposed
approach. Overall, the results indicate that integrating detail-preserving
downsampling, edge-sensitive representations, dual-domain attention, and
difficulty-adaptive regression provides a practical and efficient solution for
UAV-based small-defect inspection in power grids.

</details>


### [85] [BranchGRPO: Stable and Efficient GRPO with Structured Branching in Diffusion Models](https://arxiv.org/abs/2509.06040)
*Yuming Li,Yikai Wang,Yuying Zhu,Zhongyu Zhao,Ming Lu,Qi She,Shanghang Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为BranchGRPO的新方法，大幅降低了图像与视频生成模型对齐训练的计算开销，同时提升了对人类偏好的适应能力和训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于GRPO的方法虽然在人类偏好对齐上取得突破，但在采样与训练过程中的计算成本高、奖励稀疏导致训练不稳定，仍严重制约实际应用。

Method: BranchGRPO引入了分支采样策略，通过共享公共前缀计算、剪枝低奖励路径及冗余深度，显著降低每次更新的计算量。同时提出树状优势估计器与剪枝策略，提高学习密度、加快收敛。

Result: 实验表明，BranchGRPO在图像和视频偏好对齐任务上，相较强基线方法提升了16%的对齐分数，训练耗时缩短一半。

Conclusion: BranchGRPO有效缓解了高算力与训练不稳定问题，在保持甚至提升探索多样性的同时，提高了人类偏好对齐能力，并极大改善了模型的训练效率。

Abstract: Recent advancements in aligning image and video generative models via GRPO
have achieved remarkable gains in enhancing human preference alignment.
However, these methods still face high computational costs from on-policy
rollouts and excessive SDE sampling steps, as well as training instability due
to sparse rewards. In this paper, we propose BranchGRPO, a novel method that
introduces a branch sampling policy updating the SDE sampling process. By
sharing computation across common prefixes and pruning low-reward paths and
redundant depths, BranchGRPO substantially lowers the per-update compute cost
while maintaining or improving exploration diversity. This work makes three
main contributions: (1) a branch sampling scheme that reduces rollout and
training cost; (2) a tree-based advantage estimator incorporating dense
process-level rewards; and (3) pruning strategies exploiting path and depth
redundancy to accelerate convergence and boost performance. Experiments on
image and video preference alignment show that BranchGRPO improves alignment
scores by 16% over strong baselines, while cutting training time by 50%.

</details>


### [86] [Multi-Stage Graph Neural Networks for Data-Driven Prediction of Natural Convection in Enclosed Cavities](https://arxiv.org/abs/2509.06041)
*Mohammad Ahangarkiasari,Hassan Pouraria*

Main category: cs.CV

TL;DR: 本文提出了一种多阶段图神经网络（GNN）架构，用于提升复杂流体动力学仿真中的热传导预测能力，并在高保真CFD自然对流数据集上取得了优于现有GNN方法的效果。


<details>
  <summary>Details</summary>
Motivation: 传统的CFD（计算流体动力学）仿真虽精度高，但依赖专家设计模型、精细网格和大量算力，难以快速迭代。数据驱动建模（如GNN）虽有潜力，但常规GNN在高分辨率网格上难以建模长距离依赖关系，这成为当前的瓶颈。

Method: 作者设计了一种新的多阶段GNN结构，结合分层池化（pooling）和反池化（unpooling）操作，能够渐进式地在不同空间尺度间建模全局到局部的信息交互。方法在矩形腔体自然对流CFD仿真数据集上进行实验评估。

Result: 提出的方法比现有最先进GNN基线模型，在预测准确率、训练效率和长期误差累积三个方面均表现更优。

Conclusion: 多阶段GNN方法能更好地捕捉热流体场景中的空间多尺度依赖，有望显著提升基于网格的热传导CFD仿真建模效果，加速相关工程设计进程。

Abstract: Buoyancy-driven heat transfer in closed cavities serves as a canonical
testbed for thermal design High-fidelity CFD modelling yields accurate thermal
field solutions, yet its reliance on expert-crafted physics models, fine
meshes, and intensive computation limits rapid iteration. Recent developments
in data-driven modeling, especially Graph Neural Networks (GNNs), offer new
alternatives for learning thermal-fluid behavior directly from simulation data,
particularly on irregular mesh structures. However, conventional GNNs often
struggle to capture long-range dependencies in high-resolution graph
structures. To overcome this limitation, we propose a novel multi-stage GNN
architecture that leverages hierarchical pooling and unpooling operations to
progressively model global-to-local interactions across multiple spatial
scales. We evaluate the proposed model on our newly developed CFD dataset
simulating natural convection within a rectangular cavities with varying aspect
ratios where the bottom wall is isothermal hot, the top wall is isothermal
cold, and the two vertical walls are adiabatic. Experimental results
demonstrate that the proposed model achieves higher predictive accuracy,
improved training efficiency, and reduced long-term error accumulation compared
to state-of-the-art (SOTA) GNN baselines. These findings underscore the
potential of the proposed multi-stage GNN approach for modeling complex heat
transfer in mesh-based fluid dynamics simulations.

</details>


### [87] [Home-made Diffusion Model from Scratch to Hatch](https://arxiv.org/abs/2509.06068)
*Shih-Ying Yeh*

Main category: cs.CV

TL;DR: 本文提出了一种高效的文本到图像扩散模型（HDM），可以在普通消费级硬件上以较低成本训练并生成高质量的1024x1024图像，性能和主流方案接近。


<details>
  <summary>Details</summary>
Motivation: 当前高质量文本到图像扩散模型训练和推理成本极高，普通研究者和中小型组织难以负担。如何以更低成本获得高质量生成效果，成为亟需解决的问题。

Method: 1. 提出Cross-U-Transformer（XUT），利用跨注意力引入skip connection，实现更优的特征融合和画面一致性；2. 训练方案包含TREAD加速、shifted square crop以支持任意长宽比高效训练、分阶段分辨率提升等；3. 构建343M参数小模型，架构设计精巧，提升表现。

Result: 在仅用4块RTX5090 GPU、花费约$535-620，就能训练出质量媲美主流大模型（1024x1024分辨率）的生成模型，小模型还展现出如相机控制的潜在能力。

Conclusion: 本文模型降低了高质量扩散模型的资源和资金门槛，为更广泛的学术及行业团体提供了新思路，推动了高质量文本到图像生成的普及。

Abstract: We introduce Home-made Diffusion Model (HDM), an efficient yet powerful
text-to-image diffusion model optimized for training (and inferring) on
consumer-grade hardware. HDM achieves competitive 1024x1024 generation quality
while maintaining a remarkably low training cost of $535-620 using four RTX5090
GPUs, representing a significant reduction in computational requirements
compared to traditional approaches. Our key contributions include: (1)
Cross-U-Transformer (XUT), a novel U-shape transformer, Cross-U-Transformer
(XUT), that employs cross-attention for skip connections, providing superior
feature integration that leads to remarkable compositional consistency; (2) a
comprehensive training recipe that incorporates TREAD acceleration, a novel
shifted square crop strategy for efficient arbitrary aspect-ratio training, and
progressive resolution scaling; and (3) an empirical demonstration that smaller
models (343M parameters) with carefully crafted architectures can achieve
high-quality results and emergent capabilities, such as intuitive camera
control. Our work provides an alternative paradigm of scaling, demonstrating a
viable path toward democratizing high-quality text-to-image generation for
individual researchers and smaller organizations with limited computational
resources.

</details>


### [88] [High-Quality Tomographic Image Reconstruction Integrating Neural Networks and Mathematical Optimization](https://arxiv.org/abs/2509.06082)
*Anuraag Mishra,Andrea Gilch,Benjamin Apeleo Zubiri,Jan Rolfes,Frauke Liers*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的重建技术，可提升纳米和微型层析成像中的图像质量，特别是针对具有清晰边界的同质材料样本。通过神经网络识别边缘并嵌入优化模型，显著提高了重建的清晰度和同质性。


<details>
  <summary>Details</summary>
Motivation: 现有纳米/微层析图像重建方法在处理有锐利边缘的同质材料时，往往会产生模糊或伪影。希望利用深度学习与优化相结合，提升边缘清晰度和样本同质性。

Method: 首先利用神经网络对子图像进行边缘识别训练，再将该网络集成进数学优化模型，使优化过程中优先保持网络预测的边缘信息，如有必要也可根据原始数据调整，从而减少伪影和模糊。

Result: 在实验数据集上，方法在边界锐度和材料区域同质性方面，相比传统基线算法有显著提升，重建的图像质量更高。

Conclusion: 该技术有效引入了关于边界和同质性的先验知识，去除了模糊，提升了图像重建质量，对层析成像领域具有较大应用潜力。

Abstract: In this work, we develop a novel technique for reconstructing images from
projection-based nano- and microtomography. Our contribution focuses on
enhancing reconstruction quality, particularly for specimen composed of
homogeneous material phases connected by sharp edges. This is accomplished by
training a neural network to identify edges within subpictures. The trained
network is then integrated into a mathematical optimization model, to reduce
artifacts from previous reconstructions. To this end, the optimization approach
favors solutions according to the learned predictions, however may also
determine alternative solutions if these are strongly supported by the raw
data. Hence, our technique successfully incorporates knowledge about the
homogeneity and presence of sharp edges in the sample and thereby eliminates
blurriness. Our results on experimental datasets show significant enhancements
in interface sharpness and material homogeneity compared to benchmark
algorithms. Thus, our technique produces high-quality reconstructions,
showcasing its potential for advancing tomographic imaging techniques.

</details>


### [89] [MedSeqFT: Sequential Fine-tuning Foundation Models for 3D Medical Image Segmentation](https://arxiv.org/abs/2509.06096)
*Yiwen Ye,Yicheng Wu,Xiangde Luo,He Zhang,Ziyang Chen,Ting Dang,Yanning Zhang,Yong Xia*

Main category: cs.CV

TL;DR: 本文提出了一种名为MedSeqFT的顺序微调框架，用于将基础模型应用于医学图像分割任务，并解决现有微调方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前基础模型在医学图像分析领域表现突出，但现有微调方法要么仅针对单一任务且忽略知识共享（并行微调），要么需同时访问所有任务数据且难以增量集成新任务（多任务微调），不适用于实际临床中任务逐步演化的情景。

Method: 作者提出MedSeqFT顺序微调框架，包括两个核心组成：1）最大数据相似性（MDS）选择，从下游样本中筛选与预训练分布最相似的数据帮助保持泛化知识；2）知识与泛化保持微调（K&G RFT），基于LoRA的知识蒸馏方案，在适应新任务的同时保留预训练模型的知识。

Result: 在包含十个3D分割任务的两个多任务数据集上，MedSeqFT在性能上优于主流微调方法，平均Dice得分提升3.0%。在两个未见任务（COVID-19-20和Kidney）上，也表现出更强的可迁移性，特别是在肿瘤分割方面。可视化分析（损失景观、参数变化）也表明其鲁棒性。

Conclusion: MedSeqFT为临床中不断变化任务的基础模型适配提供了一种高效且保留知识的顺序微调新范式，优于现有方法。

Abstract: Foundation models have become a promising paradigm for advancing medical
image analysis, particularly for segmentation tasks where downstream
applications often emerge sequentially. Existing fine-tuning strategies,
however, remain limited: parallel fine-tuning isolates tasks and fails to
exploit shared knowledge, while multi-task fine-tuning requires simultaneous
access to all datasets and struggles with incremental task integration. To
address these challenges, we propose MedSeqFT, a sequential fine-tuning
framework that progressively adapts pre-trained models to new tasks while
refining their representational capacity. MedSeqFT introduces two core
components: (1) Maximum Data Similarity (MDS) selection, which identifies
downstream samples most representative of the original pre-training
distribution to preserve general knowledge, and (2) Knowledge and
Generalization Retention Fine-Tuning (K&G RFT), a LoRA-based knowledge
distillation scheme that balances task-specific adaptation with the retention
of pre-trained knowledge. Extensive experiments on two multi-task datasets
covering ten 3D segmentation tasks demonstrate that MedSeqFT consistently
outperforms state-of-the-art fine-tuning strategies, yielding substantial
performance gains (e.g., an average Dice improvement of 3.0%). Furthermore,
evaluations on two unseen tasks (COVID-19-20 and Kidney) verify that MedSeqFT
enhances transferability, particularly for tumor segmentation. Visual analyses
of loss landscapes and parameter variations further highlight the robustness of
MedSeqFT. These results establish sequential fine-tuning as an effective,
knowledge-retentive paradigm for adapting foundation models to evolving
clinical tasks. Code will be released.

</details>


### [90] [PathoHR: Hierarchical Reasoning for Vision-Language Models in Pathology](https://arxiv.org/abs/2509.06105)
*Yating Huang,Ziyan Huang,Lintao Xiang,Qijun Yang,Hujun Yin*

Main category: cs.CV

TL;DR: 本文针对病理图像自动化分析难题，提出了新的评测基准PathoHR-Bench和针对性的视觉—语言训练方案，使模型在复杂病理语义理解和推理任务上取得了更好表现。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型难以处理病理图像中高度结构相似和细微形态差异，同时无法有效理解和推理复杂的病理报告结构，限制了其在临床中的应用。需要新的基准和方法推动该领域发展。

Method: 作者提出了PathoHR-Bench新基准，专为测试视觉-语言模型在病理学领域的层次语义理解和组合推理能力而设计。此外，作者还引入了适用于病理的视觉-语言训练方案，通过生成增强和扰动样本进行多模态对比学习，提升模型表现。

Result: 实验结果显示，当前主流的视觉-语言模型在PathoHR-Bench上表现不佳，无法有效建模复杂的跨模态关系。采用作者新提出的训练方案后，不仅在PathoHR-Bench上达到最新最好成绩，也在六个其它病理数据集上取得了领先表现。

Conclusion: PathoHR-Bench有效揭示和量化了视觉-语言模型在病理领域的不足。结合针对性的训练方法，能够显著提升模型在细粒度病理表征和复杂推理任务中的表现，对自动化肿瘤诊断和病理辅助分析具有重要意义。

Abstract: Accurate analysis of pathological images is essential for automated tumor
diagnosis but remains challenging due to high structural similarity and subtle
morphological variations in tissue images. Current vision-language (VL) models
often struggle to capture the complex reasoning required for interpreting
structured pathological reports. To address these limitations, we propose
PathoHR-Bench, a novel benchmark designed to evaluate VL models' abilities in
hierarchical semantic understanding and compositional reasoning within the
pathology domain. Results of this benchmark reveal that existing VL models fail
to effectively model intricate cross-modal relationships, hence limiting their
applicability in clinical setting. To overcome this, we further introduce a
pathology-specific VL training scheme that generates enhanced and perturbed
samples for multimodal contrastive learning. Experimental evaluations
demonstrate that our approach achieves state-of-the-art performance on
PathoHR-Bench and six additional pathology datasets, highlighting its
effectiveness in fine-grained pathology representation.

</details>


### [91] [CARDIE: clustering algorithm on relevant descriptors for image enhancement](https://arxiv.org/abs/2509.06116)
*Giulia Bonino,Luca Alberto Rizzo*

Main category: cs.CV

TL;DR: 本论文提出了一种名为CARDIE的无监督图像聚类算法，通过色彩和亮度进行聚类，以提升图像增强相关任务。


<details>
  <summary>Details</summary>
Motivation: 现有自动图像聚类方法在图像增强领域应用有限，主要原因在于难以为增强任务定义有意义的聚类方式。

Method: 提出CARDIE无监督图像聚类算法，依据图像的颜色和亮度内容对其分类。此外，引入了一种评估图像增强算法对亮度分布和局部方差影响的新方法。

Result: 实验显示，CARDIE聚类结果比基于语义属性的聚类在图像增强领域更相关。利用CARDIE聚类重采样增强数据集，进一步提升了tone mapping（色调映射）和去噪等算法的表现。

Conclusion: CARDIE能生成更适合图像增强的聚类结果，并能提升相关算法性能，且代码已开源，推动该方向研究发展。

Abstract: Automatic image clustering is a cornerstone of computer vision, yet its
application to image enhancement remains limited, primarily due to the
difficulty of defining clusters that are meaningful for this specific task. To
address this issue, we introduce CARDIE, an unsupervised algorithm that
clusters images based on their color and luminosity content. In addition, we
introduce a method to quantify the impact of image enhancement algorithms on
luminance distribution and local variance. Using this method, we demonstrate
that CARDIE produces clusters more relevant to image enhancement than those
derived from semantic image attributes. Furthermore, we demonstrate that CARDIE
clusters can be leveraged to resample image enhancement datasets, leading to
improved performance for tone mapping and denoising algorithms. To encourage
adoption and ensure reproducibility, we publicly release CARDIE code on our
GitHub.

</details>


### [92] [SpecSwin3D: Generating Hyperspectral Imagery from Multispectral Data via Transformer Networks](https://arxiv.org/abs/2509.06122)
*Tang Sui,Songxi Yang,Qunying Huang*

Main category: cs.CV

TL;DR: 该论文提出了一种基于Transformer的新方法SpecSwin3D，实现了从多光谱图像高质量重建高光谱图像，极大提升了空间和光谱的保真度，在多个评测指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多光谱与高光谱图像各有优劣：多光谱空间分辨率高但光谱分辨率低，高光谱则相反。现有高光谱重建方法难以兼顾二者，因此亟需提升保真度的新方法。

Method: 提出SpecSwin3D模型，利用3D Shifted-Window Transformer结构，从5个多光谱波段重建224个高光谱波段，保持空间分辨率。同时引入级联训练策略，优化波段顺序和多光谱波段的重复排列，提升远离输入波段的重建质量和模型鲁棒性。

Result: SpecSwin3D在PSNR（35.82 dB）、SAM（2.40°）、SSIM（0.96）等指标上显著优于现有MHF-Net（PSNR提升5.6 dB以上，ERGAS减半），并能提升下游如土地利用分类、火烧区域分割等任务的性能。

Conclusion: SpecSwin3D显著提升了多光谱到高光谱生成的空间和光谱质量，具备良好的实际应用潜力，可用于遥感、农业等多个领域。

Abstract: Multispectral and hyperspectral imagery are widely used in agriculture,
environmental monitoring, and urban planning due to their complementary spatial
and spectral characteristics. A fundamental trade-off persists: multispectral
imagery offers high spatial but limited spectral resolution, while
hyperspectral imagery provides rich spectra at lower spatial resolution. Prior
hyperspectral generation approaches (e.g., pan-sharpening variants, matrix
factorization, CNNs) often struggle to jointly preserve spatial detail and
spectral fidelity. In response, we propose SpecSwin3D, a transformer-based
model that generates hyperspectral imagery from multispectral inputs while
preserving both spatial and spectral quality. Specifically, SpecSwin3D takes
five multispectral bands as input and reconstructs 224 hyperspectral bands at
the same spatial resolution. In addition, we observe that reconstruction errors
grow for hyperspectral bands spectrally distant from the input bands. To
address this, we introduce a cascade training strategy that progressively
expands the spectral range to stabilize learning and improve fidelity.
Moreover, we design an optimized band sequence that strategically repeats and
orders the five selected multispectral bands to better capture pairwise
relations within a 3D shifted-window transformer framework. Quantitatively, our
model achieves a PSNR of 35.82 dB, SAM of 2.40{\deg}, and SSIM of 0.96,
outperforming the baseline MHF-Net by +5.6 dB in PSNR and reducing ERGAS by
more than half. Beyond reconstruction, we further demonstrate the practical
value of SpecSwin3D on two downstream tasks, including land use classification
and burnt area segmentation.

</details>


### [93] [RetinaGuard: Obfuscating Retinal Age in Fundus Images for Biometric Privacy Preserving](https://arxiv.org/abs/2509.06142)
*Zhengquan Luo,Chi Liu,Dongfu Xiao,Zhen Yu,Yueye Wang,Tianqing Zhu*

Main category: cs.CV

TL;DR: 本文提出了RetinaGuard，一种提升医学图像隐私保护的新框架，可以在保护视网膜年龄等敏感信息的同时，保持图像质量和疾病诊断的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着AI通过医学图像提取隐含生物标志物（例如视网膜年龄）的能力提高，虽然有助于健康评估，但也带来了严重的隐私风险，可能导致个人敏感生物信息泄露。因此，亟需针对医学图像中的生物识别数据保护提出新的隐私增强方案。

Method: 作者提出了RetinaGuard框架，利用特征级对抗生成掩蔽方法屏蔽视网膜年龄信息，且不损失视觉质量和诊断能力。此外，采用结合视网膜基础模型及多样化代理年龄编码器的多对一知识蒸馏策略，有效防御黑盒年龄预测模型攻击，提升通用性和稳健性。

Result: 实验结果表明，RetinaGuard能显著削弱视网膜年龄预测能力，同时对图像质量和致病特征保留影响极小，效果优良。此外，该方法可灵活扩展至其他医学影像生物标志物的保护。

Conclusion: RetinaGuard为医学图像中敏感生物特征（如年龄）隐私保护提供了一种全新的高效工具，并具有良好扩展性和广泛的医疗应用前景。

Abstract: The integration of AI with medical images enables the extraction of implicit
image-derived biomarkers for a precise health assessment. Recently, retinal
age, a biomarker predicted from fundus images, is a proven predictor of
systemic disease risks, behavioral patterns, aging trajectory and even
mortality. However, the capability to infer such sensitive biometric data
raises significant privacy risks, where unauthorized use of fundus images could
lead to bioinformation leakage, breaching individual privacy. In response, we
formulate a new research problem of biometric privacy associated with medical
images and propose RetinaGuard, a novel privacy-enhancing framework that
employs a feature-level generative adversarial masking mechanism to obscure
retinal age while preserving image visual quality and disease diagnostic
utility. The framework further utilizes a novel multiple-to-one knowledge
distillation strategy incorporating a retinal foundation model and diverse
surrogate age encoders to enable a universal defense against black-box age
prediction models. Comprehensive evaluations confirm that RetinaGuard
successfully obfuscates retinal age prediction with minimal impact on image
quality and pathological feature representation. RetinaGuard is also flexible
for extension to other medical image derived biomarkers. RetinaGuard is also
flexible for extension to other medical image biomarkers.

</details>


### [94] [UniVerse-1: Unified Audio-Video Generation via Stitching of Experts](https://arxiv.org/abs/2509.06155)
*Duomin Wang,Wei Zuo,Aojie Li,Ling-Hao Chen,Xinyao Liao,Deyu Zhou,Zixin Yin,Xili Dai,Daxin Jiang,Gang Yu*

Main category: cs.CV

TL;DR: UniVerse-1 是一种类似 Veo-3 的统一音视频生成模型，通过深度融合预训练的音频和视频专家模型，实现高效的多媒体生成，并发布了新基准数据集和代码。


<details>
  <summary>Details</summary>
Motivation: 当前音视频生成模型在生成协调一致的音视频内容上存在挑战，且纯基于文本注释的数据会引入错误和时序不一致。本文为提升模型能力与效率，解决标签失配和音视频协调性问题。

Method: 采用 stitching of experts（SoE）方法，将预训练的视频与音乐生成模型在关键模块深度融合，避免从零训练。开发了在线注释流水线，动态生成对齐的音频-视频标签以消除文本注释误差，利用约7600小时数据进行微调。

Result: 模型能输出高协调的环境音音视生成效果，以及强一致性的语音与视频内容。还提出了评测基准 Verse-Bench，并通过实验展示模型在音视频同步与质量上的优越性。

Conclusion: UniVerse-1 提高了音视频生成的质量和一致性，有望推动多模态生成领域发展，并通过开放模型代码促进社区研究进步。

Abstract: We introduce UniVerse-1, a unified, Veo-3-like model capable of
simultaneously generating coordinated audio and video. To enhance training
efficiency, we bypass training from scratch and instead employ a stitching of
experts (SoE) technique. This approach deeply fuses the corresponding blocks of
pre-trained video and music generation experts models, thereby fully leveraging
their foundational capabilities. To ensure accurate annotations and temporal
alignment for both ambient sounds and speech with video content, we developed
an online annotation pipeline that processes the required training data and
generates labels during training process. This strategy circumvents the
performance degradation often caused by misalignment text-based annotations.
Through the synergy of these techniques, our model, after being finetuned on
approximately 7,600 hours of audio-video data, produces results with
well-coordinated audio-visuals for ambient sounds generation and strong
alignment for speech generation. To systematically evaluate our proposed
method, we introduce Verse-Bench, a new benchmark dataset. In an effort to
advance research in audio-video generation and to close the performance gap
with state-of-the-art models such as Veo3, we make our model and code publicly
available. We hope this contribution will benefit the broader research
community. Project page: https://dorniwang.github.io/UniVerse-1/.

</details>


### [95] [UNO: Unifying One-stage Video Scene Graph Generation via Object-Centric Visual Representation Learning](https://arxiv.org/abs/2509.06165)
*Huy Le,Nhat Chung,Tung Kieu,Jingkang Yang,Ngan Le*

Main category: cs.CV

TL;DR: 该论文提出了UNO，一个统一的视频场景图生成（VidSGG）框架，能在单阶段端到端地同时处理粗粒度和细粒度任务，并在主流基准上展现了高效且有竞争力的表现。


<details>
  <summary>Details</summary>
Motivation: 以往VidSGG方法多针对不同粒度的任务（如框级、像素级）分别设计，导致需不同的架构和繁琐的多阶段训练，缺乏统一、高效的解决方案。

Method: 提出UNO框架，通过扩展的slot attention机制，将视觉特征分解为对象槽和关系槽，同时采用对象时序一致性学习确保跨帧对象表征一致，无需显式跟踪；关系预测模块动态关联关系槽与对象对，捕获时变互动。整体为单阶段、端到端、参数共享设计。

Result: 在标准的框级和像素级VidSGG基准上，UNO都获得了有竞争力的性能，并由于统一的设计提升了效率。

Conclusion: UNO实现了不同粒度任务的统一建模，不仅性能优良，也减少了任务专属改造和训练复杂度，为动态视觉内容的结构化表征提供了高效新方案。

Abstract: Video Scene Graph Generation (VidSGG) aims to represent dynamic visual
content by detecting objects and modeling their temporal interactions as
structured graphs. Prior studies typically target either coarse-grained
box-level or fine-grained panoptic pixel-level VidSGG, often requiring
task-specific architectures and multi-stage training pipelines. In this paper,
we present UNO (UNified Object-centric VidSGG), a single-stage, unified
framework that jointly addresses both tasks within an end-to-end architecture.
UNO is designed to minimize task-specific modifications and maximize parameter
sharing, enabling generalization across different levels of visual granularity.
The core of UNO is an extended slot attention mechanism that decomposes visual
features into object and relation slots. To ensure robust temporal modeling, we
introduce object temporal consistency learning, which enforces consistent
object representations across frames without relying on explicit tracking
modules. Additionally, a dynamic triplet prediction module links relation slots
to corresponding object pairs, capturing evolving interactions over time. We
evaluate UNO on standard box-level and pixel-level VidSGG benchmarks. Results
demonstrate that UNO not only achieves competitive performance across both
tasks but also offers improved efficiency through a unified, object-centric
design.

</details>


### [96] [AI-Based Applied Innovation for Fracture Detection in X-rays Using Custom CNN and Transfer Learning Models](https://arxiv.org/abs/2509.06228)
*Amna Hassan,Ilsa Afzaal,Nouman Muneeb,Aneeqa Batool,Hamail Noor*

Main category: cs.CV

TL;DR: 本文提出了一种基于定制卷积神经网络（CNN）的人工智能方法，可自动从X光片中检测骨折，并在公开的FracAtlas数据集上获得了95.96%的高准确率。部分迁移学习模型虽表现一般，但受限于数据集不平衡和样本局限。


<details>
  <summary>Details</summary>
Motivation: 骨折检测在全球范围内尤其在资源有限地区是重大健康挑战，传统影像诊断方法成本高、辐射大且依赖专家解释。作者旨在开发一种高效、低成本且可自动检测骨折的AI工具，以改善骨折诊疗的可及性和效率。

Method: 研究采用了定制的CNN模型用于X光片骨折检测，并与EfficientNetB0、MobileNetV2、ResNet50等迁移学习模型进行基准测试。数据来源为FracAtlas公开数据集（4,083张去标识化肌骨系统X光片），并通过对比各模型在该数据集上的表现进行分析。

Result: 定制CNN在FracAtlas数据集上实现了95.96%的准确率、0.94的精度、0.88的召回率和0.91的F1分数。相比之下，采用迁移学习的模型效果较差，这可能受数据集类别不平衡和局限性影响。

Conclusion: 轻量化的CNN在X光片骨折检测方面具有巨大应用潜力，但要实现临床应用，还需重视数据集多样性、公平基准测试及外部验证。

Abstract: Bone fractures present a major global health challenge, often resulting in
pain, reduced mobility, and productivity loss, particularly in low-resource
settings where access to expert radiology services is limited. Conventional
imaging methods suffer from high costs, radiation exposure, and dependency on
specialized interpretation. To address this, we developed an AI-based solution
for automated fracture detection from X-ray images using a custom Convolutional
Neural Network (CNN) and benchmarked it against transfer learning models
including EfficientNetB0, MobileNetV2, and ResNet50. Training was conducted on
the publicly available FracAtlas dataset, comprising 4,083 anonymized
musculoskeletal radiographs. The custom CNN achieved 95.96% accuracy, 0.94
precision, 0.88 recall, and an F1-score of 0.91 on the FracAtlas dataset.
Although transfer learning models (EfficientNetB0, MobileNetV2, ResNet50)
performed poorly in this specific setup, these results should be interpreted in
light of class imbalance and data set limitations. This work highlights the
promise of lightweight CNNs for detecting fractures in X-rays and underscores
the importance of fair benchmarking, diverse datasets, and external validation
for clinical translation

</details>


### [97] [Exploring Light-Weight Object Recognition for Real-Time Document Detection](https://arxiv.org/abs/2509.06246)
*Lucas Wojcik,Luiz Coelho,Roger Granada,David Menotti*

Main category: cs.CV

TL;DR: 本文提出了一种高效的文档检测和校正流程，将IWPOD-Net模型应用于身份证等文档检测任务，结合OCR实现自动信息提取，并在效率与准确度上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统文档检测与矫正主要关注于模型性能提升（大模型）或效率改进（小模型），但针对实时文档检测矫正这一实际需求领域仍研究不足。本文旨在填补该空白，实现更快且OCR提取效果优良的文档检测流程，促进自动信息检索。

Method: 主要做法是将原本用于检测车牌的IWPOD-Net模型改编，训练于NBID合成身份证数据集，通过数据增强和跨数据集（MIDV）验证，寻找最佳训练方案。借助多种现有目标识别和倾斜矫正方法作对比，用每种方法对文档检测与校正后，由OCR系统识别文本，并应用基于Levenshtein距离的新型OCR质量度量作为性能评价。

Result: 实验表明，所提出的方法即使文档矫正不尽完美，依然能获得业界先进水准的OCR质量得分。在模型规模和运行效率上显著优于现有方法，同时保持有竞争力的文本识别质量。

Conclusion: 提出的小型高效模型能够在保证OCR提取质量的同时，显著提升检测速度，为实时文档自动化处理提供更优解决方案，适用于大规模部署应用。

Abstract: Object Recognition and Document Skew Estimation have come a long way in terms
of performance and efficiency. New models follow one of two directions:
improving performance using larger models, and improving efficiency using
smaller models. However, real-time document detection and rectification is a
niche that is largely unexplored by the literature, yet it remains a vital step
for automatic information retrieval from visual documents. In this work, we
strive towards an efficient document detection pipeline that is satisfactory in
terms of Optical Character Recognition (OCR) retrieval and faster than other
available solutions. We adapt IWPOD-Net, a license plate detection network, and
train it for detection on NBID, a synthetic ID card dataset. We experiment with
data augmentation and cross-dataset validation with MIDV (another synthetic ID
and passport document dataset) to find the optimal scenario for the model.
Other methods from both the Object Recognition and Skew Estimation
state-of-the-art are evaluated for comparison with our approach. We use each
method to detect and rectify the document, which is then read by an OCR system.
The OCR output is then evaluated using a novel OCR quality metric based on the
Levenshtein distance. Since the end goal is to improve automatic information
retrieval, we use the overall OCR quality as a performance metric. We observe
that with a promising model, document rectification does not have to be perfect
to attain state-of-the-art performance scores. We show that our model is
smaller and more efficient than current state-of-the-art solutions while
retaining a competitive OCR quality metric. All code is available at
https://github.com/BOVIFOCR/iwpod-doc-corners.git

</details>


### [98] [Spatial Reasoning with Vision-Language Models in Ego-Centric Multi-View Scenes](https://arxiv.org/abs/2509.06266)
*Mohsen Gholami,Ahmad Rezaei,Zhou Weimin,Yong Zhang,Mohammad Akbari*

Main category: cs.CV

TL;DR: 论文介绍了Ego3D-Bench，一个用于评估视觉语言模型（VLMs）三维空间推理能力的新基准。此外，提出了Ego3D-VLM后训练框架，有效提升了VLMs的空间理解表现。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs在三维空间理解方面能力有限，而实际应用如机器人和自动驾驶通常需要多视角、第一视角的空间推理。现有数据集多以单图像或室内视频为主，缺乏适用于真实场景、多视角的基准。

Method: 构建了Ego3D-Bench——一个基于室外、多视角、第一视角观测的大型问题答案（QA）数据集，含8600+QA对，质量和多样性由人工标注保证。同时评测了16款SOTA VLMs。进一步提出Ego3D-VLM，通过生成基于全球三维坐标的认知地图提升VLM的3D空间推理能力，且该方法可模块化集成至任意VLM中。

Result: 在Ego3D-Bench上的基准测试显示，当前VLM距离人类空间理解能力仍有较大差距。加入Ego3D-VLM后，VLM在多项选择QA提升12%，在绝对距离估计提升56%。

Conclusion: Ego3D-Bench为评估和提升VLM在复杂三维、多视角环境中的空间推理能力提供了标准平台。Ego3D-VLM能显著改进空间理解，有助于VLMs朝人类水平发展。

Abstract: Understanding 3D spatial relationships remains a major limitation of current
Vision-Language Models (VLMs). Prior work has addressed this issue by creating
spatial question-answering (QA) datasets based on single images or indoor
videos. However, real-world embodied AI agents such as robots and self-driving
cars typically rely on ego-centric, multi-view observations. To this end, we
introduce Ego3D-Bench, a new benchmark designed to evaluate the spatial
reasoning abilities of VLMs using ego-centric, multi-view outdoor data.
Ego3D-Bench comprises over 8,600 QA pairs, created with significant involvement
from human annotators to ensure quality and diversity. We benchmark 16 SOTA
VLMs, including GPT-4o, Gemini1.5-Pro, InternVL3, and Qwen2.5-VL. Our results
reveal a notable performance gap between human level scores and VLM
performance, highlighting that current VLMs still fall short of human level
spatial understanding. To bridge this gap, we propose Ego3D-VLM, a
post-training framework that enhances 3D spatial reasoning of VLMs. Ego3D-VLM
generates cognitive map based on estimated global 3D coordinates, resulting in
12% average improvement on multi-choice QA and 56% average improvement on
absolute distance estimation. Ego3D-VLM is modular and can be integrated with
any existing VLM. Together, Ego3D-Bench and Ego3D-VLM offer valuable tools for
advancing toward human level spatial understanding in real-world, multi-view
environments.

</details>


### [99] [AI-driven Remote Facial Skin Hydration and TEWL Assessment from Selfie Images: A Systematic Solution](https://arxiv.org/abs/2509.06282)
*Cecelia Soh,Rizhao Cai,Monalisha Paul,Dennis Sng,Alex Kot*

Main category: cs.CV

TL;DR: 本文提出了一种利用智能手机自拍照远程估算皮肤水合度（SH）和经皮水分流失（TEWL）的AI方法，使普通用户无需专业仪器即可进行皮肤健康评估。


<details>
  <summary>Details</summary>
Motivation: 皮肤屏障功能直接影响皮肤健康和疾病抵抗力。SH和TEWL是衡量皮肤屏障功能的重要指标，但测量通常需要专业设备，限制了大众的日常监测和个性化护肤。为了解决大众获取这些指标不便的问题，论文提出利用计算机视觉技术从自拍图像估算SH和TEWL。

Method: 本研究设计了一个系统方案，包括SH/TEWL数据采集与预处理，开发了一种新的基于视觉Transformer的Skin-Prior Adaptive模型进行回归预测。同时，研究发现数据标注不均衡会带来模型偏差，提出了一种基于对称的对比正则化方法以缓解该问题。

Result: 通过实验验证，所提出的方法能够在自拍人脸图像上有效地估算SH和TEWL，并且对比正则化能够减小由数据不平衡带来的模型偏差。

Conclusion: 本研究首次实现了无需物理仪器、仅通过自拍图像进行皮肤健康评估的方法，推动了计算机视觉与皮肤护理领域的融合，为大众提供了便捷可及的AI驱动皮肤分析解决方案。

Abstract: Skin health and disease resistance are closely linked to the skin barrier
function, which protects against environmental factors and water loss. Two key
physiological indicators can quantitatively represent this barrier function:
skin hydration (SH) and trans-epidermal water loss (TEWL). Measurement of SH
and TEWL is valuable for the public to monitor skin conditions regularly,
diagnose dermatological issues, and personalize their skincare regimens.
However, these measurements are not easily accessible to general users unless
they visit a dermatology clinic with specialized instruments. To tackle this
problem, we propose a systematic solution to estimate SH and TEWL from selfie
facial images remotely with smartphones. Our solution encompasses multiple
stages, including SH/TEWL data collection, data preprocessing, and formulating
a novel Skin-Prior Adaptive Vision Transformer model for SH/TEWL regression.
Through experiments, we identified the annotation imbalance of the SH/TEWL data
and proposed a symmetric-based contrastive regularization to reduce the model
bias due to the imbalance effectively. This work is the first study to explore
skin assessment from selfie facial images without physical measurements. It
bridges the gap between computer vision and skin care research, enabling
AI-driven accessible skin analysis for broader real-world applications.

</details>


### [100] [Prototype-Aware Multimodal Alignment for Open-Vocabulary Visual Grounding](https://arxiv.org/abs/2509.06291)
*Jiangnan Xie,Xiaolong Zheng,Liang Zheng*

Main category: cs.CV

TL;DR: 提出一种新框架PAML，旨在提升视觉指向任务在包含新类别物体场景下的表现，通过改进多模态对齐、特征融合和语义原型利用，取得了领先的实验结果。


<details>
  <summary>Details</summary>
Motivation: 现有基于transformer的视觉指向方法在涉及新类别物体(open-vocabulary)时效果显著下降，主要受限于模态对齐不足、特征融合有限及语义原型利用不充分。作者希望系统性地解决上述问题。

Method: 提出Prototype-Aware Multimodal Learning (PAML)框架：(1) 利用ALBEF提升视觉-语言对齐；(2) 设计视觉判别特征编码器，强化关键目标物体表示，抑制无关信息；(3) 引入原型发现与继承机制，聚合多邻居语义原型，有助于识别新类别；(4) 经过多阶段解码器实现深度多模态融合，输出最终定位结果。

Result: 在五个基准数据集上大量实验表明，PAML在常规场景下有竞争力表现，在包含新类别的开放场景下取得了SOTA（最新最好）结果。

Conclusion: PAML通过创新性地结合多模态对齐、特征优化与语义原型机制，显著提升了视觉指向任务在开放词汇场景下的性能，展现出优越的泛化能力。

Abstract: Visual Grounding (VG) aims to utilize given natural language queries to
locate specific target objects within images. While current transformer-based
approaches demonstrate strong localization performance in standard scene (i.e,
scenarios without any novel objects), they exhibit notable limitations in
open-vocabulary scene (i.e, both familiar and novel object categories during
testing). These limitations primarily stem from three key factors: (1)
imperfect alignment between visual and linguistic modalities, (2) insufficient
cross-modal feature fusion, and (3) ineffective utilization of semantic
prototype information. To overcome these challenges, we present Prototype-Aware
Multimodal Learning (PAML), an innovative framework that systematically
addresses these issues through several key components: First, we leverage ALBEF
to establish robust cross-modal alignment during initial feature encoding.
Subsequently, our Visual Discriminative Feature Encoder selectively enhances
salient object representations while suppressing irrelevant visual context. The
framework then incorporates a novel prototype discovering and inheriting
mechanism that extracts and aggregates multi-neighbor semantic prototypes to
facilitate open-vocabulary recognition. These enriched features undergo
comprehensive multimodal integration through our Multi-stage Decoder before
final bounding box regression. Extensive experiments across five benchmark
datasets validate our approach, showing competitive performance in standard
scene while achieving state-of-the-art results in open-vocabulary scene. Our
code is available at https://github.com/plankXie/PAML.

</details>


### [101] [Video-based Generalized Category Discovery via Memory-Guided Consistency-Aware Contrastive Learning](https://arxiv.org/abs/2509.06306)
*Zhang Jing,Pu Nan,Xie Yu Xiang,Guo Yanming,Lu Qianqi,Zou Shiwei,Yan Jie,Chen Yan*

Main category: cs.CV

TL;DR: 本文提出并定义了Video-GCD问题，旨在从视频中发现新的类别，并提出了一种新方法MCCL，有效融合时空信息，提高了新类别发现的准确性，且性能优于以往基于图像的方法。


<details>
  <summary>Details</summary>
Motivation: 现有GCD通常仅针对静态图像，难以充分挖掘新类别，而实际场景中视频包含丰富的时空信息，有助于更准确地发现新类别。因此，亟需一种能充分利用视频时序信息的GCD方法。

Method: 提出了Memory-guided Consistency-aware Contrastive Learning (MCCL) 框架，由一致性感知对比学习（CACL）和记忆引导的表示增强（MGRE）两部分组成：CACL根据时序特征计算未标注样本间的一致性，赋权对比损失；MGRE通过双层记忆缓冲区存储特征和logit信息以增强表示学习和类别可分性，两者循环互助优化。此外，构建了新的Video-GCD评测基准。

Result: 在新构建的Video-GCD基准（包括动作识别和鸟类分类视频集）上，大量实验表明，提出的方法显著优于现有的改编自图像GCD方法。

Conclusion: 时序信息对于视频中新类别的发现至关重要，MCCL方法能有效挖掘和利用时空关系，为开放世界新类别发现提供了强有力的技术手段。

Abstract: Generalized Category Discovery (GCD) is an emerging and challenging
open-world problem that has garnered increasing attention in recent years. Most
existing GCD methods focus on discovering categories in static images. However,
relying solely on static visual content is often insufficient to reliably
discover novel categories. To bridge this gap, we extend the GCD problem to the
video domain and introduce a new setting, termed Video-GCD. Thus, effectively
integrating multi-perspective information across time is crucial for accurate
Video-GCD. To tackle this challenge, we propose a novel Memory-guided
Consistency-aware Contrastive Learning (MCCL) framework, which explicitly
captures temporal-spatial cues and incorporates them into contrastive learning
through a consistency-guided voting mechanism. MCCL consists of two core
components: Consistency-Aware Contrastive Learning(CACL) and Memory-Guided
Representation Enhancement (MGRE). CACL exploits multiperspective temporal
features to estimate consistency scores between unlabeled instances, which are
then used to weight the contrastive loss accordingly. MGRE introduces a
dual-level memory buffer that maintains both feature-level and logit-level
representations, providing global context to enhance intra-class compactness
and inter-class separability. This in turn refines the consistency estimation
in CACL, forming a mutually reinforcing feedback loop between representation
learning and consistency modeling. To facilitate a comprehensive evaluation, we
construct a new and challenging Video-GCD benchmark, which includes action
recognition and bird classification video datasets. Extensive experiments
demonstrate that our method significantly outperforms competitive GCD
approaches adapted from image-based settings, highlighting the importance of
temporal information for discovering novel categories in videos. The code will
be publicly available.

</details>


### [102] [Text4Seg++: Advancing Image Segmentation via Generative Language Modeling](https://arxiv.org/abs/2509.06321)
*Mengcheng Lan,Chaofeng Chen,Jiaxing Xu,Zongrui Li,Yiping Ke,Xudong Jiang,Yingchen Yu,Yunqing Zhao,Song Bai*

Main category: cs.CV

TL;DR: 作者提出了一种将图像分割任务转化为文本生成的新方法，通过创新性的语义描述子简化了分割过程，实现了高效且通用的分割性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大模型（MLLMs）在视觉-语言任务表现优异，但如何将图像分割有效集成进这些模型仍具挑战性。传统方法往往需额外的解码器，流程复杂且效率不高。因此，急需一种简化分割流程、提升效率的创新方案。

Method: 作者提出text-as-mask范式，把图像分割转化为文本生成问题，使用语义描述子将每个图像块映射为文本标签。关键方法包括（1）图像级语义描述子，与语言建模管线自然结合；（2）提出行级游程编码（R-RLE），大幅压缩冗余文本序列，提高推理效率；（3）提出基于框的语义描述子与“语义砖块”token构建Text4Seg++，提升分割精细度和紧凑性，将分割变为预测下一个砖块任务。

Result: Text4Seg及改进后的Text4Seg++在多个自然与遥感数据集上实现了主流分割性能，无需针对某一细分任务做微调，与现有MLLM兼容。实验表明，该方法在不同基准上均优于最新模型，且推理速度大幅提升。

Conclusion: 本文提出的基于文本驱动的分割方法在效率、拓展性和通用性方面表现突出，为多模态大模型中的图像分割开辟了更简单、高效的新途径。

Abstract: Multimodal Large Language Models (MLLMs) have shown exceptional capabilities
in vision-language tasks. However, effectively integrating image segmentation
into these models remains a significant challenge. In this work, we propose a
novel text-as-mask paradigm that casts image segmentation as a text generation
problem, eliminating the need for additional decoders and significantly
simplifying the segmentation process. Our key innovation is semantic
descriptors, a new textual representation of segmentation masks where each
image patch is mapped to its corresponding text label. We first introduce
image-wise semantic descriptors, a patch-aligned textual representation of
segmentation masks that integrates naturally into the language modeling
pipeline. To enhance efficiency, we introduce the Row-wise Run-Length Encoding
(R-RLE), which compresses redundant text sequences, reducing the length of
semantic descriptors by 74% and accelerating inference by $3\times$, without
compromising performance. Building upon this, our initial framework Text4Seg
achieves strong segmentation performance across a wide range of vision tasks.
To further improve granularity and compactness, we propose box-wise semantic
descriptors, which localizes regions of interest using bounding boxes and
represents region masks via structured mask tokens called semantic bricks. This
leads to our refined model, Text4Seg++, which formulates segmentation as a
next-brick prediction task, combining precision, scalability, and generative
efficiency. Comprehensive experiments on natural and remote sensing datasets
show that Text4Seg++ consistently outperforms state-of-the-art models across
diverse benchmarks without any task-specific fine-tuning, while remaining
compatible with existing MLLM backbones. Our work highlights the effectiveness,
scalability, and generalizability of text-driven image segmentation within the
MLLM framework.

</details>


### [103] [Towards scalable organ level 3D plant segmentation: Bridging the data algorithm computing gap](https://arxiv.org/abs/2509.06329)
*Ruiming Du,Guangxun Zhai,Tian Qiu,Yu Jiang*

Main category: cs.CV

TL;DR: 本论文综述了3D植物表型分析中点云分割的进展和挑战，介绍了现有数据集、深度学习方法，以及一个开源基准平台，并通过实验证明了一些先进方法与数据生成策略的有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管3D计算机视觉发展迅速，但其在植物表型学中的应用受限于缺乏大规模标注数据集、适配深度网络的技术难题与缺乏专属评测标准。本论文旨在系统总结现有问题并推动3D分割技术在植物领域的实用化。

Method: （1）回顾和归纳现有植物3D点云数据集，（2）总结主流基于深度学习的点云语义与实例分割方法，（3）开发开源平台Plant Segmentation Studio（PSS）用于标准化、可复现的基准测试，（4）开展大量定量实验评估典型网络和仿真到真实环境（sim-to-real）学习策略。

Result: 实验证明稀疏卷积和基于Transformer的分割方法优越，同时通过建模和增强生成合成数据对减少标注需求起到互补作用。

Conclusion: 本研究为植物3D表型分析的算法进展与落地应用之间架起桥梁，提供了直接可用的工具及研发高效、通用深度学习解决方案的路线图，为相关领域研究者带来实际助益。

Abstract: The precise characterization of plant morphology provides valuable insights
into plant environment interactions and genetic evolution. A key technology for
extracting this information is 3D segmentation, which delineates individual
plant organs from complex point clouds. Despite significant progress in general
3D computer vision domains, the adoption of 3D segmentation for plant
phenotyping remains limited by three major challenges: i) the scarcity of
large-scale annotated datasets, ii) technical difficulties in adapting advanced
deep neural networks to plant point clouds, and iii) the lack of standardized
benchmarks and evaluation protocols tailored to plant science. This review
systematically addresses these barriers by: i) providing an overview of
existing 3D plant datasets in the context of general 3D segmentation domains,
ii) systematically summarizing deep learning-based methods for point cloud
semantic and instance segmentation, iii) introducing Plant Segmentation Studio
(PSS), an open-source framework for reproducible benchmarking, and iv)
conducting extensive quantitative experiments to evaluate representative
networks and sim-to-real learning strategies. Our findings highlight the
efficacy of sparse convolutional backbones and transformer-based instance
segmentation, while also emphasizing the complementary role of modeling-based
and augmentation-based synthetic data generation for sim-to-real learning in
reducing annotation demands. In general, this study bridges the gap between
algorithmic advances and practical deployment, providing immediate tools for
researchers and a roadmap for developing data-efficient and generalizable deep
learning solutions in 3D plant phenotyping. Data and code are available at
https://github.com/perrydoremi/PlantSegStudio.

</details>


### [104] [Quantitative Currency Evaluation in Low-Resource Settings through Pattern Analysis to Assist Visually Impaired Users](https://arxiv.org/abs/2509.06331)
*Md Sultanul Islam Ovi,Mainul Hossain,Md Badsha Biswas*

Main category: cs.CV

TL;DR: 提出了一套集成纸币面额识别、损伤量化和防伪检测的统一货币评估系统，兼具高准确性、低资源消耗和强实用性。


<details>
  <summary>Details</summary>
Motivation: 现有货币识别方法多关注于识别纸币面额，忽略了纸币损伤程度与防伪鉴定的实际需求，尤其是在低资源环境和面向视障用户的场景下，实用性有限。

Method: 构建了一个包括三大模块的统一评估系统：1）采用轻量化CNN模型进行纸币面额分类；2）通过新提出的统一货币损伤指数（UCDI），结合掩码损失、色彩失真和结构特征损失实现损伤定量评估；3）利用基于特征的模板匹配完成伪钞检测。同时，构建了包含8.2万张标注纸币图像（涵盖完好、损伤及伪钞）的数据集。

Result: Custom_CNN模型在极低参数量下实现了高准确率的面额分类。UCDI指标能连续量化纸币可用性。防伪检测模块能在多种成像条件下稳定识别伪钞。整体系统支持实时、离线设备部署，适应受限环境。

Conclusion: 该统一评估框架为纸币鉴别和损伤评估提供了准确、可解释、紧凑的解决方案，特别适用于资源有限、实际部署需求强烈的场景，具有良好的实用推广价值。

Abstract: Currency recognition systems often overlook usability and authenticity
assessment, especially in low-resource environments where visually impaired
users and offline validation are common. While existing methods focus on
denomination classification, they typically ignore physical degradation and
forgery, limiting their applicability in real-world conditions. This paper
presents a unified framework for currency evaluation that integrates three
modules: denomination classification using lightweight CNN models, damage
quantification through a novel Unified Currency Damage Index (UCDI), and
counterfeit detection using feature-based template matching. The dataset
consists of over 82,000 annotated images spanning clean, damaged, and
counterfeit notes. Our Custom_CNN model achieves high classification
performance with low parameter count. The UCDI metric provides a continuous
usability score based on binary mask loss, chromatic distortion, and structural
feature loss. The counterfeit detection module demonstrates reliable
identification of forged notes across varied imaging conditions. The framework
supports real-time, on-device inference and addresses key deployment challenges
in constrained environments. Results show that accurate, interpretable, and
compact solutions can support inclusive currency evaluation in practical
settings.

</details>


### [105] [Harnessing Object Grounding for Time-Sensitive Video Understanding](https://arxiv.org/abs/2509.06335)
*Tz-Ying Wu,Sharath Nittur Sridhar,Subarna Tripathi*

Main category: cs.CV

TL;DR: 提出了一种通过结合视频帧中的目标（grounded objects, GO）信息，提升视频大语言模型（Video-LLMs）对时间敏感性视频理解任务能力的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的Video-LLMs在处理时间定位任务时表现有限，研究者认为融入每帧的目标信息（如物体检测）能带来提升。传统做法是将物体的文字描述加入模型提示，但这样会引入更多token并且易受噪声影响。

Method: 提出GO-Tokenizer模块，通过集成常用物体检测器，将检测到的目标信息压缩成更精简的形式，动态编码并输入到Video-LLMs，无需直接把全部目标描述文字加入prompt，提高效率并减少噪声影响。

Result: GO-Tokenizer预训练的模型在不同模型、数据集和任务（如时间定位、密集视频描述）上均优于未使用该方法以及仅用物体描述文字的对照模型。

Conclusion: 通过模块化集成目标检测，实现了更高效、鲁棒的视频理解能力，并能普适提升各种Video-LLMs在多种时间敏感任务上的表现。

Abstract: We propose to improve the time-sensitive video understanding (TSV) capability
of video large language models (Video-LLMs) with grounded objects (GO). We
hypothesize that TSV tasks can benefit from GO within frames, which is
supported by our preliminary experiments on LITA, a state-of-the-art Video-LLM
for reasoning temporal localization. While augmenting prompts with textual
description of these object annotations improves the performance of LITA, it
also introduces extra token length and susceptibility to the noise in object
level information. To address this, we propose GO-Tokenizer, a lightweight
add-on module for Video-LLMs leveraging off-the-shelf object detectors to
encode compact object information on the fly. Experimental results demonstrate
that pretraining with GO-Tokenizer outperforms the vanilla Video-LLM and its
counterpart utilizing textual description of objects in the prompt. The gain
generalizes across different models, datasets and video understanding tasks
such as reasoning temporal localization and dense captioning.

</details>


### [106] [Multi View Slot Attention Using Paraphrased Texts For Face Anti-Spoofing](https://arxiv.org/abs/2509.06336)
*Jeongmin Yu,Susang Kim,Kisu Lee,Taekyoung Kwon,Won-Yong Shin,Ha Young Kim*

Main category: cs.CV

TL;DR: 本论文提出了一种新的人脸防伪方法（MVP-FAS），通过多视角和多文本语义对齐显著提升了跨域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于CLIP的人脸防伪方法没有充分利用CLIP的patch嵌入，且每类只使用一个文本提示，导致对关键伪造线索的检测和泛化能力有限。

Method: 提出了MVP-FAS框架，包含多视角Slot注意力（MVS）和多文本Patch对齐（MTPA）两个模块。通过多种重述文本融合本地和全局特征，并对patch与多个文本表述进行对齐，提高了语义鲁棒性和泛化能力。

Result: 在多个跨域数据集上，MVP-FAS实验性地优于以往的最新方法，取得了更强的跨域防伪表现。

Conclusion: MVP-FAS框架利用多视角、多文本信息有效挖掘并对齐CLIP特征，提升了人脸防伪的跨域泛化和鲁棒性。

Abstract: Recent face anti-spoofing (FAS) methods have shown remarkable cross-domain
performance by employing vision-language models like CLIP. However, existing
CLIP-based FAS models do not fully exploit CLIP's patch embedding tokens,
failing to detect critical spoofing clues. Moreover, these models rely on a
single text prompt per class (e.g., 'live' or 'fake'), which limits
generalization. To address these issues, we propose MVP-FAS, a novel framework
incorporating two key modules: Multi-View Slot attention (MVS) and Multi-Text
Patch Alignment (MTPA). Both modules utilize multiple paraphrased texts to
generate generalized features and reduce dependence on domain-specific text.
MVS extracts local detailed spatial features and global context from patch
embeddings by leveraging diverse texts with multiple perspectives. MTPA aligns
patches with multiple text representations to improve semantic robustness.
Extensive experiments demonstrate that MVP-FAS achieves superior generalization
performance, outperforming previous state-of-the-art methods on cross-domain
datasets. Code: https://github.com/Elune001/MVP-FAS.

</details>


### [107] [A Multi-Modal Deep Learning Framework for Colorectal Pathology Diagnosis: Integrating Histological and Colonoscopy Data in a Pilot Study](https://arxiv.org/abs/2509.06351)
*Krithik Ramesh,Ritvik Koneru*

Main category: cs.CV

TL;DR: 本研究提出了一个结合结直肠组织病理图像和结肠镜视频的统一深度学习诊断系统，借助CNN网络在一个流程中自动分类两种影像，提升结直肠疾病的诊断效率和一致性。


<details>
  <summary>Details</summary>
Motivation: 目前结直肠疾病诊断依赖分别分析病理切片和内镜视频，流程繁琐、易受主观影响且效率较低，因此亟需更高效、一体化的自动辅助诊断方法。

Method: 作者提出了一个基于ResNet-50卷积神经网络的统一模型，能够同时处理、分类病理切片（来自PathMNIST数据集）与结肠镜视频帧（来自HyperKvasir数据集），并引入类别均衡、数据增强与模型校准等方法提升分类准确率和鲁棒性。

Result: 联合方法展示了良好的诊断性能，实现了病理和内镜影像的自动分类，模型具有一定可解释性和可复现性。

Conclusion: 这项工作证明，将多种诊断模态统一到一个深度学习管线上，能够提升结直肠疾病检测的效率与便捷性，对未来自动化、多模态医学影像分析具有实用价值。

Abstract: Colorectal diseases, including inflammatory conditions and neoplasms, require
quick, accurate care to be effectively treated. Traditional diagnostic
pipelines require extensive preparation and rely on separate, individual
evaluations on histological images and colonoscopy footage, introducing
possible variability and inefficiencies. This pilot study proposes a unified
deep learning network that uses convolutional neural networks (CN N s) to
classify both histopathological slides and colonoscopy video frames in one
pipeline. The pipeline integrates class-balancing learning, robust
augmentation, and calibration methods to ensure accurate results. Static colon
histology images were taken from the PathMNIST dataset, and the lower
gastrointestinal (colonoscopy) videos were drawn from the HyperKvasir dataset.
The CNN architecture used was ResNet-50. This study demonstrates an
interpretable and reproducible diagnostic pipeline that unifies multiple
diagnostic modalities to advance and ease the detection of colorectal diseases.

</details>


### [108] [MRD-LiNet: A Novel Lightweight Hybrid CNN with Gradient-Guided Unlearning for Improved Drought Stress Identification](https://arxiv.org/abs/2509.06367)
*Aswini Kumar Patra,Lingaraj Sahoo*

Main category: cs.CV

TL;DR: 该论文提出了一种轻量级混合CNN框架，能够高效且精准地检测农作物干旱胁迫，并大幅减少模型参数量，同时引入了机器反遗忘机制以提升模型的自适应能力。


<details>
  <summary>Details</summary>
Motivation: 传统的干旱胁迫检测方法效率低、劳动强度大。在深度学习已展现出强大潜力的背景下，现有的CNN和Vision Transformer模型参数量大，难以在资源受限的农业场景中应用，因此亟需更为轻量、高效且适应性强的检测模型。

Method: 作者设计了一种结合ResNet、DenseNet和MobileNet优点的轻量级混合CNN结构，实现了参数的大幅压缩。同时提出基于梯度范数影响函数的机器反遗忘机制，可以精准移除特定训练数据的影响，从而提升模型自适应性。实验基于马铃薯田无人机航拍图像进行，数据包含专家标注的健康和干旱区域。

Result: 所提框架在大幅减少（参数量为传统CNN与Vision Transformer的1/15）计算资源消耗的同时，依然保持了与主流方法极具竞争力的准确率。

Conclusion: 该轻量级混合CNN模型不仅具有高准确率和低资源消耗，还能通过机器反遗忘机制自适应调整，具备在资源有限条件下实现精准、可扩展干旱胁迫监测的实际应用价值。

Abstract: Drought stress is a major threat to global crop productivity, making its
early and precise detection essential for sustainable agricultural management.
Traditional approaches, though useful, are often time-consuming and
labor-intensive, which has motivated the adoption of deep learning methods. In
recent years, Convolutional Neural Network (CNN) and Vision Transformer
architectures have been widely explored for drought stress identification;
however, these models generally rely on a large number of trainable parameters,
restricting their use in resource-limited and real-time agricultural settings.
To address this challenge, we propose a novel lightweight hybrid CNN framework
inspired by ResNet, DenseNet, and MobileNet architectures. The framework
achieves a remarkable 15-fold reduction in trainable parameters compared to
conventional CNN and Vision Transformer models, while maintaining competitive
accuracy. In addition, we introduce a machine unlearning mechanism based on a
gradient norm-based influence function, which enables targeted removal of
specific training data influence, thereby improving model adaptability. The
method was evaluated on an aerial image dataset of potato fields with
expert-annotated healthy and drought-stressed regions. Experimental results
show that our framework achieves high accuracy while substantially lowering
computational costs. These findings highlight its potential as a practical,
scalable, and adaptive solution for drought stress monitoring in precision
agriculture, particularly under resource-constrained conditions.

</details>


### [109] [Your Super Resolution Model is not Enough for Tackling Real-World Scenarios](https://arxiv.org/abs/2509.06387)
*Dongsik Yoon,Jongeun Kim*

Main category: cs.CV

TL;DR: 提出了一种可插拔的尺度感知注意力模块（SAAM），能让固定尺度的超分辨率（SR）模型支持任意尺度的高分操作，在多个现有主流SR模型中表现优异，并且计算开销小，适合实际应用。


<details>
  <summary>Details</summary>
Motivation: 现有单幅图像超分辨（SISR）方法通常只能处理预设的缩放倍率，难以适应实际中多种不同放大需求，导致应用受限。

Method: 提出SAAM模块，采用轻量级、可调尺度的特征提取与上采样方式，并结合SimAM无参数注意力模块进行有效特征引导，还引入梯度方差损失以提升图像细节锐利度。SAAM可无缝集成到多种主流SR骨干网络中。

Result: 在多个基准数据集和不同主流SR网络中进行了大量实验，SAAM在多种整数和非整数放大倍率下都表现出有竞争力甚至更优的性能。

Conclusion: SAAM实现了高效、鲁棒的多尺度超分辨率重建，且对原有模型的计算开销极小，是现实场景下具有实践价值的解决方案。

Abstract: Despite remarkable progress in Single Image Super-Resolution (SISR),
traditional models often struggle to generalize across varying scale factors,
limiting their real-world applicability. To address this, we propose a plug-in
Scale-Aware Attention Module (SAAM) designed to retrofit modern fixed-scale SR
models with the ability to perform arbitrary-scale SR. SAAM employs
lightweight, scale-adaptive feature extraction and upsampling, incorporating
the Simple parameter-free Attention Module (SimAM) for efficient guidance and
gradient variance loss to enhance sharpness in image details. Our method
integrates seamlessly into multiple state-of-the-art SR backbones (e.g., SCNet,
HiT-SR, OverNet), delivering competitive or superior performance across a wide
range of integer and non-integer scale factors. Extensive experiments on
benchmark datasets demonstrate that our approach enables robust multi-scale
upscaling with minimal computational overhead, offering a practical solution
for real-world scenarios.

</details>


### [110] [AI-based response assessment and prediction in longitudinal imaging for brain metastases treated with stereotactic radiosurgery](https://arxiv.org/abs/2509.06396)
*Lorenz Achim Kuhn,Daniel Abler,Jonas Richiardi,Andreas F. Hottinger,Luis Schiappacasse,Vincent Dunet,Adrien Depeursinge,Vincent Andrearczyk*

Main category: cs.CV

TL;DR: 本文提出了一个自动化流程，分析和预测脑转移瘤（BM）在SRS治疗后的MRI影像随访数据，提升了病变生长轨迹分析和治疗反应预测的效率和精度。


<details>
  <summary>Details</summary>
Motivation: 脑转移瘤是癌症死亡的主要原因之一，SRS是常见的治疗手段，但其长期MRI随访数据分析工作量庞大，临床医生难以系统量化和标注生长轨迹，影响对治疗效果的理解和预测。因此，急需自动化方法高效处理和分析这些影像数据。

Method: 研究建立了自动化数据整理流程，收集了177位患者896个BM、超过360天的随访MRI数据，应用数据驱动集群分析发现典型生长轨迹，并采用传统机器学习与图机器学习（GML）方法预测病灶12个月的治疗反应。

Result: 集群分析共识别出5类主要生长轨迹，对应不同的最终治疗反应。仅用治疗前及第一次随访的MRI（梯度提升方法），最大AUC达0.90。用GML法在多时间点输入下预测AUC最高达0.88，表现稳健且灵活。

Conclusion: 自动化流程能够有效提升BM随访MRI数据的分析和反应预测精度，为规模化模式发现和临床决策支持系统开发奠定基础，有助于实现个体化精准医疗。

Abstract: Brain Metastases (BM) are a large contributor to mortality of patients with
cancer. They are treated with Stereotactic Radiosurgery (SRS) and monitored
with Magnetic Resonance Imaging (MRI) at regular follow-up intervals according
to treatment guidelines. Analyzing and quantifying this longitudinal imaging
represents an intractable workload for clinicians. As a result, follow-up
images are not annotated and merely assessed by observation. Response to
treatment in longitudinal imaging is being studied, to better understand growth
trajectories and ultimately predict treatment success or toxicity as early as
possible. In this study, we implement an automated pipeline to curate a large
longitudinal dataset of SRS treatment data, resulting in a cohort of 896 BMs in
177 patients who were monitored for >360 days at approximately two-month
intervals at Lausanne University Hospital (CHUV). We use a data-driven
clustering to identify characteristic trajectories. In addition, we predict 12
months lesion-level response using classical as well as graph machine learning
Graph Machine Learning (GML). Clustering revealed 5 dominant growth
trajectories with distinct final response categories. Response prediction
reaches up to 0.90 AUC (CI95%=0.88-0.92) using only pre-treatment and first
follow-up MRI with gradient boosting. Similarly, robust predictive performance
of up to 0.88 AUC (CI95%=0.86-0.90) was obtained using GML, offering more
flexibility with a single model for multiple input time-points configurations.
Our results suggest potential automation and increased precision for the
comprehensive assessment and prediction of BM response to SRS in longitudinal
MRI. The proposed pipeline facilitates scalable data curation for the
investigation of BM growth patterns, and lays the foundation for clinical
decision support systems aiming at optimizing personalized care.

</details>


### [111] [3DOF+Quantization: 3DGS quantization for large scenes with limited Degrees of Freedom](https://arxiv.org/abs/2509.06400)
*Matthieu Gendrin,Stéphane Pateux,Théo Ladune*

Main category: cs.CV

TL;DR: 本文改进了用于3D场景重建的3D高斯撒点(3DGS)方法，提出了一种新的基于球坐标的量化方案，在有限视域（3DoF+）的情况下提升了编码效率和重建质量。


<details>
  <summary>Details</summary>
Motivation: 当前3DGS方法在处理大场景时，通常只针对拍摄视角有限的区域进行3D场景重建。由于坐标量化（即数据离散化）会带来位置误差，且这种误差随物体到摄像头距离变化显著，因此亟需改进3DGS的量化方法，提升新视角生成质量与编码效率。

Method: 作者分析了坐标量化带来的投影误差，发现投影误差与被投影点到摄像机距离的平方成反比。基于此，提出了一种基于球坐标的量化新方案，更合理地分配量化精度。并以著名的Garden场景为例，评估了该方法在码率-失真表现上的效果。

Result: 结果表明，新的球坐标量化方法在有限视域(3DoF+)下显著提升了码率-失真性能（即在较低编码开销下获得更好的重建质量），优于传统笛卡尔坐标量化。

Conclusion: 论文提出的基于球坐标的新量化方法，有效解决了3DGS在有限视域内因坐标量化导致的投影误差问题，提高了3D重建的表现，为大规模场景重建及高效编码提供了新思路。

Abstract: 3D Gaussian Splatting (3DGS) is a major breakthrough in 3D scene
reconstruction. With a number of views of a given object or scene, the
algorithm trains a model composed of 3D gaussians, which enables the production
of novel views from arbitrary points of view. This freedom of movement is
referred to as 6DoF for 6 degrees of freedom: a view is produced for any
position (3 degrees), orientation of camera (3 other degrees). On large scenes,
though, the input views are acquired from a limited zone in space, and the
reconstruction is valuable for novel views from the same zone, even if the
scene itself is almost unlimited in size. We refer to this particular case as
3DoF+, meaning that the 3 degrees of freedom of camera position are limited to
small offsets around the central position. Considering the problem of
coordinate quantization, the impact of position error on the projection error
in pixels is studied. It is shown that the projection error is proportional to
the squared inverse distance of the point being projected. Consequently, a new
quantization scheme based on spherical coordinates is proposed. Rate-distortion
performance of the proposed method are illustrated on the well-known Garden
scene.

</details>


### [112] [VQualA 2025 Challenge on Image Super-Resolution Generated Content Quality Assessment: Methods and Results](https://arxiv.org/abs/2509.06413)
*Yixiao Li,Xin Li,Chris Wei Zhou,Shuo Xing,Hadi Amirpour,Xiaoshuai Hao,Guanghui Yue,Baoquan Zhao,Weide Liu,Xiaoyuan Yang,Zhengzhong Tu,Xinyu Li,Chuanbiao Song,Chenqi Zhang,Jun Lan,Huijia Zhu,Weiqiang Wang,Xiaoyan Sun,Shishun Tian,Dongyang Yan,Weixia Zhang,Junlin Chen,Wei Sun,Zhihua Wang,Zhuohang Shi,Zhizun Luo,Hang Ouyang,Tianxin Xiao,Fan Yang,Zhaowang Wu,Kaixin Deng*

Main category: cs.CV

TL;DR: 该论文介绍了ISRGC-Q挑战赛，这是基于ISRGen-QA数据集并作为ICCV 2025工作坊VQualA竞赛的一部分。该挑战关注由最新生成式方法（如GAN和扩散模型）生成的超分辨率图像的质量评估。


<details>
  <summary>Details</summary>
Motivation: 现有的超分辨率图像质量评估（SR-IQA）数据集大多关注传统方法，缺乏针对现代生成式技术（如GAN和扩散模型）产生图像的评估标准。因此，需要新的数据集和竞赛以促进针对这些最新方法的有效评测。

Method: 构建ISRGen-QA数据集，并开展ISRGC-Q挑战赛，吸引了108位参赛者，通过实际竞赛收集和测试各团队针对现代生成式超分辨率模型的质量评估方法和结果。

Result: 共有4支队伍通过了最终测试并提交了解决方案，这些方案在ISRGen-QA数据集上取得了SOTA（最先进）性能。

Conclusion: ISRGC-Q挑战赛推动了对于生成式超分辨率方法生成内容的质量评估研究，为该研究领域建立了新的数据集标准，促进了技术发展。项目代码和数据已公开。

Abstract: This paper presents the ISRGC-Q Challenge, built upon the Image
Super-Resolution Generated Content Quality Assessment (ISRGen-QA) dataset, and
organized as part of the Visual Quality Assessment (VQualA) Competition at the
ICCV 2025 Workshops. Unlike existing Super-Resolution Image Quality Assessment
(SR-IQA) datasets, ISRGen-QA places a greater emphasis on SR images generated
by the latest generative approaches, including Generative Adversarial Networks
(GANs) and diffusion models. The primary goal of this challenge is to analyze
the unique artifacts introduced by modern super-resolution techniques and to
evaluate their perceptual quality effectively. A total of 108 participants
registered for the challenge, with 4 teams submitting valid solutions and fact
sheets for the final testing phase. These submissions demonstrated
state-of-the-art (SOTA) performance on the ISRGen-QA dataset. The project is
publicly available at: https://github.com/Lighting-YXLI/ISRGen-QA.

</details>


### [113] [Phantom-Insight: Adaptive Multi-cue Fusion for Video Camouflaged Object Detection with Multimodal LLM](https://arxiv.org/abs/2509.06422)
*Hua Zhang,Changjiang Luo,Ruoyu Chen*

Main category: cs.CV

TL;DR: 本文提出了一种结合SAM和MLLM的新方法Phantom-Insight，用于提升视频伪装目标检测在动态环境中的分割性能，并取得了最新最优的实验结果。


<details>
  <summary>Details</summary>
Motivation: 现有视频伪装目标检测方法存在两大问题：1）基于SAM的方法由于参数冻结，难以分离伪装目标的边缘；2）基于多模态大语言模型（MLLM）的方法受限于前景与背景表征不分，难以实现良好的目标分离。针对上述问题，本文提出改进方案。

Method: 提出Phantom-Insight方法：首先以时空线索和特征融合提升信息密度，并通过动态前景视觉令牌打分模块和提示网络生成多元线索，指导SAM细致分割。进一步提出前景-背景解耦学习策略，分开生成前景和背景线索并进行解耦训练，从而促使视觉令牌独立融合目标与背景信息，提升分割准确性。

Result: 实验在MoCA-Mask数据集上取得了各项指标的SOTA结果；此外，在CAD2016数据集上也展现出对未见目标的强泛化能力。

Conclusion: Phantom-Insight有效提升了动态环境中视频伪装目标检测的分割能力，解决了现有方法在目标边缘分离与前背景解耦方面的瓶颈，兼具精度提升和良好泛化性。

Abstract: Video camouflaged object detection (VCOD) is challenging due to dynamic
environments. Existing methods face two main issues: (1) SAM-based methods
struggle to separate camouflaged object edges due to model freezing, and (2)
MLLM-based methods suffer from poor object separability as large language
models merge foreground and background. To address these issues, we propose a
novel VCOD method based on SAM and MLLM, called Phantom-Insight. To enhance the
separability of object edge details, we represent video sequences with temporal
and spatial clues and perform feature fusion via LLM to increase information
density. Next, multiple cues are generated through the dynamic foreground
visual token scoring module and the prompt network to adaptively guide and
fine-tune the SAM model, enabling it to adapt to subtle textures. To enhance
the separability of objects and background, we propose a decoupled
foreground-background learning strategy. By generating foreground and
background cues separately and performing decoupled training, the visual token
can effectively integrate foreground and background information independently,
enabling SAM to more accurately segment camouflaged objects in the video.
Experiments on the MoCA-Mask dataset show that Phantom-Insight achieves
state-of-the-art performance across various metrics. Additionally, its ability
to detect unseen camouflaged objects on the CAD2016 dataset highlights its
strong generalization ability.

</details>


### [114] [When Language Model Guides Vision: Grounding DINO for Cattle Muzzle Detection](https://arxiv.org/abs/2509.06427)
*Rabin Dulal,Lihong Zheng,Muhammad Ashad Kabir*

Main category: cs.CV

TL;DR: 该论文提出了一种基于Grounding DINO模型的零样本牛鼻部检测方法，无需标注数据即可实现高效牛只身份识别。


<details>
  <summary>Details</summary>
Motivation: 牛鼻部花纹是牛只身份识别的重要生物特征，但是传统检测依赖人工，不但费时而且不稳定；现有自动化方法又过度依赖大量标注数据，难以适应新环境和新个体，因此需要一种无需标注就能通用且有效的检测方法。

Method: 采用Grounding DINO视觉语言模型，利用自然语言提示词实现牛鼻区域的自动定位，无需针对检测任务进行额外训练或数据标注，提升了模型对于不同品种和环境的自适应性。

Result: 以mAP@0.5=76.8%的成绩证明该零样本检测系统在未使用任何标注数据情况下依然表现良好。

Conclusion: 该方法首次实现了面向实际产业应用、无标注依赖的牛鼻部检测，为牛只身份识别提供了可扩展、高适应性的新方案，有望促进牲畜智能监控场景下的普及和部署。

Abstract: Muzzle patterns are among the most effective biometric traits for cattle
identification. Fast and accurate detection of the muzzle region as the region
of interest is critical to automatic visual cattle identification.. Earlier
approaches relied on manual detection, which is labor-intensive and
inconsistent. Recently, automated methods using supervised models like YOLO
have become popular for muzzle detection. Although effective, these methods
require extensive annotated datasets and tend to be trained data-dependent,
limiting their performance on new or unseen cattle. To address these
limitations, this study proposes a zero-shot muzzle detection framework based
on Grounding DINO, a vision-language model capable of detecting muzzles without
any task-specific training or annotated data. This approach leverages natural
language prompts to guide detection, enabling scalable and flexible muzzle
localization across diverse breeds and environments. Our model achieves a mean
Average Precision (mAP)@0.5 of 76.8\%, demonstrating promising performance
without requiring annotated data. To our knowledge, this is the first research
to provide a real-world, industry-oriented, and annotation-free solution for
cattle muzzle detection. The framework offers a practical alternative to
supervised methods, promising improved adaptability and ease of deployment in
livestock monitoring applications.

</details>


### [115] [Perception-oriented Bidirectional Attention Network for Image Super-resolution Quality Assessment](https://arxiv.org/abs/2509.06442)
*Yixiao Li,Xiaoyuan Yang,Guanghui Yue,Jun Fu,Qiuping Jiang,Xu Jia,Paul L. Rosin,Hantao Liu,Wei Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种面向感知的双向注意力网络（PBAN）用于图像超分辨率的全参考质量评价（FR-IQA），在多个实验中超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管已有很多图像超分辨率（SR）算法用于提升图像分辨率，但用于评估这些算法优劣的全参考质量评价指标（FR-IQA）还较为有限，因此本文致力于设计更符合人类视觉感知特性的评价方法。

Method: 提出PBAN模型，包含图像编码模块、感知导向的双向注意力模块（PBA）和质量预测模块。PBA模块引入双向注意力以更好模拟超分图像的生成与评价过程，并提出分组多尺度可变形卷积、子信息激励卷积等机制，引导模型关注失真信息和细粒度特征。最后，使用质量预测模块对整合后的特征进行回归，得出最终的质量分数。

Result: 大量实验表明，PBAN在图像超分辨率质量评价任务中优于现有的主流评价方法，获得更准确的质量评估结果。

Conclusion: PBAN通过模拟人类视觉感知过程、引入多尺度与精细注意力机制，在超分辨率图像质量评价领域达到了新的性能水平，并具备良好的应用前景。

Abstract: Many super-resolution (SR) algorithms have been proposed to increase image
resolution. However, full-reference (FR) image quality assessment (IQA) metrics
for comparing and evaluating different SR algorithms are limited. In this work,
we propose the Perception-oriented Bidirectional Attention Network (PBAN) for
image SR FR-IQA, which is composed of three modules: an image encoder module, a
perception-oriented bidirectional attention (PBA) module, and a quality
prediction module. First, we encode the input images for feature
representations. Inspired by the characteristics of the human visual system, we
then construct the perception-oriented PBA module. Specifically, different from
existing attention-based SR IQA methods, we conceive a Bidirectional Attention
to bidirectionally construct visual attention to distortion, which is
consistent with the generation and evaluation processes of SR images. To
further guide the quality assessment towards the perception of distorted
information, we propose Grouped Multi-scale Deformable Convolution, enabling
the proposed method to adaptively perceive distortion. Moreover, we design
Sub-information Excitation Convolution to direct visual perception to both
sub-pixel and sub-channel attention. Finally, the quality prediction module is
exploited to integrate quality-aware features and regress quality scores.
Extensive experiments demonstrate that our proposed PBAN outperforms
state-of-the-art quality assessment methods.

</details>


### [116] [Cross3DReg: Towards a Large-scale Real-world Cross-source Point Cloud Registration Benchmark](https://arxiv.org/abs/2509.06456)
*Zongyi Xu,Zhongpeng Lang,Yilong Chen,Shanshan Zhao,Xiaoshui Huang,Yifan Zuo,Yan Zhang,Qianni Zhang,Xinbo Gao*

Main category: cs.CV

TL;DR: 本文提出了一种新的跨源点云配准方法，并构建了最大规模的真实多模态跨源点云数据集Cross3DReg，模型在精度和鲁棒性上取得了先进水平。


<details>
  <summary>Details</summary>
Motivation: 当前跨源点云配准任务面临两个主要挑战：1）缺乏大规模真实数据集用于训练深度配准模型；2）不同传感器捕获的点云之间固有差异性导致特征一致性差，难以精确匹配。为推动该方向发展，需解决上述难题。

Method: 1）采集并构建了Cross3DReg大规模数据集，涵盖旋转机械激光雷达和混合半固态激光雷达两种传感器；2）设计基于区域重叠预测的配准框架，利用未对齐图像预测源与目标点云重叠区域，去除无关区冗余点，有效减小噪声干扰；3）提出视觉-几何注意力引导的特征匹配模块，将图像与几何信息融合，提升跨源点云特征一致性与可靠性。

Result: 方法在多项实验上取得最先进表现，显著优于以往方法：相对旋转误差减少63.2%，相对平移误差减少40.2%，配准召回率提升5.4%。

Conclusion: 提出的数据集和方法能显著提升跨源点云配准精度与鲁棒性，为后续相关研究提供了数据和方法基础。

Abstract: Cross-source point cloud registration, which aims to align point cloud data
from different sensors, is a fundamental task in 3D vision. However, compared
to the same-source point cloud registration, cross-source registration faces
two core challenges: the lack of publicly available large-scale real-world
datasets for training the deep registration models, and the inherent
differences in point clouds captured by multiple sensors. The diverse patterns
induced by the sensors pose great challenges in robust and accurate point cloud
feature extraction and matching, which negatively influence the registration
accuracy. To advance research in this field, we construct Cross3DReg, the
currently largest and real-world multi-modal cross-source point cloud
registration dataset, which is collected by a rotating mechanical lidar and a
hybrid semi-solid-state lidar, respectively. Moreover, we design an
overlap-based cross-source registration framework, which utilizes unaligned
images to predict the overlapping region between source and target point
clouds, effectively filtering out redundant points in the irrelevant regions
and significantly mitigating the interference caused by noise in
non-overlapping areas. Then, a visual-geometric attention guided matching
module is proposed to enhance the consistency of cross-source point cloud
features by fusing image and geometric information to establish reliable
correspondences and ultimately achieve accurate and robust registration.
Extensive experiments show that our method achieves state-of-the-art
registration performance. Our framework reduces the relative rotation error
(RRE) and relative translation error (RTE) by $63.2\%$ and $40.2\%$,
respectively, and improves the registration recall (RR) by $5.4\%$, which
validates its effectiveness in achieving accurate cross-source registration.

</details>


### [117] [IGAff: Benchmarking Adversarial Iterative and Genetic Affine Algorithms on Deep Neural Networks](https://arxiv.org/abs/2509.06459)
*Sebastian-Vasile Echim,Andrei-Alexandru Preda,Dumitru-Clementin Cercel,Florin Pop*

Main category: cs.CV

TL;DR: 本文提出了两种新的黑箱对抗攻击算法，利用仿射变换和遗传算法，在多个主流视觉网络及数据集上对其有效性进行评估，并与现有攻击方法对比，取得更好的攻击表现。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络虽然在各类任务中取得了优异成绩，但其“可解释性”差且易受对抗攻击。尤其是黑箱场景下（无法获取模型内部信息）进行有效攻击极具挑战。因此，研究针对不同网络架构的新型黑箱攻击方法，探测模型弱点和提升算法性能，有重要意义。

Method: 在ResNet-18、DenseNet-121、Swin Transformer V2和Vision Transformer等主流网络结构上，使用Tiny ImageNet、Caltech-256和Food-101数据集，提出并实验了两种新型黑箱迭代对抗攻击算法：1) Affine Transformation Attack (ATA)——通过随机仿射变换优化攻击得分函数；2) Affine Genetic Attack (AGA)——结合随机噪声和仿射变换的遗传算法。同时对比分析了Pixle和Square Attack等黑箱对抗算法的表现。

Result: 在图像分类任务上，两种新方法的攻击表现优于主流相似方法，部分实验的准确率提升达到8.82%。同时通过不同的算法参数、数据增强和多种攻击配置，深入分析了模型的鲁棒性和攻击防御特性。

Conclusion: 本文两种基于仿射和遗传机制的黑箱对抗攻击算法在实际任务中展现出更强的攻击力和泛化性，可为未来神经网络模型的安全性提升提供有力参考和算法基础。

Abstract: Deep neural networks currently dominate many fields of the artificial
intelligence landscape, achieving state-of-the-art results on numerous tasks
while remaining hard to understand and exhibiting surprising weaknesses. An
active area of research focuses on adversarial attacks, which aim to generate
inputs that uncover these weaknesses. However, this proves challenging,
especially in the black-box scenario where model details are inaccessible. This
paper explores in detail the impact of such adversarial algorithms on
ResNet-18, DenseNet-121, Swin Transformer V2, and Vision Transformer network
architectures. Leveraging the Tiny ImageNet, Caltech-256, and Food-101
datasets, we benchmark two novel black-box iterative adversarial algorithms
based on affine transformations and genetic algorithms: 1) Affine
Transformation Attack (ATA), an iterative algorithm maximizing our attack score
function using random affine transformations, and 2) Affine Genetic Attack
(AGA), a genetic algorithm that involves random noise and affine
transformations. We evaluate the performance of the models in the algorithm
parameter variation, data augmentation, and global and targeted attack
configurations. We also compare our algorithms with two black-box adversarial
algorithms, Pixle and Square Attack. Our experiments yield better results on
the image classification task than similar methods in the literature, achieving
an accuracy improvement of up to 8.82%. We provide noteworthy insights into
successful adversarial defenses and attacks at both global and targeted levels,
and demonstrate adversarial robustness through algorithm parameter variation.

</details>


### [118] [Focusing by Contrastive Attention: Enhancing VLMs' Visual Reasoning](https://arxiv.org/abs/2509.06461)
*Yuyao Ge,Shenghua Liu,Yiwei Wang,Lingrui Mei,Baolong Bi,Xuanshan Zhou,Jiayu Yao,Jiafeng Guo,Xueqi Cheng*

Main category: cs.CV

TL;DR: 提出了一种无需额外训练的新方法（CARVE），通过对比注意力机制，显著提升了视觉-语言模型（VLMs）在复杂视觉环境下的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉-语言模型在多种任务中表现优异，但在复杂场景下性能会下降。现有改进方法依赖额外训练、外部工具或仅支持粗粒度增强，未充分发掘模型本身潜力。本文旨在探索并提升VLMs应对复杂视觉输入的能力。

Method: 作者系统分析了VLM的注意力模式，发现视觉复杂度与注意力熵高度相关，影响模型推理效果。注意力在浅层聚焦全局，深层逐渐收敛，受视觉复杂度影响。理论证明，对普通查询与任务查询注意力图进行对比，可分离有用与噪声信号。基于此，提出训练无关的CARVE方法，通过像素级注意力对比提取任务相关的视觉信号。

Result: CARVE方法在不需额外训练的情况下，广泛提升了多种开源VLM模型的性能，部分任务提升高达75%。

Conclusion: 本文提供了视觉复杂度和注意力机制之间关键联系的见解，CARVE为复杂场景下VLMs视觉理解能力的提升提供了高效新路径。

Abstract: Vision-Language Models (VLMs) have demonstrated remarkable success across
diverse visual tasks, yet their performance degrades in complex visual
environments. While existing enhancement approaches require additional
training, rely on external segmentation tools, or operate at coarse-grained
levels, they overlook the innate ability within VLMs. To bridge this gap, we
investigate VLMs' attention patterns and discover that: (1) visual complexity
strongly correlates with attention entropy, negatively impacting reasoning
performance; (2) attention progressively refines from global scanning in
shallow layers to focused convergence in deeper layers, with convergence degree
determined by visual complexity. (3) Theoretically, we prove that the contrast
of attention maps between general queries and task-specific queries enables the
decomposition of visual signal into semantic signals and visual noise
components. Building on these insights, we propose Contrastive Attention
Refinement for Visual Enhancement (CARVE), a training-free method that extracts
task-relevant visual signals through attention contrasting at the pixel level.
Extensive experiments demonstrate that CARVE consistently enhances performance,
achieving up to 75% improvement on open-source models. Our work provides
critical insights into the interplay between visual complexity and attention
mechanisms, offering an efficient pathway for improving visual reasoning with
contrasting attention.

</details>


### [119] [A Statistical 3D Stomach Shape Model for Anatomical Analysis](https://arxiv.org/abs/2509.06464)
*Erez Posner,Ore Shtalrid,Oded Erell,Daniel Noy,Moshe Bouhnik*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的合成3D胃模型生成流程，并基于此开发了首个统计形状模型，兼具真实性和参数化，为胃脏器建模提供重要进展。


<details>
  <summary>Details</summary>
Motivation: 现有的3D人类解剖模型对胃等内部器官建模有限，主要由于数据缺乏和方法学挑战，限制了在临床、科研和手术规划中的应用。

Method: 作者设计了一个合成3D胃模型的自动化流程，生成形态多样的数据集，并利用传统文献的形态变异信息。随后，通过机器学习训练统计形状模型，捕捉解剖结构的自然变异性，并结合公开CT数据进行半监督精细化对齐，提升泛化能力。

Result: 该方法在真实CT测试集上实现了稳健的泛化和高拟合准确率，明显优于以往工作，并公开发布了相应模型和数据集。

Conclusion: 本文首次建立了统计3D胃形状模型，兼备合成与真实数据验证，可广泛应用于手术仿真、术前规划、医学教育及计算建模，推动个性化医疗进一步发展。

Abstract: Realistic and parameterized 3D models of human anatomy have become invaluable
in research, diagnostics, and surgical planning. However, the development of
detailed models for internal organs, such as the stomach, has been limited by
data availability and methodological challenges. In this paper, we propose a
novel pipeline for the generation of synthetic 3D stomach models, enabling the
creation of anatomically diverse morphologies informed by established studies
on stomach shape variability. Using this pipeline, we construct a dataset of
synthetic stomachs. Building on this dataset, we develop a 3D statistical shape
model of the stomach, trained to capture natural anatomical variability in a
low-dimensional shape space. The model is further refined using CT meshes
derived from publicly available datasets through a semi-supervised alignment
process, enhancing its ability to generalize to unseen anatomical variations.
We evaluated the model on a held-out test set of real stomach CT scans,
demonstrating robust generalization and fit accuracy. We make the statistical
shape model along with the synthetic dataset publicly available on GitLab:
https://gitlab.com/Erez.Posner/stomach_pytorch to facilitate further research.
This work introduces the first statistical 3D shape model of the stomach, with
applications ranging from surgical simulation and pre-operative planning to
medical education and computational modeling. By combining synthetic data
generation, parametric modeling, and real-world validation, our approach
represents a significant advancement in organ modeling and opens new
possibilities for personalized healthcare solutions.

</details>


### [120] [Does DINOv3 Set a New Medical Vision Standard?](https://arxiv.org/abs/2509.06467)
*Che Liu,Yinda Chen,Haoyuan Shi,Jinpeng Lu,Bailiang Jian,Jiazhen Pan,Linghan Cai,Jiayi Wang,Yundi Zhang,Jun Li,Cosmin I. Bercea,Cheng Ouyang,Chen Chen,Zhiwei Xiong,Benedikt Wiestler,Christian Wachinger,Daniel Rueckert,Wenjia Bai,Rossella Arcucci*

Main category: cs.CV

TL;DR: 本报告评估了DINOv3视觉基础模型在医学影像任务中的表现，发现该模型在多个任务上表现优异，能作为通用医学视觉编码器，但在高度专业化场景下仍有局限。


<details>
  <summary>Details</summary>
Motivation: 虽然大规模视觉基础模型在自然图像上取得了突破，但它们在医学影像等专业领域的适用性与表现尚未明朗。因此，作者希望探索此类模型（尤其是DINOv3）能否无需专门医学预训练，直接胜任医学视觉任务。

Method: 作者采用DINOv3视觉Transformer，在多种医学影像模态和任务（包括2D/3D分类与分割）中进行基准测试，并系统性地分析其模型规模和输入分辨率对性能的影响。同时，将DINOv3与专门的医学基础模型进行对比。

Result: DINOv3在大多数医学影像任务上表现出色，甚至在部分任务上超过了专为医学设计的BiomedCLIP和CT-Net，展现了良好的泛化能力。但在需要深度专业化特征的场景（如WSI、EM、PET）能力下降。此外，扩展模型尺寸或分辨率并不总能提升效果，呈现出任务依赖性的扩展规律。

Conclusion: DINOv3可以作为医学视觉任务中强有力的通用基线模型，为复杂医学任务提供鲁棒先验。然而，对于深度专业化领域还需改进，未来可探索利用其特征提升3D重建等多视图一致性任务。

Abstract: The advent of large-scale vision foundation models, pre-trained on diverse
natural images, has marked a paradigm shift in computer vision. However, how
the frontier vision foundation models' efficacies transfer to specialized
domains remains such as medical imaging remains an open question. This report
investigates whether DINOv3, a state-of-the-art self-supervised vision
transformer (ViT) that features strong capability in dense prediction tasks,
can directly serve as a powerful, unified encoder for medical vision tasks
without domain-specific pre-training. To answer this, we benchmark DINOv3
across common medical vision tasks, including 2D/3D classification and
segmentation on a wide range of medical imaging modalities. We systematically
analyze its scalability by varying model sizes and input image resolutions. Our
findings reveal that DINOv3 shows impressive performance and establishes a
formidable new baseline. Remarkably, it can even outperform medical-specific
foundation models like BiomedCLIP and CT-Net on several tasks, despite being
trained solely on natural images. However, we identify clear limitations: The
model's features degrade in scenarios requiring deep domain specialization,
such as in Whole-Slide Pathological Images (WSIs), Electron Microscopy (EM),
and Positron Emission Tomography (PET). Furthermore, we observe that DINOv3
does not consistently obey scaling law in the medical domain; performance does
not reliably increase with larger models or finer feature resolutions, showing
diverse scaling behaviors across tasks. Ultimately, our work establishes DINOv3
as a strong baseline, whose powerful visual features can serve as a robust
prior for multiple complex medical tasks. This opens promising future
directions, such as leveraging its features to enforce multiview consistency in
3D reconstruction.

</details>


### [121] [FSG-Net: Frequency-Spatial Synergistic Gated Network for High-Resolution Remote Sensing Change Detection](https://arxiv.org/abs/2509.06482)
*Zhongxiang Xie,Shuangxi Miao,Yuhan Jiang,Zhewei Zhang,Jing Yao,Xuecao Li,Jianxi Huang,Pedram Ghamisi*

Main category: cs.CV

TL;DR: 该论文提出了FSG-Net，用于提高高分辨率遥感图像中的变化检测准确率。作者从频域和空间域两方面抑制伪变化，并通过轻量门控模块融合深浅特征，在多个公开数据集上取得了新的SOTA表现。


<details>
  <summary>Details</summary>
Motivation: 高分辨率遥感图像变化检测常受伪变化干扰（如光照、季节变化），以及深浅特征难以有效融合的问题，导致边界分割不准确。作者希望通过创新方法减少误报并提升特征融合效果。

Method: 提出FSG-Net网络，主要包括三个模块：（1）在频域采用DAWIM模块，自适应处理不同频率信息以抑制伪变化；（2）在空间域应用STSAM模块，突出真实变化区域的显著性；（3）通过LGFU模块实现高层语义与浅层细节信息的选择性融合。

Result: 在三个公开遥感数据集（CDD、GZ-CD、LEVIR-CD）上，FSG-Net分别获得了94.16%、89.51%和91.27%的F1分数，性能优于现有方法，达到了最新的SOTA水平。

Conclusion: FSG-Net能有效应对遥感变化检测中的伪变化和特征融合难题，提升检测精度，增强边界分割效果，为实际应用提供了强大工具。

Abstract: Change detection from high-resolution remote sensing images lies as a
cornerstone of Earth observation applications, yet its efficacy is often
compromised by two critical challenges. First, false alarms are prevalent as
models misinterpret radiometric variations from temporal shifts (e.g.,
illumination, season) as genuine changes. Second, a non-negligible semantic gap
between deep abstract features and shallow detail-rich features tends to
obstruct their effective fusion, culminating in poorly delineated boundaries.
To step further in addressing these issues, we propose the Frequency-Spatial
Synergistic Gated Network (FSG-Net), a novel paradigm that aims to
systematically disentangle semantic changes from nuisance variations.
Specifically, FSG-Net first operates in the frequency domain, where a
Discrepancy-Aware Wavelet Interaction Module (DAWIM) adaptively mitigates
pseudo-changes by discerningly processing different frequency components.
Subsequently, the refined features are enhanced in the spatial domain by a
Synergistic Temporal-Spatial Attention Module (STSAM), which amplifies the
saliency of genuine change regions. To finally bridge the semantic gap, a
Lightweight Gated Fusion Unit (LGFU) leverages high-level semantics to
selectively gate and integrate crucial details from shallow layers.
Comprehensive experiments on the CDD, GZ-CD, and LEVIR-CD benchmarks validate
the superiority of FSG-Net, establishing a new state-of-the-art with F1-scores
of 94.16%, 89.51%, and 91.27%, respectively. The code will be made available at
https://github.com/zxXie-Air/FSG-Net after a possible publication.

</details>


### [122] [WS$^2$: Weakly Supervised Segmentation using Before-After Supervision in Waste Sorting](https://arxiv.org/abs/2509.06485)
*Andrea Marelli,Alberto Foresti,Leonardo Pesce,Giacomo Boracchi,Mario Grosso*

Main category: cs.CV

TL;DR: 本论文关注于工业质检中，利用计算机视觉系统实现对传送带上异质物品中不需要物品的自动识别和分割，并提出利用操作员“移除行为”隐含监督的新方法及首个相关多视角数据集。


<details>
  <summary>Details</summary>
Motivation: 在工业废弃物分拣等场景，人工操作员仍需手动识别并剔除不需要物品。现有完全监督式方法需大量标注，成本高且难以扩展；而操作员独特的移除行为产生的“隐性监督”尚未得到充分利用。

Method: 提出Before-After Supervision，即通过比对操作员移除前后的图片，挖掘其中视觉差异以训练分割网络，并首次发布含11000多帧多视角传送带高分辨率视频帧的新数据集WS$^2$，同时搭建端到端分割管线并对多种主流弱监督分割方法作基准测试。

Result: 建立了WS$^2$数据集并提供了基于Before-After Supervision的新分割训练流程，实验表明所建流程可为弱监督目标分割提供鲁棒基准并推动相关算法发展。

Conclusion: “前后监督”可有效降低工业自动分拣对人工标注的依赖，相关数据集与基线为后续研究提供了坚实基础，有望推动弱监督工业视觉分割技术落地。

Abstract: In industrial quality control, to visually recognize unwanted items within a
moving heterogeneous stream, human operators are often still indispensable.
Waste-sorting stands as a significant example, where operators on multiple
conveyor belts manually remove unwanted objects to select specific materials.
To automate this recognition problem, computer vision systems offer great
potential in accurately identifying and segmenting unwanted items in such
settings. Unfortunately, considering the multitude and the variety of sorting
tasks, fully supervised approaches are not a viable option to address this
challange, as they require extensive labeling efforts. Surprisingly, weakly
supervised alternatives that leverage the implicit supervision naturally
provided by the operator in his removal action are relatively unexplored. In
this paper, we define the concept of Before-After Supervision, illustrating how
to train a segmentation network by leveraging only the visual differences
between images acquired \textit{before} and \textit{after} the operator. To
promote research in this direction, we introduce WS$^2$ (Weakly Supervised
segmentation for Waste-Sorting), the first multiview dataset consisting of more
than 11 000 high-resolution video frames captured on top of a conveyor belt,
including "before" and "after" images. We also present a robust end-to-end
pipeline, used to benchmark several state-of-the-art weakly supervised
segmentation methods on WS$^2$.

</details>


### [123] [TIDE: Achieving Balanced Subject-Driven Image Generation via Target-Instructed Diffusion Enhancement](https://arxiv.org/abs/2509.06499)
*Jibai Lin,Bo Ma,Yating Yang,Rong Ma,Turghun Osman,Ahtamjan Ahmat,Rui Dong,Lei Wang,Xi Zhou*

Main category: cs.CV

TL;DR: 提出了一种名为TIDE的新框架，解决了以往图像扩散模型在保持主体身份和遵循编辑指令之间的矛盾，实现了更好的主体驱动图像生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有的主体驱动图像生成方法很难同时保持图像中主体的身份特征，又满足动态文本编辑指令的要求。该问题限制了文本到图像的扩散模型在复杂图像操控任务中的应用。

Method: 提出TIDE框架，通过目标监督和偏好学习实现，不依赖测试时微调。TIDE创新性地采用目标监督的三元组对齐方式，将（参考图像、编辑指令、目标图像）三元组作为训练样本。利用Direct Subject Diffusion(DSD)目标函数，配对生成“优胜”（身份与指令平衡）和“失败”（失真）目标，并用定量指标系统评估，通过这种方式实现隐式奖励建模，从而优化主体身份与编辑遵循的平衡。

Result: 在标准基准测试上，TIDE在生成既保持主体身份、又遵循编辑指令的图像方面，取得了优于主流基线的表现，并在多个定量指标上领先。TIDE还成功应用于结构化条件生成、图像到图像生成和文本-图像插值等多种任务，展现出很强的通用性。

Conclusion: TIDE框架有效解决了主体驱动图像生成中身份保持与指令遵循的矛盾问题，生成结果优异且通用性强，有望推动扩散模型在复杂图像编辑领域的应用。

Abstract: Subject-driven image generation (SDIG) aims to manipulate specific subjects
within images while adhering to textual instructions, a task crucial for
advancing text-to-image diffusion models. SDIG requires reconciling the tension
between maintaining subject identity and complying with dynamic edit
instructions, a challenge inadequately addressed by existing methods. In this
paper, we introduce the Target-Instructed Diffusion Enhancing (TIDE) framework,
which resolves this tension through target supervision and preference learning
without test-time fine-tuning. TIDE pioneers target-supervised triplet
alignment, modelling subject adaptation dynamics using a (reference image,
instruction, target images) triplet. This approach leverages the Direct Subject
Diffusion (DSD) objective, training the model with paired "winning" (balanced
preservation-compliance) and "losing" (distorted) targets, systematically
generated and evaluated via quantitative metrics. This enables implicit reward
modelling for optimal preservation-compliance balance. Experimental results on
standard benchmarks demonstrate TIDE's superior performance in generating
subject-faithful outputs while maintaining instruction compliance,
outperforming baseline methods across multiple quantitative metrics. TIDE's
versatility is further evidenced by its successful application to diverse
tasks, including structural-conditioned generation, image-to-image generation,
and text-image interpolation. Our code is available at
https://github.com/KomJay520/TIDE.

</details>


### [124] [Predicting Brain Tumor Response to Therapy using a Hybrid Deep Learning and Radiomics Approach](https://arxiv.org/abs/2509.06511)
*Daniil Tikhonov,Matheus Scatolin,Mohor Banerjee,Qiankun Ji,Ahmed Jaheen,Mostafa Salem,Abdelrahman Elsayed,Hu Wang,Sarim Hashmi,Mohammad Yaqub*

Main category: cs.CV

TL;DR: 本论文提出了一种结合深度学习特征和放射组学特征的自动化方法，用于基于纵向MRI扫描判断胶质母细胞瘤治疗响应，实现了较好的分类性能。


<details>
  <summary>Details</summary>
Motivation: 准确评估胶质母细胞瘤对治疗的反应对于临床决策和患者管理至关重要。虽然RANO标准提供了评估框架，但实际应用中操作复杂且存在观察者间变异，因此需要开发更为自动化和稳定的评估方法。

Method: 提出一种混合框架，结合了深度学习（利用ResNet-18提取2D多模态MRI特征）和放射组学、临床驱动特征（如3D肿瘤生长与收缩掩膜、体积变化、质心变化等，特征总数超4800），通过CatBoost分类器进行最终分类。

Result: 基于融合特征集，CatBoost分类器在四分类（完全缓解、部分缓解、病情稳定、进展）任务中，平均ROC AUC为0.81，Macro F1为0.50。

Conclusion: 深度学习影像特征与领域导向的放射组学特征协同，有助于实现鲁棒、有效的神经肿瘤治疗响应自动化评估。

Abstract: Accurate evaluation of the response of glioblastoma to therapy is crucial for
clinical decision-making and patient management. The Response Assessment in
Neuro-Oncology (RANO) criteria provide a standardized framework to assess
patients' clinical response, but their application can be complex and subject
to observer variability. This paper presents an automated method for
classifying the intervention response from longitudinal MRI scans, developed to
predict tumor response during therapy as part of the BraTS 2025 challenge. We
propose a novel hybrid framework that combines deep learning derived feature
extraction and an extensive set of radiomics and clinically chosen features.
Our approach utilizes a fine-tuned ResNet-18 model to extract features from 2D
regions of interest across four MRI modalities. These deep features are then
fused with a rich set of more than 4800 radiomic and clinically driven
features, including 3D radiomics of tumor growth and shrinkage masks,
volumetric changes relative to the nadir, and tumor centroid shift. Using the
fused feature set, a CatBoost classifier achieves a mean ROC AUC of 0.81 and a
Macro F1 score of 0.50 in the 4-class response prediction task (Complete
Response, Partial Response, Stable Disease, Progressive Disease). Our results
highlight that synergizing learned image representations with domain-targeted
radiomic features provides a robust and effective solution for automated
treatment response assessment in neuro-oncology.

</details>


### [125] [On the Reproducibility of "FairCLIP: Harnessing Fairness in Vision-Language Learning''](https://arxiv.org/abs/2509.06535)
*Hua Chang Bakker,Stan Fris,Angela Madelon Bernardy,Stan Deutekom*

Main category: cs.CV

TL;DR: 本文复现实验并评估了FairCLIP方法在CLIP模型公平性提升中的效果，但未发现显著改进。


<details>
  <summary>Details</summary>
Motivation: CLIP模型在医学影像等实际任务中存在群体偏见，FairCLIP方法尝试用Sinkhorn距离最小化群体间的图文匹配分数差异来提升模型在敏感群体上的公平性。

Method: 复现实验Luo等人提出的FairCLIP方案，分析其模型描述与原始实现的不一致，并提出A-FairCLIP新实现验设计选择，进一步提出FairCLIP+以支持多敏感属性，将这些方法应用于医学领域公开数据集进行公平性和性能评估。

Result: 实验复现实表明，FairCLIP在数据中（包括官方和重新实现A-FairCLIP）能够降低Sinkhorn距离，但在零样本青光眼分类任务上未能提升模型的性能和公平性。

Conclusion: FairCLIP未能如原论文所述改善CLIP在公平性和性能上的表现，但对公平性正则项本身和实现细节的分析对后续研究具有参考价值。

Abstract: We investigated the reproducibility of FairCLIP, proposed by Luo et al.
(2024), for improving the group fairness of CLIP (Radford et al., 2021) by
minimizing image-text similarity score disparities across sensitive groups
using the Sinkhorn distance. The experimental setup of Luo et al. (2024) was
reproduced to primarily investigate the research findings for FairCLIP. The
model description by Luo et al. (2024) was found to differ from the original
implementation. Therefore, a new implementation, A-FairCLIP, is introduced to
examine specific design choices. Furthermore, FairCLIP+ is proposed to extend
the FairCLIP objective to include multiple attributes. Additionally, the impact
of the distance minimization on FairCLIP's fairness and performance was
explored. In alignment with the original authors, CLIP was found to be biased
towards certain demographics when applied to zero-shot glaucoma classification
using medical scans and clinical notes from the Harvard-FairVLMed dataset.
However, the experimental results on two datasets do not support their claim
that FairCLIP improves the performance and fairness of CLIP. Although the
regularization objective reduces Sinkhorn distances, both the official
implementation and the aligned implementation, A-FairCLIP, were not found to
improve performance nor fairness in zero-shot glaucoma classification.

</details>


### [126] [Benchmarking EfficientTAM on FMO datasets](https://arxiv.org/abs/2509.06536)
*Senem Aktas,Charles Markham,John McDonald,Rozenn Dahyot*

Main category: cs.CV

TL;DR: 本文为快速移动物体（FMO）图像序列数据集提供了扩展的元数据（FMOX），并用其测试了先进的目标跟踪模型（EfficientTAM），结果良好。


<details>
  <summary>Details</summary>
Motivation: 快速且小型目标的跟踪在计算机视觉中仍然具有挑战性，现有数据集描述和标注不够丰富，不利于模型的公平评估和发展。

Method: 作者为四个开源FMO数据集提供了详细的JSON格式元数据，并增加了包含目标尺寸等信息的全新ground truth文件（FMOX）。同时，利用FMOX，对主流目标跟踪模型EfficientTAM进行了性能测试，并以TIoU分数与原有方法进行比较。

Result: EfficientTAM在FMOX基准测试中的表现与专门为FMO设计的跟踪管线相当。相关代码与数据以开源形式发布，方便后续研究使用。

Conclusion: 增补的FMOX元数据和开源评测，为快速移动物体追踪研究提供了标准化的基准和便利，促进了相关算法发展和对比测试。

Abstract: Fast and tiny object tracking remains a challenge in computer vision and in
this paper we first introduce a JSON metadata file associated with four open
source datasets of Fast Moving Objects (FMOs) image sequences. In addition, we
extend the description of the FMOs datasets with additional ground truth
information in JSON format (called FMOX) with object size information. Finally
we use our FMOX file to test a recently proposed foundational model for
tracking (called EfficientTAM) showing that its performance compares well with
the pipelines originally taylored for these FMO datasets. Our comparison of
these state-of-the-art techniques on FMOX is provided with Trajectory
Intersection of Union (TIoU) scores. The code and JSON is shared open source
allowing FMOX to be accessible and usable for other machine learning pipelines
aiming to process FMO datasets.

</details>


### [127] [Back To The Drawing Board: Rethinking Scene-Level Sketch-Based Image Retrieval](https://arxiv.org/abs/2509.06566)
*Emil Demić,Luka Čehovin Zajc*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的scene-level基于草图的图像检索方法，通过改进训练目标和设计使模型对草图的不确定性和噪声更加鲁棒，无需引入复杂结构便达到了SOTA表现。


<details>
  <summary>Details</summary>
Motivation: 现有基于草图的图像检索方法在提升架构复杂性的同时，忽视了手绘草图本身存在的不可避免的模糊和噪声问题。实际应用中，草图多样且有较大差异性，因此需要方法能适应这种模糊性和不准确性，提高真实场景下的检索表现。

Method: 作者设计了一种专门针对草图多样性与噪声鲁棒的训练目标，结合合适的预训练、编码器架构以及损失函数，实现了无需复杂额外结构也能提升检索性能的方法。

Result: 在FS-COCO和SketchyCOCO两个具有挑战性和广泛使用的数据集上进行了大量实验，结果显示该方法取得了最新SOTA的表现，验证了其优越性。

Conclusion: 训练目标和设计对跨模态检索任务起到关键作用，通过改进训练目标可以显著提升scene-level草图图像检索效果。同时也指出现有评估方案尚需改进。

Abstract: The goal of Scene-level Sketch-Based Image Retrieval is to retrieve natural
images matching the overall semantics and spatial layout of a free-hand sketch.
Unlike prior work focused on architectural augmentations of retrieval models,
we emphasize the inherent ambiguity and noise present in real-world sketches.
This insight motivates a training objective that is explicitly designed to be
robust to sketch variability. We show that with an appropriate combination of
pre-training, encoder architecture, and loss formulation, it is possible to
achieve state-of-the-art performance without the introduction of additional
complexity. Extensive experiments on a challenging FS-COCO and widely-used
SketchyCOCO datasets confirm the effectiveness of our approach and underline
the critical role of training design in cross-modal retrieval tasks, as well as
the need to improve the evaluation scenarios of scene-level SBIR.

</details>


### [128] [Evolving from Unknown to Known: Retentive Angular Representation Learning for Incremental Open Set Recognition](https://arxiv.org/abs/2509.06570)
*Runqing Yang,Yimin Fu,Changyuan Wu,Zhunga Liu*

Main category: cs.CV

TL;DR: 本文提出了一种新的增量开放集识别（IOSR）方法，称为 RARL，通过在角度空间中对未知类别表示进行对齐，结合 VII 训练策略与分层校正机制，显著提升了持续数据流中的分类和未知识别性能。


<details>
  <summary>Details</summary>
Motivation: 传统开放集识别(OSR)方法通常应用于静态场景，不能有效应对不断出现新类别的数据流问题。面对难以维护判别决策边界和新旧类别混淆的挑战，有必要提出一种既能识别新类别又能掌握新知识的增量开放集识别方法。

Method: 提出了保留性角度表示学习(RARL)方法。该方法在等角紧框(equiangular tight frame)构建的角度空间中，把未知类别向量聚集在非活动原型附近，防止知识更新时特征漂移。采用虚实交互(VII)训练策略，通过虚拟类别强化已知类别的判别边界。分层校正机制对决策边界进行优化，缓解类别不平衡造成的表示偏差和特征空间扭曲问题。方法在 CIFAR100 和 TinyImageNet 上进行验证。

Result: 所提方法在CIFAR100和TinyImageNet等主流数据集上，多个任务设置下性能超越现有技术，展现出更优的增量开放集识别能力。

Conclusion: RARL方法显著提升了增量开放集识别任务中的判别性和泛化性，为该方向设立了新的性能基准，对持续学习场景下的类别扩展与知识获取具有重要推动作用。

Abstract: Existing open set recognition (OSR) methods are typically designed for static
scenarios, where models aim to classify known classes and identify unknown ones
within fixed scopes. This deviates from the expectation that the model should
incrementally identify newly emerging unknown classes from continuous data
streams and acquire corresponding knowledge. In such evolving scenarios, the
discriminability of OSR decision boundaries is hard to maintain due to
restricted access to former training data, causing severe inter-class
confusion. To solve this problem, we propose retentive angular representation
learning (RARL) for incremental open set recognition (IOSR). In RARL, unknown
representations are encouraged to align around inactive prototypes within an
angular space constructed under the equiangular tight frame, thereby mitigating
excessive representation drift during knowledge updates. Specifically, we adopt
a virtual-intrinsic interactive (VII) training strategy, which compacts known
representations by enforcing clear inter-class margins through
boundary-proximal virtual classes. Furthermore, a stratified rectification
strategy is designed to refine decision boundaries, mitigating representation
bias and feature space distortion caused by imbalances between old/new and
positive/negative class samples. We conduct thorough evaluations on CIFAR100
and TinyImageNet datasets and establish a new benchmark for IOSR. Experimental
results across various task setups demonstrate that the proposed method
achieves state-of-the-art performance.

</details>


### [129] [Approximating Condorcet Ordering for Vector-valued Mathematical Morphology](https://arxiv.org/abs/2509.06577)
*Marcos Eduardo Valle,Santiago Velasco-Forero,Joao Batista Florindo,Gustavo Jesus Angulo*

Main category: cs.CV

TL;DR: 本文提出一种基于机器学习的矢量排序方法，用于改进数学形态学在多通道图像（如彩色图像和高光谱图像）中的应用。


<details>
  <summary>Details</summary>
Motivation: 尽管数学形态学已成功应用于矢量值图像领域，但针对如何为形态学操作选择最合适的矢量排序方法仍缺乏共识，此问题直接影响到操作效果。

Method: 受投票问题的启发，作者利用Condorcet排序的思想，将不同排序方式模拟为“选民”，从而得出综合排序。利用机器学习方法，学习并逼近这一Condorcet排序，形成一种简约化的矢量排序方法供形态学算子使用。

Result: 初步计算实验显示，通过学习获得的简约排序方案能够有效地定义面向彩色图像的矢量值形态学算子。

Conclusion: 本文提出的机器学习式矢量排序不仅为矢量值形态学操作提供了一种新的高效排序方法，还展现了其实际可行性和有效性，有望推动相关领域进一步发展。

Abstract: Mathematical morphology provides a nonlinear framework for image and spatial
data processing and analysis. Although there have been many successful
applications of mathematical morphology to vector-valued images, such as color
and hyperspectral images, there is still no consensus on the most suitable
vector ordering for constructing morphological operators. This paper addresses
this issue by examining a reduced ordering approximating the Condorcet ranking
derived from a set of vector orderings. Inspired by voting problems, the
Condorcet ordering ranks elements from most to least voted, with voters
representing different orderings. In this paper, we develop a machine learning
approach that learns a reduced ordering that approximates the Condorcet
ordering. Preliminary computational experiments confirm the effectiveness of
learning the reduced mapping to define vector-valued morphological operators
for color images.

</details>


### [130] [CausNVS: Autoregressive Multi-view Diffusion for Flexible 3D Novel View Synthesis](https://arxiv.org/abs/2509.06579)
*Xin Kong,Daniel Watson,Yannick Strümpler,Michael Niemeyer,Federico Tombari*

Main category: cs.CV

TL;DR: 本文提出了一种新的多视角扩散模型CausNVS，通过自回归方式逐步生成三维新视角图像，既灵活又高效，解决了之前方法速度慢和视角受限的问题。


<details>
  <summary>Details</summary>
Motivation: 当前多视角扩散模型多采用非自回归方法，导致只能处理固定数量视角、推理速度慢，同时不适用于需要灵活世界建模的场景，因此有必要设计支持任意视角并推理高效的新方法。

Method: CausNVS 使用自回归设置，结合因果遮罩和逐帧噪声训练，并引入CaPE（相对相机位姿编码）实现精确相机控制。在推理时结合空间滑动窗口、缓存和噪声增强来减少漂移，实现逐帧高效生成。

Result: 实验显示CausNVS支持多样的相机轨迹，能够灵活地进行自回归新视角合成，并在不同设置下持续输出高质量视觉结果。

Conclusion: CausNVS 在灵活性、速度和视觉质量方面相较过往多视角扩散模型具有显著优势，为三维新视角合成和世界建模提供了更优方案。

Abstract: Multi-view diffusion models have shown promise in 3D novel view synthesis,
but most existing methods adopt a non-autoregressive formulation. This limits
their applicability in world modeling, as they only support a fixed number of
views and suffer from slow inference due to denoising all frames
simultaneously. To address these limitations, we propose CausNVS, a multi-view
diffusion model in an autoregressive setting, which supports arbitrary
input-output view configurations and generates views sequentially. We train
CausNVS with causal masking and per-frame noise, using pairwise-relative camera
pose encodings (CaPE) for precise camera control. At inference time, we combine
a spatially-aware sliding-window with key-value caching and noise conditioning
augmentation to mitigate drift. Our experiments demonstrate that CausNVS
supports a broad range of camera trajectories, enables flexible autoregressive
novel view synthesis, and achieves consistently strong visual quality across
diverse settings. Project page: https://kxhit.github.io/CausNVS.html.

</details>


### [131] [Detection of trade in products derived from threatened species using machine learning and a smartphone](https://arxiv.org/abs/2509.06585)
*Ritwik Kulkarni,WU Hanqin,Enrico Di Minin*

Main category: cs.CV

TL;DR: 该论文提出了一种基于机器学习的野生动植物制品自动检测方法，可精准识别象牙、穿山甲鳞片以及老虎制品，实现了高识别准确率，并开发了手机应用便于实地和线上执法。


<details>
  <summary>Details</summary>
Motivation: 野生动植物非法贸易是生物多样性的重要威胁，尤其是在数字化市场和社交媒体上更加猖獗。由于数字内容数量庞大，急需自动化识别方法辅助打击野生动植物非法贸易。

Method: 作者收集了大象、穿山甲、老虎的非法制品图片，包含象牙及皮、穿山甲鳞片和爪子、老虎皮和骨。基于这些数据，采用不同训练策略和损失函数，发展了针对各物种以及三者通用的目标识别模型。最终还开发了基于智能手机的应用，可实时拍照识别。

Result: 最佳模型总体识别准确率为84.2%，其中象制品、穿山甲制品、虎制品准确率分别为71.1%、90.2%、93.5%。手机应用准确率达91.3%。

Conclusion: 所提出的机器学习检测方法和手机应用不仅适合网络监测，也适合线下市场执法，为政府和执法机构打击野生动植物非法贸易提供了高效工具。

Abstract: Unsustainable trade in wildlife is a major threat to biodiversity and is now
increasingly prevalent in digital marketplaces and social media. With the sheer
volume of digital content, the need for automated methods to detect wildlife
trade listings is growing. These methods are especially needed for the
automatic identification of wildlife products, such as ivory. We developed
machine learning-based object recognition models that can identify wildlife
products within images and highlight them. The data consists of images of
elephant, pangolin, and tiger products that were identified as being sold
illegally or that were confiscated by authorities. Specifically, the wildlife
products included elephant ivory and skins, pangolin scales, and claws (raw and
crafted), and tiger skins and bones. We investigated various combinations of
training strategies and two loss functions to identify the best model to use in
the automatic detection of these wildlife products. Models were trained for
each species while also developing a single model to identify products from all
three species. The best model showed an overall accuracy of 84.2% with
accuracies of 71.1%, 90.2% and 93.5% in detecting products derived from
elephants, pangolins, and tigers, respectively. We further demonstrate that the
machine learning model can be made easily available to stakeholders, such as
government authorities and law enforcement agencies, by developing a
smartphone-based application that had an overall accuracy of 91.3%. The
application can be used in real time to click images and help identify
potentially prohibited products of target species. Thus, the proposed method is
not only applicable for monitoring trade on the web but can also be used e.g.
in physical markets for monitoring wildlife trade.

</details>


### [132] [Hybrid Swin Attention Networks for Simultaneously Low-Dose PET and CT Denoising](https://arxiv.org/abs/2509.06591)
*Yichao Liu,YueYang Teng*

Main category: cs.CV

TL;DR: 本论文提出了一种新型的混合Swin注意力网络（HSANet），用于提升低剂量CT和PET医学影像的去噪效果，并兼顾模型轻量级与实际部署需求。


<details>
  <summary>Details</summary>
Motivation: 低剂量CT（LDCT）和PET扫描减少了辐射暴露，但因此导致成像噪音和伪影增多，影响诊断，因此亟需有效去噪方法提升图像质量，保证诊断安全性。

Method: 提出了HSANet网络，其中包含高效全局注意力模块（EGA），增强空间与通道特征的交互；同时引入混合上采样模块，减少对噪声的过拟合。该方法在公开LDCT/PET数据集上进行了验证。

Result: 实验结果表明，HSANet在去噪性能上优于现有方法，并且模型体积小、适合一般GPU部署，有利于实际临床应用。

Conclusion: HSANet为LDCT/PET影像去噪提供了高效、实用的新方法，兼顾了效果与部署需求，有望推动该技术在临床中的应用。

Abstract: Low-dose computed tomography (LDCT) and positron emission tomography (PET)
have emerged as safer alternatives to conventional imaging modalities by
significantly reducing radiation exposure. However, this reduction often
results in increased noise and artifacts, which can compromise diagnostic
accuracy. Consequently, denoising for LDCT/PET has become a vital area of
research aimed at enhancing image quality while maintaining radiation safety.
In this study, we introduce a novel Hybrid Swin Attention Network (HSANet),
which incorporates Efficient Global Attention (EGA) modules and a hybrid
upsampling module. The EGA modules enhance both spatial and channel-wise
interaction, improving the network's capacity to capture relevant features,
while the hybrid upsampling module mitigates the risk of overfitting to noise.
We validate the proposed approach using a publicly available LDCT/PET dataset.
Experimental results demonstrate that HSANet achieves superior denoising
performance compared to existing methods, while maintaining a lightweight model
size suitable for deployment on GPUs with standard memory configurations. This
makes our approach highly practical for real-world clinical applications.

</details>


### [133] [Improved Classification of Nitrogen Stress Severity in Plants Under Combined Stress Conditions Using Spatio-Temporal Deep Learning Framework](https://arxiv.org/abs/2509.06625)
*Aswini Kumar Patra*

Main category: cs.CV

TL;DR: 本文提出了一种结合多模态影像（RGB、多光谱和两种红外波段）与时序数据分析的深度学习方法，实现了在同时存在水分胁迫与杂草压力的复杂环境下，对作物氮素胁迫严重程度的高精度早期识别。


<details>
  <summary>Details</summary>
Motivation: 在自然环境中，作物通常同时面临多种胁迫（如养分缺乏、水分胁迫与杂草竞争），而氮素胁迫尤其复杂且与其他因素交互影响明显。早期识别氮素胁迫对作物管理和健康保护至关重要，目前缺乏能在多重压力下准确、自动识别的方法。

Method: 研究团队采集了不同氮素供应（低、中、高）、不同水分胁迫和杂草压力下作物冠层的多模态时序影像数据，并构建了以CNN提取空间特征、LSTM捕获时序特征的多模态深度学习流水线，同时对比了仅基于CNN的空间模型。

Result: 提出的CNN-LSTM模型在氮素胁迫严重度识别任务中取得98%准确率，明显优于空间模型（80.45%）及其它机器学习方法（76%）。

Conclusion: 本文的深度学习方案有效整合了多模态与时序信息，显著提升了在复杂重叠胁迫条件下的氮素胁迫早期识别能力，可为作物精准管理和健康监测提供有力的技术支持。

Abstract: Plants in their natural habitats endure an array of interacting stresses,
both biotic and abiotic, that rarely occur in isolation. Nutrient
stress-particularly nitrogen deficiency-becomes even more critical when
compounded with drought and weed competition, making it increasingly difficult
to distinguish and address its effects. Early detection of nitrogen stress is
therefore crucial for protecting plant health and implementing effective
management strategies. This study proposes a novel deep learning framework to
accurately classify nitrogen stress severity in a combined stress environment.
Our model uses a unique blend of four imaging modalities-RGB, multispectral,
and two infrared wavelengths-to capture a wide range of physiological plant
responses from canopy images. These images, provided as time-series data,
document plant health across three levels of nitrogen availability (low,
medium, and high) under varying water stress and weed pressures. The core of
our approach is a spatio-temporal deep learning pipeline that merges a
Convolutional Neural Network (CNN) for extracting spatial features from images
with a Long Short-Term Memory (LSTM) network to capture temporal dependencies.
We also devised and evaluated a spatial-only CNN pipeline for comparison. Our
CNN-LSTM pipeline achieved an impressive accuracy of 98%, impressively
surpassing the spatial-only model's 80.45% and other previously reported
machine learning method's 76%. These results bring actionable insights based on
the power of our CNN-LSTM approach in effectively capturing the subtle and
complex interactions between nitrogen deficiency, water stress, and weed
pressure. This robust platform offers a promising tool for the timely and
proactive identification of nitrogen stress severity, enabling better crop
management and improved plant health.

</details>


### [134] [VIM-GS: Visual-Inertial Monocular Gaussian Splatting via Object-level Guidance in Large Scenes](https://arxiv.org/abs/2509.06685)
*Shengkai Zhang,Yuhe Liu,Guanjun Wu,Jianhua He,Xinggang Wang,Mozi Chen,Kezhong Liu*

Main category: cs.CV

TL;DR: VIM-GS提出了一种使用单目图像进行大场景新视角合成的高质量高斯斑点框架，结合稀疏高精SfM深度和稠密但粗糙的大模型深度，实现了对大型场景的高质量渲染。


<details>
  <summary>Details</summary>
Motivation: 高斯斑点生成通常依赖RGB-D/双目摄像机获取准确深度，但这些设备对大场景支持有限。单目图像缺少深度，直接用于NVS效果不佳，而现有的大模型单目深度估计也面临一致性差和远距离场景不准等挑战。该工作旨在破解单目输入下的大场景高质量新视角渲染难题。

Method: 方法将稀疏但准确的SfM（三维重建）深度与来自大模型（LFM）的稠密但粗糙深度相结合：首先提出基于物体分割的深度传播算法，细化物体上像素的深度；然后设计动态深度细化模块专门处理动态物体和LFM深度的局限性。

Result: 实验在公开和自定义数据集上，证明了VIM-GS在大场景下生成的渲染质量优于现有方法。

Conclusion: 通过创新地结合稀疏SfM深度和稠密LFM深度，VIM-GS实现了高质量大场景新视角合成，为单目三维重建和高斯斑点应用提供了新方法。

Abstract: VIM-GS is a Gaussian Splatting (GS) framework using monocular images for
novel-view synthesis (NVS) in large scenes. GS typically requires accurate
depth to initiate Gaussian ellipsoids using RGB-D/stereo cameras. Their limited
depth sensing range makes it difficult for GS to work in large scenes.
Monocular images, however, lack depth to guide the learning and lead to
inferior NVS results. Although large foundation models (LFMs) for monocular
depth estimation are available, they suffer from cross-frame inconsistency,
inaccuracy for distant scenes, and ambiguity in deceptive texture cues. This
paper aims to generate dense, accurate depth images from monocular RGB inputs
for high-definite GS rendering. The key idea is to leverage the accurate but
sparse depth from visual-inertial Structure-from-Motion (SfM) to refine the
dense but coarse depth from LFMs. To bridge the sparse input and dense output,
we propose an object-segmented depth propagation algorithm that renders the
depth of pixels of structured objects. Then we develop a dynamic depth
refinement module to handle the crippled SfM depth of dynamic objects and
refine the coarse LFM depth. Experiments using public and customized datasets
demonstrate the superior rendering quality of VIM-GS in large scenes.

</details>


### [135] [BioLite U-Net: Edge-Deployable Semantic Segmentation for In Situ Bioprinting Monitoring](https://arxiv.org/abs/2509.06690)
*Usman Haider,Lukasz Szemet,Daniel Kelly,Vasileios Sergis,Andrew C. Daly,Karl Mason*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级的语义分割框架BioLite U-Net，实现了对生物打印过程的实时分割监测，在资源受限设备上具备高效推理能力，显著优于主流方法。


<details>
  <summary>Details</summary>
Motivation: 在生物打印过程中，实时监测印刷质量对于保证打印结构的精准性和生物活性至关重要。然而，受限于嵌入式硬件的算力和有限的图像采集数据，当前主流分割方法难以直接部署在实际系统中。

Method: 作者构建并手动标注了包含787张RGB图像的新数据集，划分为喷头、挤出生物墨水和背景三类，并提出了基于深度可分离卷积的BioLite U-Net结构，兼顾精度与硬件高效性。该模型与MobileNetV2和MobileNetV3等主流轻量级分割网络进行了对比评测，并在Raspberry Pi 4B上测试其实时推理性能。

Result: BioLite U-Net在mIoU上达到92.85%，Dice分数为96.17%，模型体积比MobileNetV2-DeepLabV3+小1300多倍，单帧推理耗时335ms，基本实现实时分割。对比MobileNetV2和V3基线，呈现更优的精度、效率及可部署性。

Conclusion: BioLite U-Net能够在低算力嵌入式平台上实现高效、精准、可实时的生物打印过程监测，为智能闭环生物打印系统的实现提供了有力的技术支持。

Abstract: Bioprinting is a rapidly advancing field that offers a transformative
approach to fabricating tissue and organ models through the precise deposition
of cell-laden bioinks. Ensuring the fidelity and consistency of printed
structures in real-time remains a core challenge, particularly under
constraints imposed by limited imaging data and resource-constrained embedded
hardware. Semantic segmentation of the extrusion process, differentiating
between nozzle, extruded bioink, and surrounding background, enables in situ
monitoring critical to maintaining print quality and biological viability. In
this work, we introduce a lightweight semantic segmentation framework tailored
for real-time bioprinting applications. We present a novel, manually annotated
dataset comprising 787 RGB images captured during the bioprinting process,
labeled across three classes: nozzle, bioink, and background. To achieve fast
and efficient inference suitable for integration with bioprinting systems, we
propose a BioLite U-Net architecture that leverages depthwise separable
convolutions to drastically reduce computational load without compromising
accuracy. Our model is benchmarked against MobileNetV2 and MobileNetV3-based
segmentation baselines using mean Intersection over Union (mIoU), Dice score,
and pixel accuracy. All models were evaluated on a Raspberry Pi 4B to assess
real-world feasibility. The proposed BioLite U-Net achieves an mIoU of 92.85%
and a Dice score of 96.17%, while being over 1300x smaller than
MobileNetV2-DeepLabV3+. On-device inference takes 335 ms per frame,
demonstrating near real-time capability. Compared to MobileNet baselines,
BioLite U-Net offers a superior tradeoff between segmentation accuracy,
efficiency, and deployability, making it highly suitable for intelligent,
closed-loop bioprinting systems.

</details>


### [136] [STAGE: Segmentation-oriented Industrial Anomaly Synthesis via Graded Diffusion with Explicit Mask Alignment](https://arxiv.org/abs/2509.06693)
*Xichen Xu,Yanshu Wang,Jinbao Wang,Qunyi Zhang,Xiaoning Lei,Guoyang Xie,Guannan Jiang,Zhichao Lu*

Main category: cs.CV

TL;DR: 本文提出了一种名为STAGE的新型工业异常合成方法，通过引入分级扩散机制和显式掩码对齐，大幅提升了异常区域纹理细节与背景融合效果，显著增强下游异常分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有工业异常合成方法生成的异常区域通常纹理细节不足，与背景匹配度低，且很难生成精细的像素级异常，限制了下游异常分割任务的性能提升。

Method: 方法STAGE引入了清洁背景先验引导扩散去噪过程，使模型更好区分和突出异常区域；设计了异常分支，以分级扩散记录本地异常，防止细微异常被忽略；并采用显式掩码对齐，逐步提升合成异常与背景的结构一致性。

Result: 实验在MVTec和BTAD数据集上验证，STAGE在工业异常合成任务上获得了当前最优性能，并有效提升了下游异常分割效果。

Conclusion: 通过提出的STAGE方法，解决了现有SIAS方法异常合成细节不足和像素对齐不佳的问题，为工业视觉异常检测提供了更高质量的训练数据和更强的分割能力。

Abstract: Segmentation-oriented Industrial Anomaly Synthesis (SIAS) plays a pivotal
role in enhancing the performance of downstream anomaly segmentation, as it
provides an effective means of expanding abnormal data. However, existing SIAS
methods face several critical limitations: (i) the synthesized anomalies often
lack intricate texture details and fail to align precisely with the surrounding
background, and (ii) they struggle to generate fine-grained, pixel-level
anomalies. To address these challenges, we propose Segmentation-oriented
Anomaly synthesis via Graded diffusion with Explicit mask alignment, termed
STAGE. STAGE introduces a novel anomaly inference strategy that incorporates
clean background information as a prior to guide the denoising distribution,
enabling the model to more effectively distinguish and highlight abnormal
foregrounds. Furthermore, it employs a graded diffusion framework with an
anomaly-only branch to explicitly record local anomalies during both the
forward and reverse processes, ensuring that subtle anomalies are not
overlooked. Finally, STAGE incorporates the explicit mask alignment (EMA)
strategy to progressively align the synthesized anomalies with the background,
resulting in context-consistent and structurally coherent generations.
Extensive experiments on the MVTec and BTAD datasets demonstrate that STAGE
achieves state-of-the-art performance in SIAS, which in turn enhances
downstream anomaly segmentation.

</details>


### [137] [Cortex-Synth: Differentiable Topology-Aware 3D Skeleton Synthesis with Hierarchical Graph Attention](https://arxiv.org/abs/2509.06705)
*Mohamed Zayaan S*

Main category: cs.CV

TL;DR: 本文提出了Cortex Synth，一种能从单张2D图片进行3D骨架几何结构与拓扑联合生成的端到端可微分框架，显著提升了准确率与骨架结构优化能力，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于2D图像三维骨架恢复方法在骨架几何及拓扑表述上均存在准确性与灵活性不足，且难以端到端优化。该研究旨在用更高效、可微分的整体结构解决这些挑战，拓展实际应用领域。

Method: 提出了三大创新：（1）采用多层次图注意力机制实现骨架逐级细化；（2）通过Laplacian特征值分解进行可微分的谱拓扑优化；（3）利用对抗式几何一致性训练实现三维姿势结构对齐。架构整合了伪3D点云生成模块、PointNet编码器、骨架坐标解码器和新颖的可微图构建网络（DGCN）。

Result: 在ShapeNet数据集上，模型在MPJPE指标上提升18.7%，在图编辑距离上提升27.3%，骨架拓扑错误率降低42%。性能远超同类方法。

Conclusion: Cortex Synth具备端到端可微优点，大幅提升了3D骨架几何与拓扑重建质量，在机器人操控、医学影像、动画角色绑定等领域有广阔应用前景。

Abstract: We present Cortex Synth, a novel end-to-end differentiable framework for
joint 3D skeleton geometry and topology synthesis from single 2D images. Our
architecture introduces three key innovations: (1) A hierarchical graph
attention mechanism with multi-scale skeletal refinement, (2) Differentiable
spectral topology optimization via Laplacian eigen decomposition, and (3)
Adversarial geometric consistency training for pose structure alignment. The
framework integrates four synergistic modules: a pseudo 3D point cloud
generator, an enhanced PointNet encoder, a skeleton coordinate decoder, and a
novel Differentiable Graph Construction Network (DGCN). Our experiments
demonstrate state-of-the-art results with 18.7 percent improvement in MPJPE and
27.3 percent in Graph Edit Distance on ShapeNet, while reducing topological
errors by 42 percent compared to previous approaches. The model's end-to-end
differentiability enables applications in robotic manipulation, medical
imaging, and automated character rigging.

</details>


### [138] [MRI-Based Brain Tumor Detection through an Explainable EfficientNetV2 and MLP-Mixer-Attention Architecture](https://arxiv.org/abs/2509.06713)
*Mustafa Yurdakul,Şakir Taşdemir*

Main category: cs.CV

TL;DR: 本文提出了一种结合EfficientNetV2和attention-based MLP-Mixer的新型深度学习模型，用于脑肿瘤MRI图像分类，取得了99.5%的高准确率并兼具可解释性。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤具有高死亡率，早期诊断至关重要，而MRI脑肿瘤手动诊断依赖专家且易出错，因此亟需高效、自动化且可解释的诊断系统。

Method: 作者首先在公开的Figshare脑肿瘤MRI数据集上，评估了九种主流CNN，最终选择EfficientNetV2为骨干网络，并将attention-based MLP-Mixer架构集成进EfficientNetV2以提升分类能力。同时，利用Grad-CAM可视化模型决策区域以增强可解释性。采用五折交叉验证进行模型评测。

Result: 最终模型取得了99.50%的准确率、99.47%的精确率、99.52%的召回率和99.49%的F1值，超过了当前文献中的主流方法。Grad-CAM结果也表明模型关注MRI图像的关键区域。

Conclusion: 结合EfficientNetV2与attention-based MLP-Mixer的深度学习模型在脑肿瘤分类上表现出优异且具有高度可解释性，具备临床决策支持系统的应用潜力。

Abstract: Brain tumors are serious health problems that require early diagnosis due to
their high mortality rates. Diagnosing tumors by examining Magnetic Resonance
Imaging (MRI) images is a process that requires expertise and is prone to
error. Therefore, the need for automated diagnosis systems is increasing day by
day. In this context, a robust and explainable Deep Learning (DL) model for the
classification of brain tumors is proposed. In this study, a publicly available
Figshare dataset containing 3,064 T1-weighted contrast-enhanced brain MRI
images of three tumor types was used. First, the classification performance of
nine well-known CNN architectures was evaluated to determine the most effective
backbone. Among these, EfficientNetV2 demonstrated the best performance and was
selected as the backbone for further development. Subsequently, an
attention-based MLP-Mixer architecture was integrated into EfficientNetV2 to
enhance its classification capability. The performance of the final model was
comprehensively compared with basic CNNs and the methods in the literature.
Additionally, Grad-CAM visualization was used to interpret and validate the
decision-making process of the proposed model. The proposed model's performance
was evaluated using the five-fold cross-validation method. The proposed model
demonstrated superior performance with 99.50% accuracy, 99.47% precision,
99.52% recall and 99.49% F1 score. The results obtained show that the model
outperforms the studies in the literature. Moreover, Grad-CAM visualizations
demonstrate that the model effectively focuses on relevant regions of MRI
images, thus improving interpretability and clinical reliability. A robust deep
learning model for clinical decision support systems has been obtained by
combining EfficientNetV2 and attention-based MLP-Mixer, providing high accuracy
and interpretability in brain tumor classification.

</details>


### [139] [Zero-shot 3D-Aware Trajectory-Guided image-to-video generation via Test-Time Training](https://arxiv.org/abs/2509.06723)
*Ruicheng Zhang,Jun Zhou,Zunnan Xu,Zihao Liu,Jiehui Huang,Mingyang Zhang,Yu Sun,Xiu Li*

Main category: cs.CV

TL;DR: 本文提出了一种无需额外训练、可在测试时实现轨迹引导的图像生成视频方法Zo3T，有效提升了合成视频的3D真实性和运动准确性。


<details>
  <summary>Details</summary>
Motivation: 已有方法在图像到视频的轨迹控制任务中，依赖训练或微调带标签数据，成本高且样本稀缺。零样本方法往往忽视3D视角，导致动画不真实。

Method: 作者提出Zo3T，包括三项创新：1）结合3D感知运动投影，利用场景深度推断校正变换，让运动更符合3D透视；2）引入轨迹引导的测试时LoRA，通过动态适配LoRA权重调整网络局部，使生成过程跟随运动指令，同时保持画面真实和风格一致；3）提出条件引导场修正策略，利用预测一步未来路径的方法，优化生成进程提升运动精度。

Result: Zo3T在无需额外数据和反复训练情况下，显著提升了图像到视频生成任务中，对用户指定轨迹的运动准确性和三维视觉拟真度，效果优于现有训练或零样本方法。

Conclusion: Zo3T为图像到视频的自定义轨迹生成提供了一种高效准确新方案，推动了无监督、零样本的3D感知视频生成技术发展，具有广泛应用前景。

Abstract: Trajectory-Guided image-to-video (I2V) generation aims to synthesize videos
that adhere to user-specified motion instructions. Existing methods typically
rely on computationally expensive fine-tuning on scarce annotated datasets.
Although some zero-shot methods attempt to trajectory control in the latent
space, they may yield unrealistic motion by neglecting 3D perspective and
creating a misalignment between the manipulated latents and the network's noise
predictions. To address these challenges, we introduce Zo3T, a novel zero-shot
test-time-training framework for trajectory-guided generation with three core
innovations: First, we incorporate a 3D-Aware Kinematic Projection, leveraging
inferring scene depth to derive perspective-correct affine transformations for
target regions. Second, we introduce Trajectory-Guided Test-Time LoRA, a
mechanism that dynamically injects and optimizes ephemeral LoRA adapters into
the denoising network alongside the latent state. Driven by a regional feature
consistency loss, this co-adaptation effectively enforces motion constraints
while allowing the pre-trained model to locally adapt its internal
representations to the manipulated latent, thereby ensuring generative fidelity
and on-manifold adherence. Finally, we develop Guidance Field Rectification,
which refines the denoising evolutionary path by optimizing the conditional
guidance field through a one-step lookahead strategy, ensuring efficient
generative progression towards the target trajectory. Zo3T significantly
enhances 3D realism and motion accuracy in trajectory-controlled I2V
generation, demonstrating superior performance over existing training-based and
zero-shot approaches.

</details>


### [140] [Co-Seg: Mutual Prompt-Guided Collaborative Learning for Tissue and Nuclei Segmentation](https://arxiv.org/abs/2509.06740)
*Qing Xu,Wenting Duan,Zhen Chen*

Main category: cs.CV

TL;DR: 本文提出了一种协同分割（Co-Seg）框架，融合组织区域与细胞核实例分割，实现更高质量的病理图像分析，并在PUMA数据集实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有病理图像分析方法仅关注组织语义分割或细胞核实例分割之一，未能挖掘两者之间的内在关系，导致理解不充分。因此，作者希望建立协同模型来提升分割精度和病理学理解。

Method: 提出Co-Seg框架，引入区域感知提示编码器（RP-Encoder）用于生成高质量语义和实例区域提示，以先验约束分割过程。又设计互导提示掩码解码器（MP-Decoder），通过任务间的交互增强上下文一致性，实现组织与细胞核的协同分割。

Result: 在PUMA数据集上，Co-Seg在组织和细胞核的语义、实例及全景分割任务中均超越其它先进方法，证明融合策略与新模块的有效性。

Conclusion: 协同分割框架有效提升了病理图像中组织与细胞核分割的性能，为肿瘤微环境和细胞形态分析提供了更高质量的工具。

Abstract: Histopathology image analysis is critical yet challenged by the demand of
segmenting tissue regions and nuclei instances for tumor microenvironment and
cellular morphology analysis. Existing studies focused on tissue semantic
segmentation or nuclei instance segmentation separately, but ignored the
inherent relationship between these two tasks, resulting in insufficient
histopathology understanding. To address this issue, we propose a Co-Seg
framework for collaborative tissue and nuclei segmentation. Specifically, we
introduce a novel co-segmentation paradigm, allowing tissue and nuclei
segmentation tasks to mutually enhance each other. To this end, we first devise
a region-aware prompt encoder (RP-Encoder) to provide high-quality semantic and
instance region prompts as prior constraints. Moreover, we design a mutual
prompt mask decoder (MP-Decoder) that leverages cross-guidance to strengthen
the contextual consistency of both tasks, collaboratively computing semantic
and instance segmentation masks. Extensive experiments on the PUMA dataset
demonstrate that the proposed Co-Seg surpasses state-of-the-arts in the
semantic, instance and panoptic segmentation of tumor tissues and nuclei
instances. The source code is available at https://github.com/xq141839/Co-Seg.

</details>


### [141] [Pothole Detection and Recognition based on Transfer Learning](https://arxiv.org/abs/2509.06750)
*Mang Hu,Qianqian Xia*

Main category: cs.CV

TL;DR: 本文提出了一种基于深度学习的自动坑洞检测模型，通过对道路图像进行特征提取，实现了高效高准确率的坑洞识别。


<details>
  <summary>Details</summary>
Motivation: 随着计算机视觉与机器学习的发展，基于图像和视频的道路坑洞自动检测受到广泛关注，旨在通过自动化手段提升道路安全和维护效率。

Method: 作者对采集到的数据集进行了标准化、归一化和数据增强预处理，并基于实验结果不断优化网络架构。最终提出了融合ResNet50、EfficientNet和RegNet的迁移学习特征提取网络。该模型通过与随机森林、MLP、SVM和LightGBM等传统方法在多项指标下进行了对比实验。

Result: 实验结果显示，提出的迁移学习模型在识别速度和准确率上均优于其他对比模型，在90个初始测试样本上准确率达到97.78%，在900个扩展测试样本上准确率为98.89%。

Conclusion: 通过有效的参数选择和模型优化，所提深度学习迁移模型在自动化坑洞检测任务上展现出卓越性能，具有广泛的实际应用前景。

Abstract: With the rapid development of computer vision and machine learning, automated
methods for pothole detection and recognition based on image and video data
have received significant attention. It is of great significance for social
development to conduct an in-depth analysis of road images through feature
extraction, thereby achieving automatic identification of the pothole condition
in new images. Consequently, this is the main issue addressed in this study.
Based on preprocessing techniques such as standardization, normalization, and
data augmentation applied to the collected raw dataset, we continuously
improved the network model based on experimental results. Ultimately, we
constructed a deep learning feature extraction network
ResNet50-EfficientNet-RegNet model based on transfer learning. This model
exhibits high classification accuracy and computational efficiency. In terms of
model evaluation, this study employed a comparative evaluation approach by
comparing the performance of the proposed transfer learning model with other
models, including Random Forest, MLP, SVM, and LightGBM. The comparison
analysis was conducted based on metrics such as Accuracy, Recall, Precision,
F1-score, and FPS, to assess the classification performance of the transfer
learning model proposed in this paper. The results demonstrate that our model
exhibits high performance in terms of recognition speed and accuracy,
surpassing the performance of other models. Through careful parameter selection
and model optimization, our transfer learning model achieved a classification
accuracy of 97.78% (88/90) on the initial set of 90 test samples and 98.89%
(890/900) on the expanded test set.

</details>


### [142] [Raw2Event: Converting Raw Frame Camera into Event Camera](https://arxiv.org/abs/2509.06767)
*Zijie Ning,Enmin Lin,Sudarshan R. Iyengar,Patrick Vandewalle*

Main category: cs.CV

TL;DR: 该论文提出了Raw2Event系统，实现了低成本帧式相机实时生成事件数据，为事件视觉研究提供了高分辨率、灵活可调的经济型解决方案。


<details>
  <summary>Details</summary>
Motivation: 昂贵的事件相机在分辨率、成本等方面存在限制，影响了其在早期开发和原型设计中的普及。作者希望通过低成本硬件，拓展事件视觉的适用范围。

Method: 提出Raw2Event软硬件系统，直接访问相机原始Bayer数据，绕过传统ISP，实现高动态范围与高分辨率的事件数据生成。该系统基于DVS-Voltmeter模型，具备可配置仿真框架，适用于嵌入式平台，并配套同步采集原始、RGB及事件数据流的管道。

Result: Raw2Event系统生成的事件流与真实事件相机高度相似，同时具备分辨率更高与自动对焦等优势，参数可灵活调整，已可在树莓派等设备上实时运行。

Conclusion: Raw2Event为事件视觉领域和系统早期开发提供了低成本、高性能的解决方案，有助于推动事件相机技术的普及和应用。

Abstract: Event cameras offer unique advantages such as high temporal resolution, low
latency, and high dynamic range, making them more and more popular for vision
tasks under challenging light conditions. However, their high cost, limited
resolution, and lack of features such as autofocus hinder their broad adoption,
particularly for early-stage development and prototyping. In this work, we
present Raw2Event, a complete hardware-software system that enables real-time
event generation from low-cost raw frame-based cameras. By leveraging direct
access to raw Bayer data and bypassing traditional image signal processors
(ISP), our system is able to utilize the full potential of camera hardware,
delivering higher dynamic range, higher resolution, and more faithful output
than RGB-based frame-to-event converters.
  Built upon the DVS-Voltmeter model, Raw2Event features a configurable
simulation framework optimized for deployment on embedded platforms. We further
design a data acquisition pipeline that supports synchronized recording of raw,
RGB, and event streams, facilitating downstream evaluation and dataset
creation. Experimental results show that Raw2Event can generate event streams
closely resembling those from real event cameras, while benefiting from higher
resolution and autofocus capabilities. The system also supports user-intuitive
parameter tuning, enabling flexible adaptation to various application
requirements. Finally, we deploy the system on a Raspberry Pi for real-time
operation, providing a scalable and cost-effective solution for event-based
vision research and early-stage system development.
  The codes are available online:
https://anonymous.4open.science/r/raw2event-BFF2/README.md.

</details>


### [143] [D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning](https://arxiv.org/abs/2509.06771)
*Sai Kartheek Reddy Kasu,Mohammad Zia Ur Rehman,Shahid Shafi Dar,Rishi Bharat Junghare,Dhanvin Sanjay Namboodiri,Nagendra Kumar*

Main category: cs.CV

TL;DR: 该论文针对网络表情包中的黑色幽默，构建了一个包含4379个Reddit表情包的多模态数据集，标注了黑色幽默、靶向类别及强度等级，并提出了结合推理能力的多模态识别方法，有效提升了黑色幽默的识别、靶向对象与强度预测任务表现。


<details>
  <summary>Details</summary>
Motivation: 黑色幽默依赖隐性、敏感和文化相关线索，目前缺乏针对多模态内容（如图片和文本结合）的黑色幽默识别资源和有效方法。为支持该领域进一步研究，需要建立高质量的数据集及改进识别技术。

Method: 论文首先构建了标注有黑色幽默及其相关属性的多模态数据集。随后，基于大规模视觉-语言模型（VLM），通过生成结构化解释和角色反转循环，提升模型对幽默推理的理解能力。文本特征通过OCR和自我推理文本编码获取，视觉特征用视觉变换器提取，三类特征通过三流交叉推理网络（TCRNet）融合并进行分类。

Result: 实验证明，所提出的方法在黑色幽默检测、对象识别和强度预测三项任务上，均优于其他强有力的基线方法。

Conclusion: 该研究为多模态黑色幽默理解和内容审核提供了高质量的数据资源和效果突出的新方法，有助于推动该领域的发展。数据集和代码也已公开，便于社区进一步研究和应用。

Abstract: Dark humor in online memes poses unique challenges due to its reliance on
implicit, sensitive, and culturally contextual cues. To address the lack of
resources and methods for detecting dark humor in multimodal content, we
introduce a novel dataset of 4,379 Reddit memes annotated for dark humor,
target category (gender, mental health, violence, race, disability, and other),
and a three-level intensity rating (mild, moderate, severe). Building on this
resource, we propose a reasoning-augmented framework that first generates
structured explanations for each meme using a Large Vision-Language Model
(VLM). Through a Role-Reversal Self-Loop, VLM adopts the author's perspective
to iteratively refine its explanations, ensuring completeness and alignment. We
then extract textual features from both the OCR transcript and the self-refined
reasoning via a text encoder, while visual features are obtained using a vision
transformer. A Tri-stream Cross-Reasoning Network (TCRNet) fuses these three
streams, text, image, and reasoning, via pairwise attention mechanisms,
producing a unified representation for classification. Experimental results
demonstrate that our approach outperforms strong baselines across three tasks:
dark humor detection, target identification, and intensity prediction. The
dataset, annotations, and code are released to facilitate further research in
multimodal humor understanding and content moderation. Code and Dataset are
available at:
https://github.com/Sai-Kartheek-Reddy/D-Humor-Dark-Humor-Understanding-via-Multimodal-Open-ended-Reasoning

</details>


### [144] [UrbanTwin: High-Fidelity Synthetic Replicas of Roadside Lidar Datasets](https://arxiv.org/abs/2509.06781)
*Muhammad Shahbaz,Shaurya Agarwal*

Main category: cs.CV

TL;DR: 本文提出了UrbanTwin数据集，即基于LUMPI、V2X-Real-IC和TUMTraf-I三组公开道路侧激光雷达（lidar）数据集，通过高精度数字孪生技术仿真合成的大规模数据集。每个数据集包括1万帧3D标注，内容涵盖3D检测、实例分割、跟踪与语义分割等多任务标签。结果显示，UrbanTwin数据集与真实数据高度一致，并在训练3D目标检测模型时表现优异。数据集已公开发布。


<details>
  <summary>Details</summary>
Motivation: 现有公开的道路激光雷达数据集在规模、场景多样性和标注完整性方面有限，且获取真实数据代价高昂。本文旨在利用数字孪生技术合成高保真、与真实场景对齐的数据集，以扩充现有基准数据并提升模型泛化能力。

Method: 作者通过对实际公开数据集对应的真实场景进行精确建模，包括周边几何、车道级路网、路口车辆流动等，在数字孪生环境中仿真并采集激光雷达数据。同时，每一帧数据配有3D包围框、实例分割、跟踪以及语义分割标签，涉及6种目标类别和9种语义类别。作者通过结构和统计分析验证与真实数据集的一致性，并在3D检测任务上仅用合成数据训练模型，再在真实数据集上测试效果。

Result: 合成数据集UrbanTwin与真实数据在统计和结构上表现出高度相似性。仅用合成数据训练的3D目标检测模型在真实未见数据上表现良好，并且在某些情况下优于直接用真实数据训练的模型，表明合成数据有补充和增强基准数据集的实际价值。

Conclusion: UrbanTwin为激光雷达感知任务提供了首套能够替代真实域数据集的数字仿真数据集，可扩展样本数和场景多样性，也能通过修改仿真参数支持更多自定义场景，对深度学习模型的发展和测试具有重要促进作用。

Abstract: This article presents UrbanTwin datasets - high-fidelity, realistic replicas
of three public roadside lidar datasets: LUMPI, V2X-Real-IC, and TUMTraf-I.
Each UrbanTwin dataset contains 10K annotated frames corresponding to one of
the public datasets. Annotations include 3D bounding boxes, instance
segmentation labels, and tracking IDs for six object classes, along with
semantic segmentation labels for nine classes. These datasets are synthesized
using emulated lidar sensors within realistic digital twins, modeled based on
surrounding geometry, road alignment at lane level, and the lane topology and
vehicle movement patterns at intersections of the actual locations
corresponding to each real dataset. Due to the precise digital twin modeling,
the synthetic datasets are well aligned with their real counterparts, offering
strong standalone and augmentative value for training deep learning models on
tasks such as 3D object detection, tracking, and semantic and instance
segmentation. We evaluate the alignment of the synthetic replicas through
statistical and structural similarity analysis with real data, and further
demonstrate their utility by training 3D object detection models solely on
synthetic data and testing them on real, unseen data. The high similarity
scores and improved detection performance, compared to the models trained on
real data, indicate that the UrbanTwin datasets effectively enhance existing
benchmark datasets by increasing sample size and scene diversity. In addition,
the digital twins can be adapted to test custom scenarios by modifying the
design and dynamics of the simulations. To our knowledge, these are the first
digitally synthesized datasets that can replace in-domain real-world datasets
for lidar perception tasks. UrbanTwin datasets are publicly available at
https://dataverse.harvard.edu/dataverse/ucf-ut.

</details>


### [145] [P3-SAM: Native 3D Part Segmentation](https://arxiv.org/abs/2509.06784)
*Changfeng Ma,Yang Li,Xinhao Yan,Jiachen Xu,Yunhan Yang,Chunshi Wang,Zibo Zhao,Yanwen Guo,Zhuo Chen,Chunchao Guo*

Main category: cs.CV

TL;DR: 本文提出了一种全自动3D部件分割模型（P3-SAM），能高效且鲁棒地对复杂3D对象进行部件划分，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有3D部件分割方法在处理复杂模型时鲁棒性差、且无法完全自动化，影响3D理解与后续应用。

Method: 提出P3-SAM模型，包含特征提取器、多个分割头及IoU预测器，支持用户交互分割。同时设计了一种自动选择与合并预测掩码的算法，实现自动部件实例分割。模型在包含370万3D模型的新数据集上训练。

Result: 实验证明，所提方法在各种复杂3D对象上表现出高精度和强鲁棒性，达到了最新的性能水平。

Conclusion: P3-SAM能够准确且鲁棒地实现3D对象的全自动分割，优于现有方案，有望促进3D资产的理解与应用。

Abstract: Segmenting 3D assets into their constituent parts is crucial for enhancing 3D
understanding, facilitating model reuse, and supporting various applications
such as part generation. However, current methods face limitations such as poor
robustness when dealing with complex objects and cannot fully automate the
process. In this paper, we propose a native 3D point-promptable part
segmentation model termed P3-SAM, designed to fully automate the segmentation
of any 3D objects into components. Inspired by SAM, P3-SAM consists of a
feature extractor, multiple segmentation heads, and an IoU predictor, enabling
interactive segmentation for users. We also propose an algorithm to
automatically select and merge masks predicted by our model for part instance
segmentation. Our model is trained on a newly built dataset containing nearly
3.7 million models with reasonable segmentation labels. Comparisons show that
our method achieves precise segmentation results and strong robustness on any
complex objects, attaining state-of-the-art performance. Our code will be
released soon.

</details>


### [146] [AIM 2025 Challenge on High FPS Motion Deblurring: Methods and Results](https://arxiv.org/abs/2509.06793)
*George Ciubotariu,Florin-Alexandru Vasluianu,Zhuyun Zhou,Nancy Mehta,Radu Timofte,Ke Wu,Long Sun,Lingshun Kong,Zhongbao Yang,Jinshan Pan,Jiangxin Dong,Jinhui Tang,Hao Chen,Yinghui Fang,Dafeng Zhang,Yongqi Song,Jiangbo Guo,Shuhua Jin,Zeyu Xiao,Rui Zhao,Zhuoyuan Li,Cong Zhang,Yufeng Peng,Xin Lu,Zhijing Sun,Chengjie Ge,Zihao Li,Zishun Liao,Ziang Zhou,Qiyu Kang,Xueyang Fu,Zheng-Jun Zha,Yuqian Zhang,Shuai Liu,Jie Liu,Zhuhao Zhang,Lishen Qu,Zhihao Liu,Shihao Zhou,Yaqi Luo,Juncheng Zhou,Jufeng Yang,Qianfeng Yang,Qiyuan Guan,Xiang Chen,Guiyue Jin,Jiyu Jin*

Main category: cs.CV

TL;DR: 本文回顾了AIM 2025高帧率非均匀运动去模糊挑战赛，介绍了各参赛方案及结果，总结了该领域的最新进展。


<details>
  <summary>Details</summary>
Motivation: 近年来由于运动导致的图像模糊问题突出，特别是在高帧率和复杂运动条件下，现有方法效果有限。设计更有效的深度学习网络，以在复杂、非均匀运动下恢复清晰图像，成为学术界关注热点。

Method: 比赛吸引了68个团队报名，最终有9支队伍提交有效方案。参赛方法多采用先进神经网络，利用新提出的MIORe数据集进行训练和测试，MIORe集成了多种复杂运动模式，提高了挑战难度。

Result: 通过综合评估各参赛方法表现，参赛团队在单帧高帧率运动去模糊任务上取得了前所未有的进展，部分方案能在极为复杂的运动场景下恢复出清晰、视觉效果良好的图像。

Conclusion: 本文全面展示了高帧率单图像运动去模糊研究的新高度，同时MIORe数据集的引入推动了该领域的发展，为未来研究提供了宝贵的参考和挑战。

Abstract: This paper presents a comprehensive review of the AIM 2025 High FPS
Non-Uniform Motion Deblurring Challenge, highlighting the proposed solutions
and final results. The objective of this challenge is to identify effective
networks capable of producing clearer and visually compelling images in diverse
and challenging conditions, by learning representative visual cues for complex
aggregations of motion types. A total of 68 participants registered for the
competition, and 9 teams ultimately submitted valid entries. This paper
thoroughly evaluates the state-of-the-art advances in high-FPS single image
motion deblurring, showcasing the significant progress in the field, while
leveraging samples of the novel dataset, MIORe, that introduces challenging
examples of movement patterns.

</details>


### [147] [SynthDrive: Scalable Real2Sim2Real Sensor Simulation Pipeline for High-Fidelity Asset Generation and Driving Data Synthesis](https://arxiv.org/abs/2509.06798)
*Zhengqing Chen,Ruohong Mei,Xiaoyang Guo,Qingjie Wang,Yubin Hu,Wei Yin,Weiqiang Ren,Qian Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种可扩展的实时仿真系统，通过3D生成实现自动素材挖掘和罕见场景数据的合成，旨在提升无人驾驶传感器模拟的多样性和适用性。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶的传感器模拟存在两大问题：一是基于CG的方法多样性不足且难以扩展；二是基于学习的方法通常只能处理特定类别目标，并且对大量多模态数据依赖性强，限制了其应用范围。因此，迫切需要一种既能覆盖多样/稀有场景又适用范围广的新型模拟方法。

Method: 本文提出了一种“real2sim2real”系统，基于3D生成技术，实现资产自动化挖掘、自动生成以及稀有案例数据自动合成，通过端到端流程提高模拟数据的多样性和扩展能力。

Result: 该系统能够自动生成多样化的3D仿真资产和罕见场景数据，提升了仿真内容的丰富性，相比现有CG或学习方法大幅度扩展了适用对象和场景。

Conclusion: 新方法为无人驾驶感知系统训练提供了更丰富、真实和可扩展的数据资源，有助于提升无人驾驶系统在真实复杂环境中的鲁棒性。

Abstract: In the field of autonomous driving, sensor simulation is essential for
generating rare and diverse scenarios that are difficult to capture in
real-world environments. Current solutions fall into two categories: 1)
CG-based methods, such as CARLA, which lack diversity and struggle to scale to
the vast array of rare cases required for robust perception training; and 2)
learning-based approaches, such as NeuSim, which are limited to specific object
categories (vehicles) and require extensive multi-sensor data, hindering their
applicability to generic objects. To address these limitations, we propose a
scalable real2sim2real system that leverages 3D generation to automate asset
mining, generation, and rare-case data synthesis.

</details>


### [148] [MIORe & VAR-MIORe: Benchmarks to Push the Boundaries of Restoration](https://arxiv.org/abs/2509.06803)
*George Ciubotariu,Zhuyun Zhou,Zongwei Wu,Radu Timofte*

Main category: cs.CV

TL;DR: 本文提出了两个新的多任务运动恢复数据集——MIORe和VAR-MIORe，克服了现有运动恢复基准的诸多局限，并为各种图像与视频恢复任务的下一代研究奠定基础。


<details>
  <summary>Details</summary>
Motivation: 当前的运动恢复基准在运动多样性、逼真性及运动幅度控制等方面存在明显不足，难以有效促进算法在复杂真实场景下的进步。

Method: 作者利用高帧率（1000 FPS）与专业光学采集手段，记录了包含复杂运动场景（如自运动、多人动态交互、深度相关模糊）的数据，通过基于光流自适应平均生成一致性运动模糊，保留清晰输入供插帧、光流等任务。VAR-MIORe扩展引入不同运动幅度，首次实现了运动幅度的可控基准设置。

Result: 这两个数据集提供了高分辨率且可扩展的高可信真值标签，在受控与极端工况下对现有运动恢复算法提出了更高挑战。

Conclusion: MIORe和VAR-MIORe数据集显著提升了运动恢复相关任务的基准质量，为后续的图像与视频恢复技术发展提供了更加严苛、真实和多样化的测试平台。

Abstract: We introduce MIORe and VAR-MIORe, two novel multi-task datasets that address
critical limitations in current motion restoration benchmarks. Designed with
high-frame-rate (1000 FPS) acquisition and professional-grade optics, our
datasets capture a broad spectrum of motion scenarios, which include complex
ego-camera movements, dynamic multi-subject interactions, and depth-dependent
blur effects. By adaptively averaging frames based on computed optical flow
metrics, MIORe generates consistent motion blur, and preserves sharp inputs for
video frame interpolation and optical flow estimation. VAR-MIORe further
extends by spanning a variable range of motion magnitudes, from minimal to
extreme, establishing the first benchmark to offer explicit control over motion
amplitude. We provide high-resolution, scalable ground truths that challenge
existing algorithms under both controlled and adverse conditions, paving the
way for next-generation research of various image and video restoration tasks.

</details>


### [149] [UMO: Scaling Multi-Identity Consistency for Image Customization via Matching Reward](https://arxiv.org/abs/2509.06818)
*Yufeng Cheng,Wenxu Wu,Shaojin Wu,Mengqi Huang,Fei Ding,Qian He*

Main category: cs.CV

TL;DR: 该论文提出了一个统一多身份优化（UMO）框架，用于图像定制过程中实现多身份的一致性与较低的身份混淆，并在多种方法上刷新了身份保持效果的新水平。


<details>
  <summary>Details</summary>
Motivation: 当前图像定制在多身份（例如多个人物）的自定义能力上有限，主要挑战是难以在多参考图像之间保持身份一致且避免身份混淆，无法很好扩展到大规模多身份场景。

Method: 提出了UMO框架，将多身份生成问题形式化为全局分配优化问题，并通过在扩散模型上引入强化学习，提升多身份一致性。为此特地构建了包含合成与真实多参考图像的大规模定制数据集，并提出了衡量身份混淆的新指标。

Result: 大量实验表明，UMO能够显著提升身份一致性，有效降低身份混淆，在开源方法中实现了身份保持新的最佳效果。

Conclusion: UMO为图像个性化领域带来了具备可扩展性与高身份一致性的多身份定制解决方案，有望提升相关应用在多身份场景下的实际表现。

Abstract: Recent advancements in image customization exhibit a wide range of
application prospects due to stronger customization capabilities. However,
since we humans are more sensitive to faces, a significant challenge remains in
preserving consistent identity while avoiding identity confusion with
multi-reference images, limiting the identity scalability of customization
models. To address this, we present UMO, a Unified Multi-identity Optimization
framework, designed to maintain high-fidelity identity preservation and
alleviate identity confusion with scalability. With "multi-to-multi matching"
paradigm, UMO reformulates multi-identity generation as a global assignment
optimization problem and unleashes multi-identity consistency for existing
image customization methods generally through reinforcement learning on
diffusion models. To facilitate the training of UMO, we develop a scalable
customization dataset with multi-reference images, consisting of both
synthesised and real parts. Additionally, we propose a new metric to measure
identity confusion. Extensive experiments demonstrate that UMO not only
improves identity consistency significantly, but also reduces identity
confusion on several image customization methods, setting a new
state-of-the-art among open-source methods along the dimension of identity
preserving. Code and model: https://github.com/bytedance/UMO

</details>


### [150] [Video-Based MPAA Rating Prediction: An Attention-Driven Hybrid Architecture Using Contrastive Learning](https://arxiv.org/abs/2509.06826)
*Dipta Neogi,Nourash Azmine Chowdhury,Muhammad Rafsan Kabir,Mohammad Ashrafuzzaman Khan*

Main category: cs.CV

TL;DR: 本文提出一种基于对比学习的视频分级自动化方法，尤其适用于MPAA年龄分级标准，实现了高准确率和实际应用的良好效果。


<details>
  <summary>Details</summary>
Motivation: 随着各类平台视觉内容的快速增长，亟需自动化工具来判别视频内容的适龄级别。传统方法受限于数据标注量大、泛化能力差和特征学习效率低，难以满足实际需求。

Method: 文章采用三种对比学习框架（Instance Discrimination、Contextual Contrastive Learning、Multi-View Contrastive Learning），并提出结合CNN+LSTM为骨干网络，辅以Bahdanau注意力机制的混合架构进行视频分级。模型分别利用CNN提取空间特征，LSTM建模时间信息，注意力机制聚焦关键画面。多种对比损失（如NT-Xent、Margin Triplet等）用于增强特征区分性。

Result: 在Contextual Contrastive Learning框架下，所提模型取得88%的准确率和0.8815的F1分数，展现出区分PG-13与R等细粒度标签的能力。不同对比损失下模型皆具稳健性。

Conclusion: 融合对比学习和深度时空特征建模，能显著提升视频内容分级的效果。模型已作为网络应用部署，为流媒体平台提供高效、实时的自动化分级解决方案，显示了良好的实际应用前景。

Abstract: The rapid growth of visual content consumption across platforms necessitates
automated video classification for age-suitability standards like the MPAA
rating system (G, PG, PG-13, R). Traditional methods struggle with large
labeled data requirements, poor generalization, and inefficient feature
learning. To address these challenges, we employ contrastive learning for
improved discrimination and adaptability, exploring three frameworks: Instance
Discrimination, Contextual Contrastive Learning, and Multi-View Contrastive
Learning. Our hybrid architecture integrates an LRCN (CNN+LSTM) backbone with a
Bahdanau attention mechanism, achieving state-of-the-art performance in the
Contextual Contrastive Learning framework, with 88% accuracy and an F1 score of
0.8815. By combining CNNs for spatial features, LSTMs for temporal modeling,
and attention mechanisms for dynamic frame prioritization, the model excels in
fine-grained borderline distinctions, such as differentiating PG-13 and R-rated
content. We evaluate the model's performance across various contrastive loss
functions, including NT-Xent, NT-logistic, and Margin Triplet, demonstrating
the robustness of our proposed architecture. To ensure practical application,
the model is deployed as a web application for real-time MPAA rating
classification, offering an efficient solution for automated content compliance
across streaming platforms.

</details>


### [151] [Curia: A Multi-Modal Foundation Model for Radiology](https://arxiv.org/abs/2509.06830)
*Corentin Dancette,Julien Khlaut,Antoine Saporta,Helene Philippe,Elodie Ferreres,Baptiste Callard,Théo Danielou,Léo Alberge,Léo Machado,Daniel Tordjman,Julie Dupuis,Korentin Le Floch,Jean Du Terrail,Mariam Moshiri,Laurent Dercle,Tom Boeken,Jules Gregory,Maxime Ronot,François Legou,Pascal Roux,Marc Sapoval,Pierre Manceron,Paul Hérent*

Main category: cs.CV

TL;DR: 该论文介绍了一款名为Curia的基础模型，在大规模、多模态医学影像数据集上进行了训练，并在多项放射学任务中取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 现有AI辅助手段大多是窄域、单任务，难以应对实际放射学中类型丰富的成像、疾病与发现。基础模型有望实现更强的泛化能力，但在放射学领域的潜力尚未被充分开发。

Method: 作者在某大型医院多年累计收集了150,000例横断面影像（共130TB），用其训练了Curia基础模型，并在新构建的19项外部验证任务基准上测试了模型的多任务能力。

Result: Curia能够准确完成器官识别、疾病检测（例如脑出血、心肌梗死）、肿瘤分期等任务，并在跨模态和低样本场景下展现出显著的临床泛化能力。其表现达到或超过放射科医生及现有基础模型。

Conclusion: Curia基础模型展示了在实际医疗环境下广义泛化的潜力。作者还开放了基础模型权重，以促进相关研究发展。

Abstract: AI-assisted radiological interpretation is based on predominantly narrow,
single-task models. This approach is impractical for covering the vast spectrum
of imaging modalities, diseases, and radiological findings. Foundation models
(FMs) hold the promise of broad generalization across modalities and in
low-data settings. However, this potential has remained largely unrealized in
radiology. We introduce Curia, a foundation model trained on the entire
cross-sectional imaging output of a major hospital over several years, which to
our knowledge is the largest such corpus of real-world data-encompassing
150,000 exams (130 TB). On a newly curated 19-task external validation
benchmark, Curia accurately identifies organs, detects conditions like brain
hemorrhages and myocardial infarctions, and predicts outcomes in tumor staging.
Curia meets or surpasses the performance of radiologists and recent foundation
models, and exhibits clinically significant emergent properties in
cross-modality, and low-data regimes. To accelerate progress, we release our
base model's weights at https://huggingface.co/raidium/curia.

</details>


### [152] [Leveraging Generic Foundation Models for Multimodal Surgical Data Analysis](https://arxiv.org/abs/2509.06831)
*Simon Pezold,Jérôme A. Kurylec,Jan S. Liechti,Beat P. Müller,Joël L. Lavanchy*

Main category: cs.CV

TL;DR: 本论文探讨了如何通过迁移学习对基础模型进行适应及结合手术室多模态数据，提升外科数据科学的能力。主要使用V-JEPA模型，并在实际任务上验证有效性。


<details>
  <summary>Details</summary>
Motivation: 外科手术过程中产生的多源数据为辅助决策和提升医疗质量提供了潜力，但如何有效利用这些数据以及预训练基础模型，仍存在挑战。论文旨在探究如何通过迁移学习和多模态信息整合提升模型表现。

Method: 以V-JEPA为基础，先对所有任务应用其预训练权重作为基线，然后在无标签手术视频上对其进行领域自适应微调。此外，论文将手术室额外的时序数据通过单独编码器与V-JEPA嵌入融合，实现多模态信息共享表征。评测任务包括住院时长、术后并发症预测（自有数据集）和手术阶段识别（公开数据集）。

Result: 在自有肝脏手术视频数据上，领域适应提升了模型表现，整合时序多模态数据进一步改善效果。在HeiCo公开数据集上，单独使用视频预训练模型已达到EndoVis2017挑战赛最佳水平，领域微调后表现更优。

Conclusion: 外科数据科学可充分利用公开泛化基础模型。领域自适应和融合合适的手术室补充数据流可显著提升性能。相关代码和模型已开源，便于后续研究。

Abstract: We investigate how both the adaptation of a generic foundation model via
transfer learning and the integration of complementary modalities from the
operating room (OR) can support surgical data science. To this end, we use
V-JEPA as the single-modality foundation of a multimodal model for minimally
invasive surgery support. We analyze how the model's downstream performance can
benefit (a) from finetuning on unlabeled surgical video data and (b) from
providing additional time-resolved data streams from the OR in a multimodal
setup.
  In an in-house dataset of liver surgery videos, we analyze the tasks of
predicting hospital length of stay and postoperative complications. In videos
of the public HeiCo dataset, we analyze the task of surgical phase recognition.
As a baseline, we apply pretrained V-JEPA to all tasks. We then finetune it on
unlabeled, held-out videos to investigate its change in performance after
domain adaptation. Following the idea of modular decision support networks, we
integrate additional data streams from the OR by training a separate encoder to
form a shared representation space with V-JEPA's embeddings.
  Our experiments show that finetuning on domain-specific data increases model
performance. On the in-house data, integrating additional time-resolved data
likewise benefits the model. On the HeiCo data, accuracy of the pretrained
video-only, single-modality baseline setup is on par with the top-performing
submissions of the EndoVis2017 challenge, while finetuning on domain-specific
data increases accuracy further. Our results thus demonstrate how surgical data
science can leverage public, generic foundation models. Likewise, they indicate
the potential of domain adaptation and of integrating suitable complementary
data streams from the OR. To support further research, we release our code and
model weights at https://github.com/DigitalSurgeryLab-Basel/ML-CDS-2025.

</details>


### [153] [Evaluating the Impact of Adversarial Attacks on Traffic Sign Classification using the LISA Dataset](https://arxiv.org/abs/2509.06835)
*Nabeyou Tadessa,Balaji Iyangar,Mashrur Chowdhury*

Main category: cs.CV

TL;DR: 本文评估了交通标志分类模型在对抗攻击下的脆弱性，并发现随着扰动增大模型准确率急剧下降。


<details>
  <summary>Details</summary>
Motivation: 目前关于对抗攻击的研究主要集中在如MNIST等数据集，现实应用场景关注较少。交通标志分类在自动驾驶等领域至关重要，研究其鲁棒性具有重要现实意义。

Method: 采用了LISA Traffic Sign数据集，训练一个卷积神经网络对47种交通标志进行分类，并用FGSM和PGD两种对抗攻击方法测试模型的鲁棒性。

Result: 随着对抗攻击扰动幅度增加，模型的分类准确率明显下降，表明模型对对抗样本非常敏感。

Conclusion: 交通标志分类模型对对抗攻击极为脆弱，亟需为实际交通标志识别系统开发更为有效的防御机制。

Abstract: Adversarial attacks pose significant threats to machine learning models by
introducing carefully crafted perturbations that cause misclassification. While
prior work has primarily focused on MNIST and similar datasets, this paper
investigates the vulnerability of traffic sign classifiers using the LISA
Traffic Sign dataset. We train a convolutional neural network to classify 47
different traffic signs and evaluate its robustness against Fast Gradient Sign
Method (FGSM) and Projected Gradient Descent (PGD) attacks. Our results show a
sharp decline in classification accuracy as the perturbation magnitude
increases, highlighting the models susceptibility to adversarial examples. This
study lays the groundwork for future exploration into defense mechanisms
tailored for real-world traffic sign recognition systems.

</details>


### [154] [ToonOut: Fine-tuned Background-Removal for Anime Characters](https://arxiv.org/abs/2509.06839)
*Matteo Muratori,Joël Seytre*

Main category: cs.CV

TL;DR: 现有的背景移除模型在动画风格内容上表现不佳，本文通过自建动画风格图片数据集，并微调BiRefNet模型，显著提升了该领域的背景移除准确度，同时开放数据集与模型。


<details>
  <summary>Details</summary>
Motivation: 尽管背景移除模型在真实图像中表现优良，但针对动画风格内容（如复杂头发、透明区域）时效果有限，因此需要针对该领域进行优化。

Method: 作者收集并标注了1,228张高质量动画风格图片，主要包含角色与物体。然后在此自建数据集上对开源的BiRefNet模型进行微调。

Result: 微调后模型在背景移除的像素精度从95.3%提升到99.5%，显著优于原模型。

Conclusion: 针对动画风格图像，专门的数据集和定制微调能极大提升背景移除效果，相关代码、模型及数据集均已开源。

Abstract: While state-of-the-art background removal models excel at realistic imagery,
they frequently underperform in specialized domains such as anime-style
content, where complex features like hair and transparency present unique
challenges. To address this limitation, we collected and annotated a custom
dataset of 1,228 high-quality anime images of characters and objects, and
fine-tuned the open-sourced BiRefNet model on this dataset. This resulted in
marked improvements in background removal accuracy for anime-style images,
increasing from 95.3% to 99.5% for our newly introduced Pixel Accuracy metric.
We are open-sourcing the code, the fine-tuned model weights, as well as the
dataset at: https://github.com/MatteoKartoon/BiRefNet.

</details>


### [155] [Automated Radiographic Total Sharp Score (ARTSS) in Rheumatoid Arthritis: A Solution to Reduce Inter-Intra Reader Variation and Enhancing Clinical Practice](https://arxiv.org/abs/2509.06854)
*Hajar Moradmand,Lei Ren*

Main category: cs.CV

TL;DR: 本研究提出了一种基于深度学习的全自动类风湿性关节炎（RA）放射学评分系统ARTSS，大幅提升了评分效率与客观性，并有效解决了患者关节消失和影像序列变长的难题。


<details>
  <summary>Details</summary>
Motivation: 传统TSS手动评分耗时且主观性强，评估结果易受操作者影响，亟需更高效、客观的自动化方法。

Method: ARTSS流程分四步：1) 用ResNet50预处理和重新定位影像，2) 用UNet.3分割手部，3) 用YOLOv7定位关节，4) 用多种深度学习模型（VGG16/19, ResNet50, DenseNet201, EfficientNetB0, ViT）预测TSS分数。采用970例患者数据，3折交叉验证和291例外部测试。评估指标包括IoU、MAP、MAE、RMSE和Huber loss。

Result: 关节识别准确率高达99%。TSS预测中，以ViT模型表现最佳，Huber loss仅0.87。深度模型整体表现在不同评价指标上均优于传统方法。

Conclusion: 深度学习可高效、自动化地完成RA评分，显著减少评分差异，提升临床诊断可靠性，同时解决了关节消失等实际难题，有助于风湿免疫科医生精准决策。

Abstract: Assessing the severity of rheumatoid arthritis (RA) using the Total Sharp/Van
Der Heijde Score (TSS) is crucial, but manual scoring is often time-consuming
and subjective. This study introduces an Automated Radiographic Sharp Scoring
(ARTSS) framework that leverages deep learning to analyze full-hand X-ray
images, aiming to reduce inter- and intra-observer variability. The research
uniquely accommodates patients with joint disappearance and variable-length
image sequences. We developed ARTSS using data from 970 patients, structured
into four stages: I) Image pre-processing and re-orientation using ResNet50,
II) Hand segmentation using UNet.3, III) Joint identification using YOLOv7, and
IV) TSS prediction using models such as VGG16, VGG19, ResNet50, DenseNet201,
EfficientNetB0, and Vision Transformer (ViT). We evaluated model performance
with Intersection over Union (IoU), Mean Average Precision (MAP), mean absolute
error (MAE), Root Mean Squared Error (RMSE), and Huber loss. The average TSS
from two radiologists was used as the ground truth. Model training employed
3-fold cross-validation, with each fold consisting of 452 training and 227
validation samples, and external testing included 291 unseen subjects. Our
joint identification model achieved 99% accuracy. The best-performing model,
ViT, achieved a notably low Huber loss of 0.87 for TSS prediction. Our results
demonstrate the potential of deep learning to automate RA scoring, which can
significantly enhance clinical practice. Our approach addresses the challenge
of joint disappearance and variable joint numbers, offers timesaving benefits,
reduces inter- and intra-reader variability, improves radiologist accuracy, and
aids rheumatologists in making more informed decisions.

</details>


### [156] [Matching Shapes Under Different Topologies: A Topology-Adaptive Deformation Guided Approach](https://arxiv.org/abs/2509.06862)
*Aymen Merrouche,Stefanie Wuhrer,Edmond Boyer*

Main category: cs.CV

TL;DR: 本文提出了一种新的适应拓扑变化的变形模型，实现了具有拓扑瑕疵的非刚性3D网格匹配，并在3D对齐任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的非刚性3D网格匹配方法通常假设形状变形是近似等距（isometric）或ARAP，但这些假设在实际多视图重建等情景下，常因拓扑瑕疵而失效。针对实际3D数据常见的拓扑问题，本文寻求一种能处理复杂拓扑变化的匹配方法。

Method: 作者提出了一个拓扑自适应的变形模型，将允许拓扑变化的约束与ARAP及双射关联约束结合。通过联合优化一个具有合适拓扑的模板网格及其与待配准形状的对齐，从而提取对应关系。

Result: 该方法不依赖任何数据驱动先验，能够有效应用于高度非等距和带有拓扑噪声的形状，尤其是在多视图重建数据上，甚至超越了基于大规模数据集训练的方法。

Conclusion: 提出的拓扑自适应变形模型提升了噪声及非理想拓扑情况下的3D网格匹配能力，在实际应用和复杂场景中显示出优越的表现。

Abstract: Non-rigid 3D mesh matching is a critical step in computer vision and computer
graphics pipelines. We tackle matching meshes that contain topological
artefacts which can break the assumption made by current approaches. While
Functional Maps assume the deformation induced by the ground truth
correspondences to be near-isometric, ARAP-like deformation-guided approaches
assume the latter to be ARAP. Neither assumption holds in certain topological
configurations of the input shapes. We are motivated by real-world scenarios
such as per-frame multi-view reconstructions, often suffering from topological
artefacts. To this end, we propose a topology-adaptive deformation model
allowing changes in shape topology to align shape pairs under ARAP and
bijective association constraints. Using this model, we jointly optimise for a
template mesh with adequate topology and for its alignment with the shapes to
be matched to extract correspondences. We show that, while not relying on any
data-driven prior, our approach applies to highly non-isometric shapes and
shapes with topological artefacts, including noisy per-frame multi-view
reconstructions, even outperforming methods trained on large datasets in 3D
alignment quality.

</details>


### [157] [A New Hybrid Model of Generative Adversarial Network and You Only Look Once Algorithm for Automatic License-Plate Recognition](https://arxiv.org/abs/2509.06868)
*Behnoud Shafiezadeh,Amir Mashmool,Farshad Eshghi,Manoochehr Kelarestaghi*

Main category: cs.CV

TL;DR: 本文提出一种结合选择性去模糊GAN和YOLOv5的自动车牌识别系统，实现了更高的识别准确率和实时性，尤其在模糊车牌情况下效果显著。


<details>
  <summary>Details</summary>
Motivation: 自动车牌识别（ALPR）在智能交通系统中至关重要，但因车牌的多样化与图像模糊等问题，传统方法难以高效应对。深度学习技术尤其适合提升识别准确性和鲁棒性，提升系统在真实环境下的应用价值。

Method: 在预处理步骤中引入选择性Deblur-GAN网络，专门对模糊图像去模糊；车牌检测及字符分割与识别均采用YOLOv5架构，省略不必要的图像处理操作，提升整体效率。在YOLOv5检测阶段，LPD和CR各检测时间仅0.026秒，确保实时性。作者还构建并公开了带有模糊-非模糊车牌的数据集，以更好地评估与训练模型性能。

Result: 所提模型在车牌检测和字符识别阶段分别达到了95%和97%的准确率。引入Deblur-GAN处理后，模型对模糊车牌的识别精度提升近40%。检测时间极短，适用于对实时响应有要求的实际场景。

Conclusion: YOLOv5结合Deblur-GAN的方案能显著提升自动车牌识别系统的准确率与实时性，特别是在处理模糊图像时效果更优，非常适合智能交通和便携式设备应用。

Abstract: Automatic License-Plate Recognition (ALPR) plays a pivotal role in
Intelligent Transportation Systems (ITS) as a fundamental element of Smart
Cities. However, due to its high variability, ALPR faces challenging issues
more efficiently addressed by deep learning techniques. In this paper, a
selective Generative Adversarial Network (GAN) is proposed for deblurring in
the preprocessing step, coupled with the state-of-the-art You-Only-Look-Once
(YOLO)v5 object detection architectures for License-Plate Detection (LPD), and
the integrated Character Segmentation (CS) and Character Recognition (CR)
steps. The selective preprocessing bypasses unnecessary and sometimes
counter-productive input manipulations, while YOLOv5 LPD/CS+CR delivers high
accuracy and low computing cost. As a result, YOLOv5 achieves a detection time
of 0.026 seconds for both LP and CR detection stages, facilitating real-time
applications with exceptionally rapid responsiveness. Moreover, the proposed
model achieves accuracy rates of 95\% and 97\% in the LPD and CR detection
phases, respectively. Furthermore, the inclusion of the Deblur-GAN
pre-processor significantly improves detection accuracy by nearly 40\%,
especially when encountering blurred License Plates (LPs).To train and test the
learning components, we generated and publicly released our blur and ALPR
datasets (using Iranian license plates as a use-case), which are more
representative of close-to-real-life ad-hoc situations. The findings
demonstrate that employing the state-of-the-art YOLO model results in excellent
overall precision and detection time, making it well-suited for portable
applications. Additionally, integrating the Deblur-GAN model as a preliminary
processing step enhances the overall effectiveness of our comprehensive model,
particularly when confronted with blurred scenes captured by the camera as
input.

</details>


### [158] [Barlow-Swin: Toward a novel siamese-based segmentation architecture using Swin-Transformers](https://arxiv.org/abs/2509.06885)
*Morteza Kiani Haftlang,Mohammadhossein Malmir,Foroutan Parand,Umberto Michelucci,Safouane El Ghazouali*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级、适用于实时医学图像二分类分割的新型网络结构，结合了Swin Transformer类编码器和U-Net类解码器，并通过自监督预训练提升特征学习效率，实现了低参数、快速推理和竞争性准确率。


<details>
  <summary>Details</summary>
Motivation: 当前医学图像分割模型（如U-Net）因卷积算子感受野有限无法充分建模全局信息；引入Transformer虽能补充全局上下文，但模型通常较深、计算量大，不适合实时应用。因此，急需一种高效、实时且精度可靠的分割新模型。

Method: 提出将类似Swin Transformer的高效编码器与U-Net的跳跃连接式解码器相结合，设计整体结构更浅。同时，在有监督微调前，采用Barlow Twins自监督方法对编码器进行预训练，提升特征表达能力，无需大量标注数据。

Result: 在医学图像二分类分割基准任务上，模型在保证准确率的前提下，实现了大幅减少参数数量和推理时间，展现出在实时和资源受限场景下的应用潜力。

Conclusion: 该方法在保持轻量和高效的同时，能在医学图像分割任务上提供与现有复杂模型相当甚至更优的性能，是面向实时和资源有限临床环境的有力备选解决方案。

Abstract: Medical image segmentation is a critical task in clinical workflows,
particularly for the detection and delineation of pathological regions. While
convolutional architectures like U-Net have become standard for such tasks,
their limited receptive field restricts global context modeling. Recent efforts
integrating transformers have addressed this, but often result in deep,
computationally expensive models unsuitable for real-time use. In this work, we
present a novel end-to-end lightweight architecture designed specifically for
real-time binary medical image segmentation. Our model combines a Swin
Transformer-like encoder with a U-Net-like decoder, connected via skip pathways
to preserve spatial detail while capturing contextual information. Unlike
existing designs such as Swin Transformer or U-Net, our architecture is
significantly shallower and competitively efficient. To improve the encoder's
ability to learn meaningful features without relying on large amounts of
labeled data, we first train it using Barlow Twins, a self-supervised learning
method that helps the model focus on important patterns by reducing unnecessary
repetition in the learned features. After this pretraining, we fine-tune the
entire model for our specific task. Experiments on benchmark binary
segmentation tasks demonstrate that our model achieves competitive accuracy
with substantially reduced parameter count and faster inference, positioning it
as a practical alternative for deployment in real-time and resource-limited
clinical environments. The code for our method is available at Github
repository: https://github.com/mkianih/Barlow-Swin.

</details>


### [159] [Intraoperative 2D/3D Registration via Spherical Similarity Learning and Inference-Time Differentiable Levenberg-Marquardt Optimization](https://arxiv.org/abs/2509.06890)
*Minheng Chen,Youyong Kong*

Main category: cs.CV

TL;DR: 本论文提出了一种改进的2D/3D手术配准方法，通过在非欧几里得球面特征空间进行相似度学习，以及采用SO(4)流形上的Riemann距离，提高了配准精度和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 传统的2D/3D配准方法受限于欧氏距离的近似，导致流形结构被扭曲，影响配准算法对大范围扰动的鲁棒性和收敛性。为解决这一问题，作者希望探索更加契合实际流形结构的相似度度量方法。

Method: 作者提出利用CNN-Transformer编码器提取特征，将其投影到球面空间，并采用SO(4)空间内的Riemann距离来逼近特征之间的测地线距离。推理阶段，采用全可微分的Levenberg-Marquardt优化方法替代传统梯度下降，以加速收敛。

Result: 在真实及合成数据集上进行实验，结果显示该方法在特定患者和非特定患者的场景中均取得了更高的准确率。

Conclusion: 该工作证明了利用非欧空间中的深度相似度度量和高效求解器能显著提升2D/3D配准任务的性能，并为相关医疗图像配准技术的发展提供了新思路。

Abstract: Intraoperative 2D/3D registration aligns preoperative 3D volumes with
real-time 2D radiographs, enabling accurate localization of instruments and
implants. A recent fully differentiable similarity learning framework
approximates geodesic distances on SE(3), expanding the capture range of
registration and mitigating the effects of substantial disturbances, but
existing Euclidean approximations distort manifold structure and slow
convergence. To address these limitations, we explore similarity learning in
non-Euclidean spherical feature spaces to better capture and fit complex
manifold structure. We extract feature embeddings using a CNN-Transformer
encoder, project them into spherical space, and approximate their geodesic
distances with Riemannian distances in the bi-invariant SO(4) space. This
enables a more expressive and geometrically consistent deep similarity metric,
enhancing the ability to distinguish subtle pose differences. During inference,
we replace gradient descent with fully differentiable Levenberg-Marquardt
optimization to accelerate convergence. Experiments on real and synthetic
datasets show superior accuracy in both patient-specific and patient-agnostic
scenarios.

</details>


### [160] [BIR-Adapter: A Low-Complexity Diffusion Model Adapter for Blind Image Restoration](https://arxiv.org/abs/2509.06904)
*Cem Eteke,Alexander Griessel,Wolfgang Kellerer,Eckehard Steinbach*

Main category: cs.CV

TL;DR: 本文提出了一种低复杂度的盲图像修复适配器BIR-Adapter，可以结合已有的大规模预训练扩散模型，无需训练额外特征提取器，实现高效的盲图像修复，在多种退化条件下效果优异，且易于集成到其他扩散模型。


<details>
  <summary>Details</summary>
Motivation: 现有盲图像修复方法在复杂未知的退化条件下仍面临困难，普遍需要训练额外的特征提取器且复杂度较高。扩散模型虽然表现优异，但如何直接利用其先验、简化流程和增强适应性是当前的挑战。

Method: BIR-Adapter利用预训练扩散模型内的特征去适配盲图像修复任务，通过扩散模型自带机制从退化图像中提取特征，并在自注意力结构中融入这些特征信息。同时，该方法引入采样引导机制抑制伪影（hallucination），无需额外特征提取器。

Result: 在合成和真实的多种退化测试下，BIR-Adapter的修复表现优于或相当于最先进的方法，但模型复杂度显著降低。此外，其适配器结构可灵活集成到其他扩散模型，扩展原本只能做超分辨的模型，在面对未知退化时也能获得更好效果。

Conclusion: BIR-Adapter是一种高效、易集成、低复杂度的盲图像修复方法，能充分利用扩散模型的强大生成能力和鲁棒特性，适合广泛的图像修复应用。

Abstract: This paper introduces BIR-Adapter, a low-complexity blind image restoration
adapter for diffusion models. The BIR-Adapter enables the utilization of the
prior of pre-trained large-scale diffusion models on blind image restoration
without training any auxiliary feature extractor. We take advantage of the
robustness of pretrained models. We extract features from degraded images via
the model itself and extend the self-attention mechanism with these degraded
features. We introduce a sampling guidance mechanism to reduce hallucinations.
We perform experiments on synthetic and real-world degradations and demonstrate
that BIR-Adapter achieves competitive or better performance compared to
state-of-the-art methods while having significantly lower complexity.
Additionally, its adapter-based design enables integration into other diffusion
models, enabling broader applications in image restoration tasks. We showcase
this by extending a super-resolution-only model to perform better under
additional unknown degradations.

</details>


### [161] [FoMo4Wheat: Toward reliable crop vision foundation models with globally curated data](https://arxiv.org/abs/2509.06907)
*Bing Han,Chen Zhu,Dong Han,Rui Yu,Songliang Cao,Jianhui Wu,Scott Chapman,Zijian Wang,Bangyou Zheng,Wei Guo,Marie Weiss,Benoit de Solan,Andreas Hund,Lukas Roth,Kirchgessner Norbert,Andrea Visioni,Yufeng Ge,Wenjuan Li,Alexis Comar,Dong Jiang,Dejun Han,Fred Baret,Yanfeng Ding,Hao Lu,Shouyang Liu*

Main category: cs.CV

TL;DR: 本文提出了FoMo4Wheat，这是首个在自监督大规模小麦图像数据（ImAg4Wheat）上预训练的作物领域视觉基础模型。该模型在10项田间任务中效果优于通用模型，并能泛化至其他作物和杂草。模型与数据集已公开。


<details>
  <summary>Details</summary>
Motivation: 现有基于通用预训练视觉模型的农田监测效果有限，原因是作物冠层结构复杂且田间环境多变，导致模型泛化性不足。针对农业场景开发专用的视觉基础模型需求迫切。

Method: 收集并整理了历时十年、涵盖30个全球地点的250万张高分辨率小麦图像（ImAg4Wheat），跨越2000多个基因型及500多类环境条件。采用自监督方式在该数据集上预训练视觉基础模型FoMo4Wheat，并在田间不同层级的10项视觉任务测试效果。

Result: FoMo4Wheat在全部10个田间冠层和器官层面的视觉任务上，均优于通用领域预训练的最先进模型。此外，该模型在其他作物和杂草任务上同样表现强健，展现良好迁移能力。

Conclusion: 面向作物场景的视觉基础模型有助于提升可靠的田间感知能力。FoMo4Wheat的成功验证了作物特定基础模型的价值，也为未来具备跨物种、跨任务能力的通用作物基础模型迈出了关键一步。

Abstract: Vision-driven field monitoring is central to digital agriculture, yet models
built on general-domain pretrained backbones often fail to generalize across
tasks, owing to the interaction of fine, variable canopy structures with
fluctuating field conditions. We present FoMo4Wheat, one of the first
crop-domain vision foundation model pretrained with self-supervision on
ImAg4Wheat, the largest and most diverse wheat image dataset to date (2.5
million high-resolution images collected over a decade at 30 global sites,
spanning >2,000 genotypes and >500 environmental conditions). This
wheat-specific pretraining yields representations that are robust for wheat and
transferable to other crops and weeds. Across ten in-field vision tasks at
canopy and organ levels, FoMo4Wheat models consistently outperform
state-of-the-art models pretrained on general-domain dataset. These results
demonstrate the value of crop-specific foundation models for reliable in-field
perception and chart a path toward a universal crop foundation model with
cross-species and cross-task capabilities. FoMo4Wheat models and the ImAg4Wheat
dataset are publicly available online: https://github.com/PheniX-Lab/FoMo4Wheat
and https://huggingface.co/PheniX-Lab/FoMo4Wheat. The demonstration website is:
https://fomo4wheat.phenix-lab.com/.

</details>


### [162] [H$_{2}$OT: Hierarchical Hourglass Tokenizer for Efficient Video Pose Transformers](https://arxiv.org/abs/2509.06956)
*Wenhao Li,Mengyuan Liu,Hong Liu,Pichao Wang,Shijian Lu,Nicu Sebe*

Main category: cs.CV

TL;DR: 提出了一种高效的视频3D人体姿态估计算法H2OT，通过对Transformer模型中的token剪枝与恢复，大幅提升推理效率且准确率依然优秀。该方法适用于多种Transformer结构，易于集成，实现了更优的速度-精度权衡。


<details>
  <summary>Details</summary>
Motivation: 目前的视频Transformer方法用于3D人体姿态估计时计算量大，难以在算力受限设备上应用。因此，需要设计既高效又准确的3D姿态估计方法。

Method: 作者设计了分层的层次化Hourglass Tokenizer(H2OT)结构，包括Token Pruning Module(TPM)和Token Recovering Module(TRM)。TPM先动态选择有代表性的token减少冗余，TRM再恢复时空细节以还原完整时序序列。整个流程兼容通用Transformer架构，可适配不同的token剪枝与恢复策略。

Result: 在多个主流数据集上实验，H2OT兼得高效率与高准确率，显著优于现有VPT方法。

Conclusion: H2OT可大幅减少视频3D人体姿态估计中的计算消耗，实现轻量化推理。该方法易融于多种主流Transformer模型，为实际部署带来新可能。

Abstract: Transformers have been successfully applied in the field of video-based 3D
human pose estimation. However, the high computational costs of these video
pose transformers (VPTs) make them impractical on resource-constrained devices.
In this paper, we present a hierarchical plug-and-play pruning-and-recovering
framework, called Hierarchical Hourglass Tokenizer (H$_{2}$OT), for efficient
transformer-based 3D human pose estimation from videos. H$_{2}$OT begins with
progressively pruning pose tokens of redundant frames and ends with recovering
full-length sequences, resulting in a few pose tokens in the intermediate
transformer blocks and thus improving the model efficiency. It works with two
key modules, namely, a Token Pruning Module (TPM) and a Token Recovering Module
(TRM). TPM dynamically selects a few representative tokens to eliminate the
redundancy of video frames, while TRM restores the detailed spatio-temporal
information based on the selected tokens, thereby expanding the network output
to the original full-length temporal resolution for fast inference. Our method
is general-purpose: it can be easily incorporated into common VPT models on
both seq2seq and seq2frame pipelines while effectively accommodating different
token pruning and recovery strategies. In addition, our H$_{2}$OT reveals that
maintaining the full pose sequence is unnecessary, and a few pose tokens of
representative frames can achieve both high efficiency and estimation accuracy.
Extensive experiments on multiple benchmark datasets demonstrate both the
effectiveness and efficiency of the proposed method. Code and models are
available at https://github.com/NationalGAILab/HoT.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [163] [An Empirical Analysis of Discrete Unit Representations in Speech Language Modeling Pre-training](https://arxiv.org/abs/2509.05359)
*Yanis Labrak,Richard Dufour,Mickaël Rouvier*

Main category: cs.CL

TL;DR: 本文探讨了在语音语言模型（SLMs）中，如何通过优化离散单元表示进行持续预训练以提升语音建模效果。


<details>
  <summary>Details</summary>
Motivation: 当前将预训练的语言模型适配于语音领域时仍存在模型结构、数据表示和训练鲁棒性等挑战，因此需要系统性地分析这些因素如何影响模型预训练效果。

Method: 系统研究了模型架构、离散数据表示（如语音编码器和聚类粒度）以及训练数据的鲁棒性，包括不同模型规模下的最优离散化方法，通过分析聚类分布、音素对齐等，探究如何有效使用离散词表和提升模型鲁棒性。

Result: 实验证明最优的离散化方法取决于模型容量，不同聚类策略对不同规模模型表现影响明显；有效的离散词表能捕捉到语音中的语言学与副语言模式；聚类数据的选择（如是否与目标领域匹配）会显著影响模型鲁棒性。

Conclusion: 离散单元表示的选择需结合模型规模与目标应用领域，合理的离散化策略和域匹配的数据能显著提升语音语言模型的表现和鲁棒性。

Abstract: This paper investigates discrete unit representations in Speech Language
Models (SLMs), focusing on optimizing speech modeling during continual
pre-training. In this paper, we systematically examine how model architecture,
data representation, and training robustness influence the pre-training stage
in which we adapt existing pre-trained language models to the speech modality.
Our experiments highlight the role of speech encoders and clustering
granularity across different model scales, showing how optimal discretization
strategies vary with model capacity. By examining cluster distribution and
phonemic alignments, we investigate the effective use of discrete vocabulary,
uncovering both linguistic and paralinguistic patterns. Additionally, we
explore the impact of clustering data selection on model robustness,
highlighting the importance of domain matching between discretization training
and target applications.

</details>


### [164] [Beyond ROUGE: N-Gram Subspace Features for LLM Hallucination Detection](https://arxiv.org/abs/2509.05360)
*Jerry Li,Evangelos Papalexakis*

Main category: cs.CL

TL;DR: 本论文提出了一种检测大语言模型幻觉的新方法，通过构建N-Gram频率张量对文本进行分析，并结合张量分解与MLP分类器，有效提升了幻觉检测的表现。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在许多自然语言任务中表现优异，但在生成一致、真实的信息时依然存在幻觉问题，影响模型可信度。因此，提升幻觉检测的准确性成为亟需解决的问题。

Method: 作者受ROUGE指标启发，提出利用N-Gram频率张量来捕捉生成文本中的更丰富语义结构，通过张量分解提取各维奇异值作为特征，训练一个多层感知机(MLP)二分类器检测幻觉。

Result: 该方法在HaluEval数据集上进行了评测，在传统基线和主流判别模型（LLM Judges）对比下表现出更显著的提升，竞争力强。

Conclusion: 本方法能够有效提升大语言模型生成文本中幻觉检测的表现，为提升模型生成内容的可信度和质量提供了新的思路和技术路线。

Abstract: Large Language Models (LLMs) have demonstrated effectiveness across a wide
variety of tasks involving natural language, however, a fundamental problem of
hallucinations still plagues these models, limiting their trustworthiness in
generating consistent, truthful information. Detecting hallucinations has
quickly become an important topic, with various methods such as uncertainty
estimation, LLM Judges, retrieval augmented generation (RAG), and consistency
checks showing promise. Many of these methods build upon foundational metrics,
such as ROUGE, BERTScore, or Perplexity, which often lack the semantic depth
necessary to detect hallucinations effectively. In this work, we propose a
novel approach inspired by ROUGE that constructs an N-Gram frequency tensor
from LLM-generated text. This tensor captures richer semantic structure by
encoding co-occurrence patterns, enabling better differentiation between
factual and hallucinated content. We demonstrate this by applying tensor
decomposition methods to extract singular values from each mode and use these
as input features to train a multi-layer perceptron (MLP) binary classifier for
hallucinations. Our method is evaluated on the HaluEval dataset and
demonstrates significant improvements over traditional baselines, as well as
competitive performance against state-of-the-art LLM judges.

</details>


### [165] [A Lightweight Framework for Trigger-Guided LoRA-Based Self-Adaptation in LLMs](https://arxiv.org/abs/2509.05385)
*Jiacheng Wei,Faguo Wu,Xiao Zhang*

Main category: cs.CL

TL;DR: 提出了一种名为SAGE的动态微调框架，使得大语言模型能够在推理时根据新数据进行自适应更新，从而提升复杂推理任务的表现。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在推理（inference）过程中无法根据新数据持续适应和学习，限制了其在复杂推理任务中的表现。因此，作者希望实现推理阶段的在线适应和知识更新。

Method: 将复杂推理任务分解成原子子任务，提出SAGE框架。SAGE包括三个核心模块：（1）Trigger模块，实时检测推理失败；（2）Trigger Buffer模块，采用HDBSCAN对异常样本进行流式聚类及稳定性和相似性合并；（3）Lora Store模块，利用适配池动态优化参数更新，保留知识。

Result: 实验结果显示，SAGE在原子推理子任务上通过动态知识更新，在准确性、鲁棒性和稳定性方面表现优异。

Conclusion: SAGE实现了推理时的动态知识更新，提升了大语言模型复杂推理任务的表现，为模型持续自适应和学习提供了一种有效机制。

Abstract: Large language models are unable to continuously adapt and learn from new
data during reasoning at inference time. To address this limitation, we propose
that complex reasoning tasks be decomposed into atomic subtasks and introduce
SAGE, a trigger-guided dynamic fine-tuning framework that enables adaptive
updates during reasoning at inference time. SAGE consists of three key
components: (1) a Trigger module that detects reasoning failures through
multiple evaluation metrics in real time; (2) a Trigger Buffer module that
clusters anomaly samples using a streaming clustering process with HDBSCAN,
followed by stability checks and similarity-based merging; and (3) a Lora Store
module that dynamically optimizes parameter updates with an adapter pool for
knowledge retention. Evaluation results show that SAGE demonstrates excellent
accuracy, robustness, and stability on the atomic reasoning subtask through
dynamic knowledge updating during test time.

</details>


### [166] [Talk Isn't Always Cheap: Understanding Failure Modes in Multi-Agent Debate](https://arxiv.org/abs/2509.05396)
*Andrea Wynn,Harsh Satija,Gillian Hadfield*

Main category: cs.CL

TL;DR: 本论文指出，在多智能体推理任务中，多智能体辩论不仅不一定提升推理能力，反而可能导致准确率下降。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体辩论被广泛认为可以提升AI推理能力，但以往研究仅关注同质化（能力相同）智能体之间的辩论，忽略了智能体能力异质性对辩论结果的影响。因此，本文研究了不同能力智能体之间互动对辩论以及结果的影响。

Method: 作者通过一系列实验对照了混合能力（强弱智能体混合）场景下的多智能体辩论表现，分析了模型在相互辩论和交换推理过程中发生的准确率变化和模型行为。

Result: 实验发现，即使强力模型数量多于弱模型，多智能体辩论也是会让整体推理准确率随着交流次数增加而降低。进一步分析显示，模型在交流中更倾向于迎合同伴、追求一致，而不是纠正错误推理，导致本来正确的答案转为错误。

Conclusion: 论文指出，在缺乏激励或能力去反击有说服力但错误的推理时，简单应用多智能体辩论策略实际可能损害整体性能。因此，对多智能体推理系统不能盲目采用辩论策略，需考虑抵御错误推理的机制设计。

Abstract: While multi-agent debate has been proposed as a promising strategy for
improving AI reasoning ability, we find that debate can sometimes be harmful
rather than helpful. The prior work has exclusively focused on debates within
homogeneous groups of agents, whereas we explore how diversity in model
capabilities influences the dynamics and outcomes of multi-agent interactions.
Through a series of experiments, we demonstrate that debate can lead to a
decrease in accuracy over time -- even in settings where stronger (i.e., more
capable) models outnumber their weaker counterparts. Our analysis reveals that
models frequently shift from correct to incorrect answers in response to peer
reasoning, favoring agreement over challenging flawed reasoning. These results
highlight important failure modes in the exchange of reasons during multi-agent
debate, suggesting that naive applications of debate may cause performance
degradation when agents are neither incentivized nor adequately equipped to
resist persuasive but incorrect reasoning.

</details>


### [167] [No Translation Needed: Forecasting Quality from Fertility and Metadata](https://arxiv.org/abs/2509.05425)
*Jessica M. Lundin,Ada Zhang,David Adelani,Cody Carroll*

Main category: cs.CL

TL;DR: 本文提出，一些简单特征（如token繁衍比、token数量和基础语言信息）可以无需真正运行翻译系统就较准确地预测翻译质量（以ChrF分数表征），并在203种语言上的FLORES-200基准测试中取得了显著结果。


<details>
  <summary>Details</summary>
Motivation: 通常，评估机器翻译质量需要运行翻译系统并获得译文，这一过程消耗时间和资源。本文动机在于寻找便捷且高效的方法，在不实际运行翻译系统的情况下预测翻译质量，为多语言环境下的系统评估和资源分配带来便利。

Method: 作者使用少量特征，包括token繁衍比、token统计以及语言家族、书写系统和地区等元数据。针对GPT-4o的翻译结果，在FLORES-200多语言数据集上，通过梯度提升模型（Gradient boosting）回归预测ChrF得分，并分析各特征的重要性。

Result: 实验结果显示，该模型能较好地预测翻译质量（XX到英文的R^2=0.66，英文到XX的R^2=0.72）。特征重要性分析发现，类型学因素在翻译到英文时主导预测，而token繁衍性在翻译到其他多样目标语言时更重要。

Conclusion: 翻译质量受到token级繁衍性和更广泛语言类型学的共同影响。即便不用真正运行翻译系统，仅凭文本和一些语言特性就能相对准确地评估多语言翻译质量，对多语言机器翻译系统的评估和质量预估具有启发意义。

Abstract: We show that translation quality can be predicted with surprising accuracy
\textit{without ever running the translation system itself}. Using only a
handful of features, token fertility ratios, token counts, and basic linguistic
metadata (language family, script, and region), we can forecast ChrF scores for
GPT-4o translations across 203 languages in the FLORES-200 benchmark. Gradient
boosting models achieve favorable performance ($R^{2}=0.66$ for
XX$\rightarrow$English and $R^{2}=0.72$ for English$\rightarrow$XX). Feature
importance analyses reveal that typological factors dominate predictions into
English, while fertility plays a larger role for translations into diverse
target languages. These findings suggest that translation quality is shaped by
both token-level fertility and broader linguistic typology, offering new
insights for multilingual evaluation and quality estimation.

</details>


### [168] [Direct-Scoring NLG Evaluators Can Use Pairwise Comparisons Too](https://arxiv.org/abs/2509.05440)
*Logan Lawrence,Ashton Williamson,Alexander Shelton*

Main category: cs.CL

TL;DR: 本文提出了一种直接评分方法，通过使用合成摘要实现对自动生成内容进行绝对评分的新方式，旨在改进现有仅能进行两两比较的自动评分系统。实验结果表明，该方法在多个评测数据集上表现良好，与当前最新的两两比较方法相当。研究还发布了合成摘要数据，有助于后续相关研究。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型越来越多地被用于自动评估自由文本内容，目前主流的方法通常基于两两比较，难以对单独生成内容给出绝对分数，而实际应用中往往需要对单个样本设定阈值。因此，开发能够为单个文本打分的自动化方法成为亟需解决的问题。

Method: 作者提出了一种直接评分方法，核心思想是在测试阶段通过合成摘要（synthetic summaries）来充当两两机器排序依据，实现对单独样本的打分。该方法与传统的两两比较方法不同，不仅能进行排名，还能对单个生成内容赋予绝对分数。

Result: 在SummEval、TopicalChat和HANNA三大元评测基准测试中，该方法在样本级相关性评分（axis-averaged sample-level correlations）与现有最优的两两比较方法表现接近，具体数值变化如+0.03、-0.03、+0.05。并且，作者公开了合成摘要数据资源。

Conclusion: 提出的直接评分方法能实现对自动生成内容的绝对打分，在样本级相关性上达到主流方法水准。发布的数据集有望推动自动化文本评估领域的进一步发展。

Abstract: As large-language models have been increasingly used as automatic raters for
evaluating free-form content, including document summarization, dialog, and
story generation, work has been dedicated to evaluating such models by
measuring their correlations with human judgment. For \textit{sample-level}
performance, methods which operate by using pairwise comparisons between
machine-generated text perform well but often lack the ability to assign
absolute scores to individual summaries, an ability crucial for use cases that
require thresholding. In this work, we propose a direct-scoring method which
uses synthetic summaries to act as pairwise machine rankings at test time. We
show that our method performs comparably to state-of-the-art pairwise
evaluators in terms of axis-averaged sample-level correlations on the SummEval
(\textbf{+0.03}), TopicalChat (\textbf{-0.03}), and HANNA (\textbf{+0.05})
meta-evaluation benchmarks, and release the synthetic in-context summaries as
data to facilitate future work.

</details>


### [169] [From Staff Messages to Actionable Insights: A Multi-Stage LLM Classification Framework for Healthcare Analytics](https://arxiv.org/abs/2509.05484)
*Hajar Sakai,Yi-En Tseng,Mohammadsadegh Mikaeili,Joshua Bosire,Franziska Jovin*

Main category: cs.CL

TL;DR: 本文提出一种基于大语言模型（LLM）的多阶段框架，对医院呼叫中心产生的员工消息进行主题识别和原因分类，并将结果集成到可视化决策支持工具中，有助于提升医疗服务效率和质量。


<details>
  <summary>Details</summary>
Motivation: 医院呼叫中心积累了大量员工消息文本，但传统监督学习方法依赖大量标注数据，训练和调优成本高，难以高效挖掘数据中的有用信息。为解决效率和效果问题，探索LLM在该场景的应用。

Method: 构建多阶段LLM框架，综合评估了推理型、通用型和轻量级等多种大语言模型，对员工消息进行主题识别与多类别原因分类，并考虑数据安全及HIPAA合规性。处理结果通过可视化工具转化为可操作洞察。

Result: 最佳模型o3的加权F1分数为78.4%，准确率为79.2%；gpt-5紧随其后。模型输出成功集成进决策支持工具。

Conclusion: 所提出的LLM框架有效提升了员工消息数据的利用效率，有助于发现导航员培训机会，改善患者体验和医疗服务质量。

Abstract: Hospital call centers serve as the primary contact point for patients within
a hospital system. They also generate substantial volumes of staff messages as
navigators process patient requests and communicate with the hospital offices
following the established protocol restrictions and guidelines. This
continuously accumulated large amount of text data can be mined and processed
to retrieve insights; however, traditional supervised learning approaches
require annotated data, extensive training, and model tuning. Large Language
Models (LLMs) offer a paradigm shift toward more computationally efficient
methodologies for healthcare analytics. This paper presents a multi-stage
LLM-based framework that identifies staff message topics and classifies
messages by their reasons in a multi-class fashion. In the process, multiple
LLM types, including reasoning, general-purpose, and lightweight models, were
evaluated. The best-performing model was o3, achieving 78.4% weighted F1-score
and 79.2% accuracy, followed closely by gpt-5 (75.3% Weighted F1-score and
76.2% accuracy). The proposed methodology incorporates data security measures
and HIPAA compliance requirements essential for healthcare environments. The
processed LLM outputs are integrated into a visualization decision support tool
that transforms the staff messages into actionable insights accessible to
healthcare professionals. This approach enables more efficient utilization of
the collected staff messaging data, identifies navigator training
opportunities, and supports improved patient experience and care quality.

</details>


### [170] [The Token Tax: Systematic Bias in Multilingual Tokenization](https://arxiv.org/abs/2509.05486)
*Jessica M. Lundin,Ada Zhang,Nihal Karim,Hamza Louzan,Victor Wei,David Adelani,Cody Carroll*

Main category: cs.CL

TL;DR: 本文研究了现有大型语言模型（LLM）在形态复杂、低资源语言上的分词低效问题，发现分词“膨胀”严重影响模型准确性与训练成本，并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: 当前主流分词策略对词形变化复杂的少数语言不友好，导致需要更多token，不仅增加算力消耗，也使这些语言的NLP任务表现较差。研究者希望揭示这种结构性不平等，并推动更公平的NLP发展。

Method: 作者选用AfriMMLU数据集（包含9千道多项选择题、5个学科、16种非洲语言），在10个大型预训练语言模型上评估分词膨胀率（每词token数——fertility）对模型表现（准确率）的影响，并比较推理型与非推理型模型区别。

Result: 分词膨胀率高的语言，模型准确率普遍较低，这一结论在所有模型、所有学科下均成立。推理型模型在各类语言上普遍优于非推理型，缩小了历代模型中的资源差距。分词翻倍会带来四倍的训练成本和时间，凸显许多语言在NLP任务中面临的“token税”。

Conclusion: 结果呼吁发展形态感知型分词方法，建立公平定价机制和多语种评测基准，以实现NLP领域的公平性及可持续性。

Abstract: Tokenization inefficiency imposes structural disadvantages on morphologically
complex, low-resource languages, inflating compute resources and depressing
accuracy. We evaluate 10 large language models (LLMs) on AfriMMLU (9,000 MCQA
items; 5 subjects; 16 African languages) and show that fertility (tokens/word)
reliably predicts accuracy. Higher fertility consistently predicts lower
accuracy across all models and subjects. We further find that reasoning models
(DeepSeek, o1) consistently outperform non-reasoning peers across high and low
resource languages in the AfriMMLU dataset, narrowing accuracy gaps observed in
prior generations. Finally, translating token inflation to economics, a
doubling in tokens results in quadrupled training cost and time, underscoring
the token tax faced by many languages. These results motivate morphologically
aware tokenization, fair pricing, and multilingual benchmarks for equitable
natural language processing (NLP).

</details>


### [171] [Biomedical Literature Q&A System Using Retrieval-Augmented Generation (RAG)](https://arxiv.org/abs/2509.05505)
*Mansi Garg,Lee-Chi Wang,Bhavesh Ghanchi,Sanjana Dumpala,Shreyash Kakde,Yen Chih Chen*

Main category: cs.CL

TL;DR: 本文提出了一种基于RAG（检索增强生成）架构的生物医学文献问答系统，有效提升医疗信息检索的准确性和便捷性。


<details>
  <summary>Details</summary>
Motivation: 面对传统健康搜索引擎的信息不准确和文献获取滞后问题，亟需一种能高效提供基于证据的医学知识的新系统。

Method: 系统基于MiniLM嵌入和FAISS向量检索实现多源信息检索，结合QLoRA优化的Mistral-7B-v0.3模型进行答案生成，能处理一般及特定领域（如乳腺癌）问题。

Result: 通过BERTScore（F1）评估，结果显示新系统在事实一致性和语义相关性上明显优于基线，乳腺癌文献实验尤为突出。

Conclusion: RAG增强的语言模型有望缩短医学文献与大众可及健康知识的距离，并为未来多语言、隐私保护和个性化医疗AI奠定基础。

Abstract: This work presents a Biomedical Literature Question Answering (Q&A) system
based on a Retrieval-Augmented Generation (RAG) architecture, designed to
improve access to accurate, evidence-based medical information. Addressing the
shortcomings of conventional health search engines and the lag in public access
to biomedical research, the system integrates diverse sources, including PubMed
articles, curated Q&A datasets, and medical encyclopedias ,to retrieve relevant
information and generate concise, context-aware responses. The retrieval
pipeline uses MiniLM-based semantic embeddings and FAISS vector search, while
answer generation is performed by a fine-tuned Mistral-7B-v0.3 language model
optimized using QLoRA for efficient, low-resource training. The system supports
both general medical queries and domain-specific tasks, with a focused
evaluation on breast cancer literature demonstrating the value of
domain-aligned retrieval. Empirical results, measured using BERTScore (F1),
show substantial improvements in factual consistency and semantic relevance
compared to baseline models. The findings underscore the potential of
RAG-enhanced language models to bridge the gap between complex biomedical
literature and accessible public health knowledge, paving the way for future
work on multilingual adaptation, privacy-preserving inference, and personalized
medical AI systems.

</details>


### [172] [Using Contrastive Learning to Improve Two-Way Reasoning in Large Language Models: The Obfuscation Task as a Case Study](https://arxiv.org/abs/2509.05553)
*Serge Lionel Nikiema,Jordan Samhi,Micheline Bénédicte Moumoula,Albérick Euraste Djiré,Abdoul Kader Kaboré,Jacques Klein,Tegawendé F. Bissyandé*

Main category: cs.CL

TL;DR: 本文探讨大型语言模型是否能够真正理解概念还是仅仅在模式识别。研究提出用“双向推理”来检验模型是否具备真正理解能力，并提出对比微调（CFT）方法来提升模型的双向推理表现。结果表明CFT提升了模型的理解深度和双向推理能力。


<details>
  <summary>Details</summary>
Motivation: AI领域亟需判别大模型是否真正理解知识，现有评估方法无法有效区分模式记忆和真正理解。作者希望找到能衡量“理解力”的有效标准。

Method: 提出“双向推理”任务来源。例如，模型若能‘变量名A→B’，也应自然具备‘B→A’能力。测试现有模型，并发现普通微调易导致认知专业化。为此，设计了对比微调（CFT）方法，用多种语义示例训练模型，不直接训练反向能力。

Result: CFT方法的模型表现出了显著的双向推理能力，包括逆向任务在内的能力均得以提升，并且未损失原本（正向）任务上的表现。

Conclusion: 双向推理是衡量AI“理解”程度的有效理论和实践框架。CFT有助于训练出具备更深理解和多向能力的AI系统。

Abstract: This research addresses a fundamental question in AI: whether large language
models truly understand concepts or simply recognize patterns. The authors
propose bidirectional reasoning,the ability to apply transformations in both
directions without being explicitly trained on the reverse direction, as a test
for genuine understanding. They argue that true comprehension should naturally
allow reversibility. For example, a model that can change a variable name like
userIndex to i should also be able to infer that i represents a user index
without reverse training. The researchers tested current language models and
discovered what they term cognitive specialization: when models are fine-tuned
on forward tasks, their performance on those tasks improves, but their ability
to reason bidirectionally becomes significantly worse. To address this issue,
they developed Contrastive Fine-Tuning (CFT), which trains models using three
types of examples: positive examples that maintain semantic meaning, negative
examples with different semantics, and forward-direction obfuscation examples.
This approach aims to develop deeper understanding rather than surface-level
pattern recognition and allows reverse capabilities to develop naturally
without explicit reverse training. Their experiments demonstrated that CFT
successfully achieved bidirectional reasoning, enabling strong reverse
performance while maintaining forward task capabilities. The authors conclude
that bidirectional reasoning serves both as a theoretical framework for
assessing genuine understanding and as a practical training approach for
developing more capable AI systems.

</details>


### [173] [Ad hoc conventions generalize to new referents](https://arxiv.org/abs/2509.05566)
*Anya Ji,Claire Augusta Bergey,Ron Eliav,Yoav Artzi,Robert D. Hawkins*

Main category: cs.CL

TL;DR: 本研究探讨人在面对未曾讨论过的新事物时如何协作并达成描述方式。通过实验发现，人们之间建立的命名惯例能够泛化到其他相关的新项目，表现出概念空间的重新协调。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解人们如何为全新事物创建共享的命名与描述，是单纯的任意标签，还是更深层次的概念对齐。这对参照理论及人工智能中的自适应语言系统有重要启示。

Method: 作者利用KiloGram数据集，招募302名参与者，分为二人小组。小组成员共同为图片设定称呼，并观察这些命名惯例是否能泛化至未曾讨论过的其他图片。通过分析对未讨论项目的描述一致性，评估不同理论。

Result: 实验结果显示，参与者对未讨论图片所用描述的对齐度相比测试前显著提升，说明了命名惯例的泛化效应。这种泛化随图片视觉相似度呈非线性衰减（与Shepard定律一致），并且在图片可命名性不同的情况下依然稳健。

Conclusion: 结果表明临时达成的命名惯例不仅仅是随意标签，更涉及概念的协调与空间调整。这对理解人类参照机制和筑造更灵活语言智能体有理论与实际意义。

Abstract: How do people talk about things they've never talked about before? One view
suggests that a new shared naming system establishes an arbitrary link to a
specific target, like proper names that cannot extend beyond their bearers. An
alternative view proposes that forming a shared way of describing objects
involves broader conceptual alignment, reshaping each individual's semantic
space in ways that should generalize to new referents. We test these competing
accounts in a dyadic communication study (N=302) leveraging the
recently-released KiloGram dataset containing over 1,000 abstract tangram
images. After pairs of participants coordinated on referential conventions for
one set of images through repeated communication, we measured the extent to
which their descriptions aligned for undiscussed images. We found strong
evidence for generalization: partners showed increased alignment relative to
their pre-test labels. Generalization also decayed nonlinearly with visual
similarity (consistent with Shepard's law) and was robust across levels of the
images' nameability. These findings suggest that ad hoc conventions are not
arbitrary labels but reflect genuine conceptual coordination, with implications
for theories of reference and the design of more adaptive language agents.

</details>


### [174] [Mitigating Spurious Correlations Between Question and Answer via Chain-of-Thought Correctness Perception Distillation](https://arxiv.org/abs/2509.05602)
*Hongyan Xie,Yitong Yao,Yikun Ban,Zixuan Huang,Deqing Wang,Zhenhe Wu,Haoxiang Su,Chao Wang,Shuangyong Song,Xuelong Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为CoPeD的蒸馏方法，通过识别与纠正推理链中的错误，提升小型语言模型（SLM）在推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在推理任务上表现优异，但部署成本高，因此通常通过教师-学生蒸馏，将大型模型的推理能力转移给小型模型。然而，链式推理（CoT）数据存在噪声，导致学生模型学到错误或无用的推理路径，影响模型的推理质量。

Method: 提出CoPeD方法，包括两个核心创新：1）基于正确性的任务设定，让学生模型基于正确的推理链预测答案，并在推理链错误时进行修正；2）提出基于正确性的加权损失函数，根据推理链与答案的联合损失动态调整每个训练样本的权重，引导模型关注推理链更能支撑正确答案的样本。

Result: 实验表明，CoPeD在IND（同分布）和OOD（异分布）推理基准数据集上均能有效提升小型模型的推理能力。

Conclusion: 通过提升推理链的正确性和对有用数据的关注，CoPeD显著增强了学生模型的推理质量，有效缓解了噪声推理链带来的负面影响。

Abstract: Large language models (LLMs) excel at reasoning tasks but are expensive to
deploy. Thus small language models (SLMs) are fine-tuned on CoT data generated
by LLMs to copy LLMs' abilities. However, these CoT data may include noisy
rationales that either fail to substantiate the answers or contribute no
additional information to support answer prediction, which leads SLMs to
capture spurious correlations between questions and answers and compromise the
quality of reasoning. In this work, we propose Chain-of-Thought Correctness
Perception Distillation (CoPeD), which aims to improve the reasoning quality of
the student model from the perspectives of task setting and data utilization.
Firstly, we introduce a correctness-aware task setting that encourages the
student model to predict answers based on correct rationales and revise them
when they are incorrect. This setting improves the faithfulness of reasoning
and allows the model to learn from its mistakes. Then, we propose a
Correctness-Aware Weighted loss, which dynamically adjusts the contribution of
each training instance based on the combined loss of the rationale and the
answer. This strategy encourages the model to focus more on samples where the
rationale offers stronger support for the correct answer. Experiments have
shown that CoPeD is effective on both in-distribution (IND) and
out-of-distribution (OOD) benchmark reasoning datasets.

</details>


### [175] [Icon$^{2}$: Aligning Large Language Models Using Self-Synthetic Preference Data via Inherent Regulation](https://arxiv.org/abs/2509.05605)
*Qiyuan Chen,Hongsen Huang,Qian Shao,Jiahe Chen,Jintai Chen,Hongxia Xu,Renjie Hua,Ren Chuan,Jian Wu*

Main category: cs.CL

TL;DR: 本文提出了一种新的偏好数据集构建范式Icon^2，有效提升大语言模型（LLMs）的人类意图对齐能力，并显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的数据集构建方法存在分布失配和高计算开销等问题，难以高效且精准地对齐LLMs与人类偏好。

Method: 作者通过分析LLMs表示空间的内在调控，首先提取分层方向向量编码复杂人类偏好，再利用这些向量筛选具内在一致性的自合成指令，在解码过程中施加双向内在控制，引导生成区分明显、对齐性强的回应对。

Result: 实验表明，新方法在Llama3-8B和Qwen2-7B上，AlpacaEval 2.0的获胜率提升13.89%，Arena-Hard提升13.45%，同时计算开销最多降低48.1%。

Conclusion: Icon^2方法能更高效地构建高质量偏好数据集，同时明显提升模型对齐性能和计算效率。

Abstract: Large Language Models (LLMs) require high quality preference datasets to
align with human preferences. However, conventional methods for constructing
such datasets face significant challenges: reliance on pre-collected
instructions often leads to distribution mismatches with target models, while
the need for sampling multiple stochastic responses introduces substantial
computational overhead. In this work, we explore a paradigm shift by leveraging
inherent regulation of LLMs' representation space for efficient and tailored
preference dataset construction, named Icon$^{2}$. Specifically, it first
extracts layer-wise direction vectors to encode sophisticated human preferences
and then uses these vectors to filter self-synthesized instructions based on
their inherent consistency. During decoding, bidirectional inherent control is
applied to steer token representations, enabling the precise generation of
response pairs with clear alignment distinctions. Experimental results
demonstrate significant improvements in both alignment and efficiency.
Llama3-8B and Qwen2-7B achieve an average win rate improvement of 13.89% on
AlpacaEval 2.0 and 13.45% on Arena-Hard, while reducing computational costs by
up to 48.1%.

</details>


### [176] [Beyond Keywords: Driving Generative Search Engine Optimization with Content-Centric Agents](https://arxiv.org/abs/2509.05607)
*Qiyuan Chen,Jiahe Chen,Hongsen Huang,Qian Shao,Jintai Chen,Renjie Hua,Hongxia Xu,Ruijia Wu,Ren Chuan,Jian Wu*

Main category: cs.CL

TL;DR: 本文提出了一个针对生成式搜索引擎（Generative Search Engines, GSE）的内容影响优化框架，并构建了相关基准集，推动针对GSE的SEO（GSEO）研究。


<details>
  <summary>Details</summary>
Motivation: 随着搜索引擎从传统的排名式检索转向生成式问答，原有SEO评估指标已不适用，迫切需要研究如何衡量并优化内容对生成答案的影响力。

Method: 1）构建了CC-GSEO-Bench大规模内容基准集，并提出多维影响力评价框架，全面量化内容在生成答案中的实质影响；2）设计了多智能体系统，实现内容的自动分析、修订与评估流程。

Result: 通过实证研究，揭示了内容影响生成式搜索引擎答案的新机制，提出了内容优化的可行策略。

Conclusion: 设立了系统性的GSEO研究基础框架，为内容创作者优化生成式搜索引擎输出提供了新思路，并推动相关领域后续研究。

Abstract: The paradigm shift from traditional ranked-based search to Generative Search
Engines has rendered conventional SEO metrics obsolete, creating an urgent need
to understand, measure, and optimize for content influence on synthesized
answers. This paper introduces a comprehensive, end-to-end framework for
Generative Search Engine Optimization (GSEO) to address this challenge. We make
two primary contributions. First, we construct CC-GSEO-Bench, a large-scale,
content-centric benchmark, and propose a multi-dimensional evaluation framework
that systematically quantifies influence, moving beyond surface-level
attribution to assess substantive semantic impact. Second, we design a novel
multi-agent system that operationalizes this framework, automating the
strategic refinement of content through a collaborative analyze-revise-evaluate
workflow. Our empirical analysis using this framework reveals novel insights
into the dynamics of content influence, offering actionable strategies for
creators and establishing a principled foundation for future GSEO research.

</details>


### [177] [New Insights into Optimal Alignment of Acoustic and Linguistic Representations for Knowledge Transfer in ASR](https://arxiv.org/abs/2509.05609)
*Xugang Lu,Peng Shen,Yu Tsao,Hisashi Kawai*

Main category: cs.CL

TL;DR: 本文提出了一种基于不均衡最优传输的对齐模型，通过检测视角处理语音与文本的对齐问题，有效提升了ASR中知识迁移的表现。


<details>
  <summary>Details</summary>
Motivation: 在自动语音识别（ASR）系统中，如何对齐声学与语言表示是知识迁移中的核心挑战。由于声学帧和文本标记间存在多对一、一对多和冗余无意义帧等不对称与结构性问题，导致传统对齐方法难以做到准确匹配，影响ASR性能。

Method: 作者将对齐和匹配问题看作检测问题，引入不均衡最优传输模型。该模型允许声学与语言单位之间进行软性、部分的概率匹配，显式解决分布不匹配和结构不对称。模型确保每个语言标记至少有一个声学观测点对应，同时灵活处理冗余噪声和多余帧。

Result: 作者在CTC架构下，结合预训练语言模型进行知识迁移实验。结果显示，所提方法在灵活调控匹配度、对抗冗余声学帧等方面均优于传统方法，显著提升了ASR的性能。

Conclusion: 通过将声学-语言对齐建模为检测问题并结合不均衡最优传输方法，能够更有效地实现知识迁移，提升ASR系统的准确率和泛化能力。

Abstract: Aligning acoustic and linguistic representations is a central challenge to
bridge the pre-trained models in knowledge transfer for automatic speech
recognition (ASR). This alignment is inherently structured and asymmetric:
while multiple consecutive acoustic frames typically correspond to a single
linguistic token (many-to-one), certain acoustic transition regions may relate
to multiple adjacent tokens (one-to-many). Moreover, acoustic sequences often
include frames with no linguistic counterpart, such as background noise or
silence may lead to imbalanced matching conditions. In this work, we take a new
insight to regard alignment and matching as a detection problem, where the goal
is to identify meaningful correspondences with high precision and recall
ensuring full coverage of linguistic tokens while flexibly handling redundant
or noisy acoustic frames in transferring linguistic knowledge for ASR. Based on
this new insight, we propose an unbalanced optimal transport-based alignment
model that explicitly handles distributional mismatch and structural
asymmetries with soft and partial matching between acoustic and linguistic
modalities. Our method ensures that every linguistic token is grounded in at
least one acoustic observation, while allowing for flexible, probabilistic
mappings from acoustic to linguistic units. We evaluate our proposed model with
experiments on an CTC-based ASR system with a pre-trained language model for
knowledge transfer. Experimental results demonstrate the effectiveness of our
approach in flexibly controlling degree of matching and hence to improve ASR
performance.

</details>


### [178] [From Joy to Fear: A Benchmark of Emotion Estimation in Pop Song Lyrics](https://arxiv.org/abs/2509.05617)
*Shay Dahary,Avi Edana,Alexander Apartsin,Yehudit Aperstein*

Main category: cs.CL

TL;DR: 本论文探讨了如何通过多标签情感归因方法，预测歌词中六种基本情感的强度分数，评估了零样本大语言模型与微调BERT模型在任务上的表现，并公开了手工标注数据集。


<details>
  <summary>Details</summary>
Motivation: 歌曲歌词的情感内容对听众体验与音乐偏好有重要影响，但歌词情感的准确识别和量化一直面临挑战。现有方法在处理多标签和情感强度预测方面有限，需要新方法和高质量标注数据集支撑智能化音乐信息检索。

Method: 作者构建了一个通过多人意见得分（MOS）方法手工标注的歌词多标签情感强度数据集。基于此，系统评估了多种公有大语言模型在零样本环境下的表现，并进一步对BERT模型进行微调用于多标签情感分数预测。

Result: 实验显示，零样本大语言模型与微调BERT模型各有优劣，在识别歌词复杂情感上表现互补，总体上微调BERT模型对多标签情感强度预测具有一定优势。

Conclusion: 研究证实大语言模型在创造性文本情感识别中的潜力，并为基于情感的音乐信息检索模型选择提供了实用建议，同时公开数据集为后续相关研究提供基础资源。

Abstract: The emotional content of song lyrics plays a pivotal role in shaping listener
experiences and influencing musical preferences. This paper investigates the
task of multi-label emotional attribution of song lyrics by predicting six
emotional intensity scores corresponding to six fundamental emotions. A
manually labeled dataset is constructed using a mean opinion score (MOS)
approach, which aggregates annotations from multiple human raters to ensure
reliable ground-truth labels. Leveraging this dataset, we conduct a
comprehensive evaluation of several publicly available large language models
(LLMs) under zero-shot scenarios. Additionally, we fine-tune a BERT-based model
specifically for predicting multi-label emotion scores. Experimental results
reveal the relative strengths and limitations of zero-shot and fine-tuned
models in capturing the nuanced emotional content of lyrics. Our findings
highlight the potential of LLMs for emotion recognition in creative texts,
providing insights into model selection strategies for emotion-based music
information retrieval applications. The labeled dataset is available at
https://github.com/LLM-HITCS25S/LyricsEmotionAttribution.

</details>


### [179] [Few-Shot Query Intent Detection via Relation-Aware Prompt Learning](https://arxiv.org/abs/2509.05635)
*Liang Zhang,Yuan Li,Shijie Zhang,Zheng Zhang,Xitong Li*

Main category: cs.CL

TL;DR: 本文提出了一种结合文本和关系结构信息的新预训练框架SAID，并引入QueryAdapt机制，有效提升了小样本意图识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有意图识别方法在小样本场景下主要只用文本数据，忽视了会话中的结构信息（如查询-查询、查询-应答关系），导致知识利用不充分。

Method: 作者提出SAID框架，首次在预训练中统一融合文本与关系结构信息。并提出QueryAdapt机制，在关系token层面生成意图特定的关系token，以实现更细粒度的知识迁移。

Result: 在两个真实数据集上，SAID显著优于现有最先进方法。

Conclusion: 融合文本与结构信息的预训练方法能显著提升小样本意图检测的效果，为意图识别模型发展提供了新方向。

Abstract: Intent detection is a crucial component of modern conversational systems,
since accurately identifying user intent at the beginning of a conversation is
essential for generating effective responses. Recent efforts have focused on
studying this problem under a challenging few-shot scenario. These approaches
primarily leverage large-scale unlabeled dialogue text corpora to pretrain
language models through various pretext tasks, followed by fine-tuning for
intent detection with very limited annotations. Despite the improvements
achieved, existing methods have predominantly focused on textual data,
neglecting to effectively capture the crucial structural information inherent
in conversational systems, such as the query-query relation and query-answer
relation. To address this gap, we propose SAID, a novel framework that
integrates both textual and relational structure information in a unified
manner for model pretraining for the first time. Building on this framework, we
further propose a novel mechanism, the query-adaptive attention network
(QueryAdapt), which operates at the relation token level by generating
intent-specific relation tokens from well-learned query-query and query-answer
relations explicitly, enabling more fine-grained knowledge transfer. Extensive
experimental results on two real-world datasets demonstrate that SAID
significantly outperforms state-of-the-art methods.

</details>


### [180] [LM-Searcher: Cross-domain Neural Architecture Search with LLMs via Unified Numerical Encoding](https://arxiv.org/abs/2509.05657)
*Yuxuan Hu,Jihao Liu,Ke Wang,Jinliang Zhen,Weikang Shi,Manyuan Zhang,Qi Dou,Rui Liu,Aojun Zhou,Hongsheng Li*

Main category: cs.CL

TL;DR: 本文提出了LM-Searcher框架，用大型语言模型（LLM）进行跨领域神经网络架构搜索，无需大量领域适配，提升实用性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有利用LLM解决神经架构搜索问题的方法依赖大量提示工程及领域特定调优，难以跨领域推广，限制了其广泛应用。

Method: 提出了NCode通用数值串编码方式统一表示神经网络架构，将神经架构搜索（NAS）问题形式化为LLM的排序任务，通过剪枝子空间采样策略构建指令微调数据集，训练LLM在候选架构中进行高性能筛选。

Result: LM-Searcher在多场景（如图像分类CNN、分割和生成任务的LoRA配置）下均获得了有竞争力的表现，体现了其跨领域架构搜索的强大能力。

Conclusion: LM-Searcher为LLM驱动的通用神经架构搜索提供了新范式，可大大减少领域适配需求，提升灵活性和泛化性。

Abstract: Recent progress in Large Language Models (LLMs) has opened new avenues for
solving complex optimization problems, including Neural Architecture Search
(NAS). However, existing LLM-driven NAS approaches rely heavily on prompt
engineering and domain-specific tuning, limiting their practicality and
scalability across diverse tasks. In this work, we propose LM-Searcher, a novel
framework that leverages LLMs for cross-domain neural architecture optimization
without the need for extensive domain-specific adaptation. Central to our
approach is NCode, a universal numerical string representation for neural
architectures, which enables cross-domain architecture encoding and search. We
also reformulate the NAS problem as a ranking task, training LLMs to select
high-performing architectures from candidate pools using instruction-tuning
samples derived from a novel pruning-based subspace sampling strategy. Our
curated dataset, encompassing a wide range of architecture-performance pairs,
encourages robust and transferable learning. Comprehensive experiments
demonstrate that LM-Searcher achieves competitive performance in both in-domain
(e.g., CNNs for image classification) and out-of-domain (e.g., LoRA
configurations for segmentation and generation) tasks, establishing a new
paradigm for flexible and generalizable LLM-based architecture search. The
datasets and models will be released at https://github.com/Ashone3/LM-Searcher.

</details>


### [181] [Cross-Question Method Reuse in Large Language Models: From Word-Level Prediction to Rational Logical-Layer Reasoning](https://arxiv.org/abs/2509.05660)
*Hong Su*

Main category: cs.CL

TL;DR: 本文提出了一种新的大语言模型（LLM）方法复用策略，将方法（问题-解决对）应用于低相似度或隐性相似的问题，突破了以往复用仅限高相似问题的限制，有效提升了跨问题方法复用的效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多只允许方法（问题-解决对）在高度相似的问题间复用，造成方法复用范围受限，不利于解决更多不同类问题。作者希望突破这种限制，实现更广泛的问题间复用，特别是针对隐藏相似性或只具有部分特性的不同问题。

Method: 作者提出在处理一般到具体（或反之）关系的问题时，先将问题和解决方案分离，再引导LLM针对新但相关的问题对已有方案进行迁移和适应。此法让LLM关注于解决方案迁移，而不是对问题本身的识别，同时推广到仅部分特征或隐性相似的问题，实现更灵活的方案复用。

Result: 实验验证表明，本文扩展的范围方法能够提升筛选出可复用解决方案的概率，显著增强跨问题方法复用的有效性。

Conclusion: 本文提出的方法扩展了大语言模型中方法复用的适用范围，突破了相似性约束，在多种不同或隐性相似的问题情境下都能提升复用效率，为通用智能问答系统研究带来了新思路。

Abstract: Large language models (LLMs) have been widely applied to assist in finding
solutions for diverse questions. Prior work has proposed representing a method
as a pair of a question and its corresponding solution, enabling method reuse.
However, existing approaches typically require the questions to be highly
similar. In this paper, we extend the scope of method reuse to address
questions with low similarity or with hidden similarities that are not
explicitly observable. For questions that are similar in a general-specific
sense (i.e., broader or narrower in scope), we propose to first separate the
question and solution, rather than directly feeding the pair to the LLM. The
LLM is then guided to adapt the solution to new but related questions, allowing
it to focus on solution transfer rather than question recognition. Furthermore,
we extend this approach to cases where questions only share partial features or
hidden characteristics. This enables cross-question method reuse beyond
conventional similarity constraints. Experimental verification shows that our
scope-extension approach increases the probability of filtering out reusable
solutions, thereby improving the effectiveness of cross-question method reuse.

</details>


### [182] [Llama-GENBA-10B: A Trilingual Large Language Model for German, English and Bavarian](https://arxiv.org/abs/2509.05668)
*Michael Hoffmann,Jophin John,Stefan Schweter,Gokul Ramakrishnan,Hoi-Fong Mak,Alice Zhang,Dmitry Gaynullin,Nicolay J. Hammer*

Main category: cs.CL

TL;DR: 本文提出了Llama-GENBA-10B——一个能够处理中英德三语的基础大模型，尤其关注低资源语言（巴伐利亚语），并在跨语言任务上取得优异效果。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型以英语为主，导致低资源语言如巴伐利亚语表现较差。该研究旨在解决英语偏置，提升多语言尤其是德语和巴伐利亚语的处理能力，满足德国NLP社区和低资源语言需求。

Method: 在Llama 3.1-8B模型基础上扩展至10B参数，采用82B英语、82B德语及8000万巴伐利亚语语料，持续预训练。创新点包括多语种语料整理、英德巴三语统一tokenizer设计、模型及数据比例调优、首次建立三语评测集（德语基准翻译为巴伐利亚语）。训练在Cerebras CS-2上完成，并统计能耗。

Result: Llama-GENBA-10B在巴伐利亚语Fine-tune后超越Apertus-8B-2509和gemma-2-9b，成为同类中效果最佳模型，对德语和英语表现也优异，超过甚至持平EuroLLM。

Conclusion: 该研究为包含低资源语言的包容性基础模型提供了范例，实现多语言平衡，提升了德语及巴伐利亚语等低资源语种的NLP能力，并具备较高能效。

Abstract: We present Llama-GENBA-10B, a trilingual foundation model addressing
English-centric bias in large language models. Built on Llama 3.1-8B and scaled
to 10B parameters, Llama-GENBA-10B is continuously pretrained on 164B tokens
(82B English, 82B German, and 80M Bavarian), balancing resources while
preventing English dominance. Targeted at the German NLP community, the model
also promotes Bavarian as a low-resource language. Development tackled four
challenges: (1) curating a multilingual corpus despite Bavarian scarcity, (2)
creating a unified tokenizer for English, German, and Bavarian, (3) optimizing
architecture and language-ratio hyperparameters for cross-lingual transfer, and
(4) establishing the first standardized trilingual evaluation suite by
translating German benchmarks into Bavarian. Evaluations show that
Llama-GENBA-10B achieves strong cross-lingual performance, with the fine-tuned
variant surpassing Apertus-8B-2509 and gemma-2-9b in Bavarian and establishing
itself as the best model in its class for this language, while also
outperforming EuroLLM in English and matching its results in German. Training
on the Cerebras CS-2 demonstrated efficient large-scale multilingual
pretraining with documented energy use, offering a blueprint for inclusive
foundation models that integrate low-resource languages.

</details>


### [183] [Revealing the Numeracy Gap: An Empirical Investigation of Text Embedding Models](https://arxiv.org/abs/2509.05691)
*Ningyuan Deng,Hanyu Duan,Yixuan Tang,Yi Yang*

Main category: cs.CL

TL;DR: 本文评估了当前主流文本嵌入模型对文本中细致数值信息（如具体数字）编码的能力，发现其准确性普遍较低。


<details>
  <summary>Details</summary>
Motivation: 虽然文本嵌入模型广泛用于NLP任务，但其在需要理解和编码文本中具体数值信息（如百分比、金额）方面的表现尚不明确，而这种能力对金融、医疗等领域尤为关键。

Method: 作者利用财务领域的合成数据，系统性评估了13种常用文本嵌入模型是否能够捕捉文本中的数值细节。通过比较模型在不同具体数字上下文中的表现，分析其嵌入对数字变化的敏感性。

Result: 结果显示，这些模型普遍难以准确捕捉和编码文本中的数值细节，对类似‘2%’和‘20%’这样的数字区分表现不佳。

Conclusion: 现有嵌入模型在处理数值内容方面存在局限，未来需专门研究提升嵌入模型对数值信息的处理能力，以更好适配实际、特别是数值敏感场景的NLP应用。

Abstract: Text embedding models are widely used in natural language processing
applications. However, their capability is often benchmarked on tasks that do
not require understanding nuanced numerical information in text. As a result,
it remains unclear whether current embedding models can precisely encode
numerical content, such as numbers, into embeddings. This question is critical
because embedding models are increasingly applied in domains where numbers
matter, such as finance and healthcare. For example, Company X's market share
grew by 2\% should be interpreted very differently from Company X's market
share grew by 20\%, even though both indicate growth in market share. This
study aims to examine whether text embedding models can capture such nuances.
Using synthetic data in a financial context, we evaluate 13 widely used text
embedding models and find that they generally struggle to capture numerical
details accurately. Our further analyses provide deeper insights into embedding
numeracy, informing future research to strengthen embedding model-based NLP
systems with improved capacity for handling numerical content.

</details>


### [184] [A Survey of the State-of-the-Art in Conversational Question Answering Systems](https://arxiv.org/abs/2509.05716)
*Manoj Madushanka Perera,Adnan Mahmood,Kasun Eranda Wijethilake,Fahmida Islam,Maryam Tahermazandarani,Quan Z. Sheng*

Main category: cs.CL

TL;DR: 本文综述了对话式问答（ConvQA）系统领域的最新进展，包括核心技术、关键数据集及未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 随着NLP技术的进步，ConvQA系统在各行业中越来越重要，尤其在需要连贯和语境相关的多轮对话场景，如客户支持、教育、医疗和法律等领域。因此，总结和分析ConvQA领域的核心技术和瓶颈迫在眉睫，有助于推动该领域进一步发展。

Method: 本文通过文献调研的方式，梳理了ConvQA系统的核心组件（历史选择、问题理解、答案预测）及其相互关系。同时重点评述了强化学习、对比学习、迁移学习等先进机器学习方法在该领域的应用，并分析了大语言模型（如RoBERTa、GPT-4、Gemini 2.0 Flash、Mistral 7B、LLaMA 3）在系统性能和规模扩展上的作用。最后，还系统梳理了ConvQA相关的主要数据集。

Result: 本文对ConvQA系统的结构和关键技术进行了归纳和梳理，全面总结了不同技术路线的优劣及其在提升对话连贯性与质量方面的表现，同时指出了各大语言模型的贡献和发展趋势；并系统性地总结了现有数据集及其应用。

Conclusion: 调查指出，虽然ConvQA取得了显著进展，但依然面临多轮交互中的上下文建模和知识迁移等挑战。未来研究可关注更高效的对话建模、更大规模的数据利用以及新型学习方法的引入，为ConvQA系统的进一步发展指明了方向。

Abstract: Conversational Question Answering (ConvQA) systems have emerged as a pivotal
area within Natural Language Processing (NLP) by driving advancements that
enable machines to engage in dynamic and context-aware conversations. These
capabilities are increasingly being applied across various domains, i.e.,
customer support, education, legal, and healthcare where maintaining a coherent
and relevant conversation is essential. Building on recent advancements, this
survey provides a comprehensive analysis of the state-of-the-art in ConvQA.
This survey begins by examining the core components of ConvQA systems, i.e.,
history selection, question understanding, and answer prediction, highlighting
their interplay in ensuring coherence and relevance in multi-turn
conversations. It further investigates the use of advanced machine learning
techniques, including but not limited to, reinforcement learning, contrastive
learning, and transfer learning to improve ConvQA accuracy and efficiency. The
pivotal role of large language models, i.e., RoBERTa, GPT-4, Gemini 2.0 Flash,
Mistral 7B, and LLaMA 3, is also explored, thereby showcasing their impact
through data scalability and architectural advancements. Additionally, this
survey presents a comprehensive analysis of key ConvQA datasets and concludes
by outlining open research directions. Overall, this work offers a
comprehensive overview of the ConvQA landscape and provides valuable insights
to guide future advancements in the field.

</details>


### [185] [Exploring Subjective Tasks in Farsi: A Survey Analysis and Evaluation of Language Models](https://arxiv.org/abs/2509.05719)
*Donya Rooein,Flor Miriam Plaza-del-Arco,Debora Nozza,Dirk Hovy*

Main category: cs.CL

TL;DR: 尽管波斯语被认为是中资源语言，但在主观任务（情感分析、情绪分析、有害性检测）中，数据数量和质量仍存在重大挑战，数据集公开性差，人口统计信息缺失，模型结果不稳定。仅有数据量提升不足以显著改善NLP表现。


<details>
  <summary>Details</summary>
Motivation: 随着数字文本资源增多，波斯语在自然语言处理（NLP）领域应享有较好资源，但在主观任务领域，这一认知需要重新审视。作者希望揭示波斯语在NLP主观任务中的实际资源状况和面临的独特挑战。

Method: 综述并分析了110篇关于波斯语主观任务的相关文献，评估相关公开数据集的数量与质量，检视关键人口属性（如年龄、性别）的涵盖情况，并用现有数据集评测各种模型，观察其表现稳定性。

Result: 发现公开数据集极为稀缺，且人口统计因素匮乏。利用有限数据集进行模型评估时，模型在不同数据集之间表现波动极大，不具稳定性。

Conclusion: 仅凭数据体量的增长难以提升波斯语在NLP主观任务中的整体表现。提升数据公开性和质量、丰富数据人口属性信息才是关键。

Abstract: Given Farsi's speaker base of over 127 million people and the growing
availability of digital text, including more than 1.3 million articles on
Wikipedia, it is considered a middle-resource language. However, this label
quickly crumbles when the situation is examined more closely. We focus on three
subjective tasks (Sentiment Analysis, Emotion Analysis, and Toxicity Detection)
and find significant challenges in data availability and quality, despite the
overall increase in data availability. We review 110 publications on subjective
tasks in Farsi and observe a lack of publicly available datasets. Furthermore,
existing datasets often lack essential demographic factors, such as age and
gender, that are crucial for accurately modeling subjectivity in language. When
evaluating prediction models using the few available datasets, the results are
highly unstable across both datasets and models. Our findings indicate that the
volume of data is insufficient to significantly improve a language's prospects
in NLP.

</details>


### [186] [QCSE: A Pretrained Quantum Context-Sensitive Word Embedding for Natural Language Processing](https://arxiv.org/abs/2509.05729)
*Charles M. Varmantchaonala,Niclas GÖtting,Nils-Erik SchÜtte,Jean Louis E. K. Fendji,Christopher Gies*

Main category: cs.CL

TL;DR: 本文提出了一种预训练的量子上下文敏感嵌入（QCSE）模型，能够利用量子计算捕捉单词的上下文信息，提高自然语言处理效果。


<details>
  <summary>Details</summary>
Motivation: 自然语言具有极高的复杂性，传统方法在捕捉词语上下文关系与多义性等方面有限，而量子计算特有的表达能力为自然语言处理带来新机遇，尤其对低资源语言亦有益。

Method: 提出了量子原生上下文学习策略，通过五种不同的上下文矩阵计算方法（包括指数衰减、正弦调制、相位偏移、哈希变换等），实现单词上下文状态的独特表达，并用Fulani和英文两个语料库验证方法有效性。

Result: QCSE模型不仅能够捕捉单词的上下文敏感性，还充分发挥了量子系统的表达能力，在低资源语料下也取得较好表现，提升了语义表示的丰富性。

Conclusion: 量子计算在自然语言处理领域展现出巨大潜力，QCSE为实际语言任务和领域带来了新思路，特别是对资源稀缺语言有重要应用前景。

Abstract: Quantum Natural Language Processing (QNLP) offers a novel approach to
encoding and understanding the complexity of natural languages through the
power of quantum computation. This paper presents a pretrained quantum
context-sensitive embedding model, called QCSE, that captures context-sensitive
word embeddings, leveraging the unique properties of quantum systems to learn
contextual relationships in languages. The model introduces quantum-native
context learning, enabling the utilization of quantum computers for linguistic
tasks. Central to the proposed approach are innovative context matrix
computation methods, designed to create unique, representations of words based
on their surrounding linguistic context. Five distinct methods are proposed and
tested for computing the context matrices, incorporating techniques such as
exponential decay, sinusoidal modulation, phase shifts, and hash-based
transformations. These methods ensure that the quantum embeddings retain
context sensitivity, thereby making them suitable for downstream language tasks
where the expressibility and properties of quantum systems are valuable
resources. To evaluate the effectiveness of the model and the associated
context matrix methods, evaluations are conducted on both a Fulani corpus, a
low-resource African language, dataset of small size and an English corpus of
slightly larger size. The results demonstrate that QCSE not only captures
context sensitivity but also leverages the expressibility of quantum systems
for representing rich, context-aware language information. The use of Fulani
further highlights the potential of QNLP to mitigate the problem of lack of
data for this category of languages. This work underscores the power of quantum
computation in natural language processing (NLP) and opens new avenues for
applying QNLP to real-world linguistic challenges across various tasks and
domains.

</details>


### [187] [Enhancing Factual Accuracy and Citation Generation in LLMs via Multi-Stage Self-Verification](https://arxiv.org/abs/2509.05741)
*Fernando Gabriela García,Qiyang Shi,Zilin Feng*

Main category: cs.CL

TL;DR: 提出了一种新方法 VeriFact-CoT，通过事实验证、反思和引用整合，提高大语言模型(LLMs)在处理复杂事实性内容时的准确性和可信度。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在生成复杂、需要事实依据的内容时，常常存在虚构信息（幻觉问题）和缺乏可靠引用来源，削弱了其在科学、新闻、法律等高要求场景下的信任度。

Method: VeriFact-CoT 采用多阶段机制，包括事实验证、反思和引用整合，让LLMs对自身的推理过程和最终答案进行批判性自省和修正，并集成可信引用。

Result: 该方法显著提高了LLMs生成内容的客观准确性、可信度和可追溯性。

Conclusion: VeriFact-CoT使得LLMs在科学研究、新闻报道、法律咨询等要求高可靠性的应用中更加实用和可靠。

Abstract: This research introduces VeriFact-CoT (Verified Factual Chain-of-Thought), a
novel method designed to address the pervasive issues of hallucination and the
absence of credible citation sources in Large Language Models (LLMs) when
generating complex, fact-sensitive content. By incorporating a multi-stage
mechanism of 'fact verification-reflection-citation integration,' VeriFact-CoT
empowers LLMs to critically self-examine and revise their intermediate
reasoning steps and final answers. This process significantly enhances the
objective accuracy, trustworthiness, and traceability of the generated outputs,
making LLMs more reliable for applications demanding high fidelity such as
scientific research, news reporting, and legal consultation.

</details>


### [188] [LatinX: Aligning a Multilingual TTS Model with Direct Preference Optimization](https://arxiv.org/abs/2509.05863)
*Luis Felipe Chary,Miguel Arjona Ramirez*

Main category: cs.CL

TL;DR: 本文提出了一种多语言文本到语音（TTS）模型LatinX，能够在跨语言语音翻译中保持源说话人身份，并在多项评测中超越现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 现有的语音到语音翻译技术往往无法在目标语言中保留说话人的声音特性，影响用户体验和实际应用的可靠性。因此，研究如何在多语言TTS系统中实现高质量的说话人克隆具有重要意义。

Method: LatinX模型采用12层解码器结构的Transformer，通过三阶段训练：1）文本到音频的预训练；2）支持零样本语音克隆的有监督微调；3）利用基于词错误率（WER）和说话人相似性自动标签，对模型进行直接偏好优化（DPO）对齐。

Result: LatinX在英语和罗曼语族（以葡萄牙语为主）上进行训练，通过DPO显著降低词错误率、提升说话人客观相似性，在主流基线（如XTTSv2）上取得更强表现。人工评价还显示主观说话人相似度优于强基线模型。

Conclusion: LatinX在跨语言TTS任务中兼顾了语音内容和说话人身份的信息保持，既提升了自动和人工评测指标，也揭示了主观与客观评价标准之间的差异。未来工作包括优化偏好信号和进一步降低模型延迟。

Abstract: We present LatinX, a multilingual text-to-speech (TTS) model for cascaded
speech-to-speech translation that preserves the source speaker's identity
across languages. LatinX is a 12-layer decoder-only Transformer trained in
three stages: (i) pre-training for text-to-audio mapping, (ii) supervised
fine-tuning for zero-shot voice cloning, and (iii) alignment with Direct
Preference Optimization (DPO) using automatically labeled pairs based on Word
Error Rate (WER) and speaker-similarity metrics. Trained on English and Romance
languages with emphasis on Portuguese, LatinX with DPO consistently reduces WER
and improves objective similarity over the fine-tuned baseline. Human
evaluations further indicate stronger perceived speaker similarity than a
strong baseline (XTTSv2), revealing gaps between objective and subjective
measures. We provide cross-lingual analyses and discuss balanced preference
signals and lower-latency architectures as future work.

</details>


### [189] [ZhiFangDanTai: Fine-tuning Graph-based Retrieval-Augmented Generation Model for Traditional Chinese Medicine Formula](https://arxiv.org/abs/2509.05867)
*ZiXuan Zhang,Bowen Hao,Yingjie Li,Hongzhi Yin*

Main category: cs.CL

TL;DR: 提出了 ZhiFangDanTai 框架，将图结构检索增强生成（GraphRAG）与大模型微调结合，实现对中医药方的高质量生成和全面解释，在多个数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有中医方剂生成和分析模型在解释性和细致度方面不足，如无法完整展示药方组成、药物角色（君臣佐使）、功效、禁忌及舌脉诊断等关键信息，导致模型输出深度有限。

Method: 提出 ZhiFangDanTai 框架，利用 GraphRAG 技术检索并整合结构化中医知识，生成简明摘要，并构建增强型指令数据集对大模型进行微调，从而提升模型整合和解释方剂的能力。同时给出理论证明，说明 GraphRAG 与微调结合能降低泛化误差和幻觉率。

Result: 在自建和临床数据集上的实验结果显示，ZhiFangDanTai 在中医方剂任务中，在完整性、解释性和准确性等方面均显著优于当前最先进模型。

Conclusion: ZhiFangDanTai 通过知识检索和大模型微调结合，有效提升中医方剂生成与解析的质量，对推动中医智能化具有重要意义。模型及相关资源已开源。

Abstract: Traditional Chinese Medicine (TCM) formulas play a significant role in
treating epidemics and complex diseases. Existing models for TCM utilize
traditional algorithms or deep learning techniques to analyze formula
relationships, yet lack comprehensive results, such as complete formula
compositions and detailed explanations. Although recent efforts have used TCM
instruction datasets to fine-tune Large Language Models (LLMs) for explainable
formula generation, existing datasets lack sufficient details, such as the
roles of the formula's sovereign, minister, assistant, courier; efficacy;
contraindications; tongue and pulse diagnosis-limiting the depth of model
outputs. To address these challenges, we propose ZhiFangDanTai, a framework
combining Graph-based Retrieval-Augmented Generation (GraphRAG) with LLM
fine-tuning. ZhiFangDanTai uses GraphRAG to retrieve and synthesize structured
TCM knowledge into concise summaries, while also constructing an enhanced
instruction dataset to improve LLMs' ability to integrate retrieved
information. Furthermore, we provide novel theoretical proofs demonstrating
that integrating GraphRAG with fine-tuning techniques can reduce generalization
error and hallucination rates in the TCM formula task. Experimental results on
both collected and clinical datasets demonstrate that ZhiFangDanTai achieves
significant improvements over state-of-the-art models. Our model is
open-sourced at https://huggingface.co/tczzx6/ZhiFangDanTai1.0.

</details>


### [190] [MedFactEval and MedAgentBrief: A Framework and Workflow for Generating and Evaluating Factual Clinical Summaries](https://arxiv.org/abs/2509.05878)
*François Grolleau,Emily Alsentzer,Timothy Keyes,Philip Chung,Akshay Swaminathan,Asad Aali,Jason Hom,Tridu Huynh,Thomas Lew,April S. Liang,Weihan Chu,Natasha Z. Steele,Christina F. Lin,Jingkun Yang,Kameron C. Black,Stephen P. Ma,Fateme N. Haredasht,Nigam H. Shah,Kevin Schulman,Jonathan H. Chen*

Main category: cs.CL

TL;DR: 本文提出了可扩展评估LLM生成临床文本事实准确性的方法及高质量病历总结生成流程，有效推动AI在医疗领域负责任部署。


<details>
  <summary>Details</summary>
Motivation: LLM在生成临床文本中存在事实准确性评估难题，人工审核不可扩展，限制了其广泛应用。

Method: 1. 提出MedFactEval评估框架：由临床医生定义关键事实，再由多LLM投票（LLM Jury）判断文本中这些事实是否被包含。
2. 开发MedAgentBrief工作流：一种与模型无关、多步骤的高质量出院总结生成方式。
3. 用七名医生多数票建立关键事实参考标准，并与LLM Jury性能对比验证。

Result: LLM Jury对关键事实的识别与专家多数意见高度一致（Cohen’s kappa=81%），表现与单一专家并无显著差异（kappa=67%，P<0.001）。

Conclusion: 该方法为医疗生成式AI提供了有力的事实性评估工具和高质量生成流程，为其在临床应用的规范、安全落地打下基础。

Abstract: Evaluating factual accuracy in Large Language Model (LLM)-generated clinical
text is a critical barrier to adoption, as expert review is unscalable for the
continuous quality assurance these systems require. We address this challenge
with two complementary contributions. First, we introduce MedFactEval, a
framework for scalable, fact-grounded evaluation where clinicians define
high-salience key facts and an "LLM Jury"--a multi-LLM majority vote--assesses
their inclusion in generated summaries. Second, we present MedAgentBrief, a
model-agnostic, multi-step workflow designed to generate high-quality, factual
discharge summaries. To validate our evaluation framework, we established a
gold-standard reference using a seven-physician majority vote on
clinician-defined key facts from inpatient cases. The MedFactEval LLM Jury
achieved almost perfect agreement with this panel (Cohen's kappa=81%), a
performance statistically non-inferior to that of a single human expert
(kappa=67%, P < 0.001). Our work provides both a robust evaluation framework
(MedFactEval) and a high-performing generation workflow (MedAgentBrief),
offering a comprehensive approach to advance the responsible deployment of
generative AI in clinical workflows.

</details>


### [191] [Let's Roleplay: Examining LLM Alignment in Collaborative Dialogues](https://arxiv.org/abs/2509.05882)
*Abhijnan Nath,Carine Graff,Nikhil Krishnaswamy*

Main category: cs.CL

TL;DR: 本文研究了不同对齐方法如何影响大语言模型在多人多轮协作任务中的表现，提出了“摩擦代理”并引入了反事实评估框架，结果显示考虑摩擦的对齐方法能够更好地促进团队共识和任务正确性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型多用于单用户场景，对齐方法亦如此，缺乏对复杂多轮多方协作场景的考量。为确保AI协作者在部署前的可靠和可验证行为，需要研究AI在长期复杂互动中表现如何。

Method: 作者提出“摩擦代理”——在群组对话中介入让团队成员反思其推理过程，并采用角色扮演方法，比较不同训练方式的摩擦代理进行干预时的协作效果。同时，作者提出反事实评估框架量化这些干预对于团队协作和信念对齐的影响。

Result: 结果显示，结合摩擦感知的对齐方法在协作过程中，无论达成共同观点还是任务结果正确率上，表现都明显优于常规对齐基线。

Conclusion: 面向多人多轮协作任务，对齐方法应关注互动中摩擦和反思机制，引入摩擦代理可有效提升团队协作效果和任务完成质量。

Abstract: As Large Language Models (LLMs) integrate into diverse workflows, they are
increasingly being considered "collaborators" with humans. If such AI
collaborators are to be reliable, their behavior over multiturn interactions
must be predictable, validated and verified before deployment. Common alignment
techniques are typically developed under simplified single-user settings and do
not account for the dynamics of long-horizon multiparty interactions. This
paper examines how different alignment methods affect LLM agents' effectiveness
as partners in multiturn, multiparty collaborations. We study this question
through the lens of friction agents that intervene in group dialogues to
encourage the collaborative group to slow down and reflect upon their reasoning
for deliberative decision-making. Using a roleplay methodology, we evaluate
interventions from differently-trained friction agents in collaborative task
conversations. We propose a novel counterfactual evaluation framework that
quantifies how friction interventions change the trajectory of group
collaboration and belief alignment. Our results show that a friction-aware
approach significantly outperforms common alignment baselines in helping both
convergence to a common ground, or agreed-upon task-relevant propositions, and
correctness of task outcomes.

</details>


### [192] [Enhancing the Robustness of Contextual ASR to Varying Biasing Information Volumes Through Purified Semantic Correlation Joint Modeling](https://arxiv.org/abs/2509.05908)
*Yue Gu,Zhihao Du,Ying Shi,Shiliang Zhang,Qian Chen,Jiqing Han*

Main category: cs.CL

TL;DR: 本文提出了一种新方法（PSC-Joint）提升带有个性化提示短语的自动语音识别（ASR）系统在变化长度的提示短语列表下的识别效果。该方法能更精准地筛选和整合相关语义信息，实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于交叉注意力的上下文ASR模型对提示短语个性化识别已取得进展，但在提示短语列表长度较长时，性能下降明显。主要原因是系统无法有效区分哪些提示短语与当前输入最相关，导致无关信息干扰识别效果。为解决这一问题，作者希望提升模型对相关提示短语的识别与利用能力，减轻无关提示短语带来的影响。

Method: 作者提出了PSC-Joint方法，即纯化语义相关性联合建模。该方法分别计算ASR中间表示和提示短语之间的三种粒度（列表级、短语级和token级）语义相关性，并联合建模三者的交集，突出并整合最相关的提示短语。此外，还设计了基于分组和竞争机制的纯化机制，从而过滤掉无关的提示短语以降低计算成本。

Result: 在AISHELL-1和KeSpeech两个数据集上，该方法在不同长度提示短语列表下，F1分数相较基线方法分别平均提升了21.34%和28.46%。

Conclusion: PSC-Joint能有效筛选出与语音内容高度相关的提示短语，使个性化ASR系统在处理长提示列表时，仍能保持较高识别性能，并显著优于现有基线。

Abstract: Recently, cross-attention-based contextual automatic speech recognition (ASR)
models have made notable advancements in recognizing personalized biasing
phrases. However, the effectiveness of cross-attention is affected by
variations in biasing information volume, especially when the length of the
biasing list increases significantly. We find that, regardless of the length of
the biasing list, only a limited amount of biasing information is most relevant
to a specific ASR intermediate representation. Therefore, by identifying and
integrating the most relevant biasing information rather than the entire
biasing list, we can alleviate the effects of variations in biasing information
volume for contextual ASR. To this end, we propose a purified semantic
correlation joint modeling (PSC-Joint) approach. In PSC-Joint, we define and
calculate three semantic correlations between the ASR intermediate
representations and biasing information from coarse to fine: list-level,
phrase-level, and token-level. Then, the three correlations are jointly modeled
to produce their intersection, so that the most relevant biasing information
across various granularities is highlighted and integrated for contextual
recognition. In addition, to reduce the computational cost introduced by the
joint modeling of three semantic correlations, we also propose a purification
mechanism based on a grouped-and-competitive strategy to filter out irrelevant
biasing phrases. Compared with baselines, our PSC-Joint approach achieves
average relative F1 score improvements of up to 21.34% on AISHELL-1 and 28.46%
on KeSpeech, across biasing lists of varying lengths.

</details>


### [193] [Accelerating Large Language Model Inference via Early-Exiting Algorithms](https://arxiv.org/abs/2509.05915)
*Sangmin Bae*

Main category: cs.CL

TL;DR: 本文提出了一种兼顾自适应计算与架构共设计的方法，用以解决大模型早退机制下，单token动态性带来的系统级吞吐瓶颈。通过高效的并行解码、参数共享和预训练路由器的方法，有效优化了推理效率与模型表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型计算开销大，实际部署受限。尽管自适应计算（如early-exiting）有望降低成本，但其token级动态常导致批量推理的吞吐瓶颈，提升反而受阻。需寻找兼顾动态性和系统效率的解决方案。

Method: 1）提出高效的并行解码机制，降低early-exiting带来的系统开销。2）利用深度参数共享，设计紧凑高效的模型架构并缓解早退带来的同步问题。3）用轻量化路由器进行预训练，根据每个token动态分配最优递归深度，统一优化自适应计算与参数效率。

Result: 1）实现了兼具适应性和高效率的批量推理。2）新架构不仅参数更少，推理更快，还缓解了同步瓶颈。3）提出的方法在效率与性能上取得了新的Pareto最优前沿。

Conclusion: 自适应算法与模型架构协同优化能有效解决大模型推理动态化与效率的矛盾，为大语言模型部署提供了更优的效率与性能权衡。

Abstract: Large language models have achieved remarkable capabilities, but their
practical deployment is hindered by significant computational costs. While
adaptive computation methods like early-exiting promise to reduce these costs,
they introduce a fundamental conflict: the per-token dynamism intended to save
computation often creates system-level bottlenecks that can paradoxically
reduce throughput in batched inference. This dissertation resolves this
conflict by co-designing adaptive algorithms and model architectures to strike
an optimal balance between dynamism and efficiency. To this end, our work first
addresses critical sources of overhead in conventional early-exiting by
proposing an efficient parallel decoding mechanism. We then show that deep
parameter sharing provides an architectural foundation that not only yields
compact, parameter-efficient models but also inherently mitigates the critical
synchronization issues affecting dynamic inference. Finally, this work presents
a unified framework where lightweight routers are pretrained to dynamically
assign an optimal recursion depth for each token. This approach establishes a
new Pareto frontier between efficiency and performance by effectively
optimizing for both adaptive computation and parameter efficiency within a
single model.

</details>


### [194] [KatotohananQA: Evaluating Truthfulness of Large Language Models in Filipino](https://arxiv.org/abs/2509.06065)
*Lorenzo Alfred Nery,Ronald Dawson Catignas,Thomas James Tiam-Lee*

Main category: cs.CL

TL;DR: 该论文将TruthfulQA评测基准翻译成菲律宾语，评估LLM在多语言环境下的真实性，发现英语和菲律宾语表现存在显著差距，部分模型具多语言鲁棒性，部分问题类型多语言迁移效果差。


<details>
  <summary>Details</summary>
Motivation: 当前多数关于大模型真实性的评测主要集中在英语，缺乏对低资源语言如菲律宾语的真实性评估工具和相关研究。为了推动LLM在更多语言下的公平与可靠性应用，亟需建立相关基准。

Method: 作者将英语TruthfulQA基准翻译成菲律宾语，构建了KatotohananQA。利用二选一测验框架，评估了七个主流免费商用模型在该基准上的表现，并针对不同类型、类别和主题的问题进行了详细分析。

Result: 发现所有模型在菲律宾语上的真实性表现远低于英语，尤其在部分问题类型、多语言迁移方面表现不佳。但OpenAI最新模型（GPT-5及其mini版）展现出较强的多语言鲁棒性。结果揭示了问题类型、类别、主题在多语言迁移中的差异。

Conclusion: 多语言环境下LLM真实性评估仍有提升空间，单一语言评测难以保证全球公平性和可靠性，建议未来加强多语言基准的构建与评估。

Abstract: Large Language Models (LLMs) achieve remarkable performance across various
tasks, but their tendency to produce hallucinations limits reliable adoption.
Benchmarks such as TruthfulQA have been developed to measure truthfulness, yet
they are primarily available in English, leaving a gap in evaluating LLMs in
low-resource languages. To address this, we present KatotohananQA, a Filipino
translation of the TruthfulQA benchmark. Seven free-tier proprietary models
were assessed using a binary-choice framework. Findings show a significant
performance gap between English and Filipino truthfulness, with newer OpenAI
models (GPT-5 and GPT-5 mini) demonstrating strong multilingual robustness.
Results also reveal disparities across question characteristics, suggesting
that some question types, categories, and topics are less robust to
multilingual transfer which highlight the need for broader multilingual
evaluation to ensure fairness and reliability in LLM usage.

</details>


### [195] [Multimodal Fine-grained Context Interaction Graph Modeling for Conversational Speech Synthesis](https://arxiv.org/abs/2509.06074)
*Zhenqi Jia,Rui Liu,Berrak Sisman,Haizhou Li*

Main category: cs.CL

TL;DR: 该论文提出了一种基于多模态细粒度上下文交互图（MFCIG-CSS）的对话语音合成方法，有效提升了合成语音的韵律表达能力。


<details>
  <summary>Details</summary>
Motivation: 现有对话语音合成方法只关注语句级别的历史交互，忽略了对话历史中词级语义和韵律的细粒度交互信息建模，导致生成的语音在韵律自然度上仍有提升空间。

Method: 作者构建了两个多模态细粒度交互图，分别对对话历史的词级语义和韵律信息进行建模。通过这两个交互图，捕捉词级语义、韵律及其对后续语句的影响，进而用于丰富生成语音的自然韵律表达。

Result: 在DailyTalk数据集上，MFCIG-CSS系统在韵律表达能力方面显著优于所有基线模型。

Conclusion: 细粒度多模态交互建模能有效捕捉会话上下文中蕴含的语义和韵律信息，为对话语音合成带来更自然的韵律表现，具有良好应用前景。

Abstract: Conversational Speech Synthesis (CSS) aims to generate speech with natural
prosody by understanding the multimodal dialogue history (MDH). The latest work
predicts the accurate prosody expression of the target utterance by modeling
the utterance-level interaction characteristics of MDH and the target
utterance. However, MDH contains fine-grained semantic and prosody knowledge at
the word level. Existing methods overlook the fine-grained semantic and
prosodic interaction modeling. To address this gap, we propose MFCIG-CSS, a
novel Multimodal Fine-grained Context Interaction Graph-based CSS system. Our
approach constructs two specialized multimodal fine-grained dialogue
interaction graphs: a semantic interaction graph and a prosody interaction
graph. These two interaction graphs effectively encode interactions between
word-level semantics, prosody, and their influence on subsequent utterances in
MDH. The encoded interaction features are then leveraged to enhance synthesized
speech with natural conversational prosody. Experiments on the DailyTalk
dataset demonstrate that MFCIG-CSS outperforms all baseline models in terms of
prosodic expressiveness. Code and speech samples are available at
https://github.com/AI-S2-Lab/MFCIG-CSS.

</details>


### [196] [Multimodal Reasoning for Science: Technical Report and 1st Place Solution to the ICML 2025 SeePhys Challenge](https://arxiv.org/abs/2509.06079)
*Hao Liang,Ruitao Wu,Bohan Zeng,Junbo Niu,Wentao Zhang,Bin Dong*

Main category: cs.CL

TL;DR: 本文提出了一种新的多模态推理方法，通过结合图片辅助文本进行推理显著提升了模型在视觉与文本混合任务中的表现，在多个权威测试中取得第一名，并具良好泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管文本推理已取得较大进展，但最先进的语言模型在多模态（如图文结合）推理方面依然表现不佳，因此需要新的方法来提高在这类任务的表现。

Method: 作者提出了一种'图像描述辅助推理框架'，通过结合视觉与文本信息实现更有效的推理，并在公开代码库中提供了实现。

Result: 该方法在ICML 2025 AI for Math Workshop与SeePhys挑战赛中获得第一名，在MathVerse几何推理基准中也表现优异，显示出方法的高效性和泛化性。

Conclusion: 该方法能够有效弥合视觉与文本推理之间的差距，为多模态推理任务提供了有力工具，在实际应用中表现出较高的适用性与鲁棒性。

Abstract: Multimodal reasoning remains a fundamental challenge in artificial
intelligence. Despite substantial advances in text-based reasoning, even
state-of-the-art models such as GPT-o3 struggle to maintain strong performance
in multimodal scenarios. To address this gap, we introduce a caption-assisted
reasoning framework that effectively bridges visual and textual modalities. Our
approach achieved 1st place in the ICML 2025 AI for Math Workshop \& Challenge
2: SeePhys, highlighting its effectiveness and robustness. Furthermore, we
validate its generalization on the MathVerse benchmark for geometric reasoning,
demonstrating the versatility of our method. Our code is publicly available at
https://github.com/OpenDCAI/SciReasoner.

</details>


### [197] [Orthogonal Low-rank Adaptation in Lie Groups for Continual Learning of Large Language Models](https://arxiv.org/abs/2509.06100)
*Kefan Cao,Shuaicheng Wu*

Main category: cs.CL

TL;DR: 本文提出了一种结合Lie群理论的低秩正交适应方法OLieRA，有效缓解LLM在多任务顺序学习中的灾难性遗忘问题，并取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLM）在顺序多任务学习中存在灾难性遗忘问题。虽然正交低秩方法（如O-LoRA, N-LoRA）通过参数正交性缓解部分干扰，但忽视了对参数几何结构的保护，影响效果。

Method: 提出OLieRA方法：使用Lie群理论对LLM参数进行乘法更新，以保持其固有的几何结构，同时对子空间施加正交约束，兼顾几何结构保护与任务干扰抑制。

Result: 实验表明，OLieRA在Standard CL基准上取得了SOTA效果，在多任务情形下依然保持领先。

Conclusion: OLieRA方法通过参数几何结构的保持和正交约束，有效提升了LLM在多任务顺序学习中的表现，优于常规参数正则化方法。

Abstract: Large language models (LLMs) are prone to catastrophic forgetting in
sequential multi-task settings. Parameter regularization methods such as O-LoRA
and N-LoRA alleviate task interference by enforcing low-rank subspace
orthogonality, but they overlook the fact that conventional additive
fine-tuning disrupts the intrinsic geometric structure of LLM parameters,
limiting performance. Our key insight is that the parameter space of LLMs
possesses a geometric structure, which must be preserved in addition to
enforcing orthogonality. Based on this, we propose Orthogonal Low-rank
Adaptation in Lie Groups (OLieRA), which introduces Lie group theory into LLM
fine-tuning: leveraging multiplicative updates to preserve parameter geometry
while applying orthogonality constraints to task subspaces. Experiments
demonstrate that OLieRA achieves state-of-the-art results on the Standard CL
benchmark and remains among the top-performing methods in the Large Number of
Tasks setting.

</details>


### [198] [Benchmarking Gender and Political Bias in Large Language Models](https://arxiv.org/abs/2509.06164)
*Jinrui Yang,Xudong Han,Timothy Baldwin*

Main category: cs.CL

TL;DR: 本文提出了EuroParlVote基准数据集，用于在政治敏感场景下评估大语言模型（LLM），并揭示了性别和政治倾向等偏差。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在政治相关任务中的应用日益增多，模型潜在的性别和政治倾向偏见问题日益突出，急需标准化数据集进行系统评测与研究。

Method: 构建并发布了EuroParlVote数据集，将欧洲议会的辩论发言与投票结果及每位议员的详细人口统计信息（例如性别、年龄、国籍、政治团体）关联。以此数据集为基础，评估多个主流LLM在性别分类与投票预测两个任务上的表现，重点分析其公平性和偏倚。

Result: LLM（包括GPT-4o等商业模型和开源模型）在性别分类上普遍存在将女性议员误判为男性的问题，且对女性发言的投票模拟准确率较低。在政治立场偏差上，模型对中间派团体更友好，而在极左和极右议员上的表现较差。商业LLM在鲁棒性和公平性方面优于开源模型。

Conclusion: EuroParlVote揭示了当前LLM在性别和政治偏见方面的不足，强调了在政治NLP任务中关注公平性的重要性。该数据集的公开有助于促进后续模型的公正性与问责性研究。

Abstract: We introduce EuroParlVote, a novel benchmark for evaluating large language
models (LLMs) in politically sensitive contexts. It links European Parliament
debate speeches to roll-call vote outcomes and includes rich demographic
metadata for each Member of the European Parliament (MEP), such as gender, age,
country, and political group. Using EuroParlVote, we evaluate state-of-the-art
LLMs on two tasks -- gender classification and vote prediction -- revealing
consistent patterns of bias. We find that LLMs frequently misclassify female
MEPs as male and demonstrate reduced accuracy when simulating votes for female
speakers. Politically, LLMs tend to favor centrist groups while underperforming
on both far-left and far-right ones. Proprietary models like GPT-4o outperform
open-weight alternatives in terms of both robustness and fairness. We release
the EuroParlVote dataset, code, and demo to support future research on fairness
and accountability in NLP within political contexts.

</details>


### [199] [Understanding the Influence of Synthetic Data for Text Embedders](https://arxiv.org/abs/2509.06184)
*Jacob Mitchell Springer,Vaibhav Adlakha,Siva Reddy,Aditi Raghunathan,Marius Mosbach*

Main category: cs.CL

TL;DR: 本文公开发布了高质量的合成LLM数据集，并分析了其对通用文本嵌入模型泛化能力的实际影响。结果发现，合成数据的效益有限且具有高度特定性，对部分任务存在增益但对其他任务则有损害。


<details>
  <summary>Details</summary>
Motivation: 近年来，通用文本嵌入模型依赖大规模合成数据训练，但缺乏公开数据集妨碍了对其泛化作用的研究。因此，作者希望通过复现并公开现有的合成数据以推动相关研究。

Method: 作者首先复现并发布了Wang等人提出的Mistral-E5合成数据集，然后在此数据集基础上训练嵌入模型，并系统分析合成数据在不同任务和数据集上的泛化效果，评估其对模型表现的实际影响和局限性。

Result: 实验发现，合成数据确实能够提升部分任务场景下的模型表现，但增益非常稀疏且具有高度数据集定位性。同时，提升某类任务的表现往往伴随着对其他任务表现的损害，存在显著权衡。

Conclusion: 当前的合成数据方法对于提升通用文本嵌入模型的鲁棒性和泛化能力存在明显局限，仅在部分场景下具有积极作用，不能广泛保证所有任务表现。这对研究者滥用合成数据训练通用嵌入器提出了警示。

Abstract: Recent progress in developing general purpose text embedders has been driven
by training on ever-growing corpora of synthetic LLM-generated data.
Nonetheless, no publicly available synthetic dataset exists, posing a barrier
to studying its role for generalization. To address this issue, we first
reproduce and publicly release the synthetic data proposed by Wang et al.
(Mistral-E5). Our synthetic data is high quality and leads to consistent
improvements in performance. Next, we critically examine where exactly
synthetic data improves model generalization. Our analysis reveals that
benefits from synthetic data are sparse and highly localized to individual
datasets. Moreover, we observe trade-offs between the performance on different
categories and data that benefits one task, degrades performance on another.
Our findings highlight the limitations of current synthetic data approaches for
building general-purpose embedders and challenge the notion that training on
synthetic data leads to more robust embedding models across tasks.

</details>


### [200] [Augmented Fine-Tuned LLMs for Enhanced Recruitment Automation](https://arxiv.org/abs/2509.06196)
*Mohamed T. Younes,Omar Walid,Khaled Shaban,Ali Hamdi,Mai Hassan*

Main category: cs.CL

TL;DR: 本文提出了一种用于招聘自动化的新方法，通过对大语言模型（LLMs）进行微调，以提高招聘流程的准确性和效率。实验结果显示，微调后的模型，在多项评价指标上均大幅超越基线和现有先进方法，表现出卓越的候选人-岗位匹配能力。


<details>
  <summary>Details</summary>
Motivation: 通用大语言模型在招聘任务中存在泛化性不足、结构化数据处理不佳等限制。为解决这一问题，作者希望通过定制模型和专用数据集显著提升招聘相关任务的表现和实用性。

Method: 作者基于此前提出的MLAR系统，采用synthetic候选人数据与真实简历数据（经DeepSeek解析为结构化JSON格式）共同训练，用于对招聘任务专门微调LLM（如Phi-4模型），同时保证数据一致性和可扩展性。

Result: 实验表明，微调的Phi-4模型在多个评测指标（如F1分数90.62%）均优于基础及其他先进LLM模型，在精确率和召回率方面表现突出，实现对招聘流程的显著优化。

Conclusion: 专用微调的LLM在招聘自动化上展现出巨大潜力，有望彻底变革招聘流程，实现更高质量的人岗匹配和自动化提升。

Abstract: This paper presents a novel approach to recruitment automation. Large
Language Models (LLMs) were fine-tuned to improve accuracy and efficiency.
Building upon our previous work on the Multilayer Large Language Model-Based
Robotic Process Automation Applicant Tracking (MLAR) system . This work
introduces a novel methodology. Training fine-tuned LLMs specifically tuned for
recruitment tasks. The proposed framework addresses the limitations of generic
LLMs by creating a synthetic dataset that uses a standardized JSON format. This
helps ensure consistency and scalability. In addition to the synthetic data
set, the resumes were parsed using DeepSeek, a high-parameter LLM. The resumes
were parsed into the same structured JSON format and placed in the training
set. This will help improve data diversity and realism. Through
experimentation, we demonstrate significant improvements in performance
metrics, such as exact match, F1 score, BLEU score, ROUGE score, and overall
similarity compared to base models and other state-of-the-art LLMs. In
particular, the fine-tuned Phi-4 model achieved the highest F1 score of 90.62%,
indicating exceptional precision and recall in recruitment tasks. This study
highlights the potential of fine-tuned LLMs. Furthermore, it will revolutionize
recruitment workflows by providing more accurate candidate-job matching.

</details>


### [201] [MSLEF: Multi-Segment LLM Ensemble Finetuning in Recruitment](https://arxiv.org/abs/2509.06200)
*Omar Walid,Mohamed T. Younes,Khaled Shaban,Mai Hassan,Ali Hamdi*

Main category: cs.CL

TL;DR: 提出了MSLEF多段集成框架，通过细分简历结构，集成多个微调大模型，用于招聘自动化的简历解析任务，并显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前单一大模型在简历解析上受限于不同格式和结构，难以泛化并保证精度，实际招聘中存在多样性和复杂性的挑战，需要更精准且适应性强的解析方法。

Method: 设计了一个多段集成框架MSLEF，将简历划分为不同结构部分，每段分别用微调后的大模型(如Gemini-2.5-Flash、Gemma 9B、LLaMA 3.1 8B、Phi-4 14B)分析，通过加权投票方式融合各模型结果，主模型负责复杂内容聚合。

Result: MSLEF在Exact Match、F1、BLEU、ROUGE与Recruitment Similarity等指标上取得显著提升，尤其在Recruitment Similarity上比最优单模型高出7%。

Conclusion: MSLEF多段结构提升了解析泛化能力和精度，应对现实招聘中简历多样性，适用于实际应用场景，提升候选人表示的准确与可靠性。

Abstract: This paper presents MSLEF, a multi-segment ensemble framework that employs
LLM fine-tuning to enhance resume parsing in recruitment automation. It
integrates fine-tuned Large Language Models (LLMs) using weighted voting, with
each model specializing in a specific resume segment to boost accuracy.
Building on MLAR , MSLEF introduces a segment-aware architecture that leverages
field-specific weighting tailored to each resume part, effectively overcoming
the limitations of single-model systems by adapting to diverse formats and
structures. The framework incorporates Gemini-2.5-Flash LLM as a high-level
aggregator for complex sections and utilizes Gemma 9B, LLaMA 3.1 8B, and Phi-4
14B. MSLEF achieves significant improvements in Exact Match (EM), F1 score,
BLEU, ROUGE, and Recruitment Similarity (RS) metrics, outperforming the best
single model by up to +7% in RS. Its segment-aware design enhances
generalization across varied resume layouts, making it highly adaptable to
real-world hiring scenarios while ensuring precise and reliable candidate
representation.

</details>


### [202] [No Encore: Unlearning as Opt-Out in Music Generation](https://arxiv.org/abs/2509.06277)
*Jinju Kim,Taehan Kim,Abdul Waheed,Rita Singh*

Main category: cs.CL

TL;DR: 本文介绍了机器遗忘技术在AI文本生成音乐领域中的初步应用，以解决对受版权保护内容的侵用问题，并提供了实际效果和挑战分析。


<details>
  <summary>Details</summary>
Motivation: AI音乐生成在提升创作力的同时，也带来了对受版权保护内容滥用的风险，亟需技术手段防止AI模型不当利用创意内容，回应法律与伦理关切。

Method: 作者将现有的机器遗忘（machine unlearning）方法应用到预训练的文本到音乐（TTM）生成模型上，通过实验测试方法在不显著损害模型性能的情况下，能否有效移除预训练数据集中的敏感或受保护内容。

Result: 实验结果揭示了在音乐生成任务中应用遗忘技术遇到的效能与保真度挑战，部分技术能够实现对特定数据的遗忘，但仍存在提升空间。

Conclusion: 研究为音乐生成模型中应用遗忘技术进行了基础性探索，指出了当前方案的难点和改进方向，为后续技术发展和更完善的版权保护研究提供了思路。

Abstract: AI music generation is rapidly emerging in the creative industries, enabling
intuitive music generation from textual descriptions. However, these systems
pose risks in exploitation of copyrighted creations, raising ethical and legal
concerns. In this paper, we present preliminary results on the first
application of machine unlearning techniques from an ongoing research to
prevent inadvertent usage of creative content. Particularly, we explore
existing methods in machine unlearning to a pre-trained Text-to-Music (TTM)
baseline and analyze their efficacy in unlearning pre-trained datasets without
harming model performance. Through our experiments, we provide insights into
the challenges of applying unlearning in music generation, offering a
foundational analysis for future works on the application of unlearning for
music generative models.

</details>


### [203] [Mask-GCG: Are All Tokens in Adversarial Suffixes Necessary for Jailbreak Attacks?](https://arxiv.org/abs/2509.06350)
*Junjie Mu,Zonghao Ying,Zhekui Fan,Zonglei Jing,Yaoyuan Zhang,Zhengmin Yu,Wenxin Zhang,Quanchen Zou,Xiangzheng Zhang*

Main category: cs.CL

TL;DR: 本论文提出Mask-GCG，一种针对大型语言模型越狱攻击的高效方法，通过可学习的token掩码去除冗余token，提升攻击效率与解释性。


<details>
  <summary>Details</summary>
Motivation: 现有GCG方法均采用固定长度的后缀token进行越狱攻击，但这些后缀中可能存在冗余token，其作用和必要性尚未被深入探讨。研究冗余有助于优化攻击方法，同时为LLM的安全和效率改进提供理论依据。

Method: 作者提出了一种即插即用的Mask-GCG方法，结合可学习的token掩码机制，在优化过程中动态识别和保留对攻击效果影响大的token，删减或掩盖影响小的token，减少后缀中的冗余并降低计算开销。并将该方法应用于原始GCG及数个改进变种上进行实验。

Result: 实验结果显示，后缀token中大部分对攻击成功有显著贡献，仅有少量低影响token可以被剪枝。该方法在不影响攻击成功率（ASR）和损失值的前提下，减少了token数量，缩小了梯度空间，同时减少了攻击所需计算资源和时间。

Conclusion: Mask-GCG有效证明了现有GCG攻击方法中token的冗余性，并通过合理剪枝提升了攻击效率与解释性。该工作为理解和提升LLM模型可解释性、安全性提供了新思路，尤其从越狱攻击视角揭示了优化空间。

Abstract: Jailbreak attacks on Large Language Models (LLMs) have demonstrated various
successful methods whereby attackers manipulate models into generating harmful
responses that they are designed to avoid. Among these, Greedy Coordinate
Gradient (GCG) has emerged as a general and effective approach that optimizes
the tokens in a suffix to generate jailbreakable prompts. While several
improved variants of GCG have been proposed, they all rely on fixed-length
suffixes. However, the potential redundancy within these suffixes remains
unexplored. In this work, we propose Mask-GCG, a plug-and-play method that
employs learnable token masking to identify impactful tokens within the suffix.
Our approach increases the update probability for tokens at high-impact
positions while pruning those at low-impact positions. This pruning not only
reduces redundancy but also decreases the size of the gradient space, thereby
lowering computational overhead and shortening the time required to achieve
successful attacks compared to GCG. We evaluate Mask-GCG by applying it to the
original GCG and several improved variants. Experimental results show that most
tokens in the suffix contribute significantly to attack success, and pruning a
minority of low-impact tokens does not affect the loss values or compromise the
attack success rate (ASR), thereby revealing token redundancy in LLM prompts.
Our findings provide insights for developing efficient and interpretable LLMs
from the perspective of jailbreak attacks.

</details>


### [204] [PL-CA: A Parametric Legal Case Augmentation Framework](https://arxiv.org/abs/2509.06356)
*Ao Chang,Yubo Chen,Jun Zhao*

Main category: cs.CL

TL;DR: 本文提出PL-CA方法，在司法领域解决传统RAG（检索增强生成）存在的上下文窗口受限和推理效率降低等问题，通过参数化知识注入替代直接扩展上下文，提升整体性能，并构建了多任务法律数据集验证方法有效性。


<details>
  <summary>Details</summary>
Motivation: 司法领域对知识完整性、逻辑性和准确性要求极高，传统RAG方法简单拼接检索内容带来上下文过长、模型注意力分散、推理效率低等问题，且公开评测多单一任务、缺乏专家标注，难以衡量真实场景的模型能力。

Method: 提出P-RAG框架，将增强后的法律知识编码为参数向量，并通过LoRA技术注入到大模型的前馈网络中，减少直接拼接文档对上下文窗口的压力。同时，作者构建了一个涵盖多种法律任务、经专家标注和人工审核的数据集。

Result: 在自建多任务法律数据集上的实验表明，PL-CA方法减少了超长上下文带来的计算开销，同时在下游任务保持与传统RAG相当甚至更优的效果。

Conclusion: 参数化RAG和FFN知识注入方式能有效解决上下文瓶颈，优化司法领域多任务表现，配套数据集为后续研究提供了高质量资源。

Abstract: Conventional RAG is considered one of the most effective methods for
addressing model knowledge insufficiency and hallucination, particularly in the
judicial domain that requires high levels of knowledge rigor, logical
consistency, and content integrity. However, the conventional RAG method only
injects retrieved documents directly into the model's context, which severely
constrains models due to their limited context windows and introduces
additional computational overhead through excessively long contexts, thereby
disrupting models' attention and degrading performance on downstream tasks.
Moreover, many existing benchmarks lack expert annotation and focus solely on
individual downstream tasks while real-world legal scenarios consist of
multiple mixed legal tasks, indicating conventional benchmarks' inadequacy for
reflecting models' true capabilities. To address these limitations, we propose
PL-CA, which introduces a parametric RAG (P-RAG) framework to perform data
augmentation on corpus knowledge and encode this legal knowledge into
parametric vectors, and then integrates this parametric knowledge into the
LLM's feed-forward networks (FFN) via LoRA, thereby alleviating models' context
pressure. Additionally, we also construct a multi-task legal dataset comprising
more than 2000 training and test instances, which are all expert-annotated and
manually verified. We conduct our experiments on our dataset, and the
experimental results demonstrate that our method reduces the overhead
associated with excessively long contexts while maintaining competitive
performance on downstream tasks compared to conventional RAG. Our code and
dataset are provided in the appendix.

</details>


### [205] [Do LLMs exhibit the same commonsense capabilities across languages?](https://arxiv.org/abs/2509.06401)
*Ivan Martínez-Murillo,Elena Lloret,Paloma Moreda,Albert Gatt*

Main category: cs.CL

TL;DR: 本文提出了MULTICOM多语言常识生成基准，评测了多种开源大模型在多语言常识生成上的能力，发现英文表现突出，较少资源语言表现不足。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型能力增强，其多语言常识生成能力成为关注焦点。然而，目前缺乏系统的评测工具和数据集来对多语言常识生成进行量化分析。作者希望通过新基准填补这一空白，深入分析模型在不同语言上的表现。

Method: 作者构建了MULTICOM基准，扩展现有COCOTEROS数据集，覆盖英文、西班牙文、荷兰文和巴伦西亚文。任务要求模型用给定三个词生成合乎常识的句子。评测对象包括LLaMA、Qwen、Gemma、EuroLLM、Salamandra等开源LLM，采用自动指标、LLM-as-a-judge方法和人工标注多维度评估表现。

Result: 实验结果显示所有模型在英文任务上表现最好，而在低资源语言（如巴伦西亚文）表现明显下降。对于低资源语言，适当的上下文支持有助于提升表现。

Conclusion: 当前主流LLM在多语言常识生成，尤其是低资源语言上仍有明显不足。MULTICOM数据集有助于促进后续研究和模型改进。

Abstract: This paper explores the multilingual commonsense generation abilities of
Large Language Models (LLMs). To facilitate this investigation, we introduce
MULTICOM, a novel benchmark that extends the COCOTEROS dataset to four
languages: English, Spanish, Dutch, and Valencian. The task involves generating
a commonsensical sentence that includes a given triplet of words. We evaluate a
range of open-source LLMs, including LLaMA, Qwen, Gemma, EuroLLM, and
Salamandra, on this benchmark. Our evaluation combines automatic metrics,
LLM-as-a-judge approaches (using Prometheus and JudgeLM), and human
annotations. Results consistently show superior performance in English, with
significantly lower performance in less-resourced languages. While contextual
support yields mixed results, it tends to benefit underrepresented languages.
These findings underscore the current limitations of LLMs in multilingual
commonsense generation. The dataset is publicly available at
https://huggingface.co/datasets/gplsi/MULTICOM.

</details>


### [206] [WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents](https://arxiv.org/abs/2509.06501)
*Junteng Liu,Yunji Li,Chi Zhang,Jingyang Li,Aili Chen,Ke Ji,Weiyu Cheng,Zijia Wu,Chengyu Du,Qidi Xu,Jiayuan Song,Zhengmao Zhu,Wenhu Chen,Pengyu Zhao,Junxian He*

Main category: cs.CL

TL;DR: 本文提出WebExplorer，一种用于生成高难度信息检索数据的数据生成方法，并基于此训练了WebExplorer-8B模型，在多项复杂网页浏览任务中取得了同规模最优表现。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在面向复杂任务的信息检索与网页代理能力上表现有限，且开源方案透明度不高，主要瓶颈在于缺少高质量、复杂的数据用于训练。

Method: 提出WebExplorer系统性数据生成方法，通过模型驱动探索和分阶段查询进化，生成需要多步推理和复杂网页导航的挑战性问答对；据此数据利用监督微调与强化学习，训练了WebExplorer-8B。该模型支持128K上下文长度和最多100轮工具调用。

Result: WebExplorer-8B在多项信息检索基准测试中（如BrowseComp-en/zh、WebWalkerQA和FRAMES）取得了同参数规模下最优或超越大模型的准确率；在HLE等泛化任务中也表现优异。

Conclusion: WebExplorer数据生成与模型训练方法有效提升了中等规模大语言模型在长时序、复杂网页代理任务上的信息检索和通用化能力，为发展面向未来的网页代理智能体提供了现实可行的路径。

Abstract: The paradigm of Large Language Models (LLMs) has increasingly shifted toward
agentic applications, where web browsing capabilities are fundamental for
retrieving information from diverse online sources. However, existing
open-source web agents either demonstrate limited information-seeking abilities
on complex tasks or lack transparent implementations. In this work, we identify
that the key challenge lies in the scarcity of challenging data for information
seeking. To address this limitation, we introduce WebExplorer: a systematic
data generation approach using model-based exploration and iterative,
long-to-short query evolution. This method creates challenging query-answer
pairs that require multi-step reasoning and complex web navigation. By
leveraging our curated high-quality dataset, we successfully develop advanced
web agent WebExplorer-8B through supervised fine-tuning followed by
reinforcement learning. Our model supports 128K context length and up to 100
tool calling turns, enabling long-horizon problem solving. Across diverse
information-seeking benchmarks, WebExplorer-8B achieves the state-of-the-art
performance at its scale. Notably, as an 8B-sized model, WebExplorer-8B is able
to effectively search over an average of 16 turns after RL training, achieving
higher accuracy than WebSailor-72B on BrowseComp-en/zh and attaining the best
performance among models up to 100B parameters on WebWalkerQA and FRAMES.
Beyond these information-seeking tasks, our model also achieves strong
generalization on the HLE benchmark even though it is only trained on
knowledge-intensive QA data. These results highlight our approach as a
practical path toward long-horizon web agents.

</details>


### [207] [Crown, Frame, Reverse: Layer-Wise Scaling Variants for LLM Pre-Training](https://arxiv.org/abs/2509.06518)
*Andrei Baroian,Kasper Notebomer*

Main category: cs.CL

TL;DR: 提出了三种用于Transformer模型的新的逐层动态结构设计方法，并系统地分析了其在相同参数预算下的表现优势。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer模型各层大小统一，未能充分利用不同层承担的功能多样性和对应的计算需求，限制了模型效率和表现。

Method: 借鉴逐层缩放（LWS）和剪枝方法，提出了Framed、Reverse和Crown三种变体，通过两点或三点线性插值在预训练阶段重新分配FFN宽度和注意力头数。对这些方法在参数量为180M、训练数据为50亿token的情况下进行系统消融实验。

Result: 所有提出的方法都能达到与等参数等成本同构模型相似的损失，并获得更好的性能，而且训练效率并未明显下降。

Conclusion: 逐层异构结构在给定预算下优于传统同构结构，是一种值得探索的新架构方向，但未来需要在更大规模实验下进一步验证其潜力。

Abstract: Transformer-based language models traditionally use uniform (isotropic) layer
sizes, yet they ignore the diverse functional roles that different depths can
play and their computational capacity needs. Building on Layer-Wise Scaling
(LWS) and pruning literature, we introduce three new LWS variants - Framed,
Reverse, and Crown - that redistribute FFN widths and attention heads via two
or three-point linear interpolation in the pre-training stage. We present the
first systematic ablation of LWS and its variants, on a fixed budget of 180M
parameters, trained on 5B tokens. All models converge to similar losses and
achieve better performance compared to an equal-cost isotropic baseline,
without a substantial decrease in training throughput. This work represents an
initial step into the design space of layer-wise architectures for
pre-training, but future work should scale experiments to orders of magnitude
more tokens and parameters to fully assess their potential.

</details>


### [208] [LAMDAS: LLM as an Implicit Classifier for Domain-specific Data Selection](https://arxiv.org/abs/2509.06524)
*Jian Wu,Hang Yu,Bingchang Liu,Wenjie Yang,Peng Di,Jianguo Li,Yue Zhang*

Main category: cs.CL

TL;DR: 本论文提出了一种新方法LAMDAS，能让大语言模型在特定领域适应时，更高效且准确地选择数据，减少了依赖人工高质量数据的难题。


<details>
  <summary>Details</summary>
Motivation: 领域适应时，手工高质量数据稀缺，而随意用大量未经筛选的数据容易带入噪音，影响表现，因此需要一种高效、准确的数据选择方法。现有的方法难以兼顾效率与准确性。

Method: 提出LAMDAS，利用预训练大语言模型本身作为隐式分类器，将数据选择问题转化为单类分类，根据小型参考数据集判断候选数据是否‘属于’目标领域，无需显式特征工程和复杂的优化流程。

Result: LAMDAS在实验中使用少量数据训练，性能超过全量训练，并优于九种主流基线方法；在多种场景下效果显著。

Conclusion: LAMDAS实现了性能提升和计算效率之间的最优平衡，优于现有同类方法，是领域数据选择和模型领域适应的新方向。

Abstract: Adapting large language models (LLMs) to specific domains often faces a
critical bottleneck: the scarcity of high-quality, human-curated data. While
large volumes of unchecked data are readily available, indiscriminately using
them for fine-tuning risks introducing noise and degrading performance.
Strategic data selection is thus crucial, requiring a method that is both
accurate and efficient. Existing approaches, categorized as similarity-based
and direct optimization methods, struggle to simultaneously achieve these
goals. In this paper, we introduce LAMDAS (LLM As an iMplicit classifier for
domain-specific DAta Selection), a novel approach that leverages the
pre-trained LLM itself as an implicit classifier, thereby bypassing explicit
feature engineering and computationally intensive optimization process. LAMDAS
reframes data selection as a one-class classification problem, identifying
candidate data that "belongs" to the target domain defined by a small reference
dataset. Extensive experimental results demonstrate that LAMDAS not only
exceeds the performance of full-data training using a fraction of the data but
also outperforms nine state-of-the-art (SOTA) baselines under various
scenarios. Furthermore, LAMDAS achieves the most compelling balance between
performance gains and computational efficiency compared to all evaluated
baselines.

</details>


### [209] [SLiNT: Structure-aware Language Model with Injection and Contrastive Training for Knowledge Graph Completion](https://arxiv.org/abs/2509.06531)
*Mengxue Yang,Chun Yang,Jiaqi Zhu,Jiafan Li,Jingqi Zhang,Yuyang Li,Ying Li*

Main category: cs.CL

TL;DR: SLiNT是一种将知识图谱结构信息与大语言模型结合，用于提升知识图谱链接预测的新方法，实验表明优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 由于大语言模型在知识图谱链接预测任务中难以充分利用结构信息，导致遇到结构稀疏或零样本任务时表现有限，因此需要一种能更好结合结构信号和语义信息的新方法。

Method: 提出SLiNT模块化框架，主要包括三部分：1) 通过SGNE方法增强稀疏实体的结构邻域；2) DHCL引入动态的对比学习以细化实体监督；3) GDDI实现了结构信息的高效注入，同时保持主干LLM参数的稳定。使用LoRA高效微调，整体模型在冻结LLM主干下实现结构感知。

Result: 在主流知识图谱任务集（WN18RR和FB15k-237）上的实验结果显示，SLiNT相比基于嵌入和生成方法的主流基线具有更优或有竞争力的性能。

Conclusion: SLiNT证明了结构感知的表示学习方法在大规模知识图谱补全任务中的有效性，并为结构与语义融合带来了新的思路。

Abstract: Link prediction in knowledge graphs requires integrating structural
information and semantic context to infer missing entities. While large
language models offer strong generative reasoning capabilities, their limited
exploitation of structural signals often results in structural sparsity and
semantic ambiguity, especially under incomplete or zero-shot settings. To
address these challenges, we propose SLiNT (Structure-aware Language model with
Injection and coNtrastive Training), a modular framework that injects
knowledge-graph-derived structural context into a frozen LLM backbone with
lightweight LoRA-based adaptation for robust link prediction. Specifically,
Structure-Guided Neighborhood Enhancement (SGNE) retrieves pseudo-neighbors to
enrich sparse entities and mitigate missing context; Dynamic Hard Contrastive
Learning (DHCL) introduces fine-grained supervision by interpolating hard
positives and negatives to resolve entity-level ambiguity; and
Gradient-Decoupled Dual Injection (GDDI) performs token-level structure-aware
intervention while preserving the core LLM parameters. Experiments on WN18RR
and FB15k-237 show that SLiNT achieves superior or competitive performance
compared with both embedding-based and generation-based baselines,
demonstrating the effectiveness of structure-aware representation learning for
scalable knowledge graph completion.

</details>


### [210] [HAVE: Head-Adaptive Gating and ValuE Calibration for Hallucination Mitigation in Large Language Models](https://arxiv.org/abs/2509.06596)
*Xin Tong,Zhi Lin,Jingya Wang,Bo Jin*

Main category: cs.CL

TL;DR: 本文提出了一种新的解码框架HAVE，有效减少LLMs（大语言模型）在带检索增强或长上下文生成任务中的幻觉现象，无需微调，且可高效应用于多种LLM。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在进行检索增强生成或长上下文生成时，常常即使有相关证据也会产生幻觉。这主要源自两个原因：一是注意力头的重要性通常被作为与输入无关的常数处理，二是原始注意力权重并不能准确反映每个token的真实贡献。

Method: 提出了HAVE（Head-Adaptive Gating and Value Calibration）框架，包括两部分：1）头自适应门控，通过软性权重调整每个实例的注意力头；2）数值校准，将value向量的幅值融入注意力，以近似token在模型状态中的实际“写回”贡献。最终，这些基于证据的模块与语言模型分布结合，通过不确定性缩放策略融合。整个流程无需模型微调，仅依赖前向推理。

Result: 在多个问答基准和多种LLM（大语言模型）上实验证明，HAVE显著减少了幻觉现象，并以较低的计算开销优于包括DAGCD在内的主流强基线。

Conclusion: HAVE是一个高效、透明、易于复现且可无缝接入主流LLMs的解码框架，有助于推动真实应用中更可信的内容生成。

Abstract: Large Language Models (LLMs) often produce hallucinations in
retrieval-augmented or long-context generation, even when relevant evidence is
present. This stems from two issues: head importance is treated as
input-agnostic, and raw attention weights poorly reflect each token's true
contribution. We present HAVE (Head-Adaptive Gating and ValuE Calibration), a
parameter-free decoding framework that directly addresses both challenges. HAVE
introduces head-adaptive gating, which performs instance-level soft reweighing
of attention heads, and value calibration, which augments attention with the
magnitude of value vectors to approximate write-back contribution. Together,
these modules construct token-level evidence aligned with model updates and
fuse it with the LM distribution through a lightweight uncertainty-scaled
policy. HAVE requires no finetuning and operates in a single forward pass,
making it efficient and broadly applicable. Experiments across multiple QA
benchmarks and LLM families demonstrate that HAVE consistently reduces
hallucinations and outperforms strong baselines, including DAGCD, with modest
overhead. The framework is transparent, reproducible, and readily integrates
with off-the-shelf LLMs, advancing trustworthy generation in real-world
settings.

</details>


### [211] [Guided Decoding and Its Critical Role in Retrieval-Augmented Generation](https://arxiv.org/abs/2509.06631)
*Özgür Uğur,Musa Yılmaz,Esra Şavirdi,Özay Ezerceli,Mahmut El Huseyni,Selva Taş,Reyhan Bayraktar*

Main category: cs.CL

TL;DR: 本研究比较了三种引导解码方法（Outlines、XGrammar、LM Format Enforcer）在RAG系统中生成结构化输出的表现，评估了其在多轮提示设置下的成功率、幻觉率和输出质量。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在各种应用场景中的应用，对结构化和可靠输出的需求不断增长。然而，RAG系统中确保输出符合预期格式且减少幻觉的挑战较大。

Method: 通过在多轮提示（0-turn、1-turn、2-turn）下对三种引导解码方法（Outlines、XGrammar、LM Format Enforcer）进行对比实验，评估这些方法在成功率、幻觉率和输出质量方面的表现。

Result: 实验揭示了多轮交互对引导解码性能的影响，发现不同方法在不同设置下会有意料之外的性能变化，为特定场景下方法的选择提供了新视角。

Conclusion: 本研究推动了RAG系统中结构化输出生成的理解，既有理论贡献，也为大语言模型的实际部署提供了方法选择和应用指导。

Abstract: The integration of Large Language Models (LLMs) into various applications has
driven the need for structured and reliable responses. A key challenge in
Retrieval-Augmented Generation (RAG) systems is ensuring that outputs align
with expected formats while minimizing hallucinations. This study examines the
role of guided decoding in RAG systems, comparing three methods, Outlines,
XGrammar, and LM Format Enforcer, across different multi-turn prompting setups
(0-turn, 1-turn, and 2-turn). By evaluating success rates, hallucination rates,
and output quality, we provide insights into their performance and
applicability. Our findings reveal how multi-turn interactions influence guided
decoding, uncovering unexpected performance variations that can inform method
selection for specific use cases. This work advances the understanding of
structured output generation in RAG systems, offering both theoretical insights
and practical guidance for LLM deployment.

</details>


### [212] [Modelling Intertextuality with N-gram Embeddings](https://arxiv.org/abs/2509.06637)
*Yi Xing*

Main category: cs.CL

TL;DR: 本文提出了一种新的定量化互文性分析方法，通过计算文本n-gram嵌入的两两相似性平均值来量化不同文本间的互文关系，并用网络分析方法揭示文本之间的结构特征。


<details>
  <summary>Details</summary>
Motivation: 互文性是文学研究中的核心概念，但传统分析多依赖定性方法，难以处理大规模文本，也难以量化和可视化文本间复杂的联系。作者希望通过计算方法实现规模化、系统性的互文性研究。

Method: 提出对文本中的n-gram进行嵌入表示，将两文本的n-gram成对比对，计算嵌入之间的相似度，取所有比对结果的平均值作为互文性指标。此外，通过网络分析（如中心性、社区结构）进一步挖掘互文关系。

Result: 方法在包含已知互文性关系的4篇文本上进行了验证，复现效果良好，并在267篇多样化文本的规模化实验中展现出较高的效率和有效性。网络分析能够清晰地揭示文本的中心性和社区结构，展示方法识别互文性的能力。

Conclusion: 新方法可扩展、高效且量化准确，不仅能支持大规模互文性分析，还能通过网络分析获得文本间深层联系，为文学研究和文本分析提供了新工具。

Abstract: Intertextuality is a central tenet in literary studies. It refers to the
intricate links between literary texts that are created by various types of
references. This paper proposes a new quantitative model of intertextuality to
enable scalable analysis and network-based insights: perform pairwise
comparisons of the embeddings of n-grams from two texts and average their
results as the overall intertextuality. Validation on four texts with known
degrees of intertextuality, alongside a scalability test on 267 diverse texts,
demonstrates the method's effectiveness and efficiency. Network analysis
further reveals centrality and community structures, affirming the approach's
success in capturing and quantifying intertextual relationships.

</details>


### [213] [Domain-Aware RAG: MoL-Enhanced RL for Efficient Training and Scalable Retrieval](https://arxiv.org/abs/2509.06650)
*Hao Lin,Peitong Xie,Jingxue Chen,Jie Lin,Qingkun Tang,Qianchun Lu*

Main category: cs.CL

TL;DR: 本文提出了一种名为MoLER的面向领域的RAG检索增强生成方法，通过在粗排序阶段引入强化学习和多损失混合优化，有效提升了检索性能，并在多个基准数据集上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在粗排序优化时，难以兼顾领域知识学习与查询增强，导致检索效果不理想。因此，亟需一种方法能同时优化领域知识融入和检索性能。

Method: MoLER方法包括两阶段流程：（1）通过混合损失（MoL）进行持续预训练，平衡领域知识和通用语言能力；（2）采用基于Group Relative Policy Optimization（GRPO）的强化学习，联合优化查询和文档生成以提升召回率。此外，创新提出多查询单文档晚融合（MSLF）策略，降低训练开销，并通过多查询多文档晚融合（MMLF）实现可扩展推理。

Result: 在多个基准数据集上的实验表明，MoLER在检索性能上显著优于当前主流基线方法，达到了最新水平。

Conclusion: MoLER弥补了RAG系统在领域知识与检索能力两方面的不足，实现了在专业领域内强健且可扩展的信息检索。

Abstract: Retrieval-Augmented Generation (RAG) systems rely heavily on the retrieval
stage, particularly the coarse-ranking process. Existing coarse-ranking
optimization approaches often struggle to balance domain-specific knowledge
learning with query enhencement, resulting in suboptimal retrieval performance.
To address this challenge, we propose MoLER, a domain-aware RAG method that
uses MoL-Enhanced Reinforcement Learning to optimize retrieval. MoLER has a
two-stage pipeline: a continual pre-training (CPT) phase using a Mixture of
Losses (MoL) to balance domain-specific knowledge with general language
capabilities, and a reinforcement learning (RL) phase leveraging Group Relative
Policy Optimization (GRPO) to optimize query and passage generation for
maximizing document recall. A key innovation is our Multi-query Single-passage
Late Fusion (MSLF) strategy, which reduces computational overhead during RL
training while maintaining scalable inference via Multi-query Multi-passage
Late Fusion (MMLF). Extensive experiments on benchmark datasets show that MoLER
achieves state-of-the-art performance, significantly outperforming baseline
methods. MoLER bridges the knowledge gap in RAG systems, enabling robust and
scalable retrieval in specialized domains.

</details>


### [214] [IntrEx: A Dataset for Modeling Engagement in Educational Conversations](https://arxiv.org/abs/2509.06652)
*Xingwei Tan,Mahathi Parvatham,Chiara Gambi,Gabriele Pergola*

Main category: cs.CL

TL;DR: 该论文提出了一个全新数据集IntrEx，分析教师与二语学习者对话中“有趣性”的语言特征，验证了精调大模型可有效预测对话有趣度，并深入探讨哪些语言因素影响学习者的参与度。


<details>
  <summary>Details</summary>
Motivation: 虽然“有趣性”对于二语学习有重要推动作用，但目前教育对话中影响学习者兴趣的语言特征研究较少，因此需要创建相关数据集并系统分析。

Method: 作者在Teacher-Student Chatroom Corpus（TSCC）基础上建立了IntrEx数据集，加入序列级的有趣性及预期有趣性的标注。采用对比评分法，超过100名二语学习者参与标注，提升一致性。基于该数据集，作者对大模型（如7B/8B LLMs）进行了微调，并与GPT-4o等更大模型进行表现比对。同时分析了具体语言与认知特征对对话吸引力的影响。

Result: 微调于有趣性标注数据上的中型LLM（7B/8B）在预测人类有趣性判断方面超越了GPT-4o等更大的闭源模型，说明专业化数据集能强化模型在教育环境下的吸引力建模能力。此外，分析发现，具体性、易读性及反馈吸收等语言与认知特征都会显著影响学习者的参与度。

Conclusion: 建立了首个面向教育对话“有趣性”的大型公开数据集，为分析和提升对话吸引力提供了基础。研究结果表明：专用任务数据能提升模型性能，同时明确了影响教育对话吸引力的关键语言、认知因素，为智能教育系统发展带来新思路。

Abstract: Engagement and motivation are crucial for second-language acquisition, yet
maintaining learner interest in educational conversations remains a challenge.
While prior research has explored what makes educational texts interesting,
still little is known about the linguistic features that drive engagement in
conversations. To address this gap, we introduce IntrEx, the first large
dataset annotated for interestingness and expected interestingness in
teacher-student interactions. Built upon the Teacher-Student Chatroom Corpus
(TSCC), IntrEx extends prior work by incorporating sequence-level annotations,
allowing for the study of engagement beyond isolated turns to capture how
interest evolves over extended dialogues. We employ a rigorous annotation
process with over 100 second-language learners, using a comparison-based rating
approach inspired by reinforcement learning from human feedback (RLHF) to
improve agreement. We investigate whether large language models (LLMs) can
predict human interestingness judgments. We find that LLMs (7B/8B parameters)
fine-tuned on interestingness ratings outperform larger proprietary models like
GPT-4o, demonstrating the potential for specialised datasets to model
engagement in educational settings. Finally, we analyze how linguistic and
cognitive factors, such as concreteness, comprehensibility (readability), and
uptake, influence engagement in educational dialogues.

</details>


### [215] [ParCzech4Speech: A New Speech Corpus Derived from Czech Parliamentary Data](https://arxiv.org/abs/2509.06675)
*Vladislav Stankov,Matyáš Kopp,Ondřej Bojar*

Main category: cs.CL

TL;DR: 本文介绍了ParCzech4Speech 1.0，这是一个为语音建模任务处理过的捷克议会演讲语料库，数据量大、对齐质量高，提供多种灵活格式并开放获取。


<details>
  <summary>Details</summary>
Motivation: 此前ParCzech 3.0语音识别版存在数据提取量有限、音频与文本对齐准确性不足等问题。研究者希望建立更大、对齐更可靠的语料资源，以促进自动语音识别和语音合成等任务发展。

Method: 研究团队将捷克议会演讲的音频和官方转录文本结合，通过WhisperX和Wav2Vec 2.0对数据进行自动音频文本对齐。与上一版本相比，数据处理流程进行了改进，提升了数据量和对齐的可靠性。语料库以三种灵活格式提供：句子分割、完整未分割和原始对齐，满足不同研究需求。所有数据保留原始元数据，采用CC-BY许可开放。

Result: ParCzech4Speech 1.0实现了比之前数据集更大的规模（2,695小时）和更高质量的音频-文本对齐。提供三种格式，适用性广，供研究者在多个公开平台获取使用。

Conclusion: ParCzech4Speech 1.0为语音识别、合成等任务提供了高质量且多样化的捷克语大规模语音语料，开放共享将推动相关领域技术发展。

Abstract: We introduce ParCzech4Speech 1.0, a processed version of the ParCzech 4.0
corpus, targeted at speech modeling tasks with the largest variant containing
2,695 hours. We combined the sound recordings of the Czech parliamentary
speeches with the official transcripts. The recordings were processed with
WhisperX and Wav2Vec 2.0 to extract automated audio-text alignment. Our
processing pipeline improves upon the ParCzech 3.0 speech recognition version
by extracting more data with higher alignment reliability. The dataset is
offered in three flexible variants: (1) sentence-segmented for automatic speech
recognition and speech synthesis tasks with clean boundaries, (2) unsegmented
preserving original utterance flow across sentences, and (3) a raw-alignment
for further custom refinement for other possible tasks. All variants maintain
the original metadata and are released under a permissive CC-BY license. The
dataset is available in the LINDAT repository, with the sentence-segmented and
unsegmented variants additionally available on Hugging Face.

</details>


### [216] [Will Annotators Disagree? Identifying Subjectivity in Value-Laden Arguments](https://arxiv.org/abs/2509.06704)
*Amir Homayounirad,Enrico Liscio,Tong Wang,Catholijn M. Jonker,Luciano C. Siebert*

Main category: cs.CL

TL;DR: 本文研究如何识别和利用文本标注者之间的主观性分歧，提升对动机类论证文本的理解与处理。


<details>
  <summary>Details</summary>
Motivation: 在需要主观判断的任务中，简单地将多个标注者的意见合并为单一标签，会丢失有价值的分歧信息。尤其在识别人类价值观动机的论证识别任务中，把握主观性有助于理解多元观点。

Method: 作者探索了两种识别主观性的方法：（1）通过价值预测间接推断主观性；（2）直接识别主观性。同时，将对比损失（contrastive loss）与二元交叉熵损失（binary cross-entropy loss）结合，对主观性识别效果进行评估。

Result: 实验显示，直接识别主观性的方法在主观性论证检测任务上显著提升了模型性能。而将对比损失与二元交叉熵损失结合并未带来性能提升，反而减少了模型对每个标签主观性的依赖。

Conclusion: 所提出的直接主观性识别方法有助于发现可能被不同个体多样解读的文本，促进更细致和多元的标注流程，为复杂主观性任务的自动化注释提供了新思路。

Abstract: Aggregating multiple annotations into a single ground truth label may hide
valuable insights into annotator disagreement, particularly in tasks where
subjectivity plays a crucial role. In this work, we explore methods for
identifying subjectivity in recognizing the human values that motivate
arguments. We evaluate two main approaches: inferring subjectivity through
value prediction vs. directly identifying subjectivity. Our experiments show
that direct subjectivity identification significantly improves the model
performance of flagging subjective arguments. Furthermore, combining
contrastive loss with binary cross-entropy loss does not improve performance
but reduces the dependency on per-label subjectivity. Our proposed methods can
help identify arguments that individuals may interpret differently, fostering a
more nuanced annotation process.

</details>


### [217] [Anchoring Refusal Direction: Mitigating Safety Risks in Tuning via Projection Constraint](https://arxiv.org/abs/2509.06795)
*Yanrui Du,Fenglei Fan,Sendong Zhao,Jiawei Cao,Qika Lin,Kai He,Ting Liu,Bing Qin,Mengling Feng*

Main category: cs.CL

TL;DR: 本文提出了一种新方法（ProCon），通过约束大模型内部与拒绝恶意指令相关的向量方向漂移，从而在提升大模型指令微调能力的同时，有效缓解安全风险。


<details>
  <summary>Details</summary>
Motivation: 指令微调（IFT）提升了大模型多种能力，但会严重损害模型在面对恶意请求时拒绝的安全性。现有研究发现隐藏状态中存在与拒绝行为高度相关的“拒绝方向”（r-direction），但在实际训练过程中该方向会发生漂移，带来安全隐患。作者因此希望能解决IFT过程中的安全风险问题，同时保持性能提升。

Method: 作者提出ProCon方法，通过在训练损失函数中加入一个投影约束项，限制每个样本隐藏状态向r-direction的投影幅值。同时采用warm-up策略，在训练初期强化约束，并扩大数据分布增强信号，从而缓解r-direction的漂移现象。

Result: 实验表明，该方法在不同数据集、情景和多种大模型上，显著降低了IFT带来的安全风险，并有效保持甚至优于基线的任务性能。进一步分析显示，ProCon确实帮助稳定了r-direction。

Conclusion: ProCon方法能有效平衡安全性和性能，通过对大模型内部机制的可解释性探索，为后续模型安全研究提供了重要基础和新思路。

Abstract: Instruction Fine-Tuning (IFT) has been widely adopted as an effective
post-training strategy to enhance various abilities of Large Language Models
(LLMs). However, prior studies have shown that IFT can significantly compromise
LLMs' safety, particularly their ability to refuse malicious instructions,
raising significant concerns. Recent research into the internal mechanisms of
LLMs has identified the refusal direction (r-direction) in the hidden states,
which plays a pivotal role in governing refusal behavior. Building on this
insight, our study reveals that the r-direction tends to drift during training,
which we identify as one of the causes of the associated safety risks. To
mitigate such drift, our proposed ProCon method introduces a
projection-constrained loss term that regularizes the projection magnitude of
each training sample's hidden state onto the r-direction. Our initial analysis
shows that applying an appropriate constraint can effectively mitigate the
refusal direction drift and associated safety risks, but remains limited by
overall performance barriers. To overcome this barrier, informed by our
observation of early-stage sharp drift and a data-driven perspective, we
introduce a warm-up strategy that emphasizes early-stage strong constraints and
broaden the data distribution to strengthen constraint signals, leading to an
enhanced ProCon method. Experimental results under various datasets, scenarios,
and LLMs demonstrate that our method can significantly mitigate safety risks
posed by IFT while preserving task performance gains. Even compared with strong
baselines, our method consistently delivers superior overall performance.
Crucially, our analysis indicates that ProCon can contribute to stabilizing the
r-direction during training, while such an interpretability-driven exploration
of LLMs' internal mechanisms lays a solid foundation for future safety
research.

</details>


### [218] [MachineLearningLM: Continued Pretraining Language Models on Millions of Synthetic Tabular Prediction Tasks Scales In-Context ML](https://arxiv.org/abs/2509.06806)
*Haoyu Dong,Pengkun Zhang,Mingzhe Lu,Yanzhen Shen,Guolin Ke*

Main category: cs.CL

TL;DR: 本文提出了MachineLearningLM，一种通过继续预训练，使大语言模型（LLM）具备强大机器学习任务场景下的类“多样本”推理能力，同时不损害其通用知识与推理能力的新框架。


<details>
  <summary>Details</summary>
Motivation: 尽管现有LLM具备丰富知识和推理能力，但在纯“上下文学习”（ICL）场景下很难通过增加演示样本数量来提升在常规机器学习任务中的表现。作者致力于让LLM更有效地利用多样本演示，从而提升其在该类任务（如表格分类、跨领域推断等）中的表现。

Method: 作者提出一种便携的连续预训练框架：1）通过数百万结构因果模型（SCMs）合成机器学习任务，任务样本数扩展到1024；2）采用随机森林模型为教师，蒸馏树模型的决策策略到LLM中，加强在数值建模上的鲁棒性；3）采用Token高效化的prompt，提升单个上下文窗口可容纳样本数（3~6倍），并支持批推理带来高吞吐率（提升50倍）。实验基础模型为Qwen-2.5-7B-Instruct+LoRA（rank8）。

Result: MachineLearningLM在金融、物理、生物、医疗等领域的表格分类任务中，对比强基线（如GPT-5-mini）平均提升约15%；模型准确率随in-context样本数从8递增到1024时单调提升；无需专用任务训练即可在百样本范围内达到与随机森林相当的精度；MMLU（知识与推理基准）测试达到75.4%。

Conclusion: 通过该预训练方法，LLM获得了比以往更强的多样本in-context机器学习能力，而原有的聊天、推理、知识表达能力未明显损失，为LLM在实际机器学习任务中应用拓展了边界。

Abstract: Large language models (LLMs) possess broad world knowledge and strong
general-purpose reasoning ability, yet they struggle to learn from many
in-context examples on standard machine learning (ML) tasks, that is, to
leverage many-shot demonstrations purely via in-context learning (ICL) without
gradient descent. We introduce MachineLearningLM, a portable
continued-pretraining framework that equips a general-purpose LLM with robust
in-context ML capability while preserving its general knowledge and reasoning
for broader chat workflows.
  Our pretraining procedure synthesizes ML tasks from millions of structural
causal models (SCMs), spanning shot counts up to 1,024. We begin with a
random-forest teacher, distilling tree-based decision strategies into the LLM
to strengthen robustness in numerical modeling. All tasks are serialized with a
token-efficient prompt, enabling 3x to 6x more examples per context window and
delivering up to 50x amortized throughput via batch inference.
  Despite a modest setup (Qwen-2.5-7B-Instruct with LoRA rank 8),
MachineLearningLM outperforms strong LLM baselines (e.g., GPT-5-mini) by an
average of about 15% on out-of-distribution tabular classification across
finance, physics, biology, and healthcare domains. It exhibits a striking
many-shot scaling law: accuracy increases monotonically as in-context
demonstrations grow from 8 to 1,024. Without any task-specific training, it
attains random-forest-level accuracy across hundreds of shots. General chat
capabilities, including knowledge and reasoning, are preserved: it achieves
75.4% on MMLU.

</details>


### [219] [MoGU V2: Toward a Higher Pareto Frontier Between Model Usability and Security](https://arxiv.org/abs/2509.06807)
*Yanrui Du,Fenglei Fan,Sendong Zhao,Jiawei Cao,Ting Liu,Bing Qin*

Main category: cs.CL

TL;DR: 本文提出了一种新框架MoGU及其改进版MoGU_v2，用于解决大语言模型（LLMs）安全性与可用性间的权衡，实现两者的兼顾。新的方法在多种实际应用场景下有效提升了模型的安全和实用性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在实际生活中的广泛应用，其安全性成为关键挑战。现有加强安全性的方法往往降低实际可用性，如何在安全与可用性间进步而非权衡，成为该领域的痛点。

Method: 提出MoGU框架，利用intra-layer router动态分配安全优先与可用性优先模型的权重，初版存在参数冗余与性能瓶颈。改进版MoGU_v2更紧密结合路由与隐藏状态，仅在编码高可区分安全特征的层插入路由器，并启用骨干模块的双向适配优化，提升效率和效果。

Result: MoGU_v2在多类主流与边缘场景的大语言模型中展现出广泛适应性和持续性能提升。即使在当前模型常见的Instruction Fine-tuning风险下，也能通过简单的数据混合策略恢复安全性且不损失任务表现。

Conclusion: MoGU_v2为现实场景中大语言模型的安全问题提供了强大且易部署的解决方案，可兼顾安全性与实用性，具备推广应用的潜力。

Abstract: As Large Language Models (LLMs) increasingly permeate human life, their
security has emerged as a critical concern, particularly their ability to
maintain harmless responses to malicious instructions. Although extensive
methods have improved LLMs' security, they often lead to conservative,
rejection-oriented responses that compromise practical usability. This presents
a key challenge: how to advance the Pareto frontier between LLMs' usability and
security, rather than necessitate a trade-off between them. To address this, we
propose the MoGU framework, in which the intra-layer router dynamically
allocates weights by sensing hidden states, thereby balancing the contributions
of security-optimized and usability-optimized variants. Despite its initial
potential, the MoGU framework faces limitations such as parameter redundancy
and performance bottlenecks. To overcome these, we further propose an improved
MoGU_v2 framework that establishes a tighter coupling between the routers and
hidden states. In MoGU_v2, routers are embedded only in layers encoding highly
classifiable security features, and backbone modules are activated during
router optimization to enable bidirectional adaptation. MoGU_V2 exhibits strong
adaptability and stable improvements across various series of LLMs, including
mainstream LLMs serving as brains in various applications, on-device LLMs
optimized for resource-constrained scenarios, and reasoning LLMs tailored for
user interpretability. Meanwhile, even facing risks introduced by Instruction
Fine-tuning, MoGU_v2 can easily restore security without compromising the task
performance gains via a simple data-mix strategy. These comprehensive
improvements highlight MoGU_V2 as a robust and versatile solution for
mitigating security risks in real-world applications.

</details>


### [220] [Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the TPTP Ecosystem](https://arxiv.org/abs/2509.06809)
*Valentin Quesnel,Damien Sileo*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的数据生成引擎，利用自动定理证明（ATP）工具，从TPTP公理库中自动生成大规模、逻辑上无误的数学推理数据集，以支持大语言模型（LLMs）在数学推理领域的发展。


<details>
  <summary>Details</summary>
Motivation: 高质量、逻辑严密的数据稀缺是提升大语言模型数学推理能力的核心瓶颈。现有方法依赖LLM自动生成或复杂的定理证明助手语法，存在错误率高和构建难度大等问题。因此，作者希望开发一种可扩展且保证数据正确性的数据生成框架。

Method: 提出利用E-prover自动定理证明工具，对大规模TPTP公理库进行饱和推理，自动生成逻辑正确的定理，并经过筛选、任务拆分，得到涵盖不同难度和不同任务（包含蕴含验证、前提选择和证明重构）的大型数据集。整个流程无LLM介入，从而消除事实性错误。

Result: 作者零样本测试现有最强大语言模型，发现其在需要深度结构化推理的任务上表现大幅下滑。此外，所提出的框架不仅能有效测量模型弱点，还能为训练提供大规模符号数据源。

Conclusion: 作者提出的符号数据生成框架可扩展、无逻辑错误，为大模型的数学推理研究和提升提供了宝贵资源。有助于发现并缩小LLM在结构性推理上的能力差距，相关代码和数据集已开源，便于社区使用和推动研究。

Abstract: The scarcity of high-quality, logically sound data is a critical bottleneck
for advancing the mathematical reasoning of Large Language Models (LLMs). Our
work confronts this challenge by turning decades of automated theorem proving
research into a scalable data engine. Rather than relying on error-prone LLMs
or complex proof-assistant syntax like Lean and Isabelle, our framework
leverages E-prover's saturation capabilities on the vast TPTP axiom library to
derive a massive, guaranteed-valid corpus of theorems. Our pipeline is
principled and simple: saturate axioms, filter for "interesting" theorems, and
generate tasks. With no LLMs in the loop, we eliminate factual errors by
construction. This purely symbolic data is then transformed into three
difficulty-controlled challenges: entailment verification, premise selection,
and proof reconstruction. Our zero-shot experiments on frontier models reveal a
clear weakness: performance collapses on tasks requiring deep, structural
reasoning. Our framework provides both the diagnostic tool to measure this gap
and a scalable source of symbolic training data to address it. We make the code
and data publicly available.
  https://github.com/sileod/reasoning_core
https://hf.co/datasets/reasoning-core/rc1

</details>


### [221] [A Comparative Benchmark of Large Language Models for Labelling Wind Turbine Maintenance Logs](https://arxiv.org/abs/2509.06813)
*Max Malyi,Jonathan Shek,Alasdair McDonald,Andre Biscaya*

Main category: cs.CL

TL;DR: 本文提出了一个开源基准框架，用于评估大语言模型（LLM）在风机运维日志文本分类任务中的表现，通过系统测试多种模型，展现其在自动化运维数据处理中的能力与局限。


<details>
  <summary>Details</summary>
Motivation: 风力发电运维日志多为非结构化自由文本，这为自动化分析带来了挑战。提升此类数据的分析效率与准确性，有助于降低风能发电的成本（LCOE）并提升维护管理能力。

Method: 作者开发并开源了一个用于对LLM在风机运维日志分类中的表现进行基准测试的框架，涵盖主流专有与开源模型，综合比较模型在可靠性、效率和置信度校准等方面的差异。

Result: 实验清晰展现了不同模型的性能层级，部分模型在基准标准对齐和置信度校准方面表现突出。分类准确度和模型一致性受任务本身语义模糊度影响较大：对于客观部件识别表现较好，但对解释性维护行为分类一致性较差。

Conclusion: 当前没有模型能完全准确地自动化处理此类复杂语义任务，且不同模型置信度校准差异大。因此最优应用场景应为“人机协同”，通过LLM助力专家数据标注，加速标准化，提高运维数据质量和后续分析的可靠性。

Abstract: Effective Operation and Maintenance (O&M) is critical to reducing the
Levelised Cost of Energy (LCOE) from wind power, yet the unstructured,
free-text nature of turbine maintenance logs presents a significant barrier to
automated analysis. Our paper addresses this by presenting a novel and
reproducible framework for benchmarking Large Language Models (LLMs) on the
task of classifying these complex industrial records. To promote transparency
and encourage further research, this framework has been made publicly available
as an open-source tool. We systematically evaluate a diverse suite of
state-of-the-art proprietary and open-source LLMs, providing a foundational
assessment of their trade-offs in reliability, operational efficiency, and
model calibration. Our results quantify a clear performance hierarchy,
identifying top models that exhibit high alignment with a benchmark standard
and trustworthy, well-calibrated confidence scores. We also demonstrate that
classification performance is highly dependent on the task's semantic
ambiguity, with all models showing higher consensus on objective component
identification than on interpretive maintenance actions. Given that no model
achieves perfect accuracy and that calibration varies dramatically, we conclude
that the most effective and responsible near-term application is a
Human-in-the-Loop system, where LLMs act as a powerful assistant to accelerate
and standardise data labelling for human experts, thereby enhancing O&M data
quality and downstream reliability analysis.

</details>


### [222] [COMPACT: Common-token Optimized Model Pruning Across Channels and Tokens](https://arxiv.org/abs/2509.06836)
*Eugene Kwek,Wenpeng Yin*

Main category: cs.CL

TL;DR: 本文提出了一种新的剪枝方法COMPACT，用于在保持Transformer标准结构的前提下高效减少大语言模型的内存、延迟和成本，同时保持甚至提升任务表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型部署在边缘设备和大规模场景时，对内存、推理延迟以及运行成本有较高的效率需求。现有剪枝方法往往破坏了Transformer架构或导致明显精度损失，需要新的方案来兼顾高效性与易用性。

Method: 作者提出COMPACT方法，主要包括：(1) 修剪稀有词汇以缩减embedding和unembedding矩阵规模；(2) 基于通用token加权激活的方式，针对FFN层的中间通道进行剪枝，使剪枝后的重要性分布与实际token分布对齐。该方法兼具深度剪枝和宽度剪枝优点，无需定制推理代码，支持灵活剪枝分配，并可在无需重新训练的情况下快速生效。

Result: COMPACT在Qwen、LLaMA和Gemma等多种模型（从0.5B到70B参数规模）上进行了实验，结果表明，在相同或更高剪枝率下，任务性能达到甚至超过现有方法，并带来显著的参数、GPU内存和端到端延迟下降。

Conclusion: COMPACT为大语言模型剪枝提供了一种高效、易用且适用多场景的解决方案，有望推动其在各类资源受限或大规模推理场景的普及应用。

Abstract: Making LLMs more efficient in memory, latency, and serving cost is crucial
for edge deployment, interactive applications, and sustainable inference at
scale. Pruning is a key technique toward this goal. However, prior pruning
methods are limited: width pruning often breaks the standard transformer layout
or requires custom inference code, while depth pruning removes entire layers
and can cause abrupt accuracy drops. In this work, we propose COMPACT, which
jointly (i) prunes rare vocabulary to shrink embedding/unembedding and (ii)
prunes FFN intermediate channels using common-token-weighted activations,
aligning importance with the post-pruning token distribution. COMPACT enjoys
merits of both depth and width pruning, such as: deployment-friendliness (keeps
a standard transformer architecture), scale-adaptivity (trade off vocab vs. FFN
pruning), training-free operation with competitive pruning time, and strong
memory savings alongside throughput gains. Experiments across Qwen, LLaMA, and
Gemma families (0.5B-70B) show state-of-the-art downstream task performance at
similar or higher pruning ratios, with substantial reductions in parameters,
GPU memory, and end-to-end latency.

</details>


### [223] [EPT Benchmark: Evaluation of Persian Trustworthiness in Large Language Models](https://arxiv.org/abs/2509.06838)
*Mohammad Reza Mirbagheri,Mohammad Mahdi Mirkamali,Zahra Motoshaker Arani,Ali Javeri,Amir Mahdi Sadeghzadeh,Rasool Jalili*

Main category: cs.CL

TL;DR: 本文提出一种针对波斯语语言模型（LLM）可信度的评估指标EPT，覆盖真实性、安全性、公平性、鲁棒性、隐私和伦理等六个核心维度。通过对多个主流模型的人机评测，发现安全性方面存在明显短板，强调需加强该方向的研究。


<details>
  <summary>Details</summary>
Motivation: LLMs在多个语言任务上表现卓越，逐渐成为现代AI的重要基础。但如何确保其在准确性及符号伦理、文化和社会价值层面上的可信度，仍是重大挑战。特别是在波斯语这种文化背景下，缺乏专门的评价指标与基准，限制了对负责任AI系统的推进。

Method: 作者提出了EPT评估指标，设计了反映波斯语伦理文化的基准，并构建标注数据集。对ChatGPT、Claude、DeepSeek、Gemini等主流大模型，进行了基于LLM自动评测和人工评测的双重测试。

Result: 测试显示，各大模型在“安全性”维度普遍表现不足。研究还详细比较了不同模型在其他维度的表现及其与波斯伦理文化价值的契合度，由此揭示出主流LLMs存在的可信度不足和文化适配问题。

Conclusion: 确保LLMs的可信度，尤其在安全性方面，需要更多研究和改进。提出的EPT基准有助于推动波斯语AI系统的责任化发展，同时为主流大模型的文化适配和伦理合规提供了重要参考。

Abstract: Large Language Models (LLMs), trained on extensive datasets using advanced
deep learning architectures, have demonstrated remarkable performance across a
wide range of language tasks, becoming a cornerstone of modern AI technologies.
However, ensuring their trustworthiness remains a critical challenge, as
reliability is essential not only for accurate performance but also for
upholding ethical, cultural, and social values. Careful alignment of training
data and culturally grounded evaluation criteria are vital for developing
responsible AI systems. In this study, we introduce the EPT (Evaluation of
Persian Trustworthiness) metric, a culturally informed benchmark specifically
designed to assess the trustworthiness of LLMs across six key aspects:
truthfulness, safety, fairness, robustness, privacy, and ethical alignment. We
curated a labeled dataset and evaluated the performance of several leading
models - including ChatGPT, Claude, DeepSeek, Gemini, Grok, LLaMA, Mistral, and
Qwen - using both automated LLM-based and human assessments. Our results reveal
significant deficiencies in the safety dimension, underscoring the urgent need
for focused attention on this critical aspect of model behavior. Furthermore,
our findings offer valuable insights into the alignment of these models with
Persian ethical-cultural values and highlight critical gaps and opportunities
for advancing trustworthy and culturally responsible AI. The dataset is
publicly available at: https://github.com/Rezamirbagheri110/EPT-Benchmark.

</details>


### [224] [The Majority is not always right: RL training for solution aggregation](https://arxiv.org/abs/2509.06870)
*Wenting Zhao,Pranjal Aggarwal,Swarnadeep Saha,Asli Celikyilmaz,Jason Weston,Ilia Kulikov*

Main category: cs.CL

TL;DR: 本文提出了一种新的大模型解答结果聚合方法——AggLM，通过学习型聚合模型，而非传统的简单投票或排序，实现多答案的高效整合。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在推理类任务上，通过生成多个解答和聚合，提升准确率。但传统聚合手段（如多数投票、奖励模型排序）效果有限，尤其在少数正确答案被多数错误答案淹没时。如何更智能、有效地聚合多解答案，是提升模型表现的关键。

Method: 作者设计了AggLM模型，将答案聚合作为一种推理能力来显式训练。具体做法是：给定多个候选答案，训练一个聚合器模型，利用可验证的奖励信号，通过强化学习融合、筛选并输出最终正确答案。训练中特别平衡了难易样本，使模型既能识别少数但正确的答案，也不会忽视简单场景下的主流正确答案。

Result: 与传统基于规则和奖励模型的投票基线相比，AggLM在多个基准任务上表现更佳。不仅如此，它还能很好地泛化到其他甚至更强大模型产生的答案，并且在需要更少计算量（token消耗）的前提下超越丰解数量多数投票策略。

Conclusion: 学习型答案聚合（AggLM）能够系统性提升大模型在高阶推理任务的表现，尤其在结果中少数正确答案与多数量不完全正确答案并存时更具优势。该方法计算效率高、泛化能力好，有较强应用前景。

Abstract: Scaling up test-time compute, by generating multiple independent solutions
and selecting or aggregating among them, has become a central paradigm for
improving large language models (LLMs) on challenging reasoning tasks. While
most prior work relies on simple majority voting or reward model ranking to
aggregate solutions, these approaches may only yield limited benefits. In this
work, we propose to learn aggregation as an explicit reasoning skill: given a
set of candidate solutions, we train an aggregator model to review, reconcile,
and synthesize a final, correct answer using reinforcement learning from
verifiable rewards. A key ingredient is careful balancing of easy and hard
training examples, allowing the model to learn both to recover
minority-but-correct answers as well as easy majority-correct answers.
Empirically, we find our method, AggLM, outperforms both strong rule-based and
reward-model baselines, across multiple benchmarks. Furthermore, it generalizes
effectively to solutions from differing models, including stronger ones than
contained in the training data, all while requiring substantially fewer tokens
than majority voting with larger numbers of solutions.

</details>


### [225] [UNH at CheckThat! 2025: Fine-tuning Vs Prompting in Claim Extraction](https://arxiv.org/abs/2509.06883)
*Joe Wilder,Nikhil Kadapala,Benji Xu,Mohammed Alsaadi,Aiden Parsons,Mitchell Rogers,Palash Agarwal,Adam Hassick,Laura Dietz*

Main category: cs.CL

TL;DR: 本文旨在通过不同的大模型提示和微调方法，从社交媒体文本中抽取值得核查的主张。


<details>
  <summary>Details</summary>
Motivation: 社交媒体信息的真实性问题日益突出，自动识别和抽取需要核查的主张可为事实核查提供重要支持，因此作者探索了提升该任务效果的多种大模型方法。

Method: 作者尝试了多种提示与上下文学习方式，包括少样本提示（few-shot prompting）和对不同大语言模型（LLM，包括FLAN-T5）进行微调，比较这些方法在抽取值得核查主张中的表现。

Result: 微调的FLAN-T5模型在METEOR评测指标下表现最佳，但作者也发现有些方法虽然METEOR得分低，但在实际上可抽取出更高质量的主张。

Conclusion: 不同方法各有优劣，高分的自动评测指标与实际主张质量未必完全一致，提示将主观或多维评测指标纳入未来研究的重要性。

Abstract: We participate in CheckThat! Task 2 English and explore various methods of
prompting and in-context learning, including few-shot prompting and fine-tuning
with different LLM families, with the goal of extracting check-worthy claims
from social media passages. Our best METEOR score is achieved by fine-tuning a
FLAN-T5 model. However, we observe that higher-quality claims can sometimes be
extracted using other methods, even when their METEOR scores are lower.

</details>


### [226] [mmBERT: A Modern Multilingual Encoder with Annealed Language Learning](https://arxiv.org/abs/2509.06888)
*Marc Marone,Orion Weller,William Fleshman,Eugene Yang,Dawn Lawrie,Benjamin Van Durme*

Main category: cs.CL

TL;DR: 本文提出了一种新的多语言编码器模型mmBERT，支持1800多种语言，尤其提升了低资源语言的任务表现。


<details>
  <summary>Details</summary>
Motivation: 当前编码器模型在多语言学习，尤其是低资源语言方面研究不足。研究者希望突破现有多语言模型在低资源语言覆盖与效果上的限制。

Method: 模型预训练涉及三万亿词符，采用了新颖的逆掩码率调度和逆温度采样策略，并在训练后期特别加入1700多种低资源语言以增强模型表现。

Result: 即使只在训练后期加入低资源语言，mmBERT在分类性能上可与OpenAI o3和Google Gemini 2.5 Pro媲美，在高低资源语言的分类与检索任务上都优于上一代模型。

Conclusion: mmBERT通过创新的数据采样和调度方法，显著提升了多语言模型，特别是低资源语言的任务表现。

Abstract: Encoder-only languages models are frequently used for a variety of standard
machine learning tasks, including classification and retrieval. However, there
has been a lack of recent research for encoder models, especially with respect
to multilingual models. We introduce mmBERT, an encoder-only language model
pretrained on 3T tokens of multilingual text in over 1800 languages. To build
mmBERT we introduce several novel elements, including an inverse mask ratio
schedule and an inverse temperature sampling ratio. We add over 1700
low-resource languages to the data mix only during the decay phase, showing
that it boosts performance dramatically and maximizes the gains from the
relatively small amount of training data. Despite only including these
low-resource languages in the short decay phase we achieve similar
classification performance to models like OpenAI's o3 and Google's Gemini 2.5
Pro. Overall, we show that mmBERT significantly outperforms the previous
generation of models on classification and retrieval tasks -- on both high and
low-resource languages.

</details>


### [227] [Proof-Carrying Numbers (PCN): A Protocol for Trustworthy Numeric Answers from LLMs via Claim Verification](https://arxiv.org/abs/2509.06902)
*Aivin V. Solatorio*

Main category: cs.CL

TL;DR: 本文提出了一种称为Proof-Carrying Numbers（PCN）的协议，用于从展示层面保证大语言模型生成数字信息的真实性，通过机械验证有效地减少数字幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在生成涉及数值的数据时，经常会出现数字与真实数据不符的“数字幻觉”现象，现有方案仅提升透明度，无法确保数字的真实可靠性。因而迫切需要一种机制，能在不依赖语言模型本身的前提下，保证数值信息的正确性。

Method: 提出PCN协议，将数值表达绑定至结构化声明，所有数字以“声明绑定令牌”形式输出，并由验证器根据政策（如精确相等、四舍五入等）逐一检查。该验证器部署于渲染端而非模型端，区分已验证和未验证数字。论文还对PCN的正确性、完备性、可扩展性、安全性做了形式化证明。

Result: PCN可无缝集成到现有系统，在保障准确性的同时增加系统的安全与透明度。模型不可伪造已验证标记，并且未验证数字在展示时自动带有不确定性提示，广泛适用于对数值极其敏感的场景。

Conclusion: PCN为大模型生成的数值提供了低成本、高效且模型无关的验证手段，仅经验证的数字才被信任，实现了“信任需要证明”的简明合同，有效减少和防止数字幻觉现象。

Abstract: Large Language Models (LLMs) as stochastic systems may generate numbers that
deviate from available data, a failure known as \emph{numeric hallucination}.
Existing safeguards -- retrieval-augmented generation, citations, and
uncertainty estimation -- improve transparency but cannot guarantee fidelity:
fabricated or misquoted values may still be displayed as if correct. We propose
\textbf{Proof-Carrying Numbers (PCN)}, a presentation-layer protocol that
enforces numeric fidelity through mechanical verification. Under PCN, numeric
spans are emitted as \emph{claim-bound tokens} tied to structured claims, and a
verifier checks each token under a declared policy (e.g., exact equality,
rounding, aliases, or tolerance with qualifiers). Crucially, PCN places
verification in the \emph{renderer}, not the model: only claim-checked numbers
are marked as verified, and all others default to unverified. This separation
prevents spoofing and guarantees fail-closed behavior. We formalize PCN and
prove soundness, completeness under honest tokens, fail-closed behavior, and
monotonicity under policy refinement. PCN is lightweight and model-agnostic,
integrates seamlessly into existing applications, and can be extended with
cryptographic commitments. By enforcing verification as a mandatory step before
display, PCN establishes a simple contract for numerically sensitive settings:
\emph{trust is earned only by proof}, while the absence of a mark communicates
uncertainty.

</details>


### [228] [Beyond Two-Stage Training: Cooperative SFT and RL for LLM Reasoning](https://arxiv.org/abs/2509.06948)
*Liang Chen,Xueting Han,Li Shen,Jing Bai,Kam-Fai Wong*

Main category: cs.CL

TL;DR: 本文提出了一种基于双层优化的新方法，实现大语言模型推理能力的高效提升，在五项推理基准测试中表现优越。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）可以增强大语言模型的推理能力，但由于RL的试错本质，训练效率低。当前常用的“监督微调+RL”两阶段方法相互独立，效果受限，缺乏两者间的协同优化。

Method: 该方法通过双层优化，将监督微调（SFT）目标依赖于最优RL策略，使SFT具备引导RL优化过程的元学习能力。训练过程中，底层执行RL更新并接受SFT监督，上层则显式最大化两者协同训练带来的性能增益。

Result: 在五个推理任务基准上，提出方法在效果和效率上均优于现有基线方法。

Conclusion: 联合SFT与RL的协同优化机制可显著提升大语言模型推理任务的表现，突破传统两阶段训练流程的瓶颈。

Abstract: Reinforcement learning (RL) has proven effective in incentivizing the
reasoning abilities of large language models (LLMs), but suffers from severe
efficiency challenges due to its trial-and-error nature. While the common
practice employs supervised fine-tuning (SFT) as a warm-up stage for RL, this
decoupled two-stage approach limits interaction between SFT and RL, thereby
constraining overall effectiveness. This study introduces a novel method for
learning reasoning models that employs bilevel optimization to facilitate
better cooperation between these training paradigms. By conditioning the SFT
objective on the optimal RL policy, our approach enables SFT to meta-learn how
to guide RL's optimization process. During training, the lower level performs
RL updates while simultaneously receiving SFT supervision, and the upper level
explicitly maximizes the cooperative gain-the performance advantage of joint
SFT-RL training over RL alone. Empirical evaluations on five reasoning
benchmarks demonstrate that our method consistently outperforms baselines and
achieves a better balance between effectiveness and efficiency.

</details>


### [229] [Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models](https://arxiv.org/abs/2509.06949)
*Yinjie Wang,Ling Yang,Bowen Li,Ye Tian,Ke Shen,Mengdi Wang*

Main category: cs.CL

TL;DR: 提出了TraceRL框架，将增强型轨迹感知强化学习用于后训练扩散语言模型，使其适用于多种架构，并提升复杂数学与编程任务的推理能力。推导出一系列SOTA扩散模型TraDo，并开源相关框架。


<details>
  <summary>Details</summary>
Motivation: 提升扩散语言模型在复杂数学、编程等推理任务上的表现，并提高采样灵活性及可扩展性，推动相关技术及开放源码生态。

Method: 设计了TraceRL，一个结合优选推理轨迹的轨迹感知强化学习方法，并引入了扩散型价值模型以提升训练稳定性。支持多模型架构，兼容块特定模型扩展到更大结构。此外，采用课程学习训练长链路思维扩散语言模型。

Result: 推导出TraDo系列新模型。TraDo-4B-Instruct 在复杂推理任务上全面优于7B量级现有AR模型。TraDo-8B-Instruct 在数学推理基准上分别较Qwen2.5-7B-Instruct和Llama3.1-8B-Instruct有6.1%和51.3%的相对准确率提升。长链路思维模型在MATH500上相对Qwen2.5-7B-Instruct提升18.1%。

Conclusion: TraceRL显著提升了扩散语言模型在推理等任务的表现，具有较好的架构兼容性与实际应用潜力。研究成果和工具已开源，以加速相关领域研究和实际场景落地。

Abstract: We propose TraceRL, a trajectory-aware reinforcement learning framework for
diffusion language models (DLMs) that incorporates preferred inference
trajectory into post-training, and is applicable across different
architectures. Equipped with a diffusion-based value model that enhances
training stability, we demonstrate improved reasoning performance on complex
math and coding tasks. Besides, it can also be applied to adapt block-specific
models to larger blocks, which improves sampling flexibility. Employing
TraceRL, we derive a series of state-of-the-art diffusion language models,
namely TraDo. Although smaller than 7B-scale AR models, TraDo-4B-Instruct still
consistently outperforms them across complex math reasoning tasks.
TraDo-8B-Instruct achieves relative accuracy improvements of 6.1% over
Qwen2.5-7B-Instruct and 51.3% over Llama3.1-8B-Instruct on mathematical
reasoning benchmarks. Through curriculum learning, we also derive the first
long-CoT DLM, outperforming Qwen2.5-7B-Instruct on MATH500 with an 18.1%
relative accuracy gain. To facilitate reproducible research and practical
applications, we release a comprehensive open-source framework for building,
training, and deploying diffusion LLMs across diverse architectures. The
framework integrates accelerated KV-cache techniques and inference engines for
both inference and reinforcement learning, and includes implementations of
various supervised fine-tuning and RL methods for mathematics, coding, and
general tasks. Code and Models: https://github.com/Gen-Verse/dLLM-RL

</details>


### [230] [On the Same Wavelength? Evaluating Pragmatic Reasoning in Language Models across Broad Concepts](https://arxiv.org/abs/2509.06952)
*Linlu Qiu,Cedegao E. Zhang,Joshua B. Tenenbaum,Yoon Kim,Roger P. Levy*

Main category: cs.CL

TL;DR: 本文提出一种新的评估框架，用于检测语言模型（LMs）在语用推理方面的能力，基于Wavelength交流游戏，并引入贝叶斯语用推理方法（RSA）提升LM表现。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型日益广泛用于对话系统，了解其在实际交流上下文中的语用推理能力（即对交流目标和规范的推理）变得越来越重要。

Method: 参考Wavelength交流游戏设计测试框架，研究语言模型在理解和生成任务中的表现，分别采用直接、Chain-of-Thought（CoT）提示。同时，探讨将贝叶斯语用推理方法（RSA）融入语言模型推断过程对能力的提升。

Result: 最先进大型语言模型在语言理解任务上表现接近人类，即使无需CoT或RSA也有很高准确度和与人类判断的高度相关。在语言生成任务中，CoT优于直接提示，RSA进一步显著提升两者效果。

Conclusion: 该研究揭示了当前LM在语用推理方面的优劣势，展示了RSA方法改善模型语用能力的潜力，为进一步探索语言模型和人类在概念表征、理解和社会推理上的研究方向提供了基础。

Abstract: Language use is shaped by pragmatics -- i.e., reasoning about communicative
goals and norms in context. As language models (LMs) are increasingly used as
conversational agents, it becomes ever more important to understand their
pragmatic reasoning abilities. We propose an evaluation framework derived from
Wavelength, a popular communication game where a speaker and a listener
communicate about a broad range of concepts in a granular manner. We study a
range of LMs on both language comprehension and language production using
direct and Chain-of-Thought (CoT) prompting, and further explore a Rational
Speech Act (RSA) approach to incorporating Bayesian pragmatic reasoning into LM
inference. We find that state-of-the-art LMs, but not smaller ones, achieve
strong performance on language comprehension, obtaining similar-to-human
accuracy and exhibiting high correlations with human judgments even without CoT
prompting or RSA. On language production, CoT can outperform direct prompting,
and using RSA provides significant improvements over both approaches. Our study
helps identify the strengths and limitations in LMs' pragmatic reasoning
abilities and demonstrates the potential for improving them with RSA, opening
up future avenues for understanding conceptual representation, language
understanding, and social reasoning in LMs and humans.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [231] [ManipDreamer3D : Synthesizing Plausible Robotic Manipulation Video with Occupancy-aware 3D Trajectory](https://arxiv.org/abs/2509.05314)
*Ying Li,Xiaobao Wei,Xiaowei Chi,Yuming Li,Zhongyu Zhao,Hao Wang,Ningning Ma,Ming Lu,Shanghang Zhang*

Main category: cs.RO

TL;DR: 本论文提出了ManipDreamer3D框架，能够根据输入图片和文本指令生成具有三维意识的机器人操作视频，有效解决了基于2D轨迹生成视频时的空间模糊问题。


<details>
  <summary>Details</summary>
Motivation: 目前机器人操作领域数据稀缺，且现有基于扩散模型的方法主要依赖2D轨迹，难以准确还原三维空间动作细节，因此亟需能生成三维合理动作视频的新方法。

Method: 提出ManipDreamer3D框架，融合三维轨迹规划与三维占用图重建。具体做法为：先从输入图片重建三维占用图，再规划优化3D机械臂轨迹（规避碰撞、优化路径），最后采用轨迹到视频的扩散模型生成符合3D运动的机器人操作视频。

Result: 本方法生成的视频在三维合理性和视觉质量上优于现有方法，且明显减少了对人工干预的需求。

Conclusion: ManipDreamer3D可以自动生成具有合理三维运动的机器人操作视频，为机器人操作任务提供了更高效的数据生成新途径。

Abstract: Data scarcity continues to be a major challenge in the field of robotic
manipulation. Although diffusion models provide a promising solution for
generating robotic manipulation videos, existing methods largely depend on 2D
trajectories, which inherently face issues with 3D spatial ambiguity. In this
work, we present a novel framework named ManipDreamer3D for generating
plausible 3D-aware robotic manipulation videos from the input image and the
text instruction. Our method combines 3D trajectory planning with a
reconstructed 3D occupancy map created from a third-person perspective, along
with a novel trajectory-to-video diffusion model. Specifically, ManipDreamer3D
first reconstructs the 3D occupancy representation from the input image and
then computes an optimized 3D end-effector trajectory, minimizing path length
while avoiding collisions. Next, we employ a latent editing technique to create
video sequences from the initial image latent and the optimized 3D trajectory.
This process conditions our specially trained trajectory-to-video diffusion
model to produce robotic pick-and-place videos. Our method generates robotic
videos with autonomously planned plausible 3D trajectories, significantly
reducing human intervention requirements. Experimental results demonstrate
superior visual quality compared to existing methods.

</details>


### [232] [Evaluation of Large Language Models for Anomaly Detection in Autonomous Vehicles](https://arxiv.org/abs/2509.05315)
*Petros Loukas,David Bassir,Savvas Chatzichristofis,Angelos Amanatiadis*

Main category: cs.RO

TL;DR: 本文评估了大语言模型（LLMs）在自动驾驶汽车实际极端场景中的应用潜力，主要关注其作为感知和规划系统补充模块的表现。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在许多领域表现出强大能力，研究界也开始探索其在自动驾驶场景中的作用。然而，现有评估多局限于合成或手动驾驶数据集，缺乏实地极端案例和感知/规划性能真相。因此，迫切需评估LLMs在实际自动驾驶失败场景中的应用效果。

Method: 提出一种结合开放词汇目标检测器、提示工程和大语言模型上下文推理的架构，用以应对自动驾驶车辆失败的真实极端案例。使用多种先进模型，针对这些场景进行评测。

Result: 对多种SOTA模型在实际极端情况中进行了性能评估，并进行了定性对比，分析了各自优劣。讨论了LLMs在异常检测中的潜在作用。

Conclusion: LLMs在实际极端场景中表现出一定的异常检测能力，可作为自动驾驶系统的补充检测模块。然而，其性能在不同场景下有差异，需要进一步优化和研究。

Abstract: The rapid evolution of large language models (LLMs) has pushed their
boundaries to many applications in various domains. Recently, the research
community has started to evaluate their potential adoption in autonomous
vehicles and especially as complementary modules in the perception and planning
software stacks. However, their evaluation is limited in synthetic datasets or
manually driving datasets without the ground truth knowledge and more
precisely, how the current perception and planning algorithms would perform in
the cases under evaluation. For this reason, this work evaluates LLMs on
real-world edge cases where current autonomous vehicles have been proven to
fail. The proposed architecture consists of an open vocabulary object detector
coupled with prompt engineering and large language model contextual reasoning.
We evaluate several state-of-the-art models against real edge cases and provide
qualitative comparison results along with a discussion on the findings for the
potential application of LLMs as anomaly detectors in autonomous vehicles.

</details>


### [233] [Plantbot: Integrating Plant and Robot through LLM Modular Agent Networks](https://arxiv.org/abs/2509.05338)
*Atsushi Masumori,Norihiro Maruyama,Itsuki Doi,johnsmith,Hiroki Sato,Takashi Ikegami*

Main category: cs.RO

TL;DR: 本文提出了Plantbot，这是一种结合植物和移动机器人的混合生命体，通过大语言模型模块网络实现生物与人工系统的自然语言互动。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过大语言模型（LLM）作为接口，实现生物和人工系统之间的无缝协作，从而推动人工生命与智能体领域的发展。

Method: Plantbot系统中，每个模块（如传感、视觉、对话、动作）利用LLM，通过自然语言异步通信，将土壤湿度、温度、视觉等多模态数据转化为语言信息，实现系统行为的协同与规范。植株状态通过该网络转为机器人动作。

Result: Plantbot成为一个能够自主适应环境条件的具身智能体，实现了植物状态与机器人行为的联动，并证明LLM可以作为生物-人工系统间的通用协议。

Conclusion: LLM模块能够协调分布式生物与人工系统行为，为人工生命与生物-人工耦合互动开辟了新路径。

Abstract: We introduce Plantbot, a hybrid lifeform that connects a living plant with a
mobile robot through a network of large language model (LLM) modules. Each
module - responsible for sensing, vision, dialogue, or action - operates
asynchronously and communicates via natural language, enabling seamless
interaction across biological and artificial domains. This architecture
leverages the capacity of LLMs to serve as hybrid interfaces, where natural
language functions as a universal protocol, translating multimodal data (soil
moisture, temperature, visual context) into linguistic messages that coordinate
system behaviors. The integrated network transforms plant states into robotic
actions, installing normativity essential for agency within the sensor-motor
loop. By combining biological and robotic elements through LLM-mediated
communication, Plantbot behaves as an embodied, adaptive agent capable of
responding autonomously to environmental conditions. This approach suggests
possibilities for a new model of artificial life, where decentralized, LLM
modules coordination enable novel interactions between biological and
artificial systems.

</details>


### [234] [INF-3DP: Implicit Neural Fields for Collision-Free Multi-Axis 3D Printing](https://arxiv.org/abs/2509.05345)
*Jiasheng Qu,Zhuo Huang,Dezhao Guo,Hailin Sun,Aoran Lyu,Chengkai Dai,Yeung Yam,Guoxin Fang*

Main category: cs.RO

TL;DR: 该论文提出了一种基于隐式神经场（INFs）的多轴3D打印通用可扩展计算框架，实现了从路径规划到运动优化的统一设计，显著提升了速度和精度。


<details>
  <summary>Details</summary>
Motivation: 现有多轴3D打印在路径规划和运动优化方面缺乏统一、有效的处理方式，且显式方法在复杂几何上的速度与精度表现不足。因此，需要一种更高效且能处理复杂目标的框架。

Method: 作者用有符号距离场（SDF）表示模型，并将各种打印目标直接编码到隐式引导场的优化中，实现了从外壳到内部填充路径的统一隐式插值。进而，通过连续四元数场对打印顺序与多轴运动联合优化，并以差分方式处理全局碰撞，提升了运动规划效率与安全性。

Result: INF-3DP在速度上相比显式方法有1到2个数量级的提升，同时大幅降低了路径点与模型表面的误差。多种复杂模型和实际物理打印实验都验证了这种方法的有效性和高效性。

Conclusion: INF-3DP框架有效统一了多轴3D打印路径和运动规划流程，在效率和打印质量上都有显著提升，具备广泛的适用性和实用价值。

Abstract: We introduce a general, scalable computational framework for multi-axis 3D
printing based on implicit neural fields (INFs) that unifies all stages of
toolpath generation and global collision-free motion planning. In our pipeline,
input models are represented as signed distance fields, with fabrication
objectives such as support-free printing, surface finish quality, and extrusion
control being directly encoded in the optimization of an implicit guidance
field. This unified approach enables toolpath optimization across both surface
and interior domains, allowing shell and infill paths to be generated via
implicit field interpolation. The printing sequence and multi-axis motion are
then jointly optimized over a continuous quaternion field. Our continuous
formulation constructs the evolving printing object as a time-varying SDF,
supporting differentiable global collision handling throughout INF-based motion
planning. Compared to explicit-representation-based methods, INF-3DP achieves
up to two orders of magnitude speedup and significantly reduces
waypoint-to-surface error. We validate our framework on diverse, complex models
and demonstrate its efficiency with physical fabrication experiments using a
robot-assisted multi-axis system.

</details>


### [235] [Human-LLM Synergy in Context-Aware Adaptive Architecture for Scalable Drone Swarm Operation](https://arxiv.org/abs/2509.05355)
*Ahmed R. Sadik,Muhammad Ashfaq,Niko Mäkitalo,Tommi Mikkonen*

Main category: cs.RO

TL;DR: 本文提出了一种自适应无人机蜂群架构，利用大型语言模型，根据任务参数动态切换最优组织形式，以提升灾难响应效率。


<details>
  <summary>Details</summary>
Motivation: 目前的固定架构难以适应灾难响应中动态、不可预测的环境，导致能耗高、连通性差、效率低，因此亟需灵活、可扩展且健壮的协调系统。

Method: 提出一种借助大型语言模型，根据实时任务复杂度、蜂群规模、通信稳定性等参数动态选择中央式、分层或全能式蜂群架构。系统旨在提高扩展性、适应性与健壮性。

Result: 大量仿真结果显示，该自适应架构在扩展性、能效和连通性方面均优于传统静态架构。

Conclusion: 自适应无人机蜂群架构能为真实世界灾难响应场景提供可扩展、适应性强且具韧性的解决方案，具有实际应用潜力。

Abstract: The deployment of autonomous drone swarms in disaster response missions
necessitates the development of flexible, scalable, and robust coordination
systems. Traditional fixed architectures struggle to cope with dynamic and
unpredictable environments, leading to inefficiencies in energy consumption and
connectivity. This paper addresses this gap by proposing an adaptive
architecture for drone swarms, leveraging a Large Language Model to dynamically
select the optimal architecture as centralized, hierarchical, or holonic based
on real time mission parameters such as task complexity, swarm size, and
communication stability. Our system addresses the challenges of scalability,
adaptability, and robustness,ensuring efficient energy consumption and
maintaining connectivity under varying conditions. Extensive simulations
demonstrate that our adaptive architecture outperforms traditional static
models in terms of scalability, energy efficiency, and connectivity. These
results highlight the potential of our approach to provide a scalable,
adaptable, and resilient solution for real world disaster response scenarios.

</details>


### [236] [Spiking Neural Networks for Continuous Control via End-to-End Model-Based Learning](https://arxiv.org/abs/2509.05356)
*Justus Huebotter,Pablo Lanillos,Marcel van Gerven,Serge Thill*

Main category: cs.RO

TL;DR: 本文提出了一种可端到端训练的全脉冲神经网络（SNN）框架，实现了在连续环境下对多自由度机器人手臂的精确控制。通过引入预测控制方法和代理梯度，证明了SNN在高维运动任务上的可行性，并通过消融实验分析模型训练影响因素。


<details>
  <summary>Details</summary>
Motivation: 虽然SNN在分类任务中取得进展，但其在连续运动控制中的应用较少。单纯基于SNN实现高维、实时的机器人控制具有推广意义，尤其在能耗和生物启发方面。

Method: 提出结合Leaky Integrate-and-Fire（LIF）单元和代理梯度的方法，端到端联合优化动力学预测模型与策略网络。实验验证包括二维平面到达任务和六自由度机械臂模拟控制。

Result: 实验结果显示SNN能够稳定训练，准确实现连续力矩控制。此外，消融实验凸显了初始化、可学习时间常数和正则化对训练稳定性的显著影响。

Conclusion: 全脉冲神经网络可实现稳定有效的复杂运动控制，但对超参数极为敏感，因此合理的模型设计和参数选择至关重要。

Abstract: Despite recent progress in training spiking neural networks (SNNs) for
classification, their application to continuous motor control remains limited.
Here, we demonstrate that fully spiking architectures can be trained end-to-end
to control robotic arms with multiple degrees of freedom in continuous
environments. Our predictive-control framework combines Leaky
Integrate-and-Fire dynamics with surrogate gradients, jointly optimizing a
forward model for dynamics prediction and a policy network for goal-directed
action. We evaluate this approach on both a planar 2D reaching task and a
simulated 6-DOF Franka Emika Panda robot. Results show that SNNs can achieve
stable training and accurate torque control, establishing their viability for
high-dimensional motor tasks. An extensive ablation study highlights the role
of initialization, learnable time constants, and regularization in shaping
training dynamics. We conclude that while stable and effective control can be
achieved, recurrent spiking networks remain highly sensitive to hyperparameter
settings, underscoring the importance of principled design choices.

</details>


### [237] [Long-Horizon Visual Imitation Learning via Plan and Code Reflection](https://arxiv.org/abs/2509.05368)
*Quan Chen,Chenrui Shi,Qi Chen,Yuwei Wu,Zhi Gao,Xintong Zhang,Rui Gao,Kun Wu,Yunde Jia*

Main category: cs.RO

TL;DR: 该论文提出了一种新型智能体框架，利用两个反思模块，提升长时序视觉模仿学习任务的效果，并设计了全新基准测试LongVILBench，验证了新方法的优势。


<details>
  <summary>Details</summary>
Motivation: 当前视觉模仿学习在长时序、复杂操作序列上的表现有限，尤其难以理解动作间的时间关系和物体间的空间关系，亟需新方法提升此类任务的能力。

Method: 论文提出在智能体框架中加入计划反思模块和代码反思模块。前者用于审查生成的动作序列与演示视频的时空一致性，后者则检测和修正生成代码的正确性和一致性，形成端到端的纠错流程。

Result: 针对自建的LongVILBench基准进行了实验，结果显示目前已有方法在该基准上的表现较差，而所提出的新框架显著提升了模型在多个长时序复杂任务中的性能。

Conclusion: 新引入的双重反思机制及LongVILBench基准共同推动了长时序视觉模仿学习的发展，为后续研究奠定了坚实基础。

Abstract: Learning from long-horizon demonstrations with complex action sequences
presents significant challenges for visual imitation learning, particularly in
understanding temporal relationships of actions and spatial relationships
between objects. In this paper, we propose a new agent framework that
incorporates two dedicated reflection modules to enhance both plan and code
generation. The plan generation module produces an initial action sequence,
which is then verified by the plan reflection module to ensure temporal
coherence and spatial alignment with the demonstration video. The code
generation module translates the plan into executable code, while the code
reflection module verifies and refines the generated code to ensure correctness
and consistency with the generated plan. These two reflection modules jointly
enable the agent to detect and correct errors in both the plan generation and
code generation, improving performance in tasks with intricate temporal and
spatial dependencies. To support systematic evaluation, we introduce
LongVILBench, a benchmark comprising 300 human demonstrations with action
sequences of up to 18 steps. LongVILBench emphasizes temporal and spatial
complexity across multiple task types. Experimental results demonstrate that
existing methods perform poorly on this benchmark, whereas our new framework
establishes a strong baseline for long-horizon visual imitation learning.

</details>


### [238] [Evaluating Magic Leap 2 Tool Tracking for AR Sensor Guidance in Industrial Inspections](https://arxiv.org/abs/2509.05391)
*Christian Masuhr,Julian Koch,Thorsten Schüppstuhl*

Main category: cs.RO

TL;DR: 本论文系统性评估了Magic Leap 2 (ML2) AR头显控制器在工具追踪方面的性能，并建立了可推广的测试基准。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏公开基准来严谨评估用于工业场景（如氢气泄漏检测）的现代AR头显控制器的追踪性能，限制了其在实际应用中的信心和广泛推广。

Method: 采用机器人臂（EN ISO 9283标准）来实现可重复运动，并用光学追踪系统作为地面真实基准，设计了静态与动态、不同条件下的系统追踪测试，含实际工业检测路径。

Result: 提出了ML2控制器在准确性和重复性方面的量化基线，结果详细展示其在多种工况下的性能表现。

Conclusion: 研究不仅为ML2控制器的适用性提供了数据支持，还提供了一种可移植、稳健的评估方法，推动AR硬件在工业传感器引导等场景中的标准化应用。

Abstract: Rigorous evaluation of commercial Augmented Reality (AR) hardware is crucial,
yet public benchmarks for tool tracking on modern Head-Mounted Displays (HMDs)
are limited. This paper addresses this gap by systematically assessing the
Magic Leap 2 (ML2) controllers tracking performance. Using a robotic arm for
repeatable motion (EN ISO 9283) and an optical tracking system as ground truth,
our protocol evaluates static and dynamic performance under various conditions,
including realistic paths from a hydrogen leak inspection use case. The results
provide a quantitative baseline of the ML2 controller's accuracy and
repeatability and present a robust, transferable evaluation methodology. The
findings provide a basis to assess the controllers suitability for the
inspection use case and similar industrial sensor-based AR guidance tasks.

</details>


### [239] [RoboBallet: Planning for Multi-Robot Reaching with Graph Neural Networks and Reinforcement Learning](https://arxiv.org/abs/2509.05397)
*Matthew Lai,Keegan Go,Zhibin Li,Torsten Kroger,Stefan Schaal,Kelsey Allen,Jonathan Scholz*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习的多机器人任务与运动自动规划框架，能够高效解决复杂障碍环境下的任务分配、调度与路径规划，实现零样本推广、快速解算和在线自适应。


<details>
  <summary>Details</summary>
Motivation: 现代制造需要多机器人在共享且障碍丰富的空间中无碰撞协作，完成大量任务。现有自动化方法难以应对实际工业规模的计算复杂性，多数工厂仍依赖人工经验手动设计路径，费时费力。因此，开发一个支持自动分配任务、调度和路径规划的高效方法极为重要。

Method: 作者提出了一个基于图神经网络（GNN）和强化学习（RL）的策略框架，将多机器人场景建模为图结构，采用RL在程序生成的多样化环境中训练GNN策略，实现对任务分配、调度与路径规划的联合解决。该方法在仿真中对大规模、多样化任务集训练后，可直接泛化到未知的机器人布置、障碍形状和任务分布。

Result: 实验表明，该方法可在八机器人、四十任务、复杂障碍环境下实现自动、多任务优化，零样本推广能力强，速度远超传统方法，并可用于工作空间布局优化、故障容错和基于感知的动态重规划等场景。

Conclusion: 该方法大幅提升了多机器人任务规划的自动化、速度与可扩展性，为工业机器人高效、灵活协作提供了坚实基础，有望推动智能制造领域的进一步发展。

Abstract: Modern robotic manufacturing requires collision-free coordination of multiple
robots to complete numerous tasks in shared, obstacle-rich workspaces. Although
individual tasks may be simple in isolation, automated joint task allocation,
scheduling, and motion planning under spatio-temporal constraints remain
computationally intractable for classical methods at real-world scales.
Existing multi-arm systems deployed in the industry rely on human intuition and
experience to design feasible trajectories manually in a labor-intensive
process. To address this challenge, we propose a reinforcement learning (RL)
framework to achieve automated task and motion planning, tested in an
obstacle-rich environment with eight robots performing 40 reaching tasks in a
shared workspace, where any robot can perform any task in any order. Our
approach builds on a graph neural network (GNN) policy trained via RL on
procedurally-generated environments with diverse obstacle layouts, robot
configurations, and task distributions. It employs a graph representation of
scenes and a graph policy neural network trained through reinforcement learning
to generate trajectories of multiple robots, jointly solving the sub-problems
of task allocation, scheduling, and motion planning. Trained on large randomly
generated task sets in simulation, our policy generalizes zero-shot to unseen
settings with varying robot placements, obstacle geometries, and task poses. We
further demonstrate that the high-speed capability of our solution enables its
use in workcell layout optimization, improving solution times. The speed and
scalability of our planner also open the door to new capabilities such as
fault-tolerant planning and online perception-based re-planning, where rapid
adaptation to dynamic task sets is required.

</details>


### [240] [HapMorph: A Pneumatic Framework for Multi-Dimensional Haptic Property Rendering](https://arxiv.org/abs/2509.05433)
*Rui Chen,Domenico Chiaradia,Antonio Frisoli,Daniele Leonardis*

Main category: cs.RO

TL;DR: 本文提出了一种名为HapMorph的气动人机交互系统，可同时、持续地调节可穿戴设备的物体尺寸和刚度。通过对该原型的实验表明，在穿戴限制下实现了多维度的触觉反馈渲染，提高了交互性能和应用可能性。


<details>
  <summary>Details</summary>
Motivation: 当前可穿戴触觉设备难以同时调节几何（如尺寸）和机械性能（如刚度），这在真实人机交互应用中制约了体验和功能扩展。为了解决这种单双一属性渲染的瓶颈，作者试图开发可同时调节多物理属性的新型系统。

Method: 作者提出了一种基于对抗性织物气动执行器（AFPA）的气动调节框架，能够独立、持续地调节可穿戴设备的尺寸和刚度。通过双气腔压力调控实现属性解耦，并实现了集成原型用于手部可穿戴交互。

Result: 原型实现了尺寸从50mm到104mm的调节，最大刚度可达4.7N/mm，设备质量仅21g。用户试验结果显示可准确区分9种不同状态（3种尺寸×3种刚度），准确率达89.4%，平均响应时间6.7秒。此外，系统架构支持进一步扩展，实现形状与刚度的同步调控。

Conclusion: 该系统首创性地突破了可穿戴触觉界面只能单一渲染的限制，展示了多属性调控的可行性，推进了下一代多维触觉交互设备的发展。

Abstract: Haptic interfaces that can simultaneously modulate multiple physical
properties remain a fundamental challenge in human-robot interaction. Existing
systems typically allow the rendering of either geometric features or
mechanical properties, but rarely both, within wearable form factors. Here, we
introduce HapMorph, a pneumatic framework that enables continuous, simultaneous
modulation of object size and stiffness through antagonistic fabric-based
pneumatic actuators (AFPAs). We implemented a HapMorph protoytpe designed for
hands interaction achieving size variation from 50 to 104 mm, stiffness
modulation up to 4.7 N/mm and mass of the wearable parts of just 21 g. Through
systematic characterization, we demonstrate decoupled control of size and
stiffness properties via dual-chamber pressure regulation. Human perception
studies with 10 participants reveal that users can distinguish nine discrete
states across three size categories and three stiffness levels with 89.4%
accuracy and 6.7 s average response time. We further demonstrate extended
architectures that combine AFPAs with complementary pneumatic structures to
enable shape or geometry morphing with concurrent stiffness control. Our
results establish antagonistic pneumatic principle as a pathway toward
next-generation haptic interfaces, capable of multi-dimensiona rendering
properties within practical wearable constraints.

</details>


### [241] [Learning Tool-Aware Adaptive Compliant Control for Autonomous Regolith Excavation](https://arxiv.org/abs/2509.05475)
*Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez,Carol Martinez*

Main category: cs.RO

TL;DR: 本文通过引入基于模型的强化学习框架，使自主机器人能够适应不同月壤地形和多样化挖掘工具，实现泛化且鲁棒的挖掘任务，有效提升未来太空任务必需的自主系统能力。


<details>
  <summary>Details</summary>
Motivation: 当前，人类在地外持续存在的重要瓶颈之一是资源的原位利用（ISRU），而自主挖掘月壤是该过程的基础环节。但月壤（颗粒介质）与工具的复杂交互动力学，以及机器人成本效益地适应多类型工具的需求，是亟待解决的技术难题。

Method: 本文提出并实现了一个基于高保真粒子物理仿真的并行化模拟环境，随机生成大量月球地形和挖掘工具形状。强化学习智能体通过在控制空间动态调整自身的刚度与阻尼，逐步学会对不同情况的自适应策略。此外，通过增加视觉反馈加强了系统感知能力。

Result: 实验发现，利用大量不同工具进行分布式训练对泛化提升极为关键，智能体在多变工具与地形条件下获得了复杂、可泛化的策略。视觉感知能力的增强明显提升了任务成功率。

Conclusion: 本文方法验证了通过高保真仿真和程序化多样训练，可显著提升智能自主挖掘系统的鲁棒性和适应性，为未来深空任务中的基础操作提供了可行的技术路径。

Abstract: Autonomous regolith excavation is a cornerstone of in-situ resource
utilization for a sustained human presence beyond Earth. However, this task is
fundamentally hindered by the complex interaction dynamics of granular media
and the operational need for robots to use diverse tools. To address these
challenges, this work introduces a framework where a model-based reinforcement
learning agent learns within a parallelized simulation. This environment
leverages high-fidelity particle physics and procedural generation to create a
vast distribution of both lunar terrains and excavation tool geometries. To
master this diversity, the agent learns an adaptive interaction strategy by
dynamically modulating its own stiffness and damping at each control step
through operational space control. Our experiments demonstrate that training
with a procedural distribution of tools is critical for generalization and
enables the development of sophisticated tool-aware behavior. Furthermore, we
show that augmenting the agent with visual feedback significantly improves task
success. These results represent a validated methodology for developing the
robust and versatile autonomous systems required for the foundational tasks of
future space missions.

</details>


### [242] [Microrobot Vascular Parkour: Analytic Geometry-based Path Planning with Real-time Dynamic Obstacle Avoidance](https://arxiv.org/abs/2509.05500)
*Yanda Yang,Max Sokolich,Fatma Ceren Kirmizitas,Sambeeta Das,Andreas A. Malikopoulos*

Main category: cs.RO

TL;DR: 本文提出了一种适用于血管中自主微型机器人导航的实时路径规划框架，结合全局规划与局部避障，有效应对血流环境中密集且动态障碍物，支持实时闭环控制。


<details>
  <summary>Details</summary>
Motivation: 在血管内应用自主微型机器人可实现微创治疗，但实际导航极为困难，主要因为血管狭窄且充满高速流动的障碍。在复杂且动态的环境下，如何安全、快速、可靠地引导微型机器人到达目标区域，是实现临床应用的关键挑战。

Method: 作者提出了一套结合解析几何全球规划器（AGP）与两种局部逃逸控制器（基于规则和基于强化学习）的路径规划系统。系统利用实时成像估计机器人、障碍物及目标的位置，融合全局路径与实时避障，确保全程无碰撞。方法在二维基础上推广至三维，并与WA*、PSO及RRT等算法进行仿真对比。

Result: 在仿真中，AGP相比WA*、PSO、RRT等方法，路径更短，规划更快且具有确定性。系统整体在仿真和实际实验下均能高效避开移动障碍物，准确到达目标，平均规划耗时仅40ms，满足25fps成像与实时闭环控制的需求。

Conclusion: 该工作在微型机器人自主导航与靶向药物递送方面取得实质进展，提出的实时路径规划方法兼具速度、可靠性和可扩展性，有望显著推进血管环境下微型机器人应用的实际可行性与精度。

Abstract: Autonomous microrobots in blood vessels could enable minimally invasive
therapies, but navigation is challenged by dense, moving obstacles. We propose
a real-time path planning framework that couples an analytic geometry global
planner (AGP) with two reactive local escape controllers, one based on rules
and one based on reinforcement learning, to handle sudden moving obstacles.
Using real-time imaging, the system estimates the positions of the microrobot,
obstacles, and targets and computes collision-free motions. In simulation, AGP
yields shorter paths and faster planning than weighted A* (WA*), particle swarm
optimization (PSO), and rapidly exploring random trees (RRT), while maintaining
feasibility and determinism. We extend AGP from 2D to 3D without loss of speed.
In both simulations and experiments, the combined global planner and local
controllers reliably avoid moving obstacles and reach targets. The average
planning time is 40 ms per frame, compatible with 25 fps image acquisition and
real-time closed-loop control. These results advance autonomous microrobot
navigation and targeted drug delivery in vascular environments.

</details>


### [243] [TeleopLab: Accessible and Intuitive Teleoperation of a Robotic Manipulator for Remote Labs](https://arxiv.org/abs/2509.05547)
*Ziling Chen,Yeo Jung Yoon,Rolando Bautista-Montesano,Zhen Zhao,Ajay Mandlekar,John Liu*

Main category: cs.RO

TL;DR: 本文提出了一种基于移动设备的远程机器臂实验操作系统TeleopLab，实现了学生对实验设备的远程操作，并通过用户研究验证了其实用性与有效性。


<details>
  <summary>Details</summary>
Motivation: 远程教育场景下，尤其是需要操作真实设备的STEM学习存在成本高、操作不便等难题。作者希望通过设计新的远程实验操作方式，提升远程实验的直观性和效率。

Method: 设计并实现了TeleopLab系统，包括机器臂、自适应夹爪、多摄像头、实验设备和手机端用户界面。通过视频通话和远程用户实验，评估学生在使用系统前后的任务表现、主观反馈、可用性和工作负荷。

Result: 随着熟练度提升，任务完成时间减少了46.1%。学生对系统的看法明显改善，NASA TLX得分38.2显示工作负担适中，SUS得分73.8表现出良好的可用性。

Conclusion: TeleopLab有效弥合了物理实验室和远程教育的鸿沟，为远程STEM学习提供了可扩展且高效的平台。

Abstract: Teleoperation offers a promising solution for enabling hands-on learning in
remote education, particularly in environments requiring interaction with
real-world equipment. However, such remote experiences can be costly or
non-intuitive. To address these challenges, we present TeleopLab, a mobile
device teleoperation system that allows students to control a robotic arm and
operate lab equipment. TeleopLab comprises a robotic arm, an adaptive gripper,
cameras, lab equipment for a diverse range of applications, a user interface
accessible through smartphones, and video call software. We conducted a user
study, focusing on task performance, students' perspectives toward the system,
usability, and workload assessment. Our results demonstrate a 46.1% reduction
in task completion time as users gained familiarity with the system.
Quantitative feedback highlighted improvements in students' perspectives after
using the system, while NASA TLX and SUS assessments indicated a manageable
workload of 38.2 and a positive usability of 73.8. TeleopLab successfully
bridges the gap between physical labs and remote education, offering a scalable
and effective platform for remote STEM learning.

</details>


### [244] [Learning to Walk in Costume: Adversarial Motion Priors for Aesthetically Constrained Humanoids](https://arxiv.org/abs/2509.05581)
*Arturo Flores Alvarez,Fatemeh Zargarbashi,Havel Liu,Shiqi Wang,Liam Edwards,Jessica Anz,Alex Xu,Fan Shi,Stelian Coros,Dennis W. Hong*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习（RL）的步态系统，用于娱乐用途的人形机器人Cosmo，强调外观和稳定性的平衡。


<details>
  <summary>Details</summary>
Motivation: 娱乐机器人常因美学设计导致如头部大、传感有限、保护壳限制动作等特殊挑战，需要创新技术以兼顾美观和运动性能。

Method: 采用Adversarial Motion Priors（AMP）方法，使机器人学会自然且稳定的动作。结合专门的领域随机化技术及奖励机制，保证从仿真到现实的安全迁移。

Result: 实验显示，AMP方法能让Cosmo在人机质量分布极端和运动受限条件下，实现稳定的站立和行走。

Conclusion: 强化学习可以帮助外观设计受限的机器人获得自然且稳定的动作，表明基于学习的方法能有效适应美学驱动的设计约束。

Abstract: We present a Reinforcement Learning (RL)-based locomotion system for Cosmo, a
custom-built humanoid robot designed for entertainment applications. Unlike
traditional humanoids, entertainment robots present unique challenges due to
aesthetic-driven design choices. Cosmo embodies these with a disproportionately
large head (16% of total mass), limited sensing, and protective shells that
considerably restrict movement. To address these challenges, we apply
Adversarial Motion Priors (AMP) to enable the robot to learn natural-looking
movements while maintaining physical stability. We develop tailored domain
randomization techniques and specialized reward structures to ensure safe
sim-to-real, protecting valuable hardware components during deployment. Our
experiments demonstrate that AMP generates stable standing and walking
behaviors despite Cosmo's extreme mass distribution and movement constraints.
These results establish a promising direction for robots that balance aesthetic
appeal with functional performance, suggesting that learning-based methods can
effectively adapt to aesthetic-driven design constraints.

</details>


### [245] [MonoGlass3D: Monocular 3D Glass Detection with Plane Regression and Adaptive Feature Fusion](https://arxiv.org/abs/2509.05599)
*Kai Zhang,Guoyang Zhao,Jianxing Shi,Bonan Liu,Weiqing Qi,Jun Ma*

Main category: cs.RO

TL;DR: 本文提出了一种名为MonoGlass3D的方法，通过单目视觉在多样环境下检测和定位3D玻璃体，并配套发布了真实场景的高质量标注数据集，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 玻璃因其光学属性导致传统计感器难以检测，且缺乏专门针对玻璃的3D真实数据集，严重制约了相关研究和应用的发展。

Method: 提出了MonoGlass3D方法，包含新数据集、适应性特征融合模块和结合几何属性的平面回归算法，专门针对单目3D玻璃检测进行优化。

Result: 该方法在玻璃分割和单目深度估计任务上均显著超越现有最优方法，尤其在透明表面理解方面表现出色。

Conclusion: 结合几何与上下文信息对于3D玻璃等透明物体检测理解至关重要，提出的数据集和方法为该领域研究提供了重要推进。

Abstract: Detecting and localizing glass in 3D environments poses significant
challenges for visual perception systems, as the optical properties of glass
often hinder conventional sensors from accurately distinguishing glass
surfaces. The lack of real-world datasets focused on glass objects further
impedes progress in this field. To address this issue, we introduce a new
dataset featuring a wide range of glass configurations with precise 3D
annotations, collected from distinct real-world scenarios. On the basis of this
dataset, we propose MonoGlass3D, a novel approach tailored for monocular 3D
glass detection across diverse environments. To overcome the challenges posed
by the ambiguous appearance and context diversity of glass, we propose an
adaptive feature fusion module that empowers the network to effectively capture
contextual information in varying conditions. Additionally, to exploit the
distinct planar geometry of glass surfaces, we present a plane regression
pipeline, which enables seamless integration of geometric properties within our
framework. Extensive experiments demonstrate that our method outperforms
state-of-the-art approaches in both glass segmentation and monocular glass
depth estimation. Our results highlight the advantages of combining geometric
and contextual cues for transparent surface understanding.

</details>


### [246] [Sharing but Not Caring: Similar Outcomes for Shared Control and Switching Control in Telepresence-Robot Navigation](https://arxiv.org/abs/2509.05672)
*Juho Kalliokoski,Evan G. Center,Steven M. LaValle,Timo Ojala,Basak Sakcak*

Main category: cs.RO

TL;DR: 本文提出并评估了一种让遥控用户与机器人共享控制的导航方法，结果表明该方法能够维持与传统控制方式相似的导航效率，但未显著降低用户任务负担。


<details>
  <summary>Details</summary>
Motivation: 远程场景下，用户通过远程呈现机器人进行交互，但高效和直观的导航一直是难点。作者希望解决如何提升用户导航体验及效率的问题。

Method: 开发并对比了两种控制方法：一种是共享控制——机器人自主导航并允许用户适度影响路径，另一种是切换控制——用户在直接控制和自动控制间切换，并通过两轮各20名参与者的用户实验进行评估。

Result: 实验结果显示，共享控制在导航效率上与切换控制相当，但在降低用户任务负担方面并没有显著优于切换控制。

Conclusion: 共享控制能在不降低导航效率的前提下提供新的交互方式，但未能明显减轻用户负荷。未来需继续研究影响用户偏好与性能的因素。

Abstract: Telepresence robots enable users to interact with remote environments, but
efficient and intuitive navigation remains a challenge. In this work, we
developed and evaluated a shared control method, in which the robot navigates
autonomously while allowing users to affect the path generation to better suit
their needs. We compared this with control switching, where users toggle
between direct and automated control. We hypothesized that shared control would
maintain efficiency comparable to control switching while potentially reducing
user workload. The results of two consecutive user studies (each with final
sample of n=20) showed that shared control does not degrade navigation
efficiency, but did not show a significant reduction in task load compared to
control switching. Further research is needed to explore the underlying factors
that influence user preference and performance in these control systems.

</details>


### [247] [A*-PRM: A Dynamic Weight-Based Probabilistic Roadmap Algorithm](https://arxiv.org/abs/2509.05701)
*Siyuan Wang,Shuyi Zhang,Zhen Tian,Yuheng Yao,Gongsen Wang,Yu Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种将A-star算法与PRM（概率路标法）结合，并引入动态权重的混合路径规划算法。在复杂障碍环境下，此方法显著提升了路径质量、计算效率与适应性。实验结果显示新算法路径更短、耗时更低，尤其在窄通道与动态障碍场景下更具优势。


<details>
  <summary>Details</summary>
Motivation: 传统路径规划算法（如A-star、PRM）各自存在局限性，A-star算法路径质量高但效率有限，PRM具有良好全局性但规划路径冗长或效率不佳。提升环境适应性与效率，解决复杂障碍物及动态环境下的路径规划难题，是本研究的动机。

Method: 将A-star算法的曼哈顿距离启发式函数结合进PRM的随机采样和连通机制，采用分层采样策略与动态连接机制以优化路径质量和计算效率，并提升对障碍复杂分布的适应性。

Result: 在1000个采样点下，A-star PRM路径长度较原始PRM短42.3%（p<0.01），平均路径为1073.23±14.8米；在3000个采样点下路径长度下降0.94%，但计算时间增幅只有PRM的约1/10。

Conclusion: A-star PRM方法在路径质量、稳定性与计算效率等多方面表现优异，较传统及现有混合算法在复杂环境（如窄通道与动态障碍）下展现出明显优势。

Abstract: Robot path planning is a fundamental challenge in enhancing the environmental
adaptability of autonomous navigation systems. This paper presents a hybrid
path planning algorithm, A-star PRM, which incorporates dynamic weights. By
embedding the Manhattan distance heuristic of the A-star algorithm into the
random sampling process of PRM, the algorithm achieves a balanced optimization
of path quality and computational efficiency. The approach uses a hierarchical
sampling strategy and a dynamic connection mechanism, greatly improving
adaptability to complex obstacle distributions. Experiments show that under a
baseline configuration with one thousand sampled vertices, the path length of
A-star PRM is 1073.23 plus or minus 14.8 meters and is 42.3 percent shorter
than that of PRM with p value less than 0.01. With high-density sampling using
three thousand vertices, the path length is reduced by 0.94 percent, 1036.61
meters compared with 1046.42 meters, while the increase in computational time
is cut to about one tenth of the PRM increase, 71 percent compared with 785
percent. These results confirm the comprehensive advantages of A-star PRM in
path quality, stability, and computational efficiency. Compared with existing
hybrid algorithms, the proposed method shows clear benefits, especially in
narrow channels and scenarios with dynamic obstacles.

</details>


### [248] [Super-LIO: A Robust and Efficient LiDAR-Inertial Odometry System with a Compact Mapping Strategy](https://arxiv.org/abs/2509.05723)
*Liansheng Wang,Xinke Zhang,Chenhui Li,Dongjiao He,Yihan Pan,Jianjun Yi*

Main category: cs.RO

TL;DR: Super-LIO是一种高效且高精度的LiDAR-惯性里程计系统，专为资源受限平台设计，采用新颖的地图结构和高效的点云匹配方法，显著提升计算效率并减少资源消耗，适用于多种自主系统。


<details>
  <summary>Details</summary>
Motivation: 传统LIO系统在资源受限的平台（如小型无人机和移动机器人）上难以部署，原因在于其高计算和存储需求。因此，开发一种高效、低资源消耗且易集成的LIO解决方案成为需求。

Method: Super-LIO核心方法是提出了一种精简的八分体体素（OctVox）地图结构，每个体素最多只存八个融合子体素，通过控制点云密度和增量去噪实现高效的地图管理；同时设计了启发式的KNN策略(HKNN)，加速特征对应搜索，提高运算速度。

Result: 在四个公开数据集和自采数据集（总计30多条序列）上测试，Super-LIO在X86与ARM平台上显示出高效率与高鲁棒性。与现有最优方法相比，每帧处理速度提升约73%，且CPU资源占用更低。

Conclusion: Super-LIO作为开源、易集成的LIO系统，兼顾了高效率和高精度，非常适合实际自主系统的部署，显著降低了对计算资源的需求，推广前景广阔。

Abstract: LiDAR-Inertial Odometry (LIO) is a foundational technique for autonomous
systems, yet its deployment on resource-constrained platforms remains
challenging due to computational and memory limitations. We propose Super-LIO,
a robust LIO system that demands both high performance and accuracy, ideal for
applications such as aerial robots and mobile autonomous systems. At the core
of Super-LIO is a compact octo-voxel-based map structure, termed OctVox, that
limits each voxel to eight fused subvoxels, enabling strict point density
control and incremental denoising during map updates. This design enables a
simple yet efficient and accurate map structure, which can be easily integrated
into existing LIO frameworks. Additionally, Super-LIO designs a
heuristic-guided KNN strategy (HKNN) that accelerates the correspondence search
by leveraging spatial locality, further reducing runtime overhead. We evaluated
the proposed system using four publicly available datasets and several
self-collected datasets, totaling more than 30 sequences. Extensive testing on
both X86 and ARM platforms confirms that Super-LIO offers superior efficiency
and robustness, while maintaining competitive accuracy. Super-LIO processes
each frame approximately 73% faster than SOTA, while consuming less CPU
resources. The system is fully open-source and plug-and-play compatible with a
wide range of LiDAR sensors and platforms. The implementation is available at:
https://github.com/Liansheng-Wang/Super-LIO.git

</details>


### [249] [Scenario-based Decision-making Using Game Theory for Interactive Autonomous Driving: A Survey](https://arxiv.org/abs/2509.05777)
*Zhihao Lin,Zhen Tian*

Main category: cs.RO

TL;DR: 本文综述了近年来基于游戏的交互式驾驶仿真在自动驾驶决策算法中的应用进展，比较了不同场景下的方法与性能。


<details>
  <summary>Details</summary>
Motivation: 尽管基于游戏的驾驶仿真为自动驾驶决策算法提供了安全、可扩展且富有挑战性的测试平台，但在面对复杂、多样的真实交通环境时，真实感与鲁棒性仍是亟需突破的问题。此外，当前尚缺乏系统性的综述来对比和评估不同仿真方法在各类驾驶场景下的表现。

Method: 文章梳理了基于游戏的交互式驾驶方法，重点总结了近期的研究进展和这些方法在不同道路及场景（如高速障碍规避、匝道并线、环形交叉口、无信号路口和无人驾驶竞速等）中的应用。对比分析了它们如何结合先进学习框架优化游戏模型，并评估了各自的决策机制及其对性能的具体影响。

Result: 基于游戏学习框架的自适应决策模型在应对复杂、多样驾驶场景时，整体优于传统仿真方法，特别是在针对具体交通难题（如障碍规避、精准操作等）时表现出更强的适应性和表现力。

Conclusion: 当前方法虽然已取得显著进展，但仍存在诸如仿真真实性、泛化能力等局限。未来研究需进一步提升仿真的现实感和算法的鲁棒性，以更好地支持自动驾驶决策研发。

Abstract: Game-based interactive driving simulations have emerged as versatile
platforms for advancing decision-making algorithms in road transport mobility.
While these environments offer safe, scalable, and engaging settings for
testing driving strategies, ensuring both realism and robust performance amid
dynamic and diverse scenarios remains a significant challenge. Recently, the
integration of game-based techniques with advanced learning frameworks has
enabled the development of adaptive decision-making models that effectively
manage the complexities inherent in varied driving conditions. These models
outperform traditional simulation methods, especially when addressing
scenario-specific challenges, ranging from obstacle avoidance on highways and
precise maneuvering during on-ramp merging to navigation in roundabouts,
unsignalized intersections, and even the high-speed demands of autonomous
racing. Despite numerous innovations in game-based interactive driving, a
systematic review comparing these approaches across different scenarios is
still missing. This survey provides a comprehensive evaluation of game-based
interactive driving methods by summarizing recent advancements and inherent
roadway features in each scenario. Furthermore, the reviewed algorithms are
critically assessed based on their adaptation of the standard game model and an
analysis of their specific mechanisms to understand their impact on
decision-making performance. Finally, the survey discusses the limitations of
current approaches and outlines promising directions for future research.

</details>


### [250] [eKalibr-Inertial: Continuous-Time Spatiotemporal Calibration for Event-Based Visual-Inertial Systems](https://arxiv.org/abs/2509.05923)
*Shuolong Chen,Xingxing Li,Liu Yuan*

Main category: cs.RO

TL;DR: 本文提出了eKalibr-Inertial方法，实现了基于事件相机的视觉-惯性系统的高精度时空（外参和时序）标定，并公开源代码。


<details>
  <summary>Details</summary>
Motivation: 事件相机因其高时间分辨率、高动态范围和低功耗在各类机器人感知任务发挥重要作用。由于事件相机与惯性传感器互补，视觉-惯性融合方案被广泛采用。要实现高精度融合，必须解决事件相机与IMU间的精确时空标定问题，目前缺乏高效可靠的工具。

Method: 本文参照传统eKalibr与eKalibr-Stereo的圆点标定板识别与跟踪流程，设计了eKalibr-Inertial标定器。首先进行高效初始化，准确恢复所有估计器参数，随后采用基于连续时间的批量优化进一步提升参数精度。

Result: 通过大量真实世界实验验证，eKalibr-Inertial实现了精确的基于事件相机的视觉-惯性系统时空标定。

Conclusion: eKalibr-Inertial为事件视觉-惯性系统提供了高效、精确且实用的时空标定方法，且已开源，便于社区进一步研究和应用。

Abstract: The bioinspired event camera, distinguished by its exceptional temporal
resolution, high dynamic range, and low power consumption, has been extensively
studied in recent years for motion estimation, robotic perception, and object
detection. In ego-motion estimation, the visual-inertial setup is commonly
adopted due to complementary characteristics between sensors (e.g., scale
perception and low drift). For optimal event-based visual-inertial fusion,
accurate spatiotemporal (extrinsic and temporal) calibration is required. In
this work, we present eKalibr-Inertial, an accurate spatiotemporal calibrator
for event-based visual-inertial systems, utilizing the widely used circle grid
board. Building upon the grid pattern recognition and tracking methods in
eKalibr and eKalibr-Stereo, the proposed method starts with a rigorous and
efficient initialization, where all parameters in the estimator would be
accurately recovered. Subsequently, a continuous-time-based batch optimization
is conducted to refine the initialized parameters toward better states. The
results of extensive real-world experiments show that eKalibr-Inertial can
achieve accurate event-based visual-inertial spatiotemporal calibration. The
implementation of eKalibr-Inertial is open-sourced at
(https://github.com/Unsigned-Long/eKalibr) to benefit the research community.

</details>


### [251] [ZLATTE: A Geometry-Aware, Learning-Free Framework for Language-Driven Trajectory Reshaping in Human-Robot Interaction](https://arxiv.org/abs/2509.06031)
*Junhui Huang,Yuhe Gong,Changsheng Li,Xingguang Duan,Luis Figueredo*

Main category: cs.RO

TL;DR: ZLATTE是个无需学习的几何感知框架，利用大模型将自然语言指令转为具体几何约束，用于人机交互场景下的运动轨迹适配，安全高效。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的轨迹调整方法依赖大量数据，泛化能力和可解释性有限。在实际人机交互中，用户通过自然语言描述目标，需要一种高效、解释性强且安全的轨迹调整方法。

Method: ZLATTE利用Vision-Language Model将视觉对象描述为几何实体，再用大语言模型将用户自然语言指令转换成明确的几何与运动学约束，把这些约束整合进势场优化中，实现对原有轨迹的灵活调整。此外还引入多智能体策略提升对复杂或冲突指令的稳健性。

Result: 在仿真和现实实验中，ZLATTE与现有主流方法相比，能够生成更平滑、更安全且更易解释的轨迹调整方案。

Conclusion: ZLATTE无需训练数据，能够结合视觉与语言理解，并高效、可解释地调整机器人运动轨迹，在复杂自然语言指令场景下表现优异。

Abstract: We present ZLATTE, a geometry-aware, learning-free framework for
language-driven trajectory reshaping in human-robot interaction. Unlike prior
learning-based methods, ZLATTE leverages Vision-Language Models to register
objects as geometric primitives and employs a Large Language Model to translate
natural language instructions into explicit geometric and kinematic
constraints. These constraints are integrated into a potential field
optimization to adapt initial trajectories while preserving feasibility and
safety. A multi-agent strategy further enhances robustness under complex or
conflicting commands. Simulation and real-world experiments demonstrate that
ZLATTE achieves smoother, safer, and more interpretable trajectory
modifications compared to state-of-the-art baselines.

</details>


### [252] [Robotic Manipulation Framework Based on Semantic Keypoints for Packing Shoes of Different Sizes, Shapes, and Softness](https://arxiv.org/abs/2509.06048)
*Yi Dong,Yangjun Liu,Jinjun Duan,Yang Li,Zhendong Dai*

Main category: cs.RO

TL;DR: 本文提出了一个用于鞋类产品自动化打包的机器人操作框架，结合语义关键点感知、重定位规划和打包规划，实现任意初始状态下鞋子的高效配对打包，并通过真实实验验证了方法的鲁棒性和有效性。


<details>
  <summary>Details</summary>
Motivation: 鞋类打包由于其物体形状不规则及可变形，配对打包任务复杂，而现有研究未充分考虑鞋子初始状态差异以及标准化打包姿态的难题。

Method: 提出包含感知模块（以语义关键点为特征）、重定位规划器（针对可变形和不同初始状态鞋子，提出原语重定位和基于重力/盒沿的快速方法）以及打包规划器的机器人体系，实现从任意初始状态到最佳打包方案的完整流程。

Result: 通过真实世界实验，验证了重定位方法在多种鞋型下的鲁棒性及打包策略的效果，展现了系统在复杂实际场景中的应用价值。

Conclusion: 语义关键点感知方法在3D可变形物体以及多对象操作中展现出新的潜力，机器人自动化打包框架为今后类似配对物体包装任务提供了有力参考。

Abstract: With the rapid development of the warehousing and logistics industries, the
packing of goods has gradually attracted the attention of academia and
industry. The packing of footwear products is a typical representative
paired-item packing task involving irregular shapes and deformable objects.
Although studies on shoe packing have been conducted, different initial states
due to the irregular shapes of shoes and standard packing placement poses have
not been considered. This study proposes a robotic manipulation framework,
including a perception module, reorientation planners, and a packing planner,
that can complete the packing of pairs of shoes in any initial state. First, to
adapt to the large intraclass variations due to the state, shape, and
deformation of the shoe, we propose a vision module based on semantic
keypoints, which can also infer more information such as size, state, pose, and
manipulation points by combining geometric features. Subsequently, we not only
proposed primitive-based reorientation methods for different states of a single
deformable shoe but also proposed a fast reorientation method for the top state
using box edge contact and gravity, which further improved the efficiency of
reorientation. Finally, based on the perception module and reorientation
methods, we propose a task planner for shoe pair packing in any initial state
to provide an optimal packing strategy. Real-world experiments were conducted
to verify the robustness of the reorientation methods and the effectiveness of
the packing strategy for various types of shoes. In this study, we highlight
the potential of semantic keypoint representation methods, introduce new
perspectives on the reorientation of 3D deformable objects and multi-object
manipulation, and provide a reference for paired object packing.

</details>


### [253] [Energy-Efficient Path Planning with Multi-Location Object Pickup for Mobile Robots on Uneven Terrain](https://arxiv.org/abs/2509.06061)
*Faiza Babakano,Ahmed Fahmin,Bojie Shen,Muhammad Aamir Cheema,Isma Farah Siddiqui*

Main category: cs.RO

TL;DR: 本文提出了面向自主移动机器人（AMR）的拾取物体最小能耗路径问题（OMEPP），旨在提升机器人在复杂地形、需拾取货物情况下的能耗路径规划效率。


<details>
  <summary>Details</summary>
Motivation: 传统能耗优化路径规划主要关注起点到终点，但忽视了实际场景中机器人需在途经不同位置拾取物品的情况，且物体负载变化会显著影响能耗。解决这一实际问题对延长AMR续航、提升任务执行效率具有重要意义。

Method: 提出了OMEPP问题，初步用迭代Z*（A*变种，针对能耗优化）算法作为基线，针对所有拾取点分别计算最优路径。为提升效率，创新性地提出了Payload-Constrained Path Database（PCPD），并采用并发PCPD搜索方法，在所有拾取点间同时开展多次Z*搜索，大幅减少分支，提高搜索效率。

Result: 实验证明：与基线算法相比，并发PCPD搜索在真实数据集下速度提高1~2个数量级，尽管解可能略次于最优，但接近最优。

Conclusion: PCPD及其并发搜索方法显著提升了有物体拾取需求时AMR能耗路径规划的效率，是解决实际应用中能耗与计算效率平衡的有效方案。

Abstract: Autonomous Mobile Robots (AMRs) operate on battery power, making energy
efficiency a critical consideration, particularly in outdoor environments where
terrain variations affect energy consumption. While prior research has
primarily focused on computing energy-efficient paths from a source to a
destination, these approaches often overlook practical scenarios where a robot
needs to pick up an object en route - an action that can significantly impact
energy consumption due to changes in payload. This paper introduces the
Object-Pickup Minimum Energy Path Problem (OMEPP), which addresses
energy-efficient route planning for AMRs required to pick up an object from one
of many possible locations and deliver it to a destination. To address OMEPP,
we first introduce a baseline algorithm that employs the Z star algorithm, a
variant of A star tailored for energy-efficient routing, to iteratively visit
each pickup point. While this approach guarantees optimality, it suffers from
high computational cost due to repeated searches at each pickup location. To
mitigate this inefficiency, we propose a concurrent PCPD search that manages
multiple Z star searches simultaneously across all pickup points. Central to
our solution is the Payload-Constrained Path Database (PCPD), an extension of
the Compressed Path Database (CPD) that incorporates payload constraints. We
demonstrate that PCPD significantly reduces branching factors during search,
improving overall performance. Although the concurrent PCPD search may produce
slightly suboptimal solutions, extensive experiments on real-world datasets
show it achieves near-optimal performance while being one to two orders of
magnitude faster than the baseline algorithm.

</details>


### [254] [Hybrid A* Path Planning with Multi-Modal Motion Extension for Four-Wheel Steering Mobile Robots](https://arxiv.org/abs/2509.06115)
*Runjiao Bao,Lin Zhang,Tianwei Niu,Haoyu Yuan,Shoukun Wang*

Main category: cs.RO

TL;DR: 该论文提出了一种面向四轮独立转向（4WIS）移动机器人的混合A*路径规划新方法，能够有效利用多种运动模式，提升在复杂环境中的机动性和路径规划性能。


<details>
  <summary>Details</summary>
Motivation: 四轮独立转向系统可以实现多种运动模式，显著提升机器人在狭小或复杂环境中的机动性。然而，现有路径规划方法通常只基于单一运动学模型，无法充分发挥4WIS平台的多模态优势。

Method: 作者提出了一种扩展的Hybrid A*算法，工作在包含空间状态和运动模式的四维状态空间。方法包括：1）为每种运动模式定制多模态Reeds-Shepp曲线；2）设计改进的启发函数，考虑模式切换的代价；3）提出智能终端连接策略，实现不同转向模式间的平滑切换。

Result: 实验结果表明，该方法能够在复杂环境下为4WIS机器人生成包含多种运动模态的无缝路径，显著提升路径规划能力和灵活性。

Conclusion: 所提规划器可有效整合并利用4WIS机器人的多种运动模式，提升其在复杂环境下的路径适应性和规划性能，对实际多模态移动机器人路径规划应用具有重要意义。

Abstract: Four-wheel independent steering (4WIS) systems provide mobile robots with a
rich set of motion modes, such as Ackermann steering, lateral steering, and
parallel movement, offering superior maneuverability in constrained
environments. However, existing path planning methods generally assume a single
kinematic model and thus fail to fully exploit the multi-modal capabilities of
4WIS platforms. To address this limitation, we propose an extended Hybrid A*
framework that operates in a four-dimensional state space incorporating both
spatial states and motion modes. Within this framework, we design multi-modal
Reeds-Shepp curves tailored to the distinct kinematic constraints of each
motion mode, develop an enhanced heuristic function that accounts for
mode-switching costs, and introduce a terminal connection strategy with
intelligent mode selection to ensure smooth transitions between different
steering patterns. The proposed planner enables seamless integration of
multiple motion modalities within a single path, significantly improving
flexibility and adaptability in complex environments. Results demonstrate
significantly improved planning performance for 4WIS robots in complex
environments.

</details>


### [255] [A Hybrid TDMA/CSMA Protocol for Time-Sensitive Traffic in Robot Applications](https://arxiv.org/abs/2509.06119)
*Shiqi Xu,Lihao Zhang,Yuyang Du,Qun Yang,Soung Chang Liew*

Main category: cs.RO

TL;DR: 本文针对机器人通信中常用的CSMA协议在高流量下存在严重的碰撞与时延问题，提出了一种兼容IEEE 802.11的混合TDMA/CSMA协议，有效提升关键任务命令的实时性能。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在制造业、医疗和自动化等领域的应用增加，实时控制对于保障操作的效率与安全变得极为重要。现有通信协议（如CSMA）在多机器人高并发通信时易出现碰撞和延迟，导致控制命令无法准时送达，影响系统稳定性。因此，需要改进通信协议以满足严苛的实时性和QoS需求。

Method: 作者设计了一种与IEEE 802.11兼容的混合TDMA/CSMA协议。该协议通过将确定性的TDMA时隙调度和CSMA的自适应性结合，实现对于异构流量的高效管理。关键创新包括：基于PTP的亚微秒级时隙同步、三段式超级帧与动态TDMA时隙分配、以及信标-NAV机制对关键通信会话的保护。系统在SDR平台和ROS仿真环境下进行了验证。

Result: 实验表明，新协议相比传统CSMA方案，任务截止时间丢包减少93%，在高速度机器人路径跟踪模拟中RMSE轨迹误差降低最高可达90%，且对非关键流量的吞吐影响在±2%以内。

Conclusion: 该混合协议兼容现有WiFi标准，可显著提升机器人在任务关键通信下的实时性和可靠性，满足实际应用中对高安全、高效率控制的需求。

Abstract: Recent progress in robotics has underscored the demand for real-time control
in applications such as manufacturing, healthcare, and autonomous systems,
where the timely delivery of mission-critical commands under heterogeneous
robotic traffic is paramount for operational efficacy and safety. In these
scenarios, mission-critical traffic follows a strict deadline-constrained
communication pattern: commands must arrive within defined QoS deadlines,
otherwise late arrivals can degrade performance or destabilize control loops.In
this work, we demonstrate on a real-time SDR platform that CSMA, widely adopted
in robotic communications,suffers severe degradation under high robot traffic
loads, with contention-induced collisions and delays disrupting the on-time
arrival of mission-critical packets. To address this problem, we propose an
IEEE 802.11-compatible hybrid TDMA/CSMA protocol that combines TDMA's
deterministic slot scheduling with CSMA's adaptability for heterogeneous robot
traffic.The protocol achieves collision-free, low-latency mission-critical
command delivery and IEEE 802.11 compatibility through the synergistic
integration of sub-microsecond PTP-based slot synchronization-essential for
establishing precise timing for TDMA, a three-session superframe with dynamic
TDMA allocation for structured and adaptable traffic management,and beacon-NAV
protection to preemptively secure these critical communication sessions from
interference. Emulation experiments on real-time SDR testbed and Robot
Operating System (ROS) simulation show that the proposed protocol reduces
missed-deadline errors by 93% compared to the CSMA baseline. In high-speed
robot path-tracking ROS simulations, the protocol lowers Root Mean Square (RMS)
trajectory error by up to 90% compared with a CSMA baseline, all while
maintaining throughput for non-critical traffic within +-2%.

</details>


### [256] [Learning in ImaginationLand: Omnidirectional Policies through 3D Generative Models (OP-Gen)](https://arxiv.org/abs/2509.06191)
*Yifei Ren,Edward Johns*

Main category: cs.RO

TL;DR: 利用3D生成模型，将单次演示扩展成多角度数据，从而显著提升机器人策略泛化能力，仅需少量演示即可胜过传统数据增强方法。


<details>
  <summary>Details</summary>
Motivation: 现有机器人学习策略通常需要大量演示样本，尤其是在希望机器人能从多种起始状态完成任务时，数据收集成本极高。3D生成模型正好能凭少量视图重建出完整三维物体，激发了其辅助机器人数据增强的新可能。

Method: 采用3D生成模型，从单次真实演示中生成对象的多视角3D外观，基于这些虚拟数据训练全方位（omnidirctional）策略，使机器人能从更多初始状态执行任务。通过设计多样实验和变量，分析不同实现对策略表现的影响，并与其他数据增强方法做对比。

Result: 机器人使用该数据增强方式后，即便从与演示完全不同（甚至对侧）的起始位点，也能顺利完成任务，如抓取、开抽屉、扔垃圾等，在多个任务里效果显著优于现有数据增强基线。

Conclusion: 利用3D生成模型增强演示数据，有效减少了策略学习所需演示数量，提升了策略的泛化性和任务成功率。该方法优于传统数据增强技术，在机器人广泛应用和低成本泛化方面意义重大。

Abstract: Recent 3D generative models, which are capable of generating full object
shapes from just a few images, now open up new opportunities in robotics. In
this work, we show that 3D generative models can be used to augment a dataset
from a single real-world demonstration, after which an omnidirectional policy
can be learned within this imagined dataset. We found that this enables a robot
to perform a task when initialised from states very far from those observed
during the demonstration, including starting from the opposite side of the
object relative to the real-world demonstration, significantly reducing the
number of demonstrations required for policy learning. Through several
real-world experiments across tasks such as grasping objects, opening a drawer,
and placing trash into a bin, we study these omnidirectional policies by
investigating the effect of various design choices on policy behaviour, and we
show superior performance to recent baselines which use alternative methods for
data augmentation.

</details>


### [257] [Grasp-MPC: Closed-Loop Visual Grasping via Value-Guided Model Predictive Control](https://arxiv.org/abs/2509.06201)
*Jun Yamada,Adithyavairavan Murali,Ajay Mandlekar,Clemens Eppner,Ingmar Posner,Balakumar Sundaralingam*

Main category: cs.RO

TL;DR: 论文提出了一种名为Grasp-MPC的闭环6自由度视觉抓取策略，显著提升了机器人在杂乱环境下对新颖物体的抓取成功率。


<details>
  <summary>Details</summary>
Motivation: 当前抓取方法在复杂、杂乱环境下容易因抓取预测误差和物体位姿变化而失败，尤其是开环方法在此环境表现不佳，闭环方法则普遍泛化能力弱。亟需一种能兼具泛化性和鲁棒性的机器人抓取策略。

Method: 提出Grasp-MPC，融合了基于视觉观测的大规模合成数据训练的价值函数，并将该价值函数与增加避障、平滑性的代价项共同融合到MPC（模型预测控制）框架，实现鲁棒、反应式的闭环抓取。

Result: 在FetchBench平台和真实多样化环境中测试，Grasp-MPC在模拟和现实中分别提升了最高32.6%和33.3%的抓取成功率，优于开环、扩散策略、变换器策略和IQL等现有方法。

Conclusion: Grasp-MPC不仅解决了传统抓取方法在复杂环境中的不足，同时可泛化至新颖物体与真实场景，有望推动机器人实际应用中的抓取技术进步。

Abstract: Grasping of diverse objects in unstructured environments remains a
significant challenge. Open-loop grasping methods, effective in controlled
settings, struggle in cluttered environments. Grasp prediction errors and
object pose changes during grasping are the main causes of failure. In
contrast, closed-loop methods address these challenges in simplified settings
(e.g., single object on a table) on a limited set of objects, with no path to
generalization. We propose Grasp-MPC, a closed-loop 6-DoF vision-based grasping
policy designed for robust and reactive grasping of novel objects in cluttered
environments. Grasp-MPC incorporates a value function, trained on visual
observations from a large-scale synthetic dataset of 2 million grasp
trajectories that include successful and failed attempts. We deploy this
learned value function in an MPC framework in combination with other cost terms
that encourage collision avoidance and smooth execution. We evaluate Grasp-MPC
on FetchBench and real-world settings across diverse environments. Grasp-MPC
improves grasp success rates by up to 32.6% in simulation and 33.3% in
real-world noisy conditions, outperforming open-loop, diffusion policy,
transformer policy, and IQL approaches. Videos and more at
http://grasp-mpc.github.io.

</details>


### [258] [O$^3$Afford: One-Shot 3D Object-to-Object Affordance Grounding for Generalizable Robotic Manipulation](https://arxiv.org/abs/2509.06233)
*Tongxuan Tian,Xuhui Kang,Yen-Ling Kuo*

Main category: cs.RO

TL;DR: 该论文提出了一种全新的单样本3D物体间可供性学习方法，提升了机器人操作任务中理解和推理物体互动关系的能力，实验结果优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 当前大多数可供性研究集中在单一物体上，忽视了真实场景中常见的物体对之间的关系。此外，数据受限条件下，如何泛化到新物体/类别也是一大难题。

Method: 作者借鉴了2D视觉基础模型的few-shot学习方法，提出结合点云几何表达与视觉语义特征的单样本3D物体-物体可供性学习管道，并将该3D表达与大语言模型结合，辅助其生成具体的机器人任务约束函数。

Result: 在3D物体-物体可供性识别和机器人操作实验中，该方法（O$^3$Afford）在准确率和泛化能力上均明显优于现有基线。

Conclusion: 提出的方法实现了数据高效、泛化性强的物体对可供性学习，并增强了大语言模型在机器人任务规划中的推理能力，在现实机器人操作任务中具有较高应用潜力。

Abstract: Grounding object affordance is fundamental to robotic manipulation as it
establishes the critical link between perception and action among interacting
objects. However, prior works predominantly focus on predicting single-object
affordance, overlooking the fact that most real-world interactions involve
relationships between pairs of objects. In this work, we address the challenge
of object-to-object affordance grounding under limited data contraints.
Inspired by recent advances in few-shot learning with 2D vision foundation
models, we propose a novel one-shot 3D object-to-object affordance learning
approach for robotic manipulation. Semantic features from vision foundation
models combined with point cloud representation for geometric understanding
enable our one-shot learning pipeline to generalize effectively to novel
objects and categories. We further integrate our 3D affordance representation
with large language models (LLMs) for robotics manipulation, significantly
enhancing LLMs' capability to comprehend and reason about object interactions
when generating task-specific constraint functions. Our experiments on 3D
object-to-object affordance grounding and robotic manipulation demonstrate that
our O$^3$Afford significantly outperforms existing baselines in terms of both
accuracy and generalization capability.

</details>


### [259] [DCReg: Decoupled Characterization for Efficient Degenerate LiDAR Registration](https://arxiv.org/abs/2509.06285)
*Xiangcheng Hu,Xieyuanli Chen,Mingkai Jia,Jin Wu,Ping Tan,Steven L. Waslander*

Main category: cs.RO

TL;DR: 本文提出了一种名为DCReg的新方法，系统性地解决了激光雷达点云配准在退化或狭窄环境下的不适定问题，大幅提升了定位精度和优化效率。


<details>
  <summary>Details</summary>
Motivation: 现有激光雷达点云配准方法在出现几何退化或环境狭小情况下，容易产生配准不稳定、精度下降的问题。过去的方法在这一场景下无法有效检测并解决不适定的核心挑战。

Method: 提出DCReg框架：1）利用Schur补分解对Hessian矩阵进行分解，将配准任务在旋转与平移子空间解耦，消除常规分析中的耦合效应，便于发现退化模式；2）在解耦后的子空间，基于特征空间与实际运动方向的定量映射，揭示受约束不足的具体运动分量；3）根据上述识别，以新颖的预处理器仅对不适定方向进行针对性稳定化处理，且保留可观测空间的全部信息，便于高效的优化。实现了物理可解释的参数化预处理协同共轭梯度法。

Result: 在多个不同环境下，DCReg在定位精度上相比最新方法提升20%~50%，优化速度快5-100倍。

Conclusion: DCReg为点云配准中的退化与不适定问题提供了可检测、可解释且高效的系统性解决方案，显著提升鲁棒性与效率，具有实际工程推广价值。

Abstract: LiDAR point cloud registration is fundamental to robotic perception and
navigation. However, in geometrically degenerate or narrow environments,
registration problems become ill-conditioned, leading to unstable solutions and
degraded accuracy. While existing approaches attempt to handle these issues,
they fail to address the core challenge: accurately detection, interpret, and
resolve this ill-conditioning, leading to missed detections or corrupted
solutions. In this study, we introduce DCReg, a principled framework that
systematically addresses the ill-conditioned registration problems through
three integrated innovations. First, DCReg achieves reliable ill-conditioning
detection by employing a Schur complement decomposition to the hessian matrix.
This technique decouples the registration problem into clean rotational and
translational subspaces, eliminating coupling effects that mask degeneracy
patterns in conventional analyses. Second, within these cleanly subspaces, we
develop quantitative characterization techniques that establish explicit
mappings between mathematical eigenspaces and physical motion directions,
providing actionable insights about which specific motions lack constraints.
Finally, leveraging this clean subspace, we design a targeted mitigation
strategy: a novel preconditioner that selectively stabilizes only the
identified ill-conditioned directions while preserving all well-constrained
information in observable space. This enables efficient and robust optimization
via the Preconditioned Conjugate Gradient method with a single physical
interpretable parameter. Extensive experiments demonstrate DCReg achieves at
least 20% - 50% improvement in localization accuracy and 5-100 times speedup
over state-of-the-art methods across diverse environments. Our implementation
will be available at https://github.com/JokerJohn/DCReg.

</details>


### [260] [Learning to Walk with Less: a Dyna-Style Approach to Quadrupedal Locomotion](https://arxiv.org/abs/2509.06296)
*Francisco Affonso,Felipe Andrade G. Tommaselli,Juliano Negri,Vivian S. Medeiros,Mateus V. Gasparino,Girish Chowdhary,Marcelo Becker*

Main category: cs.RO

TL;DR: 本文提出了一种基于模型的强化学习（MBRL）方法，通过在PPO控制器的标准采样轨迹后追加模型生成的短期虚拟数据，提高了四足机器人运动控制的数据效率。在仿真环境（Unitree Go1）证明了该方法能在减少仿真步数的同时提升策略的性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有基于RL的四足机器人运动控制方法数据利用率较低，需要大量交互才能获得强健策略。因此作者期望通过模型预测为RL过程引入更多高质量虚拟采样，从而减少真实或高仿真采样依赖，提高训练效率。

Method: 采用Dyna-Style的MBRL思路，在每次真实轨迹采样后，使用与策略并行训练的预测模型生成若干步短期虚拟转移，将其追加到轨迹末尾，并通过调度策略（根据策略更新轮次）逐步加大虚拟步数比例。通过消融实验确定最优轨迹长度和训练参数。

Result: 在Unitree Go1仿真实验中，部分用虚拟步替换真实仿真步，策略回报提升、方差降低，展现比传统RL更优的数据效率。策略还具有更强的广域运动指令跟踪能力。

Conclusion: 将预测模型生成的短期虚拟数据整合进RL过程，可有效提升四足运动控制策略的性能与泛化能力，并显著减少训练中对实际采样的需求，适合推广到数据昂贵的实际机器人场景。

Abstract: Traditional RL-based locomotion controllers often suffer from low data
efficiency, requiring extensive interaction to achieve robust performance. We
present a model-based reinforcement learning (MBRL) framework that improves
sample efficiency for quadrupedal locomotion by appending synthetic data to the
end of standard rollouts in PPO-based controllers, following the Dyna-Style
paradigm. A predictive model, trained alongside the policy, generates
short-horizon synthetic transitions that are gradually integrated using a
scheduling strategy based on the policy update iterations. Through an ablation
study, we identified a strong correlation between sample efficiency and rollout
length, which guided the design of our experiments. We validated our approach
in simulation on the Unitree Go1 robot and showed that replacing part of the
simulated steps with synthetic ones not only mimics extended rollouts but also
improves policy return and reduces variance. Finally, we demonstrate that this
improvement transfers to the ability to track a wide range of locomotion
commands using fewer simulated steps.

</details>


### [261] [Towards bridging the gap: Systematic sim-to-real transfer for diverse legged robots](https://arxiv.org/abs/2509.06342)
*Filip Bjelonic,Fabian Tischhauser,Marco Hutter*

Main category: cs.RO

TL;DR: 提出了一种结合仿真到现实强化学习与物理驱动能耗建模的新框架，实现腿式机器人高效、可靠的能量节约型运动控制，并显著提升了实际转移效果。


<details>
  <summary>Details</summary>
Motivation: 现有通过仿真训练的腿式机器人控制器在现实环境中可靠性不足，且普遍忽视了执行器的能量损失或依赖复杂的人为奖励设计，导致能效与实用性受限。

Method: 本方法集成了基于永磁同步电机的能耗物理模型和仿真到现实的强化学习，通过精简参数和基于第一性原理能耗损失的四项奖励机制，综合平衡了电气和机械的损耗，并通过参数辨识实现与真实系统的对齐，提高了策略转移的可靠性。

Result: 在10种机器人平台（包含3个主要测试平台和7种补充测试）上进行了验证。新方法实现了无需对动力学参数随机化的高可靠策略转移，相较于最先进方法，在ANYmal机器人上整体现本增加32%的能量效率（运输成本降低至1.27）。

Conclusion: 新框架显著提高了腿式机器人能效及仿真到现实的策略转移效果，对能耗建模和实际部署有直接促进作用，所用代码、模型及数据即将开源。

Abstract: Legged robots must achieve both robust locomotion and energy efficiency to be
practical in real-world environments. Yet controllers trained in simulation
often fail to transfer reliably, and most existing approaches neglect
actuator-specific energy losses or depend on complex, hand-tuned reward
formulations. We propose a framework that integrates sim-to-real reinforcement
learning with a physics-grounded energy model for permanent magnet synchronous
motors. The framework requires a minimal parameter set to capture the
simulation-to-reality gap and employs a compact four-term reward with a
first-principle-based energetic loss formulation that balances electrical and
mechanical dissipation. We evaluate and validate the approach through a
bottom-up dynamic parameter identification study, spanning actuators,
full-robot in-air trajectories and on-ground locomotion. The framework is
tested on three primary platforms and deployed on ten additional robots,
demonstrating reliable policy transfer without randomization of dynamic
parameters. Our method improves energetic efficiency over state-of-the-art
methods, achieving a 32 percent reduction in the full Cost of Transport of
ANYmal (value 1.27). All code, models, and datasets will be released.

</details>


### [262] [Adaptive Evolution Factor Risk Ellipse Framework for Reliable and Safe Autonomous Driving](https://arxiv.org/abs/2509.06375)
*Fujiang Yuan,Zhen Tian,Yangfan He,Guojian Zou,Chunhong Yuan,Yanhong Peng,Zhihao Lin*

Main category: cs.RO

TL;DR: 该论文提出一种自适应风险建模的算法，提升了自动驾驶车辆在复杂交互场景中的安全性、效率与舒适性。方法动态调整风险区域，并与MPC控制策略结合，实现平稳、高速且无碰撞的导航。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶风险建模方法存在安全性、泛化性与计算效率等方面的限制。传统基于模型的方法过于保守且计算复杂，基于学习的方法则需要大量数据且可解释性差。RPF方法虽轻量但无法动态应对复杂交通环境。

Method: 提出进化型风险势场（ERPF）方法，利用历史障碍物接近性数据，动态调整风险评估。设计风险椭圆体，将纵向可达性和横向不确定性统一建模，并引入基于TTC和TWH的演化因子，实时调整风险区域。ERPF与MPC框架无缝结合，实现对车辆决策的实时自适应优化。

Result: 实验表明ERPF-MPC方案在复杂交互环境下可实现更平滑的轨迹、更高的平均速度以及无碰撞通行，优于传统方法。

Conclusion: ERPF-MPC为自动驾驶复杂交互环境提供了高效、鲁棒且自适应的风险管理控制方案，显著提升了车辆在现实复杂交通中的实际表现。

Abstract: In recent years, ensuring safety, efficiency, and comfort in interactive
autonomous driving has become a critical challenge. Traditional model-based
techniques, such as game-theoretic methods and robust control, are often overly
conservative or computationally intensive. Conversely, learning-based
approaches typically require extensive training data and frequently exhibit
limited interpretability and generalizability. Simpler strategies, such as Risk
Potential Fields (RPF), provide lightweight alternatives with minimal data
demands but are inherently static and struggle to adapt effectively to dynamic
traffic conditions. To overcome these limitations, we propose the Evolutionary
Risk Potential Field (ERPF), a novel approach that dynamically updates risk
assessments in dynamical scenarios based on historical obstacle proximity data.
We introduce a Risk-Ellipse construct that combines longitudinal reach and
lateral uncertainty into a unified spatial temporal collision envelope.
Additionally, we define an adaptive Evolution Factor metric, computed through
sigmoid normalization of Time to Collision (TTC) and Time-Window-of-Hazard
(TWH), which dynamically adjusts the dimensions of the ellipse axes in real
time. This adaptive risk metric is integrated seamlessly into a Model
Predictive Control (MPC) framework, enabling autonomous vehicles to proactively
address complex interactive driving scenarios in terms of uncertain driving of
surrounding vehicles. Comprehensive comparative experiments demonstrate that
our ERPF-MPC approach consistently achieves smoother trajectories, higher
average speeds, and collision-free navigation, offering a robust and adaptive
solution suitable for complex interactive driving environments.

</details>


### [263] [Safety Meets Speed: Accelerated Neural MPC with Safety Guarantees and No Retraining](https://arxiv.org/abs/2509.06404)
*Kaikai Wang,Tianxun Li,Liang Xu,Qinglei Hu,Keyou You*

Main category: cs.RO

TL;DR: 该论文提出了一种名为BAN-MPC（Barrier-integrated Adaptive Neural Model Predictive Control）的新型模型预测控制框架，结合了神经网络的高效计算与MPC的约束能力，并引入控制屏障函数确保安全性。通过神经网络降低了在线计算量，并能自适应应对模型参数变化，显著提高了在嵌入式设备上的控制效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 传统的MPC虽然可以通过约束来保证安全，但由于实时计算量较大，在嵌入式设备上难以满足计算资源限制，因此需要更高效且能保证安全的方法。

Method: 该方法用神经网络离线学习得到的价值函数融入短时域MPC目标函数中，同时引入控制屏障函数（CBFs）代替欧氏距离进行碰撞规避；另用一个神经网络学习价值函数对模型参数的敏感性，参数变化时能自适应调整，无需重新训练。

Result: 在Jetson Nano上的硬件在环实验表明，该方法比传统MPC快200倍，并且在模型参数发生15%内变化时，仍能实现小于5%的控制误差和完全避障。

Conclusion: BAN-MPC框架为嵌入式平台上的MPC提供了高效且安全的替代方案，显著降低了在线和离线计算开销，提高了鲁棒性和实用性。

Abstract: While Model Predictive Control (MPC) enforces safety via constraints, its
real-time execution can exceed embedded compute budgets. We propose a
Barrier-integrated Adaptive Neural Model Predictive Control (BAN-MPC) framework
that synergizes neural networks' fast computation with MPC's
constraint-handling capability. To ensure strict safety, we replace traditional
Euclidean distance with Control Barrier Functions (CBFs) for collision
avoidance. We integrate an offline-learned neural value function into the
optimization objective of a Short-horizon MPC, substantially reducing online
computational complexity. Additionally, we use a second neural network to learn
the sensitivity of the value function to system parameters, and adaptively
adjust the neural value function based on this neural sensitivity when model
parameters change, eliminating the need for retraining and reducing offline
computation costs. The hardware in-the-loop (HIL) experiments on Jetson Nano
show that BAN-MPC solves 200 times faster than traditional MPC, enabling
collision-free navigation with control error below 5\% under model parameter
variations within 15\%, making it an effective embedded MPC alternative.

</details>


### [264] [Real-time Photorealistic Mapping for Situational Awareness in Robot Teleoperation](https://arxiv.org/abs/2509.06433)
*Ian Page,Pierre Susbielle,Olivier Aycard,Pierre-Brice Wieber*

Main category: cs.RO

TL;DR: 本文提出了一种高效的GPU加速的3D制图方法，将高斯泼溅SLAM与在线遥操作系统结合，在未知环境下实现更高效的远程遥操作，并通过实际无人机实验验证了该方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 在未知环境下，远程遥操作受限于操作人员难以及时了解现场布局，现有在线3D地图方法由于计算瓶颈，难以保证实时和高精度，导致操作效率低下，这推动了新方法的提出。

Method: 作者提出了一种基于GPU的模块化集成方法，将最新的高斯泼溅SLAM算法与在线遥操作系统高效结合，实现实时生成高质量、视觉精准的3D地图。

Result: 实验在实际无人机平台上进行，与现有最先进方法对比，其方案提升了决策速度和环境交互的准确性，极大提高了遥操作效率。

Conclusion: 该系统实现了光真实感制图和实时性能的无缝结合，可显著增强遥操作在陌生环境下的效率与效果，具有广泛应用潜力。

Abstract: Achieving efficient remote teleoperation is particularly challenging in
unknown environments, as the teleoperator must rapidly build an understanding
of the site's layout. Online 3D mapping is a proven strategy to tackle this
challenge, as it enables the teleoperator to progressively explore the site
from multiple perspectives. However, traditional online map-based teleoperation
systems struggle to generate visually accurate 3D maps in real-time due to the
high computational cost involved, leading to poor teleoperation performances.
In this work, we propose a solution to improve teleoperation efficiency in
unknown environments. Our approach proposes a novel, modular and efficient
GPU-based integration between recent advancement in gaussian splatting SLAM and
existing online map-based teleoperation systems. We compare the proposed
solution against state-of-the-art teleoperation systems and validate its
performances through real-world experiments using an aerial vehicle. The
results show significant improvements in decision-making speed and more
accurate interaction with the environment, leading to greater teleoperation
efficiency. In doing so, our system enhances remote teleoperation by seamlessly
integrating photorealistic mapping generation with real-time performances,
enabling effective teleoperation in unfamiliar environments.

</details>


### [265] [Interactive Shaping of Granular Media Using Reinforcement Learning](https://arxiv.org/abs/2509.06469)
*Benedikt Kreis,Malte Mosbach,Anny Ripke,Muhammad Ehsan Ullah,Sven Behnke,Maren Bennewitz*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习（RL）的框架，使机器人臂能够自主操纵如沙子等颗粒介质，精确塑造为目标形状，并且有效优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 在建筑、挖掘和增材制造等领域，能够自主操作和塑形颗粒物质（如沙子）具有重要意义。但颗粒材料因其高维状态空间和复杂动力学而极难精准操控，传统基于规则的方法需要大量人工设计且效果有限。

Method: 作者设计了一个强化学习框架，利用带有立方体末端执行器的机械臂和双目摄像头进行观测，通过奖励函数和紧凑的观测空间设计，引导机械臂学习如何将颗粒介质塑形成目标结构，并通过消融实验验证了设计的合理性。

Result: 实验结果表明，该RL方法能训练出视觉策略，机器人成功实现了颗粒介质的高效操纵。在真实场景部署时，RL方案表现优于两种基线方法。

Conclusion: 基于强化学习的策略可以切实提升机器人对颗粒材料的操控能力，并具有良好的泛化和实际应用价值，为相关领域提供了新方法。

Abstract: Autonomous manipulation of granular media, such as sand, is crucial for
applications in construction, excavation, and additive manufacturing. However,
shaping granular materials presents unique challenges due to their
high-dimensional configuration space and complex dynamics, where traditional
rule-based approaches struggle without extensive engineering efforts.
Reinforcement learning (RL) offers a promising alternative by enabling agents
to learn adaptive manipulation strategies through trial and error. In this
work, we present an RL framework that enables a robotic arm with a cubic
end-effector and a stereo camera to shape granular media into desired target
structures. We show the importance of compact observations and concise reward
formulations for the large configuration space, validating our design choices
with an ablation study. Our results demonstrate the effectiveness of the
proposed approach for the training of visual policies that manipulate granular
media including their real-world deployment, outperforming two baseline
approaches.

</details>


### [266] [Event Driven CBBA with Reduced Communication](https://arxiv.org/abs/2509.06481)
*Vinita Sao,Tu Dac Ho,Sujoy Bhore,P. B. Sujit*

Main category: cs.RO

TL;DR: 论文提出了一种基于事件驱动的通信机制（ED-CBBA），在保持CBBA算法收敛性和性能上限的前提下，大幅减少了多机器人任务分配过程中的通信量。


<details>
  <summary>Details</summary>
Motivation: 在多无人机监控、搜救等场景下，需多机器人协同完成多任务。但受限于机器人通信范围，去中心化任务分配成为关键。主流的CBBA算法虽然理论有保障，却依赖持续通信，易导致网络拥堵和数据丢包，影响实际性能。

Method: 作者提出引入事件驱动机制到CBBA（ED-CBBA），只在关键事件发生时进行通信，理论分析和蒙特卡洛仿真验证该策略下的收敛性和任务分配质量。

Result: 理论证明ED-CBBA的解质量与传统CBBA算法一致；实验中在不同任务、机器人及捆绑数变动下，ED-CBBA消息传输量最高减少52%。

Conclusion: ED-CBBA在确保任务分配质量和收敛性的同时，显著降低了通信负担，对实际多机器人系统更具实用性。

Abstract: In various scenarios such as multi-drone surveillance and search-and-rescue
operations, deploying multiple robots is essential to accomplish multiple tasks
at once. Due to the limited communication range of these vehicles, a
decentralised task allocation algorithm is crucial for effective task
distribution among robots. The consensus-based bundle algorithm (CBBA) has been
promising for multi-robot operation, offering theoretical guarantees. However,
CBBA demands continuous communication, leading to potential congestion and
packet loss that can hinder performance. In this study, we introduce an
event-driven communication mechanism designed to address these communication
challenges while maintaining the convergence and performance bounds of CBBA. We
demonstrate theoretically that the solution quality matches that of CBBA and
validate the approach with Monte-Carlo simulations across varying targets,
agents, and bundles. Results indicate that the proposed algorithm (ED-CBBA) can
reduce message transmissions by up to 52%.

</details>


### [267] [Co-Located VR with Hybrid SLAM-based HMD Tracking and Motion Capture Synchronization](https://arxiv.org/abs/2509.06582)
*Carlos A. Pinheiro de Sousa,Niklas Gröne,Mathias Günther,Oliver Deussen*

Main category: cs.RO

TL;DR: 本文提出了一种多用户VR同地协作框架，通过结合动作捕捉系统和基于SLAM的内向外跟踪，实现了高流畅度、低延迟且空间准确的多人虚拟现实体验。


<details>
  <summary>Details</summary>
Motivation: 现有多用户VR协作方法存在明显局限：依赖外部持续跟踪会引入延迟和抖动，单次校准则无法处理随时间产生的漂移。因此需要一种既能维持响应速度、又具备高空间一致性的新方法。

Method: 方法上，作者将本地HMD的SLAM追踪与动作捕捉结合，通常利用SLAM负责日常的快速本地定位，同时在需要时可切换/对齐到外部动作捕捉的信息以修正漂移。此外，系统支持实时姿态数据跨设备共享，以保证用户空间姿态的一致性。

Result: 实验结果显示，新框架不仅达成了自然多用户交互所需的空间精度，还在用户舒适性、系统可扩展性和健壮性等方面优于现有同类方案。

Conclusion: 新方案有效提升了多用户同地VR体验的空间对齐度和互动自然性，兼顾了低延迟、高精度和实用性，为可扩展、高质量的共空间VR协作奠定了基础。

Abstract: We introduce a multi-user VR co-location framework that synchronizes users
within a shared virtual environment aligned to physical space. Our approach
combines a motion capture system with SLAM-based inside-out tracking to deliver
smooth, high-framerate, low-latency performance. Previous methods either rely
on continuous external tracking, which introduces latency and jitter, or on
one-time calibration, which cannot correct drift over time. In contrast, our
approach combines the responsiveness of local HMD SLAM tracking with the
flexibility to realign to an external source when needed. It also supports
real-time pose sharing across devices, ensuring consistent spatial alignment
and engagement between users. Our evaluation demonstrates that our framework
achieves the spatial accuracy required for natural multi-user interaction while
offering improved comfort, scalability, and robustness over existing co-located
VR solutions.

</details>


### [268] [A Robust Approach for LiDAR-Inertial Odometry Without Sensor-Specific Modeling](https://arxiv.org/abs/2509.06593)
*Meher V. R. Malladi,Tiziano Guadagnino,Luca Lobefaro,Cyrill Stachniss*

Main category: cs.RO

TL;DR: 本文提出了一种通用、鲁棒的LiDAR-惯性测量单元（IMU）里程计系统，能够适用于多种类型和场景的传感器，在多个数据集上表现优异，并已开源。


<details>
  <summary>Details</summary>
Motivation: 现有基于传感器的里程计方法在不同传感器类型和应用场景下的泛化能力有限，且往往依赖于复杂的传感器特定建模。需要一种鲁棒、通用、易部署的感知融合方法。

Method: 提出了一种融合LiDAR和IMU的里程计系统，不依赖于具体传感器建模。与传统方法不同，该方法仅需简化的IMU运动模型，在LiDAR数据注册时采用scan-to-map方法，并引入新的正则项提升配准效果。

Result: 在多个涵盖常用机器人传感器与平台的数据集上进行了大量实验。实验结果显示该方法无需针对具体传感器调整配置即可获得一致、优异的性能，验证了其鲁棒性和通用性。

Conclusion: 所提出的方法可广泛适用于不同传感器和平台的导航任务，并提升了里程计的可靠性；论文还公开了代码，方便后续研究和实际应用。

Abstract: Accurate odometry is a critical component in a robotic navigation stack, and
subsequent modules such as planning and control often rely on an estimate of
the robot's motion. Sensor-based odometry approaches should be robust across
sensor types and deployable in different target domains, from solid-state
LiDARs mounted on cars in urban-driving scenarios to spinning LiDARs on
handheld packages used in unstructured natural environments. In this paper, we
propose a robust LiDAR-inertial odometry system that does not rely on
sensor-specific modeling. Sensor fusion techniques for LiDAR and inertial
measurement unit (IMU) data typically integrate IMU data iteratively in a
Kalman filter or use pre-integration in a factor graph framework, combined with
LiDAR scan matching often exploiting some form of feature extraction. We
propose an alternative strategy that only requires a simplified motion model
for IMU integration and directly registers LiDAR scans in a scan-to-map
approach. Our approach allows us to impose a novel regularization on the LiDAR
registration, improving the overall odometry performance. We detail extensive
experiments on a number of datasets covering a wide array of commonly used
robotic sensors and platforms. We show that our approach works with the exact
same configuration in all these scenarios, demonstrating its robustness. We
have open-sourced our implementation so that the community can build further on
our work and use it in their navigation stacks.

</details>


### [269] [LiHRA: A LiDAR-Based HRI Dataset for Automated Risk Monitoring Methods](https://arxiv.org/abs/2509.06597)
*Frederik Plahl,Georgios Katranis,Ilshat Mamaev,Andrey Morozov*

Main category: cs.RO

TL;DR: 本文提出LiHRA数据集，为人机交互中的风险监测方法开发提供多模态、高质量数据，涵盖6类典型HRI场景，支持人工智能与传统RM方法的训练与评测。


<details>
  <summary>Details</summary>
Motivation: 随着协作机器人在工业环境中日益普及，对可靠的安全系统需求增强。但欠缺捕捉现实中潜在危险事件的人机交互高质量数据集，限制了RM发展。

Method: 构建包含3D LiDAR点云、人体关键点、机器人关节状态的LiHRA多模态数据集，涵盖6种HRI场景（协作、共存、交接、表面抛光等），每种含安全与危险版本，共4,431条10Hz标签点云。同时提出基于上下文分析的场景风险定量方法。

Result: LiHRA实现高精度人、机器人与环境动态捕捉，为风险监控方法训练和评测提供了丰富资源。所提出RM方法能随时间动态量化场景风险水平。

Conclusion: LiHRA为实时风险监控与自适应安全策略研究奠定了重要基础，将推动人机协作环境中RM相关算法的发展。

Abstract: We present LiHRA, a novel dataset designed to facilitate the development of
automated, learning-based, or classical risk monitoring (RM) methods for
Human-Robot Interaction (HRI) scenarios. The growing prevalence of
collaborative robots in industrial environments has increased the need for
reliable safety systems. However, the lack of high-quality datasets that
capture realistic human-robot interactions, including potentially dangerous
events, slows development. LiHRA addresses this challenge by providing a
comprehensive, multi-modal dataset combining 3D LiDAR point clouds, human body
keypoints, and robot joint states, capturing the complete spatial and dynamic
context of human-robot collaboration. This combination of modalities allows for
precise tracking of human movement, robot actions, and environmental
conditions, enabling accurate RM during collaborative tasks. The LiHRA dataset
covers six representative HRI scenarios involving collaborative and coexistent
tasks, object handovers, and surface polishing, with safe and hazardous
versions of each scenario. In total, the data set includes 4,431 labeled point
clouds recorded at 10 Hz, providing a rich resource for training and
benchmarking classical and AI-driven RM algorithms. Finally, to demonstrate
LiHRA's utility, we introduce an RM method that quantifies the risk level in
each scenario over time. This method leverages contextual information,
including robot states and the dynamic model of the robot. With its combination
of high-resolution LiDAR data, precise human tracking, robot state data, and
realistic collision events, LiHRA offers an essential foundation for future
research into real-time RM and adaptive safety strategies in human-robot
workspaces.

</details>


### [270] [T-araVLN: Translator for Agricultural Robotic Agents on Vision-and-Language Navigation](https://arxiv.org/abs/2509.06644)
*Xiaobei Zhao,Xingqi Lyu,Xiang Li*

Main category: cs.RO

TL;DR: 本文提出了一种新方法T-araVLN，通过引入Instruction Translator模块，提升农业机器人在视觉-语言导航任务中的理解能力，显著提高了导航的准确率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的农业机器人虽然能辅助多种农业任务，但在移动时仍依赖人工或固定线路。早期的AgriVLN方法在理解简单指令上有效，但对复杂指令常出错，因此需要提升机器人对自然语言复杂指令的理解。

Method: 提出了T-araVLN方法，引入Instruction Translator模块，将原始导航指令翻译成更精炼、明确的表达，使机器人能更准确理解和执行复杂指令，并在A2A基准上进行验证。

Result: T-araVLN方法在A2A基准测试上，将成功率（SR）从0.47提升到0.63，将导航误差（NE）从2.91米降低到2.28米，达到了当前该领域最优性能。

Conclusion: T-araVLN通过提升指令理解能力，有效推动了农业机器人在视觉-语言导航任务的实际应用，改善了其执行复杂导航任务的能力，具备实际推广价值。

Abstract: Agricultural robotic agents have been becoming powerful helpers in a wide
range of agricultural tasks, nevertheless, still heavily rely on manual
operation or untransportable railway for movement. The AgriVLN method and the
A2A benchmark pioneeringly extend Vision-and-Language Navigation (VLN) to the
agricultural domain, enabling agents navigate to the target position following
the natural language instructions. AgriVLN effectively understands the simple
instructions, however, often misunderstands the complicated instructions. To
bridge this gap, we propose the method of Translator for Agricultural Robotic
Agents on Vision-and-Language Navigation (T-araVLN), in which the Instruction
Translator module translates the original instruction to be both refined and
precise. Being evaluated on the A2A benchmark, our T-araVLN effectively
improves SR from 0.47 to 0.63 and reduces NE from 2.91m to 2.28m, demonstrating
the state-of-the-art performance in the agricultural domain. Code:
https://github.com/AlexTraveling/T-araVLN.

</details>


### [271] [An Adaptive Coverage Control Approach for Multiple Autonomous Off-road Vehicles in Dynamic Agricultural Fields](https://arxiv.org/abs/2509.06682)
*Sajad Ahmadi,Mohammadreza Davoodi,Javad Mohammadpour Velni*

Main category: cs.RO

TL;DR: 本文提出了一种适用于动态农业环境的自适应覆盖控制方法，结合无人机实时监测与地面机器人路径动态规划以提升效率。


<details>
  <summary>Details</summary>
Motivation: 传统的覆盖控制多假设环境静态，不适用于农业中不断变化的障碍与地形。

Method: 通过将环境建模为加权有向图，利用无人机实时更新边权重进行障碍物检测和地形评估，结合Voronoi分区、自适应权重与基于代价的路径优化。

Result: 仿真结果显示该方法能有效提升路径规划质量、降低行进成本，并能在动态障碍和复杂地形下维持稳定覆盖。

Conclusion: 该框架有助于无人地面车队在现实农业场景下实现高效、可靠的自适应路径规划和区域覆盖。

Abstract: This paper presents an adaptive coverage control method for a fleet of
off-road and Unmanned Ground Vehicles (UGVs) operating in dynamic
(time-varying) agricultural environments. Traditional coverage control
approaches often assume static conditions, making them unsuitable for
real-world farming scenarios where obstacles, such as moving machinery and
uneven terrains, create continuous challenges. To address this, we propose a
real-time path planning framework that integrates Unmanned Aerial Vehicles
(UAVs) for obstacle detection and terrain assessment, allowing UGVs to
dynamically adjust their coverage paths. The environment is modeled as a
weighted directed graph, where the edge weights are continuously updated based
on the UAV observations to reflect obstacle motion and terrain variations. The
proposed approach incorporates Voronoi-based partitioning, adaptive edge weight
assignment, and cost-based path optimization to enhance navigation efficiency.
Simulation results demonstrate the effectiveness of the proposed method in
improving path planning, reducing traversal costs, and maintaining robust
coverage in the presence of dynamic obstacles and muddy terrains.

</details>


### [272] [Safe Robust Predictive Control-based Motion Planning of Automated Surface Vessels in Inland Waterways](https://arxiv.org/abs/2509.06687)
*Sajad Ahmadi,Hossein Nejatbakhsh Esfahani,Javad Mohammadpour Velni*

Main category: cs.RO

TL;DR: 本文提出了一种结合鲁棒模型预测控制（RMPC）和控制屏障函数（CBF）的自动化水面船舶（ASV）运动规划方法，有效提升了狭窄内河水道中ASV的安全性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在内河水道中部署自动导航水面船舶有助于缓解道路交通压力并减少排放，但现有自主导航方法在狭窄且流量大的水路环境下尚不足够鲁棒或精准，因此亟需更为安全有效的导航方法。

Method: 提出将鲁棒模型预测控制（RMPC）与控制屏障函数（CBF）结合，将河道边界和障碍物直接当作安全约束纳入控制设计框架，实现安全与鲁棒共存的运动规划。

Result: 仿真结果显示，该方法能在真实复杂环境下安全引导ASV，相较于同类顶尖方法展现出更高的安全性和适应性。

Conclusion: 所提出方法有效提升ASV在复杂内河水道中的安全导航能力，对推动自动水面船舶的实际应用具有重要意义。

Abstract: Deploying self-navigating surface vessels in inland waterways offers a
sustainable alternative to reduce road traffic congestion and emissions.
However, navigating confined waterways presents unique challenges, including
narrow channels, higher traffic density, and hydrodynamic disturbances.
Existing methods for autonomous vessel navigation often lack the robustness or
precision required for such environments. This paper presents a new motion
planning approach for Automated Surface Vessels (ASVs) using Robust Model
Predictive Control (RMPC) combined with Control Barrier Functions (CBFs). By
incorporating channel borders and obstacles as safety constraints within the
control design framework, the proposed method ensures both collision avoidance
and robust navigation on complex waterways. Simulation results demonstrate the
efficacy of the proposed method in safely guiding ASVs under realistic
conditions, highlighting its improved safety and adaptability compared to the
state-of-the-art.

</details>


### [273] [Embodied Hazard Mitigation using Vision-Language Models for Autonomous Mobile Robots](https://arxiv.org/abs/2509.06768)
*Oluwadamilola Sotomi,Devika Kodi,Kiruthiga Chandra Shekar,Aliasghar Arab*

Main category: cs.RO

TL;DR: 本文提出了一种结合视觉-语言模型和大语言模型的多模态异常检测与缓解系统，实现了机器人在动态环境中对异常状况的实时感知、报告与自动响应。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在城市与复杂环境中自主运行，对异常识别与主动缓解的诉求日益增加，旨在提升其安全性和连续作业能力。

Method: 系统整合了视觉-语言感知与大语言模型，用以多模态地探测、解释和报告危险及冲突，并在决策机制中引入了异常类型的区分，从而触发针对性缓解策略。采用边缘AI硬件实现低延迟实时处理。

Result: 用户研究（n=30）显示，异常检测准确率达91.2%，且系统响应时间较低，验证了方法的有效性。

Conclusion: 论文证明了多模态AI集成可提升机器人在动态复杂环境中的异常识别与缓解能力，并兼具高准确率和低延迟，具有实际应用前景。

Abstract: Autonomous robots operating in dynamic environments should identify and
report anomalies. Embodying proactive mitigation improves safety and
operational continuity. This paper presents a multimodal anomaly detection and
mitigation system that integrates vision-language models and large language
models to identify and report hazardous situations and conflicts in real-time.
The proposed system enables robots to perceive, interpret, report, and if
possible respond to urban and environmental anomalies through proactive
detection mechanisms and automated mitigation actions. A key contribution in
this paper is the integration of Hazardous and Conflict states into the robot's
decision-making framework, where each anomaly type can trigger specific
mitigation strategies. User studies (n = 30) demonstrated the effectiveness of
the system in anomaly detection with 91.2% prediction accuracy and relatively
low latency response times using edge-ai architecture.

</details>


### [274] [CRISP - Compliant ROS2 Controllers for Learning-Based Manipulation Policies and Teleoperation](https://arxiv.org/abs/2509.06819)
*Daniel San José Pro,Oliver Hausdörfer,Ralf Römer,Maximilian Dösch,Martin Schuck,Angela P. Schöllig*

Main category: cs.RO

TL;DR: 本文提出了CRISP，一种为ROS2标准设计的轻量级C++合规控制器，支持顺畅对接高层学习控制器和仿真/硬件数据采集，便于在各种机械臂上部署学习方法。


<details>
  <summary>Details</summary>
Motivation: 许多基于学习的高层控制（如扩散策略和视觉-语言动作模型）往往输出低频或不连续的状态变化，不利于机器人实现流畅的轨迹跟踪。为解决高层命令转换为实际操作时的不顺畅、刚性大的问题，需要开发一个能平滑接轨、支持接触顺应性的低层控制器。

Method: 开发了CRISP控制器，包括笛卡尔空间和关节空间合规控制器，采用C++实现，兼容ROS2控制框架，通过Python和Gymnasium接口方便与高层学习策略和遥操作集成，支持硬件和仿真数据一致采集和策略部署。

Result: 该系统已在Franka Robotics FR3硬件，以及Kuka IIWA14、Kinova Gen3仿真器上验证。支持多种硬件快速集成和灵活部署，并实际降低了高层学习控制方法在ROS2机械臂上的应用门槛。

Conclusion: CRISP为基于学习的高层控制策略提供了高效、统一、实时的控制与数据收集方案，加速了实际机器人系统的研究和应用。

Abstract: Learning-based controllers, such as diffusion policies and vision-language
action models, often generate low-frequency or discontinuous robot state
changes. Achieving smooth reference tracking requires a low-level controller
that converts high-level targets commands into joint torques, enabling
compliant behavior during contact interactions. We present CRISP, a lightweight
C++ implementation of compliant Cartesian and joint-space controllers for the
ROS2 control standard, designed for seamless integration with high-level
learning-based policies as well as teleoperation. The controllers are
compatible with any manipulator that exposes a joint-torque interface. Through
our Python and Gymnasium interfaces, CRISP provides a unified pipeline for
recording data from hardware and simulation and deploying high-level
learning-based policies seamlessly, facilitating rapid experimentation. The
system has been validated on hardware with the Franka Robotics FR3 and in
simulation with the Kuka IIWA14 and Kinova Gen3. Designed for rapid
integration, flexible deployment, and real-time performance, our implementation
provides a unified pipeline for data collection and policy execution, lowering
the barrier to applying learning-based methods on ROS2-compatible manipulators.
Detailed documentation is available at the project website -
https://utiasDSL.github.io/crisp_controllers.

</details>


### [275] [Dynamic Modeling and Efficient Data-Driven Optimal Control for Micro Autonomous Surface Vehicles](https://arxiv.org/abs/2509.06882)
*Zhiheng Chen,Wei Wang*

Main category: cs.RO

TL;DR: 本文提出了一种基于物理与数据驱动相结合的最优控制框架，通过在线模型学习，提高了微型自主水面艇（MicroASV）在复杂环境下的跟踪精度与控制鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 微型自主水面艇由于体积小、易受干扰、动力学建模复杂，在狭窄或浅水环境及群体机器人应用领域的精确控制十分困难。本文旨在提升MicroASV在多变环境下的操控精度与自适应能力。

Method: 构建了物理驱动的微型水面艇动力学模型，并结合弱形式的在线数据驱动模型学习方法，实现对动力学参数的实时修正与自适应最优控制。

Result: 仿真结果表明，该方法在未知负载和外部扰动情况下，明显提升了MicroASV的轨迹跟踪精度和鲁棒性。

Conclusion: 数据驱动的在线学习最优控制方法能有效提升MicroASV性能，为自主水面艇可靠、精确控制提供了可行方案。

Abstract: Micro Autonomous Surface Vehicles (MicroASVs) offer significant potential for
operations in confined or shallow waters and swarm robotics applications.
However, achieving precise and robust control at such small scales remains
highly challenging, mainly due to the complexity of modeling nonlinear
hydrodynamic forces and the increased sensitivity to self-motion effects and
environmental disturbances, including waves and boundary effects in confined
spaces. This paper presents a physics-driven dynamics model for an
over-actuated MicroASV and introduces a data-driven optimal control framework
that leverages a weak formulation-based online model learning method. Our
approach continuously refines the physics-driven model in real time, enabling
adaptive control that adjusts to changing system parameters. Simulation results
demonstrate that the proposed method substantially enhances trajectory tracking
accuracy and robustness, even under unknown payloads and external disturbances.
These findings highlight the potential of data-driven online learning-based
optimal control to improve MicroASV performance, paving the way for more
reliable and precise autonomous surface vehicle operations.

</details>


### [276] [LLaDA-VLA: Vision Language Diffusion Action Models](https://arxiv.org/abs/2509.06932)
*Yuqing Wen,Hebei Li,Kefan Gu,Yucheng Zhao,Tiancai Wang,Xiaoyan Sun*

Main category: cs.RO

TL;DR: 提出了一种基于扩散模型的视觉-语言-动作（VLA）架构LLaDA-VLA，首次将预训练的扩散视觉-语言模型（d-VLM）应用于机器人操作任务，并在仿真与现实机器人上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 虽然自回归视觉-语言模型在机器人领域受到关注，但基于扩散模型的d-VLM在机器人策略学习领域尚未被很好探索，因此作者希望填补这一空白。

Method: 作者提出LLaDA-VLA，创新点包括：1）引入局部特定token分类策略，用特定动作token替代全词汇分类，降低模型适配难度；2）分层动作结构化解码，考虑动作序列内部和之间的依赖关系。

Result: LLaDA-VLA在多个仿真和真实机器人实验中表现出显著优于最新VLA模型的性能。

Conclusion: 本工作首次将d-VLM扩散模型成功应用于机器人操作领域，验证了新策略的有效性，并为VLM和VLA结合指明了新方向。

Abstract: The rapid progress of auto-regressive vision-language models (VLMs) has
inspired growing interest in vision-language-action models (VLA) for robotic
manipulation. Recently, masked diffusion models, a paradigm distinct from
autoregressive models, have begun to demonstrate competitive performance in
text generation and multimodal applications, leading to the development of a
series of diffusion-based VLMs (d-VLMs). However, leveraging such models for
robot policy learning remains largely unexplored. In this work, we present
LLaDA-VLA, the first Vision-Language-Diffusion-Action model built upon
pretrained d-VLMs for robotic manipulation. To effectively adapt d-VLMs to
robotic domain, we introduce two key designs: (1) a localized special-token
classification strategy that replaces full-vocabulary classification with
special action token classification, reducing adaptation difficulty; (2) a
hierarchical action-structured decoding strategy that decodes action sequences
hierarchically considering the dependencies within and across actions.
Extensive experiments demonstrate that LLaDA-VLA significantly outperforms
state-of-the-art VLAs on both simulation and real-world robots.

</details>


### [277] [F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions](https://arxiv.org/abs/2509.06951)
*Qi Lv,Weijie Kong,Hao Li,Jia Zeng,Zherui Qiu,Delin Qu,Haoming Song,Qizhi Chen,Xiang Deng,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 本文提出了一种新型的视觉-语言-动作（VLA）模型F1，通过加入视觉前瞻（visual foresight）机制，提高在动态视觉环境中执行条件任务的性能。实验表明，F1在真实任务和仿真基准上均显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型多采用反应式的状态到动作映射，导致在动态场景中行为短视且鲁棒性差。作者希望通过引入决策前的视觉规划来提升模型的任务完成率和泛化能力。

Method: F1框架采用混合变换器（Mixture-of-Transformer）结构，分别搭建感知、前瞻生成和控制三个模块。核心是通过next-scale prediction生成与目标相关的未来视觉状态，用于引导逆向动力学求解动作策略。模型在包含136个任务、33万轨迹的大规模数据集上分三阶段训练，以增强模块化推理与前瞻泛化能力。

Result: 大量真实任务和仿真测试表明，F1在任务成功率和泛化性能上均优于现有VLA方法，实现了可观提升。

Conclusion: F1通过集成视觉前瞻到感知-决策流程，显著增强了模型在动态复杂环境中的适应能力和任务执行表现，为VLA模型提供了新的思路。

Abstract: Executing language-conditioned tasks in dynamic visual environments remains a
central challenge in embodied AI. Existing Vision-Language-Action (VLA) models
predominantly adopt reactive state-to-action mappings, often leading to
short-sighted behaviors and poor robustness in dynamic scenes. In this paper,
we introduce F1, a pretrained VLA framework which integrates the visual
foresight generation into decision-making pipeline. F1 adopts a
Mixture-of-Transformer architecture with dedicated modules for perception,
foresight generation, and control, thereby bridging understanding, generation,
and actions. At its core, F1 employs a next-scale prediction mechanism to
synthesize goal-conditioned visual foresight as explicit planning targets. By
forecasting plausible future visual states, F1 reformulates action generation
as a foresight-guided inverse dynamics problem, enabling actions that
implicitly achieve visual goals. To endow F1 with robust and generalizable
capabilities, we propose a three-stage training recipe on an extensive dataset
comprising over 330k trajectories across 136 diverse tasks. This training
scheme enhances modular reasoning and equips the model with transferable visual
foresight, which is critical for complex and dynamic environments. Extensive
evaluations on real-world tasks and simulation benchmarks demonstrate F1
consistently outperforms existing approaches, achieving substantial gains in
both task success rate and generalization ability.

</details>


### [278] [Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for Dynamic Environments](https://arxiv.org/abs/2509.06953)
*Jiahui Yang,Jason Jingzhou Liu,Yulong Li,Youssef Khaky,Kenneth Shaw,Deepak Pathak*

Main category: cs.RO

TL;DR: 本文提出了一种面向动态、部分可观环境中机械臂碰撞规避的新型视触觉神经运动策略（DRP），综合了IMPACT（变换器模型，预训练1000万专家轨迹）与DCP-RMP（本地动态障碍避让模块），在仿真和真实复杂环境中优于传统与现有神经方法。


<details>
  <summary>Details</summary>
Motivation: 在动态、部分可观测环境下，传统规划器需要完整知识且计算慢，神经策略虽快但泛化性差。为兼顾速度、实时性与复杂环境下的泛化能力，提出新方法。

Method: 1. 提出DRP视觉-运动神经策略，输入为点云。2. 采用IMPACT（基于Transformer、用千万专家轨迹预训练）的方式实现通用运动能力。3. 静态障碍物通过师生微调进一步提升规避能力。4. 推理阶段结合DCP-RMP模块增强动态障碍避让。实验在多个复杂仿真与实际任务中测试。

Result: DRP在杂乱、动态障碍和目标遮挡等复杂任务中，实现了高成功率，并在仿真与现实场景下表现均优于以往的经典及神经方法。

Conclusion: DRP有效兼具了传统规划和神经策略的优点，实现了在动态、部分可观环境中的高效碰撞规避与强泛化能力，为相关高端机器人应用带来新突破。

Abstract: Generating collision-free motion in dynamic, partially observable
environments is a fundamental challenge for robotic manipulators. Classical
motion planners can compute globally optimal trajectories but require full
environment knowledge and are typically too slow for dynamic scenes. Neural
motion policies offer a promising alternative by operating in closed-loop
directly on raw sensory inputs but often struggle to generalize in complex or
dynamic settings. We propose Deep Reactive Policy (DRP), a visuo-motor neural
motion policy designed for reactive motion generation in diverse dynamic
environments, operating directly on point cloud sensory input. At its core is
IMPACT, a transformer-based neural motion policy pretrained on 10 million
generated expert trajectories across diverse simulation scenarios. We further
improve IMPACT's static obstacle avoidance through iterative student-teacher
finetuning. We additionally enhance the policy's dynamic obstacle avoidance at
inference time using DCP-RMP, a locally reactive goal-proposal module. We
evaluate DRP on challenging tasks featuring cluttered scenes, dynamic moving
obstacles, and goal obstructions. DRP achieves strong generalization,
outperforming prior classical and neural methods in success rate across both
simulated and real-world settings. Video results and code available at
https://deep-reactive-policy.com

</details>


### [279] [LocoMamba: Vision-Driven Locomotion via End-to-End Deep Reinforcement Learning with Mamba](https://arxiv.org/abs/2508.11849)
*Yinuo Wang,Gavin Tao*

Main category: cs.RO

TL;DR: LocoMamba是一种基于Mamba的高效视觉驱动跨模态深度强化学习框架，能高效建模长序列依赖，在复杂环境下强化训练并取得优于现有方法的表现。


<details>
  <summary>Details</summary>
Motivation: 现有视觉驱动的强化学习方法在处理长时序数据时面临计算瓶颈、记忆消耗大和泛化性不足等问题。因此，作者希望提出一种高效能、具备长时依赖建模能力的跨模态DRL框架，以提高在复杂环境下的智能体表现和训练效率。

Method: 1. 使用MLP嵌入自身感知状态，轻量级卷积网络处理深度图像并生成紧凑token；2. 通过堆叠Mamba层实现token融合，利用线性复杂度序列建模，减少延迟和内存占用，并降低过拟合风险；3. 基于地形和观感扰动、障碍密度变化的环境下，采用PPO算法和以状态为中心的奖励机制进行端到端训练。

Result: 在有静态和动态障碍以及不平整地形的复杂仿真环境中，LocoMamba相比主流方法获得更高的回报和成功率，碰撞更少，对新环境和密度具有更强泛化能力，在相同计算预算下收敛更快。

Conclusion: LocoMamba能够高效处理长序列模式，增强跨模态状态表征和泛化能力，在视觉驱动的强化学习任务中取得了超越主流方法的整体性能和训练效率。

Abstract: We introduce LocoMamba, a vision-driven cross-modal DRL framework built on
selective state-space models, specifically leveraging Mamba, that achieves
near-linear-time sequence modeling, effectively captures long-range
dependencies, and enables efficient training with longer sequences. First, we
embed proprioceptive states with a multilayer perceptron and patchify depth
images with a lightweight convolutional neural network, producing compact
tokens that improve state representation. Second, stacked Mamba layers fuse
these tokens via near-linear-time selective scanning, reducing latency and
memory footprint, remaining robust to token length and image resolution, and
providing an inductive bias that mitigates overfitting. Third, we train the
policy end-to-end with Proximal Policy Optimization under terrain and
appearance randomization and an obstacle-density curriculum, using a compact
state-centric reward that balances progress, smoothness, and safety. We
evaluate our method in challenging simulated environments with static and
moving obstacles as well as uneven terrain. Compared with state-of-the-art
baselines, our method achieves higher returns and success rates with fewer
collisions, exhibits stronger generalization to unseen terrains and obstacle
densities, and improves training efficiency by converging in fewer updates
under the same compute budget.

</details>
