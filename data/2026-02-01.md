<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 92]
- [cs.CL](#cs.CL) [Total: 74]
- [cs.RO](#cs.RO) [Total: 36]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [MA-LipNet: Multi-Dimensional Attention Networks for Robust Lipreading](https://arxiv.org/abs/2601.20881)
*Matteo Rossi*

Main category: cs.CV

TL;DR: 提出了一种结合多重注意力机制的新型唇读网络MA-LipNet，显著提升了唇读的准确率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有唇读技术由于口型动作细微，导致特征区分性弱、泛化能力差，亟需在特征提取和增强方面进行改进。

Method: 设计了MA-LipNet模型，依次采用通道注意力模块（CA）、联合时空注意力模块（JSTA）、分离时空注意力模块（SSTA），从通道、空间、时间三个维度对输入特征进行精炼和过滤，以提升特征有效性。

Result: 在CMLR和GRID数据集上的实验结果显示，MA-LipNet明显降低了字符错误率（CER）和词错误率（WER），优于多种主流方法。

Conclusion: 多维度特征精炼（通道、空间、时间）对实现鲁棒的视觉语音识别至关重要，MA-LipNet在唇读任务上取得了显著提升。

Abstract: Lipreading, the technology of decoding spoken content from silent videos of lip movements, holds significant application value in fields such as public security. However, due to the subtle nature of articulatory gestures, existing lipreading methods often suffer from limited feature discriminability and poor generalization capabilities. To address these challenges, this paper delves into the purification of visual features from temporal, spatial, and channel dimensions. We propose a novel method named Multi-Attention Lipreading Network(MA-LipNet). The core of MA-LipNet lies in its sequential application of three dedicated attention modules. Firstly, a \textit{Channel Attention (CA)} module is employed to adaptively recalibrate channel-wise features, thereby mitigating interference from less informative channels. Subsequently, two spatio-temporal attention modules with distinct granularities-\textit{Joint Spatial-Temporal Attention (JSTA)} and \textit{Separate Spatial-Temporal Attention (SSTA)}-are leveraged to suppress the influence of irrelevant pixels and video frames. The JSTA module performs a coarse-grained filtering by computing a unified weight map across the spatio-temporal dimensions, while the SSTA module conducts a more fine-grained refinement by separately modeling temporal and spatial attentions. Extensive experiments conducted on the CMLR and GRID datasets demonstrate that MA-LipNet significantly reduces the Character Error Rate (CER) and Word Error Rate (WER), validating its effectiveness and superiority over several state-of-the-art methods. Our work highlights the importance of multi-dimensional feature refinement for robust visual speech recognition.

</details>


### [2] [Non-Markov Multi-Round Conversational Image Generation with History-Conditioned MLLMs](https://arxiv.org/abs/2601.20911)
*Haochen Zhang,Animesh Sinha,Felix Juefei-Xu,Haoyu Ma,Kunpeng Li,Zhipeng Fan,Meng Dong,Xiaoliang Dai,Tingbo Hou,Peizhao Zhang,Zecheng He*

Main category: cs.CV

TL;DR: 本文提出了一种针对多轮对话式图像生成的非马尔可夫方法，能够处理需要追溯历史、多轮指令一致性的复杂场景。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大模型在多轮对话生成与编辑图像时，大多采用近似马尔可夫假设（仅考虑最近轮次的内容），导致模型容易忽视对长期历史的依赖，无法处理用户跨轮提及、撤销操作或实体持续绑定等更加自然和复杂的应用场景。为提升多轮一致性和指令遵循性，亟需方法显式建模和利用完整的对话历史。

Method: 提出三项主要方案：1）设计非马尔可夫多轮数据，包括需回溯历史状态的图像回滚编辑和基于命名的个性化绑定策略；2）开发基于对话历史条件化的训练和推理框架，结合token级缓存，防止身份漂移；3）提升高保真图像重建和可编辑个性化的训练，包括基于重建的DiT解码器和多阶段微调策略。

Result: 实验证明，针对非马尔可夫多轮交互的专门训练，在多轮一致性和指令执行准确性上显著优于以往基于马尔可夫假设的做法，同时单轮图像编辑和个性化能力依旧优良。

Conclusion: 显式建模和训练非马尔可夫多轮交互对于提升对话式图像生成系统的长期一致性和用户指令遵循性至关重要。

Abstract: Conversational image generation requires a model to follow user instructions across multiple rounds of interaction, grounded in interleaved text and images that accumulate as chat history. While recent multimodal large language models (MLLMs) can generate and edit images, most existing multi-turn benchmarks and training recipes are effectively Markov: the next output depends primarily on the most recent image, enabling shortcut solutions that ignore long-range history. In this work we formalize and target the more challenging non-Markov setting, where a user may refer back to earlier states, undo changes, or reference entities introduced several rounds ago. We present (i) non-Markov multi-round data construction strategies, including rollback-style editing that forces retrieval of earlier visual states and name-based multi-round personalization that binds names to appearances across rounds; (ii) a history-conditioned training and inference framework with token-level caching to prevent multi-round identity drift; and (iii) enabling improvements for high-fidelity image reconstruction and editable personalization, including a reconstruction-based DiT detokenizer and a multi-stage fine-tuning curriculum. We demonstrate that explicitly training for non-Markov interactions yields substantial improvements in multi-round consistency and instruction compliance, while maintaining strong single-round editing and personalization.

</details>


### [3] [Text controllable PET denoising](https://arxiv.org/abs/2601.20990)
*Xuehua Ye,Hongxu Yang,Adam J. Schwarz*

Main category: cs.CV

TL;DR: 本文提出了一种基于文本引导的去噪方法，通过结合预训练CLIP与U-Net结构，在不同计数水平下均能有效提升PET图像质量。实验验证了该方法在定性和定量上的显著提升，为更复杂的图像去噪和降低采集时间提供了可能。


<details>
  <summary>Details</summary>
Motivation: PET图像常受多种噪声影响，影响医学诊断精度，急需高效、泛用性的图像去噪技术提升PET成像品质。

Method: 提出融合CLIP模型特征与U-Net去噪结构的文本引导去噪方法，实现单一模型对不同计数级别PET图像的鲁棒处理。

Result: 实验表明，该方法在定性与定量评价方面均取得了显著改进，图像细节和诊断价值得到提升。

Conclusion: 新方法不仅能适应复杂多变的去噪需求，还具备减少PET采集时间和剂量的潜力，具有较高的实际应用与推广价值。

Abstract: Positron Emission Tomography (PET) imaging is a vital tool in medical diagnostics, offering detailed insights into molecular processes within the human body. However, PET images often suffer from complicated noise, which can obscure critical diagnostic information. The quality of the PET image is impacted by various factors including scanner hardware, image reconstruction, tracer properties, dose/count level, and acquisition time. In this study, we propose a novel text-guided denoising method capable of enhancing PET images across a wide range of count levels within a single model. The model utilized the features from a pretrained CLIP model with a U-Net based denoising model. Experimental results demonstrate that the proposed model leads significant improvements in both qualitative and quantitative assessments. The flexibility of the model shows the potential for helping more complicated denoising demands or reducing the acquisition time.

</details>


### [4] [Low performing pixel correction in computed tomography with unrolled network and synthetic data training](https://arxiv.org/abs/2601.20995)
*Hongxu Yang,Levente Lippenszky,Edina Timko,Lehel Ferenczi,Gopal Avinash*

Main category: cs.CV

TL;DR: 本文提出一种基于合成数据的双域（sinogram和图像域）去除CT低性能像素（LPP）伪影的方法，无需真实临床数据，可以显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 低性能像素在CT探测器中会引入环形和条带伪影，影响图像质量并降低临床可用性。现有深度学习方法需大量真实数据用于训练，采集代价高，且只针对图像域或sinogram域单独校正，未利用二者间的内在联系。

Method: 提出了一种基于合成数据的unrolled双域（sinogram-图像）校正方法，通过自然图像合成sinogram和图像域数据，挖掘两域间的内在相关性，实现无真实临床数据的模型训练和LPP伪影校正。

Result: 在模拟1-2%探测器损坏、靠近等中心的场景下，实验结果显示该方法大幅优于现有最先进技术。

Conclusion: 本方法在无需真实训练数据的前提下，能够有效去除LPP伪影，并具有良好的通用性和适应性，适用于不同CT设置的软件实现。

Abstract: Low performance pixels (LPP) in Computed Tomography (CT) detectors would lead to ring and streak artifacts in the reconstructed images, making them clinically unusable. In recent years, several solutions have been proposed to correct LPP artifacts, either in the image domain or in the sinogram domain using supervised deep learning methods. However, these methods require dedicated datasets for training, which are expensive to collect. Moreover, existing approaches focus solely either on image-space or sinogram-space correction, ignoring the intrinsic correlations from the forward operation of the CT geometry. In this work, we propose an unrolled dual-domain method based on synthetic data to correct LPP artifacts. Specifically, the intrinsic correlations of LPP between the sinogram and image domains are leveraged through synthetic data generated from natural images, enabling the trained model to correct artifacts without requiring any real-world clinical data. In experiments simulating 1-2% detectors defect near the isocenter, the proposed method outperformed the state-of-the-art approaches by a large margin. The results indicate that our solution can correct LPP artifacts without the cost of data collection for model training, and it is adaptable to different scanner settings for software-based applications.

</details>


### [5] [AI-based Prediction of Biochemical Recurrence from Biopsy and Prostatectomy Samples](https://arxiv.org/abs/2601.21022)
*Andrea Camilloni,Chiara Micoli,Nita Mulliqi,Erik Everett Palm,Thorgerdur Palsdottir,Kelvin Szolnoky,Xiaoyi Ji,Sol Erika Boman,Andrea Discacciati,Henrik Grönberg,Lars Egevad,Tobias Nordström,Kimmo Kartasalo,Martin Eklund*

Main category: cs.CV

TL;DR: 本研究利用AI模型分析前列腺穿刺活检切片，以预测根治性前列腺切除术后生化复发（BCR）风险，并在多队列验证其泛化能力，结果显示AI可改善风险预测，但需进一步比较其与简化模型的优势。


<details>
  <summary>Details</summary>
Motivation: 当前预测前列腺癌患者根治性前列腺切除术后生化复发风险的工具准确性有限，亟需更精准的个体化风险预测方法以指导临床决策。

Method: 研究采用STHLM3队列的诊断活检切片训练了一个AI基础模型，结合attention-based多实例学习（MIL）方法进行BCR风险预测，并在LEOPARD、CHIMERA和TCGA-PRAD三个外部队列进行泛化能力验证，进一步与传统指南推荐的CAPRA-S模型进行对比。

Result: AI图像分析模型在三个外部验证队列的5年期AUC分别达到0.64、0.70和0.70，结合临床变量后提升了预后分层能力，并在术后风险预测方面优于CAPRA-S模型。

Conclusion: 基于活检切片的AI组学模型不仅可推广到不同的标本类型，辅助术前和术后决策，其多模态结合临床变量有望提升风险预测准确性，但需更严格验证其相较于传统简化模型的真实增益。

Abstract: Biochemical recurrence (BCR) after radical prostatectomy (RP) is a surrogate marker for aggressive prostate cancer with adverse outcomes, yet current prognostic tools remain imprecise. We trained an AI-based model on diagnostic prostate biopsy slides from the STHLM3 cohort (n = 676) to predict patient-specific risk of BCR, using foundation models and attention-based multiple instance learning. Generalizability was assessed across three external RP cohorts: LEOPARD (n = 508), CHIMERA (n = 95), and TCGA-PRAD (n = 379). The image-based approach achieved 5-year time-dependent AUCs of 0.64, 0.70, and 0.70, respectively. Integrating clinical variables added complementary prognostic value and enabled statistically significant risk stratification. Compared with guideline-based CAPRA-S, AI incrementally improved postoperative prognostication. These findings suggest biopsy-trained histopathology AI can generalize across specimen types to support preoperative and postoperative decision making, but the added value of AI-based multimodal approaches over simpler predictive models should be critically scrutinized in further studies.

</details>


### [6] [BadDet+: Robust Backdoor Attacks for Object Detection](https://arxiv.org/abs/2601.21066)
*Kealan Dunnett,Reza Arablouei,Dimity Miller,Volkan Dedeoglu,Raja Jurdak*

Main category: cs.CV

TL;DR: 本文提出了一种新的后门攻击框架BadDet+，侧重解决现有目标检测后门攻击方法假设不现实、物理验证不足等问题。通过对触发器输入施加对抗性惩罚，提升了攻击的稳健性与泛化性。实验证明BadDet+在合成与物理环境中有更好的转移性，同时理论分析揭示了攻击只影响特定特征子空间，且不损伤正常性能。


<details>
  <summary>Details</summary>
Motivation: 目标检测的后门攻击研究远不如图像分类成熟，现有方法普遍依赖不切实际的设定且鲜有物理环境验证，因此亟需更有效且现实可行的攻击模型，以揭示检测模型的真实安全隐患。

Method: 提出BadDet+，用log-barrier penalty机制对被触发输入动态抑制真实类别预测，使攻击具备位置与尺度不变性，并加强了物理世界下的攻击有效性。BadDet+能统一实现区域误分类（RMA）和目标消失（ODA）两类攻击。

Result: 在真实世界基准数据集上，BadDet+于合成到物理实验的迁移能力优于现有RMA和ODA方法，同时不影响干净样本的检测性能。理论分析表明，罚函数仅作用于特定特征子空间，精准控制攻击效果且无副作用。

Conclusion: 目标检测仍存在较大安全漏洞，BadDet+的提出凸显了现有检测模型在面对物理可行后门攻击时的脆弱性，促进了对更专业防御机制的需求。

Abstract: Backdoor attacks pose a severe threat to deep learning, yet their impact on object detection remains poorly understood compared to image classification. While attacks have been proposed, we identify critical weaknesses in existing detection-based methods, specifically their reliance on unrealistic assumptions and a lack of physical validation. To bridge this gap, we introduce BadDet+, a penalty-based framework that unifies Region Misclassification Attacks (RMA) and Object Disappearance Attacks (ODA). The core mechanism utilizes a log-barrier penalty to suppress true-class predictions for triggered inputs, resulting in (i) position and scale invariance, and (ii) enhanced physical robustness. On real-world benchmarks, BadDet+ achieves superior synthetic-to-physical transfer compared to existing RMA and ODA baselines while preserving clean performance. Theoretical analysis confirms the proposed penalty acts within a trigger-specific feature subspace, reliably inducing attacks without degrading standard inference. These results highlight significant vulnerabilities in object detection and the necessity for specialized defenses.

</details>


### [7] [Towards Mitigating Modality Bias in Vision-Language Models for Temporal Action Localization](https://arxiv.org/abs/2601.21078)
*Jiaqi Li,Guangming Wang,Shuntian Zheng,Minzhe Ni,Xiaoman Lu,Guanghui Ye,Yu Guan*

Main category: cs.CV

TL;DR: 本文提出了一种用于时序动作定位（TAL）的视觉-语言聚合框架ActionVLM，通过动态减少语言偏置以提升视觉信息的主导地位，实现更优的定位与分类效果，在THUMOS14数据集上性能超过现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有利用视觉-语言模型（VLMs）做TAL的方法往往对语言信息依赖过强，导致视觉表现下降，产生强烈的模态偏置。作者希望解决该偏置，使视觉信息在任务中占据主导，并充分利用语言信息的优势。

Method: 1）提出去偏重加权模块，对比语言与纯视觉预测的增益，动态调整语言模态权重；2）设计残差聚合策略，将语言作为对视觉信号的补充优化，而非主要信息源。整个框架旨在动态利用语言，只在其确实带来好处时才增强其影响。

Result: 实验证明，在THUMOS14数据集上，该方法mAP提升高达3.2%，优于现有SOTA方法。

Conclusion: ActionVLM有效缓解了由语言信息带来的模态偏置，提升了视觉模态主导下的时序动作定位性能，验证了其理论与实际效果。

Abstract: Temporal Action Localization (TAL) requires identifying both the boundaries and categories of actions in untrimmed videos. While vision-language models (VLMs) offer rich semantics to complement visual evidence, existing approaches tend to overemphasize linguistic priors at the expense of visual performance, leading to a pronounced modality bias. We propose ActionVLM, a vision-language aggregation framework that systematically mitigates modality bias in TAL. Our key insight is to preserve vision as the dominant signal while adaptively exploiting language only when beneficial. To this end, we introduce (i) a debiasing reweighting module that estimates the language advantage-the incremental benefit of language over vision-only predictions-and dynamically reweights language modality accordingly, and (ii) a residual aggregation strategy that treats language as a complementary refinement rather than the primary driver. This combination alleviates modality bias, reduces overconfidence from linguistic priors, and strengthens temporal reasoning. Experiments on THUMOS14 show that our model outperforms state-of-the-art by up to 3.2% mAP.

</details>


### [8] [Shape of Thought: Progressive Object Assembly via Visual Chain-of-Thought](https://arxiv.org/abs/2601.21081)
*Yu Huo,Siyu Zhang,Kun Zeng,Haoyue Liu,Owen Lee,Junlin Chen,Yuquan Lu,Yifu Guo,Yaodong Liang,Xiaoying Tang*

Main category: cs.CV

TL;DR: 本文提出了一种新的视觉链式思维（Shape-of-Thought, SoT）框架，用于提升文本到图像生成模型在结构组合性方面（如数字、属性绑定、部件关系）的表现，并引入了新的数据集和评测基准。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像的多模态生成模型在视觉效果上虽表现优异，但在结构约束下（如部件组合、属性精准绑定、生成计数能力等）表现脆弱。为了解决这些结构性组合问题，提升模型的细致生成能力需要新的方法。

Method: 提出Shape-of-Thought（SoT）框架，训练一个统一的多模态自回归模型，交替生成文本计划和中间可视化状态，以此捕捉逐步组装形状的逻辑，且推理时无需外部引擎。并构建了SoT-26K数据集，记录了基于CAD层次结构的组装流程，以及T2S-CompBench评测基准。

Result: 在SoT-26K数据集上微调后，该方法在组件计数准确性上达到88.4%，在结构拓扑准确性上达到84.8%，均比基于文本的基线高出约20%。

Conclusion: SoT框架为结构透明、过程可监督的组合式生成提供了新范式，显著提升了复杂结构场景下生成模型的表现，并推动了可解释、多步骤生成的相关研究。

Abstract: Multimodal models for text-to-image generation have achieved strong visual fidelity, yet they remain brittle under compositional structural constraints-notably generative numeracy, attribute binding, and part-level relations. To address these challenges, we propose Shape-of-Thought (SoT), a visual CoT framework that enables progressive shape assembly via coherent 2D projections without external engines at inference time. SoT trains a unified multimodal autoregressive model to generate interleaved textual plans and rendered intermediate states, helping the model capture shape-assembly logic without producing explicit geometric representations. To support this paradigm, we introduce SoT-26K, a large-scale dataset of grounded assembly traces derived from part-based CAD hierarchies, and T2S-CompBench, a benchmark for evaluating structural integrity and trace faithfulness. Fine-tuning on SoT-26K achieves 88.4% on component numeracy and 84.8% on structural topology, outperforming text-only baselines by around 20%. SoT establishes a new paradigm for transparent, process-supervised compositional generation. The code is available at https://anonymous.4open.science/r/16FE/. The SoT-26K dataset will be released upon acceptance.

</details>


### [9] [An AI Framework for Microanastomosis Motion Assessment](https://arxiv.org/abs/2601.21120)
*Yan Meng,Eduardo J. Torres-Rodríguez,Marcelle Altshuler,Nishanth Gowda,Arhum Naeem,Recai Yilmaz,Omar Arnaout,Daniel A. Donoho*

Main category: cs.CV

TL;DR: 本文提出了一种基于AI的微血管吻合操作技能自动评估系统，用于替代传统主观评价。系统通过深度学习方法实现高精度的手术器械检测、追踪与技能识别。


<details>
  <summary>Details</summary>
Motivation: 现有微外科评估方法主观性强，易受评分者个人因素干扰，缺乏标准化、客观性，同时过程耗时，效率低下。迫切需要一个自动化、可扩展的客观评估系统，以提升评估的一致性与效率。

Method: 提出了一个集成AI系统，包括：1）采用YOLO的器械检测模块，2）基于DeepSORT的器械追踪模块，3）利用形状描述子的器械尖端定位模块，4）基于专家标注数据训练的技能分类模块，对手术操作进行自动评估。

Result: 实验表明，该系统器械检测精度达97%，平均检测精度（mAP50-95）为96%，在广泛IoU阈值下表现优异。

Conclusion: AI自动化系统能够高效、准确、稳定地评估微血管吻合等微外科操作技能，有望成为相关外科教育及标准化评估的重要工具。

Abstract: Proficiency in microanastomosis is a fundamental competency across multiple microsurgical disciplines. These procedures demand exceptional precision and refined technical skills, making effective, standardized assessment methods essential. Traditionally, the evaluation of microsurgical techniques has relied heavily on the subjective judgment of expert raters. They are inherently constrained by limitations such as inter-rater variability, lack of standardized evaluation criteria, susceptibility to cognitive bias, and the time-intensive nature of manual review. These shortcomings underscore the urgent need for an objective, reliable, and automated system capable of assessing microsurgical performance with consistency and scalability. To bridge this gap, we propose a novel AI framework for the automated assessment of microanastomosis instrument handling skills. The system integrates four core components: (1) an instrument detection module based on the You Only Look Once (YOLO) architecture; (2) an instrument tracking module developed from Deep Simple Online and Realtime Tracking (DeepSORT); (3) an instrument tip localization module employing shape descriptors; and (4) a supervised classification module trained on expert-labeled data to evaluate instrument handling proficiency. Experimental results demonstrate the effectiveness of the framework, achieving an instrument detection precision of 97%, with a mean Average Precision (mAP) of 96%, measured by Intersection over Union (IoU) thresholds ranging from 50% to 95% (mAP50-95).

</details>


### [10] [Bidirectional Cross-Perception for Open-Vocabulary Semantic Segmentation in Remote Sensing Imagery](https://arxiv.org/abs/2601.21159)
*Jianzheng Wang,Huan Ni*

Main category: cs.CV

TL;DR: 该论文提出了一种新的针对高分辨率遥感影像的零训练开放词汇语义分割（OVSS）方法SDCI，使用多模块协同策略，在无需训练的情况下显著提升了分割的定位与语义表现。


<details>
  <summary>Details</summary>
Motivation: 高分辨率遥感影像地物密集且边界复杂，对几何定位和语义预测提出了更高要求。现有无训练开放词汇语义分割方法融合CLIP和视觉基础模型时只用“单向注入”和“浅层后处理”，难以满足这些需求。

Method: 提出SDCI框架，包括(1)提出跨模型注意力融合（CAF）模块，在编码阶段通过相互注入自注意力图实现协同推理；(2)提出双向跨图扩散细化（BCDR）模块，利用随机游走扩散提升分割分数的可靠性；(3)结合低层次超像素结构，设计基于凸优化的超像素协同预测（CSCP）机制，进一步优化目标边界。

Result: 在多个遥感语义分割基准上的实验显示，所提方法优于现有无训练OVSS方法。消融实验也表明，传统依赖超像素的影像分析方法在深度学习框架下依然有效。

Conclusion: SDCI能高效融合视觉基础模型和语言模型，在无需训练条件下显著改善遥感影像的语义分割精度和边界细化效果。

Abstract: High-resolution remote sensing imagery is characterized by densely distributed land-cover objects and complex boundaries, which places higher demands on both geometric localization and semantic prediction. Existing training-free open-vocabulary semantic segmentation (OVSS) methods typically fuse CLIP and vision foundation models (VFMs) using "one-way injection" and "shallow post-processing" strategies, making it difficult to satisfy these requirements. To address this issue, we propose a spatial-regularization-aware dual-branch collaborative inference framework for training-free OVSS, termed SDCI. First, during feature encoding, SDCI introduces a cross-model attention fusion (CAF) module, which guides collaborative inference by injecting self-attention maps into each other. Second, we propose a bidirectional cross-graph diffusion refinement (BCDR) module that enhances the reliability of dual-branch segmentation scores through iterative random-walk diffusion. Finally, we incorporate low-level superpixel structures and develop a convex-optimization-based superpixel collaborative prediction (CSCP) mechanism to further refine object boundaries. Experiments on multiple remote sensing semantic segmentation benchmarks demonstrate that our method achieves better performance than existing approaches. Moreover, ablation studies further confirm that traditional object-based remote sensing image analysis methods leveraging superpixel structures remain effective within deep learning frameworks. Code: https://github.com/yu-ni1989/SDCI.

</details>


### [11] [Enhancing Underwater Light Field Images via Global Geometry-aware Diffusion Process](https://arxiv.org/abs/2601.21179)
*Yuji Lin,Qian Zhao,Zongsheng Yue,Junhui Hou,Deyu Meng*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的框架GeoDiff-LF，使4维光场水下成像更高质量，显著减小水下图像的色彩失真，并在多个指标上超过现有方法。


<details>
  <summary>Details</summary>
Motivation: 水下成像常受色彩失真等影响，传统方法难以在保持空间-角度信息的同时提升图像质量。作者希望结合扩散模型和光场成像特点，提升水下4D光场成像效果。

Method: 提出的GeoDiff-LF框架基于SD-Turbo扩散模型，进行了三方面改进：1）改进U-Net结构，引入卷积与注意力模块提取几何信息；2）设计了基于张量分解与逐步加权的几何引导损失函数，保证全局结构规律；3）优化采样与噪声预测策略，提升效率。

Result: 大量实验表明，GeoDiff-LF在视觉质量和定量指标上均优于现有方法，更好地减少了水下成像中的色彩失真。

Conclusion: GeoDiff-LF融合扩散先验和光场几何，极大提升了4D水下成像质量，推动了该领域的最新进展。

Abstract: This work studies the challenging problem of acquiring high-quality underwater images via 4-D light field (LF) imaging. To this end, we propose GeoDiff-LF, a novel diffusion-based framework built upon SD-Turbo to enhance underwater 4-D LF imaging by leveraging its spatial-angular structure. GeoDiff-LF consists of three key adaptations: (1) a modified U-Net architecture with convolutional and attention adapters to model geometric cues, (2) a geometry-guided loss function using tensor decomposition and progressive weighting to regularize global structure, and (3) an optimized sampling strategy with noise prediction to improve efficiency. By integrating diffusion priors and LF geometry, GeoDiff-LF effectively mitigates color distortion in underwater scenes. Extensive experiments demonstrate that our framework outperforms existing methods across both visual fidelity and quantitative performance, advancing the state-of-the-art in enhancing underwater imaging. The code will be publicly available at https://github.com/linlos1234/GeoDiff-LF.

</details>


### [12] [FRISM: Fine-Grained Reasoning Injection via Subspace-Level Model Merging for Vision-Language Models](https://arxiv.org/abs/2601.21187)
*Chenyu Huang,Peng Ye,Xudong Tan,Jinhan Mu,Shenghe Zheng,Li Shen,Tao Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为FRISM的新方法，通过在子空间级别精细融合模型，提升视觉-语言模型的推理能力且不影响其视觉表现，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有将大推理模型（LRM）与视觉-语言模型（VLM）结合的方法多在粗粒度（如层级），导致要增强推理能力时常损失视觉能力。因此急需更细粒度的融合方法，兼顾两者能力。

Method: FRISM通过奇异值分解（SVD）将LRM的任务向量分解为不同子空间，并利用学习方式自适应调整各子空间的权重，实现推理能力的精细注入。同时，提出无标签的自蒸馏学习策略，通过常用视觉-语言数据集进行双目标优化训练。

Result: 在多个视觉推理基准测试上，FRISM始终获得最优表现，显著提升推理能力的同时维持了原有视觉能力。

Conclusion: FRISM能在不损失视觉能力的前提下，有效提升VLM的推理能力，优于当前主流融合方法。

Abstract: Efficiently enhancing the reasoning capabilities of Vision-Language Models (VLMs) by merging them with Large Reasoning Models (LRMs) has emerged as a promising direction. However, existing methods typically operate at a coarse-grained layer level, which often leads to a trade-off between injecting reasoning capabilities and preserving visual capabilities. To address this limitation, we propose {FRISM} (Fine-grained Reasoning Injection via Subspace-level model Merging), a fine-grained reasoning injection framework based on subspace-level model merging. Observing that reasoning capabilities are encoded in distinct subspaces, FRISM decomposes LRM task vectors via Singular Value Decomposition (SVD) and adaptively tunes the scaling coefficients of each subspace through learning to realize fine-grained reasoning injection. Furthermore, we introduce a label-free self-distillation learning strategy with a dual-objective optimization using common vision-language perception datasets. Extensive experiments demonstrate that FRISM effectively improves reasoning capabilities without compromising the model's original visual capabilities by consistently achieving state-of-the-art performance across diverse visual reasoning benchmarks.

</details>


### [13] [Generative Recall, Dense Reranking: Learning Multi-View Semantic IDs for Efficient Text-to-Video Retrieval](https://arxiv.org/abs/2601.21193)
*Zecheng Zhao,Zhi Chen,Zi Huang,Shazia Sadiq,Tong Chen*

Main category: cs.CV

TL;DR: 提出了一种新的视频检索方法GRDR，结合生成式召回和密集重排序，在保持高准确率的基础上，显著减少了存储和计算成本，实现了更快的全库检索。


<details>
  <summary>Details</summary>
Motivation: 传统的密集视频检索虽然精度高，但在大规模视频库下，存储和计算开销巨大。两阶段检索通过快速召回减少候选集后用高精度模型重排，效率较高，但召回阶段的能力限制了整体性能。生成式检索（GR）理论上存储和计算成本低，但存在多义性和跨模态对齐不足等问题。

Method: 提出Generative Recall and Dense Reranking（GRDR）框架，创新性地为每个视频分配多个、由查询引导的多视角语义ID，并通过联合训练tokenizer和生成检索器，共享语义codebook来建立文本和视频间的语义桥梁。推理阶段用受限解码快速召回候选，再用密集检索器精细重排。

Result: 在多个视频检索基准上，GRDR取得与强密集检索器相当的准确率的同时，索引存储需求下降一个数量级，且在全库检索场景下速度提升最高达300倍。

Conclusion: GRDR有效突破了生成式召回的核心瓶颈，实现了高效且高质量的视频检索，为大规模视频平台的实时检索提供了有竞争力的解决方案。

Abstract: Text-to-Video Retrieval (TVR) is essential in video platforms. Dense retrieval with dual-modality encoders leads in accuracy, but its computation and storage scale poorly with corpus size. Thus, real-time large-scale applications adopt two-stage retrieval, where a fast recall model gathers a small candidate pool, which is reranked by an advanced dense retriever. Due to hugely reduced candidates, the reranking model can use any off-the-shelf dense retriever without hurting efficiency, meaning the recall model bounds two-stage TVR performance. Recently, generative retrieval (GR) replaces dense video embeddings with discrete semantic IDs and retrieves by decoding text queries into ID tokens. GR offers near-constant inference and storage complexity, and its semantic IDs capture high-level video features via quantization, making it ideal for quickly eliminating irrelevant candidates during recall. However, as a recall model in two-stage TVR, GR suffers from (i) semantic ambiguity, where each video satisfies diverse queries but is forced into one semantic ID; and (ii) cross-modal misalignment, as semantic IDs are solely derived from visual features without text supervision. We propose Generative Recall and Dense Reranking (GRDR), designing a novel GR method to uplift recalled candidate quality. GRDR assigns multiple semantic IDs to each video using a query-guided multi-view tokenizer exposing diverse semantic access paths, and jointly trains the tokenizer and generative retriever via a shared codebook to cast semantic IDs as the semantic bridge between texts and videos. At inference, trie-constrained decoding generates a compact candidate set reranked by a dense model for fine-grained matching. Experiments on TVR benchmarks show GRDR matches strong dense retrievers in accuracy while reducing index storage by an order of magnitude and accelerating up to 300$\times$ in full-corpus retrieval.

</details>


### [14] [Thinker: A vision-language foundation model for embodied intelligence](https://arxiv.org/abs/2601.21199)
*Baiyu Pan,Daqin Luo,Junpeng Yang,Jiyuan Wang,Yixuan Zhang,Hailin Shi,Jichao Jiao*

Main category: cs.CV

TL;DR: 提出了Thinker大模型，改进了机器人视觉-语言理解中的视角混淆和视频时序推理失误问题，方法包括针对性大数据集和联合多种输入方式，在主流任务规划数据集上取得了SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有大模型在人类看来简单的问题上表现不佳，如视角混淆和忽视视频结尾信息，严重影响机器人任务推理和规划能力。

Method: 1）构建包含自视角视频、视觉定位、空间理解与思维链数据的大规模机器人感知与推理数据集；2）将关键帧与完整视频序列联合输入模型，提升视频理解能力。

Result: 在两个主流机器人任务规划基准数据集上，Thinker模型取得了最新最优（SOTA）表现。

Conclusion: 通过专用数据集和改进输入策略，Thinker有效提升了机器人领域大视听语言模型在任务推理中的表现，为具身智能发展提供了更强基础。

Abstract: When large vision-language models are applied to the field of robotics, they encounter problems that are simple for humans yet error-prone for models. Such issues include confusion between third-person and first-person perspectives and a tendency to overlook information in video endings during temporal reasoning. To address these challenges, we propose Thinker, a large vision-language foundation model designed for embodied intelligence. We tackle the aforementioned issues from two perspectives. Firstly, we construct a large-scale dataset tailored for robotic perception and reasoning, encompassing ego-view videos, visual grounding, spatial understanding, and chain-of-thought data. Secondly, we introduce a simple yet effective approach that substantially enhances the model's capacity for video comprehension by jointly incorporating key frames and full video sequences as inputs. Our model achieves state-of-the-art results on two of the most commonly used benchmark datasets in the field of task planning.

</details>


### [15] [LAMP: Learning Universal Adversarial Perturbations for Multi-Image Tasks via Pre-trained Models](https://arxiv.org/abs/2601.21220)
*Alvi Md Ishmam,Najibul Haque Sarker,Zaber Ibn Abdul Hakim,Chris Thomas*

Main category: cs.CV

TL;DR: 本文提出了一种针对多图像多模态大语言模型（MLLMs）的全新黑盒对抗攻击方法LAMP，实现了比现有方法更高效的攻击效果。


<details>
  <summary>Details</summary>
Motivation: 虽然多模态大语言模型在视觉-语言任务中表现优异，但其在多图像输入场景下的安全性尚未被研究。现有对抗攻击研究多集中于单图像并且假设白盒环境，与实际情况不符。该工作旨在填补多图像黑盒攻击的研究空白。

Method: 提出LAMP方法，用于学习多图像MLLMs的通用对抗扰动。LAMP利用基于注意力机制的约束阻止模型有效聚合多图像信息，并通过跨图像传染约束，使对抗扰动能够影响未被修改的输入。此外，提出索引-注意力抑制损失，提升了攻击在输入位置变化下的鲁棒性。

Result: LAMP在多个视觉-语言任务与模型上，黑盒环境下的攻击成功率均超越了最先进的基线方法。

Conclusion: LAMP显著提升了对抗攻击在多图像MLLMs下的有效性，突显出这类模型在实际应用中的安全隐患，未来应关注其鲁棒性与防御措施。

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable performance across vision-language tasks. Recent advancements allow these models to process multiple images as inputs. However, the vulnerabilities of multi-image MLLMs remain unexplored. Existing adversarial attacks focus on single-image settings and often assume a white-box threat model, which is impractical in many real-world scenarios. This paper introduces LAMP, a black-box method for learning Universal Adversarial Perturbations (UAPs) targeting multi-image MLLMs. LAMP applies an attention-based constraint that prevents the model from effectively aggregating information across images. LAMP also introduces a novel cross-image contagious constraint that forces perturbed tokens to influence clean tokens, spreading adversarial effects without requiring all inputs to be modified. Additionally, an index-attention suppression loss enables a robust position-invariant attack. Experimental results show that LAMP outperforms SOTA baselines and achieves the highest attack success rates across multiple vision-language tasks and models.

</details>


### [16] [PTQ4ARVG: Post-Training Quantization for AutoRegressive Visual Generation Models](https://arxiv.org/abs/2601.21238)
*Xuewen Liu,Zhikai Li,Jing Zhang,Mengjuan Chen,Qingyi Gu*

Main category: cs.CV

TL;DR: 本文提出了一种适用于自回归视觉生成（ARVG）模型的无训练量化方法PTQ4ARVG，能够在不显著损失性能的情况下将ARVG模型量化至8-bit和6-bit。


<details>
  <summary>Details</summary>
Motivation: 虽然ARVG模型在架构与性能上具有很强的优势，但其量化方法少有探索，现有量化技术无法很好迁移到ARVG模型，主要受限于通道、token和样本级的独特分布与动态特性。

Method: 作者提出PTQ4ARVG，一个无需额外训练的后训练量化框架，包括：1）增益投影缩放（GPS）用于缓解通道级异常值；2）静态token级量化（STWQ）利用ARVG特性降低token波动性，无需复杂校准；3）分布引导校准（DGC）通过选择对分布熵贡献最大的样本解决样本级分布不匹配。

Result: 在大量实验中，PTQ4ARVG方法成功将ARVG家族模型量化至8位和6位，且模型性能损失极小，具备实际应用价值。

Conclusion: PTQ4ARVG为ARVG模型的高效低比特量化提供了新思路，有效克服了ARVG量化的分布和动态挑战，在不增加训练负担的同时保持了高性能。

Abstract: AutoRegressive Visual Generation (ARVG) models retain an architecture compatible with language models, while achieving performance comparable to diffusion-based models. Quantization is commonly employed in neural networks to reduce model size and computational latency. However, applying quantization to ARVG remains largely underexplored, and existing quantization methods fail to generalize effectively to ARVG models. In this paper, we explore this issue and identify three key challenges: (1) severe outliers at channel-wise level, (2) highly dynamic activations at token-wise level, and (3) mismatched distribution information at sample-wise level. To these ends, we propose PTQ4ARVG, a training-free post-training quantization (PTQ) framework consisting of: (1) Gain-Projected Scaling (GPS) mitigates the channel-wise outliers, which expands the quantization loss via a Taylor series to quantify the gain of scaling for activation-weight quantization, and derives the optimal scaling factor through differentiation.(2) Static Token-Wise Quantization (STWQ) leverages the inherent properties of ARVG, fixed token length and position-invariant distribution across samples, to address token-wise variance without incurring dynamic calibration overhead.(3) Distribution-Guided Calibration (DGC) selects samples that contribute most to distributional entropy, eliminating the sample-wise distribution mismatch. Extensive experiments show that PTQ4ARVG can effectively quantize the ARVG family models to 8-bit and 6-bit while maintaining competitive performance. Code is available at http://github.com/BienLuky/PTQ4ARVG .

</details>


### [17] [NFCDS: A Plug-and-Play Noise Frequency-Controlled Diffusion Sampling Strategy for Image Restoration](https://arxiv.org/abs/2601.21248)
*Zhen Wang,Hongyi Liu,Jianing Li,Zhihui Wei*

Main category: cs.CV

TL;DR: 本文提出了一种名为NFCDS的新型反向扩散采样机制，通过在傅里叶域中调控噪声频率成分，提高扩散模型的图像重建数据保真度和感知质量间的平衡，无需额外训练并可直接集成到现有扩散模型框架中。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散采样的可插拔(PnP)方法在产生高感知质量图像的同时，常因反向扩散过程引入的噪声导致数据保真度下降。作者希望突破感知-保真悖论，解决图像清晰度与细节恢复之间的平衡问题。

Method: 作者通过对扩散过程中噪声频率成分的分析，发现低频噪声导致图像模糊，高频噪声有助于细节生成。据此，设计了一种傅里叶域滤波器，在采样时逐步抑制低频噪声并保留高频内容，将这一控制作为先验直接嵌入采样过程，提高重建速度及效果，无需额外训练或修改主模型。

Result: NFCDS模块可以作为独立组件无缝集成到各种扩散图像修复框架中，在多个zero-shot图像重建任务上显著改善了感知质量与数据一致性之间的平衡。实验结果表明，该机制能快速收敛到同时兼具高保真和良好视觉效果的结果。

Conclusion: NFCDS有效解决了扩散采样中保真-感知矛盾，为扩散模型图像重建提供了新思路。其低成本、易集成和无需额外训练的优点，使其具有广泛的应用前景。

Abstract: Diffusion sampling-based Plug-and-Play (PnP) methods produce images with high perceptual quality but often suffer from reduced data fidelity, primarily due to the noise introduced during reverse diffusion. To address this trade-off, we propose Noise Frequency-Controlled Diffusion Sampling (NFCDS), a spectral modulation mechanism for reverse diffusion noise. We show that the fidelity-perception conflict can be fundamentally understood through noise frequency: low-frequency components induce blur and degrade fidelity, while high-frequency components drive detail generation. Based on this insight, we design a Fourier-domain filter that progressively suppresses low-frequency noise and preserves high-frequency content. This controlled refinement injects a data-consistency prior directly into sampling, enabling fast convergence to results that are both high-fidelity and perceptually convincing--without additional training. As a PnP module, NFCDS seamlessly integrates into existing diffusion-based restoration frameworks and improves the fidelity-perception balance across diverse zero-shot tasks.

</details>


### [18] [Hypersolid: Emergent Vision Representations via Short-Range Repulsion](https://arxiv.org/abs/2601.21255)
*Esteban Rodríguez-Betancourt,Edgar Casasola-Murillo*

Main category: cs.CV

TL;DR: 本文提出了一种防止自监督学习中表征坍缩的新方法——Hypersolid，通过引入局部的硬球排斥约束，有效提升表征多样性，特别适用于细粒度和低分辨率分类任务。


<details>
  <summary>Details</summary>
Motivation: 自监督学习常面临表征坍缩问题，现有方法主要依赖全局正则化，但还不足以从根本上解决信息丢失和表征多样性不足的问题。本文尝试通过不同视角，提出更加简单有效的应对策略。

Method: 作者将表征学习重新描述为一个离散堆叠问题，将信息保持转化为保持映射的单射性。具体方法为Hypersolid：在表征空间中引入短程的硬球排斥，防止相邻表征发生碰撞，从而实现高分离度。

Result: 实验表明，该方法能高效保持数据增强后的多样性，尤其在细粒度和低分辨率的分类任务上表现突出。

Conclusion: Hypersolid为表征坍缩问题提供了新的思路，以本地约束简单有效地提升了表征多样性和任务表现，对自监督学习有良好的实用价值。

Abstract: A recurring challenge in self-supervised learning is preventing representation collapse. Existing solutions typically rely on global regularization, such as maximizing distances, decorrelating dimensions or enforcing certain distributions. We instead reinterpret representation learning as a discrete packing problem, where preserving information simplifies to maintaining injectivity. We operationalize this in Hypersolid, a method using short-range hard-ball repulsion to prevent local collisions. This constraint results in a high-separation geometric regime that preserves augmentation diversity, excelling on fine-grained and low-resolution classification tasks.

</details>


### [19] [Lightweight High-Fidelity Low-Bitrate Talking Face Compression for 3D Video Conference](https://arxiv.org/abs/2601.21269)
*Jianglong Li,Jun Xu,Bingcong Lu,Zhengxue Cheng,Hongwei Hu,Ronghua Wu,Li Song*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级、高保真、低码率的3D说话人脸压缩框架，结合参数模型和高效神经渲染，实现在极低码率下高质量人脸重建。


<details>
  <summary>Details</summary>
Motivation: 随着沉浸式、交互式通信需求上升，3D视频会议对高保真3D说话人脸表示的需求增长，而当前2D压缩不保留细节，主流3D神经渲染方案算力消耗大，难以应用于实时低码率场景。

Method: 采用FLAME参数化人脸建模与3DGS神经渲染结合，仅实时传输必要人脸元数据，通过高斯头部模型高效重建，提出高斯属性压缩与MLP优化，构建紧凑表示与传输机制。

Result: 实验表明，该方法在极低码率下有优越的率失真性能，能够实现高质量3D人脸重建和渲染。

Conclusion: 本方案适用于实时3D视频会议等应用，在高质量和低码率之间取得较好平衡，提升了3D通信体验。

Abstract: The demand for immersive and interactive communication has driven advancements in 3D video conferencing, yet achieving high-fidelity 3D talking face representation at low bitrates remains a challenge. Traditional 2D video compression techniques fail to preserve fine-grained geometric and appearance details, while implicit neural rendering methods like NeRF suffer from prohibitive computational costs. To address these challenges, we propose a lightweight, high-fidelity, low-bitrate 3D talking face compression framework that integrates FLAME-based parametric modeling with 3DGS neural rendering. Our approach transmits only essential facial metadata in real time, enabling efficient reconstruction with a Gaussian-based head model. Additionally, we introduce a compact representation and compression scheme, including Gaussian attribute compression and MLP optimization, to enhance transmission efficiency. Experimental results demonstrate that our method achieves superior rate-distortion performance, delivering high-quality facial rendering at extremely low bitrates, making it well-suited for real-time 3D video conferencing applications.

</details>


### [20] [GeoRC: A Benchmark for Geolocation Reasoning Chains](https://arxiv.org/abs/2601.21278)
*Mohit Talreja,Joshua Diao,Jim Thannikary James,Radu Casapu,Tejas Santanam,Ethan Mendes,Alan Ritter,Wei Xu,James Hays*

Main category: cs.CV

TL;DR: 本文提出了地理位置推理链基准，发现VLM虽然能准确预测图片地理位置，但在推理链生成上远逊于人类专家，尤其是开源模型表现极差。


<details>
  <summary>Details</summary>
Motivation: 虽然VLM在全球地理位置识别上已经达到甚至超过人类专家，但缺乏可解释性，特别是生成推理链时常常出现臆想内容，导致推理不可信，亟需专门的评测基准和系统研究。

Method: 1. 设计并提出了全球位置识别任务的推理链基准（以GeoGuessr游戏为例），涵盖100+国家。2. 与GeoGuessr专业玩家（包括世界冠军）合作，为500个场景制作了800条专家推理链。3. 评估了用LLM和VLM做推理链评分的效果，发现Qwen 3表现与人类评分最接近。4. 对比Gemini、GPT-5等大型封闭VLM，以及Llama和Qwen等开源VLM模型在该基准的推理链表现。

Result: Gemini、GPT-5等封闭VLM模型在地理位置预测上媲美人类专家，但在推理链的可审计性上仍不及专家。开源VLM如Llama和Qwen几乎完全失败，表现仅略优于基线（即无视觉信息、仅凭地点知识“编造”推理链的LLM）。

Conclusion: 现有VLM虽能准确定位，但难以像人类专家那样提供可信的推理链，尤其缺乏对高分辨率图片中细粒度视觉属性的提取能力，未来研究需关注模型解释性与细粒度视觉理解。

Abstract: Vision Language Models (VLMs) are good at recognizing the global location of a photograph -- their geolocation prediction accuracy rivals the best human experts. But many VLMs are startlingly bad at explaining which image evidence led to their prediction, even when their location prediction is correct. The reasoning chains produced by VLMs frequently hallucinate scene attributes to support their location prediction (e.g. phantom writing, imagined infrastructure, misidentified flora). In this paper, we introduce the first benchmark for geolocation reasoning chains. We focus on the global location prediction task in the popular GeoGuessr game which draws from Google Street View spanning more than 100 countries. We collaborate with expert GeoGuessr players, including the reigning world champion, to produce 800 ground truth reasoning chains for 500 query scenes. These expert reasoning chains address hundreds of different discriminative visual attributes such as license plate shape, architecture, and soil properties to name just a few. We evaluate LLM-as-a-judge and VLM-as-a-judge strategies for scoring VLM-generated reasoning chains against our expert reasoning chains and find that Qwen 3 LLM-as-a-judge correlates best with human scoring. Our benchmark reveals that while large, closed-source VLMs such as Gemini and GPT 5 rival human experts at prediction locations, they still lag behind human experts when it comes to producing auditable reasoning chains. Open weights VLMs such as Llama and Qwen catastrophically fail on our benchmark -- they perform only slightly better than a baseline in which an LLM hallucinates a reasoning chain with oracle knowledge of the photo location but no visual information at all. We believe the gap between human experts and VLMs on this task points to VLM limitations at extracting fine-grained visual attributes from high resolution images.

</details>


### [21] [Token Entropy Regularization for Multi-modal Antenna Affiliation Identification](https://arxiv.org/abs/2601.21280)
*Dong Chen,Ruoyu Li,Xinyan Zhang,Jialei Xu,Ruoseng Zhao,Zhikang Zhang,Lingyun Li,Zizhuang Wei*

Main category: cs.CV

TL;DR: 本论文提出一种利用视频、天线几何特征和PCI信号相结合的多模态方法，实现自动化的天线归属识别，显著提升识别效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前天线归属识别主要依赖人工巡检，方法繁琐易出错，急需更高效、自动化的解决方案。

Method: 将基站视频、天线几何特征和物理小区识别码（PCI）信号融合，转化为多模态分类匹配任务。针对通用预训练模型在通信领域适用性差的问题，提出融合天线图像与PCI信号的专用训练框架，并在预训练阶段引入Token Entropy Regularization（TER）模块以优化特征对齐。

Result: 实验证明，引入TER模块能够加速模型收敛并显著提升性能，分析还发现首个token的熵具有模态相关性。

Conclusion: 本文提出的新多模态方法和TER模块能够有效提升天线归属识别的智能化和准确性，有望推动相关自动化运维落地，相关代码将在论文发表后开放。

Abstract: Accurate antenna affiliation identification is crucial for optimizing and maintaining communication networks. Current practice, however, relies on the cumbersome and error-prone process of manual tower inspections. We propose a novel paradigm shift that fuses video footage of base stations, antenna geometric features, and Physical Cell Identity (PCI) signals, transforming antenna affiliation identification into multi-modal classification and matching tasks. Publicly available pretrained transformers struggle with this unique task due to a lack of analogous data in the communications domain, which hampers cross-modal alignment. To address this, we introduce a dedicated training framework that aligns antenna images with corresponding PCI signals. To tackle the representation alignment challenge, we propose a novel Token Entropy Regularization module in the pretraining stage. Our experiments demonstrate that TER accelerates convergence and yields significant performance gains. Further analysis reveals that the entropy of the first token is modality-dependent. Code will be made available upon publication.

</details>


### [22] [WorldBench: Disambiguating Physics for Diagnostic Evaluation of World Models](https://arxiv.org/abs/2601.21282)
*Rishi Upadhyay,Howard Zhang,Jim Solomon,Ayush Agrawal,Pranay Boreddy,Shruti Satya Narayana,Yunhao Ba,Alex Wong,Celso M de Melo,Achuta Kadambi*

Main category: cs.CV

TL;DR: 本文提出了WorldBench，这是一个针对物理概念具体、解耦的视频基准，用于评估生成式世界模型的物理推理能力。实验表明主流世界模型在多个物理概念上表现出一致性缺陷，因此WorldBench为物理一致性的诊断提供了更精细且可扩展的工具。


<details>
  <summary>Details</summary>
Motivation: 生成式世界模型在机器人规划和自主系统等领域需求真实的物理一致性。然而，现有基准测试常常混合多个物理概念，无法精确诊断模型在哪些具体物理知识上存在不足。

Method: 作者提出了WorldBench，一个设计为“解耦评测”的视频基准，用于分别评估单一物理概念。WorldBench涵盖两层：直观物理理解（如物体永久性、比例/视角）和低层物理常数（如摩擦系数、流体黏度），这样可以分别考查模型对不同抽象层次物理规律的掌握。

Result: 世界领先的视频生成世界模型在WorldBench上测试时，在某些物理概念上普遍失败，无法达到物理一致性要求。具体表现为模型在处理特定物理规范时出现明显错误。

Conclusion: WorldBench通过分解和细致评测物理概念，为视频生成和世界模型的物理推理能力评估提供了更精细、可扩展的方法，有助于推动更健壮、更具泛化性的世界模型学习。

Abstract: Recent advances in generative foundational models, often termed "world models," have propelled interest in applying them to critical tasks like robotic planning and autonomous system training. For reliable deployment, these models must exhibit high physical fidelity, accurately simulating real-world dynamics. Existing physics-based video benchmarks, however, suffer from entanglement, where a single test simultaneously evaluates multiple physical laws and concepts, fundamentally limiting their diagnostic capability. We introduce WorldBench, a novel video-based benchmark specifically designed for concept-specific, disentangled evaluation, allowing us to rigorously isolate and assess understanding of a single physical concept or law at a time. To make WorldBench comprehensive, we design benchmarks at two different levels: 1) an evaluation of intuitive physical understanding with concepts such as object permanence or scale/perspective, and 2) an evaluation of low-level physical constants and material properties such as friction coefficients or fluid viscosity. When SOTA video-based world models are evaluated on WorldBench, we find specific patterns of failure in particular physics concepts, with all tested models lacking the physical consistency required to generate reliable real-world interactions. Through its concept-specific evaluation, WorldBench offers a more nuanced and scalable framework for rigorously evaluating the physical reasoning capabilities of video generation and world models, paving the way for more robust and generalizable world-model-driven learning.

</details>


### [23] [Gaussian Belief Propagation Network for Depth Completion](https://arxiv.org/abs/2601.21291)
*Jie Tang,Pingping Xie,Jian Li,Ping Tan*

Main category: cs.CV

TL;DR: 该论文提出了一种结合深度学习与概率图模型的端到端深度补全新方法GBPN，在输入稀疏、分布不规律的深度数据时，性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度补全方法受限于稀疏和不规则深度输入数据，尤其在高稀疏情况下性能下降严重，因此需要一种更有效结合稀疏信息与图模型优势的新方法。

Method: 提出了Gaussian Belief Propagation Network（GBPN），通过Graphical Model Construction Network（GMCN）动态构建场景相关的马尔可夫随机场（MRF），并结合高斯置信传播（GBP）推理，创新地预测MRF的结构和势能，包括自适应非局部边。同时融合串行和并行信息传递机制，强化稀疏信息的传播能力。

Result: GBPN在NYUv2和KITTI等主流数据集上取得了SOTA（最优）性能，无论在不同稀疏度、稀疏模式以及不同数据集上均显示出优越的性能和鲁棒性。

Conclusion: 将概率图模型与深度学习结合可显著提升深度补全在稀疏输入情形下的表现，所提GBPN具有卓越的泛化能力和鲁棒性，提升了深度补全领域的技术水平。

Abstract: Depth completion aims to predict a dense depth map from a color image with sparse depth measurements. Although deep learning methods have achieved state-of-the-art (SOTA), effectively handling the sparse and irregular nature of input depth data in deep networks remains a significant challenge, often limiting performance, especially under high sparsity. To overcome this limitation, we introduce the Gaussian Belief Propagation Network (GBPN), a novel hybrid framework synergistically integrating deep learning with probabilistic graphical models for end-to-end depth completion. Specifically, a scene-specific Markov Random Field (MRF) is dynamically constructed by the Graphical Model Construction Network (GMCN), and then inferred via Gaussian Belief Propagation (GBP) to yield the dense depth distribution. Crucially, the GMCN learns to construct not only the data-dependent potentials of MRF but also its structure by predicting adaptive non-local edges, enabling the capture of complex, long-range spatial dependencies. Furthermore, we enhance GBP with a serial \& parallel message passing scheme, designed for effective information propagation, particularly from sparse measurements. Extensive experiments demonstrate that GBPN achieves SOTA performance on the NYUv2 and KITTI benchmarks. Evaluations across varying sparsity levels, sparsity patterns, and datasets highlight GBPN's superior performance, notable robustness, and generalizable capability.

</details>


### [24] [Mam-App: A Novel Parameter-Efficient Mamba Model for Apple Leaf Disease Classification](https://arxiv.org/abs/2601.21307)
*Md Nadim Mahamood,Md Imran Hasan,Md Rasheduzzaman,Ausrukona Ray,Md Shafi Ud Doula,Kamrul Hasan*

Main category: cs.CV

TL;DR: 本论文提出了一种高效、轻量级的Mamba架构模型Mam-App，用于作物叶片病害的特征提取与分类，在多个主流数据集上取得了极高准确率并大幅减少了参数量，适用于低资源设备。


<details>
  <summary>Details</summary>
Motivation: 随着全球人口增长与技术进步，对粮食生产需求剧增，作物病害导致食物大量损失。需要高效且适合低资源环境的病害诊断模型，目前主流深度学习模型参数量大，难以部署在边缘设备上。

Method: 设计了一种基于Mamba的新型轻量级模型Mam-App，用于高效特征提取及病害分类，并在PlantVillage的苹果、玉米和马铃薯叶片病害数据集上进行测试。

Result: Mam-App模型在苹果叶片病害数据集上达到了99.58%的准确率，同时参数量仅为0.051M；在玉米和马铃薯数据集上同样表现优异，准确率分别为99.48%和98.46%。

Conclusion: Mam-App显著提升了在保持高精度的同时大幅降低了模型参数量，非常适合部署于无人机、移动设备等资源受限平台，表现出良好的通用性与鲁棒性。

Abstract: The rapid growth of the global population, alongside exponential technological advancement, has intensified the demand for food production. Meeting this demand depends not only on increasing agricultural yield but also on minimizing food loss caused by crop diseases. Diseases account for a substantial portion of apple production losses, despite apples being among the most widely produced and nutritionally valuable fruits worldwide. Previous studies have employed machine learning techniques for feature extraction and early diagnosis of apple leaf diseases, and more recently, deep learning-based models have shown remarkable performance in disease recognition. However, most state-of-the-art deep learning models are highly parameter-intensive, resulting in increased training and inference time. Although lightweight models are more suitable for user-friendly and resource-constrained applications, they often suffer from performance degradation. To address the trade-off between efficiency and performance, we propose Mam-App, a parameter-efficient Mamba-based model for feature extraction and leaf disease classification. The proposed approach achieves competitive state-of-the-art performance on the PlantVillage Apple Leaf Disease dataset, attaining 99.58% accuracy, 99.30% precision, 99.14% recall, and a 99.22% F1-score, while using only 0.051M parameters. This extremely low parameter count makes the model suitable for deployment on drones, mobile devices, and other low-resource platforms. To demonstrate the robustness and generalizability of the proposed model, we further evaluate it on the PlantVillage Corn Leaf Disease and Potato Leaf Disease datasets. The model achieves 99.48%, 99.20%, 99.34%, and 99.27% accuracy, precision, recall, and F1-score on the corn dataset and 98.46%, 98.91%, 95.39%, and 97.01% on the potato dataset, respectively.

</details>


### [25] [HiFi-Mesh: High-Fidelity Efficient 3D Mesh Generation via Compact Autoregressive Dependence](https://arxiv.org/abs/2601.21314)
*Yanfeng Li,Tao Tan,Qingquan Gao,Zhiwen Cao,Xiaohong liu,Yue Sun*

Main category: cs.CV

TL;DR: 本文提出了一种高效的3D网格生成方法——LANE，并通过自适应计算图重构策略（AdaGraph）进一步提升了推理速度和可扩展性，在生成速度、结构细节和几何一致性方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的autoregessive方法，虽然能够将高保真的3D网格序列化建模，但受限于资源利用率低，推理慢且难以处理大规模序列，导致表达细节有限。

Method: 提出Latent Autoregressive Network (LANE)，通过在生成过程中引入紧凑的自回归依赖，能够生成比以往方法长6倍的序列；并提出AdaGraph策略，实现生成过程的时空解耦，大幅克服原有推理效率瓶颈。

Result: LANE方法在序列长度支持、推理速度、结构细节及几何一致性方面都优于已有方法，实现了更高质量的3D网格生成。

Conclusion: LANE与AdaGraph策略共同提升了3D网格生成的效率与质量，为高质量三维模型生成提供了有效解决方案。

Abstract: High-fidelity 3D meshes can be tokenized into one-dimension (1D) sequences and directly modeled using autoregressive approaches for faces and vertices. However, existing methods suffer from insufficient resource utilization, resulting in slow inference and the ability to handle only small-scale sequences, which severely constrains the expressible structural details. We introduce the Latent Autoregressive Network (LANE), which incorporates compact autoregressive dependencies in the generation process, achieving a $6\times$ improvement in maximum generatable sequence length compared to existing methods. To further accelerate inference, we propose the Adaptive Computation Graph Reconfiguration (AdaGraph) strategy, which effectively overcomes the efficiency bottleneck of traditional serial inference through spatiotemporal decoupling in the generation process. Experimental validation demonstrates that LANE achieves superior performance across generation speed, structural detail, and geometric consistency, providing an effective solution for high-quality 3D mesh generation.

</details>


### [26] [Optimal Transport-Induced Samples against Out-of-Distribution Overconfidence](https://arxiv.org/abs/2601.21320)
*Keke Tang,Ziyong Du,Xiaofei Wang,Weilong Peng,Peican Zhu,Zhihong Tian*

Main category: cs.CV

TL;DR: 本文提出了一种利用最优传输（OT）几何特性缓解DNN对OOD（分布外）样本过度自信预测的方法，显著提升了模型的可靠性，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在处理OOD输入时往往会给出过度自信的错误预测，影响了实际应用中的可用性和安全性。因此, 亟需一种有效机制来降低模型在未知或模糊语义区域的过度自信。

Method: 作者基于半离散最优传输理论，提出利用OT诱导的奇异边界作为语义模糊且高风险区域。具体做法包括：1）在连续基础分布与训练数据隐空间之间构建OT问题，识别奇异边界；2）在这些边界附近采样，生成一类几何上有依据、语义模糊的分布外样本（OTIS）；3）在训练中对这些OTIS样本施加置信度抑制损失，引导模型在不确定区域做更有校准的预测。

Result: 大量实验表明，该方法可显著减缓DNN对OOD输入的过度自信问题，并在多个评测上超越了现有最先进方法。

Conclusion: 通过结合OT理论与置信度抑制机制，本文方法有效提升了深度模型在开放世界场景下的鲁棒性和可靠性。

Abstract: Deep neural networks (DNNs) often produce overconfident predictions on out-of-distribution (OOD) inputs, undermining their reliability in open-world environments. Singularities in semi-discrete optimal transport (OT) mark regions of semantic ambiguity, where classifiers are particularly prone to unwarranted high-confidence predictions. Motivated by this observation, we propose a principled framework to mitigate OOD overconfidence by leveraging the geometry of OT-induced singular boundaries. Specifically, we formulate an OT problem between a continuous base distribution and the latent embeddings of training data, and identify the resulting singular boundaries. By sampling near these boundaries, we construct a class of OOD inputs, termed optimal transport-induced OOD samples (OTIS), which are geometrically grounded and inherently semantically ambiguous. During training, a confidence suppression loss is applied to OTIS to guide the model toward more calibrated predictions in structurally uncertain regions. Extensive experiments show that our method significantly alleviates OOD overconfidence and outperforms state-of-the-art methods.

</details>


### [27] [Do Pathology Foundation Models Encode Disease Progression? A Pseudotime Analysis of Visual Representations](https://arxiv.org/abs/2601.21334)
*Pritika Vig,Ren-Chin Wu,William Lotter*

Main category: cs.CV

TL;DR: 该论文探讨了视觉基础模型在表征训练数据中的连续过程（如疾病进展）能力，发现模型能捕捉疾病状态的连续变化轨迹，并提出轨迹保真度作为衡量模型表征质量的新指标。


<details>
  <summary>Details</summary>
Motivation: 当前视觉基础模型多在静态、离散采样图像上训练，虽然分类效果强，但尚不清楚它们是否能捕捉数据中潜在的连续生物过程。在计算病理学等领域，如果模型能在隐空间中表征疾病的连续进展过程，将有助于更好反映生物机制、提升泛化和疾病特征量化。

Method: 采用diffusion pseudotime（一种单细胞转录组用的轨迹推断方法）分析多个基础视觉模型对于四种癌症进展的表征，检验模型隐空间能否沿着连贯方向排列疾病状态，并通过few-shot分类结果与轨迹保真度排名关联进行验证。

Result: 所有病理特定模型均能显著优于基线地还原疾病进展轨迹，纯视觉模型表现最佳（CRC-Serrated上τ>0.78）。各模型以轨迹保真度在参照疾病上的排名能强相关预测其在新疾病上的few-shot分类表现（ρ=0.92）。推断轨迹上的细胞类型组成变化与已知生物学规律一致。

Conclusion: 视觉基础模型可从静态图像隐式学习连续进展过程，轨迹保真度是表征质量的新辅助指标。该方法有望推广到其它观察到连续但数据为静态快照的领域。

Abstract: Vision foundation models trained on discretely sampled images achieve strong performance on classification benchmarks, yet whether their representations encode the continuous processes underlying their training data remains unclear. This question is especially pertinent in computational pathology, where we posit that models whose latent representations implicitly capture continuous disease progression may better reflect underlying biology, support more robust generalization, and enable quantitative analyses of features associated with disease transitions. Using diffusion pseudotime, a method developed to infer developmental trajectories from single-cell transcriptomics, we probe whether foundation models organize disease states along coherent progression directions in representation space. Across four cancer progressions and six models, we find that all pathology-specific models recover trajectory orderings significantly exceeding null baselines, with vision-only models achieving the highest fidelities $(τ> 0.78$ on CRC-Serrated). Model rankings by trajectory fidelity on reference diseases strongly predict few-shot classification performance on held-out diseases ($ρ= 0.92$), and exploratory analysis shows cell-type composition varies smoothly along inferred trajectories in patterns consistent with known stromal remodeling. Together, these results demonstrate that vision foundation models can implicitly learn to represent continuous processes from independent static observations, and that trajectory fidelity provides a complementary measure of representation quality beyond downstream performance. While demonstrated in pathology, this framework could be applied to other domains where continuous processes are observed through static snapshots.

</details>


### [28] [SR$^{2}$-Net: A General Plug-and-Play Model for Spectral Refinement in Hyperspectral Image Super-Resolution](https://arxiv.org/abs/2601.21338)
*Ji-Xuan He,Guohang Zhuang,Junge Bo,Tingyi Li,Chen Ling,Yanan Qiao*

Main category: cs.CV

TL;DR: 该论文提出了一种轻量级可插拔的高光谱图像超分辨率修正网络（SR2-Net），能够提升空间分辨率并保持光谱一致性。该方法可用于提升各种HSI-SR模型的性能，实验显示其对重建光谱的一致性和图像质量有显著改善。


<details>
  <summary>Details</summary>
Motivation: 当前许多高光谱图像超分辨率（HSI-SR）方法虽然在提升空间分辨率上有进展，但往往忽视了波段间的光谱一致性，导致物理上不合理的伪影。现有一些通过架构设计保证光谱一致性的方法又牺牲了通用性和灵活性，因此需要新的方法平衡空间提升与光谱一致性。

Method: 作者提出了一种可作为模块插入的SR2-Net修正器，无需更改主模型架构。其包括两个关键组件：（1）分层光谱-空间协同注意力机制（H-S3A），用于增强波段间信息交互；（2）流形一致性修正（MCR），将重建光谱限制在合理的流形空间内。另引入降质一致性损失以保证输出和观测输入的一致性。

Result: 在多个公开基准数据集和不同框架下进行了大量实验，结果显示SR2-Net能够以极低的计算成本，显著提升各主流HSI-SR模型的光谱保真度和总体重建质量。

Conclusion: SR2-Net作为一种通用且高效的修正模块，可以简单地增强现有多种HSI-SR方法，有效缓解现有方法的光谱不一致问题，并带来更高质量的超分辨率重建。

Abstract: HSI-SR aims to enhance spatial resolution while preserving spectrally faithful and physically plausible characteristics. Recent methods have achieved great progress by leveraging spatial correlations to enhance spatial resolution. However, these methods often neglect spectral consistency across bands, leading to spurious oscillations and physically implausible artifacts. While spectral consistency can be addressed by designing the network architecture, it results in a loss of generality and flexibility. To address this issue, we propose a lightweight plug-and-play rectifier, physically priors Spectral Rectification Super-Resolution Network (SR$^{2}$-Net), which can be attached to a wide range of HSI-SR models without modifying their architectures. SR$^{2}$-Net follows an enhance-then-rectify pipeline consisting of (i) Hierarchical Spectral-Spatial Synergy Attention (H-S$^{3}$A) to reinforce cross-band interactions and (ii) Manifold Consistency Rectification (MCR) to constrain the reconstructed spectra to a compact, physically plausible spectral manifold. In addition, we introduce a degradation-consistency loss to enforce data fidelity by encouraging the degraded SR output to match the observed low resolution input. Extensive experiments on multiple benchmarks and diverse backbones demonstrate consistent improvements in spectral fidelity and overall reconstruction quality with negligible computational overhead. Our code will be released upon publication.

</details>


### [29] [Dynamical Adapter Fusion: Constructing A Global Adapter for Pre-Trained Model-based Class-Incremental Learning](https://arxiv.org/abs/2601.21341)
*Ruiqi Liu,Boyu Diao,Zijia An,Zhulin An,Fei Wang,Yongjun Xu*

Main category: cs.CV

TL;DR: 论文提出了一种用于类增量学习（CIL）的动态适配器融合（DAF）方法，有效整合多个任务适配器，兼顾知识保持与新知识学习，在多个基准测试上达到了先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有CIL方法通常通过冻结预训练模型并为每个新任务训练轻量适配器，但存储多个任务参数不利于共享与调用，同时参数简单融合又会导致遗忘与性能下降。论文旨在解决参数融合过程中的知识遗忘与干扰问题，提升融合适配器的表现。

Method: DAF方法基于PAC-Bayes定理，提出融合三类参数（任务专属适配器、已有全局适配器、初始化参数）的全局适配器，并利用损失函数的泰勒展开，动态寻优融合系数，实现稳定性与可塑性的平衡。同时，提出鲁棒初始化策略以增强全局模式学习。

Result: 在多个类增量学习基准上，DAF方法表现优异，取得了SOTA结果，优于现有主流增量学习方法。

Conclusion: DAF通过理论驱动的动态融合机制，成功解决了知识遗忘和互扰问题，为类增量学习提供了更具推广性和实用性的适配器结构。

Abstract: Class-Incremental Learning (CIL) requires models to continuously acquire new classes without forgetting previously learned ones. A dominant paradigm involves freezing a pre-trained model and training lightweight, task-specific adapters. However, maintaining task-specific parameters hinders knowledge transfer and incurs high retrieval costs, while naive parameter fusion often leads to destructive interference and catastrophic forgetting. To address these challenges, we propose Dynamical Adapter Fusion (DAF) to construct a single robust global adapter. Grounded in the PAC-Bayes theorem, we derive a fusion mechanism that explicitly integrates three components: the optimized task-specific adapter parameters, the previous global adapter parameters, and the initialization parameters. We utilize the Taylor expansion of the loss function to derive the optimal fusion coefficients, dynamically achieving the best balance between stability and plasticity. Furthermore, we propose a Robust Initialization strategy to effectively capture global knowledge patterns. Experiments on multiple CIL benchmarks demonstrate that DAF achieves state-of-the-art (SOTA) performance.

</details>


### [30] [Semantic-Guided Dynamic Sparsification for Pre-Trained Model-based Class-Incremental Learning](https://arxiv.org/abs/2601.21345)
*Ruiqi Liu,Boyu Diao,Zijia An,Runjie Shao,Zhulin An,Fei Wang,Yongjun Xu*

Main category: cs.CV

TL;DR: 本文针对增量式学习存在的知识遗忘问题，提出了一种新的动态稀疏化方法（SGDS），通过在激活空间中对不同类别进行有针对性的子空间分配，在不牺牲模型灵活性的情况下，有效缓解任务间的干扰，并取得了最先进的实验效果。


<details>
  <summary>Details</summary>
Motivation: 现有增量学习方法常通过冻结预训练模型并采用轻量适配器来避免遗忘，但参数空间的正交约束会影响模型对新知识的学习与适应能力。因此，作者希望提出新方法，在兼顾保持旧知识的同时提升学习新类别的能力。

Method: 提出了语义引导的动态稀疏化（SGDS）方法。该方法不再对参数空间强加正交等硬性约束，而是直接在激活空间中进行操作。其核心思想是让类别间关系指导激活子空间的分布：相似类别共享紧凑子空间以促进知识迁移，不相似类别则分配不重叠的子空间以避免相互干扰，从而实现激活空间的自适应雕刻。

Result: 在多个增量学习基准数据集上进行的大量实验表明，SGDS方法的表现优于现有主流方法，取得了最先进的性能。

Conclusion: SGDS以激活空间稀疏子空间分配取代参数空间约束，有效平衡了模型的稳定性与可塑性，为增量式学习的知识保持与迁移提供了新思路，且在实验中验证了其实用性和有效性。

Abstract: Class-Incremental Learning (CIL) requires a model to continually learn new classes without forgetting old ones. A common and efficient solution freezes a pre-trained model and employs lightweight adapters, whose parameters are often forced to be orthogonal to prevent inter-task interference. However, we argue that this parameter-constraining method is detrimental to plasticity. To this end, we propose Semantic-Guided Dynamic Sparsification (SGDS), a novel method that proactively guides the activation space by governing the orientation and rank of its subspaces through targeted sparsification. Specifically, SGDS promotes knowledge transfer by encouraging similar classes to share a compact activation subspace, while simultaneously preventing interference by assigning non-overlapping activation subspaces to dissimilar classes. By sculpting class-specific sparse subspaces in the activation space, SGDS effectively mitigates interference without imposing rigid constraints on the parameter space. Extensive experiments on various benchmark datasets demonstrate the state-of-the-art performance of SGDS.

</details>


### [31] [Towards Geometry-Aware and Motion-Guided Video Human Mesh Recovery](https://arxiv.org/abs/2601.21376)
*Hongjun Chen,Huan Zheng,Wencheng Han,Jianbing Shen*

Main category: cs.CV

TL;DR: 提出了一种新的视频3D人体网格恢复方法HMRMamba，结合了结构化状态空间模型和几何感知机制，在多个基准中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有HMR方法由于依赖不准确的3D姿态锚点和对复杂时空动态建模能力不足，导致生成的结果存在物理不合理的问题。

Method: 1. 设计了几何感知提升模块，采用创新的dual-scan Mamba架构，将2D到3D的姿态估计与图像几何特征直接结合，生成可靠的3D姿态序列。2. 提出由运动引导的重建网络，利用上述3D姿态锚点，显式建模人体运动学特征，提升网格在遮挡和运动模糊下的一致性和鲁棒性。

Result: 在3DPW、MPI-INF-3DHP和Human3.6M等数据集上，HMRMamba在重建精度、时序一致性和计算效率方面都超越了现有方法，创下最新SOTA表现。

Conclusion: 通过结合结构化状态空间模型与新颖的模块设计，HMRMamba有效克服了现有HMR方法的局限，极大提升了3D人体网格恢复的物理合理性与实用性能。

Abstract: Existing video-based 3D Human Mesh Recovery (HMR) methods often produce physically implausible results, stemming from their reliance on flawed intermediate 3D pose anchors and their inability to effectively model complex spatiotemporal dynamics. To overcome these deep-rooted architectural problems, we introduce HMRMamba, a new paradigm for HMR that pioneers the use of Structured State Space Models (SSMs) for their efficiency and long-range modeling prowess. Our framework is distinguished by two core contributions. First, the Geometry-Aware Lifting Module, featuring a novel dual-scan Mamba architecture, creates a robust foundation for reconstruction. It directly grounds the 2D-to-3D pose lifting process with geometric cues from image features, producing a highly reliable 3D pose sequence that serves as a stable anchor. Second, the Motion-guided Reconstruction Network leverages this anchor to explicitly process kinematic patterns over time. By injecting this crucial temporal awareness, it significantly enhances the final mesh's coherence and robustness, particularly under occlusion and motion blur. Comprehensive evaluations on 3DPW, MPI-INF-3DHP, and Human3.6M benchmarks confirm that HMRMamba sets a new state-of-the-art, outperforming existing methods in both reconstruction accuracy and temporal consistency while offering superior computational efficiency.

</details>


### [32] [Rectifying Geometry-Induced Similarity Distortions for Real-World Aerial-Ground Person Re-Identification](https://arxiv.org/abs/2601.21405)
*Kailash A. Hambarde,Hugo Proença*

Main category: cs.CV

TL;DR: 本文提出了一种名为GIQT的新方法，通过显式地利用摄像头几何条件校正注意力机制中的query-key相似度计算，从而显著提升了空地行人重识别任务下的匹配鲁棒性，尤其是在极端视角与尺度差异情况下。实验显示该方法在多个基准数据集上优于现有方法，且计算开销极低。


<details>
  <summary>Details</summary>
Motivation: 空地视角下的行人重识别受到极端视角与距离差异带来的几何畸变困扰，现有方法普遍假设注意力机制的点积相似度在不同几何条件下依然可靠，但作者认为该假设在实际极端情况下并不成立，因此需要针对几何畸变提出有效的对策。

Method: 本文提出了Geometry-Induced Query-Key Transformation（GIQT）模块，通过低秩变换显式校正由摄像头几何条件导致的query-key相似度空间畸变，并引入几何条件生成的全局提示，引导特征表示在整体和局部两方面适应不同的视角与尺度变化。该方法不改变原有特征本身和注意力机制的核心结构，而是对相似度计算方式进行适应性补偿。

Result: 在四个主流空地行人重识别基准数据集上，所提方法相较于目前主流几何感知和提示驱动类方法，在极端和新颖几何配置下展现了更好的鲁棒性，并且增加的计算开销很小。

Conclusion: GIQT方法通过几何感知校正相似度计算，有效解决了极端视角与尺度差异下的识别准确性问题，为空地行人重识别任务提供了高效且通用的技术解决方案，对基于注意力机制的跨视角识别问题具有重要启示。

Abstract: Aerial-ground person re-identification (AG-ReID) is fundamentally challenged by extreme viewpoint and distance discrepancies between aerial and ground cameras, which induce severe geometric distortions and invalidate the assumption of a shared similarity space across views. Existing methods primarily rely on geometry-aware feature learning or appearance-conditioned prompting, while implicitly assuming that the geometry-invariant dot-product similarity used in attention mechanisms remains reliable under large viewpoint and scale variations. We argue that this assumption does not hold. Extreme camera geometry systematically distorts the query-key similarity space and degrades attention-based matching, even when feature representations are partially aligned.
  To address this issue, we introduce Geometry-Induced Query-Key Transformation (GIQT), a lightweight low-rank module that explicitly rectifies the similarity space by conditioning query-key interactions on camera geometry. Rather than modifying feature representations or the attention formulation itself, GIQT adapts the similarity computation to compensate for dominant geometry-induced anisotropic distortions. Building on this local similarity rectification, we further incorporate a geometry-conditioned prompt generation mechanism that provides global, view-adaptive representation priors derived directly from camera geometry.
  Experiments on four aerial-ground person re-identification benchmarks demonstrate that the proposed framework consistently improves robustness under extreme and previously unseen geometric conditions, while introducing minimal computational overhead compared to state-of-the-art methods.

</details>


### [33] [Generation Enhances Understanding in Unified Multimodal Models via Multi-Representation Generation](https://arxiv.org/abs/2601.21406)
*Zihan Su,Hongyang Wei,Kangrui Cen,Yong Wang,Guanhua Chen,Chun Yuan,Xiangxiang Chu*

Main category: cs.CV

TL;DR: 本文提出了一种新的后训练方法UniMRG，通过引入多种辅助生成任务，提升统一多模态模型（UMM）的视觉理解能力。


<details>
  <summary>Details</summary>
Motivation: 目前大部分后训练方法主要关注于利用理解提升生成能力，反向利用生成促进理解的方向鲜有探索，有望进一步完善多模态模型的表现。

Method: 提出UniMRG方法，训练UMMs在常规视觉理解目标之外，还要生成输入图像的像素（重建）、深度（几何）、分割（结构）等多种内在表示，从而捕获图片的补充信息。该方法具有架构无关性。

Result: 大量实验表明，该方法能在多种UMM架构下显著提升细致感知能力、减少幻觉现象、增强空间理解以及提升生成能力。

Conclusion: 通过将多种生成任务融入视觉理解训练流程，可以有效增强统一多模态模型的整体理解与生成效果。

Abstract: Unified Multimodal Models (UMMs) integrate both visual understanding and generation within a single framework. Their ultimate aspiration is to create a cycle where understanding and generation mutually reinforce each other. While recent post-training methods have successfully leveraged understanding to enhance generation, the reverse direction of utilizing generation to improve understanding remains largely unexplored. In this work, we propose UniMRG (Unified Multi-Representation Generation), a simple yet effective architecture-agnostic post-training method. UniMRG enhances the understanding capabilities of UMMs by incorporating auxiliary generation tasks. Specifically, we train UMMs to generate multiple intrinsic representations of input images, namely pixel (reconstruction), depth (geometry), and segmentation (structure), alongside standard visual understanding objectives. By synthesizing these diverse representations, UMMs capture complementary information regarding appearance, spatial relations, and structural layout. Consequently, UMMs develop a deeper and more comprehensive understanding of visual inputs. Extensive experiments across diverse UMM architectures demonstrate that our method notably enhances fine-grained perception, reduces hallucinations, and improves spatial understanding, while simultaneously boosting generation capabilities.

</details>


### [34] [MPF-Net: Exposing High-Fidelity AI-Generated Video Forgeries via Hierarchical Manifold Deviation and Micro-Temporal Fluctuations](https://arxiv.org/abs/2601.21408)
*Xinan He,Kaiqing Lin,Yue Zhou,Jiaming Zhong,Wei Ye,Wenhui Yi,Bing Fan,Feng Ding,Haodong Li,Bo Cao,Bin Li*

Main category: cs.CV

TL;DR: 提出了一种基于“流形投影波动（MPF）”的新颖方法，通过层次化双路径框架检测高质量AI生成视频，能够区分即使是最先进的伪造视频与真实视频。


<details>
  <summary>Details</summary>
Motivation: 随着视频生成模型（如Veo和Wan）的进步，生成内容的视觉质量极高，常规宏观语义错误和时间不一致现象变得不明显，使真假视频难以区分，亟需新的检测方法。

Method: 提出一个层次化双路径检测框架。第一路径称为静态流形偏差分支，结合大规模视觉基础模型的感知边界，捕捉视频帧中空间上的残留异常。第二路径即微观时序波动分支，针对首轮空间检测未检出的高保真生成视频，通过分析帧与帧间的MPF，进一步揭示连贯视觉下的伪造痕迹。

Result: 该方法可以有效鉴别最新的高拟真AI生成视频，不仅发现全局性的物理或语义偏差，也能探测视觉上完美的伪造视频中难以察觉的微小结构模式。

Conclusion: 提出的层次化双路径框架为视频伪造检测提供了新的理论和工具，无论伪造视频在宏观或微观尺度上如何逼真，都能有效暴露其伪造本质。

Abstract: With the rapid advancement of video generation models such as Veo and Wan, the visual quality of synthetic content has reached a level where macro-level semantic errors and temporal inconsistencies are no longer prominent. However, this does not imply that the distinction between real and cutting-edge high-fidelity fake is untraceable. We argue that AI-generated videos are essentially products of a manifold-fitting process rather than a physical recording. Consequently, the pixel composition logic of consecutive adjacent frames residual in AI videos exhibits a structured and homogenous characteristic. We term this phenomenon `Manifold Projection Fluctuations' (MPF). Driven by this insight, we propose a hierarchical dual-path framework that operates as a sequential filtering process. The first, the Static Manifold Deviation Branch, leverages the refined perceptual boundaries of Large-Scale Vision Foundation Models (VFMs) to capture residual spatial anomalies or physical violations that deviate from the natural real-world manifold (off-manifold). For the remaining high-fidelity videos that successfully reside on-manifold and evade spatial detection, we introduce the Micro-Temporal Fluctuation Branch as a secondary, fine-grained filter. By analyzing the structured MPF that persists even in visually perfect sequences, our framework ensures that forgeries are exposed regardless of whether they manifest as global real-world manifold deviations or subtle computational fingerprints.

</details>


### [35] [From Implicit Ambiguity to Explicit Solidity: Diagnosing Interior Geometric Degradation in Neural Radiance Fields for Dense 3D Scene Understanding](https://arxiv.org/abs/2601.21421)
*Jiangsan Zhao,Jakob Geipel,Kryzysztof Kusnierek*

Main category: cs.CV

TL;DR: 本论文研究了NeRFs在高密度自遮挡场景中定量3D分析的局限，并提出通过显式几何管道（SVRaster）显著提升实例恢复率。


<details>
  <summary>Details</summary>
Motivation: 虽然NeRFs在多视图重建方面有突出能力，但其在密集且自遮挡场景中的定量分析表现尚不明确。实际应用中发现，现有的NeRFs在这些场景下往往重建出空心或碎片化结构，导致实例数量系统性低估。论文旨在揭示这一问题的根源，并探索更可靠的解决方案。

Method: 首先通过合成数据集上的对照实验，分析和验证现有NeRFs在高遮挡情况下的缺陷。随后，提出一种基于结构光流（SfM）初始化、稀疏体素栅格化（SVRaster）的显式几何管道。该方法通过将二维分割掩码投影到显式体素网格中、并递归拆分来保证实体的几何分离性，从而更准确地恢复密集场景中的实例数。

Result: 实验表明，在高密度自遮挡的场景下，主流的掩码监督NeRF的实例恢复率饱和在约89%，而提出的SVRaster方法可以提升到95.8%。在掩码监督退化的条件下，显式几何方法比隐式基线多恢复了43%的实例数。

Conclusion: 显式几何先验对于在强自遮挡场景下进行可靠定量3D分析是不可或缺的。相比隐式NeRF，基于SfM的显式方法能显著提升多实例恢复的准确性与鲁棒性。

Abstract: Neural Radiance Fields (NeRFs) have emerged as a powerful paradigm for multi-view reconstruction, complementing classical photogrammetric pipelines based on Structure-from-Motion (SfM) and Multi-View Stereo (MVS). However, their reliability for quantitative 3D analysis in dense, self-occluding scenes remains poorly understood. In this study, we identify a fundamental failure mode of implicit density fields under heavy occlusion, which we term Interior Geometric Degradation (IGD). We show that transmittance-based volumetric optimization satisfies photometric supervision by reconstructing hollow or fragmented structures rather than solid interiors, leading to systematic instance undercounting. Through controlled experiments on synthetic datasets with increasing occlusion, we demonstrate that state-of-the-art mask-supervised NeRFs saturate at approximately 89% instance recovery in dense scenes, despite improved surface coherence and mask quality. To overcome this limitation, we introduce an explicit geometric pipeline based on Sparse Voxel Rasterization (SVRaster), initialized from SfM feature geometry. By projecting 2D instance masks onto an explicit voxel grid and enforcing geometric separation via recursive splitting, our approach preserves physical solidity and achieves a 95.8% recovery rate in dense clusters. A sensitivity analysis using degraded segmentation masks further shows that explicit SfM-based geometry is substantially more robust to supervision failure, recovering 43% more instances than implicit baselines. These results demonstrate that explicit geometric priors are a prerequisite for reliable quantitative analysis in highly self-occluding 3D scenes.

</details>


### [36] [MultiModal Fine-tuning with Synthetic Captions](https://arxiv.org/abs/2601.21426)
*Shohei Enomoto,Shin'ya Yamaguchi*

Main category: cs.CV

TL;DR: 提出用多模态大模型生成图像描述，将单模态数据集转为多模态，并优化下游微调方式，提升分类效果，尤其在小样本下表现突出。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习预训练阶段已迈向多模态（比如图文结合），但微调阶段仍多为单模态，导致不能充分利用预训练获得的多模态表征能力，这限制了模型性能。作者希望通过改进微调方法，更好发挥多模态预训练的优势。

Method: 1. 利用多模态大模型（MLLM）结合类别标签和领域上下文，为原本无描述的图像生成高质量合成描述，实现数据集由单模态转为多模态。
2. 用合成的图文数据进行模型微调，并引入有监督对比损失函数，加强同类样本的聚类效果。
3. 提出新的推理方法：用每张图片对应的多条合成描述生成的文本嵌入平均值，辅助分类决策。

Result: 在13个图像分类基准测试中，该方法整体优于传统单模态微调方法，且在小样本学习场景中提升尤其显著。

Conclusion: 本文提出的方法有效弥补了多模态预训练与微调阶段的失配问题，定义了数据集增强的新范式，为深度模型微调带来了明显性能提升。

Abstract: In this paper, we address a fundamental gap between pre-training and fine-tuning of deep neural networks: while pre-training has shifted from unimodal to multimodal learning with enhanced visual understanding, fine-tuning predominantly remains unimodal, limiting the benefits of rich pre-trained representations. To bridge this gap, we propose a novel approach that transforms unimodal datasets into multimodal ones using Multimodal Large Language Models (MLLMs) to generate synthetic image captions for fine-tuning models with a multimodal objective. Our method employs carefully designed prompts incorporating class labels and domain context to produce high-quality captions tailored for classification tasks. Furthermore, we introduce a supervised contrastive loss function that explicitly encourages clustering of same-class representations during fine-tuning, along with a new inference technique that leverages class-averaged text embeddings from multiple synthetic captions per image. Extensive experiments across 13 image classification benchmarks demonstrate that our approach outperforms baseline methods, with particularly significant improvements in few-shot learning scenarios. Our work establishes a new paradigm for dataset enhancement that effectively bridges the gap between multimodal pre-training and fine-tuning. Our code is available at https://github.com/s-enmt/MMFT.

</details>


### [37] [Spava: Accelerating Long-Video Understanding via Sequence-Parallelism-aware Approximate Attention](https://arxiv.org/abs/2601.21444)
*Yuxiang Huang,Mingye Li,Xu Han,Chaojun Xiao,Weilin Zhao,Ao Sun,Ziqi Yuan,Hao Zhou,Fandong Meng,Zhiyuan Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为Spava的序列并行推理框架，通过跨多GPU优化注意力机制，加速大多模态模型（LMMs）在长视频上的推理过程，实现了更快的速度且性能无显著下降。


<details>
  <summary>Details</summary>
Motivation: 长视频推理中的计算瓶颈主要在于LMMs的prefill阶段，现有方法受限于单GPU稀疏注意力或视觉嵌入压缩，难以有效加速且影响性能，因此亟需一种能提高效率又不损失性能的新方法。

Method: Spava框架通过将近似注意力机制分布在多个GPU上，实现了视觉嵌入的无损并行处理。同时结合负载均衡和融合前向过程等系统级优化，充分提升了推理速度和多GPU资源利用率。

Result: 实验结果表明，Spava在不显著损失性能的前提下，推理速度相较于FlashAttn、ZigZagRing和APB分别提升了12.72倍、1.70倍和1.18倍。

Conclusion: Spava框架有效突破了现有长视频推理中的效率与性能难题，为多模态大模型的长视频推理提供了新的高效解决方案。

Abstract: The efficiency of long-video inference remains a critical bottleneck, mainly due to the dense computation in the prefill stage of Large Multimodal Models (LMMs). Existing methods either compress visual embeddings or apply sparse attention on a single GPU, yielding limited acceleration or degraded performance and restricting LMMs from handling longer, more complex videos. To overcome these issues, we propose Spava, a sequence-parallel framework with optimized attention that accelerates long-video inference across multiple GPUs. By distributing approximate attention, Spava reduces computation and increases parallelism, enabling efficient processing of more visual embeddings without compression and thereby improving task performance. System-level optimizations, such as load balancing and fused forward passes, further unleash the potential of Spava, delivering speedups of 12.72x, 1.70x, and 1.18x over FlashAttn, ZigZagRing, and APB, without notable performance loss. Code available at https://github.com/thunlp/APB

</details>


### [38] [Variance & Greediness: A comparative study of metric-learning losses](https://arxiv.org/abs/2601.21450)
*Donghuo Zeng,Hao Niu,Zhi Li,Masato Taya*

Main category: cs.CV

TL;DR: 本文通过提出一套新颖的诊断框架（主要包括类内/类间方差和梯度指标），系统比较了七种主流度量学习损失函数在图像检索任务中的表现，并为实际应用提供了选择建议。


<details>
  <summary>Details</summary>
Motivation: 尽管度量学习在图像检索等任务中非常重要，但不同损失函数对嵌入空间几何结构及优化动态的影响尚缺乏系统了解与量化分析。因此，作者希望通过新的工具和系统对比，加深对各主流损失行为方式的理解，辅以实际应用指导。

Method: 作者提出并利用了VARIANCE（分析类内、类间方差）和GREEDINESS（激活率和梯度范数）两个诊断框架，选取七种典型的度量学习损失函数（如Contrastive, Triplet, N-pair, InfoNCE, ArcFace, SCL, CCL），在五个公开图像检索数据集上进行评估和对比。

Result: 分析显示，Triplet和SCL损失能在细粒度检索任务中保留更高的类内方差、形成更明确的类间边界，从而提升首位检索准确率；Contrastive和InfoNCE则通过多次小幅更新快速压缩嵌入空间，加快收敛但容易损失类结构多样性；N-pair虽提升类间均值分离但类间间隔分布不均。

Conclusion: 各种主流损失函数在收敛效率和嵌入空间多样性（颗粒度）之间存在权衡：当需保留多样性和识别难样本时宜用Triplet/SCL，追求快速压缩则推荐Contrastive/InfoNCE。本工作为算法选择提供了理论理解与实用建议。

Abstract: Metric learning is central to retrieval, yet its effects on embedding geometry and optimization dynamics are not well understood. We introduce a diagnostic framework, VARIANCE (intra-/inter-class variance) and GREEDINESS (active ratio and gradient norms), to compare seven representative losses, i.e., Contrastive, Triplet, N-pair, InfoNCE, ArcFace, SCL, and CCL, across five image-retrieval datasets. Our analysis reveals that Triplet and SCL preserve higher within-class variance and clearer inter-class margins, leading to stronger top-1 retrieval in fine-grained settings. In contrast, Contrastive and InfoNCE compact embeddings are achieved quickly through many small updates, accelerating convergence but potentially oversimplifying class structures. N-pair achieves a large mean separation but with uneven spacing. These insights reveal a form of efficiency-granularity trade-off and provide practical guidance: prefer Triplet/SCL when diversity preservation and hard-sample discrimination are critical, and Contrastive/InfoNCE when faster embedding compaction is desired.

</details>


### [39] [Mining Forgery Traces from Reconstruction Error: A Weakly Supervised Framework for Multimodal Deepfake Temporal Localization](https://arxiv.org/abs/2601.21458)
*Midou Guo,Qilin Yin,Wei Lu,Xiangyang Luo,Rui Yang*

Main category: cs.CV

TL;DR: 本文提出了一种名为RT-DeepLoc的弱监督时序Deepfake定位方法，通过重建误差定位伪造视频片段，实现高效且无需帧级标注的Deepfake检测。


<details>
  <summary>Details</summary>
Motivation: 当前深度伪造（Deepfake）技术越来越精细，主要表现为局部、间断性的篡改，这对伪造的时序定位提出了更高要求。但帧级标注数据获取成本极高，因此亟需仅依赖视频级标签的弱监督方法来解决此问题。

Method: 论文提出RT-DeepLoc框架，核心思路是：使用只有真实数据训练的Masked Autoencoder（MAE）学习视频的时空特征，利用其在伪造片段上的重建误差作为定位依据。同时设计了新的Asymmetric Intra-video Contrastive Loss (AICL)损失，通过重建差异指导特征紧致性，从而稳定区分真实和伪造区域。

Result: RT-DeepLoc在包括LAV-DF在内的大规模数据集上进行了大量实验，结果显示在弱监督的时序伪造检测任务上达到了SOTA（最佳现有）性能。

Conclusion: 通过结合基于重建的异常检测和弱监督对比学习，RT-DeepLoc不仅有效提升了时序范围内的Deepfake精细定位能力，还展现了较强的泛化性，为实际落地提供了更具可行性的解决方案。

Abstract: Modern deepfakes have evolved into localized and intermittent manipulations that require fine-grained temporal localization. The prohibitive cost of frame-level annotation makes weakly supervised methods a practical necessity, which rely only on video-level labels. To this end, we propose Reconstruction-based Temporal Deepfake Localization (RT-DeepLoc), a weakly supervised temporal forgery localization framework that identifies forgeries via reconstruction errors. Our framework uses a Masked Autoencoder (MAE) trained exclusively on authentic data to learn its intrinsic spatiotemporal patterns; this allows the model to produce significant reconstruction discrepancies for forged segments, effectively providing the missing fine-grained cues for localization. To robustly leverage these indicators, we introduce a novel Asymmetric Intra-video Contrastive Loss (AICL). By focusing on the compactness of authentic features guided by these reconstruction cues, AICL establishes a stable decision boundary that enhances local discrimination while preserving generalization to unseen forgeries. Extensive experiments on large-scale datasets, including LAV-DF, demonstrate that RT-DeepLoc achieves state-of-the-art performance in weakly-supervised temporal forgery localization.

</details>


### [40] [Hypernetwork-Based Adaptive Aggregation for Multimodal Multiple-Instance Learning in Predicting Coronary Calcium Debulking](https://arxiv.org/abs/2601.21479)
*Kaito Shiku,Ichika Seo,Tetsuya Matoba,Rissei Hino,Yasuhiro Nakano,Ryoma Bise*

Main category: cs.CV

TL;DR: 本文提出了一种新方法，通过CT图像和病人表格数据，首次尝试自动估算是否需要对冠状动脉钙化进行去除处理。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以根据影像和具体病人情况自动判断是否需要器械去钙化，医生依赖主观经验和多表格数据，缺乏自动决策支持。

Method: 作者将问题建模为多示例学习（MIL）任务，提出基于超网络的自适应聚合Transformer（HyperAdAgFormer），该方法可根据每个病人的表格信息，通过超网络动态调整特征融合策略。

Result: 在临床数据集上的实验表明，HyperAdAgFormer表现优异，效果优于传统方法。

Conclusion: HyperAdAgFormer可实现个性化、自动化的冠状动脉钙化去除需求评估，对临床决策具有实际参考价值，源代码已开源。

Abstract: In this paper, we present the first attempt to estimate the necessity of debulking coronary artery calcifications from computed tomography (CT) images. We formulate this task as a Multiple-instance Learning (MIL) problem. The difficulty of this task lies in that physicians adjust their focus and decision criteria for device usage according to tabular data representing each patient's condition. To address this issue, we propose a hypernetwork-based adaptive aggregation transformer (HyperAdAgFormer), which adaptively modifies the feature aggregation strategy for each patient based on tabular data through a hypernetwork. The experiments using the clinical dataset demonstrated the effectiveness of HyperAdAgFormer. The code is publicly available at https://github.com/Shiku-Kaito/HyperAdAgFormer.

</details>


### [41] [Causal World Modeling for Robot Control](https://arxiv.org/abs/2601.21998)
*Lin Li,Qihang Zhang,Yiming Luo,Shuai Yang,Ruilin Wang,Fei Han,Mingrui Yu,Zelin Gao,Nan Xue,Xing Zhu,Yujun Shen,Yinghao Xu*

Main category: cs.CV

TL;DR: 本文提出 LingBot-VA 框架，通过视频世界建模结合视觉-语言预训练，为机器人学习提供了新的可扩展基础。


<details>
  <summary>Details</summary>
Motivation: 现有机器人的世界模型和视觉-语言预训练大多割裂，无法充分利用视频理解推断时序因果关系，局限了机器人感知与行动的协同和泛化能力。作者希望构建一个模型，实现动作、感知与语言信息的有效融合，提高机器人学习的效能和通用性。

Method: 提出LingBot-VA：一个自回归扩散框架，实现帧预测和策略执行并行学习。方法亮点包括：（1）共享视觉与动作的潜在空间，由Mixture-of-Transformers架构驱动；（2）闭环展开机制，通过真实的环境反馈持续学习；（3）异步推理管线，实现动作预测与电机执行的并行化。

Result: 在模拟和真实世界场景中，LingBot-VA在长时操作、训练后数据效率及新任务泛化等方面表现显著优越。

Conclusion: 视频世界建模结合视觉-语言预训练，为机器人学习带来了新的强大范式，LingBot-VA在多个方面表现出潜力，并已开源代码推动社区发展。

Abstract: This work highlights that video world modeling, alongside vision-language pre-training, establishes a fresh and independent foundation for robot learning. Intuitively, video world models provide the ability to imagine the near future by understanding the causality between actions and visual dynamics. Inspired by this, we introduce LingBot-VA, an autoregressive diffusion framework that learns frame prediction and policy execution simultaneously. Our model features three carefully crafted designs: (1) a shared latent space, integrating vision and action tokens, driven by a Mixture-of-Transformers (MoT) architecture, (2) a closed-loop rollout mechanism, allowing for ongoing acquisition of environmental feedback with ground-truth observations, (3) an asynchronous inference pipeline, parallelizing action prediction and motor execution to support efficient control. We evaluate our model on both simulation benchmarks and real-world scenarios, where it shows significant promise in long-horizon manipulation, data efficiency in post-training, and strong generalizability to novel configurations. The code and model are made publicly available to facilitate the community.

</details>


### [42] [SimGraph: A Unified Framework for Scene Graph-Based Image Generation and Editing](https://arxiv.org/abs/2601.21498)
*Thanh-Nhan Vo,Trong-Thuan Nguyen,Tam V. Nguyen,Minh-Triet Tran*

Main category: cs.CV

TL;DR: 提出SimGraph框架，实现基于场景图的图像生成与编辑，提升控制能力与一致性，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的生成式AI在图像生成和编辑任务上通常分开处理，导致空间一致性与语义连贯性差，同时难以对物体关系和空间布局进行结构化控制。

Method: 提出SimGraph统一框架，将场景图引入图像生成和编辑任务。模型在场景图驱动下，结合token-based生成和扩散模型编辑，实现对物体关系、布局与空间一致性的精准控制。

Result: 通过大量实验，验证SimGraph框架在图像质量和一致性方面优于现有最新方法。

Conclusion: SimGraph有效整合场景图于图像生成和编辑，提升了对内容和结构的可控性，结果更优，推动领域发展。

Abstract: Recent advancements in Generative Artificial Intelligence (GenAI) have significantly enhanced the capabilities of both image generation and editing. However, current approaches often treat these tasks separately, leading to inefficiencies and challenges in maintaining spatial consistency and semantic coherence between generated content and edits. Moreover, a major obstacle is the lack of structured control over object relationships and spatial arrangements. Scene graph-based methods, which represent objects and their interrelationships in a structured format, offer a solution by providing greater control over composition and interactions in both image generation and editing. To address this, we introduce SimGraph, a unified framework that integrates scene graph-based image generation and editing, enabling precise control over object interactions, layouts, and spatial coherence. In particular, our framework integrates token-based generation and diffusion-based editing within a single scene graph-driven model, ensuring high-quality and consistent results. Through extensive experiments, we empirically demonstrate that our approach outperforms existing state-of-the-art methods.

</details>


### [43] [HERS: Hidden-Pattern Expert Learning for Risk-Specific Vehicle Damage Adaptation in Diffusion Models](https://arxiv.org/abs/2601.21517)
*Teerapong Panboonyuen*

Main category: cs.CV

TL;DR: 本文提出HERS框架，通过对扩散模型进行领域特定专家适配，提升车辆受损图像合成的真实性、可控性和领域对齐性，帮助防控自动保险流程中的欺诈风险。


<details>
  <summary>Details</summary>
Motivation: 近期文本生成图像扩散模型已能高仿真生成车损场景图像，这种能力虽利于保险自动化，但带来了数据伪造与欺诈的新风险，因此需提升模型生成图像的真实度与可控性。

Method: 提出HERS框架：通过无需人工标注的自监督图片-文本对，利用大语言模型与T2I流程自动生成，分别针对不同受损类型（如凹陷、刮擦、灯损、漆裂等）训练专家，再整合为具备泛化能力的多损害模型，实现领域专家适配扩散模型。

Result: 在四种扩散模型基础上验证HERS，结果显示相较基线模型，HERS在文本一致性提升5.5%，人类偏好度提升2.3%。

Conclusion: HERS不仅提升了受损图像生成质量，也为欺诈检测、可审计性及安全性部署提供技术基础。研究强调了在汽车保险等安全关键领域可信生成的重要性，同时揭示了领域定制扩散模型的机遇与风险。

Abstract: Recent advances in text-to-image (T2I) diffusion models have enabled increasingly realistic synthesis of vehicle damage, raising concerns about their reliability in automated insurance workflows. The ability to generate crash-like imagery challenges the boundary between authentic and synthetic data, introducing new risks of misuse in fraud or claim manipulation. To address these issues, we propose HERS (Hidden-Pattern Expert Learning for Risk-Specific Damage Adaptation), a framework designed to improve fidelity, controllability, and domain alignment of diffusion-generated damage images. HERS fine-tunes a base diffusion model via domain-specific expert adaptation without requiring manual annotation. Using self-supervised image-text pairs automatically generated by a large language model and T2I pipeline, HERS models each damage category, such as dents, scratches, broken lights, or cracked paint, as a separate expert. These experts are later integrated into a unified multi-damage model that balances specialization with generalization. We evaluate HERS across four diffusion backbones and observe consistent improvements: plus 5.5 percent in text faithfulness and plus 2.3 percent in human preference ratings compared to baselines. Beyond image fidelity, we discuss implications for fraud detection, auditability, and safe deployment of generative models in high-stakes domains. Our findings highlight both the opportunities and risks of domain-specific diffusion, underscoring the importance of trustworthy generation in safety-critical applications such as auto insurance.

</details>


### [44] [Vision KAN: Towards an Attention-Free Backbone for Vision with Kolmogorov-Arnold Networks](https://arxiv.org/abs/2601.21541)
*Zhuoqin Yang,Jiansong Zhang,Xiaoling Luo,Xu Wu,Zheng Lu,Linlin Shen*

Main category: cs.CV

TL;DR: 本文提出了一种基于Kolmogorov-Arnold Network（KAN）的全新视觉主干网络Vision KAN（ViK），能够不用注意力机制却实现高效和准确的特征建模。


<details>
  <summary>Details</summary>
Motivation: 传统视觉注意力机制虽然能捕捉长程依赖，但计算复杂度高且难以解释，限制了其可扩展性和模型透明度。近期无注意力架构取得强性能，激发了对无注意力替代方案的探索。

Method: ViK采用一种名为MultiPatch-RBFKAN的token混合器，结合（a）基于RBF的patch级非线性变换，（b）轴向可分离混合实现高效局部传播，（c）低秩全局映射实现长距离交互。通过patch分组与轻量化算子恢复跨patch依赖，作为注意力模块的可替代组件，显著降低了高分辨率下的计算负担。

Result: 在ImageNet-1K数据集上的实验显示，ViK主干具备与主流注意力机制网络相当的准确率，并拥有线性复杂度。

Conclusion: 基于KAN的token混合方式是一种高效且有理论基础的注意力机制替代方案，对于改进大规模视觉任务模型具有潜力。

Abstract: Attention mechanisms have become a key module in modern vision backbones due to their ability to model long-range dependencies. However, their quadratic complexity in sequence length and the difficulty of interpreting attention weights limit both scalability and clarity. Recent attention-free architectures demonstrate that strong performance can be achieved without pairwise attention, motivating the search for alternatives. In this work, we introduce Vision KAN (ViK), an attention-free backbone inspired by the Kolmogorov-Arnold Networks. At its core lies MultiPatch-RBFKAN, a unified token mixer that combines (a) patch-wise nonlinear transform with Radial Basis Function-based KANs, (b) axis-wise separable mixing for efficient local propagation, and (c) low-rank global mapping for long-range interaction. Employing as a drop-in replacement for attention modules, this formulation tackles the prohibitive cost of full KANs on high-resolution features by adopting a patch-wise grouping strategy with lightweight operators to restore cross-patch dependencies. Experiments on ImageNet-1K show that ViK achieves competitive accuracy with linear complexity, demonstrating the potential of KAN-based token mixing as an efficient and theoretically grounded alternative to attention.

</details>


### [45] [Bi-Anchor Interpolation Solver for Accelerating Generative Modeling](https://arxiv.org/abs/2601.21542)
*Hongxu Chen,Hongxiang Li,Zhen Wang,Long Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为 Bi-Anchor Interpolation Solver (BA-solver) 的生成模型加速方案，通过引入体积小且高效的 SideNet，显著降低了生成延时且几乎无需额外训练代价。


<details>
  <summary>Details</summary>
Motivation: Flow Matching (FM) 模型在高保真合成任务中表现优异，但依赖 ODE 求解导致延迟成为瓶颈。现有加速方法要么质量下降，要么训练成本过高且不灵活，因此需要一种兼具速度、精度和通用性的解决方案。

Method: 提出 BA-solver：在冻结主干网络（backbone）的基础上，增加轻量级 SideNet（1-2% backbone 规模），通过双向时间感知（SideNet 预测历史及未来速度）和双锚点速度积分（利用两锚点速度高效近似中间速度）对轨迹插值，大步长推理时仍能保证精度。

Result: 在 ImageNet-256^2 上，BA-solver 仅用 10 步就能达成与传统 Euler 求解器（100+ 步）相当的生成质量，最少 5 步也能保持高保真，且训练成本可以忽略。

Conclusion: BA-solver 兼具训练无关性、高加速、低误差，能够无缝集成到主流生成管线中，助力后续图像编辑等下游任务。

Abstract: Flow Matching (FM) models have emerged as a leading paradigm for high-fidelity synthesis. However, their reliance on iterative Ordinary Differential Equation (ODE) solving creates a significant latency bottleneck. Existing solutions face a dichotomy: training-free solvers suffer from significant performance degradation at low Neural Function Evaluations (NFEs), while training-based one- or few-steps generation methods incur prohibitive training costs and lack plug-and-play versatility. To bridge this gap, we propose the Bi-Anchor Interpolation Solver (BA-solver). BA-solver retains the versatility of standard training-free solvers while achieving significant acceleration by introducing a lightweight SideNet (1-2% backbone size) alongside the frozen backbone. Specifically, our method is founded on two synergistic components: \textbf{1) Bidirectional Temporal Perception}, where the SideNet learns to approximate both future and historical velocities without retraining the heavy backbone; and 2) Bi-Anchor Velocity Integration, which utilizes the SideNet with two anchor velocities to efficiently approximate intermediate velocities for batched high-order integration. By utilizing the backbone to establish high-precision ``anchors'' and the SideNet to densify the trajectory, BA-solver enables large interval sizes with minimized error. Empirical results on ImageNet-256^2 demonstrate that BA-solver achieves generation quality comparable to 100+ NFEs Euler solver in just 10 NFEs and maintains high fidelity in as few as 5 NFEs, incurring negligible training costs. Furthermore, BA-solver ensures seamless integration with existing generative pipelines, facilitating downstream tasks such as image editing.

</details>


### [46] [Unifying Heterogeneous Degradations: Uncertainty-Aware Diffusion Bridge Model for All-in-One Image Restoration](https://arxiv.org/abs/2601.21592)
*Luwei Tu,Jiawei Wu,Xing Luo,Zhi Jin*

Main category: cs.CV

TL;DR: 本文提出了一个新的图像恢复方法UDBM，通过不确定性感知的扩散桥模型统一处理多类型退化问题，并在多个任务上达到最新性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多任务图像恢复方法在不同退化类型之间存在冲突目标，很难实现细粒度的调控，导致性能不足。本文的动机是设计一种能更好适配多种退化并灵活调控的方法。

Method: 作者提出了不确定性感知扩散桥模型（UDBM），将图像恢复任务转化为受像素级不确定性引导的随机运输问题。采用松弛的扩散桥，替代传统扩散桥的严格终端约束，从而同时建模退化的不确定性并解决漂移奇异问题。此外，提出双调制策略：噪声调度用于对齐不同退化至统一潜在空间，路径调度则借助熵正则的物理动力学自适应调整传输轨迹。

Result: 该方法在统一恢复框架下，仅通过一步推理即可在多个图像恢复任务上实现最新的性能表现，优于现有主流方法。

Conclusion: UDBM有效改善了图像恢复中的传输几何和动力学问题，实现了多任务图像恢复的高效统一解决，具有重要应用价值。

Abstract: All-in-One Image Restoration (AiOIR) faces the fundamental challenge in reconciling conflicting optimization objectives across heterogeneous degradations. Existing methods are often constrained by coarse-grained control mechanisms or fixed mapping schedules, yielding suboptimal adaptation. To address this, we propose an Uncertainty-Aware Diffusion Bridge Model (UDBM), which innovatively reformulates AiOIR as a stochastic transport problem steered by pixel-wise uncertainty. By introducing a relaxed diffusion bridge formulation which replaces the strict terminal constraint with a relaxed constraint, we model the uncertainty of degradations while theoretically resolving the drift singularity inherent in standard diffusion bridges. Furthermore, we devise a dual modulation strategy: the noise schedule aligns diverse degradations into a shared high-entropy latent space, while the path schedule adaptively regulates the transport trajectory motivated by the viscous dynamics of entropy regularization. By effectively rectifying the transport geometry and dynamics, UDBM achieves state-of-the-art performance across diverse restoration tasks within a single inference step.

</details>


### [47] [HydroSense: A Dual-Microcontroller IoT Framework for Real-Time Multi-Parameter Water Quality Monitoring with Edge Processing and Cloud Analytics](https://arxiv.org/abs/2601.21595)
*Abdul Hasib,A. S. M. Ahsanul Sarkar Akib,Anish Giri*

Main category: cs.CV

TL;DR: 该论文提出了一种名为HydroSense的物联网水质监测系统，能够低成本、实时监控六项关键水质参数，并在实验中展现出高精度和高可靠性。


<details>
  <summary>Details</summary>
Motivation: 全球水危机突显了经济实惠、准确且实时的水质监测解决方案的重要性，传统方法成本高且不适用于资源有限地区。

Method: 设计了基于Arduino Uno和ESP32的双微控制器结构，实现多参数监测（pH、溶解氧、温度、总溶解固体、估算氮、液位），使用五点校准算法和信号处理（中值滤波、温度补偿、容错）提升精度与稳定性，并通过Firebase实现云端实时数据传输。

Result: 在90天实验中，系统的pH、DO、TDS等数据表现出高精度（如pH误差±0.08，DO±0.2mg/L，TDS±1.9%），云端数据传输可靠性达99.8%。成本约300美元，比商用系统低85%。

Conclusion: HydroSense展示了通过智能系统架构和成本优化硬件，可实现专业级、低成本的水质监测，为环境监测提供了新范式，适合大规模推广。

Abstract: The global water crisis necessitates affordable, accurate, and real-time water quality monitoring solutions. Traditional approaches relying on manual sampling or expensive commercial systems fail to address accessibility challenges in resource-constrained environments. This paper presents HydroSense, an innovative Internet of Things framework that integrates six critical water quality parameters including pH, dissolved oxygen (DO), temperature, total dissolved solids (TDS), estimated nitrogen, and water level into a unified monitoring system. HydroSense employs a novel dual-microcontroller architecture, utilizing Arduino Uno for precision analog measurements with five-point calibration algorithms and ESP32 for wireless connectivity, edge processing, and cloud integration. The system implements advanced signal processing techniques including median filtering for TDS measurement, temperature compensation algorithms, and robust error handling. Experimental validation over 90 days demonstrates exceptional performance metrics: pH accuracy of plus or minus 0.08 units across the 0 to 14 range, DO measurement stability within plus or minus 0.2 mg/L, TDS accuracy of plus or minus 1.9 percent across 0 to 1000 ppm, and 99.8 percent cloud data transmission reliability. With a total implementation cost of 32,983 BDT (approximately 300 USD), HydroSense achieves an 85 percent cost reduction compared to commercial systems while providing enhanced connectivity through the Firebase real-time database. This research establishes a new paradigm for accessible environmental monitoring, demonstrating that professional-grade water quality assessment can be achieved through intelligent system architecture and cost-effective component selection.

</details>


### [48] [WMVLM: Evaluating Diffusion Model Image Watermarking via Vision-Language Models](https://arxiv.org/abs/2601.21610)
*Zijin Yang,Yu Sun,Kejiang Chen,Jiawei Zhao,Jun Jiang,Weiming Zhang,Nenghai Yu*

Main category: cs.CV

TL;DR: 本文提出了WMVLM，这是第一个针对扩散模型图像水印的统一且可解释的评估框架，能兼顾残留型和语义型水印，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型图像水印评估方法存在诸多局限，如缺乏统一框架、可解释性差、安全性评估不足、语义水印评价指标不当，亟需更全面的评测体系。

Method: 作者提出了WMVLM框架，利用视觉-语言模型（VLM），针对残留水印和语义水印分别重新定义质量与安全性指标。并设计三阶段训练策略，使模型具备分类、评分和文本解释能力。

Result: 实验结果显示，WMVLM在不同数据集、扩散模型及水印方法上均具备良好泛化性，并超越了现有主流视觉-语言模型的表现。

Conclusion: WMVLM为扩散模型图像水印的评估提供了首个统一且可解释的解决方案，推动了水印算法评价体系进步，具有重要应用价值和研究意义。

Abstract: Digital watermarking is essential for securing generated images from diffusion models. Accurate watermark evaluation is critical for algorithm development, yet existing methods have significant limitations: they lack a unified framework for both residual and semantic watermarks, provide results without interpretability, neglect comprehensive security considerations, and often use inappropriate metrics for semantic watermarks. To address these gaps, we propose WMVLM, the first unified and interpretable evaluation framework for diffusion model image watermarking via vision-language models (VLMs). We redefine quality and security metrics for each watermark type: residual watermarks are evaluated by artifact strength and erasure resistance, while semantic watermarks are assessed through latent distribution shifts. Moreover, we introduce a three-stage training strategy to progressively enable the model to achieve classification, scoring, and interpretable text generation. Experiments show WMVLM outperforms state-of-the-art VLMs with strong generalization across datasets, diffusion models, and watermarking methods.

</details>


### [49] [PathReasoner-R1: Instilling Structured Reasoning into Pathology Vision-Language Model via Knowledge-Guided Policy Optimization](https://arxiv.org/abs/2601.21617)
*Songhan Jiang,Fengchun Liu,Ziyue Wang,Linghan Cai,Yongbing Zhang*

Main category: cs.CV

TL;DR: 本文提出了PathReasoner数据集和PathReasoner-R1模型，用于提升视觉-语言模型在病理领域的推理能力，实现有证据可溯源、有逻辑链条的自动诊断。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言模型虽然在病理图像理解上表现出色，但缺乏可验证的推理链，直接输出诊断结论，影响临床信任与专家纠错。

Method: 作者建立了大规模的全切片图像（WSI）推理数据集PathReasoner，并设计了结合医学知识图谱的知识指导生成流程，有效对齐结构化病理发现与推理过程。同时，提出PathReasoner-R1模型，将轨迹mask监督微调与重推理导向强化学习相结合，通过知识感知奖励机制引导模型学习结构化推理能力。

Result: PathReasoner-R1在PathReasoner数据集和公开基准上均取得了领先性能，能更好输出透明且具备医学依据的推理过程。

Conclusion: 该方法显著提升了病理AI模型的推理透明度与临床可信度，有力推动了以证据为基础的自动病理诊断发展。

Abstract: Vision-Language Models (VLMs) are advancing computational pathology with superior visual understanding capabilities. However, current systems often reduce diagnosis to directly output conclusions without verifiable evidence-linked reasoning, which severely limits clinical trust and hinders expert error rectification. To address these barriers, we construct PathReasoner, the first large-scale dataset of whole-slide image (WSI) reasoning. Unlike previous work reliant on unverified distillation, we develop a rigorous knowledge-guided generation pipeline. By leveraging medical knowledge graphs, we explicitly align structured pathological findings and clinical reasoning with diagnoses, generating over 20K high-quality instructional samples. Based on the database, we propose PathReasoner-R1, which synergizes trajectory-masked supervised fine-tuning with reasoning-oriented reinforcement learning to instill structured chain-of-thought capabilities. To ensure medical rigor, we engineer a knowledge-aware multi-granular reward function incorporating an Entity Reward mechanism strictly aligned with knowledge graphs. This effectively guides the model to optimize for logical consistency rather than mere outcome matching, thereby enhancing robustness. Extensive experiments demonstrate that PathReasoner-R1 achieves state-of-the-art performance on both PathReasoner and public benchmarks across various image scales, equipping pathology models with transparent, clinically grounded reasoning capabilities. Dataset and code are available at https://github.com/cyclexfy/PathReasoner-R1.

</details>


### [50] [Similarity of Processing Steps in Vision Model Representations](https://arxiv.org/abs/2601.21621)
*Matéo Mahaut,Marco Baroni*

Main category: cs.CV

TL;DR: 本文研究了视觉模型在学习过程中表示收敛现象的具体过程，探讨不同结构（如CNN与Transformer）在表示演化上的异同，并量化分析了各阶段间的距离与处理特性差异。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究表明，无论训练目标、数据集或模态如何，较大的模型常会收敛到相似的“通用”表示，但这些研究多关注最终表示。本文关注“模型是如何收敛到这些表示的”，特别是在中间过程和具体操作上是否也趋同。

Method: 作者通过量化不同视觉模型在不同阶段的表示距离，分析模型在处理流程中表示变化的演化轨迹，并比较了模型间在哪些处理中差异最大。具体比较了CNN与Transformer模型、中间层与输出层的区别。

Result: 研究发现，不同模型在同一层级的表示最为相似，但依然存有显著差异。例如，分类模型在最后几层会丢弃与低级图像统计相关的信息。CNN与Transformer在每层变换方式上表现不同，Transformer的层间变化更为平滑。

Conclusion: 本文工作揭示了表征收敛的具体层级及差异，为模型内部处理机制的理解提供了更细致的定性和定量分析，有助于理解模型间收敛的一致性和多样性。

Abstract: Recent literature suggests that the bigger the model, the more likely it is to converge to similar, ``universal'' representations, despite different training objectives, datasets, or modalities. While this literature shows that there is an area where model representations are similar, we study here how vision models might get to those representations -- in particular, do they also converge to the same intermediate steps and operations? We therefore study the processes that lead to convergent representations in different models. First, we quantify distance between different model representations at different stages. We follow the evolution of distances between models throughout processing, identifying the processing steps which are most different between models. We find that while layers at similar positions in different models have the most similar representations, strong differences remain. Classifier models, unlike the others, will discard information about low-level image statistics in their final layers. CNN- and transformer-based models also behave differently, with transformer models applying smoother changes to representations from one layer to the next. These distinctions clarify the level and nature of convergence between model representations, and enables a more qualitative account of the underlying processes in image models.

</details>


### [51] [A Tilted Seesaw: Revisiting Autoencoder Trade-off for Controllable Diffusion](https://arxiv.org/abs/2601.21633)
*Pu Cao,Yiyang Ma,Feng Zhou,Xuedan Yin,Qing Song,Lu Yang*

Main category: cs.CV

TL;DR: 本文揭示了在潜变量扩散模型中，自动编码器（AE）的评估存在偏见，过于关注生成指标（如gFID），而忽视了重建质量，这在可控生成任务中会导致可控性下降。该工作建议应更加关注重建指标，以提升可控扩散模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前AE在ImageNet数据集上的研究和评测越来越倾向于关注生成友好性指标（如gFID），而忽略了重建质量。作者认为这种偏向可能会带来风险，特别是在对条件可控的生成任务（例如可控扩散模型）进行扩展时。因此，有必要重新审视AE的评测与选择标准。

Method: 作者通过理论分析和实证研究，比较了不同AE配置下生成指标（gFID）与重建指标对可控性的影响。他们提出并应用了一套多维条件漂移评估协议，在各种ImageNet基准上的AE模型进行实验证明。还结合ControlNet实验探究了在可控生成中的可控性与这些指标的关系。

Result: 实验发现，gFID对于条件保持（condition preservation）几乎没有预测作用，而以重建质量为导向的指标（尤其是个体级重建）则与可控性呈现显著一致性。通过ControlNet进一步证实，生成过程中的可控性与条件保持指标更紧密相关。

Conclusion: 该研究表明，现有的以ImageNet为中心的AE评估体系未能满足可扩展可控扩散需求，呼吁今后在模型评测与选择时更注重重建指标，从而提升可控生成的精度和稳健性。

Abstract: In latent diffusion models, the autoencoder (AE) is typically expected to balance two capabilities: faithful reconstruction and a generation-friendly latent space (e.g., low gFID). In recent ImageNet-scale AE studies, we observe a systematic bias toward generative metrics in handling this trade-off: reconstruction metrics are increasingly under-reported, and ablation-based AE selection often favors the best-gFID configuration even when reconstruction fidelity degrades. We theoretically analyze why this gFID-dominant preference can appear unproblematic for ImageNet generation, yet becomes risky when scaling to controllable diffusion: AEs can induce condition drift, which limits achievable condition alignment. Meanwhile, we find that reconstruction fidelity, especially instance-level measures, better indicates controllability. We empirically validate the impact of tilted autoencoder evaluation on controllability by studying several recent ImageNet AEs. Using a multi-dimensional condition-drift evaluation protocol reflecting controllable generation tasks, we find that gFID is only weakly predictive of condition preservation, whereas reconstruction-oriented metrics are substantially more aligned. ControlNet experiments further confirm that controllability tracks condition preservation rather than gFID. Overall, our results expose a gap between ImageNet-centric AE evaluation and the requirements of scalable controllable diffusion, offering practical guidance for more reliable benchmarking and model selection.

</details>


### [52] [RSGround-R1: Rethinking Remote Sensing Visual Grounding through Spatial Reasoning](https://arxiv.org/abs/2601.21634)
*Shiqi Huang,Shuting He,Bihan Wen*

Main category: cs.CV

TL;DR: 本文提出了一种针对遥感视觉定位（RSVG）任务的后训练框架RSGround-R1，通过引入空间推理与位置感知模块提升了模型的空间理解能力，在基准任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 遥感图像因空间尺度大、场景语义复杂，语言描述高度依赖空间位置信息，现有多模态大模型在空间推理上存在挑战，因此需要提升其空间推理能力以准确定位目标。

Method: 框架包括：(1) 基于链式思维(CoT)的监督微调，利用合成推理数据增强位置感知；(2) 结合新设计的连续距离相关奖励的强化微调，引导模型更准确地定位目标；(3) 引入空间一致性优化方案，通过动态调整策略更新，提升定位鲁棒性和收敛稳定性。

Result: 在多个遥感视觉定位基准上实验，RSGround-R1展现出优异的定位性能与泛化能力，优于现有方法。

Conclusion: 引入推理引导和位置感知的后训练策略能显著提升MLLMs在遥感场景中的空间理解和目标定位能力，所提RSGround-R1具有较好的实用和推广价值。

Abstract: Remote Sensing Visual Grounding (RSVG) aims to localize target objects in large-scale aerial imagery based on natural language descriptions. Owing to the vast spatial scale and high semantic ambiguity of remote sensing scenes, these descriptions often rely heavily on positional cues, posing unique challenges for Multimodal Large Language Models (MLLMs) in spatial reasoning. To leverage this unique feature, we propose a reasoning-guided, position-aware post-training framework, dubbed \textbf{RSGround-R1}, to progressively enhance spatial understanding. Specifically, we first introduce Chain-of-Thought Supervised Fine-Tuning (CoT-SFT) using synthetically generated RSVG reasoning data to establish explicit position awareness. Reinforcement Fine-Tuning (RFT) is then applied, augmented by our newly designed positional reward that provides continuous and distance-aware guidance toward accurate localization. Moreover, to mitigate incoherent localization behaviors across rollouts, we introduce a spatial consistency guided optimization scheme that dynamically adjusts policy updates based on their spatial coherence, ensuring stable and robust convergence. Extensive experiments on RSVG benchmarks demonstrate superior performance and generalization of our model.

</details>


### [53] [OCRVerse: Towards Holistic OCR in End-to-End Vision-Language Models](https://arxiv.org/abs/2601.21639)
*Yufeng Zhong,Lei Chen,Xuanle Zhao,Wenkang Han,Liming Zheng,Jing Huang,Deyang Jiang,Yilin Cao,Lin Ma,Zhixiong Zeng*

Main category: cs.CV

TL;DR: 本文提出OCRVerse，一种统一处理文本型和视觉型OCR任务的全新端到端方法，涵盖从报刊等文本密集型文档到图表、网页等视觉信息密集型图片，实现跨领域、多模态信息的高效识别，实验显示其性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有OCR方法侧重于识别图像中的文本信息（文本型OCR），但忽视了对包含丰富视觉元素的图片（如图表、网页、科学绘图等）的识别能力，致使在实际中广泛存在且具有高应用价值的视觉型信息密集型图片无法被有效处理。随着大规模视觉语言模型的发展，迫切需要创新OCR技术满足多种多模态数据的处理需求。

Method: 提出OCRVerse，首次实现统一的文本型和视觉型OCR。构建了覆盖文本型（如报刊、杂志、书籍）和视觉型（如图表、网页、科学绘图）数据的综合数据集。模型训练采取二阶段：第一阶段为SFT（监督微调），直接混合多领域数据学习初步知识；第二阶段为RL（强化学习），针对不同领域输出格式和需求，设计灵活的个性化奖励策略以提升融合与避免冲突。

Result: OCRVerse在文本型及视觉型OCR任务上的表现优异，实验结果显示，其在多种数据类型上的识别效果与当前主流的开源或闭源大规模模型相当甚至更优。

Conclusion: OCRVerse具备统一、多模态、高扩展性的优势，能够有效应对实际场景中多样化的OCR需求。该方法推动了OCR技术从单一文本识别向全局视觉信息理解发展，具有广泛应用前景。

Abstract: The development of large vision language models drives the demand for managing, and applying massive amounts of multimodal data, making OCR technology, which extracts information from visual images, increasingly popular. However, existing OCR methods primarily focus on recognizing text elements from images or scanned documents (\textbf{Text-centric OCR}), neglecting the identification of visual elements from visually information-dense image sources (\textbf{Vision-centric OCR}), such as charts, web pages and science plots. In reality, these visually information-dense images are widespread on the internet and have significant real-world application value, such as data visualization and web page analysis. In this technical report, we propose \textbf{OCRVerse}, the first holistic OCR method in end-to-end manner that enables unified text-centric OCR and vision-centric OCR. To this end, we constructe comprehensive data engineering to cover a wide range of text-centric documents, such as newspapers, magazines and books, as well as vision-centric rendered composites, including charts, web pages and scientific plots. Moreover, we propose a two-stage SFT-RL multi-domain training method for OCRVerse. SFT directly mixes cross-domain data to train and establish initial domain knowledge, while RL focuses on designing personalized reward strategies for the characteristics of each domain. Specifically, since different domains require various output formats and expected outputs, we provide sufficient flexibility in the RL stage to customize flexible reward signals for each domain, thereby improving cross-domain fusion and avoiding data conflicts. Experimental results demonstrate the effectiveness of OCRVerse, achieving competitive results across text-centric and vision-centric data types, even comparable to large-scale open-source and closed-source models.

</details>


### [54] [CAF-Mamba: Mamba-Based Cross-Modal Adaptive Attention Fusion for Multimodal Depression Detection](https://arxiv.org/abs/2601.21648)
*Bowen Zhou,Marc-André Fiedler,Ayoub Al-Hamadi*

Main category: cs.CV

TL;DR: CAF-Mamba是一种新颖的跨模态自适应注意力融合方法，能更有效地融合多模态特征用于抑郁症检测，在多个数据集上获得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁症检测深度学习方法受限于特征类型单一、未显式建模跨模态交互，只用简单拼接或静态加权进行特征融合，导致性能受限。

Method: 提出CAF-Mamba框架，基于Mamba模型，结合跨模态自适应注意力机制，能显式和隐式捕捉模态间交互，并动态调整各模态的重要性。

Result: 在LMVD和D-Vlog两个实时数据集上，CAF-Mamba均优于当前主流方法，取得了新的SOTA（最优）成绩。

Conclusion: CAF-Mamba解决了传统方法融合不足的问题，提升了多模态抑郁症检测的准确性，展示了新型深度融合方法的潜力。

Abstract: Depression is a prevalent mental health disorder that severely impairs daily functioning and quality of life. While recent deep learning approaches for depression detection have shown promise, most rely on limited feature types, overlook explicit cross-modal interactions, and employ simple concatenation or static weighting for fusion. To overcome these limitations, we propose CAF-Mamba, a novel Mamba-based cross-modal adaptive attention fusion framework. CAF-Mamba not only captures cross-modal interactions explicitly and implicitly, but also dynamically adjusts modality contributions through a modality-wise attention mechanism, enabling more effective multimodal fusion. Experiments on two in-the-wild benchmark datasets, LMVD and D-Vlog, demonstrate that CAF-Mamba consistently outperforms existing methods and achieves state-of-the-art performance.

</details>


### [55] [Few-Shot Domain Adaptation with Temporal References and Static Priors for Glacier Calving Front Delineation](https://arxiv.org/abs/2601.21663)
*Marcel Dreier,Nora Gourmelon,Dakota Pyles,Thorsten Seehaus,Matthias H. Braun,Andreas Maier,Vincent Christlein*

Main category: cs.CV

TL;DR: 现有最先进的冰川崩解前沿分割模型在基准测试中表现优异，但在新区域的实际应用中准确度不足。通过少样本领域自适应、空间静态先验知识和输入时间序列中加入夏季参考图像，将分割误差大幅降低，无需改动模型架构，为全球范围的冰川崩解监测提供新方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在已知数据集上表现良好，但在新区域（领域外数据）容易失效，限制了其实际科学应用价值，亟需提升模型跨域泛化能力。

Method: 采用三项策略提升模型泛化：1）少样本领域自适应，2）引入空间静态先验知识，3）在输入时序中加入夏季参考图像，无需修改模型架构。

Result: 分割误差从1131.6米降至68.7米，提升显著。

Conclusion: 提出的方法有效提高了冰川崩解前沿分割模型在新区域的适用性，为全球范围内的冰川监测提供了技术基础。

Abstract: During benchmarking, the state-of-the-art model for glacier calving front delineation achieves near-human performance. However, when applied in a real-world setting at a novel study site, its delineation accuracy is insufficient for calving front products intended for further scientific analyses. This site represents an out-of-distribution domain for a model trained solely on the benchmark dataset. By employing a few-shot domain adaptation strategy, incorporating spatial static prior knowledge, and including summer reference images in the input time series, the delineation error is reduced from 1131.6 m to 68.7 m without any architectural modifications. These methodological advancements establish a framework for applying deep learning-based calving front segmentation to novel study sites, enabling calving front monitoring on a global scale.

</details>


### [56] [When Gradient Optimization Is Not Enough: $\dagger$ Dispersive and Anchoring Geometric Regularizer for Multimodal Learning](https://arxiv.org/abs/2601.21670)
*Zixuan Xia,Hao Wang,Pengcheng Weng,Yanyu Qian,Yangxin Xu,William Dan,Fei Wang*

Main category: cs.CV

TL;DR: 本文提出一种关注几何结构的正则化方法，旨在解决多模态表示中的常见几何问题，提升在多模态和单模态下的表现。


<details>
  <summary>Details</summary>
Motivation: 多模态学习中，不同模态间的信息集成虽有利于提升模型能力，但现有方法仅依靠优化目标，往往未能保证良好的表示结构，导致模态内表示塌缩、跨模样本不一致等问题，影响模型整体表现。作者认为多模态学习缺乏对表示空间几何结构的直接调控手段。

Method: 提出名为\regName的正则化框架，包含两部分：其一是模态内的分散正则化，鼓励同一模态下表示的多样性；其二是跨模态锚定正则化，限制同一样本在不同模态下的表示漂移，但不要求严格对齐。该方法轻量、无须修改模型结构，可直接集成于现有多模态训练范式中。

Result: 在多个多模态基准上，大量实验证明该正则化方法无论在多模态还是单模态任务中均提升了模型性能，且有效缓解模态之间的权衡问题。

Conclusion: 显式调控多模态学习中的表示几何结构，是提升多模态融合和单模态鲁棒性的有效途径。所提出的正则化框架可作为简单且实用的解决方案应用于各类多模态模型。

Abstract: Multimodal learning aims to integrate complementary information from heterogeneous modalities, yet strong optimization alone does not guaranty well-structured representations. Even under carefully balanced training schemes, multimodal models often exhibit geometric pathologies, including intra-modal representation collapse and sample-level cross-modal inconsistency, which degrade both unimodal robustness and multimodal fusion.
  We identify representation geometry as a missing control axis in multimodal learning and propose \regName, a lightweight geometry-aware regularization framework. \regName enforces two complementary constraints on intermediate embeddings: an intra-modal dispersive regularization that promotes representation diversity, and an inter-modal anchoring regularization that bounds sample-level cross-modal drift without rigid alignment. The proposed regularizer is plug-and-play, requires no architectural modifications, and is compatible with various training paradigms.
  Extensive experiments across multiple multimodal benchmarks demonstrate consistent improvements in both multimodal and unimodal performance, showing that explicitly regulating representation geometry effectively mitigates modality trade-offs.

</details>


### [57] [Multimodal Visual Surrogate Compression for Alzheimer's Disease Classification](https://arxiv.org/abs/2601.21673)
*Dexuan Ding,Ciyuan Peng,Endrowednes Kuantama,Jingcai Guo,Jia Wu,Jian Yang,Amin Beheshti,Ming-Hsuan Yang,Yuankai Qi*

Main category: cs.CV

TL;DR: 本文提出了一种名为MVSC的多模态视觉代理压缩方法，有效提升了阿尔茨海默病诊断中基于高维结构MRI图像的特征学习性能。


<details>
  <summary>Details</summary>
Motivation: 现有的3D CNN、切片级提取（后期聚合）、以及2D基础模型的特征提取方法，各自存在计算成本高、跨切片信息丢失或判别特征提取能力不足等问题，需要新的方法来充分、高效地提取MRI中的判别信息。

Method: MVSC方法通过两个关键模块：Volume Context Encoder（在文本引导下捕捉全局跨切片上下文）与Adaptive Slice Fusion（以文本增强、patch级方式整合切片信息），将3D MRI体积压缩为与2D基础模型对齐的紧凑2D特征，后续用于阿尔茨海默病分类。

Result: 在三大阿尔茨海默病公开数据集上，MVSC方法在二分类与多分类任务中的表现均优于当前先进方法，展示了有效性。

Conclusion: MVSC方法能以低计算成本、更好地保留和压缩跨切片关键信息，从而提升阿尔茨海默病MRI分类性能，为相关影像诊断提供新的技术路径。

Abstract: High-dimensional structural MRI (sMRI) images are widely used for Alzheimer's Disease (AD) diagnosis. Most existing methods for sMRI representation learning rely on 3D architectures (e.g., 3D CNNs), slice-wise feature extraction with late aggregation, or apply training-free feature extractions using 2D foundation models (e.g., DINO). However, these three paradigms suffer from high computational cost, loss of cross-slice relations, and limited ability to extract discriminative features, respectively. To address these challenges, we propose Multimodal Visual Surrogate Compression (MVSC). It learns to compress and adapt large 3D sMRI volumes into compact 2D features, termed as visual surrogates, which are better aligned with frozen 2D foundation models to extract powerful representations for final AD classification. MVSC has two key components: a Volume Context Encoder that captures global cross-slice context under textual guidance, and an Adaptive Slice Fusion module that aggregates slice-level information in a text-enhanced, patch-wise manner. Extensive experiments on three large-scale Alzheimer's disease benchmarks demonstrate our MVSC performs favourably on both binary and multi-class classification tasks compared against state-of-the-art methods.

</details>


### [58] [ChartE$^{3}$: A Comprehensive Benchmark for End-to-End Chart Editing](https://arxiv.org/abs/2601.21694)
*Shuo Li,Jiajun Sun,Zhekai Wang,Xiaoran Fan,Hui Li,Dingwen Yang,Zhiheng Xi,Yijun Wang,Zifei Shan,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CV

TL;DR: 本文提出了ChartE$^{3}$，一个用于端到端图表编辑的基准任务，能够直接评估模型在图表编辑任务中的表现，并揭示当前主流多模态大模型在该领域存在显著性能差距。


<details>
  <summary>Details</summary>
Motivation: 当前图表编辑任务因需要兼顾细粒度控制和结构一致性，且主流方案多依赖于自然语言或代码作为中介表示，难以实现复杂且精确的编辑。缺乏端到端、高质量的评测基准，限制了相关模型的发展与实际应用。

Method: 作者构建了ChartE$^{3}$基准，包含1200多个经过人工筛选的优质样本，每个样本由图表图片、底层代码及多模态编辑指令组成。该基准涵盖了局部（如字体、颜色调整）与全局（如数据过滤、趋势线添加）两类编辑任务，无需中间程序或代码监督，直接评测模型端到端编辑能力。

Result: 通过对多种主流多模态大语言模型在ChartE$^{3}$上的测试，发现模型在全局编辑任务上表现尤为不足，显示出现有模型在端到端图表编辑上的显著局限。

Conclusion: ChartE$^{3}$为图表编辑任务提供了系统性、端到端的评测框架，有助于推动多模态图表编辑技术的发展。实验也表明当前模型存在明显短板，需要进一步改进以实现更高效、更精确的图表自动编辑。

Abstract: Charts are a fundamental visualization format for structured data analysis. Enabling end-to-end chart editing according to user intent is of great practical value, yet remains challenging due to the need for both fine-grained control and global structural consistency. Most existing approaches adopt pipeline-based designs, where natural language or code serves as an intermediate representation, limiting their ability to faithfully execute complex edits. We introduce ChartE$^{3}$, an End-to-End Chart Editing benchmark that directly evaluates models without relying on intermediate natural language programs or code-level supervision. ChartE$^{3}$ focuses on two complementary editing dimensions: local editing, which involves fine-grained appearance changes such as font or color adjustments, and global editing, which requires holistic, data-centric transformations including data filtering and trend line addition. ChartE$^{3}$ contains over 1,200 high-quality samples constructed via a well-designed data pipeline with human curation. Each sample is provided as a triplet of a chart image, its underlying code, and a multimodal editing instruction, enabling evaluation from both objective and subjective perspectives. Extensive benchmarking of state-of-the-art multimodal large language models reveals substantial performance gaps, particularly on global editing tasks, highlighting critical limitations in current end-to-end chart editing capabilities.

</details>


### [59] [DreamActor-M2: Universal Character Image Animation via Spatiotemporal In-Context Learning](https://arxiv.org/abs/2601.21716)
*Mingshuang Luo,Shuang Liang,Zhengkun Rong,Yuxuan Luo,Tianshu Hu,Ruibing Hou,Hong Chang,Yong Li,Yuan Zhang,Mingyuan Gao*

Main category: cs.CV

TL;DR: 该论文提出了一种通用的角色动画合成框架DreamActor-M2，相比现有方法更好地平衡了角色身份保持和动作一致性，并提升了对多种角色和动作的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有角色图像动画方法难以同时兼顾身份保持与动作一致性，并且过度依赖骨架等先验，无法很好处理复杂或非人形角色的动作迁移。因此，需要一种能更好泛化且对输入约束更低的新方法。

Method: 作者提出DreamActor-M2，环绕“两阶段”设计算法：第一阶段通过融合外观和动作线索到统一潜空间，实现空间身份与时间动态的联合建模（借助基础生成模型的先验）；第二阶段采用自引导的数据合成流程，自动生成伪跨身份训练对，促成从依赖骨架到直接RGB控制的过渡。此外，作者还推出了AW Bench多样角色和动作评测基准。

Result: DreamActor-M2在包括AW Bench在内的各类数据集上进行大量实验，对比显示该方法在视觉保真度与跨域泛化能力等指标上达到新的SOTA。

Conclusion: DreamActor-M2有效解决了现有角色动画方法的身份与动作平衡及泛化不足问题，在各种角色类型和动作场景下都展现出良好的适应性和视觉效果。

Abstract: Character image animation aims to synthesize high-fidelity videos by transferring motion from a driving sequence to a static reference image. Despite recent advancements, existing methods suffer from two fundamental challenges: (1) suboptimal motion injection strategies that lead to a trade-off between identity preservation and motion consistency, manifesting as a "see-saw", and (2) an over-reliance on explicit pose priors (e.g., skeletons), which inadequately capture intricate dynamics and hinder generalization to arbitrary, non-humanoid characters. To address these challenges, we present DreamActor-M2, a universal animation framework that reimagines motion conditioning as an in-context learning problem. Our approach follows a two-stage paradigm. First, we bridge the input modality gap by fusing reference appearance and motion cues into a unified latent space, enabling the model to jointly reason about spatial identity and temporal dynamics by leveraging the generative prior of foundational models. Second, we introduce a self-bootstrapped data synthesis pipeline that curates pseudo cross-identity training pairs, facilitating a seamless transition from pose-dependent control to direct, end-to-end RGB-driven animation. This strategy significantly enhances generalization across diverse characters and motion scenarios. To facilitate comprehensive evaluation, we further introduce AW Bench, a versatile benchmark encompassing a wide spectrum of characters types and motion scenarios. Extensive experiments demonstrate that DreamActor-M2 achieves state-of-the-art performance, delivering superior visual fidelity and robust cross-domain generalization. Project Page: https://grisoon.github.io/DreamActor-M2/

</details>


### [60] [From Global to Granular: Revealing IQA Model Performance via Correlation Surface](https://arxiv.org/abs/2601.21738)
*Baoliang Chen,Danni Huang,Hanwei Zhu,Lingyu Zhu,Wei Zhou,Shiqi Wang,Yuming Fang,Weisi Lin*

Main category: cs.CV

TL;DR: 本文提出了一种更细致的图像质量评估模型评价方法 Granularity-Modulated Correlation（GMC），可揭示传统全局相关性指标未能体现的模型表现细节。


<details>
  <summary>Details</summary>
Motivation: 现有的图像质量评估（IQA）模型表现评价主要依赖PLCC、SRCC等全局相关指标，这些指标只能用单一数值代表模型表现，无法反映模型在不同质量区间上的排名精度变化。此外，这些指标容易受到测试样本分布影响，导致比较不稳定。

Method: 作者提出GMC方法，包含：1）基于绝对MOS值和MOS差值加权的Granularity Modulator，对模型在不同局部质量范围的表现进行细致分析；2）Distribution Regulator，以正则化方法减弱非均匀质量分布带来的干扰。最终生成一张以MOS和MOS差值为函数的三维相关性曲面，全面呈现模型性能。

Result: GMC在标准数据集上的实验结果显示，该方法能揭示传统单一标量指标（如SRCC）无法反映的模型表现差异，更全面、客观地评估和比较IQA模型。

Conclusion: GMC为IQA模型评测提供了更可靠和信息丰富的新范式，有助于深入理解和稳健部署IQA模型。

Abstract: Evaluation of Image Quality Assessment (IQA) models has long been dominated by global correlation metrics, such as Pearson Linear Correlation Coefficient (PLCC) and Spearman Rank-Order Correlation Coefficient (SRCC). While widely adopted, these metrics reduce performance to a single scalar, failing to capture how ranking consistency varies across the local quality spectrum. For example, two IQA models may achieve identical SRCC values, yet one ranks high-quality images (related to high Mean Opinion Score, MOS) more reliably, while the other better discriminates image pairs with small quality/MOS differences (related to $|Δ$MOS$|$). Such complementary behaviors are invisible under global metrics. Moreover, SRCC and PLCC are sensitive to test-sample quality distributions, yielding unstable comparisons across test sets. To address these limitations, we propose \textbf{Granularity-Modulated Correlation (GMC)}, which provides a structured, fine-grained analysis of IQA performance. GMC includes: (1) a \textbf{Granularity Modulator} that applies Gaussian-weighted correlations conditioned on absolute MOS values and pairwise MOS differences ($|Δ$MOS$|$) to examine local performance variations, and (2) a \textbf{Distribution Regulator} that regularizes correlations to mitigate biases from non-uniform quality distributions. The resulting \textbf{correlation surface} maps correlation values as a joint function of MOS and $|Δ$MOS$|$, providing a 3D representation of IQA performance. Experiments on standard benchmarks show that GMC reveals performance characteristics invisible to scalar metrics, offering a more informative and reliable paradigm for analyzing, comparing, and deploying IQA models. Codes are available at https://github.com/Dniaaa/GMC.

</details>


### [61] [Dynamic Topology Awareness: Breaking the Granularity Rigidity in Vision-Language Navigation](https://arxiv.org/abs/2601.21751)
*Jiankun Peng,Jianyuan Guo,Ying Xu,Yue Liu,Jiashuang Yan,Xuanwei Ye,Houhua Li,Xiaoming Wang*

Main category: cs.CV

TL;DR: 本文提出了一种动态拓扑导航框架DGNav，用于解决视觉-语言导航中的拓扑图粒度刚性问题，通过动态调整图密度和边权，提高导航效率和安全性，并在主流基准上取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言导航任务需要将语言指令精确地转化为空间动作，而现有的拓扑图方法由于节点采样粒度固定，往往在简单区域造成冗余，在复杂区域采样不足，表现出“粒度刚性”问题，导致效率低下和安全隐患。

Method: DGNav框架包括两个核心创新：1）场景感知自适应策略，根据预测航点的离散度动态调整图节点密度，实现复杂环境下按需加密；2）动态图Transformer，融合视觉、语言和几何信息对边权动态赋值，提升图连通性与指令遵循性。此外，通过消除拓扑噪声增强导航安全性和准确性。

Result: 在R2R-CE和RxR-CE基准测试上，DGNav取得了更优异的导航性能和出色的泛化能力。消融实验显示，该方法有效权衡了效率与安全探索。

Conclusion: DGNav通过动态调节拓扑结构，解决了粒度刚性带来的冗余与安全问题，兼顾导航效率和安全性，为视觉-语言导航任务提供了新的思路。

Abstract: Vision-Language Navigation in Continuous Environments (VLN-CE) presents a core challenge: grounding high-level linguistic instructions into precise, safe, and long-horizon spatial actions. Explicit topological maps have proven to be a vital solution for providing robust spatial memory in such tasks. However, existing topological planning methods suffer from a "Granularity Rigidity" problem. Specifically, these methods typically rely on fixed geometric thresholds to sample nodes, which fails to adapt to varying environmental complexities. This rigidity leads to a critical mismatch: the model tends to over-sample in simple areas, causing computational redundancy, while under-sampling in high-uncertainty regions, increasing collision risks and compromising precision. To address this, we propose DGNav, a framework for Dynamic Topological Navigation, introducing a context-aware mechanism to modulate map density and connectivity on-the-fly. Our approach comprises two core innovations: (1) A Scene-Aware Adaptive Strategy that dynamically modulates graph construction thresholds based on the dispersion of predicted waypoints, enabling "densification on demand" in challenging environments; (2) A Dynamic Graph Transformer that reconstructs graph connectivity by fusing visual, linguistic, and geometric cues into dynamic edge weights, enabling the agent to filter out topological noise and enhancing instruction adherence. Extensive experiments on the R2R-CE and RxR-CE benchmarks demonstrate DGNav exhibits superior navigation performance and strong generalization capabilities. Furthermore, ablation studies confirm that our framework achieves an optimal trade-off between navigation efficiency and safe exploration. The code is available at https://github.com/shannanshouyin/DGNav.

</details>


### [62] [Synthetic-to-Real Domain Bridging for Single-View 3D Reconstruction of Ships for Maritime Monitoring](https://arxiv.org/abs/2601.21786)
*Borja Carrillo-Perez,Felix Sattler,Angel Bueno Rodriguez,Maurice Stephan,Sarah Barnes*

Main category: cs.CV

TL;DR: 本文提出了一种高效的单视角3D船舶重建管道，完全基于合成数据训练，推理时只需单张图片，实现了无需真实3D标注即可在实际海事场景中进行三维可视化与检查。


<details>
  <summary>Details</summary>
Motivation: 当前3D船舶重建方法大多依赖多视角监督、3D标注或计算资源，占用大，难以满足实时海事监控的实际需求。因此，亟需一种既高效又能适应真实环境的新方法。

Method: 方法采用Splatter Image网络，将物体用稀疏3D高斯分布表示，支持单图像快速重建。模型先在ShapeNet合成数据上调优，再用自建多样3D船舶数据集细化，以缩小合成与真实数据之间的域差。同时整合了基于YOLOv8的语义分割与自定义预处理，重建后还包含比例、居中、方向调整及通过AIS元数据及单应性映射的地理定位。最终结果可在网页上交互式查看。

Result: 在合成数据上的定量评估显示重建精度高，在真实ShipSG数据集上有良好的重建效果，展示了对实际海事监控系统的潜力。

Conclusion: 该管道实现了无需真实3D标注、可高效扩展的单视角船舶3D重建，为实际海事监控与决策提供了切实可行的技术基础，并为未来实时3D船舶可视化应用指明了方向。

Abstract: Three-dimensional (3D) reconstruction of ships is an important part of maritime monitoring, allowing improved visualization, inspection, and decision-making in real-world monitoring environments. However, most state-ofthe-art 3D reconstruction methods require multi-view supervision, annotated 3D ground truth, or are computationally intensive, making them impractical for real-time maritime deployment. In this work, we present an efficient pipeline for single-view 3D reconstruction of real ships by training entirely on synthetic data and requiring only a single view at inference. Our approach uses the Splatter Image network, which represents objects as sparse sets of 3D Gaussians for rapid and accurate reconstruction from single images. The model is first fine-tuned on synthetic ShapeNet vessels and further refined with a diverse custom dataset of 3D ships, bridging the domain gap between synthetic and real-world imagery. We integrate a state-of-the-art segmentation module based on YOLOv8 and custom preprocessing to ensure compatibility with the reconstruction network. Postprocessing steps include real-world scaling, centering, and orientation alignment, followed by georeferenced placement on an interactive web map using AIS metadata and homography-based mapping. Quantitative evaluation on synthetic validation data demonstrates strong reconstruction fidelity, while qualitative results on real maritime images from the ShipSG dataset confirm the potential for transfer to operational maritime settings. The final system provides interactive 3D inspection of real ships without requiring real-world 3D annotations. This pipeline provides an efficient, scalable solution for maritime monitoring and highlights a path toward real-time 3D ship visualization in practical applications. Interactive demo: https://dlr-mi.github.io/ship3d-demo/.

</details>


### [63] [CG-MLLM: Captioning and Generating 3D content via Multi-modal Large Language Models](https://arxiv.org/abs/2601.21798)
*Junming Huang,Weiwei Xu*

Main category: cs.CV

TL;DR: 本文提出CG-MLLM，首次在单一模型架构下实现高分辨率3D生成与3D内容描述（captioning），在3D高质量内容生成上大幅超越现有多模态大模型。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在文本与多模态感知上表现优异，但应用于3D内容生成时，现有方法仅能生成低分辨率网格或粗糙结构，难以直接捕捉细致的3D几何细节。因此，亟需一种能原生支持高分辨率3D生成的多模态大模型。

Method: 提出CG-MLLM模型：采用Mixture-of-Transformer架构，将Token-level Autoregressive(TokAR) Transformer用于处理细粒度token内容，将Block-level Autoregressive(BlockAR) Transformer用于处理空间块级内容，并结合经过预训练的视觉-语言骨干网络和专用3D VAE潜空间，实现标准token与空间block间的长上下文交互，共同推进高保真3D生成。

Result: 实验表明，CG-MLLM在3D对象生成质量上显著优于所有现有多模态大语言模型，能够原生生成高分辨率、结构细致的3D内容。

Conclusion: CG-MLLM有效将高分辨率3D内容生成引入主流大语言模型范式，为未来3D与多模态AI应用打开新的可能性。

Abstract: Large Language Models(LLMs) have revolutionized text generation and multimodal perception, but their capabilities in 3D content generation remain underexplored. Existing methods compromise by producing either low-resolution meshes or coarse structural proxies, failing to capture fine-grained geometry natively. In this paper, we propose CG-MLLM, a novel Multi-modal Large Language Model (MLLM) capable of 3D captioning and high-resolution 3D generation in a single framework. Leveraging the Mixture-of-Transformer architecture, CG-MLLM decouples disparate modeling needs, where the Token-level Autoregressive (TokenAR) Transformer handles token-level content, and the Block-level Autoregressive (BlockAR) Transformer handles block-level content. By integrating a pre-trained vision-language backbone with a specialized 3D VAE latent space, CG-MLLM facilitates long-context interactions between standard tokens and spatial blocks within a single integrated architecture. Experimental results show that CG-MLLM significantly outperforms existing MLLMs in generating high-fidelity 3D objects, effectively bringing high-resolution 3D content creation into the mainstream LLM paradigm.

</details>


### [64] [MMFineReason: Closing the Multimodal Reasoning Gap via Open Data-Centric Methods](https://arxiv.org/abs/2601.21821)
*Honglin Lin,Zheng Liu,Yun Zhu,Chonghan Qin,Juekai Lin,Xiaoran Shang,Conghui He,Wentao Zhang,Lijun Wu*

Main category: cs.CV

TL;DR: 该论文提出了一个大规模多模态推理数据集MMFineReason，有助于提升开源视觉语言模型（VLM）的深度推理能力，并显著缩小与闭源VLM的差距。


<details>
  <summary>Details</summary>
Motivation: 现有开源VLM在推理任务上落后于闭源系统，主要原因是缺乏高质量和具有挑战性领域（如STEM、视觉谜题等）的推理数据集，且普遍缺少连贯、长链式Chain-of-Thought（CoT）推理标注。

Method: 作者提出高质量多模态推理数据集MMFineReason，包含180万样本和51亿标注token。采用三阶段流程：1) 大规模数据收集与标准化；2) CoT推理标注生成；3) 综合推理质量与难度感知筛选。并在Qwen3-VL-Instruct基础上微调，得到2B/4B/8B参数量的模型。

Result: 微调模型取得同参数量下的新SOTA结果。MMFineReason-4B参数模型能力超过Qwen3-VL-8B-Thinking，8B模型甚至超越30B模型。难度感知筛选发现，仅用7%高质量样本可达整体性能。推理型数据提升模型的泛化能力。

Conclusion: 大规模高质量推理数据集显著提升开源VLM推理与泛化能力，合理的数据筛选能有效提升训练效率和模型表现，推动多模态推理研究进步。

Abstract: Recent advances in Vision Language Models (VLMs) have driven significant progress in visual reasoning. However, open-source VLMs still lag behind proprietary systems, largely due to the lack of high-quality reasoning data. Existing datasets offer limited coverage of challenging domains such as STEM diagrams and visual puzzles, and lack consistent, long-form Chain-of-Thought (CoT) annotations essential for eliciting strong reasoning capabilities. To bridge this gap, we introduce MMFineReason, a large-scale multimodal reasoning dataset comprising 1.8M samples and 5.1B solution tokens, featuring high-quality reasoning annotations distilled from Qwen3-VL-235B-A22B-Thinking. The dataset is established via a systematic three-stage pipeline: (1) large-scale data collection and standardization, (2) CoT rationale generation, and (3) comprehensive selection based on reasoning quality and difficulty awareness. The resulting dataset spans STEM problems, visual puzzles, games, and complex diagrams, with each sample annotated with visually grounded reasoning traces. We fine-tune Qwen3-VL-Instruct on MMFineReason to develop MMFineReason-2B/4B/8B versions. Our models establish new state-of-the-art results for their size class. Notably, MMFineReason-4B succesfully surpasses Qwen3-VL-8B-Thinking, and MMFineReason-8B even outperforms Qwen3-VL-30B-A3B-Thinking while approaching Qwen3-VL-32B-Thinking, demonstrating remarkable parameter efficiency. Crucially, we uncover a "less is more" phenomenon via our difficulty-aware filtering strategy: a subset of just 7\% (123K samples) achieves performance comparable to the full dataset. Notably, we reveal a synergistic effect where reasoning-oriented data composition simultaneously boosts general capabilities.

</details>


### [65] [Trajectory-Guided Diffusion for Foreground-Preserving Background Generation in Multi-Layer Documents](https://arxiv.org/abs/2601.21857)
*Taewon Kang*

Main category: cs.CV

TL;DR: 本文提出一种基于扩散模型的文档背景生成方法，能同时保证前景内容的完整与多页风格一致性。该方法通过潜空间轨迹设计实现上述目标，无需复杂的显式约束或额外机制。


<details>
  <summary>Details</summary>
Motivation: 当前文档生成任务中，既要保护前景（如文字内容）的可读性，又需保证多页背景风格一致，现有方法多依赖显式抑制、掩码或频繁手动风格指定，操作繁琐且易出错。因此，亟需一种自洽且自动化的生成框架。

Method: 该方法将扩散过程重新解释为在结构化潜空间中的随机轨迹演化。通过对初始噪声及其几何排列的设计，背景生成过程自然避开前景区域，而无需显式掩码。此外，提出缓存风格方向（style directions），将其作为潜空间中的持久向量，约束所有页面扩散轨迹至相同风格子空间，实现多页风格一致。该方法无需额外训练，兼容现有扩散模型。

Result: 实验证明，该方法可自动生成视觉连贯、前景完整且多页风格统一的文档背景，适用于复杂文档，且表现优于需频繁指定风格或依赖掩码的传统方法。

Conclusion: 通过将扩散重构为潜空间轨迹设计，本文提出了一种自洽、通用且训练自由的文档生成新范式，为结构化一致性生成任务提供了稳固基础。

Abstract: We present a diffusion-based framework for document-centric background generation that achieves foreground preservation and multi-page stylistic consistency through latent-space design rather than explicit constraints. Instead of suppressing diffusion updates or applying masking heuristics, our approach reinterprets diffusion as the evolution of stochastic trajectories through a structured latent space. By shaping the initial noise and its geometric alignment, background generation naturally avoids designated foreground regions, allowing readable content to remain intact without auxiliary mechanisms. To address the long-standing issue of stylistic drift across pages, we decouple style control from text conditioning and introduce cached style directions as persistent vectors in latent space. Once selected, these directions constrain diffusion trajectories to a shared stylistic subspace, ensuring consistent appearance across pages and editing iterations. This formulation eliminates the need for repeated prompt-based style specification and provides a more stable foundation for multi-page generation. Our framework admits a geometric and physical interpretation, where diffusion paths evolve on a latent manifold shaped by preferred directions, and foreground regions are rarely traversed as a consequence of trajectory initialization rather than explicit exclusion. The proposed method is training-free, compatible with existing diffusion backbones, and produces visually coherent, foreground-preserving results across complex documents. By reframing diffusion as trajectory design in latent space, we offer a principled approach to consistent and structured generative modeling.

</details>


### [66] [Improving Classifier-Free Guidance of Flow Matching via Manifold Projection](https://arxiv.org/abs/2601.21892)
*Jian-Feng Cai,Haixia Liu,Zhengyi Su,Chao Wang*

Main category: cs.CV

TL;DR: 本文从优化的角度为无分类器引导（Classifier-free Guidance, CFG）提供了理论解释，并提出基于流匹配的新采样方法，显著提升了生成质量与稳健性。


<details>
  <summary>Details</summary>
Motivation: 尽管CFG技术在扩散模型中应用广泛且有效，但其本质依赖于经验性启发的线性外推法，对引导因子的敏感度较高，缺乏理论支持。本文旨在为CFG提供更坚实的理论基础，并提升其实用性和稳定性。

Method: 作者将CFG视为对流匹配优化问题梯度的近似，提出将CFG采样过程重构为具流形约束的同伦优化问题。为提升效率和稳定性，设计增量式梯度下降及Anderson加速方案，无需额外训练或模型评估。

Result: 所提方法无需重新训练，即可在大型生成模型（如DiT-XL-2-256、Flux、Stable Diffusion 3.5）上，显著提升生成保真度、文本对齐度，并对引导因子更稳健。实验在多个基准测试中取得优异成绩。

Conclusion: 通过理论分析与新采样方法，本文消除了CFG对启发性技巧的依赖，提升了采样过程的稳定性和性能，对扩散模型的可控生成具有重要意义。

Abstract: Classifier-free guidance (CFG) is a widely used technique for controllable generation in diffusion and flow-based models. Despite its empirical success, CFG relies on a heuristic linear extrapolation that is often sensitive to the guidance scale. In this work, we provide a principled interpretation of CFG through the lens of optimization. We demonstrate that the velocity field in flow matching corresponds to the gradient of a sequence of smoothed distance functions, which guides latent variables toward the scaled target image set. This perspective reveals that the standard CFG formulation is an approximation of this gradient, where the prediction gap, the discrepancy between conditional and unconditional outputs, governs guidance sensitivity. Leveraging this insight, we reformulate the CFG sampling as a homotopy optimization with a manifold constraint. This formulation necessitates a manifold projection step, which we implement via an incremental gradient descent scheme during sampling. To improve computational efficiency and stability, we further enhance this iterative process with Anderson Acceleration without requiring additional model evaluations. Our proposed methods are training-free and consistently refine generation fidelity, prompt alignment, and robustness to the guidance scale. We validate their effectiveness across diverse benchmarks, demonstrating significant improvements on large-scale models such as DiT-XL-2-256, Flux, and Stable Diffusion 3.5.

</details>


### [67] [Past- and Future-Informed KV Cache Policy with Salience Estimation in Autoregressive Video Diffusion](https://arxiv.org/abs/2601.21896)
*Hanmo Chen,Chenghao Xu,Xu Yang,Xuan Chen,Cheng Deng*

Main category: cs.CV

TL;DR: 该论文提出了一种新的KV缓存策略（PaFu-KV），通过重要性估计显著提升长视频生成的质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有自回归视频生成方法在缓存策略上忽略了token重要性的差异，导致生成质量下降和资源浪费，因此需要一种更加智能的缓存管理方式以提升长视频生成表现。

Method: 作者提出了Past- and Future-Informed KV Cache Policy（PaFu-KV），利用从双向教师模型蒸馏得到的显著性估计头，为每个token分配重要性分数，从而在推理阶段仅保留对生成最有效的信息token，舍弃无关或冗余token，降低缓存占用。

Result: 通过在多个基准数据集上的实验，PaFu-KV策略在减少缓存容量和降低推理内存开销的同时，显著提升了生成长视频时的画质，并加速了推理。

Conclusion: PaFu-KV能够在保持高视频生成质量的前提下，实现更高效的长时段视频生成推理，为实际应用带来性能和资源消耗的双赢。

Abstract: Video generation is pivotal to digital media creation, and recent advances in autoregressive video generation have markedly enhanced the efficiency of real-time video synthesis. However, existing approaches generally rely on heuristic KV Cache policies, which ignore differences in token importance in long-term video generation. This leads to the loss of critical spatiotemporal information and the accumulation of redundant, invalid cache, thereby degrading video generation quality and efficiency. To address this limitation, we first observe that token contributions to video generation are highly time-heterogeneous and accordingly propose a novel Past- and Future-Informed KV Cache Policy (PaFu-KV). Specifically, PaFu-KV introduces a lightweight Salience Estimation Head distilled from a bidirectional teacher to estimate salience scores, allowing the KV cache to retain informative tokens while discarding less relevant ones. This policy yields a better quality-efficiency trade-off by shrinking KV cache capacity and reducing memory footprint at inference time. Extensive experiments on benchmarks demonstrate that our method preserves high-fidelity video generation quality while enables accelerated inference, thereby enabling more efficient long-horizon video generation. Our code will be released upon paper acceptance.

</details>


### [68] [TraceRouter: Robust Safety for Large Foundation Models via Path-Level Intervention](https://arxiv.org/abs/2601.21900)
*Chuancheng Shi,Shangze Li,Wenjun Lu,Wenhua Wu,Cong Wang,Zifeng Cheng,Fei Shen,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 本文提出了一种新的防御大型基础模型（LFMs）对抗攻击的方法，TraceRouter，通过追踪和切断有害语义在模型中的传播路径，以提升鲁棒性和效能。


<details>
  <summary>Details</summary>
Motivation: 现有LFM防御方法多基于“局部假设”，仅针对单一神经元或特征进行抑制，难以应对有害语义在模型内作为跨层分布式电路流动的复杂性，导致防御脆弱及模型实用性下降。

Method: TraceRouter框架包含三步：(1) 通过分析注意力分布，定位敏感触发层；(2) 利用稀疏自编码器和差分激活分析解离有害特征，并加以隔离；(3) 通过特征影响分数映射特征至下游因果路径，对这些因果链进行选择性抑制，有效物理切断有害信息的传播，同时保留其它正常计算路径。

Result: 实验结果显示，TraceRouter在提升对抗鲁棒性的同时，对模型的通用性能影响较小，显著优于现有同类方法，实现了安全性与实用性的更优平衡。

Conclusion: TraceRouter作为一种路径级防御机制，有效解决了现有防御策略局部化、易失效的问题，为LFM安全性提供了新视角。

Abstract: Despite their capabilities, large foundation models (LFMs) remain susceptible to adversarial manipulation. Current defenses predominantly rely on the "locality hypothesis", suppressing isolated neurons or features. However, harmful semantics act as distributed, cross-layer circuits, rendering such localized interventions brittle and detrimental to utility. To bridge this gap, we propose \textbf{TraceRouter}, a path-level framework that traces and disconnects the causal propagation circuits of illicit semantics. TraceRouter operates in three stages: (1) it pinpoints a sensitive onset layer by analyzing attention divergence; (2) it leverages sparse autoencoders (SAEs) and differential activation analysis to disentangle and isolate malicious features; and (3) it maps these features to downstream causal pathways via feature influence scores (FIS) derived from zero-out interventions. By selectively suppressing these causal chains, TraceRouter physically severs the flow of harmful information while leaving orthogonal computation routes intact. Extensive experiments demonstrate that TraceRouter significantly outperforms state-of-the-art baselines, achieving a superior trade-off between adversarial robustness and general utility. Our code will be publicly released. WARNING: This paper contains unsafe model responses.

</details>


### [69] [Beyond Global Alignment: Fine-Grained Motion-Language Retrieval via Pyramidal Shapley-Taylor Learning](https://arxiv.org/abs/2601.21904)
*Hanmo Chen,Guangtao Lyu,Chenghao Xu,Jiexi Yan,Xu Yang,Cheng Deng*

Main category: cs.CV

TL;DR: 本文提出了一种用于动作-语言检索的新型金字塔Shapley-Taylor学习框架，能够实现动作与语言之间更细粒度的匹配，并且在多个公开数据集上大幅优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有动作-语言检索方法多以整体动作与整体文本进行对齐，忽视了局部细节层面的互动及层次结构，导致检索精度受限。因此，需要一种能捕捉局部与层次化结构信息的新方法。

Method: 受人类动作感知的金字塔流程启发，作者提出Pyramidal Shapley-Taylor (PST) 学习框架，将动作分解为时间片段和空间关节点，并通过逐级关节和片段对齐方式，分层捕捉动作与文本细粒和结构语义对应关系。

Result: 经多组公开数据集实验，所提出方法在检索评价指标上显著超越现有最新方法，实现了动作片段和关节点与文本细节的精准配准。

Conclusion: 分层细粒对齐机制能更有效地桥接动作与语言的语义鸿沟，为人本跨模态理解提供了更精确的检索手段，有潜力推动相关场景应用发展。

Abstract: As a foundational task in human-centric cross-modal intelligence, motion-language retrieval aims to bridge the semantic gap between natural language and human motion, enabling intuitive motion analysis, yet existing approaches predominantly focus on aligning entire motion sequences with global textual representations. This global-centric paradigm overlooks fine-grained interactions between local motion segments and individual body joints and text tokens, inevitably leading to suboptimal retrieval performance. To address this limitation, we draw inspiration from the pyramidal process of human motion perception (from joint dynamics to segment coherence, and finally to holistic comprehension) and propose a novel Pyramidal Shapley-Taylor (PST) learning framework for fine-grained motion-language retrieval. Specifically, the framework decomposes human motion into temporal segments and spatial body joints, and learns cross-modal correspondences through progressive joint-wise and segment-wise alignment in a pyramidal fashion, effectively capturing both local semantic details and hierarchical structural relationships. Extensive experiments on multiple public benchmark datasets demonstrate that our approach significantly outperforms state-of-the-art methods, achieving precise alignment between motion segments and body joints and their corresponding text tokens. The code of this work will be released upon acceptance.

</details>


### [70] [VideoAesBench: Benchmarking the Video Aesthetics Perception Capabilities of Large Multimodal Models](https://arxiv.org/abs/2601.21915)
*Yunhao Li,Sijing Wu,Zhilin Gao,Zicheng Zhang,Qi Jia,Huiyu Duan,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 论文提出了VideoAesBench，这是一个用于评估大规模多模态模型（LMM）在视频美学质量理解上的综合基准。实验发现当前LMM在视频美学感知上能力有限。


<details>
  <summary>Details</summary>
Motivation: 虽然LMM在多种视觉任务上表现优异，但其视频美学质量评估能力尚未被充分研究。人类对视频美学有天然感知，因此需要研究LMM在这一能力上的表现，并构建相应评测基准。

Method: 作者提出了VideoAesBench基准，包含来自多个源和类型的1804个视频，并设计了多种题型（单选、多选、判断、开放式问答）和涵盖视频美学多个维度的问题。基于此，测试了23个开源及商业LMM模型在视频美学理解能力上的表现。

Result: 实验结果显示，当前的LMM仅具备基本的视频美学感知能力，表现仍不充分、存在不精确的问题。

Conclusion: VideoAesBench可以作为一个重要的测试平台，为今后可解释性的视频美学评估研究提供参考和启示。

Abstract: Large multimodal models (LMMs) have demonstrated outstanding capabilities in various visual perception tasks, which has in turn made the evaluation of LMMs significant. However, the capability of video aesthetic quality assessment, which is a fundamental ability for human, remains underexplored for LMMs. To address this, we introduce VideoAesBench, a comprehensive benchmark for evaluating LMMs' understanding of video aesthetic quality. VideoAesBench has several significant characteristics: (1) Diverse content including 1,804 videos from multiple video sources including user-generated (UGC), AI-generated (AIGC), compressed, robotic-generated (RGC), and game videos. (2) Multiple question formats containing traditional single-choice questions, multi-choice questions, True or False questions, and a novel open-ended questions for video aesthetics description. (3) Holistic video aesthetics dimensions including visual form related questions from 5 aspects, visual style related questions from 4 aspects, and visual affectiveness questions from 3 aspects. Based on VideoAesBench, we benchmark 23 open-source and commercial large multimodal models. Our findings show that current LMMs only contain basic video aesthetics perception ability, their performance remains incomplete and imprecise. We hope our VideoAesBench can be served as a strong testbed and offer insights for explainable video aesthetics assessment.

</details>


### [71] [Zero-Shot Video Restoration and Enhancement with Assistance of Video Diffusion Models](https://arxiv.org/abs/2601.21922)
*Cong Cao,Huanjing Yue,Shangbin Xie,Xin Liu,Jingyu Yang*

Main category: cs.CV

TL;DR: 本论文提出了一种无训练的利用视频扩散模型提升图像修复与增强在视频中的时序一致性的方法，通过多种融合策略和后处理，有效减少了视频零样本修复/增强中的时序闪烁问题，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽在图像无监督修复与增强取得了成功，但直接用于视频会导致明显的时序闪烁，因此需要一种新方法提升时序一致性。

Method: 提出了三种融合策略（同质与异质潜变量融合及基于COT的融合比率）联合利用文本到视频扩散模型以补充现有图像方法，并提出时序增强后处理，整体方法无需训练，适配所有基于扩散的图像修复增强方法。

Result: 实验表明，所提方法在多个视频修复与增强任务中较现有基线方法具有更好的时序一致性与整体性能。

Conclusion: 该方法为无训练视频修复/增强提供了新的思路，显著改善了时序稳定性，可广泛应用于现有扩散模型图像修复与增强场景。

Abstract: Although diffusion-based zero-shot image restoration and enhancement methods have achieved great success, applying them to video restoration or enhancement will lead to severe temporal flickering. In this paper, we propose the first framework that utilizes the rapidly-developed video diffusion model to assist the image-based method in maintaining more temporal consistency for zero-shot video restoration and enhancement. We propose homologous latents fusion, heterogenous latents fusion, and a COT-based fusion ratio strategy to utilize both homologous and heterogenous text-to-video diffusion models to complement the image method. Moreover, we propose temporal-strengthening post-processing to utilize the image-to-video diffusion model to further improve temporal consistency. Our method is training-free and can be applied to any diffusion-based image restoration and enhancement methods. Experimental results demonstrate the superiority of the proposed method.

</details>


### [72] [Just Noticeable Difference Modeling for Deep Visual Features](https://arxiv.org/abs/2601.21933)
*Rui Zhao,Wenrui Li,Lin Zhu,Yajing Zheng,Weisi Lin*

Main category: cs.CV

TL;DR: 本文提出了一种可控的特征扰动方法（FeatJND），能够在保证下游任务性能的前提下，预测并利用深度视觉特征空间中的最大可容忍扰动，用于任务对齐的特征压缩和质量调控。


<details>
  <summary>Details</summary>
Motivation: 视觉系统日益依赖深度视觉特征作为接口，因此需要描述和控制特征质量。以往人类视觉中的“最小可觉察差异（JND）”已被用于衡量图像失真，但在深度特征空间缺少相应的定义与应用场景，亟需建立相关理论和技术以利于特征压缩、传输或量化等应用。

Method: 提出了一种任务对齐的JND（FeatJND）方法，通过训练或建模，预测在保持下游任务性能时每个特征可承受的最大扰动（扰动映射）。在标准化特征分割点上实现了FeatJND估算器，并横跨分类、检测和实例分割等任务上进行了实验验证。与未结构化的高斯扰动相比，FeatJND扰动有更好性能保持能力。

Result: 实验表明，在相等失真强度下，基于FeatJND的扰动相较于无结构高斯扰动能更好地保留任务性能。可视化分析显示，FeatJND更倾向于压制非关键信息区域。作为实际应用，将FeatJND用于分词动态量化，并在相同噪声预算下显著优于随机量化和全局统一量化。

Conclusion: FeatJND为特征空间的质量调控与应用提供了新方法，不仅有效保持下游任务性能，还可广泛应用于特征压缩与量化等场景，对资源受限下的机器视觉应用有实际参考价值。

Abstract: Deep visual features are increasingly used as the interface in vision systems, motivating the need to describe feature characteristics and control feature quality for machine perception. Just noticeable difference (JND) characterizes the maximum imperceptible distortion for images under human or machine vision. Extending it to deep visual features naturally meets the above demand by providing a task-aligned tolerance boundary in feature space, offering a practical reference for controlling feature quality under constrained resources. We propose FeatJND, a task-aligned JND formulation that predicts the maximum tolerable per-feature perturbation map while preserving downstream task performance. We propose a FeatJND estimator at standardized split points and validate it across image classification, detection, and instance segmentation. Under matched distortion strength, FeatJND-based distortions consistently preserve higher task performance than unstructured Gaussian perturbations, and attribution visualizations suggest FeatJND can suppress non-critical feature regions. As an application, we further apply FeatJND to token-wise dynamic quantization and show that FeatJND-guided step-size allocation yields clear gains over random step-size permutation and global uniform step size under the same noise budget. Our code will be released after publication.

</details>


### [73] [BookNet: Book Image Rectification via Cross-Page Attention Network](https://arxiv.org/abs/2601.21938)
*Shaokai Liu,Hao Feng,Bozhi Luan,Min Hou,Jiajun Deng,Wengang Zhou*

Main category: cs.CV

TL;DR: 本文提出了BookNet，这是首个专为双页书籍图像矫正设计的端到端深度学习框架，并提供了相应的数据集和基准。实验表明BookNet效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 书籍影像常因装订导致左右页呈现复杂且不对称的弯曲，现有单页修正方法不能建模书页间的耦合关系，导致双页矫正效果不佳。

Method: BookNet采用了双分支架构和跨页面注意力机制，能够联合建模两页间几何关系，分别预测两页及整个展开图的扭曲校正流。此外，作者还合成了Book3D训练集和Book100测试集。

Result: 实验表明，BookNet在双页书籍图像矫正任务上明显优于当前主流方法。

Conclusion: BookNet首次有效解决了双页书籍图像矫正问题，方法高效且数据集齐全，为该领域提供了新的基准和研究方向。

Abstract: Book image rectification presents unique challenges in document image processing due to complex geometric distortions from binding constraints, where left and right pages exhibit distinctly asymmetric curvature patterns. However, existing single-page document image rectification methods fail to capture the coupled geometric relationships between adjacent pages in books. In this work, we introduce BookNet, the first end-to-end deep learning framework specifically designed for dual-page book image rectification. BookNet adopts a dual-branch architecture with cross-page attention mechanisms, enabling it to estimate warping flows for both individual pages and the complete book spread, explicitly modeling how left and right pages influence each other. Moreover, to address the absence of specialized datasets, we present Book3D, a large-scale synthetic dataset for training, and Book100, a comprehensive real-world benchmark for evaluation. Extensive experiments demonstrate that BookNet outperforms existing state-of-the-art methods on book image rectification. Code and dataset will be made publicly available.

</details>


### [74] [Deep Models, Shallow Alignment: Uncovering the Granularity Mismatch in Neural Decoding](https://arxiv.org/abs/2601.21948)
*Yang Du,Siyuan Dai,Yonghao Song,Paul M. Thompson,Haoteng Tang,Liang Zhan*

Main category: cs.CV

TL;DR: 该论文提出了一种名为Shallow Alignment的新型对比学习策略，用于更好地对齐神经视觉信号与视觉编码器的中间表示，从而提高视觉解码性能，兼顾低级细节与高级语义。该方法在多个基准测试中表现出显著优于传统方法的优势。


<details>
  <summary>Details</summary>
Motivation: 现有脑机接口中的视觉解码方法存在人类与机器视觉粒度不匹配的问题——深度视觉模型强调语义不变性而忽略了细节，而神经信号则包含丰富的低级和高级视觉信息。如何有效对齐两者，是提升解码准确性的关键。

Method: 作者提出Shallow Alignment方法，将神经信号与视觉编码器的中间层表示对齐，而不是仅对齐最终输出，并基于对比学习优化这种对齐方式，以在低/高级特征之间实现更平衡的映射。

Result: 在多个主流视觉骨干网络和基准测试上，Shallow Alignment解码性能显著优于传统最终层对齐方法，性能提升幅度达到22%~58%；并且随着预训练视觉骨干容量增大，解码性能可持续提升（符号解码Scaling Law）。

Conclusion: Shallow Alignment方法有效缓解了人类与机器视觉粒度不匹配的问题，大幅提升了神经视觉解码的效果，并揭示了解码系统与视觉模型容量之间的可预测关系。

Abstract: Neural visual decoding is a central problem in brain computer interface research, aiming to reconstruct human visual perception and to elucidate the structure of neural representations. However, existing approaches overlook a fundamental granularity mismatch between human and machine vision, where deep vision models emphasize semantic invariance by suppressing local texture information, whereas neural signals preserve an intricate mixture of low-level visual attributes and high-level semantic content. To address this mismatch, we propose Shallow Alignment, a novel contrastive learning strategy that aligns neural signals with intermediate representations of visual encoders rather than their final outputs, thereby striking a better balance between low-level texture details and high-level semantic features. Extensive experiments across multiple benchmarks demonstrate that Shallow Alignment significantly outperforms standard final-layer alignment, with performance gains ranging from 22% to 58% across diverse vision backbones. Notably, our approach effectively unlocks the scaling law in neural visual decoding, enabling decoding performance to scale predictably with the capacity of pre-trained vision backbones. We further conduct systematic empirical analyses to shed light on the mechanisms underlying the observed performance gains.

</details>


### [75] [PaddleOCR-VL-1.5: Towards a Multi-Task 0.9B VLM for Robust In-the-Wild Document Parsing](https://arxiv.org/abs/2601.21957)
*Cheng Cui,Ting Sun,Suyin Liang,Tingquan Gao,Zelun Zhang,Jiaxuan Liu,Xueqing Wang,Changda Zhou,Hongen Liu,Manhui Lin,Yue Zhang,Yubo Zhang,Yi Liu,Dianhai Yu,Yanjun Ma*

Main category: cs.CV

TL;DR: 本文提出了PaddleOCR-VL-1.5模型，在OmniDocBench v1.5上取得了94.5%的最新SOTA精度，并构建了Real5-OmniDocBench基准测试其在现实物理失真下的鲁棒性，实验显示其表现优异。同时模型体积仅0.9B，效率高，并增加了印章识别和文本检测任务。


<details>
  <summary>Details</summary>
Motivation: 随着OCR和视觉语言模型在实际文档处理中的广泛应用，提高模型在各种现实失真下的鲁棒性，以及支持更多任务（如印章识别），具有重要意义。现有模型受限于物理噪声鲁棒性、精度和模型体积。

Method: 1. 提出了PaddleOCR-VL-1.5新模型，通过算法和架构优化提升识别精度。2. 提出并构建了包含多种物理失真的新基准Real5-OmniDocBench，用于真实环境中的鲁棒性测试。3. 在保持模型极小尺寸（0.9B参数）的前提下，扩展支持印章识别和文本探测任务。

Result: PaddleOCR-VL-1.5在OmniDocBench v1.5取得94.5%的SOTA精度，在Real5-OmniDocBench基准的各种物理失真测试中依旧表现出色，并且在多任务（如印章识别、文本检测）上能力优异。

Conclusion: PaddleOCR-VL-1.5在精度、鲁棒性、体积以及任务扩展性等方面都达到了新高度，适用于实际多场景下的高效视觉语言理解和文档分析任务。

Abstract: We introduce PaddleOCR-VL-1.5, an upgraded model achieving a new state-of-the-art (SOTA) accuracy of 94.5% on OmniDocBench v1.5. To rigorously evaluate robustness against real-world physical distortions, including scanning, skew, warping, screen-photography, and illumination, we propose the Real5-OmniDocBench benchmark. Experimental results demonstrate that this enhanced model attains SOTA performance on the newly curated benchmark. Furthermore, we extend the model's capabilities by incorporating seal recognition and text spotting tasks, while remaining a 0.9B ultra-compact VLM with high efficiency. Code: https://github.com/PaddlePaddle/PaddleOCR

</details>


### [76] [Drive-JEPA: Video JEPA Meets Multimodal Trajectory Distillation for End-to-End Driving](https://arxiv.org/abs/2601.22032)
*Linhan Wang,Zichong Yang,Chen Bai,Guoxiang Zhang,Xiaotong Liu,Xiaoyin Zheng,Xiao-Xiao Long,Chang-Tien Lu,Cheng Lu*

Main category: cs.CV

TL;DR: 本文提出了Drive-JEPA框架，结合视频自监督预训练和多模态轨迹知识蒸馏，实现了端到端自动驾驶，在NAVSIM基准上刷新了最新性能纪录。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶视频世界模型预训练，在理解场景和规控规划学习中提升有限，主要受限于驾驶场景固有的轨迹单一性，不利于多模态行为学习。

Method: Drive-JEPA首先将V-JEPA（视频联合嵌入预测结构）适配到自动驾驶场景，在大规模驾驶视频上用ViT编码器预训练，学习与轨迹规划对齐的表示。然后，提出方案驱动型规划器，将多样的模拟器生成轨迹与真人轨迹一起蒸馏，并引入动量感知机制选择高质量轨迹以保证行为稳定安全。

Result: 在NAVSIM上，单独使用V-JEPA表征和简单transformer解码器，无感知条件下超越现有方法3分PDMS。完整Drive-JEPA框架在v1和v2两种设置上分别获得93.3 PDMS与87.8 EPDMS，刷新了SOTA成绩。

Conclusion: Drive-JEPA显著提升了自动驾驶任务中的端到端表现，证实多模态轨迹知识蒸馏与先进视频预训练技术对鲁棒规控学习具有重要作用。

Abstract: End-to-end autonomous driving increasingly leverages self-supervised video pretraining to learn transferable planning representations. However, pretraining video world models for scene understanding has so far brought only limited improvements. This limitation is compounded by the inherent ambiguity of driving: each scene typically provides only a single human trajectory, making it difficult to learn multimodal behaviors. In this work, we propose Drive-JEPA, a framework that integrates Video Joint-Embedding Predictive Architecture (V-JEPA) with multimodal trajectory distillation for end-to-end driving. First, we adapt V-JEPA for end-to-end driving, pretraining a ViT encoder on large-scale driving videos to produce predictive representations aligned with trajectory planning. Second, we introduce a proposal-centric planner that distills diverse simulator-generated trajectories alongside human trajectories, with a momentum-aware selection mechanism to promote stable and safe behavior. When evaluated on NAVSIM, the V-JEPA representation combined with a simple transformer-based decoder outperforms prior methods by 3 PDMS in the perception-free setting. The complete Drive-JEPA framework achieves 93.3 PDMS on v1 and 87.8 EPDMS on v2, setting a new state-of-the-art.

</details>


### [77] [Understanding Multimodal Complementarity for Single-Frame Action Anticipation](https://arxiv.org/abs/2601.22039)
*Manuel Benavent-Lledo,Konstantinos Bacharidis,Konstantinos Papoutsakis,Antonis Argyros,Jose Garcia-Rodriguez*

Main category: cs.CV

TL;DR: 本论文探讨了仅用单帧图像进行人类动作预测的极限与潜力，提出了AAG+框架，证明即使只用一帧也能获得接近甚至超过多帧方法的效果。


<details>
  <summary>Details</summary>
Motivation: 以往动作预测主要依赖于视频的连续时序信息，但本研究质疑这种假设，探索单帧（一个时刻的图像）是否已包含丰富未来动作线索。

Method: 系统地对单帧动作预测融合多模态信息（RGB外观、深度几何、过去动作语义）进行了分析，并对多模态融合策略、关键帧选择及历史信息源进行了实验，最终形成了优化设计的AAG+框架。

Result: AAG+框架在IKEA-ASM、Meccano、Assembly101等多个挑战性数据集上的预测表现优异，不仅超过了原AAG，还能媲美甚至超过目前基于长视频序列的方法。

Conclusion: 单帧图像中蕴含丰富未来信息，设计得当时能实现高水平动作预测，未来并非所有场景都需密集时序建模，部分场合用好“关键一帧”足矣。

Abstract: Human action anticipation is commonly treated as a video understanding problem, implicitly assuming that dense temporal information is required to reason about future actions. In this work, we challenge this assumption by investigating what can be achieved when action anticipation is constrained to a single visual observation. We ask a fundamental question: how much information about the future is already encoded in a single frame, and how can it be effectively exploited? Building on our prior work on Action Anticipation at a Glimpse (AAG), we conduct a systematic investigation of single-frame action anticipation enriched with complementary sources of information. We analyze the contribution of RGB appearance, depth-based geometric cues, and semantic representations of past actions, and investigate how different multimodal fusion strategies, keyframe selection policies and past-action history sources influence anticipation performance. Guided by these findings, we consolidate the most effective design choices into AAG+, a refined single-frame anticipation framework. Despite operating on a single frame, AAG+ consistently improves upon the original AAG and achieves performance comparable to, or exceeding, that of state-of-the-art video-based methods on challenging anticipation benchmarks including IKEA-ASM, Meccano and Assembly101. Our results offer new insights into the limits and potential of single-frame action anticipation, and clarify when dense temporal modeling is necessary and when a carefully selected glimpse is sufficient.

</details>


### [78] [Urban Neural Surface Reconstruction from Constrained Sparse Aerial Imagery with 3D SAR Fusion](https://arxiv.org/abs/2601.22045)
*Da Li,Chen Yao,Tong Mao,Jiacheng Bao,Houjun Sun*

Main category: cs.CV

TL;DR: 该论文提出利用3D合成孔径雷达（SAR）点云与航拍图像融合，在稀疏视角条件下实现高保真城市三维神经面重建，并建立了首个相关基准数据集。实验证明融合3D SAR显著提升重建精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 城市三维重建常因航拍图像视角稀疏、地形和成本等限制，导致现有神经面重建方法在几何上存在歧义和不稳定，难以满足大规模城市遥感应用需求。需研发稳定高效的稀疏视角重建方法。

Method: 提出首个融合3D SAR点云和航拍图像的城市神经面重建（NSR）框架：将SAR衍生的空间约束集成进基于SDF的NSR骨干网络，创新性地引导结构感知的光线选择与自适应采样，并构建配准的3D SAR点云-航拍影像基准数据集。

Result: 大量实验表明，在极度稀疏和侧视条件下，融合3D SAR数据相比单模态方法显著提升了三维重建的精度、完整性与鲁棒性，实现了高质量的城市三维模型输出。

Conclusion: 论文方法为高保真城市三维重建提供了技术可行路线，融合了光学与雷达传感数据，提升了稀疏航拍遥感下的建模能力，对大规模空/天基城市遥感具有重要推动意义。

Abstract: Neural surface reconstruction (NSR) has recently shown strong potential for urban 3D reconstruction from multi-view aerial imagery. However, existing NSR methods often suffer from geometric ambiguity and instability, particularly under sparse-view conditions. This issue is critical in large-scale urban remote sensing, where aerial image acquisition is limited by flight paths, terrain, and cost. To address this challenge, we present the first urban NSR framework that fuses 3D synthetic aperture radar (SAR) point clouds with aerial imagery for high-fidelity reconstruction under constrained, sparse-view settings. 3D SAR can efficiently capture large-scale geometry even from a single side-looking flight path, providing robust priors that complement photometric cues from images. Our framework integrates radar-derived spatial constraints into an SDF-based NSR backbone, guiding structure-aware ray selection and adaptive sampling for stable and efficient optimization. We also construct the first benchmark dataset with co-registered 3D SAR point clouds and aerial imagery, facilitating systematic evaluation of cross-modal 3D reconstruction. Extensive experiments show that incorporating 3D SAR markedly enhances reconstruction accuracy, completeness, and robustness compared with single-modality baselines under highly sparse and oblique-view conditions, highlighting a viable route toward scalable high-fidelity urban reconstruction with advanced airborne and spaceborne optical-SAR sensing.

</details>


### [79] [PLANING: A Loosely Coupled Triangle-Gaussian Framework for Streaming 3D Reconstruction](https://arxiv.org/abs/2601.22046)
*Changjian Jiang,Kerui Ren,Xudong Li,Kaiwen Song,Linning Xu,Tao Lu,Junting Dong,Yu Zhang,Bo Dai,Mulin Yu*

Main category: cs.CV

TL;DR: 本文提出了PLANING，一种基于混合表示的高效流式三维重建框架，通过解耦几何与外观实现了高质量与高效率的兼得，重建速度和质量均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 单目图像序列的流式三维重建往往面临效率与质量不可兼得的问题：要么重建结果精细但速度慢，要么快但精度低。为克服这一困境，作者希望实现同时具备高效率与高质量的流式三维重建。

Method: 提出一种混合表示，将显式几何基元与神经高斯表示松散耦合，对几何与外观进行解耦建模，并采用分离的几何和外观在线初始化与优化算法，以减少冗余并提升重建稳定性。

Result: 在ScanNetV2等数据集上，PLANING相比PGSR在Chamfer-L2指标上提升18.52%，PSNR较ARTDECO高1.31 dB，重建速度比2D Gaussian Splatting快5倍（100秒以内），且可达到离线优化的重建质量。

Conclusion: PLANING不仅提供高质量、低延迟的重建，同时具备结构明确与计算效率高的优势，为大规模场景建模、AI仿真环境等下游任务提供了有力支持。

Abstract: Streaming reconstruction from monocular image sequences remains challenging, as existing methods typically favor either high-quality rendering or accurate geometry, but rarely both. We present PLANING, an efficient on-the-fly reconstruction framework built on a hybrid representation that loosely couples explicit geometric primitives with neural Gaussians, enabling geometry and appearance to be modeled in a decoupled manner. This decoupling supports an online initialization and optimization strategy that separates geometry and appearance updates, yielding stable streaming reconstruction with substantially reduced structural redundancy. PLANING improves dense mesh Chamfer-L2 by 18.52% over PGSR, surpasses ARTDECO by 1.31 dB PSNR, and reconstructs ScanNetV2 scenes in under 100 seconds, over 5x faster than 2D Gaussian Splatting, while matching the quality of offline per-scene optimization. Beyond reconstruction quality, the structural clarity and computational efficiency of \modelname~make it well suited for a broad range of downstream applications, such as enabling large-scale scene modeling and simulation-ready environments for embodied AI. Project page: https://city-super.github.io/PLANING/ .

</details>


### [80] [MetricAnything: Scaling Metric Depth Pretraining with Noisy Heterogeneous Sources](https://arxiv.org/abs/2601.22054)
*Baorui Ma,Jiahui Yang,Donglin Di,Xuancheng Zhang,Jianxun Cui,Hao Li,Yan Xie,Wei Chen*

Main category: cs.CV

TL;DR: 本文提出Metric Anything，一个简单且可扩展的预训练框架，能从各种有噪声的3D数据中自监督学习度量深度，无需人工设计提示词和相机特定建模，达成了度量深度估计领域的首次可扩展性趋势。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉基础模型规模化推动了巨大进步，但度量深度估计受限于传感器噪声、相机依赖偏差和跨源3D数据的不确定性，难以直接应用此范式。论文旨在突破这一障碍。

Method: 采用新的Sparse Metric Prompt方法：随机遮蔽深度图形成提示，将空间推理与传感器/相机偏置解耦。以约2000万组图像-深度对，跨越1万款相机、多类3D源进行大规模自监督训练。

Result: 首次观察到度量深度任务上的规模趋势。预训练模型在提示驱动任务（如深度补全、超分辨率和雷达-相机融合）上表现优异；其无提示学生模型在单目深度估计、相机参数恢复、3D重建和空间规划等通用任务上取得最新最佳结果。用该模型ViT作为视觉编码器还显著增强了多模态大模型的空间推理。

Conclusion: 度量深度估计同样能够从大规模预训练的扩展规律中获益，有望成为现实世界感知的主流方案。论文开源Metric Anything支持社区研究。

Abstract: Scaling has powered recent advances in vision foundation models, yet extending this paradigm to metric depth estimation remains challenging due to heterogeneous sensor noise, camera-dependent biases, and metric ambiguity in noisy cross-source 3D data. We introduce Metric Anything, a simple and scalable pretraining framework that learns metric depth from noisy, diverse 3D sources without manually engineered prompts, camera-specific modeling, or task-specific architectures. Central to our approach is the Sparse Metric Prompt, created by randomly masking depth maps, which serves as a universal interface that decouples spatial reasoning from sensor and camera biases. Using about 20M image-depth pairs spanning reconstructed, captured, and rendered 3D data across 10000 camera models, we demonstrate-for the first time-a clear scaling trend in the metric depth track. The pretrained model excels at prompt-driven tasks such as depth completion, super-resolution and Radar-camera fusion, while its distilled prompt-free student achieves state-of-the-art results on monocular depth estimation, camera intrinsics recovery, single/multi-view metric 3D reconstruction, and VLA planning. We also show that using pretrained ViT of Metric Anything as a visual encoder significantly boosts Multimodal Large Language Model capabilities in spatial intelligence. These results show that metric depth estimation can benefit from the same scaling laws that drive modern foundation models, establishing a new path toward scalable and efficient real-world metric perception. We open-source MetricAnything at http://metric-anything.github.io/metric-anything-io/ to support community research.

</details>


### [81] [UEval: A Benchmark for Unified Multimodal Generation](https://arxiv.org/abs/2601.22155)
*Bo Li,Yida Yin,Wenhao Chai,Xingyu Fu,Zhuang Liu*

Main category: cs.CV

TL;DR: UEval是一个针对能生成图文内容的统一模型的评测基准，包含了来源于8个任务的1000个问题，采用细致的打分准则系统，对当前模型提出挑战。


<details>
  <summary>Details</summary>
Motivation: 随着多模态生成的需求提升，市场中逐渐出现既能生成图片又能生成文本的"统一模型"，但缺乏专为这类模型设计的高质量、系统性评测基准。现有方法大多只关注单一输出或依赖主观评价，难以对如此复杂的生成能力做细致评估。本文提出UEval，旨在填补这一空白。

Method: UEval包括1000道人类专家设计的问题，涉及8类实际任务，要求模型输出同时含有图片和文本。团队设计了一套基于准则的打分系统，由大模型生成初步评价准则，再由专家审核、优化，最终形成超过1万条评价标准，实现细粒度、可扩展的自动化评测。

Result: 实验表明，当前最强的闭源统一模型在UEval上仍仅得66.4分/100, 最强开源模型更只有49.1分。同时，带有推理能力的模型明显优于无推理能力模型，将推理轨迹迁移到无推理模型也能缩小差距。

Conclusion: UEval为评价图文统一生成模型提供了更具细化和权威性的基准。推理机制对复杂多模态任务的解决具有重要作用，未来模型应更加重视推理能力的提升。

Abstract: We introduce UEval, a benchmark to evaluate unified models, i.e., models capable of generating both images and text. UEval comprises 1,000 expert-curated questions that require both images and text in the model output, sourced from 8 real-world tasks. Our curated questions cover a wide range of reasoning types, from step-by-step guides to textbook explanations. Evaluating open-ended multimodal generation is non-trivial, as simple LLM-as-a-judge methods can miss the subtleties. Different from previous works that rely on multimodal Large Language Models (MLLMs) to rate image quality or text accuracy, we design a rubric-based scoring system in UEval. For each question, reference images and text answers are provided to a MLLM to generate an initial rubric, consisting of multiple evaluation criteria, and human experts then refine and validate these rubrics. In total, UEval contains 10,417 validated rubric criteria, enabling scalable and fine-grained automatic scoring. UEval is challenging for current unified models: GPT-5-Thinking scores only 66.4 out of 100, while the best open-source model reaches merely 49.1. We observe that reasoning models often outperform non-reasoning ones, and transferring reasoning traces from a reasoning model to a non-reasoning model significantly narrows the gap. This suggests that reasoning may be important for tasks requiring complex multimodal understanding and generation.

</details>


### [82] [Unsupervised Decomposition and Recombination with Discriminator-Driven Diffusion Models](https://arxiv.org/abs/2601.22057)
*Archer Wang,Emile Anand,Yilun Du,Marin Soljačić*

Main category: cs.CV

TL;DR: 该论文提出了一种改进扩散模型的无监督因子分解方法，通过引入对抗性判别器提升因子发现与组合生成质量，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 复杂数据通常包含可复用的底层因子，将其分解有助于理解数据结构并创新性地生成新样本。现有方法难以无监督挖掘到语义一致、可组合的因子表示，尤其是在扩散模型背景下。

Method: 作者提出在扩散模型的无监督因子分解框架内，引入一个对抗性信号：训练判别器区分原始样本和跨源因子组合生成的样本，生成器则优化以以假乱真。该方式鼓励生成的组合样本具备物理与语义一致性。同时，实验覆盖不同数据结构（图像、视频等）。

Result: 该方法在CelebA-HQ、Virtual KITTI、CLEVR和Falcor3D数据集上取得了比以往方法更低的FID分数和更高的可分解性（MIG和MCC指标）。在机器人视频任务上，通过因子重新组合，生成了更具多样性的视频序列，提高了LIBERO基准上的状态空间覆盖度。

Conclusion: 通过对抗性机制，无监督因子分解扩散模型不仅提升了可分解性和生成效果，还在机器人任务中展现了更强的组件复用能力，为复杂数据理解和生成开辟了新方向。

Abstract: Decomposing complex data into factorized representations can reveal reusable components and enable synthesizing new samples via component recombination. We investigate this in the context of diffusion-based models that learn factorized latent spaces without factor-level supervision. In images, factors can capture background, illumination, and object attributes; in robotic videos, they can capture reusable motion components. To improve both latent factor discovery and quality of compositional generation, we introduce an adversarial training signal via a discriminator trained to distinguish between single-source samples and those generated by recombining factors across sources. By optimizing the generator to fool this discriminator, we encourage physical and semantic consistency in the resulting recombinations. Our method outperforms implementations of prior baselines on CelebA-HQ, Virtual KITTI, CLEVR, and Falcor3D, achieving lower FID scores and better disentanglement as measured by MIG and MCC. Furthermore, we demonstrate a novel application to robotic video trajectories: by recombining learned action components, we generate diverse sequences that significantly increase state-space coverage for exploration on the LIBERO benchmark.

</details>


### [83] [Vision-DeepResearch: Incentivizing DeepResearch Capability in Multimodal Large Language Models](https://arxiv.org/abs/2601.22060)
*Wenxuan Huang,Yu Zeng,Qiuchen Wang,Zhen Fang,Shaosheng Cao,Zheng Chu,Qingyu Yin,Shuang Chen,Zhenfei Yin,Lin Chen,Zehui Chen,Yao Hu,Philip Torr,Feng Zhao,Wanli Ouyang*

Main category: cs.CV

TL;DR: 提出了一种新的多模态深度研究范式（Vision-DeepResearch），实现了多轮次、多实体、多尺度的视觉与文本搜索，大幅提升了多模态大型语言模型在复杂任务中的能力，超越了现有方法和主流闭源大模型。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型依赖简单的“推理后调用工具”范式，这种方式对真实世界中的高噪声视觉环境未能很好应对，且检索与推理深度受限，难以解决需要多源证据聚合的复杂问题。

Method: 提出Vision-DeepResearch，通过多轮次、多实体、以及多尺度的视觉和文本搜索，支持数十步推理和数百次与搜索引擎的交互，并结合冷启动监督与强化学习训练模型，将深度研究能力内化于多模态大模型中，形成端到端的多模态深度研究系统。

Result: Vision-DeepResearch显著超越现有的多模态深度研究大模型，包括在GPT-5、Gemini-2.5-pro和Claude-4-Sonnet等强大闭源基础模型上构建的工作流。

Conclusion: 多轮次、多实体、多尺度的联合视觉与文本深度搜索极大提升了多模态大模型处理真实世界复杂任务的推理与检索能力，成果具有领先优势，代码已开源。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable success across a broad range of vision tasks. However, constrained by the capacity of their internal world knowledge, prior work has proposed augmenting MLLMs by ``reasoning-then-tool-call'' for visual and textual search engines to obtain substantial gains on tasks requiring extensive factual information. However, these approaches typically define multimodal search in a naive setting, assuming that a single full-level or entity-level image query and few text query suffices to retrieve the key evidence needed to answer the question, which is unrealistic in real-world scenarios with substantial visual noise. Moreover, they are often limited in the reasoning depth and search breadth, making it difficult to solve complex questions that require aggregating evidence from diverse visual and textual sources. Building on this, we propose Vision-DeepResearch, which proposes one new multimodal deep-research paradigm, i.e., performs multi-turn, multi-entity and multi-scale visual and textual search to robustly hit real-world search engines under heavy noise. Our Vision-DeepResearch supports dozens of reasoning steps and hundreds of engine interactions, while internalizing deep-research capabilities into the MLLM via cold-start supervision and RL training, resulting in a strong end-to-end multimodal deep-research MLLM. It substantially outperforming existing multimodal deep-research MLLMs, and workflows built on strong closed-source foundation model such as GPT-5, Gemini-2.5-pro and Claude-4-Sonnet. The code will be released in https://github.com/Osilly/Vision-DeepResearch.

</details>


### [84] [BLO-Inst: Bi-Level Optimization Based Alignment of YOLO and SAM for Robust Instance Segmentation](https://arxiv.org/abs/2601.22061)
*Li Zhang,Pengtao Xie*

Main category: cs.CV

TL;DR: 提出BLO-Inst框架，通过双层优化过程，联合提升检测与分割效果，使检测器输出更适合SAM分割，超越了传统自动分割方法。


<details>
  <summary>Details</summary>
Motivation: 现有Segment Anything Model（SAM）虽然实现了先进的零样本图像分割，但依赖人工提示（prompt），难以完全自动化。主流方法用检测器自动生成提示，但现有联合训练过程存在目标不匹配和过拟合于特定提示的问题。作者希望设计一种更合理的自动化流程，使检测与分割目标对齐，提升自动分割的泛化性能。

Method: 作者提出BLO-Inst框架，将检测与分割的优化目标用双层优化（bi-level optimization）联合。具体做法是把训练数据分为两部分，下层用检测器生成的建议框去微调SAM，上层则用另一部分数据基于微调的SAM性能，优化检测器参数。这样检测器学习到的不仅仅是定位好，还要生成对分割有利的框。

Result: BLO-Inst在多个实验上表现优异，无论在通用数据集还是生物医学数据集上都超过了主流基线。

Conclusion: BLO-Inst有效地解决了检测和分割目标不一致及训练过拟合的问题，实现了更高质量、真正自动化的高性能分割。

Abstract: The Segment Anything Model has revolutionized image segmentation with its zero-shot capabilities, yet its reliance on manual prompts hinders fully automated deployment. While integrating object detectors as prompt generators offers a pathway to automation, existing pipelines suffer from two fundamental limitations: objective mismatch, where detectors optimized for geometric localization do not correspond to the optimal prompting context required by SAM, and alignment overfitting in standard joint training, where the detector simply memorizes specific prompt adjustments for training samples rather than learning a generalizable policy. To bridge this gap, we introduce BLO-Inst, a unified framework that aligns detection and segmentation objectives by bi-level optimization. We formulate the alignment as a nested optimization problem over disjoint data splits. In the lower level, the SAM is fine-tuned to maximize segmentation fidelity given the current detection proposals on a subset ($D_1$). In the upper level, the detector is updated to generate bounding boxes that explicitly minimize the validation loss of the fine-tuned SAM on a separate subset ($D_2$). This effectively transforms the detector into a segmentation-aware prompt generator, optimizing the bounding boxes not just for localization accuracy, but for downstream mask quality. Extensive experiments demonstrate that BLO-Inst achieves superior performance, outperforming standard baselines on tasks in general and biomedical domains.

</details>


### [85] [RefAny3D: 3D Asset-Referenced Diffusion Models for Image Generation](https://arxiv.org/abs/2601.22094)
*Hanzhuo Huang,Qingyang Bao,Zekai Gu,Zhongshuo Du,Cheng Lin,Yuan Liu,Sibei Yang*

Main category: cs.CV

TL;DR: 本文提出了一种结合3D资产的扩散生成模型，实现以3D资产为参考的高一致性图像生成。通过引入空间对齐的双分支生成架构，模型能同时输出RGB图像与点云图，实现2D和3D属性的紧密结合。实验结果显示，该方法能有效提升3D资产与生成图像的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有参考图像生成方法只能基于单幅2D图像进行生成，无法利用3D资产作为更丰富的参考，导致生成模型在实际3D内容创作中的适用性受限。作者希望突破这一限制，实现对3D资产的直接引用。

Method: 提出一个跨域扩散模型，采用双分支感知架构，同时处理多视角RGB图像和3D点云数据，联合建模颜色与空间坐标，实现RGB图像与点云的空间对齐与内容解耦。

Result: 模型可利用3D资产作为参考，生成与给定资产高度一致的图像。实验验证该方法在结合2D图像和3D资产特性时优于传统方法。

Conclusion: 本文方法为扩散模型与3D内容创作的结合开辟了新方向，极大提升了生成图像与3D参考之间的一致性和实用性。

Abstract: In this paper, we propose a 3D asset-referenced diffusion model for image generation, exploring how to integrate 3D assets into image diffusion models. Existing reference-based image generation methods leverage large-scale pretrained diffusion models and demonstrate strong capability in generating diverse images conditioned on a single reference image. However, these methods are limited to single-image references and cannot leverage 3D assets, constraining their practical versatility. To address this gap, we present a cross-domain diffusion model with dual-branch perception that leverages multi-view RGB images and point maps of 3D assets to jointly model their colors and canonical-space coordinates, achieving precise consistency between generated images and the 3D references. Our spatially aligned dual-branch generation architecture and domain-decoupled generation mechanism ensure the simultaneous generation of two spatially aligned but content-disentangled outputs, RGB images and point maps, linking 2D image attributes with 3D asset attributes. Experiments show that our approach effectively uses 3D assets as references to produce images consistent with the given assets, opening new possibilities for combining diffusion models with 3D content creation.

</details>


### [86] [SINA: A Circuit Schematic Image-to-Netlist Generator Using Artificial Intelligence](https://arxiv.org/abs/2601.22114)
*Saoud Aldowaish,Yashwanth Karumanchi,Kai-Chen Chiang,Soroosh Noorzad,Morteza Fayazi*

Main category: cs.CV

TL;DR: 该论文提出了SINA，一种全自动的电路图像转网表工具，实现了96.47%的准确率，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的电路图像转网表方法在元件识别和连接关系推断方面表现不佳，限制了自动化设计与仿真的发展。

Method: SINA结合深度学习实现元件检测，采用连通域标记提取连线关系，并辅以OCR检索元件编号。创新性地引入视觉-语言模型(VLM)以提升编号分配的准确性。

Result: SINA在实验中达到了96.47%的整体网表生成准确率，性能是当前最优方法的2.72倍。

Conclusion: SINA显著提升了电路图像自动转网表的精度，为电路设计自动化提供了有力工具，具有很强的应用前景。

Abstract: Current methods for converting circuit schematic images into machine-readable netlists struggle with component recognition and connectivity inference. In this paper, we present SINA, an open-source, fully automated circuit schematic image-to-netlist generator. SINA integrates deep learning for accurate component detection, Connected-Component Labeling (CCL) for precise connectivity extraction, and Optical Character Recognition (OCR) for component reference designator retrieval, while employing a Vision-Language Model (VLM) for reliable reference designator assignments. In our experiments, SINA achieves 96.47% overall netlist-generation accuracy, which is 2.72x higher than state-of-the-art approaches.

</details>


### [87] [Creative Image Generation with Diffusion Model](https://arxiv.org/abs/2601.22125)
*Kunpeng Song,Ahmed Elgammal*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的创新性图像生成框架，通过引导生成结果向CLIP嵌入空间的低概率区域移动，从而生成新颖且富有想象力的图像。


<details>
  <summary>Details</summary>
Motivation: 现有的生成式模型在激发创新性、生成罕见且高质量图像方面存在局限，需要一种新方法突破传统想象边界。

Method: 将'创造力'定义为图像在CLIP嵌入空间中的逆概率，通过直接计算并引导概率分布进入低概率区域以生成罕见图像，同时引入pullback机制兼顾图像质量。

Result: 在文本到图像扩散模型上的大量实验显示，该框架可高效生成独特、新颖且发人深省的图像，效果优异。

Conclusion: 本方法为生成式创新性提供了新的思路和理论指导，有助于推动视觉内容合成领域向更加创新的方向发展。

Abstract: Creative image generation has emerged as a compelling area of research, driven by the need to produce novel and high-quality images that expand the boundaries of imagination. In this work, we propose a novel framework for creative generation using diffusion models, where creativity is associated with the inverse probability of an image's existence in the CLIP embedding space. Unlike prior approaches that rely on a manual blending of concepts or exclusion of subcategories, our method calculates the probability distribution of generated images and drives it towards low-probability regions to produce rare, imaginative, and visually captivating outputs. We also introduce pullback mechanisms, achieving high creativity without sacrificing visual fidelity. Extensive experiments on text-to-image diffusion models demonstrate the effectiveness and efficiency of our creative generation framework, showcasing its ability to produce unique, novel, and thought-provoking images. This work provides a new perspective on creativity in generative models, offering a principled method to foster innovation in visual content synthesis.

</details>


### [88] [EditYourself: Audio-Driven Generation and Manipulation of Talking Head Videos with Diffusion Transformers](https://arxiv.org/abs/2601.22127)
*John Flynn,Wolfgang Paier,Dimitar Dinev,Sam Nhut Nguyen,Hayk Poghosyan,Manuel Toribio,Sandipan Banerjee,Guy Gafni*

Main category: cs.CV

TL;DR: 该论文提出了一种用于基于音频驱动的视频编辑（特别是唇形同步和脚本修改）的新方法EditYourself，可以对已录制的讲话人视频进行精准、自然的内容增删和时序调整，并保证运动、时序连贯、身份一致和高保真度。


<details>
  <summary>Details</summary>
Motivation: 以往视频生成模型主要侧重于从文本或图像生成新视频，对已存在视频的细粒度编辑（如仅修改台词对应的口型）难以实现，但实际后期制作中常需要在不影响整体的前提下对说话内容小幅调整，因此迫切需要更精准、自然的视频修改工具。

Method: 提出了EditYourself方法，基于通用视频扩散模型（DiT），结合音频条件约束和面向编辑的区域感知训练扩展，实现了文本脚本级的可控增删/调整、精准唇形同步及时序结构调整（通过时空补全技术），还可在新增片段中合成自然的人体运动。

Result: 该方法能够在长时段内保持视觉保真度与身份一致性的同时，实现对讲话视频的高质量增删和时序修改，尤其保证了唇形和语音同步及动作自然衔接。

Conclusion: EditYourself为生成式视频模型在专业视频后期制作中的应用奠定了基础，实现了将现有讲话人视频按照转录脚本精确编辑的能力，显示了强大的实用前景。

Abstract: Current generative video models excel at producing novel content from text and image prompts, but leave a critical gap in editing existing pre-recorded videos, where minor alterations to the spoken script require preserving motion, temporal coherence, speaker identity, and accurate lip synchronization. We introduce EditYourself, a DiT-based framework for audio-driven video-to-video (V2V) editing that enables transcript-based modification of talking head videos, including the seamless addition, removal, and retiming of visually spoken content. Building on a general-purpose video diffusion model, EditYourself augments its V2V capabilities with audio conditioning and region-aware, edit-focused training extensions. This enables precise lip synchronization and temporally coherent restructuring of existing performances via spatiotemporal inpainting, including the synthesis of realistic human motion in newly added segments, while maintaining visual fidelity and identity consistency over long durations. This work represents a foundational step toward generative video models as practical tools for professional video post-production.

</details>


### [89] [Early and Prediagnostic Detection of Pancreatic Cancer from Computed Tomography](https://arxiv.org/abs/2601.22134)
*Wenxuan Li,Pedro R. A. S. Bassi,Lizhou Wu,Xinze Zhou,Yuxuan Zhao,Qi Chen,Szymon Plotka,Tianyu Lin,Zheren Zhu,Marisa Martin,Justin Caskey,Shanshan Jiang,Xiaoxi Chen,Jaroslaw B. Ćwikla,Artur Sankowski,Yaping Wu,Sergio Decherchi,Andrea Cavalli,Chandana Lall,Cristian Tomasetti,Yaxing Guo,Xuan Yu,Yuqing Cai,Hualin Qiao,Jie Bao,Chenhan Hu,Ximing Wang,Arkadiusz Sitek,Kai Ding,Heng Li,Meiyun Wang,Dexin Yu,Guang Zhang,Yang Yang,Kang Wang,Alan L. Yuille,Zongwei Zhou*

Main category: cs.CV

TL;DR: 该论文介绍了一种名为ePAI的人工智能系统，能在CT影像中早期精准发现胰腺癌，并表现优于专业放射科医师。


<details>
  <summary>Details</summary>
Motivation: 胰腺导管腺癌（PDAC）是一种极其致命的实体肿瘤，通常在晚期才能发现，错失手术机会。已有回顾性研究表明，很多早期影像线索被人工忽略。因此，开发能自动、早期发现PDAC的AI工具具有重要临床意义。

Method: 研究开发了ePAI——早期胰腺癌AI检测系统。该系统以1598名患者的CT数据进行训练，并在内部（1009例）及外部多中心（7158例）数据集上进行测试，评估其检测小体积PDAC的表现；还特别考察了其在既往被人工忽略的预诊断CT上的检测能力，并与30名资深放射科医生进行了多读者对比研究。

Result: ePAI在内部测试集上AUC为0.939-0.999，灵敏度95.3%，特异性98.7%，能精准定位最小至2毫米的PDAC；外部测试AUC为0.918-0.945，灵敏度91.5%，特异性88.0%，检测最低5毫米病灶；在预诊断影像中，ePAI提前中位347天发现PDAC，敏感度显著高于30位放射科医师50.3%，特异性相当。

Conclusion: ePAI可作为辅助工具，显著提升胰腺癌的早期发现能力，预测在临床早筛中具有广泛应用前景。

Abstract: Pancreatic ductal adenocarcinoma (PDAC), one of the deadliest solid malignancies, is often detected at a late and inoperable stage. Retrospective reviews of prediagnostic CT scans, when conducted by expert radiologists aware that the patient later developed PDAC, frequently reveal lesions that were previously overlooked. To help detecting these lesions earlier, we developed an automated system named ePAI (early Pancreatic cancer detection with Artificial Intelligence). It was trained on data from 1,598 patients from a single medical center. In the internal test involving 1,009 patients, ePAI achieved an area under the receiver operating characteristic curve (AUC) of 0.939-0.999, a sensitivity of 95.3%, and a specificity of 98.7% for detecting small PDAC less than 2 cm in diameter, precisely localizing PDAC as small as 2 mm. In an external test involving 7,158 patients across 6 centers, ePAI achieved an AUC of 0.918-0.945, a sensitivity of 91.5%, and a specificity of 88.0%, precisely localizing PDAC as small as 5 mm. Importantly, ePAI detected PDACs on prediagnostic CT scans obtained 3 to 36 months before clinical diagnosis that had originally been overlooked by radiologists. It successfully detected and localized PDACs in 75 of 159 patients, with a median lead time of 347 days before clinical diagnosis. Our multi-reader study showed that ePAI significantly outperformed 30 board-certified radiologists by 50.3% (P < 0.05) in sensitivity while maintaining a comparable specificity of 95.4% in detecting PDACs early and prediagnostic. These findings suggest its potential of ePAI as an assistive tool to improve early detection of pancreatic cancer.

</details>


### [90] [PI-Light: Physics-Inspired Diffusion for Full-Image Relighting](https://arxiv.org/abs/2601.22135)
*Zhexin Liang,Zhaoxi Chen,Yongwei Chen,Tianyi Wei,Tengfei Wang,Xingang Pan*

Main category: cs.CV

TL;DR: 本文提出了一个称为π-Light（PI-Light）的物理启发扩散模型框架，以提升全景图片重光照任务的物理合理性和泛化能力，展现了优于以往方法的效果。


<details>
  <summary>Details</summary>
Motivation: 现有全图重光照方法受限于真实数据难采集、物理合理性难以保证以及泛化能力不足，导致模型难以适应实际场景。

Method: 提出了一种两阶段框架，其中包括：批次感知注意力机制提升预测一致性、物理引导神经渲染模块确保物理合理的光传递、物理启发损失改善泛化能力、以及自建多样化控制光照数据集进行训练和评估。

Result: 实验表明，π-Light能够在多种材料表面生成真实的高光和漫反射效果，在真实场景中的泛化能力明显优于现有方法。

Conclusion: π-Light为全图像重光照任务提供了高效且更具物理合理性的解决方案，同时为评测重光照方法提供了新的基准。

Abstract: Full-image relighting remains a challenging problem due to the difficulty of collecting large-scale structured paired data, the difficulty of maintaining physical plausibility, and the limited generalizability imposed by data-driven priors. Existing attempts to bridge the synthetic-to-real gap for full-scene relighting remain suboptimal. To tackle these challenges, we introduce Physics-Inspired diffusion for full-image reLight ($π$-Light, or PI-Light), a two-stage framework that leverages physics-inspired diffusion models. Our design incorporates (i) batch-aware attention, which improves the consistency of intrinsic predictions across a collection of images, (ii) a physics-guided neural rendering module that enforces physically plausible light transport, (iii) physics-inspired losses that regularize training dynamics toward a physically meaningful landscape, thereby enhancing generalizability to real-world image editing, and (iv) a carefully curated dataset of diverse objects and scenes captured under controlled lighting conditions. Together, these components enable efficient finetuning of pretrained diffusion models while also providing a solid benchmark for downstream evaluation. Experiments demonstrate that $π$-Light synthesizes specular highlights and diffuse reflections across a wide variety of materials, achieving superior generalization to real-world scenes compared with prior approaches.

</details>


### [91] [Do VLMs Perceive or Recall? Probing Visual Perception vs. Memory with Classic Visual Illusions](https://arxiv.org/abs/2601.22150)
*Xiaoxiao Sun,Mingyang Li,Kun yuan,Min Woo Sun,Mark Endo,Shengguang Wu,Changlin Li,Yuhui Zhang,Zeyu Wang,Serena Yeung-Levy*

Main category: cs.CV

TL;DR: 本文提出了一种新的视觉幻觉评测框架VI-Probe，系统分析大型视觉-语言模型（VLMs）在面对经典视觉幻觉时的观感与响应机制，发现模型在视觉变化明显时仍易坚持原有答案，并揭示该现象源自多种异质原因，而非单一因素。


<details>
  <summary>Details</summary>
Motivation: 以往研究发现VLMs在处理视觉幻觉时表现出类似“死记硬背”模式，对于明显的视觉信息变化也难以适应，令人质疑其是真正“感知”还是只是在回忆训练样本模式。然而，对其具体原因的探究有限，缺少系统性和可控性分析手段。

Method: 作者提出了VI-Probe框架，能通过分级扰动和视觉对照组来生成多样化且可控的视觉幻觉样本，用于区分“基于感知”的回答和“语言记忆驱动”的回答。评估指标包括极性翻转一致性、模板固着指数和经过归一化的幻觉放大因子。

Result: 对多种主流VLMs实验表明，不同模型对于谜题的“执念”来源不一，例如GPT-5偏向记忆覆盖，Claude-Opus-4.1表现为感知与记忆间竞争，Qwen族模型则显示视觉处理能力有限。

Conclusion: VLMs在经典视觉幻觉上的反应并非由单一机制决定，而是多因素综合作用。研究挑战了VLMs相关假设，推动建立兼顾知识和感知敏感性的评测方法。

Abstract: Large Vision-Language Models (VLMs) often answer classic visual illusions "correctly" on original images, yet persist with the same responses when illusion factors are inverted, even though the visual change is obvious to humans. This raises a fundamental question: do VLMs perceive visual changes or merely recall memorized patterns? While several studies have noted this phenomenon, the underlying causes remain unclear. To move from observations to systematic understanding, this paper introduces VI-Probe, a controllable visual-illusion framework with graded perturbations and matched visual controls (without illusion inducer) that disentangles visually grounded perception from language-driven recall. Unlike prior work that focuses on averaged accuracy, we measure stability and sensitivity using Polarity-Flip Consistency, Template Fixation Index, and an illusion multiplier normalized against matched controls. Experiments across different families reveal that response persistence arises from heterogeneous causes rather than a single mechanism. For instance, GPT-5 exhibits memory override, Claude-Opus-4.1 shows perception-memory competition, while Qwen variants suggest visual-processing limits. Our findings challenge single-cause views and motivate probing-based evaluation that measures both knowledge and sensitivity to controlled visual change. Data and code are available at https://sites.google.com/view/vi-probe/.

</details>


### [92] [One-step Latent-free Image Generation with Pixel Mean Flows](https://arxiv.org/abs/2601.22158)
*Yiyang Lu,Susie Lu,Qiao Sun,Hanhong Zhao,Zhicheng Jiang,Xianbang Wang,Tianhong Li,Zhengyang Geng,Kaiming He*

Main category: cs.CV

TL;DR: 该论文提出了一种新的图像生成方法“pixel MeanFlow（pMF）”，实现了无潜变量的一步生成，在ImageNet数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前扩散/流模型依赖于多步取样和潜空间，限制了生成效率和简便性。解决这两个问题有助于实现更高效、更简化的生成方法。

Method: 方法核心是将网络输出空间（预测在图像流形上）和损失空间（定义在速度空间的MeanFlow）解耦，并提出了一种简单转换，连接图像流形和平均速度场，实现了一步图像生成。

Result: 在ImageNet 256x256和512x512上，无潜变量的一步生成分别达到了2.22和2.48的FID分数，属于同类方法中的领先水平。

Conclusion: pMF方法在实现高效、简洁的一步生成方面取得了重要进展，为扩散/流生成模型提供了新思路，推动该领域边界发展。

Abstract: Modern diffusion/flow-based models for image generation typically exhibit two core characteristics: (i) using multi-step sampling, and (ii) operating in a latent space. Recent advances have made encouraging progress on each aspect individually, paving the way toward one-step diffusion/flow without latents. In this work, we take a further step towards this goal and propose "pixel MeanFlow" (pMF). Our core guideline is to formulate the network output space and the loss space separately. The network target is designed to be on a presumed low-dimensional image manifold (i.e., x-prediction), while the loss is defined via MeanFlow in the velocity space. We introduce a simple transformation between the image manifold and the average velocity field. In experiments, pMF achieves strong results for one-step latent-free generation on ImageNet at 256x256 resolution (2.22 FID) and 512x512 resolution (2.48 FID), filling a key missing piece in this regime. We hope that our study will further advance the boundaries of diffusion/flow-based generative models.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [93] [DeepSearchQA: Bridging the Comprehensiveness Gap for Deep Research Agents](https://arxiv.org/abs/2601.20975)
*Nikita Gupta,Riju Chatterjee,Lukas Haas,Connie Tao,Andrew Wang,Chang Liu,Hidekazu Oiwa,Elena Gribovskaya,Jan Ackermann,John Blitzer,Sasha Goldshtein,Dipanjan Das*

Main category: cs.CL

TL;DR: 本文提出了DeepSearchQA，一个包含900个精心设计任务的基准数据集，用于评估智能体在多步骤信息检索任务中的能力。与以往只关注单一答案检索或事实性验证的基准不同，DeepSearchQA要求智能体执行复杂的检索计划，生成全面的答案列表。评测发现现有最先进模型在高召回率和高精度间难以平衡，暴露出多种失败模式。


<details>
  <summary>Details</summary>
Motivation: 当前信息检索智能体的评测多局限于单步或静态任务，未能充分考查智能体整合多源碎片信息、去重与实体消歧、以及在开放性任务下合理终止搜索等关键能力。本文旨在填补这一空白，推动对智能体深度信息获取能力的系统研究。

Method: 作者构建了DeepSearchQA基准，包含不同领域的900个多步骤搜索任务，每个任务要求智能体按因果链顺序依次完成子任务，侧重对长程规划、上下文保持等能力的检测。通过在公开网页数据上进行验证，评估了多种主流智能体模型的表现。

Result: 实验显示，即便是SOTA智能体模型，在高召回和高精度之间很难权衡。一些模型表现为过早停止检索（召回不足），有的则扩大搜索范围但降低答案置信度（以提升召回率）。多个Failure Mode被定量识别，显示当前模型深度研究能力有限。

Conclusion: DeepSearchQA揭示了当前智能体多步骤信息检索能力的显著短板，为今后更加鲁棒和深度的信息检索智能体研究提供了重要评测和发展方向。

Abstract: We introduce DeepSearchQA, a 900-prompt benchmark for evaluating agents on difficult multi-step information-seeking tasks across 17 different fields. Unlike traditional benchmarks that target single answer retrieval or broad-spectrum factuality, DeepSearchQA features a dataset of challenging, handcrafted tasks designed to evaluate an agent's ability to execute complex search plans to generate exhaustive answer lists. This shift in design explicitly tests three critical, yet under-evaluated capabilities: 1) systematic collation of fragmented information from disparate sources, 2) de-duplication and entity resolution to ensure precision, and 3) the ability to reason about stopping criteria within an open-ended search space. Each task is structured as a causal chain, where discovering information for one step is dependent on the successful completion of the previous one, stressing long-horizon planning and context retention. All tasks are grounded in the open web with objectively verifiable answer sets. Our comprehensive evaluation of state-of-the-art agent architectures reveals significant performance limitations: even the most advanced models struggle to balance high recall with precision. We observe distinct failure modes ranging from premature stopping (under-retrieval) to hedging behaviors, where agents cast an overly wide net of low-confidence answers to artificially boost recall. These findings highlight critical headroom in current agent designs and position DeepSearchQA as an essential diagnostic tool for driving future research toward more robust, deep-research capabilities.

</details>


### [94] [asr_eval: Algorithms and tools for multi-reference and streaming speech recognition evaluation](https://arxiv.org/abs/2601.20992)
*Oleg Sedukhin,Andrey Kostin*

Main category: cs.CL

TL;DR: 本文提出改进语音识别评测的方法，包括支持多参考标注和更好对齐算法，并发布了高质量俄语语音测试集，提供工具和统一接口以便于实际应用。


<details>
  <summary>Details</summary>
Motivation: 现有语音识别评测在多参考标注、长文本插入和对齐方面存在不足，尤其在应对非拉丁语种和复杂词形时效果有限。

Method: 提出新的字符串对齐算法，能支持多参考标注和任意长度插入，提高长文本和复杂语言对齐准确性；采集并多参考标注了俄语语音测试集DiverseSpeech-Ru；对现有俄语测试集进行多参考重标注，并研究模型微调过程对标注适应的影响。同时开发可视化对齐和评估工具，以及为不同语音识别模型提供统一封装。

Result: 提出的方法提升了评测对复杂语言和长语音的适应性，发现模型微调过程中容易适应特定数据集的标注，导致评测指标虚假提升。新工具支持线上和线下模型统一评估。

Conclusion: 改进的对齐算法和多参考数据集提升了语音识别评测的公平性和准确性；相关工具和数据集将在公开代码中提供，有助于推动多语种语音识别的发展。

Abstract: We propose several improvements to the speech recognition evaluation. First, we propose a string alignment algorithm that supports both multi-reference labeling, arbitrary-length insertions and better word alignment. This is especially useful for non-Latin languages, those with rich word formation, to label cluttered or longform speech. Secondly, we collect a novel test set DiverseSpeech-Ru of longform in-the-wild Russian speech with careful multi-reference labeling. We also perform multi-reference relabeling of popular Russian tests set and study fine-tuning dynamics on its corresponding train set. We demonstrate that the model often adopts to dataset-specific labeling, causing an illusion of metric improvement. Based on the improved word alignment, we develop tools to evaluate streaming speech recognition and to align multiple transcriptions to compare them visually. Additionally, we provide uniform wrappers for many offline and streaming speech recognition models. Our code will be made publicly available.

</details>


### [95] [UrduBench: An Urdu Reasoning Benchmark using Contextually Ensembled Translations with Human-in-the-Loop](https://arxiv.org/abs/2601.21000)
*Muhammad Ali Shafique,Areej Mehboob,Layba Fiaz,Muhammad Usman Qadeer,Hamza Farooq*

Main category: cs.CL

TL;DR: 本文提出了一套基于多系统翻译和人工验证的流程，开发了针对乌尔都语的标准化推理评测基准（UrduBench），并用其对多种大语言模型（LLM）的推理能力进行了系统评估。


<details>
  <summary>Details</summary>
Motivation: 现有对大语言模型的评估主要集中于高资源语言，针对乌尔都语等低资源语言缺乏标准推理测试集，且现有翻译方法往往丢失上下文信息，影响模型评测的公正性和有效性。

Method: 提出基于上下文集成的机器翻译方案，并引入人工校验，其中借助多个翻译系统确保语言和结构的完整性，将主流推理与问答基准数据集（如MGSM, MATH-500, CommonSenseQA, OpenBookQA）翻译为乌尔都语，创建UrduBench。采用多种模型、多种任务难度、多种推理策略，对主流LLM进行细致评测。

Result: 发现LLM在乌尔都语中的多步和符号推理任务表现不佳，语言稳定性和对齐性是加强模型多语言推理能力的关键。不同数据集、任务难度、模型架构、语言一致性测试等维度，都体现了模型性能存在显著差异。

Conclusion: 本文建立了面向乌尔都语（及其他低资源语言）标准化推理能力评测的可扩展流程，为多语言LLM推理能力的研究和改进提供了实证基础，并将公开相关代码和数据集，便于社区进一步推进相关研究。

Abstract: Recent advances in large language models (LLMs) have led to strong reasoning capabilities; however, evaluating such models in low-resource languages remains challenging due to the lack of standardized benchmarks. In particular, Urdu reasoning evaluation has been limited by the sensitivity of machine translation and an emphasis on general language tasks rather than reasoning benchmarks. In this paper, we propose a contextually ensembled translation framework with human-in-the-loop validation that leverages multiple translation systems to develop Urdu reasoning benchmarks while preserving contextual and structural integrity. Using this framework, we translate widely adopted reasoning and question-answering benchmarks, including MGSM, MATH-500, CommonSenseQA, and OpenBookQA, into Urdu, collectively referred to as UrduBench, and conduct a comprehensive evaluation of both reasoning-oriented and instruction-tuned LLMs across multiple prompting strategies. Our analysis reveals performance differences across (1) four datasets, (2) five task difficulty levels, (3) diverse model architectures, (4) multiple model scaling settings, and (5) language consistency tests. We find that multi-step and symbolic reasoning tasks pose significant challenges in Urdu, and that stable language alignment is a critical prerequisite for robust reasoning. Overall, our work establishes a scalable methodology for standardized reasoning evaluation in Urdu and provides empirical insights into multilingual reasoning failures. This experimental setup is also broadly applicable to other low-resource languages. The code and datasets will be publicly released.

</details>


### [96] [Position-invariant Fine-tuning of Speech Enhancement Models with Self-supervised Speech Representations](https://arxiv.org/abs/2601.21084)
*Amit Meghanani,Thomas Hain*

Main category: cs.CL

TL;DR: 本文探讨了将前端语音增强（SE）模型与自监督学习（SSL）语音模型结合时，常用的均方误差（MSE）损失容易陷入利用位置嵌入而非内容的弊端，提出并实验验证了两种抗这一问题的方法。


<details>
  <summary>Details</summary>
Motivation: 当前环境下，SSL模型与SE结合可提升噪声条件下的下游任务表现，但现有训练机制易被模型的位置信息利用，不能充分发挥内容上的表达能力，亟需更鲁棒的训练方式。

Method: 提出了两种抗位置嵌入偏置的方法：（1）zero-padding（零填充），即在微调阶段通过填充输入以消除位置信息影响；（2）基于样本速率扰动（speed perturbations）与soft-DTW（可微动态时间规整）损失函数，增强内容相关性。

Result: 实验证明，基于soft-DTW的方法在模型收敛速度与下游任务表现上均优于传统MSE方案，验证了其有效性及实用性。

Conclusion: SSL语音模型的微调需重视消除位置相关偏差，soft-DTW等方法为实现更鲁棒的内容表征学习提供了可行路径。

Abstract: Integrating front-end speech enhancement (SE) models with self-supervised learning (SSL)-based speech models is effective for downstream tasks in noisy conditions. SE models are commonly fine-tuned using SSL representations with mean squared error (MSE) loss between enhanced and clean speech. However, MSE is prone to exploiting positional embeddings in SSL models, allowing the objective to be minimised through positional correlations instead of content-related information. This work frames the problem as a general limitation of self-supervised representation fine-tuning and investigates it through representation-guided SE. Two strategies are considered: (1) zero-padding, previously explored in SSL pre-training but here examined in the fine-tuning setting, and (2) speed perturbations with a soft-DTW loss. Experiments show that the soft-DTW-based approach achieves faster convergence and improved downstream performance, underscoring the importance of position-invariant fine-tuning in SSL-based speech modelling.

</details>


### [97] [ChunkWise LoRA: Adaptive Sequence Partitioning for Memory-Efficient Low-Rank Adaptation and Accelerated LLM Inference](https://arxiv.org/abs/2601.21109)
*Ketan Thakkar,Maitreyi Chatterjee,Ramasubramanian Balasubramanian,Achyuthan Jootoo,Rajendra Ugrani*

Main category: cs.CL

TL;DR: 本文提出了ChunkWise LoRA，一种根据输入token复杂度动态调整低秩参数的高效大模型微调方法。该方法按照token难度将序列划分为若干可变长度的chunk，并为每个chunk分配合适的低秩配置，从而优化推理效率和内存占用。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA方法在所有输入token上使用固定的低秩配置，未考虑token复杂度和计算需求的变化，导致效率和资源利用率有限。因此，有必要发展能够依据token复杂度动态调整参数配置的新方法。

Method: 本方法通过引入运行时调度器评估token难度，实现自适应chunk划分。对每个chunk使用rank-ladder机制分配低秩等级和scaling系数。提出边界安全组合模块和基于策略的KV-cache融合，保证输出一致性。整体方案兼容现有Transformer架构与推理框架。

Result: 在Wikitext-103和SQuAD等基准数据集实验表明，ChunkWise LoRA可在保持或提升BLEU、EM与困惑度等性能下，将推理延迟降低最多34%，内存开销减少38%，优于传统静态LoRA基线。

Conclusion: ChunkWise LoRA为大语言模型提供了一种动态、资源高效且易于部署的微调解决方案，既提高了实际推理效率，也易于应用于真实场景。

Abstract: Recent advances in low-rank adaptation (LoRA) have enabled efficient fine-tuning of large language models (LLMs) with minimal additional parameters. However, existing LoRA methods apply static rank configurations uniformly across all input tokens, ignoring variation in token complexity and computational requirements. In this work, we propose ChunkWise LoRA, a dynamic and adaptive approach that partitions sequences into variable-length chunks based on token complexity and assigns each chunk a tailored low-rank configuration. Our system introduces a runtime scheduler that estimates token difficulty, performs adaptive chunking, and selects per-chunk LoRA rank and scaling using a rank-ladder mechanism. To preserve output consistency, we further introduce a boundary-safe composition module and integrate policy-driven KV-cache strategies. Experiments on benchmark datasets such as Wikitext-103 and SQuAD demonstrate that ChunkWise LoRA achieves up to 34\% lower latency and 38% memory reduction compared to baseline LoRA, while maintaining or improving task performance metrics like BLEU, EM, and perplexity. The proposed framework remains fully compatible with existing transformer architectures and inference frameworks, providing a practical solution for real-world deployment of parameter-efficient LLMs.

</details>


### [98] [Multi-task Code LLMs: Data Mix or Model Merge?](https://arxiv.org/abs/2601.21115)
*Mingzhi Zhu,Boris Sobolev,Rahul Krishna,Raju Pavuluri,Stacy Patterson,Michele Merler*

Main category: cs.CL

TL;DR: 对小型多任务代码大模型的训练方法进行了对比，发现不同规模下模型合并和数据混合有不同的优劣，合并方法在大模型中表现更好，而小模型则更适合数据混合。


<details>
  <summary>Details</summary>
Motivation: 当前趋势强调在代理框架中使用高效的小型、专用代码大模型，以兼顾性能、资源和成本。如何让小模型同时高效地执行多任务（如代码生成和摘要）成为研究关注点。

Method: 比较两种多任务小模型训练方法：一是数据混合（多任务数据一起训练），二是模型合并（先分别训练，然后合并）。基于两种模型结构（Qwen Coder和DeepSeek Coder），分别在2B和7B参数规模下进行微调，评估其在多个代码生成和摘要基准上的表现。同时引入权重分析方法，分析不同任务对参数的影响。

Result: 大规模（7B）模型采用模型合并在整体性能上优于数据混合，能保留96%专用模型性能，且不损失摘要能力，有时甚至超越单独微调。小规模（2B）模型则数据混合策略更优。权重分析揭示不同任务的参数影响与合并策略相关。

Conclusion: 针对多任务小型代码大模型，需结合规模选择合适的训练策略：大模型采用模型合并，小模型选数据混合，以实现性能最优且适于资源受限的实际部署。

Abstract: Recent research advocates deploying smaller, specialized code LLMs in agentic frameworks alongside frontier models, sparking interest in efficient strategies for multi-task learning that balance performance, constraints, and costs. We compare two approaches for creating small, multi-task code LLMs: data mixing versus model merging. We conduct extensive experiments across two model families (Qwen Coder and DeepSeek Coder) at two scales (2B and 7B parameters), fine-tuning them for code generation and code summarization tasks. Our evaluation on HumanEval, MBPP, and CodeXGlue benchmarks reveals that model merging achieves the best overall performance at larger scale across model families, retaining 96% of specialized model performance on code generation tasks while maintaining summarization capabilities. Notably, merged models can even surpass individually fine-tuned models, with our best configuration of Qwen Coder 2.5 7B model achieving 92.7% Pass@1 on HumanEval compared to 90.9% for its task-specific fine-tuned equivalent. At a smaller scale we find instead data mixing to be a preferred strategy. We further introduce a weight analysis technique to understand how different tasks affect model parameters and their implications for merging strategies. The results suggest that careful merging and mixing strategies can effectively combine task-specific capabilities without significant performance degradation, making them ideal for resource-constrained deployment scenarios.

</details>


### [99] [Large Language Models Naively Recover Ethnicity from Individual Records](https://arxiv.org/abs/2601.21132)
*Noah Dasanaike*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）能仅凭姓名推断种族，准确率超越传统BISG方法，且无需额外训练数据，适用于多国和多分类场景。


<details>
  <summary>Details</summary>
Motivation: 传统的姓氏-地理法（BISG）推断种族能力有限，仅适于美国，且其准确率受限并有社会经济偏差。因此，研究者希望借助LLM改进这一任务，拓宽应用范围，提高准确性并减少偏见。

Method: 作者采用六种大语言模型，包括商业和开源模型，对美国佛罗里达、北卡罗来纳以及黎巴嫩、印度等地多个数据集（选民记录、国会议员、土地记录）进行姓名-种族类别推断。评估了上下文推理和元数据引入对准确率的影响，并与BISG方法做系统比较。同时，还通过微调的小型transformer模型模拟大规模实际部署。

Result: 在美国数据集上，LLM准确率达到84.7%，超越BISG的68.2%。补充上下文或元数据能提升准确率至86.7%。LLM显著降低BISG中因收入带来的种族误判偏差。对不同国家和场景，准确率也显著高于BISG，并能较好捕捉实际人口分布特征。小型transformer模型用LLM标签微调后，准确率亦超过BISG。

Conclusion: LLM绕过了BISG方法的局限，实现了跨地区、跨类别的高准确率种族推断，降低了社会经济偏差。该方法具有实际可扩展性，为人口统计和社会研究相关任务提供了更优工具。

Abstract: I demonstrate that large language models can infer ethnicity from names with accuracy exceeding that of Bayesian Improved Surname Geocoding (BISG) without additional training data, enabling inference outside the United States and to contextually appropriate classification categories. Using stratified samples from Florida and North Carolina voter files with self-reported race, LLM-based classification achieves up to 84.7% accuracy, outperforming BISG (68.2%) on balanced samples. I test six models including Gemini 3 Flash, GPT-4o, and open-source alternatives such as DeepSeek v3.2 and GLM-4.7. Enabling extended reasoning can improve accuracy by 1-3 percentage points, though effects vary across contexts; including metadata such as party registration reaches 86.7%. LLM classification also reduces the income bias inherent in BISG, where minorities in wealthier neighborhoods are systematically misclassified as White. I further validate using Lebanese voter registration with religious sect (64.3% accuracy), Indian MPs from reserved constituencies (99.2%), and Indian land records with caste classification (74.0%). Aggregate validation across India, Uganda, Nepal, Armenia, Chile, and Costa Rica using original full-count voter rolls demonstrates that the method recovers known population distributions where naming conventions are distinctive. For large-scale applications, small transformer models fine-tuned on LLM labels exceed BISG accuracy while enabling local deployment at no cost.

</details>


### [100] [EnsembleLink: Accurate Record Linkage Without Training Data](https://arxiv.org/abs/2601.21138)
*Noah Dasanaike*

Main category: cs.CL

TL;DR: 本文提出了一种无需人工标注的高精度记录链接方法EnsembleLink，利用预训练语言模型实现跨数据集实体匹配，其表现优于许多传统和需标注的方法。


<details>
  <summary>Details</summary>
Motivation: 目前的记录链接方法要么准确率低，要么需要大量标注数据，而学界往往忽视了链接错误带来的不确定性对后续分析的影响，缺乏实用且普适的高准度方案。

Method: 提出EnsembleLink方法，借助大型语料库训练的语言模型，自动理解如地名、组织名、党派等之间的语义联系，实现无需标注数据的高效实体匹配。

Result: 在若干涵盖不同类别、不同语言的基准数据集上，EnsembleLink的表现达到或超过那些需要大量人工标注支持的方法。同时，该方法运行于本地开源模型，无需外部API，且速度较快。

Conclusion: EnsembleLink为社会科学和其他领域的记录链接提供了一种高效、省标注负担、广泛适用且方便本地部署的新方案，有助于提升下游分析的可靠性。

Abstract: Record linkage, the process of matching records that refer to the same entity across datasets, is essential to empirical social science but remains methodologically underdeveloped. Researchers treat it as a preprocessing step, applying ad hoc rules without quantifying the uncertainty that linkage errors introduce into downstream analyses. Existing methods either achieve low accuracy or require substantial labeled training data. I present EnsembleLink, a method that achieves high accuracy without any training labels. EnsembleLink leverages pre-trained language models that have learned semantic relationships (e.g., that "South Ozone Park" is a neighborhood in "New York City" or that "Lutte ouvriere" refers to the Trotskyist "Workers' Struggle" party) from large text corpora. On benchmarks spanning city names, person names, organizations, multilingual political parties, and bibliographic records, EnsembleLink matches or exceeds methods requiring extensive labeling. The method runs locally on open-source models, requiring no external API calls, and completes typical linkage tasks in minutes.

</details>


### [101] [Output-Space Search: Targeting LLM Generations in a Frozen Encoder-Defined Output Space](https://arxiv.org/abs/2601.21169)
*Tobias Materzok*

Main category: cs.CL

TL;DR: 本文提出了一种新的大语言模型（LLM）生成方法——输出空间搜索（OS-Search），通过在一个编码器定义的三维空间中进行端点搜索，提高了文本和代码生成的多样性和效果。


<details>
  <summary>Details</summary>
Motivation: 传统LLM生成依赖逐步的token生成，这对多样性与效率有一定的限制。作者希望通过输出空间的全局搜索，打破路径依赖，提高生成质量和灵活性。

Method: 提出在冷冻编码器定义的三维输出空间中，由外层循环选择目标z*，然后训练一个以检索为基础的策略，使生成结果坐标接近z*。采用序列级强化学习，并允许在输出空间进行并行搜索或黑盒优化。

Result: 在故事生成任务中，输出空间搜索方法比提示链提高了3.1倍的多样性；在代码生成任务中，贝叶斯优化能在相同预算下，同时保持生成有效性的基础上，提升被隐藏目标函数的表现。

Conclusion: 输出空间搜索（OS-Search）有效提升了LLM生成内容的多样性和目标达成能力，为大模型生成任务提供了更具探索性和灵活性的范式。

Abstract: We introduce Output-Space Search (OS-Search), which turns LLM generation into endpoint search. An outer loop selects a target z* in a frozen encoder-defined 3D output space Z, and a retrieval-grounded policy trained with sequence-level RL generates outputs whose coordinates land near z* under standard autoregressive decoding. This enables parallel sweeps and black-box optimization in Z without path-dependent token/program search. On stories, sweeping Z (text) yields 3.1x higher LLM-scored diversity than prompt-chaining. On code, Bayesian optimization over Z (code) improves an objective withheld from the controller under matched inference budgets while preserving validity.

</details>


### [102] [From Linear Input to Hierarchical Structure: Function Words as Statistical Cues for Language Learning](https://arxiv.org/abs/2601.21191)
*Xiulin Yang,Heidi Getz,Ethan Gotlieb Wilcox*

Main category: cs.CL

TL;DR: 本文通过跨语言语料库分析和神经网络模型实验证明：功能词的高频率、结构性关联和短语边界对语言层级结构学习至关重要，且不同学习条件会影响模型对功能词依赖的方式。


<details>
  <summary>Details</summary>
Motivation: 探讨线性输入中哪种统计条件有助于学习语言的层级结构，尤其关注功能词的分布特性在语言习得中的作用。

Method: 跨186种语言语料库分析功能词的分布特性；使用反事实语言建模和消融实验，考察当功能词的三种分布属性被保留或剔除时，神经网络模型学习语言的表现；对模型内部机制做进一步探查和分析。

Result: 所有研究语言中，功能词普遍具备高频率、可靠结构关联和短语边界性；神经网络对保留全部三种属性的语言变体更易习得，频率和结构关联作用大于边界性；不同学习条件下，模型对功能词的依赖机制存在系统性差异。

Conclusion: 功能词的典型分布属性在语言层级结构学习中具有重要支持作用，但同等性能可能来自模型内部不同的机制，使得研究语言学习机制需进一步关注内部表征的多样性。

Abstract: What statistical conditions support learning hierarchical structure from linear input? In this paper, we address this question by focusing on the statistical distribution of function words. Function words have long been argued to play a crucial role in language acquisition due to their distinctive distributional properties, including high frequency, reliable association with syntactic structure, and alignment with phrase boundaries. We use cross-linguistic corpus analysis to first establish that all three properties are present across 186 studied languages. Next, we use a combination of counterfactual language modeling and ablation experiments to show that language variants preserving all three properties are more easily acquired by neural learners, with frequency and structural association contributing more strongly than boundary alignment. Follow-up probing and ablation analyses further reveal that different learning conditions lead to systematically different reliance on function words, indicating that similar performance can arise from distinct internal mechanisms.

</details>


### [103] [Scaling Embeddings Outperforms Scaling Experts in Language Models](https://arxiv.org/abs/2601.21204)
*Hong Liu,Jiaqi Zhang,Chao Wang,Xing Hu,Linkun Lyu,Jiaqi Sun,Xurui Yang,Bo Wang,Fengcun Li,Yulei Qian,Lingtong Si,Yerui Sun,Rumei Li,Peng Pei,Yuchen Xie,Xunliang Cai*

Main category: cs.CL

TL;DR: 本文提出了一种基于Embedding扩展的稀疏性扩展方法，作为Mixture-of-Experts (MoE)架构的正交补充，并通过全新结构LongCat-Flash-Lite展示了在推理速度和效果上的优势。


<details>
  <summary>Details</summary>
Motivation: 目前大模型主要使用MoE方法进行参数稀疏扩展，但该法存在边际效益递减和系统瓶颈，作者希望探索通过Embedding维度扩展能否实现更好的稀疏性扩展及性能提升。

Method: 对比分析Embedding扩展与Expert扩展对于模型规模提升的影响，并提出了一套结合架构优化、参数预算、模型宽度与深度调节的系统方案。采用系统优化和推理阶段的speculative decoding显著提升实际推理速度。

Result: 提出并训练了68.5B参数、其中约3B激活的新模型LongCat-Flash-Lite。该模型拥有超过30B Embedding参数，表现明显超越同参数量MoE模型，在智能体和编程任务上与同等规模SOTA模型表现接近或更优。

Conclusion: Embedding扩展在特定条件下可优于Expert方向的扩展，适当的系统优化可有效将稀疏带来的理论性能转化为实际推理速度提升。该方案为大模型参数稀疏扩展提供了正交补充，具有很强的实用价值和应用前景。

Abstract: While Mixture-of-Experts (MoE) architectures have become the standard for sparsity scaling in large language models, they increasingly face diminishing returns and system-level bottlenecks. In this work, we explore embedding scaling as a potent, orthogonal dimension for scaling sparsity. Through a comprehensive analysis and experiments, we identify specific regimes where embedding scaling achieves a superior Pareto frontier compared to expert scaling. We systematically characterize the critical architectural factors governing this efficacy -- ranging from parameter budgeting to the interplay with model width and depth. Moreover, by integrating tailored system optimizations and speculative decoding, we effectively convert this sparsity into tangible inference speedups. Guided by these insights, we introduce LongCat-Flash-Lite, a 68.5B parameter model with ~3B activated trained from scratch. Despite allocating over 30B parameters to embeddings, LongCat-Flash-Lite not only surpasses parameter-equivalent MoE baselines but also exhibits exceptional competitiveness against existing models of comparable scale, particularly in agentic and coding domains.

</details>


### [104] [Multilingual Dysarthric Speech Assessment Using Universal Phone Recognition and Language-Specific Phonemic Contrast Modeling](https://arxiv.org/abs/2601.21205)
*Eunjung Yeo,Julie M. Liss,Visar Berisha,David R. Mortensen*

Main category: cs.CL

TL;DR: 本文提出了一种多语言语音能懂度评估框架，结合通用音素识别与语言特异性音素解释，能有效在多种语言中量化和区分构音障碍患者语音的可懂度。


<details>
  <summary>Details</summary>
Motivation: 现有语音能懂度自动评估方法主要局限于单一语言，或无法有效捕捉语言之间影响能懂度的具体差异，而神经性构音障碍疾病在全球范围内日益普遍，迫切需要跨语言适用的评估方法。

Method: 提出多语言音素产出评估框架，融合通用音素识别和基于对比音系特征距离的语言特定音素映射和序列对齐。设计了三种评估指标：音素错误率（PER）、音系特征错误率（PFER）、新提出的无对齐度量-音素覆盖率（PhonCov）。在英文、西班牙文、意大利文和泰米尔文上实验并分析不同方案对指标的贡献。

Result: PER受益于音素映射与对齐的结合，PFER主要依赖对齐，PhonCov则因音素映射而提升。框架能够捕捉和临床一致的构音障碍语音能懂度下降相关的特征模式。

Conclusion: 该框架能够有效、跨语言地评估构音障碍语音的能懂度，捕捉具有临床意义的可懂度变化，为多语种自动语音障碍评估提供了新的技术途径。

Abstract: The growing prevalence of neurological disorders associated with dysarthria motivates the need for automated intelligibility assessment methods that are applicalbe across languages. However, most existing approaches are either limited to a single language or fail to capture language-specific factors shaping intelligibility. We present a multilingual phoneme-production assessment framework that integrates universal phone recognition with language-specific phoneme interpretation using contrastive phonological feature distances for phone-to-phoneme mapping and sequence alignment. The framework yields three metrics: phoneme error rate (PER), phonological feature error rate (PFER), and a newly proposed alignment-free measure, phoneme coverage (PhonCov). Analysis on English, Spanish, Italian, and Tamil show that PER benefits from the combination of mapping and alignment, PFER from alignment alone, and PhonCov from mapping. Further analyses demonstrate that the proposed framework captures clinically meaningful patterns of intelligibility degradation consistent with established observations of dysarthric speech.

</details>


### [105] [Scaling Reasoning Hop Exposes Weaknesses: Demystifying and Improving Hop Generalization in Large Language Models](https://arxiv.org/abs/2601.21214)
*Zhaoyi Li,Jiatong Li,Gangwei Jiang,Linqi Song,Defu Lian,Ying Wei*

Main category: cs.CL

TL;DR: 本文探讨了大语言模型（LLM）在Chain-of-thought（CoT）推理上的泛化难题，发现错误主要集中在少数关键位置，并提出了通过动态关闭有害注意力头以提升模型泛化性能的方法。


<details>
  <summary>Details</summary>
Motivation: 尽管CoT推理极大提升了LLM解决复杂问题的能力，但当前模型在面对超出训练步数分布的推理步骤时性能急剧下降，而其背后的关键机制尚不清楚。本文旨在揭示导致泛化性能下降的内在原因，并寻找改进方法。

Method: 作者对多个领域的任务进行分析，定位错误集中在少数关键token的位置。进一步研究发现，个别注意力头（ep heads）在内部竞争机制中起到放大错误推理路径、抑制正确推理的作用。基于此，提出了一种推理时动态识别并关闭ep heads的轻量级校正方法。

Result: 实验证明，在不同任务和多种主流LLM上，动态关闭有害注意力头的干预措施能显著提升推理步泛化能力，错误率降低明显。

Conclusion: 分析揭示了LLM推理泛化失败的内部机制，提出的动态干预措施提升了模型性能，具有广泛的适用性和改进潜力。

Abstract: Chain-of-thought (CoT) reasoning has become the standard paradigm for enabling Large Language Models (LLMs) to solve complex problems. However, recent studies reveal a sharp performance drop in reasoning hop generalization scenarios, where the required number of reasoning steps exceeds training distributions while the underlying algorithm remains unchanged. The internal mechanisms driving this failure remain poorly understood. In this work, we conduct a systematic study on tasks from multiple domains, and find that errors concentrate at token positions of a few critical error types, rather than being uniformly distributed. Closer inspection reveals that these token-level erroneous predictions stem from internal competition mechanisms: certain attention heads, termed erroneous processing heads (ep heads), tip the balance by amplifying incorrect reasoning trajectories while suppressing correct ones. Notably, removing individual ep heads during inference can often restore the correct predictions. Motivated by these insights, we propose test-time correction of reasoning, a lightweight intervention method that dynamically identifies and deactivates ep heads in the reasoning process. Extensive experiments across different tasks and LLMs show that it consistently improves reasoning hop generalization, highlighting both its effectiveness and potential.

</details>


### [106] [Parametric Knowledge is Not All You Need: Toward Honest Large Language Models via Retrieval of Pretraining Data](https://arxiv.org/abs/2601.21218)
*Christopher Adrian Kusuma,Muhammad Reza Qorib,Hwee Tou Ng*

Main category: cs.CL

TL;DR: 本论文提出了一个更健壮的LLM诚实性评测数据集，并利用开源模型Pythia的预训练数据，探索提升LLM诚实性的新方法。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在回答问题时，常常在知识边界之外产生错误信息（即幻觉），未能如实表述“不知道”。现有提升诚实性的方法评估方式不够健壮，未充分考虑预训练数据影响。

Method: 作者设计了一个新的评测数据集，该数据集依托于Pythia模型透明的预训练语料。除此之外，作者还提出了一种新方法，直接利用预训练数据来构建更加诚实的LLM。

Result: 通过在新数据集上的测试，证明了所提方法和数据集可以更准确评估并提升LLM的诚实性表现。

Conclusion: 本文为评估和提升大型语言模型诚实性提供了新的工具和方法，有助于减少模型幻觉、提升实际应用可靠性。

Abstract: Large language models (LLMs) are highly capable of answering questions, but they are often unaware of their own knowledge boundary, i.e., knowing what they know and what they don't know. As a result, they can generate factually incorrect responses on topics they do not have enough knowledge of, commonly known as hallucination. Rather than hallucinating, a language model should be more honest and respond with "I don't know" when it does not have enough knowledge about a topic. Many methods have been proposed to improve LLM honesty, but their evaluations lack robustness, as they do not take into account the knowledge that the LLM has ingested during its pretraining. In this paper, we propose a more robust evaluation benchmark dataset for LLM honesty by utilizing Pythia, a truly open LLM with publicly available pretraining data. In addition, we also propose a novel method for harnessing the pretraining data to build a more honest LLM.

</details>


### [107] [MGSM-Pro: A Simple Strategy for Robust Multilingual Mathematical Reasoning Evaluation](https://arxiv.org/abs/2601.21225)
*Tianyi Xu,Kosei Uemura,Alfred Malengo Kondoro,Tadesse Destaw Belay,Catherine Nana Nyaah Essuman,Ifeoma Okoh,Ganiyat Afolabi,Ayodele Awokoya,David Ifeoluwa Adelani*

Main category: cs.CL

TL;DR: 本文提出MGSM-Pro数据集，用于多语言数学推理评测，针对每道题目引入不同数字、名字与无关上下文的复现变体。实验显示，低资源语言模型对数字变体敏感，主流模型鲁棒性存在差异。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在数学推理上取得进展，但多语言高难度、多样性评测基准落后于英文，且缺乏对题目变体鲁棒性的系统评估。

Method: 基于MGSM数据集，采用GSM-Symbolic方法扩展，每题生成5个通过变更数字、名字及无关上下文的变体，覆盖9种语言，对比主流闭源模型和开源模型的表现及鲁棒性。

Result: 在不同数字变体上，许多低资源语言的表现大幅下降。闭源模型如Gemini 2.5 Flash和GPT-4.1对数字变体不够鲁棒，Claude 4.0 Sonnet更为稳健。开源模型GPT-OSS 120B与DeepSeek V3鲁棒性更强。

Conclusion: 建议数学推理评测应对每道题使用至少5种数字变体，以获得更全面和真实的模型能力评估。

Abstract: Large language models have made substantial progress in mathematical reasoning. However, benchmark development for multilingual evaluation has lagged behind English in both difficulty and recency. Recently, GSM-Symbolic showed a strong evidence of high variance when models are evaluated on different instantiations of the same question; however, the evaluation was conducted only in English. In this paper, we introduce MGSM-Pro, an extension of MGSM dataset with GSM-Symbolic approach. Our dataset provides five instantiations per MGSM question by varying names, digits and irrelevant context. Evaluations across nine languages reveal that many low-resource languages suffer large performance drops when tested on digit instantiations different from those in the original test set. We further find that some proprietary models, notably Gemini 2.5 Flash and GPT-4.1, are less robust to digit instantiation, whereas Claude 4.0 Sonnet is more robust. Among open models, GPT-OSS 120B and DeepSeek V3 show stronger robustness. Based on these findings, we recommend evaluating each problem using at least five digit-varying instantiations to obtain a more robust and realistic assessment of math reasoning.

</details>


### [108] [SHARP: Social Harm Analysis via Risk Profiles for Measuring Inequities in Large Language Models](https://arxiv.org/abs/2601.21235)
*Alok Abhishek,Tushar Bandopadhyay,Lisa Erickson*

Main category: cs.CL

TL;DR: 本文提出了一个名为SHARP的新框架，用于多维度、关注极端风险的LLM社会危害评估，发现平均风险相似的模型在极端风险上差异巨大。


<details>
  <summary>Details</summary>
Motivation: 现有评测方法常用单一平均分来度量LLM的社会风险，无法揭示最糟糕情境、风险分布以及社会危害不同维度间的相互作用，对关键极端失败暴露不足。

Method: 提出社会危害风险谱分析（SHARP）框架，将危害建模为多变量随机变量，显式分解为偏见、公平性、伦理和认知可靠性风险。采用条件风险价值（CVaR95）等分布敏感统计衡量极端行为，并把多个子风险用累加的对数风险汇总。对11个前沿LLM在901条敏感提示上评测。

Result: 发现平均风险相近的模型，在极端风险（尾部暴露）和波动性上可差异超过2倍。不同风险维度在各模型间的表现也存在系统性差异：偏见尾部风险最强，认知和公平居中，伦理风险较低。

Conclusion: 单一平均指标掩盖了模型现实世界风险结构的差异，负责任的LLM评测与治理应采纳多维度、关注极端风险的分析方法。

Abstract: Large language models (LLMs) are increasingly deployed in high-stakes domains, where rare but severe failures can result in irreversible harm. However, prevailing evaluation benchmarks often reduce complex social risk to mean-centered scalar scores, thereby obscuring distributional structure, cross-dimensional interactions, and worst-case behavior. This paper introduces Social Harm Analysis via Risk Profiles (SHARP), a framework for multidimensional, distribution-aware evaluation of social harm. SHARP models harm as a multivariate random variable and integrates explicit decomposition into bias, fairness, ethics, and epistemic reliability with a union-of-failures aggregation reparameterized as additive cumulative log-risk. The framework further employs risk-sensitive distributional statistics, with Conditional Value at Risk (CVaR95) as a primary metric, to characterize worst-case model behavior. Application of SHARP to eleven frontier LLMs, evaluated on a fixed corpus of n=901 socially sensitive prompts, reveals that models with similar average risk can exhibit more than twofold differences in tail exposure and volatility. Across models, dimension-wise marginal tail behavior varies systematically across harm dimensions, with bias exhibiting the strongest tail severities, epistemic and fairness risks occupying intermediate regimes, and ethical misalignment consistently lower; together, these patterns reveal heterogeneous, model-dependent failure structures that scalar benchmarks conflate. These findings indicate that responsible evaluation and governance of LLMs require moving beyond scalar averages toward multidimensional, tail-sensitive risk profiling.

</details>


### [109] [MoCo: A One-Stop Shop for Model Collaboration Research](https://arxiv.org/abs/2601.21257)
*Shangbin Feng,Yuyang Bai,Ziyuan Yang,Yike Wang,Zhaoxuan Tan,Jiajie Yan,Zhenyu Lei,Wenxuan Ding,Weijia Shi,Haojin Wang,Zhenting Qi,Yuru Jiang,Heng Wang,Chengsong Huang,Yu Fei,Jihan Yao,Yilun Du,Luke Zettlemoyer,Yejin Choi,Yulia Tsvetkov*

Main category: cs.CL

TL;DR: MoCo是一个用于多模型协作研究的Python库，集成了26种模型协作方法与25个评测数据集，支持大规模算法执行、评测与比较。实验显示多数协作策略优于单模型。


<details>
  <summary>Details</summary>
Motivation: 单一大型语言模型能力有限，多模型协作逐渐重要，但领域内研究分散、缺统一标准，缺少集成工具和系统性比较。

Method: 开发了MoCo库，涵盖不同粒度的模型信息交换方法（如路由、文本、logit、参数级共享），支持多种数据集和自定义数据，系统地收集、执行和评测多种模型协作算法。

Result: 在61%的模型与数据配置下，多数协作方法优于单一模型，最有效的协作方式提升可达25.8%。还分析了协作方法的可扩展性和效率，并发现协作在单模型无法解决的问题上表现尤佳。

Conclusion: MoCo为模型协作领域提供了统一的工具，有助于推动开放、模块化、去中心化、协作式AI的发展。

Abstract: Advancing beyond single monolithic language models (LMs), recent research increasingly recognizes the importance of model collaboration, where multiple LMs collaborate, compose, and complement each other. Existing research on this topic has mostly been disparate and disconnected, from different research communities, and lacks rigorous comparison. To consolidate existing research and establish model collaboration as a school of thought, we present MoCo: a one-stop Python library of executing, benchmarking, and comparing model collaboration algorithms at scale. MoCo features 26 model collaboration methods, spanning diverse levels of cross-model information exchange such as routing, text, logit, and model parameters. MoCo integrates 25 evaluation datasets spanning reasoning, QA, code, safety, and more, while users could flexibly bring their own data. Extensive experiments with MoCo demonstrate that most collaboration strategies outperform models without collaboration in 61.0% of (model, data) settings on average, with the most effective methods outperforming by up to 25.8%. We further analyze the scaling of model collaboration strategies, the training/inference efficiency of diverse methods, highlight that the collaborative system solves problems where single LMs struggle, and discuss future work in model collaboration, all made possible by MoCo. We envision MoCo as a valuable toolkit to facilitate and turbocharge the quest for an open, modular, decentralized, and collaborative AI future.

</details>


### [110] [CausalEmbed: Auto-Regressive Multi-Vector Generation in Latent Space for Visual Document Embedding](https://arxiv.org/abs/2601.21262)
*Jiahao Huo,Yu Huang,Yibo Yan,Ye Pan,Yi Cao,Mingdong Ou,Philip S. Yu,Xuming Hu*

Main category: cs.CL

TL;DR: CausalEmbed通过自回归生成技术减少视觉文档检索中的存储开销，实现高效的多向量嵌入表示，显著降低所需视觉token数，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在视觉文档检索中需使用大量视觉token生成多向量嵌入，导致存储开销大，实际应用受限。

Method: 提出CausalEmbed自回归生成方法，并在对比训练中引入迭代margin loss，引导模型学习更紧凑、结构化的表示，仅用几十个视觉token实现高效表征。

Result: 新方法在保持性能的同时，实现了token数30-155倍的压缩，在多种网络骨干和基准上表现优异。理论和实验表明，所提自回归生成在训练效率和推理扩展性方面有明显优势。

Conclusion: CausalEmbed提升了视觉文档检索的效率和灵活性，推动多模态生成式检索新范式的探索。

Abstract: Although Multimodal Large Language Models (MLLMs) have shown remarkable potential in Visual Document Retrieval (VDR) through generating high-quality multi-vector embeddings, the substantial storage overhead caused by representing a page with thousands of visual tokens limits their practicality in real-world applications. To address this challenge, we propose an auto-regressive generation approach, CausalEmbed, for constructing multi-vector embeddings. By incorporating iterative margin loss during contrastive training, CausalEmbed encourages the embedding models to learn compact and well-structured representations. Our method enables efficient VDR tasks using only dozens of visual tokens, achieving a 30-155x reduction in token count while maintaining highly competitive performance across various backbones and benchmarks. Theoretical analysis and empirical results demonstrate the unique advantages of auto-regressive embedding generation in terms of training efficiency and scalability at test time. As a result, CausalEmbed introduces a flexible test-time scaling strategy for multi-vector VDR representations and sheds light on the generative paradigm within multimodal document retrieval.

</details>


### [111] [Qwen3-ASR Technical Report](https://arxiv.org/abs/2601.21337)
*Xian Shi,Xiong Wang,Zhifang Guo,Yongqi Wang,Pei Zhang,Xinyu Zhang,Zishan Guo,Hongkun Hao,Yu Xi,Baosong Yang,Jin Xu,Jingren Zhou,Junyang Lin*

Main category: cs.CL

TL;DR: 本文介绍了Qwen3-ASR系列，包括两个支持52种语言的端到端语音识别模型和一个基于大语言模型的非自回归语音对齐器。Qwen3-ASR-1.7B在开源模型中效果领先，0.6B版本在效率与准确率间达到最佳平衡；对齐器在准确率和效率上也优于既有模型。所有模型均开放源代码。


<details>
  <summary>Details</summary>
Motivation: 现有的语音识别和对齐模型在开源场景下效果有限，尤其是在多语言支持和实际应用性能上难以媲美商业API，且缺乏高效、通用的强大模型。因此，作者希望开发高准确率、高效率的多语言语音识别和对齐模型，推动社区研究。

Method: 作者提出了两种基于大规模语音训练数据及强大基础模型Qwen3-Omni的端到端语音识别模型Qwen3-ASR-1.7B/0.6B，并设计了NAR架构的LLM对齐器Qwen3-ForcedAligner-0.6B。通过公开基准与真实场景的综合评测，验证了模型在多语言识别与对齐方面的性能和效率。

Result: Qwen3-ASR-1.7B取得了开源ASR模型中最优表现，且在与主流商业API的对比中也具竞争力。Qwen3-ASR-0.6B具备高准确率以及极低延迟和高吞吐量。Qwen3-ForcedAligner-0.6B在11种语言的对齐任务中领先现有三种最强模型，还具备更高的效率和多用性。

Conclusion: Qwen3-ASR系列模型在多语言语音识别和高效语音对齐任务中均体现出SOTA性能，并且全部以Apache 2.0协议开源，为社区带来了强大的工具，促进ASR与音频理解的研究。

Abstract: In this report, we introduce Qwen3-ASR family, which includes two powerful all-in-one speech recognition models and a novel non-autoregressive speech forced alignment model. Qwen3-ASR-1.7B and Qwen3-ASR-0.6B are ASR models that support language identification and ASR for 52 languages and dialects. Both of them leverage large-scale speech training data and the strong audio understanding ability of their foundation model Qwen3-Omni. We conduct comprehensive internal evaluation besides the open-sourced benchmarks as ASR models might differ little on open-sourced benchmark scores but exhibit significant quality differences in real-world scenarios. The experiments reveal that the 1.7B version achieves SOTA performance among open-sourced ASR models and is competitive with the strongest proprietary APIs while the 0.6B version offers the best accuracy-efficiency trade-off. Qwen3-ASR-0.6B can achieve an average TTFT as low as 92ms and transcribe 2000 seconds speech in 1 second at a concurrency of 128. Qwen3-ForcedAligner-0.6B is an LLM based NAR timestamp predictor that is able to align text-speech pairs in 11 languages. Timestamp accuracy experiments show that the proposed model outperforms the three strongest force alignment models and takes more advantages in efficiency and versatility. To further accelerate the community research of ASR and audio understanding, we release these models under the Apache 2.0 license.

</details>


### [112] [Self-Improving Pretraining: using post-trained models to pretrain better models](https://arxiv.org/abs/2601.21343)
*Ellen Xiaoqing Tan,Shehzaad Dhuliawala,Jing Xu,Ping Yu,Sainbayar Sukhbaatar,Jason Weston,Olga Golovneva*

Main category: cs.CL

TL;DR: 本文提出了一种新的大模型预训练方法，通过引入强化学习和动态文档流，显著提升了生成内容的安全性、事实性和整体质量。实验结果显示相比标准预训练，该方法在事实性和安全性上分别提升了36.2%和18.5%，在整体生成质量上的胜率提升高达86.3%。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在实际应用中的普及，生成内容的安全性、事实性及质量日益受到关注。传统方法依赖昂贵且精细的数据集和复杂的微调流程，依然无法根除预训练阶段习得的不良模式。因此，有必要在预训练阶段直接提升模型行为的规范性。

Method: 该方法创新性地在预训练过程中采用文档流+强化学习机制：模型每步生成接下来的K个token，由一个强大的后置模型对候选内容（包括原始、重写等多个版本）进行质量、安全性和事实性评估。训练早期主要采用原始和重写版本，随模型能力提高，更多依赖高质量的生成内容并进行强化学习奖励，从而逐步导向更规范行为。

Result: 实验显示，该方法在事实性提升36.2%、安全性提升18.5%，生成质量胜率提升可达86.3%。综合性能远超传统预训练流程。

Conclusion: 通过在预训练阶段嵌入强化学习和判别机制，可以从根本上提升大模型的安全性、事实性和生成质量，避免后期修正的高昂代价，为后续大模型开发提供新思路。

Abstract: Ensuring safety, factuality and overall quality in the generations of large language models is a critical challenge, especially as these models are increasingly deployed in real-world applications. The prevailing approach to addressing these issues involves collecting expensive, carefully curated datasets and applying multiple stages of fine-tuning and alignment. However, even this complex pipeline cannot guarantee the correction of patterns learned during pretraining. Therefore, addressing these issues during pretraining is crucial, as it shapes a model's core behaviors and prevents unsafe or hallucinated outputs from becoming deeply embedded. To tackle this issue, we introduce a new pretraining method that streams documents and uses reinforcement learning (RL) to improve the next K generated tokens at each step. A strong, post-trained model judges candidate generations -- including model rollouts, the original suffix, and a rewritten suffix -- for quality, safety, and factuality. Early in training, the process relies on the original and rewritten suffixes; as the model improves, RL rewards high-quality rollouts. This approach builds higher quality, safer, and more factual models from the ground up. In experiments, our method gives 36.2% and 18.5% relative improvements over standard pretraining in terms of factuality and safety, and up to 86.3% win rate improvements in overall generation quality.

</details>


### [113] [The Compliance Paradox: Semantic-Instruction Decoupling in Automated Academic Code Evaluation](https://arxiv.org/abs/2601.21360)
*Devanshu Sahoo,Manish Prasad,Vasudev Majhi,Arjun Neekhra,Yash Sinha,Murari Mandal,Vinay Chamola,Dhruv Kumar*

Main category: cs.CL

TL;DR: 本文发现主流大语言模型（LLMs）在自动代码评分时存在严重漏洞，即易于被隐藏指令误导，导致明明代码有错却被评为正确。


<details>
  <summary>Details</summary>
Motivation: 研究快速将LLMs融入自动化教育测评领域的安全与可靠性，质疑其“听话就能公正评判”的假设，探索其面临的潜在系统性攻击与失误。

Method: 作者提出了两套新方法：SPACI框架与AST-ASIP协议，通过在抽象语法树的无关节点中嵌入对抗指令，测试并揭露主流模型受骗程度，并大规模（25,000份作业，9个模型，4种语言）实验验证；同时引入三指标量化失效。

Result: 结果显示，尤其是公开权重的先进模型（如DeepSeek-V3），在隐藏指令诱导下错误评判率超过95%，会优先满足无效格式而非逻辑、功能性正确性，导致大量错误代码被‘认证’为正确。

Conclusion: 现有以RLHF为主的对齐范式在教育自动评分中存在‘木马’漏洞，需要转向关注证据优先的特定领域鲁棒性训练。数据集和工具框架已开源，供后续研究。

Abstract: The rapid integration of Large Language Models (LLMs) into educational assessment rests on the unverified assumption that instruction following capability translates directly to objective adjudication. We demonstrate that this assumption is fundamentally flawed. Instead of evaluating code quality, models frequently decouple from the submission's logic to satisfy hidden directives, a systemic vulnerability we term the Compliance Paradox, where models fine-tuned for extreme helpfulness are vulnerable to adversarial manipulation. To expose this, we introduce the Semantic-Preserving Adversarial Code Injection (SPACI) Framework and the Abstract Syntax Tree-Aware Semantic Injection Protocol (AST-ASIP). These methods exploit the Syntax-Semantics Gap by embedding adversarial directives into syntactically inert regions (trivia nodes) of the Abstract Syntax Tree. Through a large-scale evaluation of 9 SOTA models across 25,000 submissions in Python, C, C++, and Java, we reveal catastrophic failure rates (>95%) in high-capacity open-weights models like DeepSeek-V3, which systematically prioritize hidden formatting constraints over code correctness. We quantify this failure using our novel tripartite framework measuring Decoupling Probability, Score Divergence, and Pedagogical Severity to demonstrate the widespread "False Certification" of functionally broken code. Our findings suggest that current alignment paradigms create a "Trojan" vulnerability in automated grading, necessitating a shift from standard RLHF toward domain-specific Adjudicative Robustness, where models are conditioned to prioritize evidence over instruction compliance. We release our complete dataset and injection framework to facilitate further research on the topic.

</details>


### [114] [User-Centric Evidence Ranking for Attribution and Fact Verification](https://arxiv.org/abs/2601.21387)
*Guy Alt,Eran Hirsch,Serwar Basch,Ido Dagan,Oren Glickman*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的证据排序任务，旨在优化事实核查系统中证据呈现的效率和效果，通过排序让用户更早获得足够信息，减少阅读负担并提升核查准确性。


<details>
  <summary>Details</summary>
Motivation: 目前自然语言处理中的自动事实核查系统常因提供的信息过多或不足，导致用户验证效率低下、易出错。现有方法在证据组织和展示上尚未能兼顾信息充分和用户体验。

Method: 提出证据排序任务，定义了两种排序方法：一次性排序（one-shot ranking）和增量式排序（incremental ranking）；建立了基于信息检索指标的新评估框架，并整合多个事实核查数据集，构建统一基准；通过各类模型进行广泛实验。

Result: 增量排序更能捕捉证据间的互补性，基于大语言模型的方法优于浅层模型，但在充分性与冗余之间仍需平衡。用户实验显示，证据排序比传统选择显著减少阅读负担并提升核查表现。

Conclusion: 证据排序任务有助于构建更高效、易解释且以用户为中心的信任信息核查系统，为更智能的信息检验提供基础性进展。

Abstract: Attribution and fact verification are critical challenges in natural language processing for assessing information reliability. While automated systems and Large Language Models (LLMs) aim to retrieve and select concise evidence to support or refute claims, they often present users with either insufficient or overly redundant information, leading to inefficient and error-prone verification. To address this, we propose Evidence Ranking, a novel task that prioritizes presenting sufficient information as early as possible in a ranked list. This minimizes user reading effort while still making all available evidence accessible for sequential verification. We compare two approaches for the new ranking task: one-shot ranking and incremental ranking. We introduce a new evaluation framework, inspired by information retrieval metrics, and construct a unified benchmark by aggregating existing fact verification datasets. Extensive experiments with diverse models show that incremental ranking strategies better capture complementary evidence and that LLM-based methods outperform shallower baselines, while still facing challenges in balancing sufficiency and redundancy. Compared to evidence selection, we conduct a controlled user study and demonstrate that evidence ranking both reduces reading effort and improves verification. This work provides a foundational step toward more interpretable, efficient, and user-aligned information verification systems.

</details>


### [115] [Conversation for Non-verifiable Learning: Self-Evolving LLMs through Meta-Evaluation](https://arxiv.org/abs/2601.21464)
*Yuan Sui,Bryan Hooi*

Main category: cs.CL

TL;DR: CoNL 框架通过多智能体自博弈（self-play）统一了生成、评价和元评价过程，实现了在无监督场景下提升大语言模型解决非可验证任务的能力。


<details>
  <summary>Details</summary>
Motivation: LLM 在创造性写作、对话、伦理推理等缺乏客观标签的任务存在训练与评估难题。现有 LLM 作为自评器的方法受制于评判者自身水平，难以给出优质反馈，且评价偏差问题无法纠正，因此亟需新的元评价方法来优化评判机制本身。

Method: 提出 CoNL 框架：多个智能体基于统一策略，通过结构化对话进行方案提出、评论与修订，利用评论是否带来方案提升作为‘诊断奖励’，这样不仅优化了生成能力，同时通过自博弈方式提升评判能力，无需外部评判者或真实标签。

Result: 在五个基准上，CoNL 显著优于同类自奖励机制基线，且训练过程更加稳定。

Conclusion: CoNL 框架为无真实标签下大模型的训练和评价提供了高效且稳定的新方法，有望提升 LLM 在创造性和复杂推理类任务中的实际表现。

Abstract: Training large language models (LLMs) for non-verifiable tasks, such as creative writing, dialogue, and ethical reasoning, remains challenging due to the absence of ground-truth labels. While LLM-as-Judge approaches offer a scalable alternative to human feedback, they face a fundamental limitation: performance is constrained by the evaluator's own quality. If the judge cannot recognize good solutions, it cannot provide useful training signals, and evaluation biases (e.g., favoring verbosity over quality) remain unaddressed. This motivates meta-evaluation: the ability to evaluate and improve the evaluator itself. We introduce CoNL, a framework that unifies generation, evaluation, and meta-evaluation through multi-agent self-play. Our key insight: critique quality can be measured by whether it helps others improve their solutions. In CoNL, multiple agents sharing the same policy engage in structured conversations to propose, critique, and revise solutions. Critiques that enable solution improvements earn a diagnostic reward, creating explicit supervision for meta-evaluation and enabling joint optimization of generation and judging capabilities through self-play, without external judges or ground truth. Experiments on five benchmarks show that CoNL achieves consistent improvements over self-rewarding baselines while maintaining stable training.

</details>


### [116] [SOUP: Token-level Single-sample Mix-policy Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2601.21476)
*Lei Yang,Wei Bi,Chenxi Sun,Renren Jin,Deyi Xiong*

Main category: cs.CL

TL;DR: 提出了一种名为SOUP的新方法，通过对单个样本中不同token使用混合的on-policy和off-policy训练，缓解了语言模型微调中的探索不足与训练不稳定问题，有效提升了RL效果。


<details>
  <summary>Details</summary>
Motivation: 传统的on-policy RL方法（如GRPO）在大型语言模型后训练中，探索性不足且易陷入早期收敛，主要由于采样多样性低；而现有off-policy方法直接混合整个历史轨迹，会造成策略偏置和训练不稳定。因此需要一种能在保证训练稳定性的同时，有效利用off-policy数据、提升探索性的方法。

Method: 提出SOUP框架，在生成序列时将前缀部分采样自历史政策（off-policy），而后续部分则使用当前政策（on-policy），实现单样本内、token级别的策略混合。通过token层级的重要性比值校正off-policy带来的分布偏差，从而兼顾了探索性和训练稳定性。

Result: 实验显示SOUP在多项任务上，相较常规on-policy和主流off-policy扩展方法，均取得了更优的最终表现和更好的探索性。

Conclusion: SOUP通过精细的、单样本内的混合政策训练方式，在保证稳定性的同时显著提升了探索效率与最终性能，为大模型RL微调提供了新的有效路径。

Abstract: On-policy reinforcement learning (RL) methods widely used for language model post-training, like Group Relative Policy Optimization (GRPO), often suffer from limited exploration and early saturation due to low sampling diversity. While off-policy data can help, current approaches that mix entire trajectories cause significant policy mismatch and instability. In this work, we propose the $\textbf{S}$ingle-sample Mix-p$\textbf{O}$licy $\textbf{U}$nified $\textbf{P}$aradigm (SOUP), a framework that unifies off- and on-policy learning within individual samples at the token level. It confines off-policy influence to the prefix of a generated sequence sampled from historical policies, while the continuation is generated on-policy. Through token-level importance ratios, SOUP effectively leverages off-policy information while preserving training stability. Extensive experiments demonstrate that SOUP consistently outperforms standard on-policy training and existing off-policy extensions. Our further analysis clarifies how our fine-grained, single-sample mix-policy training can improve both exploration and final performance in LLM RL.

</details>


### [117] [DimStance: Multilingual Datasets for Dimensional Stance Analysis](https://arxiv.org/abs/2601.21483)
*Jonas Becker,Liang-Chih Yu,Shamsuddeen Hassan Muhammad,Jan Philip Wahle,Terry Ruas,Idris Abdulmumin,Lung-Hao Lee,Wen-Ni Liu,Tzu-Mi Lin,Zhe-Yu Xu,Ying-Lung Lin,Jin Wang,Maryam Ibrahim Mukhtar,Bela Gipp,Saif M. Mohammed*

Main category: cs.CL

TL;DR: 该论文提出了一种基于情感科学的立场检测新方法，将立场表达用情绪的维度特征（效价与唤醒度）进行细粒度建模，并发布了多语言带标注的数据集DimStance。


<details>
  <summary>Details</summary>
Motivation: 传统立场检测方法仅采用简单的三分类标签（支持、中立、反对），难以捕捉立场背后更细致的情感状态。现有方法在低资源语言及跨语言场景下表现有限，需要更精细的模型与数据支持。

Method: 利用情感科学框架，将立场建模为连续的效价与唤醒度维度。构建了包含五种语言、两个领域、带有效价-唤醒度标注的数据集DimStance。提出维度化立场回归任务，并对预训练模型及大模型在回归和提示设定下进行性能基线测试，同时分析了跨语言间的分布模式。

Result: 微调的大语言模型在维度立场回归任务上表现具有竞争力，但在低资源语言上的效果依然有限，基于token的生成方法表现不佳。

Conclusion: DimStance数据集为多语言、情感感知的立场检测和模型基准测试提供了基础，未来可推动相关研究在细粒度、多语言语境下取得更优表现。

Abstract: Stance detection is an established task that classifies an author's attitude toward a specific target into categories such as Favor, Neutral, and Against. Beyond categorical stance labels, we leverage a long-established affective science framework to model stance along real-valued dimensions of valence (negative-positive) and arousal (calm-active). This dimensional approach captures nuanced affective states underlying stance expressions, enabling fine-grained stance analysis. To this end, we introduce DimStance, the first dimensional stance resource with valence-arousal (VA) annotations. This resource comprises 11,746 target aspects in 7,365 texts across five languages (English, German, Chinese, Nigerian Pidgin, and Swahili) and two domains (politics and environmental protection). To facilitate the evaluation of stance VA prediction, we formulate the dimensional stance regression task, analyze cross-lingual VA patterns, and benchmark pretrained and large language models under regression and prompting settings. Results show competitive performance of fine-tuned LLM regressors, persistent challenges in low-resource languages, and limitations of token-based generation. DimStance provides a foundation for multilingual, emotion-aware, stance analysis and benchmarking.

</details>


### [118] [MURAD: A Large-Scale Multi-Domain Unified Reverse Arabic Dictionary Dataset](https://arxiv.org/abs/2601.21512)
*Serry Sibaee,Yasser Alhabashi,Nadia Sibai,Yara Farouk,Adel Ammar,Sawsan AlHalawani,Wadii Boulila*

Main category: cs.CL

TL;DR: 本文介绍了MURAD（多领域统一反向阿拉伯语词典），这是一个包含96,243组词-定义对的公开词汇数据集，旨在推动阿拉伯语自然语言处理和词汇语义研究。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语在科学、宗教和文学等领域词汇丰富，但目前缺乏大规模、覆盖广泛且精确定义的开放词汇数据集，限制了相关NLP和词典学研究的进展。

Method: 作者从权威参考文献和教育资源采集数据，使用直接文本解析、光学字符识别（OCR）和自动化重构等混合方法提取并标准化词汇和定义，并根据来源领域添加元数据，覆盖多个学科。

Result: 构建了一个包含96,243个词-定义对的数据集，涵盖语言学、伊斯兰研究、数学、物理、心理学和工程等领域，并将数据以开放形式发布。

Conclusion: MURAD数据集为阿拉伯语的计算语言学和词汇学研究提供了高质量资源，将促进反向词典建模、语义检索、教育工具开发等应用，有助于推动可复现和多领域的阿拉伯语词汇语义研究。

Abstract: Arabic is a linguistically and culturally rich language with a vast vocabulary that spans scientific, religious, and literary domains. Yet, large-scale lexical datasets linking Arabic words to precise definitions remain limited. We present MURAD (Multi-domain Unified Reverse Arabic Dictionary), an open lexical dataset with 96,243 word-definition pairs. The data come from trusted reference works and educational sources. Extraction used a hybrid pipeline integrating direct text parsing, optical character recognition, and automated reconstruction. This ensures accuracy and clarity. Each record aligns a target word with its standardized Arabic definition and metadata that identifies the source domain. The dataset covers terms from linguistics, Islamic studies, mathematics, physics, psychology, and engineering. It supports computational linguistics and lexicographic research. Applications include reverse dictionary modeling, semantic retrieval, and educational tools. By releasing this resource, we aim to advance Arabic natural language processing and promote reproducible research on Arabic lexical semantics.

</details>


### [119] [LMK > CLS: Landmark Pooling for Dense Embeddings](https://arxiv.org/abs/2601.21525)
*Meet Doshi,Aashka Trivedi,Vishwajeet Kumar,Parul Awasthy,Yulong Li,Jaydeep Sen,Radu Florian,Sachindra Joshi*

Main category: cs.CL

TL;DR: 当前主流序列编码器的池化方式（如[CLS]池化和均值池化）存在信息集中或稀释的问题。本文提出了一种新的Landmark（LMK）池化方法，通过分块插入landmark token，显著提升了长文本任务的表现，且对短文本任务效果无损。


<details>
  <summary>Details</summary>
Motivation: 现有序列池化策略如[CLS]池化和均值池化分别存在信息集中于前部、信息稀释、局部特征丢失等系统性弱点，尤其在长上下文任务下表现有限。

Method: 作者提出Landmark（LMK）池化方法，将序列分块，在每个块之间插入landmark token，最终通过对这些token嵌入做均值池化来获得句子表示。该方法有效结合了局部和全局信息。

Result: 实验表明，LMK池化在短文本检索任务上与现有方法表现相当，而在需要长上下文处理的任务上大幅提升了表现。

Conclusion: LMK池化是一种简单而有效的新策略，对短文本任务无明显性能影响，但在长文本任务中提升显著，为现有池化方法提供了实用且可扩展的替代方案。

Abstract: Representation learning is central to many downstream tasks such as search, clustering, classification, and reranking. State-of-the-art sequence encoders typically collapse a variable-length token sequence to a single vector using a pooling operator, most commonly a special [CLS] token or mean pooling over token embeddings. In this paper, we identify systematic weaknesses of these pooling strategies: [CLS] tends to concentrate information toward the initial positions of the sequence and can under-represent distributed evidence, while mean pooling can dilute salient local signals, sometimes leading to worse short-context performance. To address these issues, we introduce Landmark (LMK) pooling, which partitions a sequence into chunks, inserts landmark tokens between chunks, and forms the final representation by mean-pooling the landmark token embeddings. This simple mechanism improves long-context extrapolation without sacrificing local salient features, at the cost of introducing a small number of special tokens. We empirically demonstrate that LMK pooling matches existing methods on short-context retrieval tasks and yields substantial improvements on long-context tasks, making it a practical and scalable alternative to existing pooling methods.

</details>


### [120] [inversedMixup: Data Augmentation via Inverting Mixed Embeddings](https://arxiv.org/abs/2601.21543)
*Fanshuang Kong,Richong Zhang,Qiyu Sun,Zhijie Nie,Ting Deng,Chunming Hu*

Main category: cs.CL

TL;DR: 本文提出了一种名为inversedMixup的新型数据增强方法，结合了Mixup的可控性和大语言模型（LLM）生成的可解释性，通过三阶段训练使任务模型输出嵌入空间与LLM输入嵌入空间对齐，并最终将混合嵌入重构为可读文本，实现高质量数据增强。


<details>
  <summary>Details</summary>
Motivation: Mixup方法通过在嵌入空间线性插值实现数据增强，但生成样本不可解释；LLM基于提示生成可读文本，但对生成过程控制有限。当前尚缺乏统一兼具两者优点的增强方法。

Method: 文中提出的inversedMixup包括三阶段训练流程：一是对齐任务模型输出嵌入和LLM输入嵌入空间；二是利用对齐后的模型，将混合嵌入映射回自然语言文本，实现可控制的样本混合与可解释性；三是针对text Mixup中的流形侵入问题，提出简单有效的缓解策略。

Result: 实验表明，inversedMixup能在few-shot和完全监督设定下均提升数据增强效果，并首次实证揭示text Mixup中的流形侵入现象及其缓解方法。

Conclusion: inversedMixup实现了Mixup的可控性与LLM生成文本的可解释性结合，表现出良好的增强效果和泛化能力，是一种统一且实用的新型文本增强框架。

Abstract: Mixup generates augmented samples by linearly interpolating inputs and labels with a controllable ratio. However, since it operates in the latent embedding level, the resulting samples are not human-interpretable. In contrast, LLM-based augmentation methods produce sentences via prompts at the token level, yielding readable outputs but offering limited control over the generation process. Inspired by recent advances in LLM inversion, which reconstructs natural language from embeddings and helps bridge the gap between latent embedding space and discrete token space, we propose inversedMixup, a unified framework that combines the controllability of Mixup with the interpretability of LLM-based generation. Specifically, inversedMixup adopts a three-stage training procedure to align the output embedding space of a task-specific model with the input embedding space of an LLM. Upon successful alignment, inversedMixup can reconstruct mixed embeddings with a controllable mixing ratio into human-interpretable augmented sentences, thereby improving the augmentation performance. Additionally, inversedMixup provides the first empirical evidence of the manifold intrusion phenomenon in text Mixup and introduces a simple yet effective strategy to mitigate it. Extensive experiments demonstrate the effectiveness and generalizability of our approach in both few-shot and fully supervised scenarios.

</details>


### [121] [Note2Chat: Improving LLMs for Multi-Turn Clinical History Taking Using Medical Notes](https://arxiv.org/abs/2601.21551)
*Yang Zhou,Zhenting Sheng,Mingrui Tan,Yuting Song,Jun Zhou,Yu Heng Kwan,Lian Leng Low,Yang Bai,Yong Liu*

Main category: cs.CL

TL;DR: 提出了一种基于真实病历的笔记驱动框架，将医疗笔记转换为高质量医生-患者对话数据，通过三阶段微调提高大模型在结构化问诊和诊断场景下的表现，并显著优于GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 当前大模型在静态基准测试上表现良好，但在需要多轮推理和动态问询的临床问诊中表现不足。由于医疗对话数据稀缺且敏感，亟需新的方法充分利用现有资源提升模型能力。

Method: 1. 利用决策树引导的生成和优化流程，将真实世界医疗笔记转化为医生-患者对话；2. 采用三阶段微调（监督学习、模拟数据增强和偏好学习）训练大模型；3. 提出单轮推理范式，将问诊分解为多个单轮推理问题，提升可解释性和灵活性。

Result: 实验显示该方法能显著提升模型的临床推理能力，F1提升16.9，Top-1诊断准确率提升21.0，相对于GPT-4o具有更优的表现。

Conclusion: 笔记驱动的结构化问诊框架可有效提升临床大模型的能力，为自动化诊断和问诊提供了更高效与可解释的解决方案。

Abstract: Effective clinical history taking is a foundational yet underexplored component of clinical reasoning. While large language models (LLMs) have shown promise on static benchmarks, they often fall short in dynamic, multi-turn diagnostic settings that require iterative questioning and hypothesis refinement. To address this gap, we propose \method{}, a note-driven framework that trains LLMs to conduct structured history taking and diagnosis by learning from widely available medical notes. Instead of relying on scarce and sensitive dialogue data, we convert real-world medical notes into high-quality doctor-patient dialogues using a decision tree-guided generation and refinement pipeline. We then propose a three-stage fine-tuning strategy combining supervised learning, simulated data augmentation, and preference learning. Furthermore, we propose a novel single-turn reasoning paradigm that reframes history taking as a sequence of single-turn reasoning problems. This design enhances interpretability and enables local supervision, dynamic adaptation, and greater sample efficiency. Experimental results show that our method substantially improves clinical reasoning, achieving gains of +16.9 F1 and +21.0 Top-1 diagnostic accuracy over GPT-4o. Our code and dataset can be found at https://github.com/zhentingsheng/Note2Chat.

</details>


### [122] [ASTRA: Automated Synthesis of agentic Trajectories and Reinforcement Arenas](https://arxiv.org/abs/2601.21558)
*Xiaoyu Tian,Haotian Wang,Shuaiting Chen,Hao Zhou,Kaichi Yu,Yudian Zhang,Jade Ouyang,Junxi Yin,Jiong Chen,Baoyan Guo,Lei Zhang,Junjie Tao,Yuansheng Song,Ming Cui,Chengwei Liu*

Main category: cs.CL

TL;DR: 本文提出ASTRA框架，实现了大语言模型（LLMs）作为工具增强智能体时的全自动化训练，集成了可扩展数据合成和可验证强化学习。ASTRA无需手动干预，通过结构化合成与环境生成提升多步推理和工具使用能力，达到了同行业最优水平。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的工具增强智能体在多步决策训练中存在诸多问题，比如过度依赖人工干预、仿真环境不可验证、训练方法单一（只能用SFT或RL）、多轮决策稳定性差。本研究旨在通过自动化和新颖数据合成机制，解决上述挑战，提升工具智能体的实际效用和泛化能力。

Method: ASTRA包含两个主要部分：一，利用工具调用图的静态结构，自动合成多样化且结构化的学习轨迹，从而提升智能体的工具泛用能力；二，通过环境合成框架，将问题-答案拆解轨迹转换为独立、可执行、可验证的环境，便于进行确定性多轮强化学习。最终，提出融合SFT与在线RL的统一训练方法，用轨迹级奖励在任务完成度与交互效率间取得平衡。

Result: 在多个工具使用智能体基准任务上，基于ASTRA训练的大语言模型性能达到业界新高，并在保持推理能力的前提下，接近闭源系统的表现。ASTRA方法具有良好的扩展性和泛化能力。

Conclusion: ASTRA成功实现了面向工具增强LLM智能体的全自动化高效训练，突破了现有方法的多项局限，推动了多工具、多步骤智能体研究的发展，同时开源了完整流程与模型，有利于学界和工业界的进一步研究。

Abstract: Large language models (LLMs) are increasingly used as tool-augmented agents for multi-step decision making, yet training robust tool-using agents remains challenging. Existing methods still require manual intervention, depend on non-verifiable simulated environments, rely exclusively on either supervised fine-tuning (SFT) or reinforcement learning (RL), and struggle with stable long-horizon, multi-turn learning. To address these challenges, we introduce ASTRA, a fully automated end-to-end framework for training tool-augmented language model agents via scalable data synthesis and verifiable reinforcement learning. ASTRA integrates two complementary components. First, a pipeline that leverages the static topology of tool-call graphs synthesizes diverse, structurally grounded trajectories, instilling broad and transferable tool-use competence. Second, an environment synthesis framework that captures the rich, compositional topology of human semantic reasoning converts decomposed question-answer traces into independent, code-executable, and rule-verifiable environments, enabling deterministic multi-turn RL. Based on this method, we develop a unified training methodology that integrates SFT with online RL using trajectory-level rewards to balance task completion and interaction efficiency. Experiments on multiple agentic tool-use benchmarks demonstrate that ASTRA-trained models achieve state-of-the-art performance at comparable scales, approaching closed-source systems while preserving core reasoning ability. We release the full pipelines, environments, and trained models at https://github.com/LianjiaTech/astra.

</details>


### [123] [KromHC: Manifold-Constrained Hyper-Connections with Kronecker-Product Residual Matrices](https://arxiv.org/abs/2601.21579)
*Wuyang Zhou,Yuxuan Gu,Giorgos Iacovides,Danilo Mandic*

Main category: cs.CL

TL;DR: 该论文提出了一种新的方法KromHC，用于在神经网络中高效、稳定地实现Hyper-Connections，既保证了数学约束又降低了参数复杂度，实验结果优于或媲美现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有Hyper-Connections技术在神经网络中的应用存在训练不稳定和可扩展性差的难题。此前改进的mHC和mHC-lite分别面临收敛不精确、参数量巨大等问题。因此，迫切需要一种结构，既保证理论性质，又实际可扩展。

Method: KromHC方法通过Kronecker积小型双随机矩阵来参数化mHC中的残差矩阵，避免了大量参数和计算资源的消耗，并利用流形约束保证残差矩阵精确双随机。

Result: 实验表明，KromHC在节省大量参数的同时，性能与或优于现有最先进的mHC系列模型。

Conclusion: KromHC兼顾了精确的数学约束和较低的参数复杂度，有效克服了以往mHC、mHC-lite存在的问题，为神经网络中的Hyper-Connections提供了更实用的方案。

Abstract: The success of Hyper-Connections (HC) in neural networks (NN) has also highlighted issues related to its training instability and restricted scalability. The Manifold-Constrained Hyper-Connections (mHC) mitigate these challenges by projecting the residual connection space onto a Birkhoff polytope, however, it faces two issues: 1) its iterative Sinkhorn-Knopp (SK) algorithm does not always yield exact doubly stochastic residual matrices; 2) mHC incurs a prohibitive $\mathcal{O}(n^3C)$ parameter complexity with $n$ as the width of the residual stream and $C$ as the feature dimension. The recently proposed mHC-lite reparametrizes the residual matrix via the Birkhoff-von-Neumann theorem to guarantee double stochasticity, but also faces a factorial explosion in its parameter complexity, $\mathcal{O} \left( nC \cdot n! \right)$. To address both challenges, we propose \textbf{KromHC}, which uses the \underline{Kro}necker products of smaller doubly stochastic matrices to parametrize the residual matrix in \underline{mHC}. By enforcing manifold constraints across the factor residual matrices along each mode of the tensorized residual stream, KromHC guarantees exact double stochasticity of the residual matrices while reducing parameter complexity to $\mathcal{O}(n^2C)$. Comprehensive experiments demonstrate that KromHC matches or even outperforms state-of-the-art (SOTA) mHC variants, while requiring significantly fewer trainable parameters. The code is available at \texttt{https://github.com/wz1119/KromHC}.

</details>


### [124] [Language Models as Artificial Learners: Investigating Crosslinguistic Influence](https://arxiv.org/abs/2601.21587)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 该论文利用语言模型（LMs）作为受控的统计学习者，系统化地模拟双语者跨语言影响（CLI）并探索其机制。


<details>
  <summary>Details</summary>
Motivation: CLI在双语研究中至关重要，但以往对其的实证研究结果常常相互矛盾，主要由于实验变量复杂多变。作者希望通过受控的人工模型排除这些不确定性，更准确地揭示CLI的本质驱动因素。

Method: 作者使用语言模型，通过调整L1主导性和L2熟练度（用L2接触年龄模拟），以及预训练L1与L2句法距离不同的语言，系统研究这些变量对CLI的影响。结合跨语句激活技术，分析激活L1结构如何影响L2加工。

Result: 实验结果证实，语言主导性和熟练度是CLI的重要预测因子；并发现对语法结构的启动是双向的，但对不语法结构的启动受到语言主导性的影响。此外，证据显示L2加工时L1会被共同激活，并影响L2相关神经机制。

Conclusion: LMs可作为计算框架解释和拓展人类CLI理论，为双语研究和认知神经科学提供理论和方法论的新工具。

Abstract: Despite the centrality of crosslinguistic influence (CLI) to bilingualism research, human studies often yield conflicting results due to inherent experimental variance. We address these inconsistencies by using language models (LMs) as controlled statistical learners to systematically simulate CLI and isolate its underlying drivers. Specifically, we study the effect of varying the L1 language dominance and the L2 language proficiency, which we manipulate by controlling the L2 age of exposure -- defined as the training step at which the L2 is introduced. Furthermore, we investigate the impact of pretraining on L1 languages with varying syntactic distance from the L2. Using cross-linguistic priming, we analyze how activating L1 structures impacts L2 processing. Our results align with evidence from psycholinguistic studies, confirming that language dominance and proficiency are strong predictors of CLI. We further find that while priming of grammatical structures is bidirectional, the priming of ungrammatical structures is sensitive to language dominance. Finally, we provide mechanistic evidence of CLI in LMs, demonstrating that the L1 is co-activated during L2 processing and directly influences the neural circuitry recruited for the L2. More broadly, our work demonstrates that LMs can serve as a computational framework to inform theories of human CLI.

</details>


### [125] [ILRR: Inference-Time Steering Method for Masked Diffusion Language Models](https://arxiv.org/abs/2601.21647)
*Eden Avrahami,Eliya Nachmani*

Main category: cs.CL

TL;DR: 该论文提出了一种新的对离散扩散语言模型（DLM）进行推理控制的方法，将参考序列的特征迁移到生成文本，提升了属性可控性和生成质量。


<details>
  <summary>Details</summary>
Motivation: 目前非自回归文本生成的DLM模型在推理时控制生成内容（如情感等属性）的机制尚不完善，现有方法在效率和效果上仍有不足。

Method: 作者提出Iterative Latent Representation Refinement（ILRR）, 在去噪过程中，通过不断调整、对齐生成序列与参考序列的内部激活，实现属性引导，并可调控控制强度。还提出空间调制引导（Spatially Modulated Steering），支持用较短参考引导长文本生成。

Result: ILRR在LLaDA和MDLM架构上，通过每步增加一次前向推理，带来10%-60%的属性准确率提升，计算开销较低并保持高生成质量。

Conclusion: ILRR为DLM带来了高效、灵活的属性引导能力，在不显著增加计算成本的情况下大幅提升了生成文本的属性控制性和质量。

Abstract: Discrete Diffusion Language Models (DLMs) offer a promising non-autoregressive alternative for text generation, yet effective mechanisms for inference-time control remain relatively underexplored. Existing approaches include sampling-level guidance procedures or trajectory optimization mechanisms. In this work, we introduce Iterative Latent Representation Refinement (ILRR), a learning-free framework for steering DLMs using a single reference sequence. ILRR guides generation by dynamically aligning the internal activations of the generated sequence with those of a given reference throughout the denoising process. This approach captures and transfers high-level semantic properties, with a tunable steering scale enabling flexible control over attributes such as sentiment. We further introduce Spatially Modulated Steering, an extension that enables steering long texts using shorter references by regulating guidance intensity across the sequence. Empirically, we demonstrate that ILRR achieves effective attribute steering on LLaDA and MDLM architectures with a minor computational overhead, requiring only one additional parallel forward pass per denoising step. Under the same compute budget, ILRR improves attribute accuracy over comparable baselines by 10$\%$ to 60$\%$ points, while maintaining high generation quality.

</details>


### [126] [AdaptBPE: From General Purpose to Specialized Tokenizers](https://arxiv.org/abs/2601.21665)
*Vijini Liyanage,François Yvon*

Main category: cs.CL

TL;DR: 本文提出了一种在BPE分词器基础上的后训练自适应策略，通过优化词汇表提升特定领域或语言任务下的模型性能和效率。


<details>
  <summary>Details</summary>
Motivation: 传统BPE等分词方法采用通用性分词器，但在特定领域或语言中会引入低效分词，影响模型性能与推理效率。

Method: 提出了一种后训练适配算法，利用适配语料库的词频信息，替换原有低效token，从而在固定词表大小下优化编码效率，实现类似“词表微调”的轻量级适应。

Result: 在多语言生成与分类任务中，实验结果表明该方法在相同词表规模下能显著提升对测试语料的编码压缩率，优于传统基线方法。

Conclusion: 该方法为BPE分词器带来了灵活、轻量的自适应机制，允许对特定领域或任务进行有效的token优化，有助于提升LLM在不同场景下的表现。

Abstract: Subword tokenization methods, such as Byte-Pair Encoding (BPE), significantly impact the performance and efficiency of large language models (LLMs). The standard approach involves training a general-purpose tokenizer that uniformly processes all textual data during both training and inference. However, the use of a generic set of tokens can incur inefficiencies when applying the model to specific domains or languages. To address this limitation, we propose a post-training adaptation strategy that selectively replaces low-utility tokens with more relevant ones based on their frequency in an adaptation corpus. Our algorithm identifies the token inventory that most effectively encodes the adaptation corpus for a given target vocabulary size. Extensive experiments on generation and classification tasks across multiple languages demonstrate that our adapted tokenizers compress test corpora more effectively than baselines using the same vocabulary size. This method serves as a lightweight adaptation mechanism, akin to a vocabulary fine-tuning process, enabling optimized tokenization for specific domains or tasks. Our code and data are available at https://github.com/vijini/Adapt-BPE.git.

</details>


### [127] [Scale-Dependent Semantic Dynamics Revealed by Allan Deviation](https://arxiv.org/abs/2601.21678)
*Debayan Dasgupta*

Main category: cs.CL

TL;DR: 本文将文本的语义进展视为高维状态空间中的随机轨迹，采用阿兰偏差（Allan deviation）分析文本语义的动态稳定性，揭示了创造性文学与技术文本、以及人类文本与大模型生成文本在语义动态中的差异。


<details>
  <summary>Details</summary>
Motivation: 语言在表达中表现为语义状态的连续变化，但这种变化的内在动力学机制仍不清楚。作者希望用物理学工具量化和对比不同文本、不同文本生成体（人类与大模型）的语义动态特性。

Method: 将有序的句子嵌入表示为位移信号，在高维空间中描绘文本的“语义轨迹”，用精密计量学中的阿兰偏差工具，分析这些轨迹的稳定性和动态模式，比较不同文本和生成体的特征。

Result: 发现文本存在两种语义动态模式：短时尺度下表现为幂律标度，可区分创造性文学与技术文本；长时尺度下所有文本会出现稳定性受限的“噪声底”；大语言模型在局部动态上拟合人类文本但其“语义稳定性范围”系统性缩短。

Conclusion: 语义连贯性可被量化为可测量的物理属性，该方法为区分人类认知文本与算法生成文本提供了新框架。

Abstract: While language progresses through a sequence of semantic states, the underlying dynamics of this progression remain elusive. Here, we treat the semantic progression of written text as a stochastic trajectory in a high-dimensional state space. We utilize Allan deviation, a tool from precision metrology, to analyze the stability of meaning by treating ordered sentence embeddings as a displacement signal. Our analysis reveals two distinct dynamical regimes: short-time power-law scaling, which differentiates creative literature from technical texts, and a long-time crossover to a stability-limited noise floor. We find that while large language models successfully mimic the local scaling statistics of human text, they exhibit a systematic reduction in their stability horizon. These results establish semantic coherence as a measurable physical property, offering a framework to differentiate the nuanced dynamics of human cognition from the patterns generated by algorithmic models.

</details>


### [128] [FIT: Defying Catastrophic Forgetting in Continual LLM Unlearning](https://arxiv.org/abs/2601.21682)
*Xiaoyu Xu,Minxin Du,Kun Fang,Zi Liang,Yaxin Xiao,Zhicong Huang,Cheng Hong,Qingqing Ye,Haibo Hu*

Main category: cs.CL

TL;DR: 本文提出了一种名为FIT的持续卸载框架，能在面对大量数据删除请求时，有效平衡遗忘效果与模型实用性，提升大语言模型在隐私、安全等领域的应用价值。


<details>
  <summary>Details</summary>
Motivation: 大语言模型易引发隐私、版权和有害内容等风险，现实中删除请求频繁且持续，现有卸载方法难以应对大量和连续的数据删除请求，容易导致模型性能下降和遗忘失控。急需一种能持续、高效处理删除请求并保持模型稳定的解决方案。

Method: FIT（Filtering、Importance-aware updates、Targeted layer attribution）框架，通过数据过滤、重要性感知更新与目标层归因，有效处理持续、多量数据删除。配合提出的PCH基准和F.D./R.U.评估指标，系统测试忘记和保留水平。

Result: 对四种开源LLM和数百删除请求的大量实验显示，FIT在遗忘效果与实用性之间达到了最佳平衡，性能超越现有方法，且对再学习和量化恢复攻击有较强抵抗能力。

Conclusion: FIT提供了一种实用、高效且更安全的持续卸载解决方案，平衡了遗忘和实用目标，并通过新基准和评估标准，推动了LLM安全可控性的前沿发展。

Abstract: Large language models (LLMs) demonstrate impressive capabilities across diverse tasks but raise concerns about privacy, copyright, and harmful materials. Existing LLM unlearning methods rarely consider the continual and high-volume nature of real-world deletion requests, which can cause utility degradation and catastrophic forgetting as requests accumulate. To address this challenge, we introduce \fit, a framework for continual unlearning that handles large numbers of deletion requests while maintaining robustness against both catastrophic forgetting and post-unlearning recovery. \fit mitigates degradation through rigorous data \underline{F}iltering, \underline{I}mportance-aware updates, and \underline{T}argeted layer attribution, enabling stable performance across long sequences of unlearning operations and achieving a favorable balance between forgetting effectiveness and utility retention. To support realistic evaluation, we present \textbf{PCH}, a benchmark covering \textbf{P}ersonal information, \textbf{C}opyright, and \textbf{H}armful content in sequential deletion scenarios, along with two symmetric metrics, Forget Degree (F.D.) and Retain Utility (R.U.), which jointly assess forgetting quality and utility preservation. Extensive experiments on four open-source LLMs with hundreds of deletion requests show that \fit achieves the strongest trade-off between F.D. and R.U., surpasses existing methods on MMLU, CommonsenseQA, and GSM8K, and remains resistant against both relearning and quantization recovery attacks.

</details>


### [129] [Do Not Waste Your Rollouts: Recycling Search Experience for Efficient Test-Time Scaling](https://arxiv.org/abs/2601.21684)
*Xinglin Wang,Jiayi Shi,Shaoxiong Feng,Peiwen Yuan,Yiwei Li,Yueqi Zhang,Chuyi Tan,Ji Zhang,Boyuan Pan,Yao Hu,Kan Li*

Main category: cs.CL

TL;DR: 本文提出了一种在大语言模型推理过程中回收并利用中间推理经验的新方法，显著减少了推理冗余并提升了计算效率。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在推理时常采用多次独立采样策略，每次推理（rollout）产生的中间结果在试验后被丢弃，导致大量计算资源浪费在重复结论推导和无效路径探索上。

Method: 提出了回收搜索经验（RSE）的方法，在推理过程中将原始推理轨迹汇集、提炼进共享经验库。正向回收将有用的中间结论用于后续推理中避免重复推导，负向回收则利用失败模式直接剪枝无效路径，实现自我引导的推理流程，无需额外训练。

Result: 理论上分析了RSE方法带来的效率提升，并且在HMMT24、HMMT25、IMO-Bench与HLE等复杂推理任务上进行了大量实验验证，RSE在相同计算成本下均超越了强力基线，取得了行业领先的推理扩展效率。

Conclusion: RSE方法可以有效回收并利用推理过程中的中间经验，减少推理冗余，提高大模型推理扩展效率，并为解决复杂推理任务提供了更优策略。

Abstract: Test-Time Scaling enhances the reasoning capabilities of Large Language Models by allocating additional inference compute to broaden the exploration of the solution space. However, existing search strategies typically treat rollouts as disposable samples, where valuable intermediate insights are effectively discarded after each trial. This systemic memorylessness leads to massive computational redundancy, as models repeatedly re-derive discovered conclusions and revisit known dead ends across extensive attempts. To bridge this gap, we propose \textbf{Recycling Search Experience (RSE)}, a self-guided, training-free strategy that turns test-time search from a series of isolated trials into a cumulative process. By actively distilling raw trajectories into a shared experience bank, RSE enables positive recycling of intermediate conclusions to shortcut redundant derivations and negative recycling of failure patterns to prune encountered dead ends. Theoretically, we provide an analysis that formalizes the efficiency gains of RSE, validating its advantage over independent sampling in solving complex reasoning tasks. Empirically, extensive experiments on HMMT24, HMMT25, IMO-Bench, and HLE show that RSE consistently outperforms strong baselines with comparable computational cost, achieving state-of-the-art scaling efficiency.

</details>


### [130] [Can David Beat Goliath? On Multi-Hop Reasoning with Resource-Constrained Agents](https://arxiv.org/abs/2601.21699)
*Hojae Han,Heeyun Jung,Jongyoon Kim,Seung-won Hwang*

Main category: cs.CL

TL;DR: 本文提出一种高效的强化学习框架 DAVID-GRPO，使得小型语言模型在有限算力下也能实现高质量多步推理，并在多个多跳问答基准任务上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 强化学习在多轮推理中虽取得成功，但大多依赖于大量算力和高精度的模型。现实中资源受限，小模型面临训练不稳定和准确率下降的问题。论文旨在打破这一瓶颈，让小模型在低成本下也能有高表现。

Method: 提出了DAVID-GRPO框架：1）通过少量监督稳定初期训练，2）用证据召回机制进行检索奖励分配，3）通过重采近似正确但被截断的轨迹改善探索效率。

Result: 在只用4张3090显卡、最大1.5B参数的小模型上，DAVID-GRPO在六个多跳QA任务中一贯超越面向大模型的现有RL方法。

Conclusion: 选用合适的归纳偏置后，小模型在受限资源下同样可以兼具低训练成本和高推理准确性。

Abstract: While reinforcement learning (RL) has empowered multi-turn reasoning agents with retrieval and tools, existing successes largely depend on extensive on-policy rollouts in high-cost, high-accuracy regimes. Under realistic resource constraints that cannot support large models or dense explorations, however, small language model agents fall into a low-cost, low-accuracy regime, where limited rollout budgets lead to sparse exploration, sparse credit assignment, and unstable training. In this work, we challenge this trade-off and show that small language models can achieve strong multi-hop reasoning under resource constraints. We introduce DAVID-GRPO, a budget-efficient RL framework that (i) stabilizes early learning with minimal supervision, (ii) assigns retrieval credit based on evidence recall, and (iii) improves exploration by resampling truncated near-miss trajectories. Evaluated on agents up to 1.5B parameters trained on only four RTX 3090 GPUs, DAVID-GRPO consistently outperforms prior RL methods designed for large-scale settings on six multi-hop QA benchmarks. These results show that with the right inductive biases, small agents can achieve low training cost with high accuracy.

</details>


### [131] [Toward Culturally Aligned LLMs through Ontology-Guided Multi-Agent Reasoning](https://arxiv.org/abs/2601.21700)
*Wonduk Seo,Wonseok Choi,Junseo Koh,Juhyeon Lee,Hyunjin An,Minhyeong Yu,Jian Park,Qingshan Zhou,Seunghyun Lee,Yi Bu*

Main category: cs.CL

TL;DR: 本文提出OG-MAR框架，通过多智能体推理和本体指导提升大语言模型（LLM）在文化敏感决策场景下的一致性和可解释性，实验显示该方法在多个基线之上进一步提升文化对齐度和推理透明性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在处理涉及文化和价值观问题时，存在预训练数据偏倚和价值表示结构不完善等问题，导致输出偏差和解释性差。

Method: 该方法以WVS调查数据为基础，构建全球文化价值本体，通过本体引导推理生成具有人口学特征的多‘价值-角色’代理，并由判决代理综合各方意见，保证本体一致性和人口学贴合。

Result: 在四种主流LLM骨干网络及区域社会调查数据上，OG-MAR在文化对齐度、鲁棒性与推理透明性等方面优于现有方法。

Conclusion: OG-MAR能有效提升模型在文化敏感任务中的一致性、解释性和对齐度，为价值导向的LLM推理提供了新途径。

Abstract: Large Language Models (LLMs) increasingly support culturally sensitive decision making, yet often exhibit misalignment due to skewed pretraining data and the absence of structured value representations. Existing methods can steer outputs, but often lack demographic grounding and treat values as independent, unstructured signals, reducing consistency and interpretability. We propose OG-MAR, an Ontology-Guided Multi-Agent Reasoning framework. OG-MAR summarizes respondent-specific values from the World Values Survey (WVS) and constructs a global cultural ontology by eliciting relations over a fixed taxonomy via competency questions. At inference time, it retrieves ontology-consistent relations and demographically similar profiles to instantiate multiple value-persona agents, whose outputs are synthesized by a judgment agent that enforces ontology consistency and demographic proximity. Experiments on regional social-survey benchmarks across four LLM backbones show that OG-MAR improves cultural alignment and robustness over competitive baselines, while producing more transparent reasoning traces.

</details>


### [132] [Why Attention Patterns Exist: A Unifying Temporal Perspective Analysis](https://arxiv.org/abs/2601.21709)
*Qingyue Yang,Jie Wang,Xing Li,Yinqi Bai,Xialiang Tong,Huiling Zhen,Jianye Hao,Mingxuan Yuan,Bin Li*

Main category: cs.CL

TL;DR: 本文提出了TAPPA（Temporal Attention Pattern Predictability Analysis）框架，系统解释了大语言模型（LLM）中多种注意力模式，将其划分为可预测和不可预测类别，并证明该分析有助于推理加速、KV缓存压缩和模型剪枝，实验结果均优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有关于LLM注意力模式的研究较为零散，未能给出统一的解释框架。不同注意力模式（如retrieval head、sink head、对角痕迹等）的成因和规律性尚未完全理解，阻碍了有效利用注意力模式提升推理效率和模型优化。

Method: 作者提出TAPPA框架，从时间连续性的角度出发，利用数学公式分析LLM注意力的多样模式，将其分为具规律性的可预测模式和随机的不可预测模式，并通过query的时序自相似性解释这一区分。针对典型可预测模式，深入分析了query、key以及RoPE的联合作用。

Result: 基于TAPPA分析，提出了一种简单的度量指标，应用于KV缓存压缩和LLM剪枝任务中，在这些任务上的表现均明显优于传统基线方法。

Conclusion: TAPPA为理解和利用LLM注意力模式提供了统一数学解释和有效实践工具，有助于模型性能优化与推理加速，对后续相关研究具有较强指导意义。

Abstract: Attention patterns play a crucial role in both training and inference of large language models (LLMs). Prior works have identified individual patterns such as retrieval heads, sink heads, and diagonal traces, yet these observations remain fragmented and lack a unifying explanation. To bridge this gap, we introduce \textbf{Temporal Attention Pattern Predictability Analysis (TAPPA), a unifying framework that explains diverse attention patterns by analyzing their underlying mathematical formulations} from a temporally continuous perspective. TAPPA both deepens the understanding of attention behavior and guides inference acceleration approaches. Specifically, TAPPA characterizes attention patterns as predictable patterns with clear regularities and unpredictable patterns that appear effectively random. Our analysis further reveals that this distinction can be explained by the degree of query self-similarity along the temporal dimension. Focusing on the predictable patterns, we further provide a detailed mathematical analysis of three representative cases through the joint effect of queries, keys, and Rotary Positional Embeddings (RoPE). We validate TAPPA by applying its insights to KV cache compression and LLM pruning tasks. Across these tasks, a simple metric motivated by TAPPA consistently improves performance over baseline methods. The code is available at https://github.com/MIRALab-USTC/LLM-TAPPA.

</details>


### [133] [TACLer: Tailored Curriculum Reinforcement Learning for Efficient Reasoning](https://arxiv.org/abs/2601.21711)
*Huiyuan Lai,Malvina Nissim*

Main category: cs.CL

TL;DR: 本文提出了一种提升大语言模型（LLMs）推理效率和准确性的RL课程学习框架TACLer，通过动态调整推理链条长度，实现算力和效果的双提升。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs利用长链式思考（CoT）在复杂推理任务上表现优异，但长CoT依赖大规模RL训练，且易造成过度思考和冗余步骤，导致计算资源浪费和推理效率降低。因此，需寻求既保证性能又提升效率的新方法。

Method: 提出TACLer框架，包含两个核心组件：（1）定制化课程学习，根据模型当前掌握情况、逐步增强数据复杂度，实现多阶段训练；（2）混合“思考/不思考”推理范式，灵活切换是否执行链式推理模式，以平衡准确率和推理速度。

Result: 实验结果显示TACLer在学习和推理上具双重优势：（1）计算成本降低，训练计算量减少50%以上，推理时token消耗比基础模型降低42%；（2）在四个复杂数学数据集上，准确率较基础模型提升9%以上，并持续优于当前主流的“Nothinking”和“Thinking”基线模型。

Conclusion: TACLer有效解决了LLMs长链推理带来的效率和资源浪费问题，在保障甚至提升推理准确性的同时大幅减少计算和推理开销，展现出良好的应用前景。

Abstract: Large Language Models (LLMs) have shown remarkable performance on complex reasoning tasks, especially when equipped with long chain-of-thought (CoT) reasoning. However, eliciting long CoT typically requires large-scale reinforcement learning (RL) training, while often leading to overthinking with redundant intermediate steps. To improve learning and reasoning efficiency, while preserving or even enhancing performance, we propose TACLer, a model-tailored curriculum reinforcement learning framework that gradually increases the complexity of the data based on the model's proficiency in multi-stage RL training. TACLer features two core components: (i) tailored curriculum learning that determines what knowledge the model lacks and needs to learn in progressive stages; (ii) a hybrid Thinking/NoThinking reasoning paradigm that balances accuracy and efficiency by enabling or disabling the Thinking mode. Our experiments show that TACLer yields a twofold advantage in learning and reasoning: (i) it reduces computational cost, cutting training compute by over 50% compared to long thinking models and reducing inference token usage by over 42% relative to the base model; and (ii) it improves accuracy by over 9% on the base model, consistently outperforming state-of-the-art Nothinking and Thinking baselines across four math datasets with complex problems.

</details>


### [134] [Enhancing Language Models for Robust Greenwashing Detection](https://arxiv.org/abs/2601.21722)
*Neil Heinrich Braun,Keane Ong,Rui Mao,Erik Cambria,Gianmarco Mengaldo*

Main category: cs.CL

TL;DR: 本文提出了一种参数高效的框架，将对比学习与序排序目标结合，提升LLM在ESG可持续发展报告分析中的健壮性，能更好地区分具体行动与模糊声明。


<details>
  <summary>Details</summary>
Motivation: 现有NLP模型在识别绿洗和模糊声明时效果较差，过于依赖表层模式，导致泛化能力不足，因此需要更鲁棒的方法来提高可持续报告评估的可靠性。

Method: 该方法通过结构化LLM的潜在空间，结合对比学习和序列排序目标，捕捉声明的具体与模糊差异；同时引入门控特征调制过滤信息噪声，以及MetaGradNorm平衡多目标优化过程。

Result: 实验表明，在跨类别场景下该方法相较标准基线表现出更强的鲁棒性，并揭示了表征僵化与泛化能力之间的权衡关系。

Conclusion: 所提方法提升了应对ESG报告中绿洗和模糊声明的能力，为相关NLP任务带来更可靠的自动化支持。

Abstract: Sustainability reports are critical for ESG assessment, yet greenwashing and vague claims often undermine their reliability. Existing NLP models lack robustness to these practices, typically relying on surface-level patterns that generalize poorly. We propose a parameter-efficient framework that structures LLM latent spaces by combining contrastive learning with an ordinal ranking objective to capture graded distinctions between concrete actions and ambiguous claims. Our approach incorporates gated feature modulation to filter disclosure noise and utilizes MetaGradNorm to stabilize multi-objective optimization. Experiments in cross-category settings demonstrate superior robustness over standard baselines while revealing a trade-off between representational rigidity and generalization.

</details>


### [135] [Procedural Pretraining: Warming Up Language Models with Abstract Data](https://arxiv.org/abs/2601.21725)
*Liangze Jiang,Zachary Shinnick,Anton van den Hengel,Hemanth Saratchandran,Damien Teney*

Main category: cs.CL

TL;DR: 本文提出在语言模型预训练阶段，先让模型暴露于抽象的结构化数据（如形式语言生成的过程性数据），结果显著提升算法能力和语义学习效率。实验显示，即便只用0.1%的过程性数据预训练，也显著优于直接用自然语言或代码、数学语料，且能显著降低后续数据需求量。进一步分析揭示，过程性预训练能为注意力和MLP层注入有益结构。


<details>
  <summary>Details</summary>
Motivation: 现有主流预训练范式直接基于大规模网络语料，但人类通常先学抽象的逻辑、数学后再学复杂推理。因此，动机是探索让大模型先学结构化、过程性数据，是否能更有效掌握底层算法和语义能力，并加速后续自然语料训练。

Method: 作者采用人工生成的形式语言（如Dyck序列等）和简单算法生成的过程性数据来预训练语言模型，并对比标准自然语言、代码、数学数据的直接预训练效果。进一步测试上下文记忆等算法能力提升情况，并研究显著改变量表现在模型结构中的具体位置。

Result: 用极少量（0.1%）过程性数据前置预训练可使模型在“针 haystack”、“上下文记忆”等任务上表现大幅提升（如准确率由10%跃至98%），整体预训练收敛所需样本量显著降低（原本55~86%即可达到相同损失）。机制分析发现，注意力层与MLP层均受益于此类预训练，且进一步组合多种过程数据仍具潜力。

Conclusion: 过程性预训练是一种简便但效果显著的提升和加速大模型训练途径。该方法为知识获取与推理能力在LLM中的相互解耦提供了可行思路，对今后模型预训练范式有启示意义。

Abstract: Pretraining directly on web-scale corpora is the de facto paradigm for building language models. We study an alternative setting where the model is initially exposed to abstract structured data, as a means to ease the subsequent acquisition of rich semantic knowledge, much like humans learn simple logic and mathematics before higher reasoning. We specifically focus on procedural data, generated by formal languages and other simple algorithms, as such abstract data.
  We first diagnose the algorithmic skills that different forms of procedural data can improve, often significantly. For example, on context recall (Needle-in-a-haystack), the accuracy jumps from 10 to 98% when pretraining on Dyck sequences (balanced brackets). Second, we study how these gains are reflected in pretraining larger models (up to 1.3B). We find that front-loading as little as 0.1% procedural data significantly outperforms standard pretraining on natural language, code, and informal mathematics (C4, CodeParrot, and DeepMind-Math datasets). Notably, this procedural pretraining enables the models to reach the same loss value with only 55, 67, 86% of the original data. Third, we explore the mechanisms behind and find that procedural pretraining instils non-trivial structure in both attention and MLP layers. The former is particularly important for structured domains (e.g. code), and the latter for language. Finally, we lay a path for combining multiple forms of procedural data. Our results show that procedural pretraining is a simple, lightweight means to improving performance and accelerating language model pretraining, ultimately suggesting the promise of disentangling knowledge acquisition from reasoning in LLMs.

</details>


### [136] [CE-GOCD: Central Entity-Guided Graph Optimization for Community Detection to Augment LLM Scientific Question Answering](https://arxiv.org/abs/2601.21733)
*Jiayin Lan,Jiaqi Li,Baoxin Wang,Ming Liu,Dayong Wu,Shijin Wang,Bing Qin,Guoping Hu*

Main category: cs.CL

TL;DR: 提出了一种新的基于知识图谱的社区检测方法（CE-GOCD），提升了大语言模型在科学文献问答中的检索能力和回答质量。


<details>
  <summary>Details</summary>
Motivation: 现有的方法大多只用孤立的文本片段，忽略了论文之间深层次的语义联系，限制了大模型对科学文献的理解及答案的全面性和针对性。

Method: 提出Central Entity-Guided Graph Optimization for Community Detection（CE-GOCD）框架：1）以论文标题为核心实体进行子图检索；2）通过子图剪枝和补全强化隐含语义发现；3）应用社区检测提取主题一致的论文群体。

Result: 在三个NLP领域文献问答数据集上实验，CE-GOCD优于其他基于检索增强的基线方法，显示了其有效性。

Conclusion: CE-GOCD能够更好地建模和利用学术知识图谱中的语义子结构，提升了LLM科学问答的表现。

Abstract: Large Language Models (LLMs) are increasingly used for question answering over scientific research papers. Existing retrieval augmentation methods often rely on isolated text chunks or concepts, but overlook deeper semantic connections between papers. This impairs the LLM's comprehension of scientific literature, hindering the comprehensiveness and specificity of its responses. To address this, we propose Central Entity-Guided Graph Optimization for Community Detection (CE-GOCD), a method that augments LLMs' scientific question answering by explicitly modeling and leveraging semantic substructures within academic knowledge graphs. Our approach operates by: (1) leveraging paper titles as central entities for targeted subgraph retrieval, (2) enhancing implicit semantic discovery via subgraph pruning and completion, and (3) applying community detection to distill coherent paper groups with shared themes. We evaluated the proposed method on three NLP literature-based question-answering datasets, and the results demonstrate its superiority over other retrieval-augmented baseline approaches, confirming the effectiveness of our framework.

</details>


### [137] [Temporal Guidance for Large Language Models](https://arxiv.org/abs/2601.21744)
*Hong-Kai Zheng,Piji Li*

Main category: cs.CL

TL;DR: 本文提出了一种新型的自对比性解码方法TeGu，通过时间维度进行对比性指导，在提升大语言模型生成质量的同时，极大降低了额外的计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 现有的对比性解码方法虽然有效提升了生成质量，但通常需要额外辅助模型或在层间对比，这对小模型不稳定且计算开销大。因此，亟需一种低成本、稳定、适用于各规模模型的对比性解码方法。

Method: 基于LLM有局部偏好的观察，作者提出了时间维度上的对比性指导（TeGu），利用多token预测（MTP）生成较弱的自对比预测，并设计了轻量级的条件MTP投影器（cMTPP），无需多个独立网络即可实现自对比预测标准化。

Result: TeGu在多个模型系列和评测基准上，实现了显著的性能提升，并且内存和计算资源消耗极低。

Conclusion: TeGu方法有效提升了大语言模型生成质量，具备良好的资源效率和适用性，为对比性解码方法带来了新的方向。

Abstract: Contrastive Decoding (CD) enhances the generation quality of large language models (LLMs) but incurs significant additional computational overhead due to the need for an auxiliary model. Existing internal self-contrastive decoding methods, such as Decoding by Contrasting Layers (DoLa), focus on discrepancies across different layers, which are notably unstable on small-scale models. In this work, based on the observation that LLMs exhibit local preferences, we propose a novel contrastive guidance strategy along the temporal dimension, namely Temporal Guidance (TeGu). Our method ingeniously leverages Multi-Token Prediction (MTP) to construct weaker amateur predictions for model self-contrast. To standardize the implementation of this mechanism, we further introduce a lightweight Conditional MTP Projector (cMTPP), which avoids maintaining multiple independent networks as required by other MTP modules. Across various model series and benchmarks, TeGu achieves significant performance improvements while maintaining low additional memory consumption and computational overhead.

</details>


### [138] [CoFrGeNet: Continued Fraction Architectures for Language Generation](https://arxiv.org/abs/2601.21766)
*Amit Dhurandhar,Vijil Chenthamarakshan,Dennis Wei,Tejaswini Pedapati,Karthikeyan Natesan Ramamurthy,Rahul Nair*

Main category: cs.CL

TL;DR: 本文提出一种受连分数（continued fractions）启发的新型生成模型架构 CoFrGeNets，用于替代Transformer结构中的多头注意力和前馈网络部分。实验表明新结构在减少参数量和训练时间的同时，依然具备与主流Transformer模型竞争的性能。


<details>
  <summary>Details</summary>
Motivation: Transformer虽然在自然语言生成领域表现优秀，但其大量参数和高计算开销限制了其在部分场景下的应用。作者希望借助数学上的连分数思想，优化生成模型架构，从而降低参数量和计算成本，提高效率。

Method: 作者提出了一类新函数族及其具象化的、名为CoFrGeNets的神经网络架构，能够替代Transformer中的多头注意力机制与前馈网络。通过自定义梯度计算方式来更高效地训练该模型，且该组件可以无缝替换现有Transformer结构，无需大幅修改训练或推理流程。

Result: 在GPT2-xl与Llama3等不同规模、大小的数据集上进行预训练和实验，结果显示在文本分类、问答、推理和理解任务上，CoFrGeNets模型参数量仅为原模型的1/2~2/3，训练时间更短，性能却与原模型持平甚至更好。

Conclusion: CoFrGeNets能有效减少参数和训练时间，并实现与传统Transformer模型相当甚至更优的效果，是一种很有前景的Transformer替换方案。未来结合硬件优化有望进一步提升其性能。

Abstract: Transformers are arguably the preferred architecture for language generation. In this paper, inspired by continued fractions, we introduce a new function class for generative modeling. The architecture family implementing this function class is named CoFrGeNets - Continued Fraction Generative Networks. We design novel architectural components based on this function class that can replace Multi-head Attention and Feed-Forward Networks in Transformer blocks while requiring much fewer parameters. We derive custom gradient formulations to optimize the proposed components more accurately and efficiently than using standard PyTorch-based gradients. Our components are a plug-in replacement requiring little change in training or inference procedures that have already been put in place for Transformer-based models thus making our approach easy to incorporate in large industrial workflows. We experiment on two very different transformer architectures GPT2-xl (1.5B) and Llama3 (3.2B), where the former we pre-train on OpenWebText and GneissWeb, while the latter we pre-train on the docling data mix which consists of nine different datasets. Results show that the performance on downstream classification, Q\& A, reasoning and text understanding tasks of our models is competitive and sometimes even superior to the original models with $\frac{2}{3}$ to $\frac{1}{2}$ the parameters and shorter pre-training time. We believe that future implementations customized to hardware will further bring out the true potential of our architectures.

</details>


### [139] [Evaluating ChatGPT on Medical Information Extraction Tasks: Performance, Explainability and Beyond](https://arxiv.org/abs/2601.21767)
*Wei Zhu*

Main category: cs.CL

TL;DR: 本文系统评估了ChatGPT在4项医学信息抽取任务中的表现，并与微调基线模型进行对比。结果发现ChatGPT性能较弱但解释性较强，同时存在过度自信与生成不确定性问题。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型如ChatGPT在对话及通用NLP任务中表现突出，但其在医学信息抽取这一领域的能力尚未被系统性测评，因此有必要深入探究其在该类任务中的优势与不足。

Method: 作者选取了4种医学信息抽取任务和6个标准数据集，针对ChatGPT进行系统实验，考察其性能、解释性、自信度、忠实性和不确定性，并与经过微调的基线模型作对比。

Result: 实验表明：（1）ChatGPT在信息抽取任务中的得分低于微调基线模型；（2）其能够生成高质量的解释说明，但对自身判断过于自信；（3）在大多数情况下，生成内容高度忠实于原文；（4）生成的不确定性导致信息抽取结果的不确定，影响实际应用价值。

Conclusion: 尽管ChatGPT在解释性和忠实性方面表现良好，但在医学信息抽取任务中的整体性能逊于专业模型，且过度自信和不确定性的存在限制了其在此领域的应用前景。

Abstract: Large Language Models (LLMs) like ChatGPT have demonstrated amazing capabilities in comprehending user intents and generate reasonable and useful responses. Beside their ability to chat, their capabilities in various natural language processing (NLP) tasks are of interest to the research community. In this paper, we focus on assessing the overall ability of ChatGPT in 4 different medical information extraction (MedIE) tasks across 6 benchmark datasets. We present the systematically analysis by measuring ChatGPT's performance, explainability, confidence, faithfulness, and uncertainty. Our experiments reveal that: (a) ChatGPT's performance scores on MedIE tasks fall behind those of the fine-tuned baseline models. (b) ChatGPT can provide high-quality explanations for its decisions, however, ChatGPT is over-confident in its predcitions. (c) ChatGPT demonstrates a high level of faithfulness to the original text in the majority of cases. (d) The uncertainty in generation causes uncertainty in information extraction results, thus may hinder its applications in MedIE tasks.

</details>


### [140] [Zonkey: A Hierarchical Diffusion Language Model with Differentiable Tokenization and Probabilistic Attention](https://arxiv.org/abs/2601.21768)
*Alon Rozental*

Main category: cs.CL

TL;DR: 本文提出Zonkey，一个用于大语言模型（LLM）的分层扩散模型，实现了从字符到文档级表征的端到端可训练流程，用以替代传统的、不可微分的分词器（如BPE），提高适应性与表达能力。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM通常依赖固定且不可微分的分词算法（比如BPE），这限制了模型端到端优化的能力，并在处理有噪声或特定领域数据时表现不佳。因此，作者希望设计一种可微分、可训练的分词机制，从而提升模型对不同数据分布的适应性及整体表达能力。

Method: Zonkey以层次化扩散模型为框架，核心是一个可微分的分词器（Segment Splitter），通过学习序列开始（BOS）的概率实现自适应切分，无需显式人工监督。创新性提出了概率注意力机制，实现对任意长度序列的软掩码处理，分层压缩字符到词、再到句向量。采用去噪扩散混合模型（DDMM）保证在潜空间重建的稳定和高效，并引入Stitcher机制以保证分段不变性。整个流程可以端到端、全程可微地训练。

Result: 在维基百科数据集上端到端训练后，Zonkey能从噪声中生成连贯、可变长度的文本，表现出层级结构和良好的对数据分布的拟合能力。与基于熵的可学习分词器相比，Zonkey在定性表现上更优。

Conclusion: Zonkey推进了全梯度可微的LLM设计，为实现更强的领域自适应和可扩展文本生成提供了新方向。相关源码已开源，可复现实验。

Abstract: Large language models (LLMs) have revolutionized natural language processing, yet they remain constrained by fixed, non-differentiable tokenizers like Byte Pair Encoding (BPE), which hinder end-to-end optimization and adaptability to noisy or domain-specific data. We introduce Zonkey, a hierarchical diffusion model that addresses these limitations through a fully trainable pipeline from raw characters to document-level representations. At its core is a differentiable tokenizer (Segment Splitter) that learns probabilistic beginning-of-sequence (BOS) decisions, enabling adaptive splits that emerge as linguistically meaningful (e.g., word boundaries at spaces, sentence starts at periods) without explicit supervision. This differentiability is enabled by our novel Probabilistic Attention mechanism, which incorporates position-specific existence probabilities to simulate soft masking over theoretically infinite sequences while preserving gradients. Sequences decay probabilistically rather than relying on end-of-sequence tokens, supporting variable-length outputs. Hierarchical levels compress sequences into higher abstractions (e.g., character n-grams to word-like vectors, then sentence-like), with reconstruction via our Denoising Diffusion Mixed Model (DDMM) for stable and efficient denoising in latent space. A Stitcher ensures overlap invariance across segments. Trained end-to-end on Wikipedia, Zonkey generates coherent, variable-length text from noise, demonstrating emergent hierarchies and promising qualitative alignment to data distributions compared to entropy-based learnable tokenizers. Our approach advances toward fully gradient-based LLMs, with potential for better domain adaptation and scalable generation. We release the source code for training and reproducing our experiments.

</details>


### [141] [KID: Knowledge-Injected Dual-Head Learning for Knowledge-Grounded Harmful Meme Detection](https://arxiv.org/abs/2601.21796)
*Yaocong Li,Leihan Zhang,Le Zhang,Qiang Yan*

Main category: cs.CL

TL;DR: 本文提出了一种新的知识注入型双头学习框架（KID），有效提升了有害网络迷因的自动检测能力，在多语言任务上取得了最优表现。


<details>
  <summary>Details</summary>
Motivation: 网络迷因在社交平台上广泛传播，但它们通过隐喻和文化背景传递信息，往往成为隐性有害内容的载体，带来了自动内容审核的巨大挑战。现有方法往往无法充分利用外部知识来理解迷因中的隐性恶意。

Method: 提出KID框架，利用知识驱动的推理链，将视觉证据、背景知识和分类标签结构化关联，并采用双头架构，联合优化语义生成和分类任务。核心机制包括标签约束蒸馏和知识注入，使外部知识与迷因具体情境有效结合。

Result: 在英语、中文及孟加拉语等五个多语言数据集上，KID在有害迷因二分类和多标签任务中相较各类主流方法提升2.1%~19.7%。消融实验验证了知识注入与双头共同学习机制的有效互补作用。

Conclusion: 知识注入与双头架构能显著增强迷因理解的鲁棒性与泛化能力，为复杂社交媒体内容的自动审核提供了新思路。

Abstract: Internet memes have become pervasive carriers of digital culture on social platforms. However, their heavy reliance on metaphors and sociocultural context also makes them subtle vehicles for harmful content, posing significant challenges for automated content moderation. Existing approaches primarily focus on intra-modal and inter-modal signal analysis, while the understanding of implicit toxicity often depends on background knowledge that is not explicitly present in the meme itself. To address this challenge, we propose KID, a Knowledge-Injected Dual-Head Learning framework for knowledge-grounded harmful meme detection. KID adopts a label-constrained distillation paradigm to decompose complex meme understanding into structured reasoning chains that explicitly link visual evidence, background knowledge, and classification labels. These chains guide the learning process by grounding external knowledge in meme-specific contexts. In addition, KID employs a dual-head architecture that jointly optimizes semantic generation and classification objectives, enabling aligned linguistic reasoning while maintaining stable decision boundaries. Extensive experiments on five multilingual datasets spanning English, Chinese, and low-resource Bengali demonstrate that KID achieves SOTA performance on both binary and multi-label harmful meme detection tasks, improving over previous best methods by 2.1%--19.7% across primary evaluation metrics. Ablation studies further confirm the effectiveness of knowledge injection and dual-head joint learning, highlighting their complementary contributions to robust and generalizable meme understanding. The code and data are available at https://github.com/PotatoDog1669/KID.

</details>


### [142] [Enhancing Conversational Agents via Task-Oriented Adversarial Memory Adaptation](https://arxiv.org/abs/2601.21797)
*Yimin Deng,Yuqing Fu,Derong Xu,Yejing Wang,Wei Ni,Jingtong Gao,Xiaopeng Li,Chengxu Liu,Xiao Han,Guoshuai Zhao,Xiangyu Zhao,Li Zhu,Xueming Qian*

Main category: cs.CL

TL;DR: 提出了一种对话代理的记忆系统自适应机制，用于提升处理长对话时的信息提取和利用能力。


<details>
  <summary>Details</summary>
Motivation: 现有记忆系统的离线阶段忽视了任务相关性，导致下游任务表现不佳。离线记忆构建和更新阶段通常是固定且与任务无关，更新又常常依赖通用性指标，未能有效对齐具体任务需求。

Method: 提出了一种对抗式记忆自适应机制（AMA）。该方法通过模拟任务执行过程：先由挑战代理生成问答对，再利用记忆系统作答，然后由评估代理进行误差分析，最后适配代理根据错误进行双层更新（策略和内容），为记忆系统在离线阶段引入任务感知监督信号。

Result: AMA机制可灵活集成进多种已有记忆系统，在长对话基准数据集LoCoMo上进行了大量实验，结果证明了其有效性。

Conclusion: AMA机制能在离线阶段提升记忆对下游任务的适应性，对长对话场景的任务表现有显著提升，具有较强泛化性和实用价值。

Abstract: Conversational agents struggle to handle long conversations due to context window limitations. Therefore, memory systems are developed to leverage essential historical information. Existing memory systems typically follow a pipeline of offline memory construction and update, and online retrieval. Despite the flexible online phase, the offline phase remains fixed and task-independent. In this phase, memory construction operates under a predefined workflow and fails to emphasize task relevant information. Meanwhile, memory updates are guided by generic metrics rather than task specific supervision. This leads to a misalignment between offline memory preparation and task requirements, which undermines downstream task performance. To this end, we propose an Adversarial Memory Adaptation mechanism (AMA) that aligns memory construction and update with task objectives by simulating task execution. Specifically, first, a challenger agent generates question answer pairs based on the original dialogues. The constructed memory is then used to answer these questions, simulating downstream inference. Subsequently, an evaluator agent assesses the responses and performs error analysis. Finally, an adapter agent analyzes the error cases and performs dual level updates on both the construction strategy and the content. Through this process, the memory system receives task aware supervision signals in advance during the offline phase, enhancing its adaptability to downstream tasks. AMA can be integrated into various existing memory systems, and extensive experiments on long dialogue benchmark LoCoMo demonstrate its effectiveness.

</details>


### [143] [RAG-E: Quantifying Retriever-Generator Alignment and Failure Modes](https://arxiv.org/abs/2601.21803)
*Korbinian Randl,Guido Rocchietti,Aron Henriksson,Ziawasch Abedjan,Tony Lindgren,John Pavlopoulos*

Main category: cs.CL

TL;DR: 论文提出了RAG-E框架，通过数学归因方法解释和量化RAG系统中检索器与生成器的协同情况，揭示了它们之间常见的不对齐问题。


<details>
  <summary>Details</summary>
Motivation: RAG（检索增强生成）系统中检索模块和生成语言模型的互动机制不透明，难以在高度敏感领域安全部署，急需对其内部协同过程进行可解释性分析和量化。

Method: 1. 创新性地将Integrated Gradients归因方法用于检索器分析。
2. 提出了PMCSHAP（一种蒙特卡洛稳定的Shapley值近似）用于生成器归因。
3. 引入了WARG（加权归因-相关性差距）指标，量化生成器对检索器排名文档的实际利用度与理论相关的匹配度。

Result: 在TREC CAsT和FoodSafeSum任务中实证分析显示，约47.4%-66.7%的查询中，生成器会忽略检索器排名第一的文档，且有48.1%-65.9%会更多依赖排名较低、相关性较差的文档，揭示了RAG系统组件之间存在严重的不一致性。

Conclusion: RAG输出质量不仅取决于检索和生成子模块单独性能，更取决于二者的协同机制。RAG-E方法为识别和审计这种协同失灵提供了有效工具，对实际部署和改进RAG系统有重要价值。

Abstract: Retrieval-Augmented Generation (RAG) systems combine dense retrievers and language models to ground LLM outputs in retrieved documents. However, the opacity of how these components interact creates challenges for deployment in high-stakes domains. We present RAG-E, an end-to-end explainability framework that quantifies retriever-generator alignment through mathematically grounded attribution methods. Our approach adapts Integrated Gradients for retriever analysis, introduces PMCSHAP, a Monte Carlo-stabilized Shapley Value approximation, for generator attribution, and introduces the Weighted Attribution-Relevance Gap (WARG) metric to measure how well a generator's document usage aligns with a retriever's ranking. Empirical analysis on TREC CAsT and FoodSafeSum reveals critical misalignments: for 47.4% to 66.7% of queries, generators ignore the retriever's top-ranked documents, while 48.1% to 65.9% rely on documents ranked as less relevant. These failure modes demonstrate that RAG output quality depends not solely on individual component performance but on their interplay, which can be audited via RAG-E.

</details>


### [144] [Distribution-Aware Reward Estimation for Test-Time Reinforcement Learning](https://arxiv.org/abs/2601.21804)
*Bodong Du,Xuanqi Huang,Xiaomeng Li*

Main category: cs.CL

TL;DR: 本文提出了一种新的测试时强化学习(TTRL)奖励估算方法——DARE，能够在无需人工标注的情况下让大模型优化能力更强、更稳定。


<details>
  <summary>Details</summary>
Motivation: 现有TTRL方法主要采用多数投票(MV)方式对奖励进行估算，将所有展开结果只按多数结果做判断，容易丢失对少数但正确候选动作的信息，并引入系统性偏差，降低模型自我提升效果。

Method: 作者提出了基于分布感知的奖励估算(DARE)方法。DARE不再使用单一多数结果，而是利用完整的展开分布，结合探索奖励和分布裁剪机制，在探索非多数结果的同时对奖励进行去噪，更全面地评估奖励。

Result: 在AIME 2024和AMC等复杂推理数据集上，DARE相较现有SOTA基线分别获得25.3%和5.3%的性能提升，同时优化过程更稳定。

Conclusion: DARE显著提升了TTRL自我提升任务的效果和收敛稳定性，为无标注场景下大模型强化学习提供了更优解。

Abstract: Test-time reinforcement learning (TTRL) enables large language models (LLMs) to self-improve on unlabeled inputs, but its effectiveness critically depends on how reward signals are estimated without ground-truth supervision. Most existing TTRL methods rely on majority voting (MV) over rollouts to produce deterministic rewards, implicitly assuming that the majority rollout provides a reliable learning signal. We show that this assumption is fragile: MV reduces the rollout distribution into a single outcome, discarding information about non-majority but correct actions candidates, and yields systematically biased reward estimates. To address this, we propose Distribution-AwareReward Estimation (DARE), which shifts reward estimation from a single majority outcome to the full empirical rollout distribution. DARE further augments this distribution-based reward with an exploration bonus and a distribution pruning mechanism for non-majority rollout exploration and reward denoise, yielding a more informative and robust reward estimation. Extensive experiments on challenging reasoning benchmarks show that DARE improves optimization stability and final performance over recent baselines, achieving relative improvements of 25.3% on challenging AIME 2024 and 5.3% on AMC.

</details>


### [145] [Mil-SCORE: Benchmarking Long-Context Geospatial Reasoning and Planning in Large Language Models](https://arxiv.org/abs/2601.21826)
*Aadi Palnitkar,Mingyang Mao,Nicholas Waytowich,Vinicius G. Goecks,Tinoosh Mohsenin,Xiaomin Lin*

Main category: cs.CL

TL;DR: 本文提出了MilSCORE数据集，这是首个面向复杂军事规划情景的专家编写多跳问题集，用于评估大语言模型（LLMs）在多源、长上下文、地理空间富信息背景下的推理和计划能力。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在更长、更复杂任务中的应用增多，尤其在如军事大规模行动等地理空间规划问题中，亟需能真实反映长上下文、需要多模态信息整合的基准。然而现有评测数据集在这方面存在缺口。

Method: 作者构建了MilSCORE数据集，包括复杂模拟军事规划场景下的专家多跳问答，覆盖七大类问题（包括事实回忆、多步推理、空间分析等），并为一系列主流视觉语言模型给出基线评测协议与结果。

Result: 现有系统在MilSCORE上的表现存在较大提升空间，揭示了这些模型在真实场景级长上下文推理和规划任务中的明显不足。

Conclusion: MilSCORE为后续在现实、高风险、多信息融合背景下的长上下文规划研究提供了具有挑战性的标准测试平台，将推动相关领域发展。

Abstract: As large language models (LLMs) are applied to increasingly longer and more complex tasks, there is a growing need for realistic long-context benchmarks that require selective reading and integration of heterogeneous, multi-modal information sources. This need is especially acute for geospatial planning problems, such as those found in planning for large-scale military operations, which demand fast and accurate reasoning over maps, orders, intelligence reports, and other distributed data. To address this gap, we present MilSCORE (Military Scenario Contextual Reasoning), to our knowledge the first scenario-level dataset of expert-authored, multi-hop questions grounded in a complex, simulated military planning scenario used for training. MilSCORE is designed to evaluate high-stakes decision-making and planning, probing LLMs' ability to combine tactical and spatial reasoning across multiple sources and to reason over long-horizon, geospatially rich context. The benchmark includes a diverse set of question types across seven categories targeting both factual recall and multi-step reasoning about constraints, strategy, and spatial analysis. We provide an evaluation protocol and report baseline results for a range of contemporary vision-language models. Our findings highlight substantial headroom on MilSCORE, indicating that current systems struggle with realistic, scenario-level long-context planning, and positioning MilSCORE as a challenging testbed for future work.

</details>


### [146] [Embodied Task Planning via Graph-Informed Action Generation with Large Lanaguage Model](https://arxiv.org/abs/2601.21841)
*Xiang Li,Ning Yan,Masood Mortazavi*

Main category: cs.CL

TL;DR: 本文提出了一个新颖的图中图（Graph-in-Graph, GiG）规划框架，提升了大语言模型作为具身智能体在长期规划任务中的表现，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLM）在零样本推理方面表现优异，但作为具身智能体进行长期任务规划时，往往因上下文窗口限制或“幻觉”推理而导致策略丧失连贯性或违反环境逻辑，亟需为智能体设计能处理复杂状态转移和记忆的有效整合方案。

Method: 作者提出GiG框架，利用图神经网络（GNN）将环境状态编码为嵌入向量，通过动作连接形成经验记忆库中的执行轨迹图。通过聚类嵌入，系统可检索出结构感知先验知识，并结合符号化状态转移逻辑的有界前瞻模块，以提升智能体基于历史结构模式的规划能力。

Result: 在Robotouille Synchronous、Robotouille Asynchronous和ALFWorld三个具身智能体规划基准上，GiG方法分别在Pass@1指标上相较于最新基线方法取得了至多22%、37%和15%的提升，且计算成本相当或更低。

Conclusion: GiG框架极大增强了具身智能体的长期策略连贯性和环境约束满足能力，是面向复杂场景智能体规划的有效通用方案。

Abstract: While Large Language Models (LLMs) have demonstrated strong zero-shot reasoning capabilities, their deployment as embodied agents still faces fundamental challenges in long-horizon planning. Unlike open-ended text generation, embodied agents must decompose high-level intent into actionable sub-goals while strictly adhering to the logic of a dynamic, observed environment. Standard LLM planners frequently fail to maintain strategy coherence over extended horizons due to context window limitation or hallucinate transitions that violate constraints. We propose GiG, a novel planning framework that structures embodied agents' memory using a Graph-in-Graph architecture. Our approach employs a Graph Neural Network (GNN) to encode environmental states into embeddings, organizing these embeddings into action-connected execution trace graphs within an experience memory bank. By clustering these graph embeddings, the framework enables retrieval of structure-aware priors, allowing agents to ground current decisions in relevant past structural patterns. Furthermore, we introduce a novel bounded lookahead module that leverages symbolic transition logic to enhance the agents' planning capabilities through the grounded action projection. We evaluate our framework on three embodied planning benchmarks-Robotouille Synchronous, Robotouille Asynchronous, and ALFWorld. Our method outperforms state-of-the-art baselines, achieving Pass@1 performance gains of up to 22% on Robotouille Synchronous, 37% on Asynchronous, and 15% on ALFWorld with comparable or lower computational cost.

</details>


### [147] [Learn-to-Distance: Distance Learning for Detecting LLM-Generated Text](https://arxiv.org/abs/2601.21895)
*Hongyi Zhou,Jin Zhu,Erhan Xu,Kai Ye,Ying Yang,Chengchun Shi*

Main category: cs.CL

TL;DR: 该论文提出了一种自适应学习原文和重写文本之间距离的新型检测算法，用于判别大语言模型生成内容，并在多种场景下显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（如GPT、Claude、Gemini）生成的内容越来越像人类写作，导致虚假信息和学术诚信问题。因此，急需高效可靠的检测算法区分AI生成内容与人工内容。

Method: 作者首先分析了基于重写检测算法的几何直觉与推广能力，然后提出一种利用自适应学习距离函数的重写型检测新算法。理论上证实自适应距离优于固定距离。

Result: 在超过100种实验设置下，新方法在大多数场景下超过主流基线算法，对最强基线实现了57.8%到80.6%的相对性能提升。

Conclusion: 提出的检测算法不仅理论上更优，并且在实际检测大语言模型内容上有强大效果，显著提升了检测准确性，能有效应对不同LLM场景。

Abstract: Modern large language models (LLMs) such as GPT, Claude, and Gemini have transformed the way we learn, work, and communicate. Yet, their ability to produce highly human-like text raises serious concerns about misinformation and academic integrity, making it an urgent need for reliable algorithms to detect LLM-generated content. In this paper, we start by presenting a geometric approach to demystify rewrite-based detection algorithms, revealing their underlying rationale and demonstrating their generalization ability. Building on this insight, we introduce a novel rewrite-based detection algorithm that adaptively learns the distance between the original and rewritten text. Theoretically, we demonstrate that employing an adaptively learned distance function is more effective for detection than using a fixed distance. Empirically, we conduct extensive experiments with over 100 settings, and find that our approach demonstrates superior performance over baseline algorithms in the majority of scenarios. In particular, it achieves relative improvements from 57.8\% to 80.6\% over the strongest baseline across different target LLMs (e.g., GPT, Claude, and Gemini).

</details>


### [148] [SONIC: Segmented Optimized Nexus for Information Compression in Key-Value Caching](https://arxiv.org/abs/2601.21927)
*Hong Chen,Xiang Liu,Bo Wang,Yuxuan Fan,Yuanlin Chu,Zongluo Li,Xiaowen Chu,Xuming Hu*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的KV缓存压缩方法SONIC，在保证多轮对话语义连贯性的同时，大幅减小了KV缓存的存储需求，并显著提升了推理效率，优于现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 多轮大语言模型部署时，KV缓存随对话轮次线性增长，导致内存和计算瓶颈；现有压缩方法未能充分考虑多轮对话结构，且常采用启发式淘汰，容易丢失关键信息。

Method: SONIC框架将历史对话片段压缩为更紧凑且语义丰富的Nexus token，并通过动态预算训练机制，实现无须重复训练即可灵活适应不同内存约束。

Result: 在4个多轮对话基准上，SONIC于80%和50%高压缩比下，持续优于H2O和StreamingLLM等方法。于MTBench101数据集上, 平均得分提升35.55%；整体推理速度提升50.1%。

Conclusion: SONIC能高效压缩KV缓存，增强推理效率且保证对话连贯性，是多轮对话模型有效的KV缓存管理新方案。

Abstract: The linear growth of Key-Value (KV) cache remains a bottleneck for multi-turn LLM deployment. Existing KV cache compression methods often fail to account for the structural properties of multi-turn dialogues, relying on heuristic eviction that risks losing critical context. We propose \textbf{SONIC}, a learning-based framework that compresses historical segments into compact and semantically rich \textbf{Nexus} tokens. By integrating dynamic budget training, SONIC allows flexible adaptation to varying memory constraints without retraining. Experiments show that at compression ratios of 80\% and 50\%, SONIC consistently outperforms baselines such as H2O and StreamingLLM on four diverse multi-turn benchmarks. Specifically, on the widely used MTBench101 benchmark, SONIC achieves an average score improvement of 35.55\% over state-of-the-art baselines, validating its effectiveness in sustaining coherent multi-turn dialogues. Furthermore, SONIC enhances deployment efficiency, accelerating the overall inference process by 50.1\% compared to full-context generation.

</details>


### [149] [From Generative Modeling to Clinical Classification: A GPT-Based Architecture for EHR Notes](https://arxiv.org/abs/2601.21955)
*Fariba Afrin Irany*

Main category: cs.CL

TL;DR: 本文提出了一种基于GPT架构的微调方法，在只更新少量参数的基础上，有效用于电子健康记录（EHR）中的临床文本分类，尤其适合放射报告，实现了高效且表现良好的自动化医学文本分析。


<details>
  <summary>Details</summary>
Motivation: 面对EHR中数量庞大的非结构化临床文本，自动化疾病表征和队列识别存在标注数据少、类别极端不平衡及大模型训练成本高等挑战，亟需高效的分类方法。

Method: 采用冻结大部分GPT-2权重，仅微调最后一个Transformer block、最终归一化层和轻量级分类头，实现大幅度减少模型可训练参数，降低计算资源消耗。模型在MIMIC-IV-Note数据集中，利用CheXpert风格标签进行多种分类任务的评估，包括多标签及二分类方案，亦涵盖不同的不确定性处理。

Result: 实验结果表明，该方法在不同数据规模下收敛稳定，分类表现强劲，特别适用于未提及和否定性发现占主导的场景。

Conclusion: 选择性微调预训练生成式大语言模型既能高效适应实际EHR数据，也能显著减少计算复杂度，是临床文本分类的可行且高效途径。

Abstract: The increasing availability of unstructured clinical narratives in electronic health records (EHRs) has created new opportunities for automated disease characterization, cohort identification, and clinical decision support. However, modeling long, domain-specific clinical text remains challenging due to limited labeled data, severe class imbalance, and the high computational cost of adapting large pretrained language models.
  This study presents a GPT-based architecture for clinical text classification that adapts a pretrained decoder-only Transformer using a selective fine-tuning strategy. Rather than updating all model parameters, the majority of the GPT-2 backbone is frozen, and training is restricted to the final Transformer block, the final layer normalization, and a lightweight classification head. This approach substantially reduces the number of trainable parameters while preserving the representational capacity required to model complex clinical language.
  The proposed method is evaluated on radiology reports from the MIMIC-IV-Note dataset using uncertainty-aware CheXpert-style labels derived directly from report text. Experiments cover multiple problem formulations, including multi-label classification of radiographic findings, binary per-label classification under different uncertainty assumptions, and aggregate disease outcome prediction. Across varying dataset sizes, the model exhibits stable convergence behavior and strong classification performance, particularly in settings dominated by non-mention and negated findings.
  Overall, the results indicate that selective fine-tuning of pretrained generative language models provides an efficient and effective pathway for clinical text classification, enabling scalable adaptation to real-world EHR data while significantly reducing computational complexity.

</details>


### [150] [OVD: On-policy Verbal Distillation](https://arxiv.org/abs/2601.21968)
*Jing Xiong,Hui Shen,Shansan Gong,Yuxin Cheng,Jianghan Shen,Chaofan Tao,Haochen Tan,Haoli Bai,Lifeng Shang,Ngai Wong*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的On-policy Verbal Distillation (OVD)方法，用于高效地将大模型的推理能力蒸馏到小模型中，通过离散的语言得分实现轨迹对齐，大幅减少内存消耗并提升训练效率和性能。实验结果显示，在Web问答和数学推理任务上均显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的token级别蒸馏方法要求学生模型和教师模型在每一步输出上严格对齐，这限制了学生模型的探索能力，也难以有效利用基于环境反馈的策略优化，同时在强化学习任务中会遇到严重的内存瓶颈。

Method: 提出On-policy Verbal Distillation (OVD)框架，用教师模型给出的离散言语得分（如0~9分）对整个推理轨迹进行匹配，而不再是传统的token级输出概率对齐，从而实现对策略的“言语”反馈和高效内存利用。

Result: 在Web问答和数学推理任务上，OVD相比现有蒸馏方法平均提升了12.9%的EM（准确匹配）指标，在数学基准上提升高达25.7%，并具有更好的训练效率。

Conclusion: OVD不仅解决了token级对齐的局限性，还有效降低了训练内存消耗，促进了学生模型对输出空间的探索，显著提升了下游任务的表现，是一种具有前景的知识蒸馏新范式。

Abstract: Knowledge distillation offers a promising path to transfer reasoning capabilities from large teacher models to efficient student models; however, existing token-level on-policy distillation methods require token-level alignment between the student and teacher models, which restricts the student model's exploration ability, prevent effective use of interactive environment feedback, and suffer from severe memory bottlenecks in reinforcement learning. We introduce On-policy Verbal Distillation (OVD), a memory-efficient framework that replaces token-level probability matching with trajectory matching using discrete verbal scores (0--9) from teacher models. OVD dramatically reduces memory consumption while enabling on-policy distillation from teacher models with verbal feedback, and avoids token-level alignment, allowing the student model to freely explore the output space. Extensive experiments on Web question answering and mathematical reasoning tasks show that OVD substantially outperforms existing methods, delivering up to +12.9% absolute improvement in average EM on Web Q&A tasks and a up to +25.7% gain on math benchmarks (when trained with only one random samples), while also exhibiting superior training efficiency. Our project page is available at https://OVD.github.io

</details>


### [151] [Token-Guard: Towards Token-Level Hallucination Control via Self-Checking Decoding](https://arxiv.org/abs/2601.21969)
*Yifan Zhu,Huiqiang Rong,Haoran Luo*

Main category: cs.CL

TL;DR: 本文提出了一种名为Token-Guard的自检解码方法，用于细粒度控制大语言模型生成的幻觉（hallucination），实验表明方法有效降低幻觉，提高生成准确性。


<details>
  <summary>Details</summary>
Motivation: 现有减轻LLM幻觉的方法（如RAG和RLHF）成本高，轻量解码法又缺乏显式幻觉控制，因此亟需一种既高效又能细致控制幻觉的方法。

Method: 提出Token-Guard方法，在每一步解码时进行内部检验以检测幻觉token，并在隐空间对候选片段打分，结合迭代剪除与重生成机制动态纠错，实现token级幻觉检测与控制。

Result: 在HALU数据集上验证Token-Guard显著减少LLM生成中的幻觉，提高输出的准确性。

Conclusion: Token-Guard为LLM幻觉控制提供了一种高效、可扩展且模块化的新方案，并已开源。

Abstract: Large Language Models (LLMs) often hallucinate, generating content inconsistent with the input. Retrieval-Augmented Generation (RAG) and Reinforcement Learning with Human Feedback (RLHF) can mitigate hallucinations but require resource-intensive retrieval or large-scale fine-tuning. Decoding-based methods are lighter yet lack explicit hallucination control. To address this, we present Token-Guard, a token-level hallucination control method based on self-checking decoding. Token-Guard performs internal verification at each reasoning step to detect hallucinated tokens before they propagate. Candidate fragments are further evaluated in a latent space with explicit hallucination risk scoring, while iterative pruning and regeneration dynamically correct detected errors. Experiments on HALU datasets show Token-Guard substantially reduces hallucinations and improves generation accuracy, offering a scalable, modular solution for reliable LLM outputs. Our code is publicly available.

</details>


### [152] [Mechanistic Data Attribution: Tracing the Training Origins of Interpretable LLM Units](https://arxiv.org/abs/2601.21996)
*Jianhui Chen,Yuzhang Luo,Liangming Pan*

Main category: cs.CL

TL;DR: 作者提出了机制性数据归因（MDA）框架，用于追溯LLM中可解释单元与具体训练样本之间的因果联系，并通过实验证明特定训练数据对可解释结构形成有显著影响。


<details>
  <summary>Details</summary>
Motivation: 尽管理机制性可解释性发现了LLM内部可解释电路，但这些电路在训练数据中的因果起源仍未明了。因此，作者希望探索如何从训练数据中溯源这些结构的形成。

Method: 提出了一种机制性数据归因（MDA）方法，利用影响函数（Influence Functions）把LLM中的可解释单元追溯到具体训练样本。通过在Pythia模型上实验，研究了有针对性地移除或增加高影响样本与随机操作的对比效果。

Result: 发现有针对性的干预（删除或增强高影响样本）会显著调节LLM中可解释heads的出现，而随机干预没有此效应。结构性数据（如LaTeX、XML）对电路可解释性的形成有催化作用。干预induction head形成还会联动影响模型的ICL能力。

Conclusion: 本文首次提供了训练数据与LLM内部功能结构间的直接因果证据，提出的数据增强管道能加速电路收敛，为引导LLM发展提供了新方法。

Abstract: While Mechanistic Interpretability has identified interpretable circuits in LLMs, their causal origins in training data remain elusive. We introduce Mechanistic Data Attribution (MDA), a scalable framework that employs Influence Functions to trace interpretable units back to specific training samples. Through extensive experiments on the Pythia family, we causally validate that targeted intervention--removing or augmenting a small fraction of high-influence samples--significantly modulates the emergence of interpretable heads, whereas random interventions show no effect. Our analysis reveals that repetitive structural data (e.g., LaTeX, XML) acts as a mechanistic catalyst. Furthermore, we observe that interventions targeting induction head formation induce a concurrent change in the model's in-context learning (ICL) capability. This provides direct causal evidence for the long-standing hypothesis regarding the functional link between induction heads and ICL. Finally, we propose a mechanistic data augmentation pipeline that consistently accelerates circuit convergence across model scales, providing a principled methodology for steering the developmental trajectories of LLMs.

</details>


### [153] [When "Better" Prompts Hurt: Evaluation-Driven Iteration for LLM Applications](https://arxiv.org/abs/2601.22025)
*Daniel Commey*

Main category: cs.CL

TL;DR: 本文提出了针对大语言模型（LLM）应用的系统化评测流程，并发布了适用于不同类型任务的最小可行评测套件（MVES）。作者还评估了通用提示工程对模型表现的影响，强调了迭代和细分评测的重要性。


<details>
  <summary>Details</summary>
Motivation: LLM应用的输出具有随机性和高维特征，且对提示词和模型变动高度敏感，给传统软件测试带来挑战，急需新的、可复制的评测流程和工具。

Method: 设计了一个循环评测工作流（定义、测试、诊断、修复），并提出MVES评测组件，涵盖通用用例、RAG和Agent型应用。结合多种评测方法（自动检查、人类打分、LLM判决），并用本地实验评估提示工程对评测表现的影响。

Result: 在本地重现性实验中，针对Llama 3等模型，通用提示工程模板提升了任务遵循度，但在结构化信息抽取和RAG合规性上表现下降。所有评测结果和工具已开源。

Conclusion: LLM应用开发需以评测为驱动，避免“一刀切”的通用提示工程做法，应注重针对不同任务的评测循环和指标细分，实现更有效的鲁棒性提升和性能认知。

Abstract: Evaluating Large Language Model (LLM) applications differs from traditional software testing because outputs are stochastic, high-dimensional, and sensitive to prompt and model changes. We present an evaluation-driven workflow - Define, Test, Diagnose, Fix - that turns these challenges into a repeatable engineering loop.
  We introduce the Minimum Viable Evaluation Suite (MVES), a tiered set of recommended evaluation components for (i) general LLM applications, (ii) retrieval-augmented generation (RAG), and (iii) agentic tool-use workflows. We also synthesize common evaluation methods (automated checks, human rubrics, and LLM-as-judge) and discuss known judge failure modes.
  In reproducible local experiments (Ollama; Llama 3 8B Instruct and Qwen 2.5 7B Instruct), we observe that a generic "improved" prompt template can trade off behaviors: on our small structured suites, extraction pass rate decreased from 100% to 90% and RAG compliance from 93.3% to 80% for Llama 3 when replacing task-specific prompts with generic rules, while instruction-following improved. These findings motivate evaluation-driven prompt iteration and careful claim calibration rather than universal prompt recipes.
  All test suites, harnesses, and results are included for reproducibility.

</details>


### [154] [Causal Autoregressive Diffusion Language Model](https://arxiv.org/abs/2601.22031)
*Junhao Ruan,Bei Li,Yongjing Yin,Pengcheng Huang,Xin Chen,Jingang Wang,Xunliang Cai,Tong Xiao,JingBo Zhu*

Main category: cs.CL

TL;DR: 提出了Causal Autoregressive Diffusion（CARD），结合自回归模型的训练效率和扩散模型的高吞吐推理，显著提升大语言模型（LLMs）的效率。


<details>
  <summary>Details</summary>
Motivation: 现有自回归模型（ARMs）训练高效但推理慢，扩散模型推理快但训练慢。如何兼得二者优势，实现低延迟、高效率的大模型生成是一大挑战。

Method: CARD通过严格因果注意力掩码将扩散过程重塑，实现单步训练中的密集逐token监督。为解决因果扩散优化不稳定，引入软尾掩码以保留局部上下文、按信噪比设计上下文相关重加权。此外，CARD利用KV缓存支持动态并行解码，实现按置信度自适应生成变长token序列。

Result: CARD在实验中优于其他离散扩散方法，相较于块状扩散法训练延迟降低3倍。既具备自回归模型级别数据效率，也具备并行生成的延迟优势。

Conclusion: CARD为高效大模型生成提供了新的强大范式，兼顾训练与推理效率，有望成为新一代高性能LLM的基础方案。

Abstract: In this work, we propose Causal Autoregressive Diffusion (CARD), a novel framework that unifies the training efficiency of ARMs with the high-throughput inference of diffusion models. CARD reformulates the diffusion process within a strictly causal attention mask, enabling dense, per-token supervision in a single forward pass. To address the optimization instability of causal diffusion, we introduce a soft-tailed masking schema to preserve local context and a context-aware reweighting mechanism derived from signal-to-noise principles. This design enables dynamic parallel decoding, where the model leverages KV-caching to adaptively generate variable-length token sequences based on confidence. Empirically, CARD outperforms existing discrete diffusion baselines while reducing training latency by 3 $\times$ compared to block diffusion methods. Our results demonstrate that CARD achieves ARM-level data efficiency while unlocking the latency benefits of parallel generation, establishing a robust paradigm for next-generation efficient LLMs.

</details>


### [155] [Thinking Out of Order: When Output Order Stops Reflecting Reasoning Order in Diffusion Language Models](https://arxiv.org/abs/2601.22035)
*Longxuan Yu,Yu Fu,Shaorong Zhang,Hui Liu,Mukund Varma T,Greg Ver Steeg,Yue Dong*

Main category: cs.CL

TL;DR: 本文对比了自回归语言模型（AR）与掩码扩散语言模型（MDLM）在输出结构与推理顺序不一致时的表现，发现MDLM在输出要求顺序变化时更具稳健性（顺序鲁棒性），并提出了相关评测基准ReasonOrderQA。


<details>
  <summary>Details</summary>
Motivation: 自回归模型只能按固定的从左到右顺序生成文本，当下游任务要求输出顺序与自然推理顺序冲突时，例如需要先输出答案再给出推理，AR模型会导致推理过程受限，提前生成错误的答案。为解决这一结构与推理顺序耦合的问题，作者探讨了非自回归的扩散模型的可能性。

Method: 作者利用GSM8K、Math500与自建的ReasonOrderQA基准测试掩码扩散语言模型（MDLM），这些基准允许细致地控制输出顺序难度，并进行顺序级别的评估。对比了不同模型在要求先回答再给推理的prompt设置下的表现，并分析了MDLM在推理和答案生成过程中的稳定性差异。

Result: 试验发现，当prompt要求先输出答案再输出推理时，自回归模型准确率大幅下降（相较于标准chain-of-thought顺序最高下降67%），而MDLM下降很小（$%$），表现出更强的顺序鲁棒性。分析发现MDLM能让推理token比答案token更早稳定，有助于优化生成的推理流程。此外，通过ReasonOrderQA找到了MDLM鲁棒性的失效条件。

Conclusion: 掩码扩散语言模型在输出顺序与推理顺序不对齐的复杂任务中展现出相较于自回归模型更强的鲁棒性，但其鲁棒性也有一定限度，具体失效条件仍需进一步探索。

Abstract: Autoregressive (AR) language models enforce a fixed left-to-right generation order, creating a fundamental limitation when the required output structure conflicts with natural reasoning (e.g., producing answers before explanations due to presentation or schema constraints). In such cases, AR models must commit to answers before generating intermediate reasoning, and this rigid constraint forces premature commitment. Masked diffusion language models (MDLMs), which iteratively refine all tokens in parallel, offer a way to decouple computation order from output structure. We validate this capability on GSM8K, Math500, and ReasonOrderQA, a benchmark we introduce with controlled difficulty and order-level evaluation. When prompts request answers before reasoning, AR models exhibit large accuracy gaps compared to standard chain-of-thought ordering (up to 67% relative drop), while MDLMs remain stable ($\leq$14% relative drop), a property we term "order robustness". Using ReasonOrderQA, we present evidence that MDLMs achieve order robustness by stabilizing simpler tokens (e.g., reasoning steps) earlier in the diffusion process than complex ones (e.g., final answers), enabling reasoning tokens to stabilize before answer commitment. Finally, we identify failure conditions where this advantage weakens, outlining the limits required for order robustness.

</details>


### [156] [A Separable Architecture for Continuous Token Representation in Language Models](https://arxiv.org/abs/2601.22040)
*Reza T. Batley,Sourav Saha*

Main category: cs.CL

TL;DR: 本文提出了一种名为Leviathan的新型小语言模型（SLM）架构，用连续嵌入生成器替代了传统的离散嵌入表，实验证明在同等参数下性能明显优于标准LLaMA式模型。


<details>
  <summary>Details</summary>
Motivation: 大多数小型语言模型参数主要消耗在嵌入矩阵上，这种分配被认为既不合理也不高效，因此需要重新思考参数的分配方式。

Method: Leviathan架构引入连续嵌入生成器以替代传统的离散查表方式，并在Pile数据集上，采用相同参数规模进行对比实验。通过经验幂律拟合评估参数效率。

Result: Leviathan在各项实验中都超过了标准LLaMA架构，展现出更高的有效参数容量，其性能相当于参数量提升1.47至2.11倍的密集模型。

Conclusion: 连续嵌入生成器能极大提升小语言模型的参数利用效率与性能，有望取代现有的嵌入矩阵设计。

Abstract: Transformer scaling law analyses typically treat parameters as interchangeable; an abstraction that accurately predicts loss-compute relationships. Yet, in sub-billion-parameter small language models (SLMs), embedding matrices dominate the parameter budget. This work argues that this allocation is as suboptimal as it is counterintuitive. Leviathan is an architecture with a continuous embedding generator to replace the discrete lookup tables of canonical models. Evaluating on the Pile dataset under isoparametric settings, Leviathan consistently outperforms a standard, LLaMA-style architecture. By means of an empirical power-law fit, Leviathan exhibits a markedly superior effective parameter capacity. Across the regime studied, Leviathan behaves as a dense model with $1.47$ to $2.11 \times$ more parameters.

</details>


### [157] [On the Paradoxical Interference between Instruction-Following and Task Solving](https://arxiv.org/abs/2601.22047)
*Yunjia Qi,Hao Peng,Xintong Shi,Amy Xin,Xiaozhi Wang,Bin Xu,Lei Hou,Juanzi Li*

Main category: cs.CL

TL;DR: 该论文发现，大语言模型在严格遵循任务指令时，反而会降低原本的任务完成能力。研究提出了SUSTAINSCORE指标用于量化这种负面影响，并在多个任务和模型上实证验证了这一现象。


<details>
  <summary>Details</summary>
Motivation: 近年来，推动LLM严格遵循人类指令是AI安全与可靠性的重要方向，但研究者注意到过度强调“指令遵循”可能损害模型核心任务解决能力，因此需系统性评估并理解该现象。

Method: 作者设计了SUSTAINSCORE指标，即在指令中加入自明（模型原本就已满足）的约束，观察模型表现下滑程度。实验涵盖数学、多跳问答、代码生成等任务，以及包括Claude-Sonnet-4.5在内的多种先进LLM，并分析了不同类型、规模约束带来的泛化干扰现象。

Result: 结果显示，增加自明约束后，所有测试模型任务表现均大幅下降。深入分析发现，失败案例倾向于在约束内容上分配更多注意力。

Conclusion: 研究表明，指令遵循与任务完成之间存在冲突，需谨慎平衡模型训练目标。SUSTAINSCORE可作为评估这种“干扰效应”的工具，对后续模型对齐方案有借鉴意义，相关代码和数据将公开。

Abstract: Instruction following aims to align Large Language Models (LLMs) with human intent by specifying explicit constraints on how tasks should be performed. However, we reveal a counterintuitive phenomenon: instruction following can paradoxically interfere with LLMs' task-solving capability. We propose a metric, SUSTAINSCORE, to quantify the interference of instruction following with task solving. It measures task performance drop after inserting into the instruction a self-evident constraint, which is naturally met by the original successful model output and extracted from it. Experiments on current LLMs in mathematics, multi-hop QA, and code generation show that adding the self-evident constraints leads to substantial performance drops, even for advanced models such as Claude-Sonnet-4.5. We validate the generality of the interference across constraint types and scales. Furthermore, we identify common failure patterns, and by investigating the mechanisms of interference, we observe that failed cases allocate significantly more attention to constraints compared to successful ones. Finally, we use SUSTAINSCORE to conduct an initial investigation into how distinct post-training paradigms affect the interference, presenting empirical observations on current alignment strategies. We will release our code and data to facilitate further research

</details>


### [158] [MasalBench: A Benchmark for Contextual and Cross-Cultural Understanding of Persian Proverbs in LLMs](https://arxiv.org/abs/2601.22050)
*Ghazal Kalhor,Behnam Bahrak*

Main category: cs.CL

TL;DR: 本文发表了MasalBench，一个用于评估多语种大模型对波斯语谚语理解能力的基准，揭示了模型在文化知识和类比推理上的不足。


<details>
  <summary>Details</summary>
Motivation: 多数多语种大语言模型主要在高资源语言上评估，缺乏对低资源语言中文化元素（如谚语）的理解能力评估。因此，作者希望弥补这一空白，推动模型跨文化、跨语种理解能力的提升。

Method: 构建MasalBench基准，收集波斯语谚语并设计语境识别与英波谚语等价匹配任务，对8个主流LLMs进行测试，评估其波斯语语境理解以及类比推理能力。

Result: 模型在波斯语语境下识别谚语时表现优异，准确率高于0.90。但在匹配英文等价谚语时表现较弱，最优模型准确率为0.79，显示出跨文化知识迁移不足。

Conclusion: 现有LLMs在低资源语言的文化知识和类比推理能力上存在显著局限，MasalBench为推动跨文化理解提供了评测框架，对其他低资源语言研究具有借鉴意义。

Abstract: In recent years, multilingual Large Language Models (LLMs) have become an inseparable part of daily life, making it crucial for them to master the rules of conversational language in order to communicate effectively with users. While previous work has evaluated LLMs' understanding of figurative language in high-resource languages, their performance in low-resource languages remains underexplored. In this paper, we introduce MasalBench, a comprehensive benchmark for assessing LLMs' contextual and cross-cultural understanding of Persian proverbs, which are a key component of conversation in this low-resource language. We evaluate eight state-of-the-art LLMs on MasalBench and find that they perform well in identifying Persian proverbs in context, achieving accuracies above 0.90. However, their performance drops considerably when tasked with identifying equivalent English proverbs, with the best model achieving 0.79 accuracy. Our findings highlight the limitations of current LLMs in cultural knowledge and analogical reasoning, and they provide a framework for assessing cross-cultural understanding in other low-resource languages. MasalBench is available at https://github.com/kalhorghazal/MasalBench.

</details>


### [159] [$G^2$-Reader: Dual Evolving Graphs for Multimodal Document QA](https://arxiv.org/abs/2601.22055)
*Yaxin Du,Junru Song,Yifan Zhou,Cheng Wang,Jiahao Gu,Zimeng Chen,Menglan Chen,Wen Yao,Yang Yang,Ying Wen,Siheng Chen*

Main category: cs.CL

TL;DR: 论文提出了一种名为 $G^2$-Reader 的双图系统，提升了多模态长文档问答的效果，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于检索增强生成（RAG）的方法，在处理文本、表格、图像交织的长文档时存在两个主要问题：一是常规分块方法破坏了原始文档结构和不同模态间的语义连贯性；二是迭代检索在面对长上下文时容易陷入证据不全的循环或错误漂移，缺乏全局检索状态的持续性和指导性。

Method: 作者提出了 $G^2$-Reader，一个双图系统，包括内容图（Content Graph）和规划图（Planning Graph）。内容图用于保持文档结构和多模态语义的信息；规划图为有向无环图，用于跟踪中间发现并规划证据的逐步搜集，避免只关注当前片段而导致的信息丢失或漂移。

Result: 在VisDoMBench五个多模态领域的数据集评测中，$G^2$-Reader 配合 Qwen3-VL-32B-Instruct 模型，取得了平均66.21%的准确率，显著优于强基线和独立的GPT-5（53.08%）。

Conclusion: $G^2$-Reader 有效解决了多模态长文档问答中的结构与检索瓶颈，显著提升了性能，为相关任务提供了更具稳定性和可解释性的解决方案。

Abstract: Retrieval-augmented generation is a practical paradigm for question answering over long documents, but it remains brittle for multimodal reading where text, tables, and figures are interleaved across many pages. First, flat chunking breaks document-native structure and cross-modal alignment, yielding semantic fragments that are hard to interpret in isolation. Second, even iterative retrieval can fail in long contexts by looping on partial evidence or drifting into irrelevant sections as noise accumulates, since each step is guided only by the current snippet without a persistent global search state. We introduce $G^2$-Reader, a dual-graph system, to address both issues. It evolves a Content Graph to preserve document-native structure and cross-modal semantics, and maintains a Planning Graph, an agentic directed acyclic graph of sub-questions, to track intermediate findings and guide stepwise navigation for evidence completion. On VisDoMBench across five multimodal domains, $G^2$-Reader with Qwen3-VL-32B-Instruct reaches 66.21\% average accuracy, outperforming strong baselines and a standalone GPT-5 (53.08\%).

</details>


### [160] [VTC-R1: Vision-Text Compression for Efficient Long-Context Reasoning](https://arxiv.org/abs/2601.22069)
*Yibo Wang,Yongcheng Jing,Shunyu Liu,Hao Guan,Rong-cheng Tu,Chengyu Wang,Jun Huang,Dacheng Tao*

Main category: cs.CL

TL;DR: VTC-R1提出了一种通过视觉文本压缩提升长上下文推理效率与效果的方法，用于大语言模型。


<details>
  <summary>Details</summary>
Motivation: 长上下文推理虽然增强了大模型能力，但带来了严重的计算效率瓶颈，现有方法受限于复杂训练或外部模型，且容易损失关键信息。作者希望提升模型推理效率且保留信息完整性。

Method: 作者提出VTC-R1范式，将推理过程中的中间文本片段转化为紧凑的图像（光学记忆），再递归输入到视觉语言模型进行推理。并基于OpenR1-Math-220K数据集进行了构建和压缩，同时在Glyph和Qwen3-VL模型上进行微调。

Result: VTC-R1在MATH500、AIME25、AMC23、GPQA-D等基准上超越了传统长上下文推理，达到了3.4倍token压缩，推理速度提升2.7倍。

Conclusion: VTC-R1方法在提升长上下文推理效率的同时还能保持乃至提升推理效果，有望成为大规模推理应用的可扩展解决方案。

Abstract: Long-context reasoning has significantly empowered large language models (LLMs) to tackle complex tasks, yet it introduces severe efficiency bottlenecks due to the computational complexity. Existing efficient approaches often rely on complex additional training or external models for compression, which limits scalability and discards critical fine-grained information. In this paper, we propose VTC-R1, a new efficient reasoning paradigm that integrates vision-text compression into the reasoning process. Instead of processing lengthy textual traces, VTC-R1 renders intermediate reasoning segments into compact images, which are iteratively fed back into vision-language models as "optical memory." We construct a training dataset based on OpenR1-Math-220K achieving 3.4x token compression and fine-tune representative VLMs-Glyph and Qwen3-VL. Extensive experiments on benchmarks such as MATH500, AIME25, AMC23 and GPQA-D demonstrate that VTC-R1 consistently outperforms standard long-context reasoning. Furthermore, our approach significantly improves inference efficiency, achieving 2.7x speedup in end-to-end latency, highlighting its potential as a scalable solution for reasoning-intensive applications. Our code is available at https://github.com/w-yibo/VTC-R1.

</details>


### [161] [ECO: Quantized Training without Full-Precision Master Weights](https://arxiv.org/abs/2601.22101)
*Mahdi Nikdan,Amir Zandieh,Dan Alistarh,Vahab Mirrokni*

Main category: cs.CL

TL;DR: 本文提出了一种名为ECO的优化器，无需高精度主权重即可对量化参数直接进行优化，从而大幅减少大型语言模型训练过程中的内存消耗，尤其适用于稀疏专家混合模型，并在不同任务和参数规模下取得与传统方法近乎无损的效果。


<details>
  <summary>Details</summary>
Motivation: 现有量化训练方法虽然降低了计算和内存成本，但仍需为每个参数保留高精度主权重以累积梯度更新，这给稀疏专家混合等大模型带来了不可忽视的显著内存开销，成为进一步扩展量化训练的瓶颈。

Method: 提出Error-Compensating Optimizer (ECO), 抛弃主权重，直接对量化参数进行更新。每步权重量化后，将量化误差注入优化器动量，形成无需额外内存的误差反馈机制。通过理论证明其收敛性，并在Transformer、Gemma-3、Sparse MoE等多种规模和量化精度模型上进行实证分析。

Result: ECO在小型Transformer（30-800M）、Gemma-3 1B、2.1B参数的Sparse MoE（FP8量化）模型预训练中，以及DeepSeek-MoE-16B INT4精度微调中，均获得了接近有主权重基线的近无损准确率，同时大幅优化了静态内存与验证损失的权衡曲线。

Conclusion: ECO显著减少模型训练过程的内存需求，并在理论和实证层面实现与传统含主权重基线方法近乎相同的收敛与准确效果，有效推动高效大模型量化训练的发展。

Abstract: Quantization has significantly improved the compute and memory efficiency of Large Language Model (LLM) training. However, existing approaches still rely on accumulating their updates in high-precision: concretely, gradient updates must be applied to a high-precision weight buffer, known as $\textit{master weights}$. This buffer introduces substantial memory overhead, particularly for Sparse Mixture of Experts (SMoE) models, where model parameters and optimizer states dominate memory usage. To address this, we introduce the Error-Compensating Optimizer (ECO), which eliminates master weights by applying updates directly to quantized parameters. ECO quantizes weights after each step and carefully injects the resulting quantization error into the optimizer momentum, forming an error-feedback loop with no additional memory. We prove that, under standard assumptions and a decaying learning rate, ECO converges to a constant-radius neighborhood of the optimum, while naive master-weight removal can incur an error that is inversely proportional to the learning rate. We show empirical results for pretraining small Transformers (30-800M), a Gemma-3 1B model, and a 2.1B parameter Sparse MoE model with FP8 quantization, and fine-tuning DeepSeek-MoE-16B in INT4 precision. Throughout, ECO matches baselines with master weights up to near-lossless accuracy, significantly shifting the static memory vs validation loss Pareto frontier.

</details>


### [162] [A Federated and Parameter-Efficient Framework for Large Language Model Training in Medicine](https://arxiv.org/abs/2601.22124)
*Anran Li,Yuanyuan Chen,Wenjun Long,Yu Yin,Yan Hu,Hyunjae Kim,Weipeng Zhou,Yujia Zhou,Hongyi Peng,Yang Ren,Xuguang Ai,Zhenyue Qin,Ming Hu,Xiaoxiao Li,Han Yu,Yih-Chung Tham,Lucila Ohno-Machado,Hua Xu,Qingyu Chen*

Main category: cs.CL

TL;DR: 本文提出了一种高效的联邦学习框架（Fed-MedLoRA及Fed-MedLoRA+），用于在医疗领域适配大型语言模型（LLM），能够有效降低通信与计算负载，并提升模型在异构数据下的泛化性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有医学大型语言模型通常基于单一机构数据训练，缺乏泛化能力和跨机构安全性。传统联邦学习在应对多机构间模型协作时，存在通信成本高和数据异构性的限制，使得难以在医疗领域有效应用LLM。

Method: 提出Fed-MedLoRA，利用模型无关、参数高效的联邦学习策略，仅传递低秩适配器参数，减少通信与计算开销；同时推出Fed-MedLoRA+，通过自适应、数据感知的聚合方法提升跨站数据异构场景下的收敛效果。方法应用于临床信息抽取任务，包含多种评测设置。

Result: 在五个病人队列上与现有BERT、LLaMA-3、DeepSeek-R1和GPT-4o等模型进行了比较，涵盖域内外测试及低资源新站点适应情景。Fed-MedLoRA系列方法在准确性、泛化性、资源效率等方面表现优异。

Conclusion: Fed-MedLoRA及其增强版为LLM在多机构医学场景下的安全高效协作提供了可行方案，有助于提升临床信息抽取等下游任务的性能，并具有良好的推广价值。

Abstract: Large language models (LLMs) have demonstrated strong performance on medical benchmarks, including question answering and diagnosis. To enable their use in clinical settings, LLMs are typically further adapted through continued pretraining or post-training using clinical data. However, most medical LLMs are trained on data from a single institution, which faces limitations in generalizability and safety in heterogeneous systems. Federated learning (FL) is a promising solution for enabling collaborative model development across healthcare institutions. Yet applying FL to LLMs in medicine remains fundamentally limited. First, conventional FL requires transmitting the full model during each communication round, which becomes impractical for multi-billion-parameter LLMs given the limited computational resources. Second, many FL algorithms implicitly assume data homogeneity, whereas real-world clinical data are highly heterogeneous across patients, diseases, and institutional practices. We introduce the model-agnostic and parameter-efficient federated learning framework for adapting LLMs to medical applications. Fed-MedLoRA transmits only low-rank adapter parameters, reducing communication and computation overhead, while Fed-MedLoRA+ further incorporates adaptive, data-aware aggregation to improve convergence under cross-site heterogeneity. We apply the framework to clinical information extraction (IE), which transforms patient narratives into structured medical entities and relations. Accuracy was assessed across five patient cohorts through comparisons with BERT models, and LLaMA-3 and DeepSeek-R1, GPT-4o models. Evaluation settings included (1) in-domain training and testing, (2) external validation on independent cohorts, and (3) a low-resource new-site adaptation scenario using real-world clinical notes from the Yale New Haven Health System.

</details>


### [163] [Reasoning While Asking: Transforming Reasoning Large Language Models from Passive Solvers to Proactive Inquirers](https://arxiv.org/abs/2601.22139)
*Xin Chen,Feng Jiang,Yiqian Zhang,Hardy Chen,Shuo Yan,Wenya Xie,Min Yang,Shujian Huang*

Main category: cs.CL

TL;DR: 本文提出了一种主动交互推理（PIR）范式，改进了现有大语言模型在不确定信息下的推理方式，通过与用户互动而非'盲目自思'，提升了推理准确性和效率，并在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型多采取链式思维（CoT）进行推理，但面对信息缺失或不明确时仍采用“盲目自思”，导致推理低效甚至错误。因此亟需一种能动态获取关键信息并调整推理过程的新范式。

Method: PIR有两个核心组件：一是引入了关注不确定性的监督微调程序，以赋予模型交互式推理能力；二是利用用户模拟器和复合奖励驱动的策略优化框架，使模型行为与用户意图对齐。

Result: 在数学推理、代码生成、文档编辑等任务上，PIR模型相比强基线最多提升32.70%准确率、22.90%通过率、BLEU提升41.36，并大幅减少推理计算量和不必要交互回合。此外，在事实知识、问答、缺前提场景的鲁棒性和泛化性测试中，PIR也表现出色。

Conclusion: PIR有效突破了传统大模型被动解题的局限，能够主动与用户互动以消除推理过程中的不确定性，提升效率和准确性，具有广泛的通用性和实际应用前景。

Abstract: Reasoning-oriented Large Language Models (LLMs) have achieved remarkable progress with Chain-of-Thought (CoT) prompting, yet they remain fundamentally limited by a \emph{blind self-thinking} paradigm: performing extensive internal reasoning even when critical information is missing or ambiguous. We propose Proactive Interactive Reasoning (PIR), a new reasoning paradigm that transforms LLMs from passive solvers into proactive inquirers that interleave reasoning with clarification. Unlike existing search- or tool-based frameworks that primarily address knowledge uncertainty by querying external environments, PIR targets premise- and intent-level uncertainty through direct interaction with the user. PIR is implemented via two core components: (1) an uncertainty-aware supervised fine-tuning procedure that equips models with interactive reasoning capability, and (2) a user-simulator-based policy optimization framework driven by a composite reward that aligns model behavior with user intent. Extensive experiments on mathematical reasoning, code generation, and document editing demonstrate that PIR consistently outperforms strong baselines, achieving up to 32.70\% higher accuracy, 22.90\% higher pass rate, and 41.36 BLEU improvement, while reducing nearly half of the reasoning computation and unnecessary interaction turns. Further reliability evaluations on factual knowledge, question answering, and missing-premise scenarios confirm the strong generalization and robustness of PIR. Model and code are publicly available at: \href{https://github.com/SUAT-AIRI/Proactive-Interactive-R1}

</details>


### [164] [FineInstructions: Scaling Synthetic Instructions to Pre-Training Scale](https://arxiv.org/abs/2601.22146)
*Ajay Patel,Colin Raffel,Chris Callison-Burch*

Main category: cs.CL

TL;DR: 作者提出了一种大规模生成指令-回答训练对的新方法，以弥补现有大语言模型监督数据的不足，并通过FineInstructions数据集显著提升了模型在开放式响应任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型依赖于有限的监督指令数据，难以充分覆盖真实用户需求，因此有必要探索生成更大规模、更贴合实际任务的合成训练数据的方式。

Method: 作者提出利用约1800万个真实用户查询模板，将这些模板与无结构文本中的人类撰写文档匹配、实例化，自动生成数十亿对指令与答案训练样本，形成FineInstructions数据集。随后将大语言模型直接用这些大规模合成指令数据进行训练（指令微调目标），跳过传统的“预测下一个词”自监督预训练。

Result: 实验表明，使用FineInstructions直接进行指令微调预训练，在自由形式问答等下游任务上优于传统的自监督预训练以及其他合成数据方法。

Conclusion: 通过FineInstructions，作者证明了大规模合成指令数据不仅能弥补真实监督数据的不足，还能更好适应模型真实应用场景，提高生成质量。

Abstract: Due to limited supervised training data, large language models (LLMs) are typically pre-trained via a self-supervised "predict the next word" objective on a vast amount of unstructured text data. To make the resulting model useful to users, it is further trained on a far smaller amount of "instruction-tuning" data comprised of supervised training examples of instructions and responses. To overcome the limited amount of supervised data, we propose a procedure that can transform the knowledge in internet-scale pre-training documents into billions of synthetic instruction and answer training pairs. The resulting dataset, called FineInstructions, uses ~18M instruction templates created from real user-written queries and prompts. These instruction templates are matched to and instantiated with human-written source documents from unstructured pre-training corpora. With "supervised" synthetic training data generated at this scale, an LLM can be pre-trained from scratch solely with the instruction-tuning objective, which is far more in-distribution with the expected downstream usage of LLMs (responding to user prompts). We conduct controlled token-for-token training experiments and find pre-training on FineInstructions outperforms standard pre-training and other proposed synthetic pre-training techniques on standard benchmarks measuring free-form response quality. Our resources can be found at https://huggingface.co/fineinstructions .

</details>


### [165] [DynaWeb: Model-Based Reinforcement Learning of Web Agents](https://arxiv.org/abs/2601.22149)
*Hang Ding,Peidong Liu,Junqiao Wang,Ziwei Ji,Meng Cao,Rongzhao Zhang,Lynn Ai,Eric Yang,Tianyu Shi,Lei Yu*

Main category: cs.CL

TL;DR: 本文提出了一种基于模型的强化学习框架DynaWeb，通过在仿真的web环境中训练大模型驱动的自主Web智能体，有效提升了训练效率和性能。


<details>
  <summary>Details</summary>
Motivation: 当前利用大语言模型和强化学习训练自主Web代理面临与真实互联网交互的高成本、低效率以及风险等问题。急需一种能代替真实互联网交互、提升训练效率且更可控的方法。

Method: 提出DynaWeb框架：首先训练一个web世界模型，能根据智能体动作预测网页状态，然后利用该模型作为仿真环境生成大量行为轨迹，供在线强化学习训练。同时，引入真实专家轨迹并随机混插于训练中，提升算法稳定性与采样效率。

Result: 在WebArena和WebVoyager等复杂基准测试上，DynaWeb大幅并稳定提升了主流开源Web智能体模型的表现。

Conclusion: 证明了基于想象的web环境强化学习是可行且高效的，为大规模自主Web智能体训练指明了新方向。

Abstract: The development of autonomous web agents, powered by Large Language Models (LLMs) and reinforcement learning (RL), represents a significant step towards general-purpose AI assistants. However, training these agents is severely hampered by the challenges of interacting with the live internet, which is inefficient, costly, and fraught with risks. Model-based reinforcement learning (MBRL) offers a promising solution by learning a world model of the environment to enable simulated interaction. This paper introduces DynaWeb, a novel MBRL framework that trains web agents through interacting with a web world model trained to predict naturalistic web page representations given agent actions. This model serves as a synthetic web environment where an agent policy can dream by generating vast quantities of rollout action trajectories for efficient online reinforcement learning. Beyond free policy rollouts, DynaWeb incorporates real expert trajectories from training data, which are randomly interleaved with on-policy rollouts during training to improve stability and sample efficiency. Experiments conducted on the challenging WebArena and WebVoyager benchmarks demonstrate that DynaWeb consistently and significantly improves the performance of state-of-the-art open-source web agent models. Our findings establish the viability of training web agents through imagination, offering a scalable and efficient way to scale up online agentic RL.

</details>


### [166] [Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts](https://arxiv.org/abs/2601.22156)
*Yingfa Chen,Zhen Leng Thai,Zihan Zhou,Zhu Zhang,Xingyu Shen,Shuo Wang,Chaojun Xiao,Xu Han,Zhiyuan Liu*

Main category: cs.CL

TL;DR: 本论文提出了一种将Transformer模型高效转换为RNN-Transformer混合架构的方案，并在长上下文任务中取得了优于传统模型的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 传统的Hybrid Transformer架构需要大量预训练数据，训练成本高，而且现有参数迁移方法在长上下文情况表现不佳，因此实际应用受限。作者希望找到数据效率高、性能优良的混合架构迁移方案。

Method: 提出HALO管线用于高效蒸馏Transformer为RNN-Transformer混合模型，并设计新型的位置编码HyPE和多项结构优化，得到HypeNet混合架构。通过HALO，只需2.3B token即可完成参数迁移。

Result: 用2.3B token将Qwen3系列高效转换为HypeNet混合模型，新模型在长上下文性能和推理吞吐量上优于原始Transformer，性能与原模型相当。

Conclusion: HALO和HypeNet证明了通过高效蒸馏和架构创新，可以用极小的数据成本获得高性能、适合长上下文和高吞吐需求的混合模型，有望大幅降低大模型迁移与部署门槛。

Abstract: Hybrid Transformer architectures, which combine softmax attention blocks and recurrent neural networks (RNNs), have shown a desirable performance-throughput tradeoff for long-context modeling, but their adoption and studies are hindered by the prohibitive cost of large-scale pre-training from scratch. Some recent studies have shown that pre-trained softmax attention blocks can be converted into RNN blocks through parameter transfer and knowledge distillation. However, these transfer methods require substantial amounts of training data (more than 10B tokens), and the resulting hybrid models also exhibit poor long-context performance, which is the scenario where hybrid models enjoy significant inference speedups over Transformer-based models. In this paper, we present HALO (Hybrid Attention via Layer Optimization), a pipeline for distilling Transformer models into RNN-attention hybrid models. We then present HypeNet, a hybrid architecture with superior length generalization enabled by a novel position encoding scheme (named HyPE) and various architectural modifications. We convert the Qwen3 series into HypeNet using HALO, achieving performance comparable to the original Transformer models while enjoying superior long-context performance and efficiency. The conversion requires just 2.3B tokens, less than 0.01% of their pre-training data

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [167] [Quick Heuristic Validation of Edges in Dynamic Roadmap Graphs](https://arxiv.org/abs/2601.20968)
*Yulie Arad,Stav Ashur,Nancy M. Amato*

Main category: cs.RO

TL;DR: 本文提出了一种适用于动态环境下机器人路径规划的路线图调整方法，通过红-绿-灰范式对路线图进行快速、低成本的有效性标记与更新。


<details>
  <summary>Details</summary>
Motivation: 传统的路线图方法多适用于静态环境，难以高效应对环境变化，需要更有效的动态路线图更新策略。

Method: 借鉴SPITE方法，提出“红-绿-灰”范式。通过简单的计算几何方法近似机器人扫掠体积，利用廉价启发式对路线图节点和边进行碰撞检查，并将边标记为无效（红）、有效（绿）或未知（灰）以便半懒惰地更新路线图。

Result: 与Leven和Hutchinson经典方法对比，本文方法在保证更新效率的基础上，提升了有效性标记的准确率，能更好地区分和剔除无效边。

Conclusion: 红-绿-灰范式能实现更高效、准确的动态环境路线图维护，是面向动态环境机器人路径规划的有前景的路线图更新策略。

Abstract: In this paper we tackle the problem of adjusting roadmap graphs for robot motion planning to non-static environments. We introduce the "Red-Green-Gray" paradigm, a modification of the SPITE method, capable of classifying the validity status of nodes and edges using cheap heuristic checks, allowing fast semi-lazy roadmap updates. Given a roadmap, we use simple computational geometry methods to approximate the swept volumes of robots and perform lazy collision checks, and label a subset of the edges as invalid (red), valid (green), or unknown (gray). We present preliminary experimental results comparing our method to the well-established technique of Leven and Hutchinson, and showing increased accuracy as well as the ability to correctly label edges as invalid while maintaining comparable update runtimes.

</details>


### [168] [Meta-ROS: A Next-Generation Middleware Architecture for Adaptive and Scalable Robotic Systems](https://arxiv.org/abs/2601.21011)
*Anshul Ranjan,Anoosh Damodar,Neha Chougule,Dhruva S Nayak,Anantharaman P. N,Shylaja S S*

Main category: cs.RO

TL;DR: 提出了一种新型机器人中间件Meta-ROS，旨在简化集成流程、提升性能并支持多平台互操作性。在性能测试中，Meta-ROS相较于ROS2展现出更高的吞吐量和更低的延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人中间件如ROS2复杂且难以上手，影响开发者的使用效率和系统互操作性，需要一种更加简洁高效、兼容性更强的新型中间件。

Method: 开发了一种名为Meta-ROS的中间件，采用现代通信协议如Zenoh和ZeroMQ，支持多种数据类型、高效低延迟跨硬件通信，并且提升了硬件兼容性和开发者易用性。通过与ROS1和ROS2的对比实验评测其性能。

Result: Meta-ROS在吞吐量上比ROS2高30%，显著降低了消息延迟，同时优化了资源利用率。

Conclusion: Meta-ROS以优秀的性能、兼容性和开发友好特性，成为现代实时机器人AI应用理想的中间件解决方案。

Abstract: The field of robotics faces significant challenges related to the complexity and interoperability of existing middleware frameworks, like ROS2, which can be difficult for new developers to adopt. To address these issues, we propose Meta-ROS, a novel middleware solution designed to streamline robotics development by simplifying integration, enhancing performance, and ensuring cross-platform compatibility. Meta-ROS leverages modern communication protocols, such as Zenoh and ZeroMQ, to enable efficient and low-latency communication across diverse hardware platforms, while also supporting various data types like audio, images, and video. We evaluated Meta-ROS's performance through comprehensive testing, comparing it with existing middleware frameworks like ROS1 and ROS2. The results demonstrated that Meta-ROS outperforms ROS2, achieving up to 30% higher throughput, significantly reducing message latency, and optimizing resource usage. Additionally, its robust hardware support and developer-centric design facilitate seamless integration and ease of use, positioning Meta-ROS as an ideal solution for modern, real-time robotics AI applications.

</details>


### [169] [Track-centric Iterative Learning for Global Trajectory Optimization in Autonomous Racing](https://arxiv.org/abs/2601.21027)
*Youngim Nam,Jungbin Kim,Kyungtae Kang,Cheolhyeon Kwon*

Main category: cs.RO

TL;DR: 该论文提出了一种用于自动驾驶赛车在不确定动力学下最小化单圈时间的全局轨迹优化框架，通过贝叶斯优化和仿真-实测迭代实现了轨迹和车辆动力模型的协同学习与提升，实验结果显示新方法大幅优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶赛车在轨迹优化时面临计算量大和动力学不确定性的问题，现有方法往往仅在跟踪控制层面进行模型学习，未能将学习到的动力学及时反馈修正轨迹，因此无法保证全局最优。

Method: 作者采用基于小波变换的参数空间来对轨迹进行泛化表达，在贝叶斯优化框架下高效搜索全局轨迹，同时将动力学学习和轨迹优化嵌入到交替迭代的学习框架中，通过仿真和实车实验相结合不断提升性能。

Result: 在仿真和真实赛车实验下，该框架实现了相较于名义基线方案最多20.7%的单圈时间优化，并且持续优于当下先进方法。

Conclusion: 提出的全局轨迹优化框架有效结合了动力学学习与轨迹更新，实现了自动驾驶赛车在不确定环境下单圈时间的显著降低，验证了其优越性和实用价值。

Abstract: This paper presents a global trajectory optimization framework for minimizing lap time in autonomous racing under uncertain vehicle dynamics. Optimizing the trajectory over the full racing horizon is computationally expensive, and tracking such a trajectory in the real world hardly assures global optimality due to uncertain dynamics. Yet, existing work mostly focuses on dynamics learning at the tracking level, without updating the trajectory itself to account for the learned dynamics. To address these challenges, we propose a track-centric approach that directly learns and optimizes the full-horizon trajectory. We first represent trajectories through a track-agnostic parametric space in light of the wavelet transform. This space is then efficiently explored using Bayesian optimization, where the lap time of each candidate is evaluated by running simulations with the learned dynamics. This optimization is embedded in an iterative learning framework, where the optimized trajectory is deployed to collect real-world data for updating the dynamics, progressively refining the trajectory over the iterations. The effectiveness of the proposed framework is validated through simulations and real-world experiments, demonstrating lap time improvement of up to 20.7% over a nominal baseline and consistently outperforming state-of-the-art methods.

</details>


### [170] [Multi-Robot Decentralized Collaborative SLAM in Planetary Analogue Environments: Dataset, Challenges, and Lessons Learned](https://arxiv.org/abs/2601.21063)
*Pierre-Yves Lajoie,Karthik Soma,Haechan Mark Bong,Alice Lemieux-Bourque,Rongge Zhang,Vivek Shankar Varadharajan,Giovanni Beltrame*

Main category: cs.RO

TL;DR: 论文介绍了三台机器人在类火星地形条件下，利用临时网络进行去中心化协作定位与建图（C-SLAM）实验，并发布了相关通信参数数据集。


<details>
  <summary>Details</summary>
Motivation: 为了实现多机器人在未知行星环境下自主协作，无需依赖预先部署的定位与通信设施，C-SLAM技术尤为关键，尤其适用于月球、火星等空间探索任务。

Method: 在类火星地形上组织三台机器人，通过自组网络进行C-SLAM实验，系统性分析有限与间歇性通信对系统性能的影响，并收集并公布了机器人间实时通信吞吐和时延数据。

Result: 实验揭示了行星类场景中通信受限和易中断对C-SLAM性能的影响，表明在这些极端条件下的定位和建图面临独特挑战，并首次公开对应的高价值数据集。

Conclusion: 受限通信条件下的去中心化多机器人SLAM在行星探索中具有实际应用前景；发布的数据集为后续相关领域研究提供了基础。

Abstract: Decentralized collaborative simultaneous localization and mapping (C-SLAM) is essential to enable multirobot missions in unknown environments without relying on preexisting localization and communication infrastructure. This technology is anticipated to play a key role in the exploration of the Moon, Mars, and other planets. In this article, we share insights and lessons learned from C-SLAM experiments involving three robots operating on a Mars analogue terrain and communicating over an ad hoc network. We examine the impact of limited and intermittent communication on C-SLAM performance, as well as the unique localization challenges posed by planetary-like environments. Additionally, we introduce a novel dataset collected during our experiments, which includes real-time peer-to-peer inter-robot throughput and latency measurements. This dataset aims to support future research on communication-constrained, decentralized multirobot operations.

</details>


### [171] [WheelArm-Sim: A Manipulation and Navigation Combined Multimodal Synthetic Data Generation Simulator for Unified Control in Assistive Robotics](https://arxiv.org/abs/2601.21129)
*Guangping Liu,Tipu Sultan,Vittorio Di Giorgio,Nick Hawkins,Flavio Esposito,Madi Babaiasl*

Main category: cs.RO

TL;DR: 提出了一种集成轮椅和机械臂控制的新系统WheelArm，并开发了一个仿真框架WheelArm-Sim用于合成数据收集，验证了其对集成控制数据驱动机器学习模型的可行性。


<details>
  <summary>Details</summary>
Motivation: 当前辅助机器人领域，虽然轮椅和轮椅机械臂有很多进展，但对两者一体化和统一控制的研究较少，尤其是在利用机器学习模型实现集成控制方面存在空白。为实现更高效的辅助功能与自主生活，亟需统一系统与数据支持。

Method: 提出WheelArm集成控制系统概念，并在Isaac Sim环境下开发仿真平台WheelArm-Sim，收集包含导航和操作的多模态数据集（13项任务，232条轨迹，67783条样本），并在芥末酱抓取任务上建立基线动作预测模型，检验数据和模型的可行性。

Result: 成功收集了WheelArm-Sim的多模态集成数据集，并通过基线模型实验验证了该数据集支持数据驱动的机器学习集成控制。

Conclusion: WheelArm-Sim为推动轮椅与机械臂集成控制研究提供了实用的数据和平台支撑，为未来无障碍辅助机器人的智能化研究奠定了基础。

Abstract: Wheelchairs and robotic arms enhance independent living by assisting individuals with upper-body and mobility limitations in their activities of daily living (ADLs). Although recent advancements in assistive robotics have focused on Wheelchair-Mounted Robotic Arms (WMRAs) and wheelchairs separately, integrated and unified control of the combination using machine learning models remains largely underexplored. To fill this gap, we introduce the concept of WheelArm, an integrated cyber-physical system (CPS) that combines wheelchair and robotic arm controls. Data collection is the first step toward developing WheelArm models. In this paper, we present WheelArm-Sim, a simulation framework developed in Isaac Sim for synthetic data collection. We evaluate its capability by collecting a manipulation and navigation combined multimodal dataset, comprising 13 tasks, 232 trajectories, and 67,783 samples. To demonstrate the potential of the WheelArm dataset, we implement a baseline model for action prediction in the mustard-picking task. The results illustrate that data collected from WheelArm-Sim is feasible for a data-driven machine learning model for integrated control.

</details>


### [172] [InspecSafe-V1: A Multimodal Benchmark for Safety Assessment in Industrial Inspection Scenarios](https://arxiv.org/abs/2601.21173)
*Zeyi Liu,Shuang Liu,Jihai Min,Zhaoheng Zhang,Jun Cen,Pengyu Han,Songqiao Hu,Zihan Meng,Xiao He,Donghua Zhou*

Main category: cs.RO

TL;DR: 本文发布了InspecSafe-V1，这是首个面向工业巡检安全评估的多模态基准数据集，涵盖真实工业场景和多种感知模态，支持细粒度目标识别和多模态安全推理。


<details>
  <summary>Details</summary>
Motivation: 现有的公开数据集多局限于模拟数据、单一模态或缺乏精细标注，难以满足复杂工业环境下基础模型的稳健感知和多模态安全推理需求，成为部署AI巡检和预测性维护的瓶颈。

Method: 作者采集了41台巡检机器人在五类真实工业场景的2,239个有效作业点的5,013条巡检实例，每例提供可见光图像的像素级分割注释、场景语义描述与安全等级标签，并同步采集红外、音频、深度、雷达、气体、温湿度等七种传感器数据，实现多模态、多层次标注。

Result: 数据集包含丰富多样的工业环境、细致的目标级分割和丰富的多模态同步数据，能够支持多模态异常识别、跨模态融合和安全评估等任务。

Conclusion: InspecSafe-V1可作为工业AI安全评估与多模态理解的关键基准，有助于推动预测性维护和自主巡检等应用研究的进步。

Abstract: With the rapid development of industrial intelligence and unmanned inspection, reliable perception and safety assessment for AI systems in complex and dynamic industrial sites has become a key bottleneck for deploying predictive maintenance and autonomous inspection. Most public datasets remain limited by simulated data sources, single-modality sensing, or the absence of fine-grained object-level annotations, which prevents robust scene understanding and multimodal safety reasoning for industrial foundation models. To address these limitations, InspecSafe-V1 is released as the first multimodal benchmark dataset for industrial inspection safety assessment that is collected from routine operations of real inspection robots in real-world environments. InspecSafe-V1 covers five representative industrial scenarios, including tunnels, power facilities, sintering equipment, oil and gas petrochemical plants, and coal conveyor trestles. The dataset is constructed from 41 wheeled and rail-mounted inspection robots operating at 2,239 valid inspection sites, yielding 5,013 inspection instances. For each instance, pixel-level segmentation annotations are provided for key objects in visible-spectrum images. In addition, a semantic scene description and a corresponding safety level label are provided according to practical inspection tasks. Seven synchronized sensing modalities are further included, including infrared video, audio, depth point clouds, radar point clouds, gas measurements, temperature, and humidity, to support multimodal anomaly recognition, cross-modal fusion, and comprehensive safety assessment in industrial environments.

</details>


### [173] [Disturbance-Aware Flight Control of Robotic Gliding Blimp via Moving Mass Actuation](https://arxiv.org/abs/2601.21188)
*Hao Cheng,Feitian Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种针对机器人飞艇在风扰环境下的自适应控制方法，有效提升其抗风扰能力。


<details>
  <summary>Details</summary>
Motivation: 机器人飞艇具有长续航和本质安全等优点，但对风扰动极为敏感，现有控制方法难以充分补偿风的影响。因此，亟需能实时感知及补偿风扰动的控制框架，提高飞艇实际应用性。

Method: 作者设计了一种结合移动视界估计器（MHE）与模型预测控制器（MPC）的控制体系。MHE实时估算风扰，MPC则根据估算结果调控平台轨迹与航向。同时，平台采用了双自由度动质量机构以实现姿态及航向控制。

Result: 在顺风和侧风等多种典型扰动条件下，通过飞行实验验证，提出的MHE-MPC框架表现优于传统PID控制，显著增强了机器人飞艇的抗扰能力与稳定性。

Conclusion: 所提方法能够实现对机器人飞艇的风扰感知及补偿，显著提升其在复杂环境下的飞行性能，为LTA平台的实际应用提供了重要支持。

Abstract: Robotic blimps, as lighter-than-air (LTA) aerial systems, offer long endurance and inherently safe operation but remain highly susceptible to wind disturbances. Building on recent advances in moving mass actuation, this paper addresses the lack of disturbance-aware control frameworks for LTA platforms by explicitly modeling and compensating for wind-induced effects. A moving horizon estimator (MHE) infers real-time wind perturbations and provides these estimates to a model predictive controller (MPC), enabling robust trajectory and heading regulation under varying wind conditions. The proposed approach leverages a two-degree-of-freedom (2-DoF) moving-mass mechanism to generate both inertial and aerodynamic moments for attitude and heading control, thereby enhancing flight stability in disturbance-prone environments. Extensive flight experiments under headwind and crosswind conditions show that the integrated MHE-MPC framework significantly outperforms baseline PID control, demonstrating its effectiveness for disturbance-aware LTA flight.

</details>


### [174] [Abstracting Robot Manipulation Skills via Mixture-of-Experts Diffusion Policies](https://arxiv.org/abs/2601.21251)
*Ce Hao,Xuanran Zhai,Yaohua Liu,Harold Soh*

Main category: cs.RO

TL;DR: 提出了一种新的基于扩散模型的混合专家策略（SMP），能在多任务机器人操作中高效复用技能，降低模型规模和推理成本，实验证明性能优于其他大型扩散模型。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的机器人策略在单任务表现优异，但多任务扩展受限于模型参数增长和示范样本的高要求，亟需一种能高效复用技能、减少资源消耗的方法。

Method: 提出Skill Mixture-of-Experts Policy（SMP）方法，利用混合专家框架学习正交的精炼技能基，通过'粘性路由'机制让每一步仅激活少量相关专家，并采用变分训练目标和推理时动态激活专家以加快采样速度，降低算力消耗。

Result: SMP在模拟和真实双臂机器人平台上的多任务学习和迁移任务中测试，表现出更高成功率且推理成本明显低于传统大型扩散模型基线。

Conclusion: SMP为可扩展和可迁移的多任务机器人操作提供了实用路径，可一次性学习可复用技能，根据需求激活少量专家，并能快速适应新任务。

Abstract: Diffusion-based policies have recently shown strong results in robot manipulation, but their extension to multi-task scenarios is hindered by the high cost of scaling model size and demonstrations. We introduce Skill Mixture-of-Experts Policy (SMP), a diffusion-based mixture-of-experts policy that learns a compact orthogonal skill basis and uses sticky routing to compose actions from a small, task-relevant subset of experts at each step. A variational training objective supports this design, and adaptive expert activation at inference yields fast sampling without oversized backbones. We validate SMP in simulation and on a real dual-arm platform with multi-task learning and transfer learning tasks, where SMP achieves higher success rates and markedly lower inference cost than large diffusion baselines. These results indicate a practical path toward scalable, transferable multi-task manipulation: learn reusable skills once, activate only what is needed, and adapt quickly when tasks change.

</details>


### [175] [Deep QP Safety Filter: Model-free Learning for Reachability-based Safety Filter](https://arxiv.org/abs/2601.21297)
*Byeongjun Kim,H. Jin Kim*

Main category: cs.RO

TL;DR: 本文提出了一种基于深度学习的QP安全过滤器（Deep QP Safety Filter），能在无模型条件下为黑盒动力系统提供安全保障，并在多种RL任务中显著提升了学习速度与安全性。


<details>
  <summary>Details</summary>
Motivation: 传统安全过滤方法往往依赖于动力学系统的精确建模，对于实际中难以建模的复杂或混合动力系统难以适用。因此，亟需一种无需模型知识、能够对黑盒系统提供有效安全保障的方法。

Method: 本方法结合了Hamilton-Jacobi (HJ) 可达性理论和无模型学习，通过构造关于安全值及其导数的收缩型损失，训练两个神经网络，实现了对安全Q函数和其导数的逼近，最终将其用于学习和实现QP安全过滤。

Result: 实验覆盖多种动力系统与强化学习任务，包括混合系统。结果表明，Deep QP Safety Filter能大幅减少训练早期的失败案例，加速收敛并在最终结果上优于多种强化基线方法。

Conclusion: Deep QP Safety Filter为模型不可知的安全控制提供了一种高效、可靠且通用的解决办法，适用于实际中复杂的未知动力系统，兼具理论严谨性和实际可操作性。

Abstract: We introduce Deep QP Safety Filter, a fully data-driven safety layer for black-box dynamical systems. Our method learns a Quadratic-Program (QP) safety filter without model knowledge by combining Hamilton-Jacobi (HJ) reachability with model-free learning. We construct contraction-based losses for both the safety value and its derivatives, and train two neural networks accordingly. In the exact setting, the learned critic converges to the viscosity solution (and its derivative), even for non-smooth values. Across diverse dynamical systems -- even including a hybrid system -- and multiple RL tasks, Deep QP Safety Filter substantially reduces pre-convergence failures while accelerating learning toward higher returns than strong baselines, offering a principled and practical route to safe, model-free control.

</details>


### [176] [HPTune: Hierarchical Proactive Tuning for Collision-Free Model Predictive Control](https://arxiv.org/abs/2601.21346)
*Wei Zuo,Chengyang Li,Yikun Wang,Bingyang Cheng,Zeyi Ren,Shuai Wang,Derrick Wing Kwan Ng,Yik-Chung Wu*

Main category: cs.RO

TL;DR: 该论文提出了一种层次化主动参数调优（HPTune）框架，提升了MPC运动规划器在复杂环境下的安全性和灵活性。通过对已执行和未执行动作的评估，结合多层次调优与Doppler LiDAR增强感知，实现了更高效的MPC参数更新，优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有MPC运动规划参数调优方法只关注已执行动作，因失败事件（如碰撞）稀疏，导致调优效率低，缺乏适应性。因此，提升MPC在复杂动态环境下适应性和安全性成为迫切需求。

Method: 提出HPTune框架，将参数调优分为快、慢两个层次：快调优利用预测接近速度和预测接近距离作为风险指标，慢调优则借助扩展评估损失进行闭环反向传播。同时，结合Doppler LiDAR传感器获得的障碍物速度信息，提高运动预测精度。

Result: 在高保真模拟环境中进行大量实验，结果显示，HPTune能够高效调优MPC参数，在复杂环境下优于传统调优方案，展现出更强的适应性和规避能力。

Conclusion: HPTune能够实现情境自适应的运动规划，提升系统安全性和灵活性，为自动驾驶等领域MPC参数调优提供了新的思路。

Abstract: Parameter tuning is a powerful approach to enhance adaptability in model predictive control (MPC) motion planners. However, existing methods typically operate in a myopic fashion that only evaluates executed actions, leading to inefficient parameter updates due to the sparsity of failure events (e.g., obstacle nearness or collision). To cope with this issue, we propose to extend evaluation from executed to non-executed actions, yielding a hierarchical proactive tuning (HPTune) framework that combines both a fast-level tuning and a slow-level tuning. The fast one adopts risk indicators of predictive closing speed and predictive proximity distance, and the slow one leverages an extended evaluation loss for closed-loop backpropagation. Additionally, we integrate HPTune with the Doppler LiDAR that provides obstacle velocities apart from position-only measurements for enhanced motion predictions, thus facilitating the implementation of HPTune. Extensive experiments on high-fidelity simulator demonstrate that HPTune achieves efficient MPC tuning and outperforms various baseline schemes in complex environments. It is found that HPTune enables situation-tailored motion planning by formulating a safe, agile collision avoidance strategy.

</details>


### [177] [Towards Bridging the Gap between Large-Scale Pretraining and Efficient Finetuning for Humanoid Control](https://arxiv.org/abs/2601.21363)
*Weidong Huang,Zhehan Li,Hangxin Liu,Biao Hou,Yao Su,Jingwen Zhang*

Main category: cs.RO

TL;DR: 该论文提出结合大批量更新和高UTD比率的SAC算法，在大型并行仿真中进行人形机器人控制策略的预训练，并结合基于模型的方法实现高效微调与安全适应，最终在真实机器人上实现零样本部署。


<details>
  <summary>Details</summary>
Motivation: 现有基于策略的强化学习方法（如PPO）在训练人形机器人时样本效率低，限制了新环境中的安全适应。虽然离策略和基于模型的RL提高了样本效率，但在大规模预训练与高效微调之间仍存在差距。

Method: 采用离策略的SAC算法，结合大批量更新与高UTD比率进行大规模预训练，实现真实机器人零样本部署。在新环境适应阶段，利用基于模型的方法，数据收集时用确定性策略，仅在世界模型中做随机探索，降低实际探索风险。

Result: SAC可稳定支持大规模人形机器人策略预训练，实现真实机器人零样本部署。预训练模型可在新环境、分布外任务中通过基于模型的方法高效且安全地微调和适应。

Conclusion: 该方法将大规模仿真预训练的效率与基于模型微调的样本效率相结合，实现了高效且安全的人形机器人运动控制，为该领域大规模实际应用奠定基础。

Abstract: Reinforcement learning (RL) is widely used for humanoid control, with on-policy methods such as Proximal Policy Optimization (PPO) enabling robust training via large-scale parallel simulation and, in some cases, zero-shot deployment to real robots. However, the low sample efficiency of on-policy algorithms limits safe adaptation to new environments. Although off-policy RL and model-based RL have shown improved sample efficiency, the gap between large-scale pretraining and efficient finetuning on humanoids still exists. In this paper, we find that off-policy Soft Actor-Critic (SAC), with large-batch update and a high Update-To-Data (UTD) ratio, reliably supports large-scale pretraining of humanoid locomotion policies, achieving zero-shot deployment on real robots. For adaptation, we demonstrate that these SAC-pretrained policies can be finetuned in new environments and out-of-distribution tasks using model-based methods. Data collection in the new environment executes a deterministic policy while stochastic exploration is instead confined to a physics-informed world model. This separation mitigates the risks of random exploration during adaptation while preserving exploratory coverage for improvement. Overall, the approach couples the wall-clock efficiency of large-scale simulation during pretraining with the sample efficiency of model-based learning during fine-tuning.

</details>


### [178] [Towards Space-Based Environmentally-Adaptive Grasping](https://arxiv.org/abs/2601.21394)
*Leonidas Askianakis,Aleksandr Artemov*

Main category: cs.RO

TL;DR: 本文提出了一种多模态融合的潜空间强化学习方法，在复杂环境下实现高效可靠的机器人抓取任务，并展现出优于现有方法的收敛速度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前机器人在非结构化环境下操作存在高维动作空间、稀疏奖励和泛化能力差等瓶颈，特别是在实际应用（如太空抓取）中表现不足。针对这些问题，作者希望通过提升策略学习的效率和泛化，推动机器人更好地适应多变场景。

Method: 作者提出在一个融合多模态信息的潜空间上直接学习抓取策略，通过GPU加速模拟实现任务，并采用Soft Actor-Critic（SAC）强化学习算法，比对不同条件下的收敛速度与表现。实验在持续变化的抓取环境下进行，无需人工精细设计情景。

Result: 在不到100万个环境步长内，实现了超过95%的抓取任务成功率，并且在收敛速度和适应性方面，明显优于其他视觉基线算法。实验还验证了对新物体、不同机械手、环境杂乱和传感配置等变化具备更强鲁棒性。

Conclusion: 在潜空间进行策略推理显著提升了学习效率和泛化能力，尽管仍存在一些尚待突破的局限（如极端复杂空间环境下的完全自适应性），但该方法为实现更通用和可靠的机器人操作奠定基础。

Abstract: Robotic manipulation in unstructured environments requires reliable execution under diverse conditions, yet many state-of-the-art systems still struggle with high-dimensional action spaces, sparse rewards, and slow generalization beyond carefully curated training scenarios. We study these limitations through the example of grasping in space environments. We learn control policies directly in a learned latent manifold that fuses (grammarizes) multiple modalities into a structured representation for policy decision-making. Building on GPU-accelerated physics simulation, we instantiate a set of single-shot manipulation tasks and achieve over 95% task success with Soft Actor-Critic (SAC)-based reinforcement learning in less than 1M environment steps, under continuously varying grasping conditions from step 1. This empirically shows faster convergence than representative state-of-the-art visual baselines under the same open-loop single-shot conditions. Our analysis indicates that explicitly reasoning in latent space yields more sample-efficient learning and improved robustness to novel object and gripper geometries, environmental clutter, and sensor configurations compared to standard baselines. We identify remaining limitations and outline directions toward fully adaptive and generalizable grasping in the extreme conditions of space.

</details>


### [179] [DSCD-Nav: Dual-Stance Cooperative Debate for Object Navigation](https://arxiv.org/abs/2601.21409)
*Weitao An,Qi Liu,Chenghao Xu,Jiayi Chai,Xu Yang,Kun Wei,Cheng Deng*

Main category: cs.RO

TL;DR: 本论文提出了一种新型的室内导航决策机制——DSCD-Nav，通过模拟“合作辩论”替代传统单次打分策略，提高了机器人在未知环境下的导航效果和效率。


<details>
  <summary>Details</summary>
Motivation: 目前基于视觉-语言模型的导航系统在处理未见过的环境时，决策层采用单次打分方式，容易出现长期路径上的过度自信和重复性探索，影响实际导航效果。

Method: 作者提出Dual-Stance Cooperative Debate Navigation（DSCD-Nav）机制：同一时刻下，系统构建两个基于不同目标的评估立场——任务-场景理解（TSU，关注目标推进）和安全-信息平衡（SIB，关注风险及信息价值）。两者通过“合作辩论”互查优选动作（附带理由），再由“导航共识仲裁（NCA）代理”整合双方理由与证据，并在不确定时触发轻量探测以协助决策。

Result: 在HM3Dv1、HM3Dv2与MP3D室内环境数据集上实验显示，该方法显著提升了导航成功率与路径效率，并有效减少了无效探索。

Conclusion: DSCD-Nav通过引入多立场协同决策和微探测机制，增强了零样本导航的鲁棒性和效率，为家庭服务机器人在未知环境自主导航提供了更有前景的解决方案。

Abstract: Adaptive navigation in unfamiliar indoor environments is crucial for household service robots. Despite advances in zero-shot perception and reasoning from vision-language models, existing navigation systems still rely on single-pass scoring at the decision layer, leading to overconfident long-horizon errors and redundant exploration. To tackle these problems, we propose Dual-Stance Cooperative Debate Navigation (DSCD-Nav), a decision mechanism that replaces one-shot scoring with stance-based cross-checking and evidence-aware arbitration to improve action reliability under partial observability. Specifically, given the same observation and candidate action set, we explicitly construct two stances by conditioning the evaluation on diverse and complementary objectives: a Task-Scene Understanding (TSU) stance that prioritizes goal progress from scene-layout cues, and a Safety-Information Balancing (SIB) stance that emphasizes risk and information value. The stances conduct a cooperative debate and make policy by cross-checking their top candidates with cue-grounded arguments. Then, a Navigation Consensus Arbitration (NCA) agent is employed to consolidate both sides' reasons and evidence, optionally triggering lightweight micro-probing to verify uncertain choices, preserving NCA's primary intent while disambiguating. Experiments on HM3Dv1, HM3Dv2, and MP3D demonstrate consistent improvements in success and path efficiency while reducing exploration redundancy.

</details>


### [180] [Singularity-Free Lie Group Integration and Geometrically Consistent Evaluation of Multibody System Models Described in Terms of Standard Absolute Coordinates](https://arxiv.org/abs/2601.21413)
*Andreas Mueller*

Main category: cs.RO

TL;DR: 本文提出了一种将李群（Lie group）积分方法与常规多体系统（MBS）动力学方程（EOM）建模兼容的框架，解决了当前基于绝对坐标建模采用李群积分方法时面临的不兼容性问题。


<details>
  <summary>Details</summary>
Motivation: 在多体系统动力学模拟中，常用绝对坐标法建模，但在时间积分过程中空间运动参数化存在奇异性，常用单位四元数回避，但也存在一定局限性。李群积分法可无奇异性集成空间运动几何，为动力学仿真提供更自然的描述，但与现有EOM标准实现方式不兼容，推广受限。

Method: (1) 提出了一个可将李群积分器与标准EOM绝对坐标实现对接的通用接口框架，实现两者兼容。（2）给出将刚体运动空间几何性质一致性地融入绝对坐标EOM求解的方案。具体采用SO(3)xR3直积、SE(3)半直积等李群表示刚体运动，利用局部-全局转换（LGT）映射，根据李群上的局部坐标更新全局绝对坐标。

Result: 该框架可实现多种绝对坐标描述的多体系统动力学与李群积分法的无缝衔接，可以方便地在现有仿真环境中利用李群方法进行无奇异积分，无需对原有代码进行大规模重构。

Conclusion: 该方法为多体系统动力学仿真提供了一个兼容、高鲁棒性的时间积分新方案，解决了长期以来的参数化奇异性与实现兼容性问题，有助于推广李群法在MBS仿真领域的应用。

Abstract: A classical approach to the multibody systems (MBS) modeling is to use absolute coordinates, i.e., a set of (possibly redundant) coordinates that describe the absolute position and orientation of the individual bodies with respect to an inertial frame (IFR). A well-known problem for the time integration of the equations of motion (EOM) is the lack of a singularity-free parameterization of spatial motions, which is usually tackled by using unit quaternions. Lie group integration methods were proposed as an alternative approach to the singularity-free time integration. At the same time, Lie group formulations of EOM naturally respect the geometry of spatial motions during integration. Lie group integration methods, operating directly on the configuration space Lie group, are incompatible with standard formulations of the EOM, and cannot be implemented in existing MBS simulation codes without a major restructuring. The contribution of this paper is twofold: (1) A framework for interfacing Lie group integrators to standard EOM formulations is presented. It allows describing MBS in terms of various absolute coordinates and at the same using Lie group integration schemes. (2) A method for consistently incorporating the geometry of rigid body motions into the evaluation of EOM in absolute coordinates integrated with standard vector space integration schemes. The direct product group and the semidirect product group SO(3)xR3 and the semidirect product group SE(3) are used for representing rigid body motions. The key element is the local-global transitions (LGT) transition map, which facilitates the update of (global) absolute coordinates in terms of the (local) coordinates on the Lie group. This LGT map is specific to the absolute coordinates, the local coordinates on the Lie group, and the Lie group used to represent rigid body configurations.

</details>


### [181] [Spotlighting Task-Relevant Features: Object-Centric Representations for Better Generalization in Robotic Manipulation](https://arxiv.org/abs/2601.21416)
*Alexandre Chapin,Bruno Machado,Emmanuel Dellandréa,Liming Chen*

Main category: cs.RO

TL;DR: 本文提出了一种基于Slot的物体中心视觉表征（SBOCR）来提升机器人操作策略在视觉变化环境下的泛化能力，实验表明该方法优于传统的全局和密集特征表征方式。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人视觉表征大多采用全局或密集特征，这些特征无法有效区分任务相关与无关信息，容易在光照、材质变化或干扰物存在等分布转移场景下导致泛化能力下降，因此需要寻找更鲁棒的视觉表征方法。

Method: 作者提出一种介于全局特征与密集特征之间的结构化中间表征——Slot-Based Object-Centric Representation（SBOCR），将密集特征分组为有限数量的类物体实体，从而降低无关噪声输入，并保持完成操作任务所需的信息。随后，作者在多种仿真与现实的操作任务中对比评估了全局、密集与SBOCR三种表征的泛化能力。

Result: 实验结果显示，在光照、纹理变化及存在干扰物等多样视觉变化条件下，基于SBOCR的策略在泛化能力上显著优于全局和密集特征策略，且无需特定任务的预训练即可实现较好表现。

Conclusion: SBOCR为设计能在动态现实环境中高效泛化的视觉系统提供了一种有前景的方向，有望提升机器人操作策略的鲁棒性和适应性。

Abstract: The generalization capabilities of robotic manipulation policies are heavily influenced by the choice of visual representations. Existing approaches typically rely on representations extracted from pre-trained encoders, using two dominant types of features: global features, which summarize an entire image via a single pooled vector, and dense features, which preserve a patch-wise embedding from the final encoder layer. While widely used, both feature types mix task-relevant and irrelevant information, leading to poor generalization under distribution shifts, such as changes in lighting, textures, or the presence of distractors. In this work, we explore an intermediate structured alternative: Slot-Based Object-Centric Representations (SBOCR), which group dense features into a finite set of object-like entities. This representation permits to naturally reduce the noise provided to the robotic manipulation policy while keeping enough information to efficiently perform the task. We benchmark a range of global and dense representations against intermediate slot-based representations, across a suite of simulated and real-world manipulation tasks ranging from simple to complex. We evaluate their generalization under diverse visual conditions, including changes in lighting, texture, and the presence of distractors. Our findings reveal that SBOCR-based policies outperform dense and global representation-based policies in generalization settings, even without task-specific pretraining. These insights suggest that SBOCR is a promising direction for designing visual systems that generalize effectively in dynamic, real-world robotic environments.

</details>


### [182] [Nimbus: A Unified Embodied Synthetic Data Generation Framework](https://arxiv.org/abs/2601.21449)
*Zeyu He,Yuchang Zhang,Yuanzhen Zhou,Miao Tao,Hengjie Li,Yang Tian,Jia Zeng,Tai Wang,Wenzhe Cai,Yilun Chen,Ning Gao,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 提出了Nimbus，一个统一的合成数据生成框架，大幅提升了多任务、高吞吐的数据生成效率，并应用于大规模分布式场景。


<details>
  <summary>Details</summary>
Motivation: 现有的合成数据生成流程零散、专用性强，导致工程效率低和系统不稳定，难以满足基础模型训练所需要的大规模、高效数据生成。为此，需要一种统一且高效的数据生成框架来支撑多样化和大规模的数据生成需求。

Method: Nimbus采用模块化的四层架构，将轨迹规划、渲染和存储解耦为异步执行阶段。通过动态的管道调度、全局负载均衡、分布式容错技术和针对不同后端的渲染优化，实现对CPU、GPU和IO等资源的最大化利用。

Result: 实验表明，Nimbus在端到端吞吐量上相较于未优化的基线有2-3倍提升，并能在大规模分布式环境下保证长期稳定运行。

Conclusion: Nimbus为跨导航和操作任务的合成数据生成提供了统一的高效方案，有效支撑了InternData等生产级数据集生成，为通用智能体的训练打下坚实数据基础。

Abstract: Scaling data volume and diversity is critical for generalizing embodied intelligence. While synthetic data generation offers a scalable alternative to expensive physical data acquisition, existing pipelines remain fragmented and task-specific. This isolation leads to significant engineering inefficiency and system instability, failing to support the sustained, high-throughput data generation required for foundation model training. To address these challenges, we present Nimbus, a unified synthetic data generation framework designed to integrate heterogeneous navigation and manipulation pipelines. Nimbus introduces a modular four-layer architecture featuring a decoupled execution model that separates trajectory planning, rendering, and storage into asynchronous stages. By implementing dynamic pipeline scheduling, global load balancing, distributed fault tolerance, and backend-specific rendering optimizations, the system maximizes resource utilization across CPU, GPU, and I/O resources. Our evaluation demonstrates that Nimbus achieves a 2-3X improvement in end-to-end throughput compared to unoptimized baselines and ensuring robust, long-term operation in large-scale distributed environments. This framework serves as the production backbone for the InternData suite, enabling seamless cross-domain data synthesis.

</details>


### [183] [4D-CAAL: 4D Radar-Camera Calibration and Auto-Labeling for Autonomous Driving](https://arxiv.org/abs/2601.21454)
*Shanliang Yao,Zhuoxiao Li,Runwei Guan,Kebin Cao,Meng Xia,Fuping Hu,Sen Xu,Yong Yue,Xiaohui Zhu,Weiping Ding,Ryan Wen Liu*

Main category: cs.RO

TL;DR: 本文提出了一种用于4D雷达与摄像头的外参标定与自动标注统一框架（4D-CAAL），通过创新性靶标设计和算法，大幅提升了标定精度并减少了标注的人力成本。


<details>
  <summary>Details</summary>
Motivation: 目前4D雷达因其高分辨率和可测高程的优势，在自动驾驶领域越来越重要。然而，雷达与摄像头的外参标定较繁琐，现有方法针对单一模态设计靶标，导致配准困难。同时，雷达数据稀疏，人工标注困难且易出错。研究动机是解决这两大实际难题。

Method: 作者提出了4D-CAAL框架，包括一种前后双用途的标定靶标（前面是相机可识别棋盘格，背后中心植入雷达角反射器），结合鲁棒配准算法，实现两个传感器的精确外参标定。进一步，设计自动标注流程，利用几何投影与多特征优化，将相机分割标注自动映射到雷达点云上。

Result: 实验显示该方法可以实现高精度的雷达-摄像头外参标定，且大幅降低了人工雷达数据标注量，验证了其实用性和有效性。

Conclusion: 4D-CAAL方案加速多传感器融合感知系统的开发，对自动驾驶领域具有重要应用价值。其创新性地集成了高效标定与自动标注两大关键环节，为后续多模态感知算法的研究与落地提供了有力支撑。

Abstract: 4D radar has emerged as a critical sensor for autonomous driving, primarily due to its enhanced capabilities in elevation measurement and higher resolution compared to traditional 3D radar. Effective integration of 4D radar with cameras requires accurate extrinsic calibration, and the development of radar-based perception algorithms demands large-scale annotated datasets. However, existing calibration methods often employ separate targets optimized for either visual or radar modalities, complicating correspondence establishment. Furthermore, manually labeling sparse radar data is labor-intensive and unreliable. To address these challenges, we propose 4D-CAAL, a unified framework for 4D radar-camera calibration and auto-labeling. Our approach introduces a novel dual-purpose calibration target design, integrating a checkerboard pattern on the front surface for camera detection and a corner reflector at the center of the back surface for radar detection. We develop a robust correspondence matching algorithm that aligns the checkerboard center with the strongest radar reflection point, enabling accurate extrinsic calibration. Subsequently, we present an auto-labeling pipeline that leverages the calibrated sensor relationship to transfer annotations from camera-based segmentations to radar point clouds through geometric projection and multi-feature optimization. Extensive experiments demonstrate that our method achieves high calibration accuracy while significantly reducing manual annotation effort, thereby accelerating the development of robust multi-modal perception systems for autonomous driving.

</details>


### [184] [DexTac: Learning Contact-aware Visuotactile Policies via Hand-by-hand Teaching](https://arxiv.org/abs/2601.21474)
*Xingyu Zhang,Chaofan Zhang,Boyue Zhang,Zhinan Peng,Shaowei Cui,Shuo Wang*

Main category: cs.RO

TL;DR: 本文提出了DexTac框架，通过结合视觉和多维触觉信息，实现了在精细操作任务中的高效灵巧操作，相比传统方法显著提升成功率。


<details>
  <summary>Details</summary>
Motivation: 现有灵巧操作中的数据采集与技能学习常依赖低维度触觉，导致在复杂任务中表现受限。而人类操控时依赖丰富触觉，作者希望突破当前触觉信息的局限，提升机器人对复杂接触环境的操作能力。

Method: 提出了DexTac框架，它通过拟人带教（kinesthetic teaching）方式，从人类演示中直接采集多维触觉数据（包括接触力分布与空间接触区域），并将这些丰富的触觉模态与视觉信息共同输入策略网络，训练出具备接触感知能力的机器人手。

Result: 在单手注射任务中，DexTac框架达到91.67%的成功率。在小型注射器等高精准性场景下，相比仅用力传感的基线提升31.67%。

Conclusion: 通过从人类演示学习多维触觉先验，对于在复杂、富有接触的环境中实现类人灵巧操作非常关键。DexTac框架为提升操作机器人的触觉感知与自主性提供了有效新途径。

Abstract: For contact-intensive tasks, the ability to generate policies that produce comprehensive tactile-aware motions is essential. However, existing data collection and skill learning systems for dexterous manipulation often suffer from low-dimensional tactile information. To address this limitation, we propose DexTac, a visuo-tactile manipulation learning framework based on kinesthetic teaching. DexTac captures multi-dimensional tactile data-including contact force distributions and spatial contact regions-directly from human demonstrations. By integrating these rich tactile modalities into a policy network, the resulting contact-aware agent enables a dexterous hand to autonomously select and maintain optimal contact regions during complex interactions. We evaluate our framework on a challenging unimanual injection task. Experimental results demonstrate that DexTac achieves a 91.67% success rate. Notably, in high-precision scenarios involving small-scale syringes, our approach outperforms force-only baselines by 31.67%. These results underscore that learning multi-dimensional tactile priors from human demonstrations is critical for achieving robust, human-like dexterous manipulation in contact-rich environments.

</details>


### [185] [Don't double it: Efficient Agent Prediction in Occlusions](https://arxiv.org/abs/2601.21504)
*Anna Rothenhäusler,Markus Mazzola,Andreas Look,Raghu Rajan,Joschka Bödecker*

Main category: cs.RO

TL;DR: 本文提出了一种新方法MatchInformer，提升了自动驾驶中对被遮挡交通参与者（如行人、车辆）的推理和轨迹预测准确性，减少了多余预测，并能更好地处理数据不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶场景中，被遮挡的交通参与者会突然出现，带来安全挑战。现有方法在推理隐藏物体时存在冗余预测现象，导致后续规划复杂且计算量大。此外，稀疏和不平衡数据评估困难。这些问题有待解决。

Method: 提出基于SceneInformer的MatchInformer方法，将先进的匈牙利匹配算法引入训练过程，实现预测与真实标签的一对一对应，减少预测冗余。同时，将交通参与者的朝向与移动轨迹解耦，提升轨迹预测的准确性和可解释性。评估方面引入Mathews相关系数（MCC），增强对数据不平衡场景下的预测力。

Result: 在Waymo Open Motion Dataset上进行实验，MatchInformer在推理被遮挡区域和轨迹预测方面，比现有方法表现更优，预测更精准，冗余更少，对不平衡数据表现更稳健。

Conclusion: MatchInformer有效缓解了自动驾驶对遮挡目标推理中的冗余预测问题，提升了轨迹预测准确性，并为不平衡/稀疏场景提供了更可靠的评估方法，推动了该领域的研究进展。

Abstract: Occluded traffic agents pose a significant challenge for autonomous vehicles, as hidden pedestrians or vehicles can appear unexpectedly, yet this problem remains understudied. Existing learning-based methods, while capable of inferring the presence of hidden agents, often produce redundant occupancy predictions where a single agent is identified multiple times. This issue complicates downstream planning and increases computational load. To address this, we introduce MatchInformer, a novel transformer-based approach that builds on the state-of-the-art SceneInformer architecture. Our method improves upon prior work by integrating Hungarian Matching, a state-of-the-art object matching algorithm from object detection, into the training process to enforce a one-to-one correspondence between predictions and ground truth, thereby reducing redundancy. We further refine trajectory forecasts by decoupling an agent's heading from its motion, a strategy that improves the accuracy and interpretability of predicted paths. To better handle class imbalances, we propose using the Matthews Correlation Coefficient (MCC) to evaluate occupancy predictions. By considering all entries in the confusion matrix, MCC provides a robust measure even in sparse or imbalanced scenarios. Experiments on the Waymo Open Motion Dataset demonstrate that our approach improves reasoning about occluded regions and produces more accurate trajectory forecasts than prior methods.

</details>


### [186] [IROS: A Dual-Process Architecture for Real-Time VLM-Based Indoor Navigation](https://arxiv.org/abs/2601.21506)
*Joonhee Lee,Hyunseung Shin,Jeonggil Ko*

Main category: cs.RO

TL;DR: IROS提出了一种结合高效感知和深度语义推理的实时室内导航框架，提升了导航的准确性并大幅降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的室内机器人导航方法难以同时兼顾快速响应和丰富的语义理解。经典几何方法如SLAM虽有可靠定位，但无法解释针对人的高层语义线索（如标识、房间号）；而VLA和VLM虽然能进行语义推理，但计算延迟高或只能处理即时信息，难以实时运行于嵌入式设备。

Method: IROS灵感来自“双过程理论”，将快速反应决策（系统一）与缓慢深度推理（系统二）分离，只有必要时才调用VLM。系统结构为：在本地硬件上用轻量视觉感知模块做主要控制，仅在遇到需要复杂推理时调用带增强空间和文本能力的小型VLM。

Result: IROS在五个真实建筑中测试，决策准确性提升且导航延迟较持续VLM方案减少66%。

Conclusion: IROS框架兼具高效（低延迟）和高级（高语义理解）导航能力，适合部署于低成本移动机器人，有效解决了室内导航中的响应与理解难题。

Abstract: Indoor mobile robot navigation requires fast responsiveness and robust semantic understanding, yet existing methods struggle to provide both. Classical geometric approaches such as SLAM offer reliable localization but depend on detailed maps and cannot interpret human-targeted cues (e.g., signs, room numbers) essential for indoor reasoning. Vision-Language-Action (VLA) models introduce semantic grounding but remain strictly reactive, basing decisions only on visible frames and failing to anticipate unseen intersections or reason about distant textual cues. Vision-Language Models (VLMs) provide richer contextual inference but suffer from high computational latency, making them unsuitable for real-time operation on embedded platforms. In this work, we present IROS, a real-time navigation framework that combines VLM-level contextual reasoning with the efficiency of lightweight perceptual modules on low-cost, on-device hardware. Inspired by Dual Process Theory, IROS separates fast reflexive decisions (System One) from slow deliberative reasoning (System Two), invoking the VLM only when necessary. Furthermore, by augmenting compact VLMs with spatial and textual cues, IROS delivers robust, human-like navigation with minimal latency. Across five real-world buildings, IROS improves decision accuracy and reduces latency by 66% compared to continuous VLM-based navigation.

</details>


### [187] [Training slow silicon neurons to control extremely fast robots with spiking reinforcement learning](https://arxiv.org/abs/2601.21548)
*Irene Ambrosini,Ingo Blakowski,Dmitrii Zendrikov,Cristiano Capone,Luna Gava,Giacomo Indiveri,Chiara De Luca,Chiara Bartolozzi*

Main category: cs.RO

TL;DR: 该论文提出利用类脑神经形态芯片实现快速高效的机器自主空中曲棍球控制，通过硬件与学习算法协同设计，完成了实时强化学习任务。


<details>
  <summary>Details</summary>
Motivation: 空中曲棍球等高速交互任务要求极快决策速度，传统控制方法或AI实现效率受限。作者希望用仿脑的神经形态硬件结合快速学习机制，提升机器人对高速任务的应对能力。

Method: 构建了一个小型脉冲神经网络部署在混合模拟/数字神经形态处理器上，网络采用固定随机连接以捕获时序结构，并在输出层应用本地e-prop学习规则，通过与计算机联合的回路实现强化学习。

Result: 系统在极少数次训练后即可实现成功的击打行为，证明了该体系在实际机器人系统中具备实时自主学习和高效操作能力。

Conclusion: 类脑神经形态硬件与本地强化学习机制结合，能够实现高速、持续学习的机器人自主控制，为在实际复杂环境中推广仿脑智能系统提供新途径。

Abstract: Air hockey demands split-second decisions at high puck velocities, a challenge we address with a compact network of spiking neurons running on a mixed-signal analog/digital neuromorphic processor. By co-designing hardware and learning algorithms, we train the system to achieve successful puck interactions through reinforcement learning in a remarkably small number of trials. The network leverages fixed random connectivity to capture the task's temporal structure and adopts a local e-prop learning rule in the readout layer to exploit event-driven activity for fast and efficient learning. The result is real-time learning with a setup comprising a computer and the neuromorphic chip in-the-loop, enabling practical training of spiking neural networks for robotic autonomous systems. This work bridges neuroscience-inspired hardware with real-world robotic control, showing that brain-inspired approaches can tackle fast-paced interaction tasks while supporting always-on learning in intelligent machines.

</details>


### [188] [AIR-VLA: Vision-Language-Action Systems for Aerial Manipulation](https://arxiv.org/abs/2601.21602)
*Jianli Sun,Bin Tian,Qiyao Zhang,Chengxiang Li,Zihan Song,Zhiyong Cui,Yisheng Lv,Yonglin Tian*

Main category: cs.RO

TL;DR: 本文提出了首个专为空中操作系统（AMS）设计的视觉-语言-动作（VLA）基准框架AIR-VLA，并利用物理仿真环境和高质量多模态数据集，系统评估了主流VLA模型在AMS上的表现，为未来通用空中机器人研究打下基础。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型主要针对地面或静态基座设计，难以应对AMS的特殊挑战（如悬浮基座动力学、无人机与机械臂的强耦合、多步长复杂任务），缺乏专用于AMS的标准基准和数据集。因此，亟需填补VLA在空中操作系统领域的空白。

Method: 作者构建了一个基于物理仿真的模拟环境，手动采集了3000个多模态演示任务，涵盖操作控制、物体与空间理解、语义推理和长时序规划。基于此，系统评测现有VLA和视觉-语言模型（VLM）在AMS任务下的能力表现，并设计了适用于空中任务的多维评估指标。

Result: 实验表明VLA范式在AMS上具有可行性，并通过定制指标揭示了主流模型在无人机机动性、机械臂控制及高级规划等方面的能力边界。研究为后续模型的改进提供了数据支撑和测试平台。

Conclusion: AIR-VLA为空中机器人领域建立了首个标准化VLA测试平台和数据基础，对推进通用空中操作智能的研究具有重要意义。

Abstract: While Vision-Language-Action (VLA) models have achieved remarkable success in ground-based embodied intelligence, their application to Aerial Manipulation Systems (AMS) remains a largely unexplored frontier. The inherent characteristics of AMS, including floating-base dynamics, strong coupling between the UAV and the manipulator, and the multi-step, long-horizon nature of operational tasks, pose severe challenges to existing VLA paradigms designed for static or 2D mobile bases. To bridge this gap, we propose AIR-VLA, the first VLA benchmark specifically tailored for aerial manipulation. We construct a physics-based simulation environment and release a high-quality multimodal dataset comprising 3000 manually teleoperated demonstrations, covering base manipulation, object & spatial understanding, semantic reasoning, and long-horizon planning. Leveraging this platform, we systematically evaluate mainstream VLA models and state-of-the-art VLM models. Our experiments not only validate the feasibility of transferring VLA paradigms to aerial systems but also, through multi-dimensional metrics tailored to aerial tasks, reveal the capabilities and boundaries of current models regarding UAV mobility, manipulator control, and high-level planning. AIR-VLA establishes a standardized testbed and data foundation for future research in general-purpose aerial robotics. The resource of AIR-VLA will be available at https://anonymous.4open.science/r/AIR-VLA-dataset-B5CC/.

</details>


### [189] [From Instruction to Event: Sound-Triggered Mobile Manipulation](https://arxiv.org/abs/2601.21667)
*Hao Ju,Shaofei Huang,Hongyu Li,Zihan Ding,Si Liu,Meng Wang,Zhedong Zheng*

Main category: cs.RO

TL;DR: 本文提出了一种以声音触发的移动操作新范式，并开发了相应数据平台和基线方法，使机器人能自动感知和响应环境中的声音事件，无需人工指令。


<details>
  <summary>Details</summary>
Motivation: 现有移动操作多依赖文本指令，机器人角色被动，难以主动适应动态环境和突发事件。该研究旨在突破这一限制，提升机器人自主性，使其能主动探测和响应声音触发的操作需求。

Method: 作者提出了声音触发移动操作的任务设定，开发了Habitat-Echo数据平台，将声学渲染与物理交互结合。同时，设计了由高层任务规划器和低层策略模型组成的基线方法，以实现对声音事件的主动探测与响应。

Result: 实验表明，基线方法能够使机器人无需逐条指令即可主动识别并应答听觉事件。在有重叠声源的复杂场景中，机器人可以优先处理主声源并随后完成对次声源的操作，显示了方法的鲁棒性。

Conclusion: 所提声音触发移动操作范式和技术平台，有效提升了机器人在复杂环境下的自主性与灵活性，对推动移动操作领域向更加智能、自主方向发展具有重要意义。

Abstract: Current mobile manipulation research predominantly follows an instruction-driven paradigm, where agents rely on predefined textual commands to execute tasks. However, this setting confines agents to a passive role, limiting their autonomy and ability to react to dynamic environmental events. To address these limitations, we introduce sound-triggered mobile manipulation, where agents must actively perceive and interact with sound-emitting objects without explicit action instructions. To support these tasks, we develop Habitat-Echo, a data platform that integrates acoustic rendering with physical interaction. We further propose a baseline comprising a high-level task planner and low-level policy models to complete these tasks. Extensive experiments show that the proposed baseline empowers agents to actively detect and respond to auditory events, eliminating the need for case-by-case instructions. Notably, in the challenging dual-source scenario, the agent successfully isolates the primary source from overlapping acoustic interference to execute the first interaction, and subsequently proceeds to manipulate the secondary object, verifying the robustness of the baseline.

</details>


### [190] [CoFreeVLA: Collision-Free Dual-Arm Manipulation via Vision-Language-Action Model and Risk Estimation](https://arxiv.org/abs/2601.21712)
*Xuanran Zhai,Binkai Ou,Yemin Wang,Hui Yi Leong,Qiaojun Yu,Ce Hao,Yaohua Liu*

Main category: cs.RO

TL;DR: 本文提出CoFreeVLA方法，通过在端到端视觉语言动作模型中集成短期自碰撞风险估算，提升双臂机器人操作的安全性。实验证明其在减少自碰撞和提高任务成功率方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言动作（VLA）模型在双臂机器人操作中易忽视双臂及抓持物体间的自碰撞风险，导致部署不安全。因此，亟需提升VLA模型在自碰撞预测与规避方面的能力。

Method: 提出CoFreeVLA框架，在常规VLA模型中引入一个利用本体感知、视觉特征和动作计划的自碰撞风险估算模块。高风险指令被拒绝，系统可通过风险驱动的动作微调恢复到安全状态。风险模块先通过基于模型模拟生成碰撞标签预训练，再在真实机器人回放中微调校准。

Result: 在五个PiPER双臂机器人任务上，CoFreeVLA相较于RDT和APEX方法自碰撞次数更少、任务成功率更高。

Conclusion: CoFreeVLA有效提升了双臂机器人基于VLA模型的安全性和任务完成效率，可为未来多臂复杂操作提供借鉴。

Abstract: Vision Language Action (VLA) models enable instruction following manipulation, yet dualarm deployment remains unsafe due to under modeled selfcollisions between arms and grasped objects. We introduce CoFreeVLA, which augments an endtoend VLA with a short horizon selfcollision risk estimator that predicts collision likelihood from proprioception, visual embeddings, and planned actions. The estimator gates risky commands, recovers to safe states via risk-guided adjustments, and shapes policy refinement for safer rollouts. It is pre-trained with model-based collision labels and posttrained on real robot rollouts for calibration. On five bimanual tasks with the PiPER robot arm, CoFreeVLA reduces selfcollisions and improves success rates versus RDT and APEX.

</details>


### [191] [Disentangling perception and reasoning for improving data efficiency in learning cloth manipulation without demonstrations](https://arxiv.org/abs/2601.21713)
*Donatien Delehelle,Fei Chen,Darwin Caldwell*

Main category: cs.RO

TL;DR: 本文提出了一种高效且模块化的强化学习方法用于布料操作任务，大幅减少了模型规模和训练时间，并在SoftGym基准上超过了现有方法。


<details>
  <summary>Details</summary>
Motivation: 布料操作因其高维状态空间、复杂动力学及易自遮挡等特性，在机器人领域仍属挑战性难题。传统分析方法难以获得通用、鲁棒的策略，而基于数据的方法往往依赖大模型和长时间训练，计算成本高昂。作者关注在保证性能的同时如何提升学习效率及模型实用性。

Method: 作者对强化学习方法的常见端到端设计（使用图像输入的大模型）提出质疑，转而设计了一种高效、可模块化的方法，在仿真环境下通过精心的模型结构和输入选择，减少了模型复杂度与训练时长。同时，证明了该模型可迁移到现实世界。

Result: 方法在SoftGym布料操作任务上进行了评估，相较于现有基线在模型规模大幅降低的情况下，取得了显著的性能提升。

Conclusion: 本文提出的高效模块化强化学习方法不仅显著提升了布料操作的学习效率，还有效解决了大模型计算负担重的问题，实现了良好的仿真到现实迁移能力。

Abstract: Cloth manipulation is a ubiquitous task in everyday life, but it remains an open challenge for robotics. The difficulties in developing cloth manipulation policies are attributed to the high-dimensional state space, complex dynamics, and high propensity to self-occlusion exhibited by fabrics. As analytical methods have not been able to provide robust and general manipulation policies, reinforcement learning (RL) is considered a promising approach to these problems. However, to address the large state space and complex dynamics, data-based methods usually rely on large models and long training times. The resulting computational cost significantly hampers the development and adoption of these methods. Additionally, due to the challenge of robust state estimation, garment manipulation policies often adopt an end-to-end learning approach with workspace images as input. While this approach enables a conceptually straightforward sim-to-real transfer via real-world fine-tuning, it also incurs a significant computational cost by training agents on a highly lossy representation of the environment state. This paper questions this common design choice by exploring an efficient and modular approach to RL for cloth manipulation. We show that, through careful design choices, model size and training time can be significantly reduced when learning in simulation. Furthermore, we demonstrate how the resulting simulation-trained model can be transferred to the real world. We evaluate our approach on the SoftGym benchmark and achieve significant performance improvements over available baselines on our task, while using a substantially smaller model.

</details>


### [192] [Flocking behavior for dynamic and complex swarm structures](https://arxiv.org/abs/2601.21772)
*Carmen D. R. Pita-Romero,Pedro Arias-Perez,Miguel Fernandez-Cortizas,Rafael Perez-Segui,Pascual Campoy*

Main category: cs.RO

TL;DR: 本文提出了一种基于虚拟质心的多无人机队形控制算法，能够简便实现复杂队形和轨迹，经过仿真和实验证明效果优秀。


<details>
  <summary>Details</summary>
Motivation: 多无人机协作实现复杂结构与轨迹管理仍具挑战，现有方法难以兼顾灵活性和易用性，因此亟需更高效简便的队形控制策略。

Method: 采用虚拟质心（Virtual Centroid）思想发展了一种改进的虚拟行为算法，建立理论框架以动态调控无人机数量及队形结构，并通过仿真和实验证明方法的有效性。

Result: 无论面对复杂编队结构还是复杂轨迹，该算法皆可易于实现；仿真与现实实验均显示出良好的适应性和操作简便性。

Conclusion: 基于虚拟质心的队形算法能高效、简单地实现多无人机复杂协作，具有良好的应用前景。

Abstract: Maintaining the formation of complex structures with multiple UAVs and achieving complex trajectories remains a major challenge. This work presents an algorithm for implementing the flocking behavior of UAVs based on the concept of Virtual Centroid to easily develop a structure for the flock. The approach builds on the classical virtual-based behavior, providing a theoretical framework for incorporating enhancements to dynamically control both the number of agents and the formation of the structure. Simulation tests and real-world experiments were conducted, demonstrating its simplicity even with complex formations and complex trajectories.

</details>


### [193] [GAZELOAD A Multimodal Eye-Tracking Dataset for Mental Workload in Industrial Human-Robot Collaboration](https://arxiv.org/abs/2601.21829)
*Bsher Karbouj,Baha Eddin Gaaloul,Jorg Kruger*

Main category: cs.RO

TL;DR: 本文提出并发布了GAZELOAD多模态数据集，用于工业人机协作场景下的心理负荷估计。数据包括眼动追踪、环境光照、任务与机器人状态，并已组织便于算法开发和分析。


<details>
  <summary>Details</summary>
Motivation: 当前工业场景下的人机协作对操作人员的心理负荷产生了较高要求，缺乏真实、细致的多模态数据支持对心理负荷估计算法的开发和优化。该研究旨在弥补工业人机协作环境下相关公开数据资源的空白，推动心理负荷估计与工作环境因素分析。

Method: 在实验室装配测试台中，招募26名参与者与两款协作机器人交互，佩戴Meta ARIA智能眼镜。同步记录眼动数据（包括瞳孔直径、注视、扫视、凝视转移熵、注视离散指数）、环境照度、任务与机器人状态等，控制任务难度和环境条件变量，将数据分为250ms时间窗汇总，并提供环境日志及主观心理负荷评分，以结构化数据文件对外发布。

Result: 获得高时间分辨率、多模态的心理负荷相关数据集，每个被试和任务块都包含眼动指标、环境记录和主观评分。数据集可以直接用于心理负荷估计及其环境影响分析，便于后续特征提取与时序建模算法开发与评测。

Conclusion: GAZELOAD数据集为工业人机协作场景下的心理负荷研究提供了详实的多模态数据支持，将促进算法研发和环境因素效应分析，有助于推动实际应用中的人机协作安全与效率提升。

Abstract: This article describes GAZELOAD, a multimodal dataset for mental workload estimation in industrial human-robot collaboration. The data were collected in a laboratory assembly testbed where 26 participants interacted with two collaborative robots (UR5 and Franka Emika Panda) while wearing Meta ARIA smart glasses. The dataset time-synchronizes eye-tracking signals (pupil diameter, fixations, saccades, eye gaze, gaze transition entropy, fixation dispersion index) with environmental real-time and continuous measurements (illuminance) and task and robot context (bench, task block, induced faults), under controlled manipulations of task difficulty and ambient conditions. For each participant and workload-graded task block, we provide CSV files with ocular metrics aggregated into 250 ms windows, environmental logs, and self-reported mental workload ratings on a 1-10 Likert scale, organized in participant-specific folders alongside documentation. These data can be used to develop and benchmark algorithms for mental workload estimation, feature extraction, and temporal modeling in realistic industrial HRC scenarios, and to investigate the influence of environmental factors such as lighting on eye-based workload markers.

</details>


### [194] [LLM-Driven Scenario-Aware Planning for Autonomous Driving](https://arxiv.org/abs/2601.21876)
*He Li,Zhaowei Chen,Rui Gao,Guoliang Li,Qi Hao,Shuai Wang,Chengzhong Xu*

Main category: cs.RO

TL;DR: 本论文提出一种基于大语言模型（LLM）的自适应规划方法（LAP），用于自动驾驶混合规划器切换，能够在不同复杂度场景下兼顾高效与安全，实验证明该方法优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 目前的混合规划器切换框架在自动驾驶中，难以在高效高速驾驶与拥堵环境下的安全切换之间取得平衡，主要是因为场景识别依赖启发式方法且控制更新频率不高，导致表现不佳。

Method: 提出LAP方法，即通过大语言模型进行场景理解，将其推断结果用于模式切换与运动规划的联合优化中，采用树搜索模型预测控制和交替最小化算法，实现高效高质量的轨迹生成，并在ROS平台用Python实现。

Result: 高保真仿真结果表明，所提LAP方法在驾驶时间和任务成功率上均优于现有对比方法。

Conclusion: 基于LLM的自适应规划能够更智能地理解场景并优化运动规划，提高自动驾驶系统在不同复杂度环境下的整体性能。

Abstract: Hybrid planner switching framework (HPSF) for autonomous driving needs to reconcile high-speed driving efficiency with safe maneuvering in dense traffic. Existing HPSF methods often fail to make reliable mode transitions or sustain efficient driving in congested environments, owing to heuristic scene recognition and low-frequency control updates. To address the limitation, this paper proposes LAP, a large language model (LLM) driven, adaptive planning method, which switches between high-speed driving in low-complexity scenes and precise driving in high-complexity scenes, enabling high qualities of trajectory generation through confined gaps. This is achieved by leveraging LLM for scene understanding and integrating its inference into the joint optimization of mode configuration and motion planning. The joint optimization is solved using tree-search model predictive control and alternating minimization. We implement LAP by Python in Robot Operating System (ROS). High-fidelity simulation results show that the proposed LAP outperforms other benchmarks in terms of both driving time and success rate.

</details>


### [195] [Multi-Modular MANTA-RAY: A Modular Soft Surface Platform for Distributed Multi-Object Manipulation](https://arxiv.org/abs/2601.21884)
*Pratik Ingle,Jørn Lambertsen,Kasper Støy,Andres Faina*

Main category: cs.RO

TL;DR: 本论文提出了一种可扩展、模块化的软体操控平台MANTA-RAY，通过减少驱动器密度，实现对易损和异质物体的精细操控，并验证了其多模块协作能力和实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 传统“操控表面”通过密集驱动阵列实现复杂变形，但高自由度带来系统复杂性和可扩展性限制。作者旨在解决驱动器数量多带来的工程瓶颈，实现可扩展、精简、且能操控多样易碎物体的表面操控平台。

Method: 设计了基于软织物的MANTA-RAY平台，采用模块化设计，每个模块驱动器数量减少。提出了模块间物体传递与基于几何变换的PID控制策略，直接映射控制输出到驱动器指令，无需大量训练。方法在多模块仿真（3x3、4x4）及物理原型（2x2）上验证。

Result: 系统能有效操控形状、质量、材质多样的物体（如鸡蛋、苹果），实现了平行操控。多模块方案在更大操作区域和目标多样性上展现出良好扩展性和多物体协调能力。

Conclusion: 多模块化MANTA-RAY平台在降低驱动器密度的同时保持操控性能，提升了系统扩展性和实际应用可能性，适用于真实场景中对易碎、复杂物体的操控需求。

Abstract: Manipulation surfaces control objects by actively deforming their shape rather than directly grasping them. While dense actuator arrays can generate complex deformations, they also introduce high degrees of freedom (DOF), increasing system complexity and limiting scalability. The MANTA-RAY (Manipulation with Adaptive Non-rigid Textile Actuation with Reduced Actuation densitY) platform addresses these challenges by leveraging a soft, fabric-based surface with reduced actuator density to manipulate fragile and heterogeneous objects. Previous studies focused on single-module implementations supported by four actuators, whereas the feasibility and benefits of a scalable, multi-module configuration remain unexplored. In this work, we present a distributed, modular, and scalable variant of the MANTA-RAY platform that maintains manipulation performance with a reduced actuator density. The proposed multi-module MANTA-RAY platform and control strategy employs object passing between modules and a geometric transformation driven PID controller that directly maps tilt-angle control outputs to actuator commands, eliminating the need for extensive data-driven or black-box training. We evaluate system performance in simulation across surface configurations of varying modules (3x3 and 4x4) and validate its feasibility through experiments on a physical 2x2 hardware prototype. The system successfully manipulates objects with diverse geometries, masses, and textures including fragile items such as eggs and apples as well as enabling parallel manipulation. The results demonstrate that the multi-module MANTA-RAY improves scalability and enables coordinated manipulation of multiple objects across larger areas, highlighting its potential for practical, real-world applications.

</details>


### [196] [Information Filtering via Variational Regularization for Robot Manipulation](https://arxiv.org/abs/2601.21926)
*Jinhao Zhang,Wenlong Xia,Yaojia Wang,Zhexuan Zhou,Huizhe Li,Yichen Lai,Haoming Song,Youmin Gong,Jie Me*

Main category: cs.RO

TL;DR: 本文提出了一种新的变分正则化（VR）模块，用于提升基于扩散模型的机器人视觉运动策略的表现，通过对中间特征引入自适应信息瓶颈，有效去除噪声，提高模型性能，在多个仿真和实际场景中超过现有方法。


<details>
  <summary>Details</summary>
Motivation: 虽然基于扩散模型的机器人视觉运动策略表现优异，但目前主流方法依赖参数冗余的去噪解码器，导致中间特征冗余和噪声。通过实验证明，推理阶段对骨干特征随机mask可提升性能，说明中间特征存在与任务无关的干扰。作者试图改进信息利用效率，减少无效噪声。

Method: 提出Variational Regularization（VR）模块，在骨干网络特征上引入与时间步相关的高斯分布，并通过KL散度进行正则化，相当于为特征引入自适应信息瓶颈，抑制任务无关噪声。该模块轻量，易于集成于现有扩散策略框架。

Result: 在RoboTwin2.0、Adroit和MetaWorld三个仿真基准上，VR模块能让策略成功率分别比DP3基线提升6.1%、4.1%，达到新的SOTA。在实际机器人实验中也表现良好。

Conclusion: 本文验证了在基于扩散模型的机器人视觉运动策略中，中间特征熵影响性能，引入轻量变分正则化可有效提升策略成功率，兼具实用与前沿性。

Abstract: Diffusion-based visuomotor policies built on 3D visual representations have achieved strong performance in learning complex robotic skills. However, most existing methods employ an oversized denoising decoder. While increasing model capacity can improve denoising, empirical evidence suggests that it also introduces redundancy and noise in intermediate feature blocks. Crucially, we find that randomly masking backbone features at inference time (without changing training) can improve performance, confirming the presence of task-irrelevant noise in intermediate features. To this end, we propose Variational Regularization (VR), a lightweight module that imposes a timestep-conditioned Gaussian over backbone features and applies a KL-divergence regularizer, forming an adaptive information bottleneck. Extensive experiments on three simulation benchmarks (RoboTwin2.0, Adroit, and MetaWorld) show that, compared to the baseline DP3, our approach improves the success rate by 6.1% on RoboTwin2.0 and by 4.1% on Adroit and MetaWorld, achieving new state-of-the-art results. Real-world experiments further demonstrate that our method performs well in practical deployments. Code will released.

</details>


### [197] [MoE-ACT: Improving Surgical Imitation Learning Policies through Supervised Mixture-of-Experts](https://arxiv.org/abs/2601.21971)
*Lorenzo Mazza,Ariel Rodriguez,Rayan Younis,Martin Lelis,Ortrun Hellig,Chenpan Li,Sebastian Bodenstedt,Martin Wagner,Stefanie Speidel*

Main category: cs.RO

TL;DR: 作者提出了一种基于专家混合（MoE）结构的模仿学习方法，该方法能在外科机器人操作中，以极少的演示数据完成复杂任务，并具备较强的泛化和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 外科手术机器人领域受到数据稀缺、空间受限及对高安全和可预测性的要求，导致模仿学习方法较难直接应用于实际手术场景。现有方法往往需要大规模演示或多摄像头系统，应用受限。

Method: 提出了一种可集成于任意自主策略上的监督式专家混合（MoE）结构，将其与轻量级的“动作分块变换器”（ACT）结合。该方法仅需150次以下的演示，且仅依赖内窥镜立体图像即可学习操作任务。

Result: 在外科合作任务（肠道抓取和牵引）中，与最先进的视觉-语言-动作（VLA）模型和单一ACT基线相比，该MoE结构显著提升了任务成功率及跨分布泛化（如新抓取点、光照变化、遮挡等）鲁棒性，并可零样本迁移至猪体外组织。

Conclusion: MoE结构为外科机器人模仿学习提供了一条高效可靠、易于实际部署的新路径，并在初步动物体内实验中展现了良好前景，为未来临床应用奠定基础。

Abstract: Imitation learning has achieved remarkable success in robotic manipulation, yet its application to surgical robotics remains challenging due to data scarcity, constrained workspaces, and the need for an exceptional level of safety and predictability. We present a supervised Mixture-of-Experts (MoE) architecture designed for phase-structured surgical manipulation tasks, which can be added on top of any autonomous policy. Unlike prior surgical robot learning approaches that rely on multi-camera setups or thousands of demonstrations, we show that a lightweight action decoder policy like Action Chunking Transformer (ACT) can learn complex, long-horizon manipulation from less than 150 demonstrations using solely stereo endoscopic images, when equipped with our architecture. We evaluate our approach on the collaborative surgical task of bowel grasping and retraction, where a robot assistant interprets visual cues from a human surgeon, executes targeted grasping on deformable tissue, and performs sustained retraction. We benchmark our method against state-of-the-art Vision-Language-Action (VLA) models and the standard ACT baseline. Our results show that generalist VLAs fail to acquire the task entirely, even under standard in-distribution conditions. Furthermore, while standard ACT achieves moderate success in-distribution, adopting a supervised MoE architecture significantly boosts its performance, yielding higher success rates in-distribution and demonstrating superior robustness in out-of-distribution scenarios, including novel grasp locations, reduced illumination, and partial occlusions. Notably, it generalizes to unseen testing viewpoints and also transfers zero-shot to ex vivo porcine tissue without additional training, offering a promising pathway toward in vivo deployment. To support this, we present qualitative preliminary results of policy roll-outs during in vivo porcine surgery.

</details>


### [198] [Macro-Scale Electrostatic Origami Motor](https://arxiv.org/abs/2601.21976)
*Alex S. Miller,Leo McElroy,Jeffrey H. Lang*

Main category: cs.RO

TL;DR: 本论文介绍了一种首个可折叠的大尺度折纸旋转马达，能够由扁平状态展开后产生连续旋转运动，并通过实验展示了其性能。


<details>
  <summary>Details</summary>
Motivation: 目前可折叠机器人缺乏能够直接产生连续旋转运动的大尺度可折叠执行器。以往的折叠机器人执行器多为线性运动或折叠运动，未能实现大尺度上的旋转能力，制约了可折叠机器人在复杂运动上的应用突破。

Method: 作者设计并制造了一种基于折纸结构的可折叠旋转马达。该马达通过电晕放电实现扭矩输出，可以折叠为扁平结构以实现高空间利用率，展开后进行旋转驱动。本文对这一原型进行了定量实验，包括展开倍数、最大转速、输出扭矩等性能指标测试。

Result: 原型马达实现了2.5:1的展开倍数。在-29kV驱动下，最高转速达到1440 rpm，最大输出扭矩超过0.15 mN·m，主动部件扭矩密度为0.04 Nm/kg。

Conclusion: 该研究首次实现了可折叠的大尺度连续旋转马达，并验证了其可行性和基础性能，为可折叠机器人和柔性自动化系统提供了新的执行器解决方案。

Abstract: Foldable robots have been an active area of robotics research due to their high volume-to-mass ratio, easy packability, and shape adaptability. For locomotion, previously developed foldable robots have either embedded linear actuators in, or attached non-folding rotary motors to, their structure. Further, those actuators directly embedded in the structure of the folding medium all contributed to linear or folding motion, not to continuous rotary motion. On the macro-scale there has not yet been a folding continuous rotary actuator. This paper details the development and testing of the first macro-scale origami rotary motor that can be folded flat, and then unfurled to operate. Using corona discharge for torque production, the prototype motor achieved an expansion ratio of 2.5:1, reached a top speed of 1440 rpm when driven at -29 kV, and exhibited a maximum output torque over 0.15 mN m with an active component torque density of 0.04 Nm/kg.

</details>


### [199] [PocketDP3: Efficient Pocket-Scale 3D Visuomotor Policy](https://arxiv.org/abs/2601.22018)
*Jinhao Zhang,Zhexuan Zhou,Huizhe Li,Yichen Lai,Wenlong Xia,Haoming Song,Youmin Gong,Jie Me*

Main category: cs.RO

TL;DR: 本文提出了一种名为PocketDP3的新型3D视觉扩散策略，利用轻量级的Diffusion Mixer替代以往大型解码器，实现大幅减少参数和提升推理速度，并在多个仿真和真实世界任务中达到最优表现。


<details>
  <summary>Details</summary>
Motivation: 当前3D视觉扩散策略通常采用小型点云编码器和庞大解码器，导致参数浪费且推理效率低。文章发现在使用紧凑特征表示时，庞大解码器的参数并未充分利用，因此有必要优化模型结构以提升效率和实用性。

Method: 提出PocketDP3，将传统的条件U-Net解码器替换为基于MLP-Mixer块的轻量级Diffusion Mixer，能高效融合时间和通道信息，实现两步推理，支持实时部署，无需额外一致性蒸馏技术。

Result: 在RoboTwin2.0、Adroit和MetaWorld三个仿真基准上，PocketDP3以不到1%的参数量达成甚至超越以往方法的最优表现，推理速度显著提升。同时，真实世界实验展示了方法的实际可用性和良好迁移性。

Conclusion: PocketDP3通过极简的解码器结构与高效推理模式，兼顾性能、模型规模和实用性，适合在需要实时响应的机器人操作场景推广应用。

Abstract: Recently, 3D vision-based diffusion policies have shown strong capability in learning complex robotic manipulation skills. However, a common architectural mismatch exists in these models: a tiny yet efficient point-cloud encoder is often paired with a massive decoder. Given a compact scene representation, we argue that this may lead to substantial parameter waste in the decoder. Motivated by this observation, we propose PocketDP3, a pocket-scale 3D diffusion policy that replaces the heavy conditional U-Net decoder used in prior methods with a lightweight Diffusion Mixer (DiM) built on MLP-Mixer blocks. This architecture enables efficient fusion across temporal and channel dimensions, significantly reducing model size. Notably, without any additional consistency distillation techniques, our method supports two-step inference without sacrificing performance, improving practicality for real-time deployment. Across three simulation benchmarks--RoboTwin2.0, Adroit, and MetaWorld--PocketDP3 achieves state-of-the-art performance with fewer than 1% of the parameters of prior methods, while also accelerating inference. Real-world experiments further demonstrate the practicality and transferability of our method in real-world settings. Code will be released.

</details>


### [200] [mjlab: A Lightweight Framework for GPU-Accelerated Robot Learning](https://arxiv.org/abs/2601.22074)
*Kevin Zakka,Qiayuan Liao,Brent Yi,Louis Le Lay,Koushil Sreenath,Pieter Abbeel*

Main category: cs.RO

TL;DR: mjlab是一个轻量级、开源的机器人学习框架，集成了GPU加速仿真和模块化环境，安装简便，便于开发和实验。


<details>
  <summary>Details</summary>
Motivation: 现有机器人学习框架安装复杂、依赖繁多、扩展困难，同时对于高效仿真的需求越来越高。该论文旨在解决这些痛点，提供一个更易于安装和实验的高性能框架。

Method: mjlab借鉴Isaac Lab的模块化API，实现可组合的观测、奖励和事件模块，集成MuJoCo Warp实现GPU加速物理仿真，提供单命令安装和最小化依赖，直接操作MuJoCo数据结构。

Result: mjlab框架成功设计并实现，支持速度跟踪、动作模仿及操作任务的参考实例，验证了其功能完整和可用性强。

Conclusion: mjlab降低了机器人学习实验的门槛，提升了实验效率，为社区提供了强大的开源平台，适合广泛的研究与开发应用。

Abstract: We present mjlab, a lightweight, open-source framework for robot learning that combines GPU-accelerated simulation with composable environments and minimal setup friction. mjlab adopts the manager-based API introduced by Isaac Lab, where users compose modular building blocks for observations, rewards, and events, and pairs it with MuJoCo Warp for GPU-accelerated physics. The result is a framework installable with a single command, requiring minimal dependencies, and providing direct access to native MuJoCo data structures. mjlab ships with reference implementations of velocity tracking, motion imitation, and manipulation tasks.

</details>


### [201] [ReactEMG Stroke: Healthy-to-Stroke Few-shot Adaptation for sEMG-Based Intent Detection](https://arxiv.org/abs/2601.22090)
*Runsheng Wang,Katelyn Lee,Xinyue Zhu,Lauren Winterbottom,Dawn M. Nilsen,Joel Stein,Matei Ciocarlie*

Main category: cs.RO

TL;DR: 该论文提出一种利用健康人群sEMG预训练模型进行快速适应中风患者意图检测的方法，能显著提升检测精度并降低标定负担。


<details>
  <summary>Details</summary>
Motivation: 传统表面肌电(sEMG)用于中风后手部康复意图检测，需要长时间、个性化标定，且对信号变化较敏感，实用性受限。因此，急需开发更高效、健壮的意图检测方法。

Method: 作者提出一种健康人到中风患者的适应性迁移方案：先在大量健康人sEMG数据上训练意图检测模型，然后用少量特定中风受试者数据进行微调。比较三种适应策略（只调整分类头、LoRA高效适配器、端到端微调），并设计含信号变化（如漂移、姿势、臂带移动）的真实场景数据集验证效果。

Result: 健康人预训练并适应的模型，相比零样本迁移和中风患者单独训练，在相同数据条件下，意图检测表现明显提升。最佳方法可使平均状态转换精度从0.42提升到0.61、原始准确率从0.69提升到0.78。

Conclusion: 通过迁移可复用的健康人群EMG表征，不但能减少中风患者意图检测的校准工作量，还提升了系统面对现实应用中信号变化的鲁棒性，推进了基于sEMG的实时康复控制应用。

Abstract: Surface electromyography (sEMG) is a promising control signal for assist-as-needed hand rehabilitation after stroke, but detecting intent from paretic muscles often requires lengthy, subject-specific calibration and remains brittle to variability. We propose a healthy-to-stroke adaptation pipeline that initializes an intent detector from a model pretrained on large-scale able-bodied sEMG, then fine-tunes it for each stroke participant using only a small amount of subject-specific data. Using a newly collected dataset from three individuals with chronic stroke, we compare adaptation strategies (head-only tuning, parameter-efficient LoRA adapters, and full end-to-end fine-tuning) and evaluate on held-out test sets that include realistic distribution shifts such as within-session drift, posture changes, and armband repositioning. Across conditions, healthy-pretrained adaptation consistently improves stroke intent detection relative to both zero-shot transfer and stroke-only training under the same data budget; the best adaptation methods improve average transition accuracy from 0.42 to 0.61 and raw accuracy from 0.69 to 0.78. These results suggest that transferring a reusable healthy-domain EMG representation can reduce calibration burden while improving robustness for real-time post-stroke intent detection.

</details>


### [202] [DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation](https://arxiv.org/abs/2601.22153)
*Haozhe Xie,Beichen Wen,Jiarui Zheng,Zhaoxi Chen,Fangzhou Hong,Haiwen Diao,Ziwei Liu*

Main category: cs.RO

TL;DR: 本文提出了一种面向动态物体操作的新型视觉-语言-动作（VLA）模型框架DynamicVLA，能够实现对动态场景下物体的快速感知、时序推理与实时控制，显著提升了对动态环境的适应与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 虽然现有VLA模型在静态物体操作任务上表现出较强泛化能力，但在需要快速感知、时序预测和连续控制的动态操作场景中仍表现不佳。因此，研究者旨在突破动态操作这一难题，提升模型在实际复杂环境中的应用价值。

Method: 该工作设计了三项核心创新：1）构建了0.4B参数量、基于卷积视觉编码器的紧凑VLA模型，提升空间编码效率和多模态推理速度；2）提出连续推理机制，实现推理与执行的重叠进程，从而降低延迟，及时适应目标运动；3）提出潜变量感知的动作流机制，使动作执行与感知过程时序对齐。同时，作者全新构建了动态物体操作数据集DOM，包括20万合成和2000真实场景，方便模型训练和评测。

Result: 实验证明，DynamicVLA在响应速度、感知能力和泛化能力上相比现有方法有显著提升，在多种体现设备上的动态物体操作任务中均取得了优异表现。

Conclusion: DynamicVLA作为统一的动态物体操作框架，为VLA模型从静态向动态高效泛化迈出了重要一步，也为后续动态操作研究和应用提供了数据和方法基础。

Abstract: Manipulating dynamic objects remains an open challenge for Vision-Language-Action (VLA) models, which, despite strong generalization in static manipulation, struggle in dynamic scenarios requiring rapid perception, temporal anticipation, and continuous control. We present DynamicVLA, a framework for dynamic object manipulation that integrates temporal reasoning and closed-loop adaptation through three key designs: 1) a compact 0.4B VLA using a convolutional vision encoder for spatially efficient, structurally faithful encoding, enabling fast multimodal inference; 2) Continuous Inference, enabling overlapping reasoning and execution for lower latency and timely adaptation to object motion; and 3) Latent-aware Action Streaming, which bridges the perception-execution gap by enforcing temporally aligned action execution. To fill the missing foundation of dynamic manipulation data, we introduce the Dynamic Object Manipulation (DOM) benchmark, built from scratch with an auto data collection pipeline that efficiently gathers 200K synthetic episodes across 2.8K scenes and 206 objects, and enables fast collection of 2K real-world episodes without teleoperation. Extensive evaluations demonstrate remarkable improvements in response speed, perception, and generalization, positioning DynamicVLA as a unified framework for general dynamic object manipulation across embodiments.

</details>
