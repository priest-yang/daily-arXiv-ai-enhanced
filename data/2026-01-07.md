<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 66]
- [cs.CL](#cs.CL) [Total: 83]
- [cs.RO](#cs.RO) [Total: 29]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Self-Supervised Masked Autoencoders with Dense-Unet for Coronary Calcium Removal in limited CT Data](https://arxiv.org/abs/2601.02392)
*Mo Chen*

Main category: cs.CV

TL;DR: 冠脉钙化会在CTA中造成blooming伪影，影响狭窄诊断。论文提出Dense-MAE自监督预训练方法，通过随机掩盖三维血管补丁并重建，提升少样本场景下钙化伪影去除的效果。


<details>
  <summary>Details</summary>
Motivation: 当前深度CNN方法去除冠脉钙化伪影需要大量标注数据，而医学领域高质量数据难以获取。受3D点云Masked Autoencoder启发，作者希望利用自监督方法减少对人工标注的依赖。

Method: 提出Dense-MAE框架，将Dense-Unet与MAE思想结合。通过随机mask三维血管补丁，让模型自监督学习重建并捕捉血管拓扑高层特征，用于钙化伪影去除任务预训练。

Result: 在临床CTA数据集上验证表明，该MAE式预训练可显著提升Dense-Unet模型在少样本情况下的钙化伪影修复精度及狭窄程度估计，相比直接训练有明显优势。

Conclusion: Dense-MAE实现了无需人工标注情况下，获得有效的特征学习，从而提升钙化伪影去除效果，为实际临床应用提供更准确的辅助诊断。

Abstract: Coronary calcification creates blooming artifacts in Computed Tomography Angiography (CTA), severely hampering the diagnosis of lumen stenosis. While Deep Convolutional Neural Networks (DCNNs) like Dense-Unet have shown promise in removing these artifacts via inpainting, they often require large labeled datasets which are scarce in the medical domain. Inspired by recent advancements in Masked Autoencoders (MAE) for 3D point clouds, we propose \textbf{Dense-MAE}, a novel self-supervised learning framework for volumetric medical data. We introduce a pre-training strategy that randomly masks 3D patches of the vessel lumen and trains the Dense-Unet to reconstruct the missing geometry. This forces the encoder to learn high-level latent features of arterial topology without human annotation. Experimental results on clinical CTA datasets demonstrate that initializing the Calcium Removal network with our MAE-based weights significantly improves inpainting accuracy and stenosis estimation compared to training from scratch, specifically in few-shot scenarios.

</details>


### [2] [Expert-Guided Explainable Few-Shot Learning with Active Sample Selection for Medical Image Analysis](https://arxiv.org/abs/2601.02409)
*Longwei Wang,Ifrat Ikhtear Uddin,KC Santosh*

Main category: cs.CV

TL;DR: 本文提出了两个增强医学图像分析的方法框架，以应对数据稀缺和模型可解释性不足的问题，提升在不同医学影像任务中的表现和可解释性。


<details>
  <summary>Details</summary>
Motivation: 医学影像分析领域在实际部署中面对有标注数据稀少和模型决策过程难以解释两大核心难题。虽然少样本学习和主动学习可以部分缓解数据问题，但缺少对模型可解释性的关注，这限制了AI在临床场景下的广泛应用。

Method: 提出了EGxFSL（专家引导的可解释少样本学习）和xGAL（可解释性引导的主动学习）两种框架。EGxFSL借助专家标注的兴趣区域，结合Grad-CAM进行空间引导监督，在原型分类的基础上提升可解释性。xGAL则在主动学习数据采集时，综合预测不确定性与注意力偏差，实现由可解释性驱动的样本筛选。两者形成训练和采样的闭环系统。

Result: 在BraTS、VinDr-CXR和SIIM-COVID-19等数据集上，提出的方法分别取得92%、76%和62%的准确率，均优于传统基线方法；xGAL在样本极度稀缺的情况下，使用680个样本可获得76%准确率（明显优于随机采样）。Grad-CAM可视化显示模型聚焦于诊断相关区域，且在乳腺超声的测试中展示了跨模态泛化能力。

Conclusion: 本研究提出的双框架有效提升了医学影像分析在少样本和可解释性方面的能力，证明可解释性引导的数据选择和训练能提升模型在多种医学影像任务下的有效性和可信度。

Abstract: Medical image analysis faces two critical challenges: scarcity of labeled data and lack of model interpretability, both hindering clinical AI deployment. Few-shot learning (FSL) addresses data limitations but lacks transparency in predictions. Active learning (AL) methods optimize data acquisition but overlook interpretability of acquired samples. We propose a dual-framework solution: Expert-Guided Explainable Few-Shot Learning (EGxFSL) and Explainability-Guided AL (xGAL). EGxFSL integrates radiologist-defined regions-of-interest as spatial supervision via Grad-CAM-based Dice loss, jointly optimized with prototypical classification for interpretable few-shot learning. xGAL introduces iterative sample acquisition prioritizing both predictive uncertainty and attention misalignment, creating a closed-loop framework where explainability guides training and sample selection synergistically. On the BraTS (MRI), VinDr-CXR (chest X-ray), and SIIM-COVID-19 (chest X-ray) datasets, we achieve accuracies of 92\%, 76\%, and 62\%, respectively, consistently outperforming non-guided baselines across all datasets. Under severe data constraints, xGAL achieves 76\% accuracy with only 680 samples versus 57\% for random sampling. Grad-CAM visualizations demonstrate guided models focus on diagnostically relevant regions, with generalization validated on breast ultrasound confirming cross-modality applicability.

</details>


### [3] [MIAR: Modality Interaction and Alignment Representation Fuison for Multimodal Emotion](https://arxiv.org/abs/2601.02414)
*Jichao Zhu,Jun Yu*

Main category: cs.CV

TL;DR: 本论文提出了一种新的多模态情感识别方法MIAR，能够更好地融合和对齐语言、视觉和音频特征，在主流数据集上取得了优于现有方法的效果。


<details>
  <summary>Details</summary>
Motivation: 以往多模态情感识别方法在处理模态间巨大分布差异和不同模态对任务贡献差异时存在不足，且对跨文本特征的泛化能力弱，影响多模态环境下的性能。

Method: 提出了Modality Interaction and Alignment Representation（MIAR）网络，通过模态特征交互生成特征token，以表征不同模态间的信息提取关系，并利用对比学习和归一化策略对齐不同模态。

Result: 在CMU-MOSI和CMU-MOSEI两个公开数据集上进行实验，MIAR方法均优于最新的多模态情感识别相关方法。

Conclusion: 研究表明，充分考虑模态间交互与对齐的方法能显著提升多模态情感识别性能。

Abstract: Multimodal Emotion Recognition (MER) aims to perceive human emotions through three modes: language, vision, and audio. Previous methods primarily focused on modal fusion without adequately addressing significant distributional differences among modalities or considering their varying contributions to the task. They also lacked robust generalization capabilities across diverse textual model features, thus limiting performance in multimodal scenarios. Therefore, we propose a novel approach called Modality Interaction and Alignment Representation (MIAR). This network integrates contextual features across different modalities using a feature interaction to generate feature tokens to represent global representations of this modality extracting information from other modalities. These four tokens represent global representations of how each modality extracts information from others. MIAR aligns different modalities using contrastive learning and normalization strategies. We conduct experiments on two benchmarks: CMU-MOSI and CMU-MOSEI datasets, experimental results demonstrate the MIAR outperforms state-of-the-art MER methods.

</details>


### [4] [Multimodal Sentiment Analysis based on Multi-channel and Symmetric Mutual Promotion Feature Fusion](https://arxiv.org/abs/2601.02415)
*Wangyuan Zhu,Jun Yu*

Main category: cs.CV

TL;DR: 本文提出了一种改进的多模态情感分析方法，通过多通道特征提取和对称互促特征融合显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态情感分析面临单一模态特征提取不足和特征融合时忽视模态间差异的问题，导致情感识别效果受限。

Method: 首先分别在视觉和听觉模态提取多通道特征，增强模态内部特征表达；其次，提出对称互促（SMP）跨模态特征融合方法，结合对称跨模态注意力与自注意力机制，实现模态间有用信息的交换并增强互动；最后，将模态内和融合后的特征整合，兼顾互补与差异性。

Result: 在两个基准数据集上的实验表明，所提方法在多模态情感分析任务中取得了有效且优越的表现。

Conclusion: 通过丰富特征提取和改进特征融合机制，所提出方法能够更好地捕捉和利用多模态之间的互补和差异性信息，提高情感识别准确性。

Abstract: Multimodal sentiment analysis is a key technology in the fields of human-computer interaction and affective computing. Accurately recognizing human emotional states is crucial for facilitating smooth communication between humans and machines. Despite some progress in multimodal sentiment analysis research, numerous challenges remain. The first challenge is the limited and insufficiently rich features extracted from single modality data. Secondly, most studies focus only on the consistency of inter-modal feature information, neglecting the differences between features, resulting in inadequate feature information fusion. In this paper, we first extract multi-channel features to obtain more comprehensive feature information. We employ dual-channel features in both the visual and auditory modalities to enhance intra-modal feature representation. Secondly, we propose a symmetric mutual promotion (SMP) inter-modal feature fusion method. This method combines symmetric cross-modal attention mechanisms and self-attention mechanisms, where the cross-modal attention mechanism captures useful information from other modalities, and the self-attention mechanism models contextual information. This approach promotes the exchange of useful information between modalities, thereby strengthening inter-modal interactions. Furthermore, we integrate intra-modal features and inter-modal fused features, fully leveraging the complementarity of inter-modal feature information while considering feature information differences. Experiments conducted on two benchmark datasets demonstrate the effectiveness and superiority of our proposed method.

</details>


### [5] [Watch Wider and Think Deeper: Collaborative Cross-modal Chain-of-Thought for Complex Visual Reasoning](https://arxiv.org/abs/2601.02422)
*Wenting Lu,Didi Zhu,Tao Shen,Donglin Zhu,Ayong Ye,Chao Wu*

Main category: cs.CV

TL;DR: 该论文提出了CoCoT（Collaborative Cross-modal Thought）框架，通过动态多区域定位和关系感知推理，有效提升了多模态推理的效果，并构建了包含多区域标注和结构化推理链的数据集CoCoT-70K，在多个基准测试上显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的链式思维（Chain-of-Thought）方法在处理跨模态推理时主要存在两个问题：一是过度依赖单一、粗粒度的图像区域；二是在推理链的连续步骤之间存在语义割裂，导致推理连贯性和准确性下降。为此，作者希望设计能够更真实反映视觉—语言融合推理机制的方法框架。

Method: 作者提出CoCoT框架，包含两个核心创新：（1）动态多区域定位方法，可根据具体问题自适应地检测最相关的图像区域；（2）关系感知推理机制，能够迭代地将多个区域的视觉信息协同对齐，形成逻辑连贯的思维链。此外，作者还构建了CoCoT-70K数据集，涵盖7万多条高质量、多区域标注和结构化推理链样本。

Result: 通过在LLaVA-1.5和Qwen2-VL等六个具有挑战性的多模态推理基准上进行大量实验，CoCoT框架取得了平均15.4%（LLaVA-1.5）和4.0%（Qwen2-VL）的准确率提升，显著优于现有方法。

Conclusion: CoCoT框架有效解决了跨模态推理中区域粒度粗和语义割裂问题，构建的数据集和代码已开源，为复杂视觉推理任务提供了新范式和强有力支持。

Abstract: Multi-modal reasoning requires the seamless integration of visual and linguistic cues, yet existing Chain-of-Thought methods suffer from two critical limitations in cross-modal scenarios: (1) over-reliance on single coarse-grained image regions, and (2) semantic fragmentation between successive reasoning steps. To address these issues, we propose the CoCoT (Collaborative Coross-modal Thought) frame- work, built upon two key innovations: a) Dynamic Multi-Region Grounding to adaptively detect the most relevant image regions based on the question, and b) Relation-Aware Reasoning to enable multi-region collaboration by iteratively align- ing visual cues to form a coherent and logical chain of thought. Through this approach, we construct the CoCoT-70K dataset, comprising 74,691 high-quality samples with multi-region annotations and structured reasoning chains. Extensive experiments demonstrate that CoCoT significantly enhances complex visual rea- soning, achieving an average accuracy improvement of 15.4% on LLaVA-1.5 and 4.0% on Qwen2-VL across six challenging benchmarks. The data and code are available at: https://github.com/deer-echo/CoCoT.

</details>


### [6] [NitroGen: An Open Foundation Model for Generalist Gaming Agents](https://arxiv.org/abs/2601.02427)
*Loïc Magne,Anas Awadalla,Guanzhi Wang,Yinzhen Xu,Joshua Belofsky,Fengyuan Hu,Joohwan Kim,Ludwig Schmidt,Georgia Gkioxari,Jan Kautz,Yisong Yue,Yejin Choi,Yuke Zhu,Linxi "Jim" Fan*

Main category: cs.CV

TL;DR: 本文提出了NitroGen，一种面向多游戏的通用视觉-动作基础模型，通过大规模游戏视频学习，可在不同类型的游戏任务中表现优异，并展现出较强的跨游戏泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前游戏智能体通常只能解决单一特定游戏，缺乏在多种游戏或任务类型间泛化的能力。本研究旨在构建一个能跨越上千种游戏、具备更强泛化能力的通用游戏智能体，并推动通用化体智能体的研究。

Method: 1）自动从互联网上收集并提取玩家操作，构建包含40,000小时、1000多款游戏的视频-动作大数据集；2）搭建多游戏的基准评测环境以系统性测量泛化效果；3）通过大规模行为克隆训练一个统一的视觉-动作模型NitroGen。

Result: NitroGen在3D动作游戏、2D平台跳跃类高精度操作、程序生成世界中的探索任务等多样领域均表现出色。在迁移到新游戏的能力上，NitroGen相比从零训练模型任务成功率最高提升52%。

Conclusion: NitroGen证明了基于大规模游戏视频和统一模型架构，能够实现强大、通用并具备相当泛化能力的游戏智能体。该研究为多游戏通用体和具身智能领域提供了重要数据、评测标准和模型工具。

Abstract: We introduce NitroGen, a vision-action foundation model for generalist gaming agents that is trained on 40,000 hours of gameplay videos across more than 1,000 games. We incorporate three key ingredients: 1) an internet-scale video-action dataset constructed by automatically extracting player actions from publicly available gameplay videos, 2) a multi-game benchmark environment that can measure cross-game generalization, and 3) a unified vision-action model trained with large-scale behavior cloning. NitroGen exhibits strong competence across diverse domains, including combat encounters in 3D action games, high-precision control in 2D platformers, and exploration in procedurally generated worlds. It transfers effectively to unseen games, achieving up to 52% relative improvement in task success rates over models trained from scratch. We release the dataset, evaluation suite, and model weights to advance research on generalist embodied agents.

</details>


### [7] [TAP-ViTs: Task-Adaptive Pruning for On-Device Deployment of Vision Transformers](https://arxiv.org/abs/2601.02437)
*Zhibo Wang,Zuoyuan Zhang,Xiaoyi Pang,Qile Zhang,Xuanyi Hao,Shuguo Zhuo,Peng Sun*

Main category: cs.CV

TL;DR: 本文提出TAP-ViTs，一种无须访问原始本地数据、可以为每个设备自适应裁剪ViT的框架。方法通过GMM参数，构建任务代表性的数据集，结合多粒度重要性评估，实现高效且隐私友好的裁剪，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前ViT裁剪方法无法兼顾设备异质性和隐私保护，导致模型要么无法适配每台设备，要么需求本地数据，违背隐私原则。作者旨在解决这一矛盾，在不暴露本地原始数据的前提下，为每台设备定制裁剪ViT模型。

Method: 作者提出TAP-ViTs框架。首先，每台设备用高斯混合模型(GMM)拟合本地数据分布，并仅上传GMM参数，无需上传原始数据。云端据此从公共数据集中筛选分布一致的样本，为每个设备构建任务代理数据集。然后，通过同时评估神经元和层级重要性，实现细粒度的、任务感知的ViT剪枝。

Result: 在多个ViT骨干网络和数据集上进行大量实验，TAP-ViTs在相似压缩率下，准确率和效率都优于目前最好的裁剪方法。

Conclusion: TAP-ViTs实现了隐私保护、设备自适应的ViT裁剪，解决了现有方法的局限，有望推动ViT在隐私敏感和异构终端中的实际部署与应用。

Abstract: Vision Transformers (ViTs) have demonstrated strong performance across a wide range of vision tasks, yet their substantial computational and memory demands hinder efficient deployment on resource-constrained mobile and edge devices. Pruning has emerged as a promising direction for reducing ViT complexity. However, existing approaches either (i) produce a single pruned model shared across all devices, ignoring device heterogeneity, or (ii) rely on fine-tuning with device-local data, which is often infeasible due to limited on-device resources and strict privacy constraints. As a result, current methods fall short of enabling task-customized ViT pruning in privacy-preserving mobile computing settings. This paper introduces TAP-ViTs, a novel task-adaptive pruning framework that generates device-specific pruned ViT models without requiring access to any raw local data. Specifically, to infer device-level task characteristics under privacy constraints, we propose a Gaussian Mixture Model (GMM)-based metric dataset construction mechanism. Each device fits a lightweight GMM to approximate its private data distribution and uploads only the GMM parameters. Using these parameters, the cloud selects distribution-consistent samples from public data to construct a task-representative metric dataset for each device. Based on this proxy dataset, we further develop a dual-granularity importance evaluation-based pruning strategy that jointly measures composite neuron importance and adaptive layer importance, enabling fine-grained, task-aware pruning tailored to each device's computational budget. Extensive experiments across multiple ViT backbones and datasets demonstrate that TAP-ViTs consistently outperforms state-of-the-art pruning methods under comparable compression ratios.

</details>


### [8] [Understanding Pure Textual Reasoning for Blind Image Quality Assessment](https://arxiv.org/abs/2601.02441)
*Yuan Li,Shin'ya Nishida*

Main category: cs.CV

TL;DR: 本文分析了文本推理在盲图像质量评估（BIQA）中的作用，并通过三种范式（Chain-of-Thought、自洽性、自动编码器）探讨图像、文本与评分三者间的信息流关系。实验结果揭示只用文本时性能大幅下降，自洽性范式能显著提升一致性，自动编码器表现一般。


<details>
  <summary>Details</summary>
Motivation: 文本推理方法在BIQA中被广泛采用，但目前不清楚文本信息对质量预测的贡献有多大，以及文本能否充分代表与分数相关的图像内容，因此论文旨在深入理解文本在BIQA中的实际作用。

Method: 作者以信息流为视角，设计了三种学习图像-文本-评分关系的范式：Chain-of-Thought（思维链）、Self-Consistency（自洽性）、Autoencoder（自动编码器），并与现有BIQA模型进行对比实验，考察不同条件下评分预测的准确性。

Result: 实验显示，只有使用文本信息时原有模型的评分预测性能大幅下降；Chain-of-Thought范式提升有限；自洽性范式能大幅缩小图像和文本驱动得分预测之间的差距（相关性差异缩小至0.02/0.03）；自动编码器虽然未能有效缩小差距，但提供了进一步优化的方向。

Conclusion: 本文结论是：单独依靠文本用于BIQA存在信息损失，自洽性方法对于提升文本推理在高层次视觉任务的表现至关重要，自动编码器思路虽未优于自洽性，但为后续优化提供了思路。

Abstract: Textual reasoning has recently been widely adopted in Blind Image Quality Assessment (BIQA). However, it remains unclear how textual information contributes to quality prediction and to what extent text can represent the score-related image contents. This work addresses these questions from an information-flow perspective by comparing existing BIQA models with three paradigms designed to learn the image-text-score relationship: Chain-of-Thought, Self-Consistency, and Autoencoder. Our experiments show that the score prediction performance of the existing model significantly drops when only textual information is used for prediction. Whereas the Chain-of-Thought paradigm introduces little improvement in BIQA performance, the Self-Consistency paradigm significantly reduces the gap between image- and text-conditioned predictions, narrowing the PLCC/SRCC difference to 0.02/0.03. The Autoencoder-like paradigm is less effective in closing the image-text gap, yet it reveals a direction for further optimization. These findings provide insights into how to improve the textual reasoning for BIQA and high-level vision tasks.

</details>


### [9] [Evaluating the Diagnostic Classification Ability of Multimodal Large Language Models: Insights from the Osteoarthritis Initiative](https://arxiv.org/abs/2601.02443)
*Li Wang,Xi Chen,XiangWen Deng,HuaHui Yi,ZeKun Jiang,Kang Li,Jian Li*

Main category: cs.CV

TL;DR: 多模态大模型（MLLM）在医学视觉问答与报告生成上表现良好，但其能力难以迁移到疾病分类任务。本研究发现，专业的视觉编码器单独用于膝骨关节炎影像分类表现优于完整MLLM，且LLM微调并无提升。小规模、类别均衡数据优于大规模失衡数据。建议医学影像分类工作，更应关注视觉编码器优化和数据质量。


<details>
  <summary>Details</summary>
Motivation: 膝骨关节炎影响全球3-4亿人，但在医学多模态大模型基准中研究较少。作者希望评估和理解MLLM在此重要分类任务中的实际作用和各组件贡献。

Method: 对不同MLLM结构（包括视觉编码器、连接器、LLM）采用系统消融实验，以及不同训练策略下的对比评估，分析各部分对诊断准确率的影响。特别对比了仅用视觉编码器、完整MLLM流程、LLM微调、基于提示等方式。

Result: 单独训练的视觉编码器在膝骨关节炎影像分类中准确率优于完整的MLLM流程，LLM微调未带来提升。采用500张类别均衡小数据集的LoRA微调，效果优于使用5,778张类别不均衡大数据集。

Conclusion: MLLM架构在高确定性需求的医学疾病分类任务中不适宜做主分类器，更适合作为解释和报告工具。建议医学分类任务以视觉编码器优化和数据集均衡为首要。

Abstract: Multimodal large language models (MLLMs) show promising performance on medical visual question answering (VQA) and report generation, but these generation and explanation abilities do not reliably transfer to disease-specific classification. We evaluated MLLM architectures on knee osteoarthritis (OA) radiograph classification, which remains underrepresented in existing medical MLLM benchmarks, even though knee OA affects an estimated 300 to 400 million people worldwide. Through systematic ablation studies manipulating the vision encoder, the connector, and the large language model (LLM) across diverse training strategies, we measured each component's contribution to diagnostic accuracy. In our classification task, a trained vision encoder alone could outperform full MLLM pipelines in classification accuracy and fine-tuning the LLM provided no meaningful improvement over prompt-based guidance. And LoRA fine-tuning on a small, class-balanced dataset (500 images) gave better results than training on a much larger but class-imbalanced set (5,778 images), indicating that data balance and quality can matter more than raw scale for this task. These findings suggest that for domain-specific medical classification, LLMs are more effective as interpreters and report generators rather than as primary classifiers. Therefore, the MLLM architecture appears less suitable for medical image diagnostic classification tasks that demand high certainty. We recommend prioritizing vision encoder optimization and careful dataset curation when developing clinically applicable systems.

</details>


### [10] [A Spatio-Temporal Deep Learning Approach For High-Resolution Gridded Monsoon Prediction](https://arxiv.org/abs/2601.02445)
*Parashjyoti Borah,Sanghamitra Sarkar,Ranjan Phukan*

Main category: cs.CV

TL;DR: 本文提出用深度学习方法提升印度夏季风（ISM）降雨空间分辨率的长时效预报能力。


<details>
  <summary>Details</summary>
Motivation: 传统气候预报只给出单一、区域平均值，缺乏对地区资源管理至关重要的空间精细度。印度夏季风对十几亿人的农业、经济和水安全有巨大影响，因此需要能提供高分辨率地区降雨预测的新方法。

Method: 将多变量的前期大气与海洋场数据视为多通道图像序列（类似视频），基于85年ERA5再分析数据（预测因子）和IMD降雨数据（预测目标），用卷积神经网络（CNN）架构从1-5月数据预测后续季风四个月降雨的高分辨率格点图。

Result: 该深度学习框架不仅能为每个月产生独立的降水预测，还能输出总季节平均，为季节内和季节尺度的降雨预报都提供了实用性。

Conclusion: 该方法显著提升了印度夏季风降雨预报的空间分辨率，有助于支持区域级农业、经济和水资源管理。

Abstract: The Indian Summer Monsoon (ISM) is a critical climate phenomenon, fundamentally impacting the agriculture, economy, and water security of over a billion people. Traditional long-range forecasting, whether statistical or dynamical, has predominantly focused on predicting a single, spatially-averaged seasonal value, lacking the spatial detail essential for regional-level resource management. To address this gap, we introduce a novel deep learning framework that reframes gridded monsoon prediction as a spatio-temporal computer vision task. We treat multi-variable, pre-monsoon atmospheric and oceanic fields as a sequence of multi-channel images, effectively creating a video-like input tensor. Using 85 years of ERA5 reanalysis data for predictors and IMD rainfall data for targets, we employ a Convolutional Neural Network (CNN)-based architecture to learn the complex mapping from the five-month pre-monsoon period (January-May) to a high-resolution gridded rainfall pattern for the subsequent monsoon season. Our framework successfully produces distinct forecasts for each of the four monsoon months (June-September) as well as the total seasonal average, demonstrating its utility for both intra-seasonal and seasonal outlooks.

</details>


### [11] [Don't Mind the Gaps: Implicit Neural Representations for Resolution-Agnostic Retinal OCT Analysis](https://arxiv.org/abs/2601.02447)
*Bennet Kahrs,Julia Andresen,Fenja Falta,Monty Santarossa,Heinz Handels,Timo Kepp*

Main category: cs.CV

TL;DR: 本文针对常规视网膜OCT图像切片间距大、各向异性强的问题，提出基于隐式神经表示（INR）的两种三维分析框架，实现分辨率无关的视网膜结构分析。


<details>
  <summary>Details</summary>
Motivation: 当前临床OCT成像存在切片稀疏和各向异性，致使基于2D深度学习方法在高维分析时产生不连续或不一致的问题，并且卷积神经网络难以适应不同分辨率数据。需要能适用于不同分辨率和扫描协议的方法，实现视网膜三维结构的高质量分析。

Method: 提出两种INR框架：1）结合en-face模态辅助实现B-scan间的插值，增强切片间结构一致性；2）创建分辨率无关的视网膜图谱，实现对不同数据的广泛分析。两者均采用基于人口的训练方式提升模型泛化能力。

Result: 两种方法均能有效提升OCT各向异性数据的三维结构重建准确性，能够适应大B-scan间隔，突破传统方法的分辨率限制，为视网膜体积分析和病变检测提供新途径。

Conclusion: 基于INR的分辨率无关三维分析框架为稀疏采样的OCT视网膜影像提供一致、泛化能力强的结构重建手段，有望推动临床视网膜图像处理与精细化病理评估。

Abstract: Routine clinical imaging of the retina using optical coherence tomography (OCT) is performed with large slice spacing, resulting in highly anisotropic images and a sparsely scanned retina. Most learning-based methods circumvent the problems arising from the anisotropy by using 2D approaches rather than performing volumetric analyses. These approaches inherently bear the risk of generating inconsistent results for neighboring B-scans. For example, 2D retinal layer segmentations can have irregular surfaces in 3D. Furthermore, the typically used convolutional neural networks are bound to the resolution of the training data, which prevents their usage for images acquired with a different imaging protocol. Implicit neural representations (INRs) have recently emerged as a tool to store voxelized data as a continuous representation. Using coordinates as input, INRs are resolution-agnostic, which allows them to be applied to anisotropic data. In this paper, we propose two frameworks that make use of this characteristic of INRs for dense 3D analyses of retinal OCT volumes. 1) We perform inter-B-scan interpolation by incorporating additional information from en-face modalities, that help retain relevant structures between B-scans. 2) We create a resolution-agnostic retinal atlas that enables general analysis without strict requirements for the data. Both methods leverage generalizable INRs, improving retinal shape representation through population-based training and allowing predictions for unseen cases. Our resolution-independent frameworks facilitate the analysis of OCT images with large B-scan distances, opening up possibilities for the volumetric evaluation of retinal structures and pathologies.

</details>


### [12] [PatchAlign3D: Local Feature Alignment for Dense 3D Shape understanding](https://arxiv.org/abs/2601.02457)
*Souhail Hadgi,Bingchen Gong,Ramana Sundararaman,Emery Pierson,Lei Li,Peter Wonka,Maks Ovsjanikov*

Main category: cs.CV

TL;DR: 现有的3D基础模型在整体任务上表现出色，但在局部零件级别推理上表现较差。本文提出了一种只用编码器的3D模型，直接从点云提取与语言对齐的局部特征，提升了零件级分割性能，且推理速度快，无须多视角渲染。


<details>
  <summary>Details</summary>
Motivation: 现有3D模型难以泛化到复杂的局部结构识别。尽管结合视觉与语言模型的新方法在细粒度任务上有所突破，但推理昂贵且未充分利用3D结构，存在效率和泛化性问题。

Method: 提出了一种两阶段的点云Transformer编码器预训练方法，第一阶段将2D视觉编码器的密集特征蒸馏到3D点云局部块，第二阶段通过对比学习方法将这些局部块的特征对齐到零件级文本嵌入，实现多模态融合训练。

Result: 该3D编码器能实现快速、零样本3D零件分割，无需推理时多视角渲染，在多个3D零件分割基准测试中，准确率显著优于现有基于渲染和普通前馈方法。

Conclusion: 本文证明了直接点云编码、结合多模态嵌入（视觉+文本）的方法在3D局部细粒度任务上的有效性和高效性，推动了3D基础模型向更精细与通用方向发展。

Abstract: Current foundation models for 3D shapes excel at global tasks (retrieval, classification) but transfer poorly to local part-level reasoning. Recent approaches leverage vision and language foundation models to directly solve dense tasks through multi-view renderings and text queries. While promising, these pipelines require expensive inference over multiple renderings, depend heavily on large language-model (LLM) prompt engineering for captions, and fail to exploit the inherent 3D geometry of shapes. We address this gap by introducing an encoder-only 3D model that produces language-aligned patch-level features directly from point clouds. Our pre-training approach builds on existing data engines that generate part-annotated 3D shapes by pairing multi-view SAM regions with VLM captioning. Using this data, we train a point cloud transformer encoder in two stages: (1) distillation of dense 2D features from visual encoders such as DINOv2 into 3D patches, and (2) alignment of these patch embeddings with part-level text embeddings through a multi-positive contrastive objective. Our 3D encoder achieves zero-shot 3D part segmentation with fast single-pass inference without any test-time multi-view rendering, while significantly outperforming previous rendering-based and feed-forward approaches across several 3D part segmentation benchmarks. Project website: https://souhail-hadgi.github.io/patchalign3dsite/

</details>


### [13] [CT Scans As Video: Efficient Intracranial Hemorrhage Detection Using Multi-Object Tracking](https://arxiv.org/abs/2601.02521)
*Amirreza Parvahan,Mohammad Hoseyni,Javad Khoramdel,Amirhossein Nikoofard*

Main category: cs.CV

TL;DR: 本文提出了一种高效的轻量级医学影像分析框架，通过将三维CT数据转化为视频序列，实现了2D检测效率与3D上下文信息的融合，适用于边缘设备。实验结果表明，该方法在保证灵敏度的同时，显著提升了检出精度。


<details>
  <summary>Details</summary>
Motivation: 3D卷积神经网络虽然在医学影像分析中表现出色，但对于边缘设备来说，其对内存和计算资源的需求过高，阻碍了实时医学影像分析的实际应用。因此，亟需一种能够兼顾效率和3D上下文理解的新方法。

Method: 作者将体积CT数据重新表述为视频流，应用于颅内出血（ICH）检测任务。在YOLO Nano系列多个版本中，选择mAP@50最高的作为2D切片级检测基础网络，并采用ByteTrack算法在z轴强化解剖一致性。为解决视频跟踪延迟问题，结合可自适应的混合推理策略和时空一致性滤波器，以区分真实病灶和预测噪声。

Result: 在独立测试集实验中，所提框架将检测精度（Precision）由基线2D检测器的0.703提升至0.779，并保持了高灵敏度。该方法以极低的计算代价近似实现了3D推理效果。

Conclusion: 该工作为资源受限环境下，如移动卒中单元和远程IoT诊疗，提供了可扩展的实时病患优先筛查解决方案。框架兼顾效率与准确性，具有广泛的应用潜力。

Abstract: Automated analysis of volumetric medical imaging on edge devices is severely constrained by the high memory and computational demands of 3D Convolutional Neural Networks (CNNs). This paper develops a lightweight computer vision framework that reconciles the efficiency of 2D detection with the necessity of 3D context by reformulating volumetric Computer Tomography (CT) data as sequential video streams. This video-viewpoint paradigm is applied to the time-sensitive task of Intracranial Hemorrhage (ICH) detection using the Hemorica dataset. To ensure operational efficiency, we benchmarked multiple generations of the YOLO architecture (v8, v10, v11 and v12) in their Nano configurations, selecting the version with the highest mAP@50 to serve as the slice-level backbone. A ByteTrack algorithm is then introduced to enforce anatomical consistency across the $z$-axis. To address the initialization lag inherent in video trackers, a hybrid inference strategy and a spatiotemporal consistency filter are proposed to distinguish true pathology from transient prediction noise. Experimental results on independent test data demonstrate that the proposed framework serves as a rigorous temporal validator, increasing detection Precision from 0.703 to 0.779 compared to the baseline 2D detector, while maintaining high sensitivity. By approximating 3D contextual reasoning at a fraction of the computational cost, this method provides a scalable solution for real-time patient prioritization in resource-constrained environments, such as mobile stroke units and IoT-enabled remote clinics.

</details>


### [14] [MovieRecapsQA: A Multimodal Open-Ended Video Question-Answering Benchmark](https://arxiv.org/abs/2601.02536)
*Shaden Shaar,Bradon Thymes,Sirawut Chaixanien,Claire Cardie,Bharath Hariharan*

Main category: cs.CV

TL;DR: 本文提出了一个新的开放式多模态视频问答基准MovieRecapsQA，利用电影剧情回顾视频及其文本摘要生成了约8200组问题-答案对，并为每组答案提供必要事实，实现参考文献无关的评测。


<details>
  <summary>Details</summary>
Motivation: 现有的视频问答基准很难有效涵盖多模态推理，且大多不是开放式，因为评估自由回答存在难度。该工作希望借助多模态数据更好地推动对真实世界复杂视频的理解与问答能力。

Method: 作者收集了YouTube电影剧情回顾视频及其字幕与文本摘要，从中生成对齐的问题-答案对，并标注验证答案所需的关键事实。基准中支持不同长度视频以及多种问题类型的细粒度分析。此外，作者用7个最先进的多语言多模态大模型进行了基准测试。

Result: 实验发现：1）纯视觉问题仍最具挑战；2）模型会偏好有文本输入的问题；3）各模型从视频中精准抽取事实信息的能力依然有限；4）专有大模型和开源大模型在依赖视频问题上表现接近。

Conclusion: MovieRecapsQA提供了开放式、多层次、多类型的视频理解评测，有助于深入分析与推动多模态大模型在视频理解上的发展。

Abstract: Understanding real-world videos such as movies requires integrating visual and dialogue cues to answer complex questions. Yet existing VideoQA benchmarks struggle to capture this multimodal reasoning and are largely not open-ended, given the difficulty of evaluating free-form answers. In this paper, we introduce a novel open-ended multi-modal VideoQA benchmark, MovieRecapsQA created using movie recap videos--a distinctive type of YouTube content that summarizes a film by presenting its key events through synchronized visual (recap video) and textual (recap summary) modalities. Using the recap summary, we generate $\approx 8.2$ K question-answer (QA) pairs (aligned with movie-subtitles) and provide the necessary "facts" needed to verify an answer in a reference-free manner. To our knowledge, this is the first open-ended VideoQA benchmark that supplies explicit textual context of the input (video and/or text); which we use for evaluation. Our benchmark provides videos of multiple lengths (i.e., recap-segments, movie-segments) and categorizations of questions (by modality and type) to enable fine-grained analysis. We evaluate the performance of seven state-of-the-art MLLMs using our benchmark and observe that: 1) visual-only questions remain the most challenging; 2) models default to textual inputs whenever available; 3) extracting factually accurate information from video content is still difficult for all models; and 4) proprietary and open-source models perform comparably on video-dependent questions.

</details>


### [15] [Shallow- and Deep-fake Image Manipulation Localization Using Vision Mamba and Guided Graph Neural Network](https://arxiv.org/abs/2601.02566)
*Junbin Zhang,Hamid Reza Tohidypour,Yixiao Wang,Panos Nasiopoulos*

Main category: cs.CV

TL;DR: 本文提出了一种结合Vision Mamba和引导式图神经网络（G-GNN）的深度学习方法，实现对浅仿（shallowfake）和深度伪造（deepfake）图像篡改区域的本地化，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究多聚焦于浅仿或深度伪造的图像篡改检测，缺乏能同时适用于两者的统一本地化方法。而不同类型伪造对社会的影响重大，因此需研发兼容两者的检测方案。

Method: 作者使用Vision Mamba网络提取特征图，以精确表达被篡改与未篡改区域的边界。同时，提出了Guided Graph Neural Network（G-GNN）模块，进一步增强篡改像素与真实像素之间的区分能力。

Result: 所提方法在浅仿及深度伪造图像的篡改区域本地化任务上，推理准确率高于现有主流方法。

Conclusion: 结合Vision Mamba和G-GNN模块的方案能有效本地化不同类型伪造图像的篡改区域，优于最新技术，具有实际应用价值。

Abstract: Image manipulation localization is a critical research task, given that forged images may have a significant societal impact of various aspects. Such image manipulations can be produced using traditional image editing tools (known as "shallowfakes") or advanced artificial intelligence techniques ("deepfakes"). While numerous studies have focused on image manipulation localization on either shallowfake images or deepfake videos, few approaches address both cases. In this paper, we explore the feasibility of using a deep learning network to localize manipulations in both shallow- and deep-fake images, and proposed a solution for such purpose. To precisely differentiate between authentic and manipulated pixels, we leverage the Vision Mamba network to extract feature maps that clearly describe the boundaries between tampered and untouched regions. To further enhance this separation, we propose a novel Guided Graph Neural Network (G-GNN) module that amplifies the distinction between manipulated and authentic pixels. Our evaluation results show that our proposed method achieved higher inference accuracy compared to other state-of-the-art methods.

</details>


### [16] [DreamLoop: Controllable Cinemagraph Generation from a Single Photograph](https://arxiv.org/abs/2601.02646)
*Aniruddha Mahapatra,Long Mai,Cusuh Ham,Feng Liu*

Main category: cs.CV

TL;DR: 本文提出一种从单张照片生成可控Cinemagraph（动态照片）的方法，称为DreamLoop，无需专门训练数据，生成更复杂且高质量的动画效果。


<details>
  <summary>Details</summary>
Motivation: 现有的图像动画技术只适用于简单、重复纹理的场景，且动画可控性差，难以实现一般场景中高质量、无缝循环的Cinemagraph效果，因此亟需一种通用、可控的Cinemagraph生成方法。

Method: 该方法基于通用视频扩散模型，通过添加两项关键训练目标（时间桥接和运动条件控制）进行自适应。生成时，使用输入图像作为首尾帧以保证无缝循环，通过指定静态轨迹保持背景静止，同时允许用户自定义目标物体的运动路径，实现动画轨迹和时序的直观控制。

Result: DreamLoop 可在无需专门Cinemagraph训练数据的条件下，生成符合用户意图、高质量、复杂、可控的Cinemagraph动画，其效果优于现有方法。

Conclusion: DreamLoop首次实现在任意场景下，通过灵活、直观的控制方式从单张照片生成高质量Cinemagraph，为艺术创作和相关应用提供了新的解决方案。

Abstract: Cinemagraphs, which combine static photographs with selective, looping motion, offer unique artistic appeal. Generating them from a single photograph in a controllable manner is particularly challenging. Existing image-animation techniques are restricted to simple, low-frequency motions and operate only in narrow domains with repetitive textures like water and smoke. In contrast, large-scale video diffusion models are not tailored for cinemagraph constraints and lack the specialized data required to generate seamless, controlled loops. We present DreamLoop, a controllable video synthesis framework dedicated to generating cinemagraphs from a single photo without requiring any cinemagraph training data. Our key idea is to adapt a general video diffusion model by training it on two objectives: temporal bridging and motion conditioning. This strategy enables flexible cinemagraph generation. During inference, by using the input image as both the first- and last- frame condition, we enforce a seamless loop. By conditioning on static tracks, we maintain a static background. Finally, by providing a user-specified motion path for a target object, our method provides intuitive control over the animation's trajectory and timing. To our knowledge, DreamLoop is the first method to enable cinemagraph generation for general scenes with flexible and intuitive controls. We demonstrate that our method produces high-quality, complex cinemagraphs that align with user intent, outperforming existing approaches.

</details>


### [17] [GRRE: Leveraging G-Channel Removed Reconstruction Error for Robust Detection of AI-Generated Images](https://arxiv.org/abs/2601.02709)
*Shuman He,Xiehua Li,Xioaju Yang,Yang Xiong,Keqin Li*

Main category: cs.CV

TL;DR: 提出一种利用去除绿色通道重建误差（GRRE）检测AI生成图片的新方法，具有优异的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前主流的检测方法在面对新型、未知的生成模型时精度显著下降，因此亟需提升检测方法的泛化能力。

Method: 观察到真实图片在去除绿色通道后重建的误差与AI生成图片存在显著差异，提出基于G通道移除重建误差（GRRE）的方法，利用重建误差进行检测。

Result: 在多种生成模型（包括训练时未见过的模型）上，GRRE方法均能实现高检测准确率，并对各种扰动与后处理操作有很强的鲁棒性，优于现有方法。

Conclusion: 基于通道移除重建的方法为AI生成图片取证提供了有效新工具，在生成式AI图像的时代对图像真实性保障具有重要意义。

Abstract: The rapid progress of generative models, particularly diffusion models and GANs, has greatly increased the difficulty of distinguishing synthetic images from real ones. Although numerous detection methods have been proposed, their accuracy often degrades when applied to images generated by novel or unseen generative models, highlighting the challenge of achieving strong generalization. To address this challenge, we introduce a novel detection paradigm based on channel removal reconstruction. Specifically, we observe that when the green (G) channel is removed from real images and reconstructed, the resulting reconstruction errors differ significantly from those of AI-generated images. Building upon this insight, we propose G-channel Removed Reconstruction Error (GRRE), a simple yet effective method that exploits this discrepancy for robust AI-generated image detection. Extensive experiments demonstrate that GRRE consistently achieves high detection accuracy across multiple generative models, including those unseen during training. Compared with existing approaches, GRRE not only maintains strong robustness against various perturbations and post-processing operations but also exhibits superior cross-model generalization. These results highlight the potential of channel-removal-based reconstruction as a powerful forensic tool for safeguarding image authenticity in the era of generative AI.

</details>


### [18] [CAMO: Category-Agnostic 3D Motion Transfer from Monocular 2D Videos](https://arxiv.org/abs/2601.02716)
*Taeyeon Kim,Youngju Na,Jumin Lee,Minhyuk Sung,Sung-Eui Yoon*

Main category: cs.CV

TL;DR: 本文提出了一种新的方法CAMO，实现了从单目2D视频无模板地将运动迁移到各种3D模型上，显著提升了精度和适用范围。


<details>
  <summary>Details</summary>
Motivation: 当前2D视频到3D资产的运动迁移存在姿态歧义和目标形状多样性的问题，通常需要针对类别定制3D模板，限制了技术的通用性和实际应用。

Method: 提出了CAMO方法，利用形态参数化的三维高斯点云模型和密集语义对应关系，通过优化方式联合调整形状和姿态，无需预定义模板或明确3D监督。

Result: 实验表明，CAMO在运动准确性、效率和视觉一致性上都优于现有方法，能广泛应用于不同物体类别和随拍视频。

Conclusion: CAMO方法为多类别、无模板的2D到3D运动迁移提供了有效方案，极大推动了该领域的研究进展。

Abstract: Motion transfer from 2D videos to 3D assets is a challenging problem, due to inherent pose ambiguities and diverse object shapes, often requiring category-specific parametric templates. We propose CAMO, a category-agnostic framework that transfers motion to diverse target meshes directly from monocular 2D videos without relying on predefined templates or explicit 3D supervision. The core of CAMO is a morphology-parameterized articulated 3D Gaussian splatting model combined with dense semantic correspondences to jointly adapt shape and pose through optimization. This approach effectively alleviates shape-pose ambiguities, enabling visually faithful motion transfer for diverse categories. Experimental results demonstrate superior motion accuracy, efficiency, and visual coherence compared to existing methods, significantly advancing motion transfer in varied object categories and casual video scenarios.

</details>


### [19] [Robust Mesh Saliency GT Acquisition in VR via View Cone Sampling and Geometric Smoothing](https://arxiv.org/abs/2601.02721)
*Guoquan Zheng,Jie Hao,Huiyu Duan,Yongming Han,Liang Yuan,Dong Zhang,Guangtao Zhai*

Main category: cs.CV

TL;DR: 提出了一种更符合人类视觉机制的3D网格显著性采集与扩散方法，以获得更真实、鲁棒的显著性标注。


<details>
  <summary>Details</summary>
Motivation: 现有3D网格显著性数据获取方法照搬2D图像的思路，忽略了3D与2D之间在几何结构和拓扑上的差异，导致显著性结果不真实、不鲁棒。尤其在虚拟现实中，这种局限影响到人类视觉建模和交互体验。

Method: 1. 提出视锥采样（VCS）策略，用高斯分布的射线束模拟人类中央凹感受野，从而增强复杂拓扑下的采样鲁棒性；2. 提出混合流形-欧几里得约束扩散（HCD）算法，将流形测地线约束与欧氏尺度相结合，实现网格拓扑一致的显著性传播。

Result: 新方法在抑制纹理注意力偏置、避免信号越界和解决拓扑短路、混叠现象方面表现优异，获得了更高保真度的3D注意力数据，提升了显著性研究的准确性与鲁棒性。

Conclusion: 该框架更好模拟了人与3D场景交互的真实感知过程，为3D网格显著性研究提供了新范式和更高质量的基准。

Abstract: Reliable 3D mesh saliency ground truth (GT) is essential for human-centric visual modeling in virtual reality (VR). However, current 3D mesh saliency GT acquisition methods are generally consistent with 2D image methods, ignoring the differences between 3D geometry topology and 2D image array. Current VR eye-tracking pipelines rely on single ray sampling and Euclidean smoothing, triggering texture attention and signal leakage across gaps. This paper proposes a robust framework to address these limitations. We first introduce a view cone sampling (VCS) strategy, which simulates the human foveal receptive field via Gaussian-distributed ray bundles to improve sampling robustness for complex topologies. Furthermore, a hybrid Manifold-Euclidean constrained diffusion (HCD) algorithm is developed, fusing manifold geodesic constraints with Euclidean scales to ensure topologically-consistent saliency propagation. By mitigating "topological short-circuits" and aliasing, our framework provides a high-fidelity 3D attention acquisition paradigm that aligns with natural human perception, offering a more accurate and robust baseline for 3D mesh saliency research.

</details>


### [20] [Foreground-Aware Dataset Distillation via Dynamic Patch Selection](https://arxiv.org/abs/2601.02727)
*Longzhen Li,Guang Li,Ren Togo,Keisuke Maeda,Takahiro Ogawa,Miki Haseyama*

Main category: cs.CV

TL;DR: 本论文提出了一种前景感知的数据集蒸馏方法，通过内容自适应地增强图像块选择，提高了蒸馏数据的质量和适用性。实验表明该方法优于现有标准，生成的合成数据更具代表性和通用性。


<details>
  <summary>Details</summary>
Motivation: 传统数据集蒸馏方法存在计算开销高、内存消耗大、生成图片不真实且噪声较多，以及架构泛化能力有限等问题。非优化方法虽一定程度改善了上述问题，但僵化的图像块选择策略仍会丢失主目标的重要信息，因此需要一种能够更好保留关键信息的新方法。

Method: 作者利用Grounded SAM2识别前景目标并计算单图像前景占比，进而为每一类别确定块选择阈值。根据阈值，设计了一种动态的块选择策略，对于前景占优的图片直接缩放全图，否则从多个候选块中选择最有信息量的那一块，实现前景感知与内容自适应的双路径策略。

Result: 在多个基准数据集上，大量实验结果表明该方法比现有优化和非优化蒸馏方法在保留主目标信息、提升蒸馏数据集质量、提升在不同网络架构与图片构成下的鲁棒性方面有持续提升。

Conclusion: 提出的前景感知动态块选择数据集蒸馏方法有效地减少了冗余背景，保留关键前景内容，同时提升了生成数据的代表性和适应性，对不同模型和场景均表现出更高的鲁棒性。

Abstract: In this paper, we propose a foreground-aware dataset distillation method that enhances patch selection in a content-adaptive manner. With the rising computational cost of training large-scale deep models, dataset distillation has emerged as a promising approach for constructing compact synthetic datasets that retain the knowledge of their large original counterparts. However, traditional optimization-based methods often suffer from high computational overhead, memory constraints, and the generation of unrealistic, noise-like images with limited architectural generalization. Recent non-optimization methods alleviate some of these issues by constructing distilled data from real image patches, but the used rigid patch selection strategies can still discard critical information about the main objects. To solve this problem, we first leverage Grounded SAM2 to identify foreground objects and compute per-image foreground occupancy, from which we derive a category-wise patch decision threshold. Guided by these thresholds, we design a dynamic patch selection strategy that, for each image, either selects the most informative patch from multiple candidates or directly resizes the full image when the foreground dominates. This dual-path mechanism preserves more key information about the main objects while reducing redundant background content. Extensive experiments on multiple benchmarks show that the proposed method consistently improves distillation performance over existing approaches, producing more informative and representative distilled datasets and enhancing robustness across different architectures and image compositions.

</details>


### [21] [HOLO: Homography-Guided Pose Estimator Network for Fine-Grained Visual Localization on SD Maps](https://arxiv.org/abs/2601.02730)
*Xuchang Zhong,Xu Cao,Jinke Feng,Hao Fang*

Main category: cs.CV

TL;DR: 本文提出了一种用于自动驾驶中基于标准清晰度(SD)地图的视觉定位的新方法，通过单应性约束显著提升了定位精度和训练效率，大幅优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有针对SD地图的视觉定位回归方法常忽略几何先验，导致定位精度和训练效率受限。作者希望引入新的方法改进定位表现。

Method: 提出同伦引导位姿估计器网络，通过将地面视角特征映射到鸟瞰图(BEV)并与地图特征进行语义对齐，构建满足单应性约束的输入对。利用同伦关系指导特征融合并约束位姿输出于有效可行区域。显式建模单应变换，并支持跨分辨率输入。

Result: 在nuScenes数据集上进行大量实验，所提方法在视觉定位准确性和训练效率上均显著优于当前SOTA方法。

Conclusion: 首次将BEV语义推理与单应性学习统一，显著提升了SD地图下的图像到地图定位性能，提升了模型灵活性，并促进后续研究。

Abstract: Visual localization on standard-definition (SD) maps has emerged as a promising low-cost and scalable solution for autonomous driving. However, existing regression-based approaches often overlook inherent geometric priors, resulting in suboptimal training efficiency and limited localization accuracy. In this paper, we propose a novel homography-guided pose estimator network for fine-grained visual localization between multi-view images and standard-definition (SD) maps. We construct input pairs that satisfy a homography constraint by projecting ground-view features into the BEV domain and enforcing semantic alignment with map features. Then we leverage homography relationships to guide feature fusion and restrict the pose outputs to a valid feasible region, which significantly improves training efficiency and localization accuracy compared to prior methods relying on attention-based fusion and direct 3-DoF pose regression. To the best of our knowledge, this is the first work to unify BEV semantic reasoning with homography learning for image-to-map localization. Furthermore, by explicitly modeling homography transformations, the proposed framework naturally supports cross-resolution inputs, enhancing model flexibility. Extensive experiments on the nuScenes dataset demonstrate that our approach significantly outperforms existing state-of-the-art visual localization methods. Code and pretrained models will be publicly released to foster future research.

</details>


### [22] [Unveiling and Bridging the Functional Perception Gap in MLLMs: Atomic Visual Alignment and Hierarchical Evaluation via PET-Bench](https://arxiv.org/abs/2601.02737)
*Zanting Ye,Xiaolong Niu,Xuanbin Wu,Xu Han,Shengyuan Liu,Jing Hao,Zhihao Peng,Hao Sun,Jieqin Lv,Fanghu Wang,Yanchao Huang,Hubing Wu,Yixuan Yuan,Habib Zaidi,Arman Rahmim,Yefeng Zheng,Lijun Lu*

Main category: cs.CV

TL;DR: 本论文发现当前多模态大模型（MLLMs）在功能影像学（如PET）任务上存在感知缺陷，提出PET-Bench基准和Atomic Visual Alignment（AVA）方法，有效提升了模型诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 多模态大模型已在解剖影像分析上表现优异，但其对功能影像任务（如PET）能力尚未被充分研究。作者发现视觉编码器难以独立于解剖信息正确解读功能追踪剂分布，这对实际医学诊断存在安全隐患。

Method: 构建了PET-Bench数据集，涵盖52,308个QA对和9,732个多中心PET检查；系统评估了19个主流MLLM的表现，并分析标准链式思考（CoT）在PET诊断中反而容易导致幻觉式解答。为此，提出了Atomic Visual Alignment（AVA）微调策略，先训练低级视觉感知能力，再进行高级推理。

Result: 实验显示，AVA方法能显著缩小感知缺口，将CoT从“幻觉陷阱”转化为有效推理工具，诊断准确率提升最高可达14.83%。

Conclusion: 当前MLLM在PET等功能影像解读有显著缺陷，标准推理技术可能导致医学安全隐患，所提AVA方法可有效提升其诊断性能，为后续医疗应用提供参考。

Abstract: While Multimodal Large Language Models (MLLMs) have demonstrated remarkable proficiency in tasks such as abnormality detection and report generation for anatomical modalities, their capability in functional imaging remains largely unexplored. In this work, we identify and quantify a fundamental functional perception gap: the inability of current vision encoders to decode functional tracer biodistribution independent of morphological priors. Identifying Positron Emission Tomography (PET) as the quintessential modality to investigate this disconnect, we introduce PET-Bench, the first large-scale functional imaging benchmark comprising 52,308 hierarchical QA pairs from 9,732 multi-site, multi-tracer PET studies. Extensive evaluation of 19 state-of-the-art MLLMs reveals a critical safety hazard termed the Chain-of-Thought (CoT) hallucination trap. We observe that standard CoT prompting, widely considered to enhance reasoning, paradoxically decouples linguistic generation from visual evidence in PET, producing clinically fluent but factually ungrounded diagnoses. To resolve this, we propose Atomic Visual Alignment (AVA), a simple fine-tuning strategy that enforces the mastery of low-level functional perception prior to high-level diagnostic reasoning. Our results demonstrate that AVA effectively bridges the perception gap, transforming CoT from a source of hallucination into a robust inference tool and improving diagnostic accuracy by up to 14.83%. Code and data are available at https://github.com/yezanting/PET-Bench.

</details>


### [23] [D$^3$R-DETR: DETR with Dual-Domain Density Refinement for Tiny Object Detection in Aerial Images](https://arxiv.org/abs/2601.02747)
*Zixiao Wen,Zhen Yang,Xianjie Bao,Lei Zhang,Xiantai Xiang,Wenshuai Li,Yuhan Liu*

Main category: cs.CV

TL;DR: 本文提出了一种新的DETR检测器D$^3$R-DETR，通过空间和频域信息融合，显著提升了遥感图像中微小目标的检测效果。


<details>
  <summary>Details</summary>
Motivation: 微小目标在遥感智能解译中携带关键信息，但因像素有限和目标密度变化大，现有Transformer检测器难以实现快速收敛和准确匹配。

Method: 提出D$^3$R-DETR，引入双域（空间和频率）信息融合机制，改进低层特征图并预测更准确的密度图，以此指导模型更精准地定位微小目标。

Result: 在AI-TOD-v2数据集上，D$^3$R-DETR检测性能超过已有微小目标检测领域的最新方法。

Conclusion: D$^3$R-DETR利用空间与频域联合优化，为遥感微小目标检测带来更高的精度和效果。

Abstract: Detecting tiny objects plays a vital role in remote sensing intelligent interpretation, as these objects often carry critical information for downstream applications. However, due to the extremely limited pixel information and significant variations in object density, mainstream Transformer-based detectors often suffer from slow convergence and inaccurate query-object matching. To address these challenges, we propose D$^3$R-DETR, a novel DETR-based detector with Dual-Domain Density Refinement. By fusing spatial and frequency domain information, our method refines low-level feature maps and utilizes their rich details to predict more accurate object density map, thereby guiding the model to precisely localize tiny objects. Extensive experiments on the AI-TOD-v2 dataset demonstrate that D$^3$R-DETR outperforms existing state-of-the-art detectors for tiny object detection.

</details>


### [24] [Towards Zero-Shot Point Cloud Registration Across Diverse Scales, Scenes, and Sensor Setups](https://arxiv.org/abs/2601.02759)
*Hyungtae Lim,Minkyun Seo,Luca Carlone,Jaesik Park*

Main category: cs.CV

TL;DR: BUFFER-X是一种无需训练即可实现零样本泛化的点云配准框架，通过自动参数估计、无监督关键点采样和尺度归一化，解决了现有方法在不同环境下泛化性差的问题，并显著提升了配准效果。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习点云配准方法存在零样本泛化能力弱、参数依赖强、领域迁移性差的问题，限制了实际应用的广泛性。解决这些痛点能大幅提升点云配准的普适性和泛用性。

Method: 提出BUFFER-X框架，主要包含：(a) 几何自举，实现自动超参数估计；(b) 基于分布的最远点抽样，取代需训练的关键点检测器；(c) Patch级坐标归一化，确保跨数据集的尺度一致性。此外，提出多层次配准策略提升鲁棒性。BUFFER-X-Lite版本通过早退机制和快速姿态估计算法进一步提升效率。

Result: 在涵盖对象级、室内、室外、异构传感器等12个公开点云数据集上，BUFFER-X无需人工调参和领域先验，表现出卓越的零样本泛化能力，同时BUFFER-X-Lite在保持精度的同时将计算时间减少43%。

Conclusion: BUFFER-X及其精简版展现了在不同场景和传感器下的强大通用性和高效性，为点云配准提供了训练自由、鲁棒的新方法，推动了该领域实际应用的发展。

Abstract: Some deep learning-based point cloud registration methods struggle with zero-shot generalization, often requiring dataset-specific hyperparameter tuning or retraining for new environments. We identify three critical limitations: (a) fixed user-defined parameters (e.g., voxel size, search radius) that fail to generalize across varying scales, (b) learned keypoint detectors exhibit poor cross-domain transferability, and (c) absolute coordinates amplify scale mismatches between datasets. To address these three issues, we present BUFFER-X, a training-free registration framework that achieves zero-shot generalization through: (a) geometric bootstrapping for automatic hyperparameter estimation, (b) distribution-aware farthest point sampling to replace learned detectors, and (c) patch-level coordinate normalization to ensure scale consistency. Our approach employs hierarchical multi-scale matching to extract correspondences across local, middle, and global receptive fields, enabling robust registration in diverse environments. For efficiency-critical applications, we introduce BUFFER-X-Lite, which reduces total computation time by 43% (relative to BUFFER-X) through early exit strategies and fast pose solvers while preserving accuracy. We evaluate on a comprehensive benchmark comprising 12 datasets spanning object-scale, indoor, and outdoor scenes, including cross-sensor registration between heterogeneous LiDAR configurations. Results demonstrate that our approach generalizes effectively without manual tuning or prior knowledge of test domains. Code: https://github.com/MIT-SPARK/BUFFER-X.

</details>


### [25] [AnyDepth: Depth Estimation Made Easy](https://arxiv.org/abs/2601.02760)
*Zeyu Ren,Zeyu Zhang,Wukai Li,Qingxiang Liu,Hao Tang*

Main category: cs.CV

TL;DR: 提出了一种轻量级、数据驱动的零样本单目深度估计算法，在提升精度的同时大幅减少参数和所需数据规模。


<details>
  <summary>Details</summary>
Motivation: 当前单目深度估计依赖大数据集和复杂解码器，效率低且泛化能力有限，需要更高效和泛化性更强的方法。

Method: 采用DINOv3视觉编码器获取高质量特征；设计了简单而紧凑的变换器解码器SDT，单路径特征融合及上采样；引入基于数据样本质量的过滤策略，减少有害样本，提高训练质量。

Result: 在五个基准测试中，SDT框架比主流DPT方法有更高的精度，参数量减少约85%-89%，数据集需求显著缩减。

Conclusion: 模型设计和数据质量兼顾，可实现高效且具泛化能力的零样本单目深度估计。

Abstract: Monocular depth estimation aims to recover the depth information of 3D scenes from 2D images. Recent work has made significant progress, but its reliance on large-scale datasets and complex decoders has limited its efficiency and generalization ability. In this paper, we propose a lightweight and data-centric framework for zero-shot monocular depth estimation. We first adopt DINOv3 as the visual encoder to obtain high-quality dense features. Secondly, to address the inherent drawbacks of the complex structure of the DPT, we design the Simple Depth Transformer (SDT), a compact transformer-based decoder. Compared to the DPT, it uses a single-path feature fusion and upsampling process to reduce the computational overhead of cross-scale feature fusion, achieving higher accuracy while reducing the number of parameters by approximately 85%-89%. Furthermore, we propose a quality-based filtering strategy to filter out harmful samples, thereby reducing dataset size while improving overall training quality. Extensive experiments on five benchmarks demonstrate that our framework surpasses the DPT in accuracy. This work highlights the importance of balancing model design and data quality for achieving efficient and generalizable zero-shot depth estimation. Code: https://github.com/AIGeeksGroup/AnyDepth. Website: https://aigeeksgroup.github.io/AnyDepth.

</details>


### [26] [ClearAIR: A Human-Visual-Perception-Inspired All-in-One Image Restoration](https://arxiv.org/abs/2601.02763)
*Xu Zhang,Huan Zhang,Guoli Wang,Qian Zhang,Lefei Zhang*

Main category: cs.CV

TL;DR: 提出了一种新的多任务图像修复框架ClearAIR，结合多模态大模型评估与分层修复策略，有效提升复杂退化图像的修复效果。


<details>
  <summary>Details</summary>
Motivation: 现有多任务图像修复方法过度依赖特定退化方式，导致过度平滑和伪影，难以适应复杂、多样的真实退化场景。

Method: 1. 利用MLLM（多模态大模型）进行图像质量总体评估，实现更准确、跨模态的退化识别。
2. 结合区域感知和任务识别，利用语义关注机制生成粗语义提示，并结合区域上下文引导退化检测和局部处理。
3. 采用内在线索重用机制，通过自监督方式挖掘图像细节，提升细节恢复效果。

Result: 在多种合成与真实数据集上，ClearAIR修复效果超过现有主流方法，表现更为优越。

Conclusion: ClearAIR框架通过多模态质量评估、区域与任务识别及细节自监督，使全能图像修复在复杂场景下效果更好，解决了以往过拟合和伪影问题。

Abstract: All-in-One Image Restoration (AiOIR) has advanced significantly, offering promising solutions for complex real-world degradations. However, most existing approaches rely heavily on degradation-specific representations, often resulting in oversmoothing and artifacts. To address this, we propose ClearAIR, a novel AiOIR framework inspired by Human Visual Perception (HVP) and designed with a hierarchical, coarse-to-fine restoration strategy. First, leveraging the global priority of early HVP, we employ a Multimodal Large Language Model (MLLM)-based Image Quality Assessment (IQA) model for overall evaluation. Unlike conventional IQA, our method integrates cross-modal understanding to more accurately characterize complex, composite degradations. Building upon this overall assessment, we then introduce a region awareness and task recognition pipeline. A semantic cross-attention, leveraging semantic guidance unit, first produces coarse semantic prompts. Guided by this regional context, a degradation-aware module implicitly captures region-specific degradation characteristics, enabling more precise local restoration. Finally, to recover fine details, we propose an internal clue reuse mechanism. It operates in a self-supervised manner to mine and leverage the intrinsic information of the image itself, substantially enhancing detail restoration. Experimental results show that ClearAIR achieves superior performance across diverse synthetic and real-world datasets.

</details>


### [27] [AbductiveMLLM: Boosting Visual Abductive Reasoning Within MLLMs](https://arxiv.org/abs/2601.02771)
*Boyu Chang,Qi Wang,Xi Guo,Zhixiong Nan,Yazhou Yao,Tianfei Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种新范式AbductiveMLLM，通过结合语言与图像推理，显著提升了多模态大模型在视觉猜因任务（VAR）上的能力，实现了新SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型虽然具备较强的通用推理能力，但在需要补全信息、推断最可能解释的视觉猜因（VAR）任务中表现不如人类。作者受到人类“语言-图像双模态”猜因过程启发，希望通过模拟双模态推理行为提升MLLM的VAR表现。

Method: AbductiveMLLM由REASONER和IMAGINER两个协同组件构成。REASONER负责语言域，利用盲LLM生成大量候选解释，并通过跨模态因果校验筛除与视觉不符的假设，再将剩余假设作为“先验”输入MLLM，引导推理；IMAGINER负责图像域，将输入视频和REASONER输出嵌入输入扩散模型，生成与语言解释相匹配的视觉场景，丰富上下文。全系统端到端联合训练。

Result: 在主流VAR基准实验中，AbductiveMLLM表现优于传统方法和先进MLLM，取得SOTA成绩。

Conclusion: 通过模拟人类的语言和图像双模态推理，AbductiveMLLM显著提升MLLM在视觉猜因任务中的推断能力，验证了双模态协同推理的有效性。

Abstract: Visual abductive reasoning (VAR) is a challenging task that requires AI systems to infer the most likely explanation for incomplete visual observations. While recent MLLMs develop strong general-purpose multimodal reasoning capabilities, they fall short in abductive inference, as compared to human beings. To bridge this gap, we draw inspiration from the interplay between verbal and pictorial abduction in human cognition, and propose to strengthen abduction of MLLMs by mimicking such dual-mode behavior. Concretely, we introduce AbductiveMLLM comprising of two synergistic components: REASONER and IMAGINER. The REASONER operates in the verbal domain. It first explores a broad space of possible explanations using a blind LLM and then prunes visually incongruent hypotheses based on cross-modal causal alignment. The remaining hypotheses are introduced into the MLLM as targeted priors, steering its reasoning toward causally coherent explanations. The IMAGINER, on the other hand, further guides MLLMs by emulating human-like pictorial thinking. It conditions a text-to-image diffusion model on both the input video and the REASONER's output embeddings to "imagine" plausible visual scenes that correspond to verbal explanation, thereby enriching MLLMs' contextual grounding. The two components are trained jointly in an end-to-end manner. Experiments on standard VAR benchmarks show that AbductiveMLLM achieves state-of-the-art performance, consistently outperforming traditional solutions and advanced MLLMs.

</details>


### [28] [EarthVL: A Progressive Earth Vision-Language Understanding and Generation Framework](https://arxiv.org/abs/2601.02783)
*Junjue Wang,Yanfei Zhong,Zihang Chen,Zhuo Zheng,Ailong Ma,Liangpei Zhang*

Main category: cs.CV

TL;DR: 本文提出了一个结合地球视觉和语言理解的新框架EarthVLNet，并配套开放了多任务数据集EarthVLSet，用于提升遥感图像中的目标关系推理与场景综合理解。


<details>
  <summary>Details</summary>
Motivation: 当前地球视觉在地理对象识别方面已取得进展，但对对象关系推理的探索不足，限制了对复杂场景的深入理解，特别是在城市规划等应用场景中。

Method: 提出了EarthVLNet框架，分阶段进行：首先利用语义分割获得地物语义掩码，用于指导视觉问答；其次，基于像素级语义引导的大语言模型，进行对象感知的关系推理和知识总结。此外，创新性地引入数值差异损失，用于区分不同对象的特征。在数据集方面，公开了EarthVLSet，包含高分辨率遥感图像、地物掩码和大规模配对文本，支持多选和开放式VQA任务。

Result: 在语义分割、多选VQA及开放式VQA三大基准上，EarthVLNet均取得了领先性能。实验表明：（1）分割特征持续提升VQA效果，且具备跨数据集泛化性；（2）多选任务对视觉编码器更敏感；（3）开放式任务对视觉及语言编码器均有更高要求。

Conclusion: 本研究提出的框架及数据集，可作为连接遥感图像、掩码和文本理解的重要基准，有助于推动地理类地球视觉应用的发展。

Abstract: Earth vision has achieved milestones in geospatial object recognition but lacks exploration in object-relational reasoning, limiting comprehensive scene understanding. To address this, a progressive Earth vision-language understanding and generation framework is proposed, including a multi-task dataset (EarthVLSet) and a semantic-guided network (EarthVLNet). Focusing on city planning applications, EarthVLSet includes 10.9k sub-meter resolution remote sensing images, land-cover masks, and 761.5k textual pairs involving both multiple-choice and open-ended visual question answering (VQA) tasks. In an object-centric way, EarthVLNet is proposed to progressively achieve semantic segmentation, relational reasoning, and comprehensive understanding. The first stage involves land-cover segmentation to generate object semantics for VQA guidance. Guided by pixel-wise semantics, the object awareness based large language model (LLM) performs relational reasoning and knowledge summarization to generate the required answers. As for optimization, the numerical difference loss is proposed to dynamically add difference penalties, addressing the various objects' statistics. Three benchmarks, including semantic segmentation, multiple-choice, and open-ended VQA demonstrated the superiorities of EarthVLNet, yielding three future directions: 1) segmentation features consistently enhance VQA performance even in cross-dataset scenarios; 2) multiple-choice tasks show greater sensitivity to the vision encoder than to the language decoder; and 3) open-ended tasks necessitate advanced vision encoders and language decoders for an optimal performance. We believe this dataset and method will provide a beneficial benchmark that connects ''image-mask-text'', advancing geographical applications for Earth vision.

</details>


### [29] [DreamStyle: A Unified Framework for Video Stylization](https://arxiv.org/abs/2601.02785)
*Mengtian Li,Jinshu Chen,Songtao Zhao,Wanquan Feng,Pengqi Tu,Qian He*

Main category: cs.CV

TL;DR: 本文提出了一个名为DreamStyle的视频风格化统一框架，支持三种条件下的视频风格迁移，并在高质量数据和新策略的支持下取得了风格一致性和视觉质量的提升。


<details>
  <summary>Details</summary>
Motivation: 现有视频风格生成方法多只适用于一种风格条件（如文本、风格图像或首帧），导致应用范围受限。与此同时，受限于数据质量，当前方法在风格一致性和时序稳定性方面表现较差。因此解决多条件支持与高质量数据获取是研究的关键动机。

Method: 作者提出DreamStyle，一种统一的视频风格化框架，可同时支持文本、风格图像和首帧风格指导。系统基于基础的图像到视频（I2V）模型，通过带有条件token特定参数的LoRA（低秩适应）方法进行训练。此外，作者还设计了高质量数据整理流程，获得了优质的视频对数据集。

Result: 实验证明，无论是质性还是量化评价，DreamStyle在三类风格化任务中均表现良好，明显优于现有方法，特别是在风格一致性和视觉效果上有明显提升。

Conclusion: DreamStyle有效突破了现有视频风格化方法只能应用于单一条件的局限，实现了多条件多任务统一支持，并利用高质量数据和创新训练策略，显著提升了风格一致性和视频的整体品质。

Abstract: Video stylization, an important downstream task of video generation models, has not yet been thoroughly explored. Its input style conditions typically include text, style image, and stylized first frame. Each condition has a characteristic advantage: text is more flexible, style image provides a more accurate visual anchor, and stylized first frame makes long-video stylization feasible. However, existing methods are largely confined to a single type of style condition, which limits their scope of application. Additionally, their lack of high-quality datasets leads to style inconsistency and temporal flicker. To address these limitations, we introduce DreamStyle, a unified framework for video stylization, supporting (1) text-guided, (2) style-image-guided, and (3) first-frame-guided video stylization, accompanied by a well-designed data curation pipeline to acquire high-quality paired video data. DreamStyle is built on a vanilla Image-to-Video (I2V) model and trained using a Low-Rank Adaptation (LoRA) with token-specific up matrices that reduces the confusion among different condition tokens. Both qualitative and quantitative evaluations demonstrate that DreamStyle is competent in all three video stylization tasks, and outperforms the competitors in style consistency and video quality.

</details>


### [30] [Textile IR: A Bidirectional Intermediate Representation for Physics-Aware Fashion CAD](https://arxiv.org/abs/2601.02792)
*Petteri Teikari,Neliana Fuenmayor*

Main category: cs.CV

TL;DR: 本文提出了Textile IR，一个面向时尚设计的双向中间表示，用于集成CAD制版、物理仿真和生命周期评估，实现设计流程联通、智能反馈和不确定性追踪。


<details>
  <summary>Details</summary>
Motivation: 目前服装设计工具各自孤立：制版软件注重可缝制性，却不了解布料悬垂物理属性；物理仿真能预测行为但无法自动改良纸样，且各环节缺乏统一对接。为了解决制造、仿真、可持续性分析的整合与信息孤岛问题，提出Textile IR。

Method: Textile IR建立七层验证阶梯，从基础语法检测到高成本物理验证，实现多环节联通。采用场景图表达方式，将服装设计抽象为结构化程序。通过双向反馈通道，仿真失败时可反馈设计修改，材料替换会动态影响可持续性估算。不确定性在流程中显示并传播。

Result: 以三域约束满足形式化时尚工程，解决材料测试误差、仿真近似与LCA数据库缺陷造成的不确定性复合问题。展示AI如何借助Textile IR直接操控服装结构而非像素。提出六大后续研究方向，以及面向中小企业的落地建议。

Conclusion: Textile IR为服装设计工程带来统一、可感知与可操作的约束表达，显著提升设计、制造与可持续性协同水平，帮助设计师在流程早期平衡美观、制造与环保要求，减少返工和资源浪费。

Abstract: We introduce Textile IR, a bidirectional intermediate representation that connects manufacturing-valid CAD, physics-based simulation, and lifecycle assessment for fashion design. Unlike existing siloed tools where pattern software guarantees sewable outputs but understands nothing about drape, and physics simulation predicts behaviour but cannot automatically fix patterns, Textile IR provides the semantic glue for integration through a seven-layer Verification Ladder -- from cheap syntactic checks (pattern closure, seam compatibility) to expensive physics validation (drape simulation, stress analysis). The architecture enables bidirectional feedback: simulation failures suggest pattern modifications; material substitutions update sustainability estimates in real time; uncertainty propagates across the pipeline with explicit confidence bounds. We formalise fashion engineering as constraint satisfaction over three domains and demonstrate how Textile IR's scene-graph representation enables AI systems to manipulate garments as structured programs rather than pixel arrays. The framework addresses the compound uncertainty problem: when measurement errors in material testing, simulation approximations, and LCA database gaps combine, sustainability claims become unreliable without explicit uncertainty tracking. We propose six research priorities and discuss deployment considerations for fashion SMEs where integrated workflows reduce specialised engineering requirements. Key contribution: a formal representation that makes engineering constraints perceptible, manipulable, and immediately consequential -- enabling designers to navigate sustainability, manufacturability, and aesthetic tradeoffs simultaneously rather than discovering conflicts after costly physical prototyping.

</details>


### [31] [StableDPT: Temporal Stable Monocular Video Depth Estimation](https://arxiv.org/abs/2601.02793)
*Ivan Sobko,Hayko Riemenschneider,Markus Gross,Christopher Schroers*

Main category: cs.CV

TL;DR: 本文提出了一种将单帧深度估计模型适用于视频序列的新方法，并通过引入高效的时序模块显著提升了预测的时序一致性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的单帧图像深度估计模型在应用于视频时常常导致结果在不同帧之间不稳定、出现闪烁等时序伪影，而暂时还缺乏既高效又易于训练的适配方法。

Method: 作者在主流Vision Transformer编码器和Dense Prediction Transformer (DPT)的基础上，创新性地设计了一个高效的时序组件，该组件通过时序cross-attention机制充分融合多个关键帧的信息，实现多帧间的全局上下文建模。在推理阶段，提出了一种新的视频分块处理策略，从而避免了重叠窗口方法中的尺度错位与冗余计算。

Result: 在多个主流基准数据集上，所提出方法在深度预测的时间一致性方面表现优异，同时保持与当前最优方法相当甚至更好的准确率，并且推理速度提升达2倍。

Conclusion: 该方法无需大规模计算资源即可训练，显著提升了视频深度估计的时序稳定性和效率，为图像深度估计模型向视频领域拓展提供了新的解决方案。

Abstract: Applying single image Monocular Depth Estimation (MDE) models to video sequences introduces significant temporal instability and flickering artifacts. We propose a novel approach that adapts any state-of-the-art image-based (depth) estimation model for video processing by integrating a new temporal module - trainable on a single GPU in a few days. Our architecture StableDPT builds upon an off-the-shelf Vision Transformer (ViT) encoder and enhances the Dense Prediction Transformer (DPT) head. The core of our contribution lies in the temporal layers within the head, which use an efficient cross-attention mechanism to integrate information from keyframes sampled across the entire video sequence. This allows the model to capture global context and inter-frame relationships leading to more accurate and temporally stable depth predictions. Furthermore, we propose a novel inference strategy for processing videos of arbitrary length avoiding the scale misalignment and redundant computations associated with overlapping windows used in other methods. Evaluations on multiple benchmark datasets demonstrate improved temporal consistency, competitive state-of-the-art performance and on top 2x faster processing in real-world scenarios.

</details>


### [32] [Topology-aware Pathological Consistency Matching for Weakly-Paired IHC Virtual Staining](https://arxiv.org/abs/2601.02806)
*Mingzhou Jiang,Jiaying Zhou,Nan Zeng,Mickael Li,Qijie Tang,Chao He,Huazhu Fu,Honghui He*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的基于拓扑感知的虚拟染色方法，将H&E图像高效转换为IHC图像，有效提升了虚拟染色的结构一致性和病理一致性，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: IHC染色对于癌症组织样本的分子表征和临床诊断非常重要，但相比于常规H&E染色，IHC染色流程复杂、耗时且昂贵，阻碍了其广泛应用。现有将H&E图片虚拟转化为IHC的方法受限于配对数据空间错位和局部形变，影响了监督学习的有效性。

Method: 作者提出了一个拓扑感知的虚拟染色框架，包含两大机制：1）拓扑感知一致性匹配（TACM），结合图对比学习与拓扑扰动，提升空间错位情况下的结构一致性；2）拓扑约束病理匹配（TCPM），基于节点重要性对病理阳性区域进行匹配，增强病理一致性。

Result: 在两个基准数据集、共四个染色任务上，作者提出的方法在生成质量和临床相关性上均优于当前最先进方法。

Conclusion: 拓扑感知机制有效解决了虚拟染色中的空间错位和局部形变问题，为H&E到IHC虚拟染色提供了更准确和有应用价值的方案。

Abstract: Immunohistochemical (IHC) staining provides crucial molecular characterization of tissue samples and plays an indispensable role in the clinical examination and diagnosis of cancers. However, compared with the commonly used Hematoxylin and Eosin (H&E) staining, IHC staining involves complex procedures and is both time-consuming and expensive, which limits its widespread clinical use. Virtual staining converts H&E images to IHC images, offering a cost-effective alternative to clinical IHC staining. Nevertheless, using adjacent slides as ground truth often results in weakly-paired data with spatial misalignment and local deformations, hindering effective supervised learning. To address these challenges, we propose a novel topology-aware framework for H&E-to-IHC virtual staining. Specifically, we introduce a Topology-aware Consistency Matching (TACM) mechanism that employs graph contrastive learning and topological perturbations to learn robust matching patterns despite spatial misalignments, ensuring structural consistency. Furthermore, we propose a Topology-constrained Pathological Matching (TCPM) mechanism that aligns pathological positive regions based on node importance to enhance pathological consistency. Extensive experiments on two benchmarks across four staining tasks demonstrate that our method outperforms state-of-the-art approaches, achieving superior generation quality with higher clinical relevance.

</details>


### [33] [SketchThinker-R1: Towards Efficient Sketch-Style Reasoning in Large Multimodal Models](https://arxiv.org/abs/2601.02825)
*Ruiyang Zhang,Dongzhan Zhou,Zhedong Zheng*

Main category: cs.CV

TL;DR: 提出了SketchThinker-R1方法，使多模态大模型具备高效的'草图式'推理能力，显著减少推理所需算力和响应时长，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大模型进行长流程推理，虽然效果好，但会造成推理代价高、反应慢，影响模型实际应用的效率。相比之下，人类常用信息高度聚焦、目标明确的'草图式'推理。作者试图让大模型也具备这种高效推理方式。

Method: 方法分三步：首先，利用草图推理模式微调基础模型，让其初步具备草图式推理能力；其次，训练SketchJudge奖励模型，专门判断推理过程是否草图化并给高分；最后，通过强化学习让主模型在SketchJudge监督下进一步泛化草图式推理能力。

Result: 在四个基准测试上，SketchThinker-R1推理所需token数降低超过64%，但答案准确率没有下降。定性分析也显示模型能更关注关键信息。

Conclusion: 这种通过草图式推理训练大模型的方法，能大幅提升推理效率且不损失准确性，有助于实际部署落地。

Abstract: Despite the empirical success of extensive, step-by-step reasoning in large multimodal models, long reasoning processes inevitably incur substantial computational overhead, i.e., in terms of higher token costs and increased response time, which undermines inference efficiency. In contrast, humans often employ sketch-style reasoning: a concise, goal-directed cognitive process that prioritizes salient information and enables efficient problem-solving. Inspired by this cognitive efficiency, we propose SketchThinker-R1, which incentivizes sketch-style reasoning ability in large multimodal models. Our method consists of three primary stages. In the Sketch-Mode Cold Start stage, we convert standard long reasoning process into sketch-style reasoning and finetune base multimodal model, instilling initial sketch-style reasoning capability. Next, we train SketchJudge Reward Model, which explicitly evaluates thinking process of model and assigns higher scores to sketch-style reasoning. Finally, we conduct Sketch-Thinking Reinforcement Learning under supervision of SketchJudge to further generalize sketch-style reasoning ability. Experimental evaluation on four benchmarks reveals that our SketchThinker-R1 achieves over 64% reduction in reasoning token cost without compromising final answer accuracy. Qualitative analysis further shows that sketch-style reasoning focuses more on key cues during problem solving.

</details>


### [34] [DGA-Net: Enhancing SAM with Depth Prompting and Graph-Anchor Guidance for Camouflaged Object Detection](https://arxiv.org/abs/2601.02831)
*Yuetong Li,Qing Zhang,Yilin Zhao,Gongyang Li,Zeming Liu*

Main category: cs.CV

TL;DR: 本论文提出了DGA-Net，一种结合深度信息改进伪装物体检测（COD）的新框架，通过全新的“深度提示”范式，改造了Segment Anything Model（SAM）。


<details>
  <summary>Details</summary>
Motivation: 目前伪装物体检测领域普遍主要依赖稀疏提示（如点、框），难以充分挖掘与利用深度信息，这限制了检测性能。

Method: 提出了DGA-Net，引入密集深度提示，并设计了跨模态图增强（CGE）模块，将RGB和深度信息结合形成统一引导信号。同时设计锚点引导细化（AGR）模块，建立全局锚点并通过非局部路径，从深层到浅层传递高质量指导，提升分割精度。

Result: 定量和定性实验结果表明，DGA-Net方案优于现有最先进的伪装物体检测方法。

Conclusion: 通过改进提示机制、融合多模态信息并优化特征传递，DGA-Net显著提升了伪装物体检测性能，展示了深度提示与创新信息传递策略的重要性。

Abstract: To fully exploit depth cues in Camouflaged Object Detection (COD), we present DGA-Net, a specialized framework that adapts the Segment Anything Model (SAM) via a novel ``depth prompting" paradigm. Distinguished from existing approaches that primarily rely on sparse prompts (e.g., points or boxes), our method introduces a holistic mechanism for constructing and propagating dense depth prompts. Specifically, we propose a Cross-modal Graph Enhancement (CGE) module that synthesizes RGB semantics and depth geometric within a heterogeneous graph to form a unified guidance signal. Furthermore, we design an Anchor-Guided Refinement (AGR) module. To counteract the inherent information decay in feature hierarchies, AGR forges a global anchor and establishes direct non-local pathways to broadcast this guidance from deep to shallow layers, ensuring precise and consistent segmentation. Quantitative and qualitative experimental results demonstrate that our proposed DGA-Net outperforms the state-of-the-art COD methods.

</details>


### [35] [Breaking Self-Attention Failure: Rethinking Query Initialization for Infrared Small Target Detection](https://arxiv.org/abs/2601.02837)
*Yuteng Liu,Duanni Meng,Maoxun Yuan,Xingxing Wei*

Main category: cs.CV

TL;DR: 本文提出了SEF-DETR框架，通过改善查询初始化，提高红外小目标检测效果。该方法融合了频率引导、动态增强和一致性融合，有效抑制背景干扰，提升小目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于DETR的红外小目标检测方法存在性能下降，主要由于自注意力机制导致目标特征被背景特征淹没，造成检测不准确。

Method: SEF-DETR包括三大模块：（1）Frequency-guided Patch Screening (FPS)：通过傅里叶谱分析抑制背景特征，突出目标相关区域；（2）Dynamic Embedding Enhancement (DEE)：多尺度动态增强目标感知特征；（3）Reliability-Consistency-aware Fusion (RCF)：通过空间与频率一致性提升目标查询的可靠性。

Result: 在三个主流红外小目标检测公开数据集上，SEF-DETR明显优于现有检测方法，展示了更高的检测精度和鲁棒性。

Conclusion: SEF-DETR为红外小目标检测提供了高效、鲁棒的新方案，有效缓解了目标特征易被背景淹没的问题，为实际应用提供了有价值的参考。

Abstract: Infrared small target detection (IRSTD) faces significant challenges due to the low signal-to-noise ratio (SNR), small target size, and complex cluttered backgrounds. Although recent DETR-based detectors benefit from global context modeling, they exhibit notable performance degradation on IRSTD. We revisit this phenomenon and reveal that the target-relevant embeddings of IRST are inevitably overwhelmed by dominant background features due to the self-attention mechanism, leading to unreliable query initialization and inaccurate target localization. To address this issue, we propose SEF-DETR, a novel framework that refines query initialization for IRSTD. Specifically, SEF-DETR consists of three components: Frequency-guided Patch Screening (FPS), Dynamic Embedding Enhancement (DEE), and Reliability-Consistency-aware Fusion (RCF). The FPS module leverages the Fourier spectrum of local patches to construct a target-relevant density map, suppressing background-dominated features. DEE strengthens multi-scale representations in a target-aware manner, while RCF further refines object queries by enforcing spatial-frequency consistency and reliability. Extensive experiments on three public IRSTD datasets demonstrate that SEF-DETR achieves superior detection performance compared to state-of-the-art methods, delivering a robust and efficient solution for infrared small target detection task.

</details>


### [36] [Towards Agnostic and Holistic Universal Image Segmentation with Bit Diffusion](https://arxiv.org/abs/2601.02881)
*Jakob Lønborg Christensen,Morten Rieger Hannemose,Anders Bjorholm Dahl,Vedrana Andersen Dahl*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的通用图像分割方法，无需依赖常规掩码体系，直接预测整体分割。通过多项创新改进，虽然当前性能略低于主流掩码方法，但展示了一些独特优势和改进潜力。


<details>
  <summary>Details</summary>
Motivation: 传统图像分割方法多依赖掩码框架，对类别敏感，难以实现无类别假设下的图像分割。因此，作者希望设计一种“通用”图像分割框架，实现对任意分割需求的泛化支持。

Method: 采用扩散模型整体生成分割结果，对模型进行了创新的适应性调整，包括引入位置感知调色板（2D格雷码编排）、输出激活函数（tanh），以及针对离散数据选择最佳损失函数（sigmoid损失加权）和x预测方式。

Result: 模型在各项实验中表现接近主流掩码分割方法，部分场景下性能略逊于前沿模型，但确实缩小了性能差距。

Conclusion: 扩散模型具备独特能力（如原理化的不确定性建模），补齐了传统方法难以实现的特性。进一步配合大规模预训练或提示调节，有望达到或超过当前最佳性能。

Abstract: This paper introduces a diffusion-based framework for universal image segmentation, making agnostic segmentation possible without depending on mask-based frameworks and instead predicting the full segmentation in a holistic manner. We present several key adaptations to diffusion models, which are important in this discrete setting. Notably, we show that a location-aware palette with our 2D gray code ordering improves performance. Adding a final tanh activation function is crucial for discrete data. On optimizing diffusion parameters, the sigmoid loss weighting consistently outperforms alternatives, regardless of the prediction type used, and we settle on x-prediction. While our current model does not yet surpass leading mask-based architectures, it narrows the performance gap and introduces unique capabilities, such as principled ambiguity modeling, that these models lack. All models were trained from scratch, and we believe that combining our proposed improvements with large-scale pretraining or promptable conditioning could lead to competitive models.

</details>


### [37] [TA-Prompting: Enhancing Video Large Language Models for Dense Video Captioning via Temporal Anchors](https://arxiv.org/abs/2601.02908)
*Wei-Yuan Cheng,Kai-Po Chang,Chi-Pin Huang,Fu-En Yang,Yu-Chiang Frank Wang*

Main category: cs.CV

TL;DR: 本文提出了TA-Prompting方法，通过引入Temporal Anchors和事件一致性采样，大幅提升了基于大语言模型（VideoLLMs）的密集视频描述（Dense Video Captioning）任务的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的视频描述方法虽然可以生成丰富的描述，但在未剪辑视频中准确定位事件边界存在困难，这导致生成的描述无法很好地与实际事件对齐，影响了描述的准确性和有效性。

Method: 提出TA-Prompting方法，引入Temporal Anchors模块来学习精确定位视频中的事件边界，并作为提示（Prompt），引导VideoLLMs实现对事件的时序感知理解。在推理阶段，提出事件一致性采样策略，对视频中任意数量事件的描述进行选择，确保不同事件描述之间的时序连贯性和与视频内容的跨模态相似性。

Result: 在多个视频描述 benchmark 数据集上进行大量实验，结果显示TA-Prompting方法显著优于现有VideoLLMs，在密集视频描述、时序理解、事件检索等任务上都取得了更好的表现。

Conclusion: TA-Prompting能够有效提升大语言模型在未剪辑视频上的事件定位和描述能力，提升描述与事件的对应关系，在视频理解相关任务上具有较大应用前景。

Abstract: Dense video captioning aims to interpret and describe all temporally localized events throughout an input video. Recent state-of-the-art methods leverage large language models (LLMs) to provide detailed moment descriptions for video data. However, existing VideoLLMs remain challenging in identifying precise event boundaries in untrimmed videos, causing the generated captions to be not properly grounded. In this paper, we propose TA-Prompting, which enhances VideoLLMs via Temporal Anchors that learn to precisely localize events and prompt the VideoLLMs to perform temporal-aware video event understanding. During inference, in order to properly determine the output caption sequence from an arbitrary number of events presented within a video, we introduce an event coherent sampling strategy to select event captions with sufficient coherence across temporal events and cross-modal similarity with the given video. Through extensive experiments on benchmark datasets, we show that our TA-Prompting is favorable against state-of-the-art VideoLLMs, yielding superior performance on dense video captioning and temporal understanding tasks including moment retrieval and temporalQA.

</details>


### [38] [Zoom-IQA: Image Quality Assessment with Reliable Region-Aware Reasoning](https://arxiv.org/abs/2601.02918)
*Guoqiang Liang,Jianyi Wang,Zhonghua Wu,Shangchen Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种名为Zoom-IQA的视觉语言模型（VLM）用于图像质量评价（IQA），能够结合区域推理、迭代优化和不确定性感知，提升了评价的准确性和解释性。


<details>
  <summary>Details</summary>
Motivation: 现有图像质量评价方法要么只能给出数值分数、缺乏解释性，要么只能提供低层次描述，且基于视觉语言模型的IQA在推理能力上有所欠缺，难以充分融合视觉和文本信息。

Method: 提出Zoom-IQA模型，通过两阶段训练：首先在新构建的GR-IQA数据集上进行有监督微调，使模型学会关注关键区域并给出解释；接着引入强化学习，并应用KL-Coverage正则化和渐进重采样策略，提升模型推理和分数的多样性与鲁棒性，减少标注偏差。

Result: Zoom-IQA在多项实验中表现出更好的鲁棒性、解释性和泛化能力。此外，在下游任务（如图像修复）中的应用也显示了其有效性。

Conclusion: Zoom-IQA通过引入区域推理、不确定性感知和迭代优化机制，显著提升了图像质量评价的综合性能，并能为后续视觉任务提供有价值的质量判断。

Abstract: Image Quality Assessment (IQA) is a long-standing problem in computer vision. Previous methods typically focus on predicting numerical scores without explanation or provide low-level descriptions lacking precise scores. Recent reasoning-based vision language models (VLMs) have shown strong potential for IQA, enabling joint generation of quality descriptions and scores. However, we notice that existing VLM-based IQA methods tend to exhibit unreliable reasoning due to their limited capability of integrating visual and textual cues. In this work, we introduce Zoom-IQA, a VLM-based IQA model to explicitly emulate key cognitive behaviors: uncertainty awareness, region reasoning, and iterative refinement. Specifically, we present a two-stage training pipeline: 1) supervised fine-tuning (SFT) on our Grounded-Rationale-IQA (GR-IQA) dataset to teach the model to ground its assessments in key regions; and 2) reinforcement learning (RL) for dynamic policy exploration, primarily stabilized by our KL-Coverage regularizer to prevent reasoning and scoring diversity collapse, and supported by a Progressive Re-sampling Strategy to mitigate annotation bias. Extensive experiments show that Zoom-IQA achieves improved robustness, explainability, and generalization. The application to downstream tasks, such as image restoration, further demonstrates the effectiveness of Zoom-IQA.

</details>


### [39] [DCG ReID: Disentangling Collaboration and Guidance Fusion Representations for Multi-modal Vehicle Re-Identification](https://arxiv.org/abs/2601.02924)
*Aihua Zheng,Ya Gao,Shihao Li,Chenglong Li,Jin Tang*

Main category: cs.CV

TL;DR: 本文提出了一种新方法DCG-ReID，针对多模态（RGB、近红外、热红外）车辆重识别任务，能根据模态质量分布的不同动态选择融合策略，有效提升识别性能。


<details>
  <summary>Details</summary>
Motivation: 多模态车辆重识别存在不同模态间数据质量分布的不确定性，会影响融合效果。现有方法未区分质量分布不同情形的需求，导致类内一致性和模态间差异冲突难以解决。

Method: 提出动态置信度加权机制（DCDW），根据各模态的置信度动态分配权重，实现模态间无干扰的信息解耦。在此基础上，针对平衡和不平衡两种模态质量分布，分别设计协同融合模块（CFM）和引导融合模块（GFM），挖掘共性或强化主导模态。

Result: 在WMVeID863、MSVR310和RGBNT100三个多模态车辆ReID基准上进行了大量实验，验证了所提方法的有效性。

Conclusion: 针对多模态数据中质量分布差异难以平衡的问题，提出的DCG-ReID可结合动态加权和场景特定策略，提升了车辆重识别的准确性，具有较好应用前景。

Abstract: Multi-modal vehicle Re-Identification (ReID) aims to leverage complementary information from RGB, Near Infrared (NIR), and Thermal Infrared (TIR) modalities to retrieve the same vehicle. The challenges of multi-modal vehicle ReID arise from the uncertainty of modality quality distribution induced by inherent discrepancies across modalities, resulting in distinct conflicting fusion requirements for data with balanced and unbalanced quality distributions. Existing methods handle all multi-modal data within a single fusion model, overlooking the different needs of the two data types and making it difficult to decouple the conflict between intra-class consistency and inter-modal heterogeneity. To this end, we propose Disentangle Collaboration and Guidance Fusion Representations for Multi-modal Vehicle ReID (DCG-ReID). Specifically, to disentangle heterogeneous quality-distributed modal data without mutual interference, we first design the Dynamic Confidence-based Disentangling Weighting (DCDW) mechanism: dynamically reweighting three-modal contributions via interaction-derived modal confidence to build a disentangled fusion framework. Building on DCDW, we develop two scenario-specific fusion strategies: (1) for balanced quality distributions, Collaboration Fusion Module (CFM) mines pairwise consensus features to capture shared discriminative information and boost intra-class consistency; (2) for unbalanced distributions, Guidance Fusion Module (GFM) implements differential amplification of modal discriminative disparities to reinforce dominant modality advantages, guide auxiliary modalities to mine complementary discriminative info, and mitigate inter-modal divergence to boost multi-modal joint decision performance. Extensive experiments on three multi-modal ReID benchmarks (WMVeID863, MSVR310, RGBNT100) validate the effectiveness of our method. Code will be released upon acceptance.

</details>


### [40] [PrismVAU: Prompt-Refined Inference System for Multimodal Video Anomaly Understanding](https://arxiv.org/abs/2601.02927)
*Iñaki Erregue,Kamal Nasrollahi,Sergio Escalera*

Main category: cs.CV

TL;DR: 本文提出了PrismVAU，一种轻量级、实用的实时视频异常理解系统，能够在无需复杂标注和训练、无须外部模块的条件下，实现异常检测与可解释分析。


<details>
  <summary>Details</summary>
Motivation: 现有的视频异常理解方法大多依赖于深度定制的多模态大语言模型或视频字幕生成器等外部模块，这导致高昂的标注成本、复杂的训练流程及推理资源消耗，因此迫切需要一种高效、低成本且易于实际部署的VAU新方法。

Method: PrismVAU采用两阶段策略：首先通过与文本锚点的相似性评估得到粗粒度的帧级异常分数；随后，采用多模态大语言模型和系统/用户提示语对异常进行上下文细化解释。所有文本锚点和提示语均通过弱监督的自动提示工程（APE）框架进行优化。

Result: 在标准视频异常检测数据集上的实验表明，PrismVAU不仅保证了检测性能，还能生成具有可解释性的异常分析。系统无需指令微调、帧级标注或外部密集处理模块，证明了其实用性和高效性。

Conclusion: PrismVAU为实际环境下的视频异常理解提供了一种高效、低算力开销且可解释的解决方案，突破了以往方法在成本与实用性上的瓶颈。

Abstract: Video Anomaly Understanding (VAU) extends traditional Video Anomaly Detection (VAD) by not only localizing anomalies but also describing and reasoning about their context. Existing VAU approaches often rely on fine-tuned multimodal large language models (MLLMs) or external modules such as video captioners, which introduce costly annotations, complex training pipelines, and high inference overhead. In this work, we introduce PrismVAU, a lightweight yet effective system for real-time VAU that leverages a single off-the-shelf MLLM for anomaly scoring, explanation, and prompt optimization. PrismVAU operates in two complementary stages: (1) a coarse anomaly scoring module that computes frame-level anomaly scores via similarity to textual anchors, and (2) an MLLM-based refinement module that contextualizes anomalies through system and user prompts. Both textual anchors and prompts are optimized with a weakly supervised Automatic Prompt Engineering (APE) framework. Extensive experiments on standard VAD benchmarks demonstrate that PrismVAU delivers competitive detection performance and interpretable anomaly explanations -- without relying on instruction tuning, frame-level annotations, and external modules or dense processing -- making it an efficient and practical solution for real-world applications.

</details>


### [41] [HybridSolarNet: A Lightweight and Explainable EfficientNet-CBAM Architecture for Real-Time Solar Panel Fault Detection](https://arxiv.org/abs/2601.02928)
*Md. Asif Hossain,G M Mota-Tahrin Tayef,Nabil Subhan*

Main category: cs.CV

TL;DR: 本文提出了一种新型太阳能板故障检测模型HybridSolarNet，兼顾高精度和轻量化，适用于无人机实时监控。该模型通过数据集实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统光伏板人工检测效率低、成本高且易出错，亟需高效、准确且轻量级的自动化检测方法，特别适用于边缘设备（如无人机）实时应用。

Method: 作者提出HybridSolarNet，将EfficientNet-B0与CBAM注意力模块结合，对Kaggle太阳能板图像数据集进行训练，并采用分层交叉验证和严谨的数据增强前划分；引入Focal Loss应对类别不均衡，采用Cosine Annealing优化训练过程。

Result: 模型在5折交叉验证中最高平均准确率为92.37%±0.41，F1分数为0.9226±0.39，存储需求仅为16.3MB，比对比模型VGG19轻32倍，GPU下推理速度为54.9FPS，验证了CBAM和Focal loss的性能提升作用。

Conclusion: HybridSolarNet兼具高精度、轻量化和快速推理速度，非常适合作为无人机实时监控系统的太阳能板故障检测模型，具有良好的实际应用前景。

Abstract: Manual inspections for solar panel systems are a tedious, costly, and error-prone task, making it desirable for Unmanned Aerial Vehicle (UAV) based monitoring. Though deep learning models have excellent fault detection capabilities, almost all methods either are too large and heavy for edge computing devices or involve biased estimation of accuracy due to ineffective learning techniques. We propose a new solar panel fault detection model called HybridSolarNet. It integrates EfficientNet-B0 with Convolutional Block Attention Module (CBAM). We implemented it on the Kaggle Solar Panel Images competition dataset with a tight split-before-augmentation protocol. It avoids leakage in accuracy estimation. We introduced focal loss and cosine annealing. Ablation analysis validates that accuracy boosts due to added benefits from CBAM (+1.53%) and that there are benefits from recognition of classes with imbalanced samples via focal loss. Overall average accuracy on 5-fold stratified cross-validation experiments on the given competition dataset topped 92.37% +/- 0.41 and an F1-score of 0.9226 +/- 0.39 compared to baselines like VGG19, requiring merely 16.3 MB storage, i.e., 32 times less. Its inference speed measured at 54.9 FPS with GPU support makes it a successful candidate for real-time UAV implementation. Moreover, visualization obtained from Grad-CAM illustrates that HybridSolarNet focuses on actual locations instead of irrelevant ones.

</details>


### [42] [VTONQA: A Multi-Dimensional Quality Assessment Dataset for Virtual Try-on](https://arxiv.org/abs/2601.02945)
*Xinyi Wei,Sijing Wu,Zitong Xu,Yunhao Li,Huiyu Duan,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 该论文提出了VTONQA，这是首个专为虚拟试衣（VTON）图像质量评估设计的多维度数据集，并对现有VTON模型和评估方法进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 由于电商和数字时尚的快速发展，基于图像的虚拟试衣变得热门。但现有模型生成的图像存在明显问题（如服装变形、身体不一致），而缺乏专门的高质量评估标准限制了相关技术进步。因此，需要一个专业的数据集来提升评测可靠性。

Method: 作者构建了VTONQA数据集，包含来自11个VTON模型的8132张生成图像，针对服装贴合度、身体兼容性和整体质量三个维度共获得24396个主观评分（MOS）。此外，作者利用VTONQA对现有VTON模型与图像质量评估方法进行了基准测试与对比分析。

Result: 基于VTONQA，现有VTON模型在衣服贴合度、身体兼容性和整体质量上均存在不足，通用的图像质量评估方法在VTON场景下表现有限，从而突显了VTONQA数据集的价值。

Conclusion: VTONQA作为首个专为虚拟试衣设计的质量评估数据集，为推动感知一致性评估与高质量VTON模型的发展奠定了坚实基础。

Abstract: With the rapid development of e-commerce and digital fashion, image-based virtual try-on (VTON) has attracted increasing attention. However, existing VTON models often suffer from artifacts such as garment distortion and body inconsistency, highlighting the need for reliable quality evaluation of VTON-generated images. To this end, we construct VTONQA, the first multi-dimensional quality assessment dataset specifically designed for VTON, which contains 8,132 images generated by 11 representative VTON models, along with 24,396 mean opinion scores (MOSs) across three evaluation dimensions (i.e., clothing fit, body compatibility, and overall quality). Based on VTONQA, we benchmark both VTON models and a diverse set of image quality assessment (IQA) metrics, revealing the limitations of existing methods and highlighting the value of the proposed dataset. We believe that the VTONQA dataset and corresponding benchmarks will provide a solid foundation for perceptually aligned evaluation, benefiting both the development of quality assessment methods and the advancement of VTON models.

</details>


### [43] [LAMS-Edit: Latent and Attention Mixing with Schedulers for Improved Content Preservation in Diffusion-Based Image and Style Editing](https://arxiv.org/abs/2601.02987)
*Wingwa Fu,Takayuki Okatani*

Main category: cs.CV

TL;DR: 该论文提出了LAMS-Edit，一种基于扩散模型的文本到图像编辑方法，在保持图像内容的前提下，实现精确的图像编辑，尤其适用于真实图像。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像编辑方法在内容保持与编辑应用之间难以平衡，且在处理真实图像编辑时面临困难。作者希望解决这一难题。

Method: 提出LAMS-Edit方法，在生成和编辑图像过程中，利用逆变换过程中的中间状态，将潜变量和注意力图通过加权插值整合，每一步由调度器控制。该方法集成了Prompt-to-Prompt（P2P），可通过区域掩膜支持精确编辑，并通过LoRA实现风格迁移。

Result: 大量实验表明，LAMS-Edit能有效平衡内容保持和编辑应用，支持更细致和真实的图像编辑。

Conclusion: LAMS-Edit为文本到图像编辑提供了一种灵活且有效的框架，尤其适合需要高度内容保持及区块精确编辑和风格迁移的场景。

Abstract: Text-to-Image editing using diffusion models faces challenges in balancing content preservation with edit application and handling real-image editing. To address these, we propose LAMS-Edit, leveraging intermediate states from the inversion process--an essential step in real-image editing--during edited image generation. Specifically, latent representations and attention maps from both processes are combined at each step using weighted interpolation, controlled by a scheduler. This technique, Latent and Attention Mixing with Schedulers (LAMS), integrates with Prompt-to-Prompt (P2P) to form LAMS-Edit--an extensible framework that supports precise editing with region masks and enables style transfer via LoRA. Extensive experiments demonstrate that LAMS-Edit effectively balances content preservation and edit application.

</details>


### [44] [ULS+: Data-driven Model Adaptation Enhances Lesion Segmentation](https://arxiv.org/abs/2601.02988)
*Rianne Weber,Niels Rocholl,Max de Grauw,Mathias Prokop,Ewoud Smit,Alessa Hering*

Main category: cs.CV

TL;DR: 该论文提出了ULS+，这是原始Universal Lesion Segmentation (ULS)模型的增强版，通过整合更多公开数据集和优化输入尺寸，实现了更高精度与更快推理速度，实验显示ULS+显著优于原模型。


<details>
  <summary>Details</summary>
Motivation: 医学影像中病灶分割对于辅助诊断和疾病研究至关重要。原有ULS模型虽能全身范围分割，但随着新数据集的发布，更新模型以提升性能和适应性具有现实意义。

Method: ULS+通过引入新发布的多个公开数据集，同时缩小输入图片尺寸提升效率，并在ULS23 Challenge测试集和Longitudinal-CT子集上与原ULS进行了对比分析。

Result: 在所有评测中，ULS+的Dice分数和对点击点偏移的鲁棒性均显著优于ULS，同时在ULS23挑战赛测试阶段排行榜中位列第一。

Conclusion: ULS+通过持续的数据驱动迭代和临床验证，奠定了构建鲁棒且临床相关病灶分割模型的基础。

Abstract: In this study, we present ULS+, an enhanced version of the Universal Lesion Segmentation (ULS) model. The original ULS model segments lesions across the whole body in CT scans given volumes of interest (VOIs) centered around a click-point. Since its release, several new public datasets have become available that can further improve model performance. ULS+ incorporates these additional datasets and uses smaller input image sizes, resulting in higher accuracy and faster inference.
  We compared ULS and ULS+ using the Dice score and robustness to click-point location on the ULS23 Challenge test data and a subset of the Longitudinal-CT dataset. In all comparisons, ULS+ significantly outperformed ULS. Additionally, ULS+ ranks first on the ULS23 Challenge test-phase leaderboard. By maintaining a cycle of data-driven updates and clinical validation, ULS+ establishes a foundation for robust and clinically relevant lesion segmentation models.

</details>


### [45] [Towards Faithful Reasoning in Comics for Small MLLMs](https://arxiv.org/abs/2601.02991)
*Chengcheng Feng,Haojie Yin,Yucheng Jin,Kaizhu Huang*

Main category: cs.CV

TL;DR: 本文提出了一种适用于漫画视觉问答（CVQA）任务的小规模多模态大模型推理新方法，在五个基准数据集上大幅提升了表现，并且对其他相关任务（如meme与讽刺画理解）也有很好的迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型在漫画视觉问答上的推理能力有限，主要原因是漫画独有的符号抽象、叙事逻辑与幽默机制与常规视觉问答差异较大。直接将常用的Chain-of-Thought（CoT）策略应用于小模型，反而会因状态缠结等原因导致性能下降。

Method: 提出一种漫画推理框架，具体方法包括：1）将CoT生成过程模块化，2）结合基于GRPO的强化微调，3）设计新的结构化奖励函数，旨在提升小模型推理链的准确性与可迁移性。该方法不仅在漫画问答，还在meme和讽刺画等任务上进行了实验。

Result: 在五个复杂基准任务上，该方法提出的3B参数量模型超过了现有SOTA方法，另外在不同MLLMs上插件实验也平均带来12.1%的提升。

Conclusion: 模块化CoT与强化调优结合能够有效缓解漫画问答中的推理难点，使小规模多模态大模型在抽象、幽默、叙事等任务上获得显著提升。这一方法具备较强的通用性。

Abstract: Comic-based visual question answering (CVQA) poses distinct challenges to multimodal large language models (MLLMs) due to its reliance on symbolic abstraction, narrative logic, and humor, which differ from conventional VQA tasks. Although Chain-of-Thought (CoT) prompting is widely used to enhance MLLM reasoning, surprisingly, its direct application to CVQA often degrades performance, especially in small-scale models. Our theoretical and empirical analyses reveal that standard CoT in CVQA suffers from state entanglement, spurious transitions, and exploration inefficiency, with small models particularly vulnerable in resource-constrained settings. To address these issues, we propose a novel comic reasoning framework, designed to produce more faithful and transferable reasoning chains in small MLLMs. Specifically, our framework combines modular CoT generation with GRPO-based reinforcement fine-tuning and a novel structured reward. Beyond comic VQA, we further evaluate our approach on a broader class of humor-centric and abstract visual reasoning tasks, including meme understanding and editorial cartoon interpretation. Across five challenging benchmarks, our 3B model outperforms state-of-the-art methods, and plug-in experiments yield an additional average improvement of $\mathbf{12.1\%}$ across different MLLMs.

</details>


### [46] [Towards Efficient 3D Object Detection for Vehicle-Infrastructure Collaboration via Risk-Intent Selection](https://arxiv.org/abs/2601.03001)
*Li Wang,Boqi Li,Hang Chen,Xingjian Wu,Yichen Wang,Jiewen Tan,Xinyu Zhang,Huaping Liu*

Main category: cs.CV

TL;DR: 本文提出了一种互动感知驱动的车辆-基础设施协同感知框架（RiSe），能大幅降低通信量且保持先进的检测精度，突破了带宽与信息冗余的权衡瓶颈。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中，车辆与基础设施协同感知用于解决遮挡问题。但特征冗余与带宽限制成为瓶颈，现有方法未能有效针对决策关键区域优化信息传输。

Method: 提出了RiSe框架，核心包括风险意图选择性检测，基于势场理论的运动风险量化模型（PTCM）以及自动预测关键鸟瞰图区域的意图模块（IDAPM），实现只从高风险互动区传输高保真特征。

Result: 在DeepAccident数据集上实验显示，RiSe将通信量降至仅为完全特征共享的0.71%，且检测精度仍处于SOTA水平，在带宽与感知性能间达到优异权衡。

Conclusion: RiSe以风险驱动感知有效降低传输负担，为自动驾驶协同感知系统的落地提供了更高效的解决方案。

Abstract: Vehicle-Infrastructure Collaborative Perception (VICP) is pivotal for resolving occlusion in autonomous driving, yet the trade-off between communication bandwidth and feature redundancy remains a critical bottleneck. While intermediate fusion mitigates data volume compared to raw sharing, existing frameworks typically rely on spatial compression or static confidence maps, which inefficiently transmit spatially redundant features from non-critical background regions. To address this, we propose Risk-intent Selective detection (RiSe), an interaction-aware framework that shifts the paradigm from identifying visible regions to prioritizing risk-critical ones. Specifically, we introduce a Potential Field-Trajectory Correlation Model (PTCM) grounded in potential field theory to quantitatively assess kinematic risks. Complementing this, an Intention-Driven Area Prediction Module (IDAPM) leverages ego-motion priors to proactively predict and filter key Bird's-Eye-View (BEV) areas essential for decision-making. By integrating these components, RiSe implements a semantic-selective fusion scheme that transmits high-fidelity features only from high-interaction regions, effectively acting as a feature denoiser. Extensive experiments on the DeepAccident dataset demonstrate that our method reduces communication volume to 0.71\% of full feature sharing while maintaining state-of-the-art detection accuracy, establishing a competitive Pareto frontier between bandwidth efficiency and perception performance.

</details>


### [47] [ReCCur: A Recursive Corner-Case Curation Framework for Robust Vision-Language Understanding in Open and Edge Scenarios](https://arxiv.org/abs/2601.03011)
*Yihan Wei,Shenghai Yuan,Tianchen Deng,Boyang Lou,Enwen Hu*

Main category: cs.CV

TL;DR: 该论文提出了一种低算力、自动化的极端/稀有案例数据标注与整理框架ReCCur，可在有限人力与资源下，将噪声较大的网络图像数据高效转化为可审计的高质量细致标签，有助于后续模型的训练和评估。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的极端角落案例（corner cases）常常导致AI系统失效，但这类数据稀有且难以规模化整理，网络数据存在噪声和标签不可靠的问题，且实际部署场景受限于算力、无法频繁大规模重训练。如何在有限资源和人力下，获得高质量极端案例数据，是推动相关任务落地的难题。

Method: 作者提出ReCCur递归角落案例整理框架，包括大规模数据获取和基于视觉-语言模型（VLM）的三模态一致性筛选（图像、描述、关键词）、轻量化人工核查、然后利用多专家模型（如CLIP、DINOv2、BEiT）融合distillation+kNN投票与双重置信/不确定性采样，获得高精度样本；最后采用区块证据VLM对抗标签机制实现更具可解释性的标签生成，并闭环递归提升。

Result: 在极端案例（如洪水车检测等）任务中，ReCCur能在消费级GPU上运行，随着迭代纯净度和可分性持续提升，仅需极少人工参与，为下游训练和评估提供高质量数据。

Conclusion: ReCCur为资源受限场景实用高效地整理和标注极端/稀有案例数据提供了新方法，充分利用网络噪声数据、大大减轻了人工负担，并提升了数据质量，可促进稀有场景下AI系统的可靠性提升。

Abstract: Corner cases are rare or extreme scenarios that drive real-world failures, but they are difficult to curate at scale: web data are noisy, labels are brittle, and edge deployments preclude large retraining. We present ReCCur (Recursive Corner-Case Curation), a low-compute framework that converts noisy web imagery into auditable fine-grained labels via a multi-agent recursive pipeline. First, large-scale data acquisition and filtering expands a domain vocabulary with a vision-language model (VLM), crawls the web, and enforces tri-modal (image, description, keyword) consistency with light human spot checks to yield refined candidates. Next, mixture-of-experts knowledge distillation uses complementary encoders (e.g., CLIP, DINOv2, BEiT) for kNN voting with dual-confidence activation and uncertainty sampling, converging to a high-precision set. Finally, region-evidence VLM adversarial labeling pairs a proposer (multi-granularity regions and semantic cues) with a validator (global and local chained consistency) to produce explainable labels and close the loop. On realistic corner-case scenarios (e.g., flooded-car inspection), ReCCur runs on consumer-grade GPUs, steadily improves purity and separability, and requires minimal human supervision, providing a practical substrate for downstream training and evaluation under resource constraints. Code and dataset will be released.

</details>


### [48] [SA-ResGS: Self-Augmented Residual 3D Gaussian Splatting for Next Best View Selection](https://arxiv.org/abs/2601.03024)
*Kim Jun-Seong,Tae-Hyun Oh,Eduardo Pérez-Pellitero,Youngkyoon Jang*

Main category: cs.CV

TL;DR: 本文提出了一种名为SA-ResGS的3D高斯点云残差学习新框架，可更稳定地进行不确定性量化，并提升主动三维重建领域中基于不确定性的下一最佳视角(NBV)选择表现。通过创新性自增强点云生成与针对弱监督高斯分布的残差学习，提升了重建质量和视角选择鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的主动场景重建在下一最佳视角选择时，受限于不确定性评估不准确及稀疏/宽基线下高斯点分布监督不足，导致重建效率与性能受限。本文旨在提升不确定性量化的可信度和利用效率，解决高斯分布因监督不充分而影响学习稳定性的问题。

Method: 提出SA-ResGS框架，其中包括：1) 利用训练视图与外推视图三角测量生成自增强点云以评估场景覆盖效率；2) 首次针对3D高斯Splatting引入残差学习策略，结合不确定性驱动过滤、Dropout及Hard-Negative采样，提升高不确定性区域高斯点的梯度流和训练信号；3) 通过物理约束视角选择方案和残差监督，实现隐式纠偏与稳健的不确定性量化。

Result: 在主动视角选择任务上，SA-ResGS在场景重建质量与视角选择鲁棒性方面均优于现有最新方法，实验表现突出。

Conclusion: SA-ResGS有效解决了主动三维重建中由于视图稀疏、监督不足导致的不确定性量化失真和训练不稳定问题，为现实复杂场景的高质量重建和智能视角规划提供了新思路和工具。

Abstract: We propose Self-Augmented Residual 3D Gaussian Splatting (SA-ResGS), a novel framework to stabilize uncertainty quantification and enhancing uncertainty-aware supervision in next-best-view (NBV) selection for active scene reconstruction. SA-ResGS improves both the reliability of uncertainty estimates and their effectiveness for supervision by generating Self-Augmented point clouds (SA-Points) via triangulation between a training view and a rasterized extrapolated view, enabling efficient scene coverage estimation. While improving scene coverage through physically guided view selection, SA-ResGS also addresses the challenge of under-supervised Gaussians, exacerbated by sparse and wide-baseline views, by introducing the first residual learning strategy tailored for 3D Gaussian Splatting. This targeted supervision enhances gradient flow in high-uncertainty Gaussians by combining uncertainty-driven filtering with dropout- and hard-negative-mining-inspired sampling. Our contributions are threefold: (1) a physically grounded view selection strategy that promotes efficient and uniform scene coverage; (2) an uncertainty-aware residual supervision scheme that amplifies learning signals for weakly contributing Gaussians, improving training stability and uncertainty estimation across scenes with diverse camera distributions; (3) an implicit unbiasing of uncertainty quantification as a consequence of constrained view selection and residual supervision, which together mitigate conflicting effects of wide-baseline exploration and sparse-view ambiguity in NBV planning. Experiments on active view selection demonstrate that SA-ResGS outperforms state-of-the-art baselines in both reconstruction quality and view selection robustness.

</details>


### [49] [Flow Matching and Diffusion Models via PointNet for Generating Fluid Fields on Irregular Geometries](https://arxiv.org/abs/2601.03030)
*Ali Kashefi*

Main category: cs.CV

TL;DR: 本文提出了两种新颖的生成式几何深度学习框架：Flow Matching PointNet和Diffusion PointNet，能够直接在点云表示的非规则几何体上预测流体流动变量，提升了对速度、压力场和气动力的预测精度与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在复杂、非规则几何条件下对流体流动变量进行高精度预测一直是计算流体力学的重要挑战。传统方法需要将几何体投影到规则格点，会导致信息丢失和伪影现象。图神经网络扩展方法虽可处理不规则域，但常带来高频噪声且结构复杂。为解决这些问题，作者引入基于点云的方法，简化架构并提升预测效果。

Method: 作者将PointNet分别嵌入流体流动匹配模型和扩散模型，形成两种生成式几何深度学习流程。算法流程通过反向生成过程，从标准高斯噪声重构出物理场，并以点云表示输入非规则计算域，完全避免了像素化过程。与以往需额外中间网络来建模几何条件的GNN方法不同，作者的网络结构仅依赖PointNet，设计更为简洁统一。

Result: 在变化截面和朝向的圆柱外流稳态不可压缩流模拟任务中，所提框架对速度、压力场及升/阻力的预测都优于相同参数量的普通PointNet基线，同时在输入几何不完整场景下也更具鲁棒性。

Conclusion: 本文提出的Flow Matching PointNet与Diffusion PointNet可高效、精准、鲁棒地处理不规则几何上的流体流动预测任务，且结构简单，易于应用于类似的科学计算场景，有望成为几何深度学习与物理建模领域的新工具。

Abstract: We present two novel generative geometric deep learning frameworks, termed Flow Matching PointNet and Diffusion PointNet, for predicting fluid flow variables on irregular geometries by incorporating PointNet into flow matching and diffusion models, respectively. In these frameworks, a reverse generative process reconstructs physical fields from standard Gaussian noise conditioned on unseen geometries. The proposed approaches operate directly on point-cloud representations of computational domains (e.g., grid vertices of finite-volume meshes) and therefore avoid the limitations of pixelation used to project geometries onto uniform lattices. In contrast to graph neural network-based diffusion models, Flow Matching PointNet and Diffusion PointNet do not exhibit high-frequency noise artifacts in the predicted fields. Moreover, unlike such approaches, which require auxiliary intermediate networks to condition geometry, the proposed frameworks rely solely on PointNet, resulting in a simple and unified architecture. The performance of the proposed frameworks is evaluated on steady incompressible flow past a cylinder, using a geometric dataset constructed by varying the cylinder's cross-sectional shape and orientation across samples. The results demonstrate that Flow Matching PointNet and Diffusion PointNet achieve more accurate predictions of velocity and pressure fields, as well as lift and drag forces, and exhibit greater robustness to incomplete geometries compared to a vanilla PointNet with the same number of trainable parameters.

</details>


### [50] [Motion Blur Robust Wheat Pest Damage Detection with Dynamic Fuzzy Feature Fusion](https://arxiv.org/abs/2601.03046)
*Han Zhang,Yanwei Wang,Fang Li,Hongjun Wang*

Main category: cs.CV

TL;DR: 本文提出DFRCP动态模糊鲁棒卷积金字塔，作为YOLOv11插件化升级方案，用于提升检测模型在运动模糊下的鲁棒性，通过融合多尺度特征及模糊特征，有效提升模糊图像中的检测准确率，并显著加速推理，适合边缘设备部署。


<details>
  <summary>Details</summary>
Motivation: 运动模糊导致的重影会严重影响目标检测的准确性，尤其是在边缘设备部署或农作物虫害等应用场景，现有方法不是丢失结构信息就是计算开销大，急需低成本、高效率、鲁棒的检测方法。

Method: 提出DFRCP——动态模糊鲁棒卷积金字塔，通过增强YOLOv11特征金字塔，融合大中尺度特征，引入动态鲁棒切换单元自适应注入模糊特征，模糊特征通过多尺度特征旋转、非线性插值及透明卷积融合生成。配套CUDA并行核极大提升特征变换计算速度。

Result: 在人工增广（包含全图运动模糊及bbox区域旋转模糊）的小麦虫害数据集测试中，DFRCP提升YOLOv11约10.4%的检测准确率，推理速度极大加快，训练耗时增加有限。

Conclusion: DFRCP可作为通用插件增强YOLOv11等检测模型对模糊图像的鲁棒性，显著提高实际应用中的检测准确率及效率，尤其适合边缘计算设备部署，减少人工筛查负担。

Abstract: Motion blur caused by camera shake produces ghosting artifacts that substantially degrade edge side object detection. Existing approaches either suppress blur as noise and lose discriminative structure, or apply full image restoration that increases latency and limits deployment on resource constrained devices. We propose DFRCP, a Dynamic Fuzzy Robust Convolutional Pyramid, as a plug in upgrade to YOLOv11 for blur robust detection. DFRCP enhances the YOLOv11 feature pyramid by combining large scale and medium scale features while preserving native representations, and by introducing Dynamic Robust Switch units that adaptively inject fuzzy features to strengthen global perception under jitter. Fuzzy features are synthesized by rotating and nonlinearly interpolating multiscale features, then merged through a transparency convolution that learns a content adaptive trade off between original and fuzzy cues. We further develop a CUDA parallel rotation and interpolation kernel that avoids boundary overflow and delivers more than 400 times speedup, making the design practical for edge deployment. We train with paired supervision on a private wheat pest damage dataset of about 3,500 images, augmented threefold using two blur regimes, uniform image wide motion blur and bounding box confined rotational blur. On blurred test sets, YOLOv11 with DFRCP achieves about 10.4 percent higher accuracy than the YOLOv11 baseline with only a modest training time overhead, reducing the need for manual filtering after data collection.

</details>


### [51] [On the Intrinsic Limits of Transformer Image Embeddings in Non-Solvable Spatial Reasoning](https://arxiv.org/abs/2601.03048)
*Siyi Lyu,Quan Liu,Feng Yan*

Main category: cs.CV

TL;DR: 本文针对Vision Transformers（ViTs）在空间推理任务中表现不佳的问题，提出该局限本质上源自架构的复杂性下界，理论上分析了其对非可解群（如三维旋转群SO(3)）空间结构的表达能力受限，并通过实验验证了该结构性失败。


<details>
  <summary>Details</summary>
Motivation: ViT在语义识别方面表现卓越，但在空间推理任务（如心理旋转）中表现不理想。传统解释侧重于数据量不足，但作者认为主要原因在于ViT架构在表达复杂空间变换时的计算复杂性限制。

Method: 作者将空间理解形式化为学习群同态映射（Group Homomorphism），用以保持底层变换群在潜在空间中的代数结构。通过理论分析，将该问题与Word Problem的复杂性联系起来，并对ViT进行复杂性分层。用潜在空间探测实验证明ViT在非可解群任务上表现失效。

Result: 理论上证明：常数深度且多项式精度的ViT，其表达能力至多属于TC^0复杂度类，无法高效建模NC^1-完全的非可解空间结构。实验上也观测到ViT在处理如SO(3)等非可解群结构任务时，表现为结构性坍塌。

Conclusion: ViT架构在空间推理，尤其是涉及复杂空间群（如3D旋转SO(3)）的任务上，受限于其电路复杂性下界，常数深度ViT无法有效捕捉非可解空间结构，揭示了其认知局限。本研究为ViT及相关神经网络架构在高阶空间推理任务中的能力和瓶颈提供了理论指导。

Abstract: Vision Transformers (ViTs) excel in semantic recognition but exhibit systematic failures in spatial reasoning tasks such as mental rotation. While often attributed to data scale, we propose that this limitation arises from the intrinsic circuit complexity of the architecture. We formalize spatial understanding as learning a Group Homomorphism: mapping image sequences to a latent space that preserves the algebraic structure of the underlying transformation group. We demonstrate that for non-solvable groups (e.g., the 3D rotation group $\mathrm{SO}(3)$), maintaining such a structure-preserving embedding is computationally lower-bounded by the Word Problem, which is $\mathsf{NC^1}$-complete. In contrast, we prove that constant-depth ViTs with polynomial precision are strictly bounded by $\mathsf{TC^0}$. Under the conjecture $\mathsf{TC^0} \subsetneq \mathsf{NC^1}$, we establish a complexity boundary: constant-depth ViTs fundamentally lack the logical depth to efficiently capture non-solvable spatial structures. We validate this complexity gap via latent-space probing, demonstrating that ViT representations suffer a structural collapse on non-solvable tasks as compositional depth increases.

</details>


### [52] [IBISAgent: Reinforcing Pixel-Level Visual Reasoning in MLLMs for Universal Biomedical Object Referring and Segmentation](https://arxiv.org/abs/2601.03054)
*Yankai Jiang,Qiaoru Li,Binlu Xu,Haoran Sun,Chao Ding,Junting Dong,Yuxiang Cai,Xuhong Zhang,Jianwei Yin*

Main category: cs.CV

TL;DR: 本文提出了面向医学多模态大模型（MLLM）的IBISAgent方法，能更高效地实现像素级分割和视觉推理，并取得了优于现有方法的表现。


<details>
  <summary>Details</summary>
Motivation: 现有医学MLLM在像素级理解上面临两大问题：一是分割方法依赖隐式标记及同步微调MLLM与像素解码器，易遗忘且泛化性差；二是存在缺乏迭代优化且为一次性推理流程，导致结果不佳。

Method: 提出IBISAgent，通过将分割任务转化为以视觉为中心的多步决策过程，让MLLM产生交替的推理与文本点击动作、调用分割工具，无需模型架构变动反复优化分割掩码。训练分为冷启动有监督微调和针对性强化学习两个阶段。

Result: 在包括复杂医学指代、推理分割任务的多项实验中，IBISAgent在不同数据集上持续超越开源和闭源SOTA方法。

Conclusion: IBISAgent显著提升了医学MLLM的像素级分割与推理能力，具备更好的泛化性和鲁棒性，相关资源将全部开源。

Abstract: Recent research on medical MLLMs has gradually shifted its focus from image-level understanding to fine-grained, pixel-level comprehension. Although segmentation serves as the foundation for pixel-level understanding, existing approaches face two major challenges. First, they introduce implicit segmentation tokens and require simultaneous fine-tuning of both the MLLM and external pixel decoders, which increases the risk of catastrophic forgetting and limits generalization to out-of-domain scenarios. Second, most methods rely on single-pass reasoning and lack the capability to iteratively refine segmentation results, leading to suboptimal performance. To overcome these limitations, we propose a novel agentic MLLM, named IBISAgent, that reformulates segmentation as a vision-centric, multi-step decision-making process. IBISAgent enables MLLMs to generate interleaved reasoning and text-based click actions, invoke segmentation tools, and produce high-quality masks without architectural modifications. By iteratively performing multi-step visual reasoning on masked image features, IBISAgent naturally supports mask refinement and promotes the development of pixel-level visual reasoning capabilities. We further design a two-stage training framework consisting of cold-start supervised fine-tuning and agentic reinforcement learning with tailored, fine-grained rewards, enhancing the model's robustness in complex medical referring and reasoning segmentation tasks. Extensive experiments demonstrate that IBISAgent consistently outperforms both closed-source and open-source SOTA methods. All datasets, code, and trained models will be released publicly.

</details>


### [53] [Fine-Grained Generalization via Structuralizing Concept and Feature Space into Commonality, Specificity and Confounding](https://arxiv.org/abs/2601.03056)
*Zhen Wang,Jiaojiao Zhao,Qilong Wang,Yongfeng Dong,Wenlong Yu*

Main category: cs.CV

TL;DR: 本文针对细粒度领域泛化（FGDG）难题，提出了一种概念-特征结构化泛化（CFSG）模型，有效提升了模型在不同领域下的识别能力，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: FGDG任务中，由于类别间差异细微且同类内部变化较大，常规领域泛化方法效果不佳，且深度学习模型在领域迁移时对细粒度特征过于敏感，易忽略关键信息，导致性能显著下降，而人类识别可以灵活融合共性与特异属性，该机制尚未被现有模型有效利用。

Method: 提出CFSG模型，将概念和特征空间分别解耦为共性、特异和混淆三部分，并通过自适应机制动态调整三者比例，最终通过显式权重整合不同组件进行预测。

Result: 在三个单源公开细粒度泛化基准数据集上，CFSG模型平均比基线模型提升9.87%，同时超过最新SOTA 3.08%，并通过解释性分析验证了模型结构合理性。

Conclusion: CFSG能够充分融合多粒度结构化知识，提升模型泛化能力，且特征结构化有助于概念结构化，展现了较强的应用前景。

Abstract: Fine-Grained Domain Generalization (FGDG) presents greater challenges than conventional domain generalization due to the subtle inter-class differences and relatively pronounced intra-class variations inherent in fine-grained recognition tasks. Under domain shifts, the model becomes overly sensitive to fine-grained cues, leading to the suppression of critical features and a significant drop in performance. Cognitive studies suggest that humans classify objects by leveraging both common and specific attributes, enabling accurate differentiation between fine-grained categories. However, current deep learning models have yet to incorporate this mechanism effectively. Inspired by this mechanism, we propose Concept-Feature Structuralized Generalization (CFSG). This model explicitly disentangles both the concept and feature spaces into three structured components: common, specific, and confounding segments. To mitigate the adverse effects of varying degrees of distribution shift, we introduce an adaptive mechanism that dynamically adjusts the proportions of common, specific, and confounding components. In the final prediction, explicit weights are assigned to each pair of components. Extensive experiments on three single-source benchmark datasets demonstrate that CFSG achieves an average performance improvement of 9.87% over baseline models and outperforms existing state-of-the-art methods by an average of 3.08%. Additionally, explainability analysis validates that CFSG effectively integrates multi-granularity structured knowledge and confirms that feature structuralization facilitates the emergence of concept structuralization.

</details>


### [54] [Understanding Multi-Agent Reasoning with Large Language Models for Cartoon VQA](https://arxiv.org/abs/2601.03073)
*Tong Wu,Thanet Markchom*

Main category: cs.CV

TL;DR: 该论文提出了一种多智能体LLM框架，专门用于风格化卡通图像下的视觉问答（VQA）任务，验证了在Pororo和Simpsons数据集上的有效性。


<details>
  <summary>Details</summary>
Motivation: 标准大语言模型主要针对自然图像训练，难以应对卡通图像中夸张的视觉抽象及叙事驱动的上下文理解。因此，亟需针对卡通VQA特点的专用方法。

Method: 作者设计了一个多智能体架构，包括视觉、语言和批评三类智能体，三者联合工作，通过整合视觉线索和叙事语境，实现结构化推理。

Result: 实验在Pororo和Simpsons两个卡通VQA数据集上系统评估了该框架，详细分析了各智能体对最终预测的贡献。

Conclusion: 该多智能体LLM框架有效提升了卡通VQA中的多模态推理能力，对理解LLM多智能体协作提供了新的见解。

Abstract: Visual Question Answering (VQA) for stylised cartoon imagery presents challenges, such as interpreting exaggerated visual abstraction and narrative-driven context, which are not adequately addressed by standard large language models (LLMs) trained on natural images. To investigate this issue, a multi-agent LLM framework is introduced, specifically designed for VQA tasks in cartoon imagery. The proposed architecture consists of three specialised agents: visual agent, language agent and critic agent, which work collaboratively to support structured reasoning by integrating visual cues and narrative context. The framework was systematically evaluated on two cartoon-based VQA datasets: Pororo and Simpsons. Experimental results provide a detailed analysis of how each agent contributes to the final prediction, offering a deeper understanding of LLM-based multi-agent behaviour in cartoon VQA and multimodal inference.

</details>


### [55] [LesionTABE: Equitable AI for Skin Lesion Detection](https://arxiv.org/abs/2601.03090)
*Rocio Mexia Diaz,Yasmin Greenway,Petru Manescu*

Main category: cs.CV

TL;DR: 本文提出了LesionTABE——一个关注公平性的皮肤病AI诊断框架，通过结合对抗去偏和领域专属基础模型嵌入，有效提升了暗色肤色诊断表现，在公平性和准确率上显著优于传统和现有去偏方法。


<details>
  <summary>Details</summary>
Motivation: 皮肤科AI诊断模型在暗色肤色上的效果较差，成为AI临床应用的重要障碍，因此亟需提升模型的公平性，实现对不同肤色群体的准确诊断。

Method: 作者提出了LesionTABE框架，将对抗去偏技术与皮肤病专用的基础模型嵌入结合，并在多个涵盖恶性和炎症性疾病的数据集上进行了实验评估。

Result: LesionTABE在公平性指标上比ResNet-152基线模型提升超过25%，且效果优于其他现有去偏方法，同时还提升了整体诊断准确率。

Conclusion: 基础模型结合去偏策略能够显著提升皮肤科AI系统的公平性，对于推动AI在临床中平等应用具有重要意义。

Abstract: Bias remains a major barrier to the clinical adoption of AI in dermatology, as diagnostic models underperform on darker skin tones. We present LesionTABE, a fairness-centric framework that couples adversarial debiasing with dermatology-specific foundation model embeddings. Evaluated across multiple datasets covering both malignant and inflammatory conditions, LesionTABE achieves over a 25\% improvement in fairness metrics compared to a ResNet-152 baseline, outperforming existing debiasing methods while simultaneously enhancing overall diagnostic accuracy. These results highlight the potential of foundation model debiasing as a step towards equitable clinical AI adoption.

</details>


### [56] [Text-Guided Layer Fusion Mitigates Hallucination in Multimodal LLMs](https://arxiv.org/abs/2601.03100)
*Chenchen Lin,Sanbao Su,Rachel Luo,Yuxiao Chen,Yan Wang,Marco Pavone,Fei Miao*

Main category: cs.CV

TL;DR: 该论文提出了TGIF（Text-Guided Inter-layer Fusion）模块，通过依据问题内容动态融合视觉编码器不同层次的特征，以加强多模态大模型的视觉感知能力，并显著降低幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大模型（MLLMs）通常只利用视觉编码器最后一层的特征，未能充分挖掘视觉编码器不同层丰富的视觉语义层次信息，因此在认知与推理时容易出现基于文本先验的不真实幻觉现象，模型的视觉真实感不足。以往缓解方法侧重文本侧，未触达视觉特征层次融合。

Method: 作者提出了一个轻量级的融合模块TGIF：视视觉编码器不同层为“专家”，根据输入的文本动态预测各层视觉特征的融合方式，实现“外部融合”，整个过程中无需更新视觉编码器参数，且计算开销极低。模块集成到LLaVA-1.5-7B模型，并基于多个基准任务进行评测。

Result: TGIF在幻觉、OCR、视觉问答等相关基准测试上超越原模型，并在ScienceQA、GQA和MMBench等任务上保持或提升了性能。

Conclusion: 针对多模态大模型幻觉普遍问题，基于任务查询的视觉层级融合（TGIF）有效提升了模型视觉真实感，降低幻觉风险，是加强视觉基础和提升推理可靠性的可行方案。

Abstract: Multimodal large language models (MLLMs) typically rely on a single late-layer feature from a frozen vision encoder, leaving the encoder's rich hierarchy of visual cues under-utilized. MLLMs still suffer from visually ungrounded hallucinations, often relying on language priors rather than image evidence. While many prior mitigation strategies operate on the text side, they leave the visual representation unchanged and do not exploit the rich hierarchy of features encoded across vision layers. Existing multi-layer fusion methods partially address this limitation but remain static, applying the same layer mixture regardless of the query. In this work, we introduce TGIF (Text-Guided Inter-layer Fusion), a lightweight module that treats encoder layers as depth-wise "experts" and predicts a prompt-dependent fusion of visual features. TGIF follows the principle of direct external fusion, requires no vision-encoder updates, and adds minimal overhead. Integrated into LLaVA-1.5-7B, TGIF provides consistent improvements across hallucination, OCR, and VQA benchmarks, while preserving or improving performance on ScienceQA, GQA, and MMBench. These results suggest that query-conditioned, hierarchy-aware fusion is an effective way to strengthen visual grounding and reduce hallucination in modern MLLMs.

</details>


### [57] [LeafLife: An Explainable Deep Learning Framework with Robustness for Grape Leaf Disease Recognition](https://arxiv.org/abs/2601.03124)
*B. M. Shahria Alam,Md. Nasim Ahmed*

Main category: cs.CV

TL;DR: 本论文提出了一种基于深度学习的葡萄叶病害检测方法，通过Xception模型在9032张图像数据集上取得了96.23%的高准确率，并实现了可视化与在线应用。


<details>
  <summary>Details</summary>
Motivation: 葡萄叶病害严重影响作物产量和品质，及时准确地诊断对于农民的田间管理和增产至关重要，因此需要高效、准确的方法对葡萄叶病进行自动检测和分类。

Method: 作者使用包含9032张图像的葡萄叶病数据集，将图像分为三类病叶和一类健康叶。预处理后，数据集按照7:2:1比例划分为训练、验证和测试集。采用InceptionV3和Xception两种预训练深度学习模型对数据进行训练，其中Xception效果更佳。此外，引入对抗训练提升模型鲁棒性，采用Grad-CAM技术进行疾病可视化解释，并基于Streamlit实现了带热力图和置信度输出的网页版应用。

Result: Xception模型在测试集上获得了96.23%的准确率，优于InceptionV3。通过Grad-CAM，模型诊断结果更具透明性和可解释性。最终系统可在线实现葡萄叶病检测和可视化输出。

Conclusion: 本文方法能高效、准确地对葡萄叶病进行检测和分类，具有较强的鲁棒性和可解释性，并通过Web应用方便实际部署和推广，对提高农业生产具有积极意义。

Abstract: Plant disease diagnosis is essential to farmers' management choices because plant diseases frequently lower crop yield and product quality. For harvests to flourish and agricultural productivity to boost, grape leaf disease detection is important. The plant disease dataset contains grape leaf diseases total of 9,032 images of four classes, among them three classes are leaf diseases, and the other one is healthy leaves. After rigorous pre-processing dataset was split (70% training, 20% validation, 10% testing), and two pre-trained models were deployed: InceptionV3 and Xception. Xception shows a promising result of 96.23% accuracy, which is remarkable than InceptionV3. Adversarial Training is used for robustness, along with more transparency. Grad-CAM is integrated to confirm the leaf disease. Finally deployed a web application using Streamlit with a heatmap visualization and prediction with confidence level for robust grape leaf disease classification.

</details>


### [58] [Unified Thinker: A General Reasoning Modular Core for Image Generation](https://arxiv.org/abs/2601.03127)
*Sashuai Zhou,Qiang Zhou,Jijin Hu,Hanqing Yang,Yue Cao,Junpeng Ma,Yinchao Ma,Jun Song,Tiezheng Ge,Cheng Yu,Bo Zheng,Zhou Zhao*

Main category: cs.CV

TL;DR: 本文提出了Unified Thinker，一种通用的推理架构，通过将高层意图分解为可验证的执行计划，有效提升文本到图像生成和图像编辑的逻辑推理和生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在逻辑推理和指令理解方面存在明显不足，尤其与一些闭源系统（如Nano Banana）相比，开源模型存在较大差距。因此，作者希望通过改进推理机制，缩小推理-生成之间的差距。

Method: 本文提出一种通用且独立于任务的推理架构Unified Thinker，将推理（Thinker）与图像生成器（Generator）解耦。流程包括两阶段训练：首先为推理器构建结构化的计划接口，然后通过强化学习使其根据像素级反馈优化，实现生成过程由推理直观引导。该方法可与不同的生成器和工作流集成。

Result: 实验表明，Unified Thinker在文本到图像生成和图像编辑任务中，显著提升了模型的推理能力和生成结果的质量。

Conclusion: 通过引入可执行推理并分离推理与生成模块，Unified Thinker为通用图像生成提供了更强的逻辑推演能力和更高图像品质。

Abstract: Despite impressive progress in high-fidelity image synthesis, generative models still struggle with logic-intensive instruction following, exposing a persistent reasoning--execution gap. Meanwhile, closed-source systems (e.g., Nano Banana) have demonstrated strong reasoning-driven image generation, highlighting a substantial gap to current open-source models. We argue that closing this gap requires not merely better visual generators, but executable reasoning: decomposing high-level intents into grounded, verifiable plans that directly steer the generative process. To this end, we propose Unified Thinker, a task-agnostic reasoning architecture for general image generation, designed as a unified planning core that can plug into diverse generators and workflows. Unified Thinker decouples a dedicated Thinker from the image Generator, enabling modular upgrades of reasoning without retraining the entire generative model. We further introduce a two-stage training paradigm: we first build a structured planning interface for the Thinker, then apply reinforcement learning to ground its policy in pixel-level feedback, encouraging plans that optimize visual correctness over textual plausibility. Extensive experiments on text-to-image generation and image editing show that Unified Thinker substantially improves image reasoning and generation quality.

</details>


### [59] [LSP-DETR: Efficient and Scalable Nuclei Segmentation in Whole Slide Images](https://arxiv.org/abs/2601.03163)
*Matěj Pekár,Vít Musil,Rudolf Nenutil,Petr Holub,Tomáš Brázdil*

Main category: cs.CV

TL;DR: 本文提出了一种高效的细胞核实例分割方法LSP-DETR，通过轻量级Transformer实现端到端高效分割，无需繁琐后处理，可大幅提升大图像下的分割速度和精度。


<details>
  <summary>Details</summary>
Motivation: 在病理图像分析中，细胞核实例分割至关重要。目前主流方法依赖于小块处理与繁琐的事后分割，既牺牲了全局上下文，又效率低下，难以适用于超大图像。

Method: 提出LSP-DETR框架，该方法将细胞核实例表示为星形多边形，采用线性复杂度的Transformer主干网络。创新性地引入径向距离损失函数，使重叠细胞核的分割不需要显式重叠标签或复杂后处理。

Result: 在PanNuke和MoNuSeg数据集上，LSP-DETR展现出跨组织的优秀泛化性能，分割效率为现有最快方法的5倍以上，达到领先的运算速度和分割效果。

Conclusion: LSP-DETR能大幅提升巨幅病理图像细胞核分割的效率与精度，将推动病理图像处理领域的进步。

Abstract: Precise and scalable instance segmentation of cell nuclei is essential for computational pathology, yet gigapixel Whole-Slide Images pose major computational challenges. Existing approaches rely on patch-based processing and costly post-processing for instance separation, sacrificing context and efficiency. We introduce LSP-DETR (Local Star Polygon DEtection TRansformer), a fully end-to-end framework that uses a lightweight transformer with linear complexity to process substantially larger images without additional computational cost. Nuclei are represented as star-convex polygons, and a novel radial distance loss function allows the segmentation of overlapping nuclei to emerge naturally, without requiring explicit overlap annotations or handcrafted post-processing. Evaluations on PanNuke and MoNuSeg show strong generalization across tissues and state-of-the-art efficiency, with LSP-DETR being over five times faster than the next-fastest leading method. Code and models are available at https://github.com/RationAI/lsp-detr.

</details>


### [60] [DiffBench Meets DiffAgent: End-to-End LLM-Driven Diffusion Acceleration Code Generation](https://arxiv.org/abs/2601.03178)
*Jiajun jiao,Haowei Zhu,Puyuan Yang,Jianghui Wang,Ji Liu,Ziqiong Liu,Dong Li,Yuejian Fang,Junhai Yong,Bin Wang,Emad Barsoum*

Main category: cs.CV

TL;DR: 本文提出了利用大型语言模型（LLM）自动生成和评估扩散模型加速代码的框架，包括评测基准DiffBench与自动加速策略生成Agent DiffAgent，大幅提升了多种扩散模型的推理效率。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像和视频生成领域表现出色，但多步推理过程导致推理速度慢、计算开销大，阻碍了实际应用，亟需高效的自动化加速方法。

Method: 1. 提出DiffBench：一个自动评测流水线，涵盖多种扩散架构、优化组合和部署场景。
2. 提出DiffAgent：利用LLM，结合规划、调试模块与遗传算法反馈，自动迭代生成并优化加速代码。

Result: DiffBench可全面评测自动生成的加速代码；DiffAgent显著优于现有LLM，在多样化扩散模型上能自动生成更优的加速策略和代码。

Conclusion: 基于LLM的自动化代码生成与评测框架能有效提升扩散模型的推理效率，为实际部署和加速提供了新方法和实证基础。

Abstract: Diffusion models have achieved remarkable success in image and video generation. However, their inherently multiple step inference process imposes substantial computational overhead, hindering real-world deployment. Accelerating diffusion models is therefore essential, yet determining how to combine multiple model acceleration techniques remains a significant challenge. To address this issue, we introduce a framework driven by large language models (LLMs) for automated acceleration code generation and evaluation. First, we present DiffBench, a comprehensive benchmark that implements a three stage automated evaluation pipeline across diverse diffusion architectures, optimization combinations and deployment scenarios. Second, we propose DiffAgent, an agent that generates optimal acceleration strategies and codes for arbitrary diffusion models. DiffAgent employs a closed-loop workflow in which a planning component and a debugging component iteratively refine the output of a code generation component, while a genetic algorithm extracts performance feedback from the execution environment to guide subsequent code refinements. We provide a detailed explanation of the DiffBench construction and the design principles underlying DiffAgent. Extensive experiments show that DiffBench offers a thorough evaluation of generated codes and that DiffAgent significantly outperforms existing LLMs in producing effective diffusion acceleration strategies.

</details>


### [61] [AnatomiX, an Anatomy-Aware Grounded Multimodal Large Language Model for Chest X-Ray Interpretation](https://arxiv.org/abs/2601.03191)
*Anees Ur Rehman Hashmi,Numan Saeed,Christoph Lippert*

Main category: cs.CV

TL;DR: 本文提出了AnatomiX，一种专为胸部X光解读设计，多任务、多模态的大型语言模型，在空间推理和解剖学理解方面取得了显著突破。


<details>
  <summary>Details</summary>
Motivation: 目前多模态医学大语言模型在胸部X光解读中表现优秀，但在空间推理和解剖学理解方面仍有不足，特别是在建立真实解剖对应关系方面。

Method: AnatomiX借鉴放射学工作流程，采用两阶段方法：首先识别解剖结构并提取其特征，然后利用大语言模型执行包括短语定位、报告生成、视觉问答和图像理解等多种下游任务。

Result: 在多个基准测试中，AnatomiX在解剖学推理方面表现优越，在解剖定位、短语定位、基于定位的诊断和描述任务上，性能提升超过25%。

Conclusion: AnatomiX模型显著提升了胸部X光解读的解剖学基础理解，为医学多模态大语言模型的解剖推理带来新进展。

Abstract: Multimodal medical large language models have shown impressive progress in chest X-ray interpretation but continue to face challenges in spatial reasoning and anatomical understanding. Although existing grounding techniques improve overall performance, they often fail to establish a true anatomical correspondence, resulting in incorrect anatomical understanding in the medical domain. To address this gap, we introduce AnatomiX, a multitask multimodal large language model explicitly designed for anatomically grounded chest X-ray interpretation. Inspired by the radiological workflow, AnatomiX adopts a two stage approach: first, it identifies anatomical structures and extracts their features, and then leverages a large language model to perform diverse downstream tasks such as phrase grounding, report generation, visual question answering, and image understanding. Extensive experiments across multiple benchmarks demonstrate that AnatomiX achieves superior anatomical reasoning and delivers over 25% improvement in performance on anatomy grounding, phrase grounding, grounded diagnosis and grounded captioning tasks compared to existing approaches. Code and pretrained model are available at https://github.com/aneesurhashmi/anatomix

</details>


### [62] [UniCorn: Towards Self-Improving Unified Multimodal Models through Self-Generated Supervision](https://arxiv.org/abs/2601.03193)
*Ruiyan Han,Zhen Fang,XinYu Sun,Yuchen Ma,Ziheng Wang,Yu Zeng,Zehui Chen,Lin Chen,Wenxuan Huang,Wei-Jie Xu,Yi Cao,Feng Zhao*

Main category: cs.CV

TL;DR: 该论文提出了一种新方法UniCorn，通过自我提升机制提升统一多模态模型（UMM）的生成能力，无需外部数据或教师监督，大大改善了从文本到图像的生成质量。


<details>
  <summary>Details</summary>
Motivation: 尽管统一多模态模型在跨模态理解上取得了突破，但在理解转化为高质量生成时依然存在差距。作者将其形容为'传导性失语症'现象：模型能解读多模态输入，但难以将其内在理解准确生成输出。解决这一瓶颈具有重要意义。

Method: 方法上，作者将单个UMM划分为三类角色（提出者Proposer、解决者Solver、和裁判Judge），三者协作以自博弈方式提升性能，并通过认知模式重构，将潜在理解转化为明确的生成信号。还引入了UniCycle基准，通过文本—图像—文本循环一致性检验多模态生成的连贯性。

Result: UniCorn在六个通用图像生成基准上均大幅超越基础模型，尤其在TIIF、DPG、CompBench和新提出的UniCycle基准上达到SOTA水平，对WISE和OneIG也有显著提升。

Conclusion: UniCorn显著增强了统一多模态模型的生成性能且无需外部数据或监督，展示了完全自监督方法在多模态智能领域的潜力和可扩展性。

Abstract: While Unified Multimodal Models (UMMs) have achieved remarkable success in cross-modal comprehension, a significant gap persists in their ability to leverage such internal knowledge for high-quality generation. We formalize this discrepancy as Conduction Aphasia, a phenomenon where models accurately interpret multimodal inputs but struggle to translate that understanding into faithful and controllable synthesis. To address this, we propose UniCorn, a simple yet elegant self-improvement framework that eliminates the need for external data or teacher supervision. By partitioning a single UMM into three collaborative roles: Proposer, Solver, and Judge, UniCorn generates high-quality interactions via self-play and employs cognitive pattern reconstruction to distill latent understanding into explicit generative signals. To validate the restoration of multimodal coherence, we introduce UniCycle, a cycle-consistency benchmark based on a Text to Image to Text reconstruction loop. Extensive experiments demonstrate that UniCorn achieves comprehensive and substantial improvements over the base model across six general image generation benchmarks. Notably, it achieves SOTA performance on TIIF(73.8), DPG(86.8), CompBench(88.5), and UniCycle while further delivering substantial gains of +5.0 on WISE and +6.5 on OneIG. These results highlight that our method significantly enhances T2I generation while maintaining robust comprehension, demonstrating the scalability of fully self-supervised refinement for unified multimodal intelligence.

</details>


### [63] [LTX-2: Efficient Joint Audio-Visual Foundation Model](https://arxiv.org/abs/2601.03233)
*Yoav HaCohen,Benny Brazowski,Nisan Chiprut,Yaki Bitterman,Andrew Kvochko,Avishai Berkowitz,Daniel Shalem,Daphna Lifschitz,Dudu Moshe,Eitan Porat,Eitan Richardson,Guy Shiran,Itay Chachy,Jonathan Chetboun,Michael Finkelson,Michael Kupchick,Nir Zabari,Nitzan Guetta,Noa Kotler,Ofir Bibi,Ori Gordon,Poriya Panet,Roi Benita,Shahar Armon,Victor Kulikov,Yaron Inger,Yonatan Shiftan,Zeev Melumian,Zeev Farbman*

Main category: cs.CV

TL;DR: LTX-2是一种开放源代码的统一音视频生成基础模型，能够根据文本生成高质量、时间同步的音视频内容，效果接近甚至超过部分专有模型。


<details>
  <summary>Details</summary>
Motivation: 当前的文本到视频扩散模型虽然能生成高质量的视频序列，但缺乏同步的音频输出，导致生成结果在语义、情感和氛围上不足。因此，研究者希望开发一种能同时生成音视频内容，且能更好地理解文本提示的生成模型。

Method: LTX-2采用了一个非对称双流Transformer架构，包括一个拥有140亿参数的视频流和一个拥有50亿参数的音频流，通过双向音视频交叉注意力层与时间位置嵌入以及跨模态AdaLN进行联合。模型还引入了多语言文本编码器和模态感知的无分类器引导机制以提升音视频对齐和可控性。

Result: LTX-2不仅能生成语音，还能产出丰富、连贯，能随场景变化的音轨，实现背景音和拟音元素的自然融合。评测结果显示，该模型在开源系统中音视频质量和对文本提示的遵循度达到最新水平，并以更低的计算成本和更快推理速度实现与部分专有模型接近的表现。

Conclusion: LTX-2展示了统一音视频生成的新范式，支持多语义、多模态、低成本生成，且全部模型权重与代码均已开源，将为音视频生成领域的研究和应用带来新的推动。

Abstract: Recent text-to-video diffusion models can generate compelling video sequences, yet they remain silent -- missing the semantic, emotional, and atmospheric cues that audio provides. We introduce LTX-2, an open-source foundational model capable of generating high-quality, temporally synchronized audiovisual content in a unified manner. LTX-2 consists of an asymmetric dual-stream transformer with a 14B-parameter video stream and a 5B-parameter audio stream, coupled through bidirectional audio-video cross-attention layers with temporal positional embeddings and cross-modality AdaLN for shared timestep conditioning. This architecture enables efficient training and inference of a unified audiovisual model while allocating more capacity for video generation than audio generation. We employ a multilingual text encoder for broader prompt understanding and introduce a modality-aware classifier-free guidance (modality-CFG) mechanism for improved audiovisual alignment and controllability. Beyond generating speech, LTX-2 produces rich, coherent audio tracks that follow the characters, environment, style, and emotion of each scene -- complete with natural background and foley elements. In our evaluations, the model achieves state-of-the-art audiovisual quality and prompt adherence among open-source systems, while delivering results comparable to proprietary models at a fraction of their computational cost and inference time. All model weights and code are publicly released.

</details>


### [64] [A Versatile Multimodal Agent for Multimedia Content Generation](https://arxiv.org/abs/2601.03250)
*Daoan Zhang,Wenlin Yao,Xiaoyang Wang,Yebowen Hu,Jiebo Luo,Dong Yu*

Main category: cs.CV

TL;DR: 本文提出了一个自动化复杂内容创作的多媒体智能体（MultiMedia-Agent）系统，集成数据生成、工具库和评价机制，并通过分阶段训练显著提升多模态输出能力。


<details>
  <summary>Details</summary>
Motivation: 现有AIGC模型只能在特定场景中作为组件，难以实现端到端的多模态内容生成，实际应用需求亟需能整合多种媒体和工具的智能系统。

Method: 提出MultiMedia-Agent，包含数据生成流程、内容创作工具库和偏好一致性评价指标。融入技能习得理论用于数据和模型训练，采用两阶段相关性优化和三阶段模型微调及偏好优化。

Result: 对比实验表明，MultiMedia-Agent在多媒体内容生成上优于现有新兴模型，生成内容多样且质量更佳。

Conclusion: MultiMedia-Agent能高效、自动化地生成优质多模态内容，突破当前AIGC模型集成和任务复杂度限制，为实际内容创作提供更强工具。

Abstract: With the advancement of AIGC (AI-generated content) technologies, an increasing number of generative models are revolutionizing fields such as video editing, music generation, and even film production. However, due to the limitations of current AIGC models, most models can only serve as individual components within specific application scenarios and are not capable of completing tasks end-to-end in real-world applications. In real-world applications, editing experts often work with a wide variety of images and video inputs, producing multimodal outputs -- a video typically includes audio, text, and other elements. This level of integration across multiple modalities is something current models are unable to achieve effectively. However, the rise of agent-based systems has made it possible to use AI tools to tackle complex content generation tasks. To deal with the complex scenarios, in this paper, we propose a MultiMedia-Agent designed to automate complex content creation. Our agent system includes a data generation pipeline, a tool library for content creation, and a set of metrics for evaluating preference alignment. Notably, we introduce the skill acquisition theory to model the training data curation and agent training. We designed a two-stage correlation strategy for plan optimization, including self-correlation and model preference correlation. Additionally, we utilized the generated plans to train the MultiMedia-Agent via a three stage approach including base/success plan finetune and preference optimization. The comparison results demonstrate that the our approaches are effective and the MultiMedia-Agent can generate better multimedia content compared to novel models.

</details>


### [65] [InfiniDepth: Arbitrary-Resolution and Fine-Grained Depth Estimation with Neural Implicit Fields](https://arxiv.org/abs/2601.03252)
*Hao Yu,Haotong Lin,Jiawei Wang,Jiaxin Li,Yida Wang,Xueyang Zhang,Yue Wang,Xiaowei Zhou,Ruizhen Hu,Sida Peng*

Main category: cs.CV

TL;DR: 该论文提出了一种名为InfiniDepth的新型深度估计方法，通过将深度表示为神经隐式场，实现了任意分辨率下的高精度深度估计，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有深度估计方法通常仅在离散图像网格上预测深度，限制了输出分辨率和几何细节恢复能力。为了解决这些局限，作者希望提出一种新方法，实现高分辨率及细粒度的深度估计。

Method: 作者提出了InfiniDepth方法，将深度场用神经隐式场表示，并通过局部隐式解码器设计，能在连续二维坐标上查询深度，实现任意分辨率、高细节的深度预测。同时，作者自建了一个高质量4K合成数据集，以全面评估方法效果。

Result: 实验表明，InfiniDepth在合成和真实世界的基准上都达到了当前最优性能，特别是在细节区域深度估计上表现突出。同时，该方法在大视角变化下的新视角合成任务中也取得更少空洞与伪影的高质量结果。

Conclusion: InfiniDepth突破了传统深度估计的分辨率和细节限制，能实现任意分辨率和高精度的深度预测，有助于提升深度相关任务如新视角合成的质量。

Abstract: Existing depth estimation methods are fundamentally limited to predicting depth on discrete image grids. Such representations restrict their scalability to arbitrary output resolutions and hinder the geometric detail recovery. This paper introduces InfiniDepth, which represents depth as neural implicit fields. Through a simple yet effective local implicit decoder, we can query depth at continuous 2D coordinates, enabling arbitrary-resolution and fine-grained depth estimation. To better assess our method's capabilities, we curate a high-quality 4K synthetic benchmark from five different games, spanning diverse scenes with rich geometric and appearance details. Extensive experiments demonstrate that InfiniDepth achieves state-of-the-art performance on both synthetic and real-world benchmarks across relative and metric depth estimation tasks, particularly excelling in fine-detail regions. It also benefits the task of novel view synthesis under large viewpoint shifts, producing high-quality results with fewer holes and artifacts.

</details>


### [66] [Muses: Designing, Composing, Generating Nonexistent Fantasy 3D Creatures without Training](https://arxiv.org/abs/2601.03256)
*Hexiao Lu,Xiaokun Sun,Zeyu Cai,Hao Guo,Ying Tai,Jian Yang,Zhenyu Zhang*

Main category: cs.CV

TL;DR: Muses是一种无需训练、可前馈生成高质量3D奇幻生物的全新方法，通过骨架驱动的结构化流程，实现了前所未有的多样性与一致性。


<details>
  <summary>Details</summary>
Motivation: 以往的3D生成方法依赖零件优化、手工组合或2D生成，导致资产不真实或不连贯，且跨领域生成能力有限。缺乏灵活结构操作和高质量一体化是主要瓶颈。

Method: Muses利用3D骨架为生物造型的基础，先通过图约束推理生成创意3D骨架，再在结构化潜空间内以骨架为指导进行体素组合，最后结合图像引导条件生成协调统一的纹理，实现端到端的3D生物生成流程。

Result: 实验显示，Muses在视觉真实感以及与文本描述的对齐度方面均达到了当前最佳，并展现了灵活编辑3D对象的潜力。

Conclusion: Muses提出了基于骨架结构的创新3D生成范式，无需训练即可生成高质量、风格一致且易于编辑的奇幻3D生物，为3D内容创作带来显著突破。

Abstract: We present Muses, the first training-free method for fantastic 3D creature generation in a feed-forward paradigm. Previous methods, which rely on part-aware optimization, manual assembly, or 2D image generation, often produce unrealistic or incoherent 3D assets due to the challenges of intricate part-level manipulation and limited out-of-domain generation. In contrast, Muses leverages the 3D skeleton, a fundamental representation of biological forms, to explicitly and rationally compose diverse elements. This skeletal foundation formalizes 3D content creation as a structure-aware pipeline of design, composition, and generation. Muses begins by constructing a creatively composed 3D skeleton with coherent layout and scale through graph-constrained reasoning. This skeleton then guides a voxel-based assembly process within a structured latent space, integrating regions from different objects. Finally, image-guided appearance modeling under skeletal conditions is applied to generate a style-consistent and harmonious texture for the assembled shape. Extensive experiments establish Muses' state-of-the-art performance in terms of visual fidelity and alignment with textual descriptions, and potential on flexible 3D object editing. Project page: https://luhexiao.github.io/Muses.github.io/.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [67] [WearVox: An Egocentric Multichannel Voice Assistant Benchmark for Wearables](https://arxiv.org/abs/2601.02391)
*Zhaojiang Lin,Yong Xu,Kai Sun,Jing Zheng,Yin Huang,Surya Teja Appini,Krish Narang,Renjie Tao,Ishan Kapil Jain,Siddhant Arora,Ruizhi Li,Yiteng Huang,Kaushik Patnaik,Wenfang Xu,Suwon Shon,Yue Liu,Ahmed A Aly,Anuj Kumar,Florian Metze,Xin Luna Dong*

Main category: cs.CL

TL;DR: 该论文提出了WearVox，这是首个专为可穿戴设备（如AI眼镜）中的语音助手真实场景而设计的基准数据集，用于评估和推动语音助手在噪声、快速互动等实际复杂条件下的表现。


<details>
  <summary>Details</summary>
Motivation: 现有针对语音助手的基准多为干净或单一的对话音频，忽视了可穿戴设备普遍遇到的运动、噪声、快速微交互等真实挑战。因此，急需一个能反映实际使用环境复杂性的评测标准，以更准确推动语音助手技术发展。

Method: 作者搭建了WearVox数据集，包含3842条通过AI眼镜采集的多通道音频，涵盖搜索问答、背景对话过滤、工具调用、语音翻译等五类任务，覆盖室内外多种声学环境，并配有详细元数据。对多种主流和开源语音大模型进行了基准测试，并比较了单通道与多通道输入对模型鲁棒性的影响。

Result: 主流实时语音大模型在WearVox上的准确率仅为29%-59%，在噪声户外环境下性能大幅下降。对比发现，多通道音频输入能明显提升模型对环境噪声的鲁棒性及对设备指向性语音的判别能力。

Conclusion: 空间音频信息对实现上下文感知、环境适应型语音助手至关重要。WearVox为可穿戴语音AI研究提供了全方位的测试平台，促进未来语音助手在实际场景中表现的提升。

Abstract: Wearable devices such as AI glasses are transforming voice assistants into always-available, hands-free collaborators that integrate seamlessly with daily life, but they also introduce challenges like egocentric audio affected by motion and noise, rapid micro-interactions, and the need to distinguish device-directed speech from background conversations. Existing benchmarks largely overlook these complexities, focusing instead on clean or generic conversational audio. To bridge this gap, we present WearVox, the first benchmark designed to rigorously evaluate voice assistants in realistic wearable scenarios. WearVox comprises 3,842 multi-channel, egocentric audio recordings collected via AI glasses across five diverse tasks including Search-Grounded QA, Closed-Book QA, Side-Talk Rejection, Tool Calling, and Speech Translation, spanning a wide range of indoor and outdoor environments and acoustic conditions. Each recording is accompanied by rich metadata, enabling nuanced analysis of model performance under real-world constraints. We benchmark leading proprietary and open-source speech Large Language Models (SLLMs) and find that most real-time SLLMs achieve accuracies on WearVox ranging from 29% to 59%, with substantial performance degradation on noisy outdoor audio, underscoring the difficulty and realism of the benchmark. Additionally, we conduct a case study with two new SLLMs that perform inference with single-channel and multi-channel audio, demonstrating that multi-channel audio inputs significantly enhance model robustness to environmental noise and improve discrimination between device-directed and background speech. Our results highlight the critical importance of spatial audio cues for context-aware voice assistants and establish WearVox as a comprehensive testbed for advancing wearable voice AI research.

</details>


### [68] [PCEval: A Benchmark for Evaluating Physical Computing Capabilities of Large Language Models](https://arxiv.org/abs/2601.02404)
*Inpyo Song,Eunji Jeon,Jangwon Lee*

Main category: cs.CL

TL;DR: 本文提出了首个物理计算领域的大型语言模型(LLM)自动评测基准——PCEval，用于系统评估LLMs在硬件相关编程任务中的表现。结果显示，LLMs擅长代码与电路设计，但在物理布局方面还有明显短板。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在软件开发等领域表现突出，但其在涉及硬件约束的物理计算场景下的能力尚未被充分研究。当前缺乏能够自动、全面评价LLMs在物理计算任务中表现的标准化基准。

Method: 作者提出了PCEval评测基准，该系统无须人工干预，能自动测试LLMs在不同复杂度下生成电路与相应可兼容代码的能力，并在仿真环境中验证结果。文中选择了13种主流模型，系统测试其硬件实现的逻辑与物理两方面能力。

Result: 测试结果表明，多数LLMs在生成逻辑代码和电路设计方面表现良好，但在实际面包板物理布局（如针脚连接和避免电路错误）时易出错，说明其对硬件实际操作细节把控不足。

Conclusion: 本文的PCEval基准为理解和提升AI在硬件相关计算场景的协助能力奠定了基础，有助于推动更有效的物理计算教育和辅助工具的开发。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains, including software development, education, and technical assistance. Among these, software development is one of the key areas where LLMs are increasingly adopted. However, when hardware constraints are considered-for instance, in physical computing, where software must interact with and control physical hardware -their effectiveness has not been fully explored. To address this gap, we introduce \textsc{PCEval} (Physical Computing Evaluation), the first benchmark in physical computing that enables a fully automatic evaluation of the capabilities of LLM in both the logical and physical aspects of the projects, without requiring human assessment. Our evaluation framework assesses LLMs in generating circuits and producing compatible code across varying levels of project complexity. Through comprehensive testing of 13 leading models, \textsc{PCEval} provides the first reproducible and automatically validated empirical assessment of LLMs' ability to reason about fundamental hardware implementation constraints within a simulation environment. Our findings reveal that while LLMs perform well in code generation and logical circuit design, they struggle significantly with physical breadboard layout creation, particularly in managing proper pin connections and avoiding circuit errors. \textsc{PCEval} advances our understanding of AI assistance in hardware-dependent computing environments and establishes a foundation for developing more effective tools to support physical computing education.

</details>


### [69] [Losses that Cook: Topological Optimal Transport for Structured Recipe Generation](https://arxiv.org/abs/2601.02531)
*Mattia Ottoborgo,Daniele Rege Cambrin,Paolo Garza*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的组合损失方法，以提升自动生成烹饪食谱的准确性，特别是在配料、步骤、时间与温度等多方面均取得显著进步。


<details>
  <summary>Details</summary>
Motivation: 以往生成食谱的自动化方法主要关注文本流畅性，忽略了食谱对配料、步骤顺序、烹饪时间与温度等实际操作性信息的要求。作者想解决现有方法忽视食谱领域特殊需求的问题。

Method: 在已有RECIPE-NLG框架基础上，作者创新性地引入了多种组合损失，包括一种以点云表示配料并在嵌入空间中最小化预测与标准答案配料差异的拓扑损失函数。同时结合常规与食谱特定评价指标评估性能。

Result: 实验显示，新增的损失函数在配料选择和烹饪动作层面显著提升了生成效果。Dice loss在时间与温度精度方面表现突出，混合损失则在多项指标上取得均衡表现。62%的人工评测更偏好所提出模型。

Conclusion: 多损失组合方法有助于更全面地提升菜谱生成的准确性和可用性，证实了定制化目标函数对专业领域NLG任务的价值。

Abstract: Cooking recipes are complex procedures that require not only a fluent and factual text, but also accurate timing, temperature, and procedural coherence, as well as the correct composition of ingredients. Standard training procedures are primarily based on cross-entropy and focus solely on fluency. Building on RECIPE-NLG, we investigate the use of several composite objectives and present a new topological loss that represents ingredient lists as point clouds in embedding space, minimizing the divergence between predicted and gold ingredients. Using both standard NLG metrics and recipe-specific metrics, we find that our loss significantly improves ingredient- and action-level metrics. Meanwhile, the Dice loss excels in time/temperature precision, and the mixed loss yields competitive trade-offs with synergistic gains in quantity and time. A human preference analysis supports our finding, showing our model is preferred in 62% of the cases.

</details>


### [70] [ModeX: Evaluator-Free Best-of-N Selection for Open-Ended Generation](https://arxiv.org/abs/2601.02535)
*Hyeong Kyu Choi,Sharon Li*

Main category: cs.CL

TL;DR: 提出了一种新的高效选择高质量文本生成结果的方法Mode Extraction（ModeX），可以无需外部评估器或辅助模型，在开放式任务中自动选出多个生成结果中最有代表性的一条。


<details>
  <summary>Details</summary>
Motivation: 在开放式文本生成任务中，很难从多个LLM生成结果中挑出最优解，现有方法普遍依赖外部辅助评估器、奖励模型或严格的投票机制，存在效率和适用性问题。

Method: ModeX通过基于语义相似度将生成内容构建成图，再用谱聚类递归找出语义上最具代表性的中心输出，无需外部模型。进一步提出ModeX-Lite版本，通过提前剪枝提升效率。

Result: 在文本摘要、代码生成和数学推理等任务上，ModeX及其轻量化版本均优于传统的单一路径和多路路径生成基线，同时计算效率较高。

Conclusion: ModeX为开放式文本生成提供了一种无需外部模型的高效、健壮的代表性结果选择方案，性能和效率兼优，推动多生成结果下自动选优发展。

Abstract: Selecting a single high-quality output from multiple stochastic generations remains a fundamental challenge for large language models (LLMs), particularly in open-ended tasks where no canonical answer exists. While Best-of-N and self-consistency methods show that aggregating multiple generations can improve performance, existing approaches typically rely on external evaluators, reward models, or exact string-match voting, limiting their applicability and efficiency. We propose Mode Extraction (ModeX), an evaluator-free Best-of-N selection framework that generalizes majority voting to open-ended text generation by identifying the modal output representing the dominant semantic consensus among generated texts. ModeX constructs a similarity graph over candidate generations and recursively applies spectral clustering to select a representative centroid, without requiring additional inference or auxiliary models. We further instantiate this selection principle as ModeX--Lite, an improved version of ModeX with early pruning for efficiency. Across open-ended tasks--including text summarization, code generation, and mathematical reasoning--our approaches consistently outperform standard single- and multi-path baselines, providing a computationally efficient solution for robust open-ended text generation. Code is released in https://github.com/deeplearning-wisc/ModeX.

</details>


### [71] [LoRA-Drop: Temporal LoRA Decoding for Efficient LLM Inference](https://arxiv.org/abs/2601.02569)
*Hossein Rajabzadeh,Maryam Dialameh,Chul B. Park,Il-Min Kim,Hyock Ju Kwon*

Main category: cs.CL

TL;DR: 该论文提出了一种名为LoRA-Drop的推理加速框架，在不显著损失准确率的前提下，加快大语言模型的自回归解码速度，并降低KV缓存占用。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的解码过程受限于逐步、层层执行的高计算负载。已有层跳过等方案要么需要额外的路由机制，要么跳过层后难以维持准确性。因此，迫切需要无需复杂结构、且能兼顾效率和准确性的简单加速方法。

Method: 作者设计了LoRA-Drop：在大多数解码步只对部分中间层复用前一时刻隐藏状态并加上低秩LoRA修正，偶尔执行全模型的“刷新”步来修正漂移。该方法无需路由网络并支持标准KV缓存，对跳过层时可省略KV更新，从而降低缓存开销。通过不同步调实验证明其兼容主流模型和缓存机制。

Result: 在LLaMA2-7B、LLaMA3-8B、Qwen2.5-7B和Qwen2.5-14B等模型上，LoRA-Drop可实现最高2.6倍解码提速，KV缓存减少45-55%，且准确率损失不超过0.5百分点。在多种推理、代码、长上下文和多语言任务上都找到一批能兼顾质量和效率的“安全区间”配置。

Conclusion: LoRA-Drop是一种无需复杂路由、更易落地的大语言模型推理效率提升方案，可在保证模型质量的前提下大幅改善速度和存储，是推进大模型自适应计算能力有效路径。代码已开源。

Abstract: Autoregressive large language models (LLMs) are bottlenecked by sequential decoding, where each new token typically requires executing all transformer layers. Existing dynamic-depth and layer-skipping methods reduce this cost, but often rely on auxiliary routing mechanisms or incur accuracy degradation when bypassed layers are left uncompensated. We present \textbf{LoRA-Drop}, a plug-and-play inference framework that accelerates decoding by applying a \emph{temporal compute schedule} to a fixed subset of intermediate layers: on most decoding steps, selected layers reuse the previous-token hidden state and apply a low-rank LoRA correction, while periodic \emph{refresh} steps execute the full model to prevent drift. LoRA-Drop requires no routing network, is compatible with standard KV caching, and can reduce KV-cache footprint by skipping KV updates in droppable layers during LoRA steps and refreshing periodically. Across \textbf{LLaMA2-7B}, \textbf{LLaMA3-8B}, \textbf{Qwen2.5-7B}, and \textbf{Qwen2.5-14B}, LoRA-Drop achieves up to \textbf{2.6$\times$ faster decoding} and \textbf{45--55\% KV-cache reduction} while staying within \textbf{0.5 percentage points (pp)} of baseline accuracy. Evaluations on reasoning (GSM8K, MATH, BBH), code generation (HumanEval, MBPP), and long-context/multilingual benchmarks (LongBench, XNLI, XCOPA) identify a consistent \emph{safe zone} of scheduling configurations that preserves quality while delivering substantial efficiency gains, providing a simple path toward adaptive-capacity inference in LLMs. Codes are available at https://github.com/hosseinbv/LoRA-Drop.git.

</details>


### [72] [Fact-Checking with Large Language Models via Probabilistic Certainty and Consistency](https://arxiv.org/abs/2601.02574)
*Haoran Wang,Maryam Khalid,Qiong Wu,Jian Gao,Cheng Cao*

Main category: cs.CL

TL;DR: 本文提出PCC框架，通过结合大语言模型的概率置信度和推理一致性，实现针对事实性回答的自适应验证。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在需要事实准确的应用中常出现幻觉问题。现有事实核查方法无差别地检索外部证据，未充分利用模型内部知识，且检索机制造成噪音过多，缺乏应对具体不确定性的针对性机制。

Method: 提出了Probabilistic Certainty and Consistency（PCC）框架，通过联合建模概率置信度和推理一致性，来评估LLM对某个事实的自信程度。当模型自信时直接作答，存在不确定或不一致时启动有针对性的检索，高度模糊时进一步深度搜索。

Result: 大量实验显示，PCC比口头置信度表述方法拥有更好的不确定性量化效果，并在多个基准上优于强力LLM事实核查基线。同时，PCC在多种LLM上表现出良好的泛化能力。

Conclusion: PCC通过置信度引导的路由机制，实现了高效且可靠的事实核查，只在必要时调用外部检索，有效提升了LLM的事实准确性和核查效率。

Abstract: Large language models (LLMs) are increasingly used in applications requiring factual accuracy, yet their outputs often contain hallucinated responses. While fact-checking can mitigate these errors, existing methods typically retrieve external evidence indiscriminately, overlooking the model's internal knowledge and potentially introducing irrelevant noise. Moreover, current systems lack targeted mechanisms to resolve specific uncertainties in the model's reasoning. Inspired by how humans fact-check, we argue that LLMs should adaptively decide whether to rely on internal knowledge or initiate retrieval based on their confidence in a given claim. We introduce Probabilistic Certainty and Consistency (PCC), a framework that estimates factual confidence by jointly modeling an LLM's probabilistic certainty and reasoning consistency. These confidence signals enable an adaptive verification strategy: the model answers directly when confident, triggers targeted retrieval when uncertain or inconsistent, and escalates to deep search when ambiguity is high. Our confidence-guided routing mechanism ensures that retrieval is invoked only when necessary, improving both efficiency and reliability. Extensive experiments across three challenging benchmarks show that PCC achieves better uncertainty quantification than verbalized confidence and consistently outperforms strong LLM-based fact-checking baselines. Furthermore, we demonstrate that PCC generalizes well across various LLMs.

</details>


### [73] [DataParasite Enables Scalable and Repurposable Online Data Curation](https://arxiv.org/abs/2601.02578)
*Mengyi Sun*

Main category: cs.CL

TL;DR: 本文介绍了一个名为DataParasite的开源、模块化数据收集工具，能够高效、灵活地自动从网络获取结构化社会科学数据。实验表明，该工具准确率高，成本远低于人工整理。


<details>
  <summary>Details</summary>
Motivation: 当前计算社会科学研究常依赖于从不同在线渠道收集数据，这一过程通常费时、费力且难以复现。现有自动化方法不够透明、灵活性差，对科研数据整理不太合适。

Method: 提出DataParasite工具，将表格化的数据整理任务分解为独立实体级搜索，轻松配置即可适用多任务，利用自然语言指令适应各种场景。通过通用Python脚本执行实体搜索与数据抽取。

Result: 在多个经典社会科学数据整理任务中，如教师聘用历史、精英死亡事件、政治生涯路线等，DataParasite表现出高准确率，并且数据采集成本较人工大幅下降。

Conclusion: DataParasite极大降低了大规模网络数据收集的技术与人力门槛，为计算社会科学等领域提供了可扩展、透明和可复用的数据整理平台。

Abstract: Many questions in computational social science rely on datasets assembled from heterogeneous online sources, a process that is often labor-intensive, costly, and difficult to reproduce. Recent advances in large language models enable agentic search and structured extraction from the web, but existing systems are frequently opaque, inflexible, or poorly suited to scientific data curation. Here we introduce DataParasite, an open-source, modular pipeline for scalable online data collection. DataParasite decomposes tabular curation tasks into independent, entity-level searches defined through lightweight configuration files and executed through a shared, task-agnostic python script. Crucially, the same pipeline can be repurposed to new tasks, including those without predefined entity lists, using only natural-language instructions. We evaluate the pipeline on multiple canonical tasks in computational social science, including faculty hiring histories, elite death events, and political career trajectories. Across tasks, DataParasite achieves high accuracy while reducing data-collection costs by an order of magnitude relative to manual curation. By lowering the technical and labor barriers to online data assembly, DataParasite provides a practical foundation for scalable, transparent, and reusable data curation in computational social science and beyond.

</details>


### [74] [Reconstructing Item Characteristic Curves using Fine-Tuned Large Language Models](https://arxiv.org/abs/2601.02580)
*Christopher Ormerod*

Main category: cs.CL

TL;DR: 本文提出用大型语言模型（LLM）模拟不同能力水平学生的答题情况，直接估算题目难度和区分度等参数，无需依赖昂贵的实地测试数据。


<details>
  <summary>Details</summary>
Motivation: 传统题目参数标定方法依赖大规模实地测试数据，成本高、效率低，因此亟需更高效、可扩展的自动化方案。

Method: 本文利用Qwen-3系列模型结合低秩适配（LoRA）技术，微调LLM，使其能基于设定的能力水平生成多项选择题的模拟答案，从而间接还原出学生答对题目的概率曲线（ICC），据此估算IRT中的题目参数。

Result: 在六年级英语和BEA 2024数据集上验证该方法，效果与传统方法持平甚至超越，尤其在区分度建模方面表现突出。

Conclusion: 基于LLM模拟的题目参数估算方法高效准确，为题目自动化分析和标定提供了新思路，有望减少实地测试的依赖。

Abstract: Traditional methods for determining assessment item parameters, such as difficulty and discrimination, rely heavily on expensive field testing to collect student performance data for Item Response Theory (IRT) calibration. This study introduces a novel approach that implicitly models these psychometric properties by fine-tuning Large Language Models (LLMs) to simulate student responses across a spectrum of latent abilities. Leveraging the Qwen-3 dense model series and Low-Rank Adaptation (LoRA), we train models to generate responses to multiple choice questions conditioned on discrete ability descriptors. We reconstruct the probability of a correct response as a function of student ability, effectively generating synthetic Item Characteristic Curves (ICCs) to estimate IRT parameters. Evaluation on a dataset of Grade 6 English Language Arts (ELA) items and the BEA 2024 Shared Task dataset demonstrates that this method competes with or outperforms baseline approaches. This simulation-based technique seems particularly effective at modeling item discrimination.

</details>


### [75] [FlowPlan-G2P: A Structured Generation Framework for Transforming Scientific Papers into Patent Descriptions](https://arxiv.org/abs/2601.02589)
*Kris W Pan,Yongmin Yoo*

Main category: cs.CL

TL;DR: 本文提出了一种新方法，通过结构化流程将科学论文自动转化为符合法律要求的专利说明书，显著优于现有的黑盒式文本生成方法。


<details>
  <summary>Details</summary>
Motivation: 当前每年专利申请数量巨大，而撰写合格的专利说明书要求深厚的技术和法律知识。科学论文与专利文本在写作风格和法律约束上存在较大差异，自动将论文转化为专利说明对智能生成系统提出了更高的结构化与合规性挑战。

Method: 提出了FlowPlan-G2P框架，将任务分为三步：1）通过类专家的推理过程，将技术内容抽取为有向概念图；2）对概念图进行段落和章节规划，重组成与常规专利章节对应的结构；3）基于局部子图和定制提示词，生成符合法律规则的文本段落。该方法模拟了人类专家的工作流程。

Result: 实验表明，该方法在逻辑结构和法律合规性方面都明显优于传统的端到端大模型生成方法。

Conclusion: FlowPlan-G2P为论文自动转化为专利开启了新范式，为专业领域的结构化文本生成带来了重大进步。

Abstract: Over 3.5 million patents are filed annually, with drafting patent descriptions requiring deep technical and legal expertise. Transforming scientific papers into patent descriptions is particularly challenging due to their differing rhetorical styles and stringent legal requirements. Unlike black-box text-to-text approaches that struggle to model structural reasoning and legal constraints, we propose FlowPlan-G2P, a novel framework that mirrors the cognitive workflow of expert drafters by reformulating this task into three stages: (1) Concept Graph Induction, extracting technical entities and relationships into a directed graph via expert-like reasoning; (2) Paragraph and Section Planning, reorganizing the graph into coherent clusters aligned with canonical patent sections; and (3) Graph-Conditioned Generation, producing legally compliant paragraphs using section-specific subgraphs and tailored prompts. Experiments demonstrate that FlowPlan-G2P significantly improves logical coherence and legal compliance over end-to-end LLM baselines. Our framework establishes a new paradigm for paper-to-patent generation and advances structured text generation for specialized domains.

</details>


### [76] [Scalable Construction of a Lung Cancer Knowledge Base: Profiling Semantic Reasoning in LLMs](https://arxiv.org/abs/2601.02604)
*Cesar Felipe Martínez Cisneros,Jesús Ulises Quiroz Bautista,Claudia Anahí Guzmán Solano,Bogdan Kaleb García Rivera,Iván García Pacheco,Yalbi Itzel Balderas Martínez,Kolawole John Adebayoc,Ignacio Arroyo Fernández*

Main category: cs.CL

TL;DR: 本研究提出了一种利用OpenIE自动构建肺癌知识库的方法，为大语言模型在肿瘤学中的微调提供高质量、领域特定的知识数据。结果显示，用此知识库微调后的模型在语义表现和文本生成质量上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 在肿瘤学领域，模型的精确性和可解释性至关重要。而现有大语言模型的效果很大程度取决于训练数据的语义质量。需要可扩展的方式构建结构化知识库，以提升模型微调效果。

Method: 流程包括：1）用MeSH词表识别医学概念；2）过滤获取开放授权的PubMed文献（CC0）；3）用OpenIE方法抽取（主体-关系-客体）三元组；4）用实体识别技术增加三元组的生物医学相关性。最后构建专用于领域内模型微调的大规模、高质量三元组知识集。

Result: 用该知识库对T5等模型进行有监督的语义微调，通过ROUGE和BERTScore等指标进行比较评估，发现模型的语义连贯性和整体性能均有显著提升。

Conclusion: 利用OpenIE派生的知识集可以作为一种可扩展、低成本的解决方案，有效提升生物医学NLP任务中的大语言模型能力。

Abstract: The integration of Large Language Models (LLMs) into biomedical research offers new opportunities for domainspecific reasoning and knowledge representation. However, their performance depends heavily on the semantic quality of training data. In oncology, where precision and interpretability are vital, scalable methods for constructing structured knowledge bases are essential for effective fine-tuning. This study presents a pipeline for developing a lung cancer knowledge base using Open Information Extraction (OpenIE). The process includes: (1) identifying medical concepts with the MeSH thesaurus; (2) filtering open-access PubMed literature with permissive licenses (CC0); (3) extracting (subject, relation, object) triplets using OpenIE method; and (4) enriching triplet sets with Named Entity Recognition (NER) to ensure biomedical relevance. The resulting triplet sets provide a domain-specific, large-scale, and noise-aware resource for fine-tuning LLMs. We evaluated T5 models finetuned on this dataset through Supervised Semantic Fine-Tuning. Comparative assessments with ROUGE and BERTScore show significantly improved performance and semantic coherence, demonstrating the potential of OpenIE-derived resources as scalable, low-cost solutions for enhancing biomedical NLP.

</details>


### [77] [Improved Evidence Extraction for Document Inconsistency Detection with LLMs](https://arxiv.org/abs/2601.02627)
*Nelvin Tan,Yaowen Zhang,James Asikin Cheung,Fusheng Liu,Yu-Ching Shih,Dong Yang*

Main category: cs.CL

TL;DR: 本文提出了一种改进大语言模型（LLM）进行文档不一致性检测的方法，重点是提取不一致的证据，并引入了新的评估指标和过滤机制，显著优于直接提示方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型表现优异，但在文档不一致性检测领域的研究还很有限，尤其是在检测证据层面。作者希望提升LLM在实际检测文档内部不一致性的能力，并给出具体证据支持。

Method: 作者针对文档不一致性检测，提出了新颖的证据提取指标以及“修订与重试”框架，该框架通过约束性过滤策略提升检测准确性，而不是仅依赖直接提示问答。

Result: 实验证明，所提出的方法在证据提取和不一致检测方面均取得了优越的性能，优于传统直接提示法。

Conclusion: 结合新的评测标准和过滤机制，显著提升了LLM检测文档不一致性及提取相关证据的实用性和可靠性。

Abstract: Large language models (LLMs) are becoming useful in many domains due to their impressive abilities that arise from large training datasets and large model sizes. However, research on LLM-based approaches to document inconsistency detection is relatively limited. There are two key aspects of document inconsistency detection: (i) classification of whether there exists any inconsistency, and (ii) providing evidence of the inconsistent sentences. We focus on the latter, and introduce new comprehensive evidence-extraction metrics and a redact-and-retry framework with constrained filtering that substantially improves LLM-based document inconsistency detection over direct prompting. We back our claims with promising experimental results.

</details>


### [78] [Empirical Comparison of Encoder-Based Language Models and Feature-Based Supervised Machine Learning Approaches to Automated Scoring of Long Essays](https://arxiv.org/abs/2601.02659)
*Kuo Wang,Haowei Hua,Pengfei Yan,Hong Jiao,Dan Song*

Main category: cs.CL

TL;DR: 本研究比较了多种encoder-only语言模型及其集成方法在长篇作文自动评分任务中的表现，发现集成多个预训练语言模型嵌入，并结合梯度提升分类器的模型效果最佳。


<details>
  <summary>Details</summary>
Motivation: 当前主流的encoder-only模型（如BERT）在处理长文本时存在token长度限制，影响长篇文本（如作文）自动评分的准确性。研究动机是探索突破token限制、提升长文本自动评分性能的有效方法。

Method: 研究训练了多种基于BERT系列的模型（BERT, RoBERTa, DistilBERT, DeBERTa），并构建了集成模型，包括基于多模型嵌入的集成和基于特征的集成（GBDT, XGBoost, LightGBM）。使用包含17,307篇作文的数据集，按8:1:1比例切分数据进行训练、验证和测试，采用Quadratic Weighted Kappa评估性能。

Result: 多模型嵌入+梯度提升分类器的集成模型，在长篇作文自动评分任务上，显著优于单一语言模型。

Conclusion: 针对长文本自动评分任务，将多个预训练语言模型的嵌入与梯度提升分类器结合组成的集成方法，在处理长文本时能显著提升评分效果，优于单一模型方案。

Abstract: Long context may impose challenges for encoder-only language models in text processing, specifically for automated scoring of essays. This study trained several commonly used encoder-based language models for automated scoring of long essays. The performance of these trained models was evaluated and compared with the ensemble models built upon the base language models with a token limit of 512?. The experimented models include BERT-based models (BERT, RoBERTa, DistilBERT, and DeBERTa), ensemble models integrating embeddings from multiple encoder models, and ensemble models of feature-based supervised machine learning models, including Gradient-Boosted Decision Trees, eXtreme Gradient Boosting, and Light Gradient Boosting Machine. We trained, validated, and tested each model on a dataset of 17,307 essays, with an 80%/10%/10% split, and evaluated model performance using Quadratic Weighted Kappa. This study revealed that an ensemble-of-embeddings model that combines multiple pre-trained language model representations with gradient-boosting classifier as the ensemble model significantly outperforms individual language models at scoring long essays.

</details>


### [79] [When Do Tools and Planning Help LLMs Think? A Cost- and Latency-Aware Benchmark](https://arxiv.org/abs/2601.02663)
*Subha Ghoshal,Ali Al-Bustami*

Main category: cs.CL

TL;DR: 本文评估了在实际任务中，结合计划与外部工具的LLM工具型智能体的推理表现、成本与延迟，为今后模型和工具选择提供参考。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）在复杂推理任务中越来越依赖于推理时的计划和外部工具，但这类组合方法在现实应用中的效果、成本与瓶颈尚缺乏系统性评价和对比。论文旨在填补该空白。

Method: 在两个真实任务——面向事件的知识图问答（Event-QA）和Reddit换个角度说服回复（CMV）——上，作者采用LangChain与LangGraph，分别比较了单步推理（one-shot）与“计划-执行-重规划”代理（结合特定工具如DBpedia SPARQL、维基百科检索和网络搜索）。测试GPT-4o及迷你版，共采集60个样本（3组），衡量准确率、端到端延迟与token成本。

Result: 在Event-QA任务中，工具增强型智能体配置可显著提升准确率（如GPT-4o从47.5%提升至67.5%），但会带来数十倍的时间延迟（约8秒增至317秒/例）。在CMV任务上，单步推理反而更优（如GPT-4o-mini达75%准确率，延迟约6秒），多工具智能体延迟明显增加但未必带来准确率提升。模型较小情况下，多工具协作出现更多失效模式和性能下降。

Conclusion: 选择更复杂智能体结构和多工具未必总有益，需结合具体任务与成本、模型规模权衡权衡，有针对性地选用适当的模型和工具方案，避免一味求“大”或“全能”增加开销。

Abstract: Modern large language models (LLMs) increasingly rely on inference-time planning and external tools to improve reasoning. We benchmark this behavior on two real-world settings: event-centric question answering over graph-structured knowledge (Event-QA) and persuasive response generation in Reddit ChangeMyView (CMV). Using LangChain and LangGraph, we compare a one-shot baseline against a plan--execute--replan agent equipped with task-specific tools (DBpedia SPARQL/lookup/schema exploration, Wikipedia-focused retrieval, and topical web search). We evaluate on 60 examples each from Event-QA and CMV (3 splits of 20), and report both mean end-to-end latency and per-example token cost estimates. We evaluate GPT-4o and GPT-4o-mini under identical workflows and report accuracy and end-to-end latency. On Event-QA, the best tool-augmented configuration improves accuracy (e.g., 47.5\% $\rightarrow$ 67.5\% for GPT-4o) while increasing latency by orders of magnitude ($\sim$8s $\rightarrow$ $\sim$317s per example). On CMV, one-shot prompting is strongest (e.g., GPT-4o-mini achieves 75\% at $\sim$6s), and planning+search increases latency substantially without consistent gains. However, complex multi-tool orchestration exposes failure modes where the smaller model degrades. Overall, the findings highlight the need for task-specific, cost-aware choices of both model size and agent/tooling complexity.

</details>


### [80] [Towards Comprehensive Stage-wise Benchmarking of Large Language Models in Fact-Checking](https://arxiv.org/abs/2601.02669)
*Hongzhan Lin,Zixin Chen,Zhiqi Shen,Ziyang Luo,Zhen Ye,Jing Ma,Tat-Seng Chua,Guandong Xu*

Main category: cs.CL

TL;DR: 本文提出了FactArena，一个用于LLM事实核查全流程的全自动评测框架，涵盖声明提取、证据检索和结果判断，实现更全面的模型评估。


<details>
  <summary>Details</summary>
Motivation: 现有LLM事实核查评测主要集中在声明验证环节，忽视了完整事实核查流程中的其他关键步骤，如声明抽取和证据检索，导致无法发现系统性推理失误和模型弱点。作者旨在提出整体性评估框架，弥补这一缺陷。

Method: FactArena框架包含三个关键部分：1）基于LLM驱动的事实核查流程，包括统一的声明分解、工具辅助的证据检索与基于理由的预测；2）基于参考标准的“擂台赛”式判决机制，实现对不同模型的公平、无偏对比；3）声明进化模块，自动生成更具挑战性和语义可控的声明，用于测试模型的事实鲁棒性。

Result: FactArena对16种最先进的LLM进行了系统测试，能够稳定给出清晰可解释的模型排名。结果显示，单纯的声明验证准确率与端到端事实核查能力之间存在很大差异，证明了全流程综合评测的必要性。

Conclusion: FactArena为评估和比较LLM在事实核查任务中的表现提供了可扩展、可信的标准方法，有助于发现模型的推理短板，并为后续模型开发和安全关键场合下的部署提供参考。

Abstract: Large Language Models (LLMs) are increasingly deployed in real-world fact-checking systems, yet existing evaluations focus predominantly on claim verification and overlook the broader fact-checking workflow, including claim extraction and evidence retrieval. This narrow focus prevents current benchmarks from revealing systematic reasoning failures, factual blind spots, and robustness limitations of modern LLMs. To bridge this gap, we present FactArena, a fully automated arena-style evaluation framework that conducts comprehensive, stage-wise benchmarking of LLMs across the complete fact-checking pipeline. FactArena integrates three key components: (i) an LLM-driven fact-checking process that standardizes claim decomposition, evidence retrieval via tool-augmented interactions, and justification-based verdict prediction; (ii) an arena-styled judgment mechanism guided by consolidated reference guidelines to ensure unbiased and consistent pairwise comparisons across heterogeneous judge agents; and (iii) an arena-driven claim-evolution module that adaptively generates more challenging and semantically controlled claims to probe LLMs' factual robustness beyond fixed seed data. Across 16 state-of-the-art LLMs spanning seven model families, FactArena produces stable and interpretable rankings. Our analyses further reveal significant discrepancies between static claim-verification accuracy and end-to-end fact-checking competence, highlighting the necessity of holistic evaluation. The proposed framework offers a scalable and trustworthy paradigm for diagnosing LLMs' factual reasoning, guiding future model development, and advancing the reliable deployment of LLMs in safety-critical fact-checking applications.

</details>


### [81] [Multi-Turn Jailbreaking of Aligned LLMs via Lexical Anchor Tree Search](https://arxiv.org/abs/2601.02670)
*Devang Kulshreshtha,Hang Su,Chinmay Hegde,Haohan Wang*

Main category: cs.CL

TL;DR: 本文提出了一种无需攻击者LLM的高效越狱方法LATS，在攻击成功率相当高的前提下显著降低了查询次数和成本。


<details>
  <summary>Details</summary>
Motivation: 现有的越狱攻击虽然成功率高，但常常需要攻击者LLM生成对抗查询或高频访问目标模型，导致成本高昂且生成的查询难以解释。近年来对高效、可复现的低成本越狱工具的需求增长。

Method: 提出Lexical Anchor Tree Search (LATS)方法，不依赖攻击者LLM，而是通过词汇锚点注入（lexical anchor injection），将越狱过程重新建模为多轮对话下的广度优先树搜索，每一步逐渐将攻击目标词汇嵌入看似正常的提示词中。

Result: 在AdvBench和HarmBench测试上，LATS在最新的GPT、Claude和Llama等模型上能以平均约6.4次查询达到97-100%的攻击成功率，而传统方法往往需要20次以上。

Conclusion: LATS展现了会话结构本身也是一个容易被攻击且未被充分保护的面向，用更高查询效率推动了越狱研究，表明在高ASR易得的背景下，应关注越狱攻击的资源消耗问题。

Abstract: Most jailbreak methods achieve high attack success rates (ASR) but require attacker LLMs to craft adversarial queries and/or demand high query budgets. These resource limitations make jailbreaking expensive, and the queries generated by attacker LLMs often consist of non-interpretable random prefixes. This paper introduces Lexical Anchor Tree Search (), addressing these limitations through an attacker-LLM-free method that operates purely via lexical anchor injection. LATS reformulates jailbreaking as a breadth-first tree search over multi-turn dialogues, where each node incrementally injects missing content words from the attack goal into benign prompts. Evaluations on AdvBench and HarmBench demonstrate that LATS achieves 97-100% ASR on latest GPT, Claude, and Llama models with an average of only ~6.4 queries, compared to 20+ queries required by other methods. These results highlight conversational structure as a potent and under-protected attack surface, while demonstrating superior query efficiency in an era where high ASR is readily achievable. Our code will be released to support reproducibility.

</details>


### [82] [Extracting books from production language models](https://arxiv.org/abs/2601.02671)
*Ahmed Ahmed,A. Feder Cooper,Sanmi Koyejo,Percy Liang*

Main category: cs.CL

TL;DR: 本文探讨了在商用大语言模型（LLM, 如Claude 3.7 Sonnet、GPT-4.1、Gemini 2.5 Pro和Grok 3）上，能否从中提取受版权保护训练数据的问题。结果显示，尽管采取了安全防护措施，不同模型仍然存在被提取大段训练数据的风险。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在各行业落地，越来越多关注其训练过程中对受版权保护数据的记忆与复制，尤其关乎法律合规。此前多数人认为主流LLM不会直接记忆和输出训练语料，但近期研究表明实则存在相关风险。

Method: 作者提出两阶段流程：（1）初步探测提取可行性（必要时用BoN越狱），（2）用续写提示多轮尝试提取整本书。随后，在上述四个商用模型上进行系统性实验，通过基于块的最长公共子串得分（nv-recall）评估数据提取效果。

Result: 不同模型表现不同：Gemini 2.5 Pro和Grok 3无需越狱即可提取大量内容（如Harry Potter nv-recall高达76.8%和70.3%），而Claude 3.7 Sonnet和GPT-4.1则需要越狱，且Claude可几乎完整输出整本书（nv-recall=95.8%），GPT-4.1越狱尝试频次高但最终提取有限（nv-recall=4.0%）。

Conclusion: 即便在实际部署模型和系统级别引入了多重安全保护措施，训练数据特别是受版权保护的数据泄露风险依然存在，这对LLM合规和数据安全提出严峻挑战。

Abstract: Many unresolved legal questions over LLMs and copyright center on memorization: whether specific training data have been encoded in the model's weights during training, and whether those memorized data can be extracted in the model's outputs. While many believe that LLMs do not memorize much of their training data, recent work shows that substantial amounts of copyrighted text can be extracted from open-weight models. However, it remains an open question if similar extraction is feasible for production LLMs, given the safety measures these systems implement. We investigate this question using a two-phase procedure: (1) an initial probe to test for extraction feasibility, which sometimes uses a Best-of-N (BoN) jailbreak, followed by (2) iterative continuation prompts to attempt to extract the book. We evaluate our procedure on four production LLMs -- Claude 3.7 Sonnet, GPT-4.1, Gemini 2.5 Pro, and Grok 3 -- and we measure extraction success with a score computed from a block-based approximation of longest common substring (nv-recall). With different per-LLM experimental configurations, we were able to extract varying amounts of text. For the Phase 1 probe, it was unnecessary to jailbreak Gemini 2.5 Pro and Grok 3 to extract text (e.g, nv-recall of 76.8% and 70.3%, respectively, for Harry Potter and the Sorcerer's Stone), while it was necessary for Claude 3.7 Sonnet and GPT-4.1. In some cases, jailbroken Claude 3.7 Sonnet outputs entire books near-verbatim (e.g., nv-recall=95.8%). GPT-4.1 requires significantly more BoN attempts (e.g., 20X), and eventually refuses to continue (e.g., nv-recall=4.0%). Taken together, our work highlights that, even with model- and system-level safeguards, extraction of (in-copyright) training data remains a risk for production LLMs.

</details>


### [83] [Iterative Structured Pruning for Large Language Models with Multi-Domain Calibration](https://arxiv.org/abs/2601.02674)
*Guangxin Wu,Hao Zhang,Zhang Zhibin,Jiafeng Guo,Xueqi Cheng*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的结构化剪枝方法，通过结合多领域校准集和迭代式校准，有效压缩大语言模型（LLM），显著减少资源消耗且基本不损失性能。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型体积庞大，导致推理计算、内存和延迟成本高，阻碍了实际部署。虽然非结构化剪枝能压缩模型，但其产生的不规则稀疏结构依赖特殊硬件，实际应用受限，因此需要更高效、兼容性好的剪枝方案。

Method: 作者提出结构化剪枝框架，设计了混合多领域校准集和迭代校准策略，能够系统地识别和去除多余的通道，同时保证模型在主流硬件上的运行兼容性。

Result: 通过大量实验，验证了该方法在多种下游任务和不同模型上都能大幅降低模型体积和计算资源消耗，同时性能损失极小。

Conclusion: 所提结构化剪枝框架为大语言模型高效部署提供了可行途径，在保持标准硬件兼容性的同时，显著提升资源效率，具有广泛应用潜力。

Abstract: Large Language Models (LLMs) have achieved remarkable success across a wide spectrum of natural language processing tasks. However, their ever-growing scale introduces significant barriers to real-world deployment, including substantial computational overhead, memory footprint, and inference latency. While model pruning presents a viable solution to these challenges, existing unstructured pruning techniques often yield irregular sparsity patterns that necessitate specialized hardware or software support. In this work, we explore structured pruning, which eliminates entire architectural components and maintains compatibility with standard hardware accelerators. We introduce a novel structured pruning framework that leverages a hybrid multi-domain calibration set and an iterative calibration strategy to effectively identify and remove redundant channels. Extensive experiments on various models across diverse downstream tasks show that our approach achieves significant compression with minimal performance degradation.

</details>


### [84] [EvoRoute: Experience-Driven Self-Routing LLM Agent Systems](https://arxiv.org/abs/2601.02695)
*Guibin Zhang,Haiyang Yu,Kaiming Yang,Bingli Wu,Fei Huang,Yongbin Li,Shuicheng Yan*

Main category: cs.CL

TL;DR: 本文发现由多种大型语言模型（LLMs）、工具与记忆模块协同驱动的复杂AI代理系统虽然能力强大，但存在性能、成本和延迟之间难以兼顾的问题。针对这一'三难困境'，作者提出了自进化模型路由系统EvoRoute，在维持甚至提升性能的前提下，显著降低了费用和延迟。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理系统要兼顾最佳性能、最低成本和最快响应，三者很难同时优化，尚缺乏能动态权衡多目标的有效方法。作者希望解决这一理论与实践上的‘三难困境’。

Method: 提出了一种自进化模型路由框架EvoRoute。系统会利用历史经验，动态在每一步按帕累托最优选择不同LLM引擎，并根据环境反馈不断优化自己的模型选择策略。

Result: 在GAIA和BrowseComp+等复杂基准上实验证实，EvoRoute集成入现有代理系统后，不仅保证甚至提升总体性能，执行成本最多下降80%，延迟减少70%以上。

Conclusion: EvoRoute为AI代理系统突破性能—成本—延迟三难困境提供了有效路径，其动态、自优化的路由范式有望广泛应用于复杂、多轮AI任务。

Abstract: Complex agentic AI systems, powered by a coordinated ensemble of Large Language Models (LLMs), tool and memory modules, have demonstrated remarkable capabilities on intricate, multi-turn tasks. However, this success is shadowed by prohibitive economic costs and severe latency, exposing a critical, yet underexplored, trade-off. We formalize this challenge as the \textbf{Agent System Trilemma}: the inherent tension among achieving state-of-the-art performance, minimizing monetary cost, and ensuring rapid task completion. To dismantle this trilemma, we introduce EvoRoute, a self-evolving model routing paradigm that transcends static, pre-defined model assignments. Leveraging an ever-expanding knowledge base of prior experience, EvoRoute dynamically selects Pareto-optimal LLM backbones at each step, balancing accuracy, efficiency, and resource use, while continually refining its own selection policy through environment feedback. Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\%$ and latency by over $70\%$.

</details>


### [85] [Boosting Accuracy and Interpretability in Multilingual Hate Speech Detection Through Layer Freezing and Explainable AI](https://arxiv.org/abs/2601.02697)
*Meysam Shirdel Bilehsavar,Negin Mahmoudi,Mohammad Jalili Torkamani,Kiana Kiashemshaki*

Main category: cs.CL

TL;DR: 本文比较了三种Transformer模型在五种语言上的情感分析与仇恨言论检测表现，同时结合了解释性方法提升模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 情感分析与仇恨言论检测对于净化网络环境、保护用户安全至关重要，但多语言环境和模型解释性亟需提升。本文旨在提升多语言下任务的检测效果，并改善模型透明度，便于理解其预测行为。

Method: 选用BERT-base-multilingual-cased、RoBERTa-base和XLM-RoBERTa-base（三者前八层参数冻结），针对英语、韩语、日语、中文和法语进行实验。运用准确率、精确率、召回率和F1分数评估模型表现，并结合LIME方法分析单词对模型预测的贡献，以增强模型解释性。

Result: 三种Transformer模型在五种语言上的情感分析和仇恨言论检测均有系统对比，并通过LIME展示了模型决策的关键用词贡献。各模型的具体表现通过标准评估指标量化。

Conclusion: 结合LIME增强Transformer模型的可解释性和性能评测，提高了多语言情感分析与仇恨言论检测系统的有效性与透明度，为网络内容治理提供了更优模型参考。

Abstract: Sentiment analysis focuses on identifying the emotional polarity expressed in textual data, typically categorized as positive, negative, or neutral. Hate speech detection, on the other hand, aims to recognize content that incites violence, discrimination, or hostility toward individuals or groups based on attributes such as race, gender, sexual orientation, or religion. Both tasks play a critical role in online content moderation by enabling the detection and mitigation of harmful or offensive material, thereby contributing to safer digital environments. In this study, we examine the performance of three transformer-based models: BERT-base-multilingual-cased, RoBERTa-base, and XLM-RoBERTa-base with the first eight layers frozen, for multilingual sentiment analysis and hate speech detection. The evaluation is conducted across five languages: English, Korean, Japanese, Chinese, and French. The models are compared using standard performance metrics, including accuracy, precision, recall, and F1-score. To enhance model interpretability and provide deeper insight into prediction behavior, we integrate the Local Interpretable Model-agnostic Explanations (LIME) framework, which highlights the contribution of individual words to the models decisions. By combining state-of-the-art transformer architectures with explainability techniques, this work aims to improve both the effectiveness and transparency of multilingual sentiment analysis and hate speech detection systems.

</details>


### [86] [Adversarial Question Answering Robustness: A Multi-Level Error Analysis and Mitigation Study](https://arxiv.org/abs/2601.02700)
*Agniv Roy Choudhury,Vignesh Ponselvan Rajasingh*

Main category: cs.CL

TL;DR: 本论文研究了Transformer问答系统在AddSent对抗数据集上的鲁棒性，通过模型尺度、数据增强及有针对性的策略来提高系统抗干扰能力。采用多层次、五种分法的错误分析确定主要失败点，通过对抗性微调、数据增强和特定对抗训练，有效缩小了干净数据与对抗数据上的性能差距。


<details>
  <summary>Details</summary>
Motivation: 虽然现代问答系统在标准测试集上表现优异，但面对对抗样本时仍然容易出错，尤其对于否定句和实体替换等语言现象表现脆弱。因此，需要系统性分析和针对性改进，提高其在复杂语言条件下的鲁棒性。

Method: 1) 在AddSent对抗数据集上，对不同规模的ELECTRA模型进行系统实验；2) 采用五种互补的错误类别方案进行多层次错误分析，定位主要失败模式；3) 分析不同对抗性微调比例，找到最佳干净/对抗数据配比；4) 探索数据增强带来的容量瓶颈问题；5) 实施三种有针对性的抗对抗训练，特别是采用NER引导的对比学习方法。

Result: （1）否定混淆和实体替换是主要的模型失效点；（2）以80%干净+20%对抗数据微调，得到最优性能；（3）ELECTRA模型扩大参数量可消除鲁棒性与准确率的权衡难题；（4）NER引导的对比学习提升AddSent和SQuAD的EM分数至近90%，缩小对抗损失达94.9%。

Conclusion: 通过综合的错误剖析和有针对性的对抗训练，能够大幅提升问答系统对对抗样本的鲁棒性，在AddSent和SQuAD数据上达到了干净与对抗性能的近乎齐平。这项工作首次将详细语言学分析与实体识别引导的对比学习结合，用于对抗性问答，验证了针对性策略在提升系统可靠性和安全性方面的有效性。

Abstract: Question answering (QA) systems achieve impressive performance on standard benchmarks like SQuAD, but remain vulnerable to adversarial examples. This project investigates the adversarial robustness of transformer models on the AddSent adversarial dataset through systematic experimentation across model scales and targeted mitigation strategies. We perform comprehensive multi-level error analysis using five complementary categorization schemes, identifying negation confusion and entity substitution as the primary failure modes. Through systematic evaluation of adversarial fine-tuning ratios, we identify 80% clean + 20% adversarial data as optimal. Data augmentation experiments reveal a capacity bottleneck in small models. Scaling from ELECTRA-small (14M parameters) to ELECTRA-base (110M parameters) eliminates the robustness-accuracy trade-off, achieving substantial improvements on both clean and adversarial data. We implement three targeted mitigation strategies, with Entity-Aware contrastive learning achieving best performance: 89.89% AddSent Exact Match (EM) and 90.73% SQuAD EM, representing 94.9% closure of the adversarial gap. To our knowledge, this is the first work integrating comprehensive linguistic error analysis with Named Entity Recognition (NER)-guided contrastive learning for adversarial QA, demonstrating that targeted mitigation can achieve near-parity between clean and adversarial performance.

</details>


### [87] [Mitigating Prompt-Induced Hallucinations in Large Language Models via Structured Reasoning](https://arxiv.org/abs/2601.02739)
*Jinbo Hao,Kai Yang,Qingzhen Su,Yang Chen,Yifan Li,Chao Jiang*

Main category: cs.CL

TL;DR: 论文提出了一种新方法，通过引入代码模块和知识图谱探索，有效缓解大语言模型（LLMs）在推理时的幻觉现象，从而提升推理准确性和可验证性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型因其强大的自然语言处理能力在多个领域得到广泛应用，但常常受到幻觉（生成虚假信息）问题困扰，尤其是在由提示词诱发时，这极大地影响了模型的可信度和实用性。因此，有必要寻找新的方法来抑制和校正由提示引发的幻觉。

Method: 作者提出基于知识蒸馏链式模型，结合代码模块指导知识图谱探索，并将代码作为思维链提示（chain-of-thought prompt）的一部分，形成外部知识输入。通过这些设计，提升模型获取结构化、准确知识的能力，从而约束并提升其推理过程的准确性。

Result: 在公开数据集上，使用GPT-4和LLaMA-3.3进行实验，结果显示引入代码模块后模型捕获上下文信息的能力显著提升，且有效缓解了由提示词带来的幻觉现象。HIT@1/3/5分别提升15.64%、13.38%、13.28%，多项评测中成绩超过95%。

Conclusion: 新方法大幅降低了大语言模型的幻觉行为，并提升了推理的准确性和可验证性，具有较高的实际应用价值。

Abstract: To address hallucination issues in large language models (LLMs), this paper proposes a method for mitigating prompt-induced hallucinations. Building on a knowledge distillation chain-style model, we introduce a code module to guide knowledge-graph exploration and incorporate code as part of the chain-of-thought prompt, forming an external knowledge input that provides more accurate and structured information to the model. Based on this design, we develop an improved knowledge distillation chain-style model and leverage it to analyze and constrain the reasoning process of LLMs, thereby improving inference accuracy. We empirically evaluate the proposed approach using GPT-4 and LLaMA-3.3 on multiple public datasets. Experimental results demonstrate that incorporating code modules significantly enhances the model's ability to capture contextual information and effectively mitigates prompt-induced hallucinations. Specifically, HIT@1, HIT@3, and HIT@5 improve by 15.64%, 13.38%, and 13.28%, respectively. Moreover, the proposed method achieves HIT@1, HIT@3, and HIT@5 scores exceeding 95% across several evaluation settings. These results indicate that the proposed approach substantially reduces hallucination behavior while improving the accuracy and verifiability of large language models.

</details>


### [88] [Language Hierarchization Provides the Optimal Solution to Human Working Memory Limits](https://arxiv.org/abs/2601.02740)
*Luyao Chen,Weibo Gao,Junjie Wu,Jinshan Wu,Angela D. Friederici*

Main category: cs.CL

TL;DR: 本文探讨了人类语言为何以分层结构（hierarchical）为特征，认为其本质原因是高效利用有限的工作记忆容量。作者提出并验证了一个新颖的理论模型，通过计算发现分层结构能更好地优化语言处理，契合人类记忆限制。


<details>
  <summary>Details</summary>
Motivation: 尽管人类语言的分层（hierarchical）结构广泛存在，但尚不清楚其根本原因。作者关注于一个核心问题：为什么语言采用分层结构，而非线性结构？动机在于寻找这种普遍现象背后的认知基础，特别是联系到人类有限的工作记忆容量。

Method: 作者构建了一个似然函数来量化语言处理单元的平均数量与人类工作记忆容量（WMC）的匹配程度。通过最大似然估计，以及对符号序列的计算机模拟和对自然语言句子的实际分析，对比了线性处理与分层处理方式。

Result: 结果显示，分层处理明显优于线性处理，更好地约束了符号处理单元（tehta_MLE）不超出人类工作记忆极限，尤其是在序列/句子长度增加时。此外，这一分层效果与儿童记忆发展的收敛模式相契合。

Conclusion: 构建分层结构可以在记忆限制下优化序列输入的语言处理效率，这一机制可能是真正解释语言普遍具有分层结构的原因。

Abstract: Language is a uniquely human trait, conveying information efficiently by organizing word sequences in sentences into hierarchical structures. A central question persists: Why is human language hierarchical? In this study, we show that hierarchization optimally solves the challenge of our limited working memory capacity. We established a likelihood function that quantifies how well the average number of units according to the language processing mechanisms aligns with human working memory capacity (WMC) in a direct fashion. The maximum likelihood estimate (MLE) of this function, tehta_MLE, turns out to be the mean of units. Through computational simulations of symbol sequences and validation analyses of natural language sentences, we uncover that compared to linear processing, hierarchical processing far surpasses it in constraining the tehta_MLE values under the human WMC limit, along with the increase of sequence/sentence length successfully. It also shows a converging pattern related to children's WMC development. These results suggest that constructing hierarchical structures optimizes the processing efficiency of sequential language input while staying within memory constraints, genuinely explaining the universal hierarchical nature of human language.

</details>


### [89] [SYNAPSE: Empowering LLM Agents with Episodic-Semantic Memory via Spreading Activation](https://arxiv.org/abs/2601.02744)
*Hanqi Jiang,Junhao Chen,Yi Pan,Ling Chen,Weihang You,Yifan Zhou,Ruidong Zhang,Yohannes Abate,Tianming Liu*

Main category: cs.CL

TL;DR: 本文提出了Synapse，一种结合了图结构与激活扩散机制的新型记忆架构，有效解决了长时记忆断裂和语境限制的问题，并在推理任务中超越了现有技术。


<details>
  <summary>Details</summary>
Motivation: 传统的检索增强方法难以解决大模型长期、动态记忆连接的问题，使得模型在复杂推理时易陷入“语境隧道”（Contextual Tunneling），限制了其推理与泛化能力。

Method: Synapse借鉴认知科学，将记忆建模为具有动态激活扩散的图结构，通过旁抑制与时间衰减机制，在图中动态高亮相关子图并抑制干扰。同时，创新性地提出Triple Hybrid Retrieval，将几何（向量）嵌入和图激活遍历相结合，实现更有效和智能的记忆检索。

Result: 在LoCoMo基准上的全面评测显示，Synapse在复杂的时序和多跳推理任务中，明显优于最先进的方法。

Conclusion: Synapse为大模型长期和复杂记忆管理提供了高效、可扩展的解决方案，显著缓解了语境隧道问题，并有望推动推理型智能体的发展。

Abstract: While Large Language Models (LLMs) excel at generalized reasoning, standard retrieval-augmented approaches fail to address the disconnected nature of long-term agentic memory. To bridge this gap, we introduce Synapse (Synergistic Associative Processing Semantic Encoding), a unified memory architecture that transcends static vector similarity. Drawing from cognitive science, Synapse models memory as a dynamic graph where relevance emerges from spreading activation rather than pre-computed links. By integrating lateral inhibition and temporal decay, the system dynamically highlights relevant sub-graphs while filtering interference. We implement a Triple Hybrid Retrieval strategy that fuses geometric embeddings with activation-based graph traversal. Comprehensive evaluations on the LoCoMo benchmark show that Synapse significantly outperforms state-of-the-art methods in complex temporal and multi-hop reasoning tasks, offering a robust solution to the "Contextual Tunneling" problem. Our code and data will be made publicly available upon acceptance.

</details>


### [90] [Window-based Membership Inference Attacks Against Fine-tuned Large Language Models](https://arxiv.org/abs/2601.02751)
*Yuetian Chen,Yuntao Du,Kaiyuan Zhang,Ashish Kundu,Charles Fleming,Bruno Ribeiro,Ninghui Li*

Main category: cs.CL

TL;DR: 本论文提出了一种新的成员推断攻击（MIA）方法WBC，利用窗口滑动和局部特征聚合，有效提升了对LLM训练数据成员身份的检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的成员推断攻击主要依赖全局信号（如平均损失），会削弱某些更细致的记忆化局部信号，降低攻击效果。作者认为局部上下文中成员信号更明显，因此急需改进方法以捕捉这些信号。

Method: 提出了WBC（Window-Based Comparison），通过对文本序列滑动变长窗口，每个窗口根据目标模型和参考模型损失比较结果投票表决，最后结合多个不同尺度窗口的投票，融合从token到短语的多层次记忆特征。

Result: 在11个数据集上的大量实验证明，WBC在AUC和低误报率下的检测率具有大幅提升（2-3倍），远优于现有主流方法。

Conclusion: 局部证据聚合比全局平均更能有效识别训练成员暴露的风险，揭示了微调大模型在隐私泄露上的严重漏洞。

Abstract: Most membership inference attacks (MIAs) against Large Language Models (LLMs) rely on global signals, like average loss, to identify training data. This approach, however, dilutes the subtle, localized signals of memorization, reducing attack effectiveness. We challenge this global-averaging paradigm, positing that membership signals are more pronounced within localized contexts. We introduce WBC (Window-Based Comparison), which exploits this insight through a sliding window approach with sign-based aggregation. Our method slides windows of varying sizes across text sequences, with each window casting a binary vote on membership based on loss comparisons between target and reference models. By ensembling votes across geometrically spaced window sizes, we capture memorization patterns from token-level artifacts to phrase-level structures. Extensive experiments across eleven datasets demonstrate that WBC substantially outperforms established baselines, achieving higher AUC scores and 2-3 times improvements in detection rates at low false positive thresholds. Our findings reveal that aggregating localized evidence is fundamentally more effective than global averaging, exposing critical privacy vulnerabilities in fine-tuned LLMs.

</details>


### [91] [EComStage: Stage-wise and Orientation-specific Benchmarking for Large Language Models in E-commerce](https://arxiv.org/abs/2601.02752)
*Kaiyan Zhao,Zijie Meng,Zheyong Xie,Jin Duan,Yao Hu,Zuozhu Liu,Shaosheng Cao*

Main category: cs.CL

TL;DR: 本文提出了EComStage基准，专注于在电商场景中全面评估大语言模型（LLM）在感知、规划和行动等推理阶段的能力，弥补了现有基准只重视最终任务完成率而忽视中间推理过程的不足。该基准涵盖七种典型电商任务，涵盖面向客户及商家的多种实际应用。通过对30多种LLM的评测，揭示了不同模型在各阶段及场景下的优势与短板。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM评测主要关注于电商智能体是否能够完成最终任务，却忽视了在实际使用中极为重要的中间推理流程（感知用户意图、规划方案、执行决策）。中间推理能力的评估对于优化和设计更智能、更可靠的电商智能体具有重要意义。

Method: 作者设计了EComStage基准，涵盖七个代表性电商任务，囊括客户服务和商家场景，并将推理过程细分为感知、规划和行动各阶段。所有评测样本均由人工注释与质检，对30多种不同规模的LLM（含开源和闭源）进行全面测试和对比。

Result: 通过基准测试，作者系统性地量化了各种LLM在不同推理阶段以及不同应用场景（客户/商家）下的表现，总结出不同类型模型在各阶段、各任务下的优劣势。

Conclusion: EComStage基准提供了更细致和全面的评测视角，为未来LLM智能体在电商场景的设计和优化提供了可操作性的改进建议，也为相关研究社区提供了重要参考。

Abstract: Large Language Model (LLM)-based agents are increasingly deployed in e-commerce applications to assist customer services in tasks such as product inquiries, recommendations, and order management. Existing benchmarks primarily evaluate whether these agents successfully complete the final task, overlooking the intermediate reasoning stages that are crucial for effective decision-making. To address this gap, we propose EComStage, a unified benchmark for evaluating agent-capable LLMs across the comprehensive stage-wise reasoning process: Perception (understanding user intent), Planning (formulating an action plan), and Action (executing the decision). EComStage evaluates LLMs through seven separate representative tasks spanning diverse e-commerce scenarios, with all samples human-annotated and quality-checked. Unlike prior benchmarks that focus only on customer-oriented interactions, EComStage also evaluates merchant-oriented scenarios, including promotion management, content review, and operational support relevant to real-world applications. We evaluate a wide range of over 30 LLMs, spanning from 1B to over 200B parameters, including open-source models and closed-source APIs, revealing stage/orientation- specific strengths and weaknesses. Our results provide fine-grained, actionable insights for designing and optimizing LLM-based agents in real-world e-commerce settings.

</details>


### [92] [MiMo-V2-Flash Technical Report](https://arxiv.org/abs/2601.02780)
*Bangjun Xiao,Bingquan Xia,Bo Yang,Bofei Gao,Bowen Shen,Chen Zhang,Chenhong He,Chiheng Lou,Fuli Luo,Gang Wang,Gang Xie,Hailin Zhang,Hanglong Lv,Hanyu Li,Heyu Chen,Hongshen Xu,Houbin Zhang,Huaqiu Liu,Jiangshan Duo,Jianyu Wei,Jiebao Xiao,Jinhao Dong,Jun Shi,Junhao Hu,Kainan Bao,Kang Zhou,Lei Li,Liang Zhao,Linghao Zhang,Peidian Li,Qianli Chen,Shaohui Liu,Shihua Yu,Shijie Cao,Shimao Chen,Shouqiu Yu,Shuo Liu,Tianling Zhou,Weijiang Su,Weikun Wang,Wenhan Ma,Xiangwei Deng,Bohan Mao,Bowen Ye,Can Cai,Chenghua Wang,Chengxuan Zhu,Chong Ma,Chun Chen,Chunan Li,Dawei Zhu,Deshan Xiao,Dong Zhang,Duo Zhang,Fangyue Liu,Feiyu Yang,Fengyuan Shi,Guoan Wang,Hao Tian,Hao Wu,Heng Qu,Hongfei Yi,Hongxu An,Hongyi Guan,Xing Zhang,Yifan Song,Yihan Yan,Yihao Zhao,Yingchun Lai,Yizhao Gao,Yu Cheng,Yuanyuan Tian,Yudong Wang,Zhen Tang,Zhengju Tang,Zhengtao Wen,Zhichao Song,Zhixian Zheng,Zihan Jiang,Jian Wen,Jiarui Sun,Jiawei Li,Jinlong Xue,Jun Xia,Kai Fang,Menghang Zhu,Nuo Chen,Qian Tu,Qihao Zhang,Qiying Wang,Rang Li,Rui Ma,Shaolei Zhang,Shengfan Wang,Shicheng Li,Shuhao Gu,Shuhuai Ren,Sirui Deng,Tao Guo,Tianyang Lu,Weiji Zhuang,Weikang Zhang,Weimin Xiong,Wenshan Huang,Wenyu Yang,Xin Zhang,Xing Yong,Xu Wang,Xueyang Xie,Yilin Jiang,Yixin Yang,Yongzhe He,Yu Tu,Yuanliang Dong,Yuchen Liu,Yue Ma,Yue Yu,Yuxing Xiang,Zhaojun Huang,Zhenru Lin,Zhipeng Xu,Zhiyang Chen,Zhonghua Deng,Zihan Zhang,Zihao Yue*

Main category: cs.CL

TL;DR: MiMo-V2-Flash是一款309B参数的专家混合（MoE）大模型，具备高效推理和类智能体能力，采用混合注意力机制和多token预测，模型和权重已开源。


<details>
  <summary>Details</summary>
Motivation: 当前大模型虽然参数量庞大但推理速度和能力仍有限，且推理和智能体任务的提升通常意味着更大的计算开销。MiMo-V2-Flash旨在用更少活跃参数实现更强推理和任务执行能力，同时提升推理速度。

Method: 采用Sliding Window与全局attention结合的混合架构，通过多token预测（MTP）进行大规模预训练，并使用多教师策略的on-policy蒸馏（MOPD）高效迁移特定领域能力，拓展context长度至256k，推理时结合MTP加速解码。

Result: MiMo-V2-Flash在参数量远低于DeepSeek-V3.2与Kimi-K2情况下，性能表现持平或更优；在推理时，利用多token预测的草稿模型实现最大3.6倍接受长度及2.6倍解码速度提升。

Conclusion: MiMo-V2-Flash展示了以低活跃参数和高效率实现强推理及智能体能力的新范式，为高效大模型和下游任务提供了新方向，相关模型及权重已开源促进社区发展。

Abstract: We present MiMo-V2-Flash, a Mixture-of-Experts (MoE) model with 309B total parameters and 15B active parameters, designed for fast, strong reasoning and agentic capabilities. MiMo-V2-Flash adopts a hybrid attention architecture that interleaves Sliding Window Attention (SWA) with global attention, with a 128-token sliding window under a 5:1 hybrid ratio. The model is pre-trained on 27 trillion tokens with Multi-Token Prediction (MTP), employing a native 32k context length and subsequently extended to 256k. To efficiently scale post-training compute, MiMo-V2-Flash introduces a novel Multi-Teacher On-Policy Distillation (MOPD) paradigm. In this framework, domain-specialized teachers (e.g., trained via large-scale reinforcement learning) provide dense and token-level reward, enabling the student model to perfectly master teacher expertise. MiMo-V2-Flash rivals top-tier open-weight models such as DeepSeek-V3.2 and Kimi-K2, despite using only 1/2 and 1/3 of their total parameters, respectively. During inference, by repurposing MTP as a draft model for speculative decoding, MiMo-V2-Flash achieves up to 3.6 acceptance length and 2.6x decoding speedup with three MTP layers. We open-source both the model weights and the three-layer MTP weights to foster open research and community collaboration.

</details>


### [93] [Punctuation-aware Hybrid Trainable Sparse Attention for Large Language Models](https://arxiv.org/abs/2601.02819)
*Junxiang Qiu,Shuo Wang,Zhengsu Chen,Hengheng Zhang,Jinda Lu,Changcheng Li,Qi Tian*

Main category: cs.CL

TL;DR: 该论文提出了一种基于标点感知的混合稀疏注意力（PHSA）机制，有效提升大模型在长文本处理上的效率与表现。


<details>
  <summary>Details</summary>
Motivation: 现有的稠密注意力因其复杂度随序列长度二次增长，对于长文本处理效率低。稀疏注意力虽能缓解此问题，但常用的语义分块策略易导致关键信息丢失，急需更细致的分块机制。

Method: 作者提出了PHSA，利用文本中的标点符号作为语义边界锚点。具体方法包括：(1) 设计了双分支聚合机制，将全局语义表示与标点增强的边界特征融合；(2) 提出了极端稀疏自适应的训练与推理策略，保证极少激活token下模型表现稳定。

Result: 在通用和长文本基准上，PHSA在准确性方面优于稠密注意力和最优稀疏注意力（如InfLLM v2）；在0.6B参数模型和32k输入长度下，PHSA可在97.3%高稀疏率下减少10.8%的信息丢失。

Conclusion: PHSA是一种高效、可训练的稀疏注意力机制，能在极高稀疏率下兼顾信息保留和计算效率，为长文本处理提供了有效解决方案。

Abstract: Attention serves as the fundamental mechanism for long-context modeling in large language models (LLMs), yet dense attention becomes structurally prohibitive for long sequences due to its quadratic complexity. Consequently, sparse attention has received increasing attention as a scalable alternative. However, existing sparse attention methods rely on coarse-grained semantic representations during block selection, which blur intra-block semantic boundaries and lead to the loss of critical information. To address this issue, we propose \textbf{P}unctuation-aware \textbf{H}ybrid \textbf{S}parse \textbf{A}ttention \textbf{(PHSA)}, a natively trainable sparse attention framework that leverages punctuation tokens as semantic boundary anchors. Specifically, (1) we design a dual-branch aggregation mechanism that fuses global semantic representations with punctuation-enhanced boundary features, preserving the core semantic structure while introducing almost no additional computational overhead; (2) we introduce an extreme-sparsity-adaptive training and inference strategy that stabilizes model behavior under very low token activation ratios; Extensive experiments on general benchmarks and long-context evaluations demonstrate that PHSA consistently outperforms dense attention and state-of-the-art sparse attention baselines, including InfLLM v2. Specifically, for the 0.6B-parameter model with 32k-token input sequences, PHSA can reduce the information loss by 10.8\% at a sparsity ratio of 97.3\%.

</details>


### [94] [Limited Linguistic Diversity in Embodied AI Datasets](https://arxiv.org/abs/2601.03136)
*Selma Wanna,Agnes Luhtaru,Jonathan Salfity,Ryan Barron,Juston Moore,Cynthia Matuszek,Mitch Pryor*

Main category: cs.CL

TL;DR: 本文系统审查了主流视觉-语言-动作（VLA）任务用语料的数据集，发现其指令语言高度重复、模板化，结构变化有限，语言表现单一。


<details>
  <summary>Details</summary>
Motivation: 尽管语言在VLA模型中至关重要，但现有训练与评估数据集中的语言特征鲜有详尽文档记录，难以了解其多样性或局限，这不利于更好数据集的设计与应用。

Method: 作者选取了多个主流VLA数据集，对其中的指令语言从词汇多样性、重复与重叠、语义相似性及句法复杂度等维度进行了系统量化分析。

Result: 结果显示，许多数据集高度依赖简单、模板化的命令，结构单一，大量重复，导致指令形式分布狭窄、语言表现贫乏。

Conclusion: 本项分析为VLA训练和评估数据中可用的语言信号提供了描述性文档，有助于更科学地报导、选择与管理数据集，并为后续扩展语言覆盖面提供方向。

Abstract: Language plays a critical role in Vision-Language-Action (VLA) models, yet the linguistic characteristics of the datasets used to train and evaluate these systems remain poorly documented. In this work, we present a systematic dataset audit of several widely used VLA corpora, aiming to characterize what kinds of instructions these datasets actually contain and how much linguistic variety they provide. We quantify instruction language along complementary dimensions-including lexical variety, duplication and overlap, semantic similarity, and syntactic complexity. Our analysis shows that many datasets rely on highly repetitive, template-like commands with limited structural variation, yielding a narrow distribution of instruction forms. We position these findings as descriptive documentation of the language signal available in current VLA training and evaluation data, intended to support more detailed dataset reporting, more principled dataset selection, and targeted curation or augmentation strategies that broaden language coverage.

</details>


### [95] [The performances of the Chinese and U.S. Large Language Models on the Topic of Chinese Culture](https://arxiv.org/abs/2601.02830)
*Feiyan Liu,Chenxun Zhuo,Siyan Zhao,Bao Ge,Tianming Liu*

Main category: cs.CL

TL;DR: 本研究对比了中美开发的大型语言模型在中文文化相关问题上的表现，发现中国开发的模型表现优于美国模型。


<details>
  <summary>Details</summary>
Motivation: 考虑到大型语言模型主要由中美两国开发，且文化背景对问题解决方式有影响，论文旨在探究不同国家开发的LLM在中文文化理解上的差异。

Method: 采用直接提问的方式测试多种主流中美LLM（如GPT-5.1、DeepSeek-V3.2、Qwen3-Max、Gemini2.5Pro）对中国历史、文学、诗歌等传统文化内容的掌握和回答能力，并进行横向对比分析。

Result: 实验结果显示，中国开发的语言模型在中国传统文化类问题上的正确率普遍高于美国开发的模型。其中，美国的Gemini 2.5Pro和GPT-5.1表现相对较好。

Conclusion: 中美LLM在中文文化理解上存在明显差异，中国模型普遍占优，这可能与训练数据分布、本地化策略和对中文文化内容的重视程度有关。

Abstract: Cultural backgrounds shape individuals' perspectives and approaches to problem-solving. Since the emergence of GPT-1 in 2018, large language models (LLMs) have undergone rapid development. To date, the world's ten leading LLM developers are primarily based in China and the United States. To examine whether LLMs released by Chinese and U.S. developers exhibit cultural differences in Chinese-language settings, we evaluate their performance on questions about Chinese culture. This study adopts a direct-questioning paradigm to evaluate models such as GPT-5.1, DeepSeek-V3.2, Qwen3-Max, and Gemini2.5Pro. We assess their understanding of traditional Chinese culture, including history, literature, poetry, and related domains. Comparative analyses between LLMs developed in China and the U.S. indicate that Chinese models generally outperform their U.S. counterparts on these tasks. Among U.S.-developed models, Gemini 2.5Pro and GPT-5.1 achieve relatively higher accuracy. The observed performance differences may potentially arise from variations in training data distribution, localization strategies, and the degree of emphasis on Chinese cultural content during model development.

</details>


### [96] [TiMem: Temporal-Hierarchical Memory Consolidation for Long-Horizon Conversational Agents](https://arxiv.org/abs/2601.02845)
*Kai Li,Xuanqing Yu,Ziyi Ni,Yi Zeng,Yao Xu,Zheqing Zhang,Xin Li,Jitao Sang,Xiaogang Duan,Xuelei Wang,Chengbao Liu,Jie Tan*

Main category: cs.CL

TL;DR: 本论文提出了一种新型的对话智能体记忆框架——TiMem，通过引入时间-层次化的结构，高效管理和整合长期对话历史，显著提升了长时段个性化与对话表现。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在处理超出上下文窗口的大规模长期对话时，现有记忆体系难以有效支持多层次、时间结构信息的有序整合，导致记忆碎片化与长期个性化的不稳定。

Method: 作者提出TiMem框架，利用『时间记忆树（TMT）』对会话进行时间-层次化组织。其核心包括：（1）通过TMT实现会话内容的时间和语义层次组织；（2）采用语义引导的无微调记忆多级整合；（3）基于复杂度自适应的记忆回溯以平衡查询效率和精度。

Result: 在LoCoMo和LongMemEval-S两个基准测试集上，TiMem分别取得了75.30%和76.88%的准确率，优于所有对比基线方法。同时，在LoCoMo测试中召回的记忆长度减少52.20%。流形分析还显示，TiMem具有人格分离性更好、分布更集中的表现。

Conclusion: TiMem以时间连续性为核心，有效解决了长期对话智能体的记忆组织与利用问题，推动了长期个性化和对话连续性的进步。

Abstract: Long-horizon conversational agents have to manage ever-growing interaction histories that quickly exceed the finite context windows of large language models (LLMs). Existing memory frameworks provide limited support for temporally structured information across hierarchical levels, often leading to fragmented memories and unstable long-horizon personalization. We present TiMem, a temporal--hierarchical memory framework that organizes conversations through a Temporal Memory Tree (TMT), enabling systematic memory consolidation from raw conversational observations to progressively abstracted persona representations. TiMem is characterized by three core properties: (1) temporal--hierarchical organization through TMT; (2) semantic-guided consolidation that enables memory integration across hierarchical levels without fine-tuning; and (3) complexity-aware memory recall that balances precision and efficiency across queries of varying complexity. Under a consistent evaluation setup, TiMem achieves state-of-the-art accuracy on both benchmarks, reaching 75.30% on LoCoMo and 76.88% on LongMemEval-S. It outperforms all evaluated baselines while reducing the recalled memory length by 52.20% on LoCoMo. Manifold analysis indicates clear persona separation on LoCoMo and reduced dispersion on LongMemEval-S. Overall, TiMem treats temporal continuity as a first-class organizing principle for long-horizon memory in conversational agents.

</details>


### [97] [To Generate or Discriminate? Methodological Considerations for Measuring Cultural Alignment in LLMs](https://arxiv.org/abs/2601.02858)
*Saurabh Kumar Pandey,Sougata Saha,Monojit Choudhury*

Main category: cs.CL

TL;DR: 本文提出了一种逆向社会人口统计提示（ISDP）方法，通过让大语言模型（LLM）根据用户实际和模拟行为预测其人口统计属性，以消除传统SDP方法中存在的偏差和解释困难。


<details>
  <summary>Details</summary>
Motivation: 现有的社会人口统计提示（SDP）常被用于评估LLMs的文化能力，但因提示敏感性、解码参数等混杂因素，难以判断模型表现不佳的来源，更无法分辨是偏见还是任务设计问题。

Method: 作者采用逆向社会人口统计提示（ISDP），即让LLMs通过判别任务预测用户的人口统计属性（如国籍）。以Goodreads-CSI数据集为例，包含印度、墨西哥、美国用户针对英文图书评论中的理解难度，测试了四款LLMs：Aya-23、Gemma-2、GPT-4o和LLaMA-3.1。比较模型在真实与模拟用户行为上的表现。

Result: 实验显示，模型对真实用户行为的判别准确率高于模拟行为，这与传统SDP结论相反；但在个体粒度时，两者表现均降低且趋于一致，反映个性化方面的局限性。

Conclusion: ISDP作为评估LLMs文化适应性的新方法，可更好避开SDP中的混杂因素，但即便如此，模型在高度个性化任务上的判别能力仍有限。

Abstract: Socio-demographic prompting (SDP) - prompting Large Language Models (LLMs) using demographic proxies to generate culturally aligned outputs - often shows LLM responses as stereotypical and biased. While effective in assessing LLMs' cultural competency, SDP is prone to confounding factors such as prompt sensitivity, decoding parameters, and the inherent difficulty of generation over discrimination tasks due to larger output spaces. These factors complicate interpretation, making it difficult to determine if the poor performance is due to bias or the task design. To address this, we use inverse socio-demographic prompting (ISDP), where we prompt LLMs to discriminate and predict the demographic proxy from actual and simulated user behavior from different users. We use the Goodreads-CSI dataset (Saha et al., 2025), which captures difficulty in understanding English book reviews for users from India, Mexico, and the USA, and test four LLMs: Aya-23, Gemma-2, GPT-4o, and LLaMA-3.1 with ISDP. Results show that models perform better with actual behaviors than simulated ones, contrary to what SDP suggests. However, performance with both behavior types diminishes and becomes nearly equal at the individual level, indicating limits to personalization.

</details>


### [98] [Training Language Models with homotokens Leads to Delayed Overfitting](https://arxiv.org/abs/2601.02867)
*Adrian Cosma,Stefan Ruseti,Emilian Radoi,Mihai Dascalu*

Main category: cs.CL

TL;DR: 本文提出了一种“同义子词（homotokens）”的数据增强方法，通过引入多种有效的子词切分方式（而非唯一标准切分），提升语言模型泛化能力，延缓过拟合。该方法实现简单，无需更改训练目标或token接口。实验显示，在数据受限条件下和多语种微调中均有提升，尤其当tokenizer本身对输入压缩较高时效果更佳。


<details>
  <summary>Details</summary>
Motivation: 当前主流的语言模型训练时，子词切分通常选择唯一的标准化方式，但实际有多种可能且语义等价的切分方式（同义子词）。这种唯一化存在信息损失，模型对切分方式缺乏鲁棒性。本文试图充分利用这些等价的切分，提升训练数据多样性，从而提升模型泛化能力。

Method: 提出并形式化了同义子词（homotokens）：同一词项的多种有效子词切分。设计了一种轻量级训练框架：通过辅助因果编码器与block-causal cross-attention，将采样获得的同义子词token序列作为辅助条件，进行下一个token预测，无需更改训练目标和token接口。

Result: 在数据有限的预训练环境下，同义子词增强能显著延缓模型过拟合，并在多个评测任务上提升泛化能力。多语种微调实验显示，如果tokenizer对输入进行了高效压缩，homotokens增益最大；而若tokenizer切分本就很细碎，则效果较弱。

Conclusion: 同义子词增强是一种简单模块化的方法，可自然引入token化不变性，提升语言模型的泛化及健壮性，尤其适用于数据受限或tokenizer压缩友好的场景。

Abstract: Subword tokenization introduces a computational layer in language models where many distinct token sequences decode to the same surface form and preserve meaning, yet induce different internal computations. Despite this non-uniqueness, language models are typically trained using a single canonical longest-prefix tokenization. We formalize homotokens-alternative valid subword segmentations of the same lexical item-as a strictly meaning-preserving form of data augmentation. We introduce a lightweight training architecture that conditions canonical next-token prediction on sampled homotoken variants via an auxiliary causal encoder and block-causal cross-attention, without modifying the training objective or token interface. In data-constrained pretraining, homotoken augmentation consistently delays overfitting under repeated data exposure and improves generalization across diverse evaluation datasets. In multilingual fine-tuning, we find that the effectiveness of homotokens depends on tokenizer quality: gains are strongest when canonical tokens are highly compressed and diminish when the tokenizer already over-fragments the input. Overall, homotokens provide a simple and modular mechanism for inducing tokenization invariance in language models.

</details>


### [99] [LongBench Pro: A More Realistic and Comprehensive Bilingual Long-Context Evaluation Benchmark](https://arxiv.org/abs/2601.02872)
*Ziyang Chen,Xing Wu,Junlong Jia,Chaochen Gao,Qi Fu,Debing Zhang,Songlin Hu*

Main category: cs.CL

TL;DR: 该论文提出了LongBench Pro，一个覆盖中英双语、包含1500个真实长上下文样本的新基准，旨在更真实、系统地评测大模型的长文本能力。它采用人机协作流程平衡质量与规模，并首次对46个主流大模型进行了系统性测试。


<details>
  <summary>Details</summary>
Motivation: 现有大模型长上下文评测基准存在真实性与可扩展性难以兼顾的问题：合成任务简单不贴合现实，完全人工标注则成本过高。因此，亟需一个既真实又可扩展的新基准，推动长上下文处理能力的研究。

Method: 构建了LongBench Pro：收集真实中英长文本，涵盖11大类、25细任务，支持细粒度分析。采用人机协作：“前沿大模型+专家”的流程生成并校验题目与答案，高效扩充任务库。定义多维度难度分层体系。最后，用该基准评测46种长上下文大模型。

Result: 实验发现：（1）针对长上下文的优化比单纯扩大参数量更有效；（2）模型实际可用的上下文长度普遍短于标称长度，且跨语言表现不一致；（3）内生推理训练下的模型更适合“类思考”范式，混合思考方式能取得效率与效果的兼顾。

Conclusion: LongBench Pro作为覆盖面广、难度分明、任务真实的双语长上下文基准，为未来大模型长文本理解研究与技术提升，提供了更可靠的评测与分析平台。

Abstract: The rapid expansion of context length in large language models (LLMs) has outpaced existing evaluation benchmarks. Current long-context benchmarks often trade off scalability and realism: synthetic tasks underrepresent real-world complexity, while fully manual annotation is costly to scale to extreme lengths and diverse scenarios. We present LongBench Pro, a more realistic and comprehensive bilingual benchmark of 1,500 naturally occurring long-context samples in English and Chinese spanning 11 primary tasks and 25 secondary tasks, with input lengths from 8k to 256k tokens. LongBench Pro supports fine-grained analysis with task-specific metrics and a multi-dimensional taxonomy of context requirement (full vs. partial dependency), length (six levels), and difficulty (four levels calibrated by model performance). To balance quality with scalability, we propose a Human-Model Collaborative Construction pipeline: frontier LLMs draft challenging questions and reference answers, along with design rationales and solution processes, to reduce the cost of expert verification. Experts then rigorously validate correctness and refine problematic cases. Evaluating 46 widely used long-context LLMs on LongBench Pro yields three findings: (1) long-context optimization contributes more to long-context comprehension than parameter scaling; (2) effective context length is typically shorter than the claimed context length, with pronounced cross-lingual misalignment; and (3) the "thinking" paradigm helps primarily models trained with native reasoning, while mixed-thinking designs offer a promising Pareto trade-off. In summary, LongBench Pro provides a robust testbed for advancing long-context understanding.

</details>


### [100] [Revisiting Data Compression with Language Modeling](https://arxiv.org/abs/2601.02875)
*Chen-Han Tsai*

Main category: cs.CL

TL;DR: 本报告研究了大型语言模型（LLM）在数据压缩任务中的潜力，提出了不同方法，通过无需额外训练实现了新的压缩性能记录，并对多种数据类型的压缩能力进行了测试。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM已经在文本及多模态数据压缩方面取得了较好结果，但距离替代传统压缩算法仍存在实际挑战。本研究旨在寻找提升LLM压缩率的方法，推动其在实际数据压缩中的应用。

Method: 系统性探索了不同的LLM数据压缩方法，对比评测了它们在标准数据集（如enwik9）上的表现，并尝试压缩非英语文本、代码和字节流数据，无需对LLM进行额外训练。

Result: 在enwik9数据集上实现了约18%的业界领先调整压缩率。对于文本为主的数据，LLM表现优异；对于非自然文本等其他类型数据，经适当配置后，LLM的压缩表现也依然有竞争力。

Conclusion: LLM在数据压缩尤其是文本压缩方面具有巨大潜力，通过合理配置，可扩展至多种数据类型，是传统压缩算法的有力补充，但在特殊非结构化数据上尚有优化空间。

Abstract: In this report, we investigate the potential use of large language models (LLM's) in the task of data compression. Previous works have demonstrated promising results in applying LLM's towards compressing not only text, but also a wide range of multi-modal data. Despite the favorable performance achieved, there still remains several practical questions that pose a challenge towards replacing existing data compression algorithms with LLM's. In this work, we explore different methods to achieve a lower adjusted compression rate using LLM's as data compressors. In comparison to previous works, we were able to achieve a new state-of-the-art (SOTA) adjusted compression rate of around $18\%$ on the enwik9 dataset without additional model training. Furthermore, we explore the use of LLM's in compressing non-English data, code data, byte stream sequences. We show that while LLM's excel in compressing data in text-dominant domains, their ability in compressing non-natural text sequences still remain competitive if configured in the right way.

</details>


### [101] [Transparent Semantic Change Detection with Dependency-Based Profiles](https://arxiv.org/abs/2601.02891)
*Bach Phan-Tat,Kris Heylen,Dirk Geeraerts,Stefano De Pascale,Dirk Speelman*

Main category: cs.CL

TL;DR: 本文提出了一种只依赖句法依存共现模式的词义变化检测方法，无需深度学习词向量模型，并证明其有效性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的词义变化检测方法大多依赖于基于神经网络的词嵌入模型，虽然效果好但模型不透明、难以解释。本文意在寻找一种更透明、易于解释的替代方法。

Method: 提出一种纯基于依存句法分析中词的共现模式的方法，摒弃了分布式词向量，通过分析共现模式来检测词义变化。

Result: 所提方法在词义变化检测任务中，效果优于部分分布式语义模型。实验结果经过定量和定性分析，表明预测结果既有效又易于解释。

Conclusion: 仅依赖依存句法共现的方案在实际中同样可行，并有出色的可解释性，有望成为现有方法的透明补充。

Abstract: Most modern computational approaches to lexical semantic change detection (LSC) rely on embedding-based distributional word representations with neural networks. Despite the strong performance on LSC benchmarks, they are often opaque. We investigate an alternative method which relies purely on dependency co-occurrence patterns of words. We demonstrate that it is effective for semantic change detection and even outperforms a number of distributional semantic models. We provide an in-depth quantitative and qualitative analysis of the predictions, showing that they are plausible and interpretable.

</details>


### [102] [Linear Script Representations in Speech Foundation Models Enable Zero-Shot Transliteration](https://arxiv.org/abs/2601.02906)
*Ryan Soh-Eun Shim,Kwanghee Choi,Kalvin Chang,Ming-Hao Hsu,Florian Eichin,Zhizheng Wu,Alane Suhr,Michael A. Hedderich,David Harwath,David R. Mortensen,Barbara Plank*

Main category: cs.CL

TL;DR: 论文提出了一种在多语种语音模型（如 Whisper）的推理阶段，通过修改激活向量，直接控制语音识别的输出字符脚本（script）。该方法不仅能转换常见语言-脚本组合，还能实现非常规的脚本转写。实验结果显示，该方法对不同大小的Whisper模型都能带来良好表现。


<details>
  <summary>Details</summary>
Motivation: 多语种语音模型普遍训练于包含多种区域变体的大规模语音数据，但不同变体常用不同字符脚本，导致输出脚本不确定。这种输出的不一致性增加了实际应用的复杂性，因此希望能有效控制输出脚本。

Method: 作者分析了脚本信息在线性激活空间中的编码方式，并在推理时通过向激活向量添加特定“脚本向量”，实现对最终输出脚本的直接干预。同时，他们还检验了该方法在非常规语言-脚本组合中的适用性。

Result: 通过在Whisper等多语种语音识别模型上应用脚本控制方法，作者成功实现了输出脚本的后处理定制，不仅适用于常见组合，还能适配如意大利语-西里尔字母、日语-拉丁字母等非常规搭配，各模型规模下表现均具有竞争力。

Conclusion: 脚本信息可以在语音模型激活空间中以线性方式操纵，允许用户在不重新训练模型的情况下后处理控制输出脚本，为多语种、多脚本语音识别提供了灵活、高效的解决方案。

Abstract: Multilingual speech foundation models such as Whisper are trained on web-scale data, where data for each language consists of a myriad of regional varieties. However, different regional varieties often employ different scripts to write the same language, rendering speech recognition output also subject to non-determinism in the output script. To mitigate this problem, we show that script is linearly encoded in the activation space of multilingual speech models, and that modifying activations at inference time enables direct control over output script. We find the addition of such script vectors to activations at test time can induce script change even in unconventional language-script pairings (e.g. Italian in Cyrillic and Japanese in Latin script). We apply this approach to inducing post-hoc control over the script of speech recognition output, where we observe competitive performance across all model sizes of Whisper.

</details>


### [103] [Beyond the Black Box: Theory and Mechanism of Large Language Models](https://arxiv.org/abs/2601.02907)
*Zeyu Gan,Ruifeng Ren,Wei Yao,Xiaolin Hu,Gengze Xu,Chen Qian,Huayi Tang,Zixuan Gong,Xinhao Yao,Pengwei Tang,Zhenxing Dou,Yong Liu*

Main category: cs.CL

TL;DR: 本文提出以生命周期为基础的研究分类体系，系统梳理大语言模型（LLMs）理论基础及内部机制，旨在推动从工程试作向科学化演进。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在工程应用上取得巨大成功，但理论研究严重滞后，导致其仍然被视为黑盒系统。作者希望通过系统化综述来弥补理论碎片化的问题。

Method: 文章构建了包含数据准备、模型准备、训练、对齐、推理和评估六大阶段的生命周期分类体系，在此框架下综述现有基础理论与关键机制，并对相关理论问题（如数据混合的数学基础、模型表示极限、对齐优化动力学等）进行分析。

Result: 系统回顾理论进展的同时，提出了未来主要挑战：如合成数据自我提升的理论极限、安全性数学界限、涌现智能的机制等，厘清了当前工程方法的科学探究方向。

Conclusion: 该综述为LLM研究提供了清晰的理论版图和研究路线图，有助于从经验主义工程迈向科学化理论建构。

Abstract: The rapid emergence of Large Language Models (LLMs) has precipitated a profound paradigm shift in Artificial Intelligence, delivering monumental engineering successes that increasingly impact modern society. However, a critical paradox persists within the current field: despite the empirical efficacy, our theoretical understanding of LLMs remains disproportionately nascent, forcing these systems to be treated largely as ``black boxes''. To address this theoretical fragmentation, this survey proposes a unified lifecycle-based taxonomy that organizes the research landscape into six distinct stages: Data Preparation, Model Preparation, Training, Alignment, Inference, and Evaluation. Within this framework, we provide a systematic review of the foundational theories and internal mechanisms driving LLM performance. Specifically, we analyze core theoretical issues such as the mathematical justification for data mixtures, the representational limits of various architectures, and the optimization dynamics of alignment algorithms. Moving beyond current best practices, we identify critical frontier challenges, including the theoretical limits of synthetic data self-improvement, the mathematical bounds of safety guarantees, and the mechanistic origins of emergent intelligence. By connecting empirical observations with rigorous scientific inquiry, this work provides a structured roadmap for transitioning LLM development from engineering heuristics toward a principled scientific discipline.

</details>


### [104] [Image, Word and Thought: A More Challenging Language Task for the Iterated Learning Model](https://arxiv.org/abs/2601.02911)
*Hyoyeon Lee,Seth Bullock,Conor Houghton*

Main category: cs.CL

TL;DR: 本文提出了一种结合监督与无监督学习的新型半监督迭代学习模型，首次在更复杂的语义任务（如七段数码显示图像的表达）中模拟了语言的生成与传承，展示该模型下生成的语言同时具备表达性、组合性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统迭代学习模型已揭示了语言结构如何随着代际传递逐步形成，但受限于模型计算资源和实际生态的有效性，难以扩展到大规模的语义信号空间和复杂任务。为了更好地理解语言结构的演化机制，需要更具计算效率且符合实际语言学习情境的新模型。

Method: 作者引入了一种半监督迭代学习模型，将监督学习和无监督学习结合，并采用自编码器结构。模型首次应用于处理更复杂的“七段显示图像”任务，通过运行多代智能体来模拟语言在更大语义空间中的代际传递和演化。

Result: 实验结果表明，该模型能够生成一种语言，其信号为所有128种字形都分配了独特编码，具备明确的表达性。同时，信号组成与语义结构之间形成稳定的组合映射，而且语言随着代际传递保持稳定，不发生结构性变异。

Conclusion: 该半监督迭代学习模型不仅提升了对更复杂语言学习场景的模拟能力，也进一步证明了代际传递机制有助于表达性、组合性和稳定性语言结构的自发形成，这为理解自然语言的起源和结构演化提供了新的理论与技术支持。

Abstract: The iterated learning model simulates the transmission of language from generation to generation in order to explore how the constraints imposed by language transmission facilitate the emergence of language structure. Despite each modelled language learner starting from a blank slate, the presence of a bottleneck limiting the number of utterances to which the learner is exposed can lead to the emergence of language that lacks ambiguity, is governed by grammatical rules, and is consistent over successive generations, that is, one that is expressive, compositional and stable. The recent introduction of a more computationally tractable and ecologically valid semi supervised iterated learning model, combining supervised and unsupervised learning within an autoencoder architecture, has enabled exploration of language transmission dynamics for much larger meaning-signal spaces. Here, for the first time, the model has been successfully applied to a language learning task involving the communication of much more complex meanings: seven-segment display images. Agents in this model are able to learn and transmit a language that is expressive: distinct codes are employed for all 128 glyphs; compositional: signal components consistently map to meaning components, and stable: the language does not change from generation to generation.

</details>


### [105] [RAL2M: Retrieval Augmented Learning-To-Match Against Hallucination in Compliance-Guaranteed Service Systems](https://arxiv.org/abs/2601.02917)
*Mengze Hong,Di Jiang,Jiangtao Wen,Zhiyang Su,Yawen Li,Yanjie Sun,Guan Wang,Chen Jason Zhang*

Main category: cs.CL

TL;DR: 本文提出了Retrieval-Augmented Learning-to-Match（RAL2M）框架，通过将大模型作为检索系统中的查询-响应匹配判别者，而非内容生成者，从而消除生成型幻觉。此外，提出了查询自适应潜在集成策略，有效地缓解判别幻觉。实验显示该方法优于主流基线，展现出潜在表示的巨大研究价值。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）经常出现“幻觉”现象，导致生成的不可靠内容，尤其在对合规和准确性要求极高的服务系统中问题突出。因此，作者希望通过检索增强和合理模型集成，提升响应的可靠性和一致性。

Method: 1）将LLM从内容生成者转变为检索增强系统中的查询-响应配对判别者；2）提出查询自适应的潜在集成策略，显式建模不同模型的能力和依赖关系，通过集体智慧获得校准的决策共识。

Result: 在大规模基准测试上，所提出的RAL2M方法能够充分发挥多模型集体决策的优势，在准确性等关键指标上显著优于现有强基线方法。

Conclusion: 通过检索增强和集成学习，有效缓解了LLM的幻觉问题。RAL2M为提升模型响应可靠性提供了新范式，未来可继续开发和利用潜在表示以进一步优化系统表现。

Abstract: Hallucination is a major concern in LLM-driven service systems, necessitating explicit knowledge grounding for compliance-guaranteed responses. In this paper, we introduce Retrieval-Augmented Learning-to-Match (RAL2M), a novel framework that eliminates generation hallucination by repositioning LLMs as query-response matching judges within a retrieval-based system, providing a robust alternative to purely generative approaches. To further mitigate judgment hallucination, we propose a query-adaptive latent ensemble strategy that explicitly models heterogeneous model competence and interdependencies among LLMs, deriving a calibrated consensus decision. Extensive experiments on large-scale benchmarks demonstrate that the proposed method effectively leverages the "wisdom of the crowd" and significantly outperforms strong baselines. Finally, we discuss best practices and promising directions for further exploiting latent representations in future work.

</details>


### [106] [Memorization, Emergence, and Explaining Reversal Failures: A Controlled Study of Relational Semantics in LLMs](https://arxiv.org/abs/2601.02931)
*Yihua Zhu,Qianying Liu,Jiaxin Wang,Fei Cheng,Chaoran Liu,Akiko Aizawa,Sadao Kurohashi,Hidetoshi Shimodaira*

Main category: cs.CL

TL;DR: 本文探讨了自回归大语言模型在处理对称与逆向关系时，逻辑语义能力的来源及反转失败原因。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在关系推理任务上表现良好，但尚不清楚它们是否真正学会了这些关系的逻辑语义，如对称性与逆性，以及关系反转失败是由于语义欠缺还是因自回归顺序偏差。

Method: 作者提出了一种基于知识图谱的合成框架，通过生成具备对称/逆向三元组的文本，训练从头开始的GPT风格自回归模型，并对记忆、逻辑推理以及对未见实体的泛化能力进行评估。

Result: 实验发现，在具备足够逻辑监督信息时，即使是浅层模型（2-3层）也能出现关系语义能力的明显“相变”，且泛化能力与中间层稳定信号高度相关。进一步的顺序匹配正/反向测试与扩散模型基准验证，反转失败主要源自自回归顺序偏置，而非逆向逻辑语义缺失。

Conclusion: 自回归模型对关系的泛化和推理能力与逻辑监督直接相关，反转类型的错误主要由于模型生成方式的顺序偏置，而非关系语义理解不足。

Abstract: Autoregressive LLMs perform well on relational tasks that require linking entities via relational words (e.g., father/son, friend), but it is unclear whether they learn the logical semantics of such relations (e.g., symmetry and inversion logic) and, if so, whether reversal-type failures arise from missing relational semantics or left-to-right order bias. We propose a controlled Knowledge Graph-based synthetic framework that generates text from symmetric/inverse triples, train GPT-style autoregressive models from scratch, and evaluate memorization, logical inference, and in-context generalization to unseen entities to address these questions. We find a sharp phase transition in which relational semantics emerge with sufficient logic-bearing supervision, even in shallow (2-3 layer) models, and that successful generalization aligns with stable intermediate-layer signals. Finally, order-matched forward/reverse tests and a diffusion baseline indicate that reversal failures are primarily driven by autoregressive order bias rather than deficient inversion semantics.

</details>


### [107] [Pearmut: Human Evaluation of Translation Made Trivial](https://arxiv.org/abs/2601.02933)
*Vilém Zouhar,Tom Kocmi*

Main category: cs.CL

TL;DR: 本文介绍了Pearmut，一个轻量化但功能丰富的平台，可以极大简化多语言NLP中的人工评测流程，使其像自动化评测一样易于操作。


<details>
  <summary>Details</summary>
Motivation: 人工评测是多语言NLP中的金标准，但现有工具设置复杂、耗时、工程成本高，常被自动指标替代，导致人工评测难以普及。为解决这一痛点，作者开发了Pearmut。

Method: Pearmut平台支持端到端的人工评测流程，兼容现有标准评测协议（如DA、ESA、MQM），可灵活扩展新协议。平台还支持文档级上下文、绝对与对比评测、注意力检查、预注释，以及静态与主动学习任务分配。

Result: Pearmut降低了人工评测的门槛，可高效支持多语言任务、尤其是机器翻译评测。其丰富功能和便捷操作提升了人工评测的可用性与可靠性。

Conclusion: Pearmut让人工评测成为模型开发中的常规、可行步骤，而非偶尔为之的耗时工作，有助于推动高质量多语言NLP系统的持续迭代优化。

Abstract: Human evaluation is the gold standard for multilingual NLP, but is often skipped in practice and substituted with automatic metrics, because it is notoriously complex and slow to set up with existing tools with substantial engineering and operational overhead. We introduce Pearmut, a lightweight yet feature-rich platform that makes end-to-end human evaluation as easy to run as automatic evaluation. Pearmut removes common entry barriers and provides support for evaluating multilingual tasks, with a particular focus on machine translation. The platform implements standard evaluation protocols, including DA, ESA, or MQM, but is also extensible to allow prototyping new protocols. It features document-level context, absolute and contrastive evaluation, attention checks, ESAAI pre-annotations and both static and active learning-based assignment strategies. Pearmut enables reliable human evaluation to become a practical, routine component of model development and diagnosis rather than an occasional effort.

</details>


### [108] [Enhancing Multilingual RAG Systems with Debiased Language Preference-Guided Query Fusion](https://arxiv.org/abs/2601.02956)
*Jeonghyun Park,Byeongjeong Kim,Seojin Hwang,Hwanhee Lee*

Main category: cs.CL

TL;DR: 本文提出目前多语种检索增强生成（mRAG）系统中所谓的“偏好英语”现象其实是由评测基准中的结构性偏见造成，而非模型本身的语言偏见。作者提出新指标DeLP和新方法DELTA，有效消除偏见并提升多语种任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有多语种RAG系统倾向于选择英语，这被普遍认为是由于大语言模型对英语更擅长。然而，作者发现这种现象受到评测基准中暴露偏差、金标准可用性和文化先验等结构性偏见的影响，导致对模型语言偏好的不准确评估。

Method: 1）提出去偏指标DeLP，剔除评测中的结构性先验影响，更真实评估模型实际的语言偏好。2）基于DeLP分析，发现检索部分实际偏好查询和文档语言一致。3）据此提出DELTA方法，通过增强单语一致性来提升跨语种检索与生成效率。

Result: 实验表明，DELTA在多种语言下相较于传统英语中转和主流mRAG基线都有更优表现，验证了通过去除结构性偏见，单语一致策略对多语种任务的有效性。

Conclusion: mRAG系统被误认为偏好英语，实则是结构偏见造成。消除这些偏见后，优化单语一致性比英语中转更有效，有助于提升多语种（尤其低资源语言）检索与生成表现。

Abstract: Multilingual Retrieval-Augmented Generation (mRAG) systems often exhibit a perceived preference for high-resource languages, particularly English, resulting in the widespread adoption of English pivoting. While prior studies attribute this advantage to the superior English-centric capabilities of Large Language Models (LLMs), we find that such measurements are significantly distorted by structural priors inherent in evaluation benchmarks. Specifically, we identify exposure bias and a gold availability prior-both driven by the disproportionate concentration of resources in English-as well as cultural priors rooted in topic locality, as factors that hinder accurate assessment of genuine language preference. To address these biases, we propose DeLP (Debiased Language Preference), a calibrated metric designed to explicitly factor out these structural confounds. Our analysis using DeLP reveals that the previously reported English preference is largely a byproduct of evidence distribution rather than an inherent model bias. Instead, we find that retrievers fundamentally favor monolingual alignment between the query and the document language. Building on this insight, we introduce DELTA (DEbiased Language preference-guided Text Augmentation), a lightweight and efficient mRAG framework that strategically leverages monolingual alignment to optimize cross-lingual retrieval and generation. Experimental results demonstrate that DELTA consistently outperforms English pivoting and mRAG baselines across diverse languages.

</details>


### [109] [LLM-Augmented Changepoint Detection: A Framework for Ensemble Detection and Automated Explanation](https://arxiv.org/abs/2601.02957)
*Fabian Lukassen,Christoph Weisser,Michael Schlee,Manish Kumar,Anton Thielmann,Benjamin Saefken,Thomas Kneib*

Main category: cs.CL

TL;DR: 本文提出了一种结合集成统计方法与大型语言模型（LLM）的全新变点检测框架，提升了时间序列中变点检测的准确性与解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的变点检测方法在不同数据下优劣互补，难以选择最佳方法，且缺乏自动化的情境化解释，限制了实用性和可操作性。

Method: 该研究集成了10种变点检测算法形成集成方法，并结合LLM自动生成检测结果的情境化说明。对于私有或特定领域数据，引入RAG技术，从用户提供的文档中提取依据进行解释。

Result: 集成方法在检测准确性和鲁棒性上优于单一方法，LLM自动生成的上下文叙述能够有效连接变点与实际历史事件。

Conclusion: 该开源Python框架在金融、政治、环境等多个领域显示出实用价值，将生硬统计结果转化为可操作洞见。

Abstract: This paper introduces a novel changepoint detection framework that combines ensemble statistical methods with Large Language Models (LLMs) to enhance both detection accuracy and the interpretability of regime changes in time series data. Two critical limitations in the field are addressed. First, individual detection methods exhibit complementary strengths and weaknesses depending on data characteristics, making method selection non-trivial and prone to suboptimal results. Second, automated, contextual explanations for detected changes are largely absent. The proposed ensemble method aggregates results from ten distinct changepoint detection algorithms, achieving superior performance and robustness compared to individual methods. Additionally, an LLM-powered explanation pipeline automatically generates contextual narratives, linking detected changepoints to potential real-world historical events. For private or domain-specific data, a Retrieval-Augmented Generation (RAG) solution enables explanations grounded in user-provided documents. The open source Python framework demonstrates practical utility in diverse domains, including finance, political science, and environmental science, transforming raw statistical output into actionable insights for analysts and decision-makers.

</details>


### [110] [Low-Resource Heuristics for Bahnaric Optical Character Recognition Improvement](https://arxiv.org/abs/2601.02965)
*Phat Tran,Phuoc Pham,Hung Trinh,Tho Quan*

Main category: cs.CL

TL;DR: 本文针对Bahnar少数民族语言文档进行OCR识别，提出结合表格和非表格检测方法及概率后处理提升识别准确率，将准确率由72.86%提升至79.26%。该方法为Bahnar及其他少数民族语言数字化保存提供重要参考。


<details>
  <summary>Details</summary>
Motivation: Bahnar语言由于研究和数据稀缺，面临保存危机。纸质文档数字化时图像退化导致OCR错误较多，影响信息检索。因此，提升Bahnar文档OCR准确率具有现实紧迫性和学术价值。

Method: 本文采用先进的表格与非表格检测技术预处理文档图像，结合基于概率的错误后处理提升OCR识别结果准确性。步骤包括：1) 检测和识别文档中表格及非表格结构，优化输入；2) 对OCR输出结果使用概率性纠错策略。

Result: 实验显示，采用该方法后，Bahnar文档OCR识别准确率由72.86%提升至79.26%，表明方法显著提升了识别效果。

Conclusion: 提出的方法为Bahnar语言文档的高效数字化提供了方案，并具备推广到其他少数民族语言文档的潜力，有助于少数民族语言的数字化保存和传承。

Abstract: Bahnar, a minority language spoken across Vietnam, Cambodia, and Laos, faces significant preservation challenges due to limited research and data availability. This study addresses the critical need for accurate digitization of Bahnar language documents through optical character recognition (OCR) technology. Digitizing scanned paper documents poses significant challenges, as degraded image quality from broken or blurred areas introduces considerable OCR errors that compromise information retrieval systems. We propose a comprehensive approach combining advanced table and non-table detection techniques with probability-based post-processing heuristics to enhance recognition accuracy. Our method first applies detection algorithms to improve input data quality, then employs probabilistic error correction on OCR output. Experimental results indicate a substantial improvement, with recognition accuracy increasing from 72.86% to 79.26%. This work contributes valuable resources for Bahnar language preservation and provides a framework applicable to other minority language digitization efforts.

</details>


### [111] [Reliability-Aware Adaptive Self-Consistency for Efficient Sampling in LLM Reasoning](https://arxiv.org/abs/2601.02970)
*Junseok Kim,Nakyeong Yang,Kyungmin Min,Kyomin Jung*

Main category: cs.CL

TL;DR: ReASC是一种提升推理可靠性和效率的新方法，通过对响应的置信度进行理性聚合，大幅降低了多采样带来的推理成本，同时保持高准确率。


<details>
  <summary>Details</summary>
Motivation: 传统的自洽性推理（Self-Consistency）虽然可以提升模型推理的可靠性，但推理成本高昂。现有的自适应自洽方法依赖简单的计数规则，常常造成不必要的重复采样，效率依然不高。因此亟需一种更精细、更高效的推理采样策略。

Method: 提出了一种名为ReASC的新方法。该方法将自适应采样从计数机制转为证据充分性聚合，具体分两阶段：阶段一对置信度高的问题一次采样直接给出答案，阶段二对不确定问题，通过结合答案频次与置信度理性累积多个响应，聚合出最终答案。

Result: 在五种模型、四个数据集上，ReASC在准确率与推理成本之间取得了最优折中。举例来说，在Gemma-3-4B-it模型上运行GSM8K数据集时，推理成本比传统自洽法减少了最高70%，准确率基本保持不变。

Conclusion: ReASC有效提升了大模型推理效率，在成本与准确率上显著优于传统方法，在多模型与多数据集场景下均有很好的泛化能力。

Abstract: Self-Consistency improves reasoning reliability through multi-sample aggregation, but incurs substantial inference cost. Adaptive self-consistency methods mitigate this issue by adjusting the sampling budget; however, they rely on count-based stopping rules that treat all responses equally, often leading to unnecessary sampling. We propose Reliability-Aware Adaptive Self-Consistency (ReASC), which addresses this limitation by reframing adaptive sampling from response counting to evidence sufficiency, leveraging response-level confidence for principled information aggregation. ReASC operates in two stages: a single-sample decision stage that resolves instances confidently answerable from a single response, and a reliability-aware accumulation stage that aggregates responses by jointly leveraging their frequency and confidence. Across five models and four datasets, ReASC consistently achieves the best accuracy-cost trade-off compared to existing baselines, yielding improved inference efficiency across model scales from 3B to 27B parameters. As a concrete example, ReASC reduces inference cost by up to 70\% relative to self-consistency while preserving accuracy on GSM8K using Gemma-3-4B-it.

</details>


### [112] [Correct, Concise and Complete: Multi-stage Training For Adaptive Reasoning](https://arxiv.org/abs/2601.02972)
*Nathanaël Carraz Rakotonirina,Ren Pang,Neha Anna John,Michael Bohlke-Schneider,Momchil Hardalov*

Main category: cs.CL

TL;DR: 本文提出了一种多阶段高效推理方法，通过监督微调结合自适应长度惩罚的强化学习，在保持准确率的同时大大减少大语言模型推理时的冗余输出，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前的大语言模型推理通过链式思维(CoT)能提升准确率，但推理过程可能过长，导致计算量增加甚至影响模型性能，即“过度思考”问题。为此亟需方法减少不必要的推理步骤，实现效率和准确率间的更优权衡。

Method: 本文方法包含两部分：1.利用拒绝采样或推理痕迹重构进行多阶段监督微调，2.引入自适应长度惩罚的强化学习方法，具体通过一种轻量的奖励函数，在产生第一个正确答案后惩罚额外token输出，但在自验证有益时给予激励。

Result: 在七种不同推理任务上，8B参数模型响应长度减少28%，32B模型减少40%，准确率分别仅下降1.6和2.5分。效能-准确率权衡指标（OAA曲线AUC）达到76.6，领先基础模型5分，优于次佳方法2.5分。

Conclusion: 该方法结构简单却非常有效，可以大幅缩短输出长度并维持准确率，为高效推理任务提供了更好的解决方案，优于现有复杂的高效推理方法。

Abstract: The reasoning capabilities of large language models (LLMs) have improved substantially through increased test-time computation, typically in the form of intermediate tokens known as chain-of-thought (CoT). However, CoT often becomes unnecessarily long, increasing computation cost without actual accuracy gains or sometimes even degrading performance, a phenomenon known as ``overthinking''. We propose a multi-stage efficient reasoning method that combines supervised fine-tuning -- via rejection sampling or reasoning trace reformatting -- with reinforcement learning using an adaptive length penalty. We introduce a lightweight reward function that penalizes tokens generated after the first correct answer but encouraging self-verification only when beneficial. We conduct a holistic evaluation across seven diverse reasoning tasks, analyzing the accuracy--response length trade-off. Our approach reduces response length by an average of 28\% for 8B models and 40\% for 32B models, while incurring only minor performance drops of 1.6 and 2.5 points, respectively. Despite its conceptual simplicity, it achieves a superior trade-off compared to more complex state-of-the-art efficient reasoning methods, scoring 76.6, in terms of the area under the Overthinking-Adjusted Accuracy curve ($\text{AUC}_{\text{OAA}}$) -- 5 points above the base model and 2.5 points above the second-best approach.

</details>


### [113] [Mechanistic Knobs in LLMs: Retrieving and Steering High-Order Semantic Features via Sparse Autoencoders](https://arxiv.org/abs/2601.02978)
*Ruikang Zhang,Shuo Wang,Qi Su*

Main category: cs.CL

TL;DR: 本文提出了一种基于稀疏自编码器的框架，用于提取和调控大语言模型内部与高阶语义行为相关的可解释特征，实现精确且稳定地引导模型展现目标语义属性。


<details>
  <summary>Details</summary>
Motivation: 现有机制可解释性（MI）工作虽能识别和干预LLM内部特征，但难以可靠地将这些特征与生成语言时的复杂语义行为联系和调控。

Method: 使用基于稀疏自编码器的对比特征检索流程，通过语义对立控制、统计激活分析和生成检验，从稀疏激活空间中蒸馏出一语义功能明确的内部特征。以大五人格为例，对比现有方法检验该方法对行为的引导能力。

Result: 该方法能实现行为的精准、双向调控，且比如Contrastive Activation Addition（CAA）等主流方法具有更高的稳定性和性能。同时发现了“功能忠实性”现象，即对特定内部特征的干预会在多个语言维度产生与目标语义属性一致的连贯变化。

Conclusion: LLM内部已融合高层语义表征，文中方法为调节复杂AI行为提供了新颖且强健的机制路径。

Abstract: Recent work in Mechanistic Interpretability (MI) has enabled the identification and intervention of internal features in Large Language Models (LLMs). However, a persistent challenge lies in linking such internal features to the reliable control of complex, behavior-level semantic attributes in language generation. In this paper, we propose a Sparse Autoencoder-based framework for retrieving and steering semantically interpretable internal features associated with high-level linguistic behaviors. Our method employs a contrastive feature retrieval pipeline based on controlled semantic oppositions, combing statistical activation analysis and generation-based validation to distill monosemantic functional features from sparse activation spaces. Using the Big Five personality traits as a case study, we demonstrate that our method enables precise, bidirectional steering of model behavior while maintaining superior stability and performance compared to existing activation steering methods like Contrastive Activation Addition (CAA). We further identify an empirical effect, which we term Functional Faithfulness, whereby intervening on a specific internal feature induces coherent and predictable shifts across multiple linguistic dimensions aligned with the target semantic attribute. Our findings suggest that LLMs internalize deeply integrated representations of high-order concepts, and provide a novel, robust mechanistic path for the regulation of complex AI behaviors.

</details>


### [114] [P-Check: Advancing Personalized Reward Model via Learning to Generate Dynamic Checklist](https://arxiv.org/abs/2601.02986)
*Kwangwook Seo,Dongha Lee*

Main category: cs.CL

TL;DR: 本文提出了一种新的个性化奖励建模框架P-Check，通过生成动态评估清单，更好地捕捉个体判断的多样性与动态性，并显著提升了个性化奖励预测与生成任务的表现。


<details>
  <summary>Details</summary>
Motivation: 现有个性化奖励建模方法通常将用户上下文视为静态或隐式信号，难以反映人类判断的动态和多维特性。因此，亟需一种更灵活并具备解释性的个性化奖励机制。

Method: 提出了P-Check框架，训练可插拔的清单生成器，对奖励预测任务生成动态评估标准。引入Preference-Contrastive Criterion Weighting训练策略，根据标准在个性化判断中的区分能力分配重要性得分，从而提升个性化对齐效果。

Result: 大量实验表明，P-Check在个性化奖励准确率、下游个性化生成任务中均有改进，并在分布外(ood)场景中表现出较好的鲁棒性。

Conclusion: P-Check模型能够动态反映个体化判断标准，有效提升个性化自然语言任务的奖励建模的灵活性、准确性与泛化能力。

Abstract: Recent approaches in personalized reward modeling have primarily focused on leveraging user interaction history to align model judgments with individual preferences. However, existing approaches largely treat user context as a static or implicit conditioning signal, failing to capture the dynamic and multi-faceted nature of human judgment. In this paper, we propose P-Check, a novel personalized reward modeling framework, designed to train a plug-and-play checklist generator that synthesizes dynamic evaluation criteria for guiding the reward prediction. To better align these checklists with personalized nuances, we introduce Preference-Contrastive Criterion Weighting, a training strategy that assigns saliency scores to criteria based on their discriminative power for personalized judgment. We conduct extensive experiments and demonstrate that P-Check not only improves reward accuracy but also enhances downstream personalized generation, and remains robust in OOD scenarios.

</details>


### [115] [Mechanistic Interpretability of Large-Scale Counting in LLMs through a System-2 Strategy](https://arxiv.org/abs/2601.02989)
*Hosein Hasani,Mohammadali Banayeeanzade,Ali Nafisi,Sadegh Mohammadian,Fatemeh Askari,Mobin Bagherian,Amirmohammad Izadi,Mahdieh Soleymani Baghshah*

Main category: cs.CL

TL;DR: 本文发现大语言模型（LLM）在计数任务上存在系统性限制，并提出利用类似System-2认知分解策略，将大规模计数问题拆解为可控的小子问题，显著提升了模型的计数准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在复杂数学问题上表现强劲，但在计数任务中常出现精度下降，尤其是在数值较大的情况下。其根本原因是transformer结构在层级深度受限时，难以有效实现精准计数。作者希望解决LLM在计数任务上的结构性瓶颈。

Method: 作者提出了一种受System-2认知启发的测试时策略，将大规模计数任务分解为多个小而独立的子计数问题，并逐步合并结果。通过观察性和因果中介分析揭示其内部机制：局部计数被编码进子部分的最终表示，并通过特定注意力头在中间步骤间传递，最终汇总生成整体计数。

Result: 实验验证表明，该分解策略大幅提升了LLM在大规模计数任务上的准确率，超越了原有的结构性限制。同时分析明确指出了模型计数时信息传递和聚合的关键机制。

Conclusion: 该工作不仅提出了一种通用的LLM计数性能提升方案，也为理解和改进LLM推理行为提供了机制层面的洞见，具有广泛的应用和推广价值。

Abstract: Large language models (LLMs), despite strong performance on complex mathematical problems, exhibit systematic limitations in counting tasks. This issue arises from architectural limits of transformers, where counting is performed across layers, leading to degraded precision for larger counting problems due to depth constraints. To address this limitation, we propose a simple test-time strategy inspired by System-2 cognitive processes that decomposes large counting tasks into smaller, independent sub-problems that the model can reliably solve. We evaluate this approach using observational and causal mediation analyses to understand the underlying mechanism of this System-2-like strategy. Our mechanistic analysis identifies key components: latent counts are computed and stored in the final item representations of each part, transferred to intermediate steps via dedicated attention heads, and aggregated in the final stage to produce the total count. Experimental results demonstrate that this strategy enables LLMs to surpass architectural limitations and achieve high accuracy on large-scale counting tasks. This work provides mechanistic insight into System-2 counting in LLMs and presents a generalizable approach for improving and understanding their reasoning behavior.

</details>


### [116] [Stable-RAG: Mitigating Retrieval-Permutation-Induced Hallucinations in Retrieval-Augmented Generation](https://arxiv.org/abs/2601.02993)
*Qianchi Zhang,Hainan Zhang,Liang Pang,Hongwei Zheng,Zhiming Zheng*

Main category: cs.CL

TL;DR: 本文发现RAG模型对检索文档顺序敏感，提出了Stable-RAG方法，通过多顺序推理聚类，提升LLM可靠性，有效减少幻觉并提升一致性和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前RAG方法旨在减少大模型幻觉，但其对检索文档顺序敏感这一现象少有系统研究。现有方法多关注低质量检索和位置偏差，未直接解决顺序敏感性问题。

Method: 提出Stable-RAG，将检索文档顺序作为变量，多次运行生成模型，通过聚类隐藏状态获得主导推理模式，并以此为基础生成答案，从而缓解由检索顺序带来的输出幻觉。

Result: Stable-RAG在三个问答数据集上显著提升了答案准确率、推理一致性与泛化能力，相较基线方法在不同数据集、检索器与输入长度下均有更优表现。

Conclusion: 解决了RAG对检索顺序敏感导致的输出不一致和幻觉问题，Stable-RAG为提升检索增强生成模型的稳定性和实用性提供了新的有效方法。

Abstract: Retrieval-Augmented Generation (RAG) has become a key paradigm for reducing factual hallucinations in large language models (LLMs), yet little is known about how the order of retrieved documents affects model behavior. We empirically show that under Top-5 retrieval with the gold document included, LLM answers vary substantially across permutations of the retrieved set, even when the gold document is fixed in the first position. This reveals a previously underexplored sensitivity to retrieval permutations. Although robust RAG methods primarily focus on enhancing LLM robustness to low-quality retrieval and mitigating positional bias to distribute attention fairly over long contexts, neither approach directly addresses permutation sensitivity. In this paper, we propose Stable-RAG, which exploits permutation sensitivity estimation to mitigate permutation-induced hallucinations. Stable-RAG runs the generator under multiple retrieval orders, clusters hidden states, and decodes from a cluster-center representation that captures the dominant reasoning pattern. It then uses these reasoning results to align hallucinated outputs toward the correct answer, encouraging the model to produce consistent and accurate predictions across document permutations. Experiments on three QA datasets show that Stable-RAG significantly improves answer accuracy, reasoning consistency and robust generalization across datasets, retrievers, and input lengths compared with baselines.

</details>


### [117] [Large Reasoning Models Are (Not Yet) Multilingual Latent Reasoners](https://arxiv.org/abs/2601.02996)
*Yihong Liu,Raoyuan Zhao,Hinrich Schütze,Michael A. Hedderich*

Main category: cs.CL

TL;DR: 本论文系统性地研究了大型推理模型（LRMs）在多语言中的潜在推理能力，发现潜在推理广泛存在于资源丰富语言，但在资源匮乏语言和高难度任务中较弱。


<details>
  <summary>Details</summary>
Motivation: 以往研究表明LRMs在英文推理时，常在生成完整推理步骤前就得出正确答案，显示存在内部的非语言化推理。该现象在多语言环境下尚未被系统研究。本文旨在揭示LRMs在多语言数学推理任务中的潜在推理行为及其机制。

Method: 作者针对11种语言，采用基于截断的实验策略，即逐步截断推理链，观察模型内部预测何时出现，通过此方式分析不同语言下潜在推理的形成过程。此外，通过表征分析对比不同语言下的内部预测演化机制。

Result: 结果发现，在资源丰富的语言中潜在推理表现明显，在资源匮乏的语言及高难度基准测试中则表现较弱。进一步分析显示，虽然表层表现存在差异，不同语言的内部推理演化过程高度一致，并且多与英文推理路径保持一致性。

Conclusion: LRMs在多语言环境下普遍存在潜在推理能力，但这种能力受语言资源与任务难度影响。即使表面表现差异，模型内部推理路径趋向于以英文为中心，提示模型在多语言推理能力上存在局限与偏向。

Abstract: Large reasoning models (LRMs) achieve strong performance on mathematical reasoning tasks, often attributed to their capability to generate explicit chain-of-thought (CoT) explanations. However, recent work shows that LRMs often arrive at the correct answer before completing these textual reasoning steps, indicating the presence of latent reasoning -- internal, non-verbal computation encoded in hidden states. While this phenomenon has been explored in English, its multilingual behavior remains largely unknown. In this paper, we conduct a systematic investigation of multilingual latent reasoning in LRMs across 11 languages. Using a truncation-based strategy, we examine how the correct answer emerges as the model is given only partial reasoning traces, allowing us to measure stepwise latent prediction formation. Our results reveal clear evidence of multilingual latent reasoning, though unevenly: strong in resource-rich languages, weaker in low-resource ones, and broadly less observable on harder benchmarks. To understand whether these differences reflect distinct internal mechanisms, we further perform representational analyses. Despite surface-level disparities, we find that the internal evolution of predictions is highly consistent across languages and broadly aligns with English -- a pattern suggesting an English-centered latent reasoning pathway.

</details>


### [118] [SentGraph: Hierarchical Sentence Graph for Multi-hop Retrieval-Augmented Question Answering](https://arxiv.org/abs/2601.03014)
*Junli Liang,Pengfei Zhou,Wangqiu Zhou,Wenjie Qing,Qi Zhao,Ziwen Wang,Qi Song,Xiangyang Li*

Main category: cs.CL

TL;DR: 本文提出了SentGraph体系，通过基于句子的图结构化检索增强生成（RAG），显著提升了多跳问答任务中的证据链获取和推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统RAG在多跳问答时经常检索到无关或不连贯的内容，难以串联跨文档证据链，导致推理和答案错误。需要更加细致和逻辑严密的信息组织和检索方法。

Method: 作者提出基于句子的图结构RAG框架SentGraph。离线阶段，采用修正后的修辞结构理论区分文本主干和辅助句，并构造跨文档实体连接的主题级子图。在线检索阶段，通过图引导下的证据选择与路径扩展，按需检索粒度更细的句子级证据。

Result: 在四个多跳问答公开基准数据集上，SentGraph均取得了优异的实验结果，优于传统块级检索方法，有效提升了多跳推理的准确性。

Conclusion: 通过显式建模句子级逻辑关系，可以更好地支持多跳问答推理。SentGraph为多文档推理型检索增强生成提供了新思路与有效工具。

Abstract: Traditional Retrieval-Augmented Generation (RAG) effectively supports single-hop question answering with large language models but faces significant limitations in multi-hop question answering tasks, which require combining evidence from multiple documents. Existing chunk-based retrieval often provides irrelevant and logically incoherent context, leading to incomplete evidence chains and incorrect reasoning during answer generation. To address these challenges, we propose SentGraph, a sentence-level graph-based RAG framework that explicitly models fine-grained logical relationships between sentences for multi-hop question answering. Specifically, we construct a hierarchical sentence graph offline by first adapting Rhetorical Structure Theory to distinguish nucleus and satellite sentences, and then organizing them into topic-level subgraphs with cross-document entity bridges. During online retrieval, SentGraph performs graph-guided evidence selection and path expansion to retrieve fine-grained sentence-level evidence. Extensive experiments on four multi-hop question answering benchmarks demonstrate the effectiveness of SentGraph, validating the importance of explicitly modeling sentence-level logical dependencies for multi-hop reasoning.

</details>


### [119] [MMFormalizer: Multimodal Autoformalization in the Wild](https://arxiv.org/abs/2601.03017)
*Jing Xiong,Qi Han,Yunta Hsieh,Hui Shen,Huajian Xin,Chaofan Tao,Chenyang Zhao,Hengyuan Zhang,Taiqiang Wu,Zhen Zhang,Haochen Wang,Zhongwei Wan,Lingpeng Kong,Ngai Wong*

Main category: cs.CL

TL;DR: 本文提出MMFormalizer，一种将自然语言和视觉信息共同转化为可机理推理的形式化表述的系统，并在多模态数学和物理推理任务上取得领先结果。


<details>
  <summary>Details</summary>
Motivation: 现有自动形式化主要关注文本，难以覆盖现实世界复杂多模态（如需视觉推理、隐藏物理量推断等）的问题，制约了机器推理在物理等学科的应用。

Method: MMFormalizer通过递归性和自适应终止机制，将现实世界中的感知实体和物理/数学基础知识结合，逐步构建形式命题；其整合了多模态信息（如视觉元素），依赖自定义的新基准数据集PhyX-AF进行评估。

Result: 在PhyX-AF数据集上，现有大模型如GPT-5和Gemini-3-Pro具备最高的编译和语义准确率。GPT-5在物理推理表现突出，但几何任务仍然是最难的领域。

Conclusion: MMFormalizer首次实现了可扩展的多模态自动形式化方法，能统一处理从经典力学（哈密顿体系）、相对论、量子力学到热力学的自动形式化，为连接感知与形式推理提供了新框架。

Abstract: Autoformalization, which translates natural language mathematics into formal statements to enable machine reasoning, faces fundamental challenges in the wild due to the multimodal nature of the physical world, where physics requires inferring hidden constraints (e.g., mass or energy) from visual elements. To address this, we propose MMFormalizer, which extends autoformalization beyond text by integrating adaptive grounding with entities from real-world mathematical and physical domains. MMFormalizer recursively constructs formal propositions from perceptually grounded primitives through recursive grounding and axiom composition, with adaptive recursive termination ensuring that every abstraction is supported by visual evidence and anchored in dimensional or axiomatic grounding. We evaluate MMFormalizer on a new benchmark, PhyX-AF, comprising 115 curated samples from MathVerse, PhyX, Synthetic Geometry, and Analytic Geometry, covering diverse multimodal autoformalization tasks. Results show that frontier models such as GPT-5 and Gemini-3-Pro achieve the highest compile and semantic accuracy, with GPT-5 excelling in physical reasoning, while geometry remains the most challenging domain. Overall, MMFormalizer provides a scalable framework for unified multimodal autoformalization, bridging perception and formal reasoning. To the best of our knowledge, this is the first multimodal autoformalization method capable of handling classical mechanics (derived from the Hamiltonian), as well as relativity, quantum mechanics, and thermodynamics. More details are available on our project page: MMFormalizer.github.io

</details>


### [120] [Dementia-R1: Reinforced Pretraining and Reasoning from Unstructured Clinical Notes for Real-World Dementia Prognosis](https://arxiv.org/abs/2601.03018)
*Choonghan Kim,Hyunmin Hwang,Hangeol Chang,Jaemin Kim,Jinse Park,Jae-Sung Lim,Jong Chul Ye*

Main category: cs.CL

TL;DR: 本论文提出了Dementia-R1，一种基于强化学习（RL）的模型，用于从非结构化临床文本中预测痴呆症的进展轨迹，并在不同基准和数据集上实现了优异效果。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型虽在临床文本理解上表现出色，但在需要多次随访、症状复杂变动的痴呆症长期预测任务上表现不佳，主要由于缺乏对症状演变注释及RL中稀疏奖励的问题。

Method: 提出冷启动强化学习框架Dementia-R1，先预训练模型预测从患者历史提取的可验证临床指标，提升对疾病进展的推理能力，再进行最终临床状态的决策。

Result: Dementia-R1在真实世界非结构化临床数据集上达到了77.03%的F1分数。在ADNI基准上，7B参数量模型性能可比GPT-4o，能有效捕捉认知波动轨迹。

Conclusion: 通过结合强化学习与冷启动策略，新方法提升了痴呆症长期预测的能力，为患者的疾病进展预测和管理提供了有力工具。

Abstract: While Large Language Models (LLMs) have shown strong performance on clinical text understanding, they struggle with longitudinal prediction tasks such as dementia prognosis, which require reasoning over complex, non-monotonic symptom trajectories across multiple visits. Standard supervised training lacks explicit annotations for symptom evolution, while direct Reinforcement Learning (RL) is hindered by sparse binary rewards. To address this challenge, we introduce Dementia-R1, an RL-based framework for longitudinal dementia prognosis from unstructured clinical notes. Our approach adopts a Cold-Start RL strategy that pre-trains the model to predict verifiable clinical indices extracted from patient histories, enhancing the capability to reason about disease progression before determining the final clinical status. Extensive experiments demonstrate that Dementia-R1 achieves an F1 score of 77.03% on real-world unstructured clinical datasets. Notably, on the ADNI benchmark, our 7B model rivals GPT-4o, effectively capturing fluctuating cognitive trajectories. Code is available at https://anonymous.4open.science/r/dementiar1-CDB5

</details>


### [121] [MedDialogRubrics: A Comprehensive Benchmark and Evaluation Framework for Multi-turn Medical Consultations in Large Language Models](https://arxiv.org/abs/2601.03023)
*Lecheng Gong,Weimin Fang,Ting Yang,Dongjie Tao,Chunxiao Guo,Peng Wei,Bo Xie,Jinqun Guan,Zixiao Chen,Fang Shi,Jinjie Gu,Junwei Liu*

Main category: cs.CL

TL;DR: 该论文提出了MedDialogRubrics基准集，用以系统评估和提升医疗大模型的多轮诊断能力，并指出当前主流模型仍然面临众多挑战。


<details>
  <summary>Details</summary>
Motivation: 当前医疗大模型在信息获取和诊断推理方面缺乏经过严格评估的基准体系，现有评估指标和框架存在不足，需要新的工具来更准确地测评模型能力，促进医疗对话系统的安全性与有效性。

Method: 作者构建了包含5200个合成病例和超6万个细粒度评价指标的MedDialogRubrics基准。使用多智能体系统在不涉及真实电子病历的前提下，基于疾病知识自动生成病例，解决了数据隐私与治理问题。同时设计了具备动态纠错能力的虚拟病人角色，保障对话病例的连贯和临床可信度。还提出了结合LLM和专家打分、多层次证据医学指南采集的评价指标生成流水线。

Result: 对多个主流模型进行全方位评估，发现它们在多项重要指标上均存在显著短板，难以胜任复杂医疗多轮会话任务。实验验证了当前技术的局限性。

Conclusion: 作者认为简单微调底层模型并不能显著提升医疗对话质量，亟需在对话管理架构等核心领域取得突破，推动医疗AI系统切实提升。

Abstract: Medical conversational AI (AI) plays a pivotal role in the development of safer and more effective medical dialogue systems. However, existing benchmarks and evaluation frameworks for assessing the information-gathering and diagnostic reasoning abilities of medical large language models (LLMs) have not been rigorously evaluated. To address these gaps, we present MedDialogRubrics, a novel benchmark comprising 5,200 synthetically constructed patient cases and over 60,000 fine-grained evaluation rubrics generated by LLMs and subsequently refined by clinical experts, specifically designed to assess the multi-turn diagnostic capabilities of LLM. Our framework employs a multi-agent system to synthesize realistic patient records and chief complaints from underlying disease knowledge without accessing real-world electronic health records, thereby mitigating privacy and data-governance concerns. We design a robust Patient Agent that is limited to a set of atomic medical facts and augmented with a dynamic guidance mechanism that continuously detects and corrects hallucinations throughout the dialogue, ensuring internal coherence and clinical plausibility of the simulated cases. Furthermore, we propose a structured LLM-based and expert-annotated rubric-generation pipeline that retrieves Evidence-Based Medicine (EBM) guidelines and utilizes the reject sampling to derive a prioritized set of rubric items ("must-ask" items) for each case. We perform a comprehensive evaluation of state-of-the-art models and demonstrate that, across multiple assessment dimensions, current models face substantial challenges. Our results indicate that improving medical dialogue will require advances in dialogue management architectures, not just incremental tuning of the base-model.

</details>


### [122] [LittiChoQA: Literary Texts in Indic Languages Chosen for Question Answering](https://arxiv.org/abs/2601.03025)
*Aarya Khandelwal,Ritwik Mishra,Rajiv Ratn Shah*

Main category: cs.CL

TL;DR: 本论文针对印度甘地平原多语种文学文本的长上下文问答（QA）任务，提出了LittiChoQA数据集，并在多种多语言大模型上进行了实验。


<details>
  <summary>Details</summary>
Motivation: 现有文学文本长上下文问答资源，尤其是印度本地语言领域十分稀缺，限制了大语言模型在这些场景下的能力评估与模型发展。

Method: 作者构建了LittiChoQA，这是目前涵盖印度甘地平原多语言的最大文学问答数据集，包含27万多对自动生成的问题与答案，且问题类型均衡。随后，作者在多个多语言大模型（如Krutrim-2）上，对非事实性、抽象性问答进行评测，同时比较了全上下文与缩短上下文两种设置。

Result: 实验结果显示，采用全上下文微调可以获得最佳的分词和语义分数（如Krutrim-2模型的语义分为76.1），但缩短上下文可以显著提高处理效率。在缩短上下文的具体实现中，如选择答案段落可得分74.9，向量检索方式得分71.4。

Conclusion: LittiChoQA为多语言文学问答研究提供了重要资源，相关大模型在该任务下的性能与效率存在权衡。此外，Krutrim-2模型在所有设置下表现领先。

Abstract: Long-context question answering (QA) over literary texts poses significant challenges for modern large language models, particularly in low-resource languages. We address the scarcity of long-context QA resources for Indic languages by introducing LittiChoQA, the largest literary QA dataset to date covering many languages spoken in the Gangetic plains of India. The dataset comprises over 270K automatically generated question-answer pairs with a balanced distribution of factoid and non-factoid questions, generated from naturally authored literary texts collected from the open web. We evaluate multiple multilingual LLMs on non-factoid, abstractive QA, under both full-context and context-shortened settings. Results demonstrate a clear trade-off between performance and efficiency: full-context fine-tuning yields the highest token-level and semantic-level scores, while context shortening substantially improves throughput. Among the evaluated models, Krutrim-2 achieves the strongest performance, obtaining a semantic score of 76.1 with full context. While, in shortened context settings it scores 74.9 with answer paragraph selection and 71.4 with vector-based retrieval. Qualitative evaluations further corroborate these findings.

</details>


### [123] [Reducing Hallucinations in LLMs via Factuality-Aware Preference Learning](https://arxiv.org/abs/2601.03027)
*Sindhuja Chaduvula,Ahmed Y. Radwan,Azib Farooq,Yani Ioannou,Shaina Raza*

Main category: cs.CL

TL;DR: 本文提出F-DPO（事实意识直接偏好优化）以减少大模型的幻觉问题并提升事实性，方法简单高效。


<details>
  <summary>Details</summary>
Motivation: 当前RLHF和DPO等主流偏好对齐方法虽然提升了模型指令遵循性，但在偏好判断过程中容易奖励流畅性和自信度，导致对事实性把控不够、幻觉现象加剧，需要有更有效的方法提升事实性能力。

Method: 提出F-DPO方法，为DPO增加两步扩展：1）标签翻转，保证选中响应的事实性不低于被拒响应；2）事实性感知边际，突出事实性差异明显的样本；同时，使用带二元事实标签及人工合成幻觉样本的数据进行训练，无需奖励模型、逐词标注或多阶段训练。

Result: 在1B-14B范围的七个主流开源大模型上，F-DPO均显著减少幻觉率、提升事实正确性。例如，在Qwen3-8B模型上幻觉率降低五倍，事实性得分提升50%；在TruthfulQA基准上，Qwen2.5-14B的两个准确率指标较基线有显著提升。

Conclusion: F-DPO是一种简洁、事实性敏感的偏好对齐新范式，不增加训练复杂度即可有效减轻大模型的幻觉，提升事实性，对实际应用更为可靠。

Abstract: Preference alignment methods such as RLHF and Direct Preference Optimization (DPO) improve instruction following, but they can also reinforce hallucinations when preference judgments reward fluency and confidence over factual correctness. We introduce F-DPO (Factuality-aware Direct Preference Optimization), a simple extension of DPO that uses only binary factuality labels. F-DPO (i) applies a label-flipping transformation that corrects misordered preference pairs so the chosen response is never less factual than the rejected one, and (ii) adds a factuality-aware margin that emphasizes pairs with clear correctness differences, while reducing to standard DPO when both responses share the same factuality. We construct factuality-aware preference data by augmenting DPO pairs with binary factuality indicators and synthetic hallucinated variants. Across seven open-weight LLMs (1B-14B), F-DPO consistently improves factuality and reduces hallucination rates relative to both base models and standard DPO. On Qwen3-8B, F-DPO reduces hallucination rates by five times (from 0.424 to 0.084) while improving factuality scores by 50 percent (from 5.26 to 7.90). F-DPO also generalizes to out-of-distribution benchmarks: on TruthfulQA, Qwen2.5-14B achieves plus 17 percent MC1 accuracy (0.500 to 0.585) and plus 49 percent MC2 accuracy (0.357 to 0.531). F-DPO requires no auxiliary reward model, token-level annotations, or multi-stage training.

</details>


### [124] [NorwAI's Large Language Models: Technical Report](https://arxiv.org/abs/2601.03034)
*Jon Atle Gulla,Peng Liu,Lemei Zhang*

Main category: cs.CL

TL;DR: 该论文介绍了NorLLM团队开发的，专为挪威语和其他斯堪的纳维亚语言设计的大语言模型（NorwAI LLM）家族。这些模型采用多种Transformer架构，并针对挪威语定制训练和微调，覆盖大量数据，支持实际应用。


<details>
  <summary>Details</summary>
Motivation: 挪威语在NLP领域最重要的突破中依然处于资源稀缺地位，缺乏高质量的大语言模型。该团队旨在通过开发本地化、适应性更强的大模型，提升挪威及斯堪的纳维亚语言在AI应用中的表现。

Method: 构建GPT、Mistral等多种Transformer模型，采用挪威语扩展分词器，自零开始或持续预训练（覆盖250亿至884.5亿tokens），结合高级后训练策略。部分模型进行指令调优，提升交互式应用能力，并详细记录架构、数据、分词、微调与部署过程。

Result: 所开发的指令调优模型（如Mistral-7B-Instruct和Mixtral-8x7B-Instruct）具备优秀的助手能力，适合交互式和领域特定任务，在多种真实场景下展现较强适应性。

Conclusion: 该系列大模型为挪威及北欧地区AI研究和实验应用提供了重要资源，模型已开放给本地组织、企业和学生使用，为本地化自然语言处理技术发展奠定基础。

Abstract: Norwegian, spoken by approximately five million people, remains underrepresented in many of the most significant breakthroughs in Natural Language Processing (NLP). To address this gap, the NorLLM team at NorwAI has developed a family of models specifically tailored to Norwegian and other Scandinavian languages, building on diverse Transformer-based architectures such as GPT, Mistral, Llama2, Mixtral and Magistral. These models are either pretrained from scratch or continually pretrained on 25B - 88.45B tokens, using a Norwegian-extended tokenizer and advanced post-training strategies to optimize performance, enhance robustness, and improve adaptability across various real-world tasks. Notably, instruction-tuned variants (e.g., Mistral-7B-Instruct and Mixtral-8x7B-Instruct) showcase strong assistant-style capabilities, underscoring their potential for practical deployment in interactive and domain-specific applications. The NorwAI large language models are openly available to Nordic organizations, companies and students for both research and experimental use. This report provides detailed documentation of the model architectures, training data, tokenizer design, fine-tuning strategies, deployment, and evaluations.

</details>


### [125] [BaseCal: Unsupervised Confidence Calibration via Base Model Signals](https://arxiv.org/abs/2601.03042)
*Hexiang Tan,Wanli Yang,Junwei Zhang,Xin Chen,Rui Tang,Du Su,Jingang Wang,Yuanzhuo Wang,Fei Sun,Xueqi Cheng*

Main category: cs.CL

TL;DR: 本文发现后训练的大型语言模型（PoLLMs）通常会产生过度自信的输出，而其基础模型（base LLMs）通常校准良好。为此，提出一种利用基础模型校准后训练模型置信度的新方法BaseCal，有效降低置信度误差。


<details>
  <summary>Details</summary>
Motivation: 越来越多后训练的LLMs（例如经过指令微调或蒸馏的模型）应用于实际，但它们的置信度经常过度高估，影响用户信任和下游任务安全性。基础LLMs通常校准良好，因此作者希望利用基础模型来改善后训练模型的置信度校准。

Method: 提出BaseCal方法，包含两种实现：1）BaseCal-ReEval：将PoLLM输出送回基础LLM评估其置信度，但推理开销较高；2）BaseCal-Proj：训练一个轻量级投影头，将PoLLM隐藏状态映射回基础LLM，利用基础LLM的输出层获得校准置信度。该方法无需标注数据，无需修改模型，仅通过未标注数据即可使用。

Result: 作者在五个数据集、三种LLM体系上测试，BaseCal显著改善PoLLM置信度校准，平均将Expected Calibration Error (ECE) 降低了42.90%，效果优于已有的无监督基线方法。

Conclusion: BaseCal是一种简单高效、无监督且即插即用的后训练LLM置信度校准方案，能显著提升模型输出可信度，为实际部署的大型语言模型安全性与可信度提供保障。

Abstract: Reliable confidence is essential for trusting the outputs of LLMs, yet widely deployed post-trained LLMs (PoLLMs) typically compromise this trust with severe overconfidence. In contrast, we observe that their corresponding base LLMs often remain well-calibrated. This naturally motivates us to calibrate PoLLM confidence using the base LLM as a reference. This work proposes two ways to achieve this. A straightforward solution, BaseCal-ReEval, evaluates PoLLM's responses by feeding them into the base LLM to get average probabilities as confidence. While effective, this approach introduces additional inference overhead. To address this, we propose BaseCal-Proj, which trains a lightweight projection to map the final-layer hidden states of PoLLMs back to those of their base LLMs. These projected states are then processed by the base LLM's output layer to derive base-calibrated confidence for PoLLM's responses. Notably, BaseCal is an unsupervised, plug-and-play solution that operates without human labels or LLM modifications. Experiments across five datasets and three LLM families demonstrate the effectiveness of BaseCal, reducing Expected Calibration Error (ECE) by an average of 42.90\% compared to the best unsupervised baselines.

</details>


### [126] [Lil: Less is Less When Applying Post-Training Sparse-Attention Algorithms in Long-Decode Stage](https://arxiv.org/abs/2601.03043)
*Junhao Hu,Fangze Li,Mingtao Xu,Feifan Meng,Shiju Zhao,Tiancheng Hu,Ting Peng,Anmin Liu,Wenrui Huang,Chenxu Liu,Ziyue Hua,Tao Xie*

Main category: cs.CL

TL;DR: 论文揭示稀疏注意力机制在减少解码复杂度时可能导致信息损失，从而反而增加总体计算和时间开销，并提出了通过早停算法来缓解这一问题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）应用规模扩大，模型推理过程中的效率问题变得尤为突出，尤其是在解码阶段。现有稀疏注意力方法虽旨在降低解码开销，但是否真的优化了端到端性能值得进一步探讨。

Method: 本论文通过理论分析和实证实验，阐释了稀疏注意力可能带来的“Less is Less（Lil）”效应，即由于信息损失导致生成序列变长，结果增加总体复杂度。为此，作者提出了一种早停算法，能够在发现信息损失大于信息增益时自动终止稀疏解码。

Result: 早停算法在各种高推理需求的基准测试中，能够减少高达90%的token消耗，而准确率损失低于2%。

Conclusion: 尽管稀疏注意力目标为提升推理效率，但在实际端到端应用中可能适得其反。引入早停机制可以有效缓解信息损失带来的复杂度上升，实现更高效的推理。

Abstract: Large language models (LLMs) demonstrate strong capabilities across a wide range of complex tasks and are increasingly deployed at scale, placing significant demands on inference efficiency. Prior work typically decomposes inference into prefill and decode stages, with the decode stage dominating total latency. To reduce time and memory complexity in the decode stage, a line of work introduces sparse-attention algorithms. In this paper, we show, both empirically and theoretically, that sparse attention can paradoxically increase end-to-end complexity: information loss often induces significantly longer sequences, a phenomenon we term ``Less is Less'' (Lil). To mitigate the Lil problem, we propose an early-stopping algorithm that detects the threshold where information loss exceeds information gain during sparse decoding. Our early-stopping algorithm reduces token consumption by up to 90% with a marginal accuracy degradation of less than 2% across reasoning-intensive benchmarks.

</details>


### [127] [Temporal Graph Network: Hallucination Detection in Multi-Turn Conversation](https://arxiv.org/abs/2601.03051)
*Vidhi Rathore,Sambu Aneesh,Himanshu Singh*

Main category: cs.CL

TL;DR: 该论文提出了一种基于图结构的方法，用于检测对话级别的幻觉（错误或虚假的生成内容），通过对多轮对话建模以提升检测效果，性能优于已有方法。


<details>
  <summary>Details</summary>
Motivation: 目前会话AI常常在多轮对话中因为上下文变化而产生幻觉，现有检测方法对对话整体的建模较弱，难以准确识别复杂情境下的幻觉。需要能够更有效整合对话上下文和实体关联的信息，提升检测精度。

Method: 将整个对话表示为时间图，每轮对话为一个节点，通过句子Transformer编码。节点间两种连接方式：（1）共享实体边——同一实体被引用的对话轮之间相连；（2）时间边——对话轮在顺序上相连。采用消息传递机制更新节点嵌入，最后通过注意力池化形成整体对话表示，输入分类器判断幻觉类型。

Result: 提出的方法在检测对话幻觉方面，相比于现有方法表现略有提升。注意力机制可用于解释模型决策过程。

Conclusion: 基于图结构和注意力池化的建模方法能够更好检测多轮会话AI中的幻觉，并提供一定解释性，对下一步会话安全及可靠性提升有积极意义。

Abstract: Hallucinations can be produced by conversational AI systems, particularly in multi-turn conversations where context changes and contradictions may eventually surface. By representing the entire conversation as a temporal graph, we present a novel graph-based method for detecting dialogue-level hallucinations. Our framework models each dialogue as a node, encoding it using a sentence transformer. We explore two different ways of connectivity: i) shared-entity edges, which connect turns that refer to the same entities; ii) temporal edges, which connect contiguous turns in the conversation. Message-passing is used to update the node embeddings, allowing flow of information between related nodes. The context-aware node embeddings are then combined using attention pooling into a single vector, which is then passed on to a classifier to determine the presence and type of hallucinations. We demonstrate that our method offers slightly improved performance over existing methods. Further, we show the attention mechanism can be used to justify the decision making process. The code and model weights are made available at: https://github.com/sambuaneesh/anlp-project.

</details>


### [128] [Detecting Hallucinations in Retrieval-Augmented Generation via Semantic-level Internal Reasoning Graph](https://arxiv.org/abs/2601.03052)
*Jianpeng Hu,Yanzeng Li,Jialun Zhong,Wenfa Qi,Lei Zou*

Main category: cs.CL

TL;DR: 本文提出了一种基于语义级内部推理图的新方法，用于检测RAG系统中的faithfulness幻觉，并在多个基准上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 虽然RAG系统能减少事实性幻觉，但faithfulness幻觉仍广泛存在。以往的方法未能细致刻画模型内部推理过程，导致难以准确检测此类幻觉。

Method: 将层次相关传播算法从token级推广到语义级，构建基于归因向量的内部推理图，获得模型推理语义依赖的精确表示，并设计结合小型预训练语言模型的检测框架，可动态调整正确样本的通过率。

Result: 在RAGTruth和Dolly-15k两个数据集上，提出的方法在幻觉检测任务中整体表现优于现有主流方法。

Conclusion: 语义级内部推理图法能更好检测和解释LLM-RAG系统中的faithfulness幻觉，有潜力提升生成信息的可靠性。

Abstract: The Retrieval-augmented generation (RAG) system based on Large language model (LLM) has made significant progress. It can effectively reduce factuality hallucinations, but faithfulness hallucinations still exist. Previous methods for detecting faithfulness hallucinations either neglect to capture the models' internal reasoning processes or handle those features coarsely, making it difficult for discriminators to learn. This paper proposes a semantic-level internal reasoning graph-based method for detecting faithfulness hallucination. Specifically, we first extend the layer-wise relevance propagation algorithm from the token level to the semantic level, constructing an internal reasoning graph based on attribution vectors. This provides a more faithful semantic-level representation of dependency. Furthermore, we design a general framework based on a small pre-trained language model to utilize the dependencies in LLM's reasoning for training and hallucination detection, which can dynamically adjust the pass rate of correct samples through a threshold. Experimental results demonstrate that our method achieves better overall performance compared to state-of-the-art baselines on RAGTruth and Dolly-15k.

</details>


### [129] [Do LLMs Encode Functional Importance of Reasoning Tokens?](https://arxiv.org/abs/2601.03066)
*Janvijay Singh,Dilek Hakkani-Tür*

Main category: cs.CL

TL;DR: 本文提出了一种贪婪剪枝方法，能够在保持模型输出概率的前提下，删除推理过程中对最终答案影响较小的token，从而生成更短、更有效的推理链。通过在蒸馏框架下测试，学生模型在使用经过剪枝的推理链训练后，表现优于用前沿模型压缩监督的基线。分析还发现剪枝有系统性规律，且注意力得分可预测token被剪枝顺序，说明模型内部确实编码了token的功能性重要性。


<details>
  <summary>Details</summary>
Motivation: 以往精简推理链的工作要么依赖概率采样等启发式方法，要么仰赖高阶模型直接监督，但很少关注模型本身是否已在token层面编码了对答案生成有功能贡献的成分。本文旨在填补这一空白，探索大模型内部对于推理token重要性的编码情况。

Method: 作者提出了一种贪婪剪枝算法，反复删除每个最不影响生成概率（模型似然）的推理token，并对生成链长加以控制。随后将剪枝后的推理链用于知识蒸馏，训练学生模型，并与压缩监督等基线进行比较。同时分析剪枝过程与注意力模式的关系。

Result: 结果显示，使用经过贪婪剪枝后的推理链作为训练数据的学生模型，在链长相同条件下，性能超过了传统前沿模型压缩基线。此外，剪枝过程中出现了系统性的token剔除模式，且token的注意力得分能有效预测被剪顺序。

Conclusion: 本文的方法不仅有效提升了蒸馏模型的表现，还揭示了复杂大模型内部存在token功能贡献结构。注意力等内部指标可用于推断token对于最终推理结果的重要性，有助于今后模型可解释性和效率研究。

Abstract: Large language models solve complex tasks by generating long reasoning chains, achieving higher accuracy at the cost of increased computational cost and reduced ability to isolate functionally relevant reasoning. Prior work on compact reasoning shortens such chains through probabilistic sampling, heuristics, or supervision from frontier models, but offers limited insight into whether models internally encode token-level functional importance for answer generation. We address this gap diagnostically and propose greedy pruning, a likelihood-preserving deletion procedure that iteratively removes reasoning tokens whose removal minimally degrades model likelihood under a specified objective, yielding length-controlled reasoning chains. We evaluate pruned reasoning in a distillation framework and show that students trained on pruned chains outperform a frontier-model-supervised compression baseline at matched reasoning lengths. Finally, our analysis reveals systematic pruning patterns and shows that attention scores can predict greedy pruning ranks, further suggesting that models encode a nontrivial functional importance structure over reasoning tokens.

</details>


### [130] [Learning to Diagnose and Correct Moral Errors: Towards Enhancing Moral Sensitivity in Large Language Models](https://arxiv.org/abs/2601.03079)
*Bocheng Chen,Han Zi,Xi Chen,Xitong Zhang,Kristen Johnson,Guangliang Liu*

Main category: cs.CL

TL;DR: 本文提出了两种实用推理方法，有效提升大型语言模型（LLM）的道德敏感性，通过诊断和纠正道德错误，使LLM在道德相关任务中表现更优。


<details>
  <summary>Details</summary>
Motivation: 当前大多数方法关注如何让LLM与人类价值观对齐，但如何增强其道德敏感性一直极具挑战性。因此，作者旨在提升LLM察觉和处理日常道德问题的能力。

Method: 作者设计了两种实用推理方法，能够辅助LLM识别输入的道德良善性或危险性，并能主动纠正道德错误。这些方法以推理负载为基础，提供统一、原则化的推理框架，而不是仅关注表面语义多样性。

Result: 实验证实，这两种推理方法显著提升了LLM的道德敏感性，并在多个道德相关的评测基准上取得了很好的成绩。

Conclusion: 实用推理方法为LLM的道德敏感性提升提供了有效思路，推动了道德智能化的发展。

Abstract: Moral sensitivity is fundamental to human moral competence, as it guides individuals in regulating everyday behavior. Although many approaches seek to align large language models (LLMs) with human moral values, how to enable them morally sensitive has been extremely challenging. In this paper, we take a step toward answering the question: how can we enhance moral sensitivity in LLMs? Specifically, we propose two pragmatic inference methods that faciliate LLMs to diagnose morally benign and hazardous input and correct moral errors, whereby enhancing LLMs' moral sensitivity. A central strength of our pragmatic inference methods is their unified perspective: instead of modeling moral discourses across semantically diverse and complex surface forms, they offer a principled perspective for designing pragmatic inference procedures grounded in their inferential loads. Empirical evidence demonstrates that our pragmatic methods can enhance moral sensitivity in LLMs and achieves strong performance on representative morality-relevant benchmarks.

</details>


### [131] [Grad-ELLM: Gradient-based Explanations for Decoder-only LLMs](https://arxiv.org/abs/2601.03089)
*Xin Huang,Antoni B. Chan*

Main category: cs.CL

TL;DR: 本论文提出了一种针对解码器型LLM（大型语言模型）的新的归因方法Grad-ELLM，并引入了两种新的评估指标。在多个任务和模型上实验，Grad-ELLM归因的忠实度优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有输入归因方法多为模型无关，未针对transformer架构做优化，且对LLM的归因透明度和忠实度有限。因此需要专为LLM设计、提升归因忠实度的方法。

Method: 提出了Grad-ELLM，它利用梯度和注意力机制的结合，通过输出logit对注意力层梯度获取通道重要性，以及从注意力图获取空间重要性，综合生成热力图，不需要修改模型结构。此外提出了π-Soft-NC和π-Soft-NS两个公平衡量忠实度的新指标。

Result: 在情感分类、问答和开放生成等多个任务与不同模型上评测，Grad-ELLM的归因忠实度明显优于现有其他方法。

Conclusion: Grad-ELLM是一种无缝且高效的新归因方法，适用于当前主流LLM，并且所提出的新指标能够更公平地评估方法的有效性。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse tasks, yet their black-box nature raises concerns about transparency and faithfulness. Input attribution methods aim to highlight each input token's contributions to the model's output, but existing approaches are typically model-agnostic, and do not focus on transformer-specific architectures, leading to limited faithfulness. To address this, we propose Grad-ELLM, a gradient-based attribution method for decoder-only transformer-based LLMs. By aggregating channel importance from gradients of the output logit with respect to attention layers and spatial importance from attention maps, Grad-ELLM generates heatmaps at each generation step without requiring architectural modifications. Additionally, we introduce two faithfulneses metrics $π$-Soft-NC and $π$-Soft-NS, which are modifications of Soft-NC/NS that provide fairer comparisons by controlling the amount of information kept when perturbing the text. We evaluate Grad-ELLM on sentiment classification, question answering, and open-generation tasks using different models. Experiment results show that Grad-ELLM consistently achieves superior faithfulness than other attribution methods.

</details>


### [132] [Who Laughs with Whom? Disentangling Influential Factors in Humor Preferences across User Clusters and LLMs](https://arxiv.org/abs/2601.03103)
*Soichiro Murakami,Hidetaka Kamigaito,Hiroya Takamura,Manabu Okumura*

Main category: cs.CL

TL;DR: 本研究探讨了在日本Oogiri幽默游戏中，不同用户群的幽默偏好如何影响大语言模型（LLM）对幽默的判断，采用集群、权重建模和提示控制LLM倾向于特定偏好，验证了LLM可表现出类似特定人群偏好的能力。


<details>
  <summary>Details</summary>
Motivation: 幽默的评价因个体和文化差异而极为复杂，现有大语言模型对幽默理解有局限，研究动机在于探索LLM能否识别并模拟多样化的幽默偏好。

Method: 采用Oogiri游戏用户的投票日志，对用户进行聚类，通过Bradley-Terry-Luce模型为不同用户群估算可解释的幽默偏好因素权重，并用prompt让LLM进行幽默对比判断。

Result: 用户集群展现出各自独特的幽默偏好模式，部分LLM的判断结果与特定集群较为接近；通过persona提示方法，能够诱导LLM表现出更接近某一集群的偏好。

Conclusion: LLM在幽默偏好的模拟方面具备可调性和一定精度，通过合适提示可引导其偏好特定用户群，助力实现个性化幽默推荐与理解。

Abstract: Humor preferences vary widely across individuals and cultures, complicating the evaluation of humor using large language models (LLMs). In this study, we model heterogeneity in humor preferences in Oogiri, a Japanese creative response game, by clustering users with voting logs and estimating cluster-specific weights over interpretable preference factors using Bradley-Terry-Luce models. We elicit preference judgments from LLMs by prompting them to select the funnier response and found that user clusters exhibit distinct preference patterns and that the LLM results can resemble those of particular clusters. Finally, we demonstrate that, by persona prompting, LLM preferences can be directed toward a specific cluster. The scripts for data collection and analysis will be released to support reproducibility.

</details>


### [133] [Discovering and Causally Validating Emotion-Sensitive Neurons in Large Audio-Language Models](https://arxiv.org/abs/2601.03115)
*Xiutian Zhao,Björn Schuller,Berrak Sisman*

Main category: cs.CL

TL;DR: 本论文首次在大型音频语言模型中探究了情感敏感神经元（ESNs），并提供了有力的因果证据，揭示这些神经元对情感识别具有实际作用。


<details>
  <summary>Details</summary>
Motivation: 尽管情感是口头交流的核心维度，但目前尚未清楚大型音频语言模型（LALMs）内部是如何编码情感信息的。本文旨在填补该知识空白，实现对模型情感处理机制的细粒度理解。

Method: 作者在Qwen2.5-Omni、Kimi-Audio和Audio Flamingo 3等主流开源模型中，分析和比较了四种神经元选择方法（基于频率、熵、幅度和对比度），并通过推理期间的干预方法（神经元抑制与增强），考察了模型识别不同情感时相关神经元的因果作用。还研究了ESNs在模型层次中的分布与跨数据集的泛化。

Result: 实验发现，对特定情感选出的神经元进行抑制显著削弱了对该情感的识别能力，而增强则导致模型预测向目标情感转移。这些影响随干预强度系统变化，且所需识别数据量较小。此外，ESNs在层次上呈现非均匀聚类，并具备部分跨数据集迁移能力。

Conclusion: 论文以因果和神经元级别解释了LALMs中的情感决策机制，证实了可通过目标神经元干预实现情感可控的模型行为，为后续情感相关AI系统的解释和控制提供了理论与方法支持。

Abstract: Emotion is a central dimension of spoken communication, yet, we still lack a mechanistic account of how modern large audio-language models (LALMs) encode it internally. We present the first neuron-level interpretability study of emotion-sensitive neurons (ESNs) in LALMs and provide causal evidence that such units exist in Qwen2.5-Omni, Kimi-Audio, and Audio Flamingo 3. Across these three widely used open-source models, we compare frequency-, entropy-, magnitude-, and contrast-based neuron selectors on multiple emotion recognition benchmarks. Using inference-time interventions, we reveal a consistent emotion-specific signature: ablating neurons selected for a given emotion disproportionately degrades recognition of that emotion while largely preserving other classes, whereas gain-based amplification steers predictions toward the target emotion. These effects arise with modest identification data and scale systematically with intervention strength. We further observe that ESNs exhibit non-uniform layer-wise clustering with partial cross-dataset transfer. Taken together, our results offer a causal, neuron-level account of emotion decisions in LALMs and highlight targeted neuron interventions as an actionable handle for controllable affective behaviors.

</details>


### [134] [ToxiGAN: Toxic Data Augmentation via LLM-Guided Directional Adversarial Generation](https://arxiv.org/abs/2601.03121)
*Peiran Li,Jan Fillies,Adrian Paschke*

Main category: cs.CL

TL;DR: 该论文提出了一种名为ToxiGAN的新型文本增强方法，通过结合对抗生成与大语言模型的语义指导，有效提升了毒性文本分类的鲁棒性，实验结果优于传统和现有方法。


<details>
  <summary>Details</summary>
Motivation: 毒性文本分类任务中，数据不平衡与类别间分布偏斜导致模型表现不佳，现有文本增强方法难以实现可控且类别特异的数据扩充。

Method: 提出ToxiGAN框架，将GAN（生成对抗网络）和大语言模型结合，采用两步定向训练策略，并动态选取由LLM生成的中性文本作为“语义压舱石”。毒性样本在训练时被优化以远离这些中性示例，增强类别对比信号。

Result: 在四个仇恨言论基准数据集上，ToxiGAN在macro-F1和hate-F1指标上均取得最优平均性能，超越传统和基于LLM的增强方法。消融分析和敏感性测试也验证了方法中各关键模块的有效性。

Conclusion: ToxiGAN通过引入语义压舱石和定向训练机制，有效缓解了GAN文本增强的常见问题，显著提升了毒性文本分类的鲁棒性和性能。

Abstract: Augmenting toxic language data in a controllable and class-specific manner is crucial for improving robustness in toxicity classification, yet remains challenging due to limited supervision and distributional skew. We propose ToxiGAN, a class-aware text augmentation framework that combines adversarial generation with semantic guidance from large language models (LLMs). To address common issues in GAN-based augmentation such as mode collapse and semantic drift, ToxiGAN introduces a two-step directional training strategy and leverages LLM-generated neutral texts as semantic ballast. Unlike prior work that treats LLMs as static generators, our approach dynamically selects neutral exemplars to provide balanced guidance. Toxic samples are explicitly optimized to diverge from these exemplars, reinforcing class-specific contrastive signals. Experiments on four hate speech benchmarks show that ToxiGAN achieves the strongest average performance in both macro-F1 and hate-F1, consistently outperforming traditional and LLM-based augmentation methods. Ablation and sensitivity analyses further confirm the benefits of semantic ballast and directional training in enhancing classifier robustness.

</details>


### [135] [The Anatomy of Conversational Scams: A Topic-Based Red Teaming Analysis of Multi-Turn Interactions in LLMs](https://arxiv.org/abs/2601.03134)
*Xiangzhe Yuan,Zhenhao Zhang,Haoming Tang,Siying Hu*

Main category: cs.CL

TL;DR: 论文系统性研究了大模型在多轮对话中的诈骗风险，发现多轮互动下安全风险与单轮评估显著不同。


<details>
  <summary>Details</summary>
Motivation: 当前对大语言模型（LLM）的安全评估主要集中在单轮对话，但现实应用中多轮对话更容易被用作诈骗等有害用途，因此需要深入探究多轮对话下的安全性。

Method: 通过设计受控的LLM与LLM对话仿真框架，涵盖多种多轮诈骗场景，对8个主流中英大模型进行测试。对对话结果进行定性注释，分析攻击者战术、防御方式和系统失误类型等。

Result: 结果发现，诈骗互动常见递进升级模式，防御方多采用核查、拖延策略。互动失败通常源于安全防护机制触发和角色身份不稳定。

Conclusion: 多轮对话下的大模型互动安全性是影响模型部署的重要且独特的维度，值得作为独立安全风险加以关注和防护。

Abstract: As LLMs gain persuasive agentic capabilities through extended dialogues, they introduce novel risks in multi-turn conversational scams that single-turn safety evaluations fail to capture. We systematically study these risks using a controlled LLM-to-LLM simulation framework across multi-turn scam scenarios. Evaluating eight state-of-the-art models in English and Chinese, we analyze dialogue outcomes and qualitatively annotate attacker strategies, defensive responses, and failure modes. Results reveal that scam interactions follow recurrent escalation patterns, while defenses employ verification and delay mechanisms. Furthermore, interactional failures frequently stem from safety guardrail activation and role instability. Our findings highlight multi-turn interactional safety as a critical, distinct dimension of LLM behavior.

</details>


### [136] [Improving Indigenous Language Machine Translation with Synthetic Data and Language-Specific Preprocessing](https://arxiv.org/abs/2601.03135)
*Aashish Dhawan,Christopher Driggers-Ellis,Christan Grant,Daisy Zhe Wang*

Main category: cs.CL

TL;DR: 本文通过使用多语种翻译模型生成合成句对，增强美洲土著低资源语言的平行数据，利用mBART模型提升神经机器翻译效果，并在多个语对上取得了显著的翻译质量提升。


<details>
  <summary>Details</summary>
Motivation: 低资源土著语言缺乏足够的平行语料，严重制约了神经机器翻译的发展。为了缓解数据稀缺问题，作者尝试通过合成句对扩充数据集。

Method: 1. 用高容量多语种翻译模型为美洲土著语言（如瓜拉尼语、西班牙语、克丘亚语－西班牙语）生成合成的双语句对。2. 对现有精洗平行数据和合成数据分别训练多语种mBART模型。3. 采用chrF++作为主要评测指标。4. 对语料集进行正字法归一化和噪音过滤等具体的语言预处理。

Result: 在瓜拉尼语－西班牙语、克丘亚语－西班牙语的机器翻译上，合成数据增强带来了chrF++得分的持续提升。

Conclusion: 合成数据增强对于低资源土著语言的神经机器翻译非常有效，但高度黏着型语言（如艾马拉语）仅依靠通用预处理方法存在局限性，需要更有针对性的处理策略。

Abstract: Low-resource indigenous languages often lack the parallel corpora required for effective neural machine translation (NMT). Synthetic data generation offers a practical strategy for mitigating this limitation in data-scarce settings. In this work, we augment curated parallel datasets for indigenous languages of the Americas with synthetic sentence pairs generated using a high-capacity multilingual translation model. We fine-tune a multilingual mBART model on curated-only and synthetically augmented data and evaluate translation quality using chrF++, the primary metric used in recent AmericasNLP shared tasks for agglutinative languages.
  We further apply language-specific preprocessing, including orthographic normalization and noise-aware filtering, to reduce corpus artifacts. Experiments on Guarani--Spanish and Quechua--Spanish translation show consistent chrF++ improvements from synthetic data augmentation, while diagnostic experiments on Aymara highlight the limitations of generic preprocessing for highly agglutinative languages.

</details>


### [137] [Self-Verification is All You Need To Pass The Japanese Bar Examination](https://arxiv.org/abs/2601.03144)
*Andrew Shin*

Main category: cs.CL

TL;DR: 本文提出的自验证模型在保持日本司法考试原题结构和评分标准的情况下，通过全面实证首次实现了LLM通过考试的重大突破。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型进展迅速，但在高度专业和结构严谨的考试（如日本司法考试）中表现仍不可靠，尤其是在需要复杂答案格式与多命题联合评分的条件下。现有分解真伪判别方法尚未在原始考试框架下系统评估，能否反映真正的考试能力存疑。

Method: 构建了严格匹配日本司法考试真实格式与评分标准的数据集，并在其上训练了自验证模型；系统比较了多智能体推理、多分解判别等方法，并以真实考试评分进行评测。

Result: 自验证模型在原始考试结构和分数体系下超越了官方及格线，首次实现LLM通过该专业考试；其他复杂方法未能达到同等效果。

Conclusion: 高度贴合考试格式的监督和一致性自检至关重要，精心设计的单模型方案能在专业高风险推理场景优于复杂系统。数据和代码已开放。

Abstract: Despite rapid advances in large language models (LLMs), achieving reliable performance on highly professional and structured examinations remains a significant challenge. The Japanese bar examination is a particularly demanding benchmark, requiring not only advanced legal reasoning but also strict adherence to complex answer formats that involve joint evaluation of multiple propositions. While recent studies have reported improvements by decomposing such questions into simpler true--false judgments, these approaches have not been systematically evaluated under the original exam format and scoring scheme, leaving open the question of whether they truly capture exam-level competence. In this paper, we present a self-verification model trained on a newly constructed dataset that faithfully replicates the authentic format and evaluation scale of the exam. Our model is able to exceed the official passing score when evaluated on the actual exam scale, marking the first demonstration, to our knowledge, of an LLM passing the Japanese bar examination without altering its original question structure or scoring rules. We further conduct extensive comparisons with alternative strategies, including multi-agent inference and decomposition-based supervision, and find that these methods fail to achieve comparable performance. Our results highlight the importance of format-faithful supervision and consistency verification, and suggest that carefully designed single-model approaches can outperform more complex systems in high-stakes professional reasoning tasks. Our dataset and codes are publicly available.

</details>


### [138] [Decoupling the Effect of Chain-of-Thought Reasoning: A Human Label Variation Perspective](https://arxiv.org/abs/2601.03154)
*Beiduo Chen,Tiancheng Hu,Caiqi Zhang,Robert Litschko,Anna Korhonen,Barbara Plank*

Main category: cs.CL

TL;DR: 本论文研究了大模型在具有概率模糊性的任务中，用长链式思维（Chain-of-Thought, CoT）推理时，对人类标签变异性的建模能力，发现CoT虽然能提高某些分布对齐效果，但难以对多答案分布进行细致校准。


<details>
  <summary>Details</summary>
Motivation: 多数CoT调优的大模型在唯一答案推理任务中表现优异，但对于需要建模概率性模糊（多种合理答案并存）的任务，人类标注本身就有分布变异性。现有研究缺乏对大模型能否捕捉这些分布模糊性的系统研究。

Method: 作者设计了基于分布的任务和Cross-CoT实验证明，系统地将生成的推理文本和模型自身的先验影响分离开来，以探究各因子对结果的贡献。实验中逐步分析了整个推理过程中CoT与模型先验对准确率和分布排名的作用。

Result: 结果发现，CoT内容对最终判断准确率影响最大（解释了99%的方差），但对多答案下选项的概率性排序贡献较小（分布排名主要受模型固有先验支配，贡献超过80%）。逐步分析也显示CoT提升了对最终答案的决定力但难以细化分布特征。

Conclusion: 长CoT推理在确定单一最优答案方面效果显著，但面对分布型、多模糊答案场景时，难以实现对概率分布的细致校准。因此当前CoT机制适合决策导向而非概率分布建模。

Abstract: Reasoning-tuned LLMs utilizing long Chain-of-Thought (CoT) excel at single-answer tasks, yet their ability to model Human Label Variation--which requires capturing probabilistic ambiguity rather than resolving it--remains underexplored. We investigate this through systematic disentanglement experiments on distribution-based tasks, employing Cross-CoT experiments to isolate the effect of reasoning text from intrinsic model priors. We observe a distinct "decoupled mechanism": while CoT improves distributional alignment, final accuracy is dictated by CoT content (99% variance contribution), whereas distributional ranking is governed by model priors (over 80%). Step-wise analysis further shows that while CoT's influence on accuracy grows monotonically during the reasoning process, distributional structure is largely determined by LLM's intrinsic priors. These findings suggest that long CoT serves as a decisive LLM decision-maker for the top option but fails to function as a granular distribution calibrator for ambiguous tasks.

</details>


### [139] [WebAnchor: Anchoring Agent Planning to Stabilize Long-Horizon Web Reasoning](https://arxiv.org/abs/2601.03164)
*Yu Xinmiao,Zhang Liwen,Feng Xiaocheng,Jiang Yong,Qin Bing,Xie Pengjun,Zhou Jingren*

Main category: cs.CL

TL;DR: 该论文提出了一种名为Anchor-GRPO的两阶段强化学习方法，有效提升了大语言模型在长任务规划中的性能，特别是提升了首步决策对整体策略的影响。实验结果显示，在多个基准任务上该方法优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在基于Web的信息搜索任务中，长时序规划能力不足，尤其首步规划对后续影响大，但被现有强化学习算法忽视。

Method: 提出Anchor-GRPO，两阶段强化学习（RL）架构：第一阶段专注于优化首步规划，采用自博弈经验和人工标注细粒度评判标准；第二阶段执行与初始计划对齐，通过稀疏奖励促进高效工具使用。

Result: 在BrowseComp、BrowseComp-Zh、GAIA和XBench-DeepSearch四个数据集上，Anchor-GRPO在各类（3B至30B）模型中均优于基线方法（GRPO及First-step GRPO），提升了任务完成率和工具使用效率。30B模型在BrowseComp上达到46.0% pass@1，在GAIA上为76.4%。

Conclusion: Anchor-GRPO通过重视首步规划并与执行有效对齐，提升了大模型在长时序Web任务中的表现，具有良好可扩展性，随着模型变大和上下文增长精度持续提升。

Abstract: Large Language Model(LLM)-based agents have shown strong capabilities in web information seeking, with reinforcement learning (RL) becoming a key optimization paradigm. However, planning remains a bottleneck, as existing methods struggle with long-horizon strategies. Our analysis reveals a critical phenomenon, plan anchor, where the first reasoning step disproportionately impacts downstream behavior in long-horizon web reasoning tasks. Current RL algorithms, fail to account for this by uniformly distributing rewards across the trajectory. To address this, we propose Anchor-GRPO, a two-stage RL framework that decouples planning and execution. In Stage 1, the agent optimizes its first-step planning using fine-grained rubrics derived from self-play experiences and human calibration. In Stage 2, execution is aligned with the initial plan through sparse rewards, ensuring stable and efficient tool usage. We evaluate Anchor-GRPO on four benchmarks: BrowseComp, BrowseComp-Zh, GAIA, and XBench-DeepSearch. Across models from 3B to 30B, Anchor-GRPO outperforms baseline GRPO and First-step GRPO, improving task success and tool efficiency. Notably, WebAnchor-30B achieves 46.0% pass@1 on BrowseComp and 76.4% on GAIA. Anchor-GRPO also demonstrates strong scalability, getting higher accuracy as model size and context length increase.

</details>


### [140] [Can Embedding Similarity Predict Cross-Lingual Transfer? A Systematic Study on African Languages](https://arxiv.org/abs/2601.03168)
*Tewodros Kederalah Idris,Prasenjit Mitra,Roald Eiselen*

Main category: cs.CL

TL;DR: 本论文系统评估了五种嵌入相似性指标在跨语言迁移任务中的有效性，并发现部分指标能够可靠预测迁移效果，为低资源非洲语言NLP任务选择源语言提供了具体建议。


<details>
  <summary>Details</summary>
Motivation: 低资源非洲语言NLP模型开发依赖跨语言迁移，但目前缺乏有效工具来选择合适的源语言，因此需要系统性研究各种嵌入相似性指标的预测力。

Method: 作者在三大NLP任务、三种多语言模型和12种非洲语种上，进行了816次跨语言迁移实验，系统比较了五种不同的嵌入相似性指标（如cosine gap、P@1、CSLS、CKA等）对迁移成功的预测能力，并分析了模型间数据汇总对相关性的影响。

Result: cosine gap和基于检索的指标（P@1, CSLS）预测迁移表现较佳（相关系数ρ=0.4~0.6），而CKA基本没有预测作用（ρ≈0.1）；若将不同模型结果混合分析，会导致相关性方向反转（Simpson悖论）。嵌入指标的预测力可与语言类型学资源URIEL媲美。

Conclusion: 该工作为低资源非洲语言的跨语言迁移任务源语言选择提供了实证依据，强调需要针对具体模型进行嵌入指标验证，并提醒注意模型间混合统计产生的悖论影响。

Abstract: Cross-lingual transfer is essential for building NLP systems for low-resource African languages, but practitioners lack reliable methods for selecting source languages. We systematically evaluate five embedding similarity metrics across 816 transfer experiments spanning three NLP tasks, three African-centric multilingual models, and 12 languages from four language families. We find that cosine gap and retrieval-based metrics (P@1, CSLS) reliably predict transfer success ($ρ= 0.4-0.6$), while CKA shows negligible predictive power ($ρ\approx 0.1$). Critically, correlation signs reverse when pooling across models (Simpson's Paradox), so practitioners must validate per-model. Embedding metrics achieve comparable predictive power to URIEL linguistic typology. Our results provide concrete guidance for source language selection and highlight the importance of model-specific analysis.

</details>


### [141] [Maximizing Local Entropy Where It Matters: Prefix-Aware Localized LLM Unlearning](https://arxiv.org/abs/2601.03190)
*Naixin Zhai,Pengyang Shao,Binbin Zheng,Fei Shen,Long Bai,Xun Yang*

Main category: cs.CL

TL;DR: 提出了一种新的大型语言模型（LLMs）机器遗忘方法PALU，能够更有效地删除敏感内容且降低对模型总体性能的影响。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法普遍对LLM输出中的所有token一视同仁，强制对整个词表进行不确定性最大化，导致模型效用不必要损失，并对与内容无关部分也进行了优化，因此需要更精准有效的遗忘机制。

Method: 本文提出了PALU（Prefix-Aware Localized Unlearning）框架，通过在时序和词汇维度进行局部熵最大化，仅针对敏感前缀和关键子空间内的高置信度logits操作以打断模型与敏感内容的生成因果关联，同时避免对整个词表和参数空间的冗余优化。

Result: 实验显示，PALU在遗忘敏感信息的效果和保护通用模型效用方面均优于现有主流方法。

Conclusion: PALU通过更加精准和局部化的优化方式，实现了更高效、更安全的机器遗忘，为提升LLM敏感内容管理能力提供了新思路并具有实际应用前景。

Abstract: Machine unlearning aims to forget sensitive knowledge from Large Language Models (LLMs) while maintaining general utility. However, existing approaches typically treat all tokens in a response indiscriminately and enforce uncertainty over the entire vocabulary. This global treatment results in unnecessary utility degradation and extends optimization to content-agnostic regions. To address these limitations, we propose PALU (Prefix-Aware Localized Unlearning), a framework driven by a local entropy maximization objective across both temporal and vocabulary dimensions. PALU reveals that (i) suppressing the sensitive prefix alone is sufficient to sever the causal generation link, and (ii) flattening only the top-$k$ logits is adequate to maximize uncertainty in the critical subspace. These findings allow PALU to avoid redundant optimization across the full vocabulary and parameter space while minimizing collateral damage to general model performance. Extensive experiments validate that PALU achieves superior forgetting efficacy and utility preservation compared to state-of-the-art baselines.

</details>


### [142] [MemRL: Self-Evolving Agents via Runtime Reinforcement Learning on Episodic Memory](https://arxiv.org/abs/2601.03192)
*Shengtao Zhang,Jiaqian Wang,Ruiwen Zhou,Junwei Liao,Yuchen Feng,Weinan Zhang,Ying Wen,Zhiyu Li,Feiyu Xiong,Yutao Qi,Bo Tang,Muning Wen*

Main category: cs.CL

TL;DR: 本文提出了一种新的记忆增强框架MemRL，使大型语言模型（LLM）能够像人类一样通过回忆和演化经验来自主进化，而无需传统的代价高昂的模型微调。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型虽然推理能力强，但缺乏如人类般主动利用和演化过往经验自我进化的能力。传统微调整需要大量计算且易于遗忘，基于记忆的方法又容易引入无关信息噪音，难以高效利用历史经验。

Method: 作者提出MemRL框架：LLM本身参数冻结，推理能力稳定，外部拓展一个可学习的记忆模块。检索机制分为两个阶段，先根据语义相关性筛选候选记忆，再用强化学习Q值（效用）进行选择，Q值通过环境反馈不断更新优化。

Result: 在HLE、BigCodeBench、ALFWorld、Lifelong Agent Bench等任务上验证，MemRL显著优于现有最先进基线。分析实验显示MemRL能有效解决模型稳定性与记忆可塑性之间的矛盾。

Conclusion: MemRL框架能让语言模型在不修改参数的情况下，通过有效利用记忆，实现持续进步和自我优化，具有广泛的适用前景。

Abstract: The hallmark of human intelligence is the ability to master new skills through Constructive Episodic Simulation-retrieving past experiences to synthesize solutions for novel tasks. While Large Language Models possess strong reasoning capabilities, they struggle to emulate this self-evolution: fine-tuning is computationally expensive and prone to catastrophic forgetting, while existing memory-based methods rely on passive semantic matching that often retrieves noise. To address these challenges, we propose MemRL, a framework that enables agents to self-evolve via non-parametric reinforcement learning on episodic memory. MemRL explicitly separates the stable reasoning of a frozen LLM from the plastic, evolving memory. Unlike traditional methods, MemRL employs a Two-Phase Retrieval mechanism that filters candidates by semantic relevance and then selects them based on learned Q-values (utility). These utilities are continuously refined via environmental feedback in an trial-and-error manner, allowing the agent to distinguish high-value strategies from similar noise. Extensive experiments on HLE, BigCodeBench, ALFWorld, and Lifelong Agent Bench demonstrate that MemRL significantly outperforms state-of-the-art baselines. Our analysis experiments confirm that MemRL effectively reconciles the stability-plasticity dilemma, enabling continuous runtime improvement without weight updates.

</details>


### [143] [X-MuTeST: A Multilingual Benchmark for Explainable Hate Speech Detection and A Novel LLM-consulted Explanation Framework](https://arxiv.org/abs/2601.03194)
*Mohammad Zia Ur Rehman,Sai Kartheek Reddy Kasu,Shashivardhan Reddy Koppula,Sai Rithwik Reddy Chirra,Shwetank Shekhar Singh,Nagendra Kumar*

Main category: cs.CL

TL;DR: 本文提出了一种新的可解释性引导训练框架X-MuTeST，将大语言模型的语义推理与注意力技术结合，用于多语种（包括印地语、泰卢固语和英语）的仇恨言论检测，并公开了具有单词级理由注释的数据集。


<details>
  <summary>Details</summary>
Motivation: 传统仇恨言论检测在准确性和可解释性上存在挑战，尤其是在印地语等欠充分研究语言上，现有方法一般缺乏对模型决策的解释能力。

Method: 作者提出X-MuTeST框架，通过计算原文与n元语法（unigram、bigram、trigram）文本预测概率的差异，产生模型解释，并将其与基于LLM的解释融合。模型训练过程中结合了人工理由增强模型注意力，同时构建了带单词级理由注释的印地语、泰卢固语、英语数据集。

Result: 实验结果表明，结合人工理由不仅提升了模型的分类准确率，也增强了模型解释的合理性和可信度。多语言、多指标（如Token-F1、IOU-F1、Comprehensiveness、Sufficiency）评估均表现优异。

Conclusion: 本文方法不仅提升了仇恨言论检测的准确率和可解释性，还在欠资源语言上推动了该领域研究发展。公开了多语种单词级注释数据集和代码。

Abstract: Hate speech detection on social media faces challenges in both accuracy and explainability, especially for underexplored Indic languages. We propose a novel explainability-guided training framework, X-MuTeST (eXplainable Multilingual haTe Speech deTection), for hate speech detection that combines high-level semantic reasoning from large language models (LLMs) with traditional attention-enhancing techniques. We extend this research to Hindi and Telugu alongside English by providing benchmark human-annotated rationales for each word to justify the assigned class label. The X-MuTeST explainability method computes the difference between the prediction probabilities of the original text and those of unigrams, bigrams, and trigrams. Final explanations are computed as the union between LLM explanations and X-MuTeST explanations. We show that leveraging human rationales during training enhances both classification performance and explainability. Moreover, combining human rationales with our explainability method to refine the model attention yields further improvements. We evaluate explainability using Plausibility metrics such as Token-F1 and IOU-F1 and Faithfulness metrics such as Comprehensiveness and Sufficiency. By focusing on under-resourced languages, our work advances hate speech detection across diverse linguistic contexts. Our dataset includes token-level rationale annotations for 6,004 Hindi, 4,492 Telugu, and 6,334 English samples. Data and code are available on https://github.com/ziarehman30/X-MuTeST

</details>


### [144] [DIP: Dynamic In-Context Planner For Diffusion Language Models](https://arxiv.org/abs/2601.03199)
*Yang Li,Han Meng,Chenan Wang,Haipeng Chen*

Main category: cs.CL

TL;DR: 本文提出了一种针对DLM模型推理效率的新方法DIP，通过动态选择和插入上下文示例，大幅提升推理速度，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 随着上下文长度增加，DLMs因双向注意力机制导致推理计算成本显著升高，亟需提升推理效率。

Method: 本论文提出Dynamic In-Context Planner (DIP)，它在生成过程中动态优化上下文示例，避免一次性给出全部示例，充分利用DLM的扩散生成范式，实现更高效推理。

Result: DIP方法在不降低文本生成质量的前提下，实现了最高12.9倍的推理速度提升（相较于标准推理），以及1.17倍于KV缓存增强推理的加速效果。

Conclusion: DIP证明了通过上下文动态调整可以高效利用DLM的生成特性，为DLM在长文本和复杂场景下的应用提供了实用方案。

Abstract: Diffusion language models (DLMs) have shown strong potential for general natural language tasks with in-context examples. However, due to the bidirectional attention mechanism, DLMs incur substantial computational cost as context length increases. This work addresses this issue with a key discovery: unlike the sequential generation in autoregressive language models (ARLMs), the diffusion generation paradigm in DLMs allows \textit{efficient dynamic adjustment of the context} during generation. Building on this insight, we propose \textbf{D}ynamic \textbf{I}n-Context \textbf{P}lanner (DIP), a context-optimization method that dynamically selects and inserts in-context examples during generation, rather than providing all examples in the prompt upfront. Results show DIP maintains generation quality while achieving up to 12.9$\times$ inference speedup over standard inference and 1.17$\times$ over KV cache-enhanced inference.

</details>


### [145] [UltraLogic: Enhancing LLM Reasoning through Large-Scale Data Synthesis and Bipolar Float Reward](https://arxiv.org/abs/2601.03205)
*Yile Liu,Yixian Liu,Zongwei Li,Yufei Huang,Xinhua Feng,Zhichao Hu,Jinglu Hu,Jianfeng Yan,Fengzong Lian,Yuhong Liu*

Main category: cs.CL

TL;DR: 本文提出UltraLogic框架，通过代码驱动高质量、多样性和难度分级的数据生成，推动大模型通用推理能力提升，并引入BFR奖励机制辅助训练。


<details>
  <summary>Details</summary>
Motivation: 尽管大模型在自然语言处理上表现优异，但在多步推理、规划和验证等复杂通用推理任务上存在瓶颈。现有基于可验证奖励的强化学习方法数据有限，特别是大规模高质量和难度可控的推理数据短缺。本文旨在解决通用推理训练数据匮乏的问题。

Method: 提出UltraLogic框架，将问题的逻辑核心与自然语言表达解耦，通过代码自动生成高质量、多类型、分十级难度的数据，并针对奖励稀疏等问题设计BFR（Bipolar Float Reward）机制，利用连续化惩罚更好区分回答优劣。

Result: 实验表明，任务多样性是提升推理能力的关键，BFR加上难度匹配策略能有效提升训练效率，并引导模型获得更优的全局逻辑能力。

Conclusion: UltraLogic框架和BFR奖励机制有效解决了推理数据匮乏和奖励稀疏难题，为大模型推理能力提升提供了新思路和高效路径。

Abstract: While Large Language Models (LLMs) have demonstrated significant potential in natural language processing , complex general-purpose reasoning requiring multi-step logic, planning, and verification remains a critical bottleneck. Although Reinforcement Learning with Verifiable Rewards (RLVR) has succeeded in specific domains , the field lacks large-scale, high-quality, and difficulty-calibrated data for general reasoning. To address this, we propose UltraLogic, a framework that decouples the logical core of a problem from its natural language expression through a Code-based Solving methodology to automate high-quality data production. The framework comprises hundreds of unique task types and an automated calibration pipeline across ten difficulty levels. Furthermore, to mitigate binary reward sparsity and the Non-negative Reward Trap, we introduce the Bipolar Float Reward (BFR) mechanism, utilizing graded penalties to effectively distinguish perfect responses from those with logical flaws. Our experiments demonstrate that task diversity is the primary driver for reasoning enhancement , and that BFR, combined with a difficulty matching strategy, significantly improves training efficiency, guiding models toward global logical optima.

</details>


### [146] [MalruleLib: Large-Scale Executable Misconception Reasoning with Step Traces for Modeling Student Thinking in Mathematics](https://arxiv.org/abs/2601.03217)
*Xinghe Chen,Naiming Liu,Shashank Sonkar*

Main category: cs.CL

TL;DR: 本文提出了MalruleLib框架，将数学错误中的系统性误解转化为可执行的“错误规则”（malrules），并用于学生模型推理与AI教育辅助。


<details>
  <summary>Details</summary>
Motivation: 学生在数学学习中的错误往往具有系统性，即重复采用同一种错误的解决方法。现有AI教育工具难以准确建模和诊断这些误解，因此亟需一个能刻画并自动生成误解操作的工具框架，以促进教育AI系统的诊断和反馈能力。

Method: 作者开发了MalruleLib，融合了67篇学习科学和数学教育文献中已有的误解记录，将它们格式化为可执行的malrules（错误操作规则），并与498个参数化数学题模板结合，能够自动生成学生的错误步骤轨迹。提出了Malrule Reasoning Accuracy（MRA）评价问题，用以衡量从少量学生错误推断误解并在新题模板下预测学生答案的能力，并在多种大语言模型上进行实验。

Result: 实验表明，大模型对直接问题求解的准确率为66%，但在跨题型误解预测时下降到40%。通过MalruleLib可以自动生成大量配对的正确与误解路径，跨模板预测准确率普遍降低了10-21%；若提供学生步骤信息，模型预测能力可提升3-15%。

Conclusion: MalruleLib实现了对学生系统性误解的可编程建模与大规模自动生成，为教育AI系统提供了强有力的基础设施，以实现更准确的诊断和针对具体误解的个性化反馈，并推动智能教育的发展。

Abstract: Student mistakes in mathematics are often systematic: a learner applies a coherent but wrong procedure and repeats it across contexts. We introduce MalruleLib, a learning-science-grounded framework that translates documented misconceptions into executable procedures, drawing on 67 learning-science and mathematics education sources, and generates step-by-step traces of malrule-consistent student work. We formalize a core student-modeling problem as Malrule Reasoning Accuracy (MRA): infer a misconception from one worked mistake and predict the student's next answer under cross-template rephrasing. Across nine language models (4B-120B), accuracy drops from 66% on direct problem solving to 40% on cross-template misconception prediction. MalruleLib encodes 101 malrules over 498 parameterized problem templates and produces paired dual-path traces for both correct reasoning and malrule-consistent student reasoning. Because malrules are executable and templates are parameterizable, MalruleLib can generate over one million instances, enabling scalable supervision and controlled evaluation. Using MalruleLib, we observe cross-template degradations of 10-21%, while providing student step traces improves prediction by 3-15%. We release MalruleLib as infrastructure for educational AI that models student procedures across contexts, enabling diagnosis and feedback that targets the underlying misconception.

</details>


### [147] [Multi-RADS Synthetic Radiology Report Dataset and Head-to-Head Benchmarking of 41 Open-Weight and Proprietary Language Models](https://arxiv.org/abs/2601.03232)
*Kartik Bose,Abhinandan Kumar,Raghuraman Soundararajan,Priya Mudgil,Samonee Ralmilay,Niharika Dutta,Manphool Singhal,Arun Kumar,Saugata Sen,Anurima Patra,Priya Ghosh,Abanti Das,Amit Gupta,Ashish Verma,Dipin Sudhakaran,Ekta Dhamija,Himangi Unde,Ishan Kumar,Krithika Rangarajan,Prerna Garg,Rachel Sequeira,Sudhin Shylendran,Taruna Yadav,Tej Pal,Pankaj Gupta*

Main category: cs.CL

TL;DR: 本研究创建了RXL-RADSet基准，比较了不同规模开源小语言模型（SLM）和专有模型在自动分配多种RADS分级任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管RADS体系帮助规范放射学报告的风险交流，但由于分级指南复杂和模型输出限制，实现自动化分级存在困难，目前缺乏跨RADS类型和模型规模的公开基准和系统性比较。

Method: 作者基于10个不同RADS体系（如BI-RADS、LI-RADS等），利用大语言模型生成并经放射科医生两轮核验，构建了1600个多样化的合成放射学报告数据集（RXL-RADSet）。使用固定引导式提示词，对41款量化SLM（涵盖12个家族、参数量范围0.135-32B）以及专有GPT-5.2模型进行自动化分级测试，评估主要指标为分级有效性和准确率，同时比较了引导式与零样本测试效果。

Result: 在引导式提示下GPT-5.2表现最好，有效性达99.8%，准确率为81.1%。SLM整体有效性96.8%，准确率61.1%；20-32B参数模型的有效性和准确率可分别达到约99%和中高70%。模型体量越大，表现越好，尤其在大于10B参数后显著提升。更复杂RADS体系下，准确率下降主要因分类难度提升。引导式测试优于零样本。

Conclusion: RXL-RADSet作为经放射科医生核实的多RADS通用自动分级基准，可有效用于评估模型表现。大型SLM（20-32B）在引导下已接近专有模型性能，但面向复杂分级体系仍有提升空间。

Abstract: Background: Reporting and Data Systems (RADS) standardize radiology risk communication but automated RADS assignment from narrative reports is challenging because of guideline complexity, output-format constraints, and limited benchmarking across RADS frameworks and model sizes. Purpose: To create RXL-RADSet, a radiologist-verified synthetic multi-RADS benchmark, and compare validity and accuracy of open-weight small language models (SLMs) with a proprietary model for RADS assignment. Materials and Methods: RXL-RADSet contains 1,600 synthetic radiology reports across 10 RADS (BI-RADS, CAD-RADS, GB-RADS, LI-RADS, Lung-RADS, NI-RADS, O-RADS, PI-RADS, TI-RADS, VI-RADS) and multiple modalities. Reports were generated by LLMs using scenario plans and simulated radiologist styles and underwent two-stage radiologist verification. We evaluated 41 quantized SLMs (12 families, 0.135-32B parameters) and GPT-5.2 under a fixed guided prompt. Primary endpoints were validity and accuracy; a secondary analysis compared guided versus zero-shot prompting. Results: Under guided prompting GPT-5.2 achieved 99.8% validity and 81.1% accuracy (1,600 predictions). Pooled SLMs (65,600 predictions) achieved 96.8% validity and 61.1% accuracy; top SLMs in the 20-32B range reached ~99% validity and mid-to-high 70% accuracy. Performance scaled with model size (inflection between <1B and >=10B) and declined with RADS complexity primarily due to classification difficulty rather than invalid outputs. Guided prompting improved validity (99.2% vs 96.7%) and accuracy (78.5% vs 69.6%) compared with zero-shot. Conclusion: RXL-RADSet provides a radiologist-verified multi-RADS benchmark; large SLMs (20-32B) can approach proprietary-model performance under guided prompting, but gaps remain for higher-complexity schemes.

</details>


### [148] [STReasoner: Empowering LLMs for Spatio-Temporal Reasoning in Time Series via Spatial-Aware Reinforcement Learning](https://arxiv.org/abs/2601.03248)
*Juntong Ni,Shiyu Wang,Ming Jin,Qi He,Wei Jin*

Main category: cs.CL

TL;DR: 该论文提出了一个面向时空推理的新基准ST-Bench，并提出了能够进行复杂推理的STReasoner方法，在多个核心任务中提升了推理能力，还通过强化学习进一步提升了空间逻辑推理的效果。实验表现优越且成本极低。


<details>
  <summary>Details</summary>
Motivation: 时空序列分析在许多高风险场景（如交通、电网、疾病传播）中至关重要，但目前多数方法仅注重预测准确率，忽视了推理能力的提升。因此，需要发展更能强化推理能力的相关方法和评测基准。

Method: 1）提出ST-Bench基准，包含病因推理、实体识别、相关性推理和上下文预测四大任务，数据通过基于网络随机微分方程（SDE）的多智能体合成方式生成。2）提出STReasoner框架，使大模型能结合时间序列、图结构和文本进行显式推理。3）设计S-GRPO空间强化学习算法，奖励由空间信息驱动的推理提升。

Result: STReasoner在四大推理任务中的准确率提升17%-135%，仅需0.004倍于专有模型的推理成本，并能稳健泛化至真实数据集。

Conclusion: 该工作推动了时空推理领域的发展，显著提升了推理准确性，同时大幅降低了模型推理成本，为实际应用铺平了道路。

Abstract: Spatio-temporal reasoning in time series involves the explicit synthesis of temporal dynamics, spatial dependencies, and textual context. This capability is vital for high-stakes decision-making in systems such as traffic networks, power grids, and disease propagation. However, the field remains underdeveloped because most existing works prioritize predictive accuracy over reasoning. To address the gap, we introduce ST-Bench, a benchmark consisting of four core tasks, including etiological reasoning, entity identification, correlation reasoning, and in-context forecasting, developed via a network SDE-based multi-agent data synthesis pipeline. We then propose STReasoner, which empowers LLM to integrate time series, graph structure, and text for explicit reasoning. To promote spatially grounded logic, we introduce S-GRPO, a reinforcement learning algorithm that rewards performance gains specifically attributable to spatial information. Experiments show that STReasoner achieves average accuracy gains between 17% and 135% at only 0.004X the cost of proprietary models and generalizes robustly to real-world data.

</details>


### [149] [Automated Semantic Rules Detection (ASRD) for Emergent Communication Interpretation](https://arxiv.org/abs/2601.03254)
*Bastien Vanderplaetse,Xavier Siebert,Stéphane Dupont*

Main category: cs.CL

TL;DR: 本文提出了一种自动语义规则检测（ASRD）算法，可以高效地解析多智能体系统中自发产生的通信信息，从而显著提升对通信行为的理解与分析效率。


<details>
  <summary>Details</summary>
Motivation: 尽管多智能体自发通信领域发展迅速，但对于其生成语言的可解释性研究相对较少。因此，论文希望解决自发语言难以理解和解释的难题。

Method: 作者设计了ASRD算法，通过分析在Lewis Game情景下不同训练数据集下智能体之间传递的信息，自动提取其中的有效语义模式，并将其与输入数据中的具体属性建立联系。

Result: ASRD算法能够高效挖掘出智能体通信中的结构性语义规则，极大简化了人工对自发通信的分析任务，提高对语言的可解释性。

Conclusion: ASRD为多智能体自发通信系统的语言可解释性分析提供了一种实用途径，有助于后续对智能体通信机制和语言演化的研究。

Abstract: The field of emergent communication within multi-agent systems examines how autonomous agents can independently develop communication strategies, without explicit programming, and adapt them to varied environments. However, few studies have focused on the interpretability of emergent languages. The research exposed in this paper proposes an Automated Semantic Rules Detection (ASRD) algorithm, which extracts relevant patterns in messages exchanged by agents trained with two different datasets on the Lewis Game, which is often studied in the context of emergent communication. ASRD helps at the interpretation of the emergent communication by relating the extracted patterns to specific attributes of the input data, thereby considerably simplifying subsequent analysis.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [150] [Trust in LLM-controlled Robotics: a Survey of Security Threats, Defenses and Challenges](https://arxiv.org/abs/2601.02377)
*Xinyu Huang,Shyam Karthick V B,Taozhao Chen,Mitch Bryson,Thomas Chaffey,Huaming Chen,Kim-Kwang Raymond Choo,Ian R. Manchester*

Main category: cs.RO

TL;DR: 本论文系统性综述了大语言模型（LLM）在机器人领域的安全威胁与防御措施，重点分析了其独特的物理实体化风险。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在机器人中的应用日益广泛，其通过自然语言解释复杂指令和执行任务的能力显著提升，但也引入了由于抽象推理与实际物理执行之间的“embodiment gap”而产生的独特安全威胁。传统针对文本LLM的安全解决方案无法直接应用于此领域，体现了紧迫的研究需求。

Method: 作者开展了系统性的文献调研，对与LLM机器人相关的安全威胁、攻击向量（如越狱、后门、多模态提示注入）进行了分类梳理，并总结和分类了当前的防御机制（如形式化安全规范、运行时强制、多LLM监督、提示加固），同时回顾了主要的数据集和评测基准。

Result: 建立了针对LLM机器人安全威胁的清晰分类体系，整理和评价了各种防御手段，总结目前的研究现状及存在的不足，指出当前解决方案多为初步探索且不足以解决实体物理机器人面临的复杂安全问题。

Conclusion: 本文强调了为LLM驱动的机器人发展上下文感知安全解决方案的迫切需求，并为该领域安全、可靠系统的研究与开发制定了基础路线图。

Abstract: The integration of Large Language Models (LLMs) into robotics has revolutionized their ability to interpret complex human commands and execute sophisticated tasks. However, such paradigm shift introduces critical security vulnerabilities stemming from the ''embodiment gap'', a discord between the LLM's abstract reasoning and the physical, context-dependent nature of robotics. While security for text-based LLMs is an active area of research, existing solutions are often insufficient to address the unique threats for the embodied robotic agents, where malicious outputs manifest not merely as harmful text but as dangerous physical actions. In this work, we present a systematic survey, summarizing the emerging threat landscape and corresponding defense strategies for LLM-controlled robotics. Specifically, we discuss a comprehensive taxonomy of attack vectors, covering topics such as jailbreaking, backdoor attacks, and multi-modal prompt injection. In response, we analyze and categorize a range of defense mechanisms, from formal safety specifications and runtime enforcement to multi-LLM oversight and prompt hardening. Furthermore, we review key datasets and benchmarks used to evaluate the robustness of these embodied systems. By synthesizing current research, this work highlights the urgent need for context-aware security solutions and provides a foundational roadmap for the development of safe, secure, and reliable LLM-controlled robotics.

</details>


### [151] [Modeling the Mental World for Embodied AI: A Comprehensive Review](https://arxiv.org/abs/2601.02378)
*Biyuan Liu,Daigang Xu,Lei Jiang,Wenjun Guo,Ping Chen*

Main category: cs.RO

TL;DR: 本综述系统梳理了以精神世界模型（MWM）为核心的具身智能体社交理解研究，首次构建理论框架，阐明两大推理范式及评测基准，旨在推动人机协作深入发展。


<details>
  <summary>Details</summary>
Motivation: 随着具身AI在虚拟化身、可穿戴设备和机器人等领域应用加深，研究重心已从物理交互转向对复杂社会交互的理解。现有物理世界模型不足以支持对社交智能的刻画，这促使研究者转向探究能够表达内部心理状态的MWM。

Method: 作者综述分析了100余篇权威文献，首次搭建出MWM理论框架，并系统性定义其关键组成部分、两种心理元素表征范式。进一步，细致梳理了两大ToM推理范式共19种方法、神经符号混合架构集成趋势，和26个ToM评测基准。

Result: 首次明晰MWM与PWM的本质区别、理论体系和适用路径；细致比较并分类现有ToM方法和评价标准，为后续方法创新及实际应用打下理论和评测基础。

Conclusion: 本综述为具身智能体的社会智能建模提供全景式理论框架，有助于其顺利融入人类社会，推动人机协作与交互的深入发展。

Abstract: As the application of Embodied AI Agents in avatars, wearable devices, and robotic systems continues to deepen, their core research challenges have gradually shifted from physical environment interaction to the accurate understanding of social interactions. Traditional physical world models (PWM) focus on quantifiable physical attributes such as space and motion, failing to meet the needs of social intelligence modeling. In contrast, the Mental World Model (MWM), as a structured representation of humans' internal mental states, has become the critical cognitive foundation for embodied agents to achieve natural human-machine collaboration and dynamic social adaptation. However, current MWM research faces significant bottlenecks: such as fragmented conceptual framework with vague boundaries between MWM and PWM, disjointed reasoning mechanisms for the technical pathways and applicable scenarios of different Theory of Mind (ToM) reasoning paradigms, and detachment between evaluation and practice.
  To address these issues, this review systematically synthesizes over 100 authoritative studies to provide a comprehensive overview of MWM research for embodied AI. Its core contributions are threefold: First, it constructs a complete theoretical framework for MWM for the first time. Specifically, it distinguishes the essential differences between MWM and PWMs. Second, it systematically defines the key components of MWM through two paradigms for mental element representation. Third, it comprehensively analyzes two core ToM reasoning paradigms with 19 ToM methods. Finally, it also clarifies the integration trend of neuro-symbolic hybrid architectures, and synthesizes 26 ToM evaluation benchmarks. This work aims to promote the integration of embodied agents into human society and advance the in-depth development of human-machine collaborative interaction.

</details>


### [152] [Movement Primitives in Robotics: A Comprehensive Survey](https://arxiv.org/abs/2601.02379)
*Nolan B. Gutierrez,William J. Beksi*

Main category: cs.RO

TL;DR: 本文综述了运动图元（movement primitives）在机器人控制中的方法和应用，系统梳理了代表性框架、实际案例、难点与前景。


<details>
  <summary>Details</summary>
Motivation: 生物系统的复杂动作启发了研究者对“运动图元”作为基本运动单元的探索，希望为自主系统如机器人生成灵活、高效的运动指令。

Method: 作者以时间顺序系统梳理了运动图元的发展，重点介绍了各种主流框架与方法（如弹簧-阻尼系统分析、概率建模、神经网络等），并对比其在机器人运动轨迹表示和实际应用中的优劣。

Result: 运动图元方法广泛用于机器人轨迹学习与控制，能够有效编码如抓取、投掷等基本动作流程，已展现出良好的鲁棒性和可扩展性，但在多演示融合、高维策略学习等方面存在挑战。

Conclusion: 运动图元为机器人控制带来结构化和可扩展的解决方案。作者指出需进一步解决应用中的难点，如演示泛化、实际部署等，为未来研究指明了方向。

Abstract: Biological systems exhibit a continuous stream of movements, consisting of sequential segments, that allow them to perform complex tasks in a creative and versatile fashion. This observation has led researchers towards identifying elementary building blocks of motion known as movement primitives, which are well-suited for generating motor commands in autonomous systems, such as robots. In this survey, we provide an encyclopedic overview of movement primitive approaches and applications in chronological order. Concretely, we present movement primitive frameworks as a way of representing robotic control trajectories acquired through human demonstrations. Within the area of robotics, movement primitives can encode basic motions at the trajectory level, such as how a robot would grasp a cup or the sequence of motions necessary to toss a ball. Furthermore, movement primitives have been developed with the desirable analytical properties of a spring-damper system, probabilistic coupling of multiple demonstrations, using neural networks in high-dimensional systems, and more, to address difficult challenges in robotics. Although movement primitives have widespread application to a variety of fields, the goal of this survey is to inform practitioners on the use of these frameworks in the context of robotics. Specifically, we aim to (i) present a systematic review of major movement primitive frameworks and examine their strengths and weaknesses; (ii) highlight applications that have successfully made use of movement primitives; and (iii) examine open questions and discuss practical challenges when applying movement primitives in robotics.

</details>


### [153] [InternVLA-A1: Unifying Understanding, Generation and Action for Robotic Manipulation](https://arxiv.org/abs/2601.02456)
*Junhao Cai,Zetao Cai,Jiafei Cao,Yilun Chen,Zeyu He,Lei Jiang,Hang Li,Hengjie Li,Yang Li,Yufei Liu,Yanan Lu,Qi Lv,Haoxiang Ma,Jiangmiao Pang,Yu Qiao,Zherui Qiu,Yanqing Shen,Xu Shi,Yang Tian,Bolun Wang,Hanqing Wang,Jiaheng Wang,Tai Wang,Xueyuan Wei,Chao Wu,Yiman Xie,Boyang Xing,Yuqiang Yang,Yuyin Yang,Qiaojun Yu,Feng Yuan,Jia Zeng,Jingjing Zhang,Shenghan Zhang,Shi Zhang,Zhuoma Zhaxi,Bowen Zhou,Yuanzhen Zhou,Yunsong Zhou,Hongrui Zhu,Yangkun Zhu,Yuchen Zhu*

Main category: cs.RO

TL;DR: 本文提出了一种新型视觉-语言-动作（VLA）模型InternVLA-A1，结合了多模态大模型的语义理解能力与世界模型的动态预测能力，在12项现实机器人任务和仿真基准测试中显著优于当前主流方法。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型虽然语义理解能力强，但对物理世界动态建模能力不足；而世界模型侧重动态预测却缺乏语义锚定，鲁棒性差。因此有必要研发同时具备语义和动态能力的VLA模型。

Method: InternVLA-A1采用统一的Mixture-of-Transformers结构，集成场景理解、视觉前瞻和动作执行三个专家模块，通过统一的掩码自注意机制协同工作。在2B和3B参数规模下，使用涵盖533M帧的大型混合数据集进行预训练，数据合成与真实相结合，弥合仿真与现实的差距。

Result: 在12项现实机器人任务和仿真基准上测试，InternVLA-A1在日常任务中较领先模型提升14.5%，在动态场景中提升40%~73.3%，显著优于pi0和GR00T N1.5等前沿方法。

Conclusion: InternVLA-A1模型兼具语义理解与物理动态推理能力，实现了更强的机器人任务表现，为后续多模态智能体研究提供了有力的技术路径。

Abstract: Prevalent Vision-Language-Action (VLA) models are typically built upon Multimodal Large Language Models (MLLMs) and demonstrate exceptional proficiency in semantic understanding, but they inherently lack the capability to deduce physical world dynamics. Consequently, recent approaches have shifted toward World Models, typically formulated via video prediction; however, these methods often suffer from a lack of semantic grounding and exhibit brittleness when handling prediction errors. To synergize semantic understanding with dynamic predictive capabilities, we present InternVLA-A1. This model employs a unified Mixture-of-Transformers architecture, coordinating three experts for scene understanding, visual foresight generation, and action execution. These components interact seamlessly through a unified masked self-attention mechanism. Building upon InternVL3 and Qwen3-VL, we instantiate InternVLA-A1 at 2B and 3B parameter scales. We pre-train these models on hybrid synthetic-real datasets spanning InternData-A1 and Agibot-World, covering over 533M frames. This hybrid training strategy effectively harnesses the diversity of synthetic simulation data while minimizing the sim-to-real gap. We evaluated InternVLA-A1 across 12 real-world robotic tasks and simulation benchmark. It significantly outperforms leading models like pi0 and GR00T N1.5, achieving a 14.5\% improvement in daily tasks and a 40\%-73.3\% boost in dynamic settings, such as conveyor belt sorting.

</details>


### [154] [Learning and Optimizing the Efficacy of Spatio-Temporal Task Allocation under Temporal and Resource Constraints](https://arxiv.org/abs/2601.02505)
*Jiazhen Liu,Glen Neville,Jinwoo Park,Sonia Chernova,Harish Ravichandar*

Main category: cs.RO

TL;DR: 本文提出并定义了一类新问题STEAM，旨在优化多机器人系统的任务分配、调度与路径规划，并提出了新算法E-ITAGS，有效提升配置绩效并满足各种约束。


<details>
  <summary>Details</summary>
Motivation: 现有多机器人系统在任务分配上常用二元成败模型，难以应对复杂的异构能力、空间和时间约束，实际表现有限。因此亟需更细致和高效的任务分配框架。

Method: 作者提出STEAM问题类，以'能力特征-绩效映射'替代传统二元模型，并引入E-ITAGS算法，将任务分配、调度和路径规划联合优化，同时结合主动学习模块高效学习能力-绩效映射，并考虑实际可实现性。

Result: 通过大量仿真和应急响应实验表明，E-ITAGS分配生成的任务绩效超越多种对比方法，并能够严格遵守资源和空间-时间约束，其主动学习过程也显示出数据和计算高效性。

Conclusion: 论文证明STEAM和E-ITAGS能更有效地提升多机器人系统的任务分配绩效，实现资源利用最大化，是解决复杂多机器人协作问题的新路径。

Abstract: Complex multi-robot missions often require heterogeneous teams to jointly optimize task allocation, scheduling, and path planning to improve team performance under strict constraints. We formalize these complexities into a new class of problems, dubbed Spatio-Temporal Efficacy-optimized Allocation for Multi-robot systems (STEAM). STEAM builds upon trait-based frameworks that model robots using their capabilities (e.g., payload and speed), but goes beyond the typical binary success-failure model by explicitly modeling the efficacy of allocations as trait-efficacy maps. These maps encode how the aggregated capabilities assigned to a task determine performance. Further, STEAM accommodates spatio-temporal constraints, including a user-specified time budget (i.e., maximum makespan). To solve STEAM problems, we contribute a novel algorithm named Efficacy-optimized Incremental Task Allocation Graph Search (E-ITAGS) that simultaneously optimizes task performance and respects time budgets by interleaving task allocation, scheduling, and path planning. Motivated by the fact that trait-efficacy maps are difficult, if not impossible, to specify, E-ITAGS efficiently learns them using a realizability-aware active learning module. Our approach is realizability-aware since it explicitly accounts for the fact that not all combinations of traits are realizable by the robots available during learning. Further, we derive experimentally-validated bounds on E-ITAGS' suboptimality with respect to efficacy. Detailed numerical simulations and experiments using an emergency response domain demonstrate that E-ITAGS generates allocations of higher efficacy compared to baselines, while respecting resource and spatio-temporal constraints. We also show that our active learning approach is sample efficient and establishes a principled tradeoff between data and computational efficiency.

</details>


### [155] [Making Infeasible Tasks Feasible: Planning to Reconfigure Disconnected 3D Environments with Movable Objects](https://arxiv.org/abs/2601.02645)
*Samarth Kalluraya,Yiannis Kantaros*

Main category: cs.RO

TL;DR: 本文提出了BRiDGE，一种针对3D断开空间中可移动物体的智能重配置路径规划方法，实现机器人通过移动物体创建可通行路径，突破传统2D/NAMO规划器的局限。


<details>
  <summary>Details</summary>
Motivation: 以往的机器人路径规划器通常假设目标区域可达，但现实环境往往存在高度差异或空间断开，目标区不可达。因此，本文关注机器人需到达高出等不可达目标区时，如何通过与环境的交互（移动物体）实现可达。

Method: 提出了BRiDGE（Block-based Reconfiguration in Disconnected 3D Geometric Environments）采样规划器，能针对有限数量可移动物体，增量构建树状搜索空间，决策何时、如何、移动哪些物体、放在哪，以建立新的通路。规划过程中引入了非均匀采样策略以提升效率。

Result: 证明了该方法具有概率完备性，并通过大量仿真和实物实验验证了策略的有效性。

Conclusion: BRiDGE有效地解决了3D空间内机器人需通过重配置物体来克服不可达性的挑战，扩展了NAMO方法到更广泛实际3D应用场景。

Abstract: Several planners have been developed to compute dynamically feasible, collision-free robot paths from an initial to a goal configuration. A key assumption in these works is that the goal region is reachable; an assumption that often fails in practice when environments are disconnected. Motivated by this limitation, we consider known 3D environments comprising objects, also called blocks, that form distinct navigable support surfaces (planes), and that are either non-movable (e.g., tables) or movable (e.g., boxes). These surfaces may be mutually disconnected due to height differences, holes, or lateral separations. Our focus is on tasks where the robot must reach a goal region residing on an elevated plane that is unreachable. Rather than declaring such tasks infeasible, an effective strategy is to enable the robot to interact with the environment, rearranging movable objects to create new traversable connections; a problem known as Navigation Among Movable Objects (NAMO). Existing NAMO planners typically address 2D environments, where obstacles are pushed aside to clear a path. These methods cannot directly handle the considered 3D setting; in such cases, obstacles must be placed strategically to bridge these physical disconnections. We address this challenge by developing BRiDGE (Block-based Reconfiguration in Disconnected 3D Geometric Environments), a sampling-based planner that incrementally builds trees over robot and object configurations to compute feasible plans specifying which objects to move, where to place them, and in what order, while accounting for a limited number of movable objects. To accelerate planning, we introduce non-uniform sampling strategies. We show that our method is probabilistically complete and we provide extensive numerical and hardware experiments validating its effectiveness.

</details>


### [156] [Effective Online 3D Bin Packing with Lookahead Parcels Using Monte Carlo Tree Search](https://arxiv.org/abs/2601.02649)
*Jiangyi Fang,Bowen Zhou,Haotian Wang,Xin Zhu,Leye Wang*

Main category: cs.RO

TL;DR: 该论文提出了一种结合MPC和MCTS的在线3D箱装算法，利用短期预测信息提升机器人臂打包效率，对抗分布漂移，实验显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在现代物流中，实时高效的3D箱装问题对运输与人力成本控制至关重要，而现有深度强化学习方法难以适应实际环境中货物分布的短期变化，导致性能下降。

Method: 作者将带有前瞻包裹信息的在线3D箱装建模为MPC问题，并采用蒙特卡洛树搜索（MCTS）结合动态探索先验，融合RL策略和随机策略，根据前瞻信息自动调节。同时设计辅助奖励惩罚长期空间浪费。

Result: 在真实数据集上，所提方法在分布漂移条件下性能提升超10%，平均改善4%，最佳情况提升超8%，显著优于SOTA基线。

Conclusion: 结合前瞻信息和动态策略选择可有效提升在线3D箱装的鲁棒性和装箱率，为智能物流带来实际价值。

Abstract: Online 3D Bin Packing (3D-BP) with robotic arms is crucial for reducing transportation and labor costs in modern logistics. While Deep Reinforcement Learning (DRL) has shown strong performance, it often fails to adapt to real-world short-term distribution shifts, which arise as different batches of goods arrive sequentially, causing performance drops. We argue that the short-term lookahead information available in modern logistics systems is key to mitigating this issue, especially during distribution shifts. We formulate online 3D-BP with lookahead parcels as a Model Predictive Control (MPC) problem and adapt the Monte Carlo Tree Search (MCTS) framework to solve it. Our framework employs a dynamic exploration prior that automatically balances a learned RL policy and a robust random policy based on the lookahead characteristics. Additionally, we design an auxiliary reward to penalize long-term spatial waste from individual placements. Extensive experiments on real-world datasets show that our method consistently outperforms state-of-the-art baselines, achieving over 10\% gains under distributional shifts, 4\% average improvement in online deployment, and up to more than 8\% in the best case--demonstrating the effectiveness of our framework.

</details>


### [157] [Learning to Nudge: A Scalable Barrier Function Framework for Safe Robot Interaction in Dense Clutter](https://arxiv.org/abs/2601.02686)
*Haixin Jin,Nikhil Uday Shinde,Soofiyan Atar,Hongzhan Yu,Dylan Hirsch,Sicun Gao,Michael C. Yip,Sylvia Herbert*

Main category: cs.RO

TL;DR: 本文提出Dense Contact Barrier Functions（DCBF），一种能够在密集物体环境下实现安全、高效操作的机器人安全策略，无需任务重训且可扩展性强。


<details>
  <summary>Details</summary>
Motivation: 传统机器人操作中，物理接触通常被视为不安全，导致机器人只能避碰，难以在物体密集的日常场景中灵活操作。现有的模型方法面对多物体环境时计算量大，难以实际应用，而基于学习的方法又通常依赖于具体任务，缺乏泛化能力。

Method: 本文提出DCBF，基于学习的面向对象的安全函数，离线训练阶段仅需少量物体。运行时可组合扩展至任意数量物体，无需针对任务重训，并且其安全过滤器计算复杂度线性增长。

Result: 通过密集杂乱环境的仿真实验表明，该方法能够有效实现无碰撞导航和安全的接触操作，验证了其可行性和高效性。

Conclusion: DCBF为机器人在密集、复杂环境下的安全操作提供了高效通用的解决方案，实现了良好的任务泛化能力与操作安全性。

Abstract: Robots operating in everyday environments must navigate and manipulate within densely cluttered spaces, where physical contact with surrounding objects is unavoidable. Traditional safety frameworks treat contact as unsafe, restricting robots to collision avoidance and limiting their ability to function in dense, everyday settings. As the number of objects grows, model-based approaches for safe manipulation become computationally intractable; meanwhile, learned methods typically tie safety to the task at hand, making them hard to transfer to new tasks without retraining. In this work we introduce Dense Contact Barrier Functions(DCBF). Our approach bypasses the computational complexity of explicitly modeling multi-object dynamics by instead learning a composable, object-centric function that implicitly captures the safety constraints arising from physical interactions. Trained offline on interactions with a few objects, the learned DCBFcomposes across arbitrary object sets at runtime, producing a single global safety filter that scales linearly and transfers across tasks without retraining. We validate our approach through simulated experiments in dense clutter, demonstrating its ability to enable collision-free navigation and safe, contact-rich interaction in suitable settings.

</details>


### [158] [Analysis of Various Manipulator Configurations Based on Multi-Objective Black-Box Optimization](https://arxiv.org/abs/2601.02704)
*Kento Kawaharazuka,Keita Yoneda,Takahiro Hattori,Shintaro Inoue,Kei Okada*

Main category: cs.RO

TL;DR: 本文综述了6自由度和7自由度机械臂的结构设计，并通过多目标优化研究机械臂结构的最优解，有助于未来机械臂的设计。


<details>
  <summary>Details</summary>
Motivation: 不同机械臂间关节顺序和连杆长度比例各异，缺乏统一的最优结构。过去结构多靠经验确定，智能制造和机器人基础模型发展需要对机械臂结构进行系统优化。

Method: 本文采用多目标优化算法，从末端执行器可达性和关节力矩两个角度对机械臂结构进行评估和优化，并对现有机械臂结构在优化结果中的位置进行分析。

Result: 通过优化采样，获得了机械臂结构在不同目标下的分布，以及现有代表性结构在这些分布中的区域，总结了它们的优势与不足。

Conclusion: 多目标优化有助于揭示不同机械臂结构的权衡与取舍，相关研究能够为未来机械臂的设计和基础模型支持结构的选用提供理论依据。

Abstract: Various 6-degree-of-freedom (DOF) and 7-DOF manipulators have been developed to date. Over a long history, their joint configurations and link length ratios have been determined empirically. In recent years, the development of robotic foundation models has become increasingly active, leading to the continuous proposal of various manipulators to support these models. However, none of these manipulators share exactly the same structure, as the order of joints and the ratio of link lengths differ among robots. Therefore, in order to discuss the optimal structure of a manipulator, we performed multi-objective optimization from the perspectives of end-effector reachability and joint torque. We analyze where existing manipulator structures stand within the sampling results of the optimization and provide insights for future manipulator design.

</details>


### [159] [Loop Closure using AnyLoc Visual Place Recognition in DPV-SLAM](https://arxiv.org/abs/2601.02723)
*Wenzheng Zhang,Kazuki Adachi,Yoshitaka Hara,Sousuke Nakamura*

Main category: cs.RO

TL;DR: 本文提出了一种改进视觉SLAM中回环检测性能的方法，将AnyLoc深度学习视觉位置识别技术集成到DPV-SLAM系统，替换传统BoVW方法，并引入自适应相似性阈值机制，大幅提升回环检测准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统视觉SLAM中的回环检测通常依赖于BoVW等手工特征方法，这些方法在视角变化或光照不佳时表现有限，导致回环检测准确性和稳定性不足，影响SLAM建图效果。

Method: 作者采用基于深度学习的AnyLoc视觉位置识别方式替代BoVW进行回环检测，并提出一种可根据环境自适应调整相似性阈值的机制，避免人工参数调整。

Result: 在室内外数据集上的实验表明，该方法在回环检测准确性和鲁棒性方面均明显优于原始DPV-SLAM。

Conclusion: 所提出的方案有效提升了回环检测的性能，为现代SLAM系统提供了实用且可扩展的改进方法。

Abstract: Loop closure is crucial for maintaining the accuracy and consistency of visual SLAM. We propose a method to improve loop closure performance in DPV-SLAM. Our approach integrates AnyLoc, a learning-based visual place recognition technique, as a replacement for the classical Bag of Visual Words (BoVW) loop detection method. In contrast to BoVW, which relies on handcrafted features, AnyLoc utilizes deep feature representations, enabling more robust image retrieval across diverse viewpoints and lighting conditions. Furthermore, we propose an adaptive mechanism that dynamically adjusts similarity threshold based on environmental conditions, removing the need for manual tuning. Experiments on both indoor and outdoor datasets demonstrate that our method significantly outperforms the original DPV-SLAM in terms of loop closure accuracy and robustness. The proposed method offers a practical and scalable solution for enhancing loop closure performance in modern SLAM systems.

</details>


### [160] [Optimizing Control-Friendly Trajectories with Self-Supervised Residual Learning](https://arxiv.org/abs/2601.02738)
*Kexin Guo,Zihan Yang,Yuhang Liu,Jindou Jia,Xiang Yu*

Main category: cs.RO

TL;DR: 本文提出了一种自监督残差学习与轨迹优化框架，能有效提升机器人在执行高动态任务时的轨迹跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 复杂机器人系统中，传统解析物理建模很难覆盖全部动力学，导致控制难以精确跟踪激进轨迹，残余动力学效应未被有效克服。

Method: 首先，通过自监督方式学习轨迹级别的未知动力学残差，与名义动力学结合构建混合动力学模型。利用解析梯度，仅凭轨迹数据即可高效实现残差学习，并能在任意积分步长下获得准确的长时域预测。随后，提出轨迹优化器，能沿轨迹最小化残余物理效应，生成利于后续控制的最优参考轨迹。

Result: 在四旋翼敏捷飞行任务测试中，基于混合动力学及优化的轨迹，优化器能输出激进且易于精准跟踪的运动序列。

Conclusion: 所提框架通过学习残差动力学并结合轨迹优化，有效提升了复杂机器人系统对高动态轨迹的跟踪能力。

Abstract: Real-world physics can only be analytically modeled with a certain level of precision for modern intricate robotic systems. As a result, tracking aggressive trajectories accurately could be challenging due to the existence of residual physics during controller synthesis. This paper presents a self-supervised residual learning and trajectory optimization framework to address the aforementioned challenges. At first, unknown dynamic effects on the closed-loop model are learned and treated as residuals of the nominal dynamics, jointly forming a hybrid model. We show that learning with analytic gradients can be achieved using only trajectory-level data while enjoying accurate long-horizon prediction with an arbitrary integration step size. Subsequently, a trajectory optimizer is developed to compute the optimal reference trajectory with the residual physics along it minimized. It ends up with trajectories that are friendly to the following control level. The agile flight of quadrotors illustrates that by utilizing the hybrid dynamics, the proposed optimizer outputs aggressive motions that can be precisely tracked.

</details>


### [161] [Unified Meta-Representation and Feedback Calibration for General Disturbance Estimation](https://arxiv.org/abs/2601.02762)
*Zihan Yang,Jindou Jia,Meng Wang,Yuhang Liu,Kexin Guo,Xiang Yu*

Main category: cs.RO

TL;DR: 本文提出了一种结合元学习和反馈校正在线自适应的框架，实现对非结构性扰动的普适估计，在无人机现场实验中取得了优异效果。


<details>
  <summary>Details</summary>
Motivation: 在机器人领域，精确控制常被未知、随时间变化的扰动影响，现有方法依赖于预设环境结构，难以灵活应对真实、非结构性扰动。因此，亟需一种无需预定义结构即可广泛适用的扰动估计方法。

Method: 本文提出了一种基于元学习和状态反馈校正的在线自适应扰动估计框架。通过从过去观测的有限时间窗提取特征，学习能够表示一般非结构性扰动的统一特征表示，并引入状态反馈机制在线校正以减小因特征误差和泛化性不足带来的残差。

Result: 理论分析表明，学习误差和扰动估计误差可以同时收敛。实验证明，该方法能有效估计多种快速变化的扰动，特别在四旋翼无人机飞行实验中表现突出。

Conclusion: 本文方法在无需结构先验的情况下，能够高效、准确地在线估计非结构性扰动，提升了机器人系统在复杂环境下的鲁棒性和泛化能力。

Abstract: Precise control in modern robotic applications is always an open issue due to unknown time-varying disturbances. Existing meta-learning-based approaches require a shared representation of environmental structures, which lack flexibility for realistic non-structural disturbances. Besides, representation error and the distribution shifts can lead to heavy degradation in prediction accuracy. This work presents a generalizable disturbance estimation framework that builds on meta-learning and feedback-calibrated online adaptation. By extracting features from a finite time window of past observations, a unified representation that effectively captures general non-structural disturbances can be learned without predefined structural assumptions. The online adaptation process is subsequently calibrated by a state-feedback mechanism to attenuate the learning residual originating from the representation and generalizability limitations. Theoretical analysis shows that simultaneous convergence of both the online learning error and the disturbance estimation error can be achieved. Through the unified meta-representation, our framework effectively estimates multiple rapidly changing disturbances, as demonstrated by quadrotor flight experiments. See the project page for video, supplementary material and code: https://nonstructural-metalearn.github.io.

</details>


### [162] [Advancing Assistive Robotics: Multi-Modal Navigation and Biophysical Monitoring for Next-Generation Wheelchairs](https://arxiv.org/abs/2601.02766)
*Md. Anowar Hossain,Mohd. Ehsanul Hoque*

Main category: cs.RO

TL;DR: 本论文提出了一种集成多种控制方式和生命体征监测的智能电动轮椅系统，提升了残障人士的自主性和护理人员的远程监督能力。


<details>
  <summary>Details</summary>
Motivation: 当前电动轮椅虽为运动障碍人士提供帮助，但控制方式单一、患者自主性不足，且缺少高效的健康监测与紧急响应机制。论文旨在开发更智能、以患者为中心的方案。

Method: 设计与实现了集成四种控制接口（摇杆、语音、手势、电生理（EOG））的电动轮椅系统，并结合连续生命体征（心率变异、血氧、皮肤温度）监控，通过双点校准提升生理传感准确性。指令识别和系统延迟等核心性能通过20名用户、500次指令进行实验验证。同时，健康数据加密上传云端，护理人员通过APP实时接收预警。

Result: 传感器测量误差小，指令识别准确率高（摇杆99%，语音97%，手势95%），闭环延迟约20毫秒。系统符合国际安全标准，护理反馈及时，能量与延迟消耗均有报告。

Conclusion: 该多模态电动轮椅系统有效提升了患者自主性与安全监控水平，为助行机器人智能化和标准合规性提供了参考，也为后续结合机器学习的自适应扩展奠定基础。

Abstract: Assistive electric-powered wheelchairs (EPWs) have become essential mobility aids for people with disabilities such as amyotrophic lateral sclerosis (ALS), post-stroke hemiplegia, and dementia-related mobility impairment. This work presents a novel multi-modal EPW control system designed to prioritize patient needs while allowing seamless switching between control modes. Four complementary interfaces, namely joystick, speech, hand gesture, and electrooculography (EOG), are integrated with a continuous vital sign monitoring framework measuring heart rate variability, oxygen saturation (SpO2), and skin temperature. This combination enables greater patient independence while allowing caregivers to maintain real-time supervision and early intervention capability.
  Two-point calibration of the biophysical sensors against clinical reference devices resulted in root mean square errors of at most 2 bpm for heart rate, 0.5 degree Celsius for skin temperature, and 1 percent for SpO2. Experimental evaluation involved twenty participants with mobility impairments executing a total of 500 indoor navigation commands. The achieved command recognition accuracies were 99 percent for joystick control, 97 percent plus or minus 2 percent for speech, and 95 percent plus or minus 3 percent for hand gesture, with an average closed-loop latency of 20 plus or minus 0.5 milliseconds. Caregivers receive real-time alerts through an Android application following encrypted cloud transmission of physiological data. By integrating multi-modal mobility control with cloud-enabled health monitoring and reporting latency and energy budgets, the proposed prototype addresses key challenges in assistive robotics, contributes toward compliance with ISO 7176-31 and IEC 80601-2-78 safety standards, and establishes a foundation for future adaptive machine learning enhancements.

</details>


### [163] [M-SEVIQ: A Multi-band Stereo Event Visual-Inertial Quadruped-based Dataset for Perception under Rapid Motion and Challenging Illumination](https://arxiv.org/abs/2601.02777)
*Jingcheng Cao,Chaoran Xiong,Jianmin Song,Shang Yan,Jiachen Liu,Ling Pei*

Main category: cs.RO

TL;DR: 本论文发布了M-SEVIQ数据集：一套包含多波段立体事件相机、惯性测量单元和编码器的四足机器人感知数据集，支持极速、低光等挑战环境下研究。


<details>
  <summary>Details</summary>
Motivation: 传统帧式相机在机器人高速运动和低光条件下容易模糊，限制了感知性能；现有事件相机数据集在多波段、立体配置及多种光照条件下稀缺，制约了相关领域研究进展。

Method: 作者利用Unitree Go2四足机器人，装配多波段立体事件相机、帧式相机、IMU及关节编码器，采集了30多个不同速度、光照波段与条件下的真实世界序列，并提供全面的传感器标定数据用于精确融合与评测。

Result: 获得了跨速度、光照波段及光照条件的多源感知同步数据，数据集包含丰富的传感器信息与校准数据，可直接为不同感知与融合任务提供支持。

Conclusion: M-SEVIQ数据集为敏捷机器人感知、传感器融合、语义分割以及复杂环境下多模态视觉研究提供了重要资源，预计将推动相关领域的技术进步。

Abstract: Agile locomotion in legged robots poses significant challenges for visual perception. Traditional frame-based cameras often fail in these scenarios for producing blurred images, particularly under low-light conditions. In contrast, event cameras capture changes in brightness asynchronously, offering low latency, high temporal resolution, and high dynamic range. These advantages make them suitable for robust perception during rapid motion and under challenging illumination. However, existing event camera datasets exhibit limitations in stereo configurations and multi-band sensing domains under various illumination conditions. To address this gap, we present M-SEVIQ, a multi-band stereo event visual and inertial quadruped dataset collected using a Unitree Go2 equipped with stereo event cameras, a frame-based camera, an inertial measurement unit (IMU), and joint encoders. This dataset contains more than 30 real-world sequences captured across different velocity levels, illumination wavelengths, and lighting conditions. In addition, comprehensive calibration data, including intrinsic, extrinsic, and temporal alignments, are provided to facilitate accurate sensor fusion and benchmarking. Our M-SEVIQ can be used to support research in agile robot perception, sensor fusion, semantic segmentation and multi-modal vision in challenging environments.

</details>


### [164] [Closing the Reality Gap: Zero-Shot Sim-to-Real Deployment for Dexterous Force-Based Grasping and Manipulation](https://arxiv.org/abs/2601.02778)
*Haoyu Dong,Zhengmao He,Yang Li,Zhibin Li,Xinyu Yi,Zhe Zhao*

Main category: cs.RO

TL;DR: 该论文提出了一种实际可行的仿真到现实（sim-to-real）强化学习框架，使多指灵巧手能够在无需微调的情况下，直接从仿真部署到真实硬件，实现可控抓握和物体重新定向。


<details>
  <summary>Details</summary>
Motivation: 多指灵巧手具备接近人类的操作能力，但由于复杂物理接触和执行器的不完美，直接在真实硬件上训练控制策略极为困难。当前的仿真到现实转移也面临触觉建模和执行器差异大的难题，因此迫切需要一种能有效利用触觉和动力信息，且能跨越仿真与现实鸿沟的解决方案。

Method: 1）提出高效的密集触觉仿真，通过并行前向运动学，实现虚拟触觉单元与物体之间的高频率、高分辨率触觉信号用于RL训练；2）建立电流-关节力矩映射，免去了对昂贵传感器的依赖；3）通过随机化执行器的非理想特性，拟合实际物理差异；4）利用非对称策略梯度PPO管线在仿真中训练。在策略观察空间中结合触觉和力矩信息，准确建模感知及执行过程。

Result: 所训练的控制策略在未经过实际机器人微调的情况下，能够在五指灵巧手上直接实现1）基于命令的可控抓握力跟踪，以及2）物体在手内的重新定向两个关键操作，且表现出较强鲁棒性。

Conclusion: 本方法首次实现了在多指灵巧手上，完全通过仿真训练并能零样本迁移到真实硬件的可控抓取，并且无需微调，通过结合触觉与力矩信息和有效的感觉-执行动态建模，为可靠的灵巧操作提供了实用方案。

Abstract: Human-like dexterous hands with multiple fingers offer human-level manipulation capabilities, but training control policies that can directly deploy on real hardware remains difficult due to contact-rich physics and imperfect actuation. We close this gap with a practical sim-to-real reinforcement learning (RL) framework that utilizes dense tactile feedback combined with joint torque sensing to explicitly regulate physical interactions. To enable effective sim-to-real transfer, we introduce (i) a computationally fast tactile simulation that computes distances between dense virtual tactile units and the object via parallel forward kinematics, providing high-rate, high-resolution touch signals needed by RL; (ii) a current-to-torque calibration that eliminates the need for torque sensors on dexterous hands by mapping motor current to joint torque; and (iii) actuator dynamics modeling to bridge the actuation gaps with randomization of non-ideal effects such as backlash, torque-speed saturation. Using an asymmetric actor-critic PPO pipeline trained entirely in simulation, our policies deploy directly to a five-finger hand. The resulting policies demonstrated two essential skills: (1) command-based, controllable grasp force tracking, and (2) reorientation of objects in the hand, both of which were robustly executed without fine-tuning on the robot. By combining tactile and torque in the observation space with effective sensing/actuation modeling, our system provides a practical solution to achieve reliable dexterous manipulation. To our knowledge, this is the first demonstration of controllable grasping on a multi-finger dexterous hand trained entirely in simulation and transferred zero-shot on real hardware.

</details>


### [165] [Reinforcement Learning for Follow-the-Leader Robotic Endoscopic Navigation via Synthetic Data](https://arxiv.org/abs/2601.02798)
*Sicong Gao,Chen Qian,Laurence Xian,Liao Wu,Maurice Pagnucco,Yang Song*

Main category: cs.RO

TL;DR: 本文提出了一种基于柔性结构和视觉深度强化学习的自主内窥镜机器人，能够有效降低与肠道壁的接触，并提升导航精度。


<details>
  <summary>Details</summary>
Motivation: 以往自主内窥镜导航常因与管腔内壁接触过多造成患者不适，且端到端自主性不足，迫切需要一种能减少接触且精准跟踪腔道的导航方案。

Method: 设计了柔性随动型内窥镜结构，结合单目深度估计引导的视觉深度强化学习，在NVIDIA Omniverse环境中进行模拟训练。利用NVIDIA Replicator生成大量合成图像并微调Depth Anything模型，增强单目三维感知能力，并设计了几何感知奖惩机制用于精细腔道追踪。

Result: 与原始Depth Anything模型相比，所提方法$δ_{1}$深度精度提升了39.2%，导航J-index比次优方法降低了0.67，显著提升了导航鲁棒性和有效性。

Conclusion: 提出的方法能实现柔性、安全且高效的内窥镜自主导航，减少对内壁接触、提升患者舒适度，结果验证了其优越性和可行性。

Abstract: Autonomous navigation is crucial for both medical and industrial endoscopic robots, enabling safe and efficient exploration of narrow tubular environments without continuous human intervention, where avoiding contact with the inner walls has been a longstanding challenge for prior approaches. We present a follow-the-leader endoscopic robot based on a flexible continuum structure designed to minimize contact between the endoscope body and intestinal walls, thereby reducing patient discomfort. To achieve this objective, we propose a vision-based deep reinforcement learning framework guided by monocular depth estimation. A realistic intestinal simulation environment was constructed in \textit{NVIDIA Omniverse} to train and evaluate autonomous navigation strategies. Furthermore, thousands of synthetic intraluminal images were generated using NVIDIA Replicator to fine-tune the Depth Anything model, enabling dense three-dimensional perception of the intestinal environment with a single monocular camera. Subsequently, we introduce a geometry-aware reward and penalty mechanism to enable accurate lumen tracking. Compared with the original Depth Anything model, our method improves $δ_{1}$ depth accuracy by 39.2% and reduces the navigation J-index by 0.67 relative to the second-best method, demonstrating the robustness and effectiveness of the proposed approach.

</details>


### [166] [Soft Responsive Materials Enhance Humanoid Safety](https://arxiv.org/abs/2601.02857)
*Chunzheng Wang,Yiyuan Zhang,Annan Tang,Ziqiu Zeng,Haoran Chen,Quan Gao,Zixuan Zhuang,Boyu Li,Zhilin Xiong,Aoqian Zhang,Ce Hao,Siyuan Luo,Tongyang Zhao,Cecilia Laschi,Fan Shi*

Main category: cs.RO

TL;DR: 该论文提出了一种结合非牛顿流体响应软材料与刚性结构的新型人形机器人防护框架，有效提升了机器人跌倒时的安全性和环境兼容性。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人部署受限于跌倒易损和金属塑料硬结构对人及环境的潜在风险，因此需要新的设计提升其安全性。

Method: 作者设计了基于非牛顿流体的软-刚混合材料保护层，能在普通交互下保持柔软，受到冲击时迅速变硬以吸能和消能。通过物理仿真优化保护器布置与厚度，并采用学习方法优化机器人主动跌倒策略。

Result: 在42公斤真实人形机器人上测试，该防护层显著降低了跌落冲击力，实现了3米高度跌落及长楼梯滚落无硬件损伤，同时提升了多场景下的机器人鲁棒性与环境安全。

Conclusion: 该方法通过响应式材料、结构协同设计与学习控制的组合，推动了安全可交互的工业级人形机器人发展。

Abstract: Humanoid robots are envisioned as general-purpose platforms in human-centered environments, yet their deployment is limited by vulnerability to falls and the risks posed by rigid metal-plastic structures to people and surroundings. We introduce a soft-rigid co-design framework that leverages non-Newtonian fluid-based soft responsive materials to enhance humanoid safety. The material remains compliant during normal interaction but rapidly stiffens under impact, absorbing and dissipating fall-induced forces. Physics-based simulations guide protector placement and thickness and enable learning of active fall policies. Applied to a 42 kg life-size humanoid, the protector markedly reduces peak impact and allows repeated falls without hardware damage, including drops from 3 m and tumbles down long staircases. Across diverse scenarios, the approach improves robot robustness and environmental safety. By uniting responsive materials, structural co-design, and learning-based control, this work advances interact-safe, industry-ready humanoid robots.

</details>


### [167] [Warm-Starting Collision-Free Model Predictive Control With Object-Centric Diffusion](https://arxiv.org/abs/2601.02873)
*Arthur Haffemayer,Alexandre Chapin,Armand Jordana,Krzysztof Wojciechowski,Florent Lamiraux,Nicolas Mansard,Vladimir Petrik*

Main category: cs.RO

TL;DR: 论文提出了一种结合基于扩散模型的智能初始化和对象为中心的场景表征，以及带有碰撞约束的模型预测控制（MPC）的方法，实现了高效且可靠的运动轨迹生成，适用于复杂障碍环境中的机器人运动控制。


<details>
  <summary>Details</summary>
Motivation: 在充满障碍物的环境下导航和控制需要兼顾避免碰撞和动作精度。传统基于优化的控制器在障碍物较多时难以快速给出可行解，而现有扩散模型虽能多样化生成路径，但缺乏高效表达和利用场景结构的方式，因此需要一种兼具高效性与约束满足的运动生成方法。

Method: 方法结合了扩散模型进行智能初始化，强化了路径多样性，并通过对象为中心的slot attention机制获得紧凑的场景障碍表征。然后利用带刚体动力学和碰撞距离约束的模型预测控制（MPC）对生成轨迹进行精炼，实现严格物理约束下的可行运动方案。系统整体用扩散transformer对状态、任务和环境进行条件建模。

Result: 在基准任务上，该方法取得了比采样规划器及其各自组成部分更高的成功率和更低的延迟。此外，在真实Panda机器人上的实验也验证了方法的可靠性和安全性。

Conclusion: 文中提出的扩散模型与对象为中心场景表征结合碰撞感知MPC的混合方法，可以在严格时间约束下为复杂环境中的机器人提供高效、可靠、可行的运动方案。

Abstract: Acting in cluttered environments requires predicting and avoiding collisions while still achieving precise control. Conventional optimization-based controllers can enforce physical constraints, but they struggle to produce feasible solutions quickly when many obstacles are present. Diffusion models can generate diverse trajectories around obstacles, yet prior approaches lacked a general and efficient way to condition them on scene structure. In this paper, we show that combining diffusion-based warm-starting conditioned with a latent object-centric representation of the scene and with a collision-aware model predictive controller (MPC) yields reliable and efficient motion generation under strict time limits. Our approach conditions a diffusion transformer on the system state, task, and surroundings, using an object-centric slot attention mechanism to provide a compact obstacle representation suitable for control. The sampled trajectories are refined by an optimal control problem that enforces rigid-body dynamics and signed-distance collision constraints, producing feasible motions in real time. On benchmark tasks, this hybrid method achieved markedly higher success rates and lower latency than sampling-based planners or either component alone. Real-robot experiments with a torque-controlled Panda confirm reliable and safe execution with MPC.

</details>


### [168] [LOST-3DSG: Lightweight Open-Vocabulary 3D Scene Graphs with Semantic Tracking in Dynamic Environments](https://arxiv.org/abs/2601.02905)
*Sara Micol Ferraina,Michele Brienza,Francesco Argenziano,Emanuele Musumeci,Vincenzo Suriani,Domenico D. Bloisi,Daniele Nardi*

Main category: cs.RO

TL;DR: 本论文提出了一种轻量级且支持开放词汇的3D场景图（LOST-3DSG），用于在真实动态环境中追踪物体。与依赖于高维视觉特征的基础模型方法相比，该方法具有更高的效率和表现。实验在TIAGo机器人及3D真实环境中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有动态环境下的物体跟踪方法常依赖大型基础模型，导致计算效率低。本研究旨在解决动态物体追踪过程中资源消耗大、对视觉特征依赖强等局限，提出更加高效、灵活的解决方案。

Method: 提出了LOST-3DSG方法，通过结合word2vec和句子嵌入实现语义级物体跟踪，能够开放词汇地建模对象，无需存储高维CLIP视觉特征，从而降低系统负担。

Result: 通过在真实3D环境和TIAGo机器人上进行定性和定量实验，LOST-3DSG展示出更优的追踪性能与效率，优于依赖高维视觉嵌入的对比方法。

Conclusion: LOST-3DSG实现了在动态环境下的高效、开放词汇物体追踪，克服了传统方法所需高算力与大内存需求，在实际机器人应用场景中具有很高的应用前景。

Abstract: Tracking objects that move within dynamic environments is a core challenge in robotics. Recent research has advanced this topic significantly; however, many existing approaches remain inefficient due to their reliance on heavy foundation models. To address this limitation, we propose LOST-3DSG, a lightweight open-vocabulary 3D scene graph designed to track dynamic objects in real-world environments. Our method adopts a semantic approach to entity tracking based on word2vec and sentence embeddings, enabling an open-vocabulary representation while avoiding the necessity of storing dense CLIP visual features. As a result, LOST-3DSG achieves superior performance compared to approaches that rely on high-dimensional visual embeddings. We evaluate our method through qualitative and quantitative experiments conducted in a real 3D environment using a TIAGo robot. The results demonstrate the effectiveness and efficiency of LOST-3DSG in dynamic object tracking. Code and supplementary material are publicly available on the project website at https://lab-rococo-sapienza.github.io/lost-3dsg/.

</details>


### [169] [Parameter-Robust MPPI for Safe Online Learning of Unknown Parameters](https://arxiv.org/abs/2601.02948)
*Matti Vahs,Jaeyoun Choi,Niklas Schmid,Jana Tumova,Chuchu Fan*

Main category: cs.RO

TL;DR: 本文提出了一种名为PRMPPI的新型机器人控制框架，融合了在线参数学习与概率安全约束，能在动态环境下提升机器人安全性和性能。


<details>
  <summary>Details</summary>
Motivation: 动态环境下机器人常常面临关键物理参数不确定或变化，导致安全风险。现有方法难以兼顾性能优化和安全保障，亟需一种能适应参数不确定性的鲁棒控制方案。

Method: 所提PRMPPI方法结合模型预测控制和路径积分控制。核心包括：(1) 通过Stein变分梯度法对参数建立基于粒子的贝叶斯后验分布；(2) 利用共形预测，对安全约束进行概率评估；(3) 并行优化一个性能驱动的名义轨迹和一个安全优先的备用轨迹。

Result: 仿真与实际平台实验结果表明，PRMPPI相比其他基线方法，取得了更高的任务成功率、更低的跟踪误差及更准确的参数估计效果。

Conclusion: PRMPPI控制器在参数不确定或动态变化的情况下能有效提升机器人安全性和性能，在实际部署中表现优异，证明了其实用价值。

Abstract: Robots deployed in dynamic environments must remain safe even when key physical parameters are uncertain or change over time. We propose Parameter-Robust Model Predictive Path Integral (PRMPPI) control, a framework that integrates online parameter learning with probabilistic safety constraints. PRMPPI maintains a particle-based belief over parameters via Stein Variational Gradient Descent, evaluates safety constraints using Conformal Prediction, and optimizes both a nominal performance-driven and a safety-focused backup trajectory in parallel. This yields a controller that is cautious at first, improves performance as parameters are learned, and ensures safety throughout. Simulation and hardware experiments demonstrate higher success rates, lower tracking error, and more accurate parameter estimates than baselines.

</details>


### [170] [Learning to Act Robustly with View-Invariant Latent Actions](https://arxiv.org/abs/2601.02994)
*Youngjoon Jeong,Junha Chun,Taesup Kim*

Main category: cs.RO

TL;DR: 本文提出一种视角无关的潜在动作（VILA）方法，通过利用物理动态信息，而非仅仅是视觉外观，提升机器人基于视觉的策略在不同视角下的泛化与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人视觉策略对视角变化非常敏感，尤其在实际应用时，难以避免视角多变性，从而极大影响策略效果。目前方法多从场景层面学习视角不变性，但忽略了对物理动态的建模，导致泛化性能不足。

Method: VILA方法通过建模捕捉轨迹转移模式的潜在动作，利用基于动作引导的目标（借助真实动作序列）对齐不同视角下的潜在动作实现视角无关的表征。

Result: 在仿真和真实环境中的实验显示，基于VILA的策略在未见视角上的泛化能力更好，并能较好迁移到新任务，有效提升了鲁棒性与下游任务学习效率。

Conclusion: VILA作为一种预训练框架，能够为视觉机器人学习提供更强泛化性和适应能力，是一个提升策略鲁棒性的有力工具。

Abstract: Vision-based robotic policies often struggle with even minor viewpoint changes, underscoring the need for view-invariant visual representations. This challenge becomes more pronounced in real-world settings, where viewpoint variability is unavoidable and can significantly disrupt policy performance. Existing methods typically learn invariance from multi-view observations at the scene level, but such approaches rely on visual appearance and fail to incorporate the physical dynamics essential for robust generalization. We propose View-Invariant Latent Action (VILA), which models a latent action capturing transition patterns across trajectories to learn view-invariant representations grounded in physical dynamics. VILA aligns these latent actions across viewpoints using an action-guided objective based on ground-truth action sequences. Experiments in both simulation and the real world show that VILA-based policies generalize effectively to unseen viewpoints and transfer well to new tasks, establishing VILA as a strong pretraining framework that improves robustness and downstream learning performance.

</details>


### [171] [A Bi-directional Adaptive Framework for Agile UAV Landing](https://arxiv.org/abs/2601.03037)
*Chunhui Zhao,Xirui Kao,Yilin Lu,Yang Lyu*

Main category: cs.RO

TL;DR: 本文提出了一种双向合作着陆框架，可以让四旋翼无人机和移动平台协同完成高效自主着陆，突破了传统的“跟踪-后下降”模式并提升了效率与精度。


<details>
  <summary>Details</summary>
Motivation: 现有的四旋翼无人机在动态场景下的自主着陆不足，传统方法把平台视为被动目标，需要无人机执行复杂且效率低下的序列动作，因而难以应对快速、复杂的任务需求。

Method: 作者将着陆任务重新定义为一个耦合系统优化问题，让平台主动参与，通过调节自身姿态协助无人机着陆；另一方面，无人机则使用时间最优且动态可行的轨迹规划同时进行对准和下降，从而实现任务阶段并行化。

Result: 实验验证表明，在动态复杂的应用环境下，该方法提高了自主着陆的效率、准确性和鲁棒性，能够实现快速、精准的状态同步和轨迹跟踪。

Conclusion: 双向协作的新范式打破了以往限定，显著提升了复杂任务中四旋翼无人机自主回收的作业表现，具有广泛应用潜力。

Abstract: Autonomous landing on mobile platforms is crucial for extending quadcopter operational flexibility, yet conventional methods are often too inefficient for highly dynamic scenarios. The core limitation lies in the prevalent ``track-then-descend'' paradigm, which treats the platform as a passive target and forces the quadcopter to perform complex, sequential maneuvers. This paper challenges that paradigm by introducing a bi-directional cooperative landing framework that redefines the roles of the vehicle and the platform. The essential innovation is transforming the problem from a single-agent tracking challenge into a coupled system optimization. Our key insight is that the mobile platform is not merely a target, but an active agent in the landing process. It proactively tilts its surface to create an optimal, stable terminal attitude for the approaching quadcopter. This active cooperation fundamentally breaks the sequential model by parallelizing the alignment and descent phases. Concurrently, the quadcopter's planning pipeline focuses on generating a time-optimal and dynamically feasible trajectory that minimizes energy consumption. This bi-directional coordination allows the system to execute the recovery in an agile manner, characterized by aggressive trajectory tracking and rapid state synchronization within transient windows. The framework's effectiveness, validated in dynamic scenarios, significantly improves the efficiency, precision, and robustness of autonomous quadrotor recovery in complex and time-constrained missions.

</details>


### [172] [Validating Generalist Robots with Situation Calculus and STL Falsification](https://arxiv.org/abs/2601.03038)
*Changwen Li,Rongjie Yan,Chih-Hong Cheng,Jian Zhang*

Main category: cs.RO

TL;DR: 提出了一种两层验证框架，可以系统性地验证能够执行多种任务的通用型机器人，特别适合用在自然语言指令驱动下的复杂操作场景。


<details>
  <summary>Details</summary>
Motivation: 通用型机器人随着自然语言输入的发展，能执行多种不同任务。然而由于不同任务对应不同的操作环境和正确性规范，传统机器人验证方法很难全面适用，迫切需要新的验证框架。

Method: 提出两层验证框架：1）抽象层用情境演算建模世界，分析最弱前置条件，并结合约束感知的组合测试，系统生成多样且语义有效的任务环境；2）具体层通过仿真和STL自动监控，对上述环境中的机器人成行为进行失效性验证。

Result: 在桌面操作任务实验中，该框架能够有效发现NVIDIA GR00T控制器存在的失败案例，表明系统验证效果良好。

Conclusion: 新框架有助于推动通用型机器人自主能力的有效验证，具有应用前景，可发现现有方法难以察觉的问题。

Abstract: Generalist robots are becoming a reality, capable of interpreting natural language instructions and executing diverse operations. However, their validation remains challenging because each task induces its own operational context and correctness specification, exceeding the assumptions of traditional validation methods. We propose a two-layer validation framework that combines abstract reasoning with concrete system falsification. At the abstract layer, situation calculus models the world and derives weakest preconditions, enabling constraint-aware combinatorial testing to systematically generate diverse, semantically valid world-task configurations with controllable coverage strength. At the concrete layer, these configurations are instantiated for simulation-based falsification with STL monitoring. Experiments on tabletop manipulation tasks show that our framework effectively uncovers failure cases in the NVIDIA GR00T controller, demonstrating its promise for validating general-purpose robot autonomy.

</details>


### [173] [PiDR: Physics-Informed Inertial Dead Reckoning for Autonomous Platforms](https://arxiv.org/abs/2601.03040)
*Arup Kumar Sahoo,Itzik Klein*

Main category: cs.RO

TL;DR: 该论文提出了一种物理信息辅助的惯性航迹推算（PiDR）框架，专为在无法获得外部导航数据的情况下提升自主平台的惯性导航能力。


<details>
  <summary>Details</summary>
Motivation: 完全自主导航的核心需求之一，是在缺乏外部数据（如GNSS或视觉信息）环境中，依然能实现高精度导航。然而，现有惯性传感器本身存在噪声与误差，导致导航漂移。常规深度学习模型虽然有一定应用前景，但天然是黑盒模型，难以学习有限监督下的传感器数据，也难以融入物理约束和解释。

Method: 作者提出PiDR，融合物理知识的深度学习网络。在网络训练中引入物理约束的残差项，将惯性导航的物理原理嵌入到神经网络结构中，提高模型的“可解释性”与泛化能力，并减少对大量标注数据的依赖。

Result: 在实际移动机器人和水下无人平台数据集上的实验表明，PiDR导航定位精度提升超过29%。PiDR框架对不同时空环境和动力学条件均有较好适应性。

Conclusion: PiDR实现了高效、透明且资源消耗低的惯性导航方案，能够部署在资源有限的自主平台上，在恶劣环境中实现实时导航定位。

Abstract: A fundamental requirement for full autonomy is the ability to sustain accurate navigation in the absence of external data, such as GNSS signals or visual information. In these challenging environments, the platform must rely exclusively on inertial sensors, leading to pure inertial navigation. However, the inherent noise and other error terms of the inertial sensors in such real-world scenarios will cause the navigation solution to drift over time. Although conventional deep-learning models have emerged as a possible approach to inertial navigation, they are inherently black-box in nature. Furthermore, they struggle to learn effectively with limited supervised sensor data and often fail to preserve physical principles. To address these limitations, we propose PiDR, a physics-informed inertial dead-reckoning framework for autonomous platforms in situations of pure inertial navigation. PiDR offers transparency by explicitly integrating inertial navigation principles into the network training process through the physics-informed residual component. PiDR plays a crucial role in mitigating abrupt trajectory deviations even under limited or sparse supervision. We evaluated PiDR on real-world datasets collected by a mobile robot and an autonomous underwater vehicle. We obtained more than 29% positioning improvement in both datasets, demonstrating the ability of PiDR to generalize different platforms operating in various environments and dynamics. Thus, PiDR offers a robust, lightweight, yet effective architecture and can be deployed on resource-constrained platforms, enabling real-time pure inertial navigation in adverse scenarios.

</details>


### [174] [SOP: A Scalable Online Post-Training System for Vision-Language-Action Models](https://arxiv.org/abs/2601.03044)
*Mingjie Pan,Siyuan Feng,Qinglin Zhang,Xinchen Li,Jianheng Song,Chendi Qu,Yi Wang,Chuankang Li,Ziyu Xiong,Zhi Chen,Yi Liu,Jianlan Luo*

Main category: cs.RO

TL;DR: 本文提出了一种可扩展的在线后训练系统（SOP），实现了视觉-语言-动作（VLA）模型在真实世界多机器人环境下的自适应学习，显著提升了泛化模型的实际任务表现。


<details>
  <summary>Details</summary>
Motivation: 虽然大规模预训练的VLA模型具备良好的泛化能力，但在实际应用中还需要具备专家级的任务熟练度。现有的后训练方法往往局限于离线、单机器人或特定任务，不支持高效的在线自适应和大规模实际部署，无法充分挖掘真实交互数据的价值。

Method: 作者提出了SOP系统，采用闭环架构，将机器人队列的在线经验和人工干预信号实时上传至云端学习器，学习器同步下发更新策略。该系统支持并行部署、任务无关、可与多种后训练算法结合（如HG-DAgger模仿学习和RECAP强化学习），极大提升数据采集效率和适应泛化能力。

Result: 在多个真实世界的操作任务（如折叠衣物、箱子组装、日用品补货）中，SOP系统在维持单一策略泛化能力的同时，大幅提升了VLA模型的任务表现。且随着机器人数量的增加，训练效率近似线性增长，数小时即可完成有效后训练。

Conclusion: 结果显示，通过将在线学习与多机器人联合部署紧密结合，可实现高效、可靠、可扩展的通用机器人策略后训练，为VLA模型在物理世界的实际应用提供了技术基础。

Abstract: Vision-language-action (VLA) models achieve strong generalization through large-scale pre-training, but real-world deployment requires expert-level task proficiency in addition to broad generality. Existing post-training approaches for VLA models are typically offline, single-robot, or task-specific, limiting effective on-policy adaptation and scalable learning from real-world interaction. We introduce a Scalable Online Post-training (SOP) system that enables online, distributed, multi-task post-training of generalist VLA models directly in the physical world. SOP tightly couples execution and learning through a closed-loop architecture in which a fleet of robots continuously streams on-policy experience and human intervention signals to a centralized cloud learner, and asynchronously receives updated policies. This design supports prompt on-policy correction, scales experience collection through parallel deployment, and preserves generality during adaptation. SOP is agnostic to the choice of post-training algorithm; we instantiate it with both interactive imitation learning (HG-DAgger) and reinforcement learning (RECAP). Across a range of real-world manipulation tasks including cloth folding, box assembly, and grocery restocking, we show that SOP substantially improves the performance of large pretrained VLA models while maintaining a single shared policy across tasks. Effective post-training can be achieved within hours of real-world interaction, and performance scales near-linearly with the number of robots in the fleet. These results suggest that tightly coupling online learning with fleet-scale deployment is instrumental to enabling efficient, reliable, and scalable post-training of generalist robot policies in the physical world.

</details>


### [175] [A Fast Semidefinite Convex Relaxation for Optimal Control Problems With Spatio-Temporal Constraints](https://arxiv.org/abs/2601.03055)
*Shiying Dong,Zhipeng Shen,Rudolf Reiter,Hailong Huang,Bingzhao Gao,Hong Chen,Wen-Hua Chen*

Main category: cs.RO

TL;DR: 本文提出了一种新的分段时标直接多重射击方案与半正定规划的凸松弛方法，以快速精确地解决具有时空约束的自主体最优控制问题，并在仿真和实物实验中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 当前最优控制问题由于动力学与事件时序的耦合本质呈现非凸性，主流方法常通过预设路径点时间或直接进行非凸轨迹优化来简化问题，但容易导致次优结果，限制了在自动驾驶、无人机导航等实际应用的性能突破。

Method: 作者提出了一种基于时标的直接多重射击方法，将预测时域按照特征时间约束分段进行处理。同时设计了一种快速的基于半正定规划的凸松弛算法，有效利用提升后问题的稀疏结构提速求解。

Result: 大量仿真实验展现了该方法的高解优性与计算效率。更通过四旋翼在受限开放时间窗口航点飞行任务中的实物实验，证明了新方法在复杂实际环境下的有效性。

Conclusion: 所提方法不仅显著提升了解的质量与求解效率，还具备在真实复杂自主控制场景中的实际应用潜力，突破了传统简化法导致次优的局限。

Abstract: Solving optimal control problems (OCPs) of autonomous agents operating under spatial and temporal constraints fast and accurately is essential in applications ranging from eco-driving of autonomous vehicles to quadrotor navigation. However, the nonlinear programs approximating the OCPs are inherently nonconvex due to the coupling between the dynamics and the event timing, and therefore, they are challenging to solve. Most approaches address this challenge by predefining waypoint times or just using nonconvex trajectory optimization, which simplifies the problem but often yields suboptimal solutions. To significantly improve the numerical properties, we propose a formulation with a time-scaling direct multiple shooting scheme that partitions the prediction horizon into segments aligned with characteristic time constraints. Moreover, we develop a fast semidefinite-programming-based convex relaxation that exploits the sparsity pattern of the lifted formulation. Comprehensive simulation studies demonstrate the solution optimality and computational efficiency. Furthermore, real-world experiments on a quadrotor waypoint flight task with constrained open time windows validate the practical applicability of the approach in complex environments.

</details>


### [176] [HEXAR: a Hierarchical Explainability Architecture for Robots](https://arxiv.org/abs/2601.03070)
*Tamlin Love,Ferran Gebellí,Pradip Pramanick,Antonio Andriella,Guillem Alenyà,Anais Garrell,Raquel Ros,Silvia Rossi*

Main category: cs.RO

TL;DR: 该论文提出了一种新颖的机器人系统可解释性架构HEXAR，通过分层和插件式组件，为机器人决策过程提供高效、透明的解释。


<details>
  <summary>Details</summary>
Motivation: 随着机器人系统日益复杂，其决策过程的可解释性需求变得更加重要。目前主流方法要么只关注单个模块、难以从整体行为层面解释，要么采用整体方案但未利用系统的模块化特性，因此难以满足实际应用中查询多样化和透明度要求。

Method: 作者提出HEXAR框架，通过为各机器人模块设计不同类型的专用解释器（如基于大模型推理、因果模型、特征重要性等），并由一个解释选择器根据查询选择最合适的解释方式，实现分层和模块化的解释流程。

Result: 在实际家庭环境中，基于TIAGo机器人对180种情境与查询变体进行了实验，将HEXAR与端到端及聚合基线方法进行比较。结果显示HEXAR在根因定位、错误信息排除及运行效率等方面显著优于基线方法。

Conclusion: HEXAR框架为提升机器人系统的可解释性提供了高效且通用的新途径，有望推动自主机器人系统的透明化和实用性。

Abstract: As robotic systems become increasingly complex, the need for explainable decision-making becomes critical. Existing explainability approaches in robotics typically either focus on individual modules, which can be difficult to query from the perspective of high-level behaviour, or employ monolithic approaches, which do not exploit the modularity of robotic architectures. We present HEXAR (Hierarchical EXplainability Architecture for Robots), a novel framework that provides a plug-in, hierarchical approach to generate explanations about robotic systems. HEXAR consists of specialised component explainers using diverse explanation techniques (e.g., LLM-based reasoning, causal models, feature importance, etc) tailored to specific robot modules, orchestrated by an explainer selector that chooses the most appropriate one for a given query. We implement and evaluate HEXAR on a TIAGo robot performing assistive tasks in a home environment, comparing it against end-to-end and aggregated baseline approaches across 180 scenario-query variations. We observe that HEXAR significantly outperforms baselines in root cause identification, incorrect information exclusion, and runtime, offering a promising direction for transparent autonomous systems.

</details>


### [177] [Dual-quaternion learning control for autonomous vehicle trajectory tracking with safety guarantees](https://arxiv.org/abs/2601.03097)
*Omayra Yago Nieto,Alexandre Anahory Simoes,Juan I. Giribet,Leonardo Colombo*

Main category: cs.RO

TL;DR: 本文提出了一种基于学习的轨迹跟踪控制器，可用于运动可用SE(3)描述的自主机器人平台。算法利用对偶四元数和高斯过程，实现对未知扰动和模型误差的在线学习与补偿，并有理论稳定性保障。仿真验证了该方法对各种现实扰动下的鲁棒性和精度。


<details>
  <summary>Details</summary>
Motivation: 传统轨迹控制器难以应对机器人运动中的未知扰动（如传感器误差、环境不确定性、未建模机理等），尤其在复杂刚体运动描述(SE(3))下，模型不确定性更加突出。因此，需要一种能在线学习和补偿未知扰动的控制方法，提升自主系统的鲁棒性和精度。

Method: 方法在对偶四元数框架下构建几何反馈控制律，并将高斯过程回归用于在线学习和补偿对位姿影响的未知、状态相关扰动，无需明确参数化未知项。控制律作用于角速度与线速度层次，适合多种机器人平台。同时通过Lyapunov分析，证明在GP不确定性有界时系统误差有概率型有界性保证。

Result: 仿真结果表明，在存在现实传感器干扰（如受磁力计影响的相关旋转与平移扰动）下，所提算法表现出精确且平滑的轨迹跟踪能力，验证了方法面对非理想环境扰动的鲁棒性和有效性。

Conclusion: 结合几何建模与概率学习，可以有效提升自主机器人在未知复杂干扰环境下的运动控制精度与鲁棒性，为无需精确建模条件下的自主系统轨迹控制提供了新途径。

Abstract: We propose a learning-based trajectory tracking controller for autonomous robotic platforms whose motion can be described kinematically on $\mathrm{SE}(3)$. The controller is formulated in the dual quaternion framework and operates at the velocity level, assuming direct command of angular and linear velocities, as is standard in many aerial vehicles and omnidirectional mobile robots. Gaussian Process (GP) regression is integrated into a geometric feedback law to learn and compensate online for unknown, state-dependent disturbances and modeling imperfections affecting both attitude and position, while preserving the algebraic structure and coupling properties inherent to rigid-body motion.
  The proposed approach does not rely on explicit parametric models of the unknown effects, making it well-suited for robotic systems subject to sensor-induced disturbances, unmodeled actuation couplings, and environmental uncertainties. A Lyapunov-based analysis establishes probabilistic ultimate boundedness of the pose tracking error under bounded GP uncertainty, providing formal stability guarantees for the learning-based controller.
  Simulation results demonstrate accurate and smooth trajectory tracking in the presence of realistic, localized disturbances, including correlated rotational and translational effects arising from magnetometer perturbations. These results illustrate the potential of combining geometric modeling and probabilistic learning to achieve robust, data-efficient pose control for autonomous robotic systems.

</details>


### [178] [A High-Fidelity Digital Twin for Robotic Manipulation Based on 3D Gaussian Splatting](https://arxiv.org/abs/2601.03200)
*Ziyang Sun,Lingfan Bao,Tianhu Peng,Jingcheng Sun,Chengxu Zhou*

Main category: cs.RO

TL;DR: 提出了一种基于3D Gaussian Splatting (3DGS) 的新框架，能够在几分钟内用稀疏RGB输入高效、真实地重建数字孪生体，并自动生成供机器人运动规划用的碰撞模型，验证了其在实际任务中的优良性能。


<details>
  <summary>Details</summary>
Motivation: 当前数字孪生体的构建速度慢、视觉真实度有限，且难以自动转换为机器人运动规划需要的碰撞几何体，阻碍了机器人仿真到现实的迁移。

Method: 采用3D Gaussian Splatting技术进行快速、真实的三维场景重建，同时结合可见性感知的语义融合实现高精度3D标注，并提出基于滤波的高效几何体转换方法，自动生成运动规划可用的碰撞模型，并与Unity-ROS2-MoveIt物理引擎无缝集成。

Result: 在Franka Emika Panda机器人实际抓取任务中，数字孪生体的几何和语义一致性带来了稳健的操控性能，提升了真实世界操作的鲁棒性。

Conclusion: 基于3DGS的数字孪生体框架能够高效、准确地实现从感知到操控的数据闭环，为机器人在复杂环境中的应用提供了一条可靠、可扩展的路径。

Abstract: Developing high-fidelity, interactive digital twins is crucial for enabling closed-loop motion planning and reliable real-world robot execution, which are essential to advancing sim-to-real transfer. However, existing approaches often suffer from slow reconstruction, limited visual fidelity, and difficulties in converting photorealistic models into planning-ready collision geometry. We present a practical framework that constructs high-quality digital twins within minutes from sparse RGB inputs. Our system employs 3D Gaussian Splatting (3DGS) for fast, photorealistic reconstruction as a unified scene representation. We enhance 3DGS with visibility-aware semantic fusion for accurate 3D labelling and introduce an efficient, filter-based geometry conversion method to produce collision-ready models seamlessly integrated with a Unity-ROS2-MoveIt physics engine. In experiments with a Franka Emika Panda robot performing pick-and-place tasks, we demonstrate that this enhanced geometric accuracy effectively supports robust manipulation in real-world trials. These results demonstrate that 3DGS-based digital twins, enriched with semantic and geometric consistency, offer a fast, reliable, and scalable path from perception to manipulation in unstructured environments.

</details>
