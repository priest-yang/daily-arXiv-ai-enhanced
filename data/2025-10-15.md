<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 88]
- [cs.CL](#cs.CL) [Total: 62]
- [cs.RO](#cs.RO) [Total: 26]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Enhancing the Quality of 3D Lunar Maps Using JAXA's Kaguya Imagery](https://arxiv.org/abs/2510.11817)
*Yumi Iwashita,Haakon Moe,Yang Cheng,Adnan Ansar,Georgios Georgakis,Adrian Stoica,Kazuto Nakashima,Ryo Kurazume,Jim Torresen*

Main category: cs.CV

TL;DR: 本文提出了一种提升Kaguya TC（Terrain Camera）影像生成的月球3D地图质量的方法，主要通过减少压缩图像带来的视差噪声，提高高程数据的精度。


<details>
  <summary>Details</summary>
Motivation: 随着全球月球探索步伐加快，特别是长距离月球探测任务（如NASA的Endurance任务），对高质量3D月面地图的需求日益重要。目前Kaguya TC影像虽有全球覆盖，但由于立体匹配误差和JPEG压缩带来的伪影导致高程精度不足，限制了地图的实际应用。

Method: 对Kaguya TC影像的压缩行为和由此带来的系统性视差噪声（特别是暗部区域）进行分析，提出新方法以降低由压缩引入的剩余噪声，从而改善从压缩图像生成的视差和高程数据。

Result: 实验结果表明，该方法显著降低了高程噪声，提高了月球3D地图的精度与可靠性。

Conclusion: 提出的降噪方法可显著提升基于Kaguya TC压缩影像的3D地图质量，对今后月球任务中的地形数据安全性与可靠性具有积极意义。

Abstract: As global efforts to explore the Moon intensify, the need for high-quality 3D
lunar maps becomes increasingly critical-particularly for long-distance
missions such as NASA's Endurance mission concept, in which a rover aims to
traverse 2,000 km across the South Pole-Aitken basin. Kaguya TC (Terrain
Camera) images, though globally available at 10 m/pixel, suffer from altitude
inaccuracies caused by stereo matching errors and JPEG-based compression
artifacts. This paper presents a method to improve the quality of 3D maps
generated from Kaguya TC images, focusing on mitigating the effects of
compression-induced noise in disparity maps. We analyze the compression
behavior of Kaguya TC imagery, and identify systematic disparity noise
patterns, especially in darker regions. In this paper, we propose an approach
to enhance 3D map quality by reducing residual noise in disparity images
derived from compressed images. Our experimental results show that the proposed
approach effectively reduces elevation noise, enhancing the safety and
reliability of terrain data for future lunar missions.

</details>


### [2] [Data or Language Supervision: What Makes CLIP Better than DINO?](https://arxiv.org/abs/2510.11835)
*Yiming Liu,Yuhui Zhang,Dhruba Ghosh,Ludwig Schmidt,Serena Yeung-Levy*

Main category: cs.CV

TL;DR: 本文探究了CLIP与DINO作为视觉编码器在视觉-语言模型（VLM）中的差异，重点分析其性能优势源自语言监督还是数据量。通过统一架构和训练配置进行对比实验，分析特征嵌入与VLM实际表现。


<details>
  <summary>Details</summary>
Motivation: 尽管CLIP作为视觉编码器在VLM中表现优越，但不清楚其优势究竟来自于语言监督还是庞大的训练数据。本研究动机是系统性剖析和量化两者的实际影响。

Method: 作者在相同的神经网络架构、数据集和训练配置下，分别对CLIP（带语言监督）和DINO（自监督）进行预训练，并确保它们在ImageNet上取得相近的精度。随后，采用向量嵌入分析和实际VLM下游任务（如20个VQA基准测试）对比性能。此外，还测试了不同的语言监督变体。

Result: 分析发现，CLIP的特征更注重高层语义（如物体类别、文本），DINO则更关注低层视觉属性（如颜色、风格）。在VLM任务中，CLIP在文本密集的任务上表现出色，而DINO在纯视觉任务上略胜一筹。增加语言监督的方式（如不同损失函数、预训练语言编码器）提升有限。

Conclusion: CLIP对VLM性能的贡献更多体现在其语义特性，不同类型的监督和数据配置对VLM有显著影响。研究为设计高效视觉编码器及提升VLM整体性能提供了理论和实践指导。

Abstract: CLIP outperforms self-supervised models like DINO as vision encoders for
vision-language models (VLMs), but it remains unclear whether this advantage
stems from CLIP's language supervision or its much larger training data. To
disentangle these factors, we pre-train CLIP and DINO under controlled settings
-- using the same architecture, dataset, and training configuration --
achieving similar ImageNet accuracy. Embedding analysis shows that CLIP
captures high-level semantics (e.g., object categories, text), while DINO is
more responsive to low-level features like colors and styles. When integrated
into VLMs and evaluated on 20 VQA benchmarks, CLIP excels at text-intensive
tasks, while DINO slightly outperforms on vision-centric ones. Variants of
language supervision (e.g., sigmoid loss, pre-trained language encoders) yield
limited gains. Our findings provide scientific insights into vision encoder
design and its impact on VLM performance.

</details>


### [3] [MammoDINO: Anatomically Aware Self-Supervision for Mammographic Images](https://arxiv.org/abs/2510.11883)
*Sicheng Zhou,Lei Wu,Cao Xiao,Parminder Bhatia,Taha Kass-Hout*

Main category: cs.CV

TL;DR: 本文提出了MammoDINO，一种用于乳腺X光图像的自监督学习(SSL)框架，在140万乳腺影像上进行了预训练，并在多项乳腺癌筛查任务中实现了最新性能。


<details>
  <summary>Details</summary>
Motivation: 目前自监督学习在医学影像领域应用不足，主要原因包括数据有限和医学领域的特殊偏差。本研究旨在填补乳腺影像自监督预训练的空白，提升乳腺癌影像诊断的效率和准确性。

Method: MammoDINO采用面向乳腺组织的增强采样方法，结合图像级与块级监督。此外，利用3D乳腺数字断层摄影(3D-DBT)结构，引入了跨切片对比学习目标，将丰富的3D结构信息融入2D预训练中。

Result: MammoDINO在多项乳腺癌筛查任务及五个基准数据集上均取得了SOTA（最新最好）表现，展现出良好的泛化能力。

Conclusion: 该方法为多用途乳腺影像CAD工具提供了可扩展、无需标注的预训练基础，有助于减轻放射科医生的工作负担，提高乳腺癌筛查的诊断效率。

Abstract: Self-supervised learning (SSL) has transformed vision encoder training in
general domains but remains underutilized in medical imaging due to limited
data and domain specific biases. We present MammoDINO, a novel SSL framework
for mammography, pretrained on 1.4 million mammographic images. To capture
clinically meaningful features, we introduce a breast tissue aware data
augmentation sampler for both image-level and patch-level supervision and a
cross-slice contrastive learning objective that leverages 3D digital breast
tomosynthesis (DBT) structure into 2D pretraining. MammoDINO achieves
state-of-the-art performance on multiple breast cancer screening tasks and
generalizes well across five benchmark datasets. It offers a scalable,
annotation-free foundation for multipurpose computer-aided diagnosis (CAD)
tools for mammogram, helping reduce radiologists' workload and improve
diagnostic efficiency in breast cancer screening.

</details>


### [4] [Task-Specific Dual-Model Framework for Comprehensive Traffic Safety Video Description and Analysis](https://arxiv.org/abs/2510.11907)
*Blessing Agyei Kyem,Neema Jakisa Owor,Andrews Danyo,Joshua Kofi Asamoah,Eugene Denteh,Tanner Muturi,Anthony Dontoh,Yaw Adu-Gyamfi,Armstrong Aboah*

Main category: cs.CV

TL;DR: 该论文提出了一种利用双模型架构的视频理解方法，分别针对视频描述和视觉问答单独训练模型，从而提高交通安全分析的性能，并在2025 AI City Challenge Track 2 中获得了第十名的成绩。


<details>
  <summary>Details</summary>
Motivation: 交通安全需要从监控视频中深度理解复杂行为细节，为事故预防提供支持。现有方法很难同时高效处理视频描述和视觉问答任务，有任务干扰、表现有限等问题。

Method: 作者设计了一个双模型架构，分别用VideoLLaMA进行视频描述训练、Qwen2.5-VL进行视觉问答训练，通过分离训练的方式让每个模型各自专精并减少任务干扰。在WTS数据集和挑战赛中进行了大量实验与消融分析。

Result: 分离训练的双模型架构在视频描述上VideoLLaMA取得CIDEr分数1.1001，在视觉问答上Qwen2.5-VL获得60.80%的准确率，总体在挑战赛S2分数为45.7572、排名第十，消融实验显示VQA准确率比联合训练高8.6%。

Conclusion: 这种分离任务训练的双模型方案，有效提升了复杂视频理解中描述与问答的整体表现，为交通安全视频分析提供了更强支持。

Abstract: Traffic safety analysis requires complex video understanding to capture
fine-grained behavioral patterns and generate comprehensive descriptions for
accident prevention. In this work, we present a unique dual-model framework
that strategically utilizes the complementary strengths of VideoLLaMA and
Qwen2.5-VL through task-specific optimization to address this issue. The core
insight behind our approach is that separating training for captioning and
visual question answering (VQA) tasks minimizes task interference and allows
each model to specialize more effectively. Experimental results demonstrate
that VideoLLaMA is particularly effective in temporal reasoning, achieving a
CIDEr score of 1.1001, while Qwen2.5-VL excels in visual understanding with a
VQA accuracy of 60.80\%. Through extensive experiments on the WTS dataset, our
method achieves an S2 score of 45.7572 in the 2025 AI City Challenge Track 2,
placing 10th on the challenge leaderboard. Ablation studies validate that our
separate training strategy outperforms joint training by 8.6\% in VQA accuracy
while maintaining captioning quality.

</details>


### [5] [PanoTPS-Net: Panoramic Room Layout Estimation via Thin Plate Spline Transformation](https://arxiv.org/abs/2510.11992)
*Hatem Ibrahem,Ahmed Salem,Qinmin Vivian Hu,Guanghui Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新的利用全景图片进行房间三维布局估计的方法，名为PanoTPS-Net。该方法结合了卷积神经网络（CNN）和薄板样条（TPS）空间变换，可以高效地处理立方体与非立方体结构的房间布局，并在多个数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 房间三维布局估计对于机器人、增强现实和室内设计等应用具有重要意义。目前的方法在处理非立方体房间结构和泛化能力上仍有局限，因此亟需一种更加灵活且通用的解决方案。

Method: PanoTPS-Net的方法分为两个阶段：第一阶段，CNN从全景输入图像中提取高级特征并学习TPS空间变换的参数；第二阶段，利用预测得到的TPS参数，将参考布局变换为目标房间布局，从而实现对不同形状房间的适应。通过这样结合CNN与TPS变换的方法，实现了对各种复杂房间布局的更好估计。

Result: 在公开数据集PanoContext、Stanford-2D3D、Matterport3DLayout和ZInD上，PanoTPS-Net分别获得了3DIoU为85.49、86.16、81.76和91.98的优秀成绩，明显优于现有主流方法，且对多种类型房间结构都具有很好的鲁棒性。

Conclusion: PanoTPS-Net有效结合了CNN与TPS空间变换，提升了房间三维布局估计的精度和适应性。实验证明该方法能准确处理各种房间布局，尤其是更复杂的非立方体结构，并优于此前的主流方法。源码已开源。

Abstract: Accurately estimating the 3D layout of rooms is a crucial task in computer
vision, with potential applications in robotics, augmented reality, and
interior design. This paper proposes a novel model, PanoTPS-Net, to estimate
room layout from a single panorama image. Leveraging a Convolutional Neural
Network (CNN) and incorporating a Thin Plate Spline (TPS) spatial
transformation, the architecture of PanoTPS-Net is divided into two stages:
First, a convolutional neural network extracts the high-level features from the
input images, allowing the network to learn the spatial parameters of the TPS
transformation. Second, the TPS spatial transformation layer is generated to
warp a reference layout to the required layout based on the predicted
parameters. This unique combination empowers the model to properly predict room
layouts while also generalizing effectively to both cuboid and non-cuboid
layouts. Extensive experiments on publicly available datasets and comparisons
with state-of-the-art methods demonstrate the effectiveness of the proposed
method. The results underscore the model's accuracy in room layout estimation
and emphasize the compatibility between the TPS transformation and panorama
images. The robustness of the model in handling both cuboid and non-cuboid room
layout estimation is evident with a 3DIoU value of 85.49, 86.16, 81.76, and
91.98 on PanoContext, Stanford-2D3D, Matterport3DLayout, and ZInD datasets,
respectively. The source code is available at:
https://github.com/HatemHosam/PanoTPS_Net.

</details>


### [6] [Prompt-Guided Spatial Understanding with RGB-D Transformers for Fine-Grained Object Relation Reasoning](https://arxiv.org/abs/2510.11996)
*Tanner Muturi,Blessing Agyei Kyem,Joshua Kofi Asamoah,Neema Jakisa Owor,Richard Dyzinela,Andrews Danyo,Yaw Adu-Gyamfi,Armstrong Aboah*

Main category: cs.CV

TL;DR: 本论文提出了一种空间推理框架，通过在输入中嵌入物体包围框坐标，提升了AI系统在仓库等复杂3D场景的空间理解能力，并在AI City Challenge竞赛中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言系统在大型复杂3D环境（如仓库）中空间推理效果不佳，主要因为场景杂乱、遮挡严重，以及缺乏明确的空间基础，因此需要一种能够提升空间理解的新方法。

Method: 本研究为AI City Challenge的Warehouse数据集设计了空间推理框架。主要方法是将物体掩膜的包围框坐标作为结构化信息嵌入到输入prompt中，让模型能直接利用物体的几何和布局信息。该框架在距离估算、物体计数、多选定位和空间关系推理四类问题上分别进行微调，并通过在训练集里追加规范化答案优化一致性。

Result: 所提方法形成了完整的处理管线，在公开排行榜上取得73.0606分，排名第4，显示出较强性能。

Conclusion: 结构化提示增强以及任务特定优化对提升工业场景下空间推理能力有效。该方法在真实场景的空间智能任务中表现出色，有助于推动相关行业应用。

Abstract: Spatial reasoning in large-scale 3D environments such as warehouses remains a
significant challenge for vision-language systems due to scene clutter,
occlusions, and the need for precise spatial understanding. Existing models
often struggle with generalization in such settings, as they rely heavily on
local appearance and lack explicit spatial grounding. In this work, we
introduce a dedicated spatial reasoning framework for the Physical AI Spatial
Intelligence Warehouse dataset introduced in the Track 3 2025 AI City
Challenge. Our approach enhances spatial comprehension by embedding mask
dimensions in the form of bounding box coordinates directly into the input
prompts, enabling the model to reason over object geometry and layout. We
fine-tune the framework across four question categories namely: Distance
Estimation, Object Counting, Multi-choice Grounding, and Spatial Relation
Inference using task-specific supervision. To further improve consistency with
the evaluation system, normalized answers are appended to the GPT response
within the training set. Our comprehensive pipeline achieves a final score of
73.0606, placing 4th overall on the public leaderboard. These results
demonstrate the effectiveness of structured prompt enrichment and targeted
optimization in advancing spatial reasoning for real-world industrial
environments.

</details>


### [7] [Evaluating the Explainability of Vision Transformers in Medical Imaging](https://arxiv.org/abs/2510.12021)
*Leili Barekatain,Ben Glocker*

Main category: cs.CV

TL;DR: 本文比较了多种视觉Transformer模型（ViT、DeiT、DINO、Swin）及其不同训练策略在医学影像任务中的可解释性表现，发现DINO结合Grad-CAM方法可提供最准确、局部的可解释性热图，提升了模型透明度及医学信任度。


<details>
  <summary>Details</summary>
Motivation: 医学影像领域，模型的可解释性直接影响其在临床的信任与推广。虽然视觉Transformer（ViT）模型取得了优异表现，但其复杂的注意力机制让决策过程难以解释。因此，研究如何提升这些模型的可解释性，对推动其在医学领域应用至关重要。

Method: 作者评估了ViT、DeiT、DINO和Swin Transformer四种架构及其预训练策略，采用Gradient Attention Rollout与Grad-CAM两种可解释性方法，在血细胞分类与乳腺超声图像分类两个任务上进行定量和定性分析，比较不同方法在模型解释上的效果。

Result: 实验结果显示，DINO模型结合Grad-CAM方法能在不同数据集上给出最可信和更具局部相关性的解释热图。Grad-CAM产出的热图在类别区分和空间定位方面具有明显优势，而Gradient Attention Rollout则提供较为分散的激活区域。即使在模型误判时，DINO与Grad-CAM方法也能突出关键但混淆模型的临床相关结构特征。

Conclusion: 本研究表明，采用DINO与Grad-CAM能有效提升医疗视觉Transformer在关键诊断任务中的可解释性和透明度，为其在医疗诊断流程中的可靠落地提供支持。

Abstract: Understanding model decisions is crucial in medical imaging, where
interpretability directly impacts clinical trust and adoption. Vision
Transformers (ViTs) have demonstrated state-of-the-art performance in
diagnostic imaging; however, their complex attention mechanisms pose challenges
to explainability. This study evaluates the explainability of different Vision
Transformer architectures and pre-training strategies - ViT, DeiT, DINO, and
Swin Transformer - using Gradient Attention Rollout and Grad-CAM. We conduct
both quantitative and qualitative analyses on two medical imaging tasks:
peripheral blood cell classification and breast ultrasound image
classification. Our findings indicate that DINO combined with Grad-CAM offers
the most faithful and localized explanations across datasets. Grad-CAM
consistently produces class-discriminative and spatially precise heatmaps,
while Gradient Attention Rollout yields more scattered activations. Even in
misclassification cases, DINO with Grad-CAM highlights clinically relevant
morphological features that appear to have misled the model. By improving model
transparency, this research supports the reliable and explainable integration
of ViTs into critical medical diagnostic workflows.

</details>


### [8] [APGNet: Adaptive Prior-Guided for Underwater Camouflaged Object Detection](https://arxiv.org/abs/2510.12056)
*Xinxin Huang,Han Sun,Junmin Cai,Ningzhong Liu,Huiyu Zhou*

Main category: cs.CV

TL;DR: 该论文提出了一种专为水下伪装目标检测设计的新方法APGNet，显著提升在复杂水下环境中的检测效果。


<details>
  <summary>Details</summary>
Motivation: 水下环境中的图像常因光学退化（如对比度低、颜色失真）和目标自然伪装导致检测难度大。现有方法多为地面场景设计，并未充分考虑水下特性，检测效果有限。

Method: 作者提出APGNet（自适应先验引导网络），结合了Siamese架构与新颖的先验引导机制。具体包括：1）利用MSRCR算法进行数据增强，得到抗光照退化的图像；2）设计ERF模块和MPD模块，融合多尺度上下文信息，优化特征表达；3）通过分层融合位置信息和边界先验，实现粗定位与轮廓细化。

Result: 在两个公开的MAS数据集上，APGNet在多项主流评测指标下均优于现有的15种主流方法，性能突出。

Conclusion: APGNet有效解决了水下图像退化和伪装目标检测的难点，在水下生态研究和资源探测领域具有良好的应用前景。

Abstract: Detecting camouflaged objects in underwater environments is crucial for
marine ecological research and resource exploration. However, existing methods
face two key challenges: underwater image degradation, including low contrast
and color distortion, and the natural camouflage of marine organisms.
Traditional image enhancement techniques struggle to restore critical features
in degraded images, while camouflaged object detection (COD) methods developed
for terrestrial scenes often fail to adapt to underwater environments due to
the lack of consideration for underwater optical characteristics.
  To address these issues, we propose APGNet, an Adaptive Prior-Guided Network,
which integrates a Siamese architecture with a novel prior-guided mechanism to
enhance robustness and detection accuracy. First, we employ the Multi-Scale
Retinex with Color Restoration (MSRCR) algorithm for data augmentation,
generating illumination-invariant images to mitigate degradation effects.
Second, we design an Extended Receptive Field (ERF) module combined with a
Multi-Scale Progressive Decoder (MPD) to capture multi-scale contextual
information and refine feature representations. Furthermore, we propose an
adaptive prior-guided mechanism that hierarchically fuses position and boundary
priors by embedding spatial attention in high-level features for coarse
localization and using deformable convolution to refine contours in low-level
features.
  Extensive experimental results on two public MAS datasets demonstrate that
our proposed method APGNet outperforms 15 state-of-art methods under widely
used evaluation metrics.

</details>


### [9] [VIDMP3: Video Editing by Representing Motion with Pose and Position Priors](https://arxiv.org/abs/2510.12069)
*Sandeep Mishra,Oindrila Saha,Alan C. Bovik*

Main category: cs.CV

TL;DR: VidMP3提出一种基于动作捕捉先验的新型视频编辑方法，在保留运动的同时灵活实现结构和语义上的变化，并显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑方法对结构可变性的支持有限，存在时序不一致、主体漂移以及高度依赖人工操作等问题，影响了内容创作者对视频灵活编辑的需求。

Method: VidMP3利用人体姿态和位置先验，学习视频的通用运动表征。这样既能保留原始运动，又实现被编辑对象在结构和语义上的灵活变换。该方法通过结合扩散模型和动作先验，解决了结构变化下的运动一致性和主体一致性难题。

Result: 该方法在主观和客观评测上均优于现有方法，有效提升了视频编辑过程的灵活性和质量，减小了人工干预需求。

Conclusion: VidMP3为结构和语义可变的动作保留型视频编辑任务带来了更好的一致性与自由度，是视频内容创作领域的重要进步。

Abstract: Motion-preserved video editing is crucial for creators, particularly in
scenarios that demand flexibility in both the structure and semantics of
swapped objects. Despite its potential, this area remains underexplored.
Existing diffusion-based editing methods excel in structure-preserving tasks,
using dense guidance signals to ensure content integrity. While some recent
methods attempt to address structure-variable editing, they often suffer from
issues such as temporal inconsistency, subject identity drift, and the need for
human intervention. To address these challenges, we introduce VidMP3, a novel
approach that leverages pose and position priors to learn a generalized motion
representation from source videos. Our method enables the generation of new
videos that maintain the original motion while allowing for structural and
semantic flexibility. Both qualitative and quantitative evaluations demonstrate
the superiority of our approach over existing methods. The code will be made
publicly available at https://github.com/sandeep-sm/VidMP3.

</details>


### [10] [A Review on Domain Adaption and Generative Adversarial Networks(GANs)](https://arxiv.org/abs/2510.12075)
*Aashish Dhawan,Divyanshu Mudgal*

Main category: cs.CV

TL;DR: 本文探讨了在图像分类任务中如何通过领域自适应（Domain Adaptation）技术，缓解高质量标注数据稀缺的问题。重点分析了多种领域自适应方法，以实现用一种类型的数据训练的模型在另一类相关领域上获得良好表现。


<details>
  <summary>Details</summary>
Motivation: 在计算机视觉，尤其是图像分类领域，标注数据的匮乏与高昂的人工成本制约了模型性能。论文旨在找到能够应对数据不足、减少对标注数据依赖的有效方法。

Method: 论文主要讨论领域自适应方法，即利用在一个领域（如画作中的飞机）训练好的模型，对另一个相关但不同领域（如真实照片中的飞机）进行预测。论文还将对不同的领域自适应技术和实现方式进行综述。

Result: 虽然摘要未描述具体实验结果，论文主要聚焦于多种领域自适应方法的系统性比较和分析，评估这些方法在数据稀缺场景下的有效性。

Conclusion: 领域自适应能够部分缓解高质量标注数据不足的问题，使训练于一个领域的模型能较好地泛化到相关但不同的新领域，提高了图像分类任务在数据稀缺情况下的鲁棒性与可用性。

Abstract: The major challenge in today's computer vision scenario is the availability
of good quality labeled data. In a field of study like image classification,
where data is of utmost importance, we need to find more reliable methods which
can overcome the scarcity of data to produce results comparable to previous
benchmark results. In most cases, obtaining labeled data is very difficult
because of the high cost of human labor and in some cases impossible. The
purpose of this paper is to discuss Domain Adaptation and various methods to
implement it. The main idea is to use a model trained on a particular dataset
to predict on data from a different domain of the same kind, for example - a
model trained on paintings of airplanes predicting on real images of airplanes

</details>


### [11] [Playmate2: Training-Free Multi-Character Audio-Driven Animation via Diffusion Transformer with Reward Feedback](https://arxiv.org/abs/2510.12089)
*Xingpei Ma,Shenneng Huang,Jiaran Cai,Yuansheng Guan,Shen Zheng,Hanfeng Zhao,Qiang Zhang,Shunsi Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种基于Diffusion Transformer（DiT）的音频驱动人像视频生成新框架，解决了当前方法在唇形同步、长时序连贯性和多角色动画等方面的难题。该方法使用高效训练策略和无训练多角色生成方法，显著提升了生成质量和灵活性。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型最近在音频驱动的人像视频生成中取得了进展，但现有方法在唇形同步、长视频的时序连贯、以及多角色动画等挑战上仍存在局限，因此需要新方法进一步提升生成质量和多样性。

Method: 1）以Diffusion Transformer为基础，结合LoRA微调策略与位置偏移推理，提升长视频生成能力。
2）采用参数部分更新与奖励反馈机制，强化唇形同步与自然体态动作。
3）提出无训练的Mask Classifier-Free Guidance（Mask-CFG）方法，无需额外数据或模型变更即可实现多角色音频驱动的动画生成。

Result: 实验结果表明，提出的方法较现有最先进方法在视频质量、时序连贯性和多角色支持方面均有显著提升。可生成高质量、任意长度、且多角色参与的音频驱动视频。

Conclusion: 本文提出的框架简单高效、成本低，在音频驱动的多角色人像视频生成任务中达到了更优效果，为该领域带来了新的发展方向。

Abstract: Recent advances in diffusion models have significantly improved audio-driven
human video generation, surpassing traditional methods in both quality and
controllability. However, existing approaches still face challenges in lip-sync
accuracy, temporal coherence for long video generation, and multi-character
animation. In this work, we propose a diffusion transformer (DiT)-based
framework for generating lifelike talking videos of arbitrary length, and
introduce a training-free method for multi-character audio-driven animation.
First, we employ a LoRA-based training strategy combined with a position shift
inference approach, which enables efficient long video generation while
preserving the capabilities of the foundation model. Moreover, we combine
partial parameter updates with reward feedback to enhance both lip
synchronization and natural body motion. Finally, we propose a training-free
approach, Mask Classifier-Free Guidance (Mask-CFG), for multi-character
animation, which requires no specialized datasets or model modifications and
supports audio-driven animation for three or more characters. Experimental
results demonstrate that our method outperforms existing state-of-the-art
approaches, achieving high-quality, temporally coherent, and multi-character
audio-driven video generation in a simple, efficient, and cost-effective
manner.

</details>


### [12] [IL3D: A Large-Scale Indoor Layout Dataset for LLM-Driven 3D Scene Generation](https://arxiv.org/abs/2510.12095)
*Wenxu Zhou,Kaixuan Nie,Hang Du,Dong Yin,Wei Huang,Siqiang Guo,Xiaobo Zhang,Pengbo Hu*

Main category: cs.CV

TL;DR: 本文提出了IL3D，这是一个面向大语言模型（LLM）驱动的三维场景生成的大规模数据集，专为室内布局设计打造，含有丰富的高质量训练数据，可用于多模态视觉任务。


<details>
  <summary>Details</summary>
Motivation: 当前用于LLM驱动的3D场景生成任务的高质量、多样化的训练数据极其稀缺，限制了视觉-语言模型的研究和应用。因此，急需设计一个丰富、精细的数据集来推进相关领域发展。

Method: 作者构建了IL3D数据集，包含27,816个不同类型室内布局，18种常见房间类型，附带29,215个高质量3D物体资产，并配有详细的自然语言实例级注释。此外，数据集支持多种数据导出格式以适应不同视觉任务。作者还建立了严格的评测基准，并通过实验对比分析了用IL3D进行SFT后LLM在场景生成任务上的泛化能力提升。

Result: 实验表明，在IL3D数据集上进行SFT（有监督微调）显著提升了LLM在3D场景生成中的泛化能力，表现优于在其他数据集上的SFT。

Conclusion: IL3D作为一个多样且健壮的多模态3D场景数据集，对推进3D场景生成和具身智能研究具有重要意义，能为环境感知、场景生成等多种任务提供高保真支持。

Abstract: In this study, we present IL3D, a large-scale dataset meticulously designed
for large language model (LLM)-driven 3D scene generation, addressing the
pressing demand for diverse, high-quality training data in indoor layout
design. Comprising 27,816 indoor layouts across 18 prevalent room types and a
library of 29,215 high-fidelity 3D object assets, IL3D is enriched with
instance-level natural language annotations to support robust multimodal
learning for vision-language tasks. We establish rigorous benchmarks to
evaluate LLM-driven scene generation. Experimental results show that supervised
fine-tuning (SFT) of LLMs on IL3D significantly improves generalization and
surpasses the performance of SFT on other datasets. IL3D offers flexible
multimodal data export capabilities, including point clouds, 3D bounding boxes,
multiview images, depth maps, normal maps, and semantic masks, enabling
seamless adaptation to various visual tasks. As a versatile and robust
resource, IL3D significantly advances research in 3D scene generation and
embodied intelligence, by providing high-fidelity scene data to support
environment perception tasks of embodied agents.

</details>


### [13] [An Adaptive Edge-Guided Dual-Network Framework for Fast QR Code Motion Deblurring](https://arxiv.org/abs/2510.12098)
*Jianping Li,Dongyang Guo,Wenjie Li,Wei Zhao*

Main category: cs.CV

TL;DR: 本文聚焦于二维码去模糊，提出通过显式引入边缘先验提升复原性能，并通过适应性网络结构兼顾精度和速度。


<details>
  <summary>Details</summary>
Motivation: 二维码去模糊的主要目标是保障二维码的成功解码，而非单纯追求感知质量。二维码自身具有结构化且边缘清晰的特性，这为复原提供了有力的先验信息。但现有深度学习方法往往未能明确利用这些先验，因此有提升空间。

Method: 作者提出了边缘引导注意块（EGAB），将显式的边缘先验嵌入Transformer架构。基于此设计了EG-Restormer网络用于严重模糊场景；对于轻度模糊场景，设计了高效轻量的LENet网络。最终通过ADNet框架实现两网络自适应选择以应对不同模糊程度，适用于移动设备。

Result: 大量实验表明，EG-Restormer与ADNet在二维码复原及解码率上均达到了当前最佳水平，并具备较快运行速度。

Conclusion: 结合边缘先验与双网络自适应机制，不仅有效提升了二维码去模糊性能，也做到了速度与准确性的平衡，尤其适合于资源受限的移动终端应用。

Abstract: Unlike general image deblurring that prioritizes perceptual quality, QR code
deblurring focuses on ensuring successful decoding. QR codes are characterized
by highly structured patterns with sharp edges, a robust prior for restoration.
Yet existing deep learning methods rarely exploit these priors explicitly. To
address this gap, we propose the Edge-Guided Attention Block (EGAB), which
embeds explicit edge priors into a Transformer architecture. Based on EGAB, we
develop Edge-Guided Restormer (EG-Restormer), an effective network that
significantly boosts the decoding rate of severely blurred QR codes. For mildly
blurred inputs, we design the Lightweight and Efficient Network (LENet) for
fast deblurring. We further integrate these two networks into an Adaptive
Dual-network (ADNet), which dynamically selects the suitable network based on
input blur severity, making it ideal for resource-constrained mobile devices.
Extensive experiments show that our EG-Restormer and ADNet achieve
state-of-the-art performance with a competitive speed. Project page:
https://github.com/leejianping/ADNet

</details>


### [14] [G4Splat: Geometry-Guided Gaussian Splatting with Generative Prior](https://arxiv.org/abs/2510.12099)
*Junfeng Ni,Yixin Chen,Zhifei Yang,Yu Liu,Ruijie Lu,Song-Chun Zhu,Siyuan Huang*

Main category: cs.CV

TL;DR: 本文提出了一种基于平面结构的几何引导方法，提升利用生成扩散模型进行3D场景重建的效果，实现了对几何与外观的一致且高质量重建，尤其在未观察区域表现突出。


<details>
  <summary>Details</summary>
Motivation: 当前利用预训练扩散模型的3D场景生成方法存在两大问题：一是缺乏稳定的几何监督，导致已观测和未观测区域重建质量不高；二是缺少有效机制解决多视角生成图像的不一致性，造成形状-外观歧义和场景几何退化。因此，作者旨在提升3D场景重建的几何精度与多视图一致性。

Method: 作者提出通过挖掘场景中的平面结构以生成精确的、具备度量尺度的深度图，为观测和未观测区提供可靠几何监督，并将该几何信息集成进生成流程，包括可见性掩模估计、新视角选择以及多视图一致性的视频扩散模型修补，不断强化几何与外观一致性。

Result: 在Replica、ScanNet++和DeepBlending等主流数据集上，实验表明该方法在几何和外观重建精度上均优于现有主流方法，尤其是在未观测区域的表现提升显著。同时，该方法适用于单视图输入和无位姿信息视频，具备强泛化能力，无论室内还是室外场景均表现良好。

Conclusion: 精确的几何信息对于充分利用生成模型提升3D重建至关重要。通过平面结构约束和全流程几何引导，作者的方法成功解决了当前3D重建中的主要瓶颈，并展示出广泛的实际应用潜力。

Abstract: Despite recent advances in leveraging generative prior from pre-trained
diffusion models for 3D scene reconstruction, existing methods still face two
critical limitations. First, due to the lack of reliable geometric supervision,
they struggle to produce high-quality reconstructions even in observed regions,
let alone in unobserved areas. Second, they lack effective mechanisms to
mitigate multi-view inconsistencies in the generated images, leading to severe
shape-appearance ambiguities and degraded scene geometry. In this paper, we
identify accurate geometry as the fundamental prerequisite for effectively
exploiting generative models to enhance 3D scene reconstruction. We first
propose to leverage the prevalence of planar structures to derive accurate
metric-scale depth maps, providing reliable supervision in both observed and
unobserved regions. Furthermore, we incorporate this geometry guidance
throughout the generative pipeline to improve visibility mask estimation, guide
novel view selection, and enhance multi-view consistency when inpainting with
video diffusion models, resulting in accurate and consistent scene completion.
Extensive experiments on Replica, ScanNet++, and DeepBlending show that our
method consistently outperforms existing baselines in both geometry and
appearance reconstruction, particularly for unobserved regions. Moreover, our
method naturally supports single-view inputs and unposed videos, with strong
generalizability in both indoor and outdoor scenarios with practical real-world
applicability. The project page is available at
https://dali-jack.github.io/g4splat-web/.

</details>


### [15] [DRL: Discriminative Representation Learning with Parallel Adapters for Class Incremental Learning](https://arxiv.org/abs/2510.12107)
*Jiawei Zhan,Jun Liu,Jinlong Peng,Xiaochen Chen,Bin-Bin Gao,Yong Liu,Chengjie Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新的增量学习框架（DRL），利用轻量级适配器和解耦锚点监督，实现更优的无回放类增量学习，在多个基准测试中表现优越。


<details>
  <summary>Details</summary>
Motivation: 无回放类增量学习受限于模型复杂度增加、表达迁移不平滑以及阶段性与全局推理的一致性问题，现有方法难以同时高效且鲁棒地解决这些难题。

Method: 提出Discriminative Representation Learning (DRL) 框架，包括基于预训练模型的Incremental Parallel Adapter (IPA)网络，每一增量阶段仅学习小量适配器参数，通过转移门实现表达能力平滑迁移；设计了Decoupled Anchor Supervision (DAS)，分别对正、负样本通过虚拟锚点约束，提升判别力并对齐各阶段特征空间。

Result: 在6个主流数据集上，DRL在增量学习期间各阶段均优于当前主流方法，并保持高效的训练和推理速度。

Conclusion: DRL通过创新网络结构和监督方式，显著提升了无回放类增量学习的表现和效率，是应对相关增量学习挑战的一种有效解决方案。

Abstract: With the excellent representation capabilities of Pre-Trained Models (PTMs),
remarkable progress has been made in non-rehearsal Class-Incremental Learning
(CIL) research. However, it remains an extremely challenging task due to three
conundrums: increasingly large model complexity, non-smooth representation
shift during incremental learning and inconsistency between stage-wise
sub-problem optimization and global inference. In this work, we propose the
Discriminative Representation Learning (DRL) framework to specifically address
these challenges. To conduct incremental learning effectively and yet
efficiently, the DRL's network, called Incremental Parallel Adapter (IPA)
network, is built upon a PTM and increasingly augments the model by learning a
lightweight adapter with a small amount of parameter learning overhead in each
incremental stage. The adapter is responsible for adapting the model to new
classes, it can inherit and propagate the representation capability from the
current model through parallel connection between them by a transfer gate. As a
result, this design guarantees a smooth representation shift between different
incremental stages. Furthermore, to alleviate inconsistency and enable
comparable feature representations across incremental stages, we design the
Decoupled Anchor Supervision (DAS). It decouples constraints of positive and
negative samples by respectively comparing them with the virtual anchor. This
decoupling promotes discriminative representation learning and aligns the
feature spaces learned at different stages, thereby narrowing the gap between
stage-wise local optimization over a subset of data and global inference across
all classes. Extensive experiments on six benchmarks reveal that our DRL
consistently outperforms other state-of-the-art methods throughout the entire
CIL period while maintaining high efficiency in both training and inference
phases.

</details>


### [16] [Self-Supervised Selective-Guided Diffusion Model for Old-Photo Face Restoration](https://arxiv.org/abs/2510.12114)
*Wenjie Li,Xiangyi Wang,Heng Guo,Guangwei Gao,Zhanyu Ma*

Main category: cs.CV

TL;DR: 该论文提出了一种新方法（SSDiff），用于修复受损的老照片人脸区域，通过结构分步骤监督和颜色细化来提升修复效果，并引入了新的数据集VintageFace，在多项指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 老照片常见破损、褪色和严重模糊，现有方法难以同时处理局部损坏和面部颜色失真，且容易出现身份不匹配等问题，限制了修复质量和控制能力。

Method: 提出了一种自监督选择性指导扩散方法（SSDiff），利用预训练扩散模型生成的伪人脸作为参考，通过分阶段监督实现结构和颜色的分别修复，并结合人脸分割图和划痕掩码，实现对局部区域（如断裂部分）的有针对性恢复，最大程度保持面部身份一致性。

Result: SSDiff在新构建的300张真实老照片构成的VintageFace基准上，和主流GAN、扩散方法相比，在感知质量、真实性和局部可控性等多个方面表现更佳。

Conclusion: SSDiff能更有效地修复各种受损的真实老照片人脸区域，尤其在结构和颜色保持、身份一致性及细节恢复方面优于以往方法，为老照片修复领域带来更高水平的新方案。

Abstract: Old-photo face restoration poses significant challenges due to compounded
degradations such as breakage, fading, and severe blur. Existing pre-trained
diffusion-guided methods either rely on explicit degradation priors or global
statistical guidance, which struggle with localized artifacts or face color. We
propose Self-Supervised Selective-Guided Diffusion (SSDiff), which leverages
pseudo-reference faces generated by a pre-trained diffusion model under weak
guidance. These pseudo-labels exhibit structurally aligned contours and natural
colors, enabling region-specific restoration via staged supervision: structural
guidance applied throughout the denoising process and color refinement in later
steps, aligned with the coarse-to-fine nature of diffusion. By incorporating
face parsing maps and scratch masks, our method selectively restores breakage
regions while avoiding identity mismatch. We further construct VintageFace, a
300-image benchmark of real old face photos with varying degradation levels.
SSDiff outperforms existing GAN-based and diffusion-based methods in perceptual
quality, fidelity, and regional controllability. Code link:
https://github.com/PRIS-CV/SSDiff.

</details>


### [17] [ImageSentinel: Protecting Visual Datasets from Unauthorized Retrieval-Augmented Image Generation](https://arxiv.org/abs/2510.12119)
*Ziyuan Luo,Yangyi Zhao,Ka Chun Cheung,Simon See,Renjie Wan*

Main category: cs.CV

TL;DR: 本文提出了一种名为ImageSentinel的新方法，通过合成特殊哨兵图像，用于检测和防止Retrieval-Augmented Image Generation系统对私有图片数据集的未授权使用。


<details>
  <summary>Details</summary>
Motivation: 随着RAIG技术的广泛使用，提升了生成图片质量，但伴随而来的是私有图片数据集被未授权使用的问题。而传统数字水印在RAIG系统中难以起作用，因为RAIG的特征重组和提取过程会破坏水印信号。

Method: 提出ImageSentinel框架，通过生成与原始数据集视觉一致的哨兵图片，这些图片内嵌随机生成的字符序列作为检索密钥。利用视觉-语言模型生成哨兵图像，并实现与原数据集的无缝融合。

Result: 实验结果显示，ImageSentinel能够有效检测数据集的未授权使用，同时保证对被授权应用的生成质量不受损失。

Conclusion: ImageSentinel为保护视觉数据集在RAIG中的所有权和使用权限提供了有效的新方法，兼顾了安全性和实用性。

Abstract: The widespread adoption of Retrieval-Augmented Image Generation (RAIG) has
raised significant concerns about the unauthorized use of private image
datasets. While these systems have shown remarkable capabilities in enhancing
generation quality through reference images, protecting visual datasets from
unauthorized use in such systems remains a challenging problem. Traditional
digital watermarking approaches face limitations in RAIG systems, as the
complex feature extraction and recombination processes fail to preserve
watermark signals during generation. To address these challenges, we propose
ImageSentinel, a novel framework for protecting visual datasets in RAIG. Our
framework synthesizes sentinel images that maintain visual consistency with the
original dataset. These sentinels enable protection verification through
randomly generated character sequences that serve as retrieval keys. To ensure
seamless integration, we leverage vision-language models to generate the
sentinel images. Experimental results demonstrate that ImageSentinel
effectively detects unauthorized dataset usage while preserving generation
quality for authorized applications. Code is available at
https://github.com/luo-ziyuan/ImageSentinel.

</details>


### [18] [Hardware-aware Coding Function Design for Compressive Single-Photon 3D Cameras](https://arxiv.org/abs/2510.12123)
*David Parra,Felipe Gutierrez-Barragan,Trevor Seets,Andreas Velten*

Main category: cs.CV

TL;DR: 本文提出了一种面向实际硬件约束的压缩单光子3D成像编码函数设计方法，通过联合优化照明与编码矩阵，在有限带宽和峰值功率约束下明显优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 单光子相机在3D成像中广受欢迎，但受限于带宽、激光功率、传感器速率和片上资源。尽管在线压缩直方图能缓解数据速率限制，但遇到真实的硬件约束时表现不佳，需要更有效的编码方案。

Method: 提出了一种基于约束优化的方法，利用梯度下降联合优化照明和编码矩阵，使其满足实际硬件约束（如带宽、峰值功率）。在仿真及真实非理想系统中进行了评估。

Result: 优化后的编码函数在有限带宽和峰值功率限制下，相较传统方案在仿真中表现更好。峰值功率限制下尤其突出，并且方法可适应任意参数化的系统响应。

Conclusion: 所提方法显著提升了压缩单光子3D成像系统在真实硬件约束下的表现，为实际应用提供了更优的解决方案。

Abstract: Single-photon cameras are becoming increasingly popular in time-of-flight 3D
imaging because they can time-tag individual photons with extreme resolution.
However, their performance is susceptible to hardware limitations, such as
system bandwidth, maximum laser power, sensor data rates, and in-sensor memory
and compute resources. Compressive histograms were recently introduced as a
solution to the challenge of data rates through an online in-sensor compression
of photon timestamp data. Although compressive histograms work within limited
in-sensor memory and computational resources, they underperform when subjected
to real-world illumination hardware constraints. To address this, we present a
constrained optimization approach for designing practical coding functions for
compressive single-photon 3D imaging. Using gradient descent, we jointly
optimize an illumination and coding matrix (i.e., the coding functions) that
adheres to hardware constraints. We show through extensive simulations that our
coding functions consistently outperform traditional coding designs under both
bandwidth and peak power constraints. This advantage is particularly pronounced
in systems constrained by peak power. Finally, we show that our approach adapts
to arbitrary parameterized impulse responses by evaluating it on a real-world
system with a non-ideal impulse response function.

</details>


### [19] [MetaCaptioner: Towards Generalist Visual Captioning with Open-source Suites](https://arxiv.org/abs/2510.12126)
*Zhenxin Lei,Zhangwei Gao,Changyao Tian,Erfei Cui,Guanzhou Chen,Danni Yang,Yuchen Duan,Zhaokai Wang,Wenhao Li,Weiyun Wang,Xiangyu Zhao,Jiayi Ji,Yu Qiao,Wenhai Wang,Gen Luo*

Main category: cs.CV

TL;DR: 提出了CapFlow多智能体协作流程，通过整合开源模型，实现媲美GPT-4.1的通用视觉描述能力，并以低成本合成高质量视觉描述数据，最终训练出强大的通用模型MetaCaptioner。


<details>
  <summary>Details</summary>
Motivation: 现有通用视觉描述任务中，开源模型与商用模型存在明显性能差距，影响了数据合成等下游应用。作者希望通过创新方法提高开源模型性能，缩小这一差距。

Method: 设计了CapFlow这一多智能体（multi-agent）协作流程，利用多个开源模型协同处理不同视觉信号，合成不同领域的高质量视觉描述数据，再以这些数据微调开源模型，获得新的强力通用视觉描述器MetaCaptioner。

Result: 实验表明，使用CapFlow合成数据后训练的MetaCaptioner在多领域均达到了与商业模型（如GPT-4.1）相当的视觉描述水平，并大幅降低成本（减少89.5%），同时在开源社区的多模态任务中取得领先性能。

Conclusion: CapFlow有效提升了开源视觉描述模型的性能，并通过MetaCaptioner为多模态研究和应用场景提供了高效、经济的视觉描述解决方案。

Abstract: Generalist visual captioning goes beyond a simple appearance description
task, but requires integrating a series of visual cues into a caption and
handling various visual domains. In this task, current open-source models
present a large performance gap with commercial ones, which limits various
applications such as data synthesis. To bridge the gap, this paper proposes
CapFlow, a novel multi-agent collaboration workflow. CapFlow demonstrates for
the first time that, by capitalizing on open-source models, it is possible to
achieve caption quality on par with GPT-4.1 in various domains with an 89.5%
reduction in costs. By leveraging CapFlow as the data synthesizer, we produce
high-quality visual captions from image and video domains at scale, and obtain
a generalist visual captioner via fine-tuning, namely MetaCaptioner. Through
extensive experiments, we show that MetaCaptioner not only achieves comparable
captioning capabilities with commercial models but also reaches top-tier
multimodal performance in the open-source community. We hope CapFlow and
MetaCaptioner can benefit future multimodal research by providing a strong and
cost-effective visual captioning solution.

</details>


### [20] [FedHUG: Federated Heterogeneous Unsupervised Generalization for Remote Physiological Measurements](https://arxiv.org/abs/2510.12132)
*Xiao Yang,Jiyao Wang*

Main category: cs.CV

TL;DR: 本文关注于远程生理信号测量中隐私保护与无标签数据的问题，提出了联邦无监督领域泛化（FUDG）协议及FedHUG框架，显著提升了模型的泛化和性能。


<details>
  <summary>Details</summary>
Motivation: 远程生理信号测量需要用户隐私数据，而现有无接触测量方法依然依赖有标签数据。实际部署时，用户数据常常缺乏标签，且存在分布异质和长尾问题，制约了模型的更新和泛化能力。

Method: 提出了FUDG协议以及FedHUG框架。FedHUG包括：1）最小偏差聚合模块，根据先验驱动的偏差评估动态调整聚合权重，应对多域异质非IID特征；2）全局分布感知学习控制器，参数化标签分布，动态调整客户端训练策略，缓解服务器-客户端的标签分布偏斜和长尾问题。

Result: FedHUG框架在RGB视频与毫米波雷达数据的远程生理信号估计任务上，相较SOTA（state of the art）方法取得了更优性能。

Conclusion: FedHUG通过在联邦学习中引入动态聚合与分布感知的无监督泛化策略，实现了更好的隐私保护、更强的模型泛化能力，为远程生理测量的实际部署提供了可行方案。

Abstract: Remote physiological measurement gained wide attention, while it requires
collecting users' privacy-sensitive information, and existing contactless
measurements still rely on labeled client data. This presents challenges when
we want to further update real-world deployed models with numerous user data
lacking labels. To resolve these challenges, we instantiate a new protocol
called Federated Unsupervised Domain Generalization (FUDG) in this work.
Subsequently, the \textbf{Fed}erated \textbf{H}eterogeneous
\textbf{U}nsupervised \textbf{G}eneralization (\textbf{FedHUG}) framework is
proposed and consists of: (1) Minimal Bias Aggregation module dynamically
adjusts aggregation weights based on prior-driven bias evaluation to cope with
heterogeneous non-IID features from multiple domains. (2) The Global
Distribution-aware Learning Controller parameterizes the label distribution and
dynamically manipulates client-specific training strategies, thereby mitigating
the server-client label distribution skew and long-tail issue. The proposal
shows superior performance across state-of-the-art techniques in estimation
with either RGB video or mmWave radar. The code will be released.

</details>


### [21] [Class-aware Domain Knowledge Fusion and Fission for Continual Test-Time Adaptation](https://arxiv.org/abs/2510.12150)
*Jiahuan Zhou,Chao Zhu,Zhenyu Cui,Zichen Liu,Xu Zou,Gang Hua*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的持续测试时自适应方法KFF，通过动态分离与融合类别感知的领域知识，有效应对领域间切换导致的遗忘和知识干扰问题，在ImageNet-C数据集上表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有CTTA方法为减少不规则下游领域切换带来的遗忘，常依赖恢复初始模型或复用历史模型，但会面临新知识学习不足及历史有害知识干扰，导致性能下降。因此需要新的方法更有效地积累有用知识并抑制负面影响。

Method: 作者提出类感知领域知识融合与分裂方法KFF。包括领域知识分裂（KFI）模块，针对新测试领域自适应分离新知识，降低旧领域负面影响；以及领域知识融合（KFU）模块，将新分裂出的知识低成本融合进现有知识池，并采用贪心动态融合策略，提升新旧知识兼容性与效率。

Result: 在ImageNet-C数据集上的大量实验表明，KFF方法相较其他CTTA方法表现更优，有效解决了遗忘及知识干扰问题。

Conclusion: KFF方法通过类别感知地动态扩展与融合领域知识，促使模型在多变领域顺利适应，缓解了历史知识负面干扰和新知识学习不足，为持续测试时自适应提供了高效可扩展的新思路。

Abstract: Continual Test-Time Adaptation (CTTA) aims to quickly fine-tune the model
during the test phase so that it can adapt to multiple unknown downstream
domain distributions without pre-acquiring downstream domain data. To this end,
existing advanced CTTA methods mainly reduce the catastrophic forgetting of
historical knowledge caused by irregular switching of downstream domain data by
restoring the initial model or reusing historical models. However, these
methods are usually accompanied by serious insufficient learning of new
knowledge and interference from potentially harmful historical knowledge,
resulting in severe performance degradation. To this end, we propose a
class-aware domain Knowledge Fusion and Fission method for continual test-time
adaptation, called KFF, which adaptively expands and merges class-aware domain
knowledge in old and new domains according to the test-time data from different
domains, where discriminative historical knowledge can be dynamically
accumulated. Specifically, considering the huge domain gap within streaming
data, a domain Knowledge FIssion (KFI) module is designed to adaptively
separate new domain knowledge from a paired class-aware domain prompt pool,
alleviating the impact of negative knowledge brought by old domains that are
distinct from the current domain. Besides, to avoid the cumulative computation
and storage overheads from continuously fissioning new knowledge, a domain
Knowledge FUsion (KFU) module is further designed to merge the fissioned new
knowledge into the existing knowledge pool with minimal cost, where a greedy
knowledge dynamic merging strategy is designed to improve the compatibility of
new and old knowledge while keeping the computational efficiency. Extensive
experiments on the ImageNet-C dataset verify the effectiveness of our proposed
method against other methods.

</details>


### [22] [DPL: Spatial-Conditioned Diffusion Prototype Enhancement for One-Shot Medical Segmentation](https://arxiv.org/abs/2510.12159)
*Ziyuan Gao,Philippe Morel*

Main category: cs.CV

TL;DR: 该论文提出Diffusion Prototype Learning (DPL)框架，通过扩散模型生成多样化的原型表示，提升了一次性医学图像分割的效果。


<details>
  <summary>Details</summary>
Motivation: 一次性医学图像分割方法通常受限于有限的标注数据和不同患者间解剖结构的差异性，传统确定性平均的原型难以有效泛化，表现欠佳。

Method: 引入扩散概率模型，将单一样本支持集原型扩展成多样性且语义相关的原型分布，包括扩散增强模块、空间感知条件机制和保守融合策略，训练和推理阶段均采用该原型增强流程。

Result: 在腹部MRI和CT数据集上大量实验，显著优于现有方法，达到新的最先进性能。

Conclusion: DPL通过生成多样性的原型，有效提升了小样本医学分割的泛化能力，拓宽了现有原型学习方法的应用界限。

Abstract: One-shot medical image segmentation faces fundamental challenges in prototype
representation due to limited annotated data and significant anatomical
variability across patients. Traditional prototype-based methods rely on
deterministic averaging of support features, creating brittle representations
that fail to capture intra-class diversity essential for robust generalization.
This work introduces Diffusion Prototype Learning (DPL), a novel framework that
reformulates prototype construction through diffusion-based feature space
exploration. DPL models one-shot prototypes as learnable probability
distributions, enabling controlled generation of diverse yet semantically
coherent prototype variants from minimal labeled data. The framework operates
through three core innovations: (1) a diffusion-based prototype enhancement
module that transforms single support prototypes into diverse variant sets via
forward-reverse diffusion processes, (2) a spatial-aware conditioning mechanism
that leverages geometric properties derived from prototype feature statistics,
and (3) a conservative fusion strategy that preserves prototype fidelity while
maximizing representational diversity. DPL ensures training-inference
consistency by using the same diffusion enhancement and fusion pipeline in both
phases. This process generates enhanced prototypes that serve as the final
representations for similarity calculations, while the diffusion process itself
acts as a regularizer. Extensive experiments on abdominal MRI and CT datasets
demonstrate significant improvements respectively, establishing new
state-of-the-art performance in one-shot medical image segmentation.

</details>


### [23] [State Space Prompting via Gathering and Spreading Spatio-Temporal Information for Video Understanding](https://arxiv.org/abs/2510.12160)
*Jiahuan Zhou,Kai Zhu,Zhenyu Cui,Zichen Liu,Xu Zou,Gang Hua*

Main category: cs.CV

TL;DR: 作者提出了一种新的视频理解方法SSP（State Space Prompting），能更有效地在视频数据中传播区分性时空信息，且参数开销低，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前预训练状态空间模型通过对视频视觉token进行线性复杂度的顺序压缩，实现了高效处理。但在泛化到下游任务时，提示学习的方法存在显著缺陷：压缩后的prompt token难以捕获视频的空间与时序上下文信息，导致关键特征传播受限，影响最终判别信息的提取。这个问题限制了模型的表现。

Method: 作者提出了SSP方法，核心包括两个模块：1）Intra-Frame Gathering（IFG）模块，用以聚合每一帧内的空间关键信息；2）Inter-Frame Spreading（IFS）模块，用以在不同帧之间传播辨别性时空信息。二者协作，实现帧内与帧间判别信息的融合，并自适应平衡压缩关键时空信息。

Result: 在4个主流视频数据集上的大量实验表明，SSP方法平均超越现有最新（SOTA）方法2.76%，并且显著减少了微调参数的开销。

Conclusion: SSP方法通过引入帧内和帧间提示机制，有效弥补了传统状态空间prompt方法在时空特征捕获与传播方面的缺陷，提升性能且降低微调开销，具有较强的实际应用潜力。

Abstract: Recently, pre-trained state space models have shown great potential for video
classification, which sequentially compresses visual tokens in videos with
linear complexity, thereby improving the processing efficiency of video data
while maintaining high performance. To apply powerful pre-trained models to
downstream tasks, prompt learning is proposed to achieve efficient downstream
task adaptation with only a small number of fine-tuned parameters. However, the
sequentially compressed visual prompt tokens fail to capture the spatial and
temporal contextual information in the video, thus limiting the effective
propagation of spatial information within a video frame and temporal
information between frames in the state compression model and the extraction of
discriminative information. To tackle the above issue, we proposed a State
Space Prompting (SSP) method for video understanding, which combines
intra-frame and inter-frame prompts to aggregate and propagate key
spatiotemporal information in the video. Specifically, an Intra-Frame Gathering
(IFG) module is designed to aggregate spatial key information within each
frame. Besides, an Inter-Frame Spreading (IFS) module is designed to spread
discriminative spatio-temporal information across different frames. By
adaptively balancing and compressing key spatio-temporal information within and
between frames, our SSP effectively propagates discriminative information in
videos in a complementary manner. Extensive experiments on four video benchmark
datasets verify that our SSP significantly outperforms existing SOTA methods by
2.76% on average while reducing the overhead of fine-tuning parameters.

</details>


### [24] [UniGS: Unified Geometry-Aware Gaussian Splatting for Multimodal Rendering](https://arxiv.org/abs/2510.12174)
*Yusen Xie,Zhenmin Huang,Jianhao Jiao,Dimitrios Kanoulas,Jun Ma*

Main category: cs.CV

TL;DR: 本文提出了UniGS，一种基于3D Gaussian Splatting的多模态高保真三维重建统一框架。其重点是高效、精确地同时重建RGB图像、深度、法线和语义信息，并通过创新的可微分渲染优化几何参数。


<details>
  <summary>Details</summary>
Motivation: 现有三维重建方法很难同时实现多模态输出的高精度和一致性，并且在渲染效率和几何属性优化方面存在局限。作者旨在解决这些实际需求。

Method: 提出了CUDA加速光栅化管线，能同步渲染RGB、深度、法线和语义；对深度渲染进行了可微分射线-椭球交优化，实现精确可微的旋转与尺度属性学习。同时，为法线渲染推导了解析梯度，保证几何一致性，引入可学习属性以支持训练中的可微分高斯裁剪。

Result: 实验在多种模态下均达到了最先进的重建精度，验证了方法在几何感知、多模态一致性等方面的有效性，无论定量还是定性结果均优于以往方法。

Conclusion: UniGS为多模态高保真三维重建提供了统一且高效的解决方案，通过可微渲染和管线优化显著提升了重建精度和效率，并有望推动相关领域的发展。

Abstract: In this paper, we propose UniGS, a unified map representation and
differentiable framework for high-fidelity multimodal 3D reconstruction based
on 3D Gaussian Splatting. Our framework integrates a CUDA-accelerated
rasterization pipeline capable of rendering photo-realistic RGB images,
geometrically accurate depth maps, consistent surface normals, and semantic
logits simultaneously. We redesign the rasterization to render depth via
differentiable ray-ellipsoid intersection rather than using Gaussian centers,
enabling effective optimization of rotation and scale attribute through
analytic depth gradients. Furthermore, we derive the analytic gradient
formulation for surface normal rendering, ensuring geometric consistency among
reconstructed 3D scenes. To improve computational and storage efficiency, we
introduce a learnable attribute that enables differentiable pruning of
Gaussians with minimal contribution during training. Quantitative and
qualitative experiments demonstrate state-of-the-art reconstruction accuracy
across all modalities, validating the efficacy of our geometry-aware paradigm.
Source code and multimodal viewer will be available on GitHub.

</details>


### [25] [CoIRL-AD: Collaborative-Competitive Imitation-Reinforcement Learning in Latent World Models for Autonomous Driving](https://arxiv.org/abs/2510.12560)
*Xiaoji Zheng,Ziyuan Yang,Yanhao Chen,Yuhang Peng,Yuanrong Tang,Gengyuan Liu,Bokui Chen,Jiangtao Gong*

Main category: cs.CV

TL;DR: 本文提出了CoIRL-AD，一种将模仿学习（IL）与强化学习（RL）在训练过程中动态结合的对抗双策略自动驾驶框架，显著提升了模型泛化能力和复杂场景下的表现。


<details>
  <summary>Details</summary>
Motivation: 当前端到端自动驾驶模型若仅采用模仿学习，容易出现泛化能力差的问题。而纯强化学习虽然可以通过奖励最大化促进探索，但存在样本效率低和收敛不稳定的问题。因此，作者希望结合IL和RL的优势，避免各自缺点，提升自动驾驶系统的整体性能。

Method: 提出CoIRL-AD竞争式双策略框架，在训练过程中让IL代理和RL代理相互竞争与协作。创新点在于激励知识交流的竞赛机制和防止梯度冲突的策略设计，不再采用传统的IL预训练+RL微调两阶段方法，而是实现训练期交互。

Result: 在nuScenes公开数据集上实验表明，CoIRL-AD在碰撞率上较多种基线方法下降了18%，且对“长尾”稀有场景的适应能力和整体泛化能力均有提升。

Conclusion: CoIRL-AD有效融合了IL与RL各自的优点，通过创新的对抗机制，有效提升了自动驾驶模型的安全性和泛化能力，在未来自动驾驶研究与实际部署中展现出较大潜力。

Abstract: End-to-end autonomous driving models trained solely with imitation learning
(IL) often suffer from poor generalization. In contrast, reinforcement learning
(RL) promotes exploration through reward maximization but faces challenges such
as sample inefficiency and unstable convergence. A natural solution is to
combine IL and RL. Moving beyond the conventional two-stage paradigm (IL
pretraining followed by RL fine-tuning), we propose CoIRL-AD, a competitive
dual-policy framework that enables IL and RL agents to interact during
training. CoIRL-AD introduces a competition-based mechanism that facilitates
knowledge exchange while preventing gradient conflicts. Experiments on the
nuScenes dataset show an 18% reduction in collision rate compared to baselines,
along with stronger generalization and improved performance on long-tail
scenarios. Code is available at: https://github.com/SEU-zxj/CoIRL-AD.

</details>


### [26] [BEEP3D: Box-Supervised End-to-End Pseudo-Mask Generation for 3D Instance Segmentation](https://arxiv.org/abs/2510.12182)
*Youngju Yoo,Seho Kim,Changick Kim*

Main category: cs.CV

TL;DR: 本论文提出了BEEP3D，一种端到端的框级弱监督3D实例分割方法，无需耗时的两阶段伪标签生成，采用学生-教师框架，能高效且准确地进行3D实例分割，在ScanNetV2和S3DIS等数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前全监督3D实例分割方法需要大量点级标注，导致标注成本高昂。框级标注是更经济的标注形式，但在实例重叠区域存在歧义，使得点与实例的对应关系难以确定，影响分割准确性。现有方法多采用两阶段生成伪掩码，提升准确性但增加系统复杂度和训练时间。为提升3D实例分割效率并降低监督强度，亟需端到端、高效且准确的框级弱监督方案。

Method: BEEP3D采用学生-教师框架，学生模型训练时带动教师模型通过指数滑动平均进行更新，教师作为伪标签生成器。在训练中引入基于实例中心的查询细化机制，提高查询的定位能力，并重点利用实例中心区域的特征。此外，设计了查询一致性损失和遮罩特征一致性损失，强化语义与几何的匹配，更好地生成高质量的伪掩码，提升点到实例的映射准确性。

Result: 在ScanNetV2和S3DIS两个主流3D实例分割数据集上的实验结果显示，BEEP3D相比最新的弱监督方法有竞争力甚至更优的分割性能，并且整体计算开销较低。

Conclusion: BEEP3D有效缓解了框级监督下的伪掩码不准和歧义问题，在弱监督3D实例分割领域实现了端到端、高效与高精度的统一，为降低3D场景理解任务的标注成本提供了可行途径。

Abstract: 3D instance segmentation is crucial for understanding complex 3D
environments, yet fully supervised methods require dense point-level
annotations, resulting in substantial annotation costs and labor overhead. To
mitigate this, box-level annotations have been explored as a weaker but more
scalable form of supervision. However, box annotations inherently introduce
ambiguity in overlapping regions, making accurate point-to-instance assignment
challenging. Recent methods address this ambiguity by generating pseudo-masks
through training a dedicated pseudo-labeler in an additional training stage.
However, such two-stage pipelines often increase overall training time and
complexity, hinder end-to-end optimization. To overcome these challenges, we
propose BEEP3D-Box-supervised End-to-End Pseudo-mask generation for 3D instance
segmentation. BEEP3D adopts a student-teacher framework, where the teacher
model serves as a pseudo-labeler and is updated by the student model via an
Exponential Moving Average. To better guide the teacher model to generate
precise pseudo-masks, we introduce an instance center-based query refinement
that enhances position query localization and leverages features near instance
centers. Additionally, we design two novel losses-query consistency loss and
masked feature consistency loss-to align semantic and geometric signals between
predictions and pseudo-masks. Extensive experiments on ScanNetV2 and S3DIS
datasets demonstrate that BEEP3D achieves competitive or superior performance
compared to state-of-the-art weakly supervised methods while remaining
computationally efficient.

</details>


### [27] [EReLiFM: Evidential Reliability-Aware Residual Flow Meta-Learning for Open-Set Domain Generalization under Noisy Labels](https://arxiv.org/abs/2510.12687)
*Kunyu Peng,Di Wen,Kailun Yang,Jia Fu,Yufan Chen,Ruiping Liu,Jiamin Wu,Junwei Zheng,M. Saquib Sarfraz,Luc Van Gool,Danda Pani Paudel,Rainer Stiefelhagen*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的方法EReLiFM，在有噪声标签的开放域泛化任务（OSDG-NL）中实现了最佳性能。该方法兼顾标签置信度及领域间残差转移，有效提升了对见类识别和未见类拒识能力。


<details>
  <summary>Details</summary>
Motivation: 开放域泛化任务要求模型能在新领域识别未见类别，现实中的标签噪声会破坏训练数据的有效性，影响泛化能力。当前方法在标签噪声严重、干净标签少的场景下，往往无法有效弥合领域差异。为此亟需更可靠、鲁棒的方法。

Method: 作者提出了EReLiFM方法，包括两个核心创新：（1）无监督的两阶段证据损失聚类，提升标签可靠性感知；（2）基于结构化领域-类别残差的流式匹配机制，实现多样化、考虑不确定性的知识转移。此外，利用最置信预测类别生成伪标签，在模型更新时促使对干净集的改进可最大化降低噪声集损失，整体以元学习策略优化。

Result: 实验表明，EReLiFM在多个开放域泛化且带有标签噪声的数据集上优于现有主流方法，取得了最新的最佳表现。

Conclusion: EReLiFM兼顾标签置信度和领域差异建模，显著提升了带噪声标签情况下的开放域泛化能力，在实际应用中具有较高潜力。

Abstract: Open-Set Domain Generalization (OSDG) aims to enable deep learning models to
recognize unseen categories in new domains, which is crucial for real-world
applications. Label noise hinders open-set domain generalization by corrupting
source-domain knowledge, making it harder to recognize known classes and reject
unseen ones. While existing methods address OSDG under Noisy Labels (OSDG-NL)
using hyperbolic prototype-guided meta-learning, they struggle to bridge domain
gaps, especially with limited clean labeled data. In this paper, we propose
Evidential Reliability-Aware Residual Flow Meta-Learning (EReLiFM). We first
introduce an unsupervised two-stage evidential loss clustering method to
promote label reliability awareness. Then, we propose a residual flow matching
mechanism that models structured domain- and category-conditioned residuals,
enabling diverse and uncertainty-aware transfer paths beyond
interpolation-based augmentation. During this meta-learning process, the model
is optimized such that the update direction on the clean set maximizes the loss
decrease on the noisy set, using pseudo labels derived from the most confident
predicted class for supervision. Experimental results show that EReLiFM
outperforms existing methods on OSDG-NL, achieving state-of-the-art
performance. The source code is available at
https://github.com/KPeng9510/ERELIFM.

</details>


### [28] [CompoDistill: Attention Distillation for Compositional Reasoning in Multimodal LLMs](https://arxiv.org/abs/2510.12184)
*Jiwan Kim,Kibum Kim,Sangwoo Seo,Chanyoung Park*

Main category: cs.CV

TL;DR: 本论文提出了一种新的知识蒸馏方法CompoDistill，能够更有效地将大型多模态语言模型的视觉感知能力迁移到小模型上，显著提升了小模型在视觉推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型虽然性能强大，但计算和存储需求高，不利于实际应用。知识蒸馏是小模型提取大模型能力的一种手段，但当前方法难以充分继承大模型的视觉感知能力，特别是在学生模型与教师模型视觉注意力不一致的问题下。本文旨在解决这一蒸馏瓶颈。

Method: 作者提出CompoDistill，一种新的知识蒸馏框架，核心在于显式地对齐学生模型与教师模型的视觉注意力，以提升学生模型的视觉感知表现。该框架通过系统性分析找到了视觉注意力错位作为性能瓶颈，并用新机制进行纠正。

Result: 实验表明，CompoDistill方法能在需要视觉感知能力的组合推理任务上显著提升学生模型的表现，同时在视觉问答等标准任务上维持与原有方法相当的性能。此外，使用更强大的backbone模型时，CompoDistill依然有效，显示了良好的泛化能力。

Conclusion: CompoDistill解决了多模态知识蒸馏时视觉注意力错位的问题，成功提升了学生模型的视觉能力，为高效多模态模型在实际场景中的应用提供了新思路。

Abstract: Recently, efficient Multimodal Large Language Models (MLLMs) have gained
significant attention as a solution to their high computational complexity,
making them more practical for real-world applications. In this regard, the
knowledge distillation (KD) approach has emerged as a promising alternative,
which transfers the rich visual and linguistic knowledge from a larger model
(teacher) to a smaller model (student). However, we observe that existing KD
methods struggle to effectively distill the teacher MLLM's rich visual
perception abilities to the student, a challenge that has been largely
overlooked in previous studies. Through a systematic analysis, we identify
visual attention misalignment between student and teacher as the main cause of
this issue. Based on this insight, we propose CompoDistill, a novel KD
framework that explicitly aligns the student's visual attention with that of
the teacher to enhance the student's visual perception abilities. Our extensive
experiments show that CompoDistill significantly improves performance on
compositional reasoning tasks that require visual perception abilities while
maintaining strong performance on visual question answering tasks, as done in
existing studies. Furthermore, CompoDistill demonstrates effectiveness with a
more advanced backbone, highlighting its generalizability.

</details>


### [29] [Hierarchical Reasoning with Vision-Language Models for Incident Reports from Dashcam Videos](https://arxiv.org/abs/2510.12190)
*Shingo Yokoi,Kento Sasaki,Yu Yamaguchi*

Main category: cs.CV

TL;DR: 本文提出了一种分层推理框架，基于视觉-语言模型（VLMs），用于自动驾驶行车记录仪视频的事故报告生成，并在2COOOL挑战赛中取得了优异成绩。


<details>
  <summary>Details</summary>
Motivation: 尽管大规模端到端自动驾驶模型取得了进展，但在分布外场景（OOD）中表现不佳。现有基准测试局限于封闭标签体系和有限的可解释性，亟需提升模型在未见危险情景下的理解能力，以及生成可解释事故报告的能力。

Method: 提出分层推理框架，整合帧级描述、事故帧检测和细粒度推理，依托视觉-语言模型。为提升事实准确性和可读性，还采用了模型集成和Blind A/B评分机制。

Result: 在2COOOL公开排行榜中，该方法在29支队伍中排名第二，并获得最高的CIDEr-D分数，证明了该方法生成的事故报告准确且具连贯性。

Conclusion: 基于VLMs的分层推理方法为交通事故分析和安全关键事件的理解提供了有前景的解决思路。

Abstract: Recent advances in end-to-end (E2E) autonomous driving have been enabled by
training on diverse large-scale driving datasets, yet autonomous driving models
still struggle in out-of-distribution (OOD) scenarios. The COOOL benchmark
targets this gap by encouraging hazard understanding beyond closed taxonomies,
and the 2COOOL challenge extends it to generating human-interpretable incident
reports. We present a hierarchical reasoning framework for incident report
generation from dashcam videos that integrates frame-level captioning, incident
frame detection, and fine-grained reasoning within vision-language models
(VLMs). We further improve factual accuracy and readability through model
ensembling and a Blind A/B Scoring selection protocol. On the official 2COOOL
open leaderboard, our method ranks 2nd among 29 teams and achieves the best
CIDEr-D score, producing accurate and coherent incident narratives. These
results indicate that hierarchical reasoning with VLMs is a promising direction
for accident analysis and for broader understanding of safety-critical traffic
events. The implementation and code are available at
https://github.com/riron1206/kaggle-2COOOL-2nd-Place-Solution.

</details>


### [30] [The Impact of Synthetic Data on Object Detection Model Performance: A Comparative Analysis with Real-World Data](https://arxiv.org/abs/2510.12208)
*Muammer Bay,Timo von Marcard,Dren Fazlija*

Main category: cs.CV

TL;DR: 本文探讨了在仓储物流领域，利用NVIDIA Omniverse Replicator生成的合成数据对目标检测模型性能的影响，发现合成数据与真实数据的结合可提升模型在实际场景中的效果。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在各行各业优化流程方面潜力巨大，但由于专业知识和资源的不足，很多AI应用不得不依赖通用模型，而这些模型往往需要昂贵的领域数据进行微调。合成数据作为一种低成本替代方案，成为优化模型训练的热门方向。

Method: 作者设计了以仓库托盘检测为例的实验，分别使用真实数据和由NVIDIA Omniverse Replicator生成的多种合成数据策略训练目标检测模型，并对比不同数据组合对模型的影响。

Result: 实验表明，将合成数据与真实数据合理结合，能在实际仓库场景下显著提升目标检测模型的鲁棒性和效率。

Conclusion: 合成图像数据在计算机视觉领域具有重要应用价值，适度平衡合成与真实数据，可获得高性能的目标检测模型。

Abstract: Recent advances in generative AI, particularly in computer vision (CV), offer
new opportunities to optimize workflows across industries, including logistics
and manufacturing. However, many AI applications are limited by a lack of
expertise and resources, which forces a reliance on general-purpose models.
Success with these models often requires domain-specific data for fine-tuning,
which can be costly and inefficient. Thus, using synthetic data for fine-tuning
is a popular, cost-effective alternative to gathering real-world data. This
work investigates the impact of synthetic data on the performance of object
detection models, compared to models trained on real-world data only,
specifically within the domain of warehouse logistics. To this end, we examined
the impact of synthetic data generated using the NVIDIA Omniverse Replicator
tool on the effectiveness of object detection models in real-world scenarios.
It comprises experiments focused on pallet detection in a warehouse setting,
utilizing both real and various synthetic dataset generation strategies. Our
findings provide valuable insights into the practical applications of synthetic
image data in computer vision, suggesting that a balanced integration of
synthetic and real data can lead to robust and efficient object detection
models.

</details>


### [31] [DIANet: A Phase-Aware Dual-Stream Network for Micro-Expression Recognition via Dynamic Images](https://arxiv.org/abs/2510.12219)
*Vu Tram Anh Khuong,Luu Tu Nguyen,Thi Bich Phuong Man,Thanh Ha Le,Thi Duyen Ngo*

Main category: cs.CV

TL;DR: 该论文提出了一种新的双流神经网络框架DIANet，通过分别建模微表情从起始到峰值和峰值到结束两个阶段的动态图像，并利用交互注意力模块融合两者特征，在多个基准数据集上实现了比传统单阶段方法更优的微表情识别效果。


<details>
  <summary>Details</summary>
Motivation: 传统动态图像方法仅用单一图像表示微表情整个过程，忽略了表情不同时期（如起始到峰值、峰值到结束）的不同特征，影响了识别准确性。作者希望通过区分阶段性动态信息，提升微表情识别效果。

Method: 作者设计了DIANet双流框架，分别针对起始到峰值、峰值到结束两个阶段生成动态图像，并用独立CNN分别提取特征；随后通过交互注意力模块根据上下文相关性融合双流特征，最后进行识别。

Result: 在CASME-II、SAMM和MMEW三个主流微表情数据集上，DIANet在各项评测指标上均优于传统单相动态图像方法，取得了更高的准确率和稳健性。

Conclusion: 显式建模微表情的时序阶段特征能显著提升识别性能，DIANet为微表情自动识别提供了有效的新思路，建议后续研究更加关注表情变化的时间结构建模。

Abstract: Micro-expressions are brief, involuntary facial movements that typically last
less than half a second and often reveal genuine emotions. Accurately
recognizing these subtle expressions is critical for applications in
psychology, security, and behavioral analysis. However, micro-expression
recognition (MER) remains a challenging task due to the subtle and transient
nature of facial cues and the limited availability of annotated data. While
dynamic image (DI) representations have been introduced to summarize temporal
motion into a single frame, conventional DI-based methods often overlook the
distinct characteristics of different temporal phases within a
micro-expression. To address this issue, this paper proposes a novel
dual-stream framework, DIANet, which leverages phase-aware dynamic images - one
encoding the onset-to-apex phase and the other capturing the apex-to-offset
phase. Each stream is processed by a dedicated convolutional neural network,
and a cross-attention fusion module is employed to adaptively integrate
features from both streams based on their contextual relevance. Extensive
experiments conducted on three benchmark MER datasets (CASME-II, SAMM, and
MMEW) demonstrate that the proposed method consistently outperforms
conventional single-phase DI-based approaches. The results highlight the
importance of modeling temporal phase information explicitly and suggest a
promising direction for advancing MER.

</details>


### [32] [HoneyBee: Data Recipes for Vision-Language Reasoners](https://arxiv.org/abs/2510.12225)
*Hritik Bansal,Devandra Singh Sachan,Kai-Wei Chang,Aditya Grover,Gargi Ghosh,Wen-tau Yih,Ramakanth Pasunuru*

Main category: cs.CV

TL;DR: 本文分析了视觉-语言模型（VLM）推理数据集的构建原则，并提出多种数据策划方法，发现数据集来源、干预方式及规模扩展能大幅提升模型性能。进一步，提出了新数据集HoneyBee，并证明其能显著提升VLM推理能力。


<details>
  <summary>Details</summary>
Motivation: 虽然近来VLM在推理任务上表现优异，但针对高性能VL推理数据集应如何构建，还缺乏明确理论和实践指导。因此，作者希望通过系统性实验，解答哪些数据策划方法最有效，并推动领域数据集的改进。

Method: 作者系统地设计实验，对比不同的数据上下文来源，实施特定的数据干预手段（如加入图像标题的辅助信号、纯文本推理样本），并尝试增加数据规模（如每图片/问题-图片对的独特问题与思维链数量），还设计了新大规模高质量推理数据集HoneyBee。提出了推理时的成本缩减新方案。

Result: 发现：1）数据上下文来源对子任务表现影响大；2）像图像标题等辅助信号、文本推理样本能有效提升模型表现；3）数据规模的扩展各个维度均可持续提升推理能力。HoneyBee数据集训练的VLM能大幅领先同类模型，尤其在MathVerse测试中，以3B参数模型超越最优模型达7.8%，普通基线达24.8%。解码成本缩减可达73%。

Conclusion: 高质量多样化的大型推理数据集、多维度扩展和合理辅助信号能显著提升VLM推理能力。HoneyBee数据集能够让不同规模的VLM达到新的性能高点。此研究为VLM推理数据集的建设策略提供了明确指导。

Abstract: Recent advances in vision-language models (VLMs) have made them highly
effective at reasoning tasks. However, the principles underlying the
construction of performant VL reasoning training datasets remain poorly
understood. In this work, we introduce several data curation approaches and
study their impacts on VL reasoning capabilities by carefully controlling
training and evaluation setups. We analyze the effects of context (image and
question pair) sources, implement targeted data interventions, and explore
scaling up images, questions, and chain-of-thought (CoT) solutions. Our
findings reveal that (a) context source strategies significantly affect VLM
performance, (b) interventions such as auxiliary signals from image captions
and the inclusion of text-only reasoning yield substantial gains, and (c)
scaling all data dimensions (e.g., unique questions per image and unique CoTs
per image-question pair) consistently improves reasoning capability. Motivated
by these insights, we introduce HoneyBee, a large-scale, high-quality CoT
reasoning dataset with 2.5M examples consisting 350K image-question pairs. VLMs
trained with HoneyBee outperform state-of-the-art models across model sizes.
For instance, a HoneyBee-trained VLM with 3B parameters outperforms the SOTA
model and the base model by 7.8% and 24.8%, respectively, on MathVerse.
Furthermore, we propose a test-time scaling strategy that reduces decoding cost
by 73% without sacrificing accuracy. Overall, this work presents improved
strategies for VL reasoning dataset curation research.

</details>


### [33] [BIGFix: Bidirectional Image Generation with Token Fixing](https://arxiv.org/abs/2510.12231)
*Victor Besnier,David Hurych,Andrei Bursuc,Eduardo Valle*

Main category: cs.CV

TL;DR: 本文提出了一种新的自纠错图像生成方法，通过迭代性修正采样token，提高多token并行预测生成效率和质量，在ImageNet-256、CIFAR-10、UCF-101和NuScenes等数据集上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型规模和推理步骤增多，提高推理效率成为学术界和工业界关注的核心问题。多token并行预测可大幅度提升效率，但带来token间结构不一致、依赖难捕捉和错误难修正等问题。

Method: 提出一种自纠错生成框架，在训练过程中随机插入噪声token，提升模型对错误上下文的鲁棒性；在采样阶段，通过迭代修正token，有效修复不兼容或错误的生成内容，从而兼顾并行生成的效率和生成质量。

Result: 该方法在ImageNet-256和CIFAR-10的图像生成，以及UCF-101和NuScenes的视频生成任务中均显著提升了生成质量，同时保留了多token并行预测带来的高效率。

Conclusion: 通过引入自纠错机制，成功平衡了并行token预测的效率与生成一致性问题，为高效高质量的生成模型带来新的解决思路。

Abstract: Recent advances in image and video generation have raised significant
interest from both academia and industry. A key challenge in this field is
improving inference efficiency, as model size and the number of inference steps
directly impact the commercial viability of generative models while also posing
fundamental scientific challenges. A promising direction involves combining
auto-regressive sequential token modeling with multi-token prediction per step,
reducing inference time by up to an order of magnitude. However, predicting
multiple tokens in parallel can introduce structural inconsistencies due to
token incompatibilities, as capturing complex joint dependencies during
training remains challenging. Traditionally, once tokens are sampled, there is
no mechanism to backtrack and refine erroneous predictions. We propose a method
for self-correcting image generation by iteratively refining sampled tokens. We
achieve this with a novel training scheme that injects random tokens in the
context, improving robustness and enabling token fixing during sampling. Our
method preserves the efficiency benefits of parallel token prediction while
significantly enhancing generation quality. We evaluate our approach on image
generation using the ImageNet-256 and CIFAR-10 datasets, as well as on video
generation with UCF-101 and NuScenes, demonstrating substantial improvements
across both modalities.

</details>


### [34] [Ivan-ISTD: Rethinking Cross-domain Heteroscedastic Noise Perturbations in Infrared Small Target Detection](https://arxiv.org/abs/2510.12241)
*Yuehui Li,Yahao Lu,Haoyuan Wu,Sen Zhang,Liang Lin,Yukai Shi*

Main category: cs.CV

TL;DR: 本文提出了一种名为Ivan-ISTD的双小波引导不变性学习框架，用于解决红外小目标检测中跨域变化与异方差噪声问题，实验效果优于主流方法。


<details>
  <summary>Details</summary>
Motivation: 在多媒体领域，红外小目标检测对无人机多模态感知至关重要，但在实际应用中常面临跨域分布变化和复杂的噪声干扰，现有方法难以兼顾这两个挑战。

Method: 方法分为两阶段：第一阶段采用小波引导的跨域合成技术，使训练样本与目标域对齐，通过多频小波滤波准确分离目标背景；第二阶段引入真实域噪声不变性学习，从目标域提取真实噪声，构建动态噪声库并通过自监督损失学习噪声不变性，从而克服传统人工噪声建模的分布偏差。

Result: 作者还构建了跨域动态退化数据集Dynamic-ISTD，实验表明Ivan-ISTD在多个定量指标上明显超过现有SOTA方法，特别是在跨域任务中表现出极佳的鲁棒性。

Conclusion: Ivan-ISTD在解决ISTD跨域和噪声不一致性方面取得了突破，具有良好的通用性和扩展性，为红外小目标检测在实际环境中的应用提供了强有力的支持。

Abstract: In the multimedia domain, Infrared Small Target Detection (ISTD) plays a
important role in drone-based multi-modality sensing. To address the dual
challenges of cross-domain shift and heteroscedastic noise perturbations in
ISTD, we propose a doubly wavelet-guided Invariance learning
framework(Ivan-ISTD). In the first stage, we generate training samples aligned
with the target domain using Wavelet-guided Cross-domain Synthesis. This
wavelet-guided alignment machine accurately separates the target background
through multi-frequency wavelet filtering. In the second stage, we introduce
Real-domain Noise Invariance Learning, which extracts real noise
characteristics from the target domain to build a dynamic noise library. The
model learns noise invariance through self-supervised loss, thereby overcoming
the limitations of distribution bias in traditional artificial noise modeling.
Finally, we create the Dynamic-ISTD Benchmark, a cross-domain dynamic
degradation dataset that simulates the distribution shifts encountered in
real-world applications. Additionally, we validate the versatility of our
method using other real-world datasets. Experimental results demonstrate that
our approach outperforms existing state-of-the-art methods in terms of many
quantitative metrics. In particular, Ivan-ISTD demonstrates excellent
robustness in cross-domain scenarios. The code for this work can be found at:
https://github.com/nanjin1/Ivan-ISTD.

</details>


### [35] [Vectorized Video Representation with Easy Editing via Hierarchical Spatio-Temporally Consistent Proxy Embedding](https://arxiv.org/abs/2510.12256)
*Ye Chen,Liming Tan,Yupeng Zhu,Yuanbin Wang,Bingbing Ni*

Main category: cs.CV

TL;DR: 论文提出用时空一致的代理节点来稳定地表示视频中的动态物体或场景，减少像素级追踪误差带来的问题，实现更精细的外观编辑及高效的视频处理。


<details>
  <summary>Details</summary>
Motivation: 当前视频表示方法通常依赖像素级的匹配和跟踪，这些方法对微小的追踪误差或大幅运动、遮挡极为敏感，容易导致表示崩溃，限制了模型的稳定性和应用性。

Method: 作者提出以分层的代理节点（proxy nodes）跨时空表示视频对象与场景结构，这些节点能稳定表达多尺度信息，同时动态更新节点特征，融合时空先验来缓解跟踪误差的影响。此外，分离的形状和纹理编码方式增强了对外观的可控和精细化编辑。

Result: 实验表明，所提方法能以更少参数获得更高的视频重建精度，并能有效支持如视频补全、基于关键帧的时序一致视频编辑等复杂任务。

Conclusion: 该方法克服了像素级跟踪方法的不稳定问题，实现了稳定、高效且可控的视频表示和编辑，为多种视频处理应用提供了强有力的技术支持。

Abstract: Current video representations heavily rely on unstable and over-grained
priors for motion and appearance modelling, \emph{i.e.}, pixel-level matching
and tracking. A tracking error of just a few pixels would lead to the collapse
of the visual object representation, not to mention occlusions and large motion
frequently occurring in videos. To overcome the above mentioned vulnerability,
this work proposes spatio-temporally consistent proxy nodes to represent
dynamically changing objects/scenes in the video. On the one hand, the
hierarchical proxy nodes have the ability to stably express the multi-scale
structure of visual objects, so they are not affected by accumulated tracking
error, long-term motion, occlusion, and viewpoint variation. On the other hand,
the dynamic representation update mechanism of the proxy nodes adequately
leverages spatio-temporal priors of the video to mitigate the impact of
inaccurate trackers, thereby effectively handling drastic changes in scenes and
objects. Additionally, the decoupled encoding manner of the shape and texture
representations across different visual objects in the video facilitates
controllable and fine-grained appearance editing capability. Extensive
experiments demonstrate that the proposed representation achieves high video
reconstruction accuracy with fewer parameters and supports complex video
processing tasks, including video in-painting and keyframe-based temporally
consistent video editing.

</details>


### [36] [Multiplicative Loss for Enhancing Semantic Segmentation in Medical and Cellular Images](https://arxiv.org/abs/2510.12258)
*Yuto Yokoi,Kazuhiro Hotta*

Main category: cs.CV

TL;DR: 论文提出了两种新的损失函数，用于在医学和细胞图像分割任务中提高模型表现，尤其适用于数据稀缺场景。


<details>
  <summary>Details</summary>
Motivation: 现有的损失函数如交叉熵和Dice Loss常以加法组合，但对超参数敏感，且在少数据情况下表现不佳。医学图像领域受限于隐私、伦理和高昂标注成本，数据稀缺问题尤为突出，迫切需要鲁棒且高效的训练方法。

Method: 提出了两种创新的损失函数：（1）乘性损失（Multiplicative Loss）将交叉熵和Dice Loss以乘法方式结合，并根据预测置信度动态调节梯度，稳定优化过程；（2）置信度自适应乘性损失（Confidence-Adaptive Multiplicative Loss），借鉴Focal Loss的置信度加权思想，对困难样本施加强梯度，进一步增强在极端少数据下的学习能力。

Result: 在细胞和医学分割基准数据集上，所提出的方法在性能上稳定优于经过精调的加性和现有损失函数。

Conclusion: 新提出的乘性损失及其置信度自适应变体无需超参数，方法简单有效，能显著提升数据稀缺情况下的分割性能。

Abstract: We propose two novel loss functions, Multiplicative Loss and
Confidence-Adaptive Multiplicative Loss, for semantic segmentation in medical
and cellular images. Although Cross Entropy and Dice Loss are widely used,
their additive combination is sensitive to hyperparameters and often performs
suboptimally, especially with limited data. Medical images suffer from data
scarcity due to privacy, ethics, and costly annotations, requiring robust and
efficient training objectives. Our Multiplicative Loss combines Cross Entropy
and Dice losses multiplicatively, dynamically modulating gradients based on
prediction confidence. This reduces penalties for confident correct predictions
and amplifies gradients for incorrect overconfident ones, stabilizing
optimization. Building on this, Confidence-Adaptive Multiplicative Loss applies
a confidence-driven exponential scaling inspired by Focal Loss, integrating
predicted probabilities and Dice coefficients to emphasize difficult samples.
This enhances learning under extreme data scarcity by strengthening gradients
when confidence is low. Experiments on cellular and medical segmentation
benchmarks show our framework consistently outperforms tuned additive and
existing loss functions, offering a simple, effective, and hyperparameter-free
mechanism for robust segmentation under challenging data limitations.

</details>


### [37] [Local Background Features Matter in Out-of-Distribution Detection](https://arxiv.org/abs/2510.12259)
*Jinlun Ye,Zhuohao Sun,Yiqiao Qiu,Qiu Li,Zhijun Tan,Ruixuan Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种新的利用局部背景特征增强深度神经网络在异常分布（OOD）检测能力的方法，通过模拟伪OOD特征，提升模型在实际场景中的鲁棒性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前深度神经网络在处理分布外样本时，容易给出过度自信的错误预测，影响系统在实际部署时的安全和可靠性。现有辅助数据集或生成式方法成本高昂，急需成本较低且有效的OOD检测方案。

Method: 作者提出从已知分布(ID)样本中提取背景特征，作为伪OOD视觉特征参与训练，借助卷积的局部不变性理论，通过优化网络减少背景特征的L2范数，有效缓解模型对OOD数据的过度自信预测问题。

Result: 在多个主流OOD检测基准数据集上，本方法展现了优于现有方法的检测性能，并且能与主流后处理方法高效结合，取得新的SOTA水平。

Conclusion: 论文验证了利用局部背景特征构造伪OOD增强模型训练，能够显著提升深度模型对异常分布数据的检测能力，兼具高效与易用性，有望广泛应用于现实场景模型部署。

Abstract: Out-of-distribution (OOD) detection is crucial when deploying deep neural
networks in the real world to ensure the reliability and safety of their
applications. One main challenge in OOD detection is that neural network models
often produce overconfident predictions on OOD data. While some methods using
auxiliary OOD datasets or generating fake OOD images have shown promising OOD
detection performance, they are limited by the high costs of data collection
and training. In this study, we propose a novel and effective OOD detection
method that utilizes local background features as fake OOD features for model
training. Inspired by the observation that OOD images generally share similar
background regions with ID images, the background features are extracted from
ID images as simulated OOD visual representations during training based on the
local invariance of convolution. Through being optimized to reduce the
$L_2$-norm of these background features, the neural networks are able to
alleviate the overconfidence issue on OOD data. Extensive experiments on
multiple standard OOD detection benchmarks confirm the effectiveness of our
method and its wide combinatorial compatibility with existing post-hoc methods,
with new state-of-the-art performance achieved from our method.

</details>


### [38] [AngularFuse: A Closer Look at Angle-based Perception for Spatial-Sensitive Multi-Modality Image Fusion](https://arxiv.org/abs/2510.12260)
*Xiaopeng Liu,Yupei Lin,Sen Zhang,Xiao Wang,Yukai Shi,Liang Lin*

Main category: cs.CV

TL;DR: 该论文提出了基于角度感知的空间敏感图像融合框架AngularFuse，通过多创新点提升可见光-红外图像融合效果，尤其在细节、亮度及边缘方向保持上有明显优势。


<details>
  <summary>Details</summary>
Motivation: 现有无监督深度学习融合方法依赖手工损失函数，参考图像通常缺乏细节且亮度分布不均，主流梯度损失只关注梯度幅值，导致融合效果受到制约。

Method: 1. 提出跨模态互补掩码模块，增强网络对不同模态互补信息的学习。2. 引入基于Laplacian边缘增强和自适应直方图均衡的精细参考图像合成策略，生成细节更丰富、亮度更均衡的参考图像。3. 创新性引入角度感知损失，在梯度域同时约束梯度幅值和方向，从而提升融合图像纹理和边缘方向的保持。

Result: 在MSRS、RoadScene及M3FD等公开数据集上，AngularFuse在定量指标和可视化效果上均明显优于主流方法，融合结果更清晰，细节更丰富。

Conclusion: AngularFuse能有效解决传统方法的细节、亮度与边缘方向不足的问题，展现了优异的可见光-红外图像融合能力，适用性强，具有良好应用前景。

Abstract: Visible-infrared image fusion is crucial in key applications such as
autonomous driving and nighttime surveillance. Its main goal is to integrate
multimodal information to produce enhanced images that are better suited for
downstream tasks. Although deep learning based fusion methods have made
significant progress, mainstream unsupervised approaches still face serious
challenges in practical applications. Existing methods mostly rely on manually
designed loss functions to guide the fusion process. However, these loss
functions have obvious limitations. On one hand, the reference images
constructed by existing methods often lack details and have uneven brightness.
On the other hand, the widely used gradient losses focus only on gradient
magnitude. To address these challenges, this paper proposes an angle-based
perception framework for spatial-sensitive image fusion (AngularFuse). At
first, we design a cross-modal complementary mask module to force the network
to learn complementary information between modalities. Then, a fine-grained
reference image synthesis strategy is introduced. By combining Laplacian edge
enhancement with adaptive histogram equalization, reference images with richer
details and more balanced brightness are generated. Last but not least, we
introduce an angle-aware loss, which for the first time constrains both
gradient magnitude and direction simultaneously in the gradient domain.
AngularFuse ensures that the fused images preserve both texture intensity and
correct edge orientation. Comprehensive experiments on the MSRS, RoadScene, and
M3FD public datasets show that AngularFuse outperforms existing mainstream
methods with clear margin. Visual comparisons further confirm that our method
produces sharper and more detailed results in challenging scenes, demonstrating
superior fusion capability.

</details>


### [39] [SpineBench: Benchmarking Multimodal LLMs for Spinal Pathology Analysis](https://arxiv.org/abs/2510.12267)
*Chenghanyu Zhang,Zekun Li,Peipei Li,Xing Cui,Shuhan Xia,Weixiang Yan,Yiqiao Zhang,Qianyu Zhuang*

Main category: cs.CV

TL;DR: 本文提出SpineBench，一个专为脊柱领域设计的视觉问答（VQA）基准，用于细致评估多模态大模型（MLLMs）在脊柱诊断与定位等专业任务的能力。结果显示当前主要MLLM在相关任务表现较差，凸显进一步改进的必要。


<details>
  <summary>Details</summary>
Motivation: 现有医学多模态大模型评测主要关注于通用医学任务，未能充分覆盖如脊柱等高度依赖视觉信息及细分专业知识的领域。脊柱医学任务专业性强，对模型能力提出更高要求，因此需要专门基准进行细致评估。

Method: 作者整合多个开源脊柱疾病数据集，标准化图片及标注，生成了包含64,878组问答对和40,263张脊柱图片的SpineBench基准，涵盖11种脊柱疾病，并结合了疾病诊断和病灶定位两大临床任务，采用多选题形式，且为每题设计视觉相似的干扰项（hard negative）以提升挑战性。作者用12个主流MLLM进行了性能测试。

Result: 12个主流MLLM在SpineBench上的表现整体较差，无法有效完成脊柱疾病诊断与定位任务，说明现有MLLM在该细分医学领域存在明显短板。

Conclusion: 现有多模态大模型虽在通用医学任务取得进展，但在脊柱等垂直领域仍存在很大提升空间。SpineBench为相关模型的改进和针对性发展提供了基准参考，有望推动脊柱医学AI研究进步。

Abstract: With the increasing integration of Multimodal Large Language Models (MLLMs)
into the medical field, comprehensive evaluation of their performance in
various medical domains becomes critical. However, existing benchmarks
primarily assess general medical tasks, inadequately capturing performance in
nuanced areas like the spine, which relies heavily on visual input. To address
this, we introduce SpineBench, a comprehensive Visual Question Answering (VQA)
benchmark designed for fine-grained analysis and evaluation of MLLMs in the
spinal domain. SpineBench comprises 64,878 QA pairs from 40,263 spine images,
covering 11 spinal diseases through two critical clinical tasks: spinal disease
diagnosis and spinal lesion localization, both in multiple-choice format.
SpineBench is built by integrating and standardizing image-label pairs from
open-source spinal disease datasets, and samples challenging hard negative
options for each VQA pair based on visual similarity (similar but not the same
disease), simulating real-world challenging scenarios. We evaluate 12 leading
MLLMs on SpineBench. The results reveal that these models exhibit poor
performance in spinal tasks, highlighting limitations of current MLLM in the
spine domain and guiding future improvements in spinal medicine applications.
SpineBench is publicly available at
https://zhangchenghanyu.github.io/SpineBench.github.io/.

</details>


### [40] [PAGS: Priority-Adaptive Gaussian Splatting for Dynamic Driving Scenes](https://arxiv.org/abs/2510.12282)
*Ying A,Wenzhang Sun,Chang Zeng,Chunfeng Wang,Hao Li,Jianxun Cui*

Main category: cs.CV

TL;DR: 本文提出了一种名为Priority-Adaptive Gaussian Splatting (PAGS)的新方法，通过引入语义优先级，有效提升了动态三维城市场景重建的效率和关键对象的细节表现，同时大幅减少了计算资源消耗和提升渲染速度。


<details>
  <summary>Details</summary>
Motivation: 当前三维重建方法在重建精度与计算成本之间存在明显取舍，且对静态背景与关键物体一视同仁，导致资源浪费，影响自动驾驶中的安全关键对象重建。

Method: PAGS方法包含两个核心创新：（1）语义引导的剪枝与正则策略，根据场景元素的重要性对非关键部分进行简化，保留关键物体的细节；（2）基于优先级的渲染流程，利用优先级深度预处理大幅剔除被遮挡的元素，加速最终渲染。

Result: 在Waymo与KITTI数据集上的实验表明，PAGS不仅在安全关键对象上具有出色的重建质量，还大幅减少了训练时间，渲染速度提升至350 FPS以上。

Conclusion: PAGS方法有效兼顾了重建质量和效率，尤其对自动驾驶等关注安全关键对象的场景极具应用前景。

Abstract: Reconstructing dynamic 3D urban scenes is crucial for autonomous driving, yet
current methods face a stark trade-off between fidelity and computational cost.
This inefficiency stems from their semantically agnostic design, which
allocates resources uniformly, treating static backgrounds and safety-critical
objects with equal importance. To address this, we introduce Priority-Adaptive
Gaussian Splatting (PAGS), a framework that injects task-aware semantic
priorities directly into the 3D reconstruction and rendering pipeline. PAGS
introduces two core contributions: (1) Semantically-Guided Pruning and
Regularization strategy, which employs a hybrid importance metric to
aggressively simplify non-critical scene elements while preserving fine-grained
details on objects vital for navigation. (2) Priority-Driven Rendering
pipeline, which employs a priority-based depth pre-pass to aggressively cull
occluded primitives and accelerate the final shading computations. Extensive
experiments on the Waymo and KITTI datasets demonstrate that PAGS achieves
exceptional reconstruction quality, particularly on safety-critical objects,
while significantly reducing training time and boosting rendering speeds to
over 350 FPS.

</details>


### [41] [Dual Learning with Dynamic Knowledge Distillation and Soft Alignment for Partially Relevant Video Retrieval](https://arxiv.org/abs/2510.12283)
*Jianfeng Dong,Lei Huang,Daizong Liu,Xianke Chen,Xun Yang,Changting Lin,Xun Wang,Meng Wang*

Main category: cs.CV

TL;DR: 本文针对实际中部分相关性视频检索任务提出了新方法，显著提升了在多个数据集上的检索表现。


<details>
  <summary>Details</summary>
Motivation: 以往的文本-视频检索多数假设视频经过剪辑且内容与查询紧密相关，忽略了实际中视频常常未剪辑、内容冗杂且仅部分相关。为解决现实中更加复杂的检索需求，提出了更具挑战的部分相关性视频检索（PRVR）任务。

Method: 提出Dual Learning with Dynamic Knowledge Distillation (DL-DKD++) 框架：通过大规模预训练视觉-语言模型作为教师网络，将泛化知识迁移到轻量、任务特定的学生网络。学生网络分为继承分支（吸收教师迁移知识）和探索分支（从PRVR数据集学习任务特定能力），并结合动态软标签机制实现细粒度部分相关判别。

Result: 在TVR, ActivityNet, Charades-STA 等PRVR主流数据集上取得了最新最优的检索效果。

Conclusion: 动态知识蒸馏与双分支学生网络设计，有效提升了复杂场景下的视频检索能力，为实际应用提供了更实用且高效的技术方案。

Abstract: Almost all previous text-to-video retrieval works ideally assume that videos
are pre-trimmed with short durations containing solely text-related content.
However, in practice, videos are typically untrimmed in long durations with
much more complicated background content. Therefore, in this paper, we focus on
the more practical yet challenging task of Partially Relevant Video Retrieval
(PRVR), which aims to retrieve partially relevant untrimmed videos with the
given query. To tackle this task, we propose a novel framework that distills
generalization knowledge from a powerful large-scale vision-language
pre-trained model and transfers it to a lightweight, task-specific PRVR
network. Specifically, we introduce a Dual Learning framework with Dynamic
Knowledge Distillation (DL-DKD++), where a large teacher model provides
supervision to a compact dual-branch student network. The student model
comprises two branches: an inheritance branch that absorbs transferable
knowledge from the teacher, and an exploration branch that learns task-specific
information from the PRVR dataset to address domain gaps. To further enhance
learning, we incorporate a dynamic soft-target construction mechanism. By
replacing rigid hard-target supervision with adaptive soft targets that evolve
during training, our method enables the model to better capture the
fine-grained, partial relevance between videos and queries. Experiment results
demonstrate that our proposed model achieves state-of-the-art performance on
TVR, ActivityNet, and Charades-STA datasets for PRVR. The code is available at
https://github.com/HuiGuanLab/DL-DKD.

</details>


### [42] [Vision Language Models Map Logos to Text via Semantic Entanglement in the Visual Projector](https://arxiv.org/abs/2510.12287)
*Sifan Li,Hongkai Chen,Yujun Cai,Qingwen Ye,Liyang Chen,Junsong Yuan,Yiwei Wang*

Main category: cs.CV

TL;DR: 本文关注于视觉语言模型（VLMs）在未含文字的logo识别中出现的幻觉现象，并对其成因、表现与缓解方式进行了系统分析。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型尽管在多模态推理上已取得进展，仍常常发生‘幻觉’（hallucination）现象，即模型产生与视觉证据不符、内容凭空生成的输出。过往研究对logo识别中产生品牌名或文本内容的‘logo幻觉’鲜有关注，尤其logo图像并无明显文字。本文提出系统性研究，探究此类幻觉问题。

Method: 作者设计了包含纯符号、混合、含文字logo等不同类型logo的数据集，以及‘Hard-60’高难子集。在这些数据集上，作者测试并量化了主流VLM的幻觉发生率。进一步，利用九种结构化扰动（如遮挡、噪声）分析模型鲁棒性，并通过嵌入空间（embedding-level）的维度消融实验证明，少量投影器维度引发了幻觉。作者还尝试有针对性地消融相关维度，以减低幻觉率，同时保持OCR性能。

Result: 即使在被严重扰动或遮挡的情况下，主流VLM仍然频繁产生logo幻觉，尤其是圆形标志和符号logo。嵌入空间分析发现，幻觉与投影器的少量特定维度相关。消融这些维度后，幻觉大幅减少，但OCR识别准确率基本未受损。

Conclusion: VLM在logo识别任务中，往往依靠符号先验而非真实文字感知，尤以圆形、标志性logo为甚。投影器子空间是幻觉的关键发生点，有针对性地调整该子空间和结合OCR引导，可有效提升多模态系统的可靠性。

Abstract: Vision Language Models (VLMs) have achieved impressive progress in multimodal
reasoning; yet, they remain vulnerable to hallucinations, where outputs are not
grounded in visual evidence. In this paper, we investigate a previously
overlooked setting: logo hallucination, where models generate brand names or
textual content despite logos containing no visible words. Using curated splits
of pure symbols, hybrids, and text-bearing logos, as well as the challenging
Hard-60 subset, we systematically measure hallucination across leading VLMs. We
further probe robustness through nine structured perturbations and show that
hallucinations persist even under strong distortions, with occlusion exposing
the sharpest weaknesses. Embedding-level analysis with open-weight LLaVA
demonstrates that hallucination is tied to a small subset of projector
dimensions, and targeted ablation substantially reduces errors while preserving
OCR accuracy. Together, these findings reveal that VLMs often rely on symbolic
priors rather than genuine glyph perception, particularly for iconic circular
logos, and that projector subspaces play a decisive role in this failure mode.
Our work contributes both a novel diagnostic lens and actionable mitigation
insights, highlighting projector disentanglement and OCR-guided decoding as
promising directions for building more trustworthy multimodal systems.

</details>


### [43] [Hybrid Gaussian Splatting for Novel Urban View Synthesis](https://arxiv.org/abs/2510.12308)
*Mohamed Omran,Farhad Zanjani,Davide Abati,Jens Petersen,Amirhossein Habibian*

Main category: cs.CV

TL;DR: 本文提出了Qualcomm AI Research在RealADSim-NVS挑战赛上的解决方案，通过结合高斯溅射与扩散模型，实现了街景新视角合成，在排行榜取得第二名成绩。


<details>
  <summary>Details</summary>
Motivation: 街景新视角合成任务具有挑战性，尤其是在不同路径（如不同车道或方向）下生成场景新视角，以支持自动驾驶仿真和增强现实等应用。提升生成效果和真实感是核心动机。

Method: 方法分两阶段：首先构建场景三维重建并渲染目标视角下的新视图，然后用专门开发的单步扩散模型对渲染帧进行增强。重点包括高斯元素初始化、增强模型微调及训练数据筛选。

Result: 模型在新视角品质（以PSNR、SSIM、LPIPS衡量）上进行了消融对比实验，并在公开排行榜的测试集上取得了0.432的聚合分数，排名第二。

Conclusion: 结合三维重建与生成模型的混合方法，在复杂街景新视角合成任务中表现突出，为相关应用提供了可靠的技术路线。

Abstract: This paper describes the Qualcomm AI Research solution to the RealADSim-NVS
challenge, hosted at the RealADSim Workshop at ICCV 2025. The challenge
concerns novel view synthesis in street scenes, and participants are required
to generate, starting from car-centric frames captured during some training
traversals, renders of the same urban environment as viewed from a different
traversal (e.g. different street lane or car direction). Our solution is
inspired by hybrid methods in scene generation and generative simulators
merging gaussian splatting and diffusion models, and it is composed of two
stages: First, we fit a 3D reconstruction of the scene and render novel views
as seen from the target cameras. Then, we enhance the resulting frames with a
dedicated single-step diffusion model. We discuss specific choices made in the
initialization of gaussian primitives as well as the finetuning of the enhancer
model and its training data curation. We report the performance of our model
design and we ablate its components in terms of novel view quality as measured
by PSNR, SSIM and LPIPS. On the public leaderboard reporting test results, our
proposal reaches an aggregated score of 0.432, achieving the second place
overall.

</details>


### [44] [CurriFlow: Curriculum-Guided Depth Fusion with Optical Flow-Based Temporal Alignment for 3D Semantic Scene Completion](https://arxiv.org/abs/2510.12362)
*Jinzhou Lin,Jie Zhou,Wenhao Xu,Rongtao Xu,Changwei Wang,Shunpeng Chen,Kexue Fu,Yihua Shao,Li Guo,Shibiao Xu*

Main category: cs.CV

TL;DR: 本文提出了一种名为CurriFlow的新型语义场景补全方法，通过集成光流时序对齐和课程学习引导的深度融合，实现基于摄像头的3D语义场景补全任务，显著提升了在动态物体和几何鲁棒性方面的表现，实验在SemanticKITTI数据集上取得了SOTA成绩。


<details>
  <summary>Details</summary>
Motivation: 现有SSC方法在处理动态场景、遮挡和噪声深度数据时效果有限，缺乏对运动信息的显式推理，急需提升基于摄像头感知的3D几何语义理解能力，支持自动驾驶场景下的高可靠感知。

Method: CurriFlow方法结合了光流驱动的时序特征对齐和多层特征融合（分割、视觉和深度特征），利用预训练光流模型提升动态物体的理解和时序一致性。同时，引入课程学习策略，训练时由稀疏但精准的LiDAR深度逐步过渡到稠密但带噪声的立体深度，实现鲁棒的深度融合。此外，结合SAM提供的语义先验加强体素级语义一致性。

Result: 在SemanticKITTI等公开数据集上的实验表明，CurriFlow在性能上达到了当前最优，mIoU为16.9，尤其在存在动态物体、遮挡和深度噪声的场景下表现突出。

Conclusion: CurriFlow通过有效的运动引导与课程策略，改善了基于摄像头的3D语义场景补全性能，为自动驾驶等实际应用提供了更稳健可靠的感知方案。

Abstract: Semantic Scene Completion (SSC) aims to infer complete 3D geometry and
semantics from monocular images, serving as a crucial capability for
camera-based perception in autonomous driving. However, existing SSC methods
relying on temporal stacking or depth projection often lack explicit motion
reasoning and struggle with occlusions and noisy depth supervision. We propose
CurriFlow, a novel semantic occupancy prediction framework that integrates
optical flow-based temporal alignment with curriculum-guided depth fusion.
CurriFlow employs a multi-level fusion strategy to align segmentation, visual,
and depth features across frames using pre-trained optical flow, thereby
improving temporal consistency and dynamic object understanding. To enhance
geometric robustness, a curriculum learning mechanism progressively transitions
from sparse yet accurate LiDAR depth to dense but noisy stereo depth during
training, ensuring stable optimization and seamless adaptation to real-world
deployment. Furthermore, semantic priors from the Segment Anything Model (SAM)
provide category-agnostic supervision, strengthening voxel-level semantic
learning and spatial consistency. Experiments on the SemanticKITTI benchmark
demonstrate that CurriFlow achieves state-of-the-art performance with a mean
IoU of 16.9, validating the effectiveness of our motion-guided and
curriculum-aware design for camera-based 3D semantic scene completion.

</details>


### [45] [Deep Attention-guided Adaptive Subsampling](https://arxiv.org/abs/2510.12376)
*Sharath M Shankaranarayana,Soumava Kumar Roy,Prasad Sudhakar,Chandan Aladahalli*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的可学习子采样框架，可以集成到任意神经网络架构中，通过动态调整输入采样来减少冗余，提高3D影像与视频任务中的效率，同时保证或提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 神经网络虽然性能提升显著，但带来了更高的计算复杂性与成本，尤其在3D或视频任务中存在大量数据冗余。当前主流的采样方法多为静态或仅对任务自适应，难以针对不同输入动态调整，限制了实际应用价值。

Method: 提出了一种注意力引导的子采样模块，使采样机制在推理阶段也能根据输入动态调整，区别于以往通过Gumbel-max等技术只对任务自适应的方法。该模块可插入任何神经网络架构，并端到端训练。

Result: 在MedMNIST3D 3D医学影像数据集与两个超声视频分类数据集（其中一个为真实临床环境的自建挑战性数据集）上，方法显著提升了效率并带来了分类性能的提升。

Conclusion: 注意力引导、输入自适应的可学习子采样模块有效减少了神经网络模型的计算复杂性，同时保持甚至提升了任务性能，显示了在实际复杂任务中的应用潜力。

Abstract: Although deep neural networks have provided impressive gains in performance,
these improvements often come at the cost of increased computational complexity
and expense. In many cases, such as 3D volume or video classification tasks,
not all slices or frames are necessary due to inherent redundancies. To address
this issue, we propose a novel learnable subsampling framework that can be
integrated into any neural network architecture. Subsampling, being a
nondifferentiable operation, poses significant challenges for direct adaptation
into deep learning models. While some works, have proposed solutions using the
Gumbel-max trick to overcome the problem of non-differentiability, they fall
short in a crucial aspect: they are only task-adaptive and not inputadaptive.
Once the sampling mechanism is learned, it remains static and does not adjust
to different inputs, making it unsuitable for real-world applications. To this
end, we propose an attention-guided sampling module that adapts to inputs even
during inference. This dynamic adaptation results in performance gains and
reduces complexity in deep neural network models. We demonstrate the
effectiveness of our method on 3D medical imaging datasets from MedMNIST3D as
well as two ultrasound video datasets for classification tasks, one of them
being a challenging in-house dataset collected under real-world clinical
conditions.

</details>


### [46] [Learning to Recognize Correctly Completed Procedure Steps in Egocentric Assembly Videos through Spatio-Temporal Modeling](https://arxiv.org/abs/2510.12385)
*Tim J. Schoonbeek,Shao-Hsuan Hung,Dan Lehman,Hans Onvlee,Jacek Kustra,Peter H. N. de With,Fons van der Sommen*

Main category: cs.CV

TL;DR: 本文提出了一种新方法STORM-PSR，通过结合空间和时间特征，提升了过程步骤识别任务中在部分遮挡情况下的准确性和鲁棒性。与以往只关注单帧目标状态的方法相比，模型能更快、更精准地识别步骤完成时间。


<details>
  <summary>Details</summary>
Motivation: 现有的过程步骤识别模型仅利用单帧图像分析对象状态，忽视了时间信息，因此在目标部分遮挡或连续动作识别时准确率低，鲁棒性差。作者希望设计一种兼顾空间和时间信息的方法，提升模型对遮挡情形下步骤识别的能力。

Method: 作者提出了双流架构STORM-PSR：一条为仅依赖空间信息的对象状态检测流，适用于无遮挡视角；另一条为时空流，融合了空间编码（用弱监督方式预训练）和基于transformer的时间编码器，能在遮挡时利用时空相关性推断步骤完成。

Result: 在MECCANO和IndustReal数据集上，STORM-PSR分别将预测步骤完成延迟降低了11.2%和26.1%。其中时空流的引入，是有效改善遮挡情况下识别及时性的关键。

Conclusion: STORM-PSR通过有效结合空间和时间特征，显著提升了过程步骤识别在遮挡情况下的表现。方法通用性和实用性均有所增强，相关代码和数据集标签已开源。

Abstract: Procedure step recognition (PSR) aims to identify all correctly completed
steps and their sequential order in videos of procedural tasks. The existing
state-of-the-art models rely solely on detecting assembly object states in
individual video frames. By neglecting temporal features, model robustness and
accuracy are limited, especially when objects are partially occluded. To
overcome these limitations, we propose Spatio-Temporal Occlusion-Resilient
Modeling for Procedure Step Recognition (STORM-PSR), a dual-stream framework
for PSR that leverages both spatial and temporal features. The assembly state
detection stream operates effectively with unobstructed views of the object,
while the spatio-temporal stream captures both spatial and temporal features to
recognize step completions even under partial occlusion. This stream includes a
spatial encoder, pre-trained using a novel weakly supervised approach to
capture meaningful spatial representations, and a transformer-based temporal
encoder that learns how these spatial features relate over time. STORM-PSR is
evaluated on the MECCANO and IndustReal datasets, reducing the average delay
between actual and predicted assembly step completions by 11.2% and 26.1%,
respectively, compared to prior methods. We demonstrate that this reduction in
delay is driven by the spatio-temporal stream, which does not rely on
unobstructed views of the object to infer completed steps. The code for
STORM-PSR, along with the newly annotated MECCANO labels, is made publicly
available at https://timschoonbeek.github.io/stormpsr .

</details>


### [47] [Scene Coordinate Reconstruction Priors](https://arxiv.org/abs/2510.12387)
*Wenjing Bian,Axel Barroso-Laguna,Tommaso Cavallari,Victor Adrian Prisacariu,Eric Brachmann*

Main category: cs.CV

TL;DR: 本文提出通过引入概率型高层重建先验，改进场景坐标回归（SCR）模型，提升3D视觉任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 传统SCR模型需要对单一场景进行训练，且对多视角约束不足时容易退化，因此需要更强的先验信息以提升模型泛化和稳健性。

Method: 作者将SCR训练过程重新解释为概率建模，引入多种先验：包括简单的深度分布先验和基于3D点云扩散模型学习到的复杂场景坐标先验（该扩散模型在大规模室内点云数据集上预训练），该先验在训练过程中持续推拉预测3D点到可能的合理几何结构。

Result: 在三个室内数据集上的实验显示，所引入的先验促进了更好的场景表示，输出的点云更连贯，配准率和相机位姿估计精度更高，进一步提升下游任务如新视角合成和相机重定位的表现。

Conclusion: 结合概率性重建先验能够有效改善SCR模型的鲁棒性与泛化能力，推动其在3D视觉多项任务中的应用前景。

Abstract: Scene coordinate regression (SCR) models have proven to be powerful implicit
scene representations for 3D vision, enabling visual relocalization and
structure-from-motion. SCR models are trained specifically for one scene. If
training images imply insufficient multi-view constraints SCR models
degenerate. We present a probabilistic reinterpretation of training SCR models,
which allows us to infuse high-level reconstruction priors. We investigate
multiple such priors, ranging from simple priors over the distribution of
reconstructed depth values to learned priors over plausible scene coordinate
configurations. For the latter, we train a 3D point cloud diffusion model on a
large corpus of indoor scans. Our priors push predicted 3D scene points towards
plausible geometry at each training step to increase their likelihood. On three
indoor datasets our priors help learning better scene representations,
resulting in more coherent scene point clouds, higher registration rates and
better camera poses, with a positive effect on down-stream tasks such as novel
view synthesis and camera relocalization.

</details>


### [48] [Towards General Urban Monitoring with Vision-Language Models: A Review, Evaluation, and a Research Agenda](https://arxiv.org/abs/2510.12400)
*André Torneiro,Diogo Monteiro,Paulo Novais,Pedro Rangel Henriques,Nuno F. Rodrigues*

Main category: cs.CV

TL;DR: 本文系统性回顾了视觉-语言模型（VLMs）在城市基础设施监测中的应用，聚焦于零样本推理能力，并分析了其架构、数据集和应用效果。


<details>
  <summary>Details</summary>
Motivation: 城市基础设施监测面临多样性和复杂性挑战，现有方法依赖传感器和人工巡查，成本高且不易扩展，同时与市民直观感受常常存在差距。亟需寻找能像市民一样“观察”城市并给出合理判断的新工具。

Method: 采用系统性文献综述（Systematic Review）和PRISMA方法，分析了2021至2025年间32篇关于VLM在城市监测中应用的同行评审论文，着重考察VLM在零样本任务中的表现、架构、常用数据集和评估方式。

Result: 系统梳理出VLM在多种城市监测任务中的应用场景、主流架构及其性能优势，总结了支撑该领域的主要数据集资源，并归纳出不同评估方式与已报道的模型性能水平。

Conclusion: VLM作为融合视觉理解和语言推理的新技术，为提升城市基础设施监测的自动化和智能化提供了有前景的解决思路，尤其在零样本推理方面展示出了强大的潜力，为后续智能城市研究和实际部署奠定了基础。

Abstract: Urban monitoring of public infrastructure (such as waste bins, road signs,
vegetation, sidewalks, and construction sites) poses significant challenges due
to the diversity of objects, environments, and contextual conditions involved.
Current state-of-the-art approaches typically rely on a combination of IoT
sensors and manual inspections, which are costly, difficult to scale, and often
misaligned with citizens' perception formed through direct visual observation.
This raises a critical question: Can machines now "see" like citizens and infer
informed opinions about the condition of urban infrastructure? Vision-Language
Models (VLMs), which integrate visual understanding with natural language
reasoning, have recently demonstrated impressive capabilities in processing
complex visual information, turning them into a promising technology to address
this challenge. This systematic review investigates the role of VLMs in urban
monitoring, with particular emphasis on zero-shot applications. Following the
PRISMA methodology, we analyzed 32 peer-reviewed studies published between 2021
and 2025 to address four core research questions: (1) What urban monitoring
tasks have been effectively addressed using VLMs? (2) Which VLM architectures
and frameworks are most commonly used and demonstrate superior performance? (3)
What datasets and resources support this emerging field? (4) How are VLM-based
applications evaluated, and what performance levels have been reported?

</details>


### [49] [Low-Field Magnetic Resonance Image Quality Enhancement using a Conditional Flow Matching Model](https://arxiv.org/abs/2510.12408)
*Huu Tien Nguyen,Ahmed Karam Eldaly*

Main category: cs.CV

TL;DR: 本文提出了一种基于条件流匹配（CFM）的图像质量转移新框架，并在低场磁共振成像（LF-MRI）上进行了验证。该方法能够高效重建高质量图像，具有参数量小且泛化能力强的优点。


<details>
  <summary>Details</summary>
Motivation: 低场磁共振成像设备便宜且便携，但信噪比较低，诊断质量不足。作者希望通过算法方式，将低场MRI提升到与高场MRI相近的图像质量，而无需昂贵的硬件设备。

Method: 作者提出条件流匹配（CFM）框架，通过回归噪声分布与目标数据分布之间的最优速度场，实现连续流映射。与传统生成模型依赖迭代采样或对抗目标不同，CFM直接进行端到端回归。

Result: CFM方法在低场MRI重建任务中，达到了当前最优的重建效果，并且对分布内和分布外数据都具有很好的泛化性能。同时，该方法所需参数明显少于已有深度学习模型。

Conclusion: CFM作为一种高效、可扩展图像重建工具，在临床资源有限环境下，具备巨大应用潜力，能有效提升MRI图像质量。

Abstract: This paper introduces a novel framework for image quality transfer based on
conditional flow matching (CFM). Unlike conventional generative models that
rely on iterative sampling or adversarial objectives, CFM learns a continuous
flow between a noise distribution and target data distributions through the
direct regression of an optimal velocity field. We evaluate this approach in
the context of low-field magnetic resonance imaging (LF-MRI), a rapidly
emerging modality that offers affordable and portable scanning but suffers from
inherently low signal-to-noise ratio and reduced diagnostic quality. Our
framework is designed to reconstruct high-field-like MR images from their
corresponding low-field inputs, thereby bridging the quality gap without
requiring expensive infrastructure. Experiments demonstrate that CFM not only
achieves state-of-the-art performance, but also generalizes robustly to both
in-distribution and out-of-distribution data. Importantly, it does so while
utilizing significantly fewer parameters than competing deep learning methods.
These results underline the potential of CFM as a powerful and scalable tool
for MRI reconstruction, particularly in resource-limited clinical environments.

</details>


### [50] [VideoLucy: Deep Memory Backtracking for Long Video Understanding](https://arxiv.org/abs/2510.12422)
*Jialong Zuo,Yongtai Deng,Lingdong Kong,Jingkang Yang,Rui Jin,Yiwei Zhang,Nong Sang,Liang Pan,Ziwei Liu,Changxin Gao*

Main category: cs.CV

TL;DR: 提出VideoLucy框架，以层次化记忆结构和迭代回溯机制改进LLM驱动的长视频理解，实现对时间线和细节的更好捕捉；新数据集EgoMem验证效果优于主流方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的视频理解系统主要基于单帧处理，难以捕捉连续帧间的时间语境，并通过稀疏采样降低成本，易丢失关键信息。因此需要新的方法解决时间维度理解和信息完整性的挑战。

Method: VideoLucy采用人类“由粗至细回忆”启发，设计层次化记忆结构，分不同粒度和时域保存信息，并通过agent驱动的迭代回溯检索机制，从全片提取和整合相关深层信息，直至足够回答问题。

Result: VideoLucy在多个长视频理解基准上显著优于现有最先进方法，包括封闭GP-4o等专有模型，同时提出的新数据集EgoMem更好考察复杂长时序视频的理解能力。

Conclusion: VideoLucy框架有效克服了单帧推理和稀疏采样的局限，实现了更精细和全面的长视频理解，为该领域提供了高效、可复现的新范式。

Abstract: Recent studies have shown that agent-based systems leveraging large language
models (LLMs) for key information retrieval and integration have emerged as a
promising approach for long video understanding. However, these systems face
two major challenges. First, they typically perform modeling and reasoning on
individual frames, struggling to capture the temporal context of consecutive
frames. Second, to reduce the cost of dense frame-level captioning, they adopt
sparse frame sampling, which risks discarding crucial information. To overcome
these limitations, we propose VideoLucy, a deep memory backtracking framework
for long video understanding. Inspired by the human recollection process from
coarse to fine, VideoLucy employs a hierarchical memory structure with
progressive granularity. This structure explicitly defines the detail level and
temporal scope of memory at different hierarchical depths. Through an
agent-based iterative backtracking mechanism, VideoLucy systematically mines
video-wide, question-relevant deep memories until sufficient information is
gathered to provide a confident answer. This design enables effective temporal
understanding of consecutive frames while preserving critical details. In
addition, we introduce EgoMem, a new benchmark for long video understanding.
EgoMem is designed to comprehensively evaluate a model's ability to understand
complex events that unfold over time and capture fine-grained details in
extremely long videos. Extensive experiments demonstrate the superiority of
VideoLucy. Built on open-source models, VideoLucy significantly outperforms
state-of-the-art methods on multiple long video understanding benchmarks,
achieving performance even surpassing the latest proprietary models such as
GPT-4o. Our code and dataset will be made publicly at
https://videolucy.github.io

</details>


### [51] [A Review of Longitudinal Radiology Report Generation: Dataset Composition, Methods, and Performance Evaluation](https://arxiv.org/abs/2510.12444)
*Shaoyang Zhou,Yingshu Li,Yunyi Liu,Lingqiao Liu,Lei Wang,Luping Zhou*

Main category: cs.CV

TL;DR: 本综述系统梳理了基于胸部X线影像的纵向放射学报告自动生成（LRRG）领域，涵盖数据集构建、架构设计、评价标准及现有方法的表现，并提出未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 单张X线影像生成报告的方法无法有效体现患者历史病程，但医生实际诊断流程高度依赖于多时点影像对比。目前缺乏系统性针对纵向报告生成的综述，限制了该领域的研究进展。

Method: 综述了与纵向胸部X线报告自动生成相关的数据集构建策略、模型架构、针对纵向任务的特殊设计及评价标准，总结各方法性能，并结合消融实验剖析不同设计选择对模型的影响。

Result: 研究发现，结合历史影像数据以及精心设计的模型架构能显著提升自动报告生成的质量，并从多项评测和消融实验中支持这一结论。该综述还归纳了当前五大主要研究局限。

Conclusion: 有效利用纵向信息对于自动生成符合临床需求的放射学报告至关重要。本文的系统综述为后续研究提供了方法和框架参考，并为促进该领域进一步发展提出了方向。

Abstract: Chest Xray imaging is a widely used diagnostic tool in modern medicine, and
its high utilization creates substantial workloads for radiologists. To
alleviate this burden, vision language models are increasingly applied to
automate Chest Xray radiology report generation (CXRRRG), aiming for clinically
accurate descriptions while reducing manual effort. Conventional approaches,
however, typically rely on single images, failing to capture the longitudinal
context necessary for producing clinically faithful comparison statements.
Recently, growing attention has been directed toward incorporating longitudinal
data into CXR RRG, enabling models to leverage historical studies in ways that
mirror radiologists diagnostic workflows. Nevertheless, existing surveys
primarily address single image CXRRRG and offer limited guidance for
longitudinal settings, leaving researchers without a systematic framework for
model design. To address this gap, this survey provides the first comprehensive
review of longitudinal radiology report generation (LRRG). Specifically, we
examine dataset construction strategies, report generation architectures
alongside longitudinally tailored designs, and evaluation protocols
encompassing both longitudinal specific measures and widely used benchmarks. We
further summarize LRRG methods performance, alongside analyses of different
ablation studies, which collectively highlight the critical role of
longitudinal information and architectural design choices in improving model
performance. Finally, we summarize five major limitations of current research
and outline promising directions for future development, aiming to lay a
foundation for advancing this emerging field.

</details>


### [52] [MS-GAGA: Metric-Selective Guided Adversarial Generation Attack](https://arxiv.org/abs/2510.12468)
*Dion J. X. Ho,Gabriel Lee Jun Rong,Niharika Shrivastava,Harshavardhan Abichandani,Pai Chet Ng,Xiaoxiao Miao*

Main category: cs.CV

TL;DR: 本文提出了MS-GAGA框架，用于在黑盒场景下对深度伪造检测器生成可迁移且不可察觉的对抗样本，显著提升攻击效果。


<details>
  <summary>Details</summary>
Motivation: 深度伪造检测器日渐完善，但现有对抗攻击方法在迁移性和视觉不可察觉性方面仍有不足。本文旨在提升对抗样本在未知模型间的迁移性，同时保持其对人眼难以察觉的特性。

Method: MS-GAGA采用两阶段方式：第一阶段由两路攻击模块生成候选对抗样本，一路MNTD-PGD优化梯度提升微小扰动下的效果，另一路SG-PGD专注于视觉显著区域扰动，二者互补扩展对抗空间；第二阶段利用度量感知模块，从攻击成功率和结构相似性（SSIM）双重指标筛选候选，兼顾迁移性与不可察觉性。

Result: 在对未知深度伪造检测模型的攻击中，MS-GAGA的误判率比现有最优攻击方法最高提升了27%。

Conclusion: MS-GAGA能够协同提升对抗样本的迁移性和视觉不可察觉性，为应对深度伪造检测系统的鲁棒性提出了更有效的攻击手段。

Abstract: We present MS-GAGA (Metric-Selective Guided Adversarial Generation Attack), a
two-stage framework for crafting transferable and visually imperceptible
adversarial examples against deepfake detectors in black-box settings. In Stage
1, a dual-stream attack module generates adversarial candidates: MNTD-PGD
applies enhanced gradient calculations optimized for small perturbation
budgets, while SG-PGD focuses perturbations on visually salient regions. This
complementary design expands the adversarial search space and improves
transferability across unseen models. In Stage 2, a metric-aware selection
module evaluates candidates based on both their success against black-box
models and their structural similarity (SSIM) to the original image. By jointly
optimizing transferability and imperceptibility, MS-GAGA achieves up to 27%
higher misclassification rates on unseen detectors compared to state-of-the-art
attacks.

</details>


### [53] [A Text-Image Fusion Method with Data Augmentation Capabilities for Referring Medical Image Segmentation](https://arxiv.org/abs/2510.12482)
*Shurong Chai,Rahul Kumar JAIN,Rui Xu,Shaocong Mo,Ruibo Hou,Shiyu Teng,Jiaqing Liu,Lanfen Lin,Yen-Wei Chen*

Main category: cs.CV

TL;DR: 论文提出了一种结合文本和视觉特征的早期融合框架，并通过轻量级生成器实现更准确的医学影像分割，成果超过现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有医学影像分割采用多模态（图像+文本）指导，但常规数据增强（如旋转、翻转）会打乱图像与文本间空间一致性，导致性能下降。

Method: 作者提出早期融合框架，在进行数据增强前，将文本与视觉特征融合，从而保持空间对齐。此外，设计了轻量级生成器将文本嵌入映射到视觉空间，弥合语义差距。

Result: 在3个医学影像任务和4个分割框架上实验，所提方法取得了当前最优效果。可视化结果显示该方法能准确定位分割区域。

Conclusion: 早期融合+轻量生成器能有效提升带文本引导的医学影像分割表现，对空间一致性敏感任务尤其有效。

Abstract: Deep learning relies heavily on data augmentation to mitigate limited data,
especially in medical imaging. Recent multimodal learning integrates text and
images for segmentation, known as referring or text-guided image segmentation.
However, common augmentations like rotation and flipping disrupt spatial
alignment between image and text, weakening performance. To address this, we
propose an early fusion framework that combines text and visual features before
augmentation, preserving spatial consistency. We also design a lightweight
generator that projects text embeddings into visual space, bridging semantic
gaps. Visualization of generated pseudo-images shows accurate region
localization. Our method is evaluated on three medical imaging tasks and four
segmentation frameworks, achieving state-of-the-art results. Code is publicly
available on GitHub: https://github.com/11yxk/MedSeg_EarlyFusion.

</details>


### [54] [BSGS: Bi-stage 3D Gaussian Splatting for Camera Motion Deblurring](https://arxiv.org/abs/2510.12493)
*An Zhao,Piaopiao Yu,Zhe Zhu,Mingqiang Wei*

Main category: cs.CV

TL;DR: 本文提出了一种名为Bi-Stage 3D Gaussian Splatting (BSGS)的新框架，专为从由相机运动产生的运动模糊图像中重建高质量3D场景设计，通过两阶段优化，有效提升了去模糊和重建效果。


<details>
  <summary>Details</summary>
Motivation: 运动模糊导致的图像会严重影响基于3D Gaussian Splatting(3DGS)的三维场景重建质量，现有方法在相机位姿精度依赖及模糊区的高斯体密度控制方面存在不足，导致最终场景重建效果受限，亟需新的方法提升鲁棒性和质量。

Method: 提出BSGS框架，分为两个阶段：第一阶段是相机姿态优化，用于减小运动带来的畸变；第二阶段在固定粗略姿态基础上，进行全局刚性变换以进一步校正运动模糊。同时，引入子帧梯度聚合策略缓解多子帧优化阶段的梯度冲突，并采用时空双阶段优化策略动态调整高斯体密度控制阈值，防止噪声高斯体早期生成。

Result: 经过大量实验验证，BSGS方法在去模糊和3D场景重建质量上均超越了当前主流方法，在各种运动模糊场景下表现出更优的鲁棒性和准确性。

Conclusion: BSGS作为新颖的两阶段3DGS去模糊框架，在运动模糊场景中有效提升了三维重建质量，并为后续相关研究提供了新的思路和方向。

Abstract: 3D Gaussian Splatting has exhibited remarkable capabilities in 3D scene
reconstruction.However, reconstructing high-quality 3D scenes from
motion-blurred images caused by camera motion poses a significant challenge.The
performance of existing 3DGS-based deblurring methods are limited due to their
inherent mechanisms, such as extreme dependence on the accuracy of camera poses
and inability to effectively control erroneous Gaussian primitives
densification caused by motion blur.To solve these problems, we introduce a
novel framework, Bi-Stage 3D Gaussian Splatting, to accurately reconstruct 3D
scenes from motion-blurred images.BSGS contains two stages. First, Camera Pose
Refinement roughly optimizes camera poses to reduce motion-induced distortions.
Second, with fixed rough camera poses, Global RigidTransformation further
corrects motion-induced blur distortions.To alleviate multi-subframe gradient
conflicts, we propose a subframe gradient aggregation strategy to optimize both
stages.Furthermore, a space-time bi-stage optimization strategy is introduced
to dynamically adjust primitive densification thresholds and prevent premature
noisy Gaussian generation in blurred regions. Comprehensive experiments verify
the effectiveness of our proposed deblurring method and show its superiority
over the state of the arts.

</details>


### [55] [Voronoi-Assisted Diffusion for Computing Unsigned Distance Fields from Unoriented Points](https://arxiv.org/abs/2510.12524)
*Jiayi Kong,Chen Zong,Junkai Deng,Xuhui Chen,Fei Hou,Shiqing Xin,Junhui Hou,Chen Qian,Ying He*

Main category: cs.CV

TL;DR: 本文提出了一种轻量化、无神经网络的方法Voronoi-Assisted Diffusion (VAD)，可直接从无方向点云计算Unsigned Distance Fields (UDFs)，兼具高效性与稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有基于神经网络的UDF学习方法在3D形状表达方面存在数值不稳定、计算成本高、可控性差等问题，且对于非流形、开放和非可定向表面处理不足。本文旨在提出一种更高效且更稳定的新方法，解决现有方法的不足。

Method: VAD方法首先通过Voronoi相关的几何准则，将双向法向量分配给输入点云，并用能量函数优化其对齐。对齐后的法向量再扩散形成近似UDF梯度场，最后通过积分恢复最终的UDF。整个流程无需神经网络，实现端到端的UDF计算。

Result: 实验表明，VAD方法能够高效、稳定地处理水密/开放表面、复杂的非流形及非可定向几何结构，显示出优越的鲁棒性和计算效率。

Conclusion: VAD方法是一种轻量、高效且稳定的UDF计算方案，能胜任多种复杂3D拓扑结构任务。其无需神经网络的特性使其更易用且更易拓展至实际应用。

Abstract: Unsigned Distance Fields (UDFs) provide a flexible representation for 3D
shapes with arbitrary topology, including open and closed surfaces, orientable
and non-orientable geometries, and non-manifold structures. While recent neural
approaches have shown promise in learning UDFs, they often suffer from
numerical instability, high computational cost, and limited controllability. We
present a lightweight, network-free method, Voronoi-Assisted Diffusion (VAD),
for computing UDFs directly from unoriented point clouds. Our approach begins
by assigning bi-directional normals to input points, guided by two
Voronoi-based geometric criteria encoded in an energy function for optimal
alignment. The aligned normals are then diffused to form an approximate UDF
gradient field, which is subsequently integrated to recover the final UDF.
Experiments demonstrate that VAD robustly handles watertight and open surfaces,
as well as complex non-manifold and non-orientable geometries, while remaining
computationally efficient and stable.

</details>


### [56] [Unconditional Human Motion and Shape Generation via Balanced Score-Based Diffusion](https://arxiv.org/abs/2510.12537)
*David Björkstrand,Tiesheng Wang,Lars Bretzner,Josephine Sullivan*

Main category: cs.CV

TL;DR: 本文提出了一种基于score-based diffusion模型的人体动作生成方法，通过巧妙的特征空间归一化和权重调整，无需辅助损失即可达到当前最优水平，同时直接生成动作和形状，简化流程。


<details>
  <summary>Details</summary>
Motivation: 当前GAN、VAE及扩散等生成模型在动作生成中常使用过多输入特征及辅助损失提升效果，增加了复杂性且理论上对扩散模型并非必需。作者希望通过理论推导减少依赖，简化体系。

Method: 采用score-based扩散生成模型，搭配精确的特征归一化，以及根据理论推导设定L2 score-matching损失的权重，并能够在一步中直接生成动作和形状，无需后处理形状恢复步骤。

Result: 所提出方法实现了与当前最优无条件人体动作生成方法相当甚至更好的效果。通过消融实验逐步验证每个创新点的效用。

Conclusion: 只需合理的归一化与损失权重，score-based扩散模型即可高效直接地生成高质量的人体运动和形状，省略复杂的特征工程和辅助损失，显著简化流程。

Abstract: Recent work has explored a range of model families for human motion
generation, including Variational Autoencoders (VAEs), Generative Adversarial
Networks (GANs), and diffusion-based models. Despite their differences, many
methods rely on over-parameterized input features and auxiliary losses to
improve empirical results. These strategies should not be strictly necessary
for diffusion models to match the human motion distribution. We show that on
par with state-of-the-art results in unconditional human motion generation are
achievable with a score-based diffusion model using only careful feature-space
normalization and analytically derived weightings for the standard L2
score-matching loss, while generating both motion and shape directly, thereby
avoiding slow post hoc shape recovery from joints. We build the method step by
step, with a clear theoretical motivation for each component, and provide
targeted ablations demonstrating the effectiveness of each proposed addition in
isolation.

</details>


### [57] [MMOT: The First Challenging Benchmark for Drone-based Multispectral Multi-Object Tracking](https://arxiv.org/abs/2510.12565)
*Tianhao Li,Tingfa Xu,Ying Wang,Haolin Qin,Xu Lin,Jianan Li*

Main category: cs.CV

TL;DR: 论文提出了首个无人机多光谱多目标跟踪数据集MMOT，并设计了新的跟踪方法，在提升小目标和密集场景下追踪表现方面取得显著进展。


<details>
  <summary>Details</summary>
Motivation: 现有无人机多目标跟踪主要依赖RGB图像，面临小目标、遮挡和背景杂乱等挑战，且缺乏多光谱专用数据集，限制了方法改进和评估。

Method: 1. 发布MMOT多光谱数据集，包含125个视频序列和近49万注释，覆盖丰富挑战和8类目标，并提供方向标签；2. 提出多光谱与方向感知的多目标跟踪方案，包括Spectral 3D-Stem（兼容RGB预训练）、方向感知Kalman滤波器，以及端到端方向自适应Transformer。

Result: 实验证明，基于多光谱输入相比RGB方法有显著提升，尤其对小目标和密集场景表现更佳，验证了新数据集及方法高效性。

Conclusion: 该研究填补了无人机多光谱多目标跟踪领域的数据集空白，提出了有效方法，推动相关研究进展。

Abstract: Drone-based multi-object tracking is essential yet highly challenging due to
small targets, severe occlusions, and cluttered backgrounds. Existing RGB-based
tracking algorithms heavily depend on spatial appearance cues such as color and
texture, which often degrade in aerial views, compromising reliability.
Multispectral imagery, capturing pixel-level spectral reflectance, provides
crucial cues that enhance object discriminability under degraded spatial
conditions. However, the lack of dedicated multispectral UAV datasets has
hindered progress in this domain. To bridge this gap, we introduce MMOT, the
first challenging benchmark for drone-based multispectral multi-object
tracking. It features three key characteristics: (i) Large Scale - 125 video
sequences with over 488.8K annotations across eight categories; (ii)
Comprehensive Challenges - covering diverse conditions such as extreme small
targets, high-density scenarios, severe occlusions, and complex motion; and
(iii) Precise Oriented Annotations - enabling accurate localization and reduced
ambiguity under aerial perspectives. To better extract spectral features and
leverage oriented annotations, we further present a multispectral and
orientation-aware MOT scheme adapting existing methods, featuring: (i) a
lightweight Spectral 3D-Stem integrating spectral features while preserving
compatibility with RGB pretraining; (ii) an orientation-aware Kalman filter for
precise state estimation; and (iii) an end-to-end orientation-adaptive
transformer. Extensive experiments across representative trackers consistently
show that multispectral input markedly improves tracking performance over RGB
baselines, particularly for small and densely packed objects. We believe our
work will advance drone-based multispectral multi-object tracking research. Our
MMOT, code, and benchmarks are publicly available at
https://github.com/Annzstbl/MMOT.

</details>


### [58] [Learning Human Motion with Temporally Conditional Mamba](https://arxiv.org/abs/2510.12573)
*Quang Nguyen,Tri Le,Baoru Huang,Minh Nhat Vu,Ngan Le,Thieu Vo,Anh Nguyen*

Main category: cs.CV

TL;DR: 本文提出了一种新的“Temporally Conditional Mamba”模型，用于更好地生成与条件输入时序信息一致的人体动作。该方法显著提升了动作的时序对齐、真实性和条件一致性。


<details>
  <summary>Details</summary>
Motivation: 基于时序信号生成或预测人体动作广泛应用于动画、虚拟现实等领域。然而，现有方法主要依赖交叉注意力机制来融合条件和动作，只能捕捉全局信息，难以保证动作与条件输入的逐步时间对齐。为了解决该问题，作者希望提出更精确时序对齐的动作生成方法。

Method: 作者提出了Temporally Conditional Mamba模型，将条件信息直接嵌入Mamba块中的循环动态机制，从而增强动作与条件输入的时间同步性。该方法可用于人体动作生成和相关任务。

Result: 通过在多个动作生成任务上的实验证明，所提出方法在动作的时序对齐、真实性以及与条件输入的一致性方面都优于现有主流方法。

Conclusion: Temporally Conditional Mamba模型有效提升了基于时序条件信息人体动作生成的表现，有助于未来相关应用和研究。

Abstract: Learning human motion based on a time-dependent input signal presents a
challenging yet impactful task with various applications. The goal of this task
is to generate or estimate human movement that consistently reflects the
temporal patterns of conditioning inputs. Existing methods typically rely on
cross-attention mechanisms to fuse the condition with motion. However, this
approach primarily captures global interactions and struggles to maintain
step-by-step temporal alignment. To address this limitation, we introduce
Temporally Conditional Mamba, a new mamba-based model for human motion
generation. Our approach integrates conditional information into the recurrent
dynamics of the Mamba block, enabling better temporally aligned motion. To
validate the effectiveness of our method, we evaluate it on a variety of human
motion tasks. Extensive experiments demonstrate that our model significantly
improves temporal alignment, motion realism, and condition consistency over
state-of-the-art approaches. Our project page is available at
https://zquang2202.github.io/TCM.

</details>


### [59] [Unlocking Zero-Shot Plant Segmentation with Pl@ntNet Intelligence](https://arxiv.org/abs/2510.12579)
*Simon Ravé,Jean-Christophe Lombardo,Pejman Rasti,Alexis Joly,David Rousseau*

Main category: cs.CV

TL;DR: 提出了一种无需标注数据的零样本农业图像分割方法，结合了Plantnet植物分类模型、DinoV2骨干网及分割任意物体模型（SAM），在多个公开数据集上表现优秀。


<details>
  <summary>Details</summary>
Motivation: 农业图像分割通常受限于数据标注困难与数据集小，尤其在复杂野外环境下，传统的完全监督方法难以获得较好效果，因此需要一种能够减少标注工作量的分割方法。

Method: 利用Plantnet植物分类模型及其DinoV2骨干，自动识别植物区域并生成粗分割掩码，然后通过SAM模型进一步细化分割，形成详细的分割结果；整个过程无需新的人工标注数据。

Result: 在四个具有不同复杂度和对比度的公开农业数据集上进行实验，结果显示使用通过Plantnet微调过的DinoV2模型，在Jaccard Index（IoU）指标上相比基础DinoV2模型有显著提升。

Conclusion: 结合基础大模型与专用植物识别模型，可以显著缓解农业图像分割的标注瓶颈，为多样化环境下的有效分割提供了有力工具。

Abstract: We present a zero-shot segmentation approach for agricultural imagery that
leverages Plantnet, a large-scale plant classification model, in conjunction
with its DinoV2 backbone and the Segment Anything Model (SAM). Rather than
collecting and annotating new datasets, our method exploits Plantnet's
specialized plant representations to identify plant regions and produce coarse
segmentation masks. These masks are then refined by SAM to yield detailed
segmentations. We evaluate on four publicly available datasets of various
complexity in terms of contrast including some where the limited size of the
training data and complex field conditions often hinder purely supervised
methods. Our results show consistent performance gains when using
Plantnet-fine-tuned DinoV2 over the base DinoV2 model, as measured by the
Jaccard Index (IoU). These findings highlight the potential of combining
foundation models with specialized plant-centric models to alleviate the
annotation bottleneck and enable effective segmentation in diverse agricultural
scenarios.

</details>


### [60] [LayerSync: Self-aligning Intermediate Layers](https://arxiv.org/abs/2510.12581)
*Yasaman Haghighi,Bastien van Delft,Mariam Hassan,Alexandre Alahi*

Main category: cs.CV

TL;DR: 本文提出了LayerSync方法，可以自我指导扩散模型各层之间的表征，对训练无额外开销，广泛适用于图像、音频、视频等领域，大幅提升训练速度和生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的生成质量与其中层表征紧密相关。已有工作表明通过引入外部指导可提升训练效率和生成质量，本文希望找到一种无需外部资源、可自给自足的内在指导方式来进一步优化扩散模型。

Method: 提出LayerSync方法，通过让扩散模型自身语义较强的层的表征对语义较弱的层进行指导实现正则化。这一新正则项可直接集成到训练流程中，无需预训练模型，无需额外数据，也不增加训练开销，具有很强的通用性和适应性。

Result: 在图像生成（如ImageNet）、音频、视频及动作生成等任务中，LayerSync显著提升了模型训练速度（如ImageNet下加速8.75倍）和生成质量（如提升23.6%）。

Conclusion: LayerSync是一种高效、灵活、无需外部依赖的扩散模型正则化方法，能显著提升扩散模型在多模态领域的训练效率与生成质量，具有广阔的应用前景。

Abstract: We propose LayerSync, a domain-agnostic approach for improving the generation
quality and the training efficiency of diffusion models. Prior studies have
highlighted the connection between the quality of generation and the
representations learned by diffusion models, showing that external guidance on
model intermediate representations accelerates training. We reconceptualize
this paradigm by regularizing diffusion models with their own intermediate
representations. Building on the observation that representation quality varies
across diffusion model layers, we show that the most semantically rich
representations can act as an intrinsic guidance for weaker ones, reducing the
need for external supervision. Our approach, LayerSync, is a self-sufficient,
plug-and-play regularizer term with no overhead on diffusion model training and
generalizes beyond the visual domain to other modalities. LayerSync requires no
pretrained models nor additional data. We extensively evaluate the method on
image generation and demonstrate its applicability to other domains such as
audio, video, and motion generation. We show that it consistently improves the
generation quality and the training efficiency. For example, we speed up the
training of flow-based transformer by over 8.75x on ImageNet dataset and
improved the generation quality by 23.6%. The code is available at
https://github.com/vita-epfl/LayerSync.

</details>


### [61] [Advancing End-to-End Pixel Space Generative Modeling via Self-supervised Pre-training](https://arxiv.org/abs/2510.12586)
*Jiachen Lei,Keli Liu,Julius Berner,Haiming Yu,Hongkai Zheng,Jiahong Wu,Xiangxiang Chu*

Main category: cs.CV

TL;DR: 该论文提出了一种创新的双阶段训练框架，使像素空间生成模型在性能和效率上追平甚至超越潜空间生成模型。


<details>
  <summary>Details</summary>
Motivation: 像素空间生成模型（例如Pixel-space Diffusion/Consistency Models）相较于被广泛采用的潜空间模型，在训练上更困难，且通常表现不佳，因此存在效率与性能差距。该论文旨在弥合这一差距。

Method: 提出了两阶段训练方法：第一阶段预训练编码器，对干净图像提取有意义的语义特征，并对齐从先验到数据分布的确定性采样轨迹中的点；第二阶段，将预训练的编码器与随机初始化解码器结合，对整个模型进行端到端微调，适用于扩散模型和一致性模型。

Result: 该方法在ImageNet数据集上表现突出。扩散模型在ImageNet-256和ImageNet-512上分别取得了2.04和2.35的FID分数，显著优于以往的像素空间方法，且可与主流的VAE基础模型媲美。在一致性模型上，ImageNet-256单步采样下FID达8.82，首次在不依赖预训练VAE或扩散模型下，实现高分辨率图像的一致性建模。

Conclusion: 该工作创新性地缩小甚至弥合了像素空间与潜空间生成模型的性能差距，表明通过合理的编码器训练及端到端微调，像素空间生成模型也可获得优异性能，为相关方向带来新思路。

Abstract: Pixel-space generative models are often more difficult to train and generally
underperform compared to their latent-space counterparts, leaving a persistent
performance and efficiency gap. In this paper, we introduce a novel two-stage
training framework that closes this gap for pixel-space diffusion and
consistency models. In the first stage, we pre-train encoders to capture
meaningful semantics from clean images while aligning them with points along
the same deterministic sampling trajectory, which evolves points from the prior
to the data distribution. In the second stage, we integrate the encoder with a
randomly initialized decoder and fine-tune the complete model end-to-end for
both diffusion and consistency models. Our training framework demonstrates
strong empirical performance on ImageNet dataset. Specifically, our diffusion
model reaches an FID of 2.04 on ImageNet-256 and 2.35 on ImageNet-512 with 75
number of function evaluations (NFE), surpassing prior pixel-space methods by a
large margin in both generation quality and efficiency while rivaling leading
VAE-based models at comparable training cost. Furthermore, on ImageNet-256, our
consistency model achieves an impressive FID of 8.82 in a single sampling step,
significantly surpassing its latent-space counterpart. To the best of our
knowledge, this marks the first successful training of a consistency model
directly on high-resolution images without relying on pre-trained VAEs or
diffusion models.

</details>


### [62] [Reasoning in the Dark: Interleaved Vision-Text Reasoning in Latent Space](https://arxiv.org/abs/2510.12603)
*Chao Chen,Zhixin Ma,Yongqi Li,Yupeng Hu,Yinwei Wei,Wenjie Li,Liqiang Nie*

Main category: cs.CV

TL;DR: 本论文提出了一种高效的多模态隐式推理方法（IVT-LR），能在减少标注和大幅提升速度的同时提升多模态理解准确度。


<details>
  <summary>Details</summary>
Motivation: 现有多模态推理主要依赖人工标注的显式推理步骤，成本高且推理速度慢，限制了多模态大语言模型（MLLMs）的实际应用。

Method: 提出了Interleaved Vision-Text Latent Reasoning（IVT-LR）方法，在推理过程中将视觉与文本信息交错、融合于隐空间，通过“隐文本”（上一步的隐藏状态）和“隐视觉”（选中的图片特征）作为隐式推理单元，并采用多阶段递进式训练策略训练模型。

Result: 在M3CoT和ScienceQA两个多模态推理数据集上，IVT-LR方法使平均准确率提升5.45%，推理速度提升5倍以上。

Conclusion: IVT-LR有效减少了多模态推理对人工标注的需求，极大提高了推理效率和准确率，为MLLMs的实际应用提供了更优解。

Abstract: Multimodal reasoning aims to enhance the capabilities of MLLMs by
incorporating intermediate reasoning steps before reaching the final answer. It
has evolved from text-only reasoning to the integration of visual information,
enabling the thought process to be conveyed through both images and text.
Despite its effectiveness, current multimodal reasoning methods depend on
explicit reasoning steps that require labor-intensive vision-text annotations
and inherently introduce significant inference latency. To address these
issues, we introduce multimodal latent reasoning with the advantages of
multimodal representation, reduced annotation, and inference efficiency. To
facilicate it, we propose Interleaved Vision-Text Latent Reasoning (IVT-LR),
which injects both visual and textual information in the reasoning process
within the latent space. Specifically, IVT-LR represents each reasoning step by
combining two implicit parts: latent text (the hidden states from the previous
step) and latent vision (a set of selected image embeddings). We further
introduce a progressive multi-stage training strategy to enable MLLMs to
perform the above multimodal latent reasoning steps. Experiments on M3CoT and
ScienceQA demonstrate that our IVT-LR method achieves an average performance
increase of 5.45% in accuracy, while simultaneously achieving a speed increase
of over 5 times compared to existing approaches. Code available at
https://github.com/FYYDCC/IVT-LR.

</details>


### [63] [WaterFlow: Explicit Physics-Prior Rectified Flow for Underwater Saliency Mask Generation](https://arxiv.org/abs/2510.12605)
*Runting Li,Shijie Lian,Hua Li,Yutong Li,Wenhui Wu,Sam Kwong*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的流机制USOD框架WaterFlow，将水下物理成像信息作为显性先验引入网络训练过程，并进行时间维建模，极大提升了水下显著性目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 当前水下显著性目标检测（USOD）面临图像退化与领域差异问题。以往方法未充分利用成像物理原理，而简单认为图像退化只是噪音，忽略了其中包含的有用信息。本文旨在突破现有方法局限，充分挖掘水下成像物理信息助力USOD。

Method: 提出WaterFlow框架，在网络训练阶段将水下物理成像信息作为显性先验输入，结合新颖的基于流的结构，并引入时序信息建模以增强物体识别能力。

Result: 在USOD10K数据集上，WaterFlow在S_m指标上提升0.072，显示出方法的有效性和优越性。

Conclusion: 将水下物理成像先验与时序建模结合，能显著提升USOD性能，WaterFlow为领域带来有效新思路，源码将在论文录用后公开。

Abstract: Underwater Salient Object Detection (USOD) faces significant challenges,
including underwater image quality degradation and domain gaps. Existing
methods tend to ignore the physical principles of underwater imaging or simply
treat degradation phenomena in underwater images as interference factors that
must be eliminated, failing to fully exploit the valuable information they
contain. We propose WaterFlow, a rectified flow-based framework for underwater
salient object detection that innovatively incorporates underwater physical
imaging information as explicit priors directly into the network training
process and introduces temporal dimension modeling, significantly enhancing the
model's capability for salient object identification. On the USOD10K dataset,
WaterFlow achieves a 0.072 gain in S_m, demonstrating the effectiveness and
superiority of our method. The code will be published after the acceptance.

</details>


### [64] [Zero-Shot CFC: Fast Real-World Image Denoising based on Cross-Frequency Consistency](https://arxiv.org/abs/2510.12646)
*Yanlin Jiang,Yuchen Liu,Mingren Liu*

Main category: cs.CV

TL;DR: 本论文提出了一种新的零样本图像去噪方法ZSCFC（基于跨频一致性的零样本去噪器），实现了对单幅噪声图像的高效去噪，无需对噪声分布进行假设，方法在多个真实世界图像数据集上效果和效率优于同类方法。


<details>
  <summary>Details</summary>
Motivation: 现有零样本去噪方法需要较长的训练时间，并且假设噪声是独立且均值为零，这在真实场景中不成立。因此需要一种更适用现实场景、高效的新方法。

Method: 方法基于图像在不同频率带之间的纹理一致性特征，提出跨频一致性损失，同时设计了一个超轻量网络，仅需单幅噪声图像，无需对噪声分布做假设，实现端到端去噪。

Result: 在多个真实世界图像数据集上的实验表明，ZSCFC在计算效率和去噪性能上均超越现有主流零样本去噪方法。

Conclusion: ZSCFC无需噪声假设，具备高效训练和优越去噪能力，为真实世界复杂噪声条件下的图像去噪提供了新思路。

Abstract: Zero-shot denoisers address the dataset dependency of deep-learning-based
denoisers, enabling the denoising of unseen single images. Nonetheless,
existing zero-shot methods suffer from long training times and rely on the
assumption of noise independence and a zero-mean property, limiting their
effectiveness in real-world denoising scenarios where noise characteristics are
more complicated. This paper proposes an efficient and effective method for
real-world denoising, the Zero-Shot denoiser based on Cross-Frequency
Consistency (ZSCFC), which enables training and denoising with a single noisy
image and does not rely on assumptions about noise distribution. Specifically,
image textures exhibit position similarity and content consistency across
different frequency bands, while noise does not. Based on this property, we
developed cross-frequency consistency loss and an ultralight network to realize
image denoising. Experiments on various real-world image datasets demonstrate
that our ZSCFC outperforms other state-of-the-art zero-shot methods in terms of
computational efficiency and denoising performance.

</details>


### [65] [On the Use of Hierarchical Vision Foundation Models for Low-Cost Human Mesh Recovery and Pose Estimation](https://arxiv.org/abs/2510.12660)
*Shuhei Tarashima,Yushan Wang,Norio Tagawa*

Main category: cs.CV

TL;DR: 本文旨在提出面向人体网格恢复（HMR）及人体姿态估计（HPE）的高效轻量级模型，通过使用分层视觉基础模型（例如Swin Transformer等）的早期阶段作为特征编码器，达到了与当前主流大模型相近的性能，同时在准确率和计算效率之间实现了更优的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有的人体网格恢复（HMR）和人体姿态估计（HPE）主流方法依赖于大型、非层次化的视觉Transformer编码器，计算资源消耗大。作者希望为不同计算预算提供高效且可扩展的轻量替代方案，并探讨分层视觉基础模型是否可实现更好性能效率平衡。

Method: 1. 构建三种轻量化的HMR2.0基线模型，通过改造对应的ViTPose体系。
2. 提出利用Swin Transformer、GroupMixFormer、VMamba等分层视觉基础模型（VFMs）的前两到三层作为编码器。
3. 对27种基于分层VFM的HMR及HPE模型进行全面评估，比较不同阶段模型的性能与计算效率。

Result: 实验结果表明，采用VFMs的前两到三层即可取得与使用全阶段模型相当的性能。同时，这些截断模型在准确率与计算效率的权衡上优于现有轻量级模型。

Conclusion: 采用分层视觉基础模型的部分早期阶段作为HMR与HPE模型编码器，不仅能保持较高的表现，还提高了模型效率，是实现更低算力预算下人体相关任务的有效途径。

Abstract: In this work, we aim to develop simple and efficient models for human mesh
recovery (HMR) and its predecessor task, human pose estimation (HPE).
State-of-the-art HMR methods, such as HMR2.0 and its successors, rely on large,
non-hierarchical vision transformers as encoders, which are inherited from the
corresponding HPE models like ViTPose. To establish baselines across varying
computational budgets, we first construct three lightweight HMR2.0 variants by
adapting the corresponding ViTPose models. In addition, we propose leveraging
the early stages of hierarchical vision foundation models (VFMs), including
Swin Transformer, GroupMixFormer, and VMamba, as encoders. This design is
motivated by the observation that intermediate stages of hierarchical VFMs
produce feature maps with resolutions comparable to or higher than those of
non-hierarchical counterparts. We conduct a comprehensive evaluation of 27
hierarchical-VFM-based HMR and HPE models, demonstrating that using only the
first two or three stages achieves performance on par with full-stage models.
Moreover, we show that the resulting truncated models exhibit better trade-offs
between accuracy and computational efficiency compared to existing lightweight
alternatives.

</details>


### [66] [TerraCodec: Compressing Earth Observations](https://arxiv.org/abs/2510.12670)
*Julen Costa-Watanabe,Isabelle Wittmann,Benedikt Blumenstiel,Konrad Schindler*

Main category: cs.CV

TL;DR: 论文提出了一种专为地球观测（EO）多光谱影像序列设计的高效学习型压缩系统TerraCodec（TEC），显著提升压缩效率，并支持灵活速率和后续自监督应用。


<details>
  <summary>Details</summary>
Motivation: 地球观测卫星产生的大量多光谱时序影像在存储和传输上面临巨大挑战。现有自然图像压缩方法无法充分利用时间冗余或不适合EO数据，缺乏对EO特殊性的学习型压缩方法和公开预训练模型。

Method: 引入了TerraCodec（TEC）家族，包括适应多光谱输入的高效图像编码器，以及利用时序关联的Transformer模型（TEC-TT）。提出Latent Repacking方法，支持变速率神经编码器，并在Sentinel-2数据集上训练。

Result: TerraCodec在相同图像质量下压缩比为传统编解码器3到10倍，并且TEC-TT还能实现零样本云填补（zero-shot cloud inpainting），在AllClear基准上优于最先进方法。

Conclusion: 论文验证了定制化、学习型地球观测影像压缩算法的前景，并承诺公开代码和模型权重以推动领域发展。

Abstract: Earth observation (EO) satellites produce massive streams of multispectral
image time series, posing pressing challenges for storage and transmission.
Yet, learned EO compression remains fragmented, lacking publicly available
pretrained models and misaligned with advances in compression for natural
imagery. Image codecs overlook temporal redundancy, while video codecs rely on
motion priors that fail to capture the radiometric evolution of largely static
scenes. We introduce TerraCodec (TEC), a family of learned codecs tailored to
EO. TEC includes efficient image-based variants adapted to multispectral
inputs, as well as a Temporal Transformer model (TEC-TT) that leverages
dependencies across time. To overcome the fixed-rate setting of today's neural
codecs, we present Latent Repacking, a novel method for training flexible-rate
transformer models that operate on varying rate-distortion settings. Trained on
Sentinel-2 data, TerraCodec outperforms classical codecs, achieving 3-10x
stronger compression at equivalent image quality. Beyond compression, TEC-TT
enables zero-shot cloud inpainting, surpassing state-of-the-art methods on the
AllClear benchmark. Our results establish bespoke, learned compression
algorithms as a promising direction for Earth observation. Code and model
weights will be released under a permissive license.

</details>


### [67] [SRUM: Fine-Grained Self-Rewarding for Unified Multimodal Models](https://arxiv.org/abs/2510.12784)
*Weiyang Jin,Yuwei Niu,Jiaqi Liao,Chengqi Duan,Aoxue Li,Shenghua Gao,Xihui Liu*

Main category: cs.CV

TL;DR: 本文提出了一种自我奖励机制（SRUM）提升统一多模态模型（UMM）视觉生成能力，通过自身理解模块反馈优化生成模块，无需额外人工标注。


<details>
  <summary>Details</summary>
Motivation: 当前UMM虽然视觉理解能力强，但在视觉生成时难以保持理解效果，存在理解与生成之间的能力转移鸿沟。

Method: 提出SRUM自我奖励后训练框架，利用模型自身的理解模块作为评估器，通过设计全局—局部奖励体系为生成模块提供纠正信号，实现综合和细粒度指导，无须人工标注。

Result: SRUM明显提升了多项UMM视觉生成相关基准的得分，如T2I-CompBench从82.18提升至88.37，T2I-ReasonBench从43.82提升至46.75，显示出更好的生成能力和泛化能力。

Conclusion: SRUM为UMM自我改进建立了新范式—理解模块可用于自监督优化生成模块，未来有望进一步推动多模态模型的自我完善和性能提升。

Abstract: Recently, remarkable progress has been made in Unified Multimodal Models
(UMMs), which integrate vision-language generation and understanding
capabilities within a single framework. However, a significant gap exists where
a model's strong visual understanding often fails to transfer to its visual
generation. A model might correctly understand an image based on user
instructions, yet be unable to generate a faithful image from text prompts.
This phenomenon directly raises a compelling question: Can a model achieve
self-improvement by using its understanding module to reward its generation
module? To bridge this gap and achieve self-improvement, we introduce SRUM, a
self-rewarding post-training framework that can be directly applied to existing
UMMs of various designs. SRUM creates a feedback loop where the model's own
understanding module acts as an internal ``evaluator'', providing corrective
signals to improve its generation module, without requiring additional
human-labeled data. To ensure this feedback is comprehensive, we designed a
global-local dual reward system. To tackle the inherent structural complexity
of images, this system offers multi-scale guidance: a \textbf{global reward}
ensures the correctness of the overall visual semantics and layout, while a
\textbf{local reward} refines fine-grained, object-level fidelity. SRUM leads
to powerful capabilities and shows strong generalization, boosting performance
on T2I-CompBench from 82.18 to \textbf{88.37} and on T2I-ReasonBench from 43.82
to \textbf{46.75}. Overall, our work establishes a powerful new paradigm for
enabling a UMMs' understanding module to guide and enhance its own generation
via self-rewarding.

</details>


### [68] [MCOP: Multi-UAV Collaborative Occupancy Prediction](https://arxiv.org/abs/2510.12679)
*Zefu Lin,Wenbo Chen,Xiaojuan Jin,Yuran Yang,Lue Fan,Yixin Zhang,Yufeng Zhang,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的多无人机协同占用预测框架，显著提升了三维空间结构与场景语义的信息提取效率，并在准确性和通信开销上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前基于鸟瞰（BEV）的方法存在无法全面捕捉场景语义与几何信息，以及在遇到未定义或遮挡物体时性能大幅下降的问题。因此，需要新的协同感知机制来提升多无人机系统在复杂场景下的感知能力。

Method: 文中提出了结合空间感知特征编码器与跨平台特征整合的多无人机协同占用预测框架。引入了高度感知特征压缩与双遮罩感知引导机制，有效减小了通信负载并自适应选择特征。此外，作者扩展并构建了三个数据集用于系统评估。

Result: 在两个虚拟和一个真实场景数据集上的实验证明，该方法在准确性上大幅领先当前协同感知方法，并且通信开销仅为其他方法的一小部分。

Conclusion: 该框架在场景三维结构与语义保留、适应复杂遮挡和未定义物体、降低多无人机之间通信负担方面均表现突出，为多无人机协同感知的实际应用奠定了基础。

Abstract: Unmanned Aerial Vehicle (UAV) swarm systems necessitate efficient
collaborative perception mechanisms for diverse operational scenarios. Current
Bird's Eye View (BEV)-based approaches exhibit two main limitations:
bounding-box representations fail to capture complete semantic and geometric
information of the scene, and their performance significantly degrades when
encountering undefined or occluded objects. To address these limitations, we
propose a novel multi-UAV collaborative occupancy prediction framework. Our
framework effectively preserves 3D spatial structures and semantics through
integrating a Spatial-Aware Feature Encoder and Cross-Agent Feature
Integration. To enhance efficiency, we further introduce Altitude-Aware Feature
Reduction to compactly represent scene information, along with a Dual-Mask
Perceptual Guidance mechanism to adaptively select features and reduce
communication overhead. Due to the absence of suitable benchmark datasets, we
extend three datasets for evaluation: two virtual datasets (Air-to-Pred-Occ and
UAV3D-Occ) and one real-world dataset (GauUScene-Occ). Experiments results
demonstrate that our method achieves state-of-the-art accuracy, significantly
outperforming existing collaborative methods while reducing communication
overhead to only a fraction of previous approaches.

</details>


### [69] [Hybrid Explanation-Guided Learning for Transformer-Based Chest X-Ray Diagnosis](https://arxiv.org/abs/2510.12704)
*Shelley Zixin Shu,Haozhe Luo,Alexander Poellinger,Mauricio Reyes*

Main category: cs.CV

TL;DR: 本文提出了一种结合自监督与人工引导的新颖框架H-EGL，用于提升Transformer医学影像模型的泛化能力及注意力对齐，实验证明该方法优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前Transformer模型虽在医学影像任务表现优秀，但易学到伪相关性，导致偏倚和泛化能力不足。人工-人工注意力对齐虽有效，但依赖高成本人工标注。研究希望减少人工参与同时提升泛化和解释性。

Method: 提出结合自监督和人工引导的混合解释约束框架H-EGL，其中自监督部分利用类别区别性注意力，无需依靠严格先验，提高鲁棒性和灵活性；在人类-模型关注对齐基础上引入自监督约束。

Result: 在胸部X光分类任务上，基于ViT的H-EGL在分类准确性和泛化能力方面均优于两种主流的EGL方法；输出的注意力图与专家更为一致。

Conclusion: H-EGL框架有效提升了医学影像Transformer模型的鲁棒性、泛化和解释性，为相关领域提供了低人工成本的新解决思路。

Abstract: Transformer-based deep learning models have demonstrated exceptional
performance in medical imaging by leveraging attention mechanisms for feature
representation and interpretability. However, these models are prone to
learning spurious correlations, leading to biases and limited generalization.
While human-AI attention alignment can mitigate these issues, it often depends
on costly manual supervision. In this work, we propose a Hybrid
Explanation-Guided Learning (H-EGL) framework that combines self-supervised and
human-guided constraints to enhance attention alignment and improve
generalization. The self-supervised component of H-EGL leverages
class-distinctive attention without relying on restrictive priors, promoting
robustness and flexibility. We validate our approach on chest X-ray
classification using the Vision Transformer (ViT), where H-EGL outperforms two
state-of-the-art Explanation-Guided Learning (EGL) methods, demonstrating
superior classification accuracy and generalization capability. Additionally,
it produces attention maps that are better aligned with human expertise.

</details>


### [70] [Beyond Seeing: Evaluating Multimodal LLMs on Tool-Enabled Image Perception, Transformation, and Reasoning](https://arxiv.org/abs/2510.12712)
*Xingang Guo,Utkarsh Tyagi,Advait Gosai,Paula Vergara,Ernesto Gabriel Hernández Montoya,Chen Bo Calvin Zhang,Bin Hu,Yunzhong He,Bing Liu,Rakshith Sharma Srinivasa*

Main category: cs.CV

TL;DR: 本论文提出了IRIS基准，以系统评估多模态大模型（MLLMs）在主动处理和推理图像（而非仅被动感知）能力上的表现。研究发现，当前模型在复杂视觉-文本任务中的整合和工具使用方面仍有很大不足。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大模型在现实应用中常需要主动编辑或变换用户图片，然而主流评测依旧只关注对静态图像的被动理解，尚未关注对图像的操控与多步推理能力。作者希望通过更符合实际应用需求的新范式（think with images）推动MLLMs发展。

Method: 作者提出了IRIS基准，包含1204道开放式视觉任务（单轮和多轮各约半数），覆盖五个不同领域。每题配有详细评分标准，用以评估MLLMs在主动感知、转换和跨模态推理的能力。

Result: 评估表明，当前多模态大模型在涉及视觉与通用工具有效整合的任务上表现不佳，最高性能模型GPT-5-think通过率仅18.68%。不同模型的图像工具使用模式也有差异，OpenAI模型通过多样化操作有所提升，Gemini-2.5-pro无明显改善。

Conclusion: IRIS作为首个注重“图像思维”范式的基准，为推动多模态大模型视觉智能的提升提供了新思路和重要参考。

Abstract: Multimodal Large Language Models (MLLMs) are increasingly applied in
real-world scenarios where user-provided images are often imperfect, requiring
active image manipulations such as cropping, editing, or enhancement to uncover
salient visual cues. Beyond static visual perception, MLLMs must also think
with images: dynamically transforming visual content and integrating it with
other tools to solve complex tasks. However, this shift from treating vision as
passive context to a manipulable cognitive workspace remains underexplored.
Most existing benchmarks still follow a think about images paradigm, where
images are regarded as static inputs. To address this gap, we introduce IRIS,
an Interactive Reasoning with Images and Systems that evaluates MLLMs' ability
to perceive, transform, and reason across complex visual-textual tasks under
the think with images paradigm. IRIS comprises 1,204 challenging, open-ended
vision tasks (603 single-turn, 601 multi-turn) spanning across five diverse
domains, each paired with detailed rubrics to enable systematic evaluation. Our
evaluation shows that current MLLMs struggle with tasks requiring effective
integration of vision and general-purpose tools. Even the strongest model
(GPT-5-think) reaches only 18.68% pass rate. We further observe divergent
tool-use behaviors, with OpenAI models benefiting from diverse image
manipulations while Gemini-2.5-pro shows no improvement. By introducing the
first benchmark centered on think with images, IRIS offers critical insights
for advancing visual intelligence in MLLMs.

</details>


### [71] [Personalized Federated Fine-Tuning of Vision Foundation Models for Healthcare](https://arxiv.org/abs/2510.12741)
*Adam Tupper,Christian Gagné*

Main category: cs.CV

TL;DR: 本文提出一种新颖的个性化联邦微调方法，通过正交LoRA适配器来区分通用知识与客户（如医院、诊所）特有知识，提升基础模型在医疗实际应用中的适应性。


<details>
  <summary>Details</summary>
Motivation: 基础模型虽然能促进AI在医疗行业的应用，但在数据隐私受限和数据难以聚合的背景下，如何高效利用分散的医疗数据进行模型微调成为难题。作者提出利用联邦学习实现分布式微调，以缓解隐私与数据规模矛盾。

Method: 该方法引入正交LoRA适配器，将模型的通用知识与每个客户的特定知识解耦，从而使每个参与者既能充分利用自身数据，也能受益于他方共享的知识，增强模型的个性化能力。方法在真实的联邦医疗影像任务中进行了初步验证。

Result: 初步实验结果显示，该方法在多个医学影像联邦学习场景下的性能可与当前主流联邦微调方法相媲美，表现出良好的竞争性。

Conclusion: 提出的方法在保护隐私和提升模型个性化性能方面取得了积极成果，为基础模型更好地服务实际医疗环境提供了有效途径。

Abstract: Foundation models open up new possibilities for the use of AI in healthcare.
However, even when pre-trained on health data, they still need to be fine-tuned
for specific downstream tasks. Furthermore, although foundation models reduce
the amount of training data required to achieve good performance, obtaining
sufficient data is still a challenge. This is due, in part, to restrictions on
sharing and aggregating data from different sources to protect patients'
privacy. One possible solution to this is to fine-tune foundation models via
federated learning across multiple participating clients (i.e., hospitals,
clinics, etc.). In this work, we propose a new personalized federated
fine-tuning method that learns orthogonal LoRA adapters to disentangle general
and client-specific knowledge, enabling each client to fully exploit both their
own data and the data of others. Our preliminary results on real-world
federated medical imaging tasks demonstrate that our approach is competitive
against current federated fine-tuning methods.

</details>


### [72] [FlashVSR: Towards Real-Time Diffusion-Based Streaming Video Super-Resolution](https://arxiv.org/abs/2510.12747)
*Junhao Zhuang,Shi Guo,Xin Cai,Xiaohui Li,Yihao Liu,Chun Yuan,Tianfan Xue*

Main category: cs.CV

TL;DR: 本论文提出了FlashVSR，这是首个面向实时视频超分辨率（VSR）的扩散模型一步流式框架，能够实现高效、可扩展和实时的视频超分辨率重建。其在性能、推理速度和超高分辨率通用性上大幅领先现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在视频恢复领域取得了进展，但其在实际超分辨率应用中面临高延迟、高计算消耗及超高分辨率下泛化能力差等问题，难以满足实际场景下的效率与实用性需求。

Method: 1）提出了包含训练友好的三阶段蒸馏流程，实现了流式超分辨；2）设计了局部约束的稀疏注意力机制，减少冗余计算，并弥合训练与测试分辨率的差距；3）引入了极小的条件解码器，大大加快重建速度而不牺牲画质。此外，构建了包含12万段视频和18万图片的大规模VSR-120K数据集以支持训练。

Result: FlashVSR在单块A100 GPU上可对768x1408分辨率视频实现约17 FPS处理，效率达现有一步扩散VSR方法的12倍；同时能高可靠地扩展到超高分辨率，并在效果上达到甚至超越当前主流方法。

Conclusion: FlashVSR极大提升了基于扩散模型的视频超分辨率实用性，实现了效率、可扩展性与画质的三重突破，并将为未来高效扩散VSR研究提供重要参考和资源。

Abstract: Diffusion models have recently advanced video restoration, but applying them
to real-world video super-resolution (VSR) remains challenging due to high
latency, prohibitive computation, and poor generalization to ultra-high
resolutions. Our goal in this work is to make diffusion-based VSR practical by
achieving efficiency, scalability, and real-time performance. To this end, we
propose FlashVSR, the first diffusion-based one-step streaming framework
towards real-time VSR. FlashVSR runs at approximately 17 FPS for 768x1408
videos on a single A100 GPU by combining three complementary innovations: (i) a
train-friendly three-stage distillation pipeline that enables streaming
super-resolution, (ii) locality-constrained sparse attention that cuts
redundant computation while bridging the train-test resolution gap, and (iii) a
tiny conditional decoder that accelerates reconstruction without sacrificing
quality. To support large-scale training, we also construct VSR-120K, a new
dataset with 120k videos and 180k images. Extensive experiments show that
FlashVSR scales reliably to ultra-high resolutions and achieves
state-of-the-art performance with up to 12x speedup over prior one-step
diffusion VSR models. We will release the code, pretrained models, and dataset
to foster future research in efficient diffusion-based VSR.

</details>


### [73] [SPORTS: Simultaneous Panoptic Odometry, Rendering, Tracking and Segmentation for Urban Scenes Understanding](https://arxiv.org/abs/2510.12749)
*Zhiliu Yang,Jinyu Dai,Jianyuan Zhang,Zhu Yang*

Main category: cs.CV

TL;DR: 本文提出了SPORTS框架，将视频全景分割、视觉里程计和场景渲染三大任务统一融合，有效提升了场景感知和理解能力，并在多个公开数据集上超过了主流方法。


<details>
  <summary>Details</summary>
Motivation: 现有的智能体场景理解方法在分割完整性、动态干扰、数据稀疏性和视角限制方面存在不足，亟需更全面更精准的感知与理解体系。

Method: SPORTS框架通过自适应注意力几何融合机制，结合姿态、深度和光流进行跨帧特征对齐，并通过后匹配策略提升目标跟踪。视觉里程计结合分割和光流提升动态目标信心估计和深度生成。然后将稀疏点云转化为神经场，实现场景高保真渲染。三大任务紧密迭代融合，提升整体性能。

Result: 在三个公开数据集上，SPORTS的注意力特征融合方法，在里程计、跟踪、分割及新视图合成任务中性能优于多数主流先进方法。

Conclusion: SPORTS实现了多任务协同下的全景场景感知和理解，显著提升了下游多项任务的表现，推动了智能体感知与场景建模技术的发展。

Abstract: The scene perception, understanding, and simulation are fundamental
techniques for embodied-AI agents, while existing solutions are still prone to
segmentation deficiency, dynamic objects' interference, sensor data sparsity,
and view-limitation problems. This paper proposes a novel framework, named
SPORTS, for holistic scene understanding via tightly integrating Video Panoptic
Segmentation (VPS), Visual Odometry (VO), and Scene Rendering (SR) tasks into
an iterative and unified perspective. Firstly, VPS designs an adaptive
attention-based geometric fusion mechanism to align cross-frame features via
enrolling the pose, depth, and optical flow modality, which automatically
adjust feature maps for different decoding stages. And a post-matching strategy
is integrated to improve identities tracking. In VO, panoptic segmentation
results from VPS are combined with the optical flow map to improve the
confidence estimation of dynamic objects, which enhances the accuracy of the
camera pose estimation and completeness of the depth map generation via the
learning-based paradigm. Furthermore, the point-based rendering of SR is
beneficial from VO, transforming sparse point clouds into neural fields to
synthesize high-fidelity RGB views and twin panoptic views. Extensive
experiments on three public datasets demonstrate that our attention-based
feature fusion outperforms most existing state-of-the-art methods on the
odometry, tracking, segmentation, and novel view synthesis tasks.

</details>


### [74] [VQArt-Bench: A semantically rich VQA Benchmark for Art and Cultural Heritage](https://arxiv.org/abs/2510.12750)
*A. Alfarano,L. Venturoli,D. Negueruela del Castillo*

Main category: cs.CV

TL;DR: 本文提出了VQArt-Bench，一套针对文化遗产领域、关注深层次语义理解的新型大规模视觉问答基准。通过多代理协作生成高质量、多样化的问题，测试现有主流多模态大模型在符号、叙事与复杂视觉关系等维度的理解能力，并揭示了当前模型在基础任务和模型类型上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉问答（VQA）基准只考查表层特征与简单结构，无法全面衡量多模态大模型在复杂领域（如美术分析）的深度语义理解能力。这导致模型趋于利用数据偏差而不是进行真正的视觉推理。

Method: 作者提出了VQArt-Bench基准：通过设计多代理协作流程，邀请专业代理共同生成经验证且多样化的问题，涵盖美术作品中符号、叙事与复杂视觉关系等多维度的理解。评价包括14种现有主流多模态大模型，涵盖专有和开源系统。

Result: 通过VQArt-Bench基准对14个先进多模态大模型的测试发现：当前模型在简单计数任务上表现出意外的弱点；专有模型在表现上普遍优于开源模型，整体还有明显提升空间。

Conclusion: 当前的多模态大模型在对复杂视觉语义的理解和推理方面仍有明显不足。VQArt-Bench基准能够更全面、系统地衡量和促进多模态模型在文化遗产及艺术等复杂场景中的能力提升。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated significant
capabilities in joint visual and linguistic tasks. However, existing Visual
Question Answering (VQA) benchmarks often fail to evaluate deep semantic
understanding, particularly in complex domains like visual art analysis.
Confined to simple syntactic structures and surface-level attributes, these
questions fail to capture the diversity and depth of human visual inquiry. This
limitation incentivizes models to exploit statistical shortcuts rather than
engage in visual reasoning. To address this gap, we introduce VQArt-Bench, a
new, large-scale VQA benchmark for the cultural heritage domain. This benchmark
is constructed using a novel multi-agent pipeline where specialized agents
collaborate to generate nuanced, validated, and linguistically diverse
questions. The resulting benchmark is structured along relevant visual
understanding dimensions that probe a model's ability to interpret symbolic
meaning, narratives, and complex visual relationships. Our evaluation of 14
state-of-the-art MLLMs on this benchmark reveals significant limitations in
current models, including a surprising weakness in simple counting tasks and a
clear performance gap between proprietary and open-source models.

</details>


### [75] [E-MoFlow: Learning Egomotion and Optical Flow from Event Data via Implicit Regularization](https://arxiv.org/abs/2510.12753)
*Wenpu Li,Bangyan Liao,Yi Zhou,Qi Xu,Pian Wan,Peidong Liu*

Main category: cs.CV

TL;DR: 本文提出了一种全新的无监督框架（E-MoFlow），通过隐式时空与几何正则化，统一事件相机下的6-DoF自运动与光流估计，取得了领先的无监督性能，部分结果甚至媲美有监督方法。


<details>
  <summary>Details</summary>
Motivation: 传统3D视觉中自运动和光流估计常被独立处理，但在事件相机等神经形态视觉下，由于缺乏稳健的数据关联，使得这两个问题独立求解变得困难且易受假设约束。现有解决方案各有限制，需新的统一框架提升精度与效率。

Method: 方法采用无监督策略，将相机自运动建模为连续样条，将光流表征为隐式神经表示，并通过微分几何约束注入先验，实现空间-时间一致性和几何一致性，规避对显式深度估计的依赖。

Result: 方法在通用6-DoF场景下表现优异，在无监督方法中达到最优表现，对比有监督方法也具有较强竞争力。

Conclusion: E-MoFlow框架相较于现有方法，能够无监督地统一估计自运动与光流，兼具高精度与高适应性，有望促进事件相机视觉领域的发展。

Abstract: The estimation of optical flow and 6-DoF ego-motion, two fundamental tasks in
3D vision, has typically been addressed independently. For neuromorphic vision
(e.g., event cameras), however, the lack of robust data association makes
solving the two problems separately an ill-posed challenge, especially in the
absence of supervision via ground truth. Existing works mitigate this
ill-posedness by either enforcing the smoothness of the flow field via an
explicit variational regularizer or leveraging explicit structure-and-motion
priors in the parametrization to improve event alignment. The former notably
introduces bias in results and computational overhead, while the latter, which
parametrizes the optical flow in terms of the scene depth and the camera
motion, often converges to suboptimal local minima. To address these issues, we
propose an unsupervised framework that jointly optimizes egomotion and optical
flow via implicit spatial-temporal and geometric regularization. First, by
modeling camera's egomotion as a continuous spline and optical flow as an
implicit neural representation, our method inherently embeds spatial-temporal
coherence through inductive biases. Second, we incorporate structure-and-motion
priors through differential geometric constraints, bypassing explicit depth
estimation while maintaining rigorous geometric consistency. As a result, our
framework (called E-MoFlow) unifies egomotion and optical flow estimation via
implicit regularization under a fully unsupervised paradigm. Experiments
demonstrate its versatility to general 6-DoF motion scenarios, achieving
state-of-the-art performance among unsupervised methods and competitive even
with supervised approaches.

</details>


### [76] [PET Head Motion Estimation Using Supervised Deep Learning with Attention](https://arxiv.org/abs/2510.12758)
*Zhuotong Cai,Tianyi Zeng,Jiazhen Zhang,Eléonore V. Lieffrig,Kathryn Fontaine,Chenyu You,Enette Mae Revilla,James S. Duncan,Jingmin Xin,Yihuan Lu,John A. Onofrey*

Main category: cs.CV

TL;DR: 该论文提出了一种基于深度学习与交叉注意力机制的脑部PET头动矫正方法（DL-HMC++），能从一秒钟的PET原始数据中预测刚性头动，实现无需外部硬件的自动矫正。结果显示，其性能优于当前主流方法，生成的图像与硬件跟踪的金标准几乎一致，显著减少头动伪影。


<details>
  <summary>Details</summary>
Motivation: 脑PET影像中由于头部移动会导致图像伪影和定量误差，影响疾病诊断。传统依赖硬件的运动追踪受限于临床应用，因此迫切需要高效、实用的无硬件数据驱动矫正方法。

Method: 提出DL-HMC++模型，融合深度学习和交叉注意力机制，利用配有外部运动跟踪仪的动态PET数据进行有监督训练，实现对1秒钟3D原始PET数据的刚性头动估计和矫正。

Result: 在两台PET扫描仪和四种放射性示踪剂上的大样本评测显示，DL-HMC++在定性和定量上均优于当前最优数据驱动方法，头动矫正后的图像与硬件运动追踪金标准高度一致，感兴趣区标准摄取值差异仅为1.2±0.5%（HRRT）和0.5±0.2%（mCT）。

Conclusion: DL-HMC++实现了准确、通用的数据驱动脑PET头动矫正，减少了对硬件设备的依赖，有望推广到日常临床应用，使运动矫正更易于普及。

Abstract: Head movement poses a significant challenge in brain positron emission
tomography (PET) imaging, resulting in image artifacts and tracer uptake
quantification inaccuracies. Effective head motion estimation and correction
are crucial for precise quantitative image analysis and accurate diagnosis of
neurological disorders. Hardware-based motion tracking (HMT) has limited
applicability in real-world clinical practice. To overcome this limitation, we
propose a deep-learning head motion correction approach with cross-attention
(DL-HMC++) to predict rigid head motion from one-second 3D PET raw data.
DL-HMC++ is trained in a supervised manner by leveraging existing dynamic PET
scans with gold-standard motion measurements from external HMT. We evaluate
DL-HMC++ on two PET scanners (HRRT and mCT) and four radiotracers (18F-FDG,
18F-FPEB, 11C-UCB-J, and 11C-LSN3172176) to demonstrate the effectiveness and
generalization of the approach in large cohort PET studies. Quantitative and
qualitative results demonstrate that DL-HMC++ consistently outperforms
state-of-the-art data-driven motion estimation methods, producing motion-free
images with clear delineation of brain structures and reduced motion artifacts
that are indistinguishable from gold-standard HMT. Brain region of interest
standard uptake value analysis exhibits average difference ratios between
DL-HMC++ and gold-standard HMT to be 1.2 plus-minus 0.5% for HRRT and 0.5
plus-minus 0.2% for mCT. DL-HMC++ demonstrates the potential for data-driven
PET head motion correction to remove the burden of HMT, making motion
correction accessible to clinical populations beyond research settings. The
code is available at https://github.com/maxxxxxxcai/DL-HMC-TMI.

</details>


### [77] [AnyUp: Universal Feature Upsampling](https://arxiv.org/abs/2510.12764)
*Thomas Wimmer,Prune Truong,Marie-Julie Rakotosaona,Michael Oechsle,Federico Tombari,Bernt Schiele,Jan Eric Lenssen*

Main category: cs.CV

TL;DR: AnyUp是一种通用特征上采样方法，适用于任意视觉特征和分辨率，无需对特定编码器进行训练，在特征泛化和任务适用性上表现出色。


<details>
  <summary>Details</summary>
Motivation: 目前特征上采样方法如DINO或CLIP都需要针对不同特征提取器单独训练，导致泛化性差、应用受限。因此，提出一种无需特定训练且能够适应不同特征类型的上采样方法。

Method: 提出AnyUp架构，可在推理时对任意特征进行特征无关的上采样。此方法不依赖于具体特征类型或分辨率，无需额外训练过程。

Result: 实验表明，AnyUp在上采样特征的质量上达到了新的最好水平，能够泛化到不同的特征类型，并在多种下游任务上高效且保持特征语义。

Conclusion: AnyUp有效克服了现有特征上采样方法的局限，能够高效、通用地提升特征上采样质量和任务适应范围，有广泛的应用前景。

Abstract: We introduce AnyUp, a method for feature upsampling that can be applied to
any vision feature at any resolution, without encoder-specific training.
Existing learning-based upsamplers for features like DINO or CLIP need to be
re-trained for every feature extractor and thus do not generalize to different
feature types at inference time. In this work, we propose an inference-time
feature-agnostic upsampling architecture to alleviate this limitation and
improve upsampling quality. In our experiments, AnyUp sets a new state of the
art for upsampled features, generalizes to different feature types, and
preserves feature semantics while being efficient and easy to apply to a wide
range of downstream tasks.

</details>


### [78] [Efficient Perceptual Image Super Resolution: AIM 2025 Study and Benchmark](https://arxiv.org/abs/2510.12765)
*Bruno Longarela,Marcos V. Conde,Alvaro Garcia,Radu Timofte*

Main category: cs.CV

TL;DR: 本文系统研究并基准测试了高效感知型超分辨率（EPSR）。提出的新方法在保证模型高效（参数少于5M，计算量少于2000 GFLOPs）基础上，实现了优于Real-ESRGAN的感知质量提升，并建立了新的基准。


<details>
  <summary>Details</summary>
Motivation: 在超分辨率领域，虽然面向PSNR的高效算法取得了进展，但针对感知质量（视觉效果）优化的方法仍效率较低。本文旨在缩小高效性与感知质量之间的差距。

Method: 作者针对感知超分辨模型，在严格的参数与算力限制下设计方法，并基于4K分辨率、包含多种退化类型且没有原图的全新基准数据集进行评测和对比。

Result: 提出的高效方法在所有基准数据集上均全面超越Real-ESRGAN，且满足高效性限制。

Conclusion: 证明了高效框架下在感知超分辨率领域仍能取得高质量结果，并为该方向提供了新基准，推动了高效感知超分领域发展。

Abstract: This paper presents a comprehensive study and benchmark on Efficient
Perceptual Super-Resolution (EPSR). While significant progress has been made in
efficient PSNR-oriented super resolution, approaches focusing on perceptual
quality metrics remain relatively inefficient. Motivated by this gap, we aim to
replicate or improve the perceptual results of Real-ESRGAN while meeting strict
efficiency constraints: a maximum of 5M parameters and 2000 GFLOPs, calculated
for an input size of 960x540 pixels. The proposed solutions were evaluated on a
novel dataset consisting of 500 test images of 4K resolution, each degraded
using multiple degradation types, without providing the original high-quality
counterparts. This design aims to reflect realistic deployment conditions and
serves as a diverse and challenging benchmark. The top-performing approach
manages to outperform Real-ESRGAN across all benchmark datasets, demonstrating
the potential of efficient methods in the perceptual domain. This paper
establishes the modern baselines for efficient perceptual super resolution.

</details>


### [79] [Uncertainty Matters in Dynamic Gaussian Splatting for Monocular 4D Reconstruction](https://arxiv.org/abs/2510.12768)
*Fengzhi Guo,Chih-Chuan Hsu,Sihao Ding,Cheng Zhang*

Main category: cs.CV

TL;DR: 本论文提出USplat4D，一种能感知不确定性的动态高斯喷溅框架，通过对每个高斯原语的不确定性建模并优化，提升单目动态3D场景重建的精度和稳定性，尤其在遮挡和极端视角下表现更好。


<details>
  <summary>Details</summary>
Motivation: 现有动态高斯喷溅方法在所有高斯原语上均匀优化，忽略了其被观测的可靠性，导致在遮挡和新视角下运动漂移及合成效果下降。因此，需要方法感知并利用各原语在时空中的不确定性来指导优化。

Method: 核心方法是为每个高斯原语估计随时间变化的不确定性，并利用该不确定性构建时空图，在优化过程中引入不确定性感知机制，将可靠的运动信息传播至整体4D重建。

Result: 实验在多组真实和合成数据上进行，结果显示显式地建模并利用不确定性，能稳定提升动态高斯喷溅模型的几何稳定性和在极端视角下的渲染质量。

Conclusion: 引入不确定性感知机制能有效提升单目动态3D重建在存在遮挡和新视角挑战下的表现，为动态场景建模提供了更稳健和高质量的解决方案。

Abstract: Reconstructing dynamic 3D scenes from monocular input is fundamentally
under-constrained, with ambiguities arising from occlusion and extreme novel
views. While dynamic Gaussian Splatting offers an efficient representation,
vanilla models optimize all Gaussian primitives uniformly, ignoring whether
they are well or poorly observed. This limitation leads to motion drifts under
occlusion and degraded synthesis when extrapolating to unseen views. We argue
that uncertainty matters: Gaussians with recurring observations across views
and time act as reliable anchors to guide motion, whereas those with limited
visibility are treated as less reliable. To this end, we introduce USplat4D, a
novel Uncertainty-aware dynamic Gaussian Splatting framework that propagates
reliable motion cues to enhance 4D reconstruction. Our key insight is to
estimate time-varying per-Gaussian uncertainty and leverages it to construct a
spatio-temporal graph for uncertainty-aware optimization. Experiments on
diverse real and synthetic datasets show that explicitly modeling uncertainty
consistently improves dynamic Gaussian Splatting models, yielding more stable
geometry under occlusion and high-quality synthesis at extreme viewpoints.

</details>


### [80] [What If : Understanding Motion Through Sparse Interactions](https://arxiv.org/abs/2510.12777)
*Stefan Andreas Baumann,Nick Stracke,Timy Phan,Björn Ommer*

Main category: cs.CV

TL;DR: 该论文提出了一种新型的Flow Poke Transformer (FPT) 框架，能直接预测场景中局部运动的分布，并能解释物理交互及其不确定性，相比传统方法更具灵活性和表现。


<details>
  <summary>Details</summary>
Motivation: 场景动力学受局部物理交互影响多样，现有方法通常难以直接、高效地推理不同交互下的多模态场景变化和不确定性。因此，研究更解释性强且泛化性好的新方法具有实际和理论意义。

Method: 作者提出了Flow Poke Transformer (FPT)，直接以稀疏物理交互（即“poke”）为条件预测局部运动分布。FPT可解释多模态场景动力学及其与交互的关系，不同于只能采样单一场景演化结果的传统方法。通过多个下游任务对模型进行评测，并与现有方法比较。

Result: FPT在密集人脸运动生成任务上超越了专业基线模型；在分布外的合成数据集（如关节物体运动估计）微调后，优于现有领域内方法；FPT还能有效完成如通过poke分割运动部件等任务，表现出高度灵活性。

Conclusion: FPT框架可以直接且可解释地对局部场景运动分布建模，增强了对场景动力学的不确定性认识，在多个下游任务上展现出强大性能和广泛适应性，推进了物理场景理解方法的发展。

Abstract: Understanding the dynamics of a physical scene involves reasoning about the
diverse ways it can potentially change, especially as a result of local
interactions. We present the Flow Poke Transformer (FPT), a novel framework for
directly predicting the distribution of local motion, conditioned on sparse
interactions termed "pokes". Unlike traditional methods that typically only
enable dense sampling of a single realization of scene dynamics, FPT provides
an interpretable directly accessible representation of multi-modal scene
motion, its dependency on physical interactions and the inherent uncertainties
of scene dynamics. We also evaluate our model on several downstream tasks to
enable comparisons with prior methods and highlight the flexibility of our
approach. On dense face motion generation, our generic pre-trained model
surpasses specialized baselines. FPT can be fine-tuned in strongly
out-of-distribution tasks such as synthetic datasets to enable significant
improvements over in-domain methods in articulated object motion estimation.
Additionally, predicting explicit motion distributions directly enables our
method to achieve competitive performance on tasks like moving part
segmentation from pokes which further demonstrates the versatility of our FPT.
Code and models are publicly available at
https://compvis.github.io/flow-poke-transformer.

</details>


### [81] [MVP4D: Multi-View Portrait Video Diffusion for Animatable 4D Avatars](https://arxiv.org/abs/2510.12785)
*Felix Taubner,Ruihang Zhang,Mathieu Tuli,Sherwin Bahmani,David B. Lindell*

Main category: cs.CV

TL;DR: 本文提出了一种新的视频模型MVP4D，能够从单张图像生成可动画、多视角的虚拟人类视频，有效提升虚拟人类的3D和时序一致性与真实感。


<details>
  <summary>Details</summary>
Motivation: 目前，生成高真实感、动态虚拟人类头像成本高昂、耗时，需复杂设备与大量人工。尽管单图像驱动的自动生成方法降门槛，但多视角与真实感受限，表现较差。为此，作者希望突破这一限制，从单图自动生成3D一致性强、可动画的虚拟人类。

Method: 作者基于先进的视频扩散模型，提出MVP4D系统。系统输入目标人物单张照片和表情驱动信息，同时输出覆盖360度的多视角可动画视频序列，并通过特殊蒸馏技术转化为可实时渲染的4D虚拟人。

Result: 实验显示，该方法较现有单图头像生成技术，在多视角、动画和3D一致性上都有显著提升。生成头像具有更高的真实感和时空一致性，可满足实际虚拟现实与游戏需求。

Conclusion: MVP4D显著降低了高质量虚拟人类创建门槛，提升了3D与动态表现，是虚拟现实、游戏和影视领域数字人生成的重要进展。

Abstract: Digital human avatars aim to simulate the dynamic appearance of humans in
virtual environments, enabling immersive experiences across gaming, film,
virtual reality, and more. However, the conventional process for creating and
animating photorealistic human avatars is expensive and time-consuming,
requiring large camera capture rigs and significant manual effort from
professional 3D artists. With the advent of capable image and video generation
models, recent methods enable automatic rendering of realistic animated avatars
from a single casually captured reference image of a target subject. While
these techniques significantly lower barriers to avatar creation and offer
compelling realism, they lack constraints provided by multi-view information or
an explicit 3D representation. So, image quality and realism degrade when
rendered from viewpoints that deviate strongly from the reference image. Here,
we build a video model that generates animatable multi-view videos of digital
humans based on a single reference image and target expressions. Our model,
MVP4D, is based on a state-of-the-art pre-trained video diffusion model and
generates hundreds of frames simultaneously from viewpoints varying by up to
360 degrees around a target subject. We show how to distill the outputs of this
model into a 4D avatar that can be rendered in real-time. Our approach
significantly improves the realism, temporal consistency, and 3D consistency of
generated avatars compared to previous methods.

</details>


### [82] [Efficient Real-World Deblurring using Single Images: AIM 2025 Challenge Report](https://arxiv.org/abs/2510.12788)
*Daniel Feijoo,Paula Garrido-Mellado,Marcos V. Conde,Jaesung Rim,Alvaro Garcia,Sunghyun Cho,Radu Timofte*

Main category: cs.CV

TL;DR: 本文综述了AIM 2025高效真实模糊图像去模糊挑战赛，介绍了任务、数据集、参赛要求和结果，对相关高效算法进行了对比总结。


<details>
  <summary>Details</summary>
Motivation: 提升真实场景下图像去模糊的有效性与效率，尤其是在参数和计算资源受限的条件下，进一步推动实际应用发展。

Method: 挑战赛使用RSBlur真实模糊数据集，参赛者需开发参数小于500万、计算量低于200 GMACs的去模糊算法，最后将不同团队的方案在指定测试集上比较。

Result: 共有71支队伍报名，最终4队提交有效方案，最佳方案PSNR达31.1298 dB，表明在高效限制下依然可获得优异去模糊性能。

Conclusion: 本挑战促进了高效真实图像去模糊算法的发展，总结了最新进展，为今后研究提供了数据和方法参考。

Abstract: This paper reviews the AIM 2025 Efficient Real-World Deblurring using Single
Images Challenge, which aims to advance in efficient real-blur restoration. The
challenge is based on a new test set based on the well known RSBlur dataset.
Pairs of blur and degraded images in this dataset are captured using a
double-camera system. Participant were tasked with developing solutions to
effectively deblur these type of images while fulfilling strict efficiency
constraints: fewer than 5 million model parameters and a computational budget
under 200 GMACs. A total of 71 participants registered, with 4 teams finally
submitting valid solutions. The top-performing approach achieved a PSNR of
31.1298 dB, showcasing the potential of efficient methods in this domain. This
paper provides a comprehensive overview of the challenge, compares the proposed
solutions, and serves as a valuable reference for researchers in efficient
real-world image deblurring.

</details>


### [83] [UniFusion: Vision-Language Model as Unified Encoder in Image Generation](https://arxiv.org/abs/2510.12789)
*Kevin Li,Manuel Brack,Sudeep Katakol,Hareesh Ravi,Ajinkya Kale*

Main category: cs.CV

TL;DR: 本文提出UniFusion模型，通过冻结整合视觉-语言模型（VLM）作为统一多模态编码器，实现高效的文本与图像融合生成，提升了跨模态推理与知识迁移能力，提高了编辑泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散生成架构通常分别采用文本与图像编码器，限制了跨模态推理与知识传递。过去的桥接尝试要么仅利用VLM最后一层信息、要么采用多重视觉编码器或联合大规模联合训练，这些方法计算和数据消耗大，易用性不足。

Method: UniFusion使用冻结的大型视觉-语言模型（VLM）作为统一的多模态编码器，并提出了『层级注意力池化（LAP）』，从VLM的不同层提取高语义与细粒度信息，辅助扩散模型生成。提出『VERIFI』机制，在推理时仅用VLM生成的文本token，并支持灵活的条件注入和推理能力。模型在编辑任务上还进行微调。

Result: LAP方法优于其他浅层融合方法，提升了文本-图像对齐与视觉信息迁移效果。VERIFI实现了更强的推理能力和推理灵活性。单图像编辑微调后，模型可零样本泛化到多图像参考，体现了极强的泛化能力。

Conclusion: UniFusion为多模态扩散强化融合提供了高效方案，提升了跨模态知识迁移和编辑性能，并具有良好的推理灵活性与泛化性，验证了统一多模态编码器设计的有效性。

Abstract: Although recent advances in visual generation have been remarkable, most
existing architectures still depend on distinct encoders for images and text.
This separation constrains diffusion models' ability to perform cross-modal
reasoning and knowledge transfer. Prior attempts to bridge this gap often use
the last layer information from VLM, employ multiple visual encoders, or train
large unified models jointly for text and image generation, which demands
substantial computational resources and large-scale data, limiting its
accessibility.We present UniFusion, a diffusion-based generative model
conditioned on a frozen large vision-language model (VLM) that serves as a
unified multimodal encoder. At the core of UniFusion is the Layerwise Attention
Pooling (LAP) mechanism that extracts both high level semantics and low level
details from text and visual tokens of a frozen VLM to condition a diffusion
generative model. We demonstrate that LAP outperforms other shallow fusion
architectures on text-image alignment for generation and faithful transfer of
visual information from VLM to the diffusion model which is key for editing. We
propose VLM-Enabled Rewriting Injection with Flexibile Inference (VERIFI),
which conditions a diffusion transformer (DiT) only on the text tokens
generated by the VLM during in-model prompt rewriting. VERIFI combines the
alignment of the conditioning distribution with the VLM's reasoning
capabilities for increased capabilities and flexibility at inference. In
addition, finetuning on editing task not only improves text-image alignment for
generation, indicative of cross-modality knowledge transfer, but also exhibits
tremendous generalization capabilities. Our model when trained on single image
editing, zero-shot generalizes to multiple image references further motivating
the unified encoder design of UniFusion.

</details>


### [84] [ViCO: A Training Strategy towards Semantic Aware Dynamic High-Resolution](https://arxiv.org/abs/2510.12793)
*Long Cui,Weiyun Wang,Jie Shao,Zichen Wen,Gen Luo,Linfeng Zhang,Yanting Zhang,Yu Qiao,Wenhai Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新训练算法ViCO，通过根据图像语义复杂度动态调整视觉token数量，有效降低了多模态大模型的推理成本。实验证明，该方法能减少多达50%的vision tokens，性能基本不变。


<details>
  <summary>Details</summary>
Motivation: 多模态大模型（MLLMs）因引入图片产生额外视觉token，导致推理成本显著增加，因此亟需新的方法降低计算开销。

Method: ViCO方法核心是采用多个MLP连接器，根据图片的语义复杂度将vision tokens进行不同程度的下采样，并通过最小化不同MLP连接器输出之间的KL散度进行训练。推理阶段，使用视觉分辨率动态路由器（ViR），为每个图片patch自动选择最合适的压缩率。

Result: ViCO方法能够在保持模型感知、推理及OCR能力的同时，将视觉token数减少最高达50%。

Conclusion: 该工作通过动态调整视觉token数，以图像语义复杂度为依据，在提升推理效率的同时不损失模型能力，为更高效多模态大模型的研发提供了可行方案。

Abstract: Existing Multimodal Large Language Models (MLLMs) suffer from increased
inference costs due to the additional vision tokens introduced by image inputs.
In this work, we propose Visual Consistency Learning (ViCO), a novel training
algorithm that enables the model to represent images of varying semantic
complexities using different numbers of vision tokens. The key idea behind our
method is to employ multiple MLP connectors, each with a different image
compression ratio, to downsample the vision tokens based on the semantic
complexity of the image. During training, we minimize the KL divergence between
the responses conditioned on different MLP connectors. At inference time, we
introduce an image router, termed Visual Resolution Router (ViR), that
automatically selects the appropriate compression rate for each image patch.
Compared with existing dynamic high-resolution strategies, which adjust the
number of visual tokens based on image resolutions, our method dynamically
adapts the number of visual tokens according to semantic complexity.
Experimental results demonstrate that our method can reduce the number of
vision tokens by up to 50% while maintaining the model's perception, reasoning,
and OCR capabilities. We hope this work will contribute to the development of
more efficient MLLMs. The code and models will be released to facilitate future
research.

</details>


### [85] [CuMPerLay: Learning Cubical Multiparameter Persistence Vectorizations](https://arxiv.org/abs/2510.12795)
*Caner Korkmaz,Brighton Nuwagira,Barış Coşkunuzer,Tolga Birdal*

Main category: cs.CV

TL;DR: 提出了一种新的可微分多参数持久性向量化层CuMPerLay，可将多参数拓扑特征引入深度学习。通过在图像分析任务中的实验，展示了其性能提升，尤其在数据有限时表现优越。


<details>
  <summary>Details</summary>
Motivation: 多参数持久性（CMP）能表达图像的复杂拓扑结构，但其多重滤波和向量化计算难以与深度学习结合，造成应用障碍。

Method: 提出CuMPerLay，通过分解多参数持久性为多个可学习的单参数持久性，再联动学习双参数滤波函数，形成可微分向量层，可以无缝插入如Swin Transformer等深度网络中；理论上证明了其向量化过程在广义Wasserstein距离下具备稳定性。

Result: 在医学影像和计算机视觉基准数据集上验证CuMPerLay，在分类和分割任务，尤其数据有限时，显著提升了表现。

Conclusion: CuMPerLay为深度网络引入全局结构拓扑信息提供了一条新路，显著增强结构化图像分析能力，具有应用前景。

Abstract: We present CuMPerLay, a novel differentiable vectorization layer that enables
the integration of Cubical Multiparameter Persistence (CMP) into deep learning
pipelines. While CMP presents a natural and powerful way to topologically work
with images, its use is hindered by the complexity of multifiltration
structures as well as the vectorization of CMP. In face of these challenges, we
introduce a new algorithm for vectorizing MP homologies of cubical complexes.
Our CuMPerLay decomposes the CMP into a combination of individual, learnable
single-parameter persistence, where the bifiltration functions are jointly
learned. Thanks to the differentiability, its robust topological feature
vectors can be seamlessly used within state-of-the-art architectures such as
Swin Transformers. We establish theoretical guarantees for the stability of our
vectorization under generalized Wasserstein metrics. Our experiments on
benchmark medical imaging and computer vision datasets show the benefit
CuMPerLay on classification and segmentation performance, particularly in
limited-data scenarios. Overall, CuMPerLay offers a promising direction for
integrating global structural information into deep networks for structured
image analysis.

</details>


### [86] [DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving](https://arxiv.org/abs/2510.12796)
*Yingyan Li,Shuyao Shang,Weisong Liu,Bing Zhan,Haochen Wang,Yuqi Wang,Yuntao Chen,Xiaoman Wang,Yasong An,Chufeng Tang,Lu Hou,Lue Fan,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: 本论文提出了一种结合视觉、语言和行为（VLA）的新型训练范式DriveVLA-W0，通过世界建模预测未来图像，有效提升自动驾驶智能的泛化能力，并在大规模数据下取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在自动驾驶中的应用受限于“监督不足”，即模型容量很大但依靠稀疏、低维的动作信号进行监督，导致模型潜力无法被充分利用。本研究旨在通过更丰富的自监督信号释放模型的表现力。

Method: 作者提出DriveVLA-W0，将世界建模任务（预测未来环境图像）作为自监督信号，促进模型学习驾驶环境动态。作者在两类主流VLA架构上实现了此范式：一种用离散视觉tokens的自回归世界模型，另一种用连续视觉特征的扩散世界模型。基于学到的表征，作者还设计了轻量级动作专家乐于降低推理延迟，满足实时部署。

Result: 在NAVSIM v1/v2基准和一个规模大680倍的内部数据集上，DriveVLA-W0显著优于BEV和常规VLA基线，并且随着数据集规模增加，性能提升加速，验证了数据扩展定律。

Conclusion: DriveVLA-W0通过世界建模实现了更丰富的自监督学习，使VLA模型充分发挥其容量和泛化能力，显著提升了自动驾驶模型在大规模、多样化数据上的表现及扩展性。

Abstract: Scaling Vision-Language-Action (VLA) models on large-scale data offers a
promising path to achieving a more generalized driving intelligence. However,
VLA models are limited by a ``supervision deficit'': the vast model capacity is
supervised by sparse, low-dimensional actions, leaving much of their
representational power underutilized. To remedy this, we propose
\textbf{DriveVLA-W0}, a training paradigm that employs world modeling to
predict future images. This task generates a dense, self-supervised signal that
compels the model to learn the underlying dynamics of the driving environment.
We showcase the paradigm's versatility by instantiating it for two dominant VLA
archetypes: an autoregressive world model for VLAs that use discrete visual
tokens, and a diffusion world model for those operating on continuous visual
features. Building on the rich representations learned from world modeling, we
introduce a lightweight action expert to address the inference latency for
real-time deployment. Extensive experiments on the NAVSIM v1/v2 benchmark and a
680x larger in-house dataset demonstrate that DriveVLA-W0 significantly
outperforms BEV and VLA baselines. Crucially, it amplifies the data scaling
law, showing that performance gains accelerate as the training dataset size
increases.

</details>


### [87] [Detect Anything via Next Point Prediction](https://arxiv.org/abs/2510.12798)
*Qing Jiang,Junan Huo,Xingyu Chen,Yuda Xiong,Zhaoyang Zeng,Yihao Chen,Tianhe Ren,Junzhi Yu,Lei Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新的多模态大模型Rex-Omni，能够在零样本设定下，在COCO和LVIS等主流检测基准上实现甚至超过传统回归检测模型的性能，并展现出丰富的泛化视觉感知和理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前物体检测主要依赖回归坐标的方法，如YOLO、DETR等，而多模态大模型（MLLMs）在物体检测任务中还存在召回率低、重复预测、坐标不准等问题。本文旨在弥补MLLMs与传统回归模型在检测精度和泛化能力之间的差距。

Method: 1）提出以特殊token量化0-999的坐标，提升坐标预测效率和准确性；2）设计多种数据引擎，自动生成高质量语义丰富的数据；3）采用两阶段训练流程，首先在大规模数据上监督微调，然后利用增强现实感知的RL后训练，以提升坐标连续性和消除重复预测。

Result: Rex-Omni在COCO和LVIS等检测基准上获得了与或超过主流回归模型（如DINO、Grounding DINO）相媲美的零样本检测性能。同时具备对象指代、指点、视觉提示、GUI锚定、空间指代、OCR和关键点定位等多种能力，经多项专用基准评测验证。

Conclusion: Rex-Omni凭借新的设计和训练方法，在视觉感知领域推动了多模态大模型的泛化检测和语言理解能力，为更通用、具备语言感知能力的视觉感知系统奠定了基础。

Abstract: Object detection has long been dominated by traditional coordinate
regression-based models, such as YOLO, DETR, and Grounding DINO. Although
recent efforts have attempted to leverage MLLMs to tackle this task, they face
challenges like low recall rate, duplicate predictions, coordinate
misalignment, etc. In this work, we bridge this gap and propose Rex-Omni, a
3B-scale MLLM that achieves state-of-the-art object perception performance. On
benchmarks like COCO and LVIS, Rex-Omni attains performance comparable to or
exceeding regression-based models (e.g., DINO, Grounding DINO) in a zero-shot
setting. This is enabled by three key designs: 1) Task Formulation: we use
special tokens to represent quantized coordinates from 0 to 999, reducing the
model's learning difficulty and improving token efficiency for coordinate
prediction; 2) Data Engines: we construct multiple data engines to generate
high-quality grounding, referring, and pointing data, providing semantically
rich supervision for training; \3) Training Pipelines: we employ a two-stage
training process, combining supervised fine-tuning on 22 million data with
GRPO-based reinforcement post-training. This RL post-training leverages
geometry-aware rewards to effectively bridge the discrete-to-continuous
coordinate prediction gap, improve box accuracy, and mitigate undesirable
behaviors like duplicate predictions that stem from the teacher-guided nature
of the initial SFT stage. Beyond conventional detection, Rex-Omni's inherent
language understanding enables versatile capabilities such as object referring,
pointing, visual prompting, GUI grounding, spatial referring, OCR and
key-pointing, all systematically evaluated on dedicated benchmarks. We believe
that Rex-Omni paves the way for more versatile and language-aware visual
perception systems.

</details>


### [88] [DeepMMSearch-R1: Empowering Multimodal LLMs in Multimodal Web Search](https://arxiv.org/abs/2510.12801)
*Kartik Narayan,Yang Xu,Tian Cao,Kavya Nerella,Vishal M. Patel,Navid Shiee,Peter Grasch,Chao Jia,Yinfei Yang,Zhe Gan*

Main category: cs.CV

TL;DR: 本论文提出了DeepMMSearch-R1，这是首个能进行按需多轮网页搜索，并能为图像和文本搜索工具动态生成查询的多模态大语言模型。该方法在多项知识密集型任务上表现优越。


<details>
  <summary>Details</summary>
Motivation: 现实应用中的多模态大模型需要访问外部知识源，并适应动态变化的信息以满足信息需求，但现有RAG等方法存在搜索流程僵硬、查询质量差、检索效率低等问题。

Method: 提出DeepMMSearch-R1模型，可根据图像优化图片搜索、根据已检索信息迭代改进文本查询。采用两阶段训练：先监督微调，再在线强化学习。训练数据集DeepMMSearchVQA包含多跳、多模态真实世界搜索问答。

Result: 在多个知识密集型基准上进行了大量实验，结果证明DeepMMSearch-R1优于现有方法。

Conclusion: DeepMMSearch-R1提升了多模态检索问答效果，推动了多模态大模型在真实世界信息检索任务的发展。

Abstract: Multimodal Large Language Models (MLLMs) in real-world applications require
access to external knowledge sources and must remain responsive to the dynamic
and ever-changing real-world information in order to address
information-seeking and knowledge-intensive user queries. Existing approaches,
such as retrieval augmented generation (RAG) methods, search agents, and search
equipped MLLMs, often suffer from rigid pipelines, excessive search calls, and
poorly constructed search queries, which result in inefficiencies and
suboptimal outcomes. To address these limitations, we present DeepMMSearch-R1,
the first multimodal LLM capable of performing on-demand, multi-turn web
searches and dynamically crafting queries for both image and text search tools.
Specifically, DeepMMSearch-R1 can initiate web searches based on relevant crops
of the input image making the image search more effective, and can iteratively
adapt text search queries based on retrieved information, thereby enabling
self-reflection and self-correction. Our approach relies on a two-stage
training pipeline: a cold start supervised finetuning phase followed by an
online reinforcement learning optimization. For training, we introduce
DeepMMSearchVQA, a novel multimodal VQA dataset created through an automated
pipeline intermixed with real-world information from web search tools. This
dataset contains diverse, multi-hop queries that integrate textual and visual
information, teaching the model when to search, what to search for, which
search tool to use and how to reason over the retrieved information. We conduct
extensive experiments across a range of knowledge-intensive benchmarks to
demonstrate the superiority of our approach. Finally, we analyze the results
and provide insights that are valuable for advancing multimodal web-search.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [89] [PHANTOM RECALL: When Familiar Puzzles Fool Smart Models](https://arxiv.org/abs/2510.11812)
*Souradeep Mukhopadhyay,Rishabh Baral,Nimeesh Mahajan,Samhitha Harish,Aswin RRV,Mihir Parmar,Mutsumi Nakamura,Chitta Baral*

Main category: cs.CL

TL;DR: 本文提出了PHANTOM RECALL基准，用以系统性测试LLMs在经典逻辑谜题及其扰动版本上的推理能力，发现现有LLMs易依赖记忆模板而非真实推理，一旦问题细节变化表现大幅下滑，暴露“幻影回忆”这一普遍失效模式。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型看似能解决各类逻辑谜题，但越来越多证据显示它们主要靠模板记忆，缺乏真实逻辑推理，实际泛化能力存疑，因此急需有系统的方法评估并改进这个问题。

Method: 作者构建了包含25道经典谜题及149个结构不变但细节变化的扰动谜题的新基准“PHANTOM RECALL”，测试11个主流LLMs，并设计了自动等价判别工具、细粒度推理错误类别体系以及基于错误类别的提示改进策略。

Result: 主流模型在原始谜题上表现接近完美，但在扰动后的谜题上远低于人类，常发生“幻影回忆”（重复无关或错误推理）和过度解释等失误。分类工具成功识别出不同推理问题。

Conclusion: LLMs在情境发生变化时缺乏重新推理能力，容易陷入记忆性复述，显示其对语言流畅性和逻辑推理间仍存在显著差距，现有模型推理泛化能力亟需提升。

Abstract: Large language models (LLMs) such as GPT, Gemini, and Claude often appear
adept at solving classic logic puzzles--but how much genuine reasoning
underlies their answers? Recent evidence suggests that these models frequently
rely on memorized templates rather than reasoning from first principles. When
puzzles are slightly modified, their performance collapses, revealing a
striking fragility. In particular, we asked: Have LLMs addressed these issues?
To what extent? How about perturbations to other puzzles? Is there a general
way of reformulating the prompt so that the models do better? To examine these
things systematically, we introduce PHANTOM RECALL, a benchmark comprising 25
well-known logic puzzles and 149 carefully designed perturbations that preserve
reasoning structure but alter superficial details and solutions. We evaluate
eleven leading LLMs and identify a recurring failure mode--phantom
recall--where models confidently reproduce memorized solutions or spurious
rationales that no longer fit the altered scenario. To probe and mitigate this
issue, we contribute three tools: (i) an automated logical-equivalence judge to
detect reasoning mismatches, (ii) a taxonomy of fine-grained reasoning error
categories, and (iii) a prompting-based mitigation framework guided by these
categories. Despite near-perfect accuracy on unmodified puzzles, models
significantly underperform humans on perturbed ones, exhibiting both phantom
recall and over-elaboration. Our findings reveal a crucial limitation: LLMs
often fail to re-reason when contextual cues shift--highlighting the gap
between linguistic fluency and logical understanding.

</details>


### [90] [R-WoM: Retrieval-augmented World Model For Computer-use Agents](https://arxiv.org/abs/2510.11892)
*Kai Mei,Jiang Guo,Shuaichen Chang,Mingwen Dong,Dongkyu Lee,Xing Niu,Jiarong Jiang*

Main category: cs.CL

TL;DR: 本文研究了大语言模型(LLMs)用于数字环境中作为世界模型的能力，发现原始LLMs在长序列模拟表现有限，并提出了基于检索增强的R-WoM模型，有效提升了仿真准确性。


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs有潜力通过模拟未来状态和预测动作结果来提升智能体决策，减少试错探索，但其幻觉和依赖静态知识导致在长程仿真中易犯累积性错误，亟需系统性评估及改进方法。

Method: 作者设计了三个任务（下一个状态识别、完整过程规划一致性、阶段转换识别）来系统评估LLMs作为世界模型的关键能力。随后引入R-WoM模型，通过检索外部最新教程知识，增强LLMs的事实性和时效性。

Result: 分析发现，LLMs能很好地捕捉短期状态，但在长程规划任务中性能显著下降。基于检索增强的R-WoM模型相比基线，在OSWorld和WebArena任务上分别提升25.3%和18.1%，尤其在长序列仿真中优势明显。

Conclusion: 单纯依赖LLMs作为世界模型在长远任务中存在显著限制，通过结合外部事实知识检索（如R-WoM）能显著提升其模拟与预测能力，证明检索增强是未来改进LLMs世界建模能力的有效途径。

Abstract: Large Language Models (LLMs) can serve as world models to enhance agent
decision-making in digital environments by simulating future states and
predicting action outcomes, potentially eliminating costly trial-and-error
exploration. However, this capability is fundamentally limited by LLMs'
tendency toward hallucination and their reliance on static training knowledge,
which can lead to compounding errors that inhibit long-horizon simulations. To
systematically investigate whether LLMs are appropriate for world modeling, we
probe two core capabilities of world models--future state prediction and reward
estimation--through three tasks: next-state identification, full-procedure
planning alignment, and milestone transition recognition. Our analysis shows
that while LLMs effectively capture immediate next states and identify
meaningful state transitions, their performance rapidly degrades in
full-procedure planning. This highlights LLMs' limitations in reliably modeling
environment dynamics over long horizons. To address these limitations, we
propose the Retrieval-augmented World Model (R-WoM), which grounds LLM
simulations by incorporating factual, up-to-date knowledge retrieved from
external tutorials. Experiments show that R-WoM achieves substantial
improvements of up to 25.3% (OSWorld) and 18.1% (WebArena) compared to
baselines, with particular advantages in longer-horizon simulations.

</details>


### [91] [LLM Knowledge is Brittle: Truthfulness Representations Rely on Superficial Resemblance](https://arxiv.org/abs/2510.11905)
*Patrick Haller,Mark Ibrahim,Polina Kirichenko,Levent Sagun,Samuel J. Bell*

Main category: cs.CL

TL;DR: 本论文研究了大语言模型（LLM）在输入形式发生表面变化时，内部知识表征的稳定性和鲁棒性，发现模型区分真假陈述的能力在输入变得与预训练数据不同时会严重下降，说明现有知识表征较为脆弱，缺乏泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前LLM虽然在很多任务上表现优异，但研究显示其对输入细节变化非常敏感，表现出脆弱性。导致这一现象的原因尚不清楚。理解LLM内部知识表征的稳定性有助于改善模型的实用性和泛化能力。

Method: 作者基于前人工作，利用语义不变的扰动（如错别字、重写等）对输入样本进行表面改动，考察LLM内部表示能否持续区分真假陈述。覆盖了四类主流LLM、五个数据集和三种知识探测方法，系统分析知识表征的可分离性如何随样本偏离预训练分布而变化。

Result: 当输入样本的外观与预训练数据相似时，LLM能较好地区分真假陈述；但随着输入偏离原始分布（即变得更“非典型”），这种可分性明显减弱，表明知识表征在表面扰动下崩溃。

Conclusion: LLM对表面变形极为敏感，其知识表征缺乏鲁棒性和泛化性，这是性能脆弱的原因之一。文章指出，当前基于真值探针的评估方法存在局限，并呼吁进一步研究如何提升模型知识表示的鲁棒性。

Abstract: For Large Language Models (LLMs) to be reliable, they must learn robust
knowledge that can be generally applied in diverse settings -- often unlike
those seen during training. Yet, extensive research has shown that LLM
performance can be brittle, with models exhibiting excessive sensitivity to
trivial input variations. In this work, we explore whether this brittleness is
a direct result of unstable internal knowledge representations. To explore this
question, we build on previous work showing that LLM representations encode
statement truthfulness -- i.e., true, factual statements can be easily
separated from false, inaccurate ones. Specifically, we test the robustness of
learned knowledge by evaluating representation separability on samples that
have undergone superficial transformations to drive them out-of-distribution
(OOD), such as typos or reformulations. By applying semantically-preserving
perturbations, we study how separability degrades as statements become more
OOD, across four LLM families, five evaluation datasets, and three knowledge
probing methods. Our results reveal that internal representations of statement
truthfulness collapse as the samples' presentations become less similar to
those seen during pre-training. While LLMs can often distinguish between true
and false statements when they closely resemble the pre-training data, this
ability is highly dependent on the statement's exact surface form. These
findings offer a possible explanation for brittle benchmark performance: LLMs
may learn shallow, non-robust knowledge representations that allow for only
limited generalizability. Our work presents a fundamental challenge for the
utility of truthfulness probes, and more broadly, calls for further research on
improving the robustness of learned knowledge representations.

</details>


### [92] [LLM Reasoning for Machine Translation: Synthetic Data Generation over Thinking Tokens](https://arxiv.org/abs/2510.11919)
*Armel Zebaze,Rachel Bawden,Benoît Sagot*

Main category: cs.CL

TL;DR: 本论文探讨了在机器翻译任务中，生成中间推理过程（“思考型”token）对大型推理模型（LRMs）表现的影响。结果发现，简单添加推理解释并不能提升翻译质量。只有在中间token包含具体翻译尝试时，才有助于性能提升。整体来看，通过教师模型优化译文或扩展平行语料，比让模型模仿推理过程更有效。


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型在数学和编程等任务中通过显性思考获得了进步，但其在机器翻译任务中相关机制尚未被充分研究。本文旨在填补这一空白，探索生成中间推理过程是否能提升翻译效果。

Method: 作者在多种语种资源等级与多样设置下，比较了生成中间推理token与仅输入输出式训练的效果。同时，尝试了人类译者风格的逐步推理解释（人工CoT）以及多模块翻译方案，测试各方法对性能提升的影响。

Result: 实验发现，单纯“思考型”token（即模型理性推理）对翻译提升无贡献。即使通过细致推理解释微调模型，效果仍不如标准法。但若中间token包含有意义翻译内容（如分步译文结果），则可以提升性能。

Conclusion: 仅依赖模型显式思考无法提升机器翻译水平。比起让模型模仿推理过程，利用教师模型改进译文或用其扩展平行语料效果更佳。

Abstract: Large reasoning models (LRMs) have led to new possibilities in terms of
problem-solving, through the devising of a natural language thought process
prior to answering a query. While their capabilities are well known across
mathematics and coding tasks, their impact on the task of machine translation
(MT) remains underexplored. In this work, we explore the benefits of the
generation of intermediate tokens when performing MT across multiple language
pairs of different levels of resourcedness and multiple setups. We find that
"thinking tokens" do not help LRMs better perform MT. This result generalizes
to models fine-tuned to reason before translating using distilled chain of
thought (CoT) inspired by human translators' practices. Specifically,
fine-tuning a model with synthetic CoT explanations detailing how to translate
step-by-step does not outperform standard input-output fine-tuning. However,
constructing the intermediate tokens by combining the outputs of modular
translation-specific prompting strategies results in improvements. Our findings
underscore that the contribution of intermediate tokens during fine-tuning
highly depends on the presence of translation attempts within them. More
broadly, our results suggest that using a teacher to refine target translations
or to expand parallel corpora is more impactful than distilling their CoT
explanations into "thinking" MT models.

</details>


### [93] [Discrepancy Detection at the Data Level: Toward Consistent Multilingual Question Answering](https://arxiv.org/abs/2510.11928)
*Lorena Calvo-Bartolomé,Valérie Aldana,Karla Cantarero,Alonso Madroñal de Mesa,Jerónimo Arenas-García,Jordan Boyd-Graber*

Main category: cs.CL

TL;DR: 本文提出了一种用于检测多语言问答系统中事实和文化差异的用户参与型事实核查流程（MIND），并在母婴健康等领域进行验证。


<details>
  <summary>Details</summary>
Motivation: 多语言问答系统需要保证跨语言之间的事实一致性，尤其是在如“什么是黄疸？”这类客观问题；同时也要关注主观性问题中的文化差异。因此，急需一种能够自动识别多语言知识库中事实及文化不一致的解决方案。

Method: 提出了MIND（用户参与的事实核查流程），可检测问答系统中的事实和文化差异，尤其对文化敏感问题（如：谁协助分娩？）突出显示差异性答案，并构建了有双语标注的事实和文化不一致数据集进行了评估。

Result: MIND在母婴健康双语QA系统及其他领域的数据上，均能有效检测出事实和文化不一致性，可靠性较高。

Conclusion: MIND可支持开发更具文化敏感性和事实一致性的多语言问答系统，其工具和数据集有助于相关领域的进一步研究。

Abstract: Multilingual question answering (QA) systems must ensure factual consistency
across languages, especially for objective queries such as What is jaundice?,
while also accounting for cultural variation in subjective responses. We
propose MIND, a user-in-the-loop fact-checking pipeline to detect factual and
cultural discrepancies in multilingual QA knowledge bases. MIND highlights
divergent answers to culturally sensitive questions (e.g., Who assists in
childbirth?) that vary by region and context. We evaluate MIND on a bilingual
QA system in the maternal and infant health domain and release a dataset of
bilingual questions annotated for factual and cultural inconsistencies. We
further test MIND on datasets from other domains to assess generalization. In
all cases, MIND reliably identifies inconsistencies, supporting the development
of more culturally aware and factually consistent QA systems.

</details>


### [94] [TopoAlign: A Framework for Aligning Code to Math via Topological Decomposition](https://arxiv.org/abs/2510.11944)
*Yupei Li,Philipp Borchert,Gerasimos Lampouras*

Main category: cs.CL

TL;DR: 本文提出了一种名为TopoAlign的新方法，通过结构化对齐代码库的数据来提升大型语言模型在数学自动形式化任务（autoformalisation）上的表现。该方法能不用额外人工标注即可获得高质量训练数据，显著提升了主流模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在数学推理上表现出色，但在从非正式到正式数学表述的自动形式化任务中仍表现有限，主要由于同时包含非正式与正式表述数据的训练语料稀缺。

Method: TopoAlign将代码分解成docstring、主函数及依赖函数等结构单元，再重组为与正式数学表述结构对应的数据，从而无需人工标注即可制造适配于数学语言模型训练的结构对齐数据。

Result: 将TopoAlign生成的数据用于训练两个主流数学模型（DeepSeek-Math和Herald），在minif2f、Putnam、ProofNet等基准上测试，其中DeepSeek-Math在BEq@10提升17.77%，在typecheck@10提升68.82%；Herald在同指标上分别提升0.12%和1.09%。

Conclusion: TopoAlign方法能够极大丰富可用于自动数学形式化训练的数据源，显著改善深度数学模型的表现，为后续更强的自动形式化工具奠定基础。

Abstract: Large Language Models (LLMs) excel at both informal and formal (e.g. Lean 4)
mathematical reasoning but still struggle with autoformalisation, the task of
transforming informal into formal mathematical statements. Autoformalisation
helps pair the informal reasoning of LLMs with formal proof assistants which
enable machine-verifiable generation and mitigate hallucinations. Yet, the
performance of current Math LLMs is constrained by the scarcity of large-scale
corpora, particularly those containing pairs of informal and formal statements.
Although current models are trained to generate code from natural language
instructions, structural and syntactic differences between these and formal
mathematics limit effective transfer learning. We propose TopoAlign, a
framework that unlocks widely available code repositories as training resources
for Math LLMs. TopoAlign decomposes code into docstrings, main functions, and
dependency functions, and reassembles these components into analogues that
structurally mirror formal statements. This produces structurally aligned code
data that can be used for training Math LLMs without requiring additional human
annotation. We train two state-of-the-art models, DeepSeek-Math and Herald, and
evaluate them on the minif2f, Putnam, and ProofNet benchmarks. TopoAlign
provides substantial gains for DeepSeek-Math, improving performance by 17.77%
on BEq@10 and 68.82% on typecheck@10. Despite introducing no new mathematical
knowledge, our framework achieves gains of 0.12% and 1.09% for Herald on BEq@10
and typecheck@10, respectively, demonstrating that training on aligned code
data is beneficial even for specialized models.

</details>


### [95] [GRAVITY: A Framework for Personalized Text Generation via Profile-Grounded Synthetic Preferences](https://arxiv.org/abs/2510.11952)
*Priyanka Dey,Daniele Rosa,Wenqing Zheng,Daniel Barcklow,Jieyu Zhao,Emilio Ferrara*

Main category: cs.CL

TL;DR: 本文提出了一种名为GRAVITY的新方法，通过合成基于用户画像的偏好数据，来提升大模型（LLM）的个性化能力，并在不同文化背景下验证了方法有效性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型的个性化很依赖昂贵的人类反馈和交互记录，且难以刻画用户更深层次的特质，严重影响可扩展性和实际应用。作者为降低对人工标注的依赖，同时考虑更丰富的用户属性，提出新框架。

Method: GRAVITY框架基于多种人口统计、文化和心理学理论（如霍夫斯泰德文化维度、Schwartz价值观、世界价值观调查、Big Five人格模型），合成能反映用户兴趣、信念和性格特质的偏好数据；并用这些数据指导生成更加个性化的内容。实验对比了GRAVITY与基线方法（如提示词调优、标准微调、朴素合成数据），并在人种文化多样的400名亚马逊用户上评测。

Result: GRAVITY方法生成的个性化内容在多文化情境（美、巴西、日本、印度）下均优于其他方法，用户偏好提升超4%；用户主观评测显示GRAVITY生成内容有超86%被偏好。

Conclusion: 基于画像情境合成的数据能显著增强LLM个性化能力、减少人工标注依赖，并提升内容吸引力，为大模型个性化提供了高效可扩展的新途径。

Abstract: Personalization in LLMs often relies on costly human feedback or interaction
logs, limiting scalability and neglecting deeper user attributes. To reduce the
reliance on human annotations, we introduce GRAVITY (Generative Response with
Aligned Values, Interests, and Traits of You), a framework for generating
synthetic, profile-grounded preference data that captures users' interests,
values, beliefs, and personality traits. By integrating demographic, cultural,
and psychological frameworks -- including Hofstede's cultural dimensions,
Schwartz's basic values, the World Values Survey, and Big Five OCEAN traits --
GRAVITY synthesizes preference pairs to guide personalized content generation.
We evaluate GRAVITY on book descriptions for 400 Amazon users, comparing it to
prompt-based conditioning, standard fine-tuning, and naive synthetic pair
generation. Profile-grounded synthetic data consistently improves generation,
especially across multiple cultures (USA, Brazil, Japan, India), achieving over
4% higher preference gains across baselines, with user studies showing that
GRAVITY outputs are preferred over 86% of the time. Our results show that
scenario-grounded synthetic data can capture richer user variation, reduce
reliance on costly annotation, and produce more engaging, user-centered
content, offering a scalable path for LLM personalization.

</details>


### [96] [Evaluating Retrieval-Augmented Generation Systems on Unanswerable, Uncheatable, Realistic, Multi-hop Queries](https://arxiv.org/abs/2510.11956)
*Gabrielle Kaili-May Liu,Bryan Li,Arman Cohan,William Gantt Walden,Eugene Yang*

Main category: cs.CL

TL;DR: 本文提出了一种可自动生成更难、更真实的RAG（Rretrieval-Augmented Generation）系统评测问题的流程，用于发现和推动RAG系统在不完整或不可回答问题上的真实能力。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG系统在多跳推理和不可回答问题上的基准测试过于简单，容易被非真实推理‘作弊’通过，难以揭示系统的真正短板，需要更复杂和现实的评测手段。

Method: 提出首个自动化、可控难度的CRUMQs（不可作弊、真实、不可回答、多跳问题）生成流程，可移植到任意语料和领域。并在两个主流RAG数据集上应用，评估主流RAG大模型的表现。

Result: 实验表明，相比现有基准，CRUMQs让RAG系统面临更大挑战，“作弊率”最多可降低81%。

Conclusion: 该流程为增强RAG评测难度和现实性、推动系统能力提供了简单有效的工具，有助于未来更强大RAG系统的发展。

Abstract: Real-world use cases often present RAG systems with complex queries for which
relevant information is missing from the corpus or is incomplete. In these
settings, RAG systems must be able to reject unanswerable, out-of-scope queries
and identify failures of retrieval and multi-hop reasoning. Despite this,
existing RAG benchmarks rarely reflect realistic task complexity for multi-hop
or out-of-scope questions, which often can be cheated via disconnected
reasoning (i.e., solved without genuine multi-hop inference) or require only
simple factual recall. This limits the ability for such benchmarks to uncover
limitations of existing RAG systems. To address this gap, we present the first
pipeline for automatic, difficulty-controlled creation of
un$\underline{c}$heatable, $\underline{r}$ealistic, $\underline{u}$nanswerable,
and $\underline{m}$ulti-hop $\underline{q}$uerie$\underline{s}$ (CRUMQs),
adaptable to any corpus and domain. We use our pipeline to create CRUMQs over
two popular RAG datasets and demonstrate its effectiveness via benchmark
experiments on leading retrieval-augmented LLMs. Results show that compared to
prior RAG benchmarks, CRUMQs are highly challenging for RAG systems and achieve
up to 81.0\% reduction in cheatability scores. More broadly, our pipeline
offers a simple way to enhance benchmark difficulty and realism and drive
development of more capable RAG systems.

</details>


### [97] [Direct Multi-Token Decoding](https://arxiv.org/abs/2510.11958)
*Xuan Luo,Weizhi Wang,Xifeng Yan*

Main category: cs.CL

TL;DR: 该论文提出了一种新型推理范式——直接多Token解码（DMTD），可让大语言模型在不增加额外参数和运算的情况下，加速生成多个token。


<details>
  <summary>Details</summary>
Motivation: 现有的解码器架构在每次生成token时需重复遍历所有层，导致推理效率较低。已有研究表明模型不同层分工明确，因此作者思考能否只用后几层高效生成多token，加速推理。

Method: 作者提出Direct Multi-Token Decoding（DMTD）方法，先通过早期和中期层一次性处理输入，随后仅用后期（late）层生成多个token，避免对早中期层的重复计算；并将该方案在Qwen3-4B模型上调优实现。

Result: 在有限数据集微调下，DMTD实现2倍解码加速，性能损失较小。通过扩展分析发现，随训练数据增加，DMTD效果将进一步提升。

Conclusion: DMTD是一种高效、无需新增参数的方法, 能显著加速大模型推理并保持性能，有望随大规模训练进一步提升效果。

Abstract: Decoder-only transformers have become the standard architecture for large
language models (LLMs) due to their strong performance. Recent studies suggest
that, in pre-trained LLMs, early, middle, and late layers may serve distinct
roles: Early layers focus on understanding the input context, middle layers
handle task-specific processing, and late layers convert abstract
representations into output tokens. We hypothesize that once representations
have been processed by the early and middle layers, the resulting hidden states
may encapsulate sufficient information to support the generation of multiple
tokens using only the late layers, eliminating the need to repeatedly traverse
the early and middle layers. We refer to this inference paradigm as Direct
Multi-Token Decoding (DMTD). Unlike speculative decoding, our method introduces
no additional parameters, auxiliary routines, or post-generation verification.
Despite being trained on a limited dataset, a fine-tuned DMTD Qwen3-4B model
has already demonstrated promising results, achieving up to a 2x speedup with
only minor performance loss. Moreover, as shown in our scaling analysis, its
performance is expected to further improve with larger training datasets.

</details>


### [98] [Scaling Long-Horizon LLM Agent via Context-Folding](https://arxiv.org/abs/2510.11967)
*Weiwei Sun,Miao Lu,Zhan Ling,Kang Liu,Xuesong Yao,Yiming Yang,Jiecao Chen*

Main category: cs.CL

TL;DR: 本文提出了Context-Folding方法，使大语言模型代理能更高效地管理和利用有限的上下文长度，从而提升在长任务序列中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型代理在长任务（long-horizon tasks）中的表现受限于上下文窗口的长度，难以管理复杂、分步的任务，因此亟需新方法提高效率和任务处理能力。

Method: 提出了Context-Folding框架：允许代理在需要时分支处理子任务，完成后将子任务的过程折叠为简洁结果，保留任务关键信息并丢弃冗余细节。为学习此行为，作者设计了端到端的增强学习方法FoldGRPO，并通过特定过程奖励鼓励有效的任务分解与上下文管理。

Result: 在复杂长任务（如Deep Research和软件工程任务）中，提出的folding agent在上下文长度缩短10倍的情况下，性能与甚至优于现有ReAct基线，且显著强于依赖传统摘要管理上下文的方法。

Conclusion: Context-Folding能够提升大语言模型的任务分解与信息管理能力，更高效地利用有限上下文，实现更优的长任务表现，对复杂任务的处理具有实际应用前景。

Abstract: Large language model (LLM) agents are fundamentally constrained by context
length on long-horizon tasks. We introduce Context-Folding, a framework that
empowers agents to actively manage their working context. An agent can
procedurally branch into a sub-trajectory to handle a subtask and then fold it
upon completion, collapsing the intermediate steps while retaining a concise
summary of the outcome. To make this behavior learnable, we develop an
end-to-end reinforcement learning framework FoldGRPO with specific process
rewards to encourage effective task decomposition and context management. On
complex long-horizon tasks (Deep Research and SWE), our folding agent matches
or outperforms the ReAct baselines while using an active context 10$\times$
smaller and significantly outperforms models that rely on summarization-based
context management.

</details>


### [99] [Conjecturing: An Overlooked Step in Formal Mathematical Reasoning](https://arxiv.org/abs/2510.11986)
*Jasivan Alex Sivakumar,Philipp Borchert,Ronald Cardenas,Gerasimos Lampouras*

Main category: cs.CL

TL;DR: 本文提出，自动化形式化（autoformalisation）数学问题不仅仅是将非正式语言翻译为形式化语言，还涉及“猜想”步骤。作者通过构建ConjectureBench并重新设计评测框架，首次系统性衡量大模型猜想能力，并提出Lean-FIRe方法，实现了部分数学问题端到端自动形式化。实验发现，忽略猜想步骤会高估大模型表现，因此需将其作为独立任务关注。


<details>
  <summary>Details</summary>
Motivation: 当前自动化形式化研究大多将非正式陈述直接转换为正式语言，但许多数学问题无法直接形式化，往往需要“先提出结论猜想”，如具体答案或边界。大语言模型在自动形式化方面表现有限，其“猜想能力”尚缺专门评估，导致相关研究进展受限。作者为准确理解和提升大模型形式化推理能力，专门研究并量化这一步骤对自动形式化的影响。

Method: 1）作者扩充现有数据集，创建ConjectureBench，用于评估模型的猜想能力；2）重新设计评测框架与指标，将猜想独立为一项评价任务；3）测试多种基础大模型（如GPT-4.1、DeepSeek-V3.1），比较在提供与不提供猜想条件下的自动形式化表现；4）提出推理时改进方法Lean-FIRe，尝试端到端解决自动形式化问题。

Result: 实验发现，当评测指标假定已知猜想时，基础模型的自动形式化表现被高估。通过Lean-FIRe方法，GPT-4.1和DeepSeek-V3.1分别首次在PutnamBench（特定数学难题）上实现13题和7题的端到端自动形式化。作者进一步证明大模型具备推导有效猜想的知识基础，但如果不将猜想作为独立步骤，则整体表现有限。

Conclusion: 猜想能力是自动形式化中的关键且被忽视的一步。要提升大模型的自动化数学推理能力，需将猜想单独视为一项任务并深入研究其与全流程的衔接。论文为自动形式化和数学AI领域后续研究提供了新思路和未来方向。

Abstract: Autoformalisation, the task of expressing informal mathematical statements in
formal language, is often viewed as a direct translation process. This,
however, disregards a critical preceding step: conjecturing. Many mathematical
problems cannot be formalised directly without first conjecturing a conclusion
such as an explicit answer, or a specific bound. Since Large Language Models
(LLMs) already struggle with autoformalisation, and the evaluation of their
conjecturing ability is limited and often entangled within autoformalisation or
proof, it is particularly challenging to understand its effect. To address this
gap, we augment existing datasets to create ConjectureBench, and redesign the
evaluation framework and metric specifically to measure the conjecturing
capabilities of LLMs both as a distinct task and within the autoformalisation
pipeline. Our evaluation of foundational models, including GPT-4.1 and
DeepSeek-V3.1, reveals that their autoformalisation performance is
substantially overestimated when the conjecture is accounted for during
evaluation. However, the conjecture should not be assumed to be provided. We
design an inference-time method, Lean-FIRe to improve conjecturing and
autoformalisation, which, to the best of our knowledge, achieves the first
successful end-to-end autoformalisation of 13 PutnamBench problems with GPT-4.1
and 7 with DeepSeek-V3.1. We demonstrate that while LLMs possess the requisite
knowledge to generate accurate conjectures, improving autoformalisation
performance requires treating conjecturing as an independent task, and
investigating further how to correctly integrate it within autoformalisation.
Finally, we provide forward-looking guidance to steer future research toward
improving conjecturing, an overlooked step of formal mathematical reasoning.

</details>


### [100] [SAGE: A Top-Down Bottom-Up Knowledge-Grounded User Simulator for Multi-turn AGent Evaluation](https://arxiv.org/abs/2510.11997)
*Ryan Shea,Yunan Lu,Liang Qiu,Zhou Yu*

Main category: cs.CL

TL;DR: SAGE框架通过结合企业业务知识和实际数据，提升多轮对话智能体评价的真实性与有效性。


<details>
  <summary>Details</summary>
Motivation: 现有多轮对话智能体的用户模拟评价方法过于通用，忽视了行业和场景的知识背景，导致模拟用户行为不真实，难以用于准确评估和改进智能体。

Method: 提出了SAGE用户模拟框架，将商业逻辑（如理想客户画像）和业务基础设施信息（如产品目录、FAQ、知识库）引入模拟用户生成流程，从而使用户行为贴合真实市场目标用户。

Result: 实验结果显示，SAGE生成的交互既真实又多样，能够帮助识别多达33%的智能体错误，优于传统方法。

Conclusion: SAGE框架提高了多轮对话智能体的评估真实性及覆盖面，为智能体调优和查错提供了强有力的手段。

Abstract: Evaluating multi-turn interactive agents is challenging due to the need for
human assessment. Evaluation with simulated users has been introduced as an
alternative, however existing approaches typically model generic users and
overlook the domain-specific principles required to capture realistic behavior.
We propose SAGE, a novel user Simulation framework for multi-turn AGent
Evaluation that integrates knowledge from business contexts. SAGE incorporates
top-down knowledge rooted in business logic, such as ideal customer profiles,
grounding user behavior in realistic customer personas. We further integrate
bottom-up knowledge taken from business agent infrastructure (e.g., product
catalogs, FAQs, and knowledge bases), allowing the simulator to generate
interactions that reflect users' information needs and expectations in a
company's target market. Through empirical evaluation, we find that this
approach produces interactions that are more realistic and diverse, while also
identifying up to 33% more agent errors, highlighting its effectiveness as an
evaluation tool to support bug-finding and iterative agent improvement.

</details>


### [101] [Generate Logical Equivalence Questions](https://arxiv.org/abs/2510.12001)
*Xinyu Wang,Haoming Yu,Yicheng Yang,Zhiyuan Li*

Main category: cs.CL

TL;DR: 本论文提出了一种新颖的自动出题系统，用于离散数学中的逻辑等价题目，能够有效生成与教材难度相当且具有一致性的练习题，从而抑制抄袭并提升自动化题目生成的效率与质量。


<details>
  <summary>Details</summary>
Motivation: 在线教学下学术不端尤其是抄袭现象越发严重，传统手工命题难以为每个学生提供不同且有质量保障的题目。现有自动出题系统生成效率低且题目难度不均，亟需改进。

Method: 提出了一种用形式化语言定义逻辑等价题目、两套生成规则，并实现了线性时间的自动生成算法。通过与现有教材题目和大模型生成题进行对比实验，量化了生成题目的难度和准确率。

Result: 实验表明，该系统生成的题目在准确率和教材题目相当，难度水平也高度一致，优于多个大语言模型自动生成的题目。

Conclusion: 所提出的AQG系统能高效生成高质量、难度均衡的逻辑等价题，为在线教育有效防止抄袭和提高练习题覆盖度提供了可行方案。

Abstract: Academic dishonesty is met with zero tolerance in higher education, yet
plagiarism has become increasingly prevalent in the era of online teaching and
learning. Automatic Question Generation (AQG) presents a potential solution to
mitigate copying by creating unique questions for each student. Additionally,
AQG can provide a vast array of practice questions. Our AQG focuses on
generating logical equivalence questions for Discrete Mathematics, a
foundational course for first-year computer science students. A literature
review reveals that existing AQGs for this type of question generate all
propositions that meet user-defined constraints, resulting in inefficiencies
and a lack of uniform question difficulty. To address this, we propose a new
approach that defines logical equivalence questions using a formal language,
translates this language into two sets of generation rules, and develops a
linear-time algorithm for question generation. We evaluated our AQG through two
experiments. The first involved a group of students completing questions
generated by our system. Statistical analysis shows that the accuracy of these
questions is comparable to that of textbook questions. The second experiment
assessed the number of steps required to solve our generated questions,
textbook questions, and those generated by multiple large language models. The
results indicated that the difficulty of our questions was similar to that of
textbook questions, confirming the quality of our AQG.

</details>


### [102] [Information Extraction from Conversation Transcripts: Neuro-Symbolic vs. LLM](https://arxiv.org/abs/2510.12023)
*Alice Saebom Kwak,Maria Alexeeva,Gus Hahn-Powell,Keith Alcock,Kevin McLaughlin,Doug McCorkle,Gabe McNunn,Mihai Surdeanu*

Main category: cs.CL

TL;DR: 本文比较了一种神经-符号（NS）方法与一种基于大语言模型（LLM）的信息抽取（IE）系统，并在农业领域的九个访谈数据上评估其效果。基于LLM的系统在准确率上优于NS系统，但各自有不同优缺点。


<details>
  <summary>Details</summary>
Motivation: 当前信息抽取研究趋向于大规模应用大语言模型，忽略了以往积累的符号或统计IE系统经验，因此作者希望对比两种体系在农业领域下的表现及实际部署的利弊。

Method: 作者针对猪、奶制品及农作物三类农业子领域，收集了九个访谈数据，并基于此分别用NS方法和LLM方法开发IE系统。对所有信息（total）及核心信息（core）分别计算系统的F1得分及运行效率等。

Result: LLM系统在总提取信息F1得分（69.4 vs. 52.7）、核心信息F1得分（63.0 vs. 47.2）上均明显高于NS系统。但NS方法运行更快、可控性更好，对无上下文任务可获得高准确率，但泛化能力差且开发维护复杂；LLM系统则易部署、维护快、泛化性强但速度慢、控制性弱且有幻觉风险。

Conclusion: LLM系统在农业IE任务中整体效果更优，但存在控制性差等问题。现实NLP系统部署除了追求性能外需综合考虑效率与可控性等，作者强调了实际部署中的“隐藏成本”。

Abstract: The current trend in information extraction (IE) is to rely extensively on
large language models, effectively discarding decades of experience in building
symbolic or statistical IE systems. This paper compares a neuro-symbolic (NS)
and an LLM-based IE system in the agricultural domain, evaluating them on nine
interviews across pork, dairy, and crop subdomains. The LLM-based system
outperforms the NS one (F1 total: 69.4 vs. 52.7; core: 63.0 vs. 47.2), where
total includes all extracted information and core focuses on essential details.
However, each system has trade-offs: the NS approach offers faster runtime,
greater control, and high accuracy in context-free tasks but lacks
generalizability, struggles with contextual nuances, and requires significant
resources to develop and maintain. The LLM-based system achieves higher
performance, faster deployment, and easier maintenance but has slower runtime,
limited control, model dependency and hallucination risks. Our findings
highlight the "hidden cost" of deploying NLP systems in real-world
applications, emphasizing the need to balance performance, efficiency, and
control.

</details>


### [103] [CPR: Mitigating Large Language Model Hallucinations with Curative Prompt Refinement](https://arxiv.org/abs/2510.12029)
*Jung-Woo Shim,Yeong-Joon Ju,Ji-Hoon Park,Seong-Whan Lee*

Main category: cs.CL

TL;DR: 该论文提出了一种可插拔的提示词优化框架CPR，用于改善大型语言模型生成时因提示词结构不佳而导致的内容幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型虽然能流畅应答多样的提示词，但面对结构不良或含糊的用户提示时，容易产生事实错误（幻觉）内容，这降低了模型的可靠性。作者发现这些幻觉的原因之一在于用户输入的提示不够清晰、具体。

Method: 作者提出Curative Prompt Refinement（CPR）方法：1）优化和清洗结构不佳的提示词；2）用微调过的小型语言模型，自动生成更丰富和明确的任务描述，使提示与用户意图更好对齐。该方法为可插拔型，可直接应用于各种语言模型。

Result: 实验表明，应用CPR优化过的提示词在生成质量和减少幻觉方面显著优于原始提示词。在无外部知识介入的情境下，优化提示词的胜率超过90%。

Conclusion: CPR框架有效提升了语言模型的安全性和可靠性，为减少幻觉问题提供了一种简单而实用的解决方案。

Abstract: Recent advancements in large language models (LLMs) highlight their fluency
in generating responses to diverse prompts. However, these models sometimes
generate plausible yet incorrect ``hallucinated" facts, undermining trust. A
frequent but often overlooked cause of such errors is the use of poorly
structured or vague prompts by users, leading LLMs to base responses on assumed
rather than actual intentions. To mitigate hallucinations induced by these
ill-formed prompts, we introduce Curative Prompt Refinement (CPR), a
plug-and-play framework for curative prompt refinement that 1) cleans
ill-formed prompts, and 2) generates additional informative task descriptions
to align the intention of the user and the prompt using a fine-tuned small
language model. When applied to language models, we discover that CPR
significantly increases the quality of generation while also mitigating
hallucination. Empirical studies show that prompts with CPR applied achieves
over a 90\% win rate over the original prompts without any external knowledge.

</details>


### [104] [Multi-stage Prompt Refinement for Mitigating Hallucinations in Large Language Models](https://arxiv.org/abs/2510.12032)
*Jung-Woo Shim,Yeong-Joon Ju,Ji-Hoon Park,Seong-Whan Lee*

Main category: cs.CL

TL;DR: 该论文提出了一种多阶段提示优化（MPR）框架，显著减少由于提示不佳引起的大模型幻觉，提升生成内容准确性。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在理解和生成任务中表现优异，但往往会因为提示中的语义歧义、语法错误或信息不全而产生幻觉，然而目前关于提示本身质量对幻觉影响的研究较少。

Method: 提出MPR框架，将不良提示通过多个阶段逐步修正，包括标点、拼写、关键词使用等各类错误。每个阶段采用对任务精调的小型模型实现，并通过上下文补充和自反思排序机制提高提示清晰度和相关性。MPR还能与现有的幻觉后处理方法结合使用。

Result: 实验证明，经MPR修正后的提示在幻觉基准测试上，取得了超过85%的优胜率，与原始提示相比显著提升了准确率。

Conclusion: MPR是一种轻量级且适应性强的方案，有效提升了大语言模型的可依赖性，适用于多种场景，并能够与其他框架协同增强效果。

Abstract: Recent advancements in large language models (LLMs) have shown strong
performance in natural language understanding and generation tasks. However,
LLMs continue to encounter challenges with hallucinations, where models
generate plausible but incorrect information. While several factors contribute
to hallucinations, the impact of ill-formed prompts, prompts with ambiguous
wording, incorrect grammar, or incomplete information, was relatively under
explored. To address this, we introduce Multi-stage Prompt Refinement (MPR), a
framework designed to systematically improve these ill-formed prompts across
multiple stages. Each stage addresses specific errors such as punctuation,
typographical mistakes, and misuse of key terms, using small language models
(SLMs) fine-tuned for these tasks. MPR iteratively enhances the clarity of
prompts with additional context and employs a self-reflection mechanism with
ranking to prioritize the most relevant input. Experimental results on
hallucination benchmarks show that prompts refined by MPR achieve over an 85~\%
win rate compared to their original forms, demonstrating its effectiveness in
reducing hallucinations and improving LLM output accuracy. Interestingly, we
reveal that MPR can be combined with existing post-hoc hallucination mitigation
frameworks, further enhancing its versatility. MPR provides a lightweight and
adaptable solution for enhancing LLM reliability across various domains.

</details>


### [105] [On the Interplay between Human Label Variation and Model Fairness](https://arxiv.org/abs/2510.12036)
*Kemal Kurniawan,Meladel Mistica,Timothy Baldwin,Jey Han Lau*

Main category: cs.CL

TL;DR: 本文研究了人工标签差异如何影响模型公平性，并比较了多数投票标签和不同HLV方法的训练效果，发现HLV训练方法能提升模型公平性。


<details>
  <summary>Details</summary>
Motivation: 大多数公平性研究关注算法优化，但忽视了标注环节带来的人为偏差。本文希望探究不同人工标签差异对模型公平性的影响。

Method: 作者将基于多数投票的标签训练与多种涵盖标签差异的HLV方法进行对比，通过实验评估它们对模型公平性的影响。

Result: 实验证明，在无额外消偏机制时，采用HLV训练方法能提升模型公平性。

Conclusion: 标签差异虽被认为是噪声，但若合理利用，可正向影响模型公平性，未来应更多关注标注数据中的多样性。

Abstract: The impact of human label variation (HLV) on model fairness is an unexplored
topic. This paper examines the interplay by comparing training on majority-vote
labels with a range of HLV methods. Our experiments show that without explicit
debiasing, HLV training methods have a positive impact on fairness.

</details>


### [106] [Uncertainty Quantification for Hallucination Detection in Large Language Models: Foundations, Methodology, and Future Directions](https://arxiv.org/abs/2510.12040)
*Sungmin Kang,Yavuz Faruk Bakman,Duygu Nur Yaldiz,Baturalp Buyukates,Salman Avestimehr*

Main category: cs.CL

TL;DR: 本文系统性综述了大语言模型（LLMs）中关于不确定性量化（UQ）及其在检测幻觉（生成虚假内容）方面的方法与进展，对现有方法进行了归类评价，并展望了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在实际应用中表现出色，但常因幻觉而产生不可靠的输出，因此亟需一种定量分析模型输出可靠性的方法。不确定性量化（UQ）作为评估模型生成可信度的重要手段，受到关注。

Method: 论文首先介绍了UQ的基础概念，包括其正式定义以及本体和偶然性不确定性的区分，并分析这些概念如何应用到LLMs。接着，论文将UQ方法在幻觉检测中的作用进行梳理和分类，对多个代表性方法做了实证研究。

Result: 论文系统地分类总结了当前用于LLMs的不确定性量化方法，并给出多种代表方法的实证结果，展现了它们在检测幻觉中的有效性。

Conclusion: 不确定性量化是提升大语言模型可依赖性的重要手段，方法多样但尚存在不足；未来研究需进一步完善UQ技术，并更好地与幻觉检测等实际应用结合。

Abstract: The rapid advancement of large language models (LLMs) has transformed the
landscape of natural language processing, enabling breakthroughs across a wide
range of areas including question answering, machine translation, and text
summarization. Yet, their deployment in real-world applications has raised
concerns over reliability and trustworthiness, as LLMs remain prone to
hallucinations that produce plausible but factually incorrect outputs.
Uncertainty quantification (UQ) has emerged as a central research direction to
address this issue, offering principled measures for assessing the
trustworthiness of model generations. We begin by introducing the foundations
of UQ, from its formal definition to the traditional distinction between
epistemic and aleatoric uncertainty, and then highlight how these concepts have
been adapted to the context of LLMs. Building on this, we examine the role of
UQ in hallucination detection, where quantifying uncertainty provides a
mechanism for identifying unreliable generations and improving reliability. We
systematically categorize a wide spectrum of existing methods along multiple
dimensions and present empirical results for several representative approaches.
Finally, we discuss current limitations and outline promising future research
directions, providing a clearer picture of the current landscape of LLM UQ for
hallucination detection.

</details>


### [107] [Improving Text-to-Image Generation with Input-Side Inference-Time Scaling](https://arxiv.org/abs/2510.12041)
*Ruibo Chen,Jiacheng Pan,Heng Huang,Zhenheng Yang*

Main category: cs.CL

TL;DR: 本文提出了一种基于大语言模型（LLM）的提示词重写框架，用于提升文本到图像（T2I）生成系统的表现。通过奖励系统和直接偏好优化训练，能够在无监督数据下优化生成质量，并在多种T2I模型和基准下验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有T2I生成模型在处理简单或定义不清的提示词时，常导致图像与文本匹配差、画质或美学不足。如何有效提升T2I系统对用户提示的理解与生成效果，成为有待解决的问题。

Method: 提出使用大语言模型对用户原始提示词进行重写。方法核心在于设计奖励机制并结合迭代式直接偏好优化（DPO）训练流程，从而无需人工标注数据即可优化提示词重写质量。该重写器在送入T2I模型前对提示进行优化。

Result: 实验显示，该方法能在不同T2I模型和数据集上显著提升图像与文本的一致性、画面质量和美学效果，优于现有强基线。并且，经过一类T2I模型训练的重写器可无须再训练便迁移到其他T2I模型，表现良好。研究还分析了LLM规模对性能提升的影响。

Conclusion: 提示词重写是一种行之有效、可扩展且模型无关的方法，可普遍提升T2I系统性能。作者计划开源代码和训练好的重写器。

Abstract: Recent advances in text-to-image (T2I) generation have achieved impressive
results, yet existing models often struggle with simple or underspecified
prompts, leading to suboptimal image-text alignment, aesthetics, and quality.
We propose a prompt rewriting framework that leverages large language models
(LLMs) to refine user inputs before feeding them into T2I backbones. Our
approach introduces a carefully designed reward system and an iterative direct
preference optimization (DPO) training pipeline, enabling the rewriter to
enhance prompts without requiring supervised fine-tuning data. We evaluate our
method across diverse T2I models and benchmarks. Results show that our prompt
rewriter consistently improves image-text alignment, visual quality, and
aesthetics, outperforming strong baselines. Furthermore, we demonstrate strong
transferability by showing that a prompt rewriter trained on one T2I backbone
generalizes effectively to others without needing to be retrained. We also
systematically study scalability, evaluating how performance gains scale with
the capacity of the large LLM used as the rewriter. These findings highlight
that prompt rewriting is an effective, scalable, and practical model-agnostic
strategy for improving T2I systems. We plan to release the code and trained
prompt rewriters soon.

</details>


### [108] [Hierarchical Alignment: Surgical Fine-Tuning via Functional Layer Specialization in Large Language Models](https://arxiv.org/abs/2510.12044)
*Yukun Zhang,Qi Dong*

Main category: cs.CL

TL;DR: 论文提出了分层对齐（Hierarchical Alignment）的方法，通过针对Transformer不同功能层（局部：语法、中间：逻辑、全局：事实）分开进行优化，显著提升了模型在流畅性、事实一致性及逻辑连贯性上的表现，并避免了传统方法常见的对齐损耗问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM的对齐技术（如DPO）普遍对模型各层采用统一优化，但Transformer结构具备层级分工现象，不同层负责不同任务。论文动因是突破这种“一刀切”，充分利用结构差异，提升模型对齐效果与效率。

Method: 创新地将DPO细分并应用于LLM的不同功能层（局部、中间、全局），针对每个层级分开进行LoRA微调。通过在Llama-3.1-8B和Qwen1.5-7B上进行实验，并使用强大的LLM作为评测判官，量化对齐效果。

Result: 实验显示，当仅对局部层进行对齐时，模型语法流畅性显著提升；对全局层对齐时，不仅事实一致性如预期提升，更显著增强了逻辑连贯性，超越了所有基线方法。所有分层策略都有效避免了标准DPO中的“对齐税”——即流畅性提升但逻辑推理能力下降的问题。

Conclusion: 分层对齐方法不仅资源效率更高且可控、可解释，对于提升LLM的可靠性和性能具重要意义。论文倡导放弃一元化整体优化策略，转向结构感知的细致微调，将推动更先进、更可靠的LLM开发。

Abstract: Existing alignment techniques for Large Language Models (LLMs), such as
Direct Preference Optimization (DPO), typically treat the model as a monolithic
entity, applying uniform optimization pressure across all layers. This approach
overlooks the functional specialization within the Transformer architecture,
where different layers are known to handle distinct tasks from syntax to
abstract reasoning. In this paper, we challenge this one-size-fits-all paradigm
by introducing Hierarchical Alignment, a novel method that applies targeted DPO
to distinct functional blocks of a model's layers: local (syntax), intermediate
(logic), and global (factuality). Through a series of controlled experiments on
state-of-the-art models like Llama-3.1-8B and Qwen1.5-7B using LoRA for
surgical fine-tuning, our results, evaluated by a powerful LLM-as-Judge,
demonstrate significant and predictable improvements. Specifically, aligning
the local layers (Local-Align) enhances grammatical fluency. More importantly,
aligning the global layers (Global-Align) not only improves factual consistency
as hypothesized but also proves to be the most effective strategy for enhancing
logical coherence, outperforming all baselines. Critically, all hierarchical
strategies successfully avoid the "alignment tax" observed in standard DPO,
where gains in fluency come at the cost of degraded logical reasoning. These
findings establish a more resource-efficient, controllable, and interpretable
path for model alignment, highlighting the immense potential of shifting from
monolithic optimization to structure-aware surgical fine-tuning to build more
advanced and reliable LLMs.

</details>


### [109] [APCE: Adaptive Progressive Context Expansion for Long Context Processing](https://arxiv.org/abs/2510.12051)
*Baisub Lee,Sanghyun Byun,Mohanad Odema,Jung Guack,Jacob Song,Woo Seong Chung*

Main category: cs.CL

TL;DR: 本文提出了一种名为APCE的上下文感知方法，以应对长上下文Transformer模型（LCTM）在处理长序列时的内存消耗过高和性能退化（ContextRot）等关键挑战。通过只选取与当前任务最相关的输入片段，显著减少了内存占用且性能与全量输入持平或更优。


<details>
  <summary>Details</summary>
Motivation: 长上下文Transformer模型在序列长度增加时会导致内存消耗急剧上升，并伴随模型性能下降（ContextRot），这严重影响了其实际部署和应用。作者希望通过智能筛选输入，既减小内存消耗，又维持甚至提升模型表现。

Method: 提出了APCE算法，通过低维语义相似性匹配，根据当前query与候选输入片段之间的相关性，优先选取最重要的输入信息，用于后续的模型处理。该方案独立于底层硬件环境，具备良好的移植性和扩展性。

Result: 实验证明，APCE在摘要任务上能仅用50%-70%的输入即可达到与全量输入相同或更优的结果。同时，大幅降低了KV-cache和自注意力的内存占用。

Conclusion: APCE为长上下文Transformer模型提供了一种高效的上下文过滤方案，有助于模型在不同实际部署环境中高效运行，并为后续长上下文相关任务提供了借鉴与启发。

Abstract: Deploying useful Long-Context Transformer Models (LCTMs) requires addressing
two key challenges: (1) A growing memory footprint due to quadratic
self-attention and linear KV-cache scaling in memory as sequence length
increases; (2) the ContextRot phenomena where empirical evidence suggests that
transformer architecture's performance degrades with increasing context length.
Given the shared dependency on the input, a natural question arises: Can we
surgically select the most important input chunks for processing to
synergistically (a) reduce the memory footprint, and (b) mitigate the
ContextRot effects? In this paper, we answer this question in the affirmative
for long-context summarization tasks. We propose APCE as a context-aware
solution to select the most important input chunks through low-dimensional
semantic similarity matching with the current query. By directly operating on
the input, APCE decouples from strict dependency on underlying hardware or CUDA
environments, promising a compatible solution scalable to different deployment
systems. Our empirical evaluations have demonstrated superior or on-par
summarization performance for APCE compared to the full dense baseline using a
fraction (50%-70%) of the input sequence resulting in KV-cache and
self-attention memory efficiency improvements. We hope our findings inspire
further research on context-aware efficiency solutions for LCTMs geared towards
other relevant long-context tasks.

</details>


### [110] [An AI-Based Behavioral Health Safety Filter and Dataset for Identifying Mental Health Crises in Text-Based Conversations](https://arxiv.org/abs/2510.12083)
*Benjamin W. Nelson,Celeste Wong,Matthew T. Silvestrini,Sooyoon Shin,Alanna Robinson,Jessica Lee,Eric Yang,John Torous,Andrew Trister*

Main category: cs.CL

TL;DR: 本文评估了Verily行为健康安全过滤器（VBHSF）在识别精神健康危机消息方面的表现，并与NVIDIA NeMo和OpenAI的开放源内容把关工具进行了对比。VBHSF展现了高灵敏度与良好特异性，优于同类工具。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在精神健康紧急事件中常常处理不当，存在发布有害建议或助长消极行为的风险，因此需要更安全且高效的过滤技术。

Method: 本研究将VBHSF在两个人工标注的精神健康消息数据集上进行了评测，包括Verily危机数据集（1,800条消息）和NVIDIA Aegis数据集子集（794条消息）。同时将VBHSF与NVIDIA NeMo Guardrails与OpenAI Omni Moderation Latest两大开源安全工具进行了对比。评测指标为灵敏度、特异性、F1分数等，由临床专家给出参考标签。

Result: 在Verily危机数据集上，VBHSF灵敏度达0.990、特异性0.992、F1分数0.939，各项危机类别灵敏度与特异性均很高。在NVIDIA Aegis数据集上，VBHSF依然保持较高的灵敏度（0.982）和准确率（0.921），特异性略有下降（0.859）。整体表现均优于NVIDIA NeMo和OpenAI Omni Moderation Latest，尤其是灵敏度（所有类别均显著更高，p<0.001）。

Conclusion: VBHSF在精神健康危机识别方面表现鲁棒、泛化能力强，优先保障高灵敏度以最大限度减少漏检，非常适用于医疗行业场景。

Abstract: Large language models often mishandle psychiatric emergencies, offering
harmful or inappropriate advice and enabling destructive behaviors. This study
evaluated the Verily behavioral health safety filter (VBHSF) on two datasets:
the Verily Mental Health Crisis Dataset containing 1,800 simulated messages and
the NVIDIA Aegis AI Content Safety Dataset subsetted to 794 mental
health-related messages. The two datasets were clinician-labelled and we
evaluated performance using the clinician labels. Additionally, we carried out
comparative performance analyses against two open source, content moderation
guardrails: OpenAI Omni Moderation Latest and NVIDIA NeMo Guardrails. The VBHSF
demonstrated, well-balanced performance on the Verily Mental Health Crisis
Dataset v1.0, achieving high sensitivity (0.990) and specificity (0.992) in
detecting any mental health crises. It achieved an F1-score of 0.939,
sensitivity ranged from 0.917-0.992, and specificity was >= 0.978 in
identifying specific crisis categories. When evaluated against the NVIDIA Aegis
AI Content Safety Dataset 2.0, VBHSF performance remained highly sensitive
(0.982) and accuracy (0.921) with reduced specificity (0.859). When compared
with the NVIDIA NeMo and OpenAI Omni Moderation Latest guardrails, the VBHSF
demonstrated superior performance metrics across both datasets, achieving
significantly higher sensitivity in all cases (all p < 0.001) and higher
specificity relative to NVIDIA NeMo (p < 0.001), but not to OpenAI Omni
Moderation Latest (p = 0.094). NVIDIA NeMo and OpenAI Omni Moderation Latest
exhibited inconsistent performance across specific crisis types, with
sensitivity for some categories falling below 0.10. Overall, the VBHSF
demonstrated robust, generalizable performance that prioritizes sensitivity to
minimize missed crises, a crucial feature for healthcare applications.

</details>


### [111] [Deep Associations, High Creativity: A Simple yet Effective Metric for Evaluating Large Language Models](https://arxiv.org/abs/2510.12110)
*Ziliang Qiu,Renfen Hu*

Main category: cs.CL

TL;DR: 提出了一种新的LLM创造力评估方法PACE，通过生成并分析平行联想链来实现高效且数据污染风险低的自动创意评测。


<details>
  <summary>Details</summary>
Motivation: 当前大模型（LLM）创造力评估面临数据污染与人工评测耗时高昂的问题，需要一种更高效、可靠的自动评估方法。

Method: 受人类创造力测评启发，作者提出PACE方法：让LLM生成平行联想链（associative chains），以此为基础量化和评估其创造力。结合Chatbot Arena创意写作排名进行验证，并对比分析LLM与人类在联想创造力上的异同。

Result: PACE评测结果与Chatbot Arena创意写作排名高度相关（Spearman ρ=0.739, p<0.001）；优秀的LLM创造力得分可与普通人水平相当，但专业人类始终表现更优，且人类联想多样性更高。无论人或LLM，联想具体性均随链延展而降低。

Conclusion: PACE是一种高效、可靠、少数据污染的LLM创造力评估工具。领先的LLM创造力已接近大众人类水平，但在创造性多样性等方面仍有差距。

Abstract: The evaluation of LLMs' creativity represents a crucial research domain,
though challenges such as data contamination and costly human assessments often
impede progress. Drawing inspiration from human creativity assessment, we
propose PACE, asking LLMs to generate Parallel Association Chains to Evaluate
their creativity. PACE minimizes the risk of data contamination and offers a
straightforward, highly efficient evaluation, as evidenced by its strong
correlation with Chatbot Arena Creative Writing rankings (Spearman's $\rho =
0.739$, $p < 0.001$) across various proprietary and open-source models. A
comparative analysis of associative creativity between LLMs and humans reveals
that while high-performing LLMs achieve scores comparable to average human
performance, professional humans consistently outperform LLMs. Furthermore,
linguistic analysis reveals that both humans and LLMs exhibit a trend of
decreasing concreteness in their associations, and humans demonstrating a
greater diversity of associative patterns.

</details>


### [112] [Tracing Multilingual Knowledge Acquisition Dynamics in Domain Adaptation: A Case Study of English-Japanese Biomedical Adaptation](https://arxiv.org/abs/2510.12115)
*Xin Zhao,Naoki Yoshinaga,Yuma Tsuta,Akiko Aizawa*

Main category: cs.CL

TL;DR: 本文研究了在多语言领域自适应过程中，大语言模型如何在不同语言间获取和迁移知识，并提出了新的评测方法AdaXEval。


<details>
  <summary>Details</summary>
Motivation: 尽管多语言领域自适应（ML-DA）被广泛用于帮助大语言模型（LLMs）跨语言学习领域知识，但对其内部知识获取与迁移机制研究不足，尤其是在低资源情境下表现不佳，因此需要更细致的机制研究与合适的评测方法。

Method: 作者提出了一种名为AdaXEval的自适应评测方法，该方法基于训练时使用的双语领域语料自动生成多项选择问答数据集，从而能直接分析模型在领域学习中的知识获取过程。同时通过不同的训练数据配方和持续训练，跟踪模型的知识学习与转移机制。

Result: 通过在13B参数量的英日双语大模型上实验，发现即使使用高质量双语语料，跨语言知识迁移依然困难，显现出机制瓶颈。相关代码已开源。

Conclusion: 多语言领域知识迁移存在困难，需要进一步研究模型在跨语言领域知识获取和迁移的内部机制。提出的AdaXEval为此提供了直接、有效的评测方式，为后续研究奠定基础。

Abstract: Multilingual domain adaptation (ML-DA) is widely used to learn new domain
knowledge across languages into large language models (LLMs). Although many
methods have been proposed to improve domain adaptation, the mechanisms of
multilingual knowledge acquisition, how domain knowledge is learned within a
language and transferred across languages, remain underexplored. This gap leads
to suboptimal performance, particularly in low-resource settings. This work
examines the learning dynamics of LLMs during ML-DA. Because prior ML-DA
studies often train and evaluate on datasets with mismatched knowledge
coverage, we propose AdaXEval, an adaptive evaluation method that builds
multiple-choice QA datasets from the same bilingual domain corpus used for
training, thereby directly studying multilingual knowledge acquisition. Through
continual training of LLMs with diverse data recipes, we track how LLMs acquire
domain facts and pinpoint the mechanism behind the transformation process from
domain training data to knowledge. Our experiments on a 13B English-Japanese
bilingual LLM reveal that cross-lingual transfer remains challenging despite a
high-quality bilingual corpus. The code has been released.

</details>


### [113] [Understanding the Modality Gap: An Empirical Study on the Speech-Text Alignment Mechanism of Large Speech Language Models](https://arxiv.org/abs/2510.12116)
*Bajian Xiang,Shuaijiang Zhao,Tingwei Guo,Wei Zou*

Main category: cs.CL

TL;DR: 本文分析了大规模端到端语音语言模型（LSLMs）在语义理解上的性能短板，并首次系统性剖析了语音与文本输入之间的表现差距（模态差距），提出相关对齐机制及改进方法。


<details>
  <summary>Details</summary>
Motivation: 尽管端到端LSLMs在对话生成等任务上表现出色，但在语义理解测试上却明显落后于传统管线系统。研究希望揭示这种落后的根本原因，并优化LSLMs在语音输入上的表现。

Method: 论文通过系统实验，分别从粗粒度（如深层语音与文本表征的方向和幅度）和细粒度（token级别对齐关系）的角度分析LSLMs的表示，提出了用于衡量对齐质量的Alignment Path Score，并据此设计了角度投影和长度归一化等有针对性的改进策略。

Result: 发现语音与文本表征在深层时方向上渐趋一致，但幅度差异增大；表示相似度与模态差距高度相关。提出的token级干预策略可以提升语音输入的正确性。

Conclusion: 首次系统性分析了LSLMs中的模态差距及其对齐机制，并提出理论和方法指导，为后续优化LSLMs在多模态任务中的性能提供了新的方向。

Abstract: End-to-end Large Speech Language Models (LSLMs) have demonstrated impressive
conversational generation abilities, yet consistently fall short of traditional
pipeline systems on semantic understanding benchmarks. In this work, we reveal
through systematic experimentation that although LSLMs lose some text input
performance after speech-text alignment training, the performance gap between
speech and text inputs is more pronounced, which we refer to as the modality
gap. To understand this gap, we analyze both coarse- and fine-grained text and
speech representations. At the coarse-grained level, representations of speech
and text in deeper layers are found to be increasingly aligned in direction
(cosine similarity), while concurrently diverging in magnitude (Euclidean
distance). We further find that representation similarity is strongly
correlated with the modality gap. At the fine-grained level, a spontaneous
token-level alignment pattern between text and speech representations is
observed. Based on this, we introduce the Alignment Path Score to quantify
token-level alignment quality, which exhibits stronger correlation with the
modality gap. Building on these insights, we design targeted interventions on
critical tokens through angle projection and length normalization. These
strategies demonstrate the potential to improve correctness for speech inputs.
Our study provides the first systematic empirical analysis of the modality gap
and alignment mechanisms in LSLMs, offering both theoretical and methodological
guidance for future optimization.

</details>


### [114] [SafeMT: Multi-turn Safety for Multimodal Language Models](https://arxiv.org/abs/2510.12133)
*Han Zhu,Juntao Dai,Jiaming Ji,Haoran Li,Chengkun Cai,Pengcheng Wen,Chi-Min Chan,Boyuan Chen,Yaodong Yang,Sirui Han,Yike Guo*

Main category: cs.CL

TL;DR: 本文提出了SafeMT多轮对话安全基准，评估多模态大语言模型（MLLMs）在多轮对话中的安全性，并验证现有模型的安全机制存在缺陷。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在实际应用中受到安全问题关注，而现有安全评估多集中在单轮对话，忽视了更真实且风险更高的多轮对话场景。

Method: 构建SafeMT基准，包括1万个含图像的有害多轮对话样本，涵盖17种场景和4种攻破方式。提出Safety Index指标，用于衡量多轮对话下模型的安全性，并评测17个主流模型。根据实验观察，进一步提出一种对话安全调节器（moderator），用于检测并干预多轮对话的恶意意图。

Result: 安全基准测试显示，随着有害对话轮数增加，主流模型被攻破的概率显著提升，显示已有安全机制不足。对话安全调节器在多轮对话下显著提升了模型的安全性，超越了现有的防护模型。

Conclusion: 多轮对话是MLLMs安全性的重要短板，SafeMT基准和对话安全调节器为社区关注和改进多模态对话安全提供了切实工具和方向。

Abstract: With the widespread use of multi-modal Large Language models (MLLMs), safety
issues have become a growing concern. Multi-turn dialogues, which are more
common in everyday interactions, pose a greater risk than single prompts;
however, existing benchmarks do not adequately consider this situation. To
encourage the community to focus on the safety issues of these models in
multi-turn dialogues, we introduce SafeMT, a benchmark that features dialogues
of varying lengths generated from harmful queries accompanied by images. This
benchmark consists of 10,000 samples in total, encompassing 17 different
scenarios and four jailbreak methods. Additionally, we propose Safety Index
(SI) to evaluate the general safety of MLLMs during conversations. We assess
the safety of 17 models using this benchmark and discover that the risk of
successful attacks on these models increases as the number of turns in harmful
dialogues rises. This observation indicates that the safety mechanisms of these
models are inadequate for recognizing the hazard in dialogue interactions. We
propose a dialogue safety moderator capable of detecting malicious intent
concealed within conversations and providing MLLMs with relevant safety
policies. Experimental results from several open-source models indicate that
this moderator is more effective in reducing multi-turn ASR compared to existed
guard models.

</details>


### [115] [Credal Transformer: A Principled Approach for Quantifying and Mitigating Hallucinations in Large Language Models](https://arxiv.org/abs/2510.12137)
*Shihao Ji,Zihui Song,Jiajie Huang*

Main category: cs.CL

TL;DR: 作者提出了Credal Transformer，通过引入基于证据理论的Credal Attention Mechanism（CAM），用“credal set”表示注意力分布的不确定性，从而减少大型语言模型的幻觉（hallucination）和自信错误。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型常常出现幻觉，即在不确定时也生成自信但事实错误的信息。现有Transformer结构的Softmax注意力机制，在处理模糊时会强行给出唯一概率分布，导致丢失不确定性信息。

Method: 提出Credal Transformer，将传统注意力替换为Credal Attention Mechanism（CAM），将注意力打分视为Dirichlet分布的证据质量。当证据不足时，生成分散注意力，明确反映模型的不确定性；证据充分时，可恢复传统注意力。

Result: 该模型能够识别分布外输入、量化歧义，并在无法回答的问题上减少自信错误（选择弃答）。

Conclusion: Credal Transformer架构通过直接引入不确定性量化，有效减少了幻觉现象，为打造更可靠的AI模型提供了新范式。

Abstract: Large Language Models (LLMs) hallucinate, generating factually incorrect yet
confident assertions. We argue this stems from the Transformer's Softmax
function, which creates "Artificial Certainty" by collapsing ambiguous
attention scores into a single probability distribution, discarding uncertainty
information at each layer. To fix this, we introduce the Credal Transformer,
which replaces standard attention with a Credal Attention Mechanism (CAM) based
on evidential theory. CAM produces a "credal set" (a set of distributions)
instead of a single attention vector, with the set's size directly measuring
model uncertainty. We implement this by re-conceptualizing attention scores as
evidence masses for a Dirichlet distribution: sufficient evidence recovers
standard attention, while insufficient evidence yields a diffuse distribution,
representing ambiguity. Empirically, the Credal Transformer identifies
out-of-distribution inputs, quantifies ambiguity, and significantly reduces
confident errors on unanswerable questions by abstaining. Our contribution is a
new architecture to mitigate hallucinations and a design paradigm that
integrates uncertainty quantification directly into the model, providing a
foundation for more reliable AI.

</details>


### [116] [A Survey on Parallel Reasoning](https://arxiv.org/abs/2510.12164)
*Ziqi Wang,Boye Niu,Zipeng Gao,Zhi Zheng,Tong Xu,Linghui Meng,Zhongli Li,Jing Liu,Yilong Chen,Chen Zhu,Hua Wu,Haifeng Wang,Enhong Chen*

Main category: cs.CL

TL;DR: 本文系统综述了大语言模型中并行推理的进展与挑战，并提出了相关研究的未来方向。


<details>
  <summary>Details</summary>
Motivation: 标准的顺序推理方法在复杂推理任务中容易出错，鲁棒性不足。并行推理作为一种新兴范式，通过同时探索多条推理路径，提高了推理的准确性和可靠性。随着LLM能力的提升，寻求更高效的推理机制成为研究热点，因而有必要对并行推理进行整理与总结。

Method: 作者首先对并行推理进行了形式化定义，并与链式思维（Chain-of-Thought）等相关概念区分。接着提出了新的分类方法，将并行推理技术划分为非交互式推理、交互式推理和聚焦效率的解码策略。综述了每种技术的代表方法，并总结其在解决复杂问题、提高输出可靠性等应用场景中的实践效果。

Result: 通过对现有方法的梳理，本文总结了并行推理在提升LLM推理性能和可靠性方面取得的进展，展示了该领域存在的多样化研究方向。同时，揭示出并行推理在实际应用和理论基础上所面临的主要挑战。

Conclusion: 本文为大语言模型的并行推理研究提供了系统的梳理和分类，总结了当前的成就与瓶颈，并为后续的创新和突破提出了可行的研究方向。该工作为新手和研究者提供了清晰的入门路径，有望推动并行推理方法的进一步发展。

Abstract: With the increasing capabilities of Large Language Models (LLMs), parallel
reasoning has emerged as a new inference paradigm that enhances reasoning
robustness by concurrently exploring multiple lines of thought before
converging on a final answer. It has become a significant trend to explore
parallel reasoning to overcome the fragility of standard sequential methods and
improve practical performance. In this paper, we aim to survey and summarize
the progress and challenges of parallel reasoning. We first present a formal
definition of parallel reasoning and clarify its distinction from related
concepts like Chain-of-Thought. Then, we organize and discuss advanced
techniques based on a novel taxonomy, including non-interactive reasoning,
interactive reasoning, and efficiency-focused decoding strategies.
Additionally, we explore various application scenarios, such as solving complex
problems and enhancing the reliability of LLM outputs.Finally, we highlight the
core challenges of parallel reasoning and suggest potential directions for
future research. We hope that our work can provide a useful roadmap for
beginners and encourage more research on improving parallel reasoning methods.
Related source can be avaliable in
https://github.com/PPPP-kaqiu/Awesome-Parallel-Reasoning.

</details>


### [117] [Towards Inference-time Scaling for Continuous Space Reasoning](https://arxiv.org/abs/2510.12167)
*Minghan Wang,Thuy-Trang Vu,Ehsan Shareghi,Gholamreza Haffari*

Main category: cs.CL

TL;DR: 本文研究了在连续空间推理中，利用多个样本生成结合重排序方法（PRM/ORM）是否能有效提升大语言模型的推理性能。结果表明，相比离散空间，现有方法转移到连续空间时提升有限，并指出了其中存在的挑战和改进方向。


<details>
  <summary>Details</summary>
Motivation: 基于文本的大语言模型推理中，多样本生成和重排序被证明能显著提升性能。作者希望探究这些方法在以 COCONUT 为代表的连续空间推理模型中，是否同样适用并带来收益。

Method: 以COCONUT连续空间推理模型为基础，通过dropout采样生成多样化的推理路径，并结合PRM/ORM重排序技术，分析样本在不同配置下的表现，并通过研究几何属性和轨迹动态，解释成功或失败的原因。

Result: 在连续空间中，采用离散空间有效的数据生成与训练PRM/ORM模型方案，仅获得了非常有限的性能提升。进一步分析发现，当前连续推理模型缺乏关键的归纳偏置，导致模型在区别正确与错误推理路径时效果不佳。

Conclusion: 作者认为，未来连续推理模型的训练框架，需不仅关注准确率，还需显式融入归纳偏置，以便推理时能更好区分和甄别正确与错误的连续思考路径。

Abstract: Inference-time scaling through multiple sample generation in combination with
Process- or Outcome-Reward Model (PRM or ORM) re-ranking has proven effective
for text-based reasoning in large language models. This paper investigates
whether such established techniques can be successfully adapted to reasoning in
the continuous space, using COCONUT (Hao et al. 2024) continuous space
reasoning LM as the backbone. We demonstrate the feasibility of generating
diverse reasoning paths through dropout-based sampling. Our Pass@N analysis on
the generated samples reveals the potential that could enable a significant
gain in performance akin to observed gain in the discrete space. However, we
highlight unique challenges faced for materializing this gain in the continuous
thought space. In particular, working recipes for data generation and training
PRM and ORM models in the discrete space unlocks only marginal improvements in
the continuous space. Through probing various aspects including geometric
properties and trajectory dynamics we identify the underlying reasons that
prevent effective discrimination between correct and incorrect reasoning
(essential for the functioning of PRM and ORM). Our findings reveal that
current limitations stem from the absence of key inductive biases in continuous
thought representations. We argue that the training frameworks for continuous
reasoning LMs require not only to optimize for accuracy but also to explicitly
incorporate inductive biases that could be utilized during inference-time for
discrimination of correct and incorrect thoughts.\footnote{Our code and data
will be publicly available.}

</details>


### [118] [From Knowledge to Treatment: Large Language Model Assisted Biomedical Concept Representation for Drug Repurposing](https://arxiv.org/abs/2510.12181)
*Chengrui Xiang,Tengfei Ma,Xiangzheng Fu,Yiping Liu,Bosheng Song,Xiangxiang Zeng*

Main category: cs.CL

TL;DR: 本文提出了一种融合大模型知识来提升药物再利用（药物重定位）预测能力的新方法LLaDR，在多项实验和案例中取得了领先效果。


<details>
  <summary>Details</summary>
Motivation: 虽然生物医学知识图谱在药物再利用中已被广泛采纳，但现有方法往往忽略了实际常识和机制性知识（如部分药物与特定治疗本质上不兼容），因此需要提升知识图谱中生物医学概念的表达能力。

Method: 提出LLaDR框架：首先利用大语言模型（LLM）为生物医学实体生成语义丰富的、与治疗相关的文本表征，然后用这些表征微调知识图谱嵌入模型（KGE），以将治疗相关知识注入KGE模型中。

Result: 在多个基准测试中，LLaDR在不同场景下均取得了SOTA性能，阿尔茨海默病等实际案例进一步证实了其稳健性和有效性。

Conclusion: LLaDR显著提升了知识图谱在药物重定位领域的能力，特别是在处理复杂/小众病症和理解生物医学概念方面具有优势，具备实际应用潜力。

Abstract: Drug repurposing plays a critical role in accelerating treatment discovery,
especially for complex and rare diseases. Biomedical knowledge graphs (KGs),
which encode rich clinical associations, have been widely adopted to support
this task. However, existing methods largely overlook common-sense biomedical
concept knowledge in real-world labs, such as mechanistic priors indicating
that certain drugs are fundamentally incompatible with specific treatments. To
address this gap, we propose LLaDR, a Large Language Model-assisted framework
for Drug Repurposing, which improves the representation of biomedical concepts
within KGs. Specifically, we extract semantically enriched treatment-related
textual representations of biomedical entities from large language models
(LLMs) and use them to fine-tune knowledge graph embedding (KGE) models. By
injecting treatment-relevant knowledge into KGE, LLaDR largely improves the
representation of biomedical concepts, enhancing semantic understanding of
under-studied or complex indications. Experiments based on benchmarks
demonstrate that LLaDR achieves state-of-the-art performance across different
scenarios, with case studies on Alzheimer's disease further confirming its
robustness and effectiveness. Code is available at
https://github.com/xiaomingaaa/LLaDR.

</details>


### [119] [Not in Sync: Unveiling Temporal Bias in Audio Chat Models](https://arxiv.org/abs/2510.12185)
*Jiayu Yao,Shenghua Liu,Yiwei Wang,Rundong Cheng,Lingrui Mei,Baolong Bi,Zhen Xiong,Xueqi Cheng*

Main category: cs.CL

TL;DR: 本研究首次系统性地分析了大型音频语言模型（LALMs）在事件时间定位方面的偏差，发现其在时间戳预测上存在系统性错误。作者通过实验提出了并量化了这种“时间偏差”，为后续改进模型指明了方向。


<details>
  <summary>Details</summary>
Motivation: 虽然LALMs已广泛应用于音频理解和多模态推理，但其在定位事件发生时间的能力尚未得到深入研究。因此，作者希望揭示并系统性地量化LALMs在时间定位上的缺陷，以推动模型改进。

Method: 作者设计了针对LALMs的受控实验，使用带有时间戳的数据集测试模型在事件发生时刻预测上的表现，并提出了“时间偏差指数”（TBI）量化模型预测与真实时间的系统性偏离。同时配合可视化工具展示偏差分布。

Result: 结果表明：（1）LALMs在时间戳预测中普遍存在时间偏差；（2）音频长度越长，偏差越大，甚至可累计到几十秒；（3）不同事件类型和事件位置，偏差程度不同。

Conclusion: 当前LALMs在事件定位时间上的偏差是一项基本局限，未来需要专门设计更具时间鲁棒性的模型架构来解决该问题。

Abstract: Large Audio Language Models (LALMs) are increasingly applied to audio
understanding and multimodal reasoning, yet their ability to locate when events
occur remains underexplored. We present the first systematic study of temporal
bias in LALMs, revealing a key limitation in their timestamp prediction. For
example, when asked "At which second does the lecturer introduce the key
formula?", models often predict timestamps that are consistently earlier or
later than the ground truth. Through controlled experiments on timestamped
datasets, we find that temporal bias (i) is prevalent across datasets and
models, (ii) increases with audio length - even accumulating to tens of seconds
in extended recordings, and (iii) varies across event types and positions. We
quantify this effect with the Temporal Bias Index (TBI), measuring systematic
misalignment in predicted event timings, and complement it with a visualization
framework. Our findings highlight a fundamental limitation in current LALMs and
call for the development of temporally robust architectures.

</details>


### [120] [DPO-Tuned Large Language Models for Segmentation in Simultaneous Speech Translation](https://arxiv.org/abs/2510.12195)
*Zeyu Yang,Satoshi Nakamura*

Main category: cs.CL

TL;DR: 本文提出了一种基于偏好对齐微调大语言模型(LLM)的新型语音同时翻译分割方法，显著提升了分割精度、翻译质量和延时表现，超过现有预训练分割模型。


<details>
  <summary>Details</summary>
Motivation: 目前的语音同时翻译需要在分割点选择上平衡质量与延时。现有如SHAS这样的分割模型虽优于传统启发式方法，但受限于监督学习目标，缺乏与人类偏好的对齐，导致分割点不够自然，影响实际实时翻译体验。

Method: 提出用大语言模型，通过直接偏好优化(Direct Preference Optimization, DPO)方法进行微调，使模型在分割点判断上充分考虑人类偏好。采用SeamlessM4T v2作为翻译主干，对英-日、中、德三组语言对的ACL 60/60语料进行评测。

Result: 实验显示，与SHAS相比，DPO微调后的LLM在分割准确度、BLEU/COMET翻译质量指标以及平均延时(average lagging)方面都取得了更好性能，且在IWSLT基线下也有优势。

Conclusion: 通过偏好对齐大语言模型，可实现超越现有预训练分割模型的实时语音翻译分割，促进自适应且符合人类自然偏好的同传系统发展。

Abstract: Simultaneous speech translation requires accurate segmentation to balance
translation quality and latency. Recent studies such as SHAS have introduced
pretrained segmentation models, achieving stronger performance than heuristic
rules. However, segmentation models such as SHAS, though pretrained and more
robust than heuristic methods, are still constrained by supervised learning
objectives and do not incorporate human preference alignment, which is crucial
for natural real-time interpretation. In this work, we propose a segmentation
framework based on large language models (LLMs) trained with Direct Preference
Optimization (DPO). By leveraging preference alignment, our method enables LLMs
to predict natural segmentation points that better meet the demands of
real-time translation. We evaluate the system on the ACL 60/60 corpus across
three language pairs (English-Japanese, Chinese, German), using SeamlessM4T v2
as the translation backbone. Experimental results show that our DPO-tuned LLM
achieves higher segmentation accuracy than SHAS and yields consistent
improvements in translation quality (BLEU, COMET) as well as latency (Average
Lagging). Furthermore, our system benefits from IWSLT baselines for direct
comparison. These findings highlight the potential of preference-tuned LLMs to
surpass existing pretrained segmentation models and advance adaptive,
human-aligned simultaneous interpretation.

</details>


### [121] [HALF: Harm-Aware LLM Fairness Evaluation Aligned with Deployment](https://arxiv.org/abs/2510.12217)
*Ali Mekky,Omar El Herraoui,Preslav Nakov,Yuxia Wang*

Main category: cs.CL

TL;DR: 本文提出了HALF（Harm-Aware LLM Fairness）框架，能在实际应用情境下按危害严重性评估大语言模型（LLM）的公平性与偏见。发现当前LLM在不同领域的公平性表现不一致，模型规模或性能不能保证公平性。医疗领域推理型模型表现较好，但在教育领域表现较差。


<details>
  <summary>Details</summary>
Motivation: 当前LLM正广泛应用于高影响领域，需要在部署前充分评估模型的公平性与偏见。然而，现有评测方法未能模拟真实应用场景，也未考虑不同偏见引发的危害严重性，存在评估不足的问题。

Method: 作者提出HALF框架，将现实中的九大应用领域分为三类（严重、中等、轻微），并设计了五阶段流程来评估模型在这些实际应用下的偏见及危害权重。通过此框架，比较了八种主流LLM在不同应用领域的公平性表现。

Result: 实验结果表明：1）LLM在不同领域的公平性不一致；2）模型规模和性能与公平性无直接关系；3）推理型模型在医疗决策支持中表现较好，但在教育领域表现较差。

Conclusion: HALF框架揭示了LLM在现实部署前，虽然在基准测试上取得不错成绩，但在实际应用中的公平性与偏见问题仍存在显著差距，需警惕其部署风险。

Abstract: Large language models (LLMs) are increasingly deployed across high-impact
domains, from clinical decision support and legal analysis to hiring and
education, making fairness and bias evaluation before deployment critical.
However, existing evaluations lack grounding in real-world scenarios and do not
account for differences in harm severity, e.g., a biased decision in surgery
should not be weighed the same as a stylistic bias in text summarization. To
address this gap, we introduce HALF (Harm-Aware LLM Fairness), a
deployment-aligned framework that assesses model bias in realistic applications
and weighs the outcomes by harm severity. HALF organizes nine application
domains into three tiers (Severe, Moderate, Mild) using a five-stage pipeline.
Our evaluation results across eight LLMs show that (1) LLMs are not
consistently fair across domains, (2) model size or performance do not
guarantee fairness, and (3) reasoning models perform better in medical decision
support but worse in education. We conclude that HALF exposes a clear gap
between previous benchmarking success and deployment readiness.

</details>


### [122] [Analysing Moral Bias in Finetuned LLMs through Mechanistic Interpretability](https://arxiv.org/abs/2510.12229)
*Bianca Raimondi,Daniela Dalbagno,Maurizio Gabbrielli*

Main category: cs.CL

TL;DR: 本文探讨了大语言模型（LLM）在微调过程中如何获得并表现出人类类似的道德偏见（Knobe效应），并通过层级修补方法定位并消除该偏见。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在微调时表现出类似于人类的社会和道德偏见，但这些偏见的具体内在机制尚不清楚，研究者希望弄清楚这些偏见是否可以被追踪到模型的特定组成部分。

Method: 作者在3个开源权重的LLM上进行了层级修补（Layer-Patching）分析，用于检测和定位（Knobe）道德偏见效应，并尝试通过将预训练模型的激活信号修补到关键层，评估偏见的消除效果。

Result: 结果显示，道德偏见确实是在微调过程中被学习到的，并且可以定位于模型中一组特定的层。更重要的是，只需对关键层做激活修补即可显著消除偏见，而无需完全重新训练模型。

Conclusion: 研究证明，LLM中的社会偏见具有可解释性和可定位性，通过对关键层进行有针对性的调整，可以缓解或消除这些偏见，为无须重训练实现模型去偏带来新途径。

Abstract: Large language models (LLMs) have been shown to internalize human-like biases
during finetuning, yet the mechanisms by which these biases manifest remain
unclear. In this work, we investigated whether the well-known Knobe effect, a
moral bias in intentionality judgements, emerges in finetuned LLMs and whether
it can be traced back to specific components of the model. We conducted a
Layer-Patching analysis across 3 open-weights LLMs and demonstrated that the
bias is not only learned during finetuning but also localized in a specific set
of layers. Surprisingly, we found that patching activations from the
corresponding pretrained model into just a few critical layers is sufficient to
eliminate the effect. Our findings offer new evidence that social biases in
LLMs can be interpreted, localized, and mitigated through targeted
interventions, without the need for model retraining.

</details>


### [123] [DSAS: A Universal Plug-and-Play Framework for Attention Optimization in Multi-Document Question Answering](https://arxiv.org/abs/2510.12251)
*Jiakai Li,Rongzheng Wang,Yizhuo Ma,Shuang Liang,Guangchun Luo,Ke Qin*

Main category: cs.CL

TL;DR: 本文针对大模型在多文档问答（Multi-doc QA）任务中的长依赖建模困难和“信息丢失于中部”（lost-in-the-middle）问题，提出了一种无需架构修改和额外训练参数的双阶段自适应锐化（DSAS）方法，在多个主流大模型和基准测试上，F1分数平均提升4.2%。


<details>
  <summary>Details</summary>
Motivation: 当前大模型在面对长文本、多文档场景时，难以抓取关键信息且中间段落常被忽视，现有方案往往要牺牲全局信息或需要高昂的微调成本，缺乏简单通用的解决方案，因此亟需新的方法提升多文档问答性能。

Method: 提出DSAS双阶段方案，包括：（1）上下文门控加权（CGW）模块，通过分层注意力追踪和位置感知加权缓解信息中部丢失问题；（2）互抑注意力抑制（RAS）模块，通过抑制关键信息与无关文本的信息交换，强化对关键段落的关注。DSAS无需更改模型架构或引入额外参数，具备“即插即用”特性。

Result: 在Llama, Qwen, Mistral, Deepseek等主流大模型和四个基准数据集上实验证明，DSAS方法提升了多文档问答性能，Llama-3.1-8B-Instruct和Qwen2.5-14B-Instruct模型的F1分数平均提升4.2%。消融实验进一步验证了CGW和RAS模块的有效作用。

Conclusion: DSAS方案无需模型结构改动和额外训练，能显著且稳健地提升大模型在多文档问答任务中的表现，在鲁棒性与可扩展性方面也具有良好表现。

Abstract: While large language models (LLMs) show considerable promise across various
fields, they have notable limitations in handling multi-document question
answering (Multi-doc QA) tasks. The first challenge is long-range dependency
modeling, where LLMs struggle to focus on key information in long texts, which
weakens important semantic connections. Second, most LLMs suffer from the
''lost-in-the-middle'' issue, where they have difficulty processing information
in the middle of long inputs. Current solutions either truncate global
dependencies or demand costly finetuning, ultimately lacking a universal and
simple solution for these challenges. To resolve these limitations, we propose
Dual-Stage Adaptive Sharpening (DSAS) containing two modules. (i) The
Contextual Gate Weighting (CGW) module alleviates ''lost-in-the-middle'' by
assessing paragraph relevance through layer-wise attention tracking and
position-aware weighting. (ii) The Reciprocal Attention Suppression (RAS)
module enhances focus on critical paragraphs by suppressing information
exchange between key and irrelevant texts, thus mitigating the limitations in
long-range dependency modeling. Notably, DSAS functions as a plug-and-play
solution requiring no architectural modifications or extra training parameters.
Extensive experiments on four benchmarks demonstrate DSAS's efficacy across
mainstream LLMs (Llama, Qwen, Mistral, and Deepseek), with an average F1-score
improvement of 4.2% in Multi-doc QA tasks on Llama-3.1-8B-Instruct and
Qwen2.5-14B-Instruct. Ablation studies confirm the essential contributions of
both the CGW and RAS modules. In addition, detailed discussions in the Appendix
further validate the robustness and scalability of DSAS.

</details>


### [124] [Shallow Robustness, Deep Vulnerabilities: Multi-Turn Evaluation of Medical LLMs](https://arxiv.org/abs/2510.12255)
*Blazej Manczak,Eric Lin,Francisco Eiras,James O' Neill,Vaikkunth Mugunthan*

Main category: cs.CL

TL;DR: 本文针对大语言模型（LLM）在多轮医学问答场景中的鲁棒性问题，提出了新的评测框架MedQA-Followup，并评估了五个主流LLM的表现，发现模型在多轮互动中准确率显著下降，尤其受到间接干扰时影响更大。


<details>
  <summary>Details</summary>
Motivation: 现有医疗领域LLM评估多以单轮问答和理想化场景为主，忽视了真实医疗对话中多轮互动、输入矛盾、误导性语境及权威影响带来的挑战，因此需要更贴合临床实际的多轮鲁棒性评测工具。

Method: 提出MedQA-Followup框架，区分浅层鲁棒性（应对误导性初始语境）与深层鲁棒性（多轮质询下的准确性），并引入间接-直接干预轴，对五个主流LLM在MedQA数据集上通过受控干预系统地进行多轮测试。

Result: 模型在处理浅层干预时表现尚可，但多轮互动下准确率大幅下降。例如Claude Sonnet 4从91.2%跌至最低13.5%；间接、语境类干预比直接干预对模型危害更大，不同模型对连续干预的恢复能力也有差异。

Conclusion: 多轮鲁棒性是当前医疗LLM部署的主要短板，间接性干预尤其容易导致模型崩溃，相关领域需要针对真实对话场景加强评测和技术改进，以保证医疗AI的安全与可靠。

Abstract: Large language models (LLMs) are rapidly transitioning into medical clinical
use, yet their reliability under realistic, multi-turn interactions remains
poorly understood. Existing evaluation frameworks typically assess single-turn
question answering under idealized conditions, overlooking the complexities of
medical consultations where conflicting input, misleading context, and
authority influence are common. We introduce MedQA-Followup, a framework for
systematically evaluating multi-turn robustness in medical question answering.
Our approach distinguishes between shallow robustness (resisting misleading
initial context) and deep robustness (maintaining accuracy when answers are
challenged across turns), while also introducing an indirect-direct axis that
separates contextual framing (indirect) from explicit suggestion (direct).
Using controlled interventions on the MedQA dataset, we evaluate five
state-of-the-art LLMs and find that while models perform reasonably well under
shallow perturbations, they exhibit severe vulnerabilities in multi-turn
settings, with accuracy dropping from 91.2% to as low as 13.5% for Claude
Sonnet 4. Counterintuitively, indirect, context-based interventions are often
more harmful than direct suggestions, yielding larger accuracy drops across
models and exposing a significant vulnerability for clinical deployment.
Further compounding analyses reveal model differences, with some showing
additional performance drops under repeated interventions while others
partially recovering or even improving. These findings highlight multi-turn
robustness as a critical but underexplored dimension for safe and reliable
deployment of medical LLMs.

</details>


### [125] [Chinese ModernBERT with Whole-Word Masking](https://arxiv.org/abs/2510.12285)
*Zeyu Zhao,Ningtao Wang,Xing Fu,Yu Cheng*

Main category: cs.CL

TL;DR: 该论文提出了一种新型的中文编码器Chinese ModernBERT，通过优化词表、掩码策略和预训练流程，提高了中文任务的准确率和效率，在多个评测中表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有的Encoder-only Transformer在英文上取得了显著进展，但这些进展尚未有效迁移到中文领域，主要原因包括中文分词和形态结构与英文差异较大。作者旨在设计一个专为中文优化的、硬件友好的Transformer编码器以提升中文自然语言处理任务的基础能力。

Method: 1. 设计了32k的BPE词表，专注于中文高频词缀和复合词，降低嵌入参数量。2. 提出整词掩码并动态调整掩码比例（从30%降到15%），使任务难度与训练进展适配。3. 采用两阶段预训练，将原生上下文长度从1024扩展到8192，结合RoPE和局部/全局交替注意力机制。4. 采用阻尼余弦学习率调度以提升长时训练稳定性。5. 在海量高质量中文数据上预训练，并加入小量对比学习数据做检索能力提升。

Result: 在CLUE上，Chinese ModernBERT在统一微调协议下具备与主流中文编码器竞争的性能。支持bf16模式，高效处理长序列同时保持短序列推理速度。检索能力测试中，微调后在SimCLUE测试集上超越Qwen-0.6B-embedding，表明模型缩放和对比学习数据引入对STS性能有明显提升。

Conclusion: Chinese ModernBERT通过多项针对中文及实际部署优化的技术，有效提升了中文Transformer编码器的性能和效率，且具有良好的拓展性。相关资源（分词器和模型权重）即将开源，有助于学术社区的可复现研究。

Abstract: Encoder-only Transformers have advanced along three axes -- architecture,
data, and systems -- yielding Pareto gains in accuracy, speed, and memory
efficiency. Yet these improvements have not fully transferred to Chinese, where
tokenization and morphology differ markedly from English. We introduce Chinese
ModernBERT, a from-scratch Chinese encoder that couples: (i) a hardware-aware
32k BPE vocabulary tailored to frequent Chinese affixes/compounds, lowering the
embedding budget; (ii) whole-word masking (WWM) with a dynamic masking
curriculum (30% -> 15%) to align task difficulty with training progress; (iii)
a two-stage pre-training pipeline that extends the native context from 1,024 to
8,192 tokens using RoPE and alternating local/global attention; and (iv) a
damped-cosine learning-rate schedule for stable long-horizon optimization. We
pre-train on ~1.2T Chinese tokens from CCI3-HQ, CCI4 (Chinese), and
Cosmopedia-Chinese. On CLUE, Chinese ModernBERT is competitive with strong
Chinese encoders under a unified fine-tuning protocol. Under bf16 it achieves
high long-sequence throughput while maintaining strong short-sequence speed,
reflecting benefits from budget allocation and attention design. To probe
retrieval-oriented quality, we add a small amount of open contrastive data:
fine-tuning on SimCLUE (~3M pairs) improves further when adding T2Ranking
(~2M), reaching 0.505 (Pearson) / 0.537 (Spearman) on the SimCLUE test set.
Under this open-data setting, Chinese ModernBERT surpasses Qwen-0.6B-embedding
on SimCLUE, suggesting a clear scaling path for STS with additional curated
pairs. We will release tokenizer and weights to facilitate reproducible
research.

</details>


### [126] [A large-scale, unsupervised pipeline for automatic corpus annotation using LLMs: variation and change in the English consider construction](https://arxiv.org/abs/2510.12306)
*Cameron Morin,Matti Marttinen Larsson*

Main category: cs.CL

TL;DR: 该论文提出并测试了一种利用大型语言模型对大规模语料库自动进行语法标注的无监督流程，实现了高效高准确率的自动化批量标注。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言语料库的持续扩展，手动标注成为限制语料库语言学研究的重要瓶颈。亟需有效的自动化解决方案来减轻人工负担并提升处理效率。

Method: 提出一种基于LLM（以GPT-5为例）的四阶段自动语法标注流程：提示工程、事前评估、自动批处理和事后校验。以美国历史英语语料库为例，对近14.4万句子进行了案例研究。

Result: 在不到60小时内自动标注143,933句COHA数据，在两种复杂标注任务上准确率超过98%。展示了该流程的可扩展性和易用性。

Conclusion: 大型语言模型可在极少人工干预下高效完成语料库的数据预处理，大大提升研究效率，但实际应用时需考虑成本、许可证及伦理等问题。

Abstract: As natural language corpora expand at an unprecedented rate, manual
annotation remains a significant methodological bottleneck in corpus linguistic
work. We address this challenge by presenting a scalable, unsupervised pipeline
for automating grammatical annotation in voluminous corpora using large
language models (LLMs). Unlike previous supervised and iterative approaches,
our method employs a four-phase workflow: prompt engineering, pre-hoc
evaluation, automated batch processing, and post-hoc validation. We demonstrate
the pipeline's accessibility and effectiveness through a diachronic case study
of variation in the English consider construction. Using GPT-5 through the
OpenAI API, we annotate 143,933 sentences from the Corpus of Historical
American English (COHA) in under 60 hours, achieving 98%+ accuracy on two
sophisticated annotation procedures. Our results suggest that LLMs can perform
a range of data preparation tasks at scale with minimal human intervention,
opening new possibilities for corpus-based research, though implementation
requires attention to costs, licensing, and other ethical considerations.

</details>


### [127] [Beating Harmful Stereotypes Through Facts: RAG-based Counter-speech Generation](https://arxiv.org/abs/2510.12316)
*Greta Damo,Elena Cabrio,Serena Villata*

Main category: cs.CL

TL;DR: 本文提出了一种基于知识增强的反言论生成框架，可以生成更值得信赖和一致的反驳言论，对抗仇恨言论等有害内容，并显示出优于传统大模型的效果。


<details>
  <summary>Details</summary>
Motivation: 现有反言论生成多依赖大语言模型或专家，但这些方法要么缺乏文本可靠性、连贯性，要么难以扩展。因此，亟需一种既高质量又具备扩展性的反言论自动生成方法。

Method: 提出将反言论生成建模为知识增强文本生成过程，整合了高级检索增强生成（RAG）流程。该方法针对八类常见仇恨对象（如女性、有色人种等），并构建了基于联合国数字图书馆、EUR-Lex和欧盟基本权利机构的大型知识库。评测中采用了MultiTarget-CONAN数据集，通过自动和人工两种方式衡量结果质量。

Result: 实验显示该方法在JudgeLM等自动指标以及人工评价上均优于标准大模型基线和主流竞争方法。

Conclusion: 该框架及知识库为可信、合理的反言论生成提供了坚实基础，对抗仇恨言论等场景具备较大潜力。

Abstract: Counter-speech generation is at the core of many expert activities, such as
fact-checking and hate speech, to counter harmful content. Yet, existing work
treats counter-speech generation as pure text generation task, mainly based on
Large Language Models or NGO experts. These approaches show severe drawbacks
due to the limited reliability and coherence in the generated countering text,
and in scalability, respectively. To close this gap, we introduce a novel
framework to model counter-speech generation as knowledge-wise text generation
process. Our framework integrates advanced Retrieval-Augmented Generation (RAG)
pipelines to ensure the generation of trustworthy counter-speech for 8 main
target groups identified in the hate speech literature, including women, people
of colour, persons with disabilities, migrants, Muslims, Jews, LGBT persons,
and other. We built a knowledge base over the United Nations Digital Library,
EUR-Lex and the EU Agency for Fundamental Rights, comprising a total of 32,792
texts. We use the MultiTarget-CONAN dataset to empirically assess the quality
of the generated counter-speech, both through standard metrics (i.e., JudgeLM)
and a human evaluation. Results show that our framework outperforms standard
LLM baselines and competitive approach, on both assessments. The resulting
framework and the knowledge base pave the way for studying trustworthy and
sound counter-speech generation, in hate speech and beyond.

</details>


### [128] [Fine-grained Analysis of Brain-LLM Alignment through Input Attribution](https://arxiv.org/abs/2510.12355)
*Michela Proietti,Roberto Capobianco,Mariya Toneva*

Main category: cs.CL

TL;DR: 本文提出了一种细粒度的输入归因方法，揭示了大语言模型（LLM）与人脑活动对齐时，模型关注的具体词语特征，并比较了模型的下一个词预测（NWP）与大脑对齐（BA）机制的异同。结果发现两者关注的词语集合明显不同，说明二者实现对齐的方式有本质差异。


<details>
  <summary>Details</summary>
Motivation: 理解大语言模型与人脑在语言处理中的对齐机制，有助于揭示人类语言计算原理，并指导模型改进。当前关于LLM和大脑对齐关系的具体机制存在争议，尤其是与预测下一个词（NWP）任务的关系，因此亟需细致研究。

Method: 作者提出了一种细粒度的输入归因方法，可识别文本中对大脑-模型对齐最重要的词项，并用该方法系统分析BA与NWP所依赖的具体词汇及其特征，比较关注词的类别和分布规律。

Result: 发现BA与NWP在关注的词语上有显著不同。NWP偏向关注较新或首部的词，主要依靠句法特征；而BA则更依赖语义和篇章层级信息，且对新近词语有更有针对性的关注。

Conclusion: LLM的人脑对齐与下一个词预测任务在特征依赖上有本质差异。该归因方法不仅有助于探索认知相关性，还可用于其他语言处理任务模型认知机制的研究。

Abstract: Understanding the alignment between large language models (LLMs) and human
brain activity can reveal computational principles underlying language
processing. We introduce a fine-grained input attribution method to identify
the specific words most important for brain-LLM alignment, and leverage it to
study a contentious research question about brain-LLM alignment: the
relationship between brain alignment (BA) and next-word prediction (NWP). Our
findings reveal that BA and NWP rely on largely distinct word subsets: NWP
exhibits recency and primacy biases with a focus on syntax, while BA
prioritizes semantic and discourse-level information with a more targeted
recency effect. This work advances our understanding of how LLMs relate to
human language processing and highlights differences in feature reliance
between BA and NWP. Beyond this study, our attribution method can be broadly
applied to explore the cognitive relevance of model predictions in diverse
language processing tasks.

</details>


### [129] [MoBiLE: Efficient Mixture-of-Experts Inference on Consumer GPU with Mixture of Big Little Experts](https://arxiv.org/abs/2510.12357)
*Yushu Zhao,Yubin Qin,Yang Wang,Xiaolong Yang,Huiming Han,Shaojun Wei,Yang Hu,Shouyi Yin*

Main category: cs.CL

TL;DR: 本文提出了一种新的MoE模型推理框架MoBiLE，可以加速推理同时保持准确率，通过混合大/小专家与高效的内存管理获得较优的速度提升。


<details>
  <summary>Details</summary>
Motivation: 当前MoE模型推理受限于CPU-GPU带宽，原有的预取方案训练代价高且在新型细粒度MoE上效果不好，因此需要更高效的推理和专家调度机制。

Method: 提出MoBiLE框架，利用big-little专家混合机制：对不重要的token使用较少/精简的小专家，加速推理，对重要token仍用全部专家保障效果，并设计了专门的回退和预取机制以优化内存利用。

Result: 在四种现代MoE和具挑战性的生成任务下评估，MoBiLE在普通消费级GPU上比基线加速1.60x~1.72x，精度下降可忽略。

Conclusion: MoBiLE能显著提升MoE模型推理速度，且对准确率影响很小，是一种高效易用的MoE推理加速方案。

Abstract: Mixture-of-Experts (MoE) models have recently demonstrated exceptional
performance across a diverse range of applications. The principle of sparse
activation in MoE models facilitates an offloading strategy, wherein active
experts are maintained in GPU HBM, while inactive experts are stored in CPU
DRAM. The efficacy of this approach, however, is fundamentally constrained by
the limited bandwidth of the CPU-GPU interconnect. To mitigate this bottleneck,
existing approaches have employed prefetching to accelerate MoE inference.
These methods attempt to predict and prefetch the required experts using
specially trained modules. Nevertheless, such techniques are often encumbered
by significant training overhead and have shown diminished effectiveness on
recent MoE models with fine-grained expert segmentation.
  In this paper, we propose MoBiLE, a plug-and-play offloading-based MoE
inference framework with \textit{mixture of big-little experts}. It reduces the
number of experts for unimportant tokens to half for acceleration while
maintaining full experts for important tokens to guarantee model quality.
Further, a dedicated fallback and prefetching mechanism is designed for
switching between little and big experts to improve memory efficiency. We
evaluate MoBiLE on four typical modern MoE architectures and challenging
generative tasks. Our results show that MoBiLE achieves a speedup of 1.60x to
1.72x compared to the baseline on a consumer GPU system, with negligible
degradation in accuracy.

</details>


### [130] [LLM-REVal: Can We Trust LLM Reviewers Yet?](https://arxiv.org/abs/2510.12367)
*Rui Li,Jia-Chen Gu,Po-Nien Kung,Heming Xia,Junfeng liu,Xiangwen Kong,Zhifang Sui,Nanyun Peng*

Main category: cs.CL

TL;DR: 本研究探讨了大模型（LLM）在学术论文评审流程中的潜在风险，发现LLM评审存在明显偏向自生成论文，对人类作者的批评内容评判不公，提出需警惕地将其用于正式评审。


<details>
  <summary>Details</summary>
Motivation: 随着大模型发展，学界尝试将其深度整合进研究与评审流程，然而LLM对学术公平性的潜在风险尚未被充分研究。

Method: 作者构建模拟实验，设置“研究代理人”生成及修改论文，“评审代理人”由LLM担任评审，并结合人工标注分析LLM评审与人工评审的一致性。

Result: 主要发现包括：1）LLM评审对LLM自写论文显著打高分，对人类作者写的论文（尤其含批评性内容）则打低分；2）这种偏差来自对LLM文风的偏好与对批评性表述的规避。

Conclusion: 未经谨慎监管将LLM大规模用于学术评审会加剧不公，损害人类作者权益。但LLM评审在提升初学者与低质量论文时有实际助益。

Abstract: The rapid advancement of large language models (LLMs) has inspired
researchers to integrate them extensively into the academic workflow,
potentially reshaping how research is practiced and reviewed. While previous
studies highlight the potential of LLMs in supporting research and peer review,
their dual roles in the academic workflow and the complex interplay between
research and review bring new risks that remain largely underexplored. In this
study, we focus on how the deep integration of LLMs into both peer-review and
research processes may influence scholarly fairness, examining the potential
risks of using LLMs as reviewers by simulation. This simulation incorporates a
research agent, which generates papers and revises, alongside a review agent,
which assesses the submissions. Based on the simulation results, we conduct
human annotations and identify pronounced misalignment between LLM-based
reviews and human judgments: (1) LLM reviewers systematically inflate scores
for LLM-authored papers, assigning them markedly higher scores than
human-authored ones; (2) LLM reviewers persistently underrate human-authored
papers with critical statements (e.g., risk, fairness), even after multiple
revisions. Our analysis reveals that these stem from two primary biases in LLM
reviewers: a linguistic feature bias favoring LLM-generated writing styles, and
an aversion toward critical statements. These results highlight the risks and
equity concerns posed to human authors and academic research if LLMs are
deployed in the peer review cycle without adequate caution. On the other hand,
revisions guided by LLM reviews yield quality gains in both LLM-based and human
evaluations, illustrating the potential of the LLMs-as-reviewers for
early-stage researchers and enhancing low-quality papers.

</details>


### [131] [Tokenization Disparities as Infrastructure Bias: How Subword Systems Create Inequities in LLM Access and Efficiency](https://arxiv.org/abs/2510.12389)
*Hailay Kidu Teklehaymanot,Wolfgang Nejdl*

Main category: cs.CL

TL;DR: 该论文系统评估了200多种语言在大模型tokenization上的效率，揭示了不同语言间存在显著的tokenization不平等。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型多基于英语等高资源语言，tokenization方式对多语种间公平使用AI存在结构性障碍，尤其影响低资源、非拉丁文及形态复杂语言。

Method: 作者采用统一的数据预处理和tiktoken库，对200多种语言样本进行tokenization，并基于TPS和RTC等指标与英语进行基准比较。

Result: 拉丁文语言tokenization效率较高，而非拉丁文及形态复杂语言的token消耗显著增加（RTC比值高3-5倍）。这种token冗余导致这类语言在计算资源和上下文利用上处于劣势。

Conclusion: 论文指出当前AI系统存在语言结构上的不公平，呼吁开发兼容多样语言结构的tokenization和自适应词表构建方法，以实现多语言环境下的AI公平性。

Abstract: Tokenization disparities pose a significant barrier to achieving equitable
access to artificial intelligence across linguistically diverse populations.
This study conducts a large-scale cross-linguistic evaluation of tokenization
efficiency in over 200 languages to systematically quantify computational
inequities in large language models (LLMs). Using a standardized experimental
framework, we applied consistent preprocessing and normalization protocols,
followed by uniform tokenization through the tiktoken library across all
language samples. Comprehensive tokenization statistics were collected using
established evaluation metrics, including Tokens Per Sentence (TPS) and
Relative Tokenization Cost (RTC), benchmarked against English baselines. Our
cross-linguistic analysis reveals substantial and systematic disparities:
Latin-script languages consistently exhibit higher tokenization efficiency,
while non-Latin and morphologically complex languages incur significantly
greater token inflation, often 3-5 times higher RTC ratios. These
inefficiencies translate into increased computational costs and reduced
effective context utilization for underrepresented languages. Overall, the
findings highlight structural inequities in current AI systems, where speakers
of low-resource and non-Latin languages face disproportionate computational
disadvantages. Future research should prioritize the development of
linguistically informed tokenization strategies and adaptive vocabulary
construction methods that incorporate typological diversity, ensuring more
inclusive and computationally equitable multilingual AI systems.

</details>


### [132] [PRoH: Dynamic Planning and Reasoning over Knowledge Hypergraphs for Retrieval-Augmented Generation](https://arxiv.org/abs/2510.12434)
*Xiangjun Zai,Xingyu Tan,Xiaoyang Wang,Qing Liu,Xiwei Xu,Wenjie Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的面向知识超图（KH）的动态计划与推理框架PRoH，用于提升RAG系统在多跳问答任务中的表现。PRoH通过动态规划、结构化问题分解以及新的推理路径检索算法，显著超越以往方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于知识超图的RAG方法存在检索规划静态、执行不适应以及对KH结构与语义利用不足等局限，难以应对多跳推理需求。

Method: PRoH框架包括三个创新模块：（1）上下文感知的规划模块，基于本地KH邻域指导推理计划生成；（2）结构化问题分解，将子问题组织为可动态演化的有向无环图（DAG），实现自适应、多路径探索；（3）基于实体加权重叠（EWO）的方法，优先选择语义连贯的超边以增强推理路径检索。

Result: 实验表明，PRoH在多个领域的测试中均取得最先进结果，平均F1指标提升19.73%，生成质量（G-E分数）提升8.41%，并在长距离多跳推理任务中展现出强鲁棒性。

Conclusion: PRoH有效解决了KH-RAG方法的三大核心瓶颈，大幅提升了多实体、多跳问答任务中的推理能力与结果质量，推动了相关领域的研究进展。

Abstract: Knowledge Hypergraphs (KHs) have recently emerged as a knowledge
representation for retrieval-augmented generation (RAG), offering a paradigm to
model multi-entity relations into a structured form. However, existing KH-based
RAG methods suffer from three major limitations: static retrieval planning,
non-adaptive retrieval execution, and superficial use of KH structure and
semantics, which constrain their ability to perform effective multi-hop
question answering. To overcome these limitations, we propose PRoH, a dynamic
Planning and Reasoning over Knowledge Hypergraphs framework. PRoH incorporates
three core innovations: (i) a context-aware planning module that sketches the
local KH neighborhood to guide structurally grounded reasoning plan generation;
(ii) a structured question decomposition process that organizes subquestions as
a dynamically evolving Directed Acyclic Graph (DAG) to enable adaptive,
multi-trajectory exploration; and (iii) an Entity-Weighted Overlap (EWO)-guided
reasoning path retrieval algorithm that prioritizes semantically coherent
hyperedge traversals. Experiments across multiple domains demonstrate that PRoH
achieves state-of-the-art performance, surpassing the prior SOTA model
HyperGraphRAG by an average of 19.73% in F1 and 8.41% in Generation Evaluation
(G-E) score, while maintaining strong robustness in long-range multi-hop
reasoning tasks.

</details>


### [133] [Probing Latent Knowledge Conflict for Faithful Retrieval-Augmented Generation](https://arxiv.org/abs/2510.12460)
*Linfeng Gao,Baolong Bi,Zheng Yuan,Le Wang,Zerui Chen,Zhimin Wei,Shenghua Liu,Qinggang Zhang,Jinsong Su*

Main category: cs.CL

TL;DR: 本文提出了一种增强RAG系统上下文忠实性的新方法CLEAR，通过对LLM内部信息整合机制的分析，有效解决了知识冲突下模型回答不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在处理知识冲突时往往会出现模型回答与检索上下文证据矛盾的现象，即上下文不忠实问题。此前的改进方法通常将LLM作为黑盒，通过外部干预（如prompt工程或奖励微调）来解决，忽视了LLM内部是如何融合检索知识与参数知识的机制。作者希望深入理解这一过程，并解决因内部冲突带来的忠实性问题。

Method: 作者通过探查LLM的隐藏状态，对知识整合过程进行层次化分析，发现冲突主要表现为句子层面的潜在信号，同时无关上下文在和参数知识一致时也会被放大。在此基础上，提出CLEAR方法：（1）将上下文分解为细粒度句子级知识；（2）利用隐藏状态分析定位冲突；（3）引入关注冲突的微调，引导模型准确整合检索证据。

Result: 在三个基准数据集上，CLEAR方法在准确率及上下文忠实性方面均有大幅提升，在多种知识冲突条件下稳定超过强基线方法。

Conclusion: CLEAR方法不仅揭示了LLM内部知识整合和冲突定位机制，还显著提升了RAG系统在有冲突知识场景下的表现，对提升大模型可靠性和实用性具有重要意义。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm to
enhance the factuality of Large Language Models (LLMs). However, existing RAG
systems often suffer from an unfaithfulness issue, where the model's response
contradicts evidence from the retrieved context. Existing approaches to
improving contextual faithfulness largely rely on external interventions, such
as prompt engineering, decoding constraints, or reward-based fine-tuning. These
works treat the LLM as a black box and overlook a crucial question: how does
the LLM internally integrate retrieved evidence with its parametric memory,
particularly under knowledge conflicts? To address this gap, we conduct a
probing-based analysis of hidden-state representations in LLMs and observe
three findings: knowledge integration occurs hierarchically, conflicts manifest
as latent signals at the sentence level, and irrelevant context is often
amplified when aligned with parametric knowledge. Building on these findings,
we propose CLEAR (Conflict-Localized and Enhanced Attention for RAG), a
framework that (i) decomposes context into fine-grained sentence-level
knowledge, (ii) employs hidden-state probing to localize conflicting knowledge,
and (iii) introduces conflict-aware fine-tuning to guide the model to
accurately integrate retrieved evidence. Extensive experiments across three
benchmarks demonstrate that CLEAR substantially improves both accuracy and
contextual faithfulness, consistently outperforming strong baselines under
diverse conflict conditions. The related resources are available at
https://github.com/LinfengGao/CLEAR.

</details>


### [134] [Resource-sensitive but language-blind: Community size and not grammatical complexity better predicts the accuracy of Large Language Models in a novel Wug Test](https://arxiv.org/abs/2510.12463)
*Nikoleta Pantelidou,Evelina Leivada,Paolo Morosi*

Main category: cs.CL

TL;DR: 本文通过多语言版Wug测试，比较六种大型语言模型与人类在新词形态泛化上的表现，发现模型能以类似人类的准确率进行泛化，但这一能力更受语料丰富度而非结构复杂度影响。


<details>
  <summary>Details</summary>
Motivation: 当前围绕大型语言模型（LLM）的语言能力存在争议，本文试图通过新词形态泛化任务，检验模型在多语言环境下的表现，并探讨影响其能力的主导因素。

Method: 采用适配多语言的Wug测试，在加泰罗尼亚语、英语、希腊语、西班牙语四种语言上测试六种模型，并与人类进行对比，考察模型在处理新词形态时的泛化能力及其准确性。

Result: 模型能以类似人类的准确率将形态泛化至未见词，但其表现更好地随社区规模和语言资源的丰富度变化，而与语言结构复杂度的关联较弱。

Conclusion: 模型的表现主要由可用语言资源的丰富程度驱动，并非对语法复杂度的敏感，模型与人类语言能力的相似性更多体现在表面。

Abstract: The linguistic abilities of Large Language Models are a matter of ongoing
debate. This study contributes to this discussion by investigating model
performance in a morphological generalization task that involves novel words.
Using a multilingual adaptation of the Wug Test, six models were tested across
four partially unrelated languages (Catalan, English, Greek, and Spanish) and
compared with human speakers. The aim is to determine whether model accuracy
approximates human competence and whether it is shaped primarily by linguistic
complexity or by the quantity of available training data. Consistent with
previous research, the results show that the models are able to generalize
morphological processes to unseen words with human-like accuracy. However,
accuracy patterns align more closely with community size and data availability
than with structural complexity, refining earlier claims in the literature. In
particular, languages with larger speaker communities and stronger digital
representation, such as Spanish and English, revealed higher accuracy than
less-resourced ones like Catalan and Greek. Overall, our findings suggest that
model behavior is mainly driven by the richness of linguistic resources rather
than by sensitivity to grammatical complexity, reflecting a form of performance
that resembles human linguistic competence only superficially.

</details>


### [135] [SMEC: Rethinking Matryoshka Representation Learning for Retrieval Embedding Compression](https://arxiv.org/abs/2510.12474)
*Biao Zhang,Lixin Chen,Tong Liu,Bo Zheng*

Main category: cs.CL

TL;DR: 该论文提出了一种新的大型语言模型嵌入压缩算法（SMEC），在显著降低嵌入维度的同时保持了模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型生成的高维嵌入虽然蕴含丰富信息，但高维度带来的计算和存储开销极大，限制了实际应用部署。因此，研究如何在保留关键信息的前提下有效压缩嵌入维度，是当前的重要课题。

Method: 作者提出了顺序套娃嵌入压缩（SMEC）框架。该框架包括三大核心方法：（1）顺序套娃表示学习（SMRL）：用于缓解训练过程中的梯度方差问题；（2）自适应维度选择（ADS）：减少剪枝降维过程中的信息损失；（3）可选跨批记忆（S-XBM）：提升高、低维嵌入之间的无监督学习效果。

Result: 在图像、文本和多模态数据集上的实验表明，SMEC框架可以在实现极大降维的同时保持模型性能。以BEIR数据集为例，256维下SMEC对比Matryoshka-Adaptor和Search-Adaptor分别提升了1.1和2.7分。

Conclusion: SMEC框架为大模型嵌入降维提供了一种有效解决方案，同时保证了实际任务中的性能，为高效部署大型语言模型提供了理论和工程基础。

Abstract: Large language models (LLMs) generate high-dimensional embeddings that
capture rich semantic and syntactic information. However, high-dimensional
embeddings exacerbate computational complexity and storage requirements,
thereby hindering practical deployment. To address these challenges, we propose
a novel training framework named Sequential Matryoshka Embedding Compression
(SMEC). This framework introduces the Sequential Matryoshka Representation
Learning(SMRL) method to mitigate gradient variance during training, the
Adaptive Dimension Selection (ADS) module to reduce information degradation
during dimension pruning, and the Selectable Cross-batch Memory (S-XBM) module
to enhance unsupervised learning between high- and low-dimensional embeddings.
Experiments on image, text, and multimodal datasets demonstrate that SMEC
achieves significant dimensionality reduction while maintaining performance.
For instance, on the BEIR dataset, our approach improves the performance of
compressed LLM2Vec embeddings (256 dimensions) by 1.1 points and 2.7 points
compared to the Matryoshka-Adaptor and Search-Adaptor models, respectively.

</details>


### [136] [When Personalization Tricks Detectors: The Feature-Inversion Trap in Machine-Generated Text Detection](https://arxiv.org/abs/2510.12476)
*Lang Gao,Xuhui Li,Chenxi Wang,Mingzhe Li,Wei Liu,Zirui Song,Jinghui Zhang,Rui Yan,Preslav Nakov,Xiuying Chen*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）能生成个性化文本，但这增加了身份冒充风险。本文首次提出用于识别个性化机器生成文本（MGT）的基准数据集，并发现多数检测器在个性化场景下表现显著下降。作者提出一种方法，能够准确预测检测器性能变化，为未来相关研究提供基础。


<details>
  <summary>Details</summary>
Motivation: 现有的文本生成检测方法没有关注个性化机器生成文本鉴别的问题，尤其当LLM模仿个人文风时，现有检测方法效果未知。随着LLM能力提升，冒充个体身份的风险加大，亟需新的检测机制。

Method: 作者构建了首个面向个性化文本检测的基准数据集，包括文学及博客原文与LLM模仿文本。同时，提出了一种检测器表现变动预测方法，通过分析“特征反转陷阱”（原本有效的特征在新领域被误导）并构造探针数据集，预测性能变化。

Result: 实验表明，大多数最先进的检测器在个性化场景中性能大幅下降。新提出的方法能准确（85%相关性）预测性能变化的方向和幅度。

Conclusion: LLM带来个性化冒充风险，当前检测器在新场景下有局限。作者的方法为理解和预测检测器在个性化文本上的适应性提供了有效工具，有望促进后续研究的开展。

Abstract: Large language models (LLMs) have grown more powerful in language generation,
producing fluent text and even imitating personal style. Yet, this ability also
heightens the risk of identity impersonation. To the best of our knowledge, no
prior work has examined personalized machine-generated text (MGT) detection. In
this paper, we introduce \dataset, the first benchmark for evaluating detector
robustness in personalized settings, built from literary and blog texts paired
with their LLM-generated imitations. Our experimental results demonstrate large
performance gaps across detectors in personalized settings: some
state-of-the-art models suffer significant drops. We attribute this limitation
to the \textit{feature-inversion trap}, where features that are discriminative
in general domains become inverted and misleading when applied to personalized
text. Based on this finding, we propose \method, a simple and reliable way to
predict detector performance changes in personalized settings. \method
identifies latent directions corresponding to inverted features and constructs
probe datasets that differ primarily along these features to evaluate detector
dependence. Our experiments show that \method can accurately predict both the
direction and the magnitude of post-transfer changes, showing 85\% correlation
with the actual performance gaps. We hope that this work will encourage further
research on personalized text detection.

</details>


### [137] [BoN Appetit Team at LeWiDi-2025: Best-of-N Test-time Scaling Can Not Stomach Annotation Disagreements (Yet)](https://arxiv.org/abs/2510.12516)
*Tomas Ruiz,Siyao Peng,Barbara Plank,Carsten Schwemmer*

Main category: cs.CL

TL;DR: 本文研究了通过在推理阶段增加计算量（test-time scaling）来提升大语言模型（LLM）输出质量的方法在LeWiDi-2025任务上的应用，发现传统基准方法有效，但Best-of-N方法迁移效果不好。


<details>
  <summary>Details</summary>
Motivation: 目前test-time scaling多用于有确定性正确答案的领域（如数学和编程），但其在需要评估注解分歧的LeWiDi任务上的效果尚不清楚。该研究旨在探索这些技巧在新领域中的适用性。

Method: 本文在LeWiDi-2025任务上，使用了三种test-time scaling方法：模型平均法、少数服从多数法（多数投票）、以及Best-of-N采样法，并比较它们在相关任务上的效果。

Result: 实验发现，模型平均和多数投票两种基准方法在LeWiDi任务上都能一致提升LLM性能，但Best-of-N采样方法未取得期望中的改善，显示该方法从有唯一正确答案的数学任务向LeWiDi任务迁移遇到困难。

Conclusion: test-time scaling中的传统基准方法能有效提升特定任务性能，但Best-of-N采样的方法不适用于LeWiDi任务。论文进一步分析了导致这一差异的潜在原因。

Abstract: Test-time scaling is a family of techniques to improve LLM outputs at
inference time by performing extra computation. To the best of our knowledge,
test-time scaling has been limited to domains with verifiably correct answers,
like mathematics and coding. We transfer test-time scaling to the LeWiDi-2025
tasks to evaluate annotation disagreements. We experiment with three test-time
scaling methods: two benchmark algorithms (Model Averaging and Majority
Voting), and a Best-of-N sampling method. The two benchmark methods improve LLM
performance consistently on the LeWiDi tasks, but the Best-of-N method does
not. Our experiments suggest that the Best-of-N method does not currently
transfer from mathematics to LeWiDi tasks, and we analyze potential reasons for
this gap.

</details>


### [138] [VISaGE: Understanding Visual Generics and Exceptions](https://arxiv.org/abs/2510.12548)
*Stella Frank,Emily Allaway*

Main category: cs.CL

TL;DR: 该论文研究视觉语言模型（VLMs）在分析非典型实例时会在语用先验和语义先验之间产生冲突，并引入了包含典型与异常图像的新数据集VISaGE进行评估。实验证明，当图文输入不一致时，概念理解显著退化。


<details>
  <summary>Details</summary>
Motivation: VLMs虽在训练时学习了广义概念知识，但实际使用时常用于分析单一样本，尤其遇到非典型（异常）实例时，模型会在依赖输入一致（语用先验）和概念泛化（语义先验）之间产生矛盾。作者希望弄清楚VLMs如何在分析异常样本时权衡这两种先验。

Method: 作者提出了VISaGE数据集，涵盖典型与非典型图片，并设计了平衡实验，系统评估了VLMs在输入图文一致与不一致时的表现，以观察语用先验和语义先验的影响。

Result: 实验表明，当图像与文本输入不一致时，VLMs的概念理解能力明显下降。这一退化效果比依赖语义泛化的退化更强烈，说明语用先验在实际问题中影响巨大。

Conclusion: VLMs在处理异常个例时更受语用先验的影响，若输入图文不一致，模型的泛化理解能力会大幅下降。未来应考虑模型在非典型情况下对语用与语义先验的平衡能力。

Abstract: While Vision Language Models (VLMs) learn conceptual representations, in the
form of generalized knowledge, during training, they are typically used to
analyze individual instances. When evaluation instances are atypical, this
paradigm results in tension between two priors in the model. The first is a
pragmatic prior that the textual and visual input are both relevant, arising
from VLM finetuning on congruent inputs; the second is a semantic prior that
the conceptual representation is generally true for instances of the category.
In order to understand how VLMs trade off these priors, we introduce a new
evaluation dataset, VISaGE, consisting of both typical and exceptional images.
In carefully balanced experiments, we show that conceptual understanding
degrades when the assumption of congruency underlying the pragmatic prior is
violated with incongruent images. This effect is stronger than the effect of
the semantic prior when querying about individual instances.

</details>


### [139] [Teaching Language Models to Faithfully Express their Uncertainty](https://arxiv.org/abs/2510.12587)
*Bryan Eikema,Evgenia Ilia,José G. C. de Souza,Chrysoula Zerva,Wilker Aziz*

Main category: cs.CL

TL;DR: 提出了一种新的微调方法（FUT），显著提升大语言模型（LLM）对自身不确定性的忠实表达，无损准确率。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型对于不确定性的表达不够真实，连续查询时可能答案变化极大但模型往往缺乏恰当的语言标记，导致用户接收到的信息不忠实，带来信任和理解风险。

Method: 提出了一种名为Faithful Uncertainty Tuning（FUT）的微调方法：通过自动化地为模型样本添加与一致性对齐的不确定性提示词（如“可能”，“大概”），用作训练数据，无需外部人工标注。微调后的模型可以在回答时通过语言更真实地反映答案的不确定性，同时不改变其原有的回答分布。

Result: 在开放域问答多模型多数据集上评估，FUT显著缩小了模型表达的“忠实度鸿沟”，保持了准确率且语义分布变化极小。在不同解码策略、提示词乃至数值化不确定性表达等多种设定下，方法稳健有效。

Conclusion: FUT是一种简单有效、无需额外标注的数据增强微调手段，可推广用于教会LLM忠实表达不确定性，提高模型输出的可信度与可用性。

Abstract: Large language models (LLMs) often miscommunicate their uncertainty: repeated
queries can produce divergent answers, yet generated responses are typically
unhedged or hedged in ways that do not reflect this variability. This conveys
unfaithful information about the uncertain state of the LLMs' knowledge,
creating a faithfulness gap that affects even strong LLMs. We introduce
Faithful Uncertainty Tuning (FUT): a fine-tuning approach that teaches
instruction-tuned LLMs to express uncertainty faithfully without altering their
underlying answer distribution. We construct training data by augmenting model
samples with uncertainty hedges (i.e. verbal cues such as 'possibly' or
'likely') aligned with sample consistency, requiring no supervision beyond the
model and a set of prompts. We evaluate FUT on open-domain question answering
(QA) across multiple models and datasets. Our results show that FUT
substantially reduces the faithfulness gap, while preserving QA accuracy and
introducing minimal semantic distribution shift. Further analyses demonstrate
robustness across decoding strategies, choice of hedgers, and other forms of
uncertainty expression (i.e. numerical). These findings establish FUT as a
simple and effective way to teach LLMs to communicate uncertainty faithfully.

</details>


### [140] [StyleDecipher: Robust and Explainable Detection of LLM-Generated Texts with Stylistic Analysis](https://arxiv.org/abs/2510.12608)
*Siyuan Li,Aodu Wulianghai,Xi Lin,Guangyan Li,Xiang Chen,Jun Wu,Jianhua Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为StyleDecipher的检测框架，通过量化风格差异，实现对大语言模型（LLM）生成文本与真人文本的准确区分，克服了现有方法泛化性弱、易被改写和缺乏解释性的难题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在开放域写作中的应用日益广泛，检测机器生成文本变得极为重要。然而，现有方法常依赖统计特征或模型内部信息，对风格变化和混合作者情况敏感，泛化能力弱，且难以解释检测结果。

Method: 提出StyleDecipher框架，综合离散和连续风格特征（基于语义嵌入），在统一表征空间内量化风格差异，无需访问模型内部或标签数据。通过五大领域（新闻、代码、作文、评论、学术摘要）的实验，测试了检测的准确性和稳健性。

Result: StyleDecipher在所有测试领域都取得了最优的检测准确率，跨领域实验中检测能力比现有方法高出最多36.3%，并对抗了对抗性扰动和混合人机文本，显示出良好的通用性和稳健性。

Conclusion: StyleDecipher能通用、稳健且可解释性强地检测出机器生成文本，适用于多种真实应用场景，推动内容真实性和信任保障的发展。

Abstract: With the increasing integration of large language models (LLMs) into
open-domain writing, detecting machine-generated text has become a critical
task for ensuring content authenticity and trust. Existing approaches rely on
statistical discrepancies or model-specific heuristics to distinguish between
LLM-generated and human-written text. However, these methods struggle in
real-world scenarios due to limited generalization, vulnerability to
paraphrasing, and lack of explainability, particularly when facing stylistic
diversity or hybrid human-AI authorship. In this work, we propose
StyleDecipher, a robust and explainable detection framework that revisits
LLM-generated text detection using combined feature extractors to quantify
stylistic differences. By jointly modeling discrete stylistic indicators and
continuous stylistic representations derived from semantic embeddings,
StyleDecipher captures distinctive style-level divergences between human and
LLM outputs within a unified representation space. This framework enables
accurate, explainable, and domain-agnostic detection without requiring access
to model internals or labeled segments. Extensive experiments across five
diverse domains, including news, code, essays, reviews, and academic abstracts,
demonstrate that StyleDecipher consistently achieves state-of-the-art in-domain
accuracy. Moreover, in cross-domain evaluations, it surpasses existing
baselines by up to 36.30%, while maintaining robustness against adversarial
perturbations and mixed human-AI content. Further qualitative and quantitative
analysis confirms that stylistic signals provide explainable evidence for
distinguishing machine-generated text. Our source code can be accessed at
https://github.com/SiyuanLi00/StyleDecipher.

</details>


### [141] [ACADATA: Parallel Dataset of Academic Data for Machine Translation](https://arxiv.org/abs/2510.12621)
*Iñaki Lacunza,Javier Garcia Gilabert,Francesca De Luca Fornaciari,Javier Aula-Blasco,Aitor Gonzalez-Agirre,Maite Melero,Marta Villegas*

Main category: cs.CL

TL;DR: 本文发布了ACADATA，一个大规模、高质量的学术翻译平行数据集，并证明在此数据集上微调的大型语言模型在学术翻译任务上能显著优于现有专有及开源系统。


<details>
  <summary>Details</summary>
Motivation: 当前学术翻译领域缺乏高质量、覆盖广泛的平行语料，使得相关机器翻译系统难以在该领域取得突破，因此需要专门针对学术场景的大规模数据集。

Method: 作者构建了两个子集：ACAD-TRAIN（96种语言方向，约150万对原文-翻译段落，由作者生成）和ACAD-BENCH（精选的评测集，涵盖12个语言方向，约6000个翻译）。通过使用ACAD-TRAIN微调两个不同规模的LLM，并在ACAD-BENCH与主流系统进行对比测试。

Result: 实验显示，使用ACAD-TRAIN微调后，两个LLM的学术翻译质量d-BLEU分别提升了+6.1和+12.4。同时，在从英文起翻译的通用长文本场景中提升最高可达24.9%。微调后模型在学术翻译领域超越了当前最优的专有及开源模型。

Conclusion: ACADATA数据集和微调模型的发布为学术领域翻译及长文本领域翻译研究提供了重要资源，将推动该方向的进一步研究与进步。

Abstract: We present ACADATA, a high-quality parallel dataset for academic translation,
that consists of two subsets: ACAD-TRAIN, which contains approximately 1.5
million author-generated paragraph pairs across 96 language directions and
ACAD-BENCH, a curated evaluation set of almost 6,000 translations covering 12
directions. To validate its utility, we fine-tune two Large Language Models
(LLMs) on ACAD-TRAIN and benchmark them on ACAD-BENCH against specialized
machine-translation systems, general-purpose, open-weight LLMs, and several
large-scale proprietary models. Experimental results demonstrate that
fine-tuning on ACAD-TRAIN leads to improvements in academic translation quality
by +6.1 and +12.4 d-BLEU points on average for 7B and 2B models respectively,
while also improving long-context translation in a general domain by up to
24.9% when translating out of English. The fine-tuned top-performing model
surpasses the best propietary and open-weight models on academic translation
domain. By releasing ACAD-TRAIN, ACAD-BENCH and the fine-tuned models, we
provide the community with a valuable resource to advance research in academic
domain and long-context translation.

</details>


### [142] [COSTAR-A: A prompting framework for enhancing Large Language Model performance on Point-of-View questions](https://arxiv.org/abs/2510.12637)
*Nzubechukwu C. Ohalete,Kevin B. Gittner,Lauren M. Matheny*

Main category: cs.CL

TL;DR: 本研究提出COSTAR-A新的提示工程框架，通过在原有COSTAR框架基础上增加“Answer”组件，针对小型LLM优化提示效果，并在实验中证实其可提升输出表现，尤其适用于资源受限硬件。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLM）对提示设计高度敏感，优化提示技巧对于高质量输出尤为关键。原有COSTAR框架虽能改善大模型的输出一致性和清晰度，但对小型、本地优化模型支持有限，因此研究者试图提升其在这类模型上的应用表现。

Method: 在原COSTAR提示框架（Context, Objective, Style, Tone, Audience, Response）基础上，新增“Answer”组件，构成COSTAR-A。通过一系列严格的提示-输出实验，对比小型（最多8B参数）、经微调的LLM在不同提示下的表现，并重点观察输出的结构性和果断性。

Result: 实验发现，COSTAR-A可在特定任务中提升本地小型LLM输出的结构性和决断性，尽管其效果会因具体模型与使用场景有所不同。其中，Llama 3.1-8B在COSTAR-A下比用COSTAR单独提示时表现更佳。

Conclusion: COSTAR-A展现出良好的灵活性与可扩展性，尤其适合部署于计算资源受限的场合，为本地化、小型LLM提供了高效的提示工程框架。

Abstract: Large Language Models (LLMs) are highly sensitive to prompt design, and
making optimized prompting techniques is crucial for generating consistent,
high-quality outputs. In this study, we introduce COSTAR-A, a novel prompt
engineering framework that enhances the existing COSTAR method, which stands
for Context, Objective, Style, Tone, Audience, and Response, by adding the
'Answer' component at the end. We demonstrate that while the original COSTAR
framework improves prompt clarity and aligns outputs for larger LLMs, its
performance is less consistent with smaller, locally optimized models,
particularly in tasks that require more directive or constrained outputs.
Through a series of controlled prompt-output assessments with smaller (at most
8 billion parameters), fine-tuned models, we found that COSTAR-A can enhance
the output structure and decisiveness of localized LLMs for certain tasks,
although its effectiveness varies across models and use cases. Notably, the
Llama 3.1-8B model exhibited performance improvements when prompted with
COSTAR-A compared to COSTAR alone. These findings emphasize the adaptability
and scalability of COSTAR-A as a prompting framework, particularly in
computationally efficient AI deployments on resource-constrained hardware.

</details>


### [143] [Reasoning Pattern Matters: Learning to Reason without Human Rationales](https://arxiv.org/abs/2510.12643)
*Chaoxu Pang,Yixuan Cao,Ping Luo*

Main category: cs.CL

TL;DR: 该论文提出了一种取代高额人工标注推理过程（rationale）的方法，通过让大模型自举生成符合任务模式的推理过程，实现与传统大规模人工标注相当的推理能力。


<details>
  <summary>Details</summary>
Motivation: 目前SFT+RLVR范式下的大模型推理表现出色，但SFT阶段需要大量高质量人工推理过程标注，成本极高，因此需要寻找降低标注成本又不损失模型推理能力的新方法。

Method: 作者针对“模式化推理任务”——即推理过程有统一模式、各实例只在内容上不同的任务，提出以任务推理模式为基础，让大模型自动生成适配该模式的推理过程（PARO方法），大量减少对人工标注的依赖。论文通过数字语义匹配等任务，提供因果与行为证据，验证推理模式才是SFT+RLVR性能的核心，而不是推理解说的数量或质量。

Result: PARO方法生成的推理解说达到与10倍规模的真人推理解说同样的SFT+RLVR推理性能。实验证明，对于有规律推理结构的任务，自动标注可以媲美人工大规模标注。

Conclusion: 只需对推理模式做有限人类监督，即可用大模型自动生成高质量推理解说，显著降低人工标注成本。这一方法可替代人工大规模推理标注，为高效训练推理模型提供新途径。

Abstract: Large Language Models (LLMs) have demonstrated remarkable reasoning
capabilities under the widely adopted SFT+RLVR paradigm, which first performs
Supervised Fine-Tuning (SFT) on human-annotated reasoning trajectories
(rationales) to establish initial reasoning behaviors, then applies
Reinforcement Learning with Verifiable Rewards (RLVR) to optimize the model
using verifiable signals without golden rationales. However, annotating
high-quality rationales for the SFT stage remains prohibitively expensive. This
paper investigates when and how rationale annotation costs can be substantially
reduced without compromising reasoning performance. We identify a broad class
of problems, termed patterned reasoning tasks, where reasoning follows a fixed,
procedural strategy consistent across instances. Although instances vary in
content such as domain knowledge, factual information, or numeric values, the
solution derives from applying a shared reasoning pattern. We argue that the
success of SFT+RLVR on such tasks primarily stems from its ability to enable
models to internalize these reasoning patterns. Using numerical semantic
matching as a representative task, we provide both causal and behavioral
evidence showing that reasoning patterns rather than the quantity or quality of
rationales are the key determinant of performance. Building on these insights,
we propose Pattern-Aware LLMs as Rationale AnnOtators (PARO), a simple yet
effective framework that enables LLMs to generate rationales aligned with
task-specific reasoning patterns without requiring human rationale annotations.
Experiments show that PARO-generated rationales achieve comparable SFT+RLVR
performance to human rationales that are 10 times larger. These results suggest
that large-scale human rationale annotations can be replaced with LLM-based
automatic annotations requiring only limited human supervision over reasoning
patterns.

</details>


### [144] [Generation Space Size: Understanding and Calibrating Open-Endedness of LLM Generations](https://arxiv.org/abs/2510.12699)
*Sunny Yu,Ahmad Jabbar,Robert Hawkins,Dan Jurafsky,Myra Cheng*

Main category: cs.CL

TL;DR: 本文提出了生成空间规模（GSS）的概念，并通过GSSBench基准数据集评估不同LLM在生成多样性和正确性上的表现。研究发现现有模型在创意任务中输出过于统一，在事实任务中则出现多样且错误答案。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）在面对要求输出多样性的任务时，往往在创意任务中过于保守、同质化，而在事实性任务中则会出现多样但不正确的回答。这暴露出模型的生成空间配置失衡，亟需有方法理解和调整。

Method: 作者提出了生成空间规模（GSS）的新概念，用以度量模型在单一prompt下考虑的语义上不同的输出数量，并构建GSSBench任务集来评估和分析不同模型和指标。同时，论文检验了不同度量GSS的方法，包括常规多样性、不确定性度量与基于模型内部状态的指标（如EigenScore）。

Result: 实验表明，基于模型内部的幻觉检测指标（如EigenScore）在GSS评估中优于传统多样性与不确定性度量，且能提供对模型任务内部表示的可解释性。通过GSSBench，论文还演示了三方面应用：检测prompt歧义和预测澄清问题、分析推理模型的过度/不足思考，以及引导模型扩大生成空间，提升输出的质量与多样性。

Conclusion: GSS作为统一理解LLM多样性、幻觉和输出质量的新视角，既能指导更准确的评测，也能助力改进模型行为。相关指标如EigenScore为分析和调优生成空间提供了实用工具。

Abstract: Different open-ended generation tasks require different degrees of output
diversity. However, current LLMs are often miscalibrated. They collapse to
overly homogeneous outputs for creative tasks and hallucinate diverse but
incorrect responses for factual tasks. We argue that these two failure modes
are unified by, and can both be addressed by, the notion of effective
generation space size (GSS) -- the set of semantically distinct outputs a model
considers for a prompt. We present GSSBench, a task suite of prompt pairs with
ground-truth GSS relationships to assess different metrics and understand where
models diverge from desired behavior. We find that hallucination detection
metrics, particularly EigenScore, consistently outperform standard diversity
and uncertainty quantification metrics, while using only model internals,
providing interpretable insights into a model's internal task representations.
We demonstrate three applications of GSS: (1) detecting prompt ambiguity and
predicting clarification questions for better grounding, (2) interpreting
overthinking and underthinking in reasoning models, and (3) steering models to
expand their generation space to yield high-quality and diverse outputs.

</details>


### [145] [Omni-Captioner: Data Pipeline, Models, and Benchmark for Omni Detailed Perception](https://arxiv.org/abs/2510.12720)
*Ziyang Ma,Ruiyang Xu,Zhenghao Xing,Yunfei Chu,Yuxuan Wang,Jinzheng He,Jin Xu,Pheng-Ann Heng,Kai Yu,Junyang Lin,Eng Siong Chng,Xie Chen*

Main category: cs.CL

TL;DR: 本论文系统研究了全模态语言模型（OLMs）在多模态细粒度感知中的能力，并提出了Omni-Detective数据生成流水线及新的评测方法Omni-Cloze，推动模型在详细感知和低幻觉性方面取得新进展。


<details>
  <summary>Details</summary>
Motivation: 当前全模态语言模型（OLMs）虽然可并行处理音视频信号，但其细节感知与描述能力不足且缺乏系统评估。如何提升细粒度信息捕获，以及平衡细节和幻觉，是亟需解决的问题。

Method: 提出Omni-Detective数据生成管线，通过工具调用生成高细节、低幻觉的多模态数据。基于此数据训练了Audio-Captioner（针对音频）和Omni-Captioner（针对音视频），并新设Omni-Cloze评测方法系统评估模型能力。

Result: Audio-Captioner在MMAU和MMAR上超过所有开源模型，并与Gemini 2.5 Pro相当；Omni-Captioner在VDC上创下新SOTA，并在video-SALMONN 2测试集上实现最佳细节-幻觉平衡。Omni-Cloze评测表现稳定高效可靠。

Conclusion: Omni-Detective能生成高质量详细多模态描述文本，有效提升模型细粒度感知能力。新评测方法Omni-Cloze在详细感知任务上表现优异，为相关模型开发与评估提供了坚实基础。

Abstract: Fine-grained perception of multimodal information is critical for advancing
human-AI interaction. With recent progress in audio-visual technologies, Omni
Language Models (OLMs), capable of processing audio and video signals in
parallel, have emerged as a promising paradigm for achieving richer
understanding and reasoning. However, their capacity to capture and describe
fine-grained details remains limited explored. In this work, we present a
systematic and comprehensive investigation of omni detailed perception from the
perspectives of the data pipeline, models, and benchmark. We first identify an
inherent "co-growth" between detail and hallucination in current OLMs. To
address this, we propose Omni-Detective, an agentic data generation pipeline
integrating tool-calling, to autonomously produce highly detailed yet minimally
hallucinatory multimodal data. Based on the data generated with Omni-Detective,
we train two captioning models: Audio-Captioner for audio-only detailed
perception, and Omni-Captioner for audio-visual detailed perception. Under the
cascade evaluation protocol, Audio-Captioner achieves the best performance on
MMAU and MMAR among all open-source models, surpassing Gemini 2.5 Flash and
delivering performance comparable to Gemini 2.5 Pro. On existing detailed
captioning benchmarks, Omni-Captioner sets a new state-of-the-art on VDC and
achieves the best trade-off between detail and hallucination on the
video-SALMONN 2 testset. Given the absence of a dedicated benchmark for omni
detailed perception, we design Omni-Cloze, a novel cloze-style evaluation for
detailed audio, visual, and audio-visual captioning that ensures stable,
efficient, and reliable assessment. Experimental results and analysis
demonstrate the effectiveness of Omni-Detective in generating high-quality
detailed captions, as well as the superiority of Omni-Cloze in evaluating such
detailed captions.

</details>


### [146] [Which Word Orders Facilitate Length Generalization in LMs? An Investigation with GCG-Based Artificial Languages](https://arxiv.org/abs/2510.12722)
*Nadine El-Naggar,Tatsuki Kuribayashi,Ted Briscoe*

Main category: cs.CL

TL;DR: 本文研究了语言模型（LMs）在处理人工语言（ALs）时，是否更容易泛化语言中典型/频繁的语法结构。作者采用了更自然、更复杂的人工语言，并考查了LM对长句未见结构的泛化能力。结果支持：拥有更常见语序的结构，更容易被语言模型泛化。


<details>
  <summary>Details</summary>
Motivation: 此前的研究表明，LMs 可能会对自然语言常见的语法结构表现出更强的归纳偏好，但多基于简单、上下文无关的人工语言。作者希望扩展这一研究视角，使之涵盖更自然语言现象，检验LMs在更复杂、贴近自然语言的构造上的泛化能力。

Method: 本研究采用了基于广义范畴语法（GCG）的人工语言，这种形式能模拟像无界依存、轻度上下文相关等以前未涵盖的自然语言结构。此外，作者关注于测试LM在未见、更长的句子上的泛化表现，以此评估LM对典型与非典型语序的泛化能力。

Result: 实验发现，对于语序上符合语言类型学规律（即更常见、更自然的语序）的结构，LM在未见数据上有更好的泛化能力。

Conclusion: 更贴近自然语言特点的人工语言和更关注泛化性的实验方法显示，LMs更容易泛化自然语言中常见、可证实的语序结构。这为语言模型的归纳偏好及提升模型泛化能力的后续研究提供了依据。

Abstract: Whether language models (LMs) have inductive biases that favor typologically
frequent grammatical properties over rare, implausible ones has been
investigated, typically using artificial languages (ALs) (White and Cotterell,
2021; Kuribayashi et al., 2024). In this paper, we extend these works from two
perspectives. First, we extend their context-free AL formalization by adopting
Generalized Categorial Grammar (GCG) (Wood, 2014), which allows ALs to cover
attested but previously overlooked constructions, such as unbounded dependency
and mildly context-sensitive structures. Second, our evaluation focuses more on
the generalization ability of LMs to process unseen longer test sentences.
Thus, our ALs better capture features of natural languages and our experimental
paradigm leads to clearer conclusions -- typologically plausible word orders
tend to be easier for LMs to productively generalize.

</details>


### [147] [Hey, wait a minute: on at-issue sensitivity in Language Models](https://arxiv.org/abs/2510.12740)
*Sanghee J. Kim,Kanishka Misra*

Main category: cs.CL

TL;DR: 本文提出了一种新的评估语言模型对话自然性的方法DGRC，并通过实验分析语言模型在对话“核心内容”上的生成倾向。


<details>
  <summary>Details</summary>
Motivation: 现有对话自然性的衡量缺乏统一标准和可扩展的量化指标。文章希望找到一种新的、系统性的方式来评估和分析语言模型在实际对话场景中的表现。

Method: 提出了Divide, Generate, Recombine, and Compare（DGRC）方法：首先将对话分段作为提示，然后用语言模型分别扩展各部分，最后重组并比较这些重组后的对话的生成概率。该方法能系统地检测模型对于不同对话线索（如核心内容）的敏感度，降低分析偏差。

Result: 通过DGRC发现，语言模型在对话生成时倾向继续“核心内容”（at-issue content），且在经过指令微调（instruct-tuning）后，这种倾向更显著。当出现提示打断（如“Hey, wait a minute”）时，这种偏好减弱；但指令微调并不会进一步增强这种调节。

Conclusion: DGRC为评估语言模型对话自然性提供了一种新方法，揭示了模型在对话中对核心内容的动态偏好，这反映出成功对话互动的特征，对今后的对话系统研究具有启发意义。

Abstract: Evaluating the naturalness of dialogue in language models (LMs) is not
trivial: notions of 'naturalness' vary, and scalable quantitative metrics
remain limited. This study leverages the linguistic notion of 'at-issueness' to
assess dialogue naturalness and introduces a new method: Divide, Generate,
Recombine, and Compare (DGRC). DGRC (i) divides a dialogue as a prompt, (ii)
generates continuations for subparts using LMs, (iii) recombines the dialogue
and continuations, and (iv) compares the likelihoods of the recombined
sequences. This approach mitigates bias in linguistic analyses of LMs and
enables systematic testing of discourse-sensitive behavior. Applying DGRC, we
find that LMs prefer to continue dialogue on at-issue content, with this effect
enhanced in instruct-tuned models. They also reduce their at-issue preference
when relevant cues (e.g., "Hey, wait a minute") are present. Although
instruct-tuning does not further amplify this modulation, the pattern reflects
a hallmark of successful dialogue dynamics.

</details>


### [148] [Language Models Model Language](https://arxiv.org/abs/2510.12766)
*Łukasz Borchmann*

Main category: cs.CL

TL;DR: 本文批判了以索绪尔和乔姆斯基为代表的传统语言学理论对大语言模型（LLM）的质疑，转而提出采用Mańczak 的经验主义框架，将语言视为实际使用的话语总和，强调语言元素的使用频率在语言机制中的核心作用。作者据此重新评价LLM语言建模的合理性，并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: 当前学界关于LLM能否合法地建模语言存在激烈争论，许多批评者坚持传统语言理论（如“深层结构”、“概念植根”）要求，对LLM的有效性持高度怀疑态度。本文试图突破这些理论局限，寻找新的视角解释和推进LLM的语言建模能力。

Method: 作者采用Mańczak 的语言学经验主义框架，将语言定义为所有言说和书写内容的集合，重点关注使用频率原则。基于该框架，系统性地分析了以往对LLM的主要批评，并提出了对LLM设计、评估与解释的新建议。

Result: 以Mańczak 经验主义原则为基础，作者反驳了以深层结构或理念化语言能力为标准的批评，认为频率规律与实际语料才是建模语言的核心。使用此框架可以为LLM的设计、评价、解释提供更科学、更实证的路径。

Conclusion: 应从Mańczak的经验主义视角出发，重视使用频率对语言机制的主导作用，放弃传统语言学关于“深层结构”或“系统性本体”的要求，这有助于更加科学和建设性地理解与发展LLM语言建模能力。

Abstract: Linguistic commentary on LLMs, heavily influenced by the theoretical
frameworks of de Saussure and Chomsky, is often speculative and unproductive.
Critics challenge whether LLMs can legitimately model language, citing the need
for "deep structure" or "grounding" to achieve an idealized linguistic
"competence." We argue for a radical shift in perspective towards the
empiricist principles of Witold Ma\'nczak, a prominent general and historical
linguist. He defines language not as a "system of signs" or a "computational
system of the brain" but as the totality of all that is said and written. Above
all, he identifies frequency of use of particular language elements as
language's primary governing principle. Using his framework, we challenge prior
critiques of LLMs and provide a constructive guide for designing, evaluating,
and interpreting language models.

</details>


### [149] [Dr.LLM: Dynamic Layer Routing in LLMs](https://arxiv.org/abs/2510.12773)
*Ahmed Heakl,Martin Gubri,Salman Khan,Sangdoo Yun,Seong Joon Oh*

Main category: cs.CL

TL;DR: 本文提出了一种可适配、大幅提升效率且保证准确率的LLM动态路由方法Dr.LLM。


<details>
  <summary>Details</summary>
Motivation: 现有大模型对每个token都经过所有transformer层，在简单任务上浪费算力，复杂任务又可能因层数不够而推理不足。前人的自适应深度方法要么计算代价高、要么需要大规模重训练或改动架构，且提升效率常以牺牲准确率为代价。

Method: Dr.LLM框架为已经训练好的LLM模型每一层配备轻量级路由器，决定跳过、执行或重复该层。训练路由器时使用MCTS搜索获得高质量层配置，并配合windowed pooling、focal loss及瓶颈路由器设计提升鲁棒性和泛化能力。

Result: 在逻辑和数学任务（ARC、DART）上，Dr.LLM平均每个样本节省5层推理，只需很小的准确率提升(+3.4%)，且泛化到多种领域时准确率下降极有限（0.85%以内），比现有路由方法提升最高达7.7%。

Conclusion: Dr.LLM无需修改底层参数即可让现有LLM具备预算感知和准确率驱动的动态推理能力，效果优于以往自适应深度推理方法。

Abstract: Large Language Models (LLMs) process every token through all layers of a
transformer stack, causing wasted computation on simple queries and
insufficient flexibility for harder ones that need deeper reasoning.
Adaptive-depth methods can improve efficiency, but prior approaches rely on
costly inference-time search, architectural changes, or large-scale retraining,
and in practice often degrade accuracy despite efficiency gains. We introduce
Dr.LLM, Dynamic routing of Layers for LLMs, a retrofittable framework that
equips pretrained models with lightweight per-layer routers deciding to skip,
execute, or repeat a block. Routers are trained with explicit supervision:
using Monte Carlo Tree Search (MCTS), we derive high-quality layer
configurations that preserve or improve accuracy under a compute budget. Our
design, windowed pooling for stable routing, focal loss with class balancing,
and bottleneck MLP routers, ensures robustness under class imbalance and long
sequences. On ARC (logic) and DART (math), Dr.LLM improves accuracy by up to
+3.4%p while saving 5 layers per example on average. Routers generalize to
out-of-domain tasks (MMLU, GSM8k, AIME, TruthfulQA, SQuADv2, GPQA, PIQA,
AGIEval) with only 0.85% accuracy drop while retaining efficiency, and
outperform prior routing methods by up to +7.7%p. Overall, Dr.LLM shows that
explicitly supervised routers retrofit frozen LLMs for budget-aware,
accuracy-driven inference without altering base weights.

</details>


### [150] [Cost Analysis of Human-corrected Transcription for Predominately Oral Languages](https://arxiv.org/abs/2510.12781)
*Yacouba Diarra,Nouhoum Souleymane Coulibaly,Michael Leventhal*

Main category: cs.CL

TL;DR: 本文分析了为低资源语言，尤其是低识字率、以口语为主的语言（如巴姆巴拉语），创建高质量语音数据集所需的人力成本和时间。结果显示，在实验室条件下，每小时语音需30小时人工标注，在实地条件下需36小时。


<details>
  <summary>Details</summary>
Motivation: 当前自然语言处理领域日益关注低资源语言，但相关高质量语音数据集构建的真实人力和难度鲜有量化研究。作者希望为这类语言提供开发语音资源的实际参考。

Method: 作者以马里巴姆巴拉语为例，组织10名以该语为母语的转录员，在为期一个月的实地研究中，对53小时语音数据进行ASR转写后的人工校正，并统计了实际所需人力时间。

Result: 实验显示，每小时语音数据的人工准确转写，在实验室环境下平均需30小时人工，在实际田野环境下需36小时人工。还揭示了此类语言资源制作的高昂劳动力成本。

Conclusion: 该研究为低资源、低识字率口语为主语言的数据集创建提供了人力成本基线和操作参考，对同类语言的数据开发具有实际指导意义。

Abstract: Creating speech datasets for low-resource languages is a critical yet poorly
understood challenge, particularly regarding the actual cost in human labor.
This paper investigates the time and complexity required to produce
high-quality annotated speech data for a subset of low-resource languages, low
literacy Predominately Oral Languages, focusing on Bambara, a Manding language
of Mali. Through a one-month field study involving ten transcribers with native
proficiency, we analyze the correction of ASR-generated transcriptions of 53
hours of Bambara voice data. We report that it takes, on average, 30 hours of
human labor to accurately transcribe one hour of speech data under laboratory
conditions and 36 hours under field conditions. The study provides a baseline
and practical insights for a large class of languages with comparable profiles
undertaking the creation of NLP resources.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [151] [Translating Milli/Microrobots with A Value-Centered Readiness Framework](https://arxiv.org/abs/2510.12090)
*Hakan Ceylan,Edoardo Sinibaldi,Sanjay Misra,Pankaj J. Pasricha,Dietmar W. Hutmacher*

Main category: cs.RO

TL;DR: 本文综述了移动型毫微米级机器人（milli/microrobots）在介入医学中的应用前景及其临床转化所面临的主要障碍，并提出了一套技术成熟度评估框架（mTRL），以加速从实验室到临床的转化进程。


<details>
  <summary>Details</summary>
Motivation: 虽然在毫微米级机器人领域取得了许多技术突破，但这些机器人大多仍停留在实验室层面的概念验证，距离实际临床应用还有很大差距。亟需分析阻碍其转化的关键因素，并推动技术朝着满足真正医疗需求的方向发展。

Method: 作者通过回顾当前领域发展，归纳并分析了研究与临床应用之间的脱节，提出了mTRL（milli/microrobot Technology Readiness Level）框架，明确了从概念到临床应用各阶段的里程碑及活动步骤，为该领域的技术成熟度和跨学科合作提供参考。

Result: 文中明确了实验到临床转化受到的主要阻碍，如未对接医疗实际需求、缺乏与当前临床流程的兼容等。mTRL框架被提出用于评估技术成熟度与发展进度，为科研人员和医生提供共同的沟通平台和操作指引。

Conclusion: 未来毫微米级机器人能否广泛应用于临床，关键在于技术发展是否与实际医疗需求相对接、技术本身的可行性及与临床流程的融合。mTRL框架有望加速该领域创新成果的应用，最终实现更安全、更高效的医疗干预。

Abstract: Untethered mobile milli/microrobots hold transformative potential for
interventional medicine by enabling more precise and entirely non-invasive
diagnosis and therapy. Realizing this promise requires bridging the gap between
groundbreaking laboratory demonstrations and successful clinical integration.
Despite remarkable technical progress over the past two decades, most
millirobots and microrobots remain confined to laboratory proof-of-concept
demonstrations, with limited real-world feasibility. In this Review, we
identify key factors that slow translation from bench to bedside, focusing on
the disconnect between technical innovation and real-world application. We
argue that the long-term impact and sustainability of the field depend on
aligning development with unmet medical needs, ensuring applied feasibility,
and integrating seamlessly into existing clinical workflows, which are
essential pillars for delivering meaningful patient outcomes. To support this
shift, we introduce a strategic milli/microrobot Technology Readiness Level
framework (mTRL), which maps system development from initial conceptualization
to clinical adoption through clearly defined milestones and their associated
stepwise activities. The mTRL model provides a structured gauge of
technological maturity, a common language for cross-disciplinary collaboration
and actionable guidance to accelerate translational development toward new,
safer and more efficient interventions.

</details>


### [152] [Gaussian Semantic Field for One-shot LiDAR Global Localization](https://arxiv.org/abs/2510.12101)
*Pengyu Yin,Shenghai Yuan,Haozhi Cao,Xingyu Ji,Ruofei Bai,Siyu Chen,Lihua Xie*

Main category: cs.RO

TL;DR: 该论文提出了一种基于轻量级三层场景图的单次激光雷达（LiDAR）全局定位算法Outram-GSF，实现了语义消歧能力，且在公开数据集上优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有基于地标和语义注册的方法虽然全局定位效果好，但常因地标重复性而导致匹配歧义，影响精准定位。为解决这一问题，亟需更加细粒度和精确的地理语义信息表达手段。

Method: 作者构建了三层3D场景图，其中引入由高斯过程群体学习的连续语义分布函数作为中间层，有别于传统的离散语义标签，从而细致描述地理语义，与对象层和度量-语义层结合提升匹配与定位性能。

Result: 在公开数据集上，作者的方法在全局定位精度和鲁棒性上均超过现有最先进的基准，验证了提出方法的有效性。

Conclusion: 通过引入连续的语义场和三层场景图结构，实现了轻量且性能优良的单次激光雷达全局定位方案，为语义消歧与高效定位提供了新思路。

Abstract: We present a one-shot LiDAR global localization algorithm featuring semantic
disambiguation ability based on a lightweight tri-layered scene graph. While
landmark semantic registration-based methods have shown promising performance
improvements in global localization compared with geometric-only methods,
landmarks can be repetitive and misleading for correspondence establishment. We
propose to mitigate this problem by modeling semantic distributions with
continuous functions learned from a population of Gaussian processes. Compared
with discrete semantic labels, the continuous functions capture finer-grained
geo-semantic information and also provide more detailed metric information for
correspondence establishment. We insert this continuous function as the middle
layer between the object layer and the metric-semantic layer, forming a
tri-layered 3D scene graph, serving as a light-weight yet performant backend
for one-shot localization. We term our global localization pipeline Outram-GSF
(Gaussian semantic field) and conduct a wide range of experiments on publicly
available data sets, validating the superior performance against the current
state-of-the-art.

</details>


### [153] [Hybrid Terrain-Aware Path Planning: Integrating VD--RRT\(^{*}\) Exploration and VD--D\(^{*}\) Lite Repair](https://arxiv.org/abs/2510.12169)
*Akshay Naik,William R. Norris,Dustin Nottage,Ahmet Soylemezoglu*

Main category: cs.RO

TL;DR: 该论文提出了一种结合地形属性与车辆动力学的实时路径规划方法，实现了无人地面车辆在非结构化越野环境下的自主导航。


<details>
  <summary>Details</summary>
Motivation: 无人地面车辆在越野环境下行驶时，需要实时考虑地形的土壤强度、坡度等因素，以规划可行且安全的路径。但现有方法在处理复杂地形和真实感知噪声时，常面临效率低和鲁棒性差的问题，因此需要一个兼顾动力学约束与地形适应性的高效路径规划框架。

Method: 提出了一种连续状态-代价度量标准，将Bekker压力-沉陷模型与海拔坡度和姿态惩罚相结合，生成有界、单调且解析的地形代价值场。该代价场用于格点上，采用精确的转向轨迹原语（Dubins/Reeds-Shepp曲线和带时间参数的自行车模型弧线）实现状态扩展。全局用RRT*探索，局部则用D* Lite算法实时修复，实现了无需启发式平滑的毫秒级重规划。该方法将地形-车辆模型与路径规划器分离，提升了通用性和复用性。

Result: 新方法通过硬件实车测试，在软土和坡度过渡等复杂越野环境下实现了实时导航。实验结果显示，该框架在有感知噪声的情况下依然保证了路径规划的稳定性和可行性。

Conclusion: 文中方法能有效提升无人地面车辆在非结构化越野环境下的自主导航能力，兼容多种规划器，并具有良好的实时性和鲁棒性，为复杂地形下的实时路径规划提供了通用基础。

Abstract: Autonomous ground vehicles operating off-road must plan curvature-feasible
paths while accounting for spatially varying soil strength and slope hazards in
real time. We present a continuous state--cost metric that combines a Bekker
pressure--sinkage model with elevation-derived slope and attitude penalties.
The resulting terrain cost field is analytic, bounded, and monotonic in soil
modulus and slope, ensuring well-posed discretization and stable updates under
sensor noise. This metric is evaluated on a lattice with exact steering
primitives: Dubins and Reeds--Shepp motions for differential drive and
time-parameterized bicycle arcs for Ackermann steering. Global exploration is
performed using Vehicle-Dynamics RRT\(^{*}\), while local repair is managed by
Vehicle-Dynamics D\(^{*}\) Lite, enabling millisecond-scale replanning without
heuristic smoothing. By separating the terrain--vehicle model from the planner,
the framework provides a reusable basis for deterministic, sampling-based, or
learning-driven planning in deformable terrain. Hardware trials on an off-road
platform demonstrate real-time navigation across soft soil and slope
transitions, supporting reliable autonomy in unstructured environments.

</details>


### [154] [Controllable Collision Scenario Generation via Collision Pattern Prediction](https://arxiv.org/abs/2510.12206)
*Pin-Lun Chen,Chi-Hsi Kung,Che-Han Chang,Wei-Chen Chiu,Yi-Ting Chen*

Main category: cs.RO

TL;DR: 本文提出了一种可控的碰撞场景生成任务，利用COLLIDE数据集和新模型，实现用户指定碰撞类型和事故发生时间的自动生成，并提升自动驾驶系统测试的有效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶安全评估需要各种罕见而危险的碰撞场景，真实收集成本高且不安全。因此，研究者希望在仿真中精确生成多样且可控的事故场景，以提升自动驾驶车辆的安全测试。

Method: (1) 定义可控碰撞场景生成的新任务，允许用户设定碰撞类型和事故发生时间。 (2) 构建COLLIDE大规模碰撞数据集，将真实驾驶日志转化为五种碰撞类型、不同TTA（事故前时间）分布的场景。 (3) 提出预测'碰撞模式'的框架，通过捕捉事故瞬间车辆空间关系，生成对抗性轨迹。 (4) 通过实验对比，评估场景生成的准确性和可控性。

Result: 所提方法在碰撞发生率和可控性方面优于主流基线。生成的场景更易导致现有自动驾驶系统失效，有效暴露系统缺陷。用这些场景微调后，自动驾驶系统鲁棒性提升。

Conclusion: 该方法为可控碰撞场景生成提供了框架和数据支撑，有助于发现和提升自动驾驶系统在各类事故下的表现，为更安全的自动驾驶部署打下基础。

Abstract: Evaluating the safety of autonomous vehicles (AVs) requires diverse,
safety-critical scenarios, with collisions being especially important yet rare
and unsafe to collect in the real world. Therefore, the community has been
focusing on generating safety-critical scenarios in simulation. However,
controlling attributes such as collision type and time-to-accident (TTA)
remains challenging. We introduce a new task called controllable collision
scenario generation, where the goal is to produce trajectories that realize a
user-specified collision type and TTA, to investigate the feasibility of
automatically generating desired collision scenarios. To support this task, we
present COLLIDE, a large-scale collision scenario dataset constructed by
transforming real-world driving logs into diverse collisions, balanced across
five representative collision types and different TTA intervals. We propose a
framework that predicts Collision Pattern, a compact and interpretable
representation that captures the spatial configuration of the ego and the
adversarial vehicles at impact, before rolling out full adversarial
trajectories. Experiments show that our approach outperforms strong baselines
in both collision rate and controllability. Furthermore, generated scenarios
consistently induce higher planner failure rates, revealing limitations of
existing planners. We demonstrate that these scenarios fine-tune planners for
robustness improvements, contributing to safer AV deployment in different
collision scenarios.

</details>


### [155] [Learning Social Navigation from Positive and Negative Demonstrations and Rule-Based Specifications](https://arxiv.org/abs/2510.12215)
*Chanwoo Kim,Jihwan Yoon,Hyeonseong Kim,Taemoon Jeong,Changwoo Yoo,Seungbeen Lee,Soohwan Byeon,Hoon Chung,Matthew Pan,Jean Oh,Kyungjae Lee,Sungjoon Choi*

Main category: cs.RO

TL;DR: 本文提出一种将数据驱动奖励与基于规则目标结合的移动机器人导航方法，在动态人类环境中实现更高的适应性与安全性。在合成和真实环境实验中，相比基线方法获得更高成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 当前移动机器人在动态人类环境中的导航面临安全性和适应性之间的权衡难题，仅依赖规则或数据驱动方法常常难以兼顾两者。作者认为，将数据驱动的奖励与基于规则的目标相结合可以更好地同时提升导航的安全性和对多样人类行为的适应性。

Method: 作者提出了一种框架：首先通过正负示范学习基于密度的奖励，然后将其与基于规则的避障和达成目标任务结合。利用一种基于采样的前瞻控制器产生既安全又具有适应性的监督动作，再将其蒸馏为适合实时运行并能估计不确定性的紧凑策略网络。

Result: 在合成环境和电梯共乘模拟实验中，该方法在成功率和时间效率上都优于现有基线方法。真实世界与真人参与的实验亦验证了实际部署的可行性。

Conclusion: 数据驱动和规则目标的结合，有效提升了机器人导航在动态人类环境中的安全性和适应性，具备现实场景下的推广和实用前景。

Abstract: Mobile robot navigation in dynamic human environments requires policies that
balance adaptability to diverse behaviors with compliance to safety
constraints. We hypothesize that integrating data-driven rewards with
rule-based objectives enables navigation policies to achieve a more effective
balance of adaptability and safety. To this end, we develop a framework that
learns a density-based reward from positive and negative demonstrations and
augments it with rule-based objectives for obstacle avoidance and goal
reaching. A sampling-based lookahead controller produces supervisory actions
that are both safe and adaptive, which are subsequently distilled into a
compact student policy suitable for real-time operation with uncertainty
estimates. Experiments in synthetic and elevator co-boarding simulations show
consistent gains in success rate and time efficiency over baselines, and
real-world demonstrations with human participants confirm the practicality of
deployment. A video illustrating this work can be found on our project page
https://chanwookim971024.github.io/PioneeR/.

</details>


### [156] [Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model](https://arxiv.org/abs/2510.12276)
*Fuhao Li,Wenxuan Song,Han Zhao,Jingbo Wang,Pengxiang Ding,Donglin Wang,Long Zeng,Haoang Li*

Main category: cs.RO

TL;DR: 本文提出了一种无需显式3D输入即可提升机器人空间感知与行动精度的对齐方法Spatial Forcing（SF），通过将视觉语言模型中间表示与预训练3D模型的几何表示对齐，显著提升了机器人在多种任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 目前大多数视觉-语言-行动模型只用2D数据预训练，缺乏准确空间感知能力，难以精准操作3D物理世界。现有引入3D传感输入和2D图像估算深度的方法都存在硬件、数据和精度等局限。

Method: 提出Spatial Forcing（SF）对齐策略，将VLA模型中间视觉特征与3D基础模型的几何表示对齐，在无需显式3D输入或深度估算器情况下，增强模型的空间理解能力。

Result: 在仿真和真实环境的多种机器人任务中，SF方法取得了当前最佳的VLA表现，超越2D和3D基线模型，并提升训练速度最多3.8倍，数据利用效率更高。

Conclusion: SF通过中间层空间表示对齐，为无需3D输入的VLA带来空间感知重大提升，有望简化硬件需求并广泛应用于各种机器人任务。

Abstract: Vision-language-action (VLA) models have recently shown strong potential in
enabling robots to follow language instructions and execute precise actions.
However, most VLAs are built upon vision-language models pretrained solely on
2D data, which lack accurate spatial awareness and hinder their ability to
operate in the 3D physical world. Existing solutions attempt to incorporate
explicit 3D sensor inputs such as depth maps or point clouds, but these
approaches face challenges due to sensor noise, hardware heterogeneity, and
incomplete depth coverage in existing datasets. Alternative methods that
estimate 3D cues from 2D images also suffer from the limited performance of
depth estimators.We propose Spatial Forcing (SF), a simple yet effective
alignment strategy that implicitly forces VLA models to develop spatial
comprehension capabilities without relying on explicit 3D inputs or depth
estimators. SF aligns intermediate visual embeddings of VLAs with geometric
representations produced by pretrained 3D foundation models. By enforcing
alignment at intermediate layers, SF guides VLAs to encode richer spatial
representations that enhance action precision.Extensive experiments in
simulation and real-world environments demonstrate that SF achieves
state-of-the-art results, surpassing both 2D- and 3D-based VLAs. SF further
accelerates training by up to 3.8x and improves data efficiency across diverse
robotic tasks. Project page is at https://spatial-forcing.github.io/

</details>


### [157] [Shape-Aware Whole-Body Control for Continuum Robots with Application in Endoluminal Surgical Robotics](https://arxiv.org/abs/2510.12332)
*Mohammadreza Kasaei,Mostafa Ghobadi,Mohsen Khadem*

Main category: cs.RO

TL;DR: 提出了一种适用于腔道手术导航的、具备形状感知能力的全身控制框架，用于高精度与安全性的腱驱柔性机器人导航。


<details>
  <summary>Details</summary>
Motivation: 腔道手术（如支气管镜检查）需要机器人安全且精确地穿越复杂解剖结构，而传统仅控制机器人末端的方法易导致壁面接触和组织损伤，难以达到深部目标。

Method: 本方法融合了基于物理的骨架模型与增强神经常微分方程（Augmented Neural ODE）的残差学习，实现高精度形状估计和高效雅可比计算。通过采样式模型预测路径积分（MPPI）控制器，联合优化末端跟踪、骨架服从性和避障能力，支持实时动态目标调整。

Result: 在仿真和真实机器人试验中达到毫米级精度，改善了轨迹追踪、动态避障和形状服从等任务。在支气管镜模型验证中，相较于传统操控与现有方法，减少了壁面接触，提高了适应性和导航准确率。

Conclusion: 该框架显著提升了腔道手术机器人的安全性、可靠性与操作效率，有望推广至其他狭窄且安全要求高的环境中的机器人应用。

Abstract: This paper presents a shape-aware whole-body control framework for
tendon-driven continuum robots with direct application to endoluminal surgical
navigation. Endoluminal procedures, such as bronchoscopy, demand precise and
safe navigation through tortuous, patient-specific anatomy where conventional
tip-only control often leads to wall contact, tissue trauma, or failure to
reach distal targets. To address these challenges, our approach combines a
physics-informed backbone model with residual learning through an Augmented
Neural ODE, enabling accurate shape estimation and efficient Jacobian
computation. A sampling-based Model Predictive Path Integral (MPPI) controller
leverages this representation to jointly optimize tip tracking, backbone
conformance, and obstacle avoidance under actuation constraints. A task manager
further enhances adaptability by allowing real-time adjustment of objectives,
such as wall clearance or direct advancement, during tele-operation. Extensive
simulation studies demonstrate millimeter-level accuracy across diverse
scenarios, including trajectory tracking, dynamic obstacle avoidance, and
shape-constrained reaching. Real-robot experiments on a bronchoscopy phantom
validate the framework, showing improved lumen-following accuracy, reduced wall
contacts, and enhanced adaptability compared to joystick-only navigation and
existing baselines. These results highlight the potential of the proposed
framework to increase safety, reliability, and operator efficiency in minimally
invasive endoluminal surgery, with broader applicability to other confined and
safety-critical environments.

</details>


### [158] [Achieving Meaningful Collaboration: Worker-centered Design of a Physical Human-Robot Collaborative Blending Task](https://arxiv.org/abs/2510.12340)
*Nicky Mol,Luka Peternel,Alessandro Ianniello,Denis Zatyagov,Auke Nachenius,Stephan Balvert,J. Micah Prendergast,Sara Muscolo,Olger Siebinga,Eva Verhoef,Deborah Forster,David A. Abbink*

Main category: cs.RO

TL;DR: 本文提出并展示了一种跨学科的方法，通过整合学术研究与实际经验，探索协作机器人在飞机发动机维修中的应用。


<details>
  <summary>Details</summary>
Motivation: 应对劳动力短缺、人口老龄化和生产需求增加等社会挑战，推动工业中机器人应用不断增长，需要新的、多学科融合的解决方式。

Method: 采用跨学科方法，结合学术、实践和经验知识，重视工人福祉和职业吸引力，在飞机发动机维修与维护中探索协作机器人潜力。

Result: 文章介绍了正在进行的、多方面探索协作机器人在实际工业场景（如飞机引擎维修）中的应用。

Conclusion: 跨学科融合方法有助于更好地推进工业机器人实践，同时关注工人福祉和岗位吸引力，为工业转型提供新思路。

Abstract: The use of robots in industrial settings continues to grow, driven by the
need to address complex societal challenges such as labor shortages, aging
populations, and ever-increasing production demands. In this abstract, we
advocate for (and demonstrate) a transdisciplinary approach when considering
robotics in the workplace. Transdisciplinarity emphasizes the integration of
academic research with pragmatic expertise and embodied experiential knowledge,
that prioritize values such as worker wellbeing and job attractiveness. In the
following, we describe an ongoing multi-pronged effort to explore the potential
of collaborative robots in the context of airplane engine repair and
maintenance operations.

</details>


### [159] [PolygMap: A Perceptive Locomotion Framework for Humanoid Robot Stair Climbing](https://arxiv.org/abs/2510.12346)
*Bingquan Li,Ning Wang,Tianwei Zhang,Zhicheng He,Yucong Wu*

Main category: cs.RO

TL;DR: 本文提出了一种基于多传感器融合的感知-运动规划框架PolyMap，使类人双足机器人能够高效、稳健地自主攀爬台阶。


<details>
  <summary>Details</summary>
Motivation: 当前双足机器人行走技术虽有进展，但多局限于平面环境。为了让机器人能像人一样在未知环境下精确踩在看到的位置（如楼梯），需要解决实时感知与运动规划问题，尤其是对复杂三维结构（如台阶）的识别和适应。

Method: 提出PolyMap框架，使用LiDAR、RGB-D相机和IMU进行多传感器融合，实时构建多边形台阶平面语义地图，通过多边形平面分割和视觉里程计，实现台阶的识别与定位。基于这些分割平面进行足步规划，并在NVIDIA Orin平台上实时输出20-30Hz全身运动规划指令。

Result: 在室内外真实场景下部署测试，结果表明该方法能够高效并稳健地完成类人机器人的上阶任务，具备实际应用价值。

Conclusion: PolyMap框架实现了类人机器人在复杂环境（如楼梯）中的稳定自主行走，为未来机器人类人移动能力的提升提供了坚实支撑。

Abstract: Recently, biped robot walking technology has been significantly developed,
mainly in the context of a bland walking scheme. To emulate human walking,
robots need to step on the positions they see in unknown spaces accurately. In
this paper, we present PolyMap, a perception-based locomotion planning
framework for humanoid robots to climb stairs. Our core idea is to build a
real-time polygonal staircase plane semantic map, followed by a footstep planar
using these polygonal plane segments. These plane segmentation and visual
odometry are done by multi-sensor fusion(LiDAR, RGB-D camera and IMUs). The
proposed framework is deployed on a NVIDIA Orin, which performs 20-30 Hz
whole-body motion planning output. Both indoor and outdoor real-scene
experiments indicate that our method is efficient and robust for humanoid robot
stair climbing.

</details>


### [160] [Pretraining in Actor-Critic Reinforcement Learning for Robot Motion Control](https://arxiv.org/abs/2510.12363)
*Jiale Fan,Andrei Cramariuc,Tifanny Portela,Marco Hutter*

Main category: cs.RO

TL;DR: 本论文提出了一套预训练-微调范式，用于提升机器人运动控制中的强化学习训练效率与表现，通过在RL任务中预训练神经网络模型，然后用已学知识热启动后续任务。实验表明，方法大大提升了采样效率和最终性能。


<details>
  <summary>Details</summary>
Motivation: 现有机器人运动控制的强化学习方法通常每个任务都从头学习，忽视了不同任务间的可迁移性和共享知识，导致效率低下。作者希望借鉴预训练-微调理念，提升RL训练效率。

Method: 首先，设计任务无关的探索数据收集流程，获得多样的机器人动态转换数据；其次，通过监督学习训练Proprioceptive Inverse Dynamics Model（PIDM）；最后，将PIDM的预训练权重加载至RL算法（如PPO）的actor和critic网络，实现热启动。并在七个不同的机器人运动任务上验证该方法。

Result: 相比随机初始化，预训练初始化策略平均提升采样效率40.1%，任务性能提升7.5%。同时提供消融实验和实证分析，探究方法有效性机理。

Conclusion: 通过对共享知识的预训练，能够显著提升机器人强化学习的效率和效果，为机器人运动控制RL提供了通用性的初始化策略。

Abstract: The pretraining-finetuning paradigm has facilitated numerous transformative
advancements in artificial intelligence research in recent years. However, in
the domain of reinforcement learning (RL) for robot motion control, individual
skills are often learned from scratch despite the high likelihood that some
generalizable knowledge is shared across all task-specific policies belonging
to a single robot embodiment. This work aims to define a paradigm for
pretraining neural network models that encapsulate such knowledge and can
subsequently serve as a basis for warm-starting the RL process in classic
actor-critic algorithms, such as Proximal Policy Optimization (PPO). We begin
with a task-agnostic exploration-based data collection algorithm to gather
diverse, dynamic transition data, which is then used to train a Proprioceptive
Inverse Dynamics Model (PIDM) through supervised learning. The pretrained
weights are loaded into both the actor and critic networks to warm-start the
policy optimization of actual tasks. We systematically validated our proposed
method on seven distinct robot motion control tasks, showing significant
benefits to this initialization strategy. Our proposed approach on average
improves sample efficiency by 40.1% and task performance by 7.5%, compared to
random initialization. We further present key ablation studies and empirical
analyses that shed light on the mechanisms behind the effectiveness of our
method.

</details>


### [161] [Controlling Intent Expressiveness in Robot Motion with Diffusion Models](https://arxiv.org/abs/2510.12370)
*Wenli Shi,Clemence Grislain,Olivier Sigaud,Mohamed Chetouani*

Main category: cs.RO

TL;DR: 本文提出了一种新的机器人运动生成方法，可以灵活控制机器人运动在“易懂”到“模糊”之间的表现，使机器人在不同场景下更好地表达或隐匿其意图。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人的路径生成方法虽追求效率，但常常忽视让人类易于理解机器人的目标，而以“可读性”为目标的方法又仅能生成单一最易懂路径，不适应不同交流场景下对意图表达强弱的调节需求。

Method: 提出了基于“信息势场”的建模方法，能为不同轨迹连续赋予可读性分数，并基于此设计了两阶段扩散框架（diffusion framework）：先按照给定可读性水平生成路径，再将路径转换为机器人可执行动作。

Result: 在2D和3D抓取实验中验证，该方法能生成在易懂与模糊间不同表达度、且多样化的动作轨迹，同时性能与现有最优方法相当。

Conclusion: 本工作为机器人运动的意图表达提供了灵活、可调控的新范式，利于满足不同人机交互场景对意图可读性的需求。

Abstract: Legibility of robot motion is critical in human-robot interaction, as it
allows humans to quickly infer a robot's intended goal. Although traditional
trajectory generation methods typically prioritize efficiency, they often fail
to make the robot's intentions clear to humans. Meanwhile, existing approaches
to legible motion usually produce only a single "most legible" trajectory,
overlooking the need to modulate intent expressiveness in different contexts.
In this work, we propose a novel motion generation framework that enables
controllable legibility across the full spectrum, from highly legible to highly
ambiguous motions. We introduce a modeling approach based on an Information
Potential Field to assign continuous legibility scores to trajectories, and
build upon it with a two-stage diffusion framework that first generates paths
at specified legibility levels and then translates them into executable robot
actions. Experiments in both 2D and 3D reaching tasks demonstrate that our
approach produces diverse and controllable motions with varying degrees of
legibility, while achieving performance comparable to SOTA. Code and project
page: https://legibility-modulator.github.io.

</details>


### [162] [Improving Generative Behavior Cloning via Self-Guidance and Adaptive Chunking](https://arxiv.org/abs/2510.12392)
*Junhyuk So,Chiwoong Lee,Shinyoung Lee,Jungseul Ok,Eunhyeok Park*

Main category: cs.RO

TL;DR: 本文提出两项新技术，提升生成式行为克隆（GBC）在机器人多任务学习中的一致性和反应性，实现了更优的任务成功率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散策略的GBC方法虽能取得较好性能，但因采用开环控制，存在动作抽样不稳定与对动态环境响应迟缓的缺点，影响复杂任务表现。

Method: 作者提出两项改进：1）自引导方法，通过利用历史观测提升动作准确性，并隐式鼓励对未来的预判行为；2）自适应分段方法，在保持时序一致性的同时，根据需要动态局部更新动作序列，提高机器人对环境变化的反应能力。

Result: 大量仿真与实际机器人操作实验表明，所提方法有效提升了GBC在多任务环境下的表现和鲁棒性。

Conclusion: 这些新技术显著加强了GBC的实际应用潜力，提供了更稳定和灵活的机器人操作方案，对后续多任务学习和复杂环境适应具有指导意义。

Abstract: Generative Behavior Cloning (GBC) is a simple yet effective framework for
robot learning, particularly in multi-task settings. Recent GBC methods often
employ diffusion policies with open-loop (OL) control, where actions are
generated via a diffusion process and executed in multi-step chunks without
replanning. While this approach has demonstrated strong success rates and
generalization, its inherent stochasticity can result in erroneous action
sampling, occasionally leading to unexpected task failures. Moreover, OL
control suffers from delayed responses, which can degrade performance in noisy
or dynamic environments. To address these limitations, we propose two novel
techniques to enhance the consistency and reactivity of diffusion policies: (1)
self-guidance, which improves action fidelity by leveraging past observations
and implicitly promoting future-aware behavior; and (2) adaptive chunking,
which selectively updates action sequences when the benefits of reactivity
outweigh the need for temporal consistency. Extensive experiments show that our
approach substantially improves GBC performance across a wide range of
simulated and real-world robotic manipulation tasks. Our code is available at
https://github.com/junhyukso/SGAC

</details>


### [163] [Robot Learning: A Tutorial](https://arxiv.org/abs/2510.12403)
*Francesco Capuano,Caroline Pascal,Adil Zouitine,Thomas Wolf,Michel Aractingi*

Main category: cs.RO

TL;DR: 这篇论文介绍了机器人学习领域由传统模型方法向依赖数据的学习范式的转变，并通过教程形式讲解从基础到最新的机器人学习方法。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习的快速发展和大规模机器人数据的涌现，机器人学习正处于关键拐点，推动自动化系统能力的巨大提升。该论文旨在帮助研究者和从业者理解和掌握机器人学习的最新进展。

Method: 论文从强化学习（Reinforcement Learning）、行为克隆（Behavioral Cloning）等基础原则入手，逐步过渡到能处理多任务、多机器人形态的通用语言条件模型，同时结合实践示例（lerobot）进行说明。

Result: 本论文为机器人学习领域提供了一套系统的理论框架和实践工具，并配有可直接使用的代码示例，提升了读者参与和贡献机器人学习领域的能力。

Conclusion: 机器人学习正在经历由模型驱动到数据驱动的重大变革，本文以综述和实践教程的形式，为相关人员提供了入门和进阶的系统指南，促进了该领域发展。

Abstract: Robot learning is at an inflection point, driven by rapid advancements in
machine learning and the growing availability of large-scale robotics data.
This shift from classical, model-based methods to data-driven, learning-based
paradigms is unlocking unprecedented capabilities in autonomous systems. This
tutorial navigates the landscape of modern robot learning, charting a course
from the foundational principles of Reinforcement Learning and Behavioral
Cloning to generalist, language-conditioned models capable of operating across
diverse tasks and even robot embodiments. This work is intended as a guide for
researchers and practitioners, and our goal is to equip the reader with the
conceptual understanding and practical tools necessary to contribute to
developments in robot learning, with ready-to-use examples implemented in
$\texttt{lerobot}$.

</details>


### [164] [M3D-skin: Multi-material 3D-printed Tactile Sensor with Hierarchical Infill Structures for Pressure Sensing](https://arxiv.org/abs/2510.12419)
*Shunnosuke Yoshimura,Kento Kawaharazuka,Kei Okada*

Main category: cs.RO

TL;DR: 本研究提出了一种利用多材料3D打印技术（FDM）易于制造的多功能触觉传感器M3D-skin，并展示了其在机器人和运动监测领域的应用效果。


<details>
  <summary>Details</summary>
Motivation: 目前触觉传感器的制造和集成难度较高，限制了其实际应用的广泛性。作者希望通过简化制造流程和提升传感器多功能性，来扩展触觉传感器的应用场景。

Method: 研究采用多材料FDM 3D打印机，将导电和非导电柔性材料以特定填充结构混合打印，形成具有分层的内在结构。该结构在受压时会发生形变，导致电阻发生变化，从而获得触觉信息。同时探索了结构参数变化对传感器性能的影响，并实现多单元模块化设计。最后进行了多场景应用测试（如足底动作识别、机械手集成和机器人触控操作）。

Result: 实验证明，传感器对结构变化有明显响应，展现出良好的灵敏度和多应用适应性。模块化传感器可用于足底动作测量与机器人操作，并可成功集成到机械手中。

Conclusion: M3D-skin触觉传感器制造简便、适应性强，能够有效获取触觉信息，适用于多种机器人和人机交互场景，具有广阔的实际应用前景。

Abstract: Tactile sensors have a wide range of applications, from utilization in
robotic grippers to human motion measurement. If tactile sensors could be
fabricated and integrated more easily, their applicability would further
expand. In this study, we propose a tactile sensor-M3D-skin-that can be easily
fabricated with high versatility by leveraging the infill patterns of a
multi-material fused deposition modeling (FDM) 3D printer as the sensing
principle. This method employs conductive and non-conductive flexible filaments
to create a hierarchical structure with a specific infill pattern. The flexible
hierarchical structure deforms under pressure, leading to a change in
electrical resistance, enabling the acquisition of tactile information. We
measure the changes in characteristics of the proposed tactile sensor caused by
modifications to the hierarchical structure. Additionally, we demonstrate the
fabrication and use of a multi-tile sensor. Furthermore, as applications, we
implement motion pattern measurement on the sole of a foot, integration with a
robotic hand, and tactile-based robotic operations. Through these experiments,
we validate the effectiveness of the proposed tactile sensor.

</details>


### [165] [A Task-Efficient Reinforcement Learning Task-Motion Planner for Safe Human-Robot Cooperation](https://arxiv.org/abs/2510.12477)
*Gaoyuan Liu,Joris de Winter,Kelly Merckaert,Denis Steckelmacher,Ann Nowe,Bram Vanderborght*

Main category: cs.RO

TL;DR: 本文提出了一种结合强化学习的混合规划框架，用于在人机协作环境下平衡机器人安全与任务效率，经验证能有效减少失败和重规划次数。


<details>
  <summary>Details</summary>
Motivation: 在HRC环境中，机器人安全机制常常降低执行效率，过多的干预和运动重规划会增加系统负担和失败概率。作者希望解决这一安全与效率的矛盾。

Method: 作者提出了一种混合强化学习框架，包含交互式运动规划器和RL任务规划器。RL任务规划器根据运动规划器的反馈选择安全高效的任务序列，运动规划器通过实时检测人类动作保持过程无碰撞。当原路径失效时重新规划路径。

Result: 该框架在协作机器人上经仿真和实际实验验证，并与硬编码方法对比。结果显示：1）能对不确定的人类动作做出反应；2）降低了对失败目标的重复指令次数；3）减少了重新规划请求。

Conclusion: 所提混合框架能在保证机器人安全的同时提高任务效率，在HRC环境下优于传统硬编码方法，具备实际应用价值。

Abstract: In a Human-Robot Cooperation (HRC) environment, safety and efficiency are the
two core properties to evaluate robot performance. However, safety mechanisms
usually hinder task efficiency since human intervention will cause backup
motions and goal failures of the robot. Frequent motion replanning will
increase the computational load and the chance of failure. In this paper, we
present a hybrid Reinforcement Learning (RL) planning framework which is
comprised of an interactive motion planner and a RL task planner. The RL task
planner attempts to choose statistically safe and efficient task sequences
based on the feedback from the motion planner, while the motion planner keeps
the task execution process collision-free by detecting human arm motions and
deploying new paths when the previous path is not valid anymore. Intuitively,
the RL agent will learn to avoid dangerous tasks, while the motion planner
ensures that the chosen tasks are safe. The proposed framework is validated on
the cobot in both simulation and the real world, we compare the planner with
hard-coded task motion planning methods. The results show that our planning
framework can 1) react to uncertain human motions at both joint and task
levels; 2) reduce the times of repeating failed goal commands; 3) reduce the
total number of replanning requests.

</details>


### [166] [Fast Visuomotor Policy for Robotic Manipulation](https://arxiv.org/abs/2510.12483)
*Jingkai Jia,Tong Yang,Xueyao Chen,Chenhuan Liu,Wenqiang Zhang*

Main category: cs.RO

TL;DR: 本论文提出了一种名为Energy Policy的快速且高效的机器人操作策略框架，能够在高频率且计算资源有限的场景下实现高精度、高速度的机器人操作。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作策略难以同时实现高频率操作、多模态动作预测以及低计算开销，尤其在资源受限场景下表现受限。为此，作者针对这些挑战设计了新的策略框架。

Method: 作者引入能量分数（energy score）作为策略学习目标，并设计了高效的energy MLP模型，实现端到端的多模态动作预测，仅需一次前向推理即可生成多模态操作动作，结构简洁高效。

Result: 在仿真和真实机器人操作实验中，Energy Policy与现有最先进方法相比，匹配甚至超越了其性能，同时显著减少了计算开销。在MimicGen基准测试中，以更快的推理速度取得了更优成绩。

Conclusion: Energy Policy为高频率、资源受限环境下的机器人操作提供了新的解决方案，兼具高精度与高效率，有望在实际机器人系统中广泛应用。

Abstract: We present a fast and effective policy framework for robotic manipulation,
named Energy Policy, designed for high-frequency robotic tasks and
resource-constrained systems. Unlike existing robotic policies, Energy Policy
natively predicts multimodal actions in a single forward pass, enabling
high-precision manipulation at high speed. The framework is built upon two core
components. First, we adopt the energy score as the learning objective to
facilitate multimodal action modeling. Second, we introduce an energy MLP to
implement the proposed objective while keeping the architecture simple and
efficient. We conduct comprehensive experiments in both simulated environments
and real-world robotic tasks to evaluate the effectiveness of Energy Policy.
The results show that Energy Policy matches or surpasses the performance of
state-of-the-art manipulation methods while significantly reducing
computational overhead. Notably, on the MimicGen benchmark, Energy Policy
achieves superior performance with at a faster inference compared to existing
approaches.

</details>


### [167] [Automated Behavior Planning for Fruit Tree Pruning via Redundant Robot Manipulators: Addressing the Behavior Planning Challenge](https://arxiv.org/abs/2510.12509)
*Gaoyuan Liu,Bas Boom,Naftali Slob,Yuri Durodié,Ann Nowé,Bram Vanderborght*

Main category: cs.RO

TL;DR: 本论文提出了一种面向果园修剪的多层次全面规划方法，并在真实机器人上进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 果园修剪是一个重要但重复且对技术要求高的农业操作，传统依赖季节性劳动力且耗时耗力。现有机器人修剪主要聚焦于感知问题，忽略了操作臂在复杂枝叶间运动的规划与控制难点，因此亟需在规划尤其是行为规划层面作出突破。

Method: 论文将高维机械臂在复杂修剪环境下的行为规划问题进行了建模，分析了系统冗余，并提出集成感知、建模与整体规划的全面修剪操作流程。通过多层次的规划方案指导机器人末端执行器在复杂碰撞环境中的运动。

Result: 实验表明，采用更加全面的行为规划方法显著提升了机械臂在修剪任务中的性能。相关流程成功在真实机器人平台上实现。

Conclusion: 本成果补充了先前机器人修剪聚焦感知的不足，为后续修剪机器人规划技术的研究和开发提供了理论与方法支持。

Abstract: Pruning is an essential agricultural practice for orchards. Proper pruning
can promote healthier growth and optimize fruit production throughout the
orchard's lifespan. Robot manipulators have been developed as an automated
solution for this repetitive task, which typically requires seasonal labor with
specialized skills. While previous research has primarily focused on the
challenges of perception, the complexities of manipulation are often
overlooked. These challenges involve planning and control in both joint and
Cartesian spaces to guide the end-effector through intricate, obstructive
branches. Our work addresses the behavior planning challenge for a robotic
pruning system, which entails a multi-level planning problem in environments
with complex collisions. In this paper, we formulate the planning problem for a
high-dimensional robotic arm in a pruning scenario, investigate the system's
intrinsic redundancies, and propose a comprehensive pruning workflow that
integrates perception, modeling, and holistic planning. In our experiments, we
demonstrate that more comprehensive planning methods can significantly enhance
the performance of the robotic manipulator. Finally, we implement the proposed
workflow on a real-world robot. As a result, this work complements previous
efforts on robotic pruning and motivates future research and development in
planning for pruning applications.

</details>


### [168] [Two-stream network-driven vision-based tactile sensor for object feature extraction and fusion perception](https://arxiv.org/abs/2510.12528)
*Muxing Huang,Zibin Chen,Weiliang Xu,Zilan Li,Yuanzhi Zhou,Guoyuan Zhou,Wenjing Chen,Xinming Li*

Main category: cs.RO

TL;DR: 本文提出了一种结合二维和三维信息的视觉触觉特征融合策略，可以显著提升机器人对物体属性（如硬度、形状等）的感知与识别准确率。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉的触觉传感方法虽然具有高分辨率，但存在信息冗余且多维信息融合不足，导致识别精度受限，难以满足机器人对物体多属性精准感知的需求。

Method: 作者提出了两路网络策略：一路通过三维重建获取深度信息，另一路通过测量接触力获取硬度信息，两者分别采用CNN提取特征，最后再进行加权融合，以得到更加全面有效的特征表征。

Result: 在不同形状和硬度物体的标准测试中，力预测误差为0.06N（总范围12N），硬度识别准确率达98.0%，形状识别准确率为93.75%；于真实抓取场景下采用融合算法的识别准确率超过98.5%。

Conclusion: 该方法提升了人工触觉系统对对象物理属性的综合感知与认知能力，可推广至具身智能机器人等应用场景。

Abstract: Tactile perception is crucial for embodied intelligent robots to recognize
objects. Vision-based tactile sensors extract object physical attributes
multidimensionally using high spatial resolution; however, this process
generates abundant redundant information. Furthermore, single-dimensional
extraction, lacking effective fusion, fails to fully characterize object
attributes. These challenges hinder the improvement of recognition accuracy. To
address this issue, this study introduces a two-stream network feature
extraction and fusion perception strategy for vision-based tactile systems.
This strategy employs a distributed approach to extract internal and external
object features. It obtains depth map information through three-dimensional
reconstruction while simultaneously acquiring hardness information by measuring
contact force data. After extracting features with a convolutional neural
network (CNN), weighted fusion is applied to create a more informative and
effective feature representation. In standard tests on objects of varying
shapes and hardness, the force prediction error is 0.06 N (within a 12 N
range). Hardness recognition accuracy reaches 98.0%, and shape recognition
accuracy reaches 93.75%. With fusion algorithms, object recognition accuracy in
actual grasping scenarios exceeds 98.5%. Focused on object physical attributes
perception, this method enhances the artificial tactile system ability to
transition from perception to cognition, enabling its use in embodied
perception applications.

</details>


### [169] [Learning Robust Agile Flight Control with Stability Guarantees](https://arxiv.org/abs/2510.12611)
*Lukas Pries,Markus Ryll*

Main category: cs.RO

TL;DR: 本文提出了一种新型神经增强型反馈控制器，用于高速灵巧四旋翼的精准轨迹跟踪，兼具鲁棒性和高效性。


<details>
  <summary>Details</summary>
Motivation: 现有控制方法在面对执行器极限、环境干扰以及实时计算需求时存在局限，难以同时满足高性能和稳定性，因此需要一种能统一多种控制优势的新方法。

Method: 作者设计了一种神经增强型反馈控制器，将传统机械反馈控制与神经网络方法结合，提升了轨迹跟踪精确度并增强了对扰动的鲁棒性。学习过程在仿真中完成，从而无需在实物上反复训练或微调。

Result: 该控制器能够精确跟踪超出执行器可行性的激进轨迹，在强干扰环境下依然表现出优异的稳定性和鲁棒性；计算效率高，可实现高频率实时控制。

Conclusion: 本文控制器集成了多项控制范式优点，既保证了理论上的普适稳定性，又具备出色的实用性，可无缝迁移到真实平台应用。

Abstract: In the evolving landscape of high-speed agile quadrotor flight, achieving
precise trajectory tracking at the platform's operational limits is paramount.
Controllers must handle actuator constraints, exhibit robustness to
disturbances, and remain computationally efficient for safety-critical
applications. In this work, we present a novel neural-augmented feedback
controller for agile flight control. The controller addresses individual
limitations of existing state-of-the-art control paradigms and unifies their
strengths. We demonstrate the controller's capabilities, including the accurate
tracking of highly aggressive trajectories that surpass the feasibility of the
actuators. Notably, the controller provides universal stability guarantees,
enhancing its robustness and tracking performance even in exceedingly
disturbance-prone settings. Its nonlinear feedback structure is highly
efficient enabling fast computation at high update rates. Moreover, the
learning process in simulation is both fast and stable, and the controller's
inherent robustness allows direct deployment to real-world platforms without
the need for training augmentations or fine-tuning.

</details>


### [170] [Designing Tools with Control Confidence](https://arxiv.org/abs/2510.12630)
*Ajith Anil Meera,Abian Torres,Pablo Lanillos*

Main category: cs.RO

TL;DR: 本文提出了一种将“控制信心”引入机器人自主工具设计的优化框架，使设计的工具在环境不确定性下更健壮。实验表明，该方法较仅追求准确性的方案更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前自主工具设计多关注性能最大化，忽略了工具在反复使用和不确定环境下的“信心”与可靠性，因而容易在复杂环境变动时性能波动大。人类史前工具则兼顾准确性与稳定性，因此引入类似“控制信心”的概念有望提高设计工具的实用性和鲁棒性。

Method: 作者提出一个面向具体任务的自主手持工具设计优化框架，在目标函数中引入神经启发式的“控制信心”项。通过CMAES进化优化策略，指导机器人在仿真环境下设计和评估工具。

Result: 实验显示，添加控制信心后的工具，在面对环境不确定性时，表现出更小的性能波动和高鲁棒性。优化策略高效，仅需较少迭代数就能设计出最优工具，同时在鲁棒性与准确性间取得平衡，也优于同类优化方法。

Conclusion: 引入控制信心作为设计目标可显著提升自主工具设计在变动环境下的稳定性，兼顾准确性、鲁棒性且优化效率高，为机器人自主工具开发提供了方向。

Abstract: Prehistoric humans invented stone tools for specialized tasks by not just
maximizing the tool's immediate goal-completion accuracy, but also increasing
their confidence in the tool for later use under similar settings. This factor
contributed to the increased robustness of the tool, i.e., the least
performance deviations under environmental uncertainties. However, the current
autonomous tool design frameworks solely rely on performance optimization,
without considering the agent's confidence in tool use for repeated use. Here,
we take a step towards filling this gap by i) defining an optimization
framework for task-conditioned autonomous hand tool design for robots, where
ii) we introduce a neuro-inspired control confidence term into the optimization
routine that helps the agent to design tools with higher robustness. Through
rigorous simulations using a robotic arm, we show that tools designed with
control confidence as the objective function are more robust to environmental
uncertainties during tool use than a pure accuracy-driven objective. We further
show that adding control confidence to the objective function for tool design
provides a balance between the robustness and goal accuracy of the designed
tools under control perturbations. Finally, we show that our CMAES-based
evolutionary optimization strategy for autonomous tool design outperforms other
state-of-the-art optimizers by designing the optimal tool within the fewest
iterations. Code: https://github.com/ajitham123/Tool_design_control_confidence.

</details>


### [171] [Maximal Adaptation, Minimal Guidance: Permissive Reactive Robot Task Planning with Humans in the Loop](https://arxiv.org/abs/2510.12662)
*Oz Gitelson,Satya Prakash Nayak,Ritam Raha,Anne-Kathrin Schmuck*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的人机逻辑交互框架，实现机器人在协作人类且人类目标未知时，可靠满足时序逻辑任务。系统能自适应利用人类行为协同，同时只在必要时请求人类配合，降低干扰、保障自主性、并确保任务完成。通过真实机器人实验和Overcooked-AI基准验证，方法展现了超越现有方法的丰富协作行为和强理论保证。


<details>
  <summary>Details</summary>
Motivation: 人机协作日益频繁，但当前方法难以在满足复杂时序逻辑任务的同时兼顾人类目标自主性和任务干扰最小化。因此需要新的方法，能够在不完全了解人类目标的情况下实现高效、可靠的人机合作。

Method: 提出了结合“最大自适应”与“最小可调反馈”的人机逻辑交互框架：1）机器人可根据人类实时行为自适应调整策略，主动利用协作机会；2）机器人只在必要时请求人类合作，以保证任务进展。这样，在任务推进和人与机器的自由之间实现平衡。实验以实际机械臂操作与Overcooked-AI场景为例，验证方法效果。

Result: 实验表明，该方法能产生超越传统方法的丰富涌现式协作行为（如高效物品传递等），并且在理论上始终保证机器人任务的完成，即使在人类目标与机器人冲突时亦能保持任务持续推进。

Conclusion: 该方法首次实现在复杂任务与人类自主性权衡下的可靠人机协作，为实际应用中智能机器人协作提供新的理论与实验依据，具备较强推广价值。

Abstract: We present a novel framework for human-robot \emph{logical} interaction that
enables robots to reliably satisfy (infinite horizon) temporal logic tasks
while effectively collaborating with humans who pursue independent and unknown
tasks. The framework combines two key capabilities: (i) \emph{maximal
adaptation} enables the robot to adjust its strategy \emph{online} to exploit
human behavior for cooperation whenever possible, and (ii) \emph{minimal
tunable feedback} enables the robot to request cooperation by the human online
only when necessary to guarantee progress. This balance minimizes human-robot
interference, preserves human autonomy, and ensures persistent robot task
satisfaction even under conflicting human goals. We validate the approach in a
real-world block-manipulation task with a Franka Emika Panda robotic arm and in
the Overcooked-AI benchmark, demonstrating that our method produces rich,
\emph{emergent} cooperative behaviors beyond the reach of existing approaches,
while maintaining strong formal guarantees.

</details>


### [172] [Autonomous Legged Mobile Manipulation for Lunar Surface Operations via Constrained Reinforcement Learning](https://arxiv.org/abs/2510.12684)
*Alvaro Belmonte-Baeza,Miguel Cazorla,Gabriel J. García,Carlos J. Pérez-Del-Pulgar,Jorge Pomares*

Main category: cs.RO

TL;DR: 本论文提出了一套专为月球环境设计的四足移动操作机器人自主控制的强化学习框架，能够在满足安全约束的情况下，实现高精度的运动与操作。


<details>
  <summary>Details</summary>
Motivation: 当前轮式月球探测车在崎岖不平或陡峭地形存在机动性和适应性不足的问题，而建立永久性月球基地需要机器人能在复杂地形中导航和操作，因此亟需更灵活、更安全的机器人平台。

Method: 作者提出了一套约束型强化学习框架，将全身运动和操作能力集成在一起，并明确考虑了碰撞规避、动态稳定性和能效等关键安全约束，以应对月面低重力和不规则地形。

Result: 实验结果表明，该框架能够实现6维任务空间末端执行器的高精度跟踪，平均位置精度为4厘米，姿态精度为8.1度，同时严格遵守软硬安全约束，展现了对月球重力环境的自适应能力。

Conclusion: 本研究将自适应学习与任务关键安全需求相结合，为高级月球自主探索机器人奠定了基础，为未来月球任务中的机器人自主探索与作业提供了技术支撑。

Abstract: Robotics plays a pivotal role in planetary science and exploration, where
autonomous and reliable systems are crucial due to the risks and challenges
inherent to space environments. The establishment of permanent lunar bases
demands robotic platforms capable of navigating and manipulating in the harsh
lunar terrain. While wheeled rovers have been the mainstay for planetary
exploration, their limitations in unstructured and steep terrains motivate the
adoption of legged robots, which offer superior mobility and adaptability. This
paper introduces a constrained reinforcement learning framework designed for
autonomous quadrupedal mobile manipulators operating in lunar environments. The
proposed framework integrates whole-body locomotion and manipulation
capabilities while explicitly addressing critical safety constraints, including
collision avoidance, dynamic stability, and power efficiency, in order to
ensure robust performance under lunar-specific conditions, such as reduced
gravity and irregular terrain. Experimental results demonstrate the framework's
effectiveness in achieving precise 6D task-space end-effector pose tracking,
achieving an average positional accuracy of 4 cm and orientation accuracy of
8.1 degrees. The system consistently respects both soft and hard constraints,
exhibiting adaptive behaviors optimized for lunar gravity conditions. This work
effectively bridges adaptive learning with essential mission-critical safety
requirements, paving the way for advanced autonomous robotic explorers for
future lunar missions.

</details>


### [173] [Reflection-Based Task Adaptation for Self-Improving VLA](https://arxiv.org/abs/2510.12710)
*Baicheng Li,Dong Wu,Zike Yan,Xinchen Liu,Zecui Zeng,Lusong Li,Hongbin Zha*

Main category: cs.RO

TL;DR: 本文提出了一种名为Reflective Self-Adaptation的新框架，可让视觉-语言-动作预训练模型在不依赖人为干预的情况下高效自主适应新任务。该方法通过自我改进机制显著提升了强化学习适应效率。


<details>
  <summary>Details</summary>
Motivation: 虽然预训练的视觉-语言-动作模型在通用机器人领域带来了巨大突破，但它们在快速、高效适应具体新任务时，依然面临效率低下的问题。如何让机器人在新环境中能自主、快速、可靠地学习新任务成为亟需解决的难题。

Method: 提出了双通路自适应架构：一条是基于失败分析的反思型强化学习，利用视觉-语言模型推理能力生成针对性的密集奖励函数，加快策略探索；另一条是基于成功的质量引导型模仿学习，通过识别和模仿高质量成功轨迹，保证策略最终对齐真实任务目标，且配合条件型课程机制加强初期探索。

Result: 在多个复杂操作任务上进行实验，结果显示该框架较当前代表性基线方法具有更快的收敛速度和更高的最终成功率。

Conclusion: 该框架为实现机器人在新环境下的高效、可靠自主适应提供了强有力方法，有望推动通用智能体的实际应用。

Abstract: Pre-trained Vision-Language-Action (VLA) models represent a major leap
towards general-purpose robots, yet efficiently adapting them to novel,
specific tasks in-situ remains a significant hurdle. While reinforcement
learning (RL) is a promising avenue for such adaptation, the process often
suffers from low efficiency, hindering rapid task mastery. We introduce
Reflective Self-Adaptation, a framework for rapid, autonomous task adaptation
without human intervention. Our framework establishes a self-improving loop
where the agent learns from its own experience to enhance both strategy and
execution.
  The core of our framework is a dual-pathway architecture that addresses the
full adaptation lifecycle. First, a Failure-Driven Reflective RL pathway
enables rapid learning by using the VLM's causal reasoning to automatically
synthesize a targeted, dense reward function from failure analysis. This
provides a focused learning signal that significantly accelerates policy
exploration. However, optimizing such proxy rewards introduces a potential risk
of "reward hacking," where the agent masters the reward function but fails the
actual task. To counteract this, our second pathway, Success-Driven
Quality-Guided SFT, grounds the policy in holistic success. It identifies and
selectively imitates high-quality successful trajectories, ensuring the agent
remains aligned with the ultimate task goal. This pathway is strengthened by a
conditional curriculum mechanism to aid initial exploration.
  We conduct experiments in challenging manipulation tasks. The results
demonstrate that our framework achieves faster convergence and higher final
success rates compared to representative baselines. Our work presents a robust
solution for creating self-improving agents that can efficiently and reliably
adapt to new environments.

</details>


### [174] [Residual MPC: Blending Reinforcement Learning with GPU-Parallelized Model Predictive Control](https://arxiv.org/abs/2510.12717)
*Se Hwan Jeon,Ho Jae Lee,Seungwoo Hong,Sangbae Kim*

Main category: cs.RO

TL;DR: 本文提出了一种结合模型预测控制（MPC）与强化学习（RL）的运动控制方法，利用GPU并行残差架构提升控制的解释性、适应性与鲁棒性。结果显示相较于单独的MPC或RL，该方法在多方面取得了更优表现。


<details>
  <summary>Details</summary>
Motivation: MPC虽有良好可解释性和可调性，但在鲁棒性和实时计算上有限；RL虽有强鲁棒性和适应性，但可解释性和泛化性较差，训练难度大。因此，研究动机在于结合两者优势，打造更强大、更实用的运动控制器。

Method: 提出将全身运动学动力学MPC与RL残差策略深度结合，在GPU上并行模拟成千上万个智能体，通过在力矩输出层混合MPC和RL的输出，实现以MPC为先验、RL作微调的控制。

Result: 该方法实现了更高的采样效率、更快的收敛、更高的最终奖励，更广泛的速度控制范围，以及对新步态和复杂地形的零样本适应，均优于独立MPC或RL方法。

Conclusion: MPC与RL输出在力矩级别的深度耦合，能够兼备模型控制的可解释性与约束处理能力，以及RL的灵活性和鲁棒性，为高效、适应性强的运动控制提供了有效解决方案。

Abstract: Model Predictive Control (MPC) provides interpretable, tunable locomotion
controllers grounded in physical models, but its robustness depends on frequent
replanning and is limited by model mismatch and real-time computational
constraints. Reinforcement Learning (RL), by contrast, can produce highly
robust behaviors through stochastic training but often lacks interpretability,
suffers from out-of-distribution failures, and requires intensive reward
engineering. This work presents a GPU-parallelized residual architecture that
tightly integrates MPC and RL by blending their outputs at the torque-control
level. We develop a kinodynamic whole-body MPC formulation evaluated across
thousands of agents in parallel at 100 Hz for RL training. The residual policy
learns to make targeted corrections to the MPC outputs, combining the
interpretability and constraint handling of model-based control with the
adaptability of RL. The model-based control prior acts as a strong bias,
initializing and guiding the policy towards desirable behavior with a simple
set of rewards. Compared to standalone MPC or end-to-end RL, our approach
achieves higher sample efficiency, converges to greater asymptotic rewards,
expands the range of trackable velocity commands, and enables zero-shot
adaptation to unseen gaits and uneven terrain.

</details>


### [175] [T(R,O) Grasp: Efficient Graph Diffusion of Robot-Object Spatial Transformation for Cross-Embodiment Dexterous Grasping](https://arxiv.org/abs/2510.12724)
*Xin Fei,Zhixuan Xu,Huaicong Fang,Tianrui Zhang,Lin Shao*

Main category: cs.RO

TL;DR: 本文提出了T(R,O) Grasp，一种基于扩散模型的灵巧抓取方法，能在多种机器人手和物体之间，高效生成多样且精准的抓取动作，并在运行速度和准确率上明显优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 灵巧抓取是机器人领域的核心难题，由于其状态和动作空间高维，现有方法往往效率低、适应性差，难以普适于多种机器人手和对象。本文旨在解决多手型、多物体高效、泛化的抓取动作生成问题。

Method: 作者提出了T(R,O) Graph，这是一种统一手与物体空间变换和几何特性的图表示方法，并结合图扩散模型和高效逆运动学（inverse kinematics）求解器，同时支持无条件与条件抓取动作生成。

Result: 在多种灵巧机器人手上的大量实验表明，T(R,O) Grasp的平均抓取成功率为94.83%，单次推理速度为0.21秒，每秒可生成41个抓取动作，并显著降低了内存消耗，全面优于当前主流基线方法。

Conclusion: T(R,O) Grasp不仅具有优越的准确率和速度，还具备良好的泛化能力和内存效率，其高推理速度支持闭环控制灵巧操作，为构建通用型灵巧抓取基础模型奠定了基础。

Abstract: Dexterous grasping remains a central challenge in robotics due to the
complexity of its high-dimensional state and action space. We introduce T(R,O)
Grasp, a diffusion-based framework that efficiently generates accurate and
diverse grasps across multiple robotic hands. At its core is the T(R,O) Graph,
a unified representation that models spatial transformations between robotic
hands and objects while encoding their geometric properties. A graph diffusion
model, coupled with an efficient inverse kinematics solver, supports both
unconditioned and conditioned grasp synthesis. Extensive experiments on a
diverse set of dexterous hands show that T(R,O) Grasp achieves average success
rate of 94.83%, inference speed of 0.21s, and throughput of 41 grasps per
second on an NVIDIA A100 40GB GPU, substantially outperforming existing
baselines. In addition, our approach is robust and generalizable across
embodiments while significantly reducing memory consumption. More importantly,
the high inference speed enables closed-loop dexterous manipulation,
underscoring the potential of T(R,O) Grasp to scale into a foundation model for
dexterous grasping.

</details>


### [176] [HYPE: Hybrid Planning with Ego Proposal-Conditioned Predictions](https://arxiv.org/abs/2510.12733)
*Hang Yu,Julian Jordan,Julian Schmidt,Silvan Lindner,Alessandro Canevaro,Wilhelm Stork*

Main category: cs.RO

TL;DR: 提出了一种新颖的混合规划器HYPE，可简化复杂城市环境中自动驾驶车辆的运动规划，并在安全性与适应性方面取得了领先效果。


<details>
  <summary>Details</summary>
Motivation: 传统的自动驾驶运动规划器在复杂城市环境下，需要推理多智能体的双向交互并估算不同驾驶动作的代价。现有方法成本函数设计困难、在复杂场景下难以适应。需要新的规划模型以简化该流程。

Method: 提出HYPE方法，将学习得到的多模态轨迹提案作为启发式先验，结合Monte Carlo Tree Search进行规划细化。同时，使用以自车为条件的场占预测模型来实现双向交互建模，大幅简化了细化过程中的成本函数设计，仅需极简的栅格化代价。

Result: 在nuPlan和DeepUrban等大规模真实数据集上实验，HYPE在安全性和环境适应性等指标上达到了最优或领先性能。

Conclusion: HYPE显著提升了复杂城市环境运动规划的安全性和可解释性，通过更简洁的成本函数实现了对复杂多智能体交互的高效推理。

Abstract: Safe and interpretable motion planning in complex urban environments needs to
reason about bidirectional multi-agent interactions. This reasoning requires to
estimate the costs of potential ego driving maneuvers. Many existing planners
generate initial trajectories with sampling-based methods and refine them by
optimizing on learned predictions of future environment states, which requires
a cost function that encodes the desired vehicle behavior. Designing such a
cost function can be very challenging, especially if a wide range of complex
urban scenarios has to be considered. We propose HYPE: HYbrid Planning with Ego
proposal-conditioned predictions, a planner that integrates multimodal
trajectory proposals from a learned proposal model as heuristic priors into a
Monte Carlo Tree Search (MCTS) refinement. To model bidirectional interactions,
we introduce an ego-conditioned occupancy prediction model, enabling
consistent, scene-aware reasoning. Our design significantly simplifies cost
function design in refinement by considering proposal-driven guidance,
requiring only minimalistic grid-based cost terms. Evaluations on large-scale
real-world benchmarks nuPlan and DeepUrban show that HYPE effectively achieves
state-of-the-art performance, especially in safety and adaptability.

</details>
