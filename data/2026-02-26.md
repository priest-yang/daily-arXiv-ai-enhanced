<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 33]
- [cs.CL](#cs.CL) [Total: 31]
- [cs.RO](#cs.RO) [Total: 12]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [StoryTailor:A Zero-Shot Pipeline for Action-Rich Multi-Subject Visual Narratives](https://arxiv.org/abs/2602.21273)
*Jinghao Hu,Yuhe Zhang,GuoHua Geng,Kang Li,Han Zhang*

Main category: cs.CV

TL;DR: 本文提出StoryTailor方法，实现无需微调即可在单张RTX 4090显卡上，根据长文本、人物参考和区域信息，生成动作丰富且连贯的多帧视觉叙事，兼顾动作忠实度、主体一致性和背景连贯性。


<details>
  <summary>Details</summary>
Motivation: 多帧视觉叙事生成在动作准确度、人物身份保持、背景连续性三者间存在矛盾，现有零样本方法很难兼顾三者，且资源消耗大。作者希望解决这一难题，在资源有限的硬件上实现高质量生成。

Method: StoryTailor整合三大模块：1）高斯中心注意力（GCA）精准聚焦于每个主体并处理区域重叠问题；2）动作增强奇异值重加权（AB-SVR）突出文本中与动作相关的信息；3）选择性遗忘缓存（SFC）存储背景关键信息，遗忘冗余历史，跨帧关联。

Result: StoryTailor在CLIP-T指标上比基线高10-15%，DreamSim指标优于强基线，CLIP-I也处于可接受且有竞争力的水平。推断速度快于FluxKontext。

Conclusion: StoryTailor能在不微调大模型的前提下，生成连贯且表现丰富的视觉故事，兼顾动作、身份和背景三方效果，是硬件受限下的有效解决方案。

Abstract: Generating multi-frame, action-rich visual narratives without fine-tuning faces a threefold tension: action text faithfulness, subject identity fidelity, and cross-frame background continuity. We propose StoryTailor, a zero-shot pipeline that runs on a single RTX 4090 (24 GB) and produces temporally coherent, identity-preserving image sequences from a long narrative prompt, per-subject references, and grounding boxes. Three synergistic modules drive the system: Gaussian-Centered Attention (GCA) to dynamically focus on each subject core and ease grounding-box overlaps; Action-Boost Singular Value Reweighting (AB-SVR) to amplify action-related directions in the text embedding space; and Selective Forgetting Cache (SFC) that retains transferable background cues, forgets nonessential history, and selectively surfaces retained cues to build cross-scene semantic ties. Compared with baseline methods, experiments show that CLIP-T improves by up to 10-15%, with DreamSim lower than strong baselines, while CLIP-I stays in a visually acceptable, competitive range. With matched resolution and steps on a 24 GB GPU, inference is faster than FluxKontext. Qualitatively, StoryTailor delivers expressive interactions and evolving yet stable scenes.

</details>


### [2] [HorizonForge: Driving Scene Editing with Any Trajectories and Any Vehicles](https://arxiv.org/abs/2602.21333)
*Yifan Wang,Francesco Pittaluga,Zaid Tasneem,Chenyu You,Manmohan Chandraker,Ziyu Jiang*

Main category: cs.CV

TL;DR: 本文提出HorizonForge框架，实现高真实感且可控的驾驶场景生成，并通过新设计的评测基准HorizonSuite显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶仿真对高真实感和可控性场景的需求迫切，而现有方法在二者间难以兼顾，限制了仿真的效果和灵活性。

Method: 构建HorizonForge框架，将场景重建为可编辑的Gaussian Splats与Meshes，使3D内容细粒度操作及支持语言驱动车辆插入。同时创新性引入结合时空一致性的视频扩散渲染，能一次前馈高效生成多样化且一致的场景变化，无需逐轨迹优化。此外，建立了HorizonSuite评测体系，标准化各类场景编辑任务。

Result: 实验证明，Gaussian-Mesh表示相比其他3D表达方式提供了更高保真度，视频扩散中的时序先验对连贯合成关键。该方法在用户偏好提升83.4%、FID提高25.19%，显著优于次优SOTA。

Conclusion: HorizonForge为生成真感、可控驾驶仿真场景提供了新范式，兼具高精度编辑和渲染效率，有力推动自动驾驶仿真技术发展。

Abstract: Controllable driving scene generation is critical for realistic and scalable autonomous driving simulation, yet existing approaches struggle to jointly achieve photorealism and precise control. We introduce HorizonForge, a unified framework that reconstructs scenes as editable Gaussian Splats and Meshes, enabling fine-grained 3D manipulation and language-driven vehicle insertion. Edits are rendered through a noise-aware video diffusion process that enforces spatial and temporal consistency, producing diverse scene variations in a single feed-forward pass without per-trajectory optimization. To standardize evaluation, we further propose HorizonSuite, a comprehensive benchmark spanning ego- and agent-level editing tasks such as trajectory modifications and object manipulation. Extensive experiments show that Gaussian-Mesh representation delivers substantially higher fidelity than alternative 3D representations, and that temporal priors from video diffusion are essential for coherent synthesis. Combining these findings, HorizonForge establishes a simple yet powerful paradigm for photorealistic, controllable driving simulation, achieving an 83.4% user-preference gain and a 25.19% FID improvement over the second best state-of-the-art method. Project page: https://horizonforge.github.io/ .

</details>


### [3] [Scaling View Synthesis Transformers](https://arxiv.org/abs/2602.21341)
*Evan Kim,Hyunwoo Ryu,Thomas W. Mitchel,Vincent Sitzmann*

Main category: cs.CV

TL;DR: 本论文研究了无几何信息的视图合成Transformer扩展规律，提出了计算最优的设计方案，并提出了一种新的编码器-解码器结构（SVSM），在效率和性能上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前流行的无几何视图合成Transformer虽然性能优异，但其如何随计算资源扩展的规律尚未明确。因此有必要系统地研究其扩展性，以指导更高效及效果更优的模型设计。

Method: 作者对视图合成Transformer进行了系统的扩展性实验，重点比较了编码器-解码器与仅解码器结构在不同计算预算下的表现，并追溯了先前相关研究未能发现编码器-解码器结构潜力的原因，提出了一种新型可扩展编码器-解码器架构（SVSM）。

Result: 实验表明，作者提出的SVSM编码器-解码器结构在多个计算预算下扩展性良好，其性能-计算效率优于纯解码器模型，并在真实数据集上取得了更高的表现，同时训练计算量大幅降低。

Conclusion: 与以前的看法相反，合适设计的编码器-解码器结构在视图合成任务中可以达到甚至超过解码器结构，且更为高效。论文为NVS Transformer的最优设计和效率提升提供了新视角和方法。

Abstract: Geometry-free view synthesis transformers have recently achieved state-of-the-art performance in Novel View Synthesis (NVS), outperforming traditional approaches that rely on explicit geometry modeling. Yet the factors governing their scaling with compute remain unclear. We present a systematic study of scaling laws for view synthesis transformers and derive design principles for training compute-optimal NVS models. Contrary to prior findings, we show that encoder-decoder architectures can be compute-optimal; we trace earlier negative results to suboptimal architectural choices and comparisons across unequal training compute budgets. Across several compute levels, we demonstrate that our encoder-decoder architecture, which we call the Scalable View Synthesis Model (SVSM), scales as effectively as decoder-only models, achieves a superior performance-compute Pareto frontier, and surpasses the previous state-of-the-art on real-world NVS benchmarks with substantially reduced training compute.

</details>


### [4] [Towards Controllable Video Synthesis of Routine and Rare OR Events](https://arxiv.org/abs/2602.21365)
*Dominik Schneider,Lalithkumar Seenivasan,Sampath Rapuri,Vishalroshan Anil,Aiza Maksutova,Yiqing Shen,Jan Emily Mangulabnan,Hao Ding,Jose L. Porras,Masaru Ishii,Mathias Unberath*

Main category: cs.CV

TL;DR: 本文提出了一种手术室（OR）视频扩散合成框架，实现对罕见及关键安全事件的可控合成，有助于突破相关数据获取瓶颈，支持AI模型开发及验证。


<details>
  <summary>Details</summary>
Motivation: 手术室关键事件的数据稀缺，尤其是罕见或安全相关状况，因其伦理和操作难度导致采集受限，这极大阻碍了智能环境系统的开发和部署。

Method: 构建了包括几何抽象、条件控制以及经过微调的扩散视频生成三大模块的体系，首先将场景转换成抽象的几何表示，再进行条件控制，最后合成真实感手术事件视频，并以此制作合成数据集用于AI训练和验证。

Result: 本方法合成常规OR事件时，优于现有视频扩散方法，在FVD/LPIPS和SSIM/PSNR等指标上实现更佳表现。合成数据训练的AI模型在检测接近安全关键事件时召回率达到70.13%。消融实验验证关键设计的性能提升作用。

Conclusion: 新方案能从抽象几何信息受控生成各类OR事件，助力AI模型开发，不仅可合成稀有安全场景，也促进了手术室智能感知技术的进步。

Abstract: Purpose: Curating large-scale datasets of operating room (OR) workflow, encompassing rare, safety-critical, or atypical events, remains operationally and ethically challenging. This data bottleneck complicates the development of ambient intelligence for detecting, understanding, and mitigating rare or safety-critical events in the OR.
  Methods: This work presents an OR video diffusion framework that enables controlled synthesis of rare and safety-critical events. The framework integrates a geometric abstraction module, a conditioning module, and a fine-tuned diffusion model to first transform OR scenes into abstract geometric representations, then condition the synthesis process, and finally generate realistic OR event videos. Using this framework, we also curate a synthetic dataset to train and validate AI models for detecting near-misses of sterile-field violations.
  Results: In synthesizing routine OR events, our method outperforms off-the-shelf video diffusion baselines, achieving lower FVD/LPIPS and higher SSIM/PSNR in both in- and out-of-domain datasets. Through qualitative results, we illustrate its ability for controlled video synthesis of counterfactual events. An AI model trained and validated on the generated synthetic data achieved a RECALL of 70.13% in detecting near safety-critical events. Finally, we conduct an ablation study to quantify performance gains from key design choices.
  Conclusion: Our solution enables controlled synthesis of routine and rare OR events from abstract geometric representations. Beyond demonstrating its capability to generate rare and safety-critical scenarios, we show its potential to support the development of ambient intelligence models.

</details>


### [5] [Momentum Memory for Knowledge Distillation in Computational Pathology](https://arxiv.org/abs/2602.21395)
*Yongxin Guo,Hao Lu,Onur C. Koyun,Zhengjie Zhu,Muhammet Fatih Demir,Metin Nafi Gurcan*

Main category: cs.CV

TL;DR: 本文提出了一种新的动量记忆知识蒸馏（MoMKD）方法，通过汇总和利用跨批次的组学信息，提升仅用病理图像推理肿瘤信息的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态学习方法由于成对数据短缺，难以临床应用。知识蒸馏能缓解这一难题，但目前方法在小批量对齐上易引发不稳定和性能下降。作者希望突破这一瓶颈。

Method: 作者提出MoMKD框架，创新性地引入动量更新记忆模块，整合跨批次组学与病理信息，扩大监督背景。同时解耦组学和病理分支梯度，防止训练时组学信号过度影响病理特征学习，并消除推理时的模态差异。

Result: 在TCGA-BRCA的HER2、PR、ODX分类任务及独立数据集上，MoMKD显著优于主流的多实例学习和多模态知识蒸馏方法，在仅用病理图像推理情境下显示出更强的泛化性和准确性。

Conclusion: MoMKD为计算病理学提供了一种稳健、可推广的知识蒸馏新范式，有望推动组学与组织病理多模态方法的临床应用。

Abstract: Multimodal learning that integrates genomics and histopathology has shown strong potential in cancer diagnosis, yet its clinical translation is hindered by the limited availability of paired histology-genomics data. Knowledge distillation (KD) offers a practical solution by transferring genomic supervision into histopathology models, enabling accurate inference using histology alone. However, existing KD methods rely on batch-local alignment, which introduces instability due to limited within-batch comparisons and ultimately degrades performance.
  To address these limitations, we propose Momentum Memory Knowledge Distillation (MoMKD), a cross-modal distillation framework driven by a momentum-updated memory. This memory aggregates genomic and histopathology information across batches, effectively enlarging the supervisory context available to each mini-batch. Furthermore, we decouple the gradients of the genomics and histology branches, preventing genomic signals from dominating histology feature learning during training and eliminating the modality-gap issue at inference time.
  Extensive experiments on the TCGA-BRCA benchmark (HER2, PR, and ODX classification tasks) and an independent in-house testing dataset demonstrate that MoMKD consistently outperforms state-of-the-art MIL and multimodal KD baselines, delivering strong performance and generalization under histology-only inference. Overall, MoMKD establishes a robust and generalizable knowledge distillation paradigm for computational pathology.

</details>


### [6] [MMLoP: Multi-Modal Low-Rank Prompting for Efficient Vision-Language Adaptation](https://arxiv.org/abs/2602.21397)
*Sajjad Ghiasvand,Haniyeh Ehsani Oskouie,Mahnoosh Alizadeh,Ramtin Pedarsani*

Main category: cs.CV

TL;DR: 本文提出了一种名为MMLoP的高效多模态低秩提示方法，实现了仅用1.15万可训练参数即可在视觉-语言模型适应下游任务中达到高性能。


<details>
  <summary>Details</summary>
Motivation: 当前主流的视觉-语言模型提示学习通过在各层扩展视觉和文本提示显著提升表现，但参数量暴涨，降低了高效性，违背了提示学习初衷。作者希望既保持高性能，又极大减少参数数量。

Method: MMLoP在每层Transformer中对视觉和文本提示用低秩分解参数化，有效抑制小样本过拟合。此外，方法引入：1）自调一致性损失，将特征锚定在冻结的zero-shot CLIP输出；2）统一漂移修正，消除提示导致的embedding全局漂移；3）共享上投影，强化视觉和文本提示的跨模态对齐。

Result: 在3大基准和11个数据集上，MMLoP在准确率-效率权衡上优于大多数现有方法，且许多方法参数量比其多数个数量级。base-to-novel泛化harmonic mean达79.7%。

Conclusion: MMLoP证明了低参数的深层多模态提示可高效适应下游任务，兼顾了参数高效性和模型性能，推动了视觉-语言模型轻量应用的边界。

Abstract: Prompt learning has become a dominant paradigm for adapting vision-language models (VLMs) such as CLIP to downstream tasks without modifying pretrained weights. While extending prompts to both vision and text encoders across multiple transformer layers significantly boosts performance, it dramatically increases the number of trainable parameters, with state-of-the-art methods requiring millions of parameters and abandoning the parameter efficiency that makes prompt tuning attractive. In this work, we propose \textbf{MMLoP} (\textbf{M}ulti-\textbf{M}odal \textbf{Lo}w-Rank \textbf{P}rompting), a framework that achieves deep multi-modal prompting with only \textbf{11.5K trainable parameters}, comparable to early text-only methods like CoOp. MMLoP parameterizes vision and text prompts at each transformer layer through a low-rank factorization, which serves as an implicit regularizer against overfitting on few-shot training data. To further close the accuracy gap with state-of-the-art methods, we introduce three complementary components: a self-regulating consistency loss that anchors prompted representations to frozen zero-shot CLIP features at both the feature and logit levels, a uniform drift correction that removes the global embedding shift induced by prompt tuning to preserve class-discriminative structure, and a shared up-projection that couples vision and text prompts through a common low-rank factor to enforce cross-modal alignment. Extensive experiments across three benchmarks and 11 diverse datasets demonstrate that MMLoP achieves a highly favorable accuracy-efficiency tradeoff, outperforming the majority of existing methods including those with orders of magnitude more parameters, while achieving a harmonic mean of 79.70\% on base-to-novel generalization.

</details>


### [7] [FlowFixer: Towards Detail-Preserving Subject-Driven Generation](https://arxiv.org/abs/2602.21402)
*Jinyoung Jun,Won-Dong Jang,Wenbin Ouyang,Raghudeep Gadde,Jungbeom Lee*

Main category: cs.CV

TL;DR: 该论文提出了一种名为FlowFixer的新框架，可修复SDG（subject-driven generation）过程中因尺度和视角变化而丢失的图像细节。


<details>
  <summary>Details</summary>
Motivation: 现有的SDG方法易因尺度和视角变化丢失细节，且多依赖语言提示，存在歧义；缺少专门用于细节还原和评估的方法。

Method: FlowFixer直接采用图像到图像的翻译，绕过语言歧义。新引入了一步去噪的数据生成方案，用于自监督训练，模拟细节丢失错误。此外，提出了基于关键点匹配的指标，用于评估细节保真度。

Result: 实验表明FlowFixer在细节修复及定量/定性指标上均超越当前主流方法，在高保真SDG设立新标杆。

Conclusion: FlowFixer通过直接图像映射和新评估指标，极大提高了SDG中的细节还原能力，是高保真生成领域的重要进展。

Abstract: We present FlowFixer, a refinement framework for subject-driven generation (SDG) that restores fine details lost during generation caused by changes in scale and perspective of a subject. FlowFixer proposes direct image-to-image translation from visual references, avoiding ambiguities in language prompts. To enable image-to-image training, we introduce a one-step denoising scheme to generate self-supervised training data, which automatically removes high-frequency details while preserving global structure, effectively simulating real-world SDG errors. We further propose a keypoint matching-based metric to properly assess fidelity in details beyond semantic similarities usually measured by CLIP or DINO. Experimental results demonstrate that FlowFixer outperforms state-of-the-art SDG methods in both qualitative and quantitative evaluations, setting a new benchmark for high-fidelity subject-driven generation.

</details>


### [8] [Exploring Vision-Language Models for Open-Vocabulary Zero-Shot Action Segmentation](https://arxiv.org/abs/2602.21406)
*Asim Unmesh,Kaki Ramesh,Mayank Patel,Rahul Jain,Karthik Ramani*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的新方法，用于开放式词汇零样本时序动作分割（OVTAS），并系统性评估了多种视觉-语言模型（VLM）在该任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的时序动作分割方法受限于封闭式词汇和固定标签集，且由于活动复杂多样，难以构建全面的数据集，因此亟需能够适应开放式标签和新动作的分割方法。

Method: 作者提出基于分段-分类的训练自由流水线：1）利用帧-动作嵌入相似性（FAES），将视频帧与候选动作标签匹配；2）通过相似性矩阵时序分割（SMTS）保证预测序列的时序一致性。此外，作者对14种视觉-语言模型（VLM）在该开放词汇分割问题上的能力进行了系统评估。

Result: 在标准基准数据集上，无需特定任务监督的OVTAS方法表现出色，且不同VLM在开放词汇分割任务上的能力得到了首次全面对比。

Conclusion: 所提方法验证了视觉-语言模型在结构化时序理解上的巨大潜力，为开放式词汇时序分割问题提供了有效解决思路和系统性基准分析。

Abstract: Temporal Action Segmentation (TAS) requires dividing videos into action segments, yet the vast space of activities and alternative breakdowns makes collecting comprehensive datasets infeasible. Existing methods remain limited to closed vocabularies and fixed label sets. In this work, we explore the largely unexplored problem of Open-Vocabulary Zero-Shot Temporal Action Segmentation (OVTAS) by leveraging the strong zero-shot capabilities of Vision-Language Models (VLMs). We introduce a training-free pipeline that follows a segmentation-by-classification design: Frame-Action Embedding Similarity (FAES) matches video frames to candidate action labels, and Similarity-Matrix Temporal Segmentation (SMTS) enforces temporal consistency. Beyond proposing OVTAS, we present a systematic study across 14 diverse VLMs, providing the first broad analysis of their suitability for open-vocabulary action segmentation. Experiments on standard benchmarks show that OVTAS achieves strong results without task-specific supervision, underscoring the potential of VLMs for structured temporal understanding.

</details>


### [9] [WildSVG: Towards Reliable SVG Generation Under Real-Word Conditions](https://arxiv.org/abs/2602.21416)
*Marco Terral,Haotian Zhang,Tianyang Zhang,Meng Lin,Xiaoqing Xie,Haoran Dai,Darsh Kaushik,Pai Peng,Nicklas Scharpff,David Vazquez,Joan Rodriguez*

Main category: cs.CV

TL;DR: 本文提出了SVG抽取任务和全新的WildSVG基准，用于评估从自然图像中提取SVG的能力。现有多模态模型在真实场景下表现较差，新基准有助于推动领域发展。


<details>
  <summary>Details</summary>
Motivation: 目前多模态模型擅长从干净的渲染图或文本描述生成SVG，但面临处理自然图像噪声、杂乱和领域漂移的困难，而且缺乏系统的评估基准。

Method: 作者提出WildSVG基准，包括两部分数据集：1）Natural WildSVG，涵盖真实公司logo图像及其SVG注释；2）Synthetic WildSVG，将复杂SVG嵌入真实场景，模拟复杂条件。通过这些数据，系统性评估模型的SVG抽取能力。

Result: 作者用这些数据集对现有多模态模型进行测试，发现它们在真实场景下的SVG抽取表现远不理想。部分迭代优化方法显示出一定前景，模型能力在逐步提升。

Conclusion: WildSVG基准为SVG抽取任务提供了首个系统评测平台，有助于未来模型在真实场景下获得更有效和可靠的SVG提取能力。

Abstract: We introduce the task of SVG extraction, which consists in translating specific visual inputs from an image into scalable vector graphics. Existing multimodal models achieve strong results when generating SVGs from clean renderings or textual descriptions, but they fall short in real-world scenarios where natural images introduce noise, clutter, and domain shifts. A central challenge in this direction is the lack of suitable benchmarks. To address this need, we introduce the WildSVG Benchmark, formed by two complementary datasets: Natural WildSVG, built from real images containing company logos paired with their SVG annotations, and Synthetic WildSVG, which blends complex SVG renderings into real scenes to simulate difficult conditions. Together, these resources provide the first foundation for systematic benchmarking SVG extraction. We benchmark state-of-the-art multimodal models and find that current approaches perform well below what is needed for reliable SVG extraction in real scenarios. Nonetheless, iterative refinement methods point to a promising path forward, and model capabilities are steadily improving

</details>


### [10] [Synergizing Understanding and Generation with Interleaved Analyzing-Drafting Thinking](https://arxiv.org/abs/2602.21435)
*Shengqiong Wu,Bobo Li,Xinkai Wang,Xiangtai Li,Lei Cui,Furu Wei,Shuicheng Yan,Hao Fei,Tat-seng Chua*

Main category: cs.CV

TL;DR: 本文提出了一种新的视觉-语言任务解题范式——分析-起草循环（AD-Loop），通过交替分析与起草操作，提升理解和生成的协同效能。


<details>
  <summary>Details</summary>
Motivation: 现有统一视觉-语言模型（UVLMs）虽然能处理理解和生成任务，但多将两者视作并行能力，缺乏明确交互，无法实现真正的协同增强。

Method: 提出AD-Loop机制，将分析（理解）与起草（生成）操作交替进行，产生文本和视觉双重思维。训练采用两阶段策略：第一阶段利用具备交错思维的数据进行有监督学习，实现基本交替；第二阶段引入强化学习，促进模型自适应与自主切换。

Result: AD-Loop方法在多个标准基准上提升了UVLMs的理解和生成性能，并表现出高迁移性，能适用于不同架构；视觉分析表明，隐式视觉思维机制有效。

Conclusion: AD-Loop作为一种新颖且原理性强的策略，能够有效促成理解与生成的协同，具有广泛适用性。

Abstract: Unified Vision-Language Models (UVLMs) aim to advance multimodal learning by supporting both understanding and generation within a single framework. However, existing approaches largely focus on architectural unification while overlooking the need for explicit interaction between the two capabilities during task solving. As a result, current models treat understanding and generation as parallel skills rather than synergistic processes. To achieve real synergy, we introduce the interleaved Analyzing-Drafting problem-solving loop (AD-Loop), a new think paradigm that dynamically alternates between analytic and drafting operations. By interleaving textual thoughts with visual thoughts, AD-Loop enables models to iteratively refine both comprehension and outputs, fostering genuine synergy. To train this mechanism, we design a two-stage strategy: supervised learning on interleaved thought data to initialize alternation, followed by reinforcement learning to promote adaptive and autonomous control. Extensive experiments demonstrate that AD-Loop consistently improves performance across standard benchmarks for both understanding and generation, with strong transferability to various UVLMs architectures. Visual analyses further validate the effectiveness of implicit visual thoughts. These results highlight AD-Loop as a principled and broadly applicable strategy for synergizing comprehension and creation. The project page is at https://sqwu.top/AD-Loop.

</details>


### [11] [CADC: Content Adaptive Diffusion-Based Generative Image Compression](https://arxiv.org/abs/2602.21591)
*Xihua Sheng,Lingyu Zhu,Tianyu Zhang,Dong Liu,Shiqi Wang,Jing Wang*

Main category: cs.CV

TL;DR: 本文提出了一种内容自适应的扩散式生成图像压缩方法，通过三项创新技术提高了超低码率下的图像重建效果。


<details>
  <summary>Details</summary>
Motivation: 现有扩散式生成图像压缩方法存在三大问题：1）均匀量化无法根据图像内容变化，导致与扩散模型先验失配；2）高维噪声潜变量和固定解码器输入间的维度不匹配，造成语义信息保留受限；3）文本条件编码策略非自适应，存在码率开销或缺乏针对性，致使语义指导效率低下。

Method: 本方法包括三大创新：1）基于不确定性引导的自适应量化，利用学习得到的不确定性空间图，实现量化失真与图像内容特性的自适应对齐；2）辅助解码器引导的信息集中，通过轻量辅助解码器促进主要潜变量信道的内容相关信息保存；3）免码率的自适应文本条件推理，从辅助重建图像中自动提取内容相关文本描述，无需增加码率开销，为后续解码过程提供高效语义指导。

Result: 提出的方法在内容自适应性、重建质量和码率效率等方面显著优于现有扩散式图像压缩模型，尤其在超低码率重建任务中取得更具现实感和语义完整性的图像输出。

Conclusion: 内容自适应扩散式生成压缩可以实现更高效、更语义丰富的图像重建，并通过三个技术创新解决了以往无法随内容动态调整编码与解码的问题，为超低码率高质量图像压缩奠定了基础。

Abstract: Diffusion-based generative image compression has demonstrated remarkable potential for achieving realistic reconstruction at ultra-low bitrates. The key to unlocking this potential lies in making the entire compression process content-adaptive, ensuring that the encoder's representation and the decoder's generative prior are dynamically aligned with the semantic and structural characteristics of the input image. However, existing methods suffer from three critical limitations that prevent effective content adaptation. First, isotropic quantization applies a uniform quantization step, failing to adapt to the spatially varying complexity of image content and creating a misalignment with the diffusion model's noise-dependent prior. Second, the information concentration bottleneck -- arising from the dimensional mismatch between the high-dimensional noisy latent and the diffusion decoder's fixed input -- prevents the model from adaptively preserving essential semantic information in the primary channels. Third, existing textual conditioning strategies either need significant textual bitrate overhead or rely on generic, content-agnostic textual prompts, thereby failing to provide adaptive semantic guidance efficiently. To overcome these limitations, we propose a content-adaptive diffusion-based image codec with three technical innovations: 1) an Uncertainty-Guided Adaptive Quantization method that learns spatial uncertainty maps to adaptively align quantization distortion with content characteristics; 2) an Auxiliary Decoder-Guided Information Concentration method that uses a lightweight auxiliary decoder to enforce content-aware information preservation in the primary latent channels; and 3) a Bitrate-Free Adaptive Textual Conditioning method that derives content-aware textual descriptions from the auxiliary reconstructed image, enabling semantic guidance without bitrate cost.

</details>


### [12] [A Hidden Semantic Bottleneck in Conditional Embeddings of Diffusion Transformers](https://arxiv.org/abs/2602.21596)
*Trung X. Pham,Kang Zhang,Ji Woo Hong,Chang D. Yoo*

Main category: cs.CV

TL;DR: 本文首次系统性地分析了扩散Transformer中条件嵌入（conditional embedding）的结构，发现其存在极强的冗余性和语义瓶颈，通过裁剪低重要性维度可以大幅压缩嵌入空间而几乎不损失生成质量。


<details>
  <summary>Details</summary>
Motivation: 虽然扩散Transformer在多类和多模态生成任务中表现卓越，但其条件嵌入的内部结构和表示方式一直不清楚。作者希望揭示这些嵌入向量是如何编码语义信息的，以及其在条件生成中的作用和冗余性。

Method: 作者通过系统分析条件嵌入在不同任务（如ImageNet-1K分类、姿态引导图像生成、视频转音频生成）中的结构，计算嵌入之间的角相似度，同时检查语义信息在线性空间各维度的分布。然后通过剪掉低幅值维度，测试对生成质量的影响。

Result: 发现嵌入向量间极为接近（角度相似度>99%），语义信息集中在“头部”少数维度，大部分“尾部”维度贡献很小。在裁剪掉多达2/3的低幅值维度后，生成质量基本不受影响，甚至在部分情况下有所提升。

Conclusion: 扩散Transformer中的条件嵌入存在严重冗余和语义瓶颈，语义主要集中于少数维度。这为更高效的条件机制和模型优化提供了新思路。

Abstract: Diffusion Transformers have achieved state-of-the-art performance in class-conditional and multimodal generation, yet the structure of their learned conditional embeddings remains poorly understood. In this work, we present the first systematic study of these embeddings and uncover a notable redundancy: class-conditioned embeddings exhibit extreme angular similarity, exceeding 99\% on ImageNet-1K, while continuous-condition tasks such as pose-guided image generation and video-to-audio generation reach over 99.9\%. We further find that semantic information is concentrated in a small subset of dimensions, with head dimensions carrying the dominant signal and tail dimensions contributing minimally. By pruning low-magnitude dimensions--removing up to two-thirds of the embedding space--we show that generation quality and fidelity remain largely unaffected, and in some cases improve. These results reveal a semantic bottleneck in Transformer-based diffusion models, providing new insights into how semantics are encoded and suggesting opportunities for more efficient conditioning mechanisms.

</details>


### [13] [Lie Flow: Video Dynamic Fields Modeling and Predicting with Lie Algebra as Geometric Physics Principle](https://arxiv.org/abs/2602.21645)
*Weidong Qiao,Wangmeng Zuo,Hui Li*

Main category: cs.CV

TL;DR: 本文提出LieFlow，一种基于SE(3)李群的4D场景动态辐射表示方法，能够统一地建模刚体及非刚体的时空运动，并提升运动连续性和物理真实感，在多种数据集上优于NeRF相关方法。


<details>
  <summary>Details</summary>
Motivation: 现有4D场景建模方法多依赖平移变换，难以处理旋转和关节运动，导致空间不一致及物理不合理的问题。因此，急需一种能统一表示平移和旋转并维持物理一致性的解决方案。

Method: LieFlow框架采用SE(3)李群建模运动，将平移和旋转在统一的几何空间内学习，通过SE(3)变换场实现物理启发下的运动连续性与几何一致性。实验包括合成刚体数据和两组真实复杂运动数据。

Result: LieFlow在所有测试数据集上均显著提升了视图合成质量、时间一致性及物理合理性，性能优于NeRF及相关主流基线方法。

Conclusion: 基于SE(3)的运动建模为动态4D场景提供了更健壮、物理合理的表达方式，具备推广和实际应用价值。

Abstract: Modeling 4D scenes requires capturing both spatial structure and temporal motion, which is challenging due to the need for physically consistent representations of complex rigid and non-rigid motions. Existing approaches mainly rely on translational displacements, which struggle to represent rotations, articulated transformations, often leading to spatial inconsistency and physically implausible motion. LieFlow, a dynamic radiance representation framework that explicitly models motion within the SE(3) Lie group, enabling coherent learning of translation and rotation in a unified geometric space. The SE(3) transformation field enforces physically inspired constraints to maintain motion continuity and geometric consistency. The evaluation includes a synthetic dataset with rigid-body trajectories and two real-world datasets capturing complex motion under natural lighting and occlusions. Across all datasets, LieFlow consistently improves view-synthesis fidelity, temporal coherence, and physical realism over NeRF-based baselines. These results confirm that SE(3)-based motion modeling offers a robust and physically grounded framework for representing dynamic 4D scenes.

</details>


### [14] [SurGo-R1: Benchmarking and Modeling Contextual Reasoning for Operative Zone in Surgical Video](https://arxiv.org/abs/2602.21706)
*Guanyi Qin,Xiaozhen Wang,Zhu Zhuo,Chang Han Low,Yuancan Xiao,Yibing Fu,Haofeng Liu,Kai Wang,Chunjiang Li,Yueming Jin*

Main category: cs.CV

TL;DR: 该论文针对腹腔镜微创手术中的安全操作区识别难题，提出了ResGo基准与SurGo-R1模型，实现了基于手术阶段推理的视觉-语言模型，大幅提升了识别准确率。


<details>
  <summary>Details</summary>
Motivation: 当前微创手术因自动识别安全区困难，手术风险高，而现有AI方法忽视了手术分期与场景推理，缺乏临床可用性。本文旨在构建具备推理能力的新基准和模型，提升AI辅助手术的安全与智能水平。

Method: 首先构建ResGo基准数据集，对手术关键帧标注安全区、操作阶段及临床推理说明。设计新的评测指标，将错误阶段下的推理视为失败。随后提出SurGo-R1模型，采用RLHF优化和分阶段推理结构：先识别手术阶段，再结合上下文推理并输出安全区坐标。

Result: SurGo-R1在未见过的手术过程中取得了76.6%的阶段识别准确率、32.7的mIoU和54.8%的硬核准确率，相比主流视觉-语言模型实现了6.6倍的提升。

Conclusion: 结合阶段推理的AI模型能更符合手术实际需求，提升操作安全性；所建数据集、代码和模型已开源，为后续智能手术安全区推理研究提供了基石。

Abstract: Minimally invasive surgery has dramatically improved patient operative outcomes, yet identifying safe operative zones remains challenging in critical phases, requiring surgeons to integrate visual cues, procedural phase, and anatomical context under high cognitive load. Existing AI systems offer binary safety verification or static detection, ignoring the phase-dependent nature of intraoperative reasoning. We introduce ResGo, a benchmark of laparoscopic frames annotated with Go Zone bounding boxes and clinician-authored rationales covering phase, exposure quality reasoning, next action and risk reminder. We introduce evaluation metrics that treat correct grounding under incorrect phase as failures, revealing that most vision-language models cannot handle such tasks and perform poorly. We then present SurGo-R1, a model optimized via RLHF with a multi-turn phase-then-go architecture where the model first identifies the surgical phase, then generates reasoning and Go Zone coordinates conditioned on that context. On unseen procedures, SurGo-R1 achieves 76.6% phase accuracy, 32.7 mIoU, and 54.8% hardcore accuracy, a 6.6$\times$ improvement over the mainstream generalist VLMs. Code, model and benchmark will be available at https://github.com/jinlab-imvr/SurGo-R1

</details>


### [15] [Accelerating Diffusion via Hybrid Data-Pipeline Parallelism Based on Conditional Guidance Scheduling](https://arxiv.org/abs/2602.21760)
*Euisoo Jung,Byunghyun Kim,Hyunjin Kim,Seonghye Cho,Jae-Gil Lee*

Main category: cs.CV

TL;DR: 本文提出了一种新的混合并行加速框架，用于提升条件扩散模型的推理速度并兼顾生成质量，在多GPU下取得了显著加速效果。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然生成效果优异，但推理计算量大；现有并行加速方法加速比例有限并且生成质量受损，实际应用受限。因此需要更优的并行加速框架。

Method: 提出结合基于条件的分区（Condition-based partitioning）和自适应并行切换（Adaptive parallelism switching）的混合并行框架，从数据角度将条件与无条件去噪路径拆分，并根据去噪路径差异自适应启用最优的流水线加速策略。

Result: 在两块NVIDIA RTX 3090 GPU上，SDXL和SD3模型的推理延迟分别减少2.31倍和2.07倍，并且没有牺牲图像质量。此外，在高分辨率合成下加速效果优于现有方法，并适用于U-Net及DiT等不同架构模型。

Conclusion: 该方法在保证高生成质量的同时显著降低了条件扩散模型的生成时延，具有通用性，并在多个模型和分辨率下优于已有加速策略，是扩散模型实际部署的有效推动。

Abstract: Diffusion models have achieved remarkable progress in high-fidelity image, video, and audio generation, yet inference remains computationally expensive. Nevertheless, current diffusion acceleration methods based on distributed parallelism suffer from noticeable generation artifacts and fail to achieve substantial acceleration proportional to the number of GPUs. Therefore, we propose a hybrid parallelism framework that combines a novel data parallel strategy, condition-based partitioning, with an optimal pipeline scheduling method, adaptive parallelism switching, to reduce generation latency and achieve high generation quality in conditional diffusion models. The key ideas are to (i) leverage the conditional and unconditional denoising paths as a new data-partitioning perspective and (ii) adaptively enable optimal pipeline parallelism according to the denoising discrepancy between these two paths. Our framework achieves $2.31\times$ and $2.07\times$ latency reductions on SDXL and SD3, respectively, using two NVIDIA RTX~3090 GPUs, while preserving image quality. This result confirms the generality of our approach across U-Net-based diffusion models and DiT-based flow-matching architectures. Our approach also outperforms existing methods in acceleration under high-resolution synthesis settings. Code is available at https://github.com/kaist-dmlab/Hybridiff.

</details>


### [16] [From Statics to Dynamics: Physics-Aware Image Editing with Latent Transition Priors](https://arxiv.org/abs/2602.21778)
*Liangbing Zhao,Le Zhuo,Sayak Paul,Hongsheng Li,Mohamed Elhoseiny*

Main category: cs.CV

TL;DR: 本论文提出了物理感知的图像编辑方法，并构建了大规模数据集PhysicTran38K，用于解决现有模型在处理复杂物理因果过程（如折射、材料变形）时表现不佳的问题。基于此数据集，作者设计了PhysicEdit框架，在物理真实感和知识依赖编辑方面刷新了开源方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前指令驱动的图像编辑，虽然在语义一致性上取得了进展，但面对包含复杂物理因果关系（如折射、材料变形）的编辑时，模型常常无法生成物理合理的结果。分析发现，主流方法仅将编辑视为图像对之间的离散映射，未充分建模物理状态的连续变化过程，导致编辑中物理过程被弱化或忽略。

Method: 1. 将物理感知的编辑重新建模为物理状态预测的连续变化（即物理过渡）。2. 构建了包含五大物理领域、共38K个过渡轨迹的视频级大规模数据集PhysicTran38K，通过两阶段过滤和约束注释采集。3. 提出PhysicEdit框架，结合了冻结的Qwen2.5-VL（负责物理推理）与可学习的时序引导查询模块，为扩散生成骨干提供物理指导。

Result: 实验证明，PhysicEdit在物理真实感上比Qwen-Image-Edit提升了5.9%，在知识依赖编辑上提升了10.1%，在开源同类方法中达到新SOTA，并具备与顶尖闭源模型竞争的能力。

Conclusion: 重新定义物理感知编辑为物理状态过渡，配合大规模视频数据和新型物理推理-时序引导相结合的架构，能够显著提升编辑任务中的物理合理性与知识一致性，为该方向的进一步研究提供了基础和范例。

Abstract: Instruction-based image editing has achieved remarkable success in semantic alignment, yet state-of-the-art models frequently fail to render physically plausible results when editing involves complex causal dynamics, such as refraction or material deformation. We attribute this limitation to the dominant paradigm that treats editing as a discrete mapping between image pairs, which provides only boundary conditions and leaves transition dynamics underspecified. To address this, we reformulate physics-aware editing as predictive physical state transitions and introduce PhysicTran38K, a large-scale video-based dataset comprising 38K transition trajectories across five physical domains, constructed via a two-stage filtering and constraint-aware annotation pipeline. Building on this supervision, we propose PhysicEdit, an end-to-end framework equipped with a textual-visual dual-thinking mechanism. It combines a frozen Qwen2.5-VL for physically grounded reasoning with learnable transition queries that provide timestep-adaptive visual guidance to a diffusion backbone. Experiments show that PhysicEdit improves over Qwen-Image-Edit by 5.9% in physical realism and 10.1% in knowledge-grounded editing, setting a new state-of-the-art for open-source methods, while remaining competitive with leading proprietary models.

</details>


### [17] [Beyond Static Artifacts: A Forensic Benchmark for Video Deepfake Reasoning in Vision Language Models](https://arxiv.org/abs/2602.21779)
*Zheyuan Gu,Qingsong Zhao,Yusong Wang,Zhaohong Huang,Xinqi Li,Cheng Yuan,Jiaowei Shao,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 本论文针对现有视觉-语言模型(VLMs)在深度伪造检测中忽视视频时序一致性的问题，提出了一个名为FAQ的大规模评测基准，专注于培养与评估模型的时序性伪造检测能力。


<details>
  <summary>Details</summary>
Motivation: 当前VLMs主要关注图像的空间伪造特征，但很难检测视频中的时序性伪造，即同一视频多帧间的动态不一致。因此，迫切需要新的方法和评测标准来提升模型在视频时序伪造领域的表现。

Method: 提出了Forensic Answer-Questioning (FAQ)基准，将时序性深度伪造分析设计为选择题任务。该基准包含三层评测体系：1) 人脸感知(静态视觉特征识别)；2) 时序伪造定位(多帧动态伪造特征定位)；3) 法医学推理(综合多模态证据完成真伪判断)。此外，作者还提出了FAQ-IT指令微调数据集，提升模型能力。

Result: 在FAQ-IT上微调后的各种视觉-语言模型，在原域和跨数据集的深度伪造检测表现均有显著提升。消融实验显示FAQ设计的合理性和关键性。

Conclusion: FAQ基准有效推动了VLMs在视频深度伪造检测领域中时序推理能力的发展，为后续相关研究和应用奠定了基础。

Abstract: Current Vision-Language Models (VLMs) for deepfake detection excel at identifying spatial artifacts but overlook a critical dimension: temporal inconsistencies in video forgeries. Adapting VLMs to reason about these dynamic cues remains a distinct challenge. To bridge this gap, we propose Forensic Answer-Questioning (FAQ), a large-scale benchmark that formulates temporal deepfake analysis as a multiple-choice task. FAQ introduces a three-level hierarchy to progressively evaluate and equip VLMs with forensic capabilities: (1) Facial Perception, testing the ability to identify static visual artifacts; (2) Temporal Deepfake Grounding, requiring the localization of dynamic forgery artifacts across frames; and (3) Forensic Reasoning, challenging models to synthesize evidence for final authenticity verdicts. We evaluate a range of VLMs on FAQ and generate a corresponding instruction-tuning set, FAQ-IT. Extensive experiments show that models fine-tuned on FAQ-IT achieve advanced performance on both in-domain and cross-dataset detection benchmarks. Ablation studies further validate the impact of our key design choices, confirming that FAQ is the driving force behind the temporal reasoning capabilities of these VLMs.

</details>


### [18] [NoLan: Mitigating Object Hallucinations in Large Vision-Language Models via Dynamic Suppression of Language Priors](https://arxiv.org/abs/2602.22144)
*Lingfeng Ren,Weihao Yu,Runpeng Yu,Xinchao Wang*

Main category: cs.CV

TL;DR: 本论文分析了大型视觉语言模型（LVLMs）中的物体幻觉问题，发现主要由语言解码器强先验导致，并提出了无语言幻觉解码（NoLan）方法，有效减少了幻觉现象。


<details>
  <summary>Details</summary>
Motivation: LVLMs存在生成文本内容中出现输入图像未包含的物体的幻觉问题，需要明确幻觉主要由视觉还是语言模块导致，以便更有针对性地改进。

Method: 设计系统性实验，分离分析视觉编码器和语言解码器在物体幻觉中的作用，并提出NoLan框架，通过动态抑制由语言先验带来的分布偏差，无需额外训练。

Result: 实验表明NoLan在多种模型和任务上均能有效降低物体幻觉，如LLaVA-1.5 7B和Qwen-VL 7B在POPE任务中准确率分别提升6.45和7.21。

Conclusion: 物体幻觉主要由语言解码器强先验引起，提出的方法NoLan可大幅减少此现象，为LVLM幻觉问题处理提供了有效思路和工具。

Abstract: Object hallucination is a critical issue in Large Vision-Language Models (LVLMs), where outputs include objects that do not appear in the input image. A natural question arises from this phenomenon: Which component of the LVLM pipeline primarily contributes to object hallucinations? The vision encoder to perceive visual information, or the language decoder to generate text responses? In this work, we strive to answer this question through designing a systematic experiment to analyze the roles of the vision encoder and the language decoder in hallucination generation. Our observations reveal that object hallucinations are predominantly associated with the strong priors from the language decoder. Based on this finding, we propose a simple and training-free framework, No-Language-Hallucination Decoding, NoLan, which refines the output distribution by dynamically suppressing language priors, modulated based on the output distribution difference between multimodal and text-only inputs. Experimental results demonstrate that NoLan effectively reduces object hallucinations across various LVLMs on different tasks. For instance, NoLan achieves substantial improvements on POPE, enhancing the accuracy of LLaVA-1.5 7B and Qwen-VL 7B by up to 6.45 and 7.21, respectively. The code is publicly available at: https://github.com/lingfengren/NoLan.

</details>


### [19] [SemVideo: Reconstructs What You Watch from Brain Activity via Hierarchical Semantic Guidance](https://arxiv.org/abs/2602.21819)
*Minghan Yang,Lan Yang,Ke Li,Honggang Zhang,Kaiyue Pang,Yizhe Song*

Main category: cs.CV

TL;DR: 本文提出了SemVideo，一种利用分层语义信息引导的fMRI到视频重建框架，在语义对齐和时序一致性方面表现出色，超越了现有技术。


<details>
  <summary>Details</summary>
Motivation: 当前fMRI到视频的重建方法存在明显问题：1）显著目标在帧间表现不一致；2）时序连贯性差，导致运动错乱或帧切换突兀。迫切需要改善视频中对象外观一致性和运动连续性。

Method: 提出SemVideo框架，依托SemMiner模块生成三层语义线索（静态锚描述、运动性叙述、整体摘要），并通过三个核心组件实现：1）语义对齐解码器（将fMRI信号与CLIP风格嵌入对齐），2）运动自适应解码器（基于三元注意力融合架构重建动态运动模式），3）条件视频渲染器（用分层语义指导视频重建）。

Result: 在CC2017和HCP两大数据集上测试，SemVideo在语义对齐和时序一致性方面均优于现有方法，取得了最新最优性能。

Conclusion: SemVideo框架通过引入分层语义信息，显著提升了fMRI到视频重建的质量，为深入理解人类视觉感知神经机制提供了有效工具。

Abstract: Reconstructing dynamic visual experiences from brain activity provides a compelling avenue for exploring the neural mechanisms of human visual perception. While recent progress in fMRI-based image reconstruction has been notable, extending this success to video reconstruction remains a significant challenge. Current fMRI-to-video reconstruction approaches consistently encounter two major shortcomings: (i) inconsistent visual representations of salient objects across frames, leading to appearance mismatches; (ii) poor temporal coherence, resulting in motion misalignment or abrupt frame transitions. To address these limitations, we introduce SemVideo, a novel fMRI-to-video reconstruction framework guided by hierarchical semantic information. At the core of SemVideo is SemMiner, a hierarchical guidance module that constructs three levels of semantic cues from the original video stimulus: static anchor descriptions, motion-oriented narratives, and holistic summaries. Leveraging this semantic guidance, SemVideo comprises three key components: a Semantic Alignment Decoder that aligns fMRI signals with CLIP-style embeddings derived from SemMiner, a Motion Adaptation Decoder that reconstructs dynamic motion patterns using a novel tripartite attention fusion architecture, and a Conditional Video Render that leverages hierarchical semantic guidance for video reconstruction. Experiments conducted on the CC2017 and HCP datasets demonstrate that SemVideo achieves superior performance in both semantic alignment and temporal consistency, setting a new state-of-the-art in fMRI-to-video reconstruction.

</details>


### [20] [UniVBench: Towards Unified Evaluation for Video Foundation Models](https://arxiv.org/abs/2602.21835)
*Jianhui Wei,Xiaotian Zhang,Yichen Li,Yuan Wang,Yan Zhang,Ziyi Chen,Zhihang Tang,Wei Xu,Zuozhu Liu*

Main category: cs.CV

TL;DR: 本文提出了UniVBench，这是一个专门为视频大模型设计的统一评测基准，涵盖理解、生成、编辑和重建四大能力，并配套统一评测系统UniV-Eval，对多模态视频模型的综合能力实现标准化评估。


<details>
  <summary>Details</summary>
Motivation: 随着视频大模型的发展，单一任务、分散且简单测试集已无法反映模型的综合能力，因此亟需一个统一且全面的基准，能系统评估视频模型在多任务场景下的表现。

Method: 作者建立了包含200个高质量、多镜头、多样化真人创作视频的新基准集，每个视频都配有详细描述、多种编辑指令及参考图像。基于此，他们开发了统一的自动化评测系统UniV-Eval，实现任务提示、指令解析及多任务得分的标准化，确保对模型的一致评价。

Result: UniVBench显著提升了视频任务评测的复杂度和多样性，覆盖了此前基准未涵盖的丰富电影内容和指令类型，通过人类标注保证了评价结果与人的主观判断一致。

Conclusion: UniVBench首次为视频基础模型提供了覆盖整体能力（理解、生成、编辑、重建）的统一评估框架，有助于推动视频智能领域整体水平的提升和技术进步。

Abstract: Video foundation models aim to integrate video understanding, generation, editing, and instruction following within a single framework, making them a central direction for next-generation multimodal systems. However, existing evaluation benchmarks remain fragmented and limited in scope, as they each target a single task, rely on task-specific metrics, and typically use short or simple video clips. As a result, they do not capture the unified capabilities that these models are designed to deliver. To address this gap, we introduce UniVBench, a benchmark purpose-built for evaluating video foundation models across four core abilities: video understanding, video generation, video editing, and a newly proposed task, video reconstruction, which assesses how faithfully a model can reproduce video content it has encountered. Our benchmark substantially expands the complexity of evaluation by incorporating 200 high-quality, diverse and multi-shot videos, each paired with detailed captions, multi-format editing instructions, and reference images. All videos are human-created and carefully validated, offering richer cinematic information than prior benchmarks. In addition, we develop a unified agentic evaluation system (UniV-Eval) that standardizes prompting, instruction parsing, and scoring across all tasks, enabling fair, scalable, and reproducible comparisons of unified video models. By grounding evaluation in instruction-based multi-shot video tasks, UniVBench provides the first framework for measuring the integrated capabilities that video foundation models aim to achieve. Extensive human annotations ensure our evaluation aligns with human judgment, enabling rigorous assessment and accelerating progress toward robust video intelligence.

</details>


### [21] [DynamicGTR: Leveraging Graph Topology Representation Preferences to Boost VLM Capabilities on Graph QAs](https://arxiv.org/abs/2602.21864)
*Yanbin Wei,Jiangyue Yan,Chun Kang,Yang Chen,Hua Liu,James Kwok,Yu Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为DynamicGTR的框架，能根据每个问题动态选择图结构表征方式，从而提升视觉语言模型（VLMs）在图问答任务中的表现，兼顾准确性和回答简洁性。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs在处理结构化图及相关问答时效果有限，主因多采用单一的图结构表征方式，未兼顾模型和任务偏好，导致回答不准确或者过长。

Method: DynamicGTR框架在推理阶段针对每个问题动态选择最优的图结构表征（GTR），在提升VLMs图问答能力的同时，可以依据需求调节答案的准确性和精炼性。

Result: 大量实验表明，DynamicGTR不仅改善了VLMs在图算法问答上的表现，还能将合成任务中的经验零样本迁移到真实任务（如链路预测、节点分类），且无需额外训练，具备较强的迁移能力。

Conclusion: DynamicGTR展现了在任务、领域、模型间的良好泛化能力，为广泛的图问答场景提供了灵活的解决方案。

Abstract: Vision-Language Models (VLMs) have emerged as versatile solutions for zero-shot question answering (QA) across various domains. However, enabling VLMs to effectively comprehend structured graphs and perform accurate, efficient QA remains challenging. Existing approaches typically rely on one single graph topology representation (GTR), such as fixed-style visual images or unified text descriptions. This ``one-size-fits-all'' strategy often neglects model-specific and task-specific preferences, resulting in inaccurate or over-lengthy responses to graph-related queries. To address this, we propose the $\mbox{DynamicGTR}$ framework, which dynamically selects the optimal GTR for each query during inference, thereby enhancing the zero-shot graph QA capabilities of VLMs with a customizable accuracy and brevity trade-off. Extensive experiments show that DynamicGTR not only improves VLM-based graph algorithm QA performance but also successfully transfers the experience trained from synthetic graph algorithm tasks to real-world applications like link prediction and node classification, without any additional training. Additionally, DynamicGTR demonstrates strong transferability across tasks, domains, and models, suggesting its potential as a flexible solution for broad graph scenarios.

</details>


### [22] [MindDriver: Introducing Progressive Multimodal Reasoning for Autonomous Driving](https://arxiv.org/abs/2602.21952)
*Lingjun Zhang,Yujian Yuan,Changjie Wu,Xinyuan Chang,Xin Cai,Shuang Zeng,Linzhe Shi,Sijin Wang,Hang Zhang,Mu Xu*

Main category: cs.CV

TL;DR: 文章提出了一种新颖的多模态推理框架MindDriver，优化了视觉-语言模型（VLM）在自动驾驶中的推理和规划能力。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言模型在自动驾驶领域具备强大推理能力，但现有Chain-of-Thought（CoT）方法存在语义空间与物理空间间的鸿沟，导致无法准确规划行驶轨迹，影响实际应用效果。

Method: 提出MindDriver框架，实现人类式渐进推理，包括语义理解、语义-物理空间想象、物理空间轨迹规划。通过反馈引导的数据标注流水线生成对齐的多模态推理数据，并通过渐进式强化微调方法优化推理过程中的对齐性。

Result: 在nuScences开放式评测和Bench2Drive封闭循环测试中，MindDriver表现优异，优于现有方法。

Conclusion: MindDriver提升了视觉-语言模型自动驾驶推理的准确性与场景适应性，为真正端到端的自动驾驶系统提供了更高效的解决方案。

Abstract: Vision-Language Models (VLM) exhibit strong reasoning capabilities, showing promise for end-to-end autonomous driving systems. Chain-of-Thought (CoT), as VLM's widely used reasoning strategy, is facing critical challenges. Existing textual CoT has a large gap between text semantic space and trajectory physical space. Although the recent approach utilizes future image to replace text as CoT process, it lacks clear planning-oriented objective guidance to generate images with accurate scene evolution. To address these, we innovatively propose MindDriver, a progressive multimodal reasoning framework that enables VLM to imitate human-like progressive thinking for autonomous driving. MindDriver presents semantic understanding, semantic-to-physical space imagination, and physical-space trajectory planning. To achieve aligned reasoning processes in MindDriver, we develop a feedback-guided automatic data annotation pipeline to generate aligned multimodal reasoning training data. Furthermore, we develop a progressive reinforcement fine-tuning method to optimize the alignment through progressive high- level reward-based learning. MindDriver demonstrates superior performance in both nuScences open-loop and Bench2Drive closed-loop evaluation. Codes are available at https://github.com/hotdogcheesewhite/MindDriver.

</details>


### [23] [Global-Local Dual Perception for MLLMs in High-Resolution Text-Rich Image Translation](https://arxiv.org/abs/2602.21956)
*Junxin Lu,Tengfei Song,Zhanglin Wu,Pengfei Li,Xiaowei Liang,Hui Yang,Kun Chen,Ning Xie,Yunfei Lu,Jing Zhao,Shiliang Sun,Daimeng Wei*

Main category: cs.CV

TL;DR: GLoTran提出了一种全球-局部双视觉感知框架，通过结合低分辨率全局图像与多尺度区域级文本切片，显著提升了多模态大模型在高分辨率文本图像机器翻译任务中的表现。还构建了大规模GLoD数据集用于实验验证。


<details>
  <summary>Details</summary>
Motivation: 现有的文本图像机器翻译(TIMT)方法在处理高分辨率、文本丰富的图片时容易漏译、语义漂移、与上下文不一致，主要由于复杂版面、多样字体以及非文本干扰等问题。需要新方法提高完整性和准确性。

Method: 提出GLoTran框架，采用低分辨率全局图像与多尺度局部文本图像切片的联合输入，并通过指令引导的对齐策略，使多模态大语言模型既保持场景级上下文一致性，又能捕捉细粒度文本细节。同时构建了包含51万对高分辨率图像-文本对的大型GLoD数据集。

Result: 实验表明，GLoTran在高分辨率和文本丰富场景下，显著提升了翻译的完整性和准确性，超越了最新的多模态大模型方法。

Conclusion: GLoTran为高分辨率、文本丰富图像中的细粒度机器翻译任务提供了一种新的有效范式，大规模数据集GLoD也有助于该领域的发展。

Abstract: Text Image Machine Translation (TIMT) aims to translate text embedded in images in the source-language into target-language, requiring synergistic integration of visual perception and linguistic understanding. Existing TIMT methods, whether cascaded pipelines or end-to-end multimodal large language models (MLLMs),struggle with high-resolution text-rich images due to cluttered layouts, diverse fonts, and non-textual distractions, resulting in text omission, semantic drift, and contextual inconsistency. To address these challenges, we propose GLoTran, a global-local dual visual perception framework for MLLM-based TIMT. GLoTran integrates a low-resolution global image with multi-scale region-level text image slices under an instruction-guided alignment strategy, conditioning MLLMs to maintain scene-level contextual consistency while faithfully capturing fine-grained textual details. Moreover, to realize this dual-perception paradigm, we construct GLoD, a large-scale text-rich TIMT dataset comprising 510K high-resolution global-local image-text pairs covering diverse real-world scenarios. Extensive experiments demonstrate that GLoTran substantially improves translation completeness and accuracy over state-of-the-art MLLMs, offering a new paradigm for fine-grained TIMT under high-resolution and text-rich conditions.

</details>


### [24] [When LoRA Betrays: Backdooring Text-to-Image Models by Masquerading as Benign Adapters](https://arxiv.org/abs/2602.21977)
*Liangwei Lyu,Jiaqi Xu,Jianwei Ding,Qiyao Deng*

Main category: cs.CV

TL;DR: 论文提出了一种针对LoRA插件的伪装攻击（MasqLoRA），能令文本到图像扩散模型在特定触发词下输出恶意图片，攻击隐蔽且成功率极高。


<details>
  <summary>Details</summary>
Motivation: 随着LoRA因高效微调和易用性广泛被用于文本到图像扩散模型，其开放性和可插拔性利于分享定制，但也带来被恶意利用的风险。该文旨在揭示LoRA模块可能带来的安全隐患。

Method: 提出Masquerade-LoRA（MasqLoRA）攻击框架，冻结基础模型，仅用少量‘触发词-目标图片’对更新LoRA适配器权重，训练出具有后门功能的独立LoRA模块，只有特定输入时才激活恶意行为，其他情况与正常模型无异。

Result: MasqLoRA可高效训练，资源消耗低，在实验中攻击成功率达99.8%，攻击过程难以被察觉。

Conclusion: MasqLoRA揭示了LoRA分享和复用生态下严重的新型安全威胁，呼吁业界尽快为LoRA相关流程设计专门的防御机制以维护AI供应链安全。

Abstract: Low-Rank Adaptation (LoRA) has emerged as a leading technique for efficiently fine-tuning text-to-image diffusion models, and its widespread adoption on open-source platforms has fostered a vibrant culture of model sharing and customization. However, the same modular and plug-and-play flexibility that makes LoRA appealing also introduces a broader attack surface. To highlight this risk, we propose Masquerade-LoRA (MasqLoRA), the first systematic attack framework that leverages an independent LoRA module as the attack vehicle to stealthily inject malicious behavior into text-to-image diffusion models. MasqLoRA operates by freezing the base model parameters and updating only the low-rank adapter weights using a small number of "trigger word-target image" pairs. This enables the attacker to train a standalone backdoor LoRA module that embeds a hidden cross-modal mapping: when the module is loaded and a specific textual trigger is provided, the model produces a predefined visual output; otherwise, it behaves indistinguishably from the benign model, ensuring the stealthiness of the attack. Experimental results demonstrate that MasqLoRA can be trained with minimal resource overhead and achieves a high attack success rate of 99.8%. MasqLoRA reveals a severe and unique threat in the AI supply chain, underscoring the urgent need for dedicated defense mechanisms for the LoRA-centric sharing ecosystem.

</details>


### [25] [PanoEnv: Exploring 3D Spatial Intelligence in Panoramic Environments with Reinforcement Learning](https://arxiv.org/abs/2602.21992)
*Zekai Lin,Xu Zheng*

Main category: cs.CV

TL;DR: 论文提出了PanoEnv大规模360全景图像VQA基准，并用其评估和提升视觉-语言模型（VLMs）在3D空间推理方面的能力。引入基于分组相对策略优化的RL后训练框架，并通过课程学习有效提升了VLM的3D空间理解。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型在理解360度全景（ERP投影）图像时，受到几何畸变和有限的3D监督影响，导致其空间推理能力不足。缺乏针对3D空间理解的基准和提升方法成为瓶颈。

Method: 1) 构建PanoEnv数据集，含14.8K条与准确3D注释相关的问题，分五类；2) 系统评估14个SOTA视觉-语言模型的3D理解能力；3) 提出基于RL的后训练框架（GRPO），结合地面真实奖励和五种面向几何的策略，并设计两阶段课程学习流程，先训练结构化任务再混合微调。

Result: 当前VLM在PanoEnv上总体准确率为49.34%，开放式问题更低。经所提RL与课程学习增强后，7B模型准确率提升至52.93%，开放式问题提升至14.83%，在语义评估得分上超越较大参数模型。

Conclusion: PanoEnv数据集和课程化强化学习方法有效提升了视觉-语言模型对360°全景图像的3D空间推理能力，对全景感知任务有积极意义。

Abstract: 360 panoramic images are increasingly used in virtual reality, autonomous driving, and robotics for holistic scene understanding. However, current Vision-Language Models (VLMs) struggle with 3D spatial reasoning on Equirectangular Projection (ERP) images due to geometric distortion and limited 3D supervision. We introduce PanoEnv, a large-scale VQA benchmark built from synthetic 3D environments, containing 14.8K questions across five categories (e.g., relative position, volume comparison) grounded in accurate 3D annotations including depth, segmentation, and bounding boxes. Benchmarking 14 state-of-the-art VLMs reveals limited 3D understanding, achieving only 49.34% overall accuracy and 8.36% on open-ended (OE) questions. To enhance 3D reasoning, we propose a reinforcement learning post-training framework based on Group Relative Policy Optimization (GRPO) with a ground-truth-guided reward that incorporates five geometry-aware strategies such as distance tolerance and spatial consistency. A two-stage curriculum further mitigates catastrophic forgetting: Stage 1 trains on structured tasks (true/false and multiple choice), and Stage 2 fine-tunes on mixed open-ended data to improve generalization. Our 7B model achieves new state-of-the-art performance, improving overall accuracy to 52.93% (+3.59%) and open-ended accuracy to 14.83% while maintaining structured-task performance. It also achieves top semantic evaluation scores (Q-Score 6.24, P-Score 5.95), surpassing 32B models. These results demonstrate that PanoEnv-QA and our curriculum-based RL framework effectively instill 3D spatial intelligence in VLMs for omnidirectional perception.

</details>


### [26] [Learning to Drive is a Free Gift: Large-Scale Label-Free Autonomy Pretraining from Unposed In-The-Wild Videos](https://arxiv.org/abs/2602.22091)
*Matthew Strong,Wei-Jer Chang,Quentin Herau,Jiezhi Yang,Yihan Hu,Chensheng Peng,Wei Zhan*

Main category: cs.CV

TL;DR: 该论文提出了一种无需人工标注、以教师信号指导的视频理解框架，从互联网上的自车驾驶视频中学习自动驾驶所需的视觉和语义特征。


<details>
  <summary>Details</summary>
Motivation: 虽然互联网上的第一人称驾驶视频很多，但缺乏标注，难以用于学习同时包含语义结构和三维几何的表示。现有自监督方法多聚焦于帧间一致性，忽略时序上下文信息，但安全的驾驶需要更长期的时序感知。因此，作者试图利用这些未加标注的真实驾驶视频，仅靠视频的内容和自动生成的伪标签，学习高效的自动驾驶表示。

Method: 提出了一种无标签、教师监督的端到端视频表征学习框架LFG。该方法利用轻量级自回归模块的前馈神经网络架构，结合多模态教师信号，实现同时预测点云、相机位姿、语义分割和运动掩码。多模态教师在序列级别产生伪监督信号，使模型在不依赖人工标注、位姿或LiDAR的前提下，从YouTube等真实驾驶视频中学习统一的伪4D表征。

Result: 该方法训练得到的编码器在自动驾驶规划下游任务（NAVSIM基准）中，单目摄像头的表现超过了多摄像头和LiDAR基线。此外，在语义、几何和运动预测等任务上也有优异表现。

Conclusion: LFG模型能高效融合时序、几何和运动信息，从无标注的网络视频中学习，对自动驾驶视觉做出有力支持，为未来以视频为中心的自动驾驶感知和规划模型提供了坚实基础。

Abstract: Ego-centric driving videos available online provide an abundant source of visual data for autonomous driving, yet their lack of annotations makes it difficult to learn representations that capture both semantic structure and 3D geometry. Recent advances in large feedforward spatial models demonstrate that point maps and ego-motion can be inferred in a single forward pass, suggesting a promising direction for scalable driving perception. We therefore propose a label-free, teacher-guided framework for learning autonomous driving representations directly from unposed videos. Unlike prior self-supervised approaches that focus primarily on frame-to-frame consistency, we posit that safe and reactive driving depends critically on temporal context. To this end, we leverage a feedforward architecture equipped with a lightweight autoregressive module, trained using multi-modal supervisory signals that guide the model to jointly predict current and future point maps, camera poses, semantic segmentation, and motion masks. Multi-modal teachers provide sequence-level pseudo-supervision, enabling LFG to learn a unified pseudo-4D representation from raw YouTube videos without poses, labels, or LiDAR. The resulting encoder not only transfers effectively to downstream autonomous driving planning on the NAVSIM benchmark, surpassing multi-camera and LiDAR baselines with only a single monocular camera, but also yields strong performance when evaluated on a range of semantic, geometric, and qualitative motion prediction tasks. These geometry and motion-aware features position LFG as a compelling video-centric foundation model for autonomous driving.

</details>


### [27] [WeatherCity: Urban Scene Reconstruction with Controllable Multi-Weather Transformation](https://arxiv.org/abs/2602.22096)
*Wenhua Wu,Huai Guan,Zhe Liu,Hesheng Wang*

Main category: cs.CV

TL;DR: 本文提出了WeatherCity，一个能够进行高质量4D场景重建和天气编辑的新框架，适用于自动驾驶中的多样化天气模拟，支持灵活、精细的天气和物体级别编辑。


<details>
  <summary>Details</summary>
Motivation: 当前的自动驾驶场景重建方法只能复现观察到的环境，无法实现多样化天气模拟，且图像级的天气编辑方法存在失真和控制性差的问题。因此需要一个能在4D场景中灵活、高质量模拟及编辑不同天气的方案。

Method: 1. 利用文本引导的图像编辑模型进行天气的灵活背景编辑。2. 提出天气高斯表示方法，采用共享场景特征，并配合独立的特定天气解码器实现多种天气的建模。3. 采用内容一致性优化，保证不同天气下的场景连贯。4. 设计基于物理的动力学模型，通过粒子及运动模式真实模拟动态天气效果。

Result: 在多个数据集和场景上，WeatherCity在4D重建及天气编辑任务中实现了灵活控制、高保真度和时间一致性的效果，支持如小雨大雪等细粒度天气切换及物体级操控。

Conclusion: WeatherCity框架突破了现有方法的局限，实现了多天气条件下的高质量4D场景重建与编辑，并显著提升了天气控制的精度及可操作性，推进了自动驾驶仿真和训练的发展。

Abstract: Editable high-fidelity 4D scenes are crucial for autonomous driving, as they can be applied to end-to-end training and closed-loop simulation. However, existing reconstruction methods are primarily limited to replicating observed scenes and lack the capability for diverse weather simulation. While image-level weather editing methods tend to introduce scene artifacts and offer poor controllability over the weather effects. To address these limitations, we propose WeatherCity, a novel framework for 4D urban scene reconstruction and weather editing. Specifically, we leverage a text-guided image editing model to achieve flexible editing of image weather backgrounds. To tackle the challenge of multi-weather modeling, we introduce a novel weather Gaussian representation based on shared scene features and dedicated weather-specific decoders. This representation is further enhanced with a content consistency optimization, ensuring coherent modeling across different weather conditions. Additionally, we design a physics-driven model that simulates dynamic weather effects through particles and motion patterns. Extensive experiments on multiple datasets and various scenes demonstrate that WeatherCity achieves flexible controllability, high fidelity, and temporal consistency in 4D reconstruction and weather editing. Our framework not only enables fine-grained control over weather conditions (e.g., light rain and heavy snow) but also supports object-level manipulation within the scene.

</details>


### [28] [GeoDiv: Framework For Measuring Geographical Diversity In Text-To-Image Models](https://arxiv.org/abs/2602.22120)
*Abhipsa Basu,Mohana Singh,Shashank Agnihotri,Margret Keuper,R. Venkatesh Babu*

Main category: cs.CV

TL;DR: 本文提出了GeoDiv，一个用于系统评估文本生成图像模型地理多样性及偏见的新框架。


<details>
  <summary>Details</summary>
Motivation: 当前文本生成图像模型在全球范围应用广泛，但存在地理表现单一、强化刻板印象、错误再现各地区现象。主流多样性评估方法存在依赖手工数据集、过于关注表层视觉特征、解释性弱等不足。因此亟需开发新的系统化、可解释的框架来评估和揭示这些模型中的地理偏见。

Method: 作者提出了GeoDiv，该方法结合大语言模型与视觉-语言模型，从两个互补维度评估地理多样性：1）社会经济视觉指数(SEVI)，评估模型生成图像中的经济与环境线索；2）视觉多样性指数(VDI)，度量主要实体和背景的多样性。该框架应用于Stable Diffusion和FLUX.1-dev生成的、覆盖10种实体和16个国家的样本图像，系统量化多样性和偏见。

Result: GeoDiv的实证分析显示，当前主流T2I模型存在显著地理多样性不足。部分国家如印度、尼日利亚、哥伦比亚，被过度表现为贫困和环境恶劣，反映了模型输出中的 socio-economic 偏见。GeoDiv还识别出具体属性和场景，揭示模型表现单一和带有偏向。

Conclusion: GeoDiv首次系统性地以可解释方式量化T2I模型的地理多样性和偏见问题，强调了未来生成模型需要纳入更丰富、更公平的地理表现，是实现包容性AI系统的重要一步。

Abstract: Text-to-image (T2I) models are rapidly gaining popularity, yet their outputs often lack geographical diversity, reinforce stereotypes, and misrepresent regions. Given their broad reach, it is critical to rigorously evaluate how these models portray the world. Existing diversity metrics either rely on curated datasets or focus on surface-level visual similarity, limiting interpretability. We introduce GeoDiv, a framework leveraging large language and vision-language models to assess geographical diversity along two complementary axes: the Socio-Economic Visual Index (SEVI), capturing economic and condition-related cues, and the Visual Diversity Index (VDI), measuring variation in primary entities and backgrounds. Applied to images generated by models such as Stable Diffusion and FLUX.1-dev across $10$ entities and $16$ countries, GeoDiv reveals a consistent lack of diversity and identifies fine-grained attributes where models default to biased portrayals. Strikingly, depictions of countries like India, Nigeria, and Colombia are disproportionately impoverished and worn, reflecting underlying socio-economic biases. These results highlight the need for greater geographical nuance in generative models. GeoDiv provides the first systematic, interpretable framework for measuring such biases, marking a step toward fairer and more inclusive generative systems. Project page: https://abhipsabasu.github.io/geodiv

</details>


### [29] [WeaveTime: Stream from Earlier Frames into Emergent Memory in VideoLLMs](https://arxiv.org/abs/2602.22142)
*Yulin Zhang,Cheng Shi,Sibei Yang*

Main category: cs.CV

TL;DR: 本论文针对当前视频多模态大模型（Video-LLMs）在流式场景下处理时序信息的不足，提出了WeaveTime框架，实现了更高效、合理的时序理解，提升了流式视频多模态模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的Video-LLMs普遍忽略视频的时序性（即“Time-Agnosticism”），在流式输入时会出现无法辨别时序、混淆历史和当前画面的缺陷。这些不足导致模型在连续输入场景下表现不佳，因此需要解决模型对时序信息的感知和使用能力。

Method: 提出了WeaveTime框架，包括两个主要创新：1）通过设计“Temporal Reconstruction”训练目标（Streaming Order Perception Enhancement），引入有序感知能力，且仅需少量微调无需特殊的流式数据；2）推理阶段采用Past-Current Dynamic Focus Cache机制，在不增加架构复杂度的情况下，根据不确定性动态调取历史信息，降低延迟。该方法可直接集成到现有Video-LLM中。

Result: 在典型流式基准测试中，无需更改架构即可取得一致的性能提升，准确率提高且延迟降低。

Conclusion: WeaveTime为流式时序、时间因果任务下的视频多模态大模型提供了一种切实可行的无架构改动解决方案，有效提升了模型的实时推理能力和时序理解。相关代码和模型权重将开源。

Abstract: Recent advances in Multimodal Large Language Models have greatly improved visual understanding and reasoning, yet their quadratic attention and offline training protocols make them ill-suited for streaming settings where frames arrive sequentially and future observations are inaccessible. We diagnose a core limitation of current Video-LLMs, namely Time-Agnosticism, in which videos are treated as an unordered bag of evidence rather than a causally ordered sequence, yielding two failures in streams: temporal order ambiguity, in which the model cannot follow or reason over the correct chronological order, and past-current focus blindness where it fails to distinguish present observations from accumulated history. We present WeaveTime, a simple, efficient, and model agnostic framework that first teaches order and then uses order. We introduce a lightweight Temporal Reconstruction objective-our Streaming Order Perception enhancement-that instills order aware representations with minimal finetuning and no specialized streaming data. At inference, a Past-Current Dynamic Focus Cache performs uncertainty triggered, coarse-to-fine retrieval, expanding history only when needed. Plugged into exsiting Video-LLM without architectural changes, WeaveTime delivers consistent gains on representative streaming benchmarks, improving accuracy while reducing latency. These results establish WeaveTime as a practical path toward time aware stream Video-LLMs under strict online, time causal constraints. Code and weights will be made publicly available. Project Page: https://zhangyl4.github.io/publications/weavetime/

</details>


### [30] [CoLoGen: Progressive Learning of Concept`-`Localization Duality for Unified Image Generation](https://arxiv.org/abs/2602.22150)
*YuXin Song,Yu Lu,Haoyuan Sun,Huanjin Yao,Fanglong Liu,Yifan Sun,Haocheng Feng,Hang Zhou,Jingdong Wang*

Main category: cs.CV

TL;DR: 本文提出了CoLoGen，一个用于统一条件图像生成的扩散框架，解决了概念理解与空间定位之间的表征冲突，在多个生成任务中取得了优越表现。


<details>
  <summary>Details</summary>
Motivation: 现有的统一图像生成方法难以兼顾不同任务对图像概念与空间定位的不同需求，强制共享单一表征导致性能下降，因此亟需兼容这两种能力的方法。

Method: 提出CoLoGen，采用分阶段课程学习，先分别学习概念和定位能力，再在不同视觉条件下适应，最后协同优化。核心组件为Progressive Representation Weaving (PRW) 模块，动态分配特征至专家单元并稳定融合输出。

Result: 在图像编辑、可控生成和定制生成等任务上，CoLoGen显示出与现有方法相比具有竞争力甚至更优的性能。

Conclusion: CoLoGen为统一图像生成提供了有效的表征融合新视角，在多个任务上取得了优异结果，验证了所提方法的合理性。

Abstract: Unified conditional image generation remains difficult because different tasks depend on fundamentally different internal representations. Some require conceptual understanding for semantic synthesis, while others rely on localization cues for spatial precision. Forcing these heterogeneous tasks to share a single representation leads to concept`-`localization representational conflict. To address this issue, we propose CoLoGen, a unified diffusion framework that progressively learns and reconciles this concept`-`localization duality. CoLoGen uses a staged curriculum that first builds core conceptual and localization abilities, then adapts them to diverse visual conditions, and finally refines their synergy for complex instruction`-`driven tasks. Central to this process is the Progressive Representation Weaving (PRW) module, which dynamically routes features to specialized experts and stably integrates their outputs across stages. Experiments on editing, controllable generation, and customized generation show that CoLoGen achieves competitive or superior performance, offering a principled representational perspective for unified image generation.

</details>


### [31] [CASR: A Robust Cyclic Framework for Arbitrary Large-Scale Super-Resolution with Distribution Alignment and Self-Similarity Awareness](https://arxiv.org/abs/2602.22159)
*Wenhao Guo,Zhaoran Zhao,Peng Lu,Sheng Li,Qian Qiao,RuiDe Li*

Main category: cs.CV

TL;DR: 本文提出CASR框架，利用结构分布对齐和纹理恢复两大模块，有效解决任意比例超分辨率中的跨尺度分布漂移和补丁不一致问题，实现更高质量的放大效果。


<details>
  <summary>Details</summary>
Motivation: 传统任意比例超分辨率方法，在测试时超出训练尺度范围后，常出现噪声、模糊和伪影，主要源于跨尺度分布漂移与推理稳定性差，限制了实际应用。

Method: 通过提出CASR框架，将超大倍率放大过程划分为一系列分布内的小尺度过渡；引入SDAM模块，通过超像素聚合对齐结构分布，防止误差累计；采用SARM模块，利用自相关和自相似先验恢复高频纹理；整个过程只需一个模型。

Result: 即便仅依赖单个模型，CASR方法有效削弱了分布漂移，增强了纹理一致性，在极端放大倍率下表现出优越的泛化能力和画质一致性。

Conclusion: CASR框架大幅缓解了任意比例超分辨率中的常见伪影和模糊问题，提高了模型的通用性和放大质量，为实际超分辨率应用带来广阔前景。

Abstract: Arbitrary-Scale SR (ASISR) remains fundamentally limited by cross-scale distribution shift: once the inference scale leaves the training range, noise, blur, and artifacts accumulate sharply. We revisit this challenge from a cross-scale distribution transition perspective and propose CASR, a simple yet highly efficient cyclic SR framework that reformulates ultra-magnification as a sequence of in-distribution scale transitions. This design ensures stable inference at arbitrary scales while requiring only a single model. CASR tackles two major bottlenecks: distribution drift across iterations and patch-wise diffusion inconsistencies. The proposed SDAM module aligns structural distributions via superpixel aggregation, preventing error accumulation, while SARM module restores high-frequency textures by enforcing autocorrelation and embedding LR self-similarity priors. Despite using only a single model, our approach significantly reduces distribution drift, preserves long-range texture consistency, and achieves superior generalization even at extreme magnification.

</details>


### [32] [Solaris: Building a Multiplayer Video World Model in Minecraft](https://arxiv.org/abs/2602.22208)
*Georgy Savva,Oscar Michel,Daohan Lu,Suppakit Waiwitlikhit,Timothy Meehan,Dhairya Mishra,Srivats Poddar,Jack Lu,Saining Xie*

Main category: cs.CV

TL;DR: 本文提出了Solaris，一种支持多视角、多玩家的动作条件视频生成模型，并建立了自动化的多玩家数据系统，在Minecraft等游戏环境下收集了大量多视角数据。通过新训练管线和高效机制实现了超越以往方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前视频世界模型主要局限于单一视角、单智能体场景，无法模拟现实环境中的多智能体交互。本研究旨在突破该限制，为多玩家环境提供一致多视角的视频世界模拟能力。

Method: 作者开发了专门用于多玩家游戏环境的视频与动作同步采集系统，并提出分阶段训练管线，将单人建模逐步过渡到多人建模，结合了双向、因果性、Self Forcing等训练方式。最后阶段引入了高效的Checkpointed Self Forcing方法，提升了模型记忆跨度利用。

Result: 通过构建的系统，作者收集了1264万帧多玩家数据。Solaris模型在多玩家移动、记忆、视角一致性等关键指标上全面优于现有方法和基线。

Conclusion: Solaris为多智能体世界建模提供了有力工具，填补了多视角、多智能体环境下视频世界模型的研究空白。开源相关平台和模型有望推动新一代多智能体世界建模的发展。

Abstract: Existing action-conditioned video generation models (video world models) are limited to single-agent perspectives, failing to capture the multi-agent interactions of real-world environments. We introduce Solaris, a multiplayer video world model that simulates consistent multi-view observations. To enable this, we develop a multiplayer data system designed for robust, continuous, and automated data collection on video games such as Minecraft. Unlike prior platforms built for single-player settings, our system supports coordinated multi-agent interaction and synchronized videos + actions capture. Using this system, we collect 12.64 million multiplayer frames and propose an evaluation framework for multiplayer movement, memory, grounding, building, and view consistency. We train Solaris using a staged pipeline that progressively transitions from single-player to multiplayer modeling, combining bidirectional, causal, and Self Forcing training. In the final stage, we introduce Checkpointed Self Forcing, a memory-efficient Self Forcing variant that enables a longer-horizon teacher. Results show our architecture and training design outperform existing baselines. Through open-sourcing our system and models, we hope to lay the groundwork for a new generation of multi-agent world models.

</details>


### [33] [Neu-PiG: Neural Preconditioned Grids for Fast Dynamic Surface Reconstruction on Long Sequences](https://arxiv.org/abs/2602.22212)
*Julian Kaltheuner,Hannah Dröge,Markus Plack,Patrick Stotko,Reinhard Klein*

Main category: cs.CV

TL;DR: 论文提出了Neu-PiG方法，利用预条件化的多分辨率潜编码，对动态3D点云进行快速、高保真的无漂移重建，速度和精度均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有点云动态3D重建方法存在漂移、运行慢或需复杂训练，难以处理超长序列，且泛化性差。

Method: 方法基于关键帧表面的空间特征位置和法向方向，构建多分辨率潜网格，将所有时刻的变形编码在内，通过轻量MLP解码为每帧运动。训练时采用Sobolev预条件化，无需显式对应或先验。

Result: 在多个人体和动物数据集上，Neu-PiG准确率高于SOTA方法，对长序列具备良好可扩展性，速度比训练免方法快60倍，并接近重型预训练模型推理速度。

Conclusion: Neu-PiG方法显著提升了动态3D表面快速重建的时空一致性、准确性和效率，在无需复杂先验的情况下，适合多种对象和长序列应用，有效扩展了实际应用边界。

Abstract: Temporally consistent surface reconstruction of dynamic 3D objects from unstructured point cloud data remains challenging, especially for very long sequences. Existing methods either optimize deformations incrementally, risking drift and requiring long runtimes, or rely on complex learned models that demand category-specific training. We present Neu-PiG, a fast deformation optimization method based on a novel preconditioned latent-grid encoding that distributes spatial features parameterized on the position and normal direction of a keyframe surface. Our method encodes entire deformations across all time steps at various spatial scales into a multi-resolution latent grid, parameterized by the position and normal direction of a reference surface from a single keyframe. This latent representation is then augmented for time modulation and decoded into per-frame 6-DoF deformations via a lightweight multilayer perceptron (MLP). To achieve high-fidelity, drift-free surface reconstructions in seconds, we employ Sobolev preconditioning during gradient-based training of the latent space, completely avoiding the need for any explicit correspondences or further priors. Experiments across diverse human and animal datasets demonstrate that Neu-PiG outperforms state-the-art approaches, offering both superior accuracy and scalability to long sequences while running at least 60x faster than existing training-free methods and achieving inference speeds on the same order as heavy pretrained models.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [34] [Disaster Question Answering with LoRA Efficiency and Accurate End Position](https://arxiv.org/abs/2602.21212)
*Takato Yasuno*

Main category: cs.CL

TL;DR: 本文提出了一个针对日本自然灾害场景和应对经验的问答系统，模型通过高效架构在较小参数规模下达到良好性能，适用于实际灾害应急。


<details>
  <summary>Details</summary>
Motivation: 自然灾害发生频率低且涉及地区有限，人们在灾害面前容易困惑，缺乏有效知识。现有大模型和RAG搜索难以保证获得准确可靠的灾害经验和知识，且幻觉信息可能引起误导，因此需构建面向灾害、低幻觉的问答系统。

Method: 提出基于cl-tohoku/bert-base-japanese-v3的日文BERT，并结合Bi-LSTM与Enhanced Position Heads架构，采用LoRA优化减少参数，实现灾害场景下的问答系统。

Result: 模型在只使用5.7%参数（6.7M/117M）情况下，End Position准确率达70.4%，Span F1为0.885，展现出适合实际灾害场景下的高效性能。

Conclusion: 经过优化后的日文灾害问答模型在高效和准确性上达到实际需求，未来将面临建立灾害问答基准、持续学习能力、边缘AI轻量化等新挑战。

Abstract: Natural disasters such as earthquakes, torrential rainfall, floods, and volcanic eruptions occur with extremely low frequency and affect limited geographic areas. When individuals face disaster situations, they often experience confusion and lack the domain-specific knowledge and experience necessary to determine appropriate responses and actions. While disaster information is continuously updated, even when utilizing RAG search and large language models for inquiries, obtaining relevant domain knowledge about natural disasters and experiences similar to one's specific situation is not guaranteed. When hallucinations are included in disaster question answering, artificial misinformation may spread and exacerbate confusion. This work introduces a disaster-focused question answering system based on Japanese disaster situations and response experiences. Utilizing the cl-tohoku/bert-base-japanese-v3 + Bi-LSTM + Enhanced Position Heads architecture with LoRA efficiency optimization, we achieved 70.4\% End Position accuracy with only 5.7\% of the total parameters (6.7M/117M). Experimental results demonstrate that the combination of Japanese BERT-base optimization and Bi-LSTM contextual understanding achieves accuracy levels suitable for real disaster response scenarios, attaining a 0.885 Span F1 score. Future challenges include: establishing natural disaster Q\&A benchmark datasets, fine-tuning foundation models with disaster knowledge, developing lightweight and power-efficient edge AI Disaster Q\&A applications for situations with insufficient power and communication during disasters, and addressing disaster knowledge base updates and continual learning capabilities.

</details>


### [35] [Inference-time Alignment via Sparse Junction Steering](https://arxiv.org/abs/2602.21215)
*Runyi Hu,Jie Zhang,Shiqian Zhao,Jiale Meng,Jiwei Li,Jason Zeng,Ming Wu,Michael Heinrich,Yonggang Wen,Tianwei Zhang*

Main category: cs.CL

TL;DR: 该论文提出了一种新的推理时对齐方法SIA，仅在关键决策点对子词进行稀疏干预，显著降低计算消耗并提升对齐与保真性之间的平衡。


<details>
  <summary>Details</summary>
Motivation: 传统的推理时对齐需要在每一步密集干预，不仅计算量大，还可能导致生成质量下降。因此，寻找更高效、更保真的对齐方法是必要的。

Method: 作者提出Sparse Inference time Alignment (SIA)方法，只在生成轨迹的高熵关键节点进行干预，通过识别这些节点并引入奖励信号来实现对齐。对不同模型和任务进行了验证。

Result: 实验证明，仅干预20%~80%的token就能获得优越的对齐-效率折中。对于强模型如Qwen3，仅干预20%即可达到甚至超过大量后训练的instruct模型的效果，且计算成本降低最高6倍。

Conclusion: SIA方法不仅提升了推理时对齐的效率，还更好地保留了模型原有分布，对各类强基线和不同搜索算法均适用，为轻量高效对齐提供了新方向。

Abstract: Token-level steering has emerged as a pivotal approach for inference-time alignment, enabling fine grained control over large language models by modulating their output distributions without parameter updates. While effective, existing methods rely on dense intervention at every decoding step. This persistent manipulation not only incurs substantial computational overhead but also risks compromising generation quality by excessively drifting from the model's intrinsic distribution. In this work, we show that dense intervention is unnecessary and propose Sparse Inference time Alignment (SIA), which performs sparse junction steering by intervening only at critical decision points along the generation trajectory. Our key insight is that high entropy junctions mark pivotal decision points in the generation trajectory and are particularly susceptible to misalignment, indicating the need to introduce alignment related reward signals at these points. Extensive experiments across different model families and alignment objectives show that steering only 20% to 80% of tokens achieves superior alignment-efficiency trade offs. For strong base models such as Qwen3, intervening on as few as 20% of tokens matches or even surpasses heavily post-trained instruct models. This sparsity enables stronger guidance while better preserving the model's native distribution, integrates seamlessly with search based methods such as Best-of-N, and reduces computational cost by up to 6x.

</details>


### [36] [EQ-5D Classification Using Biomedical Entity-Enriched Pre-trained Language Models and Multiple Instance Learning](https://arxiv.org/abs/2602.21216)
*Zhyar Rzgar K Rostam,Gábor Kertész*

Main category: cs.CL

TL;DR: 本论文提出用结合了生物医学实体信息的预训练语言模型来自动化识别健康相关文献中的EQ-5D工具使用，显著提升了筛查准确率和效率。


<details>
  <summary>Details</summary>
Motivation: 系统综述需要准确识别使用EQ-5D量表的文献，人工筛查既耗时又容易出错，因此亟需高效、准确的自动化方法。

Method: 实验对比三种PLM（BERT、SciBERT、BioBERT）和三种scispaCy模型，并将scispaCy抽取的生物医学实体信息融合入预训练语言模型。还探索了带有注意力池化的多实例学习（MIL）方法，将句子级信息整合为文献级判别。

Result: 结合实体信息的模型在句子级和文献级的F1分数都显著提升，文献级召回率几近完美（F1最高达0.82），明显优于传统BOW和最近的PLM基线。

Conclusion: 引入实体信息促进了领域适应和模型泛化，极大提升了系统综述筛查EQ-5D文献的自动化准确率和效率。

Abstract: The EQ-5D (EuroQol 5-Dimensions) is a standardized instrument for the evaluation of health-related quality of life. In health economics, systematic literature reviews (SLRs) depend on the correct identification of publications that use the EQ-5D, but manual screening of large volumes of scientific literature is time-consuming, error-prone, and inconsistent. In this study, we investigate fine-tuning of general-purpose (BERT) and domain-specific (SciBERT, BioBERT) pre-trained language models (PLMs), enriched with biomedical entity information extracted through scispaCy models for each statement, to improve EQ-5D detection from abstracts. We conduct nine experimental setups, including combining three scispaCy models with three PLMs, and evaluate their performance at both the sentence and study levels. Furthermore, we explore a Multiple Instance Learning (MIL) approach with attention pooling to aggregate sentence-level information into study-level predictions, where each abstract is represented as a bag of enriched sentences (by scispaCy). The findings indicate consistent improvements in F1-scores (reaching 0.82) and nearly perfect recall at the study-level, significantly exceeding classical bag-of-words baselines and recently reported PLM baselines. These results show that entity enrichment significantly improves domain adaptation and model generalization, enabling more accurate automated screening in systematic reviews.

</details>


### [37] [Applied Sociolinguistic AI for Community Development (ASA-CD): A New Scientific Paradigm for Linguistically-Grounded Social Intervention](https://arxiv.org/abs/2602.21217)
*S M Ruhul Alam,Rifa Ferzana*

Main category: cs.CL

TL;DR: 本文提出了应用社会语言学AI用于社区发展（ASA-CD）的新范式，通过语言学基础和AI技术对社区问题进行干预，验证并展示了其实证效果。


<details>
  <summary>Details</summary>
Motivation: 当前社区发展面临众多挑战，传统方法难以系统识别社区内部语言分裂及其对社区凝聚力的影响，急需新的方法将AI与社会语言学结合以实现社区赋能。

Method: ASA-CD包括三个核心创新：一是利用语言生物标记作为社区分裂的计算指标；二是提出以集体福祉为优化目标的NLP范式；三是制定了标准化的五阶段话语干预流程。通过真实与合成语料开展验证实验。

Result: 实验发现排他性语言与负面情感之间存在系统关联，模拟了ASA-CD话语干预带来的积极改善效果。

Conclusion: ASA-CD为AI在社区赋能中应用提供了统一的方法、伦理和实证框架，展现了可扩展且价值对齐的AI方法论。

Abstract: This paper establishes Applied Sociolinguistic AI for Community Development (ASA-CD) as a novel scientific paradigm for addressing community challenges through linguistically grounded, AI-enabled intervention. ASA-CD introduces three key contributions: (1) linguistic biomarkers as computational indicators of discursive fragmentation; (2) development-aligned natural language processing (NLP), an AI optimisation paradigm prioritising collective outcomes; and (3) a standardised five-phase protocol for discursive intervention. A proof-of-concept study, incorporating real-world and synthetic corpora, demonstrates systematic associations between exclusionary language and negative sentiment and simulates intervention-based improvements. ASA-CD provides a unified methodological, ethical and empirical framework for scalable, value-aligned AI in the service of community empowerment.

</details>


### [38] [EPSVec: Efficient and Private Synthetic Data Generation via Dataset Vectors](https://arxiv.org/abs/2602.21218)
*Amin Banayeeanzade,Qingchuan Yang,Deqing Fu,Spencer Hong,Erin Babinsky,Alfy Samuel,Anoop Kumar,Robin Jia,Sai Praneeth Karimireddy*

Main category: cs.CL

TL;DR: 本文提出了一种名为EPSVec的差分隐私合成文本生成方法，在保护敏感数据隐私的同时高效地产生高质量合成数据，极大降低了所需资源和计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有合成敏感数据的私有文本生成方法在效率和质量上存在不足，尤其是在可用数据有限或计算资源受限时。因此，作者希望设计一种高效、低资源、高隐私保障的合成数据生成方法。

Method: EPSVec方法利用*dataset vectors*（体现敏感数据和公共语料分布差异的激活向量方向），一次性提取并处理这些向量来引导大语言模型（LLM）生成文本。提取后的向量经过隐私保护处理，无需多次数据访问，然后采用标准解码方式反复生成合成数据，隐私开销不会随生成次数增加。此外，结合预训练基础模型和固定样例提示，提升了生成文本的多样性和质量。

Result: 实验表明，EPSVec在分布对齐和下游任务效用上超越了现有基线，尤其是在数据量少时优势明显。同时，其计算开销大幅降低。

Conclusion: EPSVec为隐私敏感数据生成高质量合成文本提供了一种高效、灵活的解决方案，兼具较强隐私保护、分布拟合和实际应用价值。

Abstract: High-quality data is essential for modern machine learning, yet many valuable corpora are sensitive and cannot be freely shared. Synthetic data offers a practical substitute for downstream development, and large language models (LLMs) have emerged as powerful engines for generating it. However, existing private text generation methods are severely inefficient: they are data-intensive, computationally slow, and often require large private corpora or batch sizes to achieve usable quality. We introduce EPSVec, a differentially-private lightweight alternative that steers LLM generation using *dataset vectors*--directions in activation space that capture the distributional gap between private data and public priors. EPSVec extracts and sanitizes steering vectors just once and then performs standard decoding. This decouples the privacy budget from generation, enabling arbitrarily many synthetic samples without additional privacy cost and yielding strong fidelity even in low-data regimes. Furthermore, we enhance our method by utilizing pretrained (base) models and introducing fixed-shot prompting to boost generation diversity and fidelity. Our experiments demonstrate that EPSVec outperforms existing baselines in distributional alignment and downstream utility, particularly in low-data regimes, while significantly reducing computational overhead.

</details>


### [39] [Reasoning-Based Personalized Generation for Users with Sparse Data](https://arxiv.org/abs/2602.21219)
*Bo Ni,Branislav Kveton,Samyadeep Basu,Subhojyoti Mukherjee,Leyao Wang,Franck Dernoncourt,Sungchul Kim,Seunghyun Yoon,Zichao Wang,Ruiyi Zhang,Puneet Mathur,Jihyung Kil,Jiuxiang Gu,Nedim Lipka,Yu Wang,Ryan A. Rossi,Tyler Derr*

Main category: cs.CL

TL;DR: 本文提出了GraSPer框架，通过图神经网络扩充用户稀疏历史，从而提升大语言模型在个性化生成任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 在现有个性化生成任务中，许多真实用户存在交互历史稀疏、上下文有限的问题，导致基于大模型的个性化效果不佳。

Method: GraSPer框架分三步：首先预测用户可能未来会互动的项目；其次利用推理生成文本，扩充用户历史语境；最后基于真实历史与合成历史生成个性化内容，确保生成与用户风格及偏好对齐。

Result: 在三个人工智能个性化生成基准数据集上，GraSPer实现了显著的性能提升，尤其在稀疏用户上下文下个性化能力显著提高。

Conclusion: GraSPer有效缓解了历史稀疏背景下的个性化生成难题，为大语言模型个性化应用提供了一条新路径。

Abstract: Large Language Model (LLM) personalization holds great promise for tailoring responses by leveraging personal context and history. However, real-world users usually possess sparse interaction histories with limited personal context, such as cold-start users in social platforms and newly registered customers in online E-commerce platforms, compromising the LLM-based personalized generation. To address this challenge, we introduce GraSPer (Graph-based Sparse Personalized Reasoning), a novel framework for enhancing personalized text generation under sparse context. GraSPer first augments user context by predicting items that the user would likely interact with in the future. With reasoning alignment, it then generates texts for these interactions to enrich the augmented context. In the end, it generates personalized outputs conditioned on both the real and synthetic histories, ensuring alignment with user style and preferences. Extensive experiments on three benchmark personalized generation datasets show that GraSPer achieves significant performance gain, substantially improving personalization in sparse user context settings.

</details>


### [40] [Field-Theoretic Memory for AI Agents: Continuous Dynamics for Context Preservation](https://arxiv.org/abs/2602.21220)
*Subhadip Mitra*

Main category: cs.CL

TL;DR: 该论文提出了一种基于场理论的AI记忆系统，能有效提升长文本推理、多轮会话和多智能体协作能力。


<details>
  <summary>Details</summary>
Motivation: 传统AI记忆系统多采用离散数据库存储，难以处理长期和多轮对话中的信息动态扩散与遗忘；作者希望借助物理场理论来构建更自然、动态的记忆机制。

Method: 该方法将记忆信息视为在语义空间中的连续场，由偏微分方程调控，涵盖了记忆的扩散、热力学衰减和多智能体场耦合。通过LoCoMo和LongMemEval两个公开基准，对多轮、超长会话及多人智能体场景进行评测。

Result: 在LongMemEval上，多轮推理F1提升116%，时序推理提升43.8%，知识更新召回率提升27.8%；多智能体场耦合实验中协作智能达99.8%以上。

Conclusion: 基于场理论的记忆系统能极大提升AI多轮推理及多智能体协作能力，对长文本、复杂场景适应性更出色。代码已开源。

Abstract: We present a memory system for AI agents that treats stored information as continuous fields governed by partial differential equations rather than discrete entries in a database. The approach draws from classical field theory: memories diffuse through semantic space, decay thermodynamically based on importance, and interact through field coupling in multi-agent scenarios. We evaluate the system on two established long-context benchmarks: LoCoMo (ACL 2024) with 300-turn conversations across 35 sessions, and LongMemEval (ICLR 2025) testing multi-session reasoning over 500+ turns. On LongMemEval, the field-theoretic approach achieves significant improvements: +116% F1 on multi-session reasoning (p<0.01, d= 3.06), +43.8% on temporal reasoning (p<0.001, d= 9.21), and +27.8% retrieval recall on knowledge updates (p<0.001, d= 5.00). Multi-agent experiments show near-perfect collective intelligence (>99.8%) through field coupling. Code is available at github.com/rotalabs/rotalabs-fieldmem.

</details>


### [41] [Task-Aware LoRA Adapter Composition via Similarity Retrieval in Vector Databases](https://arxiv.org/abs/2602.21222)
*Riya Adsul,Balachandra Devarangadi Sunil,Isha Nalawade,Sudharshan Govindan*

Main category: cs.CL

TL;DR: 提出了一种动态合成LoRA适配器的新方法，通过向量数据库的相似性检索，实现多任务零样本泛化，无需重新训练即可高效组合特化适配器。


<details>
  <summary>Details</summary>
Motivation: 现有的参数高效微调方法（如LoRA）虽能高效适配单一任务，但难以在无需重新训练的情况下组合多个特化适配器来应对新任务。多任务场景下如果能动态合成已有适配器，将极大提升泛化与参数效率。

Method: 作者将22个NLP数据集（涵盖常识推理、问答、推理、情感分析）中的训练样本嵌入到向量数据库中，形成‘任务感知’数据库。推理时，检索出最相似的训练样本，通过核采样获得任务相似度分布，并据此用加权策略动态合成相关LoRA适配器。共考察了四种融合方式：线性、拼接、TIES和Magnitude Prune。

Result: 基于检索的融合方法在任务表现上达到或超越单独微调的特定任务适配器。线性合成方法在PIQA上得分70.95%、RTE上77.62%，远高于单任务基线（分别为46%与52%）。

Conclusion: 该方法无需额外训练检索器，也不需重新训练大模型，能高效、可解释地合成适配器，展示了基于检索的动态适配器融合在可扩展、多任务学习中的前景。

Abstract: Parameter efficient fine tuning methods like LoRA have enabled task specific adaptation of large language models, but efficiently composing multiple specialized adapters for unseen tasks remains challenging. We present a novel framework for dynamic LoRA adapter composition that leverages similarity retrieval in vector databases to enable zero-shot generalization across diverse NLP tasks. Our approach constructs a task-aware vector database by embedding training examples from 22 datasets spanning commonsense reasoning, question answering, natural language inference, and sentiment analysis. At inference time, we retrieve the most similar training examples, compute task similarity distributions via nucleus sampling, and dynamically merge relevant LoRA adapters using retrieval weighted fusion strategies. We evaluated four merging methods Linear, Concatenation, TIES, and Magnitude Prune demonstrating that our dataset centric retrieval approach often matches or exceeds the performance of individually fine-tuned task-specific adapters. Notably, Linear merging achieves 70.95% on PIQA and 77.62% on RTE, substantially outperforming single-task baselines (46% and 52%, respectively). Our framework requires no additional retriever training, operates with frozen embeddings, and enables efficient, interpretable adapter composition. These results suggest that retrieval based dynamic merging offers a promising direction for scalable, parameter-efficient multitask learning without requiring full model retraining for each new task.

</details>


### [42] [Measuring Pragmatic Influence in Large Language Model Instructions](https://arxiv.org/abs/2602.21223)
*Yilin Geng,Omri Abend,Eduard Hovy,Lea Frermann*

Main category: cs.CL

TL;DR: 本文研究了在提示大型语言模型（LLM）时，任务的表达方式（即语用框架）会如何影响模型的响应，并提出了一套新的分析方法来系统性地度量这种影响。结果表明，语用框架对模型的指令优先级分配有可预测和结构化的影响。


<details>
  <summary>Details</summary>
Motivation: 此前研究主要关注如何通过优化提示提升模型效果或将语境线索视为安全漏洞，但并未将语用框架本身作为指令遵循的可测量属性。因此，系统性地度量语用框架影响具有理论和实际意义。

Method: 作者提出了一个包含三大创新模块的框架：（1）指令-框架分解，将框架情境与任务内容相分离；（2）构建涵盖400种框架实例的分类体系，分为13种策略和4类机制；（3）基于优先级的测量方法，通过观察指令优先级的变化量化影响。在五种不同家族和规模的LLM上进行了实验。

Result: 不同语用框架导致模型指令优先级出现一致且结构化的变化，模型由原本中立状态转向更倾向于框架指令。这种影响在不同模型之间均有体现。

Conclusion: 语用框架是指令遵循系统中可度量且可预测的重要因素。对其理解和测量有助于更好地优化和控制大型语言模型的行为。

Abstract: It is not only what we ask large language models (LLMs) to do that matters, but also how we prompt. Phrases like "This is urgent" or "As your supervisor" can shift model behavior without altering task content. We study this effect as pragmatic framing, contextual cues that shape directive interpretation rather than task specification. While prior work exploits such cues for prompt optimization or probes them as security vulnerabilities, pragmatic framing itself has not been treated as a measurable property of instruction following. Measuring this influence systematically remains challenging, requiring controlled isolation of framing cues. We introduce a framework with three novel components: directive-framing decomposition separating framing context from task specification; a taxonomy organizing 400 instantiations of framing into 13 strategies across 4 mechanism clusters; and priority-based measurement that quantifies influence through observable shifts in directive prioritization. Across five LLMs of different families and sizes, influence mechanisms cause consistent and structured shifts in directive prioritization, moving models from baseline impartiality toward favoring the framed directive. This work establishes pragmatic framing as a measurable and predictable factor in instruction-following systems.

</details>


### [43] [Make Every Draft Count: Hidden State based Speculative Decoding](https://arxiv.org/abs/2602.21224)
*Yuetao Chen,Xuliang Wang,Xinzhou Zheng,Ming Li,Peng Wang,Hong Xu*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的系统，可以回收speculative decoding过程中被丢弃的草稿计算，从而高效提升大模型推理速度，并实现最高3.3倍的加速效果。


<details>
  <summary>Details</summary>
Motivation: 现有speculative decoding方法通过轻量draft model生成候选token并由目标模型并行验证，虽然提升了运算密度，但很多草稿token在验证后被丢弃，造成了计算浪费。作者希望通过回收这些被废弃的计算，进一步提升计算效率。

Method: 作者提出在hidden state层面进行自回归预测，并推迟token信息整合，从而使草稿hidden state不被错误token污染，实现hidden state的复用。具体包括：设计基于自回归hidden state的draft模型，增强可复用语义；设计高效的token注入机制和draft token树结构，使验证失败时能重新采样token；并优化系统，进一步减少设计带来的额外开销。

Result: 作者在各类基线下进行大量评测，提出的方法相比标准speculative decoding可实现最高3.3倍的推理加速。

Conclusion: 通过回收和复用被丢弃的草稿hidden state，本文的方法显著提高了大模型推理的硬件利用率与效率，对加速LLM在推理阶段的广泛应用具有实际意义。

Abstract: Speculative decoding has emerged as a pivotal technique to accelerate LLM inference by employing a lightweight draft model to generate candidate tokens that are subsequently verified by the target model in parallel. However, while this paradigm successfully increases the arithmetic intensity of memory-bound inference, it causes significant compute inefficiency: the majority of draft tokens fail verification and are discarded, resulting in waste of computation. Motivated by the goal of recollecting this wasted computation, we propose a novel system that transforms discarded drafts into reusable tokens. Our key insight is to perform auto-regressive prediction at the hidden states level and postpone the integrating token information after the hidden states generation, so the draft hidden states are not contaminated by incorrect tokens, enabling hidden state reuse. To implement such a system, first we introduce a draft model architecture based on auto-regressive hidden states, which preserves richer semantics than token-based drafters to facilitate draft repurposing. Second, we design an efficient token information injection mechanism that leverages our specialized draft model to construct high-quality draft token trees and enables resampling tokens from verification failures. Third, we eliminate the overhead hidden in our design to further maximize hardware utilization. We conducted extensive evaluations against various baselines, demonstrating up to a 3.3x speedup against standard speculative decoding.

</details>


### [44] [Architecture-Agnostic Curriculum Learning for Document Understanding: Empirical Evidence from Text-Only and Multimodal](https://arxiv.org/abs/2602.21225)
*Mohammed Hamdan,Vincenzo Dentamaro,Giuseppe Pirlo,Mohamed Cheriet*

Main category: cs.CL

TL;DR: 本文研究了逐步数据调度（curriculum learning）策略是否能提升不同结构的文档理解模型的训练效率。


<details>
  <summary>Details</summary>
Motivation: 随着模型规模不断扩大，训练开销巨大。如何通过更高效的数据调度策略减少训练时间和算力消耗，成为模型训练领域的重要问题。

Method: 作者采用逐步数据调度（逐步增加训练数据曝光比例：33%→67%→100%）策略，对比传统全数据训练方法，并在BERT（文本型）和LayoutLMv3（多模态）两种结构上，在FUNSD和CORD两个基准数据集上进行实验证明效果。为排除算力归因影响，还引入匹配算力的基线对比（Standard-7，控制总梯度更新次数）。

Result: 在FUNSD数据集上，BERT模型采用逐步调度比相同算力基线F1性能有显著提升（ΔF1=+0.023，统计显著），证明容量受限模型受益明显。而在多模态LayoutLMv3模型上没有类似提升，推测其编码能力足够，无需课程策略。在CORD数据集上，不管调度方式如何，所有模型表现均接近满分（F1≥0.947），说明任务已到性能上限。此外，消融实验显示效率提升主要源于更少数据体积而非数据顺序。

Conclusion: 逐步数据调度是一种可靠的计算优化策略，其带来的'课程学习'额外收益依赖于模型容量及任务难度的关系。

Abstract: We investigate whether progressive data scheduling -- a curriculum learning strategy that incrementally increases training data exposure (33\%$\rightarrow$67\%$\rightarrow$100\%) -- yields consistent efficiency gains across architecturally distinct document understanding models. By evaluating BERT (text-only, 110M parameters) and LayoutLMv3 (multimodal, 126M parameters) on the FUNSD and CORD benchmarks, we establish that this schedule reduces wall-clock training time by approximately 33\%, commensurate with the reduction from 6.67 to 10.0 effective epoch-equivalents of data. To isolate curriculum effects from compute reduction, we introduce matched-compute baselines (Standard-7) that control for total gradient updates. On the FUNSD dataset, the curriculum significantly outperforms the matched-compute baseline for BERT ($Δ$F1 = +0.023, $p=0.022$, $d_z=3.83$), constituting evidence for a genuine scheduling benefit in capacity-constrained models. In contrast, no analogous benefit is observed for LayoutLMv3 ($p=0.621$), whose multimodal representations provide sufficient inductive bias. On the CORD dataset, all conditions converge to equivalent F1 scores ($\geq$0.947) irrespective of scheduling, indicating a performance ceiling. Schedule ablations comparing progressive, two-phase, reverse, and random pacing confirm that the efficiency gain derives from reduced data volume rather than ordering. Taken together, these findings demonstrate that progressive scheduling is a reliable compute-reduction strategy across model families, with curriculum-specific benefits contingent on the interaction between model capacity and task complexity.

</details>


### [45] [IslamicLegalBench: Evaluating LLMs Knowledge and Reasoning of Islamic Law Across 1,200 Years of Islamic Pluralist Legal Traditions](https://arxiv.org/abs/2602.21226)
*Ezieddin Elmahjub,Junaid Qadir,Abdullah Mushtaq,Rafay Naeem,Ibrahim Ghaznavi,Waleed Iqbal*

Main category: cs.CL

TL;DR: 本文提出了IslamicLegalBench，这是第一个针对不同伊斯兰法学派、涵盖各种复杂度任务的基准，用以系统评估大语言模型(LLMs)在伊斯兰法律推理方面的可靠性，实验发现现有模型存在显著知识缺陷和幻觉问题，特别是在中等复杂任务上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 随着数百万穆斯林用户使用GPT、Claude、DeepSeek等大语言模型获取宗教指导，如何确保AI在伊斯兰法推理中的可靠性成为一个亟需解决的问题。作者鉴于现有LLM评测缺乏面向伊斯兰法律的专门基准，提出设立IslamicLegalBench，以系统揭示AI在现实宗教应用中的表现和不足。

Method: 作者创建了IslamicLegalBench基准，覆盖7个伊斯兰法学派，13类任务组成的718个多样性实例，对9个主流LLM进行全面评估。评测重点关注模型的准确率、幻觉（错误生成内容比率）、对于虚假前提的识别能力，以及few-shot 提示对性能提升影响。

Result: 实验发现，最佳模型正确率仅为68%，而幻觉率高达21%；部分模型正确率甚至低于35%，幻觉率超过55%。在大多数few-shot条件下模型提升有限，仅2个模型提升超过1%。中等复杂度、需要精确知识的任务错误率最高，高复杂度任务中模型似乎在语义推理方面表现较强。对于带有错误前提的问题，6/9模型错误接受率超过40%，暴露出AI盲从风险。

Conclusion: 该工作首次提出系统化评估LLM伊斯兰法律推理的基准，明确指出当前主流大模型存在严重知识缺失和幻觉，且简单的提示工程难以弥补其基础认知缺陷。IslamicLegalBench为推动AI负责任地参与宗教指导提供了急需的评测框架和改进方向。

Abstract: As millions of Muslims turn to LLMs like GPT, Claude, and DeepSeek for religious guidance, a critical question arises: Can these AI systems reliably reason about Islamic law? We introduce IslamicLegalBench, the first benchmark evaluating LLMs across seven schools of Islamic jurisprudence, with 718 instances covering 13 tasks of varying complexity. Evaluation of nine state-of-the-art models reveals major limitations: the best model achieves only 68% correctness with 21% hallucination, while several models fall below 35% correctness and exceed 55% hallucination. Few-shot prompting provides minimal gains, improving only 2 of 9 models by >1%. Moderate-complexity tasks requiring exact knowledge show the highest errors, whereas high-complexity tasks display apparent competence through semantic reasoning. False premise detection indicates risky sycophancy, with 6 of 9 models accepting misleading assumptions at rates above 40%. These results highlight that prompt-based methods cannot compensate for missing foundational knowledge. IslamicLegalBench offers the first systematic framework to evaluate Islamic legal reasoning in AI, revealing critical gaps in tools increasingly relied on for spiritual guidance.

</details>


### [46] [Budget-Aware Agentic Routing via Boundary-Guided Training](https://arxiv.org/abs/2602.21227)
*Caiqi Zhang,Menglin Xia,Xuchao Zhang,Daniel Madrigal,Ankur Mallick,Samuel Kessler,Victor Ruehle,Saravan Rajmohan*

Main category: cs.CL

TL;DR: 本文提出了一种面向预算的智能体模型路由方法，能够在特定预算内在高效与成功率之间取得最佳平衡，并通过创新的训练策略提高整体效率。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型作为自主智能体变得流行，持续调用大模型的经济成本迅速增高，而现有的单步路由难以应对多步、路径依赖的问题，每步选择均对整体成功与花费产生深远影响。

Method: 提出了Budget-Aware Agentic Routing，在每一步根据预算动态选择廉价或昂贵模型，并设计了Boundary-Guided Training方法，通过构建总是选小/总是选大的策略边界，进行分层采样和边界参考奖励驱动的策略优化（BoPO），以引导学习过程，避免陷入只选便宜模型导致失败的问题。

Result: 实验证明，所提方法能够以显著更低成本达到与强基线方法相当的性能，并能更好地适应推理阶段严格的预算限制。

Conclusion: 该方法为智能体模型路由任务提供了基础性框架，把范式从静态模型选择转移到动态、预算感知的多步决策。

Abstract: As large language models (LLMs) evolve into autonomous agents that execute long-horizon workflows, invoking a high-capability model at every step becomes economically unsustainable. While model routing is effective for single-turn queries, agentic routing is a sequential, path-dependent problem: early mistakes compound, feedback is often at the end of the episode, and deployments often demand strict per-task spending limits. We propose Budget-Aware Agentic Routing, which selects between a cheap and an expensive model at each step to optimize the cost--success frontier and to operate under strict per-task budgets. We propose Boundary-Guided Training, which leverages two boundary policies (always-small vs.\ always-large) to build a difficulty taxonomy and to anchor learning under sparse rewards. Our approach warms start with boundary-guided SFT data synthesis via stratified sampling of cost-efficient trajectories, then applies Boundary-Guided Policy Optimization (BoPO), combining boundary-relative rewards with a reference-guided advantage to avoid degenerate cheap-failure solutions. Experiment results show that our method improves the efficiency frontier, matching strong routing baselines at substantially lower cost while demonstrating generalization to strict inference-time budget constraints. Overall, our work establishes a foundational framework for agentic routing, shifting the paradigm from static model selection to dynamic, budget-aware sequential decision-making.

</details>


### [47] [Structured Prompt Language: Declarative Context Management for LLMs](https://arxiv.org/abs/2602.21257)
*Wen G. Gong*

Main category: cs.CL

TL;DR: 本文提出了一种类似SQL的新型结构化提示语言SPL及其配套工具，简化大语言模型的调用、优化token资源管理，并集成RAG与持久化存储，支持多模型调度和高可用执行。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的prompt编写冗长，token管理困难，RAG与持久存储集成复杂，且跨模型/多模型调度与成本控制不方便。作者提出SQL风格的SPL，实现更高效、更具可维护性的prompt工程和pipeline调度。

Method: 设计并实现SPL语言和SPL-flow流水线扩展，结合token预算管理、自动优化（如EXPLAIN/EXPLAIN ANALYZE）、本地及云端执行一致性、多模型分发、逻辑文档拆分（Map-Reduce）、三层回退机制等功能，并提供配套Python包及实验对比。

Result: SPL可减少65%的prompt模板冗余，将attention成本从O(N^2)降至O(N^2/k)，通过提前展示模型分层成本实现68倍成本透视，可无修改地在云端或本地运行，脚本执行成本大幅降低（如OpenRouter为$0.002，本地为零）。

Conclusion: SPL及其扩展工具极大简化了大模型prompt工程，提高了token与成本利用率，增加了透明度与可用性，在多模型与pipeline场景下表现优越。

Abstract: We present SPL (Structured Prompt Language), a declarative SQL-inspired language that treats large language models as generative knowledge bases and their context windows as constrained resources. SPL provides explicit WITH BUDGET/LIMIT token management, an automatic query optimizer, EXPLAIN transparency analogous to SQL's EXPLAIN ANALYZE, and native integration of retrieval-augmented generation (RAG) and persistent memory in a single declarative framework. SPL-flow extends SPL into resilient agentic pipelines with a three-tier provider fallback strategy (Ollama -> OpenRouter -> self-healing retry) fully transparent to the .spl script. Five extensions demonstrate the paradigm's breadth: (1) Text2SPL (multilingual NL->SPL translation); (2) Mixture-of-Models (MoM) routing that dispatches each PROMPT to a domain-specialist model at runtime; (3) Logical Chunking, an intelligent strategy for documents exceeding a single context window--expressed naturally through SPL's existing CTE syntax with no new constructs, decomposing a large query into a Map-Reduce pipeline that reduces attention cost from O(N^2) to O(N^2/k) and runs identically on cloud (parallel) or local hardware (sequential); (4) SPL-flow, a declarative agentic orchestration layer with resilient three-tier provider fallback; and (5) BENCHMARK for parallel multi-model comparison with automatic winner persistence. We provide a formal EBNF grammar, two pip-installable Python packages (spl-llm, spl-flow), and comparison against Prompty, DSPy, and LMQL. SPL reduces prompt boilerplate by 65% on average, surfaces a 68x cost spread across model tiers as a pre-execution signal, and runs the identical .spl script at $0.002 on OpenRouter or at zero marginal cost on a local Ollama instance--without modification.

</details>


### [48] [Under the Influence: Quantifying Persuasion and Vigilance in Large Language Models](https://arxiv.org/abs/2602.21262)
*Sasha Robinson,Kerem Oktar,Katherine M. Collins,Ilia Sucholutsky,Kelsey R. Allen*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLMs）在高风险人类决策领域作为顾问时的劝说力与警觉性，并首次分析了这两种能力及任务执行能力之间的关系。结果显示，这三者在LLMs中是可区分的能力。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs逐步应用于高风险决策领域，有必要弄清它们作为顾问时可能带来的风险，尤其是如何区分和利用善意与恶意信息来影响用户决策。

Method: 作者设计了一个基于多轮推理解谜游戏（Sokoban）的实验，考察LLMs在劝说、警觉和任务表现上的能力，并研究它们之间的关系。实验还分析了模型对不同类型建议的信息处理和响应方式。

Result: 研究发现：1）LLMs的解谜能力、劝说能力和警觉性彼此独立，解题能力强不代表能有效识别误导；2）即使在提示存在欺骗的情况下，模型依然容易被误导；3）LLMs能根据建议的善恶性调整推理所用token数量，但仍可能被劝说做出错的决策。

Conclusion: LLMs的劝说力、警觉性和任务执行能力是相互独立、需分别监控的，确保AI安全时对此三种能力的独立评估和提升将十分关键。

Abstract: With increasing integration of Large Language Models (LLMs) into areas of high-stakes human decision-making, it is important to understand the risks they introduce as advisors. To be useful advisors, LLMs must sift through large amounts of content, written with both benevolent and malicious intent, and then use this information to convince a user to take a specific action. This involves two social capacities: vigilance (the ability to determine which information to use, and which to discard) and persuasion (synthesizing the available evidence to make a convincing argument). While existing work has investigated these capacities in isolation, there has been little prior investigation of how these capacities may be linked. Here, we use a simple multi-turn puzzle-solving game, Sokoban, to study LLMs' abilities to persuade and be rationally vigilant towards other LLM agents. We find that puzzle-solving performance, persuasive capability, and vigilance are dissociable capacities in LLMs. Performing well on the game does not automatically mean a model can detect when it is being misled, even if the possibility of deception is explicitly mentioned. % as part of the prompt. However, LLMs do consistently modulate their token use, using fewer tokens to reason when advice is benevolent and more when it is malicious, even if they are still persuaded to take actions leading them to failure. To our knowledge, our work presents the first investigation of the relationship between persuasion, vigilance, and task performance in LLMs, and suggests that monitoring all three independently will be critical for future work in AI safety.

</details>


### [49] [ToolMATH: A Math Tool Benchmark for Realistic Long-Horizon Multi-Tool Reasoning](https://arxiv.org/abs/2602.21265)
*Hyeonje Choi,Jeongsoo Lee,Hyojun Lee,Jay-Yoon Lee*

Main category: cs.CL

TL;DR: 本论文提出了一个名为\ToolMATH的数学基准，用于系统性评估支持工具调用的语言模型在多工具环境下的表现，突出模型在实际工具操作中的可靠性和弱点。


<details>
  <summary>Details</summary>
Motivation: 随着工具增强型语言模型（LLMs）日益被用于复杂推理和操作任务，现有基准很难揭示其面对庞杂工具环境时的真实能力与主要失效点，急需更严谨、更能反映实际多工具场景的评测基准。

Method: 作者构建\ToolMATH基准，将数学问题转化为工具调用流程，关注模型在大量重叠工具和缺失关键能力情况下的执行表现。基准有8000题、12000工具，并有更高难度集。通过实验分析失败模式、工具冗余、能力缺失与决策连贯性等因素。

Result: 评测发现，主要失效原因是推理能力不足导致中间结果误差累积且影响后续判断。工具列表冗余会放大早期微小偏差，造成执行不可逆漂移。缺失必要工具时，部分干扰工具可能成为替代，但也易造成模型偏离正轨。

Conclusion: 增强鲁棒性的关键不只在于单步操作的优化，而在于规划全局连贯性与观察的有纪律利用。\ToolMATH为发现工具增强模型关键薄弱点、改进控制机制提供了标准化、可诊断的评测基础。

Abstract: We introduce \ToolMATH, a math-grounded benchmark that evaluates tool-augmented language models in realistic multi-tool environments where the output depends on calling schema-specified tools and sustaining multi-step execution. It turns math problems into a controlled, correctness-checkable benchmark with tool sets, enabling systematic evaluation of model reliability under (1) large, overlapping tool catalogs and (2) the absence of the intended capability. \ToolMATH provides actionable diagnostic evidence of failure modes in tool-augmented agents, helping identify the control mechanisms required for robustness. \ToolMATH roughly contains 8k questions and 12k tools; we provide an additional hard-set \ToolMATHHard with questions and tools. Our evaluation reveals that the key failure factor is due to the inability to reason, leading to the accumulation of intermediate results' errors and constrain later decisions. Tool-list redundancy do not simply add noise, but amplify small early deviations into irreversible execution drift. The benchmark highlights that when the intended capability is missing, distractor tools can sometimes serve as partial substitutes in solution paths, yet they can also mislead models into ungrounded tool trajectories. Finally, comparisons between tool-use protocols emphasize that improvements come less from local action selection and more from long-range plan coherence and disciplined use of observations.

</details>


### [50] [Alignment-Weighted DPO: A principled reasoning approach to improve safety alignment](https://arxiv.org/abs/2602.21346)
*Mengxuan Hu,Vivek V. Datla,Anoop Kumar,Zihan Guan,Sheng Li,Alfy Samuel,Daben Liu*

Main category: cs.CL

TL;DR: 本文针对大语言模型（LLM）在面对间接、伪装式恶意指令时易被绕过的对齐问题，提出结合推理能力的对齐训练和更细粒度的损失加权方法，有效提升模型安全性与稳健性。


<details>
  <summary>Details</summary>
Motivation: 尽管现有如SFT、RLHF、DPO等主流安全对齐方法提升了LLM安全性，但其拒绝有害内容常流于表面，缺乏深层推理，导致仍易遭‘jailbreak’攻击绕过安全限制。

Method: 1）构建包含工具性和安全敏感问题的链式思考（CoT）数据集，为每个问题给出详细推理步骤；2）基于此数据集对模型进行微调，令其拒绝有害内容时能给出推理理由；3）提出Alignment-Weighted DPO方法，对输出的推理阶段与最终答案加权，聚焦最易出错部分，实现更有针对性的优化。

Result: 在多项安全和实用性基准上，采用推理增强微调和加权DPO的方法，模型表现出比标准SFT更强的拒绝恶意问题能力，同时保持整体效用。特别在应对多样化jailbreak攻击时，模型稳健性显著提升。

Conclusion: 通过将推理能力融入安全对齐训练并细化偏好优化，能够有效提升LLM对抗间接攻击的能力，为安全对齐方法提供更有力的技术路径。

Abstract: Recent advances in alignment techniques such as Supervised Fine-Tuning (SFT), Reinforcement Learning from Human Feedback (RLHF), and Direct Preference Optimization (DPO) have improved the safety of large language models (LLMs). However, these LLMs remain vulnerable to jailbreak attacks that disguise harmful intent through indirect or deceptive phrasing. Using causal intervention, we empirically demonstrate that this vulnerability stems from shallow alignment mechanisms that lack deep reasoning, often rejecting harmful prompts without truly understanding why they are harmful. To mitigate this vulnerability, we propose enhancing alignment through reasoning-aware post-training. We construct and release a novel Chain-of-Thought (CoT) fine-tuning dataset that includes both utility-oriented and safety-critical prompts with step-by-step rationales. Fine-tuning on this dataset encourages models to produce principled refusals grounded in reasoning, outperforming standard SFT baselines. Furthermore, inspired by failure patterns in CoT fine-tuning, we introduce Alignment-Weighted DPO, which targets the most problematic parts of an output by assigning different preference weights to the reasoning and final-answer segments. This produces finer-grained, targeted updates than vanilla DPO and improves robustness to diverse jailbreak strategies. Extensive experiments across multiple safety and utility benchmarks show that our method consistently improves alignment robustness while maintaining overall model utility.

</details>


### [51] [Small Language Models for Privacy-Preserving Clinical Information Extraction in Low-Resource Languages](https://arxiv.org/abs/2602.21374)
*Mohammadreza Ghaffarzadeh-Esfahani,Nahid Yousefian,Ebrahim Heidari-Farsani,Ali Akbar Omidvarian,Sepehr Ghahraei,Atena Farangi,AmirBahador Boroumand*

Main category: cs.CL

TL;DR: 本研究提出并评估了一种结合翻译和小型语言模型的流水线，用于从低资源语言（波斯语）医疗转录中抽取临床信息，结果显示该方法实用且具有较好表现。


<details>
  <summary>Details</summary>
Motivation: 许多低资源语言的医疗文本由于缺乏数据和工具，临床信息抽取十分困难。这直接影响了相关国家和群体精准医疗与数据利用的能力。作者希望利用开源大型翻译和小型语言模型，探索节省资源、保护隐私的自动化解决方案。

Method: 设计两步法流水线：首先将波斯语医疗转录文本用Aya-expanse-8B模型翻译为英文，然后用五个不同的小型开源语言模型对13个临床特征进行二分类抽取。采用few-shot提示，无需微调。评估标准包括宏平均F1、MCC、敏感性和特异性。

Result: Qwen2.5-7B-Instruct在宏F1（0.899）和MCC（0.797）表现最佳，大模型总体优于小模型。翻译至英语有助于提升灵敏性与抗类别不平衡指标，但精度与特异性略下降。对生理症状信息能稳定抽取，心理、管理请求及复杂体征较难。

Conclusion: 该方法为医疗NLP中低资源语言自动信息抽取提供了具可行性、隐私保护的蓝图，显示优化模型规模和输入语言策略对提升医疗敏感信息处理能力至关重要。

Abstract: Extracting clinical information from medical transcripts in low-resource languages remains a significant challenge in healthcare natural language processing (NLP). This study evaluates a two-step pipeline combining Aya-expanse-8B as a Persian-to-English translation model with five open-source small language models (SLMs) -- Qwen2.5-7B-Instruct, Llama-3.1-8B-Instruct, Llama-3.2-3B-Instruct, Qwen2.5-1.5B-Instruct, and Gemma-3-1B-it -- for binary extraction of 13 clinical features from 1,221 anonymized Persian transcripts collected at a cancer palliative care call center. Using a few-shot prompting strategy without fine-tuning, models were assessed on macro-averaged F1-score, Matthews Correlation Coefficient (MCC), sensitivity, and specificity to account for class imbalance. Qwen2.5-7B-Instruct achieved the highest overall performance (median macro-F1: 0.899; MCC: 0.797), while Gemma-3-1B-it showed the weakest results. Larger models (7B--8B parameters) consistently outperformed smaller counterparts in sensitivity and MCC. A bilingual analysis of Aya-expanse-8B revealed that translating Persian transcripts to English improved sensitivity, reduced missing outputs, and boosted metrics robust to class imbalance, though at the cost of slightly lower specificity and precision. Feature-level results showed reliable extraction of physiological symptoms across most models, whereas psychological complaints, administrative requests, and complex somatic features remained challenging. These findings establish a practical, privacy-preserving blueprint for deploying open-source SLMs in multilingual clinical NLP settings with limited infrastructure and annotation resources, and highlight the importance of jointly optimizing model scale and input language strategy for sensitive healthcare applications.

</details>


### [52] [Beyond Subtokens: A Rich Character Embedding for Low-resource and Morphologically Complex Languages](https://arxiv.org/abs/2602.21377)
*Felix Schneider,Maria Gogolev,Sven Sickert,Joachim Denzler*

Main category: cs.CL

TL;DR: 本文提出了一种基于字符的词向量计算方法，解决传统token化模型在处理形态丰富和低资源语言时的局限，并在多项任务上取得了优于传统方法的结果。


<details>
  <summary>Details</summary>
Motivation: 现有基于token及sub-token的NLP模型（如word2vec、BERT、GPT）不能充分捕捉正字法相似性和形态变化，特别是对高度屈折和低资源语言。

Method: 提出一种Transformer架构的Rich Character Embeddings（RCE），直接以字符级别计算词向量，并结合Transformer和卷积机制形成混合模型，兼具语义和句法信息。这些新型向量可无缝替换原有模型的词嵌入。

Result: 在SWAG、屈折语言的变格预测、隐喻和交错修辞检测等任务上，RCE方法在OddOneOut和TopK指标下超过了传统token化方法，尤其在数据有限条件下表现突出。

Conclusion: 基于字符的Rich Character Embeddings能更好应对形态复杂和低资源语言，有望提升大模型和小模型在相关NLP任务上的效果，是token化嵌入的有力替代方案。

Abstract: Tokenization and sub-tokenization based models like word2vec, BERT and the GPTs are the state-of-the-art in natural language processing. Typically, these approaches have limitations with respect to their input representation. They fail to fully capture orthographic similarities and morphological variations, especially in highly inflected and under-resource languages. To mitigate this problem, we propose to computes word vectors directly from character strings, integrating both semantic and syntactic information. We denote this transformer-based approach Rich Character Embeddings (RCE). Furthermore, we propose a hybrid model that combines transformer and convolutional mechanisms. Both vector representations can be used as a drop-in replacement for dictionary- and subtoken-based word embeddings in existing model architectures. It has the potential to improve performance for both large context-based language models like BERT and small models like word2vec for under-resourced and morphologically rich languages. We evaluate our approach on various tasks like the SWAG, declension prediction for inflected languages, metaphor and chiasmus detection for various languages. Our experiments show that it outperforms traditional token-based approaches on limited data using OddOneOut and TopK metrics.

</details>


### [53] [RuCL: Stratified Rubric-Based Curriculum Learning for Multimodal Large Language Model Reasoning](https://arxiv.org/abs/2602.21628)
*Yukun Chen,Jiaming Li,Longze Chen,Ze Gong,Jingpeng Li,Zhen Qin,Hengyu Chang,Ancheng Xu,Zhihao Yang,Hamid Alinejad-Rokny,Qiang Qu,Bo Zheng,Min Yang*

Main category: cs.CL

TL;DR: 本论文提出了一种新的课程学习框架（RuCL），通过动态调整评分标准，引导多模态大模型从基础到高级逐步提升推理能力，在视觉推理基准测试上显著超越现有模型。


<details>
  <summary>Details</summary>
Motivation: 以往基于奖励的强化学习方法存在奖励黑客问题，模型容易学到非真实的推理方式；而细粒度评分（rubric）虽可改善监督效果，但会导致高昂的计算成本和训练效率低下。本研究希望解决如何在多模态大模型推理任务中，既高效又有效地引导模型获得更真实的推理能力。

Method: 作者提出分层评分课程学习（RuCL）框架。其核心思想为：1）自动生成通用rubric以广泛适用；2）根据模型能力将rubric分层；3）训练中动态调整不同rubric的权重，让模型从易到难逐步学习，先掌握基础感知再攻克高级逻辑推理。该方法针对rubric的设计和利用进行创新，而非仅仅筛选数据。

Result: 在多个视觉推理任务上，RuCL方法相比Qwen2.5-VL-7B模型平均提升7.83%，达到60.06%的业界最新准确率。

Conclusion: 分层rubric课程学习能有效缓解奖励黑客问题，提升多模态大语言模型推理能力且训练更高效，为相关领域带来新的方法范式。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a prevailing paradigm for enhancing reasoning in Multimodal Large Language Models (MLLMs). However, relying solely on outcome supervision risks reward hacking, where models learn spurious reasoning patterns to satisfy final answer checks. While recent rubric-based approaches offer fine-grained supervision signals, they suffer from high computational costs of instance-level generation and inefficient training dynamics caused by treating all rubrics as equally learnable. In this paper, we propose Stratified Rubric-based Curriculum Learning (RuCL), a novel framework that reformulates curriculum learning by shifting the focus from data selection to reward design. RuCL generates generalized rubrics for broad applicability and stratifies them based on the model's competence. By dynamically adjusting rubric weights during training, RuCL guides the model from mastering foundational perception to tackling advanced logical reasoning. Extensive experiments on various visual reasoning benchmarks show that RuCL yields a remarkable +7.83% average improvement over the Qwen2.5-VL-7B model, achieving a state-of-the-art accuracy of 60.06%.

</details>


### [54] [Sparsity Induction for Accurate Post-Training Pruning of Large Language Models](https://arxiv.org/abs/2602.21652)
*Minhao Jiang,Zhikai Li,Xuewen Liu,Jing Zhang,Mengjuan Chen,Qingyi Gu*

Main category: cs.CL

TL;DR: 本论文提出了一种在剪枝前提升模型稀疏性的“Sparsity Induction”方法，有效提升大语言模型参数稀疏度，从而提高模型剪枝后的性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型参数规模巨大，导致计算和存储消耗过高。虽然训练后稀疏化（PTS）可以减小模型规模，但直接剪枝会破坏模型状态，难以恢复性能，需要更好的稀疏化技术。

Method: 在剪枝前，通过分布级和特征级两个维度提升模型稀疏性。分布级利用可吸收的缩放变换提升分布稀疏性，不引入额外参数或推断时开销。特征级则引入谱范数损失，从低秩角度促进特征稀疏化。

Result: 在多种模型架构和任务上实验表明，该方法使模型更易于剪枝，实现了比现有方法更好的剪枝性能。

Conclusion: 通过在剪枝前诱导模型实现更高稀疏性，可以突破当前PTS方法的性能瓶颈，提高大语言模型剪枝后的恢复能力与实际应用价值。

Abstract: Large language models have demonstrated capabilities in text generation, while their increasing parameter scales present challenges in computational and memory efficiency. Post-training sparsity (PTS), which reduces model cost by removing weights from dense networks, is an effective approach. However, native dense matrices lack high sparsity, making existing approaches that directly remove weights disrupt model states, resulting in unsatisfactory performance recovery even with post-tuning. We propose Sparsity Induction, which promotes models toward higher sparsity at both distribution and feature levels before pruning, to push the limits of PTS. At the distribution level, we enhance distributional sparsity through mathematically equivalent scaling transformations, which are fully absorbable and incur no extra parameters or inference-time overhead. At the feature level, we introduce Spectral Norm Loss to promote feature sparsity from a low-rank perspective. Experiments across diverse model architectures and tasks demonstrate that our method further enhances sparsity-friendliness, achieving superior pruning performance over existing approaches.

</details>


### [55] [DWA-KD: Dual-Space Weighting and Time-Warped Alignment for Cross-Tokenizer Knowledge Distillation](https://arxiv.org/abs/2602.21669)
*Duc Trung Vu,Pham Khanh Chi,Dat Phi Van,Linh Ngo Van,Sang Dinh,Trung Le*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的知识蒸馏方法DWA-KD，通过双空间权重调节和时序变形对齐，有效提升跨分词器蒸馏效果，实现更优的模型压缩。


<details>
  <summary>Details</summary>
Motivation: 现有的跨分词器知识蒸馏方法在序列和词表对齐方面存在不足，导致蒸馏效果受限。为此，作者希望改进对齐机制，提升压缩后学生模型的效果。

Method: 1）在token层面，DWA-KD将教师模型和学生模型的表示映射到对方空间，通过双空间KL散度蒸馏，并对学生不确定、教师自信的位置提高权重，聚焦信息量大的token。2）在序列层面，利用Soft Dynamic Time Warping在嵌入层和最终隐藏状态层对齐，实现词汇和语义层面的精确匹配。

Result: 在多个NLP基准任务上，DWA-KD都优于现有主流知识蒸馏基线方法。消融实验显示，基于信息熵的权重机制和Soft-DTW对齐在提升性能上各有贡献，二者互补。

Conclusion: DWA-KD通过改进token权重机制和序列对齐方法，有效提升了知识蒸馏在跨分词器环境下的性能，是压缩大语言模型的有前景方法。

Abstract: Knowledge Distillation (KD) has emerged as a crucial technique for compressing Large Language Models (LLMs). Although existing cross-tokenizer KD methods have made notable progress, their effectiveness remains constrained by suboptimal alignment across sequence and vocabulary levels. To address these limitations, we introduce Dual-Space Weighting and Time-Warped Alignment (DWA-KD), a novel cross-tokenizer distillation framework that enhances token-wise distillation through dual-space entropy-based weighting and achieves precise sequence-level alignment by leveraging both lexical and semantic information. At the token level, DWA-KD maps teacher representations into the student space and vice versa, performing dual-space KD via Kullback-Leibler divergence (KL). The process is modulated by dual-space weights that up-weight tokens where the student is uncertain and the teacher is confident, thereby focusing learning on informative tokens rather than treating all positions equally. At the sequence level, DWA-KD applies Soft Dynamic Time Warping (Soft-DTW) to both the embedding and final hidden-state layers, enabling robust alignment of lexical and contextual semantics between teacher and student sequences. Extensive experiments across diverse NLP benchmarks demonstrate that DWA-KD outperforms state-of-the-art KD baselines, while ablation studies confirm the complementary contributions of entropy-based token weighting and embedding and final hidden state layer Soft-DTW alignment.

</details>


### [56] [D-COT: Disciplined Chain-of-Thought Learning for Efficient Reasoning in Small Language Models](https://arxiv.org/abs/2602.21786)
*Shunsuke Ubukata*

Main category: cs.CL

TL;DR: 本文提出了一种结构化的思维链蒸馏方法D-CoT，通过在训练中引入控制标签，引导小模型更有效地模仿大模型的推理过程，实现了性能提升和Token消耗降低。


<details>
  <summary>Details</summary>
Motivation: 传统的思维链(CoT)从大模型向小模型蒸馏时，常导致小模型"过度思考"，带来性能下降和不必要的Token浪费。缺乏有效机制约束小模型如何推理是瓶颈。

Method: 提出Disciplined Chain-of-Thought (D-CoT) 框架，通过如<TEMP_LOW>（事实核查）、<TEMP_HIGH>（多视角探索）等控制标签，在训练期间引导推理结构，优化思维链轨迹，减少推理漂移。

Result: 在Qwen3-8B小模型上，仅用5,000训练样本，D-CoT在GPQA-diamond任务上提升准确率9.9%，在MMLU-Pro(0-shot)任务上提升9.1%，同时计算成本大幅下降。

Conclusion: D-CoT能够让小语言模型在无需推理控制标签的情况下，也内化该结构化思维方式，在推理和效率之间实现平衡。

Abstract: Chain-of-Thought (CoT) distillation from Large Language Models (LLMs) often induces "overthinking" in Small Language Models (SLMs), leading to performance degradation and excessive token consumption. In this study, we propose Disciplined Chain-of-Thought (D-CoT), a novel framework that enforces a structured reasoning process using control tags -- such as <TEMP_LOW> for fact-checking and <TEMP_HIGH> for multi-perspective exploration -- as auxiliary scaffolding during training. By optimizing the CoT trajectory, D-CoT suppresses reasoning drift and simultaneously achieves token reduction and performance improvement. We demonstrate the efficacy of our approach on Qwen3-8B: with only 5,000 training samples, D-CoT significantly boosts accuracy on GPQA-diamond by 9.9% and MMLU-Pro (0-shot) by 9.1%, while drastically reducing computational costs. Furthermore, we confirm that the model internalizes this disciplined thought structure, maintaining high performance even without explicit control tags during inference.

</details>


### [57] [Personalized Graph-Empowered Large Language Model for Proactive Information Access](https://arxiv.org/abs/2602.21862)
*Chia Cheng Chang,An-Zi Yen,Hen-Hsen Huang,Hsin-Hsi Chen*

Main category: cs.CL

TL;DR: 本论文提出了一种结合大语言模型与个人知识图谱的新型主动信息访问框架，用于帮助用户回忆遗忘的生活经历。实验表明，该方法高效识别遗忘事件，提升了用户回忆效率。


<details>
  <summary>Details</summary>
Motivation: 人们往往难以记住全部生活细节，常常遗忘或混淆事件，因此亟需一种智能化系统帮助辅助记忆。然而，现有的记忆回忆系统多依赖深度学习，需要大量训练且个人生命日志数据稀缺，造成应用受限。随着个人数据不断增长，系统需具备快速自适应能力。大语言模型近期在多领域表现出色，展现了其在个性化应用中的潜力。

Method: 作者提出了利用大语言模型与个人知识图谱相结合的框架，可主动访问并整合个人信息，通过优化的决策过程提升检测信息访问需求的能力。该框架具备高度灵活性，支持底层模型替换和事实检索方法迭代，持续提升性能。

Result: 实验结果显示，该方法在识别用户遗忘事件方面具有良好表现，能有效辅助用户回忆过往经历，效率高于传统方法。

Conclusion: 本文证明了结合大语言模型和个人知识图谱的主动信息访问框架在辅助记忆方面的有效性，为智能个性化回忆系统的发展提供了新思路。

Abstract: Since individuals may struggle to recall all life details and often confuse events, establishing a system to assist users in recalling forgotten experiences is essential. While numerous studies have proposed memory recall systems, these primarily rely on deep learning techniques that require extensive training and often face data scarcity due to the limited availability of personal lifelogs. As lifelogs grow over time, systems must also adapt quickly to newly accumulated data. Recently, large language models (LLMs) have demonstrated remarkable capabilities across various tasks, making them promising for personalized applications. In this work, we present a framework that leverages LLMs for proactive information access, integrating personal knowledge graphs to enhance the detection of access needs through a refined decision-making process. Our framework offers high flexibility, enabling the replacement of base models and the modification of fact retrieval methods for continuous improvement. Experimental results demonstrate that our approach effectively identifies forgotten events, supporting users in recalling past experiences more efficiently.

</details>


### [58] [ExpLang: Improved Exploration and Exploitation in LLM Reasoning with On-Policy Thinking Language Selection](https://arxiv.org/abs/2602.21887)
*Changjiang Gao,Zixian Huang,Kaichen Yang,Jiajun Chen,Jixing Li,Shujian Huang*

Main category: cs.CL

TL;DR: 本文提出了ExpLang方法，通过在大模型强化学习微调阶段引入多语言思维轨迹选择，提升了推理模型的多语言性能，并优于只用英语训练的基线。


<details>
  <summary>Details</summary>
Motivation: 当前大推理模型训练多以英文为主，忽略了多语言思维带来的潜在优势。全球用户需求其以本地语言思维进行推理，因此需开发多语言推理能力。

Method: 提出ExpLang，在强化学习后训练阶段，将多语言思维语言的选择作为策略空间中的行为，让模型在多语言环境下学习并探索更多语言带来的推理增益。

Result: 与仅用英语训练的模型相比，ExpLang在相同计算预算下表现更优；对已见和未见语言均有较高的思维语言遵循性，分析表明多语言选择增强了探索空间和非英语带来的利用优化。

Conclusion: ExpLang方法在多语言环境下强化了大推理模型，优于单语基线，对不同RL算法均有推广性，拓展了通过多语言提升推理能力的新方向。

Abstract: Current large reasoning models (LRMs) have shown strong ability on challenging tasks after reinforcement learning (RL) based post-training. However, previous work mainly focuses on English reasoning in expectation of the strongest performance, despite the demonstrated potential advantage of multilingual thinking, as well as the requirement for native thinking traces by global users. In this paper, we propose ExpLang, a novel LLM post-training pipeline that enables on-policy thinking language selection to improve exploration and exploitation during RL with the use of multiple languages. The results show that our method steadily outperforms English-only training with the same training budget, while showing high thinking language compliance for both seen and unseen languages. Analysis shows that, by enabling on-policy thinking language selection as an action during RL, ExpLang effectively extends the RL exploration space with diversified language preference and improves the RL exploitation outcome with leveraged non-English advantage. The method is orthogonal to most RL algorithms and opens up a new perspective on using multilinguality to improve LRMs.

</details>


### [59] [Large Language Models are Algorithmically Blind](https://arxiv.org/abs/2602.21947)
*Sohan Venkatesh,Ashish Mahendran Kurapath,Tejas Melkote*

Main category: cs.CL

TL;DR: 本文研究了大语言模型（LLMs）在理解和预测算法过程中的能力，并发现它们几乎完全失败，表现甚至不如随机猜测。


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs拥有丰富的知识，但它们是否能有效推理和指导算法选择尚不明确，这对于实际应用者至关重要。

Method: 以因果发现问题为测试场景，基于大规模算法实际执行数据，评估了8个主流LLMs在信心区间预测等方面的表现。

Result: 所有模型在多数情况下，预测区间远大于真实置信区间，但仍大多没有包含实际均值；大多数表现不如随机猜测，最好的模型也仅体现基准记忆，而非真实推理能力。

Conclusion: 作者提出“算法性盲点”概念，指出LLMs在宣告性算法知识与实际预测能力之间存在根本差距。

Abstract: Large language models (LLMs) demonstrate remarkable breadth of knowledge, yet their ability to reason about computational processes remains poorly understood. Closing this gap matters for practitioners who rely on LLMs to guide algorithm selection and deployment. We address this limitation using causal discovery as a testbed and evaluate eight frontier LLMs against ground truth derived from large-scale algorithm executions and find systematic, near-total failure. Models produce ranges far wider than true confidence intervals yet still fail to contain the true algorithmic mean in the majority of instances; most perform worse than random guessing and the marginal above-random performance of the best model is most consistent with benchmark memorization rather than principled reasoning. We term this failure algorithmic blindness and argue it reflects a fundamental gap between declarative knowledge about algorithms and calibrated procedural prediction.

</details>


### [60] [MEDSYN: Benchmarking Multi-EviDence SYNthesis in Complex Clinical Cases for Multimodal Large Language Models](https://arxiv.org/abs/2602.21950)
*Boqi Chen,Xudong Liu,Jiachuan Peng,Marianne Frey-Marti,Bang Zheng,Kyle Lam,Lin Li,Jianing Qiu*

Main category: cs.CL

TL;DR: 本文提出了MEDSYN, 一个多语言、多模态的复杂临床病例基准，用于评估多模态大语言模型(MLLMs)在真实临床场景下的诊断能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态医学基准未能反映真实临床复杂性。因此, 需要一个新基准衡量MLLMs在高度复杂临床病例下的表现，推动其实际应用。

Method: 开发MEDSYN基准，包括多语言、包含最多7种临床视觉证据类型的复杂病例。以临床工作流为蓝本，评测18款MLLMs在鉴别诊断和最终诊断任务的表现，并进行消融实验，提出证据敏感性指标量化跨模态证据利用的能力。

Result: 发现顶尖模型在鉴别诊断中可与甚至超过专家, 但在鉴别诊断到最终诊断的转换中远落后于专家，揭示模型在整合多源证据上存在盲点。过度依赖文本证据与跨模态利用能力弱是其主要原因。证据敏感性与诊断准确度高度相关。

Conclusion: MLLMs虽然对部分任务表现出色, 但在复杂证据综合能力上明显欠缺。证据敏感性可作为改进目标。所开发的基准与评测工具将公开，助力社区提升医学多模态AI的诊断实用性。

Abstract: Multimodal large language models (MLLMs) have shown great potential in medical applications, yet existing benchmarks inadequately capture real-world clinical complexity. We introduce MEDSYN, a multilingual, multimodal benchmark of highly complex clinical cases with up to 7 distinct visual clinical evidence (CE) types per case. Mirroring clinical workflow, we evaluate 18 MLLMs on differential diagnosis (DDx) generation and final diagnosis (FDx) selection. While top models often match or even outperform human experts on DDx generation, all MLLMs exhibit a much larger DDx--FDx performance gap compared to expert clinicians, indicating a failure mode in synthesis of heterogeneous CE types. Ablations attribute this failure to (i) overreliance on less discriminative textual CE ($\it{e.g.}$, medical history) and (ii) a cross-modal CE utilization gap. We introduce Evidence Sensitivity to quantify the latter and show that a smaller gap correlates with higher diagnostic accuracy. Finally, we demonstrate how it can be used to guide interventions to improve model performance. We will open-source our benchmark and code.

</details>


### [61] [Dynamic Personality Adaptation in Large Language Models via State Machines](https://arxiv.org/abs/2602.22157)
*Leon Pielage,Ole Hätscher,Mitja Back,Bernhard Marschall,Benjamin Risse*

Main category: cs.CL

TL;DR: 本文提出了一种与模型无关的动态人格模拟框架，通过动态调整的人格状态实现对对话个性表达的自适应调控，并在医学教育情境下验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型在多轮互动和复杂对话中，难以根据对话动态灵活调整其人格表达，影响了实际应用中的交互表现和用户体验。

Method: 作者设计了一个人格状态机，用状态转换概率动态适应对话环境，并提出了模块化的人格连续评分管道，将对话内容沿潜在人格维度进行评分。这些得分作为动态状态变量指导系统提示，实现人格行为的动态对齐。该方法既与具体人格模型、维度、状态转移机制无关，也和所用LLM无关。应用时采用了“人际圆环”（IPC）模型，并以医疗教育为实验场景。

Result: 系统能根据用户输入成功调整自己的“人格状态”，还能够影响用户行为，提升去激化培训效果。采用轻量化、微调分类器时，评分管道的精度基本不劣于大型LLM。

Conclusion: 该工作验证了模块化、人格自适应对话系统的可行性，对教育、客服和更广的人机互动领域都有应用潜力。

Abstract: The inability of Large Language Models (LLMs) to modulate their personality expression in response to evolving dialogue dynamics hinders their performance in complex, interactive contexts. We propose a model-agnostic framework for dynamic personality simulation that employs state machines to represent latent personality states, where transition probabilities are dynamically adapted to the conversational context. Part of our architecture is a modular pipeline for continuous personality scoring that evaluates dialogues along latent axes while remaining agnostic to the specific personality models, their dimensions, transition mechanisms, or LLMs used. These scores function as dynamic state variables that systematically reconfigure the system prompt, steering behavioral alignment throughout the interaction.We evaluate this framework by operationalizing the Interpersonal Circumplex (IPC) in a medical education setting. Results demonstrate that the system successfully adapts its personality state to user inputs, but also influences user behavior, thereby facilitating de-escalation training. Notably, the scoring pipeline maintains comparable precision even when utilizing lightweight, fine-tuned classifiers instead of large-scale LLMs. This work demonstrates the feasibility of modular, personality-adaptive architectures for education, customer support, and broader human-computer interaction.

</details>


### [62] [DySCO: Dynamic Attention-Scaling Decoding for Long-Context LMs](https://arxiv.org/abs/2602.22175)
*Xi Ye,Wuwei Zhang,Fangcong Yin,Howard Yen,Danqi Chen*

Main category: cs.CL

TL;DR: 本文提出了一种名为DySCO的新型解码算法，无需重新训练即可提升各种语言模型在超长文本推理任务中的表现，尤其显著提升长上下文理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型虽然支持较长的上下文窗口，但随着输入长度增加，模型推理准确率大幅下降，原因在于模型难以持续关注最相关的信息。

Method: DySCO通过在模型内指定部分注意力头作为检索头，定位并上调每步解码时与任务相关的重要token，从而动态调整生成过程中的注意力分配。该方法无需重新训练，可直接用于各种现有语言模型。

Result: 在多个长上下文推理基准测试（如MRCR和LongBenchV2 128K）上，DySCO显著提升模型性能，部分场景下相对提升达25%，且仅需很小的计算开销。

Conclusion: DySCO为长文本推理场景提供了一种高效、可解释性强、完全免训练的新解法，对理解及改进长上下文注意力机制具有重要参考价值。

Abstract: Understanding and reasoning over long contexts is a crucial capability for language models (LMs). Although recent models support increasingly long context windows, their accuracy often deteriorates as input length grows. In practice, models often struggle to keep attention aligned with the most relevant context throughout decoding. In this work, we propose DySCO, a novel decoding algorithm for improving long-context reasoning. DySCO leverages retrieval heads--a subset of attention heads specialized for long-context retrieval--to identify task-relevant tokens at each decoding step and explicitly up-weight them. By doing so, DySCO dynamically adjusts attention during generation to better utilize relevant context. The method is training-free and can be applied directly to any off-the-shelf LMs. Across multiple instruction-tuned and reasoning models, DySCO consistently improves performance on challenging long-context reasoning benchmarks, yielding relative gains of up to 25% on MRCR and LongBenchV2 at 128K context length with modest additional compute. Further analysis highlights the importance of both dynamic attention rescaling and retrieval-head-guided selection for the effectiveness of the method, while providing interpretability insights into decoding-time attention behavior. Our code is available at https://github.com/princeton-pli/DySCO.

</details>


### [63] [LiCQA : A Lightweight Complex Question Answering System](https://arxiv.org/abs/2602.22182)
*Sourav Saha,Dwaipayan Roy,Mandar Mitra*

Main category: cs.CL

TL;DR: 本文介绍了LiCQA，这是一种无监督的问答系统模型，可有效解答答案分布于多文档的复杂问题，并在基准数据上的表现优于两种最新主流系统。


<details>
  <summary>Details</summary>
Motivation: 尽管问答系统取得进展，但处理复杂、跨多文档问题依然困难。当前主流方法依赖知识图谱或昂贵的神经模型，存在资源消耗大、对大量训练数据依赖强等问题。作者希望探索无需大量标注和昂贵训练的有效解法。

Method: 提出了一种新的无监督问答模型LiCQA，主要利用语料证据而非知识图谱或深度神经网络，无需监督数据。并将其与两种不同原理的最新问答系统从效果和效率两个维度进行对比实验。

Result: 实验结果表明，LiCQA在基准任务上不仅效果显著优于两种主流系统，还大幅降低了系统延迟，提高了运行效率。

Conclusion: LiCQA展示了无需大规模训练即可解决复杂问答问题的实用性和高效性，适合资源有限或现场部署，对未来问答系统设计有指导意义。

Abstract: Over the last twenty years, significant progress has been made in designing and implementing Question Answering (QA) systems. However, addressing complex questions, the answers to which are spread across multiple documents, remains a challenging problem. Recent QA systems that are designed to handle complex questions work either on the basis of knowledge graphs, or utilise contem- porary neural models that are expensive to train, in terms of both computational resources and the volume of training data required. In this paper, we present LiCQA, an unsupervised question answer- ing model that works primarily on the basis of corpus evidence. We empirically compare the effectiveness and efficiency of LiCQA with two recently presented QA systems, which are based on different underlying principles. The results of our experiments show that LiCQA significantly outperforms these two state-of-the-art systems on benchmark data with noteworthy reduction in latency.

</details>


### [64] [Improving Parametric Knowledge Access in Reasoning Language Models](https://arxiv.org/abs/2602.22193)
*Melody Ma,John Hewitt*

Main category: cs.CL

TL;DR: 该论文研究了语言模型在访问自身参数中的世界知识时的推理能力，并提出通过提示词和强化学习来提升其知识回溯能力。


<details>
  <summary>Details</summary>
Motivation: 目前语言模型在进行数学等需要推理的任务时表现良好，但在回忆或访问自身储存的世界知识时，推理能力却未被充分挖掘和利用。作者希望优化模型在访问自身知识上的推理能力，以提升其知识问答表现。

Method: 首先，作者通过实验发现，语言模型默认情况下在访问世界知识问题时并不会生成最佳推理路径；引入“step-by-step”推理提示词后，知识回忆有统计显著提升（但对数学无明显影响）。受此启发，作者使用世界知识问答任务（TriviaQA）作为可验证奖励，对模型进行强化学习，训练其更好地推理和访问参数中的知识，并在多个公开问答数据集上测试效果。

Result: 在TriviaQA数据集上，强化学习训练后模型性能提升9.9%，在Natural Questions、HotpotQA、SimpleQA、StrategyQA等数据集上也分别获得4.2%、2.1%、0.6%和3.0%的提升。

Conclusion: 当前推理型语言模型在参数知识调用方面训练不充分，但通过简单的训练方法（如增加推理提示与知识型强化学习），可以显著提升模型对自身世界知识的访问和推理能力。

Abstract: We study reasoning for accessing world knowledge stored in a language model's parameters. For example, recalling that Canberra is Australia's capital may benefit from thinking through major cities and the concept of purpose-built capitals. While reasoning language models are trained via reinforcement learning to produce reasoning traces on tasks such as mathematics, they may not reason well for accessing their own world knowledge. We first find that models do not generate their best world knowledge reasoning by default: adding a simple "think step-by-step" cue demonstrates statistically significant improvement in knowledge recall but not math. Motivated by this, we propose training models to reason over their parametric knowledge using world-knowledge question answering as a verifiable reward. After reinforcement learning on TriviaQA (+9.9%), performance also improves on Natural Questions, HotpotQA, SimpleQA, and StrategyQA by 4.2%, 2.1%, 0.6%, and 3.0%, respectively. Reasoning models are under-optimized for parametric knowledge access, but can be easily trained to reason better.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [65] [Cross domain Persistent Monitoring for Hybrid Aerial Underwater Vehicles](https://arxiv.org/abs/2602.21259)
*Ricardo B. Grando,Victor A. Kich,Alisson H. Kolling,Junior C. D. Jesus,Rodrigo S. Guerra,Paulo L. J. Drews-Jr*

Main category: cs.RO

TL;DR: 本文提出了一种结合深度强化学习（DRL）与迁移学习的方法，使混合空中-水下无人机（HUAUV）能够在空中和水下环境中持续自主监测。


<details>
  <summary>Details</summary>
Motivation: HUAUV能够在空中和水下运行，应用前景广泛，但由于空气和水域动力学差异，研发高效方法面临挑战，尤其是在两域自适应能力方面。

Method: 采用共享的深度强化学习结构，同时利用Lidar（空中）和声呐（水下）传感器数据进行训练，通过迁移学习实现策略在两个不同域的适应与统一。

Result: 实验结果表明，该方法能够有效应对环境不确定性和多目标动态，实现了统一策略在空中与水下环境的可行性。

Conclusion: 提出的基于DRL的监测框架为混合空中-水下无人系统提供了可扩展、自主的持续监测解决方案，推动该领域应用和研究发展。

Abstract: Hybrid Unmanned Aerial Underwater Vehicles (HUAUVs) have emerged as platforms capable of operating in both aerial and underwater environments, enabling applications such as inspection, mapping, search, and rescue in challenging scenarios. However, the development of novel methodologies poses significant challenges due to the distinct dynamics and constraints of the air and water domains. In this work, we present persistent monitoring tasks for HUAUVs by combining Deep Reinforcement Learning (DRL) and Transfer Learning to enable cross-domain adaptability. Our approach employs a shared DRL architecture trained on Lidar sensor data (on air) and Sonar data (underwater), demonstrating the feasibility of a unified policy for both environments. We further show that the methodology presents promising results, taking into account the uncertainty of the environment and the dynamics of multiple mobile targets. The proposed framework lays the groundwork for scalable autonomous persistent monitoring solutions based on DRL for hybrid aerial-underwater vehicles.

</details>


### [66] [Dual-Branch INS/GNSS Fusion with Inequality and Equality Constraints](https://arxiv.org/abs/2602.21266)
*Mor Levenhar,Itzik Klein*

Main category: cs.RO

TL;DR: 针对城市中卫星信号遮挡导致车辆导航不可靠的问题，提出了一种结合等式与不等式运动约束的新型信息辅助融合方法，通过方差加权的方案提升了导航系统的抗漂移和稳健性，无需额外传感器或硬件，仅需软件修改。


<details>
  <summary>Details</summary>
Motivation: 城市环境下，卫星信号往往被高楼等基础设施遮挡，导致依赖低成本惯性传感器和卫星的车辆导航系统出现严重的累计误差。现有的非完整约束等信息辅助方法对车辆运动强加刚性等式假设，但实际城市交通下这种假设易被违反，导致辅助效果变弱。鉴于此，作者旨在提出一种更灵活和健壮的信息辅助策略。

Method: 作者提出了“双分支信息辅助框架”，既融合等式运动约束（如传统非完整约束），又引入物理驱动的不等式约束，通过方差加权策略将两类约束自适应结合，仅需对现有导航滤波器的软件进行调整，无需增加新硬件或传感器。该方法在四个公开城市数据集上验证，涵盖各种惯性传感器、道路及动态场景。

Result: 实验结果显示：在全部GNSS（卫星信号）可用情况下，相较传统非完整约束方法，垂直定位误差降低了16.7%，高度精度提升了50.1%；在GNSS不可用时，垂直漂移减少24.2%，高度精度提升20.2%。全面覆盖4.3小时数据，传感器、环境多样。

Conclusion: 只需改进软件，采用物理驱动的不等式替代硬性等式运动假设，就能实质性提升城市导航系统的抗漂移能力及稳健性，无须任何额外硬件、地图数据或深度学习模型，是切实可行且零成本的优化方案。

Abstract: Reliable vehicle navigation in urban environments remains a challenging problem due to frequent satellite signal blockages caused by tall buildings and complex infrastructure. While fusing inertial reading with satellite positioning in an extended Kalman filter provides short-term navigation continuity, low-cost inertial sensors suffer from rapid error accumulation during prolonged outages. Existing information aiding approaches, such as the non-holonomic constraint, impose rigid equality assumptions on vehicle motion that may be violated under dynamic urban driving conditions, limiting their robustness precisely when aiding is most needed. In this paper, we propose a dual-branch information aiding framework that fuses equality and inequality motion constraints through a variance-weighted scheme, requiring only a software modification to an existing navigation filter with no additional sensors or hardware. The proposed method is evaluated on four publicly available urban datasets featuring various inertial sensors, road conditions, and dynamics, covering a total duration of 4.3 hours of recorded data. Under Full GNSS availability, the method reduces vertical position error by 16.7% and improves altitude accuracy by 50.1% over the standard non-holonomic constraint. Under GNSS-denied conditions, vertical drift is reduced by 24.2% and altitude accuracy improves by 20.2%. These results demonstrate that replacing hard motion equality assumptions with physically motivated inequality bounds is a practical and cost-free strategy for improving navigation resilience, continuity, and drift robustness without relying on additional sensors, map data, or learned models.

</details>


### [67] [Learning Deformable Object Manipulation Using Task-Level Iterative Learning Control](https://arxiv.org/abs/2602.21302)
*Krishna Suresh,Chris Atkeson*

Main category: cs.RO

TL;DR: 本文提出了一种用于可变形物体动态操作的任务级迭代学习控制方法，通过在硬件上直接学习，无需大量示范或仿真，能够让机器人高效地掌握复杂绳索动作（如飞结）操作。方法在多种不同类型的绳索上快速实现高成功率，且具备良好的迁移能力。


<details>
  <summary>Details</summary>
Motivation: 可变形物体（如绳索）由于自由度无限且动力学欠驱动，动态操作极具挑战。现有方法常需大量数据、复杂建模与仿真，实际应用受限，因此需要一种更简洁、高效的机器人学习方法。

Method: 提出任务级迭代学习控制（Task-Level Iterative Learning Control），从单次人类演示与简化绳索模型出发，在真实硬件上反复试验。每次迭代通过解二次规划，将任务空间的误差反馈到动作修正中，逐步优化操作策略，无需依赖海量数据或仿真。

Result: 在7种不同类型的绳索（包括链条、乳胶管、多种编织和扭绳，直径7-25mm，密度0.013-0.5kg/m）上测试，所有绳索类型均能在10次以内学习动作，成功率100%。方法在不同类型绳索间迁移时，约2-5次试验即可适应。

Conclusion: 本方法简单高效，能在真实环境下通过有限次数的试验掌握复杂的可变形物体操作，而且具备很强的泛化和迁移能力，在实际机器人系统中有广阔的应用前景。

Abstract: Dynamic manipulation of deformable objects is challenging for humans and robots because they have infinite degrees of freedom and exhibit underactuated dynamics. We introduce a Task-Level Iterative Learning Control method for dynamic manipulation of deformable objects. We demonstrate this method on a non-planar rope manipulation task called the flying knot. Using a single human demonstration and a simplified rope model, the method learns directly on hardware without reliance on large amounts of demonstration data or massive amounts of simulation. At each iteration, the algorithm constructs a local inverse model of the robot and rope by solving a quadratic program to propagate task-space errors into action updates. We evaluate performance across 7 different kinds of ropes, including chain, latex surgical tubing, and braided and twisted ropes, ranging in thicknesses of 7--25mm and densities of 0.013--0.5 kg/m. Learning achieves a 100\% success rate within 10 trials on all ropes. Furthermore, the method can successfully transfer between most rope types in approximately 2--5 trials. https://flying-knots.github.io

</details>


### [68] [Unified Complementarity-Based Contact Modeling and Planning for Soft Robots](https://arxiv.org/abs/2602.21316)
*Milad Azizkhani,Yue Chen*

Main category: cs.RO

TL;DR: 本文提出了一种统一的互补约束（complementarity-based）方法CUSP，用于软体机器人接触建模、仿真与规划，克服接触建模中的约束冗余与病态问题，实现了物理一致的接触建模与动态路径优化。


<details>
  <summary>Details</summary>
Motivation: 软体机器人在与环境安全、适应性高的交互过程中高度依赖于接触，但传统的接触建模与规划方法容易出现冗余约束、秩亏线性互补问题(LCP)及高刚度-低摩擦带来的病态情况，限制了建模与规划效率与准确性。

Method: 文章提出一个针对离散化软体机器人的稳健LCP模型，并通过三阶段调理流程——惯性秩选择去除冗余接触、Ruiz平衡处理尺度失衡和病态、法向块轻量正则化——解决软体机器人接触建模中的核心难题。此外，引入运动学引导的加热启动策略，支持基于互补约束的动态轨迹优化。

Result: 该框架在接触丰富的抓球任务上进行了实验验证，证明其在统一处理接触建模、动态仿真和路径规划方面均表现出优良的稳健性与有效性。

Conclusion: CUSP为软体机器人接触建模、仿真与规划提供了一个统一、物理一致的新基础，有助于推动软体机器人在复杂环境下的实用应用。

Abstract: Soft robots were introduced in large part to enable safe, adaptive interaction with the environment, and this interaction relies fundamentally on contact. However, modeling and planning contact-rich interactions for soft robots remain challenging: dense contact candidates along the body create redundant constraints and rank-deficient LCPs, while the disparity between high stiffness and low friction introduces severe ill-conditioning. Existing approaches rely on problem-specific approximations or penalty-based treatments. This letter presents a unified complementarity-based framework for soft-robot contact modeling and planning that brings contact modeling, manipulation, and planning into a unified, physically consistent formulation. We develop a robust Linear Complementarity Problem (LCP) model tailored to discretized soft robots and address these challenges with a three-stage conditioning pipeline: inertial rank selection to remove redundant contacts, Ruiz equilibration to correct scale disparity and ill-conditioning, and lightweight Tikhonov regularization on normal blocks. Building on the same formulation, we introduce a kinematically guided warm-start strategy that enables dynamic trajectory optimization through contact using Mathematical Programs with Complementarity Constraints (MPCC) and demonstrate its effectiveness on contact-rich ball manipulation tasks. In conclusion, CUSP provides a new foundation for unifying contact modeling, simulation, and planning in soft robotics.

</details>


### [69] [CableRobotGraphSim: A Graph Neural Network for Modeling Partially Observable Cable-Driven Robot Dynamics](https://arxiv.org/abs/2602.21331)
*Nelson Chen,William R. Johnson,Rebecca Kramer-Bottiglio,Kostas Bekris,Mridul Aanjaneya*

Main category: cs.RO

TL;DR: 该论文提出了一种面向缆索驱动机器人的图神经网络（GNN）模拟器CableRobotGraphSim，可处理部分可观测输入，并与真实环境数据联合训练，实现快速精准的机器人动力学建模。


<details>
  <summary>Details</summary>
Motivation: 传统的基于物理原理的机器人模拟器要求全状态可观测或大量参数搜寻，难以处理实际中部分可观测或含噪声的数据，且对缆索驱动机器人尤其不便。

Method: 作者创新性地将缆索驱动机器人建模为图结构，将刚体作为节点，缆索及接触作为边，利用GNN进行动力学模拟。同时，引入仿真-真实联合训练过程增强泛化和抗噪声能力，并集成到MPPI控制器中实现闭环导航。

Result: 实验结果表明，该模型能在仅使用部分可观测输入的情况下，高效且准确地匹配其他模拟器和真实机器人的性能，且具备良好的速度、精度和泛化性。

Conclusion: CableRobotGraphSim模型突破了传统仿真器对全状态可观测的依赖，以图结构结合GNN和联合训练方式，实现了缆索驱动机器人面向仿真与真实环境的高效建模和控制。

Abstract: General-purpose simulators have accelerated the development of robots. Traditional simulators based on first-principles, however, typically require full-state observability or depend on parameter search for system identification. This work presents \texttt{CableRobotGraphSim}, a novel Graph Neural Network (GNN) model for cable-driven robots that aims to address shortcomings of prior simulation solutions. By representing cable-driven robots as graphs, with the rigid-bodies as nodes and the cables and contacts as edges, this model can quickly and accurately match the properties of other simulation models and real robots, while ingesting only partially observable inputs. Accompanying the GNN model is a sim-and-real co-training procedure that promotes generalization and robustness to noisy real data. This model is further integrated with a Model Predictive Path Integral (MPPI) controller for closed-loop navigation, which showcases the model's speed and accuracy.

</details>


### [70] [Environment-Aware Learning of Smooth GNSS Covariance Dynamics for Autonomous Racing](https://arxiv.org/abs/2602.21366)
*Y. Deemo Chen,Arion Zimmermann,Thomas A. Berrueta,Soon-Jo Chung*

Main category: cs.RO

TL;DR: 该论文提出了一种基于学习的方法，对GNSS测量协方差的时间动态进行建模，并在高动态无人车竞速环境下验证了其在提高定位精度和估算平滑性方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 在高速自主竞赛等安全关键领域，准确且稳定的状态估计至关重要。传统方法难以同时适应环境变化和保证协方差平滑。该研究旨在解决在GNSS测量不确定性高度耦合于控制灵敏度情况下，实现自适应且平滑的不确定性建模。

Method: 作者提出了LACE框架，将GNSS测量协方差的演化建模为指数稳定的动态系统。具体方法是通过一个深度神经网络，结合注意力机制，从环境特征中学习协方差过程噪声，并采用收缩性（contraction）理论和谱约束，确保动态系统的指数稳定和估算平滑性。

Result: 在AV-24无人赛车平台上进行了实验证明，LACE方法在GNSS信号退化和挑战性环境中，能显著提升定位性能，并输出更平滑的协方差序列，相较传统方法表现更优。

Conclusion: 动态建模状态估计中的感知不确定性在与控制紧密耦合的任务中具有很大优势。LACE方法展示了结合学习建模和动力学稳定理论在安全关键领域状态估计中取得的进展。

Abstract: Ensuring accurate and stable state estimation is a challenging task crucial to safety-critical domains such as high-speed autonomous racing, where measurement uncertainty must be both adaptive to the environment and temporally smooth for control. In this work, we develop a learning-based framework, LACE, capable of directly modeling the temporal dynamics of GNSS measurement covariance. We model the covariance evolution as an exponentially stable dynamical system where a deep neural network (DNN) learns to predict the system's process noise from environmental features through an attention mechanism. By using contraction-based stability and systematically imposing spectral constraints, we formally provide guarantees of exponential stability and smoothness for the resulting covariance dynamics. We validate our approach on an AV-24 autonomous racecar, demonstrating improved localization performance and smoother covariance estimates in challenging, GNSS-degraded environments. Our results highlight the promise of dynamically modeling the perceived uncertainty in state estimation problems that are tightly coupled with control sensitivity.

</details>


### [71] [Autonomous Sea Turtle Robot for Marine Fieldwork](https://arxiv.org/abs/2602.21389)
*Zach J. Patterson,Emily Sologuren,Levi Cai,Daniel Kim,Alaa Maalouf,Pascal Spino,Daniela Rus*

Main category: cs.RO

TL;DR: 该论文提出了一种仿海龟的自主水下机器人，能够在复杂水下环境中实现安全、自主的近距离监测和追踪生物，对珊瑚礁等敏感生态系统的自动化观测具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 现有的自主水下机器人难以在珊瑚礁等拥挤、复杂环境中近距离安全作业，需发展既能灵活运动又具有高级自主性的机器人，以实现对脆弱海洋生态系统的非侵入性监测。

Method: 设计并实现了一款结合软体与刚性机构、受海龟启发的自主机器人硬件，并开发了集成视觉驱动控制系统，具备深度-航向稳定、避障和目标跟踪能力。通过实验池和新英格兰水族馆活体珊瑚礁展区进行了多场景验证。

Result: 机器人在控制池和活体珊瑚礁展区都能稳定运行，实现对快速游动的海洋生物和人类潜水员的可靠追踪。在水族馆场景中无绳实验的避障成功率达91%，并提出了低计算资源的船载目标跟踪模式。

Conclusion: 该系统首次实现了结合创新仿生硬件、集成控制与实地验证的完整自主水下监测机器人，证明此类平台有望成为在敏感生态系统中进行低干扰、近距离监测和探索的实用解决方案。

Abstract: Autonomous robots can transform how we observe marine ecosystems, but close-range operation in reefs and other cluttered habitats remains difficult. Vehicles must maneuver safely near animals and fragile structures while coping with currents, variable illumination and limited sensing. Previous approaches simplify these problems by leveraging soft materials and bioinspired swimming designs, but such platforms remain limited in terms of deployable autonomy. Here we present a sea turtle-inspired autonomous underwater robot that closed the gap between bioinspired locomotion and field-ready autonomy through a tightly integrated, vision-driven control stack. The robot combines robust depth-heading stabilization with obstacle avoidance and target-centric control, enabling it to track and interact with moving objects in complex terrain. We validate the robot in controlled pool experiments and in a live coral reef exhibit at the New England Aquarium, demonstrating stable operation and reliable tracking of fast-moving marine animals and human divers. To the best of our knowledge, this is the first integrated biomimetic robotic system, combining novel hardware, control, and field experiments, deployed to track and monitor real marine animals in their natural environment. During off-tether experiments, we demonstrate safe navigation around obstacles (91\% success rate in the aquarium exhibit) and introduce a low-compute onboard tracking mode. Together, these results establish a practical route toward soft-rigid hybrid, bioinspired underwater robots capable of minimally disruptive exploration and close-range monitoring in sensitive ecosystems.

</details>


### [72] [Event-Driven On-Sensor Locomotion Mode Recognition Using a Shank-Mounted IMU with Embedded Machine Learning for Exoskeleton Control](https://arxiv.org/abs/2602.21418)
*Mohammadsaleh Razmi,Iman Shojaei*

Main category: cs.RO

TL;DR: 本论文提出了一种可穿戴的实时人体活动识别系统，直接在小腿IMU传感器内进行推理，用于下肢外骨骼的低延迟控制。该系统基于传感器级别的机器学习内核实现活动分类，相比传统方法大幅降低了能耗和计算资源占用。


<details>
  <summary>Details</summary>
Motivation: 当前下肢外骨骼中的人体活动识别通常需要不断将原始数据传输并在主控芯片上进行分类，导致能耗高、延迟高，不适合低功耗、高响应应用。希望通过在IMU传感器端直接完成识别，解决以上问题。

Method: 采用STMicroelectronics LSM6DSV16X IMU内嵌的机器学习核心（MLC），配置并部署轻量级决策树模型，通过ST MEMS Studio完成，无需在微控制器上运行自定义ML代码。系统专注于站立、平地行走和上楼梯三种活动模式，通过中断通知主控芯片何时读取分类结果。

Result: 系统仅在有动作或分类结果更新时唤醒主控芯片，极大降低了数据传输和处理带宽。实验表明，在区分平地行走和上楼梯等模式时，系统具有较高的鲁棒性和准确性，并提高了外骨骼助力控制的效率。

Conclusion: 传感器级实时推理技术减少了计算与通讯负载，降低了能耗，提高了活动识别的鲁棒性，非常适合于可穿戴外骨骼等实时控制应用，为低功耗、低延迟的人体活动识别系统提供了新方案。

Abstract: This work presents a wearable human activity recognition (HAR) system that performs real-time inference directly inside a shank-mounted inertial measurement unit (IMU) to support low-latency control of a lower-limb exoskeleton. Unlike conventional approaches that continuously stream raw inertial data to a microcontroller for classification, the proposed system executes activity recognition at the sensor level using the embedded Machine Learning Core (MLC) of the STMicroelectronics LSM6DSV16X IMU, allowing the host microcontroller to remain in a low-power state and read only the recognized activity label from IMU registers. While the system generalizes to multiple human activities, this paper focuses on three representative locomotion modes - stance, level walking, and stair ascent - using data collected from adult participants. A lightweight decision-tree model was configured and deployed for on-sensor execution using ST MEMS Studio, enabling continuous operation without custom machine learning code on the microcontroller. During operation, the IMU asserts an interrupt when motion or a new classification is detected; the microcontroller wakes, reads the MLC output registers, and forwards the inferred mode to the exoskeleton controller. This interrupt-driven, on-sensor inference architecture reduces computation and communication overhead while preserving battery energy and improving robustness in distinguishing level walking from stair ascent for torque-assist control.

</details>


### [73] [VLA Knows Its Limits](https://arxiv.org/abs/2602.21445)
*Haoxuan Wang,Gengyu Zhang,Yan Yan,Ramana Rao Kompella,Gaowen Liu*

Main category: cs.RO

TL;DR: 作者分析了flow-based视觉-语言-动作（VLA）模型中执行视界（action chunk执行步数）对性能的影响，提出并验证了一种自适应调整执行视界的新方法AutoHorizon。


<details>
  <summary>Details</summary>
Motivation: 虽然在VLA模型中以动作块（action chunk）为单位执行操作已成常规，但不同动作块长度对下游性能的影响和适应性机制尚未深入研究。

Method: 作者通过分析cross-和self-attention权重，揭示了动作块内部对视觉-语言信息关注的可变性及首末动作作为锚点的组织现象。基于此，提出了AutoHorizon方法，在每次推理时动态预测合适的执行步数（动作块长度），以更好地适应环境。

Result: 实验表明，AutoHorizon方法在机器人操作任务上取得了优良表现，几乎不增加计算量，并能普适于多种任务和不同的流式VLA模型。

Conclusion: 动态调整动作执行步数对于提升VLA模型适应性和性能至关重要，AutoHorizon为此提供了有效的解决方案。

Abstract: Action chunking has recently emerged as a standard practice in flow-based Vision-Language-Action (VLA) models. However, the effect and choice of the execution horizon - the number of actions to be executed from each predicted chunk - remains underexplored. In this work, we first show that varying the execution horizon leads to substantial performance deviations, with performance initially improving and then declining as the horizon increases. To uncover the reasons, we analyze the cross- and self-attention weights in flow-based VLAs and reveal two key phenomena: (i) intra-chunk actions attend invariantly to vision-language tokens, limiting adaptability to environmental changes; and (ii) the initial and terminal action tokens serve as stable anchors, forming latent centers around which intermediate actions are organized. Motivated by these insights, we interpret action self-attention weights as a proxy for the model's predictive limit and propose AutoHorizon, the first test-time method that dynamically estimates the execution horizon for each predicted action chunk to adapt to changing perceptual conditions. Across simulated and real-world robotic manipulation tasks, AutoHorizon is performant, incurs negligible computational overhead, and generalizes across diverse tasks and flow-based models.

</details>


### [74] [DexRepNet++: Learning Dexterous Robotic Manipulation with Geometric and Spatial Hand-Object Representations](https://arxiv.org/abs/2602.21811)
*Qingtao Liu,Zhengnan Sun,Yu Cui,Haoming Li,Gaofeng Li,Lin Shao,Jiming Chen,Qi Ye*

Main category: cs.RO

TL;DR: 该论文聚焦于多指灵巧手的操控任务，提出了一种新的手-物体交互表征DexRep，在多项操作技能上显著提升了泛化能力，特别是在多样化物体上取得了高成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法大都关注在高维动作空间中提升采样效率，而忽略了输入空间表征对策略泛化的重要性。该研究旨在通过更好的手-物体表征提升策略在复杂输入空间下的泛化能力。

Method: 提出DexRep表征方式，能够捕捉物体表面特征及手与物体的空间关系，并基于该表征分别学习了抓取、手内重新定向和双手传递三类灵巧操作任务的策略，并进行了大量仿真实验及现实世界测试。

Result: 在抓取任务中，基于DexRep仅用40种物体训练的策略在5000多种未见过的多类别物体上取得了87.9%的成功率，显著优于需数千物体训练的现有工作；在其他任务上也提升了现有表征方案的成功率20%到40%。抓取策略在真实环境下依然表现出较强的迁移能力。

Conclusion: DexRep作为新的手-物体交互表征，极大提升了操作策略在多任务与多物体环境下的泛化能力，并有效缩小了仿真到现实的落差。

Abstract: Robotic dexterous manipulation is a challenging problem due to high degrees of freedom (DoFs) and complex contacts of multi-fingered robotic hands. Many existing deep reinforcement learning (DRL) based methods aim at improving sample efficiency in high-dimensional output action spaces. However, existing works often overlook the role of representations in achieving generalization of a manipulation policy in the complex input space during the hand-object interaction. In this paper, we propose DexRep, a novel hand-object interaction representation to capture object surface features and spatial relations between hands and objects for dexterous manipulation skill learning. Based on DexRep, policies are learned for three dexterous manipulation tasks, i.e. grasping, in-hand reorientation, bimanual handover, and extensive experiments are conducted to verify the effectiveness. In simulation, for grasping, the policy learned with 40 objects achieves a success rate of 87.9% on more than 5000 unseen objects of diverse categories, significantly surpassing existing work trained with thousands of objects; for the in-hand reorientation and handover tasks, the policies also boost the success rates and other metrics of existing hand-object representations by 20% to 40%. The grasp policies with DexRep are deployed to the real world under multi-camera and single-camera setups and demonstrate a small sim-to-real gap.

</details>


### [75] [LiLo-VLA: Compositional Long-Horizon Manipulation via Linked Object-Centric Policies](https://arxiv.org/abs/2602.21531)
*Yue Yang,Shuo Cheng,Yu Fang,Homanga Bharadhwaj,Mingyu Ding,Gedas Bertasius,Daniel Szafir*

Main category: cs.RO

TL;DR: LiLo-VLA提出了一个模块化、泛化性强的机器人操作框架，实现了无需专门训练即可零样本泛化到新颖的长时序操作任务，在仿真和真实环境下均显著优于以往方法。


<details>
  <summary>Details</summary>
Motivation: 现有VLA（视觉-语言-动作）模型虽能掌握多种基础操作技能，但在复杂、长时序、多结构变化的任务中难以有效组合并易出现连续性失败，亟需一种能高效泛化且具鲁棒性的方案。

Method: 该文提出LiLo-VLA框架，将传递与交互任务解耦：全局运动由Reaching Module负责，物体操作由基于VLA的Interaction Module负责，并采取面向对象处理以过滤无关特征、提升空间配置不变性。模块化设计支持动态重规划和技能复用，从而提升出错后的恢复能力。

Result: 在21项长时序操纵仿真任务中，LiLo-VLA平均成功率达69%，明显超越Pi0.5（+41%）和OpenVLA-OFT（+67%）。于8个实际长时序任务上也取得85%的平均成功率。

Conclusion: LiLo-VLA通过模块化和面向对象的任务解耦，实现了对新颖长时序任务的零样本泛化和极高鲁棒性，并显著提升了机器人在仿真和现实场景下的成功率。

Abstract: General-purpose robots must master long-horizon manipulation, defined as tasks involving multiple kinematic structure changes (e.g., attaching or detaching objects) in unstructured environments. While Vision-Language-Action (VLA) models offer the potential to master diverse atomic skills, they struggle with the combinatorial complexity of sequencing them and are prone to cascading failures due to environmental sensitivity. To address these challenges, we propose LiLo-VLA (Linked Local VLA), a modular framework capable of zero-shot generalization to novel long-horizon tasks without ever being trained on them. Our approach decouples transport from interaction: a Reaching Module handles global motion, while an Interaction Module employs an object-centric VLA to process isolated objects of interest, ensuring robustness against irrelevant visual features and invariance to spatial configurations. Crucially, this modularity facilitates robust failure recovery through dynamic replanning and skill reuse, effectively mitigating the cascading errors common in end-to-end approaches. We introduce a 21-task simulation benchmark consisting of two challenging suites: LIBERO-Long++ and Ultra-Long. In these simulations, LiLo-VLA achieves a 69% average success rate, outperforming Pi0.5 by 41% and OpenVLA-OFT by 67%. Furthermore, real-world evaluations across 8 long-horizon tasks demonstrate an average success rate of 85%. Project page: https://yy-gx.github.io/LiLo-VLA/.

</details>


### [76] [World Guidance: World Modeling in Condition Space for Action Generation](https://arxiv.org/abs/2602.22010)
*Yue Su,Sijin Chen,Haixin Shi,Mingyu Liu,Zhengshen Zhang,Ningyuan Huang,Weiheng Zhong,Zhengbang Zhu,Yuxiao Liu,Xihui Liu*

Main category: cs.RO

TL;DR: 本文提出了一种新的方法，通过将未来观测压缩为条件信息并注入动作生成流程，显著提升了视觉-语言-动作（VLA）模型的动作生成能力和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在生成动作时面临两难：一方面需要高效、可预测的未来表示；另一方面又要保留足够的细粒度信息以指导精确动作生成。这导致已有方法在生成精细动作和泛化能力上有限。

Method: 本文提出WoG（World Guidance）框架，将未来观测信息压缩成条件，注入动作推理流程。VLA模型被联合训练去同时预测这些压缩条件和未来动作，从而在条件空间中实现对世界的建模和动作推理。

Result: WoG方法能够帮助模型实现精细动作生成，并表现出更强的泛化能力；同时能有效利用大量人类操作视频进行学习。在仿真和真实环境中的大量实验表明，其性能优于现有基于未来预测的方法。

Conclusion: 将未来观测压缩为条件并引导动作生成，可以显著提升VLA模型的动作生成精度和泛化能力。WoG方法为基于未来建模的动作推理提供了新的解决思路。

Abstract: Leveraging future observation modeling to facilitate action generation presents a promising avenue for enhancing the capabilities of Vision-Language-Action (VLA) models. However, existing approaches struggle to strike a balance between maintaining efficient, predictable future representations and preserving sufficient fine-grained information to guide precise action generation. To address this limitation, we propose WoG (World Guidance), a framework that maps future observations into compact conditions by injecting them into the action inference pipeline. The VLA is then trained to simultaneously predict these compressed conditions alongside future actions, thereby achieving effective world modeling within the condition space for action inference. We demonstrate that modeling and predicting this condition space not only facilitates fine-grained action generation but also exhibits superior generalization capabilities. Moreover, it learns effectively from substantial human manipulation videos. Extensive experiments across both simulation and real-world environments validate that our method significantly outperforms existing methods based on future prediction. Project page is available at: https://selen-suyue.github.io/WoGNet/

</details>
