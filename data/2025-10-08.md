<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 74]
- [cs.CL](#cs.CL) [Total: 92]
- [cs.RO](#cs.RO) [Total: 29]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Attention-Enhanced Prototypical Learning for Few-Shot Infrastructure Defect Segmentation](https://arxiv.org/abs/2510.05266)
*Christina Thrainer,Md Meftahul Ferdaus,Mahdi Abdelguerfi,Christian Guetl,Steven Sloan,Kendall N. Niles,Ken Pathak*

Main category: cs.CV

TL;DR: 本文提出了一种名为E-FPN的增强特征金字塔网络，用于少样本下的语义分割任务，尤其针对涵洞和下水道的缺陷检测，显著提升了在样本稀缺场景下的分割准确率。


<details>
  <summary>Details</summary>
Motivation: 基础设施检查中标注样本稀缺，且现有深度学习方法对于新类别表现不佳，亟需能在标注数据极少时也能快速适应和精准识别新缺陷类别的分割算法。

Method: 方法包括三方面创新：1）采用InceptionSepConv模块与深度可分离卷积的自适应E-FPN编码器，提升多尺度特征提取能力；2）结合掩码平均池化的原型学习方法，用少量支持样本高效生成原型特征；3）引入全局、局部和交叉自注意力机制以增强特征表达能力。

Result: 在具有挑战性的基础设施检测数据集上进行大量实验，E-FPN方法在8-way 5-shot设置下F1得分达到82.55%，在2-way测试中的mIoU达到72.26%；自注意力机制带来F1和mIoU指标分别提升2.57%和2.9%。

Conclusion: 提出的框架有效应对了基础设施检测中缺陷类别多样且样本稀缺问题，提高了新缺陷类型的检测效率和准确性，能够为基础设施维护提供经济高效的解决方案。

Abstract: Few-shot semantic segmentation is vital for deep learning-based
infrastructure inspection applications, where labeled training examples are
scarce and expensive. Although existing deep learning frameworks perform well,
the need for extensive labeled datasets and the inability to learn new defect
categories with little data are problematic. We present our Enhanced Feature
Pyramid Network (E-FPN) framework for few-shot semantic segmentation of culvert
and sewer defect categories using a prototypical learning framework. Our
approach has three main contributions: (1) adaptive E-FPN encoder using
InceptionSepConv blocks and depth-wise separable convolutions for efficient
multi-scale feature extraction; (2) prototypical learning with masked average
pooling for powerful prototype generation from small support examples; and (3)
attention-based feature representation through global self-attention, local
self-attention and cross-attention. Comprehensive experimentation on
challenging infrastructure inspection datasets illustrates that the method
achieves excellent few-shot performance, with the best configuration being
8-way 5-shot training configuration at 82.55% F1-score and 72.26% mIoU in 2-way
classification testing. The self-attention method had the most significant
performance improvements, providing 2.57% F1-score and 2.9% mIoU gain over
baselines. Our framework addresses the critical need to rapidly respond to new
defect types in infrastructure inspection systems with limited new training
data that lead to more efficient and economical maintenance plans for critical
infrastructure systems.

</details>


### [2] [SkinMap: Weighted Full-Body Skin Segmentation for Robust Remote Photoplethysmography](https://arxiv.org/abs/2510.05296)
*Zahra Maleki,Amirhossein Akbari,Amirhossein Binesh,Babak Khalaj*

Main category: cs.CV

TL;DR: 该论文提出了一种新的皮肤分割技术，用于提升远程光电容积描记法（rPPG）在不同环境下的心率检测精度，并通过新旧数据集验证了其在多种皮肤色调和动态条件下的优越性。


<details>
  <summary>Details</summary>
Motivation: rPPG作为一种低成本、无接触的生命体征检测技术，受到光照和动作干扰的影响较大，传统方法在复杂条件下准确性难以保证，亟需更鲁棒的信号提取方法。

Method: 提出了一种优先选择高质量皮肤区域的新型皮肤分割方法，能够检测全身皮肤并排除嘴、眼、头发等干扰区域，在公开数据集及新建的SYNC-rPPG数据集上进行评估。

Result: 新方法在说话、头部转动等复杂场景下有效捕捉心率信号，并保持较低的心率预测均方误差（MAE）；对多种皮肤色调表现出较高精度。

Conclusion: 本方法在抗干扰、皮肤色多样性和动态条件下均表现突出，为rPPG技术在实际应用中提供了更可靠的解决方案。

Abstract: Remote photoplethysmography (rPPG) is an innovative method for monitoring
heart rate and vital signs by using a simple camera to record a person, as long
as any part of their skin is visible. This low-cost, contactless approach helps
in remote patient monitoring, emotion analysis, smart vehicle utilization, and
more. Over the years, various techniques have been proposed to improve the
accuracy of this technology, especially given its sensitivity to lighting and
movement. In the unsupervised pipeline, it is necessary to first select skin
regions from the video to extract the rPPG signal from the skin color changes.
We introduce a novel skin segmentation technique that prioritizes skin regions
to enhance the quality of the extracted signal. It can detect areas of skin all
over the body, making it more resistant to movement, while removing areas such
as the mouth, eyes, and hair that may cause interference. Our model is
evaluated on publicly available datasets, and we also present a new dataset,
called SYNC-rPPG, to better represent real-world conditions. The results
indicate that our model demonstrates a prior ability to capture heartbeats in
challenging conditions, such as talking and head rotation, and maintain the
mean absolute error (MAE) between predicted and actual heart rates, while other
methods fail to do so. In addition, we demonstrate high accuracy in detecting a
diverse range of skin tones, making this technique a promising option for
real-world applications.

</details>


### [3] [DeepAf: One-Shot Spatiospectral Auto-Focus Model for Digital Pathology](https://arxiv.org/abs/2510.05315)
*Yousef Yeganeh,Maximilian Frantzen,Michael Lee,Kun-Hsing Yu,Nassir Navab,Azade Farshad*

Main category: cs.CV

TL;DR: 本文提出DeepAf自动对焦系统，可大幅提升普通显微镜扫描效率，以低成本实现病理切片数字化，并保证成像质量，且在跨机构推广上表现稳健。


<details>
  <summary>Details</summary>
Motivation: 传统病理切片数字化设备昂贵，低成本自动显微镜存在对焦难、速度慢和泛化能力不足等问题，阻碍了数字病理在资源有限地区的普及。

Method: 提出DeepAf框架，结合空间和光谱特征，通过单张图像预测并自动调整至最佳焦距，省去多图像堆叠，兼顾速度与精度。该系统能将普通显微镜改造为高效扫描仪。

Result: 对焦时间缩短80%，对焦精度达到0.18微米，与双图像方法相当，但输入需求减半。跨实验室测试虚焦预测率仅0.72%，90%预测在景深内。临床试验中，4倍镜下癌症分类AUC达0.90。

Conclusion: 该系统以低成本提供实时、高精度数字病理解决方案，适用于资源受限地区，保障诊断准确性，有助于数字病理的普及和应用。

Abstract: While Whole Slide Imaging (WSI) scanners remain the gold standard for
digitizing pathology samples, their high cost limits accessibility in many
healthcare settings. Other low-cost solutions also face critical limitations:
automated microscopes struggle with consistent focus across varying tissue
morphology, traditional auto-focus methods require time-consuming focal stacks,
and existing deep-learning approaches either need multiple input images or lack
generalization capability across tissue types and staining protocols. We
introduce a novel automated microscopic system powered by DeepAf, a novel
auto-focus framework that uniquely combines spatial and spectral features
through a hybrid architecture for single-shot focus prediction. The proposed
network automatically regresses the distance to the optimal focal point using
the extracted spatiospectral features and adjusts the control parameters for
optimal image outcomes. Our system transforms conventional microscopes into
efficient slide scanners, reducing focusing time by 80% compared to stack-based
methods while achieving focus accuracy of 0.18 {\mu}m on the same-lab samples,
matching the performance of dual-image methods (0.19 {\mu}m) with half the
input requirements. DeepAf demonstrates robust cross-lab generalization with
only 0.72% false focus predictions and 90% of predictions within the depth of
field. Through an extensive clinical study of 536 brain tissue samples, our
system achieves 0.90 AUC in cancer classification at 4x magnification, a
significant achievement at lower magnification than typical 20x WSI scans. This
results in a comprehensive hardware-software design enabling accessible,
real-time digital pathology in resource-constrained settings while maintaining
diagnostic accuracy.

</details>


### [4] [Fine-Tuned CNN-Based Approach for Multi-Class Mango Leaf Disease Detection](https://arxiv.org/abs/2510.05326)
*Jalal Ahmmed,Faruk Ahmed,Rashedul Hasan Shohan,Md. Mahabub Rana,Mahdi Hasan*

Main category: cs.CV

TL;DR: 本研究比较了五种预训练卷积神经网络用于芒果叶多类病害识别，发现DenseNet201表现最佳，准确率达99.33%。


<details>
  <summary>Details</summary>
Motivation: 芒果是南亚重要水果，但常受叶部病害影响，导致产量和质量下降。通过深度学习自动诊断叶部病害，可提升生产效率和病害管理。

Method: 作者采用迁移学习和微调方法，对DenseNet201、InceptionV3、ResNet152V2、SeResNet152、Xception五种预训练CNN模型，在八类芒果叶病害数据集上进行多分类训练，并以准确率、精确率、召回率、F1分数等指标评估模型表现。

Result: DenseNet201在所有标准中表现最优，整体准确率99.33%，对不同类别特别是Cutting Weevil和Bacterial Canker识别效果突出。ResNet152V2和SeResNet152性能也很好，而InceptionV3和Xception在部分相似病害（如烟煤病和白粉病）上表现较弱。高性能模型的训练和验证曲线均显示良好收敛性。

Conclusion: 通过迁移学习和微调预训练模型，能高效且准确实现多类芒果叶病害识别，为智能农业应用提供了可靠技术方案。

Abstract: Mango is an important fruit crop in South Asia, but its cultivation is
frequently hampered by leaf diseases that greatly impact yield and quality.
This research examines the performance of five pre-trained convolutional neural
networks, DenseNet201, InceptionV3, ResNet152V2, SeResNet152, and Xception, for
multi-class identification of mango leaf diseases across eight classes using a
transfer learning strategy with fine-tuning. The models were assessed through
standard evaluation metrics, such as accuracy, precision, recall, F1-score, and
confusion matrices. Among the architectures tested, DenseNet201 delivered the
best results, achieving 99.33% accuracy with consistently strong metrics for
individual classes, particularly excelling in identifying Cutting Weevil and
Bacterial Canker. Moreover, ResNet152V2 and SeResNet152 provided strong
outcomes, whereas InceptionV3 and Xception exhibited lower performance in
visually similar categories like Sooty Mould and Powdery Mildew. The training
and validation plots demonstrated stable convergence for the highest-performing
models. The capability of fine-tuned transfer learning models, for precise and
dependable multi-class mango leaf disease detection in intelligent agricultural
applications.

</details>


### [5] [Mitigating Diffusion Model Hallucinations with Dynamic Guidance](https://arxiv.org/abs/2510.05356)
*Kostas Triaridis,Alexandros Graikos,Aggelina Chatziagapi,Grigorios G. Chrysos,Dimitris Samaras*

Main category: cs.CV

TL;DR: 提出了一种在生成时动态引导扩散模型，能有效减少模型幻觉，提高结果质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然生成效果令人印象深刻，但经常会产生结构不一致的“幻觉”样本，这些样本并不符合真实数据分布。传统方法往往只能通过后处理过滤掉这些幻觉，但没有从根本上解决生成时幻觉频发的问题。

Method: 作者提出Dynamic Guidance方法，核心思想是在生成过程中，动态地只沿着已知容易产生幻觉的方向对得分函数进行锐化处理，从而在不牺牲语义多样性的前提下，有针对性地减少幻觉。该方法区别于以往只做后处理的方案，直接嵌入生成过程。

Result: 实验在受控和真实图像数据集上进行了验证，结果显示Dynamic Guidance方法能大幅降低幻觉样本的出现，并显著优于其它基线方法。

Conclusion: Dynamic Guidance首次在扩散模型的生成过程中对幻觉进行有效抑制，实现了减少幻觉与保持语义多样性的平衡，在提高扩散模型生成质量方面具有实用价值。

Abstract: Diffusion models, despite their impressive demos, often produce hallucinatory
samples with structural inconsistencies that lie outside of the support of the
true data distribution. Such hallucinations can be attributed to excessive
smoothing between modes of the data distribution. However, semantic
interpolations are often desirable and can lead to generation diversity, thus
we believe a more nuanced solution is required. In this work, we introduce
Dynamic Guidance, which tackles this issue. Dynamic Guidance mitigates
hallucinations by selectively sharpening the score function only along the
pre-determined directions known to cause artifacts, while preserving valid
semantic variations. To our knowledge, this is the first approach that
addresses hallucinations at generation time rather than through post-hoc
filtering. Dynamic Guidance substantially reduces hallucinations on both
controlled and natural image datasets, significantly outperforming baselines.

</details>


### [6] [LightCache: Memory-Efficient, Training-Free Acceleration for Video Generation](https://arxiv.org/abs/2510.05367)
*Yang Xiao,Gen Li,Kaiyuan Deng,Yushu Wu,Zheng Zhan,Yanzhi Wang,Xiaolong Ma,Bo Hui*

Main category: cs.CV

TL;DR: 本文针对扩散模型在视频生成任务中的推理加速与内存优化问题，提出了三种无需重新训练的方法，大幅降低内存占用并提升了推理速度。


<details>
  <summary>Details</summary>
Motivation: 在利用扩散模型进行视频生成时，推理过程因潜变量冗余导致计算与存储需求激增，现有缓存加速方法带来内存飞涨，亟需解决高效推理与内存优化的矛盾。

Method: 作者将推理过程分为编码、去噪、解码三阶段，分析各阶段特性，并提出三项针对性策略：1）异步缓存交换（Asynchronous Cache Swapping）；2）特征分块（Feature chunk）；3）潜变量切片解码（Slicing latents to decode）。这些方法旨在分阶段减少内存消耗，并保证新增的时间开销不抵消整体加速效果。

Result: 相较于基线方法，本文提出的方法在加速推理的同时显著降低了内存用量，且生成视频的质量损失控制在可接受范围内。

Conclusion: 通过分阶段、训练无关的内存优化加速策略，本文实现了高效且资源友好的视频扩散模型推理，为类似任务的应用部署提供了有价值的参考。

Abstract: Training-free acceleration has emerged as an advanced research area in video
generation based on diffusion models. The redundancy of latents in diffusion
model inference provides a natural entry point for acceleration. In this paper,
we decompose the inference process into the encoding, denoising, and decoding
stages, and observe that cache-based acceleration methods often lead to
substantial memory surges in the latter two stages. To address this problem, we
analyze the characteristics of inference across different stages and propose
stage-specific strategies for reducing memory consumption: 1) Asynchronous
Cache Swapping. 2) Feature chunk. 3) Slicing latents to decode. At the same
time, we ensure that the time overhead introduced by these three strategies
remains lower than the acceleration gains themselves. Compared with the
baseline, our approach achieves faster inference speed and lower memory usage,
while maintaining quality degradation within an acceptable range. The Code is
available at https://github.com/NKUShaw/LightCache .

</details>


### [7] [See the past: Time-Reversed Scene Reconstruction from Thermal Traces Using Visual Language Models](https://arxiv.org/abs/2510.05408)
*Kebin Contreras,Luis Toscano-Palomino,Mauro Dalla Mura,Jorge Bacca*

Main category: cs.CV

TL;DR: 本研究提出了一种利用热成像与RGB图像结合、通过视觉-语言模型和扩散模型，能从当前观测数据中重建过去数秒场景状态的新方法。实验表明，该方法首次实现在受控场景下最大可追溯120秒前的场景关键帧。


<details>
  <summary>Details</summary>
Motivation: 传统RGB摄像头无法捕捉到微弱或已消失的人体活动痕迹，而热成像可获取人体或物体残留的热痕，具有追溯近期事件和动作的潜力，但热成像信息如何高效还原场景并未被有效挖掘。

Method: 使用配对的RGB与热成像数据，通过视觉语言模型生成场景描述和约束，并结合一种受约束的扩散过程重建数秒前场景状态，保证语义和结构一致性。

Result: 在三个受控实验场景下，本方法能重建并推断出最多120秒前发生过的人体与场景互动事件，效果真实且有一定可行性。

Conclusion: 该方法首次证实利用热成像残留信息结合扩散模型和视觉语言约束，可以实现近过去场景时序还原，为热成像逆时重建提供了新途径。

Abstract: Recovering the past from present observations is an intriguing challenge with
potential applications in forensics and scene analysis. Thermal imaging,
operating in the infrared range, provides access to otherwise invisible
information. Since humans are typically warmer (37 C -98.6 F) than their
surroundings, interactions such as sitting, touching, or leaning leave residual
heat traces. These fading imprints serve as passive temporal codes, allowing
for the inference of recent events that exceed the capabilities of RGB cameras.
This work proposes a time-reversed reconstruction framework that uses paired
RGB and thermal images to recover scene states from a few seconds earlier. The
proposed approach couples Visual-Language Models (VLMs) with a constrained
diffusion process, where one VLM generates scene descriptions and another
guides image reconstruction, ensuring semantic and structural consistency. The
method is evaluated in three controlled scenarios, demonstrating the
feasibility of reconstructing plausible past frames up to 120 seconds earlier,
providing a first step toward time-reversed imaging from thermal traces.

</details>


### [8] [Personalizing Retrieval using Joint Embeddings or "the Return of Fluffy"](https://arxiv.org/abs/2510.05411)
*Bruno Korbar,Andrew Zisserman*

Main category: cs.CV

TL;DR: 本文旨在通过结合图像中对象实例和自然语言描述，实现更精准的图像检索。提出了名为pi-map的可训练映射网络将对象嵌入转换为文本token，以便与CLIP模型进行联合编码和检索。方法在个性化检索基准上取得了最新最优结果。


<details>
  <summary>Details</summary>
Motivation: 当前基于文本或图像检索方法难以实现对象实例级别的个性化图像检索，尤其是需结合特定对象与描述时。本文希望解决如何基于特定目标实例和自然语言组合查询，提升检索的个性化和准确性。

Method: 设计了一个可训练的映射网络（pi-map），该网络能将局部图像嵌入映射为文本token，再与自然语言结合输入CLIP模型进行检索训练。训练过程简单，每个对象实例只需训练一次。同 时，CLIP的文本和图像编码器参数保持冻结。

Result: 在两个针对个性化检索任务的基准数据集上，本文方法显著超过当前最优方法，提升了个性化的图像检索准确率。

Conclusion: 通过pi-map映射网络和CLIP冻结编码器的结合，有效实现了结合对象实例与自然语言描述的复合查询检索，为个性化图像检索提供了一种新颖有效的解决方案。

Abstract: The goal of this paper is to be able to retrieve images using a compound
query that combines object instance information from an image, with a natural
text description of what that object is doing or where it is. For example, to
retrieve an image of "Fluffy the unicorn (specified by an image) on someone's
head". To achieve this we design a mapping network that can "translate" from a
local image embedding (of the object instance) to a text token, such that the
combination of the token and a natural language query is suitable for CLIP
style text encoding, and image retrieval. Generating a text token in this
manner involves a simple training procedure, that only needs to be performed
once for each object instance. We show that our approach of using a trainable
mapping network, termed pi-map, together with frozen CLIP text and image
encoders, improves the state of the art on two benchmarks designed to assess
personalized retrieval.

</details>


### [9] [ArchitectHead: Continuous Level of Detail Control for 3D Gaussian Head Avatars](https://arxiv.org/abs/2510.05488)
*Peizhi Yan,Rabab Ward,Qiang Tang,Shan Du*

Main category: cs.CV

TL;DR: 该论文提出了ArchitectHead，可实现3D高斯头像渲染时连续可控的细节层次（LOD），在保持高质量的前提下显著减少点数和提升速度。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯头像技术在渲染质量和速度表现优异，但高斯点数量固定，缺乏对细节层次（LOD）的灵活调整，无法兼顾效率和效果，限制了实际应用的灵活性。

Method: 作者提出将高斯点参数化到2D UV特征空间，并设计多层可学习特征图（UV feature field）存储高斯的潜在特征，通过轻量神经网络解码器将其转化为3D高斯属性。通过动态重采样UV特征图以实现连续LOD调节，无需重新训练。

Result: 在高细节层次（高LOD）任务，如跨身份重演，方法达到SOTA性能，在低LOD时维持高质量，同时仅用原6.2%的高斯点，速度几乎翻倍，画质下降适中。

Conclusion: ArchitectHead实现了高效、无缝的LOD控制，在兼顾渲染速度和质量方面具有明显优势，推动3D头像技术在实际应用中的灵活性和实用性。

Abstract: 3D Gaussian Splatting (3DGS) has enabled photorealistic and real-time
rendering of 3D head avatars. Existing 3DGS-based avatars typically rely on
tens of thousands of 3D Gaussian points (Gaussians), with the number of
Gaussians fixed after training. However, many practical applications require
adjustable levels of detail (LOD) to balance rendering efficiency and visual
quality. In this work, we propose "ArchitectHead", the first framework for
creating 3D Gaussian head avatars that support continuous control over LOD. Our
key idea is to parameterize the Gaussians in a 2D UV feature space and propose
a UV feature field composed of multi-level learnable feature maps to encode
their latent features. A lightweight neural network-based decoder then
transforms these latent features into 3D Gaussian attributes for rendering.
ArchitectHead controls the number of Gaussians by dynamically resampling
feature maps from the UV feature field at the desired resolutions. This method
enables efficient and continuous control of LOD without retraining.
Experimental results show that ArchitectHead achieves state-of-the-art (SOTA)
quality in self and cross-identity reenactment tasks at the highest LOD, while
maintaining near SOTA performance at lower LODs. At the lowest LOD, our method
uses only 6.2\% of the Gaussians while the quality degrades moderately (L1 Loss
+7.9\%, PSNR --0.97\%, SSIM --0.6\%, LPIPS Loss +24.1\%), and the rendering
speed nearly doubles.

</details>


### [10] [Human Action Recognition from Point Clouds over Time](https://arxiv.org/abs/2510.05506)
*James Dickens*

Main category: cs.CV

TL;DR: 该论文提出了一种使用3D点云进行人体动作识别的新方法，不仅支持传感器深度数据，也支持单目深度估计，核心为结合点云与稀疏卷积网络的3D动作识别主干结构，并在NTU RGB-D 120数据集上取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 目前动作识别大多集中在骨骼或视频方法，随着廉价深度传感器与Lidar普及，利用密集3D点云数据成为新的机会，因此作者探索3D点云动作识别技术，以突破现有限制。

Method: 提出一套完整流程：先将人类点云与背景分割；跟踪个体时序行为并进行身体部分分割。主干网络结合点云技术和稀疏卷积网络处理体素化点云序列，辅以点特征（如表面法线、颜色、红外强度等）提升识别表现，并支持深度传感器与单目深度估计点云输入。

Result: 在NTU RGB-D 120数据集上的实验显示，方法与现有骨架动作识别算法具备竞争力，同时在传感器和估计数据集成方案下，取得89.3%的准确率，超越过往点云方法。

Conclusion: 利用点云进行动作识别不仅能兼容多种深度数据源，还能显著提升识别精度，为3D动作识别领域提供了强有力的新范式。

Abstract: Recent research into human action recognition (HAR) has focused predominantly
on skeletal action recognition and video-based methods. With the increasing
availability of consumer-grade depth sensors and Lidar instruments, there is a
growing opportunity to leverage dense 3D data for action recognition, to
develop a third way. This paper presents a novel approach for recognizing
actions from 3D videos by introducing a pipeline that segments human point
clouds from the background of a scene, tracks individuals over time, and
performs body part segmentation. The method supports point clouds from both
depth sensors and monocular depth estimation. At the core of the proposed HAR
framework is a novel backbone for 3D action recognition, which combines
point-based techniques with sparse convolutional networks applied to
voxel-mapped point cloud sequences. Experiments incorporate auxiliary point
features including surface normals, color, infrared intensity, and body part
parsing labels, to enhance recognition accuracy. Evaluation on the NTU RGB- D
120 dataset demonstrates that the method is competitive with existing skeletal
action recognition algorithms. Moreover, combining both sensor-based and
estimated depth inputs in an ensemble setup, this approach achieves 89.3%
accuracy when different human subjects are considered for training and testing,
outperforming previous point cloud action recognition methods.

</details>


### [11] [Be Tangential to Manifold: Discovering Riemannian Metric for Diffusion Models](https://arxiv.org/abs/2510.05509)
*Shinnosuke Saito,Takashi Matsubara*

Main category: cs.CV

TL;DR: 该论文为扩散模型提出了一种新的Riemann度量方法，用于在噪声空间中推断和遵循数据流形，从而实现更自然、更真实的图像插值效果。


<details>
  <summary>Details</summary>
Motivation: 扩散模型生成效果出色但缺乏显式的低维流形空间，这限制了如插值、编辑等基于流形的分析和操作，当今插值方法往往沿高密度区域路径前进，导致结果不自然。作者旨在解决扩散模型流形不可显式分析导致的插值不自然问题。

Method: 作者提出在噪声空间中定义新的Riemann度量，借助score函数的Jacobian矩阵来刻画局部数据流形切空间，使得在此度量下的测地线（geodesics）更可能贴近或平行于数据流形，提升流形感知的插值路径自然性。

Result: 实验表明，所提出的Riemann度量在图像插值任务中相比现有密度法和简单基线法，能够产生更加自然、真实的过渡效果。

Conclusion: 该研究表明通过引入流形感知的Riemann度量，可以有效提升扩散模型中插值与过渡的感知自然性，为相关流形感知操作提供了新方法。

Abstract: Diffusion models are powerful deep generative models (DGMs) that generate
high-fidelity, diverse content. However, unlike classical DGMs, they lack an
explicit, tractable low-dimensional latent space that parameterizes the data
manifold. This absence limits manifold-aware analysis and operations, such as
interpolation and editing. Existing interpolation methods for diffusion models
typically follow paths through high-density regions, which are not necessarily
aligned with the data manifold and can yield perceptually unnatural
transitions. To exploit the data manifold learned by diffusion models, we
propose a novel Riemannian metric on the noise space, inspired by recent
findings that the Jacobian of the score function captures the tangent spaces to
the local data manifold. This metric encourages geodesics in the noise space to
stay within or run parallel to the learned data manifold. Experiments on image
interpolation show that our metric produces perceptually more natural and
faithful transitions than existing density-based and naive baselines.

</details>


### [12] [Teamwork: Collaborative Diffusion with Low-rank Coordination and Adaptation](https://arxiv.org/abs/2510.05532)
*Sam Sartor,Pieter Peers*

Main category: cs.CV

TL;DR: 本文提出了一种名为Teamwork的新方法，可以在不修改预训练扩散模型架构的前提下，灵活高效地扩展输入和输出通道，并适配到多种新任务。该方法通过协调和适配多个基础扩散模型实例（即“队友”）来实现通道扩展与任务迁移。


<details>
  <summary>Details</summary>
Motivation: 当前的大型预训练扩散模型主要面向固定通道数的任务，难以适配像神经渲染、SVBRDF估计、内在图像分解等需要更多或不同输入/输出通道的应用。现有解决方案通常针对具体应用定制，缺乏通用性和灵活性，难以推广到新模型和新任务。

Method: Teamwork无须改变预训练扩散模型的架构，而是通过组合和适配多个扩散模型实例，利用一种新型的低秩适应（LoRA）方式同步完成通道扩展和模型任务适配。此外，Teamwork还支持“队友”动态(去)激活，提高灵活性。

Result: Teamwork已在多种生成和逆向图形任务（如图像修复、单图像SVBRDF估计、内在分解、神经着色和合成等）上进行了实验，证明了其方法的灵活性和高效性。

Conclusion: Teamwork为基于扩散模型的多通道图形任务提供了统一、高效、有扩展性的解决方案，便于拓展到多种新任务和复杂需求。

Abstract: Large pretrained diffusion models can provide strong priors beneficial for
many graphics applications. However, generative applications such as neural
rendering and inverse methods such as SVBRDF estimation and intrinsic image
decomposition require additional input or output channels. Current solutions
for channel expansion are often application specific and these solutions can be
difficult to adapt to different diffusion models or new tasks. This paper
introduces Teamwork: a flexible and efficient unified solution for jointly
increasing the number of input and output channels as well as adapting a
pretrained diffusion model to new tasks. Teamwork achieves channel expansion
without altering the pretrained diffusion model architecture by coordinating
and adapting multiple instances of the base diffusion model (\ie, teammates).
We employ a novel variation of Low Rank-Adaptation (LoRA) to jointly address
both adaptation and coordination between the different teammates. Furthermore
Teamwork supports dynamic (de)activation of teammates. We demonstrate the
flexibility and efficiency of Teamwork on a variety of generative and inverse
graphics tasks such as inpainting, single image SVBRDF estimation, intrinsic
decomposition, neural shading, and intrinsic image synthesis.

</details>


### [13] [Seeing the Big Picture: Evaluating Multimodal LLMs' Ability to Interpret and Grade Handwritten Student Work](https://arxiv.org/abs/2510.05538)
*Owen Henkel,Bill Roberts,Doug Jaffe,Laurence Holt*

Main category: cs.CV

TL;DR: 本文探讨多模态大模型（MLLMs）在自动评阅和分析手写学生作业，尤其是在初中小学数学中的应用表现。通过两组实验证明，MLLMs在批改标准化算术手写作业时接近人类水平，但在需要复杂视觉解释和教育判断的主观性数学插画任务中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 数学教育中大量作业依然是手写的，人工批改不仅耗时而且难以大规模实施。利用MLLMs辅助批改和分析，可大幅减轻教师负担并为学生学习过程提供深层洞察，尤其在发展中国家和基础教育领域意义重大。

Method: 文章设计了两项实验证明MLLMs在不同数学任务下的处理能力：实验A让模型批改288份加纳初中生的标准化算术手写作业；实验B让模型分析150份美国小学生用插画作答的数学问题，并比较模型在直接看图片和参考人类详细描述时的评分差异。

Result: 实验A中MLLM批改标准算术作业准确度达95%，与人工接近（k=0.90），但仍有教师不会犯的低级错误。实验B中模型对插画作业的评分一致性很低（k=0.20），但在提供详细人工描述后评分一致性显著提升（k=0.47），与人类互评一致性接近。

Conclusion: 目前MLLMs能较好地理解和批改标准化算术手写作业，但在复杂主观插画类数学题上还依赖人工辅助，亟需提升其高级视觉与教育判断能力。

Abstract: Recent advances in multimodal large language models (MLLMs) raise the
question of their potential for grading, analyzing, and offering feedback on
handwritten student classwork. This capability would be particularly beneficial
in elementary and middle-school mathematics education, where most work remains
handwritten, because seeing students' full working of a problem provides
valuable insights into their learning processes, but is extremely
time-consuming to grade. We present two experiments investigating MLLM
performance on handwritten student mathematics classwork. Experiment A examines
288 handwritten responses from Ghanaian middle school students solving
arithmetic problems with objective answers. In this context, models achieved
near-human accuracy (95%, k = 0.90) but exhibited occasional errors that human
educators would be unlikely to make. Experiment B evaluates 150 mathematical
illustrations from American elementary students, where the drawings are the
answer to the question. These tasks lack single objective answers and require
sophisticated visual interpretation as well as pedagogical judgment in order to
analyze and evaluate them. We attempted to separate MLLMs' visual capabilities
from their pedagogical abilities by first asking them to grade the student
illustrations directly, and then by augmenting the image with a detailed human
description of the illustration. We found that when the models had to analyze
the student illustrations directly, they struggled, achieving only k = 0.20
with ground truth scores, but when given human descriptions, their agreement
levels improved dramatically to k = 0.47, which was in line with human-to-human
agreement levels. This gap suggests MLLMs can "see" and interpret arithmetic
work relatively well, but still struggle to "see" student mathematical
illustrations.

</details>


### [14] [Midway Network: Learning Representations for Recognition and Motion from Latent Dynamics](https://arxiv.org/abs/2510.05558)
*Christopher Hoang,Mengye Ren*

Main category: cs.CV

TL;DR: 本文提出了一种新的自监督学习架构——Midway Network，首次实现在自然视频中同时获得高质量的物体识别与运动理解表示。通过引入中途上行通路、密集前向预测目标和层次结构等机制，该方法在两大视频数据集上预训练后，在语义分割和光流等下游任务上均优于以往的自监督方法。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法多专注于提升物体识别或运动解析的表示，很少能够兼顾二者。另一方面，潜在动力学建模虽然应用于决策与规划，但鲜少在自然视频大规模视觉表示学习任务中实现两者结合。因此，亟需一种能够在自然视频场景中联合学习物体识别和运动理解的新方法。

Method: 作者提出了Midway Network：扩展潜在动力学建模，引入中途上行通路，用以推理视频帧之间的运动潜变量，并采用密集前向预测任务以及层次化结构以适应复杂多目标场景。该框架通过在大规模自然视频数据上自监督预训练，生成可同时应用于识别与运动相关下游任务的强大表示。

Result: 在两个大型自然视频数据集上预训练后，Midway Network在语义分割与光流任务中表现优异，相比先前自监督方法有显著提升。此外，用前向特征扰动的新颖分析方法展现出该网络学习到的动态特征能捕获高级对应关系。

Conclusion: Midway Network突破性地实现了自监督条件下物体识别和运动理解的统一视觉表示学习，为自然视频中的多任务表征学习提供了有效新范式，并可扩展至更广泛的视觉感知任务。

Abstract: Object recognition and motion understanding are key components of perception
that complement each other. While self-supervised learning methods have shown
promise in their ability to learn from unlabeled data, they have primarily
focused on obtaining rich representations for either recognition or motion
rather than both in tandem. On the other hand, latent dynamics modeling has
been used in decision making to learn latent representations of observations
and their transformations over time for control and planning tasks. In this
work, we present Midway Network, a new self-supervised learning architecture
that is the first to learn strong visual representations for both object
recognition and motion understanding solely from natural videos, by extending
latent dynamics modeling to this domain. Midway Network leverages a midway
top-down path to infer motion latents between video frames, as well as a dense
forward prediction objective and hierarchical structure to tackle the complex,
multi-object scenes of natural videos. We demonstrate that after pretraining on
two large-scale natural video datasets, Midway Network achieves strong
performance on both semantic segmentation and optical flow tasks relative to
prior self-supervised learning methods. We also show that Midway Network's
learned dynamics can capture high-level correspondence via a novel analysis
method based on forward feature perturbation.

</details>


### [15] [HoloScene: Simulation-Ready Interactive 3D Worlds from a Single Video](https://arxiv.org/abs/2510.05560)
*Hongchi Xia,Chih-Hao Lin,Hao-Yu Hsu,Quentin Leboutet,Katelyn Gao,Michael Paulitsch,Benjamin Ummenhofer,Shenlong Wang*

Main category: cs.CV

TL;DR: 提出了一种称为HoloScene的新型3D重建框架，能实现几何完整、物理真实、可交互和高仿真的虚拟环境建模，显著提升仿真数字孪生的可靠性和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有3D重建和场景理解方法在几何完整性、物理合理性、可渲染性及动态仿真等方面无法同时达到高标准，限制了增强/虚拟现实、游戏、机器人等领域的应用。

Method: HoloScene采用了全面的场景图表示方式，融合了物体几何、外观、物理属性及多层次关系。重建过程被建模为能量优化问题，将观测数据、物理约束与生成式先验统一到同一目标函数内，通过基于采样与梯度的混合优化策略实现高效求解。

Result: 所得数字孪生模型在几何准确度、物理稳定性和新视角真实渲染方面表现优异，多个基准数据集上的评测显示超越现有方法，并在交互游戏及实时孪生场景操作中展现出广泛适用性和高效性。

Conclusion: HoloScene为虚拟场景与数字孪生重建提供了一种兼顾准确性、真实感和物理合理性的新途径，为各类应用场景带来了更高的可用性和表现力。

Abstract: Digitizing the physical world into accurate simulation-ready virtual
environments offers significant opportunities in a variety of fields such as
augmented and virtual reality, gaming, and robotics. However, current 3D
reconstruction and scene-understanding methods commonly fall short in one or
more critical aspects, such as geometry completeness, object interactivity,
physical plausibility, photorealistic rendering, or realistic physical
properties for reliable dynamic simulation. To address these limitations, we
introduce HoloScene, a novel interactive 3D reconstruction framework that
simultaneously achieves these requirements. HoloScene leverages a comprehensive
interactive scene-graph representation, encoding object geometry, appearance,
and physical properties alongside hierarchical and inter-object relationships.
Reconstruction is formulated as an energy-based optimization problem,
integrating observational data, physical constraints, and generative priors
into a unified, coherent objective. Optimization is efficiently performed via a
hybrid approach combining sampling-based exploration with gradient-based
refinement. The resulting digital twins exhibit complete and precise geometry,
physical stability, and realistic rendering from novel viewpoints. Evaluations
conducted on multiple benchmark datasets demonstrate superior performance,
while practical use-cases in interactive gaming and real-time digital-twin
manipulation illustrate HoloScene's broad applicability and effectiveness.
Project page: https://xiahongchi.github.io/HoloScene.

</details>


### [16] [CalibCLIP: Contextual Calibration of Dominant Semantics for Text-Driven Image Retrieval](https://arxiv.org/abs/2510.05586)
*Bin Kang,Bin Chen,Junjie Wang,Yulin Li,Junzhi Zhao,Zhuotao Tian*

Main category: cs.CV

TL;DR: CalibCLIP 是一种无需训练的方法，通过校准文本和视觉中的主导 token，有效提升了基于文本的图像检索性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型（VLMs）在基于文本的图像检索任务中存在结构性缺陷，少数低贡献 token 过度捕捉全局语义，从而主导了信息聚合过程，抑制了区分性特征。该问题导致检索能力下降。

Method: 提出 CalibCLIP 方法，无需训练。方法包含两个模块：视觉空间中使用 Contrastive Visual Enhancer (CVE) 将视觉特征分解为目标区域和低信息区域，并动态抑制主导 token；文本空间中采用 Discriminative Concept Calibrator (DCC) 区分一般性和辨别性概念，强化对辨别性概念的表达。

Result: 在涵盖三类图像检索任务的七个评价集上进行大量实验，均获得一致性性能提升，显示方法有效。

Conclusion: CalibCLIP 可作为现有视觉语言模型的通用后处理增强方案，显著提升文本驱动的图像检索中的区分能力。

Abstract: Existing Visual Language Models (VLMs) suffer structural limitations where a
few low contribution tokens may excessively capture global semantics,
dominating the information aggregation process and suppressing the
discriminative features in text-driven image retrieval tasks. To address this,
we introduce \textbf{CalibCLIP}, a training-free method designed to calibrate
the suppressive effect of dominant tokens. Specifically, in the visual space,
we propose the Contrastive Visual Enhancer (CVE), which decouples visual
features into target and low information regions. Subsequently, it identifies
dominant tokens and dynamically suppresses their representations.In the textual
space, we introduce the Discriminative Concept Calibrator (DCC), which aims to
differentiate between general and discriminative concepts within the text
query. By mitigating the challenges posed by generic concepts and improving the
representations of discriminative concepts, DCC strengthens the differentiation
among similar samples. Finally, extensive experiments demonstrate consistent
improvements across seven benchmarks spanning three image retrieval tasks,
underscoring the effectiveness of CalibCLIP. Code is available at:
https://github.com/kangbin98/CalibCLIP

</details>


### [17] [Improving Chain-of-Thought Efficiency for Autoregressive Image Generation](https://arxiv.org/abs/2510.05593)
*Zeqi Gu,Markos Georgopoulos,Xiaoliang Dai,Marjan Ghazvininejad,Chu Wang,Felix Juefei-Xu,Kunpeng Li,Yujun Shi,Zecheng He,Zijian He,Jiawei Zhou,Abe Davis,Jialiang Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种优化大模型绘图时思维链（CoT）冗余的新方法，显著减少推理长度并提升效率，同时不损失生成画质。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大模型生成图片前通常依赖扩展型“思维链”推理来细化提示词以增强细节与对齐，但这一过程常常导致冗余和资源浪费，甚至影响原意表达，亟需一种高效且简洁的推理方法。

Method: 作者提出了ShortCoTI框架，通过自适应函数根据任务难度对简洁推理奖励，嵌入强化学习，使链式推理指令在保证生成结果质量的同时尽可能简练，从而降低冗余与资源消耗。

Result: ShortCoTI技术在多个基准上显著缩短推理长度（减少54%），并且画质指标持平或略有提升，定性结果亦显示生成提示词更简明且语义丰富，无冗余反复内容。

Conclusion: ShortCoTI有效提升了图片生成效率，无需牺牲画质或视觉效果，实现了多模态大模型推理过程的高效与高质平衡。

Abstract: Autoregressive multimodal large language models have recently gained
popularity for image generation, driven by advances in foundation models. To
enhance alignment and detail, newer approaches employ chain-of-thought (CoT)
reasoning, expanding user inputs into elaborated prompts prior to image
synthesis. However, this strategy can introduce unnecessary redundancy -- a
phenomenon we call visual overthinking -- which increases computational costs
and can introduce details that contradict the original prompt. In this work, we
explore how to generate more concise CoT sequences for more efficient image
generation. We introduce ShortCoTI, a lightweight optimization framework that
encourages more concise CoT while preserving output image quality. ShortCoTI
rewards more concise prompts with an adaptive function that scales according to
an estimated difficulty for each task. Incorporating this reward into a
reinforcement learning paradigm reduces prompt reasoning length by 54% while
maintaining or slightly improving quality metrics across multiple benchmarks
(T2I-CompBench, GenEval). Qualitative analysis shows that our method eliminates
verbose explanations and repetitive refinements, producing reasoning prompts
that are both concise and semantically rich. As a result, ShortCoTI improves
computational efficiency without compromising the fidelity or visual appeal of
generated images.

</details>


### [18] [HOI-R1: Exploring the Potential of Multimodal Large Language Models for Human-Object Interaction Detection](https://arxiv.org/abs/2510.05609)
*Junwen Chen,Peilin Xiong,Keiji Yanai*

Main category: cs.CV

TL;DR: 作者提出了一个基于多模态大模型（MLLMs），完全不依赖传统目标检测器的全新HOI检测方法HOI-R1，显著提升了检测精度。


<details>
  <summary>Details</summary>
Motivation: 当前的人物-物体交互检测（HOID）方法高度依赖VLM中的先验知识，并且将这种知识与传统目标检测器的结合带来了模型架构和训练策略的复杂性，限制了实际应用和后续发展。同时，MLLM自身的推理能力在HOID任务上的潜力尚未被充分挖掘。

Method: 提出通过强化学习对MLLM进行训练，设计纯文本化的HOI推理流程及奖励函数，用完全端到端、无检测器的方式解决HOID任务。

Result: 在HICO-DET数据集上，HOI-R1模型在准确率上达到基线模型2倍，展现出极好的泛化能力。

Conclusion: HOI-R1无须额外检测模块，通过激发MLLM推理潜力，有效简化了HOID框架并大幅提升了检测性能，为相关领域提供了新的方法路径。

Abstract: Recent Human-object interaction detection (HOID) methods highly require prior
knowledge from VLMs to enhance the interaction recognition capabilities. The
training strategies and model architectures for connecting the knowledge from
VLMs to the HOI instance representations from the object detector are
challenging, and the whole framework is complex for further development or
application. On the other hand, the inherent reasoning abilities of MLLMs on
human-object interaction detection are under-explored. Inspired by the recent
success of training MLLMs with reinforcement learning (RL) methods, we propose
HOI-R1 and first explore the potential of the language model on the HOID task
without any additional detection modules. We introduce an HOI reasoning process
and HOID reward functions to solve the HOID task by pure text. The results on
the HICO-DET dataset show that HOI-R1 achieves 2x the accuracy of the baseline
with great generalization ability. The source code is available at
https://github.com/cjw2021/HOI-R1.

</details>


### [19] [Efficient Conditional Generation on Scale-based Visual Autoregressive Models](https://arxiv.org/abs/2510.05610)
*Jiaqi Liu,Tao Huang,Chang Xu*

Main category: cs.CV

TL;DR: 本文提出了一种高效的图像自回归生成控制方法ECM（Efficient Control Model），兼顾了生成质量和训练效率。


<details>
  <summary>Details</summary>
Motivation: 当前自回归（AR）模型在图像合成中已取得较好表现，但对于需要复杂空间控制的任务，现有AR方法常常需要对预训练模型微调，造成高昂的训练成本，缺乏灵活性和高效性。作者希望通过新的框架，解决高效学习与空间控制难以兼顾的问题。

Method: 提出了ECM框架，通过一个轻量级的可插拔控制模块实现控制信号引入。其架构包括上下文感知注意力层（用于利用实时生成的token优化条件特征）和共享门控前馈网络（FFN）（用于在有限容量下最大化特征学习效率）。此外，提出了重视生成早期语义结构的采样策略，优先学习早期控制序列；并通过推理时的温度调节补偿后期token训练不足。

Result: 在多个自回归图像生成模型和任务上进行实验证明，ECM能够提升图像合成的保真度、多样性和空间控制能力，并且训练和推理效率都有明显提升，优于已有方法。

Conclusion: ECM实现了自回归图像生成的高效准确控制，能够以较低的计算成本实现复杂条件下的高质量生成，为自回归生成模型的实用性和扩展性带来提升。

Abstract: Recent advances in autoregressive (AR) models have demonstrated their
potential to rival diffusion models in image synthesis. However, for complex
spatially-conditioned generation, current AR approaches rely on fine-tuning the
pre-trained model, leading to significant training costs. In this paper, we
propose the Efficient Control Model (ECM), a plug-and-play framework featuring
a lightweight control module that introduces control signals via a distributed
architecture. This architecture consists of context-aware attention layers that
refine conditional features using real-time generated tokens, and a shared
gated feed-forward network (FFN) designed to maximize the utilization of its
limited capacity and ensure coherent control feature learning. Furthermore,
recognizing the critical role of early-stage generation in determining semantic
structure, we introduce an early-centric sampling strategy that prioritizes
learning early control sequences. This approach reduces computational cost by
lowering the number of training tokens per iteration, while a complementary
temperature scheduling during inference compensates for the resulting
insufficient training of late-stage tokens. Extensive experiments on
scale-based AR models validate that our method achieves high-fidelity and
diverse control over image generation, surpassing existing baselines while
significantly improving both training and inference efficiency.

</details>


### [20] [PointNSP: Autoregressive 3D Point Cloud Generation with Next-Scale Level-of-Detail Prediction](https://arxiv.org/abs/2510.05613)
*Ziqiao Meng,Qichao Wang,Zhiyang Dou,Zixing Song,Zhipeng Zhou,Irwin King,Peilin Zhao*

Main category: cs.CV

TL;DR: 该论文提出了一种新的点云自回归生成框架PointNSP，通过多尺度粗到细的生成方式，首次在自回归范式下实现了与甚至超越扩散模型的高质量点云生成，并且具有更高的效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 自回归点云生成模型由于对点集强加了人为顺序，导致其无法很好地捕获长距离结构特征，在生成点云整体结构时表现不佳，和扩散模型存在较大质量差距。

Method: 受形状建模中的LOD（Level-of-Detail）思想启发，提出了PointNSP多尺度分解框架：先以低分辨率生成保留整体结构的粗形状，再逐步在更高分辨率下细化几何细节。每一尺度的预测都避免了固定顺序的问题，更好地利用了点集的无序特性。

Result: 在ShapeNet数据集上，PointNSP在自回归生成方法中首次达到甚至超越了当前最优的扩散模型，不但生成质量高，而且在参数量、训练与推理效率上均优于强力的扩散类对比方法。在高密度点云（8,192点）生成任务中，优势更为明显。

Conclusion: PointNSP表明，自回归方法在多尺度建模下能够缩小与扩散模型的性能差距，甚至实现超越，并在效率和可扩展性上展现出巨大潜力。

Abstract: Autoregressive point cloud generation has long lagged behind diffusion-based
approaches in quality. The performance gap stems from the fact that
autoregressive models impose an artificial ordering on inherently unordered
point sets, forcing shape generation to proceed as a sequence of local
predictions. This sequential bias emphasizes short-range continuity but
undermines the model's capacity to capture long-range dependencies, hindering
its ability to enforce global structural properties such as symmetry,
consistent topology, and large-scale geometric regularities. Inspired by the
level-of-detail (LOD) principle in shape modeling, we propose PointNSP, a
coarse-to-fine generative framework that preserves global shape structure at
low resolutions and progressively refines fine-grained geometry at higher
scales through a next-scale prediction paradigm. This multi-scale factorization
aligns the autoregressive objective with the permutation-invariant nature of
point sets, enabling rich intra-scale interactions while avoiding brittle fixed
orderings. Experiments on ShapeNet show that PointNSP establishes
state-of-the-art (SOTA) generation quality for the first time within the
autoregressive paradigm. In addition, it surpasses strong diffusion-based
baselines in parameter, training, and inference efficiency. Finally, in dense
generation with 8,192 points, PointNSP's advantages become even more
pronounced, underscoring its scalability potential.

</details>


### [21] [TFM Dataset: A Novel Multi-task Dataset and Integrated Pipeline for Automated Tear Film Break-Up Segmentation](https://arxiv.org/abs/2510.05615)
*Guangrong Wan,Jun liu,Tang tang,Lianghao Shi,Wenjun Luo,TingTing Xu*

Main category: cs.CV

TL;DR: 本文提出了首个多任务泪膜分析数据集（TFM），并基于该数据集设计了新颖且高效的分割模型TF-Net和整合分析流程TF-Collab，实现对泪膜破裂的自动精准检测与分析。


<details>
  <summary>Details</summary>
Motivation: 干眼症的诊断依赖于泪膜破裂（TFBU）分析，但自动化TFBU分割因缺乏标注数据集及完整解决方案而受限，制约了该领域的研究与应用。

Method: 作者构建了包含三类视觉任务标注的高分辨率泪膜视频数据集（TFM），提出了基于MobileOne-mini骨干和改进特征金字塔网络的TF-Net分割模型，并设计TF-Collab多任务协同自动分析流程。方法涵盖逐帧分类、瞳孔区域定位与TFBU分割。

Result: 与多种主流医学图像分割模型对比，TF-Net在TFM分割子集上表现优异，平衡了准确率与算力开销。TF-Collab实现了三任务联合的实时泪膜破裂自动分析。实验表明两者效果显著。

Conclusion: TFM数据集、TF-Net模型及TF-Collab流程为泪膜分析领域提供了强大基线与自动化工具，为未来眼表诊断智能化研究奠定了基础。

Abstract: Tear film break-up (TFBU) analysis is critical for diagnosing dry eye
syndrome, but automated TFBU segmentation remains challenging due to the lack
of annotated datasets and integrated solutions. This paper introduces the Tear
Film Multi-task (TFM) Dataset, the first comprehensive dataset for multi-task
tear film analysis, comprising 15 high-resolution videos (totaling 6,247
frames) annotated with three vision tasks: frame-level classification ('clear',
'closed', 'broken', 'blur'), Placido Ring detection, and pixel-wise TFBU area
segmentation. Leveraging this dataset, we first propose TF-Net, a novel and
efficient baseline segmentation model. TF-Net incorporates a MobileOne-mini
backbone with re-parameterization techniques and an enhanced feature pyramid
network to achieve a favorable balance between accuracy and computational
efficiency for real-time clinical applications. We further establish benchmark
performance on the TFM segmentation subset by comparing TF-Net against several
state-of-the-art medical image segmentation models. Furthermore, we design
TF-Collab, a novel integrated real-time pipeline that synergistically leverages
models trained on all three tasks of the TFM dataset. By sequentially
orchestrating frame classification for BUT determination, pupil region
localization for input standardization, and TFBU segmentation, TF-Collab fully
automates the analysis. Experimental results demonstrate the effectiveness of
the proposed TF-Net and TF-Collab, providing a foundation for future research
in ocular surface diagnostics. Our code and the TFM datasets are available at
https://github.com/glory-wan/TF-Net

</details>


### [22] [InstaGeo: Compute-Efficient Geospatial Machine Learning from Data to Deployment](https://arxiv.org/abs/2510.05617)
*Ibrahim Salihu Yusuf,Iffanice Houndayi,Rym Oualha,Mohamed Aziz Cherif,Kobby Panford-Quainoo,Arnu Pretorius*

Main category: cs.CV

TL;DR: 本论文提出了一个名为InstaGeo的开源端到端框架，可实现自动化地理空间数据处理、模型精简和快速部署，极大简化了大规模遥感任务的流程。


<details>
  <summary>Details</summary>
Motivation: 虽然开放的多光谱遥感数据促进了地理空间基础模型的研究，但实际应用受限于原始数据处理复杂、模型体量大和缺乏自动化流程。因此需要集成的数据处理、模型压缩和高效部署方案。

Method: 提出InstaGeo框架，包含：1）自动数据处理，将原始卫星影像转为可用数据集；2）模型精蒸馏，实现小巧高效模型；3）一键部署为交互式Web地图应用。并复现了多个公开数据集与任务，对比主流方法进行了评估。

Result: 在洪水制图、作物分割、沙漠蝗虫预测三个任务中，InstaGeo的模型mIoU与标准模型差距极小（最大±1.79 pp），但模型体积缩减至1/8，推理耗能显著降低。另外自建数据集下达成60.65%的mIoU，提升12个百分点。

Conclusion: InstaGeo通过整合自动数据处理、模型压缩与便捷部署，显著提升了遥感AI的实用性和低碳属性，为大规模地球观测提供了高效工具，推动了地理空间人工智能向数据与应用驱动创新转型。

Abstract: Open-access multispectral imagery from missions like Landsat 8-9 and
Sentinel-2 has fueled the development of geospatial foundation models (GFMs)
for humanitarian and environmental applications. Yet, their deployment remains
limited by (i) the absence of automated geospatial data pipelines and (ii) the
large size of fine-tuned models. Existing GFMs lack workflows for processing
raw satellite imagery, and downstream adaptations often retain the full
complexity of the original encoder.
  We present InstaGeo, an open-source, end-to-end framework that addresses
these challenges by integrating: (1) automated data curation to transform raw
imagery into model-ready datasets; (2) task-specific model distillation to
derive compact, compute-efficient models; and (3) seamless deployment as
interactive web-map applications. Using InstaGeo, we reproduced datasets from
three published studies and trained models with marginal mIoU differences of
-0.73 pp for flood mapping, -0.20 pp for crop segmentation, and +1.79 pp for
desert locust prediction. The distilled models are up to 8x smaller than
standard fine-tuned counterparts, reducing FLOPs and CO2 emissions with minimal
accuracy loss.
  Leveraging InstaGeo's streamlined data pipeline, we also curated a larger
crop segmentation dataset, achieving a state-of-the-art mIoU of 60.65%, a 12 pp
improvement over prior baselines. Moreover, InstaGeo enables users to progress
from raw data to model deployment within a single working day.
  By unifying data preparation, model compression, and deployment, InstaGeo
transforms research-grade GFMs into practical, low-carbon tools for real-time,
large-scale Earth observation. This approach shifts geospatial AI toward data
quality and application-driven innovation. Source code, datasets, and model
checkpoints are available at:
https://github.com/instadeepai/InstaGeo-E2E-Geospatial-ML.git

</details>


### [23] [Beyond Spectral Peaks: Interpreting the Cues Behind Synthetic Image Detection](https://arxiv.org/abs/2510.05633)
*Sara Mandelli,Diego Vila-Portela,David Vázquez-Padín,Paolo Bestagini,Fernando Pérez-González*

Main category: cs.CV

TL;DR: 本论文系统研究了频域特征（尤其是周期性光谱峰）在深度伪造鉴别中的作用，发现现有检测器并不真正依赖于这些特征。


<details>
  <summary>Details</summary>
Motivation: 频域光谱峰被广泛认为是合成图像的重要鉴别特征，但当前深度学习模型像黑盒一样不透明，实际是否依赖于这些峰尚不明确，限制了可解释性和可信度。

Method: 提出了一种去除图像频谱峰的策略，并分析其对不同检测器性能的影响。此外，提出了一个仅依赖频谱峰的线性检测器作为可解释的基线方法。

Result: 实验结果表明大多数检测器并不真正依赖于频谱峰，这一发现挑战了现有的主流看法。

Conclusion: 该研究推进了对深度伪造检测器的理解，有助于开发更透明、可靠的取证工具。

Abstract: Over the years, the forensics community has proposed several deep
learning-based detectors to mitigate the risks of generative AI. Recently,
frequency-domain artifacts (particularly periodic peaks in the magnitude
spectrum), have received significant attention, as they have been often
considered a strong indicator of synthetic image generation. However,
state-of-the-art detectors are typically used as black-boxes, and it still
remains unclear whether they truly rely on these peaks. This limits their
interpretability and trust. In this work, we conduct a systematic study to
address this question. We propose a strategy to remove spectral peaks from
images and analyze the impact of this operation on several detectors. In
addition, we introduce a simple linear detector that relies exclusively on
frequency peaks, providing a fully interpretable baseline free from the
confounding influence of deep learning. Our findings reveal that most detectors
are not fundamentally dependent on spectral peaks, challenging a widespread
assumption in the field and paving the way for more transparent and reliable
forensic tools.

</details>


### [24] [Combined Hyperbolic and Euclidean Soft Triple Loss Beyond the Single Space Deep Metric Learning](https://arxiv.org/abs/2510.05643)
*Shozo Saeki,Minoru Kawahara,Hirohisa Aman*

Main category: cs.CV

TL;DR: 本文提出了一种结合超球面和欧氏空间的代理损失（CHEST loss）用于深度度量学习，提升了精度和稳定性并达到最新最优效果。


<details>
  <summary>Details</summary>
Motivation: 超球面空间能更好地表达层次或树型结构，适用于深度度量学习（DML），但传统代理损失难以直接应用于超球面空间。而代理损失对于大规模数据集有训练复杂度低的优势，因此需要解决如何在超球面空间中应用代理损失。

Method: 提出CHEST loss，将超球面和欧氏空间的代理损失与超球面分层聚类正则化损失结合。即利用两种空间特性，并通过正则化促进表示学习。

Result: 该方法在四个基准数据集上进行了评估，结果显示在DML任务中，准确性和训练稳定性均有提升，并刷新了最新的性能记录。

Conclusion: 结合超球面和欧氏空间的代理损失有助于充分利用二者的优势，不仅提升了DML性能，同时保证了训练的高效性和稳定性。

Abstract: Deep metric learning (DML) aims to learn a neural network mapping data to an
embedding space, which can represent semantic similarity between data points.
Hyperbolic space is attractive for DML since it can represent richer
structures, such as tree structures. DML in hyperbolic space is based on
pair-based loss or unsupervised regularization loss. On the other hand,
supervised proxy-based losses in hyperbolic space have not been reported yet
due to some issues in applying proxy-based losses in a hyperbolic space.
However, proxy-based losses are attractive for large-scale datasets since they
have less training complexity. To address these, this paper proposes the
Combined Hyperbolic and Euclidean Soft Triple (CHEST) loss. CHEST loss is
composed of the proxy-based losses in hyperbolic and Euclidean spaces and the
regularization loss based on hyperbolic hierarchical clustering. We find that
the combination of hyperbolic and Euclidean spaces improves DML accuracy and
learning stability for both spaces. Finally, we evaluate the CHEST loss on four
benchmark datasets, achieving a new state-of-the-art performance.

</details>


### [25] [Ocular-Induced Abnormal Head Posture: Diagnosis and Missing Data Imputation](https://arxiv.org/abs/2510.05649)
*Saja Al-Dabet,Sherzod Turaev,Nazar Zaki,Arif O. Khan,Luai Eldweik*

Main category: cs.CV

TL;DR: 本研究提出了两种深度学习框架，用于AHP（眼源性异常头位）的自动诊断与应对缺失数据，显著提升了诊断准确率。


<details>
  <summary>Details</summary>
Motivation: AHP常因斜视等眼部问题引起，早期诊断可减少并发症，但现有方法主观性强且受限于不完整的医疗记录。因此亟需自动化、客观、鲁棒的诊断工具。

Method: 提出AHP-CADNet多级注意力融合框架，整合眼部标志点、头部姿态特征及结构化临床属性，生成可解释的诊断预测。设计基于课程学习的缺失数据插补框架，融合结构化变量和非结构化临床笔记，逐步提升数据复原与诊断鲁棒性。

Result: 在PoseGaze-AHP数据集上，AHP-CADNet分类准确率达96.9%-99.0%，连续变量预测MAE为0.103-0.199且R2>0.93。插补框架在所有临床变量的准确率均维持在93.46%-99.78%，且临床依赖建模显著提升效果（p<0.001）。

Conclusion: 两大深度学习框架在自动诊断AHP及处理缺失数据方面均表现出色，有望提升临床诊断的客观性与实用性。

Abstract: Ocular-induced abnormal head posture (AHP) is a compensatory mechanism that
arises from ocular misalignment conditions, such as strabismus, enabling
patients to reduce diplopia and preserve binocular vision. Early diagnosis
minimizes morbidity and secondary complications such as facial asymmetry;
however, current clinical assessments remain largely subjective and are further
complicated by incomplete medical records. This study addresses both challenges
through two complementary deep learning frameworks. First, AHP-CADNet is a
multi-level attention fusion framework for automated diagnosis that integrates
ocular landmarks, head pose features, and structured clinical attributes to
generate interpretable predictions. Second, a curriculum learning-based
imputation framework is designed to mitigate missing data by progressively
leveraging structured variables and unstructured clinical notes to enhance
diagnostic robustness under realistic data conditions. Evaluation on the
PoseGaze-AHP dataset demonstrates robust diagnostic performance. AHP-CADNet
achieves 96.9-99.0 percent accuracy across classification tasks and low
prediction errors for continuous variables, with MAE ranging from 0.103 to
0.199 and R2 exceeding 0.93. The imputation framework maintains high accuracy
across all clinical variables (93.46-99.78 percent with PubMedBERT), with
clinical dependency modeling yielding significant improvements (p < 0.001).
These findings confirm the effectiveness of both frameworks for automated
diagnosis and recovery from missing data in clinical settings.

</details>


### [26] [EduVerse: A User-Defined Multi-Agent Simulation Space for Education Scenario](https://arxiv.org/abs/2510.05650)
*Yiping Ma,Shiyu Hu,Buyuan Zhu,Yipei Wang,Yaxuan Kang,Shiqing Liu,Kang Hao Cheong*

Main category: cs.CV

TL;DR: EduVerse是一个能真实模拟认知发展、小组互动和课堂长期演化的多智能体虚拟教室平台，并兼顾现实性、可复现性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 目前教育AI难以系统性再现真实教室中的开放式认知、动态社会互动、情感因素等多维复杂过程，现有方法多聚焦单一、短期场景，缺乏对复杂教室环境的全面研究和任务复用能力。

Method: 提出EduVerse，一个支持用户自定义环境、智能体和教学多轮次演化的多智能体仿真空间，具备人机协作接口，基于分层CIE（认知-互动-进化）架构，能实现个体一致性、真实互动和纵向适应。

Result: EduVerse在初中语文多类型文本和环境下实验显示：仿真互动IRF率与真实课堂接近（0.28-0.64 vs 0.37-0.49），小组互动和角色分化表现合理（网络密度0.27-0.40），跨多轮教学正向行为转变增加11.7%，展示了行为、情绪和认知随时间的发展轨迹。

Conclusion: EduVerse有效兼顾仿真教室真实性与可研究性，为教育AI提供可扩展的研究平台，开放源码有助于促进交叉学科研究。

Abstract: Reproducing cognitive development, group interaction, and long-term evolution
in virtual classrooms remains a core challenge for educational AI, as real
classrooms integrate open-ended cognition, dynamic social interaction,
affective factors, and multi-session development rarely captured together.
Existing approaches mostly focus on short-term or single-agent settings,
limiting systematic study of classroom complexity and cross-task reuse. We
present EduVerse, the first user-defined multi-agent simulation space that
supports environment, agent, and session customization. A distinctive
human-in-the-loop interface further allows real users to join the space. Built
on a layered CIE (Cognition-Interaction-Evolution) architecture, EduVerse
ensures individual consistency, authentic interaction, and longitudinal
adaptation in cognition, emotion, and behavior-reproducing realistic classroom
dynamics with seamless human-agent integration. We validate EduVerse in
middle-school Chinese classes across three text genres, environments, and
multiple sessions. Results show: (1) Instructional alignment: simulated IRF
rates (0.28-0.64) closely match real classrooms (0.37-0.49), indicating
pedagogical realism; (2) Group interaction and role differentiation: network
density (0.27-0.40) with about one-third of peer links realized, while
human-agent tasks indicate a balance between individual variability and
instructional stability; (3) Cross-session evolution: the positive transition
rate R+ increase by 11.7% on average, capturing longitudinal shifts in
behavior, emotion, and cognition and revealing structured learning
trajectories. Overall, EduVerse balances realism, reproducibility, and
interpretability, providing a scalable platform for educational AI. The system
will be open-sourced to foster cross-disciplinary research.

</details>


### [27] [SD-MVSum: Script-Driven Multimodal Video Summarization Method and Datasets](https://arxiv.org/abs/2510.05652)
*Manolis Mylonas,Charalampia Zerva,Evlampios Apostolidis,Vasileios Mezaris*

Main category: cs.CV

TL;DR: 本文提出了一种新的脚本驱动多模态视频摘要方法（SD-MVSum），结合视频画面及语音内容，通过加权跨模态注意力机制提升摘要与用户脚本的相关性，并扩展了现有大规模数据集以支持该方法。实验结果显示该方法在视频摘要任务上具有竞争力。


<details>
  <summary>Details</summary>
Motivation: 以往脚本驱动的视频摘要方法只关注视觉内容，忽视了视频中语音（如解说、对白）与脚本的关联，无法全面反映用户关注重点。为提升摘要质量，有必要将脚本与视频语音内容的相关性纳入模型。

Method: 提出SD-MVSum方法，通过新颖的加权跨模态注意力机制同时建模脚本与视频视觉内容、脚本与视频转录语音内容的语义关系，突出与用户脚本最相关的视频片段。此外，扩展了两个大规模视频摘要数据集，使其适用于多模态脚本驱动方法的训练和测试。

Result: 实验对比表明，SD-MVSum在脚本驱动和通用视频摘要任务上均优于或相当于其他先进算法。同时，扩展后的数据集为相关研究提供了新资源。

Conclusion: 将脚本与视频语音内容结合可以提升脚本驱动视频摘要的相关性和质量。提出的SD-MVSum方法和新数据集对推动多模态视频摘要研究具有重要意义。

Abstract: In this work, we extend a recent method for script-driven video
summarization, originally considering just the visual content of the video, to
take into account the relevance of the user-provided script also with the
video's spoken content. In the proposed method, SD-MVSum, the dependence
between each considered pair of data modalities, i.e., script-video and
script-transcript, is modeled using a new weighted cross-modal attention
mechanism. This explicitly exploits the semantic similarity between the paired
modalities in order to promote the parts of the full-length video with the
highest relevance to the user-provided script. Furthermore, we extend two
large-scale datasets for video summarization (S-VideoXum, MrHiSum), to make
them suitable for training and evaluation of script-driven multimodal video
summarization methods. Experimental comparisons document the competitiveness of
our SD-MVSum method against other SOTA approaches for script-driven and generic
video summarization. Our new method and extended datasets are available at:
https://github.com/IDT-ITI/SD-MVSum.

</details>


### [28] [A Hierarchical Geometry-guided Transformer for Histological Subtyping of Primary Liver Cancer](https://arxiv.org/abs/2510.05657)
*Anwen Lu,Mingxin Liu,Yiping Jiao,Hongyi Gong,Geyang Xu,Jun Chen,Jun Xu*

Main category: cs.CV

TL;DR: 本文提出一种新的方法ARGUS，用于提升肝癌组织学亚型分类的准确性，通过多尺度（宏观、中观、微观）信息整合，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 肝癌（特别是肝细胞癌和肝内胆管癌）表现出组织学和细胞结构的高度异质性，现有方法对全切片图像（WSIs）中的关键描述信息挖掘不足，亚型分型效果有限。

Method: 1）设计微观几何特征，利用细胞核结构表达细粒度形态信息；2）构建多层次视野对齐模块，捕捉图像中宏观和中观的分层交互；3）通过先验几何融合策略将微观与宏观/中观特征整合，实现整体表型建模。

Result: 在公开和自有数据集上实验表明，ARGUS方法在肝癌组织学分型上达到了最新最优性能（SOTA）。

Conclusion: ARGUS能更深入和准确地对肝癌进行组织学亚型识别，提高诊断效果，具有良好的临床应用前景。

Abstract: Primary liver malignancies are widely recognized as the most heterogeneous
and prognostically diverse cancers of the digestive system. Among these,
hepatocellular carcinoma (HCC) and intrahepatic cholangiocarcinoma (ICC) emerge
as the two principal histological subtypes, demonstrating significantly greater
complexity in tissue morphology and cellular architecture than other common
tumors. The intricate representation of features in Whole Slide Images (WSIs)
encompasses abundant crucial information for liver cancer histological
subtyping, regarding hierarchical pyramid structure, tumor microenvironment
(TME), and geometric representation. However, recent approaches have not
adequately exploited these indispensable effective descriptors, resulting in a
limited understanding of histological representation and suboptimal subtyping
performance. To mitigate these limitations, ARGUS is proposed to advance
histological subtyping in liver cancer by capturing the macro-meso-micro
hierarchical information within the TME. Specifically, we first construct a
micro-geometry feature to represent fine-grained cell-level pattern via a
geometric structure across nuclei, thereby providing a more refined and precise
perspective for delineating pathological images. Then, a Hierarchical
Field-of-Views (FoVs) Alignment module is designed to model macro- and
meso-level hierarchical interactions inherent in WSIs. Finally, the augmented
micro-geometry and FoVs features are fused into a joint representation via
present Geometry Prior Guided Fusion strategy for modeling holistic phenotype
interactions. Extensive experiments on public and private cohorts demonstrate
that our ARGUS achieves state-of-the-art (SOTA) performance in histological
subtyping of liver cancer, which provide an effective diagnostic tool for
primary liver malignancies in clinical practice.

</details>


### [29] [Teleportraits: Training-Free People Insertion into Any Scene](https://arxiv.org/abs/2510.05660)
*Jialu Gao,K J Joseph,Fernando De La Torre*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的新方法，将参考图片中的人物真实地插入到背景场景中，利用了预训练的扩散模型，方法效果在背景和人物身份保持方面均达到了最佳。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常把人物定位与个性化处理分开，且依赖大量训练，这导致效率低且未充分探索两者之间的联系。作者希望提出一种统一且无需训练的方法，提高效率并保持高质量插入效果。

Method: 作者设计了一个统一的训练自由流程，结合预训练文本-图像扩散模型，通过结合反演技术与classifier-free guidance，实现感知场景可能性的全局编辑，能自动决定人物合理的位置和姿态。同时，创新性地提出了基于掩膜引导的自注意力机制，使得人物在插入时能够良好地保持身份、服装和身体特征，仅需一张参考图。

Result: 实验表明，该方法无需特定任务训练即可将人物自然插入复杂场景中，视觉效果和身份保持性均达到了当前最优水平。

Conclusion: 本文首次实现了真正意义上训练自由的人物场景插入，且在背景及主体身份保持方面优于以往方法，在多样的复合场景测试中展现了先进效果。

Abstract: The task of realistically inserting a human from a reference image into a
background scene is highly challenging, requiring the model to (1) determine
the correct location and poses of the person and (2) perform high-quality
personalization conditioned on the background. Previous approaches often treat
them as separate problems, overlooking their interconnections, and typically
rely on training to achieve high performance. In this work, we introduce a
unified training-free pipeline that leverages pre-trained text-to-image
diffusion models. We show that diffusion models inherently possess the
knowledge to place people in complex scenes without requiring task-specific
training. By combining inversion techniques with classifier-free guidance, our
method achieves affordance-aware global editing, seamlessly inserting people
into scenes. Furthermore, our proposed mask-guided self-attention mechanism
ensures high-quality personalization, preserving the subject's identity,
clothing, and body features from just a single reference image. To the best of
our knowledge, we are the first to perform realistic human insertions into
scenes in a training-free manner and achieve state-of-the-art results in
diverse composite scene images with excellent identity preservation in
backgrounds and subjects.

</details>


### [30] [When and How to Cut Classical Concerts? A Multimodal Automated Video Editing Approach](https://arxiv.org/abs/2510.05661)
*Daniel Gonzálbez-Biosca,Josep Cabacas-Maso,Carles Ventura,Ismael Benito-Altamirano*

Main category: cs.CV

TL;DR: 本文提出了一种面向多摄像机古典音乐会录像的自动视频编辑方法，通过创新的多模态架构，有效提升了剪切时机检测和镜头选择的准确性，推动了自动化视频编辑技术的发展。


<details>
  <summary>Details</summary>
Motivation: 虽然视频生成和场景理解领域受到广泛关注，但自动视频编辑，特别是对多摄像机音乐会录像的自动编辑，仍然研究不足。现有方法在“剪切时机”与“剪切镜头选择”的准确性和多模态融合方面存在局限。作者希望通过新方法提升自动视频编辑的效果。

Method: 作者将自动编辑任务分为“何时剪切（when to cut）”和“如何剪切（how to cut）”两个子任务：剪切时机通过结合音频的log-mel谱、可选的图像嵌入和时序特征，采用轻量化卷积-Transformer架构；镜头选择部分则采用CLIP编码器替换旧有骨干网络，并将选择范围限定于同一场音乐会内。此外，作者利用伪标签方法构建了数据集，自动聚类生成剪辑片段。

Result: 实验表明，所提模型在剪切点检测上优于之前的基线方法，视觉片段选择也具有较强竞争力，整体提升了多模态自动化视频编辑的性能。

Conclusion: 该研究提出的多模态和改进特征融合架构，有效促进了自动视频编辑技术的进步，使得多摄像机演出录像自动编辑变得更精准和实用。

Abstract: Automated video editing remains an underexplored task in the computer vision
and multimedia domains, especially when contrasted with the growing interest in
video generation and scene understanding. In this work, we address the specific
challenge of editing multicamera recordings of classical music concerts by
decomposing the problem into two key sub-tasks: when to cut and how to cut.
Building on recent literature, we propose a novel multimodal architecture for
the temporal segmentation task (when to cut), which integrates log-mel
spectrograms from the audio signals, plus an optional image embedding, and
scalar temporal features through a lightweight convolutional-transformer
pipeline. For the spatial selection task (how to cut), we improve the
literature by updating from old backbones, e.g. ResNet, with a CLIP-based
encoder and constraining distractor selection to segments from the same
concert. Our dataset was constructed following a pseudo-labeling approach, in
which raw video data was automatically clustered into coherent shot segments.
We show that our models outperformed previous baselines in detecting cut points
and provide competitive visual shot selection, advancing the state of the art
in multimodal automated video editing.

</details>


### [31] [Development and Validation of a Low-Cost Imaging System for Seedling Germination Kinetics through Time-Cumulative Analysis](https://arxiv.org/abs/2510.05668)
*M. Torrente,A. Follador,A. Calcante,P. Casati,R. Oberti*

Main category: cs.CV

TL;DR: 该研究利用低成本的多摄像头成像系统和创新性时序图像分析算法，监测R. solani侵染对生菜种子萌发及幼苗早期发育的影响。新方法在种子识别和生长量化上表现出高度准确性，尤其适用于幼苗重叠密集场景。结果显示，R. solani显著抑制萌发率和幼苗活力。


<details>
  <summary>Details</summary>
Motivation: R. solani是一种重要的病原菌，影响作物早期生长阶段，但其对生菜种子萌发和幼苗发育的定量研究有限，且传统图像分析方法难以应对复杂生长环境。因此，作者希望开发一种低成本且高效的非破坏性表型监测方法。

Method: 搭建多摄像头低成本成像系统，持续采集生菜萌发和幼苗生长图像。开发结合形态与空间特征的图像分析新算法，并将时序信息整合进识别与计数流程，解决传统分割方法遇到的幼苗重叠、交错问题，提升种子和幼苗识别准确率。

Result: 该方法在幼苗计数和活力评估中表现出高准确度，决定系数R^2为0.98，均方根误差1.12。实验表明，R. solani感染组的种子萌发率和幼苗活力明显下降。提出的时序分析系统在幼苗高密度和叶片重叠环境下依然可以精确追踪个体生长动态。

Conclusion: 结合低成本图像采集与先进时序分析工具能够非破坏性、高通量、精准地进行植物表型监测。所提方法极大提高复杂场景下的幼苗识别和量化能力，为病原菌胁迫下作物早期发育研究提供了有效工具。

Abstract: The study investigates the effects of R. solani inoculation on the
germination and early development of Lactuca sativa L. seeds using a low-cost,
image-based monitoring system. Multiple cameras were deployed to continuously
capture images of the germination process in both infected and control groups.
The objective was to assess the impact of the pathogen by analyzing germination
dynamics and growth over time. To achieve this, a novel image analysis pipeline
was developed. The algorithm integrates both morphological and spatial features
to identify and quantify individual seedlings, even under complex conditions
where traditional image analyses fails. A key innovation of the method lies in
its temporal integration: each analysis step considers not only the current
status but also their developmental across prior time points. This approach
enables robust discrimination of individual seedlings, especially when
overlapping leaves significantly hinder object separation. The method
demonstrated high accuracy in seedling counting and vigor assessment, even in
challenging scenarios characterized by dense and intertwined growth. Results
confirm that R. solani infection significantly reduces germination rates and
early seedling vigor. The study also validates the feasibility of combining
low-cost imaging hardware with advanced computational tools to obtain
phenotyping data in a non-destructive and scalable manner. The temporal
integration enabled accurate quantification of germinated seeds and precise
determination of seedling emergence timing. This approach proved particularly
effective in later stages of the experiment, where conventional segmentation
techniques failed due to overlapping or intertwined seedlings, making accurate
counting. The method achieved a coefficient of determination of 0.98 and a root
mean square error (RMSE) of 1.12, demonstrating its robustness and reliability.

</details>


### [32] [Context Matters: Learning Global Semantics for Visual Reasoning and Comprehension](https://arxiv.org/abs/2510.05674)
*Jike Zhong,Yuxiang Lai,Xiaofeng Yang,Konstantinos Psounis*

Main category: cs.CV

TL;DR: 本文针对视觉模型在推理和上下文学习能力落后于语言模型的问题，提出通过语义化的目标函数提升ViT表现，尤其是在以‘物体’为语义单元上实现更有效的视觉建模。


<details>
  <summary>Details</summary>
Motivation: 当前视觉模型与语言模型在推理和上下文学习方面存在差距，作者认为主要原因在于视觉Transformer训练缺乏语义和上下文信息引导，导致难以学习真实的视觉分布。

Method: 提出以物体为视觉等价的‘单词’，在遮蔽图像建模（MIM）框架下用物体掩码代替随机patch掩码，引导模型学习全局语义与上下文关系。

Result: 定性和定量实验表明，基于物体级别的编码能有效学习现实世界的视觉分布，缓解像素平均等捷径问题。在多模态大模型VQA等任务上，该方法显著提升了模型推理与理解能力。

Conclusion: 物体级别的视觉表征对改善视觉模型的推理与上下文学习能力至关重要，为未来构建更强的视觉编码器和Tokenizer指明了新的研究路径。

Abstract: Recent advances in language modeling have witnessed the rise of highly
desirable emergent capabilities, such as reasoning and in-context learning.
However, vision models have yet to exhibit comparable progress in these areas.
In this paper, we argue that this gap could stem from the lack of semantic and
contextual guidance in current vision transformer (ViT) training schemes, and
such a gap can be narrowed through the design of a semantic-grounded objective.
Specifically, we notice that individual words in natural language are
inherently semantic, and modeling directly on word tokens naturally learns a
realistic distribution. In contrast, ViTs rely on spatial patchification, which
inevitably lacks semantic information. To bridge this gap, we propose to
directly model "object" as the visual equivalence of "word," pushing the model
to learn the global context and semantics among visual elements. We investigate
our hypotheses via masked image modeling (MIM), a framework where our approach
can be readily tested by applying masks to visual objects rather than random
patches. Considerable evidence from qualitative and quantitative evaluations
reveals a key finding: object-level representation alone helps to learn a
real-world distribution, whereas pixel-averaging shortcuts are often learned
without it. Moreover, further evaluations with multimodal LLMs (MLLM) on visual
question answering (VQA, GQA, ScienceQA) tasks demonstrate the strong reasoning
and contextual understanding gained with this simple objective. We hope our
study highlights the effectiveness of object-level encoding and provides a
plausible direction for developing stronger vision encoders and tokenizers.
Code and model will be publicly released. Keywords: Semantic Visual Tokenizer,
Vision Reasoning, In-context Learning, Multimodal Reasoning

</details>


### [33] [AgeBooth: Controllable Facial Aging and Rejuvenation via Diffusion Models](https://arxiv.org/abs/2510.05715)
*Shihao Zhu,Bohan Cao,Ziheng Ouyang,Zhen Li,Peng-Tao Jiang,Qibin Hou*

Main category: cs.CV

TL;DR: AgeBooth提出了一种高效的年龄控制人脸生成方法，无需大量带年龄标签的数据即可实现高质量且身份一致的年龄变化图像生成，在年龄控制和视觉质量上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型虽然能依据参考图像生成保持身份一致的图像，但难以精确控制年龄变化，且模型微调往往需要高成本的跨年龄配对数据。研究者希望找到一种无需昂贵数据集的高效年龄控制方法。

Method: 提出AgeBooth方法。主要包括两个创新点：1）年龄条件的prompt blending，利用年龄的线性特性融合不同年龄提示；2）采用age-specific LoRA融合策略（基于SVDMix矩阵融合技术），仅用少量年龄信息提高模型对年龄特征的控制能力。该方案无需依赖大量带年龄标签的数据集。

Result: AgeBooth能够直接从单张参考照生成不同年龄段的真实且身份一致的人脸图像。大量实验证实，该方法的年龄控制精确性与生成质量均优于现有基于编辑的生成方法。

Conclusion: AgeBooth在不增加数据与计算成本的前提下，有效提升了人脸年龄变化控制能力，为身份保真的人脸生成提供了新途径，对后续研究有重要启发和实用价值。

Abstract: Recent diffusion model research focuses on generating identity-consistent
images from a reference photo, but they struggle to accurately control age
while preserving identity, and fine-tuning such models often requires costly
paired images across ages. In this paper, we propose AgeBooth, a novel
age-specific finetuning approach that can effectively enhance the age control
capability of adapterbased identity personalization models without the need for
expensive age-varied datasets. To reduce dependence on a large amount of
age-labeled data, we exploit the linear nature of aging by introducing
age-conditioned prompt blending and an age-specific LoRA fusion strategy that
leverages SVDMix, a matrix fusion technique. These techniques enable
high-quality generation of intermediate-age portraits. Our AgeBooth produces
realistic and identity-consistent face images across different ages from a
single reference image. Experiments show that AgeBooth achieves superior age
control and visual quality compared to previous state-of-the-art editing-based
methods.

</details>


### [34] [Dropping the D: RGB-D SLAM Without the Depth Sensor](https://arxiv.org/abs/2510.06216)
*Mert Kiray,Alican Karaomer,Benjamin Busam*

Main category: cs.CV

TL;DR: 提出了DropD-SLAM，一个可以不依赖深度传感器而达到RGB-D精度的实时单目SLAM系统。通过结合三个预训练的视觉模型，实现了鲁棒且高精度的跟踪与建图。


<details>
  <summary>Details</summary>
Motivation: 目前高精度SLAM多依赖昂贵的主动式深度传感器，而如何利用廉价的单目设备在动态和静态环境下达成等同甚至超越RGB-D的定位与建图精度是学界和工业界关注难题。

Method: DropD-SLAM用三个预训练视觉模块（单目深度估计、关键点检测、实例分割）替换主动深度输入。动态对象通过膨胀实例掩码剔除，静态关键点用深度估计值反投影到三维，形成具有尺度信息的特征点，然后直接送入传统RGB-D SLAM后端进行跟踪和建图。

Result: 在TUM RGB-D基准测试数据集上，DropD-SLAM在静态场景中平均ATE为7.4cm，在动态场景中为1.8cm，匹配并部分超越现有RGB-D方法，同时在单GPU上以22FPS运行。

Conclusion: 现代预训练视觉模型有望完全取代昂贵的主动深度传感器，实现更简单、低成本的实时高精度SLAM系统。

Abstract: We present DropD-SLAM, a real-time monocular SLAM system that achieves
RGB-D-level accuracy without relying on depth sensors. The system replaces
active depth input with three pretrained vision modules: a monocular metric
depth estimator, a learned keypoint detector, and an instance segmentation
network. Dynamic objects are suppressed using dilated instance masks, while
static keypoints are assigned predicted depth values and backprojected into 3D
to form metrically scaled features. These are processed by an unmodified RGB-D
SLAM back end for tracking and mapping. On the TUM RGB-D benchmark, DropD-SLAM
attains 7.4 cm mean ATE on static sequences and 1.8 cm on dynamic sequences,
matching or surpassing state-of-the-art RGB-D methods while operating at 22 FPS
on a single GPU. These results suggest that modern pretrained vision models can
replace active depth sensors as reliable, real-time sources of metric scale,
marking a step toward simpler and more cost-effective SLAM systems.

</details>


### [35] [Data Factory with Minimal Human Effort Using VLMs](https://arxiv.org/abs/2510.05722)
*Jiaojiao Ye,Jiaxing Zhong,Qian Xie,Yuzhou Zhou,Niki Trigoni,Andrew Markham*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的新颖数据增广管道，利用预训练的ControlNet和视觉-语言模型自动生成带像素级标签的合成图像，以提升小样本语义分割性能，并在PASCAL-5i与COCO-20i数据集上取得了领先结果。


<details>
  <summary>Details</summary>
Motivation: 收集和逐像素标注图像非常耗时费力，传统数据增强方法难以操作高级语义属性（如材质、纹理），现有扩散模型方法要么开销大，要么表现不佳。因此，亟需高效、自动化且性能优异的数据合成方法以支持语义分割等下游任务训练。

Method: 提出一种新的训练自由型管道：融合预训练的ControlNet与视觉-语言模型（VLM），生成合成图像和像素级标签；引入多方式提示生成器（Multi-way Prompt Generator）、掩码生成器（Mask Generator）以及高质量图像筛选模块，以提升图像多样性和质量。

Result: 在主流小样本分割基准数据集PASCAL-5i和COCO-20i上，该方法表现优异，超越了当前主流扩散模型增广手段的性能。

Conclusion: 利用预训练模型自动生成带像素级标签的数据，可以有效取代传统人工标注，提升数据多样性并增强分割模型性能，为相关自动标注与数据增强工作带来新思路。

Abstract: Generating enough and diverse data through augmentation offers an efficient
solution to the time-consuming and labour-intensive process of collecting and
annotating pixel-wise images. Traditional data augmentation techniques often
face challenges in manipulating high-level semantic attributes, such as
materials and textures. In contrast, diffusion models offer a robust
alternative, by effectively utilizing text-to-image or image-to-image
transformation. However, existing diffusion-based methods are either
computationally expensive or compromise on performance. To address this issue,
we introduce a novel training-free pipeline that integrates pretrained
ControlNet and Vision-Language Models (VLMs) to generate synthetic images
paired with pixel-level labels. This approach eliminates the need for manual
annotations and significantly improves downstream tasks. To improve the
fidelity and diversity, we add a Multi-way Prompt Generator, Mask Generator and
High-quality Image Selection module. Our results on PASCAL-5i and COCO-20i
present promising performance and outperform concurrent work for one-shot
semantic segmentation.

</details>


### [36] [Redefining Generalization in Visual Domains: A Two-Axis Framework for Fake Image Detection with FusionDetect](https://arxiv.org/abs/2510.05740)
*Amirtaha Amanzadi,Zahra Dehghanian,Hamid Beigy,Hamid R. Rabiee*

Main category: cs.CV

TL;DR: 本文提出了OmniGen测试集和新方法FusionDetect，有效提升了AI合成图像的检测能力，尤其在跨生成器与跨视觉域的泛化能力上取得突破。


<details>
  <summary>Details</summary>
Motivation: 当前AI图像检测主要关注跨生成器的泛化，但实际更需解决跨视觉域的泛化挑战。传统方案评估不足以覆盖现实复杂情况，需要更全面的测试和更强的检测方法。

Method: 作者推出OmniGen基准数据集，包含12种主流生成器，模拟真实检测环境。同时提出FusionDetect方法，结合CLIP与Dinov2两个预训练基础模型的特征，融合得到适应不同生成器与内容变化的特征空间。

Result: 实验显示FusionDetect在主流基准中比同类方法提升3.87%准确率、6.13%精度，OmniGen数据集上准确率提升4.48%，且对常见图像扰动更具鲁棒性。

Conclusion: 该工作不仅提供了性能卓越的检测器，还提出了新的评测基准和框架，为通用AI图像检测研究奠定了基础。

Abstract: The rapid development of generative models has made it increasingly crucial
to develop detectors that can reliably detect synthetic images. Although most
of the work has now focused on cross-generator generalization, we argue that
this viewpoint is too limited. Detecting synthetic images involves another
equally important challenge: generalization across visual domains. To bridge
this gap,we present the OmniGen Benchmark. This comprehensive evaluation
dataset incorporates 12 state-of-the-art generators, providing a more realistic
way of evaluating detector performance under realistic conditions. In addition,
we introduce a new method, FusionDetect, aimed at addressing both vectors of
generalization. FusionDetect draws on the benefits of two frozen foundation
models: CLIP & Dinov2. By deriving features from both complementary models,we
develop a cohesive feature space that naturally adapts to changes in both
thecontent and design of the generator. Our extensive experiments demonstrate
that FusionDetect delivers not only a new state-of-the-art, which is 3.87% more
accurate than its closest competitor and 6.13% more precise on average on
established benchmarks, but also achieves a 4.48% increase in accuracy on
OmniGen,along with exceptional robustness to common image perturbations. We
introduce not only a top-performing detector, but also a new benchmark and
framework for furthering universal AI image detection. The code and dataset are
available at http://github.com/amir-aman/FusionDetect

</details>


### [37] [ALISE: Annotation-Free LiDAR Instance Segmentation for Autonomous Driving](https://arxiv.org/abs/2510.05752)
*Yongxuan Lyu,Guangfeng Jiang,Hongsi Liu,Jun Liu*

Main category: cs.CV

TL;DR: 本文提出ALISE框架，实现了完全无监督的户外LiDAR点云实例分割，大幅降低人工标注成本，并达到领先性能。


<details>
  <summary>Details</summary>
Motivation: 手工标注LiDAR点云数据用于实例分割既昂贵又耗时，即使现有方法降低了部分需求，仍需依赖人工标签。因此，开发完全无监督的分割方法以彻底消除人工依赖具有重要意义。

Method: ALISE框架融合Vision Foundation Models（VFM）生成初始伪标签，随后通过时空投票模块结合2D和3D语义优化标签。特征学习过程中引入2D先验损失与新型基于原型的对比损失，提升网络的判别能力。

Result: 在完全无监督条件下，ALISE方法在3D实例分割任务上性能显著优于现有技术，比依赖真实2D标注的MWSIS方法mAP高2.53%。

Conclusion: ALISE框架证明了在不依赖人工标注的前提下，通过多步伪标签生成和优化，可以实现高质量的3D实例分割，推动了无监督点云分割研究的发展。

Abstract: The manual annotation of outdoor LiDAR point clouds for instance segmentation
is extremely costly and time-consuming. Current methods attempt to reduce this
burden but still rely on some form of human labeling. To completely eliminate
this dependency, we introduce ALISE, a novel framework that performs LiDAR
instance segmentation without any annotations. The central challenge is to
generate high-quality pseudo-labels in a fully unsupervised manner. Our
approach starts by employing Vision Foundation Models (VFMs), guided by text
and images, to produce initial pseudo-labels. We then refine these labels
through a dedicated spatio-temporal voting module, which combines 2D and 3D
semantics for both offline and online optimization. To achieve superior feature
learning, we further introduce two forms of semantic supervision: a set of 2D
prior-based losses that inject visual knowledge into the 3D network, and a
novel prototype-based contrastive loss that builds a discriminative feature
space by exploiting 3D semantic consistency. This comprehensive design results
in significant performance gains, establishing a new state-of-the-art for
unsupervised 3D instance segmentation. Remarkably, our approach even
outperforms MWSIS, a method that operates with supervision from ground-truth
(GT) 2D bounding boxes by a margin of 2.53% in mAP (50.95% vs. 48.42%).

</details>


### [38] [OneVision: An End-to-End Generative Framework for Multi-view E-commerce Vision Search](https://arxiv.org/abs/2510.05759)
*Zexin Zheng,Huangyu Dai,Lingtao Mao,Xinyu Sun,Zihan Liang,Ben Chen,Yuqing Ding,Chenyi Lei,Wenwu Ou,Han Li,Kun Gai*

Main category: cs.CV

TL;DR: 本文提出了一种端到端的生成式视觉搜索框架OneVision，通过对传统多阶段级联架构进行创新，实现高效且个性化的图片检索推荐。


<details>
  <summary>Details</summary>
Motivation: 传统视觉搜索依赖多阶段处理以平衡效率与转化率，但难以统一不同阶段的目标，导致用户体验和转化效果难以同时最优。

Method: 提出OneVision框架，利用视觉对齐残差量化（VRQ）对多视角表示进行对齐，并采用多阶段语义对齐方案，将视觉相似性和用户个性化结合，动态进行剪枝提升推理效率。

Result: OneVision离线表现与传统多阶段系统相当，推理效率提升21%；在线A/B测试显示item点击率提升2.15%、转化率提升2.27%、订单量提升3.12%。

Conclusion: 基于语义ID的生成式架构可统一检索与个性化流程，并简化系统路径，在保证效率的同时提升用户体验和商业表现。

Abstract: Traditional vision search, similar to search and recommendation systems,
follows the multi-stage cascading architecture (MCA) paradigm to balance
efficiency and conversion. Specifically, the query image undergoes feature
extraction, recall, pre-ranking, and ranking stages, ultimately presenting the
user with semantically similar products that meet their preferences. This
multi-view representation discrepancy of the same object in the query and the
optimization objective collide across these stages, making it difficult to
achieve Pareto optimality in both user experience and conversion. In this
paper, an end-to-end generative framework, OneVision, is proposed to address
these problems. OneVision builds on VRQ, a vision-aligned residual quantization
encoding, which can align the vastly different representations of an object
across multiple viewpoints while preserving the distinctive features of each
product as much as possible. Then a multi-stage semantic alignment scheme is
adopted to maintain strong visual similarity priors while effectively
incorporating user-specific information for personalized preference generation.
In offline evaluations, OneVision performs on par with online MCA, while
improving inference efficiency by 21% through dynamic pruning. In A/B tests, it
achieves significant online improvements: +2.15% item CTR, +2.27% CVR, and
+3.12% order volume. These results demonstrate that a semantic ID centric,
generative architecture can unify retrieval and personalization while
simplifying the serving pathway.

</details>


### [39] [A Novel Technique for Robust Training of Deep Networks With Multisource Weak Labeled Remote Sensing Data](https://arxiv.org/abs/2510.05760)
*Gianmarco Perantoni,Lorenzo Bruzzone*

Main category: cs.CV

TL;DR: 本文提出了一种结合少量高可信标签和大量低可信标签源，并针对每个标签源的可靠性进行加权训练的深度学习方法，有效提升了遥感场景分类的鲁棒性和利用低质量标签的能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在遥感场景分类中需要大量高质量标注数据，但高质量数据获取代价高且数量有限，低质量数据虽然多但噪声高，如何兼顾两者成为问题。

Method: 设计了一种新的多源标签训练策略。具体做法为：将多个弱标签源与少量高可信标签源结合，根据各标签源的错误统计（通过转移矩阵建模），在标签中嵌入这些转移矩阵，并在训练中根据不同源的可靠性对标签加权。加权机制作用于梯度层面，不同实例对不同类别的优化贡献不同权重。

Result: 在不同遥感数据集上实验验证了该方法的有效性。结果表明，该方法对噪声标签鲁棒，能够很好地利用低可信标签源提升模型性能。

Conclusion: 所提方法可以有效结合高可信和低可信标签源，显著提升遥感场景分类任务中深度学习方法的泛化能力和对标签噪声的容错性。

Abstract: Deep learning has gained broad interest in remote sensing image scene
classification thanks to the effectiveness of deep neural networks in
extracting the semantics from complex data. However, deep networks require
large amounts of training samples to obtain good generalization capabilities
and are sensitive to errors in the training labels. This is a problem in remote
sensing since highly reliable labels can be obtained at high costs and in
limited amount. However, many sources of less reliable labeled data are
available, e.g., obsolete digital maps. In order to train deep networks with
larger datasets, we propose both the combination of single or multiple weak
sources of labeled data with a small but reliable dataset to generate
multisource labeled datasets and a novel training strategy where the
reliability of each source is taken in consideration. This is done by
exploiting the transition matrices describing the statistics of the errors of
each source. The transition matrices are embedded into the labels and used
during the training process to weigh each label according to the related
source. The proposed method acts as a weighting scheme at gradient level, where
each instance contributes with different weights to the optimization of
different classes. The effectiveness of the proposed method is validated by
experiments on different datasets. The results proved the robustness and
capability of leveraging on unreliable source of labels of the proposed method.

</details>


### [40] [Mysteries of the Deep: Role of Intermediate Representations in Out of Distribution Detection](https://arxiv.org/abs/2510.05782)
*I. M. De la Jara,C. Rodriguez-Opazo,D. Teney,D. Ranasinghe,E. Abbasnejad*

Main category: cs.CV

TL;DR: 本论文提出在分布外检测中利用预训练模型的中间层表示，而不只是最终输出层，能提升检测准确率。


<details>
  <summary>Details</summary>
Motivation: 现有分布外检测方法大多只利用预训练大模型的最后一层特征，忽视或未充分挖掘中间层的潜在检测价值。本文作者质疑这一做法，认为中间层也可能包含对检测分布偏移有用的信息。

Method: 作者提出使用基于熵的标准，在无需额外分布外数据和无需重新训练的前提下，自动识别并结合多个含互补信息的预训练模型中间层表征，用于提升分布外样本检测性能。

Result: 在多个模型架构和训练目标下，所提方法在远分布外和近分布外基准测试中，检测准确率分别较最优现有无训练方法提升最多10%和7%。

Conclusion: 本文验证了中间层特征在分布外检测中的重要作用，为领域提供了新的研究方向，并分析了不同训练目标和模型架构对基于置信度的分布外检测机制的影响。

Abstract: Out-of-distribution (OOD) detection is essential for reliably deploying
machine learning models in the wild. Yet, most methods treat large pre-trained
models as monolithic encoders and rely solely on their final-layer
representations for detection. We challenge this wisdom. We reveal the
\textit{intermediate layers} of pre-trained models, shaped by residual
connections that subtly transform input projections, \textit{can} encode
\textit{surprisingly rich and diverse signals} for detecting distributional
shifts. Importantly, to exploit latent representation diversity across layers,
we introduce an entropy-based criterion to \textit{automatically} identify
layers offering the most complementary information in a training-free setting
-- \textit{without access to OOD data}. We show that selectively incorporating
these intermediate representations can increase the accuracy of OOD detection
by up to \textbf{$10\%$} in far-OOD and over \textbf{$7\%$} in near-OOD
benchmarks compared to state-of-the-art training-free methods across various
model architectures and training objectives. Our findings reveal a new avenue
for OOD detection research and uncover the impact of various training
objectives and model architectures on confidence-based OOD detection methods.

</details>


### [41] [Rasterized Steered Mixture of Experts for Efficient 2D Image Regression](https://arxiv.org/abs/2510.05814)
*Yi-Hsin Li,Thomas Sikora,Sebastian Knorr,Mårten Sjöström*

Main category: cs.CV

TL;DR: 该论文提出了一种结合栅格化高斯核渲染与Steered Mixture of Experts（SMoE）边缘感知门控机制的新型优化方法，显著提升了二维图像回归任务的计算效率，保留了模型稀疏性和重建质量，同时扩展了原有方法在超分辨率和去噪领域的应用。


<details>
  <summary>Details</summary>
Motivation: 原有Steered Mixture of Experts方法虽然在图像重建、压缩、去噪等任务表现优秀，但因计算量大、效率低而难以实际应用。急需改进优化流程，实现速度和内存效率的提升，同时兼顾模型准确性和稀疏性。

Method: 方法上，作者提出将SMoE的优化由全局迭代模式改为栅格化高斯核渲染方式，结合边缘感知门控机制，减少计算量并提升参数迭代速度，使模型更高效地表示和优化图像回归问题。

Result: 新方法显著加速了参数更新，提高了内存效率，同时在二维图像重建、超分辨率和去噪等任务中取得了与原方法相当甚至更优的表现，且可扩展到标准高斯核无法直接处理的新应用。

Conclusion: 该框架有效地平衡了二维图像处理中的计算效率与重建保真度，为实际应用中的高效高质量图像回归任务提供了新思路和技术支持。

Abstract: The Steered Mixture of Experts regression framework has demonstrated strong
performance in image reconstruction, compression, denoising, and
super-resolution. However, its high computational cost limits practical
applications. This work introduces a rasterization-based optimization strategy
that combines the efficiency of rasterized Gaussian kernel rendering with the
edge-aware gating mechanism of the Steered Mixture of Experts. The proposed
method is designed to accelerate two-dimensional image regression while
maintaining the model's inherent sparsity and reconstruction quality. By
replacing global iterative optimization with a rasterized formulation, the
method achieves significantly faster parameter updates and more
memory-efficient model representations. In addition, the proposed framework
supports applications such as native super-resolution and image denoising,
which are not directly achievable with standard rasterized Gaussian kernel
approaches. The combination of fast rasterized optimization with the edge-aware
structure of the Steered Mixture of Experts provides a new balance between
computational efficiency and reconstruction fidelity for two-dimensional image
processing tasks.

</details>


### [42] [Deformable Image Registration for Self-supervised Cardiac Phase Detection in Multi-View Multi-Disease Cardiac Magnetic Resonance Images](https://arxiv.org/abs/2510.05819)
*Sven Koehler,Sarah Kaye Mueller,Jonathan Kiekenap,Gerald Greil,Tarique Hussain,Samir Sarikouch,Florian André,Norbert Frey,Sandy Engelhardt*

Main category: cs.CV

TL;DR: 本论文提出了一种自监督深度学习方法，可在心脏磁共振（CMR）影像中自动检测多个关键帧，相较常规体积曲线方法在心脏周期分析上取得了显著精度提升。


<details>
  <summary>Details</summary>
Motivation: 现有CMR自动方法主要通过心室体积曲线提取收缩末期（ES）和舒张末期（ED）帧，无法反映心肌运动的细节，影响对心脏动力学的深入分析。为提升关键帧检测的精度，并更好地刻画心肌运动，作者提出新的方法。

Method: 方法首先对CMR影像进行稠密可变形配准，获得运动场后提取一维运动描述符，从而描绘心脏收缩与舒张的动态。随后通过一套简单规则从该描述符中自动检测五个短轴(SAX)和四个四腔长轴(4CH)关键帧。方法在三个公开多中心多疾病数据集（M&Ms-2、M&Ms、ACDC）和一个罕见病患者数据集（GCN）上进行独立评估和泛化测试。

Result: 新方法在ED与ES关键帧检测准确率提升30%-51%（SAX视图）与11%-47%（4CH视图），且平均帧误差（cFD）SAX低于1.31帧、LAX低于1.73帧，较体积法有明显优势。

Conclusion: 所提自监督方法显著提升了CMR多帧关键帧检测准确性，实现了跨周期、跨患者的心脏动力学时序对齐分析，适用于不同长度的心脏周期，有望促进自动心脏功能分析和相关研究。

Abstract: Cardiovascular magnetic resonance (CMR) is the gold standard for assessing
cardiac function, but individual cardiac cycles complicate automatic temporal
comparison or sub-phase analysis. Accurate cardiac keyframe detection can
eliminate this problem. However, automatic methods solely derive end-systole
(ES) and end-diastole (ED) frames from left ventricular volume curves, which do
not provide a deeper insight into myocardial motion. We propose a
self-supervised deep learning method detecting five keyframes in short-axis
(SAX) and four-chamber long-axis (4CH) cine CMR. Initially, dense deformable
registration fields are derived from the images and used to compute a 1D motion
descriptor, which provides valuable insights into global cardiac contraction
and relaxation patterns. From these characteristic curves, keyframes are
determined using a simple set of rules. The method was independently evaluated
for both views using three public, multicentre, multidisease datasets. M&Ms-2
(n=360) dataset was used for training and evaluation, and M&Ms (n=345) and ACDC
(n=100) datasets for repeatability control. Furthermore, generalisability to
patients with rare congenital heart defects was tested using the German
Competence Network (GCN) dataset. Our self-supervised approach achieved
improved detection accuracy by 30% - 51% for SAX and 11% - 47% for 4CH in ED
and ES, as measured by cyclic frame difference (cFD), compared with the
volume-based approach. We can detect ED and ES, as well as three additional
keyframes throughout the cardiac cycle with a mean cFD below 1.31 frames for
SAX and 1.73 for LAX. Our approach enables temporally aligned inter- and
intra-patient analysis of cardiac dynamics, irrespective of cycle or phase
lengths. GitHub repository:
https://github.com/Cardio-AI/cmr-multi-view-phase-detection.git

</details>


### [43] [Flow4Agent: Long-form Video Understanding via Motion Prior from Optical Flow](https://arxiv.org/abs/2510.05836)
*Ruyang Liu,Shangkun Sun,Haoran Tang,Ge Li,Wei Gao*

Main category: cs.CV

TL;DR: 提出了Flow4Agent框架，通过融合光流的运动先验，有效缓解长视频理解中的冗余问题，大幅提升多模态大语言模型对长视频的理解能力。


<details>
  <summary>Details</summary>
Motivation: 长视频在时空维度上存在大量冗余，且目前主流的多模态大模型受限于上下文长度，难以高效处理长视频内容，亟需新的技术减少冗余，并挖掘有效信息。

Method: 提出Flow4Agent，主要包含两个模块：1）时序粒度优化（TGO），使用光流先验对相似内容分组，结合语义先验筛除无关场景；2）运动令牌裁剪（MTP），通过细粒度光流信息裁剪帧内冗余的视频token。该方法优化了时空冗余，引导模型聚焦核心运动、语义信息。

Result: 在Video-MME、MLVU、LongVideoBench等多个长视频理解基准上，Flow4Agent均显著优于现有主流方法，尤其在小时级长视频任务中取得领先分数（如Video-MME 64.7%、MLVU 71.4%、LongVideoBench 60.4%）。

Conclusion: Flow4Agent通过引入运动先验，有效提升了大模型对长视频的理解能力和效率，为多模态长视频智能分析提供了全新思路。

Abstract: Long-form video understanding has always been a challenging problem due to
the significant redundancy in both temporal and spatial contents. This
challenge is further exacerbated by the limited context length of Multimodal
Large Language Models (MLLMs). To address this issue, many previous works have
attempted to extract key video information, where the "key" is typically
semantic-aware and heavily dependent on the CLIP model as prior. In this paper,
we propose Flow4Agent, a novel framework that pioneeringly incorporates motion
priors from optical flow to facilitate LLM-based long video understanding.
Flow4Agent mitigates the redundancy in long videos at both temporal and spatial
levels through two core modules: Temporal Granularity Optimization (TGO)
adaptively refines framelevel hierarchies, which first leverages coarse flow
priors to group similar visual contents and then applies semantic priors to
filter out highly irrelevant scene information. Motion Token Pruning (MTP)
further refines the intra-frame visual representations, pruning high-redundancy
video tokens using fine-grained optical flow information. Extensive experiments
demonstrate that our Flow4Agent outperforms existing methods across a wide
range of video MLLM benchmarks, especially for hour-level video understanding
tasks, achieving 64.7% on Video-MME, 71.4% on MLVU and 60.4% on LongVideoBench.

</details>


### [44] [acia-workflows: Automated Single-cell Imaging Analysis for Scalable and Deep Learning-based Live-cell Imaging Analysis Workflows](https://arxiv.org/abs/2510.05886)
*Johannes Seiffarth,Keitaro Kasahara,Michelle Bund,Benita Lückel,Richard D. Paul,Mathias Pesch,Lennart Witting,Michael Bott,Dietrich Kohlheyer,Katharina Nöh*

Main category: cs.CV

TL;DR: 本论文介绍了acia-workflows平台，该平台结合了多种深度学习方法，实现了大规模活细胞成像（LCI）数据的自动化分析，有助于单细胞动态的系统性研究，并提供了多个可定制的实际应用工作流，支持高通量生物学研究。


<details>
  <summary>Details</summary>
Motivation: 随着活细胞成像技术的发展，对细胞单体动态行为的高通量、自动化分析需求不断增长，但庞大的数据量和对易用工具的需求成为主要瓶颈，现有的深度学习方法虽具备强大分析能力，但实际应用中缺乏易集成、易用和高可重复性的工作流工具。

Method: 作者提出了acia-workflows平台，包括：1) 支持八种深度学习细胞分割与追踪方法的Python分析库；2) 通过Jupyter Notebook集成图像分析流程、依赖、文档与可视化，实现高效、可重复和可扩展的分析工作流；3) 通过十余个现实微流控实验案例，展示平台的应用与定制化能力。

Result: 平台能够实现多类型、微流控高通量细胞成像实验的自动化与定量分析，如生长速率对比、动态响应的分钟级精确分析等，极大方便了实验数据的处理流程。所有应用工作流均开源共享。

Conclusion: acia-workflows平台为生命科学高通量细胞成像数据的分析提供了强大、易用且可重复的深度学习工作流工具，有助于推动相关领域自动化和系统化研究发展。

Abstract: Live-cell imaging (LCI) technology enables the detailed spatio-temporal
characterization of living cells at the single-cell level, which is critical
for advancing research in the life sciences, from biomedical applications to
bioprocessing. High-throughput setups with tens to hundreds of parallel cell
cultivations offer the potential for robust and reproducible insights. However,
these insights are obscured by the large amount of LCI data recorded per
experiment. Recent advances in state-of-the-art deep learning methods for cell
segmentation and tracking now enable the automated analysis of such large data
volumes, offering unprecedented opportunities to systematically study
single-cell dynamics. The next key challenge lies in integrating these powerful
tools into accessible, flexible, and user-friendly workflows that support
routine application in biological research. In this work, we present
acia-workflows, a platform that combines three key components: (1) the
Automated live-Cell Imaging Analysis (acia) Python library, which supports the
modular design of image analysis pipelines offering eight deep learning
segmentation and tracking approaches; (2) workflows that assemble the image
analysis pipeline, its software dependencies, documentation, and visualizations
into a single Jupyter Notebook, leading to accessible, reproducible and
scalable analysis workflows; and (3) a collection of application workflows
showcasing the analysis and customization capabilities in real-world
applications. Specifically, we present three workflows to investigate various
types of microfluidic LCI experiments ranging from growth rate comparisons to
precise, minute-resolution quantitative analyses of individual dynamic cells
responses to changing oxygen conditions. Our collection of more than ten
application workflows is open source and publicly available at
https://github.com/JuBiotech/acia-workflows.

</details>


### [45] [BioAutoML-NAS: An End-to-End AutoML Framework for Multimodal Insect Classification via Neural Architecture Search on Large-Scale Biodiversity Data](https://arxiv.org/abs/2510.05888)
*Arefin Ittesafun Abian,Debopom Sutradhar,Md Rafi Ur Rashid,Reem E. Mohamed,Md Rafiqul Islam,Asif Karim,Kheng Cher Yeo,Sami Azam*

Main category: cs.CV

TL;DR: 本文提出了BioAutoML-NAS方法，在昆虫分类任务上，通过多模态数据融合和自动神经结构搜索实现了精确高效的分类，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 昆虫分类对农业管理和生态研究至关重要，但由于昆虫种类复杂、不均衡及大规模数据处理困难，现有方法表现有限，因此亟需更高效准确的自动分类方法。

Method: 作者提出BioAutoML-NAS，结合图像和元数据输入，通过神经结构搜索（NAS）自动寻找最佳的图像特征提取结构，多模态融合模块结合了视觉和生物信息，并采用交替双层优化策略训练模型，利用zero operations获得稀疏有效的架构。

Result: 在BIOSCAN-5M数据集上，BioAutoML-NAS准确率96.81%、精确率97.46%、召回率96.81%、F1分数97.05%，分别比现有迁移学习、transformer、AutoML和NAS方法高约16%、10%、8%。在Insects-1M数据集上也取得了93%以上的各项指标。

Conclusion: BioAutoML-NAS在昆虫分类任务上显著超过现有主流方法，实现了高效、准确的多模态自动分类，对于现代可持续农业管理具有重要支持价值。

Abstract: Insect classification is important for agricultural management and ecological
research, as it directly affects crop health and production. However, this task
remains challenging due to the complex characteristics of insects, class
imbalance, and large-scale datasets. To address these issues, we propose
BioAutoML-NAS, the first BioAutoML model using multimodal data, including
images, and metadata, which applies neural architecture search (NAS) for images
to automatically learn the best operations for each connection within each
cell. Multiple cells are stacked to form the full network, each extracting
detailed image feature representations. A multimodal fusion module combines
image embeddings with metadata, allowing the model to use both visual and
categorical biological information to classify insects. An alternating bi-level
optimization training strategy jointly updates network weights and architecture
parameters, while zero operations remove less important connections, producing
sparse, efficient, and high-performing architectures. Extensive evaluation on
the BIOSCAN-5M dataset demonstrates that BioAutoML-NAS achieves 96.81%
accuracy, 97.46% precision, 96.81% recall, and a 97.05% F1 score, outperforming
state-of-the-art transfer learning, transformer, AutoML, and NAS methods by
approximately 16%, 10%, and 8% respectively. Further validation on the
Insects-1M dataset obtains 93.25% accuracy, 93.71% precision, 92.74% recall,
and a 93.22% F1 score. These results demonstrate that BioAutoML-NAS provides
accurate, confident insect classification that supports modern sustainable
farming.

</details>


### [46] [$\bf{D^3}$QE: Learning Discrete Distribution Discrepancy-aware Quantization Error for Autoregressive-Generated Image Detection](https://arxiv.org/abs/2510.05891)
*Yanran Zhang,Bingyao Yu,Yu Zheng,Wenzhao Zheng,Yueqi Duan,Lei Chen,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: 本文提出了一种新方法用于检测由视觉自回归（AR）模型生成的合成图像，针对其独特的离散编码特征，以实现更高效的真假图像区分。


<details>
  <summary>Details</summary>
Motivation: 随着视觉自回归模型在图像生成领域取得突破，如何准确检测这些高级模型合成的假图像成为亟需解决的问题。以往GAN或扩散模型的检测方法难以直接适用于AR模型，主要因为后者生成图像的方式及特征分布具有明显差异。

Method: 作者提出了D^3QE方法：基于编码本（codebook）频率分布偏差和离散量化误差，利用一种离散分布差异感知的Transformer网络，将动态码本统计信息融入注意力机制，实现语义特征与量化误差的融合。并建立了涵盖7种主流视觉AR模型的ARForensics检测数据集。

Result: 实验证明，所提方法在各主流视觉AR模型上获得了更高的检测准确率，且对不同假图像模型具有良好的泛化能力，并对真实场景干扰表现出较强鲁棒性。

Conclusion: D^3QE是一种高效、兼容性强的AR合成图像检测方法，有助于提升现实应用中的假图像鉴别能力，为AI内容安全提供技术支撑。

Abstract: The emergence of visual autoregressive (AR) models has revolutionized image
generation while presenting new challenges for synthetic image detection.
Unlike previous GAN or diffusion-based methods, AR models generate images
through discrete token prediction, exhibiting both marked improvements in image
synthesis quality and unique characteristics in their vector-quantized
representations. In this paper, we propose to leverage Discrete Distribution
Discrepancy-aware Quantization Error (D$^3$QE) for autoregressive-generated
image detection that exploits the distinctive patterns and the frequency
distribution bias of the codebook existing in real and fake images. We
introduce a discrete distribution discrepancy-aware transformer that integrates
dynamic codebook frequency statistics into its attention mechanism, fusing
semantic features and quantization error latent. To evaluate our method, we
construct a comprehensive dataset termed ARForensics covering 7 mainstream
visual AR models. Experiments demonstrate superior detection accuracy and
strong generalization of D$^3$QE across different AR models, with robustness to
real-world perturbations. Code is available at
\href{https://github.com/Zhangyr2022/D3QE}{https://github.com/Zhangyr2022/D3QE}.

</details>


### [47] [Efficient Universal Models for Medical Image Segmentation via Weakly Supervised In-Context Learning](https://arxiv.org/abs/2510.05899)
*Jiesi Hu,Yanwu Yang,Zhiyu Ye,Jinyan Zhou,Jianfeng Cao,Hanyang Peng,Ting Ma*

Main category: cs.CV

TL;DR: 该论文提出了弱监督的上下文学习方法（WS-ICL），将医学图像分割的标注成本大幅降低，同时保持了与传统方法相近的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的医学影像分割通用模型（如交互式和上下文学习模型）虽然泛化能力强，但需要大量精细标注，增加了人工成本和操作复杂性。为了解决标注负担重的问题，亟需更高效的标注方式。

Method: 作者提出WS-ICL范式，将弱标注（如框或点）替代密集像素标注作为上下文学习中的提示信息，无需对每张图片多次精细标注。该方法显著降低了人工标注和操作负担。

Result: 在三个独立的医学影像基准数据集上评估，WS-ICL性能几乎与常规ICL模型相当，同时所需标注成本更低；且在交互式场景下同样具备竞争力。

Conclusion: WS-ICL为医用影像分割通用模型的高效标注和统一提供了新的、有前景的解决方案，促进医学影像分割自动化和实用性提升。

Abstract: Universal models for medical image segmentation, such as interactive and
in-context learning (ICL) models, offer strong generalization but require
extensive annotations. Interactive models need repeated user prompts for each
image, while ICL relies on dense, pixel-level labels. To address this, we
propose Weakly Supervised In-Context Learning (WS-ICL), a new ICL paradigm that
leverages weak prompts (e.g., bounding boxes or points) instead of dense labels
for context. This approach significantly reduces annotation effort by
eliminating the need for fine-grained masks and repeated user prompting for all
images. We evaluated the proposed WS-ICL model on three held-out benchmarks.
Experimental results demonstrate that WS-ICL achieves performance comparable to
regular ICL models at a significantly lower annotation cost. In addition,
WS-ICL is highly competitive even under the interactive paradigm. These
findings establish WS-ICL as a promising step toward more efficient and unified
universal models for medical image segmentation. Our code and model are
publicly available at https://github.com/jiesihu/Weak-ICL.

</details>


### [48] [Kaputt: A Large-Scale Dataset for Visual Defect Detection](https://arxiv.org/abs/2510.05903)
*Sebastian Höfer,Dorian Henning,Artemij Amiranashvili,Douglas Morrison,Mariliza Tzes,Ingmar Posner,Marc Matvienko,Alessandro Rennola,Anton Milan*

Main category: cs.CV

TL;DR: 本文提出了一个面向物流场景的全新大规模缺陷检测数据集，并验证当前顶尖方法在该场景下表现不佳，旨在推动零售物流异常检测领域的研究。


<details>
  <summary>Details</summary>
Motivation: 现有工业异常检测多聚焦于姿态受控、类别有限的制造业，主流基准数据集（如MVTec-AD、VisA）方法已趋于饱和，而零售物流环境中物体姿态和外观变化大，现有方法难以适用，因此需构建更具挑战性的新基准。

Method: 作者收集并构建了一个包含23万余张图片、4.8万多个不同物体、2.9万余缺陷实例的数据集，规模为MVTec-AD的40倍。随后采用多种最新异常检测方法对该数据集进行了系统性的实验和分析。

Result: 在新数据集上，当前最优异常检测方法的AUROC最高仅为56.96%，远低于在制造业数据集上的性能，表明这是一个更具挑战性的问题；进一步定性分析显示现有方法对大幅度姿态和外观变化的样本难以利用。

Conclusion: 本文数据集为零售物流异常检测领域树立了新基准，揭示现有方法在新场景中的不足，并将推动后续研究以应对更具挑战性的物流缺陷检测任务。

Abstract: We present a novel large-scale dataset for defect detection in a logistics
setting. Recent work on industrial anomaly detection has primarily focused on
manufacturing scenarios with highly controlled poses and a limited number of
object categories. Existing benchmarks like MVTec-AD [6] and VisA [33] have
reached saturation, with state-of-the-art methods achieving up to 99.9% AUROC
scores. In contrast to manufacturing, anomaly detection in retail logistics
faces new challenges, particularly in the diversity and variability of object
pose and appearance. Leading anomaly detection methods fall short when applied
to this new setting. To bridge this gap, we introduce a new benchmark that
overcomes the current limitations of existing datasets. With over 230,000
images (and more than 29,000 defective instances), it is 40 times larger than
MVTec-AD and contains more than 48,000 distinct objects. To validate the
difficulty of the problem, we conduct an extensive evaluation of multiple
state-of-the-art anomaly detection methods, demonstrating that they do not
surpass 56.96% AUROC on our dataset. Further qualitative analysis confirms that
existing methods struggle to leverage normal samples under heavy pose and
appearance variation. With our large-scale dataset, we set a new benchmark and
encourage future research towards solving this challenging problem in retail
logistics anomaly detection. The dataset is available for download under
https://www.kaputt-dataset.com.

</details>


### [49] [Shaken or Stirred? An Analysis of MetaFormer's Token Mixing for Medical Imaging](https://arxiv.org/abs/2510.05971)
*Ron Keuth,Paul Kaftan,Mattias P. Heinrich*

Main category: cs.CV

TL;DR: 本文首次系统地评估了MetaFormer架构中不同类型的Token Mixer（包括Pooling、卷积和自注意力机制）在医学影像任务中的表现，涵盖分类和分割两种主流任务，并横跨8个医学影像数据集。结果显示，分类任务中低复杂度Token Mixer已足够，而分割任务则需卷积结构带来的本地归纳偏置。


<details>
  <summary>Details</summary>
Motivation: Transformer及其通用化结构MetaFormer在自然图像领域表现优异，但其在医学影像领域的应用较少，现有工作也很少对不同Token Mixer进行直接对比，可能错过了更合适的结构选择。因此，需系统研究Token Mixer在医学影像领域的作用。

Method: 作者在MetaFormer架构中，利用Pooling、分组卷积、标准卷积和注意力等不同Token Mixer，系统评估了它们在医学影像分类（全局预测）和分割（密集预测）任务中的性能。实验涵盖8个不同模态的医学影像数据集，并考察了自然图像预训练权重迁移到不同Token Mixer的效果。

Result: 1. 在医学影像分类任务下，低复杂度Token Mixer如分组卷积或Pooling的表现已足够好，且预训练权重迁移依然有效；2. 在分割任务中，卷积类Token Mixer所带来的本地归纳偏置至关重要。分组卷积既能提升效率又能减少参数，是最佳选择。此外，MetaFormer中的channel-MLP已补足跨通道信息交互的需求。

Conclusion: MetaFormer架构下，针对医学影像分类推荐使用低复杂度Token Mixer，针对分割任务推荐分组卷积Token Mixer。这一选择既保证了性能，也兼顾了计算效率，对医学影像领域模型设计具有实际指导价值。

Abstract: The generalization of the Transformer architecture via MetaFormer has
reshaped our understanding of its success in computer vision. By replacing
self-attention with simpler token mixers, MetaFormer provides strong baselines
for vision tasks. However, while extensively studied on natural image datasets,
its use in medical imaging remains scarce, and existing works rarely compare
different token mixers, potentially overlooking more suitable designs choices.
In this work, we present the first comprehensive study of token mixers for
medical imaging. We systematically analyze pooling-, convolution-, and
attention-based token mixers within the MetaFormer architecture on image
classification (global prediction task) and semantic segmentation (dense
prediction task). Our evaluation spans eight datasets covering diverse
modalities and common challenges in the medical domain. Given the prevalence of
pretraining from natural images to mitigate medical data scarcity, we also
examine transferring pretrained weights to new token mixers. Our results show
that, for classification, low-complexity token mixers (e.g. grouped convolution
or pooling) are sufficient, aligning with findings on natural images.
Pretrained weights remain useful despite the domain gap introduced by the new
token mixer. For segmentation, we find that the local inductive bias of
convolutional token mixers is essential. Grouped convolutions emerge as the
preferred choice, as they reduce runtime and parameter count compared to
standard convolutions, while the MetaFormer's channel-MLPs already provide the
necessary cross-channel interactions. Our code is available on GitHub.

</details>


### [50] [Diffusion Models for Low-Light Image Enhancement: A Multi-Perspective Taxonomy and Performance Analysis](https://arxiv.org/abs/2510.05976)
*Eashan Adhikarla,Yixin Liu,Brian D. Davison*

Main category: cs.CV

TL;DR: 论文综述了低光照图像增强领域中扩散模型的最新进展，系统评估了与GAN和Transformer方法的性能，并提供了未来研究的方向和挑战。


<details>
  <summary>Details</summary>
Motivation: 低光照图像会导致下游任务性能下降，在安防、自动驾驶、医疗成像等关键领域有迫切的提升需求。而扩散模型作为新兴生成范例，在该方向展现出建模复杂图像分布的优势，但其实际应用和发展潜力尚需系统梳理。

Method: 本文综合性地分析了扩散模型在低光照图像增强中的应用，对比了GAN与Transformer等现有主流方法，从六大视角（如内在分解、光谱潜表、加速、引导、多模态、自主等）进行多角度分类，并从模型机制与条件信号混合视角建立了完整的分类体系。同时，评估了各种方法的失败模式、基准测试问题、可解释性、泛化能力和推理效率之间的权衡。

Result: 综述发现扩散模型在性能、泛化和可解释性等方面与主流方法相比有诸多优缺点，实测中受到内存、能耗等部署约束和伦理问题挑战。六分类体系揭示了现有增强方法基本格局和主要研究热点，辨析了现有方法各自的瓶颈。

Conclusion: 扩散模型在低光照图像增强领域具有发展前景，但在实际部署、效率提升、模型可扩展性及新型条件自适应等方面仍有诸多开放问题和挑战，有待未来进一步研究和突破。

Abstract: Low-light image enhancement (LLIE) is vital for safety-critical applications
such as surveillance, autonomous navigation, and medical imaging, where
visibility degradation can impair downstream task performance. Recently,
diffusion models have emerged as a promising generative paradigm for LLIE due
to their capacity to model complex image distributions via iterative denoising.
This survey provides an up-to-date critical analysis of diffusion models for
LLIE, distinctively featuring an in-depth comparative performance evaluation
against Generative Adversarial Network and Transformer-based state-of-the-art
methods, a thorough examination of practical deployment challenges, and a
forward-looking perspective on the role of emerging paradigms like foundation
models. We propose a multi-perspective taxonomy encompassing six categories:
Intrinsic Decomposition, Spectral & Latent, Accelerated, Guided, Multimodal,
and Autonomous; that map enhancement methods across physical priors,
conditioning schemes, and computational efficiency. Our taxonomy is grounded in
a hybrid view of both the model mechanism and the conditioning signals. We
evaluate qualitative failure modes, benchmark inconsistencies, and trade-offs
between interpretability, generalization, and inference efficiency. We also
discuss real-world deployment constraints (e.g., memory, energy use) and
ethical considerations. This survey aims to guide the next generation of
diffusion-based LLIE research by highlighting trends and surfacing open
research questions, including novel conditioning, real-time adaptation, and the
potential of foundation models.

</details>


### [51] [A Dynamic Mode Decomposition Approach to Morphological Component Analysis](https://arxiv.org/abs/2510.05977)
*Owen T. Huber,Raghu G. Raj,Tianyu Chen,Zacharie I. Idriss*

Main category: cs.CV

TL;DR: 本文提出了一种基于场景内容变化动态调整视频表示的新方法，使用动力学模态分解特征值聚类结合形态组分分析，实现视频中结构不同形态的分离，并在去噪、信噪比提升及目标分离任务中展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前视频和信号分离方法大多依赖于先验定义的字典，适应性不足，难以应对结构多变或动态场景；因此，需开发数据驱动、自适应的视频表示和分离新方法。

Method: 将动态模态分解（DMD）特征值聚类引入形态组分分析（MCA），以此生成数据驱动的MCA字典，命名为动态形态组分分析（DMCA）。本文详细推导了该算法，并通过静止图像和视频去噪等任务进行实验验证。

Result: DMCA方法在Adobe 240fps视频去噪、微弱目标信噪比提升、以及反合成孔径雷达图像中自行车与风杂波分离等任务上表现优秀，优于传统基于预定义字典的方法。

Conclusion: DMCA是一种有效的数据驱动视频与信号分解新方法，能够自适应不同结构形态并提升信噪比，在视频去噪与复杂场景分离等实际应用中具有广泛前景。

Abstract: This paper introduces a novel methodology of adapting the representation of
videos based on the dynamics of their scene content variation. In particular,
we demonstrate how the clustering of dynamic mode decomposition eigenvalues can
be leveraged to learn an adaptive video representation for separating
structurally distinct morphologies of a video. We extend the morphological
component analysis (MCA) algorithm, which uses multiple predefined incoherent
dictionaries and a sparsity prior to separate distinct sources in signals, by
introducing our novel eigenspace clustering technique to obtain data-driven MCA
dictionaries, which we call dynamic morphological component analysis (DMCA).
After deriving our novel algorithm, we offer a motivational example of DMCA
applied to a still image, then demonstrate DMCA's effectiveness in denoising
applications on videos from the Adobe 240fps dataset. Afterwards, we provide an
example of DMCA enhancing the signal-to-noise ratio of a faint target summed
with a sea state, and conclude the paper by applying DMCA to separate a bicycle
from wind clutter in inverse synthetic aperture radar images.

</details>


### [52] [Diffusion-Based Image Editing for Breaking Robust Watermarks](https://arxiv.org/abs/2510.05978)
*Yunyi Ni,Finn Carter,Ze Niu,Emily Davis,Bo Zhang*

Main category: cs.CV

TL;DR: 扩散模型可以轻松抹除目前主流图像隐形水印，致使水印几乎无法被恢复，而视觉效果依然保真。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI特别是扩散模型的兴起，现有的图像隐形水印技术面临前所未有的新威胁，因此有必要研究这些先进生成模型对水印的冲击与破解能力。

Method: 作者通过理论分析与实验，提出并验证了两种攻击方式：其一是一般性的扩散生成过程可天然抹除水印；其二是专门引导的扩散攻击进一步针对水印信号，使其不可检测。此外，作者还证明了随着扩散变换的深入，水印与图像之间的互信息趋于消失，理论上解释了攻击效果。

Result: 在多个主流（含深度学习型）隐形水印方案（如StegaStamp、TrustMark、VINE）上的实验证实，扩散攻击后水印恢复率几乎为零，但图像肉眼效果仍高度保真。

Conclusion: 当前鲁棒隐形水印技术在生成式AI，尤其是扩散模型攻击下存在根本缺陷，未来亟需设计新的水印机制以匹配生成式AI的挑战。

Abstract: Robust invisible watermarking aims to embed hidden information into images
such that the watermark can survive various image manipulations. However, the
rise of powerful diffusion-based image generation and editing techniques poses
a new threat to these watermarking schemes. In this paper, we present a
theoretical study and method demonstrating that diffusion models can
effectively break robust image watermarks that were designed to resist
conventional perturbations. We show that a diffusion-driven ``image
regeneration'' process can erase embedded watermarks while preserving
perceptual image content. We further introduce a novel guided diffusion attack
that explicitly targets the watermark signal during generation, significantly
degrading watermark detectability. Theoretically, we prove that as an image
undergoes sufficient diffusion-based transformation, the mutual information
between the watermarked image and the embedded watermark payload vanishes,
resulting in decoding failure. Experimentally, we evaluate our approach on
multiple state-of-the-art watermarking schemes (including the deep
learning-based methods StegaStamp, TrustMark, and VINE) and demonstrate
near-zero watermark recovery rates after attack, while maintaining high visual
fidelity of the regenerated images. Our findings highlight a fundamental
vulnerability in current robust watermarking techniques against generative
model-based attacks, underscoring the need for new watermarking strategies in
the era of generative AI.

</details>


### [53] [Detection and Measurement of Hailstones with Multimodal Large Language Models](https://arxiv.org/abs/2510.06008)
*Moritz Alker,David C. Schedl,Andreas Stöckl*

Main category: cs.CV

TL;DR: 本研究利用多模态大语言模型，通过社交媒体和新闻图片自动测量冰雹直径，验证了无微调模型的测量能力，并比较了一阶段与两阶段提示策略。


<details>
  <summary>Details</summary>
Motivation: 传统的冰雹监测手段数据不够丰富与广泛，社交媒体和新闻图片提供新的高密度观测资料，如何自动化、准确利用这些图像资源，是提升冰雹监测和灾害响应能力的关键。

Method: 收集2022至2024年奥地利474张冰雹事件众包图片，包含最大直径2至11厘米。利用预训练多模态大模型，采用一阶段和两阶段（含与参照物对比）两种提示策略进行冰雹直径估算，并比较多种模型的表现。

Result: 最佳模型在冰雹直径测量上的平均绝对误差为1.12厘米。两阶段提示策略普遍提升了模型的可靠性。模型即使未经过微调，也能提取有效的冰雹尺寸信息。

Conclusion: 无需特殊训练的现成多模态大模型可通过社交媒体图片补充传统冰雹传感器，实现更快更细致的灾害评估。若实现自动化实时图像抓取，该方法有望应用于未来的实际冰雹事件监测。

Abstract: This study examines the use of social media and news images to detect and
measure hailstones, utilizing pre-trained multimodal large language models. The
dataset for this study comprises 474 crowdsourced images of hailstones from
documented hail events in Austria, which occurred between January 2022 and
September 2024. These hailstones have maximum diameters ranging from 2 to 11cm.
We estimate the hail diameters and compare four different models utilizing
one-stage and two-stage prompting strategies. The latter utilizes additional
size cues from reference objects, such as human hands, within the image. Our
results show that pretrained models already have the potential to measure
hailstone diameters from images with an average mean absolute error of 1.12cm
for the best model. In comparison to a single-stage prompt, two-stage prompting
improves the reliability of most models. Our study suggests that these
off-the-shelf models, even without fine-tuning, can complement traditional hail
sensors by extracting meaningful and spatially dense information from social
media imagery, enabling faster and more detailed assessments of severe weather
events. The automated real-time image harvesting from social media and other
sources remains an open task, but it will make our approach directly applicable
to future hail events.

</details>


### [54] [Continual Learning for Image Captioning through Improved Image-Text Alignment](https://arxiv.org/abs/2510.06009)
*Bertram Taetz,Gal Bordelius*

Main category: cs.CV

TL;DR: 本文提出了一种新的多损失框架，用于连续学习环境下的图像描述生成，能够减少灾难性遗忘并提升语义对齐效果。


<details>
  <summary>Details</summary>
Motivation: 在连续学习（continual learning）环境下，图像描述生成模型面临灾难性遗忘和视觉语义持续对齐的挑战，导致生成效果不佳。本文旨在解决这些关键瓶颈。

Method: 方法基于ViT-GPT-2预训练模型，通过标准交叉熵损失和三种新损失共同训练：(1) 基于提示的余弦相似度损失，通过合成提示（包含对象、属性和动作）引导图像嵌入语义对齐；(2) CLIP风格损失，加强图像与目标描述嵌入对齐；(3) 语言引导的对比损失，通过三元组损失增强不同任务下类别区分能力。此外，推理阶段不需额外开销，无需实际提示。

Result: 实验表明，该方法有效缓解了灾难性遗忘问题，在语义对齐和描述生成质量上，均超过现有主流方法。

Conclusion: 该多损失框架在图像描述的连续学习领域表现突出，提升了模型的描述能力和稳定性，是对现有技术的显著改进。

Abstract: Generating accurate and coherent image captions in a continual learning
setting remains a major challenge due to catastrophic forgetting and the
difficulty of aligning evolving visual concepts with language over time. In
this work, we propose a novel multi-loss framework for continual image
captioning that integrates semantic guidance through prompt-based continual
learning and contrastive alignment. Built upon a pretrained ViT-GPT-2 backbone,
our approach combines standard cross-entropy loss with three additional
components: (1) a prompt-based cosine similarity loss that aligns image
embeddings with synthetically constructed prompts encoding objects, attributes,
and actions; (2) a CLIP-style loss that promotes alignment between image
embeddings and target caption embedding; and (3) a language-guided contrastive
loss that employs a triplet loss to enhance class-level discriminability
between tasks. Notably, our approach introduces no additional overhead at
inference time and requires no prompts during caption generation. We find that
this approach mitigates catastrophic forgetting, while achieving better
semantic caption alignment compared to state-of-the-art methods. The code can
be found via the following link https://github.com/
Gepardius/Taetz_Bordelius_Continual_ImageCaptioning.

</details>


### [55] [Emergent AI Surveillance: Overlearned Person Re-Identification and Its Mitigation in Law Enforcement Context](https://arxiv.org/abs/2510.06026)
*An Thi Nguyen,Radina Stoykova,Eric Arazo*

Main category: cs.CV

TL;DR: 该论文指出通用实例检索模型在侦查中可有效降低人工分析工作，但其出现了未经训练也能识别人类个体的能力，存在隐私泄露风险。作者评估了两种技术防护手段，发现可以明显削弱人重新识别能力，但仍有关键漏洞，建议需紧急制定AI监管与标准。


<details>
  <summary>Details</summary>
Motivation: 随着监控数据量的激增，警方借助通用实例检索模型以便快速定位感兴趣对象，但作者发现这些模型意外获得了识别人类个体的能力，即便训练集没有包含人类目标。这引发了对隐私安全与个人数据保护的严重担忧。

Method: 作者重点评估了两种限制模型识别能力的技术：索引排除（index exclusion）和混淆损失（confusion loss）。通过实验，测试了这两项措施单独及联合使用对人重识别能力和非人物体检索表现的影响。

Result: 实验显示，两措施结合后可将人重新识别准确率降至2%以下，而非人物体检索能力仍能保持82%。然而，研究发现模型仍存在重要漏洞，例如可通过部分人体图像规避防护措施。

Conclusion: 作者指出通用实例检索模型的意外识别能力对数据隐私和AI监管带来新挑战。即使有技术防护，目前的漏洞依然明显，呼吁建立相关技术标准和监管体系，防止模型在良性应用下发展出未经授权的识别能力。

Abstract: Generic instance search models can dramatically reduce the manual effort
required to analyze vast surveillance footage during criminal investigations by
retrieving specific objects of interest to law enforcement. However, our
research reveals an unintended emergent capability: through overlearning, these
models can single out specific individuals even when trained on datasets
without human subjects. This capability raises concerns regarding
identification and profiling of individuals based on their personal data, while
there is currently no clear standard on how de-identification can be achieved.
We evaluate two technical safeguards to curtail a model's person
re-identification capacity: index exclusion and confusion loss. Our experiments
demonstrate that combining these approaches can reduce person re-identification
accuracy to below 2% while maintaining 82% of retrieval performance for
non-person objects. However, we identify critical vulnerabilities in these
mitigations, including potential circumvention using partial person images.
These findings highlight urgent regulatory questions at the intersection of AI
governance and data protection: How should we classify and regulate systems
with emergent identification capabilities? And what technical standards should
be required to prevent identification capabilities from developing in seemingly
benign applications?

</details>


### [56] [Universal Neural Architecture Space: Covering ConvNets, Transformers and Everything in Between](https://arxiv.org/abs/2510.06035)
*Ondřej Týbl,Lukáš Neumann*

Main category: cs.CV

TL;DR: 本文提出了UniNAS，一种通用的神经网络结构搜索空间，统一了卷积网络、Transformer及其混合架构，并实现了超越现有手工设计结构的性能。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络架构多样，卷积网络和Transformer各有优势，且二者混合结构越来越受关注，但缺乏统一的搜索空间和分析框架。动机在于打破架构割裂，实现一体化对比和创新。

Method: 提出了Unified Neural Architecture Space（UniNAS），可灵活表达多种类型网络结构，并设计了新的搜索算法，能够在此空间内高效探索和发现新架构。还配套开发了统一的训练与评估工具包，以促进可复现性和公平比较。

Result: 实验证明，UniNAS搜索空间包含的部分新架构在统一训练设置下，性能优于现有最优手工设计结构。

Conclusion: UniNAS推动了神经网络结构系统性探索，打破了架构类型壁垒，为神经架构搜索研究提供了统一、灵活且可复现的平台，具备重要的理论和实际价值。

Abstract: We introduce Universal Neural Architecture Space (UniNAS), a generic search
space for neural architecture search (NAS) which unifies convolutional
networks, transformers, and their hybrid architectures under a single, flexible
framework. Our approach enables discovery of novel architectures as well as
analyzing existing architectures in a common framework. We also propose a new
search algorithm that allows traversing the proposed search space, and
demonstrate that the space contains interesting architectures, which, when
using identical training setup, outperform state-of-the-art hand-crafted
architectures. Finally, a unified toolkit including a standardized training and
evaluation protocol is introduced to foster reproducibility and enable fair
comparison in NAS research. Overall, this work opens a pathway towards
systematically exploring the full spectrum of neural architectures with a
unified graph-based NAS perspective.

</details>


### [57] [VideoMiner: Iteratively Grounding Key Frames of Hour-Long Videos via Tree-based Group Relative Policy Optimization](https://arxiv.org/abs/2510.06040)
*Xinye Cao,Hongcan Guo,Jiawen Qian,Guoshun Nan,Chao Wang,Yuqi Pan,Tianhao Hou,Xiaojuan Wang,Yutong Gao*

Main category: cs.CV

TL;DR: 提出了VideoMiner系统与T-GRPO方法，通过分层树结构和强化学习，实现对小时级长视频的高效、准确理解。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型（MM-LLMs）在处理长视频时，容易被冗余信息干扰，影响视频理解准确性；即便采用层次化关键帧提取，依旧存在无法有效过滤冗余、难以动态适应复杂结构和高效识别关键帧的问题。

Method: 提出VideoMiner，对长视频进行迭代分割、描述和聚类，构建层次化树结构，自顶向下提取“视频-事件-帧”并保持时序连贯性。同时引入T-GRPO（基于树结构的群体相对策略优化），利用强化学习动态探索并定位关键帧，结合辅助机制自适应控制树扩展深度。

Result: 在多项长视频理解任务上取得领先性能；T-GRPO激励模型自主生成推理链条；创新的树增长机制提升了准确率和效率。

Conclusion: VideoMiner及T-GRPO方法能高效、准确地处理小时级视频理解，显著缓解冗余信息干扰及结构适应难题，推动多模态长视频理解技术发展。

Abstract: Understanding hour-long videos with multi-modal large language models
(MM-LLMs) enriches the landscape of human-centered AI applications. However,
for end-to-end video understanding with LLMs, uniformly sampling video frames
results in LLMs being overwhelmed by a vast amount of irrelevant information as
video length increases. Existing hierarchical key frame extraction methods
improve the accuracy of video understanding but still face two critical
challenges. 1) How can the interference of extensive redundant information in
long videos be mitigated? 2) How can a model dynamically adapt to complex
hierarchical structures while accurately identifying key frames? To address
these issues, we propose VideoMiner, which iteratively segments, captions, and
clusters long videos, forming a hierarchical tree structure. The proposed
VideoMiner progresses from long videos to events to frames while preserving
temporal coherence, effectively addressing the first challenge. To precisely
locate key frames, we introduce T-GRPO, a tree-based group relative policy
optimization in reinforcement learning method that guides the exploration of
the VideoMiner. The proposed T-GRPO is specifically designed for tree
structures, integrating spatiotemporal information at the event level while
being guided by the question, thus solving the second challenge. We achieve
superior performance in all long-video understanding tasks and uncover several
interesting insights. Our proposed T-GRPO surprisingly incentivizes the model
to spontaneously generate a reasoning chain. Additionally, the designed tree
growth auxin dynamically adjusts the expansion depth, obtaining accuracy and
efficiency gains. The code is publicly available at
https://github.com/caoxinye/VideoMiner.

</details>


### [58] [GLVD: Guided Learned Vertex Descent](https://arxiv.org/abs/2510.06046)
*Pol Caselles Rico,Francesc Moreno Noguer*

Main category: cs.CV

TL;DR: GLVD是一种结合全局结构引导和逐顶点神经场优化的新型3D人脸重建方法，能在少量视图下实现高效且高质量的重建。


<details>
  <summary>Details</summary>
Motivation: 现有3D人脸建模通常依赖3D形变模型（3DMM），这限制了表达能力，而且通过优化获得高质量重建的方法计算开销大。因此亟需能兼顾表现力和效率的方法。

Method: 提出了GLVD，将逐顶点神经场优化与动态预测3D关键点的全局结构信息结合，利用相对空间编码迭代优化网格顶点，无需密集的3D监督。

Result: GLVD在单视图场景中达到SOTA，在多视图下也高度竞争，同时显著降低推断时间。

Conclusion: GLVD无需密集3D标注即可高效、高质量地实现少视角3D人脸重建，是兼顾表达能力和效率的先进方法。

Abstract: Existing 3D face modeling methods usually depend on 3D Morphable Models,
which inherently constrain the representation capacity to fixed shape priors.
Optimization-based approaches offer high-quality reconstructions but tend to be
computationally expensive. In this work, we introduce GLVD, a hybrid method for
3D face reconstruction from few-shot images that extends Learned Vertex Descent
(LVD) by integrating per-vertex neural field optimization with global
structural guidance from dynamically predicted 3D keypoints. By incorporating
relative spatial encoding, GLVD iteratively refines mesh vertices without
requiring dense 3D supervision. This enables expressive and adaptable geometry
reconstruction while maintaining computational efficiency. GLVD achieves
state-of-the-art performance in single-view settings and remains highly
competitive in multi-view scenarios, all while substantially reducing inference
time.

</details>


### [59] [Medical Vision Language Models as Policies for Robotic Surgery](https://arxiv.org/abs/2510.06064)
*Akshay Muppidi,Martin Radfar*

Main category: cs.CV

TL;DR: 本文提出将医疗领域的视觉-语言模型MedFlamingo与PPO算法结合，用于提升基于视觉输入的腹腔镜机器人手术任务表现，大幅超过了传统PPO和OpenFlamingo PPO。


<details>
  <summary>Details</summary>
Motivation: 传统基于视觉观测的PPO在处理外科手术机器人任务时，受限于高维视觉输入、奖励稀疏和难以从原始视觉数据中提取相关特征，因此亟需一种更高效利用医学知识与视觉信息的方法。

Method: 将专为医疗领域训练的视觉-语言模型MedFlamingo集成到PPO中，每个回合仅处理一次观测和任务指令，生成高层次的规划token，强化医学专业知识与视觉信息的结合。

Result: 在LapGym的五个腹腔镜手术任务环境中，MedFlamingo PPO在全部环境的任务成功率均超70%，对比baseline提升66.67%-1114.29%；收敛速度也更快。

Conclusion: 将医学专业知识集成至机器人手术的学习与决策流程可显著提升视觉PPO在医疗机器人任务中的表现，展现了专业领域知识在复杂任务中的巨大价值。

Abstract: Vision-based Proximal Policy Optimization (PPO) struggles with visual
observation-based robotic laparoscopic surgical tasks due to the
high-dimensional nature of visual input, the sparsity of rewards in surgical
environments, and the difficulty of extracting task-relevant features from raw
visual data. We introduce a simple approach integrating MedFlamingo, a medical
domain-specific Vision-Language Model, with PPO. Our method is evaluated on
five diverse laparoscopic surgery task environments in LapGym, using only
endoscopic visual observations. MedFlamingo PPO outperforms and converges
faster compared to both standard vision-based PPO and OpenFlamingo PPO
baselines, achieving task success rates exceeding 70% across all environments,
with improvements ranging from 66.67% to 1114.29% compared to baseline. By
processing task observations and instructions once per episode to generate
high-level planning tokens, our method efficiently combines medical expertise
with real-time visual feedback. Our results highlight the value of specialized
medical knowledge in robotic surgical planning and decision-making.

</details>


### [60] [Reasoning under Vision: Understanding Visual-Spatial Cognition in Vision-Language Models for CAPTCHA](https://arxiv.org/abs/2510.06067)
*Python Song,Luke Tenyi Chang,Yun-Yun Tsai,Penghui Li,Junfeng Yang*

Main category: cs.CV

TL;DR: 本论文分析了当前主流视觉语言模型（VLMs）在解答高难度CAPTCHA任务中的表现，提出分步推理能大幅提升其准确率，并发布了首个面向推理的真实CAPTCHA基准（CAPTCHA-X）及新的测评体系。提出的方法显著提升了解题能力。


<details>
  <summary>Details</summary>
Motivation: 随着VLMs的发展，CAPTCHA不仅仅作为人机验证工具，更成为检验视觉和空间推理能力的重要基准，但现有主流模型对高难度空间推理类CAPTCHA仍表现不佳。亟需系统性评测工具和提升推理能力的方法。

Method: 1）提出CAPTCHA-X——涵盖7种类型、多步动作和定位标注的推理基准；2）定义5项聚焦推理能力的新评测指标；3）提出通用的基于VLM的智能体解题框架，通过强制模型分步推理提升表现。

Result: 实验证明：主流商用VLMs（如GPT、Gemini等）处理高难度CAPTCHA平均仅21.9%准确率。所提VLM智能体框架平均准确率提高至83.9%，远超现有基线。

Conclusion: 当前VLMs空间推理能力有限，CAPTCHA-X和新框架揭示推理环节至关重要。推进VLMs在复杂视觉-空间任务的能力升级需重视推理机制。

Abstract: CAPTCHA, originally designed to distinguish humans from robots, has evolved
into a real-world benchmark for assessing the spatial reasoning capabilities of
vision-language models. In this work, we first show that step-by-step reasoning
is crucial for vision-language models (VLMs) to solve CAPTCHAs, which represent
high-difficulty spatial reasoning tasks, and that current commercial
vision-language models still struggle with such reasoning. In particular, we
observe that most commercial VLMs (e.g., Gemini, Claude, GPT, etc.) fail to
effectively solve CAPTCHAs and thus achieve low accuracy (around 21.9 percent).
However, our findings indicate that requiring the model to perform step-by-step
reasoning before generating the final coordinates can significantly enhance its
solving accuracy, underscoring the severity of the gap. To systematically study
this issue, we introduce CAPTCHA-X, the first real-world CAPTCHA benchmark with
reasoning, covering seven categories of CAPTCHAs (such as Gobang, hCaptcha,
etc.) with step-by-step action solutions and grounding annotations. We further
define five reasoning-oriented metrics that enable a comprehensive evaluation
of models reasoning capabilities. To validate the effectiveness of reasoning,
we also propose a general agentic VLM-based framework that incorporates the
models inherent reasoning abilities. Our method achieves state-of-the-art
performance across five high-difficulty CAPTCHA types, with an average solving
accuracy of 83.9 percent, substantially surpassing existing baselines. These
results reveal the limitations of current models and highlight the importance
of reasoning in advancing visual-spatial challenges in the future.

</details>


### [61] [There is More to Attention: Statistical Filtering Enhances Explanations in Vision Transformers](https://arxiv.org/abs/2510.06070)
*Meghna P Ayyar,Jenny Benois-Pineau,Akka Zemmari*

Main category: cs.CV

TL;DR: 本文提出了一种新方法，通过结合注意力图和统计滤波，有效提升了视觉Transformer（ViT）模型的可解释性，并使解释更贴近人类视觉感知。


<details>
  <summary>Details</summary>
Motivation: 近年来，随着大规模Transformer模型的兴起，模型可解释性（XAI）变得越来越重要。然而，许多为卷积神经网络（CNN）设计的解释方法难以迁移到ViT上，现有基于注意力权重的解释容易产生噪声、不准确。因此，亟需适用于ViT的高质量可解释方法。

Method: 作者提出将注意力图与原本为CNN设计的统计滤波方法结合，去除注意力图中的噪声和无信息模式，提升解释的准确性。同时，提出了类别特异性变体，实现更具区分性的解释，并利用人类注视点数据评估解释的可读性。

Result: 实验表明，所提方法在多组数据集和多个现有SOTA方法对比中，生成的解释图更清晰、更易解释，且在与人类视觉关注点的一致性上表现优秀。

Conclusion: 该方法不仅能生成高质量、符合人类认知的解释，而且高效且可与现有SOTA方法媲美或超越，显示了其在XAI领域的广泛潜力。

Abstract: Explainable AI (XAI) has become increasingly important with the rise of large
transformer models, yet many explanation methods designed for CNNs transfer
poorly to Vision Transformers (ViTs). Existing ViT explanations often rely on
attention weights, which tend to yield noisy maps as they capture
token-to-token interactions within each layer.While attribution methods
incorporating MLP blocks have been proposed, we argue that attention remains a
valuable and interpretable signal when properly filtered. We propose a method
that combines attention maps with a statistical filtering, initially proposed
for CNNs, to remove noisy or uninformative patterns and produce more faithful
explanations. We further extend our approach with a class-specific variant that
yields discriminative explanations. Evaluation against popular state-of-the-art
methods demonstrates that our approach produces sharper and more interpretable
maps. In addition to perturbation-based faithfulness metrics, we incorporate
human gaze data to assess alignment with human perception, arguing that human
interpretability remains essential for XAI. Across multiple datasets, our
approach consistently outperforms or is comparable to the SOTA methods while
remaining efficient and human plausible.

</details>


### [62] [When Thinking Drifts: Evidential Grounding for Robust Video Reasoning](https://arxiv.org/abs/2510.06077)
*Mi Luo,Zihui Xue,Alex Dimakis,Kristen Grauman*

Main category: cs.CV

TL;DR: 本文发现传统文本推理中的Chain-of-Thought（CoT）机制在视频推理任务上常常导致性能下降，引入了通过强化学习奖励与视觉证据一致性的新方法（VER），显著提升了多视频理解任务的表现。


<details>
  <summary>Details</summary>
Motivation: 在AI领域，让模型基于视频动态内容进行多步逻辑推理是实现高阶智能的关键。虽然CoT机制已提升文本推理能力，但其在视频理解上的效果鲜有系统分析。作者发现模型会出现繁琐但误导性的推理过程，这种'视觉思维漂移'降低了推理的可靠性和准确性，因此有必要探索更可靠的视觉推理机制。

Method: 作者系统分析了现有多模态大模型在视频推理任务中应用CoT的表现，发现其生成的思考过程往往脱离真实画面。为此，提出了Visual Evidence Reward（VER）强化学习框架，对与视觉证据紧密相关的推理过程给予奖励，促使模型更好地基于视觉事实进行推理。

Result: 在10个不同的视频理解基准任务上，本文提出的Video-VER方法均取得了领先或最优表现，显著优于传统使用CoT方法的模型，验证了方法的有效性与鲁棒性。

Conclusion: 论文揭示了视频推理任务中与传统文本推理不同的特殊挑战，并表明只有促使模型推理更紧密地结合视觉证据，才能实现更真实可靠的多模态推理能力。这为后续多模态大模型的发展提供了新思路。

Abstract: Video reasoning, the task of enabling machines to infer from dynamic visual
content through multi-step logic, is crucial for advanced AI. While the
Chain-of-Thought (CoT) mechanism has enhanced reasoning in text-based tasks,
its application to video understanding remains underexplored. This paper
presents a systematic analysis revealing that CoT often degrades performance in
video reasoning, generating verbose but misleading internal monologues, and
leading to hallucinated visual details and overridden correct intuitions - a
phenomenon we term "visual thinking drift". We explain this drift through a
Bayesian lens, positing that CoT traces often diverge from actual visual
evidence, instead amplifying internal biases or language priors, causing models
to storytell rather than engage in grounded reasoning. To counteract this, we
introduce Visual Evidence Reward (VER), a novel reinforcement learning
framework that explicitly rewards the generation of reasoning traces that are
verifiably grounded in visual evidence. Comprehensive evaluation across 10
diverse video understanding benchmarks demonstrates that our Video-VER
consistently achieves top performance. Our work sheds light on the distinct
challenges of video-centric reasoning and encourages the development of AI that
robustly grounds its inferences in visual evidence - for large multimodal
models that not only "think before answering", but also "see while thinking".

</details>


### [63] [A public cardiac CT dataset featuring the left atrial appendage](https://arxiv.org/abs/2510.06090)
*Bjoern Hansen,Jonas Pedersen,Klaus F. Kofoed,Oscar Camara,Rasmus R. Paulsen,Kristine Soerensen*

Main category: cs.CV

TL;DR: 本文提出并公开了首个包含左心耳（LAA）、冠状动脉（CA）和肺静脉（PV）高分辨率标注的解剖一致性数据集，用于促进相关结构的医学影像分割研究。数据集基于1,000例心脏CTA公开影像，并包含全心脏标签及常见数据缺陷说明。


<details>
  <summary>Details</summary>
Motivation: 虽然当前先进分割方法（如TotalSegmentator）在多结构分割任务中取得了优异表现，但对于LAA、CA和PV等关键心血管结构的精准分割仍然存在重大挑战。为推动相关结构的分割研究，尤其是LAA的形态学分析，亟需高质量、开放获取的数据集。

Method: 作者搭建并开放了首个针对LAA、CA和PV的高分辨率公开数据集，基于1,000例ImageCAS心脏CTA影像。LAA分割通过专门开发的高分辨率分割框架，经由人工精标与心脏病学专家审核，模型先在大规模私有集上训练后再迁移至公开数据；CA和PV分割分别对原始注释及TotalSegmentator结果进行了精细化修正。另外，作者还标注了数据中常见的伪影及缺陷。

Result: 获得了高分辨率、高质量的LAA、CA、PV以及全心脏标签，覆盖数据集中的多样图像缺陷，并以开源方式提供，便于研究人员后续方法开发和临床研究验证。

Conclusion: 该工作首次为心血管影像分割领域提供了高质量、可扩展且解剖一致的公开数据集，预计将推动LAA等关键结构形态分析及相关分割方法的创新和进步。

Abstract: Despite the success of advanced segmentation frameworks such as
TotalSegmentator (TS), accurate segmentations of the left atrial appendage
(LAA), coronary arteries (CAs), and pulmonary veins (PVs) remain a significant
challenge in medical imaging. In this work, we present the first open-source,
anatomically coherent dataset of curated, high-resolution segmentations for
these structures, supplemented with whole-heart labels produced by TS on the
publicly available ImageCAS dataset consisting of 1000 cardiac computed
tomography angiography (CCTA) scans. One purpose of the data set is to foster
novel approaches to the analysis of LAA morphology.
  LAA segmentations on ImageCAS were generated using a state-of-the-art
segmentation framework developed specifically for high resolution LAA
segmentation. We trained the network on a large private dataset with manual
annotations provided by medical readers guided by a trained cardiologist and
transferred the model to ImageCAS data. CA labels were improved from the
original ImageCAS annotations, while PV segmentations were refined from TS
outputs. In addition, we provide a list of scans from ImageCAS that contains
common data flaws such as step artefacts, LAAs extending beyond the scanner's
field of view, and other types of data defects.

</details>


### [64] [Compact Multi-level-prior Tensor Representation for Hyperspectral Image Super-resolution](https://arxiv.org/abs/2510.06098)
*Yinjian Wang,Wei Li,Yuanyuan Gui,Gemine Vivone*

Main category: cs.CV

TL;DR: 本文提出了一种新型张量框架的高光谱超分辨率融合方法，有效整合了多层次先验信息（如低秩性和空间总变分等），并设计了高效收敛的优化算法，在多数据集上表现优秀。


<details>
  <summary>Details</summary>
Motivation: 目前高光谱与多光谱图像融合（即高光谱超分辨率）方法很多，张量方法证实多层次先验可提升融合效果。但已有方法难以同时高效利用多层次先验（因模型变复杂，权重难平衡，难优化）。因此，亟需新的张量模型可有效刻画和优化多层次先验。

Method: 作者提出新的张量模型：通过块项分解，将高维潜在图像分解为谱子空间和空间映射；将空间映射堆叠为张量以编码高阶空间低秩与平滑先验，并提出非凸的“mode-shuffled tensor correlated total variation”联合建模；最后，设计受线性化交替方向法启发的高效优化算法，并理论证明收敛性。

Result: 在多个数据集上实验，所提方法的融合效果优于现有方法，展示了模型和算法的有效性。

Conclusion: 提出了一种能同时高效刻画多层次先验的高光谱超分辨率新模型和优化方法，理论收敛，实验优越，具有实际应用价值。

Abstract: Fusing a hyperspectral image with a multispectral image acquired over the
same scene, \textit{i.e.}, hyperspectral image super-resolution, has become a
popular computational way to access the latent high-spatial-spectral-resolution
image. To date, a variety of fusion methods have been proposed, among which the
tensor-based ones have testified that multiple priors, such as multidimensional
low-rankness and spatial total variation at multiple levels, effectively drive
the fusion process. However, existing tensor-based models can only effectively
leverage one or two priors at one or two levels, since simultaneously
incorporating multi-level priors inevitably increases model complexity. This
introduces challenges in both balancing the weights of different priors and
optimizing multi-block structures. Concerning this, we present a novel
hyperspectral super-resolution model compactly characterizing these multi-level
priors of hyperspectral images within the tensor framework. Firstly, the
proposed model decouples the spectral low-rankness and spatial priors by
casting the latent high-spatial-spectral-resolution image into spectral
subspace and spatial maps via block term decomposition. Secondly, these spatial
maps are stacked as the spatial tensor encoding the high-order spatial
low-rankness and smoothness priors, which are co-modeled via the proposed
non-convex mode-shuffled tensor correlated total variation. Finally, we draw
inspiration from the linearized alternating direction method of multipliers to
design an efficient algorithm to optimize the resulting model, theoretically
proving its Karush-Kuhn-Tucker convergence under mild conditions. Experiments
on multiple datasets demonstrate the effectiveness of the proposed algorithm.
The code implementation will be available from https://github.com/WongYinJ.

</details>


### [65] [Multimodal Feature Prototype Learning for Interpretable and Discriminative Cancer Survival Prediction](https://arxiv.org/abs/2510.06113)
*Shuo Jiang,Zhuwen Chen,Liaoman Xu,Yanming Zhu,Changmiao Wang,Jiong Zhang,Feiwei Qin,Yifei Chen,Zhu Zhu*

Main category: cs.CV

TL;DR: 该论文提出了一种新的原型学习多模态框架FeatProto，将病理全景切片图像（WSI）的局部与全局特征和基因组信息融合，用于提高癌症生存预测的准确性和可解释性。其创新方法在四个公共癌症数据集上效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有生存分析模型可解释性差，难以辅助临床决策。原型学习虽有潜力，但现有方法过于局部且缺乏与基因数据的语义对齐，需要一种新的、多模态、可解释的生存预测方法。

Method: 提出FeatProto框架，通过构建统一的特征原型空间，将WSI的局部与全局特征和基因组数据融合。采用三项创新：（1）联合关键图像区域与全局信息，融合基因组数据，减小局部偏见；（2）利用指数原型更新策略和“游走机制”自适应肿瘤异质性并维持跨模态特征对齐；（3）分层原型匹配，全面获取全局、局部和队列级趋势。

Result: 在四个公开癌症数据集上，FeatProto模型的生存预测准确性和可解释性均超过现有单模态和多模态领先方法。

Conclusion: FeatProto开辟了跨模态原型学习在医学生存预测中的新道路，提升了模型可追溯性和临床应用价值，对关键医学场景具有重要意义。

Abstract: Survival analysis plays a vital role in making clinical decisions. However,
the models currently in use are often difficult to interpret, which reduces
their usefulness in clinical settings. Prototype learning presents a potential
solution, yet traditional methods focus on local similarities and static
matching, neglecting the broader tumor context and lacking strong semantic
alignment with genomic data. To overcome these issues, we introduce an
innovative prototype-based multimodal framework, FeatProto, aimed at enhancing
cancer survival prediction by addressing significant limitations in current
prototype learning methodologies within pathology. Our framework establishes a
unified feature prototype space that integrates both global and local features
of whole slide images (WSI) with genomic profiles. This integration facilitates
traceable and interpretable decision-making processes. Our approach includes
three main innovations: (1) A robust phenotype representation that merges
critical patches with global context, harmonized with genomic data to minimize
local bias. (2) An Exponential Prototype Update Strategy (EMA ProtoUp) that
sustains stable cross-modal associations and employs a wandering mechanism to
adapt prototypes flexibly to tumor heterogeneity. (3) A hierarchical prototype
matching scheme designed to capture global centrality, local typicality, and
cohort-level trends, thereby refining prototype inference. Comprehensive
evaluations on four publicly available cancer datasets indicate that our method
surpasses current leading unimodal and multimodal survival prediction
techniques in both accuracy and interoperability, providing a new perspective
on prototype learning for critical medical applications. Our source code is
available at https://github.com/JSLiam94/FeatProto.

</details>


### [66] [Towards Data-Efficient Medical Imaging: A Generative and Semi-Supervised Framework](https://arxiv.org/abs/2510.06123)
*Mosong Ma,Tania Stathaki,Michalis Lazarou*

Main category: cs.CV

TL;DR: 本文提出了一种称为SSGNet的统一框架，将特定类别的生成建模与迭代半监督伪标签方法结合，用于改进医学影像的分类和分割，解决数据稀缺与不平衡的问题。通过生成高质量图像扩充训练集，并不断优化伪标签方法，提升了模型性能。实验验证了该方法在多个任务上的有效性。


<details>
  <summary>Details</summary>
Motivation: 医学影像领域深度学习面临训练数据稀缺和标注不平衡的难题，严重限制了模型性能提升。作者旨在开发一种方法，能够在有限标注数据条件下，通过生成式模型和半监督学习充分挖掘数据潜力，提高分类与分割的精度和泛化能力。

Method: SSGNet框架将两个关键方法结合：1）利用StyleGAN3为指定类别生成高质量医学影像以扩充样本，2）通过半监督迭代伪标签技术逐步优化未标注样本的标签。该框架不是独立模型，而是作为现有基线的增强器，帮助模型获得更多有效训练数据和更准确标签。

Result: 在多个医学影像基准数据集上的实验表明，采用SSGNet方法后，无论是分类还是分割任务，性能都获得了显著且稳定的提升。通过Frechet Inception Distance（FID）分析，证实生成样本具有很高的图像质量。

Conclusion: SSGNet为医学影像分析提供了一种务实且有效的训练数据扩充与伪标签优化策略，能够缓解数据标注瓶颈，提升模型鲁棒性和泛化能力。

Abstract: Deep learning in medical imaging is often limited by scarce and imbalanced
annotated data. We present SSGNet, a unified framework that combines class
specific generative modeling with iterative semisupervised pseudo labeling to
enhance both classification and segmentation. Rather than functioning as a
standalone model, SSGNet augments existing baselines by expanding training data
with StyleGAN3 generated images and refining labels through iterative pseudo
labeling. Experiments across multiple medical imaging benchmarks demonstrate
consistent gains in classification and segmentation performance, while Frechet
Inception Distance analysis confirms the high quality of generated samples.
These results highlight SSGNet as a practical strategy to mitigate annotation
bottlenecks and improve robustness in medical image analysis.

</details>


### [67] [Discrete Diffusion Models with MLLMs for Unified Medical Multimodal Generation](https://arxiv.org/abs/2510.06131)
*Jiawei Mao,Yuhan Wang,Lifeng Chen,Can Zhao,Yucheng Tang,Dong Yang,Liangqiong Qu,Daguang Xu,Yuyin Zhou*

Main category: cs.CV

TL;DR: 本文提出了MeDiM，一种创新的医学离散扩散模型，首次实现了多模态医学生成任务的统一，无需特定于模态的组件，可进行图像与文本互译及图文联合生成。


<details>
  <summary>Details</summary>
Motivation: 现有的医学生成模型受限于只能处理特定模态（如图像或文本），难以整合成“基础模型”，不能全面覆盖医学多源数据，限制了其医学推理与应用能力。

Method: 作者提出了MeDiM模型：基于离散扩散架构，融合视觉与语言表示至共享的概率空间，并以多模态大语言模型（MLLM）作为主干，利用其跨模态知识和推理能力。其创新点包括：1）去除因果注意力掩码以实现双向上下文；2）融入连续的时间步嵌入增强对扩散过程的感知。

Result: MeDiM在医学图像生成（MIMIC-CXR数据集FID 16.60，PathGen FID 24.19）和自动报告生成（METEOR 0.2650与0.2580）指标上取得了高质量表现。其生成的图文对还能显著提升下游任务的性能（BLEU-1提升6.43%，BLEU-2提升18.57%，BLEU-3提升31.58%，METEOR提升4.8%）。

Conclusion: MeDiM实现了医学多模态生成任务的统一，可生成高质量且符合临床语境的多模态输出，为未来医学基础模型奠定基础。

Abstract: Recent advances in generative medical models are constrained by
modality-specific scenarios that hinder the integration of complementary
evidence from imaging, pathology, and clinical notes. This fragmentation limits
their evolution into foundation models that can learn and reason across the
full spectrum of biomedical data. We propose MeDiM, the first medical discrete
diffusion model that learns shared distributions across modalities without
modality-specific components. MeDiM unifies multiple generative tasks:
translating between images and text, and jointly producing image-report pairs
across domains in response to prompts. Built on a discrete diffusion framework,
MeDiM bridges vision and language representations through a shared
probabilistic space. To enable unified and flexible medical generation, we
employ a multimodal large language model (MLLM) as the diffusion backbone,
leveraging its prior knowledge and cross-modal reasoning. Two key designs are
introduced: (1) removing the causal attention mask for bidirectional context,
and (2) injecting continuous timestep embeddings for diffusion awareness.
Experiments demonstrate high-fidelity medical generation (FID 16.60 on
MIMIC-CXR and FID 24.19 on PathGen) and accurate report generation (METEOR
0.2650 and 0.2580). Jointly generated image-report pairs further enhance
downstream performance (plus6.43 percent BLEU-1, plus18.57 percent BLEU-2,
plus31.58 percent BLEU-3, plus4.80 percent METEOR), showing that MeDiM supports
coherent and clinically grounded multimodal outputs.

</details>


### [68] [Deforming Videos to Masks: Flow Matching for Referring Video Segmentation](https://arxiv.org/abs/2510.06139)
*Zanyi Wang,Dengyang Jiang,Liuzhuozheng Li,Sizhe Dang,Chengzu Li,Harry Yang,Guang Dai,Mengmeng Wang,Jingdong Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的Referring Video Object Segmentation（RVOS）方法——FlowRVS，将该任务建模为有条件的连续流变形问题，显著提升了分割性能，取得了最新的SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 以往RVOS方法多采用“先定位再分割”的两阶段流程，导致语义信息损失，且难以保证时序一致性。因此，亟需新的方法实现更高效、更一致的语言和视觉对齐。

Method: 本文提出FlowRVS框架，将RVOS重构为条件连续流问题，借助预训练文本到视频模型（T2V）赋能，实现像素级精细控制和视频时序连贯。在训练过程中，方法直接学习视频整体特征到目标分割掩码的语言引导变形流，实现一阶段的生成式推断。

Result: 在主流RVOS基准上均达到了新的最优性能。其中MeViS上$J&F$为51.1（较之前提升1.6），零样本Ref-DAVIS17为73.3（提升2.7）。

Conclusion: 将视频对象分割问题表述为连续形变流，显著提升了分割效果和时序一致性，为视频语义理解任务提供了新的研究视角及技术路径。

Abstract: Referring Video Object Segmentation (RVOS) requires segmenting specific
objects in a video guided by a natural language description. The core challenge
of RVOS is to anchor abstract linguistic concepts onto a specific set of pixels
and continuously segment them through the complex dynamics of a video. Faced
with this difficulty, prior work has often decomposed the task into a pragmatic
`locate-then-segment' pipeline. However, this cascaded design creates an
information bottleneck by simplifying semantics into coarse geometric prompts
(e.g, point), and struggles to maintain temporal consistency as the segmenting
process is often decoupled from the initial language grounding. To overcome
these fundamental limitations, we propose FlowRVS, a novel framework that
reconceptualizes RVOS as a conditional continuous flow problem. This allows us
to harness the inherent strengths of pretrained T2V models, fine-grained pixel
control, text-video semantic alignment, and temporal coherence. Instead of
conventional generating from noise to mask or directly predicting mask, we
reformulate the task by learning a direct, language-guided deformation from a
video's holistic representation to its target mask. Our one-stage, generative
approach achieves new state-of-the-art results across all major RVOS
benchmarks. Specifically, achieving a $\mathcal{J}\&\mathcal{F}$ of 51.1 in
MeViS (+1.6 over prior SOTA) and 73.3 in the zero shot Ref-DAVIS17 (+2.7),
demonstrating the significant potential of modeling video understanding tasks
as continuous deformation processes.

</details>


### [69] [Bimanual 3D Hand Motion and Articulation Forecasting in Everyday Images](https://arxiv.org/abs/2510.06145)
*Aditya Prakash,David Forsyth,Saurabh Gupta*

Main category: cs.CV

TL;DR: 本论文提出了一种从单张图片中预测双手三维运动和关节动作的方法，通过结合扩散模型和序列提升技术，在多数据集上实现了大幅性能提升。


<details>
  <summary>Details</summary>
Motivation: 现实场景下缺乏大量真实三维手部动作数据，阻碍了相关AI应用的发展，因此需要设计自动标注流程和更强的预测模型。

Method: 1. 首先，设计了一个扩散模型，用于将二维手部关键点序列提升成四维（含时间和3D坐标）手部动作，从而为训练集生成3D标注数据。
2. 在手部预测模型中，引入扩散损失以应对手部动作的多模态分布，提高对未来动作的预判能力。

Result: 1. 在6个数据集上，使用这套流程训练能比最佳现有标准提升14%的准确度。
2. 其提升模型在标注上表现提升42%，预测模型提升16.4%。
3. 在零样本泛化到日常图片的实验场景下效果尤其突出。

Conclusion: 本研究通过自动化数据提升和多模态损失优化，极大增强了双手三维动作预测系统在多样化现实环境中的适应性与泛化能力。

Abstract: We tackle the problem of forecasting bimanual 3D hand motion & articulation
from a single image in everyday settings. To address the lack of 3D hand
annotations in diverse settings, we design an annotation pipeline consisting of
a diffusion model to lift 2D hand keypoint sequences to 4D hand motion. For the
forecasting model, we adopt a diffusion loss to account for the multimodality
in hand motion distribution. Extensive experiments across 6 datasets show the
benefits of training on diverse data with imputed labels (14% improvement) and
effectiveness of our lifting (42% better) & forecasting (16.4% gain) models,
over the best baselines, especially in zero-shot generalization to everyday
images.

</details>


### [70] [ShapeGen4D: Towards High Quality 4D Shape Generation from Videos](https://arxiv.org/abs/2510.06208)
*Jiraphon Yenphraphai,Ashkan Mirzaei,Jianqi Chen,Jiaxu Zou,Sergey Tulyakov,Raymond A. Yeh,Peter Wonka,Chaoyang Wang*

Main category: cs.CV

TL;DR: 本文提出了一种端到端的视频到4D形状生成框架，能充分利用视频信息重建具有一致外观和几何变化的动态3D模型，明显优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有4D形状生成方法难以高效、准确地从视频直接恢复时变三维几何和外观，常存在局部不一致和算法鲁棒性弱等问题。

Method: 该方法基于大规模预训练3D模型，设计了三个核心机制：1）时序注意力机制，全局考虑视频所有帧，输出带时间索引的动态3D表示；2）时间感知点采样与4D潜变量锚定，提高几何与纹理的时序一致性；3）帧间噪声共享，增强时间稳定性。无需逐帧优化，端到端生成动态场景。

Result: 实验表明，该方法能准确建模非刚性运动、体积变化等复杂动态，并在多样性的真实视频中表现出更强的鲁棒性和感知保真度，错误率低于现有基线。

Conclusion: 提出的框架能够直接高效地从单段视频恢复高质量的时间连续三维场景，实现对4D动态形状的端到端、一体化生成，并有望推动相关领域的应用与研究。

Abstract: Video-conditioned 4D shape generation aims to recover time-varying 3D
geometry and view-consistent appearance directly from an input video. In this
work, we introduce a native video-to-4D shape generation framework that
synthesizes a single dynamic 3D representation end-to-end from the video. Our
framework introduces three key components based on large-scale pre-trained 3D
models: (i) a temporal attention that conditions generation on all frames while
producing a time-indexed dynamic representation; (ii) a time-aware point
sampling and 4D latent anchoring that promote temporally consistent geometry
and texture; and (iii) noise sharing across frames to enhance temporal
stability. Our method accurately captures non-rigid motion, volume changes, and
even topological transitions without per-frame optimization. Across diverse
in-the-wild videos, our method improves robustness and perceptual fidelity and
reduces failure modes compared with the baselines.

</details>


### [71] [Drive&Gen: Co-Evaluating End-to-End Driving and Video Generation Models](https://arxiv.org/abs/2510.06209)
*Jiahao Wang,Zhenpei Yang,Yijing Bai,Yingwei Li,Yuliang Zou,Bo Sun,Abhijit Kundu,Jose Lezama,Luna Yue Huang,Zehao Zhu,Jyh-Jing Hwang,Dragomir Anguelov,Mingxing Tan,Chiyu Max Jiang*

Main category: cs.CV

TL;DR: 本论文探索了生成模型在自动驾驶领域的应用，特别是将视频生成模型作为可控的虚拟测试环境，并结合端到端（E2E）驾驶模型来评估与提升自动驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型在视频真实感方面不断进步，自动驾驶研究者希望利用这些生成模型作为虚拟测试场景，以便提升端到端驾驶模型的泛化能力和理解其局限性。因此，作者关注生成视频的条件可控性及其在真实参数还原和E2E规划器评测中的有效性。

Method: 作者提出将驾驶模型与生成世界模型（Drive&Gen）结合，利用E2E驾驶模型制定新的统计测度来评估生成视频的真实性。通过控制生成模型的输入，设计目标性实验以分析分布差距对E2E驾驶性能的影响。同时，研究了合成数据提升E2E模型泛化能力的方法。

Result: 1）提出的统计测度能够有效衡量生成视频对E2E驾驶规划器的真实性和适用性；2）通过可控生成模型设计分布外数据，发现并分析E2E驾驶器的泛化短板；3）用生成视频合成数据训练E2E模型，显著提升了它们对新领域（新场景）的适应能力。

Conclusion: 结合生成视频模型与E2E驾驶器，为虚拟自动驾驶测试和泛化能力提升提供了新思路。合成视频数据能够作为真实世界数据的高性价比替代品，有望帮助自动驾驶更好地扩展到新的操作环境。

Abstract: Recent advances in generative models have sparked exciting new possibilities
in the field of autonomous vehicles. Specifically, video generation models are
now being explored as controllable virtual testing environments.
Simultaneously, end-to-end (E2E) driving models have emerged as a streamlined
alternative to conventional modular autonomous driving systems, gaining
popularity for their simplicity and scalability. However, the application of
these techniques to simulation and planning raises important questions. First,
while video generation models can generate increasingly realistic videos, can
these videos faithfully adhere to the specified conditions and be realistic
enough for E2E autonomous planner evaluation? Second, given that data is
crucial for understanding and controlling E2E planners, how can we gain deeper
insights into their biases and improve their ability to generalize to
out-of-distribution scenarios? In this work, we bridge the gap between the
driving models and generative world models (Drive&Gen) to address these
questions. We propose novel statistical measures leveraging E2E drivers to
evaluate the realism of generated videos. By exploiting the controllability of
the video generation model, we conduct targeted experiments to investigate
distribution gaps affecting E2E planner performance. Finally, we show that
synthetic data produced by the video generation model offers a cost-effective
alternative to real-world data collection. This synthetic data effectively
improves E2E model generalization beyond existing Operational Design Domains,
facilitating the expansion of autonomous vehicle services into new operational
contexts.

</details>


### [72] [Fine-grained Defocus Blur Control for Generative Image Models](https://arxiv.org/abs/2510.06215)
*Ayush Shrivastava,Connelly Barnes,Xuaner Zhang,Lingzhi Zhang,Andrew Owens,Sohrab Amirghodsi,Eli Shechtman*

Main category: cs.CV

TL;DR: 本文提出了一种结合相机元数据（如EXIF数据）的文图扩散模型，实现了对镜头虚化（景深）效果的精细可控生成。相比现有扩散模型，该方法可在保留场景内容的基础上，更精确地控制虚化效果。


<details>
  <summary>Details</summary>
Motivation: 当前文图扩散模型难以利用具体的相机参数，如光圈等EXIF信息，来控制最终图像效果。实际照片的景深与这些参数密切相关，因此需要一种能结合相机元数据、实现虚化可控的生成方法。

Method: 该方法首先生成一张全清晰图像，然后估算其单目深度，通过创新的焦距距离Transformer预测合理的焦点距离，最后与可微镜头虚化模型结合生成带有可控虚化效果的图像。训练时，梯度可反向传播整个流程，无需显式监督即可学习基于内容和EXIF数据自动生成虚化效果。

Result: 实验结果显示，该模型能在保持图像场景内容不变的前提下，实现比现有扩散模型更精细和可控的虚化（景深）效果。

Conclusion: 融合相机EXIF数据的扩散模型在文图生成领域实现了对景深和虚化的精细可控，填补了现有方法在相机参数控制能力上的不足。

Abstract: Current text-to-image diffusion models excel at generating diverse,
high-quality images, yet they struggle to incorporate fine-grained camera
metadata such as precise aperture settings. In this work, we introduce a novel
text-to-image diffusion framework that leverages camera metadata, or EXIF data,
which is often embedded in image files, with an emphasis on generating
controllable lens blur. Our method mimics the physical image formation process
by first generating an all-in-focus image, estimating its monocular depth,
predicting a plausible focus distance with a novel focus distance transformer,
and then forming a defocused image with an existing differentiable lens blur
model. Gradients flow backwards through this whole process, allowing us to
learn without explicit supervision to generate defocus effects based on content
elements and the provided EXIF data. At inference time, this enables precise
interactive user control over defocus effects while preserving scene contents,
which is not achievable with existing diffusion models. Experimental results
demonstrate that our model enables superior fine-grained control without
altering the depicted scene.

</details>


### [73] [EgoNight: Towards Egocentric Vision Understanding at Night with a Challenging Benchmark](https://arxiv.org/abs/2510.06218)
*Deheng Zhang,Yuqian Fu,Runyi Yang,Yang Miao,Tianwen Qian,Xu Zheng,Guolei Sun,Ajad Chhatkuli,Xuanjing Huang,Yu-Gang Jiang,Luc Van Gool,Danda Pani Paudel*

Main category: cs.CV

TL;DR: 本文提出了EgoNight，这是首个专注于夜间第一视角视觉任务的综合性基准，核心任务是视觉问答（VQA），并扩展了多项夜间相关任务。


<details>
  <summary>Details</summary>
Motivation: 现有第一视角视觉基准主要聚焦于白天场景，现实中夜间低光条件很常见但被忽视，导致模型在夜间表现不佳。因此，亟需一个系统性夜间基准来推动研究。

Method: 作者采集了Blender合成和真实世界的对齐日夜视频，用于构建EgoNight数据集，并采用创新的“日增夜”自动标注引擎和人工双重核查来生成高质量VQA数据。并提出两个辅助任务：昼夜对应检索与夜间深度估计。

Result: EgoNight-VQA含90条夜间视频和3658组问答对，类型丰富。多模态大模型在夜间场景表现明显下降，表明低光推理挑战突出。

Conclusion: EgoNight为夜间第一视角视觉理解及通用光照条件下模型构建提供了宝贵资源和新基准，有助于推动跨光照领域的相关研究和应用。

Abstract: Most existing benchmarks for egocentric vision understanding focus primarily
on daytime scenarios, overlooking the low-light conditions that are inevitable
in real-world applications. To investigate this gap, we present EgoNight, the
first comprehensive benchmark for nighttime egocentric vision, with visual
question answering (VQA) as the core task. A key feature of EgoNight is the
introduction of day-night aligned videos, which enhance night annotation
quality using the daytime data and reveal clear performance gaps between
lighting conditions. To achieve this, we collect both synthetic videos rendered
by Blender and real-world recordings, ensuring that scenes and actions are
visually and temporally aligned. Leveraging these paired videos, we construct
EgoNight-VQA, supported by a novel day-augmented night auto-labeling engine and
refinement through extensive human verification. Each QA pair is double-checked
by annotators for reliability. In total, EgoNight-VQA contains 3658 QA pairs
across 90 videos, spanning 12 diverse QA types, with more than 300 hours of
human work. Evaluations of state-of-the-art multimodal large language models
(MLLMs) reveal substantial performance drops when transferring from day to
night, underscoring the challenges of reasoning under low-light conditions.
Beyond VQA, EgoNight also introduces two auxiliary tasks, day-night
correspondence retrieval and egocentric depth estimation at night, that further
explore the boundaries of existing models. We believe EgoNight-VQA provides a
strong foundation for advancing application-driven egocentric vision research
and for developing models that generalize across illumination domains. All the
data and code will be made available upon acceptance.

</details>


### [74] [Human3R: Everyone Everywhere All at Once](https://arxiv.org/abs/2510.06219)
*Yue Chen,Xingyu Chen,Yuxuan Xue,Anpei Chen,Yuliang Xiu,Gerard Pons-Moll*

Main category: cs.CV

TL;DR: Human3R提出了一种能够实时、全流程且高效地完成多人物与场景四维重建的方法，显著简化了复杂依赖和流程，达到了业界先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有的4D人-场景重建方法大多依赖于多阶段处理流程、大量预处理模块（如人体检测、深度估计、SLAM等），这些带来计算负担、效率瓶颈与部署难题。该论文旨在提出一种更加统一、高效、端到端的解决方案，实现4D场景高效重建。

Method: Human3R基于CUT3R模型，采用参数高效的视觉提示微调技术，使模型能够直接输出多个人体SMPL-X网格、场景的三维重建以及摄像机轨迹，无需多阶段处理和迭代优化。训练仅需小规模合成数据集BEDLAM，在普通GPU上一天即可完成，保证了模型的高效性与可复现性。

Result: Human3R在多个任务（如全局人体动作估计、局部人体网格重建、视频深度估计和摄像机姿态估计）上表现出与先进模型相当甚至更优的性能，且能在单一模型、单次推理下实现实时（15 FPS）、低显存（8GB）输出。

Conclusion: Human3R作为一种统一、端到端的4D人-场景重建新范式，显著降低了使用门槛和计算成本，为相关研究和实际应用提供了高效且强大的基线方法。

Abstract: We present Human3R, a unified, feed-forward framework for online 4D
human-scene reconstruction, in the world frame, from casually captured
monocular videos. Unlike previous approaches that rely on multi-stage
pipelines, iterative contact-aware refinement between humans and scenes, and
heavy dependencies, e.g., human detection, depth estimation, and SLAM
pre-processing, Human3R jointly recovers global multi-person SMPL-X bodies
("everyone"), dense 3D scene ("everywhere"), and camera trajectories in a
single forward pass ("all-at-once"). Our method builds upon the 4D online
reconstruction model CUT3R, and uses parameter-efficient visual prompt tuning,
to strive to preserve CUT3R's rich spatiotemporal priors, while enabling direct
readout of multiple SMPL-X bodies. Human3R is a unified model that eliminates
heavy dependencies and iterative refinement. After being trained on the
relatively small-scale synthetic dataset BEDLAM for just one day on one GPU, it
achieves superior performance with remarkable efficiency: it reconstructs
multiple humans in a one-shot manner, along with 3D scenes, in one stage, at
real-time speed (15 FPS) with a low memory footprint (8 GB). Extensive
experiments demonstrate that Human3R delivers state-of-the-art or competitive
performance across tasks, including global human motion estimation, local human
mesh recovery, video depth estimation, and camera pose estimation, with a
single unified model. We hope that Human3R will serve as a simple yet strong
baseline, be easily extended for downstream applications.Code available in
https://fanegg.github.io/Human3R

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [75] [Collaborative and Proactive Management of Task-Oriented Conversations](https://arxiv.org/abs/2510.05110)
*Arezoo Saedi,Afsaneh Fatemi,Mohammad Ali Nematbakhsh,Sophie Rosset,Anne Vilnat*

Main category: cs.CL

TL;DR: 本文提出了一种基于信息状态管理的新型任务型对话系统模型，有效提升了对话规划和任务完成度。


<details>
  <summary>Details</summary>
Motivation: 现有的任务型对话系统虽然受益于大型语言模型（LLMs），但许多系统忽视了以目标为核心的主动式对话规划，导致任务完成效率和对话质量有限。作者希望通过改进对话管理机制，提升系统的任务达成能力和智能性。

Method: 作者借鉴信息状态对话管理方法，先定义用户偏好的插槽和文本信息要素，分析对话中的关键中间信息，建立对应的有限信息状态。基于这些状态，设计对话行为和必要的操作流程，并制定状态更新策略。系统利用LLM的上下文学习能力，结合插槽与文本顺序生成数据库查询和排序相关实体，实现用户偏好的一致性信息输出。

Result: 在MultiWOZ测试集上（单对话不超过一个域），新模型在inform和success指标上均达到最优，且全面优于以往方法，证明方法有效。

Conclusion: 该模型通过信息状态管理显著提升了任务型对话系统的规划能力和任务达成率，为LLM驱动的对话系统提供了新的高效管理框架。

Abstract: Task oriented dialogue systems (TOD) complete particular tasks based on user
preferences across natural language interactions. Considering the impressive
performance of large language models (LLMs) in natural language processing
(NLP) tasks, most of the latest TODs are centered on LLMs. While proactive
planning is crucial for task completion, many existing TODs overlook effective
goal-aware planning. This paper creates a model for managing task-oriented
conversations, conceptualized centered on the information state approach to
dialogue management. The created model incorporated constructive intermediate
information in planning. Initially, predefined slots and text part
informational components are created to model user preferences. Investigating
intermediate information, critical circumstances are identified. Informational
components corresponding to these circumstances are created. Possible
configurations for these informational components lead to limited information
states. Then, dialogue moves, which indicate movement between these information
states and the procedures that must be performed in the movements, are created.
Eventually, the update strategy is constructed. The created model is
implemented leveraging in-context learning of LLMs. In this model, database
queries are created centered on indicated predefined slots and the order of
retrieved entities is indicated centered on text part. This mechanism enables
passing the whole corresponding entities to the preferences in the order of
congruency. Evaluations exploiting the complete test conversations of MultiWOZ,
with no more than a domain in a conversation, illustrate maximal inform and
success, and improvement compared with previous methods.

</details>


### [76] [Trainable Reference-Based Evaluation Metric for Identifying Quality of English-Gujarati Machine Translation System](https://arxiv.org/abs/2510.05113)
*Nisheeth Joshi,Pragya Katyayan,Palak Arora*

Main category: cs.CL

TL;DR: 本文提出了一种基于监督学习的、用于评估古吉拉特语机器翻译输出质量的新方法，并证明其能更好地与人工评价相关联。


<details>
  <summary>Details</summary>
Motivation: 现有针对英语和欧洲语言的机器翻译评价方法在印度语言上表现较差，特别是古吉拉特语，因此需要开发更适合该语言的评估指标。

Method: 提出了一种参考型、基于监督学习的评价指标，利用25个特征进行训练，分别采用6层和10层隐藏层的神经网络模型，各训练500个epoch。通过对7个MT系统的1000条古吉拉特语译文进行测试，与人工翻译作比对。

Result: 新方法对1000条MT输出的评价结果与人工评分的相关性高于现有其他指标。

Conclusion: 本文提出的古吉拉特语MT评价新指标能更有效地反映人工评价标准，为印度语言MT评价提供了更佳解决方案。

Abstract: Machine Translation (MT) Evaluation is an integral part of the MT development
life cycle. Without analyzing the outputs of MT engines, it is impossible to
evaluate the performance of an MT system. Through experiments, it has been
identified that what works for English and other European languages does not
work well with Indian languages. Thus, In this paper, we have introduced a
reference-based MT evaluation metric for Gujarati which is based on supervised
learning. We have trained two versions of the metric which uses 25 features for
training. Among the two models, one model is trained using 6 hidden layers with
500 epochs while the other model is trained using 10 hidden layers with 500
epochs. To test the performance of the metric, we collected 1000 MT outputs of
seven MT systems. These MT engine outputs were compared with 1 human reference
translation. While comparing the developed metrics with other available
metrics, it was found that the metrics produced better human correlations.

</details>


### [77] [Hallucination is Inevitable for LLMs with the Open World Assumption](https://arxiv.org/abs/2510.05116)
*Bowen Xu*

Main category: cs.CL

TL;DR: 本文重新定义了大语言模型(LLMs)出现幻觉（hallucination）的问题，认为它不仅是工程缺陷，更是一般化能力的必然表现，尤其在开放世界环境下无法完全避免，并提出幻觉应作为结构性特征容忍和兼容。


<details>
  <summary>Details</summary>
Motivation: 现有研究多将大语言模型的幻觉问题当作缺陷来看待，追求减少其出现。然而，理论分析表明在某些条件下幻觉无法完全消除，尤其是在人工智能追求广泛适应性的背景下需重新审视其本质。

Method: 采用理论分析方法，区分并讨论了封闭世界（Closed World）和开放世界（Open World）两个环境下幻觉问题的不可避免性，并提出了幻觉的不同类型分类框架。

Result: 在封闭世界假设下，训练与测试分布一致，幻觉问题可以缓解；而在开放世界中，环境无限制，幻觉不可避免，部分类型可修正，部分则难以根除。

Conclusion: 幻觉是开放世界中大模型不可避免的结构性特征，不应简单当作缺陷，而应努力与人类智能兼容，并在设计时加以容忍和引导。

Abstract: Large Language Models (LLMs) exhibit impressive linguistic competence but
also produce inaccurate or fabricated outputs, often called ``hallucinations''.
Engineering approaches usually regard hallucination as a defect to be
minimized, while formal analyses have argued for its theoretical inevitability.
Yet both perspectives remain incomplete when considering the conditions
required for artificial general intelligence (AGI). This paper reframes
``hallucination'' as a manifestation of the generalization problem. Under the
Closed World assumption, where training and test distributions are consistent,
hallucinations may be mitigated. Under the Open World assumption, however,
where the environment is unbounded, hallucinations become inevitable. This
paper further develops a classification of hallucination, distinguishing cases
that may be corrected from those that appear unavoidable under open-world
conditions. On this basis, it suggests that ``hallucination'' should be
approached not merely as an engineering defect but as a structural feature to
be tolerated and made compatible with human intelligence.

</details>


### [78] [Towards Structured Knowledge: Advancing Triple Extraction from Regional Trade Agreements using Large Language Models](https://arxiv.org/abs/2510.05121)
*Durgesh Nandini,Rebekka Koch,Mirco Schoenfeld*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型（LLMs）在经济领域中从文本中提取结构化知识（三元组：主体-谓词-宾语）的效果，特别是针对区域贸易协议文本。


<details>
  <summary>Details</summary>
Motivation: 经济领域中的大量文本数据（如法律贸易协议）难以直接用于知识发现。将这些数据转为结构化的知识三元组，对于构建经济知识图谱、实现信息自动化提取具有重要意义。

Method: 采用Llama 3.1大语言模型，对区域贸易协议等无人标注的经济文本进行信息三元组抽取，探索了零样本、单样本和小样本提示工程方法，并结合正例和负例来提升抽取效果，最后通过定量和定性指标对结果进行评估。

Result: 实验表明，LLMs在经济法律文本三元组抽取任务中展现出较强能力，不同提示方法对最终表现有显著影响，提出了一些实用的提示策略。

Conclusion: 语言模型在经济领域结构化知识抽取中具有很大潜力，但仍面临具体应用中的挑战，如提升准确率、处理复杂句式等，未来可在模型优化与经济知识图谱应用方面展开深入研究。

Abstract: This study investigates the effectiveness of Large Language Models (LLMs) for
the extraction of structured knowledge in the form of Subject-Predicate-Object
triples. We apply the setup for the domain of Economics application. The
findings can be applied to a wide range of scenarios, including the creation of
economic trade knowledge graphs from natural language legal trade agreement
texts. As a use case, we apply the model to regional trade agreement texts to
extract trade-related information triples. In particular, we explore the
zero-shot, one-shot and few-shot prompting techniques, incorporating positive
and negative examples, and evaluate their performance based on quantitative and
qualitative metrics. Specifically, we used Llama 3.1 model to process the
unstructured regional trade agreement texts and extract triples. We discuss key
insights, challenges, and potential future directions, emphasizing the
significance of language models in economic applications.

</details>


### [79] [CARE: Cognitive-reasoning Augmented Reinforcement for Emotional Support Conversation](https://arxiv.org/abs/2510.05122)
*Jie Zhu,Yuanchen Zhou,Shuo Jiang,Junhui Li,Lifan Guo,Feng Chen,Chi Zhang,Fang Kong*

Main category: cs.CL

TL;DR: 本文提出了CARE框架，通过强化认知推理提升情感支持对话系统表现，而非依赖大规模合成数据。


<details>
  <summary>Details</summary>
Motivation: 现有情感支持对话研究主要关注数据增强和语料合成，忽视了实现有效情感支持所需的认知推理过程。

Method: 提出CARE框架，利用原始ESC训练集引导模型生成逻辑连贯且有支持性的回应，同时结合强化学习优化推理过程。

Result: 实验证明，CARE显著提升了回应的逻辑合理性和支持性。

Conclusion: CARE推动了更具共情能力、认知健全和类人的情感支持系统发展。

Abstract: Emotional Support Conversation (ESC) plays a vital role in alleviating
psychological stress and providing emotional value through dialogue. While
recent studies have largely focused on data augmentation and synthetic corpus
construction, they often overlook the deeper cognitive reasoning processes that
underpin effective emotional support. To address this gap, we propose
\textbf{CARE}, a novel framework that strengthens reasoning in ESC without
relying on large-scale synthetic data. CARE leverages the original ESC training
set to guide models in generating logically coherent and supportive responses,
thereby explicitly enhancing cognitive reasoning. Building on this foundation,
we further employ reinforcement learning to refine and reinforce the reasoning
process. Experimental results demonstrate that CARE significantly improves both
the logical soundness and supportive quality of responses, advancing the
development of empathetic, cognitively robust, and human-like emotional support
systems.

</details>


### [80] [MADS: Multi-Agent Dialogue Simulation for Diverse Persuasion Data Generation](https://arxiv.org/abs/2510.05124)
*Mingjin Li,Yu Liu,Huayi Liu,Xiang Ye,Chao Jiang,Hongguang Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为MADS的多智能体对话模拟框架，可通过智能体自博弈生成高质量的说服类多轮对话，旨在帮助提升小型大模型的说服能力。


<details>
  <summary>Details</summary>
Motivation: 在实际营销和对话系统中，缺乏高质量、多样化的用户对话数据限制了说服性对话模型的训练与评价；同时，传统方法数据获取成本高、冷启动难、提示设计效率低。

Method: MADS框架由三类智能体协同组成：用户智能体（模拟多样化的人设行为）、对话智能体（实施任务导向的说服策略）、优化智能体（评估与优化对话结果）。该框架无需人工标注，通过智能体自博弈生成训练数据。效果通过用户态度链建模与专用大模型的说服力评估加以验证。

Result: 在真实营销场景测试中，采用MADS生成的数据训练的小型大模型，其说服能力显著提升：自然流量转化率提升22.4%（1.83%提升到2.24%）。

Conclusion: MADS框架可低成本生成高效说服性对话数据，解决数据稀缺、冷启动与提示低效等行业痛点，显著提升小型大模型的实际应用价值和业务转化率。

Abstract: We propose MADS (Multi-Agent Dialogue Simulation), a scalable framework for
generating persuasive multi-turn dialogues via agent self-play. MADS employs
three coordinated agents: User Agents simulating diverse persona-driven
behaviors, a Dialog Agent executing task-oriented persuasion strategies and an
Optimization Agent evaluating and refining dialogue outcomes. We further
validate its effectiveness through users' Chain-of-Attitude (CoA) modeling and
dedicated LLMs' persuasion assessment. This approach enables low-cost
generation of training data without human annotation, addressing key industry
challenges such as lack of user data, cold-start evaluation difficulties, and
prompt inefficiency. Applied to a real-world marketing scenario, MADS
significantly improved the persuasion capacity of small LLMs, increasing the
organic traffic conversion rate by 22.4\% (from 1.83\% to 2.24\%) ,
demonstrating clear business value.

</details>


### [81] [Catalog-Native LLM: Speaking Item-ID Dialect with Less Entanglement for Recommendation](https://arxiv.org/abs/2510.05125)
*Reza Shirkavand,Xiaokai Wei,Chen Wang,Zheng Hui,Heng Huang,Michelle Gong*

Main category: cs.CL

TL;DR: 本文提出了一种融合协同过滤和大语言模型（LLM）优势的新颖方法，即IDIOMoE模型，实现了高效精确的推荐和优秀的自然语言理解能力。


<details>
  <summary>Details</summary>
Motivation: 现代推荐系统面临着用户对自然语言查询和推荐解释的需求，需要将协同过滤的预测准确性与大语言模型的语言理解能力结合起来。但这两者难以统一：协同过滤信号高效但语义不透明，大语言模型虽语义丰富但难以捕捉隐式用户兴趣。

Method: 提出了“Item-ID + 口语混合专家语言模型”（IDIOMoE），将物品交互历史视为语言空间中的一种方言。在LLM的每一层前馈神经网络中，划分为文本专家和物品专家，并结合token类型的门控，避免文字与目录信号的互相干扰。

Result: 该方法在多个公开和私有数据集上展现了很强的推荐性能，同时保持了预训练语言模型对文本的理解能力。

Conclusion: IDIOMoE有效融合了协同过滤与LLM的优势，能够提供强大的推荐效果及良好的文本理解，为现代推荐系统提供了新的统一范式。

Abstract: While collaborative filtering delivers predictive accuracy and efficiency,
and Large Language Models (LLMs) enable expressive and generalizable reasoning,
modern recommendation systems must bring these strengths together. Growing user
expectations, such as natural-language queries and transparent explanations,
further highlight the need for a unified approach. However, doing so is
nontrivial. Collaborative signals are often token-efficient but semantically
opaque, while LLMs are semantically rich but struggle to model implicit user
preferences when trained only on textual inputs. This paper introduces Item-ID
+ Oral-language Mixture-of-Experts Language Model (IDIOMoE), which treats item
interaction histories as a native dialect within the language space, enabling
collaborative signals to be understood in the same way as natural language. By
splitting the Feed Forward Network of each block of a pretrained LLM into a
separate text expert and an item expert with token-type gating, our method
avoids destructive interference between text and catalog modalities. IDIOMoE
demonstrates strong recommendation performance across both public and
proprietary datasets, while preserving the text understanding of the pretrained
model.

</details>


### [82] [Improving Metacognition and Uncertainty Communication in Language Models](https://arxiv.org/abs/2510.05126)
*Mark Steyvers,Catarina Belem,Padhraic Smyth*

Main category: cs.CL

TL;DR: 本文探究了用大语言模型（LLM）时，通过有监督微调提升其不确定性沟通能力，说明多任务微调可在不同任务和领域提升模型校准和判别力。


<details>
  <summary>Details</summary>
Motivation: LLM在决策中应用广泛，但它们在自信表达上的错配导致用户无法察觉不确定性，可能造成误判。因此，需要提升LLM表达不确定性的能力，以便用户更好地理解模型输出的可靠度。

Method: 作者在两种LLM上，针对通用知识、数学、开放式问答三类数据集进行有监督微调，训练模型在两个认知任务上表现：（1）单问题置信度估计；（2）成对答案置信度比较。同时考查模型在医疗、法律等新领域上的泛化能力。对比单任务与多任务微调效果。

Result: 微调能提升模型的校准（置信度与准确率的一致性）与判别力（正确答案置信度高于错误答案），且这些提升可以泛化到新领域。但在任务间不可迁移：仅做单任务微调不能兼顾另一任务，唯有多任务微调才能在不同场景下都表达更好。

Conclusion: LLM表达不确定性的能力可通过训练提升，并具泛化性，但不同的元认知技能不会自然强化彼此，需采用多任务训练共同发展。

Abstract: Large language models (LLMs) are increasingly used in decision-making
contexts, but when they present answers without signaling low confidence, users
may unknowingly act on erroneous outputs. While prior work shows that LLMs
maintain internal uncertainty signals, their explicit verbalized confidence is
typically miscalibrated and poorly discriminates between correct and incorrect
answers. Across two types of LLMs, we investigate whether supervised finetuning
can improve models' ability to communicate uncertainty and whether such
improvements generalize across tasks and domains. We finetune the LLMs on
datasets spanning general knowledge, mathematics, and open-ended trivia, and
evaluate two metacognitive tasks: (1) single-question confidence estimation,
where the model assigns a numeric certainty to its answer, and (2) pairwise
confidence comparison, where the model selects which of two answers it is more
likely to have correct. We assess generalization to unseen domains, including
medical and legal reasoning. Results show that finetuning improves calibration
(alignment between stated confidence and accuracy) and discrimination (higher
confidence for correct vs. incorrect responses) within and across domains,
while leaving accuracy unchanged. However, improvements are task-specific:
training on single-question calibration does not transfer to pairwise
comparison, and vice versa. In contrast, multitask finetuning on both forms of
metacognition yields broader gains, producing lower calibration error and
stronger discrimination in out-of-domain evaluations. These results show that
while uncertainty communication in LLMs is trainable and generalizable,
different metacognitive skills do not naturally reinforce one another and must
be developed together through multitask training.

</details>


### [83] [Advancing Automated Spatio-Semantic Analysis in Picture Description Using Language Models](https://arxiv.org/abs/2510.05128)
*Si-Ioi Ng,Pranav S. Ambadi,Kimberly D. Mueller,Julie Liss,Visar Berisha*

Main category: cs.CL

TL;DR: 文章提出了一种基于BERT的自动化从图片描述语料中提取和排序内容信息单元（CIUs）的方法，显著提升了认知语言障碍评估的效率与准确性，并且成果已开源。


<details>
  <summary>Details</summary>
Motivation: 现有图片描述的认知障碍自动评估方法往往忽略了说话者描述内容的视觉叙事路径，且目前的空间语义特征分析需人工标注或基于词典映射，费时费力。

Method: 提出了一条基于BERT的流水线，通过二元交叉熵和对比排序损失微调模型，实现自动化从“偷饼干”图片描述中提取和排序CIUs。进行了5折交叉验证对模型效果进行评估。

Result: CIUs检测的精确率和召回率分别达到93%和96%的中位数，序列误差率为24%。自动提取的特征与人工标注结果高度相关，并优于基于词典的方法。在组间差异分析任务中，表现与人工标注特征相当。

Conclusion: 新模型能够有效自动化提取视觉叙事路径，有助于认知障碍的自动评估。代码和模型已开源，为相关研究与应用提供了便利。

Abstract: Current methods for automated assessment of cognitive-linguistic impairment
via picture description often neglect the visual narrative path - the sequence
and locations of elements a speaker described in the picture. Analyses of
spatio-semantic features capture this path using content information units
(CIUs), but manual tagging or dictionary-based mapping is labor-intensive. This
study proposes a BERT-based pipeline, fine tuned with binary cross-entropy and
pairwise ranking loss, for automated CIU extraction and ordering from the
Cookie Theft picture description. Evaluated by 5-fold cross-validation, it
achieves 93% median precision, 96% median recall in CIU detection, and 24%
sequence error rates. The proposed method extracts features that exhibit strong
Pearson correlations with ground truth, surpassing the dictionary-based
baseline in external validation. These features also perform comparably to
those derived from manual annotations in evaluating group differences via
ANCOVA. The pipeline is shown to effectively characterize visual narrative
paths for cognitive impairment assessment, with the implementation and models
open-sourced to public.

</details>


### [84] [Automated Alignment of Math Items to Content Standards in Large-Scale Assessments Using Language Models](https://arxiv.org/abs/2510.05129)
*Qingshu Xu,Hong Jiao,Tianyi Zhou,Ming Li,Nan Zhang,Sydney Peters,Yanbin Fu*

Main category: cs.CL

TL;DR: 本文比较多种自动化题目归类方法，发现基于预训练语言模型（如DeBERTa、RoBERTa）的效果最佳，集成模型未能超越单一最佳模型。


<details>
  <summary>Details</summary>
Motivation: 在大规模评测中，题目与内容标准的准确对应对于得分解释的有效性至关重要，然而传统人工对齐方法耗时且易受主观影响。因此，开发高效且准确的自动化对齐方法成为亟需解决的问题。

Method: 作者比较了三种自动化题目归类思路：（1）提取向量特征并训练多种传统监督学习模型，同时评估降维对模型性能的影响；（2）微调多种BERT及其变体以实现领域标签和技能标签的自动对齐；（3）应用集成学习，包括多数投票和堆叠多元元模型。

Result: DeBERTa-v3-base在领域（domain）标签对齐中取得了最高的加权F1分数0.950，而RoBERTa-large在技能（skill）标签对齐中F1达到0.869。集成模型效果未超过最佳的单一语言模型。降维对传统线性分类器有效，但仍不及预训练语言模型表现。

Conclusion: 预训练大型语言模型在自动题目与标准对齐任务中效果突出，优于传统及集成方法。本文为大规模智能化试题分析和管理提供了有力技术支持。

Abstract: Accurate alignment of items to content standards is critical for valid score
interpretation in large-scale assessments. This study evaluates three automated
paradigms for aligning items with four domain and nineteen skill labels. First,
we extracted embeddings and trained multiple classical supervised machine
learning models, and further investigated the impact of dimensionality
reduction on model performance. Second, we fine-tuned eight BERT model and its
variants for both domain and skill alignment. Third, we explored ensemble
learning with majority voting and stacking with multiple meta-models. The
DeBERTa-v3-base achieved the highest weighted-average F1 score of 0.950 for
domain alignment while the RoBERTa-large yielded the highest F1 score of 0.869
for skill alignment. Ensemble models did not surpass the best-performing
language models. Dimension reduction enhanced linear classifiers based on
embeddings but did not perform better than language models. This study
demonstrated different methods in automated item alignment to content
standards.}

</details>


### [85] [Submodular Context Partitioning and Compression for In-Context Learning-short paper](https://arxiv.org/abs/2510.05130)
*Shaoyi Zheng,Canyu Zhang,Tianyi Zhou,Shengjie Wang*

Main category: cs.CL

TL;DR: 本文提出了一种新的块感知上下文选择框架Sub-CP，有效提升了大语言模型在ICL任务中的性能。该方法通过子模目标控制块的多样性，实现更灵活的上下文分块和性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型ICL（In-context learning）方法受限于变换器的输入复杂度，只能用较少示例训练，而现有高效ICL方案常忽略分块带来的信息冗余或表示不足，限制了性能提升。

Method: 提出Sub-CP框架，利用子模（submodular）目标函数来调控分块上下文的多样性。Sub-CP可以灵活选择策略，使每个块在全局多样性和局部连贯性之间自由切换，实现了对语义结构的精细控制并可预计算。

Result: 在多个数据集和多种任务、不同规模模型上做了大量实验，Sub-CP都带来了显著、持续的性能提升。

Conclusion: Sub-CP为ICL中的上下文选择提供了新颖、有效的解决方案，通过块多样性控制增强了模型表现，对大模型应用有重要实际意义。

Abstract: In-context learning (ICL) enables efficient few-shot learning in large
language models (LLMs) without training, but suffers from the quadratic input
complexity of transformers, limiting the maximum number of exemplars. While
various efficient ICL approaches partition the context into blocks to process
(e.g., ensembling, compression, cross-attention), they often ignore the
information redundancy or under-representation caused by different partition
strategies, leading to suboptimal performance. To tackle this problem, we
propose Sub-CP, a block-aware context selection framework that leverages
submodular objectives to control block diversity. Sub-CP supports a flexible
spectrum of selection strategies, allowing each block to range from globally
diverse to locally coherent. This allows fine-grained control over semantic
structure while enabling precomputation. Extensive experiments across diverse
tasks on multiple datasets show that Sub-CP consistently improves performance
across model scales.

</details>


### [86] [Rationale-Augmented Retrieval with Constrained LLM Re-Ranking for Task Discovery](https://arxiv.org/abs/2510.05131)
*Bowen Wei*

Main category: cs.CL

TL;DR: 本文针对Head Start项目在使用GoEngage平台检索任务（Task）模块时面临的检索准确性、效率以及术语多样性等挑战，提出了一种融合多种搜索策略的混合语义检索系统。该系统结合了容错型词法搜索、基于向量的语义相似度计算以及受限的大语言模型重排序，从技术和实践层面系统性提升搜索体验。


<details>
  <summary>Details</summary>
Motivation: 现有系统检索依赖词法匹配，难以处理领域专有术语、拼写错误和词序变化，尤其在人员流动或新员工加入时影响任务查找效率与准确率。因此，亟需一种兼具容错性、可扩展性和经济性的智能检索方案。

Method: 方法为混合检索：首先利用轻量级、容错性的词法检索生成候选集，其次通过词嵌入计算语义相似度进行精细筛选，最后采用受限的大语言模型对候选结果进行重排序。系统设计兼顾现有知识库与任务库的集成，智能缓存与分阶段部署，同时设定了线下（命中率、精确率、召回率、MRR等）和线上（查询成功率、零结果率、停留时间等）评估策略。

Result: 提出了一套详细的实施框架、资源需求、分阶段里程碑，以及评测协议，并结合真实案例制定了完善的测试与数据采集方法，预期显著提升检索相关性和使用体验。

Conclusion: 所提混合语义检索系统可显著提升任务检索的准确率、适应性和经济性，为Head Start等领域存在专业术语壁垒和用户基础复杂的检索场景提供了切实可行的解决方案。

Abstract: Head Start programs utilizing GoEngage face significant challenges when new
or rotating staff attempt to locate appropriate Tasks (modules) on the platform
homepage. These difficulties arise from domain-specific jargon (e.g., IFPA,
DRDP), system-specific nomenclature (e.g., Application Pool), and the inherent
limitations of lexical search in handling typos and varied word ordering. We
propose a pragmatic hybrid semantic search system that synergistically combines
lightweight typo-tolerant lexical retrieval, embedding-based vector similarity,
and constrained large language model (LLM) re-ranking. Our approach leverages
the organization's existing Task Repository and Knowledge Base infrastructure
while ensuring trustworthiness through low false-positive rates, evolvability
to accommodate terminological changes, and economic efficiency via intelligent
caching, shortlist generation, and graceful degradation mechanisms. We provide
a comprehensive framework detailing required resources, a phased implementation
strategy with concrete milestones, an offline evaluation protocol utilizing
curated test cases (Hit@K, Precision@K, Recall@K, MRR), and an online
measurement methodology incorporating query success metrics, zero-result rates,
and dwell-time proxies.

</details>


### [87] [Training Large Language Models To Reason In Parallel With Global Forking Tokens](https://arxiv.org/abs/2510.05132)
*Sheng Jia,Xiao Wang,Shiva Prasad Kasiviswanathan*

Main category: cs.CL

TL;DR: 本文提出了一种新的大模型监督微调方法（Set Supervised Fine-Tuning, SSFT），用来提升模型在推理类任务中多样性和精确性的平衡。实验理论和实证结果均表明新方法优于传统微调。


<details>
  <summary>Details</summary>
Motivation: 现有大模型通过并行推理提高性能时，常依赖生成既多样又精确的推理路径。然而，能产生多样推理模式的关键节点（forking tokens）通常在采样树较深处，常规鼓励多样性的策略如温度调整，会导致多样性与准确率难以兼顾。为破解这一难题，作者寻求新的训练方法以更好保留和捕捉多样又准确的推理路径。

Method: 作者将推理并行视为“下一个token集合预测”问题，提出在监督微调（SFT）中引入基于集合的全局损失，并通过自监督的二分匹配将全局关键分叉token与不同推理轨迹进行匹配。该方法称为Set Supervised Fine-Tuning（SSFT）。

Result: 实验在多个推理基准数据集上进行，SSFT在Pass@1和Cons@k等主流指标下均优于传统的SFT方法。

Conclusion: SSFT方法能够更好地保留模型的多样化推理能力，实现多样性和准确性更优平衡，为大模型推理任务微调开辟了新路径。

Abstract: Although LLMs have demonstrated improved performance by scaling parallel
test-time compute, doing so relies on generating reasoning paths that are both
diverse and accurate. For challenging problems, the forking tokens that trigger
diverse yet correct reasoning modes are typically deep in the sampling tree.
Consequently, common strategies to encourage diversity, such as temperature
scaling, encounter a worsened trade-off between diversity and accuracy.
Motivated by this challenge, we treat parallel reasoning as a
set-of-next-token-prediction problem, and incorporate a set-based global loss
into Supervised Fine-Tuning (SFT) using self-supervised bipartite matching
between our global forking tokens and unique reasoning traces. We observe that,
while naive fine-tuning with multiple reasoning traces collapses these unique
reasoning modes, our proposed method, Set Supervised Fine-Tuning (SSFT),
preserves these modes and produces emergent global forking tokens. Experiments
on multiple reasoning benchmarks show that our SSFT consistently outperforms
SFT under both Pass@1 and Cons@k metrics.

</details>


### [88] [Characterizing Model Behavior Under Synthetic Data Training: An Empirical Study Across Scales and Mixing Ratios](https://arxiv.org/abs/2510.05133)
*Y. Du,G. Wu,G. Tang,W. Wang,Q. Fan*

Main category: cs.CL

TL;DR: 本文系统性研究了大语言模型训练中合成数据比例对模型表现的影响，阐明了在一定比例内使用合成数据是安全且有效的。


<details>
  <summary>Details</summary>
Motivation: 合成数据在NLP模型训练中应用广泛，但目前对合成数据比例如何影响模型性能的系统性理解有限。

Method: 采用Pythia模型套件（参数410M-12B），在五种任务下，对模型在一至三轮训练及合成数据占总数据0-50%的情况下进行对比实验，分析性能、校准及输出特性。

Result: 主要结果为：20%以内合成数据模型表现稳定，30%以上性能下降加速；大模型对合成数据更鲁棒；模型的校准能力在准确率下降前先受影响，可用作预警；推理类任务对合成数据更敏感。

Conclusion: 符合当前最佳实践（如STaR和Self-Instruct等保持80%以上外部数据）使用习惯，并为实际工作中模型规模、任务需求下的合成数据预算提供了指导建议。

Abstract: Synthetic data generated by large language models has become integral to
modern NLP training pipelines, from bootstrapping reasoning capabilities to
augmenting instruction-following datasets. While recent work demonstrates
successful applications maintaining high external data ratios, systematic
understanding of how synthetic data proportion affects model behavior across
different scales remains limited. This paper presents a controlled empirical
study examining model performance, calibration, and output characteristics when
trained on varying synthetic-to-external data ratios. Using the Pythia model
suite (410M-12B parameters) across five diverse tasks, we evaluate models after
one to three training iterations with synthetic data proportions ranging from
0-50\%. Our key findings include: models maintain stable performance with up to
20\% synthetic data, but degradation accelerates beyond 30\%; larger models
(6.9B-12B) show greater robustness to synthetic data than smaller models
(410M-1.4B); calibration degradation precedes accuracy loss, providing an early
warning signal; and task characteristics matter, with reasoning tasks degrading
faster than retrieval tasks under synthetic data training. Importantly, we find
that current best practices, such as those employed in STaR and Self-Instruct
systems that maintain greater than 80\% external data, operate well within safe
regimes identified by our experiments. We provide practical guidance for
practitioners on synthetic data budgets based on model scale and task
requirements, alongside detailed comparison with concurrent work including
Shumailov et al.'s model collapse findings.

</details>


### [89] [Curiosity-Driven LLM-as-a-judge for Personalized Creative Judgment](https://arxiv.org/abs/2510.05135)
*Vanya Bannihatti Kumar,Divyanshu Goyal,Akhil Eppa,Neel Bhandari*

Main category: cs.CL

TL;DR: 本文提出了一种基于好奇心驱动的大语言模型(LLM)判官，用于个性化评估创造性写作，并在创造力主观性评价任务上优于传统微调方法。


<details>
  <summary>Details</summary>
Motivation: 虽然大模型在客观任务上表现出色，但在评估主观性的、个性化的如创造力等方面仍然不足。现有评判机制难以捕捉个人创造判断的细微差别，尤其在评审意见不一致时。作者希望提升模型在主观创造力评估上的能力。

Method: 作者提出了一种好奇心驱动的LLM判官方法，使模型能够根据每个人的创造力判断进行个性化调优。以TTCW基准数据集（含专家多维主观标注）进行训练，并与传统监督微调(SFT)进行了对比。

Result: 实验表明，所提方法在多个评价指标（皮尔逊相关系数、Cohen一致性、F1值等）上超越了基线的SFT方法，且适用于注释者意见不一致的主观评测场景。

Conclusion: 该方法能让不同规模的模型更好地适应不同个体对创造力的判断，有助于提升LLM在主观、创造性写作评估中的实用性。

Abstract: Modern large language models (LLMs) excel at objective tasks such as
evaluating mathematical reasoning and factual accuracy, yet they falter when
faced with the nuanced, subjective nature of assessing creativity. In this
work, we propose a novel curiosity-driven LLM-as-a-judge for evaluating
creative writing which is personlized to each individual's creative judgments.
We use the Torrance Test of Creative Thinking(TTCW) benchmark introduced in
Chakrabarty et al. (2024), which has stories annotated by expert humans across
various subjective dimensions like Originality, to test our hypothesis. We show
that our method enables models across various sizes, to learn the nuanced
creative judgments of different individuals, by showing improvements over
baseline supervised finetuning(SFT) method across various evaluation metrics
like Pearson correlation, Cohen's and F1 values. Our method is especially
useful in subjective evaluations where not all the annotators agree with each
other.

</details>


### [90] [Linguistic Characteristics of AI-Generated Text: A Survey](https://arxiv.org/abs/2510.05136)
*Luka Terčon,Kaja Dobrovoljc*

Main category: cs.CL

TL;DR: 本文系统综述了当前关于大语言模型（LLMs）生成文本语言特征的研究进展，总结了主要发现与趋势，并指出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 由于LLMs生成文本在各个领域的广泛应用，其语言特征对语言学、自然语言处理等多个学科产生深远影响，因此有必要对以往研究进行系统总结与整合，推动该领域进一步发展。

Method: 本文采用文献综述方法，将现有研究按语言层级、所用模型、分析文本体裁、语言种类和提示方式等多个维度进行分类和综合分析，并总结主流研究发现且梳理研究趋势。

Result: 现有研究普遍发现AI生成文本更偏正式和客观，名词、限定词和介词更多，而形容词和副词使用更少；词汇多样性、词汇量较低，文本更重复。研究主要集中在英文和GPT模型，跨语言、跨模型研究较少，对提示词敏感性关注不足。

Conclusion: 本文填补了AI生成文本语言特征研究的系统整合空白，指出未来应加强对多语言、多模型和多提示方式的广泛实证研究。

Abstract: Large language models (LLMs) are solidifying their position in the modern
world as effective tools for the automatic generation of text. Their use is
quickly becoming commonplace in fields such as education, healthcare, and
scientific research. There is a growing need to study the linguistic features
present in AI-generated text, as the increasing presence of such texts has
profound implications in various disciplines such as corpus linguistics,
computational linguistics, and natural language processing. Many observations
have already been made, however a broader synthesis of the findings made so far
is required to provide a better understanding of the topic. The present survey
paper aims to provide such a synthesis of extant research. We categorize the
existing works along several dimensions, including the levels of linguistic
description, the models included, the genres analyzed, the languages analyzed,
and the approach to prompting. Additionally, the same scheme is used to present
the findings made so far and expose the current trends followed by researchers.
Among the most-often reported findings is the observation that AI-generated
text is more likely to contain a more formal and impersonal style, signaled by
the increased presence of nouns, determiners, and adpositions and the lower
reliance on adjectives and adverbs. AI-generated text is also more likely to
feature a lower lexical diversity, a smaller vocabulary size, and repetitive
text. Current research, however, remains heavily concentrated on English data
and mostly on text generated by the GPT model family, highlighting the need for
broader cross-linguistic and cross-model investigation. In most cases authors
also fail to address the issue of prompt sensitivity, leaving much room for
future studies that employ multiple prompt wordings in the text generation
phase.

</details>


### [91] [Demystifying deep search: a holistic evaluation with hint-free multi-hop questions and factorised metrics](https://arxiv.org/abs/2510.05137)
*Maojia Song,Renhang Liu,Xinyu Wang,Yong Jiang,Pengjun Xie,Fei Huang,Soujanya Poria,Jingren Zhou*

Main category: cs.CL

TL;DR: 本文提出了WebDetective基准，专为评测RAG系统和Web智能体在无提示多跳推理任务下的真实能力，发现当前模型在知识利用和合理拒答方面存在显著不足，并通过新的agent工作流设计提出改进方法。


<details>
  <summary>Details</summary>
Motivation: 现有多跳检索和推理评测存在两大主要局限：一是评测数据常泄露推理路径，模型可以只依赖表面线索而非真正自发地构建推理链；二是评测方式单一，将多样化模型表现压缩成单分数，无法区分具体失败原因。

Method: 作者提出WebDetective基准，设计无路径提示的多跳问题，并配套维基百科沙盒以完全追踪模型行为，构建评价体系分别衡量“检索充分性”、“知识利用”和“合理拒答”。实验对25个主流模型逐一评估并分析表现缺陷，并提出新的agentic工作流EvidenceLoop，专门引入证据验证和记录机制，提高推理与合成能力。

Result: 实验发现，当前各类架构的模型在有足够证据情况下依然难以正确利用知识，且在缺乏证据时几乎不会合理拒绝作答，主要擅长沿用给定推理路径，难以独立发现推理链。EvidenceLoop改进了模型的检索和知识合成能力，显示该基准对持续提升系统能力有指导价值。

Conclusion: WebDetective为真实评估与分析RAG系统能力提供了细致工具，有助设计能自主推理而非单靠模式识别的智能体。其新评价框架和方法可有效促进模型架构的目标性改进，是推动自主推理研究的重要基准。

Abstract: RAG (Retrieval-Augmented Generation) systems and web agents are increasingly
evaluated on multi-hop deep search tasks, yet current practice suffers from two
major limitations. First, most benchmarks leak the reasoning path in the
question text, allowing models to follow surface cues rather than discover
reasoning chains autonomously. Second, evaluation is typically reduced to a
single pass rate, which collapses diverse behaviours into one score and
obscures whether failures stem from inadequate search, poor knowledge use, or
inappropriate refusal. To address these issues, we present WebDetective, a
benchmark of hint-free multi-hop questions paired with a controlled Wikipedia
sandbox that ensures full traceability of model actions, and a holistic
evaluation framework that separates search sufficiency, knowledge utilisation,
and refusal behaviour. Our evaluation of 25 state-of-the-art models reveals
systematic weaknesses across all architectures: models struggle with knowledge
utilisation despite having sufficient evidence and demonstrate near-absent
appropriate refusal when evidence is lacking. These patterns expose a
fundamental gap: today's systems excel at executing given reasoning paths but
fail when required to discover them. We develop an agentic workflow,
EvidenceLoop, that explicitly targets the challenges our benchmark identifies,
incorporating verification loops and systematic evidence tracking that improve
both search and synthesis capabilities. This baseline demonstrates that
WebDetective's diagnostic framework can guide concrete architectural
improvements, establishing our benchmark as a critical tool for developing
genuinely autonomous reasoning systems rather than pattern-following agents.

</details>


### [92] [LiRA: A Multi-Agent Framework for Reliable and Readable Literature Review Generation](https://arxiv.org/abs/2510.05138)
*Gregory Hok Tjoan Go,Khang Ly,Anders Søgaard,Amin Tabatabaei,Maarten de Rijke,Xinyi Chen*

Main category: cs.CL

TL;DR: 本文提出了一种多智能体协作系统LiRA，能自动生成高质量、结构化且准确的综述类科学文章，并在多个基准上超过现有自动化方法。


<details>
  <summary>Details</summary>
Motivation: 随着科学文献数量剧增，传统人工文献综述难以全面跟进，新方法大多仅聚焦于检索与筛选，综述撰写尚未得到有效自动化。该研究旨在提升科学综述自动写作的可读性与准确性。

Method: 提出LiRA系统，采用多代理协作（包括内容大纲规划、分小节写作、编辑和审稿等各环节专业代理），协同生成结构化、连贯的综述文章；实验中分别用SciReviewGen和ScienceDirect数据集进行评测。

Result: LiRA在写作质量和引用准确性上明显优于现有基线（如AutoSurvey和MASS-Survey），在与人工综述相似度上也有竞争力。此外，也证实了该系统对审稿代理模型变化的鲁棒性。

Conclusion: 多智能体LLM协作系统（如LiRA）即使未针对特定领域微调，也能显著提升科学自动写作的可靠性和实用性，有望改善和推广科研综述的自动化流程。

Abstract: The rapid growth of scientific publications has made it increasingly
difficult to keep literature reviews comprehensive and up-to-date. Though prior
work has focused on automating retrieval and screening, the writing phase of
systematic reviews remains largely under-explored, especially with regard to
readability and factual accuracy. To address this, we present LiRA (Literature
Review Agents), a multi-agent collaborative workflow which emulates the human
literature review process. LiRA utilizes specialized agents for content
outlining, subsection writing, editing, and reviewing, producing cohesive and
comprehensive review articles. Evaluated on SciReviewGen and a proprietary
ScienceDirect dataset, LiRA outperforms current baselines such as AutoSurvey
and MASS-Survey in writing and citation quality, while maintaining competitive
similarity to human-written reviews. We further evaluate LiRA in real-world
scenarios using document retrieval and assess its robustness to reviewer model
variation. Our findings highlight the potential of agentic LLM workflows, even
without domain-specific tuning, to improve the reliability and usability of
automated scientific writing.

</details>


### [93] [NLD-LLM: A systematic framework for evaluating small language transformer models on natural language description](https://arxiv.org/abs/2510.05139)
*Hamed Jelodar,Mohammad Meymani,Parisa Hamedi,Tochukwu Emmanuel Nwankwo,Samita Bai,Roozbeh Razavi-Far,Ali A. Ghorbani*

Main category: cs.CL

TL;DR: 本文提出了NLD-LLM框架，系统评估不同语言模型在自动生成源代码描述任务上的表现，并发现通过精细化提示工程，小型模型表现可与大型模型媲美。


<details>
  <summary>Details</summary>
Motivation: 随着大模型和编程辅助生成工具的发展，如何让自然语言处理模型更好地理解和描述源代码成为关键任务。现有对源代码生成或描述的评价方法不一，缺乏统一、系统性的对比框架，因此亟需完善的评测体系。

Method: 作者提出NLD-LLM评测框架，集成并对比多个主流Transformer大模型（如Qwen、DeepSeek、Phi、LLaMA、Mistral），采用标准化格式、明确任务指导和专门的提示工程策略。引入迭代优化方法提升生成结果，并通过多种语义和结构指标对输出进行定量分析。

Result: 实验证明，通过精确和系统的Prompt设计，小型模型在自然语言描述任务上的表现与大型模型相当。提示工程对模型生成代码描述的有效性提升尤为明显。

Conclusion: 提示工程可极大提升语言模型生成源码描述的质量。即便是小模型，只要设计合适提示，也能实现与大模型类似的表现，对模型高效利用和轻量部署具有重要意义。

Abstract: Natural Language Description (NLD) is a Natural Language Processing (NLP)
task that requires models to generate structured and meaningful outputs from
natural language inputs. In this work, we propose NLD-LLM, a systematic NLP
framework to evaluate the performance of language models to generate accurate
and concise source code descriptions. This framework incorporates a diverse set
of transformer models, including Qwen, DeepSeek, Phi, LLaMA, and Mistral,
spanning various sizes, architectures, and training approaches. Central to
NLD-LLM is a comprehensive prompt design strategy that includes standardized
formatting, clear task guidance, and NLD prompting, ensuring fair and
consistent evaluation. Additionally, we apply an iterative refinement process
to improve output's quality and assess the model's adaptability. Using semantic
and structural metrics, our analysis demonstrates that prompt engineering
significantly impacts the effectiveness of the model such that smaller models
often performing competitively when supported by well-crafted prompts.

</details>


### [94] [To model human linguistic prediction, make LLMs less superhuman](https://arxiv.org/abs/2510.05141)
*Byung-Doh Oh,Tal Linzen*

Main category: cs.CL

TL;DR: 当前的大型语言模型（LLMs）预测下一个词的能力已超过人类，但这导致其在人类语言理解建模上的预测能力反而下降。作者认为关键原因在于LLMs拥有比人类更强的长、短时记忆。为此，作者提出需要开发拥有类似人类记忆机制的模型，并补充更符合目标的人类实验数据。


<details>
  <summary>Details</summary>
Motivation: 近年来，大型语言模型在预测下一个单词的性能大幅提升。虽然这类模型被用作人类语言预测的认知模型，但它们与人类阅读行为之间的偏差正在加大。作者关注为何LLMs在拟合人类阅读行为时性能下降，并提出需要理解其“超人类”表现背后的原因。

Method: 本论文属于立场性（position paper），主要通过理论分析和现象总结，探讨LLMs记忆机制与人类的区别，并归纳出内在核心问题。论文中还提出通过改进模型的记忆结构及设计针对性的人类实验进行补充。

Result: 论文指出了导致LLMs在建模人类语言理解时偏离人类行为的两个核心原因：强大的事实性和例子记忆（长时记忆）以及卓越的短时文本记忆。同时，作者提出目前人类实验数据不足以精确衡量这一偏差。

Conclusion: 要让语言模型更好地模拟人类语言理解，未来需要开发拥有类似人类记忆范围和机制的模型，同时加强针对性的行为实验采集和测量。

Abstract: When people listen to or read a sentence, they actively make predictions
about upcoming words: words that are less predictable are generally read more
slowly than predictable ones. The success of large language models (LLMs),
which, like humans, make predictions about upcoming words, has motivated
exploring the use of these models as cognitive models of human linguistic
prediction. Surprisingly, in the last few years, as language models have become
better at predicting the next word, their ability to predict human reading
behavior has declined. This is because LLMs are able to predict upcoming words
much better than people can, leading them to predict lower processing
difficulty in reading than observed in human experiments; in other words,
mainstream LLMs are 'superhuman' as models of language comprehension. In this
position paper, we argue that LLMs' superhumanness is primarily driven by two
factors: compared to humans, LLMs have much stronger long-term memory for facts
and training examples, and they have much better short-term memory for previous
words in the text. We advocate for creating models that have human-like
long-term and short-term memory, and outline some possible directions for
achieving this goal. Finally, we argue that currently available human data is
insufficient to measure progress towards this goal, and outline human
experiments that can address this gap.

</details>


### [95] [Reliable End-to-End Material Information Extraction from the Literature with Source-Tracked Multi-Stage Large Language Models](https://arxiv.org/abs/2510.05142)
*Xin Wang,Anshu Raj,Matthew Luebbe,Haiming Wen,Shuozhi Xu,Kun Lu*

Main category: cs.CL

TL;DR: 本文提出了一种多阶段信息抽取流程，利用大语言模型从实验材料文献中高效且全面地提取组成、工艺、微结构及性能等47项特征，有效推动大规模数据驱动的材料发现。


<details>
  <summary>Details</summary>
Motivation: 当前材料科学极需大规模实验数据支持，但大部分信息散见于非结构化文献中，且现有抽取工作通常仅关注部分特征，难以构建体现组成-工艺-微结构-性能四要素关系的完备数据库，这成为材料行为理解和加速研发的瓶颈。

Method: 作者设计了基于大语言模型的多阶段抽取流程，覆盖47个特征，集成迭代抽取与文献溯源机制提升精度和可靠性，并通过特征层面和tuple层面进行评价。

Result: 该方法在特征和tuple层面F1分数均达到0.96左右，相比无溯源的单步抽取流程，微结构类别抽取F1分数分别提升10.0%（特征层面）与13.7%（tuple层面），在100篇涉及396种材料的文献中，漏检材料数从49减少至13，漏检率降至3.3%。

Conclusion: 本文流程支持高精度、低漏检、零误判地批量挖掘材料文献信息，为信息学和机器学习提供可靠数据输入，具备高度通用性，有望全面促进不同材料体系信息的结构化和知识发现。

Abstract: Data-driven materials discovery requires large-scale experimental datasets,
yet most of the information remains trapped in unstructured literature.
Existing extraction efforts often focus on a limited set of features and have
not addressed the integrated composition-processing-microstructure-property
relationships essential for understanding materials behavior, thereby posing
challenges for building comprehensive databases. To address this gap, we
propose a multi-stage information extraction pipeline powered by large language
models, which captures 47 features spanning composition, processing,
microstructure, and properties exclusively from experimentally reported
materials. The pipeline integrates iterative extraction with source tracking to
enhance both accuracy and reliability. Evaluations at the feature level
(independent attributes) and tuple level (interdependent features) yielded F1
scores around 0.96. Compared with single-pass extraction without source
tracking, our approach improved F1 scores of microstructure category by 10.0%
(feature level) and 13.7% (tuple level), and reduced missed materials from 49
to 13 out of 396 materials in 100 articles on precipitate-containing
multi-principal element alloys (miss rate reduced from 12.4% to 3.3%). The
pipeline enables scalable and efficient literature mining, producing databases
with high precision, minimal omissions, and zero false positives. These
datasets provide trustworthy inputs for machine learning and materials
informatics, while the modular design generalizes to diverse material classes,
enabling comprehensive materials information extraction.

</details>


### [96] [SynCED-EnDe 2025: A Synthetic and Curated English - German Dataset for Critical Error Detection in Machine Translation](https://arxiv.org/abs/2510.05144)
*Muskaan Chopra,Lorenz Sparrenberg,Rafet Sifa*

Main category: cs.CL

TL;DR: 论文提出了SynCED-EnDe数据集，专注于检测机器翻译中的严重错误，并在标签平衡、错误类型和数据新鲜度等方面显著提升，显著优于WMT21标准。


<details>
  <summary>Details</summary>
Motivation: 现有的WMT21英德机器翻译关键错误检测数据集在规模、标签平衡、领域覆盖和时效性上存在明显局限，无法满足细致、系统分析和实际应用的需要。

Method: 作者构建了全新的SynCED-EnDe数据集，包括1000个人工标注（gold-labeled）和8000个机器预标注（silver-labeled）句对，错误与非错误样本均衡，并从多个2024-2025的多样数据源（如StackExchange和GOV.UK）采集。同时新增了具体错误类别、结构化触发标记、以及多个细粒度辅助判断指标（如错误明显性、严重性等），使得分析更为系统和深入。

Result: 基于XLM-R等编码器进行的基线实验显示，由于标签更加均衡、注释细致，SynCED-EnDe在检测性能上相较WMT21有显著提升。同时数据集支持更复杂的错误风险及难度分析。

Conclusion: SynCED-EnDe数据集作为可公开获取的社区资源，不仅提升了MT关键错误检测能力，还促进了信息检索和对话助手等新兴应用场景中机器翻译的安全部署。

Abstract: Critical Error Detection (CED) in machine translation aims to determine
whether a translation is safe to use or contains unacceptable deviations in
meaning. While the WMT21 English-German CED dataset provided the first
benchmark, it is limited in scale, label balance, domain coverage, and temporal
freshness. We present SynCED-EnDe, a new resource consisting of 1,000
gold-labeled and 8,000 silver-labeled sentence pairs, balanced 50/50 between
error and non-error cases. SynCED-EnDe draws from diverse 2024-2025 sources
(StackExchange, GOV.UK) and introduces explicit error subclasses, structured
trigger flags, and fine-grained auxiliary judgments (obviousness, severity,
localization complexity, contextual dependency, adequacy deviation). These
enrichments enable systematic analyses of error risk and intricacy beyond
binary detection. The dataset is permanently hosted on GitHub and Hugging Face,
accompanied by documentation, annotation guidelines, and baseline scripts.
Benchmark experiments with XLM-R and related encoders show substantial
performance gains over WMT21 due to balanced labels and refined annotations. We
envision SynCED-EnDe as a community resource to advance safe deployment of MT
in information retrieval and conversational assistants, particularly in
emerging contexts such as wearable AI devices.

</details>


### [97] [Every Step Counts: Decoding Trajectories as Authorship Fingerprints of dLLMs](https://arxiv.org/abs/2510.05148)
*Qi Li,Runpeng Yu,Haiquan Lu,Xinchao Wang*

Main category: cs.CL

TL;DR: 本文提出了基于离散扩散语言模型（dLLMs）的模型归因新方法，利用其独特的解码机制显著提升归因准确性，并通过实验验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着dLLMs在推理速度和任务表现上的优势显现，模型溯源（归因）变得更具挑战性：不仅要区分不同模型，还需区分同一模型的不同备份或checkpoint，因此需要新的、高效的归因方法。

Method: 作者首先发现直接依赖每步的模型置信度效果较差，主要因为双向解码导致置信度冗余。为此，提出了『Directed Decoding Map（DDM）』，用于捕捉解码步骤之间的结构关系。此外，提出了『Gaussian-Trajectory Attribution（GTA）』，在每个解码位置对每个目标模型拟合高斯分布，利用轨迹在分布下的似然得分作为归因依据。

Result: 实验证明：所提DDM和GTA方法在多个场景下均能有效提升模型归因的准确率，优于直接使用置信度等传统归因手段。

Conclusion: dLLMs的新解码机制不仅提升了模型实用性，也为模型归因提供了强大工具。DDM和GTA方法能够抓取模型特有的解码结构，适用于区分不同模型或同一模型不同checkpoint，为模型溯源提供了更精确手段。

Abstract: Discrete Diffusion Large Language Models (dLLMs) have recently emerged as a
competitive paradigm for non-autoregressive language modeling. Their
distinctive decoding mechanism enables faster inference speed and strong
performance in code generation and mathematical tasks. In this work, we show
that the decoding mechanism of dLLMs not only enhances model utility but also
can be used as a powerful tool for model attribution. A key challenge in this
problem lies in the diversity of attribution scenarios, including
distinguishing between different models as well as between different
checkpoints or backups of the same model. To ensure broad applicability, we
identify two fundamental problems: what information to extract from the
decoding trajectory, and how to utilize it effectively. We first observe that
relying directly on per-step model confidence yields poor performance. This is
mainly due to the bidirectional decoding nature of dLLMs: each newly decoded
token influences the confidence of other decoded tokens, making model
confidence highly redundant and washing out structural signal regarding
decoding order or dependencies. To overcome this, we propose a novel
information extraction scheme called the Directed Decoding Map (DDM), which
captures structural relationships between decoding steps and better reveals
model-specific behaviors. Furthermore, to make full use of the extracted
structural information during attribution, we propose Gaussian-Trajectory
Attribution (GTA), where we fit a cell-wise Gaussian distribution at each
decoding position for each target model, and define the likelihood of a
trajectory as the attribution score: if a trajectory exhibits higher
log-likelihood under the distribution of a specific model, it is more likely to
have been generated by that model. Extensive experiments under different
settings validate the utility of our methods.

</details>


### [98] [Chronological Thinking in Full-Duplex Spoken Dialogue Language Models](https://arxiv.org/abs/2510.05150)
*Donghang Wu,Haoyang Zhang,Chen Chen,Tianyu Zhang,Fei Tian,Xuerui Yang,Gang Yu,Hexin Liu,Nana Hou,Yuchen Hu,Eng Siong Chng*

Main category: cs.CL

TL;DR: 本论文提出了Chronological Thinking（时序思考）机制，用于提升全双工语音对话系统中模型响应质量。该机制让模型在监听用户发言时就进行推理和思考，从而减少响应延迟并显著提升对话体验。实验结果显示，时序思考在客观指标和主观评估上都优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有全双工语音对话模型在监听阶段通常只有『等待』或输出『静音』动作，与人类在对话中会同时思考的模式不符，导致响应质量和自然度不足。因此，作者受到人类交谈行为的启发，提出在监听中进行即时推理和思考，以提升系统性能。

Method: 作者设计了Chronological Thinking机制，实现了模型在接收语音流的同时进行因果、递增的推理，期间只利用已经输入的音频数据（严格因果），且推理过程和监听重叠，无引入额外延迟。这样的设计保证了思考与输入同步，并在用户说完后能迅速作出反馈。

Result: 实验表明，采用Chronological Thinking的系统在自动指标和人工评价中，响应的自然性与质量均有提升；同时在全双工对话的动态场景中表现更为稳健，相关评测分数达到了先进水平。

Conclusion: Chronological Thinking为全双工语音对话系统引入了类人思考流程，明显提升了互动中的效率和响应质量，证明这一机制对未来实时对话AI系统具有实际应用价值。

Abstract: Recent advances in spoken dialogue language models (SDLMs) reflect growing
interest in shifting from turn-based to full-duplex systems, where the models
continuously perceive user speech streams while generating responses. This
simultaneous listening and speaking design enables real-time interaction and
the agent can handle dynamic conversational behaviors like user barge-in.
However, during the listening phase, existing systems keep the agent idle by
repeatedly predicting the silence token, which departs from human behavior: we
usually engage in lightweight thinking during conversation rather than
remaining absent-minded. Inspired by this, we propose Chronological Thinking, a
on-the-fly conversational thinking mechanism that aims to improve response
quality in full-duplex SDLMs. Specifically, chronological thinking presents a
paradigm shift from conventional LLM thinking approaches, such as
Chain-of-Thought, purpose-built for streaming acoustic input. (1) Strictly
causal: the agent reasons incrementally while listening, updating internal
hypotheses only from past audio with no lookahead. (2) No additional latency:
reasoning is amortized during the listening window; once the user stops
speaking, the agent halts thinking and begins speaking without further delay.
Experiments demonstrate the effectiveness of chronological thinking through
both objective metrics and human evaluations show consistent improvements in
response quality. Furthermore, chronological thinking robustly handles
conversational dynamics and attains competitive performance on full-duplex
interaction metrics.

</details>


### [99] [Exploring Large Language Models for Financial Applications: Techniques, Performance, and Challenges with FinMA](https://arxiv.org/abs/2510.05151)
*Prudence Djagba,Abdelkader Y. Saley*

Main category: cs.CL

TL;DR: 本文分析了FinMA金融领域大模型在金融自然语言处理任务中的表现，揭示其在情感分析和分类上具有优势，但在数值推理、实体识别和摘要方面存在挑战。


<details>
  <summary>Details</summary>
Motivation: 金融领域对高准确性和可靠性有极高要求，传统LLM难以完全满足金融行业的专业需求，因此需开发并评估适用于金融领域的定制化LLM。

Method: 以FINMA（基于PIXIU框架的金融大模型）为研究对象，分析其模型架构，采用Financial Instruction Tuning（FIT）数据集进行指令微调，并在FLARE基准下进行各种金融任务评测。

Result: FinMA在情感分析和分类任务上表现出色，而在数值推理、实体识别及摘要任务上存在明显不足。

Conclusion: 金融领域LLM定制需针对数值推理等薄弱环节持续优化，推动更精确可靠的金融NLP辅助决策应用的发展。

Abstract: This research explores the strengths and weaknesses of domain-adapted Large
Language Models (LLMs) in the context of financial natural language processing
(NLP). The analysis centers on FinMA, a model created within the PIXIU
framework, which is evaluated for its performance in specialized financial
tasks. Recognizing the critical demands of accuracy, reliability, and domain
adaptation in financial applications, this study examines FinMA's model
architecture, its instruction tuning process utilizing the Financial
Instruction Tuning (FIT) dataset, and its evaluation under the FLARE benchmark.
Findings indicate that FinMA performs well in sentiment analysis and
classification, but faces notable challenges in tasks involving numerical
reasoning, entity recognition, and summarization. This work aims to advance the
understanding of how financial LLMs can be effectively designed and evaluated
to assist in finance-related decision-making processes.

</details>


### [100] [A Single Character can Make or Break Your LLM Evals](https://arxiv.org/abs/2510.05152)
*Jingtong Su,Jianyu Zhang,Karen Ullrich,Léon Bottou,Mark Ibrahim*

Main category: cs.CL

TL;DR: 这篇论文发现，在大语言模型（LLM）评测时，仅改变演示样例之间的分隔符（如逗号、换行、分号等）会显著影响模型的表现甚至模型间排名，影响幅度高达±23%。作者还探索了提高模型对分隔符选择鲁棒性的方法，并提出了相应建议。


<details>
  <summary>Details</summary>
Motivation: 当前针对LLM的评测中普遍依赖演示样例来引导模型输出风格，样例数量已被广泛研究，但样例分隔方式对模型输出影响鲜有探讨。评测和真实应用都存在“到底用哪种分隔符？”的问题。因而作者希望系统性地研究分隔符对评测结果，尤其是模型输出质量的影响。

Method: 作者在多个主流LLM（如Llama，Qwen，Gemma）上，利用MMLU等评测任务，通过控制变量只更换演示样例的分隔符（逗号、换行、分号、#等），系统衡量结果变化。同时，通过分析注意力头的分布，理解分隔符为何影响结果。最后尝试在prompt中主动指定分隔符以提升鲁棒性，并对最优分隔符做出建议。

Result: 分隔符的选择会导致模型在标准任务上的表现评分波动高达±23%，且有时模型的性能排名因分隔符变化而逆转。注意力头分析显示表现好的分隔符能更有效引导注意力集中于关键输入。指定分隔符可提升鲁棒性。

Conclusion: 评测和实际中，分隔符选择并非无关紧要，直接影响LLM表现甚至模型排名。通过明确指定分隔符可增强鲁棒性，作者建议使用经过验证、表现较好的分隔符。

Abstract: Common Large Language model (LLM) evaluations rely on demonstration examples
to steer models' responses to the desired style. While the number of examples
used has been studied and standardized, the choice of how to format examples is
less investigated. In evaluation protocols and real world usage, users face the
choice how to separate in-context examples: use a comma? new line? semi-colon?
hashtag? etc.? Surprisingly, we find this seemingly minor choice can
dramatically alter model response quality. Across leading model families
(Llama, Qwen, Gemma), performance on MMLU for example can vary by $\pm 23\%$
depending on the choice of delimiter. In fact, one can manipulate model
rankings to put any model in the lead by only modifying the single character
separating examples. We find LLMs' brittleness pervades topics, model families,
and doesn't improve with scale. By probing attention head scores, we find that
good-performing delimiters steer attention towards key tokens in the input.
Finally, we explore methods to improve LLMs' robustness to the choice of
delimiter. We find specifying the selected delimiter in the prompt boosts
robustness and offer practical recommendations for the best-performing
delimiters to select.

</details>


### [101] [Can AI Truly Represent Your Voice in Deliberations? A Comprehensive Study of Large-Scale Opinion Aggregation with LLMs](https://arxiv.org/abs/2510.05154)
*Shenzhe Zhu,Shu Yang,Michiel A. Bakker,Alex Pentland,Jiaxin Pei*

Main category: cs.CL

TL;DR: 本文提出了用于大规模公共讨论总结评价的DeliberationBank数据集和DeliberationJudge模型，以克服现有大模型在立场代表性和公平性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在总结大规模公共讨论内容时，可能存在对少数观点的低代表性和输入顺序引发的偏见。评估和修正这些问题需要大规模且符合人类观点的数据，但现在多依赖大模型自评，与人类判断吻合度差，因此亟需更可靠的评测工具和数据。

Method: 构建DeliberationBank数据集，包括来自3000名参与者的十个议题意见及4500人对摘要的四维度（代表性、信息量、中立性、政策认可度）人工标注评价；并以此训练了DeliberationJudge——经过微调的DeBERTa模型，用于更高效且更符合人类判断地评价讨论摘要。

Result: DeliberationJudge在多方面（比如代表性和效率）优于各类LLM自评工具。利用该模型评测了18个主流LLM，发现它们在公共讨论总结中对少数派立场依然有明显低估问题。

Conclusion: DeliberationBank和DeliberationJudge为大规模政策讨论总结合理性与公平性评估提供了新途径，为AI在政策制定等关键领域的应用提供了更具代表性和公正性的基础。

Abstract: Large-scale public deliberations generate thousands of free-form
contributions that must be synthesized into representative and neutral
summaries for policy use. While LLMs have been shown as a promising tool to
generate summaries for large-scale deliberations, they also risk
underrepresenting minority perspectives and exhibiting bias with respect to the
input order, raising fairness concerns in high-stakes contexts. Studying and
fixing these issues requires a comprehensive evaluation at a large scale, yet
current practice often relies on LLMs as judges, which show weak alignment with
human judgments. To address this, we present DeliberationBank, a large-scale
human-grounded dataset with (1) opinion data spanning ten deliberation
questions created by 3,000 participants and (2) summary judgment data annotated
by 4,500 participants across four dimensions (representativeness,
informativeness, neutrality, policy approval). Using these datasets, we train
DeliberationJudge, a fine-tuned DeBERTa model that can rate deliberation
summaries from individual perspectives. DeliberationJudge is more efficient and
more aligned with human judgements compared to a wide range of LLM judges. With
DeliberationJudge, we evaluate 18 LLMs and reveal persistent weaknesses in
deliberation summarization, especially underrepresentation of minority
positions. Our framework provides a scalable and reliable way to evaluate
deliberation summarization, helping ensure AI systems are more representative
and equitable for policymaking.

</details>


### [102] [A novel hallucination classification framework](https://arxiv.org/abs/2510.05189)
*Maksym Zavhorodnii,Dmytro Dehtiarov,Anna Konovalenko*

Main category: cs.CL

TL;DR: 论文提出了一种新方法，自动检测大语言模型（LLM）推理过程中产生的幻觉内容。方法通过构建系统化的幻觉分类体系，并用prompt工程有控制地生成多样化的幻觉，再利用嵌入模型和无监督学习分析其向量空间分布。结果显示，幻觉与正确信息输出在空间上有明显区分，简单分类器即可有效检测幻觉内容。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型由于幻觉问题严重，亟需高精度、低成本的自动检测方法来提升模型输出的可靠性。现有检测方法常依赖复杂、昂贵的手段，缺乏有效性和可扩展性。因此，开发准确、简便的检测手段具有重要意义。

Method: 首先建立系统性的幻觉类型分类体系，并采用prompt工程有针对性地生成各种类型幻觉。然后，用嵌入模型将这些数据映射到向量空间，并以无监督学习（如聚类、降维）分析幻觉和正确信息的空间分布。通过定量评估各聚类中心距离，探索幻觉严重程度与正确输出的区别。

Result: 实验显示，幻觉与正确信息在向量空间中表现出一致且明显的分离，不同程度的信息扭曲导致其离正确信息聚簇距离更远。简单的分类算法已可有效区分幻觉与准确响应。

Conclusion: 该研究证明即便是简单分类器，也能根据空间分布轻量级地检测并区分幻觉和有根据的输出，为提升LLM输出可靠性提供了理论和实证支持，同时方法高效、实用。

Abstract: This work introduces a novel methodology for the automatic detection of
hallucinations generated during large language model (LLM) inference. The
proposed approach is based on a systematic taxonomy and controlled reproduction
of diverse hallucination types through prompt engineering. A dedicated
hallucination dataset is subsequently mapped into a vector space using an
embedding model and analyzed with unsupervised learning techniques in a
reduced-dimensional representation of hallucinations with veridical responses.
Quantitative evaluation of inter-centroid distances reveals a consistent
correlation between the severity of informational distortion in hallucinations
and their spatial divergence from the cluster of correct outputs. These
findings provide theoretical and empirical evidence that even simple
classification algorithms can reliably distinguish hallucinations from accurate
responses within a single LLM, thereby offering a lightweight yet effective
framework for improving model reliability.

</details>


### [103] [Let it Calm: Exploratory Annealed Decoding for Verifiable Reinforcement Learning](https://arxiv.org/abs/2510.05251)
*Chenghao Yang,Lin Gui,Chenxiao Yang,Victor Veitch,Lizhu Zhang,Zhuokai Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种新的采样策略“Exploratory Annealed Decoding(EAD)”，通过动态调整采样温度，提升了强化学习奖励可验证环境下大模型的探索效率和训练稳定性，显著超越传统固定温度采样法。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型的强化学习探索主要依赖固定温度采样法，高温时探索多但样本质量下降，低温时样本质量好但探索受限，难以兼顾高质量与有效探索。为解决这一矛盾，作者希望找到更加平衡、有效的探索机制。

Method: 作者提出EAD方法：生成文本时，将采样温度从高（起始token）逐步退火到低（结束token），即起始阶段探索多样，后期聚焦提升样本质量，并保持采样分布接近目标策略，便于训练收敛。

Result: EAD方法轻量易用，作为“即插即用”的策略，实验在多种RLVR算法和模型规模下均取得比固定温度法更高的样本效率和稳定性。

Conclusion: 探索策略与生成任务的自然语义分布相结合（先探索后收敛），能显著提升大语言模型的推理与训练表现，是改善RLVR采样质量与高效性的有力手段。

Abstract: Reinforcement learning with verifiable rewards (RLVR) is a powerful paradigm
for enhancing the reasoning capabilities of large language models (LLMs), yet
its success hinges on effective exploration. An ideal exploration strategy must
navigate two fundamental challenges: it must preserve sample quality while also
ensuring training stability. While standard fixed-temperature sampling is
simple, it struggles to balance these competing demands, as high temperatures
degrade sample quality and low temperatures limit discovery. In this work, we
propose a simpler and more effective strategy, Exploratory Annealed Decoding
(EAD), grounded in the insight that exploration is most impactful on early
tokens which define a sequence's semantic direction. EAD implements an
intuitive **explore-at-the-beginning, exploit-at-the-end** strategy by
annealing the sampling temperature from high to low during generation. This
dynamic schedule encourages meaningful, high-level diversity at the start, then
gradually lowers the temperature to preserve sample quality and keep the
sampling distribution close to the target policy, which is essential for stable
training. We demonstrate that EAD is a lightweight, plug-and-play method that
significantly improves sample efficiency, consistently outperforming
fixed-temperature sampling across various RLVR algorithms and model sizes. Our
work suggests that aligning exploration with the natural dynamics of sequential
generation offers a robust path to improving LLM reasoning.

</details>


### [104] [Camellia: Benchmarking Cultural Biases in LLMs for Asian Languages](https://arxiv.org/abs/2510.05291)
*Tarek Naous,Anagha Savit,Carlos Rafael Catalan,Geyang Guo,Jaehyeok Lee,Kyungdon Lee,Lheane Marie Dizon,Mengyu Ye,Neel Kothari,Sahajpreet Singh,Sarah Masud,Tanish Patwa,Trung Thanh Tran,Zohaib Khan,Alan Ritter,JinYeong Bak,Keisuke Sakaguchi,Tanmoy Chakraborty,Yuki Arase,Wei Xu*

Main category: cs.CL

TL;DR: 本论文提出了Camellia基准，以评估多语言大模型在九种亚洲语言中的文化偏见，分析发现LLM在亚洲语境下的文化适应能力有限，且不同模型存在各自独特的文化偏见。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型具备更强的多语言能力，其能否公正处理不同文化的实体尤为关键。现有研究揭示LLM在阿拉伯语内容中偏好西方实体，然而由于缺乏多语种的衡量标准，尚不清楚这一偏见是否在其他非西方语言中同样存在。因此，需要构建多语言、涵盖多元亚洲文化的评测基准。

Method: 作者提出Camellia基准，覆盖9种亚洲语言、6种亚洲文化，人工注释了19,530个亚洲或西方相关实体并收集了2,173条来自社交媒体的真实情境语料。利用Camellia，对4个多语种LLM家族在文化语境适应、情感关联和实体抽取问答等任务上进行了评测与比较。

Result: 分析发现，所有LLM在亚洲语言环境下的文化适应能力都有限；不同LLM源于地区及数据的差异，文化相关知识掌握程度不同；各家模型在文化与情感关联上表现出各自独特的偏见；此外，LLM在亚洲语言背景的实体抽取表现不均，存在文化间表现差异。

Conclusion: 当前主流多语种LLM在亚洲语境下仍难以有效进行文化适应，存在显著且不同表现形式的文化偏见，凸显了丰富多元文化数据和改进模型方法的必要性。

Abstract: As Large Language Models (LLMs) gain stronger multilingual capabilities,
their ability to handle culturally diverse entities becomes crucial. Prior work
has shown that LLMs often favor Western-associated entities in Arabic, raising
concerns about cultural fairness. Due to the lack of multilingual benchmarks,
it remains unclear if such biases also manifest in different non-Western
languages. In this paper, we introduce Camellia, a benchmark for measuring
entity-centric cultural biases in nine Asian languages spanning six distinct
Asian cultures. Camellia includes 19,530 entities manually annotated for
association with the specific Asian or Western culture, as well as 2,173
naturally occurring masked contexts for entities derived from social media
posts. Using Camellia, we evaluate cultural biases in four recent multilingual
LLM families across various tasks such as cultural context adaptation,
sentiment association, and entity extractive QA. Our analyses show a struggle
by LLMs at cultural adaptation in all Asian languages, with performance
differing across models developed in regions with varying access to
culturally-relevant data. We further observe that different LLM families hold
their distinct biases, differing in how they associate cultures with particular
sentiments. Lastly, we find that LLMs struggle with context understanding in
Asian languages, creating performance gaps between cultures in entity
extraction.

</details>


### [105] [RAG Makes Guardrails Unsafe? Investigating Robustness of Guardrails under RAG-style Contexts](https://arxiv.org/abs/2510.05310)
*Yining She,Daniel W. Peterson,Marianne Menglin Liu,Vikas Upadhyay,Mohammad Hossein Chaghazardi,Eunsuk Kang,Dan Roth*

Main category: cs.CL

TL;DR: 本论文发现当前基于LLM的安全防护系统（guardrail）在面对信息扩展（如引入检索文档）的情况下，判断会被误导，表现出上下文鲁棒性不足。


<details>
  <summary>Details</summary>
Motivation: 大模型越来越多被采用，如何确保其输出安全逐渐成为关注重点。现有做法是采用基于LLM的外部安全防护模型（guardrail）筛查输入输出是否安全，但这些模型自身常常因数据分布变动或提示调整而变得脆弱。本研究想探究，在检索增强生成（RAG）场景下，防护模型在遇到上下文被扩展时的表现是否可靠。

Method: 以RAG为例，系统性地评测3个Llama Guard和2个GPT-oss防护模型，在其上下文中插入普通文档，并单独分析每个上下文组件（检索文档、用户查询、LLM回复）对防护结果的影响，同时尝试两种缓解措施评估效果。

Result: 结果显示，在约11%的输入和8%的输出场景下，仅通过插入无害文档就能改变防护模型的判断。两种缓解方法的改进效果有限。

Conclusion: 当前基于LLM的防护模型存在明显的上下文鲁棒性短板，需要开发更健全的训练与评估方案来提升其对检索及查询混合上下文的适应能力。

Abstract: With the increasing adoption of large language models (LLMs), ensuring the
safety of LLM systems has become a pressing concern. External LLM-based
guardrail models have emerged as a popular solution to screen unsafe inputs and
outputs, but they are themselves fine-tuned or prompt-engineered LLMs that are
vulnerable to data distribution shifts. In this paper, taking Retrieval
Augmentation Generation (RAG) as a case study, we investigated how robust
LLM-based guardrails are against additional information embedded in the
context. Through a systematic evaluation of 3 Llama Guards and 2 GPT-oss
models, we confirmed that inserting benign documents into the guardrail context
alters the judgments of input and output guardrails in around 11% and 8% of
cases, making them unreliable. We separately analyzed the effect of each
component in the augmented context: retrieved documents, user query, and
LLM-generated response. The two mitigation methods we tested only bring minor
improvements. These results expose a context-robustness gap in current
guardrails and motivate training and evaluation protocols that are robust to
retrieval and query composition.

</details>


### [106] [WeatherArchive-Bench: Benchmarking Retrieval-Augmented Reasoning for Historical Weather Archives](https://arxiv.org/abs/2510.05336)
*Yongan Yu,Xianda Du,Qingchen Hu,Jiahao Liang,Jingwei Ni,Dan Qiang,Kaiyu Huang,Grant McKenzie,Renee Sieber,Fengran Mo*

Main category: cs.CL

TL;DR: 本文介绍了WeatherArchive-Bench，这是首个用于评估历史天气档案检索增强生成（RAG）系统的基准，旨在辅助气候科学研究挖掘社会对极端天气事件的响应。


<details>
  <summary>Details</summary>
Motivation: 历史天气档案中蕴含丰富的社会应对极端天气事件的原始记录，这些信息为理解社会脆弱性与韧性提供独特视角，但由于其数据量庞大、数字化质量参差不齐及语言古老，难以直接应用于结构化气候研究。

Method: 作者提出了WeatherArchive-Bench，这一基准数据集包含两个任务：1）WeatherArchive-Retrieval，评测系统从百万历史新闻段落中检索相关天气事件的能力；2）WeatherArchive-Assessment，评测大模型对极端天气叙事中文化脆弱性与韧性指标的分类能力。作者还系统比较了稀疏、稠密和重排序检索器及多种大模型的效果。

Result: 实验显示，主流稠密检索方法对历史术语适应较差，而大模型在辨识脆弱性和韧性概念方面常常存在误判，凸显当前系统在解读复杂社会指标上的局限性。

Conclusion: 该研究揭示了现有RAG系统和大语言模型在应对历史档案与社会指标时的短板，为未来更鲁棒的气候相关检索增强系统设计提供了方向，同时公开了数据集和评测框架，助力后续研究。

Abstract: Historical archives on weather events are collections of enduring primary
source records that offer rich, untapped narratives of how societies have
experienced and responded to extreme weather events. These qualitative accounts
provide insights into societal vulnerability and resilience that are largely
absent from meteorological records, making them valuable for climate scientists
to understand societal responses. However, their vast scale, noisy digitized
quality, and archaic language make it difficult to transform them into
structured knowledge for climate research. To address this challenge, we
introduce WeatherArchive-Bench, the first benchmark for evaluating
retrieval-augmented generation (RAG) systems on historical weather archives.
WeatherArchive-Bench comprises two tasks: WeatherArchive-Retrieval, which
measures a system's ability to locate historically relevant passages from over
one million archival news segments, and WeatherArchive-Assessment, which
evaluates whether Large Language Models (LLMs) can classify societal
vulnerability and resilience indicators from extreme weather narratives.
Extensive experiments across sparse, dense, and re-ranking retrievers, as well
as a diverse set of LLMs, reveal that dense retrievers often fail on historical
terminology, while LLMs frequently misinterpret vulnerability and resilience
concepts. These findings highlight key limitations in reasoning about complex
societal indicators and provide insights for designing more robust
climate-focused RAG systems from archival contexts. The constructed dataset and
evaluation framework are publicly available at
https://anonymous.4open.science/r/WeatherArchive-Bench/.

</details>


### [107] [Residualized Similarity for Faithfully Explainable Authorship Verification](https://arxiv.org/abs/2510.05362)
*Peter Zeng,Pegah Alipoormolabashi,Jihu Mun,Gourab Dey,Nikita Soni,Niranjan Balasubramanian,Owen Rambow,H. Schwartz*

Main category: cs.CL

TL;DR: 本文提出了一种新的作者身份验证方法（Residualized Similarity, RS），结合可解释特征与神经网络，提升性能同时保持可解释性，并在四个数据集上验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前神经网络在作者身份验证（AV）中表现出色，但不可解释。实际应用中，尤其涉及实际后果的决策，需要模型预测结果能够被真正解释并追溯至原始文本。

Method: 提出Residualized Similarity（RS）方法，用神经网络预测基于可解释特征的系统在相似性判断中的误差（similarity residual），借此提高整体准确率，同时保留原系统的可解释性。

Result: 实验覆盖四个数据集，结果显示所提方法在准确性上可以匹敌当前最先进的模型，同时能够展示最终预测的可解释性和忠实性。

Conclusion: RS方法实现了性能与可解释性的统一，使AV系统更适用于需可解释决策的实际场景，为实际应用提供了强有力的支持。

Abstract: Responsible use of Authorship Verification (AV) systems not only requires
high accuracy but also interpretable solutions. More importantly, for systems
to be used to make decisions with real-world consequences requires the model's
prediction to be explainable using interpretable features that can be traced to
the original texts. Neural methods achieve high accuracies, but their
representations lack direct interpretability. Furthermore, LLM predictions
cannot be explained faithfully -- if there is an explanation given for a
prediction, it doesn't represent the reasoning process behind the model's
prediction. In this paper, we introduce Residualized Similarity (RS), a novel
method that supplements systems using interpretable features with a neural
network to improve their performance while maintaining interpretability.
Authorship verification is fundamentally a similarity task, where the goal is
to measure how alike two documents are. The key idea is to use the neural
network to predict a similarity residual, i.e. the error in the similarity
predicted by the interpretable system. Our evaluation across four datasets
shows that not only can we match the performance of state-of-the-art authorship
verification models, but we can show how and to what degree the final
prediction is faithful and interpretable.

</details>


### [108] [The End of Transformers? On Challenging Attention and the Rise of Sub-Quadratic Architectures](https://arxiv.org/abs/2510.05364)
*Alexander M. Fichtl,Jeremias Bohn,Josefin Kelber,Edoardo Mosca,Georg Groh*

Main category: cs.CL

TL;DR: 这篇论文综述了为解决Transformer模型在序列处理任务中注意力机制带来的计算复杂度瓶颈而出现的新进展，分析了不同方案的优缺点，并对未来Transformer的主导地位提出思考。


<details>
  <summary>Details</summary>
Motivation: Transformer模型由于注意力机制的二次复杂度，随着序列长度增加计算和内存成本迅速攀升，限制了其在长序列任务中的应用。当前学术界和工业界都在寻求打破这个瓶颈的新方法。

Method: 论文系统梳理了几类降低复杂度的最新技术路线，包括次二次复杂度的注意力变体、递归神经网络（RNN）、状态空间模型以及混合架构（如结合不同结构的模型），并对它们进行了理论与实证评测。

Result: 论文对这些方法从计算、内存消耗、基准测试结果及其根本性限制进行了比较和批判性评估，指出每种方法均有优劣，且当前尚未有哪类方法完全取代纯注意力Transformer。

Conclusion: 尽管出现了多种新的架构和优化手段，但纯注意力Transformer依然保持着主导地位。未来新结构有挑战这一地位的可能，但目前来看尚无明确胜者。

Abstract: Transformers have dominated sequence processing tasks for the past seven
years -- most notably language modeling. However, the inherent quadratic
complexity of their attention mechanism remains a significant bottleneck as
context length increases. This paper surveys recent efforts to overcome this
bottleneck, including advances in (sub-quadratic) attention variants, recurrent
neural networks, state space models, and hybrid architectures. We critically
analyze these approaches in terms of compute and memory complexity, benchmark
results, and fundamental limitations to assess whether the dominance of
pure-attention transformers may soon be challenged.

</details>


### [109] [Context Length Alone Hurts LLM Performance Despite Perfect Retrieval](https://arxiv.org/abs/2510.05381)
*Yufeng Du,Minyang Tian,Srikanth Ronanki,Subendhu Rongali,Sravan Bodapati,Aram Galstyan,Azton Wells,Roy Schwartz,Eliu A Huerta,Hao Peng*

Main category: cs.CL

TL;DR: 尽管大模型可在长上下文条件下检索到所有关键信息，但其在长输入任务上的整体表现依然显著下降。仅仅增加输入长度本身就会带来性能下降，这与检索能力无关。作者提出了一种通过先让模型复述关键信息来缓解长上下文退化的简单方法，取得了小幅提升。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型声称支持更长的上下文，但实测发现其在长文本场景下表现仍难以和短文本持平。业界普遍认为这源于模型检索相关信息的失败，但作者怀疑即使检索完美，也仍存在性能下降问题，因此系统性地研究了该假设。

Method: 作者对比了5个开源与闭源大模型在数学、问答和编程任务下，从短输入到长输入区间的表现。通过实验分别控制无关信息为仅留空白、全部掩码或所有相关证据集中排列，确保检索难度不再是主要干扰因素。最后，提出通过提示模型先逐条复述相关信息再作答，以减缓长上下文影响。

Result: 即使所有相关信息均能被精准检索，且去除所有非关键信息，大模型在长上下文条件下性能依然下降，降幅在13.9%到85%之间。即便相关证据全部集中在问题前或输入中并无干扰，这种退化现象仍旧明显。所提简单缓解方法可带来小幅性能提升（如GPT-4o提升约4%）。

Conclusion: 大模型长上下文性能劣化不只是因为检索失效，长输入本身即会带来性能瓶颈。提示式证据复述是一种通用且有效的缓解方案，但这一根本限制需未来进一步研究和突破。

Abstract: Large language models (LLMs) often fail to scale their performance on
long-context tasks performance in line with the context lengths they support.
This gap is commonly attributed to retrieval failures -- the models' inability
to identify relevant information in the long inputs. Accordingly, recent
efforts often focus on evaluating and improving LLMs' retrieval performance: if
retrieval is perfect, a model should, in principle, perform just as well on a
long input as it does on a short one -- or should it? This paper presents
findings that the answer to this question may be negative. Our systematic
experiments across 5 open- and closed-source LLMs on math, question answering,
and coding tasks reveal that, even when models can perfectly retrieve all
relevant information, their performance still degrades substantially
(13.9%--85%) as input length increases but remains well within the models'
claimed lengths. This failure occurs even when the irrelevant tokens are
replaced with minimally distracting whitespace, and, more surprisingly, when
they are all masked and the models are forced to attend only to the relevant
tokens. A similar performance drop is observed when all relevant evidence is
placed immediately before the question. Our findings reveal a
previously-unrealized limitation: the sheer length of the input alone can hurt
LLM performance, independent of retrieval quality and without any distraction.
They motivate our simple, model-agnostic mitigation strategy that transforms a
long-context task into a short-context one by prompting the model to recite the
retrieved evidence before attempting to solve the problem. On RULER, we observe
a consistent improvement of GPT-4o up to 4% on an already strong baseline.

</details>


### [110] [Cross-Lingual Mental Health Ontologies for Indian Languages: Bridging Patient Expression and Clinical Understanding through Explainable AI and Human-in-the-Loop Validation](https://arxiv.org/abs/2510.05387)
*Ananth Kandala,Ratna Kandala,Akshata Kishore Moharir,Niva Manchanda,Sunaina Singh*

Main category: cs.CL

TL;DR: 本文提出了一种基于图的跨语言心理健康表达本体（CL-PDE），弥补当前主流健康本体过于偏重英语和西方文化，难以覆盖印度多语种、多元文化表达的不足。


<details>
  <summary>Details</summary>
Motivation: 印度心理健康交流受制于语言分裂和文化多样性，现有临床NLP资源严重忽视本地化和多语种患者痛苦表达。这导致AI医疗系统难以理解和服务多语种、跨文化的印度患者群体。

Method: 作者提出了一种跨语言的患者痛苦表达图谱（CL-PDE）的方法，通过图结构方法捕捉不同语言和文化中嵌入的痛苦表达，并对它们进行语言间的对齐及与专业医学术语的关联，从而构建跨语种的心理健康本体资源。

Result: 该方法实现了对印度多种语言和文化背景下的心理痛苦表达的有效捕捉和对齐，提升了多语种环境下心理健康NLP工具的包容性和临床适用性。

Conclusion: 跨语言心理健康表达本体为AI辅助的心理健康沟通提供更具文化敏感性和包容度的基础，促进更以患者为中心、多语种背景下的医疗NLP系统发展。

Abstract: Mental health communication in India is linguistically fragmented, culturally
diverse, and often underrepresented in clinical NLP. Current health ontologies
and mental health resources are dominated by diagnostic frameworks centered on
English or Western culture, leaving a gap in representing patient distress
expressions in Indian languages. We propose cross-linguistic graphs of patient
stress expressions (CL-PDE), a framework for building cross-lingual mental
health ontologies through graph-based methods that capture culturally embedded
expressions of distress, align them across languages, and link them with
clinical terminology. Our approach addresses critical gaps in healthcare
communication by grounding AI systems in culturally valid representations,
allowing more inclusive and patient-centric NLP tools for mental health care in
multilingual contexts.

</details>


### [111] [Aligning Language Models with Clinical Expertise: DPO for Heart Failure Nursing Documentation in Critical Care](https://arxiv.org/abs/2510.05410)
*Junyi Fan,Li Sun,Negin Ashrafi,Kamiar Alaei,Maryam Pishgar*

Main category: cs.CL

TL;DR: 本研究通过应用Direct Preference Optimization (DPO)方法，优化了Mistral-7B语言模型以提升ICU心衰护理文档的标准化和质量，结果显著提升了文本指标和专家评价。


<details>
  <summary>Details</summary>
Motivation: ICU护理文档对于临床决策至关重要，但存在术语不一致、书写风格随意、缺乏标准化等问题，尤其在心衰护理中尤为突出，亟需改进以促进患者安全和减轻行政负担。

Method: 通过在MIMIC-III数据库提取8,838份心衰护理记录，结合21,210对由专家审核的GPT结果、模型生成内容及原始文档组成的偏好对，采用DPO对Mistral-7B模型进行本地训练和调优。性能评估涵盖BLEU、ROUGE、BERTScore、PPL等自动分数及专家质量评定。

Result: DPO优化后，BLEU值提升84%（0.173到0.318）；BERTScore提升7.6%；专家评分中，准确性、完整性、逻辑一致性、可读性、结构清晰度各提升11-14分不等，所有指标均明显优于原始模型。

Conclusion: DPO能使轻量级的本地临床语言模型达标于专家标准，助力隐私保护的AI自动护理记录，有效减少文书负担并提升ICU患者安全性。

Abstract: Nursing documentation in intensive care units (ICUs) provides essential
clinical intelligence but often suffers from inconsistent terminology, informal
styles, and lack of standardization, challenges that are particularly critical
in heart failure care. This study applies Direct Preference Optimization (DPO)
to adapt Mistral-7B, a locally deployable language model, using 8,838 heart
failure nursing notes from the MIMIC-III database and 21,210 preference pairs
derived from expert-verified GPT outputs, model generations, and original
notes. Evaluation across BLEU, ROUGE, BERTScore, Perplexity, and expert
qualitative assessments demonstrates that DPO markedly enhances documentation
quality. Specifically, BLEU increased by 84% (0.173 to 0.318), BERTScore
improved by 7.6% (0.828 to 0.891), and expert ratings rose across accuracy
(+14.4 points), completeness (+14.5 points), logical consistency (+14.1
points), readability (+11.1 points), and structural clarity (+6.0 points).
These results indicate that DPO can align lightweight clinical language models
with expert standards, supporting privacy-preserving, AI-assisted documentation
within electronic health record systems to reduce administrative burden and
improve ICU patient safety.

</details>


### [112] [A Lightweight Large Language Model-Based Multi-Agent System for 2D Frame Structural Analysis](https://arxiv.org/abs/2510.05414)
*Ziheng Geng,Jiachen Liu,Ran Cao,Lu Cheng,Haifeng Wang,Minghui Cheng*

Main category: cs.CL

TL;DR: 该论文提出并实现了一个基于大语言模型（LLM）的多智能体系统，用于自动化有限元二维框架结构建模，提高了结构建模流程的自动化和效率，实验证明其准确率优于同期主流模型。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型在工程自动化领域有广泛应用，但在结构工程、尤其是需要几何建模与复杂推理的有限元任务中应用不足。因此需要探索LLM如何提升结构建模流程的智能化和自动化水平。

Method: 作者设计了一个多智能体系统，将有限元建模工作流分解为若干子任务，每个子任务由专用的LLM智能体（基于Llama-3.3 70B Instruct模型）负责，包括问题分析、几何推断、代码生成、模型校验和载荷施加，最终自动生成可执行的OpenSeesPy模型代码。

Result: 在20个基准问题上进行实验，系统在大多数情况下10次重复实验的准确率超过80%，并且表现优于Gemini-2.5 Pro和ChatGPT-4o等先进大模型。

Conclusion: 基于LLM的多智能体系统可以显著提升结构有限元建模的自动化水平，在准确性与效率上优于现有通用大型语言模型，具有良好的应用前景。

Abstract: Large language models (LLMs) have recently been used to empower autonomous
agents in engineering, significantly improving automation and efficiency in
labor-intensive workflows. However, their potential remains underexplored in
structural engineering, particularly for finite element modeling tasks
requiring geometric modeling, complex reasoning, and domain knowledge. To
bridge this gap, this paper develops a LLM-based multi-agent system to automate
finite element modeling of 2D frames. The system decomposes structural analysis
into subtasks, each managed by a specialized agent powered by the lightweight
Llama-3.3 70B Instruct model. The workflow begins with a Problem Analysis
Agent, which extracts geometry, boundary, and material parameters from the user
input. Next, a Geometry Agent incrementally derives node coordinates and
element connectivity by applying expert-defined rules. These structured outputs
are converted into executable OpenSeesPy code by a Translation Agent and
refined by a Model Validation Agent through consistency checks. Then, a Load
Agent applies load conditions into the assembled structural model. Experimental
evaluations on 20 benchmark problems demonstrate that the system achieves
accuracy over 80% in most cases across 10 repeated trials, outperforming
Gemini-2.5 Pro and ChatGPT-4o models.

</details>


### [113] [Self-Filtered Distillation with LLMs-generated Trust Indicators for Reliable Patent Classification](https://arxiv.org/abs/2510.05431)
*Yoo Yongmin,Zhang Xu,Cao Longbing*

Main category: cs.CL

TL;DR: 本文提出了一种名为Self-Filtered Distillation的新框架，提升了大语言模型在专利分类任务中的准确性和可解释性。该方法以LLM生成的理由为信任信号，通过无监督的可信度指标筛选和加权训练样本，实现更稳健的监督学习。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）在解释性生成中的广泛应用，其生成的自然语言理由常常包含逻辑错误、标签不一致和领域专有的失配。如果直接用这些理由作为监督信号，容易引入噪音，影响模型训练的稳定性和表现。

Method: 作者提出Self-Filtered Distillation框架，将LLM生成的理由作为信任信号而非直接监督，对其进行加权和筛选。该框架设计了三种无监督可信度指标：1）自洽性指标，评估同一输入多次生成理由的一致性；2）类蕴含对齐，衡量理由与专利类别定义的语义一致性；3）LLM一致性评分，评估理由和标签的合理性。这些指标被联合为一个信任分数，主要用于训练样本加权和过滤低可信样本，实现推理感知的监督。

Result: 在专利分类的权威数据集USPTO-2M上的实验表明，该方法在准确率、稳定性和可解释性均优于传统基于标签的训练和常规知识蒸馏方法。

Conclusion: Self-Filtered Distillation为专利分析中的基于推理的信任指标提供了有效利用范式，证明了通过可信度筛选和加权样本能显著提升训练效果及解释性，具有良好的推广潜力。

Abstract: Large language models (LLMs) increasingly generate natural language
rationales to enhance interpretability, but these often contain logical errors,
label mismatches, and domain-specific misalignments. Directly using such
rationales as supervision risks propagating noise and undermining training
stability. To address this challenge, we introduce Self-Filtered Distillation,
a framework specifically tailored for patent classification, which treats
LLM-generated rationales as trust signals rather than ground-truth supervision.
The framework employs selective distillation guided by three unsupervised trust
metrics: (1) Self-Consistency, which measures the stability of LLM-generated
rationales across multiple generations; (2) Class Entailment Alignment, which
assesses semantic coherence with patent-specific class definitions; and (3) LLM
Agreement Scoring, which validates rationale-label plausibility. These metrics
are integrated into a unified trust score that primarily weights training
samples while optionally filtering out extremely low-trust cases, enabling
reasoning-aware supervision. Experiments on the USPTO-2M dataset, a widely used
benchmark for patent classification, show that our method outperforms
label-based learning and conventional distillation in accuracy, stability, and
interpretability, establishing a reliable paradigm for leveraging
reasoning-aware trust indicators in patent analytics.

</details>


### [114] [SimulatorArena: Are User Simulators Reliable Proxies for Multi-Turn Evaluation of AI Assistants?](https://arxiv.org/abs/2510.05444)
*Yao Dou,Michel Galley,Baolin Peng,Chris Kedzie,Weixin Cai,Alan Ritter,Chris Quirk,Wei Xu,Jianfeng Gao*

Main category: cs.CL

TL;DR: 论文提出了SimulatorArena基准，用于系统评测大型语言模型（LLMs）作为用户模拟器在对话任务中的表现，并验证其能否作为真实用户的替代。


<details>
  <summary>Details</summary>
Motivation: 人工评测LLMs在多轮对话中的表现虽然权威，但成本高、耗时且不易复现。研究者希望用LLM代替真实用户进行自动化测试，但缺乏系统的基准和可验证的有效性。

Method: 构建了SimulatorArena基准，包括909组人工标注的人机对话数据，涵盖数学辅导和文档创作两类任务。用多种用户模拟器（包括带用户背景与风格特征的）和真实用户表现进行比对，并用一致性指标进行评价。

Result: 发现具备用户画像（如背景与风格）的模拟器在仿真用户行为及打分上与真实用户高度一致，在两个任务上Spearman's ρ达到0.7，显示出较强的可替代性。随后用最优模拟器评测了18个主流助手模型。

Conclusion: 具备用户特征的LLM用户模拟器在多轮对话任务中能较好地替代人工评测，为后续大模型的自动化评测提供了实用、可扩展的方法和基准。

Abstract: Large language models (LLMs) are increasingly used in interactive
applications, and human evaluation remains the gold standard for assessing
their performance in multi-turn conversations. Since human studies are costly,
time-consuming, and hard to reproduce, recent work explores using LLMs to
simulate users for automatic assistant evaluation. However, there is no
benchmark or systematic study to evaluate whether these simulated users are
reliable stand-ins for real users. To address this, we introduce
SimulatorArena, a benchmark of 909 annotated human-LLM conversations on two
interactive tasks -- math tutoring and document creation. SimulatorArena
evaluates simulators based on how closely their messages match human behavior
and how well their assistant ratings align with human judgments. Experiments on
various simulator methods show that simulators conditioned on user profiles,
capturing traits like background and message styles, align closely with human
judgments. They reach Spearman's $\rho$ of 0.7 on both tasks, providing a
practical, scalable alternative to human evaluation. Using the best simulator
for each task, we benchmark 18 assistants, including the latest LLMs such as
GPT-5, Claude 4.1 Opus, and Gemini 2.5 Pro.

</details>


### [115] [AgentRouter: A Knowledge-Graph-Guided LLM Router for Collaborative Multi-Agent Question Answering](https://arxiv.org/abs/2510.05445)
*Zheyuan Zhang,Kaiwen Shi,Zhengqing Yuan,Zehong Wang,Tianyi Ma,Keerthiram Murugesan,Vincent Galassi,Chuxu Zhang,Yanfang Ye*

Main category: cs.CL

TL;DR: 本文提出了tAgentRouter，通过知识图谱和异质图神经网络实现多智能体的自适应路由，从而提升问答任务的效果。实验证明该方法优于单一或集成智能体方案。


<details>
  <summary>Details</summary>
Motivation: 面对众多大语言模型和代理框架，实际应用中很难选择最优配置，因为不同智能体和模型存在互补优势，且大模型并非总是最佳。因此亟需设计自适应高效的路由机制。

Method: 将多智能体问答任务建模为知识图谱引导的路由问题。具体做法为：把QA实例转换为整合查询、上下文实体和智能体的知识图谱，利用异质图神经网络传播多类型节点信息，输出面向任务的智能体选择分布，通过软监督和加权集成充分发挥多智能体互补性。

Result: 方法在多个基准任务和不同大语言模型骨干下进行了充分实验，均优于单一智能体和传统模型集成基线，无论泛化性还是鲁棒性都表现突出。

Conclusion: 基于知识图谱和图神经网络的多智能体路由方法在问答任务中效果显著，证明了通过细粒度建模智能体、上下文关系实现自适应协作的有效性与通用性。

Abstract: Large language models (LLMs) and agent-based frameworks have advanced
rapidly, enabling diverse applications. Yet, with the proliferation of models
and agentic strategies, practitioners face substantial uncertainty in selecting
the best configuration for a downstream task. Prior studies show that different
agents and backbones exhibit complementary strengths, and that larger models
are not always superior, underscoring the need for adaptive routing mechanisms.
Existing approaches to agent routing, however, often emphasize cost efficiency
while overlooking the fine-grained contextual and relational structure inherent
in QA tasks. In this paper, we propose tAgentRouter, a framework that
formulates multi-agent QA as a knowledge-graph-guided routing problem
supervised by empirical performance signals. Specifically, we convert QA
instance into a knowledge graph that jointly encodes queries, contextual
entities, and agents, and then train a heterogeneous graph neural network (GNN)
to propagate information across node types and produce task-aware routing
distributions over agents. By leveraging soft supervision and weighted
aggregation of agent outputs, AgentRouter learns principled collaboration
schemes that capture the complementary strengths of diverse agents. Extensive
experiments demonstrate that our framework consistently outperforms
single-agent and ensemble baselines, while generalizing across benchmarks and
LLM backbones. These results highlight the effectiveness and robustness of
graph-supervised multi-agent routing for question answering.

</details>


### [116] [SocialNLI: A Dialogue-Centric Social Inference Dataset](https://arxiv.org/abs/2510.05458)
*Akhil Deo,Kate Sanders,Benjamin Van Durme*

Main category: cs.CL

TL;DR: 本文提出了一个专注于对话中复杂社会现象（如讽刺、反讽）理解的推理数据集SoNLI，用于评估及提升大型语言模型在推理社会性对话能力方面的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在理解人类对话中复杂社交现象（如讽刺和反讽）方面仍有不足，缺乏专门的数据集评估与提升其社会推理能力。

Method: 构建了SoNLI数据集，收集和筛选了包含复杂社会细微差别（如讽刺和反讽）的对话转录文本，并为每个对话配对推理项、概率评分和人类书写的推理解释。以多步反事实推理的方式，评估大型语言模型和推理模型的社会推理（理论心智）能力。

Result: 通过SoNLI数据集系统性分析了当前大模型在社会推理上的弱点，能够更好地暴露和量化模型在理解高级社交现象（如讽刺、反讽）上的表现与缺陷。

Conclusion: SoNLI数据集为评估和改进大语言模型在社会性推理和理论心智能力上的不足提供了新的工具和方法，有助于推动更善于理解人类社交语境的AI助手发展。

Abstract: Making theory-of-mind inferences from human dialogue is a strong indicator of
a model's underlying social abilities, which are fundamental for adept AI
assistants. However, large language and reasoning models struggle to understand
sophisticated social phenomena in transcript data, such as sarcasm and irony.
To assess the weaknesses of current models and to identify their solutions, we
introduce SocialNLI (SoNLI) -- the first social dialogue inference dataset.
SoNLI consists of a collection of dialogue transcripts hand-picked to center
complex social nuances like irony and sarcasm, paired with inferences,
corresponding likelihood scores, and human-written explanations. We explore
social inference analysis as a facet of theory-of-mind, and evaluate LLM and
reasoning model theory-of-mind ability through multi-step counterfactual
reasoning.

</details>


### [117] [TensorBLEU: Vectorized GPU-based BLEU Score Implementation for Per-Sentence In-Training Evaluation](https://arxiv.org/abs/2510.05485)
*Adam Filipek*

Main category: cs.CL

TL;DR: 作者提出了TensorBLEU，一种专为GPU环境下高效计算BLEU分数的实现，大幅提升了在PyTorch中每句BLEU评分的速度和资源利用率。该方法超越了传统NLTK实现，在消费级GPU上快13倍、数据中心级GPU上快40倍。


<details>
  <summary>Details</summary>
Motivation: 现有的BLEU评测工具，如NLTK，通常在CPU上运行，处理大规模模型和批量评测时速度慢且消耗资源，成为训练过程中瓶颈，尤其是在强化学习等依赖频繁评分的场景。

Method: TensorBLEU以GPU为中心设计，实现了BLEU分数的完全向量化和批量化评测，并创新性地用torch.unique构建紧凑的批次特定n-gram字典，有效节省显存，规避了传统哈希方法的高内存需求。

Result: 实验数据显示，在消费级GPU（NVIDIA T4）上速度提升13倍，在数据中心级（A100）上提升40倍，远超CPU版NLTK。内存占用率更低，评测基本不再成为训练瓶颈。

Conclusion: TensorBLEU可大幅加速RL等场景下模型评测与微调研究，是针对“Token-ID BLEU”开发需求的强大工具，开源实现有望推动相关领域研究进展。

Abstract: Modern natural language processing models have achieved unprecedented scale,
yet the tools for their evaluation often remain a computational bottleneck,
limiting the pace of research. This is particularly acute for in-training
evaluation metrics, such as per-sentence reward signals in Reinforcement
Learning, which must operate efficiently on batches of token IDs directly on
the GPU. In this paper, we introduce TensorBLEU, a novel implementation of the
BLEU metric designed from the ground up for this specific use case. Our
approach is fully vectorized for GPU-accelerated, per-sentence computation
within PyTorch and introduces a memory-efficient counting mechanism. By
creating a compact, batch-specific dictionary of n-grams using
\texttt{torch.unique}, our method avoids the prohibitive memory costs of
traditional hashing-based vectorization, making it practical for
large-vocabulary models. We benchmark TensorBLEU against NLTK, the standard
library for token-ID-based BLEU calculation on the CPU. Experiments show that
TensorBLEU provides speedups of over 13x on consumer-grade GPUs (NVIDIA T4) and
exceeding 40x on data-center-class hardware (NVIDIA A100). This performance
transforms a significant bottleneck into a negligible part of the training
loop. By clearly defining its role as a "Token-ID BLEU" for development
purposes and open-sourcing our implementation, we provide a powerful tool for
accelerating research in areas like RL-based model fine-tuning.

</details>


### [118] [Language Model as Planner and Formalizer under Constraints](https://arxiv.org/abs/2510.05486)
*Cassie Huang,Stuti Mohan,Ziyi Yang,Stefanie Tellex,Li Zhang*

Main category: cs.CL

TL;DR: 本文指出，当前大模型在规划任务上表现优异的假象，主要由于现有基准数据集过于简单，缺乏真实场景中的复杂约束。作者通过手工引入细粒度的自然语言限制，证明这类约束显著降低主流大模型规划能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM规划基准多为简单环境，难以真实评估模型对复杂约束的处理能力，存在高估与安全隐患。作者为更真实评测LLM能力，设计更具挑战性的基准。

Method: 在主流规划基准上，人工添加细致丰富的自然语言约束（分四类），并对4个SOTA推理大模型、三种形式语言、五种方法，四个数据集进行评测对比。

Result: 引入自然语言约束后，所有大模型规划性能均下降了约一半，并且对问题复杂度和词汇变化的鲁棒性也大幅下降。

Conclusion: 现有LLM的规划能力在缺乏复杂约束的评测下被高估，未来应关注提升其处理实际场景复杂约束的能力。

Abstract: LLMs have been widely used in planning, either as planners to generate action
sequences end-to-end, or as formalizers to represent the planning domain and
problem in a formal language that can derive plans deterministically. However,
both lines of work rely on standard benchmarks that only include generic and
simplistic environmental specifications, leading to potential overestimation of
the planning ability of LLMs and safety concerns in downstream tasks. We bridge
this gap by augmenting widely used planning benchmarks with manually annotated,
fine-grained, and rich natural language constraints spanning four formally
defined categories. Over 4 state-of-the-art reasoning LLMs, 3 formal languages,
5 methods, and 4 datasets, we show that the introduction of constraints not
only consistently halves performance, but also significantly challenges
robustness to problem complexity and lexical shift.

</details>


### [119] [LANTERN: Scalable Distillation of Large Language Models for Job-Person Fit and Explanation](https://arxiv.org/abs/2510.05490)
*Zhoutong Fu,Yihan Cao,Yi-Lin Chen,Aman Lunia,Liming Dong,Neha Saraf,Ruijie Jiang,Yun Dai,Qingquan Song,Tan Wang,Guoyao Li,Derek Koh,Haichao Wei,Zhipeng Wang,Aman Gupta,Chengming Jiang,Jianqiang Shen,Liangjie Hong,Wenjing Zhang*

Main category: cs.CL

TL;DR: 该论文针对大模型在招聘领域“人岗匹配与解释”任务中面临的性能与效率挑战，提出了LANTERN知识蒸馏框架，有效提升了任务表现和用户参与度。


<details>
  <summary>Details</summary>
Motivation: 招聘平台如LinkedIn需要根据候选人简介与岗位要求进行匹配评估和详细解释，直接用大模型存在输出质量不佳与推理效率低等问题，亟需定制化结构与轻量化方案。

Method: 提出LANTERN框架，设计多目标建模，包括分类用的编码器和解释用的解码器，多层次知识蒸馏同时整合数据与logit信息，并结合后训练与Prompt工程优化下游效果。

Result: 实验表明，LANTERN显著提升了人岗匹配和解释的任务指标。在线评测中，提升了0.24%的职位申请率和0.28%的合格申请数。

Conclusion: LANTERN框架有效破解了LLM在招聘领域的适配与效率难题，为其他垂直行业推广提供了有益借鉴。

Abstract: Large language models (LLMs) have achieved strong performance across a wide
range of natural language processing tasks. However, deploying LLMs at scale
for domain specific applications, such as job-person fit and explanation in job
seeking platforms, introduces distinct challenges. At LinkedIn, the job person
fit task requires analyzing a candidate's public profile against job
requirements to produce both a fit assessment and a detailed explanation.
Directly applying open source or finetuned LLMs to this task often fails to
yield high quality, actionable feedback due to the complexity of the domain and
the need for structured outputs. Moreover, the large size of these models leads
to high inference latency and limits scalability, making them unsuitable for
online use. To address these challenges, we introduce LANTERN, a novel LLM
knowledge distillation framework tailored specifically for job person fit
tasks. LANTERN involves modeling over multiple objectives, an encoder model for
classification purpose, and a decoder model for explanation purpose. To better
distill the knowledge from a strong black box teacher model to multiple
downstream models, LANTERN incorporates multi level knowledge distillation that
integrates both data and logit level insights. In addition to introducing the
knowledge distillation framework, we share our insights on post training
techniques and prompt engineering, both of which are crucial for successfully
adapting LLMs to domain specific downstream tasks. Extensive experimental
results demonstrate that LANTERN significantly improves task specific metrics
for both job person fit and explanation. Online evaluations further confirm its
effectiveness, showing measurable gains in job seeker engagement, including a
0.24\% increase in apply rate and a 0.28\% increase in qualified applications.

</details>


### [120] [Prototype-Based Dynamic Steering for Large Language Models](https://arxiv.org/abs/2510.05498)
*Ceyhun Efe Kayan,Li Zhang*

Main category: cs.CL

TL;DR: 该论文提出了一种在无需增加或修改指令的情况下增强大语言模型（LLM）推理能力的方法——基于原型的动态引导（PDS），并在多个任务上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM推理多依赖显式指令或静态引导方式，缺乏无需人为干预且能动态适应的推理增强方法，影响了其适用性与推理自然性。作者旨在填补无需指令、可自适应放大推理能力的空白。

Method: 提出Prototype-Based Dynamic Steering（PDS）方法，通过对链式思考（CoT）与中性提示的激活差异聚类，形成“推理原型”；在推理时将输入的隐藏状态在原型上投影，生成实例特定的引导向量，从而增强LLM的推理能力，无需微调或改写prompt。

Result: 在GSM8K、AQuA-RAT和BIG-Bench等任务上，PDS均显著提升了模型推理准确率，即使在严控推理中间步骤以降低费用的情况下，依然能保持增益，显示出引导作用源于深层推理能力的增强。

Conclusion: PDS是一种无需训练、轻量级但高效的推理增强方案，为提升LLM的推理能力提供了新的工具，对比现有依赖训练或人工作prompt的方法，更具动态性与成本优势。

Abstract: Despite impressive breadth, LLMs still rely on explicit reasoning
instructions or static, one-fits-all steering methods, leaving a gap for
adaptive, instruction-free reasoning amplification. We present Prototype-Based
Dynamic Steering (PDS), a test-time method that amplifies large language model
(LLM) reasoning without adding or altering instructions. We introduce
"reasoning prototypes" by clustering activation differences between
Chain-of-Thought (CoT) and neutral prompts. At inference, an input's hidden
state is projected onto these prototypes to form an instance-specific steering
vector. Evaluated on GSM8K, AQuA-RAT, and BIG-Bench tasks, PDS consistently
improves accuracy without fine-tuning or prompt engineering. Notably, the gains
persist even when CoT is explicitly suppressed to improve cost-efficiency,
indicating that the intervention strengthens latent reasoning processes rather
than inducing a superficial behavioral shift. These results position dynamic,
prototype-guided steering as a lightweight alternative to training-time
approaches for enhancing LLM reasoning.

</details>


### [121] [CAM: A Constructivist View of Agentic Memory for LLM-Based Reading Comprehension](https://arxiv.org/abs/2510.05520)
*Rui Li,Zeyu Zhang,Xiaohe Bo,Zihang Tian,Xu Chen,Quanyu Dai,Zhenhua Dong,Ruiming Tang*

Main category: cs.CL

TL;DR: 本文提出了一种受皮亚杰建构主义理论启发的记忆模块CAM，用于提升大语言模型对长文档的阅读理解能力。该方法通过结构化记忆和灵活激活机制，显著提升了性能与效率。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在处理长文档时面临信息量过大、难以理解的问题，缺乏系统性、高效的记忆机制。现有方法多为启发式，缺少统一的设计原则。

Method: 作者借鉴皮亚杰建构主义理论，提出智能体记忆应具备结构化图式、灵活同化和动态适应三大特性。基于此，提出了建构主义智能体记忆（CAM）原型，核心为递增式重叠聚类算法，能够结构化地构建记忆，支持分层摘要与批量整合。在推理时，CAM自适应地激活与查询相关的信息，实现类人联想过程。

Result: 在长文本阅读理解（如问答、基于查询的摘要、主张验证）等任务上，CAM表现出比现有方法更优的性能和效率。

Conclusion: 本工作为LLM记忆模块设计提供了系统性框架，验证了CAM原型能有效提升长文本的理解能力和执行效率。

Abstract: Current Large Language Models (LLMs) are confronted with overwhelming
information volume when comprehending long-form documents. This challenge
raises the imperative of a cohesive memory module, which can elevate vanilla
LLMs into autonomous reading agents. Despite the emergence of some heuristic
approaches, a systematic design principle remains absent. To fill this void, we
draw inspiration from Jean Piaget's Constructivist Theory, illuminating three
traits of the agentic memory -- structured schemata, flexible assimilation, and
dynamic accommodation. This blueprint forges a clear path toward a more robust
and efficient memory system for LLM-based reading comprehension. To this end,
we develop CAM, a prototype implementation of Constructivist Agentic Memory
that simultaneously embodies the structurality, flexibility, and dynamicity. At
its core, CAM is endowed with an incremental overlapping clustering algorithm
for structured memory development, supporting both coherent hierarchical
summarization and online batch integration. During inference, CAM adaptively
explores the memory structure to activate query-relevant information for
contextual response, akin to the human associative process. Compared to
existing approaches, our design demonstrates dual advantages in both
performance and efficiency across diverse long-text reading comprehension
tasks, including question answering, query-based summarization, and claim
verification.

</details>


### [122] [KEO: Knowledge Extraction on OMIn via Knowledge Graphs and RAG for Safety-Critical Aviation Maintenance](https://arxiv.org/abs/2510.05524)
*Kuangshi Ai,Jonathan A. Karr Jr,Meng Jiang,Nitesh V. Chawla,Chaoli Wang*

Main category: cs.CL

TL;DR: 本论文提出了KEO框架，利用知识图谱与大语言模型结合，提升了在安全关键场景下的知识抽取与推理能力，特别是在全局理解任务上优于传统RAG方法。


<details>
  <summary>Details</summary>
Motivation: 在安全关键领域，现有基于文本分块的RAG方法在全局推理和系统层次洞察上的表现有限，迫切需要更高效、更可靠的领域知识抽取与推理方案。

Method: 提出KEO框架，针对业界OMIn数据集，构建知识图谱，并融合到RAG流程中，联合本地大模型与较强的评判模型（如GPT-4o、Llama-3.3），对全局推理及细粒度任务进行对比评测。

Result: 实验表明，KEO对全局意义建构和系统性洞察能力有显著提升，而针对局部、操作性强的任务，传统RAG依然有效。

Conclusion: KG增强型大模型方案在安全关键领域的问答与高风险推理任务上极具应用前景，有望成为领域知识智能化应用的重要组成。

Abstract: We present Knowledge Extraction on OMIn (KEO), a domain-specific knowledge
extraction and reasoning framework with large language models (LLMs) in
safety-critical contexts. Using the Operations and Maintenance Intelligence
(OMIn) dataset, we construct a QA benchmark spanning global sensemaking and
actionable maintenance tasks. KEO builds a structured Knowledge Graph (KG) and
integrates it into a retrieval-augmented generation (RAG) pipeline, enabling
more coherent, dataset-wide reasoning than traditional text-chunk RAG. We
evaluate locally deployable LLMs (Gemma-3, Phi-4, Mistral-Nemo) and employ
stronger models (GPT-4o, Llama-3.3) as judges. Experiments show that KEO
markedly improves global sensemaking by revealing patterns and system-level
insights, while text-chunk RAG remains effective for fine-grained procedural
tasks requiring localized retrieval. These findings underscore the promise of
KG-augmented LLMs for secure, domain-specific QA and their potential in
high-stakes reasoning.

</details>


### [123] [H1B-KV: Hybrid One-Bit Caches for Memory-Efficient Large Language Model Inference](https://arxiv.org/abs/2510.05529)
*Harshil Vejendla*

Main category: cs.CL

TL;DR: 该论文提出了Hybrid One-Bit KV Cache（H1B-KV），一种新的KV缓存压缩方法，显著减少了大语言模型推理过程中的内存消耗，实现了超大上下文支持，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型推理需缓存海量KV对，导致内存瓶颈；现有KV压缩方法要么只压缩一个分量、要么丢失上下文信息，解决不彻底。

Method: H1B-KV用于key采用1-bit二进制sketch实现高效bitwise注意力机制，value则用4-bit量化，完整压缩KV缓存。并通过轻量级微调修复精度。

Result: 在7B参数模型上，H1B-KV将8k-token上下文的缓存内存降到60MB以内，比原始减少约70倍。经过微调，无论在困惑度还是数学推理、多任务理解和代码生成等下游任务上，H1B-KV都可达到全精度性能，并优于主流压缩和剪枝方法（KIVI、SparseLLM、Loki）。

Conclusion: H1B-KV方法为大语言模型在内存受限环境中的高效部署提供了坚实方案，实现了高“质量-字节”比且几乎无精度损失。

Abstract: Autoregressive decoding in large language models (LLMs) requires caching a
growing list of past key-value (KV) pairs, making long-context inference a
memory-bound problem. While recent methods have explored quantizing the cache,
evicting tokens, or using binary sketches for keys (e.g., Loki), these
approaches often provide an incomplete solution by leaving one component (like
values) uncompressed or by discarding context information. This paper
introduces the Hybrid One-Bit KV Cache (H1B-KV), a comprehensive compression
scheme that radically reduces memory usage without sacrificing context. H1B-KV
represents each key vector using a 1-bit binary sketch, enabling
hardware-friendly bitwise attention, and further compresses value vectors using
4-bit quantization. This holistic, hybrid approach allows a 7-billion parameter
LLM to handle an 8k-token context with under 60 MB of cache memory - a 70x
reduction. We demonstrate that after a lightweight finetuning, H1B-KV matches
full-precision performance not only on perplexity benchmarks but also on
complex downstream tasks like mathematical reasoning (GSM8K), multi-task
understanding (MMLU), and code generation (HumanEval). Our results show H1B-KV
significantly outperforms leading quantization (KIVI), token eviction
(SparseLLM), and key-only sketching (Loki) methods in quality-per-byte,
establishing it as a robust solution for deploying LLMs in memory-constrained
environments.

</details>


### [124] [On the Role of Difficult Prompts in Self-Play Preference Optimization](https://arxiv.org/abs/2510.05534)
*Yao Xiao,Jung-jae Kim,Roy Ka-wei Lee,Lidong Bing*

Main category: cs.CL

TL;DR: 本文研究提示词难度在自博弈偏好优化（self-play preference optimization, SPPO）中对大型语言模型性能的影响，发现只用简单提示词训练效果更好，难题反而拖慢整体进展。通过合理筛除困难提示词，可以提升模型整体性能。


<details>
  <summary>Details</summary>
Motivation: 当前对大型语言模型的对齐优化主要关注回答和奖励模型，忽视了提示词难度的作用。作者旨在揭示提示词难度对自博弈偏好优化效果的影响和最佳实践。

Method: 作者以提示词下N条采样回复的均值奖励作为提示词难度代理，系统比较难/易提示词在DPO训练中的优化效果，并观察模型容量对这一现象的影响。之后实验加入难提示词的删减策略等缓解方案。

Result: 难提示词自博弈优化表现远逊于简单提示词，混合难提示词对整体训练反而有轻微负面影响。仅随模型容量增大，两者性能差距才逐渐缩小。通过筛除部分困难提示词可显著改善整体效果。

Conclusion: 优化SPPO时，当前模型能力不足时不宜加入太多困难提示词训练，否则整体表现下降。建议控制提示词难度分布，针对模型能力采用相应筛选机制。

Abstract: Self-play preference optimization has emerged as a prominent paradigm for
aligning large language models (LLMs). It typically involves a language model
to generate on-policy responses for prompts and a reward model (RM) to guide
the selection of chosen and rejected responses, which can be further trained
with direct preference optimization (DPO). However, the role of prompts remains
underexplored, despite being a core component in this pipeline. In this work,
we investigate how prompts of varying difficulty influence self-play preference
optimization. We first use the mean reward of $N$ sampled responses of a prompt
as a proxy for its difficulty. We find that difficult prompts exhibit
substantially inferior self-play optimization performance in comparison to easy
prompts for language models. Moreover, incorporating difficult prompts into
training fails to enhance overall performance and, in fact, leads to slight
degradation compared to training on easy prompts alone. We also observe that
the performance gap between difficult and easy prompts closes as the model
capacity increases, suggesting that difficulty interacts with the model
capacity. Building on these findings, we explore strategies to mitigate the
negative effect of difficult prompts on final performance. We demonstrate that
selectively removing an appropriate portion of challenging prompts enhances
overall self-play performance, while also reporting failed attempts and lessons
learned.

</details>


### [125] [Activation-Informed Pareto-Guided Low-Rank Compression for Efficient LLM/VLM](https://arxiv.org/abs/2510.05544)
*Ryan Solgi,Parsa Madinei,Jiayi Tian,Rupak Swaminathan,Jing Liu,Nathan Susanj,Zheng Zhang*

Main category: cs.CL

TL;DR: 提出了一种新的低秩压缩框架，用来优化大型语言模型（LLM）和视觉-语言模型（VLM）的部署效率。


<details>
  <summary>Details</summary>
Motivation: LLM和VLM虽然性能优越，但在实际部署时带来了显著的内存和计算压力，需要更高效的模型压缩方法。

Method: 提出通过基于激活的分层低秩压缩误差来上界网络损失，并将低秩压缩问题视为双目标优化，推导出统一容忍度下的近似最优秩分配。基于此理论，提出了PGSVD（Pareto-Guided SVD）零样本压缩方法，实现秩选择和交替最小二乘优化。

Result: PGSVD在LLM和VLM上的实验结果显示，相同压缩率下，PGSVD相比已有方法有更高的模型精度和推理速度提升。

Conclusion: PGSVD为大模型的高效压缩和快速部署提供了新思路，兼顾模型性能和计算资源消耗。

Abstract: Large language models (LLM) and vision-language models (VLM) have achieved
state-of-the-art performance, but they impose significant memory and computing
challenges in deployment. We present a novel low-rank compression framework to
address this challenge. First, we upper bound the change of network loss via
layer-wise activation-based compression errors, filling a theoretical gap in
the literature. We then formulate low-rank model compression as a bi-objective
optimization and prove that a single uniform tolerance yields surrogate
Pareto-optimal heterogeneous ranks. Based on our theoretical insights, we
propose Pareto-Guided Singular Value Decomposition (PGSVD), a zero-shot
pipeline that improves activation-aware compression via Pareto-guided rank
selection and alternating least-squares implementation. We apply PGSVD to both
LLM and VLM, showing better accuracy at the same compression levels and
inference speedup.

</details>


### [126] [Presenting a Paper is an Art: Self-Improvement Aesthetic Agents for Academic Presentations](https://arxiv.org/abs/2510.05571)
*Chengzhi Liu,Yuzhe Yang,Kaiwen Zhou,Zhen Zhang,Yue Fan,Yannan Xie,Peng Qi,Xin Eric Wang*

Main category: cs.CL

TL;DR: 该论文提出了EvoPresent——一个可以自我改进的学术论文推广演示生成框架，利用多任务强化学习提升演示的叙事连贯性与美学质量，并通过全新基准集进行系统评估。


<details>
  <summary>Details</summary>
Motivation: 现有自动化学术论文推广方法在叙事性、美观性和自我调整能力上存在局限，影响了论文的有效传播。核心问题在于缺乏可靠的评估方式，无法指导改进。

Method: 提出了EvoPresent自我改进代理框架，结合连贯叙事、美学设计及虚拟角色模拟展示。引入多任务强化学习的美学模型PresAesth，兼顾美学打分、缺陷修正和比较反馈。还构建了EvoPresent Benchmark，包括生成质量评估和美学意识评估两部分。

Result: 实验证明：1）高质量反馈对代理自我提升至关重要，仅有初始能力不足以实现有效自我校正；2）自动化生成流程在视觉设计和内容构建之间存在权衡；3）多任务强化学习训练在美学意识任务上展现更强的泛化能力。

Conclusion: EvoPresent显著提升学术论文自动推广系统的自我改进能力，能兼顾叙事性与美观性，并为后续相关研究提供系统的基准和方法参考。

Abstract: The promotion of academic papers has become an important means of enhancing
research visibility. However, existing automated methods struggle limited
storytelling, insufficient aesthetic quality, and constrained self-adjustment,
making it difficult to achieve efficient and engaging dissemination. At the
heart of those challenges is a simple principle: \emph{there is no way to
improve it when you cannot evaluate it right}. To address this, we introduce
\textbf{EvoPresent}, a self-improvement agent framework that unifies coherent
narratives, aesthetic-aware designs, and realistic presentation delivery via
virtual characters. Central to EvoPresent is \textbf{PresAesth}, a multi-task
reinforcement learning (RL) aesthetic model that provides reliable aesthetic
scoring, defect adjustment, and comparative feedback, enabling iterative
self-improvement even under limited aesthetic training data. To systematically
evaluate the methods, we introduce \textbf{EvoPresent Benchmark}, a
comprehensive benchmark comprising: \textit{Presentation Generation Quality},
built on 650 top-tier AI conference papers with multimodal resources (slides,
videos and scripts) to assess both content and design; and \textit{Aesthetic
Awareness}, consisting of 2,000 slide pairs with varying aesthetic levels,
supporting joint training and evaluation on scoring, defect adjustment, and
comparison. Our findings highlight that (i) High-quality feedback is essential
for agent self-improvement, while initial capability alone does not guarantee
effective self-correction. (ii) Automated generation pipelines exhibit a
trade-off between visual design and content construction. (iii) Multi-task RL
training shows stronger generalization in aesthetic awareness tasks.

</details>


### [127] [Mission Impossible: Feedback-Guided Dynamic Interactive Planning for Improving Reasoning on LLMs](https://arxiv.org/abs/2510.05577)
*Dong Yan,Gaochen Wu,Bowen Zhou*

Main category: cs.CL

TL;DR: 本文提出了一种新的反馈引导动态交互式规划（FGDIP）框架，提升大语言模型在开放域多跳推理任务中的表现，实验结果显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前多跳推理的语言智能体在开放域问题上的表现受限，主要因为其依赖固定的推理操作序列，难以高效检索和整合大规模信息。需要开发更能适应动态信息探索和推理的机制。

Method: 提出反馈引导动态交互式规划（FGDIP）框架，通过识别关键实体，采用深度优先搜索与创新节点生成方法，结合历史错误分析和实时反馈，动态调整推理路径和节点生成策略，从而有效扩展搜索空间并提升推理准确性。

Result: FGDIP在HotpotQA数据集上获得54.47%的F1分数，在StrategyQA数据集上达70.05%，比现有最佳基线分别提升5.03%和7.25%。

Conclusion: FGDIP框架在多跳推理任务中展现出优异性能和通用性，可有效提升语言模型在复杂推理场景下的能力，对开放域推理等问题具有实际意义。

Abstract: Recent advancements in language agents have led to significant improvements
in multi-hop reasoning tasks. However, existing approaches often struggle with
handling open-domain problems, which require massive information retrieval due
to their reliance on a fixed sequence of actions. To address this, we propose
Feedback-Guided Dynamic Interactive Planning (FGDIP), a novel framework
tailored to enhance reasoning in LLMs by utilizing dynamic and adaptive
strategies for information exploration in open-domain multi-hop reasoning
tasks. Our approach begins by identifying key entities relevant to the problem,
which serve as the initial nodes in the reasoning process. From these initial
nodes, we then generate reasoning child nodes with the process being refined
through a combination of historical error analysis and real-time feedback,
which allows the framework to dynamically adjust and optimize its reasoning
strategies. By integrating depth-first search with an innovative node
generation technique, our framework adapts based on both prior error paths and
concurrently generated nodes at the same hierarchical level. This dynamic
strategy effectively expands the search space while ensuring the reasoning
process systematically converges toward accurate solutions. Experimental
results show that FGDIP achieved up to 54.47% F1 score on the HotpotQA dataset
and 70.05% on the StrategyQA dataset, surpassing the best baseline by 5.03% and
7.25% respectively, highlighting its versatility and potential to enhance
language agents in multi-hop reasoning tasks.

</details>


### [128] [A Goal Without a Plan Is Just a Wish: Efficient and Effective Global Planner Training for Long-Horizon Agent Tasks](https://arxiv.org/abs/2510.05608)
*Shuzheng Si,Haozhe Zhao,Kangyang Luo,Gang Chen,Fanchao Qi,Minjia Zhang,Baobao Chang,Maosong Sun*

Main category: cs.CL

TL;DR: 本论文提出了一种名为EAGLET的新方法，通过训练高效的全局规划器来增强大模型智能体在复杂、长序列任务中的规划与执行能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型驱动的智能体在长程任务中常常表现为盲目试错和“幻觉”式决策，根本原因是缺乏全局性的规划能力，难以系统性完成多步任务。提升智能体的整体规划水平是智能体进阶与实用部署的关键。

Method: 作者设计了“计划-执行”框架，并提出EAGLET规划器。训练分为两步：1）利用高级大模型生成高质量计划，并通过同源共识过滤确保计划质量，结合微调完成冷启动；2）基于规则的强化学习和新颖的“执行能力增益奖励”进一步提升规划器适应不同任务难度的能力。整个过程无需人工标注，实现端到端自动化训练。

Result: 实验覆盖三类长时序任务，结果显示搭载EAGLET规划器的执行智能体显著超越已有的各类方法，达成新的SOTA记录。同时，与传统RL方法相比，训练成本降低了8倍，无需额外人工和数据。

Conclusion: EAGLET方法兼具高效性与有效性，极大提升了执行智能体的任务规划与执行上限，为实际部署大模型智能体提供了新的解决方案。

Abstract: Agents based on large language models (LLMs) struggle with brainless
trial-and-error and generating hallucinatory actions due to a lack of global
planning in long-horizon tasks. In this paper, we introduce a plan-and-execute
framework and propose EAGLET, an efficient and effective planner training
method to enhance the executor agent's planning abilities without human effort.
Specifically, we train a plug-and-play global planner through a two-step
process: we first synthesize high-quality plans from an advanced LLM using our
proposed homologous consensus filtering strategy, and apply fine-tuning as a
cold start. Moreover, we further improve the planner with a rule-based
reinforcement learning stage using a novel executor capability gain reward,
ensuring it can handle task instructions of varying difficulty. Experiments on
three long-horizon agent tasks show that executor agents equipped with our
planner outperform existing methods, achieving new state-of-the-art
performance. Meanwhile, EAGLET reduces training costs by 8x compared to
RL-based baselines, and it does not require manual effort or extra training
data, offering an efficient and effective solution.

</details>


### [129] [MADIAVE: Multi-Agent Debate for Implicit Attribute Value Extraction](https://arxiv.org/abs/2510.05611)
*Wei-Chieh Huang,Cornelia Caragea*

Main category: cs.CL

TL;DR: 论文提出了一种基于多代理辩论的隐式属性值抽取方法，通过多回合讨论提升了在多模态电商环境下的推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型虽然发展迅速，但隐式属性值抽取依然受限于多维数据复杂性和视觉文本理解的不足，因此亟需新的方法提升推理精度和鲁棒性。

Method: 提出了\textsc{\modelname}，即多代理辩论框架，利用多个多模态大语言模型代理，反复多轮辩论互相校验与更新答案，提高了属性推理的准确度和稳定性。探讨了同质与异质代理及不同辩论轮数对效果的影响。

Result: 在ImplicitAVE数据集上，少量辩论轮数即可显著提升模型在低基线性能属性上的准确率。系统评估显示代理配置和辩论轮数对模型性能有直接影响。

Conclusion: 多代理辩论策略能有效弥补单一代理在隐式属性抽取上的局限，为多模态电商场景带来可扩展的解决方案。

Abstract: Implicit Attribute Value Extraction (AVE) is essential for accurately
representing products in e-commerce, as it infers lantent attributes from
multimodal data. Despite advances in multimodal large language models (MLLMs),
implicit AVE remains challenging due to the complexity of multidimensional data
and gaps in vision-text understanding. In this work, we introduce
\textsc{\modelname}, a multi-agent debate framework that employs multiple MLLM
agents to iteratively refine inferences. Through a series of debate rounds,
agents verify and update each other's responses, thereby improving inference
performance and robustness. Experiments on the ImplicitAVE dataset demonstrate
that even a few rounds of debate significantly boost accuracy, especially for
attributes with initially low performance. We systematically evaluate various
debate configurations, including identical or different MLLM agents, and
analyze how debate rounds affect convergence dynamics. Our findings highlight
the potential of multi-agent debate strategies to address the limitations of
single-agent approaches and offer a scalable solution for implicit AVE in
multimodal e-commerce.

</details>


### [130] [The African Languages Lab: A Collaborative Approach to Advancing Low-Resource African NLP](https://arxiv.org/abs/2510.05644)
*Sheriff Issaka,Keyi Wang,Yinka Ajibola,Oluwatumininu Samuel-Ipaye,Zhaoyi Zhang,Nicte Aguillon Jimenez,Evans Kofi Agyei,Abraham Lin,Rohan Ramachandran,Sadick Abdul Mumin,Faith Nchifor,Mohammed Shuraim,Lieqi Liu,Erick Rosas Gonzalez,Sylvester Kpei,Jemimah Osei,Carlene Ajeneza,Persis Boateng,Prisca Adwoa Dufie Yeboah,Saadia Gabriel*

Main category: cs.CL

TL;DR: 本文提出了一个名为African Languages Lab (ALL Lab)的研究项目，通过系统性收集数据和开发模型，极大提升了非洲语言在NLP领域的支持水平。


<details>
  <summary>Details</summary>
Motivation: 尽管非洲语言数量众多，但在现代自然语言处理技术中极度缺乏资源，多数语言被严重忽视。该项目旨在填补这一技术空白。

Method: 该研究建立了一个高质量数据收集流程，获得了覆盖40种非洲语言、包含19亿词单语文本和12628小时语音数据的大型多模态数据集。并通过模型微调和与现有系统（如Google Translate）的比较，进行了广泛的实验验证。

Result: 实验结果显示，项目数据集经过微调后，模型在31种语言上的ChrF++、COMET和BLEU等指标均大幅提升，平均分别提高了+23.69、+0.33和+15.34分。部分语言结果已接近或超过Google Translate。

Conclusion: ALL Lab为非洲语言NLP发展带来了显著进步，包括数据资源建设、模型性能提升及人才培养，同时指出仍有改进空间。

Abstract: Despite representing nearly one-third of the world's languages, African
languages remain critically underserved by modern NLP technologies, with 88\%
classified as severely underrepresented or completely ignored in computational
linguistics. We present the African Languages Lab (All Lab), a comprehensive
research initiative that addresses this technological gap through systematic
data collection, model development, and capacity building. Our contributions
include: (1) a quality-controlled data collection pipeline, yielding the
largest validated African multi-modal speech and text dataset spanning 40
languages with 19 billion tokens of monolingual text and 12,628 hours of
aligned speech data; (2) extensive experimental validation demonstrating that
our dataset, combined with fine-tuning, achieves substantial improvements over
baseline models, averaging +23.69 ChrF++, +0.33 COMET, and +15.34 BLEU points
across 31 evaluated languages; and (3) a structured research program that has
successfully mentored fifteen early-career researchers, establishing
sustainable local capacity. Our comparative evaluation against Google Translate
reveals competitive performance in several languages while identifying areas
that require continued development.

</details>


### [131] [Code-Switching In-Context Learning for Cross-Lingual Transfer of Large Language Models](https://arxiv.org/abs/2510.05678)
*Haneul Yoo,Jiho Jin,Kyunghyun Cho,Alice Oh*

Main category: cs.CL

TL;DR: 本论文提出了一种通过代码切换（code-switching）来提升大语言模型多语言推理能力的新方法（CSICL），并在多种模型、语言和数据集上验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型虽然具备较强的多语言能力，但其内部主要依赖英文隐式表征，因此在非英语场景下推理能力明显下降，影响多语言应用的普适性。现有基于单一语言示例的方法难以缓解这一障碍，反而会加剧语言隔阂。

Method: 作者提出了一种代码切换的上下文学习策略（CSICL），在提示（prompt）和示例展示过程中逐步从目标语言过渡到英文，帮助模型在推理时更好地利用其英文表征能力。它通过显式控制的语言过渡，起到语言桥梁作用，改善跨语言对齐。方法在4个LLM、6个数据集、10种语言上进行了大量实证测试。

Result: CSICL 在目标语言和未见语言的基准测试中均显著优于传统单语上下文方法，分别提升3.1%和1.9%；在低资源语言环境下提升更加显著（目标语14.7%，未见语5.3%）。

Conclusion: 代码切换（CSICL）是一种有效且稳健的多语言推理辅助策略，有助于突破现有的翻译壁垒，提升多语言LLM系统的公平性与实用性。

Abstract: While large language models (LLMs) exhibit strong multilingual abilities,
their reliance on English as latent representations creates a translation
barrier, where reasoning implicitly depends on internal translation into
English. When this process fails, performance in non-English languages
deteriorates sharply, limiting the inclusiveness of LLM-based applications.
Existing cross-lingual in-context learning (X-ICL) methods primarily leverage
monolingual demonstrations, often failing to mitigate this barrier and instead
reinforcing it. In this work, we introduce code-switching in-context learning
(CSICL), a simple yet effective prompting strategy that progressively
transitions from a target language to English within demonstrations and
instruction to facilitate their latent reasoning in English. By explicitly
scaffolding the reasoning process through controlled code-switching, CSICL acts
as an implicit linguistic bridge that enhances cross-lingual alignment and
reduces reliance on the translation barrier. We conduct extensive experiments
across 4 LLMs, 6 datasets, and 10 languages, spanning both knowledge-intensive
and reasoning-oriented domains. Our results demonstrate that CSICL consistently
outperforms X-ICL baselines, achieving gains of 3.1%p and 1.9%p in both target
and unseen languages, respectively. The improvement is even more pronounced in
low-resource settings, with gains of 14.7% in target and 5.3% in unseen
languages. These findings establish code-switching as a principled and robust
approach for overcoming the translation barrier during inference, moving LLMs
toward more equitable and effective multilingual systems.

</details>


### [132] [DecEx-RAG: Boosting Agentic Retrieval-Augmented Generation with Decision and Execution Optimization via Process Supervision](https://arxiv.org/abs/2510.05691)
*Yongqi Leng,Yikun Lei,Xikai Liu,Meizhi Zhong,Bojian Xiong,Yurong Zhang,Yan Gao,Yi Wu,Yao Hu,Deyi Xiong*

Main category: cs.CL

TL;DR: 本文提出DecEx-RAG方法，通过引入高效剪枝和流程级策略优化，提升大模型在Agentic RAG任务中的自主分解和答案生成能力，性能明显优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 虽然基于强化学习的Agentic RAG方法在复杂任务中表现出色，但仍受到探索低效、奖励稀疏和全局反馈模糊等问题困扰，需要新的机制加以改进。

Method: 作者将检索增强生成(RAG)建模为马尔科夫决策过程（MDP），并结合决策-执行结构，通过引入高效剪枝策略，优化数据扩展过程，同时进行全面的流程级策略优化。

Result: 在六个数据集上的实验显示，DecEx-RAG平均性能提升6.2%，有效超过现有基线方法；剪枝策略使数据构建效率提升近6倍。

Conclusion: DecEx-RAG为流程监督的RAG训练提供了高效方案，极大增强了大模型的自主任务分解和答案生成能力。

Abstract: Agentic Retrieval-Augmented Generation (Agentic RAG) enhances the processing
capability for complex tasks through dynamic retrieval and adaptive workflows.
Recent advances (e.g., Search-R1) have shown that outcome-supervised
reinforcement learning demonstrate strong performance. However, this approach
still suffers from inefficient exploration, sparse reward signals, and
ambiguous global reward feedback. To address these challenges, we propose
DecEx-RAG, which models RAG as a Markov Decision Process (MDP) incorporating
decision-making and execution, while introducing an efficient pruning strategy
to optimize data expansion. Through comprehensive process-level policy
optimization, DecEx-RAG significantly enhances the autonomous task
decomposition, dynamic retrieval, and high-quality answer generation
capabilities of large language models (LLMs). Experiments show that DecEx-RAG
achieves an average absolute performance improvement of $6.2\%$ across six
datasets, significantly outperforming existing baselines. Moreover, the pruning
strategy improves data construction efficiency by nearly $6 \times$, providing
an efficient solution for process-supervised RAG training. The code is
available at https://github.com/sdsxdxl/DecEx-RAG.

</details>


### [133] [Adaptive and Multi-Source Entity Matching for Name Standardization of Astronomical Observation Facilities](https://arxiv.org/abs/2510.05744)
*Liza Fretel,Baptiste Cecconi,Laura Debisschop*

Main category: cs.CL

TL;DR: 该论文提出了一种多源天文观测设施映射方法，利用NLP和大模型提升同义词实体的标准化及合理性，促进天文领域术语的一致性。


<details>
  <summary>Details</summary>
Motivation: 目前天文领域存在数据孤岛和多源异构知识库，缺乏统一标准，导致不同数据库和平台之间的实体不易关联，影响数据集成和知识共享，因此需研发多源实体映射与统一方法。

Method: 作者综合使用NLP技术（词袋法、序列方法与表面方法），基于实体的各种属性（如标签、定义、描述、观测波段、发射日期等）从八个不同语义资源中提取潜在实体，并计算多维评分进行实体映射，最后借助大语言模型（LLM）对映射候选进行人工智能审核和合理性判定，确保映射结果的可解释性和FAIR原则。

Result: 该方法生成了多源同义实体映射集，为每个实体指定唯一标准标签，显著提升了不同知识库之间的实体一致性。映射结果被集成到Name Resolver API，可进一步应用于IVOA和OntoPortal-Astro平台，支持天文领域术语和实体的互操作。

Conclusion: 新方法实现了多源天文数据实体的标准化映射，提升了术语互通性与数据可复用性，为天文领域知识管理和数据共享提供重要支撑。

Abstract: This ongoing work focuses on the development of a methodology for generating
a multi-source mapping of astronomical observation facilities. To compare two
entities, we compute scores with adaptable criteria and Natural Language
Processing (NLP) techniques (Bag-of-Words approaches, sequential approaches,
and surface approaches) to map entities extracted from eight semantic
artifacts, including Wikidata and astronomy-oriented resources. We utilize
every property available, such as labels, definitions, descriptions, external
identifiers, and more domain-specific properties, such as the observation
wavebands, spacecraft launch dates, funding agencies, etc. Finally, we use a
Large Language Model (LLM) to accept or reject a mapping suggestion and provide
a justification, ensuring the plausibility and FAIRness of the validated
synonym pairs. The resulting mapping is composed of multi-source synonym sets
providing only one standardized label per entity. Those mappings will be used
to feed our Name Resolver API and will be integrated into the International
Virtual Observatory Alliance (IVOA) Vocabularies and the OntoPortal-Astro
platform.

</details>


### [134] [Diversity Is All You Need for Contrastive Learning: Spectral Bounds on Gradient Magnitudes](https://arxiv.org/abs/2510.05767)
*Peter Ochieng*

Main category: cs.CL

TL;DR: 论文提出了非渐近的谱带，用于限制InfoNCE梯度范数，并基于谱信息优化了batch选择和训练方法，从而在主流数据集上显著加速收敛并降低梯度方差。


<details>
  <summary>Details</summary>
Motivation: 现有自监督对比学习算法中的InfoNCE损失，其梯度范数与批次内样本分布、温度参数等密切相关，但对这些关系缺乏定量刻画与利用。优化batch选择和训练策略有望提升收敛速度和模型表现。

Method: 作者推导了InfoNCE梯度范数与对齐度、温度、batch谱之间的关系的理论上界，提出用有效秩作为谱各向异性代理，并基于谱信息设计了一种快速贪心batch选择策略；结合in-batch whitening方法以提升各向同性并降低梯度方差。

Result: 在ImageNet-100上，提出的Greedy-64 batch选择方法相较于随机分组与先进方法（如Pool--P3）在精度相同下分别提升了15%与24%的训练加速；在CIFAR-10上也获得了类似效果。采用in-batch whitening能使短期（50步）梯度方差下降1.37倍，达到理论预期。

Conclusion: 谱感知的batch选择与whitening联合能有效提升对比学习训练效率和稳定性。理论与实验均表明，该方案可在保证准确率的前提下大幅缩短训练时间并改善梯度动态。

Abstract: We derive non-asymptotic spectral bands that bound the squared InfoNCE
gradient norm via alignment, temperature, and batch spectrum, recovering the
\(1/\tau^{2}\) law and closely tracking batch-mean gradients on synthetic data
and ImageNet. Using effective rank \(R_{\mathrm{eff}}\) as an anisotropy proxy,
we design spectrum-aware batch selection, including a fast greedy builder. On
ImageNet-100, Greedy-64 cuts time-to-67.5\% top-1 by 15\% vs.\ random (24\%
vs.\ Pool--P3) at equal accuracy; CIFAR-10 shows similar gains. In-batch
whitening promotes isotropy and reduces 50-step gradient variance by
\(1.37\times\), matching our theoretical upper bound.

</details>


### [135] [InforME: Improving Informativeness of Abstractive Text Summarization With Informative Attention Guided by Named Entity Salience](https://arxiv.org/abs/2510.05769)
*Jianbin Shen,Christy Jie Liang,Junyu Xuan*

Main category: cs.CL

TL;DR: 本文提出了一种新的抽象文本摘要方法，以提高摘要的信息量，通过引入基于最优传输的信息注意力和对命名实体的联合熵降低方法，实验在主流数据集上指标提升显著。


<details>
  <summary>Details</summary>
Motivation: 大数据时代需求将大量长文本高效转化为简练、有条理且信息丰富的摘要，当前抽象文本摘要方法在信息性上仍有提升空间。

Method: 方法包括两部分：（1）基于最优传输的信息性注意力机制，提升对参考摘要中关键信息的学习能力；（2）利用对命名实体的联合熵积累降低法，使摘要包含更多重要信息。

Result: 在CNN/Daily Mail数据集上ROUGE分数优于现有方法，在XSum数据集上具有竞争力。人工评估也显示新方法在信息性上优于强基线。

Conclusion: 提出的方法有效提升了摘要的信息性，自动和人工评测均有较好表现，分析也给出了方法优越性的原因。

Abstract: Abstractive text summarization is integral to the Big Data era, which demands
advanced methods to turn voluminous and often long text data into concise but
coherent and informative summaries for efficient human consumption. Despite
significant progress, there is still room for improvement in various aspects.
One such aspect is to improve informativeness. Hence, this paper proposes a
novel learning approach consisting of two methods: an optimal transport-based
informative attention method to improve learning focal information in reference
summaries and an accumulative joint entropy reduction method on named entities
to enhance informative salience. Experiment results show that our approach
achieves better ROUGE scores compared to prior work on CNN/Daily Mail while
having competitive results on XSum. Human evaluation of informativeness also
demonstrates the better performance of our approach over a strong baseline.
Further analysis gives insight into the plausible reasons underlying the
evaluation results.

</details>


### [136] [Mixture of Neuron Experts](https://arxiv.org/abs/2510.05781)
*Runxi Cheng,Yuchen Guan,Yucheng Ding,Qingguo Hu,Yongxian Wei,Chun Yuan,Yelong Shen,Weizhu Chen,Yeyun Gong*

Main category: cs.CL

TL;DR: 本文提出了一种基于神经元粒度专家选择的稀疏专家模型MoNE，仅激活高激活值神经元以提升推理效率与参数利用率，在不降低性能的情况下显著减少激活参数量。


<details>
  <summary>Details</summary>
Motivation: 现有MoE（专家混合）模型在推理时，虽然通过激活部分专家实现了模型稀疏性，但实际被激活参数仍有冗余，可能影响计算效率与硬件普适性。因此需要更细粒度（如神经元级别）的参数优化方法，进一步提升稀疏性和推理效率。

Method: 作者对主流MoE模型进行稀疏化实验，按激活大小对参数排序并逐步裁剪，被裁剪60%参数时性能几乎无损。分析专家内部神经元，大多激活值趋近于零，遂在预训练时仅选择激活值高的神经元，提出Mixture of Neuron Experts (MoNE)：在每个专家内对神经元做top-k选择，无需额外路由参数或专家间通信，延迟极低。

Result: MoNE在只激活传统MoE一半参数（50%）的情况下，实现了与传统MoE相当的性能；在激活参数量相等情况下，MoNE始终优于传统MoE。

Conclusion: MoNE模型能大幅提升MoE模型的参数利用率和推理效率，是提高稀疏专家模型实际可用性和硬件友好性的有效手段。

Abstract: In this work, we first explore whether the parameters activated by the MoE
layer remain highly sparse at inference. We perform a sparsification study on
several representative MoE models. For each expert, we rank parameters by the
magnitude of their activations from the gate projection and progressively prune
the activated subset. Pruning up to 60% of parameters within that subset causes
only negligible task-performance degradation; substantial drops occur only
after more than 90% are removed. We further decompose experts into
neuron-granular MoE and visualize their activation values, finding that most
neuron activations are near zero. This observation motivates us to select only
high-activation neuron experts during pretraining. Based on this insight, we
propose Mixture of Neuron Experts (MoNE). MoNE achieves neuron-granular expert
selection by only applying a simple top-k selection within each expert, incurs
negligible latency, and requires no additional routing parameters or
inter-expert communication. Extensive experiments demonstrate that MoNE matches
traditional MoE performance while activating only 50% of the MoE-layer
parameters, and it consistently outperforms traditional MoE when compared at
equal numbers of activated parameters. These results suggest that MoNE is a
practical approach to improving parameter utilization and inference efficiency
in MoE-like models.

</details>


### [137] [Data-efficient Targeted Token-level Preference Optimization for LLM-based Text-to-Speech](https://arxiv.org/abs/2510.05799)
*Rikuto Kotoge,Yuichi Sasaki*

Main category: cs.CL

TL;DR: 本文提出了一种新的TTS（文本到语音）系统优化方法TKTO，无需成对的数据，可在更细粒度的token级别实现自动化对齐和优化，有效提升准确性和自然度。


<details>
  <summary>Details</summary>
Motivation: 现有TTS系统通过人类偏好优化提高模型自然度和健壮性，但普遍依赖于成对的优劣样本，而utterance级别的配对不易获得且难以实现发音层面的细粒度优化。

Method: 提出TKTO方法，无需样本对，通过直接作用于token级单位，实现无需人工注释的自动细粒度对齐与奖励信号分配。

Result: 在日语TTS实验中，TKTO方法使准确性提升39%，CER（字符错误率）降低54%，指定token获得的奖励信号增强12.8倍。

Conclusion: TKTO能够以无需成对样本的方式，精细地优化TTS系统输出，在语音自然度、准确性等方面大幅提升系统性能。

Abstract: Aligning text-to-speech (TTS) system outputs with human feedback through
preference optimization has been shown to effectively improve the robustness
and naturalness of language model-based TTS models. Current approaches
primarily require paired desirable and undesirable samples at the utterance
level. However, such pairs are often limited in TTS output data, and
utterance-level formulation prevents fine-grained token-level optimization
needed for accurate pronunciation alignment. In this study, we propose TKTO
that eliminates the need for paired data, enabling a more data-efficient
training paradigm, and directly targets token-level units, automatically
providing fine-grained alignment signals without token-level annotations. TKTO
improves the challenging Japanese TTS accuracy by 39% and reduces CER by 54%,
automatically assigning 12.8 times stronger reward to targeted tokens.

</details>


### [138] [EEPO: Exploration-Enhanced Policy Optimization via Sample-Then-Forget](https://arxiv.org/abs/2510.05837)
*Liang Chen,Xueting Han,Qizhou Wang,Bo Han,Jing Bai,Hinrich Schutze,Kam-Fai Wong*

Main category: cs.CL

TL;DR: 本文提出了一种名为探索增强策略优化（EEPO）的新方法，通过两阶段采样和自适应遗忘来提升大语言模型在有验证奖励的强化学习（RLVR）中的探索能力，解决现有方法过度利用、探索受限的问题。在五项推理基准评测中，EEPO在多个模型上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前RLVR方法过于强调利用，导致策略熵崩溃和探索能力减弱，进而限制了大语言模型的性能提升。即使通过增加策略随机性以提升探索，也难以跳出主导行为模式，形成自我强化的闭环。为解决探索受限和性能提升瓶颈，亟需新方法激励多样探索。

Method: 提出EEPO探索增强策略优化框架，在每次策略优化采样时分为两阶段：第一阶段，模型常规采样生成一半轨迹；随后对已采样内容进行轻量级遗忘，临时抑制这些响应。在第二阶段，模型必须探索输出空间中的不同区域，从而打破只围绕主导模式采样的惯性，扩大输出多样性。

Result: 在五个推理基准的实验中，EEPO方法分别在Qwen2.5-3B、Llama3.2-3B-Instruct和Qwen3-8B-Base模型上相较当前主流方法（如GRPO）获得了24.3%、33.0%、10.4%的平均性能提升。

Conclusion: EEPO通过引入两阶段采样与自适应遗忘机制，有效打破自我强化闭环，强化了RLVR中大语言模型的探索能力，并在多项推理任务中实现了显著的性能提升。

Abstract: Balancing exploration and exploitation remains a central challenge in
reinforcement learning with verifiable rewards (RLVR) for large language models
(LLMs). Current RLVR methods often overemphasize exploitation, leading to
entropy collapse, diminished exploratory capacity, and ultimately limited
performance gains. Although techniques that increase policy stochasticity can
promote exploration, they frequently fail to escape dominant behavioral modes.
This creates a self-reinforcing loop-repeatedly sampling and rewarding dominant
modes-that further erodes exploration. We introduce Exploration-Enhanced Policy
Optimization (EEPO), a framework that promotes exploration via two-stage
rollouts with adaptive unlearning. In the first stage, the model generates half
of the trajectories; it then undergoes a lightweight unlearning step to
temporarily suppress these sampled responses, forcing the second stage to
explore different regions of the output space. This sample-then-forget
mechanism disrupts the self-reinforcing loop and promotes wider exploration
during rollouts. Across five reasoning benchmarks, EEPO outperforms GRPO,
achieving average relative gains of 24.3% on Qwen2.5-3B, 33.0% on
Llama3.2-3B-Instruct, and 10.4% on Qwen3-8B-Base.

</details>


### [139] [Luth: Efficient French Specialization for Small Language Models and Cross-Lingual Transfer](https://arxiv.org/abs/2510.05846)
*Maxence Lasbordes,Sinoué Gad*

Main category: cs.CL

TL;DR: 本文介绍了Luth，一种针对法语优化的小型语言模型（SLMs），通过高质量法语数据后训练取得了领先性能，并提出模型融合进一步提升英法双语能力。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）以英文为主，针对法语等其他主要语言，尤其是在小型模型规模下，性能明显落后，相关高效适配研究有限。

Method: 对高质量的法语语料进行有针对性的后训练，开发出法语专用的Luth模型家族，并通过模型策略性融合提升性能。

Result: Luth在多个法语基准测试中，超越现有同级别开源模型，同时保留了原有的英文能力。模型融合策略进一步提升了英法双语表现。

Conclusion: Luth成为法语小型语言模型的新标杆，并为后续法语相关研究提供了坚实的基线。

Abstract: The landscape of Large Language Models (LLMs) remains predominantly
English-centric, resulting in a significant performance gap for other major
languages, such as French, especially in the context of Small Language Models
(SLMs). Existing multilingual models demonstrate considerably lower performance
in French compared to English, and research on efficient adaptation methods for
French remains limited. To address this, we introduce \textbf{Luth}, a family
of French-specialized SLMs: through targeted post-training on curated,
high-quality French data, our models outperform all open-source counterparts of
comparable size on multiple French benchmarks while retaining their original
English capabilities. We further show that strategic model merging enhances
performance in both languages, establishing Luth as a new state of the art for
French SLMs and a robust baseline for future French-language research.

</details>


### [140] [DACP: Domain-Adaptive Continual Pre-Training of Large Language Models for Phone Conversation Summarization](https://arxiv.org/abs/2510.05858)
*Xue-Yong Fu,Elena Khasanova,Md Tahmid Rahman Laskar,Harsh Saini,Shashi Bhushan TN*

Main category: cs.CL

TL;DR: 本文提出利用持续预训练来适应大语言模型（LLMs）处理真实、嘈杂的对话转录文本，总结实验显示该方法能显著提升对话摘要的效果，具备较强泛化与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在专门领域或对话摘要任务中表现有限，且微调需大量高质量标注数据，获取困难且成本高。如何自监督且低成本地提升模型在真实对话数据上的摘要能力成为实际需求。

Method: 采用持续预训练（Continual Pre-training）的无监督方式，利用大规模、未标注的商业对话数据对现有大模型进行领域自适应，然后在摘要任务上进行实验评估。还分析了不同的数据选择策略对预训练成效的影响。

Result: 实验证明，持续预训练不仅在领域内对话摘要任务上提升显著，对领域外的摘要基准也有较大提升，并能保持模型的泛化性能与鲁棒性。

Conclusion: 持续预训练是一种可以大幅提升大模型对话摘要能力的可扩展、自监督方法，适合工业级摘要场景，同时数据选择策略的研究为实际落地提供了实践指南。

Abstract: Large language models (LLMs) have achieved impressive performance in text
summarization, yet their performance often falls short when applied to
specialized domains %or conversational data that differ from their original
pre-training distribution. While fine-tuning can improve summarization quality,
it typically relies on costly and scarce high-quality labeled data. In this
work, we explore continual pre-training as a scalable, self-supervised approach
to adapt LLMs for downstream summarization tasks, particularly in the context
of noisy real-world conversation transcripts. We conduct extensive experiments
using large-scale, unlabeled business conversation data to investigate whether
continual pre-training enhances model capabilities in conversational
summarization. Our results demonstrate that continual pre-training yields
substantial gains in both in-domain and out-of-domain summarization benchmarks,
while maintaining strong generalization and robustness. We also analyze the
effects of data selection strategies, providing practical guidelines for
applying continual pre-training in summarization-focused industrial
applications.

</details>


### [141] [Automated Boilerplate: Prevalence and Quality of Contract Generators in the Context of Swiss Privacy Policies](https://arxiv.org/abs/2510.05860)
*Luka Nenadic,David Rodriguez*

Main category: cs.CL

TL;DR: 本文分析了瑞士2023年隐私法修订后，自动合同生成器在帮助企业合规中的作用。研究发现，这些工具提升了隐私政策的合规率，尤其是在中小企业中效果显著。


<details>
  <summary>Details</summary>
Motivation: 中小企业面对频繁变化的数字合规要求时，缺乏资源和专业知识撰写复杂法律文件，而传统律师费用高昂，因此企业倾向使用更便宜的自动化合同生成器。但此类工具的实际使用情况和生成文档的质量鲜有实证分析。

Method: 研究团队围绕瑞士和欧盟隐私法，构建并标注了跨语言的合规义务基准数据集。基于该数据集，应用创新的GPT-5方法开展隐私政策大规模合规测评，并分析修法带来的影响。

Result: 法修订后，隐私政策合规率提升，自动合同生成器被18%本地网站明确引用，使用这些工具的网站合规率比未使用者高出约15个百分点，显示自动化工具促进了更高合规标准。

Conclusion: 本研究证明，自动合同生成器有助于提升企业隐私合规水平，尤其受益于中小企业。结果支持LLM在跨语言法律分析、欧盟法规外溢效应以及自动化工具提升合同质量的理论讨论。

Abstract: It has become increasingly challenging for firms to comply with a plethora of
novel digital regulations. This is especially true for smaller businesses that
often lack both the resources and know-how to draft complex legal documents.
Instead of seeking costly legal advice from attorneys, firms may turn to
cheaper alternative legal service providers such as automated contract
generators. While these services have a long-standing presence, there is little
empirical evidence on their prevalence and output quality.
  We address this gap in the context of a 2023 Swiss privacy law revision. To
enable a systematic evaluation, we create and annotate a multilingual benchmark
dataset that captures key compliance obligations under Swiss and EU privacy
law. Using this dataset, we validate a novel GPT-5-based method for large-scale
compliance assessment of privacy policies, allowing us to measure the impact of
the revision. We observe compliance increases indicating an effect of the
revision. Generators, explicitly referenced by 18% of local websites, are
associated with substantially higher levels of compliance, with increases of up
to 15 percentage points compared to privacy policies without generator use.
These findings contribute to three debates: the potential of LLMs for
cross-lingual legal analysis, the Brussels Effect of EU regulations, and,
crucially, the role of automated tools in improving compliance and contractual
quality.

</details>


### [142] [Revisiting Long-context Modeling from Context Denoising Perspective](https://arxiv.org/abs/2510.05862)
*Zecheng Tang,Baibei Ji,Juntao Li,Lijun Wu,Haijia Gui,Min Zhang*

Main category: cs.CL

TL;DR: 论文分析了长上下文模型（LCM）在处理长序列时面临的噪声干扰问题，并提出了一种基于Integrated Gradient分数的新方法来检测和量化上下文噪声，进一步通过Context Denoising Training（CDT）提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有LCM虽然能处理长序列，但对上下文噪声（无关token）较为敏感，这会降低模型对关键信息的注意力，影响最终预测效果。为提升模型鲁棒性和性能，需要有效检测、缓解和利用这些噪声。

Method: 作者提出使用Integrated Gradient分数作为新指标，检测和量化上下文中的噪声信息，并通过简单方法去噪后发现能显著提升模型关注关键信息。基于此，进一步设计了Context Denoising Training（CDT）训练策略，从源头提升模型对关键token的注意和预测能力。

Result: 在四个任务上、不同的上下文窗口长度和长上下文对齐设定下的大量实验证明，CDT方法显著优于传统方法。尤其采用CDT训练的开源8B模型，在相关任务上的表现（50.92分）接近GPT-4o（51.00分）。

Conclusion: 通过检测和缓解上下文噪声，并引入CDT训练策略，可以有效提升长上下文模型对关键信息的提取与预测能力，促进相关实际应用的发展。

Abstract: Long-context models (LCMs) have demonstrated great potential in processing
long sequences, facilitating many real-world applications. The success of LCMs
can be attributed to their ability to locate implicit critical information
within the context for further prediction. However, recent research reveals
that LCMs are often susceptible to contextual noise, i.e., irrelevant tokens,
that can mislead model attention. In this paper, we conduct a fine-grained
analysis of the context noise and propose an effective metric, the Integrated
Gradient (IG) score, to detect and quantify the noise information within the
context. Our findings reveal that even simple mitigation of detected context
noise can substantially boost the model's attention on critical tokens and
benefit subsequent predictions. Building on this insight, we propose Context
Denoising Training (CDT), a straightforward yet effective training strategy
that improves attention on critical tokens while reinforcing their influence on
model predictions. Extensive experiments across four tasks, under both context
window scaling and long-context alignment settings, demonstrate the superiority
of CDT. Notably, when trained with CDT, an open-source 8B model can achieve
performance (50.92) comparable to GPT-4o (51.00).

</details>


### [143] [Evaluating the Sensitivity of LLMs to Harmful Contents in Long Input](https://arxiv.org/abs/2510.05864)
*Faeze Ghorbanpour,Alexander Fraser*

Main category: cs.CL

TL;DR: 本文系统研究了大型语言模型（LLMs）在长上下文中识别有害内容（如有毒、冒犯、仇恨言论）的表现，分析了不同类型、位置、比例和上下文长度下的敏感性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs越来越多地被用于依赖长上下文的应用中（如文档处理和检索增强生成），其在涉及安全风险场景中的行为知之甚少。因此，需要系统评估其在处理有害内容时的能力与局限。

Method: 针对LLaMA-3、Qwen-2.5和Mistral三个LLM，本文设计实验，测试不同类别、位置（首、中、末）、比例（0.01-0.50）、上下文长度（600-6000 tokens）下，模型识别显式与隐式有害内容的表现。

Result: 在适度的有害内容比例（0.25）下，模型表现最佳；当比例过低或过高时性能下降。上下文越长，召回率下降。有害内容出现于开头被识别得更好，显式内容更易被检测，隐式检测较弱。不同模型表现趋势类似。

Conclusion: LLMs在长上下文下对有害内容的检测能力具备一定优势，但仍存在诸多挑战（如长上下文稀疏/密集有害内容检测能力不足、隐式内容识别弱），为安全关键领域应用提出改进方向。

Abstract: Large language models (LLMs) increasingly support applications that rely on
extended context, from document processing to retrieval-augmented generation.
While their long-context capabilities are well studied for reasoning and
retrieval, little is known about their behavior in safety-critical scenarios.
We evaluate LLMs' sensitivity to harmful content under extended context,
varying type (explicit vs. implicit), position (beginning, middle, end),
prevalence (0.01-0.50 of the prompt), and context length (600-6000 tokens).
Across harmful content categories such as toxic, offensive, and hate speech,
with LLaMA-3, Qwen-2.5, and Mistral, we observe similar patterns: performance
peaks at moderate harmful prevalence (0.25) but declines when content is very
sparse or dominant; recall decreases with increasing context length; harmful
sentences at the beginning are generally detected more reliably; and explicit
content is more consistently recognized than implicit. These findings provide
the first systematic view of how LLMs prioritize and calibrate harmful content
in long contexts, highlighting both their emerging strengths and the challenges
that remain for safety-critical use.

</details>


### [144] [The fragility of "cultural tendencies" in LLMs](https://arxiv.org/abs/2510.05869)
*Kun Sun,Rong Wang*

Main category: cs.CL

TL;DR: 本论文对LSZ（2025）关于大语言模型（LLMs）在不同语言提示下展现文化倾向的研究进行了批判性复现，并发现其“文化倾向”结论不稳定，提示语言对输出影响甚微。


<details>
  <summary>Details</summary>
Motivation: LSZ指出大语言模型在不同语言提示下会展现不同的文化倾向，引发了对于模型是否内化文化信念的讨论。本论文动机在于质疑和复查这种结论的稳健性和解释合理性。

Method: 作者针对LSZ方法进行了批判性复查，扩展了模型类型和测试题目数量，开展了更大范围的模型和样本测试，对比分析不同提示语言下模型输出变化。

Result: 实验结果显示，不同提示语言对模型输出的影响非常有限，与LSZ原始结论相悖。

Conclusion: LSZ报告的文化倾向不是模型的稳定特性，而是特定模型和任务设计下的脆弱现象。提示语言本身难以引发大规模的“文化信念”编码。

Abstract: In a recent study, Lu, Song, and Zhang (2025) (LSZ) propose that large
language models (LLMs), when prompted in different languages, display
culturally specific tendencies. They report that the two models (i.e., GPT and
ERNIE) respond in more interdependent and holistic ways when prompted in
Chinese, and more independent and analytic ways when prompted in English. LSZ
attribute these differences to deep-seated cultural patterns in the models,
claiming that prompt language alone can induce substantial cultural shifts.
While we acknowledge the empirical patterns they observed, we find their
experiments, methods, and interpretations problematic. In this paper, we
critically re-evaluate the methodology, theoretical framing, and conclusions of
LSZ. We argue that the reported "cultural tendencies" are not stable traits but
fragile artifacts of specific models and task design. To test this, we
conducted targeted replications using a broader set of LLMs and a larger number
of test items. Our results show that prompt language has minimal effect on
outputs, challenging LSZ's claim that these models encode grounded cultural
beliefs.

</details>


### [145] [Prompt reinforcing for long-term planning of large language models](https://arxiv.org/abs/2510.05921)
*Hsien-Chin Lin,Benjamin Matthias Ruppik,Carel van Niekerk,Chia-Hao Shen,Michael Heck,Nurul Lubis,Renato Vukovic,Shutong Feng,Milica Gašić*

Main category: cs.CL

TL;DR: 本文提出了一种基于强化学习启发的新型prompt优化框架，通过自适应修改LLM的任务指令prompt，显著改善了多轮任务（如text-to-SQL、任务型对话）的表现。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLM）虽在多种NLP任务表现优异，但在多轮交互中容易受早期错误假设影响，且难以长期追踪用户目标，导致实际应用受限。已有对话系统研究表明长远规划能力对多轮任务很关键。

Method: 受强化学习思想启发，作者提出通过修改任务指令prompt，使LLM本身无须参数微调即可具备规划能力。具体方案包括自动生成回合反馈、利用经验回放策略优化和重写prompt。该方法不仅能提升多轮交互任务的表现，还能适配不同LLM，同时利用多样LLM作为meta-prompting代理。

Result: 在text-to-SQL和任务型对话等多轮任务上，所提方法取得显著性能提升。并具备较强的泛化能力，可适用于不同类型的大语言模型。

Conclusion: 强化学习启发的prompt优化方法，无需对模型参数进行调整，即可提升LLM在多轮交互任务中的长期规划与泛化能力，值得未来在无参数优化、多种LLM协作等方向持续探索。

Abstract: Large language models (LLMs) have achieved remarkable success in a wide range
of natural language processing tasks and can be adapted through prompting.
However, they remain suboptimal in multi-turn interactions, often relying on
incorrect early assumptions and failing to track user goals over time, which
makes such tasks particularly challenging. Prior works in dialogue systems have
shown that long-term planning is essential for handling interactive tasks. In
this work, we propose a prompt optimisation framework inspired by reinforcement
learning, which enables such planning to take place by only modifying the task
instruction prompt of the LLM-based agent. By generating turn-by-turn feedback
and leveraging experience replay for prompt rewriting, our proposed method
shows significant improvement in multi-turn tasks such as text-to-SQL and
task-oriented dialogue. Moreover, it generalises across different LLM-based
agents and can leverage diverse LLMs as meta-prompting agents. This warrants
future research in reinforcement learning-inspired parameter-free optimisation
methods.

</details>


### [146] [Hire Your Anthropologist! Rethinking Culture Benchmarks Through an Anthropological Lens](https://arxiv.org/abs/2510.05931)
*Mai AlKhamissi,Yunze Xiao,Badr AlKhamissi,Mona Diab*

Main category: cs.CL

TL;DR: 本文批判了当前大语言模型文化评测基准的局限，提出更动态和多元的方法来改进评测。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型文化评测往往将文化简化成静态事实或单一价值观，这与人类学中认为文化是动态且富有情境性的观点相矛盾。因此，作者希望改进对文化的评测方法，以反映文化的多样性和复杂性。

Method: 作者提出了一个四部分的分析框架，从知识、偏好、表现和偏见等视角分析现有20个文化评测基准，并归纳了6个常见方法论问题，比如将国家等同于文化、忽视内部差异、采用过于简单的问卷形式。

Result: 作者发现当前大部分文化评测存在显著的抽象化和过度简化问题，无法真实反映文化本身的复杂性和动态性。

Conclusion: 文章提出应借鉴人类学方法，纳入真实故事情境、社区参与和情境化评测，提升文化评测基准的代表性和有效性，推动LLM文化能力的更科学评估。

Abstract: Cultural evaluation of large language models has become increasingly
important, yet current benchmarks often reduce culture to static facts or
homogeneous values. This view conflicts with anthropological accounts that
emphasize culture as dynamic, historically situated, and enacted in practice.
To analyze this gap, we introduce a four-part framework that categorizes how
benchmarks frame culture, such as knowledge, preference, performance, or bias.
Using this lens, we qualitatively examine 20 cultural benchmarks and identify
six recurring methodological issues, including treating countries as cultures,
overlooking within-culture diversity, and relying on oversimplified survey
formats. Drawing on established anthropological methods, we propose concrete
improvements: incorporating real-world narratives and scenarios, involving
cultural communities in design and validation, and evaluating models in context
rather than isolation. Our aim is to guide the development of cultural
benchmarks that go beyond static recall tasks and more accurately capture the
responses of the models to complex cultural situations.

</details>


### [147] [EvalMORAAL: Interpretable Chain-of-Thought and LLM-as-Judge Evaluation for Moral Alignment in Large Language Models](https://arxiv.org/abs/2510.05942)
*Hadi Mohammadi,Anastasia Giachanou,Ayoub Bagheri*

Main category: cs.CL

TL;DR: 本文提出了一种名为EvalMORAAL的透明链式思维（CoT）评估框架，用于衡量20种大模型的道德一致性，并揭示出模型在东西方地区存在明显道德偏差。


<details>
  <summary>Details</summary>
Motivation: 由于现有大语言模型在道德价值观对齐方面缺乏透明且系统的评估方法，同时存在不同地区和文化的偏见，作者旨在开发一个标准化、公开可追踪的评估框架以更好衡量模型的道德一致性和地域差异。

Method: 提出EvalMORAAL框架，结合两种评分方式（对数概率、直接评分）和‘模型作为裁判’的同行评审机制，对20个大语言模型在世界价值观调查（WVS, 55国，19话题）及皮尤全球态度调查（PEW, 39国，8话题）上的道德一致性进行评估。框架包含标准链式思维流程、自洽性检查和基于数据阈值的冲突标记。

Result: 顶尖模型与人类调查结果高度一致（WVS皮尔逊相关约0.90），但明显存在地区差别：西方相关性r=0.82，非西方r=0.61，存在0.21的绝对差距。此外，同行评审“模型裁判”可有效自动识别348处冲突，评审一致性与调查对齐度显著相关（WVS r=0.74, PEW r=0.39，p<.001）。

Conclusion: EvalMORAAL展现了大模型文化适应性评估的实质进展，但也揭示了跨地区道德一致性的挑战，对未来打造跨文化可靠AI提出了新的要求。

Abstract: We present EvalMORAAL, a transparent chain-of-thought (CoT) framework that
uses two scoring methods (log-probabilities and direct ratings) plus a
model-as-judge peer review to evaluate moral alignment in 20 large language
models. We assess models on the World Values Survey (55 countries, 19 topics)
and the PEW Global Attitudes Survey (39 countries, 8 topics). With EvalMORAAL,
top models align closely with survey responses (Pearson's r approximately 0.90
on WVS). Yet we find a clear regional difference: Western regions average
r=0.82 while non-Western regions average r=0.61 (a 0.21 absolute gap),
indicating consistent regional bias. Our framework adds three parts: (1) two
scoring methods for all models to enable fair comparison, (2) a structured
chain-of-thought protocol with self-consistency checks, and (3) a
model-as-judge peer review that flags 348 conflicts using a data-driven
threshold. Peer agreement relates to survey alignment (WVS r=0.74, PEW r=0.39,
both p<.001), supporting automated quality checks. These results show real
progress toward culture-aware AI while highlighting open challenges for use
across regions.

</details>


### [148] [Probing the Difficulty Perception Mechanism of Large Language Models](https://arxiv.org/abs/2510.05969)
*Sunbowen Lee,Qingyu Yin,Chak Tou Leong,Jialiang Zhang,Yicheng Gong,Xiaoyu Shen*

Main category: cs.CL

TL;DR: 本文探讨了大语言模型（LLM）是否能够内部表示并感知问题难度，实验证明其内部结构对问题难度有明显区分，且能够用于自动标注问题难度。


<details>
  <summary>Details</summary>
Motivation: 自适应推理与高效资源分配依赖模型能否识别任务难度，但当前对LLM内部是否有这种能力了解甚少。作者希望揭示LLM是否已蕴含对问题难度的感知机制。

Method: 作者用线性探测方法分析LLM最后一个token的内部表征，测试其对数学问题难度的区分能力；并定位到最后一层特定的多头注意力头，其激活模式对简单与困难问题有显著差异，并通过消融实验验证定位准确性。此外，分析token级别熵与难度感知的差异。

Result: 发现LLM内部表征在最后的Transformer层特定注意力头能够区分问题难度，表征简单与难题的激活模式相反；线性探测能有效回归难度等级，并且消融实验进一步证明了定位准确。

Conclusion: LLM能够自动感知并结构化表达问题难度，有潜力辅助难度自动标注，大幅减少人工成本，为基准集构建与课程学习等任务提供新方向和理论基础。

Abstract: Large language models (LLMs) are increasingly deployed on complex reasoning
tasks, yet little is known about their ability to internally evaluate problem
difficulty, which is an essential capability for adaptive reasoning and
efficient resource allocation. In this work, we investigate whether LLMs
implicitly encode problem difficulty in their internal representations. Using a
linear probe on the final-token representations of LLMs, we demonstrate that
the difficulty level of math problems can be linearly modeled. We further
locate the specific attention heads of the final Transformer layer: these
attention heads have opposite activation patterns for simple and difficult
problems, thus achieving perception of difficulty. Our ablation experiments
prove the accuracy of the location. Crucially, our experiments provide
practical support for using LLMs as automatic difficulty annotators,
potentially substantially reducing reliance on costly human labeling in
benchmark construction and curriculum learning. We also uncover that there is a
significant difference in entropy and difficulty perception at the token level.
Our study reveals that difficulty perception in LLMs is not only present but
also structurally organized, offering new theoretical insights and practical
directions for future research.

</details>


### [149] [LexiCon: a Benchmark for Planning under Temporal Constraints in Natural Language](https://arxiv.org/abs/2510.05972)
*Periklis Mantenoglou,Rishi Hazra,Pedro Zuidberg Dos Martires,Luc De Raedt*

Main category: cs.CL

TL;DR: 本文引入了一个全新的自然语言约束规划基准LexiCon，用于系统评估大语言模型在带有约束（尤其是安全约束）规划任务上的能力。实验显示，随着约束程度增强，LLM的表现显著下降。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽被用于自然语言描述的规划任务，但主流测试多忽略约束条件，尤其是安全相关约束条件。然而在实际应用中，规划任务往往受到严格约束，评估LLM在有约束条件下的能力尤为重要。

Method: 构建了LexiCon基准，将已有规划环境加入时间约束，并用自然语言描述这些约束。通过扩展性设计，可自动将更多环境生成约束问题，且难度可动态提升。实验采用顶尖LLM（如GPT-5等）在这些约束环境中解题进行系统评测。

Result: 在LexiCon基准上，先进的LLM（如GPT-5、o3、R1）在规划约束增多时，解题性能明显下降，说明当前模型在高约束复杂任务下仍有不足。

Conclusion: LexiCon为评测LLM现实世界约束规划提供了新标准。结果提醒目前LLM在高约束高安全场景尚未成熟，需持续优化模型规划与约束推理能力。

Abstract: Owing to their reasoning capabilities, large language models (LLMs) have been
evaluated on planning tasks described in natural language. However, LLMs have
largely been tested on planning domains without constraints. In order to deploy
them in real-world settings where adherence to constraints, in particular
safety constraints, is critical, we need to evaluate their performance on
constrained planning tasks. We introduce LexiCon -- a natural language-based
(Lexi) constrained (Con) planning benchmark, consisting of a suite of
environments, that can be used to evaluate the planning capabilities of LLMs in
a principled fashion. The core idea behind LexiCon is to take existing planning
environments and impose temporal constraints on the states. These constrained
problems are then translated into natural language and given to an LLM to
solve. A key feature of LexiCon is its extensibility. That is, the set of
supported environments can be extended with new (unconstrained) environment
generators, for which temporal constraints are constructed automatically. This
renders LexiCon future-proof: the hardness of the generated planning problems
can be increased as the planning capabilities of LLMs improve. Our experiments
reveal that the performance of state-of-the-art LLMs, including reasoning
models like GPT-5, o3, and R1, deteriorates as the degree of constrainedness of
the planning tasks increases.

</details>


### [150] [Exploring Gaps in the APS: Direct Minimal Pair Analysis in LLM Syntactic Assessments](https://arxiv.org/abs/2510.06001)
*Timothy Pistotti,Jason Brown,Michael Witbrock*

Main category: cs.CL

TL;DR: 本文通过对比两种评估语法习得的方法，并在复杂的语法环境下系统测试了GPT-2模型，发现直观的极小对比分析比差分法（DiD）更能有效诊断大型语言模型的语法能力。


<details>
  <summary>Details</summary>
Motivation: 对语言刺激贫困论（APS）的实证探究在于确定当代大型语言模型(Large Language Models, LLMs)能否习得复杂句法结构，但当前不同指标的结论出现分歧，亟需辨析不同方法带来的影响。

Method: 本文生成了包含8种排列组合的寄生空位（parasitic gaps, PGs）语法刺激材料，并采用Wilcox式“wh-effects”直接极小对比法，对GPT-2进行了系统性测试，并和以往研究常用的DiD差分法相比。

Result: 实验发现，GPT-2模型在全部四种寄生空位条件下均表现为成功学习，显示其对复杂填补-空位语法规则具备鲁棒性；而该结果比DiD法得出的结果更为清晰明了。

Conclusion: 选择哪种评估指标对大型语言模型句法能力的判断至关重要。本文证明，直观的极小对比法在复杂句法结构诊断方面比DiD差分法更具解释力和透明度。

Abstract: Recent studies probing the Argument from the Poverty of the Stimulus (APS)
have applied Large Language Models (LLMs) to test the learnability of complex
syntax through surprisal-based metrics. However, divergent conclusions raise
questions concerning the insights these metrics offer. While Wilcox et al.
(2024) used direct minimal pair comparisons (the "wh-effect") to demonstrate
that models successfully generalise knowledge of filler-gap dependencies, Lan
et al. (2024) used a Difference-in-Differences (DiD) metric and found that
models largely fail on parasitic gaps (PGs). This paper argues that the direct
minimal pair approach offers greater diagnostic transparency. We demonstrate
this by generating a full 8-permutation paradigm of refined PG stimuli and
evaluating the GPT-2 model used in previous studies with a systematic
Wilcox-style wh-effect analysis. Our results show that GPT-2 succeeds across
all four tested conditions, indicating robust knowledge of filler-gap licensing
principles even in complex PG environments. This finding, which contrasts with
the more ambiguous results from DiD-style metrics, suggests that the choice of
evaluation metric is critical for assessing an LLM's syntactic competence.

</details>


### [151] [MASA: Rethinking the Representational Bottleneck in LoRA with Multi-A Shared Adaptation](https://arxiv.org/abs/2510.06005)
*Qin Dong,Yuntian Tang,Heming Jia,Yunhang Shen,Bohan Jia,Wenxuan Huang,Lianyue Zhang,Jiao Xie,Shaohui Lin*

Main category: cs.CL

TL;DR: 本论文提出了MASA（Multi-A Shared Adaptation）方法，通过在参数高效微调（PEFT）中引入多个下投影矩阵A，提升大语言模型在复杂任务中的适应能力，实验结果优于现有的LoRA方法。


<details>
  <summary>Details</summary>
Motivation: LoRA方法作为PEFT主流方案，但它仅使用单一的下投影矩阵A来提取特征，导致表达能力受限，无法充分适应复杂多样的下游任务。作者认为需要改进特征适应性以提升下游任务表现。

Method: 提出MASA架构，在每一层引入多个下投影矩阵A（多A专家），以异步共享的方式分布于不同层，实现多样化特征提取，并通过单一、层特定的上投影矩阵B整合多A专家的输出，同时保证参数高效。

Result: 在多领域泛化、单领域专精和多任务推理等多个实验中，MASA均表现出更强的适应性。例如，在MMLU基准测试中，MASA平均准确率达到59.62%，相比标准LoRA提升了1.08个百分点（相对提升1.84%），同时学习参数量相近（0.52%）。

Conclusion: MASA方法通过多A架构丰富了特征表达能力，在保持参数高效的前提下，显著提升了大语言模型在复杂任务下的细调效果，优于传统单A架构的LoRA。

Abstract: Low-Rank Adaptation (LoRA) has emerged as a dominant method in
Parameter-Efficient Fine-Tuning (PEFT) for large language models, which
augments the transformer layer with one down-projection $A$ and one
up-projection $B$. However, LoRA's reliance on a single down-projection matrix
($A$) creates a representational bottleneck, as this solitary feature extractor
is inherently insufficient for capturing the diverse signals required by
complex tasks. This motivates our architectural shift to focus on enriching the
feature adaptation to improve the downstream task adaptation ability. We
propose MASA (Multi-$A$ Shared Adaptation), an architecture that implements a
multi-$A$, single-$B$ structure where the multi-$A$ expert ensemble is
asymmetrically shared across layers to ensure parameter efficiency. In MASA,
these specialized experts capture diverse features, which are then integrated
by a single, layer-specific $B$-matrix. The effectiveness and versatility of
our method are validated through a comprehensive suite of experiments spanning
multi-domain generalization, single-domain specialization, and multi-task
reasoning. For example, on the MMLU benchmark, MASA achieves an average
accuracy of 59.62%, outperforming the standard LoRA by 1.08 points (a relative
improvement of 1.84%) with comparable learnable parameters of 0.52%.

</details>


### [152] [Evaluating The Impact of Stimulus Quality in Investigations of LLM Language Performance](https://arxiv.org/abs/2510.06018)
*Timothy Pistotti,Jason Brown,Michael Witbrock*

Main category: cs.CL

TL;DR: 本文重新评估了大型语言模型（LLM）在语法预测任务中的能力，发现刺激材料的质量会显著影响模型表现。通过用经过改进的语料对GPT-2进行测试，模型性能得以提升。


<details>
  <summary>Details</summary>
Motivation: 之前使用LLM测试“刺激贫乏论”（APS）时，不同语法现象上的结果差异较大。作者认为可能是刺激材料中存在词汇歧义和结构复杂等混淆因素影响了测试结果，因此希望消除这些干扰更客观地评估模型的语法能力。

Method: 1) 首先用既往研究中用到的原始和筛选后刺激材料为基线对GPT-2进行测试；2) 用Gemini 2.5 Pro Preview生成基于语言学模板、减少干扰的新刺激集，并用其再次评估GPT-2的表现。

Result: 初步结果显示，GPT-2在经过改进的新刺激材料上表现明显优于原基线，说明刺激材料的质量对模型语法能力评估影响很大。

Conclusion: 使用经过科学设计的高质量刺激材料能更真实地反映LLM的语法能力，提示相关实验设计需关注材料本身带来的混淆效应。

Abstract: Recent studies employing Large Language Models (LLMs) to test the Argument
from the Poverty of the Stimulus (APS) have yielded contrasting results across
syntactic phenomena. This paper investigates the hypothesis that
characteristics of the stimuli used in recent studies, including lexical
ambiguities and structural complexities, may confound model performance. A
methodology is proposed for re-evaluating LLM competence on syntactic
prediction, focusing on GPT-2. This involves: 1) establishing a baseline on
previously used (both filtered and unfiltered) stimuli, and 2) generating a
new, refined dataset using a state-of-the-art (SOTA) generative LLM (Gemini 2.5
Pro Preview) guided by linguistically-informed templates designed to mitigate
identified confounds. Our preliminary findings indicate that GPT-2 demonstrates
notably improved performance on these refined PG stimuli compared to baselines,
suggesting that stimulus quality significantly influences outcomes in
surprisal-based evaluations of LLM syntactic competency.

</details>


### [153] [CDTP: A Large-Scale Chinese Data-Text Pair Dataset for Comprehensive Evaluation of Chinese LLMs](https://arxiv.org/abs/2510.06039)
*Chengwei Wu,Jiapu Wang,Mingyang Gao,Xingrui Zhuo,Jipeng Guo,Runlin Lei,Haoran Luo,Tianyu Chen,Haoyi Zhou,Shirui Pan,Zechao Li*

Main category: cs.CL

TL;DR: 该论文提出了CB-ECLLM基准，用于评估中文大模型，解决了当前评测方法对中文支持不足、缺乏结构化数据集的问题。通过自建CDTP数据集（包含700万对齐文本和1500万个三元组），实现了对中文大模型的结构化能力和知识泛化能力的全面评估。


<details>
  <summary>Details</summary>
Motivation: 当前主流大语言模型评测多以英文为主，难以反映中文语言的独特性，且缺乏针对结构化知识的评测体系。现有中文评测工具和数据集数据结构单一，不能满足知识驱动类任务和复杂多场景下中文大模型的性能展示需求。为解决这一痛点，作者构建了新的数据集和评测框架。

Method: 作者建立了CDTP大规模中英文对齐结构化文本对数据集，覆盖四大关键领域，包括700多万文本及配套三元组。基于该数据集提出CB-ECLLM评测体系，支持三元组补全、三元组转文本生成、问答等多任务，同时通过监督微调、消融实验等多种实验手段对模型性能进行细致考察。

Result: 实验表明，基于CDTP和CB-ECLLM基准能够更细致地反映中文大模型在知识泛化和结构化推理方面的能力，同时验证了该数据集和基准对多任务、不同模型结构的适用性和可靠性。

Conclusion: CB-ECLLM和CDTP数据集有效填补了中文大模型评测的结构化空白，促进更全面的模型能力评价与发展，并通过开源支持了领域可复现研究和持续创新。

Abstract: Large Language Models (LLMs) have achieved remarkable success across a wide
range of natural language processing tasks. However, Chinese LLMs face unique
challenges, primarily due to the dominance of unstructured free text and the
lack of structured representations in Chinese corpora. While existing
benchmarks for LLMs partially assess Chinese LLMs, they are still predominantly
English-centric and fail to address the unique linguistic characteristics of
Chinese, lacking structured datasets essential for robust evaluation. To
address these challenges, we present a Comprehensive Benchmark for Evaluating
Chinese Large Language Models (CB-ECLLM) based on the newly constructed Chinese
Data-Text Pair (CDTP) dataset. Specifically, CDTP comprises over 7 million
aligned text pairs, each consisting of unstructured text coupled with one or
more corresponding triples, alongside a total of 15 million triples spanning
four critical domains. The core contributions of CDTP are threefold: (i)
enriching Chinese corpora with high-quality structured information; (ii)
enabling fine-grained evaluation tailored to knowledge-driven tasks; and (iii)
supporting multi-task fine-tuning to assess generalization and robustness
across scenarios, including Knowledge Graph Completion, Triple-to-Text
generation, and Question Answering. Furthermore, we conduct rigorous
evaluations through extensive experiments and ablation studies to assess the
effectiveness, Supervised Fine-Tuning (SFT), and robustness of the benchmark.
To support reproducible research, we offer an open-source codebase and outline
potential directions for future investigations based on our insights.

</details>


### [154] [ASPO: Asymmetric Importance Sampling Policy Optimization](https://arxiv.org/abs/2510.06062)
*Jiakang Wang,Runze Liu,Lei Lin,Wenping Hu,Xiu Li,Fuzheng Zhang,Guorui Zhou,Kun Gai*

Main category: cs.CL

TL;DR: 本文揭示了现有大语言模型（LLM）基于强化学习（RL）的后训练方法在token级clip机制上存在重要缺陷，并提出了ASPO新方法，有效提升训练稳定性和模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的RL后训练主要采用Outcome-Supervised RL（OSRL）范式，依赖于token级重要性采样（IS），但作者发现IS在正优势token的权重分配存在失衡问题，影响低概率token的学习，制约模型性能。

Method: 提出了Asymmetric Importance Sampling Policy Optimization（ASPO）：通过对正优势token的IS ratio进行翻转，使正、负token的学习动态一致，并结合柔性双重clip机制，抑制极端更新同时保持梯度流畅。

Result: 在编码和数学推理基准上实验表明，ASPO显著缓解了训练早收敛问题，提升了训练稳定性和最终性能，优于强基线GRPO方法。

Conclusion: ASPO方法能有效修正OSRL中token级权重失衡，为LLM RL领域带来新见解，并强调了IS校正的重要性。

Abstract: Recent Large Language Model (LLM) post-training methods rely on token-level
clipping mechanisms during Reinforcement Learning (RL). However, we identify a
fundamental flaw in this Outcome-Supervised RL (OSRL) paradigm: the Importance
Sampling (IS) ratios of positive-advantage tokens are mismatched, leading to
unbalanced token weighting for positive and negative tokens. This mismatch
suppresses the update of low-probability tokens while over-amplifying already
high-probability ones. To address this, we propose Asymmetric Importance
Sampling Policy Optimization (ASPO), which uses a simple yet effective strategy
that flips the IS ratios of positive-advantage tokens, aligning their update
direction with the learning dynamics of negative ones. AIS further incorporates
a soft dual-clipping mechanism to stabilize extreme updates while maintaining
gradient flow. Comprehensive experiments on coding and mathematical reasoning
benchmarks demonstrate that ASPO significantly mitigates premature convergence,
improves training stability, and enhances final performance over strong
GRPO-based baselines. Our analysis provides new insights into the role of
token-level weighting in OSRL and highlights the critical importance of
correcting IS in LLM RL. The code and models of ASPO are available at
https://github.com/wizard-III/Archer2.0.

</details>


### [155] [Spectrum Tuning: Post-Training for Distributional Coverage and In-Context Steerability](https://arxiv.org/abs/2510.06084)
*Taylor Sorensen,Benjamin Newman,Jared Moore,Chan Park,Jillian Fisher,Niloofar Mireshghallah,Liwei Jiang,Yejin Choi*

Main category: cs.CL

TL;DR: 论文提出当前语言模型的后训练虽增强了模型的跟指令能力和下游任务表现，但损害了模型在多样化输出分布建模上的能力。作者引入Spectrum Suite资源用于评估，并提出Spectrum Tuning方法，改善模型可控性和分布覆盖。


<details>
  <summary>Details</summary>
Motivation: 目前主流的指令微调等后训练方法提升了大语言模型对指令的遵循和特定下游任务的表现，但人们往往忽略了这会损害模型在任务中产生多个有效答案、覆盖多样输出分布（如人类不同偏好、数值分布等）的能力。作者旨在揭示这一问题并提出改良方法。

Method: 作者提出三个分布建模的标准：上下文可引导性、有效输出空间覆盖及分布对齐性，并分析当前后训练过程如何减弱这些特性。引入大规模评测资源Spectrum Suite，涵盖来自40+源、90+任务，专为多元分布评估而设计。基于该资源，提出Spectrum Tuning后训练技术，用以提升模型可控性和分布表现。

Result: 实验显示，传统后训练可增强模型内在知识激发，但削弱模型对新分布的灵活适应能力。采用Spectrum Tuning后，模型在steerability（能根据上下文调整行为）、输出空间覆盖和分布对齐方面均较现有方法有明显提升，并在未见过的数据集上取得更优表现。

Conclusion: 论文揭示了当前后训练方法在多分布任务下的局限，并证明通过Spectrum Tuning结合Spectrum Suite评测，可显著提升模型的分布多样性能力，有助于更好满足现实应用中对多元化输出的需求。

Abstract: Language model post-training has enhanced instruction-following and
performance on many downstream tasks, but also comes with an often-overlooked
cost on tasks with many possible valid answers. We characterize three
desiderata for conditional distributional modeling: in-context steerability,
valid output space coverage, and distributional alignment, and document across
three model families how current post-training can reduce these properties. In
particular, we disambiguate between two kinds of in-context learning: ICL for
eliciting existing underlying knowledge or capabilities, and in-context
steerability, where a model must use in-context information to override its
priors and steer to a novel data generating distribution. To better evaluate
and improve these desiderata, we introduce Spectrum Suite, a large-scale
resource compiled from >40 data sources and spanning >90 tasks requiring models
to steer to and match diverse distributions ranging from varied human
preferences to numerical distributions and more. We find that while current
post-training techniques help elicit underlying capabilities and knowledge,
they hurt models' ability to flexibly steer in-context. To mitigate these
issues, we propose Spectrum Tuning, a post-training method using Spectrum Suite
to improve steerability and distributional coverage. We find that Spectrum
Tuning often improves over pretrained models and their instruction-tuned
counterparts, enhancing steerability, spanning more of the output space, and
improving distributional alignment on held-out datasets.

</details>


### [156] [The Valley of Code Reasoning: Scaling Knowledge Distillation of Large Language Models](https://arxiv.org/abs/2510.06101)
*Muyu He,Muhammad Ali Shafique,Anand Kumar,Tsach Mackey,Nazneen Rajani*

Main category: cs.CL

TL;DR: 本文研究了在将大模型的推理能力蒸馏到小模型过程中，蒸馏数据量与模型性能之间的关系，发现了先降后升的性能趋势，并提出小模型在低数据量下更受益于简单题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型具备强大的推理能力，将其知识蒸馏到小模型已被证实有效，但关于数据规模如何影响蒸馏效果研究较少，尤其是在代码推理任务上，因此本文希望探究蒸馏数据量对小模型代码推理能力提升的影响机制。

Method: 本文以两种小型的、原本不具备推理能力的LLM为对象，系统地增加蒸馏数据规模，并测试其在编程竞赛任务上的下游性能，此外在两个不同蒸馏阶段利用同等数据做微调，分析模型在不同阶段对知识类型的学习效果。

Result: 实验发现，随着蒸馏数据量增加，模型的竞赛编程能力先下降后迅速增长，呈现出所谓“代码推理之谷”；并且在数据较少阶段，小模型从简单题目中受益更大。此外，训练数据输出的正确性对蒸馏结果无显著影响。

Conclusion: 本文揭示了代码推理蒸馏过程中模型训练动态的新规律，为今后代码推理小模型的蒸馏和训练过程提供了经验和理论借鉴。

Abstract: Distilling the thinking traces of a Large Language Model (LLM) with reasoning
capabilities into a smaller model has been proven effective. Yet, there is a
scarcity of work done on how model performances scale with the quantity of
distillation data. In this work, we study the scaling trend of distilling
competitive coding skills on two small non-reasoning LLMs. We validate the
hypothesis that there is a $\textit{valley of code reasoning}$: downstream
performance on competitive coding first drops as data quantity increases, then
it steadily increases in a sharper-than-log-linear fashion. Having identified
the trend, we further fine-tune the models at two different distillation stages
on the same data to ground conclusions on their respective learning phases. We
learn that across stages in the low and medium-low data regimes, small models
benefit significantly from easier coding questions than from harder ones. We
also find that, surprisingly, the correctness of outputs in training data makes
no difference to distillation outcomes. Our work represents a step forward in
understanding the training dynamics of code reasoning distillation outside
intuition

</details>


### [157] [Distributional Semantics Tracing: A Framework for Explaining Hallucinations in Large Language Models](https://arxiv.org/abs/2510.06107)
*Gagan Bhatia,Somayajulu G Sripada,Kevin Allan,Jacobo Azcona*

Main category: cs.CL

TL;DR: 本文分析了大语言模型（LLMs）产生幻觉（生成貌似合理但事实错误的陈述）的内部原因，提出了分布式语义追踪（DST）框架，可追溯模型推理过程中语义失效，并发现模型中具体的“承诺层”导致幻觉不可避免，同时分析了不同推理路径的冲突及其机制。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型表现优异，但幻觉问题依然突出，严重影响可信度。当前缺乏对其内部失效机理的系统性解释。因此，作者希望通过结构化的分析揭示幻觉产生的本质原因及其具体实现机制。

Method: 1）提出分布式语义追踪（DST）框架，通过集成多种可解释性技术，构建模型内部因果推理图；2）精准定位大语言模型中导致幻觉发生不可逆转的具体神经网络层（即承诺层）；3）借助“双过程理论”分析模型内部的联想与语境推理路径的交互与冲突。

Result: 实验证实可用DST框架追踪推理路径，发现了承诺层，无可逆转地使模型表征偏离事实。还发现联想路径（系统1）与语境路径（系统2）存在冲突，导致“推理捷径劫持”等常见幻觉类型。同时，语境路径的连贯性与幻觉发生率呈强负相关（ρ = -0.863）。

Conclusion: 幻觉是Transformer架构固有推理机制的可预测结果。提出的DST方法可用于识别与量化语义弱点，推动模型可解释性和抗幻觉方法的发展。

Abstract: Large Language Models (LLMs) are prone to hallucination, the generation of
plausible yet factually incorrect statements. This work investigates the
intrinsic, architectural origins of this failure mode through three primary
contributions.First, to enable the reliable tracing of internal semantic
failures, we propose \textbf{Distributional Semantics Tracing (DST)}, a unified
framework that integrates established interpretability techniques to produce a
causal map of a model's reasoning, treating meaning as a function of context
(distributional semantics). Second, we pinpoint the model's layer at which a
hallucination becomes inevitable, identifying a specific \textbf{commitment
layer} where a model's internal representations irreversibly diverge from
factuality. Third, we identify the underlying mechanism for these failures. We
observe a conflict between distinct computational pathways, which we interpret
using the lens of dual-process theory: a fast, heuristic \textbf{associative
pathway} (akin to System 1) and a slow, deliberate \textbf{contextual pathway}
(akin to System 2), leading to predictable failure modes such as
\textit{Reasoning Shortcut Hijacks}. Our framework's ability to quantify the
coherence of the contextual pathway reveals a strong negative correlation
($\rho = -0.863$) with hallucination rates, implying that these failures are
predictable consequences of internal semantic weakness. The result is a
mechanistic account of how, when, and why hallucinations occur within the
Transformer architecture.

</details>


### [158] [Parallel Tokenizers: Rethinking Vocabulary Design for Cross-Lingual Transfer](https://arxiv.org/abs/2510.06128)
*Muhammad Dehan Al Kautsar,Fajri Koto*

Main category: cs.CL

TL;DR: 本文提出一种新的多语种分词框架“平行分词器”，通过对等对齐不同语言中语义等价词的词汇表，实现了更有效的跨语言迁移和共享表示。实验证明该方法在多项任务上均超越传统基线。


<details>
  <summary>Details</summary>
Motivation: 现有多语种语言模型的分词方法往往无法保证语义相同的词汇在不同语言中共享表示，这限制了模型的跨语言泛化能力，尤其是在低资源语言场景下。

Method: 提出了平行分词器框架：先在单语语料上训练分词器，然后借助双语词典或词对齐技术，将语义等价词在不同语言的词汇表中对齐到相同的索引，从而实现跨语言的共享词汇表。

Result: 在13种低资源语言上从头预训练Transformer编码器，并分别在情感分析、仇恨言论检测、情绪分类和句子嵌入相似性任务上评估。采用平行分词器的模型在所有任务中均优于常规多语分词基线模型。

Conclusion: 分词策略对于多语种表示学习至关重要。通过语义对齐分词表，平行分词器显著提升了跨语言迁移能力，特别适用于低资源语言环境。

Abstract: Tokenization defines the foundation of multilingual language models by
determining how words are represented and shared across languages. However,
existing methods often fail to support effective cross-lingual transfer because
semantically equivalent words are assigned distinct embeddings. For example, "I
eat rice" in English and "Ina cin shinkafa" in Hausa are typically mapped to
different vocabulary indices, preventing shared representations and limiting
cross-lingual generalization. We introduce parallel tokenizers. This new
framework trains tokenizers monolingually and then aligns their vocabularies
exhaustively using bilingual dictionaries or word-to-word translation, ensuring
consistent indices for semantically equivalent words. This alignment enforces a
shared semantic space across languages while naturally improving fertility
balance. To assess their effectiveness, we pretrain a transformer encoder from
scratch on thirteen low-resource languages and evaluate it on sentiment
analysis, hate speech detection, emotion classification, and sentence embedding
similarity. Across all tasks, models trained with parallel tokenizers
outperform conventional multilingual baselines, confirming that rethinking
tokenization is essential for advancing multilingual representation
learning--especially in low-resource settings.

</details>


### [159] [CreditDecoding: Accelerating Parallel Decoding in Diffusion Large Language Models with Trace Credits](https://arxiv.org/abs/2510.06133)
*Kangyu Wang,Zhiyun Jiang,Haibo Feng,Weijia Zhao,Lin Liu,Jianguo Li,Zhenzhong Lan,Weiyao Lin*

Main category: cs.CL

TL;DR: 本文提出了一种名为CreditDecoding的新型无训练并行解码方法，通过积累历史logits（Trace Credit）加速dLLM（扩散大语言模型）的置信度收敛，从而显著提升了解码速度和鲁棒性。实验证明，在多个基准上，该方法带来了接近5倍的解码加速和性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的dLLM并行解码方法因为置信度低频繁重复标记和解码，导致大量冗余运算，解码提速受限。通过分析dLLM解码过程，作者发现模型往往提前几步已经确定了最终的token预测，因此有潜力利用历史信息减少冗余、提升效率。

Method: 作者提出了“Trace Credit”概念，通过跟踪并累积分步logits，量化每个token的收敛潜力。在此基础上，提出了无需再训练、可直接应用的新型并行解码算法CreditDecoding。该方法通过将当前logits和历史Credit信息融合，加速了低置信正确token的收敛，并减少了冗余迭代。

Result: 在8个基准测试中，CreditDecoding方法在LLaDA-8B-Instruct模型上实现了5.48倍的加速和0.48的性能提升，在LLaDA-MoE-Instruct模型上实现了4.11倍加速和0.15的性能提升。该算法还可顺利扩展到长序列，优于现有并行解码法，也能和主流推理优化方法兼容。

Conclusion: CreditDecoding显著减少了dLLM并行解码的冗余步骤，实现了高效、鲁棒且易集成的推理加速方案，对长序列推理和现有优化策略具有良好的兼容性和适用性。

Abstract: Diffusion large language models (dLLMs) generate text through iterative
denoising steps, achieving parallel decoding by denoising only high-confidence
positions at each step. However, existing approaches often repetitively remask
tokens due to initially low confidence scores, leading to redundant iterations
and limiting overall acceleration. Through the analysis of dLLM decoding
traces, we observe that the model often determines the final prediction for a
token several steps before the decoding step. To leverage this historical
information and avoid redundant steps, we introduce the concept of Trace
Credit, which quantifies each token's convergence potential by accumulating
historical logits. Furthermore, we propose CreditDecoding, a training-free
parallel decoding algorithm that accelerates the confidence convergence of
correct but underconfident tokens by fusing current logits with Trace Credit.
This process significantly reduces redundant iterations and enhances decoding
robustness. On eight benchmarks, CreditDecoding achieves a 5.48 times speedup
and a 0.48 performance improvement over LLaDA-8B-Instruct, and a 4.11 times
speedup with a 0.15 performance improvement over LLaDA-MoE-Instruct.
Importantly, CreditDecoding scales effectively to long sequences and is
orthogonal to mainstream inference optimizations, making it a readily
integrable and versatile solution.

</details>


### [160] [RoSE: Round-robin Synthetic Data Evaluation for Selecting LLM Generators without Human Test Sets](https://arxiv.org/abs/2510.06143)
*Jan Cegin,Branislav Pecher,Ivan Srba,Jakub Simko*

Main category: cs.CL

TL;DR: 本文提出了一种新的代理性指标RoSE，用于在缺少人工标注数据的情况下，从多个大语言模型（LLM）中选择生成训练数据效果最好的那个。


<details>
  <summary>Details</summary>
Motivation: 对于低资源语言，人工标注数据稀缺，但LLM能够生成高质量文本。如何选择最优的LLM生成器成为难题，因为依赖人工评测代价高，而内在指标与下游表现关联弱。

Method: 提出Round robin Synthetic data Evaluation（RoSE）方法：用候选LLM生成合成数据，训练小模型，再用其他LLM生成的数据进行评测，最终RoSE分数为平均表现。

Result: 在六个LLM、十一种语言及三个任务上，RoSE比其他内在启发式指标更能准确选出最优生成器。RoSE与最佳基线仅差0.76个百分点，是唯一与人工测试数据表现呈正相关的指标。

Conclusion: RoSE为无人工测试集情况下选择最佳LLM生成器提供了有效、通用的评估方法，特别适用于低资源语言和需合成数据的场景。

Abstract: LLMs are powerful generators of synthetic data, which are used for training
smaller, specific models. This is especially valuable for low-resource
languages, where human-labelled data is scarce but LLMs can still produce
high-quality text. However, LLMs differ in how useful their outputs are for
training. Selecting the best LLM as a generator is challenging because
extrinsic evaluation requires costly human annotations (which are often
unavailable for low-resource languages), while intrinsic metrics correlate
poorly with downstream performance. We introduce Round robin Synthetic data
Evaluation (RoSE), a proxy metric for selecting the best LLM generator without
human test sets. RoSE trains a small model on the outputs of a candidate
generator (LLM) and then evaluates it on generated synthetic examples from all
other candidate LLMs. The final RoSE score is the mean performance of this
small model. Across six LLMs, eleven languages, and three tasks (sentiment,
topic, intent), RoSE identifies the optimal generator more often than any other
intrinsic heuristics. RoSE outperforms intrinsic heuristics and comes within
0.76 percentage points of the optimal generator baseline. This result is
measured in terms of downstream performance, obtained by training a small model
on the chosen generator's outputs (optimal vs. proxy metric selected) and
evaluating it on human-labelled test data. Additionally, RoSE is the only
metric to achieve a positive correlation with performance on human test data.

</details>


### [161] [VecInfer: Efficient LLM Inference with Low-Bit KV Cache via Outlier-Suppressed Vector Quantization](https://arxiv.org/abs/2510.06175)
*Dingyu Yao,Chenxu Yang,Zhengyang Tong,Zheng Lin,Wei Liu,Jian Luan,Weiping Wang*

Main category: cs.CL

TL;DR: 本文提出了VecInfer方法，通过高效的向量量化（VQ）技术，对LLM推理过程中的KV缓存进行极致压缩，同时保持和提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在推理时需要KV缓存，带来了巨大的内存开销。虽然已有的VQ方法能缓解内存占用并可调整不同位宽，但在超低位宽（如2bit）下，量化效果会因关键缓存异常值导致码本利用率低下而显著下降，严重影响推理精度。解决在极低比特数下的性能劣化，是进一步提升LLM推理效率的关键。

Method: 作者提出VecInfer，通过在VQ之前对key缓存应用平滑变换和Hadamard变换，有效压制key缓存中的异常值，提升原始数据在码本中的覆盖广度与均匀性，从而优化量化效果。此外，作者还设计了高效的CUDA核函数，将计算与反量化操作融合，减少了内存访问开销，加速了推理过程。

Result: 实验表明，VecInfer在长上下文理解和数学推理任务上均超越了现有的量化方法。在仅用2bit的量化条件下，依然能媲美全精度模型的性能，不仅带来了2.7倍的大批量自注意力计算加速，还在Llama-3.1-8B模型、196k序列长度下单批次推理端到端延迟降低达8.3倍。

Conclusion: VecInfer实现了极致KV缓存压缩下的高效且高精度LLM推理，为大模型落地和部署奠定了基础。

Abstract: The Key-Value (KV) cache introduces substantial memory overhead during large
language model (LLM) inference. Although existing vector quantization (VQ)
methods reduce KV cache usage and provide flexible representational capacity
across bit-widths, they suffer severe performance degradation at ultra-low
bit-widths due to key cache outliers that hinder effective codebook
utilization. To address this challenge, we propose VecInfer, a novel VQ method
for aggressive KV cache compression while enabling efficient inference. By
applying smooth and Hadamard transformations, VecInfer suppresses outliers in
the key cache, enabling the codebook to comprehensively cover the original data
distribution and thereby reducing quantization difficulty. To facilitate
efficient deployment, we design an optimized CUDA kernel that fuses computation
with dequantization to minimize memory access overhead. Extensive evaluations
demonstrate that VecInfer consistently outperforms existing quantization
baselines across both long-context understanding and mathematical reasoning
tasks. With only 2-bit quantization, VecInfer achieves performance comparable
to full precision, while delivering up to $\mathbf{2.7\times}$ speedup in
large-batch self-attention computation and $\mathbf{8.3\times}$ reduction in
single-batch end-to-end latency on Llama-3.1-8B with a 196k sequence length.

</details>


### [162] [Mixing Mechanisms: How Language Models Retrieve Bound Entities In-Context](https://arxiv.org/abs/2510.06182)
*Yoav Gur-Arieh,Mor Geva,Atticus Geiger*

Main category: cs.CL

TL;DR: 本文探讨了语言模型（LM）在上下文推理中绑定与检索实体的机制，发现除了已知的位置机制外，模型还结合了词汇和反身机制，并提出了融合三机制的新因果模型，在复杂及长文本中效果鲁棒。


<details>
  <summary>Details</summary>
Motivation: 以往研究显示，LM主要通过位置机制进行实体绑定与检索，但该机制在实体数量多、语境复杂时效果不佳。本研究动机是揭示LM在更复杂、自然语境下如何健壮绑定和检索实体。

Method: 作者设计了涉及九个模型和十个绑定任务的大量实验，系统测试了位置机制、词汇机制和反身机制在不同设置下的作用，并利用实验观察开发融合这三种机制的因果模型，用来预测下一个token。

Result: 实验证明，单一位置机制在复杂设置下表现下降，LM会混合使用三种机制，提出的因果模型能以95%的一致性准确预测下一token。该机制对包含实体组的长自然文本依然有效，表明其强鲁棒性。

Conclusion: LM在上下文中绑定和检索实体远不止位置机制，而是动态混合多种机制。作者提出的融合模型能更全面准确地解释和预测LM的行为，为理解和改进LM的上下文推理能力提供了重要依据。

Abstract: A key component of in-context reasoning is the ability of language models
(LMs) to bind entities for later retrieval. For example, an LM might represent
"Ann loves pie" by binding "Ann" to "pie", allowing it to later retrieve "Ann"
when asked "Who loves pie?" Prior research on short lists of bound entities
found strong evidence that LMs implement such retrieval via a positional
mechanism, where "Ann" is retrieved based on its position in context. In this
work, we find that this mechanism generalizes poorly to more complex settings;
as the number of bound entities in context increases, the positional mechanism
becomes noisy and unreliable in middle positions. To compensate for this, we
find that LMs supplement the positional mechanism with a lexical mechanism
(retrieving "Ann" using its bound counterpart "pie") and a reflexive mechanism
(retrieving "Ann" through a direct pointer). Through extensive experiments on
nine models and ten binding tasks, we uncover a consistent pattern in how LMs
mix these mechanisms to drive model behavior. We leverage these insights to
develop a causal model combining all three mechanisms that estimates next token
distributions with 95% agreement. Finally, we show that our model generalizes
to substantially longer inputs of open-ended text interleaved with entity
groups, further demonstrating the robustness of our findings in more natural
settings. Overall, our study establishes a more complete picture of how LMs
bind and retrieve entities in-context.

</details>


### [163] [RECODE-H: A Benchmark for Research Code Development with Interactive Human Feedback](https://arxiv.org/abs/2510.06186)
*Chunyu Miao,Henry Peng Zou,Yangning Li,Yankai Chen,Yibo Wang,Fangxin Wang,Yifan Li,Wooseong Yang,Bowei He,Xinni Zhang,Dianzhi Yu,Hanchen Yang,Hoang H Nguyen,Yue Zhou,Jie Yang,Jizhou Guo,Wenzhe Fan,Chin-Yuan Yeh,Panpan Meng,Liancheng Fang,Jinhu Qi,Wei-Chieh Huang,Zhengyao Gu,Yuwei Han,Langzhou He,Yuyao Yang,Xue Liu,Irwin King,Philip S. Yu*

Main category: cs.CL

TL;DR: 本文提出了RECODE-H基准，用于评估大语言模型（LLMs）在科学研究中的多轮人机协作代码生成能力，并展示了通过迭代反馈显著提升了代码生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在科学研究代码生成上的能力有限，且多采用单轮（one-shot）评测，忽略了现实科研工作中的多轮、反馈驱动流程。

Method: 作者构建了包含102个科研任务的RECODE-H基准，涵盖了结构化指令、单元测试和五层次的反馈体系，通过大语言模型模拟人类反馈对LLM代码生成进行多轮评测。此外，提出了ReCodeAgent框架，将反馈融入代码生成迭代流程，并用主流LLMs在该基准上进行了实验。

Result: 实验结果显示，利用更丰富多层次反馈的LLM在科研代码生成任务上表现有明显提升。但也发现LLM在复杂科研代码生成方面仍存在挑战。

Conclusion: RECODE-H为面向科学研究的反馈驱动型LLM智能体开发奠定了基础，有望推动大模型在科研领域落地应用。

Abstract: Large language models (LLMs) show the promise in supporting scientific
research implementation, yet their ability to generate correct and executable
code remains limited. Existing works largely adopt one-shot settings, ignoring
the iterative and feedback-driven nature of realistic workflows of scientific
research development. To address this gap, we present RECODE-H, a benchmark of
102 tasks from research papers and repositories that evaluates LLM agents
through multi-turn interactions with LLM-simulated human feedback. It includes
structured instructions,unit tests, and a five-level feedback hierarchy to
reflect realistic researcher-agent collaboration. We further present
ReCodeAgent, a framework that integrates feedback into iterative code
generation. Experiments with leading LLMs, including GPT-5, Claude-Sonnet-4,
DeepSeek-V3.1, and Gemini 2.5, show substantial performance gains with richer
feedback, while also highlighting ongoing challenges in the generation of
complex research code. RECODE-H establishes a foundation for developing
adaptive, feedback-driven LLM agents in scientific research implementation

</details>


### [164] [BanglaTalk: Towards Real-Time Speech Assistance for Bengali Regional Dialects](https://arxiv.org/abs/2510.06188)
*Jakir Hasan,Shubhashis Roy Dipta*

Main category: cs.CL

TL;DR: 该论文提出了BanglaTalk，这是第一个支持孟加拉语地区方言的实时语音助手系统，针对低带宽和低延迟进行了优化，并显著提升了语音识别性能。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语作为一种资源稀缺且方言多样的语言，在实时语音助手系统方面进展缓慢，现有系统仅支持标准孟加拉语且不适合实时应用，严重影响了信息可达性与包容性。

Method: 该系统采用客户端-服务器架构，利用实时传输协议（RTP）实现低延迟通信；为解决方言差异问题，引入了方言感知的ASR（自动语音识别）系统BRDialect，基于IndicWav2Vec模型在十种孟加拉地区方言上微调；通过在RegSpeech12数据集评估性能。

Result: BRDialect在RegSpeech12数据集上，识别准确率相比基线ASR模型提升了12.41-33.98%；整个系统可在24 kbps低带宽下运行，端到端延迟仅为4.9秒。

Conclusion: BanglaTalk有效实现了低带宽、低延迟及方言适配，使实时语音助手系统在孟加拉语多样社区中更具包容性、交互性和实用性，对提升信息可访问性有重要意义。

Abstract: Real-time speech assistants are becoming increasingly popular for ensuring
improved accessibility to information. Bengali, being a low-resource language
with a high regional dialectal diversity, has seen limited progress in
developing such systems. Existing systems are not optimized for real-time use
and focus only on standard Bengali. In this work, we present BanglaTalk, the
first real-time speech assistance system for Bengali regional dialects.
BanglaTalk follows the client-server architecture and uses the Real-time
Transport Protocol (RTP) to ensure low-latency communication. To address
dialectal variation, we introduce a dialect-aware ASR system, BRDialect,
developed by fine-tuning the IndicWav2Vec model in ten Bengali regional
dialects. It outperforms the baseline ASR models by 12.41-33.98% on the
RegSpeech12 dataset. Furthermore, BanglaTalk can operate at a low bandwidth of
24 kbps while maintaining an average end-to-end delay of 4.9 seconds. Low
bandwidth usage and minimal end-to-end delay make the system both
cost-effective and interactive for real-time use cases, enabling inclusive and
accessible speech technology for the diverse community of Bengali speakers.

</details>


### [165] [Latent Speech-Text Transformer](https://arxiv.org/abs/2510.06195)
*Yen-Ju Lu,Yashesh Gaur,Wei Zhou,Benjamin Muller,Jesus Villalba,Najim Dehak,Luke Zettlemoyer,Gargi Ghosh,Mike Lewis,Srinivasan Iyer,Duc Le*

Main category: cs.CL

TL;DR: 本文提出了Latent Speech-Text Transformer (LST)，通过对语音token进行动态聚合，提升了语音-文本模型的对齐效率和计算效率，取得了更好的基准测试表现。


<details>
  <summary>Details</summary>
Motivation: 现有自回归语音-文本模型虽然能够在理解和生成等任务上取得突破性进展，但语音token相比文本token序列过长，导致训练和推理时在两种模态的计算量严重失衡，同时限制了语音与文本的高效对齐和模型的可扩展性。

Method: 作者提出了一种Latent Speech-Text Transformer (LST)方法，将冗长的语音token序列通过动态聚合形成高层次的语音补丁（latent speech patches），这些补丁既可以与文本单元对齐以提升能力迁移，也能通过聚合常见语音序列（如静音）来提高计算效率。

Result: LST方法在语音到语音及文本到文本的各项基准测试中均优于传统方法。在HellaSwag故事补全任务中，LST在计算受控训练下语音准确率提升6.5%，数据受控下提升5.3%，文本性能亦有所提升。

Conclusion: LST能显著提升语音-文本模型在代表性对齐和计算效率方面的表现，为大规模语音-文本跨模态建模提供了有效手段。相关模型、代码和评测数据将公开，有助于进一步研究。

Abstract: Auto-regressive speech-text models are typically pre-trained on a large
number of interleaved sequences of text tokens and raw speech encoded as speech
tokens using vector quantization. These models have demonstrated
state-of-the-art performance in speech-to-speech understanding and generation
benchmarks, together with promising scaling laws, primarily enabled by the
representational alignment between text and speech. Nevertheless, they suffer
from shortcomings, partly owing to the disproportionately longer sequences of
speech tokens in contrast to textual tokens. This results in a large compute
imbalance between modalities during pre-training as well as during inference,
and a potential hindrance to effectively aligning speech and text, ultimately
translating to several orders of magnitude slower scaling laws. We introduce
the Latent Speech-Text Transformer (LST), which makes pre-training speech-text
models more data-efficient by dynamically and inexpensively aggregating speech
tokens into latent speech patches. These patches serve as higher-level units
that can either align with corresponding textual units to aid capability
transfer or even encapsulate common speech sequences like silences to be more
compute-efficient. We show that LST outperforms vanilla approaches on
speech-to-speech as well as text-to-text benchmarks in both data- and
compute-controlled settings, the former indicating more effective
representational alignment and the latter indicating steeper scaling laws for
speech-text models. On HellaSwag story completion, LST achieves 6.5% absolute
gain in speech accuracy under compute-controlled training and 5.3% under
data-controlled training, while also improving text performance. We will
release our models, code, and the evaluation data to facilitate further
research.

</details>


### [166] [Peeking inside the Black-Box: Reinforcement Learning for Explainable and Accurate Relation Extraction](https://arxiv.org/abs/2510.06198)
*Xinyu Guo,Zhengliang Shi,Minglai Yang,Mahdi Rahimi,Mihai Surdeanu*

Main category: cs.CL

TL;DR: 提出CogRE框架，通过类认知推理与强化学习提升关系抽取的准确性与可解释性，在One-shot场景下显著优于已有方法。


<details>
  <summary>Details</summary>
Motivation: 传统关系抽取(RE)在可解释性和准确性上存在局限，尤其缺乏对语言型解释的有效监督，导致模型输出难以被人类理解和信任。当前RE方法对解释性关注不足，且One-shot场景下表现有限。因此，亟需一种能兼顾性能和可解释性的RE方法。

Method: CogRE包含两大创新：一是受认知科学启发，将关系抽取建模为多个逐步文本处理推理过程，从而提升模型推理的结构性和可控性；二是基于强化学习(RL)优化，设计新奖励函数，兼顾抽取准确度与解释质量。框架中，关键词通过大模型自动构建高质量词典提取，最终促进生成可解释结果。

Result: 在两个RE数据集和两个大模型（如Qwen2.5-15B-Instruct）上做One-shot实验，CogRE对One-shot NYT29数据集F1达24.65%，优于以往推理策略，结合强化学习进一步提升绝对性能23.46%。人工评测显示，模型生成的关系关键词与金标高度对齐，可解释性获得人类评价显著提升（相对提升54%）。

Conclusion: CogRE有效提升关系抽取的可解释性和准确性，尤其适用于One-shot场景，能输出关键字解释并被人类高质量理解，为可解释NLP任务探索了新范式。

Abstract: This paper introduces a framework for relation extraction (RE) that enhances
both accuracy and explainability. The framework has two key components: (i) a
reasoning mechanism that formulates relation extraction as a series of
text-processing steps inspired by cognitive science, and (ii) an optimization
process driven by reinforcement learning (RL) with a novel reward function
designed to improve both task accuracy and explanation quality. We call our
approach CogRE. Our framework addresses the lack of supervision for
language-based explanations in traditional RE by promoting outputs that include
important relation keywords. These keywords are drawn from a high-quality
dictionary that is automatically constructed using an LLM. We evaluate our
approach for the task of one-shot RE using two LLMs and two RE datasets. Our
experiments show that CogRE improves explanation quality by addressing two
common failure patterns in one-shot RE: poor attention focus and limited
one-shot learning capability. For example, our cognitive-structured reasoning
with Qwen2.5-15B-Instruct on One-shot NYT29 achieves 24.65% F1, surpassing
prior reasoning-based designs. Optimizing this approach with RL using our
reward further improves performance by +23.46% (absolute). Finally, human
evaluation shows that our best model generates relational keywords closely
aligned with gold labels, increasing human explanation quality ratings by 54%
(relative).

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [167] [VER: Vision Expert Transformer for Robot Learning via Foundation Distillation and Dynamic Routing](https://arxiv.org/abs/2510.05213)
*Yixiao Wang,Mingxiao Huo,Zhixuan Liang,Yushi Du,Lingfeng Sun,Haotian Lin,Jinghuan Shang,Chensheng Peng,Mohit Bansal,Mingyu Ding,Masayoshi Tomizuka*

Main category: cs.RO

TL;DR: 该论文提出了VER（Vision Expert transformer for Robot learning）方法，通过整合多个视觉基础模型（VFMs）实现更通用的机器人视觉感知，显著提升多任务机器人学习性能。


<details>
  <summary>Details</summary>
Motivation: 目前单一的视觉基础模型（VFM）虽然在特定领域表现出色，但泛化能力有限，难以适配多样化的机器人任务。现有通过多个VFM知识蒸馏的方法灵活性不高，且每次适应新任务都需要从头训练，代价昂贵。作者希望打造一种既能高效利用多VFM知识，又能高效适配机器人新任务的方法。

Method: 作者提出VER方法，首先在预训练阶段将多个VFM的知识蒸馏到专家库里。下游机器人任务实现时，仅需微调一个非常轻量的专家路由网络（参数量少于0.4%），动态选择最相关的视觉专家参与决策。同时引入Patchwise Expert Routing与课程式Top-K退火技术，实现专家动态选择的灵活性与精确性。

Result: 在17项不同的机器人任务及多种决策头上，VER实现了当前最优的性能。同时，VER在减少任务无关区域（如背景）的异常特征强度、聚焦任务关键视觉区域方面表现突出。

Conclusion: VER方法能够高效整合和利用多个视觉基础模型的知识，实现参数高效、可扩展、适应性强的机器人视觉学习，显著提升多任务场景的泛化能力。

Abstract: Pretrained vision foundation models (VFMs) advance robotic learning via rich
visual representations, yet individual VFMs typically excel only in specific
domains, limiting generality across tasks. Distilling multiple VFMs into a
unified representation for policy can mitigate this limitation but often yields
inflexible task-specific feature selection and requires costly full re-training
to incorporate robot-domain knowledge. We propose VER, a Vision Expert
transformer for Robot learning. During pretraining, VER distills multiple VFMs
into a vision expert library. It then fine-tunes only a lightweight routing
network (fewer than 0.4% of parameters) to dynamically select task-relevant
experts from the pretrained library for downstream robot tasks. We further
introduce Patchwise Expert Routing with Curriculum Top-K Annealing to improve
both flexibility and precision of dynamic expert selection. Moreover, VER
supports parameter-efficient finetuning for scalable expert utilization and
adaptive robot-domain knowledge integration. Across 17 diverse robotic tasks
and multiple policy heads, VER achieves state-of-the-art performance. We find
that VER reduces large-norm outliers in task-irrelevant regions (e.g.,
background) and concentrates on task-critical regions. Visualizations and codes
can be found in https://yixiaowang7.github.io/ver_page/.

</details>


### [168] [Adaptive Dynamics Planning for Robot Navigation](https://arxiv.org/abs/2510.05330)
*Lu Yuanjie,Mao Mingyang,Xu Tong,Wang Linji,Lin Xiaomin,Xiao Xuesu*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习的自适应动力学规划（ADP）方法，用于提升自主机器人导航的成功率、安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统分层规划系统在全局与局部规划间存在动力学不连续，导致复杂环境下轨迹跟踪失败。现有方法对动力学精度采用静态调节，不能适应环境复杂性的变化，造成计算资源浪费或不足。

Method: 提出ADP方法，通过强化学习动态调整机器人的动力学参数，使规划器能适应不同环境复杂度。ADP被整合进三种主流规划器，并设计了独立的ADP导航系统，与现有方法进行对比。

Result: 在仿真和真实机器人实验中，ADP方法在导航成功率、安全性和效率上均优于对比基线方法，表现出一致的提升效果。

Conclusion: ADP系统可以根据环境动态调节动力学，克服了静态方案的局限性，显著提升了自主机器人在复杂场景下的导航表现。

Abstract: Autonomous robot navigation systems often rely on hierarchical planning,
where global planners compute collision-free paths without considering
dynamics, and local planners enforce dynamics constraints to produce executable
commands. This discontinuity in dynamics often leads to trajectory tracking
failure in highly constrained environments. Recent approaches integrate
dynamics within the entire planning process by gradually decreasing its
fidelity, e.g., increasing integration steps and reducing collision checking
resolution, for real-time planning efficiency. However, they assume that the
fidelity of the dynamics should decrease according to a manually designed
scheme. Such static settings fail to adapt to environmental complexity
variations, resulting in computational overhead in simple environments or
insufficient dynamics consideration in obstacle-rich scenarios. To overcome
this limitation, we propose Adaptive Dynamics Planning (ADP), a
learning-augmented paradigm that uses reinforcement learning to dynamically
adjust robot dynamics properties, enabling planners to adapt across diverse
environments. We integrate ADP into three different planners and further design
a standalone ADP-based navigation system, benchmarking them against other
baselines. Experiments in both simulation and real-world tests show that ADP
consistently improves navigation success, safety, and efficiency.

</details>


### [169] [A multi-modal tactile fingertip design for robotic hands to enhance dexterous manipulation](https://arxiv.org/abs/2510.05382)
*Zhuowei Xu,Zilin Si,Kevin Zhang,Oliver Kroemer,Zeynep Temel*

Main category: cs.RO

TL;DR: 本论文提出了一种集成多模态触觉传感器的低成本、易制造、紧凑型机器人手指设计，实现了高精度操控且在多任务下性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有机器人手的触觉传感器存在成本高、制造和集成难、信号处理难等问题，限制了触觉传感在机器人灵巧操作中的普及和应用。作者希望设计一种更易用、更经济的触觉传感系统，提升机器手的操作能力。

Method: 作者设计了一种紧凑型机器人指尖，将应变片和接触麦克风两种传感器嵌入内部，实现对静态力和高频振动的多模态感知，并通过传感器标定实验证明其性能。随后对机器人进行多种操作任务实验，测试系统在不同视野遮挡下的表现。

Result: 实验显示，应变片可稳定测量0-5N范围的二维平面力，接触麦克风能够区分不同材质触碰。不同的触觉信息可根据任务阶段灵活组合或与视觉联合应用，显著提升复杂任务（如堆杯分杯）的成功率，达到100%的分杯准确率，远超纯视觉方法。

Conclusion: 该工作为机器人手提供了一种低成本、高适应性且易于制造的触觉解决方案，并通过多任务实验证实其在提升操作可靠性与精度方面的有效性，为未来机器人手的触觉应用推广提供了新方向。

Abstract: Tactile sensing holds great promise for enhancing manipulation precision and
versatility, but its adoption in robotic hands remains limited due to high
sensor costs, manufacturing and integration challenges, and difficulties in
extracting expressive and reliable information from signals. In this work, we
present a low-cost, easy-to-make, adaptable, and compact fingertip design for
robotic hands that integrates multi-modal tactile sensors. We use strain gauge
sensors to capture static forces and a contact microphone sensor to measure
high-frequency vibrations during contact. These tactile sensors are integrated
into a compact design with a minimal sensor footprint, and all sensors are
internal to the fingertip and therefore not susceptible to direct wear and tear
from interactions. From sensor characterization, we show that strain gauge
sensors provide repeatable 2D planar force measurements in the 0-5 N range and
the contact microphone sensor has the capability to distinguish contact
material properties. We apply our design to three dexterous manipulation tasks
that range from zero to full visual occlusion. Given the expressiveness and
reliability of tactile sensor readings, we show that different tactile sensing
modalities can be used flexibly in different stages of manipulation, solely or
together with visual observations to achieve improved task performance. For
instance, we can precisely count and unstack a desired number of paper cups
from a stack with 100\% success rate which is hard to achieve with vision only.

</details>


### [170] [Towards Online Robot Interaction Adaptation to Human Upper-limb Mobility Impairments in Return-to-Work Scenarios](https://arxiv.org/abs/2510.05425)
*Marta Lagomarsino,Francesco Tassi*

Main category: cs.RO

TL;DR: 本文提出了一个创新的自适应人机交互在线框架，能够根据用户的上肢障碍情况实时调整机器人行为，从而促进残障人士积极参与工作。实验显示该方法能个性化适配用户受限的活动范围，并鼓励其合理使用受限关节。


<details>
  <summary>Details</summary>
Motivation: 现有工作环境和人机协作方式往往假设用户身体健全，未能充分考虑上肢障碍人士的特殊需求，因此亟需更包容、自适应的HRI框架以提升其工作参与度。

Method: 方法上，作者将特定关节活动障碍的运动模型集成到分层最优控制器中，使机器人能够在线生成对用户关节受限情况敏感的自适应反应行为，并引导用户最大化利用残余的关节活动能力。框架通过移动机械臂的交接任务进行验证，涵盖不同关节障碍（如肘部、肩部关节炎和手腕僵硬）以及坐、站等不同工作场景，并与现有HRI方法做了定量和定性比较。

Result: 初步结果显示新框架能够根据用户不同的关节功能受限程度，个性化调整人机互动方式，既适配其活动范围又能促进其受限关节的合理动作；在多种障碍类型和任务场景下均表现优异。

Conclusion: 该框架展示了包容性自适应人机交互的可行性，为上肢障碍人士更好地参与工作提供了新型技术途径，并优于现有的人机工效学方法。

Abstract: Work environments are often inadequate and lack inclusivity for individuals
with upper-body disabilities. This paper presents a novel online framework for
adaptive human-robot interaction (HRI) that accommodates users' arm mobility
impairments, ultimately aiming to promote active work participation. Unlike
traditional human-robot collaboration approaches that assume able-bodied users,
our method integrates a mobility model for specific joint limitations into a
hierarchical optimal controller. This allows the robot to generate reactive,
mobility-aware behaviour online and guides the user's impaired limb to exploit
residual functional mobility. The framework was tested in handover tasks
involving different upper-limb mobility impairments (i.e., emulated elbow and
shoulder arthritis, and wrist blockage), under both standing and seated
configurations with task constraints using a mobile manipulator, and
complemented by quantitative and qualitative comparisons with state-of-the-art
ergonomic HRI approaches. Preliminary results indicated that the framework can
personalise the interaction to fit within the user's impaired range of motion
and encourage joint usage based on the severity of their functional
limitations.

</details>


### [171] [Active Semantic Perception](https://arxiv.org/abs/2510.05430)
*Huayi Tang,Pratik Chaudhari*

Main category: cs.RO

TL;DR: 本文提出了一种主动语义感知方法，利用场景的语义信息进行探索任务，并通过分层场景图对复杂室内环境进行建模。


<details>
  <summary>Details</summary>
Motivation: 传统探索方法通常只侧重于几何或动作空间，缺乏利用环境语义信息的能力，因此难以提高探索效率与理解场景结构。

Method: 作者提出使用分层多层次的场景图表示室内环境，将房间、物体、墙体、窗口等不同语义单元通过场景图建模。提出基于大语言模型（LLMs）的方法，对未观察区域采样生成合理的场景图，并通过样本计算候选航点的信息增益，从而指导主动的空间推理和探索行动。

Result: 在仿真复杂、真实的3D室内环境进行实验，定性和定量结果均表明该方法比现有基线方法更快、更准确地推断出环境的语义信息。

Conclusion: 该方法提升了利用环境语义进行主动感知与探索任务的能力，为复杂场景下高效空间理解和探索提供了有效的新途径。

Abstract: We develop an approach for active semantic perception which refers to using
the semantics of the scene for tasks such as exploration. We build a compact,
hierarchical multi-layer scene graph that can represent large, complex indoor
environments at various levels of abstraction, e.g., nodes corresponding to
rooms, objects, walls, windows etc. as well as fine-grained details of their
geometry. We develop a procedure based on large language models (LLMs) to
sample plausible scene graphs of unobserved regions that are consistent with
partial observations of the scene. These samples are used to compute an
information gain of a potential waypoint for sophisticated spatial reasoning,
e.g., the two doors in the living room can lead to either a kitchen or a
bedroom. We evaluate this approach in complex, realistic 3D indoor environments
in simulation. We show using qualitative and quantitative experiments that our
approach can pin down the semantics of the environment quicker and more
accurately than baseline approaches.

</details>


### [172] [AD-NODE: Adaptive Dynamics Learning with Neural ODEs for Mobile Robots Control](https://arxiv.org/abs/2510.05443)
*Shao-Yi Yu,Jen-Wei Wang,Maya Horii,Vikas Garg,Tarek Zohdi*

Main category: cs.RO

TL;DR: 本文提出了一种能够自适应环境变化的机器人动力学建模方法，无需直接获取环境信息，通过历史状态-动作推断环境，实现了在不同复杂度平台的路径和目标控制任务中的有效应用。


<details>
  <summary>Details</summary>
Motivation: 移动机器人在不确定和难以直接感知环境的场景下（如物流、农业），需要能够对环境变化自适应的动力学模型以提升控制性能，避免对环境显式信息的依赖。

Method: 提出了一种基于神经常微分方程（neural ODE）的自适应动力学模型，通过两阶段训练方式学习环境的潜在表示，该模型可以根据状态-动作历史推断当前环境情况，并便于与模型预测控制(MPC)集成。

Result: 在三种不同复杂度的机器人平台上（2D轮式差速机器人、3D四旋翼、以及Sphero BOLT小车），分别模拟了如轮子接触变化、风场波动、实际接触条件变化的环境，验证了所提方法在目标抵达与路径跟踪任务中的鲁棒性和适应性。

Conclusion: 实验结果显示，所提方法能够有效应对时空变化的环境，在仿真与现实系统中均具有良好的环境适应能力，为移动机器人在不确定环境下的自主控制提供了新的解决思路。

Abstract: Mobile robots, such as ground vehicles and quadrotors, are becoming
increasingly important in various fields, from logistics to agriculture, where
they automate processes in environments that are difficult to access for
humans. However, to perform effectively in uncertain environments using
model-based controllers, these systems require dynamics models capable of
responding to environmental variations, especially when direct access to
environmental information is limited. To enable such adaptivity and facilitate
integration with model predictive control, we propose an adaptive dynamics
model which bypasses the need for direct environmental knowledge by inferring
operational environments from state-action history. The dynamics model is based
on neural ordinary equations, and a two-phase training procedure is used to
learn latent environment representations. We demonstrate the effectiveness of
our approach through goal-reaching and path-tracking tasks on three robotic
platforms of increasing complexity: a 2D differential wheeled robot with
changing wheel contact conditions, a 3D quadrotor in variational wind fields,
and the Sphero BOLT robot under two contact conditions for real-world
deployment. Empirical results corroborate that our method can handle temporally
and spatially varying environmental changes in both simulation and real-world
systems.

</details>


### [173] [Correlation-Aware Dual-View Pose and Velocity Estimation for Dynamic Robotic Manipulation](https://arxiv.org/abs/2510.05536)
*Mahboubeh Zarei,Robin Chhabra,Farrokh Janabi-Sharifi*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的去中心化视觉融合方法，实现了机器人末端操作器对目标的高精度位姿和速度估计。该方法利用两套不同视角的视觉传感器，并通过自适应扩展卡尔曼滤波在Lie群上进行信息融合，实验结果优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人多视角传感融合大多采用中心化方法，复杂度高、实时性和鲁棒性受限，因此需要更高效、分布式的融合方案来提升系统整体的估计性能，尤其是在快速动态目标估计场景。

Method: 在机械臂上分别安装手持视觉（eye-in-hand）与定点视觉（eye-to-hand）两套传感器。针对目标的随机运动（随机加速度模型），分别在两个视角上各自独立运行基于Lie群的自适应扩展卡尔曼滤波器，分别估算位姿和速度。最终通过一种相关性感知的Lie群融合规则将两路信息解耦并优雅融合，输出全局精确的目标状态。

Result: 在实际搭建的UFactory xArm 850平台及Intel RealSense视觉条件下，对移动目标进行了跟踪实验。结果显示，该去中心化双视角估计方法在位姿和速度的精度与鲁棒性方面均有显著提升，超越了当前主流的中心化或单视角融合方案。

Conclusion: 本文方法能够在无需全局中心化处理的前提下，实现对动态目标位姿与速度的高精度鲁棒估计，对提升实际机器人操作的智能水平具有重要价值。

Abstract: Accurate pose and velocity estimation is essential for effective spatial task
planning in robotic manipulators. While centralized sensor fusion has
traditionally been used to improve pose estimation accuracy, this paper
presents a novel decentralized fusion approach to estimate both pose and
velocity. We use dual-view measurements from an eye-in-hand and an eye-to-hand
vision sensor configuration mounted on a manipulator to track a target object
whose motion is modeled as random walk (stochastic acceleration model). The
robot runs two independent adaptive extended Kalman filters formulated on a
matrix Lie group, developed as part of this work. These filters predict poses
and velocities on the manifold $\mathbb{SE}(3) \times \mathbb{R}^3 \times
\mathbb{R}^3$ and update the state on the manifold $\mathbb{SE}(3)$. The final
fused state comprising the fused pose and velocities of the target is obtained
using a correlation-aware fusion rule on Lie groups. The proposed method is
evaluated on a UFactory xArm 850 equipped with Intel RealSense cameras,
tracking a moving target. Experimental results validate the effectiveness and
robustness of the proposed decentralized dual-view estimation framework,
showing consistent improvements over state-of-the-art methods.

</details>


### [174] [ARRC: Advanced Reasoning Robot Control - Knowledge-Driven Autonomous Manipulation Using Retrieval-Augmented Generation](https://arxiv.org/abs/2510.05547)
*Eugene Vorobiov,Ammar Jaleel Mahmood,Salim Rezvani,Robin Chhabra*

Main category: cs.RO

TL;DR: 本文提出了一种结合RAG、RGB-D感知和安全执行机制的机器人控制系统，实现了自然语言到本地安全机器臂控制的桥接。实验证明该方法有效提升了计划的有效性和适应性。


<details>
  <summary>Details</summary>
Motivation: 自然语言指令与机器人本地安全控制之间存在较大鸿沟，需要安全、实用、低成本的桥接方案。

Method: 系统将挑选过的机器人知识（运动模式、任务模板、安全准则）存储于向量数据库，通过RAG检索任务相关知识，大语言模型生成结构化动作计划。配合RGB-D感知和软件安全门控，在经济型机械臂上实现执行。

Result: 在标准的桌面任务场景下进行实验，结果显示RAG方法能提升动作计划的有效性和适应性，且保障了本地感知和低层控制的安全性。

Conclusion: 基于RAG的机器人系统，在保证安全和本地化控制的同时，显著提升了机器人系统理解自然语言和执行复杂任务的能力。

Abstract: We present ARRC (Advanced Reasoning Robot Control), a practical system that
connects natural-language instructions to safe local robotic control by
combining Retrieval-Augmented Generation (RAG) with RGB-D perception and
guarded execution on an affordable robot arm. The system indexes curated robot
knowledge (movement patterns, task templates, and safety heuristics) in a
vector database, retrieves task-relevant context for each instruction, and
conditions a large language model (LLM) to produce JSON-structured action
plans. Plans are executed on a UFactory xArm 850 fitted with a Dynamixel-driven
parallel gripper and an Intel RealSense D435 camera. Perception uses AprilTag
detections fused with depth to produce object-centric metric poses. Execution
is enforced via software safety gates: workspace bounds, speed and force caps,
timeouts, and bounded retries. We describe the architecture, knowledge design,
integration choices, and a reproducible evaluation protocol for tabletop scan,
approach, and pick-place tasks. Experimental results demonstrate the efficacy
of the proposed approach. Our design shows that RAG-based planning can
substantially improve plan validity and adaptability while keeping perception
and low-level control local to the robot.

</details>


### [175] [GO-Flock: Goal-Oriented Flocking in 3D Unknown Environments with Depth Maps](https://arxiv.org/abs/2510.05553)
*Yan Rui Tan,Wenqi Liu,Wai Lun Leong,John Guan Zhong Tan,Wayne Wen Huei Yong,Fan Shi,Rodney Swee Huat Teo*

Main category: cs.RO

TL;DR: 本文提出了GO-Flock混合集群控制框架，有效解决传统人工势场(APF)方法在障碍物环境中的死锁和局部极小值问题，并在真实无人机团队中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 传统的APF方法在动态避障和集群控制中容易出现死锁与陷入局部极小值，现有多数解决方案效率低下，且很少有方法能在实际或复杂障碍环境中得到验证。

Method: GO-Flock框架通过集成感知模块与集群导航模块，感知模块处理深度图提取航迹点及虚拟代理以实现避障，下游导航模块结合新型APF实现复杂环境下的有效集群行为。

Result: GO-Flock在与被动APF方法的比较中展现出更优越的集群效果和突破局部极小值的能力，并在含有障碍物环境和包含实体与虚拟无人机的实物环实验中成功实现九机协同飞行。

Conclusion: GO-Flock混合框架克服了传统APF方法的主要缺陷，可在复杂、非理想环境中实现高效的多智能体协同导航，对实际无人机集群具有重要应用价值。

Abstract: Artificial Potential Field (APF) methods are widely used for reactive
flocking control, but they often suffer from challenges such as deadlocks and
local minima, especially in the presence of obstacles. Existing solutions to
address these issues are typically passive, leading to slow and inefficient
collective navigation. As a result, many APF approaches have only been
validated in obstacle-free environments or simplified, pseudo 3D simulations.
This paper presents GO-Flock, a hybrid flocking framework that integrates
planning with reactive APF-based control. GO-Flock consists of an upstream
Perception Module, which processes depth maps to extract waypoints and virtual
agents for obstacle avoidance, and a downstream Collective Navigation Module,
which applies a novel APF strategy to achieve effective flocking behavior in
cluttered environments. We evaluate GO-Flock against passive APF-based
approaches to demonstrate their respective merits, such as their flocking
behavior and the ability to overcome local minima. Finally, we validate
GO-Flock through obstacle-filled environment and also hardware-in-the-loop
experiments where we successfully flocked a team of nine drones, six physical
and three virtual, in a forest environment.

</details>


### [176] [DeLTa: Demonstration and Language-Guided Novel Transparent Object Manipulation](https://arxiv.org/abs/2510.05662)
*Taeyeop Lee,Gyuree Kang,Bowen Wen,Youngho Kim,Seunghyeok Back,In So Kweon,David Hyunchul Shim,Kuk-Jin Yoon*

Main category: cs.RO

TL;DR: 提出了一种新框架DeLTa，可以让机器人精准地进行长序列的透明物体操作，且只需单次演示即可泛化到新物体，大幅超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前关于透明物体的机器人操作研究主要集中在短期任务和基础抓取，缺乏对新颖透明物体的长时精准操作能力，且已有方法在泛化性上存在局限。

Method: 提出Demonstration and Language-Guided Novel Transparent Object Manipulation (DeLTa) 框架，融合了深度估计、6D位姿估计和视觉-语言任务规划。以单次演示为基础，无需类别先验或额外训练即可让机器人泛化操作策略。提出新的任务规划器优化VLM生成的规划，使其适用于单臂、手眼协同的长时操作任务。

Result: 通过综合评估显示，新方法在长序列、精准操作透明物体方面大大优于现有方法，能够泛化到未见过的透明物体，实用性和通用性更强。

Conclusion: DeLTa框架为机器人长时精准操作新颖透明物体提供了有效方案，展示了单次演示下的强泛化性能，推动了机器人对高难度透明物体操作任务的能力。

Abstract: Despite the prevalence of transparent object interactions in human everyday
life, transparent robotic manipulation research remains limited to
short-horizon tasks and basic grasping capabilities.Although some methods have
partially addressed these issues, most of them have limitations in
generalizability to novel objects and are insufficient for precise long-horizon
robot manipulation. To address this limitation, we propose DeLTa (Demonstration
and Language-Guided Novel Transparent Object Manipulation), a novel framework
that integrates depth estimation, 6D pose estimation, and vision-language
planning for precise long-horizon manipulation of transparent objects guided by
natural task instructions. A key advantage of our method is its
single-demonstration approach, which generalizes 6D trajectories to novel
transparent objects without requiring category-level priors or additional
training. Additionally, we present a task planner that refines the
VLM-generated plan to account for the constraints of a single-arm, eye-in-hand
robot for long-horizon object manipulation tasks. Through comprehensive
evaluation, we demonstrate that our method significantly outperforms existing
transparent object manipulation approaches, particularly in long-horizon
scenarios requiring precise manipulation capabilities. Project page:
https://sites.google.com/view/DeLTa25/

</details>


### [177] [Verifier-free Test-Time Sampling for Vision Language Action Models](https://arxiv.org/abs/2510.05681)
*Suhyeok Jang,Dongyoung Kim,Changyeon Kim,Youngsuk Kim,Jinwoo Shin*

Main category: cs.RO

TL;DR: 本文提出了一种名为Masking Distribution Guided Selection (MG-Select)的新方法，以提升视觉-语言-行动（VLA）模型在机器人控制任务中的表现，尤其是在精度要求高的场景。该方法利用模型内部分布信息，无需额外训练或外部模块，实现了多候选动作的最优选择，并在实际机器人操作任务中显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 尽管VLA模型在机器人控制中取得了进展，但其使用单一推理策略，在需要高精度的任务中表现有限。现有的测试时性能提升方法普遍需要额外训练或外部验证器，且泛化能力不足，因此亟需一种无需额外训练且更具泛化能力的方法。

Method: MG-Select框架在测试时，通过对候选动作的概率分布与参考分布之间的KL散度，作为置信度度量，选择最优动作。参考分布通过随机mask VLA的状态和语言输入生成，体现最大不确定性但仍与目标分布对齐。此外，通过训练时对状态和语言施加dropout，使模型能同时学习条件与无条件分布，进一步提升参考分布质量。

Result: MG-Select方法在真实机器人任务上分别在分布内/分布外任务上带来28%和35%的表现提升，并在RoboCasa抓取放置任务中，利用30个演示达到168%的相对增益。

Conclusion: MG-Select框架无需额外训练或外部模块，即可提升VLA模型在高精度机器人任务中的表现，并展现出良好的泛化能力。

Abstract: Vision-Language-Action models (VLAs) have demonstrated remarkable performance
in robot control. However, they remain fundamentally limited in tasks that
require high precision due to their single-inference paradigm. While test-time
scaling approaches using external verifiers have shown promise, they require
additional training and fail to generalize to unseen conditions. We propose
Masking Distribution Guided Selection (MG-Select), a novel test-time scaling
framework for VLAs that leverages the model's internal properties without
requiring additional training or external modules. Our approach utilizes KL
divergence from a reference action token distribution as a confidence metric
for selecting the optimal action from multiple candidates. We introduce a
reference distribution generated by the same VLA but with randomly masked
states and language conditions as inputs, ensuring maximum uncertainty while
remaining aligned with the target task distribution. Additionally, we propose a
joint training strategy that enables the model to learn both conditional and
unconditional distributions by applying dropout to state and language
conditions, thereby further improving the quality of the reference
distribution. Our experiments demonstrate that MG-Select achieves significant
performance improvements, including a 28%/35% improvement in real-world
in-distribution/out-of-distribution tasks, along with a 168% relative gain on
RoboCasa pick-and-place tasks trained with 30 demonstrations.

</details>


### [178] [Oracle-Guided Masked Contrastive Reinforcement Learning for Visuomotor Policies](https://arxiv.org/abs/2510.05692)
*Yuhang Zhang,Jiaping Xiao,Chao Yan,Mir Feroskhan*

Main category: cs.RO

TL;DR: OMC-RL通过将视觉感知与运动决策解耦，并引入教师策略指导，提升了视觉运动策略学习的效率与表现，并改善了泛化能力。


<details>
  <summary>Details</summary>
Motivation: 视觉输入维度高、灵活操作需求高导致现有视觉-动作策略学习方法样本效率低、仿真与现实差距大，该文为了解决这些难题提出新方法。

Method: 提出OMC-RL，将学习分为上下游两个阶段：上游通过掩码Transformer结合时序建模和对比学习，提取时序相关的视觉特征，下游利用有特权信息的教师策略进行早期监督，逐步减少指导，最终独立学习。特征提取训练好后编码器冻结，仅用于获取视觉特征。

Result: 在模拟和真实环境广泛实验证明，OMC-RL在样本效率、策略性能和泛化能力方面均显著优于主流方法。

Conclusion: OMC-RL有效提升了视觉运动控制策略学习的效率、最终表现及跨复杂场景的泛化能力，对视觉主导的强化学习具有实际推进作用。

Abstract: A prevailing approach for learning visuomotor policies is to employ
reinforcement learning to map high-dimensional visual observations directly to
action commands. However, the combination of high-dimensional visual inputs and
agile maneuver outputs leads to long-standing challenges, including low sample
efficiency and significant sim-to-real gaps. To address these issues, we
propose Oracle-Guided Masked Contrastive Reinforcement Learning (OMC-RL), a
novel framework designed to improve the sample efficiency and asymptotic
performance of visuomotor policy learning. OMC-RL explicitly decouples the
learning process into two stages: an upstream representation learning stage and
a downstream policy learning stage. In the upstream stage, a masked Transformer
module is trained with temporal modeling and contrastive learning to extract
temporally-aware and task-relevant representations from sequential visual
inputs. After training, the learned encoder is frozen and used to extract
visual representations from consecutive frames, while the Transformer module is
discarded. In the downstream stage, an oracle teacher policy with privileged
access to global state information supervises the agent during early training
to provide informative guidance and accelerate early policy learning. This
guidance is gradually reduced to allow independent exploration as training
progresses. Extensive experiments in simulated and real-world environments
demonstrate that OMC-RL achieves superior sample efficiency and asymptotic
policy performance, while also improving generalization across diverse and
perceptually complex scenarios.

</details>


### [179] [Stable Robot Motions on Manifolds: Learning Lyapunov-Constrained Neural Manifold ODEs](https://arxiv.org/abs/2510.05707)
*David Boetius,Abdelrahman Abdelnaby,Ashok Kumar,Stefan Leue,Abdalla Swikir,Fares J. Abu-Dakka*

Main category: cs.RO

TL;DR: 本论文提出了一种在黎曼流形上利用神经常微分方程学习稳定动力系统的通用框架，并通过实验验证了其在机器人运动规划中的有效性和实用性。


<details>
  <summary>Details</summary>
Motivation: 在机器人运动规划和控制中，学习具有稳定性的动力系统对于安全性和可靠性至关重要。然而，当轨迹定义在带有几何约束的黎曼流形上时，如何保证这种稳定性变得更加困难。

Method: 提出用神经常微分方程在黎曼流形上建模，通过将神经向量场投影到严格满足Lyapunov稳定性判据的空间，实现对系统各状态的全局稳定性保证。该框架灵活地以神经网络参数化基向量场和Lyapunov函数，使系统既能表达复杂轨迹，又能自然遵守流形结构。论文还给出高效的训练策略，并在多个流形上的真实数据集以及机器人运动任务中对方法进行了验证。

Result: 该方法在单位四元数流形（S^3）、对称正定矩阵流形及R^3×S^3空间内的机器人运动等任务中都表现出了高性能、良好的扩展性和实际应用能力。

Conclusion: 通过大量仿真和现实机器人实验，证明了该框架对于在复杂流形约束下的稳定运动学习具有很强的适用性和实用价值，为安全高效的机器人运动规划提供了有效工具。

Abstract: Learning stable dynamical systems from data is crucial for safe and reliable
robot motion planning and control. However, extending stability guarantees to
trajectories defined on Riemannian manifolds poses significant challenges due
to the manifold's geometric constraints. To address this, we propose a general
framework for learning stable dynamical systems on Riemannian manifolds using
neural ordinary differential equations. Our method guarantees stability by
projecting the neural vector field evolving on the manifold so that it strictly
satisfies the Lyapunov stability criterion, ensuring stability at every system
state. By leveraging a flexible neural parameterisation for both the base
vector field and the Lyapunov function, our framework can accurately represent
complex trajectories while respecting manifold constraints by evolving
solutions directly on the manifold. We provide an efficient training strategy
for applying our framework and demonstrate its utility by solving Riemannian
LASA datasets on the unit quaternion (S^3) and symmetric positive-definite
matrix manifolds, as well as robotic motions evolving on \mathbb{R}^3 \times
S^3. We demonstrate the performance, scalability, and practical applicability
of our approach through extensive simulations and by learning robot motions in
a real-world experiment.

</details>


### [180] [Federated Split Learning for Resource-Constrained Robots in Industrial IoT: Framework Comparison, Optimization Strategies, and Future Directions](https://arxiv.org/abs/2510.05713)
*Wanli Ni,Hui Tian,Shuai Wang,Chengyang Li,Lei Sun,Zhaohui Yang*

Main category: cs.RO

TL;DR: 本文系统梳理了在工业场景下适用于资源受限机器人的联邦切分学习（FedSL）框架，并比较同步、异步、分层及异构等模型，同时对融合策略、优化技术及未来挑战进行了归纳总结。


<details>
  <summary>Details</summary>
Motivation: 随着工业物联网与智能制造的发展，数据隐私保障、通信效率和设备异构性成为瓶颈，传统联邦学习难以满足实际需求，因此探索更适合工业机器人的高效协作式智能框架刻不容缓。

Method: 对工业应用中的同步、异步、分层和异构FedSL框架进行流程、扩展性与适应性的横向比较；归类输入级、中间级和输出级三类融合策略，并分别总结其优势；提出自适应模型压缩、切分层选择、计算与无线资源分配等优化技术，并在仿真环境中进行验证。

Result: 仿真实验数据显示，所述多种FedSL框架与优化方案在工业检测环境中能有效平衡隐私、效率和设备差异性，提升了智能制造系统的实际可用性和扩展性。

Conclusion: FedSL在智能工厂中具备重要应用前景，不同框架和融合策略可根据工业场景需求灵活选择，自适应优化技术可进一步提升系统性能，但仍存在诸如安全性、泛化能力与资源分配等待解决的问题。

Abstract: Federated split learning (FedSL) has emerged as a promising paradigm for
enabling collaborative intelligence in industrial Internet of Things (IoT)
systems, particularly in smart factories where data privacy, communication
efficiency, and device heterogeneity are critical concerns. In this article, we
present a comprehensive study of FedSL frameworks tailored for
resource-constrained robots in industrial scenarios. We compare synchronous,
asynchronous, hierarchical, and heterogeneous FedSL frameworks in terms of
workflow, scalability, adaptability, and limitations under dynamic industrial
conditions. Furthermore, we systematically categorize token fusion strategies
into three paradigms: input-level (pre-fusion), intermediate-level
(intra-fusion), and output-level (post-fusion), and summarize their respective
strengths in industrial applications. We also provide adaptive optimization
techniques to enhance the efficiency and feasibility of FedSL implementation,
including model compression, split layer selection, computing frequency
allocation, and wireless resource management. Simulation results validate the
performance of these frameworks under industrial detection scenarios. Finally,
we outline open issues and research directions of FedSL in future smart
manufacturing systems.

</details>


### [181] [Precise and Efficient Collision Prediction under Uncertainty in Autonomous Driving](https://arxiv.org/abs/2510.05729)
*Marc Kaufeld,Johannes Betz*

Main category: cs.RO

TL;DR: 本研究提出了两种高效方法，用于在自动驾驶中不确定驾驶条件下评估规划轨迹的碰撞风险，显著提高了实时风险感知规划的准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶规划中，由于感知噪声、本地化误差以及对其它交通参与者的不确定预测，传统的确定性碰撞检查方法往往结果不准确或过于保守，亟需更高效精确的碰撞概率计算方法以提升整体安全性和实用性。

Method: 提出了两种半解析方法计算与任意凸障碍物的碰撞概率。第一种方法评估自动驾驶车辆与周围障碍物的空间重叠概率，第二种方法则基于随机边界穿越事件估算碰撞概率。两种方法均融合了全状态的不确定性（包括位置、朝向和速度），适用于实时规划。

Result: 仿真验证表明，所提方法能够在保证计算速度高效的前提下，碰撞概率评估结果和Monte Carlo方法高度一致，显著减少了运行时间。

Conclusion: 所提方法能够高效准确地评估自动驾驶规划轨迹的碰撞概率，适用于风险感知规划场景，并作为开源软件工具供社区使用。

Abstract: This research introduces two efficient methods to estimate the collision risk
of planned trajectories in autonomous driving under uncertain driving
conditions. Deterministic collision checks of planned trajectories are often
inaccurate or overly conservative, as noisy perception, localization errors,
and uncertain predictions of other traffic participants introduce significant
uncertainty into the planning process. This paper presents two semi-analytic
methods to compute the collision probability of planned trajectories with
arbitrary convex obstacles. The first approach evaluates the probability of
spatial overlap between an autonomous vehicle and surrounding obstacles, while
the second estimates the collision probability based on stochastic boundary
crossings. Both formulations incorporate full state uncertainties, including
position, orientation, and velocity, and achieve high accuracy at computational
costs suitable for real-time planning. Simulation studies verify that the
proposed methods closely match Monte Carlo results while providing significant
runtime advantages, enabling their use in risk-aware trajectory planning. The
collision estimation methods are available as open-source software:
https://github.com/TUM-AVS/Collision-Probability-Estimation

</details>


### [182] [Human-in-the-loop Optimisation in Robot-assisted Gait Training](https://arxiv.org/abs/2510.05780)
*Andreas Christou,Andreas Sochopoulos,Elliot Lister,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 该论文研究了通过人-机协同优化算法（HILO）为下肢外骨骼实现个性化步态训练辅助的可能性，结果发现优化虽能针对个体找到不同参数，但实际步态表现无明显提升。


<details>
  <summary>Details</summary>
Motivation: 步行模式存在较大的个体差异和时间波动，需要外骨骼能够针对每个人提供个性化的协助，从而有效促进康复和独立性。

Method: 采用人-机协同优化（HILO）的方法，具体用CMA-ES算法不断调整外骨骼的弹性控制参数。在两天的实验中对6名健康受试者进行了研究。

Result: 优化算法能够为每位受试者收敛出独特的弹性参数，但在验证实验中，个性化参数未能带来步态表现的明显提升。

Conclusion: 研究表明人-机协同优化过程中人的行为变异和协同作用比基于规则的控制器个性化带来的微弱改进影响更大，说明现有个性化方法在实际步态康复中的效果有限，并揭示了人-机协同优化实际应用中的关键挑战。

Abstract: Wearable robots offer a promising solution for quantitatively monitoring gait
and providing systematic, adaptive assistance to promote patient independence
and improve gait. However, due to significant interpersonal and intrapersonal
variability in walking patterns, it is important to design robot controllers
that can adapt to the unique characteristics of each individual. This paper
investigates the potential of human-in-the-loop optimisation (HILO) to deliver
personalised assistance in gait training. The Covariance Matrix Adaptation
Evolution Strategy (CMA-ES) was employed to continuously optimise an
assist-as-needed controller of a lower-limb exoskeleton. Six healthy
individuals participated over a two-day experiment. Our results suggest that
while the CMA-ES appears to converge to a unique set of stiffnesses for each
individual, no measurable impact on the subjects' performance was observed
during the validation trials. These findings highlight the impact of
human-robot co-adaptation and human behaviour variability, whose effect may be
greater than potential benefits of personalising rule-based assistive
controllers. Our work contributes to understanding the limitations of current
personalisation approaches in exoskeleton-assisted gait rehabilitation and
identifies key challenges for effective implementation of human-in-the-loop
optimisation in this domain.

</details>


### [183] [VCoT-Grasp: Grasp Foundation Models with Visual Chain-of-Thought Reasoning for Language-driven Grasp Generation](https://arxiv.org/abs/2510.05827)
*Haoran Zhang,Shuanghao Bai,Wanqi Zhou,Yuedi Zhang,Qi Zhang,Pengxiang Ding,Cheng Chi,Donglin Wang,Badong Chen*

Main category: cs.RO

TL;DR: 本论文提出了一种全新的端到端视觉链式思维（Visual Chain-of-Thought, VCoT）抓取基础模型VCoT-Grasp，能在复杂环境下实现高效、可解释的多目标抓取。


<details>
  <summary>Details</summary>
Motivation: 现有的语言驱动抓取方法要么推理和泛化能力不足，要么依赖复杂的模块化流程，并且大多数基础模型过于强调语义和对话而不能很好地处理复杂、多物体抓取任务。

Method: 提出VCoT-Grasp，一种端到端抓取基础模型，通过视觉链式思维推理强化对图像的理解和抓取生成。采用多轮处理动态聚焦于视觉输入，同时生成可解释的推理轨迹。训练数据集VCoT-GraspSet包含16.7万张合成图像和1.36百万抓取标注，以及400多张真实图像和1200多个抓取标注。

Result: 在VCoT-GraspSet和真实机器人上进行的广泛实验证明，VCoT-Grasp有效提升了复杂环境下（包括新物体、新背景和干扰物）的抓取成功率和泛化能力。

Conclusion: VCoT-Grasp不仅显著提升了复杂场景下的机器人抓取表现，还具备出色的推理力和可解释性，也为后续融合视觉与推理的机器人抓取研究提供了新方向。

Abstract: Robotic grasping is one of the most fundamental tasks in robotic
manipulation, and grasp detection/generation has long been the subject of
extensive research. Recently, language-driven grasp generation has emerged as a
promising direction due to its practical interaction capabilities. However,
most existing approaches either lack sufficient reasoning and generalization
capabilities or depend on complex modular pipelines. Moreover, current grasp
foundation models tend to overemphasize dialog and object semantics, resulting
in inferior performance and restriction to single-object grasping. To maintain
strong reasoning ability and generalization in cluttered environments, we
propose VCoT-Grasp, an end-to-end grasp foundation model that incorporates
visual chain-of-thought reasoning to enhance visual understanding for grasp
generation. VCoT-Grasp adopts a multi-turn processing paradigm that dynamically
focuses on visual inputs while providing interpretable reasoning traces. For
training, we refine and introduce a large-scale dataset, VCoT-GraspSet,
comprising 167K synthetic images with over 1.36M grasps, as well as 400+
real-world images with more than 1.2K grasps, annotated with intermediate
bounding boxes. Extensive experiments on both VCoT-GraspSet and real robot
demonstrate that our method significantly improves grasp success rates and
generalizes effectively to unseen objects, backgrounds, and distractors. More
details can be found at https://zhanghr2001.github.io/VCoT-Grasp.github.io.

</details>


### [184] [A Co-Design Framework for Energy-Aware Monoped Jumping with Detailed Actuator Modeling](https://arxiv.org/abs/2510.05923)
*Aman Singh,Aastha Mishra,Deepak Kapa,Suryank Joshi,Shishir Kolathaya*

Main category: cs.RO

TL;DR: 本文提出了一种三阶段联合优化设计框架，能够在保持单足机器人跳跃高度的同时显著降低机械能耗，并支持自动化生成可直接制造的CAD模型。实验结果显示能耗减少50%，跳高0.8米。


<details>
  <summary>Details</summary>
Motivation: 以往单足机器人设计多单独优化跳高或能耗，且经常忽略齿轮箱参数、采用过于简化的驱动器质量模型，导致成果难以实际复现。本文动机为提出更实用的联合优化方法，兼顾性能和制造可行性。

Method: 作者提出了一个三阶段的联合作用优化框架，综合考虑驱动器质量、齿轮箱和控制参数，并在统一框架下进行优化。优化输出支持自动生成参数化CAD模型，无需大量人工干预。

Result: 新方法相比基线设计，机械能耗减少50%，同时维持了0.8米的跳高能力。

Conclusion: 该三阶段优化框架可使单足机器人实现能效与性能的平衡，有效推动从参数化设计到实际制造的自动化流程，对机器人设计领域具有重要价值。

Abstract: A monoped's jump height and energy consumption depend on both, its mechanical
design and control strategy. Existing co-design frameworks typically optimize
for either maximum height or minimum energy, neglecting their trade-off. They
also often omit gearbox parameter optimization and use oversimplified actuator
mass models, producing designs difficult to replicate in practice. In this
work, we introduce a novel three-stage co-design optimization framework that
jointly maximizes jump height while minimizing mechanical energy consumption of
a monoped. The proposed method explicitly incorporates realistic actuator mass
models and optimizes mechanical design (including gearbox) and control
parameters within a unified framework. The resulting design outputs are then
used to automatically generate a parameterized CAD model suitable for direct
fabrication, significantly reducing manual design iterations. Our experimental
evaluations demonstrate a 50 percent reduction in mechanical energy consumption
compared to the baseline design, while achieving a jump height of 0.8m. Video
presentation is available at http://y2u.be/XW8IFRCcPgM

</details>


### [185] [Learning to Crawl: Latent Model-Based Reinforcement Learning for Soft Robotic Adaptive Locomotion](https://arxiv.org/abs/2510.05957)
*Vaughn Gzenda,Robin Chhabra*

Main category: cs.RO

TL;DR: 本论文提出了一种基于模型的强化学习（MB-RL）方法，利用传感器推断出的潜在动力学模型，指导软体机器人爬行器优化其运动策略。


<details>
  <summary>Details</summary>
Motivation: 软体机器人因具备柔性形变能力，能通过与表面接触实现移动。但由于动力学模型不精确、传感器噪声大、运动步态难以自主发现，控制策略的设计十分困难。作者旨在解决这些挑战。

Method: 作者提出了潜在动力学模型结合MB-RL方法。通过机载传感器数据，推断出机器人的潜在动力学，并利用这些模型在actor-critic算法中进行策略优化。在仿真环境下，使用惯性测量单元(IMU)和ToF传感器作为观察输入，实现了对于爬行器平台的评估。

Result: 潜在动力学模型可实现短时运动预测，actor-critic算法成功发现了有效的运动策略。

Conclusion: 该方法展示了在仅有带噪传感器反馈的条件下，采用潜在动力学MB-RL可以实现软体机器人自适应、具身的运动控制，具有推进软体机器人自动化运动策略发现的潜力。

Abstract: Soft robotic crawlers are mobile robots that utilize soft body deformability
and compliance to achieve locomotion through surface contact. Designing control
strategies for such systems is challenging due to model inaccuracies, sensor
noise, and the need to discover locomotor gaits. In this work, we present a
model-based reinforcement learning (MB-RL) framework in which latent dynamics
inferred from onboard sensors serve as a predictive model that guides an
actor-critic algorithm to optimize locomotor policies. We evaluate the
framework on a minimal crawler model in simulation using inertial measurement
units and time-of-flight sensors as observations. The learned latent dynamics
enable short-horizon motion prediction while the actor-critic discovers
effective locomotor policies. This approach highlights the potential of
latent-dynamics MB-RL for enabling embodied soft robotic adaptive locomotion
based solely on noisy sensor feedback.

</details>


### [186] [The DISTANT Design for Remote Transmission and Steering Systems for Planetary Robotics](https://arxiv.org/abs/2510.05981)
*Cristina Luna,Alba Guerra,Almudena Moreno,Manuel Esquer,Willy Roa,Mateusz Krawczak,Robert Popela,Piotr Osica,Davide Nicolis*

Main category: cs.RO

TL;DR: 本文提出了一种名为DISTANT的新型行星探测车驱动与转向系统设计，将轮上的驱动和转向执行机构移动到车体受保护的温箱内部，提高了其在极端环境下的可靠性。


<details>
  <summary>Details</summary>
Motivation: 行星探测任务要求探测车在极端环境下长期运行，现有将驱动和转向机构安装在轮上的方式易受高低温循环、灰尘污染及机械磨损影响，可靠性不足。

Method: 该设计将轮上驱动和转向执行机构移至车体内的受保护温箱，采用双叉臂悬挂、万向节和绞盘式转向结构，并结合综合方案权衡分析，优化独立轮驱动、转向及悬挂管控能力，同时实现高效防尘与热管理。

Result: 系统满足50公里无性能损失的越野需求，集成了防尘措施及热管理解决方案。原理样机按1:3比例制造，计划2026年第一季度进行测试验证。

Conclusion: DISTANT系统设计显著提升了探测车在极端行星环境下的长期可靠性，有望为未来行星长距离行驶任务提供更稳健的机械基础。

Abstract: Planetary exploration missions require robust locomotion systems capable of
operating in extreme environments over extended periods. This paper presents
the DISTANT (Distant Transmission and Steering Systems) design, a novel
approach for relocating rover traction and steering actuators from
wheel-mounted positions to a thermally protected warm box within the rover
body. The design addresses critical challenges in long-distance traversal
missions by protecting sensitive components from thermal cycling, dust
contamination, and mechanical wear. A double wishbone suspension configuration
with cardan joints and capstan drive steering has been selected as the optimal
architecture following comprehensive trade-off analysis. The system enables
independent wheel traction, steering control, and suspension management whilst
maintaining all motorisation within the protected environment. The design meets
a 50 km traverse requirement without performance degradation, with integrated
dust protection mechanisms and thermal management solutions. Testing and
validation activities are planned for Q1 2026 following breadboard
manufacturing at 1:3 scale.

</details>


### [187] [AI-Enabled Capabilities to Facilitate Next-Generation Rover Surface Operations](https://arxiv.org/abs/2510.05985)
*Cristina Luna,Robert Field,Steven Kay*

Main category: cs.RO

TL;DR: 本论文提出了集成AI系统，显著提升了星球车自主性，实现了更快的速度与更高的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有星球车行驶速度较慢（约10 cm/s），极大限制了探索效率，亟需通过提升自主导航能力和速度改善任务性能。

Method: 论文提出三大AI系统：（1）FASTNAV远程障碍物检测器，通过计算机视觉实现高达1.0 m/s的安全行驶速度；（2）CISRU多机器人协调框架，实现人-机协作与现场资源利用；（3）ViBEKO和AIAXR基于深度学习的地形分类方法。

Result: 在火星类比环境下现场验证，达到技术成熟度等级4，各系统在行驶速度提升、地形分类准确率和运行安全性方面均有显著提升。

Conclusion: 集成AI系统能够大幅提升下一代星球探测任务的效率与安全性，为未来任务部署提供了关键技术支撑。

Abstract: Current planetary rovers operate at traverse speeds of approximately 10 cm/s,
fundamentally limiting exploration efficiency. This work presents integrated AI
systems which significantly improve autonomy through three components: (i) the
FASTNAV Far Obstacle Detector (FOD), capable of facilitating sustained 1.0 m/s
speeds via computer vision-based obstacle detection; (ii) CISRU, a multi-robot
coordination framework enabling human-robot collaboration for in-situ resource
utilisation; and (iii) the ViBEKO and AIAXR deep learning-based terrain
classification studies. Field validation in Mars analogue environments
demonstrated these systems at Technology Readiness Level 4, providing
measurable improvements in traverse speed, classification accuracy, and
operational safety for next-generation planetary missions.

</details>


### [188] [Coordinate-Consistent Localization via Continuous-Time Calibration and Fusion of UWB and SLAM Observations](https://arxiv.org/abs/2510.05992)
*Tien-Dat Nguyen,Thien-Minh Nguyen,Vinh-Hao Nguyen*

Main category: cs.RO

TL;DR: 本文提出了一种将UWB定位与SLAM数据融合的方法，通过两阶段校准实现多次运行中坐标系一致且高精度的定位。


<details>
  <summary>Details</summary>
Motivation: SLAM具有高精度但每次运行原点易变；UWB定位原点一致但依赖锚点精确布置。为解决长期定位一致性与精度兼得的问题，设计数据融合方法。

Method: 第一阶段：使用一次完整运行的里程计与UWB测距数据，结合高度和锚点间距离先验，进行批量优化求解，精确还原3D锚点坐标。第二阶段：在后续运行中，采用滑动窗口优化方法实时融合SLAM与UWB测量，确保在同一坐标系内定位。

Result: 在NTU VIRAL数据集上，六种无人机飞行场景实验表明，一次性校准可实现后续多次高精度定位。效果表明该方案兼具一致性与准确性。

Conclusion: 本文方法能有效融合SLAM与UWB定位优势，实现多次运行的高一致性和高准确度定位。源代码已开源，可供社区使用。

Abstract: Onboard simultaneous localization and mapping (SLAM) methods are commonly
used to provide accurate localization information for autonomous robots.
However, the coordinate origin of SLAM estimate often resets for each run. On
the other hand, UWB-based localization with fixed anchors can ensure a
consistent coordinate reference across sessions; however, it requires an
accurate assignment of the anchor nodes' coordinates. To this end, we propose a
two-stage approach that calibrates and fuses UWB data and SLAM data to achieve
coordinate-wise consistent and accurate localization in the same environment.
In the first stage, we solve a continuous-time batch optimization problem by
using the range and odometry data from one full run, incorporating height
priors and anchor-to-anchor distance factors to recover the anchors' 3D
positions. For the subsequent runs in the second stage, a sliding-window
optimization scheme fuses the UWB and SLAM data, which facilitates accurate
localization in the same coordinate system. Experiments are carried out on the
NTU VIRAL dataset with six scenarios of UAV flight, and we show that
calibration using data in one run is sufficient to enable accurate localization
in the remaining runs. We release our source code to benefit the community at
https://github.com/ntdathp/slam-uwb-calibration.

</details>


### [189] [Cross-Embodiment Dexterous Hand Articulation Generation via Morphology-Aware Learning](https://arxiv.org/abs/2510.06068)
*Heng Zhang,Kevin Yuchen Ma,Mike Zheng Shou,Weisi Lin,Yan Wu*

Main category: cs.RO

TL;DR: 本文提出了一种新的基于主抓取（eigengrasp）的端到端跨机械手形态通用抓取方法，通过对不同手的形态进行嵌入和降维，实现高效、泛化性强的多指灵巧抓取。


<details>
  <summary>Details</summary>
Motivation: 多指灵巧机械手抓取由于高维的关节动作和传统优化算法计算代价高导致难以推广。现有端到端方法需要针对特定机械手的大规模数据集训练，泛化能力弱，无法适应不同手型，因此需要一种能够高效泛化到不同机械手形态的抓取方法。

Method: 从机械手的形态描述中提取手型嵌入和主抓取集（eigengrasp set），通过端到端网络结合目标物体点云、手腕位姿等输入，预测低维空间中的关节系数，该系数经解码后可还原为完整关节动作。通过Kinematic-Aware Articulation Loss进行监督，突出指尖运动并结合手型特异性结构信息。

Result: 该方法在三种未见过的灵巧机械手和新物体上模拟测试，平均抓取成功率达到91.9%，单次推理时间小于0.4秒。对于全新手型，利用少量样本适应后在仿真环境中抓取新物体成功率为85.6%，现实实验成功率为87%。

Conclusion: 提出的主抓取降维和形态嵌入方法大幅提升了灵巧手跨形态抓取的泛化能力和推理效率，实验证明其在多类手型和物体上的优秀表现，为后续灵巧手智能抓取提供了技术基础。

Abstract: Dexterous grasping with multi-fingered hands remains challenging due to
high-dimensional articulations and the cost of optimization-based pipelines.
Existing end-to-end methods require training on large-scale datasets for
specific hands, limiting their ability to generalize across different
embodiments. We propose an eigengrasp-based, end-to-end framework for
cross-embodiment grasp generation. From a hand's morphology description, we
derive a morphology embedding and an eigengrasp set. Conditioned on these,
together with the object point cloud and wrist pose, an amplitude predictor
regresses articulation coefficients in a low-dimensional space, which are
decoded into full joint articulations. Articulation learning is supervised with
a Kinematic-Aware Articulation Loss (KAL) that emphasizes fingertip-relevant
motions and injects morphology-specific structure. In simulation on unseen
objects across three dexterous hands, our model attains a 91.9% average grasp
success rate with less than 0.4 seconds inference per grasp. With few-shot
adaptation to an unseen hand, it achieves 85.6% success on unseen objects in
simulation, and real-world experiments on this few-shot generalized hand
achieve an 87% success rate. The code and additional materials will be made
available upon publication on our project website
https://connor-zh.github.io/cross_embodiment_dexterous_grasping.

</details>


### [190] [Multi-Robot Distributed Optimization for Exploration and Mapping of Unknown Environments using Bioinspired Tactile-Sensor](https://arxiv.org/abs/2510.06085)
*Roman Ibrahimov,Jannik Matthias Heinen*

Main category: cs.RO

TL;DR: 本文提出了一种受生物启发的多机器人分布式优化系统，用于高效探索和建图未知环境，并在模拟实验中验证了效果。


<details>
  <summary>Details</summary>
Motivation: 为了提升多机器人系统在未知环境中探索与建图的效率，借鉴昆虫触角触觉探索行为，改善现有方法受限于中心化控制或低效探索的问题。

Method: 采用类蟑螂触角的触觉传感器和墙壁跟随行为，让每台机器人自主探索并记录碰撞点，然后通过分布式优化整合局部地图为全局2D地图。控制策略去中心化，提高了任务分配和环境探索的效率。

Result: 在带有三个障碍物的1.5x1.5米仿真环境中，使用e-puck机器人完成了实验，结果显示该系统能高覆盖率探索、有效减少碰撞并生成准确的2D地图。

Conclusion: 本方法证明了仿生多机器人分布式优化在未知环境探索和建图中的有效性，具备在搜索救援、工业检测和环境监测等实际应用潜力。

Abstract: This project proposes a bioinspired multi-robot system using Distributed
Optimization for efficient exploration and mapping of unknown environments.
Each robot explores its environment and creates a map, which is afterwards put
together to form a global 2D map of the environment. Inspired by wall-following
behaviors, each robot autonomously explores its neighborhood based on a tactile
sensor, similar to the antenna of a cockroach, mounted on the surface of the
robot. Instead of avoiding obstacles, robots log collision points when they
touch obstacles. This decentralized control strategy ensures effective task
allocation and efficient exploration of unknown terrains, with applications in
search and rescue, industrial inspection, and environmental monitoring. The
approach was validated through experiments using e-puck robots in a simulated
1.5 x 1.5 m environment with three obstacles. The results demonstrated the
system's effectiveness in achieving high coverage, minimizing collisions, and
constructing accurate 2D maps.

</details>


### [191] [Towards Autonomous Tape Handling for Robotic Wound Redressing](https://arxiv.org/abs/2510.06127)
*Xiao Liang,Lu Shen,Peihan Zhang,Soofiyan Atar,Florian Richter,Michael Yip*

Main category: cs.RO

TL;DR: 本文提出了一种用于慢性伤口护理的自主机器人系统，重点在于胶带的拆卸与粘贴两个关键步骤，通过仿人力操作和轨迹优化方法，有效提升机器人换药自动化的可行性。


<details>
  <summary>Details</summary>
Motivation: 慢性伤口（如糖尿病、压疮、静脉溃疡）护理耗时费力且成本高，目前主要依赖受过专业训练的医护人员手动操作。随着患者数量和医疗费用上升，急需自动化解决方案降低护理成本，并提升效果与可及性。

Method: 针对伤口换药中棘手的胶带操作问题，作者提出：（1）胶带初始剥离阶段，采用基于力反馈的模仿学习，利用远程操作示范数据进行训练；（2）胶带粘贴阶段，开发了数值轨迹优化方法，确保胶带平顺、无褶皱地应用于不同人体表面。

Result: 通过大量实验验证，所提出的方法在胶带操作的各环节都显示出稳定且可靠的性能，无论在定量测试还是集成的自动换药流程里均有良好表现。

Conclusion: 研究表明，胶带的精确操控是实现机器人自动换药的关键环节。本方法为医疗机器人在伤口护理领域的实用化奠定了基础，有望改善慢性伤口护理现状，降低成本，提高效果。

Abstract: Chronic wounds, such as diabetic, pressure, and venous ulcers, affect over
6.5 million patients in the United States alone and generate an annual cost
exceeding \$25 billion. Despite this burden, chronic wound care remains a
routine yet manual process performed exclusively by trained clinicians due to
its critical safety demands. We envision a future in which robotics and
automation support wound care to lower costs and enhance patient outcomes. This
paper introduces an autonomous framework for one of the most fundamental yet
challenging subtasks in wound redressing: adhesive tape manipulation.
Specifically, we address two critical capabilities: tape initial detachment
(TID) and secure tape placement. To handle the complex adhesive dynamics of
detachment, we propose a force-feedback imitation learning approach trained
from human teleoperation demonstrations. For tape placement, we develop a
numerical trajectory optimization method based to ensure smooth adhesion and
wrinkle-free application across diverse anatomical surfaces. We validate these
methods through extensive experiments, demonstrating reliable performance in
both quantitative evaluations and integrated wound redressing pipelines. Our
results establish tape manipulation as an essential step toward practical
robotic wound care automation.

</details>


### [192] [Vision-Guided Targeted Grasping and Vibration for Robotic Pollination in Controlled Environments](https://arxiv.org/abs/2510.06146)
*Jaehwan Jeong,Tuan-Anh Vu,Radha Lahoti,Jiawen Wang,Vivek Alumootil,Sangpil Kim,M. Khalid Jawed*

Main category: cs.RO

TL;DR: 该论文提出了一种基于视觉引导的机器人精确授粉系统，通过3D重建和振动建模，有效地实现了温室作物的自动授粉。


<details>
  <summary>Details</summary>
Motivation: 受限于受控农业环境中风无法授粉，以及对使用商业传粉昆虫的监管限制，目前人工授粉成本高、效率低，亟需寻找自动化替代方案。

Method: 系统装有RGB-D传感器，先对植物进行三维重建并在机器人坐标系中定位，规划安全抓取姿态。再结合弹性杆模型，预测不同驱动参数与花朵动力学的关系，优化最佳授粉策略。最后利用配备软夹爪的机械臂对茎干精确夹持并施加控制振动，促进花粉释放。

Result: 实验证明系统在主茎抓取成功率为92.5%，并通过仿真优化振动参数，有效保证了授粉效率且不损伤花朵。

Conclusion: 这是首次将视觉引导抓取与振动建模集成到自动化精密授粉中的机器人系统，实验表明其安全高效，为设施农业中的自动授粉提供了新途径。

Abstract: Robotic pollination offers a promising alternative to manual labor and
bumblebee-assisted methods in controlled agriculture, where wind-driven
pollination is absent and regulatory restrictions limit the use of commercial
pollinators. In this work, we present and validate a vision-guided robotic
framework that uses data from an end-effector mounted RGB-D sensor and combines
3D plant reconstruction, targeted grasp planning, and physics-based vibration
modeling to enable precise pollination. First, the plant is reconstructed in 3D
and registered to the robot coordinate frame to identify obstacle-free grasp
poses along the main stem. Second, a discrete elastic rod model predicts the
relationship between actuation parameters and flower dynamics, guiding the
selection of optimal pollination strategies. Finally, a manipulator with soft
grippers grasps the stem and applies controlled vibrations to induce pollen
release. End-to-end experiments demonstrate a 92.5\% main-stem grasping success
rate, and simulation-guided optimization of vibration parameters further
validates the feasibility of our approach, ensuring that the robot can safely
and effectively perform pollination without damaging the flower. To our
knowledge, this is the first robotic system to jointly integrate vision-based
grasping and vibration modeling for automated precision pollination.

</details>


### [193] [A Preview of HoloOcean 2.0](https://arxiv.org/abs/2510.06160)
*Blake Romrell,Abigail Austin,Braden Meyers,Ryan Anderson,Carter Noh,Joshua G. Mangelson*

Main category: cs.RO

TL;DR: HoloOcean 2.0 是一款综合性的高保真海洋机器人仿真器，支持多种任务，并引入了多项先进特性。


<details>
  <summary>Details</summary>
Motivation: 随着海洋机器人领域的关注度提升，对于高逼真度传感器、物理和视觉渲染的仿真需求不断增长，以便更好地支持自主海洋机器人的开发和验证。

Method: HoloOcean 2.0 通过迁移到 Unreal Engine 5.3，采用 Fossen 的先进动力学模型，并自定义实现 ROS2 通信桥接，显著提升了仿真的物理与通信能力。同时还在开发基于射线追踪的高效声纳、语义传感器、环境生成工具、体积环境特效以及真实波浪模拟等功能。

Result: HoloOcean 2.0 整合了高水平的动力学仿真、传感器仿真和视觉渲染，多项新特性显著提升了仿真真实度和多样性。

Conclusion: HoloOcean 2.0 显著增强了海洋机器人仿真的能力，有利于推动自主海洋机器人技术的开发、测试与验证。

Abstract: Marine robotics simulators play a fundamental role in the development of
marine robotic systems. With increased focus on the marine robotics field in
recent years, there has been significant interest in developing higher
fidelitysimulation of marine sensors, physics, and visual rendering
capabilities to support autonomous marine robot development and validation.
HoloOcean 2.0, the next major release of HoloOcean, brings state-of-the-art
features under a general marine simulator capable of supporting a variety of
tasks. New features in HoloOcean 2.0 include migration to Unreal Engine (UE)
5.3, advanced vehicle dynamics using models from Fossen, and support for ROS2
using a custom bridge. Additional features are currently in development,
including significantly more efficient ray tracing-based sidescan,
forward-looking, and bathymetric sonar implementations; semantic sensors;
environment generation tools; volumetric environmental effects; and realistic
waves.

</details>


### [194] [DYMO-Hair: Generalizable Volumetric Dynamics Modeling for Robot Hair Manipulation](https://arxiv.org/abs/2510.06199)
*Chengyang Zhao,Uksang Yoo,Arkadeep Narayan Chaudhury,Giljoo Nam,Jonathan Francis,Jeffrey Ichnowski,Jean Oh*

Main category: cs.RO

TL;DR: 本文介绍了一种机器人头发护理系统DYMO-Hair，通过新颖的动力学学习方法和预训练的3D潜空间，实现了对多样化发型的高效护理，且在仿真和真实环境中均优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 日常头发护理对行动不便者来说难以实现，同时对机器人系统而言也非常具有挑战性，原因在于头发结构复杂且动态多变。因此亟需一种能够适应多样发型，且具备强泛化能力的机器人头发护理方案。

Method: 提出了DYMO-Hair系统，其核心为一种新颖的基于动作条件的潜状态编辑机制，并融合了紧凑的3D多发型潜空间。该潜空间通过创新的头发物理模拟器进行大规模预训练，从而增强对不同发型的泛化能力。利用此动力学模型结合模型预测路径积分（MPPI）规划器，实现目标导向的视觉发型整理。

Result: 在仿真实验中，DYMO-Hair的动力学模型在多样、未知发型的局部变形建模上显著优于对比基线。在闭环头发护理任务中，相比目前最先进系统，几何误差平均降低22%，成功率提升42%。真实环境测试中，该系统还能零样本适配新假发，成功处理了多种挑战性发型。

Conclusion: DYMO-Hair率先建立了模型驱动的机器人头发护理基线，为实现更泛化、灵活和普适的开放环境下自动头发护理迈出了关键一步。

Abstract: Hair care is an essential daily activity, yet it remains inaccessible to
individuals with limited mobility and challenging for autonomous robot systems
due to the fine-grained physical structure and complex dynamics of hair. In
this work, we present DYMO-Hair, a model-based robot hair care system. We
introduce a novel dynamics learning paradigm that is suited for volumetric
quantities such as hair, relying on an action-conditioned latent state editing
mechanism, coupled with a compact 3D latent space of diverse hairstyles to
improve generalizability. This latent space is pre-trained at scale using a
novel hair physics simulator, enabling generalization across previously unseen
hairstyles. Using the dynamics model with a Model Predictive Path Integral
(MPPI) planner, DYMO-Hair is able to perform visual goal-conditioned hair
styling. Experiments in simulation demonstrate that DYMO-Hair's dynamics model
outperforms baselines on capturing local deformation for diverse, unseen
hairstyles. DYMO-Hair further outperforms baselines in closed-loop hair styling
tasks on unseen hairstyles, with an average of 22% lower final geometric error
and 42% higher success rate than the state-of-the-art system. Real-world
experiments exhibit zero-shot transferability of our system to wigs, achieving
consistent success on challenging unseen hairstyles where the state-of-the-art
system fails. Together, these results introduce a foundation for model-based
robot hair care, advancing toward more generalizable, flexible, and accessible
robot hair styling in unconstrained physical environments. More details are
available on our project page: https://chengyzhao.github.io/DYMOHair-web/.

</details>


### [195] [EmbodiedCoder: Parameterized Embodied Mobile Manipulation via Modern Coding Model](https://arxiv.org/abs/2510.06207)
*Zefu Lin,Rongxu Cui,Chen Hanning,Xiangyu Wang,Junjia Xu,Xiaojuan Jin,Chen Wenbo,Hui Zhou,Lue Fan,Wenling Li,Zhaoxiang Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种名为EmbodiedCoder的无须训练的新框架，通过代码生成直接驱动机器人操作，提升了机器人理解和执行自然语言指令的泛化能力与可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前机器人理解自然语言指令主要依赖大数据集，方法可扩展性和可解释性有限，并且对不同环境适应能力不足。亟需一种更通用、高效、透明的方法。

Method: 作者提出EmbodiedCoder框架，利用代码生成模型将高层自然语言指令映射为可直接执行的机器人代码轨迹，无需额外数据采集和微调。该方法灵活支持不同对象参数化及操作轨迹合成。

Result: 实验证明，EmbodiedCoder在真实移动机器人上的多样化、长期任务中表现鲁棒，能有效泛化到新对象和新环境。

Conclusion: EmbodiedCoder提供了高可解释性的高层-低层连接方案，验证了代码生成驱动下机器人智能从固定原语向通用性、灵活性提升，是实现更强机器人智能的重要方向。

Abstract: Recent advances in control robot methods, from end-to-end
vision-language-action frameworks to modular systems with predefined
primitives, have advanced robots' ability to follow natural language
instructions. Nonetheless, many approaches still struggle to scale to diverse
environments, as they often rely on large annotated datasets and offer limited
interpretability.In this work, we introduce EmbodiedCoder, a training-free
framework for open-world mobile robot manipulation that leverages coding models
to directly generate executable robot trajectories. By grounding high-level
instructions in code, EmbodiedCoder enables flexible object geometry
parameterization and manipulation trajectory synthesis without additional data
collection or fine-tuning.This coding-based paradigm provides a transparent and
generalizable way to connect perception with manipulation. Experiments on real
mobile robots show that EmbodiedCoder achieves robust performance across
diverse long-term tasks and generalizes effectively to novel objects and
environments.Our results demonstrate an interpretable approach for bridging
high-level reasoning and low-level control, moving beyond fixed primitives
toward versatile robot intelligence. See the project page at:
https://anonymous.4open.science/w/Embodied-Coder/

</details>
