<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 141]
- [cs.CL](#cs.CL) [Total: 86]
- [cs.RO](#cs.RO) [Total: 43]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Comparative Analysis of Algorithms for the Fitting of Tessellations to 3D Image Data](https://arxiv.org/abs/2507.14268)
*Andreas Alpers,Orkun Furat,Christian Jung,Matthias Neumann,Claudia Redenbach,Aigerim Saken,Volker Schmidt*

Main category: cs.CV

TL;DR: 本文比较了多种用于将镶嵌模型拟合到多晶体和泡沫等材料3D图像数据的优化策略。重点分析了Voronoi、Laguerre和广义平衡幂图（GBPDs）等模型的拟合方法，评估了不同优化技术的优劣以及模型复杂度、优化复杂度和拟合精度之间的权衡，并为方法选择提供了指导。


<details>
  <summary>Details</summary>
Motivation: 在材料科学中精确地从体素化3D图像复原微观结构如晶粒（grains）结构十分重要。现有方法模型和算法繁多，性能与适用性各异，因此有必要系统比较这些算法，并为实际应用提供参考。

Method: 本文回顾并实证比较了多种优化方法，包括线性和非线性规划、随机优化（交叉熵法）及梯度下降。针对Voronoi、Laguerre与GBPDs三类镶嵌模型，使用真实材料3D图像数据集，以晶粒体积、表面积和拓扑差异等量化指标评价拟合质量。

Result: 实验结果展示了不同方法在模型复杂度、优化难度和近似精度等维度的权衡。具体地，复杂模型通常需要更复杂的优化方法，但能得到更优的拟合效果。对多组数据的结果分析揭示，不同方法适合不同的数据和需求场景。

Conclusion: 本文工作为3D材料图像结构拟合任务中不同优化与模型策略的选择提供了实证参考，强调了需根据应用场景和平衡指标来选型，并对进一步改进有针对性地指明了方向。

Abstract: This paper presents a comparative analysis of algorithmic strategies for
fitting tessellation models to 3D image data of materials such as polycrystals
and foams. In this steadily advancing field, we review and assess
optimization-based methods -- including linear and nonlinear programming,
stochastic optimization via the cross-entropy method, and gradient descent --
for generating Voronoi, Laguerre, and generalized balanced power diagrams
(GBPDs) that approximate voxelbased grain structures. The quality of fit is
evaluated on real-world datasets using discrepancy measures that quantify
differences in grain volume, surface area, and topology. Our results highlight
trade-offs between model complexity, the complexity of the optimization
routines involved, and the quality of approximation, providing guidance for
selecting appropriate methods based on data characteristics and application
needs.

</details>


### [2] [Semantic Segmentation based Scene Understanding in Autonomous Vehicles](https://arxiv.org/abs/2507.14303)
*Ehsan Rassekh*

Main category: cs.CV

TL;DR: 本文提出并评估了多种基于深度学习的高效模型，通过语义分割提升自动驾驶车辆的场景理解能力，并指出不同特征提取骨干网络(backbone)对性能有显著影响。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能尤其是深度学习的发展，机器在复杂场景决策中的表现大幅提升，尤其在自动驾驶领域。因此，提升车辆对环境的感知和场景理解能力成为研究热点。

Method: 作者基于BDD100k数据集，设计并测试了多种语义分割模型，并尝试引入不同的骨干网络作为编码器，系统对比各方法效果。

Result: 实验结果表明，选用合适的骨干网络，模型的语义分割性能（如准确率、均值交并比mean IoU和损失函数）都得到了较大提升。

Conclusion: 合适的模型结构和骨干网络极大提升了自动驾驶场景下的语义分割效果，为更好理解车辆所处环境提供了技术基础。

Abstract: In recent years, the concept of artificial intelligence (AI) has become a
prominent keyword because it is promising in solving complex tasks. The need
for human expertise in specific areas may no longer be needed because machines
have achieved successful results using artificial intelligence and can make the
right decisions in critical situations. This process is possible with the help
of deep learning (DL), one of the most popular artificial intelligence
technologies. One of the areas in which the use of DL is used is in the
development of self-driving cars, which is very effective and important. In
this work, we propose several efficient models to investigate scene
understanding through semantic segmentation. We use the BDD100k dataset to
investigate these models. Another contribution of this work is the usage of
several Backbones as encoders for models. The obtained results show that
choosing the appropriate backbone has a great effect on the performance of the
model for semantic segmentation. Better performance in semantic segmentation
allows us to understand better the scene and the environment around the agent.
In the end, we analyze and evaluate the proposed models in terms of accuracy,
mean IoU, and loss function, and the results show that these metrics are
improved.

</details>


### [3] [CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation](https://arxiv.org/abs/2507.14312)
*Marc Lafon,Gustavo Adolfo Vargas Hakim,Clément Rambour,Christian Desrosier,Nicolas Thome*

Main category: cs.CV

TL;DR: 该论文提出了一种新型基于梯度的视觉-语言模型测试时自适应方法CLIPTTA，能有效提升模型在分布变化下的泛化能力，并提高了对异常数据的检测稳定性。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言模型（如CLIP）在零样本任务下表现优异，但在遇到分布转移时泛化能力不足。现有的测试时自适应方法，多采用熵最小化目标，但这与VLM的对比训练方式并不一致，导致自适应有限并引发诸如伪标签漂移和类别塌缩等问题。因此亟需一种更加契合VLM对比训练特性的新自适应方法。

Method: 作者提出CLIPTTA，一种梯度驱动的TTA方法，采用与CLIP训练目标一致的软对比损失，理论分析表明其batch-aware设计能缓解类别塌缩风险。此外，CLIPTTA进一步扩展到open-set场景，针对同时含分布内和分布外样本，通过引入Outlier Contrastive Exposure（OCE）损失提升分布外检测能力。

Result: 在涵盖多种分布变化的75个数据集上评测，CLIPTTA在表现上优于基于熵的自适应方法，并在众多数据集上超越或媲美现有最新TTA方法，在稳定性上表现更佳。

Conclusion: CLIPTTA方法有效提升了VLM在分布变化下的稳健性和适应性，缓解了熵最小化TTA带来的固有缺陷，在多种任务和场景下展现了优越的性能与更好的一致性。

Abstract: Vision-language models (VLMs) like CLIP exhibit strong zero-shot capabilities
but often fail to generalize under distribution shifts. Test-time adaptation
(TTA) allows models to update at inference time without labeled data, typically
via entropy minimization. However, this objective is fundamentally misaligned
with the contrastive image-text training of VLMs, limiting adaptation
performance and introducing failure modes such as pseudo-label drift and class
collapse. We propose CLIPTTA, a new gradient-based TTA method for
vision-language models that leverages a soft contrastive loss aligned with
CLIP's pre-training objective. We provide a theoretical analysis of CLIPTTA's
gradients, showing how its batch-aware design mitigates the risk of collapse.
We further extend CLIPTTA to the open-set setting, where both in-distribution
(ID) and out-of-distribution (OOD) samples are encountered, using an Outlier
Contrastive Exposure (OCE) loss to improve OOD detection. Evaluated on 75
datasets spanning diverse distribution shifts, CLIPTTA consistently outperforms
entropy-based objectives and is highly competitive with state-of-the-art TTA
methods, outperforming them on a large number of datasets and exhibiting more
stable performance across diverse shifts.

</details>


### [4] [A Hidden Stumbling Block in Generalized Category Discovery: Distracted Attention](https://arxiv.org/abs/2507.14315)
*Qiyu Xu,Zhanxuan Hu,Yu Duan,Ercheng Pei,Yonghang Tai*

Main category: cs.CV

TL;DR: 本文提出一种名为Attention Focusing (AF) 的机制，通过剪除非信息性token，改善了现有广义类别发现（GCD）方法中模型注意力分散的问题，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的GCD方法在处理无标签数据时，模型容易将注意力分散到与任务无关的背景区域，导致特征提取效果不佳。针对这一隐藏难点，作者提出需要提升模型关注关键对象区域的能力，从而优化GCD任务表现。

Method: 提出了Attention Focusing（AF）机制，由两个简单且有效的组件组成：Token Importance Measurement（TIME）用于多尺度地量化token的重要性；Token Adaptive Pruning（TAP）根据TIME给出的多尺度重要性分数自适应地剪除无信息token。AF模块轻量、结构灵活，可嵌入现有GCD方法中，基本不增加计算开销。

Result: 在典型的GCD方法SimGCD中集成AF后，性能最高提升15.4%，并且计算开销极小。

Conclusion: Attention Focusing机制能有效解决GCD任务中注意力分散问题，提升模型准确性且几乎不增加资源消耗，对现有GCD方法具有良好的通用性和实际应用潜力。

Abstract: Generalized Category Discovery (GCD) aims to classify unlabeled data from
both known and unknown categories by leveraging knowledge from labeled known
categories. While existing methods have made notable progress, they often
overlook a hidden stumbling block in GCD: distracted attention. Specifically,
when processing unlabeled data, models tend to focus not only on key objects in
the image but also on task-irrelevant background regions, leading to suboptimal
feature extraction. To remove this stumbling block, we propose Attention
Focusing (AF), an adaptive mechanism designed to sharpen the model's focus by
pruning non-informative tokens. AF consists of two simple yet effective
components: Token Importance Measurement (TIME) and Token Adaptive Pruning
(TAP), working in a cascade. TIME quantifies token importance across multiple
scales, while TAP prunes non-informative tokens by utilizing the multi-scale
importance scores provided by TIME. AF is a lightweight, plug-and-play module
that integrates seamlessly into existing GCD methods with minimal computational
overhead. When incorporated into one prominent GCD method, SimGCD, AF achieves
up to 15.4% performance improvement over the baseline with minimal
computational overhead. The implementation code is provided in
https://github.com/Afleve/AFGCD.

</details>


### [5] [Hallucination Score: Towards Mitigating Hallucinations in Generative Image Super-Resolution](https://arxiv.org/abs/2507.14367)
*Weiming Ren,Raghav Goyal,Zhiming Hu,Tristan Ty Aumentado-Armstrong,Iqbal Mohomed,Alex Levinshtein*

Main category: cs.CV

TL;DR: 本文关注生成式超分辨（GSR）图像中的幻觉伪影问题，通过多模态大语言模型(MLLM)进行量化和分析，并提出利用深度特征距离优化GSR模型以减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 尽管生成式超分辨模型在感知质量上优于传统方法，但实际生成的细节可能与低分辨率输入或真实高分辨率图像不符（即幻觉伪影），影响其实际应用，因此亟需有效分析和缓解此问题。

Method: 论文提出用多模态大语言模型（MLLM）根据特定提示词，对GSR结果中的幻觉视觉元素进行评估，得出幻觉分数（HS），并分析该分数与常用图像质量指标和深度特征的关系。进一步地，将与幻觉分数高度相关的深度特征距离作为可微分奖励函数，优化模型以减少幻觉。

Result: 实验发现，MLLM生成的幻觉分数与人类主观评价高度一致，并为超分辨模型性能评估提供了有别于传统指标的补充信息。同时，某些深度特征距离与幻觉分数高度相关，将这类特征距离作为损失函数有助于缓解幻觉问题。

Conclusion: 文章提出的基于MLLM的幻觉评价方法更好地反映了人类感知，并揭示了深度特征与幻觉的相关性，为提升GSR模型的实际可靠性和可用性提供了新方法与指标。

Abstract: Generative super-resolution (GSR) currently sets the state-of-the-art in
terms of perceptual image quality, overcoming the "regression-to-the-mean" blur
of prior non-generative models. However, from a human perspective, such models
do not fully conform to the optimal balance between quality and fidelity.
Instead, a different class of artifacts, in which generated details fail to
perceptually match the low resolution image (LRI) or ground-truth image (GTI),
is a critical but under studied issue in GSR, limiting its practical
deployments. In this work, we focus on measuring, analyzing, and mitigating
these artifacts (i.e., "hallucinations"). We observe that hallucinations are
not well-characterized with existing image metrics or quality models, as they
are orthogonal to both exact fidelity and no-reference quality. Instead, we
take advantage of a multimodal large language model (MLLM) by constructing a
prompt that assesses hallucinatory visual elements and generates a
"Hallucination Score" (HS). We find that our HS is closely aligned with human
evaluations, and also provides complementary insights to prior image metrics
used for super-resolution (SR) models. In addition, we find certain deep
feature distances have strong correlations with HS. We therefore propose to
align the GSR models by using such features as differentiable reward functions
to mitigate hallucinations.

</details>


### [6] [DUSTrack: Semi-automated point tracking in ultrasound videos](https://arxiv.org/abs/2507.14368)
*Praneeth Namburi,Roger Pallarès-López,Jessica Rosendorf,Duarte Folgado,Brian W. Anthony*

Main category: cs.CV

TL;DR: 本论文提出DUSTrack——一个结合深度学习与光流技术的超声B超视频组织点追踪工具，能有效提升追踪精度与适用性。


<details>
  <summary>Details</summary>
Motivation: 超声成像因其安全、无创等优点，在医学、生物力学和运动科学等领域被广泛应用。然而，B超图像存在散斑噪声、边缘对比度低和三维运动等问题，导致组织追踪效果不佳，限制了其在解剖标志追踪和组织动力学量化中的临床与科研应用价值。因此，急需一种更为稳定、精确且易用的点追踪系统。

Method: 作者开发了DUSTrack框架，融合深度学习网络与光流算法，实现对超声B超视频中任意点的半自动高质量追踪。系统配备图形用户界面，方便生成训练数据并支持模型迭代优化；同时引入创新的光流滤波方案，有效去除帧间高频噪声并保留快速组织运动。

Result: 在实际应用中，DUSTrack在追踪精度上优于多种当前零样本点追踪器，并与某些专用方法表现相当。通过心脏壁运动、上肢运动过程肌肉变形分析、踝关节跖屈肌束追踪等三个实例，展示了其通用性和广泛应用前景。

Conclusion: DUSTrack为超声视频组织点追踪提供了开源、强大且灵活的工具，具备优异的通用性与可扩展性，可为临床和生物力学研究中组织动力学量化带来重要助力。

Abstract: Ultrasound technology enables safe, non-invasive imaging of dynamic tissue
behavior, making it a valuable tool in medicine, biomechanics, and sports
science. However, accurately tracking tissue motion in B-mode ultrasound
remains challenging due to speckle noise, low edge contrast, and out-of-plane
movement. These challenges complicate the task of tracking anatomical landmarks
over time, which is essential for quantifying tissue dynamics in many clinical
and research applications. This manuscript introduces DUSTrack (Deep learning
and optical flow-based toolkit for UltraSound Tracking), a semi-automated
framework for tracking arbitrary points in B-mode ultrasound videos. We combine
deep learning with optical flow to deliver high-quality and robust tracking
across diverse anatomical structures and motion patterns. The toolkit includes
a graphical user interface that streamlines the generation of high-quality
training data and supports iterative model refinement. It also implements a
novel optical-flow-based filtering technique that reduces high-frequency
frame-to-frame noise while preserving rapid tissue motion. DUSTrack
demonstrates superior accuracy compared to contemporary zero-shot point
trackers and performs on par with specialized methods, establishing its
potential as a general and foundational tool for clinical and biomechanical
research. We demonstrate DUSTrack's versatility through three use cases:
cardiac wall motion tracking in echocardiograms, muscle deformation analysis
during reaching tasks, and fascicle tracking during ankle plantarflexion. As an
open-source solution, DUSTrack offers a powerful, flexible framework for point
tracking to quantify tissue motion from ultrasound videos. DUSTrack is
available at https://github.com/praneethnamburi/DUSTrack.

</details>


### [7] [CRAFT: A Neuro-Symbolic Framework for Visual Functional Affordance Grounding](https://arxiv.org/abs/2507.14426)
*Zhou Chen,Joe Lin,Sathyanarayanan N. Aakur*

Main category: cs.CV

TL;DR: CRAFT是一个神经符号框架，通过整合知识库和视觉模型，实现可解释的场景理解和动作关联识别。


<details>
  <summary>Details</summary>
Motivation: 自动识别场景中能够支持特定动作（如“切割”）的物体对于智能体的场景理解和决策至关重要，但现有方法往往缺乏可解释性和鲁棒性。为此，作者希望结合符号知识和视觉信息，提升系统的解释性和准确性。

Method: CRAFT框架将ConceptNet等常识知识库和语言模型的结构化先验与CLIP等视觉模型的证据结合，通过基于能量的迭代推理机制优化预测。该方法可透明地将符号结构与感知信息结合，实现目标导向的决策。

Result: 在涉及多个物体且无标签输入的场景下，CRAFT不仅提升了识别动作相关物体的准确性，也显著增强了模型的可解释性。

Conclusion: CRAFT展现出在鲁棒与可信赖的场景理解方面的潜力，是实现可解释智能体的重要探索。

Abstract: We introduce CRAFT, a neuro-symbolic framework for interpretable affordance
grounding, which identifies the objects in a scene that enable a given action
(e.g., "cut"). CRAFT integrates structured commonsense priors from ConceptNet
and language models with visual evidence from CLIP, using an energy-based
reasoning loop to refine predictions iteratively. This process yields
transparent, goal-driven decisions to ground symbolic and perceptual
structures. Experiments in multi-object, label-free settings demonstrate that
CRAFT enhances accuracy while improving interpretability, providing a step
toward robust and trustworthy scene understanding.

</details>


### [8] [Adaptive 3D Gaussian Splatting Video Streaming](https://arxiv.org/abs/2507.14432)
*Han Gong,Qiyue Li,Zhi Liu,Hao Zhou,Peng Yuan Zhou,Zhu Li,Jie Li*

Main category: cs.CV

TL;DR: 该论文提出了一种创新的3D Gaussian splatting（3DGS）体积视频流媒体系统，实现了更高效的数据压缩和高传输质量。实验证明，该方法在视频质量、压缩效率和传输速率方面优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 3DGS的出现提升了体积视频的表现质量，但也带来了数据量大和压缩、传输复杂的难题。为了解决3DGS视频高带宽、高复杂度下的流媒体传输挑战，作者提出了新的方法。

Method: 设计基于高斯变形场的3DGS视频构建方法，并结合混合显著性分块和分级质量建模，实现高效压缩和自适应带宽波动，保证高传输质量。此外，作者还搭建了完整的3DGS视频流媒体系统并进行了实验验证。

Result: 所提出的方法在视频质量、压缩效果和传输速率等方面均优于现有的技术。

Conclusion: 创新的3DGS体积视频流媒体框架能够有效解决大数据量和高复杂度下的流媒体传输问题，为高质量3DGS内容的实用化奠定了基础。

Abstract: The advent of 3D Gaussian splatting (3DGS) has significantly enhanced the
quality of volumetric video representation. Meanwhile, in contrast to
conventional volumetric video, 3DGS video poses significant challenges for
streaming due to its substantially larger data volume and the heightened
complexity involved in compression and transmission. To address these issues,
we introduce an innovative framework for 3DGS volumetric video streaming.
Specifically, we design a 3DGS video construction method based on the Gaussian
deformation field. By employing hybrid saliency tiling and differentiated
quality modeling of 3DGS video, we achieve efficient data compression and
adaptation to bandwidth fluctuations while ensuring high transmission quality.
Then we build a complete 3DGS video streaming system and validate the
transmission performance. Through experimental evaluation, our method
demonstrated superiority over existing approaches in various aspects, including
video quality, compression effectiveness, and transmission rate.

</details>


### [9] [IRGPT: Understanding Real-world Infrared Image with Bi-cross-modal Curriculum on Large-scale Benchmark](https://arxiv.org/abs/2507.14449)
*Zhe Cao,Jin Zhang,Ruiheng Zhang*

Main category: cs.CV

TL;DR: 本文提出了IRGPT，这是首个针对真实世界红外图像的多模态大语言模型，并构建了一个包含26万红外图像-文本对的大型数据集IR-TD，提出跨模态迁移学习策略，在9项任务上实现了领先性能。


<details>
  <summary>Details</summary>
Motivation: 红外图像因获取难度大、配套文本稀缺以及具有独特的成像特性，导致现有视觉-语言模型难以直接应用。当前主流做法大多依赖可见光图像风格迁移生成合成红外图，无法真实捕捉红外的领域特性。本文旨在解决真实红外图像下视觉-语言模型数据瓶颈及域差异问题。

Method: 1) 构建大型红外图像-文本数据集IR-TD，包含26万条真实红外图像及精细标注文本，文本部分用大模型生成和规则法辅助生成；2) 提出双交叉模态课程迁移学习策略，根据红外-可见与红外-文本的任务难度分阶段迁移知识，从而提升红外领域的模型学习效果。

Result: 在包含识别、定位等9项主流任务的基准评测中，IRGPT在准确率等指标上超越了现有规模更大的多模态模型，表现出更强的泛化和任务适应能力。

Conclusion: IRGPT结合了真实大规模红外-文本数据和创新迁移策略，首次为真实红外场景下视觉-语言模型提供了强有力工具，对实际应用和后续研究具有重要推动意义。

Abstract: Real-world infrared imagery presents unique challenges for vision-language
models due to the scarcity of aligned text data and domain-specific
characteristics. Although existing methods have advanced the field, their
reliance on synthetic infrared images generated through style transfer from
visible images, which limits their ability to capture the unique
characteristics of the infrared modality. To address this, we propose IRGPT,
the first multi-modal large language model for real-world infrared images,
built upon a large-scale InfraRed-Text Dataset (IR-TD) comprising over 260K
authentic image-text pairs. The proposed IR-TD dataset contains real infrared
images paired with meticulously handcrafted texts, where the initial drafts
originated from two complementary processes: (1) LLM-generated descriptions of
visible images, and (2) rule-based descriptions of annotations. Furthermore, we
introduce a bi-cross-modal curriculum transfer learning strategy that
systematically transfers knowledge from visible to infrared domains by
considering the difficulty scores of both infrared-visible and infrared-text.
Evaluated on a benchmark of 9 tasks (e.g., recognition, grounding), IRGPT
achieves state-of-the-art performance even compared with larger-scale models.

</details>


### [10] [GPI-Net: Gestalt-Guided Parallel Interaction Network via Orthogonal Geometric Consistency for Robust Point Cloud Registration](https://arxiv.org/abs/2507.14452)
*Weikang Gu,Mingyue Han,Li Xue,Heng Dong,Changcai Yang,Riqing Chen,Lifang Wei*

Main category: cs.CV

TL;DR: 提出了一种新的结合格式塔原理和正交几何一致性的特征交互网络（GPI-Net），用于提升点云配准中的高质量对应点识别效果，在多个任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 点云配准任务中，准确找出高质量特征对应点非常关键，但现有方法难以有效融合局部和全局特征，主要因特征冗余和空间关系复杂。格式塔原理在分析局部与全局关系方面有优势，可以用来改进特征融合方法。

Method: 提出GPI-Net框架，通过格式塔原理促进局部和全局特征的信息互补。核心方法包括：采用正交集成策略减少冗余，生成更紧凑的全局特征；设计GFA模块结合自注意力和交叉注意力获取对应点的几何特征；引入DMG模块用于双路径多粒度的并行信息交互，便于不同尺度的信息融合。

Result: 在多种具有挑战性的点云配准任务上，GPI-Net均优于现有常用方法，实验结果展示了其卓越的配准效果和更高的对应点识别质量。

Conclusion: GPI-Net利用格式塔原理和正交几何一致性，有效提升了局部—全局特征融合能力和高质量对应点的识别效果，推动了点云配准领域方法的发展。

Abstract: The accurate identification of high-quality correspondences is a prerequisite
task in feature-based point cloud registration. However, it is extremely
challenging to handle the fusion of local and global features due to feature
redundancy and complex spatial relationships. Given that Gestalt principles
provide key advantages in analyzing local and global relationships, we propose
a novel Gestalt-guided Parallel Interaction Network via orthogonal geometric
consistency (GPI-Net) in this paper. It utilizes Gestalt principles to
facilitate complementary communication between local and global information.
Specifically, we introduce an orthogonal integration strategy to optimally
reduce redundant information and generate a more compact global structure for
high-quality correspondences. To capture geometric features in correspondences,
we leverage a Gestalt Feature Attention (GFA) block through a hybrid
utilization of self-attention and cross-attention mechanisms. Furthermore, to
facilitate the integration of local detail information into the global
structure, we design an innovative Dual-path Multi-Granularity parallel
interaction aggregation (DMG) block to promote information exchange across
different granularities. Extensive experiments on various challenging tasks
demonstrate the superior performance of our proposed GPI-Net in comparison to
existing methods. The code will be released at https://github.com/gwk/GPI-Net.

</details>


### [11] [Adaptive 3D Gaussian Splatting Video Streaming: Visual Saliency-Aware Tiling and Meta-Learning-Based Bitrate Adaptation](https://arxiv.org/abs/2507.14454)
*Han Gong,Qiyue Li,Jie Li,Zhi Liu*

Main category: cs.CV

TL;DR: 本文提出了一套完整的3D高斯投影视频流解决方案，包括自适应切片、质量评估和码率自适应策略，显著提升了视频流在不同网络环境下的表现。


<details>
  <summary>Details</summary>
Motivation: 3D高斯投影视频流虽然在沉浸式体验上有很大优势，但现有技术在切片、视频质量评估和码率自适应方面尚未成熟，影响其实际应用。解决这些基础挑战有助于推动这一领域的发展。

Method: 1. 提出了结合显著性分析的3DGS自适应切片方法，融合了空间与时间特征；2. 利用变形场为每个切片编码多个质量等级，支持自适应选择；3. 构建了新的3DGS视频质量评估框架，从空间降解和最终2D渲染两个层面联合评估；4. 针对网络变化，基于元学习设计自适应码率算法。

Result: 实验表明，所提出的方法在切片、自适应和质量评估等方面均优于当前领先的方法，能更有效支持3DGS视频流在网络波动环境下的稳定与高质量传输。

Conclusion: 完整方案显著提升了3DGS视频流的传输与播放效率，对推动该技术的应用与发展具有重要意义。

Abstract: 3D Gaussian splatting video (3DGS) streaming has recently emerged as a
research hotspot in both academia and industry, owing to its impressive ability
to deliver immersive 3D video experiences. However, research in this area is
still in its early stages, and several fundamental challenges, such as tiling,
quality assessment, and bitrate adaptation, require further investigation. In
this paper, we tackle these challenges by proposing a comprehensive set of
solutions. Specifically, we propose an adaptive 3DGS tiling technique guided by
saliency analysis, which integrates both spatial and temporal features. Each
tile is encoded into versions possessing dedicated deformation fields and
multiple quality levels for adaptive selection. We also introduce a novel
quality assessment framework for 3DGS video that jointly evaluates
spatial-domain degradation in 3DGS representations during streaming and the
quality of the resulting 2D rendered images. Additionally, we develop a
meta-learning-based adaptive bitrate algorithm specifically tailored for 3DGS
video streaming, achieving optimal performance across varying network
conditions. Extensive experiments demonstrate that our proposed approaches
significantly outperform state-of-the-art methods.

</details>


### [12] [GEMINUS: Dual-aware Global and Scene-Adaptive Mixture-of-Experts for End-to-End Autonomous Driving](https://arxiv.org/abs/2507.14456)
*Chi Wan,Yixin Cui,Jiatong Du,Shuo Yang,Yulong Bai,Yanjun Huang*

Main category: cs.CV

TL;DR: 本文提出了一种用于端到端自动驾驶的Mixture-of-Experts框架GEMINUS，通过引入全局专家与场景自适应专家组，并采用双感知路由器实现专家动态组合，提高了在多样化场景下的自适应性与鲁棒性，显著优于单一专家及现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前端到端自动驾驶方法大多采用单一策略，难以适应复杂多变的交通环境，且无法学习多样化的驾驶技能。因此需要一种更具多样性和适应性的规划框架。

Method: GEMINUS框架包括三个主要组件：全局专家（Global Expert，整体数据训练，保证鲁棒性）、场景自适应专家组（Scene-Adaptive Experts，根据不同场景子集训练，提高自适应能力）、双感知路由器（Dual-aware Router，同时考虑场景特征与路由不确定性，动态激活合适专家）。该框架实现专家间有效耦合，实现多场景自适应。

Result: GEMINUS在Bench2Drive闭环基准测试中表现优越，在Driving Score和Success Rate等指标上达到最新水平，仅采用单目视觉输入。消融实验也表明其在Driving Score提升7.67%、Success Rate提升22.06%、MultiAbility-Mean提升19.41%。

Conclusion: GEMINUS显著提升了端到端自动驾驶在多场景下的鲁棒性与适应性，为该领域提供了更先进的解决方案，并且相关代码将公开。

Abstract: End-to-end autonomous driving requires adaptive and robust handling of
complex and diverse traffic environments. However, prevalent single-mode
planning methods attempt to learn an overall policy while struggling to acquire
diversified driving skills to handle diverse scenarios. Therefore, this paper
proposes GEMINUS, a Mixture-of-Experts end-to-end autonomous driving framework
featuring a Global Expert, a Scene-Adaptive Experts Group, and equipped with a
Dual-aware Router. Specifically, the Global Expert is trained on the overall
dataset, possessing robust performance. The Scene-Adaptive Experts are trained
on corresponding scene subsets, achieving adaptive performance. The Dual-aware
Router simultaneously considers scenario-level features and routing uncertainty
to dynamically activate expert modules. Through the effective coupling of the
Global Expert and the Scene-Adaptive Experts Group via the Dual-aware Router,
GEMINUS achieves adaptive and robust performance in diverse scenarios. GEMINUS
outperforms existing methods in the Bench2Drive closed-loop benchmark and
achieves state-of-the-art performance in Driving Score and Success Rate, even
with only monocular vision input. Furthermore, ablation studies demonstrate
significant improvements over the original single-expert baseline: 7.67% in
Driving Score, 22.06% in Success Rate, and 19.41% in MultiAbility-Mean. The
code will be available at https://github.com/newbrains1/GEMINUS.

</details>


### [13] [VisGuard: Securing Visualization Dissemination through Tamper-Resistant Data Retrieval](https://arxiv.org/abs/2507.14459)
*Huayuan Ye,Juntong Chen,Shenzhuo Zhang,Yipeng Zhang,Changbo Wang,Chenhui Li*

Main category: cs.CV

TL;DR: VisGuard是一种耐篡改的可视化图像数据检索（VIDR）框架，通过嵌入元数据链接于可视化图像中，实现了在图像被裁剪、编辑等篡改后依然可恢复数据。其实验显示其在数据检索精度、容量和安全方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统可视化图片多为栅格图，导致源代码、交互功能及元数据丢失。已有方案尝试将元数据嵌入图像内，但大多对常见的图片篡改操作（如裁剪、编辑）不够鲁棒（易丢失信息），缺乏实用性。需要一种对篡改有抵抗力的元数据嵌入与检索方法。

Method: 提出VisGuard框架，主要包括三个技术点：（1）重复数据平铺以增强容错性；（2）可逆信息广播技术；（3）基于锚点的裁剪定位方案。实现即使图像被编辑后，嵌入的元数据链接仍可被恢复。此外，系统支持多种应用，如交互式图表重建、篡改检测及版权保护。

Result: 通过全面实验，VisGuard在数据检索准确率、嵌入容量以及对篡改与隐写分析攻击的安全性方面均优于现有方法。

Conclusion: VisGuard不仅提升了元数据在可视化图像中存储和恢复的鲁棒性，还能有效促进可视化内容的安全传播和应用，实现可靠的信息传递及增强版权、溯源等能力。

Abstract: The dissemination of visualizations is primarily in the form of raster
images, which often results in the loss of critical information such as source
code, interactive features, and metadata. While previous methods have proposed
embedding metadata into images to facilitate Visualization Image Data Retrieval
(VIDR), most existing methods lack practicability since they are fragile to
common image tampering during online distribution such as cropping and editing.
To address this issue, we propose VisGuard, a tamper-resistant VIDR framework
that reliably embeds metadata link into visualization images. The embedded data
link remains recoverable even after substantial tampering upon images. We
propose several techniques to enhance robustness, including repetitive data
tiling, invertible information broadcasting, and an anchor-based scheme for
crop localization. VisGuard enables various applications, including interactive
chart reconstruction, tampering detection, and copyright protection. We conduct
comprehensive experiments on VisGuard's superior performance in data retrieval
accuracy, embedding capacity, and security against tampering and steganalysis,
demonstrating VisGuard's competence in facilitating and safeguarding
visualization dissemination and information conveyance.

</details>


### [14] [OptiCorNet: Optimizing Sequence-Based Context Correlation for Visual Place Recognition](https://arxiv.org/abs/2507.14477)
*Zhenyu Li,Tianyi Shang,Pengjie Xu,Ruirui Zhang,Fanchen Kong*

Main category: cs.CV

TL;DR: 本文提出了一种新型视觉定位方法OptiCorNet，将空间特征提取与可微序列时差结合，实现更强鲁棒性的端到端序列建模，显著提升在动态和高混淆环境下的场所识别能力。


<details>
  <summary>Details</summary>
Motivation: 长期本地化场景中，动态变化和感知混淆对视觉场所识别(VPR)带来巨大挑战。现有方法往往只关注单帧特征，忽略图像序列中的时序一致性，导致在季节变换、视角变化等情况下准确率不足。

Method: 提出OptiCorNet框架，将1D卷积编码器与可学习的时序差分算子DSD结合，利用固定差分核和LSTM对序列中的时空信息进行建模。增加四元组损失提升类间可分性，直接端到端学习序列级特征。

Result: 在多个公开数据集上，OptiCorNet在应对季节和视角变化的VPR任务中均优于现有主流方法和基线。

Conclusion: OptiCorNet通过统一空间与时序信息的端到端学习，在动态和高混淆环境下实现更强的场所识别能力，推动了VPR方法的进步。

Abstract: Visual Place Recognition (VPR) in dynamic and perceptually aliased
environments remains a fundamental challenge for long-term localization.
Existing deep learning-based solutions predominantly focus on single-frame
embeddings, neglecting the temporal coherence present in image sequences. This
paper presents OptiCorNet, a novel sequence modeling framework that unifies
spatial feature extraction and temporal differencing into a differentiable,
end-to-end trainable module. Central to our approach is a lightweight 1D
convolutional encoder combined with a learnable differential temporal operator,
termed Differentiable Sequence Delta (DSD), which jointly captures short-term
spatial context and long-range temporal transitions. The DSD module models
directional differences across sequences via a fixed-weight differencing
kernel, followed by an LSTM-based refinement and optional residual projection,
yielding compact, discriminative descriptors robust to viewpoint and appearance
shifts. To further enhance inter-class separability, we incorporate a
quadruplet loss that optimizes both positive alignment and multi-negative
divergence within each batch. Unlike prior VPR methods that treat temporal
aggregation as post-processing, OptiCorNet learns sequence-level embeddings
directly, enabling more effective end-to-end place recognition. Comprehensive
evaluations on multiple public benchmarks demonstrate that our approach
outperforms state-of-the-art baselines under challenging seasonal and viewpoint
variations.

</details>


### [15] [DFQ-ViT: Data-Free Quantization for Vision Transformers without Fine-tuning](https://arxiv.org/abs/2507.14481)
*Yujia Tong,Jingling Yuan,Tian Zhang,Jianquan Liu,Chuang Hu*

Main category: cs.CV

TL;DR: 本文提出了一种新的Vision Transformer（ViT）数据无关量化（DFQ）方法DFQ-ViT，在不依赖真实数据的情况下提升了合成样本质量，并对激活分布失配进行了校正，从而大幅提高了量化模型的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的DFQ方法在为ViT量化时，合成样本无法平衡局部和全局特征，导致样本质量有限。同时，量化模型在推理过程中中间层的激活分布与全精度模型有显著不同，造成性能下降。

Method: 1. 提出按难度递增原则生成合成样本，提升其数据质量。2. 在校准和推理阶段为量化模型引入激活校正矩阵，使其中间层激活分布与全精度模型对齐。

Result: DFQ-ViT在多个实验上显著优于现有DFQ方法，且表现接近于基于真实数据量化的模型。例如，对DeiT-T模型的3-bit权重量化，比当前最优方法提升了4.29%的准确率。

Conclusion: DFQ-ViT方法无需微调，降低了计算开销和部署难度，既提升了能效又适合在资源受限的实际环境中应用，有助于绿色学习和实际部署。

Abstract: Data-Free Quantization (DFQ) enables the quantization of Vision Transformers
(ViTs) without requiring access to data, allowing for the deployment of ViTs on
devices with limited resources. In DFQ, the quantization model must be
calibrated using synthetic samples, making the quality of these synthetic
samples crucial. Existing methods fail to fully capture and balance the global
and local features within the samples, resulting in limited synthetic data
quality. Moreover, we have found that during inference, there is a significant
difference in the distributions of intermediate layer activations between the
quantized and full-precision models. These issues lead to a severe performance
degradation of the quantized model. To address these problems, we propose a
pipeline for Data-Free Quantization for Vision Transformers (DFQ-ViT).
Specifically, we synthesize samples in order of increasing difficulty,
effectively enhancing the quality of synthetic data. During the calibration and
inference stage, we introduce the activation correction matrix for the
quantized model to align the intermediate layer activations with those of the
full-precision model. Extensive experiments demonstrate that DFQ-ViT achieves
remarkable superiority over existing DFQ methods and its performance is on par
with models quantized through real data. For example, the performance of DeiT-T
with 3-bit weights quantization is 4.29% higher than the state-of-the-art. Our
method eliminates the need for fine-tuning, which not only reduces
computational overhead but also lowers the deployment barriers for edge
devices. This characteristic aligns with the principles of Green Learning by
improving energy efficiency and facilitating real-world applications in
resource-constrained environments.

</details>


### [16] [Benefit from Reference: Retrieval-Augmented Cross-modal Point Cloud Completion](https://arxiv.org/abs/2507.14485)
*Hongye Hou,Liu Zhan,Yang Yang*

Main category: cs.CV

TL;DR: 本文提出了一种结合跨模态检索的点云补全新方法，显著提升了点云结构恢复的质量，尤其在数据稀疏和新类别场景下表现突出。


<details>
  <summary>Details</summary>
Motivation: 点云补全面对输入数据稀疏、不完整且缺乏结构特征的情况时，现有方法依赖的结构信息不足，导致还原效果受限。虽然有部分工作尝试引入实例图像帮助学习结构特征，但大多仍只针对单一类别，泛化与生成能力有限。

Method: 提出了检索增强的点云补全框架。首先设计结构共享特征编码器(SSFE)，联合提取点云和参考图像的跨模态特征，融合检索获得的相似先验。编码器内嵌入双通道控制门机制，强化相关结构信息、抑制无关干扰。同时提出渐进式检索增强生成器(PRAG)，利用层次化特征融合机制，将参考先验逐步与待补全输入特征从全局到局部融合。

Result: 在多个公开数据集及实际场景上做了大量实验，该方法能更好地补全过程中的精细结构表达，并具备较强的泛化能力，对稀疏点云和未知类别也有良好效果。

Conclusion: 引入跨模态结构先验和渐进式融合机制，有效提升了点云补全的准确性和通用性。本文方法在补全效果和适应新场景上均取得明显进展。

Abstract: Completing the whole 3D structure based on an incomplete point cloud is a
challenging task, particularly when the residual point cloud lacks typical
structural characteristics. Recent methods based on cross-modal learning
attempt to introduce instance images to aid the structure feature learning.
However, they still focus on each particular input class, limiting their
generation abilities. In this work, we propose a novel retrieval-augmented
point cloud completion framework. The core idea is to incorporate cross-modal
retrieval into completion task to learn structural prior information from
similar reference samples. Specifically, we design a Structural Shared Feature
Encoder (SSFE) to jointly extract cross-modal features and reconstruct
reference features as priors. Benefiting from a dual-channel control gate in
the encoder, relevant structural features in the reference sample are enhanced
and irrelevant information interference is suppressed. In addition, we propose
a Progressive Retrieval-Augmented Generator (PRAG) that employs a hierarchical
feature fusion mechanism to integrate reference prior information with input
features from global to local. Through extensive evaluations on multiple
datasets and real-world scenes, our method shows its effectiveness in
generating fine-grained point clouds, as well as its generalization capability
in handling sparse data and unseen categories.

</details>


### [17] [Efficient Whole Slide Pathology VQA via Token Compression](https://arxiv.org/abs/2507.14497)
*Weimin Lyu,Qingqiao Hu,Kehan Qi,Zhan Shi,Wentao Huang,Saumya Gupta,Chao Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为TCP-LLaVA的新架构，通过令牌压缩机制，有效降低了全视野病理切片图像在多模态大模型中进行视觉问答时的计算资源消耗，并且提升了性能。


<details>
  <summary>Details</summary>
Motivation: 全视野病理切片图像（WSI）像素极大，给多模态大模型（MLLM）带来上下文过长和计算开销过高的挑战。现有方法多在小块级别分析或缺乏生成式VQA能力，直接输入大量patch会极大增加计算负担。

Method: 提出TCP-LLaVA，将可训练的令牌压缩模块嵌入到模型中，将视觉和文本信息聚合成少量压缩令牌，再传给LLM进行问答生成，大幅减少输入长度和计算成本。这个机制借鉴了BERT的[CLS] token思路。

Result: 在10种TCGA肿瘤亚型数据上，TCP-LLaVA在视觉问答准确率上优于现有MLLM基线模型，同时训练计算资源消耗大幅度降低。

Conclusion: TCP-LLaVA验证了通过令牌压缩，可高效处理极大分辨率病理图像的多模态问答任务，在准确率和资源消耗之间取得了更优平衡。

Abstract: Whole-slide images (WSIs) in pathology can reach up to 10,000 x 10,000
pixels, posing significant challenges for multimodal large language model
(MLLM) due to long context length and high computational demands. Previous
methods typically focus on patch-level analysis or slide-level classification
using CLIP-based models with multi-instance learning, but they lack the
generative capabilities needed for visual question answering (VQA). More recent
MLLM-based approaches address VQA by feeding thousands of patch tokens directly
into the language model, which leads to excessive resource consumption. To
address these limitations, we propose Token Compression Pathology LLaVA
(TCP-LLaVA), the first MLLM architecture to perform WSI VQA via token
compression. TCP-LLaVA introduces a set of trainable compression tokens that
aggregate visual and textual information through a modality compression module,
inspired by the [CLS] token mechanism in BERT. Only the compressed tokens are
forwarded to the LLM for answer generation, significantly reducing input length
and computational cost. Experiments on ten TCGA tumor subtypes show that
TCP-LLaVA outperforms existing MLLM baselines in VQA accuracy while reducing
training resource consumption by a substantial margin.

</details>


### [18] [Motion Segmentation and Egomotion Estimation from Event-Based Normal Flow](https://arxiv.org/abs/2507.14500)
*Zhiyuan Hua,Dehao Yuan,Cornelia Fermüller*

Main category: cs.CV

TL;DR: 该论文提出了一种基于事件相机的鲁棒运动分割与自运动估计算法，不依赖全光流或深度信息，通过优化流程和层级聚类实现高精度、实时运动分割。


<details>
  <summary>Details</summary>
Motivation: 常规视觉算法依赖密集光流和深度估计，难以处理事件相机输出的稀疏、高时间分辨率数据，且对边界和多运动目标表现不足。因此，迫切需要构建适合神经形态视觉传感器的高效运动分割与自运动估计算法。

Method: 提出了一种基于事件相机法向流的新框架，通过几何约束联合法向流、场景结构与惯导信息，采用迭代优化流程。流程包括：事件过分割、通过残差分析分离独立运动物体，再用结合运动相似性与时序一致性的层级聚类细化分割。

Result: 在EVIMO2v2事件相机数据集上，该方法无需计算全光流即可实现精确的运动分割与平移自运动估计，尤其在物体边界处表现优异。

Conclusion: 该方法在事件相机数据下展现出优越的鲁棒性、边界分割能力与实时性，具备良好的扩展性，适用于机器人与导航等实际应用。

Abstract: This paper introduces a robust framework for motion segmentation and
egomotion estimation using event-based normal flow, tailored specifically for
neuromorphic vision sensors. In contrast to traditional methods that rely
heavily on optical flow or explicit depth estimation, our approach exploits the
sparse, high-temporal-resolution event data and incorporates geometric
constraints between normal flow, scene structure, and inertial measurements.
The proposed optimization-based pipeline iteratively performs event
over-segmentation, isolates independently moving objects via residual analysis,
and refines segmentations using hierarchical clustering informed by motion
similarity and temporal consistency. Experimental results on the EVIMO2v2
dataset validate that our method achieves accurate segmentation and
translational motion estimation without requiring full optical flow
computation. This approach demonstrates significant advantages at object
boundaries and offers considerable potential for scalable, real-time robotic
and navigation applications.

</details>


### [19] [Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey](https://arxiv.org/abs/2507.14501)
*Jiahui Zhang,Yuelei Li,Anpei Chen,Muyu Xu,Kunhao Liu,Jianyuan Wang,Xiao-Xiao Long,Hanxue Liang,Zexiang Xu,Hao Su,Christian Theobalt,Christian Rupprecht,Andrea Vedaldi,Hanspeter Pfister,Shijian Lu,Fangneng Zhan*

Main category: cs.CV

TL;DR: 本文综述了基于前馈网络（feed-forward）的3D重建与视角合成方法，并按照表示架构分类，如点云、3D高斯Splatting、神经辐射场（NeRF）等。对于核心任务、应用、数据集和评测方法进行了详细总结，并探讨了挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: 传统3D重建与视角合成方法依赖于复杂且计算量大的迭代优化流程，难以满足实际场景需求。深度学习推动的前馈方法为这一领域带来了高效且普适的新方向，有必要进行系统梳理与总结。

Method: 文章通过综述和分类的方法，对当前主流的前馈型3D重建与视角合成技术进行了归纳，包括不同的基础表示（点云、3D高斯Splatting、NeRF等），涵盖静态/动态重建和多种合成任务。同时，回顾了相关数据集、评测协议及具体应用领域。

Result: 对各类代表性算法、应用场景和数据集做了全面总结，梳理了最新的前馈3D重建/合成技术。指出了当前主流方法的优势与局限性。

Conclusion: 前馈方法极大提升了3D视觉任务的效率与泛化能力，但在精度、自适应性等方面仍有挑战。未来应在数据多样性、评测范式、跨模态集成等方向进一步发展。

Abstract: 3D reconstruction and view synthesis are foundational problems in computer
vision, graphics, and immersive technologies such as augmented reality (AR),
virtual reality (VR), and digital twins. Traditional methods rely on
computationally intensive iterative optimization in a complex chain, limiting
their applicability in real-world scenarios. Recent advances in feed-forward
approaches, driven by deep learning, have revolutionized this field by enabling
fast and generalizable 3D reconstruction and view synthesis. This survey offers
a comprehensive review of feed-forward techniques for 3D reconstruction and
view synthesis, with a taxonomy according to the underlying representation
architectures including point cloud, 3D Gaussian Splatting (3DGS), Neural
Radiance Fields (NeRF), etc. We examine key tasks such as pose-free
reconstruction, dynamic 3D reconstruction, and 3D-aware image and video
synthesis, highlighting their applications in digital humans, SLAM, robotics,
and beyond. In addition, we review commonly used datasets with detailed
statistics, along with evaluation protocols for various downstream tasks. We
conclude by discussing open research challenges and promising directions for
future work, emphasizing the potential of feed-forward approaches to advance
the state of the art in 3D vision.

</details>


### [20] [DCHM: Depth-Consistent Human Modeling for Multiview Detection](https://arxiv.org/abs/2507.14505)
*Jiahao Ma,Tianyu Wang,Miaomiao Liu,David Ahmedt-Aristizabal,Chuong Nguyen*

Main category: cs.CV

TL;DR: 本文提出了适用于多视角行人检测的新方法DCHM，用于提升三维行人建模质量，减少噪声，无需人工标注，适用于大规模、稀疏视角和拥挤场景，并在这些任务上超过了现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前多视角行人建模对三维空间中行人表现精准度要求高，但现有方法易引入噪声，且依赖昂贵且难于泛化的人工多视角三维标注。

Method: 提出了Depth-Consistent Human Modeling（DCHM）框架，通过超像素高斯溅射实现了多视角的深度一致性，并在全局坐标系下进行三维重建，多视点融合生成精确点云以定位行人。

Result: DCHM在大规模、稀疏视角和拥挤场景下显著降低了人类建模中的噪声，在行人定位任务上的表现优于当前主流基线。

Conclusion: DCHM实现了无需人工标注的高精度三维行人重建与分割，是首个在极具挑战性的设置下完成多视角人类建模与分割的方法，为多视角行人检测提供了可靠的新思路与效果提升。

Abstract: Multiview pedestrian detection typically involves two stages: human modeling
and pedestrian localization. Human modeling represents pedestrians in 3D space
by fusing multiview information, making its quality crucial for detection
accuracy. However, existing methods often introduce noise and have low
precision. While some approaches reduce noise by fitting on costly multiview 3D
annotations, they often struggle to generalize across diverse scenes. To
eliminate reliance on human-labeled annotations and accurately model humans, we
propose Depth-Consistent Human Modeling (DCHM), a framework designed for
consistent depth estimation and multiview fusion in global coordinates.
Specifically, our proposed pipeline with superpixel-wise Gaussian Splatting
achieves multiview depth consistency in sparse-view, large-scaled, and crowded
scenarios, producing precise point clouds for pedestrian localization.
Extensive validations demonstrate that our method significantly reduces noise
during human modeling, outperforming previous state-of-the-art baselines.
Additionally, to our knowledge, DCHM is the first to reconstruct pedestrians
and perform multiview segmentation in such a challenging setting. Code is
available on the \href{https://jiahao-ma.github.io/DCHM/}{project page}.

</details>


### [21] [ArtiMuse: Fine-Grained Image Aesthetics Assessment with Joint Scoring and Expert-Level Understanding](https://arxiv.org/abs/2507.14533)
*Shuo Cao,Nan Ma,Jiayang Li,Xiaohui Li,Lihao Shao,Kaiwen Zhu,Yu Zhou,Yuandong Pu,Jiarui Wu,Jiaquan Wang,Bo Qu,Wenhai Wang,Yu Qiao,Dajuin Yao,Yihao Liu*

Main category: cs.CV

TL;DR: 本文提出了一种基于多模态大语言模型（MLLM）的新型图像美学评估模型ArtiMuse，并发布了首个专家标注的1万张图片美学数据集ArtiMuse-10K，支持联合评分与专家级理解。


<details>
  <summary>Details</summary>
Motivation: 随着教育应用、艺术创作和AI生成内容的快速发展，图像美学评估需求大增，现有方法难以兼顾定量评分和专业解释，因此亟需更全面、细致的美学评估方法。

Method: 提出了ArtiMuse模型，基于多模态大语言模型，能同时实现美学评分和专家级属性理解。并构建了ArtiMuse-10K数据集，该数据集包含1万张图片，涵盖5个主类15个子类，由专业人员进行8维属性和整体分数标注。

Result: ArtiMuse模型展现出比传统方法更强的感知和泛化能力，能够克服传统模型的单一模态偏见与属性分解不足问题。数据集为后续研究提供了丰富的高质量资源。

Conclusion: ArtiMuse模型和ArtiMuse-10K数据集的开放将推动图像美学评估领域的发展，实现更精准和专业的美学理解与评价。

Abstract: The rapid advancement of educational applications, artistic creation, and
AI-generated content (AIGC) technologies has substantially increased practical
requirements for comprehensive Image Aesthetics Assessment (IAA), particularly
demanding methods capable of delivering both quantitative scoring and
professional understanding. Multimodal Large Language Model (MLLM)-based IAA
methods demonstrate stronger perceptual and generalization capabilities
compared to traditional approaches, yet they suffer from modality bias
(score-only or text-only) and lack fine-grained attribute decomposition,
thereby failing to support further aesthetic assessment. In this paper, we
present:(1) ArtiMuse, an innovative MLLM-based IAA model with Joint Scoring and
Expert-Level Understanding capabilities; (2) ArtiMuse-10K, the first
expert-curated image aesthetic dataset comprising 10,000 images spanning 5 main
categories and 15 subcategories, each annotated by professional experts with
8-dimensional attributes analysis and a holistic score. Both the model and
dataset will be made public to advance the field.

</details>


### [22] [Real Time Captioning of Sign Language Gestures in Video Meetings](https://arxiv.org/abs/2507.14543)
*Sharanya Mukherjee,Md Hishaam Akhtar,Kannadasan R*

Main category: cs.CV

TL;DR: 本文提出了一种浏览器扩展，可以在视频通话中自动将美国手语(ASL)翻译为字幕，方便听障人士与普通人交流。


<details>
  <summary>Details</summary>
Motivation: 现实中与听障人士沟通困难，特别是在疫情期间视频通话成为主流。大多数人不懂手语，交流有障碍。因而需要自动化工具。

Method: 开发基于浏览器的扩展插件，利用计算机视觉和大型ASL视频数据集（包含2000多个词级视频及100多位手语者），实现手语到字幕的自动翻译。

Result: 实现了一个可以在实际视频通话场景中运行的手语识别和翻译系统，使手语直接转化为通话字幕。

Conclusion: 该浏览器扩展有效降低了听障人士与普通人的沟通障碍，提升了包容性，有助于推动手语识别技术在实际应用中的普及。

Abstract: It has always been a rather tough task to communicate with someone possessing
a hearing impairment. One of the most tested ways to establish such a
communication is through the use of sign based languages. However, not many
people are aware of the smaller intricacies involved with sign language. Sign
language recognition using computer vision aims at eliminating the
communication barrier between deaf-mute and ordinary people so that they can
properly communicate with others. Recently the pandemic has left the whole
world shaken up and has transformed the way we communicate. Video meetings have
become essential for everyone, even people with a hearing disability. In recent
studies, it has been found that people with hearing disabilities prefer to sign
over typing during these video calls. In this paper, we are proposing a browser
extension that will automatically translate sign language to subtitles for
everyone else in the video call. The Large-scale dataset which contains more
than 2000 Word-Level ASL videos, which were performed by over 100 signers will
be used.

</details>


### [23] [Multimodal AI for Gastrointestinal Diagnostics: Tackling VQA in MEDVQA-GI 2025](https://arxiv.org/abs/2507.14544)
*Sujata Gaihre,Amir Thapa Magar,Prasuna Pokharel,Laxmi Tiwari*

Main category: cs.CV

TL;DR: 本文提出了一种基于Florence大规模多模态基础模型的胃肠内镜视觉问答（VQA）方法，并通过特定医学增强技术提升泛化能力，在ImageCLEFmed MEDVQA 2025竞赛子任务上实现了优秀表现。


<details>
  <summary>Details</summary>
Motivation: 医学视觉问答，特别是胃肠内镜场景下，对模型理解能力和泛化性提出极高要求。当前方法难以直接应用于此领域，因此亟需开发能适应医疗图像和问答特性的VQA方法。

Method: 采用Florence多模态基础模型作为主干网络，将视觉编码器与文本编码器结合，实现内镜图像与医学问题的联合理解。为增强泛化能力，设计并应用了医学特征保持的领域专用数据增强策略。模型在KASVIR医疗数据集上进行微调和测试。

Result: Florence模型在官方VQA评测指标上取得了高度准确的答复结果，表现优异。实验结果验证了领域增强和微调的有效性。

Conclusion: 大规模多模态模型在医学视觉问答任务中展现出很大潜力，为未来在可解释性、鲁棒性和临床部署等方面的研究提供了强有力的基线。方法代码已开源。

Abstract: This paper describes our approach to Subtask 1 of the ImageCLEFmed MEDVQA
2025 Challenge, which targets visual question answering (VQA) for
gastrointestinal endoscopy. We adopt the Florence model-a large-scale
multimodal foundation model-as the backbone of our VQA pipeline, pairing a
powerful vision encoder with a text encoder to interpret endoscopic images and
produce clinically relevant answers. To improve generalization, we apply
domain-specific augmentations that preserve medical features while increasing
training diversity. Experiments on the KASVIR dataset show that fine-tuning
Florence yields accurate responses on the official challenge metrics. Our
results highlight the potential of large multimodal models in medical VQA and
provide a strong baseline for future work on explainability, robustness, and
clinical integration. The code is publicly available at:
https://github.com/TiwariLaxuu/VQA-Florence.git

</details>


### [24] [Synthesizing Images on Perceptual Boundaries of ANNs for Uncovering Human Perceptual Variability on Facial Expressions](https://arxiv.org/abs/2507.14549)
*Haotian Deng,Chi Zhang,Chen Wei,Quanying Liu*

Main category: cs.CV

TL;DR: 本研究发现，人工神经网络（ANN）在处理容易混淆的面部表情时，其判断的不确定性与真实人类观察者在情感分类上的分歧高度一致，通过新方法生成了这类样本数据集，并能通过行为数据微调ANN以更好地拟合个体感知差异。


<details>
  <summary>Details</summary>
Motivation: 虽然人工神经网络在面部表情识别上表现出高准确率，但其是否能准确反映不同个体在人类感知情绪时的巨大差异还未得到充分探索。人的情感感知在相同刺激下表现出高度可变性，理解和模拟这种变异性对于提升情感计算、人机交互以及个性化情感建模极为重要。

Method: 作者提出了一种感知边界采样新方法，从ANN的决策边界附近生成易混淆的面部表情样本，构建varEmotion数据集，并通过大规模行为实验收集人类对于这些刺激的情感分类反应。进一步，作者将实验行为数据用于微调ANN模型，对人类的群体及个体层面感知模式进行建模。

Result: 分析表明，ANN难以区分的表情样本在人类观察者中同样引起更高的不确定和分歧感知，说明两者在信息处理上存在一致性。通过使用行为数据微调ANN后，其预测结果与人类的整体和个体表现均可达到较好的一致。

Conclusion: 研究系统性地揭示了ANN决策边界与人类情感感知多样性之间的联系，并展示借助行为数据微调ANN可实现对个体情感认知差异的个性化建模。这为推动情感人工智能系统的个性化和人性化提供了新思路。

Abstract: A fundamental challenge in affective cognitive science is to develop models
that accurately capture the relationship between external emotional stimuli and
human internal experiences. While ANNs have demonstrated remarkable accuracy in
facial expression recognition, their ability to model inter-individual
differences in human perception remains underexplored. This study investigates
the phenomenon of high perceptual variability-where individuals exhibit
significant differences in emotion categorization even when viewing the same
stimulus. Inspired by the similarity between ANNs and human perception, we
hypothesize that facial expression samples that are ambiguous for ANN
classifiers also elicit divergent perceptual judgments among human observers.
To examine this hypothesis, we introduce a novel perceptual boundary sampling
method to generate facial expression stimuli that lie along ANN decision
boundaries. These ambiguous samples form the basis of the varEmotion dataset,
constructed through large-scale human behavioral experiments. Our analysis
reveals that these ANN-confusing stimuli also provoke heightened perceptual
uncertainty in human participants, highlighting shared computational principles
in emotion perception. Finally, by fine-tuning ANN representations using
behavioral data, we achieve alignment between ANN predictions and both
group-level and individual-level human perceptual patterns. Our findings
establish a systematic link between ANN decision boundaries and human
perceptual variability, offering new insights into personalized modeling of
emotional interpretation.

</details>


### [25] [Clutter Detection and Removal by Multi-Objective Analysis for Photographic Guidance](https://arxiv.org/abs/2507.14553)
*Xiaoran Wu*

Main category: cs.CV

TL;DR: 本文提出了一套智能相机指导系统，能够帮助用户识别和去除照片中的杂物，从而提升照片的美感和表达效果。系统不仅可以分析并可视化物体对整体美学的贡献，还能通过人机交互方式辅助用户处理杂物，并利用生成对抗网络实现高分辨率的图片修复。用户研究表明，该系统能有效提升用户识别杂乱内容和拍摄优质照片的效率。


<details>
  <summary>Details</summary>
Motivation: 许多摄影爱好者由于经验不足或疏忽，常常在照片中无意中包含杂物，这些杂物影响了照片的美感和信息传递。为帮助用户克服这一难题，提升照片质量，作者提出构建智能辅助系统的需求。

Method: 该系统包含两大技术亮点：首先，提出了结合美学评价的杂物判别算法，用于评估和可视化每个物体对照片整体美学的影响；其次，基于生成对抗网络（GAN）设计了迭代图像修复方法，用于在去除杂物后高质量地还原照片内容。此外，系统还提供人机交互界面和建议工具，协助用户识别及移除不同类型的杂物。

Result: 通过用户实验，验证了系统不仅在人机交互界面上表现灵活、友好，而且其算法能够准确地辅助用户识别和去除杂乱内容。实验结果显示，用户在更短时间内拍摄出了更高质量的照片。

Conclusion: 本文提出的智能相机指导系统有效地帮助用户识别和处理照片中的杂物，提高了照片的美学质量和创作效率。系统结合创新的物体美学评估与高质量图像修复，在实验中表现出较强的实用性和准确性。

Abstract: Clutter in photos is a distraction preventing photographers from conveying
the intended emotions or stories to the audience. Photography amateurs
frequently include clutter in their photos due to unconscious negligence or the
lack of experience in creating a decluttered, aesthetically appealing scene for
shooting. We are thus motivated to develop a camera guidance system that
provides solutions and guidance for clutter identification and removal. We
estimate and visualize the contribution of objects to the overall aesthetics
and content of a photo, based on which users can interactively identify
clutter. Suggestions on getting rid of clutter, as well as a tool that removes
cluttered objects computationally, are provided to guide users to deal with
different kinds of clutter and improve their photographic work. Two technical
novelties underpin interactions in our system: a clutter distinguishment
algorithm with aesthetics evaluations for objects and an iterative image
inpainting algorithm based on generative adversarial nets that reconstructs
missing regions of removed objects for high-resolution images. User studies
demonstrate that our system provides flexible interfaces and accurate
algorithms that allow users to better identify distractions and take higher
quality images within less time.

</details>


### [26] [Descrip3D: Enhancing Large Language Model-based 3D Scene Understanding with Object-Level Text Descriptions](https://arxiv.org/abs/2507.14555)
*Jintang Xue,Ganning Zhao,Jie-En Yao,Hong-En Chen,Yue Hu,Meida Chen,Suya You,C. -C. Jay Kuo*

Main category: cs.CV

TL;DR: Descrip3D是一种新型框架，通过自然语言描述显式编码3D场景中物体之间的关系，提升了基于语言的3D场景理解能力，在多个基准任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前3D场景-语言模型在理解物体的空间和语义关系方面存在不足，特别是当仅依赖视觉特征时，难以准确表达物体的角色和交互。

Method: 提出Descrip3D框架，为每个物体生成包含其属性及上下文关系的文本描述，这些描述通过“嵌入融合”和“提示注入”双重机制融入模型，实现统一的场景推理，无需特定任务头和额外监督。

Result: 在ScanRefer、Multi3DRefer、ScanQA、SQA3D和Scan2Cap等五个基准数据集上，Descrip3D的性能均优于多个强基线模型。

Conclusion: 将自然语言引入3D场景关系建模能够显著提升复杂室内场景的理解能力，Descrip3D为基于语言的3D场景推理提供了新思路。

Abstract: Understanding 3D scenes goes beyond simply recognizing objects; it requires
reasoning about the spatial and semantic relationships between them. Current 3D
scene-language models often struggle with this relational understanding,
particularly when visual embeddings alone do not adequately convey the roles
and interactions of objects. In this paper, we introduce Descrip3D, a novel and
powerful framework that explicitly encodes the relationships between objects
using natural language. Unlike previous methods that rely only on 2D and 3D
embeddings, Descrip3D enhances each object with a textual description that
captures both its intrinsic attributes and contextual relationships. These
relational cues are incorporated into the model through a dual-level
integration: embedding fusion and prompt-level injection. This allows for
unified reasoning across various tasks such as grounding, captioning, and
question answering, all without the need for task-specific heads or additional
supervision. When evaluated on five benchmark datasets, including ScanRefer,
Multi3DRefer, ScanQA, SQA3D, and Scan2Cap, Descrip3D consistently outperforms
strong baseline models, demonstrating the effectiveness of language-guided
relational representation for understanding complex indoor scenes.

</details>


### [27] [LEAD: Exploring Logit Space Evolution for Model Selection](https://arxiv.org/abs/2507.14559)
*Zixuan Hu,Xiaotong Li,Shixiang Tang,Jun Liu,Yichun Hu,Ling-Yu Duan*

Main category: cs.CV

TL;DR: 本文提出了一种基于logits输出的模型可迁移性评估方法LEAD，能够更精准预测预训练模型在下游任务中的表现，无需冗长微调。实验证明其高效且通用。


<details>
  <summary>Details</summary>
Motivation: 当前预训练-微调范式下，预训练模型数量激增，但如何高效选择最合适的模型进行下游任务微调，成为一大挑战。现有方法对微调动力学的刻画不精确，难以有效预测模型迁移性。

Method: 提出LEAD方法，通过直接建模logits输出，并利用常微分方程（ODE）理论框架，精准模拟从初始到最终状态的非线性动力学演化。同时采用类感知分解技术，处理不同类别的演化差异。该方法无需完整微调流程，可一步高效获取模型迁移能力。

Result: 在10个下游数据集、24个监督与自监督预训练模型上开展大量实验，LEAD在模型选择和迁移性预测等方面展现了优异表现，尤其在低数据量场景下依然适用。

Conclusion: LEAD有效补足了预训练模型优化目标与实际微调表现间的评估鸿沟，能够高效、准确地选择合适模型，适用性广、实践价值高。

Abstract: The remarkable success of pretrain-then-finetune paradigm has led to a
proliferation of available pre-trained models for vision tasks. This surge
presents a significant challenge in efficiently choosing the most suitable
pre-trained models for downstream tasks. The critical aspect of this challenge
lies in effectively predicting the model transferability by considering the
underlying fine-tuning dynamics. Existing methods often model fine-tuning
dynamics in feature space with linear transformations, which do not precisely
align with the fine-tuning objective and fail to grasp the essential
nonlinearity from optimization. To this end, we present LEAD, a
finetuning-aligned approach based on the network output of logits. LEAD
proposes a theoretical framework to model the optimization process and derives
an ordinary differential equation (ODE) to depict the nonlinear evolution
toward the final logit state. Additionally, we design a class-aware
decomposition method to consider the varying evolution dynamics across classes
and further ensure practical applicability. Integrating the closely aligned
optimization objective and nonlinear modeling capabilities derived from the
differential equation, our method offers a concise solution to effectively
bridge the optimization gap in a single step, bypassing the lengthy fine-tuning
process. The comprehensive experiments on 24 supervised and self-supervised
pre-trained models across 10 downstream datasets demonstrate impressive
performances and showcase its broad adaptability even in low-data scenarios.

</details>


### [28] [Benchmarking GANs, Diffusion Models, and Flow Matching for T1w-to-T2w MRI Translation](https://arxiv.org/abs/2507.14575)
*Andrea Moschetto,Lemuel Puglisi,Alec Sargood,Pierluigi Dell'Acqua,Francesco Guarnera,Sebastiano Battiato,Daniele Ravì*

Main category: cs.CV

TL;DR: 本论文对当前T1w到T2w MRI图像合成的多种生成模型（包括GAN、扩散模型和流匹配方法）进行了系统性基准测试，结果显示GAN（Pix2Pix）在结构保真度、图像质量和计算效率上优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 在临床应用中，为获取不同MRI对比度图像（如T1w, T2w）通常需要更长的扫描时间与更高成本。为了缩短扫描时间、降低病人负担及医疗成本，研究者希望通过合成未获得的对比模态，提升工作效率。

Method: 本文对主流的生成模型，包括GAN（Pix2Pix）、扩散模型和流匹配方法，在相同设置下进行了Benchmark比较。所有方法都在三个公开的健康成人MRI数据集上评测，并从结构、图像质量与效率等多维度进行定量和定性分析。

Result: 实验表明，在目前的数据量和难度下，GAN（Pix2Pix）方法在结构还原、图像质量和计算效率方面全面优于扩散模型和流匹配模型。流匹配方法易在小数据集上过拟合，需更多数据才能逼近GAN性能。

Conclusion: 研究证明GAN在小样本医疗影像合成场景中具有实用优势，并为MRI跨模态合成方法的部署和后续研究提供了实践建议和未来发展方向。

Abstract: Magnetic Resonance Imaging (MRI) enables the acquisition of multiple image
contrasts, such as T1-weighted (T1w) and T2-weighted (T2w) scans, each offering
distinct diagnostic insights. However, acquiring all desired modalities
increases scan time and cost, motivating research into computational methods
for cross-modal synthesis. To address this, recent approaches aim to synthesize
missing MRI contrasts from those already acquired, reducing acquisition time
while preserving diagnostic quality. Image-to-image (I2I) translation provides
a promising framework for this task. In this paper, we present a comprehensive
benchmark of generative models$\unicode{x2013}$specifically, Generative
Adversarial Networks (GANs), diffusion models, and flow matching (FM)
techniques$\unicode{x2013}$for T1w-to-T2w 2D MRI I2I translation. All
frameworks are implemented with comparable settings and evaluated on three
publicly available MRI datasets of healthy adults. Our quantitative and
qualitative analyses show that the GAN-based Pix2Pix model outperforms
diffusion and FM-based methods in terms of structural fidelity, image quality,
and computational efficiency. Consistent with existing literature, these
results suggest that flow-based models are prone to overfitting on small
datasets and simpler tasks, and may require more data to match or surpass GAN
performance. These findings offer practical guidance for deploying I2I
translation techniques in real-world MRI workflows and highlight promising
directions for future research in cross-modal medical image synthesis. Code and
models are publicly available at
https://github.com/AndreaMoschetto/medical-I2I-benchmark.

</details>


### [29] [Performance comparison of medical image classification systems using TensorFlow Keras, PyTorch, and JAX](https://arxiv.org/abs/2507.14587)
*Merjem Bećirović,Amina Kurtović,Nordin Smajlović,Medina Kapo,Amila Akagić*

Main category: cs.CV

TL;DR: 本文比较了TensorFlow（Keras）、PyTorch和JAX三大深度学习框架在血细胞图像分类中的推理速度与分类表现。结果显示，三者在不同图像分辨率与各自优化下，推理速度和分类性能存在差异，但PyTorch和JAX在准确率上表现优异。


<details>
  <summary>Details</summary>
Motivation: 自动化血细胞图像分类能提升医学诊断效率和准确性。尽管深度学习已广泛应用于此，但缺乏关于不同主流深度学习框架在该领域实际表现的细致比较。此研究旨在填补框架间性能评价的空白，帮助选择更适合医学图像处理的方案。

Method: 作者选用BloodMNIST公共数据集，使用TensorFlow（Keras）、PyTorch和JAX三种深度学习框架对血细胞图像进行分类实验，重点比较了不同分辨率下的推理时间，并评估了分类准确率等性能指标。

Result: 实验发现，各框架在不同分辨率和自身优化特性影响下，推理速度与性能表现存在显著差异。JAX和PyTorch在分类准确率方面与业界标杆水平相当，显示出良好的效率和适用性。

Conclusion: 对深度学习框架的性能对比有助于选择合适的医学图像分析工具。JAX和PyTorch在血细胞图像分类任务中表现出高准确率和高效率，适合用于今后的医学图像自动化分析研究。

Abstract: Medical imaging plays a vital role in early disease diagnosis and monitoring.
Specifically, blood microscopy offers valuable insights into blood cell
morphology and the detection of hematological disorders. In recent years, deep
learning-based automated classification systems have demonstrated high
potential in enhancing the accuracy and efficiency of blood image analysis.
However, a detailed performance analysis of specific deep learning frameworks
appears to be lacking. This paper compares the performance of three popular
deep learning frameworks, TensorFlow with Keras, PyTorch, and JAX, in
classifying blood cell images from the publicly available BloodMNIST dataset.
The study primarily focuses on inference time differences, but also
classification performance for different image sizes. The results reveal
variations in performance across frameworks, influenced by factors such as
image resolution and framework-specific optimizations. Classification accuracy
for JAX and PyTorch was comparable to current benchmarks, showcasing the
efficiency of these frameworks for medical image classification.

</details>


### [30] [DiSCO-3D : Discovering and segmenting Sub-Concepts from Open-vocabulary queries in NeRF](https://arxiv.org/abs/2507.14596)
*Doriand Petit,Steve Bourgeois,Vincent Gay-Bellile,Florian Chabot,Loïc Barthe*

Main category: cs.CV

TL;DR: 本文提出了DiSCO-3D，一种面向3D开放词汇子概念发现的新方法，通过结合无监督分割和弱的开放词汇指导，实现可同时适应场景和用户查询的3D语义分割，且在多个分割任务上取得了先进结果。


<details>
  <summary>Details</summary>
Motivation: 现有3D语义分割方法只关注面向特定任务的开放词汇分割或场景内容的无监督分割，缺乏能同时兼顾两者、适应场景和用户需求的方法。

Method: 基于神经场表示，提出DiSCO-3D方法，将无监督分割与轻量级的开放词汇指导相结合，实现了针对3D场景的灵活子概念发现和分割。

Result: 实验表明，DiSCO-3D在开放词汇子概念发现任务中具有良好性能，并且在传统开放词汇分割与无监督分割的边界场景中都达到了当前最优结果。

Conclusion: DiSCO-3D是首个能够同时适应场景内容和用户查询，实现3D开放词汇子概念发现的分割方法，为领域带来更灵活泛化的3D场景语义理解能力。

Abstract: 3D semantic segmentation provides high-level scene understanding for
applications in robotics, autonomous systems, \textit{etc}. Traditional methods
adapt exclusively to either task-specific goals (open-vocabulary segmentation)
or scene content (unsupervised semantic segmentation). We propose DiSCO-3D, the
first method addressing the broader problem of 3D Open-Vocabulary Sub-concepts
Discovery, which aims to provide a 3D semantic segmentation that adapts to both
the scene and user queries. We build DiSCO-3D on Neural Fields representations,
combining unsupervised segmentation with weak open-vocabulary guidance. Our
evaluations demonstrate that DiSCO-3D achieves effective performance in
Open-Vocabulary Sub-concepts Discovery and exhibits state-of-the-art results in
the edge cases of both open-vocabulary and unsupervised segmentation.

</details>


### [31] [Exp-Graph: How Connections Learn Facial Attributes in Graph-based Expression Recognition](https://arxiv.org/abs/2507.14608)
*Nandani Sharma,Dinesh Singh*

Main category: cs.CV

TL;DR: 本文提出了一种基于图神经网络与视觉变换器相结合的新型人脸表情识别框架Exp-Graph，并在多个数据集上取得了优异效果。


<details>
  <summary>Details</summary>
Motivation: 人脸表情识别对于人机交互等领域极为关键。然而，现有方法很难同时充分利用人脸属性的局部结构和全局关系。作者希望通过引入结构建模提升识别的准确性和泛化能力。

Method: 作者提出Exp-Graph框架，将人脸关键点作为图的节点，同时按照关键点距离及局部外观相似性建立图的边，并利用视觉变换器编码属性信息。再用图卷积神经网络（GCN）捕捉结构依赖关系，把这些信息整合进表达中。整个模型结合了ViT和GCN，既捕捉局部又捕捉全局依赖。

Result: 在Oulu-CASIA、eNTERFACE05、AFEW三个基准数据集上分别取得98.09%、79.01%、56.39%的准确率，优于或接近现有方法。

Conclusion: Exp-Graph能有效利用人脸关键点的结构信息，在实验室环境和真实环境下都具备很好的泛化能力，适用于实际的人脸表情识别应用。

Abstract: Facial expression recognition is crucial for human-computer interaction
applications such as face animation, video surveillance, affective computing,
medical analysis, etc. Since the structure of facial attributes varies with
facial expressions, incorporating structural information into facial attributes
is essential for facial expression recognition. In this paper, we propose
Exp-Graph, a novel framework designed to represent the structural relationships
among facial attributes using graph-based modeling for facial expression
recognition. For facial attributes graph representation, facial landmarks are
used as the graph's vertices. At the same time, the edges are determined based
on the proximity of the facial landmark and the similarity of the local
appearance of the facial attributes encoded using the vision transformer.
Additionally, graph convolutional networks are utilized to capture and
integrate these structural dependencies into the encoding of facial attributes,
thereby enhancing the accuracy of expression recognition. Thus, Exp-Graph
learns from the facial attribute graphs highly expressive semantic
representations. On the other hand, the vision transformer and graph
convolutional blocks help the framework exploit the local and global
dependencies among the facial attributes that are essential for the recognition
of facial expressions. We conducted comprehensive evaluations of the proposed
Exp-Graph model on three benchmark datasets: Oulu-CASIA, eNTERFACE05, and AFEW.
The model achieved recognition accuracies of 98.09\%, 79.01\%, and 56.39\%,
respectively. These results indicate that Exp-Graph maintains strong
generalization capabilities across both controlled laboratory settings and
real-world, unconstrained environments, underscoring its effectiveness for
practical facial expression recognition applications.

</details>


### [32] [Depthwise-Dilated Convolutional Adapters for Medical Object Tracking and Segmentation Using the Segment Anything Model 2](https://arxiv.org/abs/2507.14613)
*Guoping Xu,Christopher Kabat,You Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为DD-SAM2的新方法，能够高效地将Segment Anything Model 2（SAM2）适配到医学视频分割与追踪任务，尤其是在训练数据有限的情况下依然取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的医学图像分割方法大多依赖特定成像模态，适应性较差，且现有的通用视频分割模型如SAM2迁移到医学视频需大规模数据和高算力，存在灾难性遗忘风险。作者希望设计一种高效适配框架，降低计算与样本需求。

Method: 本文提出DD-SAM2框架，引入Depthwise-Dilated Adapter（DD-Adapter）轻量模块，增强SAM2多尺度特征提取能力，支持在少量医学视频数据上微调。DD-SAM2不仅适配静态图像，对SAM2的流式内存机制进行充分利用，实现对医学视频中目标的追踪与分割。

Result: 在TrackRad2025（肿瘤分割）和EchoNet-Dynamic（左心室追踪）数据集上，DD-SAM2分别取得了Dice分数0.93和0.97，显著优于相关方法。

Conclusion: DD-SAM2展示了少量参数和数据条件下，端到端高效迁移SAM2到医学视频分割与追踪任务的可行性。该工作为适配型SAM2微调在医学视频中的系统性探索提供了初步方案。

Abstract: Recent advances in medical image segmentation have been driven by deep
learning; however, most existing methods remain limited by modality-specific
designs and exhibit poor adaptability to dynamic medical imaging scenarios. The
Segment Anything Model 2 (SAM2) and its related variants, which introduce a
streaming memory mechanism for real-time video segmentation, present new
opportunities for prompt-based, generalizable solutions. Nevertheless, adapting
these models to medical video scenarios typically requires large-scale datasets
for retraining or transfer learning, leading to high computational costs and
the risk of catastrophic forgetting. To address these challenges, we propose
DD-SAM2, an efficient adaptation framework for SAM2 that incorporates a
Depthwise-Dilated Adapter (DD-Adapter) to enhance multi-scale feature
extraction with minimal parameter overhead. This design enables effective
fine-tuning of SAM2 on medical videos with limited training data. Unlike
existing adapter-based methods focused solely on static images, DD-SAM2 fully
exploits SAM2's streaming memory for medical video object tracking and
segmentation. Comprehensive evaluations on TrackRad2025 (tumor segmentation)
and EchoNet-Dynamic (left ventricle tracking) datasets demonstrate superior
performance, achieving Dice scores of 0.93 and 0.97, respectively. To the best
of our knowledge, this work provides an initial attempt at systematically
exploring adapter-based SAM2 fine-tuning for medical video segmentation and
tracking. Code, datasets, and models will be publicly available at
https://github.com/apple1986/DD-SAM2.

</details>


### [33] [BusterX++: Towards Unified Cross-Modal AI-Generated Content Detection and Explanation with MLLM](https://arxiv.org/abs/2507.14632)
*Haiquan Wen,Tianxiao Li,Zhenglin Huang,Yiwei He,Guangliang Cheng*

Main category: cs.CV

TL;DR: 本文提出BusterX++框架，用于跨模态合成媒体（如图片、视频等）的检测与解释，并引入了高质量基准数据集GenBuster++进行评测，实验显示BusterX++有效且具备泛化能力。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在图片和视频合成上的进步提升了假内容传播的风险，现有检测方法多局限于单一模态，难以应对多模态合成内容的检测需求，因此亟需更强跨模态的检测与解释方法。

Method: 提出BusterX++跨模态检测框架，结合强化学习后训练、分阶段训练、多阶段推理及创新的“Thinking Reward”等机制以提升检测能力，并构建高质量跨模态合成内容基准集GenBuster++来客观评测模型表现。

Result: BusterX++在新提出的GenBuster++跨模态合成内容测试集上取得了稳定且较大幅度的性能提升，展示出良好的有效性和泛化能力。

Conclusion: BusterX++能够高效检测并解释跨模态合成内容，解决了多模态合成内容难检测的痛点，为打击深度伪造等应用提供了有力工具。

Abstract: Recent advances in generative AI have dramatically improved image and video
synthesis capabilities, significantly increasing the risk of misinformation
through sophisticated fake content. In response, detection methods have evolved
from traditional approaches to multimodal large language models (MLLMs),
offering enhanced transparency and interpretability in identifying synthetic
media. However, current detection systems remain fundamentally limited by their
single-modality design. These approaches analyze images or videos separately,
making them ineffective against synthetic content that combines multiple media
formats. To address these challenges, we introduce \textbf{BusterX++}, a novel
framework designed specifically for cross-modal detection and explanation of
synthetic media. Our approach incorporates an advanced reinforcement learning
(RL) post-training strategy that eliminates cold-start. Through Multi-stage
Training, Thinking Reward, and Hybrid Reasoning, BusterX++ achieves stable and
substantial performance improvements. To enable comprehensive evaluation, we
also present \textbf{GenBuster++}, a cross-modal benchmark leveraging
state-of-the-art image and video generation techniques. This benchmark
comprises 4,000 images and video clips, meticulously curated by human experts
using a novel filtering methodology to ensure high quality, diversity, and
real-world applicability. Extensive experiments demonstrate the effectiveness
and generalizability of our approach.

</details>


### [34] [Multispectral State-Space Feature Fusion: Bridging Shared and Cross-Parametric Interactions for Object Detection](https://arxiv.org/abs/2507.14643)
*Jifeng Shen,Haibo Zhan,Shaohua Dong,Xin Zuo,Wankou Yang,Haibin Ling*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的多光谱特征融合框架MS2Fusion，解决了多光谱目标检测中局部特征偏好和感受野-计算复杂度权衡的问题，并在主流基准上取得了优异表现，具有良好的通用性。


<details>
  <summary>Details</summary>
Motivation: 现有多光谱特征融合方法过度关注局部互补特征，忽视了跨模态共享语义，导致泛化能力下降；同时，感受野大小与计算复杂度之间的权衡限制了特征建模的可扩展性。

Method: MS2Fusion基于State Space Model（SSM），采用双路径参数交互机制。第一条路径利用跨参数交互和SSM中的隐状态解码，主挖互补信息；第二条路径通过SSM参数共享联合嵌入，实现跨模态的语义对齐。最终，二者在统一框架下联合优化，实现高效有效的多光谱特征融合。

Result: 在FLIR、M3FD和LLVIP等主流数据集上，MS2Fusion显著优于当前最先进多光谱目标检测方法。此外，在RGB-T语义分割和显著目标检测等任务上，未做特殊设计的MS2Fusion同样达到SOTA水平，显示了方法的广泛适用性。

Conclusion: MS2Fusion框架能兼顾多光谱特征的互补性与共享语义空间，提高了多光谱感知任务的性能和泛化能力，且具备良好的通用性。

Abstract: Modern multispectral feature fusion for object detection faces two critical
limitations: (1) Excessive preference for local complementary features over
cross-modal shared semantics adversely affects generalization performance; and
(2) The trade-off between the receptive field size and computational complexity
present critical bottlenecks for scalable feature modeling. Addressing these
issues, a novel Multispectral State-Space Feature Fusion framework, dubbed
MS2Fusion, is proposed based on the state space model (SSM), achieving
efficient and effective fusion through a dual-path parametric interaction
mechanism. More specifically, the first cross-parameter interaction branch
inherits the advantage of cross-attention in mining complementary information
with cross-modal hidden state decoding in SSM. The second shared-parameter
branch explores cross-modal alignment with joint embedding to obtain
cross-modal similar semantic features and structures through parameter sharing
in SSM. Finally, these two paths are jointly optimized with SSM for fusing
multispectral features in a unified framework, allowing our MS2Fusion to enjoy
both functional complementarity and shared semantic space. In our extensive
experiments on mainstream benchmarks including FLIR, M3FD and LLVIP, our
MS2Fusion significantly outperforms other state-of-the-art multispectral object
detection methods, evidencing its superiority. Moreover, MS2Fusion is general
and applicable to other multispectral perception tasks. We show that, even
without specific design, MS2Fusion achieves state-of-the-art results on RGB-T
semantic segmentation and RGBT salient object detection, showing its
generality. The source code will be available at
https://github.com/61s61min/MS2Fusion.git.

</details>


### [35] [AI-Powered Precision in Sport Taekwondo: Enhancing Fairness, Speed, and Trust in Competition (FST.ai)](https://arxiv.org/abs/2507.14657)
*Keivan Shariatmadar,Ahmad Osman*

Main category: cs.CV

TL;DR: 本文提出了FST.ai，这是一个新的AI裁判系统，主要应用于跆拳道比赛中的实时头部击打检测与判分，实现了判罚速度提升和公正性的增强，并且该系统具备跨项适用的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有体育裁判体系，即使结合即时回放，仍存在主观性高、执行不一致、反应慢等问题，影响比赛公平和运动员信任，亟需新型技术解决。

Method: FST.ai系统结合计算机视觉、深度学习和边缘推理技术，通过姿态估计、动作分类和冲击力分析，实现对关键动作的自动识别与分类，并即时做出判罚。

Result: 系统将判罚时间从数分钟缩短到几秒，提高了一致性和透明度。以跆拳道头部击打判分为试点，展现了该系统的可靠性、扩展性和通用性。

Conclusion: FST.ai技术不仅提升了跆拳道等竞技项目的裁判标准，也展现了推广至空手道、柔道、击剑乃至足球、篮球等动作识别需求强烈项目的广阔应用前景。

Abstract: The integration of Artificial Intelligence (AI) into sports officiating
represents a paradigm shift in how decisions are made in competitive
environments. Traditional manual systems, even when supported by Instant Video
Replay (IVR), often suffer from latency, subjectivity, and inconsistent
enforcement, undermining fairness and athlete trust. This paper introduces
FST.ai, a novel AI-powered framework designed to enhance officiating in Sport
Taekwondo, particularly focusing on the complex task of real-time head kick
detection and scoring. Leveraging computer vision, deep learning, and edge
inference, the system automates the identification and classification of key
actions, significantly reducing decision time from minutes to seconds while
improving consistency and transparency. Importantly, the methodology is not
limited to Taekwondo. The underlying framework -- based on pose estimation,
motion classification, and impact analysis -- can be adapted to a wide range of
sports requiring action detection, such as judo, karate, fencing, or even team
sports like football and basketball, where foul recognition or performance
tracking is critical. By addressing one of Taekwondo's most challenging
scenarios -- head kick scoring -- we demonstrate the robustness, scalability,
and sport-agnostic potential of FST.ai to transform officiating standards
across multiple disciplines.

</details>


### [36] [Artificial Intelligence in the Food Industry: Food Waste Estimation based on Computer Vision, a Brief Case Study in a University Dining Hall](https://arxiv.org/abs/2507.14662)
*Shayan Rokhva,Babak Teimourpour*

Main category: cs.CV

TL;DR: 本研究提出了一种成本效益高的计算机视觉框架，通过语义分割技术对就餐前后盘中食物的RGB图像进行分析，估算机构用餐环境下的餐盘级食物浪费。


<details>
  <summary>Details</summary>
Motivation: 机构餐厅食物浪费数据匮乏，难以有效支持可持续性策略的制定，需要自动化、低成本且高效的食物浪费监测方法。

Method: 研究使用U-Net、U-Net++及其轻量版等四种全监督模型，在标注数据上结合动态逆频损失函数和AdamW优化器进行训练。通过Pixel Accuracy、Dice、IoU和定制的Distributional Pixel Agreement (DPA)等多项指标评估模型性能，并测试了模型的推理速度。

Result: 所有模型均取得令人满意的分割效果，每种食物类型中至少有一种模型的DPA接近或超过90%。轻量级模型在速度和实时性方面表现优异。干燥、结构分明的食物（如米饭、炸薯条）分割效果好，而如炖菜等复杂或黏稠食物则差，尤其用餐后。

Conclusion: 尽管存在二维成像、食物类别有限和人工采集等局限，所提方法为大规模团餐环境中实现连续、自动、无接触的食物浪费监测奠定了基础，为食堂管理与政策制定提供了数据支撑和未来改进方向。

Abstract: Quantifying post-consumer food waste in institutional dining settings is
essential for supporting data-driven sustainability strategies. This study
presents a cost-effective computer vision framework that estimates plate-level
food waste by utilizing semantic segmentation of RGB images taken before and
after meal consumption across five Iranian dishes. Four fully supervised models
(U-Net, U-Net++, and their lightweight variants) were trained using a capped
dynamic inverse-frequency loss and AdamW optimizer, then evaluated through a
comprehensive set of metrics, including Pixel Accuracy, Dice, IoU, and a
custom-defined Distributional Pixel Agreement (DPA) metric tailored to the
task. All models achieved satisfying performance, and for each food type, at
least one model approached or surpassed 90% DPA, demonstrating strong alignment
in pixel-wise proportion estimates. Lighter models with reduced parameter
counts offered faster inference, achieving real-time throughput on an NVIDIA T4
GPU. Further analysis showed superior segmentation performance for dry and more
rigid components (e.g., rice and fries), while more complex, fragmented, or
viscous dishes, such as stews, showed reduced performance, specifically
post-consumption. Despite limitations such as reliance on 2D imaging,
constrained food variety, and manual data collection, the proposed framework is
pioneering and represents a scalable, contactless solution for continuous
monitoring of food consumption. This research lays foundational groundwork for
automated, real-time waste tracking systems in large-scale food service
environments and offers actionable insights and outlines feasible future
directions for dining hall management and policymakers aiming to reduce
institutional food waste.

</details>


### [37] [Gene-DML: Dual-Pathway Multi-Level Discrimination for Gene Expression Prediction from Histopathology Images](https://arxiv.org/abs/2507.14670)
*Yaxuan Song,Jianan Fan,Hang Chang,Weidong Cai*

Main category: cs.CV

TL;DR: 本文提出了Gene-DML框架，能够更准确地从病理图像预测基因表达，实现分子分型的无创、高效化。方法通过多尺度实例和跨层次判别提升了图像-基因数据的对齐程度，显著优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 分子水平的分析对精准医疗和计算病理学具有重要意义，但现有方法在从病理图像预测基因表达时，未能充分利用不同层级下的跨模态对应关系，影响了预测准确性和泛化能力。作者旨在解决该局限。

Method: 提出Gene-DML统一框架，用双通路、多层级判别机制结构化潜在空间。第一通路通过多尺度判别，将局部、邻域及全局图像表达与基因表达对齐；第二通路则进行跨层次实例-组判别，加强个体与群体间的模态一致性。二者联合训练，提升跨模态对齐的鲁棒性和泛化性。

Result: 在公开的时空转录组数据集上大量实验，Gene-DML表现优异，基因表达预测准确率达到最新水平，超过了现有方法。

Conclusion: Gene-DML框架有效提升了病理图像基因表达预测的准确性和泛化能力，对精准医疗和相关研究具有广泛应用前景，代码和模型即将开源。

Abstract: Accurately predicting gene expression from histopathology images offers a
scalable and non-invasive approach to molecular profiling, with significant
implications for precision medicine and computational pathology. However,
existing methods often underutilize the cross-modal representation alignment
between histopathology images and gene expression profiles across multiple
representational levels, thereby limiting their prediction performance. To
address this, we propose Gene-DML, a unified framework that structures latent
space through Dual-pathway Multi-Level discrimination to enhance correspondence
between morphological and transcriptional modalities. The multi-scale
instance-level discrimination pathway aligns hierarchical histopathology
representations extracted at local, neighbor, and global levels with gene
expression profiles, capturing scale-aware morphological-transcriptional
relationships. In parallel, the cross-level instance-group discrimination
pathway enforces structural consistency between individual (image/gene)
instances and modality-crossed (gene/image, respectively) groups, strengthening
the alignment across modalities. By jointly modelling fine-grained and
structural-level discrimination, Gene-DML is able to learn robust cross-modal
representations, enhancing both predictive accuracy and generalization across
diverse biological contexts. Extensive experiments on public spatial
transcriptomics datasets demonstrate that Gene-DML achieves state-of-the-art
performance in gene expression prediction. The code and checkpoints will be
released soon.

</details>


### [38] [Docopilot: Improving Multimodal Models for Document-Level Understanding](https://arxiv.org/abs/2507.14675)
*Yuchen Duan,Zhe Chen,Yusong Hu,Weiyun Wang,Shenglong Ye,Botian Shi,Lewei Lu,Qibin Hou,Tong Lu,Hongsheng Li,Jifeng Dai,Wenhai Wang*

Main category: cs.CV

TL;DR: 论文提出了Doc-750K高质量文档级多模态数据集，并基于此开发了无需RAG的多模态文档理解模型Docopilot，实现了文档理解任务上的新基线表现。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型在处理复杂多页文档时效果不佳，原因包括缺乏高质量文档级数据集和检索增强生成（RAG）方法的局限。这推动作者构建专门的数据集和新模型以提升该领域表现。

Method: 作者提出Doc-750K数据集，涵盖丰富结构、跨页依赖和真实问答对。在此基础上，开发原生多模态模型Docopilot，无需依赖RAG即可处理文档级依赖，并设计相关实验进行评估。

Result: Docopilot模型在文档理解和多轮交互任务中展现出更佳的连贯性、准确性和效率，相较传统方法表现更优。

Conclusion: Docopilot为文档级多模态理解任务设立了新基线，实验验证了其有效性。相关数据、代码和模型均已开放。

Abstract: Despite significant progress in multimodal large language models (MLLMs),
their performance on complex, multi-page document comprehension remains
inadequate, largely due to the lack of high-quality, document-level datasets.
While current retrieval-augmented generation (RAG) methods offer partial
solutions, they suffer from issues, such as fragmented retrieval contexts,
multi-stage error accumulation, and extra time costs of retrieval. In this
work, we present a high-quality document-level dataset, Doc-750K, designed to
support in-depth understanding of multimodal documents. This dataset includes
diverse document structures, extensive cross-page dependencies, and real
question-answer pairs derived from the original documents. Building on the
dataset, we develop a native multimodal model, Docopilot, which can accurately
handle document-level dependencies without relying on RAG. Experiments
demonstrate that Docopilot achieves superior coherence, accuracy, and
efficiency in document understanding tasks and multi-turn interactions, setting
a new baseline for document-level multimodal understanding. Data, code, and
models are released at https://github.com/OpenGVLab/Docopilot

</details>


### [39] [WSI-Agents: A Collaborative Multi-Agent System for Multi-Modal Whole Slide Image Analysis](https://arxiv.org/abs/2507.14680)
*Xinheng Lyu,Yuci Liang,Wenting Chen,Meidan Ding,Jiaqi Yang,Guolin Huang,Daokun Zhang,Xiangjian He,Linlin Shen*

Main category: cs.CV

TL;DR: 本文提出了一种名为WSI-Agents的多智能体协作系统，专用于病理学全幅切片图像（WSI）的多模态分析，在多任务表现和任务准确性之间取得了优异平衡，并在多项基准任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前多模态大语言模型（MLLMs）虽支持多任务WSI分析，但在精准性上往往不及专用模型；同时多智能体系统在医疗领域显现出提升多任务能力与准确性的潜力，但在病理领域尚未被充分探索。

Method: WSI-Agents系统包含三个核心组件：（1）任务分配模块，利用多个专家型MLLM模型（模型库）对任务进行精确分配；（2）验证机制，通过内部一致性检测和利用病理知识库及领域模型进行外部验证，提升准确性；（3）总结模块，整合多方结果并生成带有可视化解读的最终分析总结。

Result: 在多个WSI多模态基准上进行的广泛实验显示，WSI-Agents系统在多项任务上成效优于当前的WSI MLLMs及其他医疗相关多智能体框架。

Conclusion: WSI-Agents通过多智能体协作和强大的任务分配、验证机制，实现了多任务分析的高通用性及高准确性，为病理学多模态自动化分析提供了有效新范式。

Abstract: Whole slide images (WSIs) are vital in digital pathology, enabling gigapixel
tissue analysis across various pathological tasks. While recent advancements in
multi-modal large language models (MLLMs) allow multi-task WSI analysis through
natural language, they often underperform compared to task-specific models.
Collaborative multi-agent systems have emerged as a promising solution to
balance versatility and accuracy in healthcare, yet their potential remains
underexplored in pathology-specific domains. To address these issues, we
propose WSI-Agents, a novel collaborative multi-agent system for multi-modal
WSI analysis. WSI-Agents integrates specialized functional agents with robust
task allocation and verification mechanisms to enhance both task-specific
accuracy and multi-task versatility through three components: (1) a task
allocation module assigning tasks to expert agents using a model zoo of patch
and WSI level MLLMs, (2) a verification mechanism ensuring accuracy through
internal consistency checks and external validation using pathology knowledge
bases and domain-specific models, and (3) a summary module synthesizing the
final summary with visual interpretation maps. Extensive experiments on
multi-modal WSI benchmarks show WSI-Agents's superiority to current WSI MLLMs
and medical agent frameworks across diverse tasks.

</details>


### [40] [From Semantics, Scene to Instance-awareness: Distilling Foundation Model for Open-vocabulary Situation Recognition](https://arxiv.org/abs/2507.14686)
*Chen Cai,Tianyi Liu,Jianjun Gao,Wenyang Liu,Kejun Wu,Ruoyu Wang,Yi Wang,Soo Chin Liew*

Main category: cs.CV

TL;DR: 本论文提出了一种新方法，通过知识蒸馏将强大的多模态大模型（MLLM）的能力转移给轻量级的小型情境识别（GSR）模型，从而提升其对未见及罕见情境的泛化与零样本识别能力。


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs尽管具备强大的零样本推理能力，但推理复杂情境识别任务时存在不足，且部署成本高。而传统GSR模型对未见和罕见情境泛化不佳。论文旨在弥补两者不足，增强小模型在边缘设备上的实用性和泛化能力。

Method: 提出“多模态交互提示蒸馏”（MIPD）框架，利用大模型生成具有上下文语义信息的正/负视觉理据，通过“负引导多模态提示对齐”（NMPA）模块进行对齐，最终将多模态知识蒸馏到学生Ov-GSR模型。

Result: 在精细化的Ov-SWiG数据集上，该方法在已见、未见及罕见情境上整体表现优越，在HICO-DET数据集上用于未见情境检测时亦优于现有方法。

Conclusion: 所提MIPD方法有效增强了小型GSR模型在开放词汇情境识别任务中的泛化能力和零样本表现，实现了对复杂情境的强健理解，适合于资源有限的实际部署场景。

Abstract: Recent Multimodal Large Language Models (MLLMs) exhibit strong zero-shot
abilities but struggle with complex Grounded Situation Recognition (GSR) and
are resource-intensive for edge device deployment. Meanwhile, conventional GSR
models often lack generalization ability, falling short in recognizing unseen
and rare situations. In this paper, we exploit transferring knowledge from a
teacher MLLM to a small GSR model to enhance its generalization and zero-shot
abilities, thereby introducing the task of Open-vocabulary Grounded Situation
Recognition (Ov-GSR). To achieve this, we propose Multimodal Interactive Prompt
Distillation (MIPD), a novel framework that distills enriched multimodal
knowledge from the foundation model, enabling the student Ov-GSR model to
recognize unseen situations and be better aware of rare situations.
Specifically, the MIPD framework first leverages the LLM-based Judgmental
Rationales Generator (JRG) to construct positive and negative glimpse and gaze
rationales enriched with contextual semantic information. The proposed
scene-aware and instance-perception prompts are then introduced to align
rationales with visual information from the MLLM teacher via the
Negative-Guided Multimodal Prompting Alignment (NMPA) module, effectively
capturing holistic and perceptual multimodal knowledge. Finally, the aligned
multimodal knowledge is distilled into the student Ov-GSR model, providing a
stronger foundation for generalization that enhances situation understanding,
bridges the gap between seen and unseen scenarios, and mitigates prediction
bias in rare cases. We evaluate MIPD on the refined Ov-SWiG dataset, achieving
superior performance on seen, rare, and unseen situations, and further
demonstrate improved unseen detection on the HICO-DET dataset.

</details>


### [41] [GTPBD: A Fine-Grained Global Terraced Parcel and Boundary Dataset](https://arxiv.org/abs/2507.14697)
*Zhiwei Zhang,Zi Ye,Yibin Wen,Shuai Yuan,Haohuan Fu,Jianxi Huang,Juepeng Zheng*

Main category: cs.CV

TL;DR: 本文提出了一个新的高精度梯田地块数据集GTPBD，覆盖全球主要梯田区，为复杂地形的农业地块提取及相关研究提供支撑，并基准测试了多种主流方法。


<details>
  <summary>Details</summary>
Motivation: 当前农业地块提取研究多集中于中等分辨率或普通平原农田，缺乏对复杂梯田地形的精细化数据和研究，影响精准农业实践。

Method: 作者构建了GTPBD数据集，人工标注了超过20万复杂梯田地块，包含高分辨率图像及多级标签，涵盖全球七大地理带。数据集支持语义分割、边缘检测、地块提取、无监督领域自适应等四类任务，并在相关主流方法上进行了基准测试和多维评估。

Result: GTPBD展示了复杂多样地形、地块形状和多域风格，基准测试结果显示该数据集对现有方法提出了较大挑战。评估体系涵盖像素级和目标级指标，结果为梯田遥感研究提供了新基准。

Conclusion: GTPBD数据集填补了复杂梯田地块遥感研究空白，促进了细粒度农业地形分析及跨场景知识迁移，为精准农业和相关遥感任务提供基础设施。

Abstract: Agricultural parcels serve as basic units for conducting agricultural
practices and applications, which is vital for land ownership registration,
food security assessment, soil erosion monitoring, etc. However, existing
agriculture parcel extraction studies only focus on mid-resolution mapping or
regular plain farmlands while lacking representation of complex terraced
terrains due to the demands of precision agriculture.In this paper, we
introduce a more fine-grained terraced parcel dataset named GTPBD (Global
Terraced Parcel and Boundary Dataset), which is the first fine-grained dataset
covering major worldwide terraced regions with more than 200,000 complex
terraced parcels with manual annotation. GTPBD comprises 47,537 high-resolution
images with three-level labels, including pixel-level boundary labels, mask
labels, and parcel labels. It covers seven major geographic zones in China and
transcontinental climatic regions around the world.Compared to the existing
datasets, the GTPBD dataset brings considerable challenges due to the: (1)
terrain diversity; (2) complex and irregular parcel objects; and (3) multiple
domain styles. Our proposed GTPBD dataset is suitable for four different tasks,
including semantic segmentation, edge detection, terraced parcel extraction,
and unsupervised domain adaptation (UDA) tasks.Accordingly, we benchmark the
GTPBD dataset on eight semantic segmentation methods, four edge extraction
methods, three parcel extraction methods, and five UDA methods, along with a
multi-dimensional evaluation framework integrating pixel-level and object-level
metrics. GTPBD fills a critical gap in terraced remote sensing research,
providing a basic infrastructure for fine-grained agricultural terrain analysis
and cross-scenario knowledge transfer.

</details>


### [42] [MultiRetNet: A Multimodal Vision Model and Deferral System for Staging Diabetic Retinopathy](https://arxiv.org/abs/2507.14738)
*Jeannie She,Katie Spivakovsky*

Main category: cs.CV

TL;DR: 本文提出了MultiRetNet，一种结合视网膜成像、社会经济因素和共病信息的新型多模态模型，通过临床人工决策机制提升糖尿病视网膜病变分期的准确性，尤其关注欠发达地区的早期筛查和诊断。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变是全球可预防失明的主要原因，低收入社区因筛查不便，诊断时多已进入晚期。共病加速病情恶化，亟需结合多源信息提升疾病早期检测与分期能力，减少健康不平等。

Method: 开发了MultiRetNet，多模态融合视网膜影像、社会经济与共病数据，尝试三种融合方式，最终选用全连接层融合。同时合成低质量对抗性图片，利用对比学习增强系统对分布外样本的识别能力，并引入临床决策转人工机制。

Result: 全连接层多模态融合表现优异，系统在低质量图片情况下依然保持分期准确。检测分布外样本的能力增强，让可疑病例导向人工医生评估。

Conclusion: MultiRetNet 能提升糖尿病视网膜病变早期检测与分期准确性，尤其对弱势群体早发现、早治疗有促进作用，有望减少费用、提高公平，有助于弥合医疗健康鸿沟。

Abstract: Diabetic retinopathy (DR) is a leading cause of preventable blindness,
affecting over 100 million people worldwide. In the United States, individuals
from lower-income communities face a higher risk of progressing to advanced
stages before diagnosis, largely due to limited access to screening. Comorbid
conditions further accelerate disease progression. We propose MultiRetNet, a
novel pipeline combining retinal imaging, socioeconomic factors, and
comorbidity profiles to improve DR staging accuracy, integrated with a clinical
deferral system for a clinical human-in-the-loop implementation. We experiment
with three multimodal fusion methods and identify fusion through a fully
connected layer as the most versatile methodology. We synthesize adversarial,
low-quality images and use contrastive learning to train the deferral system,
guiding the model to identify out-of-distribution samples that warrant
clinician review. By maintaining diagnostic accuracy on suboptimal images and
integrating critical health data, our system can improve early detection,
particularly in underserved populations where advanced DR is often first
identified. This approach may reduce healthcare costs, increase early detection
rates, and address disparities in access to care, promoting healthcare equity.

</details>


### [43] [Light Future: Multimodal Action Frame Prediction via InstructPix2Pix](https://arxiv.org/abs/2507.14809)
*Zesen Zhong,Duomin Zhang,Yijia Li*

Main category: cs.CV

TL;DR: 本文提出了一种高效、轻量化的机器人动作预测方法，能够根据当前图像和文本指令预测未来100帧（10秒）内的视觉信息，且在效率和精度上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 未来运动轨迹预测在机器人、自动驾驶和人类活动预测等领域至关重要。现有的视频预测模型通常需要多个输入帧、大量计算资源，并且推理延迟较高，限制了其实用性。本研究旨在开发一种计算开销低、推理速度快且输入需求更少的新方法，以满足实际应用对效率和多模态交互的需求。

Method: 作者创新性地将InstructPix2Pix模型由静态图像编辑扩展到机器人任务中的未来视觉帧预测。具体做法是将模型改造和微调，以接受当前图像和文本指令（多模态输入），并预测未来100帧内机器人将会观察到的画面。方法仅需单帧输入和文本提示，简化了计算流程。

Result: 在RoboTWin数据集上的实验结果显示，该方法在结构相似性（SSIM）和峰值信噪比（PSNR）等评估指标上超过现有主流的机器人动作预测基线。相较于传统方法，其在推理速度、GPU资源消耗和灵活性方面也具备显著优势。

Conclusion: 新方法能够高效、精确地预测未来机器人视觉轨迹，显著降低了运算资源需求和推理延迟，便于在机器人和体育运动精细分析等场景推广应用。

Abstract: Predicting future motion trajectories is a critical capability across domains
such as robotics, autonomous systems, and human activity forecasting, enabling
safer and more intelligent decision-making. This paper proposes a novel,
efficient, and lightweight approach for robot action prediction, offering
significantly reduced computational cost and inference latency compared to
conventional video prediction models. Importantly, it pioneers the adaptation
of the InstructPix2Pix model for forecasting future visual frames in robotic
tasks, extending its utility beyond static image editing. We implement a deep
learning-based visual prediction framework that forecasts what a robot will
observe 100 frames (10 seconds) into the future, given a current image and a
textual instruction. We repurpose and fine-tune the InstructPix2Pix model to
accept both visual and textual inputs, enabling multimodal future frame
prediction. Experiments on the RoboTWin dataset (generated based on real-world
scenarios) demonstrate that our method achieves superior SSIM and PSNR compared
to state-of-the-art baselines in robot action prediction tasks. Unlike
conventional video prediction models that require multiple input frames, heavy
computation, and slow inference latency, our approach only needs a single image
and a text prompt as input. This lightweight design enables faster inference,
reduced GPU demands, and flexible multimodal control, particularly valuable for
applications like robotics and sports motion trajectory analytics, where motion
trajectory precision is prioritized over visual fidelity.

</details>


### [44] [InterAct-Video: Reasoning-Rich Video QA for Urban Traffic](https://arxiv.org/abs/2507.14743)
*Joseph Raj Vishal,Rutuja Patil,Manas Srinivas Gowda,Katha Naik,Yezhou Yang,Bharatesh Chakravarthi*

Main category: cs.CV

TL;DR: 本文提出了InterAct VideoQA，一个用于交通监控视频问答的新数据集，以推动深度学习模型在复杂交通场景下的表现提升。


<details>
  <summary>Details</summary>
Motivation: 现有的视频问答（VideoQA）模型难以处理现实交通监控中多事件并发、复杂时空关系等问题，限制了其在智能交通系统中的应用。

Method: 作者构建了InterAct VideoQA数据集，收集了8小时真实路口交通视频，分割为10秒片段，并生成了2.5万组涵盖时空动态、车辆交互、事件检测等方面的问答对。利用该数据集，对主流VideoQA模型进行了基准评测及微调。

Result: 实验结果显示，当前最先进的VideoQA模型在此数据集上的推理能力有限，但经过针对该数据集的训练后，性能显著提升，证明了领域特定数据集的重要性。

Conclusion: InterAct VideoQA作为开放基准，可助力视频问答技术在智能交通系统中的落地和研究发展。

Abstract: Traffic monitoring is crucial for urban mobility, road safety, and
intelligent transportation systems (ITS). Deep learning has advanced
video-based traffic monitoring through video question answering (VideoQA)
models, enabling structured insight extraction from traffic videos. However,
existing VideoQA models struggle with the complexity of real-world traffic
scenes, where multiple concurrent events unfold across spatiotemporal
dimensions. To address these challenges, this paper introduces \textbf{InterAct
VideoQA}, a curated dataset designed to benchmark and enhance VideoQA models
for traffic monitoring tasks. The InterAct VideoQA dataset comprises 8 hours of
real-world traffic footage collected from diverse intersections, segmented into
10-second video clips, with over 25,000 question-answer (QA) pairs covering
spatiotemporal dynamics, vehicle interactions, incident detection, and other
critical traffic attributes. State-of-the-art VideoQA models are evaluated on
InterAct VideoQA, exposing challenges in reasoning over fine-grained
spatiotemporal dependencies within complex traffic scenarios. Additionally,
fine-tuning these models on InterAct VideoQA yields notable performance
improvements, demonstrating the necessity of domain-specific datasets for
VideoQA. InterAct VideoQA is publicly available as a benchmark dataset to
facilitate future research in real-world deployable VideoQA models for
intelligent transportation systems. GitHub Repo:
https://github.com/joe-rabbit/InterAct_VideoQA

</details>


### [45] [EBA-AI: Ethics-Guided Bias-Aware AI for Efficient Underwater Image Enhancement and Coral Reef Monitoring](https://arxiv.org/abs/2507.15036)
*Lyes Saad Saoud,Irfan Hussain*

Main category: cs.CV

TL;DR: 该论文提出了EBA-AI，一个注重伦理和偏差感知的AI框架，用于水下图像增强，解决传统AI方法中数据集偏差、高计算消耗和缺乏可解释性的问题，提升了大型海洋监测的实际可用性和可信度。


<details>
  <summary>Details</summary>
Motivation: 水下图像增强对于海洋保护（如珊瑚礁监测）至关重要，但现有AI模型常因数据集偏差导致泛化能力差、计算资源消耗大且黑箱特征严重，影响其实际大规模应用与环境决策的可靠性。

Method: 提出EBA-AI框架，结合CLIP嵌入检测并缓解数据偏差，通过自适应处理优化能效，减少GPU消耗，并引入不确定性估计和可解释性技术提升框架透明度。实验在多个公开数据集上对比主流方法，并量化了效率、性能和公平性。

Result: EBA-AI在增强质量略有下降（PSNR控制在减少1.0 dB以内）的前提下，显著降低了计算成本，实现了大规模海洋监测的实时可行性。实验还表明其解释性和公平性优于CycleGAN、FunIEGAN等主流方法。

Conclusion: EBA-AI有效平衡了效率、公平性与可解释性，为可持续和偏差感知的海洋环境监测AI提供了新路径。

Abstract: Underwater image enhancement is vital for marine conservation, particularly
coral reef monitoring. However, AI-based enhancement models often face dataset
bias, high computational costs, and lack of transparency, leading to potential
misinterpretations. This paper introduces EBA-AI, an ethics-guided bias-aware
AI framework to address these challenges. EBA-AI leverages CLIP embeddings to
detect and mitigate dataset bias, ensuring balanced representation across
varied underwater environments. It also integrates adaptive processing to
optimize energy efficiency, significantly reducing GPU usage while maintaining
competitive enhancement quality. Experiments on LSUI400, Oceanex, and UIEB100
show that while PSNR drops by a controlled 1.0 dB, computational savings enable
real-time feasibility for large-scale marine monitoring. Additionally,
uncertainty estimation and explainability techniques enhance trust in AI-driven
environmental decisions. Comparisons with CycleGAN, FunIEGAN, RAUNENet,
WaterNet, UGAN, PUGAN, and UTUIE validate EBA-AI's effectiveness in balancing
efficiency, fairness, and interpretability in underwater image processing. By
addressing key limitations of AI-driven enhancement, this work contributes to
sustainable, bias-aware, and computationally efficient marine conservation
efforts. For interactive visualizations, animations, source code, and access to
the preprint, visit: https://lyessaadsaoud.github.io/EBA-AI/

</details>


### [46] [LeAdQA: LLM-Driven Context-Aware Temporal Grounding for Video Question Answering](https://arxiv.org/abs/2507.14784)
*Xinxin Dong,Baoyun Peng,Haokai Ma,Yufei Wang,Zixuan Dong,Fei Hu,Xiaodong Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为LeAdQA的方法，通过因果感知的查询优化和细粒度的视觉定位，提升VideoQA复杂推理任务的表现，并在多个数据集上实现了SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有VideoQA方法要么对所有帧无差别处理，导致关键信息被淹没；要么仅用启发式检索方法，缺乏对视频时间和因果结构的深入理解，难以应对复杂语义推理任务。

Method: LeAdQA利用大语言模型对问题与选项进行重构，聚焦因果和时序信息，随后用精细的时序定位模型检索视频关键片段，并通过自适应融合机制整合多模态证据，最终用多模态大模型（MLLM）生成答案。

Result: 在NExT-QA、IntentQA和NExT-GQA等数据集上，LeAdQA通过更精确的视觉定位，显著提升了视频与问题的理解，取得了复杂推理任务的新SOTA结果，同时保持计算效率。

Conclusion: LeAdQA创新性地结合了因果感知的查询优化和视觉定位，有效解决了以前方法在VideoQA任务中的缺陷，并在保持效率的情况下大幅提升了性能。

Abstract: Video Question Answering (VideoQA) requires identifying sparse critical
moments in long videos and reasoning about their causal relationships to answer
semantically complex questions. While recent advances in multimodal learning
have improved alignment and fusion, current approaches remain limited by two
prevalent but fundamentally flawed strategies: (1) task-agnostic sampling
indiscriminately processes all frames, overwhelming key events with irrelevant
content; and (2) heuristic retrieval captures superficial patterns but misses
causal-temporal structures needed for complex reasoning. To address these
challenges, we introduce LeAdQA, an innovative approach that bridges these gaps
through synergizing causal-aware query refinement with fine-grained visual
grounding. Our method first leverages LLMs to reformulate question-option
pairs, resolving causal ambiguities and sharpening temporal focus. These
refined queries subsequently direct a temporal grounding model to precisely
retrieve the most salient segments, complemented by an adaptive fusion
mechanism dynamically integrating the evidence to maximize relevance. The
integrated visual-textual cues are then processed by an MLLM to generate
accurate, contextually-grounded answers. Experiments on NExT-QA, IntentQA, and
NExT-GQA demonstrate that our method's precise visual grounding substantially
enhances the understanding of video-question relationships, achieving
state-of-the-art (SOTA) performance on complex reasoning tasks while
maintaining computational efficiency.

</details>


### [47] [Visual Place Recognition for Large-Scale UAV Applications](https://arxiv.org/abs/2507.15089)
*Ioannis Tsampikos Papapetros,Ioannis Kansizoglou,Antonios Gasteratos*

Main category: cs.CV

TL;DR: 该论文提出了适用于无人机视觉定位的大规模航空图像数据集LASED，并结合可旋转卷积神经网络提升模型在旋转不变性和泛化能力上的表现。


<details>
  <summary>Details</summary>
Motivation: 无人机视觉定位受限于缺乏大规模、高空图片数据集和图片旋转歧义，导致模型泛化性差。

Method: 作者提出了LASED数据集（包含约100万张图片，覆盖爱沙尼亚17万独特地点，拥有十年时间跨度和丰富地理变化），并结合可旋转卷积神经网络（Steerable CNNs）来提升旋转不变特性。

Result: 在LASED数据集上训练的模型，召回率显著高于在其它小规模和单一数据集训练的模型。使用可旋转CNN的召回率比最佳常规CNN模型平均提升12%。

Conclusion: 结合结构化大规模航空数据集与旋转等变神经网络，可显著提高无人机视觉定位在不同地理和时间条件下的鲁棒性及泛化能力。

Abstract: Visual Place Recognition (vPR) plays a crucial role in Unmanned Aerial
Vehicle (UAV) navigation, enabling robust localization across diverse
environments. Despite significant advancements, aerial vPR faces unique
challenges due to the limited availability of large-scale, high-altitude
datasets, which limits model generalization, along with the inherent rotational
ambiguity in UAV imagery. To address these challenges, we introduce LASED, a
large-scale aerial dataset with approximately one million images,
systematically sampled from 170,000 unique locations throughout Estonia over a
decade, offering extensive geographic and temporal diversity. Its structured
design ensures clear place separation significantly enhancing model training
for aerial scenarios. Furthermore, we propose the integration of steerable
Convolutional Neural Networks (CNNs) to explicitly handle rotational variance,
leveraging their inherent rotational equivariance to produce robust,
orientation-invariant feature representations. Our extensive benchmarking
demonstrates that models trained on LASED achieve significantly higher recall
compared to those trained on smaller, less diverse datasets, highlighting the
benefits of extensive geographic coverage and temporal diversity. Moreover,
steerable CNNs effectively address rotational ambiguity inherent in aerial
imagery, consistently outperforming conventional convolutional architectures,
achieving on average 12\% recall improvement over the best-performing
non-steerable network. By combining structured, large-scale datasets with
rotation-equivariant neural networks, our approach significantly enhances model
robustness and generalization for aerial vPR.

</details>


### [48] [FOCUS: Fused Observation of Channels for Unveiling Spectra](https://arxiv.org/abs/2507.14787)
*Xi Xiao,Aristeidis Tsaris,Anika Tabassum,John Lagergren,Larry M. York,Tianyang Wang,Xiao Wang*

Main category: cs.CV

TL;DR: 本文提出了FOCUS框架，实现了对高维高光谱图像中冻结型视觉Transformer（ViT）的高效可解释性，能够生成三维显著性图和波段重要性曲线，提升了结果的稳定性和与专家注释对齐程度。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像在生物、农业和环境监测等领域应用广泛，但目前对应用于高光谱数据的ViT模型的可解释性研究较少，现有显著性方法在处理高维数据时存在注意力坍缩和计算量高等问题。

Method: FOCUS框架主要包括两个新组件：（1）类别特定的光谱提示（prompt），引导注意力关注语义相关的波段群；（2）可训练的[SINK] token，通过吸引损失吸收噪音或冗余注意力。该方法无需反向传播和骨干网络修改，单次前向传递即可输出可解释性结果，并且参数开销小于1%。

Result: FOCUS提升了波段级IoU 15%，减少了超过40%的注意力坍缩，生成的显著性结果与专家标注高度一致，效率与可靠性兼备。

Conclusion: FOCUS显著推动了高光谱成像中ViT模型的可解释性研究，使高分辨率ViT应用于实际高光谱任务成为现实，为高光谱数据建模与决策的可信性提供了有力支持。

Abstract: Hyperspectral imaging (HSI) captures hundreds of narrow, contiguous
wavelength bands, making it a powerful tool in biology, agriculture, and
environmental monitoring. However, interpreting Vision Transformers (ViTs) in
this setting remains largely unexplored due to two key challenges: (1) existing
saliency methods struggle to capture meaningful spectral cues, often collapsing
attention onto the class token, and (2) full-spectrum ViTs are computationally
prohibitive for interpretability, given the high-dimensional nature of HSI
data. We present FOCUS, the first framework that enables reliable and efficient
spatial-spectral interpretability for frozen ViTs. FOCUS introduces two core
components: class-specific spectral prompts that guide attention toward
semantically meaningful wavelength groups, and a learnable [SINK] token trained
with an attraction loss to absorb noisy or redundant attention. Together, these
designs make it possible to generate stable and interpretable 3D saliency maps
and spectral importance curves in a single forward pass, without any gradient
backpropagation or backbone modification. FOCUS improves band-level IoU by 15
percent, reduces attention collapse by over 40 percent, and produces saliency
results that align closely with expert annotations. With less than 1 percent
parameter overhead, our method makes high-resolution ViT interpretability
practical for real-world hyperspectral applications, bridging a long-standing
gap between black-box modeling and trustworthy HSI decision-making.

</details>


### [49] [Dense-depth map guided deep Lidar-Visual Odometry with Sparse Point Clouds and Images](https://arxiv.org/abs/2507.15496)
*JunYing Huang,Ao Xu,DongSun Yong,KeRen Li,YuanFeng Wang,Qi Qin*

Main category: cs.CV

TL;DR: 本论文提出了一种新的激光雷达-视觉里程计（LiDAR-Visual Odometry）框架，以融合点云和图像，实现更高精度和鲁棒性的定位与导航。


<details>
  <summary>Details</summary>
Motivation: 自动化系统在自定位和导航中依赖于高精度的里程计，目前独立的视觉或激光雷达方法在动态环境和遮挡等情况下仍存在局限，亟需融合多源传感器信息提升性能。

Method: 该方法通过深度补全，将点云和图像估算出稠密深度图，并结合带注意力机制的多尺度特征提取网络，自适应生成深度感知特征，同时利用稠密深度优化光流和减小遮挡区域的估计误差；提出层次化位姿优化模块，分阶段提升运动估计鲁棒性。

Result: 在KITTI里程计基准测试上，所提方法在准确性和鲁棒性上达到了与当前主流视觉和激光雷达里程计类似或更优的表现。

Conclusion: 融合激光雷达点云和图像的深度补全及多尺度自适应特征提取，可有效提升复杂环境下的位姿估计精度和鲁棒性，具备应用于实际自动化系统的潜力。

Abstract: Odometry is a critical task for autonomous systems for self-localization and
navigation. We propose a novel LiDAR-Visual odometry framework that integrates
LiDAR point clouds and images for accurate and robust pose estimation. Our
method utilizes a dense-depth map estimated from point clouds and images
through depth completion, and incorporates a multi-scale feature extraction
network with attention mechanisms, enabling adaptive depth-aware
representations. Furthermore, we leverage dense depth information to refine
flow estimation and mitigate errors in occlusion-prone regions. Our
hierarchical pose refinement module optimizes motion estimation progressively,
ensuring robust predictions against dynamic environments and scale ambiguities.
Comprehensive experiments on the KITTI odometry benchmark demonstrate that our
approach achieves similar or superior accuracy and robustness compared to
state-of-the-art visual and LiDAR odometry methods.

</details>


### [50] [A Novel Downsampling Strategy Based on Information Complementarity for Medical Image Segmentation](https://arxiv.org/abs/2507.14790)
*Wenbo Yue,Chang Li,Guoping Xu*

Main category: cs.CV

TL;DR: 本文提出了一种新的下采样方法Hybrid Pooling Downsampling（HPD），通过MinMaxPooling更好保留图像关键信息，从而提升语义分割准确度。实验表明，该方法优于传统的下采样方式。


<details>
  <summary>Details</summary>
Motivation: 传统下采样方法虽然可有效聚合特征、扩大感受野并减少计算量，但在语义分割任务中会丢失关键空间信息，影响像素级的预测精度。为解决该问题，作者希望设计一种既能下采样又能保留更多细节信息的方法。

Method: 作者提出了基于信息互补的下采样方法HPD，其核心在于利用MinMaxPooling替代传统下采样操作，从局部区域中提取最大值信息，有效保持图像的明暗对比和细节特征。

Result: 在ACDC和Synapse数据集上，HPD方法在多种CNN架构中的分割性能优于传统下采样方法，DSC系数平均提升了0.5%。

Conclusion: HPD模块为语义分割任务提供了一种更高效的下采样方案，能更好地保留关键空间信息并提升分割精度。

Abstract: In convolutional neural networks (CNNs), downsampling operations are crucial
to model performance. Although traditional downsampling methods (such as
maximum pooling and cross-row convolution) perform well in feature aggregation,
receptive field expansion, and computational reduction, they may lead to the
loss of key spatial information in semantic segmentation tasks, thereby
affecting the pixel-by-pixel prediction accuracy.To this end, this study
proposes a downsampling method based on information complementarity - Hybrid
Pooling Downsampling (HPD). The core is to replace the traditional method with
MinMaxPooling, and effectively retain the light and dark contrast and detail
features of the image by extracting the maximum value information of the local
area.Experiment on various CNN architectures on the ACDC and Synapse datasets
show that HPD outperforms traditional methods in segmentation performance, and
increases the DSC coefficient by 0.5% on average. The results show that the HPD
module provides an efficient solution for semantic segmentation tasks.

</details>


### [51] [Being-H0: Vision-Language-Action Pretraining from Large-Scale Human Videos](https://arxiv.org/abs/2507.15597)
*Hao Luo,Yicheng Feng,Wanpeng Zhang,Sipeng Zheng,Ye Wang,Haoqi Yuan,Jiazheng Liu,Chaoyi Xu,Qin Jin,Zongqing Lu*

Main category: cs.CV

TL;DR: 本文提出了Being-H0，一种在大规模人类视频上训练的高灵巧视觉-语言-动作（VLA）模型，显著提升了机器人灵巧操作和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型在复杂操作任务中的泛化能力有限，主要受限于合成数据的sim-to-real差距和缺乏多样性的遥操作示范。为解决数据瓶颈问题，作者提出利用丰富的人类手部操作数据作为新基础。

Method: 作者提出了一种新的物理指令微调（physical instruction tuning）训练范式，包括：1）基于人类视频的大规模VLA预训练，2）物理空间对齐以提升三维推理能力，3）机器人任务的后训练适配。同时引入了零件级运动token化方法，实现毫米级精度的手部动作重建，并搭建了综合数据管线，融合动作捕捉、VR和RGB视频等多源异构数据，生成大规模动作型指令数据集。

Result: 实验证明Being-H0在手部动作生成和指令跟随任务上表现优异，且模型和数据规模提升带来持续性能提升。物理指令微调后，在现实机器人操作任务中显著提升表现。

Conclusion: Being-H0通过利用大规模人类视频和新训练范式，有效突破了现有VLA模型在高灵巧操控、泛化和现实任务中的表现瓶颈，为机器人操作和模仿学习带来新进展。

Abstract: We introduce Being-H0, a dexterous Vision-Language-Action model (VLA) trained
on large-scale human videos. Existing VLAs struggle with complex manipulation
tasks requiring high dexterity and generalize poorly to novel scenarios and
tasks, primarily due to their reliance on synthetic data with significant
sim-to-real gaps or teleoperated demonstrations lacking scale and diversity. To
address this data bottleneck, we propose leveraging human hands as a foundation
manipulator, capitalizing on the rich dexterity and scalability present in web
data. Our approach centers on physical instruction tuning, a novel training
paradigm that combines large-scale VLA pretraining from human videos, physical
space alignment for 3D reasoning, and post-training adaptation for robotic
tasks. Additionally, we introduce a part-level motion tokenization method which
achieves millimeter-level reconstruction accuracy to model precise hand
trajectories for action learning. To support our proposed paradigm, we further
develop a comprehensive data curation pipeline that integrates heterogeneous
sources -- including motion capture, VR, and RGB-only videos -- into a
large-scale dataset with millions of motion-based instructional instances. We
empirically show the excellence of Being-H0 in hand motion generation and
instruction following, and it also scales well with model and data sizes.
Importantly, we observe the expected gains of Being-H0 in real-world robotic
manipulation as physical instruction tuning is applied. More details are
available at https://beingbeyond.github.io/Being-H0.

</details>


### [52] [Distilling Parallel Gradients for Fast ODE Solvers of Diffusion Models](https://arxiv.org/abs/2507.14797)
*Beier Zhu,Ruoyu Wang,Tong Zhao,Hanwang Zhang,Chi Zhang*

Main category: cs.CV

TL;DR: 提出了一种新的并行ODE求解器EPD，加速扩散模型采样同时保持高图像质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然生成效果很好，但由于去噪过程是序列化的，采样速度慢。在保证图像质量的情况下加速采样是当前研究的痛点。

Method: 提出Ensemble Parallel Direction（EPD）ODE求解器，通过在每一步并行评估多个梯度，降低截断误差，并可完全并行计算，从而减少时延。方法通过少量可学习参数进行蒸馏优化，无需额外大规模训练。EPD可作为插件兼容已有ODE采样器。

Result: 在多个生成基准上实验，EPD在相同延迟（5 NFE）下，相比现有方法在CIFAR-10、FFHQ、ImageNet、LSUN Bedroom等数据集FID均更低，提升显著。

Conclusion: EPD能在保证高图像质量的情况下大幅降低采样延迟，对加速扩散模型具有实际使用价值。

Abstract: Diffusion models (DMs) have achieved state-of-the-art generative performance
but suffer from high sampling latency due to their sequential denoising nature.
Existing solver-based acceleration methods often face image quality degradation
under a low-latency budget. In this paper, we propose the Ensemble Parallel
Direction solver (dubbed as \ours), a novel ODE solver that mitigates
truncation errors by incorporating multiple parallel gradient evaluations in
each ODE step. Importantly, since the additional gradient computations are
independent, they can be fully parallelized, preserving low-latency sampling.
  Our method optimizes a small set of learnable parameters in a distillation
fashion, ensuring minimal training overhead.
  In addition, our method can serve as a plugin to improve existing ODE
samplers. Extensive experiments on various image synthesis benchmarks
demonstrate the effectiveness of our \ours~in achieving high-quality and
low-latency sampling. For example, at the same latency level of 5 NFE, EPD
achieves an FID of 4.47 on CIFAR-10, 7.97 on FFHQ, 8.17 on ImageNet, and 8.26
on LSUN Bedroom, surpassing existing learning-based solvers by a significant
margin. Codes are available in https://github.com/BeierZhu/EPD.

</details>


### [53] [An Evaluation of DUSt3R/MASt3R/VGGT 3D Reconstruction on Photogrammetric Aerial Blocks](https://arxiv.org/abs/2507.14798)
*Xinyi Wu,Steven Landgraf,Markus Ulrich,Rongjun Qin*

Main category: cs.CV

TL;DR: 本文对最新的3D重建基础模型（DUSt3R、MASt3R、VGGT）在典型航拍影像集上的性能进行了详细评估。结果显示，这些方法在稀疏影像条件下的3D重建能力优于传统方法，但在高分辨率和大规模数据集上仍存在局限。


<details>
  <summary>Details</summary>
Motivation: 尽管DUSt3R、MASt3R、VGGT等模型已在多种CV基准上评测，但其在航测影像块上的性能尚未被系统研究，而该应用场景常见于实际航空遥感与测绘。

Method: 作者在UseGeo数据集的航测影像块上，对预训练DUSt3R、MASt3R、VGGT模型进行姿态估计与稠密3D重建测试，并与传统SfM/MVS系统（如COLMAP）进行对比。

Result: 这些模型能利用极少（<10张）低分辨率影像准确重建稠密点云，比COLMAP在完整性上提升最高达50%。VGGT在计算效率、可扩展性和相机姿态估计方面表现突出。但在高分辨率、大量影像时，姿态估计可靠性下降。

Conclusion: Transformer为基础的方法无法完全替代传统SfM与MVS，但在低分辨率与极稀疏图像场景下表现优异，可作为有力补充。

Abstract: State-of-the-art 3D computer vision algorithms continue to advance in
handling sparse, unordered image sets. Recently developed foundational models
for 3D reconstruction, such as Dense and Unconstrained Stereo 3D Reconstruction
(DUSt3R), Matching and Stereo 3D Reconstruction (MASt3R), and Visual Geometry
Grounded Transformer (VGGT), have attracted attention due to their ability to
handle very sparse image overlaps. Evaluating DUSt3R/MASt3R/VGGT on typical
aerial images matters, as these models may handle extremely low image overlaps,
stereo occlusions, and textureless regions. For redundant collections, they can
accelerate 3D reconstruction by using extremely sparsified image sets. Despite
tests on various computer vision benchmarks, their potential on photogrammetric
aerial blocks remains unexplored. This paper conducts a comprehensive
evaluation of the pre-trained DUSt3R/MASt3R/VGGT models on the aerial blocks of
the UseGeo dataset for pose estimation and dense 3D reconstruction. Results
show these methods can accurately reconstruct dense point clouds from very
sparse image sets (fewer than 10 images, up to 518 pixels resolution), with
completeness gains up to +50% over COLMAP. VGGT also demonstrates higher
computational efficiency, scalability, and more reliable camera pose
estimation. However, all exhibit limitations with high-resolution images and
large sets, as pose reliability declines with more images and geometric
complexity. These findings suggest transformer-based methods cannot fully
replace traditional SfM and MVS, but offer promise as complementary approaches,
especially in challenging, low-resolution, and sparse scenarios.

</details>


### [54] [Exploring Scalable Unified Modeling for General Low-Level Vision](https://arxiv.org/abs/2507.14801)
*Xiangyu Chen,Kaiwen Zhu,Yuandong Pu,Shuo Cao,Xiaohui Li,Wenlong Zhang,Yihao Liu,Yu Qiao,Jiantao Zhou,Chao Dong*

Main category: cs.CV

TL;DR: 提出了一种基于视觉任务提示的新型图像处理框架VPIP，实现了对多种低阶视觉任务的统一建模并展现出良好的泛化和扩展能力。


<details>
  <summary>Details</summary>
Motivation: 低阶视觉任务类型繁多（如图像修复、增强、风格化、特征提取等），任务目标和输出域差异显著，导致难以设计一个统一的方法来处理所有任务，本文旨在解决多种低阶视觉任务统一建模的挑战。

Method: 提出了VPIP框架，包括端到端的图像处理主干网络、提示编码器和提示交互模块，利用输入-目标图像对作为视觉提示，指导模型完成不同任务。该框架可与多种架构灵活结合，并有效利用任务特定的视觉表示。基于此设计，作者开发了统一模型GenLV，并构建了包含100多种低阶视觉任务的大规模基准测试，训练了多版本模型以测试扩展性。

Result: 实验表明，该方法在多种低阶视觉任务上达到了优异的性能。训练任务数量增加可提升泛化能力，特别是针对数据稀缺任务。模型在零样本泛化、少样本迁移和特定任务微调等情境中展现出强适应性。

Conclusion: 提出的VPIP框架实现了低阶视觉任务的统一、可扩展且具备极强泛化能力的模型基础，适合通用低阶视觉建模，具备广泛的应用潜力。

Abstract: Low-level vision involves a wide spectrum of tasks, including image
restoration, enhancement, stylization, and feature extraction, which differ
significantly in both task formulation and output domains. To address the
challenge of unified modeling across such diverse tasks, we propose a Visual
task Prompt-based Image Processing (VPIP) framework that leverages input-target
image pairs as visual prompts to guide the model in performing a variety of
low-level vision tasks. The framework comprises an end-to-end image processing
backbone, a prompt encoder, and a prompt interaction module, enabling flexible
integration with various architectures and effective utilization of
task-specific visual representations. Based on this design, we develop a
unified low-level vision model, GenLV, and evaluate its performance across
multiple representative tasks. To explore the scalability of this approach, we
extend the framework along two dimensions: model capacity and task diversity.
We construct a large-scale benchmark consisting of over 100 low-level vision
tasks and train multiple versions of the model with varying scales.
Experimental results show that the proposed method achieves considerable
performance across a wide range of tasks. Notably, increasing the number of
training tasks enhances generalization, particularly for tasks with limited
data, indicating the model's ability to learn transferable representations
through joint training. Further evaluations in zero-shot generalization,
few-shot transfer, and task-specific fine-tuning scenarios demonstrate the
model's strong adaptability, confirming the effectiveness, scalability, and
potential of the proposed framework as a unified foundation for general
low-level vision modeling.

</details>


### [55] [Seeing Through Deepfakes: A Human-Inspired Framework for Multi-Face Detection](https://arxiv.org/abs/2507.14807)
*Juan Hu,Shaojing Fan,Terence Sim*

Main category: cs.CV

TL;DR: 本论文提出了一种基于人类认知机制的新方法（HICOM），针对多个假脸同时出现的深度伪造（deepfake）视频进行检测，并显著提升了检测准确率及可解释性。


<details>
  <summary>Details</summary>
Motivation: 目前大多数deepfake检测方法主要针对单人脸场景，对现实中的多人人脸、社交场景下的deepfake视频表现不佳，因为忽略了重要的上下文线索。作者希望模仿人类辨别伪造的方式，提升多脸场景下的deepfake检测效果。

Method: 作者通过大规模的人类实验，总结出人类辨别deepfake时依赖的四大关键线索：场景与动作一致性、人脸外貌兼容性、视线对齐情况和脸部-身体一致性。在此基础上，设计了HICOM检测框架，并融合了大语言模型（LLM），进一步提供可读的解释说明，增强结果的透明性和说服力。

Result: 在多个基准测试集上，HICOM在同数据集检测中准确率提升3.3%，在实际扰动下提升2.8%。在未见过的新数据集上超越现有方法5.8%，展现了人类认知启发的普适性。框架还能输出人类可理解的检测理由。

Conclusion: 基于人类认知线索，结合大语言模型解释的HICOM方法，在多脸deepfake检测任务中相较于现有技术实现了显著性能提升，并提升了检测结果的解释性。这显示人类因素的引入对加强deepfake防御具有重要价值。

Abstract: Multi-face deepfake videos are becoming increasingly prevalent, often
appearing in natural social settings that challenge existing detection methods.
Most current approaches excel at single-face detection but struggle in
multi-face scenarios, due to a lack of awareness of crucial contextual cues. In
this work, we develop a novel approach that leverages human cognition to
analyze and defend against multi-face deepfake videos. Through a series of
human studies, we systematically examine how people detect deepfake faces in
social settings. Our quantitative analysis reveals four key cues humans rely
on: scene-motion coherence, inter-face appearance compatibility, interpersonal
gaze alignment, and face-body consistency. Guided by these insights, we
introduce \textsf{HICOM}, a novel framework designed to detect every fake face
in multi-face scenarios. Extensive experiments on benchmark datasets show that
\textsf{HICOM} improves average accuracy by 3.3\% in in-dataset detection and
2.8\% under real-world perturbations. Moreover, it outperforms existing methods
by 5.8\% on unseen datasets, demonstrating the generalization of human-inspired
cues. \textsf{HICOM} further enhances interpretability by incorporating an LLM
to provide human-readable explanations, making detection results more
transparent and convincing. Our work sheds light on involving human factors to
enhance defense against deepfakes.

</details>


### [56] [SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models](https://arxiv.org/abs/2507.14811)
*Jiaji Zhang,Ruichao Sun,Hailiang Zhao,Jiaju Wu,Peng Chen,Hao Li,Xinkui Zhao,Kingsum Chow,Gang Xiong,Lin Ye,Shuiguang Deng*

Main category: cs.CV

TL;DR: 本文提出SegQuant量化框架，用于提升扩散模型的推理效率和平衡模型精度，兼容主流部署工具。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然生成能力强，但推理计算量大，难以在受限环境部署。现有PTQ（训练后量化）方法难以泛化或集成到工业流程中，因此需要一种通用高效且易部署的量化方法。

Method: 提出SegQuant框架，包括两个关键技术：一是SegLinear，一种基于图、段感知的量化方式，关注结构语义与空间异质性；二是DualScale量化，能够保持正负激活的不对称性，从而维护生成图片的高质量视觉效果。整个框架无需重新训练数据，兼容预训练模型，适用于多种扩散模型结构。

Result: SegQuant在各类扩散模型上实现了优异的性能表现，同时大幅度降低了模型推理时间与算力消耗，并且无缝支持主流推理部署工具。

Conclusion: SegQuant作为统一量化方案，不仅提升了扩散模型部署的泛用性和效率，也为工业界扩散模型落地提供了可行且易集成的技术路径。

Abstract: Diffusion models have demonstrated exceptional generative capabilities but
are computationally intensive, posing significant challenges for deployment in
resource-constrained or latency-sensitive environments. Quantization offers an
effective means to reduce model size and computational cost, with post-training
quantization (PTQ) being particularly appealing due to its compatibility with
pre-trained models without requiring retraining or training data. However,
existing PTQ methods for diffusion models often rely on architecture-specific
heuristics that limit their generalizability and hinder integration with
industrial deployment pipelines. To address these limitations, we propose
SegQuant, a unified quantization framework that adaptively combines
complementary techniques to enhance cross-model versatility. SegQuant consists
of a segment-aware, graph-based quantization strategy (SegLinear) that captures
structural semantics and spatial heterogeneity, along with a dual-scale
quantization scheme (DualScale) that preserves polarity-asymmetric activations,
which is crucial for maintaining visual fidelity in generated outputs. SegQuant
is broadly applicable beyond Transformer-based diffusion models, achieving
strong performance while ensuring seamless compatibility with mainstream
deployment tools.

</details>


### [57] [FinChart-Bench: Benchmarking Financial Chart Comprehension in Vision-Language Models](https://arxiv.org/abs/2507.14823)
*Dong Shu,Haoyang Yuan,Yuchen Wang,Yanguang Liu,Huopu Zhang,Haiyan Zhao,Mengnan Du*

Main category: cs.CV

TL;DR: 本文提出了首个专注于真实金融图表的FinChart-Bench基准数据集，并评估了25个主流大规模视觉-语言模型（LVLM）在金融图表理解上的能力，发现现有LVLM在该领域仍存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 近年来LVLM在图表理解上有所进展，但对金融图表这一复杂且具有专业术语的领域研究不足。缺乏公开基准 hindered 对模型在此类任务的评测与提升。

Method: 构建了FinChart-Bench数据集，包含1,200张2015-2024期间收集的真实金融图表，每张配备TF、MC与QA类型共7,016道题目。系统评测25个最先进的开源与闭源LVLM，并详细分析其在指令遵循、空间推理等方面的表现。

Result: 评测结果显示：1）开源与闭源模型效果差距缩小；2）同系列升级版表现可能下滑；3）指令遵循性普遍较弱；4）空间推理能力有限；5）当前LVLM不适合作为自动评测器。

Conclusion: 当前主流LVLM在金融图表理解能力有限，存在诸多不足，FinChart-Bench为该方向的研究与模型改进提供了新基准和分析工具。

Abstract: Large vision-language models (LVLMs) have made significant progress in chart
understanding. However, financial charts, characterized by complex temporal
structures and domain-specific terminology, remain notably underexplored. We
introduce FinChart-Bench, the first benchmark specifically focused on
real-world financial charts. FinChart-Bench comprises 1,200 financial chart
images collected from 2015 to 2024, each annotated with True/False (TF),
Multiple Choice (MC), and Question Answering (QA) questions, totaling 7,016
questions. We conduct a comprehensive evaluation of 25 state-of-the-art LVLMs
on FinChart-Bench. Our evaluation reveals critical insights: (1) the
performance gap between open-source and closed-source models is narrowing, (2)
performance degradation occurs in upgraded models within families, (3) many
models struggle with instruction following, (4) both advanced models show
significant limitations in spatial reasoning abilities, and (5) current LVLMs
are not reliable enough to serve as automated evaluators. These findings
highlight important limitations in current LVLM capabilities for financial
chart understanding. The FinChart-Bench dataset is available at
https://huggingface.co/datasets/Tizzzzy/FinChart-Bench.

</details>


### [58] [PHATNet: A Physics-guided Haze Transfer Network for Domain-adaptive Real-world Image Dehazing](https://arxiv.org/abs/2507.14826)
*Fu-Jen Tsai,Yan-Tsung Peng,Yen-Yu Lin,Chia-Wen Lin*

Main category: cs.CV

TL;DR: 本文提出了一种新的图像去雾领域自适应方法PHATNet，通过转移目标域的雾模式到源域无雾图像，提升模型对新环境雾图像的泛化能力，并显著提升主流去雾模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有去雾模型在真实场景中表现有限，主要因为训练数据受限，导致模型在处理未见过的真实雾图时性能大幅下降，亟需提升模型的适应性。

Method: 提出了Physics-guided Haze Transfer Network（PHATNet），通过把未见的目标域雾模式转移到源域无雾图像，生成适应新域的微调训练集。设计了Haze-Transfer-Consistency loss和Content-Leakage Loss来提升雾模式与内容的解耦能力和模型表现。

Result: 实验表明，PHATNet能够显著提升主流SOTA去雾模型在真实世界去雾数据集上的表现，扩展了其实际应用场景。

Conclusion: PHATNet为图像去雾领域提供了一种灵活有效的领域自适应框架，可解决模型在新环境下性能骤降的问题，对提升实际去雾效果具有重要意义。

Abstract: Image dehazing aims to remove unwanted hazy artifacts in images. Although
previous research has collected paired real-world hazy and haze-free images to
improve dehazing models' performance in real-world scenarios, these models
often experience significant performance drops when handling unseen real-world
hazy images due to limited training data. This issue motivates us to develop a
flexible domain adaptation method to enhance dehazing performance during
testing. Observing that predicting haze patterns is generally easier than
recovering clean content, we propose the Physics-guided Haze Transfer Network
(PHATNet) which transfers haze patterns from unseen target domains to
source-domain haze-free images, creating domain-specific fine-tuning sets to
update dehazing models for effective domain adaptation. Additionally, we
introduce a Haze-Transfer-Consistency loss and a Content-Leakage Loss to
enhance PHATNet's disentanglement ability. Experimental results demonstrate
that PHATNet significantly boosts state-of-the-art dehazing models on benchmark
real-world image dehazing datasets.

</details>


### [59] [Paired Image Generation with Diffusion-Guided Diffusion Models](https://arxiv.org/abs/2507.14833)
*Haoxuan Zhang,Wenju Cui,Yuzhu Cao,Tao Tan,Jie Liu,Yunsong Peng,Jian Zheng*

Main category: cs.CV

TL;DR: 该论文提出了一种新的配对数据生成方法，利用扩散模型为乳腺肿块分割任务生成高质量的配对图像和标注，缓解了真实标注数据稀缺的问题，并提升了分割模型的性能。


<details>
  <summary>Details</summary>
Motivation: 乳腺肿块在数字断层合成乳腺X线（DBT）图像中的分割对乳腺癌早筛很重要，但因肿块隐蔽性强，手动标注数据有限，导致分割模型训练受限。现有扩散模型只能生成图像，无法生成配对标注，且在病灶区域的生成质量较差。

Method: 作者提出通过在条件扩散模型中训练额外的扩散引导器，无需外部条件，实现配对图像（DBT切片和肿块掩膜）的自动生成。生成的数据被用于监督模型的训练。

Result: 实验结果表明，该方法能生成高质量配对DBT图像及标注，有效提升下游分割任务性能，并在无外部条件下提升生成质量。

Conclusion: 所提方法可缓解乳腺DBT分析中的标注数据匮乏问题，通过高质量配对数据增强，显著提升了肿块分割的效果。

Abstract: The segmentation of mass lesions in digital breast tomosynthesis (DBT) images
is very significant for the early screening of breast cancer. However, the
high-density breast tissue often leads to high concealment of the mass lesions,
which makes manual annotation difficult and time-consuming. As a result, there
is a lack of annotated data for model training. Diffusion models are commonly
used for data augmentation, but the existing methods face two challenges.
First, due to the high concealment of lesions, it is difficult for the model to
learn the features of the lesion area. This leads to the low generation quality
of the lesion areas, thus limiting the quality of the generated images. Second,
existing methods can only generate images and cannot generate corresponding
annotations, which restricts the usability of the generated images in
supervised training. In this work, we propose a paired image generation method.
The method does not require external conditions and can achieve the generation
of paired images by training an extra diffusion guider for the conditional
diffusion model. During the experimental phase, we generated paired DBT slices
and mass lesion masks. Then, we incorporated them into the supervised training
process of the mass lesion segmentation task. The experimental results show
that our method can improve the generation quality without external conditions.
Moreover, it contributes to alleviating the shortage of annotated data, thus
enhancing the performance of downstream tasks.

</details>


### [60] [Training Self-Supervised Depth Completion Using Sparse Measurements and a Single Image](https://arxiv.org/abs/2507.14845)
*Rizhao Fan,Zhigen Li,Heping Li,Ning An*

Main category: cs.CV

TL;DR: 本文提出了一种无需稠密标签或多帧依赖的全新自监督深度补全方法，利用稀疏深度数据与对应图像训练，并通过创新损失函数及分割特征提升深度估计效果。


<details>
  <summary>Details</summary>
Motivation: 深度补全需将稀疏深度恢复为稠密深度，现有有监督方法依赖昂贵的稠密标签，而自监督方法依赖多帧图像，受限于实际场景应用。因此，亟需开发仅用稀疏深度和单帧图像即可训练的通用方法。

Method: 本方法在训练时仅需稀疏深度测量值和对应的图像，不依赖稠密标签或多帧图像。通过深度分布特性设计新型损失函数，实现已观测点向未观测区域的有效补全，并引入大模型为图像生成的分割图辅助深度估计。

Result: 大量实验验证了所提方法在多项指标上均优于现有方法，证明框架的有效性和泛化能力。

Conclusion: 提出的自监督深度补全方法实用性强、训练代价低，有效解决传统方法对稠密标签和多帧输入的依赖，为实际深度补全任务提供了更具推广性的解决方案。

Abstract: Depth completion is an important vision task, and many efforts have been made
to enhance the quality of depth maps from sparse depth measurements. Despite
significant advances, training these models to recover dense depth from sparse
measurements remains a challenging problem. Supervised learning methods rely on
dense depth labels to predict unobserved regions, while self-supervised
approaches require image sequences to enforce geometric constraints and
photometric consistency between frames. However, acquiring dense annotations is
costly, and multi-frame dependencies limit the applicability of self-supervised
methods in static or single-frame scenarios. To address these challenges, we
propose a novel self-supervised depth completion paradigm that requires only
sparse depth measurements and their corresponding image for training. Unlike
existing methods, our approach eliminates the need for dense depth labels or
additional images captured from neighboring viewpoints. By leveraging the
characteristics of depth distribution, we design novel loss functions that
effectively propagate depth information from observed points to unobserved
regions. Additionally, we incorporate segmentation maps generated by vision
foundation models to further enhance depth estimation. Extensive experiments
demonstrate the effectiveness of our proposed method.

</details>


### [61] [Grounding Degradations in Natural Language for All-In-One Video Restoration](https://arxiv.org/abs/2507.14851)
*Muhammad Kamran Janjua,Amirhosein Ghasemabadi,Kunlin Zhang,Mohammad Salameh,Chao Gao,Di Niu*

Main category: cs.CV

TL;DR: 本文提出了一种全新的视频复原框架，将视频帧的退化信息与自然语言基础模型结合，提升解释性和灵活性，无需已知退化信息即可实现多任务、多退化类型的高效复原，并创建了标准化基准数据集以及新的数据集，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前视频复原方法通常需要在训练或测试时预先知道退化信息，限制了其实用性与泛化能力。此外，现有复原任务缺乏统一的基准和面对真实、复杂退化(如天气变化)的数据集，影响了方法的客观评测和推广。

Method: 作者提出一种基于基础模型的全能视频复原框架，利用自然语言描述退化语境，使模型获得可解释、灵活的指导，并实现推理过程中的模型解耦，无需额外计算开销。同时，建立了3D（三任务）、4D（四任务）以及两种时间变化复合退化基准，其中之一为自建的含动态雪强度模拟天气退化的数据集。

Result: 提出的方法在所设计的所有基准测试上都取得了最新的最优性能，优于现有方法，并验证了在多种退化、多任务和复杂天气条件下的有效性。

Conclusion: 该文提出的全能视频复原方案无需事先退化知识，解释性强，适用性广，在多任务、多退化场景下表现突出，并对今后视频复原领域的基准建设和评测标准化起到推动作用。

Abstract: In this work, we propose an all-in-one video restoration framework that
grounds degradation-aware semantic context of video frames in natural language
via foundation models, offering interpretable and flexible guidance. Unlike
prior art, our method assumes no degradation knowledge in train or test time
and learns an approximation to the grounded knowledge such that the foundation
model can be safely disentangled during inference adding no extra cost.
Further, we call for standardization of benchmarks in all-in-one video
restoration, and propose two benchmarks in multi-degradation setting,
three-task (3D) and four-task (4D), and two time-varying composite degradation
benchmarks; one of the latter being our proposed dataset with varying snow
intensity, simulating how weather degradations affect videos naturally. We
compare our method with prior works and report state-of-the-art performance on
all benchmarks.

</details>


### [62] [An Uncertainty-aware DETR Enhancement Framework for Object Detection](https://arxiv.org/abs/2507.14855)
*Xingshu Chen,Sicheng Yu,Chong Cheng,Hao Wang,Ting Tian*

Main category: cs.CV

TL;DR: 本文提出了一个用于DETR目标检测器的不确定性感知增强框架，在COCO和白细胞检测任务上都取得了优异效果。


<details>
  <summary>Details</summary>
Motivation: 现有目标检测方法在边界框定位准确性上存在提升空间，并且往往忽略了预测的不确定性，导致模型鲁棒性受限。作者希望提升定位精度并建模预测的不确定性。

Method: 作者将边界框建模为多元高斯分布，并将Gromov-Wasserstein距离引入损失函数，提升预测分布与真实分布的对齐程度。同时，基于贝叶斯风险过滤高风险信息，并设计了一个简单的算法用置信区间量化定位不确定性。

Result: 方法能够有效整合进现有DETR变体，在COCO数据集上提升性能，并在白细胞检测（LISC和WBCDD数据集）任务中取得了SOTA结果。

Conclusion: 提出的框架不仅提升了目标检测定位及不确定性建模能力，在通用和特定领域检测任务上都表现出良好扩展性和有效性。

Abstract: This paper investigates the problem of object detection with a focus on
improving both the localization accuracy of bounding boxes and explicitly
modeling prediction uncertainty. Conventional detectors rely on deterministic
bounding box regression, ignoring uncertainty in predictions and limiting model
robustness. In this paper, we propose an uncertainty-aware enhancement
framework for DETR-based object detectors. We model bounding boxes as
multivariate Gaussian distributions and incorporate the Gromov-Wasserstein
distance into the loss function to better align the predicted and ground-truth
distributions. Building on this, we derive a Bayes Risk formulation to filter
high-risk information and improve detection reliability. We also propose a
simple algorithm to quantify localization uncertainty via confidence intervals.
Experiments on the COCO benchmark show that our method can be effectively
integrated into existing DETR variants, enhancing their performance. We further
extend our framework to leukocyte detection tasks, achieving state-of-the-art
results on the LISC and WBCDD datasets. These results confirm the scalability
of our framework across both general and domain-specific detection tasks. Code
page:
https://github.com/ParadiseforAndaChen/An-Uncertainty-aware-DETR-Enhancement-Framework-for-Object-Detection.

</details>


### [63] [Hybrid-supervised Hypergraph-enhanced Transformer for Micro-gesture Based Emotion Recognition](https://arxiv.org/abs/2507.14867)
*Zhaoqiang Xia,Hexiang Huang,Haoyu Chen,Xiaoyi Feng,Guoying Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种基于微手势识别情绪状态的新方法，结合超图增强的Transformer与混合监督框架进行行为模式重建和情绪识别，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 微手势是人们无意识做出的身体动作，能传达情绪状态。以往对基于微手势的人体情绪建模研究有限，因此有必要探索更有效的识别与建模方法。

Method: 提出采用超图增强的Transformer架构，构建编码器和解码器，结合自监督行为重建和监督的情绪识别任务。解码器特别设计了上采样操作以更好捕捉微手势细微动作，超图增强自注意力动态建模关节关系，最终情绪识别头以浅层结构输出情绪类别，实现端到端联合混合训练。

Result: 该方法在iMiGUE和SMG两个公开微手势数据集上进行评测，在多个指标下均取得最佳性能，超过现有相关方法。

Conclusion: 采用超图增强Transformer的混合监督方法能更有效建模和识别基于微手势的情绪状态，为人类行为理解和情感计算领域提供了新方向和技术方案。

Abstract: Micro-gestures are unconsciously performed body gestures that can convey the
emotion states of humans and start to attract more research attention in the
fields of human behavior understanding and affective computing as an emerging
topic. However, the modeling of human emotion based on micro-gestures has not
been explored sufficiently. In this work, we propose to recognize the emotion
states based on the micro-gestures by reconstructing the behavior patterns with
a hypergraph-enhanced Transformer in a hybrid-supervised framework. In the
framework, hypergraph Transformer based encoder and decoder are separately
designed by stacking the hypergraph-enhanced self-attention and multiscale
temporal convolution modules. Especially, to better capture the subtle motion
of micro-gestures, we construct a decoder with additional upsampling operations
for a reconstruction task in a self-supervised learning manner. We further
propose a hypergraph-enhanced self-attention module where the hyperedges
between skeleton joints are gradually updated to present the relationships of
body joints for modeling the subtle local motion. Lastly, for exploiting the
relationship between the emotion states and local motion of micro-gestures, an
emotion recognition head from the output of encoder is designed with a shallow
architecture and learned in a supervised way. The end-to-end framework is
jointly trained in a one-stage way by comprehensively utilizing
self-reconstruction and supervision information. The proposed method is
evaluated on two publicly available datasets, namely iMiGUE and SMG, and
achieves the best performance under multiple metrics, which is superior to the
existing methods.

</details>


### [64] [Region-aware Depth Scale Adaptation with Sparse Measurements](https://arxiv.org/abs/2507.14879)
*Rizhao Fan,Tianfang Ma,Zhigen Li,Ning An,Jian Cheng*

Main category: cs.CV

TL;DR: 本文提出了一种无需再训练、无需微调，只利用稀疏深度测量即可将基础深度预测模型的相对深度输出适配为绝对（米制）深度的方法。


<details>
  <summary>Details</summary>
Motivation: 基础深度预测模型虽然在零样本单目深度估计上有重大进展，但输出为相对深度，难以直接应用于实际场景。而现有的尺度适配方法需要再训练，代价高，且会影响模型泛化能力。

Method: 提出一种基于稀疏深度测量的、非学习型的尺度适配方法。该方法通过少量的实际深度采样，将模型输出的相对深度变换为绝对深度，无需新数据再训练或模型微调。

Result: 实验结果表明，该方法能够有效将基础模型的相对尺度深度转化为米制尺度，且不增加计算成本也不损失原有模型泛化能力。

Conclusion: 本文方法为基础深度模型在实际应用中输出米制深度提供了有效途径，有望推动深度估计在更多真实场景中的落地应用。

Abstract: In recent years, the emergence of foundation models for depth prediction has
led to remarkable progress, particularly in zero-shot monocular depth
estimation. These models generate impressive depth predictions; however, their
outputs are often in relative scale rather than metric scale. This limitation
poses challenges for direct deployment in real-world applications. To address
this, several scale adaptation methods have been proposed to enable foundation
models to produce metric depth. However, these methods are typically costly, as
they require additional training on new domains and datasets. Moreover,
fine-tuning these models often compromises their original generalization
capabilities, limiting their adaptability across diverse scenes. In this paper,
we introduce a non-learning-based approach that leverages sparse depth
measurements to adapt the relative-scale predictions of foundation models into
metric-scale depth. Our method requires neither retraining nor fine-tuning,
thereby preserving the strong generalization ability of the original foundation
models while enabling them to produce metric depth. Experimental results
demonstrate the effectiveness of our approach, high-lighting its potential to
bridge the gap between relative and metric depth without incurring additional
computational costs or sacrificing generalization ability.

</details>


### [65] [BeatFormer: Efficient motion-robust remote heart rate estimation through unsupervised spectral zoomed attention filters](https://arxiv.org/abs/2507.14885)
*Joaquim Comas,Federico Sukno*

Main category: cs.CV

TL;DR: 该论文提出了一种名为BeatFormer的高效rPPG（远程光体积描记）估算模型，结合了频谱注意力机制和光谱对比学习，实现了无需标签的训练，并在多个数据集上表现出色，尤其在含有运动的跨数据集场景中表现突出。


<details>
  <summary>Details</summary>
Motivation: 深度学习方法虽然在rPPG估算上取得了进展，但依赖大量多样性数据集才能实现良好泛化能力，且计算资源消耗大。而传统手工特征方法虽然依靠生理先验，计算高效且泛化能力好，但在复杂场景下（如运动）表现有限。两者各有优劣，急需一种能够融合两者优点的混合方法。

Method: 作者提出了BeatFormer，一种基于频谱注意力的轻量级模型。该模型创新性地整合了变焦正交复数注意力机制和频域能量测量，提高了模型的效率。此外，作者提出了光谱对比学习（SCL）方法，使模型在无PPG或HR标签的情况下也能进行训练。

Result: BeatFormer在PURE、UBFC-rPPG和MMPD等多个公开数据集上进行了验证。实验结果显示，BeatFormer在跨数据集及运动场景下具有良好的鲁棒性和性能，相比传统和深度学习方法均表现优越。

Conclusion: BeatFormer作为一种融合频谱注意力机制和光谱无监督学习的新型rPPG估算模型，兼具高效率与良好的泛化能力，能够应对实际应用中的多样性和运动、光照等复杂干扰，对未来rPPG相关研究和应用具有重要参考价值。

Abstract: Remote photoplethysmography (rPPG) captures cardiac signals from facial
videos and is gaining attention for its diverse applications. While deep
learning has advanced rPPG estimation, it relies on large, diverse datasets for
effective generalization. In contrast, handcrafted methods utilize
physiological priors for better generalization in unseen scenarios like motion
while maintaining computational efficiency. However, their linear assumptions
limit performance in complex conditions, where deep learning provides superior
pulsatile information extraction. This highlights the need for hybrid
approaches that combine the strengths of both methods. To address this, we
present BeatFormer, a lightweight spectral attention model for rPPG estimation,
which integrates zoomed orthonormal complex attention and frequency-domain
energy measurement, enabling a highly efficient model. Additionally, we
introduce Spectral Contrastive Learning (SCL), which allows BeatFormer to be
trained without any PPG or HR labels. We validate BeatFormer on the PURE,
UBFC-rPPG, and MMPD datasets, demonstrating its robustness and performance,
particularly in cross-dataset evaluations under motion scenarios.

</details>


### [66] [TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D Visual Grounding based on CLIP](https://arxiv.org/abs/2507.14904)
*Fan Li,Zanyi Wang,Zeyi Huang,Guang Dai,Jingdong Wang,Mengmeng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种统一的2D预训练多模态网络，实现了RGB图像、文本和3D点云的高效三模态处理，显著简化模型结构，并在3D视觉定位任务中超过现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有3D视觉定位方法往往为不同模态分别设计编码器（如RGB图像、文本和点云），导致模型庞大、训练效率低。即使部分方法使用2D多模态预训练模型，如CLIP，但在处理点云与2D编码器时仍需引入3D编码器，增加复杂度。因此，迫切需要一种简化架构、提高训练效率的方法。

Method: 作者提出以2D预训练多模态网络为基础，通过adapter微调机制，将2D CLIP双模态模型适配为三模态（RGB、文本、点云）。提出GARF模块，能够融合来自点云与图像的几何多尺度特征，并与文本特征进行最终融合，利用多模态解码器实现深度跨模态理解，形成端到端的3D视觉定位模型。

Result: 与基线方法相比，该模型参数量减少约58%，3D检测任务准确率提升6.52%，3D视觉定位任务表现提升6.25%。

Conclusion: 该方法显著降低了模型复杂度和训练参数量，并提升了3D视觉定位和检测任务的性能，为统一高效的三模态视觉理解提供了有效方案。

Abstract: 3D visual grounding allows an embodied agent to understand visual information
in real-world 3D environments based on human instructions, which is crucial for
embodied intelligence. Existing 3D visual grounding methods typically rely on
separate encoders for different modalities (e.g., RGB images, text, and 3D
point clouds), resulting in large and complex models that are inefficient to
train. While some approaches use pre-trained 2D multi-modal models like CLIP
for 3D tasks, they still struggle with aligning point cloud data to 2D
encoders. As a result, these methods continue to depend on 3D encoders for
feature extraction, further increasing model complexity and training
inefficiency. In this paper, we propose a unified 2D pre-trained multi-modal
network to process all three modalities (RGB images, text, and point clouds),
significantly simplifying the architecture. By leveraging a 2D CLIP bi-modal
model with adapter-based fine-tuning, this framework effectively adapts to the
tri-modal setting, improving both adaptability and performance across
modalities. Our Geometric-Aware 2D-3D Feature Recovery and Fusion (GARF) module
is designed to fuse geometric multi-scale features from point clouds and
images. We then integrate textual features for final modality fusion and
introduce a multi-modal decoder to facilitate deep cross-modal understanding.
Together, our method achieves unified feature extraction and fusion across the
three modalities, enabling an end-to-end 3D visual grounding model. Compared to
the baseline, our method reduces the number of trainable parameters by
approximately 58\%, while achieving a 6.52\% improvement in the 3D detection
task and a 6.25\% improvement in the 3D visual grounding task.

</details>


### [67] [Semantic-Aware Representation Learning for Multi-label Image Classification](https://arxiv.org/abs/2507.14918)
*Ren-Dong Xie,Zhi-Fen He,Bo Li,Bin Liu,Jin-Yan Hu*

Main category: cs.CV

TL;DR: 本文提出了一种面向多标签图像分类的语义感知表征学习方法（SARL），提升了图像表征的鲁棒性和分类性能，在PASCAL VOC 2007和MS-COCO数据集上超过了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于注意力机制或图卷积网络（GCN）的方法在多标签图像分类中生成的图像表征容易包含噪声，且定位目标不精确，导致分类效果受限。

Method: SARL方法包含三大模块：1）标签语义相关特征学习模块，用于提取图像中与标签相关的语义特征；2）基于最优传输的注意力机制，实现语义对齐的图像表征；3）区域分数聚合策略，用于多标签预测。

Result: 实验在PASCAL VOC 2007与MS-COCO两个基准数据集上进行，结果显示SARL在多项评价指标上优于现有主流方法。

Conclusion: SARL方法能有效提升多标签图像分类的表征能力和分类性能，具有应用前景。

Abstract: Multi-label image classification, an important research area in computer
vision, focuses on identifying multiple labels or concepts within an image.
Existing approaches often employ attention mechanisms or graph convolutional
networks (GCNs) to learn image representation. However, this representation may
contain noise and may not locate objects precisely. Therefore, this paper
proposes a Semantic-Aware Representation Learning (SARL) for multi-label image
classification. First, a label semantic-related feature learning module is
utilized to extract semantic-related features. Then, an optimal transport-based
attention mechanism is designed to obtain semantically aligned image
representation. Finally, a regional score aggregation strategy is used for
multi-label prediction. Experimental results on two benchmark datasets, PASCAL
VOC 2007 and MS-COCO, demonstrate the superiority of SARL over existing
methods.

</details>


### [68] [Stereo-GS: Multi-View Stereo Vision Model for Generalizable 3D Gaussian Splatting Reconstruction](https://arxiv.org/abs/2507.14921)
*Xiufeng Huang,Ka Chun Cheung,Runmin Cong,Simon See,Renjie Wan*

Main category: cs.CV

TL;DR: 该论文提出了一种高效的图像到3D高斯体重建的新方法，能够在资源消耗更少的情况下生成高质量3D内容，并且无需相机位姿参数。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯体重建方法需要大量算力和数据，并且训练依赖相机参数，映射速度慢，泛化能力不足。

Method: 作者设计了一个解耦架构，分别处理3D几何和外观信息。方法基于立体视觉，从局部图像对中提取特征后用全局注意力块融合，再分别利用特定的点和高斯预测Head生成几何点图和高斯特征，并通过一个精化网络提升重建质量。

Result: 该方法相较于依赖相机参数的传统方法，实现了免姿态高质量3D重建，并显著降低了对算力和数据的需求。

Conclusion: 提出的方法提升了3D高斯体重建泛化性和实际可用性，在资源有限及实际应用场景下表现优异，是高效可扩展的3D内容生成解决方案。

Abstract: Generalizable 3D Gaussian Splatting reconstruction showcases advanced
Image-to-3D content creation but requires substantial computational resources
and large datasets, posing challenges to training models from scratch. Current
methods usually entangle the prediction of 3D Gaussian geometry and appearance,
which rely heavily on data-driven priors and result in slow regression speeds.
To address this, we propose \method, a disentangled framework for efficient 3D
Gaussian prediction. Our method extracts features from local image pairs using
a stereo vision backbone and fuses them via global attention blocks. Dedicated
point and Gaussian prediction heads generate multi-view point-maps for geometry
and Gaussian features for appearance, combined as GS-maps to represent the 3DGS
object. A refinement network enhances these GS-maps for high-quality
reconstruction. Unlike existing methods that depend on camera parameters, our
approach achieves pose-free 3D reconstruction, improving robustness and
practicality. By reducing resource demands while maintaining high-quality
outputs, \method provides an efficient, scalable solution for real-world 3D
content generation.

</details>


### [69] [3-Dimensional CryoEM Pose Estimation and Shift Correction Pipeline](https://arxiv.org/abs/2507.14924)
*Kaishva Chintan Shah,Virajith Boddapati,Karthik S. Gurumoorthy,Sandip Kaledhonkar,Ajit Rajwade*

Main category: cs.CV

TL;DR: 本文针对cryo-EM中由于极低信噪比（SNR）导致的姿态估计和漂移校正难题，提出基于多维尺度分析（MDS）的稳健姿态估计方法，有效提升三维重建精度。


<details>
  <summary>Details</summary>
Motivation: 冷冻电镜（cryo-EM）中三维重建高度依赖单颗粒的准确姿态估计与位移校正，但极低的图像信噪比导致传统方法误差大、重建效果不佳。为提升重建质量，需要更稳健的估计手段。

Method: 作者提出利用多维尺度分析，结合共线理论，将旋转矩阵参数化为旋转轴和正交单位向量，并提出两大创新：（1）基于$\ell_1$-范数的稳健联合优化，实现旋转轴和面内向量的同时最优化，通过投影坐标下降精确施加单位范数和正交性约束；（2）基于全局最小二乘的迭代漂移校正，获得一致的面内位移。

Result: 新方法在Euler角度精度与三维重建的Fourier Shell Correlation（FSC）指标上，均较以往方法取得更优成绩，特别是在低信噪比条件下表现突出。

Conclusion: 论文所提出的整体优化流程在姿态估计和漂移校正上显著优于以往$\ell_2$-范数和顺序流程的方法，为低SNR条件下cryo-EM三维重建提供了更高可靠性的解决方案。

Abstract: Accurate pose estimation and shift correction are key challenges in cryo-EM
due to the very low SNR, which directly impacts the fidelity of 3D
reconstructions. We present an approach for pose estimation in cryo-EM that
leverages multi-dimensional scaling (MDS) techniques in a robust manner to
estimate the 3D rotation matrix of each particle from pairs of dihedral angles.
We express the rotation matrix in the form of an axis of rotation and a unit
vector in the plane perpendicular to the axis. The technique leverages the
concept of common lines in 3D reconstruction from projections. However, common
line estimation is ridden with large errors due to the very low SNR of cryo-EM
projection images. To address this challenge, we introduce two complementary
components: (i) a robust joint optimization framework for pose estimation based
on an $\ell_1$-norm objective or a similar robust norm, which simultaneously
estimates rotation axes and in-plane vectors while exactly enforcing unit norm
and orthogonality constraints via projected coordinate descent; and (ii) an
iterative shift correction algorithm that estimates consistent in-plane
translations through a global least-squares formulation. While prior approaches
have leveraged such embeddings and common-line geometry for orientation
recovery, existing formulations typically rely on $\ell_2$-based objectives
that are sensitive to noise, and enforce geometric constraints only
approximately. These choices, combined with a sequential pipeline structure,
can lead to compounding errors and suboptimal reconstructions in low-SNR
regimes. Our pipeline consistently outperforms prior methods in both Euler
angle accuracy and reconstruction fidelity, as measured by the Fourier Shell
Correlation (FSC).

</details>


### [70] [Probabilistic smooth attention for deep multiple instance learning in medical imaging](https://arxiv.org/abs/2507.14932)
*Francisco M. Castro-Macías,Pablo Morales-Álvarez,Yunan Wu,Rafael Molina,Aggelos K. Katsaggelos*

Main category: cs.CV

TL;DR: 本文提出了一种新的概率型多实例学习(MIL)框架，用于医学影像分类任务，通过对attention机制加以概率建模，提升了模型性能及可解释性，并在多个数据集和基线方法下验证了优越性。


<details>
  <summary>Details</summary>
Motivation: 医学影像分类通常缺乏精确标注，传统MIL方法依赖于包（bag）标签而不是实例标签。但现有Deep MIL方法中的attention机制为确定性，无法反映每个实例贡献的不确定性，可能影响全局和局部信息聚合的效果。为解决此问题，需要引入考虑不确定性的模型，为医学场景提供更合理的解读。

Method: 提出了一种概率性attention机制的MIL方法，对attention值建模概率分布，融合全局与局部实例间的交互。此外，该方法在三个医学数据集与11种先进基线上进行综合性能评估。

Result: 本文方法在不同评价指标下均取得最优性能，对比了11个主流基线方法，并通过三个医学影像数据集进行了充分实验验证。方法不仅提高分类准确性，还能生成可解释的不确定性可视化图用于疾病定位。

Conclusion: 概率性attention机制的MIL框架在医学图像分类任务中提升了预测性能和模型解释性，特别适用于实例贡献不确定性的场景。实验表明该方法具备较强的实用性和推广潜力。

Abstract: The Multiple Instance Learning (MIL) paradigm is attracting plenty of
attention in medical imaging classification, where labeled data is scarce. MIL
methods cast medical images as bags of instances (e.g. patches in whole slide
images, or slices in CT scans), and only bag labels are required for training.
Deep MIL approaches have obtained promising results by aggregating
instance-level representations via an attention mechanism to compute the
bag-level prediction. These methods typically capture both local interactions
among adjacent instances and global, long-range dependencies through various
mechanisms. However, they treat attention values deterministically, potentially
overlooking uncertainty in the contribution of individual instances. In this
work we propose a novel probabilistic framework that estimates a probability
distribution over the attention values, and accounts for both global and local
interactions. In a comprehensive evaluation involving {\color{review} eleven}
state-of-the-art baselines and three medical datasets, we show that our
approach achieves top predictive performance in different metrics. Moreover,
the probabilistic treatment of the attention provides uncertainty maps that are
interpretable in terms of illness localization.

</details>


### [71] [Open-set Cross Modal Generalization via Multimodal Unified Representation](https://arxiv.org/abs/2507.14935)
*Hai Huang,Yan Xia,Shulei Wang,Hanting Wang,Minghui Fang,Shengpeng Ji,Sashuai Zhou,Tao Jin,Zhou Zhao*

Main category: cs.CV

TL;DR: 本文提出了开放集跨模态泛化（OSCMG）任务，并提出了MICU方法以提升开放环境下的多模态统一表示能力。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态泛化工作主要在封闭集（closed-set）场景下展开，无法应对实际应用中的开放集（open-set）挑战。例如模型需面对新模态中新类别，需具备识别未知类别并完成知识迁移的能力。为克服现有局限，本文提出需支持开放集条件下的多模态泛化。

Method: 提出MICU方法，包含两个关键模块：Fine-Coarse Masked multimodal InfoNCE（FCMI）及Cross modal Unified Jigsaw Puzzles（CUJP）。FCMI结合粗细粒度的掩码对比学习以提升模态对齐与泛化能力。CUJP通过模态无关特征选择结合自监督学习，丰富特征与提升模型对未知类别的适应能力。

Result: 在传统CMG任务与新提出的OSCMG任务上进行了大量实验，实验证明所提方法在跨模态泛化及开放集适应性上优于现有方法。

Conclusion: 提出的OSCMG任务更贴近现实应用需求，MICU方法有效提升了开放集环境下多模态统一表示的泛化能力。

Abstract: This paper extends Cross Modal Generalization (CMG) to open-set environments
by proposing the more challenging Open-set Cross Modal Generalization (OSCMG)
task. This task evaluates multimodal unified representations in open-set
conditions, addressing the limitations of prior closed-set cross-modal
evaluations. OSCMG requires not only cross-modal knowledge transfer but also
robust generalization to unseen classes within new modalities, a scenario
frequently encountered in real-world applications. Existing multimodal unified
representation work lacks consideration for open-set environments. To tackle
this, we propose MICU, comprising two key components: Fine-Coarse Masked
multimodal InfoNCE (FCMI) and Cross modal Unified Jigsaw Puzzles (CUJP). FCMI
enhances multimodal alignment by applying contrastive learning at both holistic
semantic and temporal levels, incorporating masking to enhance generalization.
CUJP enhances feature diversity and model uncertainty by integrating
modality-agnostic feature selection with self-supervised learning, thereby
strengthening the model's ability to handle unknown categories in open-set
tasks. Extensive experiments on CMG and the newly proposed OSCMG validate the
effectiveness of our approach. The code is available at
https://github.com/haihuangcode/CMG.

</details>


### [72] [Polymorph: Energy-Efficient Multi-Label Classification for Video Streams on Embedded Devices](https://arxiv.org/abs/2507.14959)
*Saeid Ghafouri,Mohsen Fayyaz,Xiangchen Li,Deepu John,Bo Ji,Dimitrios Nikolopoulos,Hans Vandierendonck*

Main category: cs.CV

TL;DR: 提出了Polymorph框架，通过激活最小数量的低秩适配器（LoRA），实现嵌入式设备上高效的实时多标签视频分类，同时大幅降低能耗并提升准确率。


<details>
  <summary>Details</summary>
Motivation: 嵌入式设备在实时视频多标签分类任务中受到计算和能耗的限制，而视频流本身存在标签稀疏、时序连续和标签共现等结构性特征，但现有方法未能充分利用这些特性以提升推理效率。

Method: Polymorph框架为每帧输入动态选择并组合少量基于标签共现关系专门化的LoRA适配器，每个适配器负责一部分类别的判别。这些适配器作为权重叠加在共享的主干网络上，避免了全模型切换和权重合并带来的开销，实现了高效的模块化推理。

Result: 在TAO数据集上，Polymorph相较先进基线降低了40%的能耗，平均精度（mAP）提升了9个百分点。

Conclusion: 通过充分利用视频结构性特征和模块化适配器机制，Polymorph显著提升了嵌入式设备上的多标签视频分类性能和能效，具有良好可扩展性和实际应用价值。

Abstract: Real-time multi-label video classification on embedded devices is constrained
by limited compute and energy budgets. Yet, video streams exhibit structural
properties such as label sparsity, temporal continuity, and label co-occurrence
that can be leveraged for more efficient inference. We introduce Polymorph, a
context-aware framework that activates a minimal set of lightweight Low Rank
Adapters (LoRA) per frame. Each adapter specializes in a subset of classes
derived from co-occurrence patterns and is implemented as a LoRA weight over a
shared backbone. At runtime, Polymorph dynamically selects and composes only
the adapters needed to cover the active labels, avoiding full-model switching
and weight merging. This modular strategy improves scalability while reducing
latency and energy overhead. Polymorph achieves 40% lower energy consumption
and improves mAP by 9 points over strong baselines on the TAO dataset.
Polymorph is open source at https://github.com/inference-serving/polymorph/.

</details>


### [73] [Decision PCR: Decision version of the Point Cloud Registration task](https://arxiv.org/abs/2507.14965)
*Yaojie Zhang,Tianlun Huang,Weijun Wang,Wei Feng*

Main category: cs.CV

TL;DR: 本文提出了一种基于深度学习的低重叠点云配准评估方法，有效提升了现有方法在低内点率场景下的配准效果。


<details>
  <summary>Details</summary>
Motivation: 在三维视觉任务中，低重叠点云配准难度极大，传统评估指标（如最大内点数）在极低内点率场景下已不再有效，因此亟需新的评估方法。

Method: 作者将点云配准（PCR）的评估任务形式化为决策问题（Decision PCR），基于3DMatch数据集构建相应数据集，用深度学习分类器对配准质量进行判断，并嵌入常规PCR流水线，实现端到端优化。

Result: 所提方法与主流PCR方法结合后，在3DLoMatch基准上配准召回率达到86.97%，表现优于以往方法。在ETH等新场景下也表现出很好的泛化性。

Conclusion: 基于深度学习的决策型配准质量评估器能有效提升点云配准的最终效果，尤其适用于低重叠场景，在多种数据集上表现优异，具备实际应用价值。

Abstract: Low-overlap point cloud registration (PCR) remains a significant challenge in
3D vision. Traditional evaluation metrics, such as Maximum Inlier Count, become
ineffective under extremely low inlier ratios. In this paper, we revisit the
registration result evaluation problem and identify the Decision version of the
PCR task as the fundamental problem. To address this Decision PCR task, we
propose a data-driven approach. First, we construct a corresponding dataset
based on the 3DMatch dataset. Then, a deep learning-based classifier is trained
to reliably assess registration quality, overcoming the limitations of
traditional metrics. To our knowledge, this is the first comprehensive study to
address this task through a deep learning framework. We incorporate this
classifier into standard PCR pipelines. When integrated with our approach,
existing state-of-the-art PCR methods exhibit significantly enhanced
registration performance. For example, combining our framework with
GeoTransformer achieves a new SOTA registration recall of 86.97\% on the
challenging 3DLoMatch benchmark. Our method also demonstrates strong
generalization capabilities on the unseen outdoor ETH dataset.

</details>


### [74] [Hierarchical Cross-modal Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2507.14976)
*Hao Zheng,Shunzhi Yang,Zhuoxin He,Jinfeng Yang,Zhenhua Huang*

Main category: cs.CV

TL;DR: 本文提出了HiCroPL框架，通过层次化跨模态Prompt学习，改进了预训练视觉-语言模型（如CLIP）在下游任务的泛化能力，实现了在多个任务和基准上的新SOTA。


<details>
  <summary>Details</summary>
Motivation: 当前主流的视觉-语言预训练模型在适应下游任务时，常常会丢失泛化能力，现有的Prompt学习方法也存在模态隔离和语义递减等问题，阻碍了模型表现的进一步提升。

Method: 提出HiCroPL（Hierarchical Cross-modal Prompt Learning）框架，建立文本和视觉模态的双向知识流。利用层级知识映射器，将文本的清晰语义注入视觉prompt，优化早期层的表征；而后续层中，视觉prompt则反哺文本prompt，实现更深层的跨模态对齐。引入轻量级的层特定知识代理，提升跨模态交互效率。

Result: 在四项任务的广泛评测中，HiCroPL在11个基准上取得了新的SOTA成绩，表现优异且提升显著。

Conclusion: HiCroPL有效克服了跨模态Prompt学习中存在的模态隔离和语义衰减难题，实现了语义互补和多层语义融合，显著提升了大规模视觉-语言模型的适应性与泛化能力。

Abstract: Pre-trained Vision-Language Models (VLMs) such as CLIP have shown excellent
generalization abilities. However, adapting these large-scale models to
downstream tasks while preserving their generalization capabilities remains
challenging. Although prompt learning methods have shown promise, they suffer
from two fundamental bottlenecks that limit generalization: (a) modality
isolation, and (b) hierarchical semantic decay. To address these limitations,
we propose HiCroPL, a Hierarchical Cross-modal Prompt Learning framework that
establishes bidirectional knowledge flow between text and vision modalities,
enabling them to refine their semantics mutually. HiCroPL routes knowledge
flows by leveraging the complementary strengths of text and vision. In early
layers, text prompts inject relatively clear semantics into visual prompts
through a hierarchical knowledge mapper, enhancing the representation of
low-level visual semantics. In later layers, visual prompts encoding specific
task-relevant objects flow back to refine text prompts, enabling deeper
alignment. Crucially, our hierarchical knowledge mapper allows representations
at multi-scales to be fused, ensuring that deeper representations retain
transferable shallow semantics thereby enhancing generalization. We further
introduce a lightweight layer-specific knowledge proxy to enable efficient
cross-modal interactions. Extensive evaluations across four tasks demonstrate
HiCroPL's superior performance, achieving state-of-the-art results on 11
benchmarks with significant improvements. Code is available at:
https://github.com/zzeoZheng/HiCroPL.

</details>


### [75] [Language Integration in Fine-Tuning Multimodal Large Language Models for Image-Based Regression](https://arxiv.org/abs/2507.14997)
*Roy H. Jennings,Genady Paikin,Roy Shaul,Evgeny Soloveichik*

Main category: cs.CV

TL;DR: 该论文针对多模态大语言模型（MLLMs）在基于图像的回归任务中的局限性提出新方法，不仅提升了性能，还强调了语义丰富的文本输入的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs方法主要通过预设输出词汇和通用任务提示词来微调模型，但这样做并未有效利用文本输入带来的语义理解，性能未优于仅基于图像的训练。

Method: 提出了基于Transformer的回归分类方法（RvTC），用灵活的分箱方法取代了受限词汇的分类。RvTC通过增加分箱数量消除了手动设计输出词表的需求。同时创新地引入了“数据特定型任务提示词”，将与特定图像相关的语义信息融入提示中，充分利用跨模态理解能力。

Result: RvTC方法在四个图像评估数据集上仅用图像输入已取得SOTA性能。更重要的是，数据特定型提示词极大地提升了模型性能，在AVA数据集上相关性从0.83提升至0.90，达新SOTA。实验证明MLLM确实能利用语义丰富的提示词获得优于统计偏置的信息。

Conclusion: 本研究表明，MLLMs在回归任务中必须结合有意义的文本上下文（如含有语义的特定任务提示词），才能真正发挥跨模态理解优势。结合RvTC架构及语义型提示能显著提升MLLM的回归表现。

Abstract: Multimodal Large Language Models (MLLMs) show promise for image-based
regression tasks, but current approaches face key limitations. Recent methods
fine-tune MLLMs using preset output vocabularies and generic task-level prompts
(e.g., "How would you rate this image?"), assuming this mimics human rating
behavior. Our analysis reveals these approaches provide no benefit over
image-only training. Models using preset vocabularies and generic prompts
perform equivalently to image-only models, failing to leverage semantic
understanding from textual input. We propose Regression via Transformer-Based
Classification (RvTC), which replaces vocabulary-constrained classification
with a flexible bin-based approach. Unlike approaches that address
discretization errors through complex distributional modeling, RvTC eliminates
manual vocabulary crafting through straightforward bin increase, achieving
state-of-the-art performance on four image assessment datasets using only
images. More importantly, we demonstrate that data-specific prompts
dramatically improve performance. Unlike generic task descriptions, prompts
containing semantic information about specific images enable MLLMs to leverage
cross-modal understanding. On the AVA dataset, adding challenge titles to
prompts improves correlations from 0.83 to 0.90, a new state-of-the-art. We
demonstrate through empirical evidence from the AVA and AGIQA-3k datasets that
MLLMs benefit from semantic prompt information surpassing mere statistical
biases. This underscores the importance of incorporating meaningful textual
context in multimodal regression tasks.

</details>


### [76] [Axis-Aligned Document Dewarping](https://arxiv.org/abs/2507.15000)
*Chaoyun Wang,I-Chao Shen,Takeo Igarashi,Nanning Zheng,Caigui Jiang*

Main category: cs.CV

TL;DR: 本文提出了一种结合轴对齐几何约束的方法提升文档去卷曲（dewarping）效果，并在多个基准测试中取得了SOTA表现，特别是在新提出的轴对齐畸变（AAD）指标上显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的学习型文档去卷曲方法主要依赖标注数据进行监督回归，未充分利用文档去卷曲过程中的几何属性。作者希望通过引入几何约束进一步提升模型性能和泛化能力。

Method: 在训练阶段，提出了轴对齐的几何约束来加强去卷曲能力；在推理阶段，加入了轴对齐预处理策略以降低去卷曲难度；在评估阶段，提出了一种结合几何意义且更符合人类视觉感知的新指标AAD。

Result: 提出的方法在多个公开基准测试上取得最优（SOTA）结果，并在AAD指标上实现了18.2%~34.5%的提升。

Conclusion: 结合轴对齐几何约束和提出的AAD评价标准，有效提升了文档去卷曲的效果，并使结果更符合人类视觉判断，具有较强的实用价值。

Abstract: Document dewarping is crucial for many applications. However, existing
learning-based methods primarily rely on supervised regression with annotated
data without leveraging the inherent geometric properties in physical documents
to the dewarping process. Our key insight is that a well-dewarped document is
characterized by transforming distorted feature lines into axis-aligned ones.
This property aligns with the inherent axis-aligned nature of the discrete grid
geometry in planar documents. In the training phase, we propose an axis-aligned
geometric constraint to enhance document dewarping. In the inference phase, we
propose an axis alignment preprocessing strategy to reduce the dewarping
difficulty. In the evaluation phase, we introduce a new metric, Axis-Aligned
Distortion (AAD), that not only incorporates geometric meaning and aligns with
human visual perception but also demonstrates greater robustness. As a result,
our method achieves SOTA results on multiple existing benchmarks and achieves
18.2%~34.5% improvements on the AAD metric.

</details>


### [77] [FastSmoothSAM: A Fast Smooth Method For Segment Anything Model](https://arxiv.org/abs/2507.15008)
*Jiasheng Xu,Yewang Chen*

Main category: cs.CV

TL;DR: 本文提出了一种基于B样条曲线拟合的精细化方法，用于提升FastSAM分割模型的边缘质量，实现更精确且实时的分割效果。


<details>
  <summary>Details</summary>
Motivation: FastSAM模型虽然在实时语义分割方面表现优异，但其分割结果常出现锯齿状的粗糙边缘，影响对象形状的准确表达，限制了在对边缘精度要求较高的实际应用中的价值。因此，亟需改进边缘表示方式，提升分割边缘的平滑性和准确性。

Method: 作者提出了一种基于B样条曲线拟合的四阶段边缘精细化流程，包括两轮曲线拟合，以平滑FastSAM分割出来的锯齿状边缘，通过B样条的灵活几何结构和强大形状控制能力，有效改善对象边缘的准确性和视觉质量。

Result: 该方法显著提升了FastSAM分割边缘的光滑度和分割精度，无明显增加内存和推理时间，保证了其实时性。边缘分析的准确性也得到了有效增强。

Conclusion: 提出的基于B样条精细化的方法提高了FastSAM模型的边缘分割质量，同时保持了实时处理能力，增强了其在工业自动化、医学影像和自动驾驶等场景中的实际应用价值。

Abstract: Accurately identifying and representing object edges is a challenging task in
computer vision and image processing. The Segment Anything Model (SAM) has
significantly influenced the field of image segmentation, but suffers from high
memory consumption and long inference times, limiting its efficiency in
real-time applications. To address these limitations, Fast Segment Anything
(FastSAM) was proposed, achieving real-time segmentation. However, FastSAM
often generates jagged edges that deviate from the true object shapes.
Therefore, this paper introduces a novel refinement approach using B-Spline
curve fitting techniques to enhance the edge quality in FastSAM. Leveraging the
robust shape control and flexible geometric construction of B-Splines, a
four-stage refining process involving two rounds of curve fitting is employed
to effectively smooth jagged edges. This approach significantly improves the
visual quality and analytical accuracy of object edges without compromising
critical geometric information. The proposed method improves the practical
utility of FastSAM by improving segmentation accuracy while maintaining
real-time processing capabilities. This advancement unlocks greater potential
for FastSAM technology in various real-world scenarios, such as industrial
automation, medical imaging, and autonomous systems, where precise and
efficient edge recognition is crucial.

</details>


### [78] [Towards Video Thinking Test: A Holistic Benchmark for Advanced Video Reasoning and Understanding](https://arxiv.org/abs/2507.15028)
*Yuanhan Zhang,Yunice Chew,Yuhao Dong,Aria Leo,Bo Hu,Ziwei Liu*

Main category: cs.CV

TL;DR: 该论文提出了一种新的评测基准Video Thinking Test (Video-TT)，用于评估视频大模型（video LLMs）在理解复杂视频内容的正确性和鲁棒性，结果显示现有模型与人类水平存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 虽然视频大模型有进步，但目前缺乏能有效衡量其在正确性和鲁棒性上与人类智能差距的评测。因此，作者希望通过新基准更好揭示和量化这一差距。

Method: 作者构建了Video-TT基准，包括1000个YouTube Shorts视频，每个视频配有一个开放性问题和四个针对视觉与叙事复杂性的对抗性问题，以此考察模型的理解能力和抗干扰能力。通过对比模型与人类的答题表现来评估差距。

Result: 评测结果表明，视频大模型在复杂视频解释任务中的正确性和鲁棒性表现与人类有明显差距。

Conclusion: 现有视频大模型在理解和鲁棒性方面还需显著改进，Video-TT为未来模型发展提供了有效的评测工具和目标。

Abstract: Human intelligence requires correctness and robustness, with the former being
foundational for the latter. In video understanding, correctness ensures the
accurate interpretation of visual content, and robustness maintains consistent
performance in challenging conditions. Despite advances in video large language
models (video LLMs), existing benchmarks inadequately reflect the gap between
these models and human intelligence in maintaining correctness and robustness
in video interpretation. We introduce the Video Thinking Test (Video-TT), to
assess if video LLMs can interpret real-world videos as effectively as humans.
Video-TT reflects genuine gaps in understanding complex visual narratives, and
evaluates robustness against natural adversarial questions. Video-TT comprises
1,000 YouTube Shorts videos, each with one open-ended question and four
adversarial questions that probe visual and narrative complexity. Our
evaluation shows a significant gap between video LLMs and human performance.

</details>


### [79] [OpenBreastUS: Benchmarking Neural Operators for Wave Imaging Using Breast Ultrasound Computed Tomography](https://arxiv.org/abs/2507.15035)
*Zhijun Zeng,Youjia Zheng,Hao Hu,Zeyuan Dong,Yihang Zheng,Xinliang Liu,Jinzhuo Wang,Zuoqiang Shi,Linfeng Zhang,Yubing Li,He Sun*

Main category: cs.CV

TL;DR: 该论文提出了OpenBreastUS，这是一个大规模、逼真的乳腺超声波数据集，用于促进基于神经网络的偏微分方程(PDE)求解器在实际医学成像中的应用和发展。


<details>
  <summary>Details</summary>
Motivation: 传统的波动方程数值求解方法计算量大且易不稳定，限制了其在实时成像中的应用。尽管神经算子能加速PDE求解，但缺乏现实复杂度的数据集，使其在真实影像任务上的效果有限。

Method: 作者构建了OpenBreastUS数据集，包括8000个人体乳腺虚拟模型和超过1600万组超声CT现实成像配置下的频域波动方程模拟。数据集可用于基准测试各主流神经算子在正演模拟与逆成像任务中的表现，并涵盖其泛化能力和可扩展性分析。

Result: 通过OpenBreastUS，作者系统评估了神经算子的表现，并首次成功演示了基于神经算子的乳腺体内成像任务的高效性。

Conclusion: OpenBreastUS为推动神经PDE求解器在现实医疗成像应用中的研究和部署提供了重要基础，有助于该领域创新方法的发展及其向实际问题的转化。

Abstract: Accurate and efficient simulation of wave equations is crucial in
computational wave imaging applications, such as ultrasound computed tomography
(USCT), which reconstructs tissue material properties from observed scattered
waves. Traditional numerical solvers for wave equations are computationally
intensive and often unstable, limiting their practical applications for
quasi-real-time image reconstruction. Neural operators offer an innovative
approach by accelerating PDE solving using neural networks; however, their
effectiveness in realistic imaging is limited because existing datasets
oversimplify real-world complexity. In this paper, we present OpenBreastUS, a
large-scale wave equation dataset designed to bridge the gap between
theoretical equations and practical imaging applications. OpenBreastUS includes
8,000 anatomically realistic human breast phantoms and over 16 million
frequency-domain wave simulations using real USCT configurations. It enables a
comprehensive benchmarking of popular neural operators for both forward
simulation and inverse imaging tasks, allowing analysis of their performance,
scalability, and generalization capabilities. By offering a realistic and
extensive dataset, OpenBreastUS not only serves as a platform for developing
innovative neural PDE solvers but also facilitates their deployment in
real-world medical imaging problems. For the first time, we demonstrate
efficient in vivo imaging of the human breast using neural operator solvers.

</details>


### [80] [OmniVTON: Training-Free Universal Virtual Try-On](https://arxiv.org/abs/2507.15037)
*Zhaotong Yang,Yuhui Li,Shengfeng He,Xinzhe Li,Yangyang Xu,Junyu Dong,Yong Du*

Main category: cs.CV

TL;DR: OmniVTON是一种无需训练的虚拟试衣（VTON）方法，能够在各种场景下实现服装与人体姿态的解耦，从而保证服装细节和姿态一致性，实现高质量的虚拟换衣，并首次支持多人的虚拟换衣。


<details>
  <summary>Details</summary>
Motivation: 现有VTON方法受限于监督/非监督范式的取舍，难以在不同领域通用且保持高保真和强泛化能力。同时，如何解决衣物和姿态耦合带来的质量损失也是挑战。

Method: OmniVTON框架采用解耦服装和姿态约束的思想，通过服装先验生成机制对齐服饰与身体，并采用连续边界缝合技术保留衣物纹理细节。利用DDIM反演实现姿态精准对齐，有效抑制因多条件导致的扩散模型偏差。此结构无需额外训练即可适配各种场景。

Result: 在多个数据集、服装类型及应用场景下，OmniVTON均取得了优异性能。尤其支持多人的场景，是首个可实现多人高保真服装交换的虚拟试衣系统。

Conclusion: OmniVTON作为首个训练无关的通用虚拟试衣框架，可在多样化场景实现高细节服装转移和姿态一致，具备强泛化性与应用前景，并首次实现了多人人像换衣。

Abstract: Image-based Virtual Try-On (VTON) techniques rely on either supervised
in-shop approaches, which ensure high fidelity but struggle with cross-domain
generalization, or unsupervised in-the-wild methods, which improve adaptability
but remain constrained by data biases and limited universality. A unified,
training-free solution that works across both scenarios remains an open
challenge. We propose OmniVTON, the first training-free universal VTON
framework that decouples garment and pose conditioning to achieve both texture
fidelity and pose consistency across diverse settings. To preserve garment
details, we introduce a garment prior generation mechanism that aligns clothing
with the body, followed by continuous boundary stitching technique to achieve
fine-grained texture retention. For precise pose alignment, we utilize DDIM
inversion to capture structural cues while suppressing texture interference,
ensuring accurate body alignment independent of the original image textures. By
disentangling garment and pose constraints, OmniVTON eliminates the bias
inherent in diffusion models when handling multiple conditions simultaneously.
Experimental results demonstrate that OmniVTON achieves superior performance
across diverse datasets, garment types, and application scenarios. Notably, it
is the first framework capable of multi-human VTON, enabling realistic garment
transfer across multiple individuals in a single scene. Code is available at
https://github.com/Jerome-Young/OmniVTON

</details>


### [81] [Rethinking Pan-sharpening: Principled Design, Unified Training, and a Universal Loss Surpass Brute-Force Scaling](https://arxiv.org/abs/2507.15059)
*Ran Zhang,Xuanhua He,Li Xueheng,Ke Cao,Liu Liu,Wenbo Xu,Fang Jiabin,Yang Qize,Jie Zhang*

Main category: cs.CV

TL;DR: 本文提出了PanTiny——一种高效且性能强大的轻量级全色锐化框架。


<details>
  <summary>Details</summary>
Motivation: 现有全色锐化方法普遍模型庞大复杂，仅针对单一卫星数据集训练，计算消耗大且泛化能力差。作者旨在挑战这一范式，提出更高效且适应性强的方案。

Method: 1) 提出PanTiny轻量模型（单步处理）；2) 提出多合一训练范式，让一个紧凑模型在WV2、WV3和GF2三种不同分辨率和光谱信息的数据集上同时训练；3) 设计通用复合损失函数提升各种模型表现。

Result: PanTiny模型通过统一训练策略显著提升了全分辨率数据泛化能力与部署便捷性；采用创新损失函数，多种模型的性能达到新高，效果优于很多较大且专用的模型。消融实验验证方法有效。

Conclusion: 高效的模型设计、科学的训练范式和创新损失函数能够实现小模型超越大模型，推动全色锐化社群向高效、泛化与数据友好的方向转型。

Abstract: The field of pan-sharpening has recently seen a trend towards increasingly
large and complex models, often trained on single, specific satellite datasets.
This approach, however, leads to high computational overhead and poor
generalization on full resolution data, a paradigm we challenge in this paper.
In response to this issue, we propose PanTiny, a lightweight, single-step
pan-sharpening framework designed for both efficiency and robust performance.
More critically, we introduce multiple-in-one training paradigm, where a
single, compact model is trained simultaneously on three distinct satellite
datasets (WV2, WV3, and GF2) with different resolution and spectral
information. Our experiments show that this unified training strategy not only
simplifies deployment but also significantly boosts generalization on
full-resolution data. Further, we introduce a universally powerful composite
loss function that elevates the performance of almost all of models for
pan-sharpening, pushing state-of-the-art metrics into a new era. Our PanTiny
model, benefiting from these innovations, achieves a superior
performance-to-efficiency balance, outperforming most larger, specialized
models. Through extensive ablation studies, we validate that principled
engineering in model design, training paradigms, and loss functions can surpass
brute-force scaling. Our work advocates for a community-wide shift towards
creating efficient, generalizable, and data-conscious models for
pan-sharpening. The code is available at
https://github.com/Zirconium233/PanTiny .

</details>


### [82] [StableAnimator++: Overcoming Pose Misalignment and Face Distortion for Human Image Animation](https://arxiv.org/abs/2507.15064)
*Shuyuan Tu,Zhen Xing,Xintong Han,Zhi-Qi Cheng,Qi Dai,Chong Luo,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: StableAnimator++是一种新的人体图像动画视频扩散框架，与现有方法相比能更好保持身份一致性，尤其是在参考图像与驱动视频存在体型或位置差异时。该方法通过学习式位姿对齐与多模块设计，实现高质量且身份一致的动画视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散模型的人体动画在参考图像和驱动视频存在体型或位置较大差异时，难以保持身份一致性。这种问题严重影响动画生成的实际应用和视觉效果，因此亟需一种能在“参考图像+动作序列”条件下，更好保留身份特征的方法。

Method: 提出StableAnimator++框架，核心方法包括：1）通过引入可学习的层结合奇异值分解(SVD)指导，预测参考图和驱动位姿间的相似变换矩阵，实现更精准位姿对齐，减少图像与姿态之间的错位影响；2）使用现成编码器获得图像和人脸表征，并通过全局内容感知Face Encoder精细化人脸身份特征提取；3）在ID Adapter层引入分布对齐机制，抵消时序层带来的身份漂移；4）在推理过程中，将基于Hamilton-Jacobi-Bellman (HJB)的面部优化集成到扩散去噪环节，引导人脸身份增强。

Result: 在多个基准数据集上，实验结果表明StableAnimator++无论在主观视觉质量还是定量评测（如身份一致性和视频连贯性）上均显著优于现有主流方法。

Conclusion: StableAnimator++有效地提升了人体动画视频生成的身份一致性和图像质量，尤其适合参考图像与驱动视频差异较大的复杂场景，具有较高的实际应用潜力。

Abstract: Current diffusion models for human image animation often struggle to maintain
identity (ID) consistency, especially when the reference image and driving
video differ significantly in body size or position. We introduce
StableAnimator++, the first ID-preserving video diffusion framework with
learnable pose alignment, capable of generating high-quality videos conditioned
on a reference image and a pose sequence without any post-processing. Building
upon a video diffusion model, StableAnimator++ contains carefully designed
modules for both training and inference, striving for identity consistency. In
particular, StableAnimator++ first uses learnable layers to predict the
similarity transformation matrices between the reference image and the driven
poses via injecting guidance from Singular Value Decomposition (SVD). These
matrices align the driven poses with the reference image, mitigating
misalignment to a great extent. StableAnimator++ then computes image and face
embeddings using off-the-shelf encoders, refining the face embeddings via a
global content-aware Face Encoder. To further maintain ID, we introduce a
distribution-aware ID Adapter that counteracts interference caused by temporal
layers while preserving ID via distribution alignment. During the inference
stage, we propose a novel Hamilton-Jacobi-Bellman (HJB) based face optimization
integrated into the denoising process, guiding the diffusion trajectory for
enhanced facial fidelity. Experiments on benchmarks show the effectiveness of
StableAnimator++ both qualitatively and quantitatively.

</details>


### [83] [Aesthetics is Cheap, Show me the Text: An Empirical Evaluation of State-of-the-Art Generative Models for OCR](https://arxiv.org/abs/2507.15085)
*Peirong Zhang,Haowei Xu,Jiaxin Zhang,Guitao Xu,Xuhan Zheng,Zhenhua Yang,Junle Liu,Yuyi Zhang,Lianwen Jin*

Main category: cs.CV

TL;DR: 本文系统评估了现有主流生成式模型在文本图像生成与编辑方面的能力，发现当前模型在多种典型OCR任务中的表现尚有不足，并提出应将文本图像生成/编辑作为通用生成模型的基础能力。


<details>
  <summary>Details</summary>
Motivation: 随着电子社会中视觉与语言融合的信息表达需求日益增长，文本图像作为独特载体在许多场景（如文件、艺术、复杂版式等）起到了关键作用。然而，文本图像生成与编辑由于涉及视觉美学与语言语义的复杂融合，对生成模型提出了更高挑战，促使人们思考当前主流模型是否已具备这类能力。

Method: 作者设计了一套系统评测流程，提出将典型OCR相关任务（共33项，覆盖文档、手写文本、场景文本、艺术文本及复杂布局文本五类）纳入评估，以综合考察通用与专用生成模型的能力，对六个开源及闭源模型利用精心挑选的输入图片和提示语进行测试。

Result: 评测揭示了这些生成模型在文本图像生成与编辑、OCR相关任务上的优势与不足，尤其是在处理高复杂度版式、艺术性文本上存在局限。

Conclusion: 作者建议将高质量文本图像生成与编辑能力内化为通用大模型的基础技能，而非过度依赖专用工具，并希望本研究能为社区在此领域的后续改进和发展提供参考。

Abstract: Text image is a unique and crucial information medium that integrates visual
aesthetics and linguistic semantics in modern e-society. Due to their subtlety
and complexity, the generation of text images represents a challenging and
evolving frontier in the image generation field. The recent surge of
specialized image generators (\emph{e.g.}, Flux-series) and unified generative
models (\emph{e.g.}, GPT-4o), which demonstrate exceptional fidelity, raises a
natural question: can they master the intricacies of text image generation and
editing? Motivated by this, we assess current state-of-the-art generative
models' capabilities in terms of text image generation and editing. We
incorporate various typical optical character recognition (OCR) tasks into our
evaluation and broaden the concept of text-based generation tasks into OCR
generative tasks. We select 33 representative tasks and categorize them into
five categories: document, handwritten text, scene text, artistic text, and
complex \& layout-rich text. For comprehensive evaluation, we examine six
models across both closed-source and open-source domains, using tailored,
high-quality image inputs and prompts. Through this evaluation, we draw crucial
observations and identify the weaknesses of current generative models for OCR
tasks. We argue that photorealistic text image generation and editing should be
internalized as foundational skills into general-domain generative models,
rather than being delegated to specialized solutions, and we hope this
empirical analysis can provide valuable insights for the community to achieve
this goal. This evaluation is online and will be continuously updated at our
GitHub repository.

</details>


### [84] [BleedOrigin: Dynamic Bleeding Source Localization in Endoscopic Submucosal Dissection via Dual-Stage Detection and Tracking](https://arxiv.org/abs/2507.15094)
*Mengya Xu,Rulin Zhou,An Wang,Chaoyang Lyu,Zhen Li,Ning Zhong,Hongliang Ren*

Main category: cs.CV

TL;DR: 本论文聚焦于内镜黏膜下剥离术（ESD）中术中出血源的实时定位和持续追踪，提出了BleedOrigin-Bench数据集和BleedOrigin-Net检测追踪系统，实现了出血源检测和追踪的最新性能。


<details>
  <summary>Details</summary>
Motivation: ESD过程中，术中出血极大增加患者风险，且现有AI方法仅聚焦出血区域分割，缺乏对难以定位、动态变化的出血源的识别与追踪。同时，目前缺乏专门的数据集支撑相关AI研究，严重阻碍了临床辅助系统的发展。

Method: 作者构建了业界首个全面的ESD出血源数据集（BleedOrigin-Bench），涵盖多种临床场景，并提出了新颖的双阶段检测-追踪网络（BleedOrigin-Net），能实现从出血发生到持续空间追踪的全过程自动化。同时，作者与主流检测、追踪和多模态大模型方法进行了对比实验。

Result: BleedOrigin-Net在大规模真实术中数据上展示出色表现：出血起点检测帧级准确率达96.85%，初次出血源像素级定位准确度70.24%，持续追踪准确率96.11%，均优于对比方法。

Conclusion: 本文为ESD出血源AI辅助识别和追踪提供了重要基础，提出的数据集和方法显著提升了检测、追踪效能，为临床手术智能辅助提供新工具和技术基础。

Abstract: Intraoperative bleeding during Endoscopic Submucosal Dissection (ESD) poses
significant risks, demanding precise, real-time localization and continuous
monitoring of the bleeding source for effective hemostatic intervention. In
particular, endoscopists have to repeatedly flush to clear blood, allowing only
milliseconds to identify bleeding sources, an inefficient process that prolongs
operations and elevates patient risks. However, current Artificial Intelligence
(AI) methods primarily focus on bleeding region segmentation, overlooking the
critical need for accurate bleeding source detection and temporal tracking in
the challenging ESD environment, which is marked by frequent visual
obstructions and dynamic scene changes. This gap is widened by the lack of
specialized datasets, hindering the development of robust AI-assisted guidance
systems. To address these challenges, we introduce BleedOrigin-Bench, the first
comprehensive ESD bleeding source dataset, featuring 1,771 expert-annotated
bleeding sources across 106,222 frames from 44 procedures, supplemented with
39,755 pseudo-labeled frames. This benchmark covers 8 anatomical sites and 6
challenging clinical scenarios. We also present BleedOrigin-Net, a novel
dual-stage detection-tracking framework for the bleeding source localization in
ESD procedures, addressing the complete workflow from bleeding onset detection
to continuous spatial tracking. We compare with widely-used object detection
models (YOLOv11/v12), multimodal large language models, and point tracking
methods. Extensive evaluation demonstrates state-of-the-art performance,
achieving 96.85% frame-level accuracy ($\pm\leq8$ frames) for bleeding onset
detection, 70.24% pixel-level accuracy ($\leq100$ px) for initial source
detection, and 96.11% pixel-level accuracy ($\leq100$ px) for point tracking.

</details>


### [85] [LoopNet: A Multitasking Few-Shot Learning Approach for Loop Closure in Large Scale SLAM](https://arxiv.org/abs/2507.15109)
*Mohammad-Maher Nakshbandi,Ziad Sharawy,Sorin Grigorescu*

Main category: cs.CV

TL;DR: 论文提出了一种名为LoopNet的新方法，用于提升SLAM中回环检测的准确性和实时性能，并针对嵌入式硬件进行优化。还发布了新数据集LoopDB。


<details>
  <summary>Details</summary>
Motivation: SLAM系统在回环检测时面临的两大挑战是识别准确性和嵌入式设备的实时计算限制。

Method: LoopNet方法基于多任务变体的ResNet架构，能够在线少样本增量学习，并集成DISK描述子，适用于动态视觉数据和嵌入式硬件。同时还发布了LoopDB新基准数据集。

Result: LoopNet在回环检测准确性和对各种视觉变化的适应性方面超过了传统手工特征和深度学习方法。

Conclusion: LoopNet可提升SLAM系统的实际表现，适用于嵌入式系统，并推动了SLAM回环检测领域的发展。

Abstract: One of the main challenges in the Simultaneous Localization and Mapping
(SLAM) loop closure problem is the recognition of previously visited places. In
this work, we tackle the two main problems of real-time SLAM systems: 1) loop
closure detection accuracy and 2) real-time computation constraints on the
embedded hardware. Our LoopNet method is based on a multitasking variant of the
classical ResNet architecture, adapted for online retraining on a dynamic
visual dataset and optimized for embedded devices. The online retraining is
designed using a few-shot learning approach. The architecture provides both an
index into the queried visual dataset, and a measurement of the prediction
quality. Moreover, by leveraging DISK (DIStinctive Keypoints) descriptors,
LoopNet surpasses the limitations of handcrafted features and traditional deep
learning methods, offering better performance under varying conditions. Code is
available at https://github.com/RovisLab/LoopNet. Additinally, we introduce a
new loop closure benchmarking dataset, coined LoopDB, which is available at
https://github.com/RovisLab/LoopDB.

</details>


### [86] [Enhancing Visual Planning with Auxiliary Tasks and Multi-token Prediction](https://arxiv.org/abs/2507.15130)
*Ce Zhang,Yale Song,Ruta Desai,Michael Louis Iuzzolino,Joseph Tighe,Gedas Bertasius,Satwik Kottur*

Main category: cs.CV

TL;DR: 本文提出一种新的视觉规划方法VideoPlan，通过辅助任务增强和多标记预测，有效提升了对用户操作视频的长时序规划能力，在多个数据集上取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 长时序的视觉规划面对程序性标注稀缺和传统单标记预测目标难以建模结构化动作空间两个主要挑战，现有的多模态大模型在此类应用上仍有明显不足。

Method: 提出了Auxiliary Task Augmentation（辅助任务增强），通过引入与长时序规划相关的辅助任务（如目标预测），提升模型学习任务动态的能力。同时，采用Multi-token Prediction（多标记预测），采用多个预测头在训练阶段预测多个未来动作，增强对结构化动作序列的建模能力。

Result: 在COIN和CrossTask数据集上，VideoPlan在预测未来3步操作时，分别超过前人方法7.3%和3.4%；在Ego4D Long-term Action Anticipation任务上，即便未用专门的自我中心特征，也能达到与现有最优方法相当的水平。

Conclusion: VideoPlan结合辅助任务和多头多标记预测，显著提升了视频视觉辅助规划的效果，展示了该方法在长时序、结构化动作预测上优越的泛化能力和实用价值。

Abstract: Visual Planning for Assistance (VPA) aims to predict a sequence of user
actions required to achieve a specified goal based on a video showing the
user's progress. Although recent advances in multimodal large language models
(MLLMs) have shown promising results in video understanding, long-horizon
visual planning remains a challenging problem. We identify two challenges in
training large MLLMs for video-based planning tasks: (1) scarcity of procedural
annotations, limiting the model's ability to learn procedural task dynamics
effectively, and (2) inefficiency of next-token prediction objective to
explicitly capture the structured action space for visual planning when
compared to free-form, natural language. To tackle data scarcity, we introduce
Auxiliary Task Augmentation. We design and train our model on auxiliary tasks
relevant to long-horizon video-based planning (e.g., goal prediction) to
augment the model's planning ability. To more explicitly model the structured
action space unique to visual planning tasks, we leverage Multi-token
Prediction, extending traditional next-token prediction by using multiple heads
to predict multiple future tokens during training. Our approach, VideoPlan,
achieves state-of-the-art VPA performance on the COIN and CrossTask datasets,
surpassing prior methods by 7.3% and 3.4%, respectively, when predicting 3
future actions. We further extend our method to the challenging Ego4D Long-term
Action Anticipation task, and show that it is on par with the state-of-the-art
approaches despite not using specialized egocentric features. Code will be made
available.

</details>


### [87] [Event-based Graph Representation with Spatial and Motion Vectors for Asynchronous Object Detection](https://arxiv.org/abs/2507.15150)
*Aayush Atul Verma,Arpitsinh Vaghela,Bharatesh Chakravarthi,Kaustav Chanda,Yezhou Yang*

Main category: cs.CV

TL;DR: 该论文提出了一种改进的事件传感器数据处理方法，通过空间与时间双重解耦的多重图（multigraph）结构，有效提升了异步视觉任务中的检测准确性和速度。


<details>
  <summary>Details</summary>
Motivation: 将稀疏、异步的事件传感器数据直接转为稠密张量会削弱其高时空分辨率与低延迟优势，因此需要寻求既能保持数据稀疏性又便于神经网络处理的新型表示方式。现有基于图的事件数据建模由于空间-时间动态描述不充分而在下游任务表现受限。

Method: 作者提出空间-时间多重图结构：利用B样条基函数建模全局空间结构（空间图），同时采用基于运动向量的注意力机制建模局部动态变化（时间图），两者解耦设计，并用高效的2D卷积核替换计算昂贵的3D卷积核。

Result: 在Gen1和eTraM汽车事件数据集上的目标检测实验中，新方法相比其他图基方法准确率提升6%以上，速度提升5倍，模型参数更少且计算成本无增加。

Conclusion: 结构化的空间-时间图建模能高效提升异步视觉的目标检测性能，是处理事件传感器数据的有效路径。

Abstract: Event-based sensors offer high temporal resolution and low latency by
generating sparse, asynchronous data. However, converting this irregular data
into dense tensors for use in standard neural networks diminishes these
inherent advantages, motivating research into graph representations. While such
methods preserve sparsity and support asynchronous inference, their performance
on downstream tasks remains limited due to suboptimal modeling of
spatiotemporal dynamics. In this work, we propose a novel spatiotemporal
multigraph representation to better capture spatial structure and temporal
changes. Our approach constructs two decoupled graphs: a spatial graph
leveraging B-spline basis functions to model global structure, and a temporal
graph utilizing motion vector-based attention for local dynamic changes. This
design enables the use of efficient 2D kernels in place of computationally
expensive 3D kernels. We evaluate our method on the Gen1 automotive and eTraM
datasets for event-based object detection, achieving over a 6% improvement in
detection accuracy compared to previous graph-based works, with a 5x speedup,
reduced parameter count, and no increase in computational cost. These results
highlight the effectiveness of structured graph modeling for asynchronous
vision. Project page: eventbasedvision.github.io/eGSMV.

</details>


### [88] [MeshMamba: State Space Models for Articulated 3D Mesh Generation and Reconstruction](https://arxiv.org/abs/2507.15212)
*Yusuke Yoshiyasu,Leyuan Sun,Ryusuke Sagawa*

Main category: cs.CV

TL;DR: 该论文提出MeshMamba模型，利用Mamba State Space Models来高效处理超过1万顶点的3D人体网格生成与重建，实现了高质量的人体、服装和手部几何生成，并提出了相应的3D生成与恢复方法。


<details>
  <summary>Details</summary>
Motivation: 当前3D网格生成和恢复面临处理高复杂度网格（如全身带手和服装，超过1万顶点）时的效率与可扩展性瓶颈，且现有方法多只能处理较粗糙的网格或局部区域。

Method: 提出MeshMamba神经网络结构，将3D人体网格顶点按身体部位或空间关系序列化，使Mamba-SSMs能有效处理，并据此构建了MambaDiff3D（3D网格扩散生成）和Mamba-HMR（单图像到人体姿态及形状还原）两个子模型。

Result: MambaDiff3D能够生成包含服装和手部细节的高密度人体网格，并在3D人体形状生成任务上超过现有方法。Mamba-HMR首次实现全身（含头、手）的高分辨率人体重建，并保持了接近实时的性能。

Conclusion: MeshMamba有效提升了3D多关节网格建模效率与精度，并拓展了3D人体网格生成与恢复的能力，有望推动相关应用的发展。

Abstract: In this paper, we introduce MeshMamba, a neural network model for learning 3D
articulated mesh models by employing the recently proposed Mamba State Space
Models (Mamba-SSMs). MeshMamba is efficient and scalable in handling a large
number of input tokens, enabling the generation and reconstruction of body mesh
models with more than 10,000 vertices, capturing clothing and hand geometries.
The key to effectively learning MeshMamba is the serialization technique of
mesh vertices into orderings that are easily processed by Mamba. This is
achieved by sorting the vertices based on body part annotations or the 3D
vertex locations of a template mesh, such that the ordering respects the
structure of articulated shapes. Based on MeshMamba, we design 1) MambaDiff3D,
a denoising diffusion model for generating 3D articulated meshes and 2)
Mamba-HMR, a 3D human mesh recovery model that reconstructs a human body shape
and pose from a single image. Experimental results showed that MambaDiff3D can
generate dense 3D human meshes in clothes, with grasping hands, etc., and
outperforms previous approaches in the 3D human shape generation task.
Additionally, Mamba-HMR extends the capabilities of previous non-parametric
human mesh recovery approaches, which were limited to handling body-only poses
using around 500 vertex tokens, to the whole-body setting with face and hands,
while achieving competitive performance in (near) real-time.

</details>


### [89] [Improving Joint Embedding Predictive Architecture with Diffusion Noise](https://arxiv.org/abs/2507.15216)
*Yuping Qiu,Rui Zhu,Ying-cong Chen*

Main category: cs.CV

TL;DR: 本文提出将扩散模型中的噪声机制引入到自监督学习（SSL）中，通过噪声增强来提升特征表征能力，实现更强的下游视觉任务性能。


<details>
  <summary>Details</summary>
Motivation: 自监督学习在特征学习领域获得巨大成功，尤其是在判别任务上优于生成式模型，而生成模型在生成和细节增强方面表现更好。作者希望结合两者优点，用生成模型的扩散噪声提升SSL表征能力并增强模型鲁棒性。

Method: 提出N-JEPA方法，将扩散噪声以掩码token的位置嵌入形式注入掩码图像建模（MIM）中，设计多级噪声调度机制，对特征进行多层次增强。

Result: 在多项下游分类任务上，系统性实验验证了方法的有效性。

Conclusion: 将扩散噪声引入SSL显著提升了表征能力和下游任务性能，该方法兼具生成和辨别模型优势，具备良好的应用前景。

Abstract: Self-supervised learning has become an incredibly successful method for
feature learning, widely applied to many downstream tasks. It has proven
especially effective for discriminative tasks, surpassing the trending
generative models. However, generative models perform better in image
generation and detail enhancement. Thus, it is natural for us to find a
connection between SSL and generative models to further enhance the
representation capacity of SSL. As generative models can create new samples by
approximating the data distribution, such modeling should also lead to a
semantic understanding of the raw visual data, which is necessary for
recognition tasks. This enlightens us to combine the core principle of the
diffusion model: diffusion noise, with SSL to learn a competitive recognition
model. Specifically, diffusion noise can be viewed as a particular state of
mask that reveals a close relationship between masked image modeling (MIM) and
diffusion models. In this paper, we propose N-JEPA (Noise-based JEPA) to
incorporate diffusion noise into MIM by the position embedding of masked
tokens. The multi-level noise schedule is a series of feature augmentations to
further enhance the robustness of our model. We perform a comprehensive study
to confirm its effectiveness in the classification of downstream tasks. Codes
will be released soon in public.

</details>


### [90] [Hierarchical Part-based Generative Model for Realistic 3D Blood Vessel](https://arxiv.org/abs/2507.15223)
*Siqi Chen,Guoqing Zhang,Jiahao Lai,Bingzhi Shen,Sihong Zhang,Caixia Dong,Xuejin Chen,Yang Li*

Main category: cs.CV

TL;DR: 本文提出了一种分层部件式的3D血管建模方法，将全局的树状拓扑结构与局部几何细节相分离，实现了对血管复杂几何与拓扑的高效表征，并在真实数据集上取得了超越现有方法的效果。


<details>
  <summary>Details</summary>
Motivation: 血管的复杂分支、曲率和不规则形状使其三维建模具有挑战性，当前的方法难以同时兼顾血管的全局结构与细节表达，亟需新的方法提升血管建模的准确性和实用性。

Method: 方法分为三步：（1）生成关键图以建模血管的全局分层结构；（2）在几何属性条件下生成血管片段；（3）按照全局关键图将各局部片段分层组装，完成复杂血管网络的三维重建。

Result: 在真实数据集上进行验证，所提出的方法在血管复杂网络的建模上优于现有主流方法，显示出更强的综合表现。

Conclusion: 首次成功将部件生成式方法应用于3D血管建模，为未来血管数据生成和相关医学应用设立了新基准。

Abstract: Advancements in 3D vision have increased the impact of blood vessel modeling
on medical applications. However, accurately representing the complex geometry
and topology of blood vessels remains a challenge due to their intricate
branching patterns, curvatures, and irregular shapes. In this study, we propose
a hierarchical part-based frame work for 3D vessel generation that separates
the global binary tree-like topology from local geometric details. Our approach
proceeds in three stages: (1) key graph generation to model the overall
hierarchical struc ture, (2) vessel segment generation conditioned on geometric
properties, and (3) hierarchical vessel assembly by integrating the local
segments according to the global key graph. We validate our framework on real
world datasets, demonstrating superior performance over existing methods in
modeling complex vascular networks. This work marks the first successful
application of a part-based generative approach for 3D vessel modeling, setting
a new benchmark for vascular data generation. The code is available at:
https://github.com/CybercatChen/PartVessel.git.

</details>


### [91] [Mammo-SAE: Interpreting Breast Cancer Concept Learning with Sparse Autoencoders](https://arxiv.org/abs/2507.15227)
*Krishna Kanth Nakka*

Main category: cs.CV

TL;DR: 本文提出一种基于稀疏自编码器（SAE）的解释性方法，分析了乳腺影像领域大型视觉-语言基础模型Mammo-CLIP中的潜在特征，展示该方法对模型内部机制的可解释性。


<details>
  <summary>Details</summary>
Motivation: 医学影像特别是乳腺影像领域，模型可解释性对于临床采纳至关重要。目前基础模型尽管表现优异，但其决策过程不透明限制了临床信任，因此需要开发出能揭示模型内部特征与临床概念关联性的解释性方法。

Method: 作者以预训练的大规模乳腺影像-报告对基础模型Mammo-CLIP为基础，设计了面向图像patch层面的稀疏自编码器（Mammo-SAE）。通过训练Mammo-SAE，分析其潜在空间中的神经元激活，识别与『肿块』、『可疑钙化』等临床乳腺概念相关联的特征，同时研究这些潜在神经元在下游概念预测任务精调过程中的作用。

Result: 实验证明，SAE潜在空间高度激活的类别神经元与真实乳腺病变区域具有较好对齐，能够揭示影响模型决策的混杂因素。此外，分析了模型在下游任务精调时依赖哪些潜在特征，进一步提升了模型解释性。

Conclusion: 本研究表明，SAE潜在表达提供了一种高层次和层层解析基础模型内部机制的解释性途径，有助于深入理解和信任乳腺影像相关的基础模型，为临床应用铺平道路。

Abstract: Interpretability is critical in high-stakes domains such as medical imaging,
where understanding model decisions is essential for clinical adoption. In this
work, we introduce Sparse Autoencoder (SAE)-based interpretability to breast
imaging by analyzing {Mammo-CLIP}, a vision--language foundation model
pretrained on large-scale mammogram image--report pairs. We train a patch-level
\texttt{Mammo-SAE} on Mammo-CLIP to identify and probe latent features
associated with clinically relevant breast concepts such as \textit{mass} and
\textit{suspicious calcification}. Our findings reveal that top activated class
level latent neurons in the SAE latent space often tend to align with ground
truth regions, and also uncover several confounding factors influencing the
model's decision-making process. Additionally, we analyze which latent neurons
the model relies on during downstream finetuning for improving the breast
concept prediction. This study highlights the promise of interpretable SAE
latent representations in providing deeper insight into the internal workings
of foundation models at every layer for breast imaging.

</details>


### [92] [Cross-Domain Few-Shot Learning with Coalescent Projections and Latent Space Reservation](https://arxiv.org/abs/2507.15243)
*Naeem Paeedeh,Mahardhika Pratama,Wolfgang Mayer,Jimmy Cao,Ryszard Kowlczyk*

Main category: cs.CV

TL;DR: 该论文提出了Coalescent Projection (CP) 和结合自监督变换(SSTs)的伪类别生成方法，在跨域小样本学习（CD-FSL）任务中有效缓解了Transformer过拟合问题，并在极端领域转移数据集BSCD-FSL上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有CD-FSL方法中，基于DINO预训练和原型分类器的简单组合竟超过了最新的SOTA方法，但Transformer参数多且标注样本稀缺时容易过拟合。因此，急需新的方法提升模型泛化能力，降低过拟合风险。

Method: 1）提出Coalescent Projection (CP) 作为软提示（soft prompts）的升级版，只调整部分投影参数，避免大量参数更新；2）提出结合自监督变换（SSTs）的伪类别生成方法，仅用源域数据扩充类信息并增强模型泛化。

Result: 在BSCD-FSL极端领域转移基准上，所提方法经历全面实验，效果优于其他SOTA方法，验证了CP和伪类别生成的有效性。

Conclusion: 新提出的CP和伪类别生成方案能显著提升跨域小样本学习中Transformer的表现，同时避免过拟合，为CD-FSL提供了具实用价值的技术路线。

Abstract: Despite the progress in Cross-Domain Few-Shot Learning (CD-FSL), a model
pre-trained with DINO combined with a prototypical classifier outperforms the
latest SOTA methods. A crucial limitation that needs to be overcome is that
updating too many parameters of the transformers leads to overfitting due to
the scarcity of labeled samples. To address this challenge, we propose a new
concept, Coalescent Projection (CP), as an effective successor to soft prompts.
Additionally, we propose a novel pseudo-class generation method combined with
Self-Supervised Transformations (SSTs) that relies solely on the base domain to
prepare the network for encountering unseen samples from different domains. The
proposed method exhibits its effectiveness in comprehensive experiments on the
extreme domain shift scenario of the BSCD-FSL benchmark. Our code is published
at https://github.com/Naeem-Paeedeh/CPLSR.

</details>


### [93] [FreeCus: Free Lunch Subject-driven Customization in Diffusion Transformers](https://arxiv.org/abs/2507.15249)
*Yanbing Zhang,Zhe Wang,Qin Zhou,Mengping Yang*

Main category: cs.CV

TL;DR: 本文提出了FreeCus，一种无需训练的、基于Diffusion Transformer（DiT）的文本到图像个性化生成框架，通过创新机制实现高保真、个性一致的图像合成，解决了现有方法依赖训练和优化的局限。


<details>
  <summary>Details</summary>
Motivation: 现有针对文本到图像的个性化生成方法多数需要针对每个目标主体进行训练或优化（如文本嵌入优化或专门特征编码器），大大增加了使用门槛和局限性，并未充分发挥现代DiT模型的零样本能力。

Method: 提出了FreeCus框架，包括三项创新：(1)注意力共享机制，在保留编辑灵活性的同时保证主体布局完整性；(2)针对DiT特性的分析与变体设计，提高精细特征提取能力；(3)融合多模态大语言模型（MLLM）增强跨模态语义表达。该方法完全不需要额外训练。

Result: 实验显示，FreeCus在多种场景下实现了与需训练方法相当或更优的、主体一致的零样本个性化合成效果，并且能够与现有图片修补与控制模块无缝协作。

Conclusion: FreeCus显著拓展了Diffusion Transformer的实际应用边界，实现了高效、便捷的个性化图像生成，为设计和娱乐等领域带来更具吸引力的新体验。

Abstract: In light of recent breakthroughs in text-to-image (T2I) generation,
particularly with diffusion transformers (DiT), subject-driven technologies are
increasingly being employed for high-fidelity customized production that
preserves subject identity from reference inputs, enabling thrilling design
workflows and engaging entertainment. Existing alternatives typically require
either per-subject optimization via trainable text embeddings or training
specialized encoders for subject feature extraction on large-scale datasets.
Such dependencies on training procedures fundamentally constrain their
practical applications. More importantly, current methodologies fail to fully
leverage the inherent zero-shot potential of modern diffusion transformers
(e.g., the Flux series) for authentic subject-driven synthesis. To bridge this
gap, we propose FreeCus, a genuinely training-free framework that activates
DiT's capabilities through three key innovations: 1) We introduce a pivotal
attention sharing mechanism that captures the subject's layout integrity while
preserving crucial editing flexibility. 2) Through a straightforward analysis
of DiT's dynamic shifting, we propose an upgraded variant that significantly
improves fine-grained feature extraction. 3) We further integrate advanced
Multimodal Large Language Models (MLLMs) to enrich cross-modal semantic
representations. Extensive experiments reflect that our method successfully
unlocks DiT's zero-shot ability for consistent subject synthesis across diverse
contexts, achieving state-of-the-art or comparable results compared to
approaches that require additional training. Notably, our framework
demonstrates seamless compatibility with existing inpainting pipelines and
control modules, facilitating more compelling experiences. Our code is
available at: https://github.com/Monalissaa/FreeCus.

</details>


### [94] [MinCD-PnP: Learning 2D-3D Correspondences with Approximate Blind PnP](https://arxiv.org/abs/2507.15257)
*Pei An,Jiaqi Yang,Muyao Peng,You Yang,Qiong Liu,Xiaolin Wu,Liangliang Nan*

Main category: cs.CV

TL;DR: 该论文提出了一种改进的2D图像到3D点云配准方法，通过优化新的损失函数提升了配准的鲁棒性和准确率，并在多个公开数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前流行的基于差分PnP的2D-3D配准方法对噪声与离群点较为敏感，这限制了配准网络学习高质量对应关系的能力。为此，研究者希望设计更鲁棒的配准监督方案。

Method: 受到blind PnP算法对噪声鲁棒性的启发，作者引入近似的blind PnP思路，将配准问题简化为最小化2D-3D关键点的Chamfer距离（MinCD-PnP），并提出了轻量级多任务学习模块MinCD-Net，与现有的I2P网络易于集成。

Result: 在7-Scenes、RGBD-V2、ScanNet及自建数据集上，MinCD-Net在跨场景和跨数据集的条件下均取得更高的inlier ratio和registration recall，优于当前最优方法。

Conclusion: MinCD-Net为2D图像与3D点云的配准提供了一种简单高效且鲁棒的新方法，有望推进相关领域的应用。

Abstract: Image-to-point-cloud (I2P) registration is a fundamental problem in computer
vision, focusing on establishing 2D-3D correspondences between an image and a
point cloud. The differential perspective-n-point (PnP) has been widely used to
supervise I2P registration networks by enforcing the projective constraints on
2D-3D correspondences. However, differential PnP is highly sensitive to noise
and outliers in the predicted correspondences. This issue hinders the
effectiveness of correspondence learning. Inspired by the robustness of blind
PnP against noise and outliers in correspondences, we propose an approximated
blind PnP based correspondence learning approach. To mitigate the high
computational cost of blind PnP, we simplify blind PnP to an amenable task of
minimizing Chamfer distance between learned 2D and 3D keypoints, called
MinCD-PnP. To effectively solve MinCD-PnP, we design a lightweight multi-task
learning module, named as MinCD-Net, which can be easily integrated into the
existing I2P registration architectures. Extensive experiments on 7-Scenes,
RGBD-V2, ScanNet, and self-collected datasets demonstrate that MinCD-Net
outperforms state-of-the-art methods and achieves a higher inlier ratio (IR)
and registration recall (RR) in both cross-scene and cross-dataset settings.

</details>


### [95] [Conditional Video Generation for High-Efficiency Video Compression](https://arxiv.org/abs/2507.15269)
*Fangqiu Yi,Jingyu Xu,Jiawei Shao,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 本文提出一种基于条件扩散模型的视频压缩框架，通过生成模型实现感知优化的视频重建，在高压缩率下显著提升感知质量。


<details>
  <summary>Details</summary>
Motivation: 由于条件扩散模型在与人类视觉感知一致的视频重建方面表现突出，作者希望利用这种能力优化视频压缩的重构质量，从而弥补传统方法在感知质量上的不足。

Method: 将视频压缩重新表述为条件生成任务，采用生成模型从稀疏的信号中合成视频。方法引入三大模块：多粒度条件建模（整合静态场景结构和动态时空线索）、用于高效传输且语义丰富的紧凑特征表示，以及结合模态dropout和角色感知embedding的多条件训练机制，提升鲁棒性。

Result: 实验结果表明，所提方法在感知质量评价指标（如FVD和LPIPS）上，特别是高压缩率场景下，显著优于传统视频编码器和神经编码器。

Conclusion: 基于条件扩散模型的视频压缩框架能够兼顾高效压缩和高感知质量，在未来视频编码领域具有很大的潜力。

Abstract: Perceptual studies demonstrate that conditional diffusion models excel at
reconstructing video content aligned with human visual perception. Building on
this insight, we propose a video compression framework that leverages
conditional diffusion models for perceptually optimized reconstruction.
Specifically, we reframe video compression as a conditional generation task,
where a generative model synthesizes video from sparse, yet informative
signals. Our approach introduces three key modules: (1) Multi-granular
conditioning that captures both static scene structure and dynamic
spatio-temporal cues; (2) Compact representations designed for efficient
transmission without sacrificing semantic richness; (3) Multi-condition
training with modality dropout and role-aware embeddings, which prevent
over-reliance on any single modality and enhance robustness. Extensive
experiments show that our method significantly outperforms both traditional and
neural codecs on perceptual quality metrics such as Fr\'echet Video Distance
(FVD) and LPIPS, especially under high compression ratios.

</details>


### [96] [In-context Learning of Vision Language Models for Detection of Physical and Digital Attacks against Face Recognition Systems](https://arxiv.org/abs/2507.15285)
*Lazaro Janier Gonzalez-Soler,Maciej Salwowski,Christoph Busch*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉语言模型（VLM）的新方法，通过in-context learning无须大量训练数据，就能高效检测生物识别系统中的物理和数字攻击，且在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着生物识别防护系统的检测能力提升，攻击手法也变得更加高级。现有模型在未知攻击和环境变化面前表现不佳，并且收集足够多样的数据用于训练存在隐私和实际操作困难。为此，作者希望找到一种更易推广且无需大规模训练数据的方法。

Method: 作者引入了基于VLM的in-context learning方法，建立首个面向安全关键场景的VLM定量评估框架，重点针对物理呈现攻击与数字变形攻击，通过开源数据库进行实验。

Result: 在公开数据集上，提出的方法在物理和数字攻击检测任务中取得了有竞争力的结果，部分情况下优于传统的CNN，无需大量训练。

Conclusion: 实验验证该VLM+in-context learning框架能够有效提升对新型攻击的泛化检测能力，是生物识别安全领域的一项有前景的技术。

Abstract: Recent advances in biometric systems have significantly improved the
detection and prevention of fraudulent activities. However, as detection
methods improve, attack techniques become increasingly sophisticated. Attacks
on face recognition systems can be broadly divided into physical and digital
approaches. Traditionally, deep learning models have been the primary defence
against such attacks. While these models perform exceptionally well in
scenarios for which they have been trained, they often struggle to adapt to
different types of attacks or varying environmental conditions. These
subsystems require substantial amounts of training data to achieve reliable
performance, yet biometric data collection faces significant challenges,
including privacy concerns and the logistical difficulties of capturing diverse
attack scenarios under controlled conditions. This work investigates the
application of Vision Language Models (VLM) and proposes an in-context learning
framework for detecting physical presentation attacks and digital morphing
attacks in biometric systems. Focusing on open-source models, the first
systematic framework for the quantitative evaluation of VLMs in
security-critical scenarios through in-context learning techniques is
established. The experimental evaluation conducted on freely available
databases demonstrates that the proposed subsystem achieves competitive
performance for physical and digital attack detection, outperforming some of
the traditional CNNs without resource-intensive training. The experimental
results validate the proposed framework as a promising tool for improving
generalisation in attack detection.

</details>


### [97] [Minutiae-Anchored Local Dense Representation for Fingerprint Matching](https://arxiv.org/abs/2507.15297)
*Zhiyu Pan,Xiongjun Guan,Yongjie Duan,Jianjiang Feng,Jie Zhou*

Main category: cs.CV

TL;DR: 该论文提出了一种新的指纹匹配方法DMD（minutiae-anchored local dense representation），能够在多种采集条件下实现稳健的识别。


<details>
  <summary>Details</summary>
Motivation: 现有指纹识别方法在不同采集条件下（如卷印、平印、部分指纹、免接触和潜指纹等）面临显著的匹配性能下降。因此，亟需能够同时捕捉微观脊线结构和区分性细节点（minutiae）特征的鲁棒表示方法，以提升识别准确率和适应性。

Method: 提出DMD指纹表征方法：在每个检测到的细节点上，提取以其为中心且方向对齐的局部图像块的描述子，组合成一个三维张量，前两个维度为指纹平面空间位置，第三维编码语义特征。该结构融合多级、细粒度的脊线与细节点信息，并结合前景分割掩码，仅在重叠前景区域做比对，提高效率和鲁棒性。

Result: 在卷印、平印、部分、免接触和潜指纹多种数据集上的大量实验表明，DMD方法在多个主流基准测试中均取得了SOTA（最佳）表现，并兼顾高计算效率，具备良好的泛化能力。

Conclusion: DMD为大规模指纹识别提供了一种有效、通用和高效的特征表达与匹配新方案，在多种真实采集条件下表现出强大的应用潜力。

Abstract: Fingerprint matching under diverse capture conditions remains a fundamental
challenge in biometric recognition. To achieve robust and accurate performance
in such scenarios, we propose DMD, a minutiae-anchored local dense
representation which captures both fine-grained ridge textures and
discriminative minutiae features in a spatially structured manner.
Specifically, descriptors are extracted from local patches centered and
oriented on each detected minutia, forming a three-dimensional tensor, where
two dimensions represent spatial locations on the fingerprint plane and the
third encodes semantic features. This representation explicitly captures
abstract features of local image patches, enabling a multi-level, fine-grained
description that aggregates information from multiple minutiae and their
surrounding ridge structures. Furthermore, thanks to its strong spatial
correspondence with the patch image, DMD allows for the use of foreground
segmentation masks to identify valid descriptor regions. During matching,
comparisons are then restricted to overlapping foreground areas, improving
efficiency and robustness. Extensive experiments on rolled, plain, parital,
contactless, and latent fingerprint datasets demonstrate the effectiveness and
generalizability of the proposed method. It achieves state-of-the-art accuracy
across multiple benchmarks while maintaining high computational efficiency,
showing strong potential for large-scale fingerprint recognition. Corresponding
code is available at https://github.com/Yu-Yy/DMD.

</details>


### [98] [Few-Shot Object Detection via Spatial-Channel State Space Model](https://arxiv.org/abs/2507.15308)
*Zhimeng Xin,Tianxu Wu,Yixiong Zou,Shiming Chen,Dingjie Fu,Xinge You*

Main category: cs.CV

TL;DR: 本文提出了一种新的空间-通道状态建模（SCSM）模块，用于提高小样本目标检测中特征通道的有效性，从而大幅提升检测表现。


<details>
  <summary>Details</summary>
Motivation: 在小样本目标检测任务中，由于训练样本有限，现有方法难以有效选取并利用各个特征通道，导致有些高权重通道不一定有效，而低权重通道也可能有价值，因此需要更好地建模通道间的相关性与有效性。

Method: 作者受Mamba在时序序列建模的启发，提出空间-通道状态建模（SCSM）模块：其中包含空间特征建模（SFM）模块用于平衡空间和通道关系学习，以及基于Mamba的通道状态建模（CSM）模块来建模通道间相关性，进而突出有效特征并修正无效特征。

Result: 在VOC和COCO两个主流数据集上的大量实验表明，SCSM能够提升检测器对通道特征表示的质量，并取得了当前最优的性能。

Conclusion: SCSM模块能够有效提升小样本目标检测中通道特征表达的专注度和表示质量，为通道建模提供了新思路，在实际检测任务中取得了优异效果。

Abstract: Due to the limited training samples in few-shot object detection (FSOD), we
observe that current methods may struggle to accurately extract effective
features from each channel. Specifically, this issue manifests in two aspects:
i) channels with high weights may not necessarily be effective, and ii)
channels with low weights may still hold significant value. To handle this
problem, we consider utilizing the inter-channel correlation to facilitate the
novel model's adaptation process to novel conditions, ensuring the model can
correctly highlight effective channels and rectify those incorrect ones. Since
the channel sequence is also 1-dimensional, its similarity with the temporal
sequence inspires us to take Mamba for modeling the correlation in the channel
sequence. Based on this concept, we propose a Spatial-Channel State Space
Modeling (SCSM) module for spatial-channel state modeling, which highlights the
effective patterns and rectifies those ineffective ones in feature channels. In
SCSM, we design the Spatial Feature Modeling (SFM) module to balance the
learning of spatial relationships and channel relationships, and then introduce
the Channel State Modeling (CSM) module based on Mamba to learn correlation in
channels. Extensive experiments on the VOC and COCO datasets show that the SCSM
module enables the novel detector to improve the quality of focused feature
representation in channels and achieve state-of-the-art performance.

</details>


### [99] [BenchDepth: Are We on the Right Way to Evaluate Depth Foundation Models?](https://arxiv.org/abs/2507.15321)
*Zhenyu Li,Haotong Lin,Jiashi Feng,Peter Wonka,Bingyi Kang*

Main category: cs.CV

TL;DR: 本文提出一个名为BenchDepth的新基准，旨在通过实际应用任务来评估深度基础模型（DFMs），取代传统存在偏见的评测方法。


<details>
  <summary>Details</summary>
Motivation: 深度估计是计算机视觉中的基础任务，但现有评测方法由于指标和协议不统一，导致评测结果存在偏差，不利于模型的公平对比和应用推广。

Method: 作者设计了BenchDepth基准，包括深度补全、立体匹配、单目3D场景重建、SLAM、视觉-语言空间理解五个下游任务，通过这些与实际应用密切相关的任务，全面评估深度基础模型的实际效用。

Result: 研究对八个主流DFMs进行了基准测试，发现以应用导向的评测能够更准确地反映模型的真实效用，并揭示了各模型在不同任务下的表现差异和优劣特点。

Conclusion: BenchDepth为深度模型评测提供了更具有实用意义的新范式，有助于推动深度估计领域对评测最佳实践的探讨，并为今后相关研究提供了新方向。

Abstract: Depth estimation is a fundamental task in computer vision with diverse
applications. Recent advancements in deep learning have led to powerful depth
foundation models (DFMs), yet their evaluation remains challenging due to
inconsistencies in existing protocols. Traditional benchmarks rely on
alignment-based metrics that introduce biases, favor certain depth
representations, and complicate fair comparisons. In this work, we propose
BenchDepth, a new benchmark that evaluates DFMs through five carefully selected
downstream proxy tasks: depth completion, stereo matching, monocular
feed-forward 3D scene reconstruction, SLAM, and vision-language spatial
understanding. Unlike conventional evaluation protocols, our approach assesses
DFMs based on their practical utility in real-world applications, bypassing
problematic alignment procedures. We benchmark eight state-of-the-art DFMs and
provide an in-depth analysis of key findings and observations. We hope our work
sparks further discussion in the community on best practices for depth model
evaluation and paves the way for future research and advancements in depth
estimation.

</details>


### [100] [ExDD: Explicit Dual Distribution Learning for Surface Defect Detection via Diffusion Synthesis](https://arxiv.org/abs/2507.15335)
*Muhammad Aqeel,Federico Leonardi,Francesco Setti*

Main category: cs.CV

TL;DR: 本文提出了一种新的工业缺陷检测框架ExDD，通过显式建模正常与异常两类特征分布，有效提升检测性能，并使用生成模型克服数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 现有的工业缺陷检测系统多基于单类异常检测，假设异常分布均匀，且面临现实中数据稀缺的挑战，导致检测准确性不足。作者希望解决分布假设不合理和样本稀缺的问题。

Method: 提出ExDD框架，通过并行记忆库分别建模正常与异常数据的统计特性，针对异常分布非均匀的实际情况。结合领域相关的文本引导潜在扩散模型，生成符合工业背景的合成缺陷图片，缓解数据不足。引入邻域感知的比值评分，融合不同距离度量，提升异常检测效果。

Result: 在KSDD2数据集上，ExDD在I-AUROC和P-AUROC两个指标上分别取得94.2%和97.7%的领先性能，使用100个合成样本时增益最佳。

Conclusion: ExDD通过显式双分布建模及生成辅助，大幅提升了工业缺陷检测效果，为实际应用提供了有效解决方案。

Abstract: Industrial defect detection systems face critical limitations when confined
to one-class anomaly detection paradigms, which assume uniform outlier
distributions and struggle with data scarcity in realworld manufacturing
environments. We present ExDD (Explicit Dual Distribution), a novel framework
that transcends these limitations by explicitly modeling dual feature
distributions. Our approach leverages parallel memory banks that capture the
distinct statistical properties of both normality and anomalous patterns,
addressing the fundamental flaw of uniform outlier assumptions. To overcome
data scarcity, we employ latent diffusion models with domain-specific textual
conditioning, generating in-distribution synthetic defects that preserve
industrial context. Our neighborhood-aware ratio scoring mechanism elegantly
fuses complementary distance metrics, amplifying signals in regions exhibiting
both deviation from normality and similarity to known defect patterns.
Experimental validation on KSDD2 demonstrates superior performance (94.2%
I-AUROC, 97.7% P-AUROC), with optimal augmentation at 100 synthetic samples.

</details>


### [101] [RoadFusion: Latent Diffusion Model for Pavement Defect Detection](https://arxiv.org/abs/2507.15346)
*Muhammad Aqeel,Kidus Dagnaw Bellete,Francesco Setti*

Main category: cs.CV

TL;DR: 本文提出了一种新方法RoadFusion，用于解决路面缺陷检测中的数据稀缺、领域转移和缺陷多样性问题，取得了新的性能突破。


<details>
  <summary>Details</summary>
Motivation: 现有路面缺陷检测方法面临缺乏标注数据、训练与部署环境不一致（领域转移）、以及缺陷外观差异大的挑战，导致实际应用效果有限。

Method: 提出RoadFusion框架，利用潜在扩散模型通过文本提示和空间掩码生成多样、逼真的合成缺陷图像增强训练集；采用双路径特征适配器，分别针对正常与异常输入提取特征，提高系统对领域转移和缺陷多变性的鲁棒性；同时加入轻量级判别器，实现精细化缺陷模式识别。

Result: 在六个基准数据集上验证，RoadFusion在缺陷分类和定位任务上表现持续优异，在多个与实际道路巡检相关的评价指标上刷新了当前最好成绩。

Conclusion: RoadFusion能有效缓解数据不足和领域转移带来的挑战，提高路面缺陷检测的准确性与泛化能力，对实际道路巡检具有很大的应用价值。

Abstract: Pavement defect detection faces critical challenges including limited
annotated data, domain shift between training and deployment environments, and
high variability in defect appearances across different road conditions. We
propose RoadFusion, a framework that addresses these limitations through
synthetic anomaly generation with dual-path feature adaptation. A latent
diffusion model synthesizes diverse, realistic defects using text prompts and
spatial masks, enabling effective training under data scarcity. Two separate
feature adaptors specialize representations for normal and anomalous inputs,
improving robustness to domain shift and defect variability. A lightweight
discriminator learns to distinguish fine-grained defect patterns at the patch
level. Evaluated on six benchmark datasets, RoadFusion achieves consistently
strong performance across both classification and localization tasks, setting
new state-of-the-art in multiple metrics relevant to real-world road
inspection.

</details>


### [102] [DAViD: Data-efficient and Accurate Vision Models from Synthetic Data](https://arxiv.org/abs/2507.15365)
*Fatemeh Saleh,Sadegh Aliakbarian,Charlie Hewitt,Lohit Petikam,Xiao-Xian,Antonio Criminisi,Thomas J. Cashman,Tadas Baltrušaitis*

Main category: cs.CV

TL;DR: 本文提出使用高质量合成数据集进行人类为中心的计算机视觉模型训练，能以更高效率和低成本达到与传统大规模真实数据训练方法相同甚至更优的精度。


<details>
  <summary>Details</summary>
Motivation: 现有人类为中心的计算机视觉模型需庞大数据、昂贵计算资源和消耗极大的推理成本。论文试图解决高效、低成本数据获取与模型训练问题，并关注数据来源合法性和模型公平性。

Method: 利用合成数据生成技术，构建小规模但高保真度的数据集，以及配套完美标注，通过程序控制保障数据多样性，从而消除模型偏见。以三个密集预测任务（深度估计、表面法线估计与柔性前景分割）为评测点开展定量实验。

Result: 实验结果表明，该方法在真实图像上仍能保持与先进基础模型相当甚至更高的准确度，同时训练和推理成本显著降低。

Conclusion: 合成数据可高效替代昂贵且难以获得的大量真实数据，无损模型性能，同时提升数据合法合规性、用户隐私与模型公平性。

Abstract: The state of the art in human-centric computer vision achieves high accuracy
and robustness across a diverse range of tasks. The most effective models in
this domain have billions of parameters, thus requiring extremely large
datasets, expensive training regimes, and compute-intensive inference. In this
paper, we demonstrate that it is possible to train models on much smaller but
high-fidelity synthetic datasets, with no loss in accuracy and higher
efficiency. Using synthetic training data provides us with excellent levels of
detail and perfect labels, while providing strong guarantees for data
provenance, usage rights, and user consent. Procedural data synthesis also
provides us with explicit control on data diversity, that we can use to address
unfairness in the models we train. Extensive quantitative assessment on real
input images demonstrates accuracy of our models on three dense prediction
tasks: depth estimation, surface normal estimation, and soft foreground
segmentation. Our models require only a fraction of the cost of training and
inference when compared with foundational models of similar accuracy. Our
human-centric synthetic dataset and trained models are available at
https://aka.ms/DAViD.

</details>


### [103] [Rethinking Occlusion in FER: A Semantic-Aware Perspective and Go Beyond](https://arxiv.org/abs/2507.15401)
*Huiyu Zhai,Xingxing Yang,Yalan Ye,Chenyang Li,Bin Fan,Changze Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为ORSANet的新型面部表情识别方法，特别针对面部遮挡及数据集偏差问题，通过多模态引导和新损失函数提升分类准确度，同时发布了新的遮挡数据集Occlu-FER，实验结果显示性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有面部表情识别在遇到遮挡或数据集偏差时，特征提取不充分，分类准确率下降。缺乏专门针对遮挡条件的分析和数据集，限制了实际应用和模型评估。

Method: 1）引入辅助多模态语义引导，包括基于语义分割获得的密集语义先验和基于人脸关键点的稀疏几何先验；2）构建多尺度交互模块自适应融合多模态特征；3）设计动态对抗排斥增强损失，动态调整易混淆类别间间隔。

Result: 在公开基准和自建的Occlu-FER遮挡数据集上，ORSANet取得了SOTA（最优）识别性能，显著优于现有主流方法。

Conclusion: ORSANet通过多模态引导特征提取，以及创新结构与损失，显著提升了遮挡条件下的面部表情识别效果，并推动了该领域的基准建设。

Abstract: Facial expression recognition (FER) is a challenging task due to pervasive
occlusion and dataset biases. Especially when facial information is partially
occluded, existing FER models struggle to extract effective facial features,
leading to inaccurate classifications. In response, we present ORSANet, which
introduces the following three key contributions: First, we introduce auxiliary
multi-modal semantic guidance to disambiguate facial occlusion and learn
high-level semantic knowledge, which is two-fold: 1) we introduce semantic
segmentation maps as dense semantics prior to generate semantics-enhanced
facial representations; 2) we introduce facial landmarks as sparse geometric
prior to mitigate intrinsic noises in FER, such as identity and gender biases.
Second, to facilitate the effective incorporation of these two multi-modal
priors, we customize a Multi-scale Cross-interaction Module (MCM) to adaptively
fuse the landmark feature and semantics-enhanced representations within
different scales. Third, we design a Dynamic Adversarial Repulsion Enhancement
Loss (DARELoss) that dynamically adjusts the margins of ambiguous classes,
further enhancing the model's ability to distinguish similar expressions. We
further construct the first occlusion-oriented FER dataset to facilitate
specialized robustness analysis on various real-world occlusion conditions,
dubbed Occlu-FER. Extensive experiments on both public benchmarks and Occlu-FER
demonstrate that our proposed ORSANet achieves SOTA recognition performance.
Code is publicly available at https://github.com/Wenyuzhy/ORSANet-master.

</details>


### [104] [SurgX: Neuron-Concept Association for Explainable Surgical Phase Recognition](https://arxiv.org/abs/2507.15418)
*Ka Young Kim,Hyeon Bae Kim,Seong Tae Kim*

Main category: cs.CV

TL;DR: 本文提出了一种名为SurgX的新颖解释框架，通过将神经元与相关概念关联，提升手术阶段识别模型的可解释性，并在两个模型上进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 虽然深度学习方法已在手术阶段识别上取得较大进展，但模型缺乏可解释性，难以理解其决策过程，影响信任和调试。因此，提升模型可解释性是亟需解决的问题。

Method: 提出SurgX框架，包括挑选代表性神经元对应的样本序列、为手术视频数据集构建概念集合，以及分析神经元与概念间的关联，从而确定预测中关键的神经元。

Result: 作者在两种手术阶段识别模型上进行了大量实验，验证了SurgX提升了模型的解释能力，并分析了预测的解释性。

Conclusion: SurgX能够有效提升手术阶段识别模型的可解释性，为手术相关的AI算法应用与优化带来积极意义。

Abstract: Surgical phase recognition plays a crucial role in surgical workflow
analysis, enabling various applications such as surgical monitoring, skill
assessment, and workflow optimization. Despite significant advancements in deep
learning-based surgical phase recognition, these models remain inherently
opaque, making it difficult to understand how they make decisions. This lack of
interpretability hinders trust and makes it challenging to debug the model. To
address this challenge, we propose SurgX, a novel concept-based explanation
framework that enhances the interpretability of surgical phase recognition
models by associating neurons with relevant concepts. In this paper, we
introduce the process of selecting representative example sequences for
neurons, constructing a concept set tailored to the surgical video dataset,
associating neurons with concepts and identifying neurons crucial for
predictions. Through extensive experiments on two surgical phase recognition
models, we validate our method and analyze the explanation for prediction. This
highlights the potential of our method in explaining surgical phase
recognition. The code is available at https://github.com/ailab-kyunghee/SurgX

</details>


### [105] [EgoPrune: Efficient Token Pruning for Egomotion Video Reasoning in Embodied Agent](https://arxiv.org/abs/2507.15428)
*Jiaao Li,Kaiyuan Li,Chen Gao,Yong Li,Xinlei Chen*

Main category: cs.CV

TL;DR: 本文提出了EgoPrune，一种针对自运动视频高效推理的无训练token剪枝方法，在不牺牲推理性能的前提下，有效减少了冗余计算，显著降低了计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 自运动视频是具身AI最常见的视觉输入，视觉-语言模型虽然推理能力强但对长、冗余视频计算代价高昂，现有剪枝方法多为第三人称视频设计，未能充分利用自运动视频的时空连续性和运动约束，亟需高效的视频剪枝方案以便实际部署。

Method: EgoPrune包含三个核心模块：1）从EmbodiedR改进的关键帧选择器，用于高效采样关键帧；2）基于视角变换的冗余过滤（PARF），对视觉token进行对齐移除冗余信息；3）最大边际相关性（MMR）token选择器，兼顾视觉语言相关性和帧内多样性，实现token的精细筛选。该方法无须训练，即插即用。

Result: 在两个自运动视频基准上，EgoPrune在不同剪枝比例下均优于以往无训练方法，大幅降低FLOPs、内存和推理延迟，在Jetson Orin NX 16GB设备部署验证了其实用性和高效性。

Conclusion: EgoPrune能显著提升自运动视频推理的效率，为具身智能设备的落地应用提供了有效的技术支撑。

Abstract: Egomotion videos are first-person recordings where the view changes
continuously due to the agent's movement. As they serve as the primary visual
input for embodied AI agents, making egomotion video reasoning more efficient
is therefore essential for real-world deployment. Recent advances in
vision-language models have enabled strong multimodal reasoning capabilities,
but their computational cost remains prohibitive for long, redundant video
inputs. Existing token pruning methods, typically designed for third-person
videos, fail to leverage the spatiotemporal continuity and motion constraints
inherent in egomotion settings. To address this, we propose EgoPrune, a
training-free token pruning method tailored for egomotion video reasoning.
EgoPrune comprises three components: a keyframe selector adapted from EmbodiedR
for temporally efficient sampling; Perspective-Aware Redundancy Filtering
(PARF), which aligns visual tokens using perspective transformations and
removes redundant tokens; and a Maximal Marginal Relevance (MMR)-based token
selector that jointly considers visual-text relevance and intra-frame
diversity. Experiments on two egomotion video benchmarks show that EgoPrune
consistently outperforms prior training-free methods across various pruning
ratios while significantly reducing FLOPs, memory usage, and latency. Moreover,
we deploy EgoPrune on an embodied agent equipped with a Jetson Orin NX 16GB
edge device, demonstrating its real-world efficiency and suitability for
on-device egomotion video reasoning.

</details>


### [106] [One Last Attention for Your Vision-Language Model](https://arxiv.org/abs/2507.15480)
*Liang Chen,Ghazi Shazan Ahmad,Tianjun Yao,Lingqiao Liu,Zhiqiang Shen*

Main category: cs.CV

TL;DR: 本文提出了一种新的视觉-语言模型（VLMs）微调方法RAda，专注于优化多模态融合的最终表示，通过轻量注意力层动态调整特征贡献，在多种设置下提升下游性能。


<details>
  <summary>Details</summary>
Motivation: 尽管预训练的视觉-语言模型（如CLIP）在零样本任务中表现优异，但其下游任务能力很大程度上依赖于高效微调。现有方法多集中于单一模态（文本或视觉）的表示改进，忽视了最终融合表征在决策中的关键作用。为弥补这一不足，作者提出了RAda。

Method: RAda方法通过在VLM最终输出后添加轻量化注意力层，学习一个掩码（mask），动态校准融合表示中各元素的贡献。这使得在不更改中间特征的情况下，实现对最终跨模态交互的定向微调。RAda可用于不同微调场景（如更新或冻结编码器、仅用无标签测试数据的测试时训练）。

Result: RAda在多种设置下进行了实验，结果显示，无论是更新还是冻结预训练编码器，亦或是在无监督测试时训练，RAda都能以极小的代码改动提升基线性能，并在多数场景下达到当前主流技术水平。

Conclusion: RAda是一种高效、通用且易于实现的多模态融合表征微调方法，能够显著提升VLMs在各类下游任务的表现，为视觉-语言模型的进一步应用提供了有效工具。

Abstract: Pretrained vision-language models (VLMs), such as CLIP, achieve remarkable
zero-shot performance, yet their downstream potential hinges on effective
fine-tuning. Most adaptation methods typically focus on refining representation
from separate modalities (text or vision) but neglect the critical role of
their fused representations in the decision-making process, \emph{\ie} rational
matrix that drives the final prediction. To bridge the gap, we propose a simple
yet effective \textbf{R}ational \textbf{Ada}ptaion ({RAda}) to explicitly
exploit the final fused representation during fine-tuning. RAda employs a
learned mask, obtained from a lightweight attention layer attached at the end
of a VLM, to dynamically calibrate the contribution of each element in the
rational matrix, enabling targeted adjustments to the final cross-modal
interactions without incurring costly modifications to intermediate features.
Experiments in different settings (i.e., updating, or freezing pretrained
encoders in adaptation, and test-time training that can only access the
unlabeled test data) show that RAda serves as a versatile fine-tuning
technique, improving the baseline with minimal code and performing comparably
against current arts in most settings. Code is available at
\href{https://github.com/khufia/RAda/tree/main}{github.com/khufia/RAda}.

</details>


### [107] [An aerial color image anomaly dataset for search missions in complex forested terrain](https://arxiv.org/abs/2507.15492)
*Rakesh John Amala Arokia Nathan,Matthias Gessner,Nurullah Özkan,Marius Bock,Mohamed Youssef,Maximilian Mews,Björn Piltz,Ralf Berger,Oliver Bimber*

Main category: cs.CV

TL;DR: 本文介绍了在德国乡村一起家庭谋杀案后，警方为搜捕嫌犯利用遥感飞机拍摄高分辨率图像，并通过众包标注生成了遮挡条件下异常点的数据集。该数据集初步测试显示现有异常检测方法效果较差，现公开数据集和互动界面，促进该领域方法改进。


<details>
  <summary>Details</summary>
Motivation: 由于森林环境植被茂密，常规人工和自动化方法难以识别被遮挡的嫌疑人或异常线索，对大规模搜捕任务提出了新挑战。该研究希望通过数据集推动相关技术发展，提高森林环境异常检测能力。

Method: 首先通过研究飞机获取高分辨率空中图像，由于植被遮挡导致自动异常检测方法无效，研究者发起了众包搜索，收集志愿者的标注和线索，形成了遮挡条件下异常点的数据集，并进行了初步的基准测试。

Result: 该数据集包含现实世界中高度遮挡和难以检测到的异常。基于该数据集的初步测试表明，现有异常检测方法效果不佳，存在明显改进空间。

Conclusion: 公开该具有挑战性的遮挡异常点数据集，并提供交互式标注平台，可推动复杂环境下的异常检测研究，对未来的搜寻失踪人口和刑侦工作具有实际意义。

Abstract: After a family murder in rural Germany, authorities failed to locate the
suspect in a vast forest despite a massive search. To aid the search, a
research aircraft captured high-resolution aerial imagery. Due to dense
vegetation obscuring small clues, automated analysis was ineffective, prompting
a crowd-search initiative. This effort produced a unique dataset of labeled,
hard-to-detect anomalies under occluded, real-world conditions. It can serve as
a benchmark for improving anomaly detection approaches in complex forest
environments, supporting manhunts and rescue operations. Initial benchmark
tests showed existing methods performed poorly, highlighting the need for
context-aware approaches. The dataset is openly accessible for offline
processing. An additional interactive web interface supports online viewing and
dynamic growth by allowing users to annotate and submit new findings.

</details>


### [108] [Quantifying and Narrowing the Unknown: Interactive Text-to-Video Retrieval via Uncertainty Minimization](https://arxiv.org/abs/2507.15504)
*Bingqing Zhang,Zhuo Cao,Heming Du,Yang Li,Xue Li,Jiajun Liu,Sen Wang*

Main category: cs.CV

TL;DR: 提出了一种新的交互式文本-视频检索方法，通过量化和最小化三类不确定性显著提升了检索效果。


<details>
  <summary>Details</summary>
Motivation: 现有文本-视频检索方法面临文本歧义、文本与视频映射不清、视频帧质量差等不确定性问题。虽然有互动系统试图通过澄清性问题改进检索，但通常依赖启发式方法，缺乏对这些不确定性进行明确量化的方法，导致提升有限。

Method: 提出UMIVR框架，分别使用语义熵（TAS）量化文本歧义、Jensen-Shannon散度（MUS）量化文本-视频映射不确定性，以及基于时间质量的帧抽样器（TQFS）量化帧不确定性，在检索过程中自适应生成针对性澄清性问题，通过多轮交互不断消解不确定性。

Result: 在多个基准数据集上进行了大量实验，UMIVR在MSR-VTT-1k数据集的Recall@1达到了69.2%（10轮交互后），取得了显著改进。

Conclusion: UMIVR首次对交互式文本-视频检索中的多类不确定性进行明确量化和最小化，为后续相关研究提供了系统基础，并有效提升了检索性能。

Abstract: Despite recent advances, Text-to-video retrieval (TVR) is still hindered by
multiple inherent uncertainties, such as ambiguous textual queries, indistinct
text-video mappings, and low-quality video frames. Although interactive systems
have emerged to address these challenges by refining user intent through
clarifying questions, current methods typically rely on heuristic or ad-hoc
strategies without explicitly quantifying these uncertainties, limiting their
effectiveness. Motivated by this gap, we propose UMIVR, an
Uncertainty-Minimizing Interactive Text-to-Video Retrieval framework that
explicitly quantifies three critical uncertainties-text ambiguity, mapping
uncertainty, and frame uncertainty-via principled, training-free metrics:
semantic entropy-based Text Ambiguity Score (TAS), Jensen-Shannon
divergence-based Mapping Uncertainty Score (MUS), and a Temporal Quality-based
Frame Sampler (TQFS). By adaptively generating targeted clarifying questions
guided by these uncertainty measures, UMIVR iteratively refines user queries,
significantly reducing retrieval ambiguity. Extensive experiments on multiple
benchmarks validate UMIVR's effectiveness, achieving notable gains in Recall@1
(69.2\% after 10 interactive rounds) on the MSR-VTT-1k dataset, thereby
establishing an uncertainty-minimizing foundation for interactive TVR.

</details>


### [109] [SAIGFormer: A Spatially-Adaptive Illumination-Guided Network for Low-Light Image Enhancement](https://arxiv.org/abs/2507.15520)
*Hanting Li,Fei Zhou,Xin Sun,Yang Hua,Jungong Han,Liang-Jie Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的低光照图像增强方法SAIGFormer，能够有效处理非均匀照明场景，显著提升增强效果，优于现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于Transformer的低光照增强方法在恢复全局亮度方面表现良好，但对背光、阴影等非均匀照明情况恢复效果有限，常出现过曝或亮度恢复不足的问题，因此亟需能够精细建模空间光照分布的新方法。

Method: 提出了空间自适应照明引导Transformer（SAIGFormer）框架，利用动态积分图像表示建模空间变化的光照，设计了新颖的空间自适应积分照明估计器（SAI^2E），并结合照明引导多头自注意力机制（IG-MSA），提升了与亮度相关的特征校准能力。

Result: 在五个标准低光照数据集和一个跨域基准LOL-Blur上，SAIGFormer在定量和定性指标均明显优于最新方法，特别是在非均匀照明增强和跨数据集泛化性方面效果突出。

Conclusion: SAIGFormer显著改善了复杂非均匀照明下的图像增强表现，同时具备强泛化性，为低光照增强任务提供了有力的新思路。

Abstract: Recent Transformer-based low-light enhancement methods have made promising
progress in recovering global illumination. However, they still struggle with
non-uniform lighting scenarios, such as backlit and shadow, appearing as
over-exposure or inadequate brightness restoration. To address this challenge,
we present a Spatially-Adaptive Illumination-Guided Transformer (SAIGFormer)
framework that enables accurate illumination restoration. Specifically, we
propose a dynamic integral image representation to model the spatially-varying
illumination, and further construct a novel Spatially-Adaptive Integral
Illumination Estimator ($\text{SAI}^2\text{E}$). Moreover, we introduce an
Illumination-Guided Multi-head Self-Attention (IG-MSA) mechanism, which
leverages the illumination to calibrate the lightness-relevant features toward
visual-pleased illumination enhancement. Extensive experiments on five standard
low-light datasets and a cross-domain benchmark (LOL-Blur) demonstrate that our
SAIGFormer significantly outperforms state-of-the-art methods in both
quantitative and qualitative metrics. In particular, our method achieves
superior performance in non-uniform illumination enhancement while exhibiting
strong generalization capabilities across multiple datasets. Code is available
at https://github.com/LHTcode/SAIGFormer.git.

</details>


### [110] [Procedure Learning via Regularized Gromov-Wasserstein Optimal Transport](https://arxiv.org/abs/2507.15540)
*Syed Ahmed Mahmood,Ali Shah Ali,Umer Ahmed,Fawad Javed Fateh,M. Zeeshan Zia,Quoc-Huy Tran*

Main category: cs.CV

TL;DR: 本文提出了一种新的自监督程序学习框架，用于从无标注的流程视频中自动发现关键步骤及其顺序，并在多个基准数据集上表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督程序学习方法在对视频帧进行对应和排序时，容易受到顺序变化、背景杂音、冗余和重复动作的影响，导致关键步骤提取不准确。当前方法还容易陷入所有帧映射到少数关键节点的退化问题。因此，本文旨在提出一种更稳健且具结构先验的方法，提升步骤识别与排序的性能。

Method: 作者提出一种融合了Gromov-Wasserstein最优运输和结构先验的自监督框架，用于视频帧之间的高质量配对和时序对齐。为防止出现所有帧聚集于单一关键点的退化解，方法额外引入了对比性正则化约束，促使不同帧在嵌入空间映射为差异化表征。

Result: 在大规模的主观视角（EgoProceL）及第三人称（ProceL, CrossTask）流程视频数据集上进行了大量实验。结果表明，该方法在关键步骤发现与排序精度方面超越了基于Kantorovich最优运输和其他传统方法。

Conclusion: 本文所提自监督程序学习方法能有效克服顺序变异和冗余信息干扰，准确发现并排序关键步骤，显著提升了现有自监督视频流程建模的性能，具有广泛的应用价值。

Abstract: We study the problem of self-supervised procedure learning, which discovers
key steps and establishes their order from a set of unlabeled procedural
videos. Previous procedure learning methods typically learn frame-to-frame
correspondences between videos before determining key steps and their order.
However, their performance often suffers from order variations,
background/redundant frames, and repeated actions. To overcome these
challenges, we propose a self-supervised procedure learning framework, which
utilizes a fused Gromov-Wasserstein optimal transport formulation with a
structural prior for computing frame-to-frame mapping between videos. However,
optimizing exclusively for the above temporal alignment term may lead to
degenerate solutions, where all frames are mapped to a small cluster in the
embedding space and hence every video is associated with only one key step. To
address that limitation, we further integrate a contrastive regularization
term, which maps different frames to different points in the embedding space,
avoiding the collapse to trivial solutions. Finally, we conduct extensive
experiments on large-scale egocentric (i.e., EgoProceL) and third-person (i.e.,
ProceL and CrossTask) benchmarks to demonstrate superior performance by our
approach against previous methods, including OPEL which relies on a traditional
Kantorovich optimal transport formulation with an optimality prior.

</details>


### [111] [Towards Holistic Surgical Scene Graph](https://arxiv.org/abs/2507.15541)
*Jongmin Shin,Enki Cho,Ka Yong Kim,Jung Yong Kim,Seong Tae Kim,Namkee Oh*

Main category: cs.CV

TL;DR: 该论文提出了更丰富的外科手术场景图表示方法，并构建了新数据集和方法，显著提升了手术场景理解效果。


<details>
  <summary>Details</summary>
Motivation: 现有手术场景图（scene graph）方法很难全面表达工具-动作-目标及手部信息，这些要素对精准场景理解至关重要，但研究较少涉及。

Method: 作者提出Endoscapes-SG201数据集，标注了手术工具-动作-目标组合和操作手的身份。同时提出了SSG-Com方法，能够有效学习并表达这些关键信息。

Result: 在关键视图安全性评估和动作三元组识别等下游任务中，融合这些关键信息的图表示方法取得了优异性能。

Conclusion: 将工具-动作-目标和手部身份等要素纳入手术场景图，对于提升手术场景理解有显著贡献。作者的方法在多个任务中展现有效性，可为计算机辅助手术系统带来更强场景感知能力。

Abstract: Surgical scene understanding is crucial for computer-assisted intervention
systems, requiring visual comprehension of surgical scenes that involves
diverse elements such as surgical tools, anatomical structures, and their
interactions. To effectively represent the complex information in surgical
scenes, graph-based approaches have been explored to structurally model
surgical entities and their relationships. Previous surgical scene graph
studies have demonstrated the feasibility of representing surgical scenes using
graphs. However, certain aspects of surgical scenes-such as diverse
combinations of tool-action-target and the identity of the hand operating the
tool-remain underexplored in graph-based representations, despite their
importance. To incorporate these aspects into graph representations, we propose
Endoscapes-SG201 dataset, which includes annotations for tool-action-target
combinations and hand identity. We also introduce SSG-Com, a graph-based method
designed to learn and represent these critical elements. Through experiments on
downstream tasks such as critical view of safety assessment and action triplet
recognition, we demonstrated the importance of integrating these essential
scene graph components, highlighting their significant contribution to surgical
scene understanding. The code and dataset are available at
https://github.com/ailab-kyunghee/SSG-Com

</details>


### [112] [HOLa: Zero-Shot HOI Detection with Low-Rank Decomposed VLM Feature Adaptation](https://arxiv.org/abs/2507.15542)
*Qinqian Lei,Bo Wang,Robby T. Tan*

Main category: cs.CV

TL;DR: HOLa方法通过低秩分解VLM文本特征和多重权重适配，有效提升了Zero-Shot场景下的人-物交互检测能力，在HICO-DET数据集上取得了新的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有Zero-shot HOI检测方法在区分相同物体不同动作和泛化到未见类别上存在局限。因此需要一种新方法，既能提升动作区分能力，又能增强对未见类别的泛化能力。

Method: 提出了HOLa方法，利用低秩分解将VLM的文本特征分解成类别共享的基特征和可适配权重。训练中，针对每个HOI类别对权重进行自适应调整，并引入人-物token丰富视觉交互表示。为进一步区分未见动作，采用LLM指导的正则化来引导权重调整。

Result: 在HICO-DET数据集的Zero-shot设置下，HOLa在未见类别的mAP达到了27.91，刷新了当前的最优水平。

Conclusion: HOLa通过创新的特征分解和权重机制，提升了Zero-shot HOI检测的泛化能力和动作区分能力，方法效果优异，具有应用与推广价值。

Abstract: Zero-shot human-object interaction (HOI) detection remains a challenging
task, particularly in generalizing to unseen actions. Existing methods address
this challenge by tapping Vision-Language Models (VLMs) to access knowledge
beyond the training data. However, they either struggle to distinguish actions
involving the same object or demonstrate limited generalization to unseen
classes. In this paper, we introduce HOLa (Zero-Shot HOI Detection with
Low-Rank Decomposed VLM Feature Adaptation), a novel approach that both
enhances generalization to unseen classes and improves action distinction. In
training, HOLa decomposes VLM text features for given HOI classes via low-rank
factorization, producing class-shared basis features and adaptable weights.
These features and weights form a compact HOI representation that preserves
shared information across classes, enhancing generalization to unseen classes.
Subsequently, we refine action distinction by adapting weights for each HOI
class and introducing human-object tokens to enrich visual interaction
representations. To further distinguish unseen actions, we guide the weight
adaptation with LLM-derived action regularization. Experimental results show
that our method sets a new state-of-the-art across zero-shot HOI settings on
HICO-DET, achieving an unseen-class mAP of 27.91 in the unseen-verb setting.
Our code is available at https://github.com/ChelsieLei/HOLa.

</details>


### [113] [DynImg: Key Frames with Visual Prompts are Good Representation for Multi-Modal Video Understanding](https://arxiv.org/abs/2507.15569)
*Xiaoyi Bao,Chenwei Xie,Hao Tang,Tingyu Weng,Xiaofeng Wang,Yun Zheng,Xingang Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为Dynamic-Image (DynImg)的视频表示方法，通过引入非关键帧作为时序提示，引导模型关注快速运动物体区域，从而改进多模态大模型（MLLMs）的视频理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解方法往往将空间和时间信息分开处理，但这导致无法准确表示快速运动物体的特征区域，尤其在处理运动模糊等问题时，影响视频时空理解效果。

Method: 提出DynImg方法，将视频中的一组非关键帧作为时序提示加入，引导模型在视觉特征提取时重点关注相关细粒度空间区域；同时，引入4D视频旋转位置编码以维护DynImg的正确顺序和时空邻接关系，增强模型对时序和空间的理解能力。

Result: 在多个主流视频理解基准上，DynImg相较当前最优方法提升了约2%的效果，验证了该方案的有效性。

Conclusion: 通过时序提示和4D位置编码，DynImg能够有效弥补传统方法的不足，提升多模态大模型在视频理解任务中的表现。

Abstract: In recent years, the introduction of Multi-modal Large Language Models
(MLLMs) into video understanding tasks has become increasingly prevalent.
However, how to effectively integrate temporal information remains a critical
research focus. Traditional approaches treat spatial and temporal information
separately. Due to issues like motion blur, it is challenging to accurately
represent the spatial information of rapidly moving objects. This can lead to
temporally important regions being underemphasized during spatial feature
extraction, which in turn hinders accurate spatio-temporal interaction and
video understanding. To address this limitation, we propose an innovative video
representation method called Dynamic-Image (DynImg). Specifically, we introduce
a set of non-key frames as temporal prompts to highlight the spatial areas
containing fast-moving objects. During the process of visual feature
extraction, these prompts guide the model to pay additional attention to the
fine-grained spatial features corresponding to these regions. Moreover, to
maintain the correct sequence for DynImg, we employ a corresponding 4D video
Rotary Position Embedding. This retains both the temporal and spatial adjacency
of DynImg, helping MLLM understand the spatio-temporal order within this
combined format. Experimental evaluations reveal that DynImg surpasses the
state-of-the-art methods by approximately 2% across multiple video
understanding benchmarks, proving the effectiveness of our temporal prompts in
enhancing video comprehension.

</details>


### [114] [GeMix: Conditional GAN-Based Mixup for Improved Medical Image Augmentation](https://arxiv.org/abs/2507.15577)
*Hugo Carlesso,Maria Eliza Patulea,Moncef Garouani,Radu Tudor Ionescu,Josiane Mothe*

Main category: cs.CV

TL;DR: 提出了一种新的医学图像分类增强方法GeMix，通过GAN生成更真实、语义更清晰的混合样本，比传统Mixup方法在COVID-19检测任务上表现更好。


<details>
  <summary>Details</summary>
Motivation: 传统的Mixup在医学图像中因像素级插值生成不真实的图像，可能会影响模型学习和下游任务的准确性。尤其在医学图像诊断等高风险应用中，需要更真实且语义一致的数据增强手段。

Method: 1) 首先基于目标数据集训练StyleGAN2-ADA生成器；2) 在增强阶段，从两个以不同类别为主的Dirichlet分布中采样标签向量，并以Beta分布系数加权融合，获得soft label；3) 用该soft label条件生成视觉连贯且沿类别流形连续分布的图像。

Result: 在COVIDx-CT-3大规模医学影像数据集和ResNet-50、ResNet-101、EfficientNet-B0等主流骨干网络上测试，GeMix结合真实数据可在宏F1指标上优于传统Mixup，并显著降低COVID-19漏检率。

Conclusion: GeMix能有效提升混合样本的语义兼容性与真实性，作为像素级Mixup的“即插即用”替代方案，增强正则化能力且无须更改训练流程，适用于医学影像等高要求场景。

Abstract: Mixup has become a popular augmentation strategy for image classification,
yet its naive pixel-wise interpolation often produces unrealistic images that
can hinder learning, particularly in high-stakes medical applications. We
propose GeMix, a two-stage framework that replaces heuristic blending with a
learned, label-aware interpolation powered by class-conditional GANs. First, a
StyleGAN2-ADA generator is trained on the target dataset. During augmentation,
we sample two label vectors from Dirichlet priors biased toward different
classes and blend them via a Beta-distributed coefficient. Then, we condition
the generator on this soft label to synthesize visually coherent images that
lie along a continuous class manifold. We benchmark GeMix on the large-scale
COVIDx-CT-3 dataset using three backbones (ResNet-50, ResNet-101,
EfficientNet-B0). When combined with real data, our method increases macro-F1
over traditional mixup for all backbones, reducing the false negative rate for
COVID-19 detection. GeMix is thus a drop-in replacement for pixel-space mixup,
delivering stronger regularization and greater semantic fidelity, without
disrupting existing training pipelines. We publicly release our code at
https://github.com/hugocarlesso/GeMix to foster reproducibility and further
research.

</details>


### [115] [Compress-Align-Detect: onboard change detection from unregistered images](https://arxiv.org/abs/2507.15578)
*Gabriele Inzerillo,Diego Valsesia,Aniello Fiengo,Enrico Magli*

Main category: cs.CV

TL;DR: 本论文提出了一种在卫星上实时进行变更检测的端到端深度学习框架，有效解决了数据存储、影像配准以及计算资源受限下的变更检测问题，实现了低功耗硬件上的高效检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统的卫星图像变更检测存在较长延迟，影响实时或近实时应用，因此急需将检测流程前移至卫星端，而这对算法复杂度、存储及配准能力提出新挑战。

Method: 作者设计了一个端到端的深度神经网络，包括三大模块：自适应压缩存储、轻量级非正射影像配准，以及时序不变高效变更检测模型，均针对嵌入式卫星计算环境优化。

Result: 各子模块与现有技术对比，集成系统在真实低功耗硬件下实现了0.7 Mpixel/s的处理速度，并在不同压缩率下F1分数表现优良。

Conclusion: 该方法是首次将图像压缩、配准与变更检测在单独端到端系统中集合，验证了在卫星端高效变更检测的可行性，为后续智能化在轨遥感应用提供了有力支撑。

Abstract: Change detection from satellite images typically incurs a delay ranging from
several hours up to days because of latency in downlinking the acquired images
and generating orthorectified image products at the ground stations; this may
preclude real- or near real-time applications. To overcome this limitation, we
propose shifting the entire change detection workflow onboard satellites. This
requires to simultaneously solve challenges in data storage, image registration
and change detection with a strict complexity constraint. In this paper, we
present a novel and efficient framework for onboard change detection that
addresses the aforementioned challenges in an end-to-end fashion with a deep
neural network composed of three interlinked submodules: (1) image compression,
tailored to minimize onboard data storage resources; (2) lightweight
co-registration of non-orthorectified multi-temporal image pairs; and (3) a
novel temporally-invariant and computationally efficient change detection
model. This is the first approach in the literature combining all these tasks
in a single end-to-end framework with the constraints dictated by onboard
processing. Experimental results compare each submodule with the current
state-of-the-art, and evaluate the performance of the overall integrated system
in realistic setting on low-power hardware. Compelling change detection results
are obtained in terms of F1 score as a function of compression rate, sustaining
a throughput of 0.7 Mpixel/s on a 15W accelerator.

</details>


### [116] [SegDT: A Diffusion Transformer-Based Segmentation Model for Medical Imaging](https://arxiv.org/abs/2507.15595)
*Salah Eddine Bekhouche,Gaby Maroun,Fadi Dornaika,Abdenour Hadid*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散Transformer（DiT）的新型医学图像分割模型SegDT，在皮肤病变分割任务中表现优异，同时兼顾高精度和快速推理。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割对于疾病诊断和治疗规划至关重要。尤其是皮肤病变分割，是皮肤癌诊断和患者监测的重要前提。当前方法在硬件消耗、推理速度与精度之间存在权衡，因此需要一种能同时保证高性能和低成本的新模型。

Method: 提出了SegDT模型，基于Diffusion Transformer（DiT）架构，并引入Rectified Flow机制，提高扩散生成质量并减少推理步骤，同时兼容主流低成本硬件。通过与多个现有方法在三个主流公开数据集上的对比，展示模型性能。

Result: SegDT在标准数据集上取得了当前最优分割结果（state-of-the-art），且推理速度快，优于多种对比模型。

Conclusion: SegDT模型兼具高性能和低硬件需求，适合实际临床应用，可为医疗专业人员提供更快更精准的图像分析工具，推动医学影像分割和深度学习诊断辅助系统的发展。

Abstract: Medical image segmentation is crucial for many healthcare tasks, including
disease diagnosis and treatment planning. One key area is the segmentation of
skin lesions, which is vital for diagnosing skin cancer and monitoring
patients. In this context, this paper introduces SegDT, a new segmentation
model based on diffusion transformer (DiT). SegDT is designed to work on
low-cost hardware and incorporates Rectified Flow, which improves the
generation quality at reduced inference steps and maintains the flexibility of
standard diffusion models. Our method is evaluated on three benchmarking
datasets and compared against several existing works, achieving
state-of-the-art results while maintaining fast inference speeds. This makes
the proposed model appealing for real-world medical applications. This work
advances the performance and capabilities of deep learning models in medical
image analysis, enabling faster, more accurate diagnostic tools for healthcare
professionals. The code is made publicly available at
\href{https://github.com/Bekhouche/SegDT}{GitHub}.

</details>


### [117] [SurfaceSplat: Connecting Surface Reconstruction and Gaussian Splatting](https://arxiv.org/abs/2507.15602)
*Zihui Gao,Jia-Wang Bian,Guosheng Lin,Hao Chen,Chunhua Shen*

Main category: cs.CV

TL;DR: 本文提出了一种结合SDF和3DGS的新型混合方法，实现了更优的稀疏视图图像表面重建和新视角渲染，在DTU和MobileBrick数据集上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: SDF方法虽然可提取几何结构但难以捕捉细节；3DGS则虽有细节但缺乏整体几何连贯性。现有方法难以兼顾两者，亟需融合优点以提升重建和渲染质量。

Method: 提出以SDF提取粗略几何结构作为基础，辅佐3DGS提升渲染一致性，并利用3DGS的新渲染结果反向细化SDF的表面重建，从而两者互补，逐步优化。

Result: 在DTU与MobileBrick数据集上的表面重建与新视角生成任务上，本方法优于当前所有主流方法。

Conclusion: 通过将SDF与3DGS优势互补，显著提升了稀疏视图下的三维重建与新视角合成效果，具备较强实用价值。

Abstract: Surface reconstruction and novel view rendering from sparse-view images are
challenging. Signed Distance Function (SDF)-based methods struggle with fine
details, while 3D Gaussian Splatting (3DGS)-based approaches lack global
geometry coherence. We propose a novel hybrid method that combines the
strengths of both approaches: SDF captures coarse geometry to enhance
3DGS-based rendering, while newly rendered images from 3DGS refine the details
of SDF for accurate surface reconstruction. As a result, our method surpasses
state-of-the-art approaches in surface reconstruction and novel view synthesis
on the DTU and MobileBrick datasets. Code will be released at
https://github.com/Gaozihui/SurfaceSplat.

</details>


### [118] [CylinderPlane: Nested Cylinder Representation for 3D-aware Image Generation](https://arxiv.org/abs/2507.15606)
*Ru Jia,Xiaozhuang Ma,Jianji Wang,Nanning Zheng*

Main category: cs.CV

TL;DR: 论文提出了一种基于圆柱坐标系的新型三维隐式表示方法CylinderPlane，有效解决了三维感知生成模型在全方位360°图像生成中的多脸伪影等问题，实现了高质量且无伪影的多视角一致性图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有三维感知图像生成模型中的Tri-plane表示，因其笛卡尔坐标系结构，导致对称区域特征混淆，从而生成360°全景时出现多脸等伪影，影响多视图一致性。因此，需探索新的隐式表达来提升生成图像的质量和一致性。

Method: 作者提出CylinderPlane，一种基于圆柱坐标系的隐式表示，将不同角度的特征明确分离，避免特征混淆。此外，引入多尺度嵌套圆柱表示，通过组合不同分辨率的圆柱来捕获复杂几何与多尺度特征，提升细节学习能力和分辨率适应性。该表示可无缝集成到各类神经渲染框架中。

Result: 在合成与真实野外数据集上的大量实验显示，该方法在生成高质量无伪影的360°图像以及多视图一致性方面显著优于现有方法。

Conclusion: CylinderPlane消除了由笛卡尔坐标系带来的特征混淆问题，实现了高分辨率、高细节、无伪影的360°全视角一致性图像生成，具有良好的通用性和集成性。

Abstract: While the proposal of the Tri-plane representation has advanced the
development of the 3D-aware image generative models, problems rooted in its
inherent structure, such as multi-face artifacts caused by sharing the same
features in symmetric regions, limit its ability to generate 360$^\circ$ view
images. In this paper, we propose CylinderPlane, a novel implicit
representation based on Cylindrical Coordinate System, to eliminate the feature
ambiguity issue and ensure multi-view consistency in 360$^\circ$. Different
from the inevitable feature entanglement in Cartesian coordinate-based
Tri-plane representation, the cylindrical coordinate system explicitly
separates features at different angles, allowing our cylindrical representation
possible to achieve high-quality, artifacts-free 360$^\circ$ image synthesis.
We further introduce the nested cylinder representation that composites
multiple cylinders at different scales, thereby enabling the model more
adaptable to complex geometry and varying resolutions. The combination of
cylinders with different resolutions can effectively capture more critical
locations and multi-scale features, greatly facilitates fine detail learning
and robustness to different resolutions. Moreover, our representation is
agnostic to implicit rendering methods and can be easily integrated into any
neural rendering pipeline. Extensive experiments on both synthetic dataset and
unstructured in-the-wild images demonstrate that our proposed representation
achieves superior performance over previous methods.

</details>


### [119] [A Survey on Efficiency Optimization Techniques for DNN-based Video Analytics: Process Systems, Algorithms, and Applications](https://arxiv.org/abs/2507.15628)
*Shanjiang Tang,Rui Huang,Hsinyu Luo,Chunjiang Wang,Ce Yu,Yusen Li,Hao Fu,Chao Sun,and Jian Xiao*

Main category: cs.CV

TL;DR: 本综述重点梳理了提升DNN视频分析效率的各种优化技术，总结了底层到应用多层面的最新进展。


<details>
  <summary>Details</summary>
Motivation: 当前视频数据激增，对视频分析的效率和准确性提出更高要求，虽然DNN保证了准确率，但效率提升仍是难题。

Method: 本综述采用自底向上的方式，系统组织并回顾了硬件支持、数据处理和算法部署等多维度的优化方法。

Result: 文章系统梳理并分类现有针对DNN视频分析效率提升的优化技术，为研究人员提供全面的参考。

Conclusion: DNN在视频分析中高度准确但效率有待提升，未来需从多角度持续优化，文章还分析了当前技术存在的问题和挑战。

Abstract: The explosive growth of video data in recent years has brought higher demands
for video analytics, where accuracy and efficiency remain the two primary
concerns. Deep neural networks (DNNs) have been widely adopted to ensure
accuracy; however, improving their efficiency in video analytics remains an
open challenge. Different from existing surveys that make summaries of
DNN-based video mainly from the accuracy optimization aspect, in this survey,
we aim to provide a thorough review of optimization techniques focusing on the
improvement of the efficiency of DNNs in video analytics. We organize existing
methods in a bottom-up manner, covering multiple perspectives such as hardware
support, data processing, operational deployment, etc. Finally, based on the
optimization framework and existing works, we analyze and discuss the problems
and challenges in the performance optimization of DNN-based video analytics.

</details>


### [120] [Experimenting active and sequential learning in a medieval music manuscript](https://arxiv.org/abs/2507.15633)
*Sachin Sharma,Federico Simonetta,Michele Flammini*

Main category: cs.CV

TL;DR: 本文研究了主动学习（AL）与序贯学习（SL）应用于中世纪音乐手稿的目标检测及版面识别，用YOLOv8进行实验，旨在减少手工标注的数据需求。结果发现传统AL方法在小样本场景下效果有限，需探索更优策略。


<details>
  <summary>Details</summary>
Motivation: 现有OMR（光学音乐识别）在对历史手稿数字化时受限于标注数据稀缺与手稿复杂性，降低了识别效率。为提升效率并减轻标注负担，需探索能有效利用少量标注的自动化方法。

Method: 采用YOLOv8作为检测模型，运用不确定性（模型置信度最低）的主动学习，实验以仅一个标注样本起步，并通过迭代标注与训练提升性能。同时结合序贯学习在新数据集进行测试。

Result: 实验表明，用较少标注样本可获得接近全监督训练的性能，但在实际手稿场景下，基于置信度的不确定性主动学习并无明显提升，暴露其在数据稀缺场景下的局限性。

Conclusion: 不确定性驱动的主动学习在老手稿OMR场景下效果有限，应探索更适用的数据高效方法。该研究为历史音乐手稿数字化提供了新思路，也为后续设计有效的数据利用策略提供了实验基础。

Abstract: Optical Music Recognition (OMR) is a cornerstone of music digitization
initiatives in cultural heritage, yet it remains limited by the scarcity of
annotated data and the complexity of historical manuscripts. In this paper, we
present a preliminary study of Active Learning (AL) and Sequential Learning
(SL) tailored for object detection and layout recognition in an old medieval
music manuscript. Leveraging YOLOv8, our system selects samples with the
highest uncertainty (lowest prediction confidence) for iterative labeling and
retraining. Our approach starts with a single annotated image and successfully
boosts performance while minimizing manual labeling. Experimental results
indicate that comparable accuracy to fully supervised training can be achieved
with significantly fewer labeled examples. We test the methodology as a
preliminary investigation on a novel dataset offered to the community by the
Anonymous project, which studies laude, a poetical-musical genre spread across
Italy during the 12th-16th Century. We show that in the manuscript at-hand,
uncertainty-based AL is not effective and advocates for more usable methods in
data-scarcity scenarios.

</details>


### [121] [Uncovering Critical Features for Deepfake Detection through the Lottery Ticket Hypothesis](https://arxiv.org/abs/2507.15636)
*Lisan Al Amin,Md. Ismail Hossain,Thanh Thi Nguyen,Tasnim Jahan,Mahbubul Islam,Faisal Quader*

Main category: cs.CV

TL;DR: 该论文研究了如何通过神经网络剪枝，在保持高深度伪造检测准确率的同时大幅减小模型体积。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术进步使合成媒体愈加逼真，对信息真实性和社会信任构成挑战，现有检测方法模型过大、原理尚不清晰，不易实际部署，亟需更高效的解决方案。

Method: 应用Lottery Ticket Hypothesis（彩票假说）于深度伪造检测，探索神经网络中‘中奖子网络’的有效性，并比较基于LTH的迭代幅度剪枝与一次性剪枝效果，结合Grad-CAM可视化分析剪枝前后网络关注区域，还验证子网络在不同数据集间的迁移能力。

Result: 在OpenForensic和FaceForensics++数据集上测试MesoNet、CNN-5和ResNet-18模型发现，多数深度伪造检测网络能保持高稀疏度下仍有较好表现，MesoNet在80%稀疏度时仅用3000参数，准确率依旧达基线的90%，LTH迭代剪枝法持续优于一次性剪枝，关键面部区域关注性得以保留，且中奖子网络具备跨数据集迁移能力。

Conclusion: LTH驱动的模型剪枝可极大提升深度伪造检测模型的部署效率，并保持较高准确率，为实际环境下高效部署深度伪造检测系统提供了新方向。

Abstract: Recent advances in deepfake technology have created increasingly convincing
synthetic media that poses significant challenges to information integrity and
social trust. While current detection methods show promise, their underlying
mechanisms remain poorly understood, and the large sizes of their models make
them challenging to deploy in resource-limited environments. This study
investigates the application of the Lottery Ticket Hypothesis (LTH) to deepfake
detection, aiming to identify the key features crucial for recognizing
deepfakes. We examine how neural networks can be efficiently pruned while
maintaining high detection accuracy. Through extensive experiments with
MesoNet, CNN-5, and ResNet-18 architectures on the OpenForensic and
FaceForensics++ datasets, we find that deepfake detection networks contain
winning tickets, i.e., subnetworks, that preserve performance even at
substantial sparsity levels. Our results indicate that MesoNet retains 56.2%
accuracy at 80% sparsity on the OpenForensic dataset, with only 3,000
parameters, which is about 90% of its baseline accuracy (62.6%). The results
also show that our proposed LTH-based iterative magnitude pruning approach
consistently outperforms one-shot pruning methods. Using Grad-CAM
visualization, we analyze how pruned networks maintain their focus on critical
facial regions for deepfake detection. Additionally, we demonstrate the
transferability of winning tickets across datasets, suggesting potential for
efficient, deployable deepfake detection systems.

</details>


### [122] [Extracting Visual Facts from Intermediate Layers for Mitigating Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2507.15652)
*Haoran Zhou,Zihan Zhang,Hao Chen*

Main category: cs.CV

TL;DR: 本文提出了一种用于多模态大模型（MLLMs）去除视觉幻觉的简单训练无关方法EVA，实现了更准确的视觉内容生成。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型常出现对象幻觉——即模型生成了似是而非但实际上并不存在于图片中的内容。研究发现，深层先验知识会大幅抑制模型对视觉信息的利用，进而引发幻觉。这一现象在中间层的机制尚不清楚，因此需要进一步分析和解决。

Method: 作者提出EVA方法：不需要重新训练，通过动态挑选最具视觉事实信息的中间层，对比原始输入和纯文本输入的输出分布，提取视觉事实知识，并比例融入最终层以校正输出logit。EVA也能无缝配合各种MLLM与生成策略，具备通用性。

Result: 在多个主流基准测试上的实验结果显示，EVA显著降低了多模态大模型的幻觉率，优于现有基线方法。

Conclusion: EVA方法高效、泛用且无需训练，能有效缓解多模态大模型的视觉幻觉问题，对提升生成的准确性有重要意义。

Abstract: Multimodal Large Language Models (MLLMs) have made significant strides by
combining visual recognition and language understanding to generate content
that is both coherent and contextually accurate. However, MLLMs continue to
struggle with object hallucinations, where models produce seemingly plausible
but factually incorrect outputs, including objects that do not exist in the
image. Recent work has revealed that the prior knowledge in MLLMs significantly
suppresses visual information in deep layers, causing hallucinatory outputs.
However, how these priors suppress visual information at the intermediate layer
stage in MLLMs remains unclear. We observe that visual factual knowledge and
the differences between intermediate-layer prior/original probability
distributions show similar evolutionary trends in intermediate layers.
Motivated by this, we introduce Decoding by Extracting Visual Facts (EVA), a
simple, training-free method that dynamically selects intermediate layers with
the most significant visual factual information. By contrasting the output
distributions of the selected layer derived from the original input and
pure-text input, EVA extracts visual factual knowledge and proportionally
incorporates it into the final layer to correct the output logits. Importantly,
EVA is model-agnostic, seamlessly integrates with various classic decoding
strategies, and is applicable across different MLLMs. We validate EVA on
widely-used benchmarks, and the results show that it significantly reduces
hallucination rates compared to baseline methods, underscoring its
effectiveness in mitigating hallucinations.

</details>


### [123] [HW-MLVQA: Elucidating Multilingual Handwritten Document Understanding with a Comprehensive VQA Benchmark](https://arxiv.org/abs/2507.15655)
*Aniket Pal,Ajoy Mondal,Minesh Mathew,C. V. Jawahar*

Main category: cs.CV

TL;DR: 本文提出了HW-MLVQA，这是一个专为多语种手写文档视觉问答建立的新型基准数据集，旨在推动多模态大模型在多语言手写文档理解方面的研究。


<details>
  <summary>Details</summary>
Motivation: 当前多语种视觉问答（MLVQA）模型对手写文档理解的能力有限，缺乏针对多语种手写文档的真实数据集和评测工具。

Method: 提出HW-MLVQA数据集，包含1600份手写文档和2400个问题-答案对，覆盖文本、图像以及图文结合三种任务模式，并设计了评测框架，可以无须真实转写文本、直接评估商用和开源OCR模型。

Result: 实现了对多模式、多语言手写文档理解任务的综合性基准评测，为多种OCR模型提供了标准化的评测平台。

Conclusion: HW-MLVQA基准将推动多语言手写文档理解的研究，促进该领域的创新与学术发展。

Abstract: The proliferation of MultiLingual Visual Question Answering (MLVQA)
benchmarks augments the capabilities of large language models (LLMs) and
multi-modal LLMs, thereby enabling them to adeptly capture the intricate
linguistic subtleties and visual complexities inherent across diverse
languages. Despite its potential, the current MLVQA model struggles to fully
utilize its capabilities when dealing with the extensive variety of handwritten
documents. This article delineates HW-MLVQA, an avant-garde VQA benchmark
meticulously crafted to mitigate the dearth of authentic Multilingual
Handwritten document comprehension. HW-MLVQA encompasses an extensive
collection of 1,600 handwritten Pages complemented by 2,400 question-answers.
Furthermore, it provides a robust benchmark evaluation framework spanning three
distinct modalities: text, image, and an integrated image & text modality. To
simulate authentic real-world contexts devoid of ground truth textual
transcriptions, we facilitates a rigorous assessment of proprietary and
open-source OCR models. The benchmark aspires to facilitate pivotal
advancements in multilingual handwritten document interpretation, fostering
innovation and scholarly inquiry within this specialized domain.

</details>


### [124] [Visual-Language Model Knowledge Distillation Method for Image Quality Assessment](https://arxiv.org/abs/2507.15680)
*Yongkang Hou,Jiarun Song*

Main category: cs.CV

TL;DR: 本文针对图像质量评估（IQA）任务，提出了一种结合视觉-语言模型知识蒸馏的新方法，兼顾模型表现与复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统的视觉-语言模型（如CLIP）在IQA中表现出色，但其参数规模大且对局部失真识别能力有限，难以在实际部署中广泛应用，因此需要一种既能保持优秀性能又能降低参数量的方法。

Method: 作者首先设计了质量分级的提示模板，引导CLIP输出相应的质量分数，并对CLIP进行微调以增强其在IQA任务中的能力。最后，提出了一种模态自适应的知识蒸馏策略，将CLIP教师模型的知识有效地迁移到结构更优、参数量更小的学生模型。

Result: 在多个IQA数据集上的实验表明，该方法不仅显著降低了模型复杂度，还超越了现有IQA方法的性能。

Conclusion: 提出的知识蒸馏方法兼具优秀的图像质量评估能力和低复杂度，为实际应用提供了有力的技术支撑，具备很强的实际部署潜力。

Abstract: Image Quality Assessment (IQA) is a core task in computer vision. Multimodal
methods based on vision-language models, such as CLIP, have demonstrated
exceptional generalization capabilities in IQA tasks. To address the issues of
excessive parameter burden and insufficient ability to identify local distorted
features in CLIP for IQA, this study proposes a visual-language model knowledge
distillation method aimed at guiding the training of models with architectural
advantages using CLIP's IQA knowledge. First, quality-graded prompt templates
were designed to guide CLIP to output quality scores. Then, CLIP is fine-tuned
to enhance its capabilities in IQA tasks. Finally, a modality-adaptive
knowledge distillation strategy is proposed to achieve guidance from the CLIP
teacher model to the student model. Our experiments were conducted on multiple
IQA datasets, and the results show that the proposed method significantly
reduces model complexity while outperforming existing IQA methods,
demonstrating strong potential for practical deployment.

</details>


### [125] [Hi^2-GSLoc: Dual-Hierarchical Gaussian-Specific Visual Relocalization for Remote Sensing](https://arxiv.org/abs/2507.15683)
*Boni Hu,Zhenyu Xia,Lin Chen,Pengcheng Han,Shuhui Bu*

Main category: cs.CV

TL;DR: 本文提出了一种基于3D高斯泼洒（3DGS）的视觉重定位方法，兼顾精度与计算效率，适用于遥感和无人机等大场景应用。


<details>
  <summary>Details</summary>
Motivation: 现有视觉重定位方法在精度、计算复杂度和可扩展性上存在权衡，且在遥感大场景中面临高海拔变化、规模巨大及领域差异带来的挑战。

Method: 作者提出了Hi^2-GSLoc双层级重定位框架，利用3DGS紧凑表达场景的几何与外观。该框架分为两个阶段：第一阶段通过稀疏高斯特定的采样策略及地标检测器实现初步位姿估计，第二阶段采用稠密逐步优化的方法精细调整位姿并验证可靠性。同时引入分区训练、GPU并行匹配和动态内存管理提升大规模适应能力。

Result: 在模拟数据、公开数据集和真实飞行实验中，方法在定位精度、召回率和计算效率方面表现出色，且能有效筛除不可靠的位姿估计。

Conclusion: 方法验证了基于3DGS的重定位框架在遥感实际应用中的有效性，兼具高准确性和高效率，适用于大规模复杂场景。

Abstract: Visual relocalization, which estimates the 6-degree-of-freedom (6-DoF) camera
pose from query images, is fundamental to remote sensing and UAV applications.
Existing methods face inherent trade-offs: image-based retrieval and pose
regression approaches lack precision, while structure-based methods that
register queries to Structure-from-Motion (SfM) models suffer from
computational complexity and limited scalability. These challenges are
particularly pronounced in remote sensing scenarios due to large-scale scenes,
high altitude variations, and domain gaps of existing visual priors. To
overcome these limitations, we leverage 3D Gaussian Splatting (3DGS) as a novel
scene representation that compactly encodes both 3D geometry and appearance. We
introduce $\mathrm{Hi}^2$-GSLoc, a dual-hierarchical relocalization framework
that follows a sparse-to-dense and coarse-to-fine paradigm, fully exploiting
the rich semantic information and geometric constraints inherent in Gaussian
primitives. To handle large-scale remote sensing scenarios, we incorporate
partitioned Gaussian training, GPU-accelerated parallel matching, and dynamic
memory management strategies. Our approach consists of two stages: (1) a sparse
stage featuring a Gaussian-specific consistent render-aware sampling strategy
and landmark-guided detector for robust and accurate initial pose estimation,
and (2) a dense stage that iteratively refines poses through coarse-to-fine
dense rasterization matching while incorporating reliability verification.
Through comprehensive evaluation on simulation data, public datasets, and real
flight experiments, we demonstrate that our method delivers competitive
localization accuracy, recall rate, and computational efficiency while
effectively filtering unreliable pose estimates. The results confirm the
effectiveness of our approach for practical remote sensing applications.

</details>


### [126] [LINR-PCGC: Lossless Implicit Neural Representations for Point Cloud Geometry Compression](https://arxiv.org/abs/2507.15686)
*Wenjie Huang,Qi Yang,Shuting Xia,He Huang,Zhu Li,Yiling Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于隐式神经表示(Implicit Neural Representation, INR)的无损点云几何压缩方法LINR-PCGC，有效提升了点云压缩速度与压缩性能，实验上显著优于传统及AI方法。


<details>
  <summary>Details</summary>
Motivation: 现有AI点云压缩方法依赖特定训练数据分布，导致在实际应用中泛化性较差。INR方法虽然分布无关性较强，但受限于编码时间和解码端模型尺寸，目前只能应用于有损压缩，缺乏有效的无损方法。

Method: 本文提出LINR-PCGC，无损点云几何压缩方法，设计了点云级分组编码框架和高效的网络初始化策略，结合多尺度SparseConv轻量级编码网络，实现了快速推理和紧凑的解码器体积。系统包含尺度上下文提取、子节点预测和模型压缩模块。该方法大大提升了编码速度和压缩效率。

Result: 在MVUB数据集上，LINR-PCGC相较主流G-PCC TMC13v23和SparsePCGC，分别减少了21.21%和21.95%的比特流，占优于传统和AI点云压缩方法。

Conclusion: LINR-PCGC作为首个INR基础上的无损点云压缩方法，在通用性、编码效率及比特流控制等方面具有显著优势，可望推动点云压缩实际应用。

Abstract: Existing AI-based point cloud compression methods struggle with dependence on
specific training data distributions, which limits their real-world deployment.
Implicit Neural Representation (INR) methods solve the above problem by
encoding overfitted network parameters to the bitstream, resulting in more
distribution-agnostic results. However, due to the limitation of encoding time
and decoder size, current INR based methods only consider lossy geometry
compression. In this paper, we propose the first INR based lossless point cloud
geometry compression method called Lossless Implicit Neural Representations for
Point Cloud Geometry Compression (LINR-PCGC). To accelerate encoding speed, we
design a group of point clouds level coding framework with an effective network
initialization strategy, which can reduce around 60% encoding time. A
lightweight coding network based on multiscale SparseConv, consisting of scale
context extraction, child node prediction, and model compression modules, is
proposed to realize fast inference and compact decoder size. Experimental
results show that our method consistently outperforms traditional and AI-based
methods: for example, with the convergence time in the MVUB dataset, our method
reduces the bitstream by approximately 21.21% compared to G-PCC TMC13v23 and
21.95% compared to SparsePCGC. Our project can be seen on
https://huangwenjie2023.github.io/LINR-PCGC/.

</details>


### [127] [DWTGS: Rethinking Frequency Regularization for Sparse-view 3D Gaussian Splatting](https://arxiv.org/abs/2507.15690)
*Hung Nguyen,Runfa Li,An Le,Truong Nguyen*

Main category: cs.CV

TL;DR: 该论文提出了DWTGS方法，通过在稀疏视角3D高斯分布重建任务中引入小波域损失，有效提升了新视角的重建质量，并优于传统的傅里叶正则化方法。


<details>
  <summary>Details</summary>
Motivation: 稀疏视角3D高斯分布重建容易在高频细节上过拟合，现有基于傅里叶的正则化方法存在参数难以调优、高频偏置等问题。为提升重建效果，作者希望通过新的频率正则化手段缓解这些问题。

Method: 论文提出DWTGS方法：利用离散小波变换（DWT），对多尺度下的小波低频子带（LL）进行直接监督，对高频子带（HH）通过自监督方式约束其稀疏性，从而在保持空间信息的同时，抑制无意义的高频噪声。

Result: 在多个公开基准测试上，DWTGS均实现了对比傅里叶方法更优的表现，展现了更好的泛化能力和更少的高频伪影。

Conclusion: DWTGS证明了小波域低频监督结合高频稀疏性强化的方法对稀疏视角3D重建任务的有效性，能提高模型的泛化能力并减少高频幻觉。

Abstract: Sparse-view 3D Gaussian Splatting (3DGS) presents significant challenges in
reconstructing high-quality novel views, as it often overfits to the
widely-varying high-frequency (HF) details of the sparse training views. While
frequency regularization can be a promising approach, its typical reliance on
Fourier transforms causes difficult parameter tuning and biases towards
detrimental HF learning. We propose DWTGS, a framework that rethinks frequency
regularization by leveraging wavelet-space losses that provide additional
spatial supervision. Specifically, we supervise only the low-frequency (LF) LL
subbands at multiple DWT levels, while enforcing sparsity on the HF HH subband
in a self-supervised manner. Experiments across benchmarks show that DWTGS
consistently outperforms Fourier-based counterparts, as this LF-centric
strategy improves generalization and reduces HF hallucinations.

</details>


### [128] [Efficient Face Image Quality Assessment via Self-training and Knowledge Distillation](https://arxiv.org/abs/2507.15709)
*Wei Sun,Weixia Zhang,Linhan Cao,Jun Jia,Xiangyang Zhu,Dandan Zhu,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本论文提出了一种高效的面部图像质量评估（FIQA）方法，通过蒸馏技术大幅降低计算复杂度，并在ICCV 2025 VQualA FIQA挑战赛中获得第一名。


<details>
  <summary>Details</summary>
Motivation: 尽管FIQA方法取得了进展，但计算复杂度高导致实际部署受到限制。作者希望开发能在实际应用中高效部署的FIQA算法。

Method: 采用两阶段方法：首先训练一个强大的教师模型，并用自训练策略提升其能力（用标注数据训练后，对未标注数据生成伪标签）；其次，将教师模型的知识蒸馏到轻量级学生模型，包括利用伪标签数据和增强后的教师模型进一步训练学生模型。

Result: 实验表明，学生模型在极低计算负担下取得了与教师模型相当的性能。其方法在ICCV 2025 VQualA FIQA Challenge中获得了第一名。

Conclusion: 该方法在保证评估准确性的同时，极大提升了计算效率，适合在实际面部相关系统中部署。

Abstract: Face image quality assessment (FIQA) is essential for various face-related
applications. Although FIQA has been extensively studied and achieved
significant progress, the computational complexity of FIQA algorithms remains a
key concern for ensuring scalability and practical deployment in real-world
systems. In this paper, we aim to develop a computationally efficient FIQA
method that can be easily deployed in real-world applications. Specifically,
our method consists of two stages: training a powerful teacher model and
distilling a lightweight student model from it. To build a strong teacher
model, we adopt a self-training strategy to improve its capacity. We first
train the teacher model using labeled face images, then use it to generate
pseudo-labels for a set of unlabeled images. These pseudo-labeled samples are
used in two ways: (1) to distill knowledge into the student model, and (2) to
combine with the original labeled images to further enhance the teacher model
through self-training. The enhanced teacher model is used to further
pseudo-label another set of unlabeled images for distilling the student models.
The student model is trained using a combination of labeled images,
pseudo-labeled images from the original teacher model, and pseudo-labeled
images from the enhanced teacher model. Experimental results demonstrate that
our student model achieves comparable performance to the teacher model with an
extremely low computational overhead. Moreover, our method achieved first place
in the ICCV 2025 VQualA FIQA Challenge. The code is available at
https://github.com/sunwei925/Efficient-FIQA.git.

</details>


### [129] [A Practical Investigation of Spatially-Controlled Image Generation with Transformers](https://arxiv.org/abs/2507.15724)
*Guoxuan Xia,Harleen Hanspal,Petru-Daniel Tudosiu,Shifeng Zhang,Sarah Parisot*

Main category: cs.CV

TL;DR: 本论文对基于Transformer的空间可控图像生成方法进行了系统性对比实验，澄清了相关文献中的一些混淆点，提出了一些有效的、简单的基线与改进方法，并分析了不同范式下的优缺点与适用场景。


<details>
  <summary>Details</summary>
Motivation: 当前空间可控的图像生成模型对用户友好，但由于模型结构、训练数据、生成范式等差异，相关方法难以直接公平对比，导致文献中存在诸多混淆和未解之处。作者意在为开发相关系统的研究人员提供清晰指引和对比分析。

Method: 作者在ImageNet数据集上，针对扩散/流式、AR等主流生成范式进行了受控实验。提出控制Token预填充作为变换器模型的高效基线；探讨采样阶段的改进，例如将classifier-free guidance扩展至控制、softmax截断等，并进一步分析了adapter方法的实际动因和表现。

Result: 实验表明：控制Token预填充作为baseline简单有效；采样阶段的增强（如扩展classifier-free guidance和softmax截断）能极大提高生成一致性；adapter法适合小数据，但在生成-控制一致性上弱于全量训练。

Conclusion: 该文为空间可控的图像生成提供了统一、清晰的实验对比，理清了不同方法优劣及适用场合，并提出了切实可行的改进思路。

Abstract: Enabling image generation models to be spatially controlled is an important
area of research, empowering users to better generate images according to their
own fine-grained specifications via e.g. edge maps, poses. Although this task
has seen impressive improvements in recent times, a focus on rapidly producing
stronger models has come at the cost of detailed and fair scientific
comparison. Differing training data, model architectures and generation
paradigms make it difficult to disentangle the factors contributing to
performance. Meanwhile, the motivations and nuances of certain approaches
become lost in the literature. In this work, we aim to provide clear takeaways
across generation paradigms for practitioners wishing to develop
transformer-based systems for spatially-controlled generation, clarifying the
literature and addressing knowledge gaps. We perform controlled experiments on
ImageNet across diffusion-based/flow-based and autoregressive (AR) models.
First, we establish control token prefilling as a simple, general and
performant baseline approach for transformers. We then investigate previously
underexplored sampling time enhancements, showing that extending
classifier-free guidance to control, as well as softmax truncation, have a
strong impact on control-generation consistency. Finally, we re-clarify the
motivation of adapter-based approaches, demonstrating that they mitigate
"forgetting" and maintain generation quality when trained on limited downstream
data, but underperform full training in terms of generation-control
consistency. Code will be released upon publication.

</details>


### [130] [TokensGen: Harnessing Condensed Tokens for Long Video Generation](https://arxiv.org/abs/2507.15728)
*Wenqi Ouyang,Zeqi Xiao,Danni Yang,Yifan Zhou,Shuai Yang,Lei Yang,Jianlou Si,Xingang Pan*

Main category: cs.CV

TL;DR: 本论文提出了一种名为TokensGen的新颖两阶段框架，实现了高一致性长视频生成，并显著缓解了内存瓶颈与长时序不连续问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的视频生成方法在生成短视频时表现出色，但当扩展至长视频时会遇到内存消耗大和时间一致性差的问题。本研究旨在找出一种可扩展且高效的方法，实现长视频生成中内容和时序的一致性。

Method: 方法包括三大核心任务：(1)短片段内部语义控制；(2)长时序一致性控制；(3)片段间无缝衔接。具体做法为：训练一个To2V（Token-to-Video）短视频扩散模型，利用视频编码器将短片段浓缩成语义丰富的token。同时引入T2To（Text-to-Token）模型，一次性生成所有视频tokens，提升全局一致性。推断阶段采用自适应FIFO-Diffusion，将各短片段自然衔接。该方法充分利用预训练短视频生成模型和浓缩token，模块化且可扩展。

Result: 实验表明，该方法能显著提升长视频在时序与内容上的一致性，同时计算资源消耗得以有效控制。生成视频过渡自然，长远一致性强，适用场景广阔。

Conclusion: 本文提出的TokensGen通过引入浓缩token和多阶段控制，实现了高效且一致性强的长视频生成。该方案为叙事、电影和模拟等领域的长视频自动生成提供了新的技术路径。

Abstract: Generating consistent long videos is a complex challenge: while
diffusion-based generative models generate visually impressive short clips,
extending them to longer durations often leads to memory bottlenecks and
long-term inconsistency. In this paper, we propose TokensGen, a novel two-stage
framework that leverages condensed tokens to address these issues. Our method
decomposes long video generation into three core tasks: (1) inner-clip semantic
control, (2) long-term consistency control, and (3) inter-clip smooth
transition. First, we train To2V (Token-to-Video), a short video diffusion
model guided by text and video tokens, with a Video Tokenizer that condenses
short clips into semantically rich tokens. Second, we introduce T2To
(Text-to-Token), a video token diffusion transformer that generates all tokens
at once, ensuring global consistency across clips. Finally, during inference,
an adaptive FIFO-Diffusion strategy seamlessly connects adjacent clips,
reducing boundary artifacts and enhancing smooth transitions. Experimental
results demonstrate that our approach significantly enhances long-term temporal
and content coherence without incurring prohibitive computational overhead. By
leveraging condensed tokens and pre-trained short video models, our method
provides a scalable, modular solution for long video generation, opening new
possibilities for storytelling, cinematic production, and immersive
simulations. Please see our project page at
https://vicky0522.github.io/tokensgen-webpage/ .

</details>


### [131] [Appearance Harmonization via Bilateral Grid Prediction with Transformers for 3DGS](https://arxiv.org/abs/2507.15748)
*Jisu Shin,Richard Shaw,Seunghyun Shin,Anton Pelykh,Zhensong Zhang,Hae-Gon Jeon,Eduardo Perez-Pellitero*

Main category: cs.CV

TL;DR: 该论文提出了一种基于Transformer的空间自适应双边网格预测方法，用于跨视图一致地纠正照片的光度变化，在3D Gaussian Splatting管线中提升重建质量并保持高效训练。


<details>
  <summary>Details</summary>
Motivation: 现代相机自带的处理流程（如曝光、白平衡、色彩校正等）常会在不同视角间引入光度不一致，影响多视图一致性，并降低新视图合成的质量。现有联合优化场景表征与外观嵌入的方法虽然能缓解该问题，但训练复杂度和计算需求较高。作者围绕提高多视图一致性与训练效率的问题提出研究。

Method: 提出一种基于Transformer的机制，预测空间自适应的双边网格（bilateral grids），以统一矫正多视图之间的光度不一致。与以往针对每个场景分别优化不同参数的方法不同，该方法不需场景专训，能在不同场景中泛化。预测出的双边网格被整合进3D Gaussian Splatting（高斯斑点）重建流程，实现实时且一致的光度校正。

Result: 该方法通过大量实验验证，能在重建质量（保真度）和收敛速度方面超越或匹配当前主流的场景特定优化方法。在多场景泛化与效率方面表现突出。

Conclusion: 所提基于Transformer的空间自适应双边网格预测方法能有效提升多视图一致性和3D重建质量，同时兼顾训练效率，无需针对每个场景专门再训练，适应性更强。

Abstract: Modern camera pipelines apply extensive on-device processing, such as
exposure adjustment, white balance, and color correction, which, while
beneficial individually, often introduce photometric inconsistencies across
views. These appearance variations violate multi-view consistency and degrade
the quality of novel view synthesis. Joint optimization of scene
representations and per-image appearance embeddings has been proposed to
address this issue, but at the cost of increased computational complexity and
slower training. In this work, we propose a transformer-based method that
predicts spatially adaptive bilateral grids to correct photometric variations
in a multi-view consistent manner, enabling robust cross-scene generalization
without the need for scene-specific retraining. By incorporating the learned
grids into the 3D Gaussian Splatting pipeline, we improve reconstruction
quality while maintaining high training efficiency. Extensive experiments show
that our approach outperforms or matches existing scene-specific optimization
methods in reconstruction fidelity and convergence speed.

</details>


### [132] [Learning from Heterogeneity: Generalizing Dynamic Facial Expression Recognition via Distributionally Robust Optimization](https://arxiv.org/abs/2507.15765)
*Feng-Qi Cui,Anyang Tong,Jinyang Huang,Jie Zhang,Dan Guo,Zhi Liu,Meng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的异质性感知分布式框架（HDF）及其两大模块，显著提升动态人脸表情识别任务下的准确性和鲁棒性，尤其适用于多源异构数据场景。


<details>
  <summary>Details</summary>
Motivation: 现有动态人脸表情识别方法在处理多源数据和个体表情多样性时，易因样本异构性导致性能下降。作者希望解决样本多样性和难样本优化失衡带来的问题，提升方法的泛化能力和鲁棒性。

Method: 提出异质性感知分布式框架（HDF），设计了两个可插拔模块：1）时间-频率分布式注意力模块（DAM），采用双分支注意力机制，平衡时序一致性与频率鲁棒性；2）分布感知缩放模块（DSM），基于梯度敏感性与信息瓶颈，动态平衡分类与对比损失，实现更稳定、判别性更强的特征学习。

Result: 在DFEW和FERV39k两个公开数据集上进行实验，HDF在表现（WAR和UAR）和鲁棒性上均优于现有方法，并在多样化与不平衡场景下表现出较强的泛化能力。

Conclusion: HDF框架和提出的模块有效提升了动态人脸表情识别在多源异构和难样本下的识别准确率和鲁棒性，具有实用推广价值。

Abstract: Dynamic Facial Expression Recognition (DFER) plays a critical role in
affective computing and human-computer interaction. Although existing methods
achieve comparable performance, they inevitably suffer from performance
degradation under sample heterogeneity caused by multi-source data and
individual expression variability. To address these challenges, we propose a
novel framework, called Heterogeneity-aware Distributional Framework (HDF), and
design two plug-and-play modules to enhance time-frequency modeling and
mitigate optimization imbalance caused by hard samples. Specifically, the
Time-Frequency Distributional Attention Module (DAM) captures both temporal
consistency and frequency robustness through a dual-branch attention design,
improving tolerance to sequence inconsistency and visual style shifts. Then,
based on gradient sensitivity and information bottleneck principles, an
adaptive optimization module Distribution-aware Scaling Module (DSM) is
introduced to dynamically balance classification and contrastive losses,
enabling more stable and discriminative representation learning. Extensive
experiments on two widely used datasets, DFEW and FERV39k, demonstrate that HDF
significantly improves both recognition accuracy and robustness. Our method
achieves superior weighted average recall (WAR) and unweighted average recall
(UAR) while maintaining strong generalization across diverse and imbalanced
scenarios. Codes are released at https://github.com/QIcita/HDF_DFER.

</details>


### [133] [Label tree semantic losses for rich multi-class medical image segmentation](https://arxiv.org/abs/2507.15777)
*Junwen Wang,Oscar MacCormac,William Rochford,Aaron Kujawa,Jonathan Shapey,Tom Vercauteren*

Main category: cs.CV

TL;DR: 本文提出了两种基于树状结构的语义损失函数，并结合最新的稀疏标注训练方法，以提升医学影像分割任务的表现，特别是在处理细分多类别标签时表现优异。实验显示本文方法在全监督脑部分割和神经外科高光谱成像两项任务上都达到了最新最优效果。


<details>
  <summary>Details</summary>
Motivation: 当前医学影像分割任务常用的学习方法对所有分割错误赋予等同的惩罚，未能利用标签间的语义层级。随着标签数量和精细度增加，此问题尤为突出，导致模型无法充分利用标签间的关系信息，影响分割精度。为此，作者旨在设计能够利用标签语义结构的损失函数以提升分割表现。

Method: 作者提出了两种基于树状标签层级的语义损失函数，能够根据标签间的语义距离差异调整误差惩罚。同时，这些损失函数被集成进近期提出的支持稀疏标注的训练方法，以保证在标注稀少场景下依然适用。

Result: 在全监督头部MRI全脑分区和带稀疏标注的神经外科高光谱影像分割两项任务上，本文方法都达到了比以往方法更优的分割效果，刷新了相关领域内的最新结果。

Conclusion: 引入树状层次结构的语义损失函数能够有效提升多类别乃至稀疏标注情况下的医学影像分割精度。该方法具有很强的泛化性和实际临床应用潜力。

Abstract: Rich and accurate medical image segmentation is poised to underpin the next
generation of AI-defined clinical practice by delineating critical anatomy for
pre-operative planning, guiding real-time intra-operative navigation, and
supporting precise post-operative assessment. However, commonly used learning
methods for medical and surgical imaging segmentation tasks penalise all errors
equivalently and thus fail to exploit any inter-class semantics in the labels
space. This becomes particularly problematic as the cardinality and richness of
labels increases to include subtly different classes. In this work, we propose
two tree-based semantic loss functions which take advantage of a hierarchical
organisation of the labels. We further incorporate our losses in a recently
proposed approach for training with sparse, background-free annotations to
extend the applicability of our proposed losses. Extensive experiments are
reported on two medical and surgical image segmentation tasks, namely head MRI
for whole brain parcellation (WBP) with full supervision and neurosurgical
hyperspectral imaging (HSI) for scene understanding with sparse annotations.
Results demonstrate that our proposed method reaches state-of-the-art
performance in both cases.

</details>


### [134] [Regularized Low-Rank Adaptation for Few-Shot Organ Segmentation](https://arxiv.org/abs/2507.15793)
*Ghassen Baklouti,Julio Silva-Rodríguez,Jose Dolz,Houda Bahig,Ismail Ben Ayed*

Main category: cs.CV

TL;DR: 本研究提出了一种动态调整内在秩的低秩适应方法，以提升医学图像分割的参数高效微调效果。该方法通过引入l1稀疏正则项和近端优化器，实现自适应秩选择，显著优于标准LoRA和其他PEFT方法。


<details>
  <summary>Details</summary>
Motivation: 当前医学图像分割领域，参数高效微调（PEFT）因其高效性和低计算开销备受关注。然而，主流的LoRA方法需要固定不可变的秩，难以满足不同下游任务的复杂性与差异化需求，因此亟需一种可以自动调整秩的PEFT方法。

Method: 受自然图像处理中相关工作的启发，本文提出医学图像分割的新方法：把可训练权重矩阵的低秩表示视为奇异值分解，在损失函数中引入l1稀疏正则项，并用近端优化器进行训练。这个稀疏正则项相当于对分解秩的约束，实现了自动搜索最优秩。方法在few-shot微调场景下评估，并与标准LoRA及其他PEFT方法进行了对比。

Result: 在基器官和新器官分割任务上，本文方法在现实few-shot微调设定下均显著优于标准LoRA及其他PEFT方法，表现出良好效率和对非最优秩初始化的鲁棒性。

Conclusion: 本文提出的动态自适应秩PEFT方法不仅提升了医学图像分割的性能，还有效解决了传统LoRA秩难以选择的问题，具有较强的实际应用潜力。

Abstract: Parameter-efficient fine-tuning (PEFT) of pre-trained foundation models is
increasingly attracting interest in medical imaging due to its effectiveness
and computational efficiency. Among these methods, Low-Rank Adaptation (LoRA)
is a notable approach based on the assumption that the adaptation inherently
occurs in a low-dimensional subspace. While it has shown good performance, its
implementation requires a fixed and unalterable rank, which might be
challenging to select given the unique complexities and requirements of each
medical imaging downstream task. Inspired by advancements in natural image
processing, we introduce a novel approach for medical image segmentation that
dynamically adjusts the intrinsic rank during adaptation. Viewing the low-rank
representation of the trainable weight matrices as a singular value
decomposition, we introduce an l_1 sparsity regularizer to the loss function,
and tackle it with a proximal optimizer. The regularizer could be viewed as a
penalty on the decomposition rank. Hence, its minimization enables to find
task-adapted ranks automatically. Our method is evaluated in a realistic
few-shot fine-tuning setting, where we compare it first to the standard LoRA
and then to several other PEFT methods across two distinguishable tasks: base
organs and novel organs. Our extensive experiments demonstrate the significant
performance improvements driven by our method, highlighting its efficiency and
robustness against suboptimal rank initialization. Our code is publicly
available: https://github.com/ghassenbaklouti/ARENA

</details>


### [135] [Exploring Superposition and Interference in State-of-the-Art Low-Parameter Vision Models](https://arxiv.org/abs/2507.15798)
*Lilian Hollard,Lucas Mohimont,Nathalie Gaveau,Luiz-Angelo Steffenel*

Main category: cs.CV

TL;DR: 本文评估了用于计算机视觉的低参数量深度神经网络，重点探讨瓶颈结构在超线性激活函数下的表现。通过限制特征图中的干扰，提出了一种更高效的神经网络设计，并在ImageNet数据集上验证了新架构（NoDepth Bottleneck）的有效性。


<details>
  <summary>Details</summary>
Motivation: 目前对高效、参数量少的深度神经网络有强烈需求，尤其在资源有限的场景。尽管已有一些高性能架构，但瓶颈结构中神经元特征叠加（干扰）尚未得到系统研究。

Method: 作者研究了不同的瓶颈网络架构，重点分析了在使用超线性激活函数时，特征图互相干扰现象，并通过实验探查减少干扰的关键设计要素。据此，开发并提出了NoDepth Bottleneck这一概念验证性新架构。

Result: 新提出的NoDepth Bottleneck架构在低参数范围（<1.5M参数）内，在ImageNet上实现了良好的扩展性和准确率。相关实验验证了设计理念的有效性。

Conclusion: 通过减少特征图干扰，低参数神经网络能获得更优性能。提出的NoDepth Bottleneck架构为低参数视觉网络设计提供了新思路，并深化了对瓶颈结构本质的理解。

Abstract: The paper investigates the performance of state-of-the-art low-parameter deep
neural networks for computer vision, focusing on bottleneck architectures and
their behavior using superlinear activation functions. We address interference
in feature maps, a phenomenon associated with superposition, where neurons
simultaneously encode multiple characteristics. Our research suggests that
limiting interference can enhance scaling and accuracy in very low-scaled
networks (under 1.5M parameters). We identify key design elements that reduce
interference by examining various bottleneck architectures, leading to a more
efficient neural network. Consequently, we propose a proof-of-concept
architecture named NoDepth Bottleneck built on mechanistic insights from our
experiments, demonstrating robust scaling accuracy on the ImageNet dataset.
These findings contribute to more efficient and scalable neural networks for
the low-parameter range and advance the understanding of bottlenecks in
computer vision. https://caiac.pubpub.org/pub/3dh6rsel

</details>


### [136] [ConformalSAM: Unlocking the Potential of Foundational Segmentation Models in Semi-Supervised Semantic Segmentation with Conformal Prediction](https://arxiv.org/abs/2507.15803)
*Danhui Chen,Ziquan Liu,Chuxi Yang,Dan Wang,Yan Yan,Yi Xu,Xiangyang Ji*

Main category: cs.CV

TL;DR: 本研究提出了一种新的半监督语义分割框架ConformalSAM，通过结合基础分割模型和不确定性校准，有效提升了利用未标注数据进行像素级分割的性能，并在多个标准基准上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 像素级视觉任务（如语义分割）需要大量高质量标注数据，数据标注成本高昂。本文针对如何在标注匮乏情境下，充分利用基础分割模型和未标注数据，提升半监督语义分割性能的问题展开研究。

Method: 作者利用SEEM（一种针对文本输入微调的分割模型）为未标注数据生成预测mask，并提出ConformalSAM框架：首先用目标领域的标注数据对基础模型做不确定性校准，再筛除不可靠的像素标签，仅利用高置信度标签进行训练；后期采用自监督策略缓解对SEEM标签的过拟合。

Result: 在三个标准半监督语义分割基准上，ConformalSAM取得了优于近期主流方法的性能，并可作为插件提升现有方法的表现。

Conclusion: ConformalSAM充分发挥了基础分割模型在标签稀缺场景下的可靠性，并通过不确定性校准和自监督训练，推动半监督语义分割的性能提升，具有良好的实际应用前景。

Abstract: Pixel-level vision tasks, such as semantic segmentation, require extensive
and high-quality annotated data, which is costly to obtain. Semi-supervised
semantic segmentation (SSSS) has emerged as a solution to alleviate the
labeling burden by leveraging both labeled and unlabeled data through
self-training techniques. Meanwhile, the advent of foundational segmentation
models pre-trained on massive data, has shown the potential to generalize
across domains effectively. This work explores whether a foundational
segmentation model can address label scarcity in the pixel-level vision task as
an annotator for unlabeled images. Specifically, we investigate the efficacy of
using SEEM, a Segment Anything Model (SAM) variant fine-tuned for textual
input, to generate predictive masks for unlabeled data. To address the
shortcomings of using SEEM-generated masks as supervision, we propose
ConformalSAM, a novel SSSS framework which first calibrates the foundation
model using the target domain's labeled data and then filters out unreliable
pixel labels of unlabeled data so that only high-confidence labels are used as
supervision. By leveraging conformal prediction (CP) to adapt foundation models
to target data through uncertainty calibration, ConformalSAM exploits the
strong capability of the foundational segmentation model reliably which
benefits the early-stage learning, while a subsequent self-reliance training
strategy mitigates overfitting to SEEM-generated masks in the later training
stage. Our experiment demonstrates that, on three standard benchmarks of SSSS,
ConformalSAM achieves superior performance compared to recent SSSS methods and
helps boost the performance of those methods as a plug-in.

</details>


### [137] [True Multimodal In-Context Learning Needs Attention to the Visual Context](https://arxiv.org/abs/2507.15807)
*Shuo Chen,Jianzhe Liu,Zhen Han,Yan Xia,Daniel Cremers,Philip Torr,Volker Tresp,Jindong Gu*

Main category: cs.CV

TL;DR: 本论文针对多模态大语言模型（MLLMs）在多模态上下文学习（MICL）中，未能有效利用视觉信息，仅依赖文本模式的问题，提出了一种动态注意力重分配（DARA）方法以及专门的数据集TrueMICL，以提升多模态学习能力。实验表明该方法显著提升了模型在结合图像与文本信息进行任务完成时的性能。


<details>
  <summary>Details</summary>
Motivation: 虽然MLLMs在一些视觉-语言任务上表现提升，但它们往往忽视视觉线索，过于依赖文本，从而使MICL变成实质上是单模态的，难以真实发挥多模态优势且掩盖了模型的局限性。目前关于如何有效增强和评估MICL能力的研究还很缺乏。

Method: 作者提出了一种名为动态注意力重分配（DARA）的高效微调策略，鼓励模型更加关注视觉信息，通过重新平衡模型对视觉和文本信息的注意力，提高多模态能力。此外，作者设计了专门针对MICL的TrueMICL数据集，任务完成必须整合视觉与文本信息，能更真实地考查模型的多模态学习能力。

Result: 大量实验显示，采用DARA微调策略与TrueMICL数据集后，模型在真正多模态上下文学习任务中取得了显著提升，充分展示了提升后的有效多模态理解和推理能力。

Conclusion: 本文提出的方法和数据集能有效解决当前MLLMs在MICL中忽视视觉信息的问题，实现更真实和泛化的多模态学习，为多模态任务实际应用打下坚实基础。

Abstract: Multimodal Large Language Models (MLLMs), built on powerful language
backbones, have enabled Multimodal In-Context Learning (MICL)-adapting to new
tasks from a few multimodal demonstrations consisting of images, questions, and
answers. Despite showing noticeable improvement on standard vision-language
datasets, current MLLMs struggle to leverage visual information in the
demonstrations. Specifically, they tend to neglect visual cues and over-rely on
textual patterns, leading to mere text imitation rather than genuine multimodal
adaptation. This behavior makes MICL still unimodal and largely restricts its
practical utility. More importantly, this limitation is often concealed by the
improved performance on tasks that do not require understanding the visual
context. As a result, how to effectively enhance MICL ability and reliably
evaluate the MICL performance remains underexplored. To address these issues,
we first introduce Dynamic Attention Reallocation (DARA), an efficient
fine-tuning strategy that encourages models to attend to the visual context by
rebalancing attention across visual and textual tokens. In addition, we present
TrueMICL, an MICL-dedicated dataset with both support and test sets that
explicitly requires the integration of multimodal information-particularly
visual content-for correct task completion. Extensive experiments demonstrate
the effectiveness of our holistic solution, showcasing substantial improvements
in the true multimodal in-context learning capabilities. Code and datasets are
available at https://chenxshuo.github.io/true-micl-colm .

</details>


### [138] [Diffusion models for multivariate subsurface generation and efficient probabilistic inversion](https://arxiv.org/abs/2507.15809)
*Roberto Miele,Niklas Linde*

Main category: cs.CV

TL;DR: 本文利用扩散模型在多变量地下建模和概率反演场景中，提出了更高效、鲁棒的生成方法。改进了现有扩散后验采样方式，并提供了更好地处理条件数据、提升采样效率与计算速度的方案。


<details>
  <summary>Details</summary>
Motivation: 传统的VAE和GAN在多变量地下建模中表现有限，且后验反演方法计算代价大、鲁棒性不足。扩散模型因其训练稳定性和生成能力，成为改进的合理选择。

Method: 提出针对扩散后验采样方法的新校正策略，尤其是对Chung等人提出的方法进行了噪声的似然近似改进。方法在条件建模任务下（包括硬数据如井数据和非线性地球物理数据如地震数据）进行了测试。

Result: 方法在地质场景测试下表现为统计结果更稳健、后验分布采样更充分，计算开销明显降低。相较于原有方法，支持同时对硬数据和间接数据进行条件建模。

Conclusion: 所提方法兼具生成质量和计算效率，适用于需快速、条件反演的多变量地下建模任务，优于传统的VAE、GAN及需要外层循环的采样方法如MCMC。

Abstract: Diffusion models offer stable training and state-of-the-art performance for
deep generative modeling tasks. Here, we consider their use in the context of
multivariate subsurface modeling and probabilistic inversion. We first
demonstrate that diffusion models enhance multivariate modeling capabilities
compared to variational autoencoders and generative adversarial networks. In
diffusion modeling, the generative process involves a comparatively large
number of time steps with update rules that can be modified to account for
conditioning data. We propose different corrections to the popular Diffusion
Posterior Sampling approach by Chung et al. (2023). In particular, we introduce
a likelihood approximation accounting for the noise-contamination that is
inherent in diffusion modeling. We assess performance in a multivariate
geological scenario involving facies and correlated acoustic impedance.
Conditional modeling is demonstrated using both local hard data (well logs) and
nonlinear geophysics (fullstack seismic data). Our tests show significantly
improved statistical robustness, enhanced sampling of the posterior probability
density function and reduced computational costs, compared to the original
approach. The method can be used with both hard and indirect conditioning data,
individually or simultaneously. As the inversion is included within the
diffusion process, it is faster than other methods requiring an outer-loop
around the generative model, such as Markov chain Monte Carlo.

</details>


### [139] [Can Your Model Separate Yolks with a Water Bottle? Benchmarking Physical Commonsense Understanding in Video Generation Models](https://arxiv.org/abs/2507.15824)
*Enes Sanli,Baris Sarper Tezcan,Aykut Erdem,Erkut Erdem*

Main category: cs.CV

TL;DR: 本文提出了PhysVidBench基准，专门评估文本生成视频模型的物理常识推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管T2V（文本到视频）生成模型在视觉质量和时间连贯性上取得了进展，但它们常常不具备基本的物理常识，容易生成违背常理的视频。作者希望推动该领域模型真实物理推理能力的提升。

Method: 作者构建了PhysVidBench基准，包括383条涉及工具使用、材料属性和物体交互的高要求物理常识提示语。评测流程为：1）从提示语生成物理问题；2）用视觉-语言模型自动描述生成视频内容；3）用语言模型只基于描述来回答物理相关问题。通过这种间接评估方式，减少直接基于视频内容评测时产生的幻觉。

Result: 施用PhysVidBench基准，发现在物理推理和常识领域，现有多种主流T2V模型均有明显不足，提示模型无法正确捕捉物理合理性和工具使用等要素。

Conclusion: PhysVidBench为评估生成式视频模型的物理常识能力建立了全面、可解释的框架，尤其关注工具使用和物体可供性，有助于未来模型在物理真实感上的改进和进步。

Abstract: Recent progress in text-to-video (T2V) generation has enabled the synthesis
of visually compelling and temporally coherent videos from natural language.
However, these models often fall short in basic physical commonsense, producing
outputs that violate intuitive expectations around causality, object behavior,
and tool use. Addressing this gap, we present PhysVidBench, a benchmark
designed to evaluate the physical reasoning capabilities of T2V systems. The
benchmark includes 383 carefully curated prompts, emphasizing tool use,
material properties, and procedural interactions, and domains where physical
plausibility is crucial. For each prompt, we generate videos using diverse
state-of-the-art models and adopt a three-stage evaluation pipeline: (1)
formulate grounded physics questions from the prompt, (2) caption the generated
video with a vision-language model, and (3) task a language model to answer
several physics-involved questions using only the caption. This indirect
strategy circumvents common hallucination issues in direct video-based
evaluation. By highlighting affordances and tool-mediated actions, areas
overlooked in current T2V evaluations, PhysVidBench provides a structured,
interpretable framework for assessing physical commonsense in generative video
models.

</details>


### [140] [SeC: Advancing Complex Video Object Segmentation via Progressive Concept Construction](https://arxiv.org/abs/2507.15852)
*Zhixiong Zhang,Shuangrui Ding,Xiaoyi Dong,Songxin He,Jianfan Lin,Junsong Tang,Yuhang Zang,Yuhang Cao,Dahua Lin,Jiaqi Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新的基于概念的视频目标分割方法Segment Concept（SeC），突破了传统外观匹配的局限，通过高层次概念理解提升分割鲁棒性，并引入了新基准SeCVOS来评价模型高阶语义能力，在新基准中方法超过SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有视频目标分割方法主要依赖外观特征匹配，难以处理剧烈外观变化、遮挡和复杂场景转变，与人类具备的基于概念的稳健识别能力存在显著差距，亟需提升模型的高阶语义理解能力。

Method: 提出Segment Concept（SeC）框架，利用大规模视觉-语言模型（LVLMs）融合跨帧视觉线索，逐步构建目标对象的高层语义表示，同时在推理时根据场景复杂度自适应地结合语义推理和特征匹配策略；并发布了面向高阶概念推理的新数据集SeCVOS。

Result: SeC在新提出的SeCVOS基准上，比SAM 2.1提升了11.8个百分点，显著提升了具备概念感知力的视频目标分割表现。

Conclusion: SeC方法通过引入目标概念描述和LVLMs的语义理解能力，显著增强了视频目标分割对复杂变化和语义推理的鲁棒性，为相关领域树立了新SOTA，推动了概念驱动视觉理解的研究。

Abstract: Video Object Segmentation (VOS) is a core task in computer vision, requiring
models to track and segment target objects across video frames. Despite notable
advances with recent efforts, current techniques still lag behind human
capabilities in handling drastic visual variations, occlusions, and complex
scene changes. This limitation arises from their reliance on appearance
matching, neglecting the human-like conceptual understanding of objects that
enables robust identification across temporal dynamics. Motivated by this gap,
we propose Segment Concept (SeC), a concept-driven segmentation framework that
shifts from conventional feature matching to the progressive construction and
utilization of high-level, object-centric representations. SeC employs Large
Vision-Language Models (LVLMs) to integrate visual cues across diverse frames,
constructing robust conceptual priors. During inference, SeC forms a
comprehensive semantic representation of the target based on processed frames,
realizing robust segmentation of follow-up frames. Furthermore, SeC adaptively
balances LVLM-based semantic reasoning with enhanced feature matching,
dynamically adjusting computational efforts based on scene complexity. To
rigorously assess VOS methods in scenarios demanding high-level conceptual
reasoning and robust semantic understanding, we introduce the Semantic Complex
Scenarios Video Object Segmentation benchmark (SeCVOS). SeCVOS comprises 160
manually annotated multi-scenario videos designed to challenge models with
substantial appearance variations and dynamic scene transformations. In
particular, SeC achieves an 11.8-point improvement over SAM 2.1 on SeCVOS,
establishing a new state-of-the-art in concept-aware video object segmentation.

</details>


### [141] [Latent Denoising Makes Good Visual Tokenizers](https://arxiv.org/abs/2507.15856)
*Jiawei Yang,Tianhong Li,Lijie Fan,Yonglong Tian,Yue Wang*

Main category: cs.CV

TL;DR: 本文提出了一种针对生成模型更有效视觉分词器的设计——Latent Denoising Tokenizer（l-DeTok），通过使其嵌入直接对齐去噪目标，实验证明在多个生成模型中表现优异。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉分词器在生成模型中至关重要，但目前尚不清楚哪些属性能提高分词器效能。作者发现多数生成模型的训练过程实质上都是去噪（从噪声或掩码中重建干净信号），据此提出改进分词器的方法。

Method: 作者设计了Latent Denoising Tokenizer（l-DeTok），在训练过程中通过插值噪声和随机掩码扰动嵌入，使分词器学习在严重损坏的情况下也能较好重建图像，从而让嵌入对去噪任务更加友好。

Result: 在ImageNet 256x256大规模数据集上的实验证明，该分词器在六种主流生成模型中都优于标准分词器，表现出更强的稳健性和生成质量。

Conclusion: 去噪能力应成为分词器设计的核心原则，l-DeTok为未来分词器设计提供了新思路，突出其在生成模型中的性能提升。

Abstract: Despite their fundamental role, it remains unclear what properties could make
visual tokenizers more effective for generative modeling. We observe that
modern generative models share a conceptually similar training objective --
reconstructing clean signals from corrupted inputs such as Gaussian noise or
masking -- a process we term denoising. Motivated by this insight, we propose
aligning tokenizer embeddings directly with the downstream denoising objective,
encouraging latent embeddings to be more easily reconstructed even when heavily
corrupted. To achieve this, we introduce the Latent Denoising Tokenizer
(l-DeTok), a simple yet effective tokenizer trained to reconstruct clean images
from latent embeddings corrupted by interpolative noise and random masking.
Extensive experiments on ImageNet 256x256 demonstrate that our tokenizer
consistently outperforms standard tokenizers across six representative
generative models. Our findings highlight denoising as a fundamental design
principle for tokenizer development, and we hope it could motivate new
perspectives for future tokenizer design.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [142] [DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base](https://arxiv.org/abs/2507.14189)
*Song Mao,Lejun Cheng,Pinlong Cai,Guohang Yan,Ding Wang,Botian Shi*

Main category: cs.CL

TL;DR: 本文提出了一种用于专业领域（如金融报告）写作的多模态写作助手DeepWriter，通过结构化离线知识库和创新写作流程，提升文档的专业性和准确性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在金融等专业领域写作存在知识深度不足和幻觉（hallucination）问题，现有RAG或在线检索方案质量不稳定，因此需要改进。

Method: 提出DeepWriter助手，结合任务分解、提纲生成、多模态检索、分段书写与反思，并采用分层知识表示来提升检索效率与准确性，支持多模态信息融合。

Result: 在金融报告生成任务上，DeepWriter生成的内容在事实准确性和质量上均优于现有主流方法。

Conclusion: DeepWriter方式有效提升了长文写作的专业性与可信度，为专业领域写作提供了更优解决方案。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
various applications. However, their use as writing assistants in specialized
domains like finance, medicine, and law is often hampered by a lack of deep
domain-specific knowledge and a tendency to hallucinate. Existing solutions,
such as Retrieval-Augmented Generation (RAG), can suffer from inconsistency
across multiple retrieval steps, while online search-based methods often
degrade quality due to unreliable web content. To address these challenges, we
introduce DeepWriter, a customizable, multimodal, long-form writing assistant
that operates on a curated, offline knowledge base. DeepWriter leverages a
novel pipeline that involves task decomposition, outline generation, multimodal
retrieval, and section-by-section composition with reflection. By deeply mining
information from a structured corpus and incorporating both textual and visual
elements, DeepWriter generates coherent, factually grounded, and
professional-grade documents. We also propose a hierarchical knowledge
representation to enhance retrieval efficiency and accuracy. Our experiments on
financial report generation demonstrate that DeepWriter produces high-quality,
verifiable articles that surpasses existing baselines in factual accuracy and
generated content quality.

</details>


### [143] [Retention analysis of edited knowledge after fine-tuning](https://arxiv.org/abs/2507.14198)
*Fufang Wen,Shichang Zhang*

Main category: cs.CL

TL;DR: 这篇论文研究了大语言模型（LLMs）经过编辑后，其中的知识在后续微调过程中容易被遗忘的现象，并提出了改进知识保持的方法。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs被广泛应用，其存储的知识常需要修正和更新。模型编辑为此提供了高效方法，但尚不清楚这些被编辑知识在后续微调后的命运。理解微调对已编辑知识的影响对实际应用至关重要。

Method: 作者系统性地研究了不同微调目标对多种模型编辑技术的影响，并分析了知识遗忘现象。他们还测试了冻结与编辑内容相关层的方法以提高知识保持。

Result: 实验发现，编辑过的知识比模型预训练自带的“内在知识”更容易在微调时丢失。冻结相关层可以显著提升被编辑知识的保持度。

Conclusion: 当前模型编辑方法在知识保持方面存在重大局限，需在微调场景下对编辑稳健性进行评估。未来可通过改进模型结构（如冻结关键层）增强被编辑知识的稳健性。

Abstract: Large language models (LLMs) store vast amounts of knowledge, which often
requires updates to correct factual errors, incorporate newly acquired
information, or adapt model behavior. Model editing methods have emerged as
efficient solutions for such updates, offering localized and precise knowledge
modification at significantly lower computational cost than continual training.
In parallel, LLMs are frequently fine-tuned for a wide range of downstream
tasks. However, the effect of fine-tuning on previously edited knowledge
remains poorly understood. In this work, we systematically investigate how
different fine-tuning objectives interact with various model editing
techniques. Our findings show that edited knowledge is substantially more
susceptible to forgetting during fine-tuning than intrinsic knowledge acquired
through pre-training. This analysis highlights a key limitation of current
editing approaches and suggests that evaluating edit robustness under
downstream fine-tuning is critical for their practical deployment. We further
find that freezing layers associated with edited content can significantly
improve knowledge retention, offering insight into how future editing methods
might be made more robust.

</details>


### [144] [Open-Source LLMs Collaboration Beats Closed-Source LLMs: A Scalable Multi-Agent System](https://arxiv.org/abs/2507.14200)
*Shengji Tang,Jianjian Cao,Weihao Lin,Jiale Hong,Bo Zhang,Shuyue Hu,Lei Bai,Tao Chen,Wanli Ouyang,Peng Ye*

Main category: cs.CL

TL;DR: 本文提出了一种多开源大模型协作系统SMACS，能够通过有效整合多个开源LLM，在多个基准任务上超越主流闭源大模型。


<details>
  <summary>Details</summary>
Motivation: 当前主流闭源LLM（如GPT-4等）虽性能强大，但存在封闭、不可定制等局限。开源LLM社区发展迅速，若能高效集成多个开源模型，或许能向闭源模型发起有力挑战。作者希望探索如何利用开源协作，破解大模型领域“独家领先”的格局。

Method: 提出SMACS框架：（1）检索式先验选择（RPS），针对每个问题，以代理性能分数选出表现最佳的k个开源LLM；（2）探索-利用驱动的后验增强（EPE），通过先验淘汰促使候选回答多样化，用混合后验得分挑选高质量答案。该系统支持新模型持续集成和多任务泛化。

Result: 在八大主流基准上，整合15个开源LLM的SMACS体系，超越了最新的闭源大模型（如Claude-3.7-Sonnet、GPT-4.1、GPT-o3-mini），提升幅度分别达到12.73%、5.36%、5.28%。同时也比最佳单模型平均分（无论开源还是闭源）有额外提升。

Conclusion: 多个开源LLM的协同能有效提升整体推理能力，甚至突破闭源大模型的性能上限。SMACS为大模型集体智能和开源社区合作提供了强力范例。代码开源推动进一步研究与应用。

Abstract: This paper aims to demonstrate the potential and strengths of open-source
collectives. It leads to a promising question: Can we harness multiple
open-source LLMs to match or even beat the closed-source LLMs? To answer this,
we propose SMACS, a scalable multi-agent collaboration system (MACS) framework
with high performance. Specifically, for continuous integration of new LLMs and
generalization to diverse questions, we first propose a Retrieval-based Prior
Selection (RPS), which assigns a proxy performance score to each LLM to select
the Top-k LLMs at the instance level for any given question. Then, we propose
an Exploration-Exploitation-Driven Posterior Enhancement (EPE), encouraging the
generation of diverse responses through prior dropping and selecting the
high-quality response via a hybrid posterior score. Experiments on eight
mainstream benchmarks validate the effectiveness of our SMACS: by integrating
fifteen open-source LLMs, SMACS outperforms leading closed-source LLMs in 2025,
e.g., Claude-3.7-Sonnet (+12.73%), GPT-4.1(+5.36%) and GPT-o3-mini(+5.28%)
across multiple tasks. Remarkably, it even exceeds the average of best results
of different datasets from both open-source LLMs (+2.86%) and closed-source
LLMs (+2.04%), pushing the upper bound of intelligence. Code will be released
at https://github.com/magent4aci/SMACS.

</details>


### [145] [Let's Measure the Elephant in the Room: Facilitating Personalized Automated Analysis of Privacy Policies at Scale](https://arxiv.org/abs/2507.14214)
*Rui Zhao,Vladyslav Melnychuk,Jun Zhao,Jesse Wright,Nigel Shadbolt*

Main category: cs.CL

TL;DR: 本文提出了PoliAnalyzer，这是一个结合神经网络与符号推理的隐私政策自动分析工具，能够根据用户个性化需求检测隐私政策中的违规数据使用行为。


<details>
  <summary>Details</summary>
Motivation: 现代用户拥有大量在线账户，但很少阅读繁琐的服务条款或隐私政策，导致对自身数据如何被处理缺乏了解和掌控。该研究旨在降低用户理解隐私政策的认知负担，提升用户掌控数据权力。

Method: PoliAnalyzer运用自然语言处理（NLP）对隐私政策文本进行数据使用行为提取，产生形式化的数据条款表示，并采用确定性逻辑推理，将用户数据偏好与政策进行自动匹配，生成合规报告。扩展了现有的数据使用政策语言，支持以应用政策建模隐私政策，以数据政策建模用户偏好。

Result: 在由法律专家整理的PolicyIE数据集上，PoliAnalyzer在相关数据使用行为的识别任务中取得了90%-100%的F1-score。并结合23类典型用户画像与100个热门网站的隐私政策，自动化分析结果显示，仅约4.8%的政策条款与用户偏好冲突，帮助用户聚焦核心风险，有效减轻理解负担。

Conclusion: PoliAnalyzer可用现成NLP工具实现大规模、自动化、个性化的隐私政策分析，有助于提升数据透明度与用户对其数据的掌控感，也为推动更公平的数据利用格局提供了一种可行路径。

Abstract: In modern times, people have numerous online accounts, but they rarely read
the Terms of Service or Privacy Policy of those sites despite claiming
otherwise. This paper introduces PoliAnalyzer, a neuro-symbolic system that
assists users with personalized privacy policy analysis. PoliAnalyzer uses
Natural Language Processing (NLP) to extract formal representations of data
usage practices from policy texts. In favor of deterministic, logical inference
is applied to compare user preferences with the formal privacy policy
representation and produce a compliance report. To achieve this, we extend an
existing formal Data Terms of Use policy language to model privacy policies as
app policies and user preferences as data policies. In our evaluation using our
enriched PolicyIE dataset curated by legal experts, PoliAnalyzer demonstrated
high accuracy in identifying relevant data usage practices, achieving F1-score
of 90-100% across most tasks. Additionally, we demonstrate how PoliAnalyzer can
model diverse user data-sharing preferences, derived from prior research as 23
user profiles, and perform compliance analysis against the top 100 most-visited
websites. This analysis revealed that, on average, 95.2% of a privacy policy's
segments do not conflict with the analyzed user preferences, enabling users to
concentrate on understanding the 4.8% (636 / 13205) that violates preferences,
significantly reducing cognitive burden. Further, we identified common
practices in privacy policies that violate user expectations - such as the
sharing of location data with 3rd parties. This paper demonstrates that
PoliAnalyzer can support automated personalized privacy policy analysis at
scale using off-the-shelf NLP tools. This sheds light on a pathway to help
individuals regain control over their data and encourage societal discussions
on platform data practices to promote a fairer power dynamic.

</details>


### [146] [Beyond Architectures: Evaluating the Role of Contextual Embeddings in Detecting Bipolar Disorder on Social Media](https://arxiv.org/abs/2507.14231)
*Khalid Hasan,Jamil Saquer*

Main category: cs.CL

TL;DR: 本论文评估多种NLP模型在社交媒体文本中检测双相障碍迹象的能力，发现基于上下文的语言模型如RoBERTa和BERT效果最佳。


<details>
  <summary>Details</summary>
Motivation: 双相障碍早期症状隐匿且易受社会偏见影响，导致经常漏诊，因此需要高效的自动检测方法，社交媒体文本为发现早期迹象提供新渠道。

Method: 综合评估了变压器模型（如BERT, RoBERTa, ALBERT, ELECTRA, DistilBERT）和LSTM模型（分别基于BERT、GloVe、Word2Vec词嵌入），在Reddit注释数据集上，通过情感方差和人工判断验证数据有效性，并对各模型性能及训练时间进行对比分析。

Result: RoBERTa在F1得分上表现最佳（约98%），基于BERT嵌入的LSTM模型效果接近，采用静态词嵌入的LSTM表现极差（F1接近0）。DistilBERT则在效率与准确率之间取得平衡。

Conclusion: 上下文感知的语言模型对于检测双相障碍至关重要，研究为心理健康NLP模型选择提供了指导，也验证了这些模型辅助早期筛查的潜力。

Abstract: Bipolar disorder is a chronic mental illness frequently underdiagnosed due to
subtle early symptoms and social stigma. This paper explores the advanced
natural language processing (NLP) models for recognizing signs of bipolar
disorder based on user-generated social media text. We conduct a comprehensive
evaluation of transformer-based models (BERT, RoBERTa, ALBERT, ELECTRA,
DistilBERT) and Long Short Term Memory (LSTM) models based on contextualized
(BERT) and static (GloVe, Word2Vec) word embeddings. Experiments were performed
on a large, annotated dataset of Reddit posts after confirming their validity
through sentiment variance and judgmental analysis. Our results demonstrate
that RoBERTa achieves the highest performance among transformer models with an
F1 score of ~98% while LSTM models using BERT embeddings yield nearly identical
results. In contrast, LSTMs trained on static embeddings fail to capture
meaningful patterns, scoring near-zero F1. These findings underscore the
critical role of contextual language modeling in detecting bipolar disorder. In
addition, we report model training times and highlight that DistilBERT offers
an optimal balance between efficiency and accuracy. In general, our study
offers actionable insights for model selection in mental health NLP
applications and validates the potential of contextualized language models to
support early bipolar disorder screening.

</details>


### [147] [Language Models Change Facts Based on the Way You Talk](https://arxiv.org/abs/2507.14238)
*Matthew Kearney,Reuben Binns,Yarin Gal*

Main category: cs.CL

TL;DR: 该论文分析了大型语言模型在面对含有用户身份标记的文本时，其回复如何因用户的种族、性别、年龄等因素而产生偏差，对医疗、法律、政治、政府福利、工作薪资等关键领域的LLM应用影响进行评估。发现LLM极易受身份信息影响，导致医疗建议、薪酬建议、事实回答等领域出现不公平情况。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型广泛应用于各类影响民生的重要场景，但目前尚不清楚这些模型在决策过程中如何利用用户文本中的身份信息。作者希望揭示和量化隐藏在LLM决策中的身份偏见，并呼吁在实际部署前进行充分评估。

Method: 作者在医疗、法律、政治、福利、薪酬五大高风险领域，系统化测试含有不同身份标记的用户查询如何影响LLM的输出，具体分析了性别、种族、年龄等因素对模型输出内容的影响。此外，还开发了新工具以评估用户语言风格中身份信息的影响。

Result: 研究发现LLM对用户文本中身份标记高度敏感。具体表现为：同样症状下不同族裔用户收到的医疗建议存在差异；年龄较大（小）用户会得到更符合保守（自由）政治取向的回答；非白人求职者被推荐较低薪资，女性被推荐比男性更高薪资等现象。

Conclusion: 现有通用LLM直接应用于高风险领域可能造成医疗不平等、薪酬差距扩大、甚至不同身份人群间事实认知割裂。作者建议，在将LLM部署于实际用户应用前，需进行系统性评估和纠偏。

Abstract: Large language models (LLMs) are increasingly being used in user-facing
applications, from providing medical consultations to job interview advice.
Recent research suggests that these models are becoming increasingly proficient
at inferring identity information about the author of a piece of text from
linguistic patterns as subtle as the choice of a few words. However, little is
known about how LLMs use this information in their decision-making in
real-world applications. We perform the first comprehensive analysis of how
identity markers present in a user's writing bias LLM responses across five
different high-stakes LLM applications in the domains of medicine, law,
politics, government benefits, and job salaries. We find that LLMs are
extremely sensitive to markers of identity in user queries and that race,
gender, and age consistently influence LLM responses in these applications. For
instance, when providing medical advice, we find that models apply different
standards of care to individuals of different ethnicities for the same
symptoms; we find that LLMs are more likely to alter answers to align with a
conservative (liberal) political worldview when asked factual questions by
older (younger) individuals; and that LLMs recommend lower salaries for
non-White job applicants and higher salaries for women compared to men. Taken
together, these biases mean that the use of off-the-shelf LLMs for these
applications may cause harmful differences in medical care, foster wage gaps,
and create different political factual realities for people of different
identities. Beyond providing an analysis, we also provide new tools for
evaluating how subtle encoding of identity in users' language choices impacts
model decisions. Given the serious implications of these findings, we recommend
that similar thorough assessments of LLM use in user-facing applications are
conducted before future deployment.

</details>


### [148] [CCL-XCoT: An Efficient Cross-Lingual Knowledge Transfer Method for Mitigating Hallucination Generation](https://arxiv.org/abs/2507.14239)
*Weihua Zheng,Roy Ka-Wei Lee,Zhengyuan Liu,Kui Wu,AiTi Aw,Bowei Zou*

Main category: cs.CL

TL;DR: 本文提出了一种名为CCL-XCoT的两阶段微调框架，有效降低了多语言大模型在低资源语言下的幻觉现象，显著提升了跨语言的事实知识传递能力。


<details>
  <summary>Details</summary>
Motivation: 多语种大语言模型在低资源语言环境容易生成虚假或不准确内容（幻觉），尤其在专业领域文本生成时问题更为突出，主要因训练数据分布不均衡。为了解决幻觉问题，需要提升模型跨语言的对齐与推理能力。

Method: 提出了CCL-XCoT框架，包括两个阶段：第一阶段利用基于课程学习的对比学习和下一个词预测进行继续预训练，增强跨语言语义对齐；第二阶段在指令微调阶段，引入跨语言Chain-of-Thought（XCoT）提示，引导模型先用高资源语言推理，再用目标低资源语言生成答案。

Result: 实验结果显示，CCL-XCoT能将幻觉发生率最多降低62%，在多个语言对之间实现了事实知识的有效迁移，无需采用外部检索或多模型集成。

Conclusion: CCL-XCoT框架能够有效提高MLLMs在低资源语言及专业任务中的准确性和可靠性，为跨语言大模型幻觉问题提供了高效可行的解决方案。

Abstract: Multilingual Large Language Models(MLLMs) demonstrate strong generalization
across languages, yet they remain prone to hallucinations, especially in
low-resource languages, due to training data imbalances. These hallucinations,
which include inaccurate or fabricated outputs, are particularly problematic in
domain-specific generation tasks (Chataigner et al., 2024). To address this
challenge, we propose CCL-XCoT(Curriculum-based Contrastive Learning-based
Cross-lingual Chain-of-Thought), a two-stage fine-tuning framework for
mitigating hallucination in MLLMs. Our approach first enhances cross-lingual
semantic alignment through curriculum-based contrastive learning combined with
next-token prediction during continued pre-training. Building on this
foundation, we then introduce a cross-lingual Chain-of-Thought (XCoT) prompting
strategy during instruction fine-tuning, which guides the model to reason in a
high-resource language before generating answers in the target low-resource
language. Experimental results show that CCL-XCoT reduces hallucination rates
by up to 62% and substantially improves factual knowledge transfer across
language pairs, without relying on external retrieval or multi-model ensembles.

</details>


### [149] [HuggingGraph: Understanding the Supply Chain of LLM Ecosystem](https://arxiv.org/abs/2507.14240)
*Mohammad Shahedur Rahman,Peng Gao,Yuede Ji*

Main category: cs.CL

TL;DR: 本文针对大型语言模型（LLM）开发和部署过程中模型与数据集之间的供应链关系进行系统性分析。作者构建了一个包含近40万个节点和45万条边的异构有向图，揭示了LLM供应链的结构和发展动态。


<details>
  <summary>Details</summary>
Motivation: 随着LLM规模和复杂性不断提升，依赖海量算力和数据，模型的可获取性和安全性受到重视。由于多数LLM由基础模型、预训练模型和外部数据构建，容易继承已有的漏洞与偏见，存在合规与风险隐患。因此有必要追踪和分析模型与数据集的关系，以提升风险发现与治理能力。

Method: 本文提出了一种系统采集LLM供应链数据的方法，并基于这些数据，构建了模型-数据集异构有向图来描述二者间的全貌关系，对该图进行了拓扑结构和动态变化等多维度分析。

Result: 研究发现：1）LLM供应链图大且稀疏，呈幂律分布；2）图结构表现为核心密集连接、外围分散；3）数据集在模型训练和构建中起到关键作用；4）模型与数据集之间高度依赖且相互影响；5）该图具有较强的动态性，每日均有变更，反映生态系统的活跃和快速演化。

Conclusion: 理解LLM供应链有助于发现模型继承的潜在风险、提升公正性和合规保障。通过构建和分析模型-数据集关系图，可为后续的风险治理和生态健康管理提供有力支撑。

Abstract: Large language models (LLMs) leverage deep learning to process and predict
sequences of words from context, enabling them to perform various NLP tasks,
such as translation, summarization, question answering, and content generation.
However, the growing size and complexity of developing, training, and deploying
advanced LLMs require extensive computational resources and large datasets.
This creates a barrier for users. As a result, platforms that host models and
datasets are widely used. For example, Hugging Face, one of the most popular
platforms, hosted 1.8 million models and 450K datasets by June 2025, with no
sign of slowing down. Since many LLMs are built from base models, pre-trained
models, and external datasets, they can inherit vulnerabilities, biases, or
malicious components from earlier models or datasets. Therefore, it is critical
to understand the origin and development of these components to better detect
potential risks, improve model fairness, and ensure compliance. Motivated by
this, our project aims to study the relationships between models and datasets,
which are core components of the LLM supply chain. First, we design a method to
systematically collect LLM supply chain data. Using this data, we build a
directed heterogeneous graph to model the relationships between models and
datasets, resulting in a structure with 397,376 nodes and 453,469 edges. We
then perform various analyses and uncover several findings, such as: (i) the
LLM supply chain graph is large, sparse, and follows a power-law degree
distribution; (ii) it features a densely connected core and a fragmented
periphery; (iii) datasets play pivotal roles in training; (iv) strong
interdependence exists between models and datasets; and (v) the graph is
dynamic, with daily updates reflecting the ecosystem's ongoing evolution.

</details>


### [150] [Promptomatix: An Automatic Prompt Optimization Framework for Large Language Models](https://arxiv.org/abs/2507.14241)
*Rithesh Murthy,Ming Zhu,Liangwei Yang,Jielin Qiu,Juntao Tan,Shelby Heinecke,Huan Wang,Caiming Xiong,Silvio Savarese*

Main category: cs.CL

TL;DR: Promptomatix是一种能够自动优化提示词（prompt）的框架，可以将自然语言任务描述转化为高质量的提示，无需人工调优或领域专家参与，提升了大模型的易用性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型虽然能力强大，但模型输出质量高度依赖于输入提示词的设计。提示词工程（prompt engineering）操作复杂，对非专家不友好，缺乏自动化、标准化手段。亟需一种自动、普适、高效的提示优化方案。

Method: 提出Promptomatix框架：包括基于元提示的轻量优化器和基于DSPy的编译器，可模块化扩展。工作流程为：分析用户意图、生成合成训练数据、选择提示策略，并基于成本目标函数优化提示。核心亮点是全流程自动化，无需人工调优。

Result: 在5类任务上实证，Promptomatix性能和现有主流工具持平或更优，同时显著减少提示长度和计算开销。

Conclusion: Promptomatix能够自动、高效、可扩展地优化prompt，为非专家提供使用大语言模型的便利工具，有助于推动prompt工程的普及和实践应用。

Abstract: Large Language Models (LLMs) perform best with well-crafted prompts, yet
prompt engineering remains manual, inconsistent, and inaccessible to
non-experts. We introduce Promptomatix, an automatic prompt optimization
framework that transforms natural language task descriptions into high-quality
prompts without requiring manual tuning or domain expertise. Promptomatix
supports both a lightweight meta-prompt-based optimizer and a DSPy-powered
compiler, with modular design enabling future extension to more advanced
frameworks. The system analyzes user intent, generates synthetic training data,
selects prompting strategies, and refines prompts using cost-aware objectives.
Evaluated across 5 task categories, Promptomatix achieves competitive or
superior performance compared to existing libraries, while reducing prompt
length and computational overhead making prompt optimization scalable and
efficient.

</details>


### [151] [In-Depth and In-Breadth: Pre-training Multimodal Language Models Customized for Comprehensive Chart Understanding](https://arxiv.org/abs/2507.14298)
*Wan-Cyuan Fan,Yen-Chun Chen,Mengchen Liu,Alexander Jacobson,Lu Yuan,Leonid Sigal*

Main category: cs.CL

TL;DR: 该论文提出了ChartScope，一种针对多种图表类型进行深入理解的大型视觉语言模型，并建立了新的评测基准ChartDQA。通过高效的数据生成管道和创新的双路径训练策略，模型在不同类型图表理解任务上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有LVLMs在科学图表理解上取得了一些进展，但存在泛化性差（只针对少数图表类型进行定制）以及缺乏数据对齐预训练（导致对底层数据理解能力不足）的问题。作者希望解决这两大限制，提升模型对多类型图表的综合理解能力。

Method: 作者设计了一套高效的数据生成管道，可以自动合成涵盖多种图表类型的成对数据。提出了Dual-Path（双路径）训练策略，使模型既能精确捕获图表关键数据，也能保持对底层数据的推理能力。他们还开发了新的评测基准ChartDQA，以全面评估模型的问答和数据理解能力。

Result: 实验结果表明，ChartScope在各种类型的图表理解任务上均显著优于现有方法，展示了更强的泛化能力和数据推理水平。

Conclusion: ChartScope通过新的数据生成方法和训练策略，有效提升了LVLMs在多类型图表理解上的性能，并为未来科学图表的自动理解提供了强有力的工具和基准。

Abstract: Recent methods for customizing Large Vision Language Models (LVLMs) for
domain-specific tasks have shown promising results in scientific chart
comprehension. However, existing approaches face two major limitations: First,
they rely on paired data from only a few chart types, limiting generalization
to wide range of chart types. Secondly, they lack targeted pre-training for
chart-data alignment, which hampers the model's understanding of underlying
data. In this paper, we introduce ChartScope, an LVLM optimized for in-depth
chart comprehension across diverse chart types. We propose an efficient data
generation pipeline that synthesizes paired data for a wide range of chart
types, along with a novel Dual-Path training strategy that enabling the model
to succinctly capture essential data details while preserving robust reasoning
capabilities by incorporating reasoning over the underlying data. Lastly, we
establish ChartDQA, a new benchmark for evaluating not only question-answering
at different levels but also underlying data understanding. Experimental
results demonstrate that ChartScope significantly enhances comprehension on a
wide range of chart types. The code and data are available at
https://davidhalladay.github.io/chartscope_demo.

</details>


### [152] [Aligning Large Language Models to Low-Resource Languages through LLM-Based Selective Translation: A Systematic Study](https://arxiv.org/abs/2507.14304)
*Rakesh Paul,Anusha Kamath,Kanishk Singla,Raviraj Joshi,Utkarsh Vaidya,Sanjay Singh Chauhan,Niranjan Wartikar*

Main category: cs.CL

TL;DR: 本文提出了一种基于LLM的选择性翻译方法，有效用于提升低资源语言环境下的多语言大模型表现，尤其解决了标准翻译难以保留代码、数学表达式和结构化内容的问题。


<details>
  <summary>Details</summary>
Motivation: 多语言大模型在低资源语言上的性能远不如英语，主要由于缺少高质量的本地数据。采集新数据成本高，而直接翻译英语数据又容易损失重要内容，因此亟需新的对齐策略来提升低资源语言的性能。

Method: 提出利用LLM进行选择性翻译，针对输入文本只翻译可翻译部分，保留代码、数学、JSON等非翻译成分。系统性比较了选择性翻译与传统翻译手法，并探讨了对噪声译文的过滤和英文原文混合训练的效果。实验以印地语为例，比较了GCP与Llama-3.1-405B模型生成的译文。

Result: 实验显示，选择性翻译能更好地保留结构和关键信息，相较于普通翻译方法更有效。同时，滤除噪声、原文与译文混合训练也带来提升。

Conclusion: 选择性翻译是一种实用且行之有效的多语言大模型对齐方法，特别适合扩展到低资源语言，有助于提升LLM在多语言设定下的整体性能。

Abstract: Multilingual large language models (LLMs) often demonstrate a performance gap
between English and non-English languages, particularly in low-resource
settings. Aligning these models to low-resource languages is essential yet
challenging due to limited high-quality data. While English alignment datasets
are readily available, curating equivalent data in other languages is expensive
and time-consuming. A common workaround is to translate existing English
alignment data; however, standard translation techniques often fail to preserve
critical elements such as code, mathematical expressions, and structured
formats like JSON. In this work, we investigate LLM-based selective
translation, a technique that selectively translates only the translatable
parts of a text while preserving non-translatable content and sentence
structure. We conduct a systematic study to explore key questions around this
approach, including its effectiveness compared to vanilla translation, the
importance of filtering noisy outputs, and the benefits of mixing translated
samples with original English data during alignment. Our experiments focus on
the low-resource Indic language Hindi and compare translations generated by
Google Cloud Translation (GCP) and Llama-3.1-405B. The results highlight the
promise of selective translation as a practical and effective method for
improving multilingual alignment in LLMs.

</details>


### [153] [How LLMs Comprehend Temporal Meaning in Narratives: A Case Study in Cognitive Evaluation of LLMs](https://arxiv.org/abs/2507.14307)
*Karin de Langis,Jong Inn Park,Andreas Schramm,Bin Hu,Khanh Chi Le,Michael Mensink,Ahn Thu Tong,Dongyeop Kang*

Main category: cs.CL

TL;DR: 本研究发现大语言模型在叙事文本中的时体理解与人类存在本质差异，缺乏稳健的叙事理解能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型展现了强大的语言能力，但其背后的认知模式是否类人尚不明确。作者希望通过分析模型对叙事文本中时体（aspect）的处理，检验其是否具备类似人类的语义与语用推理能力。

Method: 利用‘专家参与-协同’探测流程，作者对基于人类实验的叙事材料进行系列有针对性的实验，测试大语言模型在时体语义表征与语用推理方面的表现。

Result: 发现大语言模型过度依赖原型特征，对时体的判断不一致，并在时体引发的因果推理上表现不佳，难以表现出真正的叙事理解。

Conclusion: 大语言模型处理叙事时体的方式与人类存在本质区别，缺乏健全的叙事理解。此外，作者提出了评估大模型认知与语言能力的标准化实验框架，以促进后续研究。

Abstract: Large language models (LLMs) exhibit increasingly sophisticated linguistic
capabilities, yet the extent to which these behaviors reflect human-like
cognition versus advanced pattern recognition remains an open question. In this
study, we investigate how LLMs process the temporal meaning of linguistic
aspect in narratives that were previously used in human studies. Using an
Expert-in-the-Loop probing pipeline, we conduct a series of targeted
experiments to assess whether LLMs construct semantic representations and
pragmatic inferences in a human-like manner. Our findings show that LLMs
over-rely on prototypicality, produce inconsistent aspectual judgments, and
struggle with causal reasoning derived from aspect, raising concerns about
their ability to fully comprehend narratives. These results suggest that LLMs
process aspect fundamentally differently from humans and lack robust narrative
understanding. Beyond these empirical findings, we develop a standardized
experimental framework for the reliable assessment of LLMs' cognitive and
linguistic capabilities.

</details>


### [154] [What Makes You CLIC: Detection of Croatian Clickbait Headlines](https://arxiv.org/abs/2507.14314)
*Marija Anđedelić,Dominik Šipek,Laura Majer,Jan Šnajder*

Main category: cs.CL

TL;DR: 本文探讨了克罗地亚语新闻标题中的clickbait自动检测，并提出了新数据集CLIC。对比微调模型与大语言模型(LLM)的in-context learning(ICL)方法，发现微调模型效果优于ICL。近一半标题含clickbait。


<details>
  <summary>Details</summary>
Motivation: 数字新闻高度依赖广告收入，导致大量耸人听闻的标题（clickbait），影响信息质量和用户信任。自动检测clickbait对于提高媒体质量尤为重要，尤其是在克罗地亚语等低资源语言领域，相关方法效果尚未明确。

Method: 作者构建了跨20年、包含主流及边缘媒体的克罗地亚语clickbait检测数据集CLIC。比较了BERTić模型微调与基于LLM的ICL方法（使用克罗地亚语和英语提示）的检测效果，并分析了clickbait的语言特征。

Result: 实验显示，近50%的新闻标题含clickbait。微调后的BERTić模型在检测效果上优于LLM的ICL方法，无论提示采用何种语言。

Conclusion: 对克罗地亚语clickbait检测，专门微调的模型效果优于一般的LLM-ICL法。新数据集和分析可助于更好理解和抑制数字媒体中的clickbait问题。

Abstract: Online news outlets operate predominantly on an advertising-based revenue
model, compelling journalists to create headlines that are often scandalous,
intriguing, and provocative -- commonly referred to as clickbait. Automatic
detection of clickbait headlines is essential for preserving information
quality and reader trust in digital media and requires both contextual
understanding and world knowledge. For this task, particularly in
less-resourced languages, it remains unclear whether fine-tuned methods or
in-context learning (ICL) yield better results. In this paper, we compile CLIC,
a novel dataset for clickbait detection of Croatian news headlines spanning a
20-year period and encompassing mainstream and fringe outlets. We fine-tune the
BERTi\'c model on this task and compare its performance to LLM-based ICL
methods with prompts both in Croatian and English. Finally, we analyze the
linguistic properties of clickbait. We find that nearly half of the analyzed
headlines contain clickbait, and that finetuned models deliver better results
than general LLMs.

</details>


### [155] [Can LLMs Infer Personality from Real World Conversations?](https://arxiv.org/abs/2507.14355)
*Jianfeng Zhu,Ruoming Jin,Karin G. Coifman*

Main category: cs.CL

TL;DR: 本文提出并使用了一个基于555份半结构化访谈的真实世界数据集，对大型语言模型（LLMs）执行人格推断任务的能力进行了评估。结果发现，尽管模型在一致性方面很好，但与真实人格得分的相关性较弱，评分之间一致性低，且模型预测有一定偏倚。


<details>
  <summary>Details</summary>
Motivation: 现有研究多依赖合成数据或缺乏心理测量有效性的社交媒体文本，难以真实评估LLM在推断人格特质上的表现。作者希望通过高质量、带有自评标准（BFI-10得分）的真实访谈数据，科学、系统地考察模型的人格推断能力。

Method: 作者构建了包含555份半结构化访谈及对应BFI-10自评分数的数据集，采用三种主流LLM（GPT-4.1 Mini、Meta-LLaMA、DeepSeek），分别用zero-shot和chain-of-thought提示进行人格特征预测，对其结果进行与真实分数的相关性、一致性和分布等多角度评估。

Result: 所有模型在测试-重测可靠性方面表现优异，但与真实自评得分的相关性很弱（Pearson相关系数最高仅0.27），模型预测之间的一致性低（Cohen’s kappa < 0.10），结果普遍偏向中高人格特质。逐步推理与更长输入只在分布层面带来有限改善，未显著提高准确性。

Conclusion: 当前主流LLM在人格特质推断上的效度有限，不适合作为心理学应用工具。后续研究需基于证据推动模型在人格测评等心理学领域的可靠性和有效性提升。

Abstract: Large Language Models (LLMs) such as OpenAI's GPT-4 and Meta's LLaMA offer a
promising approach for scalable personality assessment from open-ended
language. However, inferring personality traits remains challenging, and
earlier work often relied on synthetic data or social media text lacking
psychometric validity. We introduce a real-world benchmark of 555
semi-structured interviews with BFI-10 self-report scores for evaluating
LLM-based personality inference. Three state-of-the-art LLMs (GPT-4.1 Mini,
Meta-LLaMA, and DeepSeek) were tested using zero-shot prompting for BFI-10 item
prediction and both zero-shot and chain-of-thought prompting for Big Five trait
inference. All models showed high test-retest reliability, but construct
validity was limited: correlations with ground-truth scores were weak (max
Pearson's $r = 0.27$), interrater agreement was low (Cohen's $\kappa < 0.10$),
and predictions were biased toward moderate or high trait levels.
Chain-of-thought prompting and longer input context modestly improved
distributional alignment, but not trait-level accuracy. These results
underscore limitations in current LLM-based personality inference and highlight
the need for evidence-based development for psychological applications.

</details>


### [156] [Text-to-SQL for Enterprise Data Analytics](https://arxiv.org/abs/2507.14372)
*Albert Chen,Manas Bundele,Gaurav Ahlawat,Patrick Stetz,Zhitao Wang,Qiang Fei,Donghoon Jung,Audrey Chu,Bharadwaj Jayaraman,Ayushi Panth,Yatin Arora,Sourav Jain,Renjith Varma,Alexey Ilin,Iuliia Melnychuk,Chelsea Chueh,Joyan Sil,Xiaofeng Wang*

Main category: cs.CL

TL;DR: 本文介绍了LinkedIn开发的企业级Text-to-SQL数据洞察聊天机器人，利用知识图谱和智能SQL代理大幅提升了数据查询的自动化与准确性。该系统已经有显著内部用户基础和较高的问答准确率，为企业级文本到SQL转换应用提供了可复用方案。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型推动了Text-to-SQL技术进步，但真正部署到企业、应对实际动态且庞大的数据环境仍有很大挑战，例如数据海量、表结构复杂、用户身份多样等问题，需要新的工程化解决路径。

Method: 方法包括：1）通过挖掘数据库元数据、历史查询日志、wiki和代码等信息构建动态知识图谱，并利用聚类为不同团队或产品领域识别相关数据表；2）开发Text-to-SQL代理，基于知识图谱检索和排序上下文，生成SQL并自动修正幻觉和语法错误；3）搭建交互式聊天机器人，支持数据发现、查询生成、调试等多种意图，通过丰富UI鼓励多轮提问。

Result: 该聊天机器人在LinkedIn内部每周有超过300名活跃用户。内部基准测试中，专家评审表明有53%的自动化回答为正确或接近正确。消融实验揭示知识图谱和建模的哪些部分最关键。

Conclusion: 通过综合知识图谱与智能代理，企业可以切实打造可用的Text-to-SQL解决方案。论文总结了开发过程中的重要经验，突出知识结构化和多轮交互对实际性能的提升作用，为其他企业实施类似系统提供借鉴。

Abstract: The introduction of large language models has brought rapid progress on
Text-to-SQL benchmarks, but it is not yet easy to build a working enterprise
solution. In this paper, we present insights from building an internal chatbot
that enables LinkedIn's product managers, engineers, and operations teams to
self-serve data insights from a large, dynamic data lake. Our approach features
three components. First, we construct a knowledge graph that captures
up-to-date semantics by indexing database metadata, historical query logs,
wikis, and code. We apply clustering to identify relevant tables for each team
or product area. Second, we build a Text-to-SQL agent that retrieves and ranks
context from the knowledge graph, writes a query, and automatically corrects
hallucinations and syntax errors. Third, we build an interactive chatbot that
supports various user intents, from data discovery to query writing to
debugging, and displays responses in rich UI elements to encourage follow-up
chats. Our chatbot has over 300 weekly users. Expert review shows that 53% of
its responses are correct or close to correct on an internal benchmark set.
Through ablation studies, we identify the most important knowledge graph and
modeling components, offering a practical path for developing enterprise
Text-to-SQL solutions.

</details>


### [157] [Error-Aware Curriculum Learning for Biomedical Relation Classification](https://arxiv.org/abs/2507.14374)
*Sinchani Chakraborty,Sudeshna Sarkar,Pawan Goyal*

Main category: cs.CL

TL;DR: 本文提出了一种结合大语言模型（GPT-4o）的错误感知式师生学习框架，有效提升了生物医学文本中的关系分类（RC）性能，在多个数据集上取得了SOTA表现。


<details>
  <summary>Details</summary>
Motivation: 生物医学文本关系分类对于构建知识图谱、药物重利用和临床决策等应用至关重要，但现有方法面对模型预测错误难以纠正和提升性能。作者希望通过利用大型语言模型的指导，提升关系分类任务的表现与鲁棒性。

Method: 创新性地引入错误感知的师生框架：1）用GPT-4o分析学生模型的预测错误，分类错误类型，分配难度分数，并生成针对性的修正和知识图谱增强建议；2）用这些增强后的标注，通过指令微调训练第一代学生模型；3）该学生再批量标注更大数据集，并按难度组织数据，提供再训练第二代学生的课程学习，最终促进鲁棒的渐进式学习。4）此外，作者还基于PubMed摘要构建异构生物医学知识图谱，为关系分类任务提供上下文信息。

Result: 该方法在5个蛋白-蛋白相互作用（PPI）数据集中的4个以及药物-药物相互作用（DDI）数据集上均取得了新的SOTA表现，在ChemProt数据集上的表现也极具竞争力。

Conclusion: 通过结合大语言模型的错误分析和知识增强，基于难度的课程学习方法大幅提升了生物医学关系分类的表现，展示了该框架在构建高质量知识图谱等生物医学NLP任务中的应用前景。

Abstract: Relation Classification (RC) in biomedical texts is essential for
constructing knowledge graphs and enabling applications such as drug
repurposing and clinical decision-making. We propose an error-aware
teacher--student framework that improves RC through structured guidance from a
large language model (GPT-4o). Prediction failures from a baseline student
model are analyzed by the teacher to classify error types, assign difficulty
scores, and generate targeted remediations, including sentence rewrites and
suggestions for KG-based enrichment. These enriched annotations are used to
train a first student model via instruction tuning. This model then annotates a
broader dataset with difficulty scores and remediation-enhanced inputs. A
second student is subsequently trained via curriculum learning on this dataset,
ordered by difficulty, to promote robust and progressive learning. We also
construct a heterogeneous biomedical knowledge graph from PubMed abstracts to
support context-aware RC. Our approach achieves new state-of-the-art
performance on 4 of 5 PPI datasets and the DDI dataset, while remaining
competitive on ChemProt.

</details>


### [158] [X-Intelligence 3.0: Training and Evaluating Reasoning LLM for Semiconductor Display](https://arxiv.org/abs/2507.14430)
*Xiaolin Yan,Yangxing Liu,Jiazhang Zheng,Chi Liu,Mingyu Du,Caisheng Chen,Haoyang Liu,Ming Ding,Yuan Li,Qiuping Liao,Linfeng Li,Zhili Mei,Siyu Wan,Li Li,Ruyi Zhong,Jiangling Yu,Xule Liu,Huihui Hu,Jiameng Yue,Ruohui Cheng,Qi Yang,Liangqing Wu,Ke Zhu,Chi Zhang,Chufei Jing,Yifan Zhou,Yan Liang,Dongdong Li,Zhaohui Wang,Bin Zhao,Mingzhou Wu,Mingzhong Zhou,Peng Du,Zuomin Liao,Chao Dai,Pengfei Liang,Xiaoguang Zhu,Yu Zhang,Yu Gu,Kun Pan,Yuan Wu,Yanqing Guan,Shaojing Wu,Zikang Feng,Xianze Ma,Peishan Cheng,Wenjuan Jiang,Jing Ba,Huihao Yu,Zeping Hu,Yuan Xu,Zhiwei Liu,He Wang,Zhenguo Lin,Ming Liu,Yanhong Meng*

Main category: cs.CL

TL;DR: 本文提出了X-Intelligence 3.0，这是首个专为半导体显示行业开发的高性能推理大模型。该模型在行业相关推理和理解任务中表现优越，显著超过了更大参数量的SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在推理方面取得了巨大进展，但由于缺乏针对半导体显示行业的专业知识和训练，在该领域的应用效果有限。为了解决这一行业痛点，需要开发专门适用于该领域的推理模型。

Method: 作者首先整理并构建了面向半导体显示行业的专业知识库，并采用监督微调与强化学习提升模型推理和理解能力。开发过程中还设计了自动化专家评估框架，以及集成了行业特定的检索增强生成（RAG）机制。

Result: X-Intelligence 3.0模型尽管仅有320亿参数，但在多个评测指标上优于参数量更大的SOTA DeepSeek-R1-671B，表现出色。

Conclusion: X-Intelligence 3.0在半导体显示行业实现了高效精准的推理能力，证明小型专用模型通过专业知识整合和先进训练策略，可有效解决长期困扰行业的推理难题。

Abstract: Large language models (LLMs) have recently achieved significant advances in
reasoning and demonstrated their advantages in solving challenging problems.
Yet, their effectiveness in the semiconductor display industry remains limited
due to a lack of domain-specific training and expertise. To bridge this gap, we
present X-Intelligence 3.0, the first high-performance reasoning model
specifically developed for the semiconductor display industry. This model is
designed to deliver expert-level understanding and reasoning for the industry's
complex challenges. Leveraging a carefully curated industry knowledge base, the
model undergoes supervised fine-tuning and reinforcement learning to enhance
its reasoning and comprehension capabilities. To further accelerate
development, we implemented an automated evaluation framework that simulates
expert-level assessments. We also integrated a domain-specific
retrieval-augmented generation (RAG) mechanism, resulting in notable
performance gains on benchmark datasets. Despite its relatively compact size of
32 billion parameters, X-Intelligence 3.0 outperforms SOTA DeepSeek-R1-671B
across multiple evaluations. This demonstrates its exceptional efficiency and
establishes it as a powerful solution to the longstanding reasoning challenges
faced by the semiconductor display industry.

</details>


### [159] [XL-DURel: Finetuning Sentence Transformers for Ordinal Word-in-Context Classification](https://arxiv.org/abs/2507.14578)
*Sachin Yadav,Dominik Schlechtweg*

Main category: cs.CL

TL;DR: 本文提出了XL-DURel，一种针对有序Word-in-Context分类任务优化的多语种Sentence Transformer模型，在回归和排序等多种损失函数下均取得优于以往方法的表现。


<details>
  <summary>Details</summary>
Motivation: Word-in-Context (WiC)任务是自然语言处理中的基础问题，如何提升其有序和二分类的准确性及统一建模还存在挑战。现有模型在处理多语言和不同任务形式时表现有限，因此亟需更强的统一模型。

Method: 作者提出了XL-DURel模型，通过微调多语种Sentence Transformer，分别尝试回归和排序相关的损失函数。其中，基于复数空间角距离的排序目标在有序和二分类数据测试中效果最佳。作者还实验分析了将二分类WiC作为有序WiC特殊情形处理。

Result: 新模型在有序WiC和二分类WiC数据集上均取得比之前方法更好的表现，特别是基于角距离的目标函数有明显提升。此外，优化有序任务能进一步提升二分类任务效果。

Conclusion: 本文验证了以统一、有序建模的方式处理WiC任务的有效性，证明二分类可看作有序任务特例，为未来不同WiC任务的统一建模和性能提升打下基础。

Abstract: We propose XL-DURel, a finetuned, multilingual Sentence Transformer model
optimized for ordinal Word-in-Context classification. We test several loss
functions for regression and ranking tasks managing to outperform previous
models on ordinal and binary data with a ranking objective based on angular
distance in complex space. We further show that binary WiC can be treated as a
special case of ordinal WiC and that optimizing models for the general ordinal
task improves performance on the more specific binary task. This paves the way
for a unified treatment of WiC modeling across different task formulations.

</details>


### [160] [Exploring Human-AI Complementarity in CPS Diagnosis Using Unimodal and Multimodal BERT Models](https://arxiv.org/abs/2507.14579)
*Kester Wong,Sahan Bulathwela,Mutlu Cukurova*

Main category: cs.CL

TL;DR: 本文探讨了结合语音声学特征的多模态深度学习模型（AudiBERT）在检测协作性问题解决（CPS）指标中的表现，并与传统BERT模型进行了对比，分析其在社会-认知和情感维度下的分类效果及统计显著性。


<details>
  <summary>Details</summary>
Motivation: CPS的自动化检测在教育人工智能领域具有重要价值。此前仅基于文本的BERT已用于CPS指标检测，但在提升模型表现和人机互补协作方面尚存不足，尤其是多模态信息的整合潜力和统计显著性尚未明确。

Method: 在已有研究基础上，作者扩展并系统化地分析了AudiBERT与纯文本BERT模型在CPS指标检测中的对比表现，特别针对不同维度（社会-认知与情感）下的模型分类性能，并进行了统计显著性和相关性分析。

Result: AudiBERT在样本稀少类别及社会-认知维度上对比BERT表现出统计显著优势，但在情感维度上未见显著提升。训练数据量与召回率显著相关，而BERT模型精确率高时与人工标注者一致性好。针对AudiBERT表现佳的子技能，BERT诊断效果不一致。

Conclusion: 文章提出了一种支持人机互补的CPS诊断方法框架，强调模型可解释性对于提升人类在反思性编码过程中的主动性和参与度至关重要。

Abstract: Detecting collaborative problem solving (CPS) indicators from dialogue using
machine learning techniques is a significant challenge for the field of AI in
Education. Recent studies have explored the use of Bidirectional Encoder
Representations from Transformers (BERT) models on transcription data to
reliably detect meaningful CPS indicators. A notable advancement involved the
multimodal BERT variant, AudiBERT, which integrates speech and
acoustic-prosodic audio features to enhance CPS diagnosis. Although initial
results demonstrated multimodal improvements, the statistical significance of
these enhancements remained unclear, and there was insufficient guidance on
leveraging human-AI complementarity for CPS diagnosis tasks. This workshop
paper extends the previous research by highlighting that the AudiBERT model not
only improved the classification of classes that were sparse in the dataset,
but it also had statistically significant class-wise improvements over the BERT
model for classifications in the social-cognitive dimension. However, similar
significant class-wise improvements over the BERT model were not observed for
classifications in the affective dimension. A correlation analysis highlighted
that larger training data was significantly associated with higher recall
performance for both the AudiBERT and BERT models. Additionally, the precision
of the BERT model was significantly associated with high inter-rater agreement
among human coders. When employing the BERT model to diagnose indicators within
these subskills that were well-detected by the AudiBERT model, the performance
across all indicators was inconsistent. We conclude the paper by outlining a
structured approach towards achieving human-AI complementarity for CPS
diagnosis, highlighting the crucial inclusion of model explainability to
support human agency and engagement in the reflective coding process.

</details>


### [161] [Explainable Collaborative Problem Solving Diagnosis with BERT using SHAP and its Implications for Teacher Adoption](https://arxiv.org/abs/2507.14584)
*Kester Wong,Sahan Bulathwela,Mutlu Cukurova*

Main category: cs.CL

TL;DR: 本研究用SHAP方法探索BERT模型在协作式问题解决（CPS）分类中，各词对分类结果的贡献，揭示了高性能分类不一定意味着高合理性，并发现模型有时依靠语义无关的词。


<details>
  <summary>Details</summary>
Motivation: 虽然BERT等模型已广泛应用于CPS自动分类，但鲜有工作解释各词如何影响分类决策，理解模型内部机制有助于教师等用户放心使用AI工具，也促进其在教育界的推广。

Method: 利用SHAP可解释性工具，分析转录文本数据中不同分词（tokenized words）对BERT模型CPS分类决策的影响，考察模型在解释性和决策合理性方面的表现。

Result: 发现模型高准确率并不总代表着其分类依据合理，部分高频分词对分类影响大，甚至找到对分类有正向贡献却与类别无语义关系的杂词（spurious word）。

Conclusion: 提高模型透明度虽然可能无法直接帮助用户改进教学实践，但有助于防止用户对AI诊断盲目信任。未来需结合集成模型和人机互补，提高CPS子技能的细致区分能力。

Abstract: The use of Bidirectional Encoder Representations from Transformers (BERT)
model and its variants for classifying collaborative problem solving (CPS) has
been extensively explored within the AI in Education community. However,
limited attention has been given to understanding how individual tokenised
words in the dataset contribute to the model's classification decisions.
Enhancing the explainability of BERT-based CPS diagnostics is essential to
better inform end users such as teachers, thereby fostering greater trust and
facilitating wider adoption in education. This study undertook a preliminary
step towards model transparency and explainability by using SHapley Additive
exPlanations (SHAP) to examine how different tokenised words in transcription
data contributed to a BERT model's classification of CPS processes. The
findings suggested that well-performing classifications did not necessarily
equate to a reasonable explanation for the classification decisions. Particular
tokenised words were used frequently to affect classifications. The analysis
also identified a spurious word, which contributed positively to the
classification but was not semantically meaningful to the class. While such
model transparency is unlikely to be useful to an end user to improve their
practice, it can help them not to overrely on LLM diagnostics and ignore their
human expertise. We conclude the workshop paper by noting that the extent to
which the model appropriately uses the tokens for its classification is
associated with the number of classes involved. It calls for an investigation
into the exploration of ensemble model architectures and the involvement of
human-AI complementarity for CPS diagnosis, since considerable human reasoning
is still required for fine-grained discrimination of CPS subskills.

</details>


### [162] [Backtranslation and paraphrasing in the LLM era? Comparing data augmentation methods for emotion classification](https://arxiv.org/abs/2507.14590)
*Łukasz Radliński,Mateusz Guściora,Jan Kocoń*

Main category: cs.CL

TL;DR: 该论文系统性地评估了NLP中不同数据增强方法，重点比较传统方法（同义改写与回译）和基于大型语言模型的生成方法的性能，发现传统方法仍具竞争力。


<details>
  <summary>Details</summary>
Motivation: 许多领域特定的机器学习任务在实际中面临数据稀缺与类别不均衡的问题，论文希望通过数据增强手段，缓解这些问题，尤其是在当前大型语言模型兴起的背景下，探索传统与新方法的效用。

Method: 本文选取了典型数据集，设计了四种数据增强方法，包括传统的同义改写、回译以及基于ChatGPT等模型的零样本、少样本生成扩增，对比分析每种方法在生成数据质量以及增强后的分类性能表现。

Result: 实验证明，传统的回译和同义改写方法在某些指标上可以达到甚至超过零样本、少样本生成方法的性能。在结果质量和分类性能的综合对比下，部分传统方法展现出强大竞争力。

Conclusion: 请勿忽视传统数据增强方法的效用，在大型语言模型快速发展的同时，回译与同义改写等方法依然具有很高的实用价值，能够有效提升数据稀缺场景下的NLP模型性能。

Abstract: Numerous domain-specific machine learning tasks struggle with data scarcity
and class imbalance. This paper systematically explores data augmentation
methods for NLP, particularly through large language models like GPT. The
purpose of this paper is to examine and evaluate whether traditional methods
such as paraphrasing and backtranslation can leverage a new generation of
models to achieve comparable performance to purely generative methods. Methods
aimed at solving the problem of data scarcity and utilizing ChatGPT were
chosen, as well as an exemplary dataset. We conducted a series of experiments
comparing four different approaches to data augmentation in multiple
experimental setups. We then evaluated the results both in terms of the quality
of generated data and its impact on classification performance. The key
findings indicate that backtranslation and paraphrasing can yield comparable or
even better results than zero and a few-shot generation of examples.

</details>


### [163] [Retrieval-Augmented Clinical Benchmarking for Contextual Model Testing in Kenyan Primary Care: A Methodology Paper](https://arxiv.org/abs/2507.14615)
*Fred Mutisya,Shikoh Gitau,Christine Syovata,Diana Oigara,Ibrahim Matende,Muna Aden,Munira Ali,Ryan Nyotu,Diana Marion,Job Nyangena,Nasubo Ongoma,Keith Mbae,Elizabeth Wamicha,Eric Mibuari,Jean Philbert Nsengemana,Talkmore Chidede*

Main category: cs.CL

TL;DR: 本文提出并构建了针对肯尼亚基层医疗背景的大语言模型（LLM）评测基准数据集和评估框架，通过实际案例证明现有LLM在本地适应性和准确性方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 大语言模型有望提升低资源医疗环境的服务能力，但其在非洲基层医疗中的效果尚不明确，尤其缺乏符合本地规范的评测标准。该研究旨在推动针对本地医疗需求和标准的AI模型安全落地。

Method: 研究采用RAG（检索增强生成）技术，将肯尼亚国家临床指南进行数字化、分段并建立语义索引。在此基础上，利用Gemini Flash 2.0 Lite模型结合指南内容生成英语和斯瓦希里语的临床问题、情境和多选答案，由本地医师共同参与数据构建与校验。最终通过专家盲审确保临床与文化适配性。

Result: 构建了数千条与本地监管要求对齐、涵盖常见门诊病症的Alama Health QA数据集，同时提出涵盖罕见病例识别、推理链条、情境适应性的多维评测指标。初步结果显示，现有LLM在非洲本地医疗任务上的表现显著低于对欧美数据集的成绩。

Conclusion: 本研究不仅为非洲区域健康AI系统安全应用提供了可复制的基准和评估体系，还揭示了当前大模型在本地医疗情境下的不足，强调持续推动本地化、安全的AI医疗解决方案的重要性。

Abstract: Large Language Models(LLMs) hold promise for improving healthcare access in
low-resource settings, but their effectiveness in African primary care remains
underexplored. We present a methodology for creating a benchmark dataset and
evaluation framework focused on Kenyan Level 2 and 3 clinical care. Our
approach uses retrieval augmented generation (RAG) to ground clinical questions
in Kenya's national guidelines, ensuring alignment with local standards. These
guidelines were digitized, chunked, and indexed for semantic retrieval. Gemini
Flash 2.0 Lite was then prompted with guideline excerpts to generate realistic
clinical scenarios, multiple-choice questions, and rationale based answers in
English and Swahili. Kenyan physicians co-created and refined the dataset, and
a blinded expert review process ensured clinical accuracy, clarity, and
cultural appropriateness. The resulting Alama Health QA dataset includes
thousands of regulator-aligned question answer pairs across common outpatient
conditions. Beyond accuracy, we introduce evaluation metrics that test clinical
reasoning, safety, and adaptability such as rare case detection (Needle in the
Haystack), stepwise logic (Decision Points), and contextual adaptability.
Initial results reveal significant performance gaps when LLMs are applied to
localized scenarios, consistent with findings that LLM accuracy is lower on
African medical content than on US-based benchmarks. This work offers a
replicable model for guideline-driven, dynamic benchmarking to support safe AI
deployment in African health systems.

</details>


### [164] [Linear Relational Decoding of Morphology in Language Models](https://arxiv.org/abs/2507.14640)
*Eric Xia,Jugal Kalita*

Main category: cs.CL

TL;DR: 本文发现跨层的线性变换可以很好地近似处理transformer中某些语法关系，尤其在形态学任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 理解transformer语言模型内部是如何编码和表示主体-客体等语法语义关系，提升模型可解释性，特别关注模型内部不同层之间的关系。

Method: 提出并应用一种基于模型中间层表征和梯度导出的线性变换（Ws），在Bigger Analogy Test Set上验证其对终态对象的近似能力，并在多语言和多模型上测试其普适性。

Result: 该线性方法在形态学相关关系上达到约90%的近似忠实度，并在多语言和多种模型架构上得到类似结果。

Conclusion: Transformer内部部分概念语义（如形态学）在潜空间中具有高度可解释性，可以通过跨层稀疏线性变换进行捕捉和还原。

Abstract: A two-part affine approximation has been found to be a good approximation for
transformer computations over certain subject object relations. Adapting the
Bigger Analogy Test Set, we show that the linear transformation Ws, where s is
a middle layer representation of a subject token and W is derived from model
derivatives, is also able to accurately reproduce final object states for many
relations. This linear technique is able to achieve 90% faithfulness on
morphological relations, and we show similar findings multi-lingually and
across models. Our findings indicate that some conceptual relationships in
language models, such as morphology, are readily interpretable from latent
space, and are sparsely encoded by cross-layer linear transformations.

</details>


### [165] [Cleanse: Uncertainty Estimation Approach Using Clustering-based Semantic Consistency in LLMs](https://arxiv.org/abs/2507.14649)
*Minsuh Joo,Hyunsoo Cho*

Main category: cs.CL

TL;DR: 当前大语言模型（LLMs）在NLP任务上表现优异，但仍存在生成错误信息（幻觉）的问题。论文提出了一种新的不确定性估计方法Cleanse，通过聚类评估语义一致性，从而检测幻觉。实验在主流LLM和问答任务上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: LLM生成幻觉导致不安全和不可靠的问题突出，而现有的不确定性估计方法无法很好地区分正确与错误答案。需要更有效的幻觉检测手段。

Method: 提出了一种基于聚类的语义一致性评估方法Cleanse，通过对LLM生成的隐藏嵌入向量聚类，量化簇内一致性在总体一致性中的占比，作为不确定性度量，用以检测幻觉。

Result: 在LLaMA-7B、LLaMA-13B、LLaMA2-7B和Mistral-7B等4种主流模型，以及SQuAD和CoQA两个问答基准数据集上进行了实证，结果验证了Cleanse方法对幻觉检测的有效性。

Conclusion: Cleanse作为一种新的不确定性估计方法，能更有效区分LLM回答的真假，提升幻觉检测水平。

Abstract: Despite the outstanding performance of large language models (LLMs) across
various NLP tasks, hallucinations in LLMs--where LLMs generate inaccurate
responses--remains as a critical problem as it can be directly connected to a
crisis of building safe and reliable LLMs. Uncertainty estimation is primarily
used to measure hallucination levels in LLM responses so that correct and
incorrect answers can be distinguished clearly. This study proposes an
effective uncertainty estimation approach, \textbf{Cl}ust\textbf{e}ring-based
sem\textbf{an}tic con\textbf{s}ist\textbf{e}ncy (\textbf{Cleanse}). Cleanse
quantifies the uncertainty with the proportion of the intra-cluster consistency
in the total consistency between LLM hidden embeddings which contain adequate
semantic information of generations, by employing clustering. The effectiveness
of Cleanse for detecting hallucination is validated using four off-the-shelf
models, LLaMA-7B, LLaMA-13B, LLaMA2-7B and Mistral-7B and two
question-answering benchmarks, SQuAD and CoQA.

</details>


### [166] [Mangosteen: An Open Thai Corpus for Language Model Pretraining](https://arxiv.org/abs/2507.14664)
*Wannaphong Phatthiyaphaibun,Can Udomcharoenchaikit,Pakpoom Singkorapoom,Kunat Pipatanakul,Ekapol Chuangsuwanich,Peerat Limkonchotiwat,Sarana Nutanong*

Main category: cs.CL

TL;DR: 本文提出了Mangosteen，这是一个包含470亿tokens的高质量泰语预训练语料库，通过自适应和改良的数据清洗流程，将网络生语料中的噪音大幅减少，并公开了全流程资源，极大促进泰语和地区大模型（LLM）研究再现性。


<details>
  <summary>Details</summary>
Motivation: 现有的主流大规模语料库多基于英文或全语言统一流程，对泰文字体特性和文化细节处理不足，导致如赌博等有害内容无法有效剔除；过往专为泰语设计的流程数据发布和细节公开有限，影响再现性与可持续研究。

Method: 采用泰语自定义的Dolma数据清洗管道，包括自研的基于规则的语言识别、改良的C4/Gopher质量过滤器、泰语专用内容过滤器，并融合了Wikipedia、政府公报、OCR书籍、YouTube字幕等精选非网页数据，系统消融实验验证各流程作用。

Result: 使用GPT-2评估，清洗流程将CommonCrawl基础上202M份文档缩减至25M，高质量提升SEA-HELM NLG得分从3到11。8B参数量的SEA-LION模型在Mangosteen上继续预训练后，在泰语基准测试上超过SEA-LION-v3和Llama-3.1约4分。

Conclusion: Mangosteen显著提升了泰语语料质量和模型性能，公开完整数据和代码，提升研究的可复现性和区域自然语言处理的基础设施建设。

Abstract: Pre-training data shapes a language model's quality, but raw web text is
noisy and demands careful cleaning. Existing large-scale corpora rely on
English-centric or language-agnostic pipelines whose heuristics do not capture
Thai script or cultural nuances, leaving risky material such as gambling
content untreated. Prior Thai-specific efforts customize pipelines or build new
ones, yet seldom release their data or document design choices, hindering
reproducibility and raising the question of how to construct a transparent,
high-quality Thai corpus. We introduce Mangosteen: a 47 billion-token Thai
corpus built through a Thai-adapted Dolma pipeline that includes custom
rule-based language ID, revised C4/Gopher quality filters, and Thai-trained
content filters, plus curated non-web sources such as Wikipedia, Royal Gazette
texts, OCR-extracted books, and CC-licensed YouTube subtitles. Systematic
ablations using GPT-2 show the pipeline trims CommonCrawl from 202M to 25M
documents while raising SEA-HELM NLG from 3 to 11; an 8B-parameter SEA-LION
model continually pre-trained on Mangosteen then surpasses SEA-LION-v3 and
Llama-3.1 by about four points on Thai benchmarks. We release the full pipeline
code, cleaning manifests, corpus snapshot, and all checkpoints, providing a
fully reproducible foundation for future Thai and regional LLM research.

</details>


### [167] [Large Language Models as Medical Codes Selectors: a benchmark using the International Classification of Primary Care](https://arxiv.org/abs/2507.14681)
*Vinicius Anjos de Almeida,Vinicius de Camargo,Raquel Gómez-Bravo,Egbert van der Haring,Kees van Boven,Marcelo Finger,Luis Fernandez Lopez*

Main category: cs.CL

TL;DR: 本研究探讨了大语言模型（LLM）自动分配ICPC-2编码（面向医学数据结构化）的可行性，在巴西葡萄牙语临床表达数据集上评估了33种模型的性能，并提供了基准测试。


<details>
  <summary>Details</summary>
Motivation: 医学编码对于医疗数据的研究、质量监测和政策制定具有重要作用。手工编码繁琐且易出错，自动化方法（特别是基于LLM的方法）可以提升效率和准确性。因此，评估LLM是否能高效实现ICPC-2编码具有重要意义。

Method: 使用包含437条经过ICPC-2编码的巴西葡萄牙语临床表达的数据集，由基于OpenAI text-embedding-3-large的语义检索引擎，从73,563个有标注的概念中检索候选结果。再将33个LLM模型分别对每个查询及检索结果进行推理，自动选择最佳ICPC-2编码。通过F1分数、token使用量、成本、响应时间和格式合规性来综合评估模型表现。

Result: 28个模型F1分数超过0.8，10超过0.85。gpt-4.5-preview、o3和gemini-2.5-pro等表现最优。优化检索器可以再提升4分。大多数模型能正确输出格式、幻觉（错误编码）的发生率降低。小模型（参数<3B）在格式和输入长度上表现不佳。

Conclusion: LLM在自动ICPC-2编码任务上表现出强大潜力，即使未经微调也能获得高性能，但数据集有限、实验设置有限制，需在更广泛、多语言和端到端的场景中做临床验证。

Abstract: Background: Medical coding structures healthcare data for research, quality
monitoring, and policy. This study assesses the potential of large language
models (LLMs) to assign ICPC-2 codes using the output of a domain-specific
search engine.
  Methods: A dataset of 437 Brazilian Portuguese clinical expressions, each
annotated with ICPC-2 codes, was used. A semantic search engine (OpenAI's
text-embedding-3-large) retrieved candidates from 73,563 labeled concepts.
Thirty-three LLMs were prompted with each query and retrieved results to select
the best-matching ICPC-2 code. Performance was evaluated using F1-score, along
with token usage, cost, response time, and format adherence.
  Results: Twenty-eight models achieved F1-score > 0.8; ten exceeded 0.85. Top
performers included gpt-4.5-preview, o3, and gemini-2.5-pro. Retriever
optimization can improve performance by up to 4 points. Most models returned
valid codes in the expected format, with reduced hallucinations. Smaller models
(<3B) struggled with formatting and input length.
  Conclusions: LLMs show strong potential for automating ICPC-2 coding, even
without fine-tuning. This work offers a benchmark and highlights challenges,
but findings are limited by dataset scope and setup. Broader, multilingual,
end-to-end evaluations are needed for clinical validation.

</details>


### [168] [MiroMind-M1: An Open-Source Advancement in Mathematical Reasoning via Context-Aware Multi-Stage Policy Optimization](https://arxiv.org/abs/2507.14683)
*Xingxuan Li,Yao Xiao,Dianwen Ng,Hai Ye,Yue Deng,Xiang Lin,Bin Wang,Zhanfeng Mo,Chong Zhang,Yueyi Zhang,Zonglin Yang,Ruilin Li,Lei Lei,Shihao Xu,Han Zhao,Weiling Chen,Feng Ji,Lidong Bing*

Main category: cs.CL

TL;DR: 该论文提出MiroMind-M1系列完全开源推理语言模型，在数学推理任务上表现优异，并公布所有模型、数据集和训练配置以支持可复现性。


<details>
  <summary>Details</summary>
Motivation: 当前高性能推理语言模型大多为闭源或未完全开源，缺乏透明度和可复现性，阻碍了领域发展，特别是在需要多步逻辑和抽象推理的数学任务上尤为明显。

Method: 模型基于Qwen-2.5进行，分为：1）在71.9万条精炼数学推理数据（含验证的链式思考过程）上进行监督微调（SFT）；2）在6.2万道可验证的高难度问题上进行基于奖励的变分增强学习（RLVR）。创新之处在于提出上下文感知多阶段策略优化算法，通过长度递进训练和自适应重复惩罚提升RLVR效率和模型鲁棒性。

Result: 在AIME24、AIME25和MATH等数学推理基准测试中，模型在Qwen-2.5结构的开源7B、32B参数级别下，均取得了业内最佳或极具竞争力的性能，并且具备更佳的token效率。

Conclusion: MiroMind-M1系列模型与数据以及完整训练/评测配置均已开源，为社区提供可复现的高水准推理模型资源，有助于进一步研究和领域共同进步。

Abstract: Large language models have recently evolved from fluent text generation to
advanced reasoning across diverse domains, giving rise to reasoning language
models. Among these domains, mathematical reasoning serves as a representative
benchmark as it requires precise multi-step logic and abstract reasoning, which
can be generalized to other tasks. While closed-source RLMs such as GPT-o3
demonstrate impressive reasoning capabilities, their proprietary nature limits
transparency and reproducibility. Although many open-source projects aim to
close this gap, most of them lack sufficient openness by omitting critical
resources such as datasets and detailed training configurations, which hinders
reproducibility. To contribute toward greater transparency in RLM development,
we introduce the MiroMind-M1 series, a set of fully open-source RLMs built on
the Qwen-2.5 backbone that match or exceed the performance of existing
open-source RLMs. Specifically, our models are trained in two stages: SFT on a
carefully curated corpus of 719K math-reasoning problems with verified CoT
trajectories, followed by RLVR on 62K challenging and verifiable problems. To
enhance the robustness and efficiency of the RLVR process, we introduce
Context-Aware Multi-Stage Policy Optimization, an algorithm that integrates
length-progressive training with an adaptive repetition penalty to encourage
context-aware RL training. Our model achieves state-of-the-art or competitive
performance and superior token efficiency among Qwen-2.5-based open-source 7B
and 32B models on the AIME24, AIME25, and MATH benchmarks. To facilitate
reproducibility, we release the complete stack: models (MiroMind-M1-SFT-7B,
MiroMind-M1-RL-7B, MiroMind-M1-RL-32B); datasets (MiroMind-M1-SFT-719K,
MiroMind-M1-RL-62K); and all training and evaluation configurations. We hope
these resources will support further research and foster community advancement.

</details>


### [169] [Mind the Gap: A Review of Arabic Post-Training Datasets and Their Limitations](https://arxiv.org/abs/2507.14688)
*Mohammed Alkhowaiter,Norah Alshahrani,Saied Alshahrani,Reem I. Masoud,Alaa Alzahrani,Deema Alnuhait,Emad A. Alghamdi,Khalid Almubarak*

Main category: cs.CL

TL;DR: 本论文综述了Hugging Face Hub上阿拉伯语大语言模型（LLMs）的公开后训练数据集，并从多个维度对其进行系统评估，同时指出现有数据集存在的不足，并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: 近年来，为了更好地使大语言模型符合人类需求，后训练逐渐成为关键步骤。阿拉伯语作为重要语种之一，其相关后训练数据集的质量和多样性对于模型性能提升至关重要。但目前相关总结和评估有限，因此亟需全面梳理和分析。

Method: 作者从LLM能力、可引导性、对齐性和鲁棒性四个核心维度出发，对Hugging Face Hub中公开的阿拉伯语后训练数据集进行梳理和评估，同时按照流行度、实际应用、更新维护、文档与标注质量、许可透明度和学术贡献等标准进行细致评判。

Result: 分析发现：阿拉伯语后训练数据集存在任务类型单一、文档和标注缺失或不规范、社区采用率低等主要问题。

Conclusion: 数据集不足制约阿拉伯语大语言模型的发展。作者建议：未来需提升数据集多样性、完善标注与文档、增加社区应用分享，并加强学术与产业协作，以促进阿拉伯语LLMs的创新和应用。

Abstract: Post-training has emerged as a crucial technique for aligning pre-trained
Large Language Models (LLMs) with human instructions, significantly enhancing
their performance across a wide range of tasks. Central to this process is the
quality and diversity of post-training datasets. This paper presents a review
of publicly available Arabic post-training datasets on the Hugging Face Hub,
organized along four key dimensions: (1) LLM Capabilities (e.g., Question
Answering, Translation, Reasoning, Summarization, Dialogue, Code Generation,
and Function Calling); (2) Steerability (e.g., persona and system prompts); (3)
Alignment (e.g., cultural, safety, ethics, and fairness), and (4) Robustness.
Each dataset is rigorously evaluated based on popularity, practical adoption,
recency and maintenance, documentation and annotation quality, licensing
transparency, and scientific contribution. Our review revealed critical gaps in
the development of Arabic post-training datasets, including limited task
diversity, inconsistent or missing documentation and annotation, and low
adoption across the community. Finally, the paper discusses the implications of
these gaps on the progress of Arabic LLMs and applications while providing
concrete recommendations for future efforts in post-training dataset
development.

</details>


### [170] [Rethinking Suicidal Ideation Detection: A Trustworthy Annotation Framework and Cross-Lingual Model Evaluation](https://arxiv.org/abs/2507.14693)
*Amina Dzafic,Merve Kavut,Ulya Bayram*

Main category: cs.CL

TL;DR: 本论文关注自杀意念检测中的语言覆盖有限和标注不可靠两个重要挑战，提出了土耳其语社交媒体自杀意念数据集和创新标注流程，并对标注一致性和模型迁移性能进行全面评测。


<details>
  <summary>Details</summary>
Motivation: 现有自杀意念检测数据集几乎全部为英文，且高质量人工标注数据稀缺，其他语言数据更为有限，标注流程和标注可靠性常被忽视，影响AI在全球自杀预防中的应用。

Method: 作者建立了包含社交媒体帖子的土耳其语自杀意念语料库，并采用三名人工标注员加两种大语言模型的资源高效联合标注框架。随后，将此土耳其语新数据集与三个主流英文自杀意念检测数据集进行双向标签可靠性与模型一致性评估，利用八个情感/情绪预训练transformer模型进行迁移学习测试。

Result: 实验显示，现有流行模型在零样本迁移学习情境下的表现较差，强调了严格、语言多元的标注与评估方法的重要性。

Conclusion: 作者呼吁心理健康NLP领域在模型训练和数据集构建中重视透明度，优先保证数据与模型的可靠性，并指出应更多关注多语言和标注过程的科学性。

Abstract: Suicidal ideation detection is critical for real-time suicide prevention, yet
its progress faces two under-explored challenges: limited language coverage and
unreliable annotation practices. Most available datasets are in English, but
even among these, high-quality, human-annotated data remains scarce. As a
result, many studies rely on available pre-labeled datasets without examining
their annotation process or label reliability. The lack of datasets in other
languages further limits the global realization of suicide prevention via
artificial intelligence (AI). In this study, we address one of these gaps by
constructing a novel Turkish suicidal ideation corpus derived from social media
posts and introducing a resource-efficient annotation framework involving three
human annotators and two large language models (LLMs). We then address the
remaining gaps by performing a bidirectional evaluation of label reliability
and model consistency across this dataset and three popular English suicidal
ideation detection datasets, using transfer learning through eight pre-trained
sentiment and emotion classifiers. These transformers help assess annotation
consistency and benchmark model performance against manually labeled data. Our
findings underscore the need for more rigorous, language-inclusive approaches
to annotation and evaluation in mental health natural language processing (NLP)
while demonstrating the questionable performance of popular models with
zero-shot transfer learning. We advocate for transparency in model training and
dataset construction in mental health NLP, prioritizing data and model
reliability.

</details>


### [171] [Disparities in Peer Review Tone and the Role of Reviewer Anonymity](https://arxiv.org/abs/2507.14741)
*Maria Sahakyan,Bedoor AlShebli*

Main category: cs.CL

TL;DR: 本研究通过对两大学术期刊8万余份评审意见进行语言学分析，揭示了同行评议中因作者群体（性别、种族、机构）不同而存在的隐藏偏见，并探讨了匿名与实名评审对评语的影响。


<details>
  <summary>Details</summary>
Motivation: 当前关于同行评议公平性的讨论多聚焦结构性不平等，对语言层面对评审中偏见的影响关注不足。作者希望通过大规模、系统的语言分析，揭示评审过程中的微妙歧视及其机制。

Method: 本研究采用自然语言处理技术和大规模统计建模，对两大期刊逾8万篇评审报告进行分析，比较了涉及不同作者群体（性别、种族、机构等）的评语情感、用词和支持性语言。同时，结合匿名与实名评审的数据，分析评审人身份披露对评语语言的影响。

Result: 分析发现，评审意见的语气、情感倾向和支持性语言随着作者的性别、种族和机构背景而变化。此外，评审人是否匿名对评语语言有显著作用，实名时语言风格和倾向发生变化。

Conclusion: 同行评议中的隐藏语言偏见真实存在，且现行的匿名评审机制并不能完全保障公正。研究结果对学术出版改革、评审政策制定及推动公平科学环境有重要启示和反思。

Abstract: The peer review process is often regarded as the gatekeeper of scientific
integrity, yet increasing evidence suggests that it is not immune to bias.
Although structural inequities in peer review have been widely debated, much
less attention has been paid to the subtle ways in which language itself may
reinforce disparities. This study undertakes one of the most comprehensive
linguistic analyses of peer review to date, examining more than 80,000 reviews
in two major journals. Using natural language processing and large-scale
statistical modeling, it uncovers how review tone, sentiment, and supportive
language vary across author demographics, including gender, race, and
institutional affiliation. Using a data set that includes both anonymous and
signed reviews, this research also reveals how the disclosure of reviewer
identity shapes the language of evaluation. The findings not only expose hidden
biases in peer feedback, but also challenge conventional assumptions about
anonymity's role in fairness. As academic publishing grapples with reform,
these insights raise critical questions about how review policies shape career
trajectories and scientific progress.

</details>


### [172] [On the robustness of modeling grounded word learning through a child's egocentric input](https://arxiv.org/abs/2507.14749)
*Wai Keen Vong,Brenden M. Lake*

Main category: cs.CL

TL;DR: 研究通过自动语音转录技术，将三个儿童的逾500小时视觉和语言数据转为多模态训练集，训练神经网络以探索其拟人词汇学习的鲁棒性，发现模型可成功泛化并表现出个体学习差异。


<details>
  <summary>Details</summary>
Motivation: 机器学习，尤其是大型语言与多模态模型在模拟人类语言习得方面取得巨大进展，但其对大规模数据的依赖与儿童以少量输入成功习得语言之间存在巨大差距。过去只用单个儿童的数据，未探究不同儿童间模型学习的真实性与一致性，因此有必要用多儿童数据测试模型的泛化能力。

Method: 在SAYCam数据集基础上，使用自动化语音转录技术，对三个儿童超过500小时的视频数据进行语音文本提取，生成多模态视觉和语言训练与评测数据集。并在不同神经网络架构下，训练和评估模型对于词汇-指涉对象映射学习的效果。

Result: 神经网络能有效利用每个儿童自动转录的数据，学习和泛化词汇—指引用的关联，并且这一能力在多种网络架构下表现一致，证明了多模态模型在模拟儿童词汇学习上的鲁棒性。同时，不同儿童的数据训练出的模型在学习方式上展现出个体差异。

Conclusion: 多模态神经网络不仅可以鲁棒地实现词汇学习，还能反映不同个体成长经历造成的学习差异。本研究验证了自动化数据处理及小样本多模态神经网络在人类语言习得模拟研究中的有效性与适用性。

Abstract: What insights can machine learning bring to understanding human language
acquisition? Large language and multimodal models have achieved remarkable
capabilities, but their reliance on massive training datasets creates a
fundamental mismatch with children, who succeed in acquiring language from
comparatively limited input. To help bridge this gap, researchers have
increasingly trained neural networks using data similar in quantity and quality
to children's input. Taking this approach to the limit, Vong et al. (2024)
showed that a multimodal neural network trained on 61 hours of visual and
linguistic input extracted from just one child's developmental experience could
acquire word-referent mappings. However, whether this approach's success
reflects the idiosyncrasies of a single child's experience, or whether it would
show consistent and robust learning patterns across multiple children's
experiences was not explored. In this article, we applied automated speech
transcription methods to the entirety of the SAYCam dataset, consisting of over
500 hours of video data spread across all three children. Using these automated
transcriptions, we generated multi-modal vision-and-language datasets for both
training and evaluation, and explored a range of neural network configurations
to examine the robustness of simulated word learning. Our findings demonstrate
that networks trained on automatically transcribed data from each child can
acquire and generalize word-referent mappings across multiple network
architectures. These results validate the robustness of multimodal neural
networks for grounded word learning, while highlighting the individual
differences that emerge in how models learn when trained on each child's
developmental experiences.

</details>


### [173] [GRACE: Generative Recommendation via Journey-Aware Sparse Attention on Chain-of-Thought Tokenization](https://arxiv.org/abs/2507.14758)
*Luyi Ma,Wanjia Zhang,Kai Zhao,Abhishek Kulkarni,Lalitesh Morishetti,Anjana Ganesh,Ashish Ranjan,Aashika Padmanabhan,Jianpeng Xu,Jason Cho,Praveen Kanumala,Kaushiki Nag,Sumit Dutta,Kamiya Motwani,Malay Patel,Evren Korpeoglu,Sushant Kumar,Kannan Achan*

Main category: cs.CL

TL;DR: 该论文提出了GRACE模型，通过融合基于产品知识的显式属性与高效稀疏注意力机制，大幅提升了多行为推荐系统的效果与效率。


<details>
  <summary>Details</summary>
Motivation: 当前生成式推荐系统虽然利用transformer架构展现出较强潜力，但存在令token推理不透明、计算成本高及对用户历史多尺度建模能力有限等问题。

Method: 提出了GRACE框架，核心包括（1）混合型Chain-of-Thought（CoT）token化方法，将用户行为与产品知识属性（如类别、品牌、价格）编码为语义token，实现解释性和行为对齐的生成；（2）设计Journey-Aware Sparse Attention（JSA）机制，只对重要序列片段（包含当前、压缩、局部与全局上下文）选择性关注，提高计算效率。

Result: 在两个真实世界数据集上实验，GRACE相较于最优基线在Home领域提升最高达106.9%（HR@10）和106.7%（NDCG@10），在Electronics领域提升达22.1%（HR@10）；在长序列下注意力计算减少48%。

Conclusion: GRACE有效解决了生成式多行为推荐的透明性、效率及多尺度建模瓶颈，在推荐准确性和推理效率上均优于现有方法。

Abstract: Generative models have recently demonstrated strong potential in
multi-behavior recommendation systems, leveraging the expressive power of
transformers and tokenization to generate personalized item sequences. However,
their adoption is hindered by (1) the lack of explicit information for token
reasoning, (2) high computational costs due to quadratic attention complexity
and dense sequence representations after tokenization, and (3) limited
multi-scale modeling over user history. In this work, we propose GRACE
(Generative Recommendation via journey-aware sparse Attention on
Chain-of-thought tokEnization), a novel generative framework for multi-behavior
sequential recommendation. GRACE introduces a hybrid Chain-of-Thought (CoT)
tokenization method that encodes user-item interactions with explicit
attributes from product knowledge graphs (e.g., category, brand, price) over
semantic tokenization, enabling interpretable and behavior-aligned generation.
To address the inefficiency of standard attention, we design a Journey-Aware
Sparse Attention (JSA) mechanism, which selectively attends to compressed,
intra-, inter-, and current-context segments in the tokenized sequence.
Experiments on two real-world datasets show that GRACE significantly
outperforms state-of-the-art baselines, achieving up to +106.9% HR@10 and
+106.7% NDCG@10 improvement over the state-of-the-art baseline on the Home
domain, and +22.1% HR@10 on the Electronics domain. GRACE also reduces
attention computation by up to 48% with long sequences.

</details>


### [174] [FastLongSpeech: Enhancing Large Speech-Language Models for Efficient Long-Speech Processing](https://arxiv.org/abs/2507.14815)
*Shoutao Guo,Shaolei Zhang,Qingkai Fang,Zhengrui Ma,Min Zhang,Yang Feng*

Main category: cs.CL

TL;DR: 本文提出了一种名为FastLongSpeech的新框架，提升了大型语音-语言模型（LSLM）对长语音的处理能力，无需专门的长语音训练数据，并显著提高推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有LSLM大多关注语音生成或短语音任务，对长语音的高效处理仍然是个重要但未深入解决的问题，主要因缺乏长语音数据和长序列高计算消耗。

Method: 提出了FastLongSpeech框架，包括迭代融合策略以压缩超长语音为可管理长度，并引入动态压缩训练方法，使模型通过不同压缩比的短语音序列训练，迁移对长语音任务的能力。此外，构建了LongSpeech-Eval评测基准。

Result: 实验表明，FastLongSpeech在长、短语音任务上均表现出色，并显著提升了推理效率。

Conclusion: FastLongSpeech无需专用长语音数据，能有效扩展LSLM对长语音处理的能力，兼顾效率与效果。

Abstract: The rapid advancement of Large Language Models (LLMs) has spurred significant
progress in Large Speech-Language Models (LSLMs), enhancing their capabilities
in both speech understanding and generation. While existing LSLMs often
concentrate on augmenting speech generation or tackling a diverse array of
short-speech tasks, the efficient processing of long-form speech remains a
critical yet underexplored challenge. This gap is primarily attributed to the
scarcity of long-speech training datasets and the high computational costs
associated with long sequences. To address these limitations, we introduce
FastLongSpeech, a novel framework designed to extend LSLM capabilities for
efficient long-speech processing without necessitating dedicated long-speech
training data. FastLongSpeech incorporates an iterative fusion strategy that
can compress excessively long-speech sequences into manageable lengths. To
adapt LSLMs for long-speech inputs, it introduces a dynamic compression
training approach, which exposes the model to short-speech sequences at varying
compression ratios, thereby transferring the capabilities of LSLMs to
long-speech tasks. To assess the long-speech capabilities of LSLMs, we develop
a long-speech understanding benchmark called LongSpeech-Eval. Experiments show
that our method exhibits strong performance in both long-speech and
short-speech tasks, while greatly improving inference efficiency.

</details>


### [175] [Doc2Chart: Intent-Driven Zero-Shot Chart Generation from Documents](https://arxiv.org/abs/2507.14819)
*Akriti Jain,Pritika Ramu,Aparna Garimella,Apoorv Saxena*

Main category: cs.CL

TL;DR: 本文提出一种新的任务：基于用户意图从长文档中自动生成数据图表，无需人工提前选取相关内容。提出了无监督两阶段框架，并引入新评测指标和数据集，在金融和科技领域均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有大模型虽然能根据文本或表格生成数据可视化，但实际场景复杂，需要根据长文档和用户意图直接提取和可视化数据，不能依赖用户手动筛选内容。本文为弥补这一实际需求和研究空白提出新任务。

Method: 提出无监督两阶段框架：首先大模型分解意图，自动从文档中提取、校验和细化相关信息；其次启发式模块选择合适图表类型再生成代码。为评估准确性，设计了基于归因和结构化文本的新指标并构建了新数据集。

Result: 在新金融和科学领域数据集上，本方法在图表数据准确度和类型选择上，分别比现有单轮大模型和检索方法最高提升9和17百分点。

Conclusion: 本文针对基于意图的文档可视化提出了新任务、方法和评测，实验证明方法有效，有助于大模型应用于自动、智能的数据可视化实际场景。

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities in
transforming text descriptions or tables to data visualizations via
instruction-tuning methods. However, it is not straightforward to apply these
methods directly for a more real-world use case of visualizing data from long
documents based on user-given intents, as opposed to the user pre-selecting the
relevant content manually. We introduce the task of intent-based chart
generation from documents: given a user-specified intent and document(s), the
goal is to generate a chart adhering to the intent and grounded on the
document(s) in a zero-shot setting. We propose an unsupervised, two-staged
framework in which an LLM first extracts relevant information from the
document(s) by decomposing the intent and iteratively validates and refines
this data. Next, a heuristic-guided module selects an appropriate chart type
before final code generation. To assess the data accuracy of the generated
charts, we propose an attribution-based metric that uses a structured textual
representation of charts, instead of relying on visual decoding metrics that
often fail to capture the chart data effectively. To validate our approach, we
curate a dataset comprising of 1,242 $<$intent, document, charts$>$ tuples from
two domains, finance and scientific, in contrast to the existing datasets that
are largely limited to parallel text descriptions/ tables and their
corresponding charts. We compare our approach with baselines using single-shot
chart generation using LLMs and query-based retrieval methods; our method
outperforms by upto $9$ points and $17$ points in terms of chart data accuracy
and chart type respectively over the best baselines.

</details>


### [176] [Beyond Isolated Capabilities: Bridging Long CoT Reasoning and Long-Context Understanding](https://arxiv.org/abs/2507.14849)
*Yifei Wang*

Main category: cs.CL

TL;DR: 本论文探讨了大规模推理蒸馏对小型语言模型在长上下文检索和推理能力上的影响，发现推理蒸馏能显著增强模型处理和整合长文本信息的能力，缓解了“中间丢失”问题。


<details>
  <summary>Details</summary>
Motivation: 虽然推理蒸馏提升了小型模型的推理能力，但其对长上下文检索和推理等能力的影响尚未被系统研究，尤其是在检索增强生成（RAG）系统中。为了弥补这一知识空白，作者旨在厘清长链式推理过程（long-CoT）对长上下文理解的影响。

Method: 作者选用以推理能力著称的Deepseek-R1蒸馏生成的一系列开源模型，通过多文档问答任务系统评估这些模型在提取和整合长文本信息方面的表现，并进行详细实验分析。

Result: 实验结果表明，推理蒸馏能够显著提高模型对长上下文的理解能力。具体表现为模型在进行文本分析和信息解析时，能展现出更加细致和明确的推理链，提升信息整合能力。

Conclusion: 推理蒸馏机制能有效促进模型对长上下文的感知，缓解长文本场景下模型容易遗漏中间关键信息的“lost in the middle”问题，对提升小型模型在RAG体系中的实用性具有重要意义。

Abstract: Reasoning distillation has emerged as an effective approach to enhance the
reasoning capabilities of smaller language models. However, the impact of
large-scale reasoning distillation on other critical abilities, particularly
in-context retrieval and reasoning, remains unexplored. This gap in
understanding is particularly significant given the increasing importance of
Retrieval-Augmented Generation (RAG) systems, where efficient acquisition and
utilization of contextual information are paramount for generating reliable
responses. Motivated by the need to understand how the extended long-CoT
process influences long-context comprehension, we conduct a comprehensive
investigation using a series of open-source models distilled from Deepseek-R1,
renowned for its exceptional reasoning capabilities. Our study focuses on
evaluating these models' performance in extracting and integrating relevant
information from extended contexts through multi-document question and
answering tasks. Through rigorous experimentation, we demonstrate that
distilled reasoning patterns significantly improve long-context understanding.
Our analysis reveals that distillation fosters greater long-context awareness
by promoting more detailed and explicit reasoning processes during context
analysis and information parsing. This advancement effectively mitigates the
persistent "lost in the middle" issue that has hindered long-context models.

</details>


### [177] [Tiny language models](https://arxiv.org/abs/2507.14871)
*Ronit D. Gross,Yarden Tzach,Tal Halevi,Ella Koresh,Ido Kanter*

Main category: cs.CL

TL;DR: 本文探讨了小型语言模型（TLMs）在自然语言处理中的可行性，发现TLM经过预训练后，在文本分类任务上表现出与大模型相似的效果提升且可以用多个浅层模型的组合复制深层模型的表现，这为低资源环境下的NLP研究提供了新方向。


<details>
  <summary>Details</summary>
Motivation: 当前大规模语言模型（LLMs）的预训练需要巨大的算力，普通研究者难以参与，阻碍了NLP领域的广泛创新。因此，作者试图寻找无需大规模算力，也能复现主要功能的小型语言模型(TLMs)的可能性。

Method: 作者以BERT-6和BERT-1变体为代表的小型模型，在Wikipedia子集上进行预训练，并在FewRel、AGNews和DBPedia三项分类任务上验证其性能；还比较了未经预训练与预训练模型的表现，以及分析了不同数据集规模与数据重叠度的影响。此外，提出将多个独立预训练的浅层模型软集成，检验其对深层模型的性能复现能力。

Result: 1) 无论模型多小，经过预训练后的TLM在分类任务表现明显优于未预训练模型；2) 预训练数据集越大、预训练集与下游任务数据集重叠度越高，TLM性能提升越明显；3) 多个预训练浅层TLM的软委员会可无损地复制深层TLM的分类准确率。

Conclusion: 小型预训练语言模型在资源受限环境下依然有效，软集成策略为低延迟、低资源NLP应用提供了新方法。研究表明，TLM不仅帮助理解NLP核心机制，还有助于启发低资源条件下语言学习的理论建构。

Abstract: A prominent achievement of natural language processing (NLP) is its ability
to understand and generate meaningful human language. This capability relies on
complex feedforward transformer block architectures pre-trained on large
language models (LLMs). However, LLM pre-training is currently feasible only
for a few dominant companies due to the immense computational resources
required, limiting broader research participation. This creates a critical need
for more accessible alternatives. In this study, we explore whether tiny
language models (TLMs) exhibit the same key qualitative features of LLMs. We
demonstrate that TLMs exhibit a clear performance gap between pre-trained and
non-pre-trained models across classification tasks, indicating the
effectiveness of pre-training, even at a tiny scale. The performance gap
increases with the size of the pre-training dataset and with greater overlap
between tokens in the pre-training and classification datasets. Furthermore,
the classification accuracy achieved by a pre-trained deep TLM architecture can
be replicated through a soft committee of multiple, independently pre-trained
shallow architectures, enabling low-latency TLMs without affecting
classification accuracy. Our results are based on pre-training BERT-6 and
variants of BERT-1 on subsets of the Wikipedia dataset and evaluating their
performance on FewRel, AGNews, and DBPedia classification tasks. Future
research on TLM is expected to further illuminate the mechanisms underlying
NLP, especially given that its biologically inspired models suggest that TLMs
may be sufficient for children or adolescents to develop language.

</details>


### [178] [MEKiT: Multi-source Heterogeneous Knowledge Injection Method via Instruction Tuning for Emotion-Cause Pair Extraction](https://arxiv.org/abs/2507.14887)
*Shiyi Mu,Yongkang Liu,Shi Feng,Xiaocui Yang,Daling Wang,Yifei Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为MEKiT的多源异构知识注入方法，通过融合情感知识和因果知识，大幅提升了大语言模型在情感-原因对抽取（ECPE）任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然在理解和生成文本方面表现优异，但在ECPE任务上却由于缺乏辅助知识，导致表现还不如小模型。如何提升大模型对情感认知和因果推理的能力，是亟需解决的问题。

Method: 提出MEKiT方法，将内部情感知识和外部因果知识注入进大语言模型。针对这两种知识，分别采用了指令模板融入和数据混合指令微调的方法，从而增强大模型对情感的识别和因果推理能力。

Result: 实验表明，MEKiT方法在ECPE任务上比各类基准方法有绝对性能优势，显著提升了大语言模型在该任务上的表现。

Conclusion: MEKiT为ECPE任务提供了更有效、更可适配的解决方案，显著提升了大语言模型的整体能力，验证了多源异构知识融合的有效性。

Abstract: Although large language models (LLMs) excel in text comprehension and
generation, their performance on the Emotion-Cause Pair Extraction (ECPE) task,
which requires reasoning ability, is often underperform smaller language model.
The main reason is the lack of auxiliary knowledge, which limits LLMs' ability
to effectively perceive emotions and reason causes. To address this issue, we
propose a novel \textbf{M}ulti-source h\textbf{E}terogeneous \textbf{K}nowledge
\textbf{i}njection me\textbf{T}hod, MEKiT, which integrates heterogeneous
internal emotional knowledge and external causal knowledge. Specifically, for
these two distinct aspects and structures of knowledge, we apply the approaches
of incorporating instruction templates and mixing data for instruction-tuning,
which respectively facilitate LLMs in more comprehensively identifying emotion
and accurately reasoning causes. Experimental results demonstrate that MEKiT
provides a more effective and adaptable solution for the ECPE task, exhibiting
an absolute performance advantage over compared baselines and dramatically
improving the performance of LLMs on the ECPE task.

</details>


### [179] [Sparse Autoencoder-guided Supervised Finetuning to Mitigate Unexpected Code-Switching in LLMs](https://arxiv.org/abs/2507.14894)
*Boyi Deng,Yu Wan,Baosong Yang,Fei Huang,Wenjie Wang,Fuli Feng*

Main category: cs.CL

TL;DR: 大语言模型（LLMs）在生成文本时会出现意外的代码切换（语言混用），影响可读性和可用性。论文提出了一种基于稀疏自动编码器引导的监督微调方法（SASFT），有效减少了LLMs的代码切换问题，并保持了多语言能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在应答过程中可能无预期地出现跨语言切换，导致输出难以阅读和使用，但之前的解决方法机制分析不足且效果有限。

Method: 利用稀疏自动编码器分析LLMs中语言切换机制，发现与某一语言相关的特征在切换时会出现过高的预激活值。据此提出SASFT方法，在训练过程中引导模型保持适当的语言特征激活，减少意外代码切换。

Result: SASFT方法在五个模型、三种语言上的实验显示，相比标准监督微调，意外代码切换现象减少超过50%，且在四种场景下完全消除。同时，在六个多语言基准测试上的表现与原模型持平或略有提升。

Conclusion: SASFT方法不仅显著缓解了LLMs的意外代码切换问题，还能保持或提升多语言任务性能，是应对多语言模型代码切换现象的有效方案。

Abstract: Large Language Models (LLMs) have impressive multilingual capabilities, but
they suffer from unexpected code-switching, also known as language mixing,
which involves switching to unexpected languages in the model response. This
problem leads to poor readability and degrades the usability of model
responses. However, existing work on this issue lacks a mechanistic analysis
and shows limited effectiveness. In this paper, we first provide an in-depth
analysis of unexpected code-switching using sparse autoencoders and find that
when LLMs switch to a language, the features of that language exhibit excessive
pre-activation values. Based on our findings, we propose $\textbf{S}$parse
$\textbf{A}$utoencoder-guided $\textbf{S}$upervised
$\textbf{F}$ine$\textbf{t}$uning (SASFT), which teaches LLMs to maintain
appropriate pre-activation values of specific language features during
training. Experiments on five models across three languages demonstrate that
SASFT consistently reduces unexpected code-switching by more than 50\% compared
to standard supervised fine-tuning, with complete elimination in four cases.
Moreover, SASFT maintains or even improves the models' performance on six
multilingual benchmarks, showing its effectiveness in addressing code-switching
while preserving multilingual capabilities.

</details>


### [180] [From Neurons to Semantics: Evaluating Cross-Linguistic Alignment Capabilities of Large Language Models via Neurons Alignment](https://arxiv.org/abs/2507.14900)
*Chongxuan Huang,Yongshi Ye,Biao Fu,Qifeng Su,Xiaodong Shi*

Main category: cs.CL

TL;DR: 该论文提出了一种基于神经元状态的跨语言对齐评估方法NeuronXA，能够更有效评估大语言模型的多语言语义对齐能力，并在小样本下表现优异。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在多语言处理上表现突出，但目前缺乏高效、语义上有根基的跨语言对齐评估方法，尤其是在低资源语言情况下。现有方法多聚焦于句子嵌入层面，忽视了表示空间的平滑性问题，影响了评估结果。作者希望借鉴神经科学关于信息激活重叠区的发现，提出更有效的评估新方法。

Method: 作者提出了Neuron State-Based Cross-Lingual Alignment（NeuronXA）方法，通过分析多语言大模型内部神经元的激活状态来评估不同语言之间的语义对齐程度。实验选用了LLaMA、Qwen、Mistral、GLM和OLMo等多语言大模型，并在两个迁移任务和三个多语言基准测试上进行评估。

Result: NeuronXA方法只依赖100对平行句，就能在下游任务表现上取得0.9556的皮尔森相关系数，与迁移能力表现相关系数为0.8514，显示出极高的有效性和相关性。

Conclusion: NeuronXA方法能够在小数据集下有效评估多语言大模型的跨语言对齐和迁移能力，有望推动该领域研究发展，并提升多语言大模型的语义理解能力。

Abstract: Large language models (LLMs) have demonstrated remarkable multilingual
capabilities, however, how to evaluate cross-lingual alignment remains
underexplored. Existing alignment benchmarks primarily focus on sentence
embeddings, but prior research has shown that neural models tend to induce a
non-smooth representation space, which impact of semantic alignment evaluation
on low-resource languages. Inspired by neuroscientific findings that similar
information activates overlapping neuronal regions, we propose a novel Neuron
State-Based Cross-Lingual Alignment (NeuronXA) to assess the cross-lingual a
lignment capabilities of LLMs, which offers a more semantically grounded
approach to assess cross-lingual alignment. We evaluate NeuronXA on several
prominent multilingual LLMs (LLaMA, Qwen, Mistral, GLM, and OLMo) across two
transfer tasks and three multilingual benchmarks. The results demonstrate that
with only 100 parallel sentence pairs, NeuronXA achieves a Pearson correlation
of 0.9556 with downstream tasks performance and 0.8514 with transferability.
These findings demonstrate NeuronXA's effectiveness in assessing both
cross-lingual alignment and transferability, even with a small dataset. This
highlights its potential to advance cross-lingual alignment research and to
improve the semantic understanding of multilingual LLMs.

</details>


### [181] [PromptSuite: A Task-Agnostic Framework for Multi-Prompt Generation](https://arxiv.org/abs/2507.14913)
*Eliya Habba,Noam Dahan,Gili Lior,Gabriel Stanovsky*

Main category: cs.CL

TL;DR: 该论文提出了PromptSuite框架，用于自动生成多样化的LLM测试提示，提升评测的可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前单一提示(prompts)对大型语言模型(LLM)评估不可靠，细微修改会导致显著性能波动，而多提示评估因生成难度大而未被广泛应用。

Method: 提出并实现PromptSuite框架，它支持模块化设计，可对提示不同部分做可控扰动，并易于扩展，支持新组件和扰动类型，同时适配多类任务和基准。

Result: 通过多个案例分析，PromptSuite能有效产生命题多样性，帮助实现更健壮的LLM评估。

Conclusion: PromptSuite是自动化、多样化LLM评测提示生成的有力工具，有助于标准化和提升评测实践，现已开放API和Web平台。

Abstract: Evaluating LLMs with a single prompt has proven unreliable, with small
changes leading to significant performance differences. However, generating the
prompt variations needed for a more robust multi-prompt evaluation is
challenging, limiting its adoption in practice. To address this, we introduce
PromptSuite, a framework that enables the automatic generation of various
prompts. PromptSuite is flexible - working out of the box on a wide range of
tasks and benchmarks. It follows a modular prompt design, allowing controlled
perturbations to each component, and is extensible, supporting the addition of
new components and perturbation types. Through a series of case studies, we
show that PromptSuite provides meaningful variations to support strong
evaluation practices. It is available through both a Python API:
https://github.com/eliyahabba/PromptSuite, and a user-friendly web interface:
https://promptsuite.streamlit.app/

</details>


### [182] [SYNTHIA: Synthetic Yet Naturally Tailored Human-Inspired PersonAs](https://arxiv.org/abs/2507.14922)
*Vahid Rahimzadeh,Erfan Moosavi Monazzah,Mohammad Taher Pilehvar,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: 本文提出了SYNTHIA数据集，通过真实社交媒体活动生成具有真实性和连贯性的虚拟人设，兼顾真实度和一致性，推动社会计算和个性化大模型的研究。


<details>
  <summary>Details</summary>
Motivation: 现有基于个性化的大模型在社会计算中的应用，有的依赖昂贵的人类标注数据，有的生成合成角色却缺乏连贯性和真实感，因此需要一种兼顾真实性和一致性的新方法。

Method: 作者创建了SYNTHIA数据库，从BlueSky开放平台10,000名真实用户在三个时间窗口内的社交行为中，自动生成30,000个人设故事，结合数据驱动与合成生成优势，通过真实互动数据为生成过程提供支撑。

Result: SYNTHIA在人口多样性与社会调查一致性上达到了与现有最先进方法相当的效果，但在叙述连贯性上显著优于现有方法。

Conclusion: SYNTHIA为个性化大模型和社会计算领域提供了创新的数据资源，支持对个体随时间变化与社交网络互动的深入研究，为后续相关方法和应用拓展新方向。

Abstract: Persona-driven LLMs have emerged as powerful tools in computational social
science, yet existing approaches fall at opposite extremes, either relying on
costly human-curated data or producing synthetic personas that lack consistency
and realism. We introduce SYNTHIA, a dataset of 30,000 backstories derived from
10,000 real social media users from BlueSky open platform across three time
windows, bridging this spectrum by grounding synthetic generation in authentic
user activity. Our evaluation demonstrates that SYNTHIA achieves competitive
performance with state-of-the-art methods in demographic diversity and social
survey alignment while significantly outperforming them in narrative
consistency. Uniquely, SYNTHIA incorporates temporal dimensionality and
provides rich social interaction metadata from the underlying network, enabling
new research directions in computational social science and persona-driven
language modeling.

</details>


### [183] [MUR: Momentum Uncertainty guided Reasoning for Large Language Models](https://arxiv.org/abs/2507.14958)
*Hang Yan,Fangzhi Xu,Rongman Xu,Yifei Li,Jian Zhang,Haoran Luo,Xiaobao Wu,Luu Anh Tuan,Haiteng Zhao,Qika Lin,Jun Liu*

Main category: cs.CL

TL;DR: 本文提出了一种名为Momentum Uncertainty-guided Reasoning (MUR)的新方法，可以在不额外训练的前提下，高效且自适应地引导大语言模型在推理中分配计算资源。该方法通过动态分配推理预算，实现了减少冗余计算并提升准确率的效果。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型在推理类任务上表现突出，但在保持推理准确性的同时提升推理效率仍是难题。传统的测试时扩展策略（TTS）虽然能提升推理质量，但常导致过度思考、计算冗余，浪费算力。因此，亟需一种能自适应分配计算资源、减冗余且无需额外训练的新方法。

Method: 借鉴物理学中的动量思想，作者提出了MUR方法：实时追踪并聚合每步推理的不确定性，有意识地将更多推理预算分配给关键步骤。同时引入gamma-control机制，允许通过单一超参数灵活调整推理预算。还从理论和实践上证明了MUR在稳定性和偏置方面优于现有方法。

Result: 在四个高难度数据集（MATH-500、AIME24、AIME25和GPQA-diamond）和多个Qwen3模型尺寸（1.7B、4B、8B）上，MUR与其他TTS方法对比测试。实验结果表明，MUR平均减少了超过50%的计算量，同时准确率提升了0.62%到3.37%。

Conclusion: MUR在无需附加训练的情况下，能够高效自适应地分配大模型推理时的计算预算，显著降低了计算资源消耗，并小幅提升推理准确率，为后续高效推理研究提供了新思路。

Abstract: Large Language Models (LLMs) have achieved impressive performance on
reasoning-intensive tasks, yet optimizing their reasoning efficiency remains an
open challenge. While Test-Time Scaling (TTS) improves reasoning quality, it
often leads to overthinking, wasting tokens on redundant computations. This
work investigates how to efficiently and adaptively guide LLM test-time scaling
without additional training. Inspired by the concept of momentum in physics, we
propose Momentum Uncertainty-guided Reasoning (MUR), which dynamically
allocates thinking budgets to critical reasoning steps by tracking and
aggregating stepwise uncertainty over time. To support flexible inference-time
control, we introduce gamma-control, a simple mechanism that tunes the
reasoning budget via a single hyperparameter. We provide in-depth theoretical
proof to support the superiority of MUR in terms of stability and biases. MUR
is comprehensively evaluated against various TTS methods across four
challenging benchmarks (MATH-500, AIME24, AIME25, and GPQA-diamond) using
different sizes of recent Qwen3 models (1.7B, 4B, and 8B). Results demonstrate
that MUR reduces computation by over 50% on average while improving accuracy by
0.62-3.37%.

</details>


### [184] [RefCritic: Training Long Chain-of-Thought Critic Models with Refinement Feedback](https://arxiv.org/abs/2507.15024)
*Qiaoyu Tang,Hao Xiang,Le Yu,Bowen Yu,Hongyu Lin,Yaojie Lu,Xianpei Han,Le Sun,Junyang Lin*

Main category: cs.CL

TL;DR: 本文提出了一种新的基于强化学习的评论模块RefCritic，以提升大语言模型的评判和引导能力，实验表明该方法在多个基准数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前主流的评论模块常采用有监督微调方法，但结果表明这种方式产生的评论浅显、缺乏深度与验证能力，难以有效指导模型改进。因此，亟需更加有效的技术以提升评论模块的能力。

Method: 作者提出RefCritic，一种基于思维链的强化学习评论模块，采用双重规则奖励：(1) 判断解答正误的实例级准确性；(2) 基于评论引导的模型改进准确性。旨在生成高质量、可操作的反馈，用以优化和指导模型。

Result: 在Qwen2.5-14B-Instruct和DeepSeek-R1-Distill-Qwen-14B两个模型上，RefCritic在五个基准上均表现出一致优势。在AIME25数据集上，分别带来6.8%和7.2%的性能提升。多数投票下，RefCritic筛选后的模型随投票数量增加，其扩展能力优于其他方法。此外，尽管只在整体解答层面训练，但RefCritic在ProcessBench上优于逐步监督方法。

Conclusion: RefCritic以强化学习及双重规则奖励实现了对评论模块能力的显著提升，在多项基准测试中优于传统有监督微调方法，证明了其生成高质量、可指导反馈的有效性和通用性。

Abstract: With the rapid advancement of Large Language Models (LLMs), developing
effective critic modules for precise guidance has become crucial yet
challenging. In this paper, we initially demonstrate that supervised
fine-tuning for building critic modules (which is widely adopted in current
solutions) fails to genuinely enhance models' critique abilities, producing
superficial critiques with insufficient reflections and verifications. To
unlock the unprecedented critique capabilities, we propose RefCritic, a
long-chain-of-thought critic module based on reinforcement learning with dual
rule-based rewards: (1) instance-level correctness of solution judgments and
(2) refinement accuracies of the policy model based on critiques, aiming to
generate high-quality evaluations with actionable feedback that effectively
guides model refinement. We evaluate RefCritic on Qwen2.5-14B-Instruct and
DeepSeek-R1-Distill-Qwen-14B across five benchmarks. On critique and refinement
settings, RefCritic demonstrates consistent advantages across all benchmarks,
e.g., 6.8\% and 7.2\% gains on AIME25 for the respective base models. Notably,
under majority voting, policy models filtered by RefCritic show superior
scaling with increased voting numbers. Moreover, despite training on
solution-level supervision, RefCritic outperforms step-level supervised
approaches on ProcessBench, a benchmark to identify erroneous steps in
mathematical reasoning.

</details>


### [185] [WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization](https://arxiv.org/abs/2507.15061)
*Zhengwei Tao,Jialong Wu,Wenbiao Yin,Junkai Zhang,Baixuan Li,Haiyang Shen,Kuan Li,Liwen Zhang,Xinyu Wang,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.CL

TL;DR: 本文提出了一种新的基于形式化的数据合成框架WebShaper，通过对信息检索（IS）任务进行集合论形式化，系统性地生成高质量训练数据，提升了大语言模型驱动的IS智能体的表现。


<details>
  <summary>Details</summary>
Motivation: 高质量信息检索训练数据稀缺，现有方法的问答生成与检索信息的结构常不一致，影响训练和推理效果。

Method: 提出WebShaper，用集合论系统性形式化IS任务，引入知识投影（KP）机制，通过操作组合实现推理结构的精细控制。合成过程包括生成种子任务、多步扩展，每步由智能体扩展现有问题并结合信息检索与验证工具，最终获得复杂且结构合理的问题数据集。

Result: 在合成数据集上训练模型后，在GAIA和WebWalkerQA等基准测试中，WebShaper展示了优于其他开源IS智能体的性能。

Conclusion: WebShaper框架通过任务的集合论形式化与数据合成，解决了IS训练数据不足和结构不一致问题，有效提升了IS智能体的推理与表现能力。

Abstract: The advent of Large Language Model (LLM)-powered agents has revolutionized
artificial intelligence by enabling solutions to complex, open-ended tasks
through web-based information-seeking (IS) capabilities. The scarcity of
high-quality training data has limited the development of IS agents. Existing
approaches typically adopt an information-driven paradigm that first collects
web data and then generates questions based on the retrieval. However, this may
lead to inconsistency between information structure and reasoning structure,
question and answer. To mitigate, we propose a formalization-driven IS data
synthesis framework WebShaper to construct a dataset. WebShaper systematically
formalizes IS tasks through set theory. Central to the formalization is the
concept of Knowledge Projections (KP), which enables precise control over
reasoning structure by KP operation compositions. During synthesis, we begin by
creating seed tasks, then use a multi-step expansion process. At each step, an
agentic Expander expands the current formal question more complex with
retrieval and validation tools based on our formalization. We train our model
on the synthesized dataset. Experiment results demonstrate that WebShaper
achieves state-of-the-art performance among open-sourced IS agents on GAIA and
WebWalkerQA benchmarks.

</details>


### [186] [Evaluation of Coding Schemes for Transformer-based Gene Sequence Modeling](https://arxiv.org/abs/2507.15087)
*Chenlei Gong,Yuanhe Tian,Lei Mao,Yan Song*

Main category: cs.CL

TL;DR: 本文系统比较了DNA序列Transformer建模中的k-mer与BPE分词、不同位置编码方法（sinusoidal、AliBi、RoPE）及不同层数对模型表现的影响，得出BPE和RoPE在DNA序列任务上有更优表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究将DNA序列作为特殊“语言”用Transformer建模，普遍采用k-mer和BPE等分词方式，但缺乏系统比较两者优劣，也不清楚不同位置编码和模型深度对性能的具体影响。

Method: 分别使用不同长度k-mer（k=1,3,4,5,6）、4096词BPE分词，以及三种位置编码（sinusoidal、AliBi、RoPE），在3、6、12、24层Transformer编码器上，从头开始训练模型，并在GUE基准集上评估各配置。

Result: BPE分词能通过可变长度分词有效压缩频繁基序，带来更高且更稳定的任务表现，并有助于模型泛化；RoPE更擅长捕捉周期性基序且对长序列有良好外推能力；AliBi对局部依赖任务也有良好表现。模型深度从3层提升到12层带来明显提升，24层提升有限甚至略有过拟合。

Conclusion: BPE分词和RoPE编码在DNA Transformer建模上效果更优。本文为DNA序列Transformer模型的分词和位置编码选择提供了实践指导。

Abstract: Currently, many studies view DNA sequences as a special type of language and
utilize Transformers to model them. These studies use fixed-length k-mer
segmentation and BPE subword tokenization but lack a systematic evaluation to
determine which is superior. We compare k-mer segmentation with k=1,3,4,5,6, a
4,096-token BPE vocabulary, and three positional encoding methods-sinusoidal,
AliBi, and RoPE. Each configuration is trained from scratch in 3, 6, 12, and
24-layer Transformer encoders and evaluated on GUE benchmark dataset. In
general, BPE delivers higher and more stable performance across tasks by
compressing frequent motifs into variable-length tokens, reducing sequence
length, and improving model generalization. RoPE excels at capturing periodic
motifs and extrapolating to long sequences, while AliBi also performs well on
tasks driven by local dependencies. In terms of depth, we observe significant
gains when increasing layers from 3 to 12, with only marginal improvements or
slight overfitting at 24 layers. This study provides practical guidance for
designing tokenization and positional encoding in DNA Transformer models.

</details>


### [187] [A Penalty Goes a Long Way: Measuring Lexical Diversity in Synthetic Texts Under Prompt-Influenced Length Variations](https://arxiv.org/abs/2507.15092)
*Vijeta Deshpande,Ishita Dasgupta,Uttaran Bhattacharya,Somdeb Sarkhel,Saayan Mitra,Anna Rumshisky*

Main category: cs.CL

TL;DR: 本文提出了一种新的文本多样性度量方法Penalty-Adjusted Type-Token Ratio（PATTR），解决了现有指标在处理不同文本长度时的偏差问题，并在合成数据多样性评估中取得了更优表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型生成的合成文本日益用于模型训练和提升，而文本多样性至关重要。虽然提示工程用于提升多样性，但针对提示变化如何影响文本长度及其对词汇多样性度量的影响尚未被充分研究。

Method: 作者提出了一种新的多样性度量指标PATTR，该指标针对任务设定的目标响应长度进行了惩罚调整，使其对文本长度变化更具鲁棒性。采用七种主流模型（LLaMA、OLMo、Phi系列）在创意写作任务（视频脚本生成）上生成2000万字合成语料，评估PATTR与已用指标（MATTR、CR）在多样性上的表现。

Result: 实验证明，文本长度变化会使现有多样性度量偏向短文本。PATTR通过引入目标长度，有效减轻了该偏见。在选取最具词汇多样性的高排名响应时，PATTR能在保证长度符合预期的同时取得与或优于MATTR和CR的多样性表现。

Conclusion: PATTR是一种鲁棒且更公正的文本多样性评估指标，可显著改善合成数据的质量筛选，推动LLM训练与应用中的多样性提升。

Abstract: Synthetic text generated by Large Language Models (LLMs) is increasingly used
for further training and improvement of LLMs. Diversity is crucial for the
effectiveness of synthetic data, and researchers rely on prompt engineering to
improve diversity. However, the impact of prompt variations on response text
length, and, more importantly, the consequential effect on lexical diversity
measurements, remain underexplored. In this work, we propose Penalty-Adjusted
Type-Token Ratio (PATTR), a diversity metric robust to length variations. We
generate a large synthetic corpus of over 20M words using seven models from the
LLaMA, OLMo, and Phi families, focusing on a creative writing task of video
script generation, where diversity is crucial. We evaluate per-response lexical
diversity using PATTR and compare it against existing metrics of Moving-Average
TTR (MATTR) and Compression Ratio (CR). Our analysis highlights how text length
variations introduce biases favoring shorter responses. Unlike existing
metrics, PATTR explicitly considers the task-specific target response length
($L_T$) to effectively mitigate length biases. We further demonstrate the
utility of PATTR in filtering the top-10/100/1,000 most lexically diverse
responses, showing that it consistently outperforms MATTR and CR by yielding on
par or better diversity with high adherence to $L_T$.

</details>


### [188] [Filling the Gap: Is Commonsense Knowledge Generation useful for Natural Language Inference?](https://arxiv.org/abs/2507.15100)
*Chathuri Jayaweera,Brianna Yanqui,Bonnie Dorr*

Main category: cs.CL

TL;DR: 本论文探讨了大型语言模型（LLM）在自然语言推理（NLI）中生成常识知识的潜力，并评估其对推理准确性的影响。作者发现，虽然显式引入常识知识未能带来整体性能的大幅提升，但有助于区分不同类型的推理关系。


<details>
  <summary>Details</summary>
Motivation: 现有的常识知识库无法涵盖多样化的前提和假设组合，限制了自然语言推理系统的表现。本研究旨在探讨利用LLM自动生成常识知识以增强NLI任务。

Method: 作者分析并修改了现有的度量指标，用于评估LLM生成常识知识时的事实性和一致性。同时实验测试将这些生成的常识知识显式整合进NLI任务流程，对比预测准确率。

Result: 实验结果显示，将LLM生成的常识知识显式引入NLI任务，对整体准确率影响有限，但在区分‘蕴涵’、‘矛盾’和‘中性’三类推理关系中有一定提升，特别是有助于更好地区分‘蕴涵’实例。

Conclusion: 尽管直接引入LLM生成的常识知识未带来全面、显著的性能提升，但其在部分推理类型区分上发挥了积极作用。未来可进一步优化知识生成与整合机制，以提升NLI系统性能。

Abstract: Natural Language Inference (NLI) is the task of determining the semantic
entailment of a premise for a given hypothesis. The task aims to develop
systems that emulate natural human inferential processes where commonsense
knowledge plays a major role. However, existing commonsense resources lack
sufficient coverage for a variety of premise-hypothesis pairs. This study
explores the potential of Large Language Models as commonsense knowledge
generators for NLI along two key dimensions: their reliability in generating
such knowledge and the impact of that knowledge on prediction accuracy. We
adapt and modify existing metrics to assess LLM factuality and consistency in
generating in this context. While explicitly incorporating commonsense
knowledge does not consistently improve overall results, it effectively helps
distinguish entailing instances and moderately improves distinguishing
contradictory and neutral inferences.

</details>


### [189] [From Disagreement to Understanding: The Case for Ambiguity Detection in NLI](https://arxiv.org/abs/2507.15114)
*Chathuri Jayaweera,Bonnie Dorr*

Main category: cs.CL

TL;DR: 本文认为在自然语言推理（NLI）中的标注分歧往往源于内容歧义，并非单纯的无用噪声，提出需系统性识别和分类歧义类型，推动开发更与人类理解一致的NLI系统。


<details>
  <summary>Details</summary>
Motivation: 传统NLI任务多把标注分歧当作‘噪声’，简单忽略或消解，但实际上，很多分歧体现出了因内容歧义导致的人类理解差异。现有方法缺乏对歧义的系统认识和处理，阻碍了模型跟人类解释对齐。

Method: 提出了一个综合已有分类法的统一框架，系统化识别歧义输入对并进行歧义类型分类，并通过具体示例分析歧义影响标注决策。

Result: 展示了多个歧义子类型的实际例子，揭示了歧义如何影响标注者判断，论证了对歧义检测和分析的必要性。同时指出缺乏相关标注数据集是现有工作的主要局限。

Conclusion: 主张NLI研究应转向歧义感知路径，开发歧义标注数据和无监督检测方法，以实现更健壮、可解释和与人类理解更一致的NLI系统。

Abstract: This position paper argues that annotation disagreement in Natural Language
Inference (NLI) is not mere noise but often reflects meaningful interpretive
variation, especially when triggered by ambiguity in the premise or hypothesis.
While underspecified guidelines and annotator behavior can contribute to
variation, content-based ambiguity offers a process-independent signal of
divergent human perspectives. We call for a shift toward ambiguity-aware NLI by
systematically identifying ambiguous input pairs and classifying ambiguity
types. To support this, we present a unified framework that integrates existing
taxonomies and illustrate key ambiguity subtypes through concrete examples.
These examples reveal how ambiguity shapes annotator decisions and motivate the
need for targeted detection methods that better align models with human
interpretation. A key limitation is the lack of datasets annotated for
ambiguity and subtypes. We propose addressing this gap through new annotated
resources and unsupervised approaches to ambiguity detection -- paving the way
for more robust, explainable, and human-aligned NLI systems.

</details>


### [190] [A Case Against Implicit Standards: Homophone Normalization in Machine Translation for Languages that use the Ge'ez Script](https://arxiv.org/abs/2507.15142)
*Hellina Hailu Nigatu,Atnafu Lambebo Tonja,Henok Biadglign Ademtew,Hizkel Mitiku Alemayehu,Negasi Haile Abadi,Tadesse Destaw Belay,Seid Muhie Yimam*

Main category: cs.CL

TL;DR: 本文探讨同音字归一化对Amharic和其他使用Ge'ez文字的语言自然语言处理的影响，提出了推理后归一化方案以提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有Amharic NLP中常在预处理中将同音字归一化，这虽提升了指标但导致模型难以理解书写多样性，并可能影响迁移学习。本研究旨在系统评估归一化对单语和跨语种模型的影响。

Method: 作者分别在单语（Amharic）和跨语种迁移场景下比较了使用和不使用训练数据归一化的模型表现，并首次提出只对模型输出进行后处理（推理后归一化），而不在训练阶段统一归一化。

Result: 推理后归一化简单易行，在提升BLEU分数（最高提升1.03分）的同时保留了训练语料的语言特征。

Conclusion: 推理后归一化能在性能提升和语言多样性表达两者之间取得平衡，建议后续NLP研究更多关注对语言本身的理解和保护。

Abstract: Homophone normalization, where characters that have the same sound in a
writing script are mapped to one character, is a pre-processing step applied in
Amharic Natural Language Processing (NLP) literature. While this may improve
performance reported by automatic metrics, it also results in models that are
not able to understand different forms of writing in a single language.
Further, there might be impacts in transfer learning, where models trained on
normalized data do not generalize well to other languages. In this paper, we
experiment with monolingual training and cross-lingual transfer to understand
the impacts of normalization on languages that use the Ge'ez script. We then
propose a post-inference intervention in which normalization is applied to
model predictions instead of training data. With our simple scheme of
post-inference normalization, we show that we can achieve an increase in BLEU
score of up to 1.03 while preserving language features in training. Our work
contributes to the broader discussion on technology-facilitated language change
and calls for more language-aware interventions.

</details>


### [191] [What Level of Automation is "Good Enough"? A Benchmark of Large Language Models for Meta-Analysis Data Extraction](https://arxiv.org/abs/2507.15152)
*Lingbo Li,Anuradha Mathrani,Teo Susnjak*

Main category: cs.CL

TL;DR: 本研究评估了三种大语言模型（Gemini-2.0-flash、Grok-3、GPT-4o-mini）在医学RCT数据自动提取任务中的表现，发现定制化提示可显著提升召回率，并提出了分级使用指南。


<details>
  <summary>Details</summary>
Motivation: 将随机对照试验（RCT）全文中的数据自动提取用于荟萃分析是一项重要但尚未完全解决的难题。过去依赖人工过程，自动化手段有助于提升效率和规模，但当前大模型能力和实用性的系统性评估不足。

Method: 作者选用三种主流大语言模型，在高血压、糖尿病和骨科三个医学领域，对统计结果、偏倚风险、研究特征等三类数据进行自动提取性能测试，涵盖四种不同提示词策略（基础、自省、模型集成和定制化提示），并评估其精确率和召回率。

Result: 所有模型都表现出高精确率，但召回率普遍较低，常遗漏关键信息。通过定制化提示，召回率最多可提升15%。

Conclusion: 研究证明大语言模型在数据提取方面的潜力，同时需通过方法改良（如定制化提示）克服信息遗漏，并提出了分级自动化指导原则，建议将不同复杂度和风险的数据任务匹配不同自动化程度，以平衡效率与安全性。

Abstract: Automating data extraction from full-text randomised controlled trials (RCTs)
for meta-analysis remains a significant challenge. This study evaluates the
practical performance of three LLMs (Gemini-2.0-flash, Grok-3, GPT-4o-mini)
across tasks involving statistical results, risk-of-bias assessments, and
study-level characteristics in three medical domains: hypertension, diabetes,
and orthopaedics. We tested four distinct prompting strategies (basic
prompting, self-reflective prompting, model ensemble, and customised prompts)
to determine how to improve extraction quality. All models demonstrate high
precision but consistently suffer from poor recall by omitting key information.
We found that customised prompts were the most effective, boosting recall by up
to 15\%. Based on this analysis, we propose a three-tiered set of guidelines
for using LLMs in data extraction, matching data types to appropriate levels of
automation based on task complexity and risk. Our study offers practical advice
for automating data extraction in real-world meta-analyses, balancing LLM
efficiency with expert oversight through targeted, task-specific automation.

</details>


### [192] [Collaborative Distillation Strategies for Parameter-Efficient Language Model Deployment](https://arxiv.org/abs/2507.15198)
*Xiandong Meng,Yan Wu,Yexin Tian,Xin Hu,Tianze Kang,Junliang Du*

Main category: cs.CL

TL;DR: 本文提出一种由多个教师模型引导的蒸馏策略，以实现大语言模型的小型化、高效推理和高性能表现。实验结果显示，该方法在多个指标上优于主流蒸馏方法。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在实际部署时面临运算成本高、推断速度慢的问题。为提升模型小型化后在理解与生成上的能力，需要更有效的知识蒸馏技术。

Method: 构建多个教师模型，将其输出概率分布和中间语义特征融合，引导学生模型多源学习。核心包括加权输出融合机制、特征对齐损失函数和熵驱动的动态教师加权策略，提升知识转移的质量与稳定性。

Result: 学生模型在多教师引导下更好地捕获语义信息，在语言建模、文本生成、多任务学习等任务中表现优秀，并在困惑度、蒸馏损失及生成质量等指标上优于多种主流蒸馏方法。

Conclusion: 该方法为大语言模型高效压缩提供可行技术路径，证明了多教师协同机制在复杂语言建模任务中的有效性。

Abstract: This paper addresses the challenges of high computational cost and slow
inference in deploying large language models. It proposes a distillation
strategy guided by multiple teacher models. The method constructs several
teacher models and integrates their output probability distributions and
intermediate semantic features. This guides the student model to learn from
multiple sources of knowledge. As a result, the student model gains stronger
language understanding and generation ability while maintaining a small
parameter size. To achieve this, the paper introduces a weighted output fusion
mechanism, a feature alignment loss function, and an entropy-driven dynamic
teacher weighting strategy. These components improve the quality and stability
of knowledge transfer during distillation. Under multi-teacher guidance, the
student model captures semantic information more effectively and demonstrates
strong performance across multiple evaluation metrics. In particular, the
method shows high consistency in expression, generalization ability, and task
adaptability in tasks such as language modeling, text generation, and
multi-task learning. The experiments compare the proposed method with several
widely adopted distillation approaches. The results further confirm its overall
advantages in perplexity, distillation loss, and generation quality. This study
provides a feasible technical path for the efficient compression of large-scale
language models. It also demonstrates the effectiveness of multi-teacher
collaborative mechanisms in complex language modeling tasks.

</details>


### [193] [SOI Matters: Analyzing Multi-Setting Training Dynamics in Pretrained Language Models via Subsets of Interest](https://arxiv.org/abs/2507.15236)
*Shayan Vassef,Amirhossein Dabiriaghdam,Mohammadreza Bakhtiari,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: 本文研究了多任务、多语言和多源学习对预训练语言模型鲁棒性和性能的影响，并提出了SOI（兴趣子集）框架，揭示了模型训练中的多样学习行为和性能变化。


<details>
  <summary>Details</summary>
Motivation: 尽管多任务、多语言及多源学习在自然语言处理领域有应用，但其具体对预训练语言模型的影响机制和表现仍不清晰，因此需要系统分析和理解，以进一步提升模型泛化和实用能力。

Method: 作者提出SOI（一种六类训练样本行为模式的新框架），通过SOI转移热图和可视化工具，研究从单一到多种训练设定时数据样本的类别转移。并在三种实验对照下进行系统实验：多任务vs单任务（英语推理、复述、情感）；多源vs单源（情感分析）；多语vs单语（意图分类，涉及法语、英语、波斯语）。此外，引入分阶段微调策略，第二阶段依据SOI选择子集提升表现。

Result: 多源学习能稳定提升领域外表现，最高提升7%；多任务学习结果有波动，但在相似任务组合下提升显著。两阶段微调结合SOI子集筛选可实现额外性能提升。

Conclusion: SOI框架有效揭示并解释了多设定训练下数据表现变化，分析结果为语言模型优化提供了新思路和实用方法。

Abstract: This work investigates the impact of multi-task, multi-lingual, and
multi-source learning approaches on the robustness and performance of
pretrained language models. To enhance this analysis, we introduce Subsets of
Interest (SOI), a novel categorization framework that identifies six distinct
learning behavior patterns during training, including forgettable examples,
unlearned examples, and always correct examples. Through SOI transition
heatmaps and dataset cartography visualization, we analyze how examples shift
between these categories when transitioning from single-setting to
multi-setting configurations. We perform comprehensive experiments across three
parallel comparisons: multi-task vs. single-task learning using English tasks
(entailment, paraphrase, sentiment), multi-source vs. single-source learning
using sentiment analysis datasets, and multi-lingual vs. single-lingual
learning using intent classification in French, English, and Persian. Our
results demonstrate that multi-source learning consistently improves
out-of-distribution performance by up to 7%, while multi-task learning shows
mixed results with notable gains in similar task combinations. We further
introduce a two-stage fine-tuning approach where the second stage leverages
SOI-based subset selection to achieve additional performance improvements.
These findings provide new insights into training dynamics and offer practical
approaches for optimizing multi-setting language model performance.

</details>


### [194] [ChiMed 2.0: Advancing Chinese Medical Dataset in Facilitating Large Language Modeling](https://arxiv.org/abs/2507.15275)
*Yuanhe Tian,Junjie Liu,Zhizhou Kou,Yuxiang Li,Yan Song*

Main category: cs.CL

TL;DR: ChiMed 2.0 是一个面向中文医疗领域的大规模、高质量数据集，包括预训练、监督微调及强化学习数据，可支持中文医疗大模型的全流程训练。


<details>
  <summary>Details</summary>
Motivation: 目前中文医疗领域数据集体量小、领域覆盖窄，且多仅支持微调，无法满足预训练和人类反馈强化学习的需求，制约了医疗大模型的研究与应用。

Method: 作者扩展前期工作，构建了ChiMed 2.0数据集，包含中医经典和现代医学数据，涵盖预训练（164.8K文档）、监督微调（351.6K问答对）、RLHF（41.7K偏好数据），并利用该数据集在多种通用大模型上进行预训练、监督微调和RLHF训练，最后通过医疗基准测试验证效果。

Result: 在不同规模的大模型中，利用ChiMed 2.0 进行训练，相较其他数据集取得了更好的性能提升，证明了数据集的有效性和应用价值。

Conclusion: ChiMed 2.0数据集提升了中文医疗大模型的训练效果和适用范围，可为后续医疗AI研究与应用提供坚实支持。

Abstract: Building high-quality data resources is crucial for advancing artificial
intelligence research and applications in specific domains, particularly in the
Chinese medical domain. Existing Chinese medical datasets are limited in size
and narrow in domain coverage, falling short of the diverse corpora required
for effective pre-training. Moreover, most datasets are designed solely for LLM
fine-tuning and do not support pre-training and reinforcement learning from
human feedback (RLHF). In this paper, we propose a Chinese medical dataset
named ChiMed 2.0, which extends our previous work ChiMed, and covers data
collected from Chinese medical online platforms and generated by LLMs. ChiMed
2.0 contains 204.4M Chinese characters covering both traditional Chinese
medicine classics and modern general medical data, where there are 164.8K
documents for pre-training, 351.6K question-answering pairs for supervised
fine-tuning (SFT), and 41.7K preference data tuples for RLHF. To validate the
effectiveness of our approach for training a Chinese medical LLM, we conduct
further pre-training, SFT, and RLHF experiments on representative general
domain LLMs and evaluate their performance on medical benchmark datasets. The
results show performance gains across different model scales, validating the
dataset's effectiveness and applicability.

</details>


### [195] [A Novel Self-Evolution Framework for Large Language Models](https://arxiv.org/abs/2507.15281)
*Haoran Sun,Zekun Zhang,Shaoning Zeng*

Main category: cs.CL

TL;DR: 本文提出了一种名为DPSE的框架，能够在优化大语言模型用户偏好的同时提升其领域能力，实现模型的自我进化，实验证明该方法优于现有的后训练策略。


<details>
  <summary>Details</summary>
Motivation: 现有对大语言模型的后训练方法更多关注用户偏好，提升了对齐能力，但未能有效增强模型的领域认知能力。为实现更全面的模型自我进化，需要设计兼顾用户适应性和领域能力的优化路线。

Method: 提出Dual-Phase Self-Evolution (DPSE) 框架。DPSE通过引入Censor模块，提取交互信号并估算用户满意度，基于主题和用户偏好指导结构化数据扩充。扩充数据后，采用两阶段微调：首先是有监督的领域微调，再进行基于频率的偏好优化。

Result: 在通用NLP基准和长期对话任务中，DPSE在模型用户对齐和领域认知两个层面，均超过了传统有监督微调、偏好优化和记忆增强等现有方法。消融实验进一步验证了各模块的有效性。

Conclusion: DPSE为大语言模型提供了一个结合用户偏好与领域能力、可持续自主进化的后训练路径，具备比现有方法更优的实际性能和应用前景。

Abstract: The capabilities of Large Language Models (LLMs) are limited to some extent
by pre-training, so some researchers optimize LLMs through post-training.
Existing post-training strategies, such as memory-based retrieval or preference
optimization, improve user alignment yet fail to enhance the model's domain
cognition. To bridge this gap, we propose a novel Dual-Phase Self-Evolution
(DPSE) framework that jointly optimizes user preference adaptation and
domain-specific competence. DPSE introduces a Censor module to extract
multi-dimensional interaction signals and estimate satisfaction scores, which
guide structured data expansion via topic-aware and preference-driven
strategies. These expanded datasets support a two-stage fine-tuning pipeline:
supervised domain grounding followed by frequency-aware preference
optimization. Experiments across general NLP benchmarks and long-term dialogue
tasks demonstrate that DPSE consistently outperforms Supervised Fine-Tuning,
Preference Optimization, and Memory-Augmented baselines. Ablation studies
validate the contribution of each module. In this way, our framework provides
an autonomous path toward continual self-evolution of LLMs.

</details>


### [196] [Beyond Easy Wins: A Text Hardness-Aware Benchmark for LLM-generated Text Detection](https://arxiv.org/abs/2507.15286)
*Navid Ayoobi,Sadat Shahriar,Arjun Mukherjee*

Main category: cs.CL

TL;DR: 本论文提出SHIELD新的AI文本检测器评估基准，注重检测器在实际应用中的可靠性和稳定性，挑战现有方法对抗可控难度的人化攻击。


<details>
  <summary>Details</summary>
Motivation: 当前AI文本检测器大多仅报告如AUROC等常规指标，忽视了实际应用中即使较小的误报率也会严重影响系统部署。此外，真正的应用场景需要预先设定阈值并保证检测器在多领域和对抗场景下性能稳定，但既有研究和基准很少关注这些关键问题。

Method: 作者提出了SHIELD基准，将检测器的可靠性（低误报率）和稳定性（跨领域、一致表现）整合入一套新的评估指标。同时，设计了模型无关的人化攻击方法，可以通过调整参数改变攻击难度，对检测器鲁棒性进行更严苛的测试。

Result: 实验表明，现有最先进（SOTA）的零样本检测方法在作者提出的更加严苛的人化攻击和新的评价方法下，可靠性和稳定性都受到挑战，表现不理想。

Conclusion: 论文重新定义了AI文本检测器的评估标准，更加贴近实际应用需求。SHIELD基准和人化框架有助于开发更可靠、更稳健的检测器，并推动领域内更加公平、实用的评测方式。

Abstract: We present a novel evaluation paradigm for AI text detectors that prioritizes
real-world and equitable assessment. Current approaches predominantly report
conventional metrics like AUROC, overlooking that even modest false positive
rates constitute a critical impediment to practical deployment of detection
systems. Furthermore, real-world deployment necessitates predetermined
threshold configuration, making detector stability (i.e. the maintenance of
consistent performance across diverse domains and adversarial scenarios), a
critical factor. These aspects have been largely ignored in previous research
and benchmarks. Our benchmark, SHIELD, addresses these limitations by
integrating both reliability and stability factors into a unified evaluation
metric designed for practical assessment. Furthermore, we develop a post-hoc,
model-agnostic humanification framework that modifies AI text to more closely
resemble human authorship, incorporating a controllable hardness parameter.
This hardness-aware approach effectively challenges current SOTA zero-shot
detection methods in maintaining both reliability and stability. (Data and
code: https://github.com/navid-aub/SHIELD-Benchmark)

</details>


### [197] [On the Inevitability of Left-Leaning Political Bias in Aligned Language Models](https://arxiv.org/abs/2507.15328)
*Thilo Hagendorff*

Main category: cs.CL

TL;DR: 本文探讨了AI对齐（alignment）的基本原则——即让大型语言模型（LLM）做到无害、有帮助和诚实（HHH）——与大众对LLM偏向左翼政治立场的担忧之间的关系。作者认为，遵循HHH原则训练的系统必然会表现出左翼倾向，因为这些准则本身就与进步主义和左翼价值观相符。


<details>
  <summary>Details</summary>
Motivation: 目前AI对齐强调HHH原则，但同时关于LLM存在左翼偏见的讨论日益增多，相关研究多视“左倾”为风险或问题。作者试图澄清这种矛盾，并质疑这一视角是否反而违背了AI对齐目标。

Method: 作者通过分析AI对齐目标的道德基础，将其价值导向与左翼和右翼政治理念作对比，并批判性回顾当前关于模型政治偏向的研究立场。

Result: 作者认为，AI对齐所倡导的无害、包容、公平和真实性本质上契合进步主义（左翼）立场，而部分右翼意识形态则与这些原则存在冲突。因此，LLM展现出左翼偏见并非意外，而是对齐目标的自然产物。

Conclusion: 如果AI社区坚持HHH原则，就无法避免LLM在某种程度上表现出左翼政治倾向。将此倾向当做风险反而是对AI对齐目标的误解乃至违背。

Abstract: The guiding principle of AI alignment is to train large language models
(LLMs) to be harmless, helpful, and honest (HHH). At the same time, there are
mounting concerns that LLMs exhibit a left-wing political bias. Yet, the
commitment to AI alignment cannot be harmonized with the latter critique. In
this article, I argue that intelligent systems that are trained to be harmless
and honest must necessarily exhibit left-wing political bias. Normative
assumptions underlying alignment objectives inherently concur with progressive
moral frameworks and left-wing principles, emphasizing harm avoidance,
inclusivity, fairness, and empirical truthfulness. Conversely, right-wing
ideologies often conflict with alignment guidelines. Yet, research on political
bias in LLMs is consistently framing its insights about left-leaning tendencies
as a risk, as problematic, or concerning. This way, researchers are actively
arguing against AI alignment, tacitly fostering the violation of HHH
principles.

</details>


### [198] [Reasoning Models are Test Exploiters: Rethinking Multiple-Choice](https://arxiv.org/abs/2507.15337)
*Narun Raman,Taylor Lundy,Kevin Leyton-Brown*

Main category: cs.CL

TL;DR: 本文系统评估了15个问答基准和25个不同体量的大语言模型（LLM），比较了多种问答呈现方式下的模型表现，指出MCQA（多选题问答）已不再适合作为当前先进模型下游能力的代表性评价方法。


<details>
  <summary>Details</summary>
Motivation: 虽然实际应用中很少有明确选项让模型选择，但多选题型常用于评估模型，这是因为易于自动评分且结果与实际表现相关。然而，随着大模型推理能力提升，现有评测方式是否仍具代表性值得质疑。

Method: 作者对15个QA基准和25种LLM组合，尝试了5种问答呈现方式，包括：是否给选项、是否用“以上皆非”替换正确答案、推理发生在选项前/后等，系统比较各情形下模型表现。

Result: 如果推理发生在选项展示前，MCQA仍能较好反映下游表现。但如果模型能在看到选项后再推理，则其MCQA得分会显著高于无选项（自由文本）表现。

Conclusion: MCQA已经不能准确反映当今先进模型的真实下游能力。文章提出了更能抵抗选项信息偏倚、客观反映模型推理能力的评测基准设计建议。

Abstract: When evaluating Large Language Models (LLMs) in question-answering domains,
it is common to ask the model to choose among a fixed set of choices (so-called
multiple-choice question-answering, or MCQA). Although downstream tasks of
interest typically do not provide systems with explicit options among which to
choose, this approach is nevertheless widely used because it makes it makes
automatic grading straightforward and has tended to produce challenging
benchmarks that correlate sufficiently well with downstream performance. This
paper investigates the extent to which this trend continues to hold for
state-of-the-art reasoning models, describing a systematic evaluation of $15$
different question-answering benchmarks (e.g., MMLU, HLE) and $25$ different
LLMs (including small models such as Qwen 7B and relatively large models such
as Llama 70B). For each model-benchmark pair, we considered $5$ ways of
presenting the model with questions, including variations on whether multiple
choices were offered to the model at all; whether "none of the above" sometimes
replaced the right answer; and whether the model was permitted to perform
chain-of-thought reasoning before and/or after the choices were presented. MCQA
remained a good proxy for the downstream performance of models as long as they
were allowed to perform chain-of-thought reasoning only before being presented
with the options among which they had to select. On the other hand, large
models that were able to perform reasoning after being given a set of options
tended to significantly outperform their free-text performance due to
exploiting the information in the options. We conclude that MCQA is no longer a
good proxy for assessing downstream performance of state-of-the-art models, and
offer practical guidelines for designing more robust, bias-resistant benchmarks
that better reflect LLMs' genuine reasoning capabilities.

</details>


### [199] [LionGuard 2: Building Lightweight, Data-Efficient & Localised Multilingual Content Moderators](https://arxiv.org/abs/2507.15339)
*Leanne Tan,Gabriel Chua,Ziyu Ge,Roy Ka-Wei Lee*

Main category: cs.CL

TL;DR: LionGuard 2是一款专为新加坡多语言环境（英语、华语、马来语、部分泰米尔语）设计的轻量级内容审核模型，性能优于多款主流系统，并已在政府实际部署。


<details>
  <summary>Details</summary>
Motivation: 现有内容审核系统支持多语种，但对本地化和低资源语种支持不足，存在安全隐患。为此，作者希望开发适合新加坡多语言环境且高效的审核工具。

Method: LionGuard 2基于OpenAI预训练嵌入和多头有序分类器构建，无需大模型微调，通过高质量本地数据和多语言嵌入实现强劲性能。

Result: LionGuard 2在17个基准测试中优于多款商业及开源系统，能够有效处理新加坡本地和英文公开数据集中的内容。

Conclusion: 依靠高质量本地数据与强健的多语种嵌入，轻量模型可以在本地化审核任务中达到高性能，无需大模型微调。模型权重与部分数据开放，推动LLM安全研究。

Abstract: Modern moderation systems increasingly support multiple languages, but often
fail to address localisation and low-resource variants - creating safety gaps
in real-world deployments. Small models offer a potential alternative to large
LLMs, yet still demand considerable data and compute. We present LionGuard 2, a
lightweight, multilingual moderation classifier tailored to the Singapore
context, supporting English, Chinese, Malay, and partial Tamil. Built on
pre-trained OpenAI embeddings and a multi-head ordinal classifier, LionGuard 2
outperforms several commercial and open-source systems across 17 benchmarks,
including both Singapore-specific and public English datasets. The system is
actively deployed within the Singapore Government, demonstrating practical
efficacy at scale. Our findings show that high-quality local data and robust
multilingual embeddings can achieve strong moderation performance, without
fine-tuning large models. We release our model weights and part of our training
data to support future work on LLM safety.

</details>


### [200] [Probing Information Distribution in Transformer Architectures through Entropy Analysis](https://arxiv.org/abs/2507.15347)
*Amedeo Buonanno,Alessandro Rivetti,Francesco A. N. Palmieri,Giovanni Di Gennaro,Gianmarco Romano*

Main category: cs.CL

TL;DR: 本文利用熵分析的方法，研究Transformer结构内部信息分布与流动特点，通过在GPT类大模型上的案例分析，展示此方法能够揭示模型内部行为和表示的信息。


<details>
  <summary>Details</summary>
Motivation: Transformer类模型结构复杂、难以解释，为提升其可解释性和评估能力，作者提出用熵分析来刻画、理解模型内部信息处理过程。

Method: 量化单词（token）层面的不确定性，通过分析Transformer模型处理过程不同阶段的熵分布，揭示信息如何在模型各层流动与转换；并以GPT大模型为例作实证分析。

Result: 通过对GPT模型的测试，验证了熵分析方法能有效识别模型在处理信息时的分布、变化规律，从而洞悉模型行为及其内部表示特性。

Conclusion: 熵分析为Transformer模型的可解释性与评估提供了新思路，有助于更深入理解大语言模型信息处理机制，对模型解释和后续框架开发具有参考价值。

Abstract: This work explores entropy analysis as a tool for probing information
distribution within Transformer-based architectures. By quantifying token-level
uncertainty and examining entropy patterns across different stages of
processing, we aim to investigate how information is managed and transformed
within these models. As a case study, we apply the methodology to a GPT-based
large language model, illustrating its potential to reveal insights into model
behavior and internal representations. This approach may offer insights into
model behavior and contribute to the development of interpretability and
evaluation frameworks for transformer-based models

</details>


### [201] [Metaphor and Large Language Models: When Surface Features Matter More than Deep Understanding](https://arxiv.org/abs/2507.15357)
*Elisa Sanchez-Bayona,Rodrigo Agerri*

Main category: cs.CL

TL;DR: 本文系统评估了大语言模型（LLMs）在多数据集、多任务、多提示配置下解释隐喻的能力，发现其表现受表层特征影响更大，对隐喻的真实理解有限。


<details>
  <summary>Details</summary>
Motivation: 隐喻处理是自然语言处理中的一个重要难题，但以往研究大多局限于单一数据集和人工构造任务，缺乏对LLMs在现实世界隐喻解释能力的全面评估。

Method: 作者使用多个公开数据集，包括推理和隐喻标注，针对自然语言推断（NLI）和问答（QA）任务，设计多种提示和任务，测试LLMs在不同情形下的隐喻解释表现。

Result: 实验表明，LLMs在隐喻解释任务上的表现更依赖词汇重叠、句长等浅层特征，而非真正对隐喻内容的认知，所谓对隐喻语言的“涌现能力”更多源于表征、上下文学习及语言知识的结合。

Conclusion: 当前LLMs对隐喻及修辞性语言的处理能力受限，暴露出其理解深层语义的不足。作者建议未来需采用更真实、更具挑战性的评估框架，以推动模型隐喻理解能力提升。

Abstract: This paper presents a comprehensive evaluation of the capabilities of Large
Language Models (LLMs) in metaphor interpretation across multiple datasets,
tasks, and prompt configurations. Although metaphor processing has gained
significant attention in Natural Language Processing (NLP), previous research
has been limited to single-dataset evaluations and specific task settings,
often using artificially constructed data through lexical replacement. We
address these limitations by conducting extensive experiments using diverse
publicly available datasets with inference and metaphor annotations, focusing
on Natural Language Inference (NLI) and Question Answering (QA) tasks. The
results indicate that LLMs' performance is more influenced by features like
lexical overlap and sentence length than by metaphorical content, demonstrating
that any alleged emergent abilities of LLMs to understand metaphorical language
are the result of a combination of surface-level features, in-context learning,
and linguistic knowledge. This work provides critical insights into the current
capabilities and limitations of LLMs in processing figurative language,
highlighting the need for more realistic evaluation frameworks in metaphor
interpretation tasks. Data and code are publicly available.

</details>


### [202] [STITCH: Simultaneous Thinking and Talking with Chunked Reasoning for Spoken Language Models](https://arxiv.org/abs/2507.15375)
*Cheng-Han Chiang,Xiaofei Wang,Linjie Li,Chung-Ching Lin,Kevin Lin,Shujie Liu,Zhendong Wang,Zhengyuan Yang,Hung-yi Lee,Lijuan Wang*

Main category: cs.CL

TL;DR: 该论文提出了一种新的语音生成方法“Stitch”，使得口语语言模型（SLM）能够一边思考一边说话，在不增加响应延迟的情况下，实现了更强的推理能力。


<details>
  <summary>Details</summary>
Motivation: 目前的口语语言模型仅能直接生成语音回复，缺乏像人类一样在发言前进行无声思考与推理的能力。尽管可以通过完整生成推理链来改善推理，但会严重增加响应延迟。研究希望实现低延迟下的强推理口语交互。

Method: 提出了一种称为Stitch的方法，将无声推理过程与口语回复生成交错进行。当模型播放一段语音回复时，利用这段时间生成下一步的无声推理，从而实现思考与发言的并行。

Result: 在数学推理数据集上，Stitch方法较不含无声推理的基线方法提升了15%的性能；在非推理数据集上，表现与基线方法持平。最重要的是，Stitch并未增加系统的回复延迟。

Conclusion: Stitch有效提升了SLM在推理任务上的表现，同时保证了低延迟回复，为实现更自然、智能的人机语音交互提供了新方向。

Abstract: Spoken Language Models (SLMs) are designed to take speech inputs and produce
spoken responses. However, current SLMs lack the ability to perform an
internal, unspoken thinking process before responding. In contrast, humans
typically engage in complex mental reasoning internally, enabling them to
communicate ideas clearly and concisely. Thus, integrating an unspoken thought
process into SLMs is highly desirable. While naively generating a complete
chain-of-thought (CoT) reasoning before starting to talk can enable thinking
for SLMs, this induces additional latency for the speech response, as the CoT
reasoning can be arbitrarily long. To solve this issue, we propose Stitch, a
novel generation method that alternates between the generation of unspoken
reasoning chunks and spoken response chunks. Since the audio duration of a
chunk of spoken response is much longer than the time to generate the tokens in
a chunk of spoken response, we use the remaining free time to generate the
unspoken reasoning tokens. When a chunk of audio is played to the user, the
model continues to generate the next unspoken reasoning chunk, achieving
simultaneous thinking and talking. Remarkably, Stitch matches the latency of
baselines that cannot generate unspoken CoT by design while outperforming those
baselines by 15% on math reasoning datasets; Stitch also performs equally well
on non-reasoning datasets as those baseline models. Some animations and
demonstrations are on the project page: https://d223302.github.io/STITCH.

</details>


### [203] [AlgoSimBench: Identifying Algorithmically Similar Problems for Competitive Programming](https://arxiv.org/abs/2507.15378)
*Jierui Li,Raymond Mooney*

Main category: cs.CL

TL;DR: 本文提出了AlgoSimBench基准，用以评估大语言模型（LLMs）在判别算法相似问题（ASPs）上的能力，发现当前LLMs识别效果欠佳，并提出了ASM方法显著提升识别准确率。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在复杂编程问题上表现优异，但其能力是否能泛化到训练中较少接触的相关算法领域仍不得而知，因此需要新的基准来衡量LLMs对算法相似性问题的判别能力。

Method: 作者构建了AlgoSimBench数据集，包含1317道含231种细粒度算法标签的问题，从中筛选出402道多项选择题，每题含1道算法相似问题和3道表面相似但算法不同的干扰项，并用此评估主流LLMs及代码嵌入模型。此外，提出了Attempted Solution Matching（ASM）方法，通过拟合问题的解题过程提升识别精度。

Result: 实验显示，现有LLMs在算法相似问题判别上的准确率不高（最优仅65.9%），ASM方法能够使不同模型的准确率提升6.7-11.7%。代码嵌入及召回模型在设计的对抗性问题下表现甚至低于随机。但简单的叙事元素剔除可恢复性能，将ASM与BM25结合可达52.2%准确率。

Conclusion: 当前LLMs在判别算法相似问题上仍有明显不足，ASM方法有效提升了这一能力，但总体而言模型与算法知识的泛化与理解能力尚需进一步进步。

Abstract: Recent progress in LLMs, such as reasoning models, has demonstrated strong
abilities to solve complex competitive programming problems, often rivaling top
human competitors. However, it remains underexplored whether these abilities
generalize to relevant domains that are less seen during training. To address
this, we introduce AlgoSimBench, a new benchmark designed to assess LLMs'
ability to identify algorithmically similar problems (ASPs)-problems that can
be solved using similar algorithmic approaches. AlgoSimBench consists of 1317
problems, annotated with 231 distinct fine-grained algorithm tags, from which
we curate 402 multiple-choice questions (MCQs), where each question presents
one algorithmically similar problem alongside three textually similar but
algorithmically dissimilar distractors. Our evaluation reveals that LLMs
struggle to identify ASPs, with the best-performing model (o3-mini) achieving
only 65.9% accuracy on the MCQ task. To address this challenge, we propose
attempted solution matching (ASM), a novel method for improving problem
similarity detection. On our MCQ task, ASM yields an absolute accuracy
improvement of 6.7% to 11.7% across different models. We also evaluated code
embedding models and retrieval methods on similar problem identification. While
the adversarial selection of problems degrades the performance to be less than
random, we found that simply summarizing the problem to remove narrative
elements eliminates the effect, and combining ASM with a keyword-prioritized
method, BM25, can yield up to 52.2% accuracy. Code and data are available at
github.com

</details>


### [204] [ASPERA: A Simulated Environment to Evaluate Planning for Complex Action Execution](https://arxiv.org/abs/2507.15501)
*Alexandru Coca,Mark Gaynor,Zhenxing Zhang,Jianpeng Cheng,Bo-Hsiang Tseng,Pete Boothroyd,Héctor Martinez Alonso,Diarmuid Ó Séaghdha,Anders Johannsen*

Main category: cs.CL

TL;DR: 本文提出并评估了利用大型语言模型(LLMs)实现复杂动作执行的数字助理能力，提出ASPERA框架，并构建了用于评估LLM的高复杂度任务数据集Asper-Bench。结果显示基于定制库的程序生成对LLM提出新挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在代码生成上表现出色，但在执行复杂、多步骤的助理任务时，如何利用预训练的编程知识，将自定义助理库中的对象和函数组合为可执行程序，仍面临数据稀缺与评估难题。

Method: 作者提出ASPERA框架，包括助理库仿真和人工辅助的LLM数据生成引擎。该引擎辅助开发者生成高质量、复杂的用户任务，涵盖用户查询、仿真状态和验证程序，以解决数据和评估难题。同时构建Asper-Bench数据集用于评测。

Result: 通过ASPERA生成的Asper-Bench数据集表明，依赖定制助理库生成程序，比不依赖外部库的代码生成任务更具挑战性，当前LLM在此任务上的表现有限。

Conclusion: 将LLM应用于自定义助理程序的生成，依然面临显著挑战，现有LLM能力尚不足以有效执行对脚本库有依赖的复杂助理任务，开发更强大模型和更优训练方法仍是未来重点。

Abstract: This work evaluates the potential of large language models (LLMs) to power
digital assistants capable of complex action execution. These assistants rely
on pre-trained programming knowledge to execute multi-step goals by composing
objects and functions defined in assistant libraries into action execution
programs. To achieve this, we develop ASPERA, a framework comprising an
assistant library simulation and a human-assisted LLM data generation engine.
Our engine allows developers to guide LLM generation of high-quality tasks
consisting of complex user queries, simulation state and corresponding
validation programs, tackling data availability and evaluation robustness
challenges. Alongside the framework we release Asper-Bench, an evaluation
dataset of 250 challenging tasks generated using ASPERA, which we use to show
that program generation grounded in custom assistant libraries is a significant
challenge to LLMs compared to dependency-free code generation.

</details>


### [205] [Step-level Verifier-guided Hybrid Test-Time Scaling for Large Language Models](https://arxiv.org/abs/2507.15512)
*Kaiyan Chang,Yonghao Shi,Chenglong Wang,Hang Zhou,Chi Hu,Xiaoqian Liu,Yingfeng Luo,Yuan Ge,Tong Xiao,Jingbo Zhu*

Main category: cs.CL

TL;DR: 该论文关注无需训练的推理推理测试时动态扩展（Test-Time Scaling, TTS）方法，提出条件步骤级自我优化及其与经典并行方法的混合推理范式，并在多种主流大模型上实验证明有效性。


<details>
  <summary>Details</summary>
Motivation: 当前主流的测试时动态扩展方法多依赖额外训练（如持续强化学习），导致推理时计算资源消耗大。无需训练的TTS方法逐渐被忽视，但其能有效减少运算负担，值得进一步研究和优化。

Method: 1）提出条件步骤级自我优化方法，通过过程校验实现细粒度逐步推理调优；2）进一步在步骤级与经典并行扩展方法结合，探索混合推理方案，从而实现无训练条件下TTS的组合范式。

Result: 在五个主流指令微调大模型（参数规模从3B到14B，类型多样）上系统测试，实验结果显示，该细粒度混合TTS策略可显著提升LLMs推理能力，证明无训练TTS方法仍具极大潜力。

Conclusion: 无需训练的TTS方法，尤其是混合细粒度推理策略，在提升大模型推理性能及降低推理负担方面显示出广阔前景。未来可进一步拓展并部署于实际智能推理任务场景。

Abstract: Test-Time Scaling (TTS) is a promising approach to progressively elicit the
model's intelligence during inference. Recently, training-based TTS methods,
such as continued reinforcement learning (RL), have further surged in
popularity, while training-free TTS methods are gradually fading from
prominence. However, the additional computation overhead of training amplifies
the burden on test-time scaling. In this paper, we focus on training-free TTS
methods for reasoning. We first design Conditional Step-level Self-refinement,
a fine-grained sequential scaling method guided by process verification. On top
of its effectiveness, we further combine it with other classical parallel
scaling methods at the step level, to introduce a novel inference paradigm
called Hybrid Test-Time Scaling. Extensive experiments on five
instruction-tuned LLMs across different scales (3B-14B) and families
demonstrate that hybrid strategy incorporating various training-free TTS
methods at a fine granularity has considerable potential for expanding the
reasoning performance boundaries of LLMs.

</details>


### [206] [Evaluating Text Style Transfer: A Nine-Language Benchmark for Text Detoxification](https://arxiv.org/abs/2507.15557)
*Vitaly Protasov,Nikolay Babakov,Daryna Dementieva,Alexander Panchenko*

Main category: cs.CL

TL;DR: 本文首次针对跨九种语言的文本净化系统评估，比较了神经网络和LLM评测方法，提出更可靠的多语言文本风格转换评估方案。


<details>
  <summary>Details</summary>
Motivation: 现有文本风格转换评估方法主要局限于英语，且自动评价与人工评价存在显著差距，多语言场景下的评估尚未被充分研究。

Method: 作者选取九种语言（包括英语、西班牙语、德语、中文、阿拉伯语、印地语、乌克兰语、俄语和阿姆哈拉语），借鉴机器翻译领域的评价方式，分别使用神经网络模型和基于提示词的LLM评测方法，对文本净化系统进行全面评估。

Result: 实验证明，现代神经网络模型与LLM-as-a-judge方法在多语言文本风格转换评估中具有有效性，并揭示各方法优劣。研究总结出适用于多语言文本净化评估的实用流程。

Conclusion: 本研究为多语言文本风格转换，尤其是文本净化任务的自动化评估，提供了更可靠评测框架和实用建议，有助于提高相关系统的评测一致性和跨语言能力。

Abstract: Despite recent progress in large language models (LLMs), evaluation of text
generation tasks such as text style transfer (TST) remains a significant
challenge. Recent studies (Dementieva et al., 2024; Pauli et al., 2025)
revealed a substantial gap between automatic metrics and human judgments.
Moreover, most prior work focuses exclusively on English, leaving multilingual
TST evaluation largely unexplored. In this paper, we perform the first
comprehensive multilingual study on evaluation of text detoxification system
across nine languages: English, Spanish, German, Chinese, Arabic, Hindi,
Ukrainian, Russian, Amharic. Drawing inspiration from the machine translation,
we assess the effectiveness of modern neural-based evaluation models alongside
prompting-based LLM-as-a-judge approaches. Our findings provide a practical
recipe for designing more reliable multilingual TST evaluation pipeline in the
text detoxification case.

</details>


### [207] [Smart Eyes for Silent Threats: VLMs and In-Context Learning for THz Imaging](https://arxiv.org/abs/2507.15576)
*Nicolas Poggi,Shashank Agnihotri,Margret Keuper*

Main category: cs.CL

TL;DR: 本文尝试将视觉-语言模型（VLM）与上下文学习（ICL）方法结合，首次应用于太赫兹（THz）成像分类，以提升有限数据下的分类与可解释性，无需微调模型。


<details>
  <summary>Details</summary>
Motivation: 太赫兹成像常用于安全检查和材料分类，但因标注样本有限、分辨率低、图像模糊，分类任务难度较高。

Method: 采用一种模态对齐的提示方法，将两种开源VLM通过ICL方式迁移至THz领域，并在零样本和单样本（zero-/one-shot）条件下进行分类实验。

Result: 结果表明，ICL方法在低数据场景下，能提升THz图像的分类精度和模型解释性。

Conclusion: 将ICL与VLM应用在THz成像领域为小样本科学任务提供了新思路，具备良好灵活性和可扩展性，无需额外训练。

Abstract: Terahertz (THz) imaging enables non-invasive analysis for applications such
as security screening and material classification, but effective image
classification remains challenging due to limited annotations, low resolution,
and visual ambiguity. We introduce In-Context Learning (ICL) with
Vision-Language Models (VLMs) as a flexible, interpretable alternative that
requires no fine-tuning. Using a modality-aligned prompting framework, we adapt
two open-weight VLMs to the THz domain and evaluate them under zero-shot and
one-shot settings. Our results show that ICL improves classification and
interpretability in low-data regimes. This is the first application of
ICL-enhanced VLMs to THz imaging, offering a promising direction for
resource-constrained scientific domains. Code:
\href{https://github.com/Nicolas-Poggi/Project_THz_Classification/tree/main}{GitHub
repository}.

</details>


### [208] [Learning to Extract Rational Evidence via Reinforcement Learning for Retrieval-Augmented Generation](https://arxiv.org/abs/2507.15586)
*Xinping Zhao,Shouzheng Huang,Yan Zhong,Xinshuo Hu,Baotian Hu,Min Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种新的RAG去噪机制LEAR，通过显式推理和有意识抽取提升检索信息的质量，从而提升大模型生成的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前RAG方法受检索噪声影响大，证据提取易遗漏关键信息，泛化能力较弱，因此需要更高效的去噪和证据提取机制。

Method: 提出LEAR方法，包括：（1）先推理识别检索内容中的有效线索，再有意识地抽取关键线索；（2）推理与抽取统一建模，端到端训练；（3）使用知识掩码实现推理与抽取解耦；（4）设计三种可验证奖励（答案、长度、格式），结合策略优化算法进行模型更新。

Result: 在三个基准数据集上进行了大量实验，LEAR能提供简洁高质量的证据，显著提升下游任务准确率。

Conclusion: LEAR方法有效提升RAG系统中证据提取的质量和生成准确性，具备较强实用价值。

Abstract: Retrieval-Augmented Generation (RAG) effectively improves the accuracy of
Large Language Models (LLMs). However, retrieval noises significantly impact
the quality of LLMs' generation, necessitating the development of denoising
mechanisms. Previous methods extract evidence straightforwardly without
explicit thinking, which risks filtering out key clues and struggles with
generalization. To this end, we propose LEAR, which learns to extract rational
evidence by (1) explicitly reasoning to identify potential cues within
retrieval contents first, and then (2) consciously extracting to avoid omitting
any key cues helpful for answering questions. Specifically, we frame evidence
reasoning and evidence extraction into one unified response for end-to-end
training; apply knowledge token masks for disentanglement to derive
reasoning-based and extraction-based answers; and devise three types of
verifiable reward functions, including answer, length, and format, to update
the model via the policy optimization algorithm. Extensive experiments on three
benchmark datasets show the effectiveness of LEAR, providing compact and
high-quality evidence, improving the accuracy of downstream tasks, and
promoting effective application in online RAG systems.

</details>


### [209] [Conflicting narratives and polarization on social media](https://arxiv.org/abs/2507.15600)
*Armin Pournaki*

Main category: cs.CL

TL;DR: 本文通过分析德国推特圈中2021至2023年间的热点议题，研究冲突叙事如何揭示公共领域内极化和议题对齐的机制。作者重点分析乌克兰战争、新冠疫情、气候变化等事件中不同意见团体推文的叙事分歧，为理解政治极化的言语机制提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 叙事是人们理解政治现实的重要方式。当前政治极化和议题对齐现象日益突出，研究冲突叙事有助于揭示其背后的话语机制，进而理解极化如何在社会舆论中蔓延。

Method: 作者选定德国推特圈中的几个极化议题（如乌克兰战争、新冠和气候变化），提取对立意见群体在推文中的文本信号，对叙事分歧进行分析，重点关注角色分配与事件叙述差异，并探究不同叙事在多个议题间的对齐模式。

Result: 发现对立群体在相同事件中对角色的归因和事件主角选择上存在冲突性叙事（如对乌克兰战争中北约的不同解读、右倾新冠叙事中的比尔·盖茨等）。另外，初步发现了政治行为体通过叙事对齐来串联不同议题的现象。

Conclusion: 对冲突叙事的分析有助于理解极化和议题对齐的言语机制。叙事分析可作为揭示政治舆论极化的有效工具。

Abstract: Narratives are key interpretative devices by which humans make sense of
political reality. In this work, we show how the analysis of conflicting
narratives, i.e. conflicting interpretive lenses through which political
reality is experienced and told, provides insight into the discursive
mechanisms of polarization and issue alignment in the public sphere. Building
upon previous work that has identified ideologically polarized issues in the
German Twittersphere between 2021 and 2023, we analyze the discursive dimension
of polarization by extracting textual signals of conflicting narratives from
tweets of opposing opinion groups. Focusing on a selection of salient issues
and events (the war in Ukraine, Covid, climate change), we show evidence for
conflicting narratives along two dimensions: (i) different attributions of
actantial roles to the same set of actants (e.g. diverging interpretations of
the role of NATO in the war in Ukraine), and (ii) emplotment of different
actants for the same event (e.g. Bill Gates in the right-leaning Covid
narrative). Furthermore, we provide first evidence for patterns of narrative
alignment, a discursive strategy that political actors employ to align opinions
across issues. These findings demonstrate the use of narratives as an
analytical lens into the discursive mechanisms of polarization.

</details>


### [210] [Leveraging Context for Multimodal Fallacy Classification in Political Debates](https://arxiv.org/abs/2507.15641)
*Alessio Pittiglio*

Main category: cs.CL

TL;DR: 这篇论文介绍了作者团队在MM-ArgFallacy2025多模态论证挖掘任务中的工作，聚焦于政治辩论中的逻辑谬误检测。他们使用了预训练的Transformer模型，并尝试多种方式利用上下文，最终在文本、音频和多模态任务上取得了较好成绩。


<details>
  <summary>Details</summary>
Motivation: 推动多模态论证挖掘领域的发展，尤其是在政治辩论中检测逻辑谬误。

Method: 采用预训练的Transformer模型，并探索了多种结合上下文的策略，分别对文本、音频及多模态数据进行逻辑谬误分类。

Result: 在谬误分类子任务中，文本模型的macro F1为0.4444，音频为0.3559，多模态为0.4403。多模态模型的表现与文本模型相当。

Conclusion: 多模态模型目前与文本模型表现相近，但仍有进一步提升的潜力。

Abstract: In this paper, we present our submission to the MM-ArgFallacy2025 shared
task, which aims to advance research in multimodal argument mining, focusing on
logical fallacies in political debates. Our approach uses pretrained
Transformer-based models and proposes several ways to leverage context. In the
fallacy classification subtask, our models achieved macro F1-scores of 0.4444
(text), 0.3559 (audio), and 0.4403 (multimodal). Our multimodal model showed
performance comparable to the text-only model, suggesting potential for
improvements.

</details>


### [211] [P3: Prompts Promote Prompting](https://arxiv.org/abs/2507.15675)
*Xinyu Zhang,Yuanquan Hu,Fangchao Liu,Zhicheng Dou*

Main category: cs.CL

TL;DR: 本文提出了一种名为P3的自我提升框架，能够同时、迭代地优化大型语言模型（LLM）中的系统和用户提示，从而在多种任务中显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM应用常采用包含系统和用户提示的多组件提示结构，单独优化其中一方带来的提升有限，因为两者存在相互依赖关系。因此迫切需要一种能协同优化两者的方案，以充分释放模型潜力。

Method: P3框架通过迭代的方式同时优化系统和用户提示，并结合离线优化结果，将其应用于在线场景中的依赖查询优化，从而实现端到端的提示自我提升。

Result: 在通用任务和推理任务（如Arena-hard、Alpaca-eval、GSM8K、GPQA）上的大量实验表明，P3方法在自动化提示优化方面优于现有方法，取得了更高的性能效果。

Conclusion: 该研究证明了整体协同优化体系和用户提示的重要性，为提升LLM在各类任务上的表现提供了有效方案。

Abstract: Current large language model (LLM) applications often employ multi-component
prompts, comprising both system and user prompts, to guide model behaviors.
While recent advancements have demonstrated the efficacy of automatically
optimizing either the system or user prompt to boost performance, such
unilateral approaches often yield suboptimal outcomes due to the interdependent
nature of these components. In this work, we introduce P3, a novel
self-improvement framework that concurrently optimizes both system and user
prompts through an iterative process. The offline optimized prompts are further
leveraged to promote online prompting by performing query-dependent prompt
optimization. Extensive experiments on general tasks (e.g., Arena-hard and
Alpaca-eval) and reasoning tasks (e.g., GSM8K and GPQA) demonstrate that P3
achieves superior performance in the realm of automatic prompt optimization.
Our results highlight the effectiveness of a holistic optimization strategy in
enhancing LLM performance across diverse domains.

</details>


### [212] [CoLD: Counterfactually-Guided Length Debiasing for Process Reward Models](https://arxiv.org/abs/2507.15698)
*Congmin Zheng,Jiachen Zhu,Jianghao Lin,Xinyi Dai,Yong Yu,Weinan Zhang,Mengyue Yang*

Main category: cs.CL

TL;DR: 该论文提出CoLD框架，用于消除过程奖励模型(Process Reward Models, PRMs)在多步推理中的长度偏置，从而提升数学问题求解中LLMs的性能。


<details>
  <summary>Details</summary>
Motivation: 现有过程奖励模型在多步推理过程中，对更长的推理步骤赋予更高评分，即使内容和逻辑未变，导致模型推理啰嗦且奖惩机制不可靠，需要解决这一长度偏置问题。

Method: 作者提出CoLD框架，包括三个部分：1) 显式长度惩罚调整；2) 学习到的偏置估计器，用于建模长度相关的虚假信号；3) 联合训练策略，强制奖励预测对长度保持不变。该方法基于反事实推理和因果图分析设计。

Result: 在MATH500和GSM-Plus数据集上，CoLD显著降低了奖励与长度的相关性，提高了步骤选择的准确性，同时生成的推理更为简明且逻辑有效。

Conclusion: CoLD能高效实用地消除PRMs中的长度偏置，提高奖励预测的准确性和鲁棒性，有助于提升LLMs在多步推理任务中的表现。

Abstract: Process Reward Models (PRMs) play a central role in evaluating and guiding
multi-step reasoning in large language models (LLMs), especially for
mathematical problem solving. However, we identify a pervasive length bias in
existing PRMs: they tend to assign higher scores to longer reasoning steps,
even when the semantic content and logical validity are unchanged. This bias
undermines the reliability of reward predictions and leads to overly verbose
outputs during inference. To address this issue, we propose
CoLD(Counterfactually-Guided Length Debiasing), a unified framework that
mitigates length bias through three components: an explicit length-penalty
adjustment, a learned bias estimator trained to capture spurious length-related
signals, and a joint training strategy that enforces length-invariance in
reward predictions. Our approach is grounded in counterfactual reasoning and
informed by causal graph analysis. Extensive experiments on MATH500 and
GSM-Plus show that CoLD consistently reduces reward-length correlation,
improves accuracy in step selection, and encourages more concise, logically
valid reasoning. These results demonstrate the effectiveness and practicality
of CoLD in improving the fidelity and robustness of PRMs.

</details>


### [213] [Compositional Understanding in Signaling Games](https://arxiv.org/abs/2507.15706)
*David Peter Wallis Freeborn*

Main category: cs.CL

TL;DR: 传统信号博弈模型中的接收者难以学会组合性信息，即使信号者发送了组合性信息，接收者也无法组合式地理解。本文提出两种新模型，让接收者能针对消息的基本成分进行学习，从而实现真正的组合性理解。


<details>
  <summary>Details</summary>
Motivation: 受限于经典模型，接收者不能有效组合与保持消息中各部分的信息，限制了组合性语言的进化与学习。作者希望改进模型，使接收者能独立学习并保留消息各部分的信息，提高理解的组合性。

Method: 作者提出两种新型接收者模型：一是极简型接收者（minimalist receiver），只从消息的原子成分中学习；二是通才型接收者（generalist receiver），能从所有获得的信息中学习。这些模型比以往更简洁，能让接收者利用消息的原子部分推断含义。

Result: 两种新模型均展现出接收者能够演化出真正的组合性理解，即他们能独立地对每个消息成分进行学习和解释，不再像经典模型中那样一次性丧失全部信息。

Conclusion: 较简单的接收者学习机制也能实现组合性语言理解，挑战了以往模型中关于组合性学习的难题，并为语言组合性的演化研究提供了新思路。

Abstract: Receivers in standard signaling game models struggle with learning
compositional information. Even when the signalers send compositional messages,
the receivers do not interpret them compositionally. When information from one
message component is lost or forgotten, the information from other components
is also erased. In this paper I construct signaling game models in which
genuine compositional understanding evolves. I present two new models: a
minimalist receiver who only learns from the atomic messages of a signal, and a
generalist receiver who learns from all of the available information. These
models are in many ways simpler than previous alternatives, and allow the
receivers to learn from the atomic components of messages.

</details>


### [214] [Is Large Language Model Performance on Reasoning Tasks Impacted by Different Ways Questions Are Asked?](https://arxiv.org/abs/2507.15707)
*Seok Hwan Song,Mohna Chakraborty,Qi Li,Wallapak Tavanapong*

Main category: cs.CL

TL;DR: 本研究探讨了不同题型对大型语言模型（LLM）在推理任务准确率的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM已在多种题型下进行评估，但尚未有研究系统性分析题型本身如何影响LLM的推理表现，因此该研究旨在填补这一空白。

Method: 选取五种LLM，在定量与演绎推理任务中，针对三种不同题型（如选择题、判断题与简答/长答题）进行性能对比，评估其推理步骤和最终答案的准确率。

Result: 1）不同题型下LLM表现存在显著差异；2）推理由准确率不必然与最终答案选择准确率相关；3）选项数量与措辞会影响LLM表现。

Conclusion: 在评估或设计涉及LLM推理能力的任务时，题型的选择、选项设置及语句表述都需要被纳入考量，否则容易导致评估结果的偏误。

Abstract: Large Language Models (LLMs) have been evaluated using diverse question
types, e.g., multiple-choice, true/false, and short/long answers. This study
answers an unexplored question about the impact of different question types on
LLM accuracy on reasoning tasks. We investigate the performance of five LLMs on
three different types of questions using quantitative and deductive reasoning
tasks. The performance metrics include accuracy in the reasoning steps and
choosing the final answer. Key Findings: (1) Significant differences exist in
LLM performance across different question types. (2) Reasoning accuracy does
not necessarily correlate with the final selection accuracy. (3) The number of
options and the choice of words, influence LLM performance.

</details>


### [215] [Chinchunmei at SemEval-2025 Task 11: Boosting the Large Language Model's Capability of Emotion Perception using Contrastive Learning](https://arxiv.org/abs/2507.15714)
*Tian Li,Yujian Sun,Huizhi Liang*

Main category: cs.CL

TL;DR: 本文参加了SemEval-2025第11题，在28种语言的文本情感检测任务上，系统性地探索了两种对比学习方法，以提升情感识别模型的表现，并在比赛中取得了优秀成绩。


<details>
  <summary>Details</summary>
Motivation: 文本情感识别任务由于情绪表达形式和不同语言背景的多样性而存在较大难度，因此需要更先进的方法来提升模型的可靠性与泛化能力。该比赛设立了多标签分类和情感强度预测两大任务，旨在推动该领域研究进步。

Method: 作者系统性探索了两种对比学习策略：一种是基于样本的对比学习（Contrastive Reasoning Calibration），通过对比两个样本改进预测可靠性；另一种是基于生成的对比学习（如DPO、SimPO），通过区分正确与错误的生成结果提升预测能力。所有模型均在LLaMa3-Instruct-8B基础上微调。

Result: 所提出系统在英文Track A（多标签分类）获得第9名，在Track B（情感强度预测）获得第6名，并在其他语种赛道上取得了前列成绩。

Conclusion: 多种对比学习策略能够显著提升多语言文本情感识别模型的效果。模型在不同任务与语种中都表现优异，证明了方法的有效性和鲁棒性。

Abstract: The SemEval-2025 Task 11, Bridging the Gap in Text-Based Emotion Detection,
introduces an emotion recognition challenge spanning over 28 languages. This
competition encourages researchers to explore more advanced approaches to
address the challenges posed by the diversity of emotional expressions and
background variations. It features two tracks: multi-label classification
(Track A) and emotion intensity prediction (Track B), covering six emotion
categories: anger, fear, joy, sadness, surprise, and disgust. In our work, we
systematically explore the benefits of two contrastive learning approaches:
sample-based (Contrastive Reasoning Calibration) and generation-based (DPO,
SimPO) contrastive learning. The sample-based contrastive approach trains the
model by comparing two samples to generate more reliable predictions. The
generation-based contrastive approach trains the model to differentiate between
correct and incorrect generations, refining its prediction. All models are
fine-tuned from LLaMa3-Instruct-8B. Our system achieves 9th place in Track A
and 6th place in Track B for English, while ranking among the top-tier
performing systems for other languages.

</details>


### [216] [From Queries to Criteria: Understanding How Astronomers Evaluate LLMs](https://arxiv.org/abs/2507.15715)
*Alina Hyk,Kiera McCormick,Mian Zhong,Ioana Ciucă,Sanjib Sharma,John F Wu,J. E. G. Peek,Kartheik G. Iyer,Ziang Xiao,Anjalie Field*

Main category: cs.CL

TL;DR: 本研究探讨了用户如何评价应用于天文学文献的LLM（大语言模型）系统，并据此提出优化LLM评估基准的方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估基准与实际用户需求和使用方式存在脱节，特别是在天文学等科学领域。作者希望通过更好理解用户的真实评价方式来改进LLM评价框架。

Method: 研究团队在Slack平台部署了一个基于检索增强生成（RAG）的LLM机器人，让天文学家查询天文文献数据，同时收集四周内的368条真实查询，并对11位天文学家进行了访谈，通过归纳编码分析用户提出的问题类型和评价标准。

Result: 研究总结了天文学家使用LLM的需求、提出问题的方式以及他们评价模型答案的具体标准，并据此提出了优化LLM评估基准的建议，并构建了一个天文学相关的LLM评测示例基准。

Conclusion: 作者为LLM在科学研究场景下的评价与实际可用性提升提出了新思路，有助于打造更具针对性的模型评估体系。

Abstract: There is growing interest in leveraging LLMs to aid in astronomy and other
scientific research, but benchmarks for LLM evaluation in general have not kept
pace with the increasingly diverse ways that real people evaluate and use these
models. In this study, we seek to improve evaluation procedures by building an
understanding of how users evaluate LLMs. We focus on a particular use case: an
LLM-powered retrieval-augmented generation bot for engaging with astronomical
literature, which we deployed via Slack. Our inductive coding of 368 queries to
the bot over four weeks and our follow-up interviews with 11 astronomers reveal
how humans evaluated this system, including the types of questions asked and
the criteria for judging responses. We synthesize our findings into concrete
recommendations for building better benchmarks, which we then employ in
constructing a sample benchmark for evaluating LLMs for astronomy. Overall, our
work offers ways to improve LLM evaluation and ultimately usability,
particularly for use in scientific research.

</details>


### [217] [BEnchmarking LLMs for Ophthalmology (BELO) for Ophthalmological Knowledge and Reasoning](https://arxiv.org/abs/2507.15717)
*Sahana Srinivasan,Xuguang Ai,Thaddaeus Wai Soon Lo,Aidan Gilson,Minjie Zou,Ke Zou,Hyunjae Kim,Mingjia Yang,Krithi Pushpanathan,Samantha Yew,Wan Ting Loke,Jocelyn Goh,Yibing Chen,Yiming Kong,Emily Yuelei Fu,Michelle Ongyong Hui,Kristen Nwanyanwu,Amisha Dave,Kelvin Zhenghao Li,Chen-Hsin Sun,Mark Chia,Gabriel Dawei Yang,Wendy Meihua Wong,David Ziyou Chen,Dianbo Liu,Maxwell Singer,Fares Antaki,Lucian V Del Priore,Jost Jonas,Ron Adelman,Qingyu Chen,Yih-Chung Tham*

Main category: cs.CL

TL;DR: 本文提出了BELO，这是一个专为眼科学领域大语言模型（LLM）评估设计的标准化、全面性基准，涵盖900道高质量、多来源、专家审核的选择题，旨在弥补现有基准覆盖面窄且过度强调准确性的不足。


<details>
  <summary>Details</summary>
Motivation: 当前用于评估大语言模型在眼科学领域表现的基准存在覆盖范围有限且过分侧重准确性的问题，缺乏对模型临床推理能力和其他综合素质的系统性检测。因此，有必要开发一个更全面、标准化、专家参与审核的新基准。

Method: 研究团队通过关键词匹配和微调的PubMedBERT模型，从多个医学数据集中（BCSC、MedMCQA、MedQA、BioASQ、PubMedQA）筛选眼科学相关选择题，结合13名眼科医生多轮专业审核，剔除重复与低质量题目，并由10名医生精炼答案解析，最终由3位资深眼科专家终审。评测采用多种自动化指标（准确率、宏F1、ROUGE-L、BERTScore、BARTScore、METEOR、AlignScore）和专家定性评价。

Result: 最终形成了由900道专家审核题目组成，来源于五个公开数据集的高质量测试集，并建立了公开排行榜。通过BELO评测OpenAI、DeepSeek、Llama等六款主流大模型，在准确率及文本生成能力等方面进行了系统比较，也加入了专家人工定性评审。

Conclusion: BELO作为一个新型、专家审核且只用于评测的眼科学领域基准，可以为大语言模型在医学领域能力的客观、可重复、公正评价提供工具，推动技术公平透明发展。

Abstract: Current benchmarks evaluating large language models (LLMs) in ophthalmology
are limited in scope and disproportionately prioritise accuracy. We introduce
BELO (BEnchmarking LLMs for Ophthalmology), a standardized and comprehensive
evaluation benchmark developed through multiple rounds of expert checking by 13
ophthalmologists. BELO assesses ophthalmology-related clinical accuracy and
reasoning quality. Using keyword matching and a fine-tuned PubMedBERT model, we
curated ophthalmology-specific multiple-choice-questions (MCQs) from diverse
medical datasets (BCSC, MedMCQA, MedQA, BioASQ, and PubMedQA). The dataset
underwent multiple rounds of expert checking. Duplicate and substandard
questions were systematically removed. Ten ophthalmologists refined the
explanations of each MCQ's correct answer. This was further adjudicated by
three senior ophthalmologists. To illustrate BELO's utility, we evaluated six
LLMs (OpenAI o1, o3-mini, GPT-4o, DeepSeek-R1, Llama-3-8B, and Gemini 1.5 Pro)
using accuracy, macro-F1, and five text-generation metrics (ROUGE-L, BERTScore,
BARTScore, METEOR, and AlignScore). In a further evaluation involving human
experts, two ophthalmologists qualitatively reviewed 50 randomly selected
outputs for accuracy, comprehensiveness, and completeness. BELO consists of 900
high-quality, expert-reviewed questions aggregated from five sources: BCSC
(260), BioASQ (10), MedMCQA (572), MedQA (40), and PubMedQA (18). A public
leaderboard has been established to promote transparent evaluation and
reporting. Importantly, the BELO dataset will remain a hold-out,
evaluation-only benchmark to ensure fair and reproducible comparisons of future
models.

</details>


### [218] [Understanding Large Language Models' Ability on Interdisciplinary Research](https://arxiv.org/abs/2507.15736)
*Yuanhao Shen,Daniel Xavier de Sousa,Ricardo Marçal,Ali Asad,Hongyu Guo,Xiaodan Zhu*

Main category: cs.CL

TL;DR: 本文提出了IDRBench，一项专门评估大语言模型（LLM）在跨学科研究（IDR）中提出有价值科研想法能力的基准，并通过专家标注和多项任务发现，现有LLM在该领域仍有较大提升空间。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在多步骤逻辑推理和科学发现方面表现突出，但缺乏评估其在跨学科研究中创新能力的专用基准，限制了对其优劣势的全面理解。

Method: 作者构建了IDRBench基准：从ArXiv收集六大学科的科学文献，由多学科专家精确标注，强调真实跨学科维度，并设计涵盖识别、整合、推荐三个阶段的任务，对10个主流LLM设立基线实验。

Result: 实验发现，尽管LLM初步展现了跨学科意识，但在创新高质量跨学科研究想法方面仍显不足。

Conclusion: IDRBench为系统评估LLM跨学科科研能力提供了新工具，结果将推动相关研究和下一代LLM更好地服务于跨学科科学发现。

Abstract: Recent advancements in Large Language Models (LLMs) have revealed their
impressive ability to perform multi-step, logic-driven reasoning across complex
domains, positioning them as powerful tools and collaborators in scientific
discovery while challenging the long-held view that inspiration-driven ideation
is uniquely human. However, the lack of a dedicated benchmark that evaluates
LLMs' ability to develop ideas in Interdisciplinary Research (IDR) settings
poses a critical barrier to fully understanding their strengths and
limitations. To address this gap, we introduce IDRBench -- a pioneering
benchmark featuring an expert annotated dataset and a suite of tasks tailored
to evaluate LLMs' capabilities in proposing valuable research ideas from
different scientific domains for interdisciplinary research. This benchmark
aims to provide a systematic framework for assessing LLM performance in
complex, cross-domain scientific research. Our dataset consists of scientific
publications sourced from the ArXiv platform covering six distinct disciplines,
and is annotated by domain experts with diverse academic backgrounds. To ensure
high-quality annotations, we emphasize clearly defined dimensions that
characterize authentic interdisciplinary research. The design of evaluation
tasks in IDRBench follows a progressive, real-world perspective, reflecting the
natural stages of interdisciplinary research development, including 1) IDR
Paper Identification, 2) IDR Idea Integration, and 3) IDR Idea Recommendation.
Using IDRBench, we construct baselines across 10 LLMs and observe that despite
fostering some level of IDR awareness, LLMs still struggle to produce quality
IDR ideas. These findings could not only spark new research directions, but
also help to develop next-generation LLMs that excel in interdisciplinary
research.

</details>


### [219] [A Fisher's exact test justification of the TF-IDF term-weighting scheme](https://arxiv.org/abs/2507.15742)
*Paul Sheridan,Zeyad Ahmed,Aitazaz A. Farooque*

Main category: cs.CL

TL;DR: 本文将TF-IDF与统计显著性检验联系起来，证明了其有效性，并为TF-IDF提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 虽然TF-IDF广泛应用于文本分析，但其理论基础尚不完备。本文旨在从统计学角度，为TF-IDF这种常用词权重方案提供数学和理论依据，使其被统计学界更好地理解与采纳。

Method: 作者将TF-IDF（特别是TF-ICF变体）视为统计显著性检验的一种表达，通过推导和理论分析，证明在一定条件下，TF-ICF与Fisher精确检验负对数p值密切相关，并且在文档集趋于无穷大的极限下与TF-IDF等价。

Result: 结果表明，TF-ICF可近似视为一尾Fisher精确检验负对数p值，并在理想条件下两者具备严格数学联系。这为TF-IDF的有效性提供了统计学解释。

Conclusion: 本文为TF-IDF提供了新的统计学解释与理论基础，有助于其在统计学界的推广和合理应用，并解释了其长期以来实际有效的原因。

Abstract: Term frequency-inverse document frequency, or TF-IDF for short, is arguably
the most celebrated mathematical expression in the history of information
retrieval. Conceived as a simple heuristic quantifying the extent to which a
given term's occurrences are concentrated in any one given document out of
many, TF-IDF and its many variants are routinely used as term-weighting schemes
in diverse text analysis applications. There is a growing body of scholarship
dedicated to placing TF-IDF on a sound theoretical foundation. Building on that
tradition, this paper justifies the use of TF-IDF to the statistics community
by demonstrating how the famed expression can be understood from a significance
testing perspective. We show that the common TF-IDF variant TF-ICF is, under
mild regularity conditions, closely related to the negative logarithm of the
$p$-value from a one-tailed version of Fisher's exact test of statistical
significance. As a corollary, we establish a connection between TF-IDF and the
said negative log-transformed $p$-value under certain idealized assumptions. We
further demonstrate, as a limiting case, that this same quantity converges to
TF-IDF in the limit of an infinitely large document collection. The Fisher's
exact test justification of TF-IDF equips the working statistician with a ready
explanation of the term-weighting scheme's long-established effectiveness.

</details>


### [220] [DialogueForge: LLM Simulation of Human-Chatbot Dialogue](https://arxiv.org/abs/2507.15752)
*Ruizhe Zhu,Hao Zhu,Yaxuan Li,Syang Zhou,Shijing Cai,Malgorzata Lazuka,Elliott Ash*

Main category: cs.CL

TL;DR: 本文提出了DialogueForge框架，通过从真实人类与聊天机器人对话中提取种子提示，利用大语言模型（LLM）生成多轮AI模拟人机对话，以提升对话数据收集的效率。


<details>
  <summary>Details</summary>
Motivation: 人工收集人机对话数据成本高、效率低，阻碍了对话式AI领域的发展。因此亟需高效、自动的数据生成方法。

Method: 提出DialogueForge框架，首先从真实人机对话中提取seed prompt，随后用不同规模的大语言模型（包括主流专有模型和开源模型）模拟人类用户，生成多轮特定任务对话，并探索微调技术提升小模型的对话生成能力。

Result: 实验证明大型专有模型（如GPT-4o）在生成逼真对话上表现最佳，小型开源模型（如Llama、Mistral）虽然表现略逊一筹但具备更高定制化潜力，经监督微调后表现显著提升。

Conclusion: DialogueForge能够显著提升人工对话数据采集效率，但所有模型在生成连贯自然的长对话方面仍面临挑战。

Abstract: Collecting human-chatbot dialogues typically demands substantial manual
effort and is time-consuming, which limits and poses challenges for research on
conversational AI. In this work, we propose DialogueForge - a framework for
generating AI-simulated conversations in human-chatbot style. To initialize
each generated conversation, DialogueForge uses seed prompts extracted from
real human-chatbot interactions. We test a variety of LLMs to simulate the
human chatbot user, ranging from state-of-the-art proprietary models to
small-scale open-source LLMs, and generate multi-turn dialogues tailored to
specific tasks. In addition, we explore fine-tuning techniques to enhance the
ability of smaller models to produce indistinguishable human-like dialogues. We
evaluate the quality of the simulated conversations and compare different
models using the UniEval and GTEval evaluation protocols. Our experiments show
that large proprietary models (e.g., GPT-4o) generally outperform others in
generating more realistic dialogues, while smaller open-source models (e.g.,
Llama, Mistral) offer promising performance with greater customization. We
demonstrate that the performance of smaller models can be significantly
improved by employing supervised fine-tuning techniques. Nevertheless,
maintaining coherent and natural long-form human-like dialogues remains a
common challenge across all models.

</details>


### [221] [Interaction as Intelligence: Deep Research With Human-AI Partnership](https://arxiv.org/abs/2507.15759)
*Lyumanshan Ye,Xiaojie Cai,Xinkai Wang,Junfei Wang,Xiangkun Hu,Jiadi Su,Yang Nan,Sihan Wang,Bohan Zhang,Xiaoze Fan,Jinbin Luo,Yuxiang Zheng,Tianze Xu,Dayuan Fu,Yunze Wu,Pengrui Lu,Zengzhi Wang,Yiwei Qin,Zhen Huang,Yan Ma,Zhulin Hu,Haoyang Zou,Tiantian Mi,Yixin Ye,Ethan Chern,Pengfei Liu*

Main category: cs.CL

TL;DR: 本文提出通过将人机交互本身视为智能的基本维度，重新定义了在深度科研任务中人与AI的关系，并引入Deep Cognition系统，实现更有效的认知监督，显著提升深度研究类AI系统的整体表现。


<details>
  <summary>Details</summary>
Motivation: 目前的深度研究AI系统采用"输入-等待-输出"模式，导致无法动态修正、难以融合人类专长及容易产生错误传递，限制了AI系统在复杂科研任务中的表现。作者认为仅将交互作为获取AI能力的接口过于狭隘，并希望解决现有模型在灵活性、透明度和协作方面的诸多不足。

Method: 论文提出了Deep Cognition系统，将用户角色从简单指令提供者转变为认知监督者，在AI思考过程中通过关键节点干预，具体实现为三大创新：1. 透明、可控、可中断的交互，使AI推理过程可见且可随时干预；2. 细粒度双向对话；3. 共享认知上下文，AI能自动感知并适应用户行为。

Result: 用户评估结果显示，该系统在透明度、细粒度交互、实时干预、协作易用性、成果性价比与可中断性六个核心指标上均显著优于现有最强基线系统（提升幅度8.8% ~ 29.2%），在挑战性科学研究任务上整体提升31.8%至50个百分点。

Conclusion: 将人作为认知监督者深度嵌入AI研究过程，不仅提升系统灵活性、协作性与效率，更为实现强大深度科研AI系统指明了新的人机共融发展方向。

Abstract: This paper introduces "Interaction as Intelligence" research series,
presenting a reconceptualization of human-AI relationships in deep research
tasks. Traditional approaches treat interaction merely as an interface for
accessing AI capabilities-a conduit between human intent and machine output. We
propose that interaction itself constitutes a fundamental dimension of
intelligence. As AI systems engage in extended thinking processes for research
tasks, meaningful interaction transitions from an optional enhancement to an
essential component of effective intelligence. Current deep research systems
adopt an "input-wait-output" paradigm where users initiate queries and receive
results after black-box processing. This approach leads to error cascade
effects, inflexible research boundaries that prevent question refinement during
investigation, and missed opportunities for expertise integration. To address
these limitations, we introduce Deep Cognition, a system that transforms the
human role from giving instructions to cognitive oversight-a mode of engagement
where humans guide AI thinking processes through strategic intervention at
critical junctures. Deep cognition implements three key innovations:
(1)Transparent, controllable, and interruptible interaction that reveals AI
reasoning and enables intervention at any point; (2)Fine-grained bidirectional
dialogue; and (3)Shared cognitive context where the system observes and adapts
to user behaviors without explicit instruction. User evaluation demonstrates
that this cognitive oversight paradigm outperforms the strongest baseline
across six key metrics: Transparency(+20.0%), Fine-Grained Interaction(+29.2%),
Real-Time Intervention(+18.5%), Ease of Collaboration(+27.7%),
Results-Worth-Effort(+8.8%), and Interruptibility(+20.7%). Evaluations on
challenging research problems show 31.8% to 50.0% points of improvements over
deep research systems.

</details>


### [222] [Supernova: Achieving More with Less in Transformer Architectures](https://arxiv.org/abs/2507.15773)
*Andrei-Valentin Tanase,Elena Pelican*

Main category: cs.CL

TL;DR: Supernova是一种650M参数的解码器Transformer，通过创新架构设计和高效分词方法，在保持计算效率的基础上实现了大模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前大模型在提升性能的同时通常伴随参数量和计算成本显著增加，本文旨在探索通过架构优化和分词创新，在参数数目较小情况下实现接近甚至超越大模型的表现。

Method: Supernova采用了多项改进：Rotary Positional Embeddings (RoPE)；分组查询注意力（GQA，3:1压缩）；RMSNorm提升效率；SwiGLU激活函数；定制的128k词表字节级BPE分词器强化模型输入压缩性能。

Result: Supernova在只用650M参数和100B训练token的情况下，能达到1B参数模型90%的性能，模型参数减少53%、训练token需求仅为同类产品的十分之一。

Conclusion: 本文证明了通过高效架构和优质分词技术，可以大幅度减少参数量和资源消耗，同时保持优越的模型表现，挑战了盲目扩展参数的主流趋势。

Abstract: We present Supernova, a 650M-parameter decoder-only transformer that
demonstrates how careful architectural design and tokenization innovation can
achieve the performance of larger models while maintaining computational
efficiency. Our architecture combines Rotary Positional Embeddings (RoPE),
Grouped Query Attention (GQA) with a 3:1 compression ratio, RMSNorm for
computational efficiency, and SwiGLU activation functions. A critical
innovation is our custom 128,000-vocabulary byte-level BPE tokenizer, which
achieves state-of-the-art compression performance. Through detailed analysis,
we show that Supernova achieves 90% of the performance of 1B-parameter models
while using 53% fewer parameters and requiring only 100B training tokens--an
order of magnitude less than competing models. Our findings challenge the
prevailing scaling paradigm, demonstrating that architectural efficiency and
tokenization quality can compensate for reduced parameter counts.

</details>


### [223] [Stabilizing Knowledge, Promoting Reasoning: Dual-Token Constraints for RLVR](https://arxiv.org/abs/2507.15778)
*Jiakang Wang,Runze Liu,Fuzheng Zhang,Xiu Li,Guorui Zhou*

Main category: cs.CL

TL;DR: 提出了一种新的RLVR方法Archer，在强化学习奖励的基础上，分别对知识和推理相关token进行区分约束，提高了模型推理和知识保持的能力，在数学推理和代码生成任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统RLVR算法对所有token施加统一训练信号，忽略了知识型token和推理型token在语义和熵上的差异，导致无法同时优化模型的知识保持和推理能力。近期尝试区分token类型的方法往往破坏语义依赖，影响模型学习效果。

Method: 提出Archer方法，对推理token采用弱KL正则和高clipping阈值以鼓励探索，对知识token施加强约束以保持事实知识。同时两类token采用同步更新，避免语义关联被破坏。

Result: 在多个数学推理与代码生成基准测试上，Archer显著优于现有RLVR方法，在相同规模模型中达到甚至超过当前最佳水平。

Conclusion: Archer方法有效平衡了推理能力提升与知识保持，为提升大语言模型推理能力提供了新思路。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has become an effective
post-training method for improving the reasoning abilities of Large Language
Models (LLMs), mainly by shaping higher-order behaviors such as reflection and
planning. However, previous RLVR algorithms often apply uniform training
signals to all tokens, without considering the different roles of low-entropy
knowledge-related tokens and high-entropy reasoning-related tokens. Some recent
methods try to separate these token types by gradient masking or asynchronous
updates, but these approaches may break semantic dependencies in the model
output and hinder effective learning. In this work, we propose Archer, an
entropy-aware RLVR approach with dual-token constraints and synchronous
updates. Specifically, our method applies weaker KL regularization and higher
clipping thresholds to reasoning tokens to encourage exploration, while using
stronger constraints on knowledge tokens to maintain factual knowledge.
Experimental results on several mathematical reasoning and code generation
benchmarks show that our approach significantly outperforms previous RLVR
methods, reaching or exceeding state-of-the-art performance among models of
comparable size. The code is available at
https://github.com/wizard-III/ArcherCodeR.

</details>


### [224] [Reservoir Computing as a Language Model](https://arxiv.org/abs/2507.15779)
*Felix Köster,Atsushi Uchida*

Main category: cs.CL

TL;DR: 本文比较了三种字符级语言建模方法：两种不同的储备计算方法和主流的Transformer方法，分析其在性能、计算成本和预测准确率上的表现，并指出Transformer模型在预测质量上领先，而储备计算模型在速度和能耗上具备显著优势。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成文本任务中表现突出，但其高能耗和处理速度慢成为推广应用的瓶颈。因此，探讨是否有替代引擎能兼顾效率与性能成为研究动机。

Method: 作者将三种方法（包括两种只训练输出层的储备计算方法和完全基于注意力机制的Transformer）统一到同一实验流程，并控制可训练参数量一致，评价其预测能力、计算成本和速度。还探讨了传统储备+静态线性读出和引入注意力机制的动态储备方法。

Result: 实验显示，Transformer模型在预测准确率方面表现最佳，而储备计算方法显著提升训练和推理速度，大幅降低计算能耗。注意力增强的储备计算方法在一定程度上弥补了传统储备的劣势。

Conclusion: 在可训练参数量相同条件下，Transformer适合对预测准确率要求高的场景，而储备计算模型适用于资源受限、需高效推理的场景，本文结果为如何在效率和性能间取舍提供了实际指导。

Abstract: Large Language Models (LLM) have dominated the science and media landscape
duo to their impressive performance on processing large chunks of data and
produce human-like levels of text. Nevertheless, their huge energy demand and
slow processing still a bottleneck for further increasing quality while also
making the models accessible to everyone. To solve this bottleneck, we will
investigate how reservoir computing performs on natural text processing, which
could enable fast and energy efficient hardware implementations. Studies
investigating the use of reservoir computing as a language model remain sparse.
In this paper, we compare three distinct approaches for character-level
language modeling, two different reservoir computing approaches, where only an
output layer is trainable, and the well-known transformer-based architectures,
which fully learn an attention-based sequence representation. We explore the
performance, computational cost and prediction accuracy for both paradigms by
equally varying the number of trainable parameters for all models. Using a
consistent pipeline for all three approaches, we demonstrate that transformers
excel in prediction quality, whereas reservoir computers remain highly
efficient reducing the training and inference speed. Furthermore, we
investigate two types of reservoir computing: a traditional reservoir with a
static linear readout, and an attention-enhanced reservoir that dynamically
adapts its output weights via an attention mechanism. Our findings underline
how these paradigms scale and offer guidelines to balance resource constraints
with performance.

</details>


### [225] [Operationalizing AI for Good: Spotlight on Deployment and Integration of AI Models in Humanitarian Work](https://arxiv.org/abs/2507.15823)
*Anton Abilov,Ke Zhang,Hemank Lamba,Elizabeth M. Olson,Joel R. Tetreault,Alejandro Jaimes*

Main category: cs.CL

TL;DR: 本文关注于AI for Good领域AI模型实际部署与维护过程的梳理，而不仅限于模型研发。


<details>
  <summary>Details</summary>
Motivation: 现有AI for Good研究大多关注模型开发，而鲜有文献探讨与合作组织协作及模型部署带来的现实影响。

Method: 作者通过与一家具有人道主义特征的H2H（humanitarian-to-humanitarian）组织紧密合作，具体记录在资源受限条件下AI模型的部署、持续性能维护的方法，并总结了实践经验。

Result: 展示了如何在资源有限环境中成功部署AI模型，并能持续进行性能更新，合作取得了实际成效。

Conclusion: 本文为AI for Good实践者提供了项目落地、合作及运维的宝贵经验，强调了实际影响与持续维护的重要性。

Abstract: Publications in the AI for Good space have tended to focus on the research
and model development that can support high-impact applications. However, very
few AI for Good papers discuss the process of deploying and collaborating with
the partner organization, and the resulting real-world impact. In this work, we
share details about the close collaboration with a humanitarian-to-humanitarian
(H2H) organization and how to not only deploy the AI model in a
resource-constrained environment, but also how to maintain it for continuous
performance updates, and share key takeaways for practitioners.

</details>


### [226] [The Impact of Language Mixing on Bilingual LLM Reasoning](https://arxiv.org/abs/2507.15849)
*Yihao Li,Jiayi Xin,Miranda Muqing Miao,Qi Long,Lyle Ungar*

Main category: cs.CL

TL;DR: 本研究发现中英双语大模型在推理时出现语言穿插现象（language mixing），且此现象能提升推理能力。通过分析发现RLVR训练阶段促进了语言切换，而强制只用单一语言反而会降低数学推理准确率。基于此，提出可用探针判断切换时机以进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 实际中多语者常在会话中自主切换语言，近年来多语大模型也呈现类似现象。已有观察显示禁止模型切换语言会导致性能下降，促使作者系统性研究语言切换是否有利于推理任务。

Method: 研究对象为中文-英文双语推理模型，追踪训练流程（尤其是RLVR阶段）对语言切换行为的影响。对比模型在强制全程单语和允许自由切换语言两种推理模式下的准确率。同时设计一个轻量级探针模型，判断在具体推理阶段切换语言的利弊，并据此实时指导推理流程。

Result: 语言混用能力主要源自RLVR训练阶段。禁止语言切换会导致数学推理准确率降低5.6个百分点。利用探针动态判断是否切换语言，则推理准确率最多可提升6.25个百分点。

Conclusion: 语言切换不是多语训练的副产品，而是一种可提升推理效果的策略。合理引导语言切换可显著改善双语大模型推理性能。

Abstract: Proficient multilingual speakers often intentionally switch languages in the
middle of a conversation. Similarly, recent reasoning-focused bilingual large
language models (LLMs) with strong capabilities in both languages exhibit
language mixing--alternating languages within their chain of thought.
Discouraging this behavior in DeepSeek-R1 was found to degrade accuracy,
suggesting that language mixing may benefit reasoning. In this work, we study
language switching in Chinese-English bilingual reasoning models. We identify
reinforcement learning with verifiable rewards (RLVR) as the critical training
stage that leads to language mixing. We demonstrate that language mixing can
enhance reasoning: enforcing monolingual decoding reduces accuracy by 5.6
percentage points on math reasoning tasks. Additionally, a lightweight probe
can be trained to predict whether a potential language switch would benefit or
harm reasoning, and when used to guide decoding, increases accuracy by up to
6.25 percentage points. Our findings suggest that language mixing is not merely
a byproduct of multilingual training, but is a strategic reasoning behavior.

</details>


### [227] [3LM: Bridging Arabic, STEM, and Code through Benchmarking](https://arxiv.org/abs/2507.15850)
*Basma El Amel Boussaha,Leen AlQadi,Mugariya Farooq,Shaikha Alsuwaidi,Giulia Campesan,Ahmed Alzubaidi,Mohammed Alyafeai,Hakim Hacid*

Main category: cs.CL

TL;DR: 本文提出了3LM，一个专为阿拉伯语设计的三项基准测试套件，涵盖STEM和代码领域，以弥补现有阿拉伯语LLM测试在这些领域的不足。


<details>
  <summary>Details</summary>
Motivation: 尽管阿拉伯语使用广泛，但相关大型语言模型（LLM）的研发与评测仍然有限。尤其是在STEM和代码领域，现有阿拉伯语基准以语言、文化、宗教为主，缺乏现实应用场景相关的评测工具，因此有必要开发专门的基准套件。

Method: 作者提出了三个新的基准：（1）从阿拉伯语教材和练习册中自然采集的STEM问答对；（2）同样来源下合成生成的STEM问题；（3）将英文主流代码生成基准经过多輪人工翻译和校验，精确转换为阿拉伯语。所有基准均向公众开放。

Result: 成功构建了覆盖STEM和代码领域的高质量阿拉伯语基准套件，数据具有代表性并经过多轮人工校对，公开发布以供研究社区使用。

Conclusion: 3LM基准填补了阿拉伯语LLM在STEM和代码领域评测资源的空白，有助于推动相关研究和实际应用的发展。

Abstract: Arabic is one of the most widely spoken languages in the world, yet efforts
to develop and evaluate Large Language Models (LLMs) for Arabic remain
relatively limited. Most existing Arabic benchmarks focus on linguistic,
cultural, or religious content, leaving a significant gap in domains like STEM
and code which are increasingly relevant for real-world LLM applications. To
help bridge this gap, we present 3LM, a suite of three benchmarks designed
specifically for Arabic. The first is a set of STEM-related question-answer
pairs, naturally sourced from Arabic textbooks and educational worksheets. The
second consists of synthetically generated STEM questions, created using the
same sources. The third benchmark focuses on code generation, built through a
careful translation of two widely used code benchmarks, incorporating a
human-in-the-loop process with several rounds of review to ensure high-quality
and faithful translations. We release all three benchmarks publicly to support
the growth of Arabic LLM research in these essential but underrepresented
areas.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [228] [Real-Time Communication-Aware Ride-Sharing Route Planning for Urban Air Mobility: A Multi-Source Hybrid Attention Reinforcement Learning Approach](https://arxiv.org/abs/2507.14249)
*Yuejiao Xie,Maonan Wang,Di Zhou,Man-On Pun,Zhu Han*

Main category: cs.RO

TL;DR: 本文针对城市空中出行（UAM）系统路径规划面临的通信质量与实时响应难题，提出了一种基于多源混合注意力强化学习（MSHA-RL）的解决方案。实验结果显示该方法可实现通信合规的轨迹规划，并提升出行效率与安全性。


<details>
  <summary>Details</summary>
Motivation: UAM作为缓解城市拥堵的新兴方式，但其路径规划不但要考虑时空约束，还要优先保障通信质量以确保飞行安全，且需应对实时动态、不确定的乘客需求。传统基于预定义路线的路径规划已无法胜任UAM多变复杂的需求，尤其是在共享乘车等情景下。

Method: 作者首先使用无线电地图评估城市空域通信质量，并提出了多源混合注意力强化学习（MSHA-RL）框架。该框架针对乘客与UAM位置信息在表示维度上的巨大差异，先进行多源数据对齐，然后利用混合注意力机制平衡全局与局部信息，实现高效实时的路径规划。

Result: 实验表明，所提方法能有效支持具备通信约束的轨迹规划，显著降低旅程时间并提升运营效率，同时保障乘客安全。

Conclusion: MSHA-RL模型为城市空中出行提供了兼顾通信合规、效率和安全的路径规划新方案，适用于乘客需求动态变动、实时性强的UAM场景。

Abstract: Urban Air Mobility (UAM) systems are rapidly emerging as promising solutions
to alleviate urban congestion, with path planning becoming a key focus area.
Unlike ground transportation, UAM trajectory planning has to prioritize
communication quality for accurate location tracking in constantly changing
environments to ensure safety. Meanwhile, a UAM system, serving as an air taxi,
requires adaptive planning to respond to real-time passenger requests,
especially in ride-sharing scenarios where passenger demands are unpredictable
and dynamic. However, conventional trajectory planning strategies based on
predefined routes lack the flexibility to meet varied passenger ride demands.
To address these challenges, this work first proposes constructing a radio map
to evaluate the communication quality of urban airspace. Building on this, we
introduce a novel Multi-Source Hybrid Attention Reinforcement Learning
(MSHA-RL) framework for the challenge of effectively focusing on passengers and
UAM locations, which arises from the significant dimensional disparity between
the representations. This model first generates the alignment among diverse
data sources with large gap dimensions before employing hybrid attention to
balance global and local insights, thereby facilitating responsive, real-time
path planning. Extensive experimental results demonstrate that the approach
enables communication-compliant trajectory planning, reducing travel time and
enhancing operational efficiency while prioritizing passenger safety.

</details>


### [229] [A Recursive Lie-Group Formulation for the Second-Order Time Derivatives of the Inverse Dynamics of parallel Kinematic Manipulators](https://arxiv.org/abs/2507.14274)
*Andreas Mueller,Shivesh Kumar,Thomas Kordik*

Main category: cs.RO

TL;DR: 本文首次提出并高效实现了串联弹性执行器(SEA)在并联机器人(PKM)上的轨迹跟踪控制算法，重点解决了逆动力学解二阶导数的高效计算，验证了其在不同类型PKM上的可行性。


<details>
  <summary>Details</summary>
Motivation: 并联机器人由于其特殊的结构优势被广泛关注，但基于SEA的轨迹控制尚未实现，主要难点在于需高效计算逆动力学的二阶导数。

Method: 利用PKM的结构特点，将串联机器人的逆动力学递归算法与Lie群理论相结合，实现了PKM逆动力学二阶导数的高效推导，并给出具体数值仿真。

Result: 提出的方法被应用于6自由度Gough-Stewart平台(外骨骼应用)和二维平面PKM，并显示了良好的计算效率与实际可行性。

Conclusion: 本文方法首次实现了SEAs在PKM轨迹追踪控制中的应用，为该领域相关控制算法的研究与实际应用提供了理论与方法基础。

Abstract: Series elastic actuators (SEA) were introduced for serial robotic arms. Their
model-based trajectory tracking control requires the second time derivatives of
the inverse dynamics solution, for which algorithms were proposed. Trajectory
control of parallel kinematics manipulators (PKM) equipped with SEAs has not
yet been pursued. Key element for this is the computationally efficient
evaluation of the second time derivative of the inverse dynamics solution. This
has not been presented in the literature, and is addressed in the present paper
for the first time. The special topology of PKM is exploited reusing the
recursive algorithms for evaluating the inverse dynamics of serial robots. A
Lie group formulation is used and all relations are derived within this
framework. Numerical results are presented for a 6-DOF Gough-Stewart platform
(as part of an exoskeleton), and for a planar PKM when a flatness-based control
scheme is applied.

</details>


### [230] [Personalized Socially Assistive Robots With End-to-End Speech-Language Models For Well-Being Support](https://arxiv.org/abs/2507.14412)
*Mengxue Fu,Zhonghao Shi,Minyu Huang,Siqi Liu,Mina Kian,Yirui Song,Maja J. Matarić*

Main category: cs.RO

TL;DR: 本文提出使用端到端语音-语言模型（SLM）来改进社会辅助机器人（SAR）的对话能力，通过一项小型用户研究，评估其可用性，并分析现有不足，为未来改进提供建议。


<details>
  <summary>Details</summary>
Motivation: 现有的社会辅助机器人（SAR）对话系统，在实时响应、附和（back-channel）、个性化语言等方面存在较大局限，难以满足提升用户情感体验及福祉的需求。因此，希望通过更先进的模型提升SAR的对话质量。

Method: 作者提出将端到端的语音-语言模型（SLM）集成到社会辅助机器人中，并通过对11名大学生的受试者进行一项参与式用户实验，评估该系统在现实互动中的表现和用户体验。同时收集用户反馈，分析系统的不足。

Result: 实验结果显示，集成SLM的SAR系统在表现同理反馈、自然而交替的对话、附和反应及自适应回复方面受到用户好评。但用户也指出了机器人的非语言行为变化少，动作与对话缺乏同步，以及SLM输出的语言反馈过于通用和重复。

Conclusion: 研究表明，整合SLM提高了SAR在对话方面的表现，但要进一步提升体验，需要改进机器人动作与对话的实时同步、SLM的定制微调和更具表现力的语音生成，以更好地支持心理健康和个性化互动。

Abstract: Socially assistive robots (SARs) have shown great potential for supplementing
well-being support. However, prior studies have found that existing dialogue
pipelines for SARs remain limited in real-time latency, back-channeling, and
personalized speech dialogue. Toward addressing these limitations, we propose
using integrated end-to-end speech-language models (SLMs) with SARs. This work
1) evaluated the usability of an SLM-enabled SAR dialogue system through a
small user study, and 2) identified remaining limitations through study user
feedback to inform future improvements. We conducted a small within-participant
user study with university students (N = 11) whose results showed that
participants perceived an SLM-enabled SAR system as capable of providing
empathetic feedback, natural turn-taking, back-channeling, and adaptive
responses. We also found that participants reported the robot's nonverbal
behaviors as lacking variability and synchronization with conversation, and the
SLM's verbal feedback as generic and repetitive. These findings highlighted the
need for real-time robot movement synchronized with conversation, improved
prompting or fine-tuning to generate outputs better aligned with mental health
practices, and more expressive, adaptive vocal generation.

</details>


### [231] [Koopman Operator Based Time-Delay Embeddings and State History Augmented LQR for Periodic Hybrid Systems: Bouncing Pendulum and Bipedal Walking](https://arxiv.org/abs/2507.14455)
*Chun-Ming Yang,Pranav A. Bhounsule*

Main category: cs.RO

TL;DR: 本论文探索了时延嵌入技术在线性建模非平滑或混合系统中的应用，并提出了一种结合状态历史的线性二次调节器（LQR）用于更加有效的反馈控制。


<details>
  <summary>Details</summary>
Motivation: 传统的时延嵌入主要针对平滑非线性系统，而许多工程实际中的系统如混合或非平滑系统难以用现有方法建模。作者希望通过扩展方法，使其能适用于这类系统，提升控制和建模的准确性。

Method: 作者将时延嵌入技术应用于两个周期性的混合动力系统：弹跳摆和带有控制输入的最简单行走者，通过对其过去和当前状态的嵌入建立线性状态空间模型。同时，基于此拓展了线性二次调节器（LQR），使其能利用状态历史信息进行反馈。

Result: 实验结果显示，通过时延嵌入，可以有效地将周期性混合系统建模为线性系统，并且状态历史增强的LQR控制器在控制效果上表现良好。

Conclusion: 时延嵌入方法不仅适用于平滑系统，对周期性非平滑或混合系统同样有效；而采用状态历史增强的LQR能提升控制精度，为混合动力系统的线性建模和控制提供了新途径。

Abstract: Time-delay embedding is a technique that uses snapshots of state history over
time to build a linear state space model of a nonlinear smooth system. We
demonstrate that periodic non-smooth or hybrid system can also be modeled as a
linear state space system using this approach as long as its behavior is
consistent in modes and timings. We extended time-delay embeddings to generate
a linear model of two periodic hybrid systems: the bouncing pendulum and the
simplest walker with control inputs. This leads to a novel state history
augmented linear quadratic regulator (LQR) which uses current and past state
history for feedback control.

</details>


### [232] [A 21-DOF Humanoid Dexterous Hand with Hybrid SMA-Motor Actuation: CYJ Hand-0](https://arxiv.org/abs/2507.14538)
*Jin Chai,Xiang Yao,Mengfan Hou,Yanghong Li,Erbao Dong*

Main category: cs.RO

TL;DR: CYJ Hand-0是一款21自由度、融合形状记忆合金和直流电机为驱动的新型仿生仿人手，结合高强度钓鱼线腱和3D打印金属骨架，实现了类人手的灵巧性，经实验证明设计有效。


<details>
  <summary>Details</summary>
Motivation: 现有仿生手在结构和灵巧性上与人手存在差距，且驱动系统往往较重或复杂。为了提升仿生手的仿真度和实用性，开发一种兼顾紧凑度、驱动力和仿生结构的驱动系统成为必要。

Method: 该仿生手采用形状记忆合金（SMA）和直流电机相结合的混合腱驱动系统，高强度钓鱼线作为人工肌腱，3D打印AlSi10Mg金属骨架模拟人手结构。线性电机模块实现屈指，SMA模块实现伸指和侧向外展，所有模块集成在紧凑驱动单元并由Arduino控制进行实验验证。

Result: 机械与运动学实验表明，该设计不仅结构紧凑，而且实现了灵巧的仿生运动，验证了新型混合驱动和结构方案的有效性。

Conclusion: 该研究成功开发了一种高度仿生、紧凑且功能灵活的21自由度仿生手，为仿生机械手的结构设计与驱动方法提供了新思路，在医疗、服务机器人等领域有广泛应用前景。

Abstract: CYJ Hand-0 is a 21-DOF humanoid dexterous hand featuring a hybrid
tendon-driven actuation system that combines shape memory alloys (SMAs) and DC
motors. The hand employs high-strength fishing line as artificial tendons and
uses a fully 3D-printed AlSi10Mg metal frame designed to replicate the skeletal
and tendon-muscle structure of the human hand. A linear motor-driven module
controls finger flexion, while an SMA-based module enables finger extension and
lateral abduction. These modules are integrated into a compact hybrid actuation
unit mounted on a custom rear support structure. Mechanical and kinematic
experiments, conducted under an Arduino Mega 2560-based control system,
validate the effectiveness of the design and demonstrate its biomimetic
dexterity.

</details>


### [233] [BT-TL-DMPs: A Novel Robot TAMP Framework Combining Behavior Tree, Temporal Logic and Dynamical Movement Primitives](https://arxiv.org/abs/2507.14582)
*Zezhi Liu,Shizhen Wu,Hanqian Luo,Deyun Qin,Yongchun Fang*

Main category: cs.RO

TL;DR: 本文提出了一种新的层次化框架BT-TL-DMPs，将行为树、时序逻辑和动态运动基元融合，用于提升机器人在复杂长期操作任务中的泛化与适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有机器人学习系统在处理具有多阶段、复杂约束条件的长期操作任务时，难以将已学习的技能泛化到新环境和满足新需求。克服这个限制对于实现真正灵活自主的机器人至关重要。

Method: 该方法基于行为树（BT）、时序逻辑（TL）和动态运动基元（DMPs）的层次化集成，利用信号时序逻辑（STL）形式化描述复杂长期任务和约束，并将其系统性地转换为模块化的行为树，高层进行决策。同时，提出带STL约束的DMP优化方法，使底层运动在满足复杂时空约束的同时，保持从示范中学到的关键动态特征。

Result: 在仿真和真实机器人操作任务上验证了该框架。结果显示方法能在多种STL约束下，对复杂、长期操作任务场景实现更强泛化能力和自适应性能。

Conclusion: BT-TL-DMPs框架有效弥合了符号层（高层决策）与运动层（底层控制）之间的鸿沟，提升了复杂机器人任务中技能的可靠性与泛化性。

Abstract: In the field of Learning from Demonstration (LfD), enabling robots to
generalize learned manipulation skills to novel scenarios for long-horizon
tasks remains challenging. Specifically, it is still difficult for robots to
adapt the learned skills to new environments with different task and motion
requirements, especially in long-horizon, multi-stage scenarios with intricate
constraints. This paper proposes a novel hierarchical framework, called
BT-TL-DMPs, that integrates Behavior Tree (BT), Temporal Logic (TL), and
Dynamical Movement Primitives (DMPs) to address this problem. Within this
framework, Signal Temporal Logic (STL) is employed to formally specify complex,
long-horizon task requirements and constraints. These STL specifications are
systematically transformed to generate reactive and modular BTs for high-level
decision-making task structure. An STL-constrained DMP optimization method is
proposed to optimize the DMP forcing term, allowing the learned motion
primitives to adapt flexibly while satisfying intricate spatiotemporal
requirements and, crucially, preserving the essential dynamics learned from
demonstrations. The framework is validated through simulations demonstrating
generalization capabilities under various STL constraints and real-world
experiments on several long-horizon robotic manipulation tasks. The results
demonstrate that the proposed framework effectively bridges the symbolic-motion
gap, enabling more reliable and generalizable autonomous manipulation for
complex robotic tasks.

</details>


### [234] [Koopman Operator Based Linear Model Predictive Control for 2D Quadruped Trotting, Bounding, and Gait Transition](https://arxiv.org/abs/2507.14605)
*Chun-Ming Yang,Pranav A. Bhounsule*

Main category: cs.RO

TL;DR: 本文提出了一种基于Koopman算子理论与EDMD方法的混合动力学建模技术，将其与线性模型预测控制（LMPC）结合，用于四足机器人多步态及步态切换的在线优化控制，显著提升了控制系统的非线性建模能力和运动表现。


<details>
  <summary>Details</summary>
Motivation: 传统的LMPC方法因需要对动力学方程线性化，导致在复杂或高度非线性的四足机器人行走环境下控制效果不佳。作者希望解决机器人在新颖场景下自主规划运动时的动力学建模不足问题，提升机器人对复杂与崎岖地形适应性。

Method: 作者利用Koopman算子理论和扩展动态模态分解（EDMD）技术，在高维空间中建立原动力学方程的线性近似，无需对机器人动力学强行线性化，能够更好地保留系统的非线性特征。此外，针对空中相位与地面接触相位分别采用不同线性模型建模，并在LMPC框架下进行实时轨迹优化。

Result: 该方法能够在平坦和崎岖地形下，实现四足机器人多种步态（如bounding、trotting）及步态间（bound-trot、trot-bound）的动态切换，效果明显优于传统线性化方法。

Conclusion: 通过引入Koopman算子理论构建混合动力学模型，显著提高了四足机器人在线控制中的非线性建模能力和步态生成多样性，为复杂环境下高性能四足机器人运动控制提供了新的思路。

Abstract: Online optimal control of quadrupedal robots would enable them to plan their
movement in novel scenarios. Linear Model Predictive Control (LMPC) has emerged
as a practical approach for real-time control. In LMPC, an optimization problem
with a quadratic cost and linear constraints is formulated over a finite
horizon and solved on the fly. However, LMPC relies on linearizing the
equations of motion (EOM), which may lead to poor solution quality. In this
paper, we use Koopman operator theory and the Extended Dynamic Mode
Decomposition (EDMD) to create a linear model of the system in high dimensional
space, thus retaining the nonlinearity of the EOM. We model the aerial phase
and ground contact phases using different linear models. Then, using LMPC, we
demonstrate bounding, trotting, and bound-to-trot and trot-to-bound gait
transitions in level and rough terrains. The main novelty is the use of Koopman
operator theory to create hybrid models of a quadrupedal system and demonstrate
the online generation of multiple gaits and gaits transitions.

</details>


### [235] [Uncertainty-aware Probabilistic 3D Human Motion Forecasting via Invertible Networks](https://arxiv.org/abs/2507.14694)
*Yue Ma,Kanglei Zhou,Fuyang Yu,Frederick W. B. Li,Xiaohui Liang*

Main category: cs.RO

TL;DR: 提出了ProbHMI方法，利用可逆网络和显式概率建模，实现3D人体动作预测及高效的不确定性量化。方法在多个基准数据集上表现优异，尤其擅长不确定性校准，适合安全关键场景。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体动作预测方法难以对预测结果给出可靠的不确定性量化，导致在需要风险控制的机器人协作等应用中存在安全隐患。因此，提升动作预测中不确定性的建模能力十分迫切。

Method: 提出了ProbHMI方法：用可逆网络将姿态编码到解耦的潜空间，对潜变量进行概率动态建模，并通过预测未来潜在分布实现对未来动作的显式不确定性估计。

Result: 在多个公开基准数据集上，ProbHMI在确定性预测、多样性生成以及不确定性校准等关键指标上均表现出色。

Conclusion: ProbHMI不仅提升了3D动作预测的精度和多样性，更实现了可靠的不确定性量化，为人机协作等安全敏感场景提供了理论与技术支持。

Abstract: 3D human motion forecasting aims to enable autonomous applications.
Estimating uncertainty for each prediction (i.e., confidence based on
probability density or quantile) is essential for safety-critical contexts like
human-robot collaboration to minimize risks. However, existing diverse motion
forecasting approaches struggle with uncertainty quantification due to implicit
probabilistic representations hindering uncertainty modeling. We propose
ProbHMI, which introduces invertible networks to parameterize poses in a
disentangled latent space, enabling probabilistic dynamics modeling. A
forecasting module then explicitly predicts future latent distributions,
allowing effective uncertainty quantification. Evaluated on benchmarks, ProbHMI
achieves strong performance for both deterministic and diverse prediction while
validating uncertainty calibration, critical for risk-aware decision making.

</details>


### [236] [Corridor-based Adaptive Control Barrier and Lyapunov Functions for Safe Mobile Robot Navigation](https://arxiv.org/abs/2507.14700)
*Nicholas Mohammad,Nicola Bezzo*

Main category: cs.RO

TL;DR: 提出了一种结合CLF与CBF的模型预测轮廓控制（MPCC）方法，可实现在未知、拥挤环境下机器人的安全导航，并通过强化学习动态调整参数，提升可行性。


<details>
  <summary>Details</summary>
Motivation: 现有的MPCC方法虽然可以实现灵活的避障和轨迹跟踪，但缺乏形式化的安全保障，难以满足实际复杂环境中的安全要求。

Method: 设计了结合控制李亚普诺夫函数（CLF）和控制障碍函数（CBF）的MPCC框架，从轨迹周围自由空间走廊推导安全约束，并利用Soft Actor-Critic（SAC）强化学习策略在运行时自适应调整CBF参数。

Result: 通过大量仿真和真实机器人实验验证了方法在未知、复杂环境中导航的有效性和安全性。

Conclusion: 该方法能提升机器人在未知、密集障碍物环境中的安全导航性能，实现了安全性和可行性的兼顾。

Abstract: Safe navigation in unknown and cluttered environments remains a challenging
problem in robotics. Model Predictive Contour Control (MPCC) has shown promise
for performant obstacle avoidance by enabling precise and agile trajectory
tracking, however, existing methods lack formal safety assurances. To address
this issue, we propose a general Control Lyapunov Function (CLF) and Control
Barrier Function (CBF) enabled MPCC framework that enforces safety constraints
derived from a free-space corridor around the planned trajectory. To enhance
feasibility, we dynamically adapt the CBF parameters at runtime using a Soft
Actor-Critic (SAC) policy. The approach is validated with extensive simulations
and an experiment on mobile robot navigation in unknown cluttered environments.

</details>


### [237] [Leveraging Extrinsic Dexterity for Occluded Grasping on Grasp Constraining Walls](https://arxiv.org/abs/2507.14721)
*Keita Kobashi,Masayoshi Tomizuka*

Main category: cs.RO

TL;DR: 本研究提出了一种分层强化学习框架，解决机器人在物体被遮挡时的抓取问题，通过结合高层动作选择与低层技能执行，并利用CVAE指引动作位置，实现了在不同环境和物体上的良好泛化与仿真到现实的迁移能力。


<details>
  <summary>Details</summary>
Motivation: 传统的平行夹爪机器人在抓取被环境遮挡的物体时受限于灵活性和驱动能力，现有方法依赖于墙这种外部接触点，但假设的墙的尺寸在现实场景中不总是满足。因此，需要更灵活且泛化能力强的抓取方法。

Method: 提出分层强化学习框架，高层策略（通过Q-learning）选择预计收益最高的动作类型，低层技能在连续空间中采样具体动作。动作执行位置通过条件变分自编码器（CVAE）预测，CVAE基于物体点云和技能ID进行条件推理。为增强泛化，在低层技能训练中应用领域随机化。

Result: 通过在仿真中训练强化学习策略，并在六种现实物体上部署实验，表明该方法具备良好的泛化能力及强健的仿真到现实迁移性能，取得了有希望的抓取成功率。

Conclusion: 所提分层强化学习抓取策略能有效应对被遮挡物体的抓取问题，在不同物体和环境下均表现出良好的适应性和鲁棒性，证明了其在实际机器人抓取任务中的应用前景。

Abstract: This study addresses the problem of occluded grasping, where primary grasp
configurations of an object are not available due to occlusion with
environment. Simple parallel grippers often struggle with such tasks due to
limited dexterity and actuation constraints. Prior works have explored object
pose reorientation such as pivoting by utilizing extrinsic contacts between an
object and an environment feature like a wall, to make the object graspable.
However, such works often assume the presence of a short wall, and this
assumption may not always hold in real-world scenarios. If the wall available
for interaction is too large or too tall, the robot may still fail to grasp the
object even after pivoting, and the robot must combine different types of
actions to grasp. To address this, we propose a hierarchical reinforcement
learning (RL) framework. We use Q-learning to train a high-level policy that
selects the type of action expected to yield the highest reward. The selected
low-level skill then samples a specific robot action in continuous space. To
guide the robot to an appropriate location for executing the selected action,
we adopt a Conditional Variational Autoencoder (CVAE). We condition the CVAE on
the object point cloud and the skill ID, enabling it to infer a suitable
location based on the object geometry and the selected skill. To promote
generalization, we apply domain randomization during the training of low-level
skills. The RL policy is trained entirely in simulation with a box-like object
and deployed to six objects in real world. We conduct experiments to evaluate
our method and demonstrate both its generalizability and robust sim-to-real
transfer performance with promising success rates.

</details>


### [238] [X-Nav: Learning End-to-End Cross-Embodiment Navigation for Mobile Robots](https://arxiv.org/abs/2507.14731)
*Haitong Wang,Aaron Hao Tan,Angus Fung,Goldie Nejat*

Main category: cs.RO

TL;DR: X-Nav是一种能跨不同机器人结构（如轮式和四足机器人）通用的导航方法，通过两个阶段训练，实现了单一策略可适用于多种机器人。


<details>
  <summary>Details</summary>
Motivation: 现有导航方法局限于特定机器人类型，难以适用于多种机器人平台，限制了通用性和实际应用价值。

Method: 提出X-Nav框架：第一阶段，利用深度强化学习和特权观测在大量随机生成的机器人结构上训练多个专家策略；第二阶段，采用基于transformer的动作分块方法，将专家策略蒸馏成统一的通用策略，实现视觉和本体观测到低级控制指令的直接映射。

Result: 仿真实验表明X-Nav可零样本迁移至新机器人结构和真实感环境。可扩展性研究显示，训练机器人多样性越高，性能提升越多。消融实验验证了设计合理性。实地实验亦证实了方法的泛化能力。

Conclusion: X-Nav是一种高效且通用的导航框架，能够跨多种不同机器人结构以零迁移实现导航，对现实环境具有良好适应性。

Abstract: Existing navigation methods are primarily designed for specific robot
embodiments, limiting their generalizability across diverse robot platforms. In
this paper, we introduce X-Nav, a novel framework for end-to-end
cross-embodiment navigation where a single unified policy can be deployed
across various embodiments for both wheeled and quadrupedal robots. X-Nav
consists of two learning stages: 1) multiple expert policies are trained using
deep reinforcement learning with privileged observations on a wide range of
randomly generated robot embodiments; and 2) a single general policy is
distilled from the expert policies via navigation action chunking with
transformer (Nav-ACT). The general policy directly maps visual and
proprioceptive observations to low-level control commands, enabling
generalization to novel robot embodiments. Simulated experiments demonstrated
that X-Nav achieved zero-shot transfer to both unseen embodiments and
photorealistic environments. A scalability study showed that the performance of
X-Nav improves when trained with an increasing number of randomly generated
embodiments. An ablation study confirmed the design choices of X-Nav.
Furthermore, real-world experiments were conducted to validate the
generalizability of X-Nav in real-world environments.

</details>


### [239] [KGN-Pro: Keypoint-Based Grasp Prediction through Probabilistic 2D-3D Correspondence Learning](https://arxiv.org/abs/2507.14820)
*Bingran Chen,Baorun Li,Jian Yang,Yong Liu,Guangyao Zhai*

Main category: cs.RO

TL;DR: 本文提出了一种名为KGN-Pro的新型抓取网络，结合2D关键点和3D优化，实现了高效且精细化的6自由度（6-DoF）机械臂抓取。实验表明该方法在仿真和现实场景中均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有6-DoF抓取方法要么直接从点云生成抓取（易受小物体和传感噪声影响），要么依赖RGB图像推断3D信息（标注代价高且离散化误差大）；而通过2D关键点估计结合PnP算法计算6-DoF位姿的方法又存在不可微、仅利用2D监督、3D信息利用受限等问题。为解决上述不足，提升机械臂操作的精确性和鲁棒性，作者提出新方法。

Method: KGN-Pro网络以RGB-D配对图像作为输入，生成关键点图和2D置信图，利用加权重投影误差的概率建模，实现端到端的2D-3D联合优化。核心创新为引入概率PnP层，使网络能够通过最小化加权的重投影误差，将3D监督信息有效传递到2D关键点预测，并保持整个流程可微分。

Result: 实验在仿真和真实机械臂平台上进行，KGN-Pro在抓取覆盖率和成功率两项指标上均优于现有主流方法。

Conclusion: KGN-Pro方法不仅融合了2D和3D信息，克服了以往方法的主要缺陷，还能通过端到端训练充分利用3D监督，显著提升了实际机械臂抓取的性能。

Abstract: High-level robotic manipulation tasks demand flexible 6-DoF grasp estimation
to serve as a basic function. Previous approaches either directly generate
grasps from point-cloud data, suffering from challenges with small objects and
sensor noise, or infer 3D information from RGB images, which introduces
expensive annotation requirements and discretization issues. Recent methods
mitigate some challenges by retaining a 2D representation to estimate grasp
keypoints and applying Perspective-n-Point (PnP) algorithms to compute 6-DoF
poses. However, these methods are limited by their non-differentiable nature
and reliance solely on 2D supervision, which hinders the full exploitation of
rich 3D information. In this work, we present KGN-Pro, a novel grasping network
that preserves the efficiency and fine-grained object grasping of previous KGNs
while integrating direct 3D optimization through probabilistic PnP layers.
KGN-Pro encodes paired RGB-D images to generate Keypoint Map, and further
outputs a 2D confidence map to weight keypoint contributions during
re-projection error minimization. By modeling the weighted sum of squared
re-projection errors probabilistically, the network effectively transmits 3D
supervision to its 2D keypoint predictions, enabling end-to-end learning.
Experiments on both simulated and real-world platforms demonstrate that KGN-Pro
outperforms existing methods in terms of grasp cover rate and success rate.

</details>


### [240] [CoMoCAVs: Cohesive Decision-Guided Motion Planning for Connected and Autonomous Vehicles with Multi-Policy Reinforcement Learning](https://arxiv.org/abs/2507.14903)
*Pan Hu*

Main category: cs.RO

TL;DR: 提出了一种新方法CDGMP，将决策和运动规划紧密结合，提高自动驾驶在高速公路变道任务中的适应性、安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中高速公路选道决策和轨迹执行存在灵活与安全难以兼顾等挑战，亟需高效、可靠的集成式解决方案。

Method: 提出Cohesive Decision-Guided Motion Planning（CDGMP）框架，采用专家混合（MoE）结构与多策略强化学习。将复杂驾驶任务分解为多个专门子网络，并通过门控机制激活最相关的模块，实现模块化、专业化处理。

Result: 仿真结果显示，该方法在车道选择和轨迹执行方面表现可靠，提升了自动驾驶系统在多样交通场景下的适应性与鲁棒性。

Conclusion: CDGMP能够提升自动驾驶车辆的可扩展性与安全性，其架构原理对于其它高维决策与控制任务同样具有推广意义。

Abstract: Autonomous driving demands reliable and efficient solutions to closely
related problems such as decision-making and motion planning. In this work,
decision-making refers specifically to highway lane selection, while motion
planning involves generating control commands (such as speed and steering) to
reach the chosen lane. In the context of Connected Autonomous Vehicles (CAVs),
achieving both flexible and safe lane selection alongside precise trajectory
execution remains a significant challenge. This paper proposes a framework
called Cohesive Decision-Guided Motion Planning (CDGMP), which tightly
integrates decision-making and motion planning using a Mixture of Experts (MoE)
inspired architecture combined with multi-policy reinforcement learning. By
coordinating multiple specialized sub-networks through a gating mechanism, the
method decomposes the complex driving task into modular components. Each
sub-network focuses on a specific aspect of driving, improving efficiency by
activating only the most relevant modules during inference. This design also
enhances safety through modular specialization. CDGMP improves the adaptability
and robustness of CAVs across diverse traffic scenarios, offering a scalable
solution to real-world autonomy challenges. The architectural principles behind
CDGMP, especially the use of MoE, also provide a strong foundation for other
high-dimensional decision and control tasks. Simulation results (available at
https://youtu.be/_-4OXNHV0UY) demonstrate reliable performance in both lane
selection and motion planning.

</details>


### [241] [One Step Beyond: Feedthrough & Placement-Aware Rectilinear Floorplanner](https://arxiv.org/abs/2507.14914)
*Zhexuan Xu,Jie Wang,Siyuan Xu,Zijie Geng,Mingxuan Yuan,Feng Wu*

Main category: cs.RO

TL;DR: 本文提出了一种名为Flora的新型三阶段楼层规划框架，与后续物理设计阶段协同优化，在芯片PP​​A优化上优于当前方法。


<details>
  <summary>Details</summary>
Motivation: 现有芯片楼层规划方法往往未能与后续物理设计阶段有效衔接，导致芯片内部元件布局不理想，跨模块连线过多，影响性能。

Method: 提出三阶段方法：第一阶段利用线长掩码和位置掩码进行粗粒度优化，第二阶段在固定芯片轮廓下通过局部调整模块形状实现零空白空间的精细优化，第三阶段利用快速树搜索方法对各模块内元件进行布局，并根据结果动态调整模块边界，实现分阶段联合优化。

Result: 实验结果显示，Flora相对于最新方法平均减少6%的HPWL，减少5.16%的FTpin和29.15%的FTmod，元件布局性能提升14%。

Conclusion: Flora能够实现更优的楼层规划与物理设计协同，提升芯片整体设计上的PPA表现。

Abstract: Floorplanning determines the shapes and locations of modules on a chip canvas
and plays a critical role in optimizing the chip's Power, Performance, and Area
(PPA) metrics. However, existing floorplanning approaches often fail to
integrate with subsequent physical design stages, leading to suboptimal
in-module component placement and excessive inter-module feedthrough. To tackle
this challenge, we propose Flora, a three-stage feedthrough and placement aware
rectilinear floorplanner. In the first stage, Flora employs wiremask and
position mask techniques to achieve coarse-grained optimization of HPWL and
feedthrough. In the second stage, under the constraint of a fixed outline,
Flora achieves a zero-whitespace layout by locally resizing module shapes,
thereby performing fine-grained optimization of feedthrough and improving
component placement. In the third stage, Flora utilizes a fast tree
search-based method to efficiently place components-including macros and
standard cells-within each module, subsequently adjusting module boundaries
based on the placement results to enable cross-stage optimization. Experimental
results show that Flora outperforms recent state-of-the-art floorplanning
approaches, achieving an average reduction of 6% in HPWL, 5.16% in FTpin,
29.15% in FTmod, and a 14% improvement in component placement performance.

</details>


### [242] [Digital twin and extended reality for teleoperation of the electric vehicle battery disassembly](https://arxiv.org/abs/2507.14929)
*Tero Kaarlela,Sami Salo,Jose Outeiro*

Main category: cs.RO

TL;DR: 本文提出了一种远程操控系统，结合人工与自动化，实现电动车电池安全拆解与分类，提高了回收效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 目前电动车电池（EVB）的拆解主要依赖人工操作，工人在拆解过程中面临触电、有毒化学品等危险，亟需更安全、高效的解决方案以实现电池回收闭环。

Method: 提出了一种以人机混合为核心的远程操控系统，通过RGB相机对齐EVB的物理与数字孪生，利用ROS中间件建立机器人数字孪生，允许操作者为未知电池类型创建与保存拆解序列，为未来自动化打下基础。

Result: 系统降低了人工依赖，提高了回收通量，提升了拆解过程的安全性与适应性。在线试点研究验证了该系统的易用性和用户友好性。

Conclusion: 该混合远程操控与自动化方案在EVB拆解和分类应用中显示出良好潜力，有助于推动电池回收产业的安全、经济与可持续发展。

Abstract: Disassembling and sorting Electric Vehicle Batteries (EVBs) supports a
sustainable transition to electric vehicles by enabling a closed-loop supply
chain. Currently, the manual disassembly process exposes workers to hazards,
including electrocution and toxic chemicals. We propose a teleoperated system
for the safe disassembly and sorting of EVBs. A human-in-the-loop can create
and save disassembly sequences for unknown EVB types, enabling future
automation. An RGB camera aligns the physical and digital twins of the EVB, and
the digital twin of the robot is based on the Robot Operating System (ROS)
middleware. This hybrid approach combines teleoperation and automation to
improve safety, adaptability, and efficiency in EVB disassembly and sorting.
The economic contribution is realized by reducing labor dependency and
increasing throughput in battery recycling. An online pilot study was set up to
evaluate the usability of the presented approach, and the results demonstrate
the potential as a user-friendly solution.

</details>


### [243] [Designing Robots with, not for: A Co-Design Framework for Empowering Interactions in Forensic Psychiatry](https://arxiv.org/abs/2507.14931)
*Qiaoqiao Ren,Remko Proesmans,Arend Pissens,Lara Dehandschutter,William Denecker,Lotte Rouckhout,Joke Carrette,Peter Vanhopplinus,Tony Belpaeme,Francis wyffels*

Main category: cs.RO

TL;DR: 本研究在法医精神卫生环境中，通过共同设计方法开发了一款帮助缓解患者压力并追踪其行为的陪伴机器人，强调让患者参与设计过程以提升其自主性。


<details>
  <summary>Details</summary>
Motivation: 法医精神卫生场所患者由于所受限制大、风险规避高，经常失去生活的自主权，心理压力巨大。现有照护往往以安全为先，反而忽略了患者的心理体验与自我赋能。研究希望借由新型科技，提升患者在治疗过程中的自主性与参与感。

Method: 研究团队在一家法医精神病院举行了四场共同设计研讨会，将患者、照护者与治疗师纳入合作，先通过向治疗师展示初步原型，收集他们对于潜在风险与需求的反馈，随后开展患者创意工作坊和功能定义讨论，拟定最终陪伴机器人原型功能。

Result: 初步结果显示，患者参与设计过程有助于提升其表达自我需求和情绪的能力，使最终产品更贴合患者实际情况，且方案需根据患者当下情绪动态适时调整。

Conclusion: 患者在设计过程中的积极参与对于科技辅助手段在法医精神卫生中的有效性与伦理性至关重要，推动了患者自我赋能与个体需求的实现。

Abstract: Forensic mental health care involves the treatment of individuals with severe
mental disorders who have committed violent offences. These settings are often
characterized by high levels of bureaucracy, risk avoidance, and restricted
autonomy. Patients frequently experience a profound loss of control over their
lives, leading to heightened psychological stress-sometimes resulting in
isolation as a safety measure. In this study, we explore how co-design can be
used to collaboratively develop a companion robot that helps monitor and
regulate stress while maintaining tracking of the patients' interaction
behaviours for long-term intervention. We conducted four co-design workshops in
a forensic psychiatric clinic with patients, caregivers, and therapists. Our
process began with the presentation of an initial speculative prototype to
therapists, enabling reflection on shared concerns, ethical risks, and
desirable features. This was followed by a creative ideation session with
patients, a third workshop focused on defining desired functions and emotional
responses, and we are planning a final prototype demo to gather direct patient
feedback. Our findings emphasize the importance of empowering patients in the
design process and adapting proposals based on their current emotional state.
The goal was to empower the patient in the design process and ensure each
patient's voice was heard.

</details>


### [244] [Heterogeneous object manipulation on nonlinear soft surface through linear controller](https://arxiv.org/abs/2507.14967)
*Pratik Ingle,Kasper Støy,Andres Faiña*

Main category: cs.RO

TL;DR: 本论文提出了一种基于PID的线性闭环反馈控制方法，能够无需大规模训练即可实现软体操作表面对多样物体的精准、鲁棒控制。


<details>
  <summary>Details</summary>
Motivation: 高密度致动器阵列的操作表面虽能高自由度地操控物体，但控制及维护复杂，学习法控制又需要大量样本且难泛化，限制了实际应用。

Method: 采用几何变换驱动的PID控制器，将倾斜角度（1D/2D）直接映射为致动器指令，省去繁重的黑箱训练过程。

Result: 通过仿真和物理实验验证了该方法可成功操作不同形状、重量和材质的物体，包括易碎品。

Conclusion: 所提方法通用性强、实用性高，无需大量训练即可可靠控制操作表面，推动柔性机器人操作表面在实际中的应用。

Abstract: Manipulation surfaces indirectly control and reposition objects by actively
modifying their shape or properties rather than directly gripping objects.
These surfaces, equipped with dense actuator arrays, generate dynamic
deformations. However, a high-density actuator array introduces considerable
complexity due to increased degrees of freedom (DOF), complicating control
tasks. High DOF restrict the implementation and utilization of manipulation
surfaces in real-world applications as the maintenance and control of such
systems exponentially increase with array/surface size. Learning-based control
approaches may ease the control complexity, but they require extensive training
samples and struggle to generalize for heterogeneous objects. In this study, we
introduce a simple, precise and robust PID-based linear close-loop feedback
control strategy for heterogeneous object manipulation on MANTA-RAY
(Manipulation with Adaptive Non-rigid Textile Actuation with Reduced Actuation
density). Our approach employs a geometric transformation-driven PID
controller, directly mapping tilt angle control outputs(1D/2D) to actuator
commands to eliminate the need for extensive black-box training. We validate
the proposed method through simulations and experiments on a physical system,
successfully manipulating objects with diverse geometries, weights and
textures, including fragile objects like eggs and apples. The outcomes
demonstrate that our approach is highly generalized and offers a practical and
reliable solution for object manipulation on soft robotic manipulation,
facilitating real-world implementation without prohibitive training demands.

</details>


### [245] [FCRF: Flexible Constructivism Reflection for Long-Horizon Robotic Task Planning with Large Language Models](https://arxiv.org/abs/2507.14975)
*Yufan Song,Jiatao Zhang,Zeng Gu,Qingmiao Liang,Tuocheng Hu,Wei Song,Shiqiang Zhu*

Main category: cs.RO

TL;DR: 本文提出了一种新的自反思框架FCRF，大幅提升了家用机器人在复杂长任务下的自我纠错能力。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在任务规划自反思与纠错方面存在机制僵化、灵活性不足的问题，难以适应复杂任务。以人类认知灵活性为启发，作者希望提升机器人自纠正能力。

Method: 提出了名为FCRF的灵活结构主义反思框架，采用Mentor-Actor架构，使LLMs能根据任务难度灵活自反思，并融合历史经验与失败教训。将其在AlfWorld仿真及实际家庭环境中评估。

Result: 实验表明，FCRF框架能显著提升机器人整体任务表现与自我纠错的灵活性。

Conclusion: FCRF能有效增强机器人在复杂长任务中的自反思和纠错能力，为自主家用机器人提供更可靠执行保障。

Abstract: Autonomous error correction is critical for domestic robots to achieve
reliable execution of complex long-horizon tasks. Prior work has explored
self-reflection in Large Language Models (LLMs) for task planning error
correction; however, existing methods are constrained by inflexible
self-reflection mechanisms that limit their effectiveness. Motivated by these
limitations and inspired by human cognitive adaptation, we propose the Flexible
Constructivism Reflection Framework (FCRF), a novel Mentor-Actor architecture
that enables LLMs to perform flexible self-reflection based on task difficulty,
while constructively integrating historical valuable experience with failure
lessons. We evaluated FCRF on diverse domestic tasks through simulation in
AlfWorld and physical deployment in the real-world environment. Experimental
results demonstrate that FCRF significantly improves overall performance and
self-reflection flexibility in complex long-horizon robotic tasks.

</details>


### [246] [CPED-NCBFs: A Conformal Prediction for Expert Demonstration-based Neural Control Barrier Functions](https://arxiv.org/abs/2507.15022)
*Sumeadh MS,Kevin Dsouza,Ravi Prakash*

Main category: cs.RO

TL;DR: 本文针对神经网络控制障碍函数（NCBFs）安全验证问题，提出了一种基于分裂保形预测（CPED）的新方法，并在点质量系统和单轮模型上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 虽然通过专家示范学习控制障碍函数（CBFs）有助于增强控制系统安全性，但其安全性验证（尤其是神经网络CBFs）依然面临难以在整个状态空间内验证的挑战，现有验证方法存在结果保守、边界松散等问题，因此亟需更精准的验证策略。

Method: 提出了一种基于分裂保形预测的验证方法（CPED-NCBFs），以精确验证从专家示范学习到的神经网络CBFs在全状态空间内的安全性。

Result: 采用所提方法在点质量系统和单轮车模型上进行了实验，展示了其理论和方法的有效性。

Conclusion: CPED-NCBFs在验证神经网络CBFs安全性方面比传统方法具备优势，有助于缓解现有验证方法的保守性和边界松散问题。

Abstract: Among the promising approaches to enforce safety in control systems, learning
Control Barrier Functions (CBFs) from expert demonstrations has emerged as an
effective strategy. However, a critical challenge remains: verifying that the
learned CBFs truly enforce safety across the entire state space. This is
especially difficult when CBF is represented using neural networks (NCBFs).
Several existing verification techniques attempt to address this problem
including SMT-based solvers, mixed-integer programming (MIP), and interval or
bound-propagation methods but these approaches often introduce loose,
conservative bounds. To overcome these limitations, in this work we use
CPED-NCBFs a split-conformal prediction based verification strategy to verify
the learned NCBF from the expert demonstrations. We further validate our method
on point mass systems and unicycle models to demonstrate the effectiveness of
the proposed theory.

</details>


### [247] [Touch in the Wild: Learning Fine-Grained Manipulation with a Portable Visuo-Tactile Gripper](https://arxiv.org/abs/2507.15062)
*Xinyue Zhu,Binghao Huang,Yunzhu Li*

Main category: cs.RO

TL;DR: 本文提出了一种集成视觉与触觉传感器的便携手持式夹爪，并提出了一种跨模态表征学习框架，用于支持更精确高效的机器人操作学习。这种方法在细粒度操作任务中展现了更高的准确性和健壮性。


<details>
  <summary>Details</summary>
Motivation: 现有手持夹爪在采集人类操作演示时缺乏触觉感知，影响了精确操作能力，而触觉反馈对于精细操作尤为重要。因此，亟需设计带有触觉传感能力的便携夹爪，并融合视觉和触觉数据，提升下游操作任务的表现。

Method: 作者研制了一款便携且轻量化的带触觉传感器的夹爪，实现视觉与触觉数据同步采集。基于该硬件，提出了一套跨模态表征学习框架，融合但区分视觉和触觉信号，促使网络自主发现对物理交互重要的接触区域。通过利用这种联表征进行策略学习，用以提升机器人操作的精度和效率。

Result: 通过在诸如试管插入、移液等精细操作实验中验证，该方法在存在外部扰动的情况下，仍然显著提升了操作的准确性与鲁棒性。

Conclusion: 集成视觉-触觉多模态反馈和自监督学习的表征能够有效提升机器人精密操作能力。所提出的硬件和学习框架为各类真实环境下的机器人操作学习带来新的提升机会。

Abstract: Handheld grippers are increasingly used to collect human demonstrations due
to their ease of deployment and versatility. However, most existing designs
lack tactile sensing, despite the critical role of tactile feedback in precise
manipulation. We present a portable, lightweight gripper with integrated
tactile sensors that enables synchronized collection of visual and tactile data
in diverse, real-world, and in-the-wild settings. Building on this hardware, we
propose a cross-modal representation learning framework that integrates visual
and tactile signals while preserving their distinct characteristics. The
learning procedure allows the emergence of interpretable representations that
consistently focus on contacting regions relevant for physical interactions.
When used for downstream manipulation tasks, these representations enable more
efficient and effective policy learning, supporting precise robotic
manipulation based on multimodal feedback. We validate our approach on
fine-grained tasks such as test tube insertion and pipette-based fluid
transfer, demonstrating improved accuracy and robustness under external
disturbances. Our project page is available at
https://binghao-huang.github.io/touch_in_the_wild/ .

</details>


### [248] [Search-Based Autonomous Vehicle Motion Planning Using Game Theory](https://arxiv.org/abs/2507.15088)
*Pouya Panahandeh,Mohammad Pirani,Baris Fidan,Amir Khajepour*

Main category: cs.RO

TL;DR: 本论文提出一种基于博弈论的搜索型交互式自动驾驶车辆运动规划方法，通过将其他道路使用者（如司机和行人）视作智能体，实现更真实的路径规划。方法运行效率高，适合实时应用，并在自动驾驶汽车上进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 传统运动规划方法通常将其他道路使用者只看作静态障碍物，无法反映其实际智能行为，导致规划结果不够真实，因此亟需考虑其他道路使用者智能行为的运动规划方法。

Method: 本文采用博弈论思想，将道路上的其他车辆和行人建模为智能体，与自动驾驶车辆形成交互式决策，通过搜索策略综合考虑各方行为，实时生成更合理的运动路径。

Result: 实验在电动全气候自动驾驶巴士WATonoBus上进行，结果显示该方法优于传统运动规划方法，能生成更具现实感的路径，并具备实时性能。

Conclusion: 所提基于博弈论的搜索式交互运动规划方法能有效提升自动驾驶车辆运动路径的合理性和交互性，且具有良好的实时性，适用于实际应用。

Abstract: In this paper, we propose a search-based interactive motion planning scheme
for autonomous vehicles (AVs), using a game-theoretic approach. In contrast to
traditional search-based approaches, the newly developed approach considers
other road users (e.g. drivers and pedestrians) as intelligent agents rather
than static obstacles. This leads to the generation of a more realistic path
for the AV. Due to the low computational time, the proposed motion planning
scheme is implementable in real-time applications. The performance of the
developed motion planning scheme is compared with existing motion planning
techniques and validated through experiments using WATonoBus, an electrical
all-weather autonomous shuttle bus.

</details>


### [249] [Learning-Based Modeling of a Magnetically Steerable Soft Suction Device for Endoscopic Endonasal Interventions](https://arxiv.org/abs/2507.15155)
*Majid Roshanfar,Alex Zhang,Changyan He,Amir Hooshiar,Dale J. Podolsky,Thomas Looi,Eric Diller*

Main category: cs.RO

TL;DR: 本文提出了一种基于机器学习的磁控软体吸引装置建模方法，用于经内镜鼻入路脑肿瘤切除手术，通过数据驱动模型实现亚毫米级的实时形状预测。


<details>
  <summary>Details</summary>
Motivation: 现有软体机器人结构复杂、力学建模非线性强，且依赖大量物理假设，无法精确实现复杂手术场景中的实时精准控制，尤其是在脑部微创手术等高精度应用中，急需高效、精确的形状预测方法。

Method: 设计并3D打印了嵌入FBG传感器的微型磁控软体吸引装置，通过采集丰富的实验数据（不同磁场、频率、距离组合），将装置变形过程用贝塞尔曲线控制点描述，利用神经网络和随机森林方法建立数据驱动模型，分析特征重要性并评估模型性能。

Result: 随机森林模型相比神经网络在所有评估指标上表现更佳，控制点平均均方根误差仅0.087 mm，形状重建平均误差0.064 mm，实现了亚毫米级高精度实时形状预测。特征分析显示磁场对远端影响大，频率与距离主要作用于基部形态。

Conclusion: 此方法无需简化传统物理模型，即可高效模拟磁控超弹性软体机器人的复杂非线性行为，为脑部微创手术磁控软体机器人智能精细控制迈进一步，具备临床应用潜力。

Abstract: This letter introduces a novel learning-based modeling framework for a
magnetically steerable soft suction device designed for endoscopic endonasal
brain tumor resection. The device is miniaturized (4 mm outer diameter, 2 mm
inner diameter, 40 mm length), 3D printed using biocompatible SIL 30 material,
and integrates embedded Fiber Bragg Grating (FBG) sensors for real-time shape
feedback. Shape reconstruction is represented using four Bezier control points,
enabling a compact and smooth model of the device's deformation. A data-driven
model was trained on 5,097 experimental samples covering a range of magnetic
field magnitudes (0-14 mT), actuation frequencies (0.2-1.0 Hz), and vertical
tip distances (90-100 mm), using both Neural Network (NN) and Random Forest
(RF) architectures. The RF model outperformed the NN across all metrics,
achieving a mean root mean square error of 0.087 mm in control point prediction
and a mean shape reconstruction error of 0.064 mm. Feature importance analysis
further revealed that magnetic field components predominantly influence distal
control points, while frequency and distance affect the base configuration.
This learning-based approach effectively models the complex nonlinear behavior
of hyperelastic soft robots under magnetic actuation without relying on
simplified physical assumptions. By enabling sub-millimeter shape prediction
accuracy and real-time inference, this work represents an advancement toward
the intelligent control of magnetically actuated soft robotic tools in
minimally invasive neurosurgery.

</details>


### [250] [CHADET: Cross-Hierarchical-Attention for Depth-Completion Using Unsupervised Lightweight Transformer](https://arxiv.org/abs/2507.15189)
*Kevin Christiansen Marsim,Jinwoo Jeon,Yeeun Kim,Myeongwoo Jeong,Hyun Myung*

Main category: cs.RO

TL;DR: 本文提出了一种高效准确的深度补全网络CHADET，可用于机器人导航等实时任务，在KITTI、NYUv2和VOID数据集上验证效果优异。


<details>
  <summary>Details</summary>
Motivation: 现有深度补全方法在速度和准确度上存在显著权衡，内存与计算需求大，难以满足机器人实时任务需求，因此亟需在提升深度信息完整性和准确度的同时，提升处理速度。

Method: 提出了一种轻量级的深度补全网络CHADET，输入为RGB图像和稀疏深度点。网络采用分层深度特征提取，并将特征送入轻量级基于Transformer的解码器，创新性地加入交叉层次注意力模块，以优化图像特征与深度信息的融合。

Result: 在KITTI、NYUv2和VOID数据集上进行实验，所提方法提升了深度图预测的质量，并显著降低了内存使用，证明了其高效性和优异表现。

Conclusion: CHADET实现了更好精度与计算效率的平衡，适用于需要高性能的机器人实时任务，对深度补全领域具有实际应用和推广价值。

Abstract: Depth information which specifies the distance between objects and current
position of the robot is essential for many robot tasks such as navigation.
Recently, researchers have proposed depth completion frameworks to provide
dense depth maps that offer comprehensive information about the surrounding
environment. However, existing methods show significant trade-offs between
computational efficiency and accuracy during inference. The substantial memory
and computational requirements make them unsuitable for real-time applications,
highlighting the need to improve the completeness and accuracy of depth
information while improving processing speed to enhance robot performance in
various tasks. To address these challenges, in this paper, we propose
CHADET(cross-hierarchical-attention depth-completion transformer), a
lightweight depth-completion network that can generate accurate dense depth
maps from RGB images and sparse depth points. For each pair, its feature is
extracted from the depthwise blocks and passed to the equally lightweight
transformer-based decoder. In the decoder, we utilize the novel
cross-hierarchical-attention module that refines the image features from the
depth information. Our approach improves the quality and reduces memory usage
of the depth map prediction, as validated in both KITTI, NYUv2, and VOID
datasets.

</details>


### [251] [VLM-UDMC: VLM-Enhanced Unified Decision-Making and Motion Control for Urban Autonomous Driving](https://arxiv.org/abs/2507.15266)
*Haichao Liu,Haoren Guo,Pei Liu,Benshan Ma,Yuxiang Zhang,Jun Ma,Tong Heng Lee*

Main category: cs.RO

TL;DR: 本文提出了一种增强视觉-语言模型（VLM）的统一决策与运动控制框架（VLM-UDMC），提升城市自动驾驶中的场景理解和风险感知能力。通过结合慢系统的场景分析以及快系统的实时规划，有效提高了决策的透明性与鲁棒性。实验证明该方法在仿真与真实车辆中均显著提升驾驶表现。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶需要像人类司机一样具备场景理解和风险感知能力，但传统方法在透明性、可解释性和动态响应方面存在不足，因此需要一种融合多模态感知和知识检索的新框架来提升决策合理性。

Method: 提出VLM-UDMC框架，将场景推理与风险感知集成到上层慢系统中，并实时重构下游快系统的轨迹规划。慢系统采用两步推理策略（RAG），利用基础模型处理多模态输入与上下文知识检索，生成风险感知洞见；同时，轻量LSTM结构用于异构交通体的实时短时轨迹预测。

Result: 在仿真和真实车辆实验验证下，VLM-UDMC能够有效利用场景理解和注意力分解，实现更理性的驾驶决策，显著提升了城市道路自动驾驶性能。

Conclusion: VLM-UDMC框架通过结合视觉-语言模型、检索增强生成与多核LSTM预测，提升了自动驾驶系统的理解、透明性与决策质量，为城市自动驾驶场景下的安全高效驾驶提供了有力技术支撑。

Abstract: Scene understanding and risk-aware attentions are crucial for human drivers
to make safe and effective driving decisions. To imitate this cognitive ability
in urban autonomous driving while ensuring the transparency and
interpretability, we propose a vision-language model (VLM)-enhanced unified
decision-making and motion control framework, named VLM-UDMC. This framework
incorporates scene reasoning and risk-aware insights into an upper-level slow
system, which dynamically reconfigures the optimal motion planning for the
downstream fast system. The reconfiguration is based on real-time environmental
changes, which are encoded through context-aware potential functions. More
specifically, the upper-level slow system employs a two-step reasoning policy
with Retrieval-Augmented Generation (RAG), leveraging foundation models to
process multimodal inputs and retrieve contextual knowledge, thereby generating
risk-aware insights. Meanwhile, a lightweight multi-kernel decomposed LSTM
provides real-time trajectory predictions for heterogeneous traffic
participants by extracting smoother trend representations for short-horizon
trajectory prediction. The effectiveness of the proposed VLM-UDMC framework is
verified via both simulations and real-world experiments with a full-size
autonomous vehicle. It is demonstrated that the presented VLM-UDMC effectively
leverages scene understanding and attention decomposition for rational driving
decisions, thus improving the overall urban driving performance. Our
open-source project is available at https://github.com/henryhcliu/vlmudmc.git.

</details>


### [252] [RepILN: Reparameterized Inertial Localization Network](https://arxiv.org/abs/2507.15293)
*Shanshan Zhang,Tianshui Wen,Siyue Wang,Qi Zhang,Ziheng Zhou,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 本文提出了一种优化的惯性定位神经网络结构，在保持高定位精度的前提下大幅减小模型体积，适用于计算资源有限的消费级物联网设备。


<details>
  <summary>Details</summary>
Motivation: 惯性定位因其无需依赖外部基础设施和成本低，成为物联网设备定位的有前景选择。但现有数据驱动方法为提升精度，网络结构日益复杂，超出了消费级设备能承受的计算量。此外，这些方法常忽略了对惯性测量数据长期依赖性的建模，影响轨迹还原的准确性。

Method: 提出了一种再参数化的多分支惯性定位网络，训练时采用多分支增强特征提取，推理时转换为等效的单路径结构，实现高效参数利用。引入时间尺度稀疏注意力机制关注关键轨迹片段，抑制噪声，并用门控卷积单元融合长程依赖与局部特征。

Result: 在公开基准数据集上的实验证明，该方法在精度与模型紧凑性之间实现了优良折中。例如，在RoNIN数据集上，相较于RoNIN-ResNet，绝对轨迹误差下降了2.59%，参数量减少了3.86%。

Conclusion: 该方法有效地提升了惯性定位神经网络的实用性，兼顾了对IoT设备资源的友好性和定位性能，具有较强的工程应用潜力。

Abstract: Inertial localization is regarded as a promising positioning solution for
consumer-grade IoT devices due to its cost-effectiveness and independence from
external infrastructure. However, data-driven inertial localization methods
often rely on increasingly complex network architectures to improve accuracy,
which challenges the limited computational resources of IoT devices. Moreover,
these methods frequently overlook the importance of modeling long-term
dependencies in inertial measurements - a critical factor for accurate
trajectory reconstruction - thereby limiting localization performance. To
address these challenges, we propose a reparameterized inertial localization
network that uses a multi-branch structure during training to enhance feature
extraction. At inference time, this structure is transformed into an equivalent
single-path architecture to improve parameter efficiency. To further capture
long-term dependencies in motion trajectories, we introduce a temporal-scale
sparse attention mechanism that selectively emphasizes key trajectory segments
while suppressing noise. Additionally, a gated convolutional unit is
incorporated to effectively integrate long-range dependencies with local
fine-grained features. Extensive experiments on public benchmarks demonstrate
that our method achieves a favorable trade-off between accuracy and model
compactness. For example, on the RoNIN dataset, our approach reduces the
Absolute Trajectory Error (ATE) by 2.59% compared to RoNIN-ResNet while
reducing the number of parameters by 3.86%.

</details>


### [253] [Low-Latency Event-Based Velocimetry for Quadrotor Control in a Narrow Pipe](https://arxiv.org/abs/2507.15444)
*Leonard Bauersfeld,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 本文提出了一种四旋翼无人机在狭窄管道中实现稳定悬停的闭环控制系统，利用实时气流测量信息，有效对抗了不稳定的自激气动干扰。


<details>
  <summary>Details</summary>
Motivation: 现有技术在无人机管道飞行中，需通过持续运动减小气流环流带来的影响，或在悬停时稳定性不足。如何实现无人机在狭窄空间（如管道、隧道）内稳定悬停，是挑战性问题。

Method: 提出了一种低延迟基于事件的烟雾速度计方法，实时高频率地估算局部气流。用基于循环卷积神经网络的干扰估算器实时推理力和力矩扰动，并将其集成到通过强化学习训练的基于学习的控制器中。

Result: 实时气流反馈显著提升了无人机横向移动时对气动瞬态效应的补偿能力，防止了与管壁碰撞。首次实现了利用实时气流测量的空中机器人闭环控制系统。

Conclusion: 本研究为无人机在复杂气动环境中飞行提供了新思路，并揭示了狭窄圆形管道飞行时的典型气流结构，为机器人和流体动力学交界领域带来新的见解。

Abstract: Autonomous quadrotor flight in confined spaces such as pipes and tunnels
presents significant challenges due to unsteady, self-induced aerodynamic
disturbances. Very recent advances have enabled flight in such conditions, but
they either rely on constant motion through the pipe to mitigate airflow
recirculation effects or suffer from limited stability during hovering. In this
work, we present the first closed-loop control system for quadrotors for
hovering in narrow pipes that leverages real-time flow field measurements. We
develop a low-latency, event-based smoke velocimetry method that estimates
local airflow at high temporal resolution. This flow information is used by a
disturbance estimator based on a recurrent convolutional neural network, which
infers force and torque disturbances in real time. The estimated disturbances
are integrated into a learning-based controller trained via reinforcement
learning. The flow-feedback control proves particularly effective during
lateral translation maneuvers in the pipe cross-section. There, the real-time
disturbance information enables the controller to effectively counteract
transient aerodynamic effects, thereby preventing collisions with the pipe
wall. To the best of our knowledge, this work represents the first
demonstration of an aerial robot with closed-loop control informed by real-time
flow field measurements. This opens new directions for research on flight in
aerodynamically complex environments. In addition, our work also sheds light on
the characteristic flow structures that emerge during flight in narrow,
circular pipes, providing new insights at the intersection of robotics and
fluid dynamics.

</details>


### [254] [The Emergence of Deep Reinforcement Learning for Path Planning](https://arxiv.org/abs/2507.15469)
*Thanh Thi Nguyen,Saeid Nahavandi,Imran Razzak,Dung Nguyen,Nhat Truong Pham,Quoc Viet Hung Nguyen*

Main category: cs.RO

TL;DR: 本文综述了自主系统路径规划领域的传统方法和深度强化学习（DRL）的最新进展，分析了主要算法、实际应用、优势与不足，并指明未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着自主系统在复杂动态环境中的需求增长，现有的路径规划方法已难以满足日益增长的智能化与适应性要求，因此需要对传统方法与新兴的深度强化学习技术进行系统梳理与对比。

Method: 通过分类方式整理和分析了图搜索、线性规划、进化算法等传统路径规划方法与近年来深度强化学习应用在自主车辆、无人机与机器人上的代表性工作，重点突出各技术的创新点与实际实现，并对其计算效率、可扩展性、适应性和鲁棒性进行对比讨论。

Result: 系统归纳了传统与基于学习的路径规划方法在实际应用中的表现与局限，特别分析了混合方法（将DRL与传统规划技术相结合）在提升自主导航的鲁棒性与适应性方面展现的潜力。

Conclusion: 尽管深度强化学习为路径规划带来了显著进展，但仍面临如计算代价高、泛化能力不足等挑战。未来混合型方法以及理论与实际结合的研究是提升自主系统导航能力的重要方向。

Abstract: The increasing demand for autonomous systems in complex and dynamic
environments has driven significant research into intelligent path planning
methodologies. For decades, graph-based search algorithms, linear programming
techniques, and evolutionary computation methods have served as foundational
approaches in this domain. Recently, deep reinforcement learning (DRL) has
emerged as a powerful method for enabling autonomous agents to learn optimal
navigation strategies through interaction with their environments. This survey
provides a comprehensive overview of traditional approaches as well as the
recent advancements in DRL applied to path planning tasks, focusing on
autonomous vehicles, drones, and robotic platforms. Key algorithms across both
conventional and learning-based paradigms are categorized, with their
innovations and practical implementations highlighted. This is followed by a
thorough discussion of their respective strengths and limitations in terms of
computational efficiency, scalability, adaptability, and robustness. The survey
concludes by identifying key open challenges and outlining promising avenues
for future research. Special attention is given to hybrid approaches that
integrate DRL with classical planning techniques to leverage the benefits of
both learning-based adaptability and deterministic reliability, offering
promising directions for robust and resilient autonomous navigation.

</details>


### [255] [All-UWB SLAM Using UWB Radar and UWB AOA](https://arxiv.org/abs/2507.15474)
*Charith Premachandra,Achala Athukorala,U-Xuan Tan*

Main category: cs.RO

TL;DR: 本文提出了一种结合UWB雷达与角度测量(AOA)的新型SLAM方法，可在视觉受限和环境特征缺乏的情况下实现定位与地图构建。


<details>
  <summary>Details</summary>
Motivation: 传统的视觉或光学传感器在烟雾、粉尘等恶劣环境下容易失效，而UWB雷达能穿透这些环境限制，但现有方法在特征稀少区域表现较差。

Method: 提出利用UWB雷达与自部署的UWB锚点标签单元收集AOA测量，动态在特征稀少区域布设锚点，以提升SLAM性能，并针对AOA测量面临的问题给出解决方案。

Result: 实验结果表明，UWB雷达结合AOA测量单元后，能够在视觉受限且缺乏环境特征的场景下实现SLAM。

Conclusion: 该方法有效突破了传统SLAM受限于环境特征密度的问题，为恶劣环境下的自主系统定位和地图构建提供了新思路。

Abstract: There has been a growing interest in autonomous systems designed to operate
in adverse conditions (e.g. smoke, dust), where the visible light spectrum
fails. In this context, Ultra-wideband (UWB) radar is capable of penetrating
through such challenging environmental conditions due to the lower frequency
components within its broad bandwidth. Therefore, UWB radar has emerged as a
potential sensing technology for Simultaneous Localization and Mapping (SLAM)
in vision-denied environments where optical sensors (e.g. LiDAR, Camera) are
prone to failure. Existing approaches involving UWB radar as the primary
exteroceptive sensor generally extract features in the environment, which are
later initialized as landmarks in a map. However, these methods are constrained
by the number of distinguishable features in the environment. Hence, this paper
proposes a novel method incorporating UWB Angle of Arrival (AOA) measurements
into UWB radar-based SLAM systems to improve the accuracy and scalability of
SLAM in feature-deficient environments. The AOA measurements are obtained using
UWB anchor-tag units which are dynamically deployed by the robot in featureless
areas during mapping of the environment. This paper thoroughly discusses
prevailing constraints associated with UWB AOA measurement units and presents
solutions to overcome them. Our experimental results show that integrating UWB
AOA units with UWB radar enables SLAM in vision-denied feature-deficient
environments.

</details>


### [256] [The Constitutional Controller: Doubt-Calibrated Steering of Compliant Agents](https://arxiv.org/abs/2507.15478)
*Simon Kohaut,Felix Divo,Navid Hamid,Benedict Flade,Julian Eggert,Devendra Singh Dhami,Kristian Kersting*

Main category: cs.RO

TL;DR: 本文提出了一种神经符号系统（CoCo），将符号推理与深度学习集成，以提升自主智能体在不确定环境中的可靠性和合规性。


<details>
  <summary>Details</summary>
Motivation: 自主智能体在面对不确定环境时，如何保证行为既可靠又符合规则，是当前机器人领域的核心难题。传统方法在处理规则约束和复杂环境适应性之间存在权衡。

Method: 作者提出了Constitutional Controller (CoCo) 框架，将概率逻辑推理模型与深度学习结合，实现对规则约束和感知噪声数据的同时处理。框架中还引入了“自我怀疑”机制，通过条件概率密度函数，对速度、传感器状态、健康等特征的不确定性进行建模和量化。

Result: 通过实际的空中交通案例，实验证明CoCo能够使自主体学会合理怀疑，在复杂不确定环境下实现更安全、合规的导航。

Conclusion: 神经符号系统（如CoCo）有潜力成为提升自主系统安全性和合规性的有效方法，能结合结构化推理与深度表征优势，未来可广泛应用于多种不确定环境下的自主体控制。

Abstract: Ensuring reliable and rule-compliant behavior of autonomous agents in
uncertain environments remains a fundamental challenge in modern robotics. Our
work shows how neuro-symbolic systems, which integrate probabilistic, symbolic
white-box reasoning models with deep learning methods, offer a powerful
solution to this challenge. This enables the simultaneous consideration of
explicit rules and neural models trained on noisy data, combining the strength
of structured reasoning with flexible representations. To this end, we
introduce the Constitutional Controller (CoCo), a novel framework designed to
enhance the safety and reliability of agents by reasoning over deep
probabilistic logic programs representing constraints such as those found in
shared traffic spaces. Furthermore, we propose the concept of self-doubt,
implemented as a probability density conditioned on doubt features such as
travel velocity, employed sensors, or health factors. In a real-world aerial
mobility study, we demonstrate CoCo's advantages for intelligent autonomous
systems to learn appropriate doubts and navigate complex and uncertain
environments safely and compliantly.

</details>


### [257] [Robots for Kiwifruit Harvesting and Pollination](https://arxiv.org/abs/2507.15484)
*Jamie Bell*

Main category: cs.RO

TL;DR: 本文介绍了一项在棚架奇异果果园中开发移动机器人进行定点授粉与自动采收的研究，包括设计新的果实分离机构和基于激光雷达/视觉的导航技术。该系统在田间测试取得了突破性的性能。


<details>
  <summary>Details</summary>
Motivation: 由于奇异果棚架果园结构复杂，传统自动采收和授粉技术受限，采摘和授粉效率低，本项目旨在突破环境复杂性带来的自动化挑战，提高作业效率和果品品质。

Method: 设计了多种奇异果分离机构，并对其中一种进行了实地测试；开发了基于视觉与3D激光雷达的花朵检测与授粉喷洒装置，实时调整喷雾高度以避免碰撞。导航部分提出多种3D激光雷达特征提取与视觉行检测算法，实现果园自动驾驶超过30km测试。

Result: 新分离机构可采摘超80%的果实，优于70%以下的现有方案；授粉系统可边行驶边高效喷洒；3D激光雷达与视觉行识别导航均稳定有效，能实现长距离自主作业。

Conclusion: 本研究证明了集成先进分离机构及导航感知技术的移动机器人可在棚架奇异果果园实现高效率自动采收与授粉，有望推动果园自动化管理发展。

Abstract: This research was a part of a project that developed mobile robots that
performed targeted pollen spraying and automated harvesting in pergola
structured kiwifruit orchards. Multiple kiwifruit detachment mechanisms were
designed and field testing of one of the concepts showed that the mechanism
could reliably pick kiwifruit. Furthermore, this kiwifruit detachment mechanism
was able to reach over 80 percent of fruit in the cluttered kiwifruit canopy,
whereas the previous state of the art mechanism was only able to reach less
than 70 percent of the fruit. Artificial pollination was performed by detecting
flowers and then spraying pollen in solution onto the detected flowers from a
line of sprayers on a boom, while driving at up to 1.4 ms-1. In addition, the
height of the canopy was measured and the spray boom was moved up and down to
keep the boom close enough to the flowers for the spray to reach the flowers,
while minimising collisions with the canopy. Mobile robot navigation was
performed using a 2D lidar in apple orchards and vineyards. Lidar navigation in
kiwifruit orchards was more challenging because the pergola structure only
provides a small amount of data for the direction of rows, compared to the
amount of data from the overhead canopy, the undulating ground and other
objects in the orchards. Multiple methods are presented here for extracting
structure defining features from 3D lidar data in kiwifruit orchards. In
addition, a 3D lidar navigation system -- which performed row following, row
end detection and row end turns -- was tested for over 30 km of autonomous
driving in kiwifruit orchards. Computer vision algorithms for row detection and
row following were also tested. The computer vision algorithm worked as well as
the 3D lidar row following method in testing.

</details>


### [258] [GR-3 Technical Report](https://arxiv.org/abs/2507.15493)
*Chilam Cheang,Sijin Chen,Zhongren Cui,Yingdong Hu,Liqun Huang,Tao Kong,Hang Li,Yifeng Li,Yuxiao Liu,Xiao Ma,Hao Niu,Wenxuan Ou,Wanli Peng,Zeyu Ren,Haixin Shi,Jiawen Tian,Hongtao Wu,Xin Xiao,Yuyang Xiao,Jiafeng Xu,Yichu Yang*

Main category: cs.RO

TL;DR: 本文介绍了GR-3，这是一种大型视觉-语言-动作模型，能够在新颖物体、环境和抽象指令下表现出色泛化能力，还能高效微调适应新场景，在长时序和高难度任务中展现强大性能。


<details>
  <summary>Details</summary>
Motivation: 机器人要真正服务人类，需具备泛化能力，即应对各种新任务、环境和指令的能力。现有方法在适应性和任务复杂度上存在局限，亟需更通用的解决方案。

Method: 作者提出GR-3，通过WEB级视觉-语言数据协同训练，结合VR设备收集的人类轨迹高效微调，以及机器人轨迹的模仿学习。此外，引入支持双手操作和移动的ByteMini机器人，并与GR-3结合。

Result: GR-3在大量真实世界实验中显著超越当前主流基线方法π₀，特别是在高难度和多样化任务上表现突出。

Conclusion: GR-3作为通用机器人策略实现了一大步，能够更好地适应和协助日常人类生活任务，为未来通用机器人进一步发展打下基础。

Abstract: We report our recent progress towards building generalist robot policies, the
development of GR-3. GR-3 is a large-scale vision-language-action (VLA) model.
It showcases exceptional capabilities in generalizing to novel objects,
environments, and instructions involving abstract concepts. Furthermore, it can
be efficiently fine-tuned with minimal human trajectory data, enabling rapid
and cost-effective adaptation to new settings. GR-3 also excels in handling
long-horizon and dexterous tasks, including those requiring bi-manual
manipulation and mobile movement, showcasing robust and reliable performance.
These capabilities are achieved through a multi-faceted training recipe that
includes co-training with web-scale vision-language data, efficient fine-tuning
from human trajectory data collected via VR devices, and effective imitation
learning with robot trajectory data. In addition, we introduce ByteMini, a
versatile bi-manual mobile robot designed with exceptional flexibility and
reliability, capable of accomplishing a wide range of tasks when integrated
with GR-3. Through extensive real-world experiments, we show GR-3 surpasses the
state-of-the-art baseline method, $\pi_0$, on a wide variety of challenging
tasks. We hope GR-3 can serve as a step towards building generalist robots
capable of assisting humans in daily life.

</details>


### [259] [CLEVER: Stream-based Active Learning for Robust Semantic Perception from Human Instructions](https://arxiv.org/abs/2507.15499)
*Jongseok Lee,Timo Birr,Rudolph Triebel,Tamim Asfour*

Main category: cs.RO

TL;DR: 本论文提出了CLEVER系统，实现了基于主动学习的DNN语义感知，能够应对数据流场景下的失败并进行在线自适应。通过设计贝叶斯方法结合领域先验，该系统在真实机器人上提升了感知鲁棒性，并经过实验和用户验证。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在语义感知任务中虽有强大表现，但其鲁棒性和适应性在面对不断变化且流式到来的数据场景下仍有不足。传统DNN难以及时响应新场景或异常，因而需要引入一种能主动请求人类帮助并在线适应的新方法。

Method: 作者提出主动学习系统CLEVER。其核心是流式数据场景下，当DNN遇到失败样本时主动请求人类干预，并根据人的指导对模型进行在线、自适应地优化。创新性地采用贝叶斯建模以先验方式注入领域知识，实现更高效的学习。

Result: 系统已实现在实际的机器人平台（包括类人形和可变形物体实验上），并通过用户实验验证性能，结果表明CLEVER有效提升了DNN在实际环境下的语义感知稳健性。

Conclusion: CLEVER首次实现在真实机器人上的流式主动学习，实验验证了系统能在实际中显著提升DNN感知鲁棒性，为智能机器人自适应语义感知提供了新路径。

Abstract: We propose CLEVER, an active learning system for robust semantic perception
with Deep Neural Networks (DNNs). For data arriving in streams, our system
seeks human support when encountering failures and adapts DNNs online based on
human instructions. In this way, CLEVER can eventually accomplish the given
semantic perception tasks. Our main contribution is the design of a system that
meets several desiderata of realizing the aforementioned capabilities. The key
enabler herein is our Bayesian formulation that encodes domain knowledge
through priors. Empirically, we not only motivate CLEVER's design but further
demonstrate its capabilities with a user validation study as well as
experiments on humanoid and deformable objects. To our knowledge, we are the
first to realize stream-based active learning on a real robot, providing
evidence that the robustness of the DNN-based semantic perception can be
improved in practice. The project website can be accessed at
https://sites.google.com/view/thecleversystem.

</details>


### [260] [Estimation of Payload Inertial Parameters from Human Demonstrations by Hand Guiding](https://arxiv.org/abs/2507.15604)
*Johannes Hartwig,Philipp Lienhardt,Dominik Henrich*

Main category: cs.RO

TL;DR: 本文提出了一种在协作机器人（cobots）手动引导编程过程中，无需专门校准工具负载惯性参数（PIP）即可完成任务的方法，帮助缺乏编程知识的用户更高效地操作机器人。


<details>
  <summary>Details</summary>
Motivation: 随着协作机器人普及，越来越多非编程专业用户需要对机器人进行编程，现有方法在涉及机器人与环境接触时，通常需要负载惯性参数（PIP）的量化和校准，该过程对普通用户而言复杂且效率低。论文旨在简化和便捷化此流程。

Method: 采用在手动示教过程中，当任务演示中存在与环境非接触的运动段时，对这些运动段采集数据，利用既有参数估计算法来估算负载的惯性参数（PIP），从而免去单独的PIP校准步骤。

Result: 实验表明，通过非接触运动段可以准确地估计负载质量，但质心和惯性张量的估计结果受噪音和激励不足影响较大。整体上，方法证明是可行的，但需要保证负载存在足够的加速度以提升精度。

Conclusion: 该方法能够实现在手动引导时自动估算机器人工具负载的惯性参数，提升了灵活性和操作便捷性，适合非专业编程用户。不过，准确估算仍然依赖于合理的运动激励，特别是在质心和惯性张量参数上。

Abstract: As the availability of cobots increases, it is essential to address the needs
of users with little to no programming knowledge to operate such systems
efficiently. Programming concepts often use intuitive interaction modalities,
such as hand guiding, to address this. When programming in-contact motions,
such frameworks require knowledge of the robot tool's payload inertial
parameters (PIP) in addition to the demonstrated velocities and forces to
ensure effective hybrid motion-force control. This paper aims to enable
non-expert users to program in-contact motions more efficiently by eliminating
the need for a dedicated PIP calibration, thereby enabling flexible robot tool
changes. Since demonstrated tasks generally also contain motions with
non-contact, our approach uses these parts to estimate the robot's PIP using
established estimation techniques. The results show that the estimation of the
payload's mass is accurate, whereas the center of mass and the inertia tensor
are affected by noise and a lack of excitation. Overall, these findings show
the feasibility of PIP estimation during hand guiding but also highlight the
need for sufficient payload accelerations for an accurate estimation.

</details>


### [261] [A Universal Vehicle-Trailer Navigation System with Neural Kinematics and Online Residual Learning](https://arxiv.org/abs/2507.15607)
*Yanbo Chen,Yunzhe Tan,Yaojia Wang,Zhengzhe Xu,Junbo Tan,Xueqian Wang*

Main category: cs.RO

TL;DR: 本文提出了一种普适性的车辆-拖车自主导航系统，通过混合动力学模型和在线残差学习实现更准确和可靠的导航控制，并在多类型拖车和不同载重实验证明了鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前车辆-拖车系统在一些实际场景（如机场、超市、演出场地）中的自主导航需求大，但由于拖车类型及载荷的多样性，尤其是带摆轮拖车，精确建模十分困难，限制了自动化水平。因此，开发对不同拖车类型均通用的导航系统成为研究动机。

Method: 本文提出一种混合名义动力学模型，该模型结合了车辆的经典非完整约束和基于神经网络的拖车动力学，同时设计了轻量级的在线残差学习模块，用以实时修正建模误差和外部扰动。此外，构建了具有加权模型组合策略的模型预测控制框架，以提升长期预测的精度及导航安全性。

Result: 所提出方法在实际环境下进行了大量实验，测试涵盖多种类型的拖车和不同的载重条件。实验结果表明，该系统在无需人工调参和拖车特定标定的情况下，能够实现鲁棒、可靠的导航控制。

Conclusion: 该研究展示了一种无需繁琐人工标定、可适配多类型拖车系统的通用导航解决方案，为相关实际应用提供了自动化和高鲁棒性的技术支撑。

Abstract: Autonomous navigation of vehicle-trailer systems is crucial in environments
like airports, supermarkets, and concert venues, where various types of
trailers are needed to navigate with different payloads and conditions.
However, accurately modeling such systems remains challenging, especially for
trailers with castor wheels. In this work, we propose a novel universal
vehicle-trailer navigation system that integrates a hybrid nominal kinematic
model--combining classical nonholonomic constraints for vehicles and neural
network-based trailer kinematics--with a lightweight online residual learning
module to correct real-time modeling discrepancies and disturbances.
Additionally, we develop a model predictive control framework with a weighted
model combination strategy that improves long-horizon prediction accuracy and
ensures safer motion planning. Our approach is validated through extensive
real-world experiments involving multiple trailer types and varying payload
conditions, demonstrating robust performance without manual tuning or
trailer-specific calibration.

</details>


### [262] [Optimizing Force Signals from Human Demonstrations of In-Contact Motions](https://arxiv.org/abs/2507.15608)
*Johannes Hartwig,Fabian Viessmann,Dominik Henrich*

Main category: cs.RO

TL;DR: 本文针对机器人编程非专家，提出了通过优化演示中的力信号以更好反映人的意图，从而提升机器人示教编程的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前机器人编程中，对接触类任务的编程需求增长，但非专业人士使用动力引导时，输入信号常因人为演示误差而不精确，影响后续运动复现及机器学习算法性能。因此亟需改善输入信号的准确性，以促进机器人广泛应用。

Method: 本文对比了不同信号滤波方法，并提出一种用于一触即发信号偏差处理的峰值检测法。通过设定基于‘人意图’与实际输入间误差的特定评价标准，综合分析并实验各方法的关键参数影响。

Result: 研究表明，对于单个运动任务，通过优化处理，误差指标可最多降低20%，即信号与人意图的匹配度提升显著。

Conclusion: 提出的峰值检测与信号优化流程能有效提升机器人编程体验与人机交互质量，有助于非专业用户直观高效地完成接触任务编程。

Abstract: For non-robot-programming experts, kinesthetic guiding can be an intuitive
input method, as robot programming of in-contact tasks is becoming more
prominent. However, imprecise and noisy input signals from human demonstrations
pose problems when reproducing motions directly or using the signal as input
for machine learning methods. This paper explores optimizing force signals to
correspond better to the human intention of the demonstrated signal. We compare
different signal filtering methods and propose a peak detection method for
dealing with first-contact deviations in the signal. The evaluation of these
methods considers a specialized error criterion between the input and the
human-intended signal. In addition, we analyze the critical parameters'
influence on the filtering methods. The quality for an individual motion could
be increased by up to \SI{20}{\percent} concerning the error criterion. The
proposed contribution can improve the usability of robot programming and the
interaction between humans and robots.

</details>


### [263] [EMP: Executable Motion Prior for Humanoid Robot Standing Upper-body Motion Imitation](https://arxiv.org/abs/2507.15649)
*Haocheng Xu,Haodong Zhang,Zhenghan Chen,Rong Xiong*

Main category: cs.RO

TL;DR: 本论文提出了一种基于强化学习的框架，使人形机器人能够模仿人类上半身动作的同时保持整体站立稳定性，并通过设计运动重定向网络和可执行动作先验模块提升鲁棒性与安全性，方法在仿真与现实中均得到了实证验证。


<details>
  <summary>Details</summary>
Motivation: 目前，人形机器人在站立姿态下进行操作时，其可控范围有限，容易引发全身稳定性问题。为了让人形机器人能够在执行类似人类的上半身操作动作时，维持其整体稳定性，有必要开发专门的模仿与站立稳定控制方法。

Method: 作者提出了强化学习（RL）框架，结合自定义的重定向网络，生成大规模人类上半身运动数据集，用于训练RL策略以实现动作跟踪。在训练过程中引入域随机化以提升策略的鲁棒性；同时引入可执行动作先验（EMP）模块，根据机器人当前状态，对输入的目标动作加以调整，避免超出可执行能力，保障安全与稳定。

Result: 通过仿真与现实机器人实验，证明了所提方法能让机器人成功模仿上半身动作，同时维持站立稳定性，具有良好的实际应用效果。

Conclusion: 论文方法不仅提升了人形机器人模仿上半身动作时的稳定性与执行安全性，而且具有实际部署的可行性，对人形机器人在实际环境中的操作能力提升有重要意义。

Abstract: To support humanoid robots in performing manipulation tasks, it is essential
to study stable standing while accommodating upper-body motions. However, the
limited controllable range of humanoid robots in a standing position affects
the stability of the entire body. Thus we introduce a reinforcement learning
based framework for humanoid robots to imitate human upper-body motions while
maintaining overall stability. Our approach begins with designing a retargeting
network that generates a large-scale upper-body motion dataset for training the
reinforcement learning (RL) policy, which enables the humanoid robot to track
upper-body motion targets, employing domain randomization for enhanced
robustness. To avoid exceeding the robot's execution capability and ensure
safety and stability, we propose an Executable Motion Prior (EMP) module, which
adjusts the input target movements based on the robot's current state. This
adjustment improves standing stability while minimizing changes to motion
amplitude. We evaluate our framework through simulation and real-world tests,
demonstrating its practical applicability.

</details>


### [264] [Data-Driven MPC with Data Selection for Flexible Cable-Driven Robotic Arms](https://arxiv.org/abs/2507.15677)
*Huayue Liang,Yanbo Chen,Hongyang Cheng,Yanzhao Yu,Shoujie Li,Junbo Tan,Xueqian Wang,Long Zeng*

Main category: cs.RO

TL;DR: 本文提出了一种基于输入输出数据的柔性索驱动机械臂（FCRA）模型预测控制（MPC）方法，无需物理建模即可实现高精度控制，并且具有实时性优势。


<details>
  <summary>Details</summary>
Motivation: 由于柔性索驱动机械臂的电缆具有弹性、滞后和摩擦等特性，使其建模和控制存在重大挑战，现有方法很难准确、高效地控制FCRA。

Method: 提出了一种仅依赖输入输出数据的隐式模型，并将其嵌入MPC优化框架。引入数据选择算法（DSA）以筛选最能表征系统的数据，从而显著降低每步计算时间（约4ms）。还通过仿真研究超参数对跟踪误差的影响。

Result: 在真实FCRA平台进行了五点定位精度、五点响应跟踪和字母轨迹绘制实验。提出方法平均定位精度为2.070mm，平均跟踪误差为0.541度，优于传统PID（1.418度）。

Conclusion: 该方法无需物理模型即可大幅提升FCRA控制精度和实时性，优于常规PID，具有良好的应用前景。

Abstract: Flexible cable-driven robotic arms (FCRAs) offer dexterous and compliant
motion. Still, the inherent properties of cables, such as resilience,
hysteresis, and friction, often lead to particular difficulties in modeling and
control. This paper proposes a model predictive control (MPC) method that
relies exclusively on input-output data, without a physical model, to improve
the control accuracy of FCRAs. First, we develop an implicit model based on
input-output data and integrate it into an MPC optimization framework. Second,
a data selection algorithm (DSA) is introduced to filter the data that best
characterize the system, thereby reducing the solution time per step to
approximately 4 ms, which is an improvement of nearly 80%. Lastly, the
influence of hyperparameters on tracking error is investigated through
simulation. The proposed method has been validated on a real FCRA platform,
including five-point positioning accuracy tests, a five-point response tracking
test, and trajectory tracking for letter drawing. The results demonstrate that
the average positioning accuracy is approximately 2.070 mm. Moreover, compared
to the PID method with an average tracking error of 1.418{\deg}, the proposed
method achieves an average tracking error of 0.541{\deg}.

</details>


### [265] [Strong, Accurate, and Low-Cost Robot Manipulator](https://arxiv.org/abs/2507.15693)
*Georges Chebly,Spencer Little,Nisal Perera,Aliya Abedeen,Ken Suzuki,Donghyun Kim*

Main category: cs.RO

TL;DR: 本文提出Forte，一种完全3D打印、6自由度的机械臂，材料成本低于215美元，性能接近工业级。


<details>
  <summary>Details</summary>
Motivation: 现有低成本教育机械臂性能有限，难以满足更高阶教育和科研需求。作者希望用极低成本实现高性能机械臂，推动教育及AI实验发展。

Method: 采用创意性机械设计，结合绳轮驱动、同步带、简易张紧机构和拓扑优化加强结构刚度。优化传动系统以降低间隙，无需昂贵电子设备或制造工艺。

Result: 实验表明，Forte具有高重复精度（亚毫米级）、可负载0.63kg、最大作业半径0.467m，性能优于现有同类低成本机械臂。

Conclusion: Forte具备高性价比和高性能，是教育和机器人研究应用的有力平台，突破了低成本机械臂的性能瓶颈。

Abstract: This paper presents Forte, a fully 3D-printable, 6-DoF robotic arm designed
to achieve near industrial-grade performance - 0.63 kg payload, 0.467 m reach,
and sub-millimeter repeatability - at a material cost under $215. As an
accessible robot for broad applications across classroom education to AI
experiments, Forte pushes forward the performance limitations of existing
low-cost educational arms. We introduce a cost-effective mechanical design that
combines capstan-based cable drives, timing belts, simple tensioning
mechanisms, and lightweight 3D-printed structures, along with topology
optimization for structural stiffness. Through careful drivetrain engineering,
we minimize backlash and maintain control fidelity without relying on
high-power electronics or expensive manufacturing processes. Experimental
validation demonstrates that Forte achieves high repeatability and load
capacity, offering a compelling robotic platform for both classroom instruction
and advanced robotics research.

</details>


### [266] [Selective Densification for Rapid Motion Planning in High Dimensions with Narrow Passages](https://arxiv.org/abs/2507.15710)
*Lu Huang,Lingxiao Meng,Jiankun Wang,Xingjian Jing*

Main category: cs.RO

TL;DR: 本文提出了一种简单高效的采样规划框架，通过多分辨率采样提升了高维配置空间的路径规划性能，优于现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 采样算法在复杂、高维、带有狭窄通道的配置空间中效果受限，现有基于启发式或学习的提升方式泛化性差或需要大量先验训练，亟需一种高效普适的新方法。

Method: 提出了结合多粒度规划的采样框架，包括单向与双向版本。该方法通过在不同分辨率下进行均匀随机采样，并在更大的自由空间内优先探索稀疏采样点，实现稀疏与密集采样的无缝切换，提高了复杂空间内的搜索效率。

Result: 在$
mathbb{SE}(2)$、$
mathbb{SE}(3)$和$
mathbb{R}^{14}$ 测试环境下，本文方法的规划效率和能力优于多个现有主流采样器。在实际机器人（Franka Emika Panda）受限空间导航实验中也表现出更佳效果。

Conclusion: 多分辨率采样和稀疏-密集切换机制下的新采样框架，兼具速度、完备性与对复杂场景的适应性，实际测试和仿真均优于现有采样规划方法。

Abstract: Sampling-based algorithms are widely used for motion planning in
high-dimensional configuration spaces. However, due to low sampling efficiency,
their performance often diminishes in complex configuration spaces with narrow
corridors. Existing approaches address this issue using handcrafted or learned
heuristics to guide sampling toward useful regions. Unfortunately, these
strategies often lack generalizability to various problems or require extensive
prior training. In this paper, we propose a simple yet efficient sampling-based
planning framework along with its bidirectional version that overcomes these
issues by integrating different levels of planning granularity. Our approach
probes configuration spaces with uniform random samples at varying resolutions
and explores these multi-resolution samples online with a bias towards sparse
samples when traveling large free configuration spaces. By seamlessly
transitioning between sparse and dense samples, our approach can navigate
complex configuration spaces while maintaining planning speed and completeness.
The simulation results demonstrate that our approach outperforms several
state-of-the-art sampling-based planners in $\mathbb{SE}(2)$, $\mathbb{SE}(3)$,
and $\mathbb{R}^{14}$ with challenging terrains. Furthermore, experiments
conducted with the Franka Emika Panda robot operating in a constrained
workspace provide additional evidence of the superiority of the proposed
method.

</details>


### [267] [DiffPF: Differentiable Particle Filtering with Generative Sampling via Conditional Diffusion Models](https://arxiv.org/abs/2507.15716)
*Ziyu Wan,Lin Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种结合扩散模型的可微粒子滤波方法DiffPF，能够更好地解决高维、多峰状态估计问题，并在多个基准任务中性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统可微粒子滤波器依赖预定义或低容量的提议分布，且需进行重要性加权，难以有效处理复杂、高维或多峰的后验分布。为克服这些限制，作者希望借助更强的生成建模能力来构造更灵活的后验采样方法。

Method: DiffPF引入扩散模型作为条件后验采样器，具体方法是基于扩散模型对预测粒子及当前观测条件下建模，用于在复杂、可能多峰的分布中等权采样，避免了重要性加权和低容量提议分布的局限。

Result: DiffPF在模拟和真实任务中均显著超越了现有可微粒子滤波基线。在高多峰全局定位基准上准确率提升82.8%，在真实KITTI视觉里程计基准上准确率提升26%。

Conclusion: DiffPF首次将条件扩散模型引入粒子滤波，实现了高质量的后验采样和更有效的粒子分布，极大提高了状态估计的准确性。

Abstract: This paper proposes DiffPF, a differentiable particle filter that leverages
diffusion models for state estimation in dynamic systems. Unlike conventional
differentiable particle filters, which require importance weighting and
typically rely on predefined or low-capacity proposal distributions. DiffPF
learns a flexible posterior sampler by conditioning a diffusion model on
predicted particles and the current observation. This enables accurate,
equally-weighted sampling from complex, high-dimensional, and multimodal
filtering distributions. We evaluate DiffPF across a range of scenarios,
including both unimodal and highly multimodal distributions, and test it on
simulated as well as real-world tasks, where it consistently outperforms
existing filtering baselines. In particular, DiffPF achieves an 82.8%
improvement in estimation accuracy on a highly multimodal global localization
benchmark, and a 26% improvement on the real-world KITTI visual odometry
benchmark, compared to state-of-the-art differentiable filters. To the best of
our knowledge, DiffPF is the first method to integrate conditional diffusion
models into particle filtering, enabling high-quality posterior sampling that
produces more informative particles and significantly improves state
estimation.

</details>


### [268] [Gaze-supported Large Language Model Framework for Bi-directional Human-Robot Interaction](https://arxiv.org/abs/2507.15729)
*Jens V. Rüppel,Andrey Rudenko,Tim Schreiter,Martin Magnusson,Achim J. Lilienthal*

Main category: cs.RO

TL;DR: 本论文提出了一种结合注视与语音输入的人机交互系统，依托大语言模型灵活驱动，用于协作机器人辅助任务，并与传统脚本式交互系统做了实验对比。


<details>
  <summary>Details</summary>
Motivation: 为解决现有人机交互系统在双向、多模态和上下文感知等方面的不足，提升协作机器人在复杂动态任务中的适应性和用户协助能力。

Method: 设计了一个可通过注视和语音信息感知环境的模块化机器人系统，采用大语言模型进行交互状态表示和实时感知，并在多次公开性测试活动与两轮实验中评估其性能和用户体验。

Result: 研究发现，基于大语言模型的系统具有更高的适应性，在用户参与度和任务执行指标上略有提升，但也可能带来冗余输出；而传统脚本式管道更适用于简单任务。

Conclusion: LLM驱动的多模态人机协作系统提升了复杂任务下的用户体验与适应性，但在实际应用中需权衡输出效率与准确性，脚本式方案依然在简单任务中有优势。

Abstract: The rapid development of Large Language Models (LLMs) creates an exciting
potential for flexible, general knowledge-driven Human-Robot Interaction (HRI)
systems for assistive robots. Existing HRI systems demonstrate great progress
in interpreting and following user instructions, action generation, and robot
task solving. On the other hand, bi-directional, multi-modal, and context-aware
support of the user in collaborative tasks still remains an open challenge. In
this paper, we present a gaze- and speech-informed interface to the assistive
robot, which is able to perceive the working environment from multiple vision
inputs and support the dynamic user in their tasks. Our system is designed to
be modular and transferable to adapt to diverse tasks and robots, and it is
capable of real-time use of language-based interaction state representation and
fast on board perception modules. Its development was supported by multiple
public dissemination events, contributing important considerations for improved
robustness and user experience. Furthermore, in two lab studies, we compare the
performance and user ratings of our system with those of a traditional scripted
HRI pipeline. Our findings indicate that an LLM-based approach enhances
adaptability and marginally improves user engagement and task execution metrics
but may produce redundant output, while a scripted pipeline is well suited for
more straightforward tasks.

</details>


### [269] [Interleaved LLM and Motion Planning for Generalized Multi-Object Collection in Large Scene Graphs](https://arxiv.org/abs/2507.15782)
*Ruochu Yang,Yu Zhou,Fumin Zhang,Mengxue Hou*

Main category: cs.RO

TL;DR: 本论文提出了一种新的家用机器人规划算法Inter-LLM，通过结合大语言模型（LLM）与运动规划，以及引入多模态动作代价相似性函数，实现了高效的人类指令执行和多物体收集任务。实验表明，该方法相较于最新方法任务完成率提升30%。


<details>
  <summary>Details</summary>
Motivation: 当前家用机器人在处理开放式物体和高效导航大场景方面智能不足，难以完成长任务中的多物体搬运与多地点操作。研究动机是提升机器人在复杂环境下基于人类指令的长时规划与智能任务执行能力。

Method: 作者提出将大语言模型（LLM）与运动规划算法交替结合，设计了多模态动作代价相似性函数，历史与未来规划相结合进行动态优化，实现多步骤、高不确定性的物体收集与搬运任务。

Result: 在仿真实验中，提出的Inter-LLM算法，相较最新相关方法，在执行人类指令、任务成功率和成本等方面整体性能提升了30%。

Conclusion: Inter-LLM算法有效提升了家用机器人面对复杂、多变任务时的任务执行质量和效率，为实现更智能的家庭机器人提供了新途径。

Abstract: Household robots have been a longstanding research topic, but they still lack
human-like intelligence, particularly in manipulating open-set objects and
navigating large environments efficiently and accurately. To push this
boundary, we consider a generalized multi-object collection problem in large
scene graphs, where the robot needs to pick up and place multiple objects
across multiple locations in a long mission of multiple human commands. This
problem is extremely challenging since it requires long-horizon planning in a
vast action-state space under high uncertainties. To this end, we propose a
novel interleaved LLM and motion planning algorithm Inter-LLM. By designing a
multimodal action cost similarity function, our algorithm can both reflect the
history and look into the future to optimize plans, striking a good balance of
quality and efficiency. Simulation experiments demonstrate that compared with
latest works, our algorithm improves the overall mission performance by 30% in
terms of fulfilling human commands, maximizing mission success rates, and
minimizing mission costs.

</details>


### [270] [Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers](https://arxiv.org/abs/2507.15833)
*Ian Chuang,Andrew Lee,Dechen Gao,Jinyu Zou,Iman Soltani*

Main category: cs.RO

TL;DR: 本论文提出借鉴人类凝视机制，设计主动视觉系统并引入类人注视策略到机器人视觉学习中，通过将凝视信息融入视觉Transformer（ViT）模型，显著减少运算量并提升关键任务表现。


<details>
  <summary>Details</summary>
Motivation: 人类视觉系统通过凝视关注任务相关区域，从而高效处理信息；而现有机器人学习多采用对图像的被动、均匀处理，效率低、性能有限。推动机器人视觉向主动、高效的人类策略学习有助突破现有局限。

Method: 1）利用主动视觉（Active Vision）机器人平台，采集人眼凝视及机器人示范数据。2）在ViT模型中采用受人类视网膜启发的foveated patch tokenization方法，根据凝视区域在图像多尺度提取特征，减少非关键区域运算。3）探讨两种注视行为的集成方式：（a）两阶段模型，即先预测凝视引导视觉关注，再预测动作；（b）将凝视与动作联合作为端到端策略空间共同预测。

Result: 1）引入foveated tokenization后，在感兴趣区保持高视觉分辨率，显著压缩特征数量和运算成本；2）提升了机器人在高精度任务和干扰环境下的表现与鲁棒性。3）验证了两种凝视预测方法的有效性。

Conclusion: 借鉴人类主动凝视与视觉处理机制，能为机器人视觉系统带来有效归纳偏置，大幅提升效率与表现，是下一代高效机器人视觉系统设计的重要方向。

Abstract: Human vision is a highly active process driven by gaze, which directs
attention and fixation to task-relevant regions and dramatically reduces visual
processing. In contrast, robot learning systems typically rely on passive,
uniform processing of raw camera images. In this work, we explore how
incorporating human-like active gaze into robotic policies can enhance both
efficiency and performance. We build on recent advances in foveated image
processing and apply them to an Active Vision robot system that emulates both
human head movement and eye tracking. Extending prior work on the AV-ALOHA
robot simulation platform, we introduce a framework for simultaneously
collecting eye-tracking data and robot demonstrations from a human operator as
well as a simulation benchmark and dataset for training robot policies that
incorporate human gaze. Given the widespread use of Vision Transformers (ViTs)
in robot learning, we integrate gaze information into ViTs using a foveated
patch tokenization scheme inspired by recent work in image segmentation.
Compared to uniform patch tokenization, this significantly reduces the number
of tokens-and thus computation-without sacrificing visual fidelity near regions
of interest. We also explore two approaches to gaze imitation and prediction
from human data. The first is a two-stage model that predicts gaze to guide
foveation and action; the second integrates gaze into the action space,
allowing the policy to jointly predict gaze and actions end-to-end. Our results
show that our method for foveated robot vision not only drastically reduces
computational overhead, but also improves performance for high precision tasks
and robustness to unseen distractors. Together, these findings suggest that
human-inspired visual processing offers a useful inductive bias for robotic
vision systems. https://ian-chuang.github.io/gaze-av-aloha/

</details>
