<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 71]
- [cs.CL](#cs.CL) [Total: 58]
- [cs.RO](#cs.RO) [Total: 29]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Enhancing Underwater Object Detection through Spatio-Temporal Analysis and Spatial Attention Networks](https://arxiv.org/abs/2510.25797)
*Sai Likhith Karri,Ansh Saxena*

Main category: cs.CV

TL;DR: 本研究探讨了时空建模及空间注意机制在深度学习水下目标检测中的应用效果。通过对比YOLOv5、T-YOLOv5、以及加入CBAM的T-YOLOv5，发现增强型模型在复杂海洋环境下表现更优。


<details>
  <summary>Details</summary>
Motivation: 水下目标检测因动态环境、遮挡与缓慢移动等因素面临挑战。现有模型在此场景下准确性有限，作者希望通过时空信息建模和注意力机制提升模型性能。

Method: 先比较标准YOLOv5与加入时序建模的T-YOLOv5，再在T-YOLOv5基础上引入卷积块注意模块（CBAM），评估三种模型在水下目标检测中的表现。

Result: 实验结果表明，YOLOv5的mAP@50-95为0.563，T-YOLOv5为0.813，T-YOLOv5+CBAM为0.811。时空增强和注意力机制显著提升复杂场景下的检测精度和泛化能力。

Conclusion: T-YOLOv5在检测可靠性方面显著优于标准模型，加入CBAM后在复杂动态水下环境中的检测能力进一步提升，但在简单场景下会有一定精度损失。

Abstract: This study examines the effectiveness of spatio-temporal modeling and the
integration of spatial attention mechanisms in deep learning models for
underwater object detection. Specifically, in the first phase, the performance
of temporal-enhanced YOLOv5 variant T-YOLOv5 is evaluated, in comparison with
the standard YOLOv5. For the second phase, an augmented version of T-YOLOv5 is
developed, through the addition of a Convolutional Block Attention Module
(CBAM). By examining the effectiveness of the already pre-existing YOLOv5 and
T-YOLOv5 models and of the newly developed T-YOLOv5 with CBAM. With CBAM, the
research highlights how temporal modeling improves detection accuracy in
dynamic marine environments, particularly under conditions of sudden movements,
partial occlusions, and gradual motion. The testing results showed that YOLOv5
achieved a mAP@50-95 of 0.563, while T-YOLOv5 and T-YOLOv5 with CBAM
outperformed with mAP@50-95 scores of 0.813 and 0.811, respectively,
highlighting their superior accuracy and generalization in detecting complex
objects. The findings demonstrate that T-YOLOv5 significantly enhances
detection reliability compared to the standard model, while T-YOLOv5 with CBAM
further improves performance in challenging scenarios, although there is a loss
of accuracy when it comes to simpler scenarios.

</details>


### [2] [MIRO: MultI-Reward cOnditioned pretraining improves T2I quality and efficiency](https://arxiv.org/abs/2510.25897)
*Nicolas Dufour,Lucas Degeorge,Arijit Ghosh,Vicky Kalogeiton,David Picard*

Main category: cs.CV

TL;DR: 当前的文本到图像生成模型虽然能产生多样化的图片，但不能很好地符合用户偏好。以往做法用奖励模型对生成图片进行后筛选，可能会损失信息且影响多样性和训练效率。本文提出在训练时将多个奖励模型作为条件，直接引导模型学习用户偏好。该方法显著提升了图像质量和训练速度，称为MIRO，并在多个基准测试上达到最新最好成绩。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成模型在大规模非精选数据集上训练，偏重多样性，不能有效对齐用户喜好。以奖励模型作为后处理虽然能调整结果，但存在损失多样性、语义真实性和降低效率等问题，亟需一种新方式能在模型生成阶段更好地整合用户多元偏好。

Method: 提出在模型训练阶段引入多个奖励模型作为条件输入，让模型直接学习并适应用户的不同偏好，而不是在生成后再选优。这一端到端训练框架称为MIRO，可以在训练期间利用奖励信号动态调整模型方向，无需大量舍弃或筛选生成图片。

Result: 实验结果显示，MIRO方法不仅极大提升了生成图片的视觉质量，还显著加快了训练速度。在GenEval组合性基准测试，以及PickAScore、ImageReward、HPSv2等用户偏好评分上都获得了当前最优表现。

Conclusion: 多奖励模型条件化训练可以克服后处理筛选带来的缺点，让模型在生成阶段就具备对用户偏好的适应能力。MIRO不仅提升了结果质量，还提高了效率和多样性，为文本到图像生成领域提供了具有推广价值的新范式。

Abstract: Current text-to-image generative models are trained on large uncurated
datasets to enable diverse generation capabilities. However, this does not
align well with user preferences. Recently, reward models have been
specifically designed to perform post-hoc selection of generated images and
align them to a reward, typically user preference. This discarding of
informative data together with the optimizing for a single reward tend to harm
diversity, semantic fidelity and efficiency. Instead of this post-processing,
we propose to condition the model on multiple reward models during training to
let the model learn user preferences directly. We show that this not only
dramatically improves the visual quality of the generated images but it also
significantly speeds up the training. Our proposed method, called MIRO,
achieves state-of-the-art performances on the GenEval compositional benchmark
and user-preference scores (PickAScore, ImageReward, HPSv2).

</details>


### [3] [BikeScenes: Online LiDAR Semantic Segmentation for Bicycles](https://arxiv.org/abs/2510.25901)
*Denniz Goren,Holger Caesar*

Main category: cs.CV

TL;DR: 本文提出了基于自行车的多传感器感知平台SenseBike，通过开发和评估针对自行车环境优化的3D LiDAR分割方法，提升骑行者安全，并发布了新数据集BikeScenes-lidarseg。


<details>
  <summary>Details</summary>
Motivation: 随着更快电动自行车的普及，骑行者的脆弱性上升。因此，有必要将汽车领域的感知技术移植到自行车上，以改善其安全性。

Method: 构建SenseBike多传感器平台，采集3021帧LiDAR数据并人工标注29类动态与静态目标，形成BikeScenes-lidarseg数据集。将自行车数据上的微调与直接使用汽车领域（SemanticKITTI）预训练模型效果进行比较，评估分割性能。

Result: 在自行车数据上微调后，mIoU达到63.6%，远高于仅用汽车领域预训练模型的13.8%。显示了针对自行车专属数据集进行训练的重要性。

Conclusion: 使用自行车专属数据集可以显著提升感知系统的表现。BikeScenes数据集有助于推动面向骑行者的LiDAR分割技术发展，并指出了硬件受限条件下的重要挑战。

Abstract: The vulnerability of cyclists, exacerbated by the rising popularity of faster
e-bikes, motivates adapting automotive perception technologies for bicycle
safety. We use our multi-sensor 'SenseBike' research platform to develop and
evaluate a 3D LiDAR segmentation approach tailored to bicycles. To bridge the
automotive-to-bicycle domain gap, we introduce the novel BikeScenes-lidarseg
Dataset, comprising 3021 consecutive LiDAR scans around the university campus
of the TU Delft, semantically annotated for 29 dynamic and static classes. By
evaluating model performance, we demonstrate that fine-tuning on our BikeScenes
dataset achieves a mean Intersection-over-Union (mIoU) of 63.6%, significantly
outperforming the 13.8% obtained with SemanticKITTI pre-training alone. This
result underscores the necessity and effectiveness of domain-specific training.
We highlight key challenges specific to bicycle-mounted, hardware-constrained
perception systems and contribute the BikeScenes dataset as a resource for
advancing research in cyclist-centric LiDAR segmentation.

</details>


### [4] [Generative Image Restoration and Super-Resolution using Physics-Informed Synthetic Data for Scanning Tunneling Microscopy](https://arxiv.org/abs/2510.25921)
*Nikola L. Kolev,Tommaso Rodani,Neil J. Curson,Taylor J. Z. Stock,Alberto Cazzaniga*

Main category: cs.CV

TL;DR: 本文提出使用机器学习方法对扫描隧道显微镜(STM)图像进行修复和超分辨，解决探针退化和数据获取效率低的问题。通过少量原始数据和物理启发的合成数据训练模型，实现高效图像恢复，提升实验效率。


<details>
  <summary>Details</summary>
Motivation: STM具有原子级分辨率，但实际应用往往受限于探针退化导致图像质量下降以及图像采集速度慢。频繁的探针调理和人为干预增加了实验复杂性和时间成本，因此亟需提升图像采集质量和效率的新方法。

Method: 作者构建了仅包含36幅高质量Si(001):H实验图像的数据集，并通过物理知识指导生成合成数据，以扩展训练数据量。接着应用了多种当前主流的生成模型（如flow-matching和扩散模型）进行图像修复和超分辨训练。模型表现通过CMMD和结构相似度等定量指标进行评估。

Result: 实验结果表明，所提出的模型能有效修复低质量或不完整STM图像，并能在稀疏采样条件下准确重建出高质量图像，实现成像速度提升2~4倍。

Conclusion: 该机器学习框架能够明显提升STM实验通量，减少探针调理频率，并为现有高帧率STM系统提供了成像质量提升方案，对STM应用具有广泛促进作用。

Abstract: Scanning tunnelling microscopy (STM) enables atomic-resolution imaging and
atom manipulation, but its utility is often limited by tip degradation and slow
serial data acquisition. Fabrication adds another layer of complexity since the
tip is often subjected to large voltages, which may alter the shape of its
apex, requiring it to be conditioned. Here, we propose a machine learning (ML)
approach for image repair and super-resolution to alleviate both challenges.
Using a dataset of only 36 pristine experimental images of Si(001):H, we
demonstrate that a physics-informed synthetic data generation pipeline can be
used to train several state-of-the-art flow-matching and diffusion models.
Quantitative evaluation with metrics such as the CLIP Maximum Mean Discrepancy
(CMMD) score and structural similarity demonstrates that our models are able to
effectively restore images and offer a two- to fourfold reduction in image
acquisition time by accurately reconstructing images from sparsely sampled
data. Our framework has the potential to significantly increase STM
experimental throughput by offering a route to reducing the frequency of
tip-conditioning procedures and to enhancing frame rates in existing high-speed
STM systems.

</details>


### [5] [SplitFlow: Flow Decomposition for Inversion-Free Text-to-Image Editing](https://arxiv.org/abs/2510.25970)
*Sung-Hoon Yoon,Minghan Li,Gaspard Beaudouin,Congcong Wen,Muhammad Rafay Azhar,Mengyu Wang*

Main category: cs.CV

TL;DR: 提出了一种新的图像编辑框架，分解目标描述为多个子目标，分别计算流并聚合，实现了无需反演的高质量编辑。方法在多样性和一致性之间取得平衡，优于现有零样本编辑方法。


<details>
  <summary>Details</summary>
Motivation: 现有Rectified flow模型虽然在生成图像领域表现优秀，但在图像编辑任务中存在反演不准确、编辑梯度纠缠问题，导致输出不符合目标描述，限制了其实用性。

Method: 本文提出了一个去反演的分解-聚合流编辑框架。首先将目标描述语义分解为多个子目标，为每个子目标计算独立流。然后设计了基于投影和软聚合的机制，按多任务学习中的梯度冲突解决思想对不同流进行加权组合，抑制冗余、突出差异，兼顾多样性与一致性。

Result: 实验结果显示，该方法在语义一致性和属性解耦方面明显优于已有的零样本编辑方法，实现了更高质量的图像编辑效果。

Conclusion: 分解与聚合流框架能够有效缓解现有方法在编辑任务中的局限，提升编辑的多样性和一致性，为开源图像编辑带来新思路。

Abstract: Rectified flow models have become a de facto standard in image generation due
to their stable sampling trajectories and high-fidelity outputs. Despite their
strong generative capabilities, they face critical limitations in image editing
tasks: inaccurate inversion processes for mapping real images back into the
latent space, and gradient entanglement issues during editing often result in
outputs that do not faithfully reflect the target prompt. Recent efforts have
attempted to directly map source and target distributions via ODE-based
approaches without inversion; however,these methods still yield suboptimal
editing quality. In this work, we propose a flow decomposition-and-aggregation
framework built upon an inversion-free formulation to address these
limitations. Specifically, we semantically decompose the target prompt into
multiple sub-prompts, compute an independent flow for each, and aggregate them
to form a unified editing trajectory. While we empirically observe that
decomposing the original flow enhances diversity in the target space,
generating semantically aligned outputs still requires consistent guidance
toward the full target prompt. To this end, we design a projection and
soft-aggregation mechanism for flow, inspired by gradient conflict resolution
in multi-task learning. This approach adaptively weights the sub-target
velocity fields, suppressing semantic redundancy while emphasizing distinct
directions, thereby preserving both diversity and consistency in the final
edited output. Experimental results demonstrate that our method outperforms
existing zero-shot editing approaches in terms of semantic fidelity and
attribute disentanglement. The code is available at
https://github.com/Harvard-AI-and-Robotics-Lab/SplitFlow.

</details>


### [6] [Brain-IT: Image Reconstruction from fMRI via Brain-Interaction Transformer](https://arxiv.org/abs/2510.25976)
*Roman Beliy,Amit Zalcher,Jonathan Kogman,Navve Wasserman,Michal Irani*

Main category: cs.CV

TL;DR: 本论文提出了一种名为“Brain-IT”的新方法，通过脑启发式交互Transformer（BIT）改进了基于fMRI脑成像的视觉图像重建任务，显著提升了重建图像的真实性和一致性，并减少了对长时间训练数据的需求。


<details>
  <summary>Details</summary>
Motivation: 最近利用扩散模型从fMRI数据重建人类所见图像取得进展，但当前方法在图像还原的真实度上仍有不足，尤其是还原出的图像往往与实际视觉内容存在较大偏差。该研究旨在提升重建图像对原始视觉刺激的忠实度。

Method: 本研究提出Brain-IT架构，核心是Brain Interaction Transformer（BIT），通过识别和聚类大脑中功能相似的脑体素，允许这些功能簇高效交互。该方法将所有被试共享的功能集群作为信息整合的基础，同时所有模型组件在不同被试和脑区之间共享，大大提升了数据利用效率。BIT分别预测高层次语义特征（指导扩散模型聚焦正确语义内容）和低层次结构特征（辅助初始化扩散过程中的图像布局），实现脑信号到局部图像特征的信息直接流动。

Result: 本方法不仅在视觉效果上，而且在客观指标上都超过了当前最先进（SotA）的方法；并且，仅需1小时新被试的fMRI数据，即可达到传统方法需40小时数据下的效果。

Conclusion: Brain-IT通过功能簇方式结构化处理脑fMRI数据，把脑信号高效映射到图像特征层，并大幅提高了图像重建的忠实度和数据使用效率，为低资源环境下的大脑-视觉解码提供了新思路。

Abstract: Reconstructing images seen by people from their fMRI brain recordings
provides a non-invasive window into the human brain. Despite recent progress
enabled by diffusion models, current methods often lack faithfulness to the
actual seen images. We present "Brain-IT", a brain-inspired approach that
addresses this challenge through a Brain Interaction Transformer (BIT),
allowing effective interactions between clusters of functionally-similar
brain-voxels. These functional-clusters are shared by all subjects, serving as
building blocks for integrating information both within and across brains. All
model components are shared by all clusters & subjects, allowing efficient
training with a limited amount of data. To guide the image reconstruction, BIT
predicts two complementary localized patch-level image features: (i)high-level
semantic features which steer the diffusion model toward the correct semantic
content of the image; and (ii)low-level structural features which help to
initialize the diffusion process with the correct coarse layout of the image.
BIT's design enables direct flow of information from brain-voxel clusters to
localized image features. Through these principles, our method achieves image
reconstructions from fMRI that faithfully reconstruct the seen images, and
surpass current SotA approaches both visually and by standard objective
metrics. Moreover, with only 1-hour of fMRI data from a new subject, we achieve
results comparable to current methods trained on full 40-hour recordings.

</details>


### [7] [Fine-tuning Segment Anything for Real-Time Tumor Tracking in Cine-MRI](https://arxiv.org/abs/2510.25990)
*Valentin Boussot,Cédric Hémon,Jean-Claude Nunes,Jean-Louis Dillenseger*

Main category: cs.CV

TL;DR: 本研究参加了TrackRAD2025挑战，目标是在数据极度稀缺条件下，对胸部和腹部的cine-MRI序列进行实时肿瘤追踪，最终采用基于SAM 2.1的分割方法获得较好成绩，展示了基础模型在MRI引导放疗中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 在MRI引导放疗中，需要对肿瘤位置进行精准、实时追踪。然而，实际数据十分稀缺，如何在极低数据条件下实现高效、精确的肿瘤追踪成为亟需解决的问题。

Method: 研究者探索了两种互补策略：一是基于IMPACT相似性度量的无监督图像配准；二是利用基础模型（SAM 2.1及其变体）结合提示词机制进行分割。因算法要求一秒内推理，最终选择了经过小数据集微调的SAM 2.1 b+模型，以第一帧的标注mask作为提示，采用Dice+IoU损失函数，低学习率共同优化全部模块，避免过拟合。测试时，放弃了增广策略，仅用最佳Dice分数模型用于评估。

Result: 在TrackRAD2025隐藏测试集上，所提模型获得了0.8794的Dice分数，在挑战赛中排名第6。

Conclusion: 该研究证实了基础分割模型（如SAM）在极低标注数据条件下依然具有优秀的实时肿瘤追踪能力，为MRI引导下的放疗带来高效实用的解决方案。

Abstract: In this work, we address the TrackRAD2025 challenge of real-time tumor
tracking in cine-MRI sequences of the thoracic and abdominal regions under
strong data scarcity constraints. Two complementary strategies were explored:
(i) unsupervised registration with the IMPACT similarity metric and (ii)
foundation model-based segmentation leveraging SAM 2.1 and its recent variants
through prompt-based interaction. Due to the one-second runtime constraint, the
SAM-based method was ultimately selected. The final configuration used SAM2.1
b+ with mask-based prompts from the first annotated slice, fine-tuned solely on
the small labeled subset from TrackRAD2025. Training was configured to minimize
overfitting, using 1024x1024 patches (batch size 1), standard augmentations,
and a balanced Dice + IoU loss. A low uniform learning rate (0.0001) was
applied to all modules (prompt encoder, decoder, Hiera backbone) to preserve
generalization while adapting to annotator-specific styles. Training lasted 300
epochs (~12h on RTX A6000, 48GB). The same inference strategy was consistently
applied across all anatomical sites and MRI field strengths. Test-time
augmentation was considered but ultimately discarded due to negligible
performance gains. The final model was selected based on the highest Dice
Similarity Coefficient achieved on the validation set after fine-tuning. On the
hidden test set, the model reached a Dice score of 0.8794, ranking 6th overall
in the TrackRAD2025 challenge. These results highlight the strong potential of
foundation models for accurate and real-time tumor tracking in MRI-guided
radiotherapy.

</details>


### [8] [Larger Hausdorff Dimension in Scanning Pattern Facilitates Mamba-Based Methods in Low-Light Image Enhancement](https://arxiv.org/abs/2510.26001)
*Xinhua Wang,Caibo Feng,Xiangjun Fu,Chunxiao Liu*

Main category: cs.CV

TL;DR: 本文提出一种对Mamba框架的创新增强方法，通过引入Hilbert选择性扫描机制提升其扫描模式的Hausdorff维度，更高效地探索特征空间，加强了细节捕获与整体覆盖，提升了低光照图像增强任务的表现。


<details>
  <summary>Details</summary>
Motivation: 现有Mamba框架在低光照图像增强中存在信息获取不充分和空间局部性不强的问题，难以兼顾细节捕获与长距离依赖。为解决这一瓶颈，作者提出优化扫描模式以提升特征探索能力和空间表现。

Method: 提出Hilbert选择性扫描机制，通过提升扫描路径的Hausdorff维度，更深入细致地遍历与捕获特征空间的细粒度结构；增强空间局部性，同时保留对长程依赖的捕捉能力。

Result: 在公开基准上的大量实验证明，该方法在定量指标和图像视觉质量上均显著优于现有Mamba方法，并且在计算资源消耗和推理时间上有进一步降低。

Conclusion: 改进的扫描策略不仅推动了低光照图像增强领域的技术进步，也为其它Mamba相关领域带来新的应用前景。

Abstract: We propose an innovative enhancement to the Mamba framework by increasing the
Hausdorff dimension of its scanning pattern through a novel Hilbert Selective
Scan mechanism. This mechanism explores the feature space more effectively,
capturing intricate fine-scale details and improving overall coverage. As a
result, it mitigates information inconsistencies while refining spatial
locality to better capture subtle local interactions without sacrificing the
model's ability to handle long-range dependencies. Extensive experiments on
publicly available benchmarks demonstrate that our approach significantly
improves both the quantitative metrics and qualitative visual fidelity of
existing Mamba-based low-light image enhancement methods, all while reducing
computational resource consumption and shortening inference time. We believe
that this refined strategy not only advances the state-of-the-art in low-light
image enhancement but also holds promise for broader applications in fields
that leverage Mamba-based techniques.

</details>


### [9] [CAVE: Detecting and Explaining Commonsense Anomalies in Visual Environments](https://arxiv.org/abs/2510.26006)
*Rishika Bhagwatkar,Syrielle Montariol,Angelika Romanou,Beatriz Borges,Irina Rish,Antoine Bosselut*

Main category: cs.CV

TL;DR: 本文提出了CAVE，这是首个涵盖真实世界视觉异常的基准，支持异常描述、解释和正当化等任务，并为视觉异常检测领域提供认知学视角的高质量注释和评估框架。


<details>
  <summary>Details</summary>
Motivation: 目前的计算机视觉异常检测多局限于工业缺陷或人工合成异常，缺乏对真实世界视觉异常的刻画。该领域急需一个能反映自然环境中异常复杂性与多样性的基准。

Method: 作者建立了CAVE基准，包括三个开放任务（异常描述、解释、正当化），并对异常的视觉表现、复杂性、严重性和普遍性等维度进行了细致注释，借鉴认知科学方法，创建了完整的评估标准。

Result: 评测表明，最新的视觉-语言模型（VLMs）在视觉异常感知和常识推理上表现不佳，即便使用高级提示方法效果也有限。

Conclusion: CAVE为视觉异常检测和VLM常识推理研究提供了更真实且具有认知基础的评测环境，可推动该领域进一步发展。

Abstract: Humans can naturally identify, reason about, and explain anomalies in their
environment. In computer vision, this long-standing challenge remains limited
to industrial defects or unrealistic, synthetically generated anomalies,
failing to capture the richness and unpredictability of real-world anomalies.
In this work, we introduce CAVE, the first benchmark of real-world visual
anomalies. CAVE supports three open-ended tasks: anomaly description,
explanation, and justification; with fine-grained annotations for visual
grounding and categorizing anomalies based on their visual manifestations,
their complexity, severity, and commonness. These annotations draw inspiration
from cognitive science research on how humans identify and resolve anomalies,
providing a comprehensive framework for evaluating Vision-Language Models
(VLMs) in detecting and understanding anomalies. We show that state-of-the-art
VLMs struggle with visual anomaly perception and commonsense reasoning, even
with advanced prompting strategies. By offering a realistic and cognitively
grounded benchmark, CAVE serves as a valuable resource for advancing research
in anomaly detection and commonsense reasoning in VLMs.

</details>


### [10] [Climate Adaptation-Aware Flood Prediction for Coastal Cities Using Deep Learning](https://arxiv.org/abs/2510.26017)
*Bilal Hassan,Areg Karapetyan,Aaron Chung Hin Chow,Samer Madanat*

Main category: cs.CV

TL;DR: 提出了一种基于CNN的轻量级深度学习模型，有效预测城市尺度下的海岸洪水，并在不同地区实现了良好泛化性。


<details>
  <summary>Details</summary>
Motivation: 气候变化和海平面上升带来更高海岸洪水威胁，传统的物理模拟方法成本高、速度慢，难以大规模应用，需要更高效准确的预测手段。

Method: 采用一种视觉感知为主、低资源消耗的深度学习框架，开发CNN模型，并利用阿布扎比和旧金山的案例数据进行模型训练和泛化测试。

Result: 新模型在不同区域实验中，将洪水深度图的平均绝对误差（MAE）降低了近20%，优于现有主流方法。

Conclusion: 所提出方法具备可扩展性和实用性，有助于城市决策者更好地制定应对气候变化导致海岸洪水的有效策略。

Abstract: Climate change and sea-level rise (SLR) pose escalating threats to coastal
cities, intensifying the need for efficient and accurate methods to predict
potential flood hazards. Traditional physics-based hydrodynamic simulators,
although precise, are computationally expensive and impractical for city-scale
coastal planning applications. Deep Learning (DL) techniques offer promising
alternatives, however, they are often constrained by challenges such as data
scarcity and high-dimensional output requirements. Leveraging a recently
proposed vision-based, low-resource DL framework, we develop a novel,
lightweight Convolutional Neural Network (CNN)-based model designed to predict
coastal flooding under variable SLR projections and shoreline adaptation
scenarios. Furthermore, we demonstrate the ability of the model to generalize
across diverse geographical contexts by utilizing datasets from two distinct
regions: Abu Dhabi and San Francisco. Our findings demonstrate that the
proposed model significantly outperforms state-of-the-art methods, reducing the
mean absolute error (MAE) in predicted flood depth maps on average by nearly
20%. These results highlight the potential of our approach to serve as a
scalable and practical tool for coastal flood management, empowering
decision-makers to develop effective mitigation strategies in response to the
growing impacts of climate change. Project Page: https://caspiannet.github.io/

</details>


### [11] [Enhancing Temporal Understanding in Video-LLMs through Stacked Temporal Attention in Vision Encoders](https://arxiv.org/abs/2510.26027)
*Ali Rasekh,Erfan Bagheri Soula,Omid Daliran,Simon Gottschalk,Mohsen Fayyaz*

Main category: cs.CV

TL;DR: 本文提出在视觉编码器中引入堆叠时序注意力模块的新型Video-LLM架构，大幅提升了模型在视频时序理解和动作识别任务中的表现，超越现有基线。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大模型已有进展，现有Video-LLM在理解视频复杂时序动态（如动作序列、事件发展）上效果有限，因此需要改进模型以提升其时序推理能力。

Method: 作者在视觉编码器内部加入堆叠的时序注意力模块，允许模型在抽取视觉特征时便强化对帧间动作顺序与时序关系的建模，然后再将增强后的视觉token传递给LLM处理。

Result: 新方法在VITATECS、MVBench和Video-MME等基准视频问答和动作识别任务上，有最高5.5%的性能提升，证明其时序推理能力显著优于已有架构。

Conclusion: 通过增强视觉编码器以更好地表征时序结构，成功弥补了现有Video-LLM在复杂视频理解上的不足，为后续多模态视频理解提供了有效的解决方案。

Abstract: Despite significant advances in Multimodal Large Language Models (MLLMs),
understanding complex temporal dynamics in videos remains a major challenge.
Our experiments show that current Video Large Language Model (Video-LLM)
architectures have critical limitations in temporal understanding, struggling
with tasks that require detailed comprehension of action sequences and temporal
progression. In this work, we propose a Video-LLM architecture that introduces
stacked temporal attention modules directly within the vision encoder. This
design incorporates a temporal attention in vision encoder, enabling the model
to better capture the progression of actions and the relationships between
frames before passing visual tokens to the LLM. Our results show that this
approach significantly improves temporal reasoning and outperforms existing
models in video question answering tasks, specifically in action recognition.
We improve on benchmarks including VITATECS, MVBench, and Video-MME by up to
+5.5%. By enhancing the vision encoder with temporal structure, we address a
critical gap in video understanding for Video-LLMs. Project page and code are
available at: https://alirasekh.github.io/STAVEQ2/.

</details>


### [12] [FlexICL: A Flexible Visual In-context Learning Framework for Elbow and Wrist Ultrasound Segmentation](https://arxiv.org/abs/2510.26049)
*Yuyue Zhou,Jessica Knight,Shrimanti Ghosh,Banafshe Felfeliyan,Jacob L. Jaremko,Abhilash R. Hareendranathan*

Main category: cs.CV

TL;DR: 本论文提出了一种名为FlexICL的新型、灵活的上下文学习（ICL）框架，用于超声图像中骨区的自动分割，在标注数据极少的情形下依然表现出色，并优于当前主流方法。


<details>
  <summary>Details</summary>
Motivation: 儿童肘部和腕部骨折常见，超声图像分割能提高诊断与治疗效率，但像素级专家标注成本高。现有分割方法在标注不足时性能有限，急需一种高效且对标注需求低的新方法。

Method: 提出FlexICL，上下文学习框架下只需少量专家标注帧，结合多种图像拼接与数据增强策略，创新性引入新的拼接方法提升有限标签条件下的分割能力，并在四个数据集上进行了系统评估。

Result: FlexICL仅用5%的标注图片，在1252份超声录像数据上，Dice系数比Painter、MAE-VQGAN、U-Net等方法高出1-27%，展现了极佳性能。

Conclusion: FlexICL在有限标注条件下实现了高效自动分割，有望成为解决医学图像标注稀缺问题的可拓展解决方案。

Abstract: Elbow and wrist fractures are the most common fractures in pediatric
populations. Automatic segmentation of musculoskeletal structures in ultrasound
(US) can improve diagnostic accuracy and treatment planning. Fractures appear
as cortical defects but require expert interpretation. Deep learning (DL) can
provide real-time feedback and highlight key structures, helping lightly
trained users perform exams more confidently. However, pixel-wise expert
annotations for training remain time-consuming and costly. To address this
challenge, we propose FlexICL, a novel and flexible in-context learning (ICL)
framework for segmenting bony regions in US images. We apply it to an
intra-video segmentation setting, where experts annotate only a small subset of
frames, and the model segments unseen frames. We systematically investigate
various image concatenation techniques and training strategies for visual ICL
and introduce novel concatenation methods that significantly enhance model
performance with limited labeled data. By integrating multiple augmentation
strategies, FlexICL achieves robust segmentation performance across four wrist
and elbow US datasets while requiring only 5% of the training images. It
outperforms state-of-the-art visual ICL models like Painter, MAE-VQGAN, and
conventional segmentation models like U-Net and TransUNet by 1-27% Dice
coefficient on 1,252 US sweeps. These initial results highlight the potential
of FlexICL as an efficient and scalable solution for US image segmentation well
suited for medical imaging use cases where labeled data is scarce.

</details>


### [13] [Dynamic VLM-Guided Negative Prompting for Diffusion Models](https://arxiv.org/abs/2510.26052)
*Hoyeon Chang,Seungjin Kim,Yoonseok Choi*

Main category: cs.CV

TL;DR: 本文提出了一种在扩散模型中利用视觉-语言模型（VLM）自适应生成负面提示（negative prompts）的新方法，用于改进动态负面提示过程。


<details>
  <summary>Details</summary>
Motivation: 传统的负面提示方法通常采用预先设定的固定提示，难以应对不同图像生成过程中的上下文变化，导致文本与图像对齐度不理想。为此，提出更灵活的动态提示生成机制以提升生成效果。

Method: 方法是在扩散模型的特定去噪步骤中，先生成中间图像预测，再利用视觉-语言模型根据当前上下文自动生成相应的负面提示，从而动态调整生成方向。

Result: 在多个基准数据集上的实验表明，采用该方法可以有效平衡负面引导强度与文本-图像对齐性，提升生成质量。

Conclusion: 该方法展示了动态负面提示的优势，为基于扩散模型的生成任务带来更加灵活与上下文相关的控制手段。

Abstract: We propose a novel approach for dynamic negative prompting in diffusion
models that leverages Vision-Language Models (VLMs) to adaptively generate
negative prompts during the denoising process. Unlike traditional Negative
Prompting methods that use fixed negative prompts, our method generates
intermediate image predictions at specific denoising steps and queries a VLM to
produce contextually appropriate negative prompts. We evaluate our approach on
various benchmark datasets and demonstrate the trade-offs between negative
guidance strength and text-image alignment.

</details>


### [14] [Security Risk of Misalignment between Text and Image in Multi-modal Model](https://arxiv.org/abs/2510.26105)
*Xiaosen Wang,Zhijin Ge,Shaokang Wang*

Main category: cs.CV

TL;DR: 本文揭示了现有多模态扩散模型在文本与图像对齐上的不足，并提出了新型攻击方法PReMA，可仅通过修改输入图像实现对生成内容的操控，特别是在不更改文本提示的前提下生成不安全或不当内容。实验证明，该方法对现有模型具有显著威胁。


<details>
  <summary>Details</summary>
Motivation: 多模态扩散模型（如文本生成图像）近年来取得显著进展，但其对抗攻击的脆弱性和潜在风险尚未充分探讨。尤其是在模型生成内容与输入文本未能有效对齐时，存在生成不适宜（如NSFW）内容的安全隐患。

Method: 作者提出了一种名为Prompt-Restricted Multi-modal Attack（PReMA）的新型攻击方式，核心在于通过修改输入图像（而非更改提示文本），进而操控模型输出生成特定或不当内容。该方法适用于模型在固定文本提示下，需要对内容进行编辑的任务（如图像修复、风格迁移）。

Result: 通过在多个主流扩散模型的图像修复和风格迁移任务上实验证明，PReMA能够在不改变文本提示内容的情况下，有效操控输出并生成NSFW或不恰当内容，显示出现有模型在对抗此类攻击方面的脆弱性。

Conclusion: PReMA攻击方式为当前多模态扩散模型带来了新的安全威胁，特别是在需要高安全保障的图像编辑类应用中，亟需关注和改进模型对抗这类攻击的鲁棒性。

Abstract: Despite the notable advancements and versatility of multi-modal diffusion
models, such as text-to-image models, their susceptibility to adversarial
inputs remains underexplored. Contrary to expectations, our investigations
reveal that the alignment between textual and Image modalities in existing
diffusion models is inadequate. This misalignment presents significant risks,
especially in the generation of inappropriate or Not-Safe-For-Work (NSFW)
content. To this end, we propose a novel attack called Prompt-Restricted
Multi-modal Attack (PReMA) to manipulate the generated content by modifying the
input image in conjunction with any specified prompt, without altering the
prompt itself. PReMA is the first attack that manipulates model outputs by
solely creating adversarial images, distinguishing itself from prior methods
that primarily generate adversarial prompts to produce NSFW content.
Consequently, PReMA poses a novel threat to the integrity of multi-modal
diffusion models, particularly in image-editing applications that operate with
fixed prompts. Comprehensive evaluations conducted on image inpainting and
style transfer tasks across various models confirm the potent efficacy of
PReMA.

</details>


### [15] [EgoExo-Con: Exploring View-Invariant Video Temporal Understanding](https://arxiv.org/abs/2510.26113)
*Minjoon Jung,Junbin Xiao,Junghyun Kim,Byoung-Tak Zhang,Angela Yao*

Main category: cs.CV

TL;DR: 本文研究了Video-LLMs（视频大模型）在多视角下对同一事件的时序一致性理解，并提出了新的数据集EgoExo-Con及强化学习方法View-GRPO来提升一致性表现。


<details>
  <summary>Details</summary>
Motivation: 虽然Video-LLMs在单一视角下取得了良好的效果，但在同一事件的多视角（如主观视角和客观视角）视频理解中是否能保持时序一致性，尚未被系统评估和改进。解决这一问题对于更准确地综合多源视频理解非常重要。

Method: 作者提出了EgoExo-Con基准，包含主客观视角同步视频对及经过人工精炼的问题，用于评测模型在时序验证和时序定位两项任务中的正确性与跨视角一致性。此外，作者提出新的强化学习框架View-GRPO，专为提升模型的视角特异性时序推理与跨视角一致性设计，并与现有的微调和GRPO方法进行了对比。

Result: 实验表明，现有Video-LLMs在跨视角一致性上表现显著落后于其单视角性能。简单联合训练虽然提升了一致性，但单视角表现反而下降。View-GRPO方法更好地兼顾了这两方面，显著提升了跨视角一致性表现。

Conclusion: 当前Video-LLMs在跨视角时序理解上一致性不足，简单合并训练效果有限。提出的EgoExo-Con基准和View-GRPO方法为提升视频理解的跨视角一致性提供了有效手段和评测工具。

Abstract: Can Video-LLMs achieve consistent temporal understanding when videos capture
the same event from different viewpoints? To study this, we introduce
EgoExo-Con (Consistency), a benchmark of comprehensively synchronized
egocentric and exocentric video pairs with human-refined queries in natural
language. EgoExo-Con emphasizes two temporal understanding tasks: Temporal
Verification and Temporal Grounding. It evaluates not only correctness but
consistency across viewpoints. Our analysis reveals two critical limitations of
existing Video-LLMs: (1) models often fail to maintain consistency, with
results far worse than their single-view performances. (2) When naively
finetuned with synchronized videos of both viewpoints, the models show improved
consistency but often underperform those trained on a single view. For
improvements, we propose View-GRPO, a novel reinforcement learning framework
that effectively strengthens view-specific temporal reasoning while encouraging
consistent comprehension across viewpoints. Our method demonstrates its
superiority over naive SFT and GRPO, especially for improving cross-view
consistency. All resources will be made publicly available.

</details>


### [16] [OracleAgent: A Multimodal Reasoning Agent for Oracle Bone Script Research](https://arxiv.org/abs/2510.26114)
*Caoshuo Li,Zengmao Ding,Xiaobin Hu,Bang Li,Donghao Luo,Xu Peng,Taisong Jin,Yongge Liu,Shengwei Han,Jing Yang,Xiaoping He,Feng Gao,AndyPian Wu,SevenShu,Chaoyang Wang,Chengjie Wang*

Main category: cs.CV

TL;DR: 本文提出了OracleAgent系统，这是首个针对甲骨文信息结构化管理与检索的智能体系统，通过多模态知识库与大语言模型的结合，有效提升甲骨文资料管理与研究效率。


<details>
  <summary>Details</summary>
Motivation: 甲骨文作为最早的书写体系之一，代表着古代文明的重要文化与智慧遗产。但当前甲骨文研究面临解释流程复杂及信息检索效率低下等两大挑战。研究者需耗费大量精力在资源的查找、整理与管理上，极大限制了学术进展。

Method: 作者构建了OracleAgent系统，整合多种甲骨文分析工具并由大语言模型驱动，支持灵活协调多任务。同时，系统包含一个专门的领域多模态知识库，数据来源涉及经过专家标注和清洗的140万单字拓片图像及8万余条释文，为甲骨文图像、文本及释意的高效检索提供了基础。

Result: 实验表明，OracleAgent在多模态推理与生成任务上的表现优于主流多模态大模型，如GPT-4o。案例研究展示该系统能够有效支持领域专家，大幅减少甲骨文研究的时间成本。

Conclusion: OracleAgent在甲骨文研究和自动化释读系统的实用部署方面迈出了重要一步，为相关领域的高效研究与管理提供了有力工具。

Abstract: As one of the earliest writing systems, Oracle Bone Script (OBS) preserves
the cultural and intellectual heritage of ancient civilizations. However,
current OBS research faces two major challenges: (1) the interpretation of OBS
involves a complex workflow comprising multiple serial and parallel sub-tasks,
and (2) the efficiency of OBS information organization and retrieval remains a
critical bottleneck, as scholars often spend substantial effort searching for,
compiling, and managing relevant resources. To address these challenges, we
present OracleAgent, the first agent system designed for the structured
management and retrieval of OBS-related information. OracleAgent seamlessly
integrates multiple OBS analysis tools, empowered by large language models
(LLMs), and can flexibly orchestrate these components. Additionally, we
construct a comprehensive domain-specific multimodal knowledge base for OBS,
which is built through a rigorous multi-year process of data collection,
cleaning, and expert annotation. The knowledge base comprises over 1.4M
single-character rubbing images and 80K interpretation texts. OracleAgent
leverages this resource through its multimodal tools to assist experts in
retrieval tasks of character, document, interpretation text, and rubbing image.
Extensive experiments demonstrate that OracleAgent achieves superior
performance across a range of multimodal reasoning and generation tasks,
surpassing leading mainstream multimodal large language models (MLLMs) (e.g.,
GPT-4o). Furthermore, our case study illustrates that OracleAgent can
effectively assist domain experts, significantly reducing the time cost of OBS
research. These results highlight OracleAgent as a significant step toward the
practical deployment of OBS-assisted research and automated interpretation
systems.

</details>


### [17] [JOGS: Joint Optimization of Pose Estimation and 3D Gaussian Splatting](https://arxiv.org/abs/2510.26117)
*Yuxuan Li,Tao Wang,Xianben Yang*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的无须外部相机位姿估计工具的三维重建与新视图合成方法，通过联合优化三维高斯点和相机位姿，既提升了重建质量，也提升了位姿精度。


<details>
  <summary>Details</summary>
Motivation: 传统的新视图合成严重依赖于诸如COLMAP之类的外部相机位姿估计工具，这导致算法在计算上低效且容易因位姿误差影响整体复原效果。为了解决这些瓶颈，提出无需事先标定输入的统一联合优化框架。

Method: 方法采用联合优化策略，将三维高斯参数的迭代细化与相机位姿更新交替进行。具体包括：1）在位姿固定时通过可微渲染优化三维高斯点参数；2）利用结合几何与光度约束的定制3D光流算法更新相机位姿。通过两阶段交替，有效减少投影误差。

Result: 在多个公开数据集上进行评估，该方法无论是在重建质量还是位姿精度上，都显著优于现有不依赖COLMAP的方法，并且整体表现也超过了标准的基于COLMAP的基线方法。

Conclusion: 提出的联合优化框架无需外部位姿估计工具，能够有效提升三维重建和新视图合成质量，特别适用于大视角变化或特征稀疏的应用场景，在同类方法中取得了领先效果。

Abstract: Traditional novel view synthesis methods heavily rely on external camera pose
estimation tools such as COLMAP, which often introduce computational
bottlenecks and propagate errors. To address these challenges, we propose a
unified framework that jointly optimizes 3D Gaussian points and camera poses
without requiring pre-calibrated inputs. Our approach iteratively refines 3D
Gaussian parameters and updates camera poses through a novel co-optimization
strategy, ensuring simultaneous improvements in scene reconstruction fidelity
and pose accuracy. The key innovation lies in decoupling the joint optimization
into two interleaved phases: first, updating 3D Gaussian parameters via
differentiable rendering with fixed poses, and second, refining camera poses
using a customized 3D optical flow algorithm that incorporates geometric and
photometric constraints. This formulation progressively reduces projection
errors, particularly in challenging scenarios with large viewpoint variations
and sparse feature distributions, where traditional methods struggle. Extensive
evaluations on multiple datasets demonstrate that our approach significantly
outperforms existing COLMAP-free techniques in reconstruction quality, and also
surpasses the standard COLMAP-based baseline in general.

</details>


### [18] [WOD-E2E: Waymo Open Dataset for End-to-End Driving in Challenging Long-tail Scenarios](https://arxiv.org/abs/2510.26125)
*Runsheng Xu,Hubert Lin,Wonseok Jeon,Hao Feng,Yuliang Zou,Liting Sun,John Gorman,Kate Tolstaya,Sarah Tang,Brandyn White,Ben Sapp,Mingxing Tan,Jyh-Jing Hwang,Drago Anguelov*

Main category: cs.CV

TL;DR: 本文提出了WOD-E2E数据集和RFS评估指标，用于提升端到端自动驾驶系统在稀有复杂场景下的研究与评测。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端自动驾驶基准往往只涵盖常见场景，难以检验系统在稀有复杂（long-tail）场景下的表现。此外，主流的评估指标不能有效反映驾驶的多模态特性及在长尾场景下的能力。

Method: 作者构建了WOD-E2E数据集，包含4021段驾驶片段（约12小时），专为低频（<0.03%）的长尾场景设计。数据集包含高层次路径信息、车辆状态及8个摄像头的360度视图。并提出Rater Feedback Score（RFS）作为新评估指标，依据人工标注偏好轨迹对模型输出进行评分。

Result: 数据集及评测指标已发布，RFS标注覆盖验证集，并应用于WOD-E2E挑战。RFS能够更好地反映E2E模型在复杂场景下的真实能力。

Conclusion: WOD-E2E及RFS将推动E2E自动驾驶系统在通用性、鲁棒性和安全性方面的进步，促进其处理真实世界复杂场景的能力。

Abstract: Vision-based end-to-end (E2E) driving has garnered significant interest in
the research community due to its scalability and synergy with multimodal large
language models (MLLMs). However, current E2E driving benchmarks primarily
feature nominal scenarios, failing to adequately test the true potential of
these systems. Furthermore, existing open-loop evaluation metrics often fall
short in capturing the multi-modal nature of driving or effectively evaluating
performance in long-tail scenarios. To address these gaps, we introduce the
Waymo Open Dataset for End-to-End Driving (WOD-E2E). WOD-E2E contains 4,021
driving segments (approximately 12 hours), specifically curated for challenging
long-tail scenarios that that are rare in daily life with an occurring
frequency of less than 0.03%. Concretely, each segment in WOD-E2E includes the
high-level routing information, ego states, and 360-degree camera views from 8
surrounding cameras. To evaluate the E2E driving performance on these long-tail
situations, we propose a novel open-loop evaluation metric: Rater Feedback
Score (RFS). Unlike conventional metrics that measure the distance between
predicted way points and the logs, RFS measures how closely the predicted
trajectory matches rater-annotated trajectory preference labels. We have
released rater preference labels for all WOD-E2E validation set segments, while
the held out test set labels have been used for the 2025 WOD-E2E Challenge.
Through our work, we aim to foster state of the art research into
generalizable, robust, and safe end-to-end autonomous driving agents capable of
handling complex real-world situations.

</details>


### [19] [Exploring Object-Aware Attention Guided Frame Association for RGB-D SLAM](https://arxiv.org/abs/2510.26131)
*Ali Caglayan,Nevrez Imamoglu,Oguzhan Guclu,Ali Osman Serhatoglu,Ahmet Burak Can,Ryosuke Nakamura*

Main category: cs.CV

TL;DR: 本文提出将基于梯度的注意力信息与CNN特征结合，用于提升RGB-D室内SLAM中的帧关联，实验显示较基线方法有显著提升。


<details>
  <summary>Details</summary>
Motivation: 尽管基于梯度的注意力可视化对理解CNN有帮助，但这些信息很少直接集成到CNN表征中用于实际视觉任务。本研究希望将注意力信息直接用于提升SLAM任务表现。

Method: 将从网络梯度获得的分层注意力信息与CNN特征融合，用以增强RGB-D室内SLAM中帧关联准确性。

Result: 方法在实验中相较基线显著提升了帧关联，尤其在大场景环境中优势明显。

Conclusion: 集成注意力信息能有效提升SLAM性能，尤其对复杂、大规模场景具备实际价值。

Abstract: Attention models have recently emerged as a powerful approach, demonstrating
significant progress in various fields. Visualization techniques, such as class
activation mapping, provide visual insights into the reasoning of convolutional
neural networks (CNNs). Using network gradients, it is possible to identify
regions where the network pays attention during image recognition tasks.
Furthermore, these gradients can be combined with CNN features to localize more
generalizable, task-specific attentive (salient) regions within scenes.
However, explicit use of this gradient-based attention information integrated
directly into CNN representations for semantic object understanding remains
limited. Such integration is particularly beneficial for visual tasks like
simultaneous localization and mapping (SLAM), where CNN representations
enriched with spatially attentive object locations can enhance performance. In
this work, we propose utilizing task-specific network attention for RGB-D
indoor SLAM. Specifically, we integrate layer-wise attention information
derived from network gradients with CNN feature representations to improve
frame association performance. Experimental results indicate improved
performance compared to baseline methods, particularly for large environments.

</details>


### [20] [FullPart: Generating each 3D Part at Full Resolution](https://arxiv.org/abs/2510.26140)
*Lihe Ding,Shaocong Dong,Yaokun Li,Chenjian Gao,Xiao Chen,Rui Han,Yihao Kuang,Hong Zhang,Bo Huang,Zhanpeng Huang,Zibin Wang,Dan Xu,Tianfan Xue*

Main category: cs.CV

TL;DR: FullPart是一种结合隐式和显式方法的3D部件生成框架，每个部件在全分辨率体素空间中单独生成，保留精细细节，同时解决了现有方法在小部件表现和整体一致性上的不足，达到了3D部件生成的最新水平。


<details>
  <summary>Details</summary>
Motivation: 现有3D部件生成方法要么隐式表示部件导致细节丢失，要么共享全局体素网格导致小部件细节不足，因此需要一种既能保留细节又能兼顾全局和局部一致性的方案。

Method: 提出FullPart框架，先采用隐式扩散获得部件包围盒布局，再对每个部件分别在独立的全分辨率体素网格中生成精细结构；通过中心点编码策略解决部件大小差异带来的对齐问题，并构建了最大的人类注释3D部件数据集PartVerse-XL。

Result: FullPart在数据集上大幅优于现有方法，实验验证其在细节表达和整体一致性方面都表现优异，达到了3D部件生成领域的最新水平。

Conclusion: FullPart有效融合了隐式和显式3D生成方法，克服了过往方法在精细度与统一性上的难题，并随着PartVerse-XL的发布，将推动后续3D部件生成研究发展。

Abstract: Part-based 3D generation holds great potential for various applications.
Previous part generators that represent parts using implicit vector-set tokens
often suffer from insufficient geometric details. Another line of work adopts
an explicit voxel representation but shares a global voxel grid among all
parts; this often causes small parts to occupy too few voxels, leading to
degraded quality. In this paper, we propose FullPart, a novel framework that
combines both implicit and explicit paradigms. It first derives the bounding
box layout through an implicit box vector-set diffusion process, a task that
implicit diffusion handles effectively since box tokens contain little
geometric detail. Then, it generates detailed parts, each within its own fixed
full-resolution voxel grid. Instead of sharing a global low-resolution space,
each part in our method - even small ones - is generated at full resolution,
enabling the synthesis of intricate details. We further introduce a
center-point encoding strategy to address the misalignment issue when
exchanging information between parts of different actual sizes, thereby
maintaining global coherence. Moreover, to tackle the scarcity of reliable part
data, we present PartVerse-XL, the largest human-annotated 3D part dataset to
date with 40K objects and 320K parts. Extensive experiments demonstrate that
FullPart achieves state-of-the-art results in 3D part generation. We will
release all code, data, and model to benefit future research in 3D part
generation.

</details>


### [21] [BasicAVSR: Arbitrary-Scale Video Super-Resolution via Image Priors and Enhanced Motion Compensation](https://arxiv.org/abs/2510.26149)
*Wei Shang,Wanying Zhang,Shuhang Gu,Pengfei Zhu,Qinghua Hu,Dongwei Ren*

Main category: cs.CV

TL;DR: 本文提出了一种针对任意比例视频超分辨率（AVSR）任务的新基线方法BasicAVSR，通过引入多个关键模块，显著提升了增强效果、泛化能力和推理速度，在多个应用场景均取得优越性能。


<details>
  <summary>Details</summary>
Motivation: AVSR需要在不同放大比例下提升视频分辨率，但存在空间细节、时间一致性及计算复杂度等挑战，现有方法难以兼顾多方面需求，亟需稳定且高效的通用解决方案。

Method: BasicAVSR集成了四大关键组件：1）基于Laplacian金字塔自适应多尺度频率先验；2）基于光流的时空信息聚合单元；3）二阶运动补偿单元以优化帧间对齐；4）超上采样单元以自适应生成放大核。同时，设计了三种传播单元（严格在线、有限延迟在线、离线），适应不同应用需求。

Result: 大量实验表明，BasicAVSR在超级分辨率质量、泛化能力和推理速度上均优于现有同类方法，并在多种推理场景下表现出良好适应性。

Conclusion: BasicAVSR为任意比例视频超分辨率提供了强大基线，不仅推进了该领域的最新水平，其核心组件也能灵活适配于多种框架，满足不同实际场景需求。

Abstract: Arbitrary-scale video super-resolution (AVSR) aims to enhance the resolution
of video frames, potentially at various scaling factors, which presents several
challenges regarding spatial detail reproduction, temporal consistency, and
computational complexity. In this paper, we propose a strong baseline BasicAVSR
for AVSR by integrating four key components: 1) adaptive multi-scale frequency
priors generated from image Laplacian pyramids, 2) a flow-guided propagation
unit to aggregate spatiotemporal information from adjacent frames, 3) a
second-order motion compensation unit for more accurate spatial alignment of
adjacent frames, and 4) a hyper-upsampling unit to generate scale-aware and
content-independent upsampling kernels. To meet diverse application demands, we
instantiate three propagation variants: (i) a unidirectional RNN unit for
strictly online inference, (ii) a unidirectional RNN unit empowered with a
limited lookahead that tolerates a small output delay, and (iii) a
bidirectional RNN unit designed for offline tasks where computational resources
are less constrained. Experimental results demonstrate the effectiveness and
adaptability of our model across these different scenarios. Through extensive
experiments, we show that BasicAVSR significantly outperforms existing methods
in terms of super-resolution quality, generalization ability, and inference
speed. Our work not only advances the state-of-the-art in AVSR but also extends
its core components to multiple frameworks for diverse scenarios. The code is
available at https://github.com/shangwei5/BasicAVSR.

</details>


### [22] [MV-MLM: Bridging Multi-View Mammography and Language for Breast Cancer Diagnosis and Risk Prediction](https://arxiv.org/abs/2510.26151)
*Shunjie-Fabian Zheng,Hyeonjun Lee,Thijs Kooi,Ali Diba*

Main category: cs.CV

TL;DR: 本文提出了一种结合多视角乳腺钼靶影像与语言模型的新方法，用于乳腺癌的分类和风险预测，利用合成放射学报告提高数据利用效率，实现性能领先。


<details>
  <summary>Details</summary>
Motivation: 现有乳腺癌计算机辅助诊断（CAD）模型需大量精细标注数据，实际操作中获取此类高质量数据成本高、耗时长，因此需要寻找更高效的数据利用与泛化方法。

Method: 提出了一种多视角乳腺钼靶影像-语言模型（MV-MLM），以成对的乳腺影像与合成放射学报告作为训练数据，通过跨模态自监督机制和视觉-文本联合学习策略，学习丰富的乳腺影像表征，提升模型在不同任务与数据类型下的表现。

Result: 在私有和公开数据集上验证了方法的有效性，在恶性肿瘤分类、亚型分类和基于影像的风险预测三大任务中均达到了当前最优性能，同时模型在数据利用效率方面表现突出，甚至无需真实放射学报告即可超越现有方法。

Conclusion: 多视角乳腺钼靶影像与合成文本联合自监督学习具有提升乳腺癌CAD模型效果、降低标注成本的潜力，为医学影像AI提供了有效的新方案。

Abstract: Large annotated datasets are essential for training robust Computer-Aided
Diagnosis (CAD) models for breast cancer detection or risk prediction. However,
acquiring such datasets with fine-detailed annotation is both costly and
time-consuming. Vision-Language Models (VLMs), such as CLIP, which are
pre-trained on large image-text pairs, offer a promising solution by enhancing
robustness and data efficiency in medical imaging tasks. This paper introduces
a novel Multi-View Mammography and Language Model for breast cancer
classification and risk prediction, trained on a dataset of paired mammogram
images and synthetic radiology reports. Our MV-MLM leverages multi-view
supervision to learn rich representations from extensive radiology data by
employing cross-modal self-supervision across image-text pairs. This includes
multiple views and the corresponding pseudo-radiology reports. We propose a
novel joint visual-textual learning strategy to enhance generalization and
accuracy performance over different data types and tasks to distinguish breast
tissues or cancer characteristics(calcification, mass) and utilize these
patterns to understand mammography images and predict cancer risk. We evaluated
our method on both private and publicly available datasets, demonstrating that
the proposed model achieves state-of-the-art performance in three
classification tasks: (1) malignancy classification, (2) subtype
classification, and (3) image-based cancer risk prediction. Furthermore, the
model exhibits strong data efficiency, outperforming existing fully supervised
or VLM baselines while trained on synthetic text reports and without the need
for actual radiology reports.

</details>


### [23] [Detecting Unauthorized Vehicles using Deep Learning for Smart Cities: A Case Study on Bangladesh](https://arxiv.org/abs/2510.26154)
*Sudipto Das Sukanto,Diponker Roy,Fahim Shakil,Nirjhar Singha,Abdullah Asik,Aniket Joarder,Mridha Md Nafis Fuad,Muhammad Ibrahim*

Main category: cs.CV

TL;DR: 本文提出了一种基于机器学习的自动检测交通图像中自动人力车（auto-rickshaw）的方法，采用YOLOv8模型实现了较高的检测精度。


<details>
  <summary>Details</summary>
Motivation: 孟加拉等南亚国家的城市常见人力车，由于交通规则限制，需监控自动人力车，但现有系统难以区分自动与非自动人力车，人工分析繁琐，亟需自动化检测方法。

Method: 使用YOLOv8实时目标检测模型，对1730张不同交通状态下采集并注释的图像进行训练，实现自动人力车检测。

Result: 提出的方法在实时检测中表现良好，mAP50达83.447%，二元精度与召回均超78%，能有效应对高密度与稀疏交通场景。

Conclusion: 所提方法实现了高效、精确的自动人力车检测，相关数据集已公开，为后续研究提供基础。

Abstract: Modes of transportation vary across countries depending on geographical
location and cultural context. In South Asian countries rickshaws are among the
most common means of local transport. Based on their mode of operation,
rickshaws in cities across Bangladesh can be broadly classified into non-auto
(pedal-powered) and auto-rickshaws (motorized). Monitoring the movement of
auto-rickshaws is necessary as traffic rules often restrict auto-rickshaws from
accessing certain routes. However, existing surveillance systems make it quite
difficult to monitor them due to their similarity to other vehicles, especially
non-auto rickshaws whereas manual video analysis is too time-consuming. This
paper presents a machine learning-based approach to automatically detect
auto-rickshaws in traffic images. In this system, we used real-time object
detection using the YOLOv8 model. For training purposes, we prepared a set of
1,730 annotated images that were captured under various traffic conditions. The
results show that our proposed model performs well in real-time auto-rickshaw
detection and offers an mAP50 of 83.447% and binary precision and recall values
above 78%, demonstrating its effectiveness in handling both dense and sparse
traffic scenarios. The dataset has been publicly released for further research.

</details>


### [24] [CRAG-MM: Multi-modal Multi-turn Comprehensive RAG Benchmark](https://arxiv.org/abs/2510.26160)
*Jiaqi Wang,Xiao Yang,Kai Sun,Parth Suresh,Sanat Sharma,Adam Czyzewski,Derek Andersen,Surya Appini,Arkav Banerjee,Sajal Choudhary,Shervin Ghasemlou,Ziqiang Guan,Akil Iyer,Haidar Khan,Lingkun Kong,Roy Luo,Tiffany Ma,Zhen Qiao,David Tran,Wenfang Xu,Skyler Yeatman,Chen Zhou,Gunveer Gujral,Yinglong Xia,Shane Moon,Nicolas Scheffer,Nirav Shah,Eun Chang,Yue Liu,Florian Metze,Tammy Stark,Zhaleh Feizollahi,Andrea Jessee,Mangesh Pujari,Ahmed Aly,Babak Damavandi,Rakesh Wanga,Anuj Kumar,Rohit Patel,Wen-tau Yih,Xin Luna Dong*

Main category: cs.CV

TL;DR: 本文提出了首个面向可穿戴设备场景的多模态多轮对话RAG基准数据集CRAG-MM，并评估了现有检索增强生成模型在该数据集上的表现，发现仍有显著提升空间。


<details>
  <summary>Details</summary>
Motivation: 随着可穿戴设备（如智能眼镜）普及，用户需通过设备获取视野中物体的信息，然而当前针对多模态检索增强生成的系统缺乏系统性的测试基准。

Method: 作者构建了包含6500组图片-问题-答案三元组、2000组基于视觉的多轮对话、跨13个领域及6200张模拟可穿戴设备视角图片的大型数据集。问题设计涵盖多种真实场景挑战，并定义了三类任务：单源增强、多源增强、多轮对话，为图像知识库检索和网页检索都提供API。

Result: 基准测试结果显示，现有RAG方法在该数据集上的真实性仅为32%（单轮）、43%（多轮），业界最先进方法表现亦相近，表明任务难度大。KDD Cup 2025赛事有效推动了方法进步，获胜方案将表现提升了28%。

Conclusion: CRAG-MM为多模态RAG领域尤其是可穿戴设备应用提供了丰富而具挑战性的测试平台，未来还有广阔的提升空间，预计将持续促进该领域技术发展。

Abstract: Wearable devices such as smart glasses are transforming the way people
interact with their surroundings, enabling users to seek information regarding
entities in their view. Multi-Modal Retrieval-Augmented Generation (MM-RAG)
plays a key role in supporting such questions, yet there is still no
comprehensive benchmark for this task, especially regarding wearables
scenarios. To fill this gap, we present CRAG-MM -- a Comprehensive RAG
benchmark for Multi-modal Multi-turn conversations. CRAG-MM contains a diverse
set of 6.5K (image, question, answer) triplets and 2K visual-based multi-turn
conversations across 13 domains, including 6.2K egocentric images designed to
mimic captures from wearable devices. We carefully constructed the questions to
reflect real-world scenarios and challenges, including five types of
image-quality issues, six question types, varying entity popularity, differing
information dynamism, and different conversation turns. We design three tasks:
single-source augmentation, multi-source augmentation, and multi-turn
conversations -- each paired with an associated retrieval corpus and APIs for
both image-KG retrieval and webpage retrieval. Our evaluation shows that
straightforward RAG approaches achieve only 32% and 43% truthfulness on CRAG-MM
single- and multi-turn QA, respectively, whereas state-of-the-art industry
solutions have similar quality (32%/45%), underscoring ample room for
improvement. The benchmark has hosted KDD Cup 2025, attracting about 1K
participants and 5K submissions, with winning solutions improving baseline
performance by 28%, highlighting its early impact on advancing the field.

</details>


### [25] [MoTDiff: High-resolution Motion Trajectory estimation from a single blurred image using Diffusion models](https://arxiv.org/abs/2510.26173)
*Wontae Choi,Jaelin Lee,Hyung Sup Yun,Byeungwoo Jeon,Il Yong Chun*

Main category: cs.CV

TL;DR: 本论文提出了使用扩散模型（MoTDiff）从单张运动模糊图像中高分辨率估计运动轨迹的新方法，并且结果优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有单张图像运动信息提取方法（如模糊核、光流）估计结果质量较低且不够精细。对于计算成像和计算机视觉等应用，提升运动估计的精度具有重要意义。

Method: 方法包括两大创新：1）利用单张模糊图像的多尺度特征图作为条件的条件扩散模型框架；2）提出新的训练方式，提升运动轨迹的精细、连通和全局形状位置一致性估计能力。

Result: 实验显示MoTDiff在盲去模糊和编码曝光摄影等任务中优于当前最先进的方法。

Conclusion: MoTDiff能高质量地从单张运动模糊图像恢复精细的高分辨率运动轨迹，并推动相关领域的进步。

Abstract: Accurate estimation of motion information is crucial in diverse computational
imaging and computer vision applications. Researchers have investigated various
methods to extract motion information from a single blurred image, including
blur kernels and optical flow. However, existing motion representations are
often of low quality, i.e., coarse-grained and inaccurate. In this paper, we
propose the first high-resolution (HR) Motion Trajectory estimation framework
using Diffusion models (MoTDiff). Different from existing motion
representations, we aim to estimate an HR motion trajectory with high-quality
from a single motion-blurred image. The proposed MoTDiff consists of two key
components: 1) a new conditional diffusion framework that uses multi-scale
feature maps extracted from a single blurred image as a condition, and 2) a new
training method that can promote precise identification of a fine-grained
motion trajectory, consistent estimation of overall shape and position of a
motion path, and pixel connectivity along a motion trajectory. Our experiments
demonstrate that the proposed MoTDiff can outperform state-of-the-art methods
in both blind image deblurring and coded exposure photography applications.

</details>


### [26] [ConceptScope: Characterizing Dataset Bias via Disentangled Visual Concepts](https://arxiv.org/abs/2510.26186)
*Jinho Choi,Hyesu Lim,Steffen Schneider,Jaegul Choo*

Main category: cs.CV

TL;DR: 该论文提出了ConceptScope框架，用于自动发现、量化视觉数据集中的可解释概念，从而识别和分析数据集偏差，无需昂贵的属性标注。


<details>
  <summary>Details</summary>
Motivation: 机器学习数据集普遍存在数据偏差，传统方法需大量细粒度的属性标注，识别偏差代价高昂，因此需要一种自动化、可扩展的方法来识别和量化这些概念和偏差。

Method: 作者提出了ConceptScope框架，该框架利用稀疏自编码器在视觉基础模型的表示上训练，自动发现人类可解释的概念。然后根据概念与标签的语义相关性和统计相关性，将概念归类为目标、环境和偏差类型，实现对数据集的类别级描述、偏差识别和基于概念的分组评估。

Result: ConceptScope可捕捉不同类型的视觉概念（如物体、纹理、背景、面部属性、情感和动作），概念激活与图像中具有语义意义的区域有空间一致性。该方法不仅能检测已知偏差，还能发现未标注的新偏差，并已在多个公开数据集上验证有效性。

Conclusion: ConceptScope为视觉数据集的审计和模型诊断提供了一种实用、可扩展的工具，无需额外标注即可识别和分析数据集偏差。

Abstract: Dataset bias, where data points are skewed to certain concepts, is ubiquitous
in machine learning datasets. Yet, systematically identifying these biases is
challenging without costly, fine-grained attribute annotations. We present
ConceptScope, a scalable and automated framework for analyzing visual datasets
by discovering and quantifying human-interpretable concepts using Sparse
Autoencoders trained on representations from vision foundation models.
ConceptScope categorizes concepts into target, context, and bias types based on
their semantic relevance and statistical correlation to class labels, enabling
class-level dataset characterization, bias identification, and robustness
evaluation through concept-based subgrouping. We validate that ConceptScope
captures a wide range of visual concepts, including objects, textures,
backgrounds, facial attributes, emotions, and actions, through comparisons with
annotated datasets. Furthermore, we show that concept activations produce
spatial attributions that align with semantically meaningful image regions.
ConceptScope reliably detects known biases (e.g., background bias in
Waterbirds) and uncovers previously unannotated ones (e.g, co-occurring objects
in ImageNet), offering a practical tool for dataset auditing and model
diagnostics.

</details>


### [27] [Sketch2PoseNet: Efficient and Generalized Sketch to 3D Human Pose Prediction](https://arxiv.org/abs/2510.26196)
*Li Wang,Yiyu Zhuang,Yanwen Wang,Xun Cao,Chuan Guo,Xinxin Zuo,Hao Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种利用“合成学习”策略的三维人体姿态估计方法，可直接从草图中高效准确地恢复3D人体姿态，并显著优于已有方法。


<details>
  <summary>Details</summary>
Motivation: 由于草图具有抽象、比例失衡等特点，传统的人体姿态估计方法难以直接应用。现有草图-姿态方法受限于标注数据稀缺，大多依赖规则优化，效率低，泛化性差，因此需要新的解决方案。

Method: 首先，用扩散模型从投影的2D姿态合成带有不同比例和风格的草图图像，与3D姿态配对，构建了大规模合成数据集SKEP-120K。基于该数据集，提出端到端的数据驱动框架，结合2D姿态检测、扩散模型特征、前馈神经网络与启发式损失函数，保证3D-2D一致性和自接触准确性，从多种草图风格中高效估算3D姿态和形状。

Result: 实验包括定性、定量和主观评测，实际结果表明该方法在精度和速度两方面都大幅领先现有草图-姿态估计方法。

Conclusion: 利用合成数据和扩散模型，实现了草图向三维姿态和形状恢复的高效、准确的新方法，为动画、影视等场景的人机交互带来更具实用价值的技术基础。

Abstract: 3D human pose estimation from sketches has broad applications in computer
animation and film production. Unlike traditional human pose estimation, this
task presents unique challenges due to the abstract and disproportionate nature
of sketches. Previous sketch-to-pose methods, constrained by the lack of
large-scale sketch-3D pose annotations, primarily relied on optimization with
heuristic rules-an approach that is both time-consuming and limited in
generalizability. To address these challenges, we propose a novel approach
leveraging a "learn from synthesis" strategy. First, a diffusion model is
trained to synthesize sketch images from 2D poses projected from 3D human
poses, mimicking disproportionate human structures in sketches. This process
enables the creation of a synthetic dataset, SKEP-120K, consisting of 120k
accurate sketch-3D pose annotation pairs across various sketch styles. Building
on this synthetic dataset, we introduce an end-to-end data-driven framework for
estimating human poses and shapes from diverse sketch styles. Our framework
combines existing 2D pose detectors and generative diffusion priors for sketch
feature extraction with a feed-forward neural network for efficient 2D pose
estimation. Multiple heuristic loss functions are incorporated to guarantee
geometric coherence between the derived 3D poses and the detected 2D poses
while preserving accurate self-contacts. Qualitative, quantitative, and
subjective evaluations collectively show that our model substantially surpasses
previous ones in both estimation accuracy and speed for sketch-to-pose tasks.

</details>


### [28] [Developing a Multi-task Ensemble Geometric Deep Network for Supply Chain Sustainability and Risk Management](https://arxiv.org/abs/2510.26203)
*Mehdi Khaleghi,Nastaran Khaleghi,Sobhan Sheykhivand,Sebelan Danishvar*

Main category: cs.CV

TL;DR: 论文提出了一种新型Chebyshev集成几何深度网络（Ch-EGN），该方法在供应链风险管理与产品分类中取得显著效果，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 供应链可持续性是提升管理和效率的关键，而风险管理和产品正确分类是其核心难题。随着深度网络技术发展，如何利用最新的深度学习架构高效分析供应链数据成为研究热点。

Method: 提出融合卷积与几何深度学习的Chebyshev集成网络（Ch-EGN），用于从供应链数据库发掘数据样本的隐含状态，并在SupplyGraph与DataCo两个数据库上进行交付状态预测、产品与边分类实验。

Result: Ch-EGN网络在风险管理中的平均准确率为98.95%；对5类产品和4类产品关系的分类准确率分别达到100%和98.07%；25类公司关系分类准确率为92.37%。各项结果均优于现有最优方法。

Conclusion: 所提方法在供应链风险管理和可持续性层面展现出更优的性能和效率，能够为实际中的供应链管理带来价值提升。

Abstract: The sustainability of supply chain plays a key role in achieving optimal
performance in controlling the supply chain. The management of risks that occur
in a supply chain is a fundamental problem for the purpose of developing the
sustainability of the network and elevating the performance efficiency of the
supply chain. The correct classification of products is another essential
element in a sustainable supply chain. Acknowledging recent breakthroughs in
the context of deep networks, several architectural options have been deployed
to analyze supply chain datasets. A novel geometric deep network is used to
propose an ensemble deep network. The proposed Chebyshev ensemble geometric
network (Ch-EGN) is a hybrid convolutional and geometric deep learning. This
network is proposed to leverage the information dependencies in supply chain to
derive invisible states of samples in the database. The functionality of the
proposed deep network is assessed on the two different databases. The
SupplyGraph Dataset and DataCo are considered in this research. The prediction
of delivery status of DataCo supply chain is done for risk administration. The
product classification and edge classification are performed using the
SupplyGraph database to enhance the sustainability of the supply network. An
average accuracy of 98.95% is obtained for the ensemble network for risk
management. The average accuracy of 100% and 98.07% are obtained for
sustainable supply chain in terms of 5 product group classification and 4
product relation classification, respectively. The average accuracy of 92.37%
is attained for 25 company relation classification. The results confirm an
average improvement and efficiency of the proposed method compared to the
state-of-the-art approaches.

</details>


### [29] [OmniLayout: Enabling Coarse-to-Fine Learning with LLMs for Universal Document Layout Generation](https://arxiv.org/abs/2510.26213)
*Hengrui Kang,Zhuangcheng Gu,Zhiyuan Zhao,Zichen Wen,Bin Wang,Weijia Li,Conghui He*

Main category: cs.CV

TL;DR: 本文提出了首个百万级多样化文档布局数据集OmniLayout-1M，并基于此开发了两阶段Coarse-to-Fine学习范式的OmniLayout-LLM模型，实现了跨多领域的先进文档布局生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有文档AI研究集中在布局分析（DLA），而文档布局生成领域研究较少，主要受制于缺乏多样化布局数据集，尤其是开域如杂志、报纸等类型严重短缺。

Method: 作者构建了OmniLayout-1M数据集，包含六类常见文档类型的百万级丰富布局样本；同时提出OmniLayout-LLM模型，采用两阶段Coarse-to-Fine学习：先用数据集中粗粒度类别通用规则进行预训练，再用特定领域的细粒度标注进行微调。

Result: 在M$^{6}$Doc等多个数据集上，所提方法在布局生成任务上的表现显著优于已知布局生成专家方法和最新通用大模型。

Conclusion: OmniLayout-1M和OmniLayout-LLM为文档布局生成开辟了新途径，提升了多领域布局生成能力，有助于文档AI发展。数据、模型及代码将开源。

Abstract: Document AI has advanced rapidly and is attracting increasing attention. Yet,
while most efforts have focused on document layout analysis (DLA), its
generative counterpart, document layout generation, remains underexplored. A
major obstacle lies in the scarcity of diverse layouts: academic papers with
Manhattan-style structures dominate existing studies, while open-world genres
such as newspapers and magazines remain severely underrepresented. To address
this gap, we curate OmniLayout-1M, the first million-scale dataset of diverse
document layouts, covering six common document types and comprising
contemporary layouts collected from multiple sources. Moreover, since existing
methods struggle in complex domains and often fail to arrange long sequences
coherently, we introduce OmniLayout-LLM, a 0.5B model with designed two-stage
Coarse-to-Fine learning paradigm: 1) learning universal layout principles from
OmniLayout-1M with coarse category definitions, and 2) transferring the
knowledge to a specific domain with fine-grained annotations. Extensive
experiments demonstrate that our approach achieves strong performance on
multiple domains in M$^{6}$Doc dataset, substantially surpassing both existing
layout generation experts and several latest general-purpose LLMs. Our code,
models, and dataset will be publicly released.

</details>


### [30] [On Robustness of Vision-Language-Action Model against Multi-Modal Perturbations](https://arxiv.org/abs/2510.00037)
*Jianing Guo,Zhenhong Wu,Chang Tu,Yiyao Ma,Xiangqi Kong,Zhiqian Liu,Jiaming Ji,Shuning Zhang,Yuanpei Chen,Kai Chen,Qi Dou,Yaodong Yang,Xianglong Liu,Huijie Zhao,Weifeng Lv,Simin Li*

Main category: cs.CV

TL;DR: 本文提出了RobustVLA方法，以提高视觉-语言-动作（VLA）模型在多模态扰动下的鲁棒性，并在17种扰动和多个模态下进行了全面验证。结果显示新方法优于现有VLA系统，尤其在机器人真实场景下表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型主要关注视觉扰动，却忽视了动作、指令、环境和观察等多模态可能面临的扰动，因此其在真实世界部署时的鲁棒性不足。本文旨在解决这一问题。

Method: 作者首先系统性评估了主流VLA模型在17种扰动和四种模态下的性能。提出RobustVLA，通过对输出进行离线鲁棒优化（用于对抗最坏情况的动作扰动）和对输入进行鲁棒训练（保持语义一致动作），同时将多扰动鲁棒性建模为多臂赌博机问题，利用置信上限算法自动识别最有害噪声。

Result: RobustVLA在LIBERO数据集的全部17种扰动下，在pi0主干上比基线提升12.6%，在OpenVLA主干上提升10.4%，推理速度快50.6倍，并且在混合扰动下提升10.4%。在具有限定示范的真实机器人FR5上，四种模态扰动下提升了65.6%。

Conclusion: RobustVLA显著提升了VLA系统在多模态多扰动下的鲁棒性和效率，尤其适用于实际机器人应用场景。

Abstract: In Vision-Language-Action (VLA) models, robustness to real-world
perturbations is critical for deployment. Existing methods target simple visual
disturbances, overlooking the broader multi-modal perturbations that arise in
actions, instructions, environments, and observations. Here, we first evaluate
the robustness of mainstream VLAs under 17 perturbations across four
modalities. We find (1) actions as the most fragile modality, (2) Existing
visual-robust VLA do not gain robustness in other modality, and (3) pi0
demonstrates superior robustness with a diffusion-based action head. To build
multi-modal robust VLAs, we propose RobustVLA against perturbations in VLA
inputs and outputs. For output robustness, we perform offline robust
optimization against worst-case action noise that maximizes mismatch in flow
matching objective. This can be seen as adversarial training, label smoothing,
and outlier penalization. For input robustness, we enforce consistent actions
across input variations that preserve task semantics. To account for multiple
perturbations, we formulate robustness as a multi-armed bandit problem and
apply an upper confidence bound algorithm to automatically identify the most
harmful noise. Experiments on LIBERO demonstrate our RobustVLA delivers
absolute gains over baselines of 12.6% on the pi0 backbone and 10.4% on the
OpenVLA backbone across all 17 perturbations, achieving 50.6x faster inference
than existing visual-robust VLAs, and a 10.4% gain under mixed perturbations.
Our RobustVLA is particularly effective on real-world FR5 robot with limited
demonstrations, showing absolute gains by 65.6% under perturbations of four
modalities.

</details>


### [31] [Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for Vision-Language Models](https://arxiv.org/abs/2510.26241)
*Shiho Matta,Lis Kanashiro Pereira,Peitao Han,Fei Cheng,Shigeru Kitazawa*

Main category: cs.CV

TL;DR: 本文提出了一个新的评测基准AoT-PsyPhyBENCH，用于检验视觉语言模型（VLM）是否能像人类一样判断视频中的时间箭头（即视频播放是正向还是反向），结果显示当前模型在这方面表现很差。


<details>
  <summary>Details</summary>
Motivation: 虽然视觉语言模型（VLM）在多模态任务中表现优异，但在视频的时序信息处理特别薄弱，现有研究对此关注和评估不足。因此，本文旨在填补这一评测空白。

Method: 作者设计了AoT-PsyPhyBENCH基准，采用心理物理学验证的方法，将人类实验中使用的刺激和行为标准，用于评测公开和专有且具有不同推理能力的VLM模型对视频时序方向的判断能力。评测覆盖自然视频中的不可逆物理过程和因果手工动作。

Result: 评测发现，大多数模型在该任务上表现接近随机，即使最好的模型也远低于人类在不可逆物理过程和因果动作上的准确率。

Conclusion: 当前主流VLM尽管具备丰富的视觉-语义相关性，但缺乏时序连续性和因果性理解的归纳偏置。作者公开了基准测试的代码和数据，希望推动该领域进一步研究。

Abstract: Modern vision-language models (VLMs) excel at many multimodal tasks, yet
their grasp of temporal information in video remains weak and, crucially,
under-evaluated. We probe this gap with a deceptively simple but revealing
challenge: judging the arrow of time (AoT)-whether a short clip is played
forward or backward. We introduce AoT-PsyPhyBENCH, a psychophysically validated
benchmark that tests whether VLMs can infer temporal direction in natural
videos using the same stimuli and behavioral baselines established for humans.
Our comprehensive evaluation of open-weight and proprietary, reasoning and
non-reasoning VLMs reveals that most models perform near chance, and even the
best lag far behind human accuracy on physically irreversible processes (e.g.,
free fall, diffusion/explosion) and causal manual actions (division/addition)
that humans recognize almost instantly. These results highlight a fundamental
gap in current multimodal systems: while they capture rich visual-semantic
correlations, they lack the inductive biases required for temporal continuity
and causal understanding. We release the code and data for AoT-PsyPhyBENCH to
encourage further progress in the physical and temporal reasoning capabilities
of VLMs.

</details>


### [32] [Revisiting Generative Infrared and Visible Image Fusion Based on Human Cognitive Laws](https://arxiv.org/abs/2510.26268)
*Lin Guo,Xiaoqing Luo,Wei Xie,Zhancheng Zhang,Hui Li,Rui Wang,Zhenhua Feng,Xiaoning Song*

Main category: cs.CV

TL;DR: 文章提出一种新的人类认知启发的红外与可见光图像融合方法（HCLFuse），借助多尺度概率编码和物理引导扩散模型，显著提升融合图像的结构一致性和细节保真度，取得了领域内最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有红外与可见光图像融合方法在模式信息平衡和融合可靠性上存在不足，且生成式方法受限于生成能力和可解释性，难以应对复杂场景。为此，作者希望引入新的认知理论和生成机制来增强融合效果和模型解释性。

Method: 提出HCLFuse方法：首先基于无监督融合网络中的信息映射量化理论，设计多尺度掩码调控的变分瓶颈编码器，实现后验概率建模与信息分解，高效抽取精简且准确的低层模态信息。然后，将扩散模型的概率生成能力与物理规律结合，提出时变物理引导机制，自适应调控不同阶段的生成过程，从而增强模型感知数据本质结构的能力，降低对高质量数据的依赖。

Result: 在多个公开数据集上，HCLFuse在主流定性和定量评测下均实现了最优的融合效果，同时显著提升了下游语义分割的指标表现。

Conclusion: 本文充分证明了基于人类认知原理的生成式图像融合方法（HCLFuse），不仅在结构一致性和细节表现上优于现有方法，还提升了下游任务（如语义分割）的效果，在红外与可见光图像融合领域具备广阔应用前景。

Abstract: Existing infrared and visible image fusion methods often face the dilemma of
balancing modal information. Generative fusion methods reconstruct fused images
by learning from data distributions, but their generative capabilities remain
limited. Moreover, the lack of interpretability in modal information selection
further affects the reliability and consistency of fusion results in complex
scenarios. This manuscript revisits the essence of generative image fusion
under the inspiration of human cognitive laws and proposes a novel infrared and
visible image fusion method, termed HCLFuse. First, HCLFuse investigates the
quantification theory of information mapping in unsupervised fusion networks,
which leads to the design of a multi-scale mask-regulated variational
bottleneck encoder. This encoder applies posterior probability modeling and
information decomposition to extract accurate and concise low-level modal
information, thereby supporting the generation of high-fidelity structural
details. Furthermore, the probabilistic generative capability of the diffusion
model is integrated with physical laws, forming a time-varying physical
guidance mechanism that adaptively regulates the generation process at
different stages, thereby enhancing the ability of the model to perceive the
intrinsic structure of data and reducing dependence on data quality.
Experimental results show that the proposed method achieves state-of-the-art
fusion performance in qualitative and quantitative evaluations across multiple
datasets and significantly improves semantic segmentation metrics. This fully
demonstrates the advantages of this generative image fusion method, drawing
inspiration from human cognition, in enhancing structural consistency and
detail quality.

</details>


### [33] [Exploring Complementarity and Explainability in CNNs for Periocular Verification Across Acquisition Distances](https://arxiv.org/abs/2510.26282)
*Fernando Alonso-Fernandez,Kevin Hernandez Diaz,Jose M. Buades,Kiran Raja,Josef Bigun*

Main category: cs.CV

TL;DR: 该论文研究了不同CNN在眼周验证任务中的互补性，并通过融合多种模型取得了新的最佳效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在不同距离的眼周验证上表现不一，单一网络难以兼顾所有场景。研究多种CNN模型的互补性及其融合，有助于提升整体验证性能。

Method: 分别训练SqueezeNet、MobileNetv2和ResNet50三种CNN模型，使用VGGFace2的数据进行眼部图像训练。在UBIPr数据库上，尝试不同特征距离度量（余弦、卡方），探索不同网络初始化，并采用基于逻辑回归的分数层融合。此外，利用LIME热力图和Jensen-Shannon散度分析各模型关注区域的差异。

Result: ResNet50单独表现最佳；三模型融合后，性能显著提升。热力图显示网络关注不同图像区域，互补性明显。融合后方法刷新了UBIPr数据库的眼周验证成绩。

Conclusion: 多种结构CNN融合能有效提升眼周验证性能，且不同模型关注区域互补，为后续多模型融合研究提供参考。

Abstract: We study the complementarity of different CNNs for periocular verification at
different distances on the UBIPr database. We train three architectures of
increasing complexity (SqueezeNet, MobileNetv2, and ResNet50) on a large set of
eye crops from VGGFace2. We analyse performance with cosine and chi2 metrics,
compare different network initialisations, and apply score-level fusion via
logistic regression. In addition, we use LIME heatmaps and Jensen-Shannon
divergence to compare attention patterns of the CNNs. While ResNet50
consistently performs best individually, the fusion provides substantial gains,
especially when combining all three networks. Heatmaps show that networks
usually focus on distinct regions of a given image, which explains their
complementarity. Our method significantly outperforms previous works on UBIPr,
achieving a new state-of-the-art.

</details>


### [34] [Beyond Imitation: Constraint-Aware Trajectory Generation with Flow Matching For End-to-End Autonomous Driving](https://arxiv.org/abs/2510.26292)
*Lin Liu,Guanyi Yu,Ziying Song,Junqiao Li,Caiyan Jia,Feiyang Jia,Peiliang Wu,Yandan Luo*

Main category: cs.CV

TL;DR: 该论文提出了一种新的自动驾驶轨迹规划方法CATG，通过受约束的流匹配直接生成安全、合规且多样化的驾驶轨迹，并在NavSim v2挑战赛中取得优秀成绩。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法在轨迹生成时常会出现模式坍缩，缺乏多样性。同时，大多数生成模型难以直接将安全与物理约束纳入生成过程，通常需要后处理优化，效率和效果受限。作者希望解决这些限制。

Method: 提出Constrained Flow Matching（受约束流匹配）框架CATG，将安全和运动学约束直接整合进流匹配过程中，从而确保生成轨迹符合安全与运动规约。同时，CATG在轨迹生成时引入可控的驾驶激进程度控制信号，实现对驾驶风格的精准调整。

Result: 在NavSim v2挑战赛上，CATG系统取得了EPDMS分数51.31，排名第二，并获得创新奖，展现了方法在实际基准测试中的优越表现。

Conclusion: CATG能够生成多样化、受约束且可控风格的驾驶轨迹，有效缓解了模式坍缩与后处理优化的弊端，提高了自动驾驶规划的安全性与实用性。

Abstract: Planning is a critical component of end-to-end autonomous driving. However,
prevailing imitation learning methods often suffer from mode collapse, failing
to produce diverse trajectory hypotheses. Meanwhile, existing generative
approaches struggle to incorporate crucial safety and physical constraints
directly into the generative process, necessitating an additional optimization
stage to refine their outputs. To address these limitations, we propose CATG, a
novel planning framework that leverages Constrained Flow Matching. Concretely,
CATG explicitly models the flow matching process, which inherently mitigates
mode collapse and allows for flexible guidance from various conditioning
signals. Our primary contribution is the novel imposition of explicit
constraints directly within the flow matching process, ensuring that the
generated trajectories adhere to vital safety and kinematic rules. Secondly,
CATG parameterizes driving aggressiveness as a control signal during
generation, enabling precise manipulation of trajectory style. Notably, on the
NavSim v2 challenge, CATG achieved 2nd place with an EPDMS score of 51.31 and
was honored with the Innovation Award.

</details>


### [35] [Spiking Patches: Asynchronous, Sparse, and Efficient Tokens for Event Cameras](https://arxiv.org/abs/2510.26614)
*Christoffer Koo Øhrstrøm,Ronja Güldenring,Lazaros Nalpantidis*

Main category: cs.CV

TL;DR: 本文提出了一种名为Spiking Patches的事件流分词器，用于事件相机的异步、时空稀疏数据表示，在提升推理速度的同时保持或提升了任务准确率。


<details>
  <summary>Details</summary>
Motivation: 以往事件相机数据常用帧或体素表示，这些方法虽能保证准确率，但牺牲了事件数据的异步性和空间稀疏性，无法很好地凸显事件相机的独特优势。为解决这一问题，作者提出了基于token的全新表示思路。

Method: 设计了Spiking Patches分词器，将事件流转化为保持时空稀疏性的tokens，并基于GNN、PCN和Transformer架构在手势识别和目标检测任务上进行实验评估。

Result: Spiking Patches生成的tokens在推理速度上比体素方法快3.4倍，比帧方法快10.4倍，同时在准确率上基本持平甚至超越，手势识别绝对提升最高可达3.8，目标检测提升最高1.4。

Conclusion: 本文所提出的事件流token化方法兼顾了高效性与事件相机的关键属性，是事件视觉领域的重要创新方向。

Abstract: We propose tokenization of events and present a tokenizer, Spiking Patches,
specifically designed for event cameras. Given a stream of asynchronous and
spatially sparse events, our goal is to discover an event representation that
preserves these properties. Prior works have represented events as frames or as
voxels. However, while these representations yield high accuracy, both frames
and voxels are synchronous and decrease the spatial sparsity. Spiking Patches
gives the means to preserve the unique properties of event cameras and we show
in our experiments that this comes without sacrificing accuracy. We evaluate
our tokenizer using a GNN, PCN, and a Transformer on gesture recognition and
object detection. Tokens from Spiking Patches yield inference times that are up
to 3.4x faster than voxel-based tokens and up to 10.4x faster than frames. We
achieve this while matching their accuracy and even surpassing in some cases
with absolute improvements up to 3.8 for gesture recognition and up to 1.4 for
object detection. Thus, tokenization constitutes a novel direction in
event-based vision and marks a step towards methods that preserve the
properties of event cameras.

</details>


### [36] [Leveraging Large-Scale Face Datasets for Deep Periocular Recognition via Ocular Cropping](https://arxiv.org/abs/2510.26294)
*Fernando Alonso-Fernandez,Kevin Hernandez-Diaz,Jose Maria Buades Rubio,Josef Bigun*

Main category: cs.CV

TL;DR: 该论文研究了眼周区域（periocular region）在人脸生物识别中的应用，比较了三种不同卷积神经网络架构对眼周识别的效果，并使用了大规模数据集进行训练。实验结果在不同数据集上取得了目前已知的最佳误识率。


<details>
  <summary>Details</summary>
Motivation: 眼周区域作为生物特征识别目标，兼具较强的区分能力和采集便利性。但以往研究多局限于小数据集，结果有限，且缺少对深度网络架构效果的系统评估。作者希望借助大规模数据集和不同深度的网络，推动眼周识别领域研究。

Method: 选用了三种不同深度和复杂度的卷积神经网络架构，基于VGGFace2大规模数据库中近两百万个眼部裁剪图像进行训练。在VGGFace2-Pose和UFPR-Periocular两个数据集上分别测试网络表现。

Result: 在VGGFace2-Pose非受控场景下眼周区域EER为9-15%，明显高于全脸识别的3-6%；但在UFPR-Periocular高质量自拍环境下，EER降至1-2%，为该数据库上目前报告的最佳结果。

Conclusion: 大规模数据和更优规范的采集流程能显著提升眼周识别性能，部分深度网络在特定场景下已可实现极低EER，推动了眼周区域在生物识别中的实用价值和应用前景。

Abstract: We focus on ocular biometrics, specifically the periocular region (the area
around the eye), which offers high discrimination and minimal acquisition
constraints. We evaluate three Convolutional Neural Network architectures of
varying depth and complexity to assess their effectiveness for periocular
recognition. The networks are trained on 1,907,572 ocular crops extracted from
the large-scale VGGFace2 database. This significantly contrasts with existing
works, which typically rely on small-scale periocular datasets for training
having only a few thousand images. Experiments are conducted with ocular images
from VGGFace2-Pose, a subset of VGGFace2 containing in-the-wild face images,
and the UFPR-Periocular database, which consists of selfies captured via mobile
devices with user guidance on the screen. Due to the uncontrolled conditions of
VGGFace2, the Equal Error Rates (EERs) obtained with ocular crops range from
9-15%, noticeably higher than the 3-6% EERs achieved using full-face images. In
contrast, UFPR-Periocular yields significantly better performance (EERs of
1-2%), thanks to higher image quality and more consistent acquisition
protocols. To the best of our knowledge, these are the lowest reported EERs on
the UFPR dataset to date.

</details>


### [37] [Towards Realistic Earth-Observation Constellation Scheduling: Benchmark and Methodology](https://arxiv.org/abs/2510.26297)
*Luting Wang,Yinghao Xiang,Hongliang Huang,Dongjun Li,Chen Gao,Si Liu*

Main category: cs.CV

TL;DR: 本文提出了AEOS-Bench大规模基准套件和AEOS-Former调度模型，有效提升了敏捷地球观测卫星星座调度的效率与实用性。


<details>
  <summary>Details</summary>
Motivation: 敏捷地球观测卫星（AEOS）星座虽灵活但调度困难，尤其在大规模、多约束和动态环境下。现有方法多有简化，导致实际应用效果有限。

Method: 提出AEOS-Bench基准套件，包含3907颗卫星、16410个调度场景，并模拟真实卫星运行过程，附带完整调度标注。基于此设计AEOS-Former模型，使用Transformer结构和约束感知注意力机制，通过模拟学习自动适应不同调度场景。

Result: 实验显示AEOS-Former在任务完成率和能效方面均优于现有基线方法，消融实验验证了各组成模块的效用。

Conclusion: AEOS-Bench和AEOS-Former为AEOS星座调度提供了高效、可扩展且现实适用的解决方案，推动该领域研究与实际应用。

Abstract: Agile Earth Observation Satellites (AEOSs) constellations offer unprecedented
flexibility for monitoring the Earth's surface, but their scheduling remains
challenging under large-scale scenarios, dynamic environments, and stringent
constraints. Existing methods often simplify these complexities, limiting their
real-world performance. We address this gap with a unified framework
integrating a standardized benchmark suite and a novel scheduling model. Our
benchmark suite, AEOS-Bench, contains $3,907$ finely tuned satellite assets and
$16,410$ scenarios. Each scenario features $1$ to $50$ satellites and $50$ to
$300$ imaging tasks. These scenarios are generated via a high-fidelity
simulation platform, ensuring realistic satellite behavior such as orbital
dynamics and resource constraints. Ground truth scheduling annotations are
provided for each scenario. To our knowledge, AEOS-Bench is the first
large-scale benchmark suite tailored for realistic constellation scheduling.
Building upon this benchmark, we introduce AEOS-Former, a Transformer-based
scheduling model that incorporates a constraint-aware attention mechanism. A
dedicated internal constraint module explicitly models the physical and
operational limits of each satellite. Through simulation-based iterative
learning, AEOS-Former adapts to diverse scenarios, offering a robust solution
for AEOS constellation scheduling. Experimental results demonstrate that
AEOS-Former outperforms baseline models in task completion and energy
efficiency, with ablation studies highlighting the contribution of each
component. Code and data are provided in
https://github.com/buaa-colalab/AEOSBench.

</details>


### [38] [Exploring the correlation between the type of music and the emotions evoked: A study using subjective questionnaires and EEG](https://arxiv.org/abs/2510.26304)
*Jelizaveta Jankowska,Bożena Kostek,Fernando Alonso-Fernandez,Prayag Tiwari*

Main category: cs.CV

TL;DR: 本研究通过主观问卷和脑电（EEG）测量，探究不同类型的音乐对人类情绪的影响，分析情绪反应与脑部活动的关系。


<details>
  <summary>Details</summary>
Motivation: 不同类型的音乐常常对人的情绪产生影响，但背后的生理机制和主观感受之间的关系尚不明确，因此本研究希望通过结合主观和客观数据，深入了解音乐如何影响人的情绪。

Method: 受试者在听不同风格的音乐时，佩戴EEG头盔记录脑部活动，同时填写主观情绪问卷。参与者性别和音乐偏好多样，以获取广泛情绪反应。实验结束后，对问卷与脑电信号进行关系分析。

Result: 分析结果揭示了不同类型音乐对受试者情绪产生的影响，并确定了情绪反应与脑部活动之间的关联。

Conclusion: 不同类型的音乐能够引发多样的情绪反应，这些反应在主观问卷和脑电信号之间表现出一定的相关性，体现了音乐对大脑情绪处理的客观影响。

Abstract: The subject of this work is to check how different types of music affect
human emotions. While listening to music, a subjective survey and brain
activity measurements were carried out using an EEG helmet. The aim is to
demonstrate the impact of different music genres on emotions. The research
involved a diverse group of participants of different gender and musical
preferences. This had the effect of capturing a wide range of emotional
responses to music. After the experiment, a relationship analysis of the
respondents' questionnaires with EEG signals was performed. The analysis
revealed connections between emotions and observed brain activity.

</details>


### [39] [A Hybrid Framework Bridging CNN and ViT based on Theory of Evidence for Diabetic Retinopathy Grading](https://arxiv.org/abs/2510.26315)
*Junlai Qiu,Yunzhu Chen,Hao Zheng,Yawen Huang,Yuexiang Li*

Main category: cs.CV

TL;DR: 本文提出了一种基于证据理论的融合范式，将CNN与ViT两种主干网络提取的特征进行有效融合，用于糖尿病视网膜病变的自动分级。实验表明，该模型在提升分级准确性的同时，也增强了决策解释性。


<details>
  <summary>Details</summary>
Motivation: 目前利用单一主干（CNN或ViT）进行糖尿病视网膜病变自动筛查的方法性能已遇瓶颈，原因在于它们各自只擅长局部或全局特征提取。融合两者各自优势，有望进一步提升诊断效果。

Method: 提出基于证据理论的融合范式，首先用CNN提取局部特征、ViT提取全局特征，再通过深度证据网络将这些特征转化为支持性证据。利用这些证据进行自适应融合，有效提升模型性能。

Result: 在两个公开DR分级数据集上进行实验，结果表明该融合模型相比当前主流方法准确率更高，且特征融合和分类决策过程具备更强解释性。

Conclusion: 融合CNN与ViT且基于证据理论的方法能够有效提升糖尿病视网膜病变的自动分级效果，并在提升准确率的同时，兼顾模型决策的可解释性，具有实际临床应用潜力。

Abstract: Diabetic retinopathy (DR) is a leading cause of vision loss among middle-aged
and elderly people, which significantly impacts their daily lives and mental
health. To improve the efficiency of clinical screening and enable the early
detection of DR, a variety of automated DR diagnosis systems have been recently
established based on convolutional neural network (CNN) or vision Transformer
(ViT). However, due to the own shortages of CNN / ViT, the performance of
existing methods using single-type backbone has reached a bottleneck. One
potential way for the further improvements is integrating different kinds of
backbones, which can fully leverage the respective strengths of them
(\emph{i.e.,} the local feature extraction capability of CNN and the global
feature capturing ability of ViT). To this end, we propose a novel paradigm to
effectively fuse the features extracted by different backbones based on the
theory of evidence. Specifically, the proposed evidential fusion paradigm
transforms the features from different backbones into supporting evidences via
a set of deep evidential networks. With the supporting evidences, the
aggregated opinion can be accordingly formed, which can be used to adaptively
tune the fusion pattern between different backbones and accordingly boost the
performance of our hybrid model. We evaluated our method on two publicly
available DR grading datasets. The experimental results demonstrate that our
hybrid model not only improves the accuracy of DR grading, compared to the
state-of-the-art frameworks, but also provides the excellent interpretability
for feature fusion and decision-making.

</details>


### [40] [GLYPH-SR: Can We Achieve Both High-Quality Image Super-Resolution and High-Fidelity Text Recovery via VLM-guided Latent Diffusion Model?](https://arxiv.org/abs/2510.26339)
*Mingyu Sung,Seungjae Ham,Kangwoo Kim,Yeokyoung Yoon,Sangseok Yun,Il-Min Kim,Jae-Mo Kang*

Main category: cs.CV

TL;DR: GLYPH-SR提出一种结合视觉与语言的新型扩散模型，有效提升了自然场景中文本的超分辨率，兼顾文本可读性与整体图像感知质量。相比传统方法，OCR识别率显著提升，视觉质量依然领先。


<details>
  <summary>Details</summary>
Motivation: 自然图像（如标志、商品标签、店牌等）中的文本信息对于检测和识别任务至关重要。然而，当前图像超分辨率方法主要关注整体失真度或主观质量，对字符级细节恢复不敏感，导致文本难以识别、OCR准确率下降。因此，亟需一种能同时优化文本可读性和视觉质量的新方法。

Method: 本文提出GLYPH-SR，一种视觉-语言引导的扩散式超分辨框架。其核心包括：1）引入受到OCR数据指导的Text-SR Fusion ControlNet（TS-ControlNet）；2）采用'乒乓调度器'，在文本与场景引导间交替优化；3）在合成语料上有针对性地训练文本分支，主SR网络保持冻结。此法同时优化文本恢复与整体感知质量。

Result: 在SVT、SCUT-CTW1500和CUTE80数据集（x4、x8超分辨）上，GLYPH-SR在保持高感知分数（MANIQA、CLIP-IQA、MUSIQ）的同时，将OCR F1值相比现有扩散/GAN基线最高提升超过15个百分点（如在SVT x8，OpenOCR设置下）。

Conclusion: GLYPH-SR能够同时满足高文本可读性和图像视觉真实感，是自然场景文本超分辨的有效解决方案，兼顾下游任务实用性和主观质量，优于现有主流方法。

Abstract: Image super-resolution(SR) is fundamental to many vision system-from
surveillance and autonomy to document analysis and retail analytics-because
recovering high-frequency details, especially scene-text, enables reliable
downstream perception. Scene-text, i.e., text embedded in natural images such
as signs, product labels, and storefronts, often carries the most actionable
information; when characters are blurred or hallucinated, optical character
recognition(OCR) and subsequent decisions fail even if the rest of the image
appears sharp. Yet previous SR research has often been tuned to distortion
(PSNR/SSIM) or learned perceptual metrics (LIPIS, MANIQA, CLIP-IQA, MUSIQ) that
are largely insensitive to character-level errors. Furthermore, studies that do
address text SR often focus on simplified benchmarks with isolated characters,
overlooking the challenges of text within complex natural scenes. As a result,
scene-text is effectively treated as generic texture. For SR to be effective in
practical deployments, it is therefore essential to explicitly optimize for
both text legibility and perceptual quality. We present GLYPH-SR, a
vision-language-guided diffusion framework that aims to achieve both objectives
jointly. GLYPH-SR utilizes a Text-SR Fusion ControlNet(TS-ControlNet) guided by
OCR data, and a ping-pong scheduler that alternates between text- and
scene-centric guidance. To enable targeted text restoration, we train these
components on a synthetic corpus while keeping the main SR branch frozen.
Across SVT, SCUT-CTW1500, and CUTE80 at x4, and x8, GLYPH-SR improves OCR F1 by
up to +15.18 percentage points over diffusion/GAN baseline (SVT x8, OpenOCR)
while maintaining competitive MANIQA, CLIP-IQA, and MUSIQ. GLYPH-SR is designed
to satisfy both objectives simultaneously-high readability and high visual
realism-delivering SR that looks right and reds right.

</details>


### [41] [EEG-Driven Image Reconstruction with Saliency-Guided Diffusion Models](https://arxiv.org/abs/2510.26391)
*Igor Abramov,Ilya Makarov*

Main category: cs.CV

TL;DR: 本文提出了一种结合EEG特征和空间显著性机制的图像重建方法，显著提升重构质量和语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基于EEG驱动的图像重建方法普遍忽视空间注意力机制，导致图像质量和语义连贯性有限。该研究旨在通过引入空间显著性引导，提升从脑电信号到图像的重构表现。

Method: 作者提出了双条件框架：第一，用ATM模型提取EEG特征，并通过LoRA对Stable Diffusion 2.1进行微调，实现神经信号与视觉语义的对齐；第二，集成ControlNet分支将空间显著性图作为条件输入，增强生成过程中的空间控制。

Result: 在THINGS-EEG数据集上评估，该方法在低层次和高层次图像特征重构质量方面，相比现有方法有显著提升，并且更好契合人类视觉注意力模式。

Conclusion: 利用注意力先验可有效解决EEG重建中的歧义性，实现高保真度的图像重构，未来可用于医学诊断及神经自适应接口，推进神经解码技术发展。

Abstract: Existing EEG-driven image reconstruction methods often overlook spatial
attention mechanisms, limiting fidelity and semantic coherence. To address
this, we propose a dual-conditioning framework that combines EEG embeddings
with spatial saliency maps to enhance image generation. Our approach leverages
the Adaptive Thinking Mapper (ATM) for EEG feature extraction and fine-tunes
Stable Diffusion 2.1 via Low-Rank Adaptation (LoRA) to align neural signals
with visual semantics, while a ControlNet branch conditions generation on
saliency maps for spatial control. Evaluated on THINGS-EEG, our method achieves
a significant improvement in the quality of low- and high-level image features
over existing approaches. Simultaneously, strongly aligning with human visual
attention. The results demonstrate that attentional priors resolve EEG
ambiguities, enabling high-fidelity reconstructions with applications in
medical diagnostics and neuroadaptive interfaces, advancing neural decoding
through efficient adaptation of pre-trained diffusion models.

</details>


### [42] [LoCoT2V-Bench: A Benchmark for Long-Form and Complex Text-to-Video Generation](https://arxiv.org/abs/2510.26412)
*Xiangqing Zheng,Chengyue Wu,Kehai Chen,Min Zhang*

Main category: cs.CV

TL;DR: 现有文本生成视频技术在生成高质量短视频方面取得进展，但对于长视频生成（LVG）的复杂性评估仍有不足。本文提出了LoCoT2V-Bench基准，以更全面、细粒度、抽象层面评估长文本生成视频模型，弥补现有基准的空白。


<details>
  <summary>Details</summary>
Motivation: 当前主流评测基准多聚焦于简单输入和低层次指标，缺乏对长视频复杂情境（如多场景切换、事件动态）的全面、细致及抽象属性（叙事连贯、情感等）的评价手段。

Method: 1. 基于真实视频设计复杂、多样的测试题，包括场景切换、事件动态等元素。2. 构建多维度评估体系，涵盖事件级对齐、细粒度时序一致性、内容清晰度等，并新提出HERD指标用于评价叙事流畅、情感反应、角色发展等抽象属性。3. 用该框架评测9个代表性LVG模型。

Result: 现有主流LVG模型在基本视觉和时序一致性方面表现良好，但在事件间一致性、细粒度对齐和高层次主题表达等方面存在明显短板。

Conclusion: LoCoT2V-Bench基准为复杂长文本生成视频模型的综合评价提供了可靠平台，并明确指出未来模型改进应关注的方向。

Abstract: Recently text-to-video generation has made impressive progress in producing
short, high-quality clips, but evaluating long-form outputs remains a major
challenge especially when processing complex prompts. Existing benchmarks
mostly rely on simplified prompts and focus on low-level metrics, overlooking
fine-grained alignment with prompts and abstract dimensions such as narrative
coherence and thematic expression. To address these gaps, we propose
LoCoT2V-Bench, a benchmark specifically designed for long video generation
(LVG) under complex input conditions. Based on various real-world videos,
LoCoT2V-Bench introduces a suite of realistic and complex prompts incorporating
elements like scene transitions and event dynamics. Moreover, it constructs a
multi-dimensional evaluation framework that includes our newly proposed metrics
such as event-level alignment, fine-grained temporal consistency, content
clarity, and the Human Expectation Realization Degree (HERD) that focuses on
more abstract attributes like narrative flow, emotional response, and character
development. Using this framework, we conduct a comprehensive evaluation of
nine representative LVG models, finding that while current methods perform well
on basic visual and temporal aspects, they struggle with inter-event
consistency, fine-grained alignment, and high-level thematic adherence, etc.
Overall, LoCoT2V-Bench provides a comprehensive and reliable platform for
evaluating long-form complex text-to-video generation and highlights critical
directions for future method improvement.

</details>


### [43] [A-TPT: Angular Diversity Calibration Properties for Test-Time Prompt Tuning of Vision-Language Models](https://arxiv.org/abs/2510.26441)
*Shihab Aaqil Ahamed,Udaya S. K. P. Miriya Thanthrige,Ranga Rodrigo,Muhammad Haris Khan*

Main category: cs.CV

TL;DR: 提出了一种新的测试时 prompt 微调方法（A-TPT），通过促进文本特征的角度多样性，大幅提升了大规模视觉-语言模型（VLM）在无监督场景下的校准能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时 prompt 微调技术（Test-time prompt tuning, TPT）虽然可以在无标签数据下适应新任务，但由于文本特征间分布不够分散，导致模型校准效果不佳，影响其可靠性与安全性。已有方法通过促使文本特征分散或正交，但忽视了特征间角度多样性的作用。

Method: A-TPT 方法最大化类别间归一化文本特征在单位超球面上的最小成对角距离，从而鼓励文本特征的均匀分布和角度多样性，确保更优的特征分隔。该方法可在不同主干网络和数据集上进行无监督测试时适配。

Result: 大量实验表明，A-TPT 方法在多个主干网络与数据集上，始终在降低总平均校准误差方面超过了现有最先进的 TPT 方法，同时保持了可比的准确率。在面对自然分布偏移和医学数据集时，该方法的零样本校准性能表现尤为突出。

Conclusion: 促进文本特征的角度多样性可以有效提升 VLM 在测试时的校准性能，增强模型可靠性和泛化能力，为 TPT 方法带来了新的进展。作者将公开代码以便后续研究和应用。

Abstract: Test-time prompt tuning (TPT) has emerged as a promising technique for
adapting large vision-language models (VLMs) to unseen tasks without relying on
labeled data. However, the lack of dispersion between textual features can hurt
calibration performance, which raises concerns about VLMs' reliability,
trustworthiness, and safety. Current TPT approaches primarily focus on
improving prompt calibration by either maximizing average textual feature
dispersion or enforcing orthogonality constraints to encourage angular
separation. However, these methods may not always have optimal angular
separation between class-wise textual features, which implies overlooking the
critical role of angular diversity. To address this, we propose A-TPT, a novel
TPT framework that introduces angular diversity to encourage uniformity in the
distribution of normalized textual features induced by corresponding learnable
prompts. This uniformity is achieved by maximizing the minimum pairwise angular
distance between features on the unit hypersphere. We show that our approach
consistently surpasses state-of-the-art TPT methods in reducing the aggregate
average calibration error while maintaining comparable accuracy through
extensive experiments with various backbones on different datasets. Notably,
our approach exhibits superior zero-shot calibration performance on natural
distribution shifts and generalizes well to medical datasets. We provide
extensive analyses, including theoretical aspects, to establish the grounding
of A-TPT. These results highlight the potency of promoting angular diversity to
achieve well-dispersed textual features, significantly improving VLM
calibration during test-time adaptation. Our code will be made publicly
available.

</details>


### [44] [PointSt3R: Point Tracking through 3D Grounded Correspondence](https://arxiv.org/abs/2510.26443)
*Rhodri Guerrier,Adam W. Harley,Dima Damen*

Main category: cs.CV

TL;DR: 本论文将最新的3D重建基础模型（如DUSt3R和MASt3R）应用于点追踪任务，并在多个数据集上取得了优异结果。提出的方法通过在训练中融合重建损失和动态对应，显著提升了点追踪性能，超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的3D重建基础模型已在静态场景下的2D和3D对应取得优秀表现，但如何有效将其应用于点追踪（尤其动态点和遮挡情况）方面仍有挑战。点追踪对于众多下游任务（如动作分析、视频理解等）至关重要，因此作者探索将基础3D重建模型用于点追踪的可行性。

Method: 1. 验证DUSt3R和MASt3R在静态点追踪任务中的性能；2. 融合重建损失与动态点对应，并引入visibility head来提升动态点追踪能力；3. 在少量合成数据基础上微调MASt3R，用于点追踪；4. 仅用两帧（包含查询点的帧对）训练评估，从而去除时序依赖；5. 在4个数据集上进行了系统实验和消融分析。

Result: 提升了基线方法在点追踪标准上的表现。例如，在EgoPoints数据集上，方法比CoTracker2提升了33.5%；在TAP-Vid-DAVIS、RGB-S等集上表现也优于或可比最新模型。动态与静态点结合能进一步稳定提升指标。

Conclusion: 本工作表明，将3D重建基础模型应用至点追踪任务具有极大潜力，尤其在融合动态对应和额外损失设计后，可以显著提升当前追踪性能，对实际点追踪任务具有参考和借鉴意义。

Abstract: Recent advances in foundational 3D reconstruction models, such as DUSt3R and
MASt3R, have shown great potential in 2D and 3D correspondence in static
scenes. In this paper, we propose to adapt them for the task of point tracking
through 3D grounded correspondence. We first demonstrate that these models are
competitive point trackers when focusing on static points, present in current
point tracking benchmarks ($+33.5\%$ on EgoPoints vs. CoTracker2). We propose
to combine the reconstruction loss with training for dynamic correspondence
along with a visibility head, and fine-tuning MASt3R for point tracking using a
relatively small amount of synthetic data. Importantly, we only train and
evaluate on pairs of frames where one contains the query point, effectively
removing any temporal context. Using a mix of dynamic and static point
correspondences, we achieve competitive or superior point tracking results on
four datasets (e.g. competitive on TAP-Vid-DAVIS 73.8 $\delta_{avg}$ / 85.8\%
occlusion acc. for PointSt3R compared to 75.7 / 88.3\% for CoTracker2; and
significantly outperform CoTracker3 on EgoPoints 61.3 vs 54.2 and RGB-S 87.0 vs
82.8). We also present results on 3D point tracking along with several
ablations on training datasets and percentage of dynamic correspondences.

</details>


### [45] [Towards Fine-Grained Vision-Language Alignment for Few-Shot Anomaly Detection](https://arxiv.org/abs/2510.26464)
*Yuanting Fan,Jun Liu,Xiaochen Chen,Bin-Bin Gao,Jian Li,Yong Liu,Jinlong Peng,Chengjie Wang*

Main category: cs.CV

TL;DR: 本文提出了一种基于多层次细粒度语义描述的新型小样本异常检测框架FineGrainedAD，有效提升了异常区域的定位能力。


<details>
  <summary>Details</summary>
Motivation: 现有小样本异常检测方法主要依赖预训练视觉-语言模型，通过图像和文本特征匹配检测异常。但是这类方法只能用图像级别的文本描述，导致图文语义在更细粒度程度上无法对齐，影响异常区域的准确定位。

Method: 本文提出Multi-Level Fine-Grained Semantic Caption (MFSC)自动生成多层次、细粒度的文本描述数据，进一步设计FineGrainedAD框架，包括Multi-Level Learnable Prompt (MLLP)和Multi-Level Semantic Alignment (MLSA)两大组件。MLLP可引入细粒度语义到多层可学习提示中，MLSA则采用区域聚合策略和多层对齐训练提升语义与视觉区域的一致性。

Result: 在MVTec-AD和VisA小样本异常检测数据集上，FineGrainedAD在异常定位性能上明显优于现有方法。

Conclusion: 将细粒度语义描述引入小样本异常检测任务，显著提升了定位精度，为基于视觉-语言模型的异常检测提供了新思路。

Abstract: Few-shot anomaly detection (FSAD) methods identify anomalous regions with few
known normal samples. Most existing methods rely on the generalization ability
of pre-trained vision-language models (VLMs) to recognize potentially anomalous
regions through feature similarity between text descriptions and images.
However, due to the lack of detailed textual descriptions, these methods can
only pre-define image-level descriptions to match each visual patch token to
identify potential anomalous regions, which leads to the semantic misalignment
between image descriptions and patch-level visual anomalies, achieving
sub-optimal localization performance. To address the above issues, we propose
the Multi-Level Fine-Grained Semantic Caption (MFSC) to provide multi-level and
fine-grained textual descriptions for existing anomaly detection datasets with
automatic construction pipeline. Based on the MFSC, we propose a novel
framework named FineGrainedAD to improve anomaly localization performance,
which consists of two components: Multi-Level Learnable Prompt (MLLP) and
Multi-Level Semantic Alignment (MLSA). MLLP introduces fine-grained semantics
into multi-level learnable prompts through automatic replacement and
concatenation mechanism, while MLSA designs region aggregation strategy and
multi-level alignment training to facilitate learnable prompts better align
with corresponding visual regions. Experiments demonstrate that the proposed
FineGrainedAD achieves superior overall performance in few-shot settings on
MVTec-AD and VisA datasets.

</details>


### [46] [Representation-Level Counterfactual Calibration for Debiased Zero-Shot Recognition](https://arxiv.org/abs/2510.26466)
*Pei Peng,MingKun Xie,Hang Hao,Tong Jin,ShengJun Huang*

Main category: cs.CV

TL;DR: 本文提出了一种基于因果推断的方法，通过在CLIP等视觉-语言模型的表示空间中合成反事实嵌入，有效减缓了对象与背景环境的共现偏差，提高了模型在不同场景下的零样本表现。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型在测试时容易依赖训练中对象与环境的共现关系（即object-context shortcut），导致模型在新场景中泛化能力差。针对这一问题，作者将其视为因果推断问题，探索如何消除背景环境对目标预测的干扰。

Method: 作者在CLIP表示空间下，分别估计对象与背景的特征期望，通过从外部数据集、同批邻居或文本描述中采样多样化背景，生成对象在不同环境中的反事实嵌入；进一步通过模拟干预与总直接效应（TDE）减去“仅背景”的激活，有效保留有益的对象-环境交互，同时减少‘假象’得分。

Result: 无需重新训练或特别设计prompt，所提方法在多项依赖环境的零样本基准任务上，同时显著提升了最差分组表现与平均准确率，并取得了新的零样本SOTA。

Conclusion: 该方法无需额外训练，直接在表征层面进行反事实处理，为多模态模型提供了高效、实用且具因果解释性的去偏及鲁棒推理新路径。

Abstract: Object-context shortcuts remain a persistent challenge in vision-language
models, undermining zero-shot reliability when test-time scenes differ from
familiar training co-occurrences. We recast this issue as a causal inference
problem and ask: Would the prediction remain if the object appeared in a
different environment? To answer this at inference time, we estimate object and
background expectations within CLIP's representation space, and synthesize
counterfactual embeddings by recombining object features with diverse
alternative contexts sampled from external datasets, batch neighbors, or
text-derived descriptions. By estimating the Total Direct Effect and simulating
intervention, we further subtract background-only activation, preserving
beneficial object-context interactions while mitigating hallucinated scores.
Without retraining or prompt design, our method substantially improves both
worst-group and average accuracy on context-sensitive benchmarks, establishing
a new zero-shot state of the art. Beyond performance, our framework provides a
lightweight representation-level counterfactual approach, offering a practical
causal avenue for debiased and reliable multimodal reasoning.

</details>


### [47] [Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing](https://arxiv.org/abs/2510.26474)
*Xin Guo,Zhiheng Xi,Yiwen Ding,Yitao Zhai,Xiaowei Shi,Xunliang Cai,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CV

TL;DR: 本文发现大规模视觉语言模型（LVLMs）在自我提升过程中，简单问题的优化多于复杂问题，导致性能瓶颈。针对这一“马太效应”，提出分布重塑和轨迹重采等四种策略，实现复杂和简单问题的平衡优化，实验表明方法显著提升模型推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前LVLMs通过自我改进不断提升推理能力，但模型只在简单任务上优化快，复杂任务（长尾数据）提升缓慢，造成模型长期难以突破推理极限。作者希望通过平衡优化，打破这种瓶颈。

Method: 作者提出两大方向四种策略：1）分布重塑（distribution-reshaping），通过调整训练样本分布提升复杂问题出现概率；2）轨迹重采（trajectory-resampling），从复杂问题生成高质量优化轨迹。结合上述方法，实现探索和学习阶段的头尾平衡。

Result: 在Qwen2-VL-7B-Instruct和InternVL2.5-4B两个主流LVLMs及视觉推理任务上，提出方法平均提升3.86分，较传统自我改进方法有显著超越，体现推理能力全面增强。

Conclusion: 本文通过头尾平衡优化，有效抑制了自我提升中的马太效应，实验证明方法能持续提升LVLMs在高阶视觉推理任务上的表现，有助于实现更智能、更均衡的模型改进。

Abstract: Self-improvement has emerged as a mainstream paradigm for advancing the
reasoning capabilities of large vision-language models (LVLMs), where models
explore and learn from successful trajectories iteratively. However, we
identify a critical issue during this process: the model excels at generating
high-quality trajectories for simple queries (i.e., head data) but struggles
with more complex ones (i.e., tail data). This leads to an imbalanced
optimization that drives the model to prioritize simple reasoning skills, while
hindering its ability to tackle more complex reasoning tasks. Over iterations,
this imbalance becomes increasingly pronounced--a dynamic we term the "Matthew
effect"--which ultimately hinders further model improvement and leads to
performance bottlenecks. To counteract this challenge, we introduce four
efficient strategies from two perspectives: distribution-reshaping and
trajectory-resampling, to achieve head-tail re-balancing during the
exploration-and-learning self-improvement process. Extensive experiments on
Qwen2-VL-7B-Instruct and InternVL2.5-4B models across visual reasoning tasks
demonstrate that our methods consistently improve visual reasoning
capabilities, outperforming vanilla self-improvement by 3.86 points on average.

</details>


### [48] [Analysis of the Robustness of an Edge Detector Based on Cellular Automata Optimized by Particle Swarm](https://arxiv.org/abs/2510.26509)
*Vinícius Ferraria,Eurico Ruivo*

Main category: cs.CV

TL;DR: 本文提出了一种结合元启发式优化与迁移学习的二维元胞自动机可自适应边缘检测器，分析其在扩大优化空间和适应不同图像集下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 传统边缘检测器存在检测松散边缘困难和缺乏上下文适应性的问题，亟需开发一种能够自适应调整以适配不同图像属性的检测方法。

Method: 设计了一种基于二维元胞自动机的边缘检测器，通过元启发式方法优化，同时结合迁移学习提升适应性。实验分析了优化空间扩大对性能的影响，并考察了模型在自然图像及特定子集上的适应能力。

Result: 研究发现，扩大优化空间对于该图像集边缘检测效果并无提升。同时，迁移学习对模型效果无显著改善。无论验证方式如何，模型都能较好地对输入自适应。

Conclusion: 所提可自适应边缘检测器在不同图像输入下均展现了良好的适应性，但通过增加搜索空间或迁移学习并未带来明显性能提升。

Abstract: The edge detection task is essential in image processing aiming to extract
relevant information from an image. One recurring problem in this task is the
weaknesses found in some detectors, such as the difficulty in detecting loose
edges and the lack of context to extract relevant information from specific
problems. To address these weaknesses and adapt the detector to the properties
of an image, an adaptable detector described by two-dimensional cellular
automaton and optimized by meta-heuristic combined with transfer learning
techniques was developed. This study aims to analyze the impact of expanding
the search space of the optimization phase and the robustness of the
adaptability of the detector in identifying edges of a set of natural images
and specialized subsets extracted from the same image set. The results obtained
prove that expanding the search space of the optimization phase was not
effective for the chosen image set. The study also analyzed the adaptability of
the model through a series of experiments and validation techniques and found
that, regardless of the validation, the model was able to adapt to the input
and the transfer learning techniques applied to the model showed no significant
improvements.

</details>


### [49] [SA$^{2}$Net: Scale-Adaptive Structure-Affinity Transformation for Spine Segmentation from Ultrasound Volume Projection Imaging](https://arxiv.org/abs/2510.26568)
*Hao Xie,Zixun Huang,Yushen Zuo,Yakun Ju,Frank H. F. Leung,N. F. Law,Kin-Man Lam,Yong-Ping Zheng,Sai Ho Ling*

Main category: cs.CV

TL;DR: 本文提出了一种创新的多尺度自适应结构感知网络（SA²Net），用于超声投影影像下的脊柱分割，有效提升了分割准确性和健壮性。


<details>
  <summary>Details</summary>
Motivation: 超声影像下的脊柱分割任务存在全局上下文信息缺失和脊柱复杂结构信息难以编码的挑战，这会影响智能脊柱侧弯诊断的准确性。

Method: 提出SA²Net，包含两大创新：1）多尺度自适应补充策略，增强脊柱影像的跨维度长距离特征关联学习；2）结构亲和变换，将Transformer中的多头自注意与语义层亲和力结合，实现结构信息感知，以及引入特征混合损失聚合提升训练效果。

Result: SA²Net在多项实验中优于现有主流分割模型，表现出更高精度和更强鲁棒性。

Conclusion: SA²Net不仅提升了脊柱分割效果，还具备良好的模型适配性，对智能脊柱侧弯诊断具有重要应用潜力。

Abstract: Spine segmentation, based on ultrasound volume projection imaging (VPI),
plays a vital role for intelligent scoliosis diagnosis in clinical
applications. However, this task faces several significant challenges. Firstly,
the global contextual knowledge of spines may not be well-learned if we neglect
the high spatial correlation of different bone features. Secondly, the spine
bones contain rich structural knowledge regarding their shapes and positions,
which deserves to be encoded into the segmentation process. To address these
challenges, we propose a novel scale-adaptive structure-aware network
(SA$^{2}$Net) for effective spine segmentation. First, we propose a
scale-adaptive complementary strategy to learn the cross-dimensional
long-distance correlation features for spinal images. Second, motivated by the
consistency between multi-head self-attention in Transformers and semantic
level affinity, we propose structure-affinity transformation to transform
semantic features with class-specific affinity and combine it with a
Transformer decoder for structure-aware reasoning. In addition, we adopt a
feature mixing loss aggregation method to enhance model training. This method
improves the robustness and accuracy of the segmentation process. The
experimental results demonstrate that our SA$^{2}$Net achieves superior
segmentation performance compared to other state-of-the-art methods. Moreover,
the adaptability of SA$^{2}$Net to various backbones enhances its potential as
a promising tool for advanced scoliosis diagnosis using intelligent spinal
image analysis. The code and experimental demo are available at
https://github.com/taetiseo09/SA2Net.

</details>


### [50] [AdSum: Two-stream Audio-visual Summarization for Automated Video Advertisement Clipping](https://arxiv.org/abs/2510.26569)
*Wen Xie,Yanjun Zhu,Gijs Overgoor,Yakov Bart,Agata Lapedriza Garcia,Sarah Ostadabbas*

Main category: cs.CV

TL;DR: 本文提出了一种基于视频摘要技术的自动化广告剪辑系统，通过音视频融合模型自动为广告制作不同时长的剪辑版本，显著减少了人工剪辑的工作量，性能超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 广告主常需为同一广告活动制作多种时长的广告版本，传统靠人工挑选和剪辑既费时又费力。本研究旨在通过自动化方法简化该流程，提高效率并提升输出效果。

Method: 将广告视频的剪辑视为特定于广告的镜头选择问题，开发了一种音视频双流融合模型，利用音频和视觉信息预测视频帧的重要性。同时，创建了AdSum204数据集（含102对分别为30秒和15秒的真实广告），用于训练和验证模型。

Result: 在AdSum204数据集上，提出的模型在平均精度、ROC曲线下面积、斯皮尔曼系数和肯德尔系数等多项指标上均优于现有最先进的方法。

Conclusion: 结合音频和视觉的自动化广告视频剪辑方法，能有效实现高质量广告短版的自动生成，并有望推广应用于广告工业实际中，提升广告内容制作的自动化与智能化水平。

Abstract: Advertisers commonly need multiple versions of the same advertisement (ad) at
varying durations for a single campaign. The traditional approach involves
manually selecting and re-editing shots from longer video ads to create shorter
versions, which is labor-intensive and time-consuming. In this paper, we
introduce a framework for automated video ad clipping using video summarization
techniques. We are the first to frame video clipping as a shot selection
problem, tailored specifically for advertising. Unlike existing general video
summarization methods that primarily focus on visual content, our approach
emphasizes the critical role of audio in advertising. To achieve this, we
develop a two-stream audio-visual fusion model that predicts the importance of
video frames, where importance is defined as the likelihood of a frame being
selected in the firm-produced short ad. To address the lack of ad-specific
datasets, we present AdSum204, a novel dataset comprising 102 pairs of
30-second and 15-second ads from real advertising campaigns. Extensive
experiments demonstrate that our model outperforms state-of-the-art methods
across various metrics, including Average Precision, Area Under Curve,
Spearman, and Kendall.

</details>


### [51] [Dynamic Context-Aware Scene Reasoning Using Vision-Language Alignment in Zero-Shot Real-World Scenarios](https://arxiv.org/abs/2510.26580)
*Manjunath Prasad Holenarasipura Rajiv,B. M. Vidyavathi*

Main category: cs.CV

TL;DR: 提出了一种动态上下文感知场景推理框架，通过视觉-语言对齐提升AI系统零样本场景理解，并在真实复杂环境中大幅提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现实环境中，AI常遇到无标注的新场景，传统模型难以泛化，限制了视觉应用的部署。因此亟需能在无先验训练下理解新场景的方法。

Method: 该方法结合了预训练视觉Transformer和大型语言模型，通过视觉语义与自然语言描述的对齐，提升上下文理解能力。动态推理模块进一步融合全局场景线索和对象级交互，并用语言先验指导预测。

Result: 在COCO、Visual Genome、Open Images等零样本基准测试中，相比基础模型场景理解精度提升最高达18%。在含糊或拥挤场景下表现也更鲁棒。

Conclusion: 该框架为上下文感知推理提供了高效、可解释的解决方案，推动了动态真实环境下的零样本泛化能力。

Abstract: In real-world environments, AI systems often face unfamiliar scenarios
without labeled data, creating a major challenge for conventional scene
understanding models. The inability to generalize across unseen contexts limits
the deployment of vision-based applications in dynamic, unstructured settings.
This work introduces a Dynamic Context-Aware Scene Reasoning framework that
leverages Vision-Language Alignment to address zero-shot real-world scenarios.
The goal is to enable intelligent systems to infer and adapt to new
environments without prior task-specific training. The proposed approach
integrates pre-trained vision transformers and large language models to align
visual semantics with natural language descriptions, enhancing contextual
comprehension. A dynamic reasoning module refines predictions by combining
global scene cues and object-level interactions guided by linguistic priors.
Extensive experiments on zero-shot benchmarks such as COCO, Visual Genome, and
Open Images demonstrate up to 18% improvement in scene understanding accuracy
over baseline models in complex and unseen environments. Results also show
robust performance in ambiguous or cluttered scenes due to the synergistic
fusion of vision and language. This framework offers a scalable and
interpretable approach for context-aware reasoning, advancing zero-shot
generalization in dynamic real-world settings.

</details>


### [52] [CATCH: A Modular Cross-domain Adaptive Template with Hook](https://arxiv.org/abs/2510.26582)
*Xinjin Li,Yulie Lu,Jinghan Cao,Yu Ma,Zhenglin Li,Yeyang Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种名为CATCH的跨领域适应框架，通过两个轻量级适配模块，在无需重训练主干模型的情况下，提升了视觉问答（VQA）在不同领域下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有VQA模型（如LLaVA）在自然图像上表现优异，但面对遥感、医学或数学图像等领域时，因分布变化大且缺少有效适应机制，导致泛化能力严重下降。现有解决方案依赖于针对特定领域的微调或专有流程，成本高、灵活性差、难以大规模推广。

Method: 提出CATCH框架，其创新点是将视觉与语言的适应过程解耦：引入域分类器识别图像类型，并通过Prompt Adapter（语言调节）与Visual Adapter（视觉特征调节）两个适配器，在不重训练主干模型的前提下，通过统一接口动态嵌入，实现灵活、高效的多领域适应。

Result: 在MathVQA、MedVQA-RAD、ChartQA等四种领域专有VQA基准上，CATCH显著提升了模型表现：如MathVQA上BLEU提升2.3分、MedVQA-RAD上VQA提升2.6分、ChartQA上ROUGE提升3.1分，且无需重训练主模型。

Conclusion: CATCH是一种可扩展、实用的多领域VQA适应方案，能够在各类应用中轻松部署并获得持续性能提升。

Abstract: Recent advances in Visual Question Answering (VQA) have demonstrated
impressive performance in natural image domains, with models like LLaVA
leveraging large language models (LLMs) for open-ended reasoning. However,
their generalization degrades significantly when transferred to out-of-domain
scenarios such as remote sensing, medical imaging, or math diagrams, due to
large distributional shifts and the lack of effective domain adaptation
mechanisms. Existing approaches typically rely on per-domain fine-tuning or
bespoke pipelines, which are costly, inflexible, and not scalable across
diverse tasks. In this paper, we propose CATCH, a plug-and-play framework for
cross-domain adaptation that improves the generalization of VQA models while
requiring minimal changes to their core architecture. Our key idea is to
decouple visual and linguistic adaptation by introducing two lightweight
modules: a domain classifier to identify the input image type, and a dual
adapter mechanism comprising a Prompt Adapter for language modulation and a
Visual Adapter for vision feature adjustment. Both modules are dynamically
injected via a unified hook interface, requiring no retraining of the backbone
model. Experimental results across four domain-specific VQA benchmarks
demonstrate that our framework achieves consistent performance gains without
retraining the backbone model, including +2.3 BLEU on MathVQA, +2.6 VQA on
MedVQA-RAD, and +3.1 ROUGE on ChartQA. These results highlight that CATCH
provides a scalable and extensible approach to multi-domain VQA, enabling
practical deployment across diverse application domains.

</details>


### [53] [Emu3.5: Native Multimodal Models are World Learners](https://arxiv.org/abs/2510.26583)
*Yufeng Cui,Honghao Chen,Haoge Deng,Xu Huang,Xinghang Li,Jirong Liu,Yang Liu,Zhuoyan Luo,Jinsheng Wang,Wenxuan Wang,Yueze Wang,Chengyuan Wang,Fan Zhang,Yingli Zhao,Ting Pan,Xianduo Li,Zecheng Hao,Wenxuan Ma,Zhuo Chen,Yulong Ao,Tiejun Huang,Zhongyuan Wang,Xinlong Wang*

Main category: cs.CV

TL;DR: Emu3.5是一种新型大规模多模态世界模型，能同时预测视觉与语言的下一个状态，具备强大的生成和推理能力，并在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型在视觉和语言的联合预测、长时序推理以及生成能力上存在局限。作者希望开发一种能原生支持多模态输入输出、具备世界建模和推理能力的高效模型。

Method: 作者提出了Emu3.5，基于10万亿视觉-语言混合大数据的端到端预训练，通过统一的下一个token预测目标学习多模态信息，后续再用强化学习提升推理能力。此外，提出Discrete Diffusion Adaptation（DiDA），将传统逐token解码加速为双向并行预测，推理效率提升约20倍。

Result: Emu3.5不仅能处理视觉与语言交错输入和输出，在长时序生成、任意模态到图像生成、复杂文本图像生成等能力上表现突出。其在图像生成和编辑上达到行业领先标准，在多模态交错生成任务表现优于同类模型。

Conclusion: Emu3.5展现了卓越的本地多模态能力和普适世界建模能力，极大提升了复杂场景和任务下的表现，并对外开源，助推多模态AI社区研究。

Abstract: We introduce Emu3.5, a large-scale multimodal world model that natively
predicts the next state across vision and language. Emu3.5 is pre-trained
end-to-end with a unified next-token prediction objective on a corpus of
vision-language interleaved data containing over 10 trillion tokens, primarily
derived from sequential frames and transcripts of internet videos. The model
naturally accepts interleaved vision-language inputs and generates interleaved
vision-language outputs. Emu3.5 is further post-trained with large-scale
reinforcement learning to enhance multimodal reasoning and generation. To
improve inference efficiency, we propose Discrete Diffusion Adaptation (DiDA),
which converts token-by-token decoding into bidirectional parallel prediction,
accelerating per-image inference by about 20x without sacrificing performance.
Emu3.5 exhibits strong native multimodal capabilities, including long-horizon
vision-language generation, any-to-image (X2I) generation, and complex
text-rich image generation. It also exhibits generalizable world-modeling
abilities, enabling spatiotemporally consistent world exploration and
open-world embodied manipulation across diverse scenarios and tasks. For
comparison, Emu3.5 achieves performance comparable to Gemini 2.5 Flash Image
(Nano Banana) on image generation and editing tasks and demonstrates superior
results on a suite of interleaved generation tasks. We open-source Emu3.5 at
https://github.com/baaivision/Emu3.5 to support community research.

</details>


### [54] [ResMatching: Noise-Resilient Computational Super-Resolution via Guided Conditional Flow Matching](https://arxiv.org/abs/2510.26601)
*Anirban Ray,Vera Galinova,Florian Jug*

Main category: cs.CV

TL;DR: 该论文提出一种名为ResMatching的计算超分辨率（CSR）新方法，并在多种生物样本数据集上表现优异，尤其能够兼顾数据保真与感知真实感，还能输出像素级不确定性。


<details>
  <summary>Details</summary>
Motivation: 传统的显微成像受限于物理分辨率，CSR方法通过先验信息推断微观图像中的高频信息。但先验的获得依赖于模型设计与数据，现有数据驱动方法仍有提升空间，尤其在低质量或高噪声数据下。

Method: 本文提出ResMatching方法，核心为利用有指导的条件流匹配（guided conditional flow matching）学习更优的CSR数据先验。方法在BioSR数据集四个不同生物结构上，与七种主流方法作系统比较。

Result: ResMatching在四个数据集上均取得了最优的数据保真与感知真实感平衡，尤其在强先验难以学习（如高噪声低分辨率）场景下优势明显。同时，方法能隐式学习后验分布并生成像素级不确定性，指导用户甄别不确定预测。

Conclusion: ResMatching方法有效提升了显微图像超分辨率重建的准确性和可靠性，特别适用于噪声大、先验难学习的数据场景，并为后续分析提供了可靠的不确定性估计。

Abstract: Computational Super-Resolution (CSR) in fluorescence microscopy has, despite
being an ill-posed problem, a long history. At its very core, CSR is about
finding a prior that can be used to extrapolate frequencies in a micrograph
that have never been imaged by the image-generating microscope. It stands to
reason that, with the advent of better data-driven machine learning techniques,
stronger prior can be learned and hence CSR can lead to better results. Here,
we present ResMatching, a novel CSR method that uses guided conditional flow
matching to learn such improved data-priors. We evaluate ResMatching on 4
diverse biological structures from the BioSR dataset and compare its results
against 7 baselines. ResMatching consistently achieves competitive results,
demonstrating in all cases the best trade-off between data fidelity and
perceptual realism. We observe that CSR using ResMatching is particularly
effective in cases where a strong prior is hard to learn, e.g. when the given
low-resolution images contain a lot of noise. Additionally, we show that
ResMatching can be used to sample from an implicitly learned posterior
distribution and that this distribution is calibrated for all tested use-cases,
enabling our method to deliver a pixel-wise data-uncertainty term that can
guide future users to reject uncertain predictions.

</details>


### [55] [CYPRESS: Crop Yield Prediction via Regression on Prithvi's Encoder for Satellite Sensing](https://arxiv.org/abs/2510.26609)
*Shayan Nejadshamsi,Yuanyuan Zhang,Shadi Zaki,Brock Porth,Lysa Porth,Vahab Khoshdel*

Main category: cs.CV

TL;DR: 该论文提出了CYPRESS模型，通过深度学习方法，实现高分辨率油菜产量预测，显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 传统农作物产量预测方法缺乏精细化和可扩展性，难以满足现代精准农业的需求，因此需要更高效、精确的预测手段。

Method: 基于大规模地理空间基础模型Prithvi-EO-2.0-600M，通过微调，将多时相卫星影像转化为像素级、连续的产量预测地图，实现高分辨率、田间内部的产量回归。

Result: CYPRESS在加拿大草原地区的油菜数据集上实验，表现优于现有深度学习产量预测模型，精准度更高，空间分辨率更细。

Conclusion: 该研究证明了微调地球观测基础模型在精准农业中的有效性，为大规模、精细化农业监测提供了新方法，弥补了遥感观测与农场实际决策之间的空白。

Abstract: Accurate and timely crop yield prediction is crucial for global food security
and modern agricultural management. Traditional methods often lack the
scalability and granularity required for precision farming. This paper
introduces CYPRESS (Crop Yield Prediction via Regression on Prithvi's Encoder
for Satellite Sensing), a deep learning model designed for high-resolution,
intra-field canola yield prediction. CYPRESS leverages a pre-trained,
large-scale geospatial foundation model (Prithvi-EO-2.0-600M) and adapts it for
a continuous regression task, transforming multi-temporal satellite imagery
into dense, pixel-level yield maps. Evaluated on a comprehensive dataset from
the Canadian Prairies, CYPRESS demonstrates superior performance over existing
deep learning-based yield prediction models, highlighting the effectiveness of
fine-tuning foundation models for specialized agricultural applications. By
providing a continuous, high-resolution output, CYPRESS offers a more
actionable tool for precision agriculture than conventional classification or
county-level aggregation methods. This work validates a novel approach that
bridges the gap between large-scale Earth observation and on-farm
decision-making, offering a scalable solution for detailed agricultural
monitoring.

</details>


### [56] [PT-DETR: Small Target Detection Based on Partially-Aware Detail Focus](https://arxiv.org/abs/2510.26630)
*Bingcong Huo,Zhiming Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为PT-DETR的新型小目标检测算法，专为无人机影像中的复杂检测任务设计，提升了小目标和密集目标的检测能力，并在VisDrone2019数据集上取得了比原始方法更高的性能。


<details>
  <summary>Details</summary>
Motivation: 现有无人机目标检测在处理复杂背景、目标遮挡、密集小目标和光线变化等方面表现不足，尤其对小目标的检测精度有限，亟需更有效的方法提升相关性能。

Method: 基于RT-DETR，提出PT-DETR方法。网络结构上引入了部分感知细节关注（PADF）模块增强小目标特征提取，设计了中频率特征融合（MFFF）模块提升小目标细节与上下文的建模能力，并结合Focaler-SIoU增加模型对小目标特征和边界框匹配的敏感度。

Result: 与原RT-DETR方法相比，PT-DETR在VisDrone2019数据集上mAP分别提升了1.6%和1.7%，同时具有更低的计算复杂度和参数量。

Conclusion: PT-DETR方法提升了无人机影像中小目标检测的精度和鲁棒性，且计算开销较小，展示了其在实际小目标检测任务中的有效性和应用前景。

Abstract: To address the challenges in UAV object detection, such as complex
backgrounds, severe occlusion, dense small objects, and varying lighting
conditions,this paper proposes PT-DETR based on RT-DETR, a novel detection
algorithm specifically designed for small objects in UAV imagery. In the
backbone network, we introduce the Partially-Aware Detail Focus (PADF) Module
to enhance feature extraction for small objects. Additionally,we design the
Median-Frequency Feature Fusion (MFFF) module,which effectively improves the
model's ability to capture small-object details and contextual information.
Furthermore,we incorporate Focaler-SIoU to strengthen the model's bounding box
matching capability and increase its sensitivity to small-object features,
thereby further enhancing detection accuracy and robustness. Compared with
RT-DETR, our PT-DETR achieves mAP improvements of 1.6% and 1.7% on the
VisDrone2019 dataset with lower computational complexity and fewer parameters,
demonstrating its robustness and feasibility for small-object detection tasks.

</details>


### [57] [All You Need for Object Detection: From Pixels, Points, and Prompts to Next-Gen Fusion and Multimodal LLMs/VLMs in Autonomous Vehicles](https://arxiv.org/abs/2510.26641)
*Sayed Pedram Haeri Boroujeni,Niloufar Mehrabi,Hazim Alzorgan,Ahmad Sarlak,Mahlagha Fazeli,Abolfazl Razi*

Main category: cs.CV

TL;DR: 本综述聚焦于自动驾驶汽车（AVs）中的目标检测前沿，总结传感器融合、数据集结构、最新AI模型（如VLM、LLM、生成式AI）在动态场景下的应用，并分析当前挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: 尽管智能视觉与AI已带动AV目标检测显著进展，但相关知识在多模态感知、情境推理与协同智能间仍较为零散。该综述旨在综合整理前沿趋势，弥合此领域的知识分散问题。

Method: 作者系统性回顾了AV常用各类传感器（相机、超声波、激光雷达、毫米波雷达）及其融合策略，并重点探讨了它们在结合新兴大型语言与视觉语言模型（LLM/VLM）驱动的感知下的潜力。同时对主流AV数据集（涵盖自车端、路侧、车-车/车-路/车-一切协作框架）进行结构化分类和分析，详评2D、3D及融合检测方法，特别关注transformer-ViT、LLM、SLM、VLM等。

Result: 该综述整理并对比了各类传感器的优劣与多模态融合架构给予AV目标检测的提升潜力。归纳了多源数据集的特性以及最新以transformer、VLM、LLM为核心的检测算法表现，突出这些方法在复杂环境下的优势和存在的技术瓶颈。

Conclusion: 文章梳理了自动驾驶感知系统当前的能力边界，直面尚未解决的开放挑战，并为未来多模态融合、AI驱动的协作感知发展勾勒清晰路线图。

Abstract: Autonomous Vehicles (AVs) are transforming the future of transportation
through advances in intelligent perception, decision-making, and control
systems. However, their success is tied to one core capability, reliable object
detection in complex and multimodal environments. While recent breakthroughs in
Computer Vision (CV) and Artificial Intelligence (AI) have driven remarkable
progress, the field still faces a critical challenge as knowledge remains
fragmented across multimodal perception, contextual reasoning, and cooperative
intelligence. This survey bridges that gap by delivering a forward-looking
analysis of object detection in AVs, emphasizing emerging paradigms such as
Vision-Language Models (VLMs), Large Language Models (LLMs), and Generative AI
rather than re-examining outdated techniques. We begin by systematically
reviewing the fundamental spectrum of AV sensors (camera, ultrasonic, LiDAR,
and Radar) and their fusion strategies, highlighting not only their
capabilities and limitations in dynamic driving environments but also their
potential to integrate with recent advances in LLM/VLM-driven perception
frameworks. Next, we introduce a structured categorization of AV datasets that
moves beyond simple collections, positioning ego-vehicle, infrastructure-based,
and cooperative datasets (e.g., V2V, V2I, V2X, I2I), followed by a
cross-analysis of data structures and characteristics. Ultimately, we analyze
cutting-edge detection methodologies, ranging from 2D and 3D pipelines to
hybrid sensor fusion, with particular attention to emerging transformer-driven
approaches powered by Vision Transformers (ViTs), Large and Small Language
Models (SLMs), and VLMs. By synthesizing these perspectives, our survey
delivers a clear roadmap of current capabilities, open challenges, and future
opportunities.

</details>


### [58] [Towards Reliable Sea Ice Drift Estimation in the Arctic Deep Learning Optical Flow on RADARSAT-2](https://arxiv.org/abs/2510.26653)
*Daniela Martin,Joseph Gallego*

Main category: cs.CV

TL;DR: 本文首次系统性评估了48种深度学习光流模型在RADARSAT-2海冰遥感影像上的表现，并验证了这些方法优于传统方法，可高精度估计北极海冰漂移。


<details>
  <summary>Details</summary>
Motivation: 海冰漂移的准确估计对北极航行、气候研究和业务预测至关重要。传统光流方法对遥感图像适用性有限，深度学习光流在地球物理和遥感中的潜力有待验证。

Method: 作者在GNSS跟踪浮标真实数据基础上，构建了大规模基准数据，系统性测试了48个深度学习光流模型在RADARSAT-2 ScanSAR海冰影像的漂移估计能力，使用EPE和Fl等指标评价其性能。

Result: 多款模型实现了端点误差6~8像素（约300~400m），达到了远优于传统方法的精度，且能够稳定抓取区域性海冰漂移的空间分布规律。

Conclusion: 深度学习光流方法可准确、连续地估算每个像素的海冰漂移，显著优于稀疏浮标观测，能为北极航行和气候建模提供新工具，应积极推动其在极地遥感中的应用。

Abstract: Accurate estimation of sea ice drift is critical for Arctic navigation,
climate research, and operational forecasting. While optical flow, a computer
vision technique for estimating pixel wise motion between consecutive images,
has advanced rapidly in computer vision, its applicability to geophysical
problems and to satellite SAR imagery remains underexplored. Classical optical
flow methods rely on mathematical models and strong assumptions about motion,
which limit their accuracy in complex scenarios. Recent deep learning based
approaches have substantially improved performance and are now the standard in
computer vision, motivating their application to sea ice drift estimation. We
present the first large scale benchmark of 48 deep learning optical flow models
on RADARSAT 2 ScanSAR sea ice imagery, evaluated with endpoint error (EPE) and
Fl all metrics against GNSS tracked buoys. Several models achieve sub kilometer
accuracy (EPE 6 to 8 pixels, 300 to 400 m), a small error relative to the
spatial scales of sea ice motion and typical navigation requirements in the
Arctic. Our results demonstrate that the models are capable of capturing
consistent regional drift patterns and that recent deep learning based optical
flow methods, which have substantially improved motion estimation accuracy
compared to classical methods, can be effectively transferred to polar remote
sensing. Optical flow produces spatially continuous drift fields, providing
motion estimates for every image pixel rather than at sparse buoy locations,
offering new opportunities for navigation and climate modeling.

</details>


### [59] [Improving Classification of Occluded Objects through Scene Context](https://arxiv.org/abs/2510.26681)
*Courtney M. King,Daniel D. Leeds,Damian Lyons,George Kalaitzis*

Main category: cs.CV

TL;DR: 该论文提出了两种融合场景信息的方法，以提升物体检测算法在被遮挡情况下的性能，均通过在部分遮挡数据集上实验验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的强大物体识别算法在存在遮挡时表现不佳，而生物视觉中的场景上下文已被证明有助于物体识别。因此，希望引入场景信息来提升当前检测网络的鲁棒性。

Method: 提出两种场景信息融合策略：一种为检测前利用背景场景选择定制的物体检测网络，另一种为检测后将场景知识融合到初步检测分数中。此外，对不同遮挡处理训练方法（只用有遮挡，只用无遮挡，和两者结合）进行对比实验。

Result: 在含有部分遮挡的公开数据集上，两种方法都在召回率和精度上优于现有基线方法。联合遮挡和无遮挡图像训练带来最优检测效果。

Conclusion: 融合场景信息可显著提升物体检测在遮挡情况下的表现。该方法易于理解且能适应其他数据集，具有良好的实际应用前景及进一步研究空间。

Abstract: The presence of occlusions has provided substantial challenges to
typically-powerful object recognition algorithms. Additional sources of
information can be extremely valuable to reduce errors caused by occlusions.
Scene context is known to aid in object recognition in biological vision. In
this work, we attempt to add robustness into existing Region Proposal
Network-Deep Convolutional Neural Network (RPN-DCNN) object detection networks
through two distinct scene-based information fusion techniques. We present one
algorithm under each methodology: the first operates prior to prediction,
selecting a custom object network to use based on the identified background
scene, and the second operates after detection, fusing scene knowledge into
initial object scores output by the RPN. We demonstrate our algorithms on
challenging datasets featuring partial occlusions, which show overall
improvement in both recall and precision against baseline methods. In addition,
our experiments contrast multiple training methodologies for occlusion
handling, finding that training on a combination of both occluded and
unoccluded images demonstrates an improvement over the others. Our method is
interpretable and can easily be adapted to other datasets, offering many future
directions for research and practical applications.

</details>


### [60] [Process Integrated Computer Vision for Real-Time Failure Prediction in Steel Rolling Mill](https://arxiv.org/abs/2510.26684)
*Vaibhav Kurrey,Sivakalyan Pujari,Gagan Raj Gupta*

Main category: cs.CV

TL;DR: 本文介绍了一种基于机器视觉的智能异常检测系统，在钢铁轧制生产线长期部署，能预测设备故障并辅助维护。


<details>
  <summary>Details</summary>
Motivation: 钢铁轧制生产线中设备故障和非计划性停机会带来高昂的损失，急需实时、准确的预测与预警系统以提升生产可靠性和降低维护成本。

Method: 该系统在生产线上整合工业摄像头，实时监控设备运行、对准和热坯条运动。视频数据被上传至中心服务器，利用深度学习模型进行分析和早期故障预测。推理过程在服务器端完成，减轻了现场PLC的计算压力，同时还结合来自传感器的数据进行联合分析。

Result: 系统能准确预测并定位潜在故障，为维护提供决策支持，降低了非计划性停机成本，提高了生产可靠性和整体效益。服务器端推理的架构也便于在多条生产线上规模化部署。

Conclusion: 基于摄像头和多模态数据的集成方法有效提高了工业制造现场的可靠性、生产效率和盈利能力，具有推广价值。

Abstract: We present a long-term deployment study of a machine vision-based anomaly
detection system for failure prediction in a steel rolling mill. The system
integrates industrial cameras to monitor equipment operation, alignment, and
hot bar motion in real time along the process line. Live video streams are
processed on a centralized video server using deep learning models, enabling
early prediction of equipment failures and process interruptions, thereby
reducing unplanned breakdown costs. Server-based inference minimizes the
computational load on industrial process control systems (PLCs), supporting
scalable deployment across production lines with minimal additional resources.
By jointly analyzing sensor data from data acquisition systems and visual
inputs, the system identifies the location and probable root causes of
failures, providing actionable insights for proactive maintenance. This
integrated approach enhances operational reliability, productivity, and
profitability in industrial manufacturing environments.

</details>


### [61] [Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark](https://arxiv.org/abs/2510.26802)
*Ziyu Guo,Xinyan Chen,Renrui Zhang,Ruichuan An,Yu Qi,Dongzhi Jiang,Xiangtai Li,Manyuan Zhang,Hongsheng Li,Pheng-Ann Heng*

Main category: cs.CV

TL;DR: 本文系统评估了当前领先的视频生成模型（如Veo-3）是否能在复杂视觉推理任务中胜任零样本推理，通过12个维度的基准测试发现模型在短期空间一致性等方面表现较好，但在长期因果推理和抽象逻辑等方面仍有明显不足。


<details>
  <summary>Details</summary>
Motivation: 近年来视频生成模型展现出极高的视频质量和一定的视觉理解能力，这促使研究者关注它们能否进一步胜任高级视觉推理任务，特别是在无需额外训练的零样本推理场景下，因此需要全面、系统地评估其推理能力及局限性。

Method: 作者选择了Veo-3等主流视频生成模型，从空间、几何、物理、时序和具身逻辑等12个不同的推理维度进行评估，并设计了名为MME-CoF的标准化评测基准，专注于链式帧推理（Chain-of-Frame, CoF），对模型的推理表现及失效模式进行系统分析。

Result: 实验表明，视频模型在短期空间一致性、细粒度定位和局部动态规律等方面已有显著进展，但在长期因果推理、复杂几何约束和抽象逻辑能力方面表现不足，存在明显的短板。

Conclusion: 当前的视频生成模型尚不能独立作为零样本视觉推理工具，可靠性有限，但作为现有推理模型的视觉补充引擎已有可观潜力，未来可进一步拓展其推理能力。

Abstract: Recent video generation models can produce high-fidelity, temporally coherent
videos, indicating that they may encode substantial world knowledge. Beyond
realistic synthesis, they also exhibit emerging behaviors indicative of visual
perception, modeling, and manipulation. Yet, an important question still
remains: Are video models ready to serve as zero-shot reasoners in challenging
visual reasoning scenarios? In this work, we conduct an empirical study to
comprehensively investigate this question, focusing on the leading and popular
Veo-3. We evaluate its reasoning behavior across 12 dimensions, including
spatial, geometric, physical, temporal, and embodied logic, systematically
characterizing both its strengths and failure modes. To standardize this study,
we curate the evaluation data into MME-CoF, a compact benchmark that enables
in-depth and thorough assessment of Chain-of-Frame (CoF) reasoning. Our
findings reveal that while current video models demonstrate promising reasoning
patterns on short-horizon spatial coherence, fine-grained grounding, and
locally consistent dynamics, they remain limited in long-horizon causal
reasoning, strict geometric constraints, and abstract logic. Overall, they are
not yet reliable as standalone zero-shot reasoners, but exhibit encouraging
signs as complementary visual engines alongside dedicated reasoning models.
Project page: https://video-cof.github.io

</details>


### [62] [The Impact and Outlook of 3D Gaussian Splatting](https://arxiv.org/abs/2510.26694)
*Bernhard Kerbl*

Main category: cs.CV

TL;DR: 本文综述了3D高斯投影（3D Gaussian Splatting, 3DGS）自问世以来在3D场景表示领域的革命性发展及其衍生研究。


<details>
  <summary>Details</summary>
Motivation: 3DGS的出现极大提升了3D场景表示的表现力和效率，激发了如何进一步提高其效率、可扩展性和实际应用性的研究需求。

Method: 文章总结了3DGS相关研究的几个方向，包括资源高效的训练与渲染方法、动态（4DGS）表示、数学建模及渲染理论、移动端和虚拟现实平台适配、超大规模环境扩展，以及通过前馈或分布式计算实现准即时辐射场重建等。

Result: 这些研究方向带来了在不同平台、不同规模和不同应用场景下对3DGS的显著优化与扩展。

Conclusion: 3DGS已经从创新的3D表示方法成长为3D视觉与图形领域核心且多元化的基础工具。

Abstract: Since its introduction, 3D Gaussian Splatting (3DGS) has rapidly transformed
the landscape of 3D scene representations, inspiring an extensive body of
associated research. Follow-up work includes analyses and contributions that
enhance the efficiency, scalability, and real-world applicability of 3DGS. In
this summary, we present an overview of several key directions that have
emerged in the wake of 3DGS. We highlight advances enabling resource-efficient
training and rendering, the evolution toward dynamic (or four-dimensional,
4DGS) representations, and deeper exploration of the mathematical foundations
underlying its appearance modeling and rendering process. Furthermore, we
examine efforts to bring 3DGS to mobile and virtual reality platforms, its
extension to massive-scale environments, and recent progress toward
near-instant radiance field reconstruction via feed-forward or distributed
computation. Collectively, these developments illustrate how 3DGS has evolved
from a breakthrough representation into a versatile and foundational tool for
3D vision and graphics.

</details>


### [63] [SteerVLM: Robust Model Control through Lightweight Activation Steering for Vision Language Models](https://arxiv.org/abs/2510.26769)
*Anushka Sivakumar,Andrew Zhang,Zaber Hakim,Chris Thomas*

Main category: cs.CV

TL;DR: SteerVLM提出了一种轻量级模块，可以在不修改模型权重的前提下，引导视觉-语言模型（VLM）产生更符合指定指令的输出，并通过新构建的多模态数据集进行评测，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言模型在理解和执行复杂指令时，缺乏灵活可控的方法，只能通过修改模型权重或繁琐的人工干预，难以在不影响其他任务性能的前提下实现精细化控制。为此，作者希望为VLM提供一种高效、灵活的“模型操控”手段。

Method: 作者设计了一种仅占原模型0.14%参数量的steering module，通过学习目标指令及其反向行为的隐空间表达，动态调整模型跨模态激活，实现了维度级别和跨层自适应调控，无需手动干预点或静态向量提取。同时，构建了VNIA多模态数据集用于VLM操控技术的开发与评估。

Result: 实验显示，该方法在VLM操控及“幻觉”缓解基准任务上优于已有相关干预技术，并能够在不损害非目标任务性能的情况下提升输出的指令一致性。

Conclusion: SteerVLM为多模态大模型提供了一种高效、实用的激活调控解决方案，推动了模型灵活可控性的发展，并提供了新的评测数据集支持领域后续研究。

Abstract: This work introduces SteerVLM, a lightweight steering module designed to
guide Vision-Language Models (VLMs) towards outputs that better adhere to
desired instructions. Our approach learns from the latent embeddings of paired
prompts encoding target and converse behaviors to dynamically adjust
activations connecting the language modality with image context. This allows
for fine-grained, inference-time control over complex output semantics without
modifying model weights while preserving performance on off-target tasks. Our
steering module requires learning parameters equal to 0.14% of the original
VLM's size. Our steering module gains model control through dimension-wise
activation modulation and adaptive steering across layers without requiring
pre-extracted static vectors or manual tuning of intervention points.
Furthermore, we introduce VNIA (Visual Narrative Intent Alignment), a
multimodal dataset specifically created to facilitate the development and
evaluation of VLM steering techniques. Our method outperforms existing
intervention techniques on steering and hallucination mitigation benchmarks for
VLMs and proposes a robust solution for multimodal model control through
activation engineering.

</details>


### [64] [Surpassing state of the art on AMD area estimation from RGB fundus images through careful selection of U-Net architectures and loss functions for class imbalance](https://arxiv.org/abs/2510.26778)
*Valentyna Starodub,Mantas Lukoševičius*

Main category: cs.CV

TL;DR: 本研究提出改进的基于U-Net的深度学习方法，实现了RGB眼底图像中年龄相关性黄斑变性（AMD）病灶更优的语义分割性能，并超过了ADAM挑战赛过往所有结果。


<details>
  <summary>Details</summary>
Motivation: AMD是老年人不可逆致盲主要原因之一，现有RGB眼底照片易采集但自动检测算法仍有提升空间，尤其是在多类别病灶分割上。

Method: 以U-Net为基础，比较多种预处理方法、不同深度网络Backbone、针对类别不均衡设计的loss函数等配置，优化分割模型，在ADAM公开基准数据集上验证效果。

Result: 最终提出的模型在多类别AMD病灶分割任务上取得了优于ADAM挑战历史最佳的结果。相关实验代码已开源。

Conclusion: 创新U-Net增强体系大幅提升了AMD多类别病灶自动分割准确性，验证了RGB眼底影像结合深度学习的潜力，推动了眼底疾病辅助诊断发展。

Abstract: Age-related macular degeneration (AMD) is one of the leading causes of
irreversible vision impairment in people over the age of 60. This research
focuses on semantic segmentation for AMD lesion detection in RGB fundus images,
a non-invasive and cost-effective imaging technique. The results of the ADAM
challenge - the most comprehensive AMD detection from RGB fundus images
research competition and open dataset to date - serve as a benchmark for our
evaluation. Taking the U-Net connectivity as a base of our framework, we
evaluate and compare several approaches to improve the segmentation model's
architecture and training pipeline, including pre-processing techniques,
encoder (backbone) deep network types of varying complexity, and specialized
loss functions to mitigate class imbalances on image and pixel levels. The main
outcome of this research is the final configuration of the AMD detection
framework, which outperforms all the prior ADAM challenge submissions on the
multi-class segmentation of different AMD lesion types in non-invasive RGB
fundus images. The source code used to conduct the experiments presented in
this paper is made freely available.

</details>


### [65] [ChartAB: A Benchmark for Chart Grounding & Dense Alignment](https://arxiv.org/abs/2510.26781)
*Aniruddh Bansal,Davit Soselia,Dang Nguyen,Tianyi Zhou*

Main category: cs.CV

TL;DR: 本文提出了ChartAlign Benchmark (ChartAB)，用于全面评估视觉-语言模型（VLM）在图表识别与理解中的表现，通过更细粒度的任务和评价方式揭示了现有模型在不同环节的短板与偏见。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉-语言模型在图像与文本结合任务中表现出色，但在对图表细节的感知和结构提取方面仍有不足，致使模型难以准确比较和推理多个图表。这限制了它们在数据分析和可视化理解场景的应用能力。

Method: 作者构建了ChartAB基准，包括多样化类型和复杂度的图表，覆盖数据提取、元素定位和属性识别等任务；设计了专门的JSON模板用于任务相关评估；引入了两阶段推理流程，进一步考查模型在跨图表元素/属性对齐与比较方面的能力。

Result: 用多个当前主流VLM进行评测，揭示了这些模型在图表理解时存在的感知偏见、弱点、鲁棒性问题及幻觉现象，并量化了不同模型在细粒度任务上的表现差异。

Conclusion: 结果显示当前VLM在图表理解任务中表现存在诸多不足。该工作明确指出了现有模型需加强的具体技能，为后续VLM相关研究和应用提供了针对性发展方向。

Abstract: Charts play an important role in visualization, reasoning, data analysis, and
the exchange of ideas among humans. However, existing vision-language models
(VLMs) still lack accurate perception of details and struggle to extract
fine-grained structures from charts. Such limitations in chart grounding also
hinder their ability to compare multiple charts and reason over them. In this
paper, we introduce a novel "ChartAlign Benchmark (ChartAB)" to provide a
comprehensive evaluation of VLMs in chart grounding tasks, i.e., extracting
tabular data, localizing visualization elements, and recognizing various
attributes from charts of diverse types and complexities. We design a JSON
template to facilitate the calculation of evaluation metrics specifically
tailored for each grounding task. By incorporating a novel two-stage inference
workflow, the benchmark can further evaluate VLMs' capability to align and
compare elements/attributes across two charts. Our analysis of evaluations on
several recent VLMs reveals new insights into their perception biases,
weaknesses, robustness, and hallucinations in chart understanding. These
findings highlight the fine-grained discrepancies among VLMs in chart
understanding tasks and point to specific skills that need to be strengthened
in current models.

</details>


### [66] [HEIR: Learning Graph-Based Motion Hierarchies](https://arxiv.org/abs/2510.26786)
*Cheng Zheng,William Koch,Baiang Li,Felix Heide*

Main category: cs.CV

TL;DR: 该论文提出了一种通用的分层运动建模方法，能够从数据中自动学习和解释运动层级关系，无需人为手动设定基础运动单元。


<details>
  <summary>Details</summary>
Motivation: 当前运动分层建模常依赖人工设定的层级结构和固定的运动基元，导致模型在不同任务上的泛化能力有限，因此亟需一种能适应多类任务、可自动学习运动层级关系的建模方法。

Method: 作者提出以图结构表示所观察到的运动，将整体运动分解为父节点继承的运动模式和局部残差，并将层级推断问题形式化为可微分的图学习任务。具体方法采用图神经网络，节点代表基础运动，边则捕捉学习得到的父-子依赖关系。方法在一维平移、二维旋转以及三维场景高斯点动态形变三类任务上开展评测。

Result: 该方法在一维与二维实验中能够成功重建真实的运动层级，在三维高斯点动态形变场景下，产生比基线方法更加真实和易于解释的运动结果。

Conclusion: 本文提出的方法具备很强的泛化能力和解释性，为需用到运动层次结构的广泛任务提供了一种数据驱动、可扩展的分层运动建模范式。

Abstract: Hierarchical structures of motion exist across research fields, including
computer vision, graphics, and robotics, where complex dynamics typically arise
from coordinated interactions among simpler motion components. Existing methods
to model such dynamics typically rely on manually-defined or heuristic
hierarchies with fixed motion primitives, limiting their generalizability
across different tasks. In this work, we propose a general hierarchical motion
modeling method that learns structured, interpretable motion relationships
directly from data. Our method represents observed motions using graph-based
hierarchies, explicitly decomposing global absolute motions into
parent-inherited patterns and local motion residuals. We formulate hierarchy
inference as a differentiable graph learning problem, where vertices represent
elemental motions and directed edges capture learned parent-child dependencies
through graph neural networks. We evaluate our hierarchical reconstruction
approach on three examples: 1D translational motion, 2D rotational motion, and
dynamic 3D scene deformation via Gaussian splatting. Experimental results show
that our method reconstructs the intrinsic motion hierarchy in 1D and 2D cases,
and produces more realistic and interpretable deformations compared to the
baseline on dynamic 3D Gaussian splatting scenes. By providing an adaptable,
data-driven hierarchical modeling paradigm, our method offers a formulation
applicable to a broad range of motion-centric tasks. Project Page:
https://light.princeton.edu/HEIR/

</details>


### [67] [The Quest for Generalizable Motion Generation: Data, Model, and Evaluation](https://arxiv.org/abs/2510.26794)
*Jing Lin,Ruisi Wang,Junzhe Lu,Ziqi Huang,Guorui Song,Ailing Zeng,Xian Liu,Chen Wei,Wanqi Yin,Qingping Sun,Zhongang Cai,Lei Yang,Ziwei Liu*

Main category: cs.CV

TL;DR: 该论文提出了将视频生成（ViGen）领域在动作建模上的优势系统性地迁移到3D人体动作生成（MoGen）中，利用大规模数据集、统一建模框架和新的评测基准，有效提升了动作生成模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 虽然3D人体动作生成取得进展，但泛化能力依然落后于视频生成领域。如何借鉴ViGen在行为建模上的成功经验，提升MoGen的表现，是当前的核心挑战。

Method: 1）构建ViMoGen-228K数据集，融合高质量MoCap动作、语义标注的网络视频动作以及ViGen模型生成的数据，覆盖文本-动作和文本-视频-动作对；2）设计了ViMoGen扩散transformer模型，通过门控多模态条件，融合MoCap和ViGen先验；3）推出ViMoGen-light蒸馏变体，实现高效无ViGen依赖的泛化动作生成；4）构建MBench分层基准，精细评估动作质量、指令符合度与泛化能力。

Result: 在多个自动评测与人工评测中，所提出的框架均明显优于现有方法。

Conclusion: 将ViGen知识系统性迁移到MoGen可大幅提升后者的泛化能力，新提出的数据集、模型和评测工具为领域提供了新的研究基础，相关资源将开放共享。

Abstract: Despite recent advances in 3D human motion generation (MoGen) on standard
benchmarks, existing models still face a fundamental bottleneck in their
generalization capability. In contrast, adjacent generative fields, most
notably video generation (ViGen), have demonstrated remarkable generalization
in modeling human behaviors, highlighting transferable insights that MoGen can
leverage. Motivated by this observation, we present a comprehensive framework
that systematically transfers knowledge from ViGen to MoGen across three key
pillars: data, modeling, and evaluation. First, we introduce ViMoGen-228K, a
large-scale dataset comprising 228,000 high-quality motion samples that
integrates high-fidelity optical MoCap data with semantically annotated motions
from web videos and synthesized samples generated by state-of-the-art ViGen
models. The dataset includes both text-motion pairs and text-video-motion
triplets, substantially expanding semantic diversity. Second, we propose
ViMoGen, a flow-matching-based diffusion transformer that unifies priors from
MoCap data and ViGen models through gated multimodal conditioning. To enhance
efficiency, we further develop ViMoGen-light, a distilled variant that
eliminates video generation dependencies while preserving strong
generalization. Finally, we present MBench, a hierarchical benchmark designed
for fine-grained evaluation across motion quality, prompt fidelity, and
generalization ability. Extensive experiments show that our framework
significantly outperforms existing approaches in both automatic and human
evaluations. The code, data, and benchmark will be made publicly available.

</details>


### [68] [Scaling Image Geo-Localization to Continent Level](https://arxiv.org/abs/2510.26795)
*Philipp Lindenberger,Paul-Edouard Sarlin,Jan Hosang,Matteo Balice,Marc Pollefeys,Simon Lynen,Eduard Trulls*

Main category: cs.CV

TL;DR: 本文提出了一种混合方法，实现了在欧洲大范围区域内对图像进行细粒度地理定位。它通过结合分类任务和跨视角嵌入，显著提升了精度和检索效率。


<details>
  <summary>Details</summary>
Motivation: 现有图像地理定位方法在大规模场景和数据稀疏时效果有限，难以实现高精度和高效率兼备的定位，尤其是在如跨国家大面积区域的应用中。

Method: 作者提出了一种混合方法：在训练阶段通过代理分类任务学习富含位置信息的特征表征，再将这些表征与航空影像的嵌入结合，以提升地面数据稀疏下的鲁棒性，实现直接细粒度检索。

Result: 在覆盖欧洲大部分地区的数据集上，方法可将超过68%的查询图片定位在200米以内，表现优于现有技术。

Conclusion: 该混合方法有效解决了大尺度区域细粒度定位的挑战，兼具准确率和检索效率，并有望推广到更大范围和更多实际应用中。

Abstract: Determining the precise geographic location of an image at a global scale
remains an unsolved challenge. Standard image retrieval techniques are
inefficient due to the sheer volume of images (>100M) and fail when coverage is
insufficient. Scalable solutions, however, involve a trade-off: global
classification typically yields coarse results (10+ kilometers), while
cross-view retrieval between ground and aerial imagery suffers from a domain
gap and has been primarily studied on smaller regions. This paper introduces a
hybrid approach that achieves fine-grained geo-localization across a large
geographic expanse the size of a continent. We leverage a proxy classification
task during training to learn rich feature representations that implicitly
encode precise location information. We combine these learned prototypes with
embeddings of aerial imagery to increase robustness to the sparsity of
ground-level data. This enables direct, fine-grained retrieval over areas
spanning multiple countries. Our extensive evaluation demonstrates that our
approach can localize within 200m more than 68\% of queries of a dataset
covering a large part of Europe. The code is publicly available at
https://scaling-geoloc.github.io.

</details>


### [69] [SEE4D: Pose-Free 4D Generation via Auto-Regressive Video Inpainting](https://arxiv.org/abs/2510.26796)
*Dongyue Lu,Ao Liang,Tianxin Huang,Xiao Fu,Yuyang Zhao,Baorui Ma,Liang Pan,Wei Yin,Lingdong Kong,Wei Tsang Ooi,Ziwei Liu*

Main category: cs.CV

TL;DR: 本文提出SEE4D方法，实现无需3D相机位姿监督即可由日常视频合成时空4D内容。该方法摒弃了繁琐的相机参数标注和易出错的轨迹建模，采用固定虚拟相机和视频修复网络实现跨视角视频生成与4D场景建模，效果和泛化能力优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 沉浸式应用需要高效4D内容生成，但现有方法需手工标注相机位姿，这既繁琐又不适合‘野外’场景。作者希望去除人工位姿依赖，提高4D模型实用性与推广性。

Method: SEE4D采用虚拟固定相机渲染，完全去除对真实相机轨迹的要求。借助条件化视频修复模型实现视图间像素的补全，以及端到端时空自回归推理管线，合成连贯4D视频内容，无需3D注释。

Result: 在不同视角视频生成和稀疏重建任务上，SEE4D在各项定量指标和主观评测上均优于依赖位姿或轨迹的主流方法，实现更强泛化能力和更好性能。

Conclusion: SEE4D创新性地实现了无需3D/位姿标注的4D建模，在复杂真实场景下表现优秀，推动了日常视频到高质量4D内容的实用化。

Abstract: Immersive applications call for synthesizing spatiotemporal 4D content from
casual videos without costly 3D supervision. Existing video-to-4D methods
typically rely on manually annotated camera poses, which are labor-intensive
and brittle for in-the-wild footage. Recent warp-then-inpaint approaches
mitigate the need for pose labels by warping input frames along a novel camera
trajectory and using an inpainting model to fill missing regions, thereby
depicting the 4D scene from diverse viewpoints. However, this
trajectory-to-trajectory formulation often entangles camera motion with scene
dynamics and complicates both modeling and inference. We introduce SEE4D, a
pose-free, trajectory-to-camera framework that replaces explicit trajectory
prediction with rendering to a bank of fixed virtual cameras, thereby
separating camera control from scene modeling. A view-conditional video
inpainting model is trained to learn a robust geometry prior by denoising
realistically synthesized warped images and to inpaint occluded or missing
regions across virtual viewpoints, eliminating the need for explicit 3D
annotations. Building on this inpainting core, we design a spatiotemporal
autoregressive inference pipeline that traverses virtual-camera splines and
extends videos with overlapping windows, enabling coherent generation at
bounded per-step complexity. We validate See4D on cross-view video generation
and sparse reconstruction benchmarks. Across quantitative metrics and
qualitative assessments, our method achieves superior generalization and
improved performance relative to pose- or trajectory-conditioned baselines,
advancing practical 4D world modeling from casual videos.

</details>


### [70] [Masked Diffusion Captioning for Visual Feature Learning](https://arxiv.org/abs/2510.26799)
*Chao Feng,Zihao Wei,Andrew Owens*

Main category: cs.CV

TL;DR: 本文提出了一种新的视觉特征学习方法，通过图像条件的掩码扩散语言模型对图像进行描述，实现了具竞争力的视觉特征提取。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉特征学习方法（如自回归描述和对比学习）存在学习信号依赖位置或需要辅助目标等问题，寻求一种信号更均衡、方法更简单的特征学习方式。

Method: 提出了掩码扩散描述（MDC）方法：在训练阶段，将每对图像与文本描述中的词元随机掩码，利用视觉特征作为条件，通过解码器重建原始文本，无需依赖序列中每个词元的位置。

Result: 在多个学术数据集和模型上的线性探查实验显示，MDC学习到的视觉特征与主流的自回归和对比方法具备竞争性。

Conclusion: MDC无需依赖序列位置或额外目标也可有效学习视觉特征，表明这一新方法是实现高质量视觉表征的有力方案。

Abstract: We learn visual features by captioning images with an image-conditioned
masked diffusion language model, a formulation we call masked diffusion
captioning (MDC). During training, text tokens in each image-caption pair are
masked at a randomly chosen ratio, and a decoder conditioned on visual features
is trained to reconstruct the original text. After training, the learned visual
features can be applied to downstream vision tasks. Unlike autoregressive
captioning, the strength of the visual learning signal in MDC does not depend
on each token's position in the sequence, reducing the need for auxiliary
objectives. Linear probing experiments across a variety of academic-scale
models and datasets show that the learned visual features are competitive with
those produced by autoregressive and contrastive approaches.

</details>


### [71] [OmniX: From Unified Panoramic Generation and Perception to Graphics-Ready 3D Scenes](https://arxiv.org/abs/2510.26800)
*Yukun Huang,Jiwen Yu,Yanning Zhou,Jianan Wang,Xintao Wang,Pengfei Wan,Xihui Liu*

Main category: cs.CV

TL;DR: 本文提出OmniX框架，利用2D生成模型提升全景感知能力，实现高质量、可物理渲染的3D场景生成。


<details>
  <summary>Details</summary>
Motivation: 当前3D场景构建主要有两类方法：过程生成和基于2D全景图的生成。后者正变得流行，因为它能利用强大的2D生成式模型先验，生成更具沉浸感、现实感和多样性的3D环境。然而现有方法多只重外观，忽略了物理属性的感知，难以应用于物理基础渲染等高质量需求。

Method: 提出OmniX，一个基于高效跨模态适配器结构的统一框架，将2D生成式模型的先验迁移到全景下，实现对几何、材质和PBR物理属性的感知和生成。该方法涵盖全景感知、生成与补全任务，并构建了包含多样化高质量多模态全景图的大规模合成数据集。

Result: OmniX在广泛的实验中展现出卓越的全景视觉感知与面向图形的3D场景生成能力，生成结果适用于PBR、重光照和虚拟仿真等用途。

Conclusion: OmniX有效提升了全景基础上的3D场景生成质量与实用性，为沉浸式、物理真实的虚拟世界生成开拓了新方向。

Abstract: There are two prevalent ways to constructing 3D scenes: procedural generation
and 2D lifting. Among them, panorama-based 2D lifting has emerged as a
promising technique, leveraging powerful 2D generative priors to produce
immersive, realistic, and diverse 3D environments. In this work, we advance
this technique to generate graphics-ready 3D scenes suitable for physically
based rendering (PBR), relighting, and simulation. Our key insight is to
repurpose 2D generative models for panoramic perception of geometry, textures,
and PBR materials. Unlike existing 2D lifting approaches that emphasize
appearance generation and ignore the perception of intrinsic properties, we
present OmniX, a versatile and unified framework. Based on a lightweight and
efficient cross-modal adapter structure, OmniX reuses 2D generative priors for
a broad range of panoramic vision tasks, including panoramic perception,
generation, and completion. Furthermore, we construct a large-scale synthetic
panorama dataset containing high-quality multimodal panoramas from diverse
indoor and outdoor scenes. Extensive experiments demonstrate the effectiveness
of our model in panoramic visual perception and graphics-ready 3D scene
generation, opening new possibilities for immersive and physically realistic
virtual world generation.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [72] [StreetMath: Study of LLMs' Approximation Behaviors](https://arxiv.org/abs/2510.25776)
*Chiung-Yi Tseng,Somshubhra Roy,Maisha Thasin,Danyang Zhang,Blessing Effiong*

Main category: cs.CL

TL;DR: 本文引入StreetMath基准，用于评估大语言模型（LLM）在现实近似数学推理任务中的表现，并通过机制可解释性方法剖析其内部计算过程。结果显示LLM在接近运算任务中表现出精确计算倾向，且近似与精确计算涉及的网络模块较为独立。


<details>
  <summary>Details</summary>
Motivation: 虽然现有研究主要关注LLM在精准算术上的推理能力，但其在非自回归结构下应对生活中快速、非精确数学推理的能力受到的关注较少。该论文希望解决此研究空白。

Method: 作者提出了StreetMath基准，模拟真实世界下的近似运算场景，并对多种LLM架构（如Qwen、Dream、Falcon-Mamba等）进行了广泛评测。同时利用机制可解释性探查模型解决近似问题时的内部状态变化，并比较精确与近似运算涉及的神经模块。

Result: 实验证明，LLM面对近似问题时通常仍倾向于精确计算或调用外部工具，有时早期层可得出正确答案，但整体消耗更多token。精确与近似计算涉及的神经元模块大体分离。此外，现有LLM不像人类那样在生活数学推理时表现出“认知吝啬”。

Conclusion: LLM在现实近似数学问题上缺乏人类式的快速、粗略推理能力，未来提升LLM的“街头数学”表现需要新架构或机制。该基准已经开源，有助于后续研究。

Abstract: There is a substantial body of literature examining the mathematical
reasoning capabilities of large language models (LLMs), particularly their
performance on precise arithmetic operations in autoregressive architectures.
However, their ability to perform approximate reasoning in informal, fast-paced
mathematical operations has received far less attention, especially among
non-autoregressive decoder models. Our work addresses this gap by introducing
StreetMath, a benchmark designed to evaluate models' approximation abilities
under real-world approximation scenarios. We conduct extensive evaluations
across different LLM architectures: Qwen3-4B-Instruct-2507,
Qwen3-4B-Thinking-2507, Dream-v0-Instruct-7B, Falcon-Mamba-7B-Instruct, and
Mamba-GPT-3B. Furthermore, we apply mechanistic interpretability techniques to
probe their internal computational states. Our analysis reveals that LLMs
generally attempt to compute exact values or invoke external tools even in
tasks that call for approximation. Moreover, while models sometimes reach the
correct answer in early layers or steps, they still consume more tokens when
solving approximation tasks. Additional experiments indicate that exact and
approximate arithmetic operations rely on largely separate neural components.
Drawing upon research on cognitive psychology, we argue that LLMs do not
exhibit cognitive miserliness in the same way humans do in street math
settings. We open source our work https://github.com/ctseng777/StreetMath

</details>


### [73] [Review Based Entity Ranking using Fuzzy Logic Algorithmic Approach: Analysis](https://arxiv.org/abs/2510.25778)
*Pratik N. Kalamkar,Anupama G. Phakatkar*

Main category: cs.CL

TL;DR: 本文提出了一种结合短语强度与方向性的情感分析方法，能够根据用户评价和查询内容对实体进行更细致的排序与评估。


<details>
  <summary>Details</summary>
Motivation: 现有基于词典的情感分析方法往往无法区分不同强度的情感倾向，导致对情感表达细腻度的分析不够充分，难以满足用户对于细致意见理解的需求。

Method: 提出将情感词（副词、形容词、名词、动词）根据与产品相关属性的关系分为不同情感强度层级（很弱、弱、中等、强、很强）。方法结合模糊逻辑算法对情感词进行分类，并利用句法依存解析识别情感词与特定属性关系，计算实体在某一属性上的得分。

Result: 方法有效地将情感表达依强度细分，能够更准确地反映用户在特定属性上的综合感受，并固定地为实体排行提供量化依据。

Conclusion: 本研究改进了情感分析的分辨力和适用性，使得实体排名更贴合用户真实评价，有助于细化产品或服务质量分析。

Abstract: Opinion mining, also called sentiment analysis, is the field of study that
analyzes people opinions, sentiments, evaluations, appraisals, attitudes, and
emotions towards entities such as products, services, organizations,
individuals, issues, events, topics, and their attributes. Holistic
lexicon-based approach does not consider the strength of each opinion, i.e.,
whether the opinion is very strongly negative (or positive), strongly negative
(or positive), moderate negative (or positive), very weakly negative (or
positive) and weakly negative (or positive). In this paper, we propose approach
to rank entities based on orientation and strength of the entity reviews and
user's queries by classifying them in granularity levels (i.e. very weak, weak,
moderate, very strong and strong) by combining opinion words (i.e. adverb,
adjective, noun and verb) that are related to aspect of interest of certain
product. We shall use fuzzy logic algorithmic approach in order to classify
opinion words into different category and syntactic dependency resolution to
find relations for desired aspect words. Opinion words related to certain
aspects of interest are considered to find the entity score for that aspect in
the review.

</details>


### [74] [LASTIST: LArge-Scale Target-Independent STance dataset](https://arxiv.org/abs/2510.25783)
*DongJae Kim,Yaejin Lee,Minsu Park,Eunil Park*

Main category: cs.CL

TL;DR: 该论文提出了LASTIST，这是一个超大规模的韩语立场检测数据集，旨在推进低资源语言（如韩语）的立场检测研究，并开放数据集资源。


<details>
  <summary>Details</summary>
Motivation: 目前立场检测研究主要集中在面向特定目标（target-dependent）的场景，同时绝大多数基准数据集为英文，导致低资源语言（如韩语）在该领域缺乏发展空间，急需大规模、多样化的韩语数据集支持相关研究。

Method: 作者从韩国政党发布的新闻稿中收集并标注了563,299句韩文句子，构建了LASTIST数据集。详细介绍了数据的收集、构建过程，并使用主流的深度学习与立场检测模型在该数据集上进行了训练和评估。

Result: 成功构建了韩国语的超大规模立场检测数据集，并验明其在多项立场检测任务（包括目标无关以及历时性演化任务）中的应用可行性，训练得到了具有良好表现的模型。

Conclusion: LASTIST数据集为低资源语言的立场检测特别是韩语提供了基础资源和研究平台，推动了该领域多任务、多场景的进一步研究，同时数据集已公开发布，为社区提供便利。

Abstract: Stance detection has emerged as an area of research in the field of
artificial intelligence. However, most research is currently centered on the
target-dependent stance detection task, which is based on a person's stance in
favor of or against a specific target. Furthermore, most benchmark datasets are
based on English, making it difficult to develop models in low-resource
languages such as Korean, especially for an emerging field such as stance
detection. This study proposes the LArge-Scale Target-Independent STance
(LASTIST) dataset to fill this research gap. Collected from the press releases
of both parties on Korean political parties, the LASTIST dataset uses 563,299
labeled Korean sentences. We provide a detailed description of how we collected
and constructed the dataset and trained state-of-the-art deep learning and
stance detection models. Our LASTIST dataset is designed for various tasks in
stance detection, including target-independent stance detection and diachronic
evolution stance detection. We deploy our dataset on
https://anonymous.4open.science/r/LASTIST-3721/.

</details>


### [75] [zFLoRA: Zero-Latency Fused Low-Rank Adapters](https://arxiv.org/abs/2510.25784)
*Dhananjaya Gowda,Seoha Song,Harshith Goka,Junhyun Lee*

Main category: cs.CL

TL;DR: 本文提出了一种新的低延迟融合低秩适配器（zFLoRA），不仅有效提升了大语言模型在多个下游任务上的效率，还几乎不带来推理时的延迟开销。


<details>
  <summary>Details</summary>
Motivation: 现有为大语言模型设计的任务特定适配器，虽然参数量很小，但实际推理时带来显著的计算和延迟开销，尤其是移动和高效推理设备中，这一问题突出。作者旨在解决适配器带来的延迟问题。

Method: 作者提出zFLoRA，一种零或近乎零延迟的融合低秩适配器。该方法无需牺牲性能，在推理阶段与基础模型几乎一样快。zFLoRA在模型参数调整方式上进行了改进，实现了与常规LoRA和全量微调相当甚至更优的表现。

Result: 实验在1B、3B、7B规模的大语言模型和18项任务（常识推理、数学推理、摘要对话）上进行。结果显示，zFLoRA在保持高效推理的同时，性能可对标甚至超越LoRA和全量微调，无论在NPU（S25+）还是GPU（H100）上，延迟提高都极低。

Conclusion: zFLoRA是一种为大模型下游适配设计的高效、零延迟适配器。在各平台上验证了其实用性，为大模型实际部署提供了新的解决方案。

Abstract: Large language models (LLMs) are increasingly deployed with task-specific
adapters catering to multiple downstream applications. In such a scenario, the
additional compute associated with these apparently insignificant number of
adapter parameters (typically less than 1% of the base model) turns out to be
disproportionately significant during inference time (upto 2.5x times that of
the base model). In this paper, we propose a new zero-latency fused low-rank
adapter (zFLoRA) that introduces zero or negligible latency overhead on top of
the base model. Experimental results on LLMs of size 1B, 3B and 7B show that
zFLoRA compares favorably against the popular supervised fine-tuning benchmarks
including low-rank adapters (LoRA) as well as full fine-tuning (FFT).
Experiments are conducted on 18 different tasks across three different
categories namely commonsense reasoning, math reasoning and summary-dialogue.
Latency measurements made on NPU (Samsung Galaxy S25+) as well as GPU (NVIDIA
H100) platforms show that the proposed zFLoRA adapters introduce zero to
negligible latency overhead.

</details>


### [76] [BlackboxNLP-2025 MIB Shared Task: Improving Circuit Faithfulness via Better Edge Selection](https://arxiv.org/abs/2510.25786)
*Yaniv Nikankin,Dana Arad,Itay Itzhak,Anja Reusch,Adi Simhi,Gal Kesten-Pomeranz,Yonatan Belinkov*

Main category: cs.CL

TL;DR: 本文针对机械解释性中的电路发现任务提出了三项关键改进，并在多个任务和模型上优于以往方法。


<details>
  <summary>Details</summary>
Motivation: 电路发现，即确定模型中哪些部分完成特定任务，是机械解释性的主要挑战之一。现有方法存在选边不稳定或不够真实的问题，作者希望提升发现的电路的可信度和有效性。

Method: 1. 使用自助法(bootstrapping)分析边的归因分数一致性，筛选稳定相关边。2. 采用基于分数比的新筛选策略，优先选择正向高分边，从而在性能和可信度之间取得平衡。3. 用整数线性规划(ILP)替换传统贪心选择，实现更优全局决策。

Result: 新的三步方法在多个MIB基准任务和模型上实现了更忠实(realistic/faithful)的电路发现，整体效果超过了以往的主流方法。

Conclusion: 提出的方法在电路发现上的有效性和先进性获得验证，可作为机械解释性研究的新工具。代码已开源，便于学界和业界应用与改进。

Abstract: One of the main challenges in mechanistic interpretability is circuit
discovery, determining which parts of a model perform a given task. We build on
the Mechanistic Interpretability Benchmark (MIB) and propose three key
improvements to circuit discovery. First, we use bootstrapping to identify
edges with consistent attribution scores. Second, we introduce a simple
ratio-based selection strategy to prioritize strong positive-scoring edges,
balancing performance and faithfulness. Third, we replace the standard greedy
selection with an integer linear programming formulation. Our methods yield
more faithful circuits and outperform prior approaches across multiple MIB
tasks and models. Our code is available at:
https://github.com/technion-cs-nlp/MIB-Shared-Task.

</details>


### [77] [LISTEN to Your Preferences: An LLM Framework for Multi-Objective Selection](https://arxiv.org/abs/2510.25799)
*Adam S. Jovine,Tinghan Ye,Francis Bahk,Jingjing Wang,David B. Shmoys,Peter I. Frazier*

Main category: cs.CL

TL;DR: 提出LISTEN框架，用LLM作为专家偏好判别器，通过自然语言高层次指引，实现多目标下复杂选择任务的自动化。


<details>
  <summary>Details</summary>
Motivation: 在多目标、多选项情境中，专家难以将复杂隐性偏好形式化，传统偏好获取过程认知负担重且低效。

Method: 提出LISTEN，包括两种算法：LISTEN-U利用LLM迭代优化参数型效用函数；LISTEN-T采用非参数方法，模拟锦标赛式分批筛选。以自然语言描述偏好，减少对专家的硬性量化要求。

Result: 在机票预订、购物、考试安排等任务上评估，LISTEN-U在参数化偏好一致性高时效果突出，LISTEN-T则表现更为稳健。提出了衡量参数化一致性的创新一致性指标。

Conclusion: LISTEN框架显示通过自然语言引导LLM进行多目标决策具有效率与用户友好性，为复杂决策场景提供了认知负担更低的新解法。

Abstract: Human experts often struggle to select the best option from a large set of
items with multiple competing objectives, a process bottlenecked by the
difficulty of formalizing complex, implicit preferences. To address this, we
introduce LISTEN, a framework that leverages a Large Language Model (LLM) as a
zero-shot preference oracle, guided only by an expert's high-level priorities
in natural language. To operate within LLM constraints like context windows and
inference costs, we propose two iterative algorithms: LISTEN-U, which uses the
LLM to refine a parametric utility function, and LISTEN-T, a non-parametric
method that performs tournament-style selections over small batches of
solutions. Evaluated on diverse tasks including flight booking, shopping, and
exam scheduling, our results show LISTEN-U excels when preferences are
parametrically aligned (a property we measure with a novel concordance metric),
while LISTEN-T offers more robust performance. This work explores a promising
direction for steering complex multi-objective decisions directly with natural
language, reducing the cognitive burden of traditional preference elicitation.

</details>


### [78] [Beyond Length: Quantifying Long-Range Information for Long-Context LLM Pretraining Data](https://arxiv.org/abs/2510.25804)
*Haoran Deng,Yingyu Lin,Zhenghao Lin,Xiao Liu,Yizhou Sun,Yi-An Ma,Yeyun Gong*

Main category: cs.CL

TL;DR: 本文提出了LongFilter方法，通过衡量长上下文对提升模型预测的贡献，从而高效筛选对长文本建模真正有价值的训练数据，并实验证明该方法能显著提升长上下文语言模型的表现。


<details>
  <summary>Details</summary>
Motivation: 现有大部分可用的长文本训练数据在实际中缺乏有意义的长距离依赖，仅需局部上下文即可预测，对长上下文语言模型训练效率不高，因此需要精细的数据筛选，提升有效性。

Method: 提出LongFilter框架，通过比较短上下文和长上下文下模型对样本的预测差异，量化长距离上下文的信息增益，筛选出真正需要长距离依赖的信息样本用于预训练。

Result: 实验将LLaMA-3-8B的上下文长度从8K提升到64K，使用LongFilter筛选数据后，在HELMET、LongBench和RULER等多个基准测试上实现了更高质量的数据选择与大幅性能提升。

Conclusion: LongFilter能够高效地甄别和筛选出那些对长上下文建模有实质性帮助的数据样本，有效提升长文本语言模型的训练效果，在多项长文本任务上表现出显著优势。

Abstract: Long-context language models unlock advanced capabilities in reasoning, code
generation, and document summarization by leveraging dependencies across
extended spans of text. However, a significant portion of readily available
long-text data lacks meaningful long-distance dependencies; most spans can be
predicted using only local context. Training on such data is inefficient,
making careful data selection crucial. Therefore, we introduce LongFilter, a
framework for curating training data tailored to long-context pretraining.
LongFilter measures the information gain provided by extended context by
contrasting model predictions under long-context versus short-context settings,
thereby identifying samples where long-range dependencies are essential.
Experiments with LLaMA-3-8B, extending its context length from 8K to 64K, show
that LongFilter efficiently selects high-quality data and yields substantial
improvements on benchmarks such as HELMET, LongBench, and RULER.

</details>


### [79] [Ideology-Based LLMs for Content Moderation](https://arxiv.org/abs/2510.25805)
*Stefano Civelli,Pietro Bernardelle,Nardiena A. Pratama,Gianluca Demartini*

Main category: cs.CL

TL;DR: 该论文探究了大语言模型（LLM）在内容审核任务中采用不同角色（persona）对有害内容分类结果的影响，特别关注其一致性与公平性。结果表明，角色设定虽对总体准确率影响不大，但会引入不同意识形态的偏见。


<details>
  <summary>Details</summary>
Motivation: 随着LLM广泛应用于内容审核领域，如何保证其决策的中立和公平成为重要问题。本研究旨在揭示模型在设置不同角色时（一种带有背景立场的设定），其分类有害内容的表现是否受角色意识形态影响，避免AI工具潜在地加剧党派分歧。

Method: 研究通过让不同规模、架构、处理不同模态（文本/视觉）的LLM采用不同意识形态角色设定，观察其对有害内容的分类表现，并进一步分析模型输出的一致性和意识形态偏向。此外，进行了针对特定政治任务的实验来验证角色对有害性判断的影响。

Result: 在总体准确率上，角色设定影响较小。但细致分析显示，不同意识形态角色对有害内容的判定存在明显差异，模型会更倾向于与本身态度一致的观点，尤其是大型模型。此外，角色在面对本阵营与对立阵营观点时会展现“护短”倾向，对己方观点的危险性判断趋于保守。

Conclusion: 角色设定能够在不易察觉的情况下引入模型输出的意识形态偏见。这提醒我们，当前AI系统声称中立时，实际可能暗中强化党派立场，给内容审核带来公平性与公正性挑战。

Abstract: Large language models (LLMs) are increasingly used in content moderation
systems, where ensuring fairness and neutrality is essential. In this study, we
examine how persona adoption influences the consistency and fairness of harmful
content classification across different LLM architectures, model sizes, and
content modalities (language vs. vision). At first glance, headline performance
metrics suggest that personas have little impact on overall classification
accuracy. However, a closer analysis reveals important behavioral shifts.
Personas with different ideological leanings display distinct propensities to
label content as harmful, showing that the lens through which a model "views"
input can subtly shape its judgments. Further agreement analyses highlight that
models, particularly larger ones, tend to align more closely with personas from
the same political ideology, strengthening within-ideology consistency while
widening divergence across ideological groups. To show this effect more
directly, we conducted an additional study on a politically targeted task,
which confirmed that personas not only behave more coherently within their own
ideology but also exhibit a tendency to defend their perspective while
downplaying harmfulness in opposing views. Together, these findings highlight
how persona conditioning can introduce subtle ideological biases into LLM
outputs, raising concerns about the use of AI systems that may reinforce
partisan perspectives under the guise of neutrality.

</details>


### [80] [Beyond Long Context: When Semantics Matter More than Tokens](https://arxiv.org/abs/2510.25816)
*Tarun Kumar Chawdhury,Jon D. Duke*

Main category: cs.CL

TL;DR: 该论文提出了一种名为CLEAR（Clinical Entity Augmented Retrieval）的实体增强检索方法，用于提升对EHR（电子健康记录）中临床文档的语义问答效果。


<details>
  <summary>Details</summary>
Motivation: 当前EHR系统使用base64编码存储文档，难以进行高效且精准的语义检索与问答。传统向量数据库方法对细粒度的临床关系捕捉不足，存在语义丢失问题，需求能兼顾效率和准确性的检索方式。

Method: 作者设计了CLEAR方法，通过实体感知检索对临床问答进行增强，并构建了一个评测平台，将CLEAR与零样本大上下文推理和传统切块检索增强生成方法进行对比。测试样本覆盖了10,000到65,000字节的真实临床笔记。

Result: CLEAR方法在F1分数上优于嵌入式检索（0.90 vs 0.86），且节省了70%以上的tokens。在12份临床笔记测试中，CLEAR胜率为58.3%，平均语义相似度为0.878，对比宽上下文处理减少了78%的token消耗。对超长文档（>65,000 token）胜率高达75%。

Conclusion: 实体感知检索（CLEAR）在临床文本语义问答中提升了准确性与效率，尤其在处理大体量临床文档时效果突出。提出的评测平台也为此类系统提供了可复用、透明的评测基准。

Abstract: Electronic Health Records (EHR) store clinical documentation as base64
encoded attachments in FHIR DocumentReference resources, which makes semantic
question answering difficult. Traditional vector database methods often miss
nuanced clinical relationships. The Clinical Entity Augmented Retrieval (CLEAR)
method, introduced by Lopez et al. 2025, uses entity aware retrieval and
achieved improved performance with an F1 score of 0.90 versus 0.86 for
embedding based retrieval, while using over 70 percent fewer tokens. We
developed a Clinical Notes QA Evaluation Platform to validate CLEAR against
zero shot large context inference and traditional chunk based retrieval
augmented generation. The platform was tested on 12 clinical notes ranging from
10,000 to 65,000 tokens representing realistic EHR content. CLEAR achieved a
58.3 percent win rate, an average semantic similarity of 0.878, and used 78
percent fewer tokens than wide context processing. The largest performance
gains occurred on long notes, with a 75 percent win rate for documents
exceeding 65,000 tokens. These findings confirm that entity aware retrieval
improves both efficiency and accuracy in clinical natural language processing.
The evaluation framework provides a reusable and transparent benchmark for
assessing clinical question answering systems where semantic precision and
computational efficiency are critical.

</details>


### [81] [A Survey on Efficient Large Language Model Training: From Data-centric Perspectives](https://arxiv.org/abs/2510.25817)
*Junyu Luo,Bohan Wu,Xiao Luo,Zhiping Xiao,Yiqiao Jin,Rong-Cheng Tu,Nan Yin,Yifan Wang,Jingyang Yuan,Wei Ju,Ming Zhang*

Main category: cs.CL

TL;DR: 本文综述了大模型（LLM）高效调优中的数据高效性问题，系统总结了现有方法并提出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: LLM调优需要大量高质量标注数据，导致成本高且数据规模扩展效果递减，亟需数据高效的后训练方式。

Method: 提出了数据高效LLM后训练方法的分类体系：数据筛选、数据质量提升、合成数据生成、数据蒸馏与压缩、自进化数据生态系统，并分别总结代表性方法。

Result: 系统梳理并分类了当前各类数据高效LLM后训练方法，对其代表性实践进行了总结评价。

Conclusion: 该综述有助于研究者理解数据高效LLM后训练的现状与挑战，为未来大模型训练中的数据高效利用提供参考，推动相关研究发展。

Abstract: Post-training of Large Language Models (LLMs) is crucial for unlocking their
task generalization potential and domain-specific capabilities. However, the
current LLM post-training paradigm faces significant data challenges, including
the high costs of manual annotation and diminishing marginal returns on data
scales. Therefore, achieving data-efficient post-training has become a key
research question. In this paper, we present the first systematic survey of
data-efficient LLM post-training from a data-centric perspective. We propose a
taxonomy of data-efficient LLM post-training methods, covering data selection,
data quality enhancement, synthetic data generation, data distillation and
compression, and self-evolving data ecosystems. We summarize representative
approaches in each category and outline future research directions. By
examining the challenges in data-efficient LLM post-training, we highlight open
problems and propose potential research avenues. We hope our work inspires
further exploration into maximizing the potential of data utilization in
large-scale model training. Paper List:
https://github.com/luo-junyu/Awesome-Data-Efficient-LLM

</details>


### [82] [Evaluating the Impact of LLM-Assisted Annotation in a Perspectivized Setting: the Case of FrameNet Annotation](https://arxiv.org/abs/2510.25904)
*Frederico Belcavello,Ely Matos,Arthur Lorenzi,Lisandra Bonoto,Lívia Ruiz,Luiz Fernando Pereira,Victor Herbst,Yulla Navarro,Helen de Andrade Abreu,Lívia Dutra,Tiago Timponi Torrent*

Main category: cs.CL

TL;DR: 本文评估了基于大语言模型（LLM）的应用在FrameNet式语义标注任务中的表现，比较了人工、自动和半自动三种标注方式的效率和质量。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM加速或替代人工构建语言资源和数据集已变为现实，其在带有视角化的NLP任务中表现和影响的全面评估仍然缺失，尤其在语义标注方面。作者希望通过细致评估填补这一研究空白。

Method: 作者使用基于大语言模型的语义角色标注工具，对FrameNet式语义标注进行了广泛实验。对比了全人工、全自动和半自动三种方案在标注时间、覆盖率、多样性等指标上的表现。

Result: 结果显示，半自动标注在语义框架多样性和覆盖率方面与纯人工相当，明显优于纯自动的方法；自动方法只在标注时间上有优势，但在其他指标上表现较差。

Conclusion: 半自动（人机协作）方式在保证数据质量和多样性的同时，兼具一定自动化效率，是当前更优的标注模式。全自动方法尚不适合高质量的语义标注。

Abstract: The use of LLM-based applications as a means to accelerate and/or substitute
human labor in the creation of language resources and dataset is a reality.
Nonetheless, despite the potential of such tools for linguistic research,
comprehensive evaluation of their performance and impact on the creation of
annotated datasets, especially under a perspectivized approach to NLP, is still
missing. This paper contributes to reduction of this gap by reporting on an
extensive evaluation of the (semi-)automatization of FrameNet-like semantic
annotation by the use of an LLM-based semantic role labeler. The methodology
employed compares annotation time, coverage and diversity in three experimental
settings: manual, automatic and semi-automatic annotation. Results show that
the hybrid, semi-automatic annotation setting leads to increased frame
diversity and similar annotation coverage, when compared to the human-only
setting, while the automatic setting performs considerably worse in all
metrics, except for annotation time.

</details>


### [83] [RECAP: Reproducing Copyrighted Data from LLMs Training with an Agentic Pipeline](https://arxiv.org/abs/2510.25941)
*André V. Duarte,Xuying li,Bin Zeng,Arlindo L. Oliveira,Lei Li,Zhuo Li*

Main category: cs.CL

TL;DR: 提出了一种名为RECAP的流程，能自动发现并验证大模型记忆中的训练数据，并在新数据集EchoTrace上大幅提升训练数据复现能力。


<details>
  <summary>Details</summary>
Motivation: 无法直接检查大模型训练数据，难以确定模型到底看过哪些内容，需要找到有效方法证明模型是否真正见过、记住了某些数据。

Method: 提出了RECAP流程：通过模型自身生成内容，再用另一个模型与参考答案对比，识别差异后提出修正建议，反馈给目标模型迭代优化。同时加入了突破因对齐限制导致拒绝输出的数据的‘越狱’模块。整个流程形成自动化反馈驱动循环。

Result: 在新的数据集EchoTrace（包含30多本完整书籍）上验证，RECAP相比单次生成方法，能显著提升提取训练内容的正确率。在GPT-4.1上ROUGE-L分数由0.38提升到0.47，提升了24%。

Conclusion: RECAP能更有效地复现并验证大模型的训练数据记忆，极大提高训练数据回溯的自动化和准确性。

Abstract: If we cannot inspect the training data of a large language model (LLM), how
can we ever know what it has seen? We believe the most compelling evidence
arises when the model itself freely reproduces the target content. As such, we
propose RECAP, an agentic pipeline designed to elicit and verify memorized
training data from LLM outputs. At the heart of RECAP is a feedback-driven
loop, where an initial extraction attempt is evaluated by a secondary language
model, which compares the output against a reference passage and identifies
discrepancies. These are then translated into minimal correction hints, which
are fed back into the target model to guide subsequent generations. In
addition, to address alignment-induced refusals, RECAP includes a jailbreaking
module that detects and overcomes such barriers. We evaluate RECAP on
EchoTrace, a new benchmark spanning over 30 full books, and the results show
that RECAP leads to substantial gains over single-iteration approaches. For
instance, with GPT-4.1, the average ROUGE-L score for the copyrighted text
extraction improved from 0.38 to 0.47 - a nearly 24% increase.

</details>


### [84] [Revisiting Multilingual Data Mixtures in Language Model Pretraining](https://arxiv.org/abs/2510.25947)
*Negar Foroutan,Paul Teiletche,Ayush Kumar Tarun,Antoine Bosselut*

Main category: cs.CL

TL;DR: 本文探讨了在大型语言模型多语言预训练中常见的一些假设，发现通过合理的数据平衡，可以提升语言能力，而不会出现传统所担忧的性能损失。


<details>
  <summary>Details</summary>
Motivation: 多语言预训练数据如何混合、语言数量与表现之间的关系一直存在争议，学界常担心覆盖多语言会损害模型性能，尤其在支持多种语言时可能遭受“多语言诅咒”。

Method: 作者训练了两个规模（1.1B和3B参数）的模型，在25到400种语言的多样语料上进行预训练，对不同混合策略、数据分布（尤其是英语与多语数据的组合、以及选择枢纽语言的差异）进行分析和对比。

Result: 第一，英语与多语数据联合不会必然损害各自表现，只要每种语言数据量足够；第二，英语作为枢纽语言比家族内部其他高资源语言更能促进多语言泛化；第三，在当前模型规模下，增加语言数量并未明显导致“多语言诅咒”。

Conclusion: 只要训练语料中各语言数据量均衡，扩展多语言覆盖可以提升模型能力，且不会牺牲低资源语言表现，这对多语言大模型的预训练有积极意义。

Abstract: The impact of different multilingual data mixtures in pretraining large
language models (LLMs) has been a topic of ongoing debate, often raising
concerns about potential trade-offs between language coverage and model
performance (i.e., the curse of multilinguality). In this work, we investigate
these assumptions by training 1.1B and 3B parameter LLMs on diverse
multilingual corpora, varying the number of languages from 25 to 400. Our study
challenges common beliefs surrounding multilingual training. First, we find
that combining English and multilingual data does not necessarily degrade the
in-language performance of either group, provided that languages have a
sufficient number of tokens included in the pretraining corpus. Second, we
observe that using English as a pivot language (i.e., a high-resource language
that serves as a catalyst for multilingual generalization) yields benefits
across language families, and contrary to expectations, selecting a pivot
language from within a specific family does not consistently improve
performance for languages within that family. Lastly, we do not observe a
significant "curse of multilinguality" as the number of training languages
increases in models at this scale. Our findings suggest that multilingual data,
when balanced appropriately, can enhance language model capabilities without
compromising performance, even in low-resource settings

</details>


### [85] [Semantic Label Drift in Cross-Cultural Translation](https://arxiv.org/abs/2510.25967)
*Mohsinul Kabir,Tasnim Ahmed,Md Mezbaur Rahman,Polydoros Giannouris,Sophia Ananiadou*

Main category: cs.CL

TL;DR: 该论文探讨了在低资源语言的机器翻译中，由于文化差异导致语义标签发生漂移的问题，并通过实验证明文化因素是标签保持的关键影响因素。


<details>
  <summary>Details</summary>
Motivation: 过去机器翻译研究多关注情感保持，但对源语言与目标语言之间的文化对齐关注不足。作者假设，文化差异会影响标签在翻译过程中的准确性与一致性，特别在需合成低资源语言数据时，存在实际风险。

Method: 作者在文化敏感和中性领域，通过机器翻译（包括大模型与传统系统）进行实验，考察翻译后标签漂移（label drift）现象并分析其与文化相似性的关系。

Result: 实验发现：(1) 所有MT系统，特别是在文化敏感领域都会引入标签漂移；(2) 大语言模型虽蕴含文化知识，但反而会加剧标签漂移；(3) 源-目标语言间的文化相似性对标签保持有重大影响。

Conclusion: 忽略文化差异会导致机器翻译在下游任务中的标签失真甚至引发文化误解，呼吁MT研究应充分重视文化对齐问题。

Abstract: Machine Translation (MT) is widely employed to address resource scarcity in
low-resource languages by generating synthetic data from high-resource
counterparts. While sentiment preservation in translation has long been
studied, a critical but underexplored factor is the role of cultural alignment
between source and target languages. In this paper, we hypothesize that
semantic labels are drifted or altered during MT due to cultural divergence.
Through a series of experiments across culturally sensitive and neutral
domains, we establish three key findings: (1) MT systems, including modern
Large Language Models (LLMs), induce label drift during translation,
particularly in culturally sensitive domains; (2) unlike earlier statistical MT
tools, LLMs encode cultural knowledge, and leveraging this knowledge can
amplify label drift; and (3) cultural similarity or dissimilarity between
source and target languages is a crucial determinant of label preservation. Our
findings highlight that neglecting cultural factors in MT not only undermines
label fidelity but also risks misinterpretation and cultural conflict in
downstream applications.

</details>


### [86] [SymCode: A Neurosymbolic Approach to Mathematical Reasoning via Verifiable Code Generation](https://arxiv.org/abs/2510.25975)
*Sina Bagheri Nezhad,Yao Li,Ameeta Agrawal*

Main category: cs.CL

TL;DR: 本文提出了SymCode框架，将数学问题求解转化为可验证的代码生成，大幅提升了解题准确率和推理透明度。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）在数学推理上表现不佳，主要因为传统文本生成方法缺乏确定性验证机制，导致不可追溯和不可靠的问题解答。

Method: 作者提出了一种神经符号框架SymCode，将数学推理任务转换为基于SymPy库的可验证代码生成，通过代码执行实现解答的可验证性。

Result: 在MATH-500和OlympiadBench等高难度数学基准测试上，SymCode相较于传统方法准确率提升高达13.6个百分点，且表现出更高的token效率。

Conclusion: SymCode能够显著提升大语言模型在形式化领域的准确性和可信度，把不透明的推理错误转化为清晰的程序错误，是实现准确可信AI的重要一步。

Abstract: Large Language Models (LLMs) often struggle with complex mathematical
reasoning, where prose-based generation leads to unverified and arithmetically
unsound solutions. Current prompting strategies like Chain of Thought still
operate within this unreliable medium, lacking a mechanism for deterministic
verification. To address these limitations, we introduce SymCode, a
neurosymbolic framework that reframes mathematical problem-solving as a task of
verifiable code generation using the SymPy library. We evaluate SymCode on
challenging benchmarks, including MATH-500 and OlympiadBench, demonstrating
significant accuracy improvements of up to 13.6 percentage points over
baselines. Our analysis shows that SymCode is not only more token-efficient but
also fundamentally shifts model failures from opaque logical fallacies towards
transparent, programmatic errors. By grounding LLM reasoning in a deterministic
symbolic engine, SymCode represents a key step towards more accurate and
trustworthy AI in formal domains.

</details>


### [87] [NeuronMM: High-Performance Matrix Multiplication for LLM Inference on AWS Trainium](https://arxiv.org/abs/2510.25977)
*Dinghong Song,Jierui Xu,Weichu Yang,Pengfei Su,Dong Li*

Main category: cs.CL

TL;DR: 本文针对AWS推出的AI加速器Trainium，提出了优化大语言模型（LLM）推理中关键算子矩阵乘法（matmul）的方法。通过核融合和新型缓存技术，有效减少数据移动，提升整体性能。最终实现比AWS官方实现显著更高的推理速度。


<details>
  <summary>Details</summary>
Motivation: 虽然Trainium具备高性价比，但其独特的体系结构（如脉动阵列、特殊数据布局需求）使得高效利用变得困难，因此需要专门针对Trainium优化核心计算内核以推动LLM推理效率。

Method: 作者提出基于核融合与创新缓存策略的方法来优化矩阵乘法算子，最大化SRAM带宽利用，减少在软件可管理内存层级中的数据移动，并避免昂贵的矩阵转置操作。

Result: 通过九个数据集和四个最新LLM模型的测试，新方法在matmul算子层面平均加速1.35倍，最高2.22倍；在端到端LLM推理层面平均加速1.66倍，最高2.49倍，全面优于AWS官方实现。

Conclusion: 面向Trainium的定制优化方法能够大幅提升LLM推理关键核心的性能，展示了理解硬件特点并结合创新技术对AI加速器开发的重要意义。

Abstract: AI accelerators, customized to AI workloads, provide cost-effective and
high-performance solutions for training and inference. Trainium, an AI
accelerator recently developed by Amazon Web Services (AWS), provides an
attractive option for LLM training and inference through its heterogeneous
architecture. However, leveraging Trainium architecture for high performance
can be challenging because of its systolic array architecture and special
requirement on data layout. In this paper, we design high-performance matrix
multiplication (matmul), a critical compute kernel, for LLM inference on
Trainium. We introduce a series of techniques customized to Trainium based on
kernel fusion and novel caching strategies to reduce data movement across the
software-managed memory hierarchy, maximize SRAM bandwidth, and avoid expensive
matrix transpose. Evaluating with nine datasets and four recent LLMs, we show
that our system largely outperforms the state-of-the-art matmul implemented by
AWS on Trainium: at the level of matmul kernel, it achieves an average 1.35x
speedup (up to 2.22x), which translates to an average 1.66x speedup (up to
2.49x) for end-to-end LLM inference.

</details>


### [88] [AttnCache: Accelerating Self-Attention Inference for LLM Prefill via Attention Cache](https://arxiv.org/abs/2510.25979)
*Dinghong Song,Yuan Feng,Yiwei Wang,Shangye Chen,Cyril Guyot,Filip Blagojevic,Hyeran Jeon,Pengfei Su,Dong Li*

Main category: cs.CL

TL;DR: 提出了一种加速大模型推理预填阶段的新方法，通过缓存和复用相似注意力图，显著提升预填场景下的推理效率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在实际应用的预填阶段（如分类、问答等）主要开销在于自注意力机制，其计算复杂度随序列长度增加而急剧增大，成为性能瓶颈，因此需要有效加速方法。

Method: 作者观察到不同语义的句子往往具有相似的注意力图。基于此，提出AttnCache框架，在预填推理时通过建立注意力图缓存数据库，利用高效的相似性搜索与缓存技术，检索并复用预先计算的注意力图，从而减少重复计算。

Result: 在CPU上AttnCache整体推理加速平均达1.2倍，自注意力部分加速2倍；在GPU上整体1.6倍，自注意力3倍。同时几乎不降低模型输出的准确性。

Conclusion: AttnCache能显著减小大模型预填推理的时间开销，同时基本保持准确性，为实际应用中大模型高效部署提供有效方案。

Abstract: Large Language Models (LLMs) are widely used in generative applications such
as chatting, code generation, and reasoning. However, many realworld workloads
such as classification, question answering, recommendation, and text embedding
rely solely on the prefill stage of inference, where the model encodes input
sequences without performing autoregressive decoding. In these prefill only
scenarios, the self-attention computation becomes the primary performance
bottleneck due to its quadratic complexity with respect to sequence length. In
this paper, we observe that semantically different sentences often produce
similar attention maps across layers and heads. Building on this insight, we
propose AttnCache, a framework that accelerates the prefill stage of LLM
inference by retrieving and reusing similar attention maps. Based on an
attention map memorization database, AttnCache employs efficient caching and
similarity search techniques to identify and reuse pre-cached attention maps
during inference, thereby reducing the computational overhead of
self-attention. Experimental results show that AttnCache achieves an average of
1.2x end-to-end and 2x attention speedup on CPU, and 1.6x end-to-end and 3x
attention speedup on GPU, with negligible accuracy degradation.

</details>


### [89] [Supervised Reinforcement Learning: From Expert Trajectories to Step-wise Reasoning](https://arxiv.org/abs/2510.25992)
*Yihe Deng,I-Hung Hsu,Jun Yan,Zifeng Wang,Rujun Han,Gufeng Zhang,Yanfei Chen,Wei Wang,Tomas Pfister,Chen-Yu Lee*

Main category: cs.CL

TL;DR: 本文提出了一种新的训练框架——监督强化学习（SRL），能够提升小型开源大语言模型在多步推理任务中的表现，抑制传统方法的弊端。


<details>
  <summary>Details</summary>
Motivation: 小型LLM在多步推理任务中表现不佳，现有两个主流训练法（RLVR和SFT）分别存在鲁棒性和过拟合的问题，难以解决复杂问题。

Method: SRL将问题求解转化为生成逻辑动作序列，训练模型在执行每一步动作前生成推理独白，并以模型动作与专家动作的相似度给予平滑奖励，实现逐步监督，从而利用专家演示灵活指导推理。

Result: SRL让小模型能够学习此前SFT和RLVR无法解决的复杂问题；SRL预训练加RLVR微调取得了最佳效果；SRL还能推广到智能软件工程等更广泛领域。

Conclusion: SRL是一种强大且通用的以推理为导向的LLM训练框架，兼具灵活性与有效性，对提升小型模型能力尤其有效。

Abstract: Large Language Models (LLMs) often struggle with problems that require
multi-step reasoning. For small-scale open-source models, Reinforcement
Learning with Verifiable Rewards (RLVR) fails when correct solutions are rarely
sampled even after many attempts, while Supervised Fine-Tuning (SFT) tends to
overfit long demonstrations through rigid token-by-token imitation. To address
this gap, we propose Supervised Reinforcement Learning (SRL), a framework that
reformulates problem solving as generating a sequence of logical "actions". SRL
trains the model to generate an internal reasoning monologue before committing
to each action. It provides smoother rewards based on the similarity between
the model's actions and expert actions extracted from the SFT dataset in a
step-wise manner. This supervision offers richer learning signals even when all
rollouts are incorrect, while encouraging flexible reasoning guided by expert
demonstrations. As a result, SRL enables small models to learn challenging
problems previously unlearnable by SFT or RLVR. Moreover, initializing training
with SRL before refining with RLVR yields the strongest overall performance.
Beyond reasoning benchmarks, SRL generalizes effectively to agentic software
engineering tasks, establishing it as a robust and versatile training framework
for reasoning-oriented LLMs.

</details>


### [90] [PORTool: Tool-Use LLM Training with Rewarded Tree](https://arxiv.org/abs/2510.26020)
*Feijie Wu,Weiwu Zhu,Yuxiang Zhang,Soumya Chatterjee,Jiarong Zhu,Fan Mo,Rodin Luo,Jing Gao*

Main category: cs.CL

TL;DR: 本文提出了一种名为PORTool的强化学习方法来训练大型语言模型（LLM）更有效且灵活地使用外部工具，提升其多步推理和动态工具调用环境下的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的用工具协作的大模型多基于静态数据集训练，仅能模仿常规操作，缺乏探索能力，难以适应复杂和动态环境，导致性能受限。因此需要更能鼓励探索的训练方法。

Method: PORTool方法通过为同一查询生成多条工具调用路径（轨迹），形成树状结构，并根据每一步是否有助于得到正确答案以及工具调用成功与否，分配分步奖励。这些奖励结合分支相关的优势，引导LLM进行强化学习训练。

Result: 利用17种工具对不同类型的用户查询进行实验，并进行了消融实验证明分步奖励的必要性和设计合理性。与其他训练方法对比，PORTool在最终准确率和工具调用步数方面都取得了显著提升。

Conclusion: PORTool方法有效提升了工具型LLM在动态复杂环境下的推理和解决问题能力，证明了其训练策略的优越性和实用价值。

Abstract: Current tool-use large language models (LLMs) are trained on static datasets,
enabling them to interact with external tools and perform multi-step,
tool-integrated reasoning, which produces tool-call trajectories. However,
these models imitate how a query is resolved in a generic tool-call routine,
thereby failing to explore possible solutions and demonstrating limited
performance in an evolved, dynamic tool-call environment. In this work, we
propose PORTool, a reinforcement learning (RL) method that encourages a
tool-use LLM to explore various trajectories yielding the correct answer.
Specifically, this method starts with generating multiple rollouts for a given
query, and some of them share the first few tool-call steps, thereby forming a
tree-like structure. Next, we assign rewards to each step, based on its ability
to produce a correct answer and make successful tool calls. A shared step
across different trajectories receives the same reward, while different steps
under the same fork receive different rewards. Finally, these step-wise rewards
are used to calculate fork-relative advantages, blended with
trajectory-relative advantages, to train the LLM for tool use. The experiments
utilize 17 tools to address user queries, covering both time-sensitive and
time-invariant topics. We conduct ablation studies to systematically justify
the necessity and the design robustness of step-wise rewards. Furthermore, we
compare the proposed PORTool with other training approaches and demonstrate
significant improvements in final accuracy and the number of tool-call steps.

</details>


### [91] [Rethinking Cross-lingual Alignment: Balancing Transfer and Cultural Erasure in Multilingual LLMs](https://arxiv.org/abs/2510.26024)
*HyoJung Han,Sweta Agrawal,Eleftheria Briakou*

Main category: cs.CL

TL;DR: 该论文关注于跨语言表示对齐（CLA）过程中，在提升知识迁移的同时可能导致文化表达丧失的问题，并提出了一种新的分析框架与推理方法来权衡两者。


<details>
  <summary>Details</summary>
Motivation: 跨语言对齐有助于大模型不同语言间知识迁移，但可能导致输出失去语言相关的文化特色。作者希望系统性分析知识迁移与文化本地化的平衡，并缓解“文化清洗”现象。

Method: 提出了Transfer-localization plane评估框架，能定量分析知识迁移与文化本地化的权衡；分析模型内部表征层次，发现可在不同层分别优化两种能力；设计了推理时层级目标解耦算法（Surgical Steering），分别在不同层对知识迁移与文化定制进行控制。

Result: 通过新框架重新评估了当前CLA方法，发现它们往往提升事实性迁移但牺牲文化本地化。应用Surgical Steering方法后，在六种语言上同时兼顾两方面，取得更优平衡。

Conclusion: 当前CLA方法存在文化表达受损的问题。所提新框架和方法能有效缓解知识迁移与文化本地化的冲突，为跨语言模型的发展提供了新思路。

Abstract: Cross-lingual alignment (CLA) aims to align multilingual representations,
enabling Large Language Models (LLMs) to seamlessly transfer knowledge across
languages. While intuitive, we hypothesize, this pursuit of representational
convergence can inadvertently cause "cultural erasure", the functional loss of
providing culturally-situated responses that should diverge based on the query
language. In this work, we systematically analyze this trade-off by introducing
a holistic evaluation framework, the transfer-localization plane, which
quantifies both desirable knowledge transfer and undesirable cultural erasure.
Using this framework, we re-evaluate recent CLA approaches and find that they
consistently improve factual transfer at the direct cost of cultural
localization across all six languages studied. Our investigation into the
internal representations of these models reveals a key insight: universal
factual transfer and culturally-specific knowledge are optimally steerable at
different model layers. Based on this finding, we propose Surgical Steering, a
novel inference-time method that disentangles these two objectives. By applying
targeted activation steering to distinct layers, our approach achieves a better
balance between the two competing dimensions, effectively overcoming the
limitations of current alignment techniques.

</details>


### [92] [Artificial Intelligence-Enabled Analysis of Radiology Reports: Epidemiology and Consequences of Incidental Thyroid Findings](https://arxiv.org/abs/2510.26032)
*Felipe Larios,Mariana Borras-Osorio,Yuqi Wu,Ana Gabriela Claros,David Toro-Tobon,Esteban Cabezas,Ricardo Loor-Torres,Maria Mateo Chavez,Kerly Guevara Maldonado,Luis Vilatuna Andrango,Maria Lizarazo Jimenez,Ivan Mateo Alzamora,Misk Al Zahidy,Marcelo Montero,Ana Cristina Proano,Cristian Soto Jacome,Jungwei W. Fan,Oscar J. Ponce-Ponte,Megan E. Branda,Naykky Singh Ospina,Juan P. Brito*

Main category: cs.CL

TL;DR: 本研究开发并验证了一个利用NLP技术自动识别放射报告中偶然性甲状腺发现（ITF）的系统，分析其流行率、特征和随访结局。结果表明ITF常见，并与甲状腺癌过度诊断相关。


<details>
  <summary>Details</summary>
Motivation: 随着非甲状腺目的影像学检查的普及，偶然性甲状腺发现（ITF）检出率增加，但其流行率、基本特征及临床结果尚不明确。需开发高效工具自动识别ITF，明确其实际影响。

Method: 使用基于transformer的自然语言处理（NLP）管线，自动分析2017-2023年Mayo Clinic多部位多模态影像报告，识别ITF及提取结节特征，并结合回顾性队列统计分析ITF相关的下游临床事件。

Result: 在115,683名无甲状腺基础病患者中，检测到9,077例（7.8%）ITF（绝大多数为结节）。ITF更常见于女性、老年人、BMI较高者，以及肿瘤科/内科申请的影像。与胸部CT相比，颈部CT、PET、核医学检查更易发现ITF。ITF随访不足，结节关键特征记录不全。ITF与更高的结节诊断、活检、甲状腺切除和癌症诊断率相关，大多数癌为乳头状，且ITF组癌体积更大。

Conclusion: ITF检出率高且引发随访过度，推动了甲状腺小癌过度诊断。应规范报告和优化随访策略，避免不必要的医疗干预。

Abstract: Importance Incidental thyroid findings (ITFs) are increasingly detected on
imaging performed for non-thyroid indications. Their prevalence, features, and
clinical consequences remain undefined. Objective To develop, validate, and
deploy a natural language processing (NLP) pipeline to identify ITFs in
radiology reports and assess their prevalence, features, and clinical outcomes.
Design, Setting, and Participants Retrospective cohort of adults without prior
thyroid disease undergoing thyroid-capturing imaging at Mayo Clinic sites from
July 1, 2017, to September 30, 2023. A transformer-based NLP pipeline
identified ITFs and extracted nodule characteristics from image reports from
multiple modalities and body regions. Main Outcomes and Measures Prevalence of
ITFs, downstream thyroid ultrasound, biopsy, thyroidectomy, and thyroid cancer
diagnosis. Logistic regression identified demographic and imaging-related
factors. Results Among 115,683 patients (mean age, 56.8 [SD 17.2] years; 52.9%
women), 9,077 (7.8%) had an ITF, of which 92.9% were nodules. ITFs were more
likely in women, older adults, those with higher BMI, and when imaging was
ordered by oncology or internal medicine. Compared with chest CT, ITFs were
more likely via neck CT, PET, and nuclear medicine scans. Nodule
characteristics were poorly documented, with size reported in 44% and other
features in fewer than 15% (e.g. calcifications). Compared with patients
without ITFs, those with ITFs had higher odds of thyroid nodule diagnosis,
biopsy, thyroidectomy and thyroid cancer diagnosis. Most cancers were
papillary, and larger when detected after ITFs vs no ITF. Conclusions ITFs were
common and strongly associated with cascades leading to the detection of small,
low-risk cancers. These findings underscore the role of ITFs in thyroid cancer
overdiagnosis and the need for standardized reporting and more selective
follow-up.

</details>


### [93] [QCoder Benchmark: Bridging Language Generation and Quantum Hardware through Simulator-Based Feedback](https://arxiv.org/abs/2510.26101)
*Taku Mikuriya,Tatsuya Ishigaki,Masayuki Kawarada,Shunya Minami,Tadashi Kadowaki,Yohichi Suzuki,Soshun Naito,Shunya Takata,Takumi Kato,Tamotsu Basseda,Reo Yamada,Hiroya Takamura*

Main category: cs.CL

TL;DR: 本论文提出了QCoder Benchmark框架，用于评估大语言模型在量子编程领域的代码生成能力，提供硬件仿真下的反馈，并与人类编写的代码作对比。实验显示当前模型在该任务上仍有较大提升空间，QCoder数据集和API已公开。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在常规代码生成领域表现优异，但针对如量子编程等需要与硬件交互的领域研究不足。量子编程独特的硬件需求与指标对自动生成代码提出了新挑战，因此迫切需要一个专门的基准框架来推动相关研究。

Method: 提出QCoder Benchmark，结合真实编程竞赛的人类代码、量子计算仿真器进行评价，能够反馈电路深度、执行时间、错误类型等指标。支持LLM生成代码的定量与定性评估，并接受外部模型通过API测试。

Result: 实验发现，GPT-4o等先进模型在该基准上准确率仅约18.97%，而基于推理的模型o3达到78%，显著超过人类代码的平均成功率（39.98%），展现出不同模型策略在量子编程代码生成上的差异。

Conclusion: QCoder Benchmark有效揭示现有LLM在量子编程领域的短板，为未来模型优化和评价提供了标准工具，相关数据集与API的开放有助于后续深入研究和模型改进。

Abstract: Large language models (LLMs) have increasingly been applied to automatic
programming code generation. This task can be viewed as a language generation
task that bridges natural language, human knowledge, and programming logic.
However, it remains underexplored in domains that require interaction with
hardware devices, such as quantum programming, where human coders write Python
code that is executed on a quantum computer. To address this gap, we introduce
QCoder Benchmark, an evaluation framework that assesses LLMs on quantum
programming with feedback from simulated hardware devices. Our benchmark offers
two key features. First, it supports evaluation using a quantum simulator
environment beyond conventional Python execution, allowing feedback of
domain-specific metrics such as circuit depth, execution time, and error
classification, which can be used to guide better generation. Second, it
incorporates human-written code submissions collected from real programming
contests, enabling both quantitative comparisons and qualitative analyses of
LLM outputs against human-written codes. Our experiments reveal that even
advanced models like GPT-4o achieve only around 18.97% accuracy, highlighting
the difficulty of the benchmark. In contrast, reasoning-based models such as o3
reach up to 78% accuracy, outperforming averaged success rates of human-written
codes (39.98%). We release the QCoder Benchmark dataset and public evaluation
API to support further research.

</details>


### [94] [Reasoning Path Divergence: A New Metric and Curation Strategy to Unlock LLM Diverse Thinking](https://arxiv.org/abs/2510.26122)
*Feng Ju,Zeyu Qin,Rui Min,Zhitao He,Lingpeng Kong,Yi R. Fung*

Main category: cs.CL

TL;DR: 本文提出了一种“一个问题，多解答”(1PNS)的训练范式，通过让大模型接触多种合理推理路径，提高推理多样性，突破单一解答（1P1S）导致的输出单一瓶颈。引入Reasoning Path Divergence（RPD）指标，衡量多步骤推理过程中的语义差异，并用其筛选高多样解答集进行训练，显著提升了大语言模型的输出多样性和推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的推理能力提升方法（如Test-Time Scaling, TTS）常受限于1P1S训练范式，只为每个问题提供单一标准答案，导致模型推理过程和输出缺乏多样性。这影响了模型对真实世界复杂推理多样性的学习、泛化与创新能力。解决提升推理多样性、打破“单解训练”束缚的问题，是本文关注的核心动机。

Method: 作者提出1PNS训练范式，让模型在训练中接触同一问题的多种合理推理路径。为解决如何客观度量推理路径间异同，提出Reasoning Path Divergence（RPD）指标，对多步链式推理过程的中间步骤进行对齐和语义评分。借助RPD，从多解答候选中优选出多样性最大的一组解答，用以微调Qwen3-4B-Base大模型。

Result: 通过RPD选择多样解答进行1PNS训练，模型在pass@k等指标上均优于传统1P1S方式。在AIME24等数据集上，1PNS方案在pass@16上整体提升2.80%，在部分集上同比提升4.99%，表现出更优的推理多样性和更强的推理能力。

Conclusion: 1PNS训练范式配合RPD度量体系，能极大提升大语言模型的推理多样性，并进一步加强TTS类提升推理能力的方法。该范式为解决推理链多样性瓶颈、推动大模型创新推理能力提供了有效方法。

Abstract: While Test-Time Scaling (TTS) has proven effective in improving the reasoning
ability of large language models (LLMs), low diversity in model outputs often
becomes a bottleneck; this is partly caused by the common "one problem, one
solution" (1P1S) training practice, which provides a single canonical answer
and can push models toward a narrow set of reasoning paths. To address this, we
propose a "one problem, multiple solutions" (1PNS) training paradigm that
exposes the model to a variety of valid reasoning trajectories and thus
increases inference diversity. A core challenge for 1PNS is reliably measuring
semantic differences between multi-step chains of thought, so we introduce
Reasoning Path Divergence (RPD), a step-level metric that aligns and scores
Long Chain-of-Thought solutions to capture differences in intermediate
reasoning. Using RPD, we curate maximally diverse solution sets per problem and
fine-tune Qwen3-4B-Base. Experiments show that RPD-selected training yields
more varied outputs and higher pass@k, with an average +2.80% gain in pass@16
over a strong 1P1S baseline and a +4.99% gain on AIME24, demonstrating that
1PNS further amplifies the effectiveness of TTS. Our code is available at
https://github.com/fengjujf/Reasoning-Path-Divergence .

</details>


### [95] [On the Influence of Discourse Relations in Persuasive Texts](https://arxiv.org/abs/2510.26124)
*Nawar Turk,Sevag Kaspar,Leila Kosseim*

Main category: cs.CL

TL;DR: 本文利用大语言模型（LLM）和提示工程，首次构建了包含劝说技术（PTs）和话语关系（DRs）双标签的数据集，并研究了两者之间的关联。


<details>
  <summary>Details</summary>
Motivation: 目前没有同时包含PTs和DRs标签的数据集，阻碍了对劝说技术与话语关系关系的深入理解，对识别网络宣传、虚假信息等实际问题有潜在帮助。

Method: 以标注19种PTs的SemEval 2023 Task 3数据集为基础，开发LLM分类器，按PDTB 3.0二级22类DRs为每条数据自动标注；共测试4个LLM和10种提示，形成40种DR分类器。集成不同多数投票策略，生成5个银标数据集，并进行统计分析。

Result: 统计分析显示六种话语关系（原因、目的、对比、原因+信念、让步、条件）在劝说类文本尤为关键，尤其与Loaded Language、Exaggeration/Minimisation、Repetition、Doubt等PTs联系密切。

Conclusion: 劝说技术与特定话语关系之间存在显著联系，构建的银标数据集和分析对理解有效传播、以及识别网络宣传与虚假信息等具有实际意义。

Abstract: This paper investigates the relationship between Persuasion Techniques (PTs)
and Discourse Relations (DRs) by leveraging Large Language Models (LLMs) and
prompt engineering. Since no dataset annotated with both PTs and DRs exists, we
took the SemEval 2023 Task 3 dataset labelled with 19 PTs as a starting point
and developed LLM-based classifiers to label each instance of the dataset with
one of the 22 PDTB 3.0 level-2 DRs. In total, four LLMs were evaluated using 10
different prompts, resulting in 40 unique DR classifiers. Ensemble models using
different majority-pooling strategies were used to create 5 silver datasets of
instances labelled with both persuasion techniques and level-2 PDTB senses. The
silver dataset sizes vary from 1,281 instances to 204 instances, depending on
the majority pooling technique used. Statistical analysis of these silver
datasets shows that six discourse relations (namely Cause, Purpose, Contrast,
Cause+Belief, Concession, and Condition) play a crucial role in persuasive
texts, especially in the use of Loaded Language, Exaggeration/Minimisation,
Repetition and to cast Doubt. This insight can contribute to detecting online
propaganda and misinformation, as well as to our general understanding of
effective communication.

</details>


### [96] [MossNet: Mixture of State-Space Experts is a Multi-Head Attention](https://arxiv.org/abs/2510.26182)
*Shikhar Tuli,James Seale Smith,Haris Jeelani,Chi-Heng Lin,Abhishek Patel,Vasili Ramanishka,Yen-Chang Hsu,Hongxia Jin*

Main category: cs.CL

TL;DR: MossNet提出了一种新型混合状态空间专家结构，模拟多头注意力机制，在语言模型任务上超越了现有的Transformer和SSM结构，且模型高效、可扩展，速度快、资源占用低。


<details>
  <summary>Details</summary>
Motivation: 现有状态空间/门控递归模型（SSM/GRM）通常只能模拟单一注意力头，限制了模型表达能力。缺乏能够兼顾高效性、多头注意力和强表现的高性能替代架构。

Method: 提出MossNet结构，基于Mixture-of-Experts（MoE），不仅在MLP通道混合中引入MoE，还在SSM时间混合核中引入MoE，从而实现模拟多头注意力的能力。

Result: 在语言建模和多项下游任务中，MossNet模型的表现优于相似规模和数据量的Transformer及SSM架构。大规模MossNet在数万亿token的数据上表现出卓越的可扩展性和效果。实测显示其在三星S24 Ultra手机和A100 GPU上运行更快、资源占用更少。

Conclusion: MossNet为高效、高性能递归大模型架构提供了新方向，在模型表现、效率和扩展性方面均展现出优越性。

Abstract: Large language models (LLMs) have significantly advanced generative
applications in natural language processing (NLP). Recent trends in model
architectures revolve around efficient variants of transformers or
state-space/gated-recurrent models (SSMs, GRMs). However, prevailing
SSM/GRM-based methods often emulate only a single attention head, potentially
limiting their expressiveness. In this work, we propose MossNet, a novel
mixture-of-state-space-experts architecture that emulates a linear multi-head
attention (MHA). MossNet leverages a mixture-of-experts (MoE) implementation
not only in channel-mixing multi-layered perceptron (MLP) blocks but also in
the time-mixing SSM kernels to realize multiple "attention heads." Extensive
experiments on language modeling and downstream evaluations show that MossNet
outperforms both transformer- and SSM-based architectures of similar model size
and data budgets. Larger variants of MossNet, trained on trillions of tokens,
further confirm its scalability and superior performance. In addition,
real-device profiling on a Samsung Galaxy S24 Ultra and an Nvidia A100 GPU
demonstrate favorable runtime speed and resource usage compared to similarly
sized baselines. Our results suggest that MossNet is a compelling new direction
for efficient, high-performing recurrent LLM architectures.

</details>


### [97] [Similarity-Distance-Magnitude Language Models](https://arxiv.org/abs/2510.26183)
*Allen Schmaltz*

Main category: cs.CL

TL;DR: 本文提出了SDM（Similarity-Distance-Magnitude）语言模型，通过引入最终层SDM激活层进行二分类微调，提高模型的『高置信度』预测能力，并能减少模型无法做出判断的情况。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型在指令遵循等任务中常出现拒答（abstention）或置信度不高的输出，影响实际应用。作者试图改善模型的预测置信度，使其输出更可靠、更有效率。

Method: 作者将现有的解码器型Transformer语言模型，通过在训练时加入最终层的SDM激活层，用于对生成的内容是否跟随指令做二分类。训练过程中采用对比式输入编码，并在训练时在线生成hard negative（困难负样本）进行监督微调。

Result: 经过上述微调后的SDM LMs，在有效区域内生成的比例提升，模型拒答的情况减少，且在与强监督基线模型对比时取得了更高的统计效率。

Conclusion: 引入SDM激活层能显著提高语言模型对指令遵循任务的置信度与回答效率，且方法适用于现有的预训练解码器模型，具有良好的应用前景。

Abstract: We introduce Similarity-Distance-Magnitude (SDM) language models (LMs), which
are sequence prediction models fine-tuned to maximize the proportion of
generations in the well-calibrated, high-probability region partitioned by a
final-layer SDM activation layer used for binary classification of
instruction-following. We demonstrate that existing pre-trained decoder-only
Transformer LMs can be readily converted into SDM LMs via supervised
fine-tuning, using the final-layer SDM activation layer during training to
estimate a change-of-base for a supervised next-token loss over a contrastive
input encoding scheme, with additional hard negative examples generated online
during training. This results in reduced abstentions (i.e., improved
statistical efficiency) compared to strong supervised baselines.

</details>


### [98] [RCScore: Quantifying Response Consistency in Large Language Models](https://arxiv.org/abs/2510.26193)
*Dongjun Jang,Youngchae Ahn,Hyopil Shin*

Main category: cs.CL

TL;DR: 该论文提出了一种名为RCScore的新评估框架，可以评估大语言模型（LLM）在不同指令表达方式下的表现和稳定性，揭示了指令风格对模型准确性的影响。


<details>
  <summary>Details</summary>
Motivation: 目前LLM的评估通常只采用单一指令模板，忽略了模型对指令风格的敏感性，而实际应用中指令多样性非常常见。因此，有必要开发能全面反映模型对不同指令表达适应能力的评测方法。

Method: 论文通过将标准评测题目系统性转换为多种不同风格的指令，考察十个主流LLM在四项推理基准上的表现变化，提出了RCScore多维度评估体系。引入Cross-Response Similarity（CRS）方法，利用RCScore指标量化模型在不同风格下输出的一致性。

Result: 实验结果显示，不同指令风格下模型准确率可有最高16.7个百分点的波动。CRS（一致性指标）与任务准确率高度相关，且更大规模的模型跨风格一致性更好。确定性解码生成的输出在风格上的一致性更高。

Conclusion: RCScore提供了一种系统性评估LLM对指令鲁棒性的有效方法，结果表明模型在不同指令风格下表现有显著差异，提高一致性可作为提升模型可靠性的重要指标。

Abstract: Current LLM evaluations often rely on a single instruction template,
overlooking models' sensitivity to instruction style-a critical aspect for
real-world deployments. We present RCScore, a multi-dimensional framework
quantifying how instruction formulation affects model responses. By
systematically transforming benchmark problems into multiple instruction
styles, RCScore reveals performance variations undetected by conventional
metrics. Our experiments across ten LLMs on four reasoning benchmarks
demonstrate that instruction style can shift accuracy by up to 16.7% points. We
introduce Cross-Response Similarity (CRS), a method applying RCScore metrics to
measure stylistic self-consistency, and establish its strong correlation with
task accuracy, suggesting consistency as a valuable proxy for model
reliability. Additional findings show that deterministic decoding produces more
stylistically stable outputs, and model scale correlates positively with
cross-style consistency. RCScore offers a principled approach to assess
instruction robustness.

</details>


### [99] [Don't Let It Fade: Preserving Edits in Diffusion Language Models via Token Timestep Allocation](https://arxiv.org/abs/2510.26200)
*Woojin Kim,Jaeyoung Do*

Main category: cs.CL

TL;DR: 本文提出Token Timestep Allocation（TTA）方法，通过对不同token分配不同的更新步数，实现对扩散语言模型（DLMs）生成过程的更精细控制，并显著提升可控性和流畅度。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散语言模型（DLMs）具备细粒度的文本生成编辑能力，但在实际控制上存在update forgetting（更新遗忘）问题，导致生成文本的连贯性和可控性变差。作者希望解决这类模型在细节调整过程中的语义遗忘和流畅性损失。

Method: 作者提出TTA方法，为每个token分配特定的timestep更新策略：关键token早早冻结，而不确定token继续被细致编辑。该策略可为固定策略或根据任务的自适应策略，推断时即可应用，无需修改模型参数。

Result: 在情感控制任务上，TTA带来20%以上的准确率提升与近50%的困惑度降低，所需步数大幅减少。在文本净化任务上，也显著减少了最大有害分数和困惑度。

Conclusion: 分步分配token更新的soft排序机制是解决DLM中update forgetting关键，可极大提高文本生成的稳定性、流畅性及可控性。

Abstract: While diffusion language models (DLMs) enable fine-grained refinement, their
practical controllability remains fragile. We identify and formally
characterize a central failure mode called update forgetting, in which uniform
and context agnostic updates induce token level fluctuations across timesteps,
erasing earlier semantic edits and disrupting the cumulative refinement
process, thereby degrading fluency and coherence. As this failure originates in
uniform and context agnostic updates, effective control demands explicit token
ordering. We propose Token Timestep Allocation (TTA), which realizes soft and
semantic token ordering via per token timestep schedules: critical tokens are
frozen early, while uncertain tokens receive continued refinement. This
timestep based ordering can be instantiated as either a fixed policy or an
adaptive policy driven by task signals, thereby supporting a broad spectrum of
refinement strategies. Because it operates purely at inference time, it applies
uniformly across various DLMs and naturally extends to diverse supervision
sources. Empirically, TTA improves controllability and fluency: on sentiment
control, it yields more than 20 percent higher accuracy and nearly halves
perplexity using less than one fifth the steps; in detoxification, it lowers
maximum toxicity (12.2 versus 14.5) and perplexity (26.0 versus 32.0).
Together, these results demonstrate that softened ordering via timestep
allocation is the critical lever for mitigating update forgetting and achieving
stable and controllable diffusion text generation.

</details>


### [100] [What's In My Human Feedback? Learning Interpretable Descriptions of Preference Data](https://arxiv.org/abs/2510.26202)
*Rajiv Movva,Smitha Milli,Sewon Min,Emma Pierson*

Main category: cs.CL

TL;DR: 本文提出了一种名为WIMHF的新方法，用于解释和分析人类反馈数据特征，并据此提升语言模型的安全性及个人化能力。


<details>
  <summary>Details</summary>
Motivation: 现有利用人类反馈优化语言模型的方法，难以解释人类反馈数据具体包含哪些偏好特征，也难以自动发现隐含的主观因素。因此，开发能解释反馈数据、并指导安全数据筛选与模型调整的方法具有重要意义。

Method: 作者提出使用稀疏自编码器（sparse autoencoders），自动从反馈数据中提取少数能被人解释的主要特征。通过对多个人类反馈数据集进行分析，WIMHF揭示了反馈中可被测量和实际表达的各类人类偏好，并对模型表现产生贡献。

Result: WIMHF方法在7个数据集上均有效识别出主导反馈偏好的少数特征，这些特征易于人工理解，并在不同数据集展现出显著的个体差异与安全隐患（如不同用户对不当内容的容忍度）。重标注存在问题的数据后，模型的安全性显著提升了37%，个性化特征建模也提升了偏好预测效果。

Conclusion: WIMHF为分析人类反馈数据的本质提供了工具，有助于提升语言模型的安全性、透明度和个性化能力，对反馈调优流程具有实际指导价值。

Abstract: Human feedback can alter language models in unpredictable and undesirable
ways, as practitioners lack a clear understanding of what feedback data
encodes. While prior work studies preferences over certain attributes (e.g.,
length or sycophancy), automatically extracting relevant features without
pre-specifying hypotheses remains challenging. We introduce What's In My Human
Feedback? (WIMHF), a method to explain feedback data using sparse autoencoders.
WIMHF characterizes both (1) the preferences a dataset is capable of measuring
and (2) the preferences that the annotators actually express. Across 7
datasets, WIMHF identifies a small number of human-interpretable features that
account for the majority of the preference prediction signal achieved by
black-box models. These features reveal a wide diversity in what humans prefer,
and the role of dataset-level context: for example, users on Reddit prefer
informality and jokes, while annotators in HH-RLHF and PRISM disprefer them.
WIMHF also surfaces potentially unsafe preferences, such as that LMArena users
tend to vote against refusals, often in favor of toxic content. The learned
features enable effective data curation: re-labeling the harmful examples in
Arena yields large safety gains (+37%) with no cost to general performance.
They also allow fine-grained personalization: on the Community Alignment
dataset, we learn annotator-specific weights over subjective features that
improve preference prediction. WIMHF provides a human-centered analysis method
for practitioners to better understand and use preference data.

</details>


### [101] [Towards Global Retrieval Augmented Generation: A Benchmark for Corpus-Level Reasoning](https://arxiv.org/abs/2510.26205)
*Qi Luo,Xiaonan Li,Tingshuo Fan,Xinchi Chen,Xipeng Qiu*

Main category: cs.CL

TL;DR: 本文关注RAG在需要全局信息汇聚的任务中的表现，提出了相应的评测基准和方法。


<details>
  <summary>Details</summary>
Motivation: 现有RAG评测主要针对局部信息（local RAG），但实际应用往往需要跨文档、全局性质的信息整合（global RAG），目前缺乏针对这类能力的评测与提升方法。

Method: 提出GlobalQA基准，包含计数、极值、排序、Top-k等四类全局任务；系统评测主流方法后，针对不足提出GlobalRAG框架，利用chunk级检索、智能过滤与符号型聚合模块，提升全局RAG表现。

Result: 现有RAG方法在全局任务表现差，最佳F1仅1.51。GlobalRAG在Qwen2.5-14B模型上将F1提升至6.63，显著超越现有基线。

Conclusion: 全局RAG能力当前极为薄弱，GlobalQA基准和GlobalRAG框架能有效评估并提升大模型在此类复杂场景下的能力。

Abstract: Retrieval-augmented generation (RAG) has emerged as a leading approach to
reducing hallucinations in large language models (LLMs). Current RAG evaluation
benchmarks primarily focus on what we call local RAG: retrieving relevant
chunks from a small subset of documents to answer queries that require only
localized understanding within specific text chunks. However, many real-world
applications require a fundamentally different capability -- global RAG --
which involves aggregating and analyzing information across entire document
collections to derive corpus-level insights (for example, "What are the top 10
most cited papers in 2023?"). In this paper, we introduce GlobalQA -- the first
benchmark specifically designed to evaluate global RAG capabilities, covering
four core task types: counting, extremum queries, sorting, and top-k
extraction. Through systematic evaluation across different models and
baselines, we find that existing RAG methods perform poorly on global tasks,
with the strongest baseline achieving only 1.51 F1 score. To address these
challenges, we propose GlobalRAG, a multi-tool collaborative framework that
preserves structural coherence through chunk-level retrieval, incorporates
LLM-driven intelligent filters to eliminate noisy documents, and integrates
aggregation modules for precise symbolic computation. On the Qwen2.5-14B model,
GlobalRAG achieves 6.63 F1 compared to the strongest baseline's 1.51 F1,
validating the effectiveness of our method.

</details>


### [102] [Pragmatic Theories Enhance Understanding of Implied Meanings in LLMs](https://arxiv.org/abs/2510.26253)
*Takuma Sato,Seiya Kawano,Koichiro Yoshino*

Main category: cs.CL

TL;DR: 该论文探讨用含有语用理论的提示工程提升大模型对言外之意理解能力，通过实验验证此方法效果显著。


<details>
  <summary>Details</summary>
Motivation: 理解隐含意义对人类沟通和语言模型都很关键，然而大模型往往难以精确推断语用含义，因此需提升模型的语用推理能力。

Method: 提出在提示词中引入语用理论（如Grice语用学、关联理论）简介，并引导模型分步骤推理，比较这种加理论提示和不加理论提示的基线方法（零样本思想链）。

Result: 引入语用理论概述的提示能让模型在语用推理任务上，得分较基线最高提升9.6%。即使只在提示中提到理论名称，也可使大模型得分提升1-3%。

Conclusion: 通过将语用理论融入提示，可以显著增强大语言模型理解言外之意的能力，提示设计在模型表现提升中极为重要。

Abstract: The ability to accurately interpret implied meanings plays a crucial role in
human communication and language use, and language models are also expected to
possess this capability. This study demonstrates that providing language models
with pragmatic theories as prompts is an effective in-context learning approach
for tasks to understand implied meanings. Specifically, we propose an approach
in which an overview of pragmatic theories, such as Gricean pragmatics and
Relevance Theory, is presented as a prompt to the language model, guiding it
through a step-by-step reasoning process to derive a final interpretation.
Experimental results showed that, compared to the baseline, which prompts
intermediate reasoning without presenting pragmatic theories (0-shot
Chain-of-Thought), our methods enabled language models to achieve up to 9.6\%
higher scores on pragmatic reasoning tasks. Furthermore, we show that even
without explaining the details of pragmatic theories, merely mentioning their
names in the prompt leads to a certain performance improvement (around 1-3%) in
larger models compared to the baseline.

</details>


### [103] [Language Models Are Borrowing-Blind: A Multilingual Evaluation of Loanword Identification across 10 Languages](https://arxiv.org/abs/2510.26254)
*Mérilin Sousa Silva,Sina Ahmadi*

Main category: cs.CL

TL;DR: 本文研究了大模型等预训练语言模型能否像人类一样分辨借词和本族词，发现它们辨别能力较差。


<details>
  <summary>Details</summary>
Motivation: 在多语种社区，主导语言往往持续向少数语言输入借词，人类能区分二者。但目前尚不清楚语言模型是否具备类似能力。借词识别对少数语言保护工具开发有重要意义。

Method: 作者评估了多种主流预训练语言模型（包括大语言模型）在10种语言上的借词识别能力，模型在接收明确指示和上下文信息的条件下进行测试。

Result: 结果表明，尽管给予了明确指示和背景，模型在区分借词与本族词方面表现不佳，并且对借词存在偏向性。

Conclusion: 现代NLP系统在借词识别方面能力有限，倾向于借词。该结论对开发少数语言NLP工具和语言保护有重要影响。

Abstract: Throughout language history, words are borrowed from one language to another
and gradually become integrated into the recipient's lexicon. Speakers can
often differentiate these loanwords from native vocabulary, particularly in
bilingual communities where a dominant language continuously imposes lexical
items on a minority language. This paper investigates whether pretrained
language models, including large language models, possess similar capabilities
for loanword identification. We evaluate multiple models across 10 languages.
Despite explicit instructions and contextual information, our results show that
models perform poorly in distinguishing loanwords from native ones. These
findings corroborate previous evidence that modern NLP systems exhibit a bias
toward loanwords rather than native equivalents. Our work has implications for
developing NLP tools for minority languages and supporting language
preservation in communities under lexical pressure from dominant languages.

</details>


### [104] [Distilling Multilingual Vision-Language Models: When Smaller Models Stay Multilingual](https://arxiv.org/abs/2510.26271)
*Sukrit Sriratanawilai,Jhayahgrit Thongwat,Romrawin Chumpu,Patomporn Payoungkhamdee,Sarana Nutanong,Peerat Limkonchotiwat*

Main category: cs.CL

TL;DR: 本文研究了如何通过知识蒸馏提升多语种视觉-语言模型在压缩后的跨语种表现和任务稳定性，发现不同蒸馏方法在保持多语种鲁棒性和下游任务稳定性方面差异显著。


<details>
  <summary>Details</summary>
Motivation: 多语种视觉-语言模型在不同语言间表现不均，且模型尺寸缩小时问题加剧。现有知识蒸馏在多语言场景下的表现和机制尚未被充分研究。

Method: 本文控制变量，系统性比较了5种蒸馏方法在CLIP和SigLIP2模型上的行为，通过跨语种表示一致性和下游任务（包括域内检索和域外视觉问答）的稳定性进行评估。

Result: 部分知识蒸馏配置即使大幅压缩模型尺寸，也能保持甚至提升多语种检索的鲁棒性，但有些配置未能同时兼顾跨任务的稳定性，揭示了设计上的权衡，且这些不足从整体准确率难以体现。

Conclusion: 知识蒸馏在视觉-语言模型多语种能力保持有潜力，但具体蒸馏方法的选择对跨语种与跨任务表现影响显著，需综合考虑不同场景需求。

Abstract: Vision-language models (VLMs) exhibit uneven performance across languages, a
problem that is often exacerbated when the model size is reduced. While
Knowledge distillation (KD) demonstrates promising results in transferring
knowledge from larger to smaller VLMs, applying KD in multilingualism is an
underexplored area. This paper presents a controlled empirical study of KD
behavior across five distillation approaches, isolating their effects on
cross-lingual representation consistency and downstream performance stability
under model compression. We study five distillation formulations across CLIP
and SigLIP2, and evaluate them on in-domain retrieval and out-of-domain visual
QA. We find that some configurations preserve or even improve multilingual
retrieval robustness despite halving model size, but others fail to maintain
cross-task stability, exposing design-sensitive trade-offs that aggregate
accuracy alone does not reveal.

</details>


### [105] [Do LLMs Signal When They're Right? Evidence from Neuron Agreement](https://arxiv.org/abs/2510.26277)
*Kang Chen,Yaoning Wang,Kai Xiong,Zhuoka Feng,Wenhe Sun,Haotian Chen,Yixin Cao*

Main category: cs.CL

TL;DR: 论文提出了一种新的基于神经元激活内部信号的解码方法NAD，用于提升大模型推理能力，在无需标签的情形下提升准确性，并大幅减少无用token生成。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型通常依赖输出概率、熵、自评等外部信号进行样本评估和加权投票，但这些信号在模型后训练阶段经常校准不佳，无法充分利用模型内部丰富信息。作者希望利用内部神经元激活特征，提高推理过程的准确率与效率。

Method: 作者分析了正确与错误回答的内部神经元激活，发现正确回答会激活更少、但更一致的神经元。基于此，提出无监督的Neuron Agreement Decoding（NAD）方法，通过稀疏激活和不同样本神经元一致性判据，在无需标签和输出文本可比性的情境下选出最佳生成结果。

Result: NAD方法在数学和科学类有明确答案的基准集上，与传统多数投票方法表现相当；在开放式代码生成这类无法用多数投票的方法中，NAD表现优于现有平均法。同时，NAD能提前预测正确性，极大减少不必要token生成，token用量降幅高达99%，生成质量几乎无损。

Conclusion: 大模型推理中神经元层面的内部信号蕴含丰富有效信息，利用激活稀疏性与一致性可以取代或增强传统外部评估信号，实现高效、可靠、无标签的智能解码，对大模型部署和推理效率有很大意义。

Abstract: Large language models (LLMs) commonly boost reasoning via
sample-evaluate-ensemble decoders, achieving label free gains without ground
truth. However, prevailing strategies score candidates using only external
outputs such as token probabilities, entropies, or self evaluations, and these
signals can be poorly calibrated after post training. We instead analyze
internal behavior based on neuron activations and uncover three findings: (1)
external signals are low dimensional projections of richer internal dynamics;
(2) correct responses activate substantially fewer unique neurons than
incorrect ones throughout generation; and (3) activations from correct
responses exhibit stronger cross sample agreement, whereas incorrect ones
diverge. Motivated by these observations, we propose Neuron Agreement Decoding
(NAD), an unsupervised best-of-N method that selects candidates using
activation sparsity and cross sample neuron agreement, operating solely on
internal signals and without requiring comparable textual outputs. NAD enables
early correctness prediction within the first 32 generated tokens and supports
aggressive early stopping. Across math and science benchmarks with verifiable
answers, NAD matches majority voting; on open ended coding benchmarks where
majority voting is inapplicable, NAD consistently outperforms Avg@64. By
pruning unpromising trajectories early, NAD reduces token usage by 99% with
minimal loss in generation quality, showing that internal signals provide
reliable, scalable, and efficient guidance for label free ensemble decoding.

</details>


### [106] [Unravelling the Mechanisms of Manipulating Numbers in Language Models](https://arxiv.org/abs/2510.26285)
*Michal Štefánik,Timothee Mickus,Marek Kadlčík,Bertram Højer,Michal Spiegel,Raúl Vázquez,Aman Sinha,Josef Kuchař,Philipp Mondorf*

Main category: cs.CL

TL;DR: 本文探究了大语言模型（LLM）对数字信息处理的底层机制，发现模型虽有输出错误倾向，但其内部表示高度一致且准确，可以系统性地追踪和解释数字处理过程。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究表明不同的大语言模型在数字输入的嵌入表征上趋于一致且准确，但实际上模型在数字处理任务中常出现错误。本研究旨在解释这一矛盾，理解模型处理数字信息时的机制与准确性下限。

Method: 作者分析不同LLM对数字的表示，测试这些表征在不同隐藏层、输入上下文中的一致性和可互换性，并开发了普适探针方法用以追踪层级信息和错误的成因。

Result: 研究发现，不同模型对数字的内部表征高度一致、准确且在不同层和不同背景下具通用性。借助建立的探针可有效识别输出错误的层级原因。

Conclusion: 工作为理解预训练LLM如何操作数字信息提供了基础支撑，显示开发更准确的探针有助于推动LLM架构改进和数字处理能力提升。

Abstract: Recent work has shown that different large language models (LLMs) converge to
similar and accurate input embedding representations for numbers. These
findings conflict with the documented propensity of LLMs to produce erroneous
outputs when dealing with numeric information. In this work, we aim to explain
this conflict by exploring how language models manipulate numbers and quantify
the lower bounds of accuracy of these mechanisms. We find that despite
surfacing errors, different language models learn interchangeable
representations of numbers that are systematic, highly accurate and universal
across their hidden states and the types of input contexts. This allows us to
create universal probes for each LLM and to trace information -- including the
causes of output errors -- to specific layers. Our results lay a fundamental
understanding of how pre-trained LLMs manipulate numbers and outline the
potential of more accurate probing techniques in addressed refinements of LLMs'
architectures.

</details>


### [107] [Can Agent Conquer Web? Exploring the Frontiers of ChatGPT Atlas Agent in Web Games](https://arxiv.org/abs/2510.26298)
*Jingran Zhang,Ning Li,Justin Cui*

Main category: cs.CL

TL;DR: 本文评估了OpenAI ChatGPT Atlas在动态网页交互环境下（通过浏览器小游戏）表现，发现其在逻辑推理任务表现优异，但在需要实时操作的动态任务中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 虽然ChatGPT Atlas已展示信息检索任务的能力，但其在动态、交互性强的网页环境中的表现尚未被全面评估。因此，作者希望系统性评估其网页交互能力，特别是在实际动态任务中的局限性。

Method: 作者选择了几款典型的浏览器游戏作为测试场景，如T-Rex Runner、数独、Flappy Bird和Stein.world，以游戏内得分作为定量评价标准，对Atlas在不同类型任务下的表现进行比较。

Result: 实验结果显示，Atlas在需要逻辑推理的数独游戏中表现优异，解题速度远快于人类基线；但在需要实时动作和精确操作的小游戏（如Flappy Bird）中，往往卡在初始障碍，难以取得进展。

Conclusion: Atlas具备较强的分析处理能力，能够胜任静态、推理类任务，但在要求实时交互和复杂动作控制的动态网页环境下仍有明显不足，需要进一步提升其实时交互能力。

Abstract: OpenAI's ChatGPT Atlas introduces new capabilities for web interaction,
enabling the model to analyze webpages, process user intents, and execute
cursor and keyboard inputs directly within the browser. While its capacity for
information retrieval tasks has been demonstrated, its performance in dynamic,
interactive environments remains less explored. In this study, we conduct an
early evaluation of Atlas's web interaction capabilities using browser-based
games as test scenarios, including Google's T-Rex Runner, Sudoku, Flappy Bird,
and Stein.world. We employ in-game performance scores as quantitative metrics
to assess performance across different task types. Our results show that Atlas
performs strongly in logical reasoning tasks like Sudoku, completing puzzles
significantly faster than human baselines, but struggles substantially in
real-time games requiring precise timing and motor control, often failing to
progress beyond initial obstacles. These findings suggest that while Atlas
demonstrates capable analytical processing, there remain notable limitations in
dynamic web environments requiring real-time interaction. The website of our
project can be found at https://atlas-game-eval.github.io.

</details>


### [108] [SCRIBE: Structured Chain Reasoning for Interactive Behaviour Explanations using Tool Calling](https://arxiv.org/abs/2510.26322)
*Fares Fawzi,Vinitra Swamy,Dominik Glandorf,Tanya Nazaretsky,Tanja Käser*

Main category: cs.CL

TL;DR: 该论文提出了SCRIBE框架，一种多步、工具增强的推理方法，能在隐私敏感和算力有限的教育场景下，为学生个性化反馈提供高质量回答。SCRIBE经过蒸馏和微调后，小规模模型（3B和8B参数量）在多项评价上达到甚至超过大模型表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型有潜力在教育中为学生提供个性化反馈，但实际部署面临隐私、算力和教学有效性三大挑战，因此需要开发能本地运行且信息可靠的小型开源模型。

Method: 提出SCRIBE框架，结合工具使用与自反推理流程，实现多步推理、工具调用和错误恢复。通过两阶段LoRA技术对3B、8B模型进行微调，采用GPT-4o生成的合成数据进行训练。

Result: 8B-SCRIBE模型（小体量）在相关性和可操作性等维度上，与更大参数量的大模型甚至GPT-4o、Llama-3.3 70B持平或更优。

Conclusion: SCRIBE展示了小参数模型在教育类应用中兼顾隐私、低算力与高质量反馈的可行性，为低资源、需保护隐私的教育环境提供了有效解决方案。

Abstract: Language models can be used to provide interactive, personalized student
feedback in educational settings. However, real-world deployment faces three
key challenges: privacy concerns, limited computational resources, and the need
for pedagogically valid responses. These constraints require small, open-source
models that can run locally and reliably ground their outputs in correct
information. We introduce SCRIBE, a framework for multi-hop, tool-augmented
reasoning designed to generate valid responses to student questions about
feedback reports. SCRIBE combines domain-specific tools with a self-reflective
inference pipeline that supports iterative reasoning, tool use, and error
recovery. We distil these capabilities into 3B and 8B models via two-stage LoRA
fine-tuning on synthetic GPT-4o-generated data. Evaluation with a human-aligned
GPT-Judge and a user study with 108 students shows that 8B-SCRIBE models
achieve comparable or superior quality to much larger models in key dimensions
such as relevance and actionability, while being perceived on par with GPT-4o
and Llama-3.3 70B by students. These findings demonstrate the viability of
SCRIBE for low-resource, privacy-sensitive educational applications.

</details>


### [109] [From Amateur to Master: Infusing Knowledge into LLMs via Automated Curriculum Learning](https://arxiv.org/abs/2510.26336)
*Nishit Neema,Srinjoy Mukherjee,Sapan Shah,Gokul Ramakrishnan,Ganesh Venkatesh*

Main category: cs.CL

TL;DR: 该论文提出ACER方法，通过自动生成领域课程和QA对，提升大模型在经济学等专业领域的表现，同时保持其广泛能力。实验显示该方法有效促进专精领域的准确率，并未导致知识遗忘。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型虽然通用性强，但在经济学、心理学等需深入理解的专业领域表现较差，因此亟需提升模型在这些领域的能力，而不牺牲其通用性。

Method: 提出ACER流程：首先自动生成教科书式的课程大纲和符合Bloom认知层级难度的QA对，形成系统、递进的合成语料。利用该合成数据对模型持续预训练，采用交错课程调度以覆盖内容和认知维度。

Result: 在Llama 3.2(1B、3B)模型上，ACER使经济学等MMLU子集准确率提升5个百分点，所有目标领域平均提升3个百分点。同时防止灾难性遗忘，非目标领域也提升0.7个百分点。在ARC、GPQA等知识密集任务上提升2个百分点，一般推理稳定。

Conclusion: ACER可扩展且高效地弥补大模型在专业领域的短板，不影响其一般性能，是提升领域能力的有效方案。

Abstract: Large Language Models (LLMs) excel at general tasks but underperform in
specialized domains like economics and psychology, which require deep,
principled understanding. To address this, we introduce ACER (Automated
Curriculum-Enhanced Regimen) that transforms generalist models into domain
experts without sacrificing their broad capabilities. ACER first synthesizes a
comprehensive, textbook-style curriculum by generating a table of contents for
a subject and then creating question-answer (QA) pairs guided by Bloom's
taxonomy. This ensures systematic topic coverage and progressively increasing
difficulty. The resulting synthetic corpus is used for continual pretraining
with an interleaved curriculum schedule, aligning learning across both content
and cognitive dimensions.
  Experiments with Llama 3.2 (1B and 3B) show significant gains in specialized
MMLU subsets. In challenging domains like microeconomics, where baselines
struggle, ACER boosts accuracy by 5 percentage points. Across all target
domains, we observe a consistent macro-average improvement of 3 percentage
points. Notably, ACER not only prevents catastrophic forgetting but also
facilitates positive cross-domain knowledge transfer, improving performance on
non-target domains by 0.7 points. Beyond MMLU, ACER enhances performance on
knowledge-intensive benchmarks like ARC and GPQA by over 2 absolute points,
while maintaining stable performance on general reasoning tasks. Our results
demonstrate that ACER offers a scalable and effective recipe for closing
critical domain gaps in LLMs.

</details>


### [110] [MisSynth: Improving MISSCI Logical Fallacies Classification with Synthetic Data](https://arxiv.org/abs/2510.26345)
*Mykhailo Poliakov,Nadiya Shvai*

Main category: cs.CL

TL;DR: 本文提出了一种利用合成数据提升大模型识别科学谬误能力的方法，显著提高了模型效果。


<details>
  <summary>Details</summary>
Motivation: 健康相关错误信息泛滥，对大众危害极大，而这些信息通常扭曲、曲解科学发现，识别难度大。为了提升大模型在此领域的识别能力，亟需有效方法来增强有限标注资源。

Method: 作者提出MisSynth方法，利用检索增强生成（RAG）自动合成谬误样本，并用这些数据对大型语言模型（如LLaMA 3.1 8B）进行轻量级微调。通过在MISSCI数据集和框架下评估微调前后性能变化。

Result: 经合成数据微调后的模型在MISSCI测试集上的F1分数比未微调的基线模型提升了35%以上。实验表明，合成谬误样本可明显提高大模型对科学领域错误信息的零样本识别能力。

Conclusion: 通过合成数据扩充有限标注，能在低资源和有限算力条件下显著提升大模型科学错信检测表现，为实际应用提供了有效方案。

Abstract: Health-related misinformation is very prevalent and potentially harmful. It
is difficult to identify, especially when claims distort or misinterpret
scientific findings. We investigate the impact of synthetic data generation and
lightweight fine-tuning techniques on the ability of large language models
(LLMs) to recognize fallacious arguments using the MISSCI dataset and
framework. In this work, we propose MisSynth, a pipeline that applies
retrieval-augmented generation (RAG) to produce synthetic fallacy samples,
which are then used to fine-tune an LLM model. Our results show substantial
accuracy gains with fine-tuned models compared to vanilla baselines. For
instance, the LLaMA 3.1 8B fine-tuned model achieved an over 35% F1-score
absolute improvement on the MISSCI test split over its vanilla baseline. We
demonstrate that introducing synthetic fallacy data to augment limited
annotated resources can significantly enhance zero-shot LLM classification
performance on real-world scientific misinformation tasks, even with limited
computational resources. The code and synthetic dataset are available on
https://github.com/mxpoliakov/MisSynth.

</details>


### [111] [The Geometry of Dialogue: Graphing Language Models to Reveal Synergistic Teams for Multi-Agent Collaboration](https://arxiv.org/abs/2510.26352)
*Kotaro Furuya,Yuichi Kitagawa*

Main category: cs.CL

TL;DR: 本文提出了一种基于交互的自动化大型语言模型团队组建框架，通过语义对话构建模型关系图，并利用社区发现方法自动划分协同小组，无需先验知识。实验表明，所组团队在下游任务上优于随机组队，与人工精心组队效果相当。


<details>
  <summary>Details</summary>
Motivation: 多语言模型协作可能优于单一模型，但由于各模型内部特性不透明，如何自动组建高效团队成为难题。

Method: 方法通过让各模型两两对话，基于对话的语义一致性绘制“语言模型图”，再用社区检测找出潜在协作团队。无需了解各模型架构、数据或性能信息。

Result: 实验显示，该方法自动发现了功能一致的小组，组队后的效果超过随机组队，且与基于模型专长手动组队的准确率相当。

Conclusion: 该框架为自动化、多智能体LLM团队设计提供了新思路，有望推动LLM协作应用发展。

Abstract: While a multi-agent approach based on large language models (LLMs) represents
a promising strategy to surpass the capabilities of single models, its success
is critically dependent on synergistic team composition. However, forming
optimal teams is a significant challenge, as the inherent opacity of most
models obscures the internal characteristics necessary for effective
collaboration. In this paper, we propose an interaction-centric framework for
automatic team composition that does not require any prior knowledge including
their internal architectures, training data, or task performances. Our method
constructs a "language model graph" that maps relationships between models from
the semantic coherence of pairwise conversations, and then applies community
detection to identify synergistic model clusters. Our experiments with diverse
LLMs demonstrate that the proposed method discovers functionally coherent
groups that reflect their latent specializations. Priming conversations with
specific topics identified synergistic teams which outperform random baselines
on downstream benchmarks and achieve comparable accuracy to that of
manually-curated teams based on known model specializations. Our findings
provide a new basis for the automated design of collaborative multi-agent LLM
teams.

</details>


### [112] [On the Role of Context for Discourse Relation Classification in Scientific Writing](https://arxiv.org/abs/2510.26354)
*Stephen Wan,Wei Liu,Michael Strube*

Main category: cs.CL

TL;DR: 本文探讨了如何利用语篇层面的信息提升科学论文中AI生成学术主张的证据查找，重点分析了科学文本的语篇关系分类任务。


<details>
  <summary>Details</summary>
Motivation: 在科学研究工作流中，生成式AI广泛用于辅助推理和信息生成，但如何验证AI生成的学术断言成为挑战。研究动因是利用语篇结构信息，提升证据查找和推理支持能力，而科学文本在语篇关系分类领域研究相对较少。

Method: 作者基于预训练语言模型（PLM）和大型语言模型（LLM），针对科学出版物中的语篇关系分类任务开展实验，分析了上下文信息（通过语篇结构界定）对分类任务的影响，并对受益最大的语篇关系类型进行了深入分析。

Result: 实验结果显示，加入基于语篇结构定义的上下文信息，可以提升语篇关系分类任务的表现；同时，有些特定的科学语篇关系类型在使用上下文时受益更大。

Conclusion: 科学出版物中的语篇关系分类任务受益于上下文的引入，尤其针对某些语篇关系类型，利用语篇结构信息将显著提升AI帮助科学证据查找的能力。

Abstract: With the increasing use of generative Artificial Intelligence (AI) methods to
support science workflows, we are interested in the use of discourse-level
information to find supporting evidence for AI generated scientific claims. A
first step towards this objective is to examine the task of inferring discourse
structure in scientific writing.
  In this work, we present a preliminary investigation of pretrained language
model (PLM) and Large Language Model (LLM) approaches for Discourse Relation
Classification (DRC), focusing on scientific publications, an under-studied
genre for this task. We examine how context can help with the DRC task, with
our experiments showing that context, as defined by discourse structure, is
generally helpful. We also present an analysis of which scientific discourse
relation types might benefit most from context.

</details>


### [113] [OmniEduBench: A Comprehensive Chinese Benchmark for Evaluating Large Language Models in Education](https://arxiv.org/abs/2510.26422)
*Min Zhang,Hao Chen,Hao Chen,Wenqi Zhang,Didi Zhu,Xin Lin,Bo Jiang,Aimin Zhou,Fei Wu,Kun Kuang*

Main category: cs.CL

TL;DR: 本文提出了OmniEduBench，一个覆盖知识与素养维度、包含61个学科、11种题型的中文教育大模型基准数据集，用于全面评测大模型在教育场景下的能力。实验结果揭示当前模型与人类智能还有较大差距。


<details>
  <summary>Details</summary>
Motivation: 当前大模型及评测集大多只关注知识考查，忽略了素养类能力，且在中国教育场景下多学科、多题型的评测工具稀缺。这阻碍了AI在真实教育场景中的应用与进步。

Method: 构建了OmniEduBench，收录24602条高质量中英文教育问答数据，按知识与素养两个维度细分成共12个子类，覆盖61门学科、11类常见题型，并在11种主流大模型上进行了系统性评估。

Result: 在知识维度，只有Gemini-2.5 Pro超过60%准确率。素养维度中表现最好者（QWQ）与人类智能仍有近30%差距，主流模型普遍表现未达预期。

Conclusion: 当前主流大模型在包括素养等实际教育能力上存在明显不足，未来还需大幅提升模型泛化与能力，以便更好地支撑教育应用。

Abstract: With the rapid development of large language models (LLMs), various LLM-based
works have been widely applied in educational fields. However, most existing
LLMs and their benchmarks focus primarily on the knowledge dimension, largely
neglecting the evaluation of cultivation capabilities that are essential for
real-world educational scenarios. Additionally, current benchmarks are often
limited to a single subject or question type, lacking sufficient diversity.
This issue is particularly prominent within the Chinese context. To address
this gap, we introduce OmniEduBench, a comprehensive Chinese educational
benchmark. OmniEduBench consists of 24.602K high-quality question-answer pairs.
The data is meticulously divided into two core dimensions: the knowledge
dimension and the cultivation dimension, which contain 18.121K and 6.481K
entries, respectively. Each dimension is further subdivided into 6 fine-grained
categories, covering a total of 61 different subjects (41 in the knowledge and
20 in the cultivation). Furthermore, the dataset features a rich variety of
question formats, including 11 common exam question types, providing a solid
foundation for comprehensively evaluating LLMs' capabilities in education.
Extensive experiments on 11 mainstream open-source and closed-source LLMs
reveal a clear performance gap. In the knowledge dimension, only Gemini-2.5 Pro
surpassed 60\% accuracy, while in the cultivation dimension, the
best-performing model, QWQ, still trailed human intelligence by nearly 30\%.
These results highlight the substantial room for improvement and underscore the
challenges of applying LLMs in education.

</details>


### [114] [1+1>2: A Synergistic Sparse and Low-Rank Compression Method for Large Language Models](https://arxiv.org/abs/2510.26446)
*Zeliang Zong,Kai Zhang,Zheyang Li,Wenming Tan,Ye Ren,Yiyan Zhai,Jilin Hu*

Main category: cs.CL

TL;DR: 本文提出了结合稀疏化与低秩分解的LLM压缩方法SSLC，实现了显著的模型体积和推理速度提升且无损性能。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型LLM表现优异，但其高带宽和算力需求限制了实际应用。现有的参数剪枝和低秩近似单独都能缩小模型，但二者结合在LLM场景下仍欠缺系统研究。

Method: 作者提出SSLC方法，将低秩近似与稀疏优化统一建模为一个问题，并采用迭代优化算法解决。这种组合利用低秩近似保持关键信息，稀疏优化去除冗余权重，无需额外训练步骤。

Result: 在LLaMA和Qwen2.5等7B-70B参数模型上实验显示，SSLC优于单独方法，可在Qwen2.5上实现50%模型压缩且无性能损失，推理速度提升至少1.63倍，均达到最新最佳水平。

Conclusion: SSLC为大型语言模型的高效部署提供了实用方案，实现模型显著压缩和加速的同时保持原有性能。

Abstract: Large Language Models (LLMs) have demonstrated remarkable proficiency in
language comprehension and generation; however, their widespread adoption is
constrained by substantial bandwidth and computational demands. While pruning
and low-rank approximation have each demonstrated promising performance
individually, their synergy for LLMs remains underexplored. We introduce
\underline{S}ynergistic \underline{S}parse and \underline{L}ow-Rank
\underline{C}ompression (SSLC) methods for LLMs, which leverages the strengths
of both techniques: low-rank approximation compresses the model by retaining
its essential structure with minimal information loss, whereas sparse
optimization eliminates non-essential weights, preserving those crucial for
generalization. Based on theoretical analysis, we first formulate the low-rank
approximation and sparse optimization as a unified problem and solve it by
iterative optimization algorithm. Experiments on LLaMA and Qwen2.5 models
(7B-70B) show that SSLC, without any additional training steps, consistently
surpasses standalone methods, achieving state-of-the-arts results. Notably,
SSLC compresses Qwen2.5 by 50\% with no performance drop and achieves at least
1.63$\times$ speedup, offering a practical solution for efficient LLM
deployment.

</details>


### [115] [Bayesian Network Fusion of Large Language Models for Sentiment Analysis](https://arxiv.org/abs/2510.26484)
*Rasoul Amirzadeh,Dhananjay Thiruvady,Fatemeh Shiri*

Main category: cs.CL

TL;DR: 本论文提出了Bayesian network LLM fusion (BNLF) 框架，通过贝叶斯网络融合多种大型语言模型（LLMs），有效提升了金融情感分析任务的准确率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前领域定制的LLMs在透明性、可解释性、调优成本、一致性和环境影响方面存在明显问题。因此，亟需一种更高效、可解释和稳健的模型融合方法。

Method: 采用贝叶斯网络将FinBERT、RoBERTa和BERTweet三种LLMs的情感预测结果作为概率节点进行后融合，建成新的模型BNLF，实现不同模型信息的互补与不确定性建模。

Result: 在三个风格各异的金融文本数据集上，BNLF较单一LLM模型平均提升约6%的准确率，并展示出对不同数据集表现出较高的稳健性。

Conclusion: BNLF利用概率融合机制不仅提升了情感分析准确性，还增强了结果的可解释性和模型对数据变化的鲁棒性。

Abstract: Large language models (LLMs) continue to advance, with an increasing number
of domain-specific variants tailored for specialised tasks. However, these
models often lack transparency and explainability, can be costly to fine-tune,
require substantial prompt engineering, yield inconsistent results across
domains, and impose significant adverse environmental impact due to their high
computational demands. To address these challenges, we propose the Bayesian
network LLM fusion (BNLF) framework, which integrates predictions from three
LLMs, including FinBERT, RoBERTa, and BERTweet, through a probabilistic
mechanism for sentiment analysis. BNLF performs late fusion by modelling the
sentiment predictions from multiple LLMs as probabilistic nodes within a
Bayesian network. Evaluated across three human-annotated financial corpora with
distinct linguistic and contextual characteristics, BNLF demonstrates
consistent gains of about six percent in accuracy over the baseline LLMs,
underscoring its robustness to dataset variability and the effectiveness of
probabilistic fusion for interpretable sentiment classification.

</details>


### [116] [A Multi-agent Large Language Model Framework to Automatically Assess Performance of a Clinical AI Triage Tool](https://arxiv.org/abs/2510.26498)
*Adam E. Flanders,Yifan Peng,Luciano Prevedello,Robyn Ball,Errol Colak,Prahlad Menon,George Shih,Hui-Ming Lin,Paras Lakhani*

Main category: cs.CL

TL;DR: 本研究探讨了多个大语言模型（LLM）集成能否比单一LLM更可靠地评估AI医学分诊工具。结果显示，LLM集成在评估的稳定性和一致性上优于单一LLM。


<details>
  <summary>Details</summary>
Motivation: 目前常用单一LLM对医学AI系统进行评估，但单一模型容易存在偏差或不一致，影响实际临床应用的可靠性。因此，研究者希望通过集成多个LLM，提高评估的准确性和一致性。

Method: 采集29,766例无对比剂头部CT数据，由商业AI检出脑出血，报告由8个开源LLM与内部GPT-4o模型组成的集群进行分析。手动复查1,726例，并对各模型和不同集成策略的表现进行了比较。

Result: Llama3.3:70b和GPT-4o在AUC和AP表现最好，Llama3.3:70b在F1分数、召回率、精度等多项指标上最高。LLM集成方案的MCC表现优于单一GPT-4o，但不同集成方法间差异无统计学意义。

Conclusion: 使用多模型集成（ensemble）的LLM能更一致、可靠地回顾性评估医学AI分诊工具的性能，相比单一LLM更适合作为真实评估手段。

Abstract: Purpose: The purpose of this study was to determine if an ensemble of
multiple LLM agents could be used collectively to provide a more reliable
assessment of a pixel-based AI triage tool than a single LLM.
  Methods: 29,766 non-contrast CT head exams from fourteen hospitals were
processed by a commercial intracranial hemorrhage (ICH) AI detection tool.
Radiology reports were analyzed by an ensemble of eight open-source LLM models
and a HIPAA compliant internal version of GPT-4o using a single multi-shot
prompt that assessed for presence of ICH. 1,726 examples were manually
reviewed. Performance characteristics of the eight open-source models and
consensus were compared to GPT-4o. Three ideal consensus LLM ensembles were
tested for rating the performance of the triage tool.
  Results: The cohort consisted of 29,766 head CTs exam-report pairs. The
highest AUC performance was achieved with llama3.3:70b and GPT-4o (AUC= 0.78).
The average precision was highest for Llama3.3:70b and GPT-4o (AP=0.75 & 0.76).
Llama3.3:70b had the highest F1 score (0.81) and recall (0.85), greater
precision (0.78), specificity (0.72), and MCC (0.57). Using MCC (95% CI) the
ideal combination of LLMs were: Full-9 Ensemble 0.571 (0.552-0.591), Top-3
Ensemble 0.558 (0.537-0.579), Consensus 0.556 (0.539-0.574), and GPT4o 0.522
(0.500-0.543). No statistically significant differences were observed between
Top-3, Full-9, and Consensus (p > 0.05).
  Conclusion: An ensemble of medium to large sized open-source LLMs provides a
more consistent and reliable method to derive a ground truth retrospective
evaluation of a clinical AI triage tool over a single LLM alone.

</details>


### [117] [Inside CORE-KG: Evaluating Structured Prompting and Coreference Resolution for Knowledge Graphs](https://arxiv.org/abs/2510.26512)
*Dipak Meher,Carlotta Domeniconi*

Main category: cs.CL

TL;DR: 人类偷渡网络的知识图谱自动构建因法律文档的复杂性而困难，CORE-KG框架通过引入类型感知指代消解和结构化提示，有效减少了知识图谱中的噪声和节点重复。该论文系统性消融实验量化了这两个关键组件对结果的影响。


<details>
  <summary>Details</summary>
Motivation: 现有利用大模型提取法律知识图谱的方法在处理非结构化和复杂文本时容易出现节点重复和噪声，缺乏有效的提取指导和指代消解机制。论文旨在解决该问题，并分析各关键技术的贡献。

Method: 提出CORE-KG框架，结合类型感知的指代消解模块和领域知识指导的结构化提示，同时进行消融实验，分别去除这些模块以评估其作用。

Result: 移除指代消解后，节点重复增加28.32%，噪声节点增加4.32%；移除结构化提示后，节点重复增加4.34%，噪声节点增加73.33%。

Conclusion: 两大核心模块（指代消解与结构化提示）大幅提升了法律文档知识图谱抽取的准确性和整洁度，对未来大模型驱动的法律信息抽取管道设计有实际指导意义。

Abstract: Human smuggling networks are increasingly adaptive and difficult to analyze.
Legal case documents offer critical insights but are often unstructured,
lexically dense, and filled with ambiguous or shifting references, which pose
significant challenges for automated knowledge graph (KG) construction. While
recent LLM-based approaches improve over static templates, they still generate
noisy, fragmented graphs with duplicate nodes due to the absence of guided
extraction and coreference resolution. The recently proposed CORE-KG framework
addresses these limitations by integrating a type-aware coreference module and
domain-guided structured prompts, significantly reducing node duplication and
legal noise. In this work, we present a systematic ablation study of CORE-KG to
quantify the individual contributions of its two key components. Our results
show that removing coreference resolution results in a 28.32% increase in node
duplication and a 4.32% increase in noisy nodes, while removing structured
prompts leads to a 4.34% increase in node duplication and a 73.33% increase in
noisy nodes. These findings offer empirical insights for designing robust
LLM-based pipelines for extracting structured representations from complex
legal texts.

</details>


### [118] [Hebrew Diacritics Restoration using Visual Representation](https://arxiv.org/abs/2510.26521)
*Yair Elboher,Yuval Pinter*

Main category: cs.CL

TL;DR: 本文提出了一种基于视觉语言模型的希伯来语元音符号恢复系统DIVRIT，将该任务抽象为零样本分类问题，并在多个实验配置下取得了高准确率。


<details>
  <summary>Details</summary>
Motivation: 希伯来语缺乏元音符号时，文本极具歧义，准确还原元音对语音和语义有着重要意义。现有方法虽有进展，但多依赖复杂的语言分析或不足以应对高歧义性，因此需要一种通用且高效的新方法。

Method: DIVRIT系统创新性地将未标注元音的单词转为图像输入，利用视觉语言模型从动态候选集中在上下文条件下选择最优的元音符号恢复方案，不依赖繁琐的语言学特征。模型的结构和训练流程均经过针对性优化。

Result: 在多种实验设置下，DIVRIT无需复杂的语言学分析便能恢复元音，尤其在“神谕”设置下（正确候选一定在集合内）表现出极高准确率。结构优化和训练改进还显著提升了泛化表现。

Conclusion: 视觉特征在希伯来语元音恢复中极具潜力，DIVRIT系统为无标元音文本的准确自动恢复提供了一种新颖、有效的方法，对后续相关研究有重要启示和推动作用。

Abstract: Diacritics restoration in Hebrew is a fundamental task for ensuring accurate
word pronunciation and disambiguating textual meaning. Despite the language's
high degree of ambiguity when unvocalized, recent machine learning approaches
have significantly advanced performance on this task.
  In this work, we present DIVRIT, a novel system for Hebrew diacritization
that frames the task as a zero-shot classification problem. Our approach
operates at the word level, selecting the most appropriate diacritization
pattern for each undiacritized word from a dynamically generated candidate set,
conditioned on the surrounding textual context. A key innovation of DIVRIT is
its use of a Hebrew Visual Language Model, which processes undiacritized text
as an image, allowing diacritic information to be embedded directly within the
input's vector representation.
  Through a comprehensive evaluation across various configurations, we
demonstrate that the system effectively performs diacritization without relying
on complex, explicit linguistic analysis. Notably, in an ``oracle'' setting
where the correct diacritized form is guaranteed to be among the provided
candidates, DIVRIT achieves a high level of accuracy. Furthermore, strategic
architectural enhancements and optimized training methodologies yield
significant improvements in the system's overall generalization capabilities.
These findings highlight the promising potential of visual representations for
accurate and automated Hebrew diacritization.

</details>


### [119] [The Structure of Relation Decoding Linear Operators in Large Language Models](https://arxiv.org/abs/2510.26543)
*Miranda Anna Christ,Adrián Csiszárik,Gergely Becsó,Dániel Varga*

Main category: cs.CL

TL;DR: 本文研究了transformer语言模型中用于解码特定关系事实的线性算子的结构，发现这些算子主要编码的是语义属性而非具体关系，因此可以被高效压缩。


<details>
  <summary>Details</summary>
Motivation: 之前的研究表明，可以用线性算子解码transformer中的单一关系信息，本研究希望扩展到多重关系，并系统性理解这些算子的组织结构和性质。

Method: 将针对单一关系的线性算子扩展为多关系集合，采用order-3张量网络进行压缩，同时设计交叉评估协议，分析不同关系算子的相互作用与提取的信息类型。

Result: 多关系解码器集合可以被简单的order-3张量网络高效压缩，几乎不损失解码准确率。交叉评估显示，各线性算子实际上提取的是复现的、粗粒度的语义属性（如“X所属国家”），而不是具体的关系语义。

Conclusion: transformer模型中的线性关系解码主要是基于属性而非具体的关系，这一结构不仅解释了其易于压缩性，也说明了其泛化能力仅限于语义上相近的新关系。

Abstract: This paper investigates the structure of linear operators introduced in
Hernandez et al. [2023] that decode specific relational facts in transformer
language models. We extend their single-relation findings to a collection of
relations and systematically chart their organization. We show that such
collections of relation decoders can be highly compressed by simple order-3
tensor networks without significant loss in decoding accuracy. To explain this
surprising redundancy, we develop a cross-evaluation protocol, in which we
apply each linear decoder operator to the subjects of every other relation. Our
results reveal that these linear maps do not encode distinct relations, but
extract recurring, coarse-grained semantic properties (e.g., country of capital
city and country of food are both in the country-of-X property). This
property-centric structure clarifies both the operators' compressibility and
highlights why they generalize only to new relations that are semantically
close. Our findings thus interpret linear relational decoding in transformer
language models as primarily property-based, rather than relation-specific.

</details>


### [120] [InfoFlow: Reinforcing Search Agent Via Reward Density Optimization](https://arxiv.org/abs/2510.26575)
*Kun Luo,Hongjin Qian,Zheng Liu,Ziyi Xia,Shitao Xiao,Siqi Bao,Jun Zhao,Kang Liu*

Main category: cs.CL

TL;DR: 本论文提出一种提升强化学习中奖励密度（Reward Density）的新框架InfoFlow，有效解决深度搜索任务中奖励稀疏的问题，并显著提升轻量级大语言模型的表现。


<details>
  <summary>Details</summary>
Motivation: 在深度探索任务中，传统的基于可验证奖励的强化学习往往因为奖励稀疏，导致智能体需要付出极高的探索代价却只能获得极少奖励，极大阻碍了方法的实用性和效果。为此，提升单位探索代价下获得奖励的频率（奖励密度）成为亟需解决的问题。

Method: 本文提出InfoFlow框架，从三个角度提升奖励密度：1）将长距离任务分解为子任务并分配过程奖励，带来更密集的学习信号（子问题分解）；2）在受阻的探索轨迹中注入失败纠正提示，提高任务成功率（失败引导提示）；3）采用二元代理架构，将深度探索中的认知负担分离，由精炼代理综合搜索历史、压缩探索轨迹，从而降低探索成本，提高整体奖励密度（双代理精炼）。

Result: InfoFlow在多个智能体深度搜索基准任务上，均显著优于强基线方法，使轻量级开源大语言模型也能取得媲美高级私有模型的表现。

Conclusion: InfoFlow通过系统性地提升奖励密度，为深度搜索场景下的强化学习带来实用的提升，并大幅扩展了轻量级大模型的应用潜力，对复杂任务的智能体探索带来创新突破。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is a promising approach
for enhancing agentic deep search. However, its application is often hindered
by low \textbf{Reward Density} in deep search scenarios, where agents expend
significant exploratory costs for infrequent and often null final rewards. In
this paper, we formalize this challenge as the \textbf{Reward Density
Optimization} problem, which aims to improve the reward obtained per unit of
exploration cost. This paper introduce \textbf{InfoFlow}, a systematic
framework that tackles this problem from three aspects. 1) \textbf{Subproblem
decomposition}: breaking down long-range tasks to assign process rewards,
thereby providing denser learning signals. 2) \textbf{Failure-guided hints}:
injecting corrective guidance into stalled trajectories to increase the
probability of successful outcomes. 3) \textbf{Dual-agent refinement}:
employing a dual-agent architecture to offload the cognitive burden of deep
exploration. A refiner agent synthesizes the search history, which effectively
compresses the researcher's perceived trajectory, thereby reducing exploration
cost and increasing the overall reward density. We evaluate InfoFlow on
multiple agentic search benchmarks, where it significantly outperforms strong
baselines, enabling lightweight LLMs to achieve performance comparable to
advanced proprietary LLMs.

</details>


### [121] [Inference-Cost-Aware Dynamic Tree Construction for Efficient Inference in Large Language Models](https://arxiv.org/abs/2510.26577)
*Yinrong Hong,Zhiquan Tan,Kai Hu*

Main category: cs.CL

TL;DR: 本文提出了一种名为CAST的动态树结构解码方法，通过优化推理成本（如GPU配置与batch size），实现了大幅提升大模型推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在推理时因自回归特性和模型体积庞大导致延迟较高，虽然已有部分投机解码方法尝试加速，但普遍忽略了系统资源配置等实际因素的影响，导致在实际部署中效果有限。

Method: 作者提出CAST方案，将GPU配置、batch size等硬件资源和推理成本纳入动态树结构的优化过程中，动态调整树的生成与验证机制。

Result: 在六个任务和六个不同LLM的大量实验表明，CAST方法比传统方法最高提速达5.2倍，相较最新方法普遍提升5~20%。

Conclusion: 考虑系统推理成本的动态解码框架CAST能更有效地提速大语言模型推理，可为实际大规模部署提供理论和工程支持。

Abstract: Large Language Models (LLMs) face significant inference latency challenges
stemming from their autoregressive design and large size. To address this,
speculative decoding emerges as a solution, enabling the simultaneous
generation and validation of multiple tokens. While recent approaches like
EAGLE-2 and EAGLE-3 improve speculative decoding using dynamic tree structures,
they often neglect the impact of crucial system variables such as GPU devices
and batch sizes.
  Therefore, we introduce a new dynamic tree decoding approach called CAST that
takes into account inference costs, including factors such as GPU
configurations and batch sizes, to dynamically refine the tree structure.
Through comprehensive experimentation across six diverse tasks and utilizing
six distinct LLMs, our methodology demonstrates remarkable results, achieving
speeds up to 5.2 times faster than conventional decoding methods. Moreover, it
generally outperforms existing state-of-the-art techniques from 5% to 20%.

</details>


### [122] [SlideAgent: Hierarchical Agentic Framework for Multi-Page Visual Document Understanding](https://arxiv.org/abs/2510.26615)
*Yiqiao Jin,Rachneet Kaur,Zhen Zeng,Sumitra Ganesh,Srijan Kumar*

Main category: cs.CL

TL;DR: 本文提出了SlideAgent，一种专门针对多模态、多页、多布局文档（尤其是幻灯片）进行理解的智能体框架，以提升大语言模型对复杂视觉文档的精细推理能力。


<details>
  <summary>Details</summary>
Motivation: 当下的大语言模型在处理复杂的多页视觉文档时，尤其是在细粒度推理层面存在较大挑战，如很难整合跨页、跨元素的信息（比如手册、宣讲册、演示文稿等）。因此，作者希望提出一种方法来提升模型对这类文档的理解能力。

Method: 提出了SlideAgent框架，将推理分解为三层（全局、页面、元素）并利用专用智能体各司其职，共同生成包含层次结构、与查询无关的文档表示，从而同时捕捉主题与细节。在问答时，可以有选择地调用专用智能体，整合其推理结果，得到有条理、具备上下文的答案。

Result: 在大量实验中，SlideAgent在处理多页、多模态文档方面相比专有模型提升7.9分、相比开源模型提升9.8分，表现显著优于现有方案。

Conclusion: SlideAgent通过结构化分层推理与多智能体协作，极大提升了大模型对复杂多页视觉文档的理解和推理能力，对于幻灯片等场景具有很强实用价值。

Abstract: Multi-page visual documents such as manuals, brochures, presentations, and
posters convey key information through layout, colors, icons, and cross-slide
references. While large language models (LLMs) offer opportunities in document
understanding, current systems struggle with complex, multi-page visual
documents, particularly in fine-grained reasoning over elements and pages. We
introduce SlideAgent, a versatile agentic framework for understanding
multi-modal, multi-page, and multi-layout documents, especially slide decks.
SlideAgent employs specialized agents and decomposes reasoning into three
specialized levels-global, page, and element-to construct a structured,
query-agnostic representation that captures both overarching themes and
detailed visual or textual cues. During inference, SlideAgent selectively
activates specialized agents for multi-level reasoning and integrates their
outputs into coherent, context-aware answers. Extensive experiments show that
SlideAgent achieves significant improvement over both proprietary (+7.9
overall) and open-source models (+9.8 overall).

</details>


### [123] [Encoder-Decoder or Decoder-Only? Revisiting Encoder-Decoder Large Language Model](https://arxiv.org/abs/2510.26622)
*Biao Zhang,Yong Cheng,Siamak Shakeri,Xinyi Wang,Min Ma,Orhan Firat*

Main category: cs.CL

TL;DR: 该论文系统比较了编码器-解码器（encoder-decoder）与当前主流的仅解码器（decoder-only）大型语言模型（LLM），发现前者在缩放性和性能等方面表现优异，值得进一步关注和研究。


<details>
  <summary>Details</summary>
Motivation: 目前主流LLM架构已从编码器-解码器转向仅解码器，但缺乏两者尤其在扩展性方面的系统性比较，可能低估了编码器-解码器模型的潜能。

Method: 作者提出RedLLM（编码器-解码器结构），结合了近年来解码器模型的发展经验，并与仅解码器模型（DecLLM）在不同模型规模（150M-8B参数）、相同预训练数据和微调方式下进行了全面对比。

Result: 实验结果表明：在大规模下，RedLLM表现出良好的缩放性质和强大的性能；虽然DecLLM在预训练阶段计算更高效，但RedLLM在多项下游任务上经指令微调后表现出与DecLLM相当甚至更优的性能，并具有更高的推理效率。

Conclusion: 编码器-解码器结构模型具备与甚至优于当前主流结构的潜质，值得再次被关注和研究，以推动更高效、强大的LLM发展。

Abstract: Recent large language model (LLM) research has undergone an architectural
shift from encoder-decoder modeling to nowadays the dominant decoder-only
modeling. This rapid transition, however, comes without a rigorous comparative
analysis especially \textit{from the scaling perspective}, raising concerns
that the potential of encoder-decoder models may have been overlooked. To fill
this gap, we revisit encoder-decoder LLM (RedLLM), enhancing it with recent
recipes from decoder-only LLM (DecLLM). We conduct a comprehensive comparison
between RedLLM, pretrained with prefix language modeling (LM), and DecLLM,
pretrained with causal LM, at different model scales, ranging from $\sim$150M
to $\sim$8B. Using RedPajama V1 (1.6T tokens) for pretraining and FLAN for
instruction tuning, our experiments show that RedLLM produces compelling
scaling properties and surprisingly strong performance. While DecLLM is overall
more compute-optimal during pretraining, RedLLM demonstrates comparable scaling
and context length extrapolation capabilities. After instruction tuning, RedLLM
achieves comparable and even better results on various downstream tasks while
enjoying substantially better inference efficiency. We hope our findings could
inspire more efforts on re-examining RedLLM, unlocking its potential for
developing powerful and efficient LLMs.

</details>


### [124] [Evontree: Ontology Rule-Guided Self-Evolution of Large Language Models](https://arxiv.org/abs/2510.26683)
*Mingchen Tu,Zhiqiang Liu,Juan Li,Liangyurui Liu,Junjie Wang,Lei Liang,Wen Zhang*

Main category: cs.CL

TL;DR: 提出了一种名为Evontree的新方法，通过利用少量高质量本体规则提取和优化LLM中的领域知识，无需大量外部数据，实现了医疗问答等低资源场景下的大模型高效适应，效果显著。


<details>
  <summary>Details</summary>
Motivation: 在医疗等数据敏感领域，高质量、领域专用的数据难以获取，导致大模型难以有效适应专业任务。而领域专家已经积累了结构化的本体规则，如何充分利用这些规则提升LLM在专业领域的表现，是亟需解决的问题。

Method: 提出Evontree框架：无需大规模外部数据，仅依靠小规模高质量本体规则，分三步进行：1）从预训练模型中抽取领域知识本体；2）借助两条核心本体规则检测知识不一致并修正；3）通过自蒸馏微调加固优化后的知识。

Result: 在医疗问答基线上，Evontree方法应用于Llama3-8B-Instruct和Med42-v2模型，准确率提升最高达3.7%，全面超越了原始模型及主流有监督微调方法。

Conclusion: Evontree能在无需大量标注数据的情况下，有效提取并增强LLM中的专业知识，实现低资源场景下的领域适应，验证了其实用性、有效性和高鲁棒性。

Abstract: Large language models (LLMs) have demonstrated exceptional capabilities
across multiple domains by leveraging massive pre-training and curated
fine-tuning data. However, in data-sensitive fields such as healthcare, the
lack of high-quality, domain-specific training corpus hinders LLMs' adaptation
for specialized applications. Meanwhile, domain experts have distilled domain
wisdom into ontology rules, which formalize relationships among concepts and
ensure the integrity of knowledge management repositories. Viewing LLMs as
implicit repositories of human knowledge, we propose Evontree, a novel
framework that leverages a small set of high-quality ontology rules to
systematically extract, validate, and enhance domain knowledge within LLMs,
without requiring extensive external datasets. Specifically, Evontree extracts
domain ontology from raw models, detects inconsistencies using two core
ontology rules, and reinforces the refined knowledge via self-distilled
fine-tuning. Extensive experiments on medical QA benchmarks with
Llama3-8B-Instruct and Med42-v2 demonstrate consistent outperformance over both
unmodified models and leading supervised baselines, achieving up to a 3.7%
improvement in accuracy. These results confirm the effectiveness, efficiency,
and robustness of our approach for low-resource domain adaptation of LLMs.

</details>


### [125] [Kimi Linear: An Expressive, Efficient Attention Architecture](https://arxiv.org/abs/2510.26692)
*Kimi Team,Yu Zhang,Zongyu Lin,Xingcheng Yao,Jiaxi Hu,Fanqing Meng,Chengyin Liu,Xin Men,Songlin Yang,Zhiyuan Li,Wentao Li,Enzhe Lu,Weizhou Liu,Yanru Chen,Weixin Xu,Longhui Yu,Yejie Wang,Yu Fan,Longguang Zhong,Enming Yuan,Dehao Zhang,Yizhi Zhang,T. Y. Liu,Haiming Wang,Shengjun Fang,Weiran He,Shaowei Liu,Yiwei Li,Jianlin Su,Jiezhong Qiu,Bo Pang,Junjie Yan,Zhejun Jiang,Weixiao Huang,Bohong Yin,Jiacheng You,Chu Wei,Zhengtao Wang,Chao Hong,Yutian Chen,Guanduo Chen,Yucheng Wang,Huabin Zheng,Feng Wang,Yibo Liu,Mengnan Dong,Zheng Zhang,Siyuan Pan,Wenhao Wu,Yuhao Wu,Longyu Guan,Jiawen Tao,Guohong Fu,Xinran Xu,Yuzhi Wang,Guokun Lai,Yuxin Wu,Xinyu Zhou,Zhilin Yang,Yulun Du*

Main category: cs.CL

TL;DR: 本文提出Kimi Linear混合线性注意力架构，在多种任务与场景下首次公平对比中优于全量注意力方法，并大幅提升推理效率和内存使用。


<details>
  <summary>Details</summary>
Motivation: 现有全量注意力机制虽表现优异，但在大规模与长文本任务上的计算和内存成本极高。线性注意力虽高效，但精度往往不及全量注意力。作者致力于开发兼具性能与效率的新型注意力架构。

Method: 作者提出Kimi Delta Attention（KDA），扩展了Gated DeltaNet，并引入更细粒度的门控机制优化有限RNN状态记忆。结合特殊的Diagonal-Plus-Low-Rank（DPLR）转移矩阵的分块算法以提升硬件效率。模型采用KDA与多头潜在注意力（MLA）层混合架构并进行大规模预训练。

Result: Kimi Linear在相同训练配方下，全面优于全量MLA模型，在所有评测任务中表现更好。KV缓存用量降低75%，解码速度提升至6倍（百万级上下文）。

Conclusion: Kimi Linear可作为全量注意力架构的高效替代方案，特别适用于长输入输出任务。相关代码与模型已开源，助力后续研究。

Abstract: We introduce Kimi Linear, a hybrid linear attention architecture that, for
the first time, outperforms full attention under fair comparisons across
various scenarios -- including short-context, long-context, and reinforcement
learning (RL) scaling regimes. At its core lies Kimi Delta Attention (KDA), an
expressive linear attention module that extends Gated DeltaNet with a
finer-grained gating mechanism, enabling more effective use of limited
finite-state RNN memory. Our bespoke chunkwise algorithm achieves high hardware
efficiency through a specialized variant of the Diagonal-Plus-Low-Rank (DPLR)
transition matrices, which substantially reduces computation compared to the
general DPLR formulation while remaining more consistent with the classical
delta rule.
  We pretrain a Kimi Linear model with 3B activated parameters and 48B total
parameters, based on a layerwise hybrid of KDA and Multi-Head Latent Attention
(MLA). Our experiments show that with an identical training recipe, Kimi Linear
outperforms full MLA with a sizeable margin across all evaluated tasks, while
reducing KV cache usage by up to 75% and achieving up to 6 times decoding
throughput for a 1M context. These results demonstrate that Kimi Linear can be
a drop-in replacement for full attention architectures with superior
performance and efficiency, including tasks with longer input and output
lengths.
  To support further research, we open-source the KDA kernel and vLLM
implementations, and release the pre-trained and instruction-tuned model
checkpoints.

</details>


### [126] [The End of Manual Decoding: Towards Truly End-to-End Language Models](https://arxiv.org/abs/2510.26697)
*Zhichao Wang,Dongyang Ma,Xinting Huang,Deng Cai,Tian Lan,Jiahao Xu,Haitao Mi,Xiaoying Tang,Yan Wang*

Main category: cs.CL

TL;DR: 本文提出了一种名为AutoDeco的新型架构，实现了真正端到端（end-to-end）的语言模型解码控制，显著提升了解码性能和灵活性。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型（LLMs）虽然被称为"端到端"，但实际上依赖于需要人工调参（如temperature、top-p）的不可微解码过程，缺乏真正自动化和自适应的能力。

Method: 作者在标准transformer的基础上加入了轻量级预测头，使模型在每一步动态预测当前上下文下的temperature和top-p参数，同时生成下一个token的logits，实现在一次前向传播中自动调节采样策略。

Result: 在八个基准测试中，AutoDeco不仅明显优于原有的静态解码策略，还达到了通过"黑盒"方式在测试集上极致调优所得基准的可比表现。

Conclusion: AutoDeco使得LLM模型具有根据自然语言指令实时调整解码策略的能力，为更加可控和互动的生成模型开辟了新方向。

Abstract: The "end-to-end" label for LLMs is a misnomer. In practice, they depend on a
non-differentiable decoding process that requires laborious, hand-tuning of
hyperparameters like temperature and top-p. This paper introduces AutoDeco, a
novel architecture that enables truly "end-to-end" generation by learning to
control its own decoding strategy. We augment the standard transformer with
lightweight heads that, at each step, dynamically predict context-specific
temperature and top-p values alongside the next-token logits. This approach
transforms decoding into a parametric, token-level process, allowing the model
to self-regulate its sampling strategy within a single forward pass.
  Through extensive experiments on eight benchmarks, we demonstrate that
AutoDeco not only significantly outperforms default decoding strategies but
also achieves performance comparable to an oracle-tuned baseline derived from
"hacking the test set"-a practical upper bound for any static method.
Crucially, we uncover an emergent capability for instruction-based decoding
control: the model learns to interpret natural language commands (e.g.,
"generate with low randomness") and adjusts its predicted temperature and top-p
on a token-by-token basis, opening a new paradigm for steerable and interactive
LLM decoding.

</details>


### [127] [Value Drifts: Tracing Value Alignment During LLM Post-Training](https://arxiv.org/abs/2510.26707)
*Mehar Bhatia,Shravan Nayak,Gaurav Kamath,Marius Mosbach,Karolina Stańczak,Vered Shwartz,Siva Reddy*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLM）在后训练过程中其价值观对齐的形成与动态，系统分析了不同算法与数据集对价值观对齐的影响。


<details>
  <summary>Details</summary>
Motivation: 目前大多数研究关注模型完全训练后的价值观对齐评估，忽视了模型在训练过程中如何学习和内化人类价值观的动态过程。由于LLM逐渐参与现实中的决策，理解和改善其价值观对齐环节愈发重要。

Method: 本文分别对不同规模的Llama-3和Qwen-3模型，在主流的有监督微调（SFT）、偏好优化算法及数据集上进行实验，对比分析了SFT和偏好优化阶段对模型价值观的不同影响；同时利用可控的合成偏好数据集，研究不同偏好优化算法对同一偏好数据价值观对齐结果的差异。

Result: 研究发现，SFT阶段是模型价值观奠定的关键，后续的偏好优化阶段通常不会显著改变模型的价值观。另外，不同偏好优化算法即使在相同数据下也会导向不同的价值观对齐结果。

Conclusion: 本文揭示了价值观对齐在后训练过程中的形成规律，对数据策划、模型与算法选择提供了具体建议，对提升模型符合人类价值观具有重要指导意义。

Abstract: As LLMs occupy an increasingly important role in society, they are more and
more confronted with questions that require them not only to draw on their
general knowledge but also to align with certain human value systems.
Therefore, studying the alignment of LLMs with human values has become a
crucial field of inquiry. Prior work, however, mostly focuses on evaluating the
alignment of fully trained models, overlooking the training dynamics by which
models learn to express human values. In this work, we investigate how and at
which stage value alignment arises during the course of a model's
post-training. Our analysis disentangles the effects of post-training
algorithms and datasets, measuring both the magnitude and time of value drifts
during training. Experimenting with Llama-3 and Qwen-3 models of different
sizes and popular supervised fine-tuning (SFT) and preference optimization
datasets and algorithms, we find that the SFT phase generally establishes a
model's values, and subsequent preference optimization rarely re-aligns these
values. Furthermore, using a synthetic preference dataset that enables
controlled manipulation of values, we find that different preference
optimization algorithms lead to different value alignment outcomes, even when
preference data is held constant. Our findings provide actionable insights into
how values are learned during post-training and help to inform data curation,
as well as the selection of models and algorithms for preference optimization
to improve model alignment to human values.

</details>


### [128] [AMO-Bench: Large Language Models Still Struggle in High School Math Competitions](https://arxiv.org/abs/2510.26768)
*Shengnan An,Xunliang Cai,Xuezhi Cao,Xiaoyu Li,Yehao Lin,Junlin Liu,Xinxuan Lv,Dan Ma,Xuanlin Wang,Ziwen Wang,Shuang Zhou*

Main category: cs.CL

TL;DR: AMO-Bench 是一个全新的人类精心设计的高难度数学推理测试集，用于评估大语言模型（LLMs）的数学能力。即使表现最好的模型在该基准上也只有 52.4% 的准确率，远未达到人类顶级水平。


<details>
  <summary>Details</summary>
Motivation: 随着现有数学竞赛（如 AIME24/25）题库对主流 LLMs 的测评效力下降，顶级模型逐步出现性能饱和。这促使作者开发更具挑战性的新基准，以推动 LLMs 的数学推理研究前沿。

Method: AMO-Bench 收录了 50 道全新、难度达到国际数学奥林匹克（IMO）及以上的原创题，这些题目都经过专家交叉验证，排除公开题库数据影响，只要求提交最终答案以便自动化批改。

Result: 对 26 个主流 LLMs 在 AMO-Bench 上的实验显示，即使是表现最好的模型，准确率也只有 52.4%，大部分模型低于 40%。

Conclusion: 当前大模型在高级数学推理上还存在很大提升空间，AMO-Bench 的发布将为促进 LLMs 推理能力研究提供重要工具和动力。

Abstract: We present AMO-Bench, an Advanced Mathematical reasoning benchmark with
Olympiad level or even higher difficulty, comprising 50 human-crafted problems.
Existing benchmarks have widely leveraged high school math competitions for
evaluating mathematical reasoning capabilities of large language models (LLMs).
However, many existing math competitions are becoming less effective for
assessing top-tier LLMs due to performance saturation (e.g., AIME24/25). To
address this, AMO-Bench introduces more rigorous challenges by ensuring all 50
problems are (1) cross-validated by experts to meet at least the International
Mathematical Olympiad (IMO) difficulty standards, and (2) entirely original
problems to prevent potential performance leakages from data memorization.
Moreover, each problem in AMO-Bench requires only a final answer rather than a
proof, enabling automatic and robust grading for evaluation. Experimental
results across 26 LLMs on AMO-Bench show that even the best-performing model
achieves only 52.4% accuracy on AMO-Bench, with most LLMs scoring below 40%.
Beyond these poor performances, our further analysis reveals a promising
scaling trend with increasing test-time compute on AMO-Bench. These results
highlight the significant room for improving the mathematical reasoning in
current LLMs. We release AMO-Bench to facilitate further research into
advancing the reasoning abilities of language models.
https://amo-bench.github.io/

</details>


### [129] [Gistify! Codebase-Level Understanding via Runtime Execution](https://arxiv.org/abs/2510.26790)
*Hyunji Lee,Minseon Kim,Chinmay Singh,Matheus Pereira,Atharv Sonwane,Isadora White,Elias Stengel-Eskin,Mohit Bansal,Zhengyan Shi,Alessandro Sordoni,Marc-Alexandre Côté,Xingdi Yuan,Lucas Caccia*

Main category: cs.CL

TL;DR: 本文提出了一种新的用于评估编码大模型（LLM）能力的任务Gistify，需要模型在给定一个完整代码库和入口点的情况下，生成能够实现同等功能的最小化、独立可运行文件。现有主流模型对此任务表现不佳。


<details>
  <summary>Details</summary>
Motivation: 随着编码型智能体在大型代码库中的应用增多，需要自动化、具有挑战性的全代码库级评测方法，以检验模型的真正理解和代码抽象能力。现有评测方法无法有效测试模型对复杂代码结构和执行流程的掌握。

Method: 设计名为Gistify的新评测任务：给模型完整代码库及一个执行入口（如Python命令），要求其提炼核心功能，生成仅含必要代码的独立文件，其输出与原代码库一致。该任务考查模型结构理解与大规模代码重组能力。通过实验评估主流编码大模型（如ChatGPT等）在该任务下的表现。

Result: 实验显示，当前最先进的编码LLM在Gistify任务上整体表现较弱，尤其在执行路径较长或逻辑复杂度高的任务中成功率很低。

Conclusion: Gistify为评估代码大模型提出了更高标准，揭示了其在结构理解与关键代码提取方面的局限性，并为未来模型能力提升和评估方法创新指明了方向。

Abstract: As coding agents are increasingly deployed in large codebases, the need to
automatically design challenging, codebase-level evaluation is central. We
propose Gistify, a task where a coding LLM must create a single, minimal,
self-contained file that can reproduce a specific functionality of a codebase.
The coding LLM is given full access to a codebase along with a specific
entrypoint (e.g., a python command), and the generated file must replicate the
output of the same command ran under the full codebase, while containing only
the essential components necessary to execute the provided command. Success on
Gistify requires both structural understanding of the codebase, accurate
modeling of its execution flow as well as the ability to produce potentially
large code patches. Our findings show that current state-of-the-art models
struggle to reliably solve Gistify tasks, especially ones with long executions
traces.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [130] [Debate2Create: Robot Co-design via Large Language Model Debates](https://arxiv.org/abs/2510.25850)
*Kevin Qiu,Marek Cygan*

Main category: cs.RO

TL;DR: 本文提出了一种基于大型语言模型（LLM）代理辩论的机器人共同设计（结构与控制）框架，实现了更优且多样的机器人设计。


<details>
  <summary>Details</summary>
Motivation: 机器人结构与控制的联合自动化设计很难，因为设计空间庞大且“身体-行为”高度耦合，现有方法难以高效探索和优化。

Method: 作者提出D2C（Debate2Create）框架。该框架中有两个代理：一个提出机器人结构修改，另一个为该结构设计奖励函数。多名虚拟评委基于仿真结果对二者的组合进行评价与反馈，多轮“辩论”后，方案不断优化产生更有效、多样的机器人设计。

Result: 在四足机器人移动基准测试上，D2C发现的设计比默认设计能多行驶73%的距离，并且生成了多样化的机器人结构，即使没有明确要求多样性。

Conclusion: 基于LLM代理辩论并结合仿真反馈的自动设计方法，不仅提高了机器人设计效果，还显示出生成多样方案的潜力，是自动机器人联合设计的有前景新路径。

Abstract: Automating the co-design of a robot's morphology and control is a
long-standing challenge due to the vast design space and the tight coupling
between body and behavior. We introduce Debate2Create (D2C), a framework in
which large language model (LLM) agents engage in a structured dialectical
debate to jointly optimize a robot's design and its reward function. In each
round, a design agent proposes targeted morphological modifications, and a
control agent devises a reward function tailored to exploit the new design. A
panel of pluralistic judges then evaluates the design-control pair in
simulation and provides feedback that guides the next round of debate. Through
iterative debates, the agents progressively refine their proposals, producing
increasingly effective robot designs. Notably, D2C yields diverse and
specialized morphologies despite no explicit diversity objective. On a
quadruped locomotion benchmark, D2C discovers designs that travel 73% farther
than the default, demonstrating that structured LLM-based debate can serve as a
powerful mechanism for emergent robot co-design. Our results suggest that
multi-agent debate, when coupled with physics-grounded feedback, is a promising
new paradigm for automated robot design.

</details>


### [131] [Risk-Aware Safety Filters with Poisson Safety Functions and Laplace Guidance Fields](https://arxiv.org/abs/2510.25913)
*Gilbert Bahati,Ryan M. Bena,Meg Wilkinson,Pol Mestres,Ryan K. Cosner,Aaron D. Ames*

Main category: cs.RO

TL;DR: 本论文提出一种结合环境语义理解和风险感知的安全过滤器，用于提升机器人在复杂环境中的安全导航能力。


<details>
  <summary>Details</summary>
Motivation: 机器人在真实环境中导航时需要理解环境中的语义信息，尤其是环境中特定区域或障碍物所带来的风险，以便选择安全的行动路径。现有方法往往难以对不同风险级别的障碍物做出差异化反应，缺乏风险感知机制。

Method: 论文分两步：首先，利用Poisson方程的Dirichlet问题，构建一个安全函数，将安全区域表示为其0超水平集；其次，解Laplace方程的Dirichlet问题，通过可调边界条件生成对障碍物有不同警戒等级的引导场。最终，将安全函数与引导场结合，形成带有风险权重的安全约束，合成可感知风险的安全过滤器。该方法基于环境的语义理解和各区域风险级别，实现安全保障并优先规避高风险障碍物。

Result: 方法在仿真环境中进行了验证，结果显示可以将预先知道的障碍物风险有效融入安全过滤器，生成具备风险感知能力的安全导航行为。

Conclusion: 本文方法能够使机器人系统在理解环境语义和障碍物风险的基础上，提高安全导航的可靠性，尤其是在高风险区域附近可以更谨慎地采取避障行动。

Abstract: Robotic systems navigating in real-world settings require a semantic
understanding of their environment to properly determine safe actions. This
work aims to develop the mathematical underpinnings of such a
representation--specifically, the goal is to develop safety filters that are
risk-aware. To this end, we take a two step approach: encoding an understanding
of the environment via Poisson's equation, and associated risk via Laplace
guidance fields. That is, we first solve a Dirichlet problem for Poisson's
equation to generate a safety function that encodes system safety as its
0-superlevel set. We then separately solve a Dirichlet problem for Laplace's
equation to synthesize a safe \textit{guidance field} that encodes variable
levels of caution around obstacles -- by enforcing a tunable flux boundary
condition. The safety function and guidance fields are then combined to define
a safety constraint and used to synthesize a risk-aware safety filter which,
given a semantic understanding of an environment with associated risk levels of
environmental features, guarantees safety while prioritizing avoidance of
higher risk obstacles. We demonstrate this method in simulation and discuss how
\textit{a priori} understandings of obstacle risk can be directly incorporated
into the safety filter to generate safe behaviors that are risk-aware.

</details>


### [132] [Curvature-Aware Calibration of Tactile Sensors for Accurate Force Estimation on Non-Planar Surfaces](https://arxiv.org/abs/2510.25965)
*Luoyan Zhong,Heather Jin Hee Kim,Dylan P. Losey,Cara M. Nunez*

Main category: cs.RO

TL;DR: 这篇论文提出了一种用于柔性触觉传感器的曲率感知校准方法，解决了装配到弯曲或不规则表面后精度下降的问题。通过结合神经网络对曲率进行预测，实现了在不同曲率物体上的精确力估算，提升了传感器在实际应用中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有柔性触觉传感器多在平面条件下校准，装配在弯曲表面后精度和一致性会降低，影响其在机器人抓手、假肢等实际场景的可靠性和适用性。因此需要开发能兼容曲面装配的校准方案。

Method: 提出一种针对常见电阻型触觉传感器的校准模型，结合多层感知机（MLP）神经网络，通过在无载荷时的输出预测局部曲率，并进行针对性的曲率感知校准。方法在5种日常物品（不同曲率）上进行力和曲率测试验证。

Result: 神经网络对曲率的预测R2达0.91。经曲率感知校准后，传感器无论装配在不同曲率表面下，力测量依然准确且一致；而传统的平面校准会随着曲率增加而低估施加的力。

Conclusion: 曲率感知校准方法显著提升了柔性触觉传感器在复杂曲面上的精度、一致性与可靠性，有助于其在实际器械和机器人等应用场景中的广泛部署。

Abstract: Flexible tactile sensors are increasingly used in real-world applications
such as robotic grippers, prosthetic hands, wearable gloves, and assistive
devices, where they need to conform to curved and irregular surfaces. However,
most existing tactile sensors are calibrated only on flat substrates, and their
accuracy and consistency degrade once mounted on curved geometries. This
limitation restricts their reliability in practical use. To address this
challenge, we develop a calibration model for a widely used resistive tactile
sensor design that enables accurate force estimation on one-dimensional curved
surfaces. We then train a neural network (a multilayer perceptron) to predict
local curvature from baseline sensor outputs recorded under no applied load,
achieving an R2 score of 0.91. The proposed approach is validated on five daily
objects with varying curvatures under forces from 2 N to 8 N. Results show that
the curvature-aware calibration maintains consistent force accuracy across all
surfaces, while flat-surface calibration underestimates force as curvature
increases. Our results demonstrate that curvature-aware modeling improves the
accuracy, consistency, and reliability of flexible tactile sensors, enabling
dependable performance across real-world applications.

</details>


### [133] [A New Type of Axis-Angle Attitude Control Law for Rotational Systems: Synthesis, Analysis, and Experiments](https://arxiv.org/abs/2510.25985)
*Francisco M. F. R. Gonçalves,Ryan M. Bena,Néstor O. Pérez-Arancibia*

Main category: cs.RO

TL;DR: 本论文提出了一种新的基于轴-角的姿态控制方法，用于提升旋转系统（如卫星和无人机）的姿态控制性能，并通过模拟和实际飞行验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于四元数的姿态控制方法存在闭环唯一平衡点无法保证、对大旋转误差比例控制效果差等缺点，因此需要一种新的更有效的控制方法。

Method: 提出了一种利用姿态误差的欧拉轴-角信息的新型姿态控制律，并通过构造严格的Lyapunov函数，证明了所设计控制律下闭环系统唯一平衡点的渐近稳定性。方法通过数值仿真和无人机实飞验证了性能效果。

Result: 仿真和多次真实无人机翻滚回收测试均显示，基于轴-角的新控制律在稳定时间等控制性能上优于传统高性能四元数控制器。

Conclusion: 新提出的轴-角控制方法能够保证姿态闭环唯一平衡点的渐近稳定性，实际表现也明显优于四元数方法，为高可靠性的刚体旋转系统姿态控制提供了更优方案。

Abstract: Over the past few decades, continuous quaternion-based attitude control has
been proven highly effective for driving rotational systems that can be modeled
as rigid bodies, such as satellites and drones. However, methods rooted in this
approach do not enforce the existence of a unique closed-loop (CL) equilibrium
attitude-error quaternion (AEQ); and, for rotational errors about the
attitude-error Euler axis larger than {\pi}rad, their proportional-control
effect diminishes as the system state moves away from the stable equilibrium of
the CL rotational dynamics. In this paper, we introduce a new type of attitude
control law that more effectively leverages the attitude-error Euler axis-angle
information to guarantee a unique CL equilibrium AEQ and to provide greater
flexibility in the use of proportional-control efforts. Furthermore, using two
different control laws as examples-through the construction of a strict
Lyapunov function for the CL dynamics-we demonstrate that the resulting unique
equilibrium of the CL rotational system can be enforced to be uniformly
asymptotically stable. To assess and demonstrate the functionality and
performance of the proposed approach, we performed numerical simulations and
executed dozens of real-time tumble-recovery maneuvers using a small quadrotor.
These simulations and flight tests compellingly demonstrate that the proposed
axis-angle-based method achieves superior flight performance-compared with that
obtained using a high-performance quaternion-based controller-in terms of
stabilization time.

</details>


### [134] [DARTS: A Drone-Based AI-Powered Real-Time Traffic Incident Detection System](https://arxiv.org/abs/2510.26004)
*Bai Li,Achilleas Kourtellis,Rong Cao,Joseph Post,Brian Porter,Yu Zhang*

Main category: cs.RO

TL;DR: 本论文提出了一种基于无人机和人工智能的实时交通事故检测系统DARTS，在准确率、响应速度和适应性方面显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前交通事故检测方法依赖密集的基础设施或高普及率设备，限制了在事故高发地和偏远地区的应用，并且检测与核查环节分离，效率不高。

Method: 该方法开发了DARTS系统，利用无人机的高机动性和空中视角进行自适应巡查，结合热成像提升低能见度环境下的检测效果并保护隐私，并嵌入轻量级深度学习框架实现实时车辆轨迹提取与事故识别。系统支持在线验证、事故严重性评估和拥堵传播监测。

Result: 在自采数据集上，DARTS的事故检测准确率达到99%；实地测试显示，比地方管理中心提前12分钟发现事故，并能监测由事故引发的拥堵。

Conclusion: DARTS展示了更灵活、集成度更高的实时交通事故检测能力，具备良好的适应性和可扩展性，对于提升交通管理的效率与响应速度、减少拥堵和二次事故风险具有重要意义，尤其适合资源受限或偏远场景。

Abstract: Rapid and reliable incident detection is critical for reducing crash-related
fatalities, injuries, and congestion. However, conventional methods, such as
closed-circuit television, dashcam footage, and sensor-based detection,
separate detection from verification, suffer from limited flexibility, and
require dense infrastructure or high penetration rates, restricting
adaptability and scalability to shifting incident hotspots. To overcome these
challenges, we developed DARTS, a drone-based, AI-powered real-time traffic
incident detection system. DARTS integrates drones' high mobility and aerial
perspective for adaptive surveillance, thermal imaging for better
low-visibility performance and privacy protection, and a lightweight deep
learning framework for real-time vehicle trajectory extraction and incident
detection. The system achieved 99% detection accuracy on a self-collected
dataset and supports simultaneous online visual verification, severity
assessment, and incident-induced congestion propagation monitoring via a
web-based interface. In a field test on Interstate 75 in Florida, DARTS
detected and verified a rear-end collision 12 minutes earlier than the local
transportation management center and monitored incident-induced congestion
propagation, suggesting potential to support faster emergency response and
enable proactive traffic control to reduce congestion and secondary crash risk.
Crucially, DARTS's flexible deployment architecture reduces dependence on
frequent physical patrols, indicating potential scalability and
cost-effectiveness for use in remote areas and resource-constrained settings.
This study presents a promising step toward a more flexible and integrated
real-time traffic incident detection system, with significant implications for
the operational efficiency and responsiveness of modern transportation
management.

</details>


### [135] [RADRON: Cooperative Localization of Ionizing Radiation Sources by MAVs with Compton Cameras](https://arxiv.org/abs/2510.26018)
*Petr Stibinger,Tomas Baca,Daniela Doubravova,Jan Rusnak,Jaroslav Solc,Jan Jakubek,Petr Stepan,Martin Saska*

Main category: cs.RO

TL;DR: 本论文提出了一种利用多架微型无人机（MAVs）协作，结合先进的轻量级康普顿相机来实时定位放射性物质的新方法。


<details>
  <summary>Details</summary>
Motivation: 当前放射性物质定位面临重量、灵敏度和效率的难题，传统检测设备体积大且响应慢，难以应用于动态和复杂环境。

Method: 本方法采用仅重40g的最先进单探测器康普顿相机，安装于微型无人机上，利用无人机集群协作，融合稀疏的康普顿相机测量数据，通过板载实时处理，实现对放射源的精准快速定位，数据还可动态反馈指导无人机运动。

Result: 经过实验证明，该方法能有效地利用多个无人机协同，最大化信息收集速度，在极少的数据下也能快速定位静态或动态的放射源。

Conclusion: 本研究展示了微型无人机携带轻型康普顿相机的巨大潜力，能实现高效、实时、动态的放射性物质定位和跟踪，突破传统设备在灵敏度、机动性和实时性上的限制。

Abstract: We present a novel approach to localizing radioactive material by cooperating
Micro Aerial Vehicles (MAVs). Our approach utilizes a state-of-the-art
single-detector Compton camera as a highly sensitive, yet miniature detector of
ionizing radiation. The detector's exceptionally low weight (40 g) opens up new
possibilities of radiation detection by a team of cooperating agile MAVs. We
propose a new fundamental concept of fusing the Compton camera measurements to
estimate the position of the radiation source in real time even from extremely
sparse measurements. The data readout and processing are performed directly
onboard and the results are used in a dynamic feedback to drive the motion of
the vehicles. The MAVs are stabilized in a tightly cooperating swarm to
maximize the information gained by the Compton cameras, rapidly locate the
radiation source, and even track a moving radiation source.

</details>


### [136] [Accelerating Real-World Overtaking in F1TENTH Racing Employing Reinforcement Learning Methods](https://arxiv.org/abs/2510.26040)
*Emily Steiner,Daniel van der Spuy,Futian Zhou,Afereti Pama,Minas Liarokapis,Henry Williams*

Main category: cs.RO

TL;DR: 本文提出了一种能够在现实和仿真环境中实现可靠超车和赛车的自主系统，并实现在标准化物理平台F1Tenth上取得明显性能提升。


<details>
  <summary>Details</summary>
Motivation: 尽管自主赛车在单圈竞速（Time-Trial）场景下有很大进步，但在实际的车对车竞速和超车任务中，现有算法表现依然有限，亟需提升其在真实复杂驾情下的可靠性和安全性。

Method: 研究设计了一种新颖的自主赛车与超车智能体，能够利用与对手交互的训练方式学习如何安全且高效地超车，并部署在F1Tenth小车平台，在真实环境中对比不同算法表现。

Result: 该系统在实际F1Tenth竞赛中，超车成功率为87%，大幅优于仅以竞速为目标训练的智能体（56%）。

Conclusion: 通过在与对手竞速的环境下进行针对性训练，自主车辆可大幅提升超车能力，对于提升自动驾驶安全性和实用性有重要意义。

Abstract: While autonomous racing performance in Time-Trial scenarios has seen
significant progress and development, autonomous wheel-to-wheel racing and
overtaking are still severely limited. These limitations are particularly
apparent in real-life driving scenarios where state-of-the-art algorithms
struggle to safely or reliably complete overtaking manoeuvres. This is
important, as reliable navigation around other vehicles is vital for safe
autonomous wheel-to-wheel racing. The F1Tenth Competition provides a useful
opportunity for developing wheel-to-wheel racing algorithms on a standardised
physical platform. The competition format makes it possible to evaluate
overtaking and wheel-to-wheel racing algorithms against the state-of-the-art.
This research presents a novel racing and overtaking agent capable of learning
to reliably navigate a track and overtake opponents in both simulation and
reality. The agent was deployed on an F1Tenth vehicle and competed against
opponents running varying competitive algorithms in the real world. The results
demonstrate that the agent's training against opponents enables deliberate
overtaking behaviours with an overtaking rate of 87% compared 56% for an agent
trained just to race.

</details>


### [137] [Morphology-Aware Graph Reinforcement Learning for Tensegrity Robot Locomotion](https://arxiv.org/abs/2510.26067)
*Chi Zhang,Mingrui Li,Wenzhe Tong,Xiaonan Huang*

Main category: cs.RO

TL;DR: 提出一种将图神经网络（GNN）与强化学习算法SAC结合的结构感知控制方法，显著提升了tensegrity机器人行走的学习效率与稳定性，并实现了从仿真到真实机器的零调参迁移。


<details>
  <summary>Details</summary>
Motivation: Tensegrity机器人兼具刚性杆件和弹性绳索，具有优越的坚固性与可展开性，但其运动控制难以高效实现，主要挑战来源于系统的欠驱动性和强耦合动力学。因此，亟需找到一种方法，有效捕捉系统部件间的复杂关系并简化控制问题。

Method: 本文提出以机器人物理结构为基础，将其拓扑结构表示为图，并引入图神经网络（GNN）嵌入到软行为者-评论家（SAC）强化学习算法之中，构建结构感知的控制策略。通过GNN替换传统MLP网络，提升了对各部件耦合效应的建模能力。

Result: 在3杆tensegrity实体机器人上，进行了直线跟踪和双向转向等三种运动基元实验。结果表明，所提出的方法在采样效率、对噪声与弹性变化的鲁棒性以及轨迹精度上均优于MLP策略，且无需调参即可从仿真直接迁移到硬件，表现出色。

Conclusion: 将结构先验信息用GNN编码进强化学习策略，能显著提升tensegrity机器人控制的样本效率、鲁棒性和真实部署能力，表明结构感知强化学习在复杂机器人控制中具有广阔应用前景。

Abstract: Tensegrity robots combine rigid rods and elastic cables, offering high
resilience and deployability but posing major challenges for locomotion control
due to their underactuated and highly coupled dynamics. This paper introduces a
morphology-aware reinforcement learning framework that integrates a graph
neural network (GNN) into the Soft Actor-Critic (SAC) algorithm. By
representing the robot's physical topology as a graph, the proposed GNN-based
policy captures coupling among components, enabling faster and more stable
learning than conventional multilayer perceptron (MLP) policies. The method is
validated on a physical 3-bar tensegrity robot across three locomotion
primitives, including straight-line tracking and bidirectional turning. It
shows superior sample efficiency, robustness to noise and stiffness variations,
and improved trajectory accuracy. Notably, the learned policies transfer
directly from simulation to hardware without fine-tuning, achieving stable
real-world locomotion. These results demonstrate the advantages of
incorporating structural priors into reinforcement learning for tensegrity
robot control.

</details>


### [138] [I don't Want You to Die: A Shared Responsibility Framework for Safeguarding Child-Robot Companionship](https://arxiv.org/abs/2510.26080)
*Fan Yang,Renkai Ma,Yaxin Hu,Michael Rodgers,Lingyao Li*

Main category: cs.RO

TL;DR: 本研究探讨了儿童与社交机器人（如Moxie）建立情感纽带后，因服务中止产生的情感困扰及责任归属问题。通过对美国72名参与者的定性调查，发现公众认为责任应由厂商、家长、开发者和政府共同承担，但不同政治立场和是否为家长影响责任归属的看法。最后提出了分担责任的框架以减少相关情感伤害。


<details>
  <summary>Details</summary>
Motivation: 社交机器人广泛用于儿童社交和情感发展，但服务突然中断会深刻影响儿童心理，相关责任归属、规制和保护措施尚不明朗，急需研究厘清参与方责任与前瞻性政策建议。

Method: 以Moxie机器人中止为案例，通过定性问卷调查美国72名参与者，分析他们对责任归属、服务持续应否及相关政策建议的看法，并根据调查结果归纳责任分担框架。

Result: 大众普遍认为机器人公司、家长、政府、开发者均有作为责任方；对服务延续是否应当分歧鲜明，支持者提倡多元延续方案，反对者关注商业现实及依赖风险。责任归属认知受到受访者政治立场及是否为家长影响。

Conclusion: 论文构建了儿童-机器人陪伴中止情境下的责任分担实证框架，并提出以政策和设计预案缓冲服务终止带来的儿童情感伤害，对后续机器人产品设计和相关政策制定具有重要参考价值。

Abstract: Social robots like Moxie are designed to form strong emotional bonds with
children, but their abrupt discontinuation can cause significant struggles and
distress to children. When these services end, the resulting harm raises
complex questions of who bears responsibility when children's emotional bonds
are broken. Using the Moxie shutdown as a case study through a qualitative
survey of 72 U.S. participants, our findings show that the responsibility is
viewed as a shared duty across the robot company, parents, developers, and
government. However, these attributions varied by political ideology and
parental status of whether they have children. Participants' perceptions of
whether the robot service should continue are highly polarized; supporters
propose technical, financial, and governmental pathways for continuity, while
opponents cite business realities and risks of unhealthy emotional dependency.
Ultimately, this research contributes an empirically grounded shared
responsibility framework for safeguarding child-robot companionship by
detailing how accountability is distributed and contested, informing concrete
design and policy implications to mitigate the emotional harm of robot
discontinuation.

</details>


### [139] [Beyond the Uncanny Valley: A Mixed-Method Investigation of Anthropomorphism in Protective Responses to Robot Abuse](https://arxiv.org/abs/2510.26082)
*Fan Yang,Lingyao Li,Yaxin Hu,Michael Rodgers,Renkai Ma*

Main category: cs.RO

TL;DR: 研究探讨机器人人形化程度如何影响人们在面对机器人被虐待时的保护反应，发现并非越像人越受保护，反而中等人形化（最“怪异”的机器人）引发了最强烈的愤怒和道德关注。


<details>
  <summary>Details</summary>
Motivation: 随着人形特征机器人的普及，人们对机器人的道德感知和互动方式受到影响。本研究旨在理解不同人形化水平的机器人被虐待时，人类道德保护反应的变化，挑战CASA理论与恐怖谷假说在人机伦理领域的适用性。

Method: 通过实验招募201名参与者，观看三种人形化程度（低：蜘蛛型；中：两足型；高：类人型）的机器人遭受虐待的视频。综合使用自我报告问卷（情绪与怪异感）、自动面部表情生理数据和质性访谈等多模态方法分析反应。

Result: 结果显示：保护反应不是线性的，中等人形化的“两足”机器人最引发“恐怖谷”效应和生理愤怒表达。两足型和类人型机器人引发的愤怒和愧疚自评高于蜘蛛型。访谈显示，人形化越高，道德评判从“财产破坏”转向“谴责施虐者”，对机器人治理的建议也随之扩大。

Conclusion: 恐怖谷现象并未削弱对机器人的道德关怀，反而增强保护冲动。此发现对未来机器人设计、政策制定与法律框架具有重要启示意义。

Abstract: Robots with anthropomorphic features are increasingly shaping how humans
perceive and morally engage with them. Our research investigates how different
levels of anthropomorphism influence protective responses to robot abuse,
extending the Computers as Social Actors (CASA) and uncanny valley theories
into a moral domain. In an experiment, we invite 201 participants to view
videos depicting abuse toward a robot with low (Spider), moderate (Two-Foot),
or high (Humanoid) anthropomorphism. To provide a comprehensive analysis, we
triangulate three modalities: self-report surveys measuring emotions and
uncanniness, physiological data from automated facial expression analysis, and
qualitative reflections. Findings indicate that protective responses are not
linear. The moderately anthropomorphic Two-Foot robot, rated highest in
eeriness and "spine-tingling" sensations consistent with the uncanny valley,
elicited the strongest physiological anger expressions. Self-reported anger and
guilt are significantly higher for both the Two-Foot and Humanoid robots
compared to the Spider. Qualitative findings further reveal that as
anthropomorphism increases, moral reasoning shifts from technical assessments
of property damage to condemnation of the abuser's character, while governance
proposals expand from property law to calls for quasi-animal rights and broader
societal responsibility. These results suggest that the uncanny valley does not
dampen moral concern but paradoxically heightens protective impulses, offering
critical implications for robot design, policy, and future legal frameworks.

</details>


### [140] [Embodied Intelligence for Advanced Bioinspired Microrobotics: Examples and Insights](https://arxiv.org/abs/2510.26132)
*Nestor O. Perez-Arancibia*

Main category: cs.RO

TL;DR: 本文探讨了“具身智能”（Embodied Intelligence, EI）如何通过结构与行为的协同设计，提升毫米到厘米级微型机器人的智能行为表现。作者通过多个自研机器人平台，展示了EI推动下的系统设计与传统分离式架构的差异。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人设计通常将传感、计算和驱动分离，难以在微型机器人上实现高效、智能的行为。作者提出以EI为设计核心，将物理结构、材料属性、环境交互融入微型机器人设计，以突破现有限制。

Method: 采用共设计（co-design）理念，结构与行为同时、相互依赖地开发。通过多台自主开发的微型机器人（如Bee++、RoBeetle等），采用将传感、控制与驱动机制巧妙嵌入机器人本体物理结构中，探索结构动力学与物理交互带来的智能行为涌现。

Result: 展示的若干机器人能够在无需复杂外部控制或大量计算的情况下，通过本身结构和与环境的相互作用，实现包括反馈调节、决策逻辑、传感和智能驱动在内的智能行为，表现出强鲁棒性和可扩展性。

Conclusion: 共设计不仅是满足物理约束下的一种优化方法，更是实现具身智能的关键途径，为毫米至厘米级机器人提供了一种较传统分离式控制更稳健、可扩展的设计范式。

Abstract: The term embodied intelligence (EI) conveys the notion that body morphology,
material properties, interaction with the environment, and control strategies
can be purposefully integrated into the process of robotic design to generate
intelligent behavior; in particular, locomotion and navigation. In this paper,
we discuss EI as a design principle for advanced microrobotics, with a
particular focus on co-design -- the simultaneous and interdependent
development of physical structure and behavioral function. To illustrate the
contrast between EI-inspired systems and traditional architectures that
decouple sensing, computation, and actuation, we present and discuss a
collection of robots developed by the author and his team at the Autonomous
Microrobotic Systems Laboratory (AMSL). These robots exhibit intelligent
behavior that emerges from their structural dynamics and the physical
interaction between their components and with the environment. Platforms such
as the Bee++, RoBeetle, SMALLBug, SMARTI, WaterStrider, VLEIBot+, and FRISSHBot
exemplify how feedback loops, decision logics, sensing mechanisms, and smart
actuation strategies can be embedded into the physical properties of the
robotic system itself. Along these lines, we contend that co-design is not only
a method for empirical optimization under constraints, but also an enabler of
EI, offering a scalable and robust alternative to classical control for
robotics at the mm-to-cm-scale.

</details>


### [141] [Kinodynamic Task and Motion Planning using VLM-guided and Interleaved Sampling](https://arxiv.org/abs/2510.26139)
*Minseo Kwon,Young J. Kim*

Main category: cs.RO

TL;DR: 本文提出了一种新型结合视觉语言模型（VLM）指导的任务与运动规划（TAMP）方法，显著提升复杂任务的成功率与规划效率。


<details>
  <summary>Details</summary>
Motivation: 现有的TAMP方法在处理长时序任务时，由于运动采样量大，计算开销高。同时，LLMs虽具备常识推理能力，但缺乏空间几何和动力学可行性判断，导致不能有效地进行低层运动规划。为解决高层任务与低层运动规划的高效统一，本文提出新的框架。

Method: 设计了基于混合状态树的kinodynamic TAMP框架，将符号状态与数值状态统一表达，实现了任务决策与运动决策的联合优化。运动规划和物理仿真用于校验动力学约束，同时用VLM对规划过程中状态的可视化渲染进行引导和回溯搜索。

Result: 在仿真域和实际机器人环境中的实验结果表明，与传统及LLM驱动的TAMP方法相比，新方法的平均任务成功率提升32.14%至1166.67%，且在复杂任务上的规划时间明显减少。消融实验证明VLM的引导对性能提升尤为突出。

Conclusion: 该方法有效融合了符号任务、数值运动及视觉语义推理，大幅提升了TAMP系统在复杂和长时序任务中的表现，证明了VLM与运动仿真的结合在机器人自主规划中的巨大潜力。

Abstract: Task and Motion Planning (TAMP) integrates high-level task planning with
low-level motion feasibility, but existing methods are costly in long-horizon
problems due to excessive motion sampling. While LLMs provide commonsense
priors, they lack 3D spatial reasoning and cannot ensure geometric or dynamic
feasibility. We propose a kinodynamic TAMP framework based on a hybrid state
tree that uniformly represents symbolic and numeric states during planning,
enabling task and motion decisions to be jointly decided. Kinodynamic
constraints embedded in the TAMP problem are verified by an off-the-shelf
motion planner and physics simulator, and a VLM guides exploring a TAMP
solution and backtracks the search based on visual rendering of the states.
Experiments on the simulated domains and in the real world show 32.14% -
1166.67% increased average success rates compared to traditional and LLM-based
TAMP planners and reduced planning time on complex problems, with ablations
further highlighting the benefits of VLM guidance.

</details>


### [142] [Adaptive Trajectory Refinement for Optimization-based Local Planning in Narrow Passages](https://arxiv.org/abs/2510.26142)
*Hahjin Lee,Young J. Kim*

Main category: cs.RO

TL;DR: 本文提出了一种自适应轨迹优化算法，有效提升了移动机器人在复杂环境下、狭窄通道中的路径规划成功率和速度。


<details>
  <summary>Details</summary>
Motivation: 移动机器人在拥挤或狭窄环境中的轨迹规划依然面临巨大挑战，传统方法易在狭窄通道处失效或产生次优路径。因此，亟需一种更为鲁棒、安全且高效的路径优化方法。

Method: 算法分为两阶段。第一阶段，采用分段保守碰撞检测，将高风险碰撞段递归细分，直至消除风险。第二阶段，在位姿水平上，根据物体穿透方向及线搜索进行位姿修正，确保路径中每一点都安全且尽可能远离障碍物。

Result: 仿真结果显示新方法成功率最高提升1.69倍，规划速度提升3.79倍。实际实验也表明算法保证了机器人高效且安全地穿越狭窄通道。

Conclusion: 该自适应优化算法显著提升了拥挤环境中机器人的路径规划表现，可推广应用于现实复杂场景中。

Abstract: Trajectory planning for mobile robots in cluttered environments remains a
major challenge due to narrow passages, where conventional methods often fail
or generate suboptimal paths. To address this issue, we propose the adaptive
trajectory refinement algorithm, which consists of two main stages. First, to
ensure safety at the path-segment level, a segment-wise conservative collision
test is applied, where risk-prone trajectory path segments are recursively
subdivided until collision risks are eliminated. Second, to guarantee
pose-level safety, pose correction based on penetration direction and line
search is applied, ensuring that each pose in the trajectory is collision-free
and maximally clear from obstacles. Simulation results demonstrate that the
proposed method achieves up to 1.69x higher success rates and up to 3.79x
faster planning times than state-of-the-art approaches. Furthermore, real-world
experiments confirm that the robot can safely pass through narrow passages
while maintaining rapid planning performance.

</details>


### [143] [Self-localization on a 3D map by fusing global and local features from a monocular camera](https://arxiv.org/abs/2510.26170)
*Satoshi Kikuch,Masaya Kato,Tsuyoshi Tasaki*

Main category: cs.RO

TL;DR: 本研究提出了一种结合CNN和Vision Transformer的方法，提升了单目摄像头在动态环境下的三维地图自定位精度，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 单目摄像头便宜，适合在自动驾驶中实现自定位，但现有基于CNN的方法对动态障碍（如行人）环境下表现不佳，需要提升鲁棒性和精度。

Method: 提出将CNN与Vision Transformer结合，利用CNN提取局部特征、Vision Transformer提取全局特征，增强对动态障碍影响的抑制能力。

Result: 在含动态障碍的CG数据集中，相比最先进（SOTA）方法精度提升1.5倍；在公开数据集上平均定位误差比SOTA小20.1%；在实际机器人平台上，定位误差平均为7.51cm，优于SOTA。

Conclusion: 结合CNN与Vision Transformer的新方法有效提升了动态环境中单目视觉自定位的精度和鲁棒性，具有实际应用前景。

Abstract: Self-localization on a 3D map by using an inexpensive monocular camera is
required to realize autonomous driving. Self-localization based on a camera
often uses a convolutional neural network (CNN) that can extract local features
that are calculated by nearby pixels. However, when dynamic obstacles, such as
people, are present, CNN does not work well. This study proposes a new method
combining CNN with Vision Transformer, which excels at extracting global
features that show the relationship of patches on whole image. Experimental
results showed that, compared to the state-of-the-art method (SOTA), the
accuracy improvement rate in a CG dataset with dynamic obstacles is 1.5 times
higher than that without dynamic obstacles. Moreover, the self-localization
error of our method is 20.1% smaller than that of SOTA on public datasets.
Additionally, our robot using our method can localize itself with 7.51cm error
on average, which is more accurate than SOTA.

</details>


### [144] [PHUMA: Physically-Grounded Humanoid Locomotion Dataset](https://arxiv.org/abs/2510.26236)
*Kyungmin Lee,Sibeen Kim,Minho Park,Hyunseung Kim,Dongyoon Hwang,Hojoon Lee,Jaegul Choo*

Main category: cs.RO

TL;DR: 本文提出了PHUMA数据集，通过物理约束提升了大规模人类动作视频在类人机器人运动模仿中的真实性和稳定性，在多项任务上优于现有主流数据集。


<details>
  <summary>Details</summary>
Motivation: 当前类人运动模仿依赖高质量动作捕捉数据集（如AMASS），但这类数据集稀缺且昂贵，导致数据多样性和规模受限。部分研究尝试利用互联网大规模视频，但易引入如悬浮、穿模、滑步等物理问题，难以实现稳定模仿。

Method: 提出PHUMA数据集，结合大规模人类视频，通过精细化数据筛选和物理约束的动作重定向，强制关节极限、确保地面接触并消除脚部滑动，生成兼具规模和物理可靠性的动作序列。

Result: 在自录测试视频的动作模仿和仅以骨盆引导的路径跟随两项评估中，PHUMA训练的策略均超越Humanoid-X与AMASS，显著提升对多样动作的模仿能力。

Conclusion: PHUMA结合规模化视频与稳定物理约束，克服现有方法在数据规模扩大时的物理不真实问题，在类人运动模仿领域实现更高表现，并推动更真实、多样化的机器人运动学习。

Abstract: Motion imitation is a promising approach for humanoid locomotion, enabling
agents to acquire humanlike behaviors. Existing methods typically rely on
high-quality motion capture datasets such as AMASS, but these are scarce and
expensive, limiting scalability and diversity. Recent studies attempt to scale
data collection by converting large-scale internet videos, exemplified by
Humanoid-X. However, they often introduce physical artifacts such as floating,
penetration, and foot skating, which hinder stable imitation. In response, we
introduce PHUMA, a Physically-grounded HUMAnoid locomotion dataset that
leverages human video at scale, while addressing physical artifacts through
careful data curation and physics-constrained retargeting. PHUMA enforces joint
limits, ensures ground contact, and eliminates foot skating, producing motions
that are both large-scale and physically reliable. We evaluated PHUMA in two
sets of conditions: (i) imitation of unseen motion from self-recorded test
videos and (ii) path following with pelvis-only guidance. In both cases,
PHUMA-trained policies outperform Humanoid-X and AMASS, achieving significant
gains in imitating diverse motions. The code is available at
https://davian-robotics.github.io/PHUMA.

</details>


### [145] [Thor: Towards Human-Level Whole-Body Reactions for Intense Contact-Rich Environments](https://arxiv.org/abs/2510.26280)
*Gangyang Li,Qing Shi,Youhao Hu,Jincheng Hu,Zhongyuan Wang,Xinlong Wang,Shaqi Luo*

Main category: cs.RO

TL;DR: 本论文提出了一种名为Thor的新型人形机器人控制框架，在力交互任务中能表现出类人的整体身体反应，在类人体态稳定性和力适应性任务上相比传统方法大幅提升。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人在服务、工业和救援等场景中需要在与环境强力交互时保持全身稳定性，但实现类人的自适应反应依然困难，亟需突破。

Method: 作者提出了Thor框架，并设计了一种基于机器人力分析的力自适应躯干倾斜（FAT2）奖励函数，引导机器人在力交互任务中产生更类人的反应。采用分体强化学习架构，将机器人上半身、腰部和下半身控制分别进行，但共享全局观测、联合参数更新。

Result: 在Unitree G1机器人上部署后，Thor在向前与向后施力任务中，比最佳基线提升了68.9%和74.7%的最大拉力，并成功完成单手开门和拉动负载等实际任务。

Conclusion: Thor显著提升了人形机器人在力交互环境下的人体级反应能力，有助于拓展其在实际服务和救援等复杂场景的应用潜力。

Abstract: Humanoids hold great potential for service, industrial, and rescue
applications, in which robots must sustain whole-body stability while
performing intense, contact-rich interactions with the environment. However,
enabling humanoids to generate human-like, adaptive responses under such
conditions remains a major challenge. To address this, we propose Thor, a
humanoid framework for human-level whole-body reactions in contact-rich
environments. Based on the robot's force analysis, we design a force-adaptive
torso-tilt (FAT2) reward function to encourage humanoids to exhibit human-like
responses during force-interaction tasks. To mitigate the high-dimensional
challenges of humanoid control, Thor introduces a reinforcement learning
architecture that decouples the upper body, waist, and lower body. Each
component shares global observations of the whole body and jointly updates its
parameters. Finally, we deploy Thor on the Unitree G1, and it substantially
outperforms baselines in force-interaction tasks. Specifically, the robot
achieves a peak pulling force of 167.7 N (approximately 48% of the G1's body
weight) when moving backward and 145.5 N when moving forward, representing
improvements of 68.9% and 74.7%, respectively, compared with the
best-performing baseline. Moreover, Thor is capable of pulling a loaded rack
(130 N) and opening a fire door with one hand (60 N). These results highlight
Thor's effectiveness in enhancing humanoid force-interaction capabilities.

</details>


### [146] [AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian Splatting SLAM](https://arxiv.org/abs/2510.26358)
*Mirko Usuelli,David Rapado-Rincon,Gert Kootstra,Matteo Matteucci*

Main category: cs.RO

TL;DR: 本文提出了AgriGS-SLAM系统，将视觉与LiDAR融合，实现果园环境下高效、精确的3D场景建图和定位，能够应对果园中季节变化、重复行结构和风引起的植被运动等挑战，在多个季节和果园场景中验证了其优越性，并具备实时性。


<details>
  <summary>Details</summary>
Motivation: 果园场景结构复杂，存在重复排布、季节性外观变化及风导致的树叶运动等干扰，这对自主机器人在果园中的实时高精度3D感知和定位提出很高要求。而现有方法在鲁棒性、细节恢复和实时性上仍有不足，尤其是处理视觉和LiDAR数据的高效融合及在遮挡严重场景下的场景重建，因此亟需新的高效、多模态融合SLAM方法以适应果园等复杂户外环境。

Method: AgriGS-SLAM系统结合了直接的LiDAR里程计与闭环检测，并融入了多相机的3D高斯渲染（3DGS）。通过跨视角的批量渲染，提升了复杂遮挡下的结构恢复能力。在关键帧间以梯度驱动的统一建图流程，实现精细细节保持且限制内存占用。此外，加入了基于概率的LiDAR深度一致性约束，通过相机投影反向传播优化位姿，实现几何-外观一致性的精细配合。该系统在不同季节和果园类型下实地部署，采用标准化轨迹协议进行性能评测，兼顾训练视角与新视角渲染，降低过拟合风险。

Result: 在苹果和梨等果园的多个季节（休眠、开花、收获）与场景下，AgriGS-SLAM较最新3DGS-SLAM对比基线方法获得了更清晰、更稳定的重建效果以及更平稳的机器人追踪轨迹，并且能够满足实时、车载应用需求。评估涵盖了训练集视角和新视角，验证了泛化性，减小了3DGS渲染的过拟合现象。

Conclusion: AgriGS-SLAM突破了果园复杂环境下3D场景实时感知与重建的技术难题，展现出强鲁棒性和高精度。该方法不仅适用于果园监控，还具备迁移到其他需多模态感知的户外自动驾驶与机器人领域的潜力。

Abstract: Autonomous robots in orchards require real-time 3D scene understanding
despite repetitive row geometry, seasonal appearance changes, and wind-driven
foliage motion. We present AgriGS-SLAM, a Visual--LiDAR SLAM framework that
couples direct LiDAR odometry and loop closures with multi-camera 3D Gaussian
Splatting (3DGS) rendering. Batch rasterization across complementary viewpoints
recovers orchard structure under occlusions, while a unified gradient-driven
map lifecycle executed between keyframes preserves fine details and bounds
memory. Pose refinement is guided by a probabilistic LiDAR-based depth
consistency term, back-propagated through the camera projection to tighten
geometry-appearance coupling. We deploy the system on a field platform in apple
and pear orchards across dormancy, flowering, and harvesting, using a
standardized trajectory protocol that evaluates both training-view and
novel-view synthesis to reduce 3DGS overfitting in evaluation. Across seasons
and sites, AgriGS-SLAM delivers sharper, more stable reconstructions and
steadier trajectories than recent state-of-the-art 3DGS-SLAM baselines while
maintaining real-time performance on-tractor. While demonstrated in orchard
monitoring, the approach can be applied to other outdoor domains requiring
robust multimodal perception.

</details>


### [147] [Cooperative Task Spaces for Multi-Arm Manipulation Control based on Similarity Transformations](https://arxiv.org/abs/2510.26362)
*Tobias Löw,Cem Bilaloglu,Sylvain Calinon*

Main category: cs.RO

TL;DR: 本文提出了一种基于共形几何代数的多臂机器人协作任务空间理论基础，并通过解析和几何Jacobian矩阵将其与经典控制方法融合，展示了在多种机器人系统中的有效性。


<details>
  <summary>Details</summary>
Motivation: 多运动链机器人在协作搬运大物体或实现灵巧操作时具有很高的自由度，导致其动作协同变得非常复杂和难以建模。作者希望建立一种统一、简洁的理论基础来更好地刻画和控制这些多臂系统的协作行为。

Method: 作者利用共形几何代数定义协作几何基元，通过相似变换导出一种对复杂多臂机器人系统的抽象方法，使其建模方式与单臂系统直接对应。推导了相关的解析和几何Jacobian矩阵，并将其无缝集成到基于操作空间控制的传统控制框架中。采用双臂机械臂、人形机器人和多指机械手进行最优控制和遥操作实验验证方法有效性。

Result: 在仿真和遥操作实验中，提出的方法能够有效控制多种复杂机器人系统精确地到达目标几何基元。此外，该方法中的几何基元为控制器自然嵌入了nullspace结构，可进一步用于二次控制目标。

Conclusion: 该工作为多臂协作操作的控制提供了系统的理论基础，实现复杂机器人系统的统一表示与高效控制，同时为未来相关实际应用指明了方向。

Abstract: Many tasks in human environments require collaborative behavior between
multiple kinematic chains, either to provide additional support for carrying
big and bulky objects or to enable the dexterity that is required for in-hand
manipulation. Since these complex systems often have a very high number of
degrees of freedom coordinating their movements is notoriously difficult to
model. In this article, we present the derivation of the theoretical
foundations for cooperative task spaces of multi-arm robotic systems based on
geometric primitives defined using conformal geometric algebra. Based on the
similarity transformations of these cooperative geometric primitives, we derive
an abstraction of complex robotic systems that enables representing these
systems in a way that directly corresponds to single-arm systems. By deriving
the associated analytic and geometric Jacobian matrices, we then show the
straightforward integration of our approach into classical control techniques
rooted in operational space control. We demonstrate this using bimanual
manipulators, humanoids and multi-fingered hands in optimal control experiments
for reaching desired geometric primitives and in teleoperation experiments
using differential kinematics control. We then discuss how the geometric
primitives naturally embed nullspace structures into the controllers that can
be exploited for introducing secondary control objectives. This work,
represents the theoretical foundations of this cooperative manipulation control
framework, and thus the experiments are presented in an abstract way, while
giving pointers towards potential future applications.

</details>


### [148] [Towards Reinforcement Learning Based Log Loading Automation](https://arxiv.org/abs/2510.26363)
*Ilya Kurinov,Miroslav Ivanov,Grzegorz Orzechowski,Aki Mikkola*

Main category: cs.RO

TL;DR: 本文提出利用强化学习智能体，实现林业运材机自动装载原木的全过程（定位、抓取、搬运、卸载），并在仿真环境中获得94%的成功率。


<details>
  <summary>Details</summary>
Motivation: 林业运材机驾驶员需长期在偏远环境下进行繁重、单调的原木搬运操作，身心压力大。实现自动化有望减轻其负担，提高作业效率和安全性。

Method: 开发基于NVIDIA Isaac Gym的仿真环境，对典型的原木加载场景进行模拟；采用强化学习强化智能体，用课程式学习策略依次训练抓取、搬运、卸载全流程。

Result: 智能体在随机位置下，能自动完成原木的定位、抓取和搬运到车床，最佳模型装载成功率达到94%。

Conclusion: 强化学习智能体在林业运材机自动装载任务中展现出高效、稳定的性能，为推动该领域自动化应用迈出重要一步。

Abstract: Forestry forwarders play a central role in mechanized timber harvesting by
picking up and moving logs from the felling site to a processing area or a
secondary transport vehicle. Forwarder operation is challenging and physically
and mentally exhausting for the operator who must control the machine in remote
areas for prolonged periods of time. Therefore, even partial automation of the
process may reduce stress on the operator. This study focuses on continuing
previous research efforts in application of reinforcement learning agents in
automating log handling process, extending the task from grasping which was
studied in previous research to full log loading operation. The resulting agent
will be capable to automate a full loading procedure from locating and
grappling to transporting and delivering the log to a forestry forwarder bed.
To train the agent, a trailer type forestry forwarder simulation model in
NVIDIA's Isaac Gym and a virtual environment for a typical log loading scenario
were developed. With reinforcement learning agents and a curriculum learning
approach, the trained agent may be a stepping stone towards application of
reinforcement learning agents in automation of the forestry forwarder. The
agent learnt grasping a log in a random position from grapple's random position
and transport it to the bed with 94% success rate of the best performing agent.

</details>


### [149] [Human-in-the-loop Online Rejection Sampling for Robotic Manipulation](https://arxiv.org/abs/2510.26406)
*Guanxing Lu,Rui Zhao,Haitao Lin,He Zhang,Yansong Tang*

Main category: cs.RO

TL;DR: 提出了一种名为Hi-ORS的新型后训练方法，有效结合了强化学习和模仿学习的优点，实现了更高效、鲁棒的机器人操作策略微调。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习在微调视觉-语言-动作模型（VLA）时，由于价值估计不准确和中间步骤监督稀疏，训练过程不稳定；而模仿学习虽然训练简单，但因为与真实交互有限，效果欠佳。作者希望解决这两种方法的缺陷，实现训练稳定性和鲁棒性的兼得。

Method: 提出Hi-ORS方法，通过拒绝采样过滤掉奖励为负的样本，稳定价值估计；采用奖励加权的监督训练目标，提供密集的中间监督。此外，开发了异步推断-训练框架，支持在线人类校正，指导学习错误恢复行为。

Result: 在三个现实任务和两种具体机器人形态上，Hi-ORS可以在1.5小时内将基础策略微调到能掌握复杂接触操作，显著优于RL和IL基线，在效率和效果上均有提升。

Conclusion: Hi-ORS既有模仿学习的训练简便性，也具备强化学习的鲁棒性。微调后的策略不仅有效高效，还具备强大的测试时可扩展性，能可靠执行复杂的错误恢复操作，性能显著提升。

Abstract: Reinforcement learning (RL) is widely used to produce robust robotic
manipulation policies, but fine-tuning vision-language-action (VLA) models with
RL can be unstable due to inaccurate value estimates and sparse supervision at
intermediate steps. In contrast, imitation learning (IL) is easy to train but
often underperforms due to its offline nature. In this paper, we propose
Hi-ORS, a simple yet effective post-training method that utilizes rejection
sampling to achieve both training stability and high robustness. Hi-ORS
stabilizes value estimation by filtering out negatively rewarded samples during
online fine-tuning, and adopts a reward-weighted supervised training objective
to provide dense intermediate-step supervision. For systematic study, we
develop an asynchronous inference-training framework that supports flexible
online human-in-the-loop corrections, which serve as explicit guidance for
learning error-recovery behaviors. Across three real-world tasks and two
embodiments, Hi-ORS fine-tunes a pi-base policy to master contact-rich
manipulation in just 1.5 hours of real-world training, outperforming RL and IL
baselines by a substantial margin in both effectiveness and efficiency.
Notably, the fine-tuned policy exhibits strong test-time scalability by
reliably executing complex error-recovery behaviors to achieve better
performance.

</details>


### [150] [RoboOS-NeXT: A Unified Memory-based Framework for Lifelong, Scalable, and Robust Multi-Robot Collaboration](https://arxiv.org/abs/2510.26536)
*Huajie Tan,Cheng Chi,Xiansheng Chen,Yuheng Ji,Zhongxia Zhao,Xiaoshuai Hao,Yaoxu Lyu,Mingyu Cao,Junkai Zhao,Huaihai Lyu,Enshen Zhou,Ning Chen,Yankai Fu,Cheng Peng,Wei Guo,Dong Liang,Zhuo Chen,Mengsi Lyu,Chenrui He,Yulong Ao,Yonghua Lin,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang*

Main category: cs.RO

TL;DR: RoboOS-NeXT提出了一种基于统一记忆的新型多机器人协作框架，通过空间-时间-实体记忆，显著提升了机器人系统的适应性、可扩展性和鲁棒性，在多种复杂场景下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多机器人协作方法由于记忆依赖个体单元，导致难以实现长期学习、规模化团队协作及出错恢复，因此亟需一种统一的记忆表示以优化多机器人系统的核心能力。

Method: 提出RoboOS-NeXT框架，核心是引入空间-时间-实体记忆（STEM），统一整合场景几何、事件历史和机器人体态信息。将该记忆体融入类似“大脑-小脑”的决策架构，高层全局规划结合低层执行，实现记忆检索/更新与动作闭环。

Result: 在餐厅、超市、家庭等复杂多机器人场景中进行实验，RoboOS-NeXT在任务分配、协作容错和状态同步等方面表现出明显优越性，能适应不同类型机器人协同任务。

Conclusion: RoboOS-NeXT验证了统一记忆框架在解决多机器人长期、可扩展和鲁棒协作中的有效性，为未来高效多体系统协作提供了新方案。

Abstract: The proliferation of collaborative robots across diverse tasks and
embodiments presents a central challenge: achieving lifelong adaptability,
scalable coordination, and robust scheduling in multi-agent systems. Existing
approaches, from vision-language-action (VLA) models to hierarchical
frameworks, fall short due to their reliance on limited or dividual-agent
memory. This fundamentally constrains their ability to learn over long
horizons, scale to heterogeneous teams, or recover from failures, highlighting
the need for a unified memory representation. To address these limitations, we
introduce RoboOS-NeXT, a unified memory-based framework for lifelong, scalable,
and robust multi-robot collaboration. At the core of RoboOS-NeXT is the novel
Spatio-Temporal-Embodiment Memory (STEM), which integrates spatial scene
geometry, temporal event history, and embodiment profiles into a shared
representation. This memory-centric design is integrated into a
brain-cerebellum framework, where a high-level brain model performs global
planning by retrieving and updating STEM, while low-level controllers execute
actions locally. This closed loop between cognition, memory, and execution
enables dynamic task allocation, fault-tolerant collaboration, and consistent
state synchronization. We conduct extensive experiments spanning complex
coordination tasks in restaurants, supermarkets, and households. Our results
demonstrate that RoboOS-NeXT achieves superior performance across heterogeneous
embodiments, validating its effectiveness in enabling lifelong, scalable, and
robust multi-robot collaboration. Project website:
https://flagopen.github.io/RoboOS/

</details>


### [151] [Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool Manipulation in Robotics](https://arxiv.org/abs/2510.26551)
*Prathamesh Kothavale,Sravani Boddepalli*

Main category: cs.RO

TL;DR: 本文提出了一种创新性框架，使机器人能够掌握和使用不同长度工具完成任务，提升其工具操作能力，并在仿真和真实环境下取得了低误差表现。


<details>
  <summary>Details</summary>
Motivation: 传统机器人只能执行预编程任务，对自身运动学理解有限，工具使用受限。论文旨在突破这些限制，让机器人能灵活高效地选择与操作工具，拓展实际应用能力。

Method: 作者扩展了机器人的逆运动学（IK）求解器，并结合模拟学习得到的动作轨迹，实现了机器人利用不同长度工具执行一系列任务动作。通过实验验证了从仿真到现实世界的技能迁移能力。

Result: 扩展后的逆运动学求解器具备优秀精度，误差小于1厘米；训练得到的策略在仿真中的平均误差为8厘米。模型在使用长度不同的两种工具时，表现几乎无差别。

Conclusion: 本研究展示了利用扩展逆运动学求解器及模拟学习，机器人在工具使用四大关键环节均取得明显提升。这为机器人复杂工具操作和多任务学习提供了坚实基础。

Abstract: Conventional robots possess a limited understanding of their kinematics and
are confined to preprogrammed tasks, hindering their ability to leverage tools
efficiently. Driven by the essential components of tool usage - grasping the
desired outcome, selecting the most suitable tool, determining optimal tool
orientation, and executing precise manipulations - we introduce a pioneering
framework. Our novel approach expands the capabilities of the robot's inverse
kinematics solver, empowering it to acquire a sequential repertoire of actions
using tools of varying lengths. By integrating a simulation-learned action
trajectory with the tool, we showcase the practicality of transferring acquired
skills from simulation to real-world scenarios through comprehensive
experimentation. Remarkably, our extended inverse kinematics solver
demonstrates an impressive error rate of less than 1 cm. Furthermore, our
trained policy achieves a mean error of 8 cm in simulation. Noteworthy, our
model achieves virtually indistinguishable performance when employing two
distinct tools of different lengths. This research provides an indication of
potential advances in the exploration of all four fundamental aspects of tool
usage, enabling robots to master the intricate art of tool manipulation across
diverse tasks.

</details>


### [152] [FLYINGTRUST: A Benchmark for Quadrotor Navigation Across Scenarios and Vehicles](https://arxiv.org/abs/2510.26588)
*Gang Li,Chunlei Zhai,Teng Wang,Shaun Li,Shangsong Jiang,Xiangwei Zhu*

Main category: cs.RO

TL;DR: 本文提出了FLYINGTRUST，一种高保真、可配置的无人机视觉导航算法测试基准，全面考察飞行平台动力学与场景结构对导航鲁棒性的影响。通过标准化评测流程和复合评分方法，比对不同算法和平台，揭示了鲁棒性依赖于平台能力与场景结构。


<details>
  <summary>Details</summary>
Motivation: 现有四旋翼视觉导航算法在不同平台和场景下表现波动大，导致实际部署代价和风险增加，缺乏系统化、可重复的评测方式，难以促进算法的稳健性进步。

Method: 提出FLYINGTRUST基准框架，以最大推重比、各轴最大角加速度两指标刻画平台能力，结合多样化场景库和虚实混合平台集，对导航算法采用标准实验流程、复合评分与不确定性感知指标系统性评估。

Result: 实验对比了优化型与学习型导航方法，结果显示导航表现可由平台能力和场景几何共同预测，不同算法在不同平台与场景组合下有各自偏好和失败模式。

Conclusion: 导航算法设计与评估应同时纳入平台能力与场景结构考量，提升跨平台-场景稳健性是未来研究方向。

Abstract: Visual navigation algorithms for quadrotors often exhibit a large variation
in performance when transferred across different vehicle platforms and scene
geometries, which increases the cost and risk of field deployment. To support
systematic early-stage evaluation, we introduce FLYINGTRUST, a high-fidelity,
configurable benchmarking framework that measures how platform kinodynamics and
scenario structure jointly affect navigation robustness. FLYINGTRUST models
vehicle capability with two compact, physically interpretable indicators:
maximum thrust-to-weight ratio and axis-wise maximum angular acceleration. The
benchmark pairs a diverse scenario library with a heterogeneous set of real and
virtual platforms and prescribes a standardized evaluation protocol together
with a composite scoring method that balances scenario importance, platform
importance and performance stability. We use FLYINGTRUST to compare
representative optimization-based and learning-based navigation approaches
under identical conditions, performing repeated trials per platform-scenario
combination and reporting uncertainty-aware metrics. The results reveal
systematic patterns: navigation success depends predictably on platform
capability and scene geometry, and different algorithms exhibit distinct
preferences and failure modes across the evaluated conditions. These
observations highlight the practical necessity of incorporating both platform
capability and scenario structure into algorithm design, evaluation, and
selection, and they motivate future work on methods that remain robust across
diverse platforms and scenarios.

</details>


### [153] [A Sliding-Window Filter for Online Continuous-Time Continuum Robot State Estimation](https://arxiv.org/abs/2510.26623)
*Spencer Teetaert,Sven Lilge,Jessica Burgner-Kahrs,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的连续时间滑动窗口滤波（SWF）方法，实现了连续时间下连续体机器人（CRs）状态的高效随机估计，兼顾精度和实时效率。


<details>
  <summary>Details</summary>
Motivation: 现有的连续体机器人随机状态估计算法在精度和计算效率之间难以兼顾。此前滑动窗口方法仅限离散时间近似且无随机性，随机滤波则受制于测量频率，无法发挥全部潜力；而连续时间估计算法目前仅能离线运行，实用性受限。

Method: 作者提出了一种连续时间的滑动窗口滤波（SWF）方法，将连续时间随机状态估计与滑动窗口思想结合，提升估计精度的同时支持在线实时运行，且实现了快于实时的预测软件性能。

Result: 新方法较传统滤波方法在状态估计精度上有显著提升，并能够支持连续体机器人在线实时的高效运行。通过对比实验验证了该方法的有效性和优越性。

Conclusion: 首次为连续体机器人提出了专门的连续时间随机滑动窗口滤波器，为该领域后续研究开启了有前景的方向。

Abstract: Stochastic state estimation methods for continuum robots (CRs) often struggle
to balance accuracy and computational efficiency. While several recent works
have explored sliding-window formulations for CRs, these methods are limited to
simplified, discrete-time approximations and do not provide stochastic
representations. In contrast, current stochastic filter methods must run at the
speed of measurements, limiting their full potential. Recent works in
continuous-time estimation techniques for CRs show a principled approach to
addressing this runtime constraint, but are currently restricted to offline
operation. In this work, we present a sliding-window filter (SWF) for
continuous-time state estimation of CRs that improves upon the accuracy of a
filter approach while enabling continuous-time methods to operate online, all
while running at faster-than-real-time speeds. This represents the first
stochastic SWF specifically designed for CRs, providing a promising direction
for future research in this area.

</details>


### [154] [REALMS2 - Resilient Exploration And Lunar Mapping System 2 - A Comprehensive Approach](https://arxiv.org/abs/2510.26638)
*Dave van der Meer,Loïck P. Chovet,Gabriel M. Garcia,Abhishek Bera,Miguel A. Olivares-Mendez*

Main category: cs.RO

TL;DR: 本文介绍了REALMS2系统——一个用于行星探测和地图绘制的多机器人系统（MRS），其在ESA-ESRIC的测试中实现了60%区域的高效自动化勘测。


<details>
  <summary>Details</summary>
Motivation: 随着深空探测任务日益增多，需要高效、可靠的多机器人系统来解决复杂的外星环境下的勘测与制图任务。

Method: 提出REALMS2框架，基于ROS 2系统，运用视觉同步定位与制图技术（vSLAM），采用网状自组网络实现多机器人通讯，并通过统一GUI控制多个探测机器人，提升系统的管理效率与通信鲁棒性。

Result: REALMS2在ESA-ESRIC挑战赛第二轮实地测试中，利用三台同构探测车，克服了通信延迟和断链问题，成功完成了约60%区域的地图绘制任务。

Conclusion: REALMS2多机器人系统能够有效应对外星环境下的勘测与通信挑战，在行星表面资源探测中展现出良好的应用前景和稳定性。

Abstract: The European Space Agency (ESA) and the European Space Resources Innovation
Centre (ESRIC) created the Space Resources Challenge to invite researchers and
companies to propose innovative solutions for Multi-Robot Systems (MRS) space
prospection. This paper proposes the Resilient Exploration And Lunar Mapping
System 2 (REALMS2), a MRS framework for planetary prospection and mapping.
Based on Robot Operating System version 2 (ROS 2) and enhanced with Visual
Simultaneous Localisation And Mapping (vSLAM) for map generation, REALMS2 uses
a mesh network for a robust ad hoc network. A single graphical user interface
(GUI) controls all the rovers, providing a simple overview of the robotic
mission. This system is designed for heterogeneous multi-robot exploratory
missions, tackling the challenges presented by extraterrestrial environments.
REALMS2 was used during the second field test of the ESA-ESRIC Challenge and
allowed to map around 60% of the area, using three homogeneous rovers while
handling communication delays and blackouts.

</details>


### [155] [Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments](https://arxiv.org/abs/2510.26646)
*Xiaoyi He,Danggui Chen,Zhenshuo Zhang,Zimeng Bai*

Main category: cs.RO

TL;DR: 本文提出了一种层次化路径规划与控制框架，结合了高层DQN子目标选择与低层TD3连续控制。通过实际奖励设计和LiDAR安全机制，有效提升了在动态、部分可观环境下的导航成功率和效率。实验表现优于单一算法和规则基线。


<details>
  <summary>Details</summary>
Motivation: 传统单一强化学习或规则方法在动态、不可完全观测环境中的路径规划存在成功率低、泛化能力差和控制不平滑的问题。为提升机器人在实际环境中的导航性能，作者希望结合多级强化学习与增强安全机制。

Method: 采用分层结构：高层使用DQN进行离散子目标（行为）选择，低层用TD3进行连续动作控制。配合包含方向、距离、避障、平滑、碰撞和时间惩罚等因素的奖励函数，及利用LiDAR的安全机制防止危险动作，并在ROS + Gazebo仿真平台进行系统实现和测试。

Result: 在PathBench指标（包括成功率、碰撞率、路径效率和重规划效率）下，本方法在动态且部分可观环境中，成功率和样本效率均优于仅用DQN、TD3或规则基线方案，对新环境的泛化及控制平滑性也有所提升。

Conclusion: 分层强化学习结合安全机制有助于提升移动机器人在复杂环境中的导航能力，优于传统单一方法，具备更强的泛化与实际部署潜力。

Abstract: This paper presents a hierarchical path-planning and control framework that
combines a high-level Deep Q-Network (DQN) for discrete sub-goal selection with
a low-level Twin Delayed Deep Deterministic Policy Gradient (TD3) controller
for continuous actuation. The high-level module selects behaviors and
sub-goals; the low-level module executes smooth velocity commands. We design a
practical reward shaping scheme (direction, distance, obstacle avoidance,
action smoothness, collision penalty, time penalty, and progress), together
with a LiDAR-based safety gate that prevents unsafe motions. The system is
implemented in ROS + Gazebo (TurtleBot3) and evaluated with PathBench metrics,
including success rate, collision rate, path efficiency, and re-planning
efficiency, in dynamic and partially observable environments. Experiments show
improved success rate and sample efficiency over single-algorithm baselines
(DQN or TD3 alone) and rule-based planners, with better generalization to
unseen obstacle configurations and reduced abrupt control changes. Code and
evaluation scripts are available at the project repository.

</details>


### [156] [Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems](https://arxiv.org/abs/2510.26656)
*Georgios Kamaras,Craig Innes,Subramanian Ramamoorthy*

Main category: cs.RO

TL;DR: 本文提出了三种针对机器人无似然推断（LFI）中支撑集适应性的启发式变体（EDGE、MODE、CENTRE），能有效提升后验推断的准确性与智能体性能。


<details>
  <summary>Details</summary>
Motivation: LFI在机器人领域中常用于适配部署时的参数变化，但其依赖的初始支撑集可能导致后验分布失真和鲁棒性下降，亟需改进以提升推断和学习效果。

Method: 提出了EDGE、MODE和CENTRE三种启发式LFI方法，每种方法通过不同方式解读推断过程中后验众数的变化，动态调整LFI的支撑集，并与现有LFI步骤集成。

Result: 在随机动力学基准和可变形线性物体（DLO）操作任务中评估，提出的启发式方法显著改善了参数推断的准确性和类别区分度，增强了策略学习时智能体的鲁棒性和任务表现。

Conclusion: 动态适应支撑集的LFI变体能缓解原方法中支撑集失配导致的不准确后验问题，为基于仿真的策略学习提供更优的领域分布，从而实现更强鲁棒性的机器人学习。

Abstract: In robotics, likelihood-free inference (LFI) can provide the domain
distribution that adapts a learnt agent in a parametric set of deployment
conditions. LFI assumes an arbitrary support for sampling, which remains
constant as the initial generic prior is iteratively refined to more
descriptive posteriors. However, a potentially misspecified support can lead to
suboptimal, yet falsely certain, posteriors. To address this issue, we propose
three heuristic LFI variants: EDGE, MODE, and CENTRE. Each interprets the
posterior mode shift over inference steps in its own way and, when integrated
into an LFI step, adapts the support alongside posterior inference. We first
expose the support misspecification issue and evaluate our heuristics using
stochastic dynamical benchmarks. We then evaluate the impact of heuristic
support adaptation on parameter inference and policy learning for a dynamic
deformable linear object (DLO) manipulation task. Inference results in a finer
length and stiffness classification for a parametric set of DLOs. When the
resulting posteriors are used as domain distributions for sim-based policy
learning, they lead to more robust object-centric agent performance.

</details>


### [157] [Hybrid Consistency Policy: Decoupling Multi-Modal Diversity and Real-Time Efficiency in Robotic Manipulation](https://arxiv.org/abs/2510.26670)
*Qianyou Zhao,Yuliang Shen,Xuanran Zhai,Ce Hao,Duidi Wu,Jin Qi,Jie Hu,Qiaojun Yu*

Main category: cs.RO

TL;DR: 本文提出了一种新的混合一致性策略（HCP）用于视觉运动控制中的扩散模仿学习，既能保持多样性，又显著加快采样速度。通过在前期采用少量随机步进，并通过一次“一致性跳跃”完成输出，既提高了速度又保留了行为多模态性。实验证明HCP在仿真和实际机器人上都极大提升了推理效率，且准确率和模式覆盖接近传统慢速方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的模仿学习方法虽然能捕捉多模态行为，但因采样步骤繁多导致推理缓慢，难以在实际机器人任务中应用。如何在保持多模态性的同时显著加快推理速度成为一个亟需解决的问题。

Method: 作者提出HCP方法，在策略生成时先进行短暂的随机步进至自适应的“切换时间”，然后通过“一步一致性跳跃”输出最终动作。此外，训练中采用时间变化一致性蒸馏，结合轨迹一致性和去噪匹配目标以提升预测连贯性和本地精度。

Result: 在仿真和真实机器人测试中，HCP只需25步SDE和一次跳跃，性能（准确率和多模态覆盖）已接近传统80步DDPM扩散方法，且显著降低了推理延迟。

Conclusion: HCP有效解决了扩散策略在多模态与效率之间的矛盾，实现了速度与精度的权衡。这表明多模态采样不再依赖慢速推理，对机器人控制具有广泛实用价值。

Abstract: In visuomotor policy learning, diffusion-based imitation learning has become
widely adopted for its ability to capture diverse behaviors. However,
approaches built on ordinary and stochastic denoising processes struggle to
jointly achieve fast sampling and strong multi-modality. To address these
challenges, we propose the Hybrid Consistency Policy (HCP). HCP runs a short
stochastic prefix up to an adaptive switch time, and then applies a one-step
consistency jump to produce the final action. To align this one-jump
generation, HCP performs time-varying consistency distillation that combines a
trajectory-consistency objective to keep neighboring predictions coherent and a
denoising-matching objective to improve local fidelity. In both simulation and
on a real robot, HCP with 25 SDE steps plus one jump approaches the 80-step
DDPM teacher in accuracy and mode coverage while significantly reducing
latency. These results show that multi-modality does not require slow
inference, and a switch time decouples mode retention from speed. It yields a
practical accuracy efficiency trade-off for robot policies.

</details>


### [158] [Running VLAs at Real-time Speed](https://arxiv.org/abs/2510.26742)
*Yunchao Ma,Yizhuang Zhou,Yunhuan Yang,Tiancai Wang,Haoqiang Fan*

Main category: cs.RO

TL;DR: 本文展示了一种利用单块消费级GPU实现30Hz帧率、480Hz轨迹频率的pi0级多视图VLA（视觉-语言-动作）模型实时推理方法，实现了大规模VLA模型在动态任务下的实时应用。


<details>
  <summary>Details</summary>
Motivation: 当前大规模VLA模型由于推理速度瓶颈，难以应用于需要高频响应的动态和实时机器人任务。作者旨在突破推理速度限制，将VLA模型应用于实时机器人控制场景。

Method: 作者提出一系列策略，大幅度削减VLA模型推理过程中的各种开销，使得在单卡GPU上多视图输入的pi0级模型能以极高频率稳定运行。并将这些策略集成到一个完整的实时流推理框架，用于机器人控制。

Result: 实验证明，该方法使pi0策略能够以100%抓取成功率完成“捡落笔”这一高难度动态任务。此外提供了实时流推理框架，满足实际机器人的实时控制需要。

Conclusion: 本文方法突破了VLA模型实时动态任务应用的瓶颈，证明大模型也能实时高效地应用于机器人控制领域，并为后续相关研究奠定了基础。

Abstract: In this paper, we show how to run pi0-level multi-view VLA at 30Hz frame rate
and at most 480Hz trajectory frequency using a single consumer GPU. This
enables dynamic and real-time tasks that were previously believed to be
unattainable by large VLA models. To achieve it, we introduce a bag of
strategies to eliminate the overheads in model inference. The real-world
experiment shows that the pi0 policy with our strategy achieves a 100% success
rate in grasping a falling pen task. Based on the results, we further propose a
full streaming inference framework for real-time robot control of VLA. Code is
available at https://github.com/Dexmal/realtime-vla.

</details>
